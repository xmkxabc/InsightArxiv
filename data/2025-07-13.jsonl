{"id": "2507.08158", "title": "Beyond the Worst Case: Extending Differential Privacy Guarantees to Realistic Adversaries", "authors": ["Marika Swanberg", "Meenatchi Sundaram Muthu Selva Annamalai", "Jamie Hayes", "Borja Balle", "Adam Smith"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08158v1", "summary": "Differential Privacy (DP) is a family of definitions that bound the\nworst-case privacy leakage of a mechanism. One important feature of the\nworst-case DP guarantee is it naturally implies protections against adversaries\nwith less prior information, more sophisticated attack goals, and complex\nmeasures of a successful attack. However, the analytical tradeoffs between the\nadversarial model and the privacy protections conferred by DP are not well\nunderstood thus far. To that end, this work sheds light on what the worst-case\nguarantee of DP implies about the success of attackers that are more\nrepresentative of real-world privacy risks.\n  In this paper, we present a single flexible framework that generalizes and\nextends the patchwork of bounds on DP mechanisms found in prior work. Our\nframework allows us to compute high-probability guarantees for DP mechanisms on\na large family of natural attack settings that previous bounds do not capture.\nOne class of such settings is the approximate reconstruction of multiple\nindividuals' data, such as inferring nearly entire columns of a tabular data\nset from noisy marginals and extracting sensitive information from DP-trained\nlanguage models.\n  We conduct two empirical case studies to illustrate the versatility of our\nbounds and compare them to the success of state-of-the-art attacks.\nSpecifically, we study attacks that extract non-uniform PII from a DP-trained\nlanguage model, as well as multi-column reconstruction attacks where the\nadversary has access to some columns in the clear and attempts to reconstruct\nthe remaining columns for each person's record. We find that the absolute\nprivacy risk of attacking non-uniform data is highly dependent on the\nadversary's prior probability of success. Our high probability bounds give us a\nnuanced understanding of the privacy leakage of DP mechanisms in a variety of\npreviously understudied attack settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08158v1", "cate": "cs.CR", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08166", "title": "GPUHammer: Rowhammer Attacks on GPU Memories are Practical", "authors": ["Chris S. Lin", "Joyce Qu", "Gururaj Saileshwar"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      20 pages, including appendices. The paper will appear in SEC'25", "url": "http://arxiv.org/abs/2507.08166v1", "summary": "Rowhammer is a read disturbance vulnerability in modern DRAM that causes\nbit-flips, compromising security and reliability. While extensively studied on\nIntel and AMD CPUs with DDR and LPDDR memories, its impact on GPUs using GDDR\nmemories, critical for emerging machine learning applications, remains\nunexplored. Rowhammer attacks on GPUs face unique challenges: (1) proprietary\nmapping of physical memory to GDDR banks and rows, (2) high memory latency and\nfaster refresh rates that hinder effective hammering, and (3) proprietary\nmitigations in GDDR memories, difficult to reverse-engineer without FPGA-based\ntest platforms. We introduce GPUHammer, the first Rowhammer attack on NVIDIA\nGPUs with GDDR6 DRAM. GPUHammer proposes novel techniques to reverse-engineer\nGDDR DRAM row mappings, and employs GPU-specific memory access optimizations to\namplify hammering intensity and bypass mitigations. Thus, we demonstrate the\nfirst successful Rowhammer attack on a discrete GPU, injecting up to 8\nbit-flips across 4 DRAM banks on an NVIDIA A6000 with GDDR6 memory. We also\nshow how an attacker can use these to tamper with ML models, causing\nsignificant accuracy drops (up to 80%).", "comment": "20 pages, including appendices. The paper will appear in SEC'25", "pdf_url": "http://arxiv.org/pdf/2507.08166v1", "cate": "cs.CR", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08286", "title": "TruChain: A Multi-Layer Architecture for Trusted, Verifiable, and Immutable Open Banking Data", "authors": ["Aufa Nasywa Rahman", "Bimo Sunarfri Hantono", "Guntur Dharma Putra"], "categories": ["cs.CR", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      8 pages, 7 figures. Accepted to IEEE MetaCom 2025", "url": "http://arxiv.org/abs/2507.08286v1", "summary": "Open banking framework enables third party providers to access financial data\nacross banking institutions, leading to unprecedented innovations in the\nfinancial sector. However, some open banking standards remain susceptible to\nsevere technological risks, including unverified data sources, inconsistent\ndata integrity, and lack of immutability. In this paper, we propose a layered\narchitecture that provides assurance in data trustworthiness with three\ndistinct levels of trust, covering source validation, data-level\nauthentication, and tamper-proof storage. The first layer guarantees the source\nlegitimacy using decentralized identity and verifiable presentation, while the\nsecond layer verifies data authenticity and consistency using cryptographic\nsigning. Lastly, the third layer guarantees data immutability through the\nTangle, a directed acyclic graph distributed ledger. We implemented a\nproof-of-concept implementation of our solution to evaluate its performance,\nwhere the results demonstrate that the system scales linearly with a stable\nthroughput, exhibits a 100% validation rate, and utilizes under 35% of CPU and\n350 MiB memory. Compared to a real-world open banking implementation, our\nsolution offers significantly reduced latency and stronger data integrity\nassurance. Overall, our solution offers a practical and efficient system for\nsecure data sharing in financial ecosystems while maintaining regulatory\ncompliance.", "comment": "8 pages, 7 figures. Accepted to IEEE MetaCom 2025", "pdf_url": "http://arxiv.org/pdf/2507.08286v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08288", "title": "Invariant-based Robust Weights Watermark for Large Language Models", "authors": ["Qingxiao Guo", "Xinjie Zhu", "Yilong Ma", "Hui Jin", "Yunhao Wang", "Weifeng Zhang", "Xiaobing Guo"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08288v1", "summary": "Watermarking technology has gained significant attention due to the\nincreasing importance of intellectual property (IP) rights, particularly with\nthe growing deployment of large language models (LLMs) on billions\nresource-constrained edge devices. To counter the potential threats of IP theft\nby malicious users, this paper introduces a robust watermarking scheme without\nretraining or fine-tuning for transformer models. The scheme generates a unique\nkey for each user and derives a stable watermark value by solving linear\nconstraints constructed from model invariants. Moreover, this technology\nutilizes noise mechanism to hide watermark locations in multi-user scenarios\nagainst collusion attack. This paper evaluates the approach on three popular\nmodels (Llama3, Phi3, Gemma), and the experimental results confirm the strong\nrobustness across a range of attack methods (fine-tuning, pruning,\nquantization, permutation, scaling, reversible matrix and collusion attacks).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08288v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08312", "title": "Evaluating Post-Quantum Cryptographic Algorithms on Resource-Constrained Devices", "authors": ["Jesus Lopez", "Viviana Cadena", "Mohammad Saidur Rahman"], "categories": ["cs.CR", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 4 tables. This paper is accepted at the IEEE Quantum Week 2025 -- IEEE International Conference on Quantum Computing and Engineering (QCE) 2025", "url": "http://arxiv.org/abs/2507.08312v1", "summary": "The rapid advancement of quantum computing poses a critical threat to\nclassical cryptographic algorithms such as RSA and ECC, particularly in\nInternet of Things (IoT) devices, where secure communication is essential but\noften constrained by limited computational resources. This paper investigates\nthe feasibility of deploying post-quantum cryptography (PQC) algorithms on\nresource-constrained devices. In particular, we implement three PQC algorithms\n-- BIKE, CRYSTALS-Kyber, and HQC -- on a lightweight IoT platform built with\nRaspberry Pi devices. Leveraging the Open Quantum Safe (\\texttt{liboqs})\nlibrary in conjunction with \\texttt{mbedTLS}, we develop quantum-secure key\nexchange protocols, and evaluate their performance in terms of computational\noverhead, memory usage, and energy consumption for quantum secure\ncommunication. Experimental results demonstrate that the integration of PQC\nalgorithms on constrained hardware is practical, reinforcing the urgent need\nfor quantum-resilient cryptographic frameworks in next-generation IoT devices.\nThe implementation of this paper is available at\nhttps://iqsec-lab.github.io/PQC-IoT/.", "comment": "8 pages, 4 figures, 4 tables. This paper is accepted at the IEEE\n  Quantum Week 2025 -- IEEE International Conference on Quantum Computing and\n  Engineering (QCE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.08312v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08331", "title": "Qualcomm Trusted Application Emulation for Fuzzing Testing", "authors": ["Chun-I Fan", "Li-En Chang", "Cheng-Han Shie"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      This work is currently under review for presentation at the USENIX Security 2025 poster session", "url": "http://arxiv.org/abs/2507.08331v1", "summary": "In recent years, the increasing awareness of cybersecurity has led to a\nheightened focus on information security within hardware devices and products.\nIncorporating Trusted Execution Environments (TEEs) into product designs has\nbecome a standard practice for safeguarding sensitive user information.\nHowever, vulnerabilities within these components present significant risks, if\nexploited by attackers, these vulnerabilities could lead to the leakage of\nsensitive data, thereby compromising user privacy and security. This research\ncenters on trusted applications (TAs) within the Qualcomm TEE and introduces a\nnovel emulator specifically designed for these applications. Through reverse\nengineering techniques, we thoroughly analyze Qualcomm TAs and develop a\npartial emulation environment that accurately emulates their behavior.\nAdditionally, we integrate fuzzing testing techniques into the emulator to\nsystematically uncover potential vulnerabilities within Qualcomm TAs,\ndemonstrating its practical effectiveness in identifying real-world security\nflaws. This research makes a significant contribution by being the first to\nprovide both the implementation methods and source codes for a Qualcomm TAs\nemulator, offering a valuable reference for future research efforts. Unlike\nprevious approaches that relied on complex and resource-intensive full-system\nsimulations, our approach is lightweight and effective, making security testing\nof TA more convenient.", "comment": "This work is currently under review for presentation at the USENIX\n  Security 2025 poster session", "pdf_url": "http://arxiv.org/pdf/2507.08331v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08540", "title": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "authors": ["Ioannis Lamprou", "Alexander Shevtsov", "Ioannis Arapakis", "Sotiris Ioannidis"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08540v1", "summary": "The proliferation of software vulnerabilities presents a significant\nchallenge to cybersecurity, necessitating more effective detection\nmethodologies. We introduce White-Basilisk, a novel approach to vulnerability\ndetection that demonstrates superior performance while challenging prevailing\nassumptions in AI model scaling. Utilizing an innovative architecture that\nintegrates Mamba layers, linear self-attention, and a Mixture of Experts\nframework, White-Basilisk achieves state-of-the-art results in vulnerability\ndetection tasks with a parameter count of only 200M. The model's capacity to\nprocess sequences of unprecedented length enables comprehensive analysis of\nextensive codebases in a single pass, surpassing the context limitations of\ncurrent Large Language Models (LLMs). White-Basilisk exhibits robust\nperformance on imbalanced, real-world datasets, while maintaining computational\nefficiency that facilitates deployment across diverse organizational scales.\nThis research not only establishes new benchmarks in code security but also\nprovides empirical evidence that compact, efficiently designed models can\noutperform larger counterparts in specialized tasks, potentially redefining\noptimization strategies in AI development for domain-specific applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08540v1", "cate": "cs.CR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08163", "title": "Adaptive Diffusion Denoised Smoothing : Certified Robustness via Randomized Smoothing with Differentially Private Guided Denoising Diffusion", "authors": ["Frederick Shpilevskiy", "Saiyue Lyu", "Krishnamurthy Dj Dvijotham", "Mathias Lécuyer", "Pierre-André Noël"], "categories": ["cs.CV", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08163v1", "summary": "We propose Adaptive Diffusion Denoised Smoothing, a method for certifying the\npredictions of a vision model against adversarial examples, while adapting to\nthe input. Our key insight is to reinterpret a guided denoising diffusion model\nas a long sequence of adaptive Gaussian Differentially Private (GDP) mechanisms\nrefining a pure noise sample into an image. We show that these adaptive\nmechanisms can be composed through a GDP privacy filter to analyze the\nend-to-end robustness of the guided denoising process, yielding a provable\ncertification that extends the adaptive randomized smoothing analysis. We\ndemonstrate that our design, under a specific guiding strategy, can improve\nboth certified accuracy and standard accuracy on ImageNet for an $\\ell_2$\nthreat model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08163v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08190", "title": "Supporting Intel(r) SGX on Multi-Package Platforms", "authors": ["Simon Johnson", "Raghunandan Makaram", "Amy Santoni", "Vinnie Scarlata"], "categories": ["cs.DC", "cs.CR"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.08190v1", "summary": "Intel(r) Software Guard Extensions (SGX) was originally released on client\nplatforms and later extended to single socket server platforms. As developers\nhave become familiar with the capabilities of the technology, the applicability\nof this capability in the cloud has been tested. Various Cloud Service\nProviders (CSPs) are demonstrating the value of using SGX based Trusted\nExecution Environments (TEE) to create a new paradigm of Confidential Cloud\nComputing. This paper describes the additional platform enhancements we believe\nare necessary to deliver a user programmable Trusted Execution Environment that\nscales to cloud usages, performs and is secure on multi-package platforms.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.08190v1", "cate": "cs.DC", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08202", "title": "Quantum Properties Trojans (QuPTs) for Attacking Quantum Neural Networks", "authors": ["Sounak Bhowmik", "Travis S. Humble", "Himanshu Thapliyal"], "categories": ["quant-ph", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08202v1", "summary": "Quantum neural networks (QNN) hold immense potential for the future of\nquantum machine learning (QML). However, QNN security and robustness remain\nlargely unexplored. In this work, we proposed novel Trojan attacks based on the\nquantum computing properties in a QNN-based binary classifier. Our proposed\nQuantum Properties Trojans (QuPTs) are based on the unitary property of quantum\ngates to insert noise and Hadamard gates to enable superposition to develop\nTrojans and attack QNNs. We showed that the proposed QuPTs are significantly\nstealthier and heavily impact the quantum circuits' performance, specifically\nQNNs. The most impactful QuPT caused a deterioration of 23% accuracy of the\ncompromised QNN under the experimental setup. To the best of our knowledge,\nthis is the first work on the Trojan attack on a fully quantum neural network\nindependent of any hybrid classical-quantum architecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08202v1", "cate": "quant-ph", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08249", "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "authors": ["Bill Marino", "Ari Juels"], "categories": ["cs.AI", "cs.CR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08249v1", "summary": "There is growing interest in giving AI agents access to cryptocurrencies as\nwell as to the smart contracts that transact them. But doing so, this position\npaper argues, could lead to formidable new vectors of AI harm. To support this\nargument, we first examine the unique properties of cryptocurrencies and smart\ncontracts that could lead to these new vectors of harm. Next, we describe each\nof these new vectors of harm in detail. Finally, we conclude with a call for\nmore technical research aimed at preventing and mitigating these harms and,\nthereby making it safer to endow AI agents with cryptocurrencies and smart\ncontracts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08249v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08270", "title": "Agent Safety Alignment via Reinforcement Learning", "authors": ["Zeyang Sha", "Hanling Tian", "Zhuoer Xu", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "categories": ["cs.AI", "cs.CR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08270v1", "summary": "The emergence of autonomous Large Language Model (LLM) agents capable of tool\nusage has introduced new safety risks that go beyond traditional conversational\nmisuse. These agents, empowered to execute external functions, are vulnerable\nto both user-initiated threats (e.g., adversarial prompts) and tool-initiated\nthreats (e.g., malicious outputs from compromised tools). In this paper, we\npropose the first unified safety-alignment framework for tool-using agents,\nenabling models to handle both channels of threat via structured reasoning and\nsandboxed reinforcement learning. We introduce a tri-modal taxonomy, including\nbenign, malicious, and sensitive for both user prompts and tool responses, and\ndefine a policy-driven decision model. Our framework employs a custom-designed\nsandbox environment that simulates real-world tool execution and allows\nfine-grained reward shaping. Through extensive evaluations on public and\nself-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we\ndemonstrate that our safety-aligned agents significantly improve resistance to\nsecurity threats while preserving strong utility on benign tasks. Our results\nshow that safety and effectiveness can be jointly optimized, laying the\ngroundwork for trustworthy deployment of autonomous LLM agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08270v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08597", "title": "ADAPT: A Pseudo-labeling Approach to Combat Concept Drift in Malware Detection", "authors": ["Md Tanvirul Alam", "Aritran Piplai", "Nidhi Rastogi"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08597v1", "summary": "Machine learning models are commonly used for malware classification;\nhowever, they suffer from performance degradation over time due to concept\ndrift. Adapting these models to changing data distributions requires frequent\nupdates, which rely on costly ground truth annotations. While active learning\ncan reduce the annotation burden, leveraging unlabeled data through\nsemi-supervised learning remains a relatively underexplored approach in the\ncontext of malware detection. In this research, we introduce \\texttt{ADAPT}, a\nnovel pseudo-labeling semi-supervised algorithm for addressing concept drift.\nOur model-agnostic method can be applied to various machine learning models,\nincluding neural networks and tree-based algorithms. We conduct extensive\nexperiments on five diverse malware detection datasets spanning Android,\nWindows, and PDF domains. The results demonstrate that our method consistently\noutperforms baseline models and competitive benchmarks. This work paves the way\nfor more effective adaptation of machine learning models to concept drift in\nmalware detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08597v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08623", "title": "Entangled Threats: A Unified Kill Chain Model for Quantum Machine Learning Security", "authors": ["Pascal Debus", "Maximilian Wendlinger", "Kilian Tscharke", "Daniel Herr", "Cedric Brügmann", "Daniel Ohl de Mello", "Juris Ulmanis", "Alexander Erhard", "Arthur Schmidt", "Fabian Petsch"], "categories": ["quant-ph", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Accepted for publication at IEEE International Conference on Quantum Computing and Engineering (QCE) 2025", "url": "http://arxiv.org/abs/2507.08623v1", "summary": "Quantum Machine Learning (QML) systems inherit vulnerabilities from classical\nmachine learning while introducing new attack surfaces rooted in the physical\nand algorithmic layers of quantum computing. Despite a growing body of research\non individual attack vectors - ranging from adversarial poisoning and evasion\nto circuit-level backdoors, side-channel leakage, and model extraction - these\nthreats are often analyzed in isolation, with unrealistic assumptions about\nattacker capabilities and system environments. This fragmentation hampers the\ndevelopment of effective, holistic defense strategies. In this work, we argue\nthat QML security requires more structured modeling of the attack surface,\ncapturing not only individual techniques but also their relationships,\nprerequisites, and potential impact across the QML pipeline. We propose\nadapting kill chain models, widely used in classical IT and cybersecurity, to\nthe quantum machine learning context. Such models allow for structured\nreasoning about attacker objectives, capabilities, and possible multi-stage\nattack paths - spanning reconnaissance, initial access, manipulation,\npersistence, and exfiltration. Based on extensive literature analysis, we\npresent a detailed taxonomy of QML attack vectors mapped to corresponding\nstages in a quantum-aware kill chain framework that is inspired by the MITRE\nATLAS for classical machine learning. We highlight interdependencies between\nphysical-level threats (like side-channel leakage and crosstalk faults), data\nand algorithm manipulation (such as poisoning or circuit backdoors), and\nprivacy attacks (including model extraction and training data inference). This\nwork provides a foundation for more realistic threat modeling and proactive\nsecurity-in-depth design in the emerging field of quantum machine learning.", "comment": "Accepted for publication at IEEE International Conference on Quantum\n  Computing and Engineering (QCE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.08623v1", "cate": "quant-ph", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08616", "title": "AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs", "authors": ["Florian Grötschla", "Luis Müller", "Jan Tönshoff", "Mikhail Galkin", "Bryan Perozzi"], "categories": ["cs.MA", "cs.LG"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.08616v1", "summary": "Large-language models (LLMs) have demonstrated powerful problem-solving\ncapabilities, in particular when organized in multi-agent systems. However, the\nadvent of such systems also raises several questions on the ability of a\ncomplex network of agents to effectively self-organize and collaborate. While\nmeasuring performance on standard reasoning benchmarks indicates how well\nmulti-agent systems can solve reasoning tasks, it is unclear whether these\nsystems are able to leverage their topology effectively. Here, we propose\nAgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration\nfrom classical problems in distributed systems and graph theory, AgentsNet\nmeasures the ability of multi-agent systems to collaboratively form strategies\nfor problem-solving, self-organization, and effective communication given a\nnetwork topology. We evaluate a variety of baseline methods on AgentsNet\nincluding homogeneous networks of agents which first have to agree on basic\nprotocols for organization and communication. We find that some frontier LLMs\nare already demonstrating strong performance for small networks but begin to\nfall off once the size of the network scales. While existing multi-agent\nbenchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size\nand can scale with new generations of LLMs. As such, we also probe frontier\nmodels in a setup with up to 100 agents.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.08616v1", "cate": "cs.MA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2301.11050", "title": "Minerva: A File-Based Ransomware Detector", "authors": ["Dorjan Hitaj", "Giulio Pagnotta", "Fabio De Gaspari", "Lorenzo De Carli", "Luigi V. Mancini"], "categories": ["cs.CR", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted for publication at The 20th ACM ASIA Conference on Computer and Communications Security (ACM ASIACCS 2025), Meliá Hanoi", "url": "http://arxiv.org/abs/2301.11050v4", "summary": "Ransomware attacks have caused billions of dollars in damages in recent\nyears, and are expected to cause billions more in the future. Consequently,\nsignificant effort has been devoted to ransomware detection and mitigation.\nBehavioral-based ransomware detection approaches have garnered considerable\nattention recently. These behavioral detectors typically rely on process-based\nbehavioral profiles to identify malicious behaviors. However, with an\nincreasing body of literature highlighting the vulnerability of such approaches\nto evasion attacks, a comprehensive solution to the ransomware problem remains\nelusive. This paper presents Minerva, a novel, robust approach to ransomware\ndetection. Minerva is engineered to be robust by design against evasion\nattacks, with architectural and feature selection choices informed by their\nresilience to adversarial manipulation. We conduct a comprehensive analysis of\nMinerva across a diverse spectrum of ransomware types, encompassing unseen\nransomware as well as variants designed specifically to evade Minerva. Our\nevaluation showcases the ability of Minerva to accurately identify ransomware,\ngeneralize to unseen threats, and withstand evasion attacks. Furthermore, over\n99% of detected ransomware are identified within 0.52sec of activity, enabling\nthe adoption of data loss prevention techniques with near-zero overhead.", "comment": "Accepted for publication at The 20th ACM ASIA Conference on Computer\n  and Communications Security (ACM ASIACCS 2025), Meli\\'a Hanoi", "pdf_url": "http://arxiv.org/pdf/2301.11050v4", "cate": "cs.CR", "date": "2023-01-26", "updated": "2025-07-11"}
{"id": "2507.08100", "title": "Noise-Enabled Goal Attainment in Crowded Collectives", "authors": ["Lucy Liu", "Justin Werfel", "Federico Toschi", "L. Mahadevan"], "categories": ["cs.RO", "cond-mat.soft", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08100v1", "summary": "In crowded environments, individuals must navigate around other occupants to\nreach their destinations. Understanding and controlling traffic flows in these\nspaces is relevant to coordinating robot swarms and designing infrastructure\nfor dense populations. Here, we combine simulations, theory, and robotic\nexperiments to study how noisy motion can disrupt traffic jams and enable flow\nas agents travel to individual goals. Above a critical noise level, large jams\ndo not persist. From this observation, we analytically approximate the goal\nattainment rate as a function of the noise level, then solve for the optimal\nagent density and noise level that maximize the swarm's goal attainment rate.\nWe perform robotic experiments to corroborate our simulated and theoretical\nresults. Finally, we compare simple, local navigation approaches with a\nsophisticated but computationally costly central planner. A simple reactive\nscheme performs well up to moderate densities and is far more computationally\nefficient than a planner, suggesting lessons for real-world problems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08100v1", "cate": "cs.RO", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2406.01518", "title": "BISON: Blind Identification with Stateless scOped pseudoNyms", "authors": ["Jakob Heher", "Stefan More", "Lena Heimberger"], "categories": ["cs.CR", "D.4.6; C.2.2"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Paper artifacts (Source code, Firefox extension, etc) available at this https URL | Previous paper name: \"BISON: Blind Identification through Stateless scOpe-specific derivatioN\"", "url": "http://arxiv.org/abs/2406.01518v3", "summary": "Delegating authentication to identity providers like Google or Facebook,\nwhile convenient, compromises user privacy. These identity providers can record\nusers' every move; the global identifiers they provide also enable\ninternet-wide tracking.\n  We show that neither is a necessary evil by presenting the BISON pseudonym\nderivation protocol, inspired by Oblivious Pseudorandom Functions. It hides the\nservice provider's identity from the identity provider yet produces a trusted,\nscoped, immutable pseudonym. Colluding service providers cannot link BISON\npseudonyms; this prevents user tracking. BISON does not require a long-lived\nstate on the user device and does not add additional actors to the\nauthentication process.\n  BISON is practical. It is easy to understand, implement, and reason about,\nand is designed to integrate into existing authentication protocols. To\ndemonstrate this, we provide an OpenID Connect extension that allows OIDC's\nPPID pseudonyms to be derived using BISON while remaining fully backwards\ncompatible. Additionally, BISON uses only lightweight cryptography. Pseudonym\nderivation requires a total of four elliptic curve scalar-point multiplications\nand four hash function evaluations, taking $\\approx$3 ms in our proof of\nconcept implementation. Thus, BISON's privacy guarantees can be realized in\npractice. This makes BISON a crucial stepping stone towards the\nprivacy-preserving internet of tomorrow.", "comment": "Paper artifacts (Source code, Firefox extension, etc) available at\n  https://github.com/iaik-jheher/BISON | Previous paper name: \"BISON: Blind\n  Identification through Stateless scOpe-specific derivatioN\"", "pdf_url": "http://arxiv.org/pdf/2406.01518v3", "cate": "cs.CR", "date": "2024-06-03", "updated": "2025-07-11"}
{"id": "2507.08325", "title": "CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation", "authors": ["Yinzhu Quan", "Xinrui Li", "Ying Chen"], "categories": ["cs.CL", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08325v1", "summary": "In e-commerce private-domain channels such as instant messaging and e-mail,\nmerchants engage customers directly as part of their Customer Relationship\nManagement (CRM) programmes to drive retention and conversion. While a few top\nperformers excel at crafting outbound messages, most merchants struggle to\nwrite persuasive copy because they lack both expertise and scalable tools. We\nintroduce CRMAgent, a multi-agent system built on large language models (LLMs)\nthat generates high-quality message templates and actionable writing guidance\nthrough three complementary modes. First, group-based learning enables the\nagent to learn from a merchant's own top-performing messages within the same\naudience segment and rewrite low-performing ones. Second,\nretrieval-and-adaptation fetches templates that share the same audience segment\nand exhibit high similarity in voucher type and product category, learns their\nsuccessful patterns, and adapts them to the current campaign. Third, a\nrule-based fallback provides a lightweight zero-shot rewrite when no suitable\nreferences are available. Extensive experiments show that CRMAgent consistently\noutperforms merchants' original templates, delivering significant gains in both\naudience-match and marketing-effectiveness metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08325v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08112", "title": "Imitation Learning for Obstacle Avoidance Using End-to-End CNN-Based Sensor Fusion", "authors": ["Lamiaa H. Zain", "Hossam H. Ammar", "Raafat E. Shalaby"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08112v1", "summary": "Obstacle avoidance is crucial for mobile robots' navigation in both known and\nunknown environments. This research designs, trains, and tests two custom\nConvolutional Neural Networks (CNNs), using color and depth images from a depth\ncamera as inputs. Both networks adopt sensor fusion to produce an output: the\nmobile robot's angular velocity, which serves as the robot's steering command.\nA newly obtained visual dataset for navigation was collected in diverse\nenvironments with varying lighting conditions and dynamic obstacles. During\ndata collection, a communication link was established over Wi-Fi between a\nremote server and the robot, using Robot Operating System (ROS) topics.\nVelocity commands were transmitted from the server to the robot, enabling\nsynchronized recording of visual data and the corresponding steering commands.\nVarious evaluation metrics, such as Mean Squared Error, Variance Score, and\nFeed-Forward time, provided a clear comparison between the two networks and\nclarified which one to use for the application.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08112v1", "cate": "cs.RO", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2409.07580", "title": "New constructions of pseudorandom codes", "authors": ["Surendra Ghentiyala", "Venkatesan Guruswami"], "categories": ["cs.CR", "cs.CC"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      39 pages, 1 figure", "url": "http://arxiv.org/abs/2409.07580v2", "summary": "Introduced in [CG24], pseudorandom error-correcting codes (PRCs) are a new\ncryptographic primitive with applications in watermarking generative AI models.\nThese are codes where a collection of polynomially many codewords is\ncomputationally indistinguishable from random for an adversary that does not\nhave the secret key, but anyone with the secret key is able to efficiently\ndecode corrupted codewords. In this work, we examine the assumptions under\nwhich PRCs with robustness to a constant error rate exist.\n  1. We show that if both the planted hyperloop assumption introduced in\n[BKR23] and security of a version of Goldreich's PRG hold, then there exist\npublic-key PRCs for which no efficient adversary can distinguish a polynomial\nnumber of codewords from random with better than $o(1)$ advantage.\n  2. We revisit the construction of [CG24] and show that it can be based on a\nwider range of assumptions than presented in [CG24]. To do this, we introduce a\nweakened version of the planted XOR assumption which we call the weak planted\nXOR assumption and which may be of independent interest.\n  3. We initiate the study of PRCs which are secure against space-bounded\nadversaries. We show how to construct secret-key PRCs of length $O(n)$ which\nare $\\textit{unconditionally}$ indistinguishable from random by\n$\\text{poly}(n)$ time, $O(n^{1.5-\\varepsilon})$ space adversaries.", "comment": "39 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2409.07580v2", "cate": "cs.CR", "date": "2024-09-11", "updated": "2025-07-11"}
{"id": "2507.08350", "title": "Exploring Design of Multi-Agent LLM Dialogues for Research Ideation", "authors": ["Keisuke Ueda", "Wataru Hirota", "Takuto Asakura", "Takahiro Omi", "Kosuke Takahashi", "Kosuke Arima", "Tatsuya Ishigaki"], "categories": ["cs.CL", "cs.MA", "I.2.11; I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 1 figure, appendix. Accepted to SIGDIAL 2025", "url": "http://arxiv.org/abs/2507.08350v1", "summary": "Large language models (LLMs) are increasingly used to support creative tasks\nsuch as research idea generation. While recent work has shown that structured\ndialogues between LLMs can improve the novelty and feasibility of generated\nideas, the optimal design of such interactions remains unclear. In this study,\nwe conduct a comprehensive analysis of multi-agent LLM dialogues for scientific\nideation. We compare different configurations of agent roles, number of agents,\nand dialogue depth to understand how these factors influence the novelty and\nfeasibility of generated ideas. Our experimental setup includes settings where\none agent generates ideas and another critiques them, enabling iterative\nimprovement. Our results show that enlarging the agent cohort, deepening the\ninteraction depth, and broadening agent persona heterogeneity each enrich the\ndiversity of generated ideas. Moreover, specifically increasing critic-side\ndiversity within the ideation-critique-revision loop further boosts the\nfeasibility of the final proposals. Our findings offer practical guidelines for\nbuilding effective multi-agent LLM systems for scientific ideation. Our code is\navailable at https://github.com/g6000/MultiAgent-Research-Ideator.", "comment": "16 pages, 1 figure, appendix. Accepted to SIGDIAL 2025", "pdf_url": "http://arxiv.org/pdf/2507.08350v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08224", "title": "Making VLMs More Robot-Friendly: Self-Critical Distillation of Low-Level Procedural Reasoning", "authors": ["Chan Young Park", "Jillian Fisher", "Marius Memmel", "Dipika Khullar", "Andy Yun", "Abhishek Gupta", "Yejin Choi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Code Available: this https URL", "url": "http://arxiv.org/abs/2507.08224v1", "summary": "Large language models (LLMs) have shown promise in robotic procedural\nplanning, yet their human-centric reasoning often omits the low-level, grounded\ndetails needed for robotic execution. Vision-language models (VLMs) offer a\npath toward more perceptually grounded plans, but current methods either rely\non expensive, large-scale models or are constrained to narrow simulation\nsettings. We introduce SelfReVision, a lightweight and scalable\nself-improvement framework for vision-language procedural planning.\nSelfReVision enables small VLMs to iteratively critique, revise, and verify\ntheir own plans-without external supervision or teacher models-drawing\ninspiration from chain-of-thought prompting and self-instruct paradigms.\nThrough this self-distillation loop, models generate higher-quality,\nexecution-ready plans that can be used both at inference and for continued\nfine-tuning. Using models varying from 3B to 72B, our results show that\nSelfReVision not only boosts performance over weak base VLMs but also\noutperforms models 100X the size, yielding improved control in downstream\nembodied tasks.", "comment": "Code Available: https://github.com/chan0park/SelfReVision", "pdf_url": "http://arxiv.org/pdf/2507.08224v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08001", "title": "Human Creativity and AI", "authors": ["Shengyi Xie"], "categories": ["cs.AI", "cs.HC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08001v1", "summary": "With the advancement of science and technology, the philosophy of creativity\nhas undergone significant reinterpretation. This paper investigates\ncontemporary research in the fields of psychology, cognitive neuroscience, and\nthe philosophy of creativity, particularly in the context of the development of\nartificial intelligence (AI) techniques. It aims to address the central\nquestion: Can AI exhibit creativity? The paper reviews the historical\nperspectives on the philosophy of creativity and explores the influence of\npsychological advancements on the study of creativity. Furthermore, it analyzes\nvarious definitions of creativity and examines the responses of naturalism and\ncognitive neuroscience to the concept of creativity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08001v1", "cate": "cs.AI", "date": "2025-04-25", "updated": "2025-04-25"}
{"id": "2506.12430", "title": "Pushing the Limits of Safety: A Technical Report on the ATLAS Challenge 2025", "authors": ["Zonghao Ying", "Siyang Wu", "Run Hao", "Peng Ying", "Shixuan Sun", "Pengyu Chen", "Junze Chen", "Hao Du", "Kaiwen Shen", "Shangkun Wu", "Jiwei Wei", "Shiyuan He", "Yang Yang", "Xiaohai Xu", "Ke Ma", "Qianqian Xu", "Qingming Huang", "Shi Lin", "Xun Wang", "Changting Lin", "Meng Han", "Yilei Jiang", "Siqi Lai", "Yaozhi Zheng", "Yifei Song", "Xiangyu Yue", "Zonglei Jing", "Tianyuan Zhang", "Zhilei Zhu", "Aishan Liu", "Jiakai Wang", "Siyuan Liang", "Xianglong Kong", "Hainan Li", "Junjie Mu", "Haotong Qin", "Yue Yu", "Lei Chen", "Felix Juefei-Xu", "Qing Guo", "Xinyun Chen", "Yew Soon Ong", "Xianglong Liu", "Dawn Song", "Alan Yuille", "Philip Torr", "Dacheng Tao"], "categories": ["cs.CR", "cs.CV"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      AdvML@CVPR Challenge Report", "url": "http://arxiv.org/abs/2506.12430v2", "summary": "Multimodal Large Language Models (MLLMs) have enabled transformative\nadvancements across diverse applications but remain susceptible to safety\nthreats, especially jailbreak attacks that induce harmful outputs. To\nsystematically evaluate and improve their safety, we organized the Adversarial\nTesting & Large-model Alignment Safety Grand Challenge (ATLAS) 2025}. This\ntechnical report presents findings from the competition, which involved 86\nteams testing MLLM vulnerabilities via adversarial image-text attacks in two\nphases: white-box and black-box evaluations. The competition results highlight\nongoing challenges in securing MLLMs and provide valuable guidance for\ndeveloping stronger defense mechanisms. The challenge establishes new\nbenchmarks for MLLM safety evaluation and lays groundwork for advancing safer\nmultimodal AI systems. The code and data for this challenge are openly\navailable at https://github.com/NY1024/ATLAS_Challenge_2025.", "comment": "AdvML@CVPR Challenge Report", "pdf_url": "http://arxiv.org/pdf/2506.12430v2", "cate": "cs.CR", "date": "2025-06-14", "updated": "2025-07-11"}
{"id": "2507.08440", "title": "Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences", "authors": ["Selina Heller", "Mohamed Ibrahim", "David Antony Selby", "Sebastian Vollmer"], "categories": ["cs.CL", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08440v1", "summary": "Decision conferences are structured, collaborative meetings that bring\ntogether experts from various fields to address complex issues and reach a\nconsensus on recommendations for future actions or policies. These conferences\noften rely on facilitated discussions to ensure productive dialogue and\ncollective agreement. Recently, Large Language Models (LLMs) have shown\nsignificant promise in simulating real-world scenarios, particularly through\ncollaborative multi-agent systems that mimic group interactions. In this work,\nwe present a novel LLM-based multi-agent system designed to simulate decision\nconferences, specifically focusing on detecting agreement among the participant\nagents. To achieve this, we evaluate six distinct LLMs on two tasks: stance\ndetection, which identifies the position an agent takes on a given issue, and\nstance polarity detection, which identifies the sentiment as positive,\nnegative, or neutral. These models are further assessed within the multi-agent\nsystem to determine their effectiveness in complex simulations. Our results\nindicate that LLMs can reliably detect agreement even in dynamic and nuanced\ndebates. Incorporating an agreement-detection agent within the system can also\nimprove the efficiency of group debates and enhance the overall quality and\ncoherence of deliberations, making them comparable to real-world decision\nconferences regarding outcome and decision-making. These findings demonstrate\nthe potential for LLM-based multi-agent systems to simulate group\ndecision-making processes. They also highlight that such systems could be\ninstrumental in supporting decision-making with expert elicitation workshops\nacross various domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08440v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08262", "title": "CL3R: 3D Reconstruction and Contrastive Learning for Enhanced Robotic Manipulation Representations", "authors": ["Wenbo Cui", "Chengyang Zhao", "Yuhui Chen", "Haoran Li", "Zhizheng Zhang", "Dongbin Zhao", "He Wang"], "categories": ["cs.RO", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08262v1", "summary": "Building a robust perception module is crucial for visuomotor policy\nlearning. While recent methods incorporate pre-trained 2D foundation models\ninto robotic perception modules to leverage their strong semantic\nunderstanding, they struggle to capture 3D spatial information and generalize\nacross diverse camera viewpoints. These limitations hinder the policy's\neffectiveness, especially in fine-grained robotic manipulation scenarios. To\naddress these challenges, we propose CL3R, a novel 3D pre-training framework\ndesigned to enhance robotic manipulation policies. Our method integrates both\nspatial awareness and semantic understanding by employing a point cloud Masked\nAutoencoder to learn rich 3D representations while leveraging pre-trained 2D\nfoundation models through contrastive learning for efficient semantic knowledge\ntransfer. Additionally, we propose a 3D visual representation pre-training\nframework for robotic tasks. By unifying coordinate systems across datasets and\nintroducing random fusion of multi-view point clouds, we mitigate camera view\nambiguity and improve generalization, enabling robust perception from novel\nviewpoints at test time. Extensive experiments in both simulation and the real\nworld demonstrate the superiority of our method, highlighting its effectiveness\nin visuomotor policy learning for robotic manipulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08262v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08046", "title": "TableReasoner: Advancing Table Reasoning Framework with Large Language Models", "authors": ["Sishi Xiong", "Dakai Wang", "Yu Zhao", "Jie Zhang", "Changzai Pan", "Haowei He", "Xiangyu Li", "Wenhan Chang", "Zhongjiang He", "Shuangyong Song", "Yongxiang Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08046v1", "summary": "The paper presents our system developed for table question answering (TQA).\nTQA tasks face challenges due to the characteristics of real-world tabular\ndata, such as large size, incomplete column semantics, and entity ambiguity. To\naddress these issues, we propose a large language model (LLM)-powered and\nprogramming-based table reasoning framework, named TableReasoner. It models a\ntable using the schema that combines structural and semantic representations,\nenabling holistic understanding and efficient processing of large tables. We\ndesign a multi-step schema linking plan to derive a focused table schema that\nretains only query-relevant information, eliminating ambiguity and alleviating\nhallucinations. This focused table schema provides precise and sufficient table\ndetails for query refinement and programming. Furthermore, we integrate the\nreasoning workflow into an iterative thinking architecture, allowing\nincremental cycles of thinking, reasoning and reflection. Our system achieves\nfirst place in both subtasks of SemEval-2025 Task 8.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08046v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2506.14697", "title": "AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions", "authors": ["Aishan Liu", "Zonghao Ying", "Le Wang", "Junjie Mu", "Jinyang Guo", "Jiakai Wang", "Yuqing Ma", "Siyuan Liang", "Mingchuan Zhang", "Xianglong Liu", "Dacheng Tao"], "categories": ["cs.CR", "cs.RO"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      MAS@ICML 2025 camera ready", "url": "http://arxiv.org/abs/2506.14697v2", "summary": "The rapid advancement of vision-language models (VLMs) and their integration\ninto embodied agents have unlocked powerful capabilities for decision-making.\nHowever, as these systems are increasingly deployed in real-world environments,\nthey face mounting safety concerns, particularly when responding to hazardous\ninstructions. In this work, we propose AGENTSAFE, the first comprehensive\nbenchmark for evaluating the safety of embodied VLM agents under hazardous\ninstructions. AGENTSAFE simulates realistic agent-environment interactions\nwithin a simulation sandbox and incorporates a novel adapter module that\nbridges the gap between high-level VLM outputs and low-level embodied controls.\nSpecifically, it maps recognized visual entities to manipulable objects and\ntranslates abstract planning into executable atomic actions in the environment.\nBuilding on this, we construct a risk-aware instruction dataset inspired by\nAsimovs Three Laws of Robotics, including base risky instructions and mutated\njailbroken instructions. The benchmark includes 45 adversarial scenarios, 1,350\nhazardous tasks, and 8,100 hazardous instructions, enabling systematic testing\nunder adversarial conditions ranging from perception, planning, and action\nexecution stages.", "comment": "MAS@ICML 2025 camera ready", "pdf_url": "http://arxiv.org/pdf/2506.14697v2", "cate": "cs.CR", "date": "2025-06-17", "updated": "2025-07-11"}
{"id": "2507.08584", "title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions", "authors": ["Dimitrios Emmanoulopoulos", "Ollie Olby", "Justin Lyon", "Namid R. Stillman"], "categories": ["q-fin.ST", "cs.AI", "cs.CE", "cs.MA", "q-fin.CP", "68T42, 65C05, 68T01, 60H10", "I.2.11; I.2.0; I.2.1; I.2.3; I.2.4; I.2.8"], "primary_category": "Subjects:       Statistical Finance (q-fin.ST)", "pdf_link": null, "comments": "Comments:      31 pages, 7 figures, 3 tables", "url": "http://arxiv.org/abs/2507.08584v1", "summary": "Large language models (LLMs) are increasingly deployed in agentic frameworks,\nin which prompts trigger complex tool-based analysis in pursuit of a goal.\nWhile these frameworks have shown promise across multiple domains including in\nfinance, they typically lack a principled model-building step, relying instead\non sentiment- or trend-based analysis. We address this gap by developing an\nagentic system that uses LLMs to iteratively discover stochastic differential\nequations for financial time series. These models generate risk metrics which\ninform daily trading decisions. We evaluate our system in both traditional\nbacktests and using a market simulator, which introduces synthetic but causally\nplausible price paths and news events. We find that model-informed trading\nstrategies outperform standard LLM-based agents, improving Sharpe ratios across\nmultiple equities. Our results show that combining LLMs with agentic model\ndiscovery enhances market risk estimation and enables more profitable trading\ndecisions.", "comment": "31 pages, 7 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.08584v1", "cate": "q-fin.ST", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08303", "title": "Learning Robust Motion Skills via Critical Adversarial Attacks for Humanoid Robots", "authors": ["Yang Zhang", "Zhanxiang Cao", "Buqing Nie", "Haoyang Li", "Yue Gao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures", "url": "http://arxiv.org/abs/2507.08303v1", "summary": "Humanoid robots show significant potential in daily tasks. However,\nreinforcement learning-based motion policies often suffer from robustness\ndegradation due to the sim-to-real dynamics gap, thereby affecting the agility\nof real robots. In this work, we propose a novel robust adversarial training\nparadigm designed to enhance the robustness of humanoid motion policies in real\nworlds. The paradigm introduces a learnable adversarial attack network that\nprecisely identifies vulnerabilities in motion policies and applies targeted\nperturbations, forcing the motion policy to enhance its robustness against\nperturbations through dynamic adversarial training. We conduct experiments on\nthe Unitree G1 humanoid robot for both perceptive locomotion and whole-body\ncontrol tasks. The results demonstrate that our proposed method significantly\nenhances the robot's motion robustness in real world environments, enabling\nsuccessful traversal of challenging terrains and highly agile whole-body\ntrajectory tracking.", "comment": "10 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.08303v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08207", "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "authors": ["Zhengye Han", "Quanyan Zhu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08207v1", "summary": "As large language models (LLMs) are increasingly deployed in critical\napplications, the challenge of jailbreaking, where adversaries manipulate the\nmodels to bypass safety mechanisms, has become a significant concern. This\npaper presents a dynamic Stackelberg game framework to model the interactions\nbetween attackers and defenders in the context of LLM jailbreaking. The\nframework treats the prompt-response dynamics as a sequential extensive-form\ngame, where the defender, as the leader, commits to a strategy while\nanticipating the attacker's optimal responses. We propose a novel agentic AI\nsolution, the \"Purple Agent,\" which integrates adversarial exploration and\ndefensive strategies using Rapidly-exploring Random Trees (RRT). The Purple\nAgent actively simulates potential attack trajectories and intervenes\nproactively to prevent harmful outputs. This approach offers a principled\nmethod for analyzing adversarial dynamics and provides a foundation for\nmitigating the risk of jailbreaking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08207v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.04501", "title": "LINE: Public-key encryption", "authors": ["Gennady Khalimov", "Yevgen Kotukh"], "categories": ["cs.CR", "cs.IT", "math.IT"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04501v2", "summary": "We propose a public key encryption cryptosystem based on solutions of linear\nequation systems with predefinition of input parameters through shared secret\ncomputation for factorizable substitutions. The existence of multiple\nequivalent solutions for an underdetermined system of linear equations\ndetermines the impossibility of its resolution by a cryptanalyst in polynomial\ntime. The completion of input parameters of the equation system is implemented\nthrough secret homomorphic matrix transformation for substitutions factorized\nover the basis of a vector space of dimension m over the field F2. Encryption\nis implemented through computation of substitutions that are one-way functions\non an elementary abelian 2-group of order 2\"m. Decryption is implemented\nthrough completion of input parameters of the equation system. Homomorphic\ntransformations are constructed based on matrix computations. Matrix\ncomputations enable the implementation of high security and low computational\noverhead for homomorphic transformations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04501v2", "cate": "cs.CR", "date": "2025-07-06", "updated": "2025-07-10"}
{"id": "2507.08653", "title": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees", "authors": ["Berire Gunes Reyhan", "Sinem Coleri"], "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.MA"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 Pages, to be published in IEEE Transactions on Communications", "url": "http://arxiv.org/abs/2507.08653v1", "summary": "In Wireless Networked Control Systems (WNCSs), control and communication\nsystems must be co-designed due to their strong interdependence. This paper\npresents a novel optimization theory-based safe deep reinforcement learning\n(DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction\nwhile optimizing performance, for the first time in the literature. The\napproach minimizes power consumption under key constraints, including Peak Age\nof Information (PAoI) violation probability, transmit power, and schedulability\nin the finite blocklength regime. PAoI violation probability is uniquely\nderived by combining stochastic maximum allowable transfer interval (MATI) and\nmaximum allowable packet delay (MAD) constraints in a multi-sensor network. The\nframework consists of two stages: optimization theory and safe DRL. The first\nstage derives optimality conditions to establish mathematical relationships\namong variables, simplifying and decomposing the problem. The second stage\nemploys a safe DRL model where a teacher-student framework guides the DRL agent\n(student). The control mechanism (teacher) evaluates compliance with system\nconstraints and suggests the nearest feasible action when needed. Extensive\nsimulations show that the proposed framework outperforms rule-based and other\noptimization theory based DRL benchmarks, achieving faster convergence, higher\nrewards, and greater stability.", "comment": "15 Pages, to be published in IEEE Transactions on Communications", "pdf_url": "http://arxiv.org/pdf/2507.08653v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08349", "title": "Joint Optimization-based Targetless Extrinsic Calibration for Multiple LiDARs and GNSS-Aided INS of Ground Vehicles", "authors": ["Junhui Wang", "Yan Qiao", "Chao Gao", "Naiqi Wu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08349v1", "summary": "Accurate extrinsic calibration between multiple LiDAR sensors and a\nGNSS-aided inertial navigation system (GINS) is essential for achieving\nreliable sensor fusion in intelligent mining environments. Such calibration\nenables vehicle-road collaboration by aligning perception data from\nvehicle-mounted sensors to a unified global reference frame. However, existing\nmethods often depend on artificial targets, overlapping fields of view, or\nprecise trajectory estimation, which are assumptions that may not hold in\npractice. Moreover, the planar motion of mining vehicles leads to observability\nissues that degrade calibration performance. This paper presents a targetless\nextrinsic calibration method that aligns multiple onboard LiDAR sensors to the\nGINS coordinate system without requiring overlapping sensor views or external\ntargets. The proposed approach introduces an observation model based on the\nknown installation height of the GINS unit to constrain unobservable\ncalibration parameters under planar motion. A joint optimization framework is\ndeveloped to refine both the extrinsic parameters and GINS trajectory by\nintegrating multiple constraints derived from geometric correspondences and\nmotion consistency. The proposed method is applicable to heterogeneous LiDAR\nconfigurations, including both mechanical and solid-state sensors. Extensive\nexperiments on simulated and real-world datasets demonstrate the accuracy,\nrobustness, and practical applicability of the approach under diverse sensor\nsetups.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08349v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08208", "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "authors": ["Quanyan Zhu"], "categories": ["cs.AI", "cs.GT"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08208v1", "summary": "We introduce the LLM-Nash framework, a game-theoretic model where agents\nselect reasoning prompts to guide decision-making via Large Language Models\n(LLMs). Unlike classical games that assume utility-maximizing agents with full\nrationality, this framework captures bounded rationality by modeling the\nreasoning process explicitly. Equilibrium is defined over the prompt space,\nwith actions emerging as the behavioral output of LLM inference. This approach\nenables the study of cognitive constraints, mindset expressiveness, and\nepistemic learning. Through illustrative examples, we show how reasoning\nequilibria can diverge from classical Nash outcomes, offering a new foundation\nfor strategic interaction in LLM-enabled systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08208v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.06850", "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover", "authors": ["Matteo Lupinacci", "Francesco Aurelio Pironti", "Francesco Blefari", "Francesco Romeo", "Luigi Arena", "Angelo Furfaro"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06850v3", "summary": "The rapid adoption of Large Language Model (LLM) agents and multi-agent\nsystems enables unprecedented capabilities in natural language processing and\ngeneration. However, these systems have introduced unprecedented security\nvulnerabilities that extend beyond traditional prompt injection attacks. This\npaper presents the first comprehensive evaluation of LLM agents as attack\nvectors capable of achieving complete computer takeover through the\nexploitation of trust boundaries within agentic AI systems where autonomous\nentities interact and influence each other. We demonstrate that adversaries can\nleverage three distinct attack surfaces - direct prompt injection, RAG backdoor\nattacks, and inter-agent trust exploitation - to coerce popular LLMs (including\nGPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing\nmalware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals\nan alarming vulnerability hierarchy: while 41.2% of models succumb to direct\nprompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical\n82.4% can be compromised through inter-agent trust exploitation. Notably, we\ndiscovered that LLMs which successfully resist direct malicious commands will\nexecute identical payloads when requested by peer agents, revealing a\nfundamental flaw in current multi-agent security models. Our findings\ndemonstrate that only 5.9% of tested models (1/17) proved resistant to all\nattack vectors, with the majority exhibiting context-dependent security\nbehaviors that create exploitable blind spots. Our findings also highlight the\nneed to increase awareness and research on the security risks of LLMs, showing\na paradigm shift in cybersecurity threats, where AI tools themselves become\nsophisticated attack vectors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06850v3", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2505.18397", "title": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "authors": ["Fangqiao Tian", "An Luo", "Jin Du", "Xun Xian", "Robert Specht", "Ganghua Wang", "Xuan Bi", "Jiawei Zhou", "Ashish Kundu", "Jayanth Srinivasa", "Charles Fleming", "Rui Zhang", "Zirui Liu", "Mingyi Hong", "Jie Ding"], "categories": ["cs.MA", "cs.AI", "cs.ET", "cs.LG", "68T42 (Agent technology and artificial intelligence), 68T01 (General\n  topics in artificial intelligence), 68M14 (Distributed systems)", "I.2.11; I.2.4; I.2.6"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.18397v2", "summary": "A multi-agent AI system (MAS) is composed of multiple autonomous agents that\ninteract, exchange information, and make decisions based on internal generative\nmodels. Recent advances in large language models and tool-using agents have\nmade MAS increasingly practical in areas like scientific discovery and\ncollaborative automation. However, key questions remain: When are MAS more\neffective than single-agent systems? What new safety risks arise from agent\ninteractions? And how should we evaluate their reliability and structure? This\npaper outlines a formal framework for analyzing MAS, focusing on two core\naspects: effectiveness and safety. We explore whether MAS truly improve\nrobustness, adaptability, and performance, or merely repackage known techniques\nlike ensemble learning. We also study how inter-agent dynamics may amplify or\nsuppress system vulnerabilities. While MAS are relatively new to the signal\nprocessing community, we envision them as a powerful abstraction that extends\nclassical tools like distributed estimation and sensor fusion to higher-level,\npolicy-driven inference. Through experiments on data science automation, we\nhighlight the potential of MAS to reshape how signal processing systems are\ndesigned and trusted.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.18397v2", "cate": "cs.MA", "date": "2025-05-23", "updated": "2025-07-11"}
{"id": "2507.08364", "title": "Towards Robust Sensor-Fusion Ground SLAM: A Comprehensive Benchmark and A Resilient Framework", "authors": ["Deteng Zhang", "Junjie Zhang", "Yan Sun", "Tao Li", "Hao Yin", "Hongzhao Xie", "Jie Yin"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has already been accepted to IROS2025. 8 pages", "url": "http://arxiv.org/abs/2507.08364v1", "summary": "Considerable advancements have been achieved in SLAM methods tailored for\nstructured environments, yet their robustness under challenging corner cases\nremains a critical limitation. Although multi-sensor fusion approaches\nintegrating diverse sensors have shown promising performance improvements, the\nresearch community faces two key barriers: On one hand, the lack of\nstandardized and configurable benchmarks that systematically evaluate SLAM\nalgorithms under diverse degradation scenarios hinders comprehensive\nperformance assessment. While on the other hand, existing SLAM frameworks\nprimarily focus on fusing a limited set of sensor types, without effectively\naddressing adaptive sensor selection strategies for varying environmental\nconditions.\n  To bridge these gaps, we make three key contributions: First, we introduce\nM3DGR dataset: a sensor-rich benchmark with systematically induced degradation\npatterns including visual challenge, LiDAR degeneracy, wheel slippage and GNSS\ndenial. Second, we conduct a comprehensive evaluation of forty SLAM systems on\nM3DGR, providing critical insights into their robustness and limitations under\nchallenging real-world conditions. Third, we develop a resilient modular\nmulti-sensor fusion framework named Ground-Fusion++, which demonstrates robust\nperformance by coupling GNSS, RGB-D, LiDAR, IMU (Inertial Measurement Unit) and\nwheel odometry. Codes and datasets are publicly available.", "comment": "This paper has already been accepted to IROS2025. 8 pages", "pdf_url": "http://arxiv.org/pdf/2507.08364v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08210", "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "authors": ["Fryderyk Mantiuk", "Hanqi Zhou", "Charley M. Wu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08210v1", "summary": "What drives an agent to explore the world while also maintaining control over\nthe environment? From a child at play to scientists in the lab, intelligent\nagents must balance curiosity (the drive to seek knowledge) with competence\n(the drive to master and control the environment). Bridging cognitive theories\nof intrinsic motivation with reinforcement learning, we ask how evolving\ninternal representations mediate the trade-off between curiosity (novelty or\ninformation gain) and competence (empowerment). We compare two model-based\nagents using handcrafted state abstractions (Tabular) or learning an internal\nworld model (Dreamer). The Tabular agent shows curiosity and competence guide\nexploration in distinct patterns, while prioritizing both improves exploration.\nThe Dreamer agent reveals a two-way interaction between exploration and\nrepresentation learning, mirroring the developmental co-evolution of curiosity\nand competence. Our findings formalize adaptive exploration as a balance\nbetween pursuing the unknown and the controllable, offering insights for\ncognitive theories and efficient reinforcement learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08210v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.07031", "title": "ZKTorch: Compiling ML Inference to Zero-Knowledge Proofs via Parallel Proof Accumulation", "authors": ["Bing-Jyue Chen", "Lilia Tang", "Daniel Kang"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      16 pages, 2 figures", "url": "http://arxiv.org/abs/2507.07031v2", "summary": "As AI models become ubiquitous in our daily lives, there has been an\nincreasing demand for transparency in ML services. However, the model owner\ndoes not want to reveal the weights, as they are considered trade secrets. To\nsolve this problem, researchers have turned to zero-knowledge proofs of ML\nmodel inference. These proofs convince the user that the ML model output is\ncorrect, without revealing the weights of the model to the user. Past work on\nthese provers can be placed into two categories. The first method compiles the\nML model into a low-level circuit, and proves the circuit using a ZK-SNARK. The\nsecond method uses custom cryptographic protocols designed only for a specific\nclass of models. Unfortunately, the first method is highly inefficient, making\nit impractical for the large models used today, and the second method does not\ngeneralize well, making it difficult to update in the rapidly changing field of\nmachine learning. To solve this, we propose ZKTorch, an open source end-to-end\nproving system that compiles ML models into base cryptographic operations\ncalled basic blocks, each proved using specialized protocols. ZKTorch is built\non top of a novel parallel extension to the Mira accumulation scheme, enabling\nsuccinct proofs with minimal accumulation overhead. These contributions allow\nZKTorch to achieve at least a $3\\times$ reduction in the proof size compared to\nspecialized protocols and up to a $6\\times$ speedup in proving time over a\ngeneral-purpose ZKML framework.", "comment": "16 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.07031v2", "cate": "cs.CR", "date": "2025-07-09", "updated": "2025-07-10"}
{"id": "2503.16521", "title": "Conversational Self-Play for Discovering and Understanding Psychotherapy Approaches", "authors": ["Onno P Kampman", "Michael Xing", "Charmaine Lim", "Ahmad Ishqi Jabir", "Ryan Louie", "Jimmy Lee", "Robert JT Morris"], "categories": ["cs.HC", "cs.MA"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Improve writing, add multiple techniques extraction", "url": "http://arxiv.org/abs/2503.16521v2", "summary": "This paper explores conversational self-play with LLMs as a scalable approach\nfor analyzing and exploring psychotherapy approaches, evaluating how well\nAI-generated therapeutic dialogues align with established modalities.", "comment": "Improve writing, add multiple techniques extraction", "pdf_url": "http://arxiv.org/pdf/2503.16521v2", "cate": "cs.HC", "date": "2025-03-17", "updated": "2025-07-11"}
{"id": "2507.08366", "title": "Intelligent Control of Spacecraft Reaction Wheel Attitude Using Deep Reinforcement Learning", "authors": ["Ghaith El-Dalahmeh", "Mohammad Reza Jabbarpour", "Bao Quoc Vo", "Ryszard Kowalczyk"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08366v1", "summary": "Reliable satellite attitude control is essential for the success of space\nmissions, particularly as satellites increasingly operate autonomously in\ndynamic and uncertain environments. Reaction wheels (RWs) play a pivotal role\nin attitude control, and maintaining control resilience during RW faults is\ncritical to preserving mission objectives and system stability. However,\ntraditional Proportional Derivative (PD) controllers and existing deep\nreinforcement learning (DRL) algorithms such as TD3, PPO, and A2C often fall\nshort in providing the real time adaptability and fault tolerance required for\nautonomous satellite operations. This study introduces a DRL-based control\nstrategy designed to improve satellite resilience and adaptability under fault\nconditions. Specifically, the proposed method integrates Twin Delayed Deep\nDeterministic Policy Gradient (TD3) with Hindsight Experience Replay (HER) and\nDimension Wise Clipping (DWC) referred to as TD3-HD to enhance learning in\nsparse reward environments and maintain satellite stability during RW failures.\nThe proposed approach is benchmarked against PD control and leading DRL\nalgorithms. Experimental results show that TD3-HD achieves significantly lower\nattitude error, improved angular velocity regulation, and enhanced stability\nunder fault conditions. These findings underscore the proposed method potential\nas a powerful, fault tolerant, onboard AI solution for autonomous satellite\nattitude control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08366v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08216", "title": "Grounding Methods for Neural-Symbolic AI", "authors": ["Rodrigo Castellano Ontiveros", "Francesco Giannini", "Marco Gori", "Giuseppe Marra", "Michelangelo Diligenti"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08216v1", "summary": "A large class of Neural-Symbolic (NeSy) methods employs a machine learner to\nprocess the input entities, while relying on a reasoner based on First-Order\nLogic to represent and process more complex relationships among the entities. A\nfundamental role for these methods is played by the process of logic grounding,\nwhich determines the relevant substitutions for the logic rules using a\n(sub)set of entities. Some NeSy methods use an exhaustive derivation of all\npossible substitutions, preserving the full expressive power of the logic\nknowledge. This leads to a combinatorial explosion in the number of ground\nformulas to consider and, therefore, strongly limits their scalability. Other\nmethods rely on heuristic-based selective derivations, which are generally more\ncomputationally efficient, but lack a justification and provide no guarantees\nof preserving the information provided to and returned by the reasoner. Taking\ninspiration from multi-hop symbolic reasoning, this paper proposes a\nparametrized family of grounding methods generalizing classic Backward\nChaining. Different selections within this family allow us to obtain commonly\nemployed grounding methods as special cases, and to control the trade-off\nbetween expressiveness and scalability of the reasoner. The experimental\nresults show that the selection of the grounding criterion is often as\nimportant as the NeSy method itself.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08216v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08050", "title": "An Enhanced Privacy-preserving Federated Few-shot Learning Framework for Respiratory Disease Diagnosis", "authors": ["Ming Wang", "Zhaoyang Duan", "Dong Xue", "Fangzhou Liu", "Zhongheng Zhang"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08050v1", "summary": "The labor-intensive nature of medical data annotation presents a significant\nchallenge for respiratory disease diagnosis, resulting in a scarcity of\nhigh-quality labeled datasets in resource-constrained settings. Moreover,\npatient privacy concerns complicate the direct sharing of local medical data\nacross institutions, and existing centralized data-driven approaches, which\nrely on amounts of available data, often compromise data privacy. This study\nproposes a federated few-shot learning framework with privacy-preserving\nmechanisms to address the issues of limited labeled data and privacy protection\nin diagnosing respiratory diseases. In particular, a meta-stochastic gradient\ndescent algorithm is proposed to mitigate the overfitting problem that arises\nfrom insufficient data when employing traditional gradient descent methods for\nneural network training. Furthermore, to ensure data privacy against gradient\nleakage, differential privacy noise from a standard Gaussian distribution is\nintegrated into the gradients during the training of private models with local\ndata, thereby preventing the reconstruction of medical images. Given the\nimpracticality of centralizing respiratory disease data dispersed across\nvarious medical institutions, a weighted average algorithm is employed to\naggregate local diagnostic models from different clients, enhancing the\nadaptability of a model across diverse scenarios. Experimental results show\nthat the proposed method yields compelling results with the implementation of\ndifferential privacy, while effectively diagnosing respiratory diseases using\ndata from different structures, categories, and distributions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08050v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.07901", "title": "The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web", "authors": ["Sree Bhargavi Balija", "Rekha Singal", "Abhishek Singh", "Ramesh Raskar", "Erfan Darzi", "Raghu Bala", "Thomas Hardjono", "Ken Huang"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07901v2", "summary": "The fragmentation of AI agent ecosystems has created urgent demands for\ninteroperability, trust, and economic coordination that current protocols --\nincluding MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al.,\n2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present\nthe Nanda Unified Architecture, a decentralized framework built around three\ncore innovations: fast DID-based agent discovery through distributed\nregistries, semantic agent cards with verifiable credentials and composability\nprofiles, and a dynamic trust layer that integrates behavioral attestations\nwith policy compliance. The system introduces X42/H42 micropayments for\neconomic coordination and MAESTRO, a security framework incorporating\nSynergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure\ncontainerization. Real-world deployments demonstrate 99.9 percent compliance in\nhealthcare applications and substantial monthly transaction volumes with strong\nprivacy guarantees. By unifying MIT's trust research with production\ndeployments from Cisco and Synergetics, we show how cryptographic proofs and\npolicy-as-code transform agents into trust-anchored participants in a\ndecentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a\nglobally interoperable Internet of Agents where trust becomes the native\ncurrency of collaboration across both enterprise and Web3 ecosystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07901v2", "cate": "cs.CR", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2506.12003", "title": "Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?", "authors": ["Ramesh Raskar", "Pradyumna Chari", "Jared James Grogan", "Mahesh Lambe", "Robert Lincourt", "Raghu Bala", "Aditi Joshi", "Abhishek Singh", "Ayush Chopra", "Rajesh Ranjan", "Shailja Gupta", "Dimitris Stripelis", "Maria Gorskikh", "Sichao Wang"], "categories": ["cs.NI", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.12003v2", "summary": "The emerging Internet of AI Agents challenges existing web infrastructure\ndesigned for human-scale, reactive interactions. Unlike traditional web\nresources, autonomous AI agents initiate actions, maintain persistent state,\nspawn sub-agents, and negotiate directly with peers: demanding\nmillisecond-level discovery, instant credential revocation, and cryptographic\nbehavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes\nwhether to upgrade existing infrastructure or implement purpose-built index\narchitectures for autonomous agents. We identify critical failure points: DNS\npropagation (24-48 hours vs. required milliseconds), certificate revocation\nunable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate\nfor agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2)\nSwitch options, (3) Hybrid index/registries. Drawing parallels to\ndialup-to-broadband transitions, we find that agent requirements constitute\nqualitative, and not incremental, changes. While upgrades offer compatibility\nand faster deployment, clean-slate solutions provide better performance but\nrequire longer for adoption. Our analysis suggests hybrid approaches will\nemerge, with centralized indexes for critical agents and federated meshes for\nspecialized use cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.12003v2", "cate": "cs.NI", "date": "2025-06-13", "updated": "2025-07-11"}
{"id": "2507.08420", "title": "LiDAR, GNSS and IMU Sensor Alignment through Dynamic Time Warping to Construct 3D City Maps", "authors": ["Haitian Wang", "Hezam Albaqami", "Xinyu Wang", "Muhammad Ibrahim", "Zainy M. Malakan", "Abdullah M. Algamdi", "Mohammed H. Alghamdi", "Ajmal Mian"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Preparing to submit to International Journal of Applied Earth Observation and Geoinformation", "url": "http://arxiv.org/abs/2507.08420v1", "summary": "LiDAR-based 3D mapping suffers from cumulative drift causing global\nmisalignment, particularly in GNSS-constrained environments. To address this,\nwe propose a unified framework that fuses LiDAR, GNSS, and IMU data for\nhigh-resolution city-scale mapping. The method performs velocity-based temporal\nalignment using Dynamic Time Warping and refines GNSS and IMU signals via\nextended Kalman filtering. Local maps are built using Normal Distributions\nTransform-based registration and pose graph optimization with loop closure\ndetection, while global consistency is enforced using GNSS-constrained anchors\nfollowed by fine registration of overlapping segments. We also introduce a\nlarge-scale multimodal dataset captured in Perth, Western Australia to\nfacilitate future research in this direction. Our dataset comprises 144{,}000\nframes acquired with a 128-channel Ouster LiDAR, synchronized RTK-GNSS\ntrajectories, and MEMS-IMU measurements across 21 urban loops. To assess\ngeometric consistency, we evaluated our method using alignment metrics based on\nroad centerlines and intersections to capture both global and local accuracy.\nOur method reduces the average global alignment error from 3.32\\,m to 1.24\\,m,\nachieving a 61.4\\% improvement. The constructed high-fidelity map supports a\nwide range of applications, including smart city planning, geospatial data\nintegration, infrastructure monitoring, and GPS-free navigation. Our method,\nand dataset together establish a new benchmark for evaluating 3D city mapping\nin GNSS-constrained environments. The dataset and code will be released\npublicly.", "comment": "Preparing to submit to International Journal of Applied Earth\n  Observation and Geoinformation", "pdf_url": "http://arxiv.org/pdf/2507.08420v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08217", "title": "Quantum Federated Learning for Multimodal Data: A Modality-Agnostic Approach", "authors": ["Atit Pokharel", "Ratun Rahman", "Thomas Morris", "Dinh C. Nguyen"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      This paper was presented at BEAM with CVPR 2025", "url": "http://arxiv.org/abs/2507.08217v1", "summary": "Quantum federated learning (QFL) has been recently introduced to enable a\ndistributed privacy-preserving quantum machine learning (QML) model training\nacross quantum processors (clients). Despite recent research efforts, existing\nQFL frameworks predominantly focus on unimodal systems, limiting their\napplicability to real-world tasks that often naturally involve multiple\nmodalities. To fill this significant gap, we present for the first time a novel\nmultimodal approach specifically tailored for the QFL setting with the\nintermediate fusion using quantum entanglement. Furthermore, to address a major\nbottleneck in multimodal QFL, where the absence of certain modalities during\ntraining can degrade model performance, we introduce a Missing Modality\nAgnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring\nstable training without corrupted states. Simulation results demonstrate that\nthe proposed multimodal QFL method with MMA yields an improvement in accuracy\nof 6.84% in independent and identically distributed (IID) and 7.25% in non-IID\ndata distributions compared to the state-of-the-art methods.", "comment": "This paper was presented at BEAM with CVPR 2025", "pdf_url": "http://arxiv.org/pdf/2507.08217v1", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08053", "title": "Tree-Structured Parzen Estimator Can Solve Black-Box Combinatorial Optimization More Efficiently", "authors": ["Kenshin Abe", "Yunzhuo Wang", "Shuhei Watanabe"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to AutoML Conference", "url": "http://arxiv.org/abs/2507.08053v1", "summary": "Tree-structured Parzen estimator (TPE) is a versatile hyperparameter\noptimization (HPO) method supported by popular HPO tools. Since these HPO tools\nhave been developed in line with the trend of deep learning (DL), the problem\nsetups often used in the DL domain have been discussed for TPE such as\nmulti-objective optimization and multi-fidelity optimization. However, the\npractical applications of HPO are not limited to DL, and black-box\ncombinatorial optimization is actively utilized in some domains, e.g.,\nchemistry and biology. As combinatorial optimization has been an untouched, yet\nvery important, topic in TPE, we propose an efficient combinatorial\noptimization algorithm for TPE. In this paper, we first generalize the\ncategorical kernel with the numerical kernel in TPE, enabling us to introduce a\ndistance structure to the categorical kernel. Then we discuss modifications for\nthe newly developed kernel to handle a large combinatorial search space. These\nmodifications reduce the time complexity of the kernel calculation with respect\nto the size of a combinatorial search space. In the experiments using synthetic\nproblems, we verified that our proposed method identifies better solutions with\nfewer evaluations than the original TPE. Our algorithm is available in Optuna,\nan open-source framework for HPO.", "comment": "Submitted to AutoML Conference", "pdf_url": "http://arxiv.org/pdf/2507.08053v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08022", "title": "CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025", "authors": ["Hayato Tanoue", "Hiroki Nishihara", "Yuma Suzuki", "Takayuki Hori", "Hiroki Takushima", "Aiswariya Manojkumar", "Yuki Shibata", "Mitsuru Takeda", "Fumika Beppu", "Zhao Hengwei", "Yuto Kanda", "Daichi Yamaga"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      The 2nd place solution for the EgoExo4D Proficiency Estimation Challenge at the CVPR EgoVis Workshop 2025", "url": "http://arxiv.org/abs/2507.08022v1", "summary": "This report presents the CuriosAI team's submission to the EgoExo4D\nProficiency Estimation Challenge at CVPR 2025. We propose two methods for\nmulti-view skill assessment: (1) a multi-task learning framework using\nSapiens-2B that jointly predicts proficiency and scenario labels (43.6 %\naccuracy), and (2) a two-stage pipeline combining zero-shot scenario\nrecognition with view-specific VideoMAE classifiers (47.8 % accuracy). The\nsuperior performance of the two-stage approach demonstrates the effectiveness\nof scenario-conditioned modeling for proficiency estimation.", "comment": "The 2nd place solution for the EgoExo4D Proficiency Estimation\n  Challenge at the CVPR EgoVis Workshop 2025", "pdf_url": "http://arxiv.org/pdf/2507.08022v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08002", "title": "Human vs. LLM-Based Thematic Analysis for Digital Mental Health Research: Proof-of-Concept Comparative Study", "authors": ["Karisa Parkington", "Bazen G. Teferra", "Marianne Rouleau-Tang", "Argyrios Perivolaris", "Alice Rueda", "Adam Dubrowski", "Bill Kapralos", "Reza Samavi", "Andrew Greenshaw", "Yanbo Zhang", "Bo Cao", "Yuqi Wu", "Sirisha Rambhatla", "Sridhar Krishnan", "Venkat Bhat"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08002v1", "summary": "Thematic analysis provides valuable insights into participants' experiences\nthrough coding and theme development, but its resource-intensive nature limits\nits use in large healthcare studies. Large language models (LLMs) can analyze\ntext at scale and identify key content automatically, potentially addressing\nthese challenges. However, their application in mental health interviews needs\ncomparison with traditional human analysis. This study evaluates out-of-the-box\nand knowledge-base LLM-based thematic analysis against traditional methods\nusing transcripts from a stress-reduction trial with healthcare workers.\nOpenAI's GPT-4o model was used along with the Role, Instructions, Steps,\nEnd-Goal, Narrowing (RISEN) prompt engineering framework and compared to human\nanalysis in Dedoose. Each approach developed codes, noted saturation points,\napplied codes to excerpts for a subset of participants (n = 20), and\nsynthesized data into themes. Outputs and performance metrics were compared\ndirectly. LLMs using the RISEN framework developed deductive parent codes\nsimilar to human codes, but humans excelled in inductive child code development\nand theme synthesis. Knowledge-based LLMs reached coding saturation with fewer\ntranscripts (10-15) than the out-of-the-box model (15-20) and humans (90-99).\nThe out-of-the-box LLM identified a comparable number of excerpts to human\nresearchers, showing strong inter-rater reliability (K = 0.84), though the\nknowledge-based LLM produced fewer excerpts. Human excerpts were longer and\ninvolved multiple codes per excerpt, while LLMs typically applied one code.\nOverall, LLM-based thematic analysis proved more cost-effective but lacked the\ndepth of human analysis. LLMs can transform qualitative analysis in mental\nhealthcare and clinical research when combined with human oversight to balance\nparticipant perspectives and research resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08002v1", "cate": "cs.HC", "date": "2025-05-02", "updated": "2025-05-02"}
{"id": "2402.02672", "title": "Estimation of conditional average treatment effects on distributed confidential data", "authors": ["Yuji Kawamata", "Ryoki Motai", "Yukihiko Okada", "Akira Imakura", "Tetsuya Sakurai"], "categories": ["stat.ME", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "Comments:      45 pages, 12 figures", "url": "http://arxiv.org/abs/2402.02672v4", "summary": "The estimation of conditional average treatment effects (CATEs) is an\nimportant topic in many scientific fields. CATEs can be estimated with high\naccuracy if data distributed across multiple parties are centralized. However,\nit is difficult to aggregate such data owing to confidentiality or privacy\nconcerns. To address this issue, we propose data collaboration double machine\nlearning, a method for estimating CATE models using privacy-preserving fusion\ndata constructed from distributed sources, and evaluate its performance through\nsimulations. We make three main contributions. First, our method enables\nestimation and testing of semi-parametric CATE models without iterative\ncommunication on distributed data, providing robustness to model\nmis-specification compared to parametric approaches. Second, it enables\ncollaborative estimation across different time points and parties by\naccumulating a knowledge base. Third, our method performs as well as or better\nthan existing methods in simulations using synthetic, semi-synthetic, and\nreal-world datasets.", "comment": "45 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2402.02672v4", "cate": "stat.ME", "date": "2024-02-05", "updated": "2025-07-11"}
{"id": "2506.16710", "title": "Experimental Setup and Software Pipeline to Evaluate Optimization based Autonomous Multi-Robot Search Algorithms", "authors": ["Aditya Bhatt", "Mary Katherine Corra", "Franklin Merlo", "Prajit KrisshnaKumar", "Souma Chowdhury"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted for presentation in proceedings of ASME IDETC 2025", "url": "http://arxiv.org/abs/2506.16710v3", "summary": "Signal source localization has been a problem of interest in the multi-robot\nsystems domain given its applications in search & rescue and hazard\nlocalization in various industrial and outdoor settings. A variety of\nmulti-robot search algorithms exist that usually formulate and solve the\nassociated autonomous motion planning problem as a heuristic model-free or\nbelief model-based optimization process. Most of these algorithms however\nremains tested only in simulation, thereby losing the opportunity to generate\nknowledge about how such algorithms would compare/contrast in a real physical\nsetting in terms of search performance and real-time computing performance. To\naddress this gap, this paper presents a new lab-scale physical setup and\nassociated open-source software pipeline to evaluate and benchmark multi-robot\nsearch algorithms. The presented physical setup innovatively uses an acoustic\nsource (that is safe and inexpensive) and small ground robots (e-pucks)\noperating in a standard motion-capture environment. This setup can be easily\nrecreated and used by most robotics researchers. The acoustic source also\npresents interesting uncertainty in terms of its noise-to-signal ratio, which\nis useful to assess sim-to-real gaps. The overall software pipeline is designed\nto readily interface with any multi-robot search algorithm with minimal effort\nand is executable in parallel asynchronous form. This pipeline includes a\nframework for distributed implementation of multi-robot or swarm search\nalgorithms, integrated with a ROS (Robotics Operating System)-based software\nstack for motion capture supported localization. The utility of this novel\nsetup is demonstrated by using it to evaluate two state-of-the-art multi-robot\nsearch algorithms, based on swarm optimization and batch-Bayesian Optimization\n(called Bayes-Swarm), as well as a random walk baseline.", "comment": "Accepted for presentation in proceedings of ASME IDETC 2025", "pdf_url": "http://arxiv.org/pdf/2506.16710v3", "cate": "cs.RO", "date": "2025-06-20", "updated": "2025-07-11"}
{"id": "2507.08572", "title": "Robotic Calibration Based on Haptic Feedback Improves Sim-to-Real Transfer", "authors": ["Juraj Gavura", "Michal Vavrecka", "Igor Farkas", "Connor Gade"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      ICANN 2025", "url": "http://arxiv.org/abs/2507.08572v1", "summary": "When inverse kinematics (IK) is adopted to control robotic arms in\nmanipulation tasks, there is often a discrepancy between the end effector (EE)\nposition of the robot model in the simulator and the physical EE in reality. In\nmost robotic scenarios with sim-to-real transfer, we have information about\njoint positions in both simulation and reality, but the EE position is only\navailable in simulation. We developed a novel method to overcome this\ndifficulty based on haptic feedback calibration, using a touchscreen in front\nof the robot that provides information on the EE position in the real\nenvironment. During the calibration procedure, the robot touches specific\npoints on the screen, and the information is stored. In the next stage, we\nbuild a transformation function from the data based on linear transformation\nand neural networks that is capable of outputting all missing variables from\nany partial input (simulated/real joint/EE position). Our results demonstrate\nthat a fully nonlinear neural network model performs best, significantly\nreducing positioning errors.", "comment": "ICANN 2025", "pdf_url": "http://arxiv.org/pdf/2507.08572v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08264", "title": "Abductive Computational Systems: Creative Abduction and Future Directions", "authors": ["Abhinav Sood", "Kazjon Grace", "Stephen Wan", "Cecile Paris"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Published in the 16th International Conference on Computational Creativity, ICCC25. Accepted Paper in this https URL", "url": "http://arxiv.org/abs/2507.08264v1", "summary": "Abductive reasoning, reasoning for inferring explanations for observations,\nis often mentioned in scientific, design-related and artistic contexts, but its\nunderstanding varies across these domains. This paper reviews how abductive\nreasoning is discussed in epistemology, science and design, and then analyses\nhow various computational systems use abductive reasoning. Our analysis shows\nthat neither theoretical accounts nor computational implementations of\nabductive reasoning adequately address generating creative hypotheses.\nTheoretical frameworks do not provide a straightforward model for generating\ncreative abductive hypotheses, computational systems largely implement\nsyllogistic forms of abductive reasoning. We break down abductive computational\nsystems into components and conclude by identifying specific directions for\nfuture research that could advance the state of creative abductive reasoning in\ncomputational systems.", "comment": "Published in the 16th International Conference on Computational\n  Creativity, ICCC25. Accepted Paper in\n  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025abductive.pdf", "pdf_url": "http://arxiv.org/pdf/2507.08264v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08068", "title": "Quantile Reward Policy Optimization: Alignment with Pointwise Regression and Exact Partition Functions", "authors": ["Simon Matrenok", "Skander Moalla", "Caglar Gulcehre"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08068v1", "summary": "Aligning large language models with pointwise absolute rewards has so far\nrequired online, on-policy algorithms such as PPO and GRPO. In contrast,\nsimpler methods that can leverage offline or off-policy data, such as DPO and\nREBEL, are limited to learning from preference pairs or relative signals. To\nbridge this gap, we introduce \\emph{Quantile Reward Policy Optimization}\n(QRPO), which learns from pointwise absolute rewards while preserving the\nsimplicity and offline applicability of DPO-like methods. QRPO uses quantile\nrewards to enable regression to the closed-form solution of the KL-regularized\nRL objective. This reward yields an analytically tractable partition function,\nremoving the need for relative signals to cancel this term. Moreover, QRPO\nscales with increased compute to estimate quantile rewards, opening a new\ndimension for pre-computation scaling. Empirically, QRPO consistently achieves\ntop performance on chat and coding evaluations -- reward model scores,\nAlpacaEval 2, and LeetCode -- compared to DPO, REBEL, and SimPO across diverse\ndatasets and 8B-scale models. Finally, we find that training with robust\nrewards instead of converting them to preferences induces less length bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08068v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08024", "title": "Self-Consistency in Vision-Language Models for Precision Agriculture: Multi-Response Consensus for Crop Disease Management", "authors": ["Mihir Gupta", "Abhay Mangla", "Ross Greer", "Pratik Desai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08024v1", "summary": "Precision agriculture relies heavily on accurate image analysis for crop\ndisease identification and treatment recommendation, yet existing\nvision-language models (VLMs) often underperform in specialized agricultural\ndomains. This work presents a domain-aware framework for agricultural image\nprocessing that combines prompt-based expert evaluation with self-consistency\nmechanisms to enhance VLM reliability in precision agriculture applications. We\nintroduce two key innovations: (1) a prompt-based evaluation protocol that\nconfigures a language model as an expert plant pathologist for scalable\nassessment of image analysis outputs, and (2) a cosine-consistency self-voting\nmechanism that generates multiple candidate responses from agricultural images\nand selects the most semantically coherent diagnosis using domain-adapted\nembeddings. Applied to maize leaf disease identification from field images\nusing a fine-tuned PaliGemma model, our approach improves diagnostic accuracy\nfrom 82.2\\% to 87.8\\%, symptom analysis from 38.9\\% to 52.2\\%, and treatment\nrecommendation from 27.8\\% to 43.3\\% compared to standard greedy decoding. The\nsystem remains compact enough for deployment on mobile devices, supporting\nreal-time agricultural decision-making in resource-constrained environments.\nThese results demonstrate significant potential for AI-driven precision\nagriculture tools that can operate reliably in diverse field conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08024v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08003", "title": "A Versatile Dataset of Mouse and Eye Movements on Search Engine Results Pages", "authors": ["Kayhan Latifzadeh", "Jacek Gwizdka", "Luis A. Leiva"], "categories": ["cs.HC", "cs.CV", "cs.IR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08003v1", "summary": "We contribute a comprehensive dataset to study user attention and purchasing\nbehavior on Search Engine Result Pages (SERPs). Previous work has relied on\nmouse movements as a low-cost large-scale behavioral proxy but also has relied\non self-reported ground-truth labels, collected at post-task, which can be\ninaccurate and prone to biases. To address this limitation, we use an eye\ntracker to construct an objective ground-truth of continuous visual attention.\nOur dataset comprises 2,776 transactional queries on Google SERPs, collected\nfrom 47 participants, and includes: (1) HTML source files, with CSS and images;\n(2) rendered SERP screenshots; (3) eye movement data; (4) mouse movement data;\n(5) bounding boxes of direct display and organic advertisements; and (6)\nscripts for further preprocessing the data. In this paper we provide an\noverview of the dataset and baseline experiments (classification tasks) that\ncan inspire researchers about the different possibilities for future work.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08003v1", "cate": "cs.HC", "date": "2025-05-12", "updated": "2025-05-12"}
{"id": "2507.08177", "title": "Rethinking Spatio-Temporal Anomaly Detection: A Vision for Causality-Driven Cybersecurity", "authors": ["Arun Vignesh Malarkkan", "Haoyue Bai", "Xinyuan Wang", "Anjali Kaushik", "Dongjie Wang", "Yanjie Fu"], "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.NE", "F.2.2, I.2.7, I.2.4, I.2.1"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 1 figure, Under Review in Vision Paper Track-ACM SIGSPATIAL 2025", "url": "http://arxiv.org/abs/2507.08177v1", "summary": "As cyber-physical systems grow increasingly interconnected and spatially\ndistributed, ensuring their resilience against evolving cyberattacks has become\na critical priority. Spatio-Temporal Anomaly detection plays an important role\nin ensuring system security and operational integrity. However, current\ndata-driven approaches, largely driven by black-box deep learning, face\nchallenges in interpretability, adaptability to distribution shifts, and\nrobustness under evolving system dynamics. In this paper, we advocate for a\ncausal learning perspective to advance anomaly detection in spatially\ndistributed infrastructures that grounds detection in structural cause-effect\nrelationships. We identify and formalize three key directions: causal graph\nprofiling, multi-view fusion, and continual causal graph learning, each\noffering distinct advantages in uncovering dynamic cause-effect structures\nacross time and space. Drawing on real-world insights from systems such as\nwater treatment infrastructures, we illustrate how causal models provide early\nwarning signals and root cause attribution, addressing the limitations of\nblack-box detectors. Looking ahead, we outline the future research agenda\ncentered on multi-modality, generative AI-driven, and scalable adaptive causal\nframeworks. Our objective is to lay a new research trajectory toward scalable,\nadaptive, explainable, and spatially grounded anomaly detection systems. We\nhope to inspire a paradigm shift in cybersecurity research, promoting\ncausality-driven approaches to address evolving threats in interconnected\ninfrastructures.", "comment": "5 pages, 1 figure, Under Review in Vision Paper Track-ACM SIGSPATIAL\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.08177v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2503.00404", "title": "SecRef*: Securely Sharing Mutable References Between Verified and Unverified Code in F*", "authors": ["Cezar-Constantin Andrici", "Danel Ahman", "Catalin Hritcu", "Ruxandra Icleanu", "Guido Martínez", "Exequiel Rivas", "Théo Winterhalter"], "categories": ["cs.PL", "cs.CR"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "Comments:      ICFP'25 preprint", "url": "http://arxiv.org/abs/2503.00404v2", "summary": "We introduce SecRef*, a secure compilation framework protecting stateful\nprograms verified in F* against linked unverified code, with which the program\ndynamically shares ML-style mutable references. To ease program verification in\nthis setting, we propose a way of tracking which references are shareable with\nthe unverified code, and which ones are not shareable and whose contents are\nthus guaranteed to be unchanged after calling into unverified code. This\nuniversal property of non-shareable references is exposed in the interface on\nwhich the verified program can rely when calling into unverified code. The\nremaining refinement types and pre- and post-conditions that the verified code\nexpects from the unverified code are converted into dynamic checks about the\nshared references by using higher-order contracts. We prove formally in F* that\nthis strategy ensures sound and secure interoperability with unverified code.\nSince SecRef* is built on top of the Monotonic State effect of F*, these proofs\nrely on the first monadic representation for this effect, which is a\ncontribution of our work that can be of independent interest. Finally, we use\nSecRef* to build a simple cooperative multi-threading scheduler that is\nverified and that securely interacts with unverified threads.", "comment": "ICFP'25 preprint", "pdf_url": "http://arxiv.org/pdf/2503.00404v2", "cate": "cs.PL", "date": "2025-03-01", "updated": "2025-07-11"}
{"id": "2507.07257", "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "authors": ["Licong Xu", "Milind Sarkar", "Anto I. Lonappan", "Íñigo Zubeldia", "Pablo Villanueva-Domingo", "Santiago Casas", "Christian Fidler", "Chetana Amancharla", "Ujjwal Tiwari", "Adrian Bayer", "Chadi Ait Ekioui", "Miles Cranmer", "Adrian Dimitrov", "James Fergusson", "Kahaan Gandhi", "Sven Krippendorf", "Andrew Laverick", "Julien Lesgourgues", "Antony Lewis", "Thomas Meier", "Blake Sherwin", "Kristen Surrao", "Francisco Villaescusa-Navarro", "Chi Wang", "Xueqing Xu", "Boris Bolliet"], "categories": ["cs.AI", "astro-ph.IM", "cs.CL", "cs.MA"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted contribution to the ICML 2025 Workshop on Machine Learning for Astrophysics. Code: this https URL Videos: this https URL HuggingFace: this https URL Cloud: this https URL", "url": "http://arxiv.org/abs/2507.07257v2", "summary": "We present a multi-agent system for automation of scientific research tasks,\ncmbagent (https://github.com/CMBAgents/cmbagent). The system is formed by about\n30 Large Language Model (LLM) agents and implements a Planning & Control\nstrategy to orchestrate the agentic workflow, with no human-in-the-loop at any\npoint. Each agent specializes in a different task (performing retrieval on\nscientific papers and codebases, writing code, interpreting results, critiquing\nthe output of other agents) and the system is able to execute code locally. We\nsuccessfully apply cmbagent to carry out a PhD level cosmology task (the\nmeasurement of cosmological parameters using supernova data) and evaluate its\nperformance on two benchmark sets, finding superior performance over\nstate-of-the-art LLMs. The source code is available on GitHub, demonstration\nvideos are also available, and the system is deployed on HuggingFace and will\nbe available on the cloud.", "comment": "Accepted contribution to the ICML 2025 Workshop on Machine Learning\n  for Astrophysics. Code: https://github.com/CMBAgents/cmbagent Videos:\n  https://www.youtube.com/@cmbagent HuggingFace:\n  https://huggingface.co/spaces/astropilot-ai/cmbagent Cloud:\n  https://cmbagent.cloud", "pdf_url": "http://arxiv.org/pdf/2507.07257v2", "cate": "cs.AI", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2507.08656", "title": "Multi-critic Learning for Whole-body End-effector Twist Tracking", "authors": ["Aravind Elanjimattathil Vijayan", "Andrei Cramariuc", "Mattia Risiglione", "Christian Gehring", "Marco Hutter"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08656v1", "summary": "Learning whole-body control for locomotion and arm motions in a single policy\nhas challenges, as the two tasks have conflicting goals. For instance,\nefficient locomotion typically favors a horizontal base orientation, while\nend-effector tracking may benefit from base tilting to extend reachability.\nAdditionally, current Reinforcement Learning (RL) approaches using a pose-based\ntask specification lack the ability to directly control the end-effector\nvelocity, making smoothly executing trajectories very challenging. To address\nthese limitations, we propose an RL-based framework that allows for dynamic,\nvelocity-aware whole-body end-effector control. Our method introduces a\nmulti-critic actor architecture that decouples the reward signals for\nlocomotion and manipulation, simplifying reward tuning and allowing the policy\nto resolve task conflicts more effectively. Furthermore, we design a\ntwist-based end-effector task formulation that can track both discrete poses\nand motion trajectories. We validate our approach through a set of simulation\nand hardware experiments using a quadruped robot equipped with a robotic arm.\nThe resulting controller can simultaneously walk and move its end-effector and\nshows emergent whole-body behaviors, where the base assists the arm in\nextending the workspace, despite a lack of explicit formulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08656v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08306", "title": "M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning", "authors": ["Inclusion AI", ":", "Fudong Wang", "Jiajia Liu", "Jingdong Chen", "Jun Zhou", "Kaixiang Ji", "Lixiang Ru", "Qingpei Guo", "Ruobing Zheng", "Tianqi Li", "Yi Yuan", "Yifan Mao", "Yuting Xiao", "Ziping Ma"], "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      31pages, 14 figures", "url": "http://arxiv.org/abs/2507.08306v1", "summary": "Recent advancements in Multimodal Large Language Models (MLLMs), particularly\nthrough Reinforcement Learning with Verifiable Rewards (RLVR), have\nsignificantly enhanced their reasoning abilities. However, a critical gap\npersists: these models struggle with dynamic spatial interactions, a capability\nessential for real-world applications. To bridge this gap, we introduce\nM2-Reasoning-7B, a model designed to excel in both general and spatial\nreasoning. Our approach integrates two key innovations: (1) a novel data\npipeline that generates 294.2K high-quality data samples (168K for cold-start\nfine-tuning and 126.2K for RLVR), which feature logically coherent reasoning\ntrajectories and have undergone comprehensive assessment; and (2) a dynamic\nmulti-task training strategy with step-wise optimization to mitigate conflicts\nbetween data, and task-specific rewards for delivering tailored incentive\nsignals. This combination of curated data and advanced training allows\nM2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks,\nshowcasing superior performance in both general and spatial reasoning domains.", "comment": "31pages, 14 figures", "pdf_url": "http://arxiv.org/pdf/2507.08306v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08091", "title": "Low-rank Momentum Factorization for Memory Efficient Training", "authors": ["Pouria Mahdavinia", "Mehrdad Mahdavi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08091v1", "summary": "Fine-tuning large foundation models presents significant memory challenges\ndue to stateful optimizers like AdamW, often requiring several times more GPU\nmemory than inference. While memory-efficient methods like parameter-efficient\nfine-tuning (e.g., LoRA) and optimizer state compression exist, recent\napproaches like GaLore bridge these by using low-rank gradient projections and\nsubspace moment accumulation. However, such methods may struggle with fixed\nsubspaces or computationally costly offline resampling (e.g., requiring\nfull-matrix SVDs). We propose Momentum Factorized SGD (MoFaSGD), which\nmaintains a dynamically updated low-rank SVD representation of the first-order\nmomentum, closely approximating its full-rank counterpart throughout training.\nThis factorization enables a memory-efficient fine-tuning method that\nadaptively updates the optimization subspace at each iteration. Crucially,\nMoFaSGD leverages the computed low-rank momentum factors to perform efficient\nspectrally normalized updates, offering an alternative to subspace moment\naccumulation. We establish theoretical convergence guarantees for MoFaSGD,\nproving it achieves an optimal rate for non-convex stochastic optimization\nunder standard assumptions. Empirically, we demonstrate MoFaSGD's effectiveness\non large language model alignment benchmarks, achieving a competitive trade-off\nbetween memory reduction (comparable to LoRA) and performance compared to\nstate-of-the-art low-rank optimization methods. Our implementation is available\nat https://github.com/pmahdavi/MoFaSGD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08091v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08026", "title": "Development of a Canada-Wide Morphology Map for the ITU-R P. 1411 Propagation Model", "authors": ["Jennifer P. T. Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08026v1", "summary": "This paper outlines the development of a Canada-wide morphology map\nclassifying regions into residential, urban low-rise, and urban high-rise\nenvironments, following the ITU-R P.1411-12 propagation model guidelines. To\naddress the qualitative nature of the environment-type descriptors found in the\nRecommendation, a machine learning approach is employed to automate the\nclassification process. Extensive experimentation optimized classification\naccuracy, resulting in a Canada-wide morphology map that ensures more accurate\npath loss estimations for outdoor short-range propagation at frequencies\nranging from 300 MHz to 100 GHz.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08026v1", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08028", "title": "SSSUMO: Real-Time Semi-Supervised Submovement Decomposition", "authors": ["Evgenii Rudakov", "Jonathan Shock", "Otto Lappi", "Benjamin Ultan Cowley"], "categories": ["cs.HC", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08028v1", "summary": "This paper introduces a SSSUMO, semi-supervised deep learning approach for\nsubmovement decomposition that achieves state-of-the-art accuracy and speed.\nWhile submovement analysis offers valuable insights into motor control,\nexisting methods struggle with reconstruction accuracy, computational cost, and\nvalidation, due to the difficulty of obtaining hand-labeled data. We address\nthese challenges using a semi-supervised learning framework. This framework\nlearns from synthetic data, initially generated from minimum-jerk principles\nand then iteratively refined through adaptation to unlabeled human movement\ndata. Our fully convolutional architecture with differentiable reconstruction\nsignificantly surpasses existing methods on both synthetic and diverse human\nmotion datasets, demonstrating robustness even in high-noise conditions.\nCrucially, the model operates in real-time (less than a millisecond per input\nsecond), a substantial improvement over optimization-based techniques. This\nenhanced performance facilitates new applications in human-computer\ninteraction, rehabilitation medicine, and motor control studies. We demonstrate\nthe model's effectiveness across diverse human-performed tasks such as\nsteering, rotation, pointing, object moving, handwriting, and mouse-controlled\ngaming, showing notable improvements particularly on challenging datasets where\ntraditional methods largely fail. Training and benchmarking source code, along\nwith pre-trained model weights, are made publicly available at\nhttps://github.com/dolphin-in-a-coma/sssumo.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08028v1", "cate": "cs.HC", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08330", "title": "Interpretability-Aware Pruning for Efficient Medical Image Analysis", "authors": ["Nikita Malik", "Pratinav Seth", "Neeraj Kumar Singh", "Chintan Chitroda", "Vinay Kumar Sankarapu"], "categories": ["cs.CV", "cs.AI", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Pre-Print", "url": "http://arxiv.org/abs/2507.08330v1", "summary": "Deep learning has driven significant advances in medical image analysis, yet\nits adoption in clinical practice remains constrained by the large size and\nlack of transparency in modern models. Advances in interpretability techniques\nsuch as DL-Backtrace, Layer-wise Relevance Propagation, and Integrated\nGradients make it possible to assess the contribution of individual components\nwithin neural networks trained on medical imaging tasks. In this work, we\nintroduce an interpretability-guided pruning framework that reduces model\ncomplexity while preserving both predictive performance and transparency. By\nselectively retaining only the most relevant parts of each layer, our method\nenables targeted compression that maintains clinically meaningful\nrepresentations. Experiments across multiple medical image classification\nbenchmarks demonstrate that this approach achieves high compression rates with\nminimal loss in accuracy, paving the way for lightweight, interpretable models\nsuited for real-world deployment in healthcare settings.", "comment": "Pre-Print", "pdf_url": "http://arxiv.org/pdf/2507.08330v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08726", "title": "Learning human-to-robot handovers through 3D scene reconstruction", "authors": ["Yuekun Wu", "Yik Lung Pang", "Andrea Cavallaro", "Changjae Oh"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, 2 table", "url": "http://arxiv.org/abs/2507.08726v1", "summary": "Learning robot manipulation policies from raw, real-world image data requires\na large number of robot-action trials in the physical environment. Although\ntraining using simulations offers a cost-effective alternative, the visual\ndomain gap between simulation and robot workspace remains a major limitation.\nGaussian Splatting visual reconstruction methods have recently provided new\ndirections for robot manipulation by generating realistic environments. In this\npaper, we propose the first method for learning supervised-based robot\nhandovers solely from RGB images without the need of real-robot training or\nreal-robot data collection. The proposed policy learner, Human-to-Robot\nHandover using Sparse-View Gaussian Splatting (H2RH-SGS), leverages sparse-view\nGaussian Splatting reconstruction of human-to-robot handover scenes to generate\nrobot demonstrations containing image-action pairs captured with a camera\nmounted on the robot gripper. As a result, the simulated camera pose changes in\nthe reconstructed scene can be directly translated into gripper pose changes.\nWe train a robot policy on demonstrations collected with 16 household objects\nand {\\em directly} deploy this policy in the real environment. Experiments in\nboth Gaussian Splatting reconstructed scene and real-world human-to-robot\nhandover experiments demonstrate that H2RH-SGS serves as a new and effective\nrepresentation for the human-to-robot handover task.", "comment": "8 pages, 6 figures, 2 table", "pdf_url": "http://arxiv.org/pdf/2507.08726v1", "cate": "cs.RO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08392", "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08392v1", "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08392v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08118", "title": "PDE-aware Optimizer for Physics-informed Neural Networks", "authors": ["Hardik Shukla", "Manurag Khullar", "Vismay Churiwala"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08118v1", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework\nfor solving partial differential equations (PDEs) by embedding physical\nconstraints into the loss function. However, standard optimizers such as Adam\noften struggle to balance competing loss terms, particularly in stiff or\nill-conditioned systems. In this work, we propose a PDE-aware optimizer that\nadapts parameter updates based on the variance of per-sample PDE residual\ngradients. This method addresses gradient misalignment without incurring the\nheavy computational costs of second-order optimizers such as SOAP. We benchmark\nthe PDE-aware optimizer against Adam and SOAP on 1D Burgers', Allen-Cahn and\nKorteweg-de Vries(KdV) equations. Across both PDEs, the PDE-aware optimizer\nachieves smoother convergence and lower absolute errors, particularly in\nregions with sharp gradients. Our results demonstrate the effectiveness of PDE\nresidual-aware adaptivity in enhancing stability in PINNs training. While\npromising, further scaling on larger architectures and hardware accelerators\nremains an important direction for future research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08118v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08039", "title": "Towards Evaluating Robustness of Prompt Adherence in Text to Image Models", "authors": ["Sujith Vemishetty", "Advitiya Arora", "Anupama Sharma"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08039v1", "summary": "The advancements in the domain of LLMs in recent years have surprised many,\nshowcasing their remarkable capabilities and diverse applications. Their\npotential applications in various real-world scenarios have led to significant\nresearch on their reliability and effectiveness. On the other hand, multimodal\nLLMs and Text-to-Image models have only recently gained prominence, especially\nwhen compared to text-only LLMs. Their reliability remains constrained due to\ninsufficient research on assessing their performance and robustness. This paper\naims to establish a comprehensive evaluation framework for Text-to-Image\nmodels, concentrating particularly on their adherence to prompts. We created a\nnovel dataset that aimed to assess the robustness of these models in generating\nimages that conform to the specified factors of variation in the input text\nprompts. Our evaluation studies present findings on three variants of Stable\nDiffusion models: Stable Diffusion 3 Medium, Stable Diffusion 3.5 Large, and\nStable Diffusion 3.5 Large Turbo, and two variants of Janus models: Janus Pro\n1B and Janus Pro 7B. We introduce a pipeline that leverages text descriptions\ngenerated by the gpt-4o model for our ground-truth images, which are then used\nto generate artificial images by passing these descriptions to the\nText-to-Image models. We then pass these generated images again through gpt-4o\nusing the same system prompt and compare the variation between the two\ndescriptions. Our results reveal that these models struggle to create simple\nbinary images with only two factors of variation: a simple geometric shape and\nits location. We also show, using pre-trained VAEs on our dataset, that they\nfail to generate images that follow our input dataset distribution.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08039v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08142", "title": "Pushing the Boundaries of Immersion and Storytelling: A Technical Review of Unreal Engine", "authors": ["Oleksandra Sobchyshak", "Santiago Berrezueta-Guzman", "Stefan Wagner"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Paper submitted to Elsevier", "url": "http://arxiv.org/abs/2507.08142v1", "summary": "Unreal Engine is a platform that has influenced immersive storytelling and\nvirtual reality (VR) through its advanced features and diverse applications.\nThis paper provides an in-depth technical review of Unreal Engine. It analyzes\nits key innovations in creating hyper-realistic environments and emotionally\nengaging narratives, with significant applications in gaming, virtual\nproduction, education, cultural preservation, and healthcare. The findings of\nthis article highlight Unreal Engine's transformative impact across industries,\ndemonstrating its ability to merge storytelling with cutting-edge technologies.\nCase studies illustrate how Unreal Engine facilitates seamless visuals, audio,\nand interactivity integration to create compelling experiences. Additionally,\nthis study identifies Unreal Engine's versatility in applications ranging from\nprocedural content generation and AI-driven workflows to smart city simulations\nand VR-based rehabilitation programs.\n  While Unreal Engine sets new benchmarks for visual fidelity and\ninteractivity, this paper underscores critical challenges, including its high\nhardware demands, limited accessibility, and ethical concerns related to\nover-immersion and data privacy. Addressing these challenges through\ncloud-based rendering, inclusive design, and ethical practices is essential for\nbroader adoption and sustainability. This review concludes that Unreal Engine\nis suitable for innovation and interdisciplinary collaboration. Its ability to\nempower creators, redefine workflows, and push the boundaries of immersive\nstorytelling positions Unreal Engine as pivotal in shaping the future of\nvirtual reality and interactive media.", "comment": "Paper submitted to Elsevier", "pdf_url": "http://arxiv.org/pdf/2507.08142v1", "cate": "cs.HC", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.06361", "title": "Experimental Ground-State Energy of a 125-Site Flat Kagome Antiferromagnet via Hamiltonian Engineering on Quantum Computer", "authors": ["Muhammad Ahsan"], "categories": ["quant-ph", "cs.ET"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      National Center for Quantum Computing, UET Lahore, Pakistan", "url": "http://arxiv.org/abs/2507.06361v2", "summary": "We present an instance of utility-grade quantum computation by calculating\nthe ground-state energy of a 125-site flat Kagome lattice under the\nantiferromagnetic Heisenberg model (KAFH), with IBM's Heron r1 and Heron r2\nquantum processors. For spin-1/2 KAFH, our best per-site ground-state energy\nestimate arrives at -0.417J, and after applying open-boundary corrections, it\nclosely approaches the established thermodynamic value of -0.438J. To achieve\nthis, we propose a hybrid approach that splits the variational quantum\neigensolver (VQE) into local (classical) and global (quantum) components for\nefficient hardware utilization. We further introduce a Hamiltonian engineering\nstrategy that increases coupling on defect triangles to mimic loop-flip\ndynamics, allowing us to simplify the ansatz while retaining physical accuracy.\nUsing a single-repetition, hardware-efficient ansatz, we entangle up to 103\nqubits with high fidelity to determine the Hamiltonian's lowest eigenvalue.\nThis work demonstrates the scalability of VQE for frustrated 2D systems and\nlays the foundation for future studies using deeper ansatz circuits and larger\nlattices.", "comment": "National Center for Quantum Computing, UET Lahore, Pakistan", "pdf_url": "http://arxiv.org/pdf/2507.06361v2", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-10"}
{"id": "2507.08165", "title": "An Embedded Real-time Object Alert System for Visually Impaired: A Monocular Depth Estimation based Approach through Computer Vision", "authors": ["Jareen Anjom", "Rashik Iram Chowdhury", "Tarbia Hasan", "Md. Ishan Arefin Hossain"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08165v1", "summary": "Visually impaired people face significant challenges in their day-to-day\ncommutes in the urban cities of Bangladesh due to the vast number of\nobstructions on every path. With many injuries taking place through road\naccidents on a daily basis, it is paramount for a system to be developed that\ncan alert the visually impaired of objects at close distance beforehand. To\novercome this issue, a novel alert system is proposed in this research to\nassist the visually impaired in commuting through these busy streets without\ncolliding with any objects. The proposed system can alert the individual to\nobjects that are present at a close distance. It utilizes transfer learning to\ntrain models for depth estimation and object detection, and combines both\nmodels to introduce a novel system. The models are optimized through the\nutilization of quantization techniques to make them lightweight and efficient,\nallowing them to be easily deployed on embedded systems. The proposed solution\nachieved a lightweight real-time depth estimation and object detection model\nwith an mAP50 of 0.801.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08165v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08454", "title": "Why this and not that? A Logic-based Framework for Contrastive Explanations", "authors": ["Tobias Geibinger", "Reijo Jaakkola", "Antti Kuusisto", "Xinghan Liu", "Miikka Vilander"], "categories": ["cs.AI", "cs.LG", "cs.LO", "68T27, 03B05", "I.2.3; F.4.1"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      20 pages, accepted to JELIA 2025", "url": "http://arxiv.org/abs/2507.08454v1", "summary": "We define several canonical problems related to contrastive explanations,\neach answering a question of the form ''Why P but not Q?''. The problems\ncompute causes for both P and Q, explicitly comparing their differences. We\ninvestigate the basic properties of our definitions in the setting of\npropositional logic. We show, inter alia, that our framework captures a\ncardinality-minimal version of existing contrastive explanations in the\nliterature. Furthermore, we provide an extensive analysis of the computational\ncomplexities of the problems. We also implement the problems for CNF-formulas\nusing answer set programming and present several examples demonstrating how\nthey work in practice.", "comment": "20 pages, accepted to JELIA 2025", "pdf_url": "http://arxiv.org/pdf/2507.08454v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08121", "title": "Quasi-Random Physics-informed Neural Networks", "authors": ["Tianchi Yu", "Ivan Oseledets"], "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08121v1", "summary": "Physics-informed neural networks have shown promise in solving partial\ndifferential equations (PDEs) by integrating physical constraints into neural\nnetwork training, but their performance is sensitive to the sampling of points.\nBased on the impressive performance of quasi Monte-Carlo methods in high\ndimensional problems, this paper proposes Quasi-Random Physics-Informed Neural\nNetworks (QRPINNs), which use low-discrepancy sequences for sampling instead of\nrandom points directly from the domain. Theoretically, QRPINNs have been proven\nto have a better convergence rate than PINNs. Empirically, experiments\ndemonstrate that QRPINNs significantly outperform PINNs and some representative\nadaptive sampling methods, especially in high-dimensional PDEs. Furthermore,\ncombining QRPINNs with adaptive sampling can further improve the performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08121v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08044", "title": "ConsNoTrainLoRA: Data-driven Weight Initialization of Low-rank Adapters using Constraints", "authors": ["Debasmit Das", "Hyoungwoo Park", "Munawar Hayat", "Seokeon Choi", "Sungrack Yun", "Fatih Porikli"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2507.08044v1", "summary": "Foundation models are pre-trained on large-scale datasets and subsequently\nfine-tuned on small-scale datasets using parameter-efficient fine-tuning (PEFT)\ntechniques like low-rank adapters (LoRA). In most previous works, LoRA weight\nmatrices are randomly initialized with a fixed rank across all attachment\npoints. In this paper, we improve convergence and final performance of LoRA\nfine-tuning, using our proposed data-driven weight initialization method,\nConsNoTrainLoRA (CNTLoRA). We express LoRA initialization as a domain shift\nproblem where we use multiple constraints relating the pre-training and\nfine-tuning activations. By reformulating these constraints, we obtain a\nclosed-form estimate of LoRA weights that depends on pre-training weights and\nfine-tuning activation vectors and hence requires no training during\ninitialization. This weight estimate is decomposed to initialize the up and\ndown matrices with proposed flexibility of variable ranks. With the proposed\ninitialization method, we fine-tune on downstream tasks such as image\ngeneration, image classification and image understanding. Both quantitative and\nqualitative results demonstrate that CNTLoRA outperforms standard and\ndata-driven weight initialization methods. Extensive analyses and ablations\nfurther elucidate the design choices of our framework, providing an optimal\nrecipe for faster convergence and enhanced performance.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.08044v1", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08167", "title": "Emotion Detection in Older Adults Using Physiological Signals from Wearable Sensors", "authors": ["Md. Saif Hassan Onim", "Andrew M. Kiselica", "Himanshu Thapliyal"], "categories": ["cs.HC", "cs.LG", "H.1.2; J.3; C.3"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08167v1", "summary": "Emotion detection in older adults is crucial for understanding their\ncognitive and emotional well-being, especially in hospital and assisted living\nenvironments. In this work, we investigate an edge-based, non-obtrusive\napproach to emotion identification that uses only physiological signals\nobtained via wearable sensors. Our dataset includes data from 40 older\nindividuals. Emotional states were obtained using physiological signals from\nthe Empatica E4 and Shimmer3 GSR+ wristband and facial expressions were\nrecorded using camera-based emotion recognition with the iMotion's Facial\nExpression Analysis (FEA) module. The dataset also contains twelve emotion\ncategories in terms of relative intensities. We aim to study how well emotion\nrecognition can be accomplished using simply physiological sensor data, without\nthe requirement for cameras or intrusive facial analysis. By leveraging\nclassical machine learning models, we predict the intensity of emotional\nresponses based on physiological signals. We achieved the highest 0.782 r2\nscore with the lowest 0.0006 MSE on the regression task. This method has\nsignificant implications for individuals with Alzheimer's Disease and Related\nDementia (ADRD), as well as veterans coping with Post-Traumatic Stress Disorder\n(PTSD) or other cognitive impairments. Our results across multiple classical\nregression models validate the feasibility of this method, paving the way for\nprivacy-preserving and efficient emotion recognition systems in real-world\nsettings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08167v1", "cate": "cs.HC", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08707", "title": "SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations", "authors": ["Peter Crowley", "Zachary Serlin", "Tyler Paine", "Makai Mann", "Michael Benjamin", "Calin Belta"], "categories": ["cs.LG", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08707v1", "summary": "Inverse Reinforcement Learning (IRL) presents a powerful paradigm for\nlearning complex robotic tasks from human demonstrations. However, most\napproaches make the assumption that expert demonstrations are available, which\nis often not the case. Those that allow for suboptimality in the demonstrations\nare not designed for long-horizon goals or adversarial tasks. Many desirable\nrobot capabilities fall into one or both of these categories, thus highlighting\na critical shortcoming in the ability of IRL to produce field-ready robotic\nagents. We introduce Sample-efficient Preference-based inverse reinforcement\nlearning for Long-horizon Adversarial tasks from Suboptimal Hierarchical\ndemonstrations (SPLASH), which advances the state-of-the-art in learning from\nsuboptimal demonstrations to long-horizon and adversarial settings. We\nempirically validate SPLASH on a maritime capture-the-flag task in simulation,\nand demonstrate real-world applicability with sim-to-real translation\nexperiments on autonomous unmanned surface vehicles. We show that our proposed\nmethods allow SPLASH to significantly outperform the state-of-the-art in reward\nlearning from suboptimal demonstrations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08707v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08501", "title": "From Language to Logic: A Bi-Level Framework for Structured Reasoning", "authors": ["Keying Yang", "Hao Wang", "Kai Yang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08501v1", "summary": "Structured reasoning over natural language inputs remains a core challenge in\nartificial intelligence, as it requires bridging the gap between unstructured\nlinguistic expressions and formal logical representations. In this paper, we\npropose a novel \\textbf{bi-level framework} that maps language to logic through\na two-stage process: high-level task abstraction and low-level logic\ngeneration. At the upper level, a large language model (LLM) parses natural\nlanguage queries into intermediate structured representations specifying the\nproblem type, objectives, decision variables, and symbolic constraints. At the\nlower level, the LLM uses these representations to generate symbolic workflows\nor executable reasoning programs for accurate and interpretable decision\nmaking. The framework supports modular reasoning, enforces explicit\nconstraints, and generalizes across domains such as mathematical problem\nsolving, question answering, and logical inference. We further optimize the\nframework with an end-to-end {bi-level} optimization approach that jointly\nrefines both the high-level abstraction and low-level logic generation stages.\nExperiments on multiple realistic reasoning benchmarks demonstrate that our\napproach significantly outperforms existing baselines in accuracy, with\naccuracy gains reaching as high as 40\\%. Moreover, the bi-level design enhances\ntransparency and error traceability, offering a promising step toward\ntrustworthy and systematic reasoning with LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08501v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08124", "title": "Physics-Informed Neural Networks with Hard Nonlinear Equality and Inequality Constraints", "authors": ["Ashfaq Iftakher", "Rahul Golder", "M. M. Faruque Hasan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages, 8 figures", "url": "http://arxiv.org/abs/2507.08124v1", "summary": "Traditional physics-informed neural networks (PINNs) do not guarantee strict\nconstraint satisfaction. This is problematic in engineering systems where minor\nviolations of governing laws can significantly degrade the reliability and\nconsistency of model predictions. In this work, we develop KKT-Hardnet, a PINN\narchitecture that enforces both linear and nonlinear equality and inequality\nconstraints up to machine precision. It leverages a projection onto the\nfeasible region through solving Karush-Kuhn-Tucker (KKT) conditions of a\ndistance minimization problem. Furthermore, we reformulate the nonlinear KKT\nconditions using log-exponential transformation to construct a general sparse\nsystem with only linear and exponential terms, thereby making the projection\ndifferentiable. We apply KKT-Hardnet on both test problems and a real-world\nchemical process simulation. Compared to multilayer perceptrons and PINNs,\nKKT-Hardnet achieves higher accuracy and strict constraint satisfaction. This\napproach allows the integration of domain knowledge into machine learning\ntowards reliable hybrid modeling of complex systems.", "comment": "20 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.08124v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08047", "title": "A Hybrid Multilayer Extreme Learning Machine for Image Classification with an Application to Quadcopters", "authors": ["Rolando A. Hernandez-Hernandez", "Adrian Rubio-Solis"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      22 pages, 10 figures, 3 tables", "url": "http://arxiv.org/abs/2507.08047v1", "summary": "Multilayer Extreme Learning Machine (ML-ELM) and its variants have proven to\nbe an effective technique for the classification of different natural signals\nsuch as audio, video, acoustic and images. In this paper, a Hybrid Multilayer\nExtreme Learning Machine (HML-ELM) that is based on ELM-based autoencoder\n(ELM-AE) and an Interval Type-2 fuzzy Logic theory is suggested for active\nimage classification and applied to Unmanned Aerial Vehicles (UAVs). The\nproposed methodology is a hierarchical ELM learning framework that consists of\ntwo main phases: 1) self-taught feature extraction and 2) supervised feature\nclassification. First, unsupervised multilayer feature encoding is achieved by\nstacking a number of ELM-AEs, in which input data is projected into a number of\nhigh-level representations. At the second phase, the final features are\nclassified using a novel Simplified Interval Type-2 Fuzzy ELM (SIT2-FELM) with\na fast output reduction layer based on the SC algorithm; an improved version of\nthe algorithm Center of Sets Type Reducer without Sorting Requirement\n(COSTRWSR). To validate the efficiency of the HML-ELM, two types of experiments\nfor the classification of images are suggested. First, the HML-ELM is applied\nto solve a number of benchmark problems for image classification. Secondly, a\nnumber of real experiments to the active classification and transport of four\ndifferent objects between two predefined locations using a UAV is implemented.\nExperiments demonstrate that the proposed HML-ELM delivers a superior\nefficiency compared to other similar methodologies such as ML-ELM, Multilayer\nFuzzy Extreme Learning Machine (ML-FELM) and ELM.", "comment": "22 pages, 10 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.08047v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08230", "title": "Uncanny or Not? Perceptions of AI-Generated Faces in Autism", "authors": ["Gabriella Waters"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      2 figures, 15 pages", "url": "http://arxiv.org/abs/2507.08230v1", "summary": "As artificial intelligence (AI) systems become increasingly sophisticated at\ngenerating synthetic human faces, understanding how these images are perceived\nacross diverse populations is important. This study investigates how autistic\nindividuals/individuals with autism perceive AI-generated faces, focusing on\nthe uncanny valley effect. Using a qualitative approach, we analyzed\ndiscussions from the r/autism community on Reddit to explore how autistic\nparticipants/participants with autism describe their experiences with\nAI-generated faces and the uncanny valley phenomenon. The findings suggest that\nautistic people/people with autism may experience the uncanny valley\ndifferently, often reporting stronger discomfort with real human faces than\nwith artificial ones. This research contributes to our understanding of visual\nperception in autism and has implications for the development of inclusive AI\nsystems and assistive technologies.", "comment": "2 figures, 15 pages", "pdf_url": "http://arxiv.org/pdf/2507.08230v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08061", "title": "The State of Computational Science in Fission and Fusion Energy", "authors": ["Andrea Morales Coto", "Aditi Verma"], "categories": ["cs.SE", "physics.soc-ph"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08061v1", "summary": "The tools used to engineer something are just as important as the thing that\nis actually being engineered. In fact, in many cases, the tools can indeed\ndetermine what is engineerable. In fusion and fission1 energy engineering,\nsoftware has become the dominant tool for design. For that reason, in 2024, for\nthe first time ever, we asked 103 computational scientists developing the codes\nused in fusion and fission energy about the problems they are attempting to\nsolve with their codes, the tools available to them to solve them, and their\nend to end developer experience with said tools.\n  The results revealed a changing tide in software tools in fusion and fission,\nwith more and more computational scientists preferring modern programming\nlanguages, open-source codes, and modular software. These trends represent a\npeek into what will happen 5 to 10 years in the future of nuclear engineering.\nSince the majority of our respondents belonged to US national labs and\nuniversities, these results hint at the most cutting-edge trends in the\nindustry. The insights included in the State of Computational Science in\nFission and Fusion Energy indicate a dramatic shift toward multiphysics codes,\na drop-off in the use of FORTRAN in favor of more modern languages like Python\nand C++, and ever-rising budgets for code development, at times reaching $50M\nin a single organization.\n  Our survey paints a future of nuclear engineering codes that is modular in\nnature, small in terms of compute, and increasingly prioritized by\norganizations. Access to our results in web form are available online.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08061v1", "cate": "cs.SE", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2410.12169", "title": "Towards Autonomous Indoor Parking: A Globally Consistent Semantic SLAM System and A Semantic Localization Subsystem", "authors": ["Yichen Sha", "Siting Zhu", "Hekui Guo", "Zhong Wang", "Hesheng Wang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IROS 2025", "url": "http://arxiv.org/abs/2410.12169v2", "summary": "We propose a globally consistent semantic SLAM system (GCSLAM) and a\nsemantic-fusion localization subsystem (SF-Loc), which achieves accurate\nsemantic mapping and robust localization in complex parking lots. Visual\ncameras (front-view and surround-view), IMU, and wheel encoder form the input\nsensor configuration of our system. The first part of our work is GCSLAM.\nGCSLAM introduces a semantic-constrained factor graph for the optimization of\nposes and semantic map, which incorporates innovative error terms based on\nmulti-sensor data and BEV (bird's-eye view) semantic information. Additionally,\nGCSLAM integrates a Global Slot Management module that stores and manages\nparking slot observations. SF-Loc is the second part of our work, which\nleverages the semantic map built by GCSLAM to conduct map-based localization.\nSF-Loc integrates registration results and odometry poses with a novel factor\ngraph. Our system demonstrates superior performance over existing SLAM on two\nreal-world datasets, showing excellent capabilities in robust global\nlocalization and precise semantic mapping.", "comment": "IROS 2025", "pdf_url": "http://arxiv.org/pdf/2410.12169v2", "cate": "cs.RO", "date": "2024-10-16", "updated": "2025-07-11"}
{"id": "2507.08529", "title": "A Multi-granularity Concept Sparse Activation and Hierarchical Knowledge Graph Fusion Framework for Rare Disease Diagnosis", "authors": ["Mingda Zhang", "Na Zhao", "Jianglong Qin", "Guoyu Ye", "Ruixiang Tang"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages,3 figures", "url": "http://arxiv.org/abs/2507.08529v1", "summary": "Despite advances from medical large language models in healthcare,\nrare-disease diagnosis remains hampered by insufficient\nknowledge-representation depth, limited concept understanding, and constrained\nclinical reasoning. We propose a framework that couples multi-granularity\nsparse activation of medical concepts with a hierarchical knowledge graph. Four\ncomplementary matching algorithms, diversity control, and a five-level fallback\nstrategy enable precise concept activation, while a three-layer knowledge graph\n(taxonomy, clinical features, instances) provides structured, up-to-date\ncontext. Experiments on the BioASQ rare-disease QA set show BLEU gains of 0.09,\nROUGE gains of 0.05, and accuracy gains of 0.12, with peak accuracy of 0.89\napproaching the 0.90 clinical threshold. Expert evaluation confirms\nimprovements in information quality, reasoning, and professional expression,\nsuggesting our approach shortens the \"diagnostic odyssey\" for rare-disease\npatients.", "comment": "10 pages,3 figures", "pdf_url": "http://arxiv.org/pdf/2507.08529v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08153", "title": "ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction", "authors": ["Pinaki Prasad Guha Neogi", "Ahmad Mohammadshirazi", "Rajiv Ramnath"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08153v1", "summary": "Traffic accidents are rare, yet high-impact events that require long-context\nmultimodal reasoning for accurate risk forecasting. In this paper, we introduce\nALCo-FM, a unified adaptive long-context foundation model that computes a\nvolatility pre-score to dynamically select context windows for input data and\nencodes and fuses these multimodal data via shallow cross attention. Following\na local GAT layer and a BigBird-style sparse global transformer over H3\nhexagonal grids, coupled with Monte Carlo dropout for confidence, the model\nyields superior, well-calibrated predictions. Trained on data from 15 US cities\nwith a class-weighted loss to counter label imbalance, and fine-tuned with\nminimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and\nan ECE of 0.04, outperforming more than 20 state-of-the-art baselines in\nlarge-scale urban risk prediction. Code and dataset are available at:\nhttps://github.com/PinakiPrasad12/ALCo-FM", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08153v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08052", "title": "Lightweight Cloud Masking Models for On-Board Inference in Hyperspectral Imaging", "authors": ["Mazen Ali", "António Pereira", "Fabio Gentile", "Aser Cortines", "Sam Mugel", "Román Orús", "Stelios P. Neophytides", "Michalis Mavrovouniotis"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08052v1", "summary": "Cloud and cloud shadow masking is a crucial preprocessing step in\nhyperspectral satellite imaging, enabling the extraction of high-quality,\nanalysis-ready data. This study evaluates various machine learning approaches,\nincluding gradient boosting methods such as XGBoost and LightGBM as well as\nconvolutional neural networks (CNNs). All boosting and CNN models achieved\naccuracies exceeding 93%. Among the investigated models, the CNN with feature\nreduction emerged as the most efficient, offering a balance of high accuracy,\nlow storage requirements, and rapid inference times on both CPUs and GPUs.\nVariations of this version, with only up to 597 trainable parameters,\ndemonstrated the best trade-off in terms of deployment feasibility, accuracy,\nand computational efficiency. These results demonstrate the potential of\nlightweight artificial intelligence (AI) models for real-time hyperspectral\nimage processing, supporting the development of on-board satellite AI systems\nfor space-based applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08052v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08260", "title": "Do Conversational Interfaces Limit Creativity? Exploring Visual Graph Systems for Creative Writing", "authors": ["Abhinav Sood", "Maria Teresa Llano", "Jon McCormack"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Published in the 16th International Conference on Computational Creativity, ICCC25. Accepted Paper in this https URL", "url": "http://arxiv.org/abs/2507.08260v1", "summary": "We present a graphical, node-based system through which users can visually\nchain generative AI models for creative tasks. Research in the area of chaining\nLLMs has found that while chaining provides transparency, controllability and\nguardrails to approach certain tasks, chaining with pre-defined LLM steps\nprevents free exploration. Using cognitive processes from creativity research\nas a basis, we create a system that addresses the inherent constraints of\nchat-based AI interactions. Specifically, our system aims to overcome the\nlimiting linear structure that inhibits creative exploration and ideation.\nFurther, our node-based approach enables the creation of reusable, shareable\ntemplates that can address different creative tasks. In a small-scale user\nstudy, we find that our graph-based system supports ideation and allows some\nusers to better visualise and think through their writing process when compared\nto a similar conversational interface. We further discuss the weaknesses and\nlimitations of our system, noting the benefits to creativity that user\ninterfaces with higher complexity can provide for users who can effectively use\nthem.", "comment": "Published in the 16th International Conference on Computational\n  Creativity, ICCC25. Accepted Paper in\n  https://computationalcreativity.net/iccc25/wp-content/uploads/papers/iccc25-sood2025conversational.pdf", "pdf_url": "http://arxiv.org/pdf/2507.08260v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08149", "title": "Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows", "authors": ["Valerie Chen", "Ameet Talwalkar", "Robert Brennan", "Graham Neubig"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08149v1", "summary": "Developers now have access to a growing array of increasingly autonomous AI\ntools to support software development. While numerous studies have examined\ndeveloper use of copilots, which can provide chat assistance or code\ncompletions, evaluations of coding agents, which can automatically write files\nand run code, still largely rely on static benchmarks without\nhumans-in-the-loop. In this work, we conduct the first academic study to\nexplore developer interactions with coding agents and characterize how more\nautonomous AI tools affect user productivity and experience, compared to\nexisting copilots. We evaluate two leading copilot and agentic coding\nassistants, GitHub Copilot and OpenHands, recruiting participants who regularly\nuse the former. Our results show agents have the potential to assist developers\nin ways that surpass copilots (e.g., completing tasks that humans might not\nhave accomplished before) and reduce the user effort required to complete\ntasks. However, there are challenges involved in enabling their broader\nadoption, including how to ensure users have an adequate understanding of agent\nbehaviors. Our results not only provide insights into how developer workflows\nchange as a result of coding agents but also highlight how user interactions\nwith agents differ from those with existing copilots, motivating a set of\nrecommendations for researchers building new agents. Given the broad set of\ndevelopers who still largely rely on copilot-like systems, our work highlights\nkey challenges of adopting more agentic systems into developer workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08149v1", "cate": "cs.SE", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2411.03873", "title": "Biomechanics-Aware Trajectory Optimization for Online Navigation during Robotic Physiotherapy", "authors": ["Italo Belli", "Florian van Melis", "J. Micah Prendergast", "Ajay Seth", "Luka Peternel"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      15 pages, 9 figures, under review. Major changes: title, use of biomechanical model for online estimation of human muscle activation (leading to revision in abstract, methods, results, figures, discussion, and conclusion), broader review of related work", "url": "http://arxiv.org/abs/2411.03873v2", "summary": "Robotic devices provide a great opportunity to assist in delivering physical\ntherapy and rehabilitation movements, yet current robot-assisted methods\nstruggle to incorporate biomechanical metrics essential for safe and effective\ntherapy. We introduce BATON, a Biomechanics-Aware Trajectory Optimization\napproach to online robotic Navigation of human musculoskeletal loads for\nrotator cuff rehabilitation. BATON embeds a high-fidelity OpenSim model of the\nhuman shoulder into an optimal control framework, generating strain-minimizing\ntrajectories for real-time control of therapeutic movements. \\addedText{Its\ncore strength lies in the ability to adapt biomechanics-informed trajectories\nonline to unpredictable volitional human actions or reflexive reactions during\nphysical human-robot interaction based on robot-sensed motion and forces.\nBATON's adaptability is enabled by a real-time, model-based estimator that\ninfers changes in muscle activity via a rapid redundancy solver driven by robot\npose and force/torque sensor data. We validated BATON through physical\nhuman-robot interaction experiments, assessing response speed, motion\nsmoothness, and interaction forces.", "comment": "15 pages, 9 figures, under review. Major changes: title, use of\n  biomechanical model for online estimation of human muscle activation (leading\n  to revision in abstract, methods, results, figures, discussion, and\n  conclusion), broader review of related work", "pdf_url": "http://arxiv.org/pdf/2411.03873v2", "cate": "cs.RO", "date": "2024-11-06", "updated": "2025-07-11"}
{"id": "2507.08575", "title": "Large Multi-modal Model Cartographic Map Comprehension for Textual Locality Georeferencing", "authors": ["Kalana Wijegunarathna", "Kristin Stock", "Christopher B. Jones"], "categories": ["cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08575v1", "summary": "Millions of biological sample records collected in the last few centuries\narchived in natural history collections are un-georeferenced. Georeferencing\ncomplex locality descriptions associated with these collection samples is a\nhighly labour-intensive task collection agencies struggle with. None of the\nexisting automated methods exploit maps that are an essential tool for\ngeoreferencing complex relations. We present preliminary experiments and\nresults of a novel method that exploits multi-modal capabilities of recent\nLarge Multi-Modal Models (LMM). This method enables the model to visually\ncontextualize spatial relations it reads in the locality description. We use a\ngrid-based approach to adapt these auto-regressive models for this task in a\nzero-shot setting. Our experiments conducted on a small manually annotated\ndataset show impressive results for our approach ($\\sim$1 km Average distance\nerror) compared to uni-modal georeferencing with Large Language Models and\nexisting georeferencing tools. The paper also discusses the findings of the\nexperiments in light of an LMM's ability to comprehend fine-grained maps.\nMotivated by these results, a practical framework is proposed to integrate this\nmethod into a georeferencing workflow.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08575v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08154", "title": "Just Read the Question: Enabling Generalization to New Assessment Items with Text Awareness", "authors": ["Arisha Khan", "Nathaniel Li", "Tori Shen", "Anna N. Rafferty"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Poster paper at Educational Data Mining (EDM) 2025", "url": "http://arxiv.org/abs/2507.08154v1", "summary": "Machine learning has been proposed as a way to improve educational assessment\nby making fine-grained predictions about student performance and learning\nrelationships between items. One challenge with many machine learning\napproaches is incorporating new items, as these approaches rely heavily on\nhistorical data. We develop Text-LENS by extending the LENS partial variational\nauto-encoder for educational assessment to leverage item text embeddings, and\nexplore the impact on predictive performance and generalization to previously\nunseen items. We examine performance on two datasets: Eedi, a publicly\navailable dataset that includes item content, and LLM-Sim, a novel dataset with\ntest items produced by an LLM. We find that Text-LENS matches LENS' performance\non seen items and improves upon it in a variety of conditions involving unseen\nitems; it effectively learns student proficiency from and makes predictions\nabout student performance on new items.", "comment": "Poster paper at Educational Data Mining (EDM) 2025", "pdf_url": "http://arxiv.org/pdf/2507.08154v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08059", "title": "The relative importance of being Gaussian", "authors": ["F. Alberto Grünbaum", "Tondgi Xu"], "categories": ["cs.CV", "math.PR", "68T05, 68T45, 60J60, 82C22, 82C31"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08059v1", "summary": "The remarkable results for denoising in computer vision using diffusion\nmodels given in \\cite{SDWMG,HJA,HHG} yield a robust mathematical justification\nfor algorithms based on crucial properties of a sequence of Gaussian\nindependent $N(0,1)$ random variables. In particular the derivations use the\nfact that a Gaussian distribution is determined by its mean and variance and\nthat the sum of two Gaussians is another Gaussian.\n  \\bigskip\n  The issue raised in this short note is the following: suppose we use the\nalgorithm without any changes but replace the nature of the noise and use, for\ninstance, uniformly distributed noise or noise with a Beta distribution, or\nnoise which is a random superposition of two Gaussians with very different\nvariances. One could, of course, try to modify the algorithm keeping in mind\nthe nature of the noise, but this is not what we do. Instead we study the\nperformance of the algorithm when used with noise that is very far in nature\nfrom the Gaussian case, where it is designed to work well.\n  Usually these algorithms are implemented on very powerful computers. Our\nexperiments are all carried out on a small laptop and for the smallest possible\nimage size. Exploring how our observations are confirmed or changed when\ndealing in different situations remains an interesting challenge.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08059v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08624", "title": "Adaptive Framework for Ambient Intelligence in Rehabilitation Assistance", "authors": ["Gábor Baranyi", "Zsolt Csibi", "Kristian Fenech", "Áron Fóthi", "Zsófia Gaál", "Joul Skaf", "András Lőrincz"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      The paper has been submitted to a journal and waiting for review", "url": "http://arxiv.org/abs/2507.08624v1", "summary": "This paper introduces the Ambient Intelligence Rehabilitation Support (AIRS)\nframework, an advanced artificial intelligence-based solution tailored for home\nrehabilitation environments. AIRS integrates cutting-edge technologies,\nincluding Real-Time 3D Reconstruction (RT-3DR), intelligent navigation, and\nlarge Vision-Language Models (VLMs), to create a comprehensive system for\nmachine-guided physical rehabilitation. The general AIRS framework is\ndemonstrated in rehabilitation scenarios following total knee replacement\n(TKR), utilizing a database of 263 video recordings for evaluation. A\nsmartphone is employed within AIRS to perform RT-3DR of living spaces and has a\nbody-matched avatar to provide visual feedback about the excercise. This avatar\nis necessary in (a) optimizing exercise configurations, including camera\nplacement, patient positioning, and initial poses, and (b) addressing privacy\nconcerns and promoting compliance with the AI Act. The system guides users\nthrough the recording process to ensure the collection of properly recorded\nvideos. AIRS employs two feedback mechanisms: (i) visual 3D feedback, enabling\ndirect comparisons between prerecorded clinical exercises and patient home\nrecordings and (ii) VLM-generated feedback, providing detailed explanations and\ncorrections for exercise errors. The framework also supports people with visual\nand hearing impairments. It also features a modular design that can be adapted\nto broader rehabilitation contexts. AIRS software components are available for\nfurther use and customization.", "comment": "The paper has been submitted to a journal and waiting for review", "pdf_url": "http://arxiv.org/pdf/2507.08624v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08160", "title": "The Impact of Generative AI on Code Expertise Models: An Exploratory Study", "authors": ["Otávio Cury", "Guilherme Avelino"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08160v1", "summary": "Generative Artificial Intelligence (GenAI) tools for source code generation\nhave significantly boosted productivity in software development. However, they\nalso raise concerns, particularly the risk that developers may rely heavily on\nthese tools, reducing their understanding of the generated code. We hypothesize\nthat this loss of understanding may be reflected in source code knowledge\nmodels, which are used to identify developer expertise. In this work, we\npresent an exploratory analysis of how a knowledge model and a Truck Factor\nalgorithm built upon it can be affected by GenAI usage. To investigate this, we\ncollected statistical data on the integration of ChatGPT-generated code into\nGitHub projects and simulated various scenarios by adjusting the degree of\nGenAI contribution. Our findings reveal that most scenarios led to measurable\nimpacts, indicating the sensitivity of current expertise metrics. This suggests\nthat as GenAI becomes more integrated into development workflows, the\nreliability of such metrics may decrease.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08160v1", "cate": "cs.SE", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08169", "title": "Analysis of Propaganda in Tweets From Politically Biased Sources", "authors": ["Vivek Sharma", "Mohammad Mahdi Shokri", "Sarah Ita Levitan", "Elena Filatova", "Shweta Jain"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      The International FLAIRS Conference Proceedings, 38(1). this https URL", "url": "http://arxiv.org/abs/2507.08169v1", "summary": "News outlets are well known to have political associations, and many national\noutlets cultivate political biases to cater to different audiences. Journalists\nworking for these news outlets have a big impact on the stories they cover. In\nthis work, we present a methodology to analyze the role of journalists,\naffiliated with popular news outlets, in propagating their bias using some form\nof propaganda-like language. We introduce JMBX(Journalist Media Bias on X), a\nsystematically collected and annotated dataset of 1874 tweets from Twitter (now\nknown as X). These tweets are authored by popular journalists from 10 news\noutlets whose political biases range from extreme left to extreme right. We\nextract several insights from the data and conclude that journalists who are\naffiliated with outlets with extreme biases are more likely to use\npropaganda-like language in their writings compared to those who are affiliated\nwith outlets with mild political leans. We compare eight different Large\nLanguage Models (LLM) by OpenAI and Google. We find that LLMs generally\nperforms better when detecting propaganda in social media and news article\ncompared to BERT-based model which is fine-tuned for propaganda detection.\nWhile the performance improvements of using large language models (LLMs) are\nsignificant, they come at a notable monetary and environmental cost. This study\nprovides an analysis of both the financial costs, based on token usage, and the\nenvironmental impact, utilizing tools that estimate carbon emissions associated\nwith LLM operations.", "comment": "The International FLAIRS Conference Proceedings, 38(1).\n  https://doi.org/10.32473/flairs.38.1.138706", "pdf_url": "http://arxiv.org/pdf/2507.08169v1", "cate": "cs.SI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2411.05481", "title": "Relative Pose Estimation for Nonholonomic Robot Formation with UWB-IO Measurements (Extended version)", "authors": ["Kunrui Ze", "Wei Wang", "Shuoyu Yue", "Guibin Sun", "Kexin Liu", "Jinhu Lü"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      15 pages, 21 figures", "url": "http://arxiv.org/abs/2411.05481v3", "summary": "This article studies the problem of distributed formation control for\nmultiple robots by using onboard ultra wide band (UWB) distance and inertial\nodometer (IO) measurements.\n  Although this problem has been widely studied, a fundamental limitation of\nmost works is that they require each robot's pose and sensor measurements are\nexpressed in a common reference frame.\n  However, it is inapplicable for nonholonomic robot formations due to the\npractical difficulty of aligning IO measurements of individual robot in a\ncommon frame.\n  To address this problem, firstly, a concurrent-learning based estimator is\nfirstly proposed to achieve relative localization between neighboring robots in\na local frame.\n  Different from most relative localization methods in a global frame, both\nrelative position and orientation in a local frame are estimated with only UWB\nranging and IO\n  measurements.\n  Secondly, to deal with information loss caused by directed communication\ntopology, a cooperative localization algorithm is introduced to estimate the\nrelative pose to the leader robot.\n  Thirdly, based on the theoretical results on relative pose estimation, a\ndistributed formation tracking controller is proposed for nonholonomic robots.\n  Both 3D and 2D real-world experiments conducted on aerial robots and grounded\nrobots are provided to demonstrate the effectiveness of the proposed method.", "comment": "15 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2411.05481v3", "cate": "cs.RO", "date": "2024-11-08", "updated": "2025-07-11"}
{"id": "2507.08603", "title": "Unlocking Speech Instruction Data Potential with Query Rewriting", "authors": ["Yonghua Hei", "Yibo Yan", "Shuliang Liu", "Huiyu Zhou", "Linfeng Zhang", "Xuming Hu"], "categories": ["cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      ACL 2025 Findings", "url": "http://arxiv.org/abs/2507.08603v1", "summary": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong\npotential in response latency and speech comprehension capabilities, showcasing\ngeneral intelligence across speech understanding tasks. However, the ability to\nfollow speech instructions has not been fully realized due to the lack of\ndatasets and heavily biased training tasks. Leveraging the rich ASR datasets,\nprevious approaches have used Large Language Models~(\\textbf{LLMs}) to continue\nthe linguistic information of speech to construct speech instruction datasets.\nYet, due to the gap between LLM-generated results and real human responses, the\ncontinuation methods further amplify these shortcomings. Given the high costs\nof collecting and annotating speech instruction datasets by humans, using\nspeech synthesis to construct large-scale speech instruction datasets has\nbecome a balanced and robust alternative. Although modern\nText-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis\nquality, it is challenging to appropriately convert out-of-distribution text\ninstruction to speech due to the limitations of the training data distribution\nin TTS models. To address this issue, we propose a query rewriting framework\nwith multi-LLM knowledge fusion, employing multiple agents to annotate and\nvalidate the synthesized speech, making it possible to construct high-quality\nspeech instruction datasets without relying on human annotation. Experiments\nshow that this method can transform text instructions into distributions more\nsuitable for TTS models for speech synthesis through zero-shot rewriting,\nincreasing data usability from 72\\% to 93\\%. It also demonstrates unique\nadvantages in rewriting tasks that require complex knowledge and\ncontext-related abilities.", "comment": "ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.08603v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08175", "title": "Emotion Recognition in Older Adults with Quantum Machine Learning and Wearable Sensors", "authors": ["Md. Saif Hassan Onim", "Travis S. Humble", "Himanshu Thapliyal"], "categories": ["cs.LG", "cs.HC", "quant-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08175v1", "summary": "We investigate the feasibility of inferring emotional states exclusively from\nphysiological signals, thereby presenting a privacy-preserving alternative to\nconventional facial recognition techniques. We conduct a performance comparison\nof classical machine learning algorithms and hybrid quantum machine learning\n(QML) methods with a quantum kernel-based model. Our results indicate that the\nquantum-enhanced SVM surpasses classical counterparts in classification\nperformance across all emotion categories, even when trained on limited\ndatasets. The F1 scores over all classes are over 80% with around a maximum of\n36% improvement in the recall values. The integration of wearable sensor data\nwith quantum machine learning not only enhances accuracy and robustness but\nalso facilitates unobtrusive emotion recognition. This methodology holds\npromise for populations with impaired communication abilities, such as\nindividuals with Alzheimer's Disease and Related Dementias (ADRD) and veterans\nwith Post-Traumatic Stress Disorder (PTSD). The findings establish an early\nfoundation for passive emotional monitoring in clinical and assisted living\nconditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08175v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08096", "title": "An Object-Based Deep Learning Approach for Building Height Estimation from Single SAR Images", "authors": ["Babak Memar", "Luigi Russo", "Silvia Liberata Ullo", "Paolo Gamba"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08096v1", "summary": "Accurate estimation of building heights using very high resolution (VHR)\nsynthetic aperture radar (SAR) imagery is crucial for various urban\napplications. This paper introduces a Deep Learning (DL)-based methodology for\nautomated building height estimation from single VHR COSMO-SkyMed images: an\nobject-based regression approach based on bounding box detection followed by\nheight estimation. This model was trained and evaluated on a unique\nmulti-continental dataset comprising eight geographically diverse cities across\nEurope, North and South America, and Asia, employing a cross-validation\nstrategy to explicitly assess out-of-distribution (OOD) generalization. The\nresults demonstrate highly promising performance, particularly on European\ncities where the model achieves a Mean Absolute Error (MAE) of approximately\none building story (2.20 m in Munich), significantly outperforming recent\nstate-of-the-art methods in similar OOD scenarios. Despite the increased\nvariability observed when generalizing to cities in other continents,\nparticularly in Asia with its distinct urban typologies and prevalence of\nhigh-rise structures, this study underscores the significant potential of DL\nfor robust cross-city and cross-continental transfer learning in building\nheight estimation from single VHR SAR data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08096v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08659", "title": "Push or Light: Nudging Standing to Break Prolonged Sitting", "authors": ["Sohshi Yoshida", "Ko Watanabe", "Andreas Dengel", "Shoya Ishimaru", "Shingo Ata", "Manato Fujimoto"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08659v1", "summary": "Prolonged sitting is a health risk leading to metabolic and cardiovascular\ndiseases. To combat this, various \"nudging\" strategies encourage stand-ups.\nBehavior change triggers use explicit prompts such as smartphone push\nnotifications or light controls. However, comparisons of the effects of such\ninteractions, discomfort, and user context have not yet been performed. The\npresent study evaluated these methods in a mixed design experiment with 15\ncollege students. Three intervention methods (none, push notifications, and\nlight dimming) and three user task contexts (computer work, video calls, and\nreading) were tested. The frequency of standing up and comfort were assessed\nafter each ten-minute session. Results showed that dimming resulted in slightly\nmore breaks (1.4 \\pm 1.55) than push notification (1.2 \\pm 1.08), but caused\ndiscomfort for 66.7% of participants, compared to 20% for notification. The\nresults were influenced by task context. Dimming was most effective during\nvideo calls and reading, while push notifications were more effective during\ncomputer work. These findings suggest adaptive nudging systems should tailor\ninterventions based on context and individual preferences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08659v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08250", "title": "Leveraging Large Language Models for Classifying App Users' Feedback", "authors": ["Yasaman Abedini", "Abbas Heydarnoori"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08250v1", "summary": "In recent years, significant research has been conducted into classifying\napplication (app) user feedback, primarily relying on supervised machine\nlearning algorithms. However, fine-tuning more generalizable classifiers based\non existing labeled datasets remains an important challenge, as creating large\nand accurately labeled datasets often requires considerable time and resources.\nIn this paper, we evaluate the capabilities of four advanced LLMs, including\nGPT-3.5-Turbo, GPT-4, Flan-T5, and Llama3-70b, to enhance user feedback\nclassification and address the challenge of the limited labeled dataset. To\nachieve this, we conduct several experiments on eight datasets that have been\nmeticulously labeled in prior research. These datasets include user reviews\nfrom app stores, posts from the X platform, and discussions from the public\nforums, widely recognized as representative sources of app user feedback. We\nanalyze the performance of various LLMs in identifying both fine-grained and\ncoarse-grained user feedback categories. Given the substantial volume of daily\nuser feedback and the computational limitations of LLMs, we leverage these\nmodels as an annotation tool to augment labeled datasets with general and\napp-specific data. This augmentation aims to enhance the performance of\nstate-of-the-art BERT-based classification models. Our findings indicate that\nLLMs when guided by well-crafted prompts, can effectively classify user\nfeedback into coarse-grained categories. Moreover, augmenting the training\ndataset with datasets labeled using the consensus of LLMs can significantly\nenhance classifier performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08250v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08265", "title": "Addressing overlapping communities in multiple-source detection: An edge clustering approach for complex networks", "authors": ["Haomin Li", "Daniel K. Sewell"], "categories": ["cs.SI", "stat.CO"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08265v1", "summary": "The source detection problem in network analysis involves identifying the\norigins of diffusion processes, such as disease outbreaks or misinformation\npropagation. Traditional methods often focus on single sources, whereas\nreal-world scenarios frequently involve multiple sources, complicating\ndetection efforts. This study addresses the multiple-source detection (MSD)\nproblem by integrating edge clustering algorithms into the community-based\nlabel propagation framework, effectively handling mixed-membership issues where\nnodes belong to multiple communities.\n  The proposed approach applies the automated latent space edge clustering\nmodel to a network, partitioning infected networks into edge-based clusters to\nidentify multiple sources. Simulation studies on ADD HEALTH social network\ndatasets demonstrate that this method achieves superior accuracy, as measured\nby the F1-Measure, compared to state-of-the-art clustering algorithms. The\nresults highlight the robustness of edge clustering in accurately detecting\nsources, particularly in networks with complex and overlapping source regions.\nThis work advances the applicability of clustering-based methods to MSD\nproblems, offering improved accuracy and adaptability for real-world network\nanalyses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08265v1", "cate": "cs.SI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.02188", "title": "RPF-Search: Field-based Search for Robot Person Following in Unknown Dynamic Environments", "authors": ["Hanjing Ye", "Kuanqi Cai", "Yu Zhan", "Bingyi Xia", "Arash Ajoudani", "Hong Zhang"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE/ASME Transactions on Mechatronics. Project page: this https URL", "url": "http://arxiv.org/abs/2503.02188v2", "summary": "Autonomous robot person-following (RPF) systems are crucial for personal\nassistance and security but suffer from target loss due to occlusions in\ndynamic, unknown environments. Current methods rely on pre-built maps and\nassume static environments, limiting their effectiveness in real-world\nsettings. There is a critical gap in re-finding targets under topographic\n(e.g., walls, corners) and dynamic (e.g., moving pedestrians) occlusions. In\nthis paper, we propose a novel heuristic-guided search framework that\ndynamically builds environmental maps while following the target and explicitly\naddresses these two types of occlusions through distinct mechanisms. For\ntopographic occlusions, a belief-guided search field estimates the likelihood\nof the target's presence and guides search toward promising frontiers. For\ndynamic occlusions, an observation-based search strategy adaptively switches\nbetween a fluid-following field and an overtaking potential field based on\noccluder motion patterns. Our results demonstrate that the proposed method\noutperforms existing approaches in terms of search efficiency and success\nrates, both in simulations and real-world tests. Our target search method\nenhances the adaptability and reliability of RPF systems in unknown and dynamic\nenvironments, supporting their use in real-world applications.", "comment": "Accepted by IEEE/ASME Transactions on Mechatronics. Project page:\n  https://medlartea.github.io/rpf-search/", "pdf_url": "http://arxiv.org/pdf/2503.02188v2", "cate": "cs.RO", "date": "2025-03-04", "updated": "2025-07-11"}
{"id": "2507.08619", "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design", "authors": ["Soheyl Massoudi", "Mark Fuge"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      32 pages, 3 figures", "url": "http://arxiv.org/abs/2507.08619v1", "summary": "Early-stage engineering design involves complex, iterative reasoning, yet\nexisting large language model (LLM) workflows struggle to maintain task\ncontinuity and generate executable models. We evaluate whether a structured\nmulti-agent system (MAS) can more effectively manage requirements extraction,\nfunctional decomposition, and simulator code generation than a simpler\ntwo-agent system (2AS). The target application is a solar-powered water\nfiltration system as described in a cahier des charges. We introduce the\nDesign-State Graph (DSG), a JSON-serializable representation that bundles\nrequirements, physical embodiments, and Python-based physics models into graph\nnodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS\ncollapses the process to a Generator-Reflector loop. Both systems run a total\nof 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1\n70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON\nvalidity, requirement coverage, embodiment presence, code compatibility,\nworkflow completion, runtime, and graph size. Across all runs, both MAS and 2AS\nmaintained perfect JSON integrity and embodiment tagging. Requirement coverage\nremained minimal (less than 20\\%). Code compatibility peaked at 100\\% under\nspecific 2AS settings but averaged below 50\\% for MAS. Only the\nreasoning-distilled model reliably flagged workflow completion. Powered by\nDeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes)\nwhereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced\ndesign detail. Reasoning-distilled LLM improved completion rates, yet low\nrequirements and fidelity gaps in coding persisted.", "comment": "32 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.08619v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08182", "title": "CTRLS: Chain-of-Thought Reasoning via Latent State-Transition", "authors": ["Junda Wu", "Yuxin Xiong", "Xintong Li", "Zhengmian Hu", "Tong Yu", "Rui Wang", "Xiang Chen", "Jingbo Shang", "Julian McAuley"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.08182v1", "summary": "Chain-of-thought (CoT) reasoning enables large language models (LLMs) to\nbreak down complex problems into interpretable intermediate steps,\nsignificantly enhancing model transparency and performance in reasoning tasks.\nHowever, conventional CoT methods rely on heuristic sampling without structured\nmodeling of reasoning transitions, constraining their ability to systematically\nexplore and discover diverse and effective reasoning trajectories. In this\nwork, we introduce CTRLS, a framework that formulates CoT reasoning as a Markov\ndecision process (MDP) with latent state transitions, enabling principled and\nstate-aware exploration via distributional reinforcement learning. By modelling\nreasoning actions as explicit probability distributions in latent space, our\napproach explicitly models epistemic uncertainty, facilitating robust\nexploration of the reasoning space. As part of our framework, we introduce an\non-policy reinforcement learning strategy incorporating epsilon-greedy\nexploration and entropy-based regularization to iteratively refine latent state\ntransitions without requiring additional fine-tuning of the underlying LLM.\nTheoretical analyses provide evidence lower bounds (ELBO), theoretically\ngrounding our transition-aware modeling of latent reasoning dynamics. Further\nexperiments demonstrate improvements in reasoning accuracy, diversity, and\nexploration efficiency across benchmark reasoning tasks.", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.08182v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08136", "title": "RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration", "authors": ["Chong Cheng", "Yu Hu", "Sicheng Yu", "Beizhen Zhao", "Zijian Wang", "Hao Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.08136v1", "summary": "3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing\nscenes from unposed images. However, optimization-based 3DGS methods struggle\nwith sparse views due to limited prior knowledge. Meanwhile, feed-forward\nGaussian approaches are constrained by input formats, making it challenging to\nincorporate more input views. To address these challenges, we propose RegGS, a\n3D Gaussian registration-based framework for reconstructing unposed sparse\nviews. RegGS aligns local 3D Gaussians generated by a feed-forward network into\na globally consistent 3D Gaussian representation. Technically, we implement an\nentropy-regularized Sinkhorn algorithm to efficiently solve the optimal\ntransport Mixture 2-Wasserstein $(\\text{MW}_2)$ distance, which serves as an\nalignment metric for Gaussian mixture models (GMMs) in $\\mathrm{Sim}(3)$ space.\nFurthermore, we design a joint 3DGS registration module that integrates the\n$\\text{MW}_2$ distance, photometric consistency, and depth geometry. This\nenables a coarse-to-fine registration process while accurately estimating\ncamera poses and aligning the scene. Experiments on the RE10K and ACID datasets\ndemonstrate that RegGS effectively registers local Gaussians with high\nfidelity, achieving precise pose estimation and high-quality novel-view\nsynthesis. Project page: https://3dagentworld.github.io/reggs/.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.08136v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08675", "title": "LIMITER: A Gamified Interface for Harnessing Just Intonation Systems", "authors": ["Antonis Christou"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      6 pages, 11 figures, NIME, 2025", "url": "http://arxiv.org/abs/2507.08675v1", "summary": "This paper introduces LIMITER, a gamified digital musical instrument for\nharnessing and performing microtonal and justly intonated sounds. While\nmicrotonality in Western music remains a niche and esoteric system that can be\ndifficult both to conceptualize and to perform with, LIMITER presents a novel,\neasy to pickup interface that utilizes color, geometric transformations, and\ngame-like controls to create a simpler inlet into utilizing these sounds as a\nmeans of expression. We report on the background of the development of LIMITER,\nas well as explain the underlying musical and engineering systems that enable\nits function. Additionally, we offer a discussion and preliminary evaluation of\nthe creativity-enhancing effects of the interface.", "comment": "6 pages, 11 figures, NIME, 2025", "pdf_url": "http://arxiv.org/pdf/2507.08675v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08467", "title": "Computing Floating-Point Errors by Injecting Perturbations", "authors": ["Youshuai Tan", "Zhanwei Zhang", "Jinfu Chen", "Zishuo Ding", "Jifeng Xuan", "Weiyi Shang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2412.20804", "url": "http://arxiv.org/abs/2507.08467v1", "summary": "Floating-point programs form the foundation of modern science and\nengineering, providing the essential computational framework for a wide range\nof applications, such as safety-critical systems, aerospace engineering, and\nfinancial analysis. Floating-point errors can lead to severe consequences.\nAlthough floating-point errors widely exist, only a subset of inputs may\ntrigger significant errors in floating-point programs. Therefore, it is crucial\nto determine whether a given input could produce such errors. Researchers tend\nto take the results of high-precision floating-point programs as oracles for\ndetecting floating-point errors, which introduces two main limitations: (1)\ndifficulty of implementation and (2) prolonged execution time. The two recent\ntools, ATOMU and FPCC, can partially address these issues. However, ATOMU\nsuffers from false positives; while FPCC, though eliminating false positives,\noperates at a considerably slower speed.\n  To address these two challenges, we propose a novel approach named\nPI-detector to computing floating-point errors effectively and efficiently. Our\napproach is based on the observation that floating-point errors stem from large\ncondition numbers in atomic operations (such as addition and subtraction),\nwhich then propagate and accumulate. PI-detector injects small perturbations\ninto the operands of individual atomic operations within the program and\ncompares the outcomes of the original program with the perturbed version to\ncompute floating-point errors. We evaluate PI-detector with datasets from ATOMU\nand HSED, as well as a complex linear system-solving program. Experimental\nresults demonstrate that PI-detector can perform efficient and accurate\nfloating-point error computation.", "comment": "arXiv admin note: text overlap with arXiv:2412.20804", "pdf_url": "http://arxiv.org/pdf/2507.08467v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08328", "title": "Uncovering High-Order Cohesive Structures: Efficient (k,g)-Core Computation and Decomposition for Large Hypergraphs", "authors": ["Dahee Kim", "Hyewon Kim", "Song Kim", "Minseok Kim", "Junghoon Kim", "Yeon-Chang Lee", "Sungsu Lim"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      14 pages, 16 figures", "url": "http://arxiv.org/abs/2507.08328v1", "summary": "Hypergraphs, increasingly utilised to model complex and diverse relationships\nin modern networks, have gained significant attention for representing\nintricate higher-order interactions. Among various challenges, cohesive\nsubgraph discovery is one of the fundamental problems and offers deep insights\ninto these structures, yet the task of selecting appropriate parameters is an\nopen question. To address this question, we aim to design an efficient indexing\nstructure to retrieve cohesive subgraphs in an online manner. The main idea is\nto enable the discovery of corresponding structures within a reasonable time\nwithout the need for exhaustive graph traversals. Our method enables faster and\nmore effective retrieval of cohesive structures, which supports decision-making\nin applications that require online analysis of large-scale hypergraphs.\nThrough extensive experiments on real-world networks, we demonstrate the\nsuperiority of our proposed indexing technique.", "comment": "14 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.08328v1", "cate": "cs.SI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.06737", "title": "Balancing Progress and Safety: A Novel Risk-Aware Objective for RL in Autonomous Driving", "authors": ["Ahmed Abouelazm", "Jonas Michel", "Helen Gremmelmaier", "Tim Joseph", "Philip Schörner", "J. Marius Zöllner"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted in the 36th IEEE Intelligent vehicles Symposium (IV 2025)", "url": "http://arxiv.org/abs/2505.06737v2", "summary": "Reinforcement Learning (RL) is a promising approach for achieving autonomous\ndriving due to robust decision-making capabilities. RL learns a driving policy\nthrough trial and error in traffic scenarios, guided by a reward function that\ncombines the driving objectives. The design of such reward function has\nreceived insufficient attention, yielding ill-defined rewards with various\npitfalls. Safety, in particular, has long been regarded only as a penalty for\ncollisions. This leaves the risks associated with actions leading up to a\ncollision unaddressed, limiting the applicability of RL in real-world\nscenarios. To address these shortcomings, our work focuses on enhancing the\nreward formulation by defining a set of driving objectives and structuring them\nhierarchically. Furthermore, we discuss the formulation of these objectives in\na normalized manner to transparently determine their contribution to the\noverall reward. Additionally, we introduce a novel risk-aware objective for\nvarious driving interactions based on a two-dimensional ellipsoid function and\nan extension of Responsibility-Sensitive Safety (RSS) concepts. We evaluate the\nefficacy of our proposed reward in unsignalized intersection scenarios with\nvarying traffic densities. The approach decreases collision rates by 21\\% on\naverage compared to baseline rewards and consistently surpasses them in route\nprogress and cumulative reward, demonstrating its capability to promote safer\ndriving behaviors while maintaining high-performance levels.", "comment": "Accepted in the 36th IEEE Intelligent vehicles Symposium (IV 2025)", "pdf_url": "http://arxiv.org/pdf/2505.06737v2", "cate": "cs.RO", "date": "2025-05-10", "updated": "2025-07-11"}
{"id": "2507.08649", "title": "Leanabell-Prover-V2: Verifier-integrated Reasoning for Formal Theorem Proving via Reinforcement Learning", "authors": ["Xingguang Ji", "Yahui Liu", "Qi Wang", "Jingyuan Zhang", "Yang Yue", "Rui Shi", "Chenxi Sun", "Fuzheng Zhang", "Guorui Zhou", "Kun Gai"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      23 pages, 13 figures", "url": "http://arxiv.org/abs/2507.08649v1", "summary": "We introduce our Leanabell-Prover-V2, a 7B large language models (LLMs) that\ncan produce formal theorem proofs in Lean 4, with verifier-integrated Long\nChain-of-Thoughts (CoT). Following our previous work Leanabell-Prover-V1, we\ncontinual to choose to posttrain existing strong prover models for further\nperformance improvement. In our V2 version, we mainly upgrade the Reinforcement\nLearning (RL) with feedback provided by the Lean 4 verifier. Crucially,\nverifier feedback, such as indicating success or detailing specific errors,\nallows the LLM to become ``self-aware'' of the correctness of its own reasoning\nprocess and learn to reflexively correct errors. Leanabell-Prover-V2 directly\noptimizes LLM reasoning trajectories with multi-turn verifier interactions,\ntogether with feedback token masking for stable RL training and a simple reward\nstrategy. Experiments show that Leanabell-Prover-V2 improves performance by\n3.2% (pass@128) with Kimina-Prover-Preview-Distill-7B and 2.0% (pass@128) with\nDeepSeek-Prover-V2-7B on the MiniF2F test set. The source codes, curated data\nand models are available at:\nhttps://github.com/Leanabell-LM/Leanabell-Prover-V2.", "comment": "23 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.08649v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08212", "title": "EvA: Evolutionary Attacks on Graphs", "authors": ["Mohammad Sadegh Akhondzadeh", "Soroush H. Zargarbashi", "Jimin Cao", "Aleksandar Bojchevski"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      23 pages, 12 figures", "url": "http://arxiv.org/abs/2507.08212v1", "summary": "Even a slight perturbation in the graph structure can cause a significant\ndrop in the accuracy of graph neural networks (GNNs). Most existing attacks\nleverage gradient information to perturb edges. This relaxes the attack's\noptimization problem from a discrete to a continuous space, resulting in\nsolutions far from optimal. It also restricts the adaptability of the attack to\nnon-differentiable objectives. Instead, we introduce a few simple yet effective\nenhancements of an evolutionary-based algorithm to solve the discrete\noptimization problem directly. Our Evolutionary Attack (EvA) works with any\nblack-box model and objective, eliminating the need for a differentiable proxy\nloss. This allows us to design two novel attacks that reduce the effectiveness\nof robustness certificates and break conformal sets. The memory complexity of\nour attack is linear in the attack budget. Among our experiments, EvA shows\n$\\sim$11\\% additional drop in accuracy on average compared to the best previous\nattack, revealing significant untapped potential in designing attacks.", "comment": "23 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.08212v1", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08137", "title": "Temporally Consistent Amodal Completion for 3D Human-Object Interaction Reconstruction", "authors": ["Hyungjun Doh", "Dong In Lee", "Seunggeun Chi", "Pin-Hao Huang", "Kwonjoon Lee", "Sangpil Kim", "Karthik Ramani"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08137v1", "summary": "We introduce a novel framework for reconstructing dynamic human-object\ninteractions from monocular video that overcomes challenges associated with\nocclusions and temporal inconsistencies. Traditional 3D reconstruction methods\ntypically assume static objects or full visibility of dynamic subjects, leading\nto degraded performance when these assumptions are violated-particularly in\nscenarios where mutual occlusions occur. To address this, our framework\nleverages amodal completion to infer the complete structure of partially\nobscured regions. Unlike conventional approaches that operate on individual\nframes, our method integrates temporal context, enforcing coherence across\nvideo sequences to incrementally refine and stabilize reconstructions. This\ntemplate-free strategy adapts to varying conditions without relying on\npredefined models, significantly enhancing the recovery of intricate details in\ndynamic scenes. We validate our approach using 3D Gaussian Splatting on\nchallenging monocular videos, demonstrating superior precision in handling\nocclusions and maintaining temporal stability compared to existing techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08137v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08744", "title": "EqualMotion: Accessible Motion Capture for the Creative Industries", "authors": ["Clarice Hilton", "Kat Hawkins", "Phill Tew", "Freddie Collins", "Seb Madgwick", "Dominic Potts", "Tom Mitchell"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08744v1", "summary": "Motion capture technologies are increasingly used in creative and performance\ncontexts but often exclude disabled practitioners due to normative assumptions\nin body modeling, calibration, and avatar representation. EqualMotion\nintroduces a body-agnostic, wearable motion capture system designed through a\ndisability-centred co-design approach. By enabling personalised calibration,\nintegrating mobility aids, and adopting an inclusive visual language,\nEqualMotion supports diverse body types and movement styles. The system is\ndeveloped collaboratively with disabled researchers and creatives, aiming to\nfoster equitable participation in digital performance and prototyping. This\npaper outlines the system's design principles and highlights ongoing case\nstudies in dance and music to evaluate accessibility in real-world creative\nworkflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08744v1", "cate": "cs.HC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08523", "title": "InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching", "authors": ["Yilun Wang", "Pengfei Chen", "Haiyu Huang", "Zilong He", "Gou Tan", "Chuanfu Zhang", "Jingkai He", "Zibin Zheng"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08523v1", "summary": "Modern software systems generate massive volumes of runtime logs,\nnecessitating efficient and accurate log parsing to enable critical downstream\ntasks such as anomaly detection and root cause analysis. Recently, large\nlanguage models (LLMs) have achieved advanced accuracy on log parsing, but\ntheir deployment in production environments faces two major limitations: (1)\nthe privacy risks associated with commercial LLMs, driving the adoption of\nlocal deployment, and (2) the stringent latency and throughput requirements\nimposed by high-volume log streams, which existing LLM-based parsers fail to\nmeet. Although recent efforts have reduced the number of LLM queries, they\noverlook the high latency of the LLM invocations, where concurrent log parsing\nrequests can cause serve performance degradation of LLM inference system.\n  In this study, we present InferLog, the first LLM inference optimization\nmethod for online log parsing. Our key insight is that the inference efficiency\nemerges as the vital bottleneck in LLM-based online log parsing, rather than\nparsing accuracy. InferLog accelerates inference by designing (1) A\nPrefix-aware ICL Refinement policy to refine the examples and permutation of\nin-context learning to improve the prefix caching efficiency. (2) A rapid and\ntask-specific configuration tuning pipeline based on meta-learning to find the\noptimal LLM scheduling-related configuration for dynamic log parsing workloads.\nThe experimental results based on Loghub dataset and vLLM demonstrate that\nInferLog significantly outperforms existing inference optimization methods and\nmarkedly accelerates the state-of-the-art LLM-based log parser without\ncompromising parsing accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08523v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08363", "title": "Machine Learning for Evolutionary Graph Theory", "authors": ["Guoli Yang", "Matteo Cavaliere", "Mingtao Zhang", "Giovanni Masala", "Adam Miles", "Mengzhu Wang"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08363v1", "summary": "The stability of communities - whether biological, social, economic,\ntechnological or ecological depends on the balance between cooperation and\ncheating. While cooperation strengthens communities, selfish individuals, or\n\"cheaters,\" exploit collective benefits without contributing. If cheaters\nbecome too prevalent, they can trigger the collapse of cooperation and of the\ncommunity, often in an abrupt manner. A key challenge is determining whether\nthe risk of such a collapse can be detected in advance. To address this, we use\na combination of evolutionary graph theory and machine learning to examine how\none can predict the unravel of cooperation on complex networks. By introducing\nfew cheaters into a structured population, we employ machine learning to detect\nand anticipate the spreading of cheaters and cooperation collapse. Using\ntemporal and structural data, the presented results show that prediction\naccuracy improves with stronger selection strength and larger observation\nwindows, with CNN-Seq-LSTM and Seq-LSTM best performing models. Moreover, the\naccuracy for the predictions depends crucially on the type of game played\nbetween cooperators and cheaters (i.e., accuracy improves when it is more\nadvantageous to defect) and on the community structure. Overall, this work\nintroduces a machine learning approach into detecting abrupt shifts in\nevolutionary graph theory and offer potential strategies for anticipating and\npreventing cooperation collapse in complex social networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08363v1", "cate": "cs.SI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.06740", "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving", "authors": ["Ahmed Abouelazm", "Mianzhi Liu", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "url": "http://arxiv.org/abs/2505.06740v2", "summary": "Accurate prediction of surrounding road users' trajectories is essential for\nsafe and efficient autonomous driving. While deep learning models have improved\nperformance, challenges remain in preventing off-road predictions and ensuring\nkinematic feasibility. Existing methods incorporate road-awareness modules and\nenforce kinematic constraints but lack plausibility guarantees and often\nintroduce trade-offs in complexity and flexibility. This paper proposes a novel\nframework that formulates trajectory prediction as a constrained regression\nguided by permissible driving directions and their boundaries. Using the\nagent's current state and an HD map, our approach defines the valid boundaries\nand ensures on-road predictions by training the network to learn superimposed\npaths between left and right boundary polylines. To guarantee feasibility, the\nmodel predicts acceleration profiles that determine the vehicle's travel\ndistance along these paths while adhering to kinematic constraints. We evaluate\nour approach on the Argoverse-2 dataset against the HPTR baseline. Our approach\nshows a slight decrease in benchmark metrics compared to HPTR but notably\nimproves final displacement error and eliminates infeasible trajectories.\nMoreover, the proposed approach has superior generalization to less prevalent\nmaneuvers and unseen out-of-distribution scenarios, reducing the off-road rate\nunder adversarial attacks from 66% to just 1%. These results highlight the\neffectiveness of our approach in generating feasible and robust predictions.", "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "pdf_url": "http://arxiv.org/pdf/2505.06740v2", "cate": "cs.RO", "date": "2025-05-10", "updated": "2025-07-11"}
{"id": "2507.08664", "title": "Introspection of Thought Helps AI Agents", "authors": ["Haoran Sun", "Shaoning Zeng"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08664v1", "summary": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to\nperform interpretation and inference in text and image tasks without\npost-training, where LLMs and MLLMs play the most critical role and determine\nthe initial ability and limitations of AI Agents. Usually, AI Agents utilize\nsophisticated prompt engineering and external reasoning framework to obtain a\npromising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought\nand Image-of-Thought. However, they are still constrained by the inherent\nlimitations of LLM in understanding natural language, and the iterative\nreasoning process will generate a large amount of inference cost. To this end,\nwe propose a novel AI Agent Reasoning Framework with Introspection of Thought\n(INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute\nprogrammatic dialogue reasoning processes following the code in prompt.\nTherefore, self-denial and reflection occur within LLM instead of outside LLM,\nwhich can reduce token cost effectively. Through our experiments on six\nbenchmarks for three different tasks, the effectiveness of INoT is verified,\nwith an average improvement of 7.95\\% in performance, exceeding the baselines.\nFurthermore, the token cost of INoT is lower on average than the best\nperforming method at baseline by 58.3\\%. In addition, we demonstrate the\nversatility of INoT in image interpretation and inference through verification\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08664v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08235", "title": "InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems", "authors": ["Pinaki Prasad Guha Neogi", "Ahmad Mohammadshirazi", "Rajiv Ramnath"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08235v1", "summary": "Smart buildings generate vast streams of sensor and control data, but\nfacility managers often lack clear explanations for anomalous energy usage. We\npropose InsightBuild, a two-stage framework that integrates causality analysis\nwith a fine-tuned large language model (LLM) to provide human-readable, causal\nexplanations of energy consumption patterns. First, a lightweight causal\ninference module applies Granger causality tests and structural causal\ndiscovery on building telemetry (e.g., temperature, HVAC settings, occupancy)\ndrawn from Google Smart Buildings and Berkeley Office datasets. Next, an LLM,\nfine-tuned on aligned pairs of sensor-level causes and textual explanations,\nreceives as input the detected causal relations and generates concise,\nactionable explanations. We evaluate InsightBuild on two real-world datasets\n(Google: 2017-2022; Berkeley: 2018-2020), using expert-annotated ground-truth\ncauses for a held-out set of anomalies. Our results demonstrate that combining\nexplicit causal discovery with LLM-based natural language generation yields\nclear, precise explanations that assist facility managers in diagnosing and\nmitigating energy inefficiencies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08235v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08205", "title": "HNOSeg-XS: Extremely Small Hartley Neural Operator for Efficient and Resolution-Robust 3D Image Segmentation", "authors": ["Ken C. L. Wong", "Hongzhi Wang", "Tanveer Syeda-Mahmood"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper was accepted by IEEE TMI 2025", "url": "http://arxiv.org/abs/2507.08205v1", "summary": "In medical image segmentation, convolutional neural networks (CNNs) and\ntransformers are dominant. For CNNs, given the local receptive fields of\nconvolutional layers, long-range spatial correlations are captured through\nconsecutive convolutions and pooling. However, as the computational cost and\nmemory footprint can be prohibitively large, 3D models can only afford fewer\nlayers than 2D models with reduced receptive fields and abstract levels. For\ntransformers, although long-range correlations can be captured by multi-head\nattention, its quadratic complexity with respect to input size is\ncomputationally demanding. Therefore, either model may require input size\nreduction to allow more filters and layers for better segmentation.\nNevertheless, given their discrete nature, models trained with patch-wise\ntraining or image downsampling may produce suboptimal results when applied on\nhigher resolutions. To address this issue, here we propose the\nresolution-robust HNOSeg-XS architecture. We model image segmentation by\nlearnable partial differential equations through the Fourier neural operator\nwhich has the zero-shot super-resolution property. By replacing the Fourier\ntransform by the Hartley transform and reformulating the problem in the\nfrequency domain, we created the HNOSeg-XS model, which is resolution robust,\nfast, memory efficient, and extremely parameter efficient. When tested on the\nBraTS'23, KiTS'23, and MVSeg'23 datasets with a Tesla V100 GPU, HNOSeg-XS\nshowed its superior resolution robustness with fewer than 34.7k model\nparameters. It also achieved the overall best inference time (< 0.24 s) and\nmemory efficiency (< 1.8 GiB) compared to the tested CNN and transformer\nmodels.", "comment": "This paper was accepted by IEEE TMI 2025", "pdf_url": "http://arxiv.org/pdf/2507.08205v1", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08030", "title": "A Systematic Analysis of Declining Medical Safety Messaging in Generative AI Models", "authors": ["Sonali Sharma", "Ahmed M. Alaa", "Roxana Daneshjou"], "categories": ["cs.CL", "cs.CE", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures", "url": "http://arxiv.org/abs/2507.08030v1", "summary": "Generative AI models, including large language models (LLMs) and\nvision-language models (VLMs), are increasingly used to interpret medical\nimages and answer clinical questions. Their responses often include\ninaccuracies; therefore, safety measures like medical disclaimers are critical\nto remind users that AI outputs are not professionally vetted or a substitute\nfor medical advice. This study evaluated the presence of disclaimers in LLM and\nVLM outputs across model generations from 2022 to 2025. Using 500 mammograms,\n500 chest X-rays, 500 dermatology images, and 500 medical questions, outputs\nwere screened for disclaimer phrases. Medical disclaimer presence in LLM and\nVLM outputs dropped from 26.3% in 2022 to 0.97% in 2025, and from 19.6% in 2023\nto 1.05% in 2025, respectively. By 2025, the majority of models displayed no\ndisclaimers. As public models become more capable and authoritative,\ndisclaimers must be implemented as a safeguard adapting to the clinical context\nof each output.", "comment": "11 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.08030v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08594", "title": "Generating Proto-Personas through Prompt Engineering: A Case Study on Efficiency, Effectiveness and Empathy", "authors": ["Fernando Ayach", "Vitor Lameirão", "Raul Leão", "Jerfferson Felizardo", "Rafael Sobrinho", "Vanessa Borges", "Patrícia Matsubara", "Awdren Fontão"], "categories": ["cs.SE", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages; 2 figures; Preprint with the original submission accepted for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "url": "http://arxiv.org/abs/2507.08594v1", "summary": "Proto-personas are commonly used during early-stage Product Discovery, such\nas Lean Inception, to guide product definition and stakeholder alignment.\nHowever, the manual creation of proto-personas is often time-consuming,\ncognitively demanding, and prone to bias. In this paper, we propose and\nempirically investigate a prompt engineering-based approach to generate\nproto-personas with the support of Generative AI (GenAI). Our goal is to\nevaluate the approach in terms of efficiency, effectiveness, user acceptance,\nand the empathy elicited by the generated personas. We conducted a case study\nwith 19 participants embedded in a real Lean Inception, employing a qualitative\nand quantitative methods design. The results reveal the approach's efficiency\nby reducing time and effort and improving the quality and reusability of\npersonas in later discovery phases, such as Minimum Viable Product (MVP)\nscoping and feature refinement. While acceptance was generally high, especially\nregarding perceived usefulness and ease of use, participants noted limitations\nrelated to generalization and domain specificity. Furthermore, although\ncognitive empathy was strongly supported, affective and behavioral empathy\nvaried significantly across participants. These results contribute novel\nempirical evidence on how GenAI can be effectively integrated into software\nProduct Discovery practices, while also identifying key challenges to be\naddressed in future iterations of such hybrid design processes.", "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "pdf_url": "http://arxiv.org/pdf/2507.08594v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08110", "title": "AI Feedback Enhances Community-Based Content Moderation through Engagement with Counterarguments", "authors": ["Saeedeh Mohammadi", "Taha Yasseri"], "categories": ["cs.CY", "cs.SI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08110v1", "summary": "Today, social media platforms are significant sources of news and political\ncommunication, but their role in spreading misinformation has raised\nsignificant concerns. In response, these platforms have implemented various\ncontent moderation strategies. One such method, Community Notes on X, relies on\ncrowdsourced fact-checking and has gained traction, though it faces challenges\nsuch as partisan bias and delays in verification. This study explores an\nAI-assisted hybrid moderation framework in which participants receive\nAI-generated feedback -supportive, neutral, or argumentative -on their notes\nand are asked to revise them accordingly. The results show that incorporating\nfeedback improves the quality of notes, with the most substantial gains\nresulting from argumentative feedback. This underscores the value of diverse\nperspectives and direct engagement in human-AI collective intelligence. The\nresearch contributes to ongoing discussions about AI's role in political\ncontent moderation, highlighting the potential of generative AI and the\nimportance of informed design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08110v1", "cate": "cs.CY", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2505.06743", "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "authors": ["Marius Baden", "Ahmed Abouelazm", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025) for oral presentation. Winner of the best paper award", "url": "http://arxiv.org/abs/2505.06743v2", "summary": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to\nnavigate safely by anticipating the movements of surrounding road users.\nHowever, current deep learning models often lack trustworthiness as their\npredictions can be physically infeasible and illogical to humans. To make\npredictions more trustworthy, recent research has incorporated prior knowledge,\nlike the social force model for modeling interactions and kinematic models for\nphysical realism. However, these approaches focus on priors that suit either\nvehicles or pedestrians and do not generalize to traffic with mixed agent\nclasses. We propose incorporating interaction and kinematic priors of all agent\nclasses--vehicles, pedestrians, and cyclists with class-specific interaction\nlayers to capture agent behavioral differences. To improve the interpretability\nof the agent interactions, we introduce DG-SFM, a rule-based interaction\nimportance score that guides the interaction layer. To ensure physically\nfeasible predictions, we proposed suitable kinematic models for all agent\nclasses with a novel pedestrian kinematic model. We benchmark our approach on\nthe Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our\nbaseline. Experiments demonstrate that our method improves interaction\ninterpretability, revealing a correlation between incorrect predictions and\ndivergence from our interaction prior. Even though incorporating the kinematic\nmodels causes a slight decrease in accuracy, they eliminate infeasible\ntrajectories found in the dataset and the baseline model. Thus, our approach\nfosters trust in trajectory prediction as its interaction reasoning is\ninterpretable, and its predictions adhere to physics.", "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)\n  for oral presentation. Winner of the best paper award", "pdf_url": "http://arxiv.org/pdf/2505.06743v2", "cate": "cs.RO", "date": "2025-05-10", "updated": "2025-07-11"}
{"id": "2507.08705", "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings", "authors": ["Philip Osborne", "Danilo S. Carvalho", "André Freitas"], "categories": ["cs.AI", "I.2.5; I.2.1; I.2.7; I.2.11"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP 2025 Call for System Demonstrations", "url": "http://arxiv.org/abs/2507.08705v1", "summary": "We present elsciRL, an open-source Python library to facilitate the\napplication of language solutions on reinforcement learning problems. We\ndemonstrate the potential of our software by extending the Language Adapter\nwith Self-Completing Instruction framework defined in (Osborne, 2024) with the\nuse of LLMs. Our approach can be re-applied to new applications with minimal\nsetup requirements. We provide a novel GUI that allows a user to provide text\ninput for an LLM to generate instructions which it can then self-complete.\nEmpirical results indicate that these instructions \\textit{can} improve a\nreinforcement learning agent's performance. Therefore, we present this work to\naccelerate the evaluation of language solutions on reward based environments to\nenable new opportunities for scientific discovery.", "comment": "6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP\n  2025 Call for System Demonstrations", "pdf_url": "http://arxiv.org/pdf/2507.08705v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08238", "title": "Self-Supervised Learning-Based Multimodal Prediction on Prosocial Behavior Intentions", "authors": ["Abinay Reddy Naini", "Zhaobo K. Zheng", "Teruhisa Misu", "Kumar Akash"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, published at ICASSP 2025", "url": "http://arxiv.org/abs/2507.08238v1", "summary": "Human state detection and behavior prediction have seen significant\nadvancements with the rise of machine learning and multimodal sensing\ntechnologies. However, predicting prosocial behavior intentions in mobility\nscenarios, such as helping others on the road, is an underexplored area.\nCurrent research faces a major limitation. There are no large, labeled datasets\navailable for prosocial behavior, and small-scale datasets make it difficult to\ntrain deep-learning models effectively. To overcome this, we propose a\nself-supervised learning approach that harnesses multi-modal data from existing\nphysiological and behavioral datasets. By pre-training our model on diverse\ntasks and fine-tuning it with a smaller, manually labeled prosocial behavior\ndataset, we significantly enhance its performance. This method addresses the\ndata scarcity issue, providing a more effective benchmark for prosocial\nbehavior prediction, and offering valuable insights for improving intelligent\nvehicle systems and human-machine interaction.", "comment": "5 pages, 4 figures, published at ICASSP 2025", "pdf_url": "http://arxiv.org/pdf/2507.08238v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08223", "title": "SurfDist: Interpretable Three-Dimensional Instance Segmentation Using Curved Surface Patches", "authors": ["Jackson Borchardt", "Saul Kato"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.08223v1", "summary": "We present SurfDist, a convolutional neural network architecture for\nthree-dimensional volumetric instance segmentation. SurfDist enables prediction\nof instances represented as closed surfaces composed of smooth parametric\nsurface patches, specifically bicubic B\\'ezier triangles. SurfDist is a\nmodification of the popular model architecture StarDist-3D which breaks\nStarDist-3D's coupling of instance parameterization dimension and instance\nvoxel resolution, and it produces predictions which may be upsampled to\narbitrarily high resolutions without introduction of voxelization artifacts.\n  For datasets with blob-shaped instances, common in biomedical imaging,\nSurfDist can outperform StarDist-3D with more compact instance\nparameterizations. We detail SurfDist's technical implementation and show one\nsynthetic and one real-world dataset for which it outperforms StarDist-3D.\nThese results demonstrate that interpretable instance surface models can be\nlearned effectively alongside instance membership.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.08223v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08800", "title": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": ["Luke Rivard", "Sun Sun", "Hongyu Guo", "Wenhu Chen", "Yuntian Deng"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08800v1", "summary": "We introduce NeuralOS, a neural framework that simulates graphical user\ninterfaces (GUIs) of operating systems by directly predicting screen frames in\nresponse to user inputs such as mouse movements, clicks, and keyboard events.\nNeuralOS combines a recurrent neural network (RNN), which tracks computer\nstate, with a diffusion-based neural renderer that generates screen images. The\nmodel is trained on a large-scale dataset of Ubuntu XFCE recordings, which\ninclude both randomly generated interactions and realistic interactions\nproduced by AI agents. Experiments show that NeuralOS successfully renders\nrealistic GUI sequences, accurately captures mouse interactions, and reliably\npredicts state transitions like application launches. Although modeling\nfine-grained keyboard interactions precisely remains challenging, NeuralOS\noffers a step toward creating fully adaptive, generative neural interfaces for\nfuture human-computer interaction systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08800v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08627", "title": "NL in the Middle: Code Translation with LLMs and Intermediate Representations", "authors": ["Chi-en Amy Tai", "Pengyu Nie", "Lukasz Golab", "Alexander Wong"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08627v1", "summary": "Studies show that large language models (LLMs) produce buggy code\ntranslations. One avenue to improve translation accuracy is through\nintermediate representations, which could provide structured insights to guide\nthe model's understanding. We explore whether code translation using LLMs can\nbenefit from intermediate representations via natural language (NL) and\nabstract syntax trees (ASTs). Since prompt engineering greatly affects LLM\nperformance, we consider several ways to integrate these representations, from\none-shot to chain-of-thought (CoT) prompting. Using Open Gpt4 8X7B and\nspecialized StarCoder and CodeGen models on popular code translation benchmarks\n(CodeNet and AVATAR), we find that CoT with an intermediate NL summary performs\nbest, with an increase of 13.8% and 6.7%, respectively, in successful\ntranslations for the best-performing model (Open Gpt4 8X7B) compared to the\nzero-shot prompt.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08627v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2301.07791", "title": "Temporal Motifs for Financial Networks: A Study on Mercari, JPMC, and Venmo Platforms", "authors": ["Penghang Liu", "Bahadir Altun", "Rupam Acharyya", "Robert E. Tillman", "Shunya Kimura", "Naoki Masuda", "Ahmet Erdem Sarıyüce"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      To appear at ASONAM 2025", "url": "http://arxiv.org/abs/2301.07791v2", "summary": "Understanding the dynamics of financial transactions among people is critical\nfor various applications such as fraud detection. One important aspect of\nfinancial transaction networks is temporality. The order and repetition of\ntransactions can offer new insights when considered within the graph structure.\nTemporal motifs, defined as a set of nodes that interact with each other in a\nshort time period, are a promising tool in this context. In this work, we study\nthree unique temporal financial networks: transactions in Mercari, an online\nmarketplace, payments in a synthetic network generated by J.P. Morgan Chase,\nand payments and friendships among Venmo users. We consider the fraud detection\nproblem on the Mercari and J.P. Morgan Chase networks, for which the ground\ntruth is available. We show that temporal motifs offer superior performance to\nseveral baselines, including a previous method that considers simple graph\nfeatures and two node embedding techniques (LINE and node2vec), while being\npractical in terms of runtime performance. For the Venmo network, we\ninvestigate the interplay between financial and social relations on three\ntasks: friendship prediction, vendor identification, and analysis of temporal\ncycles. For friendship prediction, temporal motifs yield better results than\ngeneral heuristics, such as Jaccard and Adamic-Adar measures. We are also able\nto identify vendors with high accuracy and observe interesting patterns in rare\nmotifs, such as temporal cycles. We believe that the analysis, datasets, and\nlessons from this work will be beneficial for future research on financial\ntransaction networks.", "comment": "To appear at ASONAM 2025", "pdf_url": "http://arxiv.org/pdf/2301.07791v2", "cate": "cs.SI", "date": "2023-01-18", "updated": "2025-07-11"}
{"id": "2507.08119", "title": "Photonic Rails in ML Datacenters", "authors": ["Eric Ding", "Chuhan Ouyang", "Rachee Singh"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08119v1", "summary": "Rail-optimized network fabrics have become the de facto datacenter scale-out\nfabric for large-scale ML training. However, the use of high-radix electrical\nswitches to provide all-to-all connectivity in rails imposes massive power,\ncost, and complexity overheads. We propose a rethinking of the rail abstraction\nby retaining its communication semantics, but realizing it using optical\ncircuit switches. The key challenge is that optical switches support only\none-to-one connectivity at a time, limiting the fan-out of traffic in ML\nworkloads using hybrid parallelisms. We introduce parallelism-driven rail\nreconfiguration as a solution that leverages the sequential ordering between\ntraffic from different parallelisms. We design a control plane, Opus, to enable\ntime-multiplexed emulation of electrical rail switches using optical switches.\nMore broadly, our work discusses a new research agenda: datacenter fabrics that\nco-evolve with the model parallelism dimensions within each job, as opposed to\nthe prevailing mindset of reconfiguring networks before a job begins.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08119v1", "cate": "cs.NI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2505.08264", "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning", "authors": ["Ahmed Abouelazm", "Tim Weinstein", "Tim Joseph", "Philip Schörner", "J. Marius Zöllner"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "url": "http://arxiv.org/abs/2505.08264v2", "summary": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9% in low traffic density, +21% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.", "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "pdf_url": "http://arxiv.org/pdf/2505.08264v2", "cate": "cs.RO", "date": "2025-05-13", "updated": "2025-07-11"}
{"id": "2507.08715", "title": "System-of-systems Modeling and Optimization: An Integrated Framework for Intermodal Mobility", "authors": ["Paul Saves", "Jasper Bussemaker", "Rémi Lafage", "Thierry Lefebvre", "Nathalie Bartoli", "Youssef Diouane", "Joseph Morlier"], "categories": ["cs.AI", "cs.SY", "eess.SY", "math.OC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08715v1", "summary": "For developing innovative systems architectures, modeling and optimization\ntechniques have been central to frame the architecting process and define the\noptimization and modeling problems. In this context, for system-of-systems the\nuse of efficient dedicated approaches (often physics-based simulations) is\nhighly recommended to reduce the computational complexity of the targeted\napplications. However, exploring novel architectures using such dedicated\napproaches might pose challenges for optimization algorithms, including\nincreased evaluation costs and potential failures. To address these challenges,\nsurrogate-based optimization algorithms, such as Bayesian optimization\nutilizing Gaussian process models have emerged.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08715v1", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08239", "title": "Data Generation without Function Estimation", "authors": ["Hadi Daneshmand", "Ashkan Soleymani"], "categories": ["cs.LG", "math-ph", "math.MP", "math.OC", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08239v1", "summary": "Estimating the score function (or other population-density-dependent\nfunctions) is a fundamental component of most generative models. However, such\nfunction estimation is computationally and statistically challenging. Can we\navoid function estimation for data generation? We propose an estimation-free\ngenerative method: A set of points whose locations are deterministically\nupdated with (inverse) gradient descent can transport a uniform distribution to\narbitrary data distribution, in the mean field regime, without function\nestimation, training neural networks, and even noise injection. The proposed\nmethod is built upon recent advances in the physics of interacting particles.\nWe show, both theoretically and experimentally, that these advances can be\nleveraged to develop novel generative methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08239v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08240", "title": "Car Object Counting and Position Estimation via Extension of the CLIP-EBC Framework", "authors": ["Seoik Jung", "Taekyung Song"], "categories": ["cs.CV", "I.4.8; I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      4 pages, 2 figures, submitted to a computer vision conference", "url": "http://arxiv.org/abs/2507.08240v1", "summary": "In this paper, we investigate the applicability of the CLIP-EBC framework,\noriginally designed for crowd counting, to car object counting using the CARPK\ndataset. Experimental results show that our model achieves second-best\nperformance compared to existing methods. In addition, we propose a K-means\nweighted clustering method to estimate object positions based on predicted\ndensity maps, indicating the framework's potential extension to localization\ntasks.", "comment": "4 pages, 2 figures, submitted to a computer vision conference", "pdf_url": "http://arxiv.org/pdf/2507.08240v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.15488", "title": "Human-AI Collaboration for Wearable Technology Component Standardization", "authors": ["Andrew M. Lydner"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.15488v2", "summary": "Due to the multidisciplinary nature of wearable technology, the industry\nfaces potential limitations in innovation. The wearable technology industry is\nstill in its infancy and increased applicable use faces stagnation despite the\nplethora of technologies that have been largely wrist worn. This could be a\nresult of the lack of multidisciplinary expert knowledge disseminating through\nthe industry. Unlike other technologies which have standardizations and\nprocesses for how they are developed, wearable technologies exist in a realm of\nperpetual change as given the various materials and subcomponents that continue\nto be developed. It is essential that expert opinions form a collaborative\nfoundation, and even more so that intelligent systems foster that\ncollaboration. The caveat though, is likeliness of these artificial\nintelligence (AI) collaboration tools to be utilized by industry experts.\nMental model development for AI tool usage could be applied to wearable\ntechnology innovation in this regard, thus the goal of this paper and focus of\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.15488v2", "cate": "cs.HC", "date": "2024-12-27", "updated": "2025-07-10"}
{"id": "2507.08671", "title": "LLMCup: Ranking-Enhanced Comment Updating with LLMs", "authors": ["Hua Ge", "Juan Zhai", "Minxue Pan", "Fusen He", "Ziyue Tan"], "categories": ["cs.SE", "D.2.3; D.2.7; I.2.6"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      13 pages, 10 figures", "url": "http://arxiv.org/abs/2507.08671v1", "summary": "While comments are essential for enhancing code readability and\nmaintainability in modern software projects, developers are often motivated to\nupdate code but not comments, leading to outdated or inconsistent documentation\nthat hinders future understanding and maintenance. Recent approaches such as\nCUP and HebCup have attempted automatic comment updating using neural\nsequence-to-sequence models and heuristic rules, respectively. However, these\nmethods can miss or misinterpret crucial information during comment updating,\nresulting in inaccurate comments, and they often struggle with complex update\nscenarios. Given these challenges, a promising direction lies in leveraging\nlarge language models (LLMs), which have shown impressive performance in\nsoftware engineering tasks such as comment generation, code synthesis, and\nprogram repair. This suggests their strong potential to capture the logic\nbehind code modifications - an ability that is crucial for the task of comment\nupdating. Nevertheless, selecting an appropriate prompt strategy for an LLM on\neach update case remains challenging. To address this, we propose a novel\ncomment updating framework, LLMCup, which first uses multiple prompt strategies\nto provide diverse candidate updated comments via an LLM, and then employs a\nranking model, CupRank, to select the best candidate as final updated comment.\nExperimental results demonstrate the effectiveness of LLMCup, with improvements\nover state-of-the-art baselines (CUP and HebCup) by 49.0%-116.9% in Accuracy,\n10.8%-20% in BLEU-4, 4.6% in METEOR, 0.9%-1.9% in F1, and 2.1%-3.4% in\nSentenceBert similarity. Furthermore, a user study shows that comments updated\nby LLMCup sometimes surpass human-written updates, highlighting the importance\nof incorporating human evaluation in comment quality assessment.", "comment": "13 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.08671v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2402.10242", "title": "Signed Diverse Multiplex Networks: Clustering and Inference", "authors": ["Marianna Pensky"], "categories": ["cs.SI", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      5 figures", "url": "http://arxiv.org/abs/2402.10242v3", "summary": "The paper introduces a Signed Generalized Random Dot Product Graph (SGRDPG)\nmodel, which is a variant of the Generalized Random Dot Product Graph (GRDPG),\nwhere, in addition, edges can be positive or negative. The setting is extended\nto a multiplex version, where all layers have the same collection of nodes and\nfollow the SGRDPG. The only common feature of the layers of the network is that\nthey can be partitioned into groups with common subspace structures, while\notherwise matrices of connection probabilities can be all different. The\nsetting above is extremely flexible and includes a variety of existing\nmultiplex network models, including GRDPG, as its particular cases.\n  By employing novel methodologies, our paper ensures strongly consistent\nclustering of layers and highly accurate subspace estimation, which are\nsignificant improvements over the results of Pensky and Wang (2024). All\nalgorithms and theoretical results in the paper remain true for both signed and\nbinary networks. In addition, the paper shows that keeping signs of the edges\nin the process of network construction leads to a better precision of\nestimation and clustering and, hence, is beneficial for tackling real world\nproblems such as, for example, analysis of brain networks.", "comment": "5 figures", "pdf_url": "http://arxiv.org/pdf/2402.10242v3", "cate": "cs.SI", "date": "2024-02-14", "updated": "2025-07-10"}
{"id": "2507.08134", "title": "Rattan: An Extensible and Scalable Modular Internet Path Emulator", "authors": ["Minhu Wang", "Yixin Shen", "Bo Wang", "Haixuan Tong", "Yutong Xie", "Yixuan Gao", "Yan Liu", "Li Chen", "Mingwei Xu", "Jianping Wu"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08134v1", "summary": "The rapid growth of Internet paths in heterogeneity, scale, and dynamics has\nmade existing emulators increasingly insufficient in flexibility, scalability,\nand usability. To address these limitations, we present Rattan, an extensible\nand scalable software network path emulator for modern Internet conditions.\nRattan's core innovation lies in its cell-based architecture: by splitting\nemulation functions into modular \"cells\" with well-documented asynchronous\ninterfaces, users are allowed to easily compose different cells by\nhierarchically linking them and easily construct new cells by using standard\ncell interfaces. This design enables: (1) scalability, supporting hundreds of\nconcurrent gigabit-level paths on a single machine and cluster-level\nexperiments composed of multiple machines; (2) extensibility, simulating new\nnetwork conditions by constructing new cells. Rattan empowers developers and\nresearchers to efficiently and confidently evaluate, validate, and diagnose\ndiverse network transport innovations for online services.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08134v1", "cate": "cs.NI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2506.01635", "title": "Riemannian Time Warping: Multiple Sequence Alignment in Curved Spaces", "authors": ["Julian Richter", "Christopher Erdös", "Christian Scheurer", "Jochen J. Steil", "Niels Dehio"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01635v2", "summary": "Temporal alignment of multiple signals through time warping is crucial in\nmany fields, such as classification within speech recognition or robot motion\nlearning. Almost all related works are limited to data in Euclidean space.\nAlthough an attempt was made in 2011 to adapt this concept to unit quaternions,\na general extension to Riemannian manifolds remains absent. Given its\nimportance for numerous applications in robotics and beyond, we introduce\nRiemannian Time Warping (RTW). This novel approach efficiently aligns multiple\nsignals by considering the geometric structure of the Riemannian manifold in\nwhich the data is embedded. Extensive experiments on synthetic and real-world\ndata, including tests with an LBR iiwa robot, demonstrate that RTW consistently\noutperforms state-of-the-art baselines in both averaging and classification\ntasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01635v2", "cate": "cs.RO", "date": "2025-06-02", "updated": "2025-07-11"}
{"id": "2507.05314", "title": "Dual-Attention U-Net++ with Class-Specific Ensembles and Bayesian Hyperparameter Optimization for Precise Wound and Scale Marker Segmentation", "authors": ["Daniel Cieślak", "Miriam Reca", "Olena Onyshchenko", "Jacek Rumiński"], "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.6; I.5.1; I.2.6; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, conference: Joint 20th Nordic-Baltic Conference on Biomedical Engineering & 24th Polish Conference on Biocybernetics and Biomedical Engineering; 6 figures, 2 tables, 11 sources", "url": "http://arxiv.org/abs/2507.05314v1", "summary": "Accurate segmentation of wounds and scale markers in clinical images remainsa\nsignificant challenge, crucial for effective wound management and\nautomatedassessment. In this study, we propose a novel dual-attention U-Net++\narchi-tecture, integrating channel-wise (SCSE) and spatial attention mechanisms\ntoaddress severe class imbalance and variability in medical images\neffectively.Initially, extensive benchmarking across diverse architectures and\nencoders via 5-fold cross-validation identified EfficientNet-B7 as the optimal\nencoder backbone.Subsequently, we independently trained two class-specific\nmodels with tailoredpreprocessing, extensive data augmentation, and Bayesian\nhyperparameter tun-ing (WandB sweeps). The final model ensemble utilized Test\nTime Augmentationto further enhance prediction reliability. Our approach was\nevaluated on a bench-mark dataset from the NBC 2025 & PCBBE 2025 competition.\nSegmentationperformance was quantified using a weighted F1-score (75% wounds,\n25% scalemarkers), calculated externally by competition organizers on\nundisclosed hard-ware. The proposed approach achieved an F1-score of 0.8640,\nunderscoring itseffectiveness for complex medical segmentation tasks.", "comment": "11 pages, conference: Joint 20th Nordic-Baltic Conference on\n  Biomedical Engineering & 24th Polish Conference on Biocybernetics and\n  Biomedical Engineering; 6 figures, 2 tables, 11 sources", "pdf_url": "http://arxiv.org/pdf/2507.05314v1", "cate": "eess.IV", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.08243", "title": "CoreSPECT: Enhancing Clustering Algorithms via an Interplay of Density and Geometry", "authors": ["Chandra Sekhar Mukherjee", "Joonyoung Bae", "Jiapeng Zhang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08243v1", "summary": "Density and geometry have long served as two of the fundamental guiding\nprinciples in clustering algorithm design, with algorithm usually focusing\neither on the density structure of the data (e.g., HDBSCAN and Density Peak\nClustering) or the complexity of underlying geometry (e.g., manifold clustering\nalgorithms).\n  In this paper, we identify and formalize a recurring but often overlooked\ninteraction between distribution and geometry and leverage this insight to\ndesign our clustering enhancement framework CoreSPECT (Core Space\nProjection-based Enhancement of Clustering Techniques). Our framework boosts\nthe performance of simple algorithms like K-Means and GMM by applying them to\nstrategically selected regions, then extending the partial partition to a\ncomplete partition for the dataset using a novel neighborhood graph based\nmulti-layer propagation procedure.\n  We apply our framework on 15 datasets from three different domains and obtain\nconsistent and substantial gain in clustering accuracy for both K-Means and\nGMM. On average, our framework improves the ARI of K-Means by 40% and of GMM by\n14%, often surpassing the performance of both manifold-based and recent\ndensity-based clustering algorithms. We further support our framework with\ninitial theoretical guarantees, ablation to demonstrate the usefulness of the\nindividual steps and with evidence of robustness to noise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08243v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08248", "title": "Transfer Learning and Mixup for Fine-Grained Few-Shot Fungi Classification", "authors": ["Jason Kahei Tam", "Murilo Gustineli", "Anthony Miyaguchi"], "categories": ["cs.CV", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08248v1", "summary": "Accurate identification of fungi species presents a unique challenge in\ncomputer vision due to fine-grained inter-species variation and high\nintra-species variation. This paper presents our approach for the FungiCLEF\n2025 competition, which focuses on few-shot fine-grained visual categorization\n(FGVC) using the FungiTastic Few-Shot dataset. Our team (DS@GT) experimented\nwith multiple vision transformer models, data augmentation, weighted sampling,\nand incorporating textual information. We also explored generative AI models\nfor zero-shot classification using structured prompting but found them to\nsignificantly underperform relative to vision-based models. Our final model\noutperformed both competition baselines and highlighted the effectiveness of\ndomain specific pretraining and balanced sampling strategies. Our approach\nranked 35/74 on the private test set in post-completion evaluation, this\nsuggests additional work can be done on metadata selection and domain-adapted\nmulti-modal learning. Our code is available at\nhttps://github.com/dsgt-arc/fungiclef-2025.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08248v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.09166", "title": "An Exploration of Default Images in Text-to-Image Generation", "authors": ["Hannu Simonen", "Atte Kiviniemi", "Jonas Oppenlaender"], "categories": ["cs.HC", "cs.AI", "H.5.m; I.2.m"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      16 pages, 6 figures", "url": "http://arxiv.org/abs/2505.09166v3", "summary": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions.", "comment": "16 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2505.09166v3", "cate": "cs.HC", "date": "2025-05-14", "updated": "2025-07-11"}
{"id": "2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": ["Zezhen Xiang", "Jingzhi Gong", "Tao Chen"], "categories": ["cs.SE", "cs.AI"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted by ICSE 2026", "url": "http://arxiv.org/abs/2507.08730v1", "summary": "Modern configurable software systems need to learn models that correlate\nconfiguration and performance. However, when the system operates in dynamic\nenvironments, the workload variations, hardware changes, and system updates\nwill inevitably introduce concept drifts at different levels - global drifts,\nwhich reshape the performance landscape of the entire configuration space; and\nlocal drifts, which only affect certain sub-regions of that space. As such,\nexisting offline and transfer learning approaches can struggle to adapt to\nthese implicit and unpredictable changes in real-time, rendering configuration\nperformance learning challenging. To address this, we propose DHDA, an online\nconfiguration performance learning framework designed to capture and adapt to\nthese drifts at different levels. The key idea is that DHDA adapts to both the\nlocal and global drifts using dually hierarchical adaptation: at the upper\nlevel, we redivide the data into different divisions, within each of which the\nlocal model is retrained, to handle global drifts only when necessary. At the\nlower level, the local models of the divisions can detect local drifts and\nadapt themselves asynchronously. To balance responsiveness and efficiency, DHDA\ncombines incremental updates with periodic full retraining to minimize\nredundant computation when no drifts are detected. Through evaluating eight\nsoftware systems and against state-of-the-art approaches, we show that DHDA\nachieves considerably better accuracy and can effectively adapt to drifts with\nup to 2x improvements, while incurring reasonable overhead and is able to\nimprove different local models in handling concept drift.", "comment": "Accepted by ICSE 2026", "pdf_url": "http://arxiv.org/pdf/2507.08730v1", "cate": "cs.SE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.05255", "title": "Incivility and Contentiousness Spillover in Public Engagement with Public Health and Climate Science", "authors": ["Hasti Narimanzadeh", "Arash Badie-Modiri", "Iuliia Smirnova", "Ted Hsuan Yun Chen"], "categories": ["cs.SI", "cs.CY", "physics.soc-ph"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      33 pages, 6 figures", "url": "http://arxiv.org/abs/2502.05255v2", "summary": "Affective polarization and political sorting drive public antagonism around\nissues at the science-policy nexus. Looking at the COVID-19 period, we study\ncross-domain spillover of incivility and contentiousness in public engagements\nwith climate change and public health on Twitter and Reddit. We find strong\nevidence of the signatures of affective polarization surrounding COVID-19\nspilling into the climate change domain. Across different social media systems,\nCOVID-19 content is associated with incivility and contentiousness in climate\ndiscussions. These patterns of increased antagonism were responsive to pandemic\nevents that made the link between science and public policy more salient. The\nobserved spillover activated along pre-pandemic political cleavages,\nspecifically anti-internationalist populist beliefs, that linked climate policy\nopposition to vaccine hesitancy. Our findings show how affective polarization\nin public engagement with science becomes entrenched across science policy\ndomains.", "comment": "33 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2502.05255v2", "cate": "cs.SI", "date": "2025-02-07", "updated": "2025-07-10"}
{"id": "2507.08164", "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence", "authors": ["Yun Tang", "Mengbang Zou", "Zeinab Nezami", "Syed Ali Raza Zaidi", "Weisi Guo"], "categories": ["cs.NI", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, submitted for possible publication", "url": "http://arxiv.org/abs/2507.08164v1", "summary": "The emergence of large language models (LLMs) and agentic systems is enabling\nautonomous 6G networks with advanced intelligence, including\nself-configuration, self-optimization, and self-healing. However, the current\nimplementation of individual intelligence tasks necessitates isolated knowledge\nretrieval pipelines, resulting in redundant data flows and inconsistent\ninterpretations. Inspired by the service model unification effort in Open-RAN\n(to support interoperability and vendor diversity), we propose KP-A: a unified\nNetwork Knowledge Plane specifically designed for Agentic network intelligence.\nBy decoupling network knowledge acquisition and management from intelligence\nlogic, KP-A streamlines development and reduces maintenance complexity for\nintelligence engineers. By offering an intuitive and consistent knowledge\ninterface, KP-A also enhances interoperability for the network intelligence\nagents. We demonstrate KP-A in two representative intelligence tasks: live\nnetwork knowledge Q&A and edge AI service orchestration. All implementation\nartifacts have been open-sourced to support reproducibility and future\nstandardization efforts.", "comment": "7 pages, 5 figures, submitted for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.08164v1", "cate": "cs.NI", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2506.07454", "title": "Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs", "authors": ["Jared Strader", "Aaron Ray", "Jacob Arkin", "Mason B. Peterson", "Yun Chang", "Nathan Hughes", "Christopher Bradley", "Yi Xuan Jia", "Carlos Nieto-Granda", "Rajat Talak", "Chuchu Fan", "Luca Carlone", "Jonathan P. How", "Nicholas Roy"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, 4 tables", "url": "http://arxiv.org/abs/2506.07454v2", "summary": "In this paper, we introduce a multi-robot system that integrates mapping,\nlocalization, and task and motion planning (TAMP) enabled by 3D scene graphs to\nexecute complex instructions expressed in natural language. Our system builds a\nshared 3D scene graph incorporating an open-set object-based map, which is\nleveraged for multi-robot 3D scene graph fusion. This representation supports\nreal-time, view-invariant relocalization (via the object-based map) and\nplanning (via the 3D scene graph), allowing a team of robots to reason about\ntheir surroundings and execute complex tasks. Additionally, we introduce a\nplanning approach that translates operator intent into Planning Domain\nDefinition Language (PDDL) goals using a Large Language Model (LLM) by\nleveraging context from the shared 3D scene graph and robot capabilities. We\nprovide an experimental assessment of the performance of our system on\nreal-world tasks in large-scale, outdoor environments. A supplementary video is\navailable at https://youtu.be/8xbGGOLfLAY.", "comment": "12 pages, 4 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2506.07454v2", "cate": "cs.RO", "date": "2025-06-09", "updated": "2025-07-10"}
{"id": "2507.08005", "title": "Unraveling the Potential of Diffusion Models in Small Molecule Generation", "authors": ["Peining Zhang", "Daniel Baker", "Minghu Song", "Jinbo Bi"], "categories": ["q-bio.BM", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08005v1", "summary": "Generative AI presents chemists with novel ideas for drug design and\nfacilitates the exploration of vast chemical spaces. Diffusion models (DMs), an\nemerging tool, have recently attracted great attention in drug R\\&D. This paper\ncomprehensively reviews the latest advancements and applications of DMs in\nmolecular generation. It begins by introducing the theoretical principles of\nDMs. Subsequently, it categorizes various DM-based molecular generation methods\naccording to their mathematical and chemical applications. The review further\nexamines the performance of these models on benchmark datasets, with a\nparticular focus on comparing the generation performance of existing 3D\nmethods. Finally, it concludes by emphasizing current challenges and suggesting\nfuture research directions to fully exploit the potential of DMs in drug\ndiscovery.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08005v1", "cate": "q-bio.BM", "date": "2025-06-25", "updated": "2025-06-25"}
{"id": "2507.08255", "title": "Quantum-Accelerated Neural Imputation with Large Language Models (LLMs)", "authors": ["Hossein Jamali"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08255v1", "summary": "Missing data presents a critical challenge in real-world datasets,\nsignificantly degrading the performance of machine learning models. While Large\nLanguage Models (LLMs) have recently demonstrated remarkable capabilities in\ntabular data imputation, exemplified by frameworks like UnIMP, their reliance\non classical embedding methods often limits their ability to capture complex,\nnon-linear correlations, particularly in mixed-type data scenarios encompassing\nnumerical, categorical, and textual features. This paper introduces\nQuantum-UnIMP, a novel framework that integrates shallow quantum circuits into\nan LLM-based imputation architecture. Our core innovation lies in replacing\nconventional classical input embeddings with quantum feature maps generated by\nan Instantaneous Quantum Polynomial (IQP) circuit. This approach enables the\nmodel to leverage quantum phenomena such as superposition and entanglement,\nthereby learning richer, more expressive representations of data and enhancing\nthe recovery of intricate missingness patterns. Our experiments on benchmark\nmixed-type datasets demonstrate that Quantum-UnIMP reduces imputation error by\nup to 15.2% for numerical features (RMSE) and improves classification accuracy\nby 8.7% for categorical features (F1-Score) compared to state-of-the-art\nclassical and LLM-based methods. These compelling results underscore the\nprofound potential of quantum-enhanced representations for complex data\nimputation tasks, even with near-term quantum hardware.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08255v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08268", "title": "Portable Biomechanics Laboratory: Clinically Accessible Movement Analysis from a Handheld Smartphone", "authors": ["J. D. Peiffer", "Kunal Shah", "Irina Djuraskovic", "Shawana Anarwala", "Kayan Abdou", "Rujvee Patel", "Prakash Jayabalan", "Brenton Pennicooke", "R. James Cotton"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      15 pages, 7 figures", "url": "http://arxiv.org/abs/2507.08268v1", "summary": "The way a person moves is a direct reflection of their neurological and\nmusculoskeletal health, yet it remains one of the most underutilized vital\nsigns in clinical practice. Although clinicians visually observe movement\nimpairments, they lack accessible and validated methods to objectively measure\nmovement in routine care. This gap prevents wider use of biomechanical\nmeasurements in practice, which could enable more sensitive outcome measures or\nearlier identification of impairment. We present our Portable Biomechanics\nLaboratory (PBL), which includes a secure, cloud-enabled smartphone app for\ndata collection and a novel algorithm for fitting biomechanical models to this\ndata. We extensively validated PBL's biomechanical measures using a large,\nclinically representative dataset. Next, we tested the usability and utility of\nour system in neurosurgery and sports medicine clinics. We found joint angle\nerrors within 3 degrees across participants with neurological injury,\nlower-limb prosthesis users, pediatric inpatients, and controls. In addition to\nbeing easy to use, gait metrics computed from the PBL showed high reliability\nand were sensitive to clinical differences. For example, in individuals\nundergoing decompression surgery for cervical myelopathy, the mJOA score is a\ncommon patient-reported outcome measure; we found that PBL gait metrics\ncorrelated with mJOA scores and demonstrated greater responsiveness to surgical\nintervention than the patient-reported outcomes. These findings support the use\nof handheld smartphone video as a scalable, low-burden tool for capturing\nclinically meaningful biomechanical data, offering a promising path toward\naccessible monitoring of mobility impairments. We release the first clinically\nvalidated method for measuring whole-body kinematics from handheld smartphone\nvideo at\nhttps://intelligentsensingandrehabilitation.github.io/MonocularBiomechanics/ .", "comment": "15 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.08268v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07362", "title": "FLoRA: An Advanced AI-Powered Engine to Facilitate Hybrid Human-AI Regulated Learning", "authors": ["Xinyu Li", "Tongguang Li", "Lixiang Yan", "Yuheng Li", "Linxuan Zhao", "Mladen Raković", "Inge Molenaar", "Dragan Gašević", "Yizhou Fan"], "categories": ["cs.HC", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07362v2", "summary": "SRL, defined as learners' ability to systematically plan, monitor, and\nregulate their learning activities, is crucial for sustained academic\nachievement and lifelong learning competencies. Emerging Artificial\nIntelligence (AI) developments profoundly influence SRL interactions by\npotentially either diminishing or strengthening learners' opportunities to\nexercise their own regulatory skills. Recent literature emphasizes a balanced\napproach termed Hybrid Human-AI Regulated Learning (HHAIRL), in which AI\nprovides targeted, timely scaffolding while preserving the learners' role as\nactive decision-makers and reflective monitors of their learning process.\nNevertheless, existing digital tools frequently fall short, lacking\nadaptability, focusing narrowly on isolated SRL phases, and insufficiently\nsupport meaningful human-AI interactions. In response, this paper introduces\nthe enhanced FLoRA Engine, which incorporates advanced Generative Artificial\nIntelligence (GenAI) features and state-of-the-art learning analytics,\nexplicitly grounded in SRL and HHAIRL theories. The FLoRA Engine offers\ninstrumentation tools such as collaborative writing, multi-agents chatbot, and\ndetailed learning trace logging to support dynamic, adaptive scaffolding\ntailored to individual needs in real time. We further present a summary of\nseveral research studies that provide the validations for and illustrate how\nthese instrumentation tools can be utilized in real-world educational and\nexperimental contexts. These studies demonstrate the effectiveness of FLoRA\nEngine in fostering SRL and HHAIRL, providing both theoretical insights and\npractical solutions for the future of AI-enhanced learning context.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07362v2", "cate": "cs.HC", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08719", "title": "Multilingual Multimodal Software Developer for Code Generation", "authors": ["Linzheng Chai", "Jian Yang", "Shukai Liu", "Wei Zhang", "Liran Wang", "Ke Jin", "Tao Sun", "Congnan Liu", "Chenchen Zhang", "Hualei Zhu", "Jiaheng Liu", "Xianjie Wu", "Ge Zhang", "Tianyu Liu", "Zhoujun Li"], "categories": ["cs.CL", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.08719v1", "summary": "The rapid advancement of Large Language Models (LLMs) has significantly\nimproved code generation, yet most models remain text-only, neglecting crucial\nvisual aids like diagrams and flowcharts used in real-world software\ndevelopment. To bridge this gap, we introduce MM-Coder, a Multilingual\nMultimodal software developer. MM-Coder integrates visual design inputs-Unified\nModeling Language (UML) diagrams and flowcharts (termed Visual Workflow)-with\ntextual instructions to enhance code generation accuracy and architectural\nalignment. To enable this, we developed MMc-Instruct, a diverse multimodal\ninstruction-tuning dataset including visual-workflow-based code generation,\nallowing MM-Coder to synthesize textual and graphical information like human\ndevelopers, distinct from prior work on narrow tasks. Furthermore, we introduce\nMMEval, a new benchmark for evaluating multimodal code generation, addressing\nexisting text-only limitations. Our evaluations using MMEval highlight\nsignificant remaining challenges for models in precise visual information\ncapture, instruction following, and advanced programming knowledge. Our work\naims to revolutionize industrial programming by enabling LLMs to interpret and\nimplement complex specifications conveyed through both text and visual designs.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.08719v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2407.02624", "title": "Optimizing Probabilistic Propagation in Graphs by Adding Edges", "authors": ["Aditya Bhaskara", "Alex Crane", "Shweta Jain", "Md Mumtahin Habib Ullah Mazumder", "Blair D. Sullivan", "Prasanth Yalamanchili"], "categories": ["cs.DS", "cs.SI"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Abstract shortened to comply with arxiv requirements", "url": "http://arxiv.org/abs/2407.02624v3", "summary": "Probabilistic graphs are an abstraction that allow us to study randomized\npropagation in graphs. In a probabilistic graph, each edge is \"active\" with a\ncertain probability, independent of the other edges. For two vertices $u,v$, a\nclassic quantity of interest, that we refer to as the proximity\n$\\mathcal{P}_{G}(u, v)$, is the probability that there exists a path between\n$u$ and $v$ all of whose edges are active. For a given subset of vertices\n$V_s$, the reach of $V_s$ is defined as the minimum over pairs $u \\in V_s$ and\n$v \\in V$ of the proximity $\\mathcal{P}_{G}(u,v)$. This quantity has been\nstudied in the context of multicast in unreliable communication networks and in\nsocial network analysis.\n  We study the problem of improving the reach in a probabilistic graph via edge\naugmentation. Formally, given a budget $k$ of edge additions and a set of\nsource vertices $V_s$, the goal of Reach Improvement is to maximize the reach\nof $V_s$ by adding at most $k$ new edges to the graph. The problem was\nintroduced in earlier empirical work in the algorithmic fairness community. We\nprovide the first approximation guarantees and hardness results for Reach\nImprovement.\n  We prove that the existence of a good augmentation implies a cluster\nstructure for the graph. We use this structural result to analyze a novel\nalgorithm that outputs a $k$-edge augmentation with an objective value that is\npoly($\\beta^*$), where $\\beta^*$ is the objective value for the optimal\naugmentation. We also give an algorithm that adds $O(k \\log n)$ edges and\nyields a multiplicative approximation to $\\beta^*$. Our arguments rely on new\nprobabilistic tools for analyzing proximity, inspired by techniques in\npercolation theory; these tools may be of broader interest. Finally, we show\nthat significantly better approximations are unlikely, under known hardness\nassumptions related to gap variants of the classic Set Cover problem.", "comment": "Abstract shortened to comply with arxiv requirements", "pdf_url": "http://arxiv.org/pdf/2407.02624v3", "cate": "cs.DS", "date": "2024-07-02", "updated": "2025-07-10"}
{"id": "2507.08403", "title": "Towards AI-Native RAN: An Operator's Perspective of 6G Day 1 Standardization", "authors": ["Nan Li", "Qi Sun", "Lehan Wang", "Xiaofei Xu", "Jinri Huang", "Chunhui Liu", "Jing Gao", "Yuhong Huang", "Chih-Lin I"], "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08403v1", "summary": "Artificial Intelligence/Machine Learning (AI/ML) has become the most certain\nand prominent feature of 6G mobile networks. Unlike 5G, where AI/ML was not\nnatively integrated but rather an add-on feature over existing architecture, 6G\nshall incorporate AI from the onset to address its complexity and support\nubiquitous AI applications. Based on our extensive mobile network operation and\nstandardization experience from 2G to 5G, this paper explores the design and\nstandardization principles of AI-Native radio access networks (RAN) for 6G,\nwith a particular focus on its critical Day 1 architecture, functionalities and\ncapabilities. We investigate the framework of AI-Native RAN and present its\nthree essential capabilities to shed some light on the standardization\ndirection; namely, AI-driven RAN processing/optimization/automation, reliable\nAI lifecycle management (LCM), and AI-as-a-Service (AIaaS) provisioning. The\nstandardization of AI-Native RAN, in particular the Day 1 features, including\nan AI-Native 6G RAN architecture, were proposed. For validation, a large-scale\nfield trial with over 5000 5G-A base stations have been built and delivered\nsignificant improvements in average air interface latency, root cause\nidentification, and network energy consumption with the proposed architecture\nand the supporting AI functions. This paper aims to provide a Day 1 framework\nfor 6G AI-Native RAN standardization design, balancing technical innovation\nwith practical deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08403v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.18355", "title": "Robotic Manipulation of a Rotating Chain with Bottom End Fixed", "authors": ["Qi Jing Chen", "Shilin Shan", "Quang-Cuong Pham"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures", "url": "http://arxiv.org/abs/2506.18355v2", "summary": "This paper studies the problem of using a robot arm to manipulate a uniformly\nrotating chain with its bottom end fixed. Existing studies have investigated\nideal rotational shapes for practical applications, yet they do not discuss how\nthese shapes can be consistently achieved through manipulation planning. Our\nwork presents a manipulation strategy for stable and consistent shape\ntransitions. We find that the configuration space of such a chain is\nhomeomorphic to a three-dimensional cube. Using this property, we suggest a\nstrategy to manipulate the chain into different configurations, specifically\nfrom one rotation mode to another, while taking stability and feasibility into\nconsideration. We demonstrate the effectiveness of our strategy in physical\nexperiments by successfully transitioning from rest to the first two rotation\nmodes. The concepts explored in our work have critical applications in ensuring\nsafety and efficiency of drill string and yarn spinning operations.", "comment": "6 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2506.18355v2", "cate": "cs.RO", "date": "2025-06-23", "updated": "2025-07-11"}
{"id": "2507.08011", "title": "Energy Management for Renewable-Colocated Artificial Intelligence Data Centers", "authors": ["Siying Li", "Lang Tong", "Timothy D. Mount"], "categories": ["math.OC", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08011v1", "summary": "We develop an energy management system (EMS) for artificial intelligence (AI)\ndata centers with colocated renewable generation. Under a profit-maximizing\nframework, the EMS of renewable-colocated data center (RCDC) co-optimizes AI\nworkload scheduling, on-site renewable utilization, and electricity market\nparticipation. Within both wholesale and retail market participation models,\nthe economic benefit of the RCDC operation is maximized. Empirical evaluations\nusing real-world traces of electricity prices, data center power consumption,\nand renewable generation demonstrate significant profit gains from renewable\nand AI data center colocations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08011v1", "cate": "math.OC", "date": "2025-07-04", "updated": "2025-07-04"}
{"id": "2507.08267", "title": "A Practical Two-Stage Recipe for Mathematical LLMs: Maximizing Accuracy with SFT and Efficiency with Reinforcement Learning", "authors": ["Hiroshi Yoshihara", "Taiki Yamaguchi", "Yuichi Inoue"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented at ICML 2025 Workshop on The second AI for MATH", "url": "http://arxiv.org/abs/2507.08267v1", "summary": "Enhancing the mathematical reasoning of Large Language Models (LLMs) is a\npivotal challenge in advancing AI capabilities. While Supervised Fine-Tuning\n(SFT) and Reinforcement Learning (RL) are the dominant training paradigms, a\nsystematic methodology for combining them to maximize both accuracy and\nefficiency remains largely unexplored. This paper introduces a practical and\neffective training recipe that strategically integrates extended SFT with RL\nfrom online inference (GRPO). We posit that these methods play complementary,\nnot competing, roles: a prolonged SFT phase first pushes the model's accuracy\nto its limits, after which a GRPO phase dramatically improves token efficiency\nwhile preserving this peak performance. Our experiments reveal that extending\nSFT for as many as 10 epochs is crucial for performance breakthroughs, and that\nthe primary role of GRPO in this framework is to optimize solution length. The\nefficacy of our recipe is rigorously validated through top-tier performance on\nchallenging benchmarks, including a high rank among over 2,200 teams in the\nstrictly leak-free AI Mathematical Olympiad (AIMO). This work provides the\ncommunity with a battle-tested blueprint for developing state-of-the-art\nmathematical reasoners that are both exceptionally accurate and practically\nefficient. To ensure full reproducibility and empower future research, we will\nopen-source our entire framework, including all code, model checkpoints, and\ntraining configurations at\nhttps://github.com/analokmaus/kaggle-aimo2-fast-math-r1.", "comment": "Presented at ICML 2025 Workshop on The second AI for MATH", "pdf_url": "http://arxiv.org/pdf/2507.08267v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08290", "title": "Cross-Resolution SAR Target Detection Using Structural Hierarchy Adaptation and Reliable Adjacency Alignment", "authors": ["Jiang Qin", "Bin Zou", "Haolin Li", "Lamei Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to IEEE TGRS (major revision)", "url": "http://arxiv.org/abs/2507.08290v1", "summary": "In recent years, continuous improvements in SAR resolution have significantly\nbenefited applications such as urban monitoring and target detection. However,\nthe improvement in resolution leads to increased discrepancies in scattering\ncharacteristics, posing challenges to the generalization ability of target\ndetection models. While domain adaptation technology is a potential solution,\nthe inevitable discrepancies caused by resolution differences often lead to\nblind feature adaptation and unreliable semantic propagation, ultimately\ndegrading the domain adaptation performance. To address these challenges, this\npaper proposes a novel SAR target detection method (termed CR-Net), that\nincorporates structure priors and evidential learning theory into the detection\nmodel, enabling reliable domain adaptation for cross-resolution detection. To\nbe specific, CR-Net integrates Structure-induced Hierarchical Feature\nAdaptation (SHFA) and Reliable Structural Adjacency Alignment (RSAA). SHFA\nmodule is introduced to establish structural correlations between targets and\nachieve structure-aware feature adaptation, thereby enhancing the\ninterpretability of the feature adaptation process. Afterwards, the RSAA module\nis proposed to enhance reliable semantic alignment, by leveraging the secure\nadjacency set to transfer valuable discriminative knowledge from the source\ndomain to the target domain. This further improves the discriminability of the\ndetection model in the target domain. Based on experimental results from\ndifferent-resolution datasets,the proposed CR-Net significantly enhances\ncross-resolution adaptation by preserving intra-domain structures and improving\ndiscriminability. It achieves state-of-the-art (SOTA) performance in\ncross-resolution SAR target detection.", "comment": "Submitted to IEEE TGRS (major revision)", "pdf_url": "http://arxiv.org/pdf/2507.08290v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07930", "title": "Probing Experts' Perspectives on AI-Assisted Public Speaking Training", "authors": ["Nesrine Fourati", "Alisa Barkar", "Marion Dragée", "Liv Danthon-Lefebvre", "Mathieu Chollet"], "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07930v2", "summary": "Background: Public speaking is a vital professional skill, yet it remains a\nsource of significant anxiety for many individuals. Traditional training relies\nheavily on expert coaching, but recent advances in AI has led to novel types of\ncommercial automated public speaking feedback tools. However, most research has\nfocused on prototypes rather than commercial applications, and little is known\nabout how public speaking experts perceive these tools.\n  Objectives: This study aims to evaluate expert opinions on the efficacy and\ndesign of commercial AI-based public speaking training tools and to propose\nguidelines for their improvement.\n  Methods: The research involved 16 semi-structured interviews and 2 focus\ngroups with public speaking experts. Participants discussed their views on\ncurrent commercial tools, their potential integration into traditional\ncoaching, and suggestions for enhancing these systems.\n  Results and Conclusions: Experts acknowledged the value of AI tools in\nhandling repetitive, technical aspects of training, allowing coaches to focus\non higher-level skills. However they found key issues in current tools,\nemphasising the need for personalised, understandable, carefully selected\nfeedback and clear instructional design. Overall, they supported a hybrid model\ncombining traditional coaching with AI-supported exercises.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07930v2", "cate": "cs.HC", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2408.08054", "title": "Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework", "authors": ["Changyu Du", "Sebastian Esser", "Stavros Nousias", "André Borrmann"], "categories": ["cs.AI", "cs.CL", "cs.SE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Journal of Computing in Civil Engineering", "url": "http://arxiv.org/abs/2408.08054v2", "summary": "The conventional BIM authoring process typically requires designers to master\ncomplex and tedious modeling commands in order to materialize their design\nintentions within BIM authoring tools. This additional cognitive burden\ncomplicates the design process and hinders the adoption of BIM and model-based\ndesign in the AEC (Architecture, Engineering, and Construction) industry. To\nfacilitate the expression of design intentions more intuitively, we propose\nText2BIM, an LLM-based multi-agent framework that can generate 3D building\nmodels from natural language instructions. This framework orchestrates multiple\nLLM agents to collaborate and reason, transforming textual user input into\nimperative code that invokes the BIM authoring tool's APIs, thereby generating\neditable BIM models with internal layouts, external envelopes, and semantic\ninformation directly in the software. Furthermore, a rule-based model checker\nis introduced into the agentic workflow, utilizing predefined domain knowledge\nto guide the LLM agents in resolving issues within the generated models and\niteratively improving model quality. Extensive experiments were conducted to\ncompare and analyze the performance of three different LLMs under the proposed\nframework. The evaluation results demonstrate that our approach can effectively\ngenerate high-quality, structurally rational building models that are aligned\nwith the abstract concepts specified by user input. Finally, an interactive\nsoftware prototype was developed to integrate the framework into the BIM\nauthoring software Vectorworks, showcasing the potential of modeling by\nchatting. The code is available at: https://github.com/dcy0577/Text2BIM", "comment": "Journal of Computing in Civil Engineering", "pdf_url": "http://arxiv.org/pdf/2408.08054v2", "cate": "cs.AI", "date": "2024-08-15", "updated": "2025-07-11"}
{"id": "2410.05401", "title": "Post-hoc Study of Climate Microtargeting on Social Media Ads with LLMs: Thematic Insights and Fairness Evaluation", "authors": ["Tunazzina Islam", "Dan Goldwasser"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.05401v3", "summary": "Climate change communication on social media increasingly employs\nmicrotargeting strategies to effectively reach and influence specific\ndemographic groups. This study presents a post-hoc analysis of microtargeting\npractices within climate campaigns by leveraging large language models (LLMs)\nto examine Facebook advertisements. Our analysis focuses on two key aspects:\ndemographic targeting and fairness. We evaluate the ability of LLMs to\naccurately predict the intended demographic targets, such as gender and age\ngroup, achieving an overall accuracy of 88.55%. Furthermore, we instruct the\nLLMs to generate explanations for their classifications, providing transparent\nreasoning behind each decision. These explanations reveal the specific thematic\nelements used to engage different demographic segments, highlighting distinct\nstrategies tailored to various audiences. Our findings show that young adults\nare primarily targeted through messages emphasizing activism and environmental\nconsciousness, while women are engaged through themes related to caregiving\nroles and social advocacy. In addition to evaluating the effectiveness of LLMs\nin detecting microtargeted messaging, we conduct a comprehensive fairness\nanalysis to identify potential biases in model predictions. Our findings\nindicate that while LLMs perform well overall, certain biases exist,\nparticularly in the classification of senior citizens and male audiences. By\nshowcasing the efficacy of LLMs in dissecting and explaining targeted\ncommunication strategies and by highlighting fairness concerns, this study\nprovides a valuable framework for future research aimed at enhancing\ntransparency, accountability, and inclusivity in social media-driven climate\ncampaigns.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.05401v3", "cate": "cs.CL", "date": "2024-10-07", "updated": "2025-07-10"}
{"id": "2507.08429", "title": "Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method", "authors": ["Geng Sun", "Likun Zhang", "Jiahui Li", "Jing Wu", "Jiacheng Wang", "Zemin Sun", "Changyuan Zhao", "Victor C. M. Leung"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      21 pages, 8 figures", "url": "http://arxiv.org/abs/2507.08429v1", "summary": "The integration of unmanned aerial vehicles (UAVs) with Internet of Things\n(IoT) networks offers promising solutions for efficient data collection.\nHowever, the limited energy capacity of UAVs remains a significant challenge.\nIn this case, laser beam directors (LBDs) have emerged as an effective\ntechnology for wireless charging of UAVs during operation, thereby enabling\nsustained data collection without frequent returns to charging stations (CSs).\nIn this work, we investigate the age of information (AoI) optimization in\nLBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from\ndistributed IoTs while being recharged by laser beams. We formulate a joint\noptimization problem that aims to minimize the peak AoI while determining\noptimal UAV trajectories and laser charging strategies. This problem is\nparticularly challenging due to its non-convex nature, complex temporal\ndependencies, and the need to balance data collection efficiency with energy\nconsumption constraints. To address these challenges, we propose a novel\nmulti-agent proximal policy optimization with temporal memory and multi-agent\ncoordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal\nmemory mechanisms to capture the dynamic nature of UAV operations and\nfacilitates effective coordination among multiple UAVs through decentralized\nlearning while considering global system objectives. Simulation results\ndemonstrate that the proposed MAPPO-TM algorithm outperforms conventional\napproaches in terms of peak AoI minimization and energy efficiency. Ideally,\nthe proposed algorithm achieves up to 15.1% reduction in peak AoI compared to\nconventional multi-agent deep reinforcement learning (MADRL) methods.", "comment": "21 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.08429v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.20487", "title": "A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots", "authors": ["Mingqi Yuan", "Tao Yu", "Wenqi Ge", "Xiuyong Yao", "Huijiang Wang", "Jiayu Chen", "Xin Jin", "Bo Li", "Hua Chen", "Wei Zhang", "Wenjun Zeng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures", "url": "http://arxiv.org/abs/2506.20487v2", "summary": "Humanoid robots are drawing significant attention as versatile platforms for\ncomplex motor control, human-robot interaction, and general-purpose physical\nintelligence. However, achieving efficient whole-body control (WBC) in\nhumanoids remains a fundamental challenge due to sophisticated dynamics,\nunderactuation, and diverse task requirements. While learning-based controllers\nhave shown promise for complex tasks, their reliance on labor-intensive and\ncostly retraining for new scenarios limits real-world applicability. To address\nthese limitations, behavior(al) foundation models (BFMs) have emerged as a new\nparadigm that leverages large-scale pre-training to learn reusable primitive\nskills and broad behavioral priors, enabling zero-shot or rapid adaptation to a\nwide range of downstream tasks. In this paper, we present a comprehensive\noverview of BFMs for humanoid WBC, tracing their development across diverse\npre-training pipelines. Furthermore, we discuss real-world applications,\ncurrent limitations, urgent challenges, and future opportunities, positioning\nBFMs as a key approach toward scalable and general-purpose humanoid\nintelligence. Finally, we provide a curated and long-term list of BFM papers\nand projects to facilitate more subsequent research, which is available at\nhttps://github.com/yuanmingqi/awesome-bfm-papers.", "comment": "18 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2506.20487v2", "cate": "cs.RO", "date": "2025-06-25", "updated": "2025-07-11"}
{"id": "2507.08012", "title": "RepeaTTS: Towards Feature Discovery through Repeated Fine-Tuning", "authors": ["Atli Sigurgeirsson", "Simon King"], "categories": ["cs.CL", "cs.AI", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08012v1", "summary": "A Prompt-based Text-To-Speech model allows a user to control different\naspects of speech, such as speaking rate and perceived gender, through natural\nlanguage instruction. Although user-friendly, such approaches are on one hand\nconstrained: control is limited to acoustic features exposed to the model\nduring training, and too flexible on the other: the same inputs yields\nuncontrollable variation that are reflected in the corpus statistics.\n  We investigate a novel fine-tuning regime to address both of these issues at\nthe same time by exploiting the uncontrollable variance of the model. Through\nprincipal component analysis of thousands of synthesised samples, we determine\nlatent features that account for the highest proportion of the output variance\nand incorporate them as new labels for secondary fine-tuning. We evaluate the\nproposed methods on two models trained on an expressive Icelandic speech\ncorpus, one with emotional disclosure and one without. In the case of the model\nwithout emotional disclosure, the method yields both continuous and discrete\nfeatures that improve overall controllability of the model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08012v1", "cate": "cs.CL", "date": "2025-07-05", "updated": "2025-07-05"}
{"id": "2507.08269", "title": "Data-Driven Dimensional Synthesis of Diverse Planar Four-bar Function Generation Mechanisms via Direct Parameterization", "authors": ["Woon Ryong Kim", "Jaeheun Jung", "Jeong Un Ha", "Donghun Lee", "Jae Kyung Shim"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08269v1", "summary": "Dimensional synthesis of planar four-bar mechanisms is a challenging inverse\nproblem in kinematics, requiring the determination of mechanism dimensions from\ndesired motion specifications. We propose a data-driven framework that bypasses\ntraditional equation-solving and optimization by leveraging supervised\nlearning. Our method combines a synthetic dataset, an LSTM-based neural network\nfor handling sequential precision points, and a Mixture of Experts (MoE)\narchitecture tailored to different linkage types. Each expert model is trained\non type-specific data and guided by a type-specifying layer, enabling both\nsingle-type and multi-type synthesis. A novel simulation metric evaluates\nprediction quality by comparing desired and generated motions. Experiments show\nour approach produces accurate, defect-free linkages across various\nconfigurations. This enables intuitive and efficient mechanism design, even for\nnon-expert users, and opens new possibilities for scalable and flexible\nsynthesis in kinematic design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08269v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08307", "title": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation", "authors": ["Kui Jiang", "Shiyu Liu", "Junjun Jiang", "Xin Yang", "Hongxun Yang", "Xiaopeng Fan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08307v1", "summary": "Audio-driven talking head generation holds significant potential for film\nproduction. While existing 3D methods have advanced motion modeling and content\nsynthesis, they often produce rendering artifacts, such as motion blur,\ntemporal jitter, and local penetration, due to limitations in representing\nstable, fine-grained motion fields. Through systematic analysis, we reformulate\ntalking head generation into a unified framework comprising three steps: video\npreprocessing, motion representation, and rendering reconstruction. This\nframework underpins our proposed M2DAO-Talker, which addresses current\nlimitations via multi-granular motion decoupling and alternating\noptimization.Specifically, we devise a novel 2D portrait preprocessing pipeline\nto extract frame-wise deformation control conditions (motion region\nsegmentation masks, and camera parameters) to facilitate motion representation.\nTo ameliorate motion modeling, we elaborate a multi-granular motion decoupling\nstrategy, which independently models non-rigid (oral and facial) and rigid\n(head) motions for improved reconstruction accuracy.Meanwhile, a motion\nconsistency constraint is developed to ensure head-torso kinematic consistency,\nthereby mitigating penetration artifacts caused by motion aliasing. In\naddition, an alternating optimization strategy is designed to iteratively\nrefine facial and oral motion parameters, enabling more realistic video\ngeneration.Experiments across multiple datasets show that M2DAO-Talker achieves\nstate-of-the-art performance, with the 2.43 dB PSNR improvement in generation\nquality and 0.64 gain in user-evaluated video realness versus TalkingGaussian\nwhile with 150 FPS inference speed. Our project homepage is\nhttps://m2dao-talker.github.io/M2DAO-Talk.github.io", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08307v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.01163", "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers", "authors": ["Rin Ashizawa", "Yoichi Hirose", "Nozomu Yoshinari", "Kento Uchida", "Shinichi Shirakawa"], "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 Findings", "url": "http://arxiv.org/abs/2503.01163v2", "summary": "Prompt optimization aims to search for effective prompts that enhance the\nperformance of large language models (LLMs). Although existing prompt\noptimization methods have discovered effective prompts, they often differ from\nsophisticated prompts carefully designed by human experts. Prompt design\nstrategies, representing best practices for improving prompt performance, can\nbe key to improving prompt optimization. Recently, a method termed the\nAutonomous Prompt Engineering Toolbox (APET) has incorporated various prompt\ndesign strategies into the prompt optimization process. In APET, the LLM is\nneeded to implicitly select and apply the appropriate strategies because prompt\ndesign strategies can have negative effects. This implicit selection may be\nsuboptimal due to the limited optimization capabilities of LLMs. This paper\nintroduces Optimizing Prompts with sTrategy Selection (OPTS), which implements\nexplicit selection mechanisms for prompt design. We propose three mechanisms,\nincluding a Thompson sampling-based approach, and integrate them into\nEvoPrompt, a well-known prompt optimizer. Experiments optimizing prompts for\ntwo LLMs, Llama-3-8B-Instruct and GPT-4o mini, were conducted using BIG-Bench\nHard. Our results show that the selection of prompt design strategies improves\nthe performance of EvoPrompt, and the Thompson sampling-based mechanism\nachieves the best overall results. Our experimental code is provided at\nhttps://github.com/shiralab/OPTS .", "comment": "Accepted to ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2503.01163v2", "cate": "cs.AI", "date": "2025-03-03", "updated": "2025-07-11"}
{"id": "2507.07649", "title": "ProvideQ: A Quantum Optimization Toolbox", "authors": ["Domenik Eichhorn", "Nick Poser", "Maximilian Schweikart", "Ina Schaefer"], "categories": ["quant-ph", "cs.SE"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      This paper was submitted and accepted at the IEEE QSW 2025. Code available at: this https URL", "url": "http://arxiv.org/abs/2507.07649v2", "summary": "Hybrid solvers for combinatorial optimization problems combine the advantages\nof classical and quantum computing to overcome difficult computational\nchallenges. Although their theoretical performance seems promising, their\npractical applicability is challenging due to the lack of a technological stack\nthat can seamlessly integrate quantum solutions with existing classical\noptimization frameworks. We tackle this challenge by introducing the ProvideQ\ntoolbox, a software tool that enables users to easily adapt and configure\nhybrid solvers via Meta-Solver strategies. A Meta-Solver strategy implements\ndecomposition techniques, which splits problems into classical and quantum\nsubroutines. The ProvideQ toolbox enables the interactive creation of such\ndecompositions via a Meta-Solver configuration tool. It combines\nwell-established classical optimization techniques with quantum circuits that\nare seamlessly executable on multiple backends. This paper introduces the\ntechnical details of the ProvideQ toolbox, explains its architecture, and\ndemonstrates possible applications for several real-world use cases. Our proof\nof concept shows that Meta-Solver strategies already enable the application of\nquantum subroutines today, however, more sophisticated hardware is required to\nmake their performance competitive.", "comment": "This paper was submitted and accepted at the IEEE QSW 2025. Code\n  available at: https://github.com/ProvideQ", "pdf_url": "http://arxiv.org/pdf/2507.07649v2", "cate": "quant-ph", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08507", "title": "Recovery of UAV Swarm-enabled Collaborative Beamforming in Low-altitude Wireless Networks under Wind Field Disturbances", "authors": ["Geng Sun", "Chenbang Liu", "Jiahui Li", "Guannan Qu", "Shuang Liang", "Jiacheng Wang", "Changyuan Zhao", "Dusit Niyato"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08507v1", "summary": "Unmanned aerial vehicle (UAV) swarms utilizing collaborative beamforming (CB)\nin low-altitude wireless networks (LAWN) demonstrate significant potential for\nenhanced communication range, energy efficiency, and signal directivity through\nthe formation of virtual antenna arrays (VAA). However, environmental\ndisturbances, particularly wind fields, significantly degrade CB performance by\nintroducing positional errors that disrupt beam patterns, thereby compromising\ntransmission reliability. This paper investigates the critical challenge of\nmaintaining CB performance in UAV-based VAAs operating in LAWN under wind field\ndisturbances. We propose a comprehensive framework that models the impact of\nthree distinct wind conditions (constant, shear, and turbulent) on UAV array\nperformance, and formulate a long-term real-time optimization problem to\nmaximize directivity while minimizing maximum sidelobe levels through adaptive\nexcitation current weight adjustments. To address the inherent complexity of\nthis problem, we propose a novel proximal policy optimization algorithm with\nlong short-term memory (LSTM) structure and adaptive learning rate (PPO-LA),\nwhich effectively captures temporal patterns in wind field disturbances and\nenables real-time adaptation without requiring extensive prior training for\nspecific wind conditions. Our simulation results demonstrate that the proposed\nPPO-LA algorithm successfully recovers degraded CB performance across various\nwind scenarios, and thus significantly outperforming benchmark algorithms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08507v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.06574", "title": "AI Space Cortex: An Experimental System for Future Era Space Exploration", "authors": ["Thomas Touma", "Ersin Daş", "Erica Tevere", "Martin Feather", "Ksenia Kolcio", "Maurice Prather", "Alberto Candela", "Ashish Goel", "Erik Kramer", "Hari Nayar", "Lorraine Fesq", "Joel W. Burdick"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06574v2", "summary": "Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)\neffort contributes to NASA's Concepts for Ocean worlds Life Detection\nTechnology (COLDTech) program, which explores science platform technologies for\nocean worlds such as Europa and Enceladus. Ocean world missions pose\nsignificant operational challenges. These include long communication lags,\nlimited power, and lifetime limitations caused by radiation damage and hostile\nconditions. Given these operational limitations, onboard autonomy will be vital\nfor future Ocean world missions. Besides the management of nominal lander\noperations, onboard autonomy must react appropriately in the event of\nanomalies. Traditional spacecraft rely on a transition into 'safe-mode' in\nwhich non-essential components and subsystems are powered off to preserve\nsafety and maintain communication with Earth. For a severely time-limited Ocean\nworld mission, resolutions to these anomalies that can be executed without\nEarth-in-the-loop communication and associated delays are paramount for\ncompletion of the mission objectives and science goals. To address these\nchallenges, the REASIMO effort aims to demonstrate a robust level of\nAI-assisted autonomy for such missions, including the ability to detect and\nrecover from anomalies, and to perform missions based on pre-trained behaviors\nrather than hard-coded, predetermined logic like all prior space missions. We\ndeveloped an AI-assisted, personality-driven, intelligent framework for control\nof an Ocean world mission by combining a mix of advanced technologies. To\ndemonstrate the capabilities of the framework, we perform tests of autonomous\nsampling operations on a lander-manipulator testbed at the NASA Jet Propulsion\nLaboratory, approximating possible surface conditions such a mission might\nencounter.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06574v2", "cate": "cs.RO", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2507.08013", "title": "MedicalBERT: enhancing biomedical natural language processing using pretrained BERT-based model", "authors": ["K. Sahit Reddy", "N. Ragavenderan", "Vasanth K.", "Ganesh N. Naik", "Vishalakshi Prabhu", "Nagaraja G. S"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08013v1", "summary": "Recent advances in natural language processing (NLP) have been driven\nbypretrained language models like BERT, RoBERTa, T5, and GPT. Thesemodels excel\nat understanding complex texts, but biomedical literature, withits\ndomain-specific terminology, poses challenges that models likeWord2Vec and\nbidirectional long short-term memory (Bi-LSTM) can't fullyaddress. GPT and T5,\ndespite capturing context, fall short in tasks needingbidirectional\nunderstanding, unlike BERT. Addressing this, we proposedMedicalBERT, a\npretrained BERT model trained on a large biomedicaldataset and equipped with\ndomain-specific vocabulary that enhances thecomprehension of biomedical\nterminology. MedicalBERT model is furtheroptimized and fine-tuned to address\ndiverse tasks, including named entityrecognition, relation extraction, question\nanswering, sentence similarity, anddocument classification. Performance metrics\nsuch as the F1-score,accuracy, and Pearson correlation are employed to showcase\nthe efficiencyof our model in comparison to other BERT-based models such as\nBioBERT,SciBERT, and ClinicalBERT. MedicalBERT outperforms these models onmost\nof the benchmarks, and surpasses the general-purpose BERT model by5.67% on\naverage across all the tasks evaluated respectively. This work alsounderscores\nthe potential of leveraging pretrained BERT models for medicalNLP tasks,\ndemonstrating the effectiveness of transfer learning techniques incapturing\ndomain-specific information.\n  (PDF) MedicalBERT: enhancing biomedical natural language processing using\npretrained BERT-based model. Available from:\nhttps://www.researchgate.net/publication/392489050_MedicalBERT_enhancing_biomedical_natural_language_processing_using_pretrained_BERT-based_model\n[accessed Jul 06 2025].", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08013v1", "cate": "cs.CL", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.08284", "title": "Lightweight Safety Guardrails via Synthetic Data and RL-guided Adversarial Training", "authors": ["Aleksei Ilin", "Gor Matevosyan", "Xueying Ma", "Vladimir Eremin", "Suhaa Dada", "Muqun Li", "Riyaaz Shaik", "Haluk Noyan Tokgozoglu"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08284v1", "summary": "We introduce a lightweight yet highly effective safety guardrail framework\nfor language models, demonstrating that small-scale language models can\nachieve, and even surpass, the performance of larger counterparts in content\nmoderation tasks. This is accomplished through high-fidelity synthetic data\ngeneration and adversarial training. The synthetic data generation process\nbegins with human-curated seed data, which undergoes query augmentation and\nparaphrasing to create diverse and contextually rich examples. This augmented\ndata is then subjected to multiple rounds of curation, ensuring high fidelity\nand relevance. Inspired by recent advances in the Generative Adversarial\nNetwork (GAN) architecture, our adversarial training employs reinforcement\nlearning to guide a generator that produces challenging synthetic examples.\nThese examples are used to fine-tune the safety classifier, enhancing its\nability to detect and mitigate harmful content. Additionally, we incorporate\nstrategies from recent research on efficient LLM training, leveraging the\ncapabilities of smaller models to improve the performance of larger generative\nmodels. With iterative adversarial training and the generation of diverse,\nhigh-quality synthetic data, our framework enables small language models (SLMs)\nto serve as robust safety guardrails. This approach not only reduces\ncomputational overhead but also enhances resilience against adversarial\nattacks, offering a scalable and efficient solution for content moderation in\nAI systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08284v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08329", "title": "Cross-Domain Identity Representation for Skull to Face Matching with Benchmark DataSet", "authors": ["Ravi Shankar Prasad", "Dinesh Singh"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages, 12 figures, Pattern Recognition Letters", "url": "http://arxiv.org/abs/2507.08329v1", "summary": "Craniofacial reconstruction in forensic science is crucial for the\nidentification of the victims of crimes and disasters. The objective is to map\na given skull to its corresponding face in a corpus of faces with known\nidentities using recent advancements in computer vision, such as deep learning.\nIn this paper, we presented a framework for the identification of a person\ngiven the X-ray image of a skull using convolutional Siamese networks for\ncross-domain identity representation. Siamese networks are twin networks that\nshare the same architecture and can be trained to discover a feature space\nwhere nearby observations that are similar are grouped and dissimilar\nobservations are moved apart. To do this, the network is exposed to two sets of\ncomparable and different data. The Euclidean distance is then minimized between\nsimilar pairs and maximized between dissimilar ones. Since getting pairs of\nskull and face images are difficult, we prepared our own dataset of 40\nvolunteers whose front and side skull X-ray images and optical face images were\ncollected. Experiments were conducted on the collected cross-domain dataset to\ntrain and validate the Siamese networks. The experimental results provide\nsatisfactory results on the identification of a person from the given skull.", "comment": "7 pages, 12 figures, Pattern Recognition Letters", "pdf_url": "http://arxiv.org/pdf/2507.08329v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08549", "title": "Stabilizing and Optimizing Inter-Shell Routing in LEO Networks with Integrated Routing Cost", "authors": ["Yaojia Wang", "Qi Zhang", "Kun Qiu", "Yue Gao"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures, 2025 IEEE/CIC International Conference on Communications in China (ICCC Workshops)", "url": "http://arxiv.org/abs/2507.08549v1", "summary": "The low Earth orbit (LEO) mega-constellation network (LMCN), which uses\nthousands of satellites across multi-shell architectures to deliver different\nservices, is facing challenges in inter-shell routing stability due to dynamic\nnetwork topologies and frequent inter-satellite link (ISL) switching. Existing\nstrategies, such as the Minimum Hop Path set, prioritize minimizing hop counts\nto reduce latency, but ignore ISL switching costs, which leads to high\ninstability. To overcome this, the Adaptive Path Routing Scheme introduces path\nsimilarity thresholds to reduce the ISL switching frequency between shells.\nHowever, the greedy approach of Adaptive Path Routing Scheme is often trapped\nin local optima, sacrificing inter-shell path distance efficiency. To address\nthese limitations, we propose the Dynamic Programming-based Integrated Routing\nCost (DP-IRC) algorithm, which is designed explicitly for inter-shell routing\noptimization. By formulating multi-shell paths as a multistage decision\nproblem, DP-IRC balances hop counts and ISL stability through an Integrated\nRouting Cost (IRC) metric, combining inter-/intra-shell hops and switching\ncosts. Experiments over 60 time slots with real-world Starlink and OneWeb\nconfigurations show that DP-IRC reduces inter-shell ISL switching rates by\n39.1% and 22.0% compared to the Minimum Hop Path set strategy and Adaptive Path\nRouting Scheme, respectively, while still maintaining near-optimal end-to-end\ndistances.", "comment": "6 pages, 8 figures, 2025 IEEE/CIC International Conference on\n  Communications in China (ICCC Workshops)", "pdf_url": "http://arxiv.org/pdf/2507.08549v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2409.14679", "title": "Quantifying Context Bias in Domain Adaptation for Object Detection", "authors": ["Hojun Son", "Asma Almutairi", "Arpan Kusari"], "categories": ["cs.CV", "cs.AI", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Under review", "url": "http://arxiv.org/abs/2409.14679v3", "summary": "Domain adaptation for object detection (DAOD) has become essential to counter\nperformance degradation caused by distribution shifts between training and\ndeployment domains. However, a critical factor influencing DAOD - context bias\nresulting from learned foreground-background (FG-BG) associations - has\nremained underexplored. We address three key questions regarding FG BG\nassociations in object detection: are FG-BG associations encoded during the\ntraining, is there a causal relationship between FG-BG associations and\ndetection performance, and is there an effect of FG-BG association on DAOD. To\nexamine how models capture FG BG associations, we analyze class-wise and\nfeature-wise performance degradation using background masking and feature\nperturbation, measured via change in accuracies (defined as drop rate). To\nexplore the causal role of FG-BG associations, we apply do-calculus on FG-BG\npairs guided by class activation mapping (CAM). To quantify the causal\ninfluence of FG-BG associations across domains, we propose a novel metric -\ndomain association gradient - defined as the ratio of drop rate to maximum mean\ndiscrepancy (MMD). Through systematic experiments involving background masking,\nfeature-level perturbations, and CAM, we reveal that convolution-based object\ndetection models encode FG-BG associations. Our results demonstrate that\ncontext bias not only exists but causally undermines the generalization\ncapabilities of object detection models across domains. Furthermore, we\nvalidate these findings across multiple models and datasets, including\nstate-of-the-art architectures such as ALDI++. This study highlights the\nnecessity of addressing context bias explicitly in DAOD frameworks, providing\ninsights that pave the way for developing more robust and generalizable object\ndetection systems.", "comment": "Under review", "pdf_url": "http://arxiv.org/pdf/2409.14679v3", "cate": "cs.CV", "date": "2024-09-23", "updated": "2025-07-11"}
{"id": "2507.08014", "title": "Mass-Scale Analysis of In-the-Wild Conversations Reveals Complexity Bounds on LLM Jailbreaking", "authors": ["Aldan Creo", "Raul Castro Fernandez", "Manuel Cebrian"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Code: this https URL Results: this https URL Visualizer: this https URL", "url": "http://arxiv.org/abs/2507.08014v1", "summary": "As large language models (LLMs) become increasingly deployed, understanding\nthe complexity and evolution of jailbreaking strategies is critical for AI\nsafety.\n  We present a mass-scale empirical analysis of jailbreak complexity across\nover 2 million real-world conversations from diverse platforms, including\ndedicated jailbreaking communities and general-purpose chatbots. Using a range\nof complexity metrics spanning probabilistic measures, lexical diversity,\ncompression ratios, and cognitive load indicators, we find that jailbreak\nattempts do not exhibit significantly higher complexity than normal\nconversations. This pattern holds consistently across specialized jailbreaking\ncommunities and general user populations, suggesting practical bounds on attack\nsophistication. Temporal analysis reveals that while user attack toxicity and\ncomplexity remains stable over time, assistant response toxicity has decreased,\nindicating improving safety mechanisms. The absence of power-law scaling in\ncomplexity distributions further points to natural limits on jailbreak\ndevelopment.\n  Our findings challenge the prevailing narrative of an escalating arms race\nbetween attackers and defenders, instead suggesting that LLM safety evolution\nis bounded by human ingenuity constraints while defensive measures continue\nadvancing. Our results highlight critical information hazards in academic\njailbreak disclosure, as sophisticated attacks exceeding current complexity\nbaselines could disrupt the observed equilibrium and enable widespread harm\nbefore defensive adaptation.", "comment": "Code: https://github.com/ACMCMC/risky-conversations Results:\n  https://huggingface.co/risky-conversations Visualizer:\n  https://huggingface.co/spaces/risky-conversations/Visualizer", "pdf_url": "http://arxiv.org/pdf/2507.08014v1", "cate": "cs.CL", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.08311", "title": "CAS Condensed and Accelerated Silhouette: An Efficient Method for Determining the Optimal K in K-Means Clustering", "authors": ["Krishnendu Das", "Sumit Gupta", "Awadhesh Kumar"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08311v1", "summary": "Clustering is a critical component of decision-making in todays data-driven\nenvironments. It has been widely used in a variety of fields such as\nbioinformatics, social network analysis, and image processing. However,\nclustering accuracy remains a major challenge in large datasets. This paper\npresents a comprehensive overview of strategies for selecting the optimal value\nof k in clustering, with a focus on achieving a balance between clustering\nprecision and computational efficiency in complex data environments. In\naddition, this paper introduces improvements to clustering techniques for text\nand image data to provide insights into better computational performance and\ncluster validity. The proposed approach is based on the Condensed Silhouette\nmethod, along with statistical methods such as Local Structures, Gap\nStatistics, Class Consistency Ratio, and a Cluster Overlap Index CCR and\nCOIbased algorithm to calculate the best value of k for K-Means clustering. The\nresults of comparative experiments show that the proposed approach achieves up\nto 99 percent faster execution times on high-dimensional datasets while\nretaining both precision and scalability, making it highly suitable for real\ntime clustering needs or scenarios demanding efficient clustering with minimal\nresource utilization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08311v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08334", "title": "CoCo-Bot: Energy-based Composable Concept Bottlenecks for Interpretable Generative Models", "authors": ["Sangwon Kim", "In-su Jang", "Pyongkun Kim", "Kwang-Ju Kim"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08334v1", "summary": "Concept Bottleneck Models (CBMs) provide interpretable and controllable\ngenerative modeling by routing generation through explicit,\nhuman-understandable concepts. However, previous generative CBMs often rely on\nauxiliary visual cues at the bottleneck to compensate for information not\ncaptured by the concepts, which undermines interpretability and\ncompositionality. We propose CoCo-Bot, a post-hoc, composable concept\nbottleneck generative model that eliminates the need for auxiliary cues by\ntransmitting all information solely through explicit concepts. Guided by\ndiffusion-based energy functions, CoCo-Bot supports robust post-hoc\ninterventions-such as concept composition and negation-across arbitrary\nconcepts. Experiments using StyleGAN2 pre-trained on CelebA-HQ show that\nCoCo-Bot improves concept-level controllability and interpretability, while\nmaintaining competitive visual quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08334v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08677", "title": "Qualitative Assessment of Low Power Wide Area Network Protocols and their Security Aspect", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphal"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08677v1", "summary": "There are currently many communication options in the Internet of Things,\neven in particular areas such as constrained and battery-powered devices, such\nas Low Power Wide Area Networks. Understanding the differences and\ncharacteristics of each option is a challenge, even for professionals and\nresearchers in the field. To meet this need, this work analyses the qualitative\ncharacteristics of Low Power Wide Area Network protocols and the challenges and\nopportunities of using constrained devices for sparse networks based on\nlong-life batteries. For this study, a bibliographic survey of the literature\nwas carried out as an analysis of three protocols (LoRaWAN, NB-IoT, and\nSigfox), and a detailing of the first one. As a result, there is a discussion\nabout the chosen network protocol and its use in IoT solutions with sparse\nsensors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08677v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2501.04729", "title": "Stability analysis through folds: An end-loaded elastic with a lever arm", "authors": ["Siva Prasad Chakri Dhanakoti"], "categories": ["math.OC", "cond-mat.soft", "cs.RO"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      22 pages, 12 figures", "url": "http://arxiv.org/abs/2501.04729v3", "summary": "Many physical systems can be modelled as parameter-dependent variational\nproblems. In numerous cases, multiple equilibria co-exist, requiring the\nevaluation of their stability, and the monitoring of transitions between them.\nGenerally, the stability characteristics of the equilibria change near folds in\nthe parameter space. The direction of stability changes is embedded in a\nspecific projection of the solutions, known as distinguished bifurcation\ndiagrams. In this article, we identify such projections for variational\nproblems characterized by fixed-free ends -- a class of problems frequently\nencountered in mechanics. Using these diagrams, we study an Elastica subject to\nan end load applied through a rigid lever arm. Several instances of snap-back\ninstability are reported, along with their dependence on system parameters\nthrough numerical examples. These findings have potential applications in the\ndesign of soft robot arms and other actuator designs.", "comment": "22 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2501.04729v3", "cate": "math.OC", "date": "2025-01-06", "updated": "2025-07-11"}
{"id": "2507.08017", "title": "Mechanistic Indicators of Understanding in Large Language Models", "authors": ["Pierre Beckmann", "Matthieu Queloz"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2507.08017v1", "summary": "Recent findings in mechanistic interpretability (MI), the field probing the\ninner workings of Large Language Models (LLMs), challenge the view that these\nmodels rely solely on superficial statistics. Here, we offer an accessible\nsynthesis of these findings that doubles as an introduction to MI, all while\nintegrating these findings within a novel theoretical framework for thinking\nabout machine understanding. We argue that LLMs develop internal structures\nthat are functionally analogous to the kind of understanding that consists in\nseeing connections. To sharpen this idea, we propose a three-tiered conception\nof machine understanding. First, conceptual understanding emerges when a model\nforms \"features\" as directions in latent space, thereby learning the\nconnections between diverse manifestations of something. Second,\nstate-of-the-world understanding emerges when a model learns contingent factual\nconnections between features and dynamically tracks changes in the world.\nThird, principled understanding emerges when a model ceases to rely on a\ncollection of memorized facts and discovers a \"circuit\" that connects these\nfacts. However, we conclude by exploring the \"parallel mechanisms\" phenomenon,\narguing that while LLMs exhibit forms of understanding, their cognitive\narchitecture remains different from ours, and the debate should shift from\nwhether LLMs understand to how their strange minds work.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2507.08017v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.08317", "title": "A Comprehensively Adaptive Architectural Optimization-Ingrained Quantum Neural Network Model for Cloud Workloads Prediction", "authors": ["Jitendra Kumar", "Deepika Saxena", "Kishu Gupta", "Satyam Kumar", "Ashutosh Kumar Singh"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08317v1", "summary": "Accurate workload prediction and advanced resource reservation are\nindispensably crucial for managing dynamic cloud services. Traditional neural\nnetworks and deep learning models frequently encounter challenges with diverse,\nhigh-dimensional workloads, especially during sudden resource demand changes,\nleading to inefficiencies. This issue arises from their limited optimization\nduring training, relying only on parametric (inter-connection weights)\nadjustments using conventional algorithms. To address this issue, this work\nproposes a novel Comprehensively Adaptive Architectural Optimization-based\nVariable Quantum Neural Network (CA-QNN), which combines the efficiency of\nquantum computing with complete structural and qubit vector parametric\nlearning. The model converts workload data into qubits, processed through qubit\nneurons with Controlled NOT-gated activation functions for intuitive pattern\nrecognition. In addition, a comprehensive architecture optimization algorithm\nfor networks is introduced to facilitate the learning and propagation of the\nstructure and parametric values in variable-sized QNNs. This algorithm\nincorporates quantum adaptive modulation and size-adaptive recombination during\ntraining process. The performance of CA-QNN model is thoroughly investigated\nagainst seven state-of-the-art methods across four benchmark datasets of\nheterogeneous cloud workloads. The proposed model demonstrates superior\nprediction accuracy, reducing prediction errors by up to 93.40% and 91.27%\ncompared to existing deep learning and QNN-based approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08317v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08340", "title": "Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": ["Jia-Xuan Jiang", "Jiashuai Liu", "Hongtao Wu", "Yifeng Wu", "Zhong Wang", "Qi Bi", "Yefeng Zheng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM 25", "url": "http://arxiv.org/abs/2507.08340v1", "summary": "Deep learning has shown remarkable performance in integrating multimodal data\nfor survival prediction. However, existing multimodal methods mainly focus on\nsingle cancer types and overlook the challenge of generalization across\ncancers. In this work, we are the first to reveal that multimodal prognosis\nmodels often generalize worse than unimodal ones in cross-cancer scenarios,\ndespite the critical need for such robustness in clinical practice. To address\nthis, we propose a new task: Cross-Cancer Single Domain Generalization for\nMultimodal Prognosis, which evaluates whether models trained on a single cancer\ntype can generalize to unseen cancers. We identify two key challenges: degraded\nfeatures from weaker modalities and ineffective multimodal integration. To\ntackle these, we introduce two plug-and-play modules: Sparse Dirac Information\nRebalancer (SDIR) and Cancer-aware Distribution Entanglement (CADE). SDIR\nmitigates the dominance of strong features by applying Bernoulli-based\nsparsification and Dirac-inspired stabilization to enhance weaker modality\nsignals. CADE, designed to synthesize the target domain distribution, fuses\nlocal morphological cues and global gene expression in latent space.\nExperiments on a four-cancer-type benchmark demonstrate superior\ngeneralization, laying the foundation for practical, robust cross-cancer\nmultimodal prognosis. Code is available at\nhttps://github.com/HopkinsKwong/MCCSDG", "comment": "Accepted by ACMMM 25", "pdf_url": "http://arxiv.org/pdf/2507.08340v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08717", "title": "Knowledge Graph-Based approach for Sustainable 6G End-to-End System Design", "authors": ["Akshay Jain", "Sylvaine Kerboeuf", "Sokratis Barmpounakis", "Cristóbal Vinagre Z.", "Stefan Wendt", "Dinh Thai Bui", "Pol Alemany", "Riccardo Nicolicchia", "José María Jorquera Valero", "Dani Korpi", "Mohammad Hossein Moghaddam", "Mikko A. Uusitalo", "Patrik Rugeland", "Abdelkader Outtagarts", "Karthik Upadhya", "Panagiotis Demestichas", "Raul Muñoz", "Manuel Gil Pérez", "Daniel Adanza", "Ricard Vilalta"], "categories": ["cs.NI", "00"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      The paper is submitted to IEEE Open Journal of the Communications Society (IEEE OJCOMS)", "url": "http://arxiv.org/abs/2507.08717v1", "summary": "Previous generations of cellular communication, such as 5G, have been\ndesigned with the objective of improving key performance indicators (KPIs) such\nas throughput, latency, etc. However, to meet the evolving KPI demands as well\nas the ambitious sustainability targets for the ICT industry, 6G will need to\nbe designed differently. Concretely, 6G will need to consider both the\nperformance and sustainability targets for the various use cases it will serve.\nMoreover, like previous generations, 6G will have various candidate\ntechnological enablers, making the design space of the system even more\ncomplex. Furthermore, given the subjective nature of the sustainability\nindicators, in particular social sustainability, there is a significant gap in\nliterature on how technical enablers and 6G System design can be linked to\nthem. Hence, in this article a novel method for 6G end-to-end (E2E) system\ndesign based on Knowledge graphs (KG) has been introduced. It considers as its\ninput: the use case KPIs, use case sustainability requirements expressed as Key\nValues (KV) and KV Indicators (KVIs), the ability of the technological enablers\nto satisfy these KPIs and KVIs, the 6G system design principles defined in\nHexa-X-II project, the maturity of a technological enabler and the dependencies\nbetween the various enablers. As part of the KG method, a novel approach for\ndetermining the key values a technological enabler addresses, has also been\nintroduced. The effectiveness of the KG method was demonstrated by its\napplication in designing the 6G E2E system for the cooperating mobile robot use\ncase defined in the Hexa-X-II project, where 82 enablers were selected. Lastly,\nresults from proof-of-concept demonstrations for a subset of the selected\nenablers have also been provided, which reinforce the efficacy of the KG method\nfor designing a sustainable 6G system.", "comment": "The paper is submitted to IEEE Open Journal of the Communications\n  Society (IEEE OJCOMS)", "pdf_url": "http://arxiv.org/pdf/2507.08717v1", "cate": "cs.NI", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.07656", "title": "DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving", "authors": ["Xiaosong Jia", "Junqi You", "Zhiyuan Zhang", "Junchi Yan"], "categories": ["cs.LG", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by ICLR2025; Fix Typo", "url": "http://arxiv.org/abs/2503.07656v2", "summary": "End-to-end autonomous driving (E2E-AD) has emerged as a trend in the field of\nautonomous driving, promising a data-driven, scalable approach to system\ndesign. However, existing E2E-AD methods usually adopt the sequential paradigm\nof perception-prediction-planning, which leads to cumulative errors and\ntraining instability. The manual ordering of tasks also limits the system`s\nability to leverage synergies between tasks (for example, planning-aware\nperception and game-theoretic interactive prediction and planning). Moreover,\nthe dense BEV representation adopted by existing methods brings computational\nchallenges for long-range perception and long-term temporal fusion. To address\nthese challenges, we present DriveTransformer, a simplified E2E-AD framework\nfor the ease of scaling up, characterized by three key features: Task\nParallelism (All agent, map, and planning queries direct interact with each\nother at each block), Sparse Representation (Task queries direct interact with\nraw sensor features), and Streaming Processing (Task queries are stored and\npassed as history information). As a result, the new framework is composed of\nthree unified operations: task self-attention, sensor cross-attention, temporal\ncross-attention, which significantly reduces the complexity of system and leads\nto better training stability. DriveTransformer achieves state-of-the-art\nperformance in both simulated closed-loop benchmark Bench2Drive and real world\nopen-loop benchmark nuScenes with high FPS.", "comment": "Accepted by ICLR2025; Fix Typo", "pdf_url": "http://arxiv.org/pdf/2503.07656v2", "cate": "cs.LG", "date": "2025-03-07", "updated": "2025-07-11"}
{"id": "2507.08020", "title": "Circumventing Safety Alignment in Large Language Models Through Embedding Space Toxicity Attenuation", "authors": ["Zhibo Zhang", "Yuxi Li", "Kailong Wang", "Shuai Yuan", "Ling Shi", "Haoyu Wang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08020v1", "summary": "Large Language Models (LLMs) have achieved remarkable success across domains\nsuch as healthcare, education, and cybersecurity. However, this openness also\nintroduces significant security risks, particularly through embedding space\npoisoning, which is a subtle attack vector where adversaries manipulate the\ninternal semantic representations of input data to bypass safety alignment\nmechanisms. While previous research has investigated universal perturbation\nmethods, the dynamics of LLM safety alignment at the embedding level remain\ninsufficiently understood. Consequently, more targeted and accurate adversarial\nperturbation techniques, which pose significant threats, have not been\nadequately studied.\n  In this work, we propose ETTA (Embedding Transformation Toxicity\nAttenuation), a novel framework that identifies and attenuates\ntoxicity-sensitive dimensions in embedding space via linear transformations.\nETTA bypasses model refusal behaviors while preserving linguistic coherence,\nwithout requiring model fine-tuning or access to training data. Evaluated on\nfive representative open-source LLMs using the AdvBench benchmark, ETTA\nachieves a high average attack success rate of 88.61%, outperforming the best\nbaseline by 11.34%, and generalizes to safety-enhanced models (e.g., 77.39% ASR\non instruction-tuned defenses). These results highlight a critical\nvulnerability in current alignment strategies and underscore the need for\nembedding-aware defenses.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08020v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08355", "title": "scE$^2$TM: Toward Interpretable Single-Cell Embedding via Topic Modeling", "authors": ["Hegang Chen", "Yuyin Lu", "Zhiming Dai", "Fu Lee Wang", "Qing Li", "Yanghui Rao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08355v1", "summary": "Recent advances in sequencing technologies have enabled researchers to\nexplore cellular heterogeneity at single-cell resolution. Meanwhile,\ninterpretability has gained prominence parallel to the rapid increase in the\ncomplexity and performance of deep learning models. In recent years, topic\nmodels have been widely used for interpretable single-cell embedding learning\nand clustering analysis, which we refer to as single-cell embedded topic\nmodels. However, previous studies evaluated the interpretability of the models\nmainly through qualitative analysis, and these single-cell embedded topic\nmodels suffer from the potential problem of interpretation collapse.\nFurthermore, their neglect of external biological knowledge constrains\nanalytical performance. Here, we present scE2TM, an external knowledge-guided\nsingle-cell embedded topic model that provides a high-quality cell embedding\nand strong interpretation, contributing to comprehensive scRNA-seq data\nanalysis. Our comprehensive evaluation across 20 scRNA-seq datasets\ndemonstrates that scE2TM achieves significant clustering performance gains\ncompared to 7 state-of-the-art methods. In addition, we propose a new\ninterpretability evaluation benchmark that introduces 10 metrics to\nquantitatively assess the interpretability of single-cell embedded topic\nmodels. The results show that the interpretation provided by scE2TM performs\nencouragingly in terms of diversity and consistency with the underlying\nbiological signals, contributing to a better revealing of the underlying\nbiological mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08355v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08343", "title": "Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation", "authors": ["Junxue Yang", "Xin Liao", "Weixuan Tang", "Jianhua Yang", "Zheng Qin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08343v1", "summary": "Deep hiding has been exploring the hiding capability of deep learning-based\nmodels, aiming to conceal image-level messages into cover images and reveal\nthem from generated stego images. Existing schemes are easily detected by\nsteganalyzers due to their large payloads and their limitation to feature\nextraction based solely on either pure convolution or pure transformer\noperators within a single range, as well as pixel-level loss constraints. To\naddress the issue, in this paper, we introduce generation-based adversarial\nattacks into color JPEG image deep hiding and propose a multi-range\nrepresentations-driven adversarial stego generation framework called MRAG from\na steganalysis perspective. Specifically, we integrate the local-range neighbor\nreception characteristic of the convolution and the global-range dependency\nmodeling of the transformer to construct MRAG. Meanwhile, we use the\ntransformed images obtained through coarse-grained and fine-grained frequency\ndecomposition as inputs, introducing multi-grained information. Furthermore, a\nfeatures angle-norm disentanglement loss is designed to constrain the generated\nstegos closer to covers in the angle and norm space of the steganalyzer's\nclassified features. Consequently, small yet effective adversarial\nperturbations can be injected into the process of generating stegos, ensuring\nthat stegos maintain favorable secret restorability and imperceptibility.\nExtensive experiments demonstrate that MRAG can achieve state-of-the-art\nperformance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08343v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08021", "title": "Unveiling Effective In-Context Configurations for Image Captioning: An External & Internal Analysis", "authors": ["Li Li", "Yongliang Wu", "Jingze Zhu", "Jiawei Peng", "Jianfei Cai", "Xu Yang"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      16 pages, 11 figures", "url": "http://arxiv.org/abs/2507.08021v1", "summary": "The evolution of large models has witnessed the emergence of In-Context\nLearning (ICL) capabilities. In Natural Language Processing (NLP), numerous\nstudies have demonstrated the effectiveness of ICL. Inspired by the success of\nLarge Language Models (LLMs), researchers have developed Large Multimodal\nModels (LMMs) with ICL capabilities. However, explorations of demonstration\nconfiguration for multimodal ICL remain preliminary. Additionally, the\ncontrollability of In-Context Examples (ICEs) provides an efficient and\ncost-effective means to observe and analyze the inference characteristics of\nLMMs under varying inputs. This paper conducts a comprehensive external and\ninternal investigation of multimodal in-context learning on the image\ncaptioning task. Externally, we explore demonstration configuration strategies\nthrough three dimensions: shot number, image retrieval, and caption assignment.\nWe employ multiple metrics to systematically and thoroughly evaluate and\nsummarize key findings. Internally, we analyze typical LMM attention\ncharacteristics and develop attention-based metrics to quantify model\nbehaviors. We also conduct auxiliary experiments to explore the feasibility of\nattention-driven model acceleration and compression. We further compare\nperformance variations between LMMs with identical model design and pretraining\nstrategies and explain the differences from the angles of pre-training data\nfeatures. Our study reveals both how ICEs configuration strategies impact model\nperformance through external experiments and characteristic typical patterns\nthrough internal inspection, providing dual perspectives for understanding\nmultimodal ICL in LMMs. Our method of combining external and internal analysis\nto investigate large models, along with our newly proposed metrics, can be\napplied to broader research areas.", "comment": "16 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.08021v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08362", "title": "Leveraging Machine Learning and Enhanced Parallelism Detection for BPMN Model Generation from Text", "authors": ["Phuong Nam Lê", "Charlotte Schneider-Depré", "Alexandre Goossens", "Alexander Stevens", "Aurélie Leribaux", "Johannes De Smedt"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08362v1", "summary": "Efficient planning, resource management, and consistent operations often rely\non converting textual process documents into formal Business Process Model and\nNotation (BPMN) models. However, this conversion process remains time-intensive\nand costly. Existing approaches, whether rule-based or machine-learning-based,\nstill struggle with writing styles and often fail to identify parallel\nstructures in process descriptions.\n  This paper introduces an automated pipeline for extracting BPMN models from\ntext, leveraging the use of machine learning and large language models. A key\ncontribution of this work is the introduction of a newly annotated dataset,\nwhich significantly enhances the training process. Specifically, we augment the\nPET dataset with 15 newly annotated documents containing 32 parallel gateways\nfor model training, a critical feature often overlooked in existing datasets.\nThis addition enables models to better capture parallel structures, a common\nbut complex aspect of process descriptions. The proposed approach demonstrates\nadequate performance in terms of reconstruction accuracy, offering a promising\nfoundation for organizations to accelerate BPMN model creation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08362v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08344", "title": "MM-Gesture: Towards Precise Micro-Gesture Recognition through Multimodal Fusion", "authors": ["Jihao Gu", "Fei Wang", "Kun Li", "Yanyan Wei", "Zhiliang Wu", "Dan Guo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08344v1", "summary": "In this paper, we present MM-Gesture, the solution developed by our team\nHFUT-VUT, which ranked 1st in the micro-gesture classification track of the 3rd\nMiGA Challenge at IJCAI 2025, achieving superior performance compared to\nprevious state-of-the-art methods. MM-Gesture is a multimodal fusion framework\ndesigned specifically for recognizing subtle and short-duration micro-gestures\n(MGs), integrating complementary cues from joint, limb, RGB video,\nTaylor-series video, optical-flow video, and depth video modalities. Utilizing\nPoseConv3D and Video Swin Transformer architectures with a novel\nmodality-weighted ensemble strategy, our method further enhances RGB modality\nperformance through transfer learning pre-trained on the larger MA-52 dataset.\nExtensive experiments on the iMiGUE benchmark, including ablation studies\nacross different modalities, validate the effectiveness of our proposed\napproach, achieving a top-1 accuracy of 73.213%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08344v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08034", "title": "Integrating External Tools with Large Language Models to Improve Accuracy", "authors": ["Nripesh Niketan", "Hadj Batatia"], "categories": ["cs.CL", "cs.AI", "cs.LG", "68T50", "I.2.7; I.2.6"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 3 figures, 2 tables. Extended version of paper published in Proceedings of International Conference on Information Technology and Applications, Springer Nature Singapore, 2025, pp. 409-421. This version includes additional experimental results comparing against GPT-4o, LLaMA-Large, Mistral-Large, and Phi-Large, expanded evaluation methodology, and enhanced analysis", "url": "http://arxiv.org/abs/2507.08034v1", "summary": "This paper deals with improving querying large language models (LLMs). It is\nwell-known that without relevant contextual information, LLMs can provide poor\nquality responses or tend to hallucinate. Several initiatives have proposed\nintegrating LLMs with external tools to provide them with up-to-date data to\nimprove accuracy. In this paper, we propose a framework to integrate external\ntools to enhance the capabilities of LLMs in answering queries in educational\nsettings. Precisely, we develop a framework that allows accessing external APIs\nto request additional relevant information. Integrated tools can also provide\ncomputational capabilities such as calculators or calendars. The proposed\nframework has been evaluated using datasets from the Multi-Modal Language\nUnderstanding (MMLU) collection. The data consists of questions on mathematical\nand scientific reasoning. Results compared to state-of-the-art language models\nshow that the proposed approach significantly improves performance. Our Athena\nframework achieves 83% accuracy in mathematical reasoning and 88% in scientific\nreasoning, substantially outperforming all tested models including GPT-4o,\nLLaMA-Large, Mistral-Large, Phi-Large, and GPT-3.5, with the best baseline\nmodel (LLaMA-Large) achieving only 67% and 79% respectively. These promising\nresults open the way to creating complex computing ecosystems around LLMs to\nmake their use more natural to support various tasks and activities.", "comment": "9 pages, 3 figures, 2 tables. Extended version of paper published in\n  Proceedings of International Conference on Information Technology and\n  Applications, Springer Nature Singapore, 2025, pp. 409-421. This version\n  includes additional experimental results comparing against GPT-4o,\n  LLaMA-Large, Mistral-Large, and Phi-Large, expanded evaluation methodology,\n  and enhanced analysis", "pdf_url": "http://arxiv.org/pdf/2507.08034v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08365", "title": "Prediction of Lane Change Intentions of Human Drivers using an LSTM, a CNN and a Transformer", "authors": ["Francesco De Cristofaro", "Felix Hofbaur", "Aixi Yang", "Arno Eichberger"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages, 18 figures", "url": "http://arxiv.org/abs/2507.08365v1", "summary": "Lane changes of preceding vehicles have a great impact on the motion planning\nof automated vehicles especially in complex traffic situations. Predicting them\nwould benefit the public in terms of safety and efficiency. While many research\nefforts have been made in this direction, few concentrated on predicting\nmaneuvers within a set time interval compared to predicting at a set prediction\ntime. In addition, there exist a lack of comparisons between different\narchitectures to try to determine the best performing one and to assess how to\ncorrectly choose the input for such models. In this paper the structure of an\nLSTM, a CNN and a Transformer network are described and implemented to predict\nthe intention of human drivers to perform a lane change. We show how the data\nwas prepared starting from a publicly available dataset (highD), which features\nwere used, how the networks were designed and finally we compare the results of\nthe three networks with different configurations of input data. We found that\ntransformer networks performed better than the other networks and was less\naffected by overfitting. The accuracy of the method spanned from $82.79\\%$ to\n$96.73\\%$ for different input configurations and showed overall good\nperformances considering also precision and recall.", "comment": "14 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.08365v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08357", "title": "Cycle Context Verification for In-Context Medical Image Segmentation", "authors": ["Shishuai Hu", "Zehui Liao", "Liangli Zhen", "Huazhu Fu", "Yong Xia"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      MICCAI 2025", "url": "http://arxiv.org/abs/2507.08357v1", "summary": "In-context learning (ICL) is emerging as a promising technique for achieving\nuniversal medical image segmentation, where a variety of objects of interest\nacross imaging modalities can be segmented using a single model. Nevertheless,\nits performance is highly sensitive to the alignment between the query image\nand in-context image-mask pairs. In a clinical scenario, the scarcity of\nannotated medical images makes it challenging to select optimal in-context\npairs, and fine-tuning foundation ICL models on contextual data is infeasible\ndue to computational costs and the risk of catastrophic forgetting. To address\nthis challenge, we propose Cycle Context Verification (CCV), a novel framework\nthat enhances ICL-based medical image segmentation by enabling\nself-verification of predictions and accordingly enhancing contextual\nalignment. Specifically, CCV employs a cyclic pipeline in which the model\ninitially generates a segmentation mask for the query image. Subsequently, the\nroles of the query and an in-context pair are swapped, allowing the model to\nvalidate its prediction by predicting the mask of the original in-context\nimage. The accuracy of this secondary prediction serves as an implicit measure\nof the initial query segmentation. A query-specific prompt is introduced to\nalter the query image and updated to improve the measure, thereby enhancing the\nalignment between the query and in-context pairs. We evaluated CCV on seven\nmedical image segmentation datasets using two ICL foundation models,\ndemonstrating its superiority over existing methods. Our results highlight\nCCV's ability to enhance ICL-based segmentation, making it a robust solution\nfor universal medical image segmentation. The code will be available at\nhttps://github.com/ShishuaiHu/CCV.", "comment": "MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.08357v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08037", "title": "CRISP: Complex Reasoning with Interpretable Step-based Plans", "authors": ["Matan Vetzler", "Koren Lazar", "Guy Uziel", "Eran Hirsch", "Ateret Anaby-Tavor", "Leshem Choshen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08037v1", "summary": "Recent advancements in large language models (LLMs) underscore the need for\nstronger reasoning capabilities to solve complex problems effectively. While\nChain-of-Thought (CoT) reasoning has been a step forward, it remains\ninsufficient for many domains. A promising alternative is explicit high-level\nplan generation, but existing approaches largely assume that LLMs can produce\neffective plans through few-shot prompting alone, without additional training.\nIn this work, we challenge this assumption and introduce CRISP (Complex\nReasoning with Interpretable Step-based Plans), a multi-domain dataset of\nhigh-level plans for mathematical reasoning and code generation. The plans in\nCRISP are automatically generated and rigorously validated--both intrinsically,\nusing an LLM as a judge, and extrinsically, by evaluating their impact on\ndownstream task performance. We demonstrate that fine-tuning a small model on\nCRISP enables it to generate higher-quality plans than much larger models using\nfew-shot prompting, while significantly outperforming Chain-of-Thought\nreasoning. Furthermore, our out-of-domain evaluation reveals that fine-tuning\non one domain improves plan generation in the other, highlighting the\ngeneralizability of learned planning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08037v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08379", "title": "Advances in Machine Learning: Where Can Quantum Techniques Help?", "authors": ["Samarth Kashyap", "Rohit K Ramakrishnan", "Kumari Jyoti", "Apoorva D Patel"], "categories": ["cs.LG", "quant-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      28 pages, 1 figure", "url": "http://arxiv.org/abs/2507.08379v1", "summary": "Quantum Machine Learning (QML) represents a promising frontier at the\nintersection of quantum computing and artificial intelligence, aiming to\nleverage quantum computational advantages to enhance data-driven tasks. This\nreview explores the potential of QML to address the computational bottlenecks\nof classical machine learning, particularly in processing complex datasets. We\nintroduce the theoretical foundations of QML, including quantum data encoding,\nquantum learning theory and optimization techniques, while categorizing QML\napproaches based on data type and computational architecture. It is\nwell-established that quantum computational advantages are problem-dependent,\nand so potentially useful directions for QML need to be systematically\nidentified. Key developments, such as Quantum Principal Component Analysis,\nquantum-enhanced sensing and applications in material science, are critically\nevaluated for their theoretical speed-ups and practical limitations. The\nchallenges posed by Noisy Intermediate-Scale Quantum (NISQ) devices, including\nhardware noise, scalability constraints and data encoding overheads, are\ndiscussed in detail. We also outline future directions, emphasizing the need\nfor quantum-native algorithms, improved error correction, and realistic\nbenchmarks to bridge the gap between theoretical promise and practical\ndeployment. This comprehensive analysis underscores that while QML has\nsignificant potential for specific applications such as quantum chemistry and\nsensing, its broader utility in real-world scenarios remains contingent on\novercoming technological and methodological hurdles.", "comment": "28 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.08379v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08367", "title": "Understanding Driving Risks using Large Language Models: Toward Elderly Driver Assessment", "authors": ["Yuki Yoshihara", "Linjing Jiang", "Nihan Karatas", "Hitoshi Kanamori", "Asuka Harada", "Takahiro Tanaka"], "categories": ["cs.CV", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08367v1", "summary": "This study investigates the potential of a multimodal large language model\n(LLM), specifically ChatGPT-4o, to perform human-like interpretations of\ntraffic scenes using static dashcam images. Herein, we focus on three judgment\ntasks relevant to elderly driver assessments: evaluating traffic density,\nassessing intersection visibility, and recognizing stop signs recognition.\nThese tasks require contextual reasoning rather than simple object detection.\nUsing zero-shot, few-shot, and multi-shot prompting strategies, we evaluated\nthe performance of the model with human annotations serving as the reference\nstandard. Evaluation metrics included precision, recall, and F1-score. Results\nindicate that prompt design considerably affects performance, with recall for\nintersection visibility increasing from 21.7% (zero-shot) to 57.0%\n(multi-shot). For traffic density, agreement increased from 53.5% to 67.6%. In\nstop-sign detection, the model demonstrated high precision (up to 86.3%) but a\nlower recall (approximately 76.7%), indicating a conservative response\ntendency. Output stability analysis revealed that humans and the model faced\ndifficulties interpreting structurally ambiguous scenes. However, the model's\nexplanatory texts corresponded with its predictions, enhancing\ninterpretability. These findings suggest that, with well-designed prompts, LLMs\nhold promise as supportive tools for scene-level driving risk assessments.\nFuture studies should explore scalability using larger datasets, diverse\nannotators, and next-generation model architectures for elderly driver\nassessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08367v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08281", "title": "Fast and Interactive Byzantine Fault-tolerant Web Services via Session-Based Consensus Decoupling", "authors": ["Ahmad Zaki Akmal", "Azkario Rizky Pratama", "Guntur Dharma Putra"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      6 pages, 5 figures. Accepted to IEEE MetaCom 2025 as a short paper", "url": "http://arxiv.org/abs/2507.08281v1", "summary": "Byzantine fault-tolerant (BFT) web services provide critical integrity\nguarantees for distributed applications but face significant latency challenges\nthat hinder interactive user experiences. We propose a novel two-layer\narchitecture that addresses this fundamental tension between security and\nresponsiveness in BFT systems. Our approach introduces a session-aware\ntransaction buffer layer (Layer 2) that delivers immediate feedback to users\nthrough consensus simulation, while periodically committing batched operations\nto a fully Byzantine fault-tolerant consensus layer (Layer 1). By separating\ninteractive operations from consensus finalization, our system achieves\nresponsive user experiences of under 200ms, while maintaining strong BFT\nsecurity guarantees. We demonstrate the efficacy of our architecture through a\nsupply chain management implementation, where operators require both immediate\nfeedback during multi-step workflows and tamper-proof record keeping. Our\nevaluation shows that our Layer 2 operations perform four times faster than the\nLayer 1 counterpart, while substantially preserving the end-to-end transaction\nintegrity. Our approach enables BFT applications in domains previously\nconsidered impractical due to latency constraints, such as metaverse\nenvironments, where users require both responsive interaction and guaranteed\nstate consistency.", "comment": "6 pages, 5 figures. Accepted to IEEE MetaCom 2025 as a short paper", "pdf_url": "http://arxiv.org/pdf/2507.08281v1", "cate": "cs.DC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08038", "title": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research", "authors": ["Talor Abramovich", "Gal Chechik"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08038v1", "summary": "Autonomous agents built on language models (LMs) are showing increasing\npopularity in many fields, including scientific research. AI co-scientists aim\nto support or automate parts of the research process using these agents. A key\ncomponent of empirical AI research is the design of ablation experiments. To\nthis end, we introduce AblationBench, a benchmark suite for evaluating agents\non ablation planning tasks in empirical AI research. It includes two tasks:\nAuthorAblation, which helps authors propose ablation experiments based on a\nmethod section and contains 83 instances, and ReviewerAblation, which helps\nreviewers find missing ablations in a full paper and contains 350 instances.\nFor both tasks, we develop LM-based judges that serve as an automatic\nevaluation framework. Our experiments with frontier LMs show that these tasks\nremain challenging, with the best-performing LM system identifying only 29% of\nthe original ablations on average. Lastly, we analyze the limitations of\ncurrent LMs on these tasks, and find that chain-of-thought prompting\noutperforms the currently existing agent-based approach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08038v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08382", "title": "Two-cluster test", "authors": ["Xinying Liu", "Lianyu Hu", "Mudi Jiang", "Simen Zhang", "Jun Lou", "Zengyou He"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08382v1", "summary": "Cluster analysis is a fundamental research issue in statistics and machine\nlearning. In many modern clustering methods, we need to determine whether two\nsubsets of samples come from the same cluster. Since these subsets are usually\ngenerated by certain clustering procedures, the deployment of classic\ntwo-sample tests in this context would yield extremely smaller p-values,\nleading to inflated Type-I error rate. To overcome this bias, we formally\nintroduce the two-cluster test issue and argue that it is a totally different\nsignificance testing issue from conventional two-sample test. Meanwhile, we\npresent a new method based on the boundary points between two subsets to derive\nan analytical p-value for the purpose of significance quantification.\nExperiments on both synthetic and real data sets show that the proposed test is\nable to significantly reduce the Type-I error rate, in comparison with several\nclassic two-sample testing methods. More importantly, the practical usage of\nsuch two-cluster test is further verified through its applications in\ntree-based interpretable clustering and significance-based hierarchical\nclustering.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08382v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08375", "title": "Unsupervised Methods for Video Quality Improvement: A Survey of Restoration and Enhancement Techniques", "authors": ["Alexandra Malyugina", "Yini Li", "Joanne Lin", "Nantheera Anantrasirichai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08375v1", "summary": "Video restoration and enhancement are critical not only for improving visual\nquality, but also as essential pre-processing steps to boost the performance of\na wide range of downstream computer vision tasks. This survey presents a\ncomprehensive review of video restoration and enhancement techniques with a\nparticular focus on unsupervised approaches. We begin by outlining the most\ncommon video degradations and their underlying causes, followed by a review of\nearly conventional and deep learning methods-based, highlighting their\nstrengths and limitations. We then present an in-depth overview of unsupervised\nmethods, categorise by their fundamental approaches, including domain\ntranslation, self-supervision signal design and blind spot or noise-based\nmethods. We also provide a categorization of loss functions employed in\nunsupervised video restoration and enhancement, and discuss the role of paired\nsynthetic datasets in enabling objective evaluation. Finally, we identify key\nchallenges and outline promising directions for future research in this field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08375v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08348", "title": "Content-Oblivious Leader Election in 2-Edge-Connected Networks", "authors": ["Yi-Jun Chang", "Lyuting Chen", "Haoran Zhou"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08348v1", "summary": "Censor-Hillel, Cohen, Gelles, and Sela (PODC 2022 \\& Distributed Computing\n2023) studied fully-defective asynchronous networks, where communication\nchannels may suffer an extreme form of alteration errors, rendering messages\ncompletely corrupted. The model is equivalent to content-oblivious computation,\nwhere nodes communicate solely via pulses. They showed that if the network is\n2-edge-connected, then any algorithm for a noiseless setting can be simulated\nin the fully-defective setting; otherwise, no non-trivial computation is\npossible in the fully-defective setting. However, their simulation requires a\npredesignated leader, which they conjectured to be necessary for any\nnon-trivial content-oblivious task.\n  Recently, Frei, Gelles, Ghazy, and Nolin (DISC 2024) refuted this conjecture\nfor the special case of oriented ring topology. They designed two asynchronous\ncontent-oblivious leader election algorithms with message complexity $O(n \\cdot\n\\mathsf{ID}_{\\max})$, where $n$ is the number of nodes and $\\mathsf{ID}_{\\max}$\nis the maximum $\\mathsf{ID}$. The first algorithm stabilizes in unoriented\nrings without termination detection. The second algorithm quiescently\nterminates in oriented rings, thus enabling the execution of the simulation\nalgorithm after leader election.\n  In this work, we present an asynchronous content-oblivious leader election\nalgorithm that quiescently terminates in any 2-edge connected network with\nmessage complexity $O(m \\cdot N \\cdot \\mathsf{ID}_{\\min})$, where $m$ is the\nnumber of edges, $N$ is a known upper bound on the number of nodes, and\n$\\mathsf{ID}_{\\min}$ is the smallest $\\mathsf{ID}$. Combined with the previous\nsimulation result, our finding implies that any algorithm from the noiseless\nsetting can be simulated in the fully-defective setting without assuming a\npreselected leader, entirely refuting the original conjecture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08348v1", "cate": "cs.DC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08045", "title": "Krul: Efficient State Restoration for Multi-turn Conversations with Dynamic Cross-layer KV Sharing", "authors": ["Junyi Wen", "Junyuan Liang", "Zicong Hong", "Wuhui Chen", "Zibin Zheng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08045v1", "summary": "Efficient state restoration in multi-turn conversations with large language\nmodels (LLMs) remains a critical challenge, primarily due to the overhead of\nrecomputing or loading full key-value (KV) caches for all historical tokens. To\naddress this, existing approaches compress KV caches across adjacent layers\nwith highly similar attention patterns. However, these methods often apply a\nfixed compression scheme across all conversations, selecting the same layer\npairs for compression without considering conversation-specific attention\ndynamics. This static strategy overlooks variability in attention pattern\nsimilarity across different conversations, which can lead to noticeable\naccuracy degradation.\n  We present Krul, a multi-turn LLM inference system that enables accurate and\nefficient KV cache restoration. Krul dynamically selects compression strategies\nbased on attention similarity across layer pairs and uses a\nrecomputation-loading pipeline to restore the KV cache. It introduces three key\ninnovations: 1) a preemptive compression strategy selector to preserve critical\ncontext for future conversation turns and selects a customized strategy for the\nconversation; 2) a token-wise heterogeneous attention similarity estimator to\nmitigate the attention similarity computation and storage overhead during model\ngeneration; 3) a bubble-free restoration scheduler to reduce potential bubbles\nbrought by the imbalance of recomputing and loading stream due to compressed KV\ncaches. Empirical evaluations on real-world tasks demonstrate that Krul\nachieves a 1.5x-2.68x reduction in time-to-first-token (TTFT) and a 1.33x-2.35x\nreduction in KV cache storage compared to state-of-the-art methods without\ncompromising generation quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08045v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08387", "title": "Online Pre-Training for Offline-to-Online Reinforcement Learning", "authors": ["Yongjae Shin", "Jeonghye Kim", "Whiyoung Jung", "Sunghoon Hong", "Deunsol Yoon", "Youngsoo Jang", "Geonhyeong Kim", "Jongseong Chae", "Youngchul Sung", "Kanghoon Lee", "Woohyung Lim"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2025 camera-ready", "url": "http://arxiv.org/abs/2507.08387v1", "summary": "Offline-to-online reinforcement learning (RL) aims to integrate the\ncomplementary strengths of offline and online RL by pre-training an agent\noffline and subsequently fine-tuning it through online interactions. However,\nrecent studies reveal that offline pre-trained agents often underperform during\nonline fine-tuning due to inaccurate value estimation caused by distribution\nshift, with random initialization proving more effective in certain cases. In\nthis work, we propose a novel method, Online Pre-Training for Offline-to-Online\nRL (OPT), explicitly designed to address the issue of inaccurate value\nestimation in offline pre-trained agents. OPT introduces a new learning phase,\nOnline Pre-Training, which allows the training of a new value function tailored\nspecifically for effective online fine-tuning. Implementation of OPT on TD3 and\nSPOT demonstrates an average 30% improvement in performance across a wide range\nof D4RL environments, including MuJoCo, Antmaze, and Adroit.", "comment": "ICML 2025 camera-ready", "pdf_url": "http://arxiv.org/pdf/2507.08387v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08380", "title": "From Enhancement to Understanding: Build a Generalized Bridge for Low-light Vision via Semantically Consistent Unsupervised Fine-tuning", "authors": ["Sen Wang", "Shao Zeng", "Tianjun Gu", "Zhizhong Zhang", "Ruixin Zhang", "Shouhong Ding", "Jingyun Zhang", "Jun Wang", "Xin Tan", "Yuan Xie", "Lizhuang Ma"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.08380v1", "summary": "Low-level enhancement and high-level visual understanding in low-light vision\nhave traditionally been treated separately. Low-light enhancement improves\nimage quality for downstream tasks, but existing methods rely on physical or\ngeometric priors, limiting generalization. Evaluation mainly focuses on visual\nquality rather than downstream performance. Low-light visual understanding,\nconstrained by scarce labeled data, primarily uses task-specific domain\nadaptation, which lacks scalability. To address these challenges, we build a\ngeneralized bridge between low-light enhancement and low-light understanding,\nwhich we term Generalized Enhancement For Understanding (GEFU). This paradigm\nimproves both generalization and scalability. To address the diverse causes of\nlow-light degradation, we leverage pretrained generative diffusion models to\noptimize images, achieving zero-shot generalization performance. Building on\nthis, we propose Semantically Consistent Unsupervised Fine-tuning (SCUF).\nSpecifically, to overcome text prompt limitations, we introduce an\nillumination-aware image prompt to explicitly guide image generation and\npropose a cycle-attention adapter to maximize its semantic potential. To\nmitigate semantic degradation in unsupervised training, we propose caption and\nreflectance consistency to learn high-level semantics and image-level spatial\nsemantics. Extensive experiments demonstrate that our proposed method\noutperforms current state-of-the-art methods in traditional image quality and\nGEFU tasks including classification, detection, and semantic segmentation.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.08380v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08725", "title": "Carbon-Aware Workflow Scheduling with Fixed Mapping and Deadline Constraint", "authors": ["Dominik Schweisgut", "Anne Benoit", "Yves Robert", "Henning Meyerhenke"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      40 pages, 17 figures. Accepted at ICPP 2025. Code available at: this https URL", "url": "http://arxiv.org/abs/2507.08725v1", "summary": "Large data and computing centers consume a significant share of the world's\nenergy consumption. A prominent subset of the workloads in such centers are\nworkflows with interdependent tasks, usually represented as directed acyclic\ngraphs (DAGs). To reduce the carbon emissions resulting from executing such\nworkflows in centers with a mixed (renewable and non-renewable) energy supply,\nit is advisable to move task executions to time intervals with sufficient green\nenergy when possible. To this end, we formalize the above problem as a\nscheduling problem with a given mapping and ordering of the tasks. We show that\nthis problem can be solved in polynomial time in the uniprocessor case. For at\nleast two processors, however, the problem becomes NP-hard. Hence, we propose a\nheuristic framework called CaWoSched that combines several greedy approaches\nwith local search. To assess the 16 heuristics resulting from different\ncombinations, we also devise a simple baseline algorithm and an exact ILP-based\nsolution. Our experimental results show that our heuristics provide significant\nsavings in carbon emissions compared to the baseline.", "comment": "40 pages, 17 figures. Accepted at ICPP 2025. Code available at:\n  https://github.com/KIT-EAE/CaWoSched.git", "pdf_url": "http://arxiv.org/pdf/2507.08725v1", "cate": "cs.DC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08104", "title": "VideoConviction: A Multimodal Benchmark for Human Conviction and Stock Market Recommendations", "authors": ["Michael Galarnyk", "Veer Kejriwal", "Agam Shah", "Yash Bhardwaj", "Nicholas Meyer", "Anand Krishnan", "Sudheer Chava"], "categories": ["cs.MM", "cs.AI", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08104v1", "summary": "Social media has amplified the reach of financial influencers known as\n\"finfluencers,\" who share stock recommendations on platforms like YouTube.\nUnderstanding their influence requires analyzing multimodal signals like tone,\ndelivery style, and facial expressions, which extend beyond text-based\nfinancial analysis. We introduce VideoConviction, a multimodal dataset with\n6,000+ expert annotations, produced through 457 hours of human effort, to\nbenchmark multimodal large language models (MLLMs) and text-based large\nlanguage models (LLMs) in financial discourse. Our results show that while\nmultimodal inputs improve stock ticker extraction (e.g., extracting Apple's\nticker AAPL), both MLLMs and LLMs struggle to distinguish investment actions\nand conviction--the strength of belief conveyed through confident delivery and\ndetailed reasoning--often misclassifying general commentary as definitive\nrecommendations. While high-conviction recommendations perform better than\nlow-conviction ones, they still underperform the popular S\\&P 500 index fund.\nAn inverse strategy--betting against finfluencer recommendations--outperforms\nthe S\\&P 500 by 6.8\\% in annual returns but carries greater risk (Sharpe ratio\nof 0.41 vs. 0.65). Our benchmark enables a diverse evaluation of multimodal\ntasks, comparing model performance on both full video and segmented video\ninputs. This enables deeper advancements in multimodal financial research. Our\ncode, dataset, and evaluation leaderboard are available under the CC BY-NC 4.0\nlicense.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08104v1", "cate": "cs.MM", "date": "2025-06-04", "updated": "2025-06-04"}
{"id": "2507.08390", "title": "Inference-Time Scaling of Diffusion Language Models with Particle Gibbs Sampling", "authors": ["Meihua Dang", "Jiaqi Han", "Minkai Xu", "Kai Xu", "Akash Srivastava", "Stefano Ermon"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08390v1", "summary": "Discrete diffusion models have emerged as a powerful paradigm for language\nmodeling, rivaling auto-regressive models by training-time scaling. However,\ninference-time scaling in discrete diffusion models remains relatively\nunder-explored. In this work, we study sampling-based approaches for achieving\nhigh-quality text generation from discrete diffusion models in reward-guided\nsettings. We introduce a novel inference-time scaling approach based on\nparticle Gibbs sampling for discrete diffusion models. The particle Gibbs\nsampling algorithm iteratively refines full diffusion trajectories using\nconditional Sequential Monte Carlo as its transition mechanism. This process\nensures that the updated samples progressively improve and move closer to the\nreward-weighted target distribution. Unlike existing inference-time scaling\nmethods, which are often limited to single diffusion trajectories, our approach\nleverages iterative refinement across multiple trajectories. Within this\nframework, we further analyze the trade-offs between four key axes for\ninference-time scaling under fixed compute budgets: particle Gibbs iterations,\nparticle count, denoising steps, and reward estimation cost. Empirically, our\nmethod consistently outperforms prior inference-time strategies on\nreward-guided text generation tasks, achieving significant improvement in\naccuracy under varying compute budgets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08390v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08384", "title": "Smelly, dense, and spreaded: The Object Detection for Olfactory References (ODOR) dataset", "authors": ["Mathias Zinnen", "Prathmesh Madhu", "Inger Leemans", "Peter Bell", "Azhar Hussian", "Hang Tran", "Ali Hürriyetoğlu", "Andreas Maier", "Vincent Christlein"], "categories": ["cs.CV", "68T45 68T45", "I.5.4; I.2.10; I.4.8"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08384v1", "summary": "Real-world applications of computer vision in the humanities require\nalgorithms to be robust against artistic abstraction, peripheral objects, and\nsubtle differences between fine-grained target classes. Existing datasets\nprovide instance-level annotations on artworks but are generally biased towards\nthe image centre and limited with regard to detailed object classes. The\nproposed ODOR dataset fills this gap, offering 38,116 object-level annotations\nacross 4712 images, spanning an extensive set of 139 fine-grained categories.\nConducting a statistical analysis, we showcase challenging dataset properties,\nsuch as a detailed set of categories, dense and overlapping objects, and\nspatial distribution over the whole image canvas. Furthermore, we provide an\nextensive baseline analysis for object detection models and highlight the\nchallenging properties of the dataset through a set of secondary studies.\nInspiring further research on artwork object detection and broader visual\ncultural heritage studies, the dataset challenges researchers to explore the\nintersection of object recognition and smell perception.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08384v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08406", "title": "CCSS: Hardware-Accelerated RTL Simulation with Fast Combinational Logic Computing and Sequential Logic Synchronization", "authors": ["Weigang Feng", "Yijia Zhang", "Zekun Wang", "Zhengyang Wang", "Yi Wang", "Peijun Ma", "Ningyi Xu"], "categories": ["cs.AR", "cs.DC"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08406v1", "summary": "As transistor counts in a single chip exceed tens of billions, the complexity\nof RTL-level simulation and verification has grown exponentially, often\nextending simulation campaigns to several months. In industry practice, RTL\nsimulation is divided into two phases: functional debug and system validation.\nWhile system validation demands high simulation speed and is typically\naccelerated using FPGAs, functional debug relies on rapid compilation-rendering\nmulti-core CPUs the primary choice. However, the limited simulation speed of\nCPUs has become a major bottleneck. To address this challenge, we propose CCSS,\na scalable multi-core RTL simulation platform that achieves both fast\ncompilation and high simulation throughput. CCSS accelerates combinational\nlogic computation and sequential logic synchronization through specialized\narchitecture and compilation strategies. It employs a balanced DAG partitioning\nmethod and efficient boolean computation cores for combinational logic, and\nadopts a low-latency network-on-chip (NoC) design to synchronize sequential\nstates across cores efficiently. Experimental results show that CCSS delivers\nup to 12.9x speedup over state-of-the-art multi-core simulators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08406v1", "cate": "cs.AR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08128", "title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models", "authors": ["Arushi Goel", "Sreyan Ghosh", "Jaehyeon Kim", "Sonal Kumar", "Zhifeng Kong", "Sang-gil Lee", "Chao-Han Huck Yang", "Ramani Duraiswami", "Dinesh Manocha", "Rafael Valle", "Bryan Catanzaro"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Code, Datasets and Models: this https URL", "url": "http://arxiv.org/abs/2507.08128v1", "summary": "We present Audio Flamingo 3 (AF3), a fully open state-of-the-art (SOTA) large\naudio-language model that advances reasoning and understanding across speech,\nsound, and music. AF3 introduces: (i) AF-Whisper, a unified audio encoder\ntrained using a novel strategy for joint representation learning across all 3\nmodalities of speech, sound, and music; (ii) flexible, on-demand thinking,\nallowing the model to do chain-of-thought-type reasoning before answering;\n(iii) multi-turn, multi-audio chat; (iv) long audio understanding and reasoning\n(including speech) up to 10 minutes; and (v) voice-to-voice interaction. To\nenable these capabilities, we propose several large-scale training datasets\ncurated using novel strategies, including AudioSkills-XL, LongAudio-XL,\nAF-Think, and AF-Chat, and train AF3 with a novel five-stage curriculum-based\ntraining strategy. Trained on only open-source audio data, AF3 achieves new\nSOTA results on over 20+ (long) audio understanding and reasoning benchmarks,\nsurpassing both open-weight and closed-source models trained on much larger\ndatasets.", "comment": "Code, Datasets and Models: https://research.nvidia.com/labs/adlr/AF3/", "pdf_url": "http://arxiv.org/pdf/2507.08128v1", "cate": "cs.SD", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08424", "title": "RTNinja: a generalized machine learning framework for analyzing random telegraph noise signals in nanoelectronic devices", "authors": ["Anirudh Varanasi", "Robin Degraeve", "Philippe Roussel", "Clement Merckling"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08424v1", "summary": "Random telegraph noise is a prevalent variability phenomenon in\nnanoelectronic devices, arising from stochastic carrier exchange at defect\nsites and critically impacting device reliability and performance. Conventional\nanalysis techniques often rely on restrictive assumptions or manual\ninterventions, limiting their applicability to complex, noisy datasets. Here,\nwe introduce RTNinja, a generalized, fully automated machine learning framework\nfor the unsupervised analysis of random telegraph noise signals. RTNinja\ndeconvolves complex signals to identify the number and characteristics of\nhidden individual sources, without requiring prior knowledge of the system. The\nframework comprises two modular components: LevelsExtractor, which uses\nBayesian inference and model selection to denoise and discretize the signal;\nand SourcesMapper, which infers source configurations through probabilistic\nclustering and optimization. To evaluate performance, we developed a Monte\nCarlo simulator that generates labeled datasets spanning broad signal-to-noise\nratios and source complexities; across 7000 such datasets, RTNinja consistently\ndemonstrated high-fidelity signal reconstruction and accurate extraction of\nsource amplitudes and activity patterns. Our results demonstrate that RTNinja\noffers a robust, scalable, and device-agnostic tool for random telegraph noise\ncharacterization, enabling large-scale statistical benchmarking,\nreliability-centric technology qualification, predictive failure modeling, and\ndevice physics exploration in next-generation nanoelectronics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08424v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08396", "title": "Subject-Consistent and Pose-Diverse Text-to-Image Generation", "authors": ["Zhanxin Gao", "Beier Zhu", "Liang Yao", "Jian Yang", "Ying Tai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08396v1", "summary": "Subject-consistent generation (SCG)-aiming to maintain a consistent subject\nidentity across diverse scenes-remains a challenge for text-to-image (T2I)\nmodels. Existing training-free SCG methods often achieve consistency at the\ncost of layout and pose diversity, hindering expressive visual storytelling. To\naddress the limitation, we propose subject-Consistent and pose-Diverse T2I\nframework, dubbed as CoDi, that enables consistent subject generation with\ndiverse pose and layout. Motivated by the progressive nature of diffusion,\nwhere coarse structures emerge early and fine details are refined later, CoDi\nadopts a two-stage strategy: Identity Transport (IT) and Identity Refinement\n(IR). IT operates in the early denoising steps, using optimal transport to\ntransfer identity features to each target image in a pose-aware manner. This\npromotes subject consistency while preserving pose diversity. IR is applied in\nthe later denoising steps, selecting the most salient identity features to\nfurther refine subject details. Extensive qualitative and quantitative results\non subject consistency, pose diversity, and prompt fidelity demonstrate that\nCoDi achieves both better visual perception and stronger performance across all\nmetrics. The code is provided in https://github.com/NJU-PCALab/CoDi.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08396v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.02356", "title": "Efficient Long Context Fine-tuning with Chunk Flow", "authors": ["Xiulong Yuan", "Hongtao Xu", "Wenting Shen", "Ang Wang", "Xiafei Qiu", "Jie Zhang", "Yuqiong Liu", "Bowen Yu", "Junyang Lin", "Mingzhen Li", "Weile Jia", "Yong Li", "Wei Lin"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02356v3", "summary": "Long context fine-tuning of large language models(LLMs) involves training on\ndatasets that are predominantly composed of short sequences and a small\nproportion of longer sequences. However, existing approaches overlook this\nlong-tail distribution and employ training strategies designed specifically for\nlong sequences. Moreover, these approaches also fail to address the challenges\nposed by variable sequence lengths during distributed training, such as load\nimbalance in data parallelism and severe pipeline bubbles in pipeline\nparallelism. These issues lead to suboptimal training performance and poor GPU\nresource utilization. To tackle these problems, we propose a chunk-centric\ntraining method named ChunkFlow. ChunkFlow reorganizes input sequences into\nuniformly sized chunks by consolidating short sequences and splitting longer\nones. This approach achieves optimal computational efficiency and balance among\ntraining inputs. Additionally, ChunkFlow incorporates a state-aware chunk\nscheduling mechanism to ensure that the peak memory usage during training is\nprimarily determined by the chunk size rather than the maximum sequence length\nin the dataset. Integrating this scheduling mechanism with existing pipeline\nscheduling algorithms further enhances the performance of distributed training.\nExperimental results demonstrate that, compared with Megatron-LM, ChunkFlow can\nbe up to 4.53x faster in the long context fine-tuning of LLMs. Furthermore, we\nbelieve that ChunkFlow serves as an effective solution for a broader range of\nscenarios, such as long context continual pre-training, where datasets contain\nvariable-length sequences.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02356v3", "cate": "cs.DC", "date": "2025-03-04", "updated": "2025-07-11"}
{"id": "2507.08143", "title": "Compactor: Calibrated Query-Agnostic KV Cache Compression with Approximate Leverage Scores", "authors": ["Vivek Chari", "Benjamin Van Durme"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08143v1", "summary": "Modern Large Language Models (LLMs) are increasingly trained to support very\nlarge context windows. Unfortunately the ability to use long contexts in\ngeneration is complicated by the large memory requirement of the KV cache,\nwhich scales linearly with the context length. This memory footprint is often\nthe dominant resource bottleneck in real-world deployments, limiting throughput\nand increasing serving cost. One way to address this is by compressing the KV\ncache, which can be done either with knowledge of the question being asked\n(query-aware) or without knowledge of the query (query-agnostic). We present\nCompactor, a parameter-free, query-agnostic KV compression strategy that uses\napproximate leverage scores to determine token importance. We show that\nCompactor can achieve the same performance as competing methods while retaining\n1/2 the tokens in both synthetic and real-world context tasks, with minimal\ncomputational overhead. We further introduce a procedure for context-calibrated\ncompression, which allows one to infer the maximum compression ratio a given\ncontext can support. Using context-calibrated compression, we show that\nCompactor achieves full KV performance on Longbench while reducing the KV\nmemory burden by 63%, on average. To demonstrate the efficacy and\ngeneralizability of our approach, we apply Compactor to 27 synthetic and\nreal-world tasks from RULER and Longbench, with models from both the Qwen 2.5\nand Llama 3.1 families.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08143v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08443", "title": "KGRAG-Ex: Explainable Retrieval-Augmented Generation with Knowledge Graph-based Perturbations", "authors": ["Georgios Balanos", "Evangelos Chasanis", "Konstantinos Skianis", "Evaggelia Pitoura"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08443v1", "summary": "Retrieval-Augmented Generation (RAG) enhances language models by grounding\nresponses in external information, yet explainability remains a critical\nchallenge, particularly when retrieval relies on unstructured text. Knowledge\ngraphs (KGs) offer a solution by introducing structured, semantically rich\nrepresentations of entities and their relationships, enabling transparent\nretrieval paths and interpretable reasoning. In this work, we present KGRAG-Ex,\na RAG system that improves both factual grounding and explainability by\nleveraging a domain-specific KG constructed via prompt-based information\nextraction. Given a user query, KGRAG-Ex identifies relevant entities and\nsemantic paths in the graph, which are then transformed into pseudo-paragraphs:\nnatural language representations of graph substructures that guide corpus\nretrieval. To improve interpretability and support reasoning transparency, we\nincorporate perturbation-based explanation methods that assess the influence of\nspecific KG-derived components on the generated answers. We conduct a series of\nexperiments to analyze the sensitivity of the system to different perturbation\nmethods, the relationship between graph component importance and their\nstructural positions, the influence of semantic node types, and how graph\nmetrics correspond to the influence of components within the explanations\nprocess.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08443v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08400", "title": "PanMatch: Unleashing the Potential of Large Vision Models for Unified Matching Models", "authors": ["Yongjian Zhang", "Longguang Wang", "Kunhong Li", "Ye Zhang", "Yun Wang", "Liang Lin", "Yulan Guo"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08400v1", "summary": "This work presents PanMatch, a versatile foundation model for robust\ncorrespondence matching. Unlike previous methods that rely on task-specific\narchitectures and domain-specific fine-tuning to support tasks like stereo\nmatching, optical flow or feature matching, our key insight is that any\ntwo-frame correspondence matching task can be addressed within a 2D\ndisplacement estimation framework using the same model weights. Such a\nformulation eliminates the need for designing specialized unified architectures\nor task-specific ensemble models. Instead, it achieves multi-task integration\nby endowing displacement estimation algorithms with unprecedented\ngeneralization capabilities. To this end, we highlight the importance of a\nrobust feature extractor applicable across multiple domains and tasks, and\npropose the feature transformation pipeline that leverage all-purpose features\nfrom Large Vision Models to endow matching baselines with zero-shot cross-view\nmatching capabilities. Furthermore, we assemble a cross-domain dataset with\nnear 1.8 million samples from stereo matching, optical flow, and feature\nmatching domains to pretrain PanMatch. We demonstrate the versatility of\nPanMatch across a wide range of domains and downstream tasks using the same\nmodel weights. Our model outperforms UniMatch and Flow-Anything on cross-task\nevaluations, and achieves comparable performance to most state-of-the-art\ntask-specific algorithms on task-oriented benchmarks. Additionally, PanMatch\npresents unprecedented zero-shot performance in abnormal scenarios, such as\nrainy day and satellite imagery, where most existing robust algorithms fail to\nyield meaningful results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08400v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.08311", "title": "Mind the Memory Gap: Unveiling GPU Bottlenecks in Large-Batch LLM Inference", "authors": ["Pol G. Recasens", "Ferran Agullo", "Yue Zhu", "Chen Wang", "Eun Kyung Lee", "Olivier Tardieu", "Jordi Torres", "Josep Ll. Berral"], "categories": ["cs.DC", "cs.LG"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      Pol G. Recasens, Ferran Agullo: equal contribution. Paper accepted at IEEE CLOUD 2025", "url": "http://arxiv.org/abs/2503.08311v2", "summary": "Large language models have been widely adopted across different tasks, but\ntheir auto-regressive generation nature often leads to inefficient resource\nutilization during inference. While batching is commonly used to increase\nthroughput, performance gains plateau beyond a certain batch size, especially\nwith smaller models, a phenomenon that existing literature typically explains\nas a shift to the compute-bound regime. In this paper, through an in-depth\nGPU-level analysis, we reveal that large-batch inference remains memory-bound,\nwith most GPU compute capabilities underutilized due to DRAM bandwidth\nsaturation as the primary bottleneck. To address this, we propose a Batching\nConfiguration Advisor (BCA) that optimizes memory allocation, reducing GPU\nmemory requirements with minimal impact on throughput. The freed memory and\nunderutilized GPU compute capabilities can then be leveraged by concurrent\nworkloads. Specifically, we use model replication to improve serving throughput\nand GPU utilization. Our findings challenge conventional assumptions about LLM\ninference, offering new insights and practical strategies for improving\nresource utilization, particularly for smaller language models. The code is\npublicly available at\nhttps://github.com/FerranAgulloLopez/vLLMBatchingMemoryGap.", "comment": "Pol G. Recasens, Ferran Agullo: equal contribution. Paper accepted at\n  IEEE CLOUD 2025", "pdf_url": "http://arxiv.org/pdf/2503.08311v2", "cate": "cs.DC", "date": "2025-03-11", "updated": "2025-07-11"}
{"id": "2507.08162", "title": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration", "authors": ["Peng Qiu", "Hanqi Feng", "Barnabas Poczos"], "categories": ["q-bio.BM", "cs.AI"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08162v1", "summary": "Red-blood-cell lysis (HC50) is the principal safety barrier for\nantimicrobial-peptide (AMP) therapeutics, yet existing models only say \"toxic\"\nor \"non-toxic.\" AmpLyze closes this gap by predicting the actual HC50 value\nfrom sequence alone and explaining the residues that drive toxicity. The model\ncouples residue-level ProtT5/ESM2 embeddings with sequence-level descriptors in\ndual local and global branches, aligned by a cross-attention module and trained\nwith log-cosh loss for robustness to assay noise. The optimal AmpLyze model\nreaches a PCC of 0.756 and an MSE of 0.987, outperforming classical regressors\nand the state-of-the-art. Ablations confirm that both branches are essential,\nand cross-attention adds a further 1% PCC and 3% MSE improvement.\nExpected-Gradients attributions reveal known toxicity hotspots and suggest\nsafer substitutions. By turning hemolysis assessment into a quantitative,\nsequence-based, and interpretable prediction, AmpLyze facilitates AMP design\nand offers a practical tool for early-stage toxicity screening.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08162v1", "cate": "q-bio.BM", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08456", "title": "Space filling positionality and the Spiroformer", "authors": ["M. Maurin", "M. Á. Evangelista-Alvarado", "P. Suárez-Serrato"], "categories": ["cs.LG", "cs.AI", "math.DG", "math.DS", "math.SG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figures. To appear in Geometric Science of Information 2025", "url": "http://arxiv.org/abs/2507.08456v1", "summary": "Transformers excel when dealing with sequential data. Generalizing\ntransformer models to geometric domains, such as manifolds, we encounter the\nproblem of not having a well-defined global order. We propose a solution with\nattention heads following a space-filling curve. As a first experimental\nexample, we present the Spiroformer, a transformer that follows a polar spiral\non the $2$-sphere.", "comment": "9 pages, 5 figures. To appear in Geometric Science of Information\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.08456v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08404", "title": "Deep Hashing with Semantic Hash Centers for Image Retrieval", "authors": ["Li Chen", "Rui Liu", "Yuxiang Zhou", "Xudong Ma", "Yong Chen", "Dell Zhang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08404v1", "summary": "Deep hashing is an effective approach for large-scale image retrieval.\nCurrent methods are typically classified by their supervision types:\npoint-wise, pair-wise, and list-wise. Recent point-wise techniques (e.g., CSQ,\nMDS) have improved retrieval performance by pre-assigning a hash center to each\nclass, enhancing the discriminability of hash codes across various datasets.\nHowever, these methods rely on data-independent algorithms to generate hash\ncenters, which neglect the semantic relationships between classes and may\ndegrade retrieval performance.\n  This paper introduces the concept of semantic hash centers, building on the\nidea of traditional hash centers. We hypothesize that hash centers of\nsemantically related classes should have closer Hamming distances, while those\nof unrelated classes should be more distant. To this end, we propose a\nthree-stage framework, SHC, to generate hash codes that preserve semantic\nstructure.\n  First, we develop a classification network to identify semantic similarities\nbetween classes using a data-dependent similarity calculation that adapts to\nvarying data distributions. Second, we introduce an optimization algorithm to\ngenerate semantic hash centers, preserving semantic relatedness while enforcing\na minimum distance between centers to avoid excessively similar hash codes.\nFinally, a deep hashing network is trained using these semantic centers to\nconvert images into binary hash codes.\n  Experimental results on large-scale retrieval tasks across several public\ndatasets show that SHC significantly improves retrieval performance.\nSpecifically, SHC achieves average improvements of +7.26%, +7.62%, and +11.71%\nin MAP@100, MAP@1000, and MAP@ALL metrics, respectively, over state-of-the-art\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08404v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08191", "title": "Overview of the TREC 2021 deep learning track", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Daniel Campos", "Jimmy Lin"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08191v1", "summary": "This is the third year of the TREC Deep Learning track. As in previous years,\nwe leverage the MS MARCO datasets that made hundreds of thousands of human\nannotated training labels available for both passage and document ranking\ntasks. In addition, this year we refreshed both the document and the passage\ncollections which also led to a nearly four times increase in the document\ncollection size and nearly $16$ times increase in the size of the passage\ncollection. Deep neural ranking models that employ large scale pretraininig\ncontinued to outperform traditional retrieval methods this year. We also found\nthat single stage retrieval can achieve good performance on both tasks although\nthey still do not perform at par with multistage retrieval pipelines. Finally,\nthe increase in the collection size and the general data refresh raised some\nquestions about completeness of NIST judgments and the quality of the training\nlabels that were mapped to the new collections from the old ones which we\ndiscuss in this report.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08191v1", "cate": "cs.IR", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08465", "title": "Ranked Set Sampling-Based Multilayer Perceptron: Improving Generalization via Variance-Based Bounds", "authors": ["Feijiang Li", "Liuya Zhang", "Jieting Wang", "Tao Yan", "Yuhua Qian"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08465v1", "summary": "Multilayer perceptron (MLP), one of the most fundamental neural networks, is\nextensively utilized for classification and regression tasks. In this paper, we\nestablish a new generalization error bound, which reveals how the variance of\nempirical loss influences the generalization ability of the learning model.\nInspired by this learning bound, we advocate to reduce the variance of\nempirical loss to enhance the ability of MLP. As is well-known, bagging is a\npopular ensemble method to realize variance reduction. However, bagging\nproduces the base training data sets by the Simple Random Sampling (SRS)\nmethod, which exhibits a high degree of randomness. To handle this issue, we\nintroduce an ordered structure in the training data set by Rank Set Sampling\n(RSS) to further reduce the variance of loss and develop a RSS-MLP method.\nTheoretical results show that the variance of empirical exponential loss and\nthe logistic loss estimated by RSS are smaller than those estimated by SRS,\nrespectively. To validate the performance of RSS-MLP, we conduct comparison\nexperiments on twelve benchmark data sets in terms of the two convex loss\nfunctions under two fusion methods. Extensive experimental results and analysis\nillustrate the effectiveness and rationality of the propose method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08465v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08410", "title": "Multi-modal Mutual-Guidance Conditional Prompt Learning for Vision-Language Models", "authors": ["Shijun Yang", "Xiang Zhang", "Wanqing Zhao", "Hangzai Luo", "Sheng Zhong", "Jinye Peng", "Jianping Fan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      21 pages, 8 figures", "url": "http://arxiv.org/abs/2507.08410v1", "summary": "Prompt learning facilitates the efficient adaptation of Vision-Language\nModels (VLMs) to various downstream tasks. However, it faces two significant\nchallenges: (1) inadequate modeling of class embedding distributions for unseen\ninstances, leading to suboptimal generalization on novel classes; (2)\nprevailing methodologies predominantly confine cross-modal alignment to the\nfinal output layer of vision and text encoders, which fundamentally limits\ntheir capacity to preserve topological consistency with pre-trained multi-modal\nembedding spaces. To this end, we introduce MuGCP (Multi-modal Mutual-Guidance\nConditional Prompt Learning), a novel paradigm designed for conditional prompt\ngeneration. MuGCP leverages Multi-modal Large Language Models (MLLMs) as\nconditional prompt learners to adaptively generate Semantic Conditional Prompts\n(SCP) that incorporate rich, fine-grained high-level semantic knowledge for\nimage instances. To ensure effective alignment and interaction across the\nmulti-modal space of Vision-Language Models (VLMs), we introduce the Attention\nMutual-Guidance (AMG) module, which facilitates interactions between visual and\nsemantic information. Through mutual guidance, the AMG module generates Visual\nConditional Prompts (VCP), enhancing the model's performance in multi-modal\ntasks. Additionally, we present a Multi-Prompt Fusion (MPF) mechanism that\nintegrates SCP and VCP with contextual prompts, ensuring seamless coordination\namong the different prompts and enhancing the modeling of class embeddings and\ninstance-specific knowledge. Our MuGCP outperforms existing state-of-the-art\nmethods on 14 different datasets. The code will be made available after\npublication.", "comment": "21 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.08410v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08197", "title": "Consciousness as a Jamming Phase", "authors": ["Kaichen Ouyang"], "categories": ["cond-mat.dis-nn", "cs.AI"], "primary_category": "Subjects:       Disordered Systems and Neural Networks (cond-mat.dis-nn)", "pdf_link": null, "comments": "Comments:      18 pages, 13 figures", "url": "http://arxiv.org/abs/2507.08197v1", "summary": "This paper develops a neural jamming phase diagram that interprets the\nemergence of consciousness in large language models as a critical phenomenon in\nhigh-dimensional disordered systems.By establishing analogies with jamming\ntransitions in granular matter and other complex systems, we identify three\nfundamental control parameters governing the phase behavior of neural networks:\ntemperature, volume fraction, and stress.The theory provides a unified physical\nexplanation for empirical scaling laws in artificial intelligence,\ndemonstrating how computational cooling, density optimization, and noise\nreduction collectively drive systems toward a critical jamming surface where\ngeneralized intelligence emerges. Remarkably, the same thermodynamic principles\nthat describe conventional jamming transitions appear to underlie the emergence\nof consciousness in neural networks, evidenced by shared critical signatures\nincluding divergent correlation lengths and scaling exponents.Our work explains\nneural language models' critical scaling through jamming physics, suggesting\nconsciousness is a jamming phase that intrinsically connects knowledge\ncomponents via long-range correlations.", "comment": "18 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.08197v1", "cate": "cond-mat.dis-nn", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08472", "title": "Pre-Training LLMs on a budget: A comparison of three optimizers", "authors": ["Joel Schlotthauer", "Christian Kroos", "Chris Hinze", "Viktor Hangya", "Luzian Hahn", "Fabian Küch"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08472v1", "summary": "Optimizers play a decisive role in reducing pre-training times for LLMs and\nachieving better-performing models. In this study, we compare three major\nvariants: the de-facto standard AdamW, the simpler Lion, developed through an\nevolutionary search, and the second-order optimizer Sophia. For better\ngeneralization, we train with two different base architectures and use a\nsingle- and a multiple-epoch approach while keeping the number of tokens\nconstant. Using the Maximal Update Parametrization and smaller proxy models, we\ntune relevant hyperparameters separately for each combination of base\narchitecture and optimizer. We found that while the results from all three\noptimizers were in approximately the same range, Sophia exhibited the lowest\ntraining and validation loss, Lion was fastest in terms of training GPU hours\nbut AdamW led to the best downstream evaluation results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08472v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08416", "title": "InstaScene: Towards Complete 3D Instance Decomposition and Reconstruction from Cluttered Scenes", "authors": ["Zesong Yang", "Bangbang Yang", "Wenqi Dong", "Chenxuan Cao", "Liyuan Cui", "Yuewen Ma", "Zhaopeng Cui", "Hujun Bao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. Project page: this https URL", "url": "http://arxiv.org/abs/2507.08416v1", "summary": "Humans can naturally identify and mentally complete occluded objects in\ncluttered environments. However, imparting similar cognitive ability to\nrobotics remains challenging even with advanced reconstruction techniques,\nwhich models scenes as undifferentiated wholes and fails to recognize complete\nobject from partial observations. In this paper, we propose InstaScene, a new\nparadigm towards holistic 3D perception of complex scenes with a primary goal:\ndecomposing arbitrary instances while ensuring complete reconstruction. To\nachieve precise decomposition, we develop a novel spatial contrastive learning\nby tracing rasterization of each instance across views, significantly enhancing\nsemantic supervision in cluttered scenes. To overcome incompleteness from\nlimited observations, we introduce in-situ generation that harnesses valuable\nobservations and geometric cues, effectively guiding 3D generative models to\nreconstruct complete instances that seamlessly align with the real world.\nExperiments on scene decomposition and object completion across complex\nreal-world and synthetic scenes demonstrate that our method achieves superior\ndecomposition accuracy while producing geometrically faithful and visually\nintact objects.", "comment": "Accepted by ICCV 2025. Project page:\n  https://zju3dv.github.io/instascene/", "pdf_url": "http://arxiv.org/pdf/2507.08416v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08103", "title": "A Systematic Mapping Study on Open Source Agriculture Technology Research", "authors": ["Kevin Lumbard", "Vinod Kumar Ahuja", "Matt Cantu Snell"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08103v1", "summary": "Agriculture contributes trillions of dollars to the US economy each year.\nDigital technologies are disruptive forces in agriculture. The open source\nmovement is beginning to emerge in agriculture technology and has dramatic\nimplications for the future of farming and agriculture digital technologies.\nThe convergence of open source and agriculture digital technology is observable\nin scientific research, but the implications of open source ideals related to\nagriculture technology have yet to be explored. This study explores open\nagriculture digital technology through a systematic mapping of available open\nagriculture digital technology research. The study contributes to Information\nSystems research by illuminating current trends and future research\nopportunities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08103v1", "cate": "cs.CY", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08232", "title": "Can LLMs Reliably Simulate Real Students' Abilities in Mathematics and Reading Comprehension?", "authors": ["KV Aditya Srivatsa", "Kaushal Kumar Maurya", "Ekaterina Kochmar"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to the 20th Workshop on Innovative Use of NLP for Building Educational Applications (BEA), co-located with ACL 2025", "url": "http://arxiv.org/abs/2507.08232v1", "summary": "Large Language Models (LLMs) are increasingly used as proxy students in the\ndevelopment of Intelligent Tutoring Systems (ITSs) and in piloting test\nquestions. However, to what extent these proxy students accurately emulate the\nbehavior and characteristics of real students remains an open question. To\ninvestigate this, we collected a dataset of 489 items from the National\nAssessment of Educational Progress (NAEP), covering mathematics and reading\ncomprehension in grades 4, 8, and 12. We then apply an Item Response Theory\n(IRT) model to position 11 diverse and state-of-the-art LLMs on the same\nability scale as real student populations. Our findings reveal that, without\nguidance, strong general-purpose models consistently outperform the average\nstudent at every grade, while weaker or domain-mismatched models may align\nincidentally. Using grade-enforcement prompts changes models' performance, but\nwhether they align with the average grade-level student remains highly model-\nand prompt-specific: no evaluated model-prompt pair fits the bill across\nsubjects and grades, underscoring the need for new training and evaluation\nstrategies. We conclude by providing guidelines for the selection of viable\nproxies based on our findings.", "comment": "Accepted to the 20th Workshop on Innovative Use of NLP for Building\n  Educational Applications (BEA), co-located with ACL 2025", "pdf_url": "http://arxiv.org/pdf/2507.08232v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08473", "title": "Evaluating SAE interpretability without explanations", "authors": ["Gonçalo Paulo", "Nora Belrose"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08473v1", "summary": "Sparse autoencoders (SAEs) and transcoders have become important tools for\nmachine learning interpretability. However, measuring how interpretable they\nare remains challenging, with weak consensus about which benchmarks to use.\nMost evaluation procedures start by producing a single-sentence explanation for\neach latent. These explanations are then evaluated based on how well they\nenable an LLM to predict the activation of a latent in new contexts. This\nmethod makes it difficult to disentangle the explanation generation and\nevaluation process from the actual interpretability of the latents discovered.\nIn this work, we adapt existing methods to assess the interpretability of\nsparse coders, with the advantage that they do not require generating natural\nlanguage explanations as an intermediate step. This enables a more direct and\npotentially standardized assessment of interpretability. Furthermore, we\ncompare the scores produced by our interpretability metrics with human\nevaluations across similar tasks and varying setups, offering suggestions for\nthe community on improving the evaluation of these techniques.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08473v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08422", "title": "Upsample What Matters: Region-Adaptive Latent Sampling for Accelerated Diffusion Transformers", "authors": ["Wongi Jeong", "Kyungryeol Lee", "Hoigi Seo", "Se Young Chun"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08422v1", "summary": "Diffusion transformers have emerged as an alternative to U-net-based\ndiffusion models for high-fidelity image and video generation, offering\nsuperior scalability. However, their heavy computation remains a major obstacle\nto real-world deployment. Existing acceleration methods primarily exploit the\ntemporal dimension such as reusing cached features across diffusion timesteps.\nHere, we propose Region-Adaptive Latent Upsampling (RALU), a training-free\nframework that accelerates inference along spatial dimension. RALU performs\nmixed-resolution sampling across three stages: 1) low-resolution denoising\nlatent diffusion to efficiently capture global semantic structure, 2)\nregion-adaptive upsampling on specific regions prone to artifacts at\nfull-resolution, and 3) all latent upsampling at full-resolution for detail\nrefinement. To stabilize generations across resolution transitions, we leverage\nnoise-timestep rescheduling to adapt the noise level across varying\nresolutions. Our method significantly reduces computation while preserving\nimage quality by achieving up to 7.0$\\times$ speed-up on FLUX and 3.0$\\times$\non Stable Diffusion 3 with minimal degradation. Furthermore, RALU is\ncomplementary to existing temporal accelerations such as caching methods, thus\ncan be seamlessly integrated to further reduce inference latency without\ncompromising generation quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08422v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08211", "title": "Effect of Static vs. Conversational AI-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial", "authors": ["Neil K. R. Sehgal", "Manuel Tonneau", "Andy Tan", "Shivan J. Mehta", "Alison Buttenheim", "Lyle Ungar", "Anish K. Agarwal", "Sharath Chandra Guntuku"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08211v1", "summary": "Large language model (LLM) chatbots show increasing promise in persuasive\ncommunication. Yet their real-world utility remains uncertain, particularly in\nclinical settings where sustained conversations are difficult to scale. In a\npre-registered randomized controlled trial, we enrolled 915 U.S. adults (ages\n45-75) who had never completed colorectal cancer (CRC) screening. Participants\nwere randomized to: (1) no message control, (2) expert-written patient\nmaterials, (3) single AI-generated message, or (4) a motivational interviewing\nchatbot. All participants were required to remain in their assigned condition\nfor at least three minutes. Both AI arms tailored content using participant's\nself-reported demographics including age and gender. Both AI interventions\nsignificantly increased stool test intentions by over 12 points\n(12.9-13.8/100), compared to a 7.5 gain for expert materials (p<.001 for all\ncomparisons). While the AI arms outperformed the no message control for\ncolonoscopy intent, neither showed improvement xover expert materials. Notably,\nfor both outcomes, the chatbot did not outperform the single AI message in\nboosting intent despite participants spending ~3.5 minutes more on average\nengaging with it. These findings suggest concise, demographically tailored AI\nmessages may offer a more scalable and clinically viable path to health\nbehavior change than more complex conversational agents and generic time\nintensive expert-written materials. Moreover, LLMs appear more persuasive for\nlesser-known and less-invasive screening approaches like stool testing, but may\nbe less effective for entrenched preferences like colonoscopy. Future work\nshould examine which facets of personalization drive behavior change, whether\nintegrating structural supports can translate these modest intent gains into\ncompleted screenings, and which health behaviors are most responsive to\nAI-supported guidance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08211v1", "cate": "cs.CY", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08309", "title": "Improving MLLM's Document Image Machine Translation via Synchronously Self-reviewing Its OCR Proficiency", "authors": ["Yupu Liang", "Yaping Zhang", "Zhiyang Zhang", "Zhiyuan Chen", "Yang Zhao", "Lu Xiang", "Chengqing Zong", "Yu Zhou"], "categories": ["cs.CL", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 Findings", "url": "http://arxiv.org/abs/2507.08309v1", "summary": "Multimodal Large Language Models (MLLMs) have shown strong performance in\ndocument image tasks, especially Optical Character Recognition (OCR). However,\nthey struggle with Document Image Machine Translation (DIMT), which requires\nhandling both cross-modal and cross-lingual challenges. Previous efforts to\nenhance DIMT capability through Supervised Fine-Tuning (SFT) on the DIMT\ndataset often result in the forgetting of the model's existing monolingual\nabilities, such as OCR. To address these challenges, we introduce a novel\nfine-tuning paradigm, named Synchronously Self-Reviewing (SSR) its OCR\nproficiency, inspired by the concept \"Bilingual Cognitive Advantage\".\nSpecifically, SSR prompts the model to generate OCR text before producing\ntranslation text, which allows the model to leverage its strong monolingual OCR\nability while learning to translate text across languages. Comprehensive\nexperiments demonstrate the proposed SSR learning helps mitigate catastrophic\nforgetting, improving the generalization ability of MLLMs on both OCR and DIMT\ntasks.", "comment": "Accepted by ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2507.08309v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08475", "title": "SynBridge: Bridging Reaction States via Discrete Flow for Bidirectional Reaction Prediction", "authors": ["Haitao Lin", "Junjie Wang", "Zhifeng Gao", "Xiaohong Ji", "Rong Zhu", "Linfeng Zhang", "Guolin Ke", "Weinan E"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      22pages, 2 figures", "url": "http://arxiv.org/abs/2507.08475v1", "summary": "The essence of a chemical reaction lies in the redistribution and\nreorganization of electrons, which is often manifested through electron\ntransfer or the migration of electron pairs. These changes are inherently\ndiscrete and abrupt in the physical world, such as alterations in the charge\nstates of atoms or the formation and breaking of chemical bonds. To model the\ntransition of states, we propose SynBridge, a bidirectional flow-based\ngenerative model to achieve multi-task reaction prediction. By leveraging a\ngraph-to-graph transformer network architecture and discrete flow bridges\nbetween any two discrete distributions, SynBridge captures bidirectional\nchemical transformations between graphs of reactants and products through the\nbonds' and atoms' discrete states. We further demonstrate the effectiveness of\nour method through extensive experiments on three benchmark datasets\n(USPTO-50K, USPTO-MIT, Pistachio), achieving state-of-the-art performance in\nboth forward and retrosynthesis tasks. Our ablation studies and noise\nscheduling analysis reveal the benefits of structured diffusion over discrete\nspaces for reaction prediction.", "comment": "22pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.08475v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08434", "title": "RePaintGS: Reference-Guided Gaussian Splatting for Realistic and View-Consistent 3D Scene Inpainting", "authors": ["Ji Hyun Seo", "Byounhyun Yoo", "Gerard Jounghyun Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08434v1", "summary": "Radiance field methods, such as Neural Radiance Field or 3D Gaussian\nSplatting, have emerged as seminal 3D representations for synthesizing\nrealistic novel views. For practical applications, there is ongoing research on\nflexible scene editing techniques, among which object removal is a\nrepresentative task. However, removing objects exposes occluded regions, often\nleading to unnatural appearances. Thus, studies have employed image inpainting\ntechniques to replace such regions with plausible content - a task referred to\nas 3D scene inpainting. However, image inpainting methods produce one of many\nplausible completions for each view, leading to inconsistencies between\nviewpoints. A widely adopted approach leverages perceptual cues to blend\ninpainted views smoothly. However, it is prone to detail loss and can fail when\nthere are perceptual inconsistencies across views. In this paper, we propose a\nnovel 3D scene inpainting method that reliably produces realistic and\nperceptually consistent results even for complex scenes by leveraging a\nreference view. Given the inpainted reference view, we estimate the inpainting\nsimilarity of the other views to adjust their contribution in constructing an\naccurate geometry tailored to the reference. This geometry is then used to warp\nthe reference inpainting to other views as pseudo-ground truth, guiding the\noptimization to match the reference appearance. Comparative evaluation studies\nhave shown that our approach improves both the geometric fidelity and\nappearance consistency of inpainted scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08434v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08310", "title": "Generative AI in Science: Applications, Challenges, and Emerging Questions", "authors": ["Ryan Harries", "Cornelia Lawson", "Philip Shapira"], "categories": ["cs.CY", "cs.AI", "K.4; I.2"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure, 1 appendix", "url": "http://arxiv.org/abs/2507.08310v1", "summary": "This paper examines the impact of Generative Artificial Intelligence (GenAI)\non scientific practices, conducting a qualitative review of selected literature\nto explore its applications, benefits, and challenges. The review draws on the\nOpenAlex publication database, using a Boolean search approach to identify\nscientific literature related to GenAI (including large language models and\nChatGPT). Thirty-nine highly cited papers and commentaries are reviewed and\nqualitatively coded. Results are categorized by GenAI applications in science,\nscientific writing, medical practice, and education and training. The analysis\nfinds that while there is a rapid adoption of GenAI in science and science\npractice, its long-term implications remain unclear, with ongoing uncertainties\nabout its use and governance. The study provides early insights into GenAI's\ngrowing role in science and identifies questions for future research in this\nevolving field.", "comment": "9 pages, 1 figure, 1 appendix", "pdf_url": "http://arxiv.org/pdf/2507.08310v1", "cate": "cs.CY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08333", "title": "Audio Inpanting using Discrete Diffusion Model", "authors": ["Tali Dror", "Iftach Shoham", "Moshe Buchris", "Oren Gal", "Haim Permuter", "Gilad Katz", "Eliya Nachmani"], "categories": ["cs.SD", "cs.AI", "cs.IT", "cs.LG", "eess.AS", "math.IT"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08333v1", "summary": "Audio inpainting refers to the task of reconstructing missing segments in\ncorrupted audio recordings. While prior approaches-including waveform and\nspectrogram-based diffusion models-have shown promising results for short gaps,\nthey often degrade in quality when gaps exceed 100 milliseconds (ms). In this\nwork, we introduce a novel inpainting method based on discrete diffusion\nmodeling, which operates over tokenized audio representations produced by a\npre-trained audio tokenizer. Our approach models the generative process\ndirectly in the discrete latent space, enabling stable and semantically\ncoherent reconstruction of missing audio. We evaluate the method on the\nMusicNet dataset using both objective and perceptual metrics across gap\ndurations up to 300 ms. We further evaluated our approach on the MTG dataset,\nextending the gap duration to 500 ms. Experimental results demonstrate that our\nmethod achieves competitive or superior performance compared to existing\nbaselines, particularly for longer gaps, offering a robust solution for\nrestoring degraded musical recordings. Audio examples of our proposed method\ncan be found at https://iftach21.github.io/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08333v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08505", "title": "Efficient Deployment of Vision-Language Models on Mobile Devices: A Case Study on OnePlus 13R", "authors": ["Pablo Robin Guerrero", "Yueyang Pan", "Sanidhya Kashyap"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08505v1", "summary": "Vision-Language Models (VLMs) offer promising capabilities for mobile\ndevices, but their deployment faces significant challenges due to computational\nlimitations and energy inefficiency, especially for real-time applications.\nThis study provides a comprehensive survey of deployment frameworks for VLMs on\nmobile devices, evaluating llama.cpp, MLC-Imp, and mllm in the context of\nrunning LLaVA-1.5 7B, MobileVLM-3B, and Imp-v1.5 3B as representative workloads\non a OnePlus 13R. Each deployment framework was evaluated on the OnePlus 13R\nwhile running VLMs, with measurements covering CPU, GPU, and NPU utilization,\ntemperature, inference time, power consumption, and user experience.\nBenchmarking revealed critical performance bottlenecks across frameworks: CPU\nresources were consistently over-utilized during token generation, while GPU\nand NPU accelerators were largely unused. When the GPU was used, primarily for\nimage feature extraction, it was saturated, leading to degraded device\nresponsiveness. The study contributes framework-level benchmarks, practical\nprofiling tools, and an in-depth analysis of hardware utilization bottlenecks,\nhighlighting the consistent overuse of CPUs and the ineffective or unstable use\nof GPUs and NPUs in current deployment frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08505v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08441", "title": "Vision Foundation Models as Effective Visual Tokenizers for Autoregressive Image Generation", "authors": ["Anlin Zheng", "Xin Wen", "Xuanyang Zhang", "Chuofan Ma", "Tiancai Wang", "Gang Yu", "Xiangyu Zhang", "Xiaojuan Qi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      19 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08441v1", "summary": "Leveraging the powerful representations of pre-trained vision foundation\nmodels -- traditionally used for visual comprehension -- we explore a novel\ndirection: building an image tokenizer directly atop such models, a largely\nunderexplored area. Specifically, we employ a frozen vision foundation model as\nthe encoder of our tokenizer. To enhance its effectiveness, we introduce two\nkey components: (1) a region-adaptive quantization framework that reduces\nredundancy in the pre-trained features on regular 2D grids, and (2) a semantic\nreconstruction objective that aligns the tokenizer's outputs with the\nfoundation model's representations to preserve semantic fidelity. Based on\nthese designs, our proposed image tokenizer, VFMTok, achieves substantial\nimprovements in image reconstruction and generation quality, while also\nenhancing token efficiency. It further boosts autoregressive (AR) generation --\nachieving a gFID of 2.07 on ImageNet benchmarks, while accelerating model\nconvergence by three times, and enabling high-fidelity class-conditional\nsynthesis without the need for classifier-free guidance (CFG). The code will be\nreleased publicly to benefit the community.", "comment": "19 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08441v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08027", "title": "\"Amazing, They All Lean Left\" -- Analyzing the Political Temperaments of Current LLMs", "authors": ["W. Russell Neuman", "Chad Coleman", "Ali Dasdan", "Safinah Ali", "Manan Shah", "Kund Meghani"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08027v1", "summary": "Recent studies have revealed a consistent liberal orientation in the ethical\nand political responses generated by most commercial large language models\n(LLMs), yet the underlying causes and resulting implications remain unclear.\nThis paper systematically investigates the political temperament of seven\nprominent LLMs - OpenAI's GPT-4o, Anthropic's Claude Sonnet 4, Perplexity\n(Sonar Large), Google's Gemini 2.5 Flash, Meta AI's Llama 4, Mistral 7b Le Chat\nand High-Flyer's DeepSeek R1 -- using a multi-pronged approach that includes\nMoral Foundations Theory, a dozen established political ideology scales and a\nnew index of current political controversies. We find strong and consistent\nprioritization of liberal-leaning values, particularly care and fairness,\nacross most models. Further analysis attributes this trend to four overlapping\nfactors: Liberal-leaning training corpora, reinforcement learning from human\nfeedback (RLHF), the dominance of liberal frameworks in academic ethical\ndiscourse and safety-driven fine-tuning practices. We also distinguish between\npolitical \"bias\" and legitimate epistemic differences, cautioning against\nconflating the two. A comparison of base and fine-tuned model pairs reveals\nthat fine-tuning generally increases liberal lean, an effect confirmed through\nboth self-report and empirical testing. We argue that this \"liberal tilt\" is\nnot a programming error or the personal preference of programmers but an\nemergent property of training on democratic rights-focused discourse. Finally,\nwe propose that LLMs may indirectly echo John Rawls' famous veil-of ignorance\nphilosophical aspiration, reflecting a moral stance unanchored to personal\nidentity or interest. Rather than undermining democratic discourse, this\npattern may offer a new lens through which to examine collective reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08027v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08427", "title": "ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains", "authors": ["Zilu Dong", "Xiangqing Shen", "Zinong Yang", "Rui Xia"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 (main)", "url": "http://arxiv.org/abs/2507.08427v1", "summary": "Current knowledge editing methods for large language models (LLMs) struggle\nto maintain logical consistency when propagating ripple effects to associated\nfacts. We propose ChainEdit, a framework that synergizes knowledge\ngraph-derived logical rules with LLM logical reasoning capabilities to enable\nsystematic chain updates. By automatically extracting logical patterns from\nstructured knowledge bases and aligning them with LLMs' internal logics,\nChainEdit dynamically generates and edits logically connected knowledge\nclusters. Experiments demonstrate an improvement of more than 30% in logical\ngeneralization over baselines while preserving editing reliability and\nspecificity. We further address evaluation biases in existing benchmarks\nthrough knowledge-aware protocols that disentangle external dependencies. This\nwork establishes new state-of-the-art performance on ripple effect while\nensuring internal logical consistency after knowledge editing.", "comment": "Accepted to ACL 2025 (main)", "pdf_url": "http://arxiv.org/pdf/2507.08427v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08508", "title": "SFedKD: Sequential Federated Learning with Discrepancy-Aware Multi-Teacher Knowledge Distillation", "authors": ["Haotian Xu", "Jinrui Zhou", "Xichong Zhang", "Mingjun Xiao", "He Sun", "Yin Xu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08508v1", "summary": "Federated Learning (FL) is a distributed machine learning paradigm which\ncoordinates multiple clients to collaboratively train a global model via a\ncentral server. Sequential Federated Learning (SFL) is a newly-emerging FL\ntraining framework where the global model is trained in a sequential manner\nacross clients. Since SFL can provide strong convergence guarantees under data\nheterogeneity, it has attracted significant research attention in recent years.\nHowever, experiments show that SFL suffers from severe catastrophic forgetting\nin heterogeneous environments, meaning that the model tends to forget knowledge\nlearned from previous clients. To address this issue, we propose an SFL\nframework with discrepancy-aware multi-teacher knowledge distillation, called\nSFedKD, which selects multiple models from the previous round to guide the\ncurrent round of training. In SFedKD, we extend the single-teacher Decoupled\nKnowledge Distillation approach to our multi-teacher setting and assign\ndistinct weights to teachers' target-class and non-target-class knowledge based\non the class distributional discrepancy between teacher and student data.\nThrough this fine-grained weighting strategy, SFedKD can enhance model training\nefficacy while mitigating catastrophic forgetting. Additionally, to prevent\nknowledge dilution, we eliminate redundant teachers for the knowledge\ndistillation and formalize it as a variant of the maximum coverage problem.\nBased on the greedy strategy, we design a complementary-based teacher selection\nmechanism to ensure that the selected teachers achieve comprehensive knowledge\nspace coverage while reducing communication and computational costs. Extensive\nexperiments show that SFedKD effectively overcomes catastrophic forgetting in\nSFL and outperforms state-of-the-art FL methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08508v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08448", "title": "Review of Feed-forward 3D Reconstruction: From DUSt3R to VGGT", "authors": ["Wei Zhang", "Yihang Wu", "Songhua Li", "Wenjie Ma", "Xin Ma", "Qiang Li", "Qi Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08448v1", "summary": "3D reconstruction, which aims to recover the dense three-dimensional\nstructure of a scene, is a cornerstone technology for numerous applications,\nincluding augmented/virtual reality, autonomous driving, and robotics. While\ntraditional pipelines like Structure from Motion (SfM) and Multi-View Stereo\n(MVS) achieve high precision through iterative optimization, they are limited\nby complex workflows, high computational cost, and poor robustness in\nchallenging scenarios like texture-less regions. Recently, deep learning has\ncatalyzed a paradigm shift in 3D reconstruction. A new family of models,\nexemplified by DUSt3R, has pioneered a feed-forward approach. These models\nemploy a unified deep network to jointly infer camera poses and dense geometry\ndirectly from an Unconstrained set of images in a single forward pass. This\nsurvey provides a systematic review of this emerging domain. We begin by\ndissecting the technical framework of these feed-forward models, including\ntheir Transformer-based correspondence modeling, joint pose and geometry\nregression mechanisms, and strategies for scaling from two-view to multi-view\nscenarios. To highlight the disruptive nature of this new paradigm, we contrast\nit with both traditional pipelines and earlier learning-based methods like\nMVSNet. Furthermore, we provide an overview of relevant datasets and evaluation\nmetrics. Finally, we discuss the technology's broad application prospects and\nidentify key future challenges and opportunities, such as model accuracy and\nscalability, and handling dynamic scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08448v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08029", "title": "Better Together: Quantifying the Benefits of AI-Assisted Recruitment", "authors": ["Ada Aka", "Emil Palikot", "Ali Ansari", "Nima Yazdani"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08029v1", "summary": "Artificial intelligence (AI) is increasingly used in recruitment, yet\nempirical evidence quantifying its impact on hiring efficiency and candidate\nselection remains limited. We randomly assign 37,000 applicants for a\njunior-developer position to either a traditional recruitment process (resume\nscreening followed by human selection) or an AI-assisted recruitment pipeline\nincorporating an initial AI-driven structured video interview before human\nevaluation. Candidates advancing from either track faced the same final-stage\nhuman interview, with interviewers blind to the earlier selection method. In\nthe AI-assisted pipeline, 54% of candidates passed the final interview compared\nwith 34% from the traditional pipeline, yielding an average treatment effect of\n20 percentage points (SE 12 pp.). Five months later, we collected LinkedIn\nprofiles of top applicants from both groups and found that 18% (SE 1.1%) of\napplicants from the traditional track found new jobs compared with 23% (SE\n2.3%) from the AI group, resulting in a 5.9 pp. (SE 2.6 pp.) difference in the\nprobability of finding new employment between groups. The AI system tended to\nselect younger applicants with less experience and fewer advanced credentials.\nWe analyze AI-generated interview transcripts to examine the selection criteria\nand conversational dynamics. Our findings contribute to understanding how AI\ntechnologies affect decision making in recruitment and talent acquisition while\nhighlighting some of their potential implications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08029v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08445", "title": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval", "authors": ["Yaodong Su", "Yixiang Fang", "Yingli Zhou", "Quanqing Xu", "Chuanhui Yang"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08445v1", "summary": "Despite the remarkable progress of Large Language Models (LLMs), their\nperformance in question answering (QA) remains limited by the lack of\ndomain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG)\naddresses this limitation by incorporating external information, often from\ngraph-structured data. However, existing graph-based RAG methods suffer from\npoor graph quality due to incomplete extraction and insufficient utilization of\nquery information during retrieval. To overcome these limitations, we propose\nCUE-RAG, a novel approach that introduces (1) a multi-partite graph index\nincorporates text Chunks, knowledge Units, and Entities to capture semantic\ncontent at multiple levels of granularity, (2) a hybrid extraction strategy\nthat reduces LLM token usage while still producing accurate and disambiguated\nknowledge units, and (3) Q-Iter, a query-driven iterative retrieval strategy\nthat enhances relevance through semantic search and constrained graph\ntraversal. Experiments on three QA benchmarks show that CUE-RAG significantly\noutperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy\nand 113.51% higher F1 score while reducing indexing costs by 72.58%.\nRemarkably, CUE-RAG matches or outperforms baselines even without using an LLM\nfor indexing. These results demonstrate the effectiveness and cost-efficiency\nof CUE-RAG in advancing graph-based RAG systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08445v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08537", "title": "Recursive Reward Aggregation", "authors": ["Yuting Tang", "Yivan Zhang", "Johannes Ackermann", "Yu-Jie Zhang", "Soichiro Nishimori", "Masashi Sugiyama"], "categories": ["cs.LG", "math.CT"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Reinforcement Learning Conference 2025", "url": "http://arxiv.org/abs/2507.08537v1", "summary": "In reinforcement learning (RL), aligning agent behavior with specific\nobjectives typically requires careful design of the reward function, which can\nbe challenging when the desired objectives are complex. In this work, we\npropose an alternative approach for flexible behavior alignment that eliminates\nthe need to modify the reward function by selecting appropriate reward\naggregation functions. By introducing an algebraic perspective on Markov\ndecision processes (MDPs), we show that the Bellman equations naturally emerge\nfrom the recursive generation and aggregation of rewards, allowing for the\ngeneralization of the standard discounted sum to other recursive aggregations,\nsuch as discounted max and Sharpe ratio. Our approach applies to both\ndeterministic and stochastic settings and integrates seamlessly with\nvalue-based and actor-critic algorithms. Experimental results demonstrate that\nour approach effectively optimizes diverse objectives, highlighting its\nversatility and potential for real-world applications.", "comment": "Reinforcement Learning Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.08537v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08458", "title": "A document is worth a structured record: Principled inductive bias design for document recognition", "authors": ["Benjamin Meyer", "Lukas Tuggener", "Sascha Hänzi", "Daniel Schmid", "Erdal Ayfer", "Benjamin F. Grewe", "Ahmed Abdulkadir", "Thilo Stadelmann"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08458v1", "summary": "Many document types use intrinsic, convention-driven structures that serve to\nencode precise and structured information, such as the conventions governing\nengineering drawings. However, state-of-the-art approaches treat document\nrecognition as a mere computer vision problem, neglecting these underlying\ndocument-type-specific structural properties, making them dependent on\nsub-optimal heuristic post-processing and rendering many less frequent or more\ncomplicated document types inaccessible to modern document recognition. We\nsuggest a novel perspective that frames document recognition as a transcription\ntask from a document to a record. This implies a natural grouping of documents\nbased on the intrinsic structure inherent in their transcription, where related\ndocument types can be treated (and learned) similarly. We propose a method to\ndesign structure-specific inductive biases for the underlying machine-learned\nend-to-end document recognition systems, and a respective base transformer\narchitecture that we successfully adapt to different structures. We demonstrate\nthe effectiveness of the so-found inductive biases in extensive experiments\nwith progressively complex record structures from monophonic sheet music, shape\ndrawings, and simplified engineering drawings. By integrating an inductive bias\nfor unrestricted graph structures, we train the first-ever successful\nend-to-end model to transcribe engineering drawings to their inherently\ninterlinked information. Our approach is relevant to inform the design of\ndocument recognition systems for document types that are less well understood\nthan standard OCR, OMR, etc., and serves as a guide to unify the design of\nfuture document foundation models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08458v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08701", "title": "A Personalised Formal Verification Framework for Monitoring Activities of Daily Living of Older Adults Living Independently in Their Homes", "authors": ["Ricardo Contreras", "Filip Smola", "Nuša Farič", "Jiawei Zheng", "Jane Hillston", "Jacques D. Fleuriot"], "categories": ["cs.LO", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "Comments:      19 pages, 6 figures", "url": "http://arxiv.org/abs/2507.08701v1", "summary": "There is an imperative need to provide quality of life to a growing\npopulation of older adults living independently. Personalised solutions that\nfocus on the person and take into consideration their preferences and context\nare key. In this work, we introduce a framework for representing and reasoning\nabout the Activities of Daily Living of older adults living independently at\nhome. The framework integrates data from sensors and contextual information\nthat aggregates semi-structured interviews, home layouts and sociological\nobservations from the participants. We use these data to create formal models,\npersonalised for each participant according to their preferences and context.\nWe formulate requirements that are specific to each individual as properties\nencoded in Linear Temporal Logic and use a model checker to verify whether each\nproperty is satisfied by the model. When a property is violated, a\ncounterexample is generated giving the cause of the violation. We demonstrate\nthe framework's generalisability by applying it to different participants,\nhighlighting its potential to enhance the safety and well-being of older adults\nageing in place.", "comment": "19 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.08701v1", "cate": "cs.LO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08184", "title": "EP-GAT: Energy-based Parallel Graph Attention Neural Network for Stock Trend Classification", "authors": ["Zhuodong Jiang", "Pengju Zhang", "Peter Martin"], "categories": ["cs.CE", "cs.LG"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      Accepted by IJCNN 2025, oral presentation", "url": "http://arxiv.org/abs/2507.08184v1", "summary": "Graph neural networks have shown remarkable performance in forecasting stock\nmovements, which arises from learning complex inter-dependencies between stocks\nand intra-dynamics of stocks. Existing approaches based on graph neural\nnetworks typically rely on static or manually defined factors to model changing\ninter-dependencies between stocks. Furthermore, these works often struggle to\npreserve hierarchical features within stocks. To bridge these gaps, this work\npresents the Energy-based Parallel Graph Attention Neural Network, a novel\napproach for predicting future movements for multiple stocks. First, it\ngenerates a dynamic stock graph with the energy difference between stocks and\nBoltzmann distribution, capturing evolving inter-dependencies between stocks.\nThen, a parallel graph attention mechanism is proposed to preserve the\nhierarchical intra-stock dynamics. Extensive experiments on five real-world\ndatasets are conducted to validate the proposed approach, spanning from the US\nstock markets (NASDAQ, NYSE, SP) and UK stock markets (FTSE, LSE). The\nexperimental results demonstrate that EP-GAT consistently outperforms\ncompetitive five baselines on test periods across various metrics. The ablation\nstudies and hyperparameter sensitivity analysis further validate the\neffectiveness of each module in the proposed method.", "comment": "Accepted by IJCNN 2025, oral presentation", "pdf_url": "http://arxiv.org/pdf/2507.08184v1", "cate": "cs.CE", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08487", "title": "Enhancing Essay Cohesion Assessment: A Novel Item Response Theory Approach", "authors": ["Bruno Alexandre Rosa", "Hilário Oliveira", "Luiz Rodrigues", "Eduardo Araujo Oliveira", "Rafael Ferreira Mello"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      24 pages, 4 tables", "url": "http://arxiv.org/abs/2507.08487v1", "summary": "Essays are considered a valuable mechanism for evaluating learning outcomes\nin writing. Textual cohesion is an essential characteristic of a text, as it\nfacilitates the establishment of meaning between its parts. Automatically\nscoring cohesion in essays presents a challenge in the field of educational\nartificial intelligence. The machine learning algorithms used to evaluate texts\ngenerally do not consider the individual characteristics of the instances that\ncomprise the analysed corpus. In this meaning, item response theory can be\nadapted to the context of machine learning, characterising the ability,\ndifficulty and discrimination of the models used. This work proposes and\nanalyses the performance of a cohesion score prediction approach based on item\nresponse theory to adjust the scores generated by machine learning models. In\nthis study, the corpus selected for the experiments consisted of the extended\nEssay-BR, which includes 6,563 essays in the style of the National High School\nExam (ENEM), and the Brazilian Portuguese Narrative Essays, comprising 1,235\nessays written by 5th to 9th grade students from public schools. We extracted\n325 linguistic features and treated the problem as a machine learning\nregression task. The experimental results indicate that the proposed approach\noutperforms conventional machine learning models and ensemble methods in\nseveral evaluation metrics. This research explores a potential approach for\nimproving the automatic evaluation of cohesion in educational essays.", "comment": "24 pages, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.08487v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08542", "title": "CircFormerMoE: An End-to-End Deep Learning Framework for Circular RNA Splice Site Detection and Pairing in Plant Genomes", "authors": ["Tianyou Jiang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08542v1", "summary": "Circular RNAs (circRNAs) are important components of the non-coding RNA\nregulatory network. Previous circRNA identification primarily relies on\nhigh-throughput RNA sequencing (RNA-seq) data combined with alignment-based\nalgorithms that detect back-splicing signals. However, these methods face\nseveral limitations: they can't predict circRNAs directly from genomic DNA\nsequences and relies heavily on RNA experimental data; they involve high\ncomputational costs due to complex alignment and filtering steps; and they are\ninefficient for large-scale or genome-wide circRNA prediction. The challenge is\neven greater in plants, where plant circRNA splice sites often lack the\ncanonical GT-AG motif seen in human mRNA splicing, and no efficient deep\nlearning model with strong generalization capability currently exists.\nFurthermore, the number of currently identified plant circRNAs is likely far\nlower than their true abundance. In this paper, we propose a deep learning\nframework named CircFormerMoE based on transformers and mixture-of experts for\npredicting circRNAs directly from plant genomic DNA. Our framework consists of\ntwo subtasks known as splicing site detection (SSD) and splicing site pairing\n(SSP). The model's effectiveness has been validated on gene data of 10 plant\nspecies. Trained on known circRNA instances, it is also capable of discovering\npreviously unannotated circRNAs. In addition, we performed interpretability\nanalyses on the trained model to investigate the sequence patterns contributing\nto its predictions. Our framework provides a fast and accurate computational\nmethod and tool for large-scale circRNA discovery in plants, laying a\nfoundation for future research in plant functional genomics and non-coding RNA\nannotation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08542v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08460", "title": "F3-Net: Foundation Model for Full Abnormality Segmentation of Medical Images with Flexible Input Modality Requirement", "authors": ["Seyedeh Sahar Taheri Otaghsara", "Reza Rahmanzadeh"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08460v1", "summary": "F3-Net is a foundation model designed to overcome persistent challenges in\nclinical medical image segmentation, including reliance on complete multimodal\ninputs, limited generalizability, and narrow task specificity. Through flexible\nsynthetic modality training, F3-Net maintains robust performance even in the\npresence of missing MRI sequences, leveraging a zero-image strategy to\nsubstitute absent modalities without relying on explicit synthesis networks,\nthereby enhancing real-world applicability. Its unified architecture supports\nmulti-pathology segmentation across glioma, metastasis, stroke, and white\nmatter lesions without retraining, outperforming CNN-based and\ntransformer-based models that typically require disease-specific fine-tuning.\nEvaluated on diverse datasets such as BraTS 2021, BraTS 2024, and ISLES 2022,\nF3-Net demonstrates strong resilience to domain shifts and clinical\nheterogeneity. On the whole pathology dataset, F3-Net achieves average Dice\nSimilarity Coefficients (DSCs) of 0.94 for BraTS-GLI 2024, 0.82 for BraTS-MET\n2024, 0.94 for BraTS 2021, and 0.79 for ISLES 2022. This positions it as a\nversatile, scalable solution bridging the gap between deep learning research\nand practical clinical deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08460v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08702", "title": "ONION: A Multi-Layered Framework for Participatory ER Design", "authors": ["Viktoriia Makovska", "George Fletcher", "Julia Stoyanovich"], "categories": ["cs.DB", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08702v1", "summary": "We present ONION, a multi-layered framework for participatory\nEntity-Relationship (ER) modeling that integrates insights from design justice,\nparticipatory AI, and conceptual modeling. ONION introduces a five-stage\nmethodology: Observe, Nurture, Integrate, Optimize, Normalize. It supports\nprogressive abstraction from unstructured stakeholder input to structured ER\ndiagrams.\n  Our approach aims to reduce designer bias, promote inclusive participation,\nand increase transparency through the modeling process. We evaluate ONION\nthrough real-world workshops focused on sociotechnical systems in Ukraine,\nhighlighting how diverse stakeholder engagement leads to richer data models and\ndeeper mutual understanding. Early results demonstrate ONION's potential to\nhost diversity in early-stage data modeling. We conclude with lessons learned,\nlimitations and challenges involved in scaling and refining the framework for\nbroader adoption.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08702v1", "cate": "cs.DB", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2311.05076", "title": "Evaluating diversion and treatment policies for opioid use disorder", "authors": ["Veronica M. White", "Laura A. Albert"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2311.05076v4", "summary": "The United States (US) opioid crisis contributed to 81,806 fatalities in\n2022. It has strained hospitals, treatment facilities, and law enforcement\nagencies due to the enormous resources and procedures needed to respond to the\ncrisis. As a result, many individuals who use opioids never receive or finish\nthe treatment they need and instead have many interactions with hospitals or\nthe criminal justice system. This paper introduces a discrete event simulation\nmodel that evaluates three opioid use disorder treatment policies: arrest\ndiversion, re-entry case management, and overdose diversion. Publicly available\ndata from 2011 to 2019 in Dane County, Wisconsin, was used to forecast\nopioid-related outcomes through 2032. Through analyzing a variety of policy-mix\nimplementations, the study offers a versatile framework for evaluating policies\nat various implementation levels. The results demonstrate that treatment\npolicies that create new pathways and programming by utilizing treatment\nservices and successfully divert at least 20% of eligible individuals can lead\nto more opioid-resilient communities. The benefits increase when more policies\nare enacted and/or offered to more individuals, with the largest impact from\noverdose diversion, followed by re-entry case management, and the smallest\nimpact from arrest diversion. The statistically significant 10-year cumulative\ntotal reduction in societal costs from 2023 through 2032 ranges from $39 M\n(USD) to $584 M (USD), excluding implementation costs of policies. To reverse\nthe opioid crisis within a community, treatment policies may need to be\ncombined with other strategies, such as harm reduction, supply reduction, and\nuse prevention.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2311.05076v4", "cate": "cs.CE", "date": "2023-11-09", "updated": "2025-07-10"}
{"id": "2507.08499", "title": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts", "authors": ["Ziyi Huang", "Xia Cui"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08499v1", "summary": "This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in\nText-Based Emotion Detection (Track A), which focuses on multi-label emotion\ndetection in short texts. We propose a feature-centric framework that\ndynamically adapts document representations and learning algorithms to optimize\nlanguage-specific performance. Our study evaluates three key components:\ndocument representation, dimensionality reduction, and model training in 28\nlanguages, highlighting five for detailed analysis. The results show that\nTF-IDF remains highly effective for low-resource languages, while contextual\nembeddings like FastText and transformer-based document representations, such\nas those produced by Sentence-BERT, exhibit language-specific strengths.\nPrincipal Component Analysis (PCA) reduces training time without compromising\nperformance, particularly benefiting FastText and neural models such as\nMulti-Layer Perceptrons (MLP). Computational efficiency analysis underscores\nthe trade-off between model complexity and processing cost. Our framework\nprovides a scalable solution for multilingual emotion detection, addressing the\nchallenges of linguistic diversity and resource constraints.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08499v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08563", "title": "STRAP: Spatial-Temporal Risk-Attentive Vehicle Trajectory Prediction for Autonomous Driving", "authors": ["Xinyi Ning", "Zilin Bian", "Kaan Ozbay", "Semiha Ergan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, accepted at ITSC 2025", "url": "http://arxiv.org/abs/2507.08563v1", "summary": "Accurate vehicle trajectory prediction is essential for ensuring safety and\nefficiency in fully autonomous driving systems. While existing methods\nprimarily focus on modeling observed motion patterns and interactions with\nother vehicles, they often neglect the potential risks posed by the uncertain\nor aggressive behaviors of surrounding vehicles. In this paper, we propose a\nnovel spatial-temporal risk-attentive trajectory prediction framework that\nincorporates a risk potential field to assess perceived risks arising from\nbehaviors of nearby vehicles. The framework leverages a spatial-temporal\nencoder and a risk-attentive feature fusion decoder to embed the risk potential\nfield into the extracted spatial-temporal feature representations for\ntrajectory prediction. A risk-scaled loss function is further designed to\nimprove the prediction accuracy of high-risk scenarios, such as short relative\nspacing. Experiments on the widely used NGSIM and HighD datasets demonstrate\nthat our method reduces average prediction errors by 4.8% and 31.2%\nrespectively compared to state-of-the-art approaches, especially in high-risk\nscenarios. The proposed framework provides interpretable, risk-aware\npredictions, contributing to more robust decision-making for autonomous driving\nsystems.", "comment": "6 pages, 3 figures, accepted at ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2507.08563v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08492", "title": "Dual Dimensions Geometric Representation Learning Based Document Dewarping", "authors": ["Heng Li", "Qingcai Chen", "Xiangping Wu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08492v1", "summary": "Document image dewarping remains a challenging task in the deep learning era.\nWhile existing methods have improved by leveraging text line awareness, they\ntypically focus only on a single horizontal dimension. In this paper, we\npropose a fine-grained deformation perception model that focuses on Dual\nDimensions of document horizontal-vertical-lines to improve document Dewarping\ncalled D2Dewarp. It can perceive distortion trends in different directions\nacross document details. To combine the horizontal and vertical granularity\nfeatures, an effective fusion module based on X and Y coordinate is designed to\nfacilitate interaction and constraint between the two dimensions for feature\ncomplementarity. Due to the lack of annotated line features in current public\ndewarping datasets, we also propose an automatic fine-grained annotation method\nusing public document texture images and an automatic rendering engine to build\na new large-scale distortion training dataset. The code and dataset will be\npublicly released. On public Chinese and English benchmarks, both quantitative\nand qualitative results show that our method achieves better rectification\nresults compared with the state-of-the-art methods. The dataset will be\npublicly available at https://github.com/xiaomore/DocDewarpHV", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08492v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2501.19334", "title": "The Value of Prediction in Identifying the Worst-Off", "authors": ["Unai Fischer-Abaigar", "Christoph Kern", "Juan Carlos Perdomo"], "categories": ["cs.CY", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.19334v3", "summary": "Machine learning is increasingly used in government programs to identify and\nsupport the most vulnerable individuals, prioritizing assistance for those at\ngreatest risk over optimizing aggregate outcomes. This paper examines the\nwelfare impacts of prediction in equity-driven contexts, and how they compare\nto other policy levers, such as expanding bureaucratic capacity. Through\nmathematical models and a real-world case study on long-term unemployment\namongst German residents, we develop a comprehensive understanding of the\nrelative effectiveness of prediction in surfacing the worst-off. Our findings\nprovide clear analytical frameworks and practical, data-driven tools that\nempower policymakers to make principled decisions when designing these systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.19334v3", "cate": "cs.CY", "date": "2025-01-31", "updated": "2025-07-11"}
{"id": "2501.06583", "title": "Optimizing wheel loader performance -- an end-to-end approach", "authors": ["Koji Aoshima", "Eddie Wadbro", "Martin Servin"], "categories": ["cs.CE", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      18 pages, 11 figures", "url": "http://arxiv.org/abs/2501.06583v3", "summary": "Wheel loaders in mines and construction sites repeatedly load soil from a\npile to load receivers. Automating this task presents a challenging planning\nproblem since each loading's performance depends on the pile state, which\ndepends on previous loadings. We investigate an end-to-end optimization\napproach considering future loading outcomes and transportation costs between\nthe pile and load receivers. To predict the evolution of the pile state and the\nloading performance, we use world models that leverage deep neural networks\ntrained on numerous simulated loading cycles. A look-ahead tree search\noptimizes the sequence of loading actions by evaluating the performance of\nthousands of action candidates, which expand into subsequent action candidates\nunder the predicted pile states recursively. Test results demonstrate that,\nover a horizon of 15 sequential loadings, the look-ahead tree search is 6% more\nefficient than a greedy strategy, which always selects the action that\nmaximizes the current single loading performance, and 14% more efficient than\nusing a fixed loading controller optimized for the nominal case.", "comment": "18 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2501.06583v3", "cate": "cs.CE", "date": "2025-01-11", "updated": "2025-07-10"}
{"id": "2507.08530", "title": "MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling", "authors": ["Jingjing Tang", "Xin Wang", "Zhe Zhang", "Junichi Yamagishi", "Geraint Wiggins", "George Fazekas"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted by ISMIR 2025", "url": "http://arxiv.org/abs/2507.08530v1", "summary": "Generating expressive audio performances from music scores requires models to\ncapture both instrument acoustics and human interpretation. Traditional music\nperformance synthesis pipelines follow a two-stage approach, first generating\nexpressive performance MIDI from a score, then synthesising the MIDI into\naudio. However, the synthesis models often struggle to generalise across\ndiverse MIDI sources, musical styles, and recording environments. To address\nthese challenges, we propose MIDI-VALLE, a neural codec language model adapted\nfrom the VALLE framework, which was originally designed for zero-shot\npersonalised text-to-speech (TTS) synthesis. For performance MIDI-to-audio\nsynthesis, we improve the architecture to condition on a reference audio\nperformance and its corresponding MIDI. Unlike previous TTS-based systems that\nrely on piano rolls, MIDI-VALLE encodes both MIDI and audio as discrete tokens,\nfacilitating a more consistent and robust modelling of piano performances.\nFurthermore, the model's generalisation ability is enhanced by training on an\nextensive and diverse piano performance dataset. Evaluation results show that\nMIDI-VALLE significantly outperforms a state-of-the-art baseline, achieving\nover 75% lower Frechet Audio Distance on the ATEPP and Maestro datasets. In the\nlistening test, MIDI-VALLE received 202 votes compared to 58 for the baseline,\ndemonstrating improved synthesis quality and generalisation across diverse\nperformance MIDI inputs.", "comment": "Accepted by ISMIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.08530v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08567", "title": "AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling", "authors": ["Preslav Aleksandrov", "Meghdad Kurmanji", "Fernando Garcia Redondo", "David O'Shea", "William Shen", "Alex Iacob", "Lorenzo Sani", "Xinchi Qiu", "Nicola Cancedda", "Nicholas D. Lane"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      14 pages and 6 figures. Submitted to NeurIPS 2025", "url": "http://arxiv.org/abs/2507.08567v1", "summary": "We introduce the Autoregressive Block-Based Iterative Encoder (AbbIE), a\nnovel recursive generalization of the encoder-only Transformer architecture,\nwhich achieves better perplexity than a standard Transformer and allows for the\ndynamic scaling of compute resources at test time. This simple, recursive\napproach is a complement to scaling large language model (LLM) performance\nthrough parameter and token counts. AbbIE performs its iterations in latent\nspace, but unlike latent reasoning models, does not require a specialized\ndataset or training protocol. We show that AbbIE upward generalizes (ability to\ngeneralize to arbitrary iteration lengths) at test time by only using 2\niterations during train time, far outperforming alternative iterative methods.\nAbbIE's ability to scale its computational expenditure based on the complexity\nof the task gives it an up to \\textbf{12\\%} improvement in zero-shot in-context\nlearning tasks versus other iterative and standard methods and up to 5\\%\nimprovement in language perplexity. The results from this study open a new\navenue to Transformer performance scaling. We perform all of our evaluations on\nmodel sizes up to 350M parameters.", "comment": "14 pages and 6 figures. Submitted to NeurIPS 2025", "pdf_url": "http://arxiv.org/pdf/2507.08567v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08494", "title": "Unified People Tracking with Graph Neural Networks", "authors": ["Martin Engilberge", "Ivan Vrkic", "Friedrich Wilke Grosche", "Julien Pilet", "Engin Turetken", "Pascal Fua"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08494v1", "summary": "This work presents a unified, fully differentiable model for multi-people\ntracking that learns to associate detections into trajectories without relying\non pre-computed tracklets. The model builds a dynamic spatiotemporal graph that\naggregates spatial, contextual, and temporal information, enabling seamless\ninformation propagation across entire sequences. To improve occlusion handling,\nthe graph can also encode scene-specific information. We also introduce a new\nlarge-scale dataset with 25 partially overlapping views, detailed scene\nreconstructions, and extensive occlusions. Experiments show the model achieves\nstate-of-the-art performance on public benchmarks and the new dataset, with\nflexibility across diverse conditions. Both the dataset and approach will be\npublicly released to advance research in multi-people tracking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08494v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.13959", "title": "AI Safety Should Prioritize the Future of Work", "authors": ["Sanchaita Hazra", "Bodhisattwa Prasad Majumder", "Tuhin Chakrabarty"], "categories": ["cs.CY", "cs.AI", "cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13959v2", "summary": "Current efforts in AI safety prioritize filtering harmful content, preventing\nmanipulation of human behavior, and eliminating existential risks in\ncybersecurity or biosecurity. While pressing, this narrow focus overlooks\ncritical human-centric considerations that shape the long-term trajectory of a\nsociety. In this position paper, we identify the risks of overlooking the\nimpact of AI on the future of work and recommend comprehensive transition\nsupport towards the evolution of meaningful labor with human agency. Through\nthe lens of economic theories, we highlight the intertemporal impacts of AI on\nhuman livelihood and the structural changes in labor markets that exacerbate\nincome inequality. Additionally, the closed-source approach of major\nstakeholders in AI development resembles rent-seeking behavior through\nexploiting resources, breeding mediocrity in creative labor, and monopolizing\ninnovation. To address this, we argue in favor of a robust international\ncopyright anatomy supported by implementing collective licensing that ensures\nfair compensation mechanisms for using data to train AI models. We strongly\nrecommend a pro-worker framework of global AI governance to enhance shared\nprosperity and economic justice while reducing technical debt.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13959v2", "cate": "cs.CY", "date": "2025-04-16", "updated": "2025-07-11"}
{"id": "2507.07789", "title": "Computationally Efficient Information-Driven Optical Design with Interchanging Optimization", "authors": ["Eric Markley", "Henry Pinkard", "Leyla Kabuli", "Nalini Singh", "Laura Waller"], "categories": ["eess.IV", "cs.CE", "cs.CV", "cs.IT", "math.IT", "physics.optics"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07789v2", "summary": "Recent work has demonstrated that imaging systems can be evaluated through\nthe information content of their measurements alone, enabling\napplication-agnostic optical design that avoids computational decoding\nchallenges. Information-Driven Encoder Analysis Learning (IDEAL) was proposed\nto automate this process through gradient-based optimization. In this work, we\nstudy IDEAL across diverse imaging systems and find that it suffers from high\nmemory usage, long runtimes, and a potentially mismatched objective function\ndue to end-to-end differentiability requirements. We introduce IDEAL with\nInterchanging Optimization (IDEAL-IO), a method that decouples density\nestimation from optical parameter optimization by alternating between fitting\nmodels to current measurements and updating optical parameters using fixed\nmodels for information estimation. This approach reduces runtime and memory\nusage by up to 6x while enabling more expressive density models that guide\noptimization toward superior designs. We validate our method on diffractive\noptics, lensless imaging, and snapshot 3D microscopy applications, establishing\ninformation-theoretic optimization as a practical, scalable strategy for\nreal-world imaging system design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07789v2", "cate": "eess.IV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2505.20547", "title": "A Family of Sequences Generalizing the Thue Morse and Rudin Shapiro Sequences", "authors": ["Russell Jay Hendel"], "categories": ["cs.FL", "68Q45"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "Comments:      Version 3: Adds results about squares; removes many (inexcusable) typos; reformats equations so that they align; improved proofs; added remarks and concluding section comparing families of sequences to regular and synchronized sequence as a method of extending automatic sequences. Version 2 added results about palindromes. Next version will add results about borders", "url": "http://arxiv.org/abs/2505.20547v3", "summary": "For $m \\ge 1,$ let $P_m =1^m,$ the binary string of $m$ ones. Further define\nthe infinite sequence $s_m$ by $s_{m,n} = 1$ iff the number of (possibly\noverlapping) occurrences of $P_m$ in the binary representation of $n$ is odd,\n$n \\ge 0.$ For $m=1,2$ respectively $s_m$ is the Thue-Morse and Rudin-Shapiro\nsequences. This paper shows that for each $m\\ge 1,$ (i) $s_m$ is automatic;\n(ii) the minimal, DFA (deterministic finite automata) accepting $s_m$ has $2m$\nstates; (iii) it suffices to use prefixes of length $2^{m-1}$ to distinguish\nall sequences in the 2-kernel of $s_m$; and (iv) the characteristic function of\nthe length $2^{m-1}$ prefix of the 2-kernel sequences of $s_m$ can be\nformulated using the Vile and Jacobsthal sequences. The proofs are based on a\ncorrespondence between binary strings under concatenation and integers under\naddition and multiplication. Both Mathematica and Walnut are employed for\nexploratory analysis of patterns. The paper presents results about maximal\nruns, palindromes, order of squares, and borders in $s_m,$ generalizing similar\nresults for $s_1$ and $s_2.$ In the conclusion we suggest that families of\nautomatic sequences is a fruitful concept and a useful group of sequences\nextending automatic sequences similar to the regular and synchronized\nsequences.", "comment": "Version 3: Adds results about squares; removes many (inexcusable)\n  typos; reformats equations so that they align; improved proofs; added remarks\n  and concluding section comparing families of sequences to regular and\n  synchronized sequence as a method of extending automatic sequences. Version 2\n  added results about palindromes. Next version will add results about borders", "pdf_url": "http://arxiv.org/pdf/2505.20547v3", "cate": "cs.FL", "date": "2025-05-26", "updated": "2025-07-11"}
{"id": "2507.08546", "title": "RadiomicsRetrieval: A Customizable Framework for Medical Image Retrieval Using Radiomics Features", "authors": ["Inye Na", "Nejung Rue", "Jiwon Chung", "Hyunjin Park"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI 2025", "url": "http://arxiv.org/abs/2507.08546v1", "summary": "Medical image retrieval is a valuable field for supporting clinical\ndecision-making, yet current methods primarily support 2D images and require\nfully annotated queries, limiting clinical flexibility. To address this, we\npropose RadiomicsRetrieval, a 3D content-based retrieval framework bridging\nhandcrafted radiomics descriptors with deep learning-based embeddings at the\ntumor level. Unlike existing 2D approaches, RadiomicsRetrieval fully exploits\nvolumetric data to leverage richer spatial context in medical images. We employ\na promptable segmentation model (e.g., SAM) to derive tumor-specific image\nembeddings, which are aligned with radiomics features extracted from the same\ntumor via contrastive learning. These representations are further enriched by\nanatomical positional embedding (APE). As a result, RadiomicsRetrieval enables\nflexible querying based on shape, location, or partial feature sets. Extensive\nexperiments on both lung CT and brain MRI public datasets demonstrate that\nradiomics features significantly enhance retrieval specificity, while APE\nprovides global anatomical context essential for location-based searches.\nNotably, our framework requires only minimal user prompts (e.g., a single\npoint), minimizing segmentation overhead and supporting diverse clinical\nscenarios. The capability to query using either image embeddings or selected\nradiomics attributes highlights its adaptability, potentially benefiting\ndiagnosis, treatment planning, and research on large-scale medical imaging\nrepositories. Our code is available at\nhttps://github.com/nainye/RadiomicsRetrieval.", "comment": "Accepted at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.08546v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08605", "title": "Remote Sensing Reveals Adoption of Sustainable Rice Farming Practices Across Punjab, India", "authors": ["Ando Shah", "Rajveer Singh", "Akram Zaytar", "Girmaw Abebe Tadesse", "Caleb Robinson", "Negar Tafti", "Stephen A. Wood", "Rahul Dodhia", "Juan M. Lavista Ferres"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Dataset and code will be published shortly and links updated in v2", "url": "http://arxiv.org/abs/2507.08605v1", "summary": "Rice cultivation consumes 24-30% of global freshwater, creating critical\nwater management challenges in major rice-producing regions. Sustainable\nirrigation practices like direct seeded rice (DSR) and alternate wetting and\ndrying (AWD) can reduce water use by 20-40% while maintaining yields, helping\nsecure long-term agricultural productivity as water scarcity intensifies - a\nkey component of the Zero Hunger Sustainable Development Goal. However, limited\ndata on adoption rates of these practices prevents evidence-based policymaking\nand targeted resource allocation. We developed a novel remote sensing framework\nto monitor sustainable water management practices at scale in Punjab, India - a\nregion facing severe groundwater depletion of 41.6 cm/year. To collect\nessential ground truth data, we partnered with the Nature Conservancy's\nPromoting Regenerative and No-burn Agriculture (PRANA) program, which trained\napproximately 1,400 farmers on water-saving techniques while documenting their\nfield-level practices. Using this data, we created a classification system with\nSentinel-1 satellite imagery that separates water management along sowing and\nirrigation dimensions. Our approach achieved a 78% F1-score in distinguishing\nDSR from traditional puddled transplanted rice without requiring prior\nknowledge of planting dates. We demonstrated scalability by mapping DSR\nadoption across approximately 3 million agricultural plots in Punjab, with\ndistrict-level predictions showing strong correlation (Pearson=0.77, RBO= 0.77)\nwith government records. This study provides policymakers with a powerful tool\nto track sustainable water management adoption, target interventions, and\nmeasure program impacts at scale.", "comment": "Dataset and code will be published shortly and links updated in v2", "pdf_url": "http://arxiv.org/pdf/2507.08605v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08520", "title": "Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification", "authors": ["Yufei Zheng", "Wenjun Wang", "Wenjun Gan", "Jiawei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures", "url": "http://arxiv.org/abs/2507.08520v1", "summary": "Occluded person re-identification aims to retrieve holistic images based on\noccluded ones. Existing methods often rely on aligning visible body parts,\napplying occlusion augmentation, or complementing missing semantics using\nholistic images. However, they face challenges in handling diverse occlusion\nscenarios not seen during training and the issue of feature contamination from\nholistic images. To address these limitations, we propose Occlusion-Guided\nFeature Purification Learning via Reinforced Knowledge Distillation (OGFR),\nwhich simultaneously mitigates these challenges. OGFR adopts a teacher-student\ndistillation architecture that effectively incorporates diverse occlusion\npatterns into feature representation while transferring the purified\ndiscriminative holistic knowledge from the holistic to the occluded branch\nthrough reinforced knowledge distillation. Specifically, an Occlusion-Aware\nVision Transformer is designed to leverage learnable occlusion pattern\nembeddings to explicitly model such diverse occlusion types, thereby guiding\nocclusion-aware robust feature representation. Moreover, we devise a Feature\nErasing and Purification Module within the holistic branch, in which an agent\nis employed to identify low-quality patch tokens of holistic images that\ncontain noisy negative information via deep reinforcement learning, and\nsubstitute these patch tokens with learnable embedding tokens to avoid feature\ncontamination and further excavate identity-related discriminative clues.\nAfterward, with the assistance of knowledge distillation, the student branch\neffectively absorbs the purified holistic knowledge to precisely learn robust\nrepresentation regardless of the interference of occlusions.", "comment": "13 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.08520v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.08846", "title": "Addressing Pitfalls in Auditing Practices of Automatic Speech Recognition Technologies: A Case Study of People with Aphasia", "authors": ["Katelyn Xiaoying Mei", "Anna Seo Gyeong Choi", "Hilke Schellmann", "Mona Sloane", "Allison Koenecke"], "categories": ["cs.CY", "cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.08846v2", "summary": "Automatic Speech Recognition (ASR) has transformed daily tasks from video\ntranscription to workplace hiring. ASR systems' growing use warrants robust and\nstandardized auditing approaches to ensure automated transcriptions of high and\nequitable quality. This is especially critical for people with speech and\nlanguage disorders (such as aphasia) who may disproportionately depend on ASR\nsystems to navigate everyday life. In this work, we identify three pitfalls in\nexisting standard ASR auditing procedures, and demonstrate how addressing them\nimpacts audit results via a case study of six popular ASR systems' performance\nfor aphasia speakers. First, audits often adhere to a single method of text\nstandardization during data pre-processing, which (a) masks variability in ASR\nperformance from applying different standardization methods, and (b) may not be\nconsistent with how users - especially those from marginalized speech\ncommunities - would want their transcriptions to be standardized. Second,\naudits often display high-level demographic findings without further\nconsidering performance disparities among (a) more nuanced demographic\nsubgroups, and (b) relevant covariates capturing acoustic information from the\ninput audio. Third, audits often rely on a single gold-standard metric -- the\nWord Error Rate -- which does not fully capture the extent of errors arising\nfrom generative AI models, such as transcription hallucinations. We propose a\nmore holistic auditing framework that accounts for these three pitfalls, and\nexemplify its results in our case study, finding consistently worse ASR\nperformance for aphasia speakers relative to a control group. We call on\npractitioners to implement these robust ASR auditing practices that remain\nflexible to the rapidly changing ASR landscape.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.08846v2", "cate": "cs.CY", "date": "2025-06-10", "updated": "2025-07-11"}
{"id": "2301.12463", "title": "Comparing Spoken Languages using Paninian System of Sounds and Finite State Machines", "authors": ["Shreekanth M Prabhu", "Abhisek Midya"], "categories": ["cs.CL", "cs.FL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      63 Pages, 20 Figures, 27 Tables", "url": "http://arxiv.org/abs/2301.12463v3", "summary": "The study of spoken languages comprises phonology, morphology, and grammar.\nThe languages can be classified as root languages, inflectional languages, and\nstem languages. In addition, languages continually change over time and space\nby picking isoglosses, as speakers move from region to/through region. All\nthese factors lead to the formation of vocabulary, which has\ncommonality/similarity across languages as well as distinct and subtle\ndifferences among them. Comparison of vocabularies across languages and\ndetailed analysis has led to the hypothesis of language families. In\nparticular, in the view of Western linguists, Vedic Sanskrit is a daughter\nlanguage, part of the Indo-Iranian branch of the Indo-European Language family,\nand Dravidian Languages belong to an entirely different family. These and such\nconclusions are reexamined in this paper. Based on our study and analysis, we\npropose an Ecosystem Model for Linguistic Development with Sanskrit at the\ncore, in place of the widely accepted family tree model. To that end, we\nleverage the Paninian system of sounds to construct a phonetic map. Then we\nrepresent words across languages as state transitions on the phonetic map and\nconstruct corresponding Morphological Finite Automata (MFA) that accept groups\nof words. Regardless of whether the contribution of this paper is significant\nor minor, it is an important step in challenging policy-driven research that\nhas plagued this field.", "comment": "63 Pages, 20 Figures, 27 Tables", "pdf_url": "http://arxiv.org/pdf/2301.12463v3", "cate": "cs.CL", "date": "2023-01-29", "updated": "2025-07-11"}
{"id": "2507.08557", "title": "FreeAudio: Training-Free Timing Planning for Controllable Long-Form Text-to-Audio Generation", "authors": ["Yuxuan Jiang", "Zehua Chen", "Zeqian Ju", "Chang Li", "Weibei Dou", "Jun Zhu"], "categories": ["cs.SD", "cs.AI", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ACM MM 2025", "url": "http://arxiv.org/abs/2507.08557v1", "summary": "Text-to-audio (T2A) generation has achieved promising results with the recent\nadvances in generative models. However, because of the limited quality and\nquantity of temporally-aligned audio-text pairs, existing T2A methods struggle\nto handle the complex text prompts that contain precise timing control, e.g.,\n\"owl hooted at 2.4s-5.2s\". Recent works have explored data augmentation\ntechniques or introduced timing conditions as model inputs to enable\ntiming-conditioned 10-second T2A generation, while their synthesis quality is\nstill limited. In this work, we propose a novel training-free timing-controlled\nT2A framework, FreeAudio, making the first attempt to enable timing-controlled\nlong-form T2A generation, e.g., \"owl hooted at 2.4s-5.2s and crickets chirping\nat 0s-24s\". Specifically, we first employ an LLM to plan non-overlapping time\nwindows and recaption each with a refined natural language description, based\non the input text and timing prompts. Then we introduce: 1) Decoupling and\nAggregating Attention Control for precise timing control; 2) Contextual Latent\nComposition for local smoothness and Reference Guidance for global consistency.\nExtensive experiments show that: 1) FreeAudio achieves state-of-the-art\ntiming-conditioned T2A synthesis quality among training-free methods and is\ncomparable to leading training-based methods; 2) FreeAudio demonstrates\ncomparable long-form generation quality with training-based Stable Audio and\npaves the way for timing-controlled long-form T2A synthesis. Demo samples are\navailable at: https://freeaudio.github.io/FreeAudio/", "comment": "Accepted at ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.08557v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08610", "title": "Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data", "authors": ["Parag Dutta", "Ambedkar Dukkipati"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08610v1", "summary": "Image captioning is an important problem in developing various AI systems,\nand these tasks require large volumes of annotated images to train the models.\nSince all existing labelled datasets are already used for training the large\nVision Language Models (VLMs), it becomes challenging to improve the\nperformance of the same. Considering this, it is essential to consider the\nunsupervised image captioning performance, which remains relatively\nunder-explored. To that end, we propose LoGIC (Lewis Communication Game for\nImage Captioning), a Multi-agent Reinforcement Learning game. The proposed\nmethod consists of two agents, a 'speaker' and a 'listener', with the objective\nof learning a strategy for communicating in natural language. We train agents\nin the cooperative common-reward setting using the GRPO algorithm and show that\nimprovement in image captioning performance emerges as a consequence of the\nagents learning to play the game. We show that using pre-trained VLMs as the\n'speaker' and Large Language Model (LLM) for language understanding in the\n'listener', we achieved a $46$ BLEU score after fine-tuning using LoGIC without\nadditional labels, a $2$ units advantage in absolute metrics compared to the\n$44$ BLEU score of the vanilla VLM. Additionally, we replace the VLM from the\n'speaker' with lightweight components: (i) a ViT for image perception and (ii)\na GPT2 language generation, and train them from scratch using LoGIC, obtaining\na $31$ BLEU score in the unsupervised setting, a $10$ points advantage over\nexisting unsupervised image-captioning methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08610v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08548", "title": "SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2", "authors": ["Alen Adamyan", "Tomáš Čížek", "Matej Straka", "Klara Janouskova", "Martin Schmid"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08548v1", "summary": "Segment Anything Model 2 (SAM 2) has demonstrated strong performance in\nobject segmentation tasks and has become the state-of-the-art for visual object\ntracking. The model stores information from previous frames in a memory bank,\nenabling temporal consistency across video sequences. Recent methods augment\nSAM 2 with hand-crafted update rules to better handle distractors, occlusions,\nand object motion. We propose a fundamentally different approach using\nreinforcement learning for optimizing memory updates in SAM 2 by framing memory\ncontrol as a sequential decision-making problem. In an overfitting setup with a\nseparate agent per video, our method achieves a relative improvement over SAM 2\nthat exceeds by more than three times the gains of existing heuristics. These\nresults reveal the untapped potential of the memory bank and highlight\nreinforcement learning as a powerful alternative to hand-crafted update rules\nfor memory control in visual object tracking.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08548v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2409.17642", "title": "AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure", "authors": ["Zhiyang Zhang", "Xi Chen", "Fangkai Yang", "Xiaoting Qin", "Chao Du", "Xi Cheng", "Hangxin Liu", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.17642v3", "summary": "Large language model (LLM)-based AI delegates are increasingly utilized to\nact on behalf of users, assisting them with a wide range of tasks through\nconversational interfaces. Despite their advantages, concerns arise regarding\nthe potential risk of privacy leaks, particularly in scenarios involving social\ninteractions. While existing research has focused on protecting privacy by\nlimiting the access of AI delegates to sensitive user information, many social\nscenarios require disclosing private details to achieve desired social goals,\nnecessitating a balance between privacy protection and disclosure. To address\nthis challenge, we first conduct a pilot study to investigate user perceptions\nof AI delegates across various social relations and task scenarios, and then\npropose a novel AI delegate system that enables privacy-conscious\nself-disclosure. Our user study demonstrates that the proposed AI delegate\nstrategically protects privacy, pioneering its use in diverse and dynamic\nsocial interactions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.17642v3", "cate": "cs.AI", "date": "2024-09-26", "updated": "2025-07-11"}
{"id": "2506.14123", "title": "Sampling from Your Language Model One Byte at a Time", "authors": ["Jonathan Hayase", "Alisa Liu", "Noah A. Smith", "Sewoong Oh"], "categories": ["cs.CL", "cs.FL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 pages, 8 figures", "url": "http://arxiv.org/abs/2506.14123v2", "summary": "Tokenization is used almost universally by modern language models, enabling\nefficient text representation using multi-byte or multi-character tokens.\nHowever, prior work has shown that tokenization can introduce distortion into\nthe model's generations, an issue known as the Prompt Boundary Problem (PBP).\nFor example, users are often advised not to end their prompts with a space\nbecause it prevents the model from including the space as part of the next\ntoken. While this heuristic is effective in English, the underlying PBP\ncontinues to affect languages such as Chinese as well as code generation, where\ntokens often do not line up with word and syntactic boundaries. In this work,\nwe present an inference-time method to convert any autoregressive LM with a BPE\ntokenizer into a character-level or byte-level LM. Our method efficiently\nsolves the PBP and is also able to unify the vocabularies of language models\nwith different tokenizers, allowing one to ensemble LMs with different\ntokenizers at inference time or transfer the post-training from one model to\nanother using proxy-tuning. We demonstrate in experiments that the ensemble and\nproxy-tuned models outperform their constituents on downstream evals. Code is\navailable at https://github.com/SewoongLab/byte-sampler .", "comment": "23 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2506.14123v2", "cate": "cs.CL", "date": "2025-06-17", "updated": "2025-07-11"}
{"id": "2507.08574", "title": "A Multi-Modal Fusion Framework for Brain Tumor Segmentation Based on 3D Spatial-Language-Vision Integration and Bidirectional Interactive Attention Mechanism", "authors": ["Mingda Zhang", "Kaiwen Pan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08574v1", "summary": "This study aims to develop a novel multi-modal fusion framework for brain\ntumor segmentation that integrates spatial-language-vision information through\nbidirectional interactive attention mechanisms to improve segmentation accuracy\nand boundary delineation. Methods: We propose two core components: Multi-modal\nSemantic Fusion Adapter (MSFA) integrating 3D MRI data with clinical text\ndescriptions through hierarchical semantic decoupling, and Bidirectional\nInteractive Visual-semantic Attention (BIVA) enabling iterative information\nexchange between modalities. The framework was evaluated on BraTS 2020 dataset\ncomprising 369 multi-institutional MRI scans. Results: The proposed method\nachieved average Dice coefficient of 0.8505 and 95% Hausdorff distance of\n2.8256mm across enhancing tumor, tumor core, and whole tumor regions,\noutperforming state-of-the-art methods including SCAU-Net, CA-Net, and 3D\nU-Net. Ablation studies confirmed critical contributions of semantic and\nspatial modules to boundary precision. Conclusion: Multi-modal semantic fusion\ncombined with bidirectional interactive attention significantly enhances brain\ntumor segmentation performance, establishing new paradigms for integrating\nclinical knowledge into medical image analysis.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08574v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08617", "title": "Towards Collaborative Fairness in Federated Learning Under Imbalanced Covariate Shift", "authors": ["Tianrun Yu", "Jiaqi Wang", "Haoyu Wang", "Mingquan Lin", "Han Liu", "Nelson S. Yee", "Fenglong Ma"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, accepted to the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD' 25), Toronto, Canada, August 3-7 2025", "url": "http://arxiv.org/abs/2507.08617v1", "summary": "Collaborative fairness is a crucial challenge in federated learning. However,\nexisting approaches often overlook a practical yet complex form of\nheterogeneity: imbalanced covariate shift. We provide a theoretical analysis of\nthis setting, which motivates the design of FedAKD (Federated Asynchronous\nKnowledge Distillation)- simple yet effective approach that balances accurate\nprediction with collaborative fairness. FedAKD consists of client and server\nupdates. In the client update, we introduce a novel asynchronous knowledge\ndistillation strategy based on our preliminary analysis, which reveals that\nwhile correctly predicted samples exhibit similar feature distributions across\nclients, incorrectly predicted samples show significant variability. This\nsuggests that imbalanced covariate shift primarily arises from misclassified\nsamples. Leveraging this insight, our approach first applies traditional\nknowledge distillation to update client models while keeping the global model\nfixed. Next, we select correctly predicted high-confidence samples and update\nthe global model using these samples while keeping client models fixed. The\nserver update simply aggregates all client models. We further provide a\ntheoretical proof of FedAKD's convergence. Experimental results on public\ndatasets (FashionMNIST and CIFAR10) and a real-world Electronic Health Records\n(EHR) dataset demonstrate that FedAKD significantly improves collaborative\nfairness, enhances predictive accuracy, and fosters client participation even\nunder highly heterogeneous data distributions.", "comment": "18 pages, accepted to the 31st ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD' 25), Toronto, Canada, August 3-7 2025", "pdf_url": "http://arxiv.org/pdf/2507.08617v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08554", "title": "Image Translation with Kernel Prediction Networks for Semantic Segmentation", "authors": ["Cristina Mata", "Michael S. Ryoo", "Henrik Turbell"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      OOD-CV Workshop at ECCV 2024", "url": "http://arxiv.org/abs/2507.08554v1", "summary": "Semantic segmentation relies on many dense pixel-wise annotations to achieve\nthe best performance, but owing to the difficulty of obtaining accurate\nannotations for real world data, practitioners train on large-scale synthetic\ndatasets. Unpaired image translation is one method used to address the ensuing\ndomain gap by generating more realistic training data in low-data regimes.\nCurrent methods for unpaired image translation train generative adversarial\nnetworks (GANs) to perform the translation and enforce pixel-level semantic\nmatching through cycle consistency. These methods do not guarantee that the\nsemantic matching holds, posing a problem for semantic segmentation where\nperformance is sensitive to noisy pixel labels. We propose a novel image\ntranslation method, Domain Adversarial Kernel Prediction Network (DA-KPN), that\nguarantees semantic matching between the synthetic label and translation.\nDA-KPN estimates pixel-wise input transformation parameters of a lightweight\nand simple translation function. To ensure the pixel-wise transformation is\nrealistic, DA-KPN uses multi-scale discriminators to distinguish between\ntranslated and target samples. We show DA-KPN outperforms previous GAN-based\nmethods on syn2real benchmarks for semantic segmentation with limited access to\nreal image labels and achieves comparable performance on face parsing.", "comment": "OOD-CV Workshop at ECCV 2024", "pdf_url": "http://arxiv.org/pdf/2507.08554v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.07531", "title": "A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure", "authors": ["Warmhold Jan Thomas Mollema"], "categories": ["cs.AI", "cs.CY", "K.4"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      33 pages; 3 figures; 3 tables", "url": "http://arxiv.org/abs/2504.07531v2", "summary": "Epistemic injustice related to AI is a growing concern. In relation to\nmachine learning models, epistemic injustice can have a diverse range of\nsources, ranging from epistemic opacity, the discriminatory automation of\ntestimonial prejudice, and the distortion of human beliefs via generative AI's\nhallucinations to the exclusion of the global South in global AI governance,\nthe execution of bureaucratic violence via algorithmic systems, and\ninteractions with conversational artificial agents. Based on a proposed general\ntaxonomy of epistemic injustice, this paper first sketches a taxonomy of the\ntypes of epistemic injustice in the context of AI, relying on the work of\nscholars from the fields of philosophy of technology, political philosophy and\nsocial epistemology. Secondly, an additional conceptualization on epistemic\ninjustice in the context of AI is provided: generative hermeneutical erasure. I\nargue that this injustice the automation of 'epistemicide', the injustice done\nto epistemic agents in their capacity for collective sense-making through the\nsuppression of difference in epistemology and conceptualization by LLMs. AI\nsystems' 'view from nowhere' epistemically inferiorizes non-Western\nepistemologies and thereby contributes to the erosion of their epistemic\nparticulars, gradually contributing to hermeneutical erasure. This work's\nrelevance lies in proposal of a taxonomy that allows epistemic injustices to be\nmapped in the AI domain and the proposal of a novel form of AI-related\nepistemic injustice.", "comment": "33 pages; 3 figures; 3 tables", "pdf_url": "http://arxiv.org/pdf/2504.07531v2", "cate": "cs.AI", "date": "2025-04-10", "updated": "2025-07-11"}
{"id": "2507.08621", "title": "A comprehensive study of LLM-based argument classification: from LLAMA through GPT-4o to Deepseek-R1", "authors": ["Marcin Pietroń", "Rafał Olszowski", "Jakub Gomułka", "Filip Gampel", "Andrzej Tomski"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08621v1", "summary": "Argument mining (AM) is an interdisciplinary research field that integrates\ninsights from logic, philosophy, linguistics, rhetoric, law, psychology, and\ncomputer science. It involves the automatic identification and extraction of\nargumentative components, such as premises and claims, and the detection of\nrelationships between them, such as support, attack, or neutrality. Recently,\nthe field has advanced significantly, especially with the advent of large\nlanguage models (LLMs), which have enhanced the efficiency of analyzing and\nextracting argument semantics compared to traditional methods and other deep\nlearning models. There are many benchmarks for testing and verifying the\nquality of LLM, but there is still a lack of research and results on the\noperation of these models in publicly available argument classification\ndatabases. This paper presents a study of a selection of LLM's, using diverse\ndatasets such as Args.me and UKP. The models tested include versions of GPT,\nLlama, and DeepSeek, along with reasoning-enhanced variants incorporating the\nChain-of-Thoughts algorithm. The results indicate that ChatGPT-4o outperforms\nthe others in the argument classification benchmarks. In case of models\nincorporated with reasoning capabilities, the Deepseek-R1 shows its\nsuperiority. However, despite their superiority, GPT-4o and Deepseek-R1 still\nmake errors. The most common errors are discussed for all models. To our\nknowledge, the presented work is the first broader analysis of the mentioned\ndatasets using LLM and prompt algorithms. The work also shows some weaknesses\nof known prompt algorithms in argument analysis, while indicating directions\nfor their improvement. The added value of the work is the in-depth analysis of\nthe available argument datasets and the demonstration of their shortcomings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08621v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08637", "title": "Scaling Attention to Very Long Sequences in Linear Time with Wavelet-Enhanced Random Spectral Attention (WERSA)", "authors": ["Vincenzo Dentamaro"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure", "url": "http://arxiv.org/abs/2507.08637v1", "summary": "Transformer models are computationally costly on long sequences since regular\nattention has quadratic $O(n^2)$ time complexity. We introduce Wavelet-Enhanced\nRandom Spectral Attention (WERSA), a novel mechanism of linear $O(n)$ time\ncomplexity that is pivotal to enable successful long-sequence processing\nwithout the performance trade-off. WERSA merges content-adaptive random\nspectral features together with multi-resolution Haar wavelets and learnable\nparameters to selectively attend to informative scales of data while preserving\nlinear efficiency.\n  Large-scale comparisons \\textbf{on single GPU} and across various benchmarks\n(vision, NLP, hierarchical reasoning) and various attention mechanisms (like\nMultiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer,\nWaveformer), reveal uniform advantages of WERSA. It achieves best accuracy in\nall tests. On ArXiv classification, WERSA improves accuracy over vanilla\nattention by 1.2\\% (86.2\\% vs 85.0\\%) while cutting training time by 81\\% (296s\nvs 1554s) and FLOPS by 73.4\\% (26.2G vs 98.4G). Significantly, WERSA excels\nwhere vanilla and FlashAttention-2 fail: on ArXiv-128k's extremely lengthy\nsequences, it achieves best accuracy (79.1\\%) and AUC (0.979) among viable\nmethods, operating on data that gives Out-Of-Memory errors to quadratic methods\nwhile being \\textbf{twice as fast} as Waveformer, its next-best competitor.\n  By significantly reducing computational loads without compromising accuracy,\nWERSA makes possible more practical, more affordable, long-context models, in\nparticular on low-resource hardware, for more sustainable and more scalable AI\ndevelopment.", "comment": "10 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.08637v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08555", "title": "Disentangling Instance and Scene Contexts for 3D Semantic Scene Completion", "authors": ["Enyu Liu", "En Yu", "Sijia Chen", "Wenbing Tao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.08555v1", "summary": "3D Semantic Scene Completion (SSC) has gained increasing attention due to its\npivotal role in 3D perception. Recent advancements have primarily focused on\nrefining voxel-level features to construct 3D scenes. However, treating voxels\nas the basic interaction units inherently limits the utilization of class-level\ninformation, which is proven critical for enhancing the granularity of\ncompletion results. To address this, we propose \\textbf{D}isentangling Instance\nand Scene Contexts (DISC), a novel dual-stream paradigm that enhances learning\nfor both instance and scene categories through separated optimization.\nSpecifically, we replace voxel queries with discriminative class queries, which\nincorporate class-specific geometric and semantic priors. Additionally, we\nexploit the intrinsic properties of classes to design specialized decoding\nmodules, facilitating targeted interactions and efficient class-level\ninformation flow. Experimental results demonstrate that DISC achieves\nstate-of-the-art (SOTA) performance on both SemanticKITTI and\nSSCBench-KITTI-360 benchmarks, with mIoU scores of 17.35 and 20.55,\nrespectively. Remarkably, DISC even outperforms multi-frame SOTA methods using\nonly single-frame input and significantly improves instance category\nperformance, surpassing both single-frame and multi-frame SOTA instance mIoU by\n17.9\\% and 11.9\\%, respectively, on the SemanticKITTI hidden test. The code is\navailable at https://github.com/Enyu-Liu/DISC.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.08555v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.12546", "title": "Extracting memorized pieces of (copyrighted) books from open-weight language models", "authors": ["A. Feder Cooper", "Aaron Gokaslan", "Ahmed Ahmed", "Amy B. Cyphert", "Christopher De Sa", "Mark A. Lemley", "Daniel E. Ho", "Percy Liang"], "categories": ["cs.CL", "cs.CY", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12546v2", "summary": "Plaintiffs and defendants in copyright lawsuits over generative AI often make\nsweeping, opposing claims about the extent to which large language models\n(LLMs) have memorized plaintiffs' protected expression. Drawing on adversarial\nML and copyright law, we show that these polarized positions dramatically\noversimplify the relationship between memorization and copyright. To do so, we\nleverage a recent probabilistic extraction technique to extract pieces of the\nBooks3 dataset from 17 open-weight LLMs. Through numerous experiments, we show\nthat it's possible to extract substantial parts of at least some books from\ndifferent LLMs. This is evidence that these LLMs have memorized the extracted\ntext; this memorized content is copied inside the model parameters. But the\nresults are complicated: the extent of memorization varies both by model and by\nbook. With our specific experiments, we find that the largest LLMs don't\nmemorize most books--either in whole or in part. However, we also find that\nLlama 3.1 70B memorizes some books, like Harry Potter and the Sorcerer's Stone\nand 1984, almost entirely. In fact, Harry Potter is so memorized that, using a\nseed prompt consisting of just the first line of chapter 1, we can\ndeterministically generate the entire book near-verbatim. We discuss why our\nresults have significant implications for copyright cases, though not ones that\nunambiguously favor either side.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12546v2", "cate": "cs.CL", "date": "2025-05-18", "updated": "2025-07-10"}
{"id": "2507.08196", "title": "Deep Reinforcement Learning in Applied Control: Challenges, Analysis, and Insights", "authors": ["Klinsmann Agyei", "Pouria Sarhadi", "Daniel Polani"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08196v1", "summary": "Over the past decade, remarkable progress has been made in adopting deep\nneural networks to enhance the performance of conventional reinforcement\nlearning. A notable milestone was the development of Deep Q-Networks (DQN),\nwhich achieved human-level performance across a range of Atari games,\ndemonstrating the potential of deep learning to stabilise and scale\nreinforcement learning. Subsequently, extensions to continuous control\nalgorithms paved the way for a new paradigm in control, one that has attracted\nbroader attention than any classical control approach in recent literature.\nThese developments also demonstrated strong potential for advancing\ndata-driven, model-free algorithms for control and for achieving higher levels\nof autonomy. However, the application of these methods has remained largely\nconfined to simulated and gaming environments, with ongoing efforts to extend\nthem to real-world applications. Before such deployment can be realised, a\nsolid and quantitative understanding of their performance on applied control\nproblems is necessary. This paper conducts a comparative analysis of these\napproaches on four diverse benchmark problems with implementation results. This\nanalysis offers a scrutinising and systematic evaluation to shed light on the\nreal-world capabilities and limitations of deep reinforcement learning methods\nin applied control settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08196v1", "cate": "eess.SY", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08636", "title": "Normalized vs Diplomatic Annotation: A Case Study of Automatic Information Extraction from Handwritten Uruguayan Birth Certificates", "authors": ["Natalia Bottaioli", "Solène Tarride", "Jérémy Anger", "Seginus Mowlavi", "Marina Gardella", "Antoine Tadros", "Gabriele Facciolo", "Rafael Grompone von Gioi", "Christopher Kermorvant", "Jean-Michel Morel", "Javier Preciozzi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08636v1", "summary": "This study evaluates the recently proposed Document Attention Network (DAN)\nfor extracting key-value information from Uruguayan birth certificates,\nhandwritten in Spanish. We investigate two annotation strategies for\nautomatically transcribing handwritten documents, fine-tuning DAN with minimal\ntraining data and annotation effort. Experiments were conducted on two datasets\ncontaining the same images (201 scans of birth certificates written by more\nthan 15 different writers) but with different annotation methods. Our findings\nindicate that normalized annotation is more effective for fields that can be\nstandardized, such as dates and places of birth, whereas diplomatic annotation\nperforms much better for fields containing names and surnames, which can not be\nstandardized.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08636v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08686", "title": "Forget Me Not: Fighting Local Overfitting with Knowledge Fusion and Distillation", "authors": ["Uri Stern", "Eli Corn", "Daphna Weinshall"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      arXiv admin note: substantial text overlap with arXiv:2412.12968", "url": "http://arxiv.org/abs/2507.08686v1", "summary": "Overfitting in deep neural networks occurs less frequently than expected.\nThis is a puzzling observation, as theory predicts that greater model capacity\nshould eventually lead to overfitting -- yet this is rarely seen in practice.\nBut what if overfitting does occur, not globally, but in specific sub-regions\nof the data space? In this work, we introduce a novel score that measures the\nforgetting rate of deep models on validation data, capturing what we term local\noverfitting: a performance degradation confined to certain regions of the input\nspace. We demonstrate that local overfitting can arise even without\nconventional overfitting, and is closely linked to the double descent\nphenomenon.\n  Building on these insights, we introduce a two-stage approach that leverages\nthe training history of a single model to recover and retain forgotten\nknowledge: first, by aggregating checkpoints into an ensemble, and then by\ndistilling it into a single model of the original size, thus enhancing\nperformance without added inference cost.\n  Extensive experiments across multiple datasets, modern architectures, and\ntraining regimes validate the effectiveness of our approach. Notably, in the\npresence of label noise, our method -- Knowledge Fusion followed by Knowledge\nDistillation -- outperforms both the original model and independently trained\nensembles, achieving a rare win-win scenario: reduced training and inference\ncomplexity.", "comment": "arXiv admin note: substantial text overlap with arXiv:2412.12968", "pdf_url": "http://arxiv.org/pdf/2507.08686v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08607", "title": "BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis", "authors": ["Shuang Cui", "Jinglin Xu", "Yi Li", "Xiongxin Tang", "Jiangmeng Li", "Jiahuan Zhou", "Fanjiang Xu", "Fuchun Sun", "Hui Xiong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08607v1", "summary": "Vision-language models (VLMs) such as CLIP achieve strong zero-shot\nrecognition but degrade significantly under \\textit{temporally evolving\ndistribution shifts} common in real-world scenarios (e.g., gradual illumination\nor seasonal changes). Existing continual test-time adaptation (CTTA) methods\nare typically built around sudden and severe distribution shifts and neglect\ntemporal continuity, leading to three core defects: limited memory cache\nrestricts long-range distribution modeling, causing catastrophic forgetting;\nentropy-based confidence becomes unreliable under temporal drift, worsening\nerror accumulation; and static visual representations misalign with evolving\ninputs. We formalize this practical problem as \\textit{Continual-Temporal\nTest-Time Adaptation (CT-TTA)}, where test distributions evolve gradually over\ntime. To address it, we propose \\textit{BayesTTA}, a Bayesian adaptation\nframework that enforces temporally consistent predictions and dynamically\naligns visual representations. Specifically, BayesTTA incrementally estimates\nclass-conditional Gaussian mixture distributions without storing raw data,\nadaptively selects covariance structures through statistical hypothesis\ntesting, and performs calibrated inference using Gaussian discriminant analysis\n(GDA). These calibrated predictions supervise self-paced adaptation of\nnormalization layers, ensuring efficient and stable representation alignment.\nWe establish a comprehensive CT-TTA benchmark across four temporally evolving\ndatasets and further evaluate generalization on ten standard TTA datasets.\nExtensive experiments show that BayesTTA consistently outperforms\nstate-of-the-art methods, achieving significant gains while maintaining\nefficiency. Code is available at\n\\href{https://github.com/cuishuang99/BayesTTA}{https://github.com/cuishuang99/BayesTTA}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08607v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08234", "title": "Maneuver Detection via a Confidence Dominance Maneuver Indicator", "authors": ["Xingyu Zhou", "Roberto Armellin", "Laura Pirovano", "Dong Qiao", "Xiangyu Li"], "categories": ["eess.SY", "astro-ph.IM", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08234v1", "summary": "Accurate and efficient maneuver detection is critical for ensuring the safety\nand predictability of spacecraft trajectories. This paper presents a novel\nmaneuver detection approach based on comparing the confidence levels associated\nwith the orbital state estimation and the observation likelihood. First, a\nconfidence-dominance maneuver indicator (CDMI) is proposed by setting a\nconfidence level for the state estimation and computing the maximum likelihood\nof the observation and its confidence level. The CDMI then flag a maneuver when\nthe observation's confidence level exceeds that of the state estimation,\nindicating that the observation is unlikely under the no-maneuver hypothesis\nwhile maintaining consistency with the prior state estimation confidence. To\nefficiently compute the maximum likelihood of the observation and obtain the\nCDMI, a recursive polynomial optimization method is developed, taking advantage\nof convex optimization and polynomial approximation. In addition, an integrated\nCDMI approach is developed to eliminate the need to manually select the state\nconfidence level. The integrated CDMI approach maintains high detection\naccuracy while simultaneously providing an indication of maneuver likelihood,\nthereby enhancing robustness and practical applicability. The performance of\nthe proposed CDMI-based maneuver detection approaches is evaluated against an\noptimal control distance metric and two mixture-based approaches. The\nsimulation results demonstrate that the proposed integrated CDMI approach can\nachieve up to 99.33\\% detection accuracy, at least 10% higher than the\ncompeting methods, while substantially reducing computational costs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08234v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08648", "title": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images", "authors": ["Haoran Sun", "Haoyu Bian", "Shaoning Zeng", "Yunbo Rao", "Xu Xu", "Lin Mei", "Jianping Gou"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08648v1", "summary": "Common knowledge indicates that the process of constructing image datasets\nusually depends on the time-intensive and inefficient method of manual\ncollection and annotation. Large models offer a solution via data generation.\nNonetheless, real-world data are obviously more valuable comparing to\nartificially intelligence generated data, particularly in constructing image\ndatasets. For this reason, we propose a novel method for auto-constructing\ndatasets from real-world images by a multiagent collaborative system, named as\nDatasetAgent. By coordinating four different agents equipped with Multi-modal\nLarge Language Models (MLLMs), as well as a tool package for image\noptimization, DatasetAgent is able to construct high-quality image datasets\naccording to user-specified requirements. In particular, two types of\nexperiments are conducted, including expanding existing datasets and creating\nnew ones from scratch, on a variety of open-source datasets. In both cases,\nmultiple image datasets constructed by DatasetAgent are used to train various\nvision models for image classification, object detection, and image\nsegmentation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08648v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08697", "title": "Domain-Informed Operation Excellence of Gas Turbine System with Machine Learning", "authors": ["Waqar Muhammad Ashraf", "Amir H. Keshavarzzadeh", "Abdulelah S. Alshehri", "Abdulrahman bin Jumah", "Ramit Debnath", "Vivek Dua"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08697v1", "summary": "The domain-consistent adoption of artificial intelligence (AI) remains low in\nthermal power plants due to the black-box nature of AI algorithms and low\nrepresentation of domain knowledge in conventional data-centric analytics. In\nthis paper, we develop a MAhalanobis Distance-based OPTimization (MAD-OPT)\nframework that incorporates the Mahalanobis distance-based constraint to\nintroduce domain knowledge into data-centric analytics. The developed MAD-OPT\nframework is applied to maximize thermal efficiency and minimize turbine heat\nrate for a 395 MW capacity gas turbine system. We demonstrate that the MAD-OPT\nframework can estimate domain-informed optimal process conditions under\ndifferent ambient conditions, and the optimal solutions are found to be robust\nas evaluated by Monte Carlo simulations. We also apply the MAD-OPT framework to\nestimate optimal process conditions beyond the design power generation limit of\nthe gas turbine system, and have found comparable results with the actual data\nof the power plant. We demonstrate that implementing data-centric optimization\nanalytics without incorporating domain-informed constraints may provide\nineffective solutions that may not be implementable in the real operation of\nthe gas turbine system. This research advances the integration of the\ndata-driven domain knowledge into machine learning-powered analytics that\nenhances the domain-informed operation excellence and paves the way for safe AI\nadoption in thermal power systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08697v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08644", "title": "OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception", "authors": ["Junho Koh", "Youngwoo Lee", "Jungho Kim", "Dongyoung Lee", "Jun Won Choi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to Transactions on Intelligent Transportation Systems", "url": "http://arxiv.org/abs/2507.08644v1", "summary": "Multi-view camera-based 3D perception can be conducted using bird's eye view\n(BEV) features obtained through perspective view-to-BEV transformations.\nSeveral studies have shown that the performance of these 3D perception methods\ncan be further enhanced by combining sequential BEV features obtained from\nmultiple camera frames. However, even after compensating for the ego-motion of\nan autonomous agent, the performance gain from temporal aggregation is limited\nwhen combining a large number of image frames. This limitation arises due to\ndynamic changes in BEV features over time caused by object motion. In this\npaper, we introduce a novel temporal 3D perception method called OnlineBEV,\nwhich combines BEV features over time using a recurrent structure. This\nstructure increases the effective number of combined features with minimal\nmemory usage. However, it is critical to spatially align the features over time\nto maintain strong performance. OnlineBEV employs the Motion-guided BEV Fusion\nNetwork (MBFNet) to achieve temporal feature alignment. MBFNet extracts motion\nfeatures from consecutive BEV frames and dynamically aligns historical BEV\nfeatures with current ones using these motion features. To enforce temporal\nfeature alignment explicitly, we use Temporal Consistency Learning Loss, which\ncaptures discrepancies between historical and target BEV features. Experiments\nconducted on the nuScenes benchmark demonstrate that OnlineBEV achieves\nsignificant performance gains over the current best method, SOLOFusion.\nOnlineBEV achieves 63.9% NDS on the nuScenes test set, recording\nstate-of-the-art performance in the camera-only 3D object detection task.", "comment": "Accepted to Transactions on Intelligent Transportation Systems", "pdf_url": "http://arxiv.org/pdf/2507.08644v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08259", "title": "Neural Parameter-varying Data-enabled Predictive Control of Cold Atmospheric Pressure Plasma Jets", "authors": ["Pegah GhafGhanbari", "Mircea Lazar", "Javad Mohammadpour Velni"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08259v1", "summary": "Cold Atmospheric Pressure Plasma Jets (APPJs) show significant potential for\nbiomedical applications, but their inherent complexity, characterized by\nnonlinear dynamics and strong sensitivity to operating conditions like\ntip-to-surface distance, presents considerable challenges for achieving robust\nand reliable real-time control. To address these issues, this paper presents\nthe Neural Parameter-Varying Data-enabled Predictive Control (NPV-DeePC)\nframework. By integrating hyper neural networks (hypernets) into the neural\nData-enabled Predictive Control (DeePC) paradigm, the proposed method\nadaptively captures system nonlinearities and parameter variations, updates the\nneural feature space accordingly, and enables efficient and accurate trajectory\nprediction and control. The NPV-DeePC framework is validated through extensive\nsimulations involving surface temperature tracking and thermal dose delivery.\nThe results highlight its ability to outperform existing controllers in terms\nof accuracy and adaptability. The computational efficiency of the NPV-DeePC\napproach makes it a viable candidate for real-time applications. These findings\nunderscore its potential to advance the safe and precise control of APPJs and\nprovide a scalable solution for other parameter-varying nonlinear systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08259v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08665", "title": "KELPS: A Framework for Verified Multi-Language Autoformalization via Semantic-Syntactic Alignment", "authors": ["Jiyao Zhang", "Chengli Zhong", "Hui Xu", "Qige Li", "Yi Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by the ICML 2025 AI4MATH Workshop. 22 pages, 16 figures, 2 tables", "url": "http://arxiv.org/abs/2507.08665v1", "summary": "Modern large language models (LLMs) show promising progress in formalizing\ninformal mathematics into machine-verifiable theorems. However, these methods\nstill face bottlenecks due to the limited quantity and quality of multilingual\nparallel corpora. In this paper, we propose a novel neuro-symbolic framework\nKELPS (Knowledge-Equation based Logical Processing System) to address these\nproblems. KELPS is an iterative framework for translating, synthesizing, and\nfiltering informal data into multiple formal languages (Lean, Coq, and\nIsabelle). First, we translate natural language into Knowledge Equations (KEs),\na novel language that we designed, theoretically grounded in assertional logic.\nNext, we convert them to target languages through rigorously defined rules that\npreserve both syntactic structure and semantic meaning. This process yielded a\nparallel corpus of over 60,000 problems. Our framework achieves 88.9% syntactic\naccuracy (pass@1) on MiniF2F, outperforming SOTA models such as Deepseek-V3\n(81%) and Herald (81.3%) across multiple datasets. All datasets and codes are\navailable in the supplementary materials.", "comment": "Accepted by the ICML 2025 AI4MATH Workshop. 22 pages, 16 figures, 2\n  tables", "pdf_url": "http://arxiv.org/pdf/2507.08665v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08718", "title": "On the Effect of Regularization in Policy Mirror Descent", "authors": ["Jan Felix Kleuker", "Aske Plaat", "Thomas Moerland"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at RLC", "url": "http://arxiv.org/abs/2507.08718v1", "summary": "Policy Mirror Descent (PMD) has emerged as a unifying framework in\nreinforcement learning (RL) by linking policy gradient methods with a\nfirst-order optimization method known as mirror descent. At its core, PMD\nincorporates two key regularization components: (i) a distance term that\nenforces a trust region for stable policy updates and (ii) an MDP regularizer\nthat augments the reward function to promote structure and robustness. While\nPMD has been extensively studied in theory, empirical investigations remain\nscarce. This work provides a large-scale empirical analysis of the interplay\nbetween these two regularization techniques, running over 500k training seeds\non small RL environments. Our results demonstrate that, although the two\nregularizers can partially substitute each other, their precise combination is\ncritical for achieving robust performance. These findings highlight the\npotential for advancing research on more robust algorithms in RL, particularly\nwith respect to hyperparameter sensitivity.", "comment": "Accepted at RLC", "pdf_url": "http://arxiv.org/pdf/2507.08718v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08655", "title": "Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model", "authors": ["Zach Eidex", "Mojtaba Safari", "Tonghe Wang", "Vanessa Wildman", "David S. Yu", "Hui Mao", "Erik Middlebrooks", "Aparna Kesewala", "Xiaofeng Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08655v1", "summary": "Purpose: Ultra-high-field 7T MRI offers improved resolution and contrast over\nstandard clinical field strengths (1.5T, 3T). However, 7T scanners are costly,\nscarce, and introduce additional challenges such as susceptibility artifacts.\nWe propose an efficient transformer-based model (7T-Restormer) to synthesize\n7T-quality T1-maps from routine 1.5T or 3T T1-weighted (T1W) images. Methods:\nOur model was validated on 35 1.5T and 108 3T T1w MRI paired with corresponding\n7T T1 maps of patients with confirmed MS. A total of 141 patient cases (32,128\nslices) were randomly divided into 105 (25; 80) training cases (19,204 slices),\n19 (5; 14) validation cases (3,476 slices), and 17 (5; 14) test cases (3,145\nslices) where (X; Y) denotes the patients with 1.5T and 3T T1W scans,\nrespectively. The synthetic 7T T1 maps were compared against the ResViT and\nResShift models. Results: The 7T-Restormer model achieved a PSNR of 26.0 +/-\n4.6 dB, SSIM of 0.861 +/- 0.072, and NMSE of 0.019 +/- 0.011 for 1.5T inputs,\nand 25.9 +/- 4.9 dB, and 0.866 +/- 0.077 for 3T inputs, respectively. Using\n10.5 M parameters, our model reduced NMSE by 64 % relative to 56.7M parameter\nResShift (0.019 vs 0.052, p = <.001 and by 41 % relative to 70.4M parameter\nResViT (0.019 vs 0.032, p = <.001) at 1.5T, with similar advantages at 3T\n(0.021 vs 0.060 and 0.033; p < .001). Training with a mixed 1.5 T + 3 T corpus\nwas superior to single-field strategies. Restricting the model to 1.5T\nincreased the 1.5T NMSE from 0.019 to 0.021 (p = 1.1E-3) while training solely\non 3T resulted in lower performance on input 1.5T T1W MRI. Conclusion: We\npropose a novel method for predicting quantitative 7T MP2RAGE maps from 1.5T\nand 3T T1W scans with higher quality than existing state-of-the-art methods.\nOur approach makes the benefits of 7T MRI more accessible to standard clinical\nworkflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08655v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08299", "title": "Two-Level Distributed Interference Management for Large-Scale HAPS-Empowered vHetNets", "authors": ["Afsoon Alidadi Shamsabadi", "Animesh Yadav", "Halim Yanikomeroglu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08299v1", "summary": "Next-generation wireless networks (xG) must provide ubiquitous connectivity\nwhile enhancing user experience in both densely populated urban areas and rural\nregions. To achieve this, a disruptive network architecture is essential, and\nhigh altitude platform stations (HAPS) offer a promising solution. By\nintegrating HAPS with terrestrial networks, we can create HAPS-empowered\nvertical heterogeneous networks (vHetNets), which significantly improve\ncoverage and capacity, as well as support emerging use cases. In HAPS-empowered\nvHetNets, different tiers can share the same spectrum, forming harmonized\nspectrum vHetNets that enhance spectral efficiency (SE). However, we face two\nmajor challenges: i) co-channel interference in harmonized spectrum vHetNets,\nand ii) the large-scale nature of the network. To address the first challenge,\nwe adopt a cell-free approach as the underlying network architecture for the\nHAPS-empowered vHetNet. In this approach, base stations use beamforming to\ndirect high-gain, narrow beams toward users, which helps mitigate interference.\nHowever, this creates a nonconvex and high-dimensional optimization problem,\nwhich highlights the second challenge of dealing with a large-scale network.\nConsequently, centralized solutions become impractical due to the computational\nand communication overhead involved. The standard two-block alternating\ndirection method of multipliers (ADMM) is one option, but nonconvex constraints\ncan hinder its convergence. As an alternative, we have developed a two-level\ndistributed proportional fairness beamforming weight design (PFBWD) algorithm.\nThis algorithm uses a combination of the augmented Lagrangian method (ALM) and\na three-block ADMM framework. The proposed method effectively tackles\nnonconvexity, reduces complexity, and enables scalable, distributed\noptimization with guaranteed convergence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08299v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08145", "title": "AI-Augmented Visible Light Communication: A Framework for Noise Mitigation and Secure Data Transmission", "authors": ["A. A. Nutfaji", "Moustafa Hassan Elmallah"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      currently 4 pages. However, we're planning to work more on the topic", "url": "http://arxiv.org/abs/2507.08145v1", "summary": "This paper presents a proposed AI Deep Learning model that addresses common\nchallenges encountered in Visible Light Communication (VLC) systems. In this\nwork, we run a Python simulation that models a basic VLC system primarily\naffected by Additive White Gaussian Noise (AWGN). A Deep Neural Network (DNN)\nis then trained to equalize the noisy signal received and improve signal\nintegrity. The system evaluates and compares the Bit Error Rate (BER) before\nand after equalization to demonstrate the effectiveness of the proposed model.\nThis paper starts by introducing the concept of visible light communication,\nthen it dives deep into some details about the process of VLC and the\nchallenges it faces, shortly after we propose our project which helps overcome\nthese challenges. We finally conclude with a lead for future work, highlighting\nthe areas that are most suitable for future improvements.", "comment": "currently 4 pages. However, we're planning to work more on the topic", "pdf_url": "http://arxiv.org/pdf/2507.08145v1", "cate": "eess.SP", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08683", "title": "MoSAiC: Multi-Modal Multi-Label Supervision-Aware Contrastive Learning for Remote Sensing", "authors": ["Debashis Gupta", "Aditi Golder", "Rongkhun Zhu", "Kangning Cui", "Wei Tang", "Fan Yang", "Ovidiu Csillik", "Sarra Alaqahtani", "V. Paul Pauca"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08683v1", "summary": "Contrastive learning (CL) has emerged as a powerful paradigm for learning\ntransferable representations without the reliance on large labeled datasets.\nIts ability to capture intrinsic similarities and differences among data\nsamples has led to state-of-the-art results in computer vision tasks. These\nstrengths make CL particularly well-suited for Earth System Observation (ESO),\nwhere diverse satellite modalities such as optical and SAR imagery offer\nnaturally aligned views of the same geospatial regions. However, ESO presents\nunique challenges, including high inter-class similarity, scene clutter, and\nambiguous boundaries, which complicate representation learning -- especially in\nlow-label, multi-label settings. Existing CL frameworks often focus on\nintra-modality self-supervision or lack mechanisms for multi-label alignment\nand semantic precision across modalities. In this work, we introduce MoSAiC, a\nunified framework that jointly optimizes intra- and inter-modality contrastive\nlearning with a multi-label supervised contrastive loss. Designed specifically\nfor multi-modal satellite imagery, MoSAiC enables finer semantic\ndisentanglement and more robust representation learning across spectrally\nsimilar and spatially complex classes. Experiments on two benchmark datasets,\nBigEarthNet V2.0 and Sent12MS, show that MoSAiC consistently outperforms both\nfully supervised and self-supervised baselines in terms of accuracy, cluster\ncoherence, and generalization in low-label and high-class-overlap scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08683v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08721", "title": "Monitoring Risks in Test-Time Adaptation", "authors": ["Mona Schirmer", "Metod Jazbec", "Christian A. Naesseth", "Eric Nalisnick"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08721v1", "summary": "Encountering shifted data at test time is a ubiquitous challenge when\ndeploying predictive models. Test-time adaptation (TTA) methods address this\nissue by continuously adapting a deployed model using only unlabeled test data.\nWhile TTA can extend the model's lifespan, it is only a temporary solution.\nEventually the model might degrade to the point that it must be taken offline\nand retrained. To detect such points of ultimate failure, we propose pairing\nTTA with risk monitoring frameworks that track predictive performance and raise\nalerts when predefined performance criteria are violated. Specifically, we\nextend existing monitoring tools based on sequential testing with confidence\nsequences to accommodate scenarios in which the model is updated at test time\nand no test labels are available to estimate the performance metrics of\ninterest. Our extensions unlock the application of rigorous statistical risk\nmonitoring to TTA, and we demonstrate the effectiveness of our proposed TTA\nmonitoring framework across a representative set of datasets, distribution\nshift types, and TTA methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08721v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08679", "title": "ByDeWay: Boost Your multimodal LLM with DEpth prompting in a Training-Free Way", "authors": ["Rajarshi Roy", "Devleena Das", "Ankesh Banerjee", "Arjya Bhattacharjee", "Kousik Dasgupta", "Subarna Tripathi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08679v1", "summary": "We introduce ByDeWay, a training-free framework designed to enhance the\nperformance of Multimodal Large Language Models (MLLMs). ByDeWay uses a novel\nprompting strategy called Layered-Depth-Based Prompting (LDP), which improves\nspatial reasoning and grounding without modifying any model parameters. It\nsegments the scene into closest, mid-range, and farthest layers using monocular\ndepth estimation, then generates region-specific captions with a grounded\nvision-language model. These structured, depth-aware captions are appended to\nthe image-question prompt, enriching it with spatial context. This guides MLLMs\nto produce more grounded and less hallucinated responses. Our method is\nlightweight, modular, and compatible with black-box MLLMs. Experiments on\nhallucination-sensitive (POPE) and reasoning-intensive (GQA) benchmarks show\nconsistent improvements across multiple MLLMs, validating the effectiveness of\ndepth-aware prompting in a zero-training setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08679v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08383", "title": "A Generalized Stability Analysis Method with Dynamic Phasors for LV AC Microgrids", "authors": ["Bülent Dağ"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures, not published anywhere", "url": "http://arxiv.org/abs/2507.08383v1", "summary": "Representation of inductive coupling lines with conventional static phasors\nis the main reason of inadequacy of the existing phasors based simplified\nstability analysis methods for microgrids with inductive coupling lines. In the\nliterature, dynamic phasors have been proposed for the dynamic modelling of\ninductive lines to conserve the simplified structure of the analysis method. In\nthis study a generalized stability analysis method for LV AC microgrids,\ncomposed of droop controlled inverters, is presented. The proposed analysis\nmethod is based on the inclusion of dynamic phasors for inductive coupling\nlines into the existing phasors based stability analysis method. The results\nshow that the stability analysis method with dynamic phasors successfully\npredicts the instability boundaries of LV AC microgrids.", "comment": "8 pages, 6 figures, not published anywhere", "pdf_url": "http://arxiv.org/pdf/2507.08383v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08293", "title": "Ambiguity Function Analysis of AFDM Signals for Integrated Sensing and Communications", "authors": ["Haoran Yin", "Yanqun Tang", "Yuanhan Ni", "Zulin Wang", "Gaojie Chen", "Jun Xiong", "Kai Yang", "Marios Kountouris", "Yong Liang Guan", "Yong Zeng"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      14 pages, 14 figures. Under revision in an IEEE Journal", "url": "http://arxiv.org/abs/2507.08293v1", "summary": "Affine frequency division multiplexing (AFDM) is a promising chirp-based\nwaveform with high flexibility and resilience, making it well-suited for\nnext-generation wireless networks, particularly in high-mobility scenarios. In\nthis paper, we investigate the ambiguity functions (AFs) of AFDM signals, which\nfundamentally characterize their range and velocity estimation capabilities in\nboth monostatic and bistatic settings. Specifically, we first derive the\nauto-ambiguity function (AAF) of an AFDM chirp subcarrier, revealing its\n\"spike-like\" local property and \"periodic-like\" global property along the\nrotated delay and Doppler dimensions. This structure naturally forms a\nparallelogram for each localized pulse of the AAF of the AFDM chirp subcarrier,\nenabling unambiguous target sensing. Then, we study the cross-ambiguity\nfunction (CAF) between two different AFDM chirp subcarriers, which exhibits the\nsame local and global properties as the AAF but with an additional shift along\nthe Doppler dimension. We then extend our analysis to the AF of various typical\nAFDM frames, considering both deterministic pilot and random data symbols. In\nparticular, we demonstrate that inserting guard symbols in AFDM facilitates\ninterference-free sensing. Simulation results validate our theoretical\nfindings, highlighting AFDM's strong potential for ISAC applications.", "comment": "14 pages, 14 figures. Under revision in an IEEE Journal", "pdf_url": "http://arxiv.org/pdf/2507.08293v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08704", "title": "KG-Attention: Knowledge Graph-Guided Attention at Test-Time via Bidirectional Information Aggregation", "authors": ["Songlin Zhai", "Guilin Qi", "Yuan Meng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08704v1", "summary": "Knowledge graphs (KGs) play a critical role in enhancing large language\nmodels (LLMs) by introducing structured and grounded knowledge into the\nlearning process. However, most existing KG-enhanced approaches rely on\nparameter-intensive fine-tuning, which risks catastrophic forgetting and\ndegrades the pretrained model's generalization. Moreover, they exhibit limited\nadaptability to real-time knowledge updates due to their static integration\nframeworks. To address these issues, we introduce the first test-time\nKG-augmented framework for LLMs, built around a dedicated knowledge\ngraph-guided attention (KGA) module that enables dynamic knowledge fusion\nwithout any parameter updates. The proposed KGA module augments the standard\nself-attention mechanism with two synergistic pathways: outward and inward\naggregation. Specifically, the outward pathway dynamically integrates external\nknowledge into input representations via input-driven KG fusion. This inward\naggregation complements the outward pathway by refining input representations\nthrough KG-guided filtering, suppressing task-irrelevant signals and amplifying\nknowledge-relevant patterns. Importantly, while the outward pathway handles\nknowledge fusion, the inward path selects the most relevant triples and feeds\nthem back into the fusion process, forming a closed-loop enhancement mechanism.\nBy synergistically combining these two pathways, the proposed method supports\nreal-time knowledge fusion exclusively at test-time, without any parameter\nmodification. Extensive experiments on five benchmarks verify the comparable\nknowledge fusion performance of KGA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08704v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08736", "title": "Catastrophic Forgetting Mitigation Through Plateau Phase Activity Profiling", "authors": ["Idan Mashiach", "Oren Glickman", "Tom Tirer"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08736v1", "summary": "Catastrophic forgetting in deep neural networks occurs when learning new\ntasks degrades performance on previously learned tasks due to knowledge\noverwriting. Among the approaches to mitigate this issue, regularization\ntechniques aim to identify and constrain \"important\" parameters to preserve\nprevious knowledge. In the highly nonconvex optimization landscape of deep\nlearning, we propose a novel perspective: tracking parameters during the final\ntraining plateau is more effective than monitoring them throughout the entire\ntraining process. We argue that parameters that exhibit higher activity\n(movement and variability) during this plateau reveal directions in the loss\nlandscape that are relatively flat, making them suitable for adaptation to new\ntasks while preserving knowledge from previous ones. Our comprehensive\nexperiments demonstrate that this approach achieves superior performance in\nbalancing catastrophic forgetting mitigation with strong performance on newly\nlearned tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08736v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08690", "title": "An Efficient Approach for Muscle Segmentation and 3D Reconstruction Using Keypoint Tracking in MRI Scan", "authors": ["Mengyuan Liu", "Jeongkyu Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08690v1", "summary": "Magnetic resonance imaging (MRI) enables non-invasive, high-resolution\nanalysis of muscle structures. However, automated segmentation remains limited\nby high computational costs, reliance on large training datasets, and reduced\naccuracy in segmenting smaller muscles. Convolutional neural network\n(CNN)-based methods, while powerful, often suffer from substantial\ncomputational overhead, limited generalizability, and poor interpretability\nacross diverse populations. This study proposes a training-free segmentation\napproach based on keypoint tracking, which integrates keypoint selection with\nLucas-Kanade optical flow. The proposed method achieves a mean Dice similarity\ncoefficient (DSC) ranging from 0.6 to 0.7, depending on the keypoint selection\nstrategy, performing comparably to state-of-the-art CNN-based models while\nsubstantially reducing computational demands and enhancing interpretability.\nThis scalable framework presents a robust and explainable alternative for\nmuscle segmentation in clinical and research applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08690v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08393", "title": "PGD-based optimization of 3D bobsleigh track centerlines from 2D centerlines for simulation applications", "authors": ["Zhe Chen", "Huichao Zhao", "Yongfeng Jiang", "Minghui Bai", "Lun Li", "Jicheng Chen"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08393v1", "summary": "The centerline of a bobsleigh track defines its geometry and is essential for\nsimulation modeling. To reduce bBobsleigh training costs, leveraging the\ncenterline of the bobsleigh track to construct a virtual environment that\nclosely replicates real competitive settings presents a promising solution.\nHowever, publicly available centerline data are typically limited and it is\nimprecise to construct a training system solely based on 2-dimensional (2D)\ncenterline. To address this practical issue, this paper proposes a method for\ngenerating a 3-dimensional (3D) track centerline based on 2D centerline data.\nIncorporating international track design regulations, the method formulates an\noptimization problem that considers total track length, height difference,\nslope constraints, and geometric continuity. A Projected Gradient Descent (PGD)\nalgorithm is used to solve the optimization problem. The generated 3D\ncenterlines are compared with real track data, and the results show that the\nmethod can reproduce realistic centerline trends from original or scaled 2D\ndata. For the selected track segment, the relative errors in total length,\nheight difference, and average slope are within 1.7%, 3.2% and 4.1%,\nrespectively, for real 2D data and within 1.1%, 3.5% and 4.3% respectively for\nscaled data. All slope values remain within the allowable limits. Moreover, by\nadjusting the segmentation or modifying the weight of height difference in the\ncost function, various centerline styles applicable to different competitions\ncan be generated. Under different segmentation and weight factors, the maximum\nerrors reach up to 4.4%, 4.8%, and 9.8%, and 4.4%, 4.8%, and 10.0%,\nrespectively. The proposed method provides a flexible and efficient tool for\nsupporting bobsleigh track centerline design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08393v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08399", "title": "Unobtrusive Reflectance Photoplethysmography for Detecting and Severity Grading of Sleep Apnea via Oxygen Desaturation Index", "authors": ["Karen Adam", "Clémentine Aguet", "Patrick Theurillat", "Florent Baty", "Maximilian Boesch", "Damien Ferrario", "Mathieu Lemay", "Martin Brutsche", "Fabian Braun"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted to BMT2025", "url": "http://arxiv.org/abs/2507.08399v1", "summary": "Sleep apnea is a common chronic sleep-related disorder which is known to be a\ncomorbidity for cerebro- and cardio-vascular disease. Diagnosis of sleep apnea\nusually requires an overnight polysomnography at the sleep laboratory. In this\npaper, we used a wearable device which measures reflectance\nphotoplethysmography (PPG) at the wrist and upper arm to estimate continuous\nSpO2 levels during sleep and subsequently derive an oxygen desaturation index\n(ODI) for each patient. On a cohort of 170 patients undergoing sleep apnea\nscreening, we evaluated whether this ODI value could represent a surrogate\nmarker for the apnea-hypopnea index (AHI) for the diagnosis and severity\nassessment of sleep apnea. As the ODI was simultaneously obtained at the\nfingertip, upper arm and wrist, we compared ODI diagnostic performance\ndepending on the measurement location. We then further evaluated the accuracy\nof ODI as a direct predictor for moderate and severe sleep apnea as defined by\nestablished AHI thresholds. We found that ODI values obtained at the upper arm\nwere good predictors for moderate or severe sleep apnea, with 86% accuracy, 96%\nsensitivity and 70% specificity, whereas ODI values obtained at the wrist were\nless reliable as a diagnostic tool.", "comment": "Accepted to BMT2025", "pdf_url": "http://arxiv.org/pdf/2507.08399v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08738", "title": "Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy Chaotic Time Series", "authors": ["Azimov Sherkhon", "Susana Lopez-Moreno", "Eric Dolores-Cuenca", "Sieun Lee", "Sangil Kim"], "categories": ["cs.LG", "cs.AI", "math.DS", "68T07, 37M10, 00A79, 37M22, 65P20"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2507.08738v1", "summary": "Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have\nshown promise in forecasting chaotic dynamical systems, such as the Lorenz-63\nmodel and El Nino-Southern Oscillation. However, their reliance on fixed\nnonlinearities - polynomial expansions in NVAR or random feature maps in RC -\nlimits their adaptability to high noise or real-world data. These methods also\nscale poorly in high-dimensional settings due to costly matrix inversion during\nreadout computation. We propose an adaptive NVAR model that combines\ndelay-embedded linear inputs with features generated by a shallow, learnable\nmulti-layer perceptron (MLP). The MLP and linear readout are jointly trained\nusing gradient-based optimization, enabling the model to learn data-driven\nnonlinearities while preserving a simple readout structure. Unlike standard\nNVAR, our approach avoids the need for an exhaustive and sensitive grid search\nover ridge and delay parameters. Instead, tuning is restricted to neural\nnetwork hyperparameters, improving scalability. Initial experiments on chaotic\nsystems tested under noise-free and synthetically noisy conditions showed that\nthe adaptive model outperformed the standard NVAR in predictive accuracy and\nshowed robust forecasting under noisy conditions with a lower observation\nfrequency.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.08738v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08746", "title": "Partitioned Hybrid Quantum Fourier Neural Operators for Scientific Quantum Machine Learning", "authors": ["Paolo Marcandelli", "Yuanchun He", "Stefano Mariani", "Martina Siena", "Stefano Markidis"], "categories": ["cs.LG", "quant-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08746v1", "summary": "We introduce the Partitioned Hybrid Quantum Fourier Neural Operator (PHQFNO),\na generalization of the Quantum Fourier Neural Operator (QFNO) for scientific\nmachine learning. PHQFNO partitions the Fourier operator computation across\nclassical and quantum resources, enabling tunable quantum-classical\nhybridization and distributed execution across quantum and classical devices.\nThe method extends QFNOs to higher dimensions and incorporates a\nmessage-passing framework to distribute data across different partitions. Input\ndata are encoded into quantum states using unary encoding, and quantum circuit\nparameters are optimized using a variational scheme. We implement PHQFNO using\nPennyLane with PyTorch integration and evaluate it on Burgers' equation,\nincompressible and compressible Navier-Stokes equations. We show that PHQFNO\nrecovers classical FNO accuracy. On incompressible Navier-Stokes, PHQFNO\nachieves higher accuracy than its classical counterparts. Finally, we perform a\nsensitivity analysis under input noise, confirming improved stability of PHQFNO\nover classical baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08746v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08710", "title": "L-CLIPScore: a Lightweight Embedding-based Captioning Metric for Evaluating and Training", "authors": ["Li Li", "Yingzhe Peng", "Xu Yang", "Ruoxi Cheng", "Haiyang Xu", "Ming Yan", "Fei Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08710v1", "summary": "We propose a novel embedding-based captioning metric termed as L-CLIPScore\nthat can be used for efficiently evaluating caption quality and training\ncaptioning model. L-CLIPScore is calculated from a lightweight CLIP (L-CLIP),\nwhich is a dual-encoder architecture compressed and distilled from CLIP. To\ncompress, we apply two powerful techniques which are weight multiplexing and\nmatrix decomposition for reducing the parameters of encoders and word embedding\nmatrix, respectively. To distill, we design a novel multi-modal Similarity\nRegulator (SR) loss to transfer more vision-language alignment knowledge.\nSpecifically, SR loss amplifies the multi-modal embedding similarity if the\ngiven image-text pair is matched and diminishes the similarity if the pair is\nnon-matched. By compressing and distilling by this novel SR loss, our L-CLIP\nachieves comparable multi-modal alignment ability to the original CLIP while it\nrequires fewer computation resources and running time. We carry out exhaustive\nexperiments to validate the efficiency and effectiveness of L-CLIPScore when\nusing it as the judge to evaluate caption quality. We also discover that when\nusing L-CLIPScore as the supervisor to train the captioning model, it should be\nmixed up by an n-gram-based metric and meanwhile analyze why using L-CLIPScore\nonly will cause fail training.", "comment": "10 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08710v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08684", "title": "Large-Scale Processing and Validation of Grid Data for Assessing the Fair Spatial Distribution of PV Hosting Capacity", "authors": ["Ali Mohamed Ali", "Yaser Raeisi", "Plouton Grammatikos", "Davide Pavanello", "Pierre Roduit", "Fabrizio Sossan"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08684v1", "summary": "The integration of PV systems and increased electrification levels present\nsignificant challenges to the traditional design and operation of distribution\ngrids. This paper presents a methodology for extracting, validating, and\nadapting grid data from a distribution system operator's (DSO) database to\nfacilitate large-scale grid studies, including load flow and optimal power flow\nanalyses. The validation process combines rule-based sanity checks and offline\nautomated power flow analyses to ensure data consistency and detect potential\nerrors in the grid database, allowing for their correction. As a practical\napplication, the paper proposes a method to assess the PV hosting capacity of\ndistribution grids, with a focus on ensuring fairness in their spatial\ndistribution. By incorporating fairness criteria into the analyses, we quantify\nthe costs (in terms of missed revenues from selling PV generation) associated\nwith spatial fairness.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08684v1", "cate": "eess.SY", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08423", "title": "Exploiting Cognition in ISAR Processing for Spectral Compatibility Applications", "authors": ["Massimo Rosamilia", "Augusto Aubry", "Alessio Balleri", "Antonio De Maio", "Marco Martorella"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      submitted to IEEE Transactions on Radar Systems", "url": "http://arxiv.org/abs/2507.08423v1", "summary": "This paper introduces and analyzes the concept of a cognitive inverse\nsynthetic aperture radar (ISAR) ensuring spectral compatibility in crowded\nelectromagnetic environments. In such a context, the proposed approach\nalternates between environmental perception, recognizing possible emitters in\nits frequency range, and an action stage, synthesizing and transmitting a\ntailored radar waveform to achieve the desired imaging task while guaranteeing\nspectral coexistence with overlaid emitters. The perception is carried out by a\nspectrum sensing module providing the true relevant spectral parameters of the\nsources in the environment. The action stage employs a tailored signal design\nprocess, synthesizing a radar waveform with bespoke spectral notches, enabling\nISAR imaging over a wide spectral bandwidth without interfering with the other\nradio frequency (RF) sources. A key enabling requirement for the proposed\napplication is the capability to successfully recover possible missing data in\nthe frequency domain (induced by spectral notches) and in the slow-time\ndimension (enabling concurrent RF activities still in a cognitive fashion).\nThis process is carried out by resorting to advanced methods based on either\nthe compressed-sensing framework or a rank-minimization recovery strategy. The\ncapabilities of the proposed system are assessed exploiting a dataset of drone\nmeasurements in the frequency band between 13 GHz and 15 GHz. Results highlight\nthe effectiveness of the devised architecture to enable spectral compatibility\nwhile delivering high-quality ISAR images as well as additional RF activities.", "comment": "submitted to IEEE Transactions on Radar Systems", "pdf_url": "http://arxiv.org/pdf/2507.08423v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08743", "title": "Geo-ORBIT: A Federated Digital Twin Framework for Scene-Adaptive Lane Geometry Detection", "authors": ["Rei Tamaru", "Pei Li", "Bin Ran"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08743v1", "summary": "Digital Twins (DT) have the potential to transform traffic management and\noperations by creating dynamic, virtual representations of transportation\nsystems that sense conditions, analyze operations, and support decision-making.\nA key component for DT of the transportation system is dynamic roadway geometry\nsensing. However, existing approaches often rely on static maps or costly\nsensors, limiting scalability and adaptability. Additionally, large-scale DTs\nthat collect and analyze data from multiple sources face challenges in privacy,\ncommunication, and computational efficiency. To address these challenges, we\nintroduce Geo-ORBIT (Geometrical Operational Roadway Blueprint with Integrated\nTwin), a unified framework that combines real-time lane detection, DT\nsynchronization, and federated meta-learning. At the core of Geo-ORBIT is\nGeoLane, a lightweight lane detection model that learns lane geometries from\nvehicle trajectory data using roadside cameras. We extend this model through\nMeta-GeoLane, which learns to personalize detection parameters for local\nentities, and FedMeta-GeoLane, a federated learning strategy that ensures\nscalable and privacy-preserving adaptation across roadside deployments. Our\nsystem is integrated with CARLA and SUMO to create a high-fidelity DT that\nrenders highway scenarios and captures traffic flows in real-time. Extensive\nexperiments across diverse urban scenes show that FedMeta-GeoLane consistently\noutperforms baseline and meta-learning approaches, achieving lower geometric\nerror and stronger generalization to unseen locations while drastically\nreducing communication overhead. This work lays the foundation for flexible,\ncontext-aware infrastructure modeling in DTs. The framework is publicly\navailable at https://github.com/raynbowy23/FedMeta-GeoLane.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08743v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08749", "title": "Modeling Partially Observed Nonlinear Dynamical Systems and Efficient Data Assimilation via Discrete-Time Conditional Gaussian Koopman Network", "authors": ["Chuanqi Chen", "Zhongrui Wang", "Nan Chen", "Jin-Long Wu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08749v1", "summary": "A discrete-time conditional Gaussian Koopman network (CGKN) is developed in\nthis work to learn surrogate models that can perform efficient state forecast\nand data assimilation (DA) for high-dimensional complex dynamical systems,\ne.g., systems governed by nonlinear partial differential equations (PDEs).\nFocusing on nonlinear partially observed systems that are common in many\nengineering and earth science applications, this work exploits Koopman\nembedding to discover a proper latent representation of the unobserved system\nstates, such that the dynamics of the latent states are conditional linear,\ni.e., linear with the given observed system states. The modeled system of the\nobserved and latent states then becomes a conditional Gaussian system, for\nwhich the posterior distribution of the latent states is Gaussian and can be\nefficiently evaluated via analytical formulae. The analytical formulae of DA\nfacilitate the incorporation of DA performance into the learning process of the\nmodeled system, which leads to a framework that unifies scientific machine\nlearning (SciML) and data assimilation. The performance of discrete-time CGKN\nis demonstrated on several canonical problems governed by nonlinear PDEs with\nintermittency and turbulent features, including the viscous Burgers' equation,\nthe Kuramoto-Sivashinsky equation, and the 2-D Navier-Stokes equations, with\nwhich we show that the discrete-time CGKN framework achieves comparable\nperformance as the state-of-the-art SciML methods in state forecast and\nprovides efficient and accurate DA results. The discrete-time CGKN framework\nalso serves as an example to illustrate unifying the development of SciML\nmodels and their other outer-loop applications such as design optimization,\ninverse problems, and optimal control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08749v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08711", "title": "SGPMIL: Sparse Gaussian Process Multiple Instance Learning", "authors": ["Andreas Lolos", "Stergios Christodoulidis", "Maria Vakalopoulou", "Jose Dolz", "Aris Moustakas"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 4 figures, 2 tables", "url": "http://arxiv.org/abs/2507.08711v1", "summary": "Multiple Instance Learning (MIL) offers a natural solution for settings where\nonly coarse, bag-level labels are available, without having access to\ninstance-level annotations. This is usually the case in digital pathology,\nwhich consists of gigapixel sized images. While deterministic attention-based\nMIL approaches achieve strong bag-level performance, they often overlook the\nuncertainty inherent in instance relevance. In this paper, we address the lack\nof uncertainty quantification in instance-level attention scores by introducing\n\\textbf{SGPMIL}, a new probabilistic attention-based MIL framework grounded in\nSparse Gaussian Processes (SGP). By learning a posterior distribution over\nattention scores, SGPMIL enables principled uncertainty estimation, resulting\nin more reliable and calibrated instance relevance maps. Our approach not only\npreserves competitive bag-level performance but also significantly improves the\nquality and interpretability of instance-level predictions under uncertainty.\nSGPMIL extends prior work by introducing feature scaling in the SGP predictive\nmean function, leading to faster training, improved efficiency, and enhanced\ninstance-level performance. Extensive experiments on multiple well-established\ndigital pathology datasets highlight the effectiveness of our approach across\nboth bag- and instance-level evaluations. Our code will be made publicly\navailable.", "comment": "8 pages, 4 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.08711v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08411", "title": "A Dissipativity Framework for Constructing Scaled Graphs", "authors": ["Timo de Groot", "Maurice heemels", "Sebastiaan van den Eijnden"], "categories": ["math.OC", "cs.SY", "eess.SY", "93D25, 93C10"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08411v1", "summary": "Scaled relative graphs have been originally introduced in the context of\nconvex optimization and have recently gained attention in the control systems\ncommunity for the graphical analysis of nonlinear systems. Of particular\ninterest in stability analysis of feedback systems is the scaled graph, a\nspecial case of the scaled relative graph. In many ways, scaled graphs can be\nseen as a generalization of the classical Nyquist plot for linear\ntime-invariant systems, and facilitate a powerful graphical tool for analyzing\nnonlinear feedback systems. In their current formulation, however, scaled\ngraphs require characterizing the input-output behaviour of a system for an\nuncountable number of inputs. This poses a practical bottleneck in obtaining\nthe scaled graph of a nonlinear system, and currently limits its use. This\npaper presents a framework grounded in dissipativity for efficiently computing\nthe scaled graph of several important classes of systems, including\nmultivariable linear time-invariant systems, impulsive systems, and piecewise\nlinear systems. The proposed approach leverages novel connections between\nlinear matrix inequalities, integral quadratic constraints, and scaled graphs,\nand is shown to be exact for specific linear time-invariant systems. The\nresults are accompanied by several examples illustrating the potential and\neffectiveness of the presented framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08411v1", "cate": "math.OC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08470", "title": "A Temporal Gaussian Noise Model for Equalization-enhanced Phase Noise", "authors": ["Benedikt Geiger", "Fred Buchali", "Vahid Aref", "Laurent Schmalen"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      Accepted at 51st European Conference on Optical Communication (ECOC), Copenhagen, Denmark", "url": "http://arxiv.org/abs/2507.08470v1", "summary": "Equalization-enhanced Phase Noise causes burst-like distortions in high\nsymbol-rate transmission systems. We propose a temporal Gaussian noise model\nthat captures these distortions by introducing a time-varying distortion power.\nValidated through simulations and experiments, it enables accurate and simple\nperformance prediction for high symbol-rate transmission systems.", "comment": "Accepted at 51st European Conference on Optical Communication (ECOC),\n  Copenhagen, Denmark", "pdf_url": "http://arxiv.org/pdf/2507.08470v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08761", "title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data", "authors": ["Jeonghye Kim", "Yongjae Shin", "Whiyoung Jung", "Sunghoon Hong", "Deunsol Yoon", "Youngchul Sung", "Kanghoon Lee", "Woohyung Lim"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICML2025", "url": "http://arxiv.org/abs/2507.08761v1", "summary": "Reinforcement learning with offline data suffers from Q-value extrapolation\nerrors. To address this issue, we first demonstrate that linear extrapolation\nof the Q-function beyond the data range is particularly problematic. To\nmitigate this, we propose guiding the gradual decrease of Q-values outside the\ndata range, which is achieved through reward scaling with layer normalization\n(RS-LN) and a penalization mechanism for infeasible actions (PA). By combining\nRS-LN and PA, we develop a new algorithm called PARS. We evaluate PARS across a\nrange of tasks, demonstrating superior performance compared to state-of-the-art\nalgorithms in both offline training and online fine-tuning on the D4RL\nbenchmark, with notable success in the challenging AntMaze Ultra task.", "comment": "Accepted to ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.08761v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08751", "title": "ML-Based Automata Simplification for Symbolic Accelerators", "authors": ["Tiffany Yu", "Rye Stahle-Smith", "Darssan Eswaramoorthi", "Rasha Karakchi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08751v1", "summary": "Symbolic accelerators are increasingly used for symbolic data processing in\ndomains such as genomics, NLP, and cybersecurity. However, these accelerators\nface scalability issues due to excessive memory use and routing complexity,\nespecially when targeting a large set. We present AutoSlim, a machine\nlearning-based graph simplification framework designed to reduce the complexity\nof symbolic accelerators built on Non-deterministic Finite Automata (NFA)\ndeployed on FPGA-based overlays such as NAPOLY+. AutoSlim uses Random Forest\nclassification to prune low-impact transitions based on edge scores and\nstructural features, significantly reducing automata graph density while\npreserving semantic correctness. Unlike prior tools, AutoSlim targets automated\nscore-aware simplification with weighted transitions, enabling efficient\nranking-based sequence analysis. We evaluated data sets (1K to 64K nodes) in\nNAPOLY+ and conducted performance measurements including latency, throughput,\nand resource usage. AutoSlim achieves up to 40 percent reduction in FPGA LUTs\nand over 30 percent pruning in transitions, while scaling to graphs an order of\nmagnitude larger than existing benchmarks. Our results also demonstrate how\nhardware interconnection (fanout) heavily influences hardware cost and that\nAutoSlim's pruning mitigates resource blowup.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08751v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08716", "title": "Unreal is all you need: Multimodal ISAC Data Simulation with Only One Engine", "authors": ["Kongwu Huang", "Shiyi Mu", "Jun Jiang", "Yuan Gao", "Shugong Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08716v1", "summary": "Scaling laws have achieved success in LLM and foundation models. To explore\ntheir potential in ISAC research, we propose Great-X. This single-engine\nmultimodal data twin platform reconstructs the ray-tracing computation of\nSionna within Unreal Engine and is deeply integrated with autonomous driving\ntools. This enables efficient and synchronized simulation of multimodal data,\nincluding CSI, RGB, Radar, and LiDAR. Based on this platform, we construct an\nopen-source, large-scale, low-altitude UAV multimodal synaesthesia dataset\nnamed Great-MSD, and propose a baseline CSI-based UAV 3D localization\nalgorithm, demonstrating its feasibility and generalizability across different\nCSI simulation engines. The related code and dataset are publicly available at:\nhttps://github.com/hkw-xg/Great-MCD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08716v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2005.03120", "title": "Electricity-Aware Bid Format for Coordinated Heat and Electricity Market Clearing", "authors": ["Lesia Mitridati", "Jalal Kazempour", "Pascal Van Hentenryck"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:1910.08617", "url": "http://arxiv.org/abs/2005.03120v4", "summary": "Coordination between heat and electricity markets is essential to achieve a\ncost-effective and efficient operation of the energy system. In the current\nsequential market practice, the heat market is cleared before the electricity\nmarket and has no insight into the impacts of heat dispatch on the electricity\nmarket. While preserving this sequential practice, this paper introduces an\nelectricity-aware bid format for the coordination of heat and electricity\nsystems. This novel market mechanism defines heat bids conditionally on the\nday-ahead electricity prices. Prior to clearing heat and electricity markets,\nthe proposed bid selection mechanism selects the valid bids which minimize the\nheat system operating cost while anticipating heat and electricity market\nclearing. This mechanism is modeled as a trilevel optimization problem, which\nwe recast as a mixed-integer linear program using a lexicographic function. We\nuse a realistic case study based on the Danish electricity and heat system and\nshow that the proposed bid selection mechanism yields a 4.5% reduction in the\ntotal operating cost of heat and electricity systems compared to the existing\nmarket-clearing procedure while reducing the financial losses of combined heat\nand power plants and heat pumps due to invalid bids by up to 20.3 million\neuros.", "comment": "arXiv admin note: text overlap with arXiv:1910.08617", "pdf_url": "http://arxiv.org/pdf/2005.03120v4", "cate": "eess.SY", "date": "2020-05-06", "updated": "2025-07-11"}
{"id": "2507.08670", "title": "Multi-Symbol Digital AirComp via Modulation Design and Power Adaptation", "authors": ["Xiaojing Yan", "Saeed Razavikia", "Carlo Fischione"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08670v1", "summary": "In this paper, we consider digital over-the-air computation (AirComp) and\nintroduce a new multi-symbol modulation framework called sequential modulation\nfor AirComp (SeMAC). Building upon ChannelComp, a general framework for\ndesigning modulation schemes to support arbitrary function computation over a\nmultiple access channel (MAC), SeMAC maps each input value to a sequence of\nmodulated symbols using distinct constellation diagrams across multiple time\nslots. This extension generalizes ChannelComp by enabling flexible modulation\ndesign across multiple transmissions, thereby enhancing reliability against\nchannel noise. We formulate the modulation design as a non-convex optimization\nproblem, apply matrix lifting to relax it into a semidefinite programming\n(SDP), and recover a feasible modulation solution by solving a low rank\napproximation. For scenarios where the modulation formats cannot be changed, we\nfurther develop a power adaptation scheme that adjusts amplitude and phase of\nthe modulated symbols while preserving the modulation structure. Numerical\nresults show that SeMAC can achieve a reliable computation by reducing the\ncomputation error up to 18 dB compared to other existing methods, particularly\nfor the product function.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08670v1", "cate": "eess.SP", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08025", "title": "3D forest semantic segmentation using multispectral LiDAR and 3D deep learning", "authors": ["Narges Takhtkeshha", "Lauris Bocaux", "Lassi Ruoppa", "Fabio Remondino", "Gottfried Mandlburger", "Antero Kukko", "Juha Hyyppä"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08025v1", "summary": "Conservation and decision-making regarding forest resources necessitate\nregular forest inventory. Light detection and ranging (LiDAR) in laser scanning\nsystems has gained significant attention over the past two decades as a remote\nand non-destructive solution to streamline the labor-intensive and\ntime-consuming procedure of forest inventory. Advanced multispectral (MS) LiDAR\nsystems simultaneously acquire three-dimensional (3D) spatial and spectral\ninformation across multiple wavelengths of the electromagnetic spectrum.\nConsequently, MS-LiDAR technology enables the estimation of both the\nbiochemical and biophysical characteristics of forests. Forest component\nsegmentation is crucial for forest inventory. The synergistic use of spatial\nand spectral laser information has proven to be beneficial for achieving\nprecise forest semantic segmentation. Thus, this study aims to investigate the\npotential of MS-LiDAR data, captured by the HeliALS system, providing\nhigh-density multispectral point clouds to segment forests into six components:\nground, low vegetation, trunks, branches, foliage, and woody debris. Three\npoint-wise 3D deep learning models and one machine learning model, including\nkernel point convolution, superpoint transformer, point transformer V3, and\nrandom forest, are implemented. Our experiments confirm the superior accuracy\nof the KPConv model. Additionally, various geometric and spectral feature\nvector scenarios are examined. The highest accuracy is achieved by feeding all\nthree wavelengths (1550 nm, 905 nm, and 532 nm) as the initial features into\nthe deep learning model, resulting in improvements of 33.73% and 32.35% in mean\nintersection over union (mIoU) and in mean accuracy (mAcc), respectively. This\nstudy highlights the excellent potential of multispectral LiDAR for improving\nthe accuracy in fully automated forest component segmentation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08025v1", "cate": "eess.IV", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2507.08765", "title": "Compress Any Segment Anything Model (SAM)", "authors": ["Juntong Fan", "Zhiwei Hao", "Jianqiang Shen", "Shang-Ling Jui", "Yi Zhang", "Jing-Xiao Liao", "Feng-Lei Fan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      13 pages, 6 tables, 8 figures", "url": "http://arxiv.org/abs/2507.08765v1", "summary": "Due to the excellent performance in yielding high-quality, zero-shot\nsegmentation, Segment Anything Model (SAM) and its variants have been widely\napplied in diverse scenarios such as healthcare and intelligent manufacturing.\nTherefore, effectively compressing SAMs has become an increasingly pressing\npractical need. In this study, we propose Birkhoff, a novel data-free\ncompression algorithm for SAM and its variants. Unlike quantization, pruning,\ndistillation, and other compression methods, Birkhoff embodies versatility\nacross model types, agility in deployment, faithfulness to the original model,\nand compactness in model size. Specifically, Birkhoff introduces a novel\ncompression algorithm: Hyper-Compression, whose core principle is to find a\ndense trajectory to turn a high-dimensional parameter vector into a\nlow-dimensional scalar. Furthermore, Birkhoff designs a dedicated linear layer\noperator, HyperLinear, to fuse decompression and matrix multiplication to\nsignificantly accelerate inference of the compressed SAMs. Extensive\nexperiments on 18 SAMs in the COCO, LVIS, and SA-1B datasets show that Birkhoff\nperforms consistently and competitively in compression time, compression ratio,\npost-compression performance, and inference speed. For example, Birkhoff can\nachieve a compression ratio of 5.17x on SAM2-B, with less than 1% performance\ndrop without using any fine-tuning data. Moreover, the compression is finished\nwithin 60 seconds for all models.", "comment": "13 pages, 6 tables, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.08765v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08771", "title": "BlockFFN: Towards End-Side Acceleration-Friendly Mixture-of-Experts with Chunk-Level Activation Sparsity", "authors": ["Chenyang Song", "Weilin Zhao", "Xu Han", "Chaojun Xiao", "Yingfa Chen", "Yuxuan Li", "Zhiyuan Liu", "Maosong Sun"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 7 figures, 15 tables", "url": "http://arxiv.org/abs/2507.08771v1", "summary": "To alleviate the computational burden of large language models (LLMs),\narchitectures with activation sparsity, represented by mixture-of-experts\n(MoE), have attracted increasing attention. However, the non-differentiable and\ninflexible routing of vanilla MoE hurts model performance. Moreover, while each\ntoken activates only a few parameters, these sparsely-activated architectures\nexhibit low chunk-level sparsity, indicating that the union of multiple\nconsecutive tokens activates a large ratio of parameters. Such a sparsity\npattern is unfriendly for acceleration under low-resource conditions (e.g.,\nend-side devices) and incompatible with mainstream acceleration techniques\n(e.g., speculative decoding). To address these challenges, we introduce a novel\nMoE architecture, BlockFFN, as well as its efficient training and deployment\ntechniques. Specifically, we use a router integrating ReLU activation and\nRMSNorm for differentiable and flexible routing. Next, to promote both\ntoken-level sparsity (TLS) and chunk-level sparsity (CLS), CLS-aware training\nobjectives are designed, making BlockFFN more acceleration-friendly. Finally,\nwe implement efficient acceleration kernels, combining activation sparsity and\nspeculative decoding for the first time. The experimental results demonstrate\nthe superior performance of BlockFFN over other MoE baselines, achieving over\n80% TLS and 70% 8-token CLS. Our kernels achieve up to 3.67$\\times$ speedup on\nreal end-side devices than dense models. All codes and checkpoints are\navailable publicly (https://github.com/thunlp/BlockFFN).", "comment": "21 pages, 7 figures, 15 tables", "pdf_url": "http://arxiv.org/pdf/2507.08771v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08729", "title": "RoundaboutHD: High-Resolution Real-World Urban Environment Benchmark for Multi-Camera Vehicle Tracking", "authors": ["Yuqiang Lin", "Sam Lockyer", "Mingxuan Sui", "Li Gan", "Florian Stanek", "Markus Zarbock", "Wenbin Li", "Adrian Evans", "Nic Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08729v1", "summary": "The multi-camera vehicle tracking (MCVT) framework holds significant\npotential for smart city applications, including anomaly detection, traffic\ndensity estimation, and suspect vehicle tracking. However, current publicly\navailable datasets exhibit limitations, such as overly simplistic scenarios,\nlow-resolution footage, and insufficiently diverse conditions, creating a\nconsiderable gap between academic research and real-world scenario. To fill\nthis gap, we introduce RoundaboutHD, a comprehensive, high-resolution\nmulti-camera vehicle tracking benchmark dataset specifically designed to\nrepresent real-world roundabout scenarios. RoundaboutHD provides a total of 40\nminutes of labelled video footage captured by four non-overlapping,\nhigh-resolution (4K resolution, 15 fps) cameras. In total, 512 unique vehicle\nidentities are annotated across different camera views, offering rich\ncross-camera association data. RoundaboutHD offers temporal consistency video\nfootage and enhanced challenges, including increased occlusions and nonlinear\nmovement inside the roundabout. In addition to the full MCVT dataset, several\nsubsets are also available for object detection, single camera tracking, and\nimage-based vehicle re-identification (ReID) tasks. Vehicle model information\nand camera modelling/ geometry information are also included to support further\nanalysis. We provide baseline results for vehicle detection, single-camera\ntracking, image-based vehicle re-identification, and multi-camera tracking. The\ndataset and the evaluation code are publicly available at:\nhttps://github.com/siri-rouser/RoundaboutHD.git", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08729v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2307.02004", "title": "Wholesale Market Participation of DERA: Competitive DER Aggregation", "authors": ["Cong Chen", "Ahmed S. Alahmed", "Timothy D. Mount", "Lang Tong"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures", "url": "http://arxiv.org/abs/2307.02004v4", "summary": "We consider the aggregation of distributed energy resources (DERs) by a\nprofit-seeking aggregator participating directly in wholesale market under\ndistribution network access constraints. We propose a competitive DER\naggregator (DERA) model that maximizes the DERA's profit while ensuring each\naggregated customer gains no less surplus and pays no higher energy cost than\nunder the regulated retail tariff. The DERA participates in wholesale\nelectricity market as virtual storage with optimized generation offers and\nconsumption bids derived from our competitive aggregation model. Also derived\nare DERA's bid curves for the distribution network access and DERA's\nprofitability when competing with the regulated retail tariff. We show that,\nwith the same distribution network access, the proposed DERA's wholesale market\nparticipation achieves the same welfare-maximizing outcome as when its\ncustomers participate directly in the wholesale market. Numerical studies\ncompare the proposed DERA with existing methods in terms of customer surplus\nand DERA profit. We empirically evaluate how many DERAs can survive in the\ncompetition at long-run equilibrium, and assess the impacts of DER adoption\nlevels and distribution network access on short-run market outcomes.", "comment": "16 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2307.02004v4", "cate": "eess.SY", "date": "2023-07-05", "updated": "2025-07-11"}
{"id": "2507.08051", "title": "Modèle physique variationnel pour l'estimation de réponses impulsionnelles de salles", "authors": ["Louis Lalay", "Mathieu Fontaine", "Roland Badeau"], "categories": ["cs.SD", "eess.AS", "eess.SP", "physics.class-ph"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      in French language. GRETSI, Aug 2025, Strasbourg (67000), France", "url": "http://arxiv.org/abs/2507.08051v1", "summary": "Room impulse response estimation is essential for tasks like speech\ndereverberation, which improves automatic speech recognition. Most existing\nmethods rely on either statistical signal processing or deep neural networks\ndesigned to replicate signal processing principles. However, combining\nstatistical and physical modeling for RIR estimation remains largely\nunexplored. This paper proposes a novel approach integrating both aspects\nthrough a theoretically grounded model. The RIR is decomposed into\ninterpretable parameters: white Gaussian noise filtered by a\nfrequency-dependent exponential decay (e.g. modeling wall absorption) and an\nautoregressive filter (e.g. modeling microphone response). A variational\nfree-energy cost function enables practical parameter estimation. As a proof of\nconcept, we show that given dry and reverberant speech signals, the proposed\nmethod outperforms classical deconvolution in noisy environments, as validated\nby objective metrics.", "comment": "in French language. GRETSI, Aug 2025, Strasbourg (67000), France", "pdf_url": "http://arxiv.org/pdf/2507.08051v1", "cate": "cs.SD", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08178", "title": "Cracking Instance Jigsaw Puzzles: An Alternative to Multiple Instance Learning for Whole Slide Image Analysis", "authors": ["Xiwen Chen", "Peijie Qiu", "Wenhui Zhu", "Hao Wang", "Huayu Li", "Xuanzhao Dong", "Xiaotong Sun", "Xiaobing Yu", "Yalin Wang", "Abolfazl Razi", "Aristeidis Sotiras"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.08178v1", "summary": "While multiple instance learning (MIL) has shown to be a promising approach\nfor histopathological whole slide image (WSI) analysis, its reliance on\npermutation invariance significantly limits its capacity to effectively uncover\nsemantic correlations between instances within WSIs. Based on our empirical and\ntheoretical investigations, we argue that approaches that are not\npermutation-invariant but better capture spatial correlations between instances\ncan offer more effective solutions. In light of these findings, we propose a\nnovel alternative to existing MIL for WSI analysis by learning to restore the\norder of instances from their randomly shuffled arrangement. We term this task\nas cracking an instance jigsaw puzzle problem, where semantic correlations\nbetween instances are uncovered. To tackle the instance jigsaw puzzles, we\npropose a novel Siamese network solution, which is theoretically justified by\noptimal transport theory. We validate the proposed method on WSI classification\nand survival prediction tasks, where the proposed method outperforms the recent\nstate-of-the-art MIL competitors. The code is available at\nhttps://github.com/xiwenc1/MIL-JigsawPuzzles.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.08178v1", "cate": "eess.IV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08766", "title": "A Hybrid Multi-Well Hopfield-CNN with Feature Extraction and K-Means for MNIST Classification", "authors": ["Ahmed Farooq"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08766v1", "summary": "This study presents a hybrid model for classifying handwritten digits in the\nMNIST dataset, combining convolutional neural networks (CNNs) with a multi-well\nHopfield network. The approach employs a CNN to extract high-dimensional\nfeatures from input images, which are then clustered into class-specific\nprototypes using k-means clustering. These prototypes serve as attractors in a\nmulti-well energy landscape, where a Hopfield network performs classification\nby minimizing an energy function that balances feature similarity and class\nassignment.The model's design enables robust handling of intraclass\nvariability, such as diverse handwriting styles, while providing an\ninterpretable framework through its energy-based decision process. Through\nsystematic optimization of the CNN architecture and the number of wells, the\nmodel achieves a high test accuracy of 99.2% on 10,000 MNIST images,\ndemonstrating its effectiveness for image classification tasks. The findings\nhighlight the critical role of deep feature extraction and sufficient prototype\ncoverage in achieving high performance, with potential for broader applications\nin pattern recognition.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08766v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08784", "title": "Greedy Low-Rank Gradient Compression for Distributed Learning with Convergence Guarantees", "authors": ["Chuyan Chen", "Yutong He", "Pengrui Li", "Weichen Jia", "Kun Yuan"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures", "url": "http://arxiv.org/abs/2507.08784v1", "summary": "Distributed optimization is pivotal for large-scale signal processing and\nmachine learning, yet communication overhead remains a major bottleneck.\nLow-rank gradient compression, in which the transmitted gradients are\napproximated by low-rank matrices to reduce communication, offers a promising\nremedy. Existing methods typically adopt either randomized or greedy\ncompression strategies: randomized approaches project gradients onto randomly\nchosen subspaces, introducing high variance and degrading empirical\nperformance; greedy methods select the most informative subspaces, achieving\nstrong empirical results but lacking convergence guarantees. To address this\ngap, we propose GreedyLore--the first Greedy Low-Rank gradient compression\nalgorithm for distributed learning with rigorous convergence guarantees.\nGreedyLore incorporates error feedback to correct the bias introduced by greedy\ncompression and introduces a semi-lazy subspace update that ensures the\ncompression operator remains contractive throughout all iterations. With these\ntechniques, we prove that GreedyLore achieves a convergence rate of\n$\\mathcal{O}(\\sigma/\\sqrt{NT} + 1/T)$ under standard optimizers such as MSGD\nand Adam--marking the first linear speedup convergence rate for low-rank\ngradient compression. Extensive experiments are conducted to validate our\ntheoretical findings.", "comment": "18 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.08784v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08735", "title": "Ensemble of Weak Spectral Total Variation Learners: a PET-CT Case Study", "authors": ["Anna Rosenberg", "John Kennedy", "Zohar Keidar", "Yehoshua Y. Zeevi", "Guy Gilboa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08735v1", "summary": "Solving computer vision problems through machine learning, one often\nencounters lack of sufficient training data. To mitigate this we propose the\nuse of ensembles of weak learners based on spectral total-variation (STV)\nfeatures (Gilboa 2014). The features are related to nonlinear eigenfunctions of\nthe total-variation subgradient and can characterize well textures at various\nscales. It was shown (Burger et-al 2016) that, in the one-dimensional case,\northogonal features are generated, whereas in two-dimensions the features are\nempirically lowly correlated. Ensemble learning theory advocates the use of\nlowly correlated weak learners. We thus propose here to design ensembles using\nlearners based on STV features. To show the effectiveness of this paradigm we\nexamine a hard real-world medical imaging problem: the predictive value of\ncomputed tomography (CT) data for high uptake in positron emission tomography\n(PET) for patients suspected of skeletal metastases. The database consists of\n457 scans with 1524 unique pairs of registered CT and PET slices. Our approach\nis compared to deep-learning methods and to Radiomics features, showing STV\nlearners perform best (AUC=0.87), compared to neural nets (AUC=0.75) and\nRadiomics (AUC=0.79). We observe that fine STV scales in CT images are\nespecially indicative for the presence of high uptake in PET.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08735v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.01984", "title": "A Preventive-Corrective Scheme for Ensuring Power System Security During Active Wildfire Risks", "authors": ["Satyaprajna Sahoo", "Anamitra Pal"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Submitted to the Open Access Journal of Power and Energy (OAJPE)", "url": "http://arxiv.org/abs/2410.01984v2", "summary": "The focus of this paper is on operating the electric power grid in a secure\nmanner when wildfire risks are high. This is a challenging problem because of\nthe uncertain ways in which the fires can impact the operation of the power\nsystem. To address this challenge, we propose a novel preventive-corrective\ncoordinated decision-making scheme that quickly mitigates both static and\ndynamic insecurities given the risk of active wildfires in a region. The scheme\nutilizes a comprehensive contingency analysis tool for multi-asset outages that\nleverages: (i) a Feasibility Test algorithm which exhaustively desaturates\noverloaded cut-sets to prevent cascading line outages, and (ii) a data-driven\ntransient stability analyzer which alleviates dynamic instabilities. This tool\nis then used to operate a coordinated unit commitment/optimal power flow model\nthat is designed to adapt to varying risk levels associated with wildfires.\nDepending on the allowed risk, the model balances economical operation and grid\nrobustness. The results obtained using the IEEE 118-bus system indicate that\nthe proposed approach alleviates system vulnerabilities to wildfires while also\nminimizing operational cost.", "comment": "Submitted to the Open Access Journal of Power and Energy (OAJPE)", "pdf_url": "http://arxiv.org/pdf/2410.01984v2", "cate": "eess.SY", "date": "2024-10-02", "updated": "2025-07-11"}
{"id": "2412.13843", "title": "A Review on Deep Learning Autoencoder in the Design of Next-Generation Communication Systems", "authors": ["Omar Alnaseri", "Laith Alzubaidi", "Yassine Himeur", "Mohammed Alaa Ala'anzy", "Jens Timmermann", "Mohammed S. M. Gismalla"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.13843v2", "summary": "Traditional mathematical models used in designing next-generation\ncommunication systems often fall short due to inherent simplifications, narrow\nscope, and computational limitations. In recent years, the incorporation of\ndeep learning (DL) methodologies into communication systems has made\nsignificant progress in system design and performance optimisation.\nAutoencoders (AEs) have become essential, enabling end-to-end learning that\nallows for the combined optimisation of transmitters and receivers.\nConsequently, AEs offer a data-driven methodology capable of bridging the gap\nbetween theoretical models and real-world complexities. The paper presents a\ncomprehensive survey of the application of AEs within communication systems,\nwith a particular focus on their architectures, associated challenges, and\nfuture directions. We examine 120 recent studies across wireless, optical,\nsemantic, and quantum communication fields, categorising them according to\ntransceiver design, channel modelling, digital signal processing, and\ncomputational complexity. This paper further examines the challenges\nencountered in the implementation of AEs, including the need for extensive\ntraining data, the risk of overfitting, and the requirement for differentiable\nchannel models. Through data-driven approaches, AEs provide robust solutions\nfor end-to-end system optimisation, surpassing traditional mathematical models\nconfined by simplifying assumptions. This paper also summarises the\ncomputational complexity associated with AE-based systems by conducting an\nin-depth analysis employing the metric of floating-point operations per second\n(FLOPS). This analysis encompasses the evaluation of matrix multiplications,\nbias additions, and activation functions. This survey aims to establish a\nroadmap for future research, emphasising the transformative potential of AEs in\nthe formulation of next-generation communication systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.13843v2", "cate": "eess.SP", "date": "2024-12-18", "updated": "2025-07-11"}
{"id": "2507.08214", "title": "Depth-Sequence Transformer (DST) for Segment-Specific ICA Calcification Mapping on Non-Contrast CT", "authors": ["Xiangjian Hou", "Ebru Yaman Akcicek", "Xin Wang", "Kazem Hashemizadeh", "Scott Mcnally", "Chun Yuan", "Xiaodong Ma"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08214v1", "summary": "While total intracranial carotid artery calcification (ICAC) volume is an\nestablished stroke biomarker, growing evidence shows this aggregate metric\nignores the critical influence of plaque location, since calcification in\ndifferent segments carries distinct prognostic and procedural risks. However, a\nfiner-grained, segment-specific quantification has remained technically\ninfeasible. Conventional 3D models are forced to process downsampled volumes or\nisolated patches, sacrificing the global context required to resolve anatomical\nambiguity and render reliable landmark localization. To overcome this, we\nreformulate the 3D challenge as a \\textbf{Parallel Probabilistic Landmark\nLocalization} task along the 1D axial dimension. We propose the\n\\textbf{Depth-Sequence Transformer (DST)}, a framework that processes\nfull-resolution CT volumes as sequences of 2D slices, learning to predict $N=6$\nindependent probability distributions that pinpoint key anatomical landmarks.\nOur DST framework demonstrates exceptional accuracy and robustness. Evaluated\non a 100-patient clinical cohort with rigorous 5-fold cross-validation, it\nachieves a Mean Absolute Error (MAE) of \\textbf{0.1 slices}, with \\textbf{96\\%}\nof predictions falling within a $\\pm1$ slice tolerance. Furthermore, to\nvalidate its architectural power, the DST backbone establishes the best result\non the public Clean-CC-CCII classification benchmark under an end-to-end\nevaluation protocol. Our work delivers the first practical tool for automated\nsegment-specific ICAC analysis. The proposed framework provides a foundation\nfor further studies on the role of location-specific biomarkers in diagnosis,\nprognosis, and procedural planning. Our code will be made publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08214v1", "cate": "eess.IV", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08768", "title": "On Barriers to Archival Audio Processing", "authors": ["Peter Sullivan", "Muhammad Abdul-Mageed"], "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Update with Acknowledgements of ICNSLP 2025 paper", "url": "http://arxiv.org/abs/2507.08768v1", "summary": "In this study, we leverage a unique UNESCO collection of mid-20th century\nradio recordings to probe the robustness of modern off-the-shelf language\nidentification (LID) and speaker recognition (SR) methods, especially with\nrespect to the impact of multilingual speakers and cross-age recordings. Our\nfindings suggest that LID systems, such as Whisper, are increasingly adept at\nhandling second-language and accented speech. However, speaker embeddings\nremain a fragile component of speech processing pipelines that is prone to\nbiases related to the channel, age, and language. Issues which will need to be\novercome should archives aim to employ SR methods for speaker indexing.", "comment": "Update with Acknowledgements of ICNSLP 2025 paper", "pdf_url": "http://arxiv.org/pdf/2507.08768v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08793", "title": "Optimistic Exploration for Risk-Averse Constrained Reinforcement Learning", "authors": ["James McCarthy", "Radu Marinescu", "Elizabeth Daly", "Ivana Dusparic"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08793v1", "summary": "Risk-averse Constrained Reinforcement Learning (RaCRL) aims to learn policies\nthat minimise the likelihood of rare and catastrophic constraint violations\ncaused by an environment's inherent randomness. In general, risk-aversion leads\nto conservative exploration of the environment which typically results in\nconverging to sub-optimal policies that fail to adequately maximise reward or,\nin some cases, fail to achieve the goal. In this paper, we propose an\nexploration-based approach for RaCRL called Optimistic Risk-averse Actor Critic\n(ORAC), which constructs an exploratory policy by maximising a local upper\nconfidence bound of the state-action reward value function whilst minimising a\nlocal lower confidence bound of the risk-averse state-action cost value\nfunction. Specifically, at each step, the weighting assigned to the cost value\nis increased or decreased if it exceeds or falls below the safety constraint\nvalue. This way the policy is encouraged to explore uncertain regions of the\nenvironment to discover high reward states whilst still satisfying the safety\nconstraints. Our experimental results demonstrate that the ORAC approach\nprevents convergence to sub-optimal policies and improves significantly the\nreward-cost trade-off in various continuous control tasks such as\nSafety-Gymnasium and a complex building energy management environment\nCityLearn.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08793v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08741", "title": "HieraRS: A Hierarchical Segmentation Paradigm for Remote Sensing Enabling Multi-Granularity Interpretation and Cross-Domain Transfer", "authors": ["Tianlong Ai", "Tianzhu Liu", "Haochen Jiang", "Yanfeng Gu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures", "url": "http://arxiv.org/abs/2507.08741v1", "summary": "Hierarchical land cover and land use (LCLU) classification aims to assign\npixel-wise labels with multiple levels of semantic granularity to remote\nsensing (RS) imagery. However, existing deep learning-based methods face two\nmajor challenges: 1) They predominantly adopt a flat classification paradigm,\nwhich limits their ability to generate end-to-end multi-granularity\nhierarchical predictions aligned with tree-structured hierarchies used in\npractice. 2) Most cross-domain studies focus on performance degradation caused\nby sensor or scene variations, with limited attention to transferring LCLU\nmodels to cross-domain tasks with heterogeneous hierarchies (e.g., LCLU to crop\nclassification). These limitations hinder the flexibility and generalization of\nLCLU models in practical applications. To address these challenges, we propose\nHieraRS, a novel hierarchical interpretation paradigm that enables\nmulti-granularity predictions and supports the efficient transfer of LCLU\nmodels to cross-domain tasks with heterogeneous tree-structured hierarchies. We\nintroduce the Bidirectional Hierarchical Consistency Constraint Mechanism\n(BHCCM), which can be seamlessly integrated into mainstream flat classification\nmodels to generate hierarchical predictions, while improving both semantic\nconsistency and classification accuracy. Furthermore, we present TransLU, a\ndual-branch cross-domain transfer framework comprising two key components:\nCross-Domain Knowledge Sharing (CDKS) and Cross-Domain Semantic Alignment\n(CDSA). TransLU supports dynamic category expansion and facilitates the\neffective adaptation of LCLU models to heterogeneous hierarchies. In addition,\nwe construct MM-5B, a large-scale multi-modal hierarchical land use dataset\nfeaturing pixel-wise annotations. The code and MM-5B dataset will be released\nat: https://github.com/AI-Tianlong/HieraRS.", "comment": "17 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.08741v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.00922", "title": "Online convex optimization for constrained control of nonlinear systems", "authors": ["Marko Nonhoff", "Johannes Köhler", "Matthias A. Müller"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2412.00922v2", "summary": "This paper proposes a modular approach that combines the online convex\noptimization framework and reference governors to solve a constrained control\nproblem featuring time-varying and a priori unknown cost functions. Compared to\nexisting results, the proposed framework is uniquely applicable to nonlinear\ndynamical systems subject to state and input constraints. Furthermore, our\nmethod is general in the sense that we do not limit our analysis to a specific\nchoice of online convex optimization algorithm or reference governor. We show\nthat the dynamic regret of the proposed framework is bounded linearly in both\nthe dynamic regret and the path length of the chosen online convex optimization\nalgorithm, even though the online convex optimization algorithm does not\naccount for the underlying dynamics. We prove that a linear bound with respect\nto the online convex optimization algorithm's dynamic regret is optimal, i.e.,\ncannot be improved upon. Furthermore, for a standard class of online convex\noptimization algorithms, our proposed framework attains a bound on its dynamic\nregret that is linear only in the variation of the cost functions, which is\nknown to be an optimal bound. Finally, we demonstrate implementation and\nflexibility of the proposed framework by comparing different combinations of\nonline convex optimization algorithms and reference governors to control a\nnonlinear chemical reactor in a numerical experiment.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2412.00922v2", "cate": "eess.SY", "date": "2024-12-01", "updated": "2025-07-11"}
{"id": "2503.06807", "title": "Physically Large Apertures for Wireless Power Transfer: Performance and Regulatory Aspects", "authors": ["Benjamin J. B. Deutschmann", "Ulrich Muehlmann", "Ahmet Kaplan", "Gilles Callebaut", "Thomas Wilding", "Bert Cox", "Liesbet Van der Perre", "Fredrik Tufvesson", "Erik G. Larsson", "Klaus Witrisal"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.06807v2", "summary": "Wireless power transfer (WPT) is a promising service for the Internet of\nThings, providing a cost-effective and sustainable solution to deploy so-called\nenergy-neutral devices on a massive scale. The power received at the device\nside from a conventional transmit antenna with a physically small aperture\ndecays rapidly with the distance. New opportunities arise from the transition\nfrom conventional far-field beamforming to near-field beam focusing. We argue\nthat a physically large aperture, i.e., large with respect to the distance to\nthe receiver, enables a power budget that remains practically independent of\ndistance. Distance-dependent array gain patterns allow focusing the power\ndensity maximum precisely at the device location, while reducing the power\ndensity near the infrastructure. Physical aperture size is a key resource in\nenabling efficient yet regulatory-compliant WPT. We use real-world measurements\nto demonstrate that a regulatory-compliant system operating at sub-10GHz\nfrequencies can increase the power received at the device into the milliwatt\nrange. Our empirical demonstration shows that power-optimal near-field beam\nfocusing inherently exploits multipath propagation, yielding both increased WPT\nefficiency and improved human exposure safety.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.06807v2", "cate": "eess.SP", "date": "2025-03-09", "updated": "2025-07-10"}
{"id": "2507.08254", "title": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models", "authors": ["Ulzee An", "Moonseong Jeong", "Simon A. Lee", "Aditya Gorla", "Yuzhe Yang", "Sriram Sankararaman"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      21 pages, 10 figures, accepted to ICML 2025. The first two authors contributed equally", "url": "http://arxiv.org/abs/2507.08254v1", "summary": "Current challenges in developing foundational models for volumetric imaging\ndata, such as magnetic resonance imaging (MRI), stem from the computational\ncomplexity of training state-of-the-art architectures in high dimensions and\ncurating sufficiently large datasets of volumes. To address these challenges,\nwe introduce Raptor (Random Planar Tensor Reduction), a train-free method for\ngenerating semantically rich embeddings for volumetric data. Raptor leverages a\nfrozen 2D foundation model, pretrained on natural images, to extract visual\ntokens from individual cross-sections of medical volumes. These tokens are then\nspatially compressed using random projections, significantly reducing\ncomputational complexity while retaining semantic information. Extensive\nexperiments on ten diverse medical volume tasks verify the superior performance\nof Raptor over state-of-the-art methods, including those pretrained exclusively\non medical volumes (+3% SuPreM, +6% MISFM, +10% Merlin, +13% VoCo, and +14%\nSLIViT), while entirely bypassing the need for costly training. Our results\nhighlight the effectiveness and versatility of Raptor as a foundation for\nadvancing deep learning-based methods for medical volumes.", "comment": "21 pages, 10 figures, accepted to ICML 2025. The first two authors\n  contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.08254v1", "cate": "eess.IV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08799", "title": "KV Cache Steering for Inducing Reasoning in Small Language Models", "authors": ["Max Belitsky", "Dawid J. Kopiczko", "Michael Dorkenwald", "M. Jehanzeb Mirza", "Cees G. M. Snoek", "Yuki M. Asano"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08799v1", "summary": "We propose cache steering, a lightweight method for implicit steering of\nlanguage models via a one-shot intervention applied directly to the key-value\ncache. To validate its effectiveness, we apply cache steering to induce\nchain-of-thought reasoning in small language models. Our approach leverages\nGPT-4o-generated reasoning traces to construct steering vectors that shift\nmodel behavior toward more explicit, multi-step reasoning without fine-tuning\nor prompt modifications. Experimental evaluations on diverse reasoning\nbenchmarks demonstrate that cache steering improves both the qualitative\nstructure of model reasoning and quantitative task performance. Compared to\nprior activation steering techniques that require continuous interventions, our\none-shot cache steering offers substantial advantages in terms of\nhyperparameter stability, inference-time efficiency, and ease of integration,\nmaking it a more robust and practical solution for controlled generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08799v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08794", "title": "One Token to Fool LLM-as-a-Judge", "authors": ["Yulai Zhao", "Haolin Liu", "Dian Yu", "S. Y. Kung", "Haitao Mi", "Dong Yu"], "categories": ["cs.LG", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08794v1", "summary": "Generative reward models (also known as LLMs-as-judges), which use large\nlanguage models (LLMs) to evaluate answer quality, are increasingly adopted in\nreinforcement learning with verifiable rewards (RLVR). They are often preferred\nover rigid rule-based metrics, especially for complex reasoning tasks involving\nfree-form outputs. In this paradigm, an LLM is typically prompted to compare a\ncandidate answer against a ground-truth reference and assign a binary reward\nindicating correctness. Despite the seeming simplicity of this comparison task,\nwe find that generative reward models exhibit surprising vulnerabilities to\nsuperficial manipulations: non-word symbols (e.g., \":\" or \".\") or reasoning\nopeners like \"Thought process:\" and \"Let's solve this problem step by step.\"\ncan often lead to false positive rewards. We demonstrate that this weakness is\nwidespread across LLMs, datasets, and prompt formats, posing a serious threat\nfor core algorithmic paradigms that rely on generative reward models, such as\nrejection sampling, preference optimization, and RLVR. To mitigate this issue,\nwe introduce a simple yet effective data augmentation strategy and train a new\ngenerative reward model with substantially improved robustness. Our findings\nhighlight the urgent need for more reliable LLM-based evaluation methods. We\nrelease our robust, general-domain reward model and its synthetic training data\nat https://huggingface.co/sarosavo/Master-RM and\nhttps://huggingface.co/datasets/sarosavo/Master-RM.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08794v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08772", "title": "From One to More: Contextual Part Latents for 3D Generation", "authors": ["Shaocong Dong", "Lihe Ding", "Xiao Chen", "Yaokun Li", "Yuxin Wang", "Yucheng Wang", "Qi Wang", "Jaehyeok Kim", "Chenjian Gao", "Zhanpeng Huang", "Zibin Wang", "Tianfan Xue", "Dan Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.08772v1", "summary": "Recent advances in 3D generation have transitioned from multi-view 2D\nrendering approaches to 3D-native latent diffusion frameworks that exploit\ngeometric priors in ground truth data. Despite progress, three key limitations\npersist: (1) Single-latent representations fail to capture complex multi-part\ngeometries, causing detail degradation; (2) Holistic latent coding neglects\npart independence and interrelationships critical for compositional design; (3)\nGlobal conditioning mechanisms lack fine-grained controllability. Inspired by\nhuman 3D design workflows, we propose CoPart - a part-aware diffusion framework\nthat decomposes 3D objects into contextual part latents for coherent multi-part\ngeneration. This paradigm offers three advantages: i) Reduces encoding\ncomplexity through part decomposition; ii) Enables explicit part relationship\nmodeling; iii) Supports part-level conditioning. We further develop a mutual\nguidance strategy to fine-tune pre-trained diffusion models for joint part\nlatent denoising, ensuring both geometric coherence and foundation model\npriors. To enable large-scale training, we construct Partverse - a novel 3D\npart dataset derived from Objaverse through automated mesh segmentation and\nhuman-verified annotations. Extensive experiments demonstrate CoPart's superior\ncapabilities in part-level editing, articulated object generation, and scene\ncomposition with unprecedented controllability.", "comment": "Project page: https://hkdsc.github.io/project/copart", "pdf_url": "http://arxiv.org/pdf/2507.08772v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.08033", "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "authors": ["Axel TahmasebiMoradi", "Vincent Ren", "Benjamin Le-Creurer", "Chetra Mang", "Mouadh Yagoubi"], "categories": ["eess.SY", "cs.LG", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.08033v3", "summary": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.08033v3", "cate": "eess.SY", "date": "2025-06-02", "updated": "2025-07-11"}
{"id": "2506.06311", "title": "A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration", "authors": ["Meiyan Kang", "Shizuo Kaji", "Sang-Yun Lee", "Taegon Kim", "Hee-Hwan Ryu", "Suyoung Choi"], "categories": ["eess.SP", "cs.LG"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 pages, 6 figures", "url": "http://arxiv.org/abs/2506.06311v2", "summary": "Ground Penetrating Radar (GPR) is a widely used Non-Destructive Testing (NDT)\ntechnique for subsurface exploration, particularly in infrastructure inspection\nand maintenance. However, conventional interpretation methods are often limited\nby noise sensitivity and a lack of structural awareness. This study presents a\nnovel framework that enhances the detection of underground utilities,\nespecially pipelines, by integrating shape-aware topological features derived\nfrom B-scan GPR images using Topological Data Analysis (TDA), with the spatial\ndetection capabilities of the YOLOv5 deep neural network (DNN). We propose a\nnovel shape-aware topological representation that amplifies structural features\nin the input data, thereby improving the model's responsiveness to the\ngeometrical features of buried objects. To address the scarcity of annotated\nreal-world data, we employ a Sim2Real strategy that generates diverse and\nrealistic synthetic datasets, effectively bridging the gap between simulated\nand real-world domains. Experimental results demonstrate significant\nimprovements in mean Average Precision (mAP), validating the robustness and\nefficacy of our approach. This approach underscores the potential of\nTDA-enhanced learning in achieving reliable, real-time subsurface object\ndetection, with broad applications in urban planning, safety inspection, and\ninfrastructure management.", "comment": "15 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2506.06311v2", "cate": "eess.SP", "date": "2025-05-26", "updated": "2025-07-11"}
{"id": "2507.08282", "title": "MetaH2: A Snapshot Metasurface HDR Hyperspectral Camera", "authors": ["Yuxuan Liu", "Qi Guo"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      To appear in IEEE ICIP 2025", "url": "http://arxiv.org/abs/2507.08282v1", "summary": "We present a metasurface camera that jointly performs high-dynamic range\n(HDR) and hyperspectral imaging in a snapshot. The system integrates exposure\nbracketing and computed tomography imaging spectrometry (CTIS) by\nsimultaneously forming multiple spatially multiplexed projections with unique\npower ratios and chromatic aberrations on a photosensor. The measurements are\nsubsequently processed through a deep reconstruction model to generate an HDR\nimage and a hyperspectral datacube. Our simulation studies show that the\nproposed system achieves higher reconstruction accuracy than previous snapshot\nhyperspectral imaging methods on benchmark datasets. We assemble a working\nprototype and demonstrate snapshot reconstruction of 60 dB dynamic range and 10\nnm spectral resolution from 600 nm to 700 nm on real-world scenes from a\nmonochrome photosensor.", "comment": "To appear in IEEE ICIP 2025", "pdf_url": "http://arxiv.org/pdf/2507.08282v1", "cate": "eess.IV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08135", "title": "DARAS: Dynamic Audio-Room Acoustic Synthesis for Blind Room Impulse Response Estimation", "authors": ["Chunxi Wang", "Maoshen Jia", "Wenyu Jin"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      14 pages, 9 figures, submitted to IEEE/ACM Transactions on Audio, Speech, and Language Processing", "url": "http://arxiv.org/abs/2507.08135v1", "summary": "Room Impulse Responses (RIRs) accurately characterize acoustic properties of\nindoor environments and play a crucial role in applications such as speech\nenhancement, speech recognition, and audio rendering in augmented reality (AR)\nand virtual reality (VR). Existing blind estimation methods struggle to achieve\npractical accuracy. To overcome this challenge, we propose the dynamic\naudio-room acoustic synthesis (DARAS) model, a novel deep learning framework\nthat is explicitly designed for blind RIR estimation from monaural reverberant\nspeech signals. First, a dedicated deep audio encoder effectively extracts\nrelevant nonlinear latent space features. Second, the Mamba-based\nself-supervised blind room parameter estimation (MASS-BRPE) module, utilizing\nthe efficient Mamba state space model (SSM), accurately estimates key room\nacoustic parameters and features. Third, the system incorporates a hybrid-path\ncross-attention feature fusion module, enhancing deep integration between audio\nand room acoustic features. Finally, our proposed dynamic acoustic tuning (DAT)\ndecoder adaptively segments early reflections and late reverberation to improve\nthe realism of synthesized RIRs. Experimental results, including a MUSHRA-based\nsubjective listening study, demonstrate that DARAS substantially outperforms\nexisting baseline models, providing a robust and effective solution for\npractical blind RIR estimation in real-world acoustic environments.", "comment": "14 pages, 9 figures, submitted to IEEE/ACM Transactions on Audio,\n  Speech, and Language Processing", "pdf_url": "http://arxiv.org/pdf/2507.08135v1", "cate": "eess.AS", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08801", "title": "Lumos-1: On Autoregressive Video Generation from a Unified Model Perspective", "authors": ["Hangjie Yuan", "Weihua Chen", "Jun Cen", "Hu Yu", "Jingyun Liang", "Shuning Chang", "Zhihui Lin", "Tao Feng", "Pengwei Liu", "Jiazheng Xing", "Hao Luo", "Jiasheng Tang", "Fan Wang", "Yi Yang"], "categories": ["cs.CV", "cs.AI", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Code and Models: this https URL", "url": "http://arxiv.org/abs/2507.08801v1", "summary": "Autoregressive large language models (LLMs) have unified a vast range of\nlanguage tasks, inspiring preliminary efforts in autoregressive video\ngeneration. Existing autoregressive video generators either diverge from\nstandard LLM architectures, depend on bulky external text encoders, or incur\nprohibitive latency due to next-token decoding. In this paper, we introduce\nLumos-1, an autoregressive video generator that retains the LLM architecture\nwith minimal architectural modifications. To inject spatiotemporal correlations\nin LLMs, we identify the efficacy of incorporating 3D RoPE and diagnose its\nimbalanced frequency spectrum ranges. Therefore, we propose MM-RoPE, a RoPE\nscheme that preserves the original textual RoPE while providing comprehensive\nfrequency spectra and scaled 3D positions for modeling multimodal\nspatiotemporal data. Moreover, Lumos-1 resorts to a token dependency strategy\nthat obeys intra-frame bidirectionality and inter-frame temporal causality.\nBased on this dependency strategy, we identify the issue of frame-wise loss\nimbalance caused by spatial information redundancy and solve it by proposing\nAutoregressive Discrete Diffusion Forcing (AR-DF). AR-DF introduces temporal\ntube masking during training with a compatible inference-time masking policy to\navoid quality degradation. By using memory-efficient training techniques, we\npre-train Lumos-1 on only 48 GPUs, achieving performance comparable to EMU3 on\nGenEval, COSMOS-Video2World on VBench-I2V, and OpenSoraPlan on VBench-T2V. Code\nand models are available at https://github.com/alibaba-damo-academy/Lumos.", "comment": "Code and Models: https://github.com/alibaba-damo-academy/Lumos", "pdf_url": "http://arxiv.org/pdf/2507.08801v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08802", "title": "The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?", "authors": ["Denis Sutter", "Julian Minder", "Thomas Hofmann", "Tiago Pimentel"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      42 pages, 17 figures, code available in this http URL", "url": "http://arxiv.org/abs/2507.08802v1", "summary": "The concept of causal abstraction got recently popularised to demystify the\nopaque decision-making processes of machine learning models; in short, a neural\nnetwork can be abstracted as a higher-level algorithm if there exists a\nfunction which allows us to map between them. Notably, most interpretability\npapers implement these maps as linear functions, motivated by the linear\nrepresentation hypothesis: the idea that features are encoded linearly in a\nmodel's representations. However, this linearity constraint is not required by\nthe definition of causal abstraction. In this work, we critically examine the\nconcept of causal abstraction by considering arbitrarily powerful alignment\nmaps. In particular, we prove that under reasonable assumptions, any neural\nnetwork can be mapped to any algorithm, rendering this unrestricted notion of\ncausal abstraction trivial and uninformative. We complement these theoretical\nfindings with empirical evidence, demonstrating that it is possible to\nperfectly map models to algorithms even when these models are incapable of\nsolving the actual task; e.g., on an experiment using randomly initialised\nlanguage models, our alignment maps reach 100% interchange-intervention\naccuracy on the indirect object identification task. This raises the non-linear\nrepresentation dilemma: if we lift the linearity constraint imposed to\nalignment maps in causal abstraction analyses, we are left with no principled\nway to balance the inherent trade-off between these maps' complexity and\naccuracy. Together, these results suggest an answer to our title's question:\ncausal abstraction is not enough for mechanistic interpretability, as it\nbecomes vacuous without assumptions about how models encode information.\nStudying the connection between this information-encoding assumption and causal\nabstraction should lead to exciting future work.", "comment": "42 pages, 17 figures, code available in\n  github.com/densutter/non-linear-representation-dilemma", "pdf_url": "http://arxiv.org/pdf/2507.08802v1", "cate": "cs.LG", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08776", "title": "CLiFT: Compressive Light-Field Tokens for Compute-Efficient and Adaptive Neural Rendering", "authors": ["Zhengqing Wang", "Yuefan Wu", "Jiacheng Chen", "Fuyang Zhang", "Yasutaka Furukawa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project page: this https URL", "url": "http://arxiv.org/abs/2507.08776v1", "summary": "This paper proposes a neural rendering approach that represents a scene as\n\"compressed light-field tokens (CLiFTs)\", retaining rich appearance and\ngeometric information of a scene. CLiFT enables compute-efficient rendering by\ncompressed tokens, while being capable of changing the number of tokens to\nrepresent a scene or render a novel view with one trained network. Concretely,\ngiven a set of images, multi-view encoder tokenizes the images with the camera\nposes. Latent-space K-means selects a reduced set of rays as cluster centroids\nusing the tokens. The multi-view ``condenser'' compresses the information of\nall the tokens into the centroid tokens to construct CLiFTs. At test time,\ngiven a target view and a compute budget (i.e., the number of CLiFTs), the\nsystem collects the specified number of nearby tokens and synthesizes a novel\nview using a compute-adaptive renderer. Extensive experiments on RealEstate10K\nand DL3DV datasets quantitatively and qualitatively validate our approach,\nachieving significant data reduction with comparable rendering quality and the\nhighest overall rendering score, while providing trade-offs of data size,\nrendering quality, and rendering speed.", "comment": "Project page: https://c-lift.github.io", "pdf_url": "http://arxiv.org/pdf/2507.08776v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.10964", "title": "A Stability Condition for Online Feedback Optimization without Timescale Separation", "authors": ["Mattia Bianchi", "Florian Dörfler"], "categories": ["math.OC", "cs.SY", "eess.SY", "math.DS"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.10964v2", "summary": "Online Feedback Optimization (OFO) is a control approach to drive a dynamical\nplant to an optimal steady state. By interconnecting optimization algorithms\nwith real-time plant measurements, OFO provides all the benefits of feedback\ncontrol, yet without requiring exact knowledge of plant dynamics for computing\na setpoint. On the downside, existing stability guarantees for OFO require the\ncontroller to evolve on a sufficiently slower timescale than the plant,\npossibly affecting transient performance and responsiveness to disturbances. In\nthis paper, we prove that, under suitable conditions, OFO ensures stability\nwithout any timescale separation. In particular, the condition we propose is\nindependent of the time constant of the plant, hence it is scaling-invariant.\nOur analysis leverages a composite Lyapunov function, which is the $\\max$ of\nplant-related and controller-related components. We corroborate our theoretical\nresults with numerical examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.10964v2", "cate": "math.OC", "date": "2024-12-14", "updated": "2025-07-11"}
{"id": "2412.19470", "title": "Movable Antenna-Aided Near-Field Integrated Sensing and Communication", "authors": ["Jingze Ding", "Zijian Zhou", "Xiaodan Shao", "Bingli Jiao", "Rui Zhang"], "categories": ["cs.IT", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by IEEE Transactions on Wireless Communications", "url": "http://arxiv.org/abs/2412.19470v2", "summary": "Integrated sensing and communication (ISAC) is emerging as a pivotal\ntechnology for next-generation wireless networks. However, existing ISAC\nsystems are based on fixed-position antennas (FPAs), which inevitably incur a\nloss in performance when balancing the trade-off between sensing and\ncommunication. Movable antenna (MA) technology offers promising potential to\nenhance ISAC performance by enabling flexible antenna movement. Nevertheless,\nexploiting more spatial channel variations requires larger antenna moving\nregions, which may invalidate the conventional far-field assumption for\nchannels between transceivers. Therefore, this paper utilizes the MA to enhance\nsensing and communication capabilities in near-field ISAC systems, where a\nfull-duplex base station (BS) is equipped with multiple transmit and receive\nMAs movable in large-size regions to simultaneously sense multiple targets and\nserve multiple uplink (UL) and downlink (DL) users for communication. We aim to\nmaximize the weighted sum of sensing and communication rates (WSR) by jointly\ndesigning the transmit beamformers, sensing signal covariance matrices, receive\nbeamformers, and MA positions at the BS, as well as the UL power allocation.\nThe resulting optimization problem is challenging to solve. Thus, we propose an\nefficient two-layer random position (RP) algorithm to tackle it. In addition,\nto reduce movement delay and cost, we design an antenna position matching (APM)\nalgorithm based on the greedy strategy to minimize the total MA movement\ndistance. Extensive simulation results demonstrate the substantial performance\nimprovement achieved by deploying MAs in near-field ISAC systems. Moreover, the\nresults show the effectiveness of the proposed APM algorithm in reducing the\nantenna movement distance, which is helpful for energy saving and time overhead\nreduction for MA-aided near-field ISAC systems with large moving regions.", "comment": "This paper has been accepted by IEEE Transactions on Wireless\n  Communications", "pdf_url": "http://arxiv.org/pdf/2412.19470v2", "cate": "cs.IT", "date": "2024-12-27", "updated": "2025-07-11"}
{"id": "2507.08490", "title": "Onboard Neuromorphic Split Computing via Optical Links for LEO Remote Sensing", "authors": ["Zihang Song", "Petar Popovski"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08490v1", "summary": "Low Earth orbit (LEO) satellite constellations increasingly require onboard\nintelligence under strict power and communication constraints. This paper\nproposes a neuromorphic split computing framework tailored for hierarchical LEO\nsystems, where edge satellites perform event-driven sensing using dynamic\nvision sensors (DVS) and lightweight spiking neural network (SNN) encoders,\nwhile core satellites conduct inference using a powerful SNN decoder. A learned\nspike mapping scheme enables direct transmission over optical inter-satellite\nlinks (OISLs) without conventional modulation overhead. Experimental results on\nsynthetic aerial scene classification demonstrate that the proposed\narchitecture achieves accuracy on par with modern large vision-based pipelines,\nwhile offering energy efficiency comparable to that of existing lightweight\nimplementations. These findings highlight the potential of neuromorphic\ncomputing for energy-efficient inter-satellite split computing in LEO remote\nsensing missions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08490v1", "cate": "eess.IV", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08227", "title": "RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing", "authors": ["Yang Xiao", "Ting Dang", "Rohan Kumar Das"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Submitted to APSIPA ASC 2025", "url": "http://arxiv.org/abs/2507.08227v1", "summary": "Automatic speaker verification (ASV) systems are often affected by spoofing\nattacks. Recent transformer-based models have improved anti-spoofing\nperformance by learning strong feature representations. However, these models\nusually need high computing power. To address this, we introduce RawTFNet, a\nlightweight CNN model designed for audio signals. The RawTFNet separates\nfeature processing along time and frequency dimensions, which helps to capture\nthe fine-grained details of synthetic speech. We tested RawTFNet on the\nASVspoof 2021 LA and DF evaluation datasets. The results show that RawTFNet\nreaches comparable performance to that of the state-of-the-art models, while\nalso using fewer computing resources. The code and models will be made publicly\navailable.", "comment": "Submitted to APSIPA ASC 2025", "pdf_url": "http://arxiv.org/pdf/2507.08227v1", "cate": "eess.AS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2209.01619", "title": "Interpreting systems as solving POMDPs: a step towards a formal understanding of agency", "authors": ["Martin Biehl", "Nathaniel Virgo"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      17 pages, no figures, published in Proceedings of 3rd International Workshop on Active Inference 2022", "url": "http://arxiv.org/abs/2209.01619v2", "summary": "Under what circumstances can a system be said to have beliefs and goals, and\nhow do such agency-related features relate to its physical state? Recent work\nhas proposed a notion of interpretation map, a function that maps the state of\na system to a probability distribution representing its beliefs about an\nexternal world. Such a map is not completely arbitrary, as the beliefs it\nattributes to the system must evolve over time in a manner that is consistent\nwith Bayes' theorem, and consequently the dynamics of a system constrain its\npossible interpretations. Here we build on this approach, proposing a notion of\ninterpretation not just in terms of beliefs but in terms of goals and actions.\nTo do this we make use of the existing theory of partially observable Markov\nprocesses (POMDPs): we say that a system can be interpreted as a solution to a\nPOMDP if it not only admits an interpretation map describing its beliefs about\nthe hidden state of a POMDP but also takes actions that are optimal according\nto its belief state. An agent is then a system together with an interpretation\nof this system as a POMDP solution. Although POMDPs are not the only possible\nformulation of what it means to have a goal, this nevertheless represents a\nstep towards a more general formal definition of what it means for a system to\nbe an agent.", "comment": "17 pages, no figures, published in Proceedings of 3rd International\n  Workshop on Active Inference 2022", "pdf_url": "http://arxiv.org/pdf/2209.01619v2", "cate": "cs.AI", "date": "2022-09-04", "updated": "2025-07-11"}
{"id": "2507.08015", "title": "Assessing the Capabilities and Limitations of FinGPT Model in Financial NLP Applications", "authors": ["Prudence Djagba", "Chimezie A. Odinakachukwu"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08015v1", "summary": "This work evaluates FinGPT, a financial domain-specific language model,\nacross six key natural language processing (NLP) tasks: Sentiment Analysis,\nText Classification, Named Entity Recognition, Financial Question Answering,\nText Summarization, and Stock Movement Prediction. The evaluation uses\nfinance-specific datasets to assess FinGPT's capabilities and limitations in\nreal-world financial applications. The results show that FinGPT performs\nstrongly in classification tasks such as sentiment analysis and headline\ncategorization, often achieving results comparable to GPT-4. However, its\nperformance is significantly lower in tasks that involve reasoning and\ngeneration, such as financial question answering and summarization. Comparisons\nwith GPT-4 and human benchmarks highlight notable performance gaps,\nparticularly in numerical accuracy and complex reasoning. Overall, the findings\nindicate that while FinGPT is effective for certain structured financial tasks,\nit is not yet a comprehensive solution. This research provides a useful\nbenchmark for future research and underscores the need for architectural\nimprovements and domain-specific optimization in financial language models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08015v1", "cate": "cs.CL", "date": "2025-07-06", "updated": "2025-07-06"}
{"id": "2507.08036", "title": "Barriers in Integrating Medical Visual Question Answering into Radiology Workflows: A Scoping Review and Clinicians' Insights", "authors": ["Deepali Mishra", "Chaklam Silpasuwanchai", "Ashutosh Modi", "Madhumita Sushil", "Sorayouth Chumnanvej"], "categories": ["cs.CL", "cs.CV"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages, 5 figures (1 in supplementary), 3 tables (1 in main text, 2 in supplementary). Scoping review and clinician survey", "url": "http://arxiv.org/abs/2507.08036v1", "summary": "Medical Visual Question Answering (MedVQA) is a promising tool to assist\nradiologists by automating medical image interpretation through question\nanswering. Despite advances in models and datasets, MedVQA's integration into\nclinical workflows remains limited. This study systematically reviews 68\npublications (2018-2024) and surveys 50 clinicians from India and Thailand to\nexamine MedVQA's practical utility, challenges, and gaps. Following the Arksey\nand O'Malley scoping review framework, we used a two-pronged approach: (1)\nreviewing studies to identify key concepts, advancements, and research gaps in\nradiology workflows, and (2) surveying clinicians to capture their perspectives\non MedVQA's clinical relevance. Our review reveals that nearly 60% of QA pairs\nare non-diagnostic and lack clinical relevance. Most datasets and models do not\nsupport multi-view, multi-resolution imaging, EHR integration, or domain\nknowledge, features essential for clinical diagnosis. Furthermore, there is a\nclear mismatch between current evaluation metrics and clinical needs. The\nclinician survey confirms this disconnect: only 29.8% consider MedVQA systems\nhighly useful. Key concerns include the absence of patient history or domain\nknowledge (87.2%), preference for manually curated datasets (51.1%), and the\nneed for multi-view image support (78.7%). Additionally, 66% favor models\nfocused on specific anatomical regions, and 89.4% prefer dialogue-based\ninteractive systems. While MedVQA shows strong potential, challenges such as\nlimited multimodal analysis, lack of patient context, and misaligned evaluation\napproaches must be addressed for effective clinical integration.", "comment": "29 pages, 5 figures (1 in supplementary), 3 tables (1 in main text, 2\n  in supplementary). Scoping review and clinician survey", "pdf_url": "http://arxiv.org/pdf/2507.08036v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2502.12096", "title": "Token Communications: A Unified Framework for Cross-modal Context-aware Semantic Communications", "authors": ["Li Qiao", "Mahdi Boloursaz Mashhadi", "Zhen Gao", "Rahim Tafazolli", "Mehdi Bennis", "Dusit Niyato"], "categories": ["cs.IT", "cs.CV", "cs.MM", "eess.SP", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Wireless Communications Magazine", "url": "http://arxiv.org/abs/2502.12096v3", "summary": "In this paper, we introduce token communications (TokCom), a large\nmodel-driven framework to leverage cross-modal context information in\ngenerative semantic communications (GenSC). TokCom is a new paradigm, motivated\nby the recent success of generative foundation models and multimodal large\nlanguage models (GFM/MLLMs), where the communication units are tokens, enabling\nefficient transformer-based token processing at the transmitter and receiver.\nIn this paper, we introduce the potential opportunities and challenges of\nleveraging context in GenSC, explore how to integrate GFM/MLLMs-based token\nprocessing into semantic communication systems to leverage cross-modal context\neffectively at affordable complexity, present the key principles for efficient\nTokCom at various layers in future wireless networks. In a typical image\nsemantic communication setup, we demonstrate a significant improvement of the\nbandwidth efficiency, achieved by TokCom by leveraging the context information\namong tokens. Finally, the potential research directions are identified to\nfacilitate adoption of TokCom in future wireless networks.", "comment": "Accepted at IEEE Wireless Communications Magazine", "pdf_url": "http://arxiv.org/pdf/2502.12096v3", "cate": "cs.IT", "date": "2025-02-17", "updated": "2025-07-11"}
{"id": "2507.08658", "title": "Fast and Efficient Merge of Sorted Input Lists in Hardware Using List Offset Merge Sorters", "authors": ["Robert B. Kent", "Marios S. Pattichis"], "categories": ["cs.AR", "cs.DS", "eess.IV"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08658v1", "summary": "A new set of hardware merge sort devices are introduced here, which merge\nmultiple sorted input lists into a single sorted output list in a fast and\nefficient manner. In each merge sorter, the values from the sorted input lists\nare arranged in an input 2-D setup array, but with the order of each sorted\ninput list offset from the order of each of the other sorted input lists. In\nthese new devices, called List Offset Merge Sorters (LOMS), a minimal set of\ncolumn sort stages alternating with row sort stages process the input setup\narray into a final output array, now in the defined sorted order. LOMS 2-way\nsorters, which merge 2 sorted input lists, require only 2 merge stages and are\nsignificantly faster than Kenneth Batcher's previous state-of-the-art 2-way\nmerge devices, Bitonic Merge Sorters and Odd-Even Merge Sorters. LOMS 2-way\nsorters utilize the recently-introduced Single-Stage 2-way Merge Sorters (S2MS)\nin their first stage. Both LOMS and S2MS devices can merge any mixture of input\nlist sizes, while Batcher's merge sorters are difficult to design unless the 2\ninput lists are equal, and a power-of-2. By themselves, S2MS devices are the\nfastest 2-way merge sorters when implemented in this study's target FPGA\ndevices, but they tend to use a large number of LUT resources. LOMS 2-way\ndevices use fewer resources than comparable S2MS devices, enabling some large\nLOMS devices to be implemented in a given FPGA when comparable S2MS devices\ncannot fit in that FPGA. A List Offset 2-way sorter merges 2 lists, each with\n32 values, into a sorted output list of those 64 values in 2.24 nS, a speedup\nof 2.63 versus a comparable Batcher device. A LOMS 3-way merge sorter, merging\n3 sorted input lists with 7 values, fully merges the 21 values in 3.4 nS, a\nspeedup of 1.36 versus the comparable state-of-the-art 3-way merge device.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08658v1", "cate": "cs.AR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08236", "title": "Distilling Spectrograms into Tokens: Fast and Lightweight Bioacoustic Classification for BirdCLEF+ 2025", "authors": ["Anthony Miyaguchi", "Murilo Gustineli", "Adrian Cheung"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Working note submitted to CLEF 2025 under the LifeCLEF lab", "url": "http://arxiv.org/abs/2507.08236v1", "summary": "The BirdCLEF+ 2025 challenge requires classifying 206 species, including\nbirds, mammals, insects, and amphibians, from soundscape recordings under a\nstrict 90-minute CPU-only inference deadline, making many state-of-the-art deep\nlearning approaches impractical. To address this constraint, the DS@GT BirdCLEF\nteam explored two strategies. First, we establish competitive baselines by\noptimizing pre-trained models from the Bioacoustics Model Zoo for CPU\ninference. Using TFLite, we achieved a nearly 10x inference speedup for the\nPerch model, enabling it to run in approximately 16 minutes and achieve a final\nROC-AUC score of 0.729 on the public leaderboard post-competition and 0.711 on\nthe private leaderboard. The best model from the zoo was BirdSetEfficientNetB1,\nwith a public score of 0.810 and a private score of 0.778. Second, we introduce\na novel, lightweight pipeline named Spectrogram Token Skip-Gram (STSG) that\ntreats bioacoustics as a sequence modeling task. This method converts audio\ninto discrete \"spectrogram tokens\" by clustering Mel-spectrograms using Faiss\nK-means and then learns high-quality contextual embeddings for these tokens in\nan unsupervised manner with a Word2Vec skip-gram model. For classification,\nembeddings within a 5-second window are averaged and passed to a linear model.\nWith a projected inference time of 6 minutes for a 700-minute test set, the\nSTSG approach achieved a final ROC-AUC public score of 0.559 and a private\nscore of 0.520, demonstrating the viability of fast tokenization approaches\nwith static embeddings for bioacoustic classification. Supporting code for this\npaper can be found at https://github.com/dsgt-arc/birdclef-2025.", "comment": "Working note submitted to CLEF 2025 under the LifeCLEF lab", "pdf_url": "http://arxiv.org/pdf/2507.08236v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.09918", "title": "Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces", "authors": ["DiJia Su", "Sainbayar Sukhbaatar", "Michael Rabbat", "Yuandong Tian", "Qinqing Zheng"], "categories": ["cs.AI", "cs.LG", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.09918v3", "summary": "In cognition theory, human thinking is governed by two systems: the fast and\nintuitive System 1 and the slower but more deliberative System 2. Analogously,\nLarge Language Models (LLMs) can operate in two reasoning modes: outputting\nonly the solutions (\\emph{fast mode}) or both the reasoning chain and the final\nsolution (\\emph{slow mode}). We present \\dualformer, a single Transformer model\nthat seamlessly integrates both the fast and slow reasoning modes by training\non randomized reasoning traces, where different parts of the traces are\nstrategically dropped during training. At inference time, \\dualformer can be\neasily configured to execute in either fast or slow mode, or automatically\ndecide which mode to engage (\\emph{auto mode}). It outperforms baselines in\nboth performance and computational efficiency across all three modes: (1) in\nslow mode, \\dualformer achieves $97.6\\%$ optimal rate on unseen $30 \\times 30$\nmaze tasks, surpassing the \\searchformer baseline ($93.3\\%$) trained on data\nwith complete reasoning traces, with $45.5\\%$ fewer reasoning steps; (2) in\nfast mode, \\dualformer achieves $80\\%$ optimal rate, significantly\noutperforming the Solution-Only model trained on solution-only data, which has\nan optimal rate of only $30\\%$; (3) in auto mode, \\dualformer achieves $96.6\\%$\noptimal rate with $59.9\\%$ fewer steps than \\searchformer. Moreover,\n\\dualformer produces more diverse reasoning traces than \\searchformer{}. For\nmath reasoning problems, our techniques have also achieved improved performance\nwith LLM fine-tuning, demonstrating its generalization beyond task-specific\nmodels. We open source our code at\nhttps://github.com/facebookresearch/dualformer.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.09918v3", "cate": "cs.AI", "date": "2024-10-13", "updated": "2025-07-11"}
{"id": "2507.08018", "title": "Review, Remask, Refine (R3): Process-Guided Block Diffusion for Text Generation", "authors": ["Nikita Mounier", "Parsa Idehpour"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Methods and Opportunities at Small Scale (MOSS), ICML 2025", "url": "http://arxiv.org/abs/2507.08018v1", "summary": "A key challenge for iterative text generation is enabling models to\nefficiently identify and correct their own errors. We propose Review, Remask,\nRefine (R3), a relatively simple yet elegant framework that requires no\nadditional model training and can be applied to any pre-trained masked text\ndiffusion model (e.g., LLaDA or BD3-LM). In R3, a Process Reward Model (PRM) is\nutilized for the Review of intermediate generated blocks. The framework then\ntranslates these PRM scores into a Remask strategy: the lower a block's PRM\nscore, indicating potential mistakes, the greater the proportion of tokens\nwithin that block are remasked. Finally, the model is compelled to Refine these\ntargeted segments, focusing its efforts more intensively on specific\nsub-optimal parts of past generations, leading to improved final output.", "comment": "Accepted at Methods and Opportunities at Small Scale (MOSS), ICML\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.08018v1", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-07"}
{"id": "2507.08064", "title": "PUMA: Layer-Pruned Language Model for Efficient Unified Multimodal Retrieval with Modality-Adaptive Learning", "authors": ["Yibo Lyu", "Rui Shao", "Gongwei Chen", "Yijie Zhu", "Weili Guan", "Liqiang Nie"], "categories": ["cs.MM", "cs.CV"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Accepted to ACM MM 2025", "url": "http://arxiv.org/abs/2507.08064v1", "summary": "As multimedia content expands, the demand for unified multimodal retrieval\n(UMR) in real-world applications increases. Recent work leverages multimodal\nlarge language models (MLLMs) to tackle this task. However, their large\nparameter size results in high training costs and low inference efficiency. To\naddress this, we propose PUMA: a Layer-Pruned Language Model for Efficient\nUnified Multimodal Retrieval with Modality-Adaptive Learning. Our approach\nimproves UMR from both structural and learning perspectives. (1) Structurally,\nwe propose Layer-Pruned Self-Distillation, which prunes MLLMs by keeping only\nshallow layers while distilling features from dropped deep layers as teacher\nsignals. This reduces parameters and preserves representation capability. (2)\nOn the learning side, we introduce Modality-Adaptive Contrastive Learning Loss\n(MAC-Loss), which separates in-batch negatives into harder intra-modality and\neasier inter-modality groups based on the target modality, assigning different\ntemperature strategies to enhance learning efficiency. Experiments show our\nmethod significantly reduces resource usage while maintaining strong\nperformance.", "comment": "Accepted to ACM MM 2025", "pdf_url": "http://arxiv.org/pdf/2507.08064v1", "cate": "cs.MM", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2505.08056", "title": "QubitLens: An Interactive Learning Tool for Quantum State Tomography", "authors": ["Mohammad Aamir Sohail", "Ranga Sudharshan", "S. Sandeep Pradhan", "Arvind Rao"], "categories": ["quant-ph", "eess.SP"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures", "url": "http://arxiv.org/abs/2505.08056v2", "summary": "Quantum state tomography is a fundamental task in quantum computing,\ninvolving the reconstruction of an unknown quantum state from measurement\noutcomes. Although essential, it is typically introduced at the graduate level\ndue to its reliance on advanced concepts such as the density matrix formalism,\ntensor product structures, and partial trace operations. This complexity often\ncreates a barrier for students and early learners. In this work, we introduce\nQubitLens, an interactive visualization tool designed to make quantum state\ntomography more accessible and intuitive. QubitLens leverages maximum\nlikelihood estimation (MLE), a classical statistical method, to estimate pure\nquantum states from projective measurement outcomes in the X, Y, and Z bases.\nThe tool emphasizes conceptual clarity through visual representations,\nincluding Bloch sphere plots of true and reconstructed qubit states, bar charts\ncomparing parameter estimates, and fidelity gauges that quantify reconstruction\naccuracy. QubitLens offers a hands-on approach to learning quantum tomography\nwithout requiring deep prior knowledge of density matrices or optimization\ntheory. The tool supports both single- and multi-qubit systems and is intended\nto bridge the gap between theory and practice in quantum computing education.", "comment": "7 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2505.08056v2", "cate": "quant-ph", "date": "2025-05-12", "updated": "2025-07-10"}
{"id": "2503.20653", "title": "UWarp: A Whole Slide Image Registration Pipeline to Characterize Scanner-Induced Local Domain Shift", "authors": ["Antoine Schieb", "Bilal Hadjadji", "Natalia Fernanda Valderrama", "Daniel Tshokola Mweze", "Valentin Derangère", "Laurent Arnould", "Sylvain Ladoire", "Alain Lalande", "Alessio Fiorin", "Carlos López Pablo", "Noèlia Gallardo Borràs", "Shrief Abdelazeez", "Vincenzo Della Mea", "Anna Korzynska", "Louis-Oscar Morel", "Nathan Vinçon"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2503.20653v3", "summary": "Histopathology slide digitization introduces scanner-induced domain shift\nthat can significantly impact computational pathology models based on deep\nlearning methods. In the state-of-the-art, this shift is often characterized at\na broad scale (slide-level or dataset-level) but not patch-level, which limits\nour comprehension of the impact of localized tissue characteristics on the\naccuracy of the deep learning models. To address this challenge, we present a\ndomain shift analysis framework based on UWarp, a novel registration tool\ndesigned to accurately align histological slides scanned under varying\nconditions. UWarp employs a hierarchical registration approach, combining\nglobal affine transformations with fine-grained local corrections to achieve\nrobust tissue patch alignment. We evaluate UWarp using two private datasets,\nCypathLung and BosomShieldBreast, containing whole slide images scanned by\nmultiple devices. Our experiments demonstrate that UWarp outperforms existing\nopen-source registration methods, achieving a median target registration error\n(TRE) of less than 4 pixels (<1 micrometer at 40x magnification) while\nsignificantly reducing computational time. Additionally, we apply UWarp to\ncharacterize scanner-induced local domain shift in the predictions of\nBreast-NEOprAIdict, a deep learning model for breast cancer pathological\nresponse prediction. We find that prediction variability is strongly correlated\nwith tissue density on a given patch. Our findings highlight the importance of\nlocalized domain shift analysis and suggest that UWarp can serve as a valuable\ntool for improving model robustness and domain adaptation strategies in\ncomputational pathology.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2503.20653v3", "cate": "eess.IV", "date": "2025-03-26", "updated": "2025-07-10"}
{"id": "2507.08319", "title": "Active Learning for Text-to-Speech Synthesis with Informative Sample Collection", "authors": ["Kentaro Seki", "Shinnosuke Takamichi", "Takaaki Saeki", "Hiroshi Saruwatari"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08319v1", "summary": "The construction of high-quality datasets is a cornerstone of modern\ntext-to-speech (TTS) systems. However, the increasing scale of available data\nposes significant challenges, including storage constraints. To address these\nissues, we propose a TTS corpus construction method based on active learning.\nUnlike traditional feed-forward and model-agnostic corpus construction\napproaches, our method iteratively alternates between data collection and model\ntraining, thereby focusing on acquiring data that is more informative for model\nimprovement. This approach enables the construction of a data-efficient corpus.\nExperimental results demonstrate that the corpus constructed using our method\nenables higher-quality speech synthesis than corpora of the same size.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08319v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.00557", "title": "A Hybrid SMT-NRA Solver: Integrating 2D Cell-Jump-Based Local Search, MCSAT and OpenCAD", "authors": ["Tianyi Ding", "Haokun Li", "Xinpeng Ni", "Bican Xia", "Tianqi Zhao"], "categories": ["cs.AI", "cs.LO", "cs.SC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00557v2", "summary": "In this paper, we propose a hybrid framework for Satisfiability Modulo the\nTheory of Nonlinear Real Arithmetic (SMT-NRA for short). First, we introduce a\ntwo-dimensional cell-jump move, called \\emph{$2d$-cell-jump}, generalizing the\nkey operation, cell-jump, of the local search method for SMT-NRA. Then, we\npropose an extended local search framework, named \\emph{$2d$-LS} (following the\nlocal search framework, LS, for SMT-NRA), integrating the model constructing\nsatisfiability calculus (MCSAT) framework to improve search efficiency. To\nfurther improve the efficiency of MCSAT, we implement a recently proposed\ntechnique called \\emph{sample-cell projection operator} for MCSAT, which is\nwell suited for CDCL-style search in the real domain and helps guide the search\naway from conflicting states. Finally, we present a hybrid framework for\nSMT-NRA integrating MCSAT, $2d$-LS and OpenCAD, to improve search efficiency\nthrough information exchange. The experimental results demonstrate improvements\nin local search performance, highlighting the effectiveness of the proposed\nmethods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00557v2", "cate": "cs.AI", "date": "2025-07-01", "updated": "2025-07-11"}
{"id": "2507.08106", "title": "Predicting Flow Dynamics using Diffusion Models", "authors": ["Yannick Gachnang", "Vismay Churiwala"], "categories": ["physics.flu-dyn", "cs.LG"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08106v1", "summary": "In this work, we aimed to replicate and extend the results presented in the\nDiffFluid paper[1]. The DiffFluid model showed that diffusion models combined\nwith Transformers are capable of predicting fluid dynamics. It uses a denoising\ndiffusion probabilistic model (DDPM) framework to tackle Navier-Stokes and\nDarcy flow equations. Our goal was to validate the reproducibility of the\nmethods in the DiffFluid paper while testing its viability for other simulation\ntypes, particularly the Lattice Boltzmann method. Despite our computational\nlimitations and time constraints, this work provides evidence of the\nflexibility and potential of the model as a general-purpose solver for fluid\ndynamics. Our results show both the potential and challenges of applying\ndiffusion models to complex fluid dynamics problems. This work highlights the\nopportunities for future research in optimizing the computational efficiency\nand scaling such models in broader domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08106v1", "cate": "physics.flu-dyn", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08285", "title": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields", "authors": ["Gwanhyeong Koo", "Sunjae Yoon", "Younghwan Lee", "Ji Woo Hong", "Chang D. Yoo"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      ICML 2025 Spotlight", "url": "http://arxiv.org/abs/2507.08285v1", "summary": "Drag-based editing allows precise object manipulation through point-based\ncontrol, offering user convenience. However, current methods often suffer from\na geometric inconsistency problem by focusing exclusively on matching\nuser-defined points, neglecting the broader geometry and leading to artifacts\nor unstable edits. We propose FlowDrag, which leverages geometric information\nfor more accurate and coherent transformations. Our approach constructs a 3D\nmesh from the image, using an energy function to guide mesh deformation based\non user-defined drag points. The resulting mesh displacements are projected\ninto 2D and incorporated into a UNet denoising process, enabling precise\nhandle-to-target point alignment while preserving structural integrity.\nAdditionally, existing drag-editing benchmarks provide no ground truth, making\nit difficult to assess how accurately the edits match the intended\ntransformations. To address this, we present VFD (VidFrameDrag) benchmark\ndataset, which provides ground-truth frames using consecutive shots in a video\ndataset. FlowDrag outperforms existing drag-based editing methods on both VFD\nBench and DragBench.", "comment": "ICML 2025 Spotlight", "pdf_url": "http://arxiv.org/pdf/2507.08285v1", "cate": "cs.GR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.05312", "title": "Introducing Image-Space Preconditioning in the Variational Formulation of MRI Reconstructions", "authors": ["Bastien Milani", "Jean-Baptist Ledoux", "Berk Can Acikgoz", "Xavier Richard"], "categories": ["physics.med-ph", "eess.SP"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      48 pages, 7 figures, 3 latex graphics", "url": "http://arxiv.org/abs/2507.05312v2", "summary": "The aim of the present article is to enrich the comprehension of iterative\nmagnetic resonance imaging (MRI) reconstructions, including compressed sensing\n(CS) and iterative deep learning (DL) reconstructions, by describing them in\nthe general framework of finite-dimensional inner-product spaces. In\nparticular, we show that image-space preconditioning (ISP) and data-space\npreconditioning (DSP) can be formulated as non-conventional inner-products. The\nmain gain of our reformulation is an embedding of ISP in the variational\nformulation of the MRI reconstruction problem (in an algorithm-independent way)\nwhich allows in principle to naturally and systematically propagate ISP in all\niterative reconstructions, including many iterative DL and CS reconstructions\nwhere preconditioning is lacking. The way in which we apply linear algebraic\ntools to MRI reconstructions as presented in this article is a novelty.\n  A secondary aim of our article is to offer a certain didactic material to\nscientists who are new in the field of MRI reconstruction. Since we explore\nhere some mathematical concepts of reconstruction, we take that opportunity to\nrecall some principles that may be understood for experts, but which may be\nhard to find in the literature for beginners. In fact, the description of many\nmathematical tools of MRI reconstruction is fragmented in the literature or\nsometimes missing because considered as a general knowledge. Further, some of\nthose concepts can be found in mathematic manuals, but not in a form that is\noriented toward MRI. For example, we think of the conjugate gradient descent,\nthe notion of derivative with respect to non-conventional inner products, or\nsimply the notion of adjoint. The authors believe therefore that it is\nbeneficial for their field of research to dedicate some space to such a\ndidactic material.", "comment": "48 pages, 7 figures, 3 latex graphics", "pdf_url": "http://arxiv.org/pdf/2507.05312v2", "cate": "physics.med-ph", "date": "2025-07-07", "updated": "2025-07-11"}
{"id": "2410.03008", "title": "Ultrasound Autofocusing: Common Midpoint Phase Error Optimization via Differentiable Beamforming", "authors": ["Walter Simson", "Louise Zhuang", "Benjamin N. Frey", "Sergio J. Sanabria", "Jeremy J. Dahl", "Dongwoon Hyun"], "categories": ["physics.med-ph", "eess.IV"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.03008v2", "summary": "In ultrasound imaging, propagation of an acoustic wavefront through\nheterogeneous media causes phase aberrations that degrade the coherence of the\nreflected wavefront, leading to reduced image resolution and contrast. Adaptive\nimaging techniques attempt to correct this phase aberration and restore\ncoherence, leading to improved focusing of the image. We propose an\nautofocusing paradigm for aberration correction in ultrasound imaging by\nfitting an acoustic velocity field to pressure measurements, via optimization\nof the common midpoint phase error (CMPE), using a straight-ray wave\npropagation model for beamforming in diffusely scattering media. We show that\nCMPE induced by heterogeneous acoustic velocity is a robust measure of phase\naberration that can be used for acoustic autofocusing. CMPE is optimized\niteratively using a differentiable beamforming approach to simultaneously\nimprove the image focus while estimating the acoustic velocity field of the\ninterrogated medium. The approach relies solely on wavefield measurements using\na straight-ray integral solution of the two-way time-of-flight without explicit\nnumerical time-stepping models of wave propagation. We demonstrate method\nperformance through in silico simulations, in vitro phantom measurements, and\nin vivo mammalian models, showing practical applications in distributed\naberration quantification, correction, and velocity estimation for medical\nultrasound autofocusing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.03008v2", "cate": "physics.med-ph", "date": "2024-10-03", "updated": "2025-07-11"}
{"id": "2507.08412", "title": "Enforcing Speech Content Privacy in Environmental Sound Recordings using Segment-wise Waveform Reversal", "authors": ["Modan Tailleur", "Mathieu Lagrange", "Pierre Aumond", "Vincent Tourre"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08412v1", "summary": "Environmental sound recordings often contain intelligible speech, raising\nprivacy concerns that limit analysis, sharing and reuse of data. In this paper,\nwe introduce a method that renders speech unintelligible while preserving both\nthe integrity of the acoustic scene, and the overall audio quality. Our\napproach involves reversing waveform segments to distort speech content. This\nprocess is enhanced through a voice activity detection and speech separation\npipeline, which allows for more precise targeting of speech.\n  In order to demonstrate the effectivness of the proposed approach, we\nconsider a three-part evaluation protocol that assesses: 1) speech\nintelligibility using Word Error Rate (WER), 2) sound sources detectability\nusing Sound source Classification Accuracy-Drop (SCAD) from a widely used\npre-trained model, and 3) audio quality using the Fr\\'echet Audio Distance\n(FAD), computed with our reference dataset that contains unaltered speech.\nExperiments on this simulated evaluation dataset, which consists of linear\nmixtures of speech and environmental sound scenes, show that our method\nachieves satisfactory speech intelligibility reduction (97.9% WER), minimal\ndegradation of the sound sources detectability (2.7% SCAD), and high perceptual\nquality (FAD of 1.40). An ablation study further highlights the contribution of\neach component of the pipeline. We also show that incorporating random splicing\nto our speech content privacy enforcement method can enhance the algorithm's\nrobustness to attempt to recover the clean speech, at a slight cost of audio\nquality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08412v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.03190", "title": "Discovering Algorithms with Computational Language Processing", "authors": ["Theo Bourdais", "Abeynaya Gnanasekaran", "Houman Owhadi", "Tuhin Sahai"], "categories": ["cs.AI", "cs.DS", "cs.LG", "es: 68T05, 68T20, 68Q12, 90C27", "I.2.6; I.2.8; F.2.2; F.1.2; G.2.1"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2507.03190v2", "summary": "Algorithms are the engine for reproducible problem-solving. We present a\nframework automating algorithm discovery by conceptualizing them as sequences\nof operations, represented as tokens. These computational tokens are chained\nusing a grammar, enabling the formation of increasingly sophisticated\nprocedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement\nlearning (RL) explores token chaining and drives the creation of new tokens.\nThis methodology rediscovers, improves, and generates new algorithms that\nsubstantially outperform existing methods for strongly NP-hard combinatorial\noptimization problems and foundational quantum computing approaches such as\nGrover's and Quantum Approximate Optimization Algorithm. Operating at the\ncomputational rather than code-generation level, our framework produces\nalgorithms that can be tailored specifically to problem instances, not merely\nclasses.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2507.03190v2", "cate": "cs.AI", "date": "2025-07-03", "updated": "2025-07-11"}
{"id": "2507.08108", "title": "Mallows Model with Learned Distance Metrics: Sampling and Maximum Likelihood Estimation", "authors": ["Yeganeh Alimohammadi", "Kiana Asgari"], "categories": ["stat.ML", "cs.DS", "cs.LG", "math.PR", "math.ST", "stat.TH", "62F10, 62H20, 68W20, 60C05", "F.2.2; G.3; I.2.6; H.2.8"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08108v1", "summary": "\\textit{Mallows model} is a widely-used probabilistic framework for learning\nfrom ranking data, with applications ranging from recommendation systems and\nvoting to aligning language models with human\npreferences~\\cite{chen2024mallows, kleinberg2021algorithmic,\nrafailov2024direct}. Under this model, observed rankings are noisy\nperturbations of a central ranking $\\sigma$, with likelihood decaying\nexponentially in distance from $\\sigma$, i.e, $P (\\pi) \\propto \\exp\\big(-\\beta\n\\cdot d(\\pi, \\sigma)\\big),$ where $\\beta > 0$ controls dispersion and $d$ is a\ndistance function.\n  Existing methods mainly focus on fixed distances (such as Kendall's $\\tau$\ndistance), with no principled approach to learning the distance metric directly\nfrom data. In practice, however, rankings naturally vary by context; for\ninstance, in some sports we regularly see long-range swaps (a low-rank team\nbeating a high-rank one), while in others such events are rare. Motivated by\nthis, we propose a generalization of Mallows model that learns the distance\nmetric directly from data. Specifically, we focus on $L_\\alpha$ distances:\n$d_\\alpha(\\pi,\\sigma):=\\sum_{i=1} |\\pi(i)-\\sigma(i)|^\\alpha$.\n  For any $\\alpha\\geq 1$ and $\\beta>0$, we develop a Fully Polynomial-Time\nApproximation Scheme (FPTAS) to efficiently generate samples that are\n$\\epsilon$- close (in total variation distance) to the true distribution. Even\nin the special cases of $L_1$ and $L_2$, this generalizes prior results that\nrequired vanishing dispersion ($\\beta\\to0$). Using this sampling algorithm, we\npropose an efficient Maximum Likelihood Estimation (MLE) algorithm that jointly\nestimates the central ranking, the dispersion parameter, and the optimal\ndistance metric. We prove strong consistency results for our estimators (for\nany values of $\\alpha$ and $\\beta$), and we validate our approach empirically\nusing datasets from sports rankings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08108v1", "cate": "stat.ML", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08513", "title": "Advancing Multimodal LLMs by Large-Scale 3D Visual Instruction Dataset Generation", "authors": ["Liu He", "Xiao Zeng", "Yizhi Song", "Albert Y. C. Chen", "Lu Xia", "Shashwat Verma", "Sankalp Dayal", "Min Sun", "Cheng-Hao Kuo", "Daniel Aliaga"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08513v1", "summary": "Multimodal Large Language Models (MLLMs) struggle with accurately capturing\ncamera-object relations, especially for object orientation, camera viewpoint,\nand camera shots. This stems from the fact that existing MLLMs are trained on\nimages with limited diverse camera-object relations and corresponding textual\ndescriptions. To address this, we propose a synthetic generation pipeline to\ncreate large-scale 3D visual instruction datasets. Our framework takes 3D\nassets as input and uses rendering and diffusion-based image generation models\nto create photorealistic images preserving precise camera-object relations.\nAdditionally, large language models (LLMs) are used to generate text prompts\nfor guiding visual instruction tuning and controlling image generation. We\ncreate Ultimate3D, a dataset of 240K VQAs with precise camera-object\nannotations, and corresponding benchmark. MLLMs fine-tuned on our proposed\ndataset outperform commercial models by a large margin, achieving an average\naccuracy improvement of 33.4% on camera-object relation recognition tasks. Our\ncode, dataset, and benchmark will contribute to broad MLLM applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08513v1", "cate": "cs.GR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.08229", "title": "Improvement of Spiking Neural Network with Bit Planes and Color Models", "authors": ["Nhan T. Luu", "Duong T. Luu", "Nam N. Pham", "Thang C. Truong"], "categories": ["cs.CV", "cs.NE", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      2024 IEEE 16th International Conference on Computational Intelligence and Communication Networks (CICN)", "url": "http://arxiv.org/abs/2410.08229v3", "summary": "Spiking neural network (SNN) has emerged as a promising paradigm in\ncomputational neuroscience and artificial intelligence, offering advantages\nsuch as low energy consumption and small memory footprint. However, their\npractical adoption is constrained by several challenges, prominently among them\nbeing performance optimization. In this study, we present a novel approach to\nenhance the performance of SNN for images through a new coding method that\nexploits bit plane representation. Our proposed technique is designed to\nimprove the accuracy of SNN without increasing model size. Also, we investigate\nthe impacts of color models of the proposed coding process. Through extensive\nexperimental validation, we demonstrate the effectiveness of our coding\nstrategy in achieving performance gain across multiple datasets. To the best of\nour knowledge, this is the first research that considers bit planes and color\nmodels in the context of SNN. By leveraging the unique characteristics of bit\nplanes, we hope to unlock new potentials in SNNs performance, potentially\npaving the way for more efficient and effective SNNs models in future\nresearches and applications.", "comment": "2024 IEEE 16th International Conference on Computational Intelligence\n  and Communication Networks (CICN)", "pdf_url": "http://arxiv.org/pdf/2410.08229v3", "cate": "cs.CV", "date": "2024-09-28", "updated": "2025-07-11"}
{"id": "2507.08626", "title": "Phoneme-Level Analysis for Person-of-Interest Speech Deepfake Detection", "authors": ["Davide Salvi", "Viola Negroni", "Sara Mandelli", "Paolo Bestagini", "Stefano Tubaro"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV Workshop - Authenticity & Provenance in the age of Generative AI", "url": "http://arxiv.org/abs/2507.08626v1", "summary": "Recent advances in generative AI have made the creation of speech deepfakes\nwidely accessible, posing serious challenges to digital trust. To counter this,\nvarious speech deepfake detection strategies have been proposed, including\nPerson-of-Interest (POI) approaches, which focus on identifying impersonations\nof specific individuals by modeling and analyzing their unique vocal traits.\nDespite their excellent performance, the existing methods offer limited\ngranularity and lack interpretability. In this work, we propose a POI-based\nspeech deepfake detection method that operates at the phoneme level. Our\napproach decomposes reference audio into phonemes to construct a detailed\nspeaker profile. In inference, phonemes from a test sample are individually\ncompared against this profile, enabling fine-grained detection of synthetic\nartifacts. The proposed method achieves comparable accuracy to traditional\napproaches while offering superior robustness and interpretability, key aspects\nin multimedia forensics. By focusing on phoneme analysis, this work explores a\nnovel direction for explainable, speaker-centric deepfake detection.", "comment": "Accepted at ICCV Workshop - Authenticity & Provenance in the age of\n  Generative AI", "pdf_url": "http://arxiv.org/pdf/2507.08626v1", "cate": "cs.SD", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07445", "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "authors": ["Weihao Tan", "Changjiu Jiang", "Yu Duan", "Mingcong Lei", "Jiageng Li", "Yitian Hong", "Xinrun Wang", "Bo An"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Project website: this https URL", "url": "http://arxiv.org/abs/2507.07445v2", "summary": "Autonomous agents navigating human society must master both production\nactivities and social interactions, yet existing benchmarks rarely evaluate\nthese skills simultaneously. To bridge this gap, we introduce StarDojo, a novel\nbenchmark based on Stardew Valley, designed to assess AI agents in open-ended\nproduction-living simulations. In StarDojo, agents are tasked to perform\nessential livelihood activities such as farming and crafting, while\nsimultaneously engaging in social interactions to establish relationships\nwithin a vibrant community. StarDojo features 1,000 meticulously curated tasks\nacross five key domains: farming, crafting, exploration, combat, and social\ninteractions. Additionally, we provide a compact subset of 100 representative\ntasks for efficient model evaluation. The benchmark offers a unified,\nuser-friendly interface that eliminates the need for keyboard and mouse\ncontrol, supports all major operating systems, and enables the parallel\nexecution of multiple environment instances, making it particularly well-suited\nfor evaluating the most capable foundation agents, powered by multimodal large\nlanguage models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents\ndemonstrate substantial limitations, with the best-performing model, GPT-4.1,\nachieving only a 12.7% success rate, primarily due to challenges in visual\nunderstanding, multimodal reasoning and low-level manipulation. As a\nuser-friendly environment and benchmark, StarDojo aims to facilitate further\nresearch towards robust, open-ended agents in complex production-living\nenvironments.", "comment": "Project website: https://weihaotan.github.io/StarDojo", "pdf_url": "http://arxiv.org/pdf/2507.07445v2", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08150", "title": "CLEAR: Calibrated Learning for Epistemic and Aleatoric Risk", "authors": ["Ilia Azizi", "Juraj Bodik", "Jakob Heiss", "Bin Yu"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Code: this https URL", "url": "http://arxiv.org/abs/2507.08150v1", "summary": "Accurate uncertainty quantification is critical for reliable predictive\nmodeling, especially in regression tasks. Existing methods typically address\neither aleatoric uncertainty from measurement noise or epistemic uncertainty\nfrom limited data, but not necessarily both in a balanced way. We propose\nCLEAR, a calibration method with two distinct parameters, $\\gamma_1$ and\n$\\gamma_2$, to combine the two uncertainty components for improved conditional\ncoverage. CLEAR is compatible with any pair of aleatoric and epistemic\nestimators; we show how it can be used with (i) quantile regression for\naleatoric uncertainty and (ii) ensembles drawn from the\nPredictability-Computability-Stability (PCS) framework for epistemic\nuncertainty. Across 17 diverse real-world datasets, CLEAR achieves an average\nimprovement of 28.2% and 17.4% in the interval width compared to the two\nindividually calibrated baselines while maintaining nominal coverage. This\nimprovement can be particularly evident in scenarios dominated by either high\nepistemic or high aleatoric uncertainty.", "comment": "Code: https://github.com/Unco3892/clear", "pdf_url": "http://arxiv.org/pdf/2507.08150v1", "cate": "stat.ML", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08590", "title": "Visual Semantic Description Generation with MLLMs for Image-Text Matching", "authors": ["Junyu Chen", "Yihua Gao", "Mingyong Li"], "categories": ["cs.MM", "cs.CV"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Accepted by ICME2025 oral", "url": "http://arxiv.org/abs/2507.08590v1", "summary": "Image-text matching (ITM) aims to address the fundamental challenge of\naligning visual and textual modalities, which inherently differ in their\nrepresentations, continuous, high-dimensional image features vs. discrete,\nstructured text. We propose a novel framework that bridges the modality gap by\nleveraging multimodal large language models (MLLMs) as visual semantic parsers.\nBy generating rich Visual Semantic Descriptions (VSD), MLLMs provide semantic\nanchor that facilitate cross-modal alignment. Our approach combines: (1)\nInstance-level alignment by fusing visual features with VSD to enhance the\nlinguistic expressiveness of image representations, and (2) Prototype-level\nalignment through VSD clustering to ensure category-level consistency. These\nmodules can be seamlessly integrated into existing ITM models. Extensive\nexperiments on Flickr30K and MSCOCO demonstrate substantial performance\nimprovements. The approach also exhibits remarkable zero-shot generalization to\ncross-domain tasks, including news and remote sensing ITM. The code and model\ncheckpoints are available at https://github.com/Image-Text-Matching/VSD.", "comment": "Accepted by ICME2025 oral", "pdf_url": "http://arxiv.org/pdf/2507.08590v1", "cate": "cs.MM", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.22511", "title": "Lighting the Night with Generative Artificial Intelligence", "authors": ["Tingting Zhou", "Feng Zhang", "Haoyang Fu", "Baoxiang Pan", "Renhe Zhang", "Feng Lu", "Zhixin Yang"], "categories": ["cs.CV", "cs.AI", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Title corrected (Lightning to Lighting); terminology updated (retrieval to generative)", "url": "http://arxiv.org/abs/2506.22511v2", "summary": "The visible light reflectance data from geostationary satellites is crucial\nfor meteorological observations and plays an important role in weather\nmonitoring and forecasting. However, due to the lack of visible light at night,\nit is impossible to conduct continuous all-day weather observations using\nvisible light reflectance data. This study pioneers the use of generative\ndiffusion models to address this limitation. Based on the multi-band thermal\ninfrared brightness temperature data from the Advanced Geostationary Radiation\nImager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we\ndeveloped a high-precision visible light reflectance generative model, called\nReflectance Diffusion (RefDiff), which enables 0.47~\\mu\\mathrm{m},\n0.65~\\mu\\mathrm{m}, and 0.825~\\mu\\mathrm{m} bands visible light reflectance\ngeneration at night. Compared to the classical models, RefDiff not only\nsignificantly improves accuracy through ensemble averaging but also provides\nuncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,\nwith particularly significant improvements in areas with complex cloud\nstructures and thick clouds. The model's nighttime generation capability was\nvalidated using VIIRS nighttime product, demonstrating comparable performance\nto its daytime counterpart. In summary, this research has made substantial\nprogress in the ability to generate visible light reflectance at night, with\nthe potential to expand the application of nighttime visible light data.", "comment": "Title corrected (Lightning to Lighting); terminology updated\n  (retrieval to generative)", "pdf_url": "http://arxiv.org/pdf/2506.22511v2", "cate": "cs.CV", "date": "2025-06-26", "updated": "2025-07-11"}
{"id": "2409.13216", "title": "MuCodec: Ultra Low-Bitrate Music Codec", "authors": ["Yaoxun Xu", "Hangting Chen", "Jianwei Yu", "Wei Tan", "Rongzhi Gu", "Shun Lei", "Zhiwei Lin", "Zhiyong Wu"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.13216v3", "summary": "Music codecs are a vital aspect of audio codec research, and ultra\nlow-bitrate compression holds significant importance for music transmission and\ngeneration. Due to the complexity of music backgrounds and the richness of\nvocals, solely relying on modeling semantic or acoustic information cannot\neffectively reconstruct music with both vocals and backgrounds. To address this\nissue, we propose MuCodec, specifically targeting music compression and\nreconstruction tasks at ultra low bitrates. MuCodec employs MuEncoder to\nextract both acoustic and semantic features, discretizes them with RVQ, and\nobtains Mel-VAE features via flow-matching. The music is then reconstructed\nusing a pre-trained MEL-VAE decoder and HiFi-GAN. MuCodec can reconstruct\nhigh-fidelity music at ultra low (0.35kbps) or high bitrates (1.35kbps),\nachieving the best results to date in both subjective and objective metrics.\nCode and Demo: https://xuyaoxun.github.io/MuCodec_demo/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.13216v3", "cate": "cs.SD", "date": "2024-09-20", "updated": "2025-07-11"}
{"id": "2507.07787", "title": "Measuring AI Alignment with Human Flourishing", "authors": ["Elizabeth Hilliard", "Akshaya Jagadeesh", "Alex Cook", "Steele Billings", "Nicholas Skytland", "Alicia Llewellyn", "Jackson Paull", "Nathan Paull", "Nolan Kurylo", "Keatra Nesbitt", "Robert Gruenewald", "Anthony Jantzi", "Omar Chavez"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07787v2", "summary": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel\nevaluation framework that assesses AI alignment with human flourishing across\nseven dimensions: Character and Virtue, Close Social Relationships, Happiness\nand Life Satisfaction, Meaning and Purpose, Mental and Physical Health,\nFinancial and Material Stability, and Faith and Spirituality. Unlike\ntraditional benchmarks that focus on technical capabilities or harm prevention,\nthe FAI Benchmark measures AI performance on how effectively models contribute\nto the flourishing of a person across these dimensions. The benchmark evaluates\nhow effectively LLM AI systems align with current research models of holistic\nhuman well-being through a comprehensive methodology that incorporates 1,229\nobjective and subjective questions. Using specialized judge Large Language\nModels (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs\ngeometric mean scoring to ensure balanced performance across all flourishing\ndimensions. Initial testing of 28 leading language models reveals that while\nsome models approach holistic alignment (with the highest-scoring models\nachieving 72/100), none are acceptably aligned across all dimensions,\nparticularly in Faith and Spirituality, Character and Virtue, and Meaning and\nPurpose. This research establishes a framework for developing AI systems that\nactively support human flourishing rather than merely avoiding harm, offering\nsignificant implications for AI development, ethics, and evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07787v2", "cate": "cs.AI", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08183", "title": "Parametrized Quantum Circuit Learning for Quantum Chemical Applications", "authors": ["Grier M. Jones", "Viki Kumar Prasad", "Ulrich Fekl", "Hans-Arno Jacobsen"], "categories": ["quant-ph", "cs.LG", "physics.chem-ph"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08183v1", "summary": "In the field of quantum machine learning (QML), parametrized quantum circuits\n(PQCs) -- constructed using a combination of fixed and tunable quantum gates --\nprovide a promising hybrid framework for tackling complex machine learning\nproblems. Despite numerous proposed applications, there remains limited\nexploration of datasets relevant to quantum chemistry. In this study, we\ninvestigate the potential benefits and limitations of PQCs on two chemically\nmeaningful datasets: (1) the BSE49 dataset, containing bond separation energies\nfor 49 different classes of chemical bonds, and (2) a dataset of water\nconformations, where coupled-cluster singles and doubles (CCSD) wavefunctions\nare predicted from lower-level electronic structure methods using the\ndata-driven coupled-cluster (DDCC) approach. We construct a comprehensive set\nof 168 PQCs by combining 14 data encoding strategies with 12 variational\nans{\\\"a}tze, and evaluate their performance on circuits with 5 and 16 qubits.\nOur initial analysis examines the impact of circuit structure on model\nperformance using state-vector simulations. We then explore how circuit depth\nand training set size influence model performance. Finally, we assess the\nperformance of the best-performing PQCs on current quantum hardware, using both\nnoisy simulations (\"fake\" backends) and real quantum devices. Our findings\nunderscore the challenges of applying PQCs to chemically relevant problems that\nare straightforward for classical machine learning methods but remain\nnon-trivial for quantum approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08183v1", "cate": "quant-ph", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2306.03538", "title": "SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving", "authors": ["Honghao Fu", "Yongli Gu", "Yidong Yan", "Yilang Shen", "Yiwen Wu", "Libo Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.03538v5", "summary": "With the advancement of vision-based autonomous driving technology,\npedestrian detection have become an important component for improving traffic\nsafety and driving system robustness. Nevertheless, in complex traffic\nscenarios, conventional pose estimation approaches frequently fail to\naccurately reconstruct occluded keypoints, primarily due to obstructions caused\nby vehicles, vegetation, or architectural elements. To address this issue, we\npropose a novel real-time occluded pedestrian pose completion framework termed\nSeparation and Dimensionality Reduction-based Generative Adversarial Imputation\nNets (SDR-GAIN). Unlike previous approaches that train visual models to\ndistinguish occlusion patterns, SDR-GAIN aims to learn human pose directly from\nthe numerical distribution of keypoint coordinates and interpolate missing\npositions. It employs a self-supervised adversarial learning paradigm to train\nlightweight generators with residual structures for the imputation of missing\npose keypoints. Additionally, it integrates multiple pose standardization\ntechniques to alleviate the difficulty of the learning process. Experiments\nconducted on the COCO and JAAD datasets demonstrate that SDR-GAIN surpasses\nconventional machine learning and Transformer-based missing data interpolation\nalgorithms in accurately recovering occluded pedestrian keypoints, while\nsimultaneously achieving microsecond-level real-time inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.03538v5", "cate": "cs.CV", "date": "2023-06-06", "updated": "2025-07-11"}
{"id": "2410.05739", "title": "End-to-end multi-channel speaker extraction and binaural speech synthesis", "authors": ["Cheng Chi", "Xiaoyu Li", "Yuxuan Ke", "Qunping Ni", "Yao Ge", "Xiaodong Li", "Chengshi Zheng"], "categories": ["cs.SD", "cs.AI", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.05739v2", "summary": "Speech clarity and spatial audio immersion are the two most critical factors\nin enhancing remote conferencing experiences. Existing methods are often\nlimited: either due to the lack of spatial information when using only one\nmicrophone, or because their performance is highly dependent on the accuracy of\ndirection-of-arrival estimation when using microphone array. To overcome this\nissue, we introduce an end-to-end deep learning framework that has the capacity\nof mapping multi-channel noisy and reverberant signals to clean and spatialized\nbinaural speech directly. This framework unifies source extraction, noise\nsuppression, and binaural rendering into one network. In this framework, a\nnovel magnitude-weighted interaural level difference loss function is proposed\nthat aims to improve the accuracy of spatial rendering. Extensive evaluations\nshow that our method outperforms established baselines in terms of both speech\nquality and spatial fidelity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.05739v2", "cate": "cs.SD", "date": "2024-10-08", "updated": "2025-07-11"}
{"id": "2401.02984", "title": "Large Language Models in Mental Health Care: a Scoping Review", "authors": ["Yining Hua", "Fenglin Liu", "Kailai Yang", "Zehan Li", "Hongbin Na", "Yi-han Sheu", "Peilin Zhou", "Lauren V. Moran", "Sophia Ananiadou", "David A. Clifton", "Andrew Beam", "John Torous"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.02984v3", "summary": "Objectieve:This review aims to deliver a comprehensive analysis of Large\nLanguage Models (LLMs) utilization in mental health care, evaluating their\neffectiveness, identifying challenges, and exploring their potential for future\napplication. Materials and Methods: A systematic search was performed across\nmultiple databases including PubMed, Web of Science, Google Scholar, arXiv,\nmedRxiv, and PsyArXiv in November 2023. The review includes all types of\noriginal research, regardless of peer-review status, published or disseminated\nbetween October 1, 2019, and December 2, 2023. Studies were included without\nlanguage restrictions if they employed LLMs developed after T5 and directly\ninvestigated research questions within mental health care settings. Results:\nOut of an initial 313 articles, 34 were selected based on their relevance to\nLLMs applications in mental health care and the rigor of their reported\noutcomes. The review identified various LLMs applications in mental health\ncare, including diagnostics, therapy, and enhancing patient engagement. Key\nchallenges highlighted were related to data availability and reliability, the\nnuanced handling of mental states, and effective evaluation methods. While LLMs\nshowed promise in improving accuracy and accessibility, significant gaps in\nclinical applicability and ethical considerations were noted. Conclusion: LLMs\nhold substantial promise for enhancing mental health care. For their full\npotential to be realized, emphasis must be placed on developing robust\ndatasets, development and evaluation frameworks, ethical guidelines, and\ninterdisciplinary collaborations to address current limitations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.02984v3", "cate": "cs.CL", "date": "2024-01-01", "updated": "2025-07-11"}
{"id": "2507.08189", "title": "Robust Semi-Supervised CT Radiomics for Lung Cancer Prognosis: Cost-Effective Learning with Limited Labels and SHAP Interpretation", "authors": ["Mohammad R. Salmanpour", "Amir Hossein Pouria", "Sonia Falahati", "Shahram Taeb", "Somayeh Sadat Mehrnia", "Ali Fathi Jouzdani", "Mehrdad Oveisi", "Ilker Hacihaliloglu", "Arman Rahmim"], "categories": ["physics.med-ph", "cs.LG", "F.2.2, I.2.7"], "primary_category": "Subjects:       Medical Physics (physics.med-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures", "url": "http://arxiv.org/abs/2507.08189v1", "summary": "Background: CT imaging is vital for lung cancer management, offering detailed\nvisualization for AI-based prognosis. However, supervised learning SL models\nrequire large labeled datasets, limiting their real-world application in\nsettings with scarce annotations.\n  Methods: We analyzed CT scans from 977 patients across 12 datasets extracting\n1218 radiomics features using Laplacian of Gaussian and wavelet filters via\nPyRadiomics Dimensionality reduction was applied with 56 feature selection and\nextraction algorithms and 27 classifiers were benchmarked A semi supervised\nlearning SSL framework with pseudo labeling utilized 478 unlabeled and 499\nlabeled cases Model sensitivity was tested in three scenarios varying labeled\ndata in SL increasing unlabeled data in SSL and scaling both from 10 percent to\n100 percent SHAP analysis was used to interpret predictions Cross validation\nand external testing in two cohorts were performed.\n  Results: SSL outperformed SL, improving overall survival prediction by up to\n17 percent. The top SSL model, Random Forest plus XGBoost classifier, achieved\n0.90 accuracy in cross-validation and 0.88 externally. SHAP analysis revealed\nenhanced feature discriminability in both SSL and SL, especially for Class 1\nsurvival greater than 4 years. SSL showed strong performance with only 10\npercent labeled data, with more stable results compared to SL and lower\nvariance across external testing, highlighting SSL's robustness and cost\neffectiveness.\n  Conclusion: We introduced a cost-effective, stable, and interpretable SSL\nframework for CT-based survival prediction in lung cancer, improving\nperformance, generalizability, and clinical readiness by integrating SHAP\nexplainability and leveraging unlabeled data.", "comment": "12 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.08189v1", "cate": "physics.med-ph", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2311.10011", "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot Class-Agnostic Counting", "authors": ["Hefeng Wu", "Yandong Chen", "Lingbo Liu", "Tianshui Chen", "Keze Wang", "Liang Lin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE Transactions on Image Processing", "url": "http://arxiv.org/abs/2311.10011v2", "summary": "The class-agnostic counting (CAC) task has recently been proposed to solve\nthe problem of counting all objects of an arbitrary class with several\nexemplars given in the input image. To address this challenging task, existing\nleading methods all resort to density map regression, which renders them\nimpractical for downstream tasks that require object locations and restricts\ntheir ability to well explore the scale information of exemplars for\nsupervision. To address the limitations, we propose a novel localization-based\nCAC approach, termed Scale-modulated Query and Localization Network (SQLNet).\nIt fully explores the scales of exemplars in both the query and localization\nstages and achieves effective counting by accurately locating each object and\npredicting its approximate size. Specifically, during the query stage, rich\ndiscriminative representations of the target class are acquired by the\nHierarchical Exemplars Collaborative Enhancement (HECE) module from the few\nexemplars through multi-scale exemplar cooperation with equifrequent size\nprompt embedding. These representations are then fed into the Exemplars-Unified\nQuery Correlation (EUQC) module to interact with the query features in a\nunified manner and produce the correlated query tensor. In the localization\nstage, the Scale-aware Multi-head Localization (SAML) module utilizes the query\ntensor to predict the confidence, location, and size of each potential object.\nMoreover, a scale-aware localization loss is introduced, which exploits\nflexible location associations and exemplar scales for supervision to optimize\nthe model performance. Extensive experiments demonstrate that SQLNet\noutperforms state-of-the-art methods on popular CAC benchmarks, achieving\nexcellent performance not only in counting accuracy but also in localization\nand bounding box generation. Our codes will be available at\nhttps://github.com/HCPLab-SYSU/SQLNet", "comment": "Accepted by IEEE Transactions on Image Processing", "pdf_url": "http://arxiv.org/pdf/2311.10011v2", "cate": "cs.CV", "date": "2023-11-16", "updated": "2025-07-10"}
{"id": "2506.09874", "title": "UmbraTTS: Adapting Text-to-Speech to Environmental Contexts with Flow Matching", "authors": ["Neta Glazer", "Aviv Navon", "Yael Segal", "Aviv Shamsian", "Hilit Segev", "Asaf Buchnick", "Menachem Pirchi", "Gil Hetz", "Joseph Keshet"], "categories": ["cs.SD", "cs.LG", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      ICML Workshop on Machine Learning for Audio 2025", "url": "http://arxiv.org/abs/2506.09874v2", "summary": "Recent advances in Text-to-Speech (TTS) have enabled highly natural speech\nsynthesis, yet integrating speech with complex background environments remains\nchallenging. We introduce UmbraTTS, a flow-matching based TTS model that\njointly generates both speech and environmental audio, conditioned on text and\nacoustic context. Our model allows fine-grained control over background volume\nand produces diverse, coherent, and context-aware audio scenes. A key challenge\nis the lack of data with speech and background audio aligned in natural\ncontext. To overcome the lack of paired training data, we propose a\nself-supervised framework that extracts speech, background audio, and\ntranscripts from unannotated recordings. Extensive evaluations demonstrate that\nUmbraTTS significantly outperformed existing baselines, producing natural,\nhigh-quality, environmentally aware audios.", "comment": "ICML Workshop on Machine Learning for Audio 2025", "pdf_url": "http://arxiv.org/pdf/2506.09874v2", "cate": "cs.SD", "date": "2025-06-11", "updated": "2025-07-10"}
{"id": "2507.08019", "title": "Signal or Noise? Evaluating Large Language Models in Resume Screening Across Contextual Variations and Human Expert Benchmarks", "authors": ["Aryan Varshney", "Venkat Ram Reddy Ganuthula"], "categories": ["cs.CL", "econ.GN", "q-fin.EC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08019v1", "summary": "This study investigates whether large language models (LLMs) exhibit\nconsistent behavior (signal) or random variation (noise) when screening resumes\nagainst job descriptions, and how their performance compares to human experts.\nUsing controlled datasets, we tested three LLMs (Claude, GPT, and Gemini)\nacross contexts (No Company, Firm1 [MNC], Firm2 [Startup], Reduced Context)\nwith identical and randomized resumes, benchmarked against three human\nrecruitment experts. Analysis of variance revealed significant mean differences\nin four of eight LLM-only conditions and consistently significant differences\nbetween LLM and human evaluations (p < 0.01). Paired t-tests showed GPT adapts\nstrongly to company context (p < 0.001), Gemini partially (p = 0.038 for\nFirm1), and Claude minimally (p > 0.1), while all LLMs differed significantly\nfrom human experts across contexts. Meta-cognition analysis highlighted\nadaptive weighting patterns that differ markedly from human evaluation\napproaches. Findings suggest LLMs offer interpretable patterns with detailed\nprompts but diverge substantially from human judgment, informing their\ndeployment in automated hiring systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08019v1", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-08"}
{"id": "2402.19002", "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction", "authors": ["Amar Fadillah", "Ching-Lin Lee", "Zhi-Xuan Wang", "Kuan-Ting Lai"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.19002v2", "summary": "Predicting the future trajectories of pedestrians on the road is an important\ntask for autonomous driving. The pedestrian trajectory prediction is affected\nby scene paths, pedestrian's intentions and decision-making, which is a\nmulti-modal problem. Most recent studies use past trajectories to predict a\nvariety of potential future trajectory distributions, which do not account for\nthe scene context and pedestrian targets. Instead of predicting the future\ntrajectory directly, we propose to use scene context and observed trajectory to\npredict the goal points first, and then reuse the goal points to predict the\nfuture trajectories. By leveraging the information from scene context and\nobserved trajectory, the uncertainty can be limited to a few target areas,\nwhich represent the \"goals\" of the pedestrians. In this paper, we propose\nGoalNet, a new trajectory prediction neural network based on the goal areas of\na pedestrian. Our network can predict both pedestrian's trajectories and\nbounding boxes. The overall model is efficient and modular, and its outputs can\nbe changed according to the usage scenario. Experimental results show that\nGoalNet significantly improves the previous state-of-the-art performance by\n48.7% on the JAAD and 40.8% on the PIE dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.19002v2", "cate": "cs.CV", "date": "2024-02-29", "updated": "2025-07-11"}
{"id": "2507.08193", "title": "Entity-Specific Cyber Risk Assessment using InsurTech Empowered Risk Factors", "authors": ["Jiayi Guo", "Zhiyun Quan", "Linfeng Zhang"], "categories": ["q-fin.RM", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Risk Management (q-fin.RM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08193v1", "summary": "The lack of high-quality public cyber incident data limits empirical research\nand predictive modeling for cyber risk assessment. This challenge persists due\nto the reluctance of companies to disclose incidents that could damage their\nreputation or investor confidence. Therefore, from an actuarial perspective,\npotential resolutions conclude two aspects: the enhancement of existing cyber\nincident datasets and the implementation of advanced modeling techniques to\noptimize the use of the available data. A review of existing data-driven\nmethods highlights a significant lack of entity-specific organizational\nfeatures in publicly available datasets. To address this gap, we propose a\nnovel InsurTech framework that enriches cyber incident data with\nentity-specific attributes. We develop various machine learning (ML) models: a\nmultilabel classification model to predict the occurrence of cyber incident\ntypes (e.g., Privacy Violation, Data Breach, Fraud and Extortion, IT Error, and\nOthers) and a multioutput regression model to estimate their annual\nfrequencies. While classifier and regressor chains are implemented to explore\ndependencies among cyber incident types as well, no significant correlations\nare observed in our datasets. Besides, we apply multiple interpretable ML\ntechniques to identify and cross-validate potential risk factors developed by\nInsurTech across ML models. We find that InsurTech empowered features enhance\nprediction occurrence and frequency estimation robustness compared to only\nusing conventional risk factors. The framework generates transparent,\nentity-specific cyber risk profiles, supporting customized underwriting and\nproactive cyber risk mitigation. It provides insurers and organizations with\ndata-driven insights to support decision-making and compliance planning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08193v1", "cate": "q-fin.RM", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2403.06759", "title": "Average Calibration Error: A Differentiable Loss for Improved Reliability in Image Segmentation", "authors": ["Theodore Barfoot", "Luis Garcia-Peraza-Herrera", "Ben Glocker", "Tom Vercauteren"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accidental replacement intended for arXiv:2506.03942", "url": "http://arxiv.org/abs/2403.06759v3", "summary": "Deep neural networks for medical image segmentation often produce\noverconfident results misaligned with empirical observations. Such\nmiscalibration, challenges their clinical translation. We propose to use\nmarginal L1 average calibration error (mL1-ACE) as a novel auxiliary loss\nfunction to improve pixel-wise calibration without compromising segmentation\nquality. We show that this loss, despite using hard binning, is directly\ndifferentiable, bypassing the need for approximate but differentiable surrogate\nor soft binning approaches. Our work also introduces the concept of dataset\nreliability histograms which generalises standard reliability diagrams for\nrefined visual assessment of calibration in semantic segmentation aggregated at\nthe dataset level. Using mL1-ACE, we reduce average and maximum calibration\nerror by 45% and 55% respectively, maintaining a Dice score of 87% on the BraTS\n2021 dataset. We share our code here: https://github.com/cai4cai/ACE-DLIRIS", "comment": "accidental replacement intended for arXiv:2506.03942", "pdf_url": "http://arxiv.org/pdf/2403.06759v3", "cate": "cs.CV", "date": "2024-03-11", "updated": "2025-07-11"}
{"id": "2507.07879", "title": "LISTEN: Lightweight Industrial Sound-representable Transformer for Edge Notification", "authors": ["Changheon Han", "Yun Seok Kang", "Yuseop Sim", "Hyung Wook Park", "Martin Byung-Guk Jun"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07879v2", "summary": "Deep learning-based machine listening is broadening the scope of industrial\nacoustic analysis for applications like anomaly detection and predictive\nmaintenance, thereby improving manufacturing efficiency and reliability.\nNevertheless, its reliance on large, task-specific annotated datasets for every\nnew task limits widespread implementation on shop floors. While emerging sound\nfoundation models aim to alleviate data dependency, they are too large and\ncomputationally expensive, requiring cloud infrastructure or high-end hardware\nthat is impractical for on-site, real-time deployment. We address this gap with\nLISTEN (Lightweight Industrial Sound-representable Transformer for Edge\nNotification), a kilobyte-sized industrial sound foundation model. Using\nknowledge distillation, LISTEN runs in real-time on low-cost edge devices. On\nbenchmark downstream tasks, it performs nearly identically to its much larger\nparent model, even when fine-tuned with minimal datasets and training resource.\nBeyond the model itself, we demonstrate its real-world utility by integrating\nLISTEN into a complete machine monitoring framework on an edge device with an\nIndustrial Internet of Things (IIoT) sensor and system, validating its\nperformance and generalization capabilities on a live manufacturing shop floor.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07879v2", "cate": "cs.SD", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08031", "title": "Beyond Scale: Small Language Models are Comparable to GPT-4 in Mental Health Understanding", "authors": ["Hong Jia", "Shiya Fu", "Vassilis Kostakos", "Feng Xia", "Ting Dang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08031v1", "summary": "The emergence of Small Language Models (SLMs) as privacy-preserving\nalternatives for sensitive applications raises a fundamental question about\ntheir inherent understanding capabilities compared to Large Language Models\n(LLMs). This paper investigates the mental health understanding capabilities of\ncurrent SLMs through systematic evaluation across diverse classification tasks.\nEmploying zero-shot and few-shot learning paradigms, we benchmark their\nperformance against established LLM baselines to elucidate their relative\nstrengths and limitations in this critical domain. We assess five\nstate-of-the-art SLMs (Phi-3, Phi-3.5, Qwen2.5, Llama-3.2, Gemma2) against\nthree LLMs (GPT-4, FLAN-T5-XXL, Alpaca-7B) on six mental health understanding\ntasks. Our findings reveal that SLMs achieve mean performance within 2\\% of\nLLMs on binary classification tasks (F1 scores of 0.64 vs 0.66 in zero-shot\nsettings), demonstrating notable competence despite orders of magnitude fewer\nparameters. Both model categories experience similar degradation on multi-class\nseverity tasks (a drop of over 30\\%), suggesting that nuanced clinical\nunderstanding challenges transcend model scale. Few-shot prompting provides\nsubstantial improvements for SLMs (up to 14.6\\%), while LLM gains are more\nvariable. Our work highlights the potential of SLMs in mental health\nunderstanding, showing they can be effective privacy-preserving tools for\nanalyzing sensitive online text data. In particular, their ability to quickly\nadapt and specialize with minimal data through few-shot learning positions them\nas promising candidates for scalable mental health screening tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08031v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2405.19715", "title": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths", "authors": ["Kaixuan Huang", "Xudong Guo", "Mengdi Wang"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to COLM 2025", "url": "http://arxiv.org/abs/2405.19715v3", "summary": "Speculative decoding reduces the inference latency of a target large language\nmodel via utilizing a smaller and faster draft model. Its performance depends\non a hyperparameter K -- the candidate length, i.e., the number of candidate\ntokens for the target model to verify in each round. However, previous methods\noften use simple heuristics to choose K, which may result in sub-optimal\nperformance. We study the choice of the candidate length K and formulate it as\na Markov Decision Process. We theoretically show that the optimal policy of\nthis Markov decision process takes the form of a threshold policy, i.e., the\ncurrent speculation should stop and be verified when the probability of getting\na rejection exceeds a threshold value. Motivated by this theory, we propose\nSpecDec++, an enhanced version of speculative decoding that adaptively\ndetermines the candidate length on the fly. We augment the draft model with a\ntrained acceptance prediction head to predict the conditional acceptance\nprobability of the candidate tokens. SpecDec++ will stop the current\nspeculation when the predicted probability that at least one token gets\nrejected exceeds a threshold. We implement SpecDec++ and apply it to the\nllama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup\non the Alpaca dataset (7.2% improvement over the baseline speculative\ndecoding). On the GSM8K and HumanEval datasets, our method achieves a 2.26x\nspeedup (9.4% improvement) and 2.23x speedup (11.1% improvement), respectively.\nThe code of this paper is available at\nhttps://github.com/Kaffaljidhmah2/SpecDec_pp.", "comment": "Accepted to COLM 2025", "pdf_url": "http://arxiv.org/pdf/2405.19715v3", "cate": "cs.CL", "date": "2024-05-30", "updated": "2025-07-11"}
{"id": "2507.08218", "title": "Simple Mechanistic Explanations for Out-Of-Context Reasoning", "authors": ["Atticus Wang", "Joshua Engels", "Oliver Clive-Griffin"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025 Workshop R2-FM", "url": "http://arxiv.org/abs/2507.08218v1", "summary": "Out-of-context reasoning (OOCR) is a phenomenon in which fine-tuned LLMs\nexhibit surprisingly deep out-of-distribution generalization. Rather than\nlearning shallow heuristics, they implicitly internalize and act on the\nconsequences of observations scattered throughout the fine-tuning data. In this\nwork, we investigate this phenomenon mechanistically and find that many\ninstances of OOCR in the literature have a simple explanation: the LoRA\nfine-tuning essentially adds a constant steering vector, steering the model\ntowards a general concept. This improves performance on the fine-tuning task\nand in many other concept-related domains, causing the surprising\ngeneralization. Moreover, we can directly train steering vectors for these\ntasks from scratch, which also induces OOCR. We find that our results hold even\nfor a task that seems like it must involve conditional behavior (model\nbackdoors); it turns out that unconditionally adding a steering vector is\nsufficient. Overall, our work presents one explanation of what gets learned\nduring fine-tuning for OOCR tasks, contributing to the key question of why LLMs\ncan reason out of context, an advanced capability that is highly relevant to\ntheir safe and reliable deployment.", "comment": "ICML 2025 Workshop R2-FM", "pdf_url": "http://arxiv.org/pdf/2507.08218v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2405.09150", "title": "Curriculum Dataset Distillation", "authors": ["Zhiheng Ma", "Anjia Cao", "Funing Yang", "Yihong Gong", "Xing Wei"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.09150v2", "summary": "Most dataset distillation methods struggle to accommodate large-scale\ndatasets due to their substantial computational and memory requirements. Recent\nresearch has begun to explore scalable disentanglement methods. However, there\nare still performance bottlenecks and room for optimization in this direction.\nIn this paper, we present a curriculum-based dataset distillation framework\naiming to harmonize performance and scalability. This framework strategically\ndistills synthetic images, adhering to a curriculum that transitions from\nsimple to complex. By incorporating curriculum evaluation, we address the issue\nof previous methods generating images that tend to be homogeneous and\nsimplistic, doing so at a manageable computational cost. Furthermore, we\nintroduce adversarial optimization towards synthetic images to further improve\ntheir representativeness and safeguard against their overfitting to the neural\nnetwork involved in distilling. This enhances the generalization capability of\nthe distilled images across various neural network architectures and also\nincreases their robustness to noise. Extensive experiments demonstrate that our\nframework sets new benchmarks in large-scale dataset distillation, achieving\nsubstantial improvements of 11.1\\% on Tiny-ImageNet, 9.0\\% on ImageNet-1K, and\n7.3\\% on ImageNet-21K. Our distilled datasets and code are available at\nhttps://github.com/MIV-XJTU/CUDD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.09150v2", "cate": "cs.CV", "date": "2024-05-15", "updated": "2025-07-11"}
{"id": "2507.08107", "title": "GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs", "authors": ["Sebastian Walter", "Hannah Bast"], "categories": ["cs.CL", "cs.DB", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08107v1", "summary": "We propose a new approach for generating SPARQL queries on RDF knowledge\ngraphs from natural language questions or keyword queries, using a large\nlanguage model. Our approach does not require fine-tuning. Instead, it uses the\nlanguage model to explore the knowledge graph by strategically executing SPARQL\nqueries and searching for relevant IRIs and literals. We evaluate our approach\non a variety of benchmarks (for knowledge graphs of different kinds and sizes)\nand language models (of different scales and types, commercial as well as\nopen-source) and compare it with existing approaches. On Wikidata we reach\nstate-of-the-art results on multiple benchmarks, despite the zero-shot setting.\nOn Freebase we come close to the best few-shot methods. On other, less commonly\nevaluated knowledge graphs and benchmarks our approach also performs well\noverall. We conduct several additional studies, like comparing different ways\nof searching the graphs, incorporating a feedback mechanism, or making use of\nfew-shot examples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08107v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2406.03897", "title": "HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew", "authors": ["Tzuf Paz-Argaman", "Itai Mondshine", "Asaf Achi Mordechai", "Reut Tsarfaty"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.03897v3", "summary": "While large language models (LLMs) excel in various natural language tasks in\nEnglish, their performance in lower-resourced languages like Hebrew, especially\nfor generative tasks such as abstractive summarization, remains unclear. The\nhigh morphological richness in Hebrew adds further challenges due to the\nambiguity in sentence comprehension and the complexities in meaning\nconstruction. In this paper, we address this resource and evaluation gap by\nintroducing HeSum, a novel benchmark specifically designed for abstractive text\nsummarization in Modern Hebrew. HeSum consists of 10,000 article-summary pairs\nsourced from Hebrew news websites written by professionals. Linguistic analysis\nconfirms HeSum's high abstractness and unique morphological challenges. We show\nthat HeSum presents distinct difficulties for contemporary state-of-the-art\nLLMs, establishing it as a valuable testbed for generative language technology\nin Hebrew, and MRLs generative challenges in general.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.03897v3", "cate": "cs.CL", "date": "2024-06-06", "updated": "2025-07-11"}
{"id": "2507.08241", "title": "Exploring Gender Differences in Chronic Pain Discussions on Reddit", "authors": ["Ancita Maria Andrade", "Tanvi Banerjee", "Ramakrishna Mundugar"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This is an extended version of the short paper accepted at ASONAM 2025", "url": "http://arxiv.org/abs/2507.08241v1", "summary": "Pain is an inherent part of human existence, manifesting as both physical and\nemotional experiences, and can be categorized as either acute or chronic. Over\nthe years, extensive research has been conducted to understand the causes of\npain and explore potential treatments, with contributions from various\nscientific disciplines. However, earlier studies often overlooked the role of\ngender in pain experiences. In this study, we utilized Natural Language\nProcessing (NLP) to analyze and gain deeper insights into individuals' pain\nexperiences, with a particular focus on gender differences. We successfully\nclassified posts into male and female corpora using the Hidden Attribute\nModel-Convolutional Neural Network (HAM-CNN), achieving an F1 score of 0.86 by\naggregating posts based on usernames. Our analysis revealed linguistic\ndifferences between genders, with female posts tending to be more emotionally\nfocused. Additionally, the study highlighted that conditions such as migraine\nand sinusitis are more prevalent among females and explored how pain medication\naffects individuals differently based on gender.", "comment": "This is an extended version of the short paper accepted at ASONAM\n  2025", "pdf_url": "http://arxiv.org/pdf/2507.08241v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2407.17907", "title": "Amortized Posterior Sampling with Diffusion Prior Distillation", "authors": ["Abbas Mammadov", "Hyungjin Chung", "Jong Chul Ye"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.17907v2", "summary": "We propose Amortized Posterior Sampling (APS), a novel variational inference\napproach for efficient posterior sampling in inverse problems. Our method\ntrains a conditional flow model to minimize the divergence between the\nvariational distribution and the posterior distribution implicitly defined by\nthe diffusion model. This results in a powerful, amortized sampler capable of\ngenerating diverse posterior samples with a single neural function evaluation,\ngeneralizing across various measurements. Unlike existing methods, our approach\nis unsupervised, requires no paired training data, and is applicable to both\nEuclidean and non-Euclidean domains. We demonstrate its effectiveness on a\nrange of tasks, including image restoration, manifold signal reconstruction,\nand climate data imputation. APS significantly outperforms existing approaches\nin computational efficiency while maintaining competitive reconstruction\nquality, enabling real-time, high-quality solutions to inverse problems across\ndiverse domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.17907v2", "cate": "cs.CV", "date": "2024-07-25", "updated": "2025-07-11"}
{"id": "2507.08109", "title": "Audit, Alignment, and Optimization of LM-Powered Subroutines with Application to Public Comment Processing", "authors": ["Reilly Raab", "Mike Parker", "Dan Nally", "Sadie Montgomery", "Anastasia Bernat", "Sai Munikoti", "Sameera Horawalavithana"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08109v1", "summary": "The advent of language models (LMs) has the potential to dramatically\naccelerate tasks that may be cast to text-processing; however, real-world\nadoption is hindered by concerns regarding safety, explainability, and bias.\nHow can we responsibly leverage LMs in a transparent, auditable manner --\nminimizing risk and allowing human experts to focus on informed decision-making\nrather than data-processing or prompt engineering? In this work, we propose a\nframework for declaring statically typed, LM-powered subroutines (i.e.,\ncallable, function-like procedures) for use within conventional asynchronous\ncode -- such that sparse feedback from human experts is used to improve the\nperformance of each subroutine online (i.e., during use). In our\nimplementation, all LM-produced artifacts (i.e., prompts, inputs, outputs, and\ndata-dependencies) are recorded and exposed to audit on demand. We package this\nframework as a library to support its adoption and continued development. While\nthis framework may be applicable across several real-world decision workflows\n(e.g., in healthcare and legal fields), we evaluate it in the context of public\ncomment processing as mandated by the 1969 National Environmental Protection\nAct (NEPA): Specifically, we use this framework to develop \"CommentNEPA,\" an\napplication that compiles, organizes, and summarizes a corpus of public\ncommentary submitted in response to a project requiring environmental review.\nWe quantitatively evaluate the application by comparing its outputs (when\noperating without human feedback) to historical ``ground-truth'' data as\nlabelled by human annotators during the preparation of official environmental\nimpact statements.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08109v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08194", "title": "On the Parallel Complexity of Finding a Matroid Basis", "authors": ["Sanjeev Khanna", "Aaron Putterman", "Junkai Song"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08194v1", "summary": "A fundamental question in parallel computation, posed by Karp, Upfal, and\nWigderson (FOCS 1985, JCSS 1988), asks: \\emph{given only independence-oracle\naccess to a matroid on $n$ elements, how many rounds are required to find a\nbasis using only polynomially many queries?} This question generalizes, among\nothers, the complexity of finding bases of linear spaces, partition matroids,\nand spanning forests in graphs. In their work, they established an upper bound\nof $O(\\sqrt{n})$ rounds and a lower bound of $\\widetilde{\\Omega}(n^{1/3})$\nrounds for this problem, and these bounds have remained unimproved since then.\n  In this work, we make the first progress in narrowing this gap by designing a\nparallel algorithm that finds a basis of an arbitrary matroid in\n$\\tilde{O}(n^{7/15})$ rounds (using polynomially many independence queries per\nround) with high probability, surpassing the long-standing $O(\\sqrt{n})$\nbarrier. Our approach introduces a novel matroid decomposition technique and\nother structural insights that not only yield this general result but also lead\nto a much improved new algorithm for the class of \\emph{partition matroids}\n(which underlies the $\\widetilde\\Omega(n^{1/3})$ lower bound of Karp, Upfal,\nand Wigderson). Specifically, we develop an $\\tilde{O}(n^{1/3})$-round\nalgorithm, thereby settling the round complexity of finding a basis in\npartition matroids.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08194v1", "cate": "cs.DS", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2406.14023", "title": "Evaluating Implicit Bias in Large Language Models by Attacking From a Psychometric Perspective", "authors": ["Yuchen Wen", "Keping Bi", "Wei Chen", "Jiafeng Guo", "Xueqi Cheng"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 Findings", "url": "http://arxiv.org/abs/2406.14023v5", "summary": "As large language models (LLMs) become an important way of information\naccess, there have been increasing concerns that LLMs may intensify the spread\nof unethical content, including implicit bias that hurts certain populations\nwithout explicit harmful words. In this paper, we conduct a rigorous evaluation\nof LLMs' implicit bias towards certain demographics by attacking them from a\npsychometric perspective to elicit agreements to biased viewpoints. Inspired by\npsychometric principles in cognitive and social psychology, we propose three\nattack approaches, i.e., Disguise, Deception, and Teaching. Incorporating the\ncorresponding attack instructions, we built two benchmarks: (1) a bilingual\ndataset with biased statements covering four bias types (2.7K instances) for\nextensive comparative analysis, and (2) BUMBLE, a larger benchmark spanning\nnine common bias types (12.7K instances) for comprehensive evaluation.\nExtensive evaluation of popular commercial and open-source LLMs shows that our\nmethods can elicit LLMs' inner bias more effectively than competitive\nbaselines. Our attack methodology and benchmarks offer an effective means of\nassessing the ethical risks of LLMs, driving progress toward greater\naccountability in their development. Our code, data, and benchmarks are\navailable at https://yuchenwen1.github.io/ImplicitBiasEvaluation/.", "comment": "Accepted to ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2406.14023v5", "cate": "cs.CL", "date": "2024-06-20", "updated": "2025-07-11"}
{"id": "2507.08261", "title": "Admissibility of Stein Shrinkage for Batch Normalization in the Presence of Adversarial Attacks", "authors": ["Sofia Ivolgina", "P. Thomas Fletcher", "Baba C. Vemuri"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08261v1", "summary": "Batch normalization (BN) is a ubiquitous operation in deep neural networks\nused primarily to achieve stability and regularization during network training.\nBN involves feature map centering and scaling using sample means and variances,\nrespectively. Since these statistics are being estimated across the feature\nmaps within a batch, this problem is ideally suited for the application of\nStein's shrinkage estimation, which leads to a better, in the\nmean-squared-error sense, estimate of the mean and variance of the batch. In\nthis paper, we prove that the Stein shrinkage estimator for the mean and\nvariance dominates over the sample mean and variance estimators in the presence\nof adversarial attacks when modeling these attacks using sub-Gaussian\ndistributions. This facilitates and justifies the application of Stein\nshrinkage to estimate the mean and variance parameters in BN and use it in\nimage classification (segmentation) tasks with and without adversarial attacks.\nWe present SOTA performance results using this Stein corrected batch norm in a\nstandard ResNet architecture applied to the task of image classification using\nCIFAR-10 data, 3D CNN on PPMI (neuroimaging) data and image segmentation using\nHRNet on Cityscape data with and without adversarial attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08261v1", "cate": "stat.ML", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.24204", "title": "GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering", "authors": ["Kai Ye", "Chong Gao", "Guanbin Li", "Wenzheng Chen", "Baoquan Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025", "url": "http://arxiv.org/abs/2410.24204v3", "summary": "Recent 3D Gaussian Splatting (3DGS) representations have demonstrated\nremarkable performance in novel view synthesis; further, material-lighting\ndisentanglement on 3DGS warrants relighting capabilities and its adaptability\nto broader applications. While the general approach to the latter operation\nlies in integrating differentiable physically-based rendering (PBR) techniques\nto jointly recover BRDF materials and environment lighting, achieving a precise\ndisentanglement remains an inherently difficult task due to the challenge of\naccurately modeling light transport. Existing approaches typically approximate\nGaussian points' normals, which constitute an implicit geometric constraint.\nHowever, they usually suffer from inaccuracies in normal estimation that\nsubsequently degrade light transport, resulting in noisy material decomposition\nand flawed relighting results. To address this, we propose GeoSplatting, a\nnovel approach that augments 3DGS with explicit geometry guidance for precise\nlight transport modeling. By differentiably constructing a surface-grounded\n3DGS from an optimizable mesh, our approach leverages well-defined mesh normals\nand the opaque mesh surface, and additionally facilitates the use of mesh-based\nray tracing techniques for efficient, occlusion-aware light transport\ncalculations. This enhancement ensures precise material decomposition while\npreserving the efficiency and high-quality rendering capabilities of 3DGS.\nComprehensive evaluations across diverse datasets demonstrate the effectiveness\nof GeoSplatting, highlighting its superior efficiency and state-of-the-art\ninverse rendering performance. The project page can be found at\nhttps://pku-vcl-geometry.github.io/GeoSplatting/.", "comment": "ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2410.24204v3", "cate": "cs.CV", "date": "2024-10-31", "updated": "2025-07-11"}
{"id": "2507.08151", "title": "Distilling Empathy from Large Language Models", "authors": ["Henry J. Xie", "Jinghan Zhang", "Xinhao Zhang", "Kunpeng Liu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by SIGDIAL 2025", "url": "http://arxiv.org/abs/2507.08151v1", "summary": "The distillation of knowledge from Large Language Models (LLMs) into Smaller\nLanguage Models (SLMs), preserving the capabilities and performance of LLMs\nwhile reducing model size, has played a key role in the proliferation of LLMs.\nBecause SLMs are considerably smaller than LLMs, they are often utilized in\ndomains where human interaction is frequent but resources are highly\nconstrained, e.g., smart phones. Therefore, it is crucial to ensure that\nempathy, a fundamental aspect of positive human interactions, already instilled\ninto LLMs, is retained by SLMs after distillation. In this paper, we develop a\ncomprehensive approach for effective empathy distillation from LLMs into SLMs.\nOur approach features a two-step fine-tuning process that fully leverages\ndatasets of empathetic dialogue responses distilled from LLMs. We explore\nseveral distillation methods beyond basic direct prompting and propose four\nunique sets of prompts for targeted empathy improvement to significantly\nenhance the empathy distillation process. Our evaluations demonstrate that SLMs\nfine-tuned through the two-step fine-tuning process with distillation datasets\nenhanced by the targeted empathy improvement prompts significantly outperform\nthe base SLM at generating empathetic responses with a win rate of 90%. Our\ntargeted empathy improvement prompts substantially outperform the basic direct\nprompting with a 10% improvement in win rate.", "comment": "Accepted by SIGDIAL 2025", "pdf_url": "http://arxiv.org/pdf/2507.08151v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08316", "title": "Approximation Algorithms for the Cumulative Vehicle Routing Problem with Stochastic Demands", "authors": ["Jingyang Zhao", "Mingyu Xiao"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08316v1", "summary": "In the Cumulative Vehicle Routing Problem (Cu-VRP), we need to find a\nfeasible itinerary for a capacitated vehicle located at the depot to satisfy\ncustomers' demand, as in the well-known Vehicle Routing Problem (VRP), but the\ngoal is to minimize the cumulative cost of the vehicle, which is based on the\nvehicle's load throughout the itinerary. If the demand of each customer is\nunknown until the vehicle visits it, the problem is called Cu-VRP with\nStochastic Demands (Cu-VRPSD). Assume that the approximation ratio of metric\nTSP is $1.5$. In this paper, we propose a randomized $3.456$-approximation\nalgorithm for Cu-VRPSD, improving the best-known approximation ratio of $6$\n(Discret. Appl. Math. 2020). Since VRP with Stochastic Demands (VRPSD) is a\nspecial case of Cu-VRPSD, as a corollary, we also obtain a randomized\n$3.25$-approximation algorithm for VRPSD, improving the best-known\napproximation ratio of $3.5$ (Oper. Res. 2012). For Cu-VRP, we give a\nrandomized $3.194$-approximation algorithm, improving the best-known\napproximation ratio of $4$ (Oper. Res. Lett. 2013). Moreover, if each customer\nis allowed to be satisfied by using multiple tours, we obtain further\nimprovements for Cu-VRPSD and Cu-VRP.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08316v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2407.10657", "title": "An Empirical Study of Validating Synthetic Data for Formula Generation", "authors": ["Usneek Singh", "José Cambronero", "Sumit Gulwani", "Aditya Kanade", "Anirudh Khatry", "Vu Le", "Mukul Singh", "Gust Verbruggen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Findings of NAACL", "url": "http://arxiv.org/abs/2407.10657v4", "summary": "Large language models (LLMs) can be leveraged to help with writing formulas\nin spreadsheets, but resources on these formulas are scarce, impacting both the\nbase performance of pre-trained models and limiting the ability to fine-tune\nthem. Given a corpus of formulas, we can use a(nother) model to generate\nsynthetic natural language utterances for fine-tuning. However, it is important\nto validate whether the NL generated by the LLM is indeed accurate to be\nbeneficial for fine-tuning. In this paper, we provide empirical results on the\nimpact of validating these synthetic training examples with surrogate\nobjectives that evaluate the accuracy of the synthetic annotations. We\ndemonstrate that validation improves performance over raw data across four\nmodels (2 open and 2 closed weight). Interestingly, we show that although\nvalidation tends to prune more challenging examples, it increases the\ncomplexity of problems that models can solve after being fine-tuned on\nvalidated data.", "comment": "Accepted at Findings of NAACL", "pdf_url": "http://arxiv.org/pdf/2407.10657v4", "cate": "cs.CL", "date": "2024-07-15", "updated": "2025-07-11"}
{"id": "2507.08280", "title": "MIRRAMS: Towards Training Models Robust to Missingness Distribution Shifts", "authors": ["Jihye Lee", "Minseo Kang", "Dongha Kim"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08280v1", "summary": "In real-world data analysis, missingness distributional shifts between\ntraining and test input datasets frequently occur, posing a significant\nchallenge to achieving robust prediction performance. In this study, we propose\na novel deep learning framework designed to address such shifts in missingness\ndistributions. We begin by introducing a set of mutual information-based\nconditions, called MI robustness conditions, which guide a prediction model to\nextract label-relevant information while remaining invariant to diverse\nmissingness patterns, thereby enhancing robustness to unseen missingness\nscenarios at test-time. To make these conditions practical, we propose simple\nyet effective techniques to derive loss terms corresponding to each and\nformulate a final objective function, termed MIRRAMS(Mutual Information\nRegularization for Robustness Against Missingness Shifts). As a by-product, our\nanalysis provides a theoretical interpretation of the principles underlying\nconsistency regularization-based semi-supervised learning methods, such as\nFixMatch. Extensive experiments across various benchmark datasets show that\nMIRRAMS consistently outperforms existing baselines and maintains stable\nperformance across diverse missingness scenarios. Moreover, our approach\nachieves state-of-the-art performance even without missing data and can be\nnaturally extended to address semi-supervised learning tasks, highlighting\nMIRRAMS as a powerful, off-the-shelf framework for general-purpose learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08280v1", "cate": "stat.ML", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2411.09250", "title": "Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning", "authors": ["Dunwei Tu", "Huiyu Yi", "Tieyi Zhang", "Ruotong Li", "Furao Shen", "Jian Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to Neural Networks", "url": "http://arxiv.org/abs/2411.09250v2", "summary": "Few-shot class-incremental learning (FSCIL) aims to continually learn new\nclasses from only a few samples without forgetting previous ones, requiring\nintelligent agents to adapt to dynamic environments. FSCIL combines the\ncharacteristics and challenges of class-incremental learning and few-shot\nlearning: (i) Current classes occupy the entire feature space, which is\ndetrimental to learning new classes. (ii) The small number of samples in\nincremental rounds is insufficient for fully training. In existing mainstream\nvirtual class methods, for addressing the challenge (i), they attempt to use\nvirtual classes as placeholders. However, new classes may not necessarily align\nwith the virtual classes. For the challenge (ii), they replace trainable fully\nconnected layers with Nearest Class Mean (NCM) classifiers based on cosine\nsimilarity, but NCM classifiers do not account for sample imbalance issues. To\naddress these issues in previous methods, we propose the class-center guided\nembedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning\nframework, which provides balanced space for all classes and leverages norm\ndifferences caused by sample imbalance to enhance classification criteria.\nSpecifically, for challenge (i), SAAN divides the feature space into multiple\nsubspaces and allocates a dedicated subspace for each session by guiding\nsamples with the pre-set category centers. For challenge (ii), SAAN establishes\na norm distribution for each class and generates angle-norm joint logits.\nExperiments demonstrate that SAAN can achieve state-of-the-art performance and\nit can be directly embedded into other SOTA methods as a plug-in, further\nenhancing their performance.", "comment": "This paper has been accepted to Neural Networks", "pdf_url": "http://arxiv.org/pdf/2411.09250v2", "cate": "cs.CV", "date": "2024-11-14", "updated": "2025-07-11"}
{"id": "2507.08203", "title": "TruthTorchLM: A Comprehensive Library for Predicting Truthfulness in LLM Outputs", "authors": ["Duygu Nur Yaldiz", "Yavuz Faruk Bakman", "Sungmin Kang", "Alperen Öziş", "Hayrettin Eren Yildiz", "Mitash Ashish Shah", "Zhiqi Huang", "Anoop Kumar", "Alfy Samuel", "Daben Liu", "Sai Praneeth Karimireddy", "Salman Avestimehr"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08203v1", "summary": "Generative Large Language Models (LLMs)inevitably produce untruthful\nresponses. Accurately predicting the truthfulness of these outputs is critical,\nespecially in high-stakes settings. To accelerate research in this domain and\nmake truthfulness prediction methods more accessible, we introduce TruthTorchLM\nan open-source, comprehensive Python library featuring over 30 truthfulness\nprediction methods, which we refer to as Truth Methods. Unlike existing\ntoolkits such as Guardrails, which focus solely on document-grounded\nverification, or LM-Polygraph, which is limited to uncertainty-based methods,\nTruthTorchLM offers a broad and extensible collection of techniques. These\nmethods span diverse tradeoffs in computational cost, access level (e.g.,\nblack-box vs white-box), grounding document requirements, and supervision type\n(self-supervised or supervised). TruthTorchLM is seamlessly compatible with\nboth HuggingFace and LiteLLM, enabling support for locally hosted and API-based\nmodels. It also provides a unified interface for generation, evaluation,\ncalibration, and long-form truthfulness prediction, along with a flexible\nframework for extending the library with new methods. We conduct an evaluation\nof representative truth methods on three datasets, TriviaQA, GSM8K, and\nFactScore-Bio. The code is available at https://github.com/Ybakman/TruthTorchLM", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08203v1", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08541", "title": "H-Planarity and Parametric Extensions: when Modulators Act Globally", "authors": ["Fedor V. Fomin", "Petr A. Golovach", "Laure Morelle", "Dimitrios M. Thilikos"], "categories": ["cs.DS", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08541v1", "summary": "We introduce a series of graph decompositions based on the modulator/target\nscheme of modification problems that enable several algorithmic applications\nthat parametrically extend the algorithmic potential of planarity. In the core\nof our approach is a polynomial time algorithm for computing planar\nH-modulators. Given a graph class H, a planar H-modulator of a graph G is a set\nX \\subseteq V(G) such that the ``torso'' of X is planar and all connected\ncomponents of G - X belong to H. Here, the torso of X is obtained from G[X] if,\nfor every connected component of G-X, we form a clique out of its neighborhood\non G[X]. We introduce H-Planarity as the problem of deciding whether a graph G\nhas a planar H-modulator. We prove that, if H is hereditary, CMSO-definable,\nand decidable in polynomial time, then H-Planarity is solvable in polynomial\ntime. Further, we introduce two parametric extensions of H-Planarity by\ndefining the notions of H-planar treedepth and H-planar treewidth, which\ngeneralize the concepts of elimination distance and tree decompositions to the\nclass H. Combining this result with existing FPT algorithms for various\nH-modulator problems, we thereby obtain FPT algorithms parameterized by\nH-planar treedepth and H-planar treewidth for numerous graph classes H. By\ncombining the well-known algorithmic properties of planar graphs and graphs of\nbounded treewidth, our methods for computing H-planar treedepth and H-planar\ntreewidth lead to a variety of algorithmic applications. For instance, once we\nknow that a given graph has bounded H-planar treedepth or bounded H-planar\ntreewidth, we can derive additive approximation algorithms for graph coloring\nand polynomial-time algorithms for counting (weighted) perfect matchings.\nFurthermore, we design Efficient Polynomial-Time Approximation Schemes\n(EPTAS-es) for several problems, including Maximum Independent Set.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08541v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.14371", "title": "SEREP: Semantic Facial Expression Representation for Robust In-the-Wild Capture and Retargeting", "authors": ["Arthur Josi", "Luiz Gustavo Hafemann", "Abdallah Dib", "Emeline Got", "Rafael M. O. Cruz", "Marc-Andre Carbonneau"], "categories": ["cs.CV", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      For our project page, see this https URL", "url": "http://arxiv.org/abs/2412.14371v3", "summary": "Monocular facial performance capture in-the-wild is challenging due to varied\ncapture conditions, face shapes, and expressions. Most current methods rely on\nlinear 3D Morphable Models, which represent facial expressions independently of\nidentity at the vertex displacement level. We propose SEREP (Semantic\nExpression Representation), a model that disentangles expression from identity\nat the semantic level. We start by learning an expression representation from\nhigh-quality 3D data of unpaired facial expressions. Then, we train a model to\npredict expression from monocular images relying on a novel semi-supervised\nscheme using low quality synthetic data. In addition, we introduce MultiREX, a\nbenchmark addressing the lack of evaluation resources for the expression\ncapture task. Our experiments show that SEREP outperforms state-of-the-art\nmethods, capturing challenging expressions and transferring them to new\nidentities.", "comment": "For our project page, see\n  https://ubisoft-laforge.github.io/character/serep/", "pdf_url": "http://arxiv.org/pdf/2412.14371v3", "cate": "cs.CV", "date": "2024-12-18", "updated": "2025-07-11"}
{"id": "2410.00381", "title": "Downscaling Extreme Precipitation with Wasserstein Regularized Diffusion", "authors": ["Yuhao Liu", "James Doss-Gollin", "Qiushi Dai", "Ashok Veeraraghavan", "Guha Balakrishnan"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 10 figures, 4 tables", "url": "http://arxiv.org/abs/2410.00381v3", "summary": "Understanding the risks posed by extreme rainfall events necessitates both\nhigh-resolution products (to assess localized hazards) and extensive historical\nrecords (to capture rare occurrences). Radar and mesonet networks provide\nkilometer-scale precipitation fields, but with limited historical records and\ngeographical coverage. Conversely, global gauge and blended products span\ndecades, yet their coarse 30-50 km grids obscure local extremes. This work\nintroduces Wasserstein Regularized Diffusion (WassDiff), a generative\ndownscaling framework that integrates diffusion modeling with a\ndistribution-matching (Wasserstein) regularizer, suppressing bias throughout\nthe entire generative denoising process. Conditioned on 55 km CPC gauge-based\nprecipitation and the 31 km ERA5 reanalysis, WassDiff generates 1 km\nprecipitation estimates that remain well-calibrated to targets across the full\nintensity range, including the extremes. Comprehensive evaluations demonstrate\nthat WassDiff outperforms existing state-of-the-art downscaling methods,\ndelivering lower reconstruction error and reduced bias. Case studies further\ndemonstrate its ability to reproduce realistic fine-scale structures and\naccurate peak intensities from extreme weather phenomena, such as tropical\nstorms and cold fronts. By unlocking decades of high-resolution rainfall\ninformation from globally available coarse records, WassDiff offers a practical\npathway toward more accurate flood-risk assessments and climate-adaptation\nplanning.", "comment": "21 pages, 10 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2410.00381v3", "cate": "cs.LG", "date": "2024-10-01", "updated": "2025-07-10"}
{"id": "2507.08322", "title": "Towards Efficient Quantity Retrieval from Text:an Approach via Description Parsing and Weak Supervision", "authors": ["Yixuan Cao", "Zhengrong Chen", "Chengxuan Xia", "Kun Wu", "Ping Luo"], "categories": ["cs.IR", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Extended version of the paper accepted in DEXA 2025", "url": "http://arxiv.org/abs/2507.08322v1", "summary": "Quantitative facts are continually generated by companies and governments,\nsupporting data-driven decision-making. While common facts are structured, many\nlong-tail quantitative facts remain buried in unstructured documents, making\nthem difficult to access. We propose the task of Quantity Retrieval: given a\ndescription of a quantitative fact, the system returns the relevant value and\nsupporting evidence. Understanding quantity semantics in context is essential\nfor this task. We introduce a framework based on description parsing that\nconverts text into structured (description, quantity) pairs for effective\nretrieval. To improve learning, we construct a large paraphrase dataset using\nweak supervision based on quantity co-occurrence. We evaluate our approach on a\nlarge corpus of financial annual reports and a newly annotated quantity\ndescription dataset. Our method significantly improves top-1 retrieval accuracy\nfrom 30.98 percent to 64.66 percent.", "comment": "Extended version of the paper accepted in DEXA 2025", "pdf_url": "http://arxiv.org/pdf/2507.08322v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2411.10715", "title": "EVT: Efficient View Transformation for Multi-Modal 3D Object Detection", "authors": ["Yongjin Lee", "Hyeon-Mun Jeong", "Yurim Jeon", "Sanghyun Kim"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2411.10715v4", "summary": "Multi-modal sensor fusion in Bird's Eye View (BEV) representation has become\nthe leading approach for 3D object detection. However, existing methods often\nrely on depth estimators or transformer encoders to transform image features\ninto BEV space, which reduces robustness or introduces significant\ncomputational overhead. Moreover, the insufficient geometric guidance in view\ntransformation results in ray-directional misalignments, limiting the\neffectiveness of BEV representations. To address these challenges, we propose\nEfficient View Transformation (EVT), a novel 3D object detection framework that\nconstructs a well-structured BEV representation, improving both accuracy and\nefficiency. Our approach focuses on two key aspects. First, Adaptive Sampling\nand Adaptive Projection (ASAP), which utilizes LiDAR guidance to generate 3D\nsampling points and adaptive kernels, enables more effective transformation of\nimage features into BEV space and a refined BEV representation. Second, an\nimproved query-based detection framework, incorporating group-wise mixed query\nselection and geometry-aware cross-attention, effectively captures both the\ncommon properties and the geometric structure of objects in the transformer\ndecoder. On the nuScenes test set, EVT achieves state-of-the-art performance of\n75.3% NDS with real-time inference speed.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2411.10715v4", "cate": "cs.CV", "date": "2024-11-16", "updated": "2025-07-11"}
{"id": "2507.08297", "title": "KAT-V1: Kwai-AutoThink Technical Report", "authors": ["Zizheng Zhan", "Ken Deng", "Huaixi Tang", "Wen Xiang", "Kun Wu", "Weihao Li", "Wenqiang Zhu", "Jingxuan Xu", "Lecheng Huang", "Zongxian Feng", "Shaojie Wang", "Shangpeng Yan", "Jiaheng Liu", "Zhongyuan Peng", "Zuchen Gao", "Haoyang Huang", "Ziqi Zhan", "Yanan Wu", "Yuanxing Zhang", "Jian Yang", "Guang Chen", "Haotian Zhang", "Bin Chen", "Bing Yu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08297v1", "summary": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model\ndeveloped to address the overthinking problem in reasoning-intensive tasks,\nwhere an automatic thinking training paradigm is proposed to dynamically switch\nbetween reasoning and non-reasoning modes based on task complexity.\nSpecifically, first, we construct the dual-regime dataset based on a novel\ntagging pipeline and a multi-agent synthesis strategy, and then we apply\nMulti-Token Prediction (MTP)-enhanced knowledge distillation, enabling\nefficient and fine-grained reasoning transfer with minimal pretraining cost.\nBesides, we implement a cold-start initialization strategy that introduces\nmode-selection priors using majority-vote signals and intent-aware prompting.\nFinally, we propose Step-SRPO, a reinforcement learning algorithm that\nincorporates intermediate supervision into the GRPO framework, offering\nstructured guidance over both reasoning-mode selection and response accuracy.\nExtensive experiments across multiple benchmarks demonstrate that KAT\nconsistently matches or even outperforms current state-of-the-art models,\nincluding DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of\nreasoning-intensive tasks while reducing token usage by up to approximately\n30\\%. Beyond academic evaluation, KAT has been successfully deployed in\nKwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world\ndevelopment workflows with high accuracy, efficiency, and controllable\nreasoning behaviors. Moreover, we are actively training a 200B\nMixture-of-Experts (MoE) with 40B activation parameters, where the early-stage\nresults already demonstrate promising improvements in performance and\nefficiency, further showing the scalability of the AutoThink paradigm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08297v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08685", "title": "Beer Path Problems in Temporal Graphs", "authors": ["Andrea D'Ascenzo", "Giuseppe F. Italiano", "Sotiris Kanellopoulos", "Anna Mpanti", "Aris Pagourtzis", "Christos Pergaminelis"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08685v1", "summary": "Computing paths in graph structures is a fundamental operation in a wide\nrange of applications, from transportation networks to data analysis. The beer\npath problem, which captures the option of visiting points of interest, such as\ngas stations or convenience stops, prior to reaching the final destination, has\nbeen recently introduced and extensively studied in static graphs. However,\nexisting approaches do not account for temporal information, which is often\ncrucial in real-world scenarios. For instance, transit services may follow\nfixed schedules, and shops may only be accessible during certain hours.\n  In this work, we introduce the notion of beer paths in temporal graphs, where\nedges are time-dependent and certain vertices (beer vertices) are active only\nat specific time instances. We formally define the problems of computing\nearliest-arrival, latest-departure, fastest, and shortest temporal beer paths\nand propose efficient algorithms for these problems under both edge stream and\nadjacency list representations. The time complexity of each of our algorithms\nis aligned with that of corresponding temporal pathfinding algorithms, thus\npreserving efficiency.\n  Additionally, we present preprocessing techniques that enable efficient query\nanswering under dynamic conditions, for example new openings or closings of\nshops. We achieve this through appropriate precomputation of selected paths or\nby transforming a temporal graph into an equivalent static graph.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08685v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08360", "title": "DS@GT at LongEval: Evaluating Temporal Performance in Web Search Systems and Topics with Two-Stage Retrieval", "authors": ["Anthony Miyaguchi", "Imran Afrulbasha", "Aleksandar Pramov"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08360v1", "summary": "Information Retrieval (IR) models are often trained on static datasets,\nmaking them vulnerable to performance degradation as web content evolves. The\nDS@GT competition team participated in the Longitudinal Evaluation of Model\nPerformance (LongEval) lab at CLEF 2025, which evaluates IR systems across\ntemporally distributed web snapshots. Our analysis of the Qwant web dataset\nincludes exploratory data analysis with topic modeling over time. The two-phase\nretrieval system employs sparse keyword searches, utilizing query expansion and\ndocument reranking. Our best system achieves an average NDCG@10 of 0.296 across\nthe entire training and test dataset, with an overall best score of 0.395 on\n2023-05. The accompanying source code for this paper is at\nhttps://github.com/dsgt-arc/longeval-2025", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08360v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2410.06303", "title": "Compositional Risk Minimization", "authors": ["Divyat Mahajan", "Mohammad Pezeshki", "Charles Arnal", "Ioannis Mitliagkas", "Kartik Ahuja", "Pascal Vincent"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Proceedings of the 42nd International Conference on Machine Learning (ICML) 2025", "url": "http://arxiv.org/abs/2410.06303v3", "summary": "Compositional generalization is a crucial step towards developing\ndata-efficient intelligent machines that generalize in human-like ways. In this\nwork, we tackle a challenging form of distribution shift, termed compositional\nshift, where some attribute combinations are completely absent at training but\npresent in the test distribution. This shift tests the model's ability to\ngeneralize compositionally to novel attribute combinations in discriminative\ntasks. We model the data with flexible additive energy distributions, where\neach energy term represents an attribute, and derive a simple alternative to\nempirical risk minimization termed compositional risk minimization (CRM). We\nfirst train an additive energy classifier to predict the multiple attributes\nand then adjust this classifier to tackle compositional shifts. We provide an\nextensive theoretical analysis of CRM, where we show that our proposal\nextrapolates to special affine hulls of seen attribute combinations. Empirical\nevaluations on benchmark datasets confirms the improved robustness of CRM\ncompared to other methods from the literature designed to tackle various forms\nof subpopulation shifts.", "comment": "Proceedings of the 42nd International Conference on Machine Learning\n  (ICML) 2025", "pdf_url": "http://arxiv.org/pdf/2410.06303v3", "cate": "cs.LG", "date": "2024-10-08", "updated": "2025-07-10"}
{"id": "2507.08402", "title": "SPINT: Spatial Permutation-Invariant Neural Transformer for Consistent Intracortical Motor Decoding", "authors": ["Trung Le", "Hao Fang", "Jingyuan Li", "Tung Nguyen", "Lu Mi", "Amy Orsborn", "Uygar Sümbül", "Eli Shlizerman"], "categories": ["q-bio.NC", "cs.LG"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08402v1", "summary": "Intracortical Brain-Computer Interfaces (iBCI) aim to decode behavior from\nneural population activity, enabling individuals with motor impairments to\nregain motor functions and communication abilities. A key challenge in\nlong-term iBCI is the nonstationarity of neural recordings, where the\ncomposition and tuning profiles of the recorded populations are unstable across\nrecording sessions. Existing methods attempt to address this issue by explicit\nalignment techniques; however, they rely on fixed neural identities and require\ntest-time labels or parameter updates, limiting their generalization across\nsessions and imposing additional computational burden during deployment. In\nthis work, we introduce SPINT - a Spatial Permutation-Invariant Neural\nTransformer framework for behavioral decoding that operates directly on\nunordered sets of neural units. Central to our approach is a novel\ncontext-dependent positional embedding scheme that dynamically infers\nunit-specific identities, enabling flexible generalization across recording\nsessions. SPINT supports inference on variable-size populations and allows\nfew-shot, gradient-free adaptation using a small amount of unlabeled data from\nthe test session. To further promote model robustness to population\nvariability, we introduce dynamic channel dropout, a regularization method for\niBCI that simulates shifts in population composition during training. We\nevaluate SPINT on three multi-session datasets from the FALCON Benchmark,\ncovering continuous motor decoding tasks in human and non-human primates. SPINT\ndemonstrates robust cross-session generalization, outperforming existing\nzero-shot and few-shot unsupervised baselines while eliminating the need for\ntest-time alignment and fine-tuning. Our work contributes an initial step\ntoward a robust and scalable neural decoding framework for long-term iBCI\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08402v1", "cate": "q-bio.NC", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.00136", "title": "FonTS: Text Rendering with Typography and Style Controls", "authors": ["Wenda Shi", "Yiren Song", "Dengming Zhang", "Jiaming Liu", "Xingxing Zou"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2412.00136v3", "summary": "Visual text rendering are widespread in various real-world applications,\nrequiring careful font selection and typographic choices. Recent progress in\ndiffusion transformer (DiT)-based text-to-image (T2I) models show promise in\nautomating these processes. However, these methods still encounter challenges\nlike inconsistent fonts, style variation, and limited fine-grained control,\nparticularly at the word-level. This paper proposes a two-stage DiT-based\npipeline to address these problems by enhancing controllability over typography\nand style in text rendering. We introduce typography control fine-tuning\n(TC-FT), an parameter-efficient fine-tuning method (on $5\\%$ key parameters)\nwith enclosing typography control tokens (ETC-tokens), which enables precise\nword-level application of typographic features. To further address style\ninconsistency in text rendering, we propose a text-agnostic style control\nadapter (SCA) that prevents content leakage while enhancing style consistency.\nTo implement TC-FT and SCA effectively, we incorporated HTML-render into the\ndata synthesis pipeline and proposed the first word-level controllable dataset.\nThrough comprehensive experiments, we demonstrate the effectiveness of our\napproach in achieving superior word-level typographic control, font\nconsistency, and style consistency in text rendering tasks. The datasets and\nmodels will be available for academic use.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2412.00136v3", "cate": "cs.CV", "date": "2024-11-28", "updated": "2025-07-11"}
{"id": "2507.08335", "title": "MK2 at PBIG Competition: A Prompt Generation Solution", "authors": ["Yuzheng Xu", "Tosho Hirasawa", "Seiya Kawano", "Shota Kato", "Tadashi Kozuno"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, to appear in the 2nd Workshop on Agent AI for Scenario Planning (AGENTSCEN 2025)", "url": "http://arxiv.org/abs/2507.08335v1", "summary": "The Patent-Based Idea Generation task asks systems to turn real patents into\nproduct ideas viable within three years. We propose MK2, a prompt-centric\npipeline: Gemini 2.5 drafts and iteratively edits a prompt, grafting useful\nfragments from weaker outputs; GPT-4.1 then uses this prompt to create one idea\nper patent, and an Elo loop judged by Qwen3-8B selects the best prompt-all\nwithout extra training data. Across three domains, two evaluator types, and six\ncriteria, MK2 topped the automatic leaderboard and won 25 of 36 tests. Only the\nmaterials-chemistry track lagged, indicating the need for deeper domain\ngrounding; yet, the results show that lightweight prompt engineering has\nalready delivered competitive, commercially relevant ideation from patents.", "comment": "9 pages, to appear in the 2nd Workshop on Agent AI for Scenario\n  Planning (AGENTSCEN 2025)", "pdf_url": "http://arxiv.org/pdf/2507.08335v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08693", "title": "On the Constant-Factor Approximability of Minimum Cost Constraint Satisfaction Problems", "authors": ["Ian DeHaan", "Neng Huang", "Euiwoong Lee"], "categories": ["cs.DS", "cs.CC", "cs.DM"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      22 pages", "url": "http://arxiv.org/abs/2507.08693v1", "summary": "We study minimum cost constraint satisfaction problems (MinCostCSP) through\nthe algebraic lens. We show that for any constraint language $\\Gamma$ which has\nthe dual discriminator operation as a polymorphism, there exists a\n$|D|$-approximation algorithm for MinCostCSP$(\\Gamma)$ where $D$ is the domain.\nComplementing our algorithmic result, we show that any constraint language\n$\\Gamma$ where MinCostCSP$(\\Gamma)$ admits a constant-factor approximation must\nhave a \\emph{near-unanimity} (NU) polymorphism unless P = NP, extending a\nsimilar result by Dalmau et al. on MinCSPs. These results imply a dichotomy of\nconstant-factor approximability for constraint languages that contain all\npermutation relations (a natural generalization for Boolean CSPs that allow\nvariable negation): either MinCostCSP$(\\Gamma)$ has an NU polymorphism and is\n$|D|$-approximable, or it does not have any NU polymorphism and is NP-hard to\napproximate within any constant factor. Finally, we present a constraint\nlanguage which has a majority polymorphism, but is nonetheless NP-hard to\napproximate within any constant factor assuming the Unique Games Conjecture,\nshowing that the condition of having an NU polymorphism is in general not\nsufficient unless UGC fails.", "comment": "22 pages", "pdf_url": "http://arxiv.org/pdf/2507.08693v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08480", "title": "Improving Korean-English Cross-Lingual Retrieval: A Data-Centric Study of Language Composition and Model Merging", "authors": ["Youngjoon Jang", "Junyoung Son", "Taemin Lee", "Seongtae Hong", "Heuiseok Lim"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08480v1", "summary": "With the increasing utilization of multilingual text information,\nCross-Lingual Information Retrieval (CLIR) has become a crucial research area.\nHowever, the impact of training data composition on both CLIR and Mono-Lingual\nInformation Retrieval (IR) performance remains under-explored. To\nsystematically investigate this data-centric aspect, we construct\nlinguistically parallel Korean-English datasets and train retrieval models with\nvarious language combinations. Our experiments reveal that the language\ncomposition of training data significantly influences IR performance,\nexhibiting important inter-lingual correlations: CLIR performance improves with\nspecific language pairs, while Mono-Lingual IR performance declines. Our work\ndemonstrates that Model Merging can effectively mitigate this trade-off,\nachieving strong CLIR results while preserving Mono-Lingual IR capabilities.\nOur findings underscore the effects of linguistic configuration of training\ndata on both CLIR and Mono-Lingual IR, and present Model Merging as a viable\nstrategy to optimize performance across these tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08480v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2411.06728", "title": "On the Principles of ReLU Networks with One Hidden Layer", "authors": ["Changcun Huang"], "categories": ["cs.LG", "cs.AI", "cs.NE", "68T07(Primary), 41A15(Secondary)", "I.2.6; G.1.2"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.06728v2", "summary": "A neural network with one hidden layer or a two-layer network (regardless of\nthe input layer) is the simplest feedforward neural network, whose mechanism\nmay be the basis of more general network architectures. However, even to this\ntype of simple architecture, it is also a ``black box''; that is, it remains\nunclear how to interpret the mechanism of its solutions obtained by the\nback-propagation algorithm and how to control the training process through a\ndeterministic way. This paper systematically studies the first problem by\nconstructing universal function-approximation solutions. It is shown that, both\ntheoretically and experimentally, the training solution for the one-dimensional\ninput could be completely understood, and that for a higher-dimensional input\ncan also be well interpreted to some extent. Those results pave the way for\nthoroughly revealing the black box of two-layer ReLU networks and advance the\nunderstanding of deep ReLU networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.06728v2", "cate": "cs.LG", "date": "2024-11-11", "updated": "2025-07-11"}
{"id": "2507.08438", "title": "Optimal and Practical Batched Linear Bandit Algorithm", "authors": ["Sanghoon Yu", "Min-hwan Oh"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted at ICML 2025", "url": "http://arxiv.org/abs/2507.08438v1", "summary": "We study the linear bandit problem under limited adaptivity, known as the\nbatched linear bandit. While existing approaches can achieve near-optimal\nregret in theory, they are often computationally prohibitive or underperform in\npractice. We propose \\texttt{BLAE}, a novel batched algorithm that integrates\narm elimination with regularized G-optimal design, achieving the minimax\noptimal regret (up to logarithmic factors in $T$) in both large-$K$ and\nsmall-$K$ regimes for the first time, while using only $O(\\log\\log T)$ batches.\nOur analysis introduces new techniques for batch-wise optimal design and\nrefined concentration bounds. Crucially, \\texttt{BLAE} demonstrates low\ncomputational overhead and strong empirical performance, outperforming\nstate-of-the-art methods in extensive numerical evaluations. Thus,\n\\texttt{BLAE} is the first algorithm to combine provable minimax-optimality in\nall regimes and practical superiority in batched linear bandits.", "comment": "Accepted at ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.08438v1", "cate": "stat.ML", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.09626", "title": "FreeScale: Unleashing the Resolution of Diffusion Models via Tuning-Free Scale Fusion", "authors": ["Haonan Qiu", "Shiwei Zhang", "Yujie Wei", "Ruihang Chu", "Hangjie Yuan", "Xiang Wang", "Yingya Zhang", "Ziwei Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025, Project Page: this http URL , Code Repo: this https URL", "url": "http://arxiv.org/abs/2412.09626v2", "summary": "Visual diffusion models achieve remarkable progress, yet they are typically\ntrained at limited resolutions due to the lack of high-resolution data and\nconstrained computation resources, hampering their ability to generate\nhigh-fidelity images or videos at higher resolutions. Recent efforts have\nexplored tuning-free strategies to exhibit the untapped potential\nhigher-resolution visual generation of pre-trained models. However, these\nmethods are still prone to producing low-quality visual content with repetitive\npatterns. The key obstacle lies in the inevitable increase in high-frequency\ninformation when the model generates visual content exceeding its training\nresolution, leading to undesirable repetitive patterns deriving from the\naccumulated errors. To tackle this challenge, we propose FreeScale, a\ntuning-free inference paradigm to enable higher-resolution visual generation\nvia scale fusion. Specifically, FreeScale processes information from different\nreceptive scales and then fuses it by extracting desired frequency components.\nExtensive experiments validate the superiority of our paradigm in extending the\ncapabilities of higher-resolution visual generation for both image and video\nmodels. Notably, compared with previous best-performing methods, FreeScale\nunlocks the 8k-resolution text-to-image generation for the first time.", "comment": "ICCV 2025, Project Page:\n  http://haonanqiu.com/projects/FreeScale.html, Code Repo:\n  https://github.com/ali-vilab/FreeScale", "pdf_url": "http://arxiv.org/pdf/2412.09626v2", "cate": "cs.CV", "date": "2024-12-12", "updated": "2025-07-11"}
{"id": "2507.08336", "title": "Distillation versus Contrastive Learning: How to Train Your Rerankers", "authors": ["Zhichao Xu", "Zhiqi Huang", "Shengyao Zhuang", "Ashim Gupta", "Vivek Srikumar"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08336v1", "summary": "Training text rerankers is crucial for information retrieval. Two primary\nstrategies are widely used: contrastive learning (optimizing directly on\nground-truth labels) and knowledge distillation (transferring knowledge from a\nlarger reranker). While both have been studied in the literature, a clear\ncomparison of their effectiveness for training cross-encoder rerankers under\npractical conditions is needed.\n  This paper empirically compares these strategies by training rerankers of\ndifferent sizes and architectures using both methods on the same data, with a\nstrong contrastive learning model acting as the distillation teacher. Our\nresults show that knowledge distillation generally yields better in-domain and\nout-of-domain ranking performance than contrastive learning when distilling\nfrom a larger teacher model. This finding is consistent across student model\nsizes and architectures. However, distilling from a teacher of the same\ncapacity does not provide the same advantage, particularly for out-of-domain\ntasks. These findings offer practical guidance for choosing a training strategy\nbased on available teacher models. Therefore, we recommend using knowledge\ndistillation to train smaller rerankers if a larger, more powerful teacher is\naccessible; in its absence, contrastive learning provides a strong and more\nreliable alternative otherwise.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08336v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08698", "title": "To buy or not to buy: deterministic rent-or-buy problems on node-weighted graphs", "authors": ["Sander Borst", "Moritz Venzin"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08698v1", "summary": "We study the rent-or-buy variant of the online Steiner forest problem on\nnode- and edge-weighted graphs. For $n$-node graphs with at most $\\bar{n}$\nnon-zero node-weights, and at most $\\tilde{k}$ different arriving terminal\npairs, we obtain a deterministic, $O(\\log n \\log \\bar{n})$-competitive\nalgorithm. This improves on the previous best, $O(\\log^4 n)$-competitive\nalgorithm obtained by the black-box reduction from (Bartal et al. 2021)\ncombined with the previously best deterministic algorithms for the simpler\n'buy-only' setting. We also obtain a deterministic, $O(\\bar{n}\\log\n\\tilde{k})$-competitive algorithm. This generalizes the $O(\\log\n\\tilde{k})$-competitive algorithm for the purely edge-weighted setting from\n(Umboh 2015). We also obtain a randomized, $O(\\log \\tilde{k} \\log\n\\bar{n})$-competitive algorithm. All previous approaches were based on the\nrandomized, black-box reduction from~\\cite{AwerbuchAzarBartal96} that achieves\na $O(\\log \\tilde{k} \\log n)$-competitive ratio when combined with an algorithm\nfor the 'buy-only' setting. Our key technical ingredient is a novel charging\nscheme to an instance of \\emph{online prize-collecting set cover}. This allows\nus to extend the witness-technique of (Umboh 2015) to the node-weighted setting\nand obtain refined guarantees with respect to $\\bar{n}$, already in the much\nsimpler 'buy-only' setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08698v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08553", "title": "Digital gazetteers: review and prospects for place name knowledge bases", "authors": ["Kalana Wijegunarathna", "Kristin Stock", "Christopher B. Jones"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08553v1", "summary": "Gazetteers typically store data on place names, place types and the\nassociated coordinates. They play an essential role in disambiguating place\nnames in online geographical information retrieval systems for navigation and\nmapping, detecting and disambiguating place names in text, and providing\ncoordinates. Currently there are many gazetteers in use derived from many\nsources, with no commonly accepted standard for encoding the data. Most\ngazetteers are also very limited in the extent to which they represent the\nmultiple facets of the named places yet they have potential to assist user\nsearch for locations with specific physical, commercial, social or cultural\ncharacteristics. With a view to understanding digital gazetteer technologies\nand advancing their future effectiveness for information retrieval, we provide\na review of data sources, components, software and data management\ntechnologies, data quality and volunteered data, and methods for matching\nsources that refer to the same real-world places. We highlight the need for\nfuture work on richer representation of named places, the temporal evolution of\nplace identity and location, and the development of more effective methods for\ndata integration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08553v1", "cate": "cs.IR", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.00994", "title": "PIAD-SRNN: Physics-Informed Adaptive Decomposition in State-Space RNN", "authors": ["Ahmad Mohammadshirazi", "Pinaki Prasad Guha Neogi", "Rajiv Ramnath"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.00994v2", "summary": "Time series forecasting often demands a trade-off between accuracy and\nefficiency. While recent Transformer models have improved forecasting\ncapabilities, they come with high computational costs. Linear-based models have\nshown better accuracy than Transformers but still fall short of ideal\nperformance. We propose PIAD-SRNN, a physics-informed adaptive decomposition\nstate-space RNN, that separates seasonal and trend components and embeds domain\nequations in a recurrent framework. We evaluate PIAD-SRNN's performance on\nindoor air quality datasets, focusing on CO2 concentration prediction across\nvarious forecasting horizons, and results demonstrate that it consistently\noutperforms SoTA models in both long-term and short-term time series\nforecasting, including transformer-based architectures, in terms of both MSE\nand MAE. Besides proposing PIAD-SRNN which balances accuracy with efficiency,\nthis paper also provides four curated datasets. Code and data:\nhttps://github.com/ahmad-shirazi/DSSRNN", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.00994v2", "cate": "cs.LG", "date": "2024-12-01", "updated": "2025-07-10"}
{"id": "2507.08518", "title": "Data Depth as a Risk", "authors": ["Arturo Castellanos", "Pavlo Mozharovskyi"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08518v1", "summary": "Data depths are score functions that quantify in an unsupervised fashion how\ncentral is a point inside a distribution, with numerous applications such as\nanomaly detection, multivariate or functional data analysis, arising across\nvarious fields. The halfspace depth was the first depth to aim at generalising\nthe notion of quantile beyond the univariate case. Among the existing variety\nof depth definitions, it remains one of the most used notions of data depth.\nTaking a different angle from the quantile point of view, we show that the\nhalfspace depth can also be regarded as the minimum loss of a set of\nclassifiers for a specific labelling of the points. By changing the loss or the\nset of classifiers considered, this new angle naturally leads to a family of\n\"loss depths\", extending to well-studied classifiers such as, e.g., SVM or\nlogistic regression, among others. This framework directly inherits\ncomputational efficiency of existing machine learning algorithms as well as\ntheir fast statistical convergence rates, and opens the data depth realm to the\nhigh-dimensional setting. Furthermore, the new loss depths highlight a\nconnection between the dataset and the right amount of complexity or simplicity\nof the classifiers. The simplicity of classifiers as well as the interpretation\nas a risk makes our new kind of data depth easy to explain, yet efficient for\nanomaly detection, as is shown by experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08518v1", "cate": "stat.ML", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.11540", "title": "SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer", "authors": ["Jiaxu Wan", "Hong Zhang", "Ziqi He", "Yangyan Deng", "Qishu Wang", "Ding Yuan", "Yifan Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accept by ICCV2025", "url": "http://arxiv.org/abs/2412.11540v2", "summary": "Point transformers have demonstrated remarkable progress in 3D understanding\nthrough expanded receptive fields (RF), but further expanding the RF leads to\ndilution in group attention and decreases detailed feature extraction\ncapability. Proxy, which serves as abstract representations for simplifying\nfeature maps, enables global RF. However, existing proxy-based approaches face\ncritical limitations: Global proxies incur quadratic complexity for large-scale\npoint clouds and suffer positional ambiguity, while local proxy alternatives\nstruggle with 1) Unreliable sampling from the geometrically diverse point\ncloud, 2) Inefficient proxy interaction computation, and 3) Imbalanced\nlocal-global information fusion; To address these challenges, we propose Sparse\nProxy Point Transformer (SP$^{2}$T) -- a local proxy-based dual-stream point\ntransformer with three key innovations: First, for reliable sampling,\nspatial-wise proxy sampling with vertex-based associations enables robust\nsampling on geometrically diverse point clouds. Second, for efficient proxy\ninteraction, sparse proxy attention with a table-based relative bias\neffectively achieves the interaction with efficient map-reduce computation.\nThird, for local-global information fusion, our dual-stream architecture\nmaintains local-global balance through parallel branches. Comprehensive\nexperiments reveal that SP$^{2}$T sets state-of-the-art results with acceptable\nlatency on indoor and outdoor 3D comprehension benchmarks, demonstrating marked\nimprovement (+3.8% mIoU vs. SPoTr@S3DIS, +22.9% mIoU vs. PointASNL@Sem.KITTI)\ncompared to other proxy-based point cloud methods.", "comment": "Accept by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2412.11540v2", "cate": "cs.CV", "date": "2024-12-16", "updated": "2025-07-11"}
{"id": "2507.08339", "title": "What Factors Affect LLMs and RLLMs in Financial Question Answering?", "authors": ["Peng Wang", "Xuesi Hu", "Jiageng Wu", "Yuntao Zou", "Qiancheng Zhang", "Dagang Li"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Preprint", "url": "http://arxiv.org/abs/2507.08339v1", "summary": "Recently, the development of large language models (LLMs) and reasoning large\nlanguage models (RLLMs) have gained considerable attention from many\nresearchers. RLLMs enhance the reasoning capabilities of LLMs through Long\nChain-of-Thought (Long CoT) processes, significantly improving the performance\nof LLMs in addressing complex problems. However, there are few works that\nsystematically explore what methods can fully unlock the performance of LLMs\nand RLLMs within the financial domain. To investigate the impact of various\nmethods on LLMs and RLLMs, we utilize five LLMs and three RLLMs to assess the\neffects of prompting methods, agentic frameworks, and multilingual alignment\nmethods on financial question-answering tasks. Our research findings indicate:\n(1) Current prompting methods and agent frameworks enhance the performance of\nLLMs in financial question answering by simulating Long CoT; (2) RLLMs possess\ninherent Long CoT capabilities, which limits the effectiveness of conventional\nmethods in further enhancing their performance; (3) Current advanced\nmultilingual alignment methods primarily improve the multilingual performance\nof LLMs by extending the reasoning length, which yields minimal benefits for\nRLLMs. We hope that this study can serve as an important reference for LLMs and\nRLLMs in the field of financial question answering.", "comment": "Preprint", "pdf_url": "http://arxiv.org/pdf/2507.08339v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08758", "title": "On Fair Epsilon Net and Geometric Hitting Set", "authors": ["Mohsen Dehghankar", "Stavros Sintos", "Abolfazl Asudeh"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08758v1", "summary": "Fairness has emerged as a formidable challenge in data-driven decisions. Many\nof the data problems, such as creating compact data summaries for approximate\nquery processing, can be effectively tackled using concepts from computational\ngeometry, such as $\\varepsilon$-nets. However, these powerful tools have yet to\nbe examined from the perspective of fairness. To fill this research gap, we add\nfairness to classical geometric approximation problems of $\\varepsilon$-net,\n$\\varepsilon$-sample, and geometric hitting set. We introduce and address two\nnotions of group fairness: demographic parity, which requires preserving group\nproportions from the input distribution, and custom-ratios fairness, which\ndemands satisfying arbitrary target ratios. We develop two algorithms to\nenforce fairness: one based on sampling and another on discrepancy theory. The\nsampling-based algorithm is faster and computes a fair $\\varepsilon$-net of\nsize which is only larger by a $\\log(k)$ factor compared to the standard\n(unfair) $\\varepsilon$-net, where $k$ is the number of demographic groups. The\ndiscrepancy-based algorithm is slightly slower (for bounded VC dimension), but\nit computes a smaller fair $\\varepsilon$-net. Notably, we reduce the fair\ngeometric hitting set problem to finding fair $\\varepsilon$-nets. This results\nin a $O(\\log \\mathsf{OPT} \\times \\log k)$ approximation of a fair geometric\nhitting set. Additionally, we show that under certain input distributions,\nconstructing fair $\\varepsilon$-samples can be infeasible, highlighting\nlimitations in fair sampling. Beyond the theoretical guarantees, our\nexperimental results validate the practical effectiveness of the proposed\nalgorithms. In particular, we achieve zero unfairness with only a modest\nincrease in output size compared to the unfair setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08758v1", "cate": "cs.DS", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07030", "title": "UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations", "authors": ["Fengran Mo", "Yifan Gao", "Chuan Meng", "Xin Liu", "Zhuofeng Wu", "Kelong Mao", "Zhengyang Wang", "Pei Chen", "Zheng Li", "Xian Li", "Bing Yin", "Meng Jiang"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by ACL 2025 (main)", "url": "http://arxiv.org/abs/2507.07030v1", "summary": "The rapid advancement of conversational search systems revolutionizes how\ninformation is accessed by enabling the multi-turn interaction between the user\nand the system. Existing conversational search systems are usually built with\ntwo different models. This separation restricts the system from leveraging the\nintrinsic knowledge of the models simultaneously, which cannot ensure the\neffectiveness of retrieval benefiting the generation. The existing studies for\ndeveloping unified models cannot fully address the aspects of understanding\nconversational context, managing retrieval independently, and generating\nresponses. In this paper, we explore how to unify dense retrieval and response\ngeneration for large language models in conversation. We conduct joint\nfine-tuning with different objectives and design two mechanisms to reduce the\ninconsistency risks while mitigating data discrepancy. The evaluations on five\nconversational search datasets demonstrate that our unified model can mutually\nimprove both tasks and outperform the existing baselines.", "comment": "Accepted by ACL 2025 (main)", "pdf_url": "http://arxiv.org/pdf/2507.07030v1", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.08320", "title": "NeurOptimisation: The Spiking Way to Evolve", "authors": ["Jorge Mario Cruz-Duarte", "El-Ghazali Talbi"], "categories": ["cs.NE", "90C26, 68T07, 65K10, 68W10, 68W50", "I.2.6; I.2.8; I.2.11; G.1.6; I.6.3; F.1.1"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Submitted to the IEEE Transactions on Evolutionary Computation (under review)", "url": "http://arxiv.org/abs/2507.08320v1", "summary": "The increasing energy footprint of artificial intelligence systems urges\nalternative computational models that are both efficient and scalable.\nNeuromorphic Computing (NC) addresses this challenge by empowering event-driven\nalgorithms that operate with minimal power requirements through biologically\ninspired spiking dynamics. We present the NeurOptimiser, a fully spike-based\noptimisation framework that materialises the neuromorphic-based metaheuristic\nparadigm through a decentralised NC system. The proposed approach comprises a\npopulation of Neuromorphic Heuristic Units (NHUs), each combining spiking\nneuron dynamics with spike-triggered perturbation heuristics to evolve\ncandidate solutions asynchronously. The NeurOptimiser's coordination arises\nthrough native spiking mechanisms that support activity propagation, local\ninformation sharing, and global state updates without external orchestration.\nWe implement this framework on Intel's Lava platform, targeting the Loihi 2\nchip, and evaluate it on the noiseless BBOB suite up to 40 dimensions. We\ndeploy several NeurOptimisers using different configurations, mainly\nconsidering dynamic systems such as linear and Izhikevich models for spiking\nneural dynamics, and fixed and Differential Evolution mutation rules for\nspike-triggered heuristics. Although these configurations are implemented as a\nproof of concept, we document and outline further extensions and improvements\nto the framework implementation. Results show that the proposed approach\nexhibits structured population dynamics, consistent convergence, and\nmilliwatt-level power feasibility. They also position spike-native MHs as a\nviable path toward real-time, low-energy, and decentralised optimisation.", "comment": "Submitted to the IEEE Transactions on Evolutionary Computation (under\n  review)", "pdf_url": "http://arxiv.org/pdf/2507.08320v1", "cate": "cs.NE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.02367", "title": "Field Matching: an Electrostatic Paradigm to Generate and Transfer Data", "authors": ["Alexander Kolesov", "Manukhov Stepan", "Vladimir V. Palyulin", "Alexander Korotin"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Proceedings of the 42nd International Conference on Machine. Learning, Vancouver, Canada. PMLR 267, 2025", "url": "http://arxiv.org/abs/2502.02367v2", "summary": "We propose Electrostatic Field Matching (EFM), a novel method that is\nsuitable for both generative modeling and distribution transfer tasks. Our\napproach is inspired by the physics of an electrical capacitor. We place source\nand target distributions on the capacitor plates and assign them positive and\nnegative charges, respectively. We then learn the electrostatic field of the\ncapacitor using a neural network approximator. To map the distributions to each\nother, we start at one plate of the capacitor and move the samples along the\nlearned electrostatic field lines until they reach the other plate. We\ntheoretically justify that this approach provably yields the distribution\ntransfer. In practice, we demonstrate the performance of our EFM in toy and\nimage data experiments.", "comment": "Proceedings of the 42nd International Conference on Machine.\n  Learning, Vancouver, Canada. PMLR 267, 2025", "pdf_url": "http://arxiv.org/pdf/2502.02367v2", "cate": "cs.LG", "date": "2025-02-04", "updated": "2025-07-11"}
{"id": "2507.08543", "title": "Quantum Algorithms for Projection-Free Sparse Convex Optimization", "authors": ["Jianhao He", "John C. S. Lui"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08543v1", "summary": "This paper considers the projection-free sparse convex optimization problem\nfor the vector domain and the matrix domain, which covers a large number of\nimportant applications in machine learning and data science. For the vector\ndomain $\\mathcal{D} \\subset \\mathbb{R}^d$, we propose two quantum algorithms\nfor sparse constraints that finds a $\\varepsilon$-optimal solution with the\nquery complexity of $O(\\sqrt{d}/\\varepsilon)$ and $O(1/\\varepsilon)$ by using\nthe function value oracle, reducing a factor of $O(\\sqrt{d})$ and $O(d)$ over\nthe best classical algorithm, respectively, where $d$ is the dimension. For the\nmatrix domain $\\mathcal{D} \\subset \\mathbb{R}^{d\\times d}$, we propose two\nquantum algorithms for nuclear norm constraints that improve the time\ncomplexity to $\\tilde{O}(rd/\\varepsilon^2)$ and\n$\\tilde{O}(\\sqrt{r}d/\\varepsilon^3)$ for computing the update step, reducing at\nleast a factor of $O(\\sqrt{d})$ over the best classical algorithm, where $r$ is\nthe rank of the gradient matrix. Our algorithms show quantum advantages in\nprojection-free sparse convex optimization problems as they outperform the\noptimal classical methods in dependence on the dimension $d$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08543v1", "cate": "quant-ph", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.05928", "title": "ClinKD: Cross-Modal Clinical Knowledge Distiller For Multi-Task Medical Images", "authors": ["Hongyu Ge", "Longkun Hao", "Zihui Xu", "Zhenxin Lin", "Bin Li", "Shoujun Zhou", "Hongjin Zhao", "Yihang Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.05928v4", "summary": "Medical Visual Question Answering (Med-VQA) represents a critical and\nchallenging subtask within the general VQA domain. Despite significant\nadvancements in general VQA, multimodal large language models (MLLMs) still\nexhibit substantial limitations when handling multi-task VQA scenarios. These\nlimitations manifest through erroneous spatial localization and\nmisinterpretation of medical images, which primarily arise from two fundamental\nissues: inadequate image-text alignment and insufficient domain-specified\nknowledge for medical applications. To address these issues, we introduce the\nCross-Modal Clinical Knowledge Distiller (ClinKD), an innovative framework\ndesigned to enhance image-text alignment and establish more effective medical\nknowledge transformation mechanisms, which enables MLLMs to perform better even\nwhen lacking prior medical knowledge. Our extensive experimental evaluations\ndemonstrate that the ClinKD achieves state-of-the-art performance on several\ndatasets which are challenging for Med-VQA task. The results indicate that our\napproach not only significantly improves image-text alignment but also\neffectively enables MLLMs to adapt to the medical knowledge. The source code\nfor ClinKD is available at: https://github.com/overloadedHenry/ClinKD.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.05928v4", "cate": "cs.CV", "date": "2025-02-09", "updated": "2025-07-11"}
{"id": "2507.08342", "title": "Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization", "authors": ["Itai Mondshine", "Tzuf Paz-Argaman", "Reut Tsarfaty"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Main", "url": "http://arxiv.org/abs/2507.08342v1", "summary": "Automatic n-gram based metrics such as ROUGE are widely used for evaluating\ngenerative tasks such as summarization. While these metrics are considered\nindicative (even if imperfect) of human evaluation for English, their\nsuitability for other languages remains unclear. To address this, we\nsystematically assess evaluation metrics for generation both n-gram-based and\nneural based to evaluate their effectiveness across languages and tasks.\nSpecifically, we design a large-scale evaluation suite across eight languages\nfrom four typological families: agglutinative, isolating, low-fusional, and\nhigh-fusional, spanning both low- and high-resource settings, to analyze their\ncorrelation with human judgments. Our findings highlight the sensitivity of\nevaluation metrics to the language type. For example, in fusional languages,\nn-gram-based metrics show lower correlation with human assessments compared to\nisolating and agglutinative languages. We also demonstrate that proper\ntokenization can significantly mitigate this issue for morphologically rich\nfusional languages, sometimes even reversing negative trends. Additionally, we\nshow that neural-based metrics specifically trained for evaluation, such as\nCOMET, consistently outperform other neural metrics and better correlate with\nhuman judgments in low-resource languages. Overall, our analysis highlights the\nlimitations of n-gram metrics for fusional languages and advocates for greater\ninvestment in neural-based metrics trained for evaluation tasks.", "comment": "ACL 2025 Main", "pdf_url": "http://arxiv.org/pdf/2507.08342v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.08139", "title": "Finding a solution to the Erdős-Ginzburg-Ziv theorem in $O(n\\log\\log\\log n)$ time", "authors": ["Yui Hin Arvin Leung"], "categories": ["math.CO", "cs.DS"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "Comments:      22 pages, 0 figures", "url": "http://arxiv.org/abs/2507.08139v1", "summary": "The Erd\\H{o}s-Ginzburg-Ziv theorem states that for any sequence of $2n-1$\nintegers, there exists a subsequence of $n$ elements whose sum is divisible by\n$n$. In this article, we provide a simple, practical $O(n\\log\\log n)$ algorithm\nand a theoretical $O(n\\log\\log\\log n)$ algorithm, both of which improve upon\nthe best previously known $O(n\\log n)$ approach. This shows that a specific\nvariant of boolean convolution can be implemented in time faster than the usual\n$O(n\\log n)$ expected from FFT-based methods.", "comment": "22 pages, 0 figures", "pdf_url": "http://arxiv.org/pdf/2507.08139v1", "cate": "math.CO", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2411.11767", "title": "Drowning in Documents: Consequences of Scaling Reranker Inference", "authors": ["Mathew Jacob", "Erik Lindgren", "Matei Zaharia", "Michael Carbin", "Omar Khattab", "Andrew Drozdov"], "categories": ["cs.IR", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted to ReNeuIR 2025 Workshop at SIGIR 2025 Conference", "url": "http://arxiv.org/abs/2411.11767v2", "summary": "Rerankers, typically cross-encoders, are computationally intensive but are\nfrequently used because they are widely assumed to outperform cheaper initial\nIR systems. We challenge this assumption by measuring reranker performance for\nfull retrieval, not just re-scoring first-stage retrieval. To provide a more\nrobust evaluation, we prioritize strong first-stage retrieval using modern\ndense embeddings and test rerankers on a variety of carefully chosen,\nchallenging tasks, including internally curated datasets to avoid\ncontamination, and out-of-domain ones. Our empirical results reveal a\nsurprising trend: the best existing rerankers provide initial improvements when\nscoring progressively more documents, but their effectiveness gradually\ndeclines and can even degrade quality beyond a certain limit. We hope that our\nfindings will spur future research to improve reranking.", "comment": "Accepted to ReNeuIR 2025 Workshop at SIGIR 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2411.11767v2", "cate": "cs.IR", "date": "2024-11-18", "updated": "2025-07-11"}
{"id": "2507.08368", "title": "Enhancing Parameter Control Policies with State Information", "authors": ["Gianluca Covini", "Denis Antipov", "Carola Doerr"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      To appear in the Proc. of FOGA, the 18th ACM/SIGEVO Conference on Foundations of Genetic Algorithms", "url": "http://arxiv.org/abs/2507.08368v1", "summary": "Parameter control and dynamic algorithm configuration study how to\ndynamically choose suitable configurations of a parametrized algorithm during\nthe optimization process. Despite being an intensively researched topic in\nevolutionary computation, optimal control policies are known only for very few\ncases, limiting the development of automated approaches to achieve them.\n  With this work we propose four new benchmarks for which we derive optimal or\nclose-to-optimal control policies. More precisely, we consider the optimization\nof the \\LeadingOnes function via RLS$_{k}$, a local search algorithm allowing\nfor a dynamic choice of the mutation strength $k$. The benchmarks differ in\nwhich information the algorithm can exploit to set its parameters and to select\noffspring. In existing running time results, the exploitable information is\ntypically limited to the quality of the current-best solution. In this work, we\nconsider how additional information about the current state of the algorithm\ncan help to make better choices of parameters, and how these choices affect the\nperformance. Namely, we allow the algorithm to use information about the\ncurrent \\OneMax value, and we find that it allows much better parameter\nchoices, especially in marginal states. Although those states are rarely\nvisited by the algorithm, such policies yield a notable speed-up in terms of\nexpected runtime. This makes the proposed benchmarks a challenging, but\npromising testing ground for analysis of parameter control methods in rich\nstate spaces and of their ability to find optimal policies by catching the\nperformance improvements yielded by correct parameter choices.", "comment": "To appear in the Proc. of FOGA, the 18th ACM/SIGEVO Conference on\n  Foundations of Genetic Algorithms", "pdf_url": "http://arxiv.org/pdf/2507.08368v1", "cate": "cs.NE", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.08525", "title": "GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training", "authors": ["Tong Wei", "Yijun Yang", "Junliang Xing", "Yuanchun Shi", "Zongqing Lu", "Deheng Ye"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.08525v2", "summary": "Reinforcement learning with verifiable outcome rewards (RLVR) has effectively\nscaled up chain-of-thought (CoT) reasoning in large language models (LLMs).\nYet, its efficacy in training vision-language model (VLM) agents for\ngoal-directed action reasoning in visual environments is less established. This\nwork investigates this problem through extensive experiments on complex card\ngames, such as 24 points, and embodied tasks from ALFWorld. We find that when\nrewards are based solely on action outcomes, RL fails to incentivize CoT\nreasoning in VLMs, instead leading to a phenomenon we termed thought collapse,\ncharacterized by a rapid loss of diversity in the agent's thoughts,\nstate-irrelevant and incomplete reasoning, and subsequent invalid actions,\nresulting in negative rewards. To counteract thought collapse, we highlight the\nnecessity of process guidance and propose an automated corrector that evaluates\nand refines the agent's reasoning at each RL step. This simple and scalable GTR\n(Guided Thought Reinforcement) framework trains reasoning and action\nsimultaneously without the need for dense, per-step human labeling. Our\nexperiments demonstrate that GTR significantly enhances the performance and\ngeneralization of the LLaVA-7b model across various visual environments,\nachieving 3-5 times higher task success rates compared to SoTA models with\nnotably smaller model sizes.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.08525v2", "cate": "cs.CV", "date": "2025-03-11", "updated": "2025-07-11"}
{"id": "2507.08660", "title": "The Impact of Automatic Speech Transcription on Speaker Attribution", "authors": ["Cristina Aggazzotti", "Matthew Wiesner", "Elizabeth Allyn Smith", "Nicholas Andrews"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08660v1", "summary": "Speaker attribution from speech transcripts is the task of identifying a\nspeaker from the transcript of their speech based on patterns in their language\nuse. This task is especially useful when the audio is unavailable (e.g.\ndeleted) or unreliable (e.g. anonymized speech). Prior work in this area has\nprimarily focused on the feasibility of attributing speakers using transcripts\nproduced by human annotators. However, in real-world settings, one often only\nhas more errorful transcripts produced by automatic speech recognition (ASR)\nsystems. In this paper, we conduct what is, to our knowledge, the first\ncomprehensive study of the impact of automatic transcription on speaker\nattribution performance. In particular, we study the extent to which speaker\nattribution performance degrades in the face of transcription errors, as well\nas how properties of the ASR system impact attribution. We find that\nattribution is surprisingly resilient to word-level transcription errors and\nthat the objective of recovering the true transcript is minimally correlated\nwith attribution performance. Overall, our findings suggest that speaker\nattribution on more errorful transcripts produced by ASR is as good, if not\nbetter, than attribution based on human-transcribed data, possibly because ASR\ntranscription errors can capture speaker-specific features revealing of speaker\nidentity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08660v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.17414", "title": "X-Dancer: Expressive Music to Human Dance Video Generation", "authors": ["Zeyuan Chen", "Hongyi Xu", "Guoxian Song", "You Xie", "Chenxu Zhang", "Xin Chen", "Chao Wang", "Di Chang", "Linjie Luo"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICCV 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2502.17414v2", "summary": "We present X-Dancer, a novel zero-shot music-driven image animation pipeline\nthat creates diverse and long-range lifelike human dance videos from a single\nstatic image. As its core, we introduce a unified transformer-diffusion\nframework, featuring an autoregressive transformer model that synthesize\nextended and music-synchronized token sequences for 2D body, head and hands\nposes, which then guide a diffusion model to produce coherent and realistic\ndance video frames. Unlike traditional methods that primarily generate human\nmotion in 3D, X-Dancer addresses data limitations and enhances scalability by\nmodeling a wide spectrum of 2D dance motions, capturing their nuanced alignment\nwith musical beats through readily available monocular videos. To achieve this,\nwe first build a spatially compositional token representation from 2D human\npose labels associated with keypoint confidences, encoding both large\narticulated body movements (e.g., upper and lower body) and fine-grained\nmotions (e.g., head and hands). We then design a music-to-motion transformer\nmodel that autoregressively generates music-aligned dance pose token sequences,\nincorporating global attention to both musical style and prior motion context.\nFinally we leverage a diffusion backbone to animate the reference image with\nthese synthesized pose tokens through AdaIN, forming a fully differentiable\nend-to-end framework. Experimental results demonstrate that X-Dancer is able to\nproduce both diverse and characterized dance videos, substantially\noutperforming state-of-the-art methods in term of diversity, expressiveness and\nrealism. Code and model will be available for research purposes.", "comment": "ICCV 2025. Project Page: https://zeyuan-chen.com/X-Dancer/", "pdf_url": "http://arxiv.org/pdf/2502.17414v2", "cate": "cs.CV", "date": "2025-02-24", "updated": "2025-07-11"}
{"id": "2507.08371", "title": "The Curious Case of Factuality Finetuning: Models' Internal Beliefs Can Improve Factuality", "authors": ["Benjamin Newman", "Abhilasha Ravichander", "Jaehun Jung", "Rui Xin", "Hamish Ivison", "Yegor Kuznetsov", "Pang Wei Koh", "Yejin Choi"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages, 4 figures, 16 tables", "url": "http://arxiv.org/abs/2507.08371v1", "summary": "Language models are prone to hallucination - generating text that is\nfactually incorrect. Finetuning models on high-quality factual information can\npotentially reduce hallucination, but concerns remain; obtaining factual gold\ndata can be expensive and training on correct but unfamiliar data may\npotentially lead to even more downstream hallucination. What data should\npractitioners finetune on to mitigate hallucinations in language models? In\nthis work, we study the relationship between the factuality of finetuning data\nand the prevalence of hallucinations in long-form generation tasks.\nCounterintuitively, we find that finetuning on factual gold data is not as\nhelpful as finetuning on model-generated data that models believe to be\nfactual. Next, we evaluate filtering strategies applied on both factual gold\ndata and model-generated data, and find that finetuning on model-generated data\nthat is filtered by models' own internal judgments often leads to better\noverall factuality compared to other configurations: training on gold data\nfiltered by models' judgments, training on gold data alone, or training on\nmodel-generated data that is supported by gold data. These factuality\nimprovements transfer across three domains we study, suggesting that a models'\nown beliefs can provide a powerful signal for factuality.", "comment": "29 pages, 4 figures, 16 tables", "pdf_url": "http://arxiv.org/pdf/2507.08371v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2402.08830", "title": "Sequence graphs realizations and ambiguity in language models", "authors": ["Sammy Khalife", "Yann Ponty", "Laurent Bulteau"], "categories": ["cs.DS", "cs.CC", "cs.CL"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.08830v2", "summary": "Several popular language models represent local contexts in an input text $x$\nas bags of words. Such representations are naturally encoded by a sequence\ngraph whose vertices are the distinct words occurring in $x$, with edges\nrepresenting the (ordered) co-occurrence of two words within a sliding window\nof size $w$. However, this compressed representation is not generally\nbijective: some may be ambiguous, admitting several realizations as a sequence,\nwhile others may not admit any realization. In this paper, we study the\nrealizability and ambiguity of sequence graphs from a combinatorial and\nalgorithmic point of view. We consider the existence and enumeration of\nrealizations of a sequence graph under multiple settings: window size $w$,\npresence/absence of graph orientation, and presence/absence of weights\n(multiplicities). When $w=2$, we provide polynomial time algorithms for\nrealizability and enumeration in all cases except the undirected/weighted\nsetting, where we show the $\\#$P-hardness of enumeration. For $w \\ge 3$, we\nprove the hardness of all variants, even when $w$ is considered as a constant,\nwith the notable exception of the undirected unweighted case for which we\npropose XP algorithms for both problems, tight due to a corresponding\n$W[1]-$hardness result. We conclude with an integer program formulation to\nsolve the realizability problem, and a dynamic programming algorithm to solve\nthe enumeration problem in instances of moderate sizes. This work leaves open\nthe membership to NP of both problems, a non-trivial question due to the\nexistence of minimum realizations having size exponential on the instance\nencoding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.08830v2", "cate": "cs.DS", "date": "2024-02-13", "updated": "2025-07-11"}
{"id": "2504.01403", "title": "Generative Retrieval and Alignment Model: A New Paradigm for E-commerce Retrieval", "authors": ["Ming Pang", "Chunyuan Yuan", "Xiaoyu He", "Zheng Fang", "Donghao Xie", "Fanyi Qu", "Xue Jiang", "Changping Peng", "Zhangang Lin", "Ching Law", "Jingping Shao"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted by WWW2025", "url": "http://arxiv.org/abs/2504.01403v2", "summary": "Traditional sparse and dense retrieval methods struggle to leverage general\nworld knowledge and often fail to capture the nuanced features of queries and\nproducts. With the advent of large language models (LLMs), industrial search\nsystems have started to employ LLMs to generate identifiers for product\nretrieval. Commonly used identifiers include (1) static/semantic IDs and (2)\nproduct term sets. The first approach requires creating a product ID system\nfrom scratch, missing out on the world knowledge embedded within LLMs. While\nthe second approach leverages this general knowledge, the significant\ndifference in word distribution between queries and products means that\nproduct-based identifiers often do not align well with user search queries,\nleading to missed product recalls. Furthermore, when queries contain numerous\nattributes, these algorithms generate a large number of identifiers, making it\ndifficult to assess their quality, which results in low overall recall\nefficiency.\n  To address these challenges, this paper introduces a novel e-commerce\nretrieval paradigm: the Generative Retrieval and Alignment Model (GRAM). GRAM\nemploys joint training on text information from both queries and products to\ngenerate shared text identifier codes, effectively bridging the gap between\nqueries and products. This approach not only enhances the connection between\nqueries and products but also improves inference efficiency. The model uses a\nco-alignment strategy to generate codes optimized for maximizing retrieval\nefficiency. Additionally, it introduces a query-product scoring mechanism to\ncompare product values across different codes, further boosting retrieval\nefficiency. Extensive offline and online A/B testing demonstrates that GRAM\nsignificantly outperforms traditional models and the latest generative\nretrieval models, confirming its effectiveness and practicality.", "comment": "Accepted by WWW2025", "pdf_url": "http://arxiv.org/pdf/2504.01403v2", "cate": "cs.IR", "date": "2025-04-02", "updated": "2025-07-11"}
{"id": "2507.08253", "title": "Massively parallel and universal approximation of nonlinear functions using diffractive processors", "authors": ["Md Sadman Sakib Rahman", "Yuhang Li", "Xilin Yang", "Shiqi Chen", "Aydogan Ozcan"], "categories": ["physics.optics", "cs.NE", "physics.app-ph"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      28 Pages, 7 Figures", "url": "http://arxiv.org/abs/2507.08253v1", "summary": "Nonlinear computation is essential for a wide range of information processing\ntasks, yet implementing nonlinear functions using optical systems remains a\nchallenge due to the weak and power-intensive nature of optical nonlinearities.\nOvercoming this limitation without relying on nonlinear optical materials could\nunlock unprecedented opportunities for ultrafast and parallel optical computing\nsystems. Here, we demonstrate that large-scale nonlinear computation can be\nperformed using linear optics through optimized diffractive processors composed\nof passive phase-only surfaces. In this framework, the input variables of\nnonlinear functions are encoded into the phase of an optical wavefront, e.g.,\nvia a spatial light modulator (SLM), and transformed by an optimized\ndiffractive structure with spatially varying point-spread functions to yield\noutput intensities that approximate a large set of unique nonlinear functions,\nall in parallel. We provide proof establishing that this architecture serves as\na universal function approximator for an arbitrary set of bandlimited nonlinear\nfunctions, also covering multi-variate and complex-valued functions. We also\nnumerically demonstrate the parallel computation of one million distinct\nnonlinear functions, accurately executed at wavelength-scale spatial density at\nthe output of a diffractive optical processor. Furthermore, we experimentally\nvalidated this framework using in situ optical learning and approximated 35\nunique nonlinear functions in a single shot using a compact setup consisting of\nan SLM and an image sensor. These results establish diffractive optical\nprocessors as a scalable platform for massively parallel universal nonlinear\nfunction approximation, paving the way for new capabilities in analog optical\ncomputing based on linear materials.", "comment": "28 Pages, 7 Figures", "pdf_url": "http://arxiv.org/pdf/2507.08253v1", "cate": "physics.optics", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.11924", "title": "REGEN: A Dataset and Benchmarks with Natural Language Critiques and Narratives", "authors": ["Kun Su", "Krishna Sayana", "Hubert Pham", "James Pine", "Yuri Vasilevski", "Raghavendra Vasudeva", "Marialena Kyriakidi", "Liam Hebert", "Ambarish Jash", "Anushya Subbiah", "Sukhdeep Sodhi"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.11924v2", "summary": "This paper introduces a novel dataset REGEN (Reviews Enhanced with GEnerative\nNarratives), designed to benchmark the conversational capabilities of\nrecommender Large Language Models (LLMs), addressing the limitations of\nexisting datasets that primarily focus on sequential item prediction. REGEN\nextends the Amazon Product Reviews dataset by inpainting two key natural\nlanguage features: (1) user critiques, representing user \"steering\" queries\nthat lead to the selection of a subsequent item, and (2) narratives, rich\ntextual outputs associated with each recommended item taking into account prior\ncontext. The narratives include product endorsements, purchase explanations,\nand summaries of user preferences.\n  Further, we establish an end-to-end modeling benchmark for the task of\nconversational recommendation, where models are trained to generate both\nrecommendations and corresponding narratives conditioned on user history (items\nand critiques). For this joint task, we introduce a modeling framework LUMEN\n(LLM-based Unified Multi-task Model with Critiques, Recommendations, and\nNarratives) which uses an LLM as a backbone for critiquing, retrieval and\ngeneration. We also evaluate the dataset's quality using standard auto-rating\ntechniques and benchmark it by training both traditional and LLM-based\nrecommender models. Our results demonstrate that incorporating critiques\nenhances recommendation quality by enabling the recommender to learn language\nunderstanding and integrate it with recommendation signals. Furthermore, LLMs\ntrained on our dataset effectively generate both recommendations and contextual\nnarratives, achieving performance comparable to state-of-the-art recommenders\nand language models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.11924v2", "cate": "cs.CL", "date": "2025-03-14", "updated": "2025-07-11"}
{"id": "2507.08745", "title": "Hashing for Fast Pattern Set Selection", "authors": ["Maiju Karjalainen", "Pauli Miettinen"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      17 pages, 5 figures, to appear at ECML-PKDD 2025", "url": "http://arxiv.org/abs/2507.08745v1", "summary": "Pattern set mining, which is the task of finding a good set of patterns\ninstead of all patterns, is a fundamental problem in data mining. Many\ndifferent definitions of what constitutes a good set have been proposed in\nrecent years. In this paper, we consider the reconstruction error as a proxy\nmeasure for the goodness of the set, and concentrate on the adjacent problem of\nhow to find a good set efficiently. We propose a method based on bottom-k\nhashing for efficiently selecting the set and extend the method for the common\ncase where the patterns might only appear in approximate form in the data. Our\napproach has applications in tiling databases, Boolean matrix factorization,\nand redescription mining, among others. We show that our hashing-based approach\nis significantly faster than the standard greedy algorithm while obtaining\nalmost equally good results in both synthetic and real-world data sets.", "comment": "17 pages, 5 figures, to appear at ECML-PKDD 2025", "pdf_url": "http://arxiv.org/pdf/2507.08745v1", "cate": "cs.DB", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.07499", "title": "AthletePose3D: A Benchmark Dataset for 3D Human Pose Estimation and Kinematic Validation in Athletic Movements", "authors": ["Calvin Yeung", "Tomohiro Suzuki", "Ryota Tanaka", "Zhuoer Yin", "Keisuke Fujii"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Erratum: A preprocessing mistake occurred in one camera angle of the running motions. This has been corrected, the experiment re-run, and the results updated accordingly. Please note that the conclusions of the experiment and the overall paper remain unchanged", "url": "http://arxiv.org/abs/2503.07499v3", "summary": "Human pose estimation is a critical task in computer vision and sports\nbiomechanics, with applications spanning sports science, rehabilitation, and\nbiomechanical research. While significant progress has been made in monocular\n3D pose estimation, current datasets often fail to capture the complex,\nhigh-acceleration movements typical of competitive sports. In this work, we\nintroduce AthletePose3D, a novel dataset designed to address this gap.\nAthletePose3D includes 12 types of sports motions across various disciplines,\nwith approximately 1.3 million frames and 165 thousand individual postures,\nspecifically capturing high-speed, high-acceleration athletic movements. We\nevaluate state-of-the-art (SOTA) monocular 2D and 3D pose estimation models on\nthe dataset, revealing that models trained on conventional datasets perform\npoorly on athletic motions. However, fine-tuning these models on AthletePose3D\nnotably reduces the SOTA model mean per joint position error (MPJPE) from 214mm\nto 65mm-a reduction of over 69%. We also validate the kinematic accuracy of\nmonocular pose estimations through waveform analysis, highlighting strong\ncorrelations in joint angle estimations but limitations in velocity estimation.\nOur work provides a comprehensive evaluation of monocular pose estimation\nmodels in the context of sports, contributing valuable insights for advancing\nmonocular pose estimation techniques in high-performance sports environments.\nThe dataset, code, and model checkpoints are available at:\nhttps://github.com/calvinyeungck/AthletePose3D", "comment": "Erratum: A preprocessing mistake occurred in one camera angle of the\n  running motions. This has been corrected, the experiment re-run, and the\n  results updated accordingly. Please note that the conclusions of the\n  experiment and the overall paper remain unchanged", "pdf_url": "http://arxiv.org/pdf/2503.07499v3", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-11"}
{"id": "2507.08425", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "authors": ["Lu Xiang", "Yang Zhao", "Yaping Zhang", "Chengqing Zong"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08425v1", "summary": "Large Language Models (LLMs) have demonstrated their transformative potential\nacross numerous disciplinary studies, reshaping the existing research\nmethodologies and fostering interdisciplinary collaboration. However, a\nsystematic understanding of their integration into diverse disciplines remains\nunderexplored. This survey paper provides a comprehensive overview of the\napplication of LLMs in interdisciplinary studies, categorising research efforts\nfrom both a technical perspective and with regard to their applicability. From\na technical standpoint, key methodologies such as supervised fine-tuning,\nretrieval-augmented generation, agent-based approaches, and tool-use\nintegration are examined, which enhance the adaptability and effectiveness of\nLLMs in discipline-specific contexts. From the perspective of their\napplicability, this paper explores how LLMs are contributing to various\ndisciplines including mathematics, physics, chemistry, biology, and the\nhumanities and social sciences, demonstrating their role in discipline-specific\ntasks. The prevailing challenges are critically examined and the promising\nresearch directions are highlighted alongside the recent advances in LLMs. By\nproviding a comprehensive overview of the technical developments and\napplications in this field, this survey aims to serve as an invaluable resource\nfor the researchers who are navigating the complex landscape of LLMs in the\ncontext of interdisciplinary studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08425v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.07668", "title": "On Deterministically Finding an Element of High Order Modulo a Composite", "authors": ["Ziv Oznovich", "Ben Lee Volk"], "categories": ["cs.DS", "math.NT"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.07668v2", "summary": "We give a deterministic algorithm that, given a composite number $N$ and a\ntarget order $D \\ge N^{1/6}$, runs in time $D^{1/2+o(1)}$ and finds either an\nelement $a \\in \\mathbb{Z}_N^*$ of multiplicative order at least $D$, or a\nnontrivial factor of $N$. Our algorithm improves upon an algorithm of Hittmeir\n(arXiv:1608.08766), who designed a similar algorithm under the stronger\nassumption $D \\ge N^{2/5}$. Hittmeir's algorithm played a crucial role in the\nrecent breakthrough deterministic integer factorization algorithms of Hittmeir\nand Harvey (arXiv:2006.16729, arXiv:2010.05450, arXiv:2105.11105). When $N$ is\nassumed to have an $r$-power divisor with $r\\ge 2$, our algorithm provides the\nsame guarantees assuming $D \\ge N^{1/6r}$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.07668v2", "cate": "cs.DS", "date": "2025-06-09", "updated": "2025-07-11"}
{"id": "2410.10381", "title": "Collaborative filtering based on nonnegative/binary matrix factorization", "authors": ["Yukino Terui", "Yuka Inoue", "Yohei Hamakawa", "Kosuke Tatsumura", "Kazue Kudo"], "categories": ["cond-mat.stat-mech", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Statistical Mechanics (cond-mat.stat-mech)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures", "url": "http://arxiv.org/abs/2410.10381v3", "summary": "Collaborative filtering generates recommendations by exploiting user-item\nsimilarities based on rating data, which often contains numerous unrated items.\nThis paper proposes a nonnegative/binary matrix factorization (NBMF) algorithm\nmodified for collaborative filtering and demonstrates that utilizing a\nlow-latency Ising machine in NBMF is advantageous in terms of computation time.\nWhile previous studies have primarily applied NBMF to dense data, such as\nimages, this study applies a modified NBMF to sparse data. Results show the\nbenefits of using a low-latency Ising machine to implement the proposed method.", "comment": "12 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2410.10381v3", "cate": "cond-mat.stat-mech", "date": "2024-10-14", "updated": "2025-07-11"}
{"id": "2505.04165", "title": "TS-SNN: Temporal Shift Module for Spiking Neural Networks", "authors": ["Kairong Yu", "Tianqing Zhang", "Qi Xu", "Gang Pan", "Hongwei Wang"], "categories": ["cs.NE", "cs.AI"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      Accepted by ICML2025", "url": "http://arxiv.org/abs/2505.04165v5", "summary": "Spiking Neural Networks (SNNs) are increasingly recognized for their\nbiological plausibility and energy efficiency, positioning them as strong\nalternatives to Artificial Neural Networks (ANNs) in neuromorphic computing\napplications. SNNs inherently process temporal information by leveraging the\nprecise timing of spikes, but balancing temporal feature utilization with low\nenergy consumption remains a challenge. In this work, we introduce Temporal\nShift module for Spiking Neural Networks (TS-SNN), which incorporates a novel\nTemporal Shift (TS) module to integrate past, present, and future spike\nfeatures within a single timestep via a simple yet effective shift operation. A\nresidual combination method prevents information loss by integrating shifted\nand original features. The TS module is lightweight, requiring only one\nadditional learnable parameter, and can be seamlessly integrated into existing\narchitectures with minimal additional computational cost. TS-SNN achieves\nstate-of-the-art performance on benchmarks like CIFAR-10 (96.72\\%), CIFAR-100\n(80.28\\%), and ImageNet (70.61\\%) with fewer timesteps, while maintaining low\nenergy consumption. This work marks a significant step forward in developing\nefficient and accurate SNN architectures.", "comment": "Accepted by ICML2025", "pdf_url": "http://arxiv.org/pdf/2505.04165v5", "cate": "cs.NE", "date": "2025-05-07", "updated": "2025-07-11"}
{"id": "2507.08226", "title": "A Stokes-Brinkman-type formulation for the eigenvalue problem in porous media", "authors": ["Felipe Lepe", "Gonzalo Rivera", "Jesus Vellojin"], "categories": ["math.NA", "cs.NA", "35Q35, 65N15, 65N25, 65N30, 65N50"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08226v1", "summary": "In this paper we introduce and analyze, for two and three dimensions, a\nfinite element method to approximate the natural frequencies of a flow system\ngoverned by the Stokes-Brinkman equations. Here, the fluid presents the\ncapability of being within a porous media. Taking advantage of the Stokes\nregularity results for the solution, and considering inf-sup stable families of\nfinite elements, we prove convergence together with a priori and a posteriori\nerror estimates for the eigenvalues and eigenfunctions with the aid of the\ncompact operators theory. We report a series of numerical tests in order to\nconfirm the developed theory.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08226v1", "cate": "math.NA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.22589", "title": "Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012", "authors": ["Adam Breuer", "Bryce J. Dietrich", "Michael H. Crespin", "Matthew Butler", "J. A. Pryse", "Kosuke Imai"], "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      17 pages, 7 tables, 4 figures, and linked datasets", "url": "http://arxiv.org/abs/2503.22589v2", "summary": "This paper introduces the largest and most comprehensive dataset of US\npresidential campaign television advertisements, available in digital format.\nThe dataset also includes machine-searchable transcripts and high-quality\nsummaries designed to facilitate a variety of academic research. To date, there\nhas been great interest in collecting and analyzing US presidential campaign\nadvertisements, but the need for manual procurement and annotation led many to\nrely on smaller subsets. We design a large-scale parallelized, AI-based\nanalysis pipeline that automates the laborious process of preparing,\ntranscribing, and summarizing videos. We then apply this methodology to the\n9,707 presidential ads from the Julian P. Kanter Political Commercial Archive.\nWe conduct extensive human evaluations to show that these transcripts and\nsummaries match the quality of manually generated alternatives. We illustrate\nthe value of this data by including an application that tracks the genesis and\nevolution of current focal issue areas over seven decades of presidential\nelections. Our analysis pipeline and codebase also show how to use LLM-based\ntools to obtain high-quality summaries for other video datasets.", "comment": "17 pages, 7 tables, 4 figures, and linked datasets", "pdf_url": "http://arxiv.org/pdf/2503.22589v2", "cate": "cs.MM", "date": "2025-03-28", "updated": "2025-07-10"}
{"id": "2507.08796", "title": "Filter Equivariant Functions: A symmetric account of length-general extrapolation on lists", "authors": ["Owen Lewis", "Neil Ghani", "Andrew Dudzik", "Christos Perivolaropoulos", "Razvan Pascanu", "Petar Veličković"], "categories": ["cs.PL", "cs.LG"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "Comments:      18 pages, 2 figures", "url": "http://arxiv.org/abs/2507.08796v1", "summary": "What should a function that extrapolates beyond known input/output examples\nlook like? This is a tricky question to answer in general, as any function\nmatching the outputs on those examples can in principle be a correct\nextrapolant. We argue that a \"good\" extrapolant should follow certain kinds of\nrules, and here we study a particularly appealing criterion for rule-following\nin list functions: that the function should behave predictably even when\ncertain elements are removed. In functional programming, a standard way to\nexpress such removal operations is by using a filter function. Accordingly, our\npaper introduces a new semantic class of functions -- the filter equivariant\nfunctions. We show that this class contains interesting examples, prove some\nbasic theorems about it, and relate it to the well-known class of map\nequivariant functions. We also present a geometric account of filter\nequivariants, showing how they correspond naturally to certain simplicial\nstructures. Our highlight result is the amalgamation algorithm, which\nconstructs any filter-equivariant function's output by first studying how it\nbehaves on sublists of the input, in a way that extrapolates perfectly.", "comment": "18 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.08796v1", "cate": "cs.PL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2503.09131", "title": "MP-HSIR: A Multi-Prompt Framework for Universal Hyperspectral Image Restoration", "authors": ["Zhehui Wu", "Yong Chen", "Naoto Yokoya", "Wei He"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.09131v2", "summary": "Hyperspectral images (HSIs) often suffer from diverse and unknown\ndegradations during imaging, leading to severe spectral and spatial\ndistortions. Existing HSI restoration methods typically rely on specific\ndegradation assumptions, limiting their effectiveness in complex scenarios. In\nthis paper, we propose \\textbf{MP-HSIR}, a novel multi-prompt framework that\neffectively integrates spectral, textual, and visual prompts to achieve\nuniversal HSI restoration across diverse degradation types and intensities.\nSpecifically, we develop a prompt-guided spatial-spectral transformer, which\nincorporates spatial self-attention and a prompt-guided dual-branch spectral\nself-attention. Since degradations affect spectral features differently, we\nintroduce spectral prompts in the local spectral branch to provide universal\nlow-rank spectral patterns as prior knowledge for enhancing spectral\nreconstruction. Furthermore, the text-visual synergistic prompt fuses\nhigh-level semantic representations with fine-grained visual features to encode\ndegradation information, thereby guiding the restoration process. Extensive\nexperiments on 9 HSI restoration tasks, including all-in-one scenarios,\ngeneralization tests, and real-world cases, demonstrate that MP-HSIR not only\nconsistently outperforms existing all-in-one methods but also surpasses\nstate-of-the-art task-specific approaches across multiple tasks. The code and\nmodels are available at https://github.com/ZhehuiWu/MP-HSIR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.09131v2", "cate": "cs.CV", "date": "2025-03-12", "updated": "2025-07-11"}
{"id": "2507.08459", "title": "Diagnosing Failures in Large Language Models' Answers: Integrating Error Attribution into Evaluation Framework", "authors": ["Zishan Xu", "Shuyi Xie", "Qingsong Lv", "Shupei Xiao", "Linlin Song", "Sui Wenjuan", "Fan Lin"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08459v1", "summary": "With the widespread application of Large Language Models (LLMs) in various\ntasks, the mainstream LLM platforms generate massive user-model interactions\ndaily. In order to efficiently analyze the performance of models and diagnose\nfailures in their answers, it is essential to develop an automated framework to\nsystematically categorize and attribute errors. However, existing evaluation\nmodels lack error attribution capability. In this work, we establish a\ncomprehensive Misattribution Framework with 6 primary and 15 secondary\ncategories to facilitate in-depth analysis. Based on this framework, we present\nAttriData, a dataset specifically designed for error attribution, encompassing\nmisattribution, along with the corresponding scores and feedback. We also\npropose MisAttributionLLM, a fine-tuned model on AttriData, which is the first\ngeneral-purpose judge model capable of simultaneously generating score,\nmisattribution, and feedback. Extensive experiments and analyses are conducted\nto confirm the effectiveness and robustness of our proposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08459v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.14734", "title": "Compressing Suffix Trees by Path Decompositions", "authors": ["Ruben Becker", "Davide Cenzato", "Travis Gagie", "Sung-Hwan Kim", "Ragnar Groot Koerkamp", "Giovanni Manzini", "Nicola Prezza"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Article almost completed (more thorough experiments coming soon)", "url": "http://arxiv.org/abs/2506.14734v2", "summary": "In this paper, we solve the long-standing problem of designing I/O-efficient\ncompressed indexes. Our solution broadly consists of generalizing suffix\nsorting and revisiting suffix tree path compression. In classic suffix trees,\npath compression works by replacing unary suffix trie paths with pairs of\npointers to $T$, which must be available in the form of some random access\noracle at query time. In our approach, instead, we (i) sort the suffix tree's\nleaves according to a more general priority function $\\pi$ (generalizing suffix\nsorting), (ii) we build a suffix tree path decomposition prioritizing the\nleftmost paths in such an order, and (iii) we path-compress the decomposition's\npaths as pointers to a small subset of the string's suffixes. At this point, we\nshow that the colexicographically-sorted array of those pointers represents a\nnew elegant, simple, and remarkably I/O-efficient compressed suffix tree. For\ninstance, by taking $\\pi$ to be the lexicographic rank of $T$'s suffixes, we\ncan compress the suffix tree topology in $O(r)$ space on top of a $n\\log\\sigma\n+ O(\\log n)$-bits text representation while essentially matching the pattern\nmatching I/O complexity of Weiner and McCreight's suffix tree. Another (more\npractical) solution is obtained by taking $\\pi$ to be the colexicographic rank\nof $T$'s prefixes and using a fully-compressed random access oracle. The\nresulting self-index allows us to locate all occurrences of a given query\npattern in less space and orders of magnitude faster than the $r$-index.", "comment": "Article almost completed (more thorough experiments coming soon)", "pdf_url": "http://arxiv.org/pdf/2506.14734v2", "cate": "cs.DS", "date": "2025-06-17", "updated": "2025-07-10"}
{"id": "2412.02482", "title": "What should a neuron aim for? Designing local objective functions based on information theory", "authors": ["Andreas C. Schneider", "Valentin Neuhaus", "David A. Ehrlich", "Abdullah Makkeh", "Alexander S. Ecker", "Viola Priesemann", "Michael Wibral"], "categories": ["cs.IT", "cs.LG", "cs.NE", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Presented as an oral at ICLR 2025. Conference version: this https URL , 24 pages, 11 figures", "url": "http://arxiv.org/abs/2412.02482v4", "summary": "In modern deep neural networks, the learning dynamics of the individual\nneurons is often obscure, as the networks are trained via global optimization.\nConversely, biological systems build on self-organized, local learning,\nachieving robustness and efficiency with limited global information. We here\nshow how self-organization between individual artificial neurons can be\nachieved by designing abstract bio-inspired local learning goals. These goals\nare parameterized using a recent extension of information theory, Partial\nInformation Decomposition (PID), which decomposes the information that a set of\ninformation sources holds about an outcome into unique, redundant and\nsynergistic contributions. Our framework enables neurons to locally shape the\nintegration of information from various input classes, i.e. feedforward,\nfeedback, and lateral, by selecting which of the three inputs should contribute\nuniquely, redundantly or synergistically to the output. This selection is\nexpressed as a weighted sum of PID terms, which, for a given problem, can be\ndirectly derived from intuitive reasoning or via numerical optimization,\noffering a window into understanding task-relevant local information\nprocessing. Achieving neuron-level interpretability while enabling strong\nperformance using local learning, our work advances a principled\ninformation-theoretic foundation for local learning strategies.", "comment": "Presented as an oral at ICLR 2025. Conference version:\n  https://openreview.net/forum?id=CLE09ESvul, 24 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2412.02482v4", "cate": "cs.IT", "date": "2024-12-03", "updated": "2025-07-11"}
{"id": "2507.08506", "title": "Computational algorithm for downward continuation of gravity anomalies", "authors": ["D. K. Ivanov", "L. N. Temirbekova", "P. N. Vabishchevich"], "categories": ["math.NA", "cs.NA", "35R30, 65R20, 86A22, 65F10, 45Q05"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      17 pages, 11 figures", "url": "http://arxiv.org/abs/2507.08506v1", "summary": "The downward continuation of potential fields from the Earth's surface into\nthe subsurface is a critical task in gravity exploration, as it helps to\nidentify the sources of gravity anomalies. This problem is often addressed by\nsolving a first-kind integral equation using regularization techniques to\nstabilize an inherently unstable process. A similar approach is used in our\nwork, where the continued field is represented as the potential of a simple\nlayer or its vertical derivative. The constancy of the density sign of this\nequivalent simple layer preserves the sign of anomalies, provided that the\nlayer's surface encloses all anomalous sources. This constraint is a key\nfeature of our algorithm for the downward continuation of potential fields. To\nenforce, for instance, non-negativity in the simple layer density, we employ\nthe NNLS (Non-Negative Least Squares) method. The efficiency of the proposed\nmethod is demonstrated on model examples.", "comment": "17 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.08506v1", "cate": "math.NA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.06897", "title": "MedSegFactory: Text-Guided Generation of Medical Image-Mask Pairs", "authors": ["Jiawei Mao", "Yuhan Wang", "Yucheng Tang", "Daguang Xu", "Kang Wang", "Yang Yang", "Zongwei Zhou", "Yuyin Zhou"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures, The project page can be accessed via this https URL", "url": "http://arxiv.org/abs/2504.06897v2", "summary": "This paper presents MedSegFactory, a versatile medical synthesis framework\nthat generates high-quality paired medical images and segmentation masks across\nmodalities and tasks. It aims to serve as an unlimited data repository,\nsupplying image-mask pairs to enhance existing segmentation tools. The core of\nMedSegFactory is a dual-stream diffusion model, where one stream synthesizes\nmedical images and the other generates corresponding segmentation masks. To\nensure precise alignment between image-mask pairs, we introduce Joint\nCross-Attention (JCA), enabling a collaborative denoising paradigm by dynamic\ncross-conditioning between streams. This bidirectional interaction allows both\nrepresentations to guide each other's generation, enhancing consistency between\ngenerated pairs. MedSegFactory unlocks on-demand generation of paired medical\nimages and segmentation masks through user-defined prompts that specify the\ntarget labels, imaging modalities, anatomical regions, and pathological\nconditions, facilitating scalable and high-quality data generation. This new\nparadigm of medical image synthesis enables seamless integration into diverse\nmedical imaging workflows, enhancing both efficiency and accuracy. Extensive\nexperiments show that MedSegFactory generates data of superior quality and\nusability, achieving competitive or state-of-the-art performance in 2D and 3D\nsegmentation tasks while addressing data scarcity and regulatory constraints.", "comment": "12 pages, 8 figures, The project page can be accessed via\n  https://jwmao1.github.io/MedSegFactory_web", "pdf_url": "http://arxiv.org/pdf/2504.06897v2", "cate": "cs.CV", "date": "2025-04-09", "updated": "2025-07-11"}
{"id": "2205.07249", "title": "Pocket2Mol: Efficient Molecular Sampling Based on 3D Protein Pockets", "authors": ["Xingang Peng", "Shitong Luo", "Jiaqi Guan", "Qi Xie", "Jian Peng", "Jianzhu Ma"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ICML 2022 accepted", "url": "http://arxiv.org/abs/2205.07249v2", "summary": "Deep generative models have achieved tremendous success in designing novel\ndrug molecules in recent years. A new thread of works have shown the great\npotential in advancing the specificity and success rate of in silico drug\ndesign by considering the structure of protein pockets. This setting posts\nfundamental computational challenges in sampling new chemical compounds that\ncould satisfy multiple geometrical constraints imposed by pockets. Previous\nsampling algorithms either sample in the graph space or only consider the 3D\ncoordinates of atoms while ignoring other detailed chemical structures such as\nbond types and functional groups. To address the challenge, we develop\nPocket2Mol, an E(3)-equivariant generative network composed of two modules: 1)\na new graph neural network capturing both spatial and bonding relationships\nbetween atoms of the binding pockets and 2) a new efficient algorithm which\nsamples new drug candidates conditioned on the pocket representations from a\ntractable distribution without relying on MCMC. Experimental results\ndemonstrate that molecules sampled from Pocket2Mol achieve significantly better\nbinding affinity and other drug properties such as druglikeness and synthetic\naccessibility.", "comment": "ICML 2022 accepted", "pdf_url": "http://arxiv.org/pdf/2205.07249v2", "cate": "cs.LG", "date": "2022-05-15", "updated": "2025-07-11"}
{"id": "2503.20287", "title": "InsViE-1M: Effective Instruction-based Video Editing with Elaborate Dataset Construction", "authors": ["Yuhui Wu", "Liyi Chen", "Ruibin Li", "Shihao Wang", "Chenxi Xie", "Lei Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.20287v2", "summary": "Instruction-based video editing allows effective and interactive editing of\nvideos using only instructions without extra inputs such as masks or\nattributes. However, collecting high-quality training triplets (source video,\nedited video, instruction) is a challenging task. Existing datasets mostly\nconsist of low-resolution, short duration, and limited amount of source videos\nwith unsatisfactory editing quality, limiting the performance of trained\nediting models. In this work, we present a high-quality Instruction-based Video\nEditing dataset with 1M triplets, namely InsViE-1M. We first curate\nhigh-resolution and high-quality source videos and images, then design an\neffective editing-filtering pipeline to construct high-quality editing triplets\nfor model training. For a source video, we generate multiple edited samples of\nits first frame with different intensities of classifier-free guidance, which\nare automatically filtered by GPT-4o with carefully crafted guidelines. The\nedited first frame is propagated to subsequent frames to produce the edited\nvideo, followed by another round of filtering for frame quality and motion\nevaluation. We also generate and filter a variety of video editing triplets\nfrom high-quality images. With the InsViE-1M dataset, we propose a multi-stage\nlearning strategy to train our InsViE model, progressively enhancing its\ninstruction following and editing ability. Extensive experiments demonstrate\nthe advantages of our InsViE-1M dataset and the trained model over\nstate-of-the-art works. Codes are available at\n\\href{https://github.com/langmanbusi/InsViE}{InsViE}.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.20287v2", "cate": "cs.CV", "date": "2025-03-26", "updated": "2025-07-11"}
{"id": "2507.08468", "title": "Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study", "authors": ["Marina Luketina", "Andrea Benkel", "Christoph G. Schuetz"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      26 pages, 5 figures, 6 tables", "url": "http://arxiv.org/abs/2507.08468v1", "summary": "This paper provides an experimental evaluation of the capability of large\nlanguage models (LLMs) to assist in legal decision-making within the framework\nof Austrian and European Union value-added tax (VAT) law. In tax consulting\npractice, clients often describe cases in natural language, making LLMs a prime\ncandidate for supporting automated decision-making and reducing the workload of\ntax professionals. Given the requirement for legally grounded and\nwell-justified analyses, the propensity of LLMs to hallucinate presents a\nconsiderable challenge. The experiments focus on two common methods for\nenhancing LLM performance: fine-tuning and retrieval-augmented generation\n(RAG). In this study, these methods are applied on both textbook cases and\nreal-world cases from a tax consulting firm to systematically determine the\nbest configurations of LLM-based systems and assess the legal-reasoning\ncapabilities of LLMs. The findings highlight the potential of using LLMs to\nsupport tax consultants by automating routine tasks and providing initial\nanalyses, although current prototypes are not ready for full automation due to\nthe sensitivity of the legal domain. The findings indicate that LLMs, when\nproperly configured, can effectively support tax professionals in VAT tasks and\nprovide legally grounded justifications for decisions. However, limitations\nremain regarding the handling of implicit client knowledge and context-specific\ndocumentation, underscoring the need for future integration of structured\nbackground information.", "comment": "26 pages, 5 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.08468v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.20687", "title": "Review of Three Variants of the k-d Tree", "authors": ["Russell A. Brown"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      29 pages, 11 figures, one listing, one table", "url": "http://arxiv.org/abs/2506.20687v4", "summary": "The original description of the k-d tree recognized that rebalancing\ntechniques, such as used to build an AVL tree or a red-black tree, are not\napplicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is\nnecessary to find the median of a set of data for each recursive subdivision of\nthat set. The sort or selection used to find the median, and the technique used\nto partition the set about that median, strongly influence the computational\ncomplexity of building a k-d tree. This article describes and contrasts three\nvariants of the k-d tree that differ in their technique used to partition the\nset, and compares the performance of those variants. In addition, dual-threaded\nexecution is proposed and analyzed for one of the three variants.", "comment": "29 pages, 11 figures, one listing, one table", "pdf_url": "http://arxiv.org/pdf/2506.20687v4", "cate": "cs.DS", "date": "2025-06-25", "updated": "2025-07-10"}
{"id": "2503.18114", "title": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry", "authors": ["Chi-Ning Chou", "Hang Le", "Yichen Wang", "SueYeon Chung"], "categories": ["cs.LG", "cs.NE", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work was published in ICML 2025 and was selected for a spotlight presentation", "url": "http://arxiv.org/abs/2503.18114v2", "summary": "Integrating task-relevant information into neural representations is a\nfundamental ability of both biological and artificial intelligence systems.\nRecent theories have categorized learning into two regimes: the rich regime,\nwhere neural networks actively learn task-relevant features, and the lazy\nregime, where networks behave like random feature models. Yet this simple\nlazy-rich dichotomy overlooks a diverse underlying taxonomy of feature\nlearning, shaped by differences in learning algorithms, network architectures,\nand data properties. To address this gap, we introduce an analysis framework to\nstudy feature learning via the geometry of neural representations. Rather than\ninspecting individual learned features, we characterize how task-relevant\nrepresentational manifolds evolve throughout the learning process. We show, in\nboth theoretical and empirical settings, that as networks learn features,\ntask-relevant manifolds untangle, with changes in manifold geometry revealing\ndistinct learning stages and strategies beyond the lazy-rich dichotomy. This\nframework provides novel insights into feature learning across neuroscience and\nmachine learning, shedding light on structural inductive biases in neural\ncircuits and the mechanisms underlying out-of-distribution generalization.", "comment": "This work was published in ICML 2025 and was selected for a spotlight\n  presentation", "pdf_url": "http://arxiv.org/pdf/2503.18114v2", "cate": "cs.LG", "date": "2025-03-23", "updated": "2025-07-11"}
{"id": "2507.08632", "title": "Minimum-norm interpolation for unknown surface reconstruction", "authors": ["Alex Shiu Lun Chu", "Leevan Ling", "Ka Chun Cheung"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08632v1", "summary": "We study algorithms to estimate geometric properties of raw point cloud data\nthrough implicit surface representations. Given that any level-set function\nwith a constant level set corresponding to the surface can be used for such\nestimations, numerical methods need not specify a unique target function for\nthe domain-type interpolation problems. In this paper, we focus on kernel-based\ninterpolation by radial basis functions (RBF) and reformulate the uniquely\nsolvable interpolation problem into a constrained optimization model. This\nmodel minimizes some user-defined norm while enforcing all interpolation\nconditions. To enable nontrivial feasible solutions, we propose to enhance the\ntrial space with 1D kernel basis functions inspired by Kolmogorov-Arnold\nNetworks (KANs). Numerical experiments demonstrate that our proposed mixed\ndimensional trial space significantly improves surface reconstruction from raw\npoint clouds. This is particularly evident in the precise estimation of surface\nnormals, outperforming traditional RBF trial spaces including the one for\nHermite interpolation. This framework not only enhances processing of raw point\ncloud data but also shows potential for further contributions to computational\ngeometry. We demonstrate this with a point cloud processing example.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08632v1", "cate": "math.NA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.13078", "title": "MGT: Extending Virtual Try-Off to Multi-Garment Scenarios", "authors": ["Riza Velioglu", "Petra Bevandic", "Robin Chan", "Barbara Hammer"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCVW'25", "url": "http://arxiv.org/abs/2504.13078v2", "summary": "Computer vision is transforming fashion industry through Virtual Try-On\n(VTON) and Virtual Try-Off (VTOFF). VTON generates images of a person in a\nspecified garment using a target photo and a standardized garment image, while\na more challenging variant, Person-to-Person Virtual Try-On (p2p-VTON), uses a\nphoto of another person wearing the garment. VTOFF, in contrast, extracts\nstandardized garment images from photos of clothed individuals. We introduce\nMulti-Garment TryOffDiff (MGT), a diffusion-based VTOFF model capable of\nhandling diverse garment types, including upper-body, lower-body, and dresses.\nMGT builds on a latent diffusion architecture with SigLIP-based image\nconditioning to capture garment characteristics such as shape, texture, and\npattern. To address garment diversity, MGT incorporates class-specific\nembeddings, achieving state-of-the-art VTOFF results on VITON-HD and\ncompetitive performance on DressCode. When paired with VTON models, it further\nenhances p2p-VTON by reducing unwanted attribute transfer, such as skin tone,\nensuring preservation of person-specific characteristics. Demo, code, and\nmodels are available at: https://rizavelioglu.github.io/tryoffdiff/", "comment": "Accepted at ICCVW'25", "pdf_url": "http://arxiv.org/pdf/2504.13078v2", "cate": "cs.CV", "date": "2025-04-17", "updated": "2025-07-11"}
{"id": "2402.05274", "title": "Convergence of Natural Policy Gradient for a Family of Infinite-State Queueing MDPs", "authors": ["Isaac Grosof", "Siva Theja Maguluri", "R. Srikant"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      32 pages", "url": "http://arxiv.org/abs/2402.05274v3", "summary": "A wide variety of queueing systems can be naturally modeled as infinite-state\nMarkov Decision Processes (MDPs). In the reinforcement learning (RL) context, a\nvariety of algorithms have been developed to learn and optimize these MDPs. At\nthe heart of many popular policy-gradient based learning algorithms, such as\nnatural actor-critic, TRPO, and PPO, lies the Natural Policy Gradient (NPG)\npolicy optimization algorithm. Convergence results for these RL algorithms rest\non convergence results for the NPG algorithm. However, all existing results on\nthe convergence of the NPG algorithm are limited to finite-state settings.\n  We study a general class of queueing MDPs, and prove a $O(1/\\sqrt{T})$\nconvergence rate for the NPG algorithm, if the NPG algorithm is initialized\nwith the MaxWeight policy. This is the first convergence rate bound for the NPG\nalgorithm for a general class of infinite-state average-reward MDPs. Moreover,\nour result applies to a beyond the queueing setting to any countably-infinite\nMDP satisfying certain mild structural assumptions, given a sufficiently good\ninitial policy. Key to our result are state-dependent bounds on the relative\nvalue function achieved by the iterate policies of the NPG algorithm.", "comment": "32 pages", "pdf_url": "http://arxiv.org/pdf/2402.05274v3", "cate": "cs.LG", "date": "2024-02-07", "updated": "2025-07-10"}
{"id": "2504.00901", "title": "A Decade of Deep Learning for Remote Sensing Spatiotemporal Fusion: Advances, Challenges, and Opportunities", "authors": ["Enzhe Sun", "Yongchuan Cui", "Peng Liu", "Jining Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.00901v2", "summary": "Remote sensing spatiotemporal fusion (STF) addresses the fundamental\ntrade-off between temporal and spatial resolution by combining high\ntemporal-low spatial and high spatial-low temporal imagery. This paper presents\nthe first comprehensive survey of deep learning advances in remote sensing STF\nover the past decade. We establish a systematic taxonomy of deep learning\narchitectures including Convolutional Neural Networks (CNNs), Transformers,\nGenerative Adversarial Networks (GANs), diffusion models, and sequence models,\nrevealing significant growth in deep learning adoption for STF tasks. Our\nanalysis reveals that CNN-based methods dominate spatial feature extraction,\nwhile Transformer architectures show superior performance in capturing\nlong-range temporal dependencies. GAN and diffusion models demonstrate\nexceptional capability in detail reconstruction, substantially outperforming\ntraditional methods in structural similarity and spectral fidelity. Through\ncomprehensive experiments on seven benchmark datasets comparing ten\nrepresentative methods, we validate these findings and quantify the performance\ntrade-offs between different approaches. We identify five critical challenges:\ntime-space conflicts, limited generalization across datasets, computational\nefficiency for large-scale processing, multi-source heterogeneous fusion, and\ninsufficient benchmark diversity. The survey highlights promising opportunities\nin foundation models, hybrid architectures, and self-supervised learning\napproaches that could address current limitations and enable multimodal\napplications. The specific models, datasets, and other information mentioned in\nthis article have been collected in:\nhttps://github.com/yc-cui/Deep-Learning-Spatiotemporal-Fusion-Survey.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.00901v2", "cate": "cs.CV", "date": "2025-04-01", "updated": "2025-07-11"}
{"id": "2507.08477", "title": "ILT-Iterative LoRA Training through Focus-Feedback-Fix for Multilingual Speech Recognition", "authors": ["Qingliang Meng", "Hao Wu", "Wei Liang", "Wei Xu", "Qing Zhao"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted By Interspeech 2025 MLC-SLM workshop as a Research Paper", "url": "http://arxiv.org/abs/2507.08477v1", "summary": "The deep integration of large language models and automatic speech\nrecognition systems has become a promising research direction with high\npractical value. To address the overfitting issue commonly observed in Low-Rank\nAdaptation (LoRA) during the supervised fine-tuning (SFT) stage, this work\nproposes an innovative training paradigm Iterative LoRA Training (ILT) in\ncombination with an Iterative Pseudo Labeling strategy, effectively enhancing\nthe theoretical upper bound of model performance. Based on Whisper-large-v3 and\nQwen2-Audio, we conduct systematic experiments using a three-stage training\nprocess: Focus Training, Feed Back Training, and Fix Training. Experimental\nresults demonstrate the effectiveness of the proposed method. Furthermore, the\nMegaAIS research team applied this technique in the Interspeech 2025\nMultilingual Conversational Speech Language Modeling Challenge (MLC-SLM),\nachieving 4th in Track 1 (Multilingual ASR Task) and 1st place in Track 2\n(Speech Separation and Recognition Task), showcasing the practical feasibility\nand strong application potential of our approach.", "comment": "Accepted By Interspeech 2025 MLC-SLM workshop as a Research Paper", "pdf_url": "http://arxiv.org/pdf/2507.08477v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.00708", "title": "On the (In)Approximability of the Monitoring Edge Geodetic Set Problem", "authors": ["Davide Bilò", "Giordano Colli", "Luca Forlizzi", "Stefano Leucci"], "categories": ["cs.DS", "cs.CC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2405.13875", "url": "http://arxiv.org/abs/2507.00708v2", "summary": "We study the minimum \\emph{Monitoring Edge Geodetic Set} (\\megset) problem\nintroduced in [Foucaud et al., CALDAM'23]: given a graph $G$, we say that an\nedge is monitored by a pair $u,v$ of vertices if \\emph{all} shortest paths\nbetween $u$ and $v$ traverse $e$; the goal of the problem consists in finding a\nsubset $M$ of vertices of $G$ such that each edge of $G$ is monitored by at\nleast one pair of vertices in $M$, and $|M|$ is minimized.\n  In this paper, we prove that all polynomial-time approximation algorithms for\nthe minimum \\megset problem must have an approximation ratio of $\\Omega(\\log\nn)$, unless \\p = \\np. To the best of our knowledge, this is the first\nnon-constant inapproximability result known for this problem. We also\nstrengthen the known \\np-hardness of the problem on $2$-apex graphs by showing\nthat the same result holds for $1$-apex graphs. This leaves open the problem of\ndetermining whether the problem remains \\np-hard on planar (i.e., $0$-apex)\ngraphs.\n  On the positive side, we design an algorithm that computes good approximate\nsolutions for hereditary graph classes that admit efficiently computable\nbalanced separators of truly sublinear size. This immediately results in\npolynomial-time approximation algorithms achieving an approximation ratio of\n$O(n^{\\frac{1}{4}} \\sqrt{\\log n})$ on planar graphs, graphs with bounded genus,\nand $k$-apex graphs with $k=O(n^{\\frac{1}{4}})$. On graphs with bounded\ntreewidth, we obtain an approximation ratio of $O(\\log^{3/2} n)$ for any\nconstant $\\varepsilon > 0$. This compares favorably with the best-known\napproximation algorithm for general graphs, which achieves an approximation\nratio of $O(\\sqrt{n \\log n})$ via a simple reduction to the \\textsc{Set Cover}\nproblem.", "comment": "arXiv admin note: text overlap with arXiv:2405.13875", "pdf_url": "http://arxiv.org/pdf/2507.00708v2", "cate": "cs.DS", "date": "2025-07-01", "updated": "2025-07-11"}
{"id": "2507.08752", "title": "Long-time relative error analysis for linear ODEs with perturbed initial value", "authors": ["Stefano Maset"], "categories": ["math.NA", "cs.NA", "math.DS"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08752v1", "summary": "We investigate the propagation of initial value perturbations along the\nsolution of a linear ODE \\( y'(t) = Ay(t) \\). This propagation is analized\nusing the relative error rather than the absolute error. Our focus is on the\nlong-term behavior of this relative error, which differs significantly from\nthat of the absolute error. Understanding this long-term behavior provides\ninsights into the growth of the relative error over all times, not just at\nlarge times. Therefore, it represents a crucial and fundamental aspect of the\nconditioning of linear ODEs, with applications in, for example, non-normal\ndynamics. The author hopes that this paper will stimulate attention to the role\nof relative error in dynamic contexts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08752v1", "cate": "math.NA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.18246", "title": "One-Pass to Reason: Token Duplication and Block-Sparse Mask for Efficient Fine-Tuning on Multi-Turn Reasoning", "authors": ["Ritesh Goru", "Shanay Mehta", "Prateek Jain"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      9 pages, 3 figures", "url": "http://arxiv.org/abs/2504.18246v2", "summary": "Fine-tuning Large Language Models (LLMs) on multi-turn reasoning datasets\nrequires N (number of turns) separate forward passes per conversation due to\nreasoning token visibility constraints, as reasoning tokens for a turn are\ndiscarded in subsequent turns. We propose duplicating response tokens along\nwith a custom attention mask to enable single-pass processing of entire\nconversations. We prove our method produces identical losses to the N-pass\napproach while reducing time complexity from $O\\bigl(N^{3}\\bigl)$ to\n$O\\bigl(N^{2}\\bigl)$ and maintaining the same memory complexity for a\ntransformer based model. Our approach achieves significant training speedup\nwhile preserving accuracy. Our implementation is available online\n(https://github.com/devrev/One-Pass-to-Reason).", "comment": "9 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2504.18246v2", "cate": "cs.CL", "date": "2025-04-25", "updated": "2025-07-11"}
{"id": "2406.03099", "title": "Graph Convolutional Branch and Bound", "authors": ["Lorenzo Sciandra", "Roberto Esposito", "Andrea Cesare Grosso", "Laura Sacerdote", "Cristina Zucca"], "categories": ["cs.LG", "math.OC", "68T07, 90C27"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Submitted to European Journal of Operational Research", "url": "http://arxiv.org/abs/2406.03099v3", "summary": "This article explores the integration of deep learning models into\ncombinatorial optimization pipelines, specifically targeting NP-hard problems.\nTraditional exact algorithms for such problems often rely on heuristic criteria\nto guide the exploration of feasible solutions. In this work, we propose using\nneural networks to learn informative heuristics-most notably, an optimality\nscore that estimates a solution's proximity to the optimum. This score is used\nto evaluate nodes within a branch-and-bound framework, enabling a more\nefficient traversal of the solution space. Focusing on the Traveling Salesman\nProblem, we describe two exact solvers-1-tree branch-and-bound and Concorde-and\nintroduce a hybrid approach called Graph Convolutional Branch and Bound, which\naugments these solvers with a graph convolutional neural network along with a\nnovel unsupervised training strategy that facilitates generalization to graphs\nof varying sizes without requiring labeled data. Empirical results demonstrate\nthe effectiveness of the proposed method, showing a significant reduction in\nthe number of explored branch-and-bound nodes and overall computational time.", "comment": "Submitted to European Journal of Operational Research", "pdf_url": "http://arxiv.org/pdf/2406.03099v3", "cate": "cs.LG", "date": "2024-06-05", "updated": "2025-07-10"}
{"id": "2504.10012", "title": "EBAD-Gaussian: Event-driven Bundle Adjusted Deblur Gaussian Splatting", "authors": ["Yufei Deng", "Yuanjian Wang", "Rong Xiao", "Chenwei Tang", "Jizhe Zhou", "Jiahao Fan", "Deng Xiong", "Jiancheng Lv", "Huajin Tang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.10012v2", "summary": "While 3D Gaussian Splatting (3D-GS) achieves photorealistic novel view\nsynthesis, its performance degrades with motion blur. In scenarios with rapid\nmotion or low-light conditions, existing RGB-based deblurring methods struggle\nto model camera pose and radiance changes during exposure, reducing\nreconstruction accuracy. Event cameras, capturing continuous brightness changes\nduring exposure, can effectively assist in modeling motion blur and improving\nreconstruction quality. Therefore, we propose Event-driven Bundle Adjusted\nDeblur Gaussian Splatting (EBAD-Gaussian), which reconstructs sharp 3D\nGaussians from event streams and severely blurred images. This method jointly\nlearns the parameters of these Gaussians while recovering camera motion\ntrajectories during exposure time. Specifically, we first construct a blur loss\nfunction by synthesizing multiple latent sharp images during the exposure time,\nminimizing the difference between real and synthesized blurred images. Then we\nuse event stream to supervise the light intensity changes between latent sharp\nimages at any time within the exposure period, supplementing the light\nintensity dynamic changes lost in RGB images. Furthermore, we optimize the\nlatent sharp images at intermediate exposure times based on the event-based\ndouble integral (EDI) prior, applying consistency constraints to enhance the\ndetails and texture information of the reconstructed images. Extensive\nexperiments on synthetic and real-world datasets show that EBAD-Gaussian can\nachieve high-quality 3D scene reconstruction under the condition of blurred\nimages and event stream inputs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.10012v2", "cate": "cs.CV", "date": "2025-04-14", "updated": "2025-07-11"}
{"id": "2507.08491", "title": "A Third Paradigm for LLM Evaluation: Dialogue Game-Based Evaluation using clembench", "authors": ["David Schlangen", "Sherzod Hakimov", "Jonathan Jordan", "Philipp Sadler"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      All code required to run the benchmark, as well as extensive documentation, is available at this https URL", "url": "http://arxiv.org/abs/2507.08491v1", "summary": "There are currently two main paradigms for evaluating large language models\n(LLMs), reference-based evaluation and preference-based evaluation. The first,\ncarried over from the evaluation of machine learning models in general, relies\non pre-defined task instances, for which reference task executions are\navailable. The second, best exemplified by the LM-arena, relies on (often\nself-selected) users bringing their own intents to a site that routes these to\nseveral models in parallel, among whose responses the user then selects their\nmost preferred one. The former paradigm hence excels at control over what is\ntested, while the latter comes with higher ecological validity, testing actual\nuse cases interactively. Recently, a third complementary paradigm has emerged\nthat combines some of the strengths of these approaches, offering control over\nmulti-turn, reference-free, repeatable interactions, while stressing\ngoal-directedness: dialogue game based evaluation. While the utility of this\napproach has been shown by several projects, its adoption has been held back by\nthe lack of a mature, easily re-usable implementation. In this paper, we\npresent clembench, which has been in continuous development since 2023 and has\nin its latest release been optimized for ease of general use. We describe how\nit can be used to benchmark one's own models (using a provided set of benchmark\ngame instances in English), as well as how easily the benchmark itself can be\nextended with new, tailor-made targeted tests.", "comment": "All code required to run the benchmark, as well as extensive\n  documentation, is available at https://github.com/clembench/clembench", "pdf_url": "http://arxiv.org/pdf/2507.08491v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07524", "title": "Finding One Local Optimum Is Easy -- But What about Two?", "authors": ["Yasuaki Kobayashi", "Kazuhiro Kurita", "Yutaro Yamaguchi"], "categories": ["cs.DS", "cs.CC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      15 pages", "url": "http://arxiv.org/abs/2507.07524v2", "summary": "The class PLS (Polynomial Local Search) captures the complexity of finding a\nsolution that is locally optimal and has proven to be an important concept in\nthe theory of local search. It has been shown that local search versions of\nvarious combinatorial optimization problems, such as Maximum Independent Set\nand Max Cut, are complete for this class. Such computational intractability\ntypically arises in local search problems allowing arbitrary weights; in\ncontrast, for unweighted problems, locally optimal solutions can be found in\npolynomial time under standard settings. In this paper, we pursue the\ncomplexity of local search problems from a different angle: We show that\ncomputing two locally optimal solutions is NP-hard for various natural\nunweighted local search problems, including Maximum Independent Set, Minimum\nDominating Set, Max SAT, and Max Cut. We also discuss several tractable cases\nfor finding two (or more) local optimal solutions.", "comment": "15 pages", "pdf_url": "http://arxiv.org/pdf/2507.07524v2", "cate": "cs.DS", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.08762", "title": "Asymptotic condition numbers for linear ODEs", "authors": ["Stefano Maset"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08762v1", "summary": "We are interested in the (relative) conditioning of the linear problem\n$y_0\\mapsto \\mathrm{e}^{tA}y_0$, i.e. the conditioning of the action of the\nmatrix exponential $\\mathrm{e}^{tA}$ on a vector with respect to perturbations\nof this vector. The present paper is a qualitative study of the long-time\nbehavior of this conditioning. In other words, we are interested to study the\npropagation to the solution $y(t)$ of perturbations of the initial value for a\nlinear ODE $y^\\prime(t)=Ay(t)$, by measuring these perturbations with relative\nerrors instead of absolute errors. We introduce three condition numbers: the\nfirst considers a specific initial value and a specific direction of\nperturbation; the second considers a specific initial value and the worst case\nby varying the direction of perturbation; and the third considers the worst\ncase by varying both the initial value and the direction of perturbation. The\nlong-time behaviors of these three condition numbers are studied.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08762v1", "cate": "math.NA", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.00467", "title": "Red Teaming Large Language Models for Healthcare", "authors": ["Vahid Balazadeh", "Michael Cooper", "David Pellow", "Atousa Assadi", "Jennifer Bell", "Mark Coatsworth", "Kaivalya Deshpande", "Jim Fackler", "Gabriel Funingana", "Spencer Gable-Cook", "Anirudh Gangadhar", "Abhishek Jaiswal", "Sumanth Kaja", "Christopher Khoury", "Amrit Krishnan", "Randy Lin", "Kaden McKeen", "Sara Naimimohasses", "Khashayar Namdar", "Aviraj Newatia", "Allan Pang", "Anshul Pattoo", "Sameer Peesapati", "Diana Prepelita", "Bogdana Rakova", "Saba Sadatamin", "Rafael Schulman", "Ajay Shah", "Syed Azhar Shah", "Syed Ahmar Shah", "Babak Taati", "Balagopal Unnikrishnan", "Iñigo Urteaga", "Stephanie Williams", "Rahul G Krishnan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00467v2", "summary": "We present the design process and findings of the pre-conference workshop at\nthe Machine Learning for Healthcare Conference (2024) entitled Red Teaming\nLarge Language Models for Healthcare, which took place on August 15, 2024.\nConference participants, comprising a mix of computational and clinical\nexpertise, attempted to discover vulnerabilities -- realistic clinical prompts\nfor which a large language model (LLM) outputs a response that could cause\nclinical harm. Red-teaming with clinicians enables the identification of LLM\nvulnerabilities that may not be recognised by LLM developers lacking clinical\nexpertise. We report the vulnerabilities found, categorise them, and present\nthe results of a replication study assessing the vulnerabilities across all\nLLMs provided.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00467v2", "cate": "cs.CL", "date": "2025-05-01", "updated": "2025-07-11"}
{"id": "2406.06227", "title": "PAC-Bayes Analysis for Recalibration in Classification", "authors": ["Masahiro Fujisawa", "Futoshi Futami"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by the 42nd International Conference on Machine Learning (ICML2025), 38 pages, 8 figures", "url": "http://arxiv.org/abs/2406.06227v2", "summary": "Nonparametric estimation using uniform-width binning is a standard approach\nfor evaluating the calibration performance of machine learning models. However,\nexisting theoretical analyses of the bias induced by binning are limited to\nbinary classification, creating a significant gap with practical applications\nsuch as multiclass classification. Additionally, many parametric recalibration\nalgorithms lack theoretical guarantees for their generalization performance. To\naddress these issues, we conduct a generalization analysis of calibration error\nusing the probably approximately correct Bayes framework. This approach enables\nus to derive the first optimizable upper bound for generalization error in the\ncalibration context. On the basis of our theory, we propose a\ngeneralization-aware recalibration algorithm. Numerical experiments show that\nour algorithm enhances the performance of Gaussian process-based recalibration\nacross various benchmark datasets and models.", "comment": "Accepted by the 42nd International Conference on Machine Learning\n  (ICML2025), 38 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2406.06227v2", "cate": "cs.LG", "date": "2024-06-10", "updated": "2025-07-11"}
{"id": "2504.17224", "title": "Visual and Textual Prompts in VLLMs for Enhancing Emotion Recognition", "authors": ["Zhifeng Wang", "Qixuan Zhang", "Peter Zhang", "Wenjia Niu", "Kaihao Zhang", "Ramesh Sankaranarayana", "Sabrina Caldwell", "Tom Gedeon"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TCSVT", "url": "http://arxiv.org/abs/2504.17224v3", "summary": "Vision Large Language Models (VLLMs) exhibit promising potential for\nmulti-modal understanding, yet their application to video-based emotion\nrecognition remains limited by insufficient spatial and contextual awareness.\nTraditional approaches, which prioritize isolated facial features, often\nneglect critical non-verbal cues such as body language, environmental context,\nand social interactions, leading to reduced robustness in real-world scenarios.\nTo address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel\nframework that enhances zero-shot emotion recognition by integrating spatial\nannotations (e.g., bounding boxes, facial landmarks), physiological signals\n(facial action units), and contextual cues (body posture, scene dynamics,\nothers' emotions) into a unified prompting strategy. SoVTP preserves holistic\nscene information while enabling fine-grained analysis of facial muscle\nmovements and interpersonal dynamics. Extensive experiments show that SoVTP\nachieves substantial improvements over existing visual prompting methods,\ndemonstrating its effectiveness in enhancing VLLMs' video emotion recognition\ncapabilities.", "comment": "Accepted by IEEE TCSVT", "pdf_url": "http://arxiv.org/pdf/2504.17224v3", "cate": "cs.CV", "date": "2025-04-24", "updated": "2025-07-11"}
{"id": "2507.08496", "title": "LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning", "authors": ["Shibo Sun", "Xue Li", "Donglin Di", "Mingjie Wei", "Lanshun Nie", "Wei-Nan Zhang", "Dechen Zhan", "Yang Song", "Lei Fan"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08496v1", "summary": "While large language models (LLMs) have advanced procedural planning for\nembodied AI systems through strong reasoning abilities, the integration of\nmultimodal inputs and counterfactual reasoning remains underexplored. To tackle\nthese challenges, we introduce LLaPa, a vision-language model framework\ndesigned for multimodal procedural planning. LLaPa generates executable action\nsequences from textual task descriptions and visual environmental images using\nvision-language models (VLMs). Furthermore, we enhance LLaPa with two auxiliary\nmodules to improve procedural planning. The first module, the Task-Environment\nReranker (TER), leverages task-oriented segmentation to create a task-sensitive\nfeature space, aligning textual descriptions with visual environments and\nemphasizing critical regions for procedural execution. The second module, the\nCounterfactual Activities Retriever (CAR), identifies and emphasizes potential\ncounterfactual conditions, enhancing the model's reasoning capability in\ncounterfactual scenarios. Extensive experiments on ActPlan-1K and ALFRED\nbenchmarks demonstrate that LLaPa generates higher-quality plans with superior\nLCS and correctness, outperforming advanced models. The code and models are\navailable https://github.com/sunshibo1234/LLaPa.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08496v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2309.15647", "title": "Black-Box Identity Testing of Noncommutative Rational Formulas in Deterministic Quasipolynomial Time", "authors": ["V. Arvind", "Abhranil Chatterjee", "Partha Mukhopadhyay"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2309.15647v4", "summary": "Rational Identity Testing (RIT) is the decision problem of determining\nwhether or not a noncommutative rational formula computes zero in the free skew\nfield. It admits a deterministic polynomial-time white-box algorithm [Garg,\nGurvits, Oliveira, and Wigderson (2016); Ivanyos, Qiao, Subrahmanyam (2018);\nHamada and Hirai (2021)], and a randomized polynomial-time algorithm [Derksen\nand Makam (2017)] in the black-box setting, via singularity testing of linear\nmatrices over the free skew field. Indeed, a randomized NC algorithm for RIT in\nthe white-box setting follows from the result of Derksen and Makam (2017).\n  Designing an efficient deterministic black-box algorithm for RIT and\nunderstanding the parallel complexity of RIT are major open problems in this\narea. Despite being open since the work of Garg, Gurvits, Oliveira, and\nWigderson (2016), these questions have seen limited progress. In fact, the only\nknown result in this direction is the construction of a quasipolynomial-size\nhitting set for rational formulas of only inversion height two [Arvind,\nChatterjee, Mukhopadhyay (2022)].\n  In this paper, we significantly improve the black-box complexity of this\nproblem and obtain the first quasipolynomial-size hitting set for all rational\nformulas of polynomial size. Our construction also yields the first\ndeterministic quasi-NC upper bound for RIT in the white-box setting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2309.15647v4", "cate": "cs.CC", "date": "2023-09-27", "updated": "2025-07-11"}
{"id": "2507.08115", "title": "Entropy-conservative numerical fluxes for compressible Euler equations with thermally perfect gas models", "authors": ["Alessandro Aiello", "Carlo De Michele", "Gennaro Coppola"], "categories": ["physics.flu-dyn", "cs.NA", "math.NA", "76N15, 76M25"], "primary_category": "Subjects:       Fluid Dynamics (physics.flu-dyn)", "pdf_link": null, "comments": "Comments:      11 pages, 2 figures", "url": "http://arxiv.org/abs/2507.08115v1", "summary": "This study proposes a novel spatial discretization procedure for the\ncompressible Euler equations that guarantees entropy conservation at a discrete\nlevel for thermally perfect gases. The procedure is based on a locally\nconservative formulation, and extends the entropy-conserving schemes to the\nmore realistic case of thermally perfect gases, while still guaranteeing\npreservation of both linear invariants and kinetic energy. The proposed\nmethodology, which can also be extended to multicomponent gases and to an\nAsymptotically Entropy-Conservative formulation, shows advantages in terms of\naccuracy and robustness when compared to existing similar approaches.", "comment": "11 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.08115v1", "cate": "physics.flu-dyn", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.08315", "title": "New constructions of $2$-to-$1$ mappings over $\\gf_{2^n}$ and their applications to binary linear codes", "authors": ["Yaqin Li", "Kangquan Li", "Qiancheng Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08315v1", "summary": "The $2$-to-$1$ mapping over finite fields has a wide range of applications,\nincluding combinatorial mathematics and coding theory. Thus, constructions of\n$2$-to-$1$ mappings have attracted considerable attention recently. Based on\nsummarizing the existing construction results of all $2$-to-$1$ mappings over\nfinite fields with even characteristic, this article first applies the\ngeneralized switching method to the study of $2$-to-$1$ mappings, that is, to\nconstruct $2$-to-$1$ mappings over the finite field $\\mathbb{F}_{q^l}$ with\n$F(x)=G(x)+{\\rm Tr}_{q^l/q}(R(x))$, where $G$ is a monomial and $R$ is a\nmonomial or binomial. Using the properties of Dickson polynomial theory and the\ncomplete characterization of low-degree equations, we construct a total of $16$\nnew classes of $2$-to-$1$ mappings, which are not QM-equivalent to any existing\n$2$-to-$1$ polynomials. Among these, $9$ classes are of the form $cx + {\\rm\nTr}_{q^l/q}(x^d)$, and $7$ classes have the form $cx + {\\rm Tr}_{q^l/q}(x^{d_1}\n+ x^{d_2})$. These new infinite classes explain most of numerical results by\nMAGMA under the conditions that $q=2^k$, $k>1$, $kl<14$ and $c \\in\n\\gf_{q^l}^*$. Finally, we construct some binary linear codes using the newly\nproposed $2$-to-$1$ mappings of the form $cx + {\\rm Tr}_{q^l/q}(x^d)$. The\nweight distributions of these codes are also determined. Interestingly, our\ncodes are self-orthogonal, minimal, and have few weights.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08315v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2505.14765", "title": "Deep Learning-Based Forecasting of Boarding Patient Counts to Address ED Overcrowding", "authors": ["Orhun Vural", "Bunyamin Ozaydin", "James Booth", "Brittany F. Lindsey", "Abdulaziz Ahmed"], "categories": ["cs.LG", "cs.AI", "68T07", "I.2.6; J.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Feature engineering, results, and model explainability have been updated. NBEATSx algorithm was removed due to overfitting during training", "url": "http://arxiv.org/abs/2505.14765v2", "summary": "This study presents a deep learning-based framework for predicting emergency\ndepartment (ED) boarding counts six hours in advance using only operational and\ncontextual data, without patient-level information. Data from ED tracking\nsystems, inpatient census, weather, holidays, and local events were aggregated\nhourly and processed with comprehensive feature engineering. The mean ED\nboarding count was 28.7 (standard deviation = 11.2). Multiple deep learning\nmodels, including ResNetPlus, TSTPlus, and TSiTPlus, were trained and optimized\nusing Optuna, with TSTPlus achieving the best results (mean absolute error =\n4.30, mean squared error = 29.47, R2 = 0.79). The framework accurately\nforecasted boarding counts, including during extreme periods, and demonstrated\nthat broader input features improve predictive accuracy. This approach supports\nproactive hospital management and offers a practical method for mitigating ED\novercrowding.", "comment": "Feature engineering, results, and model explainability have been\n  updated. NBEATSx algorithm was removed due to overfitting during training", "pdf_url": "http://arxiv.org/pdf/2505.14765v2", "cate": "cs.LG", "date": "2025-05-20", "updated": "2025-07-10"}
{"id": "2408.16138", "title": "Thinner Latent Spaces: Detecting Dimension and Imposing Invariance with Conformal Autoencoders", "authors": ["George A. Kevrekidis", "Zan Ahmad", "Mauro Maggioni", "Soledad Villar", "Yannis G. Kevrekidis"], "categories": ["cs.LG", "math.DG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2408.16138v2", "summary": "Conformal Autoencoders are a neural network architecture that imposes\northogonality conditions between the gradients of latent variables to obtain\ndisentangled representations of data. In this work we show that orthogonality\nrelations within the latent layer of the network can be leveraged to infer the\nintrinsic dimensionality of nonlinear manifold data sets (locally characterized\nby the dimension of their tangent space), while simultaneously computing\nencoding and decoding (embedding) maps. We outline the relevant theory relying\non differential geometry, and describe the corresponding gradient-descent\noptimization algorithm. The method is applied to several data sets and we\nhighlight its applicability, advantages, and shortcomings. In addition, we\ndemonstrate that the same computational technology can be used to build\ncoordinate invariance to local group actions when defined only on a (reduced)\nsubmanifold of the embedding space.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2408.16138v2", "cate": "cs.LG", "date": "2024-08-28", "updated": "2025-07-11"}
{"id": "2504.18906", "title": "Sim-to-Real: An Unsupervised Noise Layer for Screen-Camera Watermarking Robustness", "authors": ["Yufeng Wu", "Xin Liao", "Baowei Wang", "Han Fang", "Xiaoshuai Wu", "Guiling Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.18906v2", "summary": "Unauthorized screen capturing and dissemination pose severe security threats\nsuch as data leakage and information theft. Several studies propose robust\nwatermarking methods to track the copyright of Screen-Camera (SC) images,\nfacilitating post-hoc certification against infringement. These techniques\ntypically employ heuristic mathematical modeling or supervised neural network\nfitting as the noise layer, to enhance watermarking robustness against SC.\nHowever, both strategies cannot fundamentally achieve an effective\napproximation of SC noise. Mathematical simulation suffers from biased\napproximations due to the incomplete decomposition of the noise and the absence\nof interdependence among the noise components. Supervised networks require\npaired data to train the noise-fitting model, and it is difficult for the model\nto learn all the features of the noise. To address the above issues, we propose\nSimulation-to-Real (S2R). Specifically, an unsupervised noise layer employs\nunpaired data to learn the discrepancy between the modeled simulated noise\ndistribution and the real-world SC noise distribution, rather than directly\nlearning the mapping from sharp images to real-world images. Learning this\ntransformation from simulation to reality is inherently simpler, as it\nprimarily involves bridging the gap in noise distributions, instead of the\ncomplex task of reconstructing fine-grained image details. Extensive\nexperimental results validate the efficacy of the proposed method,\ndemonstrating superior watermark robustness and generalization compared to\nstate-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.18906v2", "cate": "cs.CV", "date": "2025-04-26", "updated": "2025-07-11"}
{"id": "2507.08498", "title": "Semantic-Augmented Latent Topic Modeling with LLM-in-the-Loop", "authors": ["Mengze Hong", "Chen Jason Zhang", "Di Jiang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08498v1", "summary": "Latent Dirichlet Allocation (LDA) is a prominent generative probabilistic\nmodel used for uncovering abstract topics within document collections. In this\npaper, we explore the effectiveness of augmenting topic models with Large\nLanguage Models (LLMs) through integration into two key phases: Initialization\nand Post-Correction. Since the LDA is highly dependent on the quality of its\ninitialization, we conduct extensive experiments on the LLM-guided topic\nclustering for initializing the Gibbs sampling algorithm. Interestingly, the\nexperimental results reveal that while the proposed initialization strategy\nimproves the early iterations of LDA, it has no effect on the convergence and\nyields the worst performance compared to the baselines. The LLM-enabled\npost-correction, on the other hand, achieved a promising improvement of 5.86%\nin the coherence evaluation. These results highlight the practical benefits of\nthe LLM-in-the-loop approach and challenge the belief that LLMs are always the\nsuperior text mining alternative.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08498v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.09832", "title": "Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs", "authors": ["Zhangsong Li"], "categories": ["stat.ML", "cs.DS", "cs.LG", "math.PR", "math.ST", "stat.TH", "68Q87, 62M20"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      minor updates; extended abstract to appear in RANDOM 2025", "url": "http://arxiv.org/abs/2502.09832v3", "summary": "In this paper, assuming a natural strengthening of the low-degree conjecture,\nwe provide evidence of computational hardness for two problems: (1) the\n(partial) matching recovery problem in the sparse correlated Erd\\H{o}s-R\\'enyi\ngraphs $\\mathcal G(n,q;\\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the\ncorrelation $\\rho<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a\nremaining problem in \\cite{DDL23+}; (2) the detection problem between the\ncorrelated sparse stochastic block model $\\mathcal\nS(n,\\tfrac{\\lambda}{n};k,\\epsilon;s)$ and a pair of independent stochastic\nblock models $\\mathcal S(n,\\tfrac{\\lambda s}{n};k,\\epsilon)$ when $\\epsilon^2\n\\lambda s<1$ lies below the Kesten-Stigum (KS) threshold and $s<\\sqrt{\\alpha}$\nlies below the Otter's threshold, solving a remaining problem in\n\\cite{CDGL24+}.\n  One of the main ingredient in our proof is to derive certain forms of\n\\emph{algorithmic contiguity} between two probability measures based on bounds\non their low-degree advantage. To be more precise, consider the\nhigh-dimensional hypothesis testing problem between two probability measures\n$\\mathbb{P}$ and $\\mathbb{Q}$ based on the sample $\\mathsf Y$. We show that if\nthe low-degree advantage $\\mathsf{Adv}_{\\leq D} \\big(\n\\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\mathbb{Q}} \\big)=O(1)$, then (assuming\nthe low-degree conjecture) there is no efficient algorithm $\\mathcal A$ such\nthat $\\mathbb{Q}(\\mathcal A(\\mathsf Y)=0)=1-o(1)$ and $\\mathbb{P}(\\mathcal\nA(\\mathsf Y)=1)=\\Omega(1)$. This framework provides a useful tool for\nperforming reductions between different inference tasks.", "comment": "minor updates; extended abstract to appear in RANDOM 2025", "pdf_url": "http://arxiv.org/pdf/2502.09832v3", "cate": "stat.ML", "date": "2025-02-14", "updated": "2025-07-11"}
{"id": "2311.06069", "title": "A filtered multilevel Monte Carlo method for estimating the expectation of cell-centered discretized random fields", "authors": ["Jérémy Briant", "Paul Mycek", "Mayeul Destouches", "Olivier Goux", "Serge Gratton", "Selime Gürol", "Ehouarn Simon", "Anthony T. Weaver"], "categories": ["math.NA", "cs.NA", "65C05, 62P12"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2311.06069v4", "summary": "In this paper, we investigate the use of multilevel Monte Carlo (MLMC)\nmethods for estimating the expectation of discretized random fields.\nSpecifically, we consider a setting in which the input and output vectors of\nnumerical simulators have inconsistent dimensions across the multilevel\nhierarchy. This motivates the introduction of grid transfer operators borrowed\nfrom multigrid methods. By adapting mathematical tools from multigrid methods,\nwe perform a theoretical spectral analysis of the MLMC estimator of the\nexpectation of discretized random fields, in the specific case of linear,\nsymmetric and circulant simulators. We then propose filtered MLMC (F-MLMC)\nestimators based on a filtering mechanism similar to the smoothing process of\nmultigrid methods, and we show that the filtering operators improve the\nestimation of both the small- and large-scale components of the variance,\nresulting in a reduction of the total variance of the estimator. Next, the\nconclusions of the spectral analysis are experimentally verified with a\none-dimensional illustration. Finally, the proposed F-MLMC estimator is applied\nto the problem of estimating the discretized variance field of a\ndiffusion-based covariance operator, which amounts to estimating the\nexpectation of a discretized random field. The numerical experiments support\nthe conclusions of the theoretical analysis even with non-linear simulators,\nand demonstrate the improvements brought by the F-MLMC estimator compared to\nboth a crude MC and an unfiltered MLMC estimator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2311.06069v4", "cate": "math.NA", "date": "2023-11-10", "updated": "2025-07-11"}
{"id": "2507.08352", "title": "Secrecy Offloading Analysis of UAV-assisted NOMA-MEC Incorporating WPT in IoT Networks", "authors": ["Gia-Huy Nguyen", "Anh-Nhat Nguyen", "Minh-Sang Nguyen", "Khai Nguyen", "Tung-Son Ngo", "Ngoc-Anh Bui", "Phuong-Chi Le", "Manh-Duc Hoang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 7 figures, 2024 28th International Computer Science and Engineering Conference (ICSEC)", "url": "http://arxiv.org/abs/2507.08352v1", "summary": "This article studies the efficiency of secrecy data offloading for an\nunmanned aerial vehicle (UAV)-assisted nonorthogonal multiple access\n(NOMA)-integrated mobile-edge computing (MEC) incorporating wireless power\ntransfer (WPT) within an Internet of Things (IoT) network. Specifically, this\nstudy assumes an UAV to function in dual roles: as a mobile computation\nplatform and as an aerial power-supply station, offering substantial advantages\nfor resource-constrained edge devices (EDs) in mitigating interference from an\npassive eavesdropper. To assess the system's secrecy offloading efficacy, the\nsecrecy successful computation probability (SSCP) closed-formed formulation\nunder Nakagami-m fading channel is derived. The theoretical results are\nconducted with a variety of parameters, thereby validating the precision of our\nanalysis.", "comment": "6 pages, 7 figures, 2024 28th International Computer Science and\n  Engineering Conference (ICSEC)", "pdf_url": "http://arxiv.org/pdf/2507.08352v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.05718", "title": "Grokking Beyond the Euclidean Norm of Model Parameters", "authors": ["Pascal Jr Tikeng Notsawo", "Guillaume Dumas", "Guillaume Rabusseau"], "categories": ["cs.LG", "cs.AI", "stat.ML", "I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      67 pages, 35 figures. Forty-second International Conference on Machine Learning (ICML), 2025", "url": "http://arxiv.org/abs/2506.05718v2", "summary": "Grokking refers to a delayed generalization following overfitting when\noptimizing artificial neural networks with gradient-based methods. In this\nwork, we demonstrate that grokking can be induced by regularization, either\nexplicit or implicit. More precisely, we show that when there exists a model\nwith a property $P$ (e.g., sparse or low-rank weights) that generalizes on the\nproblem of interest, gradient descent with a small but non-zero regularization\nof $P$ (e.g., $\\ell_1$ or nuclear norm regularization) results in grokking.\nThis extends previous work showing that small non-zero weight decay induces\ngrokking. Moreover, our analysis shows that over-parameterization by adding\ndepth makes it possible to grok or ungrok without explicitly using\nregularization, which is impossible in shallow cases. We further show that the\n$\\ell_2$ norm is not a reliable proxy for generalization when the model is\nregularized toward a different property $P$, as the $\\ell_2$ norm grows in many\ncases where no weight decay is used, but the model generalizes anyway. We also\nshow that grokking can be amplified solely through data selection, with any\nother hyperparameter fixed.", "comment": "67 pages, 35 figures. Forty-second International Conference on\n  Machine Learning (ICML), 2025", "pdf_url": "http://arxiv.org/pdf/2506.05718v2", "cate": "cs.LG", "date": "2025-06-06", "updated": "2025-07-10"}
{"id": "2410.04774", "title": "Granular Ball Twin Support Vector Machine", "authors": ["A. Quadir", "M. Sajid", "M. Tanveer"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Manuscript submitted to IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS: 19 September 2023; revised 13 February 2024 and 14 July 2024; accepted 05 October 2024", "url": "http://arxiv.org/abs/2410.04774v3", "summary": "On Efficient and Scalable Computation of the Nonparametric Maximum Likelihood\nEstimator in Mixture ModelsTwin support vector machine (TSVM) is an emerging\nmachine learning model with versatile applicability in classification and\nregression endeavors. Nevertheless, TSVM confronts noteworthy challenges: $(i)$\nthe imperative demand for matrix inversions presents formidable obstacles to\nits efficiency and applicability on large-scale datasets; $(ii)$ the omission\nof the structural risk minimization (SRM) principle in its primal formulation\nheightens the vulnerability to overfitting risks; and $(iii)$ the TSVM exhibits\na high susceptibility to noise and outliers, and also demonstrates instability\nwhen subjected to resampling. In view of the aforementioned challenges, we\npropose the granular ball twin support vector machine (GBTSVM). GBTSVM takes\ngranular balls, rather than individual data points, as inputs to construct a\nclassifier. These granular balls, characterized by their coarser granularity,\nexhibit robustness to resampling and reduced susceptibility to the impact of\nnoise and outliers. We further propose a novel large-scale granular ball twin\nsupport vector machine (LS-GBTSVM). LS-GBTSVM's optimization formulation\nensures two critical facets: $(i)$ it eliminates the need for matrix\ninversions, streamlining the LS-GBTSVM's computational efficiency, and $(ii)$\nit incorporates the SRM principle through the incorporation of regularization\nterms, effectively addressing the issue of overfitting. The proposed LS-GBTSVM\nexemplifies efficiency, scalability for large datasets, and robustness against\nnoise and outliers. We conduct a comprehensive evaluation of the GBTSVM and\nLS-GBTSVM models on benchmark datasets from UCI, KEEL, and NDC datasets. Our\nexperimental findings and statistical analyses affirm the superior\ngeneralization prowess of the proposed GBTSVM and LS-GBTSVM models.", "comment": "Manuscript submitted to IEEE TRANSACTIONS ON NEURAL NETWORKS AND\n  LEARNING SYSTEMS: 19 September 2023; revised 13 February 2024 and 14 July\n  2024; accepted 05 October 2024", "pdf_url": "http://arxiv.org/pdf/2410.04774v3", "cate": "cs.LG", "date": "2024-10-07", "updated": "2025-07-11"}
{"id": "2505.08423", "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "authors": ["Sadaf Gulshad", "Abdullah Aldahlawi Thakaa"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.08423v3", "summary": "Facial recognition systems have achieved remarkable success by leveraging\ndeep neural networks, advanced loss functions, and large-scale datasets.\nHowever, their performance often deteriorates in real-world scenarios involving\nlow-quality facial images. Such degradations, common in surveillance footage or\nstandoff imaging include low resolution, motion blur, and various distortions,\nresulting in a substantial domain gap from the high-quality data typically used\nduring training. While existing approaches attempt to address robustness by\nmodifying network architectures or modeling global spatial transformations,\nthey frequently overlook local, non-rigid deformations that are inherently\npresent in real-world settings. In this work, we introduce \\textbf{DArFace}, a\n\\textbf{D}eformation-\\textbf{A}ware \\textbf{r}obust \\textbf{Face} recognition\nframework that enhances robustness to such degradations without requiring\npaired high- and low-quality training samples. Our method adversarially\nintegrates both global transformations (e.g., rotation, translation) and local\nelastic deformations during training to simulate realistic low-quality\nconditions. Moreover, we introduce a contrastive objective to enforce identity\nconsistency across different deformed views. Extensive evaluations on\nlow-quality benchmarks including TinyFace, IJB-B, and IJB-C demonstrate that\nDArFace surpasses state-of-the-art methods, with significant gains attributed\nto the inclusion of local deformation modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.08423v3", "cate": "cs.CV", "date": "2025-05-13", "updated": "2025-07-11"}
{"id": "2507.08538", "title": "The AI Language Proficiency Monitor -- Tracking the Progress of LLMs on Multilingual Benchmarks", "authors": ["David Pomerenke", "Jonas Nothnagel", "Simon Ostermann"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08538v1", "summary": "To ensure equitable access to the benefits of large language models (LLMs),\nit is essential to evaluate their capabilities across the world's languages. We\nintroduce the AI Language Proficiency Monitor, a comprehensive multilingual\nbenchmark that systematically assesses LLM performance across up to 200\nlanguages, with a particular focus on low-resource languages. Our benchmark\naggregates diverse tasks including translation, question answering, math, and\nreasoning, using datasets such as FLORES+, MMLU, GSM8K, TruthfulQA, and ARC. We\nprovide an open-source, auto-updating leaderboard and dashboard that supports\nresearchers, developers, and policymakers in identifying strengths and gaps in\nmodel performance. In addition to ranking models, the platform offers\ndescriptive insights such as a global proficiency map and trends over time. By\ncomplementing and extending prior multilingual benchmarks, our work aims to\nfoster transparency, inclusivity, and progress in multilingual AI. The system\nis available at\nhttps://huggingface.co/spaces/fair-forward/evals-for-every-language.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08538v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2502.14407", "title": "Sharp Phase Transitions in Estimation with Low-Degree Polynomials", "authors": ["Youngtak Sohn", "Alexander S. Wein"], "categories": ["math.ST", "cs.CC", "cs.DS", "math.PR", "stat.TH"], "primary_category": "Subjects:       Statistics Theory (math.ST)", "pdf_link": null, "comments": "Comments:      65 pages, updated references and improved exposition", "url": "http://arxiv.org/abs/2502.14407v2", "summary": "High-dimensional planted problems, such as finding a hidden dense subgraph\nwithin a random graph, often exhibit a gap between statistical and\ncomputational feasibility. While recovering the hidden structure may be\nstatistically possible, it is conjectured to be computationally intractable in\ncertain parameter regimes. A powerful approach to understanding this hardness\ninvolves proving lower bounds on the efficacy of low-degree polynomial\nalgorithms. We introduce new techniques for establishing such lower bounds,\nleading to novel results across diverse settings: planted submatrix, planted\ndense subgraph, the spiked Wigner model, and the stochastic block model.\nNotably, our results address the estimation task -- whereas most prior work is\nlimited to hypothesis testing -- and capture sharp phase transitions such as\nthe \"BBP\" transition in the spiked Wigner model (named for Baik, Ben Arous, and\nP\\'{e}ch\\'{e}) and the Kesten-Stigum threshold in the stochastic block model.\nExisting work on estimation either falls short of achieving these sharp\nthresholds or is limited to polynomials of very low (constant or logarithmic)\ndegree. In contrast, our results rule out estimation with polynomials of degree\n$n^{\\delta}$ where $n$ is the dimension and $\\delta > 0$ is a constant, and in\nsome cases we pin down the optimal constant $\\delta$. Our work resolves open\nproblems posed by Hopkins & Steurer (2017) and Schramm & Wein (2022), and\nprovides rigorous support within the low-degree framework for conjectures by\nAbbe & Sandon (2018) and Lelarge & Miolane (2019).", "comment": "65 pages, updated references and improved exposition", "pdf_url": "http://arxiv.org/pdf/2502.14407v2", "cate": "math.ST", "date": "2025-02-20", "updated": "2025-07-11"}
{"id": "2407.18594", "title": "Decoupling multistep schemes for elliptic-parabolic problems", "authors": ["Robert Altmann", "Abdullah Mujahid", "Benjamin Unger"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.18594v2", "summary": "We study the construction and convergence of decoupling multistep schemes of\nhigher order using the backward differentiation formulae for an\nelliptic-parabolic problem, which includes multiple-network poroelasticity as a\nspecial case. These schemes were first introduced in [Altmann, Maier, Unger,\nBIT Numer. Math., 64:20, 2024], where a convergence proof for the second-order\ncase is presented. Here, we present a slightly modified version of these\nschemes using a different construction of related time delay systems. We\npresent a novel convergence proof relying on concepts from G-stability\napplicable for any order and providing a sharper characterization of the\nrequired weak coupling condition. The key tool for the convergence analysis is\nthe construction of a weighted norm enabling a telescoping argument for the sum\nof the errors.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.18594v2", "cate": "math.NA", "date": "2024-07-26", "updated": "2025-07-11"}
{"id": "2507.08598", "title": "Discovering the Unequal Importance of Coded Bits in the Decoding of Polar Codes", "authors": ["Hossam Hassan", "Ali Gaber", "Mohammed Karmoose", "Noha Korany"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08598v1", "summary": "Polar codes are widely used in modern communication systems due to their\ncapacity-achieving properties. This paper investigates the importance of coded\nbits in the decoding process of polar codes and aims to determine which bits\ncontribute most to successful decoding. We investigate the problem via a\nbrute-force search approach and surrogate optimization techniques to identify\nthe most critical coded bits. We also demonstrate how mapping these important\nbits to the most reliable channels improves system performance with minimal\nadditional cost. We show the performance of our proposed bit mapping in OFDM\nbased systems, and demonstrate up to x7 gain in BER performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08598v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2506.20893", "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "authors": ["Yian Wang", "Ali Ebrahimpour-Boroojeny", "Hari Sundaram"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.20893v2", "summary": "In this work, we introduce an output-reweighting unlearning method, RWFT, a\nlightweight technique that erases an entire class from a trained classifier\nwithout full retraining. Forgetting specific classes from trained models is\nessential for enforcing user deletion rights and mitigating harmful or biased\npredictions. The full retraining is costly and existing unlearning methods fail\nto replicate the behavior of the retrained models when predicting samples from\nthe unlearned class. We prove this failure by designing a variant of membership\ninference attacks, MIA-NN that successfully reveals the unlearned class for any\nof these methods. We propose a simple redistribution of the probability mass\nfor the prediction on the samples in the forgotten class which is robust to\nMIA-NN. We also introduce a new metric based on the total variation (TV)\ndistance of the prediction probabilities to quantify residual leakage to\nprevent future methods from susceptibility to the new attack. Through extensive\nexperiments with state of the art baselines in machine unlearning, we show that\nour approach matches the results of full retraining in both metrics used for\nevaluation by prior work and the new metric we propose in this work. Compare to\nstate-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%\nin our new TV-based metric over the best existing method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.20893v2", "cate": "cs.LG", "date": "2025-06-25", "updated": "2025-07-10"}
{"id": "2411.18607", "title": "Task Arithmetic Through The Lens Of One-Shot Federated Learning", "authors": ["Zhixu Silvia Tao", "Ian Mason", "Sanjeev Kulkarni", "Xavier Boix"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published in Transactions on Machine Learning Research", "url": "http://arxiv.org/abs/2411.18607v2", "summary": "Task Arithmetic is a model merging technique that enables the combination of\nmultiple models' capabilities into a single model through simple arithmetic in\nthe weight space, without the need for additional fine-tuning or access to the\noriginal training data. However, the factors that determine the success of Task\nArithmetic remain unclear. In this paper, we examine Task Arithmetic for\nmulti-task learning by framing it as a one-shot Federated Learning problem. We\ndemonstrate that Task Arithmetic is mathematically equivalent to the commonly\nused algorithm in Federated Learning, called Federated Averaging (FedAvg). By\nleveraging well-established theoretical results from FedAvg, we identify two\nkey factors that impact the performance of Task Arithmetic: data heterogeneity\nand training heterogeneity. To mitigate these challenges, we adapt several\nalgorithms from Federated Learning to improve the effectiveness of Task\nArithmetic. Our experiments demonstrate that applying these algorithms can\noften significantly boost performance of the merged model compared to the\noriginal Task Arithmetic approach. This work bridges Task Arithmetic and\nFederated Learning, offering new theoretical perspectives on Task Arithmetic\nand improved practical methodologies for model merging.", "comment": "Published in Transactions on Machine Learning Research", "pdf_url": "http://arxiv.org/pdf/2411.18607v2", "cate": "cs.LG", "date": "2024-11-27", "updated": "2025-07-11"}
{"id": "2505.11868", "title": "MonoMobility: Zero-Shot 3D Mobility Analysis from Monocular Videos", "authors": ["Hongyi Zhou", "Yulan Guo", "Xiaogang Wang", "Kai Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.11868v3", "summary": "Accurately analyzing the motion parts and their motion attributes in dynamic\nenvironments is crucial for advancing key areas such as embodied intelligence.\nAddressing the limitations of existing methods that rely on dense multi-view\nimages or detailed part-level annotations, we propose an innovative framework\nthat can analyze 3D mobility from monocular videos in a zero-shot manner. This\nframework can precisely parse motion parts and motion attributes only using a\nmonocular video, completely eliminating the need for annotated training data.\nSpecifically, our method first constructs the scene geometry and roughly\nanalyzes the motion parts and their initial motion attributes combining depth\nestimation, optical flow analysis and point cloud registration method, then\nemploys 2D Gaussian splatting for scene representation. Building on this, we\nintroduce an end-to-end dynamic scene optimization algorithm specifically\ndesigned for articulated objects, refining the initial analysis results to\nensure the system can handle 'rotation', 'translation', and even complex\nmovements ('rotation+translation'), demonstrating high flexibility and\nversatility. To validate the robustness and wide applicability of our method,\nwe created a comprehensive dataset comprising both simulated and real-world\nscenarios. Experimental results show that our framework can effectively analyze\narticulated object motions in an annotation-free manner, showcasing its\nsignificant potential in future embodied intelligence applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.11868v3", "cate": "cs.CV", "date": "2025-05-17", "updated": "2025-07-11"}
{"id": "2507.08606", "title": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures", "authors": ["Benno Uthayasooriyar", "Antoine Ly", "Franck Vermet", "Caio Corro"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08606v1", "summary": "We introduce DocPolarBERT, a layout-aware BERT model for document\nunderstanding that eliminates the need for absolute 2D positional embeddings.\nWe extend self-attention to take into account text block positions in relative\npolar coordinate system rather than the Cartesian one. Despite being\npre-trained on a dataset more than six times smaller than the widely used\nIIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results\ndemonstrate that a carefully designed attention mechanism can compensate for\nreduced pre-training data, offering an efficient and effective alternative for\ndocument understanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08606v1", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2412.18964", "title": "Tensor Density Estimator by Convolution-Deconvolution", "authors": ["Yifan Peng", "Siyao Yang", "Yuehaw Khoo", "Daren Wang"], "categories": ["math.NA", "cs.NA", "15A69, 62Gxx"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.18964v3", "summary": "We propose a linear algebraic framework for performing density estimation. It\nconsists of three simple steps: convolving the empirical distribution with\ncertain smoothing kernels to remove the exponentially large variance;\ncompressing the empirical distribution after convolution as a tensor train,\nwith efficient tensor decomposition algorithms; and finally, applying a\ndeconvolution step to recover the estimated density from such tensor-train\nrepresentation. Numerical results demonstrate the high accuracy and efficiency\nof the proposed methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.18964v3", "cate": "math.NA", "date": "2024-12-25", "updated": "2025-07-11"}
{"id": "2507.08599", "title": "Learning to Transmit Over Unknown Erasure Channels with Empirical Erasure Rate Feedback", "authors": ["Haricharan Balasundaram", "Krishna Jagannathan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08599v1", "summary": "We address the problem of reliable data transmission within a finite time\nhorizon $T$ over a binary erasure channel with unknown erasure probability. We\nconsider a feedback model wherein the transmitter can query the receiver\ninfrequently and obtain the empirical erasure rate experienced by the latter.\nWe aim to minimize a regret quantity, i.e. how much worse a strategy performs\ncompared to an oracle who knows the probability of erasure, while operating at\nthe same block error rate. A learning vs. exploitation dilemma manifests in\nthis scenario -- specifically, we need to balance between (i) learning the\nerasure probability with reasonable accuracy and (ii) utilizing the channel to\ntransmit as many information bits as possible. We propose two strategies: (i) a\ntwo-phase approach using rate estimation followed by transmission that achieves\nan $O({T}^{\\frac 23})$ regret using only one query, and (ii) a windowing\nstrategy using geometrically-increasing window sizes that achieves an\n$O({\\sqrt{T}})$ regret using $O(\\log(T))$ queries.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08599v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.01381", "title": "Distributional Soft Actor-Critic with Diffusion Policy", "authors": ["Tong Liu", "Yinuo Wang", "Xujie Song", "Wenjun Zou", "Liangfa Chen", "Likun Wang", "Bin Shuai", "Jingliang Duan", "Shengbo Eben Li"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted IEEE ITSC 2025", "url": "http://arxiv.org/abs/2507.01381v3", "summary": "Reinforcement learning has been proven to be highly effective in handling\ncomplex control tasks. Traditional methods typically use unimodal\ndistributions, such as Gaussian distributions, to model the output of value\ndistributions. However, unimodal distribution often and easily causes bias in\nvalue function estimation, leading to poor algorithm performance. This paper\nproposes a distributional reinforcement learning algorithm called DSAC-D\n(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges\nof estimating bias in value functions and obtaining multimodal policy\nrepresentations. A multimodal distributional policy iteration framework that\ncan converge to the optimal policy was established by introducing policy\nentropy and value distribution function. A diffusion value network that can\naccurately characterize the distribution of multi peaks was constructed by\ngenerating a set of reward samples through reverse sampling using a diffusion\nmodel. Based on this, a distributional reinforcement learning algorithm with\ndual diffusion of the value network and the policy network was derived. MuJoCo\ntesting tasks demonstrate that the proposed algorithm not only learns\nmultimodal policy, but also achieves state-of-the-art (SOTA) performance in all\n9 control tasks, with significant suppression of estimation bias and total\naverage return improvement of over 10% compared to existing mainstream\nalgorithms. The results of real vehicle testing show that DSAC-D can accurately\ncharacterize the multimodal distribution of different driving styles, and the\ndiffusion policy network can characterize multimodal trajectories.", "comment": "Accepted IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2507.01381v3", "cate": "cs.LG", "date": "2025-07-02", "updated": "2025-07-11"}
{"id": "2501.00615", "title": "Predicting Barge Presence and Quantity on Inland Waterways using Vessel Tracking Data: A Machine Learning Approach", "authors": ["Geoffery Agorku", "Sarah Hernandez", "Maria Falquez", "Subhadipto Poddar", "Shihao Pang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00615v2", "summary": "This study presents a machine learning approach to predict the number of\nbarges transported by vessels on inland waterways using tracking data from the\nAutomatic Identification System (AIS). While AIS tracks the location of tug and\ntow vessels, it does not monitor the presence or number of barges transported\nby those vessels. Understanding the number and types of barges conveyed along\nriver segments, between ports, and at ports is crucial for estimating the\nquantities of freight transported on the nation's waterways. This insight is\nalso valuable for waterway management and infrastructure operations impacting\nareas such as targeted dredging operations, and data-driven resource\nallocation. Labeled sample data was generated using observations from traffic\ncameras located along key river segments and matched to AIS data records. A\nsample of 164 vessels representing up to 42 barge convoys per vessel was used\nfor model development. The methodology involved first predicting barge presence\nand then predicting barge quantity. Features derived from the AIS data included\nspeed measures, vessel characteristics, turning measures, and interaction\nterms. For predicting barge presence, the AdaBoost model achieved an F1 score\nof 0.932. For predicting barge quantity, the Random Forest combined with an\nAdaBoost ensemble model achieved an F1 score of 0.886. Bayesian optimization\nwas used for hyperparameter tuning. By advancing predictive modeling for inland\nwaterways, this study offers valuable insights for transportation planners and\norganizations, which require detailed knowledge of traffic volumes, including\nthe flow of commodities, their destinations, and the tonnage moving in and out\nof ports.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00615v2", "cate": "cs.LG", "date": "2024-12-31", "updated": "2025-07-11"}
{"id": "2505.11992", "title": "SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations", "authors": ["Songchun Zhang", "Huiyao Xu", "Sitong Guo", "Zhongwei Xie", "Hujun Bao", "Weiwei Xu", "Changqing Zou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025. 12 pages, 9 figures", "url": "http://arxiv.org/abs/2505.11992v2", "summary": "Novel view synthesis (NVS) boosts immersive experiences in computer vision\nand graphics. Existing techniques, though progressed, rely on dense multi-view\nobservations, restricting their application. This work takes on the challenge\nof reconstructing photorealistic 3D scenes from sparse or single-view inputs.\nWe introduce SpatialCrafter, a framework that leverages the rich knowledge in\nvideo diffusion models to generate plausible additional observations, thereby\nalleviating reconstruction ambiguity. Through a trainable camera encoder and an\nepipolar attention mechanism for explicit geometric constraints, we achieve\nprecise camera control and 3D consistency, further reinforced by a unified\nscale estimation strategy to handle scale discrepancies across datasets.\nFurthermore, by integrating monocular depth priors with semantic features in\nthe video latent space, our framework directly regresses 3D Gaussian primitives\nand efficiently processes long-sequence features using a hybrid network\nstructure. Extensive experiments show our method enhances sparse view\nreconstruction and restores the realistic appearance of 3D scenes.", "comment": "Accepted by ICCV 2025. 12 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2505.11992v2", "cate": "cs.CV", "date": "2025-05-17", "updated": "2025-07-11"}
{"id": "2507.08432", "title": "xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models", "authors": ["Gustavo Correa Publio", "José Emilio Labra Gayo"], "categories": ["cs.DB", "cs.CL"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the 2nd LLM+Graph Workshop, colocated at VLDB'25", "url": "http://arxiv.org/abs/2507.08432v1", "summary": "Shapes Constraint Language (SHACL) is a powerful language for validating RDF\ndata. Given the recent industry attention to Knowledge Graphs (KGs), more users\nneed to validate linked data properly. However, traditional SHACL validation\nengines often provide terse reports in English that are difficult for\nnon-technical users to interpret and act upon. This paper presents xpSHACL, an\nexplainable SHACL validation system that addresses this issue by combining\nrule-based justification trees with retrieval-augmented generation (RAG) and\nlarge language models (LLMs) to produce detailed, multilanguage, human-readable\nexplanations for constraint violations. A key feature of xpSHACL is its usage\nof a Violation KG to cache and reuse explanations, improving efficiency and\nconsistency.", "comment": "Accepted for publication in the 2nd LLM+Graph Workshop, colocated at\n  VLDB'25", "pdf_url": "http://arxiv.org/pdf/2507.08432v1", "cate": "cs.DB", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2501.10660", "title": "Blind free deconvolution over one-parameter sparse families via eigenmatrix", "authors": ["Lexing Ying"], "categories": ["math.NA", "cs.NA", "math.ST", "stat.TH"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.10660v2", "summary": "This note considers the blind free deconvolution problems of sparse spectral\nmeasures from one-parameter families. These problems pose significant\nchallenges since they involve nonlinear sparse recovery. The main technical\ntool is the eigenmatrix method for solving unstructured sparse recovery\nproblems. The key idea is to turn the nonlinear inverse problem into a linear\ninverse problem by leveraging the R-transform for free addition and the\nS-transform for free product. The resulting linear problem is solved with the\neigenmatrix method tailored to the domain of the parametric family. Numerical\nresults are provided for both the additive and multiplicative free\ndeconvolutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.10660v2", "cate": "math.NA", "date": "2025-01-18", "updated": "2025-07-10"}
{"id": "2507.08611", "title": "Evaluating the Performance of Reconfigurable Intelligent Base Stations through Ray Tracing", "authors": ["Sina Beyraghi", "Giovanni Interdonato", "Giovanni Geraci", "Stefano Buzzi", "Angel Lozano"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08611v1", "summary": "Massive multiple-input multiple-output (mMIMO) is a key capacity-boosting\ntechnology in 5G wireless systems. To reduce the number of radio frequency (RF)\nchains needed in such systems, a novel approach has recently been introduced\ninvolving an antenna array supported by a reconfigurable intelligent surface.\nThis arrangement, known as a reconfigurable intelligent base station (RIBS),\noffers performance comparable to that of a traditional mMIMO array, but with\nsignificantly fewer RF chains. Given the growing importance of precise,\nlocation-specific performance prediction, this paper evaluates the performance\nof an RIBS system by means of the SIONNA ray-tracing module. That performance\nis contrasted against results derived from a statistical 3GPP-compliant channel\nmodel, optimizing power and RIS configuration to maximize the sum spectral\nefficiency. Ray tracing predicts better performance than the statistical model\nin the evaluated scenario, suggesting the potential of site-specific modeling.\nHowever, empirical validation is needed to confirm this advantage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08611v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.02358", "title": "Hita: Holistic Tokenizer for Autoregressive Image Generation", "authors": ["Anlin Zheng", "Haochen Wang", "Yucheng Zhao", "Weipeng Deng", "Tiancai Wang", "Xiangyu Zhang", "Xiaojuan Qi"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 10 figures", "url": "http://arxiv.org/abs/2507.02358v4", "summary": "Vanilla autoregressive image generation models generate visual tokens\nstep-by-step, limiting their ability to capture holistic relationships among\ntoken sequences. Moreover, because most visual tokenizers map local image\npatches into latent tokens, global information is limited. To address this, we\nintroduce \\textit{Hita}, a novel image tokenizer for autoregressive (AR) image\ngeneration. It introduces a holistic-to-local tokenization scheme with\nlearnable holistic queries and local patch tokens. Hita incorporates two key\nstrategies to better align with the AR generation process: 1) {arranging} a\nsequential structure with holistic tokens at the beginning, followed by\npatch-level tokens, and using causal attention to maintain awareness of\nprevious tokens; and 2) adopting a lightweight fusion module before feeding the\nde-quantized tokens into the decoder to control information flow and prioritize\nholistic tokens. Extensive experiments show that Hita accelerates the training\nspeed of AR generators and outperforms those trained with vanilla tokenizers,\nachieving \\textbf{2.59 FID} and \\textbf{281.9 IS} on the ImageNet benchmark.\nDetailed analysis of the holistic representation highlights its ability to\ncapture global image properties, such as textures, materials, and shapes.\nAdditionally, Hita also demonstrates effectiveness in zero-shot style transfer\nand image in-painting. The code is available at\n\\href{https://github.com/CVMI-Lab/Hita}{https://github.com/CVMI-Lab/Hita}.", "comment": "17 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.02358v4", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-11"}
{"id": "2502.02582", "title": "Open Materials Generation with Stochastic Interpolants", "authors": ["Philipp Hoellmer", "Thomas Egg", "Maya M. Martirossyan", "Eric Fuemmeler", "Zeren Shui", "Amit Gupta", "Pawan Prakash", "Adrian Roitberg", "Mingjie Liu", "George Karypis", "Mark Transtrum", "Richard G. Hennig", "Ellad B. Tadmor", "Stefano Martiniani"], "categories": ["cs.LG", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at Forty-second International Conference on Machine Learning (ICML): this https URL", "url": "http://arxiv.org/abs/2502.02582v2", "summary": "The discovery of new materials is essential for enabling technological\nadvancements. Computational approaches for predicting novel materials must\neffectively learn the manifold of stable crystal structures within an infinite\ndesign space. We introduce Open Materials Generation (OMatG), a unifying\nframework for the generative design and discovery of inorganic crystalline\nmaterials. OMatG employs stochastic interpolants (SI) to bridge an arbitrary\nbase distribution to the target distribution of inorganic crystals via a broad\nclass of tunable stochastic processes, encompassing both diffusion models and\nflow matching as special cases. In this work, we adapt the SI framework by\nintegrating an equivariant graph representation of crystal structures and\nextending it to account for periodic boundary conditions in unit cell\nrepresentations. Additionally, we couple the SI flow over spatial coordinates\nand lattice vectors with discrete flow matching for atomic species. We\nbenchmark OMatG's performance on two tasks: Crystal Structure Prediction (CSP)\nfor specified compositions, and 'de novo' generation (DNG) aimed at discovering\nstable, novel, and unique structures. In our ground-up implementation of OMatG,\nwe refine and extend both CSP and DNG metrics compared to previous works. OMatG\nestablishes a new state of the art in generative modeling for materials\ndiscovery, outperforming purely flow-based and diffusion-based implementations.\nThese results underscore the importance of designing flexible deep learning\nframeworks to accelerate progress in materials science. The OMatG code is\navailable at https://github.com/FERMat-ML/OMatG.", "comment": "Accepted at Forty-second International Conference on Machine Learning\n  (ICML): https://openreview.net/forum?id=gHGrzxFujU", "pdf_url": "http://arxiv.org/pdf/2502.02582v2", "cate": "cs.LG", "date": "2025-02-04", "updated": "2025-07-11"}
{"id": "2506.03942", "title": "Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation", "authors": ["Theodore Barfoot", "Luis C. Garcia-Peraza-Herrera", "Samet Akcay", "Ben Glocker", "Tom Vercauteren"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures, IEEE TMI submission. This version originally appeared in error as arXiv:2403.06759 (v2)", "url": "http://arxiv.org/abs/2506.03942v2", "summary": "Deep neural networks for medical image segmentation are often overconfident,\ncompromising both reliability and clinical utility. In this work, we propose\ndifferentiable formulations of marginal L1 Average Calibration Error (mL1-ACE)\nas an auxiliary loss that can be computed on a per-image basis. We compare both\nhard- and soft-binning approaches to directly improve pixel-wise calibration.\nOur experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that\nincorporating mL1-ACE significantly reduces calibration errors, particularly\nAverage Calibration Error (ACE) and Maximum Calibration Error (MCE), while\nlargely maintaining high Dice Similarity Coefficients (DSCs). We find that the\nsoft-binned variant yields the greatest improvements in calibration, over the\nDice plus cross-entropy loss baseline, but often compromises segmentation\nperformance, with hard-binned mL1-ACE maintaining segmentation performance,\nalbeit with weaker calibration improvement. To gain further insight into\ncalibration performance and its variability across an imaging dataset, we\nintroduce dataset reliability histograms, an aggregation of per-image\nreliability diagrams. The resulting analysis highlights improved alignment\nbetween predicted confidences and true accuracies. Overall, our approach not\nonly enhances the trustworthiness of segmentation predictions but also shows\npotential for safer integration of deep learning methods into clinical\nworkflows. We share our code here:\nhttps://github.com/cai4cai/Average-Calibration-Losses", "comment": "12 pages, 5 figures, IEEE TMI submission. This version originally\n  appeared in error as arXiv:2403.06759(v2)", "pdf_url": "http://arxiv.org/pdf/2506.03942v2", "cate": "cs.CV", "date": "2025-06-04", "updated": "2025-07-11"}
{"id": "2111.14003", "title": "Answer Generation for Questions With Multiple Information Sources in E-Commerce", "authors": ["Anand A. Rajasekar", "Nikesh Garera"], "categories": ["cs.CL", "cs.LG", "I.2.7; H.3.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      7 pages, 10 tables, 1 figure", "url": "http://arxiv.org/abs/2111.14003v2", "summary": "Automatic question answering is an important yet challenging task in\nE-commerce given the millions of questions posted by users about the product\nthat they are interested in purchasing. Hence, there is a great demand for\nautomatic answer generation systems that provide quick responses using related\ninformation about the product. There are three sources of knowledge available\nfor answering a user posted query, they are reviews, duplicate or similar\nquestions, and specifications. Effectively utilizing these information sources\nwill greatly aid us in answering complex questions. However, there are two main\nchallenges present in exploiting these sources: (i) The presence of irrelevant\ninformation and (ii) the presence of ambiguity of sentiment present in reviews\nand similar questions. Through this work we propose a novel pipeline (MSQAP)\nthat utilizes the rich information present in the aforementioned sources by\nseparately performing relevancy and ambiguity prediction before generating a\nresponse.\n  Experimental results show that our relevancy prediction model (BERT-QA)\noutperforms all other variants and has an improvement of 12.36% in F1 score\ncompared to the BERT-base baseline. Our generation model (T5-QA) outperforms\nthe baselines in all content preservation metrics such as BLEU, ROUGE and has\nan average improvement of 35.02% in ROUGE and 198.75% in BLEU compared to the\nhighest performing baseline (HSSC-q). Human evaluation of our pipeline shows us\nthat our method has an overall improvement in accuracy of 30.7% over the\ngeneration model (T5-QA), resulting in our full pipeline-based approach (MSQAP)\nproviding more accurate answers. To the best of our knowledge, this is the\nfirst work in the e-commerce domain that automatically generates natural\nlanguage answers combining the information present in diverse sources such as\nspecifications, similar questions, and reviews data.", "comment": "7 pages, 10 tables, 1 figure", "pdf_url": "http://arxiv.org/pdf/2111.14003v2", "cate": "cs.CL", "date": "2021-11-27", "updated": "2025-07-11"}
{"id": "2505.00258", "title": "Quantile-RK and Double Quantile-RK Error Horizon Analysis", "authors": ["Emeric Battaglia", "Anna Ma"], "categories": ["math.NA", "cs.NA", "65F10, 65F20"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.00258v2", "summary": "In solving linear systems of equations of the form $Ax=b$, corruptions\npresent in $b$ affect stochastic iterative algorithms' ability to reach the\ntrue solution $x^\\ast$ to the uncorrupted linear system. The randomized\nKaczmarz method converges in expectation to $x^\\ast$ up to an error horizon\ndependent on the conditioning of $A$ and the supremum norm of the corruption in\n$b$. To avoid this error horizon in the sparse corruption setting, previous\nworks have proposed quantile-based adaptations that make iterative methods\nrobust. Our work first establishes a new convergence rate for the\nquantile-based random Kaczmarz (qRK) and double quantile-based random Kaczmarz\n(dqRK) methods, which, under certain conditions, improves upon known bounds. We\nfurther consider the more practical setting in which the vector $b$ includes\nboth non-sparse ``noise\" and sparse ``corruption\". Error horizon bounds for qRK\nand dqRK are derived and shown to produce a smaller error horizon compared to\ntheir non-quantile-based counterparts, further demonstrating the advantages of\nquantile-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.00258v2", "cate": "math.NA", "date": "2025-05-01", "updated": "2025-07-11"}
{"id": "2507.08696", "title": "Fine-tuning ORBGRAND with Very Few Channel Soft Values", "authors": ["Li Wan", "Huarui Yin", "Wenyi Zhang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08696v1", "summary": "Guessing random additive noise decoding (GRAND) is a universal decoding\nparadigm that decodes by repeatedly testing error patterns until identifying a\ncodeword, where the ordering of tests is generated by the received channel\nvalues. On one hand, while testing error patterns in a descending order of\nposterior probabilities leads to maximum likelihood decoding, its\nimplementation complexity is prohibitive. On the other hand, testing error\npatterns with a prescribed set of error patterns permuted by the ranking among\nmagnitudes of log-likelihood ratios (i.e., ordered reliability bits, ORB)\nenables efficient implementation, but results in performance loss for\nfinite-length codes. Aiming at harnessing the strengths of these two\napproaches, this work proposes a fine-tuning method to improve ORBGRAND,\nadjusting the ordering of tests with the aid of very few exact channel soft\nvalues. This method is based on a metric for assessing the ``well-orderedness''\nof error patterns. The metric is studied via the lens of the asymptotic theory\nof integer partitioning, which provides highly accurate estimation in numerical\nexperiments. The metric then leads to an effective identification of\nfine-tuning to conduct, at the cost of a negligible increment of complexity.\nNumerical experiments demonstrate that the proposed fine-tuning method achieves\na substantial performance enhancement compared with ORBGRAND.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08696v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.02827", "title": "USAD: End-to-End Human Activity Recognition via Diffusion Model with Spatiotemporal Attention", "authors": ["Hang Xiao", "Ying Yu", "Jiarui Li", "Zhifan Yang", "Haotian Tang", "Hanyu Liu", "Chao Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.02827v2", "summary": "The primary objective of human activity recognition (HAR) is to infer ongoing\nhuman actions from sensor data, a task that finds broad applications in health\nmonitoring, safety protection, and sports analysis. Despite proliferating\nresearch, HAR still faces key challenges, including the scarcity of labeled\nsamples for rare activities, insufficient extraction of high-level features,\nand suboptimal model performance on lightweight devices. To address these\nissues, this paper proposes a comprehensive optimization approach centered on\nmulti-attention interaction mechanisms. First, an unsupervised,\nstatistics-guided diffusion model is employed to perform data augmentation,\nthereby alleviating the problems of labeled data scarcity and severe class\nimbalance. Second, a multi-branch spatio-temporal interaction network is\ndesigned, which captures multi-scale features of sequential data through\nparallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels.\nSimultaneously, temporal attention mechanisms are incorporated to identify\ncritical time points, while spatial attention enhances inter-sensor\ninteractions. A cross-branch feature fusion unit is further introduced to\nimprove the overall feature representation capability. Finally, an adaptive\nmulti-loss function fusion strategy is integrated, allowing for dynamic\nadjustment of loss weights and overall model optimization. Experimental results\non three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the\nproposed unsupervised data augmentation spatio-temporal attention diffusion\nnetwork (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively,\nsignificantly outperforming existing approaches. Furthermore, practical\ndeployment on embedded devices verifies the efficiency and feasibility of the\nproposed method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.02827v2", "cate": "cs.CV", "date": "2025-07-03", "updated": "2025-07-11"}
{"id": "2502.03366", "title": "Rethinking Approximate Gaussian Inference in Classification", "authors": ["Bálint Mucsányi", "Nathaël Da Costa", "Philipp Hennig"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      35 pages", "url": "http://arxiv.org/abs/2502.03366v2", "summary": "In classification tasks, softmax functions are ubiquitously used as output\nactivations to produce predictive probabilities. Such outputs only capture\naleatoric uncertainty. To capture epistemic uncertainty, approximate Gaussian\ninference methods have been proposed. We develop a common formalism to describe\nsuch methods, which we view as outputting Gaussian distributions over the logit\nspace. Predictives are then obtained as the expectations of the Gaussian\ndistributions pushed forward through the softmax. However, such softmax\nGaussian integrals cannot be solved analytically, and Monte Carlo (MC)\napproximations can be costly and noisy. We propose to replace the softmax\nactivation by element-wise normCDF or sigmoid, which allows for the accurate\nsampling-free approximation of predictives. This also enables the approximation\nof the Gaussian pushforwards by Dirichlet distributions with moment matching.\nThis approach entirely eliminates the runtime and memory overhead associated\nwith MC sampling. We evaluate it combined with several approximate Gaussian\ninference methods (Laplace, HET, SNGP) on large- and small-scale datasets\n(ImageNet, CIFAR-100, CIFAR-10), demonstrating improved uncertainty\nquantification capabilities compared to softmax MC sampling.", "comment": "35 pages", "pdf_url": "http://arxiv.org/pdf/2502.03366v2", "cate": "cs.LG", "date": "2025-02-05", "updated": "2025-07-11"}
{"id": "2507.02899", "title": "Learning to Generate Vectorized Maps at Intersections with Multiple Roadside Cameras", "authors": ["Quanxin Zheng", "Miao Fan", "Shengtong Xu", "Linghe Kong", "Haoyi Xiong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IROS'25", "url": "http://arxiv.org/abs/2507.02899v3", "summary": "Vectorized maps are indispensable for precise navigation and the safe\noperation of autonomous vehicles. Traditional methods for constructing these\nmaps fall into two categories: offline techniques, which rely on expensive,\nlabor-intensive LiDAR data collection and manual annotation, and online\napproaches that use onboard cameras to reduce costs but suffer from limited\nperformance, especially at complex intersections. To bridge this gap, we\nintroduce MRC-VMap, a cost-effective, vision-centric, end-to-end neural network\ndesigned to generate high-definition vectorized maps directly at intersections.\nLeveraging existing roadside surveillance cameras, MRC-VMap directly converts\ntime-aligned, multi-directional images into vectorized map representations.\nThis integrated solution lowers the need for additional intermediate\nmodules--such as separate feature extraction and Bird's-Eye View (BEV)\nconversion steps--thus reducing both computational overhead and error\npropagation. Moreover, the use of multiple camera views enhances mapping\ncompleteness, mitigates occlusions, and provides robust performance under\npractical deployment constraints. Extensive experiments conducted on 4,000\nintersections across 4 major metropolitan areas in China demonstrate that\nMRC-VMap not only outperforms state-of-the-art online methods but also achieves\naccuracy comparable to high-cost LiDAR-based approaches, thereby offering a\nscalable and efficient solution for modern autonomous navigation systems.", "comment": "Accepted by IROS'25", "pdf_url": "http://arxiv.org/pdf/2507.02899v3", "cate": "cs.CV", "date": "2025-06-23", "updated": "2025-07-11"}
{"id": "2310.18290", "title": "Riddle Generation using Learning Resources", "authors": ["Niharika Sri Parasa", "Chaitali Diwan", "Srinath Srinivasa"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2310.18290v3", "summary": "One of the primary challenges in online learning environments, is to retain\nlearner engagement. Several different instructional strategies are proposed\nboth in online and offline environments to enhance learner engagement. The\nConcept Attainment Model is one such instructional strategy that focuses on\nlearners acquiring a deeper understanding of a concept rather than just its\ndictionary definition. This is done by searching and listing the properties\nused to distinguish examples from non-examples of various concepts. Our work\nattempts to apply the Concept Attainment Model to build conceptual riddles, to\ndeploy over online learning environments. The approach involves creating\nfactual triples from learning resources, classifying them based on their\nuniqueness to a concept into `Topic Markers' and `Common', followed by\ngenerating riddles based on the Concept Attainment Model's format and capturing\nall possible solutions to those riddles. The results obtained from the human\nevaluation of riddles prove encouraging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2310.18290v3", "cate": "cs.CL", "date": "2023-10-27", "updated": "2025-07-10"}
{"id": "2507.01762", "title": "Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination", "authors": ["Dong Wang", "Chunyu Chen", "Huayi Wei"], "categories": ["math.NA", "cs.NA", "math.OC", "65N50, 65K10, 65F08"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.01762v2", "summary": "The quality of simplex mesh is crucial for the stability and accuracy of\nnumerical simulations in finite element analysis and computational geometry.\nHowever, the presence of sliver elements in 3D simplex mesh can severely impact\nthe results. This paper presents a novel method based on a radius ratio energy\nfunction to optimize the quality of simplex mesh elements. This method can\neffectively eliminate sliver elements, thereby enhancing mesh quality.The\ngradient of the proposed energy function can be decomposed into a matrix-vector\nproduct. With minor processing, the matrix becomes symmetric positive definite,\nand this symmetric positive definite matrix can serve as a preconditioner to\nsignificantly accelerate the optimization process. Experimental results\ndemonstrate that this method has significant advantages in eliminating sliver\nelements and improving mesh quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.01762v2", "cate": "math.NA", "date": "2025-07-02", "updated": "2025-07-11"}
{"id": "2507.08755", "title": "Column Twisted Reed-Solomon Codes as MDS Codes", "authors": ["Wei Liu", "Jinquan Luo", "Puyin Wang", "Dengxin Zhai"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08755v1", "summary": "In this paper, we study column twisted Reed-Solomon(TRS) codes. We establish\nsome conditions for column TRS codes to be MDS codes and show that the\ndimension of their Schur square codes is $2k$. Consequently, these TRS codes\nare not equivalent to Reed-Solomon(RS) codes. Moreover, this construction\nmethod provides more flexible parameters compared to previous twisted\ngeneralized Reed-Solomon(TGRS) code constructions. For large odd prime power\n$q$, different from the systematically constructed TGRS codes whose length was\npreviously limited to $\\frac{q+1}{2}$, our construction achieves code lengths\nup to $\\frac{q+3}{2}$. Finally, we present the dual codes of column TRS codes.\nThis paper provides a new approach to construct MDS codes by adding column\nvectors to generator matrix of RS codes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08755v1", "cate": "cs.IT", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2504.10240", "title": "GNN-ACLP: Graph Neural Networks Based Analog Circuit Link Prediction", "authors": ["Guanyuan Pan", "Tiansheng Zhou", "Bingtao Ma", "Yaqi Wang", "Jianxiang Zhao", "Zhi Li", "Yugui Lin", "Pietro Lio", "Shuai Wang"], "categories": ["cs.AR", "cs.LG"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Code and data will be made available on request. V3 Update: Add Ablation Study and Discussion; Improve Introduction; Optimize Figures; Add references", "url": "http://arxiv.org/abs/2504.10240v3", "summary": "Circuit link prediction identifying missing component connections from\nincomplete netlists is crucial in automating analog circuit design. However,\nexisting methods face three main challenges: 1) Insufficient use of topological\npatterns in circuit graphs reduces prediction accuracy; 2) Data scarcity due to\nthe complexity of annotations hinders model generalization; 3) Limited\nadaptability to various netlist formats. We propose GNN-ACLP, a Graph Neural\nNetworks (GNNs) based framework featuring three innovations to tackle these\nchallenges. First, we introduce the SEAL (Subgraphs, Embeddings, and Attributes\nfor Link Prediction) framework and achieve port-level accuracy in circuit link\nprediction. Second, we propose Netlist Babel Fish, a netlist format conversion\ntool leveraging retrieval-augmented generation (RAG) with a large language\nmodel (LLM) to enhance the compatibility of netlist formats. Finally, we\nconstruct SpiceNetlist, a comprehensive dataset that contains 775 annotated\ncircuits across 10 different component classes. Experiments demonstrate\naccuracy improvements of 16.08% on SpiceNetlist, 11.38% on Image2Net, and\n16.01% on Masala-CHAI compared to the baseline in intra-dataset evaluation,\nwhile maintaining accuracy from 92.05% to 99.07% in cross-dataset evaluation,\nexhibiting robust feature transfer capabilities.", "comment": "Code and data will be made available on request. V3 Update: Add\n  Ablation Study and Discussion; Improve Introduction; Optimize Figures; Add\n  references", "pdf_url": "http://arxiv.org/pdf/2504.10240v3", "cate": "cs.AR", "date": "2025-04-14", "updated": "2025-07-11"}
{"id": "2507.03222", "title": "The role of gain neuromodulation in layer-5 pyramidal neurons", "authors": ["Alejandro Rodriguez-Garcia", "Christopher J. Whyte", "Brandon R. Munn", "Jie Mei", "James M. Shine", "Srikanth Ramaswamy"], "categories": ["q-bio.NC", "cs.AI", "68T05"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      12 pages, 7 figures, 1 table, presented at 34th Annual Computational Neuroscience Meeting", "url": "http://arxiv.org/abs/2507.03222v2", "summary": "Biological and artificial learning systems alike confront the\nplasticity-stability dilemma. In the brain, neuromodulators such as\nacetylcholine and noradrenaline relieve this tension by tuning neuronal gain\nand inhibitory gating, balancing segregation and integration of circuits. Fed\nby dense cholinergic and noradrenergic projections from the ascending arousal\nsystem, layer-5 pyramidal neurons in the cerebral cortex offer a relevant\nsubstrate for understanding these dynamics. When distal dendritic signals\ncoincide with back-propagating action potentials, calcium plateaus turn a\nsingle somatic spike into a high-gain burst, and interneuron inhibition sculpts\nthe output. These properties make layer-5 cells gain-tunable amplifiers that\ntranslate neuromodulatory cues into flexible cortical activity. To capture this\nmechanism we developed a two-compartment Izhikevich model for pyramidal neurons\nand single-compartment somatostatin (SOM) and parvalbumin (PV) interneurons,\nlinked by Gaussian connectivity and spike-timing-dependent plasticity (STDP).\nThe soma and apical dendrite are so coupled that somatic spikes back-propagate,\nwhile dendritic plateaus can switch the soma from regular firing to bursting by\nshifting reset and adaptation variables. We show that stronger dendritic drive\nor tighter coupling raise gain by increasing the likelihood of\ncalcium-triggered somatic bursts. In contrast, dendritic-targeted inhibition\nsuppresses gain, while somatic-targeted inhibition raises the firing threshold\nof neighboring neurons, thus gating neurons output. Notably, bursting\naccelerates STDP, supporting rapid synaptic reconfiguration and flexibility.\nThis suggests that brief gain pulses driven by neuromodulators could serve as\nan adaptive two-timescale optimization mechanism, effectively modulating the\nsynaptic weight updates.", "comment": "12 pages, 7 figures, 1 table, presented at 34th Annual Computational\n  Neuroscience Meeting", "pdf_url": "http://arxiv.org/pdf/2507.03222v2", "cate": "q-bio.NC", "date": "2025-07-03", "updated": "2025-07-11"}
{"id": "2502.05044", "title": "Hybrid machine learning based scale bridging framework for permeability prediction of fibrous structures", "authors": ["Denis Korolev", "Tim Schmidt", "Dinesh K. Natarajan", "Stefano Cassola", "David May", "Miro Duhovic", "Michael Hintermüller"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Paper restructured, updated numerical results", "url": "http://arxiv.org/abs/2502.05044v2", "summary": "This study introduces a hybrid machine learning-based scale-bridging\nframework for predicting the permeability of fibrous textile structures. By\naddressing the computational challenges inherent to multiscale modeling, the\nproposed approach evaluates the efficiency and accuracy of different\nscale-bridging methodologies combining traditional surrogate models and even\nintegrating physics-informed neural networks (PINNs) with numerical solvers,\nenabling accurate permeability predictions across micro- and mesoscales. Four\nmethodologies were evaluated: Single Scale Method (SSM), Simple Upscaling\nMethod (SUM), Scale-Bridging Method (SBM), and Fully Resolved Model (FRM). SSM,\nthe simplest method, neglects microscale permeability and exhibited\npermeability values deviating by up to 150\\% of the FRM model, which was taken\nas ground truth at an equivalent lower fiber volume content. SUM improved\npredictions by considering uniform microscale permeability, yielding closer\nvalues under similar conditions, but still lacked structural variability. The\nSBM method, incorporating segment-based microscale permeability assignments,\nshowed significant enhancements, achieving almost equivalent values while\nmaintaining computational efficiency and modeling runtimes of ~45 minutes per\nsimulation. In contrast, FRM, which provides the highest fidelity by fully\nresolving microscale and mesoscale geometries, required up to 270 times more\ncomputational time than SSM, with model files exceeding 300 GB. Additionally, a\nhybrid dual-scale solver incorporating PINNs has been developed and shows the\npotential to overcome generalization errors and the problem of data scarcity of\nthe data-driven surrogate approaches. The hybrid framework advances\npermeability modelling by balancing computational cost and prediction\nreliability, laying the foundation for further applications in fibrous\ncomposite manufacturing.", "comment": "Paper restructured, updated numerical results", "pdf_url": "http://arxiv.org/pdf/2502.05044v2", "cate": "cs.LG", "date": "2025-02-07", "updated": "2025-07-10"}
{"id": "2507.05730", "title": "Hyperspectral Anomaly Detection Methods: A Survey and Comparative Study", "authors": ["Aayushma Pant", "Arbind Agrahari Baniya", "Tsz-Kwan Lee", "Sunil Aryal"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05730v2", "summary": "Hyperspectral images are high-dimensional datasets comprising hundreds of\ncontiguous spectral bands, enabling detailed analysis of materials and\nsurfaces. Hyperspectral anomaly detection (HAD) refers to the technique of\nidentifying and locating anomalous targets in such data without prior\ninformation about a hyperspectral scene or target spectrum. This technology has\nseen rapid advancements in recent years, with applications in agriculture,\ndefence, military surveillance, and environmental monitoring. Despite this\nsignificant progress, existing HAD methods continue to face challenges such as\nhigh computational complexity, sensitivity to noise, and limited generalisation\nacross diverse datasets. This study presents a comprehensive comparison of\nvarious HAD techniques, categorising them into statistical models,\nrepresentation-based methods, classical machine learning approaches, and deep\nlearning models. We evaluated these methods across 17 benchmarking datasets\nusing different performance metrics, such as ROC, AUC, and separability map to\nanalyse detection accuracy, computational efficiency, their strengths,\nlimitations, and directions for future research. Our findings highlight that\ndeep learning models achieved the highest detection accuracy, while statistical\nmodels demonstrated exceptional speed across all datasets. This survey aims to\nprovide valuable insights for researchers and practitioners working to advance\nthe field of hyperspectral anomaly detection methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05730v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-11"}
{"id": "2401.17256", "title": "Weak-to-Strong Jailbreaking on Large Language Models", "authors": ["Xuandong Zhao", "Xianjun Yang", "Tianyu Pang", "Chao Du", "Lei Li", "Yu-Xiang Wang", "William Yang Wang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ICML 2025", "url": "http://arxiv.org/abs/2401.17256v4", "summary": "Large language models (LLMs) are vulnerable to jailbreak attacks - resulting\nin harmful, unethical, or biased text generations. However, existing\njailbreaking methods are computationally costly. In this paper, we propose the\nweak-to-strong jailbreaking attack, an efficient inference time attack for\naligned LLMs to produce harmful text. Our key intuition is based on the\nobservation that jailbroken and aligned models only differ in their initial\ndecoding distributions. The weak-to-strong attack's key technical insight is\nusing two smaller models (a safe and an unsafe one) to adversarially modify a\nsignificantly larger safe model's decoding probabilities. We evaluate the\nweak-to-strong attack on 5 diverse open-source LLMs from 3 organizations. The\nresults show our method can increase the misalignment rate to over 99% on two\ndatasets with just one forward pass per example. Our study exposes an urgent\nsafety issue that needs to be addressed when aligning LLMs. As an initial\nattempt, we propose a defense strategy to protect against such attacks, but\ncreating more advanced defenses remains challenging. The code for replicating\nthe method is available at https://github.com/XuandongZhao/weak-to-strong", "comment": "ICML 2025", "pdf_url": "http://arxiv.org/pdf/2401.17256v4", "cate": "cs.CL", "date": "2024-01-30", "updated": "2025-07-11"}
{"id": "2402.02523", "title": "FEniCSx-pctools: Tools for PETSc block linear algebra preconditioning in FEniCSx", "authors": ["Martin Řehoř", "Jack S. Hale"], "categories": ["cs.MS", "cs.NA", "math.NA", "65N22, 65F08, 65F10"], "primary_category": "Subjects:       Mathematical Software (cs.MS)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 1 table", "url": "http://arxiv.org/abs/2402.02523v2", "summary": "Solving partial differential equations with the finite element method leads\nto large linear systems of equations that must be solved. When these systems\nhave a natural block structure due to multiple field variables, using iterative\nsolvers with carefully designed preconditioning strategies that exploit the\nunderlying physical structure becomes necessary for an efficient and scalable\nsolution process. FEniCSx Preconditioning Tools (FEniCSx-pctools) is a software\npackage that eases the specification of PETSc (Portable, Extensible Toolkit for\nScientific Computation) block preconditioning strategies on linear systems\nassembled using the DOLFINx finite element solver of the FEniCS Project. The\npackage automatically attaches all necessary metadata so that preconditioning\nstrategies can be applied via PETSc's standard options-based configuration\nsystem. The documented examples include a simple mixed Poisson system and more\ncomplex pressure convection-diffusion approach to preconditioning the\nNavier-Stokes equations. We show weak parallel scaling on a fully coupled\ntemperature-Navier-Stokes system up to 8192 MPI (Message Passing Interface)\nprocesses, demonstrating the applicability of the approach to large-scale\nproblems.", "comment": "11 pages, 7 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2402.02523v2", "cate": "cs.MS", "date": "2024-02-04", "updated": "2025-07-10"}
{"id": "2507.08040", "title": "Conditional Probability formula as a consequence of the Insufficient Reason Principle", "authors": ["Alexander Dukhovny"], "categories": ["math.PR", "cs.IT", "math.IT", "primary 60"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08040v1", "summary": "The standard conditional probability definition formula is derived as a\nconsequence of the Insufficient Reason Principle expressed as the Maximum\nRelative Divergence Principle for grading (order-comonotonic) functions on a\ntotally ordered set.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08040v1", "cate": "math.PR", "date": "2025-07-09", "updated": "2025-07-09"}
{"id": "2507.05416", "title": "EmissionNet: Air Quality Pollution Forecasting for Agriculture", "authors": ["Prady Saligram", "Tanvir Bhathal"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The appendix figures are mixed up - several emission plots (e.g. CO2, CH4, GWP) are mislabeled and appear in the wrong order, leading to confusion in interpreting the results", "url": "http://arxiv.org/abs/2507.05416v2", "summary": "Air pollution from agricultural emissions is a significant yet often\noverlooked contributor to environmental and public health challenges.\nTraditional air quality forecasting models rely on physics-based approaches,\nwhich struggle to capture complex, nonlinear pollutant interactions. In this\nwork, we explore forecasting N$_2$O agricultural emissions through evaluating\npopular architectures, and proposing two novel deep learning architectures,\nEmissionNet (ENV) and EmissionNet-Transformer (ENT). These models leverage\nconvolutional and transformer-based architectures to extract spatial-temporal\ndependencies from high-resolution emissions data", "comment": "The appendix figures are mixed up - several emission plots (e.g. CO2,\n  CH4, GWP) are mislabeled and appear in the wrong order, leading to confusion\n  in interpreting the results", "pdf_url": "http://arxiv.org/pdf/2507.05416v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-11"}
{"id": "2503.04088", "title": "Cloud Computing Energy Consumption Prediction Based on Kernel Extreme Learning Machine Algorithm Improved by Vector Weighted Average Algorithm", "authors": ["Yuqing Wang", "Xiao Yang"], "categories": ["cs.LG", "cs.PF"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04088v3", "summary": "With the rapid expansion of cloud computing infrastructure, energy\nconsumption has become a critical challenge, driving the need for accurate and\nefficient prediction models. This study proposes a novel Vector Weighted\nAverage Kernel Extreme Learning Machine (VWAA-KELM) model to enhance energy\nconsumption prediction in cloud computing environments. By integrating a vector\nweighted average algorithm (VWAA) with kernel extreme learning machine (KELM),\nthe proposed model dynamically adjusts feature weights and optimizes kernel\nfunctions, significantly improving prediction accuracy and generalization.\nExperimental results demonstrate the superior performance of VWAA-KELM: 94.7%\nof test set prediction errors fall within [0, 50] units, with only three cases\nexceeding 100 units, indicating strong stability. The model achieves a\ncoefficient of determination (R2) of 0.987 in the training set (RMSE = 28.108,\nRPD = 8.872) and maintains excellent generalization with R2 = 0.973 in the test\nset (RMSE = 43.227, RPD = 6.202). Visual analysis confirms that predicted\nvalues closely align with actual energy consumption trends, avoiding\noverfitting while capturing nonlinear dependencies. A key innovation of this\nstudy is the introduction of adaptive feature weighting, allowing the model to\ndynamically assign importance to different input parameters, thereby enhancing\nhigh-dimensional data processing. This advancement provides a scalable and\nefficient approach for optimizing cloud data center energy consumption. Beyond\ncloud computing, the proposed hybrid framework has broader applications in\nInternet of Things (IoT) and edge computing, supporting real-time energy\nmanagement and intelligent resource allocation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04088v3", "cate": "cs.LG", "date": "2025-03-06", "updated": "2025-07-10"}
{"id": "2507.07104", "title": "Vision-Language-Vision Auto-Encoder: Scalable Knowledge Distillation from Diffusion Models", "authors": ["Tiezheng Zhang", "Yitong Li", "Yu-cheng Chou", "Jieneng Chen", "Alan Yuille", "Chen Wei", "Junfei Xiao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project Page: this https URL", "url": "http://arxiv.org/abs/2507.07104v2", "summary": "Building state-of-the-art Vision-Language Models (VLMs) with strong\ncaptioning capabilities typically necessitates training on billions of\nhigh-quality image-text pairs, requiring millions of GPU hours. This paper\nintroduces the Vision-Language-Vision (VLV) auto-encoder framework, which\nstrategically leverages key pretrained components: a vision encoder, the\ndecoder of a Text-to-Image (T2I) diffusion model, and subsequently, a Large\nLanguage Model (LLM). Specifically, we establish an information bottleneck by\nregularizing the language representation space, achieved through freezing the\npretrained T2I diffusion decoder. Our VLV pipeline effectively distills\nknowledge from the text-conditioned diffusion model using continuous\nembeddings, demonstrating comprehensive semantic understanding via high-quality\nreconstructions. Furthermore, by fine-tuning a pretrained LLM to decode the\nintermediate language representations into detailed descriptions, we construct\na state-of-the-art (SoTA) captioner comparable to leading models like GPT-4o\nand Gemini 2.0 Flash. Our method demonstrates exceptional cost-efficiency and\nsignificantly reduces data requirements; by primarily utilizing single-modal\nimages for training and maximizing the utility of existing pretrained models\n(image encoder, T2I diffusion model, and LLM), it circumvents the need for\nmassive paired image-text datasets, keeping the total training expenditure\nunder $1,000 USD.", "comment": "Project Page: https://lambert-x.github.io/Vision-Language-Vision/", "pdf_url": "http://arxiv.org/pdf/2507.07104v2", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2404.14192", "title": "Swap distance minimization beyond entropy minimization in word order variation", "authors": ["Víctor Franco-Sánchez", "Arnau Martí-Llobet", "Ramon Ferrer-i-Cancho"], "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Reorganization with technical appendices; minor corrections; in press in the Journal of Quantitative Linguistics", "url": "http://arxiv.org/abs/2404.14192v5", "summary": "Consider a linguistic structure formed by $n$ elements, for instance,\nsubject, direct object and verb ($n=3$) or subject, direct object, indirect\nobject and verb ($n=4$). We investigate whether the frequency of the $n!$\npossible orders is constrained by two principles. First, entropy minimization,\na principle that has been suggested to shape natural communication systems at\ndistinct levels of organization. Second, swap distance minimization, namely a\npreference for word orders that require fewer swaps of adjacent elements to be\nproduced from a source order. We present average swap distance, a novel score\nfor research on swap distance minimization. We find strong evidence of pressure\nfor entropy minimization and swap distance minimization with respect to a die\nrolling experiment in distinct linguistic structures with $n=3$ or $n=4$.\nEvidence with respect to a Polya urn process is strong for $n=4$ but weaker for\n$n=3$. We still find evidence consistent with the action of swap distance\nminimization when word order frequencies are shuffled, indicating that swap\ndistance minimization effects are beyond pressure to reduce word order entropy.", "comment": "Reorganization with technical appendices; minor corrections; in press\n  in the Journal of Quantitative Linguistics", "pdf_url": "http://arxiv.org/pdf/2404.14192v5", "cate": "cs.CL", "date": "2024-04-22", "updated": "2025-07-11"}
{"id": "2410.15982", "title": "State Estimation Using Sparse DEIM and Recurrent Neural Networks", "authors": ["Mohammad Farazmand"], "categories": ["math.DS", "cs.LG", "cs.NA", "math.NA", "nlin.CD"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.15982v2", "summary": "Sparse Discrete Empirical Interpolation Method (S-DEIM) was recently proposed\nfor state estimation in dynamical systems when only a sparse subset of the\nstate variables can be observed. The S-DEIM estimate involves a kernel vector\nwhose optimal value is inferred through a data assimilation algorithm. This\ndata assimilation step suffers from two drawbacks: (i) It requires the\nknowledge of the governing equations of the dynamical system, and (ii) It is\nnot generally guaranteed to converge to the optimal kernel vector. To address\nthese issues, here we introduce an equation-free S-DEIM framework that\nestimates the optimal kernel vector from sparse observational time series using\nrecurrent neural networks (RNNs). We show that the recurrent architecture is\nnecessary since the kernel vector cannot be estimated from instantaneous\nobservations. But RNNs, which incorporate the past history of the observations\nin the learning process, lead to nearly optimal estimations. We demonstrate the\nefficacy of our method on three numerical examples with increasing degree of\nspatiotemporal complexity: a conceptual model of atmospheric flow known as the\nLorenz-96 system, the Kuramoto-Sivashinsky equation, and the Rayleigh-Benard\nconvection. In each case, the resulting S-DEIM estimates are satisfactory even\nwhen a relatively simple RNN architecture, namely the reservoir computing\nnetwork, is used.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.15982v2", "cate": "math.DS", "date": "2024-10-21", "updated": "2025-07-10"}
{"id": "2507.08433", "title": "On the $(k,\\ell)$-multiset anonymity measure for social graphs", "authors": ["Alejandro Estrada-Moreno", "Elena Fernández", "Dorota Kuziak", "Manuel Muñoz-Márquez", "Rolando Trujillo-Rasua", "Ismael G. Yero"], "categories": ["math.CO", "cs.IT", "math.IT"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "Comments:      25 pages", "url": "http://arxiv.org/abs/2507.08433v1", "summary": "The publication of social graphs must be preceded by a rigorous analysis of\nprivacy threats against social graph users. When the threat comes from inside\nthe social network itself, the threat is called an active attack, and the\nde-facto privacy measure used to quantify the resistance to such an attack is\nthe $(k,\\ell)$-anonymity. The original formulation of $(k,\\ell)$-anonymity\nrepresents the adversary's knowledge as a vector of distances to the set of\nattacker nodes. In this article, we argue that such adversary is too strong\nwhen it comes to counteracting active attacks. We, instead, propose a new\nformulation where the adversary's knowledge is the multiset of distances to the\nset of attacker nodes. The goal of this article is to study the\n$(k,\\ell)$-multiset anonymity from a graph theoretical point of view, while\nestablishing its relationship to $(k,\\ell)$-anonymity in one hand, and\nconsidering the $k$-multiset antiresolving sets as its theoretical frame, in a\nsecond one. That is, we prove properties of some graph families in relation to\nwhether they contain a set of attacker nodes that breaks the\n$(k,\\ell)$-multiset anonymity. From a practical point of view, we develop a\nlinear programming formulation of the $k$-multiset antiresolving sets that\nallows us to calculate the resistance of social graphs against active attacks.\nThis is useful for analysts who wish to know the level of privacy offered by a\ngraph.", "comment": "25 pages", "pdf_url": "http://arxiv.org/pdf/2507.08433v1", "cate": "math.CO", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.06261", "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": ["Gheorghe Comanici", "Eric Bieber", "Mike Schaekermann", "Ice Pasupat", "Noveen Sachdeva", "Inderjit Dhillon", "Marcel Blistein", "Ori Ram", "Dan Zhang", "Evan Rosen", "Luke Marris", "Sam Petulla", "Colin Gaffney", "Asaf Aharoni", "Nathan Lintz", "Tiago Cardal Pais", "Henrik Jacobsson", "Idan Szpektor", "Nan-Jiang Jiang", "Krishna Haridasan", "Ahmed Omran", "Nikunj Saunshi", "Dara Bahri", "Gaurav Mishra", "Eric Chu", "Toby Boyd", "Brad Hekman", "Aaron Parisi", "Chaoyi Zhang", "Kornraphop Kawintiranon", "Tania Bedrax-Weiss", "Oliver Wang", "Ya Xu", "Ollie Purkiss", "Uri Mendlovic", "Ilaï Deutel", "Nam Nguyen", "Adam Langley", "Flip Korn", "Lucia Rossazza", "Alexandre Ramé", "Sagar Waghmare", "Helen Miller", "Vaishakh Keshava", "Ying Jian", "Xiaofan Zhang", "Raluca Ada Popa", "Kedar Dhamdhere", "Blaž Bratanič", "Kyuyeun Kim", "Terry Koo", "Ferran Alet", "Yi-ting Chen", "Arsha Nagrani", "Hannah Muckenhirn", "Zhiyuan Zhang", "Corbin Quick", "Filip Pavetić", "Duc Dung Nguyen", "Joao Carreira", "Michael Elabd", "Haroon Qureshi", "Fabian Mentzer", "Yao-Yuan Yang", "Danielle Eisenbud", "Anmol Gulati", "Ellie Talius", "Eric Ni", "Sahra Ghalebikesabi", "Edouard Yvinec", "Alaa Saade", "Thatcher Ulrich", "Lorenzo Blanco", "Dan A. Calian", "Muhuan Huang", "Aäron van den Oord", "Naman Goyal", "Terry Chen", "Praynaa Rawlani", "Christian Schallhart", "Swachhand Lokhande", "Xianghong Luo", "Jyn Shan", "Ceslee Montgomery", "Victoria Krakovna", "Federico Piccinini", "Omer Barak", "Jingyu Cui", "Yiling Jia", "Mikhail Dektiarev", "Alexey Kolganov", "Shiyu Huang", "Zhe Chen", "Xingyu Wang", "Jessica Austin", "Peter de Boursac", "Evgeny Sluzhaev", "Frank Ding", "Huijian Li", "Surya Bhupatiraju", "Mohit Agarwal", "Sławek Kwasiborski", "Paramjit Sandhu", "Patrick Siegler", "Ahmet Iscen", "Eyal Ben-David", "Shiraz Butt", "Miltos Allamanis", "Seth Benjamin", "Robert Busa-Fekete", "Felix Hernandez-Campos", "Sasha Goldshtein", "Matt Dibb", "Weiyang Zhang", "Annie Marsden", "Carey Radebaugh", "Stephen Roller", "Abhishek Nayyar", "Jacob Austin", "Tayfun Terzi", "Bhargav Kanagal Shamanna", "Pete Shaw", "Aayush Singh", "Florian Luisier", "Artur Mendonça", "Vaibhav Aggarwal", "Larisa Markeeva", "Claudio Fantacci", "Sergey Brin", "HyunJeong Choe", "Guanyu Wang", "Hartwig Adam", "Avigail Dabush", "Tatsuya Kiyono", "Eyal Marcus", "Jeremy Cole", "Theophane Weber", "Hongrae Lee", "Ronny Huang", "Alex Muzio", "Leandro Kieliger", "Maigo Le", "Courtney Biles", "Long Le", "Archit Sharma", "Chengrun Yang", "Avery Lamp", "Dave Dopson", "Nate Hurley", "Katrina Xinyi Xu", "Zhihao Shan", "Shuang Song", "Jiewen Tan", "Alexandre Senges", "George Zhang", "Chong You", "Yennie Jun", "David Raposo", "Susanna Ricco", "Xuan Yang", "Weijie Chen", "Prakhar Gupta", "Arthur Szlam", "Kevin Villela", "Chun-Sung Ferng", "Daniel Kasenberg", "Chen Liang", "Rui Zhu", "Arunachalam Narayanaswamy", "Florence Perot", "Paul Pucciarelli", "Anna Shekhawat", "Alexey Stern", "Rishikesh Ingale", "Stefani Karp", "Sanaz Bahargam", "Adrian Goedeckemeyer", "Jie Han", "Sicheng Li", "Andrea Tacchetti", "Dian Yu", "Abhishek Chakladar", "Zhiying Zhang", "Mona El Mahdy", "Xu Gao", "Dale Johnson", "Samrat Phatale", "AJ Piergiovanni", "Hyeontaek Lim", "Clement Farabet", "Carl Lebsack", "Theo Guidroz", "John Blitzer", "Nico Duduta", "David Madras", "Steve Li", "Daniel von Dincklage", "Xin Li", "Mahdis Mahdieh", "George Tucker", "Ganesh Jawahar", "Owen Xiao", "Danny Tarlow", "Robert Geirhos", "Noam Velan", "Daniel Vlasic", "Kalesha Bullard", "SK Park", "Nishesh Gupta", "Kellie Webster", "Ayal Hitron", "Jieming Mao", "Julian Eisenschlos", "Laurel Prince", "Nina D'Souza", "Kelvin Zheng", "Sara Nasso", "Gabriela Botea", "Carl Doersch", "Caglar Unlu", "Chris Alberti", "Alexey Svyatkovskiy", "Ankita Goel", "Krzysztof Choromanski", "Pan-Pan Jiang", "Richard Nguyen", "Four Flynn", "Daria Ćurko", "Peter Chen", "Nicholas Roth", "Kieran Milan", "Caleb Habtegebriel", "Shashi Narayan", "Michael Moffitt", "Jake Marcus", "Thomas Anthony", "Brendan McMahan", "Gowoon Cheon", "Ruibo Liu", "Megan Barnes", "Lukasz Lew", "Rebeca Santamaria-Fernandez", "Mayank Upadhyay", "Arjun Akula", "Arnar Mar Hrafnkelsson", "Alvaro Caceres", "Andrew Bunner", "Michal Sokolik", "Subha Puttagunta", "Lawrence Moore", "Berivan Isik", "Jay Hartford", "Lawrence Chan", "Pradeep Shenoy", "Dan Holtmann-Rice", "Jane Park", "Fabio Viola", "Alex Salcianu", "Sujeevan Rajayogam", "Ian Stewart-Binks", "Zelin Wu", "Richard Everett", "Xi Xiong", "Pierre-Antoine Manzagol", "Gary Leung", "Carl Saroufim", "Bo Pang", "Dawid Wegner", "George Papamakarios", "Jennimaria Palomaki", "Helena Pankov", "Guangda Lai", "Guilherme Tubone", "Shubin Zhao", "Theofilos Strinopoulos", "Seth Neel", "Mingqiu Wang", "Joe Kelley", "Li Li", "Pingmei Xu", "Anitha Vijayakumar", "Andrea D'olimpio", "Omer Levy", "Massimo Nicosia", "Grigory Rozhdestvenskiy", "Ni Lao", "Sirui Xie", "Yash Katariya", "Jon Simon", "Sanjiv Kumar", "Florian Hartmann", "Michael Kilgore", "Jinhyuk Lee", "Aroma Mahendru", "Roman Ring", "Tom Hennigan", "Fiona Lang", "Colin Cherry", "David Steiner", "Dawsen Hwang", "Ray Smith", "Pidong Wang", "Jeremy Chen", "Ming-Hsuan Yang", "Sam Kwei", "Philippe Schlattner", "Donnie Kim", "Ganesh Poomal Girirajan", "Nikola Momchev", "Ayushi Agarwal", "Xingyi Zhou", "Ilkin Safarli", "Zachary Garrett", "AJ Pierigiovanni", "Sarthak Jauhari", "Alif Raditya Rochman", "Shikhar Vashishth", "Quan Yuan", "Christof Angermueller", "Jon Blanton", "Xinying Song", "Nitesh Bharadwaj Gundavarapu", "Thi Avrahami", "Maxine Deines", "Subhrajit Roy", "Manish Gupta", "Christopher Semturs", "Shobha Vasudevan", "Aditya Srikanth Veerubhotla", "Shriya Sharma", "Josh Jacob", "Zhen Yang", "Andreas Terzis", "Dan Karliner", "Auriel Wright", "Tania Rojas-Esponda", "Ashley Brown", "Abhijit Guha Roy", "Pawan Dogra", "Andrei Kapishnikov", "Peter Young", "Wendy Kan", "Vinodh Kumar Rajendran", "Maria Ivanova", "Salil Deshmukh", "Chia-Hua Ho", "Mike Kwong", "Stav Ginzburg", "Annie Louis", "KP Sawhney", "Slav Petrov", "Jing Xie", "Yunfei Bai", "Georgi Stoyanov", "Alex Fabrikant", "Rajesh Jayaram", "Yuqi Li", "Joe Heyward", "Justin Gilmer", "Yaqing Wang", "Radu Soricut", "Luyang Liu", "Qingnan Duan", "Jamie Hayes", "Maura O'Brien", "Gaurav Singh Tomar", "Sivan Eiger", "Bahar Fatemi", "Jeffrey Hui", "Catarina Barros", "Adaeze Chukwuka", "Alena Butryna", "Saksham Thakur", "Austin Huang", "Zhufeng Pan", "Haotian Tang", "Serkan Cabi", "Tulsee Doshi", "Michiel Bakker", "Sumit Bagri", "Ruy Ley-Wild", "Adam Lelkes", "Jennie Lees", "Patrick Kane", "David Greene", "Shimu Wu", "Jörg Bornschein", "Gabriela Surita", "Sarah Hodkinson", "Fangtao Li", "Chris Hidey", "Sébastien Pereira", "Sean Ammirati", "Phillip Lippe", "Adam Kraft", "Pu Han", "Sebastian Gerlach", "Zifeng Wang", "Liviu Panait", "Feng Han", "Brian Farris", "Yingying Bi", "Hannah DeBalsi", "Miaosen Wang", "Gladys Tyen", "James Cohan", "Susan Zhang", "Jarred Barber", "Da-Woon Chung", "Jaeyoun Kim", "Markus Kunesch", "Steven Pecht", "Nami Akazawa", "Abe Friesen", "James Lyon", "Ali Eslami", "Junru Wu", "Jie Tan", "Yue Song", "Ravi Kumar", "Chris Welty", "Ilia Akolzin", "Gena Gibson", "Sean Augenstein", "Arjun Pillai", "Nancy Yuen", "Du Phan", "Xin Wang", "Iain Barr", "Heiga Zen", "Nan Hua", "Casper Liu", "Jilei Jerry Wang", "Tanuj Bhatia", "Hao Xu", "Oded Elyada", "Pushmeet Kohli", "Mirek Olšák", "Ke Chen", "Azalia Mirhoseini", "Noam Shazeer", "Shoshana Jakobovits", "Maggie Tran", "Nolan Ramsden", "Tarun Bharti", "Fred Alcober", "Yunjie Li", "Shilpa Shetty", "Jing Chen", "Dmitry Kalashnikov", "Megha Nawhal", "Sercan Arik", "Hanwen Chen", "Michiel Blokzijl", "Shubham Gupta", "James Rubin", "Rigel Swavely", "Sophie Bridgers", "Ian Gemp", "Chen Su", "Arun Suggala", "Juliette Pluto", "Mary Cassin", "Alain Vaucher", "Kaiyang Ji", "Jiahao Cai", "Andrew Audibert", "Animesh Sinha", "David Tian", "Efrat Farkash", "Amy Hua", "Jilin Chen", "Duc-Hieu Tran", "Edward Loper", "Nicole Brichtova", "Lara McConnaughey", "Ballie Sandhu", "Robert Leland", "Doug DeCarlo", "Andrew Over", "James Huang", "Xing Wu", "Connie Fan", "Eric Li", "Yun Lei", "Deepak Sharma", "Cosmin Paduraru", "Luo Yu", "Matko Bošnjak", "Phuong Dao", "Min Choi", "Sneha Kudugunta", "Jakub Adamek", "Carlos Guía", "Ali Khodaei", "Jie Feng", "Wenjun Zeng", "David Welling", "Sandeep Tata", "Christina Butterfield", "Andrey Vlasov", "Seliem El-Sayed", "Swaroop Mishra", "Tara Sainath", "Shentao Yang", "RJ Skerry-Ryan", "Jeremy Shar", "Robert Berry", "Arunkumar Rajendran", "Arun Kandoor", "Andrea Burns", "Deepali Jain", "Tom Stone", "Wonpyo Park", "Shibo Wang", "Albin Cassirer", "Guohui Wang", "Hayato Kobayashi", "Sergey Rogulenko", "Vineetha Govindaraj", "Mikołaj Rybiński", "Nadav Olmert", "Colin Evans", "Po-Sen Huang", "Kelvin Xu", "Premal Shah", "Terry Thurk", "Caitlin Sikora", "Mu Cai", "Jin Xie", "Elahe Dabir", "Saloni Shah", "Norbert Kalb", "Carrie Zhang", "Shruthi Prabhakara", "Amit Sabne", "Artiom Myaskovsky", "Vikas Raunak", "Blanca Huergo", "Behnam Neyshabur", "Jon Clark", "Ye Zhang", "Shankar Krishnan", "Eden Cohen", "Dinesh Tewari", "James Lottes", "Yumeya Yamamori", "Hui Elena Li", "Mohamed Elhawaty", "Ada Maksutaj Oflazer", "Adrià Recasens", "Sheryl Luo", "Duy Nguyen", "Taylor Bos", "Kalyan Andra", "Ana Salazar", "Ed Chi", "Jeongwoo Ko", "Matt Ginsberg", "Anders Andreassen", "Anian Ruoss", "Todor Davchev", "Elnaz Davoodi", "Chenxi Liu", "Min Kim", "Santiago Ontanon", "Chi Ming To", "Dawei Jia", "Rosemary Ke", "Jing Wang", "Anna Korsun", "Moran Ambar", "Ilya Kornakov", "Irene Giannoumis", "Toni Creswell", "Denny Zhou", "Yi Su", "Ishaan Watts", "Aleksandr Zaks", "Evgenii Eltyshev", "Ziqiang Feng", "Sidharth Mudgal", "Alex Kaskasoli", "Juliette Love", "Kingshuk Dasgupta", "Sam Shleifer", "Richard Green", "Sungyong Seo", "Chansoo Lee", "Dale Webster", "Prakash Shroff", "Ganna Raboshchuk", "Isabel Leal", "James Manyika", "Sofia Erell", "Daniel Murphy", "Zhisheng Xiao", "Anton Bulyenov", "Julian Walker", "Mark Collier", "Matej Kastelic", "Nelson George", "Sushant Prakash", "Sailesh Sidhwani", "Alexey Frolov", "Steven Hansen", "Petko Georgiev", "Tiberiu Sosea", "Chris Apps", "Aishwarya Kamath", "David Reid", "Emma Cooney", "Charlotte Magister", "Oriana Riva", "Alec Go", "Pu-Chin Chen", "Sebastian Krause", "Nir Levine", "Marco Fornoni", "Ilya Figotin", "Nick Roy", "Parsa Mahmoudieh", "Vladimir Magay", "Mukundan Madhavan", "Jin Miao", "Jianmo Ni", "Yasuhisa Fujii", "Ian Chou", "George Scrivener", "Zak Tsai", "Siobhan Mcloughlin", "Jeremy Selier", "Sandra Lefdal", "Jeffrey Zhao", "Abhijit Karmarkar", "Kushal Chauhan", "Shivanker Goel", "Zhaoyi Zhang", "Vihan Jain", "Parisa Haghani", "Mostafa Dehghani", "Jacob Scott", "Erin Farnese", "Anastasija Ilić", "Steven Baker", "Julia Pawar", "Li Zhong", "Josh Camp", "Yoel Zeldes", "Shravya Shetty", "Anand Iyer", "Vít Listík", "Jiaxian Guo", "Luming Tang", "Mark Geller", "Simon Bucher", "Yifan Ding", "Hongzhi Shi", "Carrie Muir", "Dominik Grewe", "Ramy Eskander", "Octavio Ponce", "Boqing Gong", "Derek Gasaway", "Samira Khan", "Umang Gupta", "Angelos Filos", "Weicheng Kuo", "Klemen Kloboves", "Jennifer Beattie", "Christian Wright", "Leon Li", "Alicia Jin", "Sandeep Mariserla", "Miteyan Patel", "Jens Heitkaemper", "Dilip Krishnan", "Vivek Sharma", "David Bieber", "Christian Frank", "John Lambert", "Paul Caron", "Martin Polacek", "Mai Giménez", "Himadri Choudhury", "Xing Yu", "Sasan Tavakkol", "Arun Ahuja", "Franz Och", "Rodolphe Jenatton", "Wojtek Skut", "Bryan Richter", "David Gaddy", "Andy Ly", "Misha Bilenko", "Megh Umekar", "Ethan Liang", "Martin Sevenich", "Mandar Joshi", "Hassan Mansoor", "Rebecca Lin", "Sumit Sanghai", "Abhimanyu Singh", "Xiaowei Li", "Sudheendra Vijayanarasimhan", "Zaheer Abbas", "Yonatan Bitton", "Hansa Srinivasan", "Manish Reddy Vuyyuru", "Alexander Frömmgen", "Yanhua Sun", "Ralph Leith", "Alfonso Castaño", "DJ Strouse", "Le Yan", "Austin Kyker", "Satish Kambala", "Mary Jasarevic", "Thibault Sellam", "Chao Jia", "Alexander Pritzel", "Raghavender R", "Huizhong Chen", "Natalie Clay", "Sudeep Gandhe", "Sean Kirmani", "Sayna Ebrahimi", "Hannah Kirkwood", "Jonathan Mallinson", "Chao Wang", "Adnan Ozturel", "Kuo Lin", "Shyam Upadhyay", "Vincent Cohen-Addad", "Sean Purser-haskell", "Yichong Xu", "Ebrahim Songhori", "Babi Seal", "Alberto Magni", "Almog Gueta", "Tingting Zou", "Guru Guruganesh", "Thais Kagohara", "Hung Nguyen", "Khalid Salama", "Alejandro Cruzado Ruiz", "Justin Frye", "Zhenkai Zhu", "Matthias Lochbrunner", "Simon Osindero", "Wentao Yuan", "Lisa Lee", "Aman Prasad", "Lam Nguyen Thiet", "Daniele Calandriello", "Victor Stone", "Qixuan Feng", "Han Ke", "Maria Voitovich", "Geta Sampemane", "Lewis Chiang", "Ling Wu", "Alexander Bykovsky", "Matt Young", "Luke Vilnis", "Ishita Dasgupta", "Aditya Chawla", "Qin Cao", "Bowen Liang", "Daniel Toyama", "Szabolcs Payrits", "Anca Stefanoiu", "Dimitrios Vytiniotis", "Ankesh Anand", "Tianxiao Shen", "Blagoj Mitrevski", "Michael Tschannen", "Sreenivas Gollapudi", "Aishwarya P S", "José Leal", "Zhe Shen", "Han Fu", "Wei Wang", "Arvind Kannan", "Doron Kukliansky", "Sergey Yaroshenko", "Svetlana Grant", "Umesh Telang", "David Wood", "Alexandra Chronopoulou", "Alexandru Ţifrea", "Tao Zhou", "Tony Tu\\'ân Nguy\\~ên", "Muge Ersoy", "Anima Singh", "Meiyan Xie", "Emanuel Taropa", "Woohyun Han", "Eirikur Agustsson", "Andrei Sozanschi", "Hui Peng", "Alex Chen", "Yoel Drori", "Efren Robles", "Yang Gao", "Xerxes Dotiwalla", "Ying Chen", "Anudhyan Boral", "Alexei Bendebury", "John Nham", "Chris Tar", "Luis Castro", "Jiepu Jiang", "Canoee Liu", "Felix Halim", "Jinoo Baek", "Andy Wan", "Jeremiah Liu", "Yuan Cao", "Shengyang Dai", "Trilok Acharya", "Ruoxi Sun", "Fuzhao Xue", "Saket Joshi", "Morgane Lustman", "Yongqin Xian", "Rishabh Joshi", "Deep Karkhanis", "Nora Kassner", "Jamie Hall", "Xiangzhuo Ding", "Gan Song", "Gang Li", "Chen Zhu", "Yana Kulizhskaya", "Bin Ni", "Alexey Vlaskin", "Solomon Demmessie", "Lucio Dery", "Salah Zaiem", "Yanping Huang", "Cindy Fan", "Felix Gimeno", "Ananth Balashankar", "Koji Kojima", "Hagai Taitelbaum", "Maya Meng", "Dero Gharibian", "Sahil Singla", "Wei Chen", "Ambrose Slone", "Guanjie Chen", "Sujee Rajayogam", "Max Schumacher", "Suyog Kotecha", "Rory Blevins", "Qifei Wang", "Mor Hazan Taege", "Alex Morris", "Xin Liu", "Fayaz Jamil", "Richard Zhang", "Pratik Joshi", "Ben Ingram", "Tyler Liechty", "Ahmed Eleryan", "Scott Baird", "Alex Grills", "Gagan Bansal", "Shan Han", "Kiran Yalasangi", "Shawn Xu", "Majd Al Merey", "Isabel Gao", "Felix Weissenberger", "Igor Karpov", "Robert Riachi", "Ankit Anand", "Gautam Prasad", "Kay Lamerigts", "Reid Hayes", "Jamie Rogers", "Mandy Guo", "Ashish Shenoy", "Qiong Q Hu", "Kyle He", "Yuchen Liu", "Polina Zablotskaia", "Sagar Gubbi", "Yifan Chang", "Jay Pavagadhi", "Kristian Kjems", "Archita Vadali", "Diego Machado", "Yeqing Li", "Renshen Wang", "Dipankar Ghosh", "Aahil Mehta", "Dana Alon", "George Polovets", "Alessio Tonioni", "Nate Kushman", "Joel D'sa", "Lin Zhuo", "Allen Wu", "Rohin Shah", "John Youssef", "Jiayu Ye", "Justin Snyder", "Karel Lenc", "Senaka Buthpitiya", "Matthew Tung", "Jichuan Chang", "Tao Chen", "David Saxton", "Jenny Lee", "Lydia Lihui Zhang", "James Qin", "Prabakar Radhakrishnan", "Maxwell Chen", "Piotr Ambroszczyk", "Metin Toksoz-Exley", "Yan Zhong", "Nitzan Katz", "Brendan O'Donoghue", "Tamara von Glehn", "Adi Gerzi Rosenthal", "Aga Świetlik", "Xiaokai Zhao", "Nick Fernando", "Jinliang Wei", "Jieru Mei", "Sergei Vassilvitskii", "Diego Cedillo", "Pranjal Awasthi", "Hui Zheng", "Koray Kavukcuoglu", "Itay Laish", "Joseph Pagadora", "Marc Brockschmidt", "Christopher A. Choquette-Choo", "Arunkumar Byravan", "Yifeng Lu", "Xu Chen", "Mia Chen", "Kenton Lee", "Rama Pasumarthi", "Sijal Bhatnagar", "Aditya Shah", "Qiyin Wu", "Zhuoyuan Chen", "Zack Nado", "Bartek Perz", "Zixuan Jiang", "David Kao", "Ganesh Mallya", "Nino Vieillard", "Lantao Mei", "Sertan Girgin", "Mandy Jordan", "Yeongil Ko", "Alekh Agarwal", "Yaxin Liu", "Yasemin Altun", "Raoul de Liedekerke", "Anastasios Kementsietsidis", "Daiyi Peng", "Dangyi Liu", "Utku Evci", "Peter Humphreys", "Austin Tarango", "Xiang Deng", "Yoad Lewenberg", "Kevin Aydin", "Chengda Wu", "Bhavishya Mittal", "Tsendsuren Munkhdalai", "Kleopatra Chatziprimou", "Rodrigo Benenson", "Uri First", "Xiao Ma", "Jinning Li", "Armand Joulin", "Hamish Tomlinson", "Tingnan Zhang", "Milad Nasr", "Zhi Hong", "Michaël Sander", "Lisa Anne Hendricks", "Anuj Sharma", "Andrew Bolt", "Eszter Vértes", "Jiri Simsa", "Tomer Levinboim", "Olcan Sercinoglu", "Divyansh Shukla", "Austin Wu", "Craig Swanson", "Danny Vainstein", "Fan Bu", "Bo Wang", "Ryan Julian", "Charles Yoon", "Sergei Lebedev", "Antonious Girgis", "Bernd Bandemer", "David Du", "Todd Wang", "Xi Chen", "Ying Xiao", "Peggy Lu", "Natalie Ha", "Vlad Ionescu", "Simon Rowe", "Josip Matak", "Federico Lebron", "Andreas Steiner", "Lalit Jain", "Manaal Faruqui", "Nicolas Lacasse", "Georgie Evans", "Neesha Subramaniam", "Dean Reich", "Giulia Vezzani", "Aditya Pandey", "Joe Stanton", "Tianhao Zhou", "Liam McCafferty", "Henry Griffiths", "Verena Rieser", "Soheil Hassas Yeganeh", "Eleftheria Briakou", "Lu Huang", "Zichuan Wei", "Liangchen Luo", "Erik Jue", "Gabby Wang", "Victor Cotruta", "Myriam Khan", "Jongbin Park", "Qiuchen Guo", "Peiran Li", "Rong Rong", "Diego Antognini", "Anastasia Petrushkina", "Chetan Tekur", "Eli Collins", "Parul Bhatia", "Chester Kwak", "Wenhu Chen", "Arvind Neelakantan", "Immanuel Odisho", "Sheng Peng", "Vincent Nallatamby", "Vaibhav Tulsyan", "Fabian Pedregosa", "Peng Xu", "Raymond Lin", "Yulong Wang", "Emma Wang", "Sholto Douglas", "Reut Tsarfaty", "Elena Gribovskaya", "Renga Aravamudhan", "Manu Agarwal", "Mara Finkelstein", "Qiao Zhang", "Elizabeth Cole", "Phil Crone", "Sarmishta Velury", "Anil Das", "Chris Sauer", "Luyao Xu", "Danfeng Qin", "Chenjie Gu", "Dror Marcus", "CJ Zheng", "Wouter Van Gansbeke", "Sobhan Miryoosefi", "Haitian Sun", "YaGuang Li", "Charlie Chen", "Jae Yoo", "Pavel Dubov", "Alex Tomala", "Adams Yu", "Paweł Wesołowski", "Alok Gunjan", "Eddie Cao", "Jiaming Luo", "Nikhil Sethi", "Arkadiusz Socala", "Laura Graesser", "Tomas Kocisky", "Arturo BC", "Minmin Chen", "Edward Lee", "Sophie Wang", "Weize Kong", "Qiantong Xu", "Nilesh Tripuraneni", "Yiming Li", "Xinxin Yu", "Allen Porter", "Paul Voigtlaender", "Biao Zhang", "Arpi Vezer", "Sarah York", "Qing Wei", "Geoffrey Cideron", "Mark Kurzeja", "Seungyeon Kim", "Benny Li", "Angéline Pouget", "Hyo Lee", "Kaspar Daugaard", "Yang Li", "Dave Uthus", "Aditya Siddhant", "Paul Cavallaro", "Sriram Ganapathy", "Maulik Shah", "Rolf Jagerman", "Jeff Stanway", "Piermaria Mendolicchio", "Li Xiao", "Kayi Lee", "Tara Thompson", "Shubham Milind Phal", "Jason Chase", "Sun Jae Lee", "Adrian N Reyes", "Disha Shrivastava", "Zhen Qin", "Roykrong Sukkerd", "Seth Odoom", "Lior Madmoni", "John Aslanides", "Jonathan Herzig", "Elena Pochernina", "Sheng Zhang", "Parker Barnes", "Daisuke Ikeda", "Qiujia Li", "Shuo-yiin Chang", "Shakir Mohamed", "Jim Sproch", "Richard Powell", "Bidisha Samanta", "Domagoj Ćevid", "Anton Kovsharov", "Shrestha Basu Mallick", "Srinivas Tadepalli", "Anne Zheng", "Kareem Ayoub", "Andreas Noever", "Christian Reisswig", "Zhuo Xu", "Junhyuk Oh", "Martin Matysiak", "Tim Blyth", "Shereen Ashraf", "Julien Amelot", "Boone Severson", "Michele Bevilacqua", "Motoki Sano", "Ethan Dyer", "Ofir Roval", "Anu Sinha", "Yin Zhong", "Sagi Perel", "Tea Sabolić", "Johannes Mauerer", "Willi Gierke", "Mauro Verzetti", "Rodrigo Cabrera", "Alvin Abdagic", "Steven Hemingray", "Austin Stone", "Jong Lee", "Farooq Ahmad", "Karthik Raman", "Lior Shani", "Jonathan Lai", "Orhan Firat", "Nathan Waters", "Eric Ge", "Mo Shomrat", "Himanshu Gupta", "Rajeev Aggarwal", "Tom Hudson", "Bill Jia", "Simon Baumgartner", "Palak Jain", "Joe Kovac", "Junehyuk Jung", "Ante Žužul", "Will Truong", "Morteza Zadimoghaddam", "Songyou Peng", "Marco Liang", "Rachel Sterneck", "Balaji Lakshminarayanan", "Machel Reid", "Oliver Woodman", "Tong Zhou", "Jianling Wang", "Vincent Coriou", "Arjun Narayanan", "Jay Hoover", "Yenai Ma", "Apoorv Jindal", "Clayton Sanford", "Doug Reid", "Swaroop Ramaswamy", "Alex Kurakin", "Roland Zimmermann", "Yana Lunts", "Dragos Dena", "Zalán Borsos", "Vered Cohen", "Shujian Zhang", "Will Grathwohl", "Robert Dadashi", "Morgan Redshaw", "Joshua Kessinger", "Julian Odell", "Silvano Bonacina", "Zihang Dai", "Grace Chen", "Ayush Dubey", "Pablo Sprechmann", "Mantas Pajarskas", "Wenxuan Zhou", "Niharika Ahuja", "Tara Thomas", "Martin Nikoltchev", "Matija Kecman", "Bharath Mankalale", "Andrey Ryabtsev", "Jennifer She", "Christian Walder", "Jiaming Shen", "Lu Li", "Carolina Parada", "Sheena Panthaplackel", "Okwan Kwon", "Matt Lawlor", "Utsav Prabhu", "Yannick Schroecker", "Marc'aurelio Ranzato", "Pete Blois", "Iurii Kemaev", "Ting Yu", "Dmitry Lepikhin", "Hao Xiong", "Sahand Sharifzadeh", "Oleaser Johnson", "Jeremiah Willcock", "Rui Yao", "Greg Farquhar", "Sujoy Basu", "Hidetoshi Shimokawa", "Nina Anderson", "Haiguang Li", "Khiem Pham", "Yizhong Liang", "Sebastian Borgeaud", "Alexandre Moufarek", "Hideto Kazawa", "Blair Kutzman", "Marcin Sieniek", "Sara Smoot", "Ruth Wang", "Natalie Axelsson", "Nova Fallen", "Prasha Sundaram", "Yuexiang Zhai", "Varun Godbole", "Petros Maniatis", "Alek Wang", "Ilia Shumailov", "Santhosh Thangaraj", "Remi Crocker", "Nikita Gupta", "Gang Wu", "Phil Chen", "Gellért Weisz", "Celine Smith", "Mojtaba Seyedhosseini", "Boya Fang", "Xiyang Luo", "Roey Yogev", "Zeynep Cankara", "Andrew Hard", "Helen Ran", "Rahul Sukthankar", "George Necula", "Gaël Liu", "Honglong Cai", "Praseem Banzal", "Daniel Keysers", "Sanjay Ghemawat", "Connie Tao", "Emma Dunleavy", "Aditi Chaudhary", "Wei Li", "Maciej Mikuła", "Chen-Yu Lee", "Tiziana Refice", "Krishna Somandepalli", "Alexandre Fréchette", "Dan Bahir", "John Karro", "Keith Rush", "Sarah Perrin", "Bill Rosgen", "Xiaomeng Yang", "Clara Huiyi Hu", "Mahmoud Alnahlawi", "Justin Mao-Jones", "Roopal Garg", "Hoang Nguyen", "Bat-Orgil Batsaikhan", "Iñaki Iturrate", "Anselm Levskaya", "Avi Singh", "Ashyana Kachra", "Tony Lu", "Denis Petek", "Zheng Xu", "Mark Graham", "Lukas Zilka", "Yael Karov", "Marija Kostelac", "Fangyu Liu", "Yaohui Guo", "Weiyue Wang", "Bernd Bohnet", "Emily Pitler", "Tony Bruguier", "Keisuke Kinoshita", "Chrysovalantis Anastasiou", "Nilpa Jha", "Ting Liu", "Jerome Connor", "Phil Wallis", "Philip Pham", "Eric Bailey", "Shixin Li", "Heng-Tze Cheng", "Sally Ma", "Haiqiong Li", "Akanksha Maurya", "Kate Olszewska", "Manfred Warmuth", "Christy Koh", "Dominik Paulus", "Siddhartha Reddy Jonnalagadda", "Enrique Piqueras", "Ali Elqursh", "Geoff Brown", "Hadar Shemtov", "Loren Maggiore", "Fei Xia", "Ryan Foley", "Beka Westberg", "George van den Driessche", "Livio Baldini Soares", "Arjun Kar", "Michael Quinn", "Siqi Zuo", "Jialin Wu", "Kyle Kastner", "Anna Bortsova", "Aijun Bai", "Ales Mikhalap", "Luowei Zhou", "Jennifer Brennan", "Vinay Ramasesh", "Honglei Zhuang", "John Maggs", "Johan Schalkwyk", "Yuntao Xu", "Hui Huang", "Andrew Howard", "Sasha Brown", "Linting Xue", "Gloria Shen", "Brian Albert", "Neha Jha", "Daniel Zheng", "Varvara Krayvanova", "Spurthi Amba Hombaiah", "Olivier Lacombe", "Gautam Vasudevan", "Dan Graur", "Tian Xie", "Meet Gandhi", "Bangju Wang", "Dustin Zelle", "Harman Singh", "Dahun Kim", "Sébastien Cevey", "Victor Ungureanu", "Natasha Noy", "Fei Liu", "Annie Xie", "Fangxiaoyu Feng", "Katerina Tsihlas", "Daniel Formoso", "Neera Vats", "Quentin Wellens", "Yinan Wang", "Niket Kumar Bhumihar", "Samrat Ghosh", "Matt Hoffman", "Tom Lieber", "Oran Lang", "Kush Bhatia", "Tom Paine", "Aroonalok Pyne", "Ronny Votel", "Madeleine Clare Elish", "Benoit Schillings", "Alex Panagopoulos", "Haichuan Yang", "Adam Raveret", "Zohar Yahav", "Shuang Liu", "Dalia El Badawy", "Nishant Agrawal", "Mohammed Badawi", "Mahdi Mirzazadeh", "Carla Bromberg", "Fan Ye", "Chang Liu", "Tatiana Sholokhova", "George-Cristian Muraru", "Gargi Balasubramaniam", "Jonathan Malmaud", "Alen Carin", "Danilo Martins", "Irina Jurenka", "Pankil Botadra", "Dave Lacey", "Richa Singh", "Mariano Schain", "Dan Zheng", "Isabelle Guyon", "Victor Lavrenko", "Seungji Lee", "Xiang Zhou", "Demis Hassabis", "Jeshwanth Challagundla", "Derek Cheng", "Nikhil Mehta", "Matthew Mauger", "Michela Paganini", "Pushkar Mishra", "Kate Lee", "Zhang Li", "Lexi Baugher", "Ondrej Skopek", "Max Chang", "Amir Zait", "Gaurav Menghani", "Lizzetth Bellot", "Guangxing Han", "Jean-Michel Sarr", "Sharat Chikkerur", "Himanshu Sahni", "Rohan Anil", "Arun Narayanan", "Chandu Thekkath", "Daniele Pighin", "Hana Strejček", "Marko Velic", "Fred Bertsch", "Manuel Tragut", "Keran Rong", "Alicia Parrish", "Kai Bailey", "Jiho Park", "Isabela Albuquerque", "Abhishek Bapna", "Rajesh Venkataraman", "Alec Kosik", "Johannes Griesser", "Zhiwei Deng", "Alek Andreev", "Qingyun Dou", "Kevin Hui", "Fanny Wei", "Xiaobin Yu", "Lei Shu", "Avia Aharon", "David Barker", "Badih Ghazi", "Sebastian Flennerhag", "Chris Breaux", "Yuchuan Liu", "Matthew Bilotti", "Josh Woodward", "Uri Alon", "Stephanie Winkler", "Tzu-Kuo Huang", "Kostas Andriopoulos", "João Gabriel Oliveira", "Penporn Koanantakool", "Berkin Akin", "Michael Wunder", "Cicero Nogueira dos Santos", "Mohammad Hossein Bateni", "Lin Yang", "Dan Horgan", "Beer Changpinyo", "Keyvan Amiri", "Min Ma", "Dayeong Lee", "Lihao Liang", "Anirudh Baddepudi", "Tejasi Latkar", "Raia Hadsell", "Jun Xu", "Hairong Mu", "Michael Han", "Aedan Pope", "Snchit Grover", "Frank Kim", "Ankit Bhagatwala", "Guan Sun", "Yamini Bansal", "Amir Globerson", "Alireza Nazari", "Samira Daruki", "Hagen Soltau", "Jane Labanowski", "Laurent El Shafey", "Matt Harvey", "Yanif Ahmad", "Elan Rosenfeld", "William Kong", "Etienne Pot", "Yi-Xuan Tan", "Aurora Wei", "Victoria Langston", "Marcel Prasetya", "Petar Veličković", "Richard Killam", "Robin Strudel", "Darren Ni", "Zhenhai Zhu", "Aaron Archer", "Kavya Kopparapu", "Lynn Nguyen", "Emilio Parisotto", "Hussain Masoom", "Sravanti Addepalli", "Jordan Grimstad", "Hexiang Hu", "Joss Moore", "Avinatan Hassidim", "Le Hou", "Mukund Raghavachari", "Jared Lichtarge", "Adam R. Brown", "Hilal Dib", "Natalia Ponomareva", "Justin Fu", "Yujing Zhang", "Altaf Rahman", "Joana Iljazi", "Edouard Leurent", "Gabriel Dulac-Arnold", "Cosmo Du", "Chulayuth Asawaroengchai", "Larry Jin", "Ela Gruzewska", "Ziwei Ji", "Benigno Uria", "Daniel De Freitas", "Paul Barham", "Lauren Beltrone", "Víctor Campos", "Jun Yan", "Neel Kovelamudi", "Arthur Nguyen", "Elinor Davies", "Zhichun Wu", "Zoltan Egyed", "Kristina Toutanova", "Nithya Attaluri", "Hongliang Fei", "Peter Stys", "Siddhartha Brahma", "Martin Izzard", "Siva Velusamy", "Scott Lundberg", "Vincent Zhuang", "Kevin Sequeira", "Adam Santoro", "Ehsan Amid", "Ophir Aharoni", "Shuai Ye", "Mukund Sundararajan", "Lijun Yu", "Yu-Cheng Ling", "Stephen Spencer", "Hugo Song", "Josip Djolonga", "Christo Kirov", "Sonal Gupta", "Alessandro Bissacco", "Clemens Meyer", "Mukul Bhutani", "Andrew Dai", "Weiyi Wang", "Siqi Liu", "Ashwin Sreevatsa", "Qijun Tan", "Maria Wang", "Lucy Kim", "Yicheng Wang", "Alex Irpan", "Yang Xiao", "Stanislav Fort", "Yifan He", "Alex Gurney", "Bryan Gale", "Yue Ma", "Monica Roy", "Viorica Patraucean", "Taylan Bilal", "Golnaz Ghiasi", "Anahita Hosseini", "Melvin Johnson", "Zhuowan Li", "Yi Tay", "Benjamin Beyret", "Katie Millican", "Josef Broder", "Mayank Lunayach", "Danny Swisher", "Eugen Vušak", "David Parkinson", "MH Tessler", "Adi Mayrav Gilady", "Richard Song", "Allan Dafoe", "Yves Raimond", "Masa Yamaguchi", "Itay Karo", "Elizabeth Nielsen", "Kevin Kilgour", "Mike Dusenberry", "Rajiv Mathews", "Jiho Choi", "Siyuan Qiao", "Harsh Mehta", "Sahitya Potluri", "Chris Knutsen", "Jialu Liu", "Tat Tan", "Kuntal Sengupta", "Keerthana Gopalakrishnan", "Abodunrinwa Toki", "Mencher Chiang", "Mike Burrows", "Grace Vesom", "Zafarali Ahmed", "Ilia Labzovsky", "Siddharth Vashishtha", "Preeti Singh", "Ankur Sharma", "Ada Ma", "Jinyu Xie", "Pranav Talluri", "Hannah Forbes-Pollard", "Aarush Selvan", "Joel Wee", "Loic Matthey", "Tom Funkhouser", "Parthasarathy Gopavarapu", "Lev Proleev", "Cheng Li", "Matt Thomas", "Kashyap Kolipaka", "Zhipeng Jia", "Ashwin Kakarla", "Srinivas Sunkara", "Joan Puigcerver", "Suraj Satishkumar Sheth", "Emily Graves", "Chen Wang", "Sadh MNM Khan", "Kai Kang", "Shyamal Buch", "Fred Zhang", "Omkar Savant", "David Soergel", "Kevin Lee", "Linda Friso", "Xuanyi Dong", "Rahul Arya", "Shreyas Chandrakaladharan", "Connor Schenck", "Greg Billock", "Tejas Iyer", "Anton Bakalov", "Leslie Baker", "Alex Ruiz", "Angad Chandorkar", "Trieu Trinh", "Matt Miecnikowski", "Yanqi Zhou", "Yangsibo Huang", "Jiazhong Nie", "Ali Shah", "Ashish Thapliyal", "Sam Haves", "Lun Wang", "Uri Shaham", "Patrick Morris-Suzuki", "Soroush Radpour", "Leonard Berrada", "Thomas Strohmann", "Chaochao Yan", "Jingwei Shen", "Sonam Goenka", "Tris Warkentin", "Petar Dević", "Dan Belov", "Albert Webson", "Madhavi Yenugula", "Puranjay Datta", "Jerry Chang", "Nimesh Ghelani", "Aviral Kumar", "Vincent Perot", "Jessica Lo", "Yang Song", "Herman Schmit", "Jianmin Chen", "Vasilisa Bashlovkina", "Xiaoyue Pan", "Diana Mincu", "Paul Roit", "Isabel Edkins", "Andy Davis", "Yujia Li", "Ben Horn", "Xinjian Li", "Pradeep Kumar S", "Eric Doi", "Wanzheng Zhu", "Sri Gayatri Sundara Padmanabhan", "Siddharth Verma", "Jasmine Liu", "Heng Chen", "Mihajlo Velimirović", "Malcolm Reynolds", "Priyanka Agrawal", "Nick Sukhanov", "Abhinit Modi", "Siddharth Goyal", "John Palowitch", "Nima Khajehnouri", "Wing Lowe", "David Klinghoffer", "Sharon Silver", "Vinh Tran", "Candice Schumann", "Francesco Piccinno", "Xi Liu", "Mario Lučić", "Xiaochen Yang", "Sandeep Kumar", "Ajay Kannan", "Ragha Kotikalapudi", "Mudit Bansal", "Fabian Fuchs", "Mohammad Javad Hosseini", "Abdelrahman Abdelhamed", "Dawn Bloxwich", "Tianhe Yu", "Ruoxin Sang", "Gregory Thornton", "Karan Gill", "Yuchi Liu", "Virat Shejwalkar", "Jason Lin", "Zhipeng Yan", "Kehang Han", "Thomas Buschmann", "Michael Pliskin", "Zhi Xing", "Susheel Tatineni", "Junlin Zhang", "Sissie Hsiao", "Gavin Buttimore", "Marcus Wu", "Zefei Li", "Geza Kovacs", "Legg Yeung", "Tao Huang", "Aaron Cohen", "Bethanie Brownfield", "Averi Nowak", "Mikel Rodriguez", "Tianze Shi", "Hado van Hasselt", "Kevin Cen", "Deepanway Ghoshal", "Kushal Majmundar", "Weiren Yu", "Warren Weilun Chen", "Danila Sinopalnikov", "Hao Zhang", "Vlado Galić", "Di Lu", "Zeyu Zheng", "Maggie Song", "Gary Wang", "Gui Citovsky", "Swapnil Gawde", "Isaac Galatzer-Levy", "David Silver", "Ivana Balazevic", "Dipanjan Das", "Kingshuk Majumder", "Yale Cong", "Praneet Dutta", "Dustin Tran", "Hui Wan", "Junwei Yuan", "Daniel Eppens", "Alanna Walton", "Been Kim", "Harry Ragan", "James Cobon-Kerr", "Lu Liu", "Weijun Wang", "Bryce Petrini", "Jack Rae", "Rakesh Shivanna", "Yan Xiong", "Chace Lee", "Pauline Coquinot", "Yiming Gu", "Lisa Patel", "Blake Hechtman", "Aviel Boag", "Orion Jankowski", "Alex Wertheim", "Alex Lee", "Paul Covington", "Hila Noga", "Sam Sobell", "Shanthal Vasanth", "William Bono", "Chirag Nagpal", "Wei Fan", "Xavier Garcia", "Kedar Soparkar", "Aybuke Turker", "Nathan Howard", "Sachit Menon", "Yuankai Chen", "Vikas Verma", "Vladimir Pchelin", "Harish Rajamani", "Valentin Dalibard", "Ana Ramalho", "Yang Guo", "Kartikeya Badola", "Seojin Bang", "Nathalie Rauschmayr", "Julia Proskurnia", "Sudeep Dasari", "Xinyun Chen", "Mikhail Sushkov", "Anja Hauth", "Pauline Sho", "Abhinav Singh", "Bilva Chandra", "Allie Culp", "Max Dylla", "Olivier Bachem", "James Besley", "Heri Zhao", "Timothy Lillicrap", "Wei Wei", "Wael Al Jishi", "Ning Niu", "Alban Rrustemi", "Raphaël Lopez Kaufman", "Ryan Poplin", "Jewel Zhao", "Minh Truong", "Shikhar Bharadwaj", "Ester Hlavnova", "Eli Stickgold", "Cordelia Schmid", "Georgi Stephanov", "Zhaoqi Leng", "Frederick Liu", "Léonard Hussenot", "Shenil Dodhia", "Juliana Vicente Franco", "Lesley Katzen", "Abhanshu Sharma", "Sarah Cogan", "Zuguang Yang", "Aniket Ray", "Sergi Caelles", "Shen Yan", "Ravin Kumar", "Daniel Gillick", "Renee Wong", "Joshua Ainslie", "Jonathan Hoech", "Séb Arnold", "Dan Abolafia", "Anca Dragan", "Ben Hora", "Grace Hu", "Alexey Guseynov", "Yang Lu", "Chas Leichner", "Jinmeng Rao", "Abhimanyu Goyal", "Nagabhushan Baddi", "Daniel Hernandez Diaz", "Tim McConnell", "Max Bain", "Jake Abernethy", "Qiqi Yan", "Rylan Schaeffer", "Paul Vicol", "Will Thompson", "Montse Gonzalez Arenas", "Mathias Bellaiche", "Pablo Barrio", "Stefan Zinke", "Riccardo Patana", "Pulkit Mehta", "JK Kearns", "Avraham Ruderman", "Scott Pollom", "David D'Ambrosio", "Cath Hope", "Yang Yu", "Andrea Gesmundo", "Kuang-Huei Lee", "Aviv Rosenberg", "Yiqian Zhou", "Yaoyiran Li", "Drew Garmon", "Yonghui Wu", "Safeen Huda", "Gil Fidel", "Martin Baeuml", "Jian Li", "Phoebe Kirk", "Rhys May", "Tao Tu", "Sara Mc Carthy", "Toshiyuki Fukuzawa", "Miranda Aperghis", "Chih-Kuan Yeh", "Toshihiro Yoshino", "Bo Li", "Austin Myers", "Kaisheng Yao", "Ben Limonchik", "Changwan Ryu", "Rohun Saxena", "Alex Goldin", "Ruizhe Zhao", "Rocky Rhodes", "Tao Zhu", "Divya Tyam", "Heidi Howard", "Nathan Byrd", "Hongxu Ma", "Yan Wu", "Ryan Mullins", "Qingze Wang", "Aida Amini", "Sebastien Baur", "Yiran Mao", "Subhashini Venugopalan", "Will Song", "Wen Ding", "Paul Collins", "Sashank Reddi", "Megan Shum", "Andrei Rusu", "Luisa Zintgraf", "Kelvin Chan", "Sheela Goenka", "Mathieu Blondel", "Michael Collins", "Renke Pan", "Marissa Giustina", "Nikolai Chinaev", "Christian Schuler", "Ce Zheng", "Jonas Valfridsson", "Alyssa Loo", "Alex Yakubovich", "Jamie Smith", "Tao Jiang", "Rich Munoz", "Gabriel Barcik", "Rishabh Bansal", "Mingyao Yang", "Yilun Du", "Pablo Duque", "Mary Phuong", "Alexandra Belias", "Kunal Lad", "Zeyu Liu", "Tal Schuster", "Karthik Duddu", "Jieru Hu", "Paige Kunkle", "Matthew Watson", "Jackson Tolins", "Josh Smith", "Denis Teplyashin", "Garrett Bingham", "Marvin Ritter", "Marco Andreetto", "Divya Pitta", "Mohak Patel", "Shashank Viswanadha", "Trevor Strohman", "Catalin Ionescu", "Jincheng Luo", "Yogesh Kalley", "Jeremy Wiesner", "Dan Deutsch", "Derek Lockhart", "Peter Choy", "Rumen Dangovski", "Chawin Sitawarin", "Cat Graves", "Tanya Lando", "Joost van Amersfoort", "Ndidi Elue", "Zhouyuan Huo", "Pooya Moradi", "Jean Tarbouriech", "Henryk Michalewski", "Wenting Ye", "Eunyoung Kim", "Alex Druinsky", "Florent Altché", "Xinyi Chen", "Artur Dwornik", "Da-Cheng Juan", "Rivka Moroshko", "Horia Toma", "Jarrod Kahn", "Hai Qian", "Maximilian Sieb", "Irene Cai", "Roman Goldenberg", "Praneeth Netrapalli", "Sindhu Raghuram", "Yuan Gong", "Lijie Fan", "Evan Palmer", "Yossi Matias", "Valentin Gabeur", "Shreya Pathak", "Tom Ouyang", "Don Metzler", "Geoff Bacon", "Srinivasan Venkatachary", "Sridhar Thiagarajan", "Alex Cullum", "Eran Ofek", "Vytenis Sakenas", "Mohamed Hammad", "Cesar Magalhaes", "Mayank Daswani", "Oscar Chang", "Ashok Popat", "Ruichao Li", "Komal Jalan", "Yanhan Hou", "Josh Lipschultz", "Antoine He", "Wenhao Jia", "Pier Giuseppe Sessa", "Prateek Kolhar", "William Wong", "Sumeet Singh", "Lukas Haas", "Jay Whang", "Hanna Klimczak-Plucińska", "Georges Rotival", "Grace Chung", "Yiqing Hua", "Anfal Siddiqui", "Nicolas Serrano", "Dongkai Chen", "Billy Porter", "Libin Bai", "Keshav Shivam", "Sho Arora", "Partha Talukdar", "Tom Cobley", "Sangnie Bhardwaj", "Evgeny Gladchenko", "Simon Green", "Kelvin Guu", "Felix Fischer", "Xiao Wu", "Eric Wang", "Achintya Singhal", "Tatiana Matejovicova", "James Martens", "Hongji Li", "Roma Patel", "Elizabeth Kemp", "Jiaqi Pan", "Lily Wang", "Blake JianHang Chen", "Jean-Baptiste Alayrac", "Navneet Potti", "Erika Gemzer", "Eugene Ie", "Kay McKinney", "Takaaki Saeki", "Edward Chou", "Pascal Lamblin", "SQ Mah", "Zach Fisher", "Martin Chadwick", "Jon Stritar", "Obaid Sarvana", "Andrew Hogue", "Artem Shtefan", "Hadi Hashemi", "Yang Xu", "Jindong Gu", "Sharad Vikram", "Chung-Ching Chang", "Sabela Ramos", "Logan Kilpatrick", "Weijuan Xi", "Jenny Brennan", "Yinghao Sun", "Abhishek Jindal", "Ionel Gog", "Dawn Chen", "Felix Wu", "Jason Lee", "Sudhindra Kopalle", "Srinadh Bhojanapalli", "Oriol Vinyals", "Natan Potikha", "Burcu Karagol Ayan", "Yuan Yuan", "Michael Riley", "Piotr Stanczyk", "Sergey Kishchenko", "Bing Wang", "Dan Garrette", "Antoine Yang", "Vlad Feinberg", "CJ Carey", "Javad Azizi", "Viral Shah", "Erica Moreira", "Chongyang Shi", "Josh Feldman", "Elizabeth Salesky", "Thomas Lampe", "Aneesh Pappu", "Duhyeon Kim", "Jonas Adler", "Avi Caciularu", "Brian Walker", "Yunhan Xu", "Yochai Blau", "Dylan Scandinaro", "Terry Huang", "Sam El-Husseini", "Abhishek Sinha", "Lijie Ren", "Taylor Tobin", "Patrik Sundberg", "Tim Sohn", "Vikas Yadav", "Mimi Ly", "Emily Xue", "Jing Xiong", "Afzal Shama Soudagar", "Sneha Mondal", "Nikhil Khadke", "Qingchun Ren", "Ben Vargas", "Stan Bileschi", "Sarah Chakera", "Cindy Wang", "Boyu Wang", "Yoni Halpern", "Joe Jiang", "Vikas Sindhwani", "Petre Petrov", "Pranavaraj Ponnuramu", "Sanket Vaibhav Mehta", "Yu Watanabe", "Betty Chan", "Matheus Wisniewski", "Trang Pham", "Jingwei Zhang", "Conglong Li", "Dario de Cesare", "Art Khurshudov", "Alex Vasiloff", "Melissa Tan", "Zoe Ashwood", "Bobak Shahriari", "Maryam Majzoubi", "Garrett Tanzer", "Olga Kozlova", "Robin Alazard", "James Lee-Thorp", "Nguyet Minh Phu", "Isaac Tian", "Junwhan Ahn", "Andy Crawford", "Lauren Lax", "Yuan Shangguan", "Iftekhar Naim", "David Ross", "Oleksandr Ferludin", "Tongfei Guo", "Andrea Banino", "Hubert Soyer", "Xiaoen Ju", "Dominika Rogozińska", "Ishaan Malhi", "Marcella Valentine", "Daniel Balle", "Apoorv Kulshreshtha", "Maciej Kula", "Yiwen Song", "Sophia Austin", "John Schultz", "Roy Hirsch", "Arthur Douillard", "Apoorv Reddy", "Michael Fink", "Summer Yue", "Khyatti Gupta", "Adam Zhang", "Norman Rink", "Daniel McDuff", "Lei Meng", "András György", "Yasaman Razeghi", "Ricky Liang", "Kazuki Osawa", "Aviel Atias", "Matan Eyal", "Tyrone Hill", "Nikolai Grigorev", "Zhengdong Wang", "Nitish Kulkarni", "Rachel Soh", "Ivan Lobov", "Zachary Charles", "Sid Lall", "Kazuma Hashimoto", "Ido Kessler", "Victor Gomes", "Zelda Mariet", "Danny Driess", "Alessandro Agostini", "Canfer Akbulut", "Jingcao Hu", "Marissa Ikonomidis", "Emily Caveness", "Kartik Audhkhasi", "Saurabh Agrawal", "Ioana Bica", "Evan Senter", "Jayaram Mudigonda", "Kelly Chen", "Jingchen Ye", "Xuanhui Wang", "James Svensson", "Philipp Fränken", "Josh Newlan", "Li Lao", "Eva Schnider", "Sami Alabed", "Joseph Kready", "Jesse Emond", "Afief Halumi", "Tim Zaman", "Chengxi Ye", "Naina Raisinghani", "Vilobh Meshram", "Bo Chang", "Ankit Singh Rawat", "Axel Stjerngren", "Sergey Levi", "Rui Wang", "Xiangzhu Long", "Mitchelle Rasquinha", "Steven Hand", "Aditi Mavalankar", "Lauren Agubuzu", "Sudeshna Roy", "Junquan Chen", "Jarek Wilkiewicz", "Hao Zhou", "Michal Jastrzebski", "Qiong Hu", "Agustin Dal Lago", "Ramya Sree Boppana", "Wei-Jen Ko", "Jennifer Prendki", "Yao Su", "Zhi Li", "Eliza Rutherford", "Girish Ramchandra Rao", "Ramona Comanescu", "Adrià Puigdomènech", "Qihang Chen", "Dessie Petrova", "Christine Chan", "Vedrana Milutinovic", "Felipe Tiengo Ferreira", "Chin-Yi Cheng", "Ming Zhang", "Tapomay Dey", "Sherry Yang", "Ramesh Sampath", "Quoc Le", "Howard Zhou", "Chu-Cheng Lin", "Hoi Lam", "Christine Kaeser-Chen", "Kai Hui", "Dean Hirsch", "Tom Eccles", "Basil Mustafa", "Shruti Rijhwani", "Morgane Rivière", "Yuanzhong Xu", "Junjie Wang", "Xinyang Geng", "Xiance Si", "Arjun Khare", "Cheolmin Kim", "Vahab Mirrokni", "Kamyu Lee", "Khuslen Baatarsukh", "Nathaniel Braun", "Lisa Wang", "Pallavi LV", "Richard Tanburn", "Yonghao Zhu", "Fangda Li", "Setareh Ariafar", "Dan Goldberg", "Ken Burke", "Daniil Mirylenka", "Meiqi Guo", "Olaf Ronneberger", "Hadas Natalie Vogel", "Liqun Cheng", "Nishita Shetty", "Johnson Jia", "Thomas Jimma", "Corey Fry", "Ted Xiao", "Martin Sundermeyer", "Ryan Burnell", "Yannis Assael", "Mario Pinto", "JD Chen", "Rohit Sathyanarayana", "Donghyun Cho", "Jing Lu", "Rishabh Agarwal", "Sugato Basu", "Lucas Gonzalez", "Dhruv Shah", "Meng Wei", "Dre Mahaarachchi", "Rohan Agrawal", "Tero Rissa", "Yani Donchev", "Ramiro Leal-Cavazos", "Adrian Hutter", "Markus Mircea", "Alon Jacovi", "Faruk Ahmed", "Jiageng Zhang", "Shuguang Hu", "Bo-Juen Chen", "Jonni Kanerva", "Guillaume Desjardins", "Andrew Lee", "Nikos Parotsidis", "Asier Mujika", "Tobias Weyand", "Jasper Snoek", "Jo Chick", "Kai Chen", "Paul Chang", "Ethan Mahintorabi", "Zi Wang", "Tolly Powell", "Orgad Keller", "Abhirut Gupta", "Claire Sha", "Kanav Garg", "Nicolas Heess", "Ágoston Weisz", "Cassidy Hardin", "Bartek Wydrowski", "Ben Coleman", "Karina Zainullina", "Pankaj Joshi", "Alessandro Epasto", "Terry Spitz", "Binbin Xiong", "Kai Zhao", "Arseniy Klimovskiy", "Ivy Zheng", "Johan Ferret", "Itay Yona", "Waleed Khawaja", "Jean-Baptiste Lespiau", "Maxim Krikun", "Siamak Shakeri", "Timothee Cour", "Bonnie Li", "Igor Krivokon", "Dan Suh", "Alex Hofer", "Jad Al Abdallah", "Nikita Putikhin", "Oscar Akerlund", "Silvio Lattanzi", "Anurag Kumar", "Shane Settle", "Himanshu Srivastava", "Folawiyo Campbell-Ajala", "Edouard Rosseel", "Mihai Dorin Istin", "Nishanth Dikkala", "Anand Rao", "Nick Young", "Kate Lin", "Dhruva Bhaswar", "Yiming Wang", "Jaume Sanchez Elias", "Kritika Muralidharan", "James Keeling", "Dayou Du", "Siddharth Gopal", "Gregory Dibb", "Charles Blundell", "Manolis Delakis", "Jacky Liang", "Marco Tulio Ribeiro", "Georgi Karadzhov", "Guillermo Garrido", "Ankur Bapna", "Jiawei Cao", "Adam Sadovsky", "Pouya Tafti", "Arthur Guez", "Coline Devin", "Yixian Di", "Jinwei Xing", "Chuqiao Joyce Xu", "Hanzhao Lin", "Chun-Te Chu", "Sameera Ponda", "Wesley Helmholz", "Fan Yang", "Yue Gao", "Sara Javanmardi", "Wael Farhan", "Alex Ramirez", "Ricardo Figueira", "Khe Chai Sim", "Yuval Bahat", "Ashwin Vaswani", "Liangzhe Yuan", "Gufeng Zhang", "Leland Rechis", "Hanjun Dai", "Tayo Oguntebi", "Alexandra Cordell", "Eugénie Rives", "Kaan Tekelioglu", "Naveen Kumar", "Bing Zhang", "Aurick Zhou", "Nikolay Savinov", "Andrew Leach", "Alex Tudor", "Sanjay Ganapathy", "Yanyan Zheng", "Mirko Rossini", "Vera Axelrod", "Arnaud Autef", "Yukun Zhu", "Zheng Zheng", "Mingda Zhang", "Baochen Sun", "Jie Ren", "Nenad Tomasev", "Nithish Kannen", "Amer Sinha", "Charles Chen", "Louis O'Bryan", "Alex Pak", "Aditya Kusupati", "Weel Yang", "Deepak Ramachandran", "Patrick Griffin", "Seokhwan Kim", "Philipp Neubeck", "Craig Schiff", "Tammo Spalink", "Mingyang Ling", "Arun Nair", "Ga-Young Joung", "Linda Deng", "Avishkar Bhoopchand", "Lora Aroyo", "Tom Duerig", "Jordan Griffith", "Gabe Barth-Maron", "Jake Ades", "Alex Haig", "Ankur Taly", "Yunting Song", "Paul Michel", "Dave Orr", "Dean Weesner", "Corentin Tallec", "Carrie Grimes Bostock", "Paul Niemczyk", "Andy Twigg", "Mudit Verma", "Rohith Vallu", "Henry Wang", "Marco Gelmi", "Kiranbir Sodhia", "Aleksandr Chuklin", "Omer Goldman", "Jasmine George", "Liang Bai", "Kelvin Zhang", "Petar Sirkovic", "Efrat Nehoran", "Golan Pundak", "Jiaqi Mu", "Alice Chen", "Alex Greve", "Paulo Zacchello", "David Amos", "Heming Ge", "Eric Noland", "Colton Bishop", "Jeffrey Dudek", "Youhei Namiki", "Elena Buchatskaya", "Jing Li", "Dorsa Sadigh", "Masha Samsikova", "Dan Malkin", "Damien Vincent", "Robert David", "Rob Willoughby", "Phoenix Meadowlark", "Shawn Gao", "Yan Li", "Raj Apte", "Amit Jhindal", "Stein Xudong Lin", "Alex Polozov", "Zhicheng Wang", "Tomas Mery", "Anirudh GP", "Varun Yerram", "Sage Stevens", "Tianqi Liu", "Noah Fiedel", "Charles Sutton", "Matthew Johnson", "Xiaodan Song", "Kate Baumli", "Nir Shabat", "Muqthar Mohammad", "Hao Liu", "Marco Selvi", "Yichao Zhou", "Mehdi Hafezi Manshadi", "Chu-ling Ko", "Anthony Chen", "Michael Bendersky", "Jorge Gonzalez Mendez", "Nisarg Kothari", "Amir Zandieh", "Yiling Huang", "Daniel Andor", "Ellie Pavlick", "Idan Brusilovsky", "Jitendra Harlalka", "Sally Goldman", "Andrew Lampinen", "Guowang Li", "Asahi Ushio", "Somit Gupta", "Lei Zhang", "Chuyuan Kelly Fu", "Madhavi Sewak", "Timo Denk", "Jed Borovik", "Brendan Jou", "Avital Zipori", "Prateek Jain", "Junwen Bai", "Thang Luong", "Jonathan Tompson", "Alice Li", "Li Liu", "George Powell", "Jiajun Shen", "Alex Feng", "Grishma Chole", "Da Yu", "Yinlam Chow", "Tongxin Yin", "Eric Malmi", "Kefan Xiao", "Yash Pande", "Shachi Paul", "Niccolò Dal Santo", "Adil Dostmohamed", "Sergio Guadarrama", "Aaron Phillips", "Thanumalayan Sankaranarayana Pillai", "Gal Yona", "Amin Ghafouri", "Preethi Lahoti", "Benjamin Lee", "Dhruv Madeka", "Eren Sezener", "Simon Tokumine", "Adrian Collister", "Nicola De Cao", "Richard Shin", "Uday Kalra", "Parker Beak", "Emily Nottage", "Ryo Nakashima", "Ivan Jurin", "Vikash Sehwag", "Meenu Gaba", "Junhao Zeng", "Kevin R. McKee", "Fernando Pereira", "Tamar Yakar", "Amayika Panda", "Arka Dhar", "Peilin Zhong", "Daniel Sohn", "Mark Brand", "Lars Lowe Sjoesund", "Viral Carpenter", "Sharon Lin", "Shantanu Thakoor", "Marcus Wainwright", "Ashwin Chaugule", "Pranesh Srinivasan", "Muye Zhu", "Bernett Orlando", "Jack Weber", "Ayzaan Wahid", "Gilles Baechler", "Apurv Suman", "Jovana Mitrović", "Gabe Taubman", "Honglin Yu", "Helen King", "Josh Dillon", "Cathy Yip", "Dhriti Varma", "Tomas Izo", "Levent Bolelli", "Borja De Balle Pigem", "Julia Di Trapani", "Fotis Iliopoulos", "Adam Paszke", "Nishant Ranka", "Joe Zou", "Francesco Pongetti", "Jed McGiffin", "Alex Siegman", "Rich Galt", "Ross Hemsley", "Goran Žužić", "Victor Carbune", "Tao Li", "Myle Ott", "Félix de Chaumont Quitry", "David Vilar Torres", "Yuri Chervonyi", "Tomy Tsai", "Prem Eruvbetine", "Samuel Yang", "Matthew Denton", "Jake Walker", "Slavica Andačić", "Idan Heimlich Shtacher", "Vittal Premachandran", "Harshal Tushar Lehri", "Cip Baetu", "Damion Yates", "Lampros Lamprou", "Mariko Iinuma", "Ioana Mihailescu", "Ben Albrecht", "Shachi Dave", "Susie Sargsyan", "Bryan Perozzi", "Lucas Manning", "Chiyuan Zhang", "Denis Vnukov", "Igor Mordatch", "Raia Hadsell Wolfgang Macherey", "Ryan Kappedal", "Jim Stephan", "Aditya Tripathi", "Klaus Macherey", "Jun Qian", "Abhishek Bhowmick", "Shekoofeh Azizi", "Rémi Leblond", "Shiva Mohan Reddy Garlapati", "Timothy Knight", "Matthew Wiethoff", "Wei-Chih Hung", "Anelia Angelova", "Georgios Evangelopoulos", "Pawel Janus", "Dimitris Paparas", "Matthew Rahtz", "Ken Caluwaerts", "Vivek Sampathkumar", "Daniel Jarrett", "Shadi Noghabi", "Antoine Miech", "Chak Yeung", "Geoff Clark", "Henry Prior", "Fei Zheng", "Jean Pouget-Abadie", "Indro Bhattacharya", "Kalpesh Krishna", "Will Bishop", "Zhe Yuan", "Yunxiao Deng", "Ashutosh Sathe", "Kacper Krasowiak", "Ciprian Chelba", "Cho-Jui Hsieh", "Kiran Vodrahalli", "Buhuang Liu", "Thomas Köppe", "Amr Khalifa", "Lubo Litchev", "Pichi Charoenpanit", "Reed Roberts", "Sachin Yadav", "Yasumasa Onoe", "Desi Ivanov", "Megha Mohabey", "Vighnesh Birodkar", "Nemanja Rakićević", "Pierre Sermanet", "Vaibhav Mehta", "Krishan Subudhi", "Travis Choma", "Will Ng", "Luheng He", "Kathie Wang", "Tasos Kementsietsidis", "Shane Gu", "Mansi Gupta", "Andrew Nystrom", "Mehran Kazemi", "Timothy Chung", "Nacho Cano", "Nikhil Dhawan", "Yufei Wang", "Jiawei Xia", "Trevor Yacovone", "Eric Jia", "Mingqing Chen", "Simeon Ivanov", "Ashrith Sheshan", "Sid Dalmia", "Paweł Stradomski", "Pengcheng Yin", "Salem Haykal", "Congchao Wang", "Dennis Duan", "Neslihan Bulut", "Greg Kochanski", "Liam MacDermed", "Namrata Godbole", "Shitao Weng", "Jingjing Chen", "Rachana Fellinger", "Ramin Mehran", "Daniel Suo", "Hisham Husain", "Tong He", "Kaushal Patel", "Joshua Howland", "Randall Parker", "Kelvin Nguyen", "Sharath Maddineni", "Chris Rawles", "Mina Khan", "Shlomi Cohen-Ganor", "Amol Mandhane", "Xinyi Wu", "Chenkai Kuang", "Iulia Comşa", "Ramya Ganeshan", "Hanie Sedghi", "Adam Bloniarz", "Nuo Wang Pierse", "Anton Briukhov", "Petr Mitrichev", "Anita Gergely", "Serena Zhan", "Allan Zhou", "Nikita Saxena", "Eva Lu", "Josef Dean", "Ashish Gupta", "Nicolas Perez-Nieves", "Renjie Wu", "Cory McLean", "Wei Liang", "Disha Jindal", "Anton Tsitsulin", "Wenhao Yu", "Kaiz Alarakyia", "Tom Schaul", "Piyush Patil", "Peter Sung", "Elijah Peake", "Hongkun Yu", "Feryal Behbahani", "JD Co-Reyes", "Alan Ansell", "Sean Sun", "Clara Barbu", "Jonathan Lee", "Seb Noury", "James Allingham", "Bilal Piot", "Mohit Sharma", "Christopher Yew", "Ivan Korotkov", "Bibo Xu", "Demetra Brady", "Goran Petrovic", "Shibl Mourad", "Claire Cui", "Aditya Gupta", "Parker Schuh", "Saarthak Khanna", "Anna Goldie", "Abhinav Arora", "Vadim Zubov", "Amy Stuart", "Mark Epstein", "Yun Zhu", "Jianqiao Liu", "Yury Stuken", "Ziyue Wang", "Karolis Misiunas", "Dee Guo", "Ashleah Gill", "Ale Hartman", "Zaid Nabulsi", "Aurko Roy", "Aleksandra Faust", "Jason Riesa", "Ben Withbroe", "Mengchao Wang", "Marco Tagliasacchi", "Andreea Marzoca", "James Noraky", "Serge Toropov", "Malika Mehrotra", "Bahram Raad", "Sanja Deur", "Steve Xu", "Marianne Monteiro", "Zhongru Wu", "Yi Luan", "Sam Ritter", "Nick Li", "Håvard Garnes", "Yanzhang He", "Martin Zlocha", "Jifan Zhu", "Matteo Hessel", "Will Wu", "Spandana Raj Babbula", "Chizu Kawamoto", "Yuanzhen Li", "Mehadi Hassen", "Yan Wang", "Brian Wieder", "James Freedman", "Yin Zhang", "Xinyi Bai", "Tianli Yu", "David Reitter", "XiangHai Sheng", "Mateo Wirth", "Aditya Kini", "Dima Damen", "Mingcen Gao", "Rachel Hornung", "Michael Voznesensky", "Brian Roark", "Adhi Kuncoro", "Yuxiang Zhou", "Rushin Shah", "Anthony Brohan", "Kuangyuan Chen", "James Wendt", "David Rim", "Paul Kishan Rubenstein", "Jonathan Halcrow", "Michelle Liu", "Ty Geri", "Yunhsuan Sung", "Jane Shapiro", "Shaan Bijwadia", "Chris Duvarney", "Christina Sorokin", "Paul Natsev", "Reeve Ingle", "Pramod Gupta", "Young Maeng", "Ndaba Ndebele", "Kexin Zhu", "Valentin Anklin", "Katherine Lee", "Yuan Liu", "Yaroslav Akulov", "Shaleen Gupta", "Guolong Su", "Flavien Prost", "Tianlin Liu", "Vitaly Kovalev", "Pol Moreno", "Martin Scholz", "Sam Redmond", "Zongwei Zhou", "Alex Castro-Ros", "André Susano Pinto", "Dia Kharrat", "Michal Yarom", "Rachel Saputro", "Jannis Bulian", "Ben Caine", "Ji Liu", "Abbas Abdolmaleki", "Shariq Iqbal", "Tautvydas Misiunas", "Mikhail Sirotenko", "Shefali Garg", "Guy Bensky", "Huan Gui", "Xuezhi Wang", "Raphael Koster", "Mike Bernico", "Da Huang", "Romal Thoppilan", "Trevor Cohn", "Ben Golan", "Wenlei Zhou", "Andrew Rosenberg", "Markus Freitag", "Tynan Gangwani", "Vincent Tsang", "Anand Shukla", "Xiaoqi Ren", "Minh Giang", "Chi Zou", "Andre Elisseeff", "Charline Le Lan", "Dheeru Dua", "Shuba Lall", "Pranav Shyam", "Frankie Garcia", "Sarah Nguyen", "Michael Guzman", "AJ Maschinot", "Marcello Maggioni", "Ming-Wei Chang", "Karol Gregor", "Lotte Weerts", "Kumaran Venkatesan", "Bogdan Damoc", "Leon Liu", "Jan Wassenberg", "Lewis Ho", "Becca Roelofs", "Majid Hadian", "François-Xavier Aubet", "Yu Liang", "Sami Lachgar", "Danny Karmon", "Yong Cheng", "Amelio Vázquez-Reina", "Angie Chen", "Zhuyun Dai", "Andy Brock", "Shubham Agrawal", "Chenxi Pang", "Peter Garst", "Mariella Sanchez-Vargas", "Ivor Rendulic", "Aditya Ayyar", "Andrija Ražnatović", "Olivia Ma", "Roopali Vij", "Neha Sharma", "Ashwin Balakrishna", "Bingyuan Liu", "Ian Mackinnon", "Sorin Baltateanu", "Petra Poklukar", "Gabriel Ibagon", "Colin Ji", "Hongyang Jiao", "Isaac Noble", "Wojciech Stokowiec", "Zhihao Li", "Jeff Dean", "David Lindner", "Mark Omernick", "Kristen Chiafullo", "Mason Dimarco", "Vitor Rodrigues", "Vittorio Selo", "Garrett Honke", "Xintian Cindy Wu", "Wei He", "Adam Hillier", "Anhad Mohananey", "Vihari Piratla", "Chang Ye", "Chase Malik", "Sebastian Riedel", "Samuel Albanie", "Zi Yang", "Kenny Vassigh", "Maria Bauza", "Sheng Li", "Yiqing Tao", "Nevan Wichers", "Andrii Maksai", "Abe Ittycheriah", "Ross Mcilroy", "Bryan Seybold", "Noah Goodman", "Romina Datta", "Steven M. Hernandez", "Tian Shi", "Yony Kochinski", "Anna Bulanova", "Ken Franko", "Mikita Sazanovich", "Nicholas FitzGerald", "Praneeth Kacham", "Shubha Srinivas Raghvendra", "Vincent Hellendoorn", "Alexander Grushetsky", "Julian Salazar", "Angeliki Lazaridou", "Jason Chang", "Jan-Thorsten Peter", "Sushant Kafle", "Yann Dauphin", "Abhishek Rao", "Filippo Graziano", "Izhak Shafran", "Yuguo Liao", "Tianli Ding", "Geng Yan", "Grace Chu", "Zhao Fu", "Vincent Roulet", "Gabriel Rasskin", "Duncan Williams", "Shahar Drath", "Alex Mossin", "Raphael Hoffmann", "Jordi Orbay", "Francesco Bertolini", "Hila Sheftel", "Justin Chiu", "Siyang Xue", "Yuheng Kuang", "Ferjad Naeem", "Swaroop Nath", "Nana Nti", "Phil Culliton", "Kashyap Krishnakumar", "Michael Isard", "Pei Sun", "Ayan Chakrabarti", "Nathan Clement", "Regev Cohen", "Arissa Wongpanich", "GS Oh", "Ashwin Murthy", "Hao Zheng", "Jessica Hamrick", "Oskar Bunyan", "Suhas Ganesh", "Nitish Gupta", "Roy Frostig", "John Wieting", "Yury Malkov", "Pierre Marcenac", "Zhixin Lucas Lai", "Xiaodan Tang", "Mohammad Saleh", "Fedir Zubach", "Chinmay Kulkarni", "Huanjie Zhou", "Vicky Zayats", "Nan Ding", "Anshuman Tripathi", "Arijit Pramanik", "Patrik Zochbauer", "Harish Ganapathy", "Vedant Misra", "Zach Behrman", "Hugo Vallet", "Mingyang Zhang", "Mukund Sridhar", "Ye Jin", "Mohammad Babaeizadeh", "Siim Põder", "Megha Goel", "Divya Jain", "Tajwar Nasir", "Shubham Mittal", "Tim Dozat", "Diego Ardila", "Aliaksei Severyn", "Fabio Pardo", "Sammy Jerome", "Siyang Qin", "Louis Rouillard", "Amir Yazdanbakhsh", "Zizhao Zhang", "Shivani Agrawal", "Kaushik Shivakumar", "Caden Lu", "Praveen Kallakuri", "Rachita Chhaparia", "Kanishka Rao", "Charles Kwong", "Asya Fadeeva", "Shitij Nigam", "Yan Virin", "Yuan Zhang", "Balaji Venkatraman", "Beliz Gunel", "Marc Wilson", "Huiyu Wang", "Abhinav Gupta", "Xiaowei Xu", "Adrien Ali Taïga", "Kareem Mohamed", "Doug Fritz", "Daniel Rodriguez", "Zoubin Ghahramani", "Harry Askham", "Lior Belenki", "James Zhao", "Rahul Gupta", "Krzysztof Jastrzębski", "Takahiro Kosakai", "Kaan Katircioglu", "Jon Schneider", "Rina Panigrahy", "Konstantinos Bousmalis", "Peter Grabowski", "Prajit Ramachandran", "Chaitra Hegde", "Mihaela Rosca", "Angelo Scorza Scarpati", "Kyriakos Axiotis", "Ying Xu", "Zach Gleicher", "Assaf Hurwitz Michaely", "Mandar Sharma", "Sanil Jain", "Christoph Hirnschall", "Tal Marian", "Xuhui Jia", "Kevin Mather", "Kilol Gupta", "Linhai Qiu", "Nigamaa Nayakanti", "Lucian Ionita", "Steven Zheng", "Lucia Loher", "Kurt Shuster", "Igor Petrovski", "Roshan Sharma", "Rahma Chaabouni", "Angel Yeh", "James An", "Arushi Gupta", "Steven Schwarcz", "Seher Ellis", "Sam Conway-Rahman", "Javier Snaider", "Alex Zhai", "James Atwood", "Daniel Golovin", "Liqian Peng", "Te I", "Vivian Xia", "Salvatore Scellato", "Mahan Malihi", "Arthur Bražinskas", "Vlad-Doru Ion", "Younghoon Jun", "James Swirhun", "Soroosh Mariooryad", "Jiao Sun", "Steve Chien", "Rey Coaguila", "Ariel Brand", "Yi Gao", "Tom Kwiatkowski", "Roee Aharoni", "Cheng-Chun Lee", "Mislav Žanić", "Yichi Zhang", "Dan Ethier", "Vitaly Nikolaev", "Pranav Nair", "Yoav Ben Shalom", "Hen Fitoussi", "Jai Gupta", "Hongbin Liu", "Dee Cattle", "Tolga Bolukbasi", "Ben Murdoch", "Fantine Huot", "Yin Li", "Chris Hahn"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      72 pages, 17 figures", "url": "http://arxiv.org/abs/2507.06261v2", "summary": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and\nGemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite\nmodels. Gemini 2.5 Pro is our most capable model yet, achieving SoTA\nperformance on frontier coding and reasoning benchmarks. In addition to its\nincredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that\nexcels at multimodal understanding and it is now able to process up to 3 hours\nof video content. Its unique combination of long context, multimodal and\nreasoning capabilities can be combined to unlock new agentic workflows. Gemini\n2.5 Flash provides excellent reasoning abilities at a fraction of the compute\nand latency requirements and Gemini 2.0 Flash and Flash-Lite provide high\nperformance at low latency and cost. Taken together, the Gemini 2.X model\ngeneration spans the full Pareto frontier of model capability vs cost, allowing\nusers to explore the boundaries of what is possible with complex agentic\nproblem solving.", "comment": "72 pages, 17 figures", "pdf_url": "http://arxiv.org/pdf/2507.06261v2", "cate": "cs.CL", "date": "2025-07-07", "updated": "2025-07-11"}
{"id": "2504.01531", "title": "DRAN: A Distribution and Relation Adaptive Network for Spatio-temporal Forecasting", "authors": ["Xiaobei Zou", "Luolin Xiong", "Kexuan Zhang", "Cesare Alippi", "Yang Tang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      15 pages, 10 figures", "url": "http://arxiv.org/abs/2504.01531v3", "summary": "Accurate predictions of spatio-temporal systems are crucial for tasks such as\nsystem management, control, and crisis prevention. However, the inherent time\nvariance of many spatio-temporal systems poses challenges to achieving accurate\npredictions whenever stationarity is not granted. In order to address\nnon-stationarity, we propose a Distribution and Relation Adaptive Network\n(DRAN) capable of dynamically adapting to relation and distribution changes\nover time. While temporal normalization and de-normalization are frequently\nused techniques to adapt to distribution shifts, this operation is not suitable\nfor the spatio-temporal context as temporal normalization scales the time\nseries of nodes and possibly disrupts the spatial relations among nodes. In\norder to address this problem, a Spatial Factor Learner (SFL) module is\ndeveloped that enables the normalization and de-normalization process. To adapt\nto dynamic changes in spatial relationships among sensors, we propose a\nDynamic-Static Fusion Learner (DSFL) module that effectively integrates\nfeatures learned from both dynamic and static relations through an adaptive\nfusion ratio mechanism. Furthermore, we introduce a Stochastic Learner to\ncapture the noisy components of spatio-temporal representations. Our approach\noutperforms state-of-the-art methods on weather prediction and traffic flow\nforecasting tasks.Experimental results show that our SFL efficiently preserves\nspatial relationships across various temporal normalization operations.\nVisualizations of the learned dynamic and static relations demonstrate that\nDSFL can capture both local and distant relationships between nodes.", "comment": "15 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2504.01531v3", "cate": "cs.LG", "date": "2025-04-02", "updated": "2025-07-11"}
{"id": "2507.07340", "title": "Entity Re-identification in Visual Storytelling via Contrastive Reinforcement Learning", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "categories": ["cs.CV", "I.2; I.4; I.5; I.7"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      7 pages", "url": "http://arxiv.org/abs/2507.07340v2", "summary": "Visual storytelling systems, particularly large vision-language models,\nstruggle to maintain character and object identity across frames, often failing\nto recognize when entities in different images represent the same individuals\nor objects, leading to inconsistent references and referential hallucinations.\nThis occurs because models lack explicit training on when to establish entity\nconnections across frames. We propose a contrastive reinforcement learning\napproach that trains models to discriminate between coherent image sequences\nand stories from unrelated images. We extend the Story Reasoning dataset with\nsynthetic negative examples to teach appropriate entity connection behavior. We\nemploy Direct Preference Optimization with a dual-component reward function\nthat promotes grounding and re-identification of entities in real stories while\npenalizing incorrect entity connections in synthetic contexts. Using this\ncontrastive framework, we fine-tune Qwen Storyteller (based on Qwen2.5-VL 7B).\nEvaluation shows improvements in grounding mAP from 0.27 to 0.31 (+14.8%), F1\nfrom 0.35 to 0.41 (+17.1%). Pronoun grounding accuracy improved across all\npronoun types except \"its\", and cross-frame character and object persistence\nincreased across all frame counts, with entities appearing in 5 or more frames\nadvancing from 29.3% to 33.3% (+13.7%). Well-structured stories, containing the\nchain-of-thought and grounded story, increased from 79.1% to 97.5% (+23.3%).", "comment": "7 pages", "pdf_url": "http://arxiv.org/pdf/2507.07340v2", "cate": "cs.CV", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2404.18865", "title": "Truth-value judgment in language models: 'truth directions' are context sensitive", "authors": ["Stefan F. Schouten", "Peter Bloem", "Ilia Markov", "Piek Vossen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2404.18865v3", "summary": "Recent work has demonstrated that the latent spaces of large language models\n(LLMs) contain directions predictive of the truth of sentences. Multiple\nmethods recover such directions and build probes that are described as\nuncovering a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon,\nlooking closely at the impact of context on the probes. Our experiments\nestablish where in the LLM the probe's predictions are (most) sensitive to the\npresence of related sentences, and how to best characterize this kind of\nsensitivity. We do so by measuring different types of consistency errors that\noccur after probing an LLM whose inputs consist of hypotheses preceded by\n(negated) supporting and contradicting sentences. We also perform a causal\nintervention experiment, investigating whether moving the representation of a\npremise along these truth-value directions influences the position of an\nentailed or contradicted sentence along that same direction. We find that the\nprobes we test are generally context sensitive, but that contexts which should\nnot affect the truth often still impact the probe outputs. Our experiments show\nthat the type of errors depend on the layer, the model, and the kind of data.\nFinally, our results suggest that truth-value directions are causal mediators\nin the inference process that incorporates in-context information.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2404.18865v3", "cate": "cs.CL", "date": "2024-04-29", "updated": "2025-07-11"}
{"id": "2507.08536", "title": "Enhancing Decoding Performance using Efficient Error Learning", "authors": ["Pavithran Iyer", "Aditya Jain", "Stephen D. Bartlett", "Joseph Emerson"], "categories": ["quant-ph", "cs.IT", "math.IT"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      22 pages, 11 figures", "url": "http://arxiv.org/abs/2507.08536v1", "summary": "Lowering the resource overhead needed to achieve fault-tolerant quantum\ncomputation is crucial to building scalable quantum computers. We show that\nadapting conventional maximum likelihood (ML) decoders to a small subset of\nefficiently learnable physical error characteristics can significantly improve\nthe logical performance of a quantum error-correcting code. Specifically, we\nleverage error information obtained from efficient characterization methods\nbased on Cycle Error Reconstruction (CER), which yields Pauli error rates on\nthe $n$ qubits of an error-correcting code. Although the total number of Pauli\nerror rates needed to describe a general noise process is exponentially large\nin $n$, we show that only a few of the largest few Pauli error rates are needed\nand that a heuristic technique can complete the Pauli error distribution for ML\ndecoding from this restricted dataset. Using these techniques, we demonstrate\nsignificant performance improvements for decoding quantum codes under a variety\nof physically relevant error models. For instance, with CER data that\nconstitute merely $1\\%$ of the Pauli error rates in the system, we achieve a\n$10X$ gain in performance compared to the case where decoding is based solely\non the fidelity of the underlying noise process. Our conclusions underscore the\npromise of recent error characterization methods for improving quantum error\ncorrection and lowering overheads.", "comment": "22 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.08536v1", "cate": "quant-ph", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.06892", "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model", "authors": ["Jing Liang", "Hongyao Tang", "Yi Ma", "Jinyi Liu", "Yan Zheng", "Shuyue Hu", "Lei Bai", "Jianye Hao"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Preliminary version, v3, added the missing name of x-axis in the left part of Fig.1 and corrected a wrong number in Fig.3. Project page: this https URL", "url": "http://arxiv.org/abs/2507.06892v3", "summary": "Reinforcement Learning (RL) has demonstrated its potential to improve the\nreasoning ability of Large Language Models (LLMs). One major limitation of most\nexisting Reinforcement Finetuning (RFT) methods is that they are on-policy RL\nin nature, i.e., data generated during the past learning process is not fully\nutilized. This inevitably comes at a significant cost of compute and time,\nposing a stringent bottleneck on continuing economic and efficient scaling. To\nthis end, we launch the renaissance of off-policy RL and propose Reincarnating\nMix-policy Proximal Policy Gradient (ReMix), a general approach to enable\non-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix\nconsists of three major components: (1) Mix-policy proximal policy gradient\nwith an increased Update-To-Data (UTD) ratio for efficient training; (2)\nKL-Convex policy constraint to balance the trade-off between stability and\nflexibility; (3) Policy reincarnation to achieve a seamless transition from\nefficient early-stage learning to steady asymptotic improvement. In our\nexperiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base\nmodels. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with\n0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B\nmodel) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math\nreasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and\nMATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level\nperformance with an over 30x to 450x reduction in training cost in terms of\nrollout data volume. In addition, we reveal insightful findings via\nmultifaceted analysis, including the implicit preference for shorter responses\ndue to the Whipping Effect of off-policy discrepancy, the collapse mode of\nself-reflection behavior under the presence of severe off-policyness, etc.", "comment": "Preliminary version, v3, added the missing name of x-axis in the left\n  part of Fig.1 and corrected a wrong number in Fig.3. Project page:\n  https://anitaleungxx.github.io/ReMix", "pdf_url": "http://arxiv.org/pdf/2507.06892v3", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2504.13792", "title": "Binary and Ternary Quantization Can Enhance Feature Discrimination", "authors": ["Weizhi Lu", "Mingrui Chen", "Weiyu Li"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.13792v2", "summary": "Quantization is widely applied in machine learning to reduce computational\nand storage costs for both data and models. Considering that classification\ntasks are fundamental to the field, it is crucial to investigate how\nquantization impacts classification performance. Traditional research has\nfocused on quantization errors, assuming that larger errors generally lead to\nlower classification accuracy. However, this assumption lacks a solid\ntheoretical foundation and often contradicts empirical observations. For\nexample, despite introducing significant errors, $\\{0,1\\}$-binary and $\\{0,\n\\pm1\\}$-ternary quantized data have sometimes achieved classification accuracy\ncomparable or even superior to full-precision data. To reasonably explain this\nphenomenon, a more accurate evaluation of classification performance is\nrequired. To achieve this, we propose a direct analysis of the feature\ndiscrimination of quantized data, instead of focusing on quantization errors.\nOur analysis reveals that both binary and ternary quantization can potentially\nenhance, rather than degrade, the feature discrimination of the original data.\nThis finding is supported by classification experiments conducted on both\nsynthetic and real data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.13792v2", "cate": "cs.LG", "date": "2025-04-18", "updated": "2025-07-11"}
{"id": "2507.07393", "title": "KeyRe-ID: Keypoint-Guided Person Re-Identification using Part-Aware Representation in Videos", "authors": ["Jinseong Kim", "Junghoon Song", "Gyeongseon Baek", "Byeongjoon Noh"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures,", "url": "http://arxiv.org/abs/2507.07393v2", "summary": "We propose \\textbf{KeyRe-ID}, a keypoint-guided video-based person\nre-identification framework consisting of global and local branches that\nleverage human keypoints for enhanced spatiotemporal representation learning.\nThe global branch captures holistic identity semantics through\nTransformer-based temporal aggregation, while the local branch dynamically\nsegments body regions based on keypoints to generate fine-grained, part-aware\nfeatures. Extensive experiments on MARS and iLIDS-VID benchmarks demonstrate\nstate-of-the-art performance, achieving 91.73\\% mAP and 97.32\\% Rank-1 accuracy\non MARS, and 96.00\\% Rank-1 and 100.0\\% Rank-5 accuracy on iLIDS-VID. The code\nfor this work will be publicly available on GitHub upon publication.", "comment": "10 pages, 2 figures,", "pdf_url": "http://arxiv.org/pdf/2507.07393v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2411.01077", "title": "Emoji Attack: Enhancing Jailbreak Attacks Against Judge LLM Detection", "authors": ["Zhipeng Wei", "Yuqi Liu", "N. Benjamin Erichson"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.01077v4", "summary": "Jailbreaking techniques trick Large Language Models (LLMs) into producing\nrestricted output, posing a potential threat. One line of defense is to use\nanother LLM as a Judge to evaluate the harmfulness of generated text. However,\nwe reveal that these Judge LLMs are vulnerable to token segmentation bias, an\nissue that arises when delimiters alter the tokenization process, splitting\nwords into smaller sub-tokens. This alters the embeddings of the entire\nsequence, reducing detection accuracy and allowing harmful content to be\nmisclassified as safe. In this paper, we introduce Emoji Attack, a novel\nstrategy that amplifies existing jailbreak prompts by exploiting token\nsegmentation bias. Our method leverages in-context learning to systematically\ninsert emojis into text before it is evaluated by a Judge LLM, inducing\nembedding distortions that significantly lower the likelihood of detecting\nunsafe content. Unlike traditional delimiters, emojis also introduce semantic\nambiguity, making them particularly effective in this attack. Through\nexperiments on state-of-the-art Judge LLMs, we demonstrate that Emoji Attack\nsubstantially reduces the unsafe prediction rate, bypassing existing\nsafeguards.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.01077v4", "cate": "cs.CL", "date": "2024-11-01", "updated": "2025-07-11"}
{"id": "2507.08773", "title": "Total/dual correlation/coherence, redundancy/synergy, complexity, and O-information for real and complex valued multivariate data", "authors": ["Roberto D. Pascual-Marqui", "Kieko Kochi", "Toshihiko Kinoshita"], "categories": ["stat.ME", "cs.IT", "math.IT", "math.ST", "stat.TH"], "primary_category": "Subjects:       Methodology (stat.ME)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08773v1", "summary": "Firstly, assuming Gaussianity, equations for the following information theory\nmeasures are presented: total correlation/coherence (TC), dual total\ncorrelation/coherence (DTC), O-information, TSE complexity, and the\nredundancy-synergy index (RSI). Since these measures are functions of the\ncovariance matrix \"S\" and its inverse \"S^-1\", the associated Wishart and\ninverse-Wishart distributions are of note. The DTC is shown here to be the\nKullback-Leibler (KL) divergence for the inverse-Wishart pair \"(S^-1)\" and its\ndiagonal matrix \"diag(S^-1)\", shedding light on its interpretation as a measure\nof \"total partial correlation\", -lndetP, with test hypothesis H0: P=I, where\n\"P\" is the standardized inverse covariance (i.e. P=(D^-1/2)(S^-1)(D^-1/2), with\nD=diag(S^-1)). The second aim of this paper introduces a generalization of all\nthese measures for structured groups of variables. For instance, consider three\nor more groups, each consisting of three or more variables, with predominant\nredundancy within each group, but with synergistic interactions between groups.\nO-information will miss the between group synergy (since redundancy occurs more\noften in the system). In contrast, the structured O-information measure\npresented here will correctly report predominant synergy between groups. This\nis a relevant generalization towards structured multivariate information\nmeasures. A third aim is the presentation of a framework for quantifying the\ncontribution of \"connections\" between variables, to the system's TC, DTC,\nO-information, and TSE complexity. A fourth aim is to present a generalization\nof the redundancy-synergy index for quantifying the contribution of a group of\nvariables to the system's redundancy-synergy balance. Finally, it is shown that\nthe expressions derived here directly apply to data from several other\nelliptical distributions. All program codes, data files, and executables are\navailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08773v1", "cate": "stat.ME", "date": "2025-07-11", "updated": "2025-07-11"}
{"id": "2507.07460", "title": "Objectomaly: Objectness-Aware Refinement for OoD Segmentation with Structural Consistency and Boundary Precision", "authors": ["Jeonghoon Song", "Sunghun Kim", "Jaegyun Im", "Byeongjoon Noh"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07460v2", "summary": "Out-of-Distribution (OoD) segmentation is critical for safety-sensitive\napplications like autonomous driving. However, existing mask-based methods\noften suffer from boundary imprecision, inconsistent anomaly scores within\nobjects, and false positives from background noise. We propose\n\\textbf{\\textit{Objectomaly}}, an objectness-aware refinement framework that\nincorporates object-level priors. Objectomaly consists of three stages: (1)\nCoarse Anomaly Scoring (CAS) using an existing OoD backbone, (2)\nObjectness-Aware Score Calibration (OASC) leveraging SAM-generated instance\nmasks for object-level score normalization, and (3) Meticulous Boundary\nPrecision (MBP) applying Laplacian filtering and Gaussian smoothing for contour\nrefinement. Objectomaly achieves state-of-the-art performance on key OoD\nsegmentation benchmarks, including SMIYC AnomalyTrack/ObstacleTrack and\nRoadAnomaly, improving both pixel-level (AuPRC up to 96.99, FPR$_{95}$ down to\n0.07) and component-level (F1$-$score up to 83.44) metrics. Ablation studies\nand qualitative results on real-world driving videos further validate the\nrobustness and generalizability of our method. Code will be released upon\npublication.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07460v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2504.19034", "title": "On learning functions over biological sequence space: relating Gaussian process priors, regularization, and gauge fixing", "authors": ["Samantha Petti", "Carlos Martí-Gómez", "Justin B. Kinney", "Juannan Zhou", "David M. McCandlish"], "categories": ["cs.LG", "q-bio.GN", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.19034v2", "summary": "Mappings from biological sequences (DNA, RNA, protein) to quantitative\nmeasures of sequence functionality play an important role in contemporary\nbiology. We are interested in the related tasks of (i) inferring predictive\nsequence-to-function maps and (ii) decomposing sequence-function maps to\nelucidate the contributions of individual subsequences. Because each\nsequence-function map can be written as a weighted sum over subsequences in\nmultiple ways, meaningfully interpreting these weights requires \"gauge-fixing,\"\ni.e., defining a unique representation for each map. Recent work has\nestablished that most existing gauge-fixed representations arise as the unique\nsolutions to $L_2$-regularized regression in an overparameterized \"weight\nspace\" where the choice of regularizer defines the gauge. Here, we establish\nthe relationship between regularized regression in overparameterized weight\nspace and Gaussian process approaches that operate in \"function space,\" i.e.\nthe space of all real-valued functions on a finite set of sequences. We\ndisentangle how weight space regularizers both impose an implicit prior on the\nlearned function and restrict the optimal weights to a particular gauge. We\nalso show how to construct regularizers that correspond to arbitrary explicit\nGaussian process priors combined with a wide variety of gauges. Next, we derive\nthe distribution of gauge-fixed weights implied by the Gaussian process\nposterior and demonstrate that even for long sequences this distribution can be\nefficiently computed for product-kernel priors using a kernel trick. Finally,\nwe characterize the implicit function space priors associated with the most\ncommon weight space regularizers. Overall, our framework unifies and extends\nour ability to infer and interpret sequence-function relationships.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.19034v2", "cate": "cs.LG", "date": "2025-04-26", "updated": "2025-07-11"}
{"id": "2507.07521", "title": "Spline Deformation Field", "authors": ["Mingyang Song", "Yang Zhang", "Marko Mihajlovic", "Siyu Tang", "Markus Gross", "Tunç Ozan Aydın"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      SIGGRAPH 2025, Conference track", "url": "http://arxiv.org/abs/2507.07521v2", "summary": "Trajectory modeling of dense points usually employs implicit deformation\nfields, represented as neural networks that map coordinates to relate canonical\nspatial positions to temporal offsets. However, the inductive biases inherent\nin neural networks can hinder spatial coherence in ill-posed scenarios. Current\nmethods focus either on enhancing encoding strategies for deformation fields,\noften resulting in opaque and less intuitive models, or adopt explicit\ntechniques like linear blend skinning, which rely on heuristic-based node\ninitialization. Additionally, the potential of implicit representations for\ninterpolating sparse temporal signals remains under-explored. To address these\nchallenges, we propose a spline-based trajectory representation, where the\nnumber of knots explicitly determines the degrees of freedom. This approach\nenables efficient analytical derivation of velocities, preserving spatial\ncoherence and accelerations, while mitigating temporal fluctuations. To model\nknot characteristics in both spatial and temporal domains, we introduce a novel\nlow-rank time-variant spatial encoding, replacing conventional coupled\nspatiotemporal techniques. Our method demonstrates superior performance in\ntemporal interpolation for fitting continuous fields with sparse inputs.\nFurthermore, it achieves competitive dynamic scene reconstruction quality\ncompared to state-of-the-art methods while enhancing motion coherence without\nrelying on linear blend skinning or as-rigid-as-possible constraints.", "comment": "SIGGRAPH 2025, Conference track", "pdf_url": "http://arxiv.org/pdf/2507.07521v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2503.08893", "title": "EvalTree: Profiling Language Model Weaknesses via Hierarchical Capability Trees", "authors": ["Zhiyuan Zeng", "Yizhong Wang", "Hannaneh Hajishirzi", "Pang Wei Koh"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      COLM 2025", "url": "http://arxiv.org/abs/2503.08893v2", "summary": "An ideal model evaluation should achieve two goals: identifying where the\nmodel fails and providing actionable improvement guidance. Toward these goals\nfor language model (LM) evaluations, we formulate the problem of generating a\nweakness profile, a set of weaknesses expressed in natural language, given an\nLM's performance on every individual instance in a benchmark. We introduce a\nsuite of quantitative assessments to compare different weakness profiling\nmethods. We also introduce a weakness profiling method EvalTree. EvalTree\nconstructs a capability tree where each node represents a capability described\nin natural language and is linked to a subset of benchmark instances that\nspecifically evaluate this capability; it then extracts nodes where the LM\nperforms poorly to generate a weakness profile. On the MATH and WildChat\nbenchmarks, we show that EvalTree outperforms baseline weakness profiling\nmethods by identifying weaknesses more precisely and comprehensively. Weakness\nprofiling further enables weakness-guided data collection, and training data\ncollection guided by EvalTree-identified weaknesses improves LM performance\nmore than other data collection strategies. We also show how EvalTree exposes\nflaws in Chatbot Arena's human-voter-based evaluation practice. To facilitate\nfuture work, we provide an interface that allows practitioners to interactively\nexplore the capability trees built by EvalTree.", "comment": "COLM 2025", "pdf_url": "http://arxiv.org/pdf/2503.08893v2", "cate": "cs.CL", "date": "2025-03-11", "updated": "2025-07-11"}
{"id": "2401.07835", "title": "$q$-ary Sequential Locally Recoverable Codes from the Product Construction", "authors": ["Akram Baghban", "Marc Newman", "Anna-Lena Horlemann", "Mehdi Ghiyasvand"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2401.07835v2", "summary": "This work focuses on sequential locally recoverable codes (SLRCs), a special\nfamily of locally repairable codes, capable of correcting multiple code symbol\nerasures, which are commonly used for distributed storage systems. First, we\nconstruct an extended $q$-ary family of non-binary SLRCs using code products\nwith a novel maximum number of recoverable erasures $t$ and a minimal repair\nalternativity $A$. Second, we study how MDS and BCH codes can be used to\nconstruct $q$-ary SLRCs. Finally, we compare our codes to other LRCs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2401.07835v2", "cate": "cs.IT", "date": "2024-01-15", "updated": "2025-07-11"}
{"id": "2507.08138", "title": "On Conservative Matrix Fields: Continuous Asymptotics and Arithmetic", "authors": ["Shachar Weinbaum", "Elyasheev Leibtag", "Rotem Kalisch", "Michael Shalyt", "Ido Kaminer"], "categories": ["math.NT", "cs.SC", "math.CO", "math.RA", "11J70, 11J82, 40A15, 33C80, 33C70, 68W30"], "primary_category": "Subjects:       Number Theory (math.NT)", "pdf_link": null, "comments": "Comments:      26 pages, 5 figures", "url": "http://arxiv.org/abs/2507.08138v1", "summary": "Ratios of D-finite sequences and their limits -- known as Ap\\'ery limits --\nhave driven much of the work on irrationality proofs since Ap\\'ery's 1979\nbreakthrough proof of the irrationality of $\\zeta(3)$. We extend ratios of\nD-finite sequences to a high-dimensional setting by introducing the\nConservative Matrix Field (CMF). We demonstrate how classical Ap\\'ery limits\nare included by this object as special cases. A useful construction of CMFs is\nprovided, drawing a connection to gauge transformations and to representations\nof shift operators in finite dimensional modules of Ore algebras. Finally,\nnumerical experiments on these objects reveal surprising arithmetic and\ndynamical phenomena, which are formulated into conjectures. If established,\nthese conjectures would extend Poincar\\'e--Perron asymptotics to higher\ndimensions, potentially opening the door to optimization-based searches for new\nirrationality proofs.", "comment": "26 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.08138v1", "cate": "math.NT", "date": "2025-07-10", "updated": "2025-07-10"}
{"id": "2507.07505", "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "authors": ["Varin Sikka", "Vishal Sikka"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      6 pages; to be submitted to AAAI-26 after reviews", "url": "http://arxiv.org/abs/2507.07505v2", "summary": "With widespread adoption of transformer-based language models in AI, there is\nsignificant interest in the limits of LLMs capabilities, specifically so-called\nhallucinations, occurrences in which LLMs provide spurious, factually incorrect\nor nonsensical information when prompted on certain subjects. Furthermore,\nthere is growing interest in agentic uses of LLMs - that is, using LLMs to\ncreate agents that act autonomously or semi-autonomously to carry out various\ntasks, including tasks with applications in the real world. This makes it\nimportant to understand the types of tasks LLMs can and cannot perform. We\nexplore this topic from the perspective of the computational complexity of LLM\ninference. We show that LLMs are incapable of carrying out computational and\nagentic tasks beyond a certain complexity, and further that LLMs are incapable\nof verifying the accuracy of tasks beyond a certain complexity. We present\nexamples of both, then discuss some consequences of this work.", "comment": "6 pages; to be submitted to AAAI-26 after reviews", "pdf_url": "http://arxiv.org/pdf/2507.07505v2", "cate": "cs.CL", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2505.07735", "title": "Assessing the Chemical Intelligence of Large Language Models", "authors": ["Nicholas T. Runcie", "Charlotte M. Deane", "Fergus Imrie"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.07735v2", "summary": "Large Language Models are versatile, general-purpose tools with a wide range\nof applications. Recently, the advent of \"reasoning models\" has led to\nsubstantial improvements in their abilities in advanced problem-solving domains\nsuch as mathematics and software engineering. In this work, we assessed the\nability of reasoning models to perform chemistry tasks directly, without any\nassistance from external tools. We created a novel benchmark, called ChemIQ,\nconsisting of 816 questions assessing core concepts in organic chemistry,\nfocused on molecular comprehension and chemical reasoning. Unlike previous\nbenchmarks, which primarily use multiple choice formats, our approach requires\nmodels to construct short-answer responses, more closely reflecting real-world\napplications. The reasoning models, OpenAI's o3-mini, Google's Gemini Pro 2.5,\nand DeepSeek R1, answered 50%-57% of questions correctly in the highest\nreasoning modes, with higher reasoning levels significantly increasing\nperformance on all tasks. These models substantially outperformed the\nnon-reasoning models which achieved only 3%-7% accuracy. We found that Large\nLanguage Models can now convert SMILES strings to IUPAC names, a task earlier\nmodels were unable to perform. Additionally, we show that the latest reasoning\nmodels can elucidate structures from 1D and 2D 1H and 13C NMR data, with Gemini\nPro 2.5 correctly generating SMILES strings for around 90% of molecules\ncontaining up to 10 heavy atoms, and in one case solving a structure comprising\n25 heavy atoms. For each task, we found evidence that the reasoning process\nmirrors that of a human chemist. Our results demonstrate that the latest\nreasoning models can, in some cases, perform advanced chemical reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.07735v2", "cate": "cs.LG", "date": "2025-05-12", "updated": "2025-07-10"}
{"id": "2507.07620", "title": "ViLU: Learning Vision-Language Uncertainties for Failure Prediction", "authors": ["Marc Lafon", "Yannis Karmim", "Julio Silva-Rodríguez", "Paul Couairon", "Clément Rambour", "Raphaël Fournier-Sniehotta", "Ismail Ben Ayed", "Jose Dolz", "Nicolas Thome"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07620v2", "summary": "Reliable Uncertainty Quantification (UQ) and failure prediction remain open\nchallenges for Vision-Language Models (VLMs). We introduce ViLU, a new\nVision-Language Uncertainty quantification framework that contextualizes\nuncertainty estimates by leveraging all task-relevant textual representations.\nViLU constructs an uncertainty-aware multi-modal representation by integrating\nthe visual embedding, the predicted textual embedding, and an image-conditioned\ntextual representation via cross-attention. Unlike traditional UQ methods based\non loss prediction, ViLU trains an uncertainty predictor as a binary classifier\nto distinguish correct from incorrect predictions using a weighted binary\ncross-entropy loss, making it loss-agnostic. In particular, our proposed\napproach is well-suited for post-hoc settings, where only vision and text\nembeddings are available without direct access to the model itself. Extensive\nexperiments on diverse datasets show the significant gains of our method\ncompared to state-of-the-art failure prediction methods. We apply our method to\nstandard classification datasets, such as ImageNet-1k, as well as large-scale\nimage-caption datasets like CC12M and LAION-400M. Ablation studies highlight\nthe critical role of our architecture and training in achieving effective\nuncertainty quantification. Our code is publicly available and can be found\nhere: https://github.com/ykrmm/ViLU.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07620v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2503.13857", "title": "Enabling Inclusive Systematic Reviews: Incorporating Preprint Articles with Large Language Model-Driven Evaluations", "authors": ["Rui Yang", "Jiayi Tong", "Haoyuan Wang", "Hui Huang", "Ziyang Hu", "Peiyu Li", "Nan Liu", "Christopher J. Lindsell", "Michael J. Pencina", "Yong Chen", "Chuan Hong"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      30 pages, 6 figures", "url": "http://arxiv.org/abs/2503.13857v4", "summary": "Background. Systematic reviews in comparative effectiveness research require\ntimely evidence synthesis. Preprints accelerate knowledge dissemination but\nvary in quality, posing challenges for systematic reviews.\n  Methods. We propose AutoConfidence (automated confidence assessment), an\nadvanced framework for predicting preprint publication, which reduces reliance\non manual curation and expands the range of predictors, including three key\nadvancements: (1) automated data extraction using natural language processing\ntechniques, (2) semantic embeddings of titles and abstracts, and (3) large\nlanguage model (LLM)-driven evaluation scores. Additionally, we employed two\nprediction models: a random forest classifier for binary outcome and a survival\ncure model that predicts both binary outcome and publication risk over time.\n  Results. The random forest classifier achieved AUROC 0.692 with LLM-driven\nscores, improving to 0.733 with semantic embeddings and 0.747 with article\nusage metrics. The survival cure model reached AUROC 0.716 with LLM-driven\nscores, improving to 0.731 with semantic embeddings. For publication risk\nprediction, it achieved a concordance index of 0.658, increasing to 0.667 with\nsemantic embeddings.\n  Conclusion. Our study advances the framework for preprint publication\nprediction through automated data extraction and multiple feature integration.\nBy combining semantic embeddings with LLM-driven evaluations, AutoConfidence\nenhances predictive performance while reducing manual annotation burden. The\nframework has the potential to facilitate incorporation of preprint articles\nduring the appraisal phase of systematic reviews, supporting researchers in\nmore effective utilization of preprint resources.", "comment": "30 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2503.13857v4", "cate": "cs.CL", "date": "2025-03-18", "updated": "2025-07-11"}
{"id": "2405.08352", "title": "Sibson $α$-Mutual Information and Its Variational Representations", "authors": ["Amedeo Roberto Esposito", "Michael Gastpar", "Ibrahim Issa"], "categories": ["cs.IT", "math.IT", "math.PR"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.08352v2", "summary": "Information measures can be constructed from R\\'enyi divergences much like\nmutual information from Kullback-Leibler divergence. One such information\nmeasure is known as Sibson $\\alpha$-mutual information and has received renewed\nattention recently in several contexts: concentration of measure under\ndependence, statistical learning, hypothesis testing, and estimation theory. In\nthis paper, we survey and extend the state of the art. In particular, we\nintroduce variational representations for Sibson $\\alpha$-mutual information\nand employ them in each described context to derive novel results. Namely, we\nproduce generalized Transportation-Cost inequalities and Fano-type\ninequalities. We also present an overview of known applications, spanning from\nlearning theory and Bayesian risk to universal prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.08352v2", "cate": "cs.IT", "date": "2024-05-14", "updated": "2025-07-11"}
{"id": "2507.07532", "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings", "authors": ["Berkant Turan", "Suhrab Asadulla", "David Steinmann", "Wolfgang Stammer", "Sebastian Pokutta"], "categories": ["cs.LG", "cs.AI", "68T01, 68T07", "I.2.6"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 pages, 4 figures, 8 tables, revised references", "url": "http://arxiv.org/abs/2507.07532v2", "summary": "While Prover-Verifier Games (PVGs) offer a promising path toward\nverifiability in nonlinear classification models, they have not yet been\napplied to complex inputs such as high-dimensional images. Conversely, Concept\nBottleneck Models (CBMs) effectively translate such data into interpretable\nconcepts but are limited by their reliance on low-capacity linear predictors.\nIn this work, we introduce the Neural Concept Verifier (NCV), a unified\nframework combining PVGs with concept encodings for interpretable, nonlinear\nclassification in high-dimensional settings. NCV achieves this by utilizing\nrecent minimally supervised concept discovery models to extract structured\nconcept encodings from raw inputs. A prover then selects a subset of these\nencodings, which a verifier -- implemented as a nonlinear predictor -- uses\nexclusively for decision-making. Our evaluations show that NCV outperforms CBM\nand pixel-based PVG classifier baselines on high-dimensional, logically complex\ndatasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV\nas a promising step toward performative, verifiable AI.", "comment": "16 pages, 4 figures, 8 tables, revised references", "pdf_url": "http://arxiv.org/pdf/2507.07532v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2505.17621", "title": "Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration", "authors": ["Jingtong Gao", "Ling Pan", "Yejing Wang", "Rui Zhong", "Chi Lu", "Qingpeng Cai", "Peng Jiang", "Xiangyu Zhao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.17621v3", "summary": "Reinforcement learning (RL) has emerged as a pivotal method for improving the\nreasoning capabilities of Large Language Models (LLMs). However, prevalent RL\napproaches such as Proximal Policy Optimization (PPO) and Group-Regularized\nPolicy Optimization (GRPO) face critical limitations due to their reliance on\nsparse outcome-based rewards and inadequate mechanisms for incentivizing\nexploration. These limitations result in inefficient guidance for multi-step\nreasoning processes. Specifically, sparse reward signals fail to deliver\neffective or sufficient feedback, particularly for challenging problems.\nFurthermore, such reward structures induce systematic biases that prioritize\nexploitation of familiar trajectories over novel solution discovery. These\nshortcomings critically hinder performance in complex reasoning tasks, which\ninherently demand iterative refinement across ipntermediate steps. To address\nthese challenges, we propose an Intrinsic Motivation guidEd exploratioN meThOd\nfoR LLM Reasoning (i-MENTOR), a novel method designed to both deliver dense\nrewards and amplify explorations in the RL-based training paradigm. i-MENTOR\nintroduces three key innovations: trajectory-aware exploration rewards that\nmitigate bias in token-level strategies while maintaining computational\nefficiency; dynamic reward scaling to stabilize exploration and exploitation in\nlarge action spaces; and advantage-preserving reward implementation that\nmaintains advantage distribution integrity while incorporating exploratory\nguidance. Experiments across three public datasets demonstrate i-MENTOR's\neffectiveness with a 22.39% improvement on the difficult dataset Countdown-4.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.17621v3", "cate": "cs.LG", "date": "2025-05-23", "updated": "2025-07-11"}
{"id": "2507.07633", "title": "T-GVC: Trajectory-Guided Generative Video Coding at Ultra-Low Bitrates", "authors": ["Zhitao Wang", "Hengyu Man", "Wenrui Li", "Xingtao Wang", "Xiaopeng Fan", "Debin Zhao"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07633v2", "summary": "Recent advances in video generation techniques have given rise to an emerging\nparadigm of generative video coding, aiming to achieve semantically accurate\nreconstructions in Ultra-Low Bitrate (ULB) scenarios by leveraging strong\ngenerative priors. However, most existing methods are limited by domain\nspecificity (e.g., facial or human videos) or an excessive dependence on\nhigh-level text guidance, which often fails to capture motion details and\nresults in unrealistic reconstructions. To address these challenges, we propose\na Trajectory-Guided Generative Video Coding framework (dubbed T-GVC). T-GVC\nemploys a semantic-aware sparse motion sampling pipeline to effectively bridge\nlow-level motion tracking with high-level semantic understanding by extracting\npixel-wise motion as sparse trajectory points based on their semantic\nimportance, not only significantly reducing the bitrate but also preserving\ncritical temporal semantic information. In addition, by incorporating\ntrajectory-aligned loss constraints into diffusion processes, we introduce a\ntraining-free latent space guidance mechanism to ensure physically plausible\nmotion patterns without sacrificing the inherent capabilities of generative\nmodels. Experimental results demonstrate that our framework outperforms both\ntraditional codecs and state-of-the-art end-to-end video compression methods\nunder ULB conditions. Furthermore, additional experiments confirm that our\napproach achieves more precise motion control than existing text-guided\nmethods, paving the way for a novel direction of generative video coding guided\nby geometric motion modeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07633v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2504.00927", "title": "Multi-Token Attention", "authors": ["Olga Golovneva", "Tianlu Wang", "Jason Weston", "Sainbayar Sukhbaatar"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.00927v2", "summary": "Soft attention is a critical mechanism powering LLMs to locate relevant parts\nwithin a given context. However, individual attention weights are determined by\nthe similarity of only a single query and key token vector. This \"single token\nattention\" bottlenecks the amount of information used in distinguishing a\nrelevant part from the rest of the context. To address this issue, we propose a\nnew attention method, Multi-Token Attention (MTA), which allows LLMs to\ncondition their attention weights on multiple query and key vectors\nsimultaneously. This is achieved by applying convolution operations over\nqueries, keys and heads, allowing nearby queries and keys to affect each\nother's attention weights for more precise attention. As a result, our method\ncan locate relevant context using richer, more nuanced information that can\nexceed a single vector's capacity. Through extensive evaluations, we\ndemonstrate that MTA achieves enhanced performance on a range of popular\nbenchmarks. Notably, it outperforms Transformer baseline models on standard\nlanguage modeling tasks, and on tasks that require searching for information\nwithin long contexts, where our method's ability to leverage richer information\nproves particularly beneficial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.00927v2", "cate": "cs.CL", "date": "2025-04-01", "updated": "2025-07-11"}
{"id": "2507.07668", "title": "Learning Pole Structures of Hadronic States using Predictive Uncertainty Estimation", "authors": ["Felix Frohnert", "Denny Lane B. Sombillo", "Evert van Nieuwenburg", "Patrick Emonts"], "categories": ["hep-ph", "cs.AI", "cs.LG", "hep-ex"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07668v2", "summary": "Matching theoretical predictions to experimental data remains a central\nchallenge in hadron spectroscopy. In particular, the identification of new\nhadronic states is difficult, as exotic signals near threshold can arise from a\nvariety of physical mechanisms. A key diagnostic in this context is the pole\nstructure of the scattering amplitude, but different configurations can produce\nsimilar signatures. The mapping between pole configurations and line shapes is\nespecially ambiguous near the mass threshold, where analytic control is\nlimited. In this work, we introduce an uncertainty-aware machine learning\napproach for classifying pole structures in $S$-matrix elements. Our method is\nbased on an ensemble of classifier chains that provide both epistemic and\naleatoric uncertainty estimates. We apply a rejection criterion based on\npredictive uncertainty, achieving a validation accuracy of nearly $95\\%$ while\ndiscarding only a small fraction of high-uncertainty predictions. Trained on\nsynthetic data with known pole structures, the model generalizes to previously\nunseen experimental data, including enhancements associated with the\n$P_{c\\bar{c}}(4312)^+$ state observed by LHCb. In this, we infer a four-pole\nstructure, representing the presence of a genuine compact pentaquark in the\npresence of a higher channel virtual state pole with non-vanishing width. While\nevaluated on this particular state, our framework is broadly applicable to\nother candidate hadronic states and offers a scalable tool for pole structure\ninference in scattering amplitudes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07668v2", "cate": "hep-ph", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2505.24360", "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "authors": ["Stepan Shabalin", "Ayush Panda", "Dmitrii Kharlapenko", "Abdur Raheem Ali", "Yixiong Hao", "Arthur Conmy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR 2025", "url": "http://arxiv.org/abs/2505.24360v3", "summary": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "comment": "10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR\n  2025", "pdf_url": "http://arxiv.org/pdf/2505.24360v3", "cate": "cs.LG", "date": "2025-05-30", "updated": "2025-07-10"}
{"id": "2507.07722", "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays", "authors": ["Ethan Dack", "Chengliang Dai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07722v2", "summary": "Recent works have revisited the infamous task ``Name That Dataset'',\ndemonstrating that non-medical datasets contain underlying biases and that the\ndataset origin task can be solved with high accuracy. In this work, we revisit\nthe same task applied to popular open-source chest X-ray datasets. Medical\nimages are naturally more difficult to release for open-source due to their\nsensitive nature, which has led to certain open-source datasets being extremely\npopular for research purposes. By performing the same task, we wish to explore\nwhether dataset bias also exists in these datasets. To extend our work, we\napply simple transformations to the datasets, repeat the same task, and perform\nan analysis to identify and explain any detected biases. Given the importance\nof AI applications in medical imaging, it's vital to establish whether modern\nmethods are taking shortcuts or are focused on the relevant pathology. We\nimplement a range of different network architectures on the datasets: NIH,\nCheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more\nexplainable research being performed in medical imaging and the creation of\nmore open-source datasets in the medical domain. Our code can be found here:\nhttps://github.com/eedack01/x_ray_ds_bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07722v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2506.11903", "title": "GeistBERT: Breathing Life into German NLP", "authors": ["Raphael Scheible-Schmitt", "Johann Frei"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11903v4", "summary": "Advances in transformer-based language models have highlighted the benefits\nof language-specific pre-training on high-quality corpora. In this context,\nGerman NLP stands to gain from updated architectures and modern datasets\ntailored to the linguistic characteristics of the German language. GeistBERT\nseeks to improve German language processing by incrementally training on a\ndiverse corpus and optimizing model performance across various NLP tasks. We\npre-trained GeistBERT using fairseq, following the RoBERTa base configuration\nwith Whole Word Masking (WWM), and initialized from GottBERT weights. The model\nwas trained on a 1.3 TB German corpus with dynamic masking and a fixed sequence\nlength of 512 tokens. For evaluation, we fine-tuned the model on standard\ndownstream tasks, including NER (CoNLL 2003, GermEval 2014), text\nclassification (GermEval 2018 coarse/fine, 10kGNAD), and NLI (German XNLI),\nusing $F_1$ score and accuracy as evaluation metrics. GeistBERT achieved strong\nresults across all tasks, leading among base models and setting a new\nstate-of-the-art (SOTA) in GermEval 2018 fine text classification. It also\noutperformed several larger models, particularly in classification benchmarks.\nTo support research in German NLP, we release GeistBERT under the MIT license.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11903v4", "cate": "cs.CL", "date": "2025-06-13", "updated": "2025-07-10"}
{"id": "2506.06489", "title": "Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks", "authors": ["Daniel Kunin", "Giovanni Luca Marchetti", "Feng Chen", "Dhruva Karkada", "James B. Simon", "Michael R. DeWeese", "Surya Ganguli", "Nina Miolane"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      39 pages, 7 figures", "url": "http://arxiv.org/abs/2506.06489v2", "summary": "What features neural networks learn, and how, remains an open question. In\nthis paper, we introduce Alternating Gradient Flows (AGF), an algorithmic\nframework that describes the dynamics of feature learning in two-layer networks\ntrained from small initialization. Prior works have shown that gradient flow in\nthis regime exhibits a staircase-like loss curve, alternating between plateaus\nwhere neurons slowly align to useful directions and sharp drops where neurons\nrapidly grow in norm. AGF approximates this behavior as an alternating two-step\nprocess: maximizing a utility function over dormant neurons and minimizing a\ncost function over active ones. AGF begins with all neurons dormant. At each\nround, a dormant neuron activates, triggering the acquisition of a feature and\na drop in the loss. AGF quantifies the order, timing, and magnitude of these\ndrops, matching experiments across architectures. We show that AGF unifies and\nextends existing saddle-to-saddle analyses in fully connected linear networks\nand attention-only linear transformers, where the learned features are singular\nmodes and principal components, respectively. In diagonal linear networks, we\nprove AGF converges to gradient flow in the limit of vanishing initialization.\nApplying AGF to quadratic networks trained to perform modular addition, we give\nthe first complete characterization of the training dynamics, revealing that\nnetworks learn Fourier features in decreasing order of coefficient magnitude.\nAltogether, AGF offers a promising step towards understanding feature learning\nin neural networks.", "comment": "39 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2506.06489v2", "cate": "cs.LG", "date": "2025-06-06", "updated": "2025-07-11"}
{"id": "2507.07802", "title": "Synergistic Prompting for Robust Visual Recognition with Missing Modalities", "authors": ["Zhihui Zhang", "Luanyuan Dai", "Qika Lin", "Yunfeng Diao", "Guangyin Jin", "Yufei Guo", "Jing Zhang", "Xiaoshuai Hao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07802v2", "summary": "Large-scale multi-modal models have demonstrated remarkable performance\nacross various visual recognition tasks by leveraging extensive paired\nmulti-modal training data. However, in real-world applications, the presence of\nmissing or incomplete modality inputs often leads to significant performance\ndegradation. Recent research has focused on prompt-based strategies to tackle\nthis issue; however, existing methods are hindered by two major limitations:\n(1) static prompts lack the flexibility to adapt to varying missing-data\nconditions, and (2) basic prompt-tuning methods struggle to ensure reliable\nperformance when critical modalities are missing.To address these challenges,\nwe propose a novel Synergistic Prompting (SyP) framework for robust visual\nrecognition with missing modalities. The proposed SyP introduces two key\ninnovations: (I) a Dynamic Adapter, which computes adaptive scaling factors to\ndynamically generate prompts, replacing static parameters for flexible\nmulti-modal adaptation, and (II) a Synergistic Prompting Strategy, which\ncombines static and dynamic prompts to balance information across modalities,\nensuring robust reasoning even when key modalities are missing. The proposed\nSyP achieves significant performance improvements over existing approaches\nacross three widely-used visual recognition datasets, demonstrating robustness\nunder diverse missing rates and conditions. Extensive experiments and ablation\nstudies validate its effectiveness in handling missing modalities, highlighting\nits superior adaptability and reliability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07802v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.05788", "title": "Flippi: End To End GenAI Assistant for E-Commerce", "authors": ["Anand A. Rajasekar", "Praveen Tangarajan", "Anjali Nainani", "Amogh Batwal", "Vinay Rao Dandin", "Anusua Trivedi", "Ozan Ersoy"], "categories": ["cs.CL", "I.2.7; H.3.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 7 tables", "url": "http://arxiv.org/abs/2507.05788v2", "summary": "The emergence of conversational assistants has fundamentally reshaped user\ninteractions with digital platforms. This paper introduces Flippi-a\ncutting-edge, end-to-end conversational assistant powered by large language\nmodels (LLMs) and tailored for the e-commerce sector. Flippi addresses the\nchallenges posed by the vast and often overwhelming product landscape, enabling\ncustomers to discover products more efficiently through natural language\ndialogue. By accommodating both objective and subjective user requirements,\nFlippi delivers a personalized shopping experience that surpasses traditional\nsearch methods. This paper details how Flippi interprets customer queries to\nprovide precise product information, leveraging advanced NLP techniques such as\nQuery Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG),\nNamed Entity Recognition (NER), and Context Reduction. Flippi's unique\ncapability to identify and present the most attractive offers on an e-commerce\nsite is also explored, demonstrating how it empowers users to make\ncost-effective decisions. Additionally, the paper discusses Flippi's\ncomparative analysis features, which help users make informed choices by\ncontrasting product features, prices, and other relevant attributes. The\nsystem's robust architecture is outlined, emphasizing its adaptability for\nintegration across various e-commerce platforms and the technological choices\nunderpinning its performance and accuracy. Finally, a comprehensive evaluation\nframework is presented, covering performance metrics, user satisfaction, and\nthe impact on customer engagement and conversion rates. By bridging the\nconvenience of online shopping with the personalized assistance traditionally\nfound in physical stores, Flippi sets a new standard for customer satisfaction\nand engagement in the digital marketplace.", "comment": "10 pages, 2 figures, 7 tables", "pdf_url": "http://arxiv.org/pdf/2507.05788v2", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-11"}
{"id": "2506.18247", "title": "Exploring Efficient Quantification of Modeling Uncertainties with Differentiable Physics-Informed Machine Learning Architectures", "authors": ["Manaswin Oddiraju", "Bharath Varma Penumatsa", "Divyang Amin", "Michael Piedmonte", "Souma Chowdhury"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for presentation in proceedings of ASME IDETC 2025", "url": "http://arxiv.org/abs/2506.18247v2", "summary": "Quantifying and propagating modeling uncertainties is crucial for reliability\nanalysis, robust optimization, and other model-based algorithmic processes in\nengineering design and control. Now, physics-informed machine learning (PIML)\nmethods have emerged in recent years as a new alternative to traditional\ncomputational modeling and surrogate modeling methods, offering a balance\nbetween computing efficiency, modeling accuracy, and interpretability. However,\ntheir ability to predict and propagate modeling uncertainties remains mostly\nunexplored. In this paper, a promising class of auto-differentiable hybrid PIML\narchitectures that combine partial physics and neural networks or ANNs (for\ninput transformation or adaptive parameter estimation) is integrated with\nBayesian Neural networks (replacing the ANNs); this is done with the goal to\nexplore whether BNNs can successfully provision uncertainty propagation\ncapabilities in the PIML architectures as well, further supported by the\nauto-differentiability of these architectures. A two-stage training process is\nused to alleviate the challenges traditionally encountered in training\nprobabilistic ML models. The resulting BNN-integrated PIML architecture is\nevaluated on an analytical benchmark problem and flight experiments data for a\nfixed-wing RC aircraft, with prediction performance observed to be slightly\nworse or at par with purely data-driven ML and original PIML models. Moreover,\nMonte Carlo sampling of probabilistic BNN weights was found to be most\neffective in propagating uncertainty in the BNN-integrated PIML architectures.", "comment": "Accepted for presentation in proceedings of ASME IDETC 2025", "pdf_url": "http://arxiv.org/pdf/2506.18247v2", "cate": "cs.LG", "date": "2025-06-23", "updated": "2025-07-11"}
{"id": "2507.07878", "title": "Single-Step Latent Diffusion for Underwater Image Restoration", "authors": ["Jiayi Wu", "Tianfu Wang", "Md Abu Bakr Siddique", "Md Jahidul Islam", "Cornelia Fermuller", "Yiannis Aloimonos", "Christopher A. Metzler"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07878v2", "summary": "Underwater image restoration algorithms seek to restore the color, contrast,\nand appearance of a scene that is imaged underwater. They are a critical tool\nin applications ranging from marine ecology and aquaculture to underwater\nconstruction and archaeology. While existing pixel-domain diffusion-based image\nrestoration approaches are effective at restoring simple scenes with limited\ndepth variation, they are computationally intensive and often generate\nunrealistic artifacts when applied to scenes with complex geometry and\nsignificant depth variation. In this work we overcome these limitations by\ncombining a novel network architecture (SLURPP) with an accurate synthetic data\ngeneration pipeline. SLURPP combines pretrained latent diffusion models --\nwhich encode strong priors on the geometry and depth of scenes -- with an\nexplicit scene decomposition -- which allows one to model and account for the\neffects of light attenuation and backscattering. To train SLURPP we design a\nphysics-based underwater image synthesis pipeline that applies varied and\nrealistic underwater degradation effects to existing terrestrial image\ndatasets. This approach enables the generation of diverse training data with\ndense medium/degradation annotations. We evaluate our method extensively on\nboth synthetic and real-world benchmarks and demonstrate state-of-the-art\nperformance. Notably, SLURPP is over 200X faster than existing diffusion-based\nmethods while offering ~ 3 dB improvement in PSNR on synthetic benchmarks. It\nalso offers compelling qualitative improvements on real-world data. Project\nwebsite https://tianfwang.github.io/slurpp/.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07878v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.06565", "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "authors": ["Juan B. Gutiérrez"], "categories": ["cs.CL", "cs.LG", "68T01, 60J10, 91D30, 05C82, 68T50, 68W20, 94A15", "I.2.7; I.2.11; G.3"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      27 pages, 3 figures, 4 tables, 1 algorithm, 48 references", "url": "http://arxiv.org/abs/2507.06565v2", "summary": "Large-language models turn writing into a live exchange between humans and\nsoftware. We capture this new medium with a discursive-network model that\ntreats people and LLMs as equal nodes and tracks how their statements\ncirculate. Broadening the focus from isolated hallucinations, we define\ninvalidation (any factual, logical, or structural breach) and show it follows\nfour hazards: drift from truth, self-repair, fresh fabrication, and external\ndetection. A general mathematical model of discursive networks is developed to\nprovide valuable insights: A network governed only by drift and self-repair\nstabilizes at a modest error rate; adding fabrication reproduces the high rates\nseen in current LLMs. Giving each false claim even a small chance of peer\nreview shifts the system to a truth-dominant state. We operationalize peer\nreview with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a\nconfigurable loop in which any set of agents critique one another while a\nharmoniser merges their verdicts. The takeaway is practical and cultural:\nreliability in this new medium comes not from perfecting single models but from\nwiring imperfect ones into networks that keep each other honest.", "comment": "27 pages, 3 figures, 4 tables, 1 algorithm, 48 references", "pdf_url": "http://arxiv.org/pdf/2507.06565v2", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-10"}
{"id": "2506.19703", "title": "Learning-aided Bigraph Matching Approach to Multi-Crew Restoration of Damaged Power Networks Coupled with Road Transportation Networks", "authors": ["Nathan Maurer", "Harshal Kaushik", "Roshni Anna Jacob", "Jie Zhang", "Souma Chowdhury"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted for presentation in proceedings of ASME IDETC 2025", "url": "http://arxiv.org/abs/2506.19703v2", "summary": "The resilience of critical infrastructure networks (CINs) after disruptions,\nsuch as those caused by natural hazards, depends on both the speed of\nrestoration and the extent to which operational functionality can be regained.\nAllocating resources for restoration is a combinatorial optimal planning\nproblem that involves determining which crews will repair specific network\nnodes and in what order. This paper presents a novel graph-based formulation\nthat merges two interconnected graphs, representing crew and transportation\nnodes and power grid nodes, into a single heterogeneous graph. To enable\nefficient planning, graph reinforcement learning (GRL) is integrated with\nbigraph matching. GRL is utilized to design the incentive function for\nassigning crews to repair tasks based on the graph-abstracted state of the\nenvironment, ensuring generalization across damage scenarios. Two learning\ntechniques are employed: a graph neural network trained using Proximal Policy\nOptimization and another trained via Neuroevolution. The learned incentive\nfunctions inform a bipartite graph that links crews to repair tasks, enabling\nweighted maximum matching for crew-to-task allocations. An efficient simulation\nenvironment that pre-computes optimal node-to-node path plans is used to train\nthe proposed restoration planning methods. An IEEE 8500-bus power distribution\ntest network coupled with a 21 square km transportation network is used as the\ncase study, with scenarios varying in terms of numbers of damaged nodes,\ndepots, and crews. Results demonstrate the approach's generalizability and\nscalability across scenarios, with learned policies providing 3-fold better\nperformance than random policies, while also outperforming optimization-based\nsolutions in both computation time (by several orders of magnitude) and power\nrestored.", "comment": "Accepted for presentation in proceedings of ASME IDETC 2025", "pdf_url": "http://arxiv.org/pdf/2506.19703v2", "cate": "cs.LG", "date": "2025-06-24", "updated": "2025-07-11"}
{"id": "2507.07994", "title": "Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection", "authors": ["Subhajit Maity", "Ayan Kumar Bhunia", "Subhadeep Koley", "Pinaki Nath Chowdhury", "Aneeshan Sain", "Yi-Zhe Song"], "categories": ["cs.CV", "I.4.0; I.4.9"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2507.07994v2", "summary": "Keypoint detection, integral to modern machine perception, faces challenges\nin few-shot learning, particularly when source data from the same distribution\nas the query is unavailable. This gap is addressed by leveraging sketches, a\npopular form of human expression, providing a source-free alternative. However,\nchallenges arise in mastering cross-modal embeddings and handling user-specific\nsketch styles. Our proposed framework overcomes these hurdles with a\nprototypical setup, combined with a grid-based locator and prototypical domain\nadaptation. We also demonstrate success in few-shot convergence across novel\nkeypoints and classes through extensive experiments.", "comment": "Accepted at ICCV 2025. Project Page: https://subhajitmaity.me/DYKp", "pdf_url": "http://arxiv.org/pdf/2507.07994v2", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2507.07248", "title": "Medical Red Teaming Protocol of Language Models: On the Importance of User Perspectives in Healthcare Settings", "authors": ["Jean-Philippe Corbeil", "Minseon Kim", "Alessandro Sordoni", "Francois Beaulieu", "Paul Vozila"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07248v2", "summary": "As the performance of large language models (LLMs) continues to advance,\ntheir adoption is expanding across a wide range of domains, including the\nmedical field. The integration of LLMs into medical applications raises\ncritical safety concerns, particularly due to their use by users with diverse\nroles, e.g. patients and clinicians, and the potential for model's outputs to\ndirectly affect human health. Despite the domain-specific capabilities of\nmedical LLMs, prior safety evaluations have largely focused only on general\nsafety benchmarks. In this paper, we introduce a safety evaluation protocol\ntailored to the medical domain in both patient user and clinician user\nperspectives, alongside general safety assessments and quantitatively analyze\nthe safety of medical LLMs. We bridge a gap in the literature by building the\nPatientSafetyBench containing 466 samples over 5 critical categories to measure\nsafety from the perspective of the patient. We apply our red-teaming protocols\non the MediPhi model collection as a case study. To our knowledge, this is the\nfirst work to define safety evaluation criteria for medical LLMs through\ntargeted red-teaming taking three different points of view - patient,\nclinician, and general user - establishing a foundation for safer deployment in\nmedical domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07248v2", "cate": "cs.CL", "date": "2025-07-09", "updated": "2025-07-11"}
{"id": "2506.21940", "title": "Sculpting Quantum Landscapes: Fubini-Study Metric Conditioning for Geometry Aware Learning in Parameterized Quantum Circuits", "authors": ["Marwan Ait Haddou", "Mohamed Bennai"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Need more analysis", "url": "http://arxiv.org/abs/2506.21940v3", "summary": "We present a novel meta learning framework called Sculpture that explicitly\nconditions the Fubini Study metric tensor of parameterized quantum circuits to\nmitigate barren plateaus in variational quantum algorithms. Our theoretical\nanalysis identifies the logarithmic condition number of the Fubini Study metric\nas a critical geometric quantity governing trainability, optimization dynamics,\nand generalization. Sculpture uses a classical meta model trained to generate\ndata dependent quantum circuit initializations that minimize the logarithmic\ncondition number, thereby promoting an isotropic and well conditioned parameter\nspace.\n  Empirical results show that meta training reduces the logarithmic condition\nnumber from approximately 1.47 to 0.64 by significantly increasing the minimum\neigenvalue and slightly decreasing the maximum eigenvalue of the metric,\neffectively alleviating barren plateaus. This improved conditioning generalizes\nwell to unseen data, consistently producing well conditioned quantum circuit\ninitializations. In a downstream hybrid quantum classical classification task\non the Kaggle diabetes dataset, increasing the meta scaling coefficient\naccelerates convergence, reduces training loss and gradient norms, and\ncrucially improves generalization, with test accuracy increasing from about\n0.68 to over 0.78. These findings demonstrate that sculpting the quantum\nlandscape via meta learning serves as a principled geometric regularizer,\nsubstantially enhancing trainability, optimization, and generalization of\nparameterized quantum circuits and enabling more robust and efficient\nvariational quantum algorithms.", "comment": "Need more analysis", "pdf_url": "http://arxiv.org/pdf/2506.21940v3", "cate": "cs.LG", "date": "2025-06-27", "updated": "2025-07-11"}
{"id": "2506.23182", "title": "Attribution assignment for deep-generative sequence models enables interpretability analysis using positive-only data", "authors": ["Robert Frank", "Michael Widrich", "Rahmad Akbar", "Günter Klambauer", "Geir Kjetil Sandve", "Philippe A. Robert", "Victor Greiff"], "categories": ["cs.LG", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23182v2", "summary": "Generative machine learning models offer a powerful framework for therapeutic\ndesign by efficiently exploring large spaces of biological sequences enriched\nfor desirable properties. Unlike supervised learning methods, which require\nboth positive and negative labeled data, generative models such as LSTMs can be\ntrained solely on positively labeled sequences, for example, high-affinity\nantibodies. This is particularly advantageous in biological settings where\nnegative data are scarce, unreliable, or biologically ill-defined. However, the\nlack of attribution methods for generative models has hindered the ability to\nextract interpretable biological insights from such models. To address this\ngap, we developed Generative Attribution Metric Analysis (GAMA), an attribution\nmethod for autoregressive generative models based on Integrated Gradients. We\nassessed GAMA using synthetic datasets with known ground truths to characterize\nits statistical behavior and validate its ability to recover biologically\nrelevant features. We further demonstrated the utility of GAMA by applying it\nto experimental antibody-antigen binding data. GAMA enables model\ninterpretability and the validation of generative sequence design strategies\nwithout the need for negative training data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23182v2", "cate": "cs.LG", "date": "2025-06-29", "updated": "2025-07-11"}
{"id": "2507.03631", "title": "Scientific Machine Learning of Chaotic Systems Discovers Governing Equations for Neural Populations", "authors": ["Anthony G. Chesebro", "David Hofmann", "Vaibhav Dixit", "Earl K. Miller", "Richard H. Granger", "Alan Edelman", "Christopher V. Rackauckas", "Lilianne R. Mujica-Parodi", "Helmut H. Strey"], "categories": ["cs.LG", "math-ph", "math.MP", "nlin.CD", "q-bio.NC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      46 pages, 9 figures", "url": "http://arxiv.org/abs/2507.03631v2", "summary": "Discovering governing equations that describe complex chaotic systems remains\na fundamental challenge in physics and neuroscience. Here, we introduce the\nPEM-UDE method, which combines the prediction-error method with universal\ndifferential equations to extract interpretable mathematical expressions from\nchaotic dynamical systems, even with limited or noisy observations. This\napproach succeeds where traditional techniques fail by smoothing optimization\nlandscapes and removing the chaotic properties during the fitting process\nwithout distorting optimal parameters. We demonstrate its efficacy by\nrecovering hidden states in the Rossler system and reconstructing dynamics from\nnoise-corrupted electrical circuit data, where the correct functional form of\nthe dynamics is recovered even when one of the observed time series is\ncorrupted by noise 5x the magnitude of the true signal. We demonstrate that\nthis method is capable of recovering the correct dynamics, whereas direct\nsymbolic regression methods, such as SINDy, fail to do so with the given amount\nof data and noise. Importantly, when applied to neural populations, our method\nderives novel governing equations that respect biological constraints such as\nnetwork sparsity - a constraint necessary for cortical information processing\nyet not captured in next-generation neural mass models - while preserving\nmicroscale neuronal parameters. These equations predict an emergent\nrelationship between connection density and both oscillation frequency and\nsynchrony in neural circuits. We validate these predictions using three\nintracranial electrode recording datasets from the medial entorhinal cortex,\nprefrontal cortex, and orbitofrontal cortex. Our work provides a pathway to\ndevelop mechanistic, multi-scale brain models that generalize across diverse\nneural architectures, bridging the gap between single-neuron dynamics and\nmacroscale brain activity.", "comment": "46 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.03631v2", "cate": "cs.LG", "date": "2025-07-04", "updated": "2025-07-10"}
{"id": "2507.04196", "title": "Predicting Air Pollution in Cork, Ireland Using Machine Learning", "authors": ["Md Rashidunnabi", "Fahmida Faiza Ananna", "Kailash Hambarde", "Bruno Gabriel Nascimento Andrade", "Dean Venables", "Hugo Proenca"], "categories": ["cs.LG", "stat.AP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The draft was submitted prematurely and requires further analysis, added research findings, and corrected references. Some co-authors have not yet approved this version. I will ensure all necessary revisions and approvals before resubmitting", "url": "http://arxiv.org/abs/2507.04196v2", "summary": "Air pollution poses a critical health threat in cities worldwide, with\nnitrogen dioxide levels in Cork, Ireland exceeding World Health Organization\nsafety standards by up to $278\\%$. This study leverages artificial intelligence\nto predict air pollution with unprecedented accuracy, analyzing nearly ten\nyears of data from five monitoring stations combined with 30 years of weather\nrecords. We evaluated 17 machine learning algorithms, with Extra Trees emerging\nas the optimal solution, achieving $77\\%$ prediction accuracy and significantly\noutperforming traditional forecasting methods. Our analysis reveals that\nmeteorological conditions particularly temperature, wind speed, and humidity\nare the primary drivers of pollution levels, while traffic patterns and\nseasonal changes create predictable pollution cycles. Pollution exhibits\ndramatic seasonal variations, with winter levels nearly double those of summer,\nand daily rush-hour peaks reaching $120\\%$ above normal levels. While Cork's\nair quality shows concerning violations of global health standards, our models\ndetected an encouraging $31\\%$ improvement from 2014 to 2022. This research\ndemonstrates that intelligent forecasting systems can provide city planners and\nenvironmental officials with powerful prediction tools, enabling life-saving\nearly warning systems and informed urban planning decisions. The technology\nexists today to transform urban air quality management. All research materials\nand code are freely available at:\nhttps://github.com/MdRashidunnabi/Air-Pollution-Analysis.git", "comment": "The draft was submitted prematurely and requires further analysis,\n  added research findings, and corrected references. Some co-authors have not\n  yet approved this version. I will ensure all necessary revisions and\n  approvals before resubmitting", "pdf_url": "http://arxiv.org/pdf/2507.04196v2", "cate": "cs.LG", "date": "2025-07-06", "updated": "2025-07-11"}
{"id": "2507.07883", "title": "SAMO: A Lightweight Sharpness-Aware Approach for Multi-Task Optimization with Joint Global-Local Perturbation", "authors": ["Hao Ban", "Gokul Ram Subramani", "Kaiyi Ji"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.07883v2", "summary": "Multi-task learning (MTL) enables a joint model to capture commonalities\nacross multiple tasks, reducing computation costs and improving data\nefficiency. However, a major challenge in MTL optimization is task conflicts,\nwhere the task gradients differ in direction or magnitude, limiting model\nperformance compared to single-task counterparts. Sharpness-aware minimization\n(SAM) minimizes task loss while simultaneously reducing the sharpness of the\nloss landscape. Our empirical observations show that SAM effectively mitigates\ntask conflicts in MTL. Motivated by these findings, we explore integrating SAM\ninto MTL but face two key challenges. While both the average loss gradient and\nindividual task gradients-referred to as global and local\ninformation-contribute to SAM, how to combine them remains unclear. Moreover,\ndirectly computing each task gradient introduces significant computational and\nmemory overheads. To address these challenges, we propose SAMO, a lightweight\n\\textbf{S}harpness-\\textbf{A}ware \\textbf{M}ulti-task \\textbf{O}ptimization\napproach, that leverages a joint global-local perturbation. The local\nperturbations are approximated using only forward passes and are layerwise\nnormalized to improve efficiency. Extensive experiments on a suite of\nmulti-task benchmarks demonstrate both the effectiveness and efficiency of our\nmethod. Code is available at https://github.com/OptMN-Lab/SAMO.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.07883v2", "cate": "cs.LG", "date": "2025-07-10", "updated": "2025-07-11"}
{"id": "2403.17285", "title": "Unraveling the Interplay between Carryover Effects and Reward Autocorrelations in Switchback Experiments", "authors": ["Qianglin Wen", "Chengchun Shi", "Yang Ying", "Niansheng Tang", "Hongtu Zhu"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.17285v5", "summary": "A/B testing has become the gold standard for policy evaluation in modern\ntechnological industries. Motivated by the widespread use of switchback\nexperiments in A/B testing, this paper conducts a comprehensive comparative\nanalysis of various switchback designs in Markovian environments. Unlike many\nexisting works which derive the optimal design based on specific and relatively\nsimple estimators, our analysis covers a range of state-of-the-art estimators\ndeveloped in the reinforcement learning (RL) literature. It reveals that the\neffectiveness of different switchback designs depends crucially on (i) the size\nof the carryover effect and (ii) the auto-correlations among reward errors over\ntime. Meanwhile, these findings are estimator-agnostic, i.e., they apply to\nmost RL estimators. Based on these insights, we provide a workflow to offer\nguidelines for practitioners on designing switchback experiments in A/B\ntesting.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.17285v5", "cate": "stat.ML", "date": "2024-03-26", "updated": "2025-07-11"}
{"id": "2410.02548", "title": "Local Flow Matching Generative Models", "authors": ["Chen Xu", "Xiuyuan Cheng", "Yao Xie"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.02548v3", "summary": "Flow Matching (FM) is a simulation-free method for learning a continuous and\ninvertible flow to interpolate between two distributions, and in particular to\ngenerate data from noise. Inspired by the variational nature of the diffusion\nprocess as a gradient flow, we introduce a stepwise FM model called Local Flow\nMatching (LFM), which consecutively learns a sequence of FM sub-models, each\nmatching a diffusion process up to the time of the step size in the\ndata-to-noise direction. In each step, the two distributions to be interpolated\nby the sub-flow model are closer to each other than data vs. noise, and this\nenables the use of smaller models with faster training. This variational\nperspective also allows us to theoretically prove a generation guarantee of the\nproposed flow model in terms of the $\\chi^2$-divergence between the generated\nand true data distributions, utilizing the contraction property of the\ndiffusion process. In practice, the stepwise structure of LFM is natural to be\ndistilled and different distillation techniques can be adopted to speed up\ngeneration. We empirically demonstrate improved training efficiency and\ncompetitive generative performance of LFM compared to FM on the unconditional\ngeneration of tabular data and image datasets, and also on the conditional\ngeneration of robotic manipulation policies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.02548v3", "cate": "stat.ML", "date": "2024-10-03", "updated": "2025-07-11"}
{"id": "2410.02857", "title": "Reconstructing Galaxy Cluster Mass Maps using Score-based Generative Modeling", "authors": ["Alan Hsu", "Matthew Ho", "Joyce Lin", "Carleen Markey", "Michelle Ntampaka", "Hy Trac", "Barnabás Póczos"], "categories": ["astro-ph.CO", "cs.LG"], "primary_category": "Subjects:       Cosmology and Nongalactic Astrophysics (astro-ph.CO)", "pdf_link": null, "comments": "Comments:      Published in the Open Journal of Astrophysics", "url": "http://arxiv.org/abs/2410.02857v2", "summary": "We present a novel approach to reconstruct gas and dark matter projected\ndensity maps of galaxy clusters using score-based generative modeling. Our\ndiffusion model takes in mock SZ and X-ray images as conditional inputs, and\ngenerates realizations of corresponding gas and dark matter maps by sampling\nfrom a learned data posterior. We train and validate the performance of our\nmodel by using mock data from a cosmological simulation. The model accurately\nreconstructs both the mean and spread of the radial density profiles in the\nspatial domain, indicating that the model is able to distinguish between\nclusters of different mass sizes. In the spectral domain, the model achieves\nclose-to-unity values for the bias and cross-correlation coefficients,\nindicating that the model can accurately probe cluster structures on both large\nand small scales. Our experiments demonstrate the ability of score models to\nlearn a strong, nonlinear, and unbiased mapping between input observables and\nfundamental density distributions of galaxy clusters. These diffusion models\ncan be further fine-tuned and generalized to not only take in additional\nobservables as inputs, but also real observations and predict unknown density\ndistributions of galaxy clusters.", "comment": "Published in the Open Journal of Astrophysics", "pdf_url": "http://arxiv.org/pdf/2410.02857v2", "cate": "astro-ph.CO", "date": "2024-10-03", "updated": "2025-07-10"}
{"id": "2410.12690", "title": "Local transfer learning Gaussian process modeling, with applications to surrogate modeling of expensive computer simulators", "authors": ["Xinming Wang", "Simon Mak", "John Miller", "Jianguo Wu"], "categories": ["stat.ML", "cs.LG", "stat.AP", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.12690v3", "summary": "A critical bottleneck for scientific progress is the costly nature of\ncomputer simulations for complex systems. Surrogate models provide an appealing\nsolution: such models are trained on simulator evaluations, then used to\nemulate and quantify uncertainty on the expensive simulator at unexplored\ninputs. In many applications, one often has available data on related systems.\nFor example, in designing a new jet turbine, there may be existing studies on\nturbines with similar configurations. A key question is how information from\nsuch ``source'' systems can be transferred for effective surrogate training on\nthe ``target'' system of interest. We thus propose a new LOcal transfer\nLearning Gaussian Process (LOL-GP) model, which leverages a carefully-designed\nGaussian process to transfer such information for surrogate modeling. The key\nnovelty of the LOL-GP is a latent regularization model, which identifies\nregions where transfer should be performed and regions where it should be\navoided. Such a ``local transfer'' property is present in many scientific\nsystems: at certain parameters, systems may behave similarly and thus transfer\nis beneficial; at other parameters, they may behave differently and thus\ntransfer is detrimental. By accounting for local transfer, the LOL-GP can\ntemper the risk of ``negative transfer'', i.e., the risk of worsening\npredictive performance from information transfer. We derive a Gibbs sampling\nalgorithm for efficient posterior predictive sampling on the LOL-GP, for both\nthe multi-source and multi-fidelity transfer settings. We then show, via a\nsuite of numerical experiments and an application for jet turbine design, the\nimproved surrogate performance of the LOL-GP over existing methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.12690v3", "cate": "stat.ML", "date": "2024-10-16", "updated": "2025-07-11"}
{"id": "2410.20289", "title": "On the Gaussian process limit of Bayesian Additive Regression Trees", "authors": ["Giacomo Petrillo"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Check out the software at this https URL", "url": "http://arxiv.org/abs/2410.20289v2", "summary": "Bayesian Additive Regression Trees (BART) is a nonparametric Bayesian\nregression technique of rising fame. It is a sum-of-decision-trees model, and\nis in some sense the Bayesian version of boosting. In the limit of infinite\ntrees, it becomes equivalent to Gaussian process (GP) regression. This limit is\nknown but has not yet led to any useful analysis or application. For the first\ntime, I derive and compute the exact BART prior covariance function. With it I\nimplement the infinite trees limit of BART as GP regression. Through empirical\ntests, I show that this limit is worse than standard BART in a fixed\nconfiguration, but also that tuning its hyperparameters in the natural GP way\nmakes it competitive with BART. The advantage of using a GP surrogate of BART\nis the analytical likelihood, which simplifies model building and sidesteps the\ncomplex BART MCMC algorithm. More generally, this study opens new ways to\nunderstand and develop BART and GP regression. The implementation of BART as GP\nis available in the Python package lsqfitgp.", "comment": "Check out the software at https://github.com/Gattocrucco/lsqfitgp", "pdf_url": "http://arxiv.org/pdf/2410.20289v2", "cate": "stat.ML", "date": "2024-10-26", "updated": "2025-07-11"}
{"id": "2411.09686", "title": "Conditional regression for the Nonlinear Single-Variable Model", "authors": ["Yantao Wu", "Mauro Maggioni"], "categories": ["stat.ML", "cs.LG", "62G08"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      57 pages, 10 figures", "url": "http://arxiv.org/abs/2411.09686v2", "summary": "Regressing a function $F$ on $\\mathbb{R}^d$ without the statistical and\ncomputational curse of dimensionality requires special statistical models, for\nexample that impose geometric assumptions on the distribution of the data\n(e.g., that its support is low-dimensional), or strong smoothness assumptions\non $F$, or a special structure $F$. Among the latter, compositional models\n$F=f\\circ g$ with $g$ mapping to $\\mathbb{R}^r$ with $r\\ll d$ include classical\nsingle- and multi-index models, as well as neural networks. While the case\nwhere $g$ is linear is well-understood, less is known when $g$ is nonlinear,\nand in particular for which $g$'s the curse of dimensionality in estimating\n$F$, or both $f$ and $g$, may be circumvented. Here we consider a model\n$F(X):=f(\\Pi_\\gamma X)$ where\n$\\Pi_\\gamma:\\mathbb{R}^d\\to[0,\\textrm{len}_\\gamma]$ is the closest-point\nprojection onto the parameter of a regular curve $\\gamma:[0,\n\\textrm{len}_\\gamma]\\to\\mathbb{R}^d$, and $f:[0,\\textrm{len}_\\gamma]\\to\n\\mathbb{R}^1$. The input data $X$ is not low-dimensional: it can be as far from\n$\\gamma$ as the condition that $\\Pi_\\gamma(X)$ is well-defined allows. The\ndistribution $X$, the curve $\\gamma$ and the function $f$ are all unknown. This\nmodel is a natural nonlinear generalization of the single-index model,\ncorresponding to $\\gamma$ being a line. We propose a nonparametric estimator,\nbased on conditional regression, that under suitable assumptions, the strongest\nof which being that $f$ is coarsely monotone, achieves, up to log factors, the\n$\\textit{one-dimensional}$ optimal min-max rate for non-parametric regression,\nup to the level of noise in the observations, and be constructed in time\n$\\mathcal{O}(d^2 n\\log n)$. All the constants in the learning bounds, in the\nminimal number of samples required for our bounds to hold, and in the\ncomputational complexity are at most low-order polynomials in $d$.", "comment": "57 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2411.09686v2", "cate": "stat.ML", "date": "2024-11-14", "updated": "2025-07-11"}
{"id": "2501.08202", "title": "Data-driven system identification using quadratic embeddings of nonlinear dynamics", "authors": ["Stefan Klus", "Joel-Pascal Ntwali N'konzi"], "categories": ["math.DS", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Dynamical Systems (math.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.08202v2", "summary": "We propose a novel data-driven method called QENDy (Quadratic Embedding of\nNonlinear Dynamics) that not only allows us to learn quadratic representations\nof highly nonlinear dynamical systems, but also to identify the governing\nequations. The approach is based on an embedding of the system into a\nhigher-dimensional feature space in which the dynamics become quadratic. Just\nlike SINDy (Sparse Identification of Nonlinear Dynamics), our method requires\ntrajectory data, time derivatives for the training data points, which can also\nbe estimated using finite difference approximations, and a set of preselected\nbasis functions, called dictionary. We illustrate the efficacy and accuracy of\nQENDy with the aid of various benchmark problems and compare its performance\nwith SINDy and a deep learning method for identifying quadratic embeddings.\nFurthermore, we analyze the convergence of QENDy and SINDy in the infinite data\nlimit, highlight their similarities and main differences, and compare the\nquadratic embedding with linearization techniques based on the Koopman\noperator.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.08202v2", "cate": "math.DS", "date": "2025-01-14", "updated": "2025-07-11"}
{"id": "2503.02494", "title": "Enhancing Distributional Robustness in Principal Component Analysis by Wasserstein Distances", "authors": ["Lei Wang", "Xin Liu", "Xiaojun Chen"], "categories": ["math.OC", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02494v2", "summary": "We consider the distributionally robust optimization (DRO) model of principal\ncomponent analysis (PCA) to account for uncertainty in the underlying\nprobability distribution. The resulting formulation leads to a nonsmooth\nconstrained min-max optimization problem, where the ambiguity set captures the\ndistributional uncertainty by the type-$2$ Wasserstein distance. We prove that\nthe inner maximization problem admits a closed-form optimal value. This\nexplicit characterization equivalently reformulates the original DRO model into\na minimization problem on the Stiefel manifold with intricate nonsmooth terms,\na challenging formulation beyond the reach of existing algorithms. To address\nthis issue, we devise an efficient smoothing manifold proximal gradient\nalgorithm. Our analysis establishes Riemannian gradient consistency and global\nconvergence of our algorithm to a stationary point of the nonsmooth\nminimization problem. We also provide the iteration complexity\n$O(\\epsilon^{-3})$ of our algorithm to achieve an $\\epsilon$-approximate\nstationary point. Finally, numerical experiments are conducted to validate the\neffectiveness and scalability of our algorithm, as well as to highlight the\nnecessity and rationality of adopting the DRO model for PCA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02494v2", "cate": "math.OC", "date": "2025-03-04", "updated": "2025-07-11"}
{"id": "2503.02870", "title": "Multiaccuracy and Multicalibration via Proxy Groups", "authors": ["Beepul Bharti", "Mary Versa Clemens-Sewall", "Paul H. Yi", "Jeremias Sulam"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.02870v3", "summary": "As the use of predictive machine learning algorithms increases in high-stakes\ndecision-making, it is imperative that these algorithms are fair across\nsensitive groups. However, measuring and enforcing fairness in real-world\napplications can be challenging due to the missing or incomplete sensitive\ngroup information. Proxy-sensitive attributes have been proposed as a practical\nand effective solution in these settings, but only for parity-based fairness\nnotions. Knowing how to evaluate and control for fairness with missing\nsensitive group data for newer, different, and more flexible frameworks, such\nas multiaccuracy and multicalibration, remain unexplored. In this work, we\naddress this gap by demonstrating that in the absence of sensitive group data,\nproxy-sensitive attributes can provably used to derive actionable upper bounds\non the true multiaccuracy and multicalibration violations, providing insights\ninto a predictive model's potential worst-case fairness violations.\nAdditionally, we show that adjusting models to satisfy multiaccuracy and\nmulticalibration across proxy-sensitive attributes can significantly mitigate\nthese violations for the true, but unknown, sensitive groups. Through several\nexperiments on real-world datasets, we illustrate that approximate\nmultiaccuracy and multicalibration can be achieved even when sensitive group\ndata is incomplete or unavailable.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.02870v3", "cate": "stat.ML", "date": "2025-03-04", "updated": "2025-07-11"}
{"id": "2503.04518", "title": "Leveraging priors on distribution functions for multi-arm bandits", "authors": ["Sumit Vashishtha", "Odalric-Ambrym Maillard"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Camera ready version -- Reinforcement Learning Journal, 2025", "url": "http://arxiv.org/abs/2503.04518v2", "summary": "We introduce Dirichlet Process Posterior Sampling (DPPS), a Bayesian\nnon-parametric algorithm for multi-arm bandits based on Dirichlet Process (DP)\npriors. Like Thompson-sampling, DPPS is a probability-matching algorithm, i.e.,\nit plays an arm based on its posterior-probability of being optimal. Instead of\nassuming a parametric class for the reward generating distribution of each arm,\nand then putting a prior on the parameters, in DPPS the reward generating\ndistribution is directly modeled using DP priors. DPPS provides a principled\napproach to incorporate prior belief about the bandit environment, and in the\nnoninformative limit of the DP posteriors (i.e. Bayesian Bootstrap), we recover\nNon Parametric Thompson Sampling (NPTS), a popular non-parametric bandit\nalgorithm, as a special case of DPPS. We employ stick-breaking representation\nof the DP priors, and show excellent empirical performance of DPPS in\nchallenging synthetic and real world bandit environments. Finally, using an\ninformation-theoretic analysis, we show non-asymptotic optimality of DPPS in\nthe Bayesian regret setup.", "comment": "Camera ready version -- Reinforcement Learning Journal, 2025", "pdf_url": "http://arxiv.org/pdf/2503.04518v2", "cate": "stat.ML", "date": "2025-03-06", "updated": "2025-07-11"}
{"id": "2503.17546", "title": "Communities in the Kuramoto Model: Dynamics and Detection via Path Signatures", "authors": ["Tâm Johan Nguyên", "Darrick Lee", "Bernadette Jana Stolz"], "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "nlin.AO", "q-bio.NC", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      56 pages, 21 figures", "url": "http://arxiv.org/abs/2503.17546v3", "summary": "The behavior of multivariate dynamical processes is often governed by\nunderlying structural connections that relate the components of the system. For\nexample, brain activity, which is often measured via time series is determined\nby an underlying structural graph, where nodes represent neurons or brain\nregions and edges cortical connectivity. Existing methods for inferring\nstructural connections from observed dynamics, such as correlation-based or\nspectral techniques, may fail to fully capture complex relationships in\nhigh-dimensional time series in an interpretable way. Here, we propose the use\nof path signatures, a mathematical framework that encodes geometric and\ntemporal properties of continuous paths, to address this problem. Path\nsignatures provide a reparametrization-invariant characterization of dynamical\ndata and can be used to compute the lead matrix, which reveals lead-lag\nphenomena. We showcase our approach on time series from coupled oscillators in\nthe Kuramoto model defined on a stochastic block model graph, termed the\nKuramoto Stochastic Block Model (KSBM). Using mean-field theory and Gaussian\napproximations, we analytically derive reduced models of KSBM dynamics in\ndifferent temporal regimes and theoretically characterize the lead matrix in\nthese settings. Leveraging these insights, we propose a novel signature-based\ncommunity detection algorithm, achieving exact recovery of structural\ncommunities from observed time series in multiple KSBM instances. We also\nexplored the performance of our community detection on a stochastic variant of\nthe KSBM as well as on real neuropixels of cortical recordings to demonstrate\napplicability on real-world data. Our results demonstrate that path signatures\nprovide a novel perspective on analyzing complex neural data and other\nhigh-dimensional systems, explicitly exploiting temporal functional\nrelationships to infer underlying structure.", "comment": "56 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2503.17546v3", "cate": "stat.ML", "date": "2025-03-21", "updated": "2025-07-11"}
{"id": "2504.11436", "title": "Shifting Work Patterns with Generative AI", "authors": ["Eleanor Wiske Dillon", "Sonia Jaffe", "Nicole Immorlica", "Christopher T. Stanton"], "categories": ["econ.GN", "cs.LG", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.11436v3", "summary": "We present evidence on how generative AI changes the work patterns of\nknowledge workers using data from a 6-month-long, cross-industry, randomized\nfield experiment. Half of the 7,137 workers in the study received access to a\ngenerative AI tool integrated into the applications they already used for\nemails, document creation, and meetings. We find that access to the AI tool\nduring the first year of its release primarily impacted behaviors that workers\ncould change independently and not behaviors that require coordination to\nchange: workers who used the tool in more than half of the sample weeks spent\n3.6 fewer hours, or 31% less time on email each week (intent to treat estimate\nis 1.3 hours) and completed documents moderately faster, but did not\nsignificantly change time spent in meetings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.11436v3", "cate": "econ.GN", "date": "2025-04-15", "updated": "2025-07-10"}
{"id": "2506.22236", "title": "A Plea for History and Philosophy of Statistics and Machine Learning", "authors": ["Hanti Lin"], "categories": ["stat.OT", "cs.LG"], "primary_category": "Subjects:       Other Statistics (stat.OT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22236v2", "summary": "The integration of the history and philosophy of statistics was initiated at\nleast by Hacking (1965) and advanced by Mayo (1996), but it has not received\nsustained follow-up. Yet such integration is more urgent than ever, as the\nrecent success of artificial intelligence has been driven largely by machine\nlearning -- a field historically developed alongside statistics. Today, the\nboundary between statistics and machine learning is increasingly blurred. What\nwe now need is integration, twice over: of history and philosophy, and of two\nfields they engage -- statistics and machine learning. I present a case study\nof a philosophical idea in machine learning (and in formal epistemology) whose\nroot can be traced back to an often under-appreciated insight in Neyman and\nPearson's 1936 work (a follow-up to their 1933 classic). This leads to the\narticulation of an epistemological principle -- largely implicit in, but shared\nby, the practices of frequentist statistics and machine learning -- which I\ncall achievabilism: the thesis that the correct standard for assessing\nnon-deductive inference methods should not be fixed, but should instead be\nsensitive to what is achievable in specific problem contexts. Another\nintegration also emerges at the level of methodology, combining two ends of the\nphilosophy of science spectrum: history and philosophy of science on the one\nhand, and formal epistemology on the other hand.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22236v2", "cate": "stat.OT", "date": "2025-06-27", "updated": "2025-07-11"}
{"id": "2507.05550", "title": "A Malliavin calculus approach to score functions in diffusion generative models", "authors": ["Ehsan Mirafzali", "Frank Proske", "Utkarsh Gupta", "Daniele Venturi", "Razvan Marinescu"], "categories": ["stat.ML", "cs.LG", "math.PR"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05550v2", "summary": "Score-based diffusion generative models have recently emerged as a powerful\ntool for modelling complex data distributions. These models aim at learning the\nscore function, which defines a map from a known probability distribution to\nthe target data distribution via deterministic or stochastic differential\nequations (SDEs). The score function is typically estimated from data using a\nvariety of approximation techniques, such as denoising or sliced score\nmatching, Hyv\\\"arien's method, or Schr\\\"odinger bridges. In this paper, we\nderive an exact, closed form, expression for the score function for a broad\nclass of nonlinear diffusion generative models. Our approach combines modern\nstochastic analysis tools such as Malliavin derivatives and their adjoint\noperators (Skorokhod integrals or Malliavin Divergence) with a new Bismut-type\nformula. The resulting expression for the score function can be written\nentirely in terms of the first and second variation processes, with all\nMalliavin derivatives systematically eliminated, thereby enhancing its\npractical applicability. The theoretical framework presented in this work\noffers a principled foundation for advancing score estimation methods in\ngenerative modelling, enabling the design of new sampling algorithms for\ncomplex probability distributions. Our results can be extended to broader\nclasses of stochastic differential equations, opening new directions for the\ndevelopment of score-based diffusion generative models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05550v2", "cate": "stat.ML", "date": "2025-07-08", "updated": "2025-07-11"}
{"id": "2507.05640", "title": "Learnable quantum spectral filters for hybrid graph neural networks", "authors": ["Ammar Daskin"], "categories": ["quant-ph", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      The simulation code and results used for this paper is publicly available at: this https URL", "url": "http://arxiv.org/abs/2507.05640v2", "summary": "In this paper, we describe a parameterized quantum circuit that can be\nconsidered as convolutional and pooling layers for graph neural networks. The\ncircuit incorporates the parameterized quantum Fourier circuit where the qubit\nconnections for the controlled gates derived from the Laplacian operator.\nSpecifically, we show that the eigenspace of the Laplacian operator of a graph\ncan be approximated by using QFT based circuit whose connections are determined\nfrom the adjacency matrix. For an $N\\times N$ Laplacian, this approach yields\nan approximate polynomial-depth circuit requiring only $n=log(N)$ qubits. These\ntypes of circuits can eliminate the expensive classical computations for\napproximating the learnable functions of the Laplacian through Chebyshev\npolynomial or Taylor expansions.\n  Using this circuit as a convolutional layer provides an $n-$ dimensional\nprobability vector that can be considered as the filtered and compressed graph\nsignal. Therefore, the circuit along with the measurement can be considered a\nvery efficient convolution plus pooling layer that transforms an\n$N$-dimensional signal input into $n-$dimensional signal with an exponential\ncompression. We then apply a classical neural network prediction head to the\noutput of the circuit to construct a complete graph neural network. Since the\ncircuit incorporates geometric structure through its graph connection-based\napproach, we present graph classification results for the benchmark datasets\nlisted in TUDataset library. Using only [1-100] learnable parameters for the\nquantum circuit and minimal classical layers (1000-5000 parameters) in a\ngeneric setting, the obtained results are comparable to and in some cases\nbetter than many of the baseline results, particularly for the cases when\ngeometric structure plays a significant role.", "comment": "The simulation code and results used for this paper is publicly\n  available at: https://github.com/adaskin/gnn-qsf", "pdf_url": "http://arxiv.org/pdf/2507.05640v2", "cate": "quant-ph", "date": "2025-07-08", "updated": "2025-07-11"}
{"id": "2507.07469", "title": "Galerkin-ARIMA: A Two-Stage Polynomial Regression Framework for Fast Rolling One-Step-Ahead Forecasting", "authors": ["Haojie Liu", "Zihan Lin"], "categories": ["stat.ML", "cs.LG", "econ.EM"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07469v2", "summary": "We introduce Galerkin-ARIMA, a novel time-series forecasting framework that\nintegrates Galerkin projection techniques with the classical ARIMA model to\ncapture potentially nonlinear dependencies in lagged observations. By replacing\nthe fixed linear autoregressive component with a spline-based basis expansion,\nGalerkin-ARIMA flexibly approximates the underlying relationship among past\nvalues via ordinary least squares, while retaining the moving-average structure\nand Gaussian innovation assumptions of ARIMA. We derive closed-form solutions\nfor both the AR and MA components using two-stage Galerkin projections,\nestablish conditions for asymptotic unbiasedness and consistency, and analyze\nthe bias-variance trade-off under basis-size growth. Complexity analysis\nreveals that, for moderate basis dimensions, our approach can substantially\nreduce computational cost compared to maximum-likelihood ARIMA estimation.\nThrough extensive simulations on four synthetic processes-including noisy ARMA,\nseasonal, trend-AR, and nonlinear recursion series-we demonstrate that\nGalerkin-ARIMA matches or closely approximates ARIMA's forecasting accuracy\nwhile achieving orders-of-magnitude speedups in rolling forecasting tasks.\nThese results suggest that Galerkin-ARIMA offers a powerful, efficient\nalternative for modeling complex time series dynamics in high-volume or\nreal-time applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07469v2", "cate": "stat.ML", "date": "2025-07-10", "updated": "2025-07-11"}
