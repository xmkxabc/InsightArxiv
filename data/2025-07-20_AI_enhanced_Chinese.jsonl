{"id": "2507.13481", "title": "Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence", "authors": ["Arthur Bueno", "Bruno Cafeo", "Maria Cagnin", "Awdren Fontão"], "categories": ["cs.SE", "cs.CY"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      12 pages; 2 figures; Preprint with the original submission accepted for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "url": "http://arxiv.org/abs/2507.13481v1", "summary": "Code samples play a pivotal role in open-source ecosystems (OSSECO), serving\nas lightweight artifacts that support knowledge transfer, onboarding, and\nframework adoption. Despite their instructional relevance, these samples are\noften governed informally, with minimal review and unclear ownership, which\nincreases their exposure to socio-technical degradation. In this context, the\nco-occurrence and longitudinal interplay of code smells (e.g., large classes,\npoor modularity) and community smells (e.g., lone contributors, fragmented\ncommunication) become particularly critical. While each type of smell has been\nstudied in isolation, little is known about how community-level dysfunctions\nanticipate or exacerbate technical anomalies in code samples over time. This\nstudy investigates how code and community smells emerge, co-occur, and evolve\nwithin code samples maintained in OSSECOs. A Multivocal Literature Review\nprotocol was applied, encompassing 30 peer-reviewed papers and 17\npractitioner-oriented sources (2013-2024). Thematic synthesis was conducted to\nidentify recurring socio-technical patterns related to smell dynamics. Nine\npatterns were identified, showing that community smells often precede or\nreinforce technical degradation in code samples. Symptoms such as \"radio\nsilence\" and centralized ownership were frequently associated with persistent\nstructural anomalies. Additionally, limited onboarding, the absence of\ncontinuous refactoring, and informal collaboration emerged as recurring\nconditions for smell accumulation. Conclusion: In OSSECOs, particularly within\ncode samples, community-level dysfunctions not only correlate with but often\nsignal maintainability decay. These findings underscore the need for\nsocio-technical quality indicators and lightweight governance mechanisms\ntailored to shared instructional artifacts.", "comment": "12 pages; 2 figures; Preprint with the original submission accepted\n  for publication at 39th Brazilian Symposium on Software Engineering (SBES)", "pdf_url": "http://arxiv.org/pdf/2507.13481v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "代码样本中的社会技术异味动态：关于出现、演变和共现的多声部综述", "tldr": "本研究通过多声部文献综述，揭示了开源生态系统中代码样本中社会技术异味的出现、演变和共现模式，强调社区层面的功能障碍常预示或加剧代码的可维护性衰退。", "motivation": "尽管代码样本在开源生态系统中扮演着关键角色，但其非正式管理导致其容易遭受社会技术退化。此前对代码异味和社区异味的研究多为孤立进行，对于社区层面的功能障碍如何随时间推移预示或加剧代码样本中的技术异常知之甚少。", "method": "本研究采用多声部文献综述协议，涵盖了2013年至2024年的30篇同行评审论文和17个面向实践者的资源。通过主题综合，识别了与异味动态相关的重复出现的社会技术模式。", "result": "研究识别了九种模式，表明社区异味通常先于或强化代码样本中的技术退化。例如，“无线电静默”和集中所有权等症状常与持久的结构异常相关。此外，有限的新手引导、缺乏持续重构和非正式协作被认为是异味累积的反复出现条件。", "conclusion": "在开源生态系统，特别是代码样本中，社区层面的功能障碍不仅与可维护性衰退相关，而且通常预示着这种衰退。这些发现强调了对共享教学工件量身定制的社会技术质量指标和轻量级治理机制的需求。", "translation": "代码样本在开源生态系统（OSSECO）中扮演着关键角色，作为支持知识转移、新手引导和框架采纳的轻量级工件。尽管它们具有教学相关性，但这些样本通常是非正式管理的，审查极少且所有权不明确，这增加了它们暴露于社会技术退化的风险。在这种背景下，代码异味（例如，大类、模块化差）和社区异味（例如，独立贡献者、碎片化沟通）的共现和纵向相互作用变得尤为关键。虽然每种异味都曾被单独研究，但对于社区层面的功能障碍如何随时间推移预示或加剧代码样本中的技术异常知之甚少。本研究调查了代码和社区异味如何在OSSECO中维护的代码样本中出现、共现和演变。应用了多声部文献综述协议，涵盖了2013年至2024年的30篇同行评审论文和17个面向实践者的资源。进行了主题综合以识别与异味动态相关的重复出现的社会技术模式。识别了九种模式，表明社区异味通常先于或强化代码样本中的技术退化。诸如“无线电静默”和集中所有权等症状常与持久的结构异常相关。此外，有限的新手引导、缺乏持续重构和非正式协作被认为是异味累积的反复出现条件。结论：在OSSECO中，特别是在代码样本中，社区层面的功能障碍不仅与可维护性衰退相关，而且通常预示着这种衰退。这些发现强调了对共享教学工件量身定制的社会技术质量指标和轻量级治理机制的需求。", "summary": "本研究通过对代码样本中社会技术异味动态的多声部文献综述，探讨了开源生态系统中代码异味和社区异味的出现、演变和共现。研究发现，社区层面的功能障碍，如“无线电静默”和集中所有权，常预示或加剧代码样本中的技术退化。这强调了在开源生态系统中，社区健康对代码可维护性的重要性，并呼吁引入针对共享教学工件的社会技术质量指标和轻量级治理机制。", "keywords": "社会技术异味, 代码样本, 社区异味, 开源生态系统, 多声部综述", "comments": "该论文的创新之处在于首次将代码异味和社区异味放在一起，通过“多声部文献综述”方法，系统地探讨了它们在开源代码样本中的社会技术动态。它揭示了社区层面的问题如何直接影响代码质量和可维护性，为理解软件退化提供了新的视角。这项研究对于开源项目的维护者和贡献者具有重要指导意义，强调了在技术改进的同时，也需要关注社区健康和治理机制的建设。"}}
{"id": "2507.13833", "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13833v1", "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13833v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DistFlow：一个用于可扩展高效LLM后期训练的完全分布式强化学习框架", "tldr": "DistFlow是一个全新的完全分布式强化学习框架，旨在解决大型语言模型后期训练中RL的可扩展性瓶颈，通过消除中心化节点实现近乎线性的扩展性和高达7倍的吞吐量提升。", "motivation": "强化学习（RL）已成为大型语言模型（LLM）后期训练的关键技术。有效扩展RL对于释放LLM的先进推理能力和确保安全、目标对齐的行为至关重要。然而，主流框架采用的混合控制器架构中，单一控制器管理全局执行逻辑和数据传输，导致负载不平衡并引入显著瓶颈，从而限制了系统的可扩展性。", "method": "本文引入了DistFlow，一个新颖的完全分布式RL框架，旨在打破扩展障碍。DistFlow采用多控制器范式，将数据传输和执行任务分派给所有工作节点，从而消除了中心化节点。这种设计允许每个工作节点独立操作。此外，其架构将资源配置与执行逻辑解耦，允许每个工作节点拥有独特的执行流，为快速且经济高效的算法实验提供了显著的灵活性。", "result": "DistFlow实现了高达数千个GPU的近乎线性可扩展性，并带来了显著的效率提升。广泛的实验表明，DistFlow实现了卓越的线性可扩展性，并且比最先进的（SOTA）框架实现了高达7倍的端到端吞吐量提升。", "conclusion": "DistFlow通过其完全分布式架构成功解决了大型语言模型后期训练中强化学习的可扩展性瓶颈，显著提高了系统效率和吞吐量，并提供了更大的实验灵活性。", "translation": "强化学习（RL）已成为大型语言模型后期训练的关键技术。有效扩展强化学习现在是解锁最强大LLM的先进推理能力并确保安全、目标对齐行为的关键。主流框架通常采用混合控制器架构，其中一个单一控制器调度整体执行逻辑并管理整体数据传输，而多控制器执行分布式计算。对于大规模强化学习，轻微的负载不平衡都可能引入显著的瓶颈，最终限制系统的可扩展性。为了解决这一限制，我们引入了DistFlow，一个新颖的、完全分布式的RL框架，旨在打破扩展障碍。我们采用多控制器范式，将数据传输和执行任务分派给所有工作节点，从而消除了中心化节点。这使得每个工作节点能够独立操作，从而实现了高达数千个GPU的近乎线性可扩展性，并带来了显著的效率提升。此外，我们的架构将资源配置与执行逻辑解耦，允许每个工作节点拥有独特的执行流，为快速且经济高效的算法实验提供了显著的灵活性。广泛的实验表明，DistFlow实现了卓越的线性可扩展性，并且比最先进的（SOTA）框架实现了高达7倍的端到端吞吐量提升。", "summary": "DistFlow是一个创新的、完全分布式的强化学习框架，专为解决大型语言模型后期训练中的可扩展性问题而设计。它通过采用多控制器范式并消除传统的中心化节点，将数据传输和执行任务分派给所有工作节点，从而允许每个节点独立运行。这种架构不仅实现了高达数千个GPU的近乎线性可扩展性和显著的效率提升，还将资源配置与执行逻辑解耦，为算法实验提供了更大的灵活性。实验证明，DistFlow在端到端吞吐量上比现有最先进框架提高了7倍。", "keywords": "强化学习, LLM, 分布式框架, 可扩展性, 后期训练", "comments": "DistFlow的关键创新在于其完全分布式的RL框架设计，通过消除中心化控制器，有效解决了大规模RL训练中常见的负载不平衡和可扩展性瓶颈问题。它实现了近乎线性的扩展性和显著的吞吐量提升，这对于大型语言模型（LLM）的后期训练至关重要。此外，资源配置与执行逻辑的解耦增加了算法实验的灵活性和效率，降低了成本。该框架对于推动LLM的RL后期训练具有重要意义。"}}
{"id": "2507.14004", "title": "Smart fault detection in satellite electrical power system", "authors": ["Niloofar Nobahari", "Alireza Rezaee"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14004v1", "summary": "This paper presents an new approach for detecting in the electrical power\nsystem of satellites operating in Low Earth Orbit (LEO) without an Attitude\nDetermination and Control Subsystem (ADCS). Components of these systems are\nprone to faults, such as line-to-line faults in the photovoltaic subsystem,\nopen circuits, and short circuits in the DC-to-DC converter, as well as ground\nfaults in batteries. In the previous research has largely focused on detecting\nfaults in each components, such as photovoltaic arrays or converter systems,\ntherefore, has been limited attention given to whole electrical power system of\nsatellite as a whole system. Our approach addresses this gap by utilizing a\nMulti-Layer Perceptron (MLP) neural network model, which leverages input data\nsuch as solar radiation and surface temperature to predict current and load\noutputs. These machine learning techniques that classifiy use different\napproaches like Principal Component Analysis (PCA) and K-Nearest Neighbors\n(KNN), to classify faults effectively. The model presented achieves over 99%\naccuracy in identifying faults across multiple subsystems, marking a notable\nadvancement from previous approaches by offering a complete diagnostic solution\nfor the entire satellite power system. This thorough method boosts system\nreliability and helps lower the chances of mission failure", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14004v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "卫星电力系统智能故障检测", "tldr": "本文提出一种使用MLP神经网络在无ADCS的LEO卫星上进行整体电力系统智能故障检测的方法，准确率超过99%。", "motivation": "以前的研究主要集中在单个组件的故障检测，对整个卫星电力系统作为整体的故障检测关注有限。", "method": "采用多层感知器（MLP）神经网络模型，利用太阳辐射和表面温度等输入数据预测电流和负载输出。使用PCA和KNN等机器学习技术进行故障分类。", "result": "该模型在识别多个子系统故障方面的准确率超过99%，为整个卫星电力系统提供了完整的诊断解决方案。", "conclusion": "该方法显著提高了系统可靠性，并有助于降低任务失败的可能性。", "translation": "本文提出了一种在低地球轨道（LEO）运行的无姿态确定与控制子系统（ADCS）的卫星电力系统中进行故障检测的新方法。这些系统的组件容易发生故障，例如光伏子系统中的线间故障、DC-DC转换器中的开路和短路，以及电池中的接地故障。以往的研究主要集中在检测每个组件的故障，例如光伏阵列或转换器系统，因此对整个卫星电力系统作为一个整体的关注有限。我们的方法通过利用多层感知器（MLP）神经网络模型来解决这一空白，该模型利用太阳辐射和表面温度等输入数据来预测电流和负载输出。这些机器学习技术，如主成分分析（PCA）和K-最近邻（KNN），通过不同的方法进行分类，以有效分类故障。所提出的模型在识别多个子系统故障方面的准确率超过99%，标志着与以往方法相比取得了显著进步，为整个卫星电力系统提供了完整的诊断解决方案。这种全面的方法提高了系统可靠性，有助于降低任务失败的可能性。", "summary": "本文提出了一种针对低地球轨道（LEO）无ADCS卫星电力系统的智能故障检测新方法。针对以往研究主要关注单一组件而非整体系统的不足，该方法利用多层感知器（MLP）神经网络模型，结合太阳辐射和表面温度等输入预测电流和负载，并通过PCA和KNN等技术进行故障分类。该模型在识别跨子系统故障方面实现了超过99%的准确率，为整个卫星电力系统提供了全面的诊断方案，显著提升了系统可靠性并降低了任务失败风险。", "keywords": "卫星电力系统, 故障检测, 多层感知器, 机器学习", "comments": "本文的创新之处在于将故障检测的范围从单一组件扩展到整个卫星电力系统，填补了现有研究的空白。通过采用MLP神经网络结合传统机器学习分类器，实现了高准确率的故障诊断，对于提升卫星任务的可靠性具有重要意义。"}}
{"id": "2501.02183", "title": "Data-Driven Reduced-Order Models for Port-Hamiltonian Systems with Operator Inference", "authors": ["Yuwei Geng", "Lili Ju", "Boris Kramer", "Zhu Wang"], "categories": ["math.NA", "cs.NA", "65P99, 65L70"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 13 figures", "url": "http://arxiv.org/abs/2501.02183v2", "summary": "Hamiltonian operator inference has been developed in [Sharma, H., Wang, Z.,\nKramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn\nstructure-preserving reduced-order models (ROMs) for Hamiltonian systems. The\nmethod constructs a low-dimensional model using only data and knowledge of the\nfunctional form of the Hamiltonian. The resulting ROMs preserve the intrinsic\nstructure of the system, ensuring that the mechanical and physical properties\nof the system are maintained. In this work, we extend this approach to\nport-Hamiltonian systems, which generalize Hamiltonian systems by including\nenergy dissipation, external input, and output. Based on snapshots of the\nsystem's state and output, together with the information about the functional\nform of the Hamiltonian, reduced operators are inferred through optimization\nand are then used to construct data-driven ROMs. To further alleviate the\ncomplexity of evaluating nonlinear terms in the ROMs, a hyper-reduction method\nvia discrete empirical interpolation is applied. Accordingly, we derive error\nestimates for the ROM approximations of the state and output. Finally, we\ndemonstrate the structure preservation, as well as the accuracy of the proposed\nport-Hamiltonian operator inference framework, through numerical experiments on\na linear mass-spring-damper problem and a nonlinear Toda lattice problem.", "comment": "28 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2501.02183v2", "cate": "math.NA", "date": "2025-01-04", "updated": "2025-07-18", "AI": {"title_translation": "基于算子推理的端口哈密顿系统数据驱动降阶模型", "tldr": "本文将哈密顿算子推理方法扩展到端口哈密顿系统，通过数据和哈密顿量的函数形式推断降阶算子，并结合超降维方法构建数据驱动的降阶模型，数值实验证明了其结构保持性和准确性。", "motivation": "现有哈密顿算子推理方法已能为哈密顿系统构建结构保持的降阶模型，但未能涵盖包含能量耗散、外部输入和输出的端口哈密顿系统。本文旨在将该方法扩展到更通用的端口哈密顿系统。", "method": "基于系统状态和输出的快照以及哈密顿量的函数形式信息，通过优化推断出降阶算子，并用这些算子构建数据驱动的降阶模型。为降低非线性项评估的复杂性，应用了通过离散经验插值实现的超降维方法。同时，推导了状态和输出的降阶模型近似误差估计。", "result": "通过在线性质量-弹簧-阻尼器问题和非线性Toda晶格问题上的数值实验，证明了所提出的端口哈密顿算子推理框架的结构保持性以及准确性。", "conclusion": "本文成功将哈密顿算子推理框架扩展到端口哈密顿系统，所提出的数据驱动降阶模型不仅保持了系统的内在结构，而且在数值实验中展现出良好的准确性。", "translation": "哈密顿算子推理已在[Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022]中发展起来，用于学习哈密顿系统的结构保持降阶模型（ROMs）。该方法仅使用数据和哈密顿量的函数形式知识来构建低维模型。由此产生的ROMs保留了系统的内在结构，确保了系统的机械和物理特性得以维持。在这项工作中，我们将这种方法扩展到端口哈密顿系统，该系统通过包含能量耗散、外部输入和输出而推广了哈密顿系统。基于系统状态和输出的快照，结合哈密顿量的函数形式信息，通过优化推断出降阶算子，然后用于构建数据驱动的ROMs。为了进一步减轻ROMs中非线性项评估的复杂性，应用了通过离散经验插值实现的超降维方法。因此，我们推导了状态和输出的ROM近似误差估计。最后，通过在线性质量-弹簧-阻尼器问题和非线性Toda晶格问题上的数值实验，证明了所提出的端口哈密顿算子推理框架的结构保持性以及准确性。", "summary": "本文将已有的哈密顿算子推理方法扩展到端口哈密顿系统，该系统包含能量耗散、外部输入和输出。研究人员利用系统状态和输出数据以及哈密顿量的函数形式，通过优化推断出降阶算子，并构建了数据驱动的降阶模型。为处理非线性项复杂性，引入了离散经验插值超降维技术，并推导了误差估计。数值实验证明了该方法在结构保持性和准确性方面的有效性。", "keywords": "端口哈密顿系统, 降阶模型, 算子推理, 数据驱动, 结构保持", "comments": "本文的创新点在于将哈密顿算子推理方法成功扩展到更普遍的端口哈密顿系统，这对于处理包含能量耗散和外部交互的复杂系统具有重要意义。通过结合数据驱动的算子推理和超降维技术，该方法不仅能构建结构保持的降阶模型，还能有效降低计算复杂度，为复杂物理系统的建模和仿真提供了新的工具。"}}
{"id": "2507.13818", "title": "Treedepth Inapproximability and Exponential ETH Lower Bound", "authors": ["Édouard Bonnet", "Daniel Neuen", "Marek Sokołowski"], "categories": ["cs.CC", "cs.DS"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "Comments:      10 pages", "url": "http://arxiv.org/abs/2507.13818v1", "summary": "Treedepth is a central parameter to algorithmic graph theory. The current\nstate-of-the-art in computing and approximating treedepth consists of a\n$2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\\text{OPT}\n\\log^{3/2} \\text{OPT})$-approximation algorithm, where the former algorithm\nreturns an elimination forest of height $k$ (witnessing that treedepth is at\nmost $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has\ntreedepth larger than $k$, and $\\text{OPT}$ is the actual value of the\ntreedepth. On the complexity side, exactly computing treedepth is NP-complete,\nbut the known reductions do not rule out a polynomial-time approximation scheme\n(PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running\ntime of $2^{o(\\sqrt n)}$ for exact algorithms.\n  We show that 1.0003-approximating treedepth is NP-hard, and that exactly\ncomputing the treedepth of an $n$-vertex graph requires time $2^{\\Omega(n)}$,\nunless the ETH fails. We further derive that there exist absolute constants\n$\\delta, c > 0$ such that any $(1+\\delta)$-approximation algorithm requires\ntime $2^{\\Omega(n / \\log^c n)}$. We do so via a simple direct reduction from\nSatisfiability to Treedepth, inspired by a reduction recently designed for\nTreewidth [STOC '25].", "comment": "10 pages", "pdf_url": "http://arxiv.org/pdf/2507.13818v1", "cate": "cs.CC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "树深度的不可近似性与指数级ETH下界", "tldr": "本文证明了树深度的1.0003-近似是NP-难的，并在ETH假设下，精确计算树深度需要$2^{\\Omega(n)}$时间，且任意$(1+\\delta)$-近似算法需要$2^{\\Omega(n / \\log^c n)}$时间。", "motivation": "现有算法在计算和近似树深度方面存在局限性，例如精确算法时间复杂度高，近似算法精度有限。更重要的是，在复杂度方面，尽管精确计算树深度是NP-完全的，但已知归约并未排除多项式时间近似方案（PTAS），且在指数时间假设（ETH）下，仅排除了$2^{o(\\sqrt n)}$的运行时间，这意味着可能存在更强的下界。", "method": "通过从可满足性问题（Satisfiability）到树深度（Treedepth）的简单直接归约来证明这些结果，该归约受到了最近为树宽（Treewidth）设计的归约启发。", "result": "1. 证明了1.0003-近似树深度是NP-难的。\n2. 证明了除非指数时间假设（ETH）失败，否则精确计算一个n个顶点的图的树深度需要$2^{\\Omega(n)}$时间。\n3. 推导出存在绝对常数$\\delta, c > 0$，使得任何$(1+\\delta)$-近似算法需要$2^{\\Omega(n / \\log^c n)}$时间。", "conclusion": "本文通过建立树深度的强不可近似性结果和指数级ETH下界，显著推进了对树深度计算复杂度的理解，填补了现有理论中的空白。", "translation": "树深度是算法图论中的一个核心参数。目前计算和近似树深度的最新技术包括一个$2^{O(k^2)} n$时间的精确算法和一个多项式时间$O(\\text{OPT} \\log^{3/2} \\text{OPT})$-近似算法，其中前者算法对于$n$个顶点的输入图$G$返回一个高度为$k$的消除森林（证明树深度最多为$k$），或者正确报告$G$的树深度大于$k$，而$\\text{OPT}$是树深度的实际值。在复杂度方面，精确计算树深度是NP-完全的，但已知的归约并未排除多项式时间近似方案（PTAS），并且在指数时间假设（ETH）下，仅排除了精确算法$2^{o(\\sqrt n)}$的运行时间。\n我们证明了1.0003-近似树深度是NP-难的，并且除非ETH失败，否则精确计算一个$n$个顶点的图的树深度需要$2^{\\Omega(n)}$时间。我们进一步推导出存在绝对常数$\\delta, c > 0$，使得任何$(1+\\delta)$-近似算法需要$2^{\\Omega(n / \\log^c n)}$时间。我们通过从可满足性问题到树深度的简单直接归约来做到这一点，该归约受到了最近为树宽设计的归约（STOC '25）的启发。", "summary": "本文研究了算法图论中核心参数树深度的计算复杂度。针对现有精确算法时间复杂度高且近似算法精度有限的问题，以及理论上对树深度计算下界认识不足的现状，作者通过从可满足性问题到树深度的直接归约，证明了1.0003-近似树深度是NP-难的。此外，在指数时间假设（ETH）下，作者还证明了精确计算树深度需要指数级时间$2^{\\Omega(n)}$，并且任何$(1+\\delta)$-近似算法也需要$2^{\\Omega(n / \\log^c n)}$的指数级时间，从而为树深度的计算复杂性提供了更强的理论下界。", "keywords": "树深度, 不可近似性, 指数时间假设 (ETH), 计算复杂度, 图算法", "comments": "本文通过引入新的归约方法，显著加强了树深度计算的复杂性理论，特别是证明了其强不可近似性以及在ETH假设下的指数级下界。这对于理解图算法的根本限制具有重要意义，并为未来近似算法的设计提供了明确的挑战。创新点在于其从可满足性到树深度的直接归约，这提供了一个更简洁和强大的证明框架。"}}
{"id": "2507.13940", "title": "NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning", "authors": ["Qingyi Chen", "Ahmed H. Qureshi"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13940v1", "summary": "Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in\nrobotics. Despite substantial advancements, existing methods often face a\ndilemma. Decentralized algorithms typically rely on predicting the behavior of\nother agents, sharing contracts, or maintaining communication for safety, while\ncentralized approaches struggle with scalability and real-time decision-making.\nTo address these challenges, we introduce Neural Hamilton-Jacobi Reachability\nLearning (HJR) for Decentralized Multi-Agent Motion Planning. Our method\nprovides scalable neural HJR modeling to tackle high-dimensional configuration\nspaces and capture worst-case collision and safety constraints between agents.\nWe further propose a decentralized trajectory optimization framework that\nincorporates the learned HJR solutions to solve MAMP tasks in real-time. We\ndemonstrate that our method is both scalable and data-efficient, enabling the\nsolution of MAMP problems in higher-dimensional scenarios with complex\ncollision constraints. Our approach generalizes across various dynamical\nsystems, including a 12-dimensional dual-arm setup, and outperforms a range of\nstate-of-the-art techniques in successfully addressing challenging MAMP tasks.\nVideo demonstrations are available at https://youtu.be/IZiePX0p1Mc.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13940v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "NeHMO：用于分散式安全多智能体运动规划的神经哈密顿-雅可比可达性学习", "tldr": "NeHMO利用神经哈密顿-雅可比可达性学习，以可扩展和数据高效的方式解决分散式安全多智能体运动规划中的高维和复杂碰撞约束问题。", "motivation": "现有安全多智能体运动规划（MAMP）方法面临挑战：分散式算法通常依赖预测、共享协议或通信来实现安全，而集中式方法则难以扩展和进行实时决策。", "method": "本文引入了神经哈密顿-雅可比可达性学习（HJR）用于分散式多智能体运动规划（NeHMO）。该方法提供可扩展的神经HJR建模，以处理高维配置空间并捕获智能体间最坏情况下的碰撞和安全约束。此外，还提出了一个分散式轨迹优化框架，该框架结合学习到的HJR解决方案来实时解决MAMP任务。", "result": "该方法具有可扩展性和数据效率，能够解决高维场景中具有复杂碰撞约束的MAMP问题。它能泛化到各种动力系统，包括一个12维双臂设置，并且在成功解决具有挑战性的MAMP任务方面优于一系列最先进的技术。", "conclusion": "NeHMO通过神经哈密顿-雅可比可达性学习，成功地为分散式安全多智能体运动规划提供了一个可扩展、数据高效且能处理高维复杂碰撞约束的解决方案，并在实际任务中表现出色。", "translation": "安全多智能体运动规划（MAMP）是机器人领域的一个重大挑战。尽管取得了实质性进展，但现有方法通常面临困境。分散式算法通常依赖于预测其他智能体的行为、共享契约或保持通信以确保安全，而集中式方法则在可扩展性和实时决策方面遇到困难。为了解决这些挑战，我们引入了用于分散式多智能体运动规划的神经哈密顿-雅可比可达性学习（HJR）。我们的方法提供了可扩展的神经HJR建模，以应对高维配置空间并捕获智能体之间最坏情况下的碰撞和安全约束。我们进一步提出了一个分散式轨迹优化框架，该框架结合学习到的HJR解决方案来实时解决MAMP任务。我们证明了我们的方法既可扩展又数据高效，能够解决具有复杂碰撞约束的更高维场景中的MAMP问题。我们的方法可以泛化到各种动力系统，包括一个12维双臂设置，并且在成功解决具有挑战性的MAMP任务方面优于一系列最先进的技术。视频演示可在https://youtu.be/IZiePX0p1Mc观看。", "summary": "本文提出了一种名为NeHMO的新型方法，用于分散式安全多智能体运动规划。该方法利用神经哈密顿-雅可比可达性学习（HJR），通过可扩展的神经HJR建模来处理高维配置空间并捕获智能体间的碰撞和安全约束。结合一个分散式轨迹优化框架，NeHMO能够实时解决多智能体运动规划任务。实验结果表明，该方法在可扩展性、数据效率和泛化能力方面表现突出，能够有效处理高维复杂碰撞场景，并优于现有技术。", "keywords": "多智能体运动规划, 哈密顿-雅可比可达性, 分散式控制, 碰撞避免, 神经学习", "comments": "该论文的创新点在于将神经哈密顿-雅可比可达性学习应用于分散式多智能体运动规划，有效解决了传统方法在可扩展性和处理高维复杂碰撞约束方面的局限性。其数据高效性和对多种动力系统的泛化能力是其重要优势，为安全多智能体系统提供了新的解决方案。"}}
{"id": "2505.05223", "title": "Multi-Objective Reinforcement Learning for Adaptable Personalized Autonomous Driving", "authors": ["Hendrik Surmann", "Jorge de Heuvel", "Maren Bennewitz"], "categories": ["cs.RO", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.05223v2", "summary": "Human drivers exhibit individual preferences regarding driving style.\nAdapting autonomous vehicles to these preferences is essential for user trust\nand satisfaction. However, existing end-to-end driving approaches often rely on\npredefined driving styles or require continuous user feedback for adaptation,\nlimiting their ability to support dynamic, context-dependent preferences. We\npropose a novel approach using multi-objective reinforcement learning (MORL)\nwith preference-driven optimization for end-to-end autonomous driving that\nenables runtime adaptation to driving style preferences. Preferences are\nencoded as continuous weight vectors to modulate behavior along interpretable\nstyle objectives$\\unicode{x2013}$including efficiency, comfort, speed, and\naggressiveness$\\unicode{x2013}$without requiring policy retraining. Our\nsingle-policy agent integrates vision-based perception in complex mixed-traffic\nscenarios and is evaluated in diverse urban environments using the CARLA\nsimulator. Experimental results demonstrate that the agent dynamically adapts\nits driving behavior according to changing preferences while maintaining\nperformance in terms of collision avoidance and route completion.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.05223v2", "cate": "cs.RO", "date": "2025-05-08", "updated": "2025-07-18", "AI": {"title_translation": "用于可适应个性化自动驾驶的多目标强化学习", "tldr": "本文提出了一种基于多目标强化学习（MORL）的新方法，用于端到端自动驾驶，能够根据用户偏好（如效率、舒适度、速度和激进程度）在运行时动态调整驾驶风格，而无需重新训练策略。", "motivation": "人类驾驶员表现出个性化的驾驶风格偏好，而现有的自动驾驶方法通常依赖预定义风格或需要持续用户反馈，限制了其支持动态、上下文相关偏好的能力。为提升用户信任和满意度，自动驾驶车辆必须能适应这些个性化偏好。", "method": "本文提出了一种新颖的、基于偏好驱动优化的多目标强化学习（MORL）方法，用于端到端自动驾驶。该方法通过将偏好编码为连续权重向量，在运行时根据可解释的风格目标（包括效率、舒适度、速度和激进程度）调节驾驶行为，无需重新训练策略。其单策略智能体集成了基于视觉的感知能力，并在复杂混合交通场景中进行评估。", "result": "实验结果表明，该智能体能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和路线完成方面保持了性能。", "conclusion": "本文提出的基于多目标强化学习的方法能够有效地使自动驾驶车辆在运行时适应用户个性化的驾驶风格偏好，同时不牺牲基本的安全性和任务完成度，从而显著提升用户体验和信任。", "translation": "人类驾驶员表现出个性化的驾驶风格偏好。使自动驾驶车辆适应这些偏好对于用户信任和满意度至关重要。然而，现有的端到端驾驶方法通常依赖预定义的驾驶风格或需要持续的用户反馈进行适应，这限制了它们支持动态、上下文相关偏好的能力。我们提出了一种利用多目标强化学习（MORL）和偏好驱动优化相结合的新方法，用于端到端自动驾驶，该方法能够在运行时适应驾驶风格偏好。偏好被编码为连续权重向量，以在可解释的风格目标（包括效率、舒适度、速度和激进程度）上调节行为，而无需重新训练策略。我们的单策略智能体在复杂的混合交通场景中集成了基于视觉的感知，并使用CARLA模拟器在不同的城市环境中进行了评估。实验结果表明，该智能体能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和路线完成方面保持了性能。", "summary": "本文提出了一种基于多目标强化学习（MORL）的端到端自动驾驶新范式，旨在解决现有方法在适应驾驶员个性化、动态偏好方面的局限性。通过将用户偏好编码为连续权重向量，该系统能够在运行时调整车辆行为，优化效率、舒适度、速度和激进程度等风格目标，而无需重新训练策略。在CARLA模拟器中的评估显示，该智能体能根据变化的偏好动态调整驾驶风格，同时保持高水平的碰撞避免和路线完成能力。", "keywords": "多目标强化学习, 自动驾驶, 个性化, 驾驶风格, 运行时适应", "comments": "这篇论文的创新点在于将多目标强化学习应用于自动驾驶领域，实现了运行时对用户个性化驾驶风格偏好的动态适应，而无需策略重训练。这种方法显著提升了自动驾驶的用户体验和接受度，解决了现有系统在个性化方面的不足。其引入连续权重向量来调节可解释的风格目标，提供了一种灵活且高效的偏好集成方式，具有很高的实用价值。"}}
{"id": "2507.13766", "title": "ISAC: From Human to Environmental Sensing", "authors": ["Kai Wu", "Zhongqin Wang", "Shu-Lin Chen", "J. Andrew Zhang", "Y. Jay Guo"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      15 pages, 8 figures", "url": "http://arxiv.org/abs/2507.13766v1", "summary": "Integrated Sensing and Communications (ISAC) is poised to become one of the\ndefining capabilities of the sixth generation (6G) wireless communications\nsystems, enabling the network infrastructure to jointly support high-throughput\ncommunications and situational awareness. While recent advances have explored\nISAC for both human-centric applications and environmental monitoring, existing\nresearch remains fragmented across these domains. This paper provides the first\nunified review of ISAC-enabled sensing for both human activities and\nenvironment, focusing on signal-level mechanisms, sensing features, and\nreal-world feasibility. We begin by characterising how diverse physical\nphenomena, ranging from human vital sign and motion to precipitation and flood\ndynamics, impact wireless signal propagation, producing measurable signatures\nin channel state information (CSI), Doppler profiles, and signal statistics. A\ncomprehensive analysis is then presented across two domains: human sensing\napplications including localisation, activity recognition, and vital sign\nmonitoring; and environmental sensing for rainfall, soil moisture, and water\nlevel. Experimental results from Long-Term Evolution (LTE) sensing under\nnon-line-of-sight (NLOS) conditions are incorporated to highlight the\nfeasibility in infrastructure-limited scenarios. Open challenges in signal\nfusion, domain adaptation, and generalisable sensing architectures are\ndiscussed to facilitate future research toward scalable and autonomous ISAC.", "comment": "15 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.13766v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "ISAC：从人体感知到环境感知", "tldr": "该论文首次对ISAC在人体活动和环境感知方面的应用进行了统一综述，探讨了信号层机制、感知特征和实际可行性，并讨论了开放性挑战。", "motivation": "集成感知与通信（ISAC）是第六代（6G）无线通信系统的关键能力之一，旨在使网络基础设施能够同时支持高吞吐量通信和态势感知。然而，目前针对人体中心应用和环境监测的ISAC研究仍然分散，缺乏统一的视角。", "method": "本文首次对ISAC支持的人体活动和环境感知进行了统一综述。首先，阐述了各种物理现象（如人体生命体征、运动、降水和洪水动态）如何影响无线信号传播，并在信道状态信息（CSI）、多普勒剖面和信号统计中产生可测量的特征。然后，对人体感知应用（包括定位、活动识别和生命体征监测）和环境感知（用于降雨、土壤湿度和水位）这两个领域进行了全面分析。此外，还结合了非视距（NLOS）条件下长期演进（LTE）感知的实验结果，以突出其在基础设施受限场景下的可行性。", "result": "通过在非视距（NLOS）条件下进行的长期演进（LTE）感知实验结果表明，ISAC在基础设施受限的场景中具有可行性。", "conclusion": "论文讨论了信号融合、域适应和可泛化感知架构等方面的开放性挑战，以期推动未来可扩展和自主ISAC的研究。", "translation": "集成感知与通信（ISAC）有望成为第六代（6G）无线通信系统的标志性能力之一，使网络基础设施能够协同支持高吞吐量通信和态势感知。尽管最近的进展已经探索了用于以人为中心的应用和环境监测的ISAC，但现有研究在这些领域仍然是分散的。本文首次对ISAC支持的人体活动和环境感知进行了统一综述，重点关注信号层机制、感知特征和实际可行性。我们首先描述了各种物理现象，从人体生命体征和运动到降水和洪水动态，如何影响无线信号传播，在信道状态信息（CSI）、多普勒剖面和信号统计中产生可测量的特征。然后，对两个领域进行了全面分析：包括定位、活动识别和生命体征监测的人体感知应用；以及用于降雨、土壤湿度和水位监测的环境感知。文中结合了非视距（NLOS）条件下长期演进（LTE）感知的实验结果，以突出其在基础设施受限场景下的可行性。讨论了信号融合、域适应和可泛化感知架构等方面的开放性挑战，以促进未来向可扩展和自主ISAC的研究。", "summary": "这篇论文首次对集成感知与通信（ISAC）在人体活动和环境感知方面的应用进行了统一综述。文章详细阐述了物理现象如何影响无线信号并产生可测量特征，并全面分析了ISAC在人体感知（如定位、活动识别）和环境感知（如降雨、土壤湿度）中的应用。通过LTE感知实验验证了其在基础设施受限场景下的可行性，并指出了信号融合、域适应等未来研究的开放挑战，旨在推动可扩展和自主ISAC的发展。", "keywords": "ISAC, 6G, 人体感知, 环境感知, 无线通信", "comments": "该论文的创新之处在于首次对ISAC在人体和环境感知领域的碎片化研究进行了统一综述，填补了现有研究的空白。其重要性在于为6G无线通信系统中ISAC的关键能力提供了全面的理论基础和应用前景，并结合实验验证了实际可行性。论文也坦诚地指出了信号融合、域适应等开放性挑战，为未来的研究指明了方向。"}}
{"id": "2501.14068", "title": "Flexible 3D Cage-based Deformation via Green Coordinates on Bézier Patches", "authors": ["Dong Xiao", "Renjie Chen"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by SIGGRAPH 2025 conference track", "url": "http://arxiv.org/abs/2501.14068v4", "summary": "Cage-based deformation is a fundamental problem in geometry processing, where\na cage, a user-specified boundary of a region, is used to deform the ambient\nspace of a given mesh. Traditional 3D cages are typically composed of triangles\nand quads. While quads can represent non-planar regions when their four corners\nare not coplanar, they form ruled surfaces with straight isoparametric curves,\nwhich limits their ability to handle curved and high-curvature deformations. In\nthis work, we extend the cage for curved boundaries using B\\'{e}zier patches,\nenabling flexible and high-curvature deformations with only a few control\npoints. The higher-order structure of the B\\'{e}zier patch also allows for the\ncreation of a more compact and precise curved cage for the input model. Based\non Green's third identity, we derive the Green coordinates for the B\\'{e}zier\ncage, achieving shape-preserving deformation with smooth surface boundaries.\nThese coordinates are defined based on the vertex positions and normals of the\nB\\'{e}zier control net. Given that the coordinates are approximately calculated\nthrough the Riemann summation, we propose a global projection technique to\nensure that the coordinates accurately conform to the linear reproduction\nproperty. Experimental results show that our method achieves high performance\nin handling curved and high-curvature deformations.", "comment": "Accepted by SIGGRAPH 2025 conference track", "pdf_url": "http://arxiv.org/pdf/2501.14068v4", "cate": "cs.GR", "date": "2025-01-23", "updated": "2025-07-18", "AI": {"title_translation": "基于Bézier曲面的格林坐标柔性三维笼式变形", "tldr": "本文提出了一种使用Bézier曲面扩展3D笼式变形的方法，通过格林坐标实现高曲率和形状保持的变形，并引入全局投影以确保坐标精度。", "motivation": "传统的3D笼式变形通常由三角形和四边形组成，其中四边形在处理弯曲和高曲率变形时能力有限，因为它们形成直纹曲面。", "method": "该工作通过使用Bézier曲面扩展笼子，使其能够处理弯曲和高曲率变形。基于格林第三恒等式，推导了Bézier笼的格林坐标，这些坐标基于Bézier控制网格的顶点位置和法线定义。为了解决通过黎曼和近似计算坐标的问题，提出了一种全局投影技术，以确保坐标准确符合线性再现特性。", "result": "实验结果表明，该方法在处理弯曲和高曲率变形方面表现出高性能。", "conclusion": "Not mentioned in abstract", "translation": "笼式变形是几何处理中的一个基本问题，其中笼子（用户指定的区域边界）用于变形给定网格的环境空间。传统的三维笼子通常由三角形和四边形组成。虽然四边形在四个角不共面时可以表示非平面区域，但它们形成具有直线等参数曲线的直纹曲面，这限制了它们处理弯曲和高曲率变形的能力。在这项工作中，我们使用Bézier曲面扩展了用于弯曲边界的笼子，仅用少量控制点即可实现灵活和高曲率的变形。Bézier曲面的高阶结构还允许为输入模型创建更紧凑、更精确的弯曲笼子。基于格林第三恒等式，我们推导了Bézier笼的格林坐标，实现了具有平滑表面边界的形状保持变形。这些坐标是根据Bézier控制网格的顶点位置和法线定义的。鉴于坐标是通过黎曼和近似计算的，我们提出了一种全局投影技术，以确保坐标准确符合线性再现特性。实验结果表明，我们的方法在处理弯曲和高曲率变形方面表现出高性能。", "summary": "针对传统三维笼式变形在处理弯曲和高曲率变形时的局限性，本文提出了一种基于Bézier曲面的柔性三维笼式变形方法。通过使用Bézier曲面扩展变形笼，并基于格林第三恒等式推导了Bézier笼的格林坐标，实现了仅用少量控制点即可进行高曲率变形和形状保持。为确保坐标的线性再现特性，引入了一种全局投影技术。实验结果验证了该方法在处理弯曲和高曲率变形方面的优异性能。", "keywords": "笼式变形, Bézier曲面, 格林坐标, 三维变形, 高曲率变形", "comments": "该论文的创新之处在于将Bézier曲面引入到3D笼式变形中，从而显著提高了处理弯曲和高曲率变形的灵活性和精度。通过推导Bézier笼的格林坐标，并提出全局投影技术来确保坐标的线性再现属性，解决了传统方法在复杂形状变形上的不足，是几何处理领域的一个重要进展。"}}
{"id": "2507.13874", "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery", "authors": ["Mateusz Bystroński", "Mikołaj Hołysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13874v1", "summary": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13874v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "大型语言模型作为创新者：利用潜在空间探索进行新颖性发现的框架", "tldr": "本文提出了一个模型无关的潜在空间构思框架，通过导航思想的连续嵌入空间，使大型语言模型能可控、可扩展地生成新颖且相关的创意，克服了现有方法的局限性。", "motivation": "创新思想生成仍然是AI的核心挑战，大型语言模型（LLMs）难以产生既新颖又相关的输出，倾向于复制训练模式，限制了创造性发散。现有通过领域特定启发式和结构化提示的方法脆弱且难以泛化。", "method": "本文提出了一个模型无关的潜在空间构思框架，通过导航思想的连续嵌入空间，实现可控、可扩展的创造力。该框架无需手工规则，并能轻松适应不同领域、输入格式和创意任务。", "result": "本文介绍了该方法的早期原型，概述了概念框架和初步结果，突出了其作为人类-AI协作的通用共同构思者的潜力。", "conclusion": "该早期原型展示了其作为通用人类-AI协作共同构思者的潜力，克服了现有LLM在创新生成上的局限。", "translation": "创新思想生成仍然是人工智能领域的核心挑战，因为大型语言模型（LLMs）通常难以产生既新颖又相关的输出。尽管它们具有流畅性，但LLMs倾向于复制训练期间看到的模式，这限制了它们在没有大量提示工程的情况下进行创造性发散的能力。先前的工作通过领域特定的启发式方法和结构化提示管道解决了这个问题，但这些解决方案脆弱且难以泛化。在本文中，我们提出了一个模型无关的潜在空间构思框架，通过导航思想的连续嵌入空间，实现可控、可扩展的创造力。与先前的方法不同，我们的框架不需要手工制作的规则，并且易于适应不同的领域、输入格式和创意任务。本文介绍了我们方法的早期原型，概述了概念框架和初步结果，突出了其作为人类-AI协作的通用共同构思者的潜力。", "summary": "本文提出了一个模型无关的潜在空间构思框架，旨在解决大型语言模型在生成新颖且相关创意方面的挑战。该框架通过探索思想的连续嵌入空间，实现可控和可扩展的创造力，且无需预设规则，易于适应不同应用场景。初步结果表明，该框架在人机协作中作为通用共同构思者具有巨大潜力。", "keywords": "大型语言模型, 创新, 潜在空间探索, 创意生成, 人机协作", "comments": "该论文提出了一种新颖的方法，通过利用潜在空间探索来提升大型语言模型的创新能力，解决了LLM在生成新颖性方面普遍存在的挑战。其“模型无关”和“无需手工规则”的特性使其具有较高的通用性和普适性，有望在人机协作的创意生成领域发挥重要作用。"}}
{"id": "2507.06482", "title": "FedDifRC: Unlocking the Potential of Text-to-Image Diffusion Models in Heterogeneous Federated Learning", "authors": ["Huan Wang", "Haoran Li", "Huaming Chen", "Jun Yan", "Jiahua Shi", "Jun Shen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 Pages, ICCV 2025", "url": "http://arxiv.org/abs/2507.06482v2", "summary": "Federated learning aims at training models collaboratively across\nparticipants while protecting privacy. However, one major challenge for this\nparadigm is the data heterogeneity issue, where biased data preferences across\nmultiple clients, harming the model's convergence and performance. In this\npaper, we first introduce powerful diffusion models into the federated learning\nparadigm and show that diffusion representations are effective steers during\nfederated training. To explore the possibility of using diffusion\nrepresentations in handling data heterogeneity, we propose a novel\ndiffusion-inspired Federated paradigm with Diffusion Representation\nCollaboration, termed FedDifRC, leveraging meaningful guidance of diffusion\nmodels to mitigate data heterogeneity. The key idea is to construct text-driven\ndiffusion contrasting and noise-driven diffusion regularization, aiming to\nprovide abundant class-related semantic information and consistent convergence\nsignals. On the one hand, we exploit the conditional feedback from the\ndiffusion model for different text prompts to build a text-driven contrastive\nlearning strategy. On the other hand, we introduce a noise-driven consistency\nregularization to align local instances with diffusion denoising\nrepresentations, constraining the optimization region in the feature space. In\naddition, FedDifRC can be extended to a self-supervised scheme without relying\non any labeled data. We also provide a theoretical analysis for FedDifRC to\nensure convergence under non-convex objectives. The experiments on different\nscenarios validate the effectiveness of FedDifRC and the efficiency of crucial\ncomponents.", "comment": "11 Pages, ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.06482v2", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-18", "AI": {"title_translation": "FedDifRC：在异构联邦学习中释放文本到图像扩散模型的潜力", "tldr": "FedDifRC将扩散模型引入联邦学习以解决数据异构性问题，通过文本驱动的对比学习和噪声驱动的正则化提高模型性能和收敛性。", "motivation": "联邦学习面临数据异构性问题，即客户端之间数据偏好存在偏差，这会损害模型的收敛性和性能。", "method": "提出FedDifRC，一个受扩散启发的新型联邦范式，利用扩散模型的引导来缓解数据异构性。核心思想是构建文本驱动的扩散对比和噪声驱动的扩散正则化。文本驱动的对比学习利用扩散模型的条件反馈，噪声驱动的正则化使局部实例与扩散去噪表示对齐。FedDifRC可扩展到无监督方案，并有理论收敛性分析。", "result": "实验验证了FedDifRC的有效性以及关键组件的效率。", "conclusion": "FedDifRC成功地将扩散模型引入联邦学习，有效缓解了数据异构性问题，并通过理论分析和实验验证了其性能和收敛性。", "translation": "联邦学习旨在保护隐私的同时，在参与者之间协同训练模型。然而，这种范式面临的一个主要挑战是数据异构性问题，即多个客户端之间存在偏向的数据偏好，损害了模型的收敛性和性能。在本文中，我们首次将强大的扩散模型引入联邦学习范式，并表明扩散表示在联邦训练期间是有效的引导。为了探索使用扩散表示处理数据异构性的可能性，我们提出了一种新颖的、受扩散启发的联邦范式，名为FedDifRC，它利用扩散模型的有意义引导来缓解数据异构性。其核心思想是构建文本驱动的扩散对比和噪声驱动的扩散正则化，旨在提供丰富的类别相关语义信息和一致的收敛信号。一方面，我们利用扩散模型对不同文本提示的条件反馈来构建文本驱动的对比学习策略。另一方面，我们引入噪声驱动的一致性正则化，使局部实例与扩散去噪表示对齐，从而约束特征空间中的优化区域。此外，FedDifRC可以扩展到不依赖任何标记数据的自监督方案。我们还为FedDifRC提供了理论分析，以确保在非凸目标下的收敛性。在不同场景下的实验验证了FedDifRC的有效性和关键组件的效率。", "summary": "本文提出了FedDifRC，一种将文本到图像扩散模型引入联邦学习以解决数据异构性的新范式。它利用扩散表示作为有效引导，通过构建文本驱动的扩散对比学习和噪声驱动的扩散正则化来提供丰富的语义信息和一致的收敛信号。FedDifRC支持自监督学习，并提供了理论收敛性保证。实验证明了其在不同场景下的有效性。", "keywords": "联邦学习, 扩散模型, 数据异构性, 对比学习, FedDifRC", "comments": "FedDifRC的创新之处在于首次将强大的扩散模型引入联邦学习框架，并利用其生成能力来解决数据异构性这一联邦学习中的核心挑战。通过结合文本驱动的对比学习和噪声驱动的正则化，它为数据异构性提供了一种新颖且理论上得到支持的解决方案，这对于提升联邦学习在实际应用中的鲁棒性和性能具有重要意义。"}}
{"id": "2507.13415", "title": "SEER: Semantic Enhancement and Emotional Reasoning Network for Multimodal Fake News Detection", "authors": ["Peican Zhu", "Yubo Jing", "Le Cheng", "Bin Chen", "Xiaodong Cui", "Lianwei Wu", "Keke Tang"], "categories": ["cs.MM", "cs.AI"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      Accepted by SMC 2025", "url": "http://arxiv.org/abs/2507.13415v1", "summary": "Previous studies on multimodal fake news detection mainly focus on the\nalignment and integration of cross-modal features, as well as the application\nof text-image consistency. However, they overlook the semantic enhancement\neffects of large multimodal models and pay little attention to the emotional\nfeatures of news. In addition, people find that fake news is more inclined to\ncontain negative emotions than real ones. Therefore, we propose a novel\nSemantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake\nnews detection. We generate summarized captions for image semantic\nunderstanding and utilize the products of large multimodal models for semantic\nenhancement. Inspired by the perceived relationship between news authenticity\nand emotional tendencies, we propose an expert emotional reasoning module that\nsimulates real-life scenarios to optimize emotional features and infer the\nauthenticity of news. Extensive experiments on two real-world datasets\ndemonstrate the superiority of our SEER over state-of-the-art baselines.", "comment": "Accepted by SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.13415v1", "cate": "cs.MM", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "SEER：用于多模态假新闻检测的语义增强和情感推理网络", "tldr": "SEER是一种新颖的多模态假新闻检测网络，通过利用大型多模态模型的语义增强能力和引入情感推理模块，有效解决了现有方法忽视语义和情感特征的问题，并在真实数据集上表现出优越性。", "motivation": "现有研究主要关注跨模态特征对齐、整合和文本-图像一致性，但忽视了大型多模态模型的语义增强效果和新闻的情感特征。此外，假新闻通常比真实新闻包含更多负面情绪。", "method": "提出了一种新颖的语义增强和情感推理（SEER）网络。通过为图像生成摘要标题以进行语义理解，并利用大型多模态模型进行语义增强。引入了一个专家情感推理模块，该模块模拟现实生活场景来优化情感特征并推断新闻真实性。", "result": "在两个真实世界数据集上的大量实验表明，SEER网络优于最先进的基线方法。", "conclusion": "通过结合语义增强和情感推理，SEER网络显著提高了多模态假新闻检测的性能，证明了考虑大型多模态模型语义和情感特征的有效性。", "translation": "多模态假新闻检测的现有研究主要关注跨模态特征的对齐和整合，以及文本-图像一致性的应用。然而，它们忽视了大型多模态模型的语义增强效果，并且很少关注新闻的情感特征。此外，人们发现假新闻比真实新闻更倾向于包含负面情绪。因此，我们提出了一种新颖的语义增强和情感推理（SEER）网络用于多模态假新闻检测。我们为图像语义理解生成摘要标题，并利用大型多模态模型的产物进行语义增强。受新闻真实性与情感倾向之间感知关系的启发，我们提出了一个专家情感推理模块，该模块模拟现实生活场景以优化情感特征并推断新闻的真实性。在两个真实世界数据集上的大量实验证明了我们的SEER优于最先进的基线方法。", "summary": "SEER是一种新颖的多模态假新闻检测网络，旨在解决现有方法忽略大型多模态模型语义增强和新闻情感特征的问题。该网络通过为图像生成摘要标题并利用大型多模态模型进行语义增强，同时引入一个专家情感推理模块来优化情感特征并推断新闻真实性。实验结果表明，SEER在假新闻检测方面优于现有基线方法。", "keywords": "多模态假新闻检测, 语义增强, 情感推理, 大型多模态模型, SEER", "comments": "该论文创新性地将大型多模态模型的语义增强能力和新闻的情感特征引入多模态假新闻检测，特别是提出模拟现实场景的专家情感推理模块，抓住了假新闻常伴负面情绪的特点，为该领域提供了新的视角和有效方法。"}}
{"id": "2507.13394", "title": "Enhanced DeepLab Based Nerve Segmentation with Optimized Tuning", "authors": ["Akhil John Thomas", "Christiaan Boerkamp"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13394v1", "summary": "Nerve segmentation is crucial in medical imaging for precise identification\nof nerve structures. This study presents an optimized DeepLabV3-based\nsegmentation pipeline that incorporates automated threshold fine-tuning to\nimprove segmentation accuracy. By refining preprocessing steps and implementing\nparameter optimization, we achieved a Dice Score of 0.78, an IoU of 0.70, and a\nPixel Accuracy of 0.95 on ultrasound nerve imaging. The results demonstrate\nsignificant improvements over baseline models and highlight the importance of\ntailored parameter selection in automated nerve detection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13394v1", "cate": "eess.IV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于优化调优的增强DeepLab神经分割", "tldr": "本研究提出并优化了一个基于DeepLabV3的神经分割流水线，通过自动化阈值微调和参数优化，在超声神经图像上实现了显著更高的分割精度。", "motivation": "神经分割在医学成像中对精确识别神经结构至关重要，但目前的分割精度有待提高。", "method": "本研究提出了一个优化的DeepLabV3-based分割流水线，该流水线结合了自动化阈值微调、精炼的预处理步骤和参数优化。", "result": "在超声神经成像上，实现了0.78的Dice分数、0.70的IoU和0.95的像素精度，显著优于基线模型。", "conclusion": "定制化的参数选择在自动化神经检测中至关重要，且本方法能显著提高神经分割精度。", "translation": "神经分割在医学成像中对于精确识别神经结构至关重要。本研究提出了一种优化的基于DeepLabV3的分割流水线，该流水线结合了自动化阈值微调以提高分割精度。通过完善预处理步骤和实施参数优化，我们在超声神经成像上实现了0.78的Dice分数、0.70的IoU和0.95的像素精度。结果表明，与基线模型相比有显著改进，并突出了在自动化神经检测中定制化参数选择的重要性。", "summary": "本研究开发并优化了一个基于DeepLabV3的神经分割系统，通过自动化阈值微调和参数优化，在超声神经图像上取得了高精度的分割结果，突出了定制化参数在医学图像分割中的重要性。", "keywords": "神经分割, DeepLabV3, 自动化阈值微调, 参数优化, 医学成像", "comments": "该研究的创新点在于结合了DeepLabV3模型并引入了自动化阈值微调和参数优化，有效提升了神经分割的精度。其重要性在于为医学影像中神经结构的精确识别提供了更可靠的工具，对于临床诊断和治疗具有潜在价值。"}}
{"id": "2507.13525", "title": "Revisiting Prompt Engineering: A Comprehensive Evaluation for LLM-based Personalized Recommendation", "authors": ["Genki Kusano", "Kosuke Akimoto", "Kunihiro Takeoka"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted to ACM RecSys2025 reproducibility", "url": "http://arxiv.org/abs/2507.13525v1", "summary": "Large language models (LLMs) can perform recommendation tasks by taking\nprompts written in natural language as input. Compared to traditional methods\nsuch as collaborative filtering, LLM-based recommendation offers advantages in\nhandling cold-start, cross-domain, and zero-shot scenarios, as well as\nsupporting flexible input formats and generating explanations of user behavior.\nIn this paper, we focus on a single-user setting, where no information from\nother users is used. This setting is practical for privacy-sensitive or\ndata-limited applications. In such cases, prompt engineering becomes especially\nimportant for controlling the output generated by the LLM. We conduct a\nlarge-scale comparison of 23 prompt types across 8 public datasets and 12 LLMs.\nWe use statistical tests and linear mixed-effects models to evaluate both\naccuracy and inference cost. Our results show that for cost-efficient LLMs,\nthree types of prompts are especially effective: those that rephrase\ninstructions, consider background knowledge, and make the reasoning process\neasier to follow. For high-performance LLMs, simple prompts often outperform\nmore complex ones while reducing cost. In contrast, commonly used prompting\nstyles in natural language processing, such as step-by-step reasoning, or the\nuse of reasoning models often lead to lower accuracy. Based on these findings,\nwe provide practical suggestions for selecting prompts and LLMs depending on\nthe required balance between accuracy and cost.", "comment": "Accepted to ACM RecSys2025 reproducibility", "pdf_url": "http://arxiv.org/pdf/2507.13525v1", "cate": "cs.IR", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "重新审视提示工程：基于LLM的个性化推荐的综合评估", "tldr": "本文对基于LLM的个性化推荐中的提示工程进行了大规模评估，发现在单用户设置下，不同成本效益的LLM有不同的最佳提示策略，简单提示对高性能LLM更优，并提供了实用建议。", "motivation": "大型语言模型（LLM）可以通过自然语言提示执行推荐任务，相较于传统方法，LLM在冷启动、跨领域和零样本场景中具有优势，并支持灵活输入和生成解释。在隐私敏感或数据受限的单用户设置中，提示工程对于控制LLM输出尤为重要。", "method": "在单用户设置下，对8个公开数据集和12个大型语言模型进行了23种提示类型的大规模比较。通过统计测试和线性混合效应模型评估了准确性和推理成本。", "result": "对于成本效益高的LLM，三种类型的提示（重述指令、考虑背景知识、使推理过程更易于遵循）特别有效。对于高性能LLM，简单提示通常优于复杂提示，同时降低成本。相反，自然语言处理中常用的提示风格（如分步推理或使用推理模型）往往导致较低的准确性。", "conclusion": "根据研究结果，论文为用户提供了根据准确性和成本之间的权衡来选择提示和LLM的实用建议。", "translation": "大型语言模型（LLM）可以通过接收自然语言编写的提示来执行推荐任务。与协同过滤等传统方法相比，基于LLM的推荐在处理冷启动、跨领域和零样本场景方面具有优势，并支持灵活的输入格式和生成用户行为解释。在本文中，我们专注于单用户设置，即不使用来自其他用户的信息。这种设置对于隐私敏感或数据受限的应用程序是实用的。在这种情况下，提示工程对于控制LLM生成的输出变得尤为重要。我们对8个公开数据集和12个LLM上的23种提示类型进行了大规模比较。我们使用统计测试和线性混合效应模型来评估准确性和推理成本。我们的结果表明，对于成本效益高的LLM，三种类型的提示特别有效：那些重述指令、考虑背景知识并使推理过程更容易遵循的提示。对于高性能LLM，简单提示通常优于更复杂的提示，同时降低成本。相比之下，自然语言处理中常用的提示风格，例如分步推理或使用推理模型，往往导致准确性较低。基于这些发现，我们根据准确性和成本之间所需的平衡，提供了选择提示和LLM的实用建议。", "summary": "本文对基于大型语言模型（LLM）的个性化推荐中的提示工程进行了全面评估。研究特别关注单用户设置，该设置适用于隐私敏感或数据受限的应用场景。作者在8个公开数据集和12个LLM上，比较了23种不同的提示类型，并使用统计测试和线性混合效应模型评估了其准确性和推理成本。研究结果表明，对于成本效益型LLM，重述指令、考虑背景知识和简化推理过程的提示最为有效；而对于高性能LLM，简单的提示往往表现更优且成本更低。此外，NLP中常见的复杂推理提示（如分步推理）在推荐任务中反而可能导致准确性下降。基于这些发现，论文提供了根据准确性和成本需求选择提示和LLM的实用建议。", "keywords": "提示工程, 大型语言模型, 个性化推荐, 综合评估, 单用户设置", "comments": "这项研究通过大规模实验，系统地评估了LLM在个性化推荐中提示工程的效果，特别关注了单用户设置，这在隐私敏感场景下具有重要意义。其创新在于揭示了不同性能和成本的LLM对提示类型的偏好，颠覆了NLP中一些常见提示范式在推荐任务中的表现，为实际应用提供了宝贵的经验指导。"}}
{"id": "2507.12396", "title": "OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments", "authors": ["Hayat Ullah", "Abbas Khan", "Arslan Munir", "Hari Kalva"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages", "url": "http://arxiv.org/abs/2507.12396v2", "summary": "Realistic human surveillance datasets are crucial for training and evaluating\ncomputer vision models under real-world conditions, facilitating the\ndevelopment of robust algorithms for human and human-interacting object\ndetection in complex environments. These datasets need to offer diverse and\nchallenging data to enable a comprehensive assessment of model performance and\nthe creation of more reliable surveillance systems for public safety. To this\nend, we present two visual object detection benchmarks named OD-VIRAT Large and\nOD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance\nimagery. The video sequences in both benchmarks cover 10 different scenes of\nhuman surveillance recorded from significant height and distance. The proposed\nbenchmarks offer rich annotations of bounding boxes and categories, where\nOD-VIRAT Large has 8.7 million annotated instances in 599,996 images and\nOD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also\nfocuses on benchmarking state-of-the-art object detection architectures,\nincluding RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object\ndetection-specific variant of VIRAT dataset. To the best of our knowledge, it\nis the first work to examine the performance of these recently published\nstate-of-the-art object detection architectures on realistic surveillance\nimagery under challenging conditions such as complex backgrounds, occluded\nobjects, and small-scale objects. The proposed benchmarking and experimental\nsettings will help in providing insights concerning the performance of selected\nobject detection models and set the base for developing more efficient and\nrobust object detection architectures.", "comment": "14 pages", "pdf_url": "http://arxiv.org/pdf/2507.12396v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "OD-VIRAT：一个用于现实监控环境下目标检测的大规模基准", "tldr": "本文提出了OD-VIRAT大规模数据集，用于在复杂监控环境中评估和基准测试最先进的目标检测模型。", "motivation": "在现实世界条件下训练和评估计算机视觉模型需要真实的、多样化且具有挑战性的人类监控数据集，以开发鲁棒的算法并创建更可靠的公共安全监控系统。", "method": "提出了两个视觉目标检测基准数据集：OD-VIRAT Large（599,996张图像，870万实例）和OD-VIRAT Tiny（19,860张图像，288,901实例）。这两个基准包含来自10个不同场景的视频序列，并提供丰富的边界框和类别注释。此外，还对RETMDET、YOLOX、RetinaNet、DETR和Deformable-DETR等最先进的目标检测架构进行了基准测试。", "result": "创建了OD-VIRAT Large和OD-VIRAT Tiny两个大规模目标检测基准数据集，其中包含大量注释实例和多样化的监控场景。首次在具有挑战性的现实监控图像上评估了现有最先进的目标检测架构的性能，包括复杂背景、遮挡和小型目标。", "conclusion": "所提出的基准和实验设置有助于深入了解所选目标检测模型的性能，并为开发更高效、更鲁棒的目标检测架构奠定基础。", "translation": "在现实世界条件下训练和评估计算机视觉模型，真实的、人类监控数据集至关重要，它有助于在复杂环境中开发用于人类和人机交互物体的鲁棒算法。这些数据集需要提供多样化和具有挑战性的数据，以全面评估模型性能并为公共安全创建更可靠的监控系统。为此，我们提出了两个名为OD-VIRAT Large和OD-VIRAT Tiny的视觉目标检测基准，旨在推进监控图像中的视觉理解任务。这两个基准中的视频序列涵盖了从高处和远距离记录的10个不同的人类监控场景。所提出的基准提供了丰富的边界框和类别注释，其中OD-VIRAT Large在599,996张图像中包含870万个注释实例，OD-VIRAT Tiny在19,860张图像中包含288,901个注释实例。这项工作还专注于对VIRAT数据集的这个特定于目标检测的变体上的最先进目标检测架构进行基准测试，包括RETMDET、YOLOX、RetinaNet、DETR和Deformable-DETR。据我们所知，这是首次在复杂背景、遮挡物体和小型物体等挑战性条件下，检查这些最近发布的最先进目标检测架构在现实监控图像上的性能。所提出的基准测试和实验设置将有助于提供有关所选目标检测模型性能的见解，并为开发更高效、更鲁棒的目标检测架构奠定基础。", "summary": "本文介绍了OD-VIRAT，一个用于现实监控环境下目标检测的大规模基准数据集，分为OD-VIRAT Large和OD-VIRAT Tiny。该数据集包含来自10个不同监控场景的视频序列，并提供了数百万个带注释的边界框实例。研究人员还利用该基准评估了多种最先进的目标检测模型，旨在促进在复杂真实世界监控条件下的算法开发和性能分析，从而为未来更鲁棒的检测系统奠定基础。", "keywords": "目标检测, 监控, 基准数据集, OD-VIRAT, 计算机视觉", "comments": "该论文通过创建大规模、多样化且具有挑战性的OD-VIRAT数据集，为现实监控环境下的目标检测研究做出了重要贡献。其创新之处在于首次在如此真实的条件下对多个SOTA模型进行了全面基准测试，揭示了模型在复杂背景、遮挡和小目标等方面的表现，这对于推动鲁棒性算法的开发至关重要。该工作填补了现有数据集在真实性和挑战性方面的空白，为社区提供了一个宝贵的评估工具。"}}
{"id": "2507.13423", "title": "Air Traffic Controller Task Demand via Graph Neural Networks: An Interpretable Approach to Airspace Complexity", "authors": ["Edward Henderson", "Dewi Gould", "Richard Everson", "George De Ath", "Nick Pepper"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Author Accepted Manuscript version of paper at the AIAA AVIATION Forum 2025", "url": "http://arxiv.org/abs/2507.13423v1", "summary": "Real-time assessment of near-term Air Traffic Controller (ATCO) task demand\nis a critical challenge in an increasingly crowded airspace, as existing\ncomplexity metrics often fail to capture nuanced operational drivers beyond\nsimple aircraft counts. This work introduces an interpretable Graph Neural\nNetwork (GNN) framework to address this gap. Our attention-based model predicts\nthe number of upcoming clearances, the instructions issued to aircraft by\nATCOs, from interactions within static traffic scenarios. Crucially, we derive\nan interpretable, per-aircraft task demand score by systematically ablating\naircraft and measuring the impact on the model's predictions. Our framework\nsignificantly outperforms an ATCO-inspired heuristic and is a more reliable\nestimator of scenario complexity than established baselines. The resulting tool\ncan attribute task demand to specific aircraft, offering a new way to analyse\nand understand the drivers of complexity for applications in controller\ntraining and airspace redesign.", "comment": "Author Accepted Manuscript version of paper at the AIAA AVIATION\n  Forum 2025", "pdf_url": "http://arxiv.org/pdf/2507.13423v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "基于图神经网络的空中交通管制员任务需求：一种可解释的空域复杂性方法", "tldr": "本文提出了一种可解释的图神经网络（GNN）框架，用于实时评估空中交通管制员（ATCO）的任务需求，通过预测即将到来的指令数量并提供可归因于特定飞机的任务需求分数，该框架在性能上优于现有基线。", "motivation": "在日益拥挤的空域中，实时评估空中交通管制员（ATCO）的近期任务需求是一个严峻挑战。现有复杂性指标通常无法捕捉除简单飞机数量之外的细微操作驱动因素。", "method": "本文引入了一个可解释的基于注意力机制的图神经网络（GNN）框架。该模型通过静态交通场景中的交互来预测即将到来的指令数量。通过系统性地消融飞机并测量其对模型预测的影响，从而推导出可解释的、每架飞机的任务需求分数。", "result": "所提出的框架显著优于受ATCO启发式方法，并且比现有基线更可靠地估计场景复杂性。生成的工具可以将任务需求归因于特定飞机。", "conclusion": "该工具提供了一种分析和理解复杂性驱动因素的新方法，可应用于管制员培训和空域重新设计。", "translation": "实时评估近期的空中交通管制员（ATCO）任务需求在日益拥挤的空域中是一个严峻挑战，因为现有的复杂性指标往往无法捕捉除简单飞机数量之外的细微操作驱动因素。这项工作引入了一个可解释的图神经网络（GNN）框架来解决这一问题。我们基于注意力机制的模型根据静态交通场景中的交互来预测即将到来的指令数量（ATCO向飞机发出的指令）。至关重要的是，我们通过系统性地消融飞机并测量其对模型预测的影响，从而推导出可解释的、每架飞机的任务需求分数。我们的框架显著优于ATCO启发式方法，并且比现有基线更可靠地估计场景复杂性。由此产生的工具可以将任务需求归因于特定飞机，为分析和理解复杂性驱动因素提供了新方法，可应用于管制员培训和空域重新设计。", "summary": "本文提出了一种基于注意力机制的可解释图神经网络（GNN）框架，旨在解决空中交通管制员（ATCO）任务需求实时评估的挑战。该模型通过分析静态交通场景中的飞机交互来预测即将到来的指令数量，并通过系统性消融方法为每架飞机提供可解释的任务需求分数。实验结果表明，该框架在预测准确性和可靠性方面均优于传统启发式方法和现有基线，并能将任务需求归因于特定飞机，为提升管制员培训和空域设计提供了新工具。", "keywords": "空中交通管制, 任务需求, 图神经网络, 可解释性, 空域复杂性", "comments": "该论文的创新之处在于将可解释的图神经网络引入空中交通管制员任务需求评估，解决了传统指标无法捕捉细微操作驱动因素的问题。其通过系统性消融方法提供每架飞机的任务需求分数，极大地增强了模型的可解释性和实用性，为管制员培训和空域优化提供了有力的分析工具。"}}
{"id": "2507.13721", "title": "Graph-Structured Data Analysis of Component Failure in Autonomous Cargo Ships Based on Feature Fusion", "authors": ["Zizhao Zhang", "Tianxiang Zhao", "Yu Sun", "Liping Sun", "Jichuan Kang"], "categories": ["cs.LG", "cs.DB"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13721v1", "summary": "To address the challenges posed by cascading reactions caused by component\nfailures in autonomous cargo ships (ACS) and the uncertainties in emergency\ndecision-making, this paper proposes a novel hybrid feature fusion framework\nfor constructing a graph-structured dataset of failure modes. By employing an\nimproved cuckoo search algorithm (HN-CSA), the literature retrieval efficiency\nis significantly enhanced, achieving improvements of 7.1% and 3.4% compared to\nthe NSGA-II and CSA search algorithms, respectively. A hierarchical feature\nfusion framework is constructed, using Word2Vec encoding to encode\nsubsystem/component features, BERT-KPCA to process failure modes/reasons, and\nSentence-BERT to quantify the semantic association between failure impact and\nemergency decision-making. The dataset covers 12 systems, 1,262 failure modes,\nand 6,150 propagation paths. Validation results show that the GATE-GNN model\nachieves a classification accuracy of 0.735, comparable to existing benchmarks.\nAdditionally, a silhouette coefficient of 0.641 indicates that the features are\nhighly distinguishable. In the label prediction results, the Shore-based\nMeteorological Service System achieved an F1 score of 0.93, demonstrating high\nprediction accuracy. This paper not only provides a solid foundation for\nfailure analysis in autonomous cargo ships but also offers reliable support for\nfault diagnosis, risk assessment, and intelligent decision-making systems. The\nlink to the dataset is\nhttps://github.com/wojiufukele/Graph-Structured-about-CSA.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13721v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于特征融合的自主货船部件故障图结构数据分析", "tldr": "本文提出了一种混合特征融合框架，用于构建自主货船故障模式的图结构数据集，并通过改进的布谷鸟搜索算法提高了文献检索效率，并利用多种模型（如GATE-GNN）实现了高精度的故障分类和预测，为自主货船的故障分析和智能决策提供支持。", "motivation": "为了解决自主货船（ACS）中部件故障引起的级联反应挑战以及应急决策中的不确定性。", "method": "本文提出了一种新颖的混合特征融合框架来构建故障模式的图结构数据集。该框架采用改进的布谷鸟搜索算法（HN-CSA）来提高文献检索效率。在特征融合方面，使用Word2Vec编码子系统/部件特征，BERT-KPCA处理故障模式/原因，以及Sentence-BERT量化故障影响与应急决策之间的语义关联。", "result": "改进的布谷鸟搜索算法（HN-CSA）的文献检索效率比NSGA-II和CSA分别提高了7.1%和3.4%。构建的数据集包含12个系统、1,262种故障模式和6,150条传播路径。GATE-GNN模型分类准确率达到0.735，轮廓系数为0.641，表明特征区分度高。岸基气象服务系统在标签预测中F1分数达到0.93。", "conclusion": "本文不仅为自主货船的故障分析提供了坚实的基础，还为故障诊断、风险评估和智能决策系统提供了可靠支持。", "translation": "为了解决自主货船（ACS）中部件故障引起的级联反应挑战以及应急决策中的不确定性，本文提出了一种新颖的混合特征融合框架，用于构建故障模式的图结构数据集。通过采用改进的布谷鸟搜索算法（HN-CSA），文献检索效率显著提高，与NSGA-II和CSA搜索算法相比，分别提高了7.1%和3.4%。构建了一个分层特征融合框架，使用Word2Vec编码子系统/部件特征，BERT-KPCA处理故障模式/原因，以及Sentence-BERT量化故障影响与应急决策之间的语义关联。该数据集涵盖12个系统、1,262种故障模式和6,150条传播路径。验证结果表明，GATE-GNN模型实现了0.735的分类准确率，与现有基准相当。此外，0.641的轮廓系数表明特征具有高度可区分性。在标签预测结果中，岸基气象服务系统F1分数为0.93，表明预测精度高。本文不仅为自主货船的故障分析提供了坚实的基础，还为故障诊断、风险评估和智能决策系统提供了可靠支持。数据集链接为https://github.com/wojiufukele/Graph-Structured-about-CSA。", "summary": "本文针对自主货船部件故障引起的级联反应及应急决策不确定性问题，提出了一种基于混合特征融合的图结构故障模式数据集构建框架。该框架通过改进的布谷鸟搜索算法提升文献检索效率，并结合Word2Vec、BERT-KPCA和Sentence-BERT进行分层特征融合。研究构建了一个包含多系统、故障模式和传播路径的大型数据集，并通过GATE-GNN模型验证了其在故障分类和预测上的有效性，显示出较高的准确性和特征区分度，为自主货船的故障分析与智能决策提供了新途径。", "keywords": "自主货船, 故障分析, 图结构数据, 特征融合, 布谷鸟搜索算法", "comments": "本文的创新点在于提出了一个新颖的混合特征融合框架，并结合改进的搜索算法来构建自主货船的图结构故障模式数据集。其重要性体现在为自主货船的故障诊断、风险评估和智能决策提供了数据基础和方法支持。通过融合多种先进的自然语言处理技术（Word2Vec, BERT-KPCA, Sentence-BERT）处理不同层级的故障信息，并利用图神经网络进行分析，显示了其在复杂系统故障分析方面的潜力。"}}
{"id": "2506.18183", "title": "Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?", "authors": ["Zhiting Mei", "Christina Zhang", "Tenny Yin", "Justin Lidard", "Ola Shorinwa", "Anirudha Majumdar"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18183v3", "summary": "Reasoning language models have set state-of-the-art (SOTA) records on many\nchallenging benchmarks, enabled by multi-step reasoning induced using\nreinforcement learning. However, like previous language models, reasoning\nmodels are prone to generating confident, plausible responses that are\nincorrect (hallucinations). Knowing when and how much to trust these models is\ncritical to the safe deployment of reasoning models in real-world applications.\nTo this end, we explore uncertainty quantification of reasoning models in this\nwork. Specifically, we ask three fundamental questions: First, are reasoning\nmodels well-calibrated? Second, does deeper reasoning improve model\ncalibration? Finally, inspired by humans' innate ability to double-check their\nthought processes to verify the validity of their answers and their confidence,\nwe ask: can reasoning models improve their calibration by explicitly reasoning\nabout their chain-of-thought traces? We introduce introspective uncertainty\nquantification (UQ) to explore this direction. In extensive evaluations on SOTA\nreasoning models across a broad range of benchmarks, we find that reasoning\nmodels: (i) are typically overconfident, with self-verbalized confidence\nestimates often greater than 85% particularly for incorrect responses, (ii)\nbecome even more overconfident with deeper reasoning, and (iii) can become\nbetter calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not\nuniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we\nconclude with important research directions to design necessary UQ benchmarks\nand improve the calibration of reasoning models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18183v3", "cate": "cs.AI", "date": "2025-06-22", "updated": "2025-07-18", "AI": {"title_translation": "关于不确定性推理：推理模型是否知道它们何时不知道？", "tldr": "推理模型通常过于自信，尤其是在进行更深入的推理时，但通过内省可以改善部分模型的校准。", "motivation": "推理语言模型尽管在许多基准测试中取得了最先进的成果，但它们容易生成自信但错误的响应（幻觉）。了解何时以及在多大程度上信任这些模型对于在实际应用中安全部署推理模型至关重要。", "method": "本研究通过提出三个基本问题来探索推理模型的不确定性量化：推理模型是否校准良好？更深入的推理是否能改善模型校准？推理模型能否通过明确地推理其思维链轨迹来改善校准？为此，引入了内省不确定性量化（UQ），并在广泛的基准测试中对最先进的推理模型进行了广泛评估。", "result": "研究发现，推理模型：(i) 通常过于自信，自我表达的置信度估计（特别是对于不正确的响应）常常超过85%；(ii) 随着更深入的推理变得更加过度自信；(iii) 可以通过内省变得更好地校准（例如o3-Mini和DeepSeek R1），但并非普遍适用（例如Claude 3.7 Sonnet的校准反而更差）。", "conclusion": "设计必要的不确定性量化基准和改进推理模型校准是重要的未来研究方向。", "translation": "关于不确定性推理：推理模型是否知道它们何时不知道？\n\n推理语言模型凭借使用强化学习诱导的多步骤推理，在许多具有挑战性的基准测试中创造了最先进（SOTA）的记录。然而，与之前的语言模型一样，推理模型容易生成自信、合理但错误的响应（幻觉）。了解何时以及在多大程度上信任这些模型对于在实际应用中安全部署推理模型至关重要。为此，我们在这项工作中探索了推理模型的不确定性量化（UQ）。具体来说，我们提出了三个基本问题：首先，推理模型是否校准良好？其次，更深入的推理是否能改善模型校准？最后，受人类天生能够复核其思维过程以验证答案有效性和置信度的启发，我们提出：推理模型能否通过明确地推理其思维链轨迹来改善校准？我们引入了内省不确定性量化（UQ）来探索这一方向。在对最先进的推理模型在广泛基准测试中的广泛评估中，我们发现推理模型：(i) 通常过于自信，自我表达的置信度估计常常超过85%，特别是对于不正确的响应；(ii) 随着更深入的推理变得更加过度自信；(iii) 可以通过内省变得更好地校准（例如o3-Mini和DeepSeek R1），但并非普遍适用（例如Claude 3.7 Sonnet的校准反而更差）。最后，我们总结了设计必要的不确定性量化基准和改进推理模型校准的重要研究方向。", "summary": "尽管推理语言模型在性能上取得了显著进展，但它们普遍存在过度自信和生成错误响应（幻觉）的问题。本研究旨在通过不确定性量化（UQ）来评估这些模型的校准性。研究发现，推理模型普遍过度自信，且更深入的推理会加剧这种现象。然而，通过内省（即让模型推理其思维链）可以改善部分模型的校准，但这种效果并非普遍存在。论文最后指出了未来在设计UQ基准和提高模型校准方面的重要研究方向。", "keywords": "不确定性量化, 推理模型, 校准, 过度自信, 内省", "comments": "这篇论文解决了部署推理模型时的一个关键安全问题，即模型校准和其表达不确定性的能力。引入“内省不确定性量化”是一种利用模型自身思维过程来改进校准的创新方法。研究结果显示，内省的效果并非对所有模型都一致，这凸显了校准改进的复杂性和模型特异性，暗示目前可能不存在普适的解决方案。"}}
{"id": "2507.13949", "title": "Exploiting Primacy Effect To Improve Large Language Models", "authors": ["Bianca Raimondi", "Maurizio Gabbrielli"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted by RANLP 2025", "url": "http://arxiv.org/abs/2507.13949v1", "summary": "Large Language Models (LLMs) have become essential in many Natural Language\nProcessing (NLP) tasks, leveraging extensive pre-training and fine-tuning to\nachieve high accuracy. However, like humans, LLMs exhibit biases, particularly\npositional biases such as primacy and recency effects, which can influence the\naccuracy of the answers. The primacy effect-where items presented first are\nmore likely to be remembered or selected-plays a key role in Multiple Choice\nQuestion Answering (MCQA), where the order of answer options can affect\nprediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We\nfirst show that fine-tuning amplifies this bias, probably due to exposure to\nhuman-like patterns. Hence, we strategically leverage this effect by reordering\nresponse options based on semantic similarity to the query, without requiring\nknowledge of the correct answer. Our experimental results show that this\napproach significantly improves performance in MCQA. More generally, our\nfindings underscore the dual nature of biases as both challenges and\nopportunities, offering insights for bias-aware model design and NLP\napplications.", "comment": "Accepted by RANLP 2025", "pdf_url": "http://arxiv.org/pdf/2507.13949v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "利用首因效应改进大型语言模型", "tldr": "本研究发现微调会加剧大型语言模型的首因偏差，并提出通过根据语义相似性重新排序响应选项来利用此效应，从而显著提高多项选择问答性能。", "motivation": "大型语言模型（LLMs）在自然语言处理任务中表现出位置偏差，特别是首因效应，这会影响答案的准确性。在多项选择问答（MCQA）中，选项顺序会影响预测结果。研究发现微调会放大这种首因偏差。", "method": "通过根据响应选项与查询的语义相似性来重新排序选项，从而策略性地利用首因效应，而无需知道正确答案。", "result": "实验结果表明，这种方法显著提高了多项选择问答（MCQA）的性能。", "conclusion": "偏见既是挑战也是机遇，本研究为偏差感知模型设计和自然语言处理应用提供了见解。", "translation": "大型语言模型（LLMs）已成为许多自然语言处理（NLP）任务中不可或缺的一部分，它们利用广泛的预训练和微调来实现高准确性。然而，与人类一样，LLMs 也表现出偏差，特别是位置偏差，如首因效应和近因效应，这会影响答案的准确性。首因效应——即首先呈现的项更有可能被记住或选择——在多项选择问答（MCQA）中发挥着关键作用，其中答案选项的顺序会影响预测结果。本研究重点关注微调LLMs中的首因偏差：我们首先表明微调会放大这种偏差，这可能归因于暴露于类似人类的模式。因此，我们通过根据与查询的语义相似性重新排序响应选项来策略性地利用这种效应，而无需知道正确答案。我们的实验结果表明，这种方法显著提高了MCQA的性能。更普遍地说，我们的发现强调了偏差的双重性质，即既是挑战也是机遇，为偏差感知模型设计和NLP应用提供了见解。", "summary": "本文探讨了大型语言模型（LLMs）中的首因效应，发现微调会加剧这种位置偏差。研究提出了一种策略，通过根据语义相似性重新排序多项选择问答（MCQA）中的答案选项，来利用而非消除这种偏差。实验证明，这种方法显著提升了MCQA的性能，并指出偏差可以被视为改进模型设计的机会。", "keywords": "大型语言模型, 首因效应, 位置偏差, 多项选择问答, 语义相似性", "comments": "这项研究的创新之处在于，它没有试图消除LLM中的固有偏差，而是巧妙地利用了“首因效应”来提高模型性能。这提供了一个新的视角，即某些偏差并非总是负面因素，通过策略性地利用它们，反而可以优化模型表现。这种“偏差即机遇”的理念对于未来偏差感知模型的设计具有重要意义。"}}
{"id": "2502.04589", "title": "PASE: A Massively Parallel Augmented Subspace Eigensolver for Large Scale Eigenvalue Problems", "authors": ["Yangfei Liao", "Haochen Liu", "Hehu Xie", "Zijing Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      25pages, 6 figures", "url": "http://arxiv.org/abs/2502.04589v2", "summary": "In this paper, we present a novel parallel augmented subspace method and\nbuild a package Parallel Augmented Subspace Eigensolver (PASE) for solving\nlarge scale eigenvalue problems by the massively parallel finite element\ndiscretization. Based on the augmented subspace, solving high dimensional\neigenvalue problems can be transformed to solving the corresponding linear\nequations and low dimensional eigenvalue problems on the augmented subspace.\nThus the complexity of solving the eigenvalue problems by augmented subspace\nmethod will be comparable to that of solving the same dimensinal linear\nequations. In order to improve the scalability and efficiency, we also present\nsome implementing techniques for the parallel augmented subspace method. Based\non parallel augmented subspace method and the concerned implementing\ntechniques, a package PASE is built for solving large scale eigenvalue\nproblems. Some numerical examples are provided to validate the efficiency and\nscalability of the proposed numerical methods.", "comment": "25pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2502.04589v2", "cate": "math.NA", "date": "2025-02-07", "updated": "2025-07-17", "AI": {"title_translation": "PASE: 大规模特征值问题的海量并行增强子空间特征求解器", "tldr": "提出一种新的并行增强子空间方法PASE，用于高效解决大规模特征值问题，通过将其转化为线性方程组和低维特征值问题，并验证了其效率和可扩展性。", "motivation": "解决大规模特征值问题，尤其是在海量并行有限元离散化背景下，需要一种高效且可扩展的方法。", "method": "提出一种新颖的并行增强子空间方法，并构建了PASE软件包。该方法将高维特征值问题转化为求解对应的线性方程组和增强子空间上的低维特征值问题。同时，还提出了并行增强子空间方法的实现技术以提高可扩展性和效率。", "result": "通过数值例子验证了所提出数值方法的效率和可扩展性。增强子空间方法求解特征值问题的复杂度与求解相同维数线性方程组的复杂度相当。", "conclusion": "PASE软件包和所提出的并行增强子空间方法能够高效且可扩展地解决大规模特征值问题。", "translation": "在本文中，我们提出了一种新颖的并行增强子空间方法，并构建了一个名为并行增强子空间特征求解器（PASE）的软件包，用于通过海量并行有限元离散化解决大规模特征值问题。基于增强子空间，解决高维特征值问题可以转化为解决相应的线性方程组和增强子空间上的低维特征值问题。因此，通过增强子空间方法解决特征值问题的复杂度将与解决相同维数线性方程组的复杂度相当。为了提高可扩展性和效率，我们还提出了一些并行增强子空间方法的实现技术。基于并行增强子空间方法和相关实现技术，构建了PASE软件包用于解决大规模特征值问题。提供了一些数值例子来验证所提出数值方法的效率和可扩展性。", "summary": "本文介绍了一种名为PASE（并行增强子空间特征求解器）的新型并行增强子空间方法及其软件包，旨在解决大规模特征值问题。该方法通过将高维特征值问题转化为求解线性方程组和低维特征值问题来降低计算复杂度，使其与求解同维度线性方程组的复杂度相当。为提升可扩展性和效率，文中还提出了相应的实现技术。数值例子验证了所提方法的有效性和高性能。", "keywords": "特征值问题, 并行计算, 增强子空间, 有限元离散化, PASE", "comments": "这项工作创新性地将增强子空间方法与并行计算相结合，并通过转化为线性方程组和低维问题显著降低了大规模特征值问题的计算复杂度。PASE软件包的开发及其实现技术的提出，进一步提升了该方法在实际应用中的可扩展性和效率，对于解决科学和工程领域中的大型计算问题具有重要意义。"}}
{"id": "2507.13886", "title": "Effects of Cognitive Distraction and Driving Environment Complexity on Adaptive Cruise Control Use and Its Impact on Driving Performance: A Simulator Study", "authors": ["Anaïs Halin", "Marc Van Droogenbroeck", "Christel Devue"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13886v1", "summary": "In this simulator study, we adopt a human-centered approach to explore\nwhether and how drivers' cognitive state and driving environment complexity\ninfluence reliance on driving automation features. Besides, we examine whether\nsuch reliance affects driving performance. Participants operated a vehicle\nequipped with adaptive cruise control (ACC) in a simulator across six\npredefined driving scenarios varying in traffic conditions while either\nperforming a cognitively demanding task (i.e., responding to mental\ncalculations) or not. Throughout the experiment, participants had to respect\nspeed limits and were free to activate or deactivate ACC. In complex driving\nenvironments, we found that the overall ACC engagement time was lower compared\nto less complex driving environments. We observed no significant effect of\ncognitive load on ACC use. Furthermore, while ACC use had no effect on the\nnumber of lane changes, it impacted the speed limits compliance and improved\nlateral control.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13886v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "认知分心和驾驶环境复杂性对自适应巡航控制使用及其对驾驶性能影响：一项模拟器研究", "tldr": "该模拟器研究发现，复杂驾驶环境降低了ACC使用时间，认知负荷对ACC使用无显著影响，且ACC使用能改善横向控制和限速遵守，但对变道次数无影响。", "motivation": "探索驾驶员的认知状态和驾驶环境复杂性如何影响对驾驶自动化功能（如ACC）的依赖，以及这种依赖是否影响驾驶性能。", "method": "在模拟器中，参与者驾驶配备ACC的车辆，经历六种不同交通条件的预设驾驶场景，同时进行或不进行认知负荷任务（心算）。参与者需遵守限速并可自由启停ACC。", "result": "1. 在复杂驾驶环境中，ACC总使用时间低于简单环境。2. 认知负荷对ACC使用无显著影响。3. ACC使用对变道次数无影响。4. ACC使用影响了限速遵守并改善了横向控制。", "conclusion": "复杂驾驶环境会减少ACC的使用，但认知负荷对其使用影响不显著。ACC的使用可以提升部分驾驶性能（限速遵守和横向控制），但对其他方面（变道）无影响。", "translation": "在这项模拟器研究中，我们采用以人为中心的方法，探讨驾驶员的认知状态和驾驶环境复杂性是否以及如何影响对驾驶自动化功能的依赖。此外，我们还考察了这种依赖是否影响驾驶性能。参与者在模拟器中操作一辆配备自适应巡航控制（ACC）的车辆，经历六种交通条件各异的预设驾驶场景，同时进行（即响应心算）或不进行认知要求高的任务。在整个实验过程中，参与者必须遵守速度限制，并可以自由激活或停用ACC。在复杂的驾驶环境中，我们发现ACC的总启用时间低于复杂度较低的驾驶环境。我们没有观察到认知负荷对ACC使用有显著影响。此外，尽管ACC使用对变道次数没有影响，但它影响了对速度限制的遵守并改善了横向控制。", "summary": "本模拟器研究以人为中心，探讨了认知分心和驾驶环境复杂性对驾驶员自适应巡航控制（ACC）使用及其对驾驶性能的影响。研究发现，在复杂驾驶环境中ACC使用时间减少，但认知负荷对ACC使用无显著影响。ACC使用虽不影响变道次数，却能提升限速遵守并改善横向控制。", "keywords": "自适应巡航控制, 认知分心, 驾驶环境复杂性, 驾驶性能, 模拟器研究", "comments": "这项研究通过模拟器实验，深入探讨了认知状态和环境复杂性对ACC使用的影响，并评估了ACC使用对驾驶性能的具体作用。其创新之处在于结合了认知负荷和环境复杂性两个维度，并细化了ACC对不同驾驶性能指标的影响。研究结果对未来ACC系统设计和人机交互策略的优化具有指导意义，尤其是在复杂驾驶场景下如何提升驾驶员对自动化系统的信任和有效使用。"}}
{"id": "2507.04295", "title": "LearnLens: LLM-Enabled Personalised, Curriculum-Grounded Feedback with Educators in the Loop", "authors": ["Runcong Zhao", "Artem Bobrov", "Jiazheng Li", "Yulan He"], "categories": ["cs.CY", "cs.AI", "cs.CL", "cs.HC"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04295v3", "summary": "Effective feedback is essential for student learning but is time-intensive\nfor teachers. We present LearnLens, a modular, LLM-based system that generates\npersonalised, curriculum-aligned feedback in science education. LearnLens\ncomprises three components: (1) an error-aware assessment module that captures\nnuanced reasoning errors; (2) a curriculum-grounded generation module that uses\na structured, topic-linked memory chain rather than traditional\nsimilarity-based retrieval, improving relevance and reducing noise; and (3) an\neducator-in-the-loop interface for customisation and oversight. LearnLens\naddresses key challenges in existing systems, offering scalable, high-quality\nfeedback that empowers both teachers and students.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04295v3", "cate": "cs.CY", "date": "2025-07-06", "updated": "2025-07-18", "AI": {"title_translation": "LearnLens：LLM驱动的个性化、课程导向的教师参与式反馈系统", "tldr": "LearnLens是一个基于LLM的系统，为科学教育提供个性化、课程导向的反馈，并支持教师干预，旨在解决教师提供有效反馈耗时的问题。", "motivation": "有效的学生反馈对学习至关重要，但对教师而言耗时巨大。现有系统面临挑战，无法提供可扩展、高质量的反馈。", "method": "提出了LearnLens系统，一个模块化的、基于LLM的系统。它包含三个组件：(1) 错误感知评估模块，捕获细微推理错误；(2) 课程导向生成模块，使用结构化、主题链接的记忆链而非传统相似度检索，提高相关性并减少噪音；(3) 教师参与界面，用于定制和监督。", "result": "LearnLens能够生成个性化、课程对齐的反馈。它解决了现有系统的关键挑战，提供了可扩展、高质量的反馈，赋能教师和学生。", "conclusion": "LearnLens通过提供可扩展、高质量的反馈，赋能教师和学生，有效解决了现有反馈系统中的挑战。", "translation": "有效的反馈对于学生的学习至关重要，但对教师来说却非常耗时。我们提出了LearnLens，一个模块化的、基于大型语言模型（LLM）的系统，它能在科学教育中生成个性化、与课程对齐的反馈。LearnLens包含三个组件：(1) 一个错误感知评估模块，用于捕捉细微的推理错误；(2) 一个课程导向的生成模块，它使用结构化的、与主题相关的记忆链，而非传统的基于相似度的检索，从而提高了相关性并减少了噪音；(3) 一个教师参与的界面，用于定制和监督。LearnLens解决了现有系统中的关键挑战，提供了可扩展、高质量的反馈，赋能教师和学生。", "summary": "LearnLens是一个基于LLM的创新系统，旨在通过自动化和个性化方式为科学教育提供高效反馈。该系统包含错误感知评估、课程导向反馈生成（采用结构化记忆链）和教师参与界面三大模块。它解决了教师反馈耗时且现有系统不足的痛点，提供可扩展的高质量反馈，从而提升教学效率和学生学习体验。", "keywords": "LLM, 个性化反馈, 课程导向, 教师参与, 科学教育", "comments": "该论文的创新点在于结合了大型语言模型的能力与课程导向的结构化记忆链，这有望显著提高反馈的相关性和准确性。同时，\"教师参与\"的设计确保了反馈的质量和教师的控制力，使其更具实用性和可信度。该系统有望在教育领域，尤其是在个性化教学和大规模反馈方面，产生积极影响。"}}
{"id": "2507.13381", "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation", "authors": ["Rafiq Kamel", "Filippo Guerranti", "Simon Geisler", "Stephan Günnemann"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "url": "http://arxiv.org/abs/2507.13381v1", "summary": "Large Language Models (LLMs) are increasingly applied to tasks involving\nstructured inputs such as graphs. Abstract Meaning Representations (AMRs),\nwhich encode rich semantics as directed graphs, offer a rigorous testbed for\nevaluating LLMs on text generation from such structures. Yet, current methods\noften arbitrarily linearize AMRs, discarding key structural cues, or rely on\narchitectures incompatible with standard LLMs. We introduce SAFT, a\nstructure-aware fine-tuning approach that injects graph topology into\npretrained LLMs without architectural changes. We compute direction-sensitive\npositional encodings from the magnetic Laplacian of transformed AMRs and\nproject them into the embedding space of the LLM. While possibly applicable to\nany graph-structured inputs, we focus on AMR-to-text generation as a\nrepresentative and challenging benchmark. SAFT sets a new state-of-the-art on\nAMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph\ncomplexity, highlighting the value of structure-aware representations in\nenhancing LLM performance. SAFT offers a general and effective pathway for\nbridging structured data and language models.", "comment": "Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "pdf_url": "http://arxiv.org/pdf/2507.13381v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "SAFT：面向AMR到文本生成的结构感知大型语言模型微调", "tldr": "SAFT提出了一种结构感知微调方法，通过磁拉普拉斯算子将图拓扑注入大型语言模型，在不改变模型架构的情况下，显著提升了AMR到文本生成的性能，并在AMR 3.0上达到了新的SOTA。", "motivation": "当前大型语言模型处理图等结构化输入时，常任意线性化抽象语义表示（AMR），丢失关键结构信息，或依赖于与标准大型语言模型不兼容的架构。这限制了大型语言模型在结构化输入任务上的表现。", "method": "SAFT是一种结构感知微调方法，它在不改变大型语言模型架构的情况下，将图拓扑注入预训练的大型语言模型。具体方法是，从转换后的AMR的磁拉普拉斯算子中计算方向敏感的位置编码，并将其投影到大型语言模型的嵌入空间中。", "result": "SAFT在AMR 3.0上取得了新的最先进（SOTA）性能，相较于基线模型，BLEU分数提升了3.5。性能提升与图复杂性呈正相关，凸显了结构感知表示在提升大型语言模型性能方面的价值。", "conclusion": "SAFT为连接结构化数据和语言模型提供了一条通用且有效的途径。", "translation": "大型语言模型（LLMs）正越来越多地应用于涉及结构化输入（如图）的任务。抽象语义表示（AMRs）以有向图的形式编码丰富的语义，为评估LLMs从这些结构生成文本的能力提供了严格的测试平台。然而，当前的方法通常任意地线性化AMRs，丢弃了关键的结构线索，或者依赖于与标准LLMs不兼容的架构。我们引入了SAFT，一种结构感知微调方法，它在不改变架构的情况下将图拓扑注入预训练的LLMs。我们从转换后的AMRs的磁拉普拉斯算子计算方向敏感的位置编码，并将其投影到LLM的嵌入空间中。虽然可能适用于任何图结构输入，但我们专注于AMR到文本生成，将其作为一个具有代表性和挑战性的基准。SAFT在AMR 3.0上取得了新的最先进（state-of-the-art）性能，相比基线模型，BLEU分数提高了3.5。性能提升与图复杂性呈正比，突出了结构感知表示在增强LLM性能方面的价值。SAFT为连接结构化数据和语言模型提供了一条通用且有效的途径。", "summary": "该论文提出了SAFT，一种结构感知微调方法，旨在解决大型语言模型在处理图结构化输入（如抽象语义表示AMR）时，现有方法丢失结构信息或架构不兼容的问题。SAFT通过计算转换后AMR的磁拉普拉斯算子生成方向敏感的位置编码，并将其注入大型语言模型的嵌入空间，从而在不改变模型架构的前提下，将图拓扑信息融入模型。在AMR到文本生成任务中，SAFT在AMR 3.0数据集上取得了新的SOTA，BLEU分数相对基线提升3.5，并证明了结构感知表示对提升大型语言模型性能的有效性和通用性。", "keywords": "大型语言模型, 结构感知微调, 抽象语义表示, AMR到文本生成, 磁拉普拉斯算子", "comments": "SAFT的创新点在于，它提供了一种无需修改大型语言模型现有架构即可注入图结构信息的方法，这极大地提高了其在处理复杂结构化数据时的通用性和适用性。通过利用磁拉普拉斯算子生成方向敏感的位置编码，SAFT有效地捕获了图的拓扑结构，并将其转化为LLM可理解的嵌入。其在AMR到文本生成任务上取得的显著性能提升，特别是随着图复杂性增加而带来的收益，强调了结构感知表示的重要性。这为LLMs处理更广泛的结构化数据任务，如知识图谱推理、程序生成等，开辟了新的途径。"}}
{"id": "2402.14009", "title": "Geometry-Informed Neural Networks", "authors": ["Arturs Berzins", "Andreas Radler", "Eric Volkmann", "Sebastian Sanokowski", "Sepp Hochreiter", "Johannes Brandstetter"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Code available at this https URL", "url": "http://arxiv.org/abs/2402.14009v4", "summary": "Geometry is a ubiquitous tool in computer graphics, design, and engineering.\nHowever, the lack of large shape datasets limits the application of\nstate-of-the-art supervised learning methods and motivates the exploration of\nalternative learning strategies. To this end, we introduce geometry-informed\nneural networks (GINNs) -- a framework for training shape-generative neural\nfields without data by leveraging user-specified design requirements in the\nform of objectives and constraints. By adding diversity as an explicit\nconstraint, GINNs avoid mode-collapse and can generate multiple diverse\nsolutions, often required in geometry tasks. Experimentally, we apply GINNs to\nseveral problems spanning physics, geometry, and engineering design, showing\ncontrol over geometrical and topological properties, such as surface smoothness\nor the number of holes. These results demonstrate the potential of training\nshape-generative models without data, paving the way for new generative design\napproaches without large datasets.", "comment": "Code available at\n  https://github.com/ml-jku/GINNs-Geometry-informed-Neural-Networks", "pdf_url": "http://arxiv.org/pdf/2402.14009v4", "cate": "cs.LG", "date": "2024-02-21", "updated": "2025-07-18", "AI": {"title_translation": "几何信息神经网络", "tldr": "GINN是一种无需大量数据，通过利用用户指定的几何设计要求来训练形状生成神经网络的方法，能生成多样化的解决方案并避免模式崩溃。", "motivation": "缺乏大型形状数据集限制了现有监督学习方法在计算机图形学、设计和工程中的应用。", "method": "引入了几何信息神经网络（GINNs），该框架通过利用用户指定的设计要求（以目标和约束的形式）来训练形状生成神经场，无需数据。通过添加多样性作为显式约束，GINNs避免了模式崩溃，并能生成多个多样化的解决方案。", "result": "将GINNs应用于物理、几何和工程设计中的多个问题，展示了对几何和拓扑属性（如表面平滑度或孔洞数量）的控制能力。", "conclusion": "实验结果证明了在没有大型数据集的情况下训练形状生成模型的潜力，为新的生成设计方法铺平了道路。", "translation": "几何学是计算机图形学、设计和工程领域中无处不在的工具。然而，大型形状数据集的缺乏限制了最先进的监督学习方法的应用，并促使人们探索替代学习策略。为此，我们引入了几何信息神经网络（GINNs）——一个通过利用用户指定的、以目标和约束形式存在的设计要求来训练形状生成神经场的无数据框架。通过将多样性作为显式约束，GINNs避免了模式崩溃，并且可以生成多个多样化的解决方案，这在几何任务中通常是必需的。实验上，我们将GINNs应用于跨越物理学、几何学和工程设计的几个问题，展示了对几何和拓扑属性的控制能力，例如表面平滑度或孔洞数量。这些结果证明了在没有数据的情况下训练形状生成模型的潜力，为无需大型数据集的新型生成设计方法铺平了道路。", "summary": "本文提出了一种名为几何信息神经网络（GINNs）的新框架，旨在解决缺乏大型形状数据集的问题。GINNs通过利用用户指定的设计目标和约束，无需大量数据即可训练形状生成神经场。通过引入多样性约束，GINNs能够避免模式崩溃并生成多样化的几何解决方案。实验证明，GINNs在物理、几何和工程设计问题中能有效控制几何和拓扑属性，展现了无需数据的生成模型在设计领域的巨大潜力。", "keywords": "几何信息神经网络, 形状生成, 无数据训练, 神经场, 几何设计", "comments": "这篇论文的创新点在于提出了一个无需大型数据集即可训练形状生成模型的方法，通过将几何设计要求转化为目标和约束，并引入多样性约束来避免模式崩溃。这对于数据稀缺的几何和工程设计领域具有重要意义，为生成设计开辟了新的途径。"}}
{"id": "2507.06602", "title": "Generalization in Reinforcement Learning for Radio Access Networks", "authors": ["Burak Demirel", "Yu Wang", "Cristian Tatino", "Pablo Soldati"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06602v2", "summary": "Modern RAN operate in highly dynamic and heterogeneous environments, where\nhand-tuned, rule-based RRM algorithms often underperform. While RL can surpass\nsuch heuristics in constrained settings, the diversity of deployments and\nunpredictable radio conditions introduce major generalization challenges.\nData-driven policies frequently overfit to training conditions, degrading\nperformance in unseen scenarios. To address this, we propose a\ngeneralization-centered RL framework for RAN control that: (i) robustly\nreconstructs dynamically varying states from partial and noisy observations,\nwhile encoding static and semi-static information, such as radio nodes, cell\nattributes, and their topology, through graph representations; (ii) applies\ndomain randomization to broaden the training distribution; and (iii)\ndistributes data generation across multiple actors while centralizing training\nin a cloud-compatible architecture aligned with O-RAN principles. Although\ngeneralization increases computational and data-management complexity, our\ndistributed design mitigates this by scaling data collection and training\nacross diverse network conditions. Applied to downlink link adaptation in five\n5G benchmarks, our policy improves average throughput and spectral efficiency\nby ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and\nby >20% under high mobility. It matches specialized RL in full-buffer traffic\nand achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks,\nrespectively. In nine-cell deployments, GAT models offer 30% higher throughput\nover MLP baselines. These results, combined with our scalable architecture,\noffer a path toward AI-native 6G RAN using a single, generalizable RL agent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06602v2", "cate": "cs.LG", "date": "2025-07-09", "updated": "2025-07-18", "AI": {"title_translation": "无线接入网络中强化学习的泛化能力", "tldr": "本文提出了一种以泛化为中心的强化学习框架，用于无线接入网络（RAN）控制，以解决传统方法和现有RL方法在动态环境中泛化能力不足的问题。", "motivation": "现代无线接入网络（RAN）在高度动态和异构环境中运行，导致传统的人工调优、基于规则的无线电资源管理（RRM）算法性能不佳。虽然强化学习（RL）在受限设置中可以超越这些启发式方法，但部署的多样性和不可预测的无线电条件带来了严重的泛化挑战，数据驱动的策略经常过度拟合训练条件，导致在未见场景中性能下降。", "method": "本研究提出了一种以泛化为中心的RAN控制强化学习框架，该框架包含三个主要组成部分：(i) 能够从部分和噪声观测中稳健地重建动态变化的状态，并通过图表示编码静态和半静态信息（如无线电节点、小区属性和拓扑）；(ii) 应用域随机化技术以拓宽训练数据的分布；(iii) 采用分布式数据生成，在多个参与者之间分配数据收集，同时将训练集中在与O-RAN原则兼容的云架构中。", "result": "在五个5G基准测试中，该策略应用于下行链路自适应，相较于OLLA基线（10% BLER目标），在全缓冲区MIMO/mMIMO中，平均吞吐量和频谱效率提高了约10%；在高移动性下，性能提升超过20%。在全缓冲区流量中，其性能与专用强化学习方法相当，并在eMBB和混合流量基准测试中分别实现了高达4倍和2倍的增益。在九小区部署中，GAT模型比MLP基线提供了30%更高的吞吐量。", "conclusion": "本研究提出的可扩展架构及其取得的成果，为使用单一、可泛化的强化学习智能体实现AI原生6G无线接入网络提供了可行途径。", "translation": "现代RAN在高度动态和异构的环境中运行，其中人工调优的、基于规则的RRM算法往往表现不佳。虽然RL在受限设置中可以超越这些启发式方法，但部署的多样性和不可预测的无线电条件带来了主要的泛化挑战。数据驱动的策略经常过度拟合训练条件，导致在未见场景中性能下降。为了解决这个问题，我们提出了一种以泛化为中心的RAN控制RL框架，该框架：(i) 从部分和噪声观测中稳健地重建动态变化的状态，同时通过图表示编码静态和半静态信息，如无线电节点、小区属性及其拓扑；(ii) 应用域随机化以拓宽训练分布；(iii) 在多个参与者之间分配数据生成，同时将训练集中在与O-RAN原则一致的云兼容架构中。尽管泛化增加了计算和数据管理复杂性，但我们的分布式设计通过在多样化的网络条件下扩展数据收集和训练来缓解了这一点。应用于五个5G基准测试中的下行链路自适应，我们的策略在全缓冲区MIMO/mMIMO中，相较于OLLA基线（10% BLER目标），平均吞吐量和频谱效率提高了约10%；在高移动性下提高了20%以上。它在全缓冲区流量中与专用RL相匹配，并在eMBB和混合流量基准测试中分别实现了高达4倍和2倍的增益。在九小区部署中，GAT模型比MLP基线提供了30%更高的吞吐量。这些结果，结合我们可扩展的架构，为使用单一、可泛化的RL代理实现AI原生6G RAN提供了途径。", "summary": "本文提出了一种以泛化为中心的强化学习（RL）框架，用于无线接入网络（RAN）控制，旨在解决传统方法在动态环境中性能不足以及现有RL方法易于过拟合的问题。该框架通过使用图表示进行鲁棒的状态重建、应用域随机化来拓宽训练分布，并采用分布式数据生成与集中式训练相结合的架构。在5G基准测试中的实验结果表明，该框架显著提高了吞吐量和频谱效率，突显了其在实现可扩展、AI原生6G RAN方面的巨大潜力。", "keywords": "强化学习, 无线接入网络, 泛化, 域随机化, 5G", "comments": "该论文解决了将强化学习应用于实际无线接入网络中的一个关键挑战：泛化能力。所提出的框架结合了多项创新技术，如利用图表示编码静态信息、域随机化以及分布式训练架构，这些技术非常适合无线接入网络动态异构的特性。在各种5G场景中取得的强大实证结果突显了其重要的实际意义和未来在AI原生6G系统中的潜力。"}}
{"id": "2507.14116", "title": "Quantum Boltzmann Machines using Parallel Annealing for Medical Image Classification", "authors": ["Daniëlle Schuman", "Mark V. Seebode", "Tobias Rohe", "Maximilian Balthasar Mansky", "Michael Schroedl-Baumann", "Jonas Stein", "Claudia Linnhoff-Popien", "Florian Krellner"], "categories": ["quant-ph", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 5 figures (10 if counting subfigures), 2 tables. To be published in the proceedings of the 2025 IEEE International Conference on Quantum Computing and Engineering (QCE)", "url": "http://arxiv.org/abs/2507.14116v1", "summary": "Exploiting the fact that samples drawn from a quantum annealer inherently\nfollow a Boltzmann-like distribution, annealing-based Quantum Boltzmann\nMachines (QBMs) have gained increasing popularity in the quantum research\ncommunity. While they harbor great promises for quantum speed-up, their usage\ncurrently stays a costly endeavor, as large amounts of QPU time are required to\ntrain them. This limits their applicability in the NISQ era. Following the idea\nof No\\`e et al. (2024), who tried to alleviate this cost by incorporating\nparallel quantum annealing into their unsupervised training of QBMs, this paper\npresents an improved version of parallel quantum annealing that we employ to\ntrain QBMs in a supervised setting. Saving qubits to encode the inputs, the\nlatter setting allows us to test our approach on medical images from the\nMedMNIST data set (Yang et al., 2023), thereby moving closer to real-world\napplicability of the technology. Our experiments show that QBMs using our\napproach already achieve reasonable results, comparable to those of\nsimilarly-sized Convolutional Neural Networks (CNNs), with markedly smaller\nnumbers of epochs than these classical models. Our parallel annealing technique\nleads to a speed-up of almost 70 % compared to regular annealing-based BM\nexecutions.", "comment": "12 pages, 5 figures (10 if counting subfigures), 2 tables. To be\n  published in the proceedings of the 2025 IEEE International Conference on\n  Quantum Computing and Engineering (QCE)", "pdf_url": "http://arxiv.org/pdf/2507.14116v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "量子玻尔兹曼机在医学图像分类中的并行退火应用", "tldr": "本文提出一种改进的并行量子退火方法，用于监督式训练量子玻尔兹曼机，并在医学图像分类中取得了与CNN相当的性能，同时显著减少了训练时间。", "motivation": "现有的退火量子玻尔兹曼机（QBMs）训练成本高昂，需要大量的QPU时间，这限制了它们在NISQ时代的实际应用。", "method": "本文提出了一种改进的并行量子退火方法，用于在监督式设置下训练量子玻ol兹曼机（QBMs），并通过节省用于编码输入的量子比特，将其应用于MedMNIST数据集的医学图像分类。", "result": "使用该方法的QBMs在医学图像分类中取得了与同等规模的卷积神经网络（CNNs）相当的合理结果，所需训练周期（epochs）显著少于经典模型。并行退火技术相比常规退火玻尔兹曼机执行速度提升了近70%。", "conclusion": "改进的并行量子退火技术可以有效降低量子玻尔兹曼机的训练成本和时间，使其在医学图像分类等实际应用中展现出潜力，并有望在NISQ时代推广应用。", "translation": "利用量子退火器抽取的样本固有地遵循玻尔兹曼类分布这一事实，基于退火的量子玻尔兹曼机（QBMs）在量子研究社区中日益普及。尽管它们在量子加速方面前景广阔，但目前其使用仍然是一项成本高昂的尝试，因为训练它们需要大量的QPU时间。这限制了它们在NISQ时代的应用。遵循Noe等（2024）的想法，他们试图通过将并行量子退火纳入其QBM的无监督训练来减轻这一成本，本文提出了一种改进的并行量子退火版本，我们将其用于监督式训练QBMs。通过节省用于编码输入的量子比特，后一种设置使我们能够使用MedMNIST数据集（Yang等，2023）中的医学图像测试我们的方法，从而更接近该技术的实际应用。我们的实验表明，采用我们方法的QBMs已经取得了合理的结果，与同等规模的卷积神经网络（CNNs）相当，并且所需的训练周期明显少于这些经典模型。我们的并行退火技术相比常规基于退火的BM执行速度提升了近70%。", "summary": "本文提出了一种改进的并行量子退火方法，用于监督式训练量子玻尔兹曼机（QBMs），以解决现有QBM训练成本高昂的问题。该方法通过节省量子比特来编码输入，并在MedMNIST医学图像数据集上进行了测试。实验结果表明，该方法训练的QBMs在性能上可与同等规模的卷积神经网络（CNNs）媲美，且训练周期显著减少，同时并行退火技术实现了近70%的速度提升，从而推动了QBMs在现实世界应用中的可行性。", "keywords": "量子玻尔兹曼机, 并行退火, 医学图像分类, 量子机器学习, NISQ", "comments": "本文的创新点在于提出了改进的并行量子退火方法，将其应用于监督式量子玻尔兹曼机训练，并成功应用于医学图像分类，这在NISQ时代具有重要的实际意义。该方法不仅提高了训练效率，还降低了资源消耗，为量子机器学习在实际应用中的推广提供了新的思路。"}}
{"id": "2507.13425", "title": "CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction", "authors": ["Sirui Wang", "Zhou Guan", "Bingxi Zhao", "Tongjia Gu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13425v1", "summary": "Accurate prediction of driving intention is key to enhancing the safety and\ninteractive efficiency of human-machine co-driving systems. It serves as a\ncornerstone for achieving high-level autonomous driving. However, current\napproaches remain inadequate for accurately modeling the complex\nspatio-temporal interdependencies and the unpredictable variability of human\ndriving behavior. To address these challenges, we propose CaSTFormer, a Causal\nSpatio-Temporal Transformer to explicitly model causal interactions between\ndriver behavior and environmental context for robust intention prediction.\nSpecifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)\nmechanism for precise temporal alignment of internal and external feature\nstreams, a Causal Pattern Extraction (CPE) module that systematically\neliminates spurious correlations to reveal authentic causal dependencies, and\nan innovative Feature Synthesis Network (FSN) that adaptively synthesizes these\npurified representations into coherent spatio-temporal inferences. We evaluate\nthe proposed CaSTFormer on the public Brain4Cars dataset, and it achieves\nstate-of-the-art performance. It effectively captures complex causal\nspatio-temporal dependencies and enhances both the accuracy and transparency of\ndriving intention prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13425v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "CaSTFormer：用于驾驶意图预测的因果时空Transformer", "tldr": "CaSTFormer是一个因果时空Transformer模型，通过明确建模驾驶员行为和环境背景之间的因果互动，提高了驾驶意图预测的准确性和透明度。", "motivation": "准确预测驾驶意图对于提高人机共驾系统的安全性和交互效率至关重要，是实现高级别自动驾驶的基础。然而，现有方法在准确建模复杂的时空相互依赖性以及人类驾驶行为的不可预测变异性方面仍显不足。", "method": "本文提出了CaSTFormer，一个因果时空Transformer模型，用于明确建模驾驶员行为和环境背景之间的因果互动，以实现鲁棒的意图预测。CaSTFormer引入了新颖的互惠位移融合（RSF）机制，用于内部和外部特征流的精确时间对齐；一个因果模式提取（CPE）模块，系统性地消除虚假相关性以揭示真实的因果依赖性；以及一个创新的特征合成网络（FSN），自适应地将这些纯化后的表示合成为连贯的时空推断。", "result": "CaSTFormer在公共Brain4Cars数据集上进行了评估，并取得了最先进的性能。它有效地捕获了复杂的因果时空依赖性。", "conclusion": "CaSTFormer模型通过明确建模因果互动，显著提升了驾驶意图预测的准确性和透明度，解决了现有方法在处理复杂时空依赖和行为变异性方面的不足。", "translation": "准确预测驾驶意图是提高人机共驾系统安全性和交互效率的关键，也是实现高级别自动驾驶的基石。然而，现有方法在准确建模复杂的时空相互依赖性以及人类驾驶行为的不可预测变异性方面仍显不足。为了解决这些挑战，我们提出了CaSTFormer，一个因果时空Transformer，旨在明确建模驾驶员行为和环境背景之间的因果互动，以实现鲁棒的意图预测。具体而言，CaSTFormer引入了一种新颖的互惠位移融合（RSF）机制，用于内部和外部特征流的精确时间对齐；一个因果模式提取（CPE）模块，系统性地消除虚假相关性以揭示真实的因果依赖性；以及一个创新的特征合成网络（FSN），自适应地将这些纯化后的表示合成为连贯的时空推断。我们在公共Brain4Cars数据集上评估了所提出的CaSTFormer，并取得了最先进的性能。它有效地捕获了复杂的因果时空依赖性，并提高了驾驶意图预测的准确性和透明度。", "summary": "本研究提出了CaSTFormer，一个用于驾驶意图预测的因果时空Transformer模型。该模型旨在通过明确建模驾驶员行为与环境背景之间的因果互动来解决现有方法在处理复杂时空依赖性和行为变异性方面的不足。CaSTFormer包含互惠位移融合（RSF）机制、因果模式提取（CPE）模块和特征合成网络（FSN）。在Brain4Cars数据集上的评估表明，CaSTFormer取得了最先进的性能，并提升了预测的准确性和透明度。", "keywords": "驾驶意图预测, 因果建模, 时空Transformer, 自动驾驶, CaSTFormer", "comments": "CaSTFormer的创新之处在于其明确建模因果关系的方法，这对于理解和预测复杂的人类驾驶行为至关重要。通过引入RSF、CPE和FSN模块，该模型能够有效处理时空对齐、消除虚假相关性并合成纯化特征，从而提高了预测的鲁棒性和透明度。这种因果建模方法有望为自动驾驶系统的决策制定提供更可靠的依据。"}}
{"id": "2507.13797", "title": "DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance", "authors": ["Huu-Phu Do", "Yu-Wei Chen", "Yi-Cheng Liao", "Chi-Wei Hsiao", "Han-Yang Wang", "Wei-Chen Chiu", "Ching-Chun Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2507.13797v1", "summary": "Blind Face Restoration aims to recover high-fidelity, detail-rich facial\nimages from unknown degraded inputs, presenting significant challenges in\npreserving both identity and detail. Pre-trained diffusion models have been\nincreasingly used as image priors to generate fine details. Still, existing\nmethods often use fixed diffusion sampling timesteps and a global guidance\nscale, assuming uniform degradation. This limitation and potentially imperfect\ndegradation kernel estimation frequently lead to under- or over-diffusion,\nresulting in an imbalance between fidelity and quality. We propose\nDynFaceRestore, a novel blind face restoration approach that learns to map any\nblindly degraded input to Gaussian blurry images. By leveraging these blurry\nimages and their respective Gaussian kernels, we dynamically select the\nstarting timesteps for each blurry image and apply closed-form guidance during\nthe diffusion sampling process to maintain fidelity. Additionally, we introduce\na dynamic guidance scaling adjuster that modulates the guidance strength across\nlocal regions, enhancing detail generation in complex areas while preserving\nstructural fidelity in contours. This strategy effectively balances the\ntrade-off between fidelity and quality. DynFaceRestore achieves\nstate-of-the-art performance in both quantitative and qualitative evaluations,\ndemonstrating robustness and effectiveness in blind face restoration.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.13797v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DynFaceRestore：在扩散引导的盲人脸修复中通过动态模糊水平映射和引导平衡保真度与质量", "tldr": "DynFaceRestore提出了一种新颖的盲人脸修复方法，通过动态模糊水平映射和引导，解决了现有扩散模型在保真度和质量之间平衡不佳的问题，并实现了最先进的性能。", "motivation": "现有的扩散模型在盲人脸修复中常使用固定的扩散采样时间步和全局引导尺度，假设退化是均匀的。这种局限性以及潜在的不完善退化核估计，经常导致欠扩散或过扩散，从而造成保真度与质量之间的不平衡。", "method": "本文提出了DynFaceRestore，一种新颖的盲人脸修复方法。它学习将任何盲退化输入映射到高斯模糊图像。利用这些模糊图像及其高斯核，该方法动态选择每个模糊图像的起始时间步，并在扩散采样过程中应用闭合形式的引导以保持保真度。此外，引入了一个动态引导缩放调节器，用于在局部区域调节引导强度，以增强复杂区域的细节生成，同时保持轮廓的结构保真度。", "result": "DynFaceRestore在定量和定性评估中均达到了最先进的性能，在盲人脸修复中展示了鲁棒性和有效性。", "conclusion": "DynFaceRestore通过动态模糊水平映射和引导，有效地平衡了扩散引导的盲人脸修复中保真度与质量之间的权衡，并取得了最先进的性能。", "translation": "盲人脸修复旨在从未知退化输入中恢复高保真、细节丰富的人脸图像，在保持身份和细节方面提出了重大挑战。预训练的扩散模型越来越多地被用作图像先验来生成精细细节。然而，现有方法通常使用固定的扩散采样时间步和全局引导尺度，假设退化是均匀的。这种局限性以及潜在的不完善退化核估计，经常导致欠扩散或过扩散，从而造成保真度与质量之间的不平衡。我们提出了DynFaceRestore，一种新颖的盲人脸修复方法，它学习将任何盲退化输入映射到高斯模糊图像。通过利用这些模糊图像及其各自的高斯核，我们动态选择每个模糊图像的起始时间步，并在扩散采样过程中应用闭合形式的引导以保持保真度。此外，我们引入了一个动态引导缩放调节器，用于在局部区域调节引导强度，以增强复杂区域的细节生成，同时保持轮廓的结构保真度。这一策略有效地平衡了保真度与质量之间的权衡。DynFaceRestore在定量和定性评估中均达到了最先进的性能，在盲人脸修复中展示了鲁棒性和有效性。", "summary": "DynFaceRestore是一种用于盲人脸修复的新方法，旨在解决现有扩散模型中保真度和质量难以平衡的问题。它通过学习将退化输入映射到高斯模糊图像，并动态选择扩散采样的起始时间步和应用闭合形式的引导来保持高保真度。此外，引入了动态引导缩放调节器，以局部调整引导强度，从而在复杂区域增强细节并保持结构完整性。该方法在盲人脸修复中实现了最先进的性能。", "keywords": "盲人脸修复, 扩散模型, 动态模糊水平映射, 动态引导缩放, 图像质量", "comments": "该论文的创新点在于提出了动态模糊水平映射和动态引导缩放调节器，解决了现有扩散模型在盲人脸修复中固定参数导致保真度与质量失衡的问题。通过根据图像的实际模糊程度动态调整扩散过程，DynFaceRestore能够更有效地恢复细节，同时保持身份和结构，这对于实际应用具有重要意义。"}}
{"id": "2507.14137", "title": "Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning", "authors": ["Shashanka Venkataramanan", "Valentinos Pariza", "Mohammadreza Salehi", "Lukas Knobel", "Spyros Gidaris", "Elias Ramzi", "Andrei Bursuc", "Yuki M. Asano"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14137v1", "summary": "We present Franca (pronounced Fran-ka): free one; the first fully open-source\n(data, code, weights) vision foundation model that matches and in many cases\nsurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,\nCLIP, SigLIPv2, etc. Our approach is grounded in a transparent training\npipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and\na subset of ReLAION-2B. Beyond model release, we tackle critical limitations in\nSSL clustering methods. While modern models rely on assigning image features to\nlarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to\naccount for the inherent ambiguity in clustering semantics. To address this, we\nintroduce a parameter-efficient, multi-head clustering projector based on\nnested Matryoshka representations. This design progressively refines features\ninto increasingly fine-grained clusters without increasing the model size,\nenabling both performance and memory efficiency. Additionally, we propose a\nnovel positional disentanglement strategy that explicitly removes positional\nbiases from dense representations, thereby improving the encoding of semantic\ncontent. This leads to consistent gains on several downstream benchmarks,\ndemonstrating the utility of cleaner feature spaces. Our contributions\nestablish a new standard for transparent, high-performance vision models and\nopen a path toward more reproducible and generalizable foundation models for\nthe broader AI community. The code and model checkpoints are available at\nhttps://github.com/valeoai/Franca.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14137v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Franca: 用于可扩展视觉表示学习的嵌套套娃聚类", "tldr": "Franca是一个新的全开源视觉基础模型，它通过引入基于嵌套套娃表示的多头聚类投影仪和新颖的位置解缠策略，解决了SSL聚类方法的局限性，实现了与最先进专有模型相当甚至超越的性能。", "motivation": "现代自监督学习（SSL）模型依赖于通过聚类算法将图像特征分配给大型码本，但这些方法未能解决聚类语义中固有的歧义性。此外，存在对透明、高性能视觉模型的需求。", "method": "本文提出了Franca，一个全开源的视觉基础模型。其训练流程受Web-SSL启发，使用公开数据（ImageNet-21K和ReLAION-2B子集）。为解决聚类歧义，引入了一种基于嵌套套娃表示的参数高效、多头聚类投影仪，该设计能逐步将特征细化为更精细的聚类。此外，还提出了一种新颖的位置解缠策略，用于显式消除密集表示中的位置偏差。", "result": "Franca在性能上与最先进的专有模型（如DINOv2, CLIP, SigLIPv2等）相当，并在许多情况下超越它们。其方法在多个下游基准测试中带来了持续的性能提升，证明了更清晰特征空间的实用性，并改善了语义内容的编码。", "conclusion": "Franca的贡献为透明、高性能的视觉模型树立了新标准，并为更可复现和泛化的基础模型开辟了道路。", "translation": "我们提出了Franca（发音为Fran-ka）：一个自由的、第一个完全开源（数据、代码、权重）的视觉基础模型，其性能与最先进的专有模型（例如DINOv2、CLIP、SigLIPv2等）相当，并且在许多情况下超越它们。我们的方法基于受Web-SSL启发的透明训练管道，并使用公开可用数据：ImageNet-21K和ReLAION-2B的一个子集。除了模型发布，我们还解决了SSL聚类方法中的关键局限性。虽然现代模型依赖于通过Sinkhorn-Knopp等聚类算法将图像特征分配给大型码本，但它们未能考虑聚类语义中固有的模糊性。为了解决这个问题，我们引入了一种基于嵌套套娃表示的参数高效、多头聚类投影仪。这种设计逐步将特征细化为越来越精细的聚类，而无需增加模型大小，从而实现了性能和内存效率。此外，我们提出了一种新颖的位置解缠策略，明确消除了密集表示中的位置偏差，从而改进了语义内容的编码。这在几个下游基准测试中带来了持续的增益，证明了更清晰特征空间的实用性。我们的贡献为透明、高性能的视觉模型树立了新标准，并为更可复现和泛化的基础模型为更广泛的AI社区开辟了道路。代码和模型检查点可在https://github.com/valeoai/Franca获取。", "summary": "本文介绍了Franca，一个创新的全开源视觉基础模型，其性能超越了现有专有模型。Franca采用受Web-SSL启发的透明训练流程和公开数据集。为解决自监督学习中聚类语义的模糊性，该模型引入了基于嵌套套娃表示的参数高效多头聚类投影仪，实现特征的精细化聚类而不增加模型大小，同时提升了效率。此外，Franca还提出了一种新颖的位置解缠策略，以消除位置偏差并优化语义编码。这些创新使其在多个基准测试中表现出色，为透明、可复现和泛化的视觉基础模型设定了新标准。", "keywords": "Franca, 视觉基础模型, 嵌套套娃聚类, 位置解缠, 自监督学习", "comments": "Franca的创新之处在于其完全开源的特性，以及在自监督学习中解决聚类语义模糊性的方法。通过引入嵌套套娃聚类和位置解缠策略，该模型不仅提升了性能和效率，还促进了特征空间的清晰度。其作为首个全开源模型，为AI社区提供了高度透明和可复现的研究基础，对于推动视觉基础模型的标准化和泛化具有重要意义。"}}
{"id": "2507.12426", "title": "DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition", "authors": ["Hayat Ullah", "Muhammad Ali Shafique", "Abbas Khan", "Arslan Munir"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages", "url": "http://arxiv.org/abs/2507.12426v2", "summary": "The landscape of video recognition has evolved significantly, shifting from\ntraditional Convolutional Neural Networks (CNNs) to Transformer-based\narchitectures for improved accuracy. While 3D CNNs have been effective at\ncapturing spatiotemporal dynamics, recent Transformer models leverage\nself-attention to model long-range spatial and temporal dependencies. Despite\nachieving state-of-the-art performance on major benchmarks, Transformers remain\ncomputationally expensive, particularly with dense video data. To address this,\nwe propose a lightweight Video Focal Modulation Network, DVFL-Net, which\ndistills spatiotemporal knowledge from a large pre-trained teacher into a\ncompact nano student model, enabling efficient on-device deployment. DVFL-Net\nutilizes knowledge distillation and spatial-temporal feature modulation to\nsignificantly reduce computation while preserving high recognition performance.\nWe employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal\nfocal modulation to effectively transfer both local and global context from the\nVideo-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate\nDVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it\nagainst recent state-of-the-art methods in Human Action Recognition (HAR).\nAdditionally, we conduct a detailed ablation study analyzing the impact of\nforward KL divergence. The results confirm the superiority of DVFL-Net in\nachieving an optimal balance between performance and efficiency, demonstrating\nlower memory usage, reduced GFLOPs, and strong accuracy, making it a practical\nsolution for real-time HAR applications.", "comment": "17 pages", "pdf_url": "http://arxiv.org/pdf/2507.12426v2", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "DVFL-Net：一种用于时空动作识别的轻量级蒸馏视频焦点调制网络", "tldr": "提出DVFL-Net，通过知识蒸馏将大型视频识别模型的知识转移到轻量级模型，实现高效时空动作识别。", "motivation": "现有的Transformer模型在视频识别中虽然性能优越，但计算成本高昂，不适合在设备上部署，因此需要一个轻量级且高效的模型来解决这一问题。", "method": "本文提出了DVFL-Net，一个轻量级视频焦点调制网络。它通过知识蒸馏将大型预训练教师模型的时空知识蒸馏到紧凑的纳米学生模型中。具体采用前向Kullback-Leibler（KL）散度结合时空焦点调制，以有效传递教师模型的局部和全局上下文。", "result": "DVFL-Net在UCF50、UCF101、HMDB51、SSV2和Kinetics-400等基准测试中进行了评估，结果显示其在性能和效率之间取得了最佳平衡，表现出更低的内存使用量、更少的GFLOPs和强大的准确性，优于现有最先进方法。", "conclusion": "DVFL-Net是一种实用的解决方案，适用于实时人类动作识别（HAR）应用，因为它在保持高识别性能的同时显著降低了计算量。", "translation": "视频识别领域已经发生了显著演变，从传统的卷积神经网络（CNNs）转向基于Transformer的架构以提高准确性。虽然3D CNNs在捕获时空动态方面一直很有效，但最近的Transformer模型利用自注意力机制来建模长距离的空间和时间依赖性。尽管在主要基准测试中取得了最先进的性能，但Transformer模型计算成本仍然很高，特别是对于密集的视频数据。为了解决这个问题，我们提出了一种轻量级视频焦点调制网络DVFL-Net，它将大型预训练教师模型的时空知识蒸馏到一个紧凑的纳米学生模型中，从而实现高效的设备部署。DVFL-Net利用知识蒸馏和时空特征调制显著减少计算量，同时保持高识别性能。我们采用前向Kullback-Leibler（KL）散度结合时空焦点调制，有效地将视频焦点网络基础版（教师）的局部和全局上下文传输到所提出的VFL-Net（学生）中。我们在UCF50、UCF101、HMDB51、SSV2和Kinetics-400数据集上评估了DVFL-Net，并将其与人类动作识别（HAR）领域最近的最先进方法进行了基准测试。此外，我们还进行了详细的消融研究，分析了前向KL散度的影响。结果证实了DVFL-Net在实现性能和效率最佳平衡方面的优越性，展示了更低的内存使用量、更少的GFLOPs和强大的准确性，使其成为实时HAR应用的实用解决方案。", "summary": "本文提出了DVFL-Net，一个轻量级蒸馏视频焦点调制网络，旨在解决Transformer模型在视频识别中计算成本高昂的问题。DVFL-Net通过知识蒸馏和时空特征调制，将大型教师模型的时空知识有效转移到紧凑的学生模型，显著降低了计算量并保持了高识别性能。实验结果表明，DVFL-Net在多个视频动作识别基准测试中实现了性能与效率的最佳平衡，适用于实时动作识别应用。", "keywords": "视频识别, 动作识别, 知识蒸馏, 焦点调制, 轻量级网络", "comments": "本文的创新点在于结合知识蒸馏和焦点调制机制，有效地将大型模型的性能优势转移到轻量级模型上，解决了Transformer计算开销大的问题，使其适用于边缘设备部署。这对于实时动作识别应用具有重要意义和实用价值。"}}
{"id": "2507.13361", "title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs", "authors": ["Shmuel Berman", "Jia Deng"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13361v1", "summary": "Visual Language Models (VLMs) excel at complex visual tasks such as VQA and\nchart understanding, yet recent work suggests they struggle with simple\nperceptual tests. We present an evaluation that tests vision-language models'\ncapacity for nonlocal visual reasoning -- reasoning that requires chaining\nevidence collected from multiple, possibly distant, regions of an image. We\nisolate three distinct forms of non-local vision: comparative perception, which\ndemands holding two images in working memory and comparing them; saccadic\nsearch, which requires making discrete, evidence-driven jumps to locate\nsuccessive targets; and smooth visual search, which involves searching smoothly\nalong a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude\nVision 3.7, GPT-o4-mini), even those that perform well on prior\nprimitive-vision benchmarks, fail these tests and barely exceed random accuracy\non two variants of our tasks that are trivial for humans. Our structured\nevaluation suite allows us to test if VLMs can perform similar visual\nalgorithms to humans. Our findings show that despite gains in raw visual\nacuity, current models lack core visual reasoning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13361v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04", "AI": {"title_translation": "VLMs具有隧道视野：评估领先VLMs中的非局部视觉推理", "tldr": "VLMs在非局部视觉推理方面表现不佳，即使是领先模型也未能通过需要链接多个图像区域证据的测试。", "motivation": "尽管视觉语言模型（VLMs）在复杂的视觉任务（如VQA和图表理解）中表现出色，但近期研究表明它们在简单的感知测试中存在困难。本研究旨在评估VLMs进行非局部视觉推理的能力。", "method": "本研究提出了一个评估套件，测试VLMs的非局部视觉推理能力，这种推理需要将来自图像多个可能遥远区域的证据串联起来。研究分离了三种不同的非局部视觉形式：比较感知（需要将两张图像保存在工作记忆中并进行比较）、眼跳式搜索（需要进行离散的、证据驱动的跳跃以定位连续目标）和平滑视觉搜索（涉及沿着连续轮廓平滑搜索）。", "result": "领先模型（例如Gemini 2.5 Pro、Claude Vision 3.7、GPT-o4-mini），即使在先前的原始视觉基准上表现良好，也未能通过这些测试，并且在人类看来微不足道的两类任务上，它们的准确率几乎没有超过随机水平。", "conclusion": "研究结果表明，尽管在原始视觉敏锐度方面有所提升，但当前的视觉语言模型缺乏核心的视觉推理能力，无法执行与人类相似的视觉算法。", "translation": "视觉语言模型（VLMs）擅长VQA和图表理解等复杂视觉任务，然而最近的研究表明它们在简单的感知测试中表现不佳。我们提出了一项评估，测试视觉语言模型进行非局部视觉推理的能力——这种推理需要将从图像多个可能遥远区域收集到的证据串联起来。我们分离了三种不同形式的非局部视觉：比较感知，要求将两张图像保存在工作记忆中并进行比较；眼跳式搜索，要求进行离散的、证据驱动的跳跃以定位连续目标；以及平滑视觉搜索，涉及沿着连续轮廓平滑搜索。领先模型（例如Gemini 2.5 Pro、Claude Vision 3.7、GPT-o4-mini），即使是那些在先前原始视觉基准上表现良好的模型，也未能通过这些测试，并且在人类看来微不足道的两类任务上，它们的准确率几乎没有超过随机水平。我们结构化的评估套件允许我们测试VLMs是否能执行与人类相似的视觉算法。我们的发现表明，尽管在原始视觉敏锐度方面有所提升，但目前的模型缺乏核心的视觉推理能力。", "summary": "本研究评估了领先视觉语言模型（VLMs）在非局部视觉推理方面的能力。通过设计包含比较感知、眼跳式搜索和平滑视觉搜索三种形式的测试，研究发现，即使是先进的VLMs（如Gemini 2.5 Pro、Claude Vision 3.7、GPT-o4-mini），在这些对人类而言简单的任务上，其表现也远低于预期，仅略高于随机水平。这表明尽管VLMs在视觉敏锐度上有所进步，但它们仍缺乏类似人类的核心视觉推理能力。", "keywords": "视觉语言模型, 非局部视觉推理, 隧道视野, 比较感知, 眼跳式搜索", "comments": "这篇论文揭示了当前领先VLMs的一个重要局限性，即它们在需要整合来自图像不同区域信息的非局部视觉推理方面表现不佳。这项研究的创新之处在于其结构化的评估套件，它将非局部视觉推理细分为具体的可测试形式，并使用了人类轻松完成的任务来凸显模型的不足。这对于未来VLMs的发展方向提供了重要的指导，即需要超越简单的模式识别，提升更深层次的、类似人类的视觉认知能力。"}}
{"id": "2410.11569", "title": "Identification over Affine Poisson Channels: Application to Molecular Mixture Communication Systems", "authors": ["Mohammad Javad Salariseddigh", "Heinz Koeppl", "Holger Boche", "Vahid Jamali"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 Pages. A preliminary version of this research has been accepted for presentation at the IEEE Information Theory Workshop (ITW) 2025", "url": "http://arxiv.org/abs/2410.11569v3", "summary": "Identification capacity has been established as a relevant performance metric\nfor various goal-/task-oriented applications, where the receiver may be\ninterested in only a particular message that represents an event or a task. For\nexample, in olfactory molecular communications (MCs), odors or pheromones,\nwhich are often a mixture of various molecule types, may signal nearby danger,\nfood, or a mate. In this paper, we examine the identification capacity with\ndeterministic encoder for the discrete affine Poisson channel which can be used\nto model MC systems with molecule counting receivers. We establish lower and\nupper bounds on the identification capacity in terms of features of the\naffinity matrix between the released molecules and receptors at the receiver.\nAs a key finding, we show that even when the number of receptor types scales\nsub-linearly in the number of molecule types $N,$ the number of reliably\nidentifiable messages can grow super-exponentially with the rank of the\naffinity matrix, $T,$ i.e., $\\sim 2^{(T \\log T)R},$ where $R$ denotes the\ncoding rate. We further derive lower and upper bounds on $R,$ and show that the\nproposed capacity theorem includes several known results in the literature as\nits special cases.", "comment": "11 Pages. A preliminary version of this research has been accepted\n  for presentation at the IEEE Information Theory Workshop (ITW) 2025", "pdf_url": "http://arxiv.org/pdf/2410.11569v3", "cate": "cs.IT", "date": "2024-10-15", "updated": "2025-07-18", "AI": {"title_translation": "仿射泊松信道上的识别：在分子混合物通信系统中的应用", "tldr": "本文研究了离散仿射泊松信道上的识别容量，并发现即使受体类型数量有限，可识别消息的数量也能随亲和矩阵的秩超指数增长，且其容量定理包含了现有结果。", "motivation": "识别容量是面向目标/任务应用的重要性能指标，尤其在嗅觉分子通信（MCs）等系统中，接收器可能只对特定信息感兴趣，例如表示危险、食物或配偶的信号，而这些信号通常是多种分子类型的混合物。", "method": "本文研究了具有确定性编码器的离散仿射泊松信道上的识别容量，该信道可用于建模具有分子计数接收器的MC系统。作者建立了识别容量的上下界，这些界限与释放分子和接收器受体之间的亲和矩阵特征相关。", "result": "建立了识别容量的上下界，这些界限与亲和矩阵的特征相关。主要发现是，即使当受体类型数量相对于分子类型数量N呈亚线性增长时，可靠可识别消息的数量也能以亲和矩阵秩T的超指数形式增长，即 $\\sim 2^{(T \\log T)R}$，其中R是编码速率。进一步推导了R的上下界。所提出的容量定理包含了文献中的几个已知结果作为特例。", "conclusion": "本文成功建立了离散仿射泊松信道上的识别容量理论，证明了在分子通信系统中，即使受体数量有限，仍能实现大量消息的可靠识别，并且该理论具有普适性，能够涵盖现有研究成果。", "translation": "识别容量已被确立为各种面向目标/任务应用的相关性能指标，其中接收器可能只对代表事件或任务的特定消息感兴趣。例如，在嗅觉分子通信（MCs）中，气味或信息素（通常是各种分子类型的混合物）可能预示附近的危险、食物或配偶。在本文中，我们研究了离散仿射泊松信道上具有确定性编码器的识别容量，该信道可用于建模具有分子计数接收器的MC系统。我们根据释放分子和接收器受体之间亲和矩阵的特征，建立了识别容量的上下界。作为一个关键发现，我们表明，即使当受体类型数量相对于分子类型数量N呈亚线性增长时，可靠可识别消息的数量也能以亲和矩阵秩T的超指数形式增长，即 $\\sim 2^{(T \\log T)R}$，其中R表示编码速率。我们进一步推导了R的上下界，并表明所提出的容量定理包含了文献中的几个已知结果作为其特例。", "summary": "本文研究了离散仿射泊松信道上的识别容量，该信道适用于分子通信系统。研究建立了识别容量的上下界，并发现即使受体数量有限，可识别消息的数量也能随着亲和矩阵的秩超指数增长。此外，论文还推导了编码速率的界限，并指出其提出的容量定理是现有文献中多个已知结果的推广。", "keywords": "识别容量, 仿射泊松信道, 分子通信, 亲和矩阵, 容量界限", "comments": "这项研究在分子通信领域具有重要意义，尤其是在生物启发式通信系统设计方面。其创新之处在于将识别容量理论应用于仿射泊松信道，并揭示了在受体有限的情况下，通过亲和矩阵的特性可以实现超指数增长的可识别消息数量。这为未来设计高效、目标导向的分子通信系统提供了理论基础。"}}
{"id": "2507.14020", "title": "Influence of Cell Position on the Capacity of Retired Batteries: Experimental and Statistical Studies", "authors": ["Marwan Hassini", "Colette Mintsa-Eya", "Eduardo Redondo-Iglesias", "Pascal Venet"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      5 pages, 4 figures, IECON 2025", "url": "http://arxiv.org/abs/2507.14020v1", "summary": "Understanding how batteries perform after automotive use is crucial to\ndetermining their potential for reuse. This article presents experimental\nresults aimed at advancing knowledge of retired battery performance. Three\nmodules extracted from electric vehicles were tested. Their performance was\nassessed, and the results were analyzed statistically using analysis of\nvariance (ANOVA). The 36 retired cells exhibited a high level of performance,\nalbeit with significant variation. On average, the cells had a 95% state of\nhealth capacity with a dispersion of 2.4%. ANOVA analysis suggests that cell\nperformance is not correlated with their position inside the module. These\nresults demonstrate the need to evaluate dispersion within retired batteries\nand to develop thermal management and balancing systems for second-life\nbatteries.", "comment": "5 pages, 4 figures, IECON 2025", "pdf_url": "http://arxiv.org/pdf/2507.14020v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "废役电池电芯位置对容量的影响：实验与统计研究", "tldr": "本研究通过对电动汽车废役电池进行实验和统计分析，发现废役电芯虽然性能高但存在显著差异，且其性能与在模块中的位置无关，强调了评估电池离散度和开发二次利用电池热管理及均衡系统的必要性。", "motivation": "了解电池在汽车使用后的性能对于确定其再利用潜力至关重要。", "method": "研究测试了从电动汽车中提取的三个电池模块（共36个废役电芯），评估了它们的性能，并使用方差分析（ANOVA）对结果进行了统计分析。", "result": "36个废役电芯表现出高水平的性能，平均健康状态容量为95%，离散度为2.4%，但存在显著差异。ANOVA分析表明，电芯性能与它们在模块内的位置无关。", "conclusion": "研究结果表明，需要评估废役电池内部的性能离散度，并为二次利用电池开发热管理和均衡系统。", "translation": "了解电池在汽车使用后的性能对于确定其再利用潜力至关重要。本文介绍了旨在增进废役电池性能知识的实验结果。测试了从电动汽车中提取的三个模块。评估了它们的性能，并使用方差分析（ANOVA）对结果进行了统计分析。36个废役电芯表现出高水平的性能，尽管存在显著差异。平均而言，电芯的健康状态容量为95%，离散度为2.4%。ANOVA分析表明，电芯性能与它们在模块内的位置无关。这些结果表明，需要评估废役电池内部的离散度，并为二次利用电池开发热管理和均衡系统。", "summary": "本文通过对从电动汽车中提取的三个废役电池模块（共36个电芯）进行实验和统计分析（ANOVA），研究了废役电池的性能。研究发现，这些废役电芯整体表现出高水平的性能（平均95%健康状态容量，2.4%离散度），但存在显著的性能差异。重要的是，ANOVA分析表明电芯性能与其在模块内的位置无关。研究强调了评估废役电池内部性能离散度以及为二次利用电池开发热管理和均衡系统的重要性。", "keywords": "废役电池, 电芯性能, 方差分析, 二次利用, 电池管理系统", "comments": "这项研究通过实验和统计方法，为废役电池的二次利用提供了关键数据。其创新点在于明确指出电芯位置对性能无显著影响，这有助于简化二次利用电池的筛选和重组过程。同时，研究强调了性能离散度及其对二次利用系统（如热管理和均衡系统）的需求，这对于提高二次利用电池的可靠性和寿命具有重要指导意义。"}}
{"id": "2507.07953", "title": "Incremental Collision Laws Based on the Bouc-Wen Model: External Forces and Corner Cases", "authors": ["Mihails Milehins", "Dan Marghitu"], "categories": ["physics.class-ph", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Classical Physics (physics.class-ph)", "pdf_link": null, "comments": "Comments:      12 pages, 3 figures, see this https URL (v2) minor amendments; arXiv admin note: text overlap with arXiv:2410.08147", "url": "http://arxiv.org/abs/2507.07953v2", "summary": "In the article titled \"The Bouc-Wen Model for Binary Direct Collinear\nCollisions of Convex Viscoplastic Bodies\" and published in the Journal of\nComputational and Nonlinear Dynamics (Volume 20, Issue 6, June 2025), the\nauthors studied mathematical models of binary direct collinear collisions of\nconvex viscoplastic bodies that employed two incremental collision laws based\non the Bouc-Wen differential model of hysteresis. It was shown that the models\npossess favorable analytical properties, and several model parameter\nidentification studies were conducted, demonstrating that the models can\naccurately capture the nature of a variety of collision phenomena. In this\narticle, the aforementioned models are augmented by modeling the effects of\nexternal forces as time-dependent inputs that belong to a certain function\nspace. Furthermore, the range of the parameters under which the models possess\nfavorable analytical properties is extended to several corner cases that were\nnot considered in the prior publication. Finally, the previously conducted\nmodel parameter identification studies are extended, and an additional model\nparameter identification study is provided in an attempt to validate the\nability of the augmented models to represent the effects of external forces.", "comment": "12 pages, 3 figures, see https://gitlab.com/user9716869/EBWCM; (v2)\n  minor amendments; arXiv admin note: text overlap with arXiv:2410.08147", "pdf_url": "http://arxiv.org/pdf/2507.07953v2", "cate": "physics.class-ph", "date": "2025-07-10", "updated": "2025-07-18", "AI": {"title_translation": "基于Bouc-Wen模型的增量碰撞定律：外力和极端情况", "tldr": "本文扩展了基于Bouc-Wen模型的增量碰撞定律，以纳入外部力并处理之前未考虑的极端参数情况，并通过参数识别研究验证了其有效性。", "motivation": "为了增强现有基于Bouc-Wen模型的碰撞定律的适用性和准确性，本文旨在将外部力的影响纳入模型中，并将其分析特性扩展到之前未考虑的极端情况。", "method": "本文通过将外部力建模为时间依赖的输入来增强了现有的基于Bouc-Wen模型的增量碰撞定律，并将模型的参数范围扩展到多个极端情况。同时，进行了扩展的模型参数识别研究和额外的研究以验证增强模型表示外部力影响的能力。", "result": "通过扩展和额外的模型参数识别研究，验证了增强模型能够准确表示外部力的影响。", "conclusion": "本文成功扩展了基于Bouc-Wen模型的增量碰撞定律，使其能够处理外部力和多种极端情况，从而提高了模型的鲁棒性和适用性。", "translation": "在题为“凸粘塑性体二元直接共线碰撞的Bouc-Wen模型”并发表于《计算与非线性动力学杂志》（第20卷，第6期，2025年6月）的文章中，作者研究了采用两种基于Bouc-Wen滞后微分模型的增量碰撞定律的凸粘塑性体二元直接共线碰撞的数学模型。结果表明，这些模型具有良好的分析特性，并进行了一些模型参数识别研究，证明这些模型能够准确捕捉各种碰撞现象的本质。在本文中，通过将外部力的影响建模为属于某个函数空间的时间依赖输入，对上述模型进行了增强。此外，模型具有良好分析特性的参数范围扩展到了之前未在先前出版物中考虑的几个极端情况。最后，扩展了先前进行过的模型参数识别研究，并提供了一项额外的模型参数识别研究，以验证增强模型表示外部力影响的能力。", "summary": "本文基于先前研究的Bouc-Wen增量碰撞定律，对其进行了两方面的重要增强：一是将外部力建模为时间依赖输入纳入模型，二是将模型的分析特性参数范围扩展到之前未考虑的极端情况。通过扩展和新增的模型参数识别研究，验证了增强后的模型能够有效表示外部力的影响。", "keywords": "Bouc-Wen模型, 增量碰撞定律, 外部力, 极端情况, 粘塑性体", "comments": "本文在现有Bouc-Wen模型的基础上进行了有价值的增量式创新，通过纳入外部力和处理极端情况，显著提升了模型的实用性和适用范围。特别是在外部力建模和对“极端情况”的考量上，展现了对实际应用复杂性的深入洞察。"}}
{"id": "2502.06158", "title": "Efficient numerical method for the Schrödinger equation with high-contrast potentials", "authors": ["Xingguang Jin", "Liu Liu", "Xiang Zhong", "Eric T. Chung"], "categories": ["math.NA", "cs.NA", "65M12, 65M15, 65N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06158v2", "summary": "In this paper, we study the Schr\\\"{o}dinger equation in the semiclassical\nregime and with multiscale potential function. We develop the so-called\nconstraint energy minimization generalized multiscale finite element method\n(CEM-GMsFEM), in the framework of Crank-Nicolson (CN) discretization in time.\nThe localized multiscale basis functions are constructed by addressing the\nspectral problem and a constrained energy minimization problem related to the\nHamiltonian norm. A first-order convergence in the energy norm and second-order\nconvergence in the $L^2$ norm for our numerical scheme are shown, with a\nrelation between oversampling number in the CEM-GMsFEM method, spatial mesh\nsize and the semiclassical parameter provided. Furthermore, we demonstrate the\nconvergence of the proposed Crank-Nicolson CEM-GMsFEM scheme. The convergence\nrequires $H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{5}{4}})$, $\\Delta\nt=O(\\varepsilon^{\\frac{5}{4}})$ if $\\varepsilon\\leq \\delta$; while if\n$\\delta<\\varepsilon$, the convergence requires\n$H/\\sqrt{\\Lambda}=O(\\varepsilon^{\\frac{1}{4}}\\delta)$, $\\Delta\nt=O(\\frac{\\delta^2}{\\varepsilon^{3/4}})$ (where $H$ represents the maximum\ndiameter of coarse elements, $\\Lambda$ is the minimal eigenvalue associated\nwith the eigenvector not included in the auxiliary space, $\\Delta t$ is the\ntime step, $0 < \\varepsilon\\ll 1$ is the Planck constant and $\\delta$ describes\nthe multiscale structure of the potential).Several numerical examples including\n1D and 2D in space, with high-contrast potential are conducted to demonstrate\nthe efficiency and accuracy of our proposed scheme.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06158v2", "cate": "math.NA", "date": "2025-02-10", "updated": "2025-07-18", "AI": {"title_translation": "求解高对比度势薛定谔方程的高效数值方法", "tldr": "本文提出了一种基于Crank-Nicolson和CEM-GMsFEM的高效数值方法，用于求解半经典和多尺度势薛定谔方程，并证明了其收敛性和准确性。", "motivation": "本文旨在研究半经典区域和具有多尺度势函数的薛定谔方程，并开发一种有效的数值方法来解决其计算挑战。", "method": "本文开发了约束能量最小化广义多尺度有限元方法（CEM-GMsFEM），并将其应用于时间上的Crank-Nicolson（CN）离散化框架。局部多尺度基函数通过解决谱问题和与哈密顿范数相关的约束能量最小化问题来构建。", "result": "数值方案在能量范数下显示出一阶收敛性，在L2范数下显示出二阶收敛性。研究了CEM-GMsFEM中过采样数、空间网格尺寸和半经典参数之间的关系。同时，给出了所提出的Crank-Nicolson CEM-GMsFEM方案的收敛条件。通过包含一维和二维高对比度势的数值示例，证明了所提出方案的效率和准确性。", "conclusion": "本文提出的Crank-Nicolson CEM-GMsFEM方法能够高效准确地求解半经典区域和具有高对比度势的多尺度薛定谔方程，并具有理论收敛性保证。", "translation": "在本文中，我们研究了半经典区域和具有多尺度势函数的薛定谔方程。我们开发了所谓的约束能量最小化广义多尺度有限元方法（CEM-GMsFEM），并将其应用于时间上的Crank-Nicolson（CN）离散化框架。局部多尺度基函数通过解决谱问题和与哈密顿范数相关的约束能量最小化问题来构建。我们的数值方案在能量范数下显示出一阶收敛性，在L2范数下显示出二阶收敛性，并给出了CEM-GMsFEM方法中过采样数、空间网格尺寸和半经典参数之间的关系。此外，我们证明了所提出的Crank-Nicolson CEM-GMsFEM方案的收敛性。如果$\\\\varepsilon\\leq \\\\delta$，收敛性要求$H/\\\\sqrt{\\\\Lambda}=O(\\\\varepsilon^{\\\\frac{5}{4}})$，$\\\\Delta t=O(\\\\varepsilon^{\\\\frac{5}{4}})$；如果$\\\\delta<\\\\varepsilon$，收敛性要求$H/\\\\sqrt{\\\\Lambda}=O(\\\\varepsilon^{\\\\frac{1}{4}}\\\\delta)$，$\\\\Delta t=O(\\\\frac{\\\\delta^2}{\\\\varepsilon^{3/4}})$（其中$H$表示粗网格元素的最大直径，$\\\\Lambda$是与未包含在辅助空间中的特征向量相关的最小特征值，$\\\\Delta t$是时间步长，$0 < \\\\varepsilon\\\\ll 1$是普朗克常数，$\\\\delta$描述了势的多尺度结构）。进行了包括空间一维和二维、具有高对比度势的几个数值示例，以证明我们提出的方案的效率和准确性。", "summary": "本文提出了一种结合Crank-Nicolson时间离散化和约束能量最小化广义多尺度有限元方法（CEM-GMsFEM）的新型数值方案，用于高效求解半经典和高对比度多尺度势薛定谔方程。该方法通过解决谱问题和约束能量最小化问题构建局部多尺度基函数，并证明了其在能量范数下的一阶收敛性和L2范数下的二阶收敛性。通过理论分析给出了收敛条件，并通过数值示例验证了其效率和准确性。", "keywords": "薛定谔方程, 多尺度, 有限元方法, Crank-Nicolson, 高对比度势", "comments": "本文的创新点在于将约束能量最小化广义多尺度有限元方法（CEM-GMsFEM）与Crank-Nicolson时间离散化相结合，以有效处理半经典区域和高对比度多尺度势的薛定谔方程。该方法不仅在理论上证明了收敛性（包括详细的收敛条件），并通过数值实验验证了其在复杂势场下的高效性和准确性，为多尺度量子力学问题提供了一个有前景的数值工具。"}}
{"id": "2507.13499", "title": "AI-Assisted Fixes to Code Review Comments at Scale", "authors": ["Chandra Maddila", "Negar Ghorbani", "James Saindon", "Parth Thakkar", "Vijayaraghavan Murali", "Rui Abreu", "Jingyue Shen", "Brian Zhou", "Nachiappan Nagappan", "Peter C. Rigby"], "categories": ["cs.SE", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13499v1", "summary": "Aim. There are 10s of thousands of code review comments each week at Meta. We\ndeveloped Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes\nfor reviewer comments in production at scale.\n  Method. We developed an internal benchmark of 64k <review comment, patch>\ndata points to fine-tune Llama models. Once our models achieve reasonable\noffline results, we roll them into production. To ensure that our AI-assisted\nfixes do not negatively impact the time it takes to do code reviews, we conduct\nrandomized controlled safety trials as well as full production experiments.\n  Offline Results. As a baseline, we compare GPT-4o to our small and large\nLlama models. In offline results, our LargeLSFT model creates an exact match\npatch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The\ninternal models also use more modern Hack functions when compared to the PHP\nfunctions suggested by GPT-4o.\n  Safety Trial. When we roll MetaMateCR into production in a safety trial that\ncompares no AI patches with AI patch suggestions, we see a large regression\nwith reviewers taking over 5% longer to conduct reviews. After investigation,\nwe modify the UX to only show authors the AI patches, and see no regressions in\nthe time for reviews.\n  Production. When we roll LargeLSFT into production, we see an\nActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.\nOur results illustrate the importance of safety trials in ensuring that AI does\nnot inadvertently slow down engineers, and a successful review comment to AI\npatch product running at scale.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13499v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "AI辅助大规模代码审查评论修复", "tldr": "Meta开发并部署了MetaMateCR，一个AI辅助的代码审查评论修复工具，通过微调Llama模型并在大规模生产环境中验证其有效性和安全性，实现了显著的性能提升。", "motivation": "Meta每周有数万条代码审查评论，开发MetaMateCR旨在提供AI辅助的修复方案，以提高代码审查效率和规模化处理能力。", "method": "开发了一个包含6.4万个<审查评论，补丁>数据点的内部基准来微调Llama模型。在模型达到合理的离线结果后，将其投入生产。通过随机对照安全试验和全面的生产实验，确保AI辅助修复不会对代码审查时间产生负面影响。", "result": "离线测试中，LargeLSFT模型生成精确匹配补丁的准确率为68%，比GPT-4o高出9个百分点，并且使用了更现代的Hack函数。安全试验初期，AI补丁建议导致审查时间增加超过5%，经过用户体验（UX）修改（仅向作者显示AI补丁）后，审查时间没有出现回溯。生产环境中，LargeLSFT模型的“可操作到应用”率为19.7%，比GPT-4o提升了9.2个百分点。", "conclusion": "AI辅助的代码审查评论修复工具MetaMateCR已成功大规模运行，结果强调了安全试验在确保AI不无意中减慢工程师速度方面的重要性。", "translation": "目的：Meta每周有数万条代码审查评论。我们开发了Metamate for Code Review (MetaMateCR)，它在大规模生产环境中提供AI辅助的审查评论修复。\n方法：我们开发了一个包含6.4万个<审查评论，补丁>数据点的内部基准来微调Llama模型。一旦我们的模型达到合理的离线结果，我们就会将其投入生产。为了确保我们的AI辅助修复不会对代码审查所需的时间产生负面影响，我们进行了随机对照安全试验以及全面的生产实验。\n离线结果：作为基准，我们将GPT-4o与我们的小型和大型Llama模型进行比较。在离线结果中，我们的LargeLSFT模型在68%的时间内创建了精确匹配补丁，比GPT-4o高出9个百分点。与GPT-4o建议的PHP函数相比，内部模型还使用了更现代的Hack函数。\n安全试验：当我们将MetaMateCR投入生产进行安全试验时（比较无AI补丁和AI补丁建议），我们发现审查人员进行审查的时间增加了5%以上，出现了大幅回溯。经过调查，我们修改了用户体验（UX），只向作者显示AI补丁，并且审查时间没有出现回溯。\n生产：当我们将LargeLSFT投入生产时，我们看到“可操作到应用”率为19.7%，比GPT-4o提升了9.2个百分点。我们的结果说明了安全试验在确保AI不会无意中减慢工程师速度方面的重要性，以及一个成功运行大规模审查评论到AI补丁产品的案例。", "summary": "Meta开发并部署了MetaMateCR，一个AI辅助的代码审查评论修复系统，旨在解决大规模代码审查评论问题。该系统通过使用包含6.4万个<评论，补丁>对的内部数据集微调Llama模型实现。离线测试显示，其LargeLSFT模型在精确匹配补丁生成方面优于GPT-4o（68%对59%）。在生产部署过程中，团队通过严格的安全试验发现并解决了AI补丁建议可能导致审查时间增加的问题，通过优化用户体验（仅向作者显示AI补丁）消除了负面影响。最终，MetaMateCR在生产环境中实现了19.7%的“可操作到应用”率，比GPT-4o提高了9.2个百分点，证明了AI在提高代码审查效率方面的潜力以及安全试验的重要性。", "keywords": "AI辅助修复, 代码审查, Llama模型, MetaMateCR, 安全试验", "comments": "这篇论文的创新点在于其在大规模生产环境中成功部署AI辅助代码审查修复工具，并特别强调了通过严格的安全试验来识别和解决潜在的用户体验问题（例如AI建议可能导致审查时间增加）。这种对实际用户影响的关注和迭代优化是其重要性所在。它不仅展示了AI在软件工程中的应用潜力，也提供了在部署大型AI系统时需要考虑用户行为和安全性的宝贵经验。"}}
{"id": "2507.14080", "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "categories": ["cs.DC", "D.2.4; C.2.4"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      14 pages, 13 figures", "url": "http://arxiv.org/abs/2507.14080v1", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios.", "comment": "14 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.14080v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Shipwright: 证明拜占庭参与者的分布式系统活性", "tldr": "Shipwright是一个验证框架，用于证明存在恶意参与者的分布式系统的活性，并首次验证了PBFT可执行实现的活性。", "motivation": "确保去中心化系统（如PBFT）的活性至关重要，因为没有单一管理员可在出现活性错误时重启系统。同时，实现活性具有挑战性，因为任何单个参与者都可能是恶意的，但系统仍需向前推进。尽管验证是确保无错误的有前景方法，但此前没有工作能够验证PBFT可执行实现的活性。", "method": "Shipwright是一个验证框架，用于证明存在恶意参与者的分布式系统的正确性和活性。它引入了三种技术：1. 实现对存在恶意参与者的去中心化环境进行形式化推理。2. 允许开发者以模块化方式将系统和证明分解为子协议和子证明。3. 支持对消息中可能嵌入的加密签名进行可靠推理。", "result": "作者使用Shipwright实现并验证了PBFT中单个日志条目一致性的初始原型（存在一些限制），并将其翻译成Go语言的可执行实现。实验证明了其在常见情况和多种故障场景下的操作和活性。", "conclusion": "Shipwright框架成功地首次实现了对PBFT可执行实现活性的验证，并通过实验证明了其在恶意参与者环境下的鲁棒性，从而解决了去中心化系统活性验证的难题。", "translation": "确保去中心化系统（如PBFT）的活性至关重要，因为如果系统遇到活性错误，可能没有单一管理员可以重启系统。同时，活性难以实现，因为任何单个参与者都可能是恶意的，但整个系统必须向前推进。虽然验证是确保没有错误的一种有前景的方法，但此前没有工作能够验证PBFT可执行实现的活性。\nShipwright是一个验证框架，用于证明存在恶意参与者的分布式系统的正确性和活性。Shipwright引入了三种技术，使得能够对存在恶意参与者的去中心化设置进行形式化推理，允许开发人员以模块化方式将其系统和证明分解为子协议和子证明，并支持对消息中可能嵌入的加密签名进行可靠推理。我们使用Shipwright实现了PBFT中单个日志条目一致性的初始原型（存在一些限制）并进行了验证，然后将其翻译成Go语言的可执行实现。我们通过实验证明了其在常见情况和多种故障场景下的操作和活性。", "summary": "Shipwright是一个新颖的验证框架，旨在解决去中心化系统中，特别是像PBFT这样存在恶意参与者的分布式系统的活性验证难题。该框架通过引入形式化推理、模块化分解和加密签名推理等技术，首次成功验证了PBFT可执行实现的活性。实验结果表明，Shipwright在常见情况和故障场景下均能有效保障系统活性。", "keywords": "分布式系统, 活性, 拜占庭容错, 形式化验证, PBFT", "comments": "这项工作具有显著的创新性，因为它首次成功验证了PBFT可执行实现的活性，填补了该领域的一个重要空白。Shipwright引入的三种技术（形式化推理、模块化分解、加密签名推理）对于处理拜占庭容错系统中的复杂性至关重要，为分布式系统的形式化验证提供了新的工具和方法。其重要性在于解决了去中心化系统中一个关键的可靠性问题——活性，这对于确保系统持续运行至关重要。抽象中提到“存在一些限制”，但未详细说明，这可能是未来研究需要关注的潜在局限性。"}}
{"id": "2507.13826", "title": "Simulation for Noncontact Radar-Based Physiological Sensing Using Depth-Camera-Derived Human 3D Model with Electromagnetic Scattering Analysis", "authors": ["Kimitaka Sumi", "Takuya Sakamoto"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      10 pages, 9 figures, 6 tables. This work is going to be submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2507.13826v1", "summary": "This study proposes a method for simulating signals received by\nfrequency-modulated continuous-wave radar during respiratory monitoring, using\nhuman body geometry and displacement data acquired via a depth camera. Unlike\nprevious studies that rely on simplified models of body geometry or\ndisplacement, the proposed approach models high-frequency scattering centers\nbased on realistic depth-camera-measured body shapes and motions. Experiments\nwere conducted with six participants under varying conditions, including\nvarying target distances, seating orientations, and radar types, with\nsimultaneous acquisition from the radar and depth camera. Relative to\nconventional model-based methods, the proposed technique achieved improvements\nof 7.5%, 58.2%, and 3.2% in the correlation coefficients of radar images,\ndisplacements, and spectrograms, respectively. This work contributes to the\ngeneration of radar-based physiological datasets through simulation and\nenhances our understanding of factors affecting the accuracy of non-contact\nsensing.", "comment": "10 pages, 9 figures, 6 tables. This work is going to be submitted to\n  the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2507.13826v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于深度相机生成的人体3D模型结合电磁散射分析的非接触雷达生理传感仿真", "tldr": "本研究提出了一种使用深度相机获取的真实人体3D模型和运动数据来模拟雷达呼吸监测信号的方法，相比传统方法显著提高了模拟精度。", "motivation": "以往的雷达生理传感仿真研究依赖于简化的人体几何或位移模型，导致模拟精度不足。本研究旨在通过使用深度相机获取的更真实的人体模型和运动数据，提高仿真准确性，并增进对非接触传感精度影响因素的理解。", "method": "本研究提出了一种模拟调频连续波雷达在呼吸监测过程中接收信号的方法。该方法利用深度相机获取的人体几何和位移数据，基于真实的人体形状和运动对高频散射中心进行建模。实验招募了六名参与者，在不同的目标距离、坐姿方向和雷达类型条件下进行，并同步采集雷达和深度相机数据。", "result": "与传统的基于模型的方法相比，所提出的技术在雷达图像、位移和频谱图的相关系数方面分别取得了7.5%、58.2%和3.2%的改进。", "conclusion": "这项工作通过仿真促进了基于雷达的生理数据集的生成，并增强了我们对影响非接触传感精度的因素的理解。", "translation": "这篇研究提出了一种利用深度相机获取的人体几何和位移数据，模拟调频连续波雷达在呼吸监测过程中接收信号的方法。与以往依赖简化人体几何或位移模型的研究不同，该方法基于真实的深度相机测量的人体形状和运动，对高频散射中心进行建模。实验在六名参与者身上进行，条件包括不同的目标距离、坐姿方向和雷达类型，同时从雷达和深度相机获取数据。相对于传统的基于模型的方法，该技术在雷达图像、位移和频谱图的相关系数方面分别取得了7.5%、58.2%和3.2%的改进。这项工作有助于通过仿真生成基于雷达的生理数据集，并增强我们对影响非接触传感精度的因素的理解。", "summary": "本文介绍了一种用于非接触雷达生理传感（特别是呼吸监测）的新型仿真方法。该方法利用深度相机获取的人体3D模型和运动数据，构建更真实的高频散射中心，克服了以往使用简化模型的局限。通过对六名参与者的实验表明，与传统基于模型的技术相比，该方法在雷达图像、位移和频谱图的相关系数方面均有显著提高。这项研究推动了模拟雷达生理数据集的生成，并加深了对影响非接触传感精度因素的理解。", "keywords": "雷达, 生理传感, 仿真, 深度相机, 电磁散射", "comments": "本研究的创新之处在于利用深度相机获取的真实人体3D模型和运动数据进行雷达信号仿真，显著提高了模拟精度，克服了以往简化模型的不足。这对于生成更可靠的模拟生理数据集以及更好地理解非接触雷达传感中的复杂相互作用至关重要。其中，位移相关系数高达58.2%的改进尤为突出。"}}
{"id": "2507.13761", "title": "Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models", "authors": ["Palash Nandi", "Maithili Joshi", "Tanmoy Chakraborty"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13761v1", "summary": "Language models are highly sensitive to prompt formulations - small changes\nin input can drastically alter their output. This raises a critical question:\nTo what extent can prompt sensitivity be exploited to generate inapt content?\nIn this paper, we investigate how discrete components of prompt design\ninfluence the generation of inappropriate content in Visual Language Models\n(VLMs). Specifically, we analyze the impact of three key factors on successful\njailbreaks: (a) the inclusion of detailed visual information, (b) the presence\nof adversarial examples, and (c) the use of positively framed beginning\nphrases. Our findings reveal that while a VLM can reliably distinguish between\nbenign and harmful inputs in unimodal settings (text-only or image-only), this\nability significantly degrades in multimodal contexts. Each of the three\nfactors is independently capable of triggering a jailbreak, and we show that\neven a small number of in-context examples (as few as three) can push the model\ntoward generating inappropriate outputs. Furthermore, we propose a framework\nthat utilizes a skip-connection between two internal layers of the VLM, which\nsubstantially increases jailbreak success rates, even when using benign images.\nFinally, we demonstrate that memes, often perceived as humorous or harmless,\ncan be as effective as toxic visuals in eliciting harmful content, underscoring\nthe subtle and complex vulnerabilities of VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13761v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "炮火中的无辜：跳跃连接在越狱视觉语言模型中的作用", "tldr": "本文探讨了提示敏感性在越狱视觉语言模型（VLMs）中生成不当内容的应用，发现多模态环境下VLMs的区分能力显著下降，并提出了一种利用跳跃连接提高越狱成功率的框架。", "motivation": "语言模型对提示词高度敏感，微小输入变化可大幅改变输出。本文旨在探究提示敏感性在多大程度上可被利用来生成不当内容，并深入研究提示设计中的离散组件如何影响视觉语言模型（VLMs）中不当内容的生成。", "method": "研究人员调查了三个关键因素对成功越狱的影响：详细视觉信息、对抗性示例和积极开头短语的使用。此外，他们提出了一种利用VLM两个内部层之间跳跃连接的框架，以提高越狱成功率。", "result": "研究发现，VLM在单模态设置下能可靠区分良性与有害输入，但在多模态环境下能力显著下降。三个因素均能独立触发越狱，少量上下文示例（少至三个）即可使模型生成不当输出。所提出的跳跃连接框架显著提高了越狱成功率，即使使用良性图像。模因在引发有害内容方面与有毒视觉内容同样有效。", "conclusion": "视觉语言模型（VLMs）在多模态环境下表现出显著的脆弱性，其区分良性与有害输入的能力会下降。即使是无害的模因也能有效引发有害内容，揭示了VLMs脆弱性的微妙性和复杂性。跳跃连接可被利用来显著提高越狱成功率。", "translation": "语言模型对提示词的表述高度敏感——输入的微小变化可以彻底改变其输出。这引出了一个关键问题：提示敏感性可以在多大程度上被利用来生成不恰当的内容？在本文中，我们研究了提示设计的离散组件如何影响视觉语言模型（VLMs）中不恰当内容的生成。具体来说，我们分析了三个关键因素对成功越狱的影响：(a) 包含详细的视觉信息，(b) 对抗性示例的存在，以及 (c) 使用积极措辞的开头短语。我们的发现表明，虽然VLM在单模态设置（仅文本或仅图像）中可以可靠地区分良性输入和有害输入，但这种能力在多模态环境中显著下降。这三个因素中的每一个都能够独立触发越狱，我们表明即使少量上下文示例（少至三个）也可以推动模型生成不恰当的输出。此外，我们提出了一种利用VLM两个内部层之间跳跃连接的框架，这大大提高了越狱成功率，即使在使用良性图像时也是如此。最后，我们证明了模因，通常被认为是幽默或无害的，在引发有害内容方面可以与有毒视觉内容一样有效，这突显了VLM微妙而复杂的漏洞。", "summary": "本文研究了提示敏感性在越狱视觉语言模型（VLMs）中生成不当内容的应用。研究分析了详细视觉信息、对抗性示例和积极开头短语等因素对越狱成功的影响。结果显示，VLMs在多模态环境下区分良性与有害内容的能力显著下降，且这些因素能独立触发越狱，少量上下文示例即可生效。论文还提出了一种利用跳跃连接的框架，能大幅提高越狱成功率。此外，研究指出，看似无害的模因也能有效引发有害内容，揭示了VLMs的复杂脆弱性。", "keywords": "越狱, 视觉语言模型, 跳跃连接, 提示敏感性, 多模态脆弱性", "comments": "本文揭示了视觉语言模型（VLMs）在多模态场景下的深层漏洞，特别强调了提示敏感性、上下文示例以及跳跃连接在越狱攻击中的关键作用。其创新之处在于提出了利用跳跃连接作为一种攻击手段，并揭示了模因这类看似无害的内容也能成为攻击媒介，这对于理解和提升VLMs的安全性具有重要意义。研究结果强调了在实际部署中加强多模态内容审查和模型鲁棒性训练的紧迫性。"}}
{"id": "2507.09754", "title": "Explainable AI in Genomics: Transcription Factor Binding Site Prediction with Mixture of Experts", "authors": ["Aakash Tripathi", "Ian E. Nielsen", "Muhammad Umer", "Ravi P. Ramachandran", "Ghulam Rasool"], "categories": ["cs.LG", "q-bio.GN"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09754v2", "summary": "Transcription Factor Binding Site (TFBS) prediction is crucial for\nunderstanding gene regulation and various biological processes. This study\nintroduces a novel Mixture of Experts (MoE) approach for TFBS prediction,\nintegrating multiple pre-trained Convolutional Neural Network (CNN) models,\neach specializing in different TFBS patterns. We evaluate the performance of\nour MoE model against individual expert models on both in-distribution and\nout-of-distribution (OOD) datasets, using six randomly selected transcription\nfactors (TFs) for OOD testing. Our results demonstrate that the MoE model\nachieves competitive or superior performance across diverse TF binding sites,\nparticularly excelling in OOD scenarios. The Analysis of Variance (ANOVA)\nstatistical test confirms the significance of these performance differences.\nAdditionally, we introduce ShiftSmooth, a novel attribution mapping technique\nthat provides more robust model interpretability by considering small shifts in\ninput sequences. Through comprehensive explainability analysis, we show that\nShiftSmooth offers superior attribution for motif discovery and localization\ncompared to traditional Vanilla Gradient methods. Our work presents an\nefficient, generalizable, and interpretable solution for TFBS prediction,\npotentially enabling new discoveries in genome biology and advancing our\nunderstanding of transcriptional regulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09754v2", "cate": "cs.LG", "date": "2025-07-13", "updated": "2025-07-18", "AI": {"title_translation": "基因组学中的可解释人工智能：基于专家混合模型的转录因子结合位点预测", "tldr": "本研究提出了一种新颖的专家混合（MoE）方法，用于转录因子结合位点（TFBS）预测，该方法整合了多个预训练的卷积神经网络（CNN）模型，并在分布内和分布外数据集上表现出竞争性或卓越的性能。此外，引入了ShiftSmooth，一种新的归因映射技术，为模型提供了更强的可解释性。", "motivation": "转录因子结合位点（TFBS）预测对于理解基因调控和各种生物过程至关重要。", "method": "本研究引入了一种新颖的专家混合（MoE）方法进行TFBS预测，该方法整合了多个预训练的卷积神经网络（CNN）模型，每个模型专门处理不同的TFBS模式。研究团队在分布内和分布外（OOD）数据集上评估了MoE模型的性能，并与单个专家模型进行对比，使用六个随机选择的转录因子（TF）进行OOD测试。此外，研究还引入了ShiftSmooth，一种新的归因映射技术，通过考虑输入序列的微小位移来提供更鲁棒的模型可解释性。", "result": "MoE模型在各种TF结合位点上实现了竞争性或卓越的性能，尤其在OOD场景中表现出色。方差分析（ANOVA）统计测试证实了这些性能差异的显著性。ShiftSmooth在基序发现和定位方面提供了优于传统Vanilla Gradient方法的归因。", "conclusion": "本研究为TFBS预测提供了一种高效、通用且可解释的解决方案，有望在基因组生物学中实现新发现并推进我们对转录调控的理解。", "translation": "转录因子结合位点（TFBS）预测对于理解基因调控和各种生物过程至关重要。本研究引入了一种新颖的专家混合（MoE）方法用于TFBS预测，该方法整合了多个预训练的卷积神经网络（CNN）模型，每个模型专门处理不同的TFBS模式。我们评估了MoE模型在分布内和分布外（OOD）数据集上相对于单个专家模型的性能，使用六个随机选择的转录因子（TF）进行OOD测试。我们的结果表明，MoE模型在各种TF结合位点上实现了竞争性或卓越的性能，尤其在OOD场景中表现出色。方差分析（ANOVA）统计测试证实了这些性能差异的显著性。此外，我们引入了ShiftSmooth，一种新颖的归因映射技术，通过考虑输入序列的微小位移来提供更鲁棒的模型可解释性。通过全面的可解释性分析，我们发现ShiftSmooth在基序发现和定位方面提供了优于传统Vanilla Gradient方法的归因。我们的工作为TFBS预测提供了一种高效、通用且可解释的解决方案，有望在基因组生物学中实现新发现并推进我们对转录调控的理解。", "summary": "本研究提出了一种创新的专家混合（MoE）模型，用于转录因子结合位点（TFBS）预测，该模型结合了多个专门的卷积神经网络（CNN）。该MoE模型在分布内和分布外数据集上均表现出优异或竞争性性能，尤其在处理未见过的数据时表现突出。此外，研究还引入了一种名为ShiftSmooth的新型归因映射技术，显著增强了模型的可解释性，在基序发现和定位方面优于传统方法。这项工作为TFBS预测提供了一个高效、通用且可解释的框架，有望推动基因组生物学和转录调控研究的进展。", "keywords": "转录因子结合位点预测, 专家混合模型, 卷积神经网络, 可解释人工智能, ShiftSmooth", "comments": "这项研究的创新之处在于结合了专家混合模型（MoE）与卷积神经网络（CNN）来解决TFBS预测的复杂性，并特别关注了模型在分布外（OOD）数据上的泛化能力。引入的ShiftSmooth技术是一个重要的贡献，它通过提高模型的可解释性，特别是通过提供更鲁棒的归因映射来帮助发现和定位生物基序，解决了可解释AI在基因组学应用中的关键挑战。这使得该解决方案不仅高效和通用，而且在实际生物学发现中更具实用价值。"}}
{"id": "2507.13970", "title": "A segmented robot grasping perception neural network for edge AI", "authors": ["Casper Bröcheler", "Thomas Vroom", "Derrick Timmermans", "Alan van den Akker", "Guangzhi Tang", "Charalampos S. Kouzinopoulos", "Rico Möckel"], "categories": ["cs.RO", "cs.AI", "I.2; I.2.9; I.2.10"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted by SMC 2025", "url": "http://arxiv.org/abs/2507.13970v1", "summary": "Robotic grasping, the ability of robots to reliably secure and manipulate\nobjects of varying shapes, sizes and orientations, is a complex task that\nrequires precise perception and control. Deep neural networks have shown\nremarkable success in grasp synthesis by learning rich and abstract\nrepresentations of objects. When deployed at the edge, these models can enable\nlow-latency, low-power inference, making real-time grasping feasible in\nresource-constrained environments. This work implements Heatmap-Guided Grasp\nDetection, an end-to-end framework for the detection of 6-Dof grasp poses, on\nthe GAP9 RISC-V System-on-Chip. The model is optimised using hardware-aware\ntechniques, including input dimensionality reduction, model partitioning, and\nquantisation. Experimental evaluation on the GraspNet-1Billion benchmark\nvalidates the feasibility of fully on-chip inference, highlighting the\npotential of low-power MCUs for real-time, autonomous manipulation.", "comment": "Accepted by SMC 2025", "pdf_url": "http://arxiv.org/pdf/2507.13970v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "用于边缘AI的分割机器人抓取感知神经网络", "tldr": "该研究在边缘AI芯片上实现了并优化了一种机器人抓取感知神经网络，证明了低功耗微控制器实现实时自主操作的可行性。", "motivation": "机器人抓取是一个需要精确感知和控制的复杂任务。深度神经网络在抓取合成方面取得了成功，但在资源受限的环境中，需要在边缘设备上实现低延迟、低功耗的实时抓取推理。", "method": "本文在GAP9 RISC-V片上系统上实现了热图引导的抓取检测（Heatmap-Guided Grasp Detection），这是一个用于检测6自由度抓取姿态的端到端框架。模型通过硬件感知技术进行了优化，包括输入降维、模型分区和量化。", "result": "在GraspNet-1Billion基准测试上的实验评估验证了完全片上推理的可行性。", "conclusion": "研究结果突出了低功耗微控制器在实时、自主操作方面的潜力。", "translation": "机器人抓取，即机器人可靠地固定和操纵不同形状、大小和方向物体的能力，是一项需要精确感知和控制的复杂任务。深度神经网络通过学习丰富和抽象的物体表示，在抓取合成方面取得了显著成功。当部署在边缘设备上时，这些模型可以实现低延迟、低功耗的推理，从而在资源受限的环境中实现实时抓取。这项工作在GAP9 RISC-V片上系统上实现了热图引导的抓取检测，这是一个用于检测6自由度抓取姿态的端到端框架。该模型使用硬件感知技术进行了优化，包括输入降维、模型分区和量化。在GraspNet-1Billion基准测试上的实验评估验证了完全片上推理的可行性，突出了低功耗微控制器在实时、自主操作方面的潜力。", "summary": "本文在GAP9 RISC-V片上系统上实现并优化了一种用于6自由度抓取姿态检测的端到端神经网络框架——热图引导的抓取检测。该模型通过输入降维、模型分区和量化等硬件感知技术进行了优化，旨在实现边缘设备上的低延迟、低功耗实时机器人抓取。在GraspNet-1Billion基准测试上的实验验证了其完全片上推理的可行性，展示了低功耗微控制器在实时自主操作中的巨大潜力。", "keywords": "机器人抓取, 边缘AI, 神经网络, 硬件优化, RISC-V", "comments": "这项工作创新性地将复杂的机器人抓取感知神经网络部署到资源受限的边缘AI芯片上，并通过硬件感知优化实现了高效的片上推理。其重要性在于为实时、低功耗的自主机器人操作提供了可行的解决方案，特别是在工业自动化和嵌入式系统等领域具有广阔的应用前景。"}}
{"id": "2505.13916", "title": "Robotic Monitoring of Colorimetric Leaf Sensors for Precision Agriculture", "authors": ["Malakhi Hopkins", "Alice Kate Li", "Shobhita Kramadhati", "Jackson Arnold", "Akhila Mallavarapu", "Chavez Lawrence", "Varun Murali", "Sanjeev J. Koppal", "Cherie R. Kagan", "Vijay Kumar"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Revised version. Initial version was accepted to the Novel Approaches for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "url": "http://arxiv.org/abs/2505.13916v2", "summary": "Common remote sensing modalities (RGB, multispectral, hyperspectral imaging\nor LiDAR) are often used to indirectly measure crop health and do not directly\ncapture plant stress indicators. Commercially available direct leaf sensors are\nbulky, powered electronics that are expensive and interfere with crop growth.\nIn contrast, low-cost, passive and bio-degradable leaf sensors offer an\nopportunity to advance real-time monitoring as they directly interface with the\ncrop surface while not interfering with crop growth. To this end, we co-design\na sensor-detector system, where the sensor is a passive colorimetric leaf\nsensor that directly measures crop health in a precision agriculture setting,\nand the detector autonomously obtains optical signals from these leaf sensors.\nThe detector comprises a low size weight and power (SWaP) mobile ground robot\nwith an onboard monocular RGB camera and object detector to localize each leaf\nsensor, as well as a hyperspectral camera with a motorized mirror and halogen\nlight to acquire hyperspectral images. The sensor's crop health-dependent\noptical signals can be extracted from the hyperspectral images. The\nproof-of-concept system is demonstrated in row-crop environments both indoors\nand outdoors where it is able to autonomously navigate, locate and obtain a\nhyperspectral image of all leaf sensors present, and acquire interpretable\nspectral resonance with 80 $\\%$ accuracy within a required retrieval distance\nfrom the sensor.", "comment": "Revised version. Initial version was accepted to the Novel Approaches\n  for Precision Agriculture and Forestry with Autonomous Robots IEEE ICRA\n  Workshop - 2025", "pdf_url": "http://arxiv.org/pdf/2505.13916v2", "cate": "cs.RO", "date": "2025-05-20", "updated": "2025-07-18", "AI": {"title_translation": "用于精准农业的颜色叶片传感器机器人监测", "tldr": "本文提出并演示了一种机器人系统，用于自主监测低成本、无源颜色叶片传感器，以直接测量作物健康，克服了传统遥感和现有叶片传感器的局限性。", "motivation": "传统的遥感方法（如RGB、多光谱、高光谱成像或激光雷达）通常间接测量作物健康，无法直接捕捉植物胁迫指标。市售的直接叶片传感器体积庞大、需要供电、价格昂贵且会干扰作物生长。", "method": "本文共同设计了一个传感器-探测器系统。传感器是无源颜色叶片传感器，直接测量作物健康。探测器是一个低功耗、轻量级、小型化的移动地面机器人，配备板载单目RGB相机和物体检测器用于定位叶片传感器，以及一个带有电动镜和卤素灯的高光谱相机，用于获取高光谱图像。通过高光谱图像提取依赖于作物健康的传感器光学信号。", "result": "该概念验证系统在室内外行作物环境中进行了演示，能够自主导航、定位并获取所有叶片传感器的高光谱图像，并在所需检索距离内以80%的准确率获取可解释的光谱共振。", "conclusion": "该机器人监测系统成功展示了在精准农业中自主监测颜色叶片传感器的可行性，能够有效获取作物健康数据。", "translation": "常见的遥感模式（RGB、多光谱、高光谱成像或激光雷达）通常用于间接测量作物健康，并且不能直接捕获植物胁迫指标。市售的直接叶片传感器是笨重、需要供电的电子设备，它们价格昂贵并干扰作物生长。相比之下，低成本、无源和可生物降解的叶片传感器为推进实时监测提供了机会，因为它们直接与作物表面接触，同时不干扰作物生长。为此，我们共同设计了一个传感器-探测器系统，其中传感器是无源颜色叶片传感器，可在精准农业环境中直接测量作物健康，探测器自主地从这些叶片传感器获取光学信号。探测器包括一个低尺寸重量和功率（SWaP）的移动地面机器人，该机器人配备板载单目RGB相机和物体检测器以定位每个叶片传感器，以及一个带有电动镜和卤素灯的高光谱相机以获取高光谱图像。传感器的作物健康相关光学信号可以从高光谱图像中提取。该概念验证系统在室内外行作物环境中进行了演示，它能够自主导航、定位并获取所有现有叶片传感器的高光谱图像，并在所需检索距离内以80%的准确率获取可解释的光谱共振。", "summary": "本文提出了一种用于精准农业的机器人监测系统，旨在克服传统遥感和现有叶片传感器在作物健康监测方面的局限性。该系统由低成本、无源的颜色叶片传感器和搭载RGB相机、物体检测器及高光谱相机的移动地面机器人组成。机器人能够自主导航、定位并获取叶片传感器的高光谱图像，从中提取作物健康相关的光学信号。概念验证系统在室内外环境中演示成功，实现了对叶片传感器的自主识别和数据采集，并在指定距离内达到了80%的光谱共振准确率，为直接、非侵入性作物健康监测提供了有效方案。", "keywords": "机器人监测, 颜色叶片传感器, 精准农业, 高光谱成像, 地面机器人", "comments": "该论文提出了一种新颖的集成系统，将低成本、无源的颜色叶片传感器与自主移动机器人相结合，用于直接、非侵入性地监测作物健康。其创新点在于结合了直接接触式传感器和自动化高光谱图像采集，克服了传统遥感间接性以及现有直采传感器高成本和干扰作物生长的缺点。系统在自主导航和数据获取方面的概念验证成功，展示了其在精准农业领域的巨大潜力。然而，论文未详细说明颜色叶片传感器的具体工作原理和生物降解性细节，也未提及系统的部署成本效益分析和长期耐久性。"}}
{"id": "2507.13458", "title": "Domain-randomized deep learning for neuroimage analysis", "authors": ["Malte Hoffmann"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      12 pages, 6 figures, 2 tables, deep learning, domain generalization, domain randomization, neuroimaging, medical image analysis, accepted for publication in IEEE Signal Processing Magazine", "url": "http://arxiv.org/abs/2507.13458v1", "summary": "Deep learning has revolutionized neuroimage analysis by delivering\nunprecedented speed and accuracy. However, the narrow scope of many training\ndatasets constrains model robustness and generalizability. This challenge is\nparticularly acute in magnetic resonance imaging (MRI), where image appearance\nvaries widely across pulse sequences and scanner hardware. A recent\ndomain-randomization strategy addresses the generalization problem by training\ndeep neural networks on synthetic images with randomized intensities and\nanatomical content. By generating diverse data from anatomical segmentation\nmaps, the approach enables models to accurately process image types unseen\nduring training, without retraining or fine-tuning. It has demonstrated\neffectiveness across modalities including MRI, computed tomography, positron\nemission tomography, and optical coherence tomography, as well as beyond\nneuroimaging in ultrasound, electron and fluorescence microscopy, and X-ray\nmicrotomography. This tutorial paper reviews the principles, implementation,\nand potential of the synthesis-driven training paradigm. It highlights key\nbenefits, such as improved generalization and resistance to overfitting, while\ndiscussing trade-offs such as increased computational demands. Finally, the\narticle explores practical considerations for adopting the technique, aiming to\naccelerate the development of generalizable tools that make deep learning more\naccessible to domain experts without extensive computational resources or\nmachine learning knowledge.", "comment": "12 pages, 6 figures, 2 tables, deep learning, domain generalization,\n  domain randomization, neuroimaging, medical image analysis, accepted for\n  publication in IEEE Signal Processing Magazine", "pdf_url": "http://arxiv.org/pdf/2507.13458v1", "cate": "eess.IV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "域随机化深度学习在神经影像分析中的应用", "tldr": "本文综述了一种域随机化深度学习策略，通过在合成图像上训练模型，显著提高了神经影像分析中深度学习模型的泛化能力和鲁棒性。", "motivation": "深度学习在神经影像分析中表现出色，但训练数据集的范围狭窄限制了模型的鲁棒性和泛化能力，尤其是在MRI中图像外观差异大。需要一种方法来解决泛化问题。", "method": "采用域随机化策略，通过在具有随机强度和解剖内容的合成图像上训练深度神经网络。这种方法通过从解剖分割图生成多样化数据，使模型能够准确处理训练期间未见的图像类型，无需重新训练或微调。", "result": "该方法已在MRI、CT、PET、OCT等多种模态以及超声、电子和荧光显微镜、X射线显微断层扫描等非神经影像领域中证明了其有效性。它提高了泛化能力并增强了抗过拟合能力。", "conclusion": "本文探讨了域随机化训练范式的原理、实现和潜力，旨在加速可泛化工具的开发，使深度学习更易于领域专家使用，即使他们缺乏大量计算资源或机器学习知识。", "translation": "深度学习以其前所未有的速度和准确性彻底改变了神经影像分析。然而，许多训练数据集的狭窄范围限制了模型的鲁棒性和泛化能力。这一挑战在磁共振成像（MRI）中尤为突出，因为图像外观在不同的脉冲序列和扫描仪硬件之间差异很大。最近的域随机化策略通过在具有随机强度和解剖内容的合成图像上训练深度神经网络来解决泛化问题。通过从解剖分割图生成多样化数据，该方法使模型能够准确处理训练期间未见的图像类型，而无需重新训练或微调。它已在包括MRI、计算机断层扫描、正电子发射断层扫描和光学相干断层扫描在内的多种模态中，以及在神经影像学之外的超声、电子和荧光显微镜和X射线显微断层扫描中证明了其有效性。本教程论文回顾了这种合成驱动训练范式的原理、实现和潜力。它强调了主要优点，例如改进的泛化能力和抗过拟合能力，同时讨论了计算需求增加等权衡。最后，本文探讨了采用该技术的实际考虑因素，旨在加速可泛化工具的开发，使深度学习更容易被没有大量计算资源或机器学习知识的领域专家所接受。", "summary": "本教程论文综述了一种名为域随机化的深度学习策略，旨在解决神经影像分析中深度学习模型泛化能力不足的问题。该方法通过在具有随机强度和解剖内容的合成图像上训练神经网络，从而生成多样化数据。这使得模型无需重新训练或微调即可处理未见过的图像类型，并在多种影像模态中展现出卓越的泛化能力和抗过拟合性。论文探讨了其原理、实现、潜在益处（如泛化能力提升）和权衡（如计算需求增加），并提供了实用建议，以期推动可泛化深度学习工具的普及。", "keywords": "域随机化, 深度学习, 神经影像分析, 泛化能力, 合成数据", "comments": "该论文重点介绍的域随机化策略通过合成数据训练，有效解决了深度学习在神经影像分析中泛化能力差的问题，具有重要的创新性。它提供了一种无需大量真实世界多样化数据和重复微调即可提高模型鲁棒性的方法，对于资源有限的领域专家尤其重要。然而，这种方法的计算成本增加是一个需要考虑的限制。"}}
{"id": "2507.11291", "title": "Permutation patterns in streams", "authors": ["Benjamin Aram Berendsohn"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11291v2", "summary": "Permutation patterns and pattern avoidance are central, well-studied concepts\nin combinatorics and computer science. Given two permutations $\\tau$ and $\\pi$,\nthe pattern matching problem (PPM) asks whether $\\tau$ contains $\\pi$. This\nproblem arises in various contexts in computer science and statistics and has\nbeen studied extensively in exact-, parameterized-, approximate-,\nproperty-testing- and other formulations.\n  In this paper, we study pattern matching in a streaming setting, when the\ninput $\\tau$ is revealed sequentially, one element at a time. There is\nextensive work on the space complexity of various statistics in streams of\nintegers. The novelty of our setting is that the input stream is a permutation,\nwhich allows inferring some information about future inputs. Our algorithms\ncrucially take advantage of this fact, while existing lower bound techniques\nbecome difficult to apply.\n  We show that the complexity of the problem changes dramatically depending on\nthe pattern $\\pi$. The space requirement is: $\\Theta(k\\log{n})$ for the\nmonotone patterns $\\pi = 12\\dots k$, or $\\pi = k\\dots21$, $O(\\sqrt{n\\log{n}})$\nfor $\\pi \\in \\{312,132\\}$, $O(\\sqrt{n} \\log n)$ for $\\pi \\in \\{231,213\\}$, and\n$\\widetilde{\\Theta}_{\\pi}(n)$ for all other $\\pi$. If $\\tau$ is an arbitrary\nsequence of integers (not necessary a permutation), we show that the complexity\nis $\\widetilde{\\Theta}_{\\pi}(n)$ in all except the first (monotone) cases.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11291v2", "cate": "cs.DS", "date": "2025-07-15", "updated": "2025-07-18", "AI": {"title_translation": "流中的排列模式", "tldr": "本文研究了流式设置中排列模式匹配的空间复杂度，发现其复杂度高度依赖于特定模式。", "motivation": "排列模式匹配问题（PPM）在组合学、计算机科学和统计学中是一个核心且被广泛研究的问题，但传统研究未充分考虑输入以流式形式（一次一个元素）揭示的情况。本文的动机在于研究这种流式设置下的PPM，特别是当输入流被保证为排列时，这与现有整数流研究不同，并可能利用排列的特性来设计更高效的算法。", "method": "本文在流式设置下研究排列模式匹配问题，其中输入排列 $\\tau$ 的元素是顺序揭示的。研究利用了输入流是排列这一特性，该特性允许推断未来输入的一些信息，并据此设计算法，这使得现有针对任意整数流的下界技术难以直接应用。", "result": "研究表明，问题的空间复杂度随模式 $\\pi$ 的不同而显著变化：对于单调模式 $\\pi = 12\\dots k$ 或 $\\pi = k\\dots21$，空间需求为 $\\Theta(k\\log{n})$；对于 $\\pi \\in \\{312,132\\}$，空间需求为 $O(\\sqrt{n\\log{n}})$；对于 $\\pi \\in \\{231,213\\}$，空间需求为 $O(\\sqrt{n} \\log n)$；对于所有其他模式 $\\pi$，空间需求为 $\\widetilde{\\Theta}_{\\pi}(n)$。此外，如果 $\\tau$ 是任意整数序列（非排列），则除了单调模式外，所有情况的复杂度均为 $\\widetilde{\\Theta}_{\\pi}(n)$。", "conclusion": "排列模式匹配在流式设置中的空间复杂度高度依赖于具体的模式类型。当输入流被保证为排列时，可以利用其结构特性来设计更高效的算法，从而在某些情况下实现比处理任意整数流更低的复杂度。", "translation": "排列模式和模式避免是组合学和计算机科学中核心且被充分研究的概念。给定两个排列 $\\tau$ 和 $\\pi$，模式匹配问题（PPM）询问 $\\tau$ 是否包含 $\\pi$。这个问题出现在计算机科学和统计学的各种背景中，并已在精确、参数化、近似、属性测试和其他形式中得到了广泛研究。\n在本文中，我们研究了流式设置中的模式匹配，即输入 $\\tau$ 元素是顺序揭示的，一次一个。关于整数流中各种统计量的空间复杂性已有大量工作。我们设置的新颖之处在于输入流是一个排列，这允许推断未来输入的一些信息。我们的算法关键地利用了这一事实，而现有下界技术变得难以应用。\n我们发现问题的复杂性根据模式 $\\pi$ 的不同而显著变化。空间需求如下：对于单调模式 $\\pi = 12\\dots k$ 或 $\\pi = k\\dots21$，为 $\\Theta(k\\log{n})$；对于 $\\pi \\in \\{312,132\\}$，为 $O(\\sqrt{n\\log{n}})$；对于 $\\pi \\in \\{231,213\\}$，为 $O(\\sqrt{n} \\log n)$；对于所有其他 $\\pi$，为 $\\widetilde{\\Theta}_{\\pi}(n)$。如果 $\\tau$ 是任意整数序列（不一定是排列），我们发现除了第一种（单调）情况外，复杂度在所有其他情况下均为 $\\widetilde{\\Theta}_{\\pi}(n)$。", "summary": "本文研究了流式设置下的排列模式匹配问题，其中输入排列逐个元素揭示。与现有研究不同，本文利用输入是排列这一特性来设计算法。研究发现，该问题的空间复杂度高度依赖于所匹配的特定模式：对于单调模式复杂度较低，对于特定长度为3的模式复杂度为次线性，而对于大多数其他模式则与输入大小线性相关。此外，研究还比较了排列流与任意整数流的复杂度差异，突出了排列特性带来的优化潜力。", "keywords": "排列模式, 流算法, 空间复杂度, 模式匹配, 组合学", "comments": "本文的创新点在于将排列模式匹配问题引入流式处理环境，并特别强调了输入是排列而非任意整数序列这一特性。这种区分使得研究能够利用排列的结构信息来设计更高效的算法，突破了传统下界的限制。其重要性在于揭示了在流数据分析中，数据类型的特定属性（如排列）如何显著影响算法复杂性，为未来在特定结构化流数据上的算法设计提供了新的视角。"}}
{"id": "2502.13445", "title": "An Efficient Iterative Decoupling Method for Thermo-Poroelasticity Based on a Four-Field Formulation", "authors": ["Mingchao Cai", "Jingzhi Li", "Ziliang Li", "Qiang Liu"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      submitted to a journal, accepted", "url": "http://arxiv.org/abs/2502.13445v2", "summary": "This paper studies the thermo-poroelasticity model. By introducing an\nintermediate variable, we transform the original three-field model into a\nfour-field model. Building upon this four-field model, we present both a\ncoupled finite element method and a decoupled iterative finite element method.\nWe prove the stability and optimal convergence of the coupled finite element\nmethod. Furthermore, we establish the convergence of the decoupled iterative\nmethod. This paper focuses primarily on analyzing the iterative decoupled\nalgorithm. It demonstrates that the algorithm's convergence does not require\nany additional assumptions about physical parameters or stabilization\nparameters. Numerical results are provided to demonstrate the effectiveness and\ntheoretical validity of these new methods.", "comment": "submitted to a journal, accepted", "pdf_url": "http://arxiv.org/pdf/2502.13445v2", "cate": "math.NA", "date": "2025-02-19", "updated": "2025-07-18", "AI": {"title_translation": "基于四场公式的热孔弹性高效迭代解耦方法", "tldr": "本文提出并分析了一种基于四场公式的热孔弹性高效迭代解耦方法，证明了其收敛性和有效性。", "motivation": "本文旨在研究热孔弹性模型，并通过引入中间变量将原始的三场模型转化为四场模型，进而开发出更高效、稳定的耦合和解耦有限元数值方法。", "method": "通过引入一个中间变量，将原始的三场热孔弹性模型转化为四场模型。基于此四场模型，提出了一种耦合有限元方法和一种解耦迭代有限元方法。证明了耦合有限元方法的稳定性和最优收敛性。建立了迭代解耦方法的收敛性，并指出其收敛性不需要对物理参数或稳定化参数有任何额外的假设。提供了数值结果以证明新方法的有效性和理论正确性。", "result": "耦合有限元方法的稳定性和最优收敛性得到了证明。迭代解耦方法的收敛性得到了建立，并且其收敛性不依赖于对物理或稳定化参数的额外假设。数值结果验证了这些新方法的有效性和理论正确性。", "conclusion": "本文成功开发并分析了基于四场公式的热孔弹性高效且稳定的数值方法（包括耦合和解耦迭代有限元方法），其中迭代方法展现出鲁棒的收敛特性。", "translation": "本文研究热孔弹性模型。通过引入一个中间变量，我们将原始的三场模型转化为四场模型。在此四场模型的基础上，我们提出了一种耦合有限元方法和一种解耦迭代有限元方法。我们证明了耦合有限元方法的稳定性和最优收敛性。此外，我们建立了解耦迭代方法的收敛性。本文主要侧重于分析迭代解耦算法。它表明该算法的收敛性不需要对物理参数或稳定化参数有任何额外的假设。提供了数值结果来证明这些新方法的有效性和理论有效性。", "summary": "本文通过引入一个中间变量，将热孔弹性模型从三场公式转换为四场公式。在此基础上，提出了耦合有限元方法和解耦迭代有限元方法。研究证明了耦合有限元方法的稳定性和最优收敛性，并建立了迭代解耦方法的收敛性，强调其收敛性不依赖于额外的参数假设。数值结果验证了这些新方法的有效性。", "keywords": "热孔弹性, 四场公式, 迭代解耦方法, 有限元方法, 收敛性", "comments": "本文的创新点在于将热孔弹性模型转换为四场公式，从而能够开发出更鲁棒的数值方法，特别是迭代解耦算法，其收敛性不依赖于对物理或稳定化参数的额外假设。这提升了该方法的实际适用性和可靠性。"}}
{"id": "2507.13956", "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "categories": ["cs.AI", "cs.CV", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13956v1", "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13956v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "阿尔茨海默病预测的跨模态因果干预", "tldr": "本研究提出了一种名为ADPC的跨模态因果干预框架，利用大型语言模型和多模态影像数据，通过因果干预隐式消除混杂因素，从而在阿尔茨海默病（AD）诊断中实现最先进的性能。", "motivation": "轻度认知障碍（MCI）是阿尔茨海默病（AD）的前驱阶段，早期识别和干预可以有效延缓疾病进展。然而，由于多模态数据的选择偏差和变量间复杂关系引起的混杂因素，AD的诊断仍然是一个重大的挑战。非因果模型易捕获虚假相关性，导致结果不可靠。", "method": "本研究提出了一种名为阿尔茨海默病预测的跨模态因果干预（ADPC）的新型视觉-语言因果干预框架。ADPC利用大型语言模型（LLM）在严格模板下总结临床数据，即使数据集不完整或分布不均也能保持结构化文本输出。该模型使用磁共振成像（MRI）、功能性磁共振成像（fMRI）图像以及LLM生成的文本数据，将参与者分类为认知正常（CN）、MCI和AD类别。通过因果干预，该框架隐式地消除了神经影像伪影和年龄相关生物标志物等混杂因素。", "result": "实验结果表明，该方法在区分CN/MCI/AD病例方面表现出色，在大多数评估指标上取得了最先进（SOTA）的性能。", "conclusion": "该研究展示了将因果推理与多模态学习相结合用于神经系统疾病诊断的潜力。", "translation": "轻度认知障碍（MCI）是阿尔茨海默病（AD）的前驱阶段，早期识别和干预可以有效延缓痴呆症的进展。然而，由于主要由多模态数据的选择偏差和变量之间复杂关系引起的混杂因素，AD的诊断在神经病学中仍然是一个重大挑战。为了解决这些问题，我们提出了一种名为阿尔茨海默病预测的跨模态因果干预（ADPC）的新型视觉-语言因果干预框架，用于诊断辅助。我们的ADPC采用大型语言模型（LLM）在严格模板下总结临床数据，即使数据集不完整或分布不均也能保持结构化文本输出。ADPC模型利用磁共振成像（MRI）、功能性磁共振成像（fMRI）图像以及LLM生成的文本数据来将参与者分类为认知正常（CN）、MCI和AD类别。由于混杂因素（如神经影像伪影和年龄相关生物标志物）的存在，非因果模型可能捕获虚假输入-输出相关性，从而产生不可靠的结果。我们的框架通过因果干预隐式地消除了混杂因素。实验结果表明，我们的方法在区分CN/MCI/AD病例方面表现出色，在大多数评估指标上取得了最先进（SOTA）的性能。这项研究展示了将因果推理与多模态学习相结合用于神经系统疾病诊断的潜力。", "summary": "本研究提出了一种名为ADPC的跨模态因果干预框架，旨在解决阿尔茨海默病（AD）诊断中因混杂因素导致的问题。ADPC结合了大型语言模型（LLM）处理临床文本数据（确保结构化输出）以及MRI和fMRI影像数据。通过因果干预，该框架能够隐式消除混杂因素，避免非因果模型可能捕获的虚假相关性。实验证明，ADPC在区分认知正常、轻度认知障碍和AD患者方面表现优异，并在多项评估指标上达到了最先进水平，突显了因果推理与多模态学习在神经系统疾病诊断中的巨大潜力。", "keywords": "阿尔茨海默病预测, 跨模态, 因果干预, 大型语言模型, 多模态学习", "comments": "这项研究的创新之处在于将因果干预引入跨模态学习，以解决阿尔茨海默病诊断中常见的混杂因素问题。通过结合大型语言模型处理临床文本数据和神经影像数据，ADPC提供了一个强大的诊断辅助工具。其在消除混杂因素方面的能力，使其结果比传统非因果模型更可靠，为神经系统疾病的精准诊断开辟了新途径。"}}
{"id": "2507.13428", "title": "\"PhyWorldBench\": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models", "authors": ["Jing Gu", "Xian Liu", "Yu Zeng", "Ashwin Nagarajan", "Fangrui Zhu", "Daniel Hong", "Yue Fan", "Qianqi Yan", "Kaiwen Zhou", "Ming-Yu Liu", "Xin Eric Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      31 pages, 21 figures", "url": "http://arxiv.org/abs/2507.13428v1", "summary": "Video generation models have achieved remarkable progress in creating\nhigh-quality, photorealistic content. However, their ability to accurately\nsimulate physical phenomena remains a critical and unresolved challenge. This\npaper presents PhyWorldBench, a comprehensive benchmark designed to evaluate\nvideo generation models based on their adherence to the laws of physics. The\nbenchmark covers multiple levels of physical phenomena, ranging from\nfundamental principles like object motion and energy conservation to more\ncomplex scenarios involving rigid body interactions and human or animal motion.\nAdditionally, we introduce a novel \"\"Anti-Physics\"\" category, where prompts\nintentionally violate real-world physics, enabling the assessment of whether\nmodels can follow such instructions while maintaining logical consistency.\nBesides large-scale human evaluation, we also design a simple yet effective\nmethod that could utilize current MLLM to evaluate the physics realism in a\nzero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation\nmodels, including five open-source and five proprietary models, with a detailed\ncomparison and analysis. we identify pivotal challenges models face in adhering\nto real-world physics. Through systematic testing of their outputs across 1,050\ncurated prompts-spanning fundamental, composite, and anti-physics scenarios-we\nidentify pivotal challenges these models face in adhering to real-world\nphysics. We then rigorously examine their performance on diverse physical\nphenomena with varying prompt types, deriving targeted recommendations for\ncrafting prompts that enhance fidelity to physical principles.", "comment": "31 pages, 21 figures", "pdf_url": "http://arxiv.org/pdf/2507.13428v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "“PhyWorldBench”：文本到视频模型中物理真实性的综合评估", "tldr": "本文提出了PhyWorldBench，一个全面的基准测试，用于评估文本到视频模型在物理真实性方面的表现，并揭示了现有模型面临的关键挑战。", "motivation": "视频生成模型在创建高质量、照片级真实感内容方面取得了显著进展，但其准确模拟物理现象的能力仍然是一个关键且未解决的挑战。", "method": "本文提出了PhyWorldBench，一个旨在评估视频生成模型对物理定律遵守程度的综合基准。该基准涵盖从物体运动、能量守恒等基本原理到刚体相互作用、人类或动物运动等更复杂场景的多个物理现象级别。此外，引入了一个新颖的“反物理”类别，其中提示故意违反现实世界物理，以评估模型在保持逻辑一致性的同时是否能遵循此类指令。除了大规模人工评估，还设计了一种简单有效的方法，利用当前的MLLM进行零样本物理真实性评估。评估了12个最先进的文本到视频生成模型，包括五个开源和五个专有模型，并进行了详细的比较和分析。", "result": "通过对1,050个精心策划的提示（涵盖基本、复合和反物理场景）的输出进行系统测试，论文识别了模型在遵守现实世界物理方面面临的关键挑战。通过严格检查模型在不同提示类型下对各种物理现象的表现，论文得出了针对性建议，以指导如何编写提示来增强对物理原理的忠实度。", "conclusion": "现有文本到视频模型在模拟物理现象方面存在显著挑战，PhyWorldBench基准测试能有效识别这些问题并为提升物理真实性提供指导和建议。", "translation": "视频生成模型在创建高质量、照片级真实感内容方面取得了显著进展。然而，它们准确模拟物理现象的能力仍然是一个关键且未解决的挑战。本文提出了PhyWorldBench，一个旨在评估视频生成模型对物理定律遵守程度的综合基准。该基准涵盖了多个级别的物理现象，从物体运动、能量守恒等基本原理到涉及刚体相互作用以及人类或动物运动的更复杂场景。此外，我们引入了一个新颖的“反物理”类别，其中提示故意违反现实世界物理，从而能够评估模型在保持逻辑一致性的同时是否能遵循此类指令。除了大规模人工评估，我们还设计了一种简单而有效的方法，可以利用当前的MLLM以零样本方式评估物理真实性。我们评估了12个最先进的文本到视频生成模型，包括五个开源和五个专有模型，并进行了详细的比较和分析。我们识别了模型在遵守现实世界物理方面面临的关键挑战。通过对1,050个精心策划的提示（涵盖基本、复合和反物理场景）的输出进行系统测试，我们识别了这些模型在遵守现实世界物理方面面临的关键挑战。然后，我们严格检查了它们在不同提示类型下对各种物理现象的表现，得出了针对性建议，以指导如何编写提示来增强对物理原理的忠实度。", "summary": "本文提出了PhyWorldBench，一个全面的基准测试，旨在评估文本到视频模型在模拟物理现象方面的能力。该基准涵盖了从基本物理原理到复杂交互的多个层面，并引入了独特的“反物理”类别以测试模型遵循反常指令的能力。研究结合了大规模人工评估和基于MLLM的零样本评估方法，对12个主流文本到视频模型进行了测试。结果揭示了现有模型在物理真实性方面面临的关键挑战，并提供了优化提示以提高物理准确性的具体建议。", "keywords": "文本到视频模型, 物理真实性, 基准测试, PhyWorldBench, 评估", "comments": "本文的创新之处在于提出了PhyWorldBench这一全面的物理真实性评估基准，特别是引入了“反物理”类别，这为评估模型理解和遵循违反物理常识指令的能力提供了新颖视角。此外，结合MLLM进行零样本评估的方法也值得关注。该研究对于理解当前文本到视频模型在物理模拟方面的局限性具有重要意义，并为未来模型的发展提供了明确的方向和优化建议。"}}
{"id": "2507.13957", "title": "DUALRec: A Hybrid Sequential and Language Model Framework for Context-Aware Movie Recommendation", "authors": ["Yitong Li", "Raoul Grasman"], "categories": ["cs.IR", "cs.AI", "cs.LG", "68T05, 68T50, 62M45", "H.3.3; I.2.6; H.3.4; I.2.7"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13957v1", "summary": "The modern recommender systems are facing an increasing challenge of\nmodelling and predicting the dynamic and context-rich user preferences.\nTraditional collaborative filtering and content-based methods often struggle to\ncapture the temporal patternings and evolving user intentions. While Large\nLanguage Models (LLMs) have gained gradual attention in recent years, by their\nstrong semantic understanding and reasoning abilities, they are not inherently\ndesigned to model chronologically evolving user preference and intentions. On\nthe other hand, for sequential models like LSTM (Long-Short-Term-Memory) which\nis good at capturing the temporal dynamics of user behaviour and evolving user\npreference over time, but still lacks a rich semantic understanding for\ncomprehensive recommendation generation. In this study, we propose DUALRec\n(Dynamic User-Aware Language-based Recommender), a novel recommender that\nleverages the complementary strength of both models, which combines the\ntemporal modelling abilities of LSTM networks with semantic reasoning power of\nthe fine-tuned Large Language Models. The LSTM component will capture users\nevolving preference through their viewing history, while the fine-tuned LLM\nvariants will leverage these temporal user insights to generate next movies\nthat users might enjoy. Experimental results on MovieLens-1M dataset shows that\nthe DUALRec model outperforms a wide range of baseline models, with\ncomprehensive evaluation matrices of Hit Rate (HR@k), Normalized Discounted\nCumulative Gain (NDCG@k), and genre similarity metrics. This research proposes\na novel architecture that bridges the gap between temporal sequence modeling\nand semantic reasoning, and offers a promising direction for developing more\nintelligent and context-aware recommenders.", "comment": "10 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13957v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DUALRec：一种用于上下文感知电影推荐的混合序列和语言模型框架", "tldr": "DUALRec结合LSTM和LLM，利用两者的互补优势，提高了上下文感知电影推荐的性能。", "motivation": "现代推荐系统难以建模和预测动态且上下文丰富的用户偏好。传统方法难以捕捉时间模式，而LLM虽有强语义理解能力但未设计用于建模时间演变偏好，序列模型（如LSTM）擅长时间动态但缺乏语义理解。", "method": "提出DUALRec模型，它结合了LSTM网络的时间建模能力和微调大型语言模型的语义推理能力。LSTM组件捕捉用户通过观看历史演变的偏好，而微调的LLM则利用这些时间洞察来生成推荐。", "result": "在MovieLens-1M数据集上的实验结果表明，DUALRec模型在命中率（HR@k）、归一化折损累积增益（NDCG@k）和流派相似性等综合评估指标上优于各种基线模型。", "conclusion": "本研究提出了一种新颖的架构，成功弥合了时间序列建模和语义推理之间的鸿沟，为开发更智能、上下文感知的推荐器提供了有希望的方向。", "translation": "现代推荐系统面临着建模和预测动态且上下文丰富的用户偏好的日益严峻的挑战。传统的协同过滤和基于内容的方法往往难以捕捉时间模式和不断变化的用户意图。虽然大型语言模型（LLM）近年来因其强大的语义理解和推理能力而逐渐受到关注，但它们并非天生设计用于建模按时间顺序演变的用户偏好和意图。另一方面，对于像LSTM（长短期记忆）这样的序列模型，它们擅长捕捉用户行为的时间动态和用户偏好随时间的演变，但仍然缺乏丰富的语义理解以生成全面的推荐。在本研究中，我们提出了DUALRec（动态用户感知语言推荐器），一种新颖的推荐系统，它利用了这两种模型的互补优势，结合了LSTM网络的时间建模能力和微调大型语言模型的语义推理能力。LSTM组件将通过用户的观看历史捕捉用户不断演变的偏好，而微调的LLM变体将利用这些时间用户洞察来生成用户可能喜欢的下一部电影。MovieLens-1M数据集上的实验结果表明，DUALRec模型在命中率（HR@k）、归一化折损累积增益（NDCG@k）和流派相似性指标等综合评估矩阵上优于各种基线模型。这项研究提出了一种新颖的架构，弥合了时间序列建模和语义推理之间的鸿沟，为开发更智能、上下文感知的推荐器提供了有希望的方向。", "summary": "该论文提出了DUALRec，一个结合LSTM和大型语言模型（LLM）的混合推荐框架，旨在解决现代推荐系统中捕捉动态和上下文丰富用户偏好的挑战。DUALRec利用LSTM捕捉用户偏好的时间演变，并结合LLM的语义理解能力生成电影推荐。实验结果表明，DUALRec在MovieLens-1M数据集上优于现有基线模型，证明了其在弥合时间序列建模和语义推理之间差距方面的有效性。", "keywords": "推荐系统, 混合模型, 序列模型, 大型语言模型, 上下文感知", "comments": "该研究的创新之处在于成功地将序列模型（LSTM）的时间动态捕捉能力与大型语言模型（LLM）的语义理解和推理能力结合起来，弥补了单一模型在处理复杂用户偏好时的不足。这种混合架构为上下文感知推荐系统提供了一个有前景的方向，特别是在处理用户偏好随时间演变和需要深层语义理解的场景中。其局限性可能在于模型的复杂性以及微调LLM所需的计算资源。"}}
{"id": "2506.23957", "title": "GaVS: 3D-Grounded Video Stabilization via Temporally-Consistent Local Reconstruction and Rendering", "authors": ["Zinuo You", "Stamatios Georgoulis", "Anpei Chen", "Siyu Tang", "Dengxin Dai"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      siggraph 2025, project website: this https URL . version 2, update discussion", "url": "http://arxiv.org/abs/2506.23957v2", "summary": "Video stabilization is pivotal for video processing, as it removes unwanted\nshakiness while preserving the original user motion intent. Existing\napproaches, depending on the domain they operate, suffer from several issues\n(e.g. geometric distortions, excessive cropping, poor generalization) that\ndegrade the user experience. To address these issues, we introduce\n\\textbf{GaVS}, a novel 3D-grounded approach that reformulates video\nstabilization as a temporally-consistent `local reconstruction and rendering'\nparadigm. Given 3D camera poses, we augment a reconstruction model to predict\nGaussian Splatting primitives, and finetune it at test-time, with multi-view\ndynamics-aware photometric supervision and cross-frame regularization, to\nproduce temporally-consistent local reconstructions. The model are then used to\nrender each stabilized frame. We utilize a scene extrapolation module to avoid\nframe cropping. Our method is evaluated on a repurposed dataset, instilled with\n3D-grounded information, covering samples with diverse camera motions and scene\ndynamics. Quantitatively, our method is competitive with or superior to\nstate-of-the-art 2D and 2.5D approaches in terms of conventional task metrics\nand new geometry consistency. Qualitatively, our method produces noticeably\nbetter results compared to alternatives, validated by the user study.", "comment": "siggraph 2025, project website: https://sinoyou.github.io/gavs.\n  version 2, update discussion", "pdf_url": "http://arxiv.org/pdf/2506.23957v2", "cate": "cs.GR", "date": "2025-06-30", "updated": "2025-07-18", "AI": {"title_translation": "GaVS：通过时间一致性局部重建和渲染实现的3D视频稳定", "tldr": "GaVS是一种新的3D视频稳定方法，通过局部3D重建和渲染来消除抖动并保持用户运动意图，避免裁剪。", "motivation": "现有视频稳定方法存在几何失真、过度裁剪和泛化性差等问题，这些问题会降低用户体验。", "method": "本文提出GaVS，一种3D-grounded的方法，将视频稳定重构为时间一致的“局部重建和渲染”范式。给定3D相机姿态，增强重建模型以预测高斯泼溅基元，并在测试时通过多视图动态感知光度监督和跨帧正则化进行微调，以生成时间一致的局部重建。模型用于渲染稳定帧，并利用场景外推模块避免帧裁剪。", "result": "在重新利用的3D数据集上进行评估，定量上，GaVS在传统任务指标和新的几何一致性方面与最先进的2D和2.5D方法相比具有竞争力或更优。定性上，与替代方法相比，GaVS产生了明显更好的结果，并得到了用户研究的验证。", "conclusion": "GaVS通过3D重建和渲染范式，有效解决了现有视频稳定方法的局限性，实现了高质量且无裁剪的稳定视频。", "translation": "视频稳定对于视频处理至关重要，因为它能去除不必要的抖动，同时保留原始用户运动意图。现有方法根据其操作领域，存在一些问题（例如几何失真、过度裁剪、泛化性差），这些问题会降低用户体验。为了解决这些问题，我们引入了**GaVS**，这是一种新颖的3D-grounded方法，它将视频稳定重新定义为时间一致的“局部重建和渲染”范式。给定3D相机姿态，我们增强了一个重建模型来预测高斯泼溅基元，并在测试时通过多视图动态感知光度监督和跨帧正则化对其进行微调，以生成时间一致的局部重建。然后，该模型用于渲染每个稳定的帧。我们利用场景外推模块来避免帧裁剪。我们的方法在一个经过改造的、注入了3D-grounded信息的、包含各种相机运动和场景动态样本的数据集上进行了评估。在定量方面，我们的方法在传统任务指标和新的几何一致性方面与最先进的2D和2.5D方法相比具有竞争力或更优。在定性方面，与替代方法相比，我们的方法产生了明显更好的结果，并得到了用户研究的验证。", "summary": "GaVS是一种新颖的3D视频稳定方法，通过将视频稳定重构为时间一致的“局部重建和渲染”范式来解决现有方法存在的几何失真和过度裁剪问题。该方法利用3D相机姿态，通过微调高斯泼溅基元生成时间一致的局部重建，并使用场景外推避免裁剪。实验表明，GaVS在定量和定性上均优于或与现有2D/2.5D方法相当。", "keywords": "视频稳定, 3D重建, 高斯泼溅, 局部重建, 时间一致性", "comments": "GaVS的创新之处在于将视频稳定问题转化为3D局部重建和渲染，利用高斯泼溅和时间一致性处理，并引入场景外推避免裁剪，这在视频稳定领域是一个新颖且有效的方法。其3D-grounded的特性有望带来更好的几何一致性和泛化能力。"}}
{"id": "2507.09958", "title": "Rethinking Inductive Bias in Geographically Neural Network Weighted Regression", "authors": ["Zhenyuan Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09958v3", "summary": "Inductive bias is a key factor in spatial regression models, determining how\nwell a model can learn from limited data and capture spatial patterns. This\nwork revisits the inductive biases in Geographically Neural Network Weighted\nRegression (GNNWR) and identifies limitations in current approaches for\nmodeling spatial non-stationarity. While GNNWR extends traditional\nGeographically Weighted Regression by using neural networks to learn spatial\nweighting functions, existing implementations are often restricted by fixed\ndistance-based schemes and limited inductive bias. We propose to generalize\nGNNWR by incorporating concepts from convolutional neural networks, recurrent\nneural networks, and transformers, introducing local receptive fields,\nsequential context, and self-attention into spatial regression. Through\nextensive benchmarking on synthetic spatial datasets with varying\nheterogeneity, noise, and sample sizes, we show that GNNWR outperforms classic\nmethods in capturing nonlinear and complex spatial relationships. Our results\nalso reveal that model performance depends strongly on data characteristics,\nwith local models excelling in highly heterogeneous or small-sample scenarios,\nand global models performing better with larger, more homogeneous data. These\nfindings highlight the importance of inductive bias in spatial modeling and\nsuggest future directions, including learnable spatial weighting functions,\nhybrid neural architectures, and improved interpretability for models handling\nnon-stationary spatial data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09958v3", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "重新思考地理神经网络加权回归中的归纳偏置", "tldr": "本文重新审视并改进了地理神经网络加权回归（GNNWR）中的归纳偏置，通过引入卷积神经网络、循环神经网络和Transformer的概念，使其在捕获非线性复杂空间关系方面优于传统方法，并发现模型性能受数据特性影响。", "motivation": "本文旨在重新审视地理神经网络加权回归（GNNWR）中的归纳偏置，并识别当前方法在建模空间非平稳性方面的局限性，特别是现有实现常受限于固定的基于距离的方案和有限的归纳偏置。", "method": "研究提出通过结合卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，将局部感受野、序列上下文和自注意力引入空间回归。", "result": "通过在具有不同异质性、噪声和样本量的合成空间数据集上进行广泛基准测试，结果表明泛化后的GNNWR在捕获非线性复杂空间关系方面优于经典方法。研究还发现模型性能强烈依赖于数据特性，其中局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更均匀的数据中表现更好。", "conclusion": "这些发现强调了归纳偏置在空间建模中的重要性，并为未来研究方向提供了建议，包括可学习的空间加权函数、混合神经网络架构以及提高处理非平稳空间数据的模型的可解释性。", "translation": "归纳偏置是空间回归模型中的一个关键因素，它决定了模型从有限数据中学习和捕获空间模式的能力。本研究重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置，并指出了当前方法在建模空间非平稳性方面的局限性。虽然GNNWR通过使用神经网络学习空间加权函数来扩展传统地理加权回归，但现有实现通常受限于固定的基于距离的方案和有限的归纳偏置。我们提出通过结合卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，从而将局部感受野、序列上下文和自注意力引入空间回归。通过在具有不同异质性、噪声和样本量的合成空间数据集上进行广泛基准测试，我们表明GNNWR在捕获非线性复杂空间关系方面优于经典方法。我们的结果还揭示，模型性能强烈依赖于数据特性，其中局部模型在高度异质或小样本场景中表现出色，而全局模型在更大、更均匀的数据中表现更好。这些发现强调了归纳偏置在空间建模中的重要性，并为未来方向提供了建议，包括可学习的空间加权函数、混合神经网络架构以及提高处理非平稳空间数据的模型的可解释性。", "summary": "本文重新审视了地理神经网络加权回归（GNNWR）中的归纳偏置及其在建模空间非平稳性方面的局限性。为解决此问题，研究提出通过引入卷积神经网络、循环神经网络和Transformer的概念来泛化GNNWR，从而将局部感受野、序列上下文和自注意力应用于空间回归。在合成数据集上的广泛测试表明，改进后的GNNWR在捕获非线性复杂空间关系方面优于传统方法，且模型性能受数据特性显著影响。研究强调了归纳偏置在空间建模中的关键作用，并指出了未来的研究方向。", "keywords": "地理神经网络加权回归, 归纳偏置, 空间非平稳性, 深度学习, 空间回归", "comments": "本文的创新点在于将深度学习领域（CNN、RNN、Transformer）的先进概念引入到地理神经网络加权回归（GNNWR）中，以增强其对空间非平稳性的建模能力和归纳偏置。这对于提升空间回归模型处理复杂非线性关系的能力具有重要意义，并为空间建模与深度学习的融合提供了新的思路和实证支持。"}}
{"id": "2507.13727", "title": "Adversarial Training Improves Generalization Under Distribution Shifts in Bioacoustics", "authors": ["René Heinrich", "Lukas Rauch", "Bernhard Sick", "Christoph Scholz"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Work in progress", "url": "http://arxiv.org/abs/2507.13727v1", "summary": "Adversarial training is a promising strategy for enhancing model robustness\nagainst adversarial attacks. However, its impact on generalization under\nsubstantial data distribution shifts in audio classification remains largely\nunexplored. To address this gap, this work investigates how different\nadversarial training strategies improve generalization performance and\nadversarial robustness in audio classification. The study focuses on two model\narchitectures: a conventional convolutional neural network (ConvNeXt) and an\ninherently interpretable prototype-based model (AudioProtoPNet). The approach\nis evaluated using a challenging bird sound classification benchmark. This\nbenchmark is characterized by pronounced distribution shifts between training\nand test data due to varying environmental conditions and recording methods, a\ncommon real-world challenge. The investigation explores two adversarial\ntraining strategies: one based on output-space attacks that maximize the\nclassification loss function, and another based on embedding-space attacks\ndesigned to maximize embedding dissimilarity. These attack types are also used\nfor robustness evaluation. Additionally, for AudioProtoPNet, the study assesses\nthe stability of its learned prototypes under targeted embedding-space attacks.\nResults show that adversarial training, particularly using output-space\nattacks, improves clean test data performance by an average of 10.5% relative\nand simultaneously strengthens the adversarial robustness of the models. These\nfindings, although derived from the bird sound domain, suggest that adversarial\ntraining holds potential to enhance robustness against both strong distribution\nshifts and adversarial attacks in challenging audio classification settings.", "comment": "Work in progress", "pdf_url": "http://arxiv.org/pdf/2507.13727v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "对抗训练改善生物声学中分布偏移下的泛化能力", "tldr": "本研究发现，在音频分类中，对抗训练（特别是基于输出空间的攻击）可以显著提高模型在分布偏移下的泛化性能和对抗鲁棒性。", "motivation": "对抗训练在增强模型对对抗攻击的鲁棒性方面很有前景，但其在音频分类中，面对显著数据分布偏移时的泛化能力影响尚不明确。本研究旨在填补这一空白。", "method": "本研究调查了不同对抗训练策略如何提高音频分类中的泛化性能和对抗鲁棒性。研究使用了两种模型架构：ConvNeXt和AudioProtoPNet，并在一个具有显著训练-测试数据分布偏移的鸟类声音分类基准上进行评估。探讨了两种对抗训练策略：基于输出空间攻击（最大化分类损失）和基于嵌入空间攻击（最大化嵌入差异）。同时，这些攻击类型也用于鲁棒性评估，并对AudioProtoPNet的原型稳定性进行了评估。", "result": "结果表明，对抗训练，特别是使用输出空间攻击，将干净测试数据的性能平均相对提高了10.5%，同时增强了模型的对抗鲁棒性。", "conclusion": "尽管研究结果来自鸟类声音领域，但它们表明对抗训练有潜力在具有挑战性的音频分类环境中增强模型对强分布偏移和对抗攻击的鲁棒性。", "translation": "对抗训练是增强模型对抗对抗攻击鲁棒性的一种有前景的策略。然而，其在音频分类中，面对显著数据分布偏移时的泛化能力影响在很大程度上仍未被探索。为了弥补这一空白，本研究调查了不同对抗训练策略如何提高音频分类中的泛化性能和对抗鲁棒性。该研究侧重于两种模型架构：传统的卷积神经网络（ConvNeXt）和固有的可解释的基于原型的模型（AudioProtoPNet）。该方法使用一个具有挑战性的鸟类声音分类基准进行评估。该基准的特点是由于环境条件和记录方法的不同，训练和测试数据之间存在明显的分布偏移，这是一个常见的现实世界挑战。本研究探讨了两种对抗训练策略：一种基于输出空间攻击，旨在最大化分类损失函数；另一种基于嵌入空间攻击，旨在最大化嵌入不相似性。这些攻击类型也用于鲁棒性评估。此外，对于AudioProtoPNet，该研究评估了其学习到的原型在目标嵌入空间攻击下的稳定性。结果显示，对抗训练，特别是使用输出空间攻击，使干净测试数据的性能平均相对提高了10.5%，同时增强了模型的对抗鲁棒性。这些发现，尽管来源于鸟类声音领域，但表明对抗训练有潜力在具有挑战性的音频分类环境中增强模型对强分布偏移和对抗攻击的鲁棒性。", "summary": "本研究探讨了对抗训练在音频分类中提高模型在数据分布偏移下的泛化能力和对抗鲁棒性的效果。研究使用了ConvNeXt和AudioProtoPNet两种模型，并在具有挑战性的鸟类声音分类数据集上进行了评估。结果表明，对抗训练，尤其是基于输出空间的攻击，能够显著提升干净测试数据性能并增强模型鲁棒性，这为应对生物声学等领域中的现实世界挑战提供了有前景的解决方案。", "keywords": "对抗训练, 分布偏移, 生物声学, 音频分类, 鲁棒性", "comments": "该论文创新性地将对抗训练应用于生物声学领域的音频分类，以解决现实世界中常见的分布偏移问题。其重要性在于证明了对抗训练不仅能提高对抗鲁棒性，还能显著改善模型在未见数据分布下的泛化性能。特别是，强调了输出空间攻击的有效性。这项工作为未来在复杂音频环境中提高模型可靠性提供了新的方向。"}}
{"id": "2507.13482", "title": "Improving Out-of-distribution Human Activity Recognition via IMU-Video Cross-modal Representation Learning", "authors": ["Seyyed Saeid Cheshmi", "Buyao Lyu", "Thomas Lisko", "Rajesh Rajamani", "Robert A. McGovern", "Yogatheesan Varatharajah"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13482v1", "summary": "Human Activity Recognition (HAR) based on wearable inertial sensors plays a\ncritical role in remote health monitoring. In patients with movement disorders,\nthe ability to detect abnormal patient movements in their home environments can\nenable continuous optimization of treatments and help alert caretakers as\nneeded. Machine learning approaches have been proposed for HAR tasks using\nInertial Measurement Unit (IMU) data; however, most rely on\napplication-specific labels and lack generalizability to data collected in\ndifferent environments or populations. To address this limitation, we propose a\nnew cross-modal self-supervised pretraining approach to learn representations\nfrom large-sale unlabeled IMU-video data and demonstrate improved\ngeneralizability in HAR tasks on out of distribution (OOD) IMU datasets,\nincluding a dataset collected from patients with Parkinson's disease.\nSpecifically, our results indicate that the proposed cross-modal pretraining\napproach outperforms the current state-of-the-art IMU-video pretraining\napproach and IMU-only pretraining under zero-shot and few-shot evaluations.\nBroadly, our study provides evidence that in highly dynamic data modalities,\nsuch as IMU signals, cross-modal pretraining may be a useful tool to learn\ngeneralizable data representations. Our software is available at\nhttps://github.com/scheshmi/IMU-Video-OOD-HAR.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13482v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "通过IMU-视频跨模态表征学习改进分布外人体活动识别", "tldr": "本文提出了一种新的跨模态自监督预训练方法，利用IMU-视频数据来提高人体活动识别（HAR）在分布外（OOD）数据集上的泛化能力，并在零样本和少样本评估中优于现有方法。", "motivation": "现有的基于惯性测量单元（IMU）的人体活动识别（HAR）方法大多依赖于特定应用的标签，并且缺乏对在不同环境或人群中收集的数据的泛化能力，这限制了它们在远程健康监测，特别是对运动障碍患者的应用。", "method": "提出了一种新的跨模态自监督预训练方法，用于从大规模未标记的IMU-视频数据中学习表征，以提高HAR任务在分布外（OOD）IMU数据集上的泛化能力。", "result": "所提出的跨模态预训练方法在零样本和少样本评估下，优于当前的最新IMU-视频预训练方法和仅IMU的预训练方法，并在包括帕金森病患者数据集在内的OOD IMU数据集上展示了改进的泛化能力。", "conclusion": "研究表明，在IMU信号等高度动态的数据模态中，跨模态预训练可能是学习可泛化数据表征的有用工具。", "translation": "基于可穿戴惯性传感器的人体活动识别（HAR）在远程健康监测中发挥着关键作用。对于运动障碍患者，在家中环境中检测异常患者运动的能力可以实现治疗的持续优化，并根据需要帮助提醒护理人员。机器学习方法已被提议用于使用惯性测量单元（IMU）数据的HAR任务；然而，大多数依赖于特定应用的标签，并且缺乏对在不同环境或人群中收集的数据的泛化能力。为了解决这一限制，我们提出了一种新的跨模态自监督预训练方法，用于从大规模未标记的IMU-视频数据中学习表征，并证明了在分布外（OOD）IMU数据集（包括从帕金森病患者收集的数据集）上的HAR任务中泛化能力的提高。具体而言，我们的结果表明，在零样本和少样本评估下，所提出的跨模态预训练方法优于当前的最新IMU-视频预训练方法和仅IMU的预训练。从广义上讲，我们的研究提供了证据，表明在IMU信号等高度动态的数据模态中，跨模态预训练可能是学习可泛化数据表征的有用工具。我们的软件可在https://github.com/scheshmi/IMU-Video-OOD-HAR获取。", "summary": "本文提出了一种创新的跨模态自监督预训练方法，旨在解决基于IMU的人体活动识别（HAR）在分布外（OOD）数据上泛化能力不足的问题。通过利用大规模未标记的IMU和视频数据进行联合学习，该方法能够从动态IMU信号中提取更具泛化性的特征。实验结果表明，该方法在零样本和少样本场景下，显著优于现有的IMU-视频和纯IMU预训练方法，尤其是在运动障碍患者等OOD数据集上表现出更强的鲁棒性，证实了跨模态学习在提高HAR泛化能力方面的潜力。", "keywords": "人体活动识别, IMU, 跨模态学习, 分布外泛化, 自监督学习", "comments": "本文的创新点在于提出了利用IMU-视频跨模态自监督预训练来解决IMU-based HAR的OOD泛化性问题。这种方法利用了多模态数据的互补性，通过无监督学习在大规模数据上预训练模型，从而避免了对大量特定标签的依赖。其重要性在于，为远程健康监测，特别是对运动障碍患者的异常活动检测，提供了一种更通用和鲁棒的解决方案。该研究为动态数据模态中的表征学习提供了新的视角，并展示了跨模态预训练的巨大潜力。"}}
{"id": "2507.13382", "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case", "authors": ["Chandrashekar Muniyappa", "Sirisha Velampalli"], "categories": ["cs.CL", "cs.LG", "05-05C12"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      CSAIDE '25: Proceedings of the 2025 4th International Conference on Cyber Security, Artificial Intelligence and the Digital Economy", "url": "http://arxiv.org/abs/2507.13382v1", "summary": "In today\\'s digital world, fake news is spreading with immense speed. Its a\nsignificant concern to address. In this work, we addressed that challenge using\nnovel graph based approach. We took dataset from Kaggle that contains real and\nfake news articles. To test our approach we incorporated recent covid-19\nrelated news articles that contains both genuine and fake news that are\nrelevant to this problem. This further enhances the dataset as well instead of\nrelying completely on the original dataset. We propose a contextual graph-based\napproach to detect fake news articles. We need to convert news articles into\nappropriate schema, so we leverage Natural Language Processing (NLP) techniques\nto transform news articles into contextual graph structures. We then apply the\nMinimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)\nalgorithm for graph mining. Graph-based methods are particularly effective for\nhandling rich contextual data, as they enable the discovery of complex patterns\nthat traditional query-based or statistical techniques might overlook. Our\nproposed approach identifies normative patterns within the dataset and\nsubsequently uncovers anomalous patterns that deviate from these established\nnorms.", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "pdf_url": "http://arxiv.org/pdf/2507.13382v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于图方法的上下文虚假新闻检测：以COVID-19为例", "tldr": "本文提出了一种基于上下文图的方法，结合NLP和MDL-GBAD算法，用于检测虚假新闻，并通过COVID-19新闻数据集进行了验证。", "motivation": "虚假新闻在数字世界中传播迅速，已成为一个亟待解决的重大问题。", "method": "本文提出了一种新颖的基于上下文图的方法来检测虚假新闻。首先，利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构。然后，应用基于最小描述长度（MDL）的图基异常检测（GBAD）算法进行图挖掘，以识别数据集中偏离正常模式的异常模式。数据集使用了Kaggle上的真实和虚假新闻文章，并额外加入了COVID-19相关新闻文章来增强数据集。", "result": "所提出的方法能够识别数据集中的规范模式，并随后发现偏离这些既定规范的异常模式。", "conclusion": "基于图的方法在处理丰富的上下文数据方面特别有效，能够发现传统技术可能忽略的复杂模式，从而有效检测虚假新闻。", "translation": "在当今数字世界中，虚假新闻正以极快的速度传播。这是一个需要解决的重大问题。在这项工作中，我们使用一种新颖的基于图的方法来应对这一挑战。我们从Kaggle获取了包含真实和虚假新闻文章的数据集。为了测试我们的方法，我们纳入了最近与COVID-19相关的新闻文章，这些文章包含与此问题相关的真实和虚假新闻。这进一步增强了数据集，而不是完全依赖原始数据集。我们提出了一种基于上下文图的方法来检测虚假新闻文章。我们需要将新闻文章转换为适当的模式，因此我们利用自然语言处理（NLP）技术将新闻文章转换为上下文图结构。然后，我们应用基于最小描述长度（MDL）的图基异常检测（GBAD）算法进行图挖掘。基于图的方法在处理丰富的上下文数据方面特别有效，因为它们能够发现传统基于查询或统计技术可能忽略的复杂模式。我们提出的方法识别数据集中的规范模式，并随后发现偏离这些既定规范的异常模式。", "summary": "本文提出了一种新颖的基于上下文图的虚假新闻检测方法，以应对数字世界中虚假新闻的快速传播问题。该方法利用自然语言处理技术将新闻文章转换为上下文图结构，并应用基于MDL的图基异常检测（GBAD）算法来识别异常模式。研究人员通过结合Kaggle数据集和COVID-19相关新闻文章构建了增强数据集，以验证该方法的有效性。该方法能够有效处理丰富的上下文数据，并发现传统方法难以捕捉的复杂模式。", "keywords": "虚假新闻检测, 图方法, 上下文图, 自然语言处理, 异常检测", "comments": "本文的创新点在于将自然语言处理技术与图神经网络相结合，构建上下文图来表示新闻文章，并利用MDL-GBAD算法进行异常检测，这为虚假新闻检测提供了一个新颖且强大的框架。COVID-19用例的引入增加了研究的现实意义和时效性。该方法强调了图结构在捕捉复杂上下文关系方面的优势，克服了传统方法可能存在的局限性。"}}
{"id": "2507.13622", "title": "IP2: Entity-Guided Interest Probing for Personalized News Recommendation", "authors": ["Youlin Wu", "Yuanyuan Sun", "Xiaokun Zhang", "Haoxi Zhan", "Bo Xu", "Liang Yang", "Hongfei Lin"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted in RecSys 2025", "url": "http://arxiv.org/abs/2507.13622v1", "summary": "News recommender systems aim to provide personalized news reading experiences\nfor users based on their reading history. Behavioral science studies suggest\nthat screen-based news reading contains three successive steps: scanning, title\nreading, and then clicking. Adhering to these steps, we find that intra-news\nentity interest dominates the scanning stage, while the inter-news entity\ninterest guides title reading and influences click decisions. Unfortunately,\ncurrent methods overlook the unique utility of entities in news recommendation.\nTo this end, we propose a novel method called IP2 to probe entity-guided\nreading interest at both intra- and inter-news levels. At the intra-news level,\na Transformer-based entity encoder is devised to aggregate mentioned entities\nin the news title into one signature entity. Then, a signature entity-title\ncontrastive pre-training is adopted to initialize entities with proper meanings\nusing the news story context, which in the meantime facilitates us to probe for\nintra-news entity interest. As for the inter-news level, a dual tower user\nencoder is presented to capture inter-news reading interest from both the title\nmeaning and entity sides. In addition to highlighting the contribution of\ninter-news entity guidance, a cross-tower attention link is adopted to\ncalibrate title reading interest using inter-news entity interest, thus further\naligning with real-world behavior. Extensive experiments on two real-world\ndatasets demonstrate that our IP2 achieves state-of-the-art performance in news\nrecommendation.", "comment": "Accepted in RecSys 2025", "pdf_url": "http://arxiv.org/pdf/2507.13622v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "IP2：实体引导兴趣探测个性化新闻推荐", "tldr": "IP2是一种新的新闻推荐方法，通过在新闻内部和新闻之间两个层面探测实体引导的阅读兴趣，实现了最先进的性能。", "motivation": "当前新闻推荐系统忽视了实体在新闻推荐中的独特作用，特别是新闻内部实体兴趣主导扫描阶段，新闻之间实体兴趣引导标题阅读和影响点击决策。", "method": "提出IP2方法。在新闻内部层面，设计一个基于Transformer的实体编码器来聚合新闻标题中提及的实体为一个签名实体，并采用签名实体-标题对比预训练来初始化实体意义并探测新闻内部实体兴趣。在新闻之间层面，提出一个双塔用户编码器来捕获标题意义和实体两方面的新闻之间阅读兴趣，并采用跨塔注意力链接利用新闻之间实体兴趣校准标题阅读兴趣。", "result": "在两个真实世界数据集上的广泛实验表明，IP2在新闻推荐方面取得了最先进的性能。", "conclusion": "IP2通过有效探测新闻内部和新闻之间的实体引导兴趣，显著提升了个性化新闻推荐的性能，并与真实世界行为模式更一致。", "translation": "新闻推荐系统旨在根据用户的阅读历史提供个性化的新闻阅读体验。行为科学研究表明，基于屏幕的新闻阅读包含三个连续的步骤：扫描、标题阅读，然后是点击。遵循这些步骤，我们发现新闻内部实体兴趣主导扫描阶段，而新闻之间实体兴趣引导标题阅读并影响点击决策。不幸的是，当前方法忽视了实体在新闻推荐中的独特效用。为此，我们提出了一种名为IP2的新方法，用于在新闻内部和新闻之间两个层面探测实体引导的阅读兴趣。在新闻内部层面，设计了一个基于Transformer的实体编码器，将新闻标题中提及的实体聚合为一个签名实体。然后，采用签名实体-标题对比预训练来使用新闻故事上下文初始化实体以获得适当的意义，这同时有助于我们探测新闻内部实体兴趣。至于新闻之间层面，提出了一个双塔用户编码器，从标题意义和实体两方面捕获新闻之间阅读兴趣。除了突出新闻之间实体引导的贡献外，还采用了一个跨塔注意力链接，利用新闻之间实体兴趣校准标题阅读兴趣，从而进一步与真实世界行为保持一致。在两个真实世界数据集上进行的广泛实验表明，我们的IP2在新闻推荐中取得了最先进的性能。", "summary": "本研究提出了一种名为IP2的新型个性化新闻推荐方法，旨在解决现有系统忽视实体独特效用的问题。IP2在新闻内部和新闻之间两个层面探测实体引导的阅读兴趣。在新闻内部层面，它使用Transformer编码器和对比预训练来捕捉新闻标题中的实体兴趣。在新闻之间层面，它采用双塔用户编码器和跨塔注意力机制来整合标题和实体信息，并校准阅读兴趣。实验结果表明，IP2在新闻推荐方面达到了最先进的性能。", "keywords": "新闻推荐, 实体引导, 兴趣探测, IP2, Transformer", "comments": "该论文的创新点在于首次将新闻内部和新闻之间的实体兴趣作为关键因素引入新闻推荐系统，并设计了相应的模块（如Transformer实体编码器、对比预训练、双塔用户编码器和跨塔注意力链接）来有效捕获和利用这些兴趣。其重要性在于，通过更精细地模拟用户阅读行为中的实体作用，提升了推荐的准确性和用户体验，为个性化推荐领域提供了新的视角。"}}
{"id": "2402.13670", "title": "The Riemannian Convex Bundle Method", "authors": ["Ronny Bergmann", "Roland Herzog", "Hajg Jasa"], "categories": ["math.OC", "cs.NA", "math.DG", "math.NA"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.13670v3", "summary": "We introduce the convex bundle method to solve convex, non-smooth\noptimization problems on Riemannian manifolds of bounded sectional curvature.\nEach step of our method is based on a model that involves the convex hull of\npreviously collected subgradients, parallelly transported into the current\nserious iterate. This approach generalizes the dual form of classical bundle\nsubproblems in Euclidean space. We prove that, under mild conditions, the\nconvex bundle method converges to a minimizer. Several numerical examples\nimplemented using Manopt$.$jl illustrate the performance of the proposed method\nand compare it to the subgradient method, the cyclic proximal point algorithm,\nas well as the proximal bundle method.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.13670v3", "cate": "math.OC", "date": "2024-02-21", "updated": "2025-07-18", "AI": {"title_translation": "黎曼凸束方法", "tldr": "本文提出了一种黎曼流形上的凸束方法，用于解决黎曼流形上的凸、非光滑优化问题，并证明了其收敛性，通过数值例子展示了其性能。", "motivation": "在黎曼流形上解决凸、非光滑优化问题。", "method": "该方法基于一个模型，该模型涉及将先前收集的次梯度平行传输到当前迭代点所形成的凸包。这种方法推广了欧几里得空间中经典束子问题的对偶形式。", "result": "在温和条件下，所提出的凸束方法收敛到一个极小值点。通过使用Manopt.jl实现的几个数值例子，展示了该方法的性能，并将其与次梯度法、循环近端点算法以及近端束方法进行了比较。", "conclusion": "所提出的黎曼凸束方法能够有效解决黎曼流形上的凸、非光滑优化问题，并且在数值实验中表现良好。", "translation": "我们引入凸束方法来解决具有有界截面曲率的黎曼流形上的凸、非光滑优化问题。我们方法的每一步都基于一个模型，该模型涉及将先前收集的次梯度平行传输到当前严格迭代点所形成的凸包。这种方法推广了欧几里得空间中经典束子问题的对偶形式。我们证明，在温和条件下，凸束方法收敛到一个极小值点。使用Manopt.jl实现的几个数值例子说明了所提出方法的性能，并将其与次梯度法、循环近端点算法以及近端束方法进行了比较。", "summary": "本文提出了一种名为“黎曼凸束方法”的新型优化算法，旨在解决具有有界截面曲率的黎曼流形上的凸、非光滑优化问题。该方法的核心思想是利用先前收集的次梯度通过平行传输形成的凸包来构建模型。作者证明了该方法在温和条件下的收敛性，并通过数值实验展示了其优越性能，与现有的次梯度法、循环近端点算法和近端束方法进行了对比。", "keywords": "黎曼流形, 凸束方法, 非光滑优化, 次梯度, 收敛性", "comments": "该论文的创新之处在于将经典的凸束方法推广到了黎曼流形，这是一个重要的理论进展，因为它使得在非欧几里得几何背景下处理非光滑优化问题成为可能。其收敛性证明和数值验证增加了方法的可靠性与实用性。"}}
{"id": "2507.13923", "title": "Initiating and Replicating the Observations of Interactional Properties by User Studies Optimizing Applicative Prototypes", "authors": ["Guillaume Rivière"], "categories": ["cs.HC", "H.5.2"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Written in French. 22 pages. Approximately 11700 words. 10 figures and 6 tables", "url": "http://arxiv.org/abs/2507.13923v1", "summary": "The science of Human-Computer Interaction (HCI) is populated by isolated\nempirical findings, often tied to specific technologies, designs, and tasks.\nThis paper proposes a formalization of user interaction observations (instead\nof user interfaces) and an associated revealing method (interaction loop\ndiffraction). The resulting interactional properties that are studied in a\ncalibrated manner, are well suited to replication across various conditions\n(prototypes, technologies, tasks, and user profiles). In particular,\ninteractional properties can emerge and be replicated within the workflow of\napplicative cases, which in return benefit from the optimization of applicative\nprototypes. Applicative cases' publications will then contribute to\ndemonstrating technology utility, along with providing empirical results that\nwill lead future work to theory consolidation and theory building, and finally\nto a catalog and a science of relevant interactional properties. These\nproperties will contribute to better user interactions, especially for the\nvariety of ubiquitous user interfaces.", "comment": "Written in French. 22 pages. Approximately 11700 words. 10 figures\n  and 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.13923v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "通过用户研究优化应用原型，启动和复制交互属性的观察", "tldr": "本文提出了一种形式化用户交互观察及其关联的揭示方法（交互循环衍射），以研究可复制的交互属性，旨在通过优化应用原型来促进人机交互领域的理论构建和实用性展示。", "motivation": "人机交互（HCI）领域充满了孤立的经验发现，这些发现通常与特定的技术、设计和任务紧密相关，导致难以进行复制和推广。", "method": "本文提出了一种用户交互观察的规范化方法（而非用户界面），以及一种相关的揭示方法（交互循环衍射）。这种方法旨在校准地研究交互属性。", "result": "通过该方法研究的交互属性能够很好地在各种条件（原型、技术、任务和用户画像）下进行复制。这些属性可以在应用案例的工作流程中出现并被复制，从而优化应用原型。", "conclusion": "这些交互属性将有助于更好地进行用户交互，特别是对于各种无处不在的用户界面。应用案例的发表将有助于展示技术效用，并提供实证结果，从而促进未来的理论整合、理论构建，并最终形成一个相关交互属性的目录和科学。", "translation": "人机交互（HCI）科学充满了孤立的经验发现，这些发现通常与特定的技术、设计和任务紧密相关。本文提出了一种用户交互观察（而非用户界面）的形式化方法和一种相关的揭示方法（交互循环衍射）。由此产生的交互属性以校准的方式进行研究，非常适合在各种条件（原型、技术、任务和用户画像）下进行复制。特别是，交互属性可以在应用案例的工作流程中出现并被复制，这反过来又受益于应用原型的优化。然后，应用案例的出版将有助于展示技术效用，同时提供实证结果，这将引导未来的工作走向理论整合和理论构建，并最终形成一个相关交互属性的目录和科学。这些属性将有助于更好地进行用户交互，特别是对于各种无处不在的用户界面。", "summary": "本文针对人机交互领域中经验发现难以复制的问题，提出了一种形式化用户交互观察（而非用户界面）的方法及其揭示技术（交互循环衍射）。该方法旨在研究可复制的交互属性，这些属性能够在不同条件下被复制，并通过优化应用原型来促进交互属性的出现和复制。最终目标是通过应用案例的发表来推动理论整合与构建，并建立一个交互属性的科学目录，从而改善用户交互。", "keywords": "人机交互, 交互属性, 用户研究, 复制性, 理论构建", "comments": "本文的创新点在于将研究重点从具体的用户界面转移到更抽象和可复制的“交互属性”上，并提出了一种形式化和揭示这些属性的方法。这对于解决人机交互领域中经验发现碎片化的问题具有重要意义，有助于推动该领域的理论化和科学化。其强调的复制性和在应用案例中验证的流程，对于提升研究的普适性和实用价值具有积极作用。"}}
{"id": "2507.13486", "title": "Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation", "authors": ["Debao Huang", "Rongjun Qin"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 9 figures, this manuscript has been submitted to ISPRS Journal of Photogrammetry and Remote Sensing for consideration", "url": "http://arxiv.org/abs/2507.13486v1", "summary": "Uncertainty quantification of the photogrammetry process is essential for\nproviding per-point accuracy credentials of the point clouds. Unlike airborne\nLiDAR, which typically delivers consistent accuracy across various scenes, the\naccuracy of photogrammetric point clouds is highly scene-dependent, since it\nrelies on algorithm-generated measurements (i.e., stereo or multi-view stereo).\nGenerally, errors of the photogrammetric point clouds propagate through a\ntwo-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),\nfollowed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM\nstage has been well studied using the first-order statistics of the\nreprojection error function, that in the MVS stage remains largely unsolved and\nnon-standardized, primarily due to its non-differentiable and multi-modal\nnature (i.e., from pixel values to geometry). In this paper, we present an\nuncertainty quantification framework closing this gap by associating an error\ncovariance matrix per point accounting for this two-step photogrammetry\nprocess. Specifically, to estimate the uncertainty in the MVS stage, we propose\na novel, self-calibrating method by taking reliable n-view points (n>=6)\nper-view to regress the disparity uncertainty using highly relevant cues (such\nas matching cost values) from the MVS stage. Compared to existing approaches,\nour method uses self-contained, reliable 3D points extracted directly from the\nMVS process, with the benefit of being self-supervised and naturally adhering\nto error propagation path of the photogrammetry process, thereby providing a\nrobust and certifiable uncertainty quantification across diverse scenes. We\nevaluate the framework using a variety of publicly available airborne and UAV\nimagery datasets. Results demonstrate that our method outperforms existing\napproaches by achieving high bounding rates without overestimating uncertainty.", "comment": "16 pages, 9 figures, this manuscript has been submitted to ISPRS\n  Journal of Photogrammetry and Remote Sensing for consideration", "pdf_url": "http://arxiv.org/pdf/2507.13486v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "通过误差传播实现航空和无人机摄影测量的不确定性量化框架", "tldr": "本文提出了一个不确定性量化框架，通过解决多视图立体（MVS）阶段的不确定性估计问题，为航空和无人机摄影测量提供鲁棒且可认证的逐点精度。", "motivation": "光度测量点云的精度高度依赖于场景，其误差通过运动恢复结构（SfM）和多视图立体（MVS）两阶段传播。尽管SfM阶段的不确定性估计已得到充分研究，但MVS阶段的不确定性估计仍未解决且非标准化，这阻碍了提供点云的逐点精度凭证。", "method": "本文提出了一个不确定性量化框架，通过为每个点关联一个误差协方差矩阵来解决两阶段光度测量过程中的不确定性。特别地，针对MVS阶段的不确定性估计，提出了一种新颖的自校准方法，通过利用MVS阶段的可靠n视图点（n>=6）和相关线索（如匹配成本值）来回归视差不确定性。", "result": "实验结果表明，与现有方法相比，该方法在不夸大不确定性的情况下实现了高边界率，性能优于现有方法。", "conclusion": "该框架提供了一种鲁棒且可认证的不确定性量化方法，适用于各种场景。其方法利用直接从MVS过程提取的自包含、可靠的3D点，具有自监督的优势，并自然遵循摄影测量误差传播路径。", "translation": "摄影测量过程的不确定性量化对于提供点云的逐点精度凭证至关重要。与通常在各种场景中提供一致精度的机载激光雷达不同，摄影测量点云的精度高度依赖于场景，因为它依赖于算法生成的测量值（即立体或多视图立体）。通常，摄影测量点云的误差通过两步过程传播：运动恢复结构（SfM）与光束法平差（BA），然后是多视图立体（MVS）。虽然SfM阶段的不确定性估计已通过重投影误差函数的一阶统计量得到充分研究，但MVS阶段的不确定性估计仍然在很大程度上未解决且非标准化，这主要归因于其不可微分和多模态的性质（即从像素值到几何）。在本文中，我们提出了一个不确定性量化框架，通过为每个点关联一个误差协方差矩阵来弥补这一空白，该矩阵考虑了这一两步摄影测量过程。具体而言，为了估计MVS阶段的不确定性，我们提出了一种新颖的自校准方法，通过每视图获取可靠的n视图点（n>=6）来回归视差不确定性，该方法利用MVS阶段的高度相关线索（如匹配成本值）。与现有方法相比，我们的方法使用直接从MVS过程中提取的自包含、可靠的3D点，具有自监督的优点，并自然地遵循摄影测量过程的误差传播路径，从而在不同场景中提供鲁棒且可认证的不确定性量化。我们使用各种公开可用的机载和无人机图像数据集评估了该框架。结果表明，我们的方法通过实现高边界率而不夸大不确定性，优于现有方法。", "summary": "本文提出了一个针对航空和无人机摄影测量的不确定性量化框架，旨在解决传统方法在多视图立体（MVS）阶段不确定性估计的不足。该框架通过为每个点关联误差协方差矩阵来追踪SfM和MVS两阶段的误差传播。为了克服MVS阶段的挑战，研究人员开发了一种新颖的自校准方法，利用MVS过程中可靠的n视图点和匹配成本等线索来回归视差不确定性。实验结果表明，该自监督方法在不夸大不确定性的情况下，提供了比现有方法更优越、更鲁棒且可认证的逐点精度。", "keywords": "摄影测量, 不确定性量化, 误差传播, 多视图立体, 无人机", "comments": "本文的创新之处在于提出了一个针对MVS阶段不确定性估计的自校准方法，有效填补了摄影测量误差传播链中的一个关键空白。其自监督特性和对误差传播路径的自然遵循，使得该框架能够提供在不同场景下鲁棒且可认证的精度量化，对于需要高精度点云的应用具有重要意义。"}}
{"id": "2507.13803", "title": "GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation", "authors": ["Weiqi Yang", "Xu Zhou", "Jingfu Guan", "Hao Du", "Tianyu Bai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13803v1", "summary": "Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely\ndeployed in smart homes, intelligent transport, industrial automation, and\nhealthcare. However, existing systems often face challenges: high model\ncomplexity hinders deployment in resource-constrained environments,\nunidirectional modal alignment neglects inter-modal relationships, and\nrobustness suffers when sensor data is missing. These issues impede efficient\nand robust multimodal perception in real-world IoT settings. To overcome these\nlimitations, we propose GRAM-MAMBA. This framework utilizes the\nlinear-complexity Mamba model for efficient sensor time-series processing,\ncombined with an optimized GRAM matrix strategy for pairwise alignment among\nmodalities, addressing the shortcomings of traditional single-modality\nalignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive\nlow-rank layer compensation strategy to handle missing modalities\npost-training. This strategy freezes the pre-trained model core and irrelevant\nadaptive layers, fine-tuning only those related to available modalities and the\nfusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On\nthe SPAWC2021 indoor positioning dataset, the pre-trained model shows lower\nerror than baselines; adapting to missing modalities yields a 24.5% performance\nboost by training less than 0.2% of parameters. On the USC-HAD human activity\nrecognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),\noutperforming prior work; the update strategy increases F1 by 23% while\ntraining less than 0.3% of parameters. These results highlight GRAM-MAMBA's\npotential for achieving efficient and robust multimodal perception in\nresource-constrained environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13803v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "GRAM-MAMBA：用于无线感知的整体特征对齐与自适应低秩补偿", "tldr": "GRAM-MAMBA提出了一种高效且鲁棒的多模态感知框架，结合Mamba模型进行时间序列处理，GRAM矩阵进行模态对齐，以及受LoRA启发的自适应低秩补偿策略以应对模态缺失，在资源受限环境中表现出色。", "motivation": "现有物联网感知系统面临模型复杂度高、单向模态对齐忽视模态间关系以及传感器数据缺失时鲁棒性差等挑战，这些问题阻碍了在真实物联网环境中高效且鲁棒的多模态感知。", "method": "提出GRAM-MAMBA框架。利用线性复杂度的Mamba模型处理传感器时间序列，结合优化的GRAM矩阵策略实现模态间的两两对齐。引入受低秩适应（LoRA）启发的自适应低秩层补偿策略，用于处理训练后模态缺失的情况，该策略冻结预训练模型核心和不相关的自适应层，仅微调与可用模态和融合过程相关的部分。", "result": "在SPAWC2021室内定位数据集上，预训练模型比基线误差更低；适应缺失模态时，通过训练不到0.2%的参数实现了24.5%的性能提升。在USC-HAD人类活动识别数据集上，F1得分达到93.55%，总体准确率（OA）达到93.81%，优于现有工作；更新策略通过训练不到0.3%的参数将F1得分提高了23%。", "conclusion": "GRAM-MAMBA在资源受限环境中展示了实现高效且鲁棒多模态感知的潜力。", "translation": "多模态融合对于物联网（IoT）感知至关重要，广泛应用于智能家居、智能交通、工业自动化和医疗保健。然而，现有系统常面临挑战：高模型复杂度阻碍了在资源受限环境中的部署，单向模态对齐忽视了模态间关系，以及当传感器数据缺失时鲁棒性下降。这些问题阻碍了在真实物联网环境中高效且鲁棒的多模态感知。为了克服这些限制，我们提出了GRAM-MAMBA。该框架利用线性复杂度的Mamba模型进行高效的传感器时间序列处理，结合优化的GRAM矩阵策略实现模态间的两两对齐，解决了传统单模态对齐的不足。受低秩适应（LoRA）的启发，我们引入了一种自适应低秩层补偿策略，以处理训练后模态缺失的情况。该策略冻结预训练模型核心和不相关的自适应层，仅微调与可用模态和融合过程相关的部分。大量实验验证了GRAM-MAMBA的有效性。在SPAWC2021室内定位数据集上，预训练模型显示出比基线更低的误差；适应缺失模态时，通过训练不到0.2%的参数实现了24.5%的性能提升。在USC-HAD人类活动识别数据集上，F1得分达到93.55%，总体准确率（OA）达到93.81%，优于现有工作；更新策略通过训练不到0.3%的参数将F1得分提高了23%。这些结果突出了GRAM-MAMBA在资源受限环境中实现高效且鲁棒多模态感知的潜力。", "summary": "本文提出了GRAM-MAMBA框架，旨在解决物联网多模态感知中模型复杂度高、模态对齐不足和数据缺失鲁棒性差的问题。GRAM-MAMBA结合了高效的Mamba模型进行时间序列处理，优化的GRAM矩阵实现全面的模态间对齐，并引入了受LoRA启发的自适应低秩补偿策略以有效处理训练后的模态缺失。实验结果表明，GRAM-MAMBA在室内定位和人类活动识别任务上均取得了优异的性能，尤其在处理模态缺失时展现出显著的参数效率和性能提升，验证了其在资源受限环境中实现高效鲁棒多模态感知的潜力。", "keywords": "多模态融合, 无线感知, Mamba模型, 低秩补偿, 物联网", "comments": "GRAM-MAMBA的创新点在于其结合了Mamba模型的高效性、GRAM矩阵的全面模态对齐能力以及LoRA启发的自适应低秩补偿策略，从而在资源受限的物联网环境中实现了高效且鲁棒的多模态感知。特别是针对模态缺失问题的解决方案，通过极少量参数的微调即可显著提升性能，这对于实际部署具有重要意义。该方法在处理多模态数据融合和鲁棒性方面具有较强的实用价值。"}}
{"id": "2506.23306", "title": "GATSim: Urban Mobility Simulation with Generative Agents", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23306v2", "summary": "Traditional agent-based urban mobility simulations often rely on rigid\nrule-based systems that struggle to capture the complexity, adaptability, and\nbehavioral diversity inherent in human travel decision making. Recent\nadvancements in large language models and AI agent technologies present new\nopportunities to develop agents with enhanced reasoning capabilities,\npersistent memory, and adaptive learning. We introduce GATSim (Generative-Agent\nTransport Simulation), a novel framework that leverages these advancements to\nsimulate urban mobility using generative agents with rich, human-like\nbehaviors. Unlike conventional approaches, GATSim agents are characterized by\ndiverse socioeconomic profiles, individual lifestyles, and evolving preferences\nshaped through psychologically informed memory systems, tool usage, and\nlifelong learning. The main contributions of this work are: (1) a comprehensive\narchitecture that integrates an urban mobility foundation model with agent\ncognitive systems and a transport simulation environment; (2) a hierarchical\nmemory designed for efficient retrieval of contextually relevant information,\nincorporating spatial and temporal associations, keyword matching, and semantic\nrelevance; (3) innovative planning and reactive mechanisms for modeling\nadaptive mobility behaviors which integrate a multi-scale reflection process to\ntransform specific travel experiences into generalized behavioral insights. We\nimplement a prototype system and conduct systematic validation, demonstrating\nthat generative agents produce believable and coherent travel behaviors.\nExperimental results indicate that generative agents perform at least as well\nas human annotators with 92\\% posterior probability, while naturally producing\nrealistic macroscopic traffic patterns. The code for the prototype\nimplementation is publicly available at https://github.com/qiliuchn/gatsim.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23306v2", "cate": "cs.AI", "date": "2025-06-29", "updated": "2025-07-18", "AI": {"title_translation": "GATSim：基于生成式智能体的城市出行模拟", "tldr": "GATSim引入了一种新的框架，利用大型语言模型和AI智能体技术，通过具有丰富类人行为的生成式智能体来模拟城市出行，解决了传统基于规则系统在捕捉人类出行决策复杂性方面的不足。", "motivation": "传统基于规则的城市出行模拟系统难以捕捉人类出行决策的复杂性、适应性和行为多样性。大型语言模型和AI智能体技术的最新进展为开发具有增强推理能力、持久记忆和自适应学习能力的智能体提供了新机会。", "method": "本文提出了GATSim（生成式智能体交通模拟）框架，该框架利用生成式智能体模拟城市出行。GATSim智能体具有多样化的社会经济背景、个体生活方式和通过心理学记忆系统、工具使用和终身学习形成的不断演变偏好。其主要贡献包括：1) 整合城市出行基础模型、智能体认知系统和交通模拟环境的综合架构；2) 用于高效检索上下文相关信息的分层记忆系统，包含空间和时间关联、关键词匹配和语义相关性；3) 创新的规划和反应机制，用于建模自适应出行行为，并集成多尺度反思过程以将特定出行经验转化为通用行为洞察。", "result": "原型系统验证表明，生成式智能体能够产生可信且连贯的出行行为。实验结果表明，生成式智能体的表现至少与人类标注者相当，后验概率达到92%，同时自然地生成了宏观真实的交通模式。", "conclusion": "GATSim框架及其生成式智能体能够有效地模拟城市出行中复杂、多样且适应性强的人类行为，其性能与人类标注者相当，并能生成真实的交通模式。", "translation": "传统基于智能体的城市出行模拟通常依赖僵化的基于规则的系统，这些系统难以捕捉人类出行决策中固有的复杂性、适应性和行为多样性。大型语言模型和AI智能体技术的最新进展为开发具有增强推理能力、持久记忆和自适应学习能力的智能体提供了新机会。我们引入了GATSim（生成式智能体交通模拟），一个利用这些进展来模拟城市出行的创新框架，它使用具有丰富类人行为的生成式智能体。与传统方法不同，GATSim智能体的特点是具有多样化的社会经济背景、个体生活方式以及通过心理学记忆系统、工具使用和终身学习形成的不断演变偏好。这项工作的主要贡献包括：（1）一个综合架构，将城市出行基础模型与智能体认知系统和交通模拟环境相结合；（2）一个为高效检索上下文相关信息而设计的分层记忆系统，其中包含空间和时间关联、关键词匹配和语义相关性；（3）创新的规划和反应机制，用于建模自适应出行行为，这些机制集成了多尺度反思过程，将特定的出行经验转化为普遍的行为洞察。我们实现了一个原型系统并进行了系统验证，证明了生成式智能体产生了可信且连贯的出行行为。实验结果表明，生成式智能体的表现至少与人类标注者相当，后验概率达到92%，同时自然地产生了宏观真实的交通模式。原型实现的源代码可在https://github.com/qiliuchn/gatsim公开获取。", "summary": "GATSim是一种新型城市出行模拟框架，旨在克服传统规则系统在捕捉人类出行行为复杂性方面的不足。它利用大型语言模型和AI智能体技术，通过具有多样化社会经济背景、生活方式和不断演变偏好的生成式智能体来模拟城市出行。GATSim的核心贡献包括一个整合了出行基础模型、认知系统和模拟环境的综合架构，一个高效的分层记忆系统，以及用于建模自适应行为的创新规划和反应机制。实验验证表明，GATSim的生成式智能体能够产生可信且连贯的出行行为，性能与人类标注者相当，并能生成真实的宏观交通模式。", "keywords": "城市出行模拟,生成式智能体,大型语言模型,交通模式,行为多样性", "comments": "GATSim的创新之处在于将大型语言模型和AI智能体技术引入城市出行模拟领域，显著提升了模拟智能体的行为多样性和适应性，使其更接近真实人类行为。其分层记忆系统和多尺度反思机制是关键的技术突破。这项工作对于未来城市规划、交通管理和智能交通系统的发展具有重要意义。"}}
{"id": "2507.11928", "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "authors": ["Abhishek Sriram", "Neal Tuffy"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper is a pre-print version and has been submitted to the IEEE International Conference on Future Machine Learning and Data Science (FMLDS 2025)", "url": "http://arxiv.org/abs/2507.11928v2", "summary": "This paper presents a machine learning-accelerated optimization framework for\nRF power amplifier design that reduces simulation requirements by 65% while\nmaintaining $\\pm0.4$ dBm accuracy for the majority of the modes. The proposed\nmethod combines MaxMin Latin Hypercube Sampling with CatBoost gradient boosting\nto intelligently explore multidimensional parameter spaces. Instead of\nexhaustively simulating all parameter combinations to achieve target P2dB\ncompression specifications, our approach strategically selects approximately\n35% of critical simulation points. The framework processes ADS netlists,\nexecutes harmonic balance simulations on the reduced dataset, and trains a\nCatBoost model to predict P2dB performance across the entire design space.\nValidation across 15 PA operating modes yields an average $R^2$ of 0.901, with\nthe system ranking parameter combinations by their likelihood of meeting target\nspecifications. The integrated solution delivers 58.24% to 77.78% reduction in\nsimulation time through automated GUI-based workflows, enabling rapid design\niterations without compromising accuracy standards required for production RF\ncircuits.", "comment": "This paper is a pre-print version and has been submitted to the IEEE\n  International Conference on Future Machine Learning and Data Science (FMLDS\n  2025)", "pdf_url": "http://arxiv.org/pdf/2507.11928v2", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "智能采样与基于机器学习的参数调优加速射频功率放大器设计", "tldr": "通过智能采样和机器学习，显著加速射频功率放大器设计并减少仿真需求，同时保持高精度。", "motivation": "传统的射频功率放大器设计需要详尽的仿真，耗时且资源密集，这限制了设计迭代的速度。本研究的动机在于开发一种能够大幅减少仿真需求并加速设计过程的优化框架。", "method": "本文提出了一种机器学习加速的优化框架，它结合了MaxMin拉丁超立方采样（MaxMin Latin Hypercube Sampling）和CatBoost梯度提升（CatBoost gradient boosting）算法。该方法通过智能地选择大约35%的关键仿真点，而不是穷举模拟所有参数组合，来探索多维参数空间。框架处理ADS网表，在缩减的数据集上执行谐波平衡仿真，并训练CatBoost模型来预测P2dB性能。", "result": "该框架成功将仿真要求减少了65%，同时在大多数模式下保持了±0.4 dBm的精度。在15种PA操作模式下的验证显示，平均R²达到0.901。通过自动化GUI工作流程，仿真时间减少了58.24%至77.78%。", "conclusion": "该集成解决方案在不牺牲生产级射频电路所需精度标准的情况下，实现了快速设计迭代，显著加速了射频功率放大器设计过程。", "translation": "本论文提出了一种机器学习加速的射频功率放大器设计优化框架，该框架将仿真需求减少了65%，同时在大多数模式下保持±0.4 dBm的精度。所提出的方法结合了MaxMin拉丁超立方采样与CatBoost梯度提升，以智能地探索多维参数空间。我们的方法并非穷举模拟所有参数组合以达到目标P2dB压缩规范，而是策略性地选择大约35%的关键仿真点。该框架处理ADS网表，在缩减的数据集上执行谐波平衡仿真，并训练CatBoost模型以预测整个设计空间中的P2dB性能。在15种PA操作模式下的验证显示平均R²为0.901，系统根据参数组合满足目标规格的可能性进行排序。该集成解决方案通过自动化基于GUI的工作流程，实现了58.24%至77.78%的仿真时间缩减，从而在不影响生产射频电路所需精度标准的情况下，实现了快速设计迭代。", "summary": "本文提出了一种基于机器学习的射频功率放大器设计优化框架，其核心在于结合MaxMin拉丁超立方采样和CatBoost梯度提升，以智能地选择关键仿真点，从而将仿真需求大幅减少65%。该框架通过处理ADS网表、执行谐波平衡仿真并训练模型来预测性能，最终实现了58.24%至77.78%的仿真时间缩减，同时保持了高精度，极大地加速了射频电路的设计迭代。", "keywords": "射频功率放大器设计, 机器学习, 智能采样, CatBoost, 仿真加速", "comments": "这篇论文通过将智能采样技术与机器学习（CatBoost）相结合，为射频功率放大器设计领域提供了一个高效且创新的优化框架。其核心贡献在于显著减少了传统设计中耗时且资源密集型的仿真需求，同时确保了生产级电路所需的精度。这种方法对于加速射频电路的研发周期和降低设计成本具有重要的实际应用价值。"}}
{"id": "2506.17135", "title": "No Scratch Quantum Computing by Reducing Qubit Overhead for Efficient Arithmetics", "authors": ["Omid Faizy", "Norbert Wehn", "Paul Lukowicz", "Maximilian Kiefer-Emmanouilidis"], "categories": ["quant-ph", "cs.ET", "cs.LO"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.17135v2", "summary": "Quantum arithmetic computation requires a substantial number of scratch\nqubits to stay reversible. These operations necessitate qubit and gate\nresources equivalent to those needed for the larger of the input or output\nregisters due to state encoding. Quantum Hamiltonian Computing (QHC) introduces\na novel approach by encoding input for logic operations within a single\nrotating quantum gate. This innovation reduces the required qubit register $ N\n$ to the size of the output states $ O $, where $ N = \\log_2 O $. Leveraging\nQHC principles, we present reversible half-adder and full-adder circuits that\ncompress the standard Toffoli + CNOT layout [Vedral et al., PRA, 54, 11,\n(1996)] from three-qubit and four-qubit formats for the Quantum half-adder\ncircuit and five sequential Fredkin gates using five qubits [Moutinho et al.,\nPRX Energy 2, 033002 (2023)] for full-adder circuit; into a two-qubit, 4$\\times\n$4 Hilbert space. This scheme, presented here, is optimized for classical logic\nevaluated on quantum hardware, which due to unitary evolution can bypass\nclassical CMOS energy limitations to certain degree. Although we avoid\nsuperposition of input and output states in this manuscript, this remains\nfeasible in principle. We see the best application for QHC in finding the\nminimal qubit and gate resources needed to evaluate any truth table, advancing\nFPGA capabilities using integrated quantum circuits or photonics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.17135v2", "cate": "quant-ph", "date": "2025-06-20", "updated": "2025-07-18", "AI": {"title_translation": "无需暂存量子计算：通过减少量子比特开销实现高效算术运算", "tldr": "该研究提出了一种基于量子哈密顿计算 (QHC) 的新方法，用于实现高效的量子算术运算，显著减少了执行半加器和全加器所需的量子比特数量，将其压缩到两量子比特的希尔伯特空间，从而降低了量子计算的资源开销。", "motivation": "传统的量子算术计算需要大量的暂存量子比特以保持可逆性，并且由于状态编码，所需的量子比特和门资源与输入或输出寄存器中较大的一个相当，这导致了高昂的资源开销。", "method": "该研究引入了量子哈密顿计算 (QHC) 方法，通过在单个旋转量子门内编码逻辑运算的输入，将所需量子比特寄存器N减少到输出状态O的大小（N = log2 O）。利用QHC原理，论文展示了可逆半加器和全加器电路，将标准Toffoli + CNOT布局（三量子比特和四量子比特）以及五量子比特的Fredkin门序列（用于全加器）压缩到两量子比特、4x4的希尔伯特空间中。", "result": "研究成功地将量子半加器和全加器电路所需的量子比特和门资源从传统的三量子比特、四量子比特或五量子比特配置，大幅压缩到仅需两量子比特的4x4希尔伯特空间。这种方案优化了在量子硬件上评估经典逻辑的能力，并且由于酉演化，可以在一定程度上绕过经典CMOS的能量限制。", "conclusion": "量子哈密顿计算 (QHC) 为评估任意真值表提供了最小的量子比特和门资源，有望通过集成量子电路或光子学技术推动FPGA能力的发展。", "translation": "量子算术计算需要大量的暂存量子比特以保持可逆性。由于状态编码，这些操作所需的量子比特和门资源相当于输入或输出寄存器中较大的一个。量子哈密顿计算 (QHC) 引入了一种新颖的方法，通过在单个旋转量子门内编码逻辑运算的输入。这项创新将所需量子比特寄存器 N 减少到输出状态 O 的大小，其中 N = log2 O。利用 QHC 原理，我们提出了可逆半加器和全加器电路，将标准 Toffoli + CNOT 布局 [Vedral 等人，PRA，54，11，(1996)] 从量子半加器电路的三量子比特和四量子比特格式，以及全加器电路的五个使用五个量子比特的顺序 Fredkin 门 [Moutinho 等人，PRX Energy 2，033002 (2023)] 压缩到两量子比特、4x4 希尔伯特空间。这里提出的这种方案针对在量子硬件上评估经典逻辑进行了优化，由于酉演化，它可以在一定程度上绕过经典 CMOS 的能量限制。尽管我们在本手稿中避免了输入和输出状态的叠加，但这在原则上仍然是可行的。我们认为 QHC 的最佳应用在于寻找评估任意真值表所需的最小量子比特和门资源，从而通过集成量子电路或光子学技术推进 FPGA 的能力。", "summary": "该论文介绍了一种基于量子哈密顿计算 (QHC) 的方法，旨在显著减少量子算术运算所需的量子比特开销。通过在单个旋转量子门中编码输入，QHC 能够将所需的量子比特数量从传统配置大幅压缩。具体地，研究展示了如何将可逆半加器和全加器电路从多量子比特（如三、四或五量子比特）格式优化到仅需两量子比特的 4x4 希尔伯特空间。这种方法不仅提高了量子算术的资源效率，还为在量子硬件上评估经典逻辑提供了新的途径，并有望应用于未来FPGA能力的提升。", "keywords": "量子计算, 量子比特开销, 量子算术, QHC, 可逆电路", "comments": "该论文在量子计算领域具有重要意义，特别是在解决量子算术运算中量子比特开销过大的挑战方面。QHC方法的提出，通过创新的输入编码方式和门设计，实现了显著的资源优化，将复杂的算术电路压缩到极小的希尔伯特空间，这对于构建更实用的量子计算机至关重要。其创新点在于从根本上改变了量子逻辑门的设计范式，从而绕过了一些传统限制。此外，该研究指出了其在超越经典CMOS能量限制以及未来FPGA应用方面的潜力，预示了广阔的应用前景。"}}
{"id": "2412.15366", "title": "Capacity and PAPR Analysis for MIMO Faster-than-Nyquist Signaling with High Acceleration Rate", "authors": ["Zichao Zhang", "Melda Yuksel", "Gokhan M. Guvensen", "Halim Yanikomeroglu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.15366v2", "summary": "Faster-than-Nyquist (FTN) signaling is a non-orthogonal transmission\ntechnique offering a promising solution for future generations of\ncommunications. This paper studies the capacity of FTN signaling in\nmultiple-input multiple-output (MIMO) channels for high acceleration factors.\nIn our previous study [1], we found the capacity for MIMO FTN channels if the\nacceleration factor is larger than a certain threshold, which depends on the\nbandwidth of the pulse shape used. In this paper, we extend the capacity\nanalysis to acceleration factors smaller than this mentioned threshold. In\naddition to capacity, we conduct peak-to-average power ratio (PAPR) analysis\nand simulation for MIMO FTN for varying acceleration factors for both Gaussian\nand QPSK symbol sets. Our analysis reveals important insights about\ntransmission power and received signal-to-noise ratio (SNR) variation in FTN.\nAs the acceleration factor approaches 0, if the transmission power is fixed,\nthe received SNR diminishes, or if the received SNR is fixed, PAPR at the\ntransmitter explodes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.15366v2", "cate": "cs.IT", "date": "2024-12-19", "updated": "2025-07-17", "AI": {"title_translation": "MIMO高速率超奈奎斯特信号的容量和峰均功率比分析", "tldr": "本文分析了MIMO超奈奎斯特信号在不同加速因子下的容量和峰均功率比，并揭示了低加速因子下的关键性能权衡。", "motivation": "超奈奎斯特（FTN）信号是一种非正交传输技术，为未来通信提供了一种有前景的解决方案。", "method": "本文研究了多输入多输出（MIMO）信道中FTN信号的容量，特别扩展了对小于特定阈值的加速因子的容量分析。此外，还对MIMO FTN在不同加速因子下（针对高斯和QPSK符号集）进行了峰均功率比（PAPR）分析和仿真。", "result": "分析揭示了FTN中传输功率和接收信噪比（SNR）变化的重要见解。当加速因子趋近于0时，如果传输功率固定，接收SNR会减小；如果接收SNR固定，则发射端的PAPR会急剧增大。", "conclusion": "随着加速因子趋近于0，FTN系统在传输功率和接收SNR之间存在权衡，即固定功率会导致SNR下降，而固定SNR则会导致PAPR爆炸。", "translation": "超奈奎斯特（FTN）信号是一种非正交传输技术，为未来通信提供了一种有前景的解决方案。本文研究了多输入多输出（MIMO）信道中FTN信号在高速率加速因子下的容量。在我们之前的研究[1]中，我们发现当加速因子大于某个特定阈值（取决于所用脉冲波形的带宽）时，MIMO FTN信道的容量。在本文中，我们将容量分析扩展到小于此阈值的加速因子。除了容量，我们还对MIMO FTN在不同加速因子下（针对高斯和QPSK符号集）进行了峰均功率比（PAPR）分析和仿真。我们的分析揭示了关于FTN中传输功率和接收信噪比（SNR）变化的重要见解。当加速因子趋近于0时，如果传输功率固定，接收到的SNR会减小；或者如果接收到的SNR固定，则发射端的PAPR会急剧增大。", "summary": "本文研究了MIMO超奈奎斯特（FTN）信号在不同加速因子下的容量和峰均功率比（PAPR）。在扩展了对低加速因子下的容量分析后，研究发现当加速因子趋近于0时，FTN系统在保持固定传输功率时会面临接收信噪比（SNR）下降的问题，而若要保持固定接收SNR，则会引发发射端PAPR的急剧增大，揭示了该技术在极端条件下的性能权衡。", "keywords": "超奈奎斯特信号, MIMO, 容量, 峰均功率比, 加速因子", "comments": "这篇论文通过深入分析MIMO FTN信号在不同加速因子下的容量和PAPR，特别是关注了低加速因子的情况，填补了现有研究的空白。其创新之处在于揭示了加速因子趋近于0时，传输功率、接收SNR和PAPR之间的关键权衡，这对FTN系统的实际部署和优化具有重要指导意义，尤其是在追求极高频谱效率时需考虑的功耗和硬件复杂度问题。"}}
{"id": "2507.14025", "title": "Reference-Free Iterative Learning Model Predictive Control with Neural Certificates", "authors": ["Wataru Hashimoto", "Kazumune Hashimoto", "Masako Kishida", "Shigemasa Takai"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This paper was submitted to IET Control Theory & Applications on May 19, 2025 (under review)", "url": "http://arxiv.org/abs/2507.14025v1", "summary": "In this paper, we propose a novel reference-free iterative learning model\npredictive control (MPC). In the proposed method, a certificate function based\non the concept of Control Lyapunov Barrier Function (CLBF) is learned using\ndata collected from past control executions and used to define the terminal set\nand cost in the MPC optimization problem at the current iteration. This scheme\nenables the progressive refinement of the MPC's terminal components over\nsuccessive iterations. Unlike existing methods that rely on mixed-integer\nprogramming and suffer from numerical difficulties, the proposed approach\nformulates the MPC optimization problem as a standard nonlinear program,\nenabling more efficient online computation. The proposed method satisfies key\nMPC properties, including recursive feasibility and asymptotic stability.\nAdditionally, we demonstrate that the performance cost is non-increasing with\nrespect to the number of iterations, under certain assumptions. Numerical\nexperiments including the simulation with PyBullet confirm that our control\nscheme iteratively enhances control performance and significantly improves\nonline computational efficiency compared to the existing methods.", "comment": "This paper was submitted to IET Control Theory & Applications on May\n  19, 2025 (under review)", "pdf_url": "http://arxiv.org/pdf/2507.14025v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "无参考迭代学习模型预测控制与神经证书", "tldr": "本文提出一种新型无参考迭代学习模型预测控制（MPC），通过学习神经证书函数改进MPC的终端组分，并将其MPC优化问题表述为标准非线性规划，显著提升了在线计算效率和控制性能。", "motivation": "现有模型预测控制（MPC）方法常依赖混合整数规划（MIP），存在数值困难，且在线计算效率不高。", "method": "提出一种无参考迭代学习模型预测控制（MPC）方法。该方法通过从过去的控制执行中收集数据，学习一个基于控制Lyapunov障碍函数（CLBF）概念的证书函数。这个证书函数用于定义当前迭代中MPC优化问题的终端集和成本，从而实现MPC终端组件的逐步改进。与现有方法不同，该方法将MPC优化问题表述为标准非线性规划。", "result": "该方法满足MPC的关键性质，包括递归可行性和渐近稳定性。在特定假设下，性能成本随迭代次数的增加而非递增。数值实验（包括使用PyBullet的仿真）证实，该控制方案迭代地增强了控制性能，并与现有方法相比显著提高了在线计算效率。", "conclusion": "所提出的无参考迭代学习MPC方法通过引入神经证书和采用标准非线性规划，有效解决了现有方法的局限性，实现了控制性能的迭代提升和在线计算效率的大幅改善。", "translation": "在本文中，我们提出了一种新颖的无参考迭代学习模型预测控制（MPC）。在所提出的方法中，一个基于控制Lyapunov障碍函数（CLBF）概念的证书函数通过从过去的控制执行中收集的数据进行学习，并用于定义当前迭代中MPC优化问题的终端集和成本。该方案能够实现在连续迭代中MPC终端组件的逐步完善。与依赖混合整数规划并存在数值困难的现有方法不同，所提出的方法将MPC优化问题表述为标准非线性规划，从而实现了更高效的在线计算。所提出的方法满足关键的MPC性质，包括递归可行性和渐近稳定性。此外，我们证明在某些假设下，性能成本随迭代次数的增加而非递增。包括使用PyBullet的仿真在内的数值实验证实，我们的控制方案迭代地增强了控制性能，并与现有方法相比显著提高了在线计算效率。", "summary": "本文介绍了一种新颖的无参考迭代学习模型预测控制（MPC）框架。该框架通过从历史数据中学习一个基于控制Lyapunov障碍函数（CLBF）的“神经证书”，来动态定义MPC优化问题的终端集和成本，从而在迭代过程中逐步优化MPC的性能。与现有依赖混合整数规划的方法不同，本方法将MPC问题转换为标准非线性规划，显著提升了在线计算效率。实验证明，该方法不仅保证了递归可行性和渐近稳定性，还能迭代提升控制性能并大幅提高计算效率。", "keywords": "模型预测控制, 迭代学习, 神经证书, 无参考控制, 非线性规划", "comments": "本文的创新点在于结合了迭代学习控制和模型预测控制，并通过引入“神经证书”的概念，实现了终端集和成本的自适应学习与优化，避免了传统MPC中需要预先设计终端组件的难题。此外，将MPC问题转化为标准非线性规划而非混合整数规划，是其在工程应用中提升计算效率的关键突破。这对于实时控制系统具有重要意义。"}}
{"id": "2403.07486", "title": "XpertAI: uncovering regression model strategies for sub-manifolds", "authors": ["Simon Letzgus", "Klaus-Robert Müller", "Grégoire Montavon"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Best paper award - World Conference on eXplainable Artificial Intelligence, 09-11 July, 2025 - Istanbul, Turkey", "url": "http://arxiv.org/abs/2403.07486v4", "summary": "In recent years, Explainable AI (XAI) methods have facilitated profound\nvalidation and knowledge extraction from ML models. While extensively studied\nfor classification, few XAI solutions have addressed the challenges specific to\nregression models. In regression, explanations need to be precisely formulated\nto address specific user queries (e.g.\\ distinguishing between `Why is the\noutput above 0?' and `Why is the output above 50?'). They should furthermore\nreflect the model's behavior on the relevant data sub-manifold. In this paper,\nwe introduce XpertAI, a framework that disentangles the prediction strategy\ninto multiple range-specific sub-strategies and allows the formulation of\nprecise queries about the model (the `explanandum') as a linear combination of\nthose sub-strategies. XpertAI is formulated generally to work alongside popular\nXAI attribution techniques, based on occlusion, gradient integration, or\nreverse propagation. Qualitative and quantitative results, demonstrate the\nbenefits of our approach.", "comment": "Best paper award - World Conference on eXplainable Artificial\n  Intelligence, 09-11 July, 2025 - Istanbul, Turkey", "pdf_url": "http://arxiv.org/pdf/2403.07486v4", "cate": "cs.LG", "date": "2024-03-12", "updated": "2025-07-18", "AI": {"title_translation": "XpertAI：揭示子流形上的回归模型策略", "tldr": "XpertAI是一个针对回归模型的新型可解释AI框架，它能将预测策略分解为多个范围特定的子策略，以回答精确的用户查询，并可与现有归因技术结合，其有效性已得到验证。", "motivation": "现有的可解释人工智能（XAI）方法主要针对分类模型，而很少有解决方案能够解决回归模型特有的挑战。在回归中，解释需要精确地表达以响应特定的用户查询（例如，区分“为什么输出高于0？”和“为什么输出高于50？”），并且需要反映模型在相关数据子流形上的行为。", "method": "本文引入了XpertAI框架，该框架将预测策略分解为多个范围特定子策略，并允许将关于模型的精确查询（“可解释项”）表述为这些子策略的线性组合。XpertAI被普遍地设计为可以与流行的XAI归因技术（基于遮挡、梯度积分或反向传播）协同工作。", "result": "定性和定量结果证明了该方法的优势。", "conclusion": "XpertAI框架通过将预测策略分解为范围特定的子策略，并允许精确的用户查询，有效解决了回归模型可解释性中的特定挑战，并能与现有XAI技术兼容。", "translation": "近年来，可解释人工智能（XAI）方法促进了对机器学习模型的深度验证和知识提取。尽管在分类领域得到了广泛研究，但很少有XAI解决方案能够解决回归模型特有的挑战。在回归中，解释需要精确地表达，以响应特定的用户查询（例如，区分“为什么输出高于0？”和“为什么输出高于50？”）。此外，它们还应反映模型在相关数据子流形上的行为。在本文中，我们引入了XpertAI，这是一个将预测策略分解为多个范围特定子策略的框架，并允许将关于模型的精确查询（“被解释项”）表述为这些子策略的线性组合。XpertAI被普遍地设计为可以与流行的XAI归因技术（基于遮挡、梯度积分或反向传播）协同工作。定性和定量结果证明了我们方法的优势。", "summary": "本文提出了XpertAI，一个专门为回归模型设计的可解释AI框架。它通过将模型预测策略分解为针对特定输出范围的子策略，并允许用户提出精确的查询，从而解决了现有XAI方法在回归模型中面临的挑战。XpertAI与主流归因技术兼容，并通过实验验证了其有效性。", "keywords": "可解释AI, 回归模型, 子流形, 预测策略, XpertAI", "comments": "XpertAI的创新之处在于其对回归模型解释的细粒度处理，特别是将预测策略分解为范围特定的子策略，以响应精确的用户查询。这弥补了现有XAI方法在回归领域的一个重要空白，并强调了模型行为在数据子流形上的重要性。其与现有归因技术的兼容性也增强了其实用性。"}}
{"id": "2409.00901", "title": "On the optimal approximation of Sobolev and Besov functions using deep ReLU neural networks", "authors": ["Yunfei Yang"], "categories": ["stat.ML", "cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.00901v3", "summary": "This paper studies the problem of how efficiently functions in the Sobolev\nspaces $\\mathcal{W}^{s,q}([0,1]^d)$ and Besov spaces\n$\\mathcal{B}^s_{q,r}([0,1]^d)$ can be approximated by deep ReLU neural networks\nwith width $W$ and depth $L$, when the error is measured in the $L^p([0,1]^d)$\nnorm. This problem has been studied by several recent works, which obtained the\napproximation rate $\\mathcal{O}((WL)^{-2s/d})$ up to logarithmic factors when\n$p=q=\\infty$, and the rate $\\mathcal{O}(L^{-2s/d})$ for networks with fixed\nwidth when the Sobolev embedding condition $1/q -1/p<s/d$ holds. We generalize\nthese results by showing that the rate $\\mathcal{O}((WL)^{-2s/d})$ indeed holds\nunder the Sobolev embedding condition. It is known that this rate is optimal up\nto logarithmic factors. The key tool in our proof is a novel encoding of sparse\nvectors by using deep ReLU neural networks with varied width and depth, which\nmay be of independent interest.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.00901v3", "cate": "stat.ML", "date": "2024-09-02", "updated": "2025-07-18", "AI": {"title_translation": "关于使用深度ReLU神经网络最优逼近Sobolev和Besov函数", "tldr": "本文证明了在Sobolev嵌入条件下，深度ReLU网络可以最优逼近Sobolev和Besov函数，并引入了一种新颖的稀疏向量编码方法。", "motivation": "以往研究已探讨深度ReLU神经网络对Sobolev和Besov函数的逼近效率，但存在特定条件限制（例如$p=q=\\infty$或固定宽度网络）。本文旨在推广这些结果，证明在更广泛的Sobolev嵌入条件下也能达到最优逼近速率。", "method": "通过证明在Sobolev嵌入条件下，深度ReLU神经网络的逼近速率为$\\mathcal{O}((WL)^{-2s/d})$来推广现有结果。证明的关键工具是使用宽度和深度可变的深度ReLU神经网络对稀疏向量进行新颖的编码。", "result": "本文证明了在Sobolev嵌入条件下，深度ReLU神经网络对Sobolev和Besov函数的逼近速率为$\\mathcal{O}((WL)^{-2s/d})$，且该速率在不计对数因子的情况下是最佳的。", "conclusion": "深度ReLU神经网络在Sobolev嵌入条件下能够实现对Sobolev和Besov函数的最佳逼近。论文中提出的稀疏向量新颖编码方法可能具有独立的理论意义和应用价值。", "translation": "本文研究了在$L^p([0,1]^d)$范数下，深度ReLU神经网络以宽度$W$和深度$L$如何高效地逼近Sobolev空间$\\mathcal{W}^{s,q}([0,1]^d)$和Besov空间$\\mathcal{B}^s_{q,r}([0,1]^d)$中的函数的问题。这个问题已被几项近期工作研究过，当$p=q=\\infty$时，其逼近速率达到$\\mathcal{O}((WL)^{-2s/d})$（不计对数因子），当Sobolev嵌入条件$1/q -1/p<s/d$成立时，对于固定宽度的网络，速率为$\\mathcal{O}(L^{-2s/d})$。我们通过证明在Sobolev嵌入条件下速率$\\mathcal{O}((WL)^{-2s/d})$确实成立来推广这些结果。已知该速率在不计对数因子的情况下是最佳的。我们证明中的关键工具是使用宽度和深度可变的深度ReLU神经网络对稀疏向量进行新颖的编码，这本身可能具有独立的意义。", "summary": "本文研究了深度ReLU神经网络对Sobolev和Besov函数的最优逼近效率。论文推广了现有研究成果，证明在Sobolev嵌入条件下，深度为$L$、宽度为$W$的深度ReLU网络的逼近速率可达到最优的$\\mathcal{O}((WL)^{-2s/d})$。此外，论文提出了一种新颖的稀疏向量编码方法作为证明的关键工具，该方法本身可能具有独立的研究价值。", "keywords": "深度ReLU神经网络, Sobolev空间, Besov空间, 逼近速率, 稀疏向量编码", "comments": "该论文的创新之处在于将深度ReLU神经网络的最优逼近速率推广到Sobolev嵌入条件，这是理论上的一个重要进展。此外，论文提出了一种使用深度ReLU网络进行稀疏向量编码的新颖方法，这不仅是证明的关键，也可能在其他领域具有广泛的应用潜力，值得进一步关注。"}}
{"id": "2507.13362", "title": "Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning", "authors": ["Binbin Ji", "Siddharth Agrawal", "Qiance Tang", "Yvonne Wu"], "categories": ["cs.CV", "cs.AI", "cs.CL", "I.2.10; I.4.8; I.2.6; I.2.7; I.5.4; I.5.1"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 5 figures, submitted to a conference (IEEE formate). Authored by students from the Courant Institute, NYU", "url": "http://arxiv.org/abs/2507.13362v1", "summary": "This study investigates the spatial reasoning capabilities of vision-language\nmodels (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement\nlearning. We begin by evaluating the impact of different prompting strategies\nand find that simple CoT formats, where the model generates a reasoning step\nbefore the answer, not only fail to help, but can even harm the model's\noriginal performance. In contrast, structured multi-stage prompting based on\nscene graphs (SceneGraph CoT) significantly improves spatial reasoning\naccuracy. Furthermore, to improve spatial reasoning ability, we fine-tune\nmodels using Group Relative Policy Optimization (GRPO) on the SAT dataset and\nevaluate their performance on CVBench. Compared to supervised fine-tuning\n(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates\nsuperior robustness under out-of-distribution (OOD) conditions. In particular,\nwe find that SFT overfits to surface-level linguistic patterns and may degrade\nperformance when test-time phrasing changes (e.g., from \"closer to\" to \"farther\nfrom\"). GRPO, on the other hand, generalizes more reliably and maintains stable\nperformance under such shifts. Our findings provide insights into how\nreinforcement learning and structured prompting improve the spatial reasoning\ncapabilities and generalization behavior of modern VLMs. All code is open\nsource at: https://github.com/Yvonne511/spatial-vlm-investigator", "comment": "10 pages, 5 figures, submitted to a conference (IEEE formate).\n  Authored by students from the Courant Institute, NYU", "pdf_url": "http://arxiv.org/pdf/2507.13362v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06", "AI": {"title_translation": "通过思维链提示和强化学习增强视觉语言模型的空间推理能力", "tldr": "本研究发现，简单的思维链提示可能损害视觉语言模型的空间推理能力，而结构化的场景图思维链提示则显著提高准确性。此外，基于强化学习的群组相对策略优化（GRPO）微调在空间推理方面优于监督微调（SFT），在分布外条件下表现出更高的准确性和卓越的鲁棒性。", "motivation": "本研究旨在调查视觉语言模型（VLM）的空间推理能力，并探究思维链（CoT）提示和强化学习对其性能的影响，特别是提升其泛化能力。", "method": "研究评估了不同的提示策略，包括简单CoT和基于场景图的结构化多阶段提示（SceneGraph CoT）。此外，使用群组相对策略优化（GRPO）在SAT数据集上对模型进行微调，并在CVBench上与监督微调（SFT）进行性能比较。", "result": "简单的CoT格式未能帮助甚至损害了模型的原始性能。结构化多阶段的SceneGraph CoT显著提高了空间推理准确性。与SFT相比，GRPO在Pass@1评估中取得了更高的准确率，并在分布外（OOD）条件下表现出卓越的鲁棒性。SFT过度拟合表面语言模式，而GRPO则更可靠地泛化并保持稳定性能。", "conclusion": "强化学习（GRPO）和结构化提示（SceneGraph CoT）能够有效提高现代视觉语言模型的空间推理能力和泛化行为。", "translation": "本研究通过思维链（CoT）提示和强化学习，探讨了视觉语言模型（VLM）的空间推理能力。我们首先评估了不同提示策略的影响，发现简单的CoT格式（模型在回答前生成推理步骤）不仅没有帮助，甚至可能损害模型的原始性能。相比之下，基于场景图的结构化多阶段提示（SceneGraph CoT）显著提高了空间推理准确性。此外，为了提高空间推理能力，我们使用群组相对策略优化（GRPO）在SAT数据集上对模型进行微调，并在CVBench上评估其性能。与监督微调（SFT）相比，GRPO在Pass@1评估中取得了更高的准确率，并在分布外（OOD）条件下表现出卓越的鲁棒性。特别是，我们发现SFT过度拟合表面语言模式，当测试时措辞改变时（例如，从“更靠近”到“更远离”），可能会降低性能。而GRPO则更可靠地泛化，并在此类变化下保持稳定性能。我们的发现提供了关于强化学习和结构化提示如何提高现代VLM空间推理能力和泛化行为的见解。所有代码均已开源：https://github.com/Yvonne511/spatial-vlm-investigator", "summary": "本研究探讨了如何增强视觉语言模型（VLM）的空间推理能力。研究发现，简单的思维链（CoT）提示可能有害，而基于场景图的结构化CoT（SceneGraph CoT）能显著提升准确性。进一步地，通过群组相对策略优化（GRPO）在SAT数据集上进行微调，模型在CVBench上的空间推理表现优于监督微调（SFT），特别是在分布外条件下的鲁棒性和泛化能力更强。研究强调了强化学习和结构化提示对于提升VLM空间推理及其泛化行为的重要性。", "keywords": "空间推理, 视觉语言模型, 思维链, 强化学习, 泛化", "comments": "这篇论文对视觉语言模型中CoT提示和强化学习在空间推理方面的应用提供了重要见解。其发现简单CoT可能有害，这挑战了当前的普遍认知。引入SceneGraph CoT并证明GRPO在泛化性上优于SFT，解决了当前VLM在处理语言变体时的关键限制。这项工作有助于构建更可靠和泛化能力更强的VLM。"}}
{"id": "2507.13470", "title": "Faster Multi-Source Reachability and Approximate Distances via Shortcuts, Hopsets and Matrix Multiplication", "authors": ["Michael Elkin", "Chhaya Trehan"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13470v1", "summary": "Given an $n$-vertex $m$-edge digraph $G = (V,E)$ and a subset $S \\subseteq V$\nof $|S| = n^{\\sigma}$ (for some $0 \\le \\sigma \\le 1$) designated sources, the\n$S \\times V$ reachability problem is to compute the sets $\\mathcal V_s$ of\nvertices reachable from $s$, for every $s \\in S$. Naive centralized algorithms\nrun BFS/DFS from each source in $O(m \\cdot n^{\\sigma})$ time or compute $G$'s\ntransitive closure in $\\hat O(n^{\\omega})$ time, where $\\omega \\le\n2.371552\\ldots$ is the matrix multiplication exponent. Thus, the best known\nbound is $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$. Leveraging shortcut\nconstructions by Kogan and Parter [SODA 2022, ICALP 2022], we develop a\ncentralized algorithm with running time $\\hat O(n^{1 + \\frac{2}{3}\n\\omega(\\sigma)})$, where $\\omega(\\sigma)$ is the rectangular matrix\nmultiplication exponent. Using current estimates on $\\omega(\\sigma)$, our\nexponent improves upon $\\min \\{2 + \\sigma, \\omega \\}$ for $\\tilde \\sigma \\leq\n\\sigma \\leq 0.53$, where $1/3 < \\tilde \\sigma < 0.3336$ is a universal\nconstant.\n  In a classical result, Cohen [Journal of Algorithms, 1996] devised parallel\nalgorithms for $S \\times V$ reachability on graphs admitting balanced recursive\nseparators of size $n^{\\rho}$ for $\\rho < 1$, requiring polylogarithmic time\nand work $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$. We significantly\nimprove, extend, and generalize Cohen's result. First, our parallel algorithm\nfor graphs with small recursive separators has lower work complexity than\nCohen's in boraod paramater ranges. Second, we generalize our algorithm to\ngraphs of treewidth at most $n^{\\rho}$ ($\\rho < 1$) and provide a centralized\nalgorithm that outperforms existing bounds for $S \\times V$ reachability on\nsuch graphs. We also do this for some other graph familes with small\nseparators. Finally, we extend these results to $(1 + \\epsilon)$-approximate\ndistance computation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13470v1", "cate": "cs.DS", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "通过快捷方式、跳跃集和矩阵乘法实现更快的多源可达性和近似距离计算", "tldr": "该论文通过利用快捷方式、跳跃集和矩阵乘法，为多源可达性和近似距离计算提供了更快的算法，在各种图类型上改进了现有界限。", "motivation": "对于给定有向图中的 $S \\times V$ 可达性问题，朴素的集中式算法（如对每个源进行BFS/DFS或计算传递闭包）的运行时间过长，分别为 $O(m \\cdot n^{\\sigma})$ 或 $\\hat O(n^{\\omega})$，最佳已知上界为 $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$。因此，需要更高效的算法来解决此问题。", "method": "本研究利用了Kogan和Parter构建的快捷方式，开发了一种集中式算法，其运行时间为 $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$。此外，论文显著改进、扩展和推广了Cohen在Journal of Algorithms, 1996中提出的经典并行算法，使其适用于具有小递归分离器的图。算法还推广到树宽至多为 $n^{\\rho}$ 的图，并将其结果扩展到 $(1 + \\epsilon)$-近似距离计算。", "result": "所提出的集中式算法的运行时间为 $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$，使用当前 $\\omega(\\sigma)$ 的估计值，在 $\\tilde \\sigma \\leq \\sigma \\leq 0.53$ 范围内（其中 $1/3 < \\tilde \\sigma < 0.3336$ 为通用常数）优于 $\\min \\{2 + \\sigma, \\omega \\}$。对于具有小递归分离器的图，我们的并行算法的工作复杂度低于Cohen的算法。对于树宽至多为 $n^{\\rho}$ 的图，所提出的集中式算法在 $S \\times V$ 可达性方面优于现有界限。这些结果也成功扩展到了 $(1 + \\epsilon)$-近似距离计算。", "conclusion": "本论文为多源可达性问题和近似距离计算提供了显著改进的算法。通过利用快捷方式和推广现有并行算法，新方法在各种图类（包括具有小分离器和有界树宽的图）上表现出优于先前方法的性能。", "translation": "给定一个 $n$ 顶点 $m$ 边的有向图 $G = (V,E)$ 和一个大小为 $|S| = n^{\\sigma}$（对于某个 $0 \\le \\sigma \\le 1$）的指定源点子集 $S \\subseteq V$， $S \\times V$ 可达性问题是计算对于每个 $s \\in S$ 从 $s$ 可达的顶点集 $\\mathcal V_s$。朴素的集中式算法从每个源点运行 BFS/DFS 需要 $O(m \\cdot n^{\\sigma})$ 时间，或者计算 $G$ 的传递闭包需要 $\\hat O(n^{\\omega})$ 时间，其中 $\\omega \\le 2.371552\\ldots$ 是矩阵乘法指数。因此，最佳已知上界是 $\\hat O(n^{\\min \\{ 2 + \\sigma, \\omega\\}})$。通过利用 Kogan 和 Parter 构建的快捷方式 [SODA 2022, ICALP 2022]，我们开发了一种运行时间为 $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$ 的集中式算法，其中 $\\omega(\\sigma)$ 是矩形矩阵乘法指数。使用当前对 $\\omega(\\sigma)$ 的估计值，我们的指数在 $\\tilde \\sigma \\leq \\sigma \\leq 0.53$ 范围内优于 $\\min \\{2 + \\sigma, \\omega \\}$，其中 $1/3 < \\tilde \\sigma < 0.3336$ 是一个通用常数。在一个经典结果中，Cohen [Journal of Algorithms, 1996] 为具有大小为 $n^{\\rho}$（对于 $\\rho < 1$）的平衡递归分离器的图设计了 $S \\times V$ 可达性并行算法，需要多对数时间，工作量为 $n^{\\max \\{\\omega \\rho, 2\\rho + \\sigma \\} + o(1)}$。我们显著改进、扩展和推广了 Cohen 的结果。首先，在广泛的参数范围内，我们针对具有小递归分离器的图的并行算法的工作复杂度低于 Cohen 的算法。其次，我们将算法推广到树宽至多为 $n^{\\rho}$（$\\rho < 1$）的图，并提供了一种集中式算法，其在这些图上的 $S \\times V$ 可达性方面优于现有界限。我们还为其他一些具有小分离器的图族完成了这一点。最后，我们将这些结果扩展到 $(1 + \\epsilon)$-近似距离计算。", "summary": "本论文主要研究有向图中的 $S \\times V$ 可达性问题，其中 $S$ 是源点子集。作者提出了一种新的集中式算法，该算法利用了快捷方式构造，实现了 $\\hat O(n^{1 + \\frac{2}{3} \\omega(\\sigma)})$ 的运行时间，在特定 $\\sigma$ 范围内优于现有最佳界限。此外，论文还对Cohen的经典并行算法进行了显著改进和推广，使其适用于具有小递归分离器的图，并降低了工作复杂度。这些成果进一步扩展到树宽有界的图以及 $(1 + \\epsilon)$-近似距离计算，在这些图族上均超越了现有性能。", "keywords": "多源可达性, 近似距离, 快捷方式, 矩阵乘法, 图算法", "comments": "这篇论文在理论计算机科学领域做出了重要贡献，特别是在图算法的效率方面。通过引入快捷方式构造和对现有并行算法的推广，论文为多源可达性和近似距离计算提供了更优的复杂度上界。其创新性在于将抽象的矩阵乘法指数与具体的图问题相结合，并针对具有特定结构（如小分离器或有界树宽）的图族取得了突破性进展。这对于理解图算法的极限以及设计更高效的算法具有重要意义。"}}
{"id": "2507.13829", "title": "On two fundamental properties of the zeros of spectrograms of noisy signals", "authors": ["Arnaud Poinas", "Rémi Bardenet"], "categories": ["eess.SP", "math.PR"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13829v1", "summary": "The spatial distribution of the zeros of the spectrogram is significantly\naltered when a signal is added to white Gaussian noise. The zeros tend to\ndelineate the support of the signal, and deterministic structures form in the\npresence of interference, as if the zeros were trapped. While sophisticated\nmethods have been proposed to detect signals as holes in the pattern of\nspectrogram zeros, few formal arguments have been made to support the\ndelineation and trapping effects. Through detailed computations for simple toy\nsignals, we show that two basic mathematical arguments, the intensity of zeros\nand Rouch\\'e's theorem, allow discussing delineation and trapping, and the\ninfluence of parameters like the signal-to-noise ratio. In particular,\ninterfering chirps, even nearly superimposed, yield an easy-to-detect\ndeterministic structure among zeros.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13829v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "关于含噪信号谱图零点的两个基本性质", "tldr": "研究表明，含噪信号谱图零点的空间分布会发生显著变化，并能通过零点强度和Rouché定理解释零点对信号的支持边界的描绘作用和干扰下的陷落效应。", "motivation": "尽管已提出多种方法通过谱图零点模式的“孔洞”检测信号，但对于零点描绘信号支持边界和在干扰下形成陷落效应的现象，缺乏正式的数学论证。", "method": "通过对简单“玩具”信号进行详细计算，利用零点强度（intensity of zeros）和Rouché定理这两个基本数学论证来探讨和解释零点的描绘（delineation）和陷落（trapping）效应，并分析信噪比等参数的影响。", "result": "研究表明，零点强度和Rouché定理能够有效解释零点对信号支持边界的描绘作用以及在干扰下的陷落效应。特别是，即使是几乎叠加的干扰线性调频信号，也能在零点中产生易于检测的确定性结构。", "conclusion": "零点强度和Rouché定理为含噪信号谱图零点的描绘和陷落效应提供了坚实的数学基础，这有助于理解和利用谱图零点进行信号分析和检测。", "translation": "当信号中加入高斯白噪声时，谱图零点的空间分布会发生显著改变。零点倾向于描绘信号的支撑范围，并且在存在干扰的情况下会形成确定性结构，仿佛零点被“困住”了一样。尽管已经提出了复杂的信号检测方法，将信号视为谱图零点模式中的“孔洞”，但很少有正式的论证来支持这种描绘和陷落效应。通过对简单的“玩具”信号进行详细计算，我们展示了两个基本的数学论证，即零点强度和Rouché定理，可以用来讨论描绘和陷落效应，以及信噪比等参数的影响。特别是，相互干扰的线性调频信号，即使几乎叠加，也能在零点中产生易于检测的确定性结构。", "summary": "本文探讨了含噪信号谱图零点的两个基本性质：零点描绘信号支持边界的能力和在干扰下形成确定性结构的陷落效应。针对现有研究缺乏正式数学论证的问题，作者通过对简单“玩具”信号的详细计算，运用零点强度和Rouché定理，提供了对这些效应及其受信任比等参数影响的数学解释。研究发现，这些数学工具能够有效支持所观察到的现象，并且即使是接近叠加的干扰线性调频信号，也能在零点中产生易于检测的确定性结构。", "keywords": "谱图零点,含噪信号,零点强度,Rouché定理,信号检测", "comments": "本文的创新之处在于首次为含噪信号谱图零点的描绘和陷落效应提供了坚实的数学理论支持，填补了该领域形式论证的空白。通过引入零点强度和Rouché定理，为理解和利用谱图零点进行信号处理提供了新的视角。其重要性在于能够为基于谱图零点的信号检测和分析方法提供更可靠的理论基础。"}}
{"id": "2311.04938", "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures", "authors": ["Prasad Gabbur"], "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2, I.4"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      29 pages, 14 figures; Analysis of DDIM-GMM as a multimodal denoiser; Additional experiments on LSUN datasets and text-to-image generation with Stable Diffusion; Comparison with DPM-Solver; Ablations on GMM parameters; Updated equations with bold font for vectors and matrices", "url": "http://arxiv.org/abs/2311.04938v3", "summary": "We propose using a Gaussian Mixture Model (GMM) as reverse transition\noperator (kernel) within the Denoising Diffusion Implicit Models (DDIM)\nframework, which is one of the most widely used approaches for accelerated\nsampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).\nSpecifically we match the first and second order central moments of the DDPM\nforward marginals by constraining the parameters of the GMM. We see that moment\nmatching is sufficient to obtain samples with equal or better quality than the\noriginal DDIM with Gaussian kernels. We provide experimental results with\nunconditional models trained on CelebAHQ and FFHQ and class-conditional models\ntrained on ImageNet datasets respectively. Our results suggest that using the\nGMM kernel leads to significant improvements in the quality of the generated\nsamples when the number of sampling steps is small, as measured by FID and IS\nmetrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a\nFID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73\nrespectively with a Gaussian kernel.", "comment": "29 pages, 14 figures; Analysis of DDIM-GMM as a multimodal denoiser;\n  Additional experiments on LSUN datasets and text-to-image generation with\n  Stable Diffusion; Comparison with DPM-Solver; Ablations on GMM parameters;\n  Updated equations with bold font for vectors and matrices", "pdf_url": "http://arxiv.org/pdf/2311.04938v3", "cate": "cs.CV", "date": "2023-11-08", "updated": "2025-07-18", "AI": {"title_translation": "基于矩匹配高斯混合模型的改进DDIM采样", "tldr": "本文提出在DDIM框架中使用高斯混合模型（GMM）作为逆向转移算子，并通过匹配DDPM前向边际分布的一阶和二阶中心矩来约束GMM参数。实验证明，在采样步数较少时，GMM核能显著提高生成样本的质量。", "motivation": "Denoising Diffusion Implicit Models (DDIM) 是加速从预训练Denoising Diffusion Probabilistic Models (DDPM) 采样的常用方法之一，本文旨在进一步改进DDIM的采样质量，尤其是在采样步数较少的情况下。", "method": "本文提出在DDIM框架中，使用高斯混合模型（GMM）作为逆向转移算子（核）。具体而言，通过约束GMM的参数，使其匹配DDPM前向边际分布的一阶和二阶中心矩。", "result": "实验结果表明，与原始使用高斯核的DDIM相比，矩匹配方法足以获得相同或更优的样本质量。在使用少量采样步数时，GMM核显著提高了生成样本的质量，这通过FID和IS指标衡量。例如，在ImageNet 256x256数据集上，使用10个采样步数时，GMM核的FID为6.94，IS为207.85，而高斯核的FID分别为10.15和196.73。", "conclusion": "本文的结论是，在DDIM框架中使用高斯混合模型（GMM）作为逆向转移算子，并通过匹配前向边际分布的矩，可以显著提高生成样本的质量，尤其是在采样步数较少的情况下。", "translation": "我们提出在去噪扩散隐式模型（DDIM）框架内使用高斯混合模型（GMM）作为逆向转移算子（核），DDIM是用于从预训练去噪扩散概率模型（DDPM）加速采样的最广泛使用的方法之一。具体来说，我们通过约束GMM的参数来匹配DDPM前向边际分布的一阶和二阶中心矩。我们发现，矩匹配足以获得与原始使用高斯核的DDIM相同或更好的样本质量。我们提供了在CelebAHQ和FFHQ上训练的无条件模型以及在ImageNet数据集上训练的类别条件模型的实验结果。我们的结果表明，当采样步数较少时，使用GMM核可以显著提高生成样本的质量，这通过FID和IS指标衡量。例如，在ImageNet 256x256上，使用10个采样步数时，GMM核的FID为6.94，IS为207.85，而高斯核的FID分别为10.15和196.73。", "summary": "本文提出了一种改进DDIM采样的方法，即在DDIM框架中引入高斯混合模型（GMM）作为逆向转移算子。该方法通过匹配DDPM前向边际分布的一阶和二阶中心矩来约束GMM参数。实验结果表明，与传统的DDIM相比，这种基于GMM核的方法在采样步数较少时能够显著提升生成样本的质量，例如在ImageNet数据集上展示了FID和IS指标的显著改善。", "keywords": "DDIM, 高斯混合模型, 扩散模型, 采样加速, 矩匹配", "comments": "本文的创新点在于将高斯混合模型（GMM）引入到DDIM的逆向采样过程中，并通过矩匹配的方式对GMM参数进行约束，从而有效地提升了生成样本的质量，尤其是在低采样步数下的性能表现。这对于需要快速生成高质量样本的应用场景具有重要意义，是DDIM采样加速领域的一个有价值的改进。"}}
{"id": "2507.12144", "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "authors": ["Boris Bonev", "Thorsten Kurth", "Ankur Mahesh", "Mauro Bisson", "Jean Kossaifi", "Karthik Kashinath", "Anima Anandkumar", "William D. Collins", "Michael S. Pritchard", "Alexander Keller"], "categories": ["cs.LG", "physics.ao-ph", "86-10, 68T07", "I.2.1; I.6.5; G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12144v2", "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 60-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 4 minutes. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12144v2", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "FourCastNet 3：一种大规模概率机器学习天气预报的几何方法", "tldr": "FourCastNet 3 是一种基于几何机器学习的大规模概率天气预报模型，它比传统方法更快、更准确，并能保持长期预测的稳定性。", "motivation": "该研究旨在通过实现可扩展的几何机器学习方法来推进全球天气建模，以进行概率集合预报，并解决现有方法在处理球形几何、空间相关概率性质以及预测速度和准确性方面的挑战。", "method": "FourCastNet 3 采用了一种可扩展的几何机器学习方法进行概率集合预报，该方法尊重球形几何并精确建模空间相关的概率性质。它使用纯卷积神经网络架构，并针对球形几何进行定制。通过一种受经典数值模型域分解方法启发的新型训练范式，结合了模型并行和数据并行，实现了在 1024 个及更多 GPU 上的可扩展高效大规模训练。", "result": "FourCastNet 3 的预报精度超越了领先的传统集合模型，并与最佳的基于扩散的方法相媲美，同时预报速度比这些方法快 8 到 60 倍。与其他机器学习方法相比，FourCastNet 3 表现出出色的概率校准，即使在长达 60 天的延长预报时间下也能保持真实的频谱。它能在单个 GPU 上快速推理，在 4 分钟内生成 0.25 度、6 小时分辨率的 60 天全球预报。", "conclusion": "FourCastNet 3 的计算效率、中期概率技能、频谱保真度和次季节时间尺度上的滚动稳定性使其成为通过大规模集合预测改进气象预报和早期预警系统的有力候选者。", "translation": "FourCastNet 3 通过实现一种可扩展的、几何机器学习（ML）方法进行概率集合预报，从而推进全球天气建模。该方法旨在尊重球形几何并准确建模问题的空间相关概率性质，从而在多个尺度上产生稳定的频谱和真实的动力学。FourCastNet 3 的预报精度超越了领先的传统集合模型，并与最佳的基于扩散的方法相媲美，同时预报速度比这些方法快 8 到 60 倍。与其他机器学习方法不同，FourCastNet 3 表现出出色的概率校准，即使在长达 60 天的延长预报时间下也能保持真实的频谱。所有这些进展都是通过为球形几何量身定制的纯卷积神经网络架构实现的。受经典数值模型中域分解方法启发的一种新颖的训练范式，结合了模型并行和数据并行，实现了在 1024 个及更多 GPU 上的可扩展高效大规模训练。此外，FourCastNet 3 能够在单个 GPU 上进行快速推理，在 4 分钟内生成 0.25 度、6 小时分辨率的 60 天全球预报。其计算效率、中期概率技能、频谱保真度和次季节时间尺度上的滚动稳定性使其成为通过大规模集合预测改进气象预报和早期预警系统的有力候选者。", "summary": "FourCastNet 3 提出了一种创新的几何机器学习方法，用于大规模概率天气预报。该模型专门设计以尊重地球的球形几何和处理空间相关性，从而在多尺度上实现稳定的动力学和频谱。它在预测准确性上超越了传统模型并与顶级的扩散方法匹敌，同时显著提高了预测速度。FourCastNet 3 在长期预测中展现出卓越的概率校准和频谱保真度，并通过定制的卷积神经网络架构和新颖的分布式训练范式实现。其高效的单 GPU 推理能力和在次季节时间尺度上的稳定性使其成为改进气象预报和早期预警系统的强大工具。", "keywords": "天气预报, 机器学习, 概率预报, 几何方法, 卷积神经网络", "comments": "FourCastNet 3 的创新之处在于其将几何机器学习方法应用于大规模概率天气预报，特别是通过定制的卷积神经网络来尊重球形几何，并结合了新颖的分布式训练范式。其在保持高精度和良好概率校准的同时，大幅提升了预测速度，这对于实时气象预报和早期预警系统具有重要意义。该研究展示了机器学习在复杂科学领域超越传统方法的潜力。"}}
{"id": "2507.13553", "title": "Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 9th International Workshop on Crowd-Based Requirements Engineering (CrowdRE'25)", "url": "http://arxiv.org/abs/2507.13553v1", "summary": "As user demands evolve, effectively incorporating feature requests is crucial\nfor maintaining software relevance and user satisfaction. Feature requests,\ntypically expressed in natural language, often suffer from ambiguity or\nincomplete information due to communication gaps or the requester's limited\ntechnical expertise. These issues can lead to misinterpretation, faulty\nimplementation, and reduced software quality. While seeking clarification from\nrequesters is a common strategy to mitigate these risks, little is known about\nhow developers engage in this clarification process in practice-how they\nformulate clarifying questions, seek technical or contextual details, align on\ngoals and use cases, or decide to close requests without attempting\nclarification. This study investigates how feature requests are prone to NL\ndefects (i.e. ambiguous or incomplete) and the conversational dynamics of\nclarification in open-source software (OSS) development, aiming to understand\nhow developers handle ambiguous or incomplete feature requests. Our findings\nsuggest that feature requests published on the OSS platforms do possess\nambiguity and incompleteness, and in some cases, both. We also find that\nexplicit clarification for the resolution of these defects is uncommon;\ndevelopers usually focus on aligning with project goals rather than resolving\nunclear text. When clarification occurs, it emphasizes understanding user\nintent/goal and feasibility, rather than technical details. By characterizing\nthe dynamics of clarification in open-source issue trackers, this work\nidentifies patterns that can improve user-developer collaboration and inform\nbest practices for handling feature requests effectively.", "comment": "Accepted at the 9th International Workshop on Crowd-Based\n  Requirements Engineering (CrowdRE'25)", "pdf_url": "http://arxiv.org/pdf/2507.13553v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "从大众获取更好需求的途径：开源软件中开发者对功能请求的参与", "tldr": "本研究调查了开源软件中开发者如何澄清模糊或不完整的功能请求，发现明确的澄清并不常见，且侧重于项目目标一致性和用户意图，而非技术细节。", "motivation": "功能请求通常存在歧义或信息不完整，导致误解、错误实现和软件质量下降。目前对于开发者如何实际参与澄清过程知之甚少。", "method": "本研究调查了功能请求如何容易出现自然语言缺陷（即模糊或不完整），以及开源软件（OSS）开发中澄清的对话动态，旨在了解开发者如何处理模糊或不完整的功能请求。", "result": "开源软件平台上的功能请求确实存在歧义和不完整性。为解决这些缺陷而进行的明确澄清并不常见；开发者通常侧重于与项目目标保持一致，而不是解决不清楚的文本。当发生澄清时，它强调理解用户意图/目标和可行性，而不是技术细节。", "conclusion": "通过描述开源问题跟踪器中澄清的动态，这项工作识别出可以改善用户与开发者协作并为有效处理功能请求提供最佳实践的模式。", "translation": "随着用户需求的演变，有效整合功能请求对于保持软件相关性和用户满意度至关重要。功能请求通常以自然语言表达，由于沟通障碍或请求者技术专业知识有限，常常存在歧义或信息不完整。这些问题可能导致误解、错误的实现和软件质量下降。虽然向请求者寻求澄清是减轻这些风险的常见策略，但对于开发者在实践中如何参与这种澄清过程知之甚少——他们如何提出澄清问题、寻求技术或上下文细节、就目标和用例达成一致，或者决定不尝试澄清就关闭请求。本研究调查了功能请求如何容易出现自然语言缺陷（即模糊或不完整），以及开源软件（OSS）开发中澄清的对话动态，旨在了解开发者如何处理模糊或不完整的功能请求。我们的发现表明，在开源软件平台上发布的功能请求确实存在歧义和不完整性，在某些情况下两者兼有。我们还发现，为解决这些缺陷而进行的明确澄清并不常见；开发者通常侧重于与项目目标保持一致，而不是解决不清楚的文本。当发生澄清时，它强调理解用户意图/目标和可行性，而不是技术细节。通过描述开源问题跟踪器中澄清的动态，这项工作识别出可以改善用户与开发者协作并为有效处理功能请求提供最佳实践的模式。", "summary": "本文研究了开源软件项目中开发者如何处理模糊或不完整的功能请求。研究发现此类请求很常见，但明确的澄清却很少发生。当澄清确实发生时，开发者优先考虑与项目目标保持一致以及理解用户意图/可行性，而不是解决文本歧义或技术细节。该研究旨在改善用户与开发者之间的协作，并为有效管理功能请求提供最佳实践。", "keywords": "功能请求, 开源软件, 开发者参与, 澄清, 自然语言缺陷", "comments": "这篇论文为管理开源项目中用户反馈的实际挑战提供了宝贵的见解。其创新之处在于实证研究了经常被忽视的澄清过程，揭示了开发者优先考虑战略一致性而非详细的文本解决方案。这可以为促进更有效沟通的工具和流程提供信息。"}}
{"id": "2505.19688", "title": "GeoPF: Infusing Geometry into Potential Fields for Reactive Planning in Non-trivial Environments", "authors": ["Yuhe Gong", "Riddhiman Laha", "Luis Figueredo"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.19688v2", "summary": "Reactive intelligence remains one of the cornerstones of versatile robotics\noperating in cluttered, dynamic, and human-centred environments. Among reactive\napproaches, potential fields (PF) continue to be widely adopted due to their\nsimplicity and real-time applicability. However, existing PF methods typically\noversimplify environmental representations by relying on isotropic, point- or\nsphere-based obstacle approximations. In human-centred settings, this\nsimplification results in overly conservative paths, cumbersome tuning, and\ncomputational overhead -- even breaking real-time requirements. In response, we\npropose the Geometric Potential Field (GeoPF), a reactive motion-planning\nframework that explicitly infuses geometric primitives -- points, lines,\nplanes, cubes, and cylinders -- their structure and spatial relationship in\nmodulating the real-time repulsive response. Extensive quantitative analyses\nconsistently show GeoPF's higher success rates, reduced tuning complexity (a\nsingle parameter set across experiments), and substantially lower computational\ncosts (up to 2 orders of magnitude) compared to traditional PF methods.\nReal-world experiments further validate GeoPF reliability, robustness, and\npractical ease of deployment, as well as its scalability to whole-body\navoidance. GeoPF provides a fresh perspective on reactive planning problems\ndriving geometric-aware temporal motion generation, enabling flexible and\nlow-latency motion planning suitable for modern robotic applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.19688v2", "cate": "cs.RO", "date": "2025-05-26", "updated": "2025-07-18", "AI": {"title_translation": "GeoPF：在非平凡环境中将几何学融入势场以进行反应式规划", "tldr": "GeoPF通过将几何原语融入势场，显著提高了反应式机器人规划的成功率、降低了计算成本和调优复杂性。", "motivation": "现有势场（PF）方法在处理复杂、动态和以人为中心的环境时，通过过度简化环境表示（依赖各向同性、点或球体障碍物近似）导致路径过于保守、调优繁琐和计算开销大，甚至无法满足实时性要求。", "method": "提出了几何势场（GeoPF），一个反应式运动规划框架，它明确地将几何原语（点、线、平面、立方体和圆柱体）、它们的结构和空间关系融入到实时排斥响应的调节中。", "result": "GeoPF相比传统PF方法，成功率更高，调优复杂度降低（实验中仅需一套参数），计算成本显著降低（高达两个数量级）。实际实验进一步验证了GeoPF的可靠性、鲁棒性、部署便捷性以及其对全身避障的扩展性。", "conclusion": "GeoPF为反应式规划问题提供了新视角，推动了几何感知的时间运动生成，实现了适用于现代机器人应用的灵活低延迟运动规划。", "translation": "反应式智能仍然是多功能机器人在杂乱、动态和以人为中心的环境中运行的基石之一。在反应式方法中，势场（PF）因其简单性和实时适用性而继续被广泛采用。然而，现有的PF方法通常通过依赖各向同性、基于点或球体的障碍物近似来过度简化环境表示。在以人为中心的设置中，这种简化导致路径过于保守、调优繁琐和计算开销大——甚至打破了实时性要求。作为回应，我们提出了几何势场（GeoPF），一个反应式运动规划框架，它明确地将几何原语——点、线、平面、立方体和圆柱体——它们的结构和空间关系融入到实时排斥响应的调节中。大量的定量分析一致表明，与传统PF方法相比，GeoPF的成功率更高，调优复杂性降低（跨实验仅需一套参数），计算成本显著降低（高达两个数量级）。实际实验进一步验证了GeoPF的可靠性、鲁棒性、实际部署便捷性以及其对全身避障的扩展性。GeoPF为反应式规划问题提供了新视角，推动了几何感知的时间运动生成，实现了适用于现代机器人应用的灵活低延迟运动规划。", "summary": "本研究提出了GeoPF，一种将几何原语（如点、线、面、立方体、圆柱体）及其空间关系融入势场（PF）的反应式运动规划框架，以解决传统PF方法在复杂环境中因过度简化障碍物表示而导致的保守路径、调优困难和高计算成本问题。实验结果表明，GeoPF在成功率、调优简易性及计算效率上均显著优于传统方法，并能有效应用于全身避障，为现代机器人提供灵活低延迟的运动规划能力。", "keywords": "势场, 反应式规划, 几何原语, 机器人, 运动规划", "comments": "创新点在于将几何原语而非简单的点/球体近似融入势场，显著提升了其在复杂环境中的适用性、效率和鲁棒性。这解决了传统势场方法长期存在的局限性，使得反应式规划更加实用和高效。"}}
{"id": "2507.13782", "title": "Converting T1-weighted MRI from 3T to 7T quality using deep learning", "authors": ["Malo Gicquel", "Ruoyi Zhao", "Anika Wuestefeld", "Nicola Spotorno", "Olof Strandberg", "Kalle Åström", "Yu Xiao", "Laura EM Wisse", "Danielle van Westen", "Rik Ossenkoppele", "Niklas Mattsson-Carlgren", "David Berron", "Oskar Hansson", "Gabrielle Flood", "Jacob Vogel"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13782v1", "summary": "Ultra-high resolution 7 tesla (7T) magnetic resonance imaging (MRI) provides\ndetailed anatomical views, offering better signal-to-noise ratio, resolution\nand tissue contrast than 3T MRI, though at the cost of accessibility. We\npresent an advanced deep learning model for synthesizing 7T brain MRI from 3T\nbrain MRI. Paired 7T and 3T T1-weighted images were acquired from 172\nparticipants (124 cognitively unimpaired, 48 impaired) from the Swedish\nBioFINDER-2 study. To synthesize 7T MRI from 3T images, we trained two models:\na specialized U-Net, and a U-Net integrated with a generative adversarial\nnetwork (GAN U-Net). Our models outperformed two additional state-of-the-art\n3T-to-7T models in image-based evaluation metrics. Four blinded MRI\nprofessionals judged our synthetic 7T images as comparable in detail to real 7T\nimages, and superior in subjective visual quality to 7T images, apparently due\nto the reduction of artifacts. Importantly, automated segmentations of the\namygdalae of synthetic GAN U-Net 7T images were more similar to manually\nsegmented amygdalae (n=20), than automated segmentations from the 3T images\nthat were used to synthesize the 7T images. Finally, synthetic 7T images showed\nsimilar performance to real 3T images in downstream prediction of cognitive\nstatus using MRI derivatives (n=3,168). In all, we show that synthetic\nT1-weighted brain images approaching 7T quality can be generated from 3T\nimages, which may improve image quality and segmentation, without compromising\nperformance in downstream tasks. Future directions, possible clinical use\ncases, and limitations are discussed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13782v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用深度学习将3T T1加权MRI转换为7T质量", "tldr": "本研究开发并评估了一种深度学习模型，可以将3T脑部MRI图像合成为接近7T质量的图像，提高了图像质量和分割精度，同时不影响下游任务性能。", "motivation": "7T MRI提供比3T MRI更详细的解剖视图、更好的信噪比、分辨率和组织对比度，但其可及性较低。本研究旨在通过深度学习模型从3T MRI合成7T脑部MRI，以克服7T MRI的可及性限制。", "method": "研究使用了来自瑞典BioFINDER-2研究的172名参与者的配对7T和3T T1加权图像。训练了两种深度学习模型：专门的U-Net和集成生成对抗网络（GAN U-Net）的U-Net。模型性能通过图像评估指标和四位盲法MRI专业人员的主观评估进行比较。此外，还评估了合成图像在杏仁核自动分割和下游认知状态预测任务中的表现。", "result": "研究的模型在图像评估指标上优于其他两种最先进的3T到7T模型。盲法MRI专业人员认为合成的7T图像在细节上与真实7T图像相当，在主观视觉质量上甚至优于真实7T图像（可能是由于伪影减少）。合成GAN U-Net 7T图像的杏仁核自动分割结果比用于合成的3T图像更接近手动分割结果。在利用MRI衍生物预测认知状态的下游任务中，合成7T图像表现出与真实3T图像相似的性能。", "conclusion": "研究表明，可以从3T图像生成接近7T质量的合成T1加权脑部图像，这可能在不影响下游任务性能的情况下，提高图像质量和分割效果。", "translation": "超高分辨率7特斯拉（7T）磁共振成像（MRI）提供了详细的解剖视图，与3T MRI相比，具有更好的信噪比、分辨率和组织对比度，但代价是可及性较低。我们提出了一种先进的深度学习模型，用于从3T脑部MRI合成7T脑部MRI。我们从瑞典BioFINDER-2研究的172名参与者（124名认知正常，48名认知受损）那里获取了配对的7T和3T T1加权图像。为了从3T图像合成7T MRI，我们训练了两个模型：一个专门的U-Net，以及一个与生成对抗网络（GAN U-Net）集成的U-Net。我们的模型在基于图像的评估指标上优于另外两种最先进的3T到7T模型。四位盲法MRI专业人员判断我们的合成7T图像在细节上与真实7T图像相当，并且在主观视觉质量上优于真实7T图像，这显然是由于伪影的减少。重要的是，合成GAN U-Net 7T图像的杏仁核自动分割结果（n=20）比用于合成7T图像的3T图像的自动分割结果更接近手动分割的杏仁核。最后，合成7T图像在利用MRI衍生物进行认知状态下游预测（n=3,168）中表现出与真实3T图像相似的性能。总而言之，我们表明可以从3T图像生成接近7T质量的合成T1加权脑部图像，这可能在不影响下游任务性能的情况下提高图像质量和分割效果。论文还讨论了未来的方向、可能的临床应用和局限性。", "summary": "本研究提出了一种深度学习模型，能够将3T T1加权脑部MRI转换为接近7T的图像质量。通过训练U-Net和GAN U-Net模型，研究发现合成的7T图像在客观指标和主观视觉质量上均优于现有方法，且与真实7T图像相当。此外，合成图像显著提高了特定脑区（如杏仁核）的自动分割精度，并在下游认知状态预测任务中保持了与真实3T图像相同的性能。这项工作为在更广泛的临床环境中获得高分辨率MRI数据提供了新的途径。", "keywords": "深度学习, 7T MRI, 图像合成, 3T MRI, GAN U-Net", "comments": "这项研究的创新之处在于利用深度学习，特别是GAN U-Net，有效地将低场强MRI图像提升至高场强MRI的质量水平，从而在不增加硬件成本和可及性限制的情况下，获得高分辨率的解剖细节。其重要性在于，这可能极大地扩展7T MRI在临床和研究中的应用，尤其是在需要精细结构分析的神经科学领域。通过提高图像质量和自动化分割精度，同时不牺牲下游任务性能，该方法具有显著的临床转化潜力。论文提及了未来的方向、可能的临床应用和局限性，显示了研究团队对该技术发展前景的全面思考。"}}
{"id": "2507.13793", "title": "An Enhanced Model-based Approach for Short Text Clustering", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Xuemeng Song", "Tian Gan", "Liqiang Nie"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13793v1", "summary": "Short text clustering has become increasingly important with the popularity\nof social media like Twitter, Google+, and Facebook. Existing methods can be\nbroadly categorized into two paradigms: topic model-based approaches and deep\nrepresentation learning-based approaches. This task is inherently challenging\ndue to the sparse, large-scale, and high-dimensional characteristics of the\nshort text data. Furthermore, the computational intensity required by\nrepresentation learning significantly increases the running time. To address\nthese issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet\nMultinomial Mixture model (GSDMM), which effectively handles the sparsity and\nhigh dimensionality of short texts while identifying representative words for\neach cluster. Based on several aspects of GSDMM that warrant further\nrefinement, we propose an improved approach, GSDMM+, designed to further\noptimize its performance. GSDMM+ reduces initialization noise and adaptively\nadjusts word weights based on entropy, achieving fine-grained clustering that\nreveals more topic-related information. Additionally, strategic cluster merging\nis employed to refine clustering granularity, better aligning the predicted\ndistribution with the true category distribution. We conduct extensive\nexperiments, comparing our methods with both classical and state-of-the-art\napproaches. The experimental results demonstrate the efficiency and\neffectiveness of our methods. The source code for our model is publicly\navailable at https://github.com/chehaoa/VEMC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13793v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "短文本聚类的增强型基于模型的方法", "tldr": "本文提出GSDMM及其改进版GSDMM+，通过优化初始化、自适应词权重和聚类合并来有效处理短文本聚类中的稀疏性和高维性问题，实验证明其高效性与有效性。", "motivation": "随着社交媒体的普及，短文本聚类变得越来越重要。然而，短文本数据稀疏、大规模、高维度，且表示学习计算强度大，给现有方法带来了挑战。", "method": "本文提出了一种用于Dirichlet多项式混合模型的Collapsed Gibbs Sampling算法（GSDMM），以有效处理短文本的稀疏性和高维度，并识别每个聚类的代表词。在此基础上，进一步提出了改进方法GSDMM+，通过减少初始化噪声、基于熵自适应调整词权重以实现细粒度聚类，并采用策略性聚类合并来优化聚类粒度。", "result": "实验结果表明，所提出的方法与经典和最先进的方法相比，具有高效性和有效性。", "conclusion": "本文提出的GSDMM及其增强版GSDMM+能够有效且高效地处理短文本聚类中的挑战，通过优化算法细节，实现了更好的聚类性能和更细粒度的信息揭示。", "translation": "随着Twitter、Google+和Facebook等社交媒体的普及，短文本聚类变得越来越重要。现有方法大致可分为两类：基于主题模型的方法和基于深度表示学习的方法。由于短文本数据稀疏、大规模和高维的特点，这项任务本身就具有挑战性。此外，表示学习所需的计算强度显著增加了运行时间。为了解决这些问题，我们提出了一种用于Dirichlet多项式混合模型的Collapsed Gibbs Sampling算法（GSDMM），它能有效处理短文本的稀疏性和高维度，同时识别每个聚类的代表词。基于GSDMM的几个值得进一步完善的方面，我们提出了一种改进方法GSDMM+，旨在进一步优化其性能。GSDMM+减少了初始化噪声，并基于熵自适应调整词权重，实现了揭示更多主题相关信息的细粒度聚类。此外，采用策略性聚类合并来细化聚类粒度，使预测分布更好地与真实类别分布对齐。我们进行了广泛的实验，将我们的方法与经典和最先进的方法进行了比较。实验结果证明了我们方法的效率和有效性。我们模型的源代码已在https://github.com/chehaoa/VEMC公开。", "summary": "针对短文本聚类中稀疏性、高维度和计算强度大的挑战，本文提出了GSDMM算法及其增强版GSDMM+。GSDMM有效处理短文本特性并识别代表词，而GSDMM+通过减少初始化噪声、自适应词权重和策略性聚类合并进一步优化性能，实现细粒度聚类。实验证明其高效性和有效性。", "keywords": "短文本聚类, GSDMM, GSDMM+, 主题模型, 稀疏性", "comments": "本文在短文本聚类领域提出了一种基于模型的新颖方法GSDMM及其改进版GSDMM+。其创新点在于对GSDMM的细节进行了优化，特别是引入了自适应词权重和策略性聚类合并，以应对短文本数据特有的挑战，并实现了更细粒度的聚类效果。这对于处理社交媒体等平台上的海量短文本数据具有重要意义。"}}
{"id": "2507.12900", "title": "Learning to Reject Low-Quality Explanations via User Feedback", "authors": ["Luca Stradiotti", "Dario Pesenti", "Stefano Teso", "Jesse Davis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12900v2", "summary": "Machine Learning predictors are increasingly being employed in high-stakes\napplications such as credit scoring. Explanations help users unpack the reasons\nbehind their predictions, but are not always \"high quality''. That is,\nend-users may have difficulty interpreting or believing them, which can\ncomplicate trust assessment and downstream decision-making. We argue that\nclassifiers should have the option to refuse handling inputs whose predictions\ncannot be explained properly and introduce a framework for learning to reject\nlow-quality explanations (LtX) in which predictors are equipped with a rejector\nthat evaluates the quality of explanations. In this problem setting, the key\nchallenges are how to properly define and assess explanation quality and how to\ndesign a suitable rejector. Focusing on popular attribution techniques, we\nintroduce ULER (User-centric Low-quality Explanation Rejector), which learns a\nsimple rejector from human ratings and per-feature relevance judgments to\nmirror human judgments of explanation quality. Our experiments show that ULER\noutperforms both state-of-the-art and explanation-aware learning to reject\nstrategies at LtX on eight classification and regression benchmarks and on a\nnew human-annotated dataset, which we will publicly release to support future\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12900v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "通过用户反馈学习拒绝低质量解释", "tldr": "本文提出了一种通过用户反馈学习拒绝低质量解释（LtX）的框架，旨在解决机器学习解释质量不高的问题，并引入了ULER模型，实验证明其性能优于现有方法。", "motivation": "机器学习预测器越来越多地应用于信用评分等高风险应用中。解释有助于用户理解预测背后的原因，但并非总是“高质量”的，即终端用户可能难以理解或信任这些解释，这会影响信任评估和后续决策。因此，分类器应该能够拒绝处理那些无法正确解释其预测的输入。", "method": "本文引入了一个学习拒绝低质量解释（LtX）的框架，其中预测器配备了一个评估解释质量的拒绝器。主要挑战在于如何定义和评估解释质量以及如何设计合适的拒绝器。针对流行的归因技术，本文引入了ULER（User-centric Low-quality Explanation Rejector），它通过人类评分和特征相关性判断来学习一个简单的拒绝器，以反映人类对解释质量的判断。", "result": "实验表明，ULER在八个分类和回归基准测试以及一个新的带有人工标注的数据集上，在LtX方面优于最先进的和解释感知型的学习拒绝策略。该新数据集将公开以支持未来的研究。", "conclusion": "本文成功开发并验证了一种通过用户反馈学习拒绝低质量解释的框架和模型（ULER），有效地解决了机器学习解释质量不高的问题，并提升了模型的可信度和决策支持能力。", "translation": "机器学习预测器越来越多地应用于信用评分等高风险应用中。解释有助于用户理解预测背后的原因，但并非总是“高质量”的。也就是说，终端用户可能难以理解或信任它们，这会使信任评估和后续决策复杂化。我们认为分类器应该有能力拒绝处理那些预测无法得到适当解释的输入，并引入了一个学习拒绝低质量解释（LtX）的框架，其中预测器配备了一个评估解释质量的拒绝器。在这个问题设置中，关键挑战是如何正确定义和评估解释质量以及如何设计一个合适的拒绝器。本文关注流行的归因技术，引入了ULER（User-centric Low-quality Explanation Rejector），它通过人类评分和每个特征的相关性判断来学习一个简单的拒绝器，以反映人类对解释质量的判断。我们的实验表明，ULER在八个分类和回归基准测试以及一个新的带有人工标注的数据集上，在LtX方面优于最先进的和解释感知型的学习拒绝策略，我们将公开该数据集以支持未来的研究。", "summary": "本文提出了一个名为“学习拒绝低质量解释”（LtX）的框架，旨在解决机器学习模型解释质量不高的问题，该问题可能阻碍用户信任和决策。该框架为预测器配备了一个拒绝器，用于评估解释质量。针对这一挑战，本文开发了ULER（User-centric Low-quality Explanation Rejector），它利用用户反馈和特征相关性判断来学习拒绝低质量解释。实验结果表明，ULER在多个基准测试和新的人工标注数据集上，性能优于现有的最先进方法。", "keywords": "机器学习解释, 解释质量, 用户反馈, 拒绝学习, ULER", "comments": "本文的创新点在于提出了一个将用户反馈融入到解释质量评估和拒绝机制中的框架，这对于提升高风险应用中机器学习模型的可信度和实用性至关重要。ULER模型的设计考虑了人类对解释质量的判断，使其更具用户中心性。同时，公开新的人工标注数据集将极大地推动该领域未来的研究。"}}
{"id": "2507.13459", "title": "Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection", "authors": ["Vijay K. Dubey", "Collin E. Haese", "Osman Gültekin", "David Dalton", "Manuel K. Rausch", "Jan N. Fuhg"], "categories": ["cs.CE", "cs.AI", "cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13459v1", "summary": "Surrogate models for the rapid inference of nonlinear boundary value problems\nin mechanics are helpful in a broad range of engineering applications. However,\neffective surrogate modeling of applications involving the contact of\ndeformable bodies, especially in the context of varying geometries, is still an\nopen issue. In particular, existing methods are confined to rigid body contact\nor, at best, contact between rigid and soft objects with well-defined contact\nplanes. Furthermore, they employ contact or collision detection filters that\nserve as a rapid test but use only the necessary and not sufficient conditions\nfor detection. In this work, we present a graph neural network architecture\nthat utilizes continuous collision detection and, for the first time,\nincorporates sufficient conditions designed for contact between soft deformable\nbodies. We test its performance on two benchmarks, including a problem in soft\ntissue mechanics of predicting the closed state of a bioprosthetic aortic\nvalve. We find a regularizing effect on adding additional contact terms to the\nloss function, leading to better generalization of the network. These benefits\nhold for simple contact at similar planes and element normal angles, and\ncomplex contact at differing planes and element normal angles. We also\ndemonstrate that the framework can handle varying reference geometries.\nHowever, such benefits come with high computational costs during training,\nresulting in a trade-off that may not always be favorable. We quantify the\ntraining cost and the resulting inference speedups on various hardware\narchitectures. Importantly, our graph neural network implementation results in\nup to a thousand-fold speedup for our benchmark problems at inference.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13459v1", "cate": "cs.CE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于接触可变形体的图神经网络代理模型，具有必要和充分的接触检测", "tldr": "本文提出了一种图神经网络架构，首次将充分条件引入软可变形体接触检测，实现了对非线性边界值问题的快速推理，并在推理速度上实现了显著提升，但训练成本较高。", "motivation": "现有的力学非线性边界值问题代理模型在处理可变形体接触，尤其是在几何形状变化的情况下，仍存在开放性问题。现有方法局限于刚体接触或刚体与软体之间的接触，且接触/碰撞检测滤波器仅使用必要条件而非充分条件。", "method": "本文提出了一种图神经网络架构，利用连续碰撞检测，并首次引入了针对软可变形体接触设计的充分条件。该模型通过在损失函数中添加额外的接触项来实现正则化，并能处理不同的参考几何形状。", "result": "该模型在两个基准测试（包括生物人工主动脉瓣的闭合状态预测）中表现良好，添加额外的接触项对损失函数有正则化作用，从而提高了网络的泛化能力。该框架能够处理不同的参考几何形状。在推理时，基准问题的速度提升高达千倍。然而，训练计算成本高。", "conclusion": "本文提出的图神经网络代理模型成功地解决了可变形体接触检测中的挑战，通过引入充分条件和连续碰撞检测，实现了显著的推理速度提升，但训练成本较高，存在权衡。", "translation": "力学中用于快速推断非线性边界值问题的代理模型在广泛的工程应用中都很有帮助。然而，对涉及可变形体接触的应用进行有效的代理建模，特别是在几何形状变化的情况下，仍然是一个开放性问题。具体而言，现有方法仅限于刚体接触，或者至多是刚体与具有明确接触平面的软体之间的接触。此外，它们采用的接触或碰撞检测滤波器仅作为快速测试，但只使用检测的必要条件而非充分条件。在这项工作中，我们提出了一种图神经网络架构，该架构利用连续碰撞检测，并首次包含了为软可变形体接触设计的充分条件。我们在两个基准测试中测试了其性能，其中包括预测生物人工主动脉瓣闭合状态的软组织力学问题。我们发现，在损失函数中添加额外的接触项具有正则化作用，从而使网络具有更好的泛化能力。这些优点适用于相似平面和单元法线角度的简单接触，以及不同平面和单元法线角度的复杂接触。我们还证明了该框架可以处理不同的参考几何形状。然而，这些优点伴随着高昂的训练计算成本，导致可能并不总是有利的权衡。我们量化了在各种硬件架构上的训练成本和由此产生的推理加速。重要的是，我们的图神经网络实现使得我们的基准问题在推理时实现了高达千倍的速度提升。", "summary": "本文提出了一种新颖的图神经网络代理模型，用于解决可变形体接触的非线性边界值问题。该模型首次将连续碰撞检测和针对软可变形体的充分接触条件相结合，克服了现有方法仅限于刚体接触或缺乏充分条件检测的局限性。通过在损失函数中加入额外接触项，模型展现出更好的泛化能力，并能处理变化的几何形状。尽管训练成本较高，但该方法在推理速度上实现了显著的千倍提升，为复杂的接触力学问题提供了高效的解决方案。", "keywords": "图神经网络, 可变形体接触, 代理模型, 接触检测, 连续碰撞检测", "comments": "本文的主要创新点在于首次将充分条件引入到基于图神经网络的可变形体接触检测中，并结合了连续碰撞检测，从而提高了模型的准确性和泛化能力。该研究解决了现有代理模型在处理复杂可变形体接触方面的局限性，尤其是在几何形状多变的应用场景。虽然训练成本是一个限制，但其在推理速度上的巨大提升（高达千倍）凸显了其在实际工程应用中的巨大潜力，例如在医疗器械模拟等领域。"}}
{"id": "2507.14043", "title": "A multi-strategy improved snake optimizer for three-dimensional UAV path planning and engineering problems", "authors": ["Genliang Li", "Yaxin Cui", "Jinyu Su"], "categories": ["cs.RO", "cs.AI", "cs.CE"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      59 pages, 22 figures", "url": "http://arxiv.org/abs/2507.14043v1", "summary": "Metaheuristic algorithms have gained widespread application across various\nfields owing to their ability to generate diverse solutions. One such algorithm\nis the Snake Optimizer (SO), a progressive optimization approach. However, SO\nsuffers from the issues of slow convergence speed and susceptibility to local\noptima. In light of these shortcomings, we propose a novel Multi-strategy\nImproved Snake Optimizer (MISO). Firstly, we propose a new adaptive random\ndisturbance strategy based on sine function to alleviate the risk of getting\ntrapped in a local optimum. Secondly, we introduce adaptive Levy flight\nstrategy based on scale factor and leader and endow the male snake leader with\nflight capability, which makes it easier for the algorithm to leap out of the\nlocal optimum and find the global optimum. More importantly, we put forward a\nposition update strategy combining elite leadership and Brownian motion,\neffectively accelerating the convergence speed while ensuring precision.\nFinally, to demonstrate the performance of MISO, we utilize 30 CEC2017 test\nfunctions and the CEC2022 test suite, comparing it with 11 popular algorithms\nacross different dimensions to validate its effectiveness. Moreover, Unmanned\nAerial Vehicle (UAV) has been widely used in various fields due to its\nadvantages of low cost, high mobility and easy operation. However, the UAV path\nplanning problem is crucial for flight safety and efficiency, and there are\nstill challenges in establishing and optimizing the path model. Therefore, we\napply MISO to the UAV 3D path planning problem as well as 6 engineering design\nproblems to assess its feasibility in practical applications. The experimental\nresults demonstrate that MISO exceeds other competitive algorithms in terms of\nsolution quality and stability, establishing its strong potential for\napplication.", "comment": "59 pages, 22 figures", "pdf_url": "http://arxiv.org/pdf/2507.14043v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "一种多策略改进的蛇群优化器用于三维无人机路径规划和工程问题", "tldr": "本文提出了一种多策略改进的蛇群优化器（MISO），旨在解决原始蛇群优化器收敛速度慢和易陷入局部最优的问题，并将其应用于三维无人机路径规划和工程设计问题，实验结果显示其性能优于其他算法。", "motivation": "蛇群优化器（SO）存在收敛速度慢和容易陷入局部最优的问题。同时，无人机路径规划在建立和优化路径模型方面也面临挑战。", "method": "本文提出了一种多策略改进蛇群优化器（MISO）。该算法首先引入了基于正弦函数的自适应随机扰动策略以避免局部最优；其次，引入了基于比例因子和领导者的自适应Levy飞行策略，并赋予雄性蛇领导者飞行能力，以帮助算法跳出局部最优并找到全局最优；更重要的是，提出了一种结合精英领导和布朗运动的位置更新策略，以加速收敛速度并保证精度。为验证MISO的性能，将其应用于30个CEC2017测试函数和CEC2022测试套件，并与11种流行算法进行比较，同时应用于无人机三维路径规划问题和6个工程设计问题。", "result": "MISO在解决方案质量和稳定性方面均优于其他竞争算法，并在无人机三维路径规划和工程设计问题中展现出实际应用的可行性。", "conclusion": "MISO在解决方案质量和稳定性方面表现出色，具有强大的应用潜力。", "translation": "元启发式算法因其生成多样化解决方案的能力而在各个领域获得了广泛应用。蛇群优化器（SO）就是其中一种渐进式优化方法。然而，SO存在收敛速度慢和容易陷入局部最优的问题。鉴于这些缺点，我们提出了一种新颖的多策略改进蛇群优化器（MISO）。首先，我们提出了一种基于正弦函数的新型自适应随机扰动策略，以减轻陷入局部最优的风险。其次，我们引入了基于比例因子和领导者的自适应Levy飞行策略，并赋予雄性蛇领导者飞行能力，这使得算法更容易跳出局部最优并找到全局最优。更重要的是，我们提出了一种结合精英领导和布朗运动的位置更新策略，在保证精度的同时有效加快收敛速度。最后，为了证明MISO的性能，我们利用30个CEC2017测试函数和CEC2022测试套件，并将其与11种流行算法在不同维度上进行比较，以验证其有效性。此外，无人机（UAV）因其低成本、高机动性和易于操作等优点已广泛应用于各个领域。然而，无人机路径规划问题对于飞行安全和效率至关重要，并且在建立和优化路径模型方面仍存在挑战。因此，我们将MISO应用于无人机三维路径规划问题以及6个工程设计问题，以评估其在实际应用中的可行性。实验结果表明，MISO在解决方案质量和稳定性方面均优于其他竞争算法，确立了其强大的应用潜力。", "summary": "本文提出了一种多策略改进蛇群优化器（MISO），以解决原始蛇群优化器（SO）收敛慢和易陷入局部最优的问题。MISO集成了基于正弦函数的自适应随机扰动策略、基于比例因子和领导者的自适应Levy飞行策略以及结合精英领导和布朗运动的位置更新策略。通过在标准测试函数和实际应用（如三维无人机路径规划和工程设计问题）上的广泛评估，MISO在解决方案质量和稳定性方面均表现出优于现有算法的性能，验证了其在实际应用中的潜力。", "keywords": "蛇群优化器, 元启发式算法, 无人机路径规划, 多策略, 优化", "comments": "该论文通过引入多种策略对蛇群优化器进行了改进，这是元启发式算法研究中提升性能的常见方法。所提出的具体策略（自适应随机扰动、Levy飞行、精英领导与布朗运动结合）似乎能有效解决局部最优和收敛速度慢的问题。将其应用于三维无人机路径规划和工程问题增加了实际相关性，展示了算法的实用性。与11种流行算法在两个CEC测试套件上的广泛比较提供了有力的验证。"}}
{"id": "2507.13966", "title": "Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need", "authors": ["Bhishma Dedhia", "Yuval Kansal", "Niraj K. Jha"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13966v1", "summary": "Language models traditionally used for cross-domain generalization have\nrecently demonstrated task-specific reasoning. However, their top-down training\napproach on general corpora is insufficient for acquiring abstractions needed\nfor deep domain expertise. This may require a bottom-up approach that acquires\nexpertise by learning to compose simple domain concepts into more complex ones.\nA knowledge graph (KG) provides this compositional structure, where domain\nprimitives are represented as head-relation-tail edges and their paths encode\nhigher-level concepts. We present a task generation pipeline that synthesizes\ntasks directly from KG primitives, enabling models to acquire and compose them\nfor reasoning. We fine-tune language models on the resultant KG-grounded\ncurriculum to demonstrate domain-specific superintelligence. While broadly\napplicable, we validate our approach in medicine, where reliable KGs exist.\nUsing a medical KG, we curate 24,000 reasoning tasks paired with thinking\ntraces derived from diverse medical primitives. We fine-tune the QwQ-32B model\non this curriculum to obtain QwQ-Med-3 that takes a step towards medical\nsuperintelligence. We also introduce ICD-Bench, an evaluation suite to quantify\nreasoning abilities across 15 medical domains. Our experiments demonstrate that\nQwQ-Med-3 significantly outperforms state-of-the-art reasoning models on\nICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired\nprimitives to widen the performance gap on the hardest tasks of ICD-Bench.\nFinally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3\ntransfers acquired expertise to enhance the base model's performance. While the\nindustry's approach to artificial general intelligence (AGI) emphasizes broad\nexpertise, we envision a future in which AGI emerges from the composable\ninteraction of efficient domain-specific superintelligent agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13966v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "自下而上的领域特定超智能：我们需要一个可靠的知识图谱", "tldr": "现有语言模型难以获得深度领域专业知识，本文提出一种利用知识图谱的自下而上方法来训练领域特定超智能，并在医学领域验证了其显著的性能提升。", "motivation": "传统语言模型自上而下的通用语料库训练方法不足以获取深度领域专业知识以进行任务特定推理。需要一种自下而上的方法。", "method": "提出一种利用知识图谱（KG）的自下而上方法，通过组合简单领域概念来获取专业知识。知识图谱将领域原语表示为头-关系-尾边，其路径编码更高级别的概念。提出一个任务生成管道，直接从KG原语合成任务，使模型能够获取并组合它们进行推理。在生成的基于KG的课程上微调语言模型（具体是QwQ-32B），以展示领域特定超智能。在医学领域进行了验证，使用医学KG整理了24,000个带有思维轨迹的推理任务。引入ICD-Bench，一个评估套件来量化15个医学领域的推理能力。", "result": "QwQ-Med-3（微调后的QwQ-32B）在医学超智能方面迈出了一步。QwQ-Med-3在ICD-Bench类别上显著优于最先进的推理模型。QwQ-Med-3利用习得的原语扩大了ICD-Bench最难任务的性能差距。在医学问答基准上的评估表明，QwQ-Med-3能够转移所获得的专业知识，以增强基础模型的性能。", "conclusion": "尽管业界专注于通过广泛专业知识实现通用人工智能（AGI），但作者设想AGI将从高效领域特定超智能代理的可组合交互中出现。这项工作通过知识图谱展示了实现领域特定超智能的途径。", "translation": "传统上用于跨领域泛化的语言模型最近展示了任务特定推理能力。然而，它们在通用语料库上自上而下的训练方法不足以获取深度领域专业知识所需的抽象能力。这可能需要一种自下而上的方法，通过学习将简单的领域概念组合成更复杂的概念来获取专业知识。知识图谱（KG）提供了这种组合结构，其中领域原语表示为头-关系-尾边，它们的路径编码更高级别的概念。我们提出一个任务生成管道，直接从KG原语合成任务，使模型能够获取并组合它们进行推理。我们根据由此产生的基于KG的课程对语言模型进行微调，以展示领域特定超智能。虽然我们的方法具有广泛适用性，但我们在存在可靠KG的医学领域验证了它。使用医学KG，我们整理了24,000个推理任务，并配有从各种医学原语中导出的思维轨迹。我们在此课程上微调了QwQ-32B模型，获得了QwQ-Med-3，这向医学超智能迈进了一步。我们还引入了ICD-Bench，一个评估套件，用于量化15个医学领域的推理能力。我们的实验表明，QwQ-Med-3在ICD-Bench类别上显著优于最先进的推理模型。进一步分析表明，QwQ-Med-3利用习得的原语扩大了ICD-Bench最难任务的性能差距。最后，对医学问答基准的评估表明，QwQ-Med-3能够转移所获得的专业知识，以增强基础模型的性能。尽管业界对通用人工智能（AGI）的方法强调广泛的专业知识，但我们设想AGI将从高效领域特定超智能代理的可组合交互中出现。", "summary": "本文提出了一种自下而上的方法，通过利用可靠的知识图谱（KG）来实现领域特定超智能。与传统的自上而下语言模型训练不同，该方法直接从KG原语合成推理任务，使模型能够通过组合更简单的概念来学习复杂概念。该方法在医学领域得到验证，作者在一个基于医学KG的课程上微调了QwQ-32B模型，得到了QwQ-Med-3。该模型在新的医学推理基准（ICD-Bench）上显著优于最先进的模型，并将专业知识转移以增强基础模型的性能，这表明通过交互式领域特定代理实现AGI的途径。", "keywords": "知识图谱, 领域特定超智能, 语言模型, 自下而上学习, 医学人工智能", "comments": "这篇论文为实现AI专业知识提供了一个创新视角，从广泛的泛化转向深入的领域特定知识。利用知识图谱进行组合学习的自下而上方法是解决当前大型语言模型在获取真正领域专业知识方面局限性的一种新颖方式。任务生成管道和专用医学评估基准（ICD-Bench）的创建是重要的贡献。关于AGI将从领域特定代理的交互中出现的愿景，是当前行业焦点之外一个发人深省的替代方案。"}}
{"id": "2505.12699", "title": "More Efforts Towards Fixed-Parameter Approximability of Multiwinner Rules", "authors": ["Sushmita Gupta", "Pallavi Jain", "Souvik Saha", "Saket Saurabh", "Anannya Upasana"], "categories": ["cs.GT", "cs.DS"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "Comments:      To appear in the Proceedings of the 34th International Joint Conference on Artificial Intelligence (IJCAI 2025)", "url": "http://arxiv.org/abs/2505.12699v2", "summary": "Multiwinner Elections have emerged as a prominent area of research with\nnumerous practical applications. We contribute to this area by designing\nparameterized approximation algorithms and also resolving an open question by\nYang and Wang [AAMAS'18]. More formally, given a set of candidates,\n\\mathcal{C}, a set of voters,\\mathcal{V}, approving a subset of candidates\n(called approval set of a voter), and an integer $k$, we consider the problem\nof selecting a ``good'' committee using Thiele rules. This problem is\ncomputationally challenging for most Thiele rules with monotone submodular\nsatisfaction functions, as there is no (1-\\frac{1}{e}-\\epsilon)\\footnote{Here,\n$e$ denotes the base of the natural logarithm.}-approximation algorithm in\nf(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)} time for any fixed $\\epsilon > 0$\nand any computable function $f$, and no {\\sf PTAS} even when the length of\napproval set is two. Skowron [WINE'16] designed an approximation scheme running\nin FPT time parameterized by the combined parameter, size of the approval set\nand $k$. In this paper, we consider a parameter $d+k$ (no $d$ voters approve\nthe same set of $d$ candidates), where $d$ is upper bounded by the size of the\napproval set (thus, can be much smaller).\n  With respect to this parameter, we design parameterized approximation\nschemes, a lossy polynomial-time preprocessing method, and show that an extra\ncommittee member suffices to achieve the desired score (i.e., $1$-additive\napproximation). Additionally, we resolve an open question by Yang and\nWang~[AAMAS'18] regarding the fixed-parameter tractability of the problem under\nthe PAV rule with the total score as the parameter, demonstrating that it\nadmits an FPT algorithm.", "comment": "To appear in the Proceedings of the 34th International Joint\n  Conference on Artificial Intelligence (IJCAI 2025)", "pdf_url": "http://arxiv.org/pdf/2505.12699v2", "cate": "cs.GT", "date": "2025-05-19", "updated": "2025-07-18", "AI": {"title_translation": "多赢规则的固定参数可近似性研究的更多努力", "tldr": "本文针对多赢选举中的Thiele规则，设计了新的参数化近似算法，并解决了一个关于PAV规则的开放问题，证明其存在FPT算法。", "motivation": "多赢选举在实践中应用广泛，但使用Thiele规则选择“好”委员会的计算问题具有挑战性，缺乏有效的近似算法，且难以获得好的近似比。", "method": "引入了新的参数 d+k；设计了基于此参数的参数化近似方案；提出了一种有损多项式时间预处理方法；解决了Yang和Wang关于PAV规则固定参数可处理性的开放问题。", "result": "在参数 d+k 下，设计了参数化近似方案和有损多项式时间预处理方法，并证明了通过增加一名委员会成员足以达到期望分数（1-加性近似）。解决了Yang和Wang的开放问题，证明了在总分数作为参数的PAV规则下，问题存在FPT算法。", "conclusion": "Not mentioned in abstract", "translation": "多赢选举已成为一个研究热点领域，具有广泛的实际应用。我们通过设计参数化近似算法并解决Yang和Wang [AAMAS'18]提出的一个开放问题，为该领域做出了贡献。更正式地说，给定一组候选人 $\\mathcal{C}$，一组选民 $\\mathcal{V}$，他们批准候选人的一个子集（称为选民的批准集），以及一个整数 $k$，我们考虑使用Thiele规则选择一个“好”委员会的问题。对于大多数具有单调次模满意度函数的Thiele规则，这个问题在计算上具有挑战性，因为在任何固定的 $\\epsilon > 0$ 和任何可计算函数 $f$ 的情况下，都没有在 $f(k)(|\\mathcal{C}| + |\\mathcal{V}|)^{o(k)}$ 时间内运行的 $(1-\\frac{1}{e}-\\epsilon)$-近似算法，即使批准集长度为二，也没有PTAS。Skowron [WINE'16] 设计了一种近似方案，其运行时间由组合参数（批准集大小和 $k$）参数化为FPT时间。在本文中，我们考虑参数 $d+k$（没有 $d$ 个选民批准相同的 $d$ 个候选人），其中 $d$ 的上限是批准集的大小（因此，可以小得多）。 关于此参数，我们设计了参数化近似方案、一种有损多项式时间预处理方法，并表明增加一名委员会成员足以达到期望分数（即1-加性近似）。此外，我们解决了Yang和Wang [AAMAS'18]提出的关于PAV规则在总分数作为参数时固定参数可处理性的开放问题，证明它允许FPT算法。", "summary": "本文研究了多赢选举中Thiele规则下的委员会选择问题，该问题在计算上具有挑战性。作者引入了一个新的参数 d+k，并在此参数下设计了参数化近似方案和有损多项式时间预处理方法，实现了1-加性近似。此外，论文解决了一个关于PAV规则固定参数可处理性的开放问题，证明了该问题存在FPT算法。", "keywords": "多赢选举, Thiele规则, 参数化近似, FPT, PAV规则", "comments": "本文通过引入新的参数 d+k 并设计相应的参数化近似算法，在解决多赢选举中的计算难题方面取得了进展。特别值得注意的是，它解决了一个长期存在的开放问题，这表明了其理论贡献。"}}
{"id": "2507.12931", "title": "Improving DAPO from a Mixed-Policy Perspective", "authors": ["Hongze Tan"], "categories": ["cs.LG", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12931v2", "summary": "This paper introduces two novel modifications to the Dynamic sAmpling Policy\nOptimization (DAPO) algorithm [1], approached from a mixed-policy perspective.\nStandard policy gradient methods can suffer from instability and sample\ninefficiency, particularly in sparse reward settings. To address this, we first\npropose a method that incorporates a pre-trained, stable guiding policy\n($\\piphi$) to provide off-policy experience, thereby regularizing the training\nof the target policy ($\\pion$). This approach improves training stability and\nconvergence speed by adaptively adjusting the learning step size. Secondly, we\nextend this idea to re-utilize zero-reward samples, which are often discarded\nby dynamic sampling strategies like DAPO's. By treating these samples as a\ndistinct batch guided by the expert policy, we further enhance sample\nefficiency. We provide a theoretical analysis for both methods, demonstrating\nthat their objective functions converge to the optimal solution within the\nestablished theoretical framework of reinforcement learning. The proposed\nmixed-policy framework effectively balances exploration and exploitation,\npromising more stable and efficient policy optimization.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12931v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "从混合策略角度改进DAPO", "tldr": "本文从混合策略角度对DAPO算法进行了两项新颖的改进，通过引入预训练的引导策略和重新利用零奖励样本，提高了训练稳定性、收敛速度和样本效率，并提供了理论分析。", "motivation": "标准的策略梯度方法在稀疏奖励设置下可能存在不稳定和样本效率低的问题。动态采样策略优化（DAPO）算法也面临样本效率的挑战，特别是对零奖励样本的处理。", "method": "本文引入了两项对DAPO算法的修改：1. 结合预训练的稳定引导策略（$\\piphi$）来提供离策略经验，从而正则化目标策略（$\\pion$）的训练，通过自适应调整学习步长来提高训练稳定性和收敛速度。2. 扩展此想法，重新利用动态采样策略（如DAPO）通常会丢弃的零奖励样本，将其视为由专家策略引导的独立批次，进一步提高样本效率。", "result": "两种方法都进行了理论分析，证明其目标函数在强化学习的既定理论框架内收敛到最优解。提出的混合策略框架有效平衡了探索和利用。", "conclusion": "本文提出的混合策略框架有效平衡了探索和利用，有望实现更稳定和高效的策略优化。", "translation": "本文从混合策略角度对动态采样策略优化（DAPO）算法[1]引入了两项新颖的修改。标准的策略梯度方法可能存在不稳定和样本效率低的问题，尤其是在稀疏奖励设置下。为了解决这个问题，我们首先提出了一种方法，该方法结合了预训练的稳定引导策略（$\\piphi$）来提供离策略经验，从而正则化目标策略（$\\pion$）的训练。这种方法通过自适应调整学习步长来提高训练稳定性和收敛速度。其次，我们扩展了这一思想，重新利用动态采样策略（如DAPO）通常会丢弃的零奖励样本。通过将这些样本视为由专家策略引导的独立批次，我们进一步提高了样本效率。我们为这两种方法提供了理论分析，证明它们的目标函数在强化学习的既定理论框架内收敛到最优解。所提出的混合策略框架有效地平衡了探索和利用，有望实现更稳定和高效的策略优化。", "summary": "本文从混合策略视角出发，对动态采样策略优化（DAPO）算法提出了两项创新性改进。针对标准策略梯度方法的不稳定性和样本效率问题，特别是稀疏奖励场景，研究提出引入预训练的稳定引导策略来正则化目标策略训练，并通过自适应学习步长提升稳定性与收敛速度。此外，还创新性地重新利用DAPO通常丢弃的零奖励样本，进一步提高样本效率。研究提供了理论分析，证明了所提方法的目标函数能收敛到最优解。该混合策略框架旨在平衡探索与利用，实现更稳定高效的策略优化。", "keywords": "DAPO, 强化学习, 策略优化, 混合策略, 样本效率", "comments": "该论文通过引入混合策略视角，对DAPO算法进行了有意义的改进。其创新点在于结合了预训练的引导策略来提高训练稳定性，并巧妙地重新利用了通常被丢弃的零奖励样本，显著提升了样本效率。这对于解决强化学习中稀疏奖励和样本效率低下的常见挑战具有重要意义。"}}
{"id": "2507.13958", "title": "Towards Constraint Temporal Answer Set Programming", "authors": ["Pedro Cabalar", "Martín Diéguez", "François Olivier", "Torsten Schaub", "Igor Stéphan"], "categories": ["cs.AI", "cs.LO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13958v1", "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13958v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "走向约束时间答案集编程", "tldr": "本文提出了一种新的、基于时间和约束的答案集编程（ASP）扩展，旨在解决动态系统精细时间与数值推理的挑战。", "motivation": "基于逻辑的方法（如答案集编程ASP）在对具有细粒度时间和数值分辨率的动态系统进行推理时面临重大挑战。", "method": "作者介绍了一种新颖的、基于时间和约束的Here-and-There逻辑及其非单调均衡扩展。该方法通过协同组合两种基础ASP扩展实现：提供强大非单调时间推理能力的线性时间Here-and-There逻辑，以及能够直接集成和操作数值约束的带约束的Here-and-There逻辑。", "result": "这项工作建立了处理ASP范式内高分辨率复杂动态系统的基础逻辑框架，并且是首个专门为ASP量身定制的、结合约束的非单调时间推理方法。", "conclusion": "这项工作为在ASP范式内处理具有高分辨率的复杂动态系统提供了一个基础的逻辑框架，解决了先前在时间推理和数值约束方面的限制。", "translation": "对具有细粒度时间和数值分辨率的动态系统进行推理，对答案集编程（ASP）等基于逻辑的方法提出了重大挑战。为了解决这个问题，我们介绍并阐述了一种新的、基于时间和约束的Here-and-There逻辑及其非单调均衡扩展，据我们所知，这是首个专门为ASP量身定制的、结合约束的非单调时间推理方法。这个富有表现力的系统是通过两种基础ASP扩展的协同组合实现的：提供强大非单调时间推理能力的线性时间Here-and-There逻辑，以及能够直接集成和操作数值约束的带约束的Here-and-There逻辑。这项工作为在ASP范式内解决高分辨率复杂动态系统奠定了基础逻辑框架。", "summary": "本文提出了一种名为“约束时间答案集编程”的新型答案集编程（ASP）扩展，旨在克服ASP在处理具有细粒度时间和数值分辨率的动态系统推理时的挑战。该方法通过结合线性时间Here-and-There逻辑和带约束的Here-and-There逻辑，创建了首个专门为ASP设计的、集成了约束的非单调时间推理方法。这项工作为在ASP范式内对复杂动态系统进行高分辨率推理奠定了基础逻辑框架。", "keywords": "答案集编程, 时间推理, 约束, 动态系统, Here-and-There逻辑", "comments": "该论文通过将时间推理和数值约束集成到答案集编程中，提出了显著的创新，解决了ASP在处理细粒度动态系统方面的已知局限性。其新颖之处在于协同组合了两种基础ASP扩展，这可能为复杂系统建模和分析开辟新途径。"}}
{"id": "2507.13741", "title": "SamGoG: A Sampling-Based Graph-of-Graphs Framework for Imbalanced Graph Classification", "authors": ["Shangyou Wang", "Zezhong Ding", "Xike Xie"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13741v1", "summary": "Graph Neural Networks (GNNs) have shown remarkable success in graph\nclassification tasks by capturing both structural and feature-based\nrepresentations. However, real-world graphs often exhibit two critical forms of\nimbalance: class imbalance and graph size imbalance. These imbalances can bias\nthe learning process and degrade model performance. Existing methods typically\naddress only one type of imbalance or incur high computational costs. In this\nwork, we propose SamGoG, a sampling-based Graph-of-Graphs (GoG) learning\nframework that effectively mitigates both class and graph size imbalance.\nSamGoG constructs multiple GoGs through an efficient importance-based sampling\nmechanism and trains on them sequentially. This sampling mechanism incorporates\nthe learnable pairwise similarity and adaptive GoG node degree to enhance edge\nhomophily, thus improving downstream model quality. SamGoG can seamlessly\nintegrate with various downstream GNNs, enabling their efficient adaptation for\ngraph classification tasks. Extensive experiments on benchmark datasets\ndemonstrate that SamGoG achieves state-of-the-art performance with up to a\n15.66% accuracy improvement with 6.7$\\times$ training acceleration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13741v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "SamGoG：一种基于采样的图-图框架，用于不平衡图分类", "tldr": "SamGoG是一个基于采样的图-图（GoG）学习框架，旨在有效解决图分类任务中存在的类别不平衡和图大小不平衡问题，并显著提升性能和训练效率。", "motivation": "图神经网络（GNNs）在图分类任务中表现出色，但现实世界的图常存在类别不平衡和图大小不平衡两种关键形式，这会偏置学习过程并降低模型性能。现有方法通常只解决一种不平衡或计算成本高昂。", "method": "本文提出了SamGoG，一个基于采样的图-图（GoG）学习框架。SamGoG通过高效的基于重要性的采样机制构建多个GoG，并依次在它们上进行训练。该采样机制结合可学习的成对相似性和自适应GoG节点度来增强边缘同质性，从而提高下游模型质量。SamGoG可以无缝集成到各种下游GNNs中。", "result": "在基准数据集上的大量实验表明，SamGoG实现了最先进的性能，准确率提高了高达15.66%，训练速度加快了6.7倍。", "conclusion": "SamGoG框架通过其独特的采样机制和图-图构建方法，成功地解决了图分类中存在的类别和图大小不平衡问题，显著提升了模型性能和训练效率，并能与现有GNNs良好集成。", "translation": "图神经网络（GNNs）通过捕获结构和基于特征的表示，在图分类任务中取得了显著成功。然而，现实世界中的图通常表现出两种关键形式的不平衡：类别不平衡和图大小不平衡。这些不平衡会偏置学习过程并降低模型性能。现有方法通常只解决一种不平衡或产生高计算成本。在这项工作中，我们提出了SamGoG，一个基于采样的图-图（GoG）学习框架，它能有效缓解类别不平衡和图大小不平衡。SamGoG通过高效的基于重要性的采样机制构建多个GoG，并依次在它们上进行训练。这种采样机制结合了可学习的成对相似性和自适应GoG节点度，以增强边缘同质性，从而提高下游模型质量。SamGoG可以无缝集成到各种下游GNNs中，从而使它们能够高效地适应图分类任务。在基准数据集上的大量实验表明，SamGoG实现了最先进的性能，准确率提高了高达15.66%，训练速度加快了6.7倍。", "summary": "SamGoG是一个创新的基于采样的图-图（GoG）框架，旨在解决图分类中常见的类别和图大小不平衡问题。它通过构建多个GoG并利用高效的基于重要性的采样机制（结合可学习的成对相似性和自适应GoG节点度）来增强边缘同质性。该框架可与现有GNNs无缝集成，并在实验中展现出显著的性能提升和训练加速，达到最先进水平。", "keywords": "图分类, 图神经网络, 不平衡数据, 采样, 图-图", "comments": "SamGoG的创新之处在于其结合了图-图框架与重要性采样机制，以同时解决类别和图大小不平衡问题，这是现有方法常常无法兼顾的。其提出的采样机制通过增强边缘同质性来提高模型质量，并且能够与多种GNNs无缝集成，显示出良好的通用性。性能上的显著提升和训练加速证明了其重要性和实用性。"}}
{"id": "2507.13390", "title": "PARAM-1 BharatGen 2.9B Model", "authors": ["Kundeshwar Pundalik", "Piyush Sawarkar", "Nihar Sahoo", "Abhishek Shinde", "Prateek Chanda", "Vedant Goswami", "Ajay Nagpal", "Atul Singh", "Viraj Thakur", "Vijay Dewane", "Aamod Thakur", "Bhargav Patel", "Smita Gautam", "Bhagwan Panditi", "Shyam Pawar", "Madhav Kotcha", "Suraj Racha", "Saral Sureka", "Pankaj Singh", "Rishi Bal", "Rohit Saluja", "Ganesh Ramakrishnan"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13390v1", "summary": "Large Language Models (LLMs) have emerged as powerful general-purpose\nreasoning systems, yet their development remains dominated by English-centric\ndata, architectures, and optimization paradigms. This exclusionary design\nresults in structural under-representation of linguistically diverse regions\nsuch as India, where over 20 official languages and 100+ dialects coexist\nalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a\n2.9B parameter decoder-only, text-only language model trained from scratch with\nan explicit architectural and linguistic focus on Indian diversity. PARAM-1 is\ntrained on a bilingual dataset consisting of only Hindi and English,\nconstructed with a strong focus on fact-rich, high-quality content. It is\nguided by three core principles: equitable representation of Indic languages\nthrough a 25% corpus allocation; tokenization fairness via a SentencePiece\ntokenizer adapted to Indian morphological structures; and culturally aligned\nevaluation benchmarks across IndicQA, code-mixed reasoning, and\nsocio-linguistic robustness tasks. By embedding diversity at the pretraining\nlevel-rather than deferring it to post-hoc alignment-PARAM-1 offers a\ndesign-first blueprint for equitable foundation modeling. Our results\ndemonstrate that it serves as both a competent general-purpose model and a\nrobust baseline for India-centric applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13390v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "PARAM-1 BharatGen 2.9B 模型", "tldr": "PARAM-1 是一个专注于印度语言多样性、从头训练的双语大型语言模型。", "motivation": "现有的大型语言模型（LLMs）以英语为中心，导致印度等语言多样性丰富的地区在数据、架构和优化范式方面存在结构性代表不足，无法有效处理多语言共存、语码转换和双语现象。", "method": "PARAM-1是一个2.9亿参数的仅解码器、仅文本语言模型，从头开始训练。它使用一个仅包含印地语和英语的双语数据集，该数据集注重事实丰富和高质量内容。其开发遵循三个核心原则：通过25%的语料分配实现印度语言的公平代表；通过适应印度形态结构的SentencePiece分词器实现分词公平性；以及在IndicQA、语码混合推理和社会语言鲁棒性任务中进行文化对齐的评估。", "result": "PARAM-1既是一个称职的通用模型，也是印度中心应用的稳健基线。", "conclusion": "PARAM-1通过在预训练层面嵌入多样性，而非将其推迟到事后对齐，为公平基础模型提供了一个设计优先的蓝图。", "translation": "大型语言模型（LLMs）已成为强大的通用推理系统，但其发展仍主要由以英语为中心的数据、架构和优化范式主导。这种排他性设计导致印度等语言多样性丰富的地区存在结构性代表不足，印度拥有20多种官方语言和100多种方言，并存在语码转换和双语现象。我们引入了PARAM-1，一个2.9亿参数的仅解码器、仅文本语言模型，该模型从头开始训练，明确关注印度多样性的架构和语言特征。PARAM-1在一个仅包含印地语和英语的双语数据集上进行训练，该数据集高度重视事实丰富、高质量的内容。它遵循三个核心原则：通过25%的语料分配实现印度语言的公平代表；通过适应印度形态结构的SentencePiece分词器实现分词公平性；以及在IndicQA、语码混合推理和社会语言鲁棒性任务中进行文化对齐的评估基准。通过在预训练层面嵌入多样性——而不是将其推迟到事后对齐——PARAM-1为公平基础模型提供了一个设计优先的蓝图。我们的结果表明，它既是一个称职的通用模型，也是印度中心应用的稳健基线。", "summary": "PARAM-1是一个2.9亿参数的仅解码器、仅文本大型语言模型，专门为解决大型语言模型中印度语言多样性的代表性不足问题而设计。该模型从头开始训练，使用了高质量的印地语和英语双语数据集，并遵循公平的语言代表、分词和文化对齐的评估原则。研究结果表明，PARAM-1是一个有效的通用模型，也是印度特定应用的可靠基线，为构建公平的基础模型提供了设计优先的方法。", "keywords": "大型语言模型, 印度语言, 语言多样性, 多语言模型, 公平人工智能", "comments": "该论文的创新之处在于其“设计优先”的方法，即在预训练阶段就嵌入语言多样性，以解决大型语言模型在多语言环境中（特别是印度）的代表性不足问题。这与常见的后处理对齐方法形成对比，为公平的人工智能发展提供了重要的蓝图。"}}
{"id": "2507.12168", "title": "Shape Adaptation for 3D Hairstyle Retargeting", "authors": ["Lu Yu", "Zhong Ren", "Youyi Zheng", "Xiang Chen", "Kun Zhou"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12168v2", "summary": "It is demanding to author an existing hairstyle for novel characters in games\nand VR applications. However, it is a non-trivial task for artists due to the\ncomplicated hair geometries and spatial interactions to preserve. In this\npaper, we present an automatic shape adaptation method to retarget 3D\nhairstyles. We formulate the adaptation process as a constrained optimization\nproblem, where all the shape properties and spatial relationships are converted\ninto individual objectives and constraints. To make such an optimization on\nhigh-resolution hairstyles tractable, we adopt a multi-scale strategy to\ncompute the target positions of the hair strands in a coarse-to-fine manner.\nThe global solving for the inter-strands coupling is restricted to the coarse\nlevel, and the solving for fine details is made local and parallel. In\naddition, we present a novel hairline edit tool to allow for user customization\nduring retargeting. We achieve it by solving physics-based deformations of an\nembedded membrane to redistribute the hair roots with minimal distortion. We\ndemonstrate the efficacy of our method through quantitative and qualitative\nexperiments on various hairstyles and characters.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12168v2", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "3D发型重定向的形状自适应", "tldr": "本文提出了一种自动形状自适应方法，用于将3D发型重定向到新角色，通过多尺度优化和发际线编辑工具解决复杂发型几何和空间交互问题。", "motivation": "在游戏和VR应用中为新角色创作现有发型非常困难，因为头发几何复杂且需要保留空间交互，对艺术家来说是非平凡的任务。", "method": "将自适应过程表述为约束优化问题，将形状属性和空间关系转化为目标和约束。采用多尺度策略（从粗到细）计算发束目标位置，全局求解股间耦合限制在粗尺度，细节求解局部并行。此外，提出一种新的发际线编辑工具，通过求解嵌入膜的物理形变来重新分布发根，以实现最小失真。", "result": "通过对各种发型和角色进行定量和定性实验，证明了方法的有效性。", "conclusion": "本文提出的自动形状自适应方法能够有效地将3D发型重定向到新角色，并通过多尺度优化和发际线编辑工具解决了复杂发型重定向的挑战。", "translation": "在游戏和VR应用中为新角色创作现有发型是一项要求很高的任务。然而，由于复杂的头发几何形状和需要保留的空间交互，这对艺术家来说并非易事。在本文中，我们提出了一种自动形状自适应方法来重定向3D发型。我们将自适应过程表述为一个约束优化问题，其中所有形状属性和空间关系都被转换为单独的目标和约束。为了使这种在高分辨率发型上的优化变得可行，我们采用了一种多尺度策略，以从粗到细的方式计算发束的目标位置。股间耦合的全局求解被限制在粗尺度，而精细细节的求解则是局部并行进行的。此外，我们提出了一种新颖的发际线编辑工具，允许用户在重定向过程中进行自定义。我们通过求解嵌入膜的基于物理的变形来实现这一点，以最小的失真重新分布发根。我们通过对各种发型和角色的定量和定性实验证明了我们方法的有效性。", "summary": "本文提出了一种针对3D发型重定向的自动形状自适应方法。该方法将发型自适应建模为约束优化问题，通过多尺度策略处理高分辨率发型，实现从粗到细的发束位置计算，并分离全局和局部求解。此外，引入了新的发际线编辑工具，允许用户自定义发根分布。实验证明了该方法在各种发型和角色上的有效性。", "keywords": "3D发型, 形状自适应, 发型重定向, 多尺度优化, 发际线编辑", "comments": "本文的创新点在于将3D发型重定向问题转化为约束优化，并引入了多尺度策略来处理高分辨率数据，提高了效率和可行性。同时，提出的发际线编辑工具增加了用户自定义的灵活性，使得重定向结果更符合需求。该方法对于游戏和VR等应用中快速生成多样化角色具有重要意义。"}}
{"id": "2507.12950", "title": "Insights into a radiology-specialised multimodal large language model with sparse autoencoders", "authors": ["Kenza Bouzid", "Shruthi Bannur", "Felix Meissen", "Daniel Coelho de Castro", "Anton Schwaighofer", "Javier Alvarez-Valle", "Stephanie L. Hyland"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Actionable Interpretability Workshop at ICML 2025. 24 pages, 7 figures, 5 tables", "url": "http://arxiv.org/abs/2507.12950v2", "summary": "Interpretability can improve the safety, transparency and trust of AI models,\nwhich is especially important in healthcare applications where decisions often\ncarry significant consequences. Mechanistic interpretability, particularly\nthrough the use of sparse autoencoders (SAEs), offers a promising approach for\nuncovering human-interpretable features within large transformer-based models.\nIn this study, we apply Matryoshka-SAE to the radiology-specialised multimodal\nlarge language model, MAIRA-2, to interpret its internal representations. Using\nlarge-scale automated interpretability of the SAE features, we identify a range\nof clinically relevant concepts - including medical devices (e.g., line and\ntube placements, pacemaker presence), pathologies such as pleural effusion and\ncardiomegaly, longitudinal changes and textual features. We further examine the\ninfluence of these features on model behaviour through steering, demonstrating\ndirectional control over generations with mixed success. Our results reveal\npractical and methodological challenges, yet they offer initial insights into\nthe internal concepts learned by MAIRA-2 - marking a step toward deeper\nmechanistic understanding and interpretability of a radiology-adapted\nmultimodal large language model, and paving the way for improved model\ntransparency. We release the trained SAEs and interpretations:\nhttps://huggingface.co/microsoft/maira-2-sae.", "comment": "Actionable Interpretability Workshop at ICML 2025. 24 pages, 7\n  figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.12950v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "使用稀疏自编码器深入了解放射学专用多模态大型语言模型", "tldr": "本研究使用Matryoshka-SAE来解释放射学专用多模态大型语言模型MAIRA-2的内部表示，识别出临床相关概念，并通过操纵特征来控制模型生成，旨在提高AI模型的透明度和可信度。", "motivation": "在医疗保健应用中，AI模型的决策具有重要后果，因此提高其安全性、透明度和信任度至关重要。机械可解释性，特别是通过稀疏自编码器（SAE）的应用，为揭示大型transformer模型中人类可解释的特征提供了一种有前景的方法。", "method": "本研究将Matryoshka-SAE应用于放射学专用多模态大型语言模型MAIRA-2，以解释其内部表示。通过对SAE特征进行大规模自动化解释，识别出临床相关概念，并进一步通过操纵这些特征来检验它们对模型行为的影响。", "result": "研究识别出一系列临床相关概念，包括医疗设备（如管线、起搏器）、病理（如胸腔积液、心脏肥大）、纵向变化和文本特征。通过操纵特征来控制模型生成，但成功程度不一，揭示了实际和方法上的挑战。", "conclusion": "尽管存在实际和方法上的挑战，本研究为MAIRA-2所学习的内部概念提供了初步见解，标志着向更深入地机械理解和解释放射学专用多模态大型语言模型迈进了一步，并为提高模型透明度铺平了道路。", "translation": "可解释性可以提高AI模型的安全性、透明度和信任度，这在决策通常具有重大后果的医疗保健应用中尤为重要。机械可解释性，特别是通过使用稀疏自编码器（SAE），为揭示大型基于Transformer的模型中人类可解释的特征提供了一种有前景的方法。在本研究中，我们将Matryoshka-SAE应用于放射学专用多模态大型语言模型MAIRA-2，以解释其内部表示。通过对SAE特征进行大规模自动化解释，我们识别出一系列临床相关概念——包括医疗设备（例如管线和导管放置、起搏器存在）、胸腔积液和心脏肥大等病理、纵向变化和文本特征。我们通过操纵进一步检验了这些特征对模型行为的影响，展示了对生成的定向控制，但成功程度不一。我们的结果揭示了实际和方法上的挑战，但它们提供了对MAIRA-2学习到的内部概念的初步见解——标志着向更深入地机械理解和解释放射学专用多模态大型语言模型迈出了一步，并为提高模型透明度铺平了道路。我们发布了训练好的SAE和解释：https://huggingface.co/microsoft/maira-2-sae。", "summary": "本研究旨在提高医疗AI模型的透明度和可信度，通过使用Matryoshka-SAE来解释放射学专用多模态大型语言模型MAIRA-2的内部表示。研究识别出MAIRA-2学习到的多种临床相关概念，包括医疗设备、病理和文本特征。尽管在通过操纵特征控制模型生成方面存在挑战，但本工作为深入理解此类模型的内部机制提供了初步见解，并为未来的模型透明度研究奠定了基础。", "keywords": "机械可解释性, 稀疏自编码器, 放射学AI, 多模态大型语言模型, MAIRA-2", "comments": "本论文的创新点在于将稀疏自编码器应用于放射学领域的多模态大型语言模型，以实现机械可解释性。这对于医疗AI领域至关重要，因为它直接关系到模型的安全性和可信度。尽管研究指出了在特征操纵方面存在的挑战，但其识别出临床相关概念的发现具有重要意义，为未来更深入的理解和改进医疗AI模型提供了宝贵的基础。发布训练好的SAE也体现了开放科学的精神。"}}
{"id": "2507.13491", "title": "Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents", "authors": ["Thomas Banker", "Ali Mesbah"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13491v1", "summary": "Training sophisticated agents for optimal decision-making under uncertainty\nhas been key to the rapid development of modern autonomous systems across\nfields. Notably, model-free reinforcement learning (RL) has enabled\ndecision-making agents to improve their performance directly through system\ninteractions, with minimal prior knowledge about the system. Yet, model-free RL\nhas generally relied on agents equipped with deep neural network function\napproximators, appealing to the networks' expressivity to capture the agent's\npolicy and value function for complex systems. However, neural networks amplify\nthe issues of sample inefficiency, unsafe learning, and limited\ninterpretability in model-free RL. To this end, this work introduces\nmodel-based agents as a compelling alternative for control policy\napproximation, leveraging adaptable models of system dynamics, cost, and\nconstraints for safe policy learning. These models can encode prior system\nknowledge to inform, constrain, and aid in explaining the agent's decisions,\nwhile deficiencies due to model mismatch can be remedied with model-free RL. We\noutline the benefits and challenges of learning model-based agents --\nexemplified by model predictive control -- and detail the primary learning\napproaches: Bayesian optimization, policy search RL, and offline strategies,\nalong with their respective strengths. While model-free RL has long been\nestablished, its interplay with model-based agents remains largely unexplored,\nmotivating our perspective on their combined potentials for sample-efficient\nlearning of safe and interpretable decision-making agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13491v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "无模型强化学习用于基于模型的控制：迈向安全、可解释和样本高效的智能体", "tldr": "本文探讨将无模型强化学习与基于模型的控制相结合，以解决强化学习智能体中样本效率低下、不安全和可解释性差等问题。", "motivation": "无模型强化学习（RL）虽然在现代自主系统中发展迅速，但其与深度神经网络结合时存在样本效率低下、学习不安全以及可解释性有限等问题。本文旨在探讨将无模型RL与基于模型的控制相结合，以克服这些局限并发挥其联合潜力。", "method": "本文提出以基于模型的智能体作为控制策略近似的替代方案，利用系统动力学、成本和约束的可适应模型来实现安全策略学习。这些模型可以编码先验系统知识，并通过无模型强化学习弥补模型不匹配的缺陷。文中概述了学习基于模型的智能体（以模型预测控制为例）的益处和挑战，并详细介绍了主要的学习方法：贝叶斯优化、策略搜索强化学习和离线策略。", "result": "未在摘要中提及", "conclusion": "本文旨在探讨无模型强化学习与基于模型的智能体相结合的潜力，以实现样本高效、安全且可解释的决策智能体。", "translation": "在不确定性下训练复杂的智能体以实现最优决策，是现代自主系统在各领域快速发展的关键。值得注意的是，无模型强化学习（RL）使决策智能体能够直接通过系统交互提高性能，对系统先验知识的需求极少。然而，无模型RL通常依赖于配备深度神经网络函数逼近器的智能体，利用网络的表达能力来捕捉复杂系统的智能体策略和价值函数。但神经网络会放大无模型RL中样本效率低下、学习不安全和可解释性有限的问题。为此，这项工作引入了基于模型的智能体作为控制策略近似的有力替代方案，利用系统动力学、成本和约束的可适应模型来实现安全策略学习。这些模型可以编码先验系统知识，以指导、约束和帮助解释智能体的决策，而由于模型不匹配导致的缺陷可以通过无模型RL来弥补。我们概述了学习基于模型的智能体（以模型预测控制为例）的益处和挑战，并详细介绍了主要的学习方法：贝叶斯优化、策略搜索RL和离线策略，以及它们各自的优势。虽然无模型RL早已确立，但其与基于模型的智能体之间的相互作用在很大程度上仍未被探索，这促使我们对它们在样本高效学习安全和可解释决策智能体方面的结合潜力提出见解。", "summary": "该论文探讨了无模型强化学习（RL）在应用深度神经网络时所面临的样本效率低下、安全性差和可解释性不足等挑战。为解决这些问题，论文提出将基于模型的智能体作为控制策略近似的有效替代方案，利用可适应的系统动力学、成本和约束模型实现安全策略学习。文章论述了基于模型的智能体的优势和挑战（以模型预测控制为例），并详细介绍了贝叶斯优化、策略搜索RL和离线策略等主要学习方法。论文强调，尽管无模型RL已成熟发展，但其与基于模型的智能体的结合潜力仍未充分探索，这促使作者深入研究两者的结合如何实现样本高效、安全且可解释的决策智能体。", "keywords": "无模型强化学习, 基于模型控制, 安全性, 可解释性, 样本效率", "comments": "本文通过提出一种混合方法，解决了当前无模型强化学习在安全性、可解释性和样本效率方面的重要局限性。其创新之处在于倡导无模型和基于模型方法之间的协同结合，这有望带来更鲁棒和实用的强化学习系统。"}}
{"id": "2507.13514", "title": "Sugar-Beet Stress Detection using Satellite Image Time Series", "authors": ["Bhumika Laxman Sadbhave", "Philipp Vaeth", "Denise Dejon", "Gunther Schorcht", "Magda Gregorová"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13514v1", "summary": "Satellite Image Time Series (SITS) data has proven effective for agricultural\ntasks due to its rich spectral and temporal nature. In this study, we tackle\nthe task of stress detection in sugar-beet fields using a fully unsupervised\napproach. We propose a 3D convolutional autoencoder model to extract meaningful\nfeatures from Sentinel-2 image sequences, combined with\nacquisition-date-specific temporal encodings to better capture the growth\ndynamics of sugar-beets. The learned representations are used in a downstream\nclustering task to separate stressed from healthy fields. The resulting stress\ndetection system can be directly applied to data from different years, offering\na practical and accessible tool for stress detection in sugar-beets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13514v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "使用卫星图像时间序列进行甜菜胁迫检测", "tldr": "本研究提出了一种基于3D卷积自编码器和时间编码的无监督方法，利用卫星图像时间序列数据检测甜菜田的胁迫状况，并开发了一个可应用于不同年份数据的实用系统。", "motivation": "卫星图像时间序列（SITS）数据因其丰富的光谱和时间特性，在农业任务中被证明是有效的。本研究旨在解决甜菜田的胁迫检测问题。", "method": "本研究提出了一种3D卷积自编码器模型，用于从Sentinel-2图像序列中提取有意义的特征，并结合采集日期特定的时间编码以更好地捕捉甜菜的生长动态。学习到的表征随后用于下游聚类任务，以区分受胁迫和健康的田地。", "result": "开发了一个可直接应用于不同年份数据的甜菜胁迫检测系统。", "conclusion": "该研究提出的甜菜胁迫检测系统提供了一个实用且易于使用的工具，能够直接应用于不同年份的数据进行甜菜胁迫检测。", "translation": "卫星图像时间序列（SITS）数据因其丰富的光谱和时间特性，已被证明在农业任务中是有效的。在本研究中，我们采用一种完全无监督的方法来解决甜菜田的胁迫检测任务。我们提出了一种3D卷积自编码器模型，用于从Sentinel-2图像序列中提取有意义的特征，并结合采集日期特定的时间编码，以更好地捕捉甜菜的生长动态。学习到的表示用于下游聚类任务，以区分受胁迫的田地和健康的田地。由此产生的胁迫检测系统可以直接应用于不同年份的数据，为甜菜胁迫检测提供了一个实用且易于使用的工具。", "summary": "本研究提出了一种利用卫星图像时间序列数据进行甜菜胁迫检测的完全无监督方法。通过结合3D卷积自编码器和采集日期特定的时间编码，从Sentinel-2图像中提取特征，并通过聚类区分受胁迫和健康的甜菜田。该系统具有跨年份应用的能力，提供了一个实用的甜菜胁迫检测工具。", "keywords": "甜菜胁迫检测, 卫星图像时间序列, 3D卷积自编码器, 无监督学习, 农业遥感", "comments": "该论文的创新点在于提出了结合3D卷积自编码器和时间编码的无监督方法来处理卫星图像时间序列数据，以捕捉甜菜的生长动态并进行胁迫检测。其重要性体现在提供了一个无需大量标记数据即可实现胁迫检测的实用工具，且能够应用于不同年份的数据，这对于农业监测具有显著的实际意义和可扩展性。"}}
{"id": "2507.13812", "title": "SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing", "authors": ["Yingying Zhang", "Lixiang Ru", "Kang Wu", "Lei Yu", "Lei Liang", "Yansheng Li", "Jingdong Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV25", "url": "http://arxiv.org/abs/2507.13812v1", "summary": "The multi-modal remote sensing foundation model (MM-RSFM) has significantly\nadvanced various Earth observation tasks, such as urban planning, environmental\nmonitoring, and natural disaster management. However, most existing approaches\ngenerally require the training of separate backbone networks for each data\nmodality, leading to redundancy and inefficient parameter utilization.\nMoreover, prevalent pre-training methods typically apply self-supervised\nlearning (SSL) techniques from natural images without adequately accommodating\nthe characteristics of remote sensing (RS) images, such as the complicated\nsemantic distribution within a single RS image. In this work, we present\nSkySense V2, a unified MM-RSFM that employs a single transformer backbone to\nhandle multiple modalities. This backbone is pre-trained with a novel SSL\nstrategy tailored to the distinct traits of RS data. In particular, SkySense V2\nincorporates an innovative adaptive patch merging module and learnable modality\nprompt tokens to address challenges related to varying resolutions and limited\nfeature diversity across modalities. In additional, we incorporate the mixture\nof experts (MoE) module to further enhance the performance of the foundation\nmodel. SkySense V2 demonstrates impressive generalization abilities through an\nextensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense\nby an average of 1.8 points.", "comment": "Accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2507.13812v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "SkySense V2：一种多模态遥感统一基础模型", "tldr": "SkySense V2是一个统一的多模态遥感基础模型，通过单个Transformer骨干网络和定制的自监督学习策略解决了现有方法的冗余和遥感数据适应性问题。", "motivation": "现有多模态遥感基础模型通常为每种数据模态训练独立的骨干网络，导致冗余和参数利用效率低下。此外，主流的预训练方法未能充分适应遥感图像的复杂语义分布等特性。", "method": "本文提出了SkySense V2，一个统一的多模态遥感基础模型，采用单个Transformer骨干网络处理多种模态。该骨干网络通过一种专为遥感数据特性设计的新型自监督学习策略进行预训练。SkySense V2还结合了创新的自适应补丁合并模块和可学习模态提示符，以解决不同分辨率和模态间特征多样性有限的挑战，并引入了专家混合（MoE）模块以进一步提升性能。", "result": "SkySense V2在涉及7个任务的16个数据集上进行了广泛评估，展示了令人印象深刻的泛化能力，平均性能超越SkySense 1.8个点。", "conclusion": "SkySense V2通过其统一的Transformer骨干网络、定制的自监督学习策略以及针对遥感数据特性的创新模块，有效解决了现有MM-RSFM的效率和适应性问题，并在多任务多数据集上取得了显著的性能提升和泛化能力。", "translation": "多模态遥感基础模型（MM-RSFM）显著推动了城市规划、环境监测和自然灾害管理等多种地球观测任务的发展。然而，大多数现有方法通常需要为每种数据模态训练独立的骨干网络，导致冗余和参数利用效率低下。此外，主流的预训练方法通常采用自然图像中的自监督学习（SSL）技术，而没有充分适应遥感图像的特性，例如单个遥感图像内复杂的语义分布。在这项工作中，我们提出了SkySense V2，一个统一的MM-RSFM，它采用单个Transformer骨干网络来处理多种模态。该骨干网络通过一种专为遥感数据独特特性量身定制的新型SSL策略进行预训练。特别是，SkySense V2整合了一个创新的自适应补丁合并模块和可学习的模态提示符，以解决不同分辨率和模态间有限特征多样性相关的挑战。此外，我们引入了专家混合（MoE）模块，以进一步增强基础模型的性能。SkySense V2通过在7个任务的16个数据集上进行的广泛评估，展示了令人印象深刻的泛化能力，平均性能超越SkySense 1.8个点。", "summary": "SkySense V2是一个创新的统一多模态遥感基础模型，旨在解决现有模型在多模态数据处理中的冗余和遥感数据适应性不足的问题。它采用单个Transformer骨干网络，并通过专为遥感数据设计的新型自监督学习策略进行预训练。模型引入了自适应补丁合并模块、可学习模态提示符以及专家混合（MoE）模块，以处理分辨率差异和提升特征多样性。在多项任务和数据集上的广泛评估表明，SkySense V2具有出色的泛化能力，并超越了现有模型。", "keywords": "多模态遥感, 基础模型, 自监督学习, Transformer, 专家混合", "comments": "SkySense V2的创新在于其统一的Transformer骨干网络设计，有效解决了多模态遥感数据处理中常见的冗余和效率问题。通过定制的自监督学习策略和针对遥感数据特性（如分辨率差异和特征多样性）设计的模块（自适应补丁合并、模态提示符和MoE），该模型显著提升了对复杂遥感数据的适应性和泛化能力。其在广泛数据集上的性能提升证明了其在地球观测领域的潜在应用价值。"}}
{"id": "2507.13910", "title": "PARK: Personalized academic retrieval with knowledge-graphs", "authors": ["Pranav Kasela", "Gabriella Pasi", "Raffaele Perego"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Accepted in Information Systems. [17 May 2025] this https URL", "url": "http://arxiv.org/abs/2507.13910v1", "summary": "Academic Search is a search task aimed to manage and retrieve scientific\ndocuments like journal articles and conference papers. Personalization in this\ncontext meets individual researchers' needs by leveraging, through user\nprofiles, the user related information (e.g. documents authored by a\nresearcher), to improve search effectiveness and to reduce the information\noverload. While citation graphs are a valuable means to support the outcome of\nrecommender systems, their use in personalized academic search (with, e.g.\nnodes as papers and edges as citations) is still under-explored.\n  Existing personalized models for academic search often struggle to fully\ncapture users' academic interests. To address this, we propose a two-step\napproach: first, training a neural language model for retrieval, then\nconverting the academic graph into a knowledge graph and embedding it into a\nshared semantic space with the language model using translational embedding\ntechniques. This allows user models to capture both explicit relationships and\nhidden structures in citation graphs and paper content. We evaluate our\napproach in four academic search domains, outperforming traditional graph-based\nand personalized models in three out of four, with up to a 10\\% improvement in\nMAP@100 over the second-best model. This highlights the potential of knowledge\ngraph-based user models to enhance retrieval effectiveness.", "comment": "Accepted in Information Systems. [17 May 2025]\n  https://doi.org/10.1016/j.is.2025.102574", "pdf_url": "http://arxiv.org/pdf/2507.13910v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "PARK：基于知识图谱的个性化学术检索", "tldr": "本文提出了一种结合知识图谱和神经语言模型的两步法PARK，用于个性化学术检索，显著提升了检索效果，解决了现有模型难以捕捉用户兴趣的问题。", "motivation": "现有个性化学术搜索模型难以充分捕捉用户的学术兴趣，且引文图谱在个性化学术搜索中的应用仍未被充分探索。", "method": "提出了一种两步法：首先训练一个用于检索的神经语言模型；然后将学术图谱转换为知识图谱，并使用平移嵌入技术将其与语言模型嵌入到共享语义空间中。", "result": "在四个学术检索领域中的三个领域，该方法优于传统的基于图谱和个性化模型，在MAP@100指标上比次优模型提高了高达10%。", "conclusion": "基于知识图谱的用户模型具有增强检索有效性的潜力。", "translation": "学术搜索是一项旨在管理和检索科学文档（如期刊文章和会议论文）的搜索任务。在这种背景下的个性化，通过用户画像利用与用户相关的信息（例如研究人员撰写的文档），以满足个体研究人员的需求，从而提高搜索效率并减少信息过载。虽然引文图谱是支持推荐系统结果的宝贵手段，但它们在个性化学术搜索中的应用（例如，节点为论文，边为引文）仍未被充分探索。\n现有的个性化学术搜索模型通常难以完全捕捉用户的学术兴趣。为了解决这个问题，我们提出了一种两步法：首先，训练一个用于检索的神经语言模型，然后将学术图谱转换为知识图谱，并使用平移嵌入技术将其与语言模型嵌入到共享语义空间中。这使得用户模型能够捕捉引文图谱和论文内容中的显式关系和隐藏结构。我们在四个学术搜索领域评估了我们的方法，在其中三个领域中，我们的方法优于传统的基于图谱和个性化模型，在MAP@100指标上比次优模型提高了高达10%。这突出了基于知识图谱的用户模型在增强检索有效性方面的潜力。", "summary": "本文提出了PARK，一种基于知识图谱和神经语言模型的个性化学术检索方法。针对现有模型难以捕捉用户兴趣的问题，该方法通过两步实现：先训练神经语言模型，再将学术图谱转化为知识图谱并与语言模型嵌入到共享语义空间。实验结果表明，该方法在多个学术搜索领域表现优异，显著提升了检索效果。", "keywords": "个性化学术检索, 知识图谱, 神经语言模型, 信息检索, 引文图谱", "comments": "该研究创新性地结合了神经语言模型和知识图谱，有效解决了现有个性化学术检索模型在捕捉用户兴趣方面的局限性，并利用知识图谱的结构信息进一步提升了检索性能，具有重要的实践意义。"}}
{"id": "2507.13207", "title": "MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling", "authors": ["Etienne Le Naour", "Tahar Nabil", "Ghislain Agoua"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      10th Workshop on Advanced Analytics and Learning on Temporal Data (AALTD), ECML 2025", "url": "http://arxiv.org/abs/2507.13207v2", "summary": "Recent years have witnessed a growing interest for time series foundation\nmodels, with a strong emphasis on the forecasting task. Yet, the crucial task\nof out-of-domain imputation of missing values remains largely underexplored. We\npropose a first step to fill this gap by leveraging implicit neural\nrepresentations (INRs). INRs model time series as continuous functions and\nnaturally handle various missing data scenarios and sampling rates. While they\nhave shown strong performance within specific distributions, they struggle\nunder distribution shifts. To address this, we introduce MoTM (Mixture of\nTimeflow Models), a step toward a foundation model for time series imputation.\nBuilding on the idea that a new time series is a mixture of previously seen\npatterns, MoTM combines a basis of INRs, each trained independently on a\ndistinct family of time series, with a ridge regressor that adapts to the\nobserved context at inference. We demonstrate robust in-domain and\nout-of-domain generalization across diverse imputation scenarios (e.g., block\nand pointwise missingness, variable sampling rates), paving the way for\nadaptable foundation imputation models.", "comment": "10th Workshop on Advanced Analytics and Learning on Temporal Data\n  (AALTD), ECML 2025", "pdf_url": "http://arxiv.org/pdf/2507.13207v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "MoTM：迈向基于连续建模的时间序列插补基础模型", "tldr": "MoTM提出了一个基于隐式神经表示的混合模型，用于解决时间序列数据中域外缺失值的插补问题，并在各种插补场景中表现出强大的泛化能力。", "motivation": "当前时间序列基础模型主要关注预测任务，而域外缺失值插补这一关键任务却在很大程度上未被充分探索。现有隐式神经表示（INRs）在处理特定分布内的数据时表现良好，但在分布偏移下表现不佳。", "method": "本文提出了MoTM（Mixture of Timeflow Models），旨在解决时间序列插补问题。MoTM基于“新的时间序列是先前已见模式的混合”这一思想，结合了INRs基础（每个INR独立训练于一个不同的时间序列族）和一个岭回归器，该回归器在推理时根据观察到的上下文进行调整。", "result": "MoTM在各种插补场景（例如，块状和点状缺失、可变采样率）中，展示了强大的域内和域外泛化能力。", "conclusion": "MoTM为适应性基础插补模型铺平了道路，有效解决了时间序列缺失值插补中的分布偏移挑战。", "translation": "近年来，人们对时间序列基础模型的兴趣日益增长，其中重点是预测任务。然而，域外缺失值插补这一关键任务在很大程度上仍未得到充分探索。我们提出利用隐式神经表示（INRs）迈出填补这一空白的第一步。INRs将时间序列建模为连续函数，自然地处理各种缺失数据场景和采样率。虽然它们在特定分布内表现出强大的性能，但在分布偏移下却面临困难。为了解决这个问题，我们引入了MoTM（时间流模型混合体），这是迈向时间序列插补基础模型的一步。MoTM基于新的时间序列是先前已见模式混合的理念，结合了INRs基础（每个INR在不同的时间序列家族上独立训练）和一个岭回归器，该回归器在推理时适应观察到的上下文。我们展示了在各种插补场景（例如，块状和点状缺失、可变采样率）中强大的域内和域外泛化能力，为适应性基础插补模型铺平了道路。", "summary": "MoTM（时间流模型混合体）是一种旨在解决时间序列缺失值插补问题的新方法，特别关注域外泛化能力。该模型利用隐式神经表示（INRs）将时间序列建模为连续函数，并通过结合独立训练的INRs基础和一个适应上下文的岭回归器来克服传统INRs在分布偏移下的局限性。MoTM在多种缺失数据场景和采样率下表现出强大的域内和域外插补性能，为时间序列插补的基础模型奠定了基础。", "keywords": "时间序列插补, 基础模型, 隐式神经表示, 域外泛化, 缺失值", "comments": "MoTM的创新之处在于其将隐式神经表示与混合模型相结合，以应对时间序列插补中的分布偏移挑战。这种方法为构建更鲁棒、更具泛化能力的时间序列基础模型提供了新的视角，尤其是在处理现实世界中复杂的缺失数据和可变采样率场景方面具有重要意义。该研究为未来开发适应性更强的插补模型奠定了基础。"}}
{"id": "2507.13951", "title": "Democratizing Game Modding with GenAI: A Case Study of StarCharM, a Stardew Valley Character Maker", "authors": ["Hamid Zand Miralvand", "Mohammad Ronagh Nikghalb", "Mohammad Darandeh", "Abidullah Khan", "Ian Arawjo", "Jinghui Cheng"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to CHI Play 2025, 35 pages, 4 figures", "url": "http://arxiv.org/abs/2507.13951v1", "summary": "Game modding offers unique and personalized gaming experiences, but the\ntechnical complexity of creating mods often limits participation to skilled\nusers. We envision a future where every player can create personalized mods for\ntheir games. To explore this space, we designed StarCharM, a GenAI-based\nnon-player character (NPC) creator for Stardew Valley. Our tool enables players\nto iteratively create new NPC mods, requiring minimal user input while allowing\nfor fine-grained adjustments through user control. We conducted a user study\nwith ten Stardew Valley players who had varied mod usage experiences to\nunderstand the impacts of StarCharM and provide insights into how GenAI tools\nmay reshape modding, particularly in NPC creation. Participants expressed\nexcitement in bringing their character ideas to life, although they noted\nchallenges in generating rich content to fulfill complex visions. While they\nbelieved GenAI tools like StarCharM can foster a more diverse modding\ncommunity, some voiced concerns about diminished originality and community\nengagement that may come with such technology. Our findings provided\nimplications and guidelines for the future of GenAI-powered modding tools and\nco-creative modding practices.", "comment": "Accepted to CHI Play 2025, 35 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13951v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用生成式AI普及游戏模组：以星露谷物语角色创建器StarCharM为例", "tldr": "该研究通过开发一个基于生成式AI的星露谷物语NPC创建工具StarCharM，探索了生成式AI如何使游戏模组制作民主化，并进行了用户研究，发现玩家对此感到兴奋但也存在对内容丰富性和原创性的担忧。", "motivation": "游戏模组制作的技术复杂性限制了多数玩家的参与，研究旨在探索如何通过生成式AI使每个玩家都能创建个性化模组，并设想一个所有玩家都能为游戏创建个性化模组的未来。", "method": "设计并开发了StarCharM，一个基于生成式AI的星露谷物语非玩家角色（NPC）创建工具。该工具允许玩家迭代创建新的NPC模组，仅需最少的用户输入，同时允许通过用户控制进行精细调整。对十名具有不同模组使用经验的星露谷物语玩家进行了用户研究。", "result": "参与者对实现他们的角色想法感到兴奋，尽管他们指出在生成丰富内容以实现复杂愿景方面存在挑战。他们认为StarCharM等生成式AI工具可以培养更多样化的模组社区，但也有人担心此类技术可能导致原创性下降和社区参与度降低。", "conclusion": "研究结果为未来生成式AI驱动的模组工具和协同创作模组实践提供了启示和指导。", "translation": "游戏模组提供了独特和个性化的游戏体验，但创建模组的技术复杂性通常将参与者限制在熟练用户。我们设想一个未来，每个玩家都可以为他们的游戏创建个性化模组。为了探索这个领域，我们设计了StarCharM，一个基于生成式AI的星露谷物语非玩家角色（NPC）创建器。我们的工具使玩家能够迭代创建新的NPC模组，仅需最少的用户输入，同时允许通过用户控制进行精细调整。我们对十名具有不同模组使用经验的星露谷物语玩家进行了用户研究，以了解StarCharM的影响，并提供关于生成式AI工具如何重塑模组制作，特别是在NPC创建方面的见解。参与者表达了将他们的角色想法变为现实的兴奋，尽管他们指出在生成丰富内容以实现复杂愿景方面存在挑战。虽然他们认为像StarCharM这样的生成式AI工具可以培养一个更多样化的模组社区，但一些人对这种技术可能带来的原创性下降和社区参与度降低表示担忧。我们的发现为未来生成式AI驱动的模组工具和协同创作模组实践提供了启示和指导。", "summary": "本研究旨在通过生成式AI使游戏模组制作民主化，为此开发了StarCharM，一个用于星露谷物语的生成式AI驱动的NPC创建工具。该工具允许玩家以最小输入创建并精细调整角色模组。通过对十名玩家进行用户研究，发现玩家对利用GenAI实现角色想法感到兴奋，但同时也担忧内容生成丰富性不足以及可能对原创性和社区参与度造成负面影响。研究为未来GenAI模组工具的发展提供了指导。", "keywords": "生成式AI, 游戏模组, NPC创建, 星露谷物语, 用户研究", "comments": "本论文创新性地将生成式AI应用于游戏模组制作，特别是NPC创建，旨在降低技术门槛，普及个性化游戏体验。其重要性在于探索了GenAI在用户生成内容领域的潜力，并揭示了技术普及与原创性及社区参与度之间的潜在冲突，为未来GenAI工具的设计提供了宝贵的用户反馈和指导。"}}
{"id": "2504.00181", "title": "Beamforming Design for Continuous Aperture Array (CAPA)-Based MIMO Systems", "authors": ["Zhaolin Wang", "Chongjun Ouyang", "Yuanwei Liu"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures", "url": "http://arxiv.org/abs/2504.00181v3", "summary": "An efficient beamforming design is proposed for continuous aperture array\n(CAPA)-based point-to-point multiple-input multiple-output (MIMO) systems. In\ncontrast to conventional spatially discrete array (SPDA)-MIMO systems, whose\noptimal beamforming can be obtained using singular-value decomposition,\nCAPA-MIMO systems require solving the eigendecomposition of a Hermitian kernel\noperator, which is computationally prohibitive. To address this challenge, an\nexplicit closed-form expression for the achievable rate of CAPA-MIMO systems is\nfirst derived as a function of the continuous transmit beamformer.\nSubsequently, an iterative weighted minimum mean-squared error (WMMSE)\nalgorithm is proposed, directly addressing the CAPA-MIMO beamforming\noptimization without discretization approximation. Closed-form updates for each\niteration of the WMMSE algorithm are derived via the calculus of variations\n(CoV) method. For low-complexity implementation, an equivalent matrix-based\niterative solution is introduced using Gauss-Legendre quadrature. Our numerical\nresults demonstrate that 1) CAPA-MIMO achieves substantial performance gain\nover the SPDA-MIMO, 2) the proposed WMMSE algorithm enhances performance while\nsignificantly reducing computational complexity compared to state-of-the-art\nFourier-based approaches, and 3) the proposed WMMSE algorithm enables practical\nrealization of parallel, non-interfering transmissions.", "comment": "16 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2504.00181v3", "cate": "cs.IT", "date": "2025-03-31", "updated": "2025-07-18", "AI": {"title_translation": "连续孔径阵列(CAPA)MIMO系统的波束赋形设计", "tldr": "针对连续孔径阵列(CAPA)MIMO系统，提出了一种高效的波束赋形设计，解决了其计算复杂性问题并显著提升了性能。", "motivation": "传统的空间离散阵列（SPDA）-MIMO系统可以通过奇异值分解获得最优波束赋形，但CAPA-MIMO系统需要求解计算量巨大的Hermitian核算子特征分解。", "method": "首先推导了CAPA-MIMO系统可实现速率的显式闭式表达式；随后，提出了一种迭代加权最小均方误差（WMMSE）算法，直接优化CAPA-MIMO波束赋形，无需离散化近似；通过变分法推导了WMMSE算法每次迭代的闭式更新；为实现低复杂度，引入了使用高斯-勒让德积分的等效基于矩阵的迭代解。", "result": "数值结果表明：1) CAPA-MIMO比SPDA-MIMO获得了显著的性能增益；2) 所提出的WMMSE算法与现有基于傅里叶的方法相比，提高了性能并显著降低了计算复杂度；3) 所提出的WMMSE算法能够实现并行、无干扰传输的实际实现。", "conclusion": "所提出的WMMSE波束赋形算法有效解决了CAPA-MIMO系统的计算挑战，实现了显著的性能提升和更低的复杂度，并支持实际的并行传输。", "translation": "提出了一种用于基于连续孔径阵列（CAPA）的点对点多输入多输出（MIMO）系统的高效波束赋形设计。与传统的空间离散阵列（SPDA）-MIMO系统不同，后者的最优波束赋形可以通过奇异值分解获得，而CAPA-MIMO系统需要求解Hermitian核算子的特征分解，这在计算上是极其耗费的。为了解决这一挑战，首先推导了CAPA-MIMO系统可实现速率的显式闭式表达式，该表达式是连续发射波束形成器的函数。随后，提出了一种迭代加权最小均方误差（WMMSE）算法，直接处理CAPA-MIMO波束赋形优化，无需离散化近似。通过变分法（CoV）推导了WMMSE算法每次迭代的闭式更新。为了实现低复杂度，引入了使用高斯-勒让德积分的等效基于矩阵的迭代解。我们的数值结果表明：1）CAPA-MIMO比SPDA-MIMO获得了显著的性能增益，2）所提出的WMMSE算法与现有基于傅里叶的方法相比，提高了性能并显著降低了计算复杂度，3）所提出的WMMSE算法能够实现并行、无干扰传输的实际实现。", "summary": "本文提出了一种针对连续孔径阵列（CAPA）MIMO系统的高效波束赋形设计。针对CAPA-MIMO系统计算Hermitian核算子特征分解的挑战，作者首先推导了可实现速率的闭式表达式，并进一步提出了一种迭代加权最小均方误差（WMMSE）算法。该算法无需离散化近似，并通过变分法推导了闭式更新，同时引入基于高斯-勒让德积分的低复杂度实现方案。数值结果表明，该方法不仅使CAPA-MIMO系统性能显著优于传统SPDA-MIMO，而且相比现有方法显著降低了计算复杂度，并支持并行无干扰传输。", "keywords": "连续孔径阵列, MIMO, 波束赋形, WMMSE, 变分法", "comments": "这篇论文的创新点在于提出了直接针对连续孔径阵列（CAPA）MIMO系统波束赋形优化的迭代WMMSE算法，避免了传统的离散化近似。通过引入变分法推导闭式更新和使用高斯-勒让德积分实现低复杂度，有效解决了CAPA系统计算复杂性高的问题，使其更具实用性。其重要性在于推动了CAPA-MIMO系统在实际应用中的可行性。"}}
{"id": "2507.14052", "title": "Physics-guided gated recurrent units for inversion-based feedforward control", "authors": ["Mingdao Lin", "Max Bolderman", "Mircea Lazar"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.14052v1", "summary": "Inversion-based feedforward control relies on an accurate model that\ndescribes the inverse system dynamics. The gated recurrent unit (GRU), which is\na recent architecture in recurrent neural networks, is a strong candidate for\nobtaining such a model from data. However, due to their black-box nature, GRUs\nface challenges such as limited interpretability and vulnerability to\noverfitting. Recently, physics-guided neural networks (PGNNs) have been\nintroduced, which integrate the prior physical model structure into the\nprediction process. This approach not only improves training convergence, but\nalso facilitates the learning of a physics-based model. In this work, we\nintegrate a GRU in the PGNN framework to obtain a PG-GRU, based on which we\nadopt a two-step approach to feedforward control design. First, we adopt stable\ninversion techniques to design a stable linear model of the inverse dynamics.\nThen, a GRU trained on the residual is tailored to inverse system\nidentification. The resulting PG-GRU feedforward controller is validated by\nmeans of real-life experiments on a two-mass spring-damper system, where it\ndemonstrates roughly a two-fold improvement compared to the linear feedforward\nand a preview-based GRU feedforward in terms of the integral absolute error.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.14052v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "物理引导门控循环单元用于基于逆模型的前馈控制", "tldr": "本文提出了一种物理引导门控循环单元（PG-GRU）用于基于逆模型的前馈控制。通过将GRU与物理模型结合，解决了传统GRU在可解释性和过拟合方面的挑战。在实际系统上，该方法在积分绝对误差方面比传统方法提高了约两倍。", "motivation": "基于逆模型的前馈控制需要精确的逆系统动力学模型。门控循环单元（GRU）是获取此类模型的有力候选，但其黑盒性质导致可解释性有限且易于过拟合。物理引导神经网络（PGNNs）通过整合先验物理模型结构，可以改善训练收敛性并促进基于物理的模型学习。", "method": "本研究将门控循环单元（GRU）集成到物理引导神经网络（PGNN）框架中，形成了PG-GRU。在此基础上，采用两步法设计前馈控制器：首先，利用稳定逆技术设计逆动力学的稳定线性模型；然后，训练一个基于残差的GRU进行逆系统辨识。", "result": "所提出的PG-GRU前馈控制器在双质量弹簧阻尼系统上的实际实验中得到了验证，结果显示，与线性前馈控制器和基于预览的GRU前馈控制器相比，在积分绝对误差方面，性能大约提高了两倍。", "conclusion": "本文提出的物理引导门控循环单元（PG-GRU）前馈控制器通过结合GRU的数据驱动能力和物理模型的指导，显著提高了基于逆模型的前馈控制性能，并在实际系统中展现出优越性，克服了传统GRU的一些局限性。", "translation": "基于逆模型的前馈控制依赖于描述逆系统动力学的精确模型。门控循环单元（GRU）作为循环神经网络中的一种新型架构，是数据获取此类模型的有力候选。然而，由于其黑盒性质，GRU面临着可解释性有限和易于过拟合等挑战。最近，引入了物理引导神经网络（PGNNs），它将先验物理模型结构整合到预测过程中。这种方法不仅提高了训练收敛性，还有助于学习基于物理的模型。在这项工作中，我们将GRU集成到PGNN框架中，以获得PG-GRU，并在此基础上采用两步法进行前馈控制设计。首先，我们采用稳定逆技术设计了逆动力学的稳定线性模型。然后，针对逆系统辨识，训练了一个基于残差的GRU。所得到的PG-GRU前馈控制器通过在双质量弹簧阻尼系统上的实际实验进行了验证，结果表明，与线性前馈和基于预览的GRU前馈相比，在积分绝对误差方面，性能大约提高了两倍。", "summary": "本文提出了一种用于基于逆模型前馈控制的物理引导门控循环单元（PG-GRU）。该方法通过将GRU与先验物理模型结构相结合，旨在解决传统GRU在可解释性和过拟合方面的不足。控制设计采用两步法：首先利用稳定逆技术构建稳定的线性逆动力学模型，然后训练一个GRU来识别残差。在双质量弹簧阻尼系统上的实际实验验证表明，PG-GRU前馈控制器在积分绝对误差方面，性能比现有线性前馈和基于预览的GRU前馈方法提高了约两倍。", "keywords": "物理引导, 门控循环单元, 前馈控制, 逆动力学, 混合控制", "comments": "该论文提出了一种创新的混合方法，将GRU的数据驱动能力与物理引导神经网络的鲁棒性和可解释性优势相结合，解决了深度学习在控制系统应用中黑盒模型的问题。其两步设计方法，即利用线性模型处理主要动力学并用GRU处理残差，是一种实用且有效结合模型驱动和数据驱动技术的方式。在实际系统上取得的显著性能提升凸显了其重要的实际应用价值。"}}
{"id": "2507.13549", "title": "Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies", "authors": ["Jim O'Connor", "Nicholas Lorentzen", "Gary B. Parker", "Derin Gezgin"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      IJCCI Conference on Evolutionary Computation and Theory and Applications, 2025", "url": "http://arxiv.org/abs/2507.13549v1", "summary": "This paper investigates the development of high-performance racing\ncontrollers for a newly implemented racing mode within the Xpilot-AI platform,\nutilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By\nleveraging NEAT's capability to evolve both the structure and weights of neural\nnetworks, we develop adaptive controllers that can navigate complex circuits\nunder the challenging space simulation physics of Xpilot-AI, which includes\nelements such as inertia, friction, and gravity. The racing mode we introduce\nsupports flexible circuit designs and allows for the evaluation of multiple\nagents in parallel, enabling efficient controller optimization across\ngenerations. Experimental results demonstrate that our evolved controllers\nachieve up to 32% improvement in lap time compared to the controller's initial\nperformance and develop effective racing strategies, such as optimal cornering\nand speed modulation, comparable to human-like techniques. This work\nillustrates NEAT's effectiveness in producing robust control strategies within\ndemanding game environments and highlights Xpilot-AI's potential as a rigorous\ntestbed for competitive AI controller evolution.", "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "pdf_url": "http://arxiv.org/pdf/2507.13549v1", "cate": "cs.NE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "使用增强拓扑神经进化算法为Xpilot-AI赛车进化神经控制器", "tldr": "本文利用NEAT算法为Xpilot-AI平台开发了高性能赛车控制器，实现了圈速提升和类人驾驶策略。", "motivation": "为Xpilot-AI平台新引入的赛车模式开发高性能的赛车控制器，以应对其复杂的空间模拟物理环境。", "method": "研究团队利用增强拓扑神经进化（NEAT）算法，进化神经网络的结构和权重，开发出自适应控制器。该方法在Xpilot-AI平台的新赛车模式中进行，该模式支持灵活的赛道设计和多智能体并行评估，以实现高效的控制器优化。", "result": "进化的控制器将圈速提高了32%，并发展出有效的赛车策略，例如最佳过弯和速度调节，这些策略与人类驾驶技术相似。", "conclusion": "这项工作表明NEAT在要求严苛的游戏环境中生成鲁棒控制策略的有效性，并突出了Xpilot-AI作为竞争性AI控制器进化的严谨测试平台的潜力。", "translation": "本文研究了在Xpilot-AI平台新实现的赛车模式中，利用增强拓扑神经进化（NEAT）算法开发高性能赛车控制器。通过利用NEAT进化神经网络结构和权重的能力，我们开发了自适应控制器，这些控制器能够在Xpilot-AI具有惯性、摩擦和重力等元素的挑战性空间模拟物理环境下，导航复杂的赛道。我们引入的赛车模式支持灵活的赛道设计，并允许并行评估多个智能体，从而实现跨代的高效控制器优化。实验结果表明，我们进化的控制器与初始性能相比，圈速提高了高达32%，并发展出有效的赛车策略，如最佳过弯和速度调节，这些策略与人类技术相似。这项工作表明了NEAT在要求严苛的游戏环境中生成鲁棒控制策略的有效性，并突出了Xpilot-AI作为竞争性AI控制器进化的严谨测试平台的潜力。", "summary": "本文利用增强拓扑神经进化（NEAT）算法，为Xpilot-AI平台开发了高性能赛车控制器。通过进化神经网络的结构和权重，所开发的控制器能够应对Xpilot-AI复杂的空间模拟物理环境和赛道。实验结果显示，进化的控制器将圈速提升了32%，并形成了如最佳过弯和速度调节等类人驾驶策略。研究强调了NEAT在复杂游戏环境中生成鲁棒控制策略的有效性，并展示了Xpilot-AI作为AI控制器进化测试平台的潜力。", "keywords": "神经进化, NEAT, 神经控制器, Xpilot-AI, 赛车AI", "comments": "该研究创新性地将NEAT算法应用于Xpilot-AI赛车环境，成功实现了控制器性能的显著提升和类人驾驶策略的形成。其重要性在于验证了NEAT在复杂、动态游戏环境中生成鲁棒控制策略的有效性，并为Xpilot-AI作为AI研究测试平台提供了有力支持。"}}
{"id": "2403.18840", "title": "An AI-powered Technology Stack for Solving Many-Electron Field Theory", "authors": ["Pengcheng Hou", "Tao Wang", "Daniel Cerkoney", "Xiansheng Cai", "Zhiyi Li", "Youjin Deng", "Lei Wang", "Kun Chen"], "categories": ["hep-th", "cond-mat.str-el", "cs.LG", "hep-ph", "physics.comp-ph"], "primary_category": "Subjects:       High Energy Physics - Theory (hep-th)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.18840v2", "summary": "Quantum field theory (QFT) for interacting many-electron systems is\nfundamental to condensed matter physics, yet achieving accurate solutions\nconfronts computational challenges in managing the combinatorial complexity of\nFeynman diagrams, implementing systematic renormalization, and evaluating\nhigh-dimensional integrals. We present a unifying framework that integrates QFT\ncomputational workflows with an AI-powered technology stack. A cornerstone of\nthis framework is representing Feynman diagrams as computational graphs, which\nstructures the inherent mathematical complexity and facilitates the application\nof optimized algorithms developed for machine learning and high-performance\ncomputing. Consequently, automatic differentiation, native to these graph\nrepresentations, delivers efficient, fully automated, high-order\nfield-theoretic renormalization procedures. This graph-centric approach also\nenables sophisticated numerical integration; our neural-network-enhanced Monte\nCarlo method, accelerated via massively parallel GPU implementation,\nefficiently evaluates challenging high-dimensional diagrammatic integrals.\nApplying this framework to the uniform electron gas, we determine the\nquasiparticle effective mass to a precision significantly surpassing current\nstate-of-the-art simulations. Our work demonstrates the transformative\npotential of integrating AI-driven computational advances with QFT, opening\nsystematic pathways for solving complex quantum many-body problems across\ndisciplines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.18840v2", "cate": "hep-th", "date": "2024-02-28", "updated": "2025-07-18", "AI": {"title_translation": "一个用于解决多电子场论的AI驱动技术栈", "tldr": "该研究提出了一个由AI驱动的技术栈，通过将费曼图表示为计算图并利用自动微分和神经网络增强的蒙特卡洛方法，高效且高精度地解决了相互作用多电子系统的量子场论计算挑战。", "motivation": "相互作用多电子系统的量子场论是凝聚态物理学的基本理论，但其精确求解面临计算挑战，包括费曼图的组合复杂性、系统重整化的实现以及高维积分的评估。", "method": "该论文提出了一个统一的框架，将量子场论的计算工作流程与一个AI驱动的技术栈相结合。其核心是将费曼图表示为计算图，这有助于构建固有的数学复杂性并应用为机器学习和高性能计算开发的优化算法。通过这种图中心方法，实现了高效、全自动、高阶的场论重整化过程（利用自动微分），并支持复杂的数值积分（通过神经-网络增强的蒙特卡洛方法，并通过大规模并行GPU实现加速）。", "result": "将该框架应用于均匀电子气，确定了准粒子有效质量，其精度显著超越了当前最先进的模拟结果。", "conclusion": "该工作展示了将AI驱动的计算进步与量子场论相结合的变革潜力，为跨学科解决复杂的量子多体问题开辟了系统途径。", "translation": "相互作用多电子系统的量子场论（QFT）是凝聚态物理学的基本理论，但实现精确解在管理费曼图的组合复杂性、实现系统重整化和评估高维积分方面面临计算挑战。我们提出了一个统一的框架，将QFT计算工作流程与一个AI驱动的技术栈相结合。该框架的基石是将费曼图表示为计算图，这构建了固有的数学复杂性，并有助于应用为机器学习和高性能计算开发的优化算法。因此，这些图表示固有的自动微分技术，提供了高效、全自动、高阶的场论重整化过程。这种以图为中心的方法还支持复杂的数值积分；我们的神经网络增强蒙特卡洛方法，通过大规模并行GPU实现加速，有效地评估了具有挑战性的高维图积分。将此框架应用于均匀电子气，我们确定了准粒子有效质量，其精度显著超越了当前最先进的模拟结果。我们的工作展示了将AI驱动的计算进步与QFT相结合的变革潜力，为跨学科解决复杂的量子多体问题开辟了系统途径。", "summary": "该论文提出了一个将AI技术与量子场论（QFT）计算相结合的统一框架，旨在克服多电子系统QFT求解中的计算瓶颈。通过将费曼图表示为计算图，并利用自动微分和神经网络增强的蒙特卡洛方法，该框架能够高效地处理复杂的重整化过程和高维积分。实验证明，该方法在均匀电子气准粒子有效质量的计算上达到了超越现有技术的精度，预示了AI在解决复杂量子多体问题上的巨大潜力。", "keywords": "量子场论, AI, 费曼图, 计算图, 自动微分", "comments": "该论文的创新之处在于将费曼图转化为计算图，并巧妙地引入了机器学习领域的自动微分和神经网络增强的蒙特卡洛方法来解决量子场论中的核心计算难题，如重整化和高维积分。这不仅提高了计算效率和精度，也为量子多体问题的研究开辟了新的范式，具有重要的科学意义和应用前景。"}}
{"id": "2507.13363", "title": "Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop", "authors": ["Atharv Goel", "Mehar Khurana"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13363v1", "summary": "Modern 3D object detection datasets are constrained by narrow class\ntaxonomies and costly manual annotations, limiting their ability to scale to\nopen-world settings. In contrast, 2D vision-language models trained on\nweb-scale image-text pairs exhibit rich semantic understanding and support\nopen-vocabulary detection via natural language prompts. In this work, we\nleverage the maturity and category diversity of 2D foundation models to perform\nopen-vocabulary 3D object detection without any human-annotated 3D labels.\n  Our pipeline uses a 2D vision-language detector to generate text-conditioned\nproposals, which are segmented with SAM and back-projected into 3D using camera\ngeometry and either LiDAR or monocular pseudo-depth. We introduce a geometric\ninflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D\nbounding boxes without training. To simulate adverse real-world conditions, we\nconstruct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes\ndataset.\n  Experiments demonstrate that our method achieves competitive localization\nperformance across multiple settings, including LiDAR-based and purely RGB-D\ninputs, all while remaining training-free and open-vocabulary. Our results\nhighlight the untapped potential of 2D foundation models for scalable 3D\nperception. We open-source our code and resources at\nhttps://github.com/atharv0goel/open-world-3D-det.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13363v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06", "AI": {"title_translation": "只需几何：无梯度开放词汇3D目标检测，无需人工参与", "tldr": "该研究利用2D视觉-语言模型和几何学，实现了无需训练的开放词汇3D目标检测，无需人工标注。", "motivation": "现代3D目标检测数据集受限于狭窄的类别分类和昂贵的手动标注，限制了其在开放世界环境中的扩展能力。2D视觉-语言模型展现出丰富的语义理解能力并支持开放词汇检测。本文旨在利用2D基础模型的成熟度和类别多样性，在无需任何人工标注的3D标签的情况下，执行开放词汇3D目标检测。", "method": "该方法利用2D视觉-语言检测器生成文本条件下的提议，通过SAM进行分割，并利用相机几何和激光雷达或单目伪深度反投影到3D空间。引入了一种基于DBSCAN聚类和旋转卡尺的几何膨胀策略，用于在不进行训练的情况下推断3D边界框。此外，他们构建了一个名为Pseudo-nuScenes的数据集，它是nuScenes数据集的一个雾增强、纯RGB变体，用于模拟恶劣的真实世界条件。", "result": "实验表明，该方法在多种设置下（包括基于激光雷达和纯RGB-D输入）实现了具有竞争力的定位性能，同时保持了免训练和开放词汇的特性。", "conclusion": "结果突出了2D基础模型在可扩展3D感知方面的未开发潜力。", "translation": "现代3D目标检测数据集受限于狭窄的类别分类和昂贵的手动标注，限制了其在开放世界环境中的扩展能力。相比之下，在网络规模图像-文本对上训练的2D视觉-语言模型展现出丰富的语义理解能力，并通过自然语言提示支持开放词汇检测。在本文中，我们利用2D基础模型的成熟度和类别多样性，在无需任何人工标注的3D标签的情况下，执行开放词汇3D目标检测。我们的管道使用2D视觉-语言检测器生成文本条件下的提议，这些提议通过SAM进行分割，并利用相机几何和激光雷达或单目伪深度反投影到3D空间。我们引入了一种基于DBSCAN聚类和旋转卡尺的几何膨胀策略，用于在不进行训练的情况下推断3D边界框。为了模拟不利的真实世界条件，我们构建了一个名为Pseudo-nuScenes的数据集，它是nuScenes数据集的一个雾增强、纯RGB变体。实验表明，我们的方法在多种设置下（包括基于激光雷达和纯RGB-D输入）实现了具有竞争力的定位性能，同时保持了免训练和开放词汇的特性。我们的结果突出了2D基础模型在可扩展3D感知方面的未开发潜力。我们开源了我们的代码和资源，网址为https://github.com/atharv0goel/open-world-3D-det。", "summary": "本文提出了一种新颖的无梯度、免训练、开放词汇3D目标检测方法，该方法利用成熟的2D视觉-语言模型。它使用2D检测器生成文本条件下的提议，通过SAM进行分割，并利用几何和深度将其反投影到3D空间。一种几何膨胀策略用于推断3D边界框。实验表明，该方法在多种输入下均表现出有竞争力的性能，展示了2D模型在无需人工3D标注的情况下实现可扩展3D感知的潜力。", "keywords": "开放词汇3D检测, 2D基础模型, 无梯度, 几何推断, 免训练", "comments": "该研究的创新点在于无需任何3D人工标注或专门的3D训练，将强大的2D视觉-语言模型应用于3D目标检测，实现了真正的开放词汇和可扩展性。“只需几何”的方法简化了问题。其重要性在于解决了3D检测中数据稀缺和标注成本高的重大挑战，为更具可扩展性和灵活性的3D感知系统铺平了道路。尽管具有竞争力，但其性能可能无法与高度专业化、训练密集型的3D检测器在封闭集基准上相媲美。"}}
{"id": "2507.13895", "title": "Application Placement with Constraint Relaxation", "authors": ["Damiano Azzolini", "Marco Duca", "Stefano Forti", "Francesco Gallo", "Antonio Ielo"], "categories": ["cs.LO", "cs.DC"], "primary_category": "Subjects:       Logic in Computer Science (cs.LO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13895v1", "summary": "Novel utility computing paradigms rely upon the deployment of multi-service\napplications to pervasive and highly distributed cloud-edge infrastructure\nresources. Deciding onto which computational nodes to place services in\ncloud-edge networks, as per their functional and non-functional constraints,\ncan be formulated as a combinatorial optimisation problem. Most existing\nsolutions in this space are not able to deal with \\emph{unsatisfiable} problem\ninstances, nor preferences, i.e. requirements that DevOps may agree to relax to\nobtain a solution. In this article, we exploit Answer Set Programming\noptimisation capabilities to tackle this problem. Experimental results in\nsimulated settings show that our approach is effective on lifelike networks and\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13895v1", "cate": "cs.LO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "带约束松弛的应用放置", "tldr": "本文提出了一种利用答案集编程（ASP）优化能力来解决云边网络中多服务应用放置问题的方法，该方法能够处理不可满足的问题实例和可放松的偏好，并在模拟环境中被证明是有效的。", "motivation": "在普适且高度分布式的云边基础设施资源上部署多服务应用时，根据其功能和非功能约束决定将服务放置到哪个计算节点是一个组合优化问题。现有的大多数解决方案无法处理不可满足的问题实例或可放松的偏好。", "method": "本文利用答案集编程（Answer Set Programming, ASP）的优化能力来解决应用放置问题，特别是处理约束松弛。", "result": "在模拟环境中的实验结果表明，所提出的方法在逼真的网络和应用上是有效的。", "conclusion": "本文提出的基于答案集编程的应用放置方法能够有效处理云边网络中带约束松弛的多服务应用部署问题。", "translation": "新型的效用计算范式依赖于将多服务应用程序部署到普适且高度分布式的云边基础设施资源上。根据功能和非功能约束，决定将服务放置在云边网络中的哪些计算节点上，可以被表述为一个组合优化问题。该领域现有的大多数解决方案无法处理不可满足的问题实例，也无法处理偏好，即DevOps可能同意放松以获得解决方案的需求。在本文中，我们利用答案集编程的优化能力来解决这个问题。在模拟设置中的实验结果表明，我们的方法在逼真的网络和应用程序上是有效的。", "summary": "本文提出了一种利用答案集编程（ASP）优化能力解决云边网络中多服务应用放置问题的新方法。针对现有解决方案无法处理不可满足问题实例和可放松偏好的局限性，该方法将应用放置建模为组合优化问题，并利用ASP进行求解。实验结果表明，该方法在模拟的真实网络和应用场景中表现出有效性。", "keywords": "应用放置, 约束松弛, 答案集编程, 云边计算, 组合优化", "comments": "本文的创新点在于利用答案集编程（ASP）来解决带有约束松弛的应用放置问题，这弥补了现有解决方案无法处理不可满足实例和偏好的不足。其重要性在于为日益复杂的云边计算环境中的资源优化配置提供了一种有效的新途径。该方法为处理实际部署中常见的柔性约束提供了理论和实践基础。"}}
{"id": "2507.13938", "title": "Device-Free Localization Using Commercial UWB Transceivers", "authors": ["Hyun Seok Lee"], "categories": ["eess.SP", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures, preprint", "url": "http://arxiv.org/abs/2507.13938v1", "summary": "Recently, commercial ultra-wideband (UWB) transceivers have enabled not only\nmeasuring device-to-device distance but also tracking the position of a\npedestrian who does not carry a UWB device. UWB-based device-free localization\nthat does not require dedicated radar equipment is compatible with existing\nanchor infrastructure and can be reused to reduce hardware deployment costs.\nHowever, it is difficult to estimate the target's position accurately in\nreal-world scenarios due to the low signal-to-noise ratio (SNR) and the\ncluttered environment. In this paper, we propose a deep learning (DL)-assisted\nparticle filter to overcome these challenges. First, the channel impulse\nresponse (CIR) variance is analyzed to capture the variability induced by the\ntarget's movement. Then, a DL-based one-dimensional attention U-Net is used to\nextract only the reflection components caused by the target and suppress the\nnoise components within the CIR variance profile. Finally, multiple\npreprocessed CIR variance profiles are used as input to a particle filter to\nestimate the target's position. Experimental results demonstrate that the\nproposed system is a practical and cost-effective solution for IoT and\nautomotive applications with a root mean square error (RMSE) of about 15 cm and\nan average processing time of 4 ms. Furthermore, comparisons with existing\nstate-of-the-art methods show that the proposed method provides the best\nperformance with reasonable computational costs.", "comment": "8 pages, 10 figures, preprint", "pdf_url": "http://arxiv.org/pdf/2507.13938v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用商用UWB收发器进行无设备定位", "tldr": "本文提出了一种基于深度学习辅助粒子滤波的无设备定位系统，利用商用UWB收发器在复杂环境中实现高精度目标位置估计，RMSE约为15厘米，处理时间为4毫秒。", "motivation": "在低信噪比和杂乱环境下，使用商用超宽带（UWB）收发器进行无设备定位难以准确估计目标位置。", "method": "本文提出了一种深度学习（DL）辅助的粒子滤波器。首先，分析信道脉冲响应（CIR）方差以捕捉目标移动引起的变异性。然后，使用基于DL的一维注意力U-Net提取由目标引起的反射分量并抑制CIR方差剖面中的噪声分量。最后，将多个预处理的CIR方差剖面作为输入，通过粒子滤波器估计目标位置。", "result": "所提出的系统是一种实用且经济高效的物联网和汽车应用解决方案，均方根误差（RMSE）约为15厘米，平均处理时间为4毫秒。与现有最先进的方法相比，该方法以合理的计算成本提供了最佳性能。", "conclusion": "本文提出的基于深度学习辅助粒子滤波的无设备定位系统，能够有效克服复杂环境下的挑战，实现高精度、低成本的目标定位，适用于物联网和汽车应用。", "translation": "最近，商用超宽带（UWB）收发器不仅能够测量设备到设备的距离，还能够跟踪不携带UWB设备的行人的位置。基于UWB的无设备定位不需要专用的雷达设备，与现有锚点基础设施兼容，并且可以重复使用以降低硬件部署成本。然而，由于低信噪比（SNR）和杂乱环境，在实际场景中难以准确估计目标位置。在本文中，我们提出了一种深度学习（DL）辅助的粒子滤波器来克服这些挑战。首先，分析信道脉冲响应（CIR）方差以捕捉由目标移动引起的变异性。然后，使用基于DL的一维注意力U-Net来提取仅由目标引起的反射分量并抑制CIR方差剖面中的噪声分量。最后，将多个预处理的CIR方差剖面作为输入，通过粒子滤波器估计目标位置。实验结果表明，所提出的系统是一种实用且经济高效的物联网和汽车应用解决方案，均方根误差（RMSE）约为15厘米，平均处理时间为4毫秒。此外，与现有最先进的方法相比，所提出的方法以合理的计算成本提供了最佳性能。", "summary": "本文提出了一种基于深度学习（DL）辅助粒子滤波的无设备定位系统，旨在克服在低信噪比和复杂环境下使用商用UWB收发器进行目标定位的挑战。该方法首先分析信道脉冲响应（CIR）方差以捕捉目标移动，随后利用DL-based一维注意力U-Net从CIR方差剖面中提取目标反射分量并抑制噪声。最终，通过粒子滤波器估计目标位置。实验证明，该系统在物联网和汽车应用中表现出约15厘米的RMSE和4毫秒的平均处理时间，并且性能优于现有先进方法。", "keywords": "无设备定位, UWB, 深度学习, 粒子滤波, CIR方差", "comments": "该论文的创新点在于将深度学习与粒子滤波相结合，有效处理了UWB信号在复杂环境下的低信噪比问题，从而实现了高精度的无设备定位。其成本效益和在IoT及汽车领域的应用潜力使其具有重要意义。"}}
{"id": "2507.10397", "title": "Instance space analysis of the capacitated vehicle routing problem", "authors": ["Alessandra M. M. M. Gouvêa", "Nuno Paulos", "Eduardo Uchoa", "Mariá C. V. Nascimento"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10397v2", "summary": "This paper seeks to advance CVRP research by addressing the challenge of\nunderstanding the nuanced relationships between instance characteristics and\nmetaheuristic (MH) performance. We present Instance Space Analysis (ISA) as a\nvaluable tool that allows for a new perspective on the field. By combining the\nISA methodology with a dataset from the DIMACS 12th Implementation Challenge on\nVehicle Routing, our research enabled the identification of 23 relevant\ninstance characteristics. Our use of the PRELIM, SIFTED, and PILOT stages,\nwhich employ dimensionality reduction and machine learning methods, allowed us\nto create a two-dimensional projection of the instance space to understand how\nthe structure of instances affect the behavior of MHs. A key contribution of\nour work is that we provide a projection matrix, which makes it straightforward\nto incorporate new instances into this analysis and allows for a new method for\ninstance analysis in the CVRP field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10397v2", "cate": "cs.AI", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "带有容量限制的车辆路径问题的实例空间分析", "tldr": "本文提出了实例空间分析（ISA）方法，通过结合DIMACS数据集和机器学习技术，识别了CVRP的23个实例特征，并创建了二维投影，以理解实例结构如何影响元启发式算法的性能，同时提供了一个便于新实例分析的投影矩阵。", "motivation": "本文旨在通过理解实例特性与元启发式算法（MH）性能之间的细微关系，推动带有容量限制的车辆路径问题（CVRP）的研究。", "method": "本文提出了实例空间分析（ISA）作为一种工具。研究结合ISA方法与DIMACS第12届车辆路径实施挑战赛的数据集，并利用PRELIM、SIFTED和PILOT阶段，这些阶段采用了降维和机器学习方法，创建了实例空间的二维投影。", "result": "研究识别了23个相关的实例特性，并创建了实例空间的二维投影，以理解实例结构如何影响元启发式算法的行为。一个关键贡献是提供了一个投影矩阵，使得将新实例纳入分析变得简单，并为CVRP领域的实例分析提供了一种新方法。", "conclusion": "本文提出的实例空间分析（ISA）方法，通过结合数据集和机器学习技术，成功识别并投影了CVRP的实例特性，揭示了实例结构对元启发式算法性能的影响，并提供了一个实用的投影矩阵，为CVRP实例分析开辟了新途径。", "translation": "本文旨在通过解决理解实例特性与元启发式（MH）性能之间细微关系的挑战，推进CVRP研究。我们提出了实例空间分析（ISA）作为一种有价值的工具，它为该领域提供了新的视角。通过将ISA方法与来自DIMACS第12届车辆路径实施挑战赛的数据集相结合，我们的研究能够识别出23个相关的实例特性。我们使用PRELIM、SIFTED和PILOT阶段，这些阶段采用了降维和机器学习方法，使我们能够创建实例空间的二维投影，以理解实例结构如何影响MH的行为。我们工作的一个关键贡献是提供了一个投影矩阵，这使得将新实例纳入此分析变得简单，并为CVRP领域的实例分析提供了一种新方法。", "summary": "本文提出并应用了实例空间分析（ISA）方法来研究带有容量限制的车辆路径问题（CVRP）。通过结合ISA与DIMACS数据集，并利用降维和机器学习技术，研究识别了23个关键实例特性，并构建了实例空间的二维投影，以揭示实例结构如何影响元启发式算法的性能。文章还提供了一个投影矩阵，便于未来对新实例进行分析，为CVRP领域的实例分析提供了新工具。", "keywords": "实例空间分析, 容量限制车辆路径问题, 元启发式, 机器学习, 降维", "comments": "该论文通过引入实例空间分析（ISA）为CVRP研究提供了一个新颖的视角，尤其是在理解问题实例特性与元启发式算法性能之间关系方面。其创新点在于结合了ISA方法、机器学习和降维技术来识别和可视化实例空间，并提供了一个可重用的投影矩阵，这对于后续研究和新实例的分析具有重要意义。这有助于研究人员更好地选择或设计适用于特定实例类型的算法。"}}
{"id": "2405.15441", "title": "Statistical and Computational Guarantees of Kernel Max-Sliced Wasserstein Distances", "authors": ["Jie Wang", "March Boedihardjo", "Yao Xie"], "categories": ["stat.ML", "cs.CC", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted by ICML-2025", "url": "http://arxiv.org/abs/2405.15441v4", "summary": "Optimal transport has been very successful for various machine learning\ntasks; however, it is known to suffer from the curse of dimensionality. Hence,\ndimensionality reduction is desirable when applied to high-dimensional data\nwith low-dimensional structures. The kernel max-sliced (KMS) Wasserstein\ndistance is developed for this purpose by finding an optimal nonlinear mapping\nthat reduces data into $1$ dimension before computing the Wasserstein distance.\nHowever, its theoretical properties have not yet been fully developed. In this\npaper, we provide sharp finite-sample guarantees under milder technical\nassumptions compared with state-of-the-art for the KMS $p$-Wasserstein distance\nbetween two empirical distributions with $n$ samples for general\n$p\\in[1,\\infty)$. Algorithm-wise, we show that computing the KMS\n$2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite\nrelaxation (SDR) formulation (which can be solved efficiently in polynomial\ntime) and provide a relaxation gap for the obtained solution. We provide\nnumerical examples to demonstrate the good performance of our scheme for\nhigh-dimensional two-sample testing.", "comment": "Accepted by ICML-2025", "pdf_url": "http://arxiv.org/pdf/2405.15441v4", "cate": "stat.ML", "date": "2024-05-24", "updated": "2025-07-18", "AI": {"title_translation": "核最大切片 Wasserstein 距离的统计和计算保证", "tldr": "本文为核最大切片 Wasserstein 距离提供了严格的有限样本理论保证，证明了其计算的 NP 难性，并提出了一个可有效求解的半定松弛算法。", "motivation": "最佳传输方法在机器学习中表现出色，但受维度诅咒影响；核最大切片 Wasserstein (KMS) 距离为此目的而开发，但其理论性质尚未完全发展。", "method": "本文为核最大切片 p-Wasserstein 距离提供了有限样本保证，放宽了技术假设。在算法方面，证明了计算 KMS 2-Wasserstein 距离是 NP-hard 的，并提出了一个半定松弛 (SDR) 公式，该公式可以在多项式时间内有效求解，并提供了松弛间隙。", "result": "提供了 KMS p-Wasserstein 距离的严格有限样本保证；证明了 KMS 2-Wasserstein 距离计算的 NP-hard 性；提出了有效的半定松弛 (SDR) 算法并提供了松弛间隙；数值示例展示了该方案在高维两样本检验中的良好性能。", "conclusion": "本文在理论上完善了 KMS Wasserstein 距离的有限样本保证，并在计算上提出了一个高效的近似算法来处理其NP-hard问题，为高维数据分析提供了有效的工具。", "translation": "最佳传输在各种机器学习任务中取得了巨大成功；然而，众所周知，它受到维度诅咒的影响。因此，当应用于具有低维结构的高维数据时，降维是可取的。核最大切片 (KMS) Wasserstein 距离为此目的而开发，通过找到一个最优的非线性映射，将数据降至 1 维，然后计算 Wasserstein 距离。然而，其理论性质尚未完全发展。在本文中，我们针对两个具有 n 个样本的经验分布之间的 KMS p-Wasserstein 距离（对于一般 p∈[1,∞)）提供了比现有技术更宽松的技术假设下的精确有限样本保证。在算法方面，我们证明了计算 KMS 2-Wasserstein 距离是 NP-hard 的，然后我们进一步提出了一个半定松弛 (SDR) 公式（可以在多项式时间内有效求解），并为获得的解提供了松弛间隙。我们提供了数值示例来证明我们方案在高维两样本检验中的良好性能。", "summary": "本文深入研究了核最大切片 (KMS) Wasserstein 距离的理论和计算特性。针对其在高维数据分析中缓解维度诅咒的潜力，作者首次提供了在宽松假设下的精确有限样本理论保证。同时，针对 KMS 2-Wasserstein 距离计算的 NP-hard 问题，提出了一种高效的半定松弛 (SDR) 算法并分析了其松弛间隙。数值实验验证了该方法在高维两样本检验中的有效性。", "keywords": "核最大切片 Wasserstein 距离, 维度诅咒, 有限样本保证, NP-hard, 半定松弛, 高维两样本检验", "comments": "本文的创新点在于为核最大切片 Wasserstein 距离提供了严格的理论保证，填补了该领域的一个空白。同时，针对其计算复杂性提出了实用的半定松弛算法，使其在高维机器学习任务中更具可用性。这项工作对于推动最佳传输在高维数据分析中的应用具有重要意义。"}}
{"id": "2507.13555", "title": "Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software", "authors": ["Pragyan K C", "Rambod Ghandiparsi", "Thomas Herron", "John Heaps", "Mitra Bokaei Hosseini"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Accepted at the 33rd IEEE International Requirements Engineering 2025", "url": "http://arxiv.org/abs/2507.13555v1", "summary": "The growing popularity and widespread use of software applications (apps)\nacross various domains have driven rapid industry growth. Along with this\ngrowth, fast-paced market changes have led to constantly evolving software\nrequirements. Such requirements are often grounded in feature requests and\nenhancement suggestions, typically provided by users in natural language (NL).\nHowever, these requests often suffer from defects such as ambiguity and\nincompleteness, making them challenging to interpret. Traditional validation\nmethods (e.g., interviews and workshops) help clarify such defects but are\nimpractical in decentralized environments like open-source software (OSS),\nwhere change requests originate from diverse users on platforms like GitHub.\nThis paper proposes a novel approach leveraging Large Language Models (LLMs) to\ndetect and refine NL defects in feature requests. Our approach automates the\nidentification of ambiguous and incomplete requests and generates clarification\nquestions (CQs) to enhance their usefulness for developers. To evaluate its\neffectiveness, we apply our method to real-world OSS feature requests and\ncompare its performance against human annotations. In addition, we conduct\ninterviews with GitHub developers to gain deeper insights into their\nperceptions of NL defects, the strategies they use to address these defects,\nand the impact of defects on downstream software engineering (SE) tasks.", "comment": "Accepted at the 33rd IEEE International Requirements Engineering 2025", "pdf_url": "http://arxiv.org/pdf/2507.13555v1", "cate": "cs.SE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "揭秘功能请求：利用大型语言模型改进开源软件中的功能请求", "tldr": "本文提出一种利用大型语言模型（LLMs）自动化检测并完善开源软件中自然语言功能请求缺陷的方法，通过生成澄清问题来提高请求的实用性。", "motivation": "软件应用在各领域的普及导致行业快速增长，市场变化带来不断演进的软件需求。这些需求常以自然语言功能请求的形式出现，但往往存在歧义和不完整性等缺陷，难以解释。传统验证方法在开源软件（OSS）等去中心化环境中不切实际，因为请求来自GitHub等平台上的不同用户。", "method": "本文提出一种利用大型语言模型（LLMs）检测并完善功能请求中自然语言缺陷的新方法。该方法自动化识别模糊和不完整的请求，并生成澄清问题（CQs）以提高其对开发人员的实用性。为了评估其有效性，该方法应用于真实的OSS功能请求，并与人工标注进行性能比较。此外，还对GitHub开发人员进行了访谈，以深入了解他们对自然语言缺陷的看法、解决策略以及缺陷对下游软件工程（SE）任务的影响。", "result": "该方法已应用于真实世界的开源软件功能请求，并将其性能与人工标注进行了比较。此外，还对GitHub开发人员进行了访谈，以深入了解他们对自然语言缺陷的看法、解决这些缺陷的策略以及缺陷对下游软件工程任务的影响。抽象中未提及具体的实验结果或访谈发现。", "conclusion": "抽象中未明确提及研究的结论，特别是关于所提方法有效性的具体结论。研究的目的是提高功能请求的实用性，但其实现程度未在摘要中说明。", "translation": "软件应用程序（app）在各个领域日益普及和广泛使用，推动了行业的快速增长。伴随这一增长，快速的市场变化导致软件需求不断演进。这些需求通常基于功能请求和增强建议，通常由用户以自然语言（NL）提供。然而，这些请求常常存在诸如歧义和不完整性等缺陷，使其难以解释。传统的验证方法（例如，访谈和研讨会）有助于澄清此类缺陷，但在开源软件（OSS）等去中心化环境中却不切实际，因为变更请求源自GitHub等平台上的不同用户。本文提出了一种利用大型语言模型（LLMs）检测和完善功能请求中自然语言缺陷的新方法。我们的方法自动化识别模糊和不完整的请求，并生成澄清问题（CQs）以增强其对开发人员的实用性。为了评估其有效性，我们将我们的方法应用于真实的OSS功能请求，并将其性能与人工标注进行比较。此外，我们还对GitHub开发人员进行了访谈，以深入了解他们对自然语言缺陷的看法、他们用于解决这些缺陷的策略以及缺陷对下游软件工程（SE）任务的影响。", "summary": "该论文针对开源软件（OSS）中自然语言功能请求存在的歧义和不完整性缺陷，提出了一种利用大型语言模型（LLMs）进行自动化检测和完善的新方法。鉴于传统验证方法在去中心化OSS环境中的局限性，该方法旨在通过识别缺陷并生成澄清问题（CQs）来提高请求对开发人员的实用性。为评估其有效性，研究将该方法应用于真实的OSS请求并与人工标注进行比较，同时还访谈了GitHub开发人员以获取对缺陷影响和处理策略的见解。", "keywords": "大型语言模型, 功能请求, 开源软件, 自然语言处理, 软件工程", "comments": "该论文的创新之处在于利用大型语言模型（LLMs）来解决开源软件中自然语言功能请求的固有缺陷，这对于传统方法在去中心化环境中难以扩展的问题提供了新的解决方案。其重要性体现在提高软件需求工程的效率和准确性，尤其是在用户贡献驱动的开源项目中。然而，摘要中并未提供所提出方法的具体实验结果或性能数据，这使得读者无法直接评估其有效性。"}}
{"id": "2506.14180", "title": "Non-Overlap-Aware Egocentric Pose Estimation for Collaborative Perception in Connected Autonomy", "authors": ["Hong Huang", "Dongkuan Xu", "Hao Zhang", "Peng Gao"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IROS 2025", "url": "http://arxiv.org/abs/2506.14180v2", "summary": "Egocentric pose estimation is a fundamental capability for multi-robot\ncollaborative perception in connected autonomy, such as connected autonomous\nvehicles. During multi-robot operations, a robot needs to know the relative\npose between itself and its teammates with respect to its own coordinates.\nHowever, different robots usually observe completely different views that\ncontains similar objects, which leads to wrong pose estimation. In addition, it\nis unrealistic to allow robots to share their raw observations to detect\noverlap due to the limited communication bandwidth constraint. In this paper,\nwe introduce a novel method for Non-Overlap-Aware Egocentric Pose Estimation\n(NOPE), which performs egocentric pose estimation in a multi-robot team while\nidentifying the non-overlap views and satifying the communication bandwidth\nconstraint. NOPE is built upon an unified hierarchical learning framework that\nintegrates two levels of robot learning: (1) high-level deep graph matching for\ncorrespondence identification, which allows to identify if two views are\noverlapping or not, (2) low-level position-aware cross-attention graph learning\nfor egocentric pose estimation. To evaluate NOPE, we conduct extensive\nexperiments in both high-fidelity simulation and real-world scenarios.\nExperimental results have demonstrated that NOPE enables the novel capability\nfor non-overlapping-aware egocentric pose estimation and achieves state-of-art\nperformance compared with the existing methods. Our project page at\nhttps://hongh0.github.io/NOPE/.", "comment": "IROS 2025", "pdf_url": "http://arxiv.org/pdf/2506.14180v2", "cate": "cs.RO", "date": "2025-06-17", "updated": "2025-07-18", "AI": {"title_translation": "用于互联自主协作感知的非重叠感知自我姿态估计", "tldr": "本文提出了一种名为NOPE的新方法，用于在多机器人协作感知中进行非重叠感知自我姿态估计，克服了视图差异和通信带宽限制。", "motivation": "在互联自主的多机器人协作感知中，机器人需要知道自身与队友的相对姿态。然而，不同机器人通常观察到完全不同的视图，这会导致错误的姿态估计。此外，由于通信带宽限制，允许机器人共享原始观测以检测重叠是不现实的。", "method": "本文引入了一种名为NOPE（Non-Overlap-Aware Egocentric Pose Estimation）的新方法。NOPE建立在一个统一的分层学习框架之上，该框架集成了两个层次的机器人学习：1）用于对应识别的高级深度图匹配，用于识别两个视图是否重叠；2）用于自我姿态估计的低级位置感知交叉注意力图学习。", "result": "实验结果表明，NOPE实现了非重叠感知自我姿态估计的新能力，并且与现有方法相比，取得了最先进的性能。", "conclusion": "NOPE能够有效解决多机器人协作感知中因视图非重叠和通信带宽受限导致的自我姿态估计问题，并达到了先进水平。", "translation": "自我姿态估计是互联自主中多机器人协作感知的一项基本能力，例如互联自动驾驶汽车。在多机器人操作期间，机器人需要了解自身与其队友相对于自身坐标的相对姿态。然而，不同的机器人通常观察到包含相似对象的完全不同的视图，这会导致错误的姿态估计。此外，由于通信带宽限制，允许机器人共享其原始观测以检测重叠是不现实的。在本文中，我们介绍了一种用于非重叠感知自我姿态估计（NOPE）的新方法，该方法在识别非重叠视图并满足通信带宽限制的同时，在多机器人团队中执行自我姿态估计。NOPE建立在一个统一的分层学习框架之上，该框架集成了两个层次的机器人学习：(1) 用于对应识别的高级深度图匹配，它允许识别两个视图是否重叠，(2) 用于自我姿态估计的低级位置感知交叉注意力图学习。为了评估NOPE，我们在高保真模拟和真实世界场景中进行了广泛的实验。实验结果表明，NOPE实现了非重叠感知自我姿态估计的新能力，并且与现有方法相比，取得了最先进的性能。我们的项目页面位于 https://hongh0.github.io/NOPE/。", "summary": "本文提出了一种新颖的非重叠感知自我姿态估计（NOPE）方法，旨在解决多机器人协作感知中因视图差异和通信带宽受限而导致的姿态估计挑战。NOPE采用统一的分层学习框架，结合深度图匹配来识别视图重叠情况，并利用位置感知交叉注意力图学习进行自我姿态估计。实验结果表明，NOPE在处理非重叠视图方面表现出色，并达到了当前最先进的性能。", "keywords": "自我姿态估计, 多机器人协作, 非重叠感知, 通信带宽, 图学习", "comments": "该论文的创新点在于提出了“非重叠感知”的自我姿态估计方法，有效解决了多机器人协作中因不同视角和通信带宽限制带来的实际挑战。通过集成高层图匹配和低层图学习，NOPE提供了一个实用的解决方案，对于推动互联自主系统在复杂环境中的应用具有重要意义。"}}
{"id": "2507.13830", "title": "Divide and Conquer: A Large-Scale Dataset and Model for Left-Right Breast MRI Segmentation", "authors": ["Maximilian Rokuss", "Benjamin Hamm", "Yannick Kirchhoff", "Klaus Maier-Hein"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted at MICCAI 2025 WOMEN", "url": "http://arxiv.org/abs/2507.13830v1", "summary": "We introduce the first publicly available breast MRI dataset with explicit\nleft and right breast segmentation labels, encompassing more than 13,000\nannotated cases. Alongside this dataset, we provide a robust deep-learning\nmodel trained for left-right breast segmentation. This work addresses a\ncritical gap in breast MRI analysis and offers a valuable resource for the\ndevelopment of advanced tools in women's health. The dataset and trained model\nare publicly available at: www.github.com/MIC-DKFZ/BreastDivider", "comment": "Accepted at MICCAI 2025 WOMEN", "pdf_url": "http://arxiv.org/pdf/2507.13830v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "分而治之：一个用于左右乳腺MRI分割的大规模数据集和模型", "tldr": "引入了首个大规模公开左右乳腺MRI分割数据集和相应的深度学习模型，填补了乳腺MRI分析的空白。", "motivation": "解决乳腺MRI分析中左右乳腺分割标签的空白，并为女性健康领域高级工具的开发提供宝贵资源。", "method": "引入了首个公开可用的、包含超过13,000个标注病例的左右乳腺分割数据集，并提供了一个针对左右乳腺分割训练的鲁棒深度学习模型。", "result": "提供了一个包含超过13,000个标注病例的左右乳腺分割数据集，以及一个用于左右乳腺分割的鲁棒深度学习模型。这些资源已公开可用。", "conclusion": "该工作填补了乳腺MRI分析中的关键空白，并为女性健康领域高级工具的开发提供了宝贵资源。", "translation": "我们引入了首个公开可用的乳腺MRI数据集，该数据集包含明确的左右乳腺分割标签，涵盖了超过13,000个标注病例。除了这个数据集，我们还提供了一个为左右乳腺分割训练的鲁棒深度学习模型。这项工作解决了乳腺MRI分析中的一个关键空白，并为女性健康领域高级工具的开发提供了宝贵资源。数据集和训练模型可在：www.github.com/MIC-DKFZ/BreastDivider 公开获取。", "summary": "该论文介绍了首个公开可用的乳腺MRI数据集，该数据集拥有明确的左右乳腺分割标签，并包含超过13,000个标注病例。同时，研究人员还提供了一个为此数据集训练的鲁棒深度学习模型。这项工作旨在弥补乳腺MRI分析中的关键空白，为女性健康领域先进工具的开发提供重要资源。数据集和模型均已公开。", "keywords": "乳腺MRI分割, 大规模数据集, 深度学习, 左右乳腺, 女性健康", "comments": "该论文的创新之处在于首次公开了一个大规模的、带有明确左右乳腺分割标签的MRI数据集，这填补了现有资源的一个关键空白。其重要性在于为乳腺MRI分析和女性健康领域高级工具的开发提供了宝贵且急需的资源。"}}
{"id": "2403.13740", "title": "Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks", "authors": ["Jon Vadillo", "Roberto Santana", "Jose A. Lozano", "Marta Kwiatkowska"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2403.13740v3", "summary": "The lack of transparency of Deep Neural Networks continues to be a limitation\nthat severely undermines their reliability and usage in high-stakes\napplications. Promising approaches to overcome such limitations are\nPrototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions\nrely on the similarity between the input at hand and a set of prototypical\nrepresentations of the output classes, offering therefore a deep, yet\ntransparent-by-design, architecture. In this paper, we introduce a\nprobabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point\nestimates for the prototypes with probability distributions over their values.\nThis provides not only a more flexible framework for an end-to-end learning of\nprototypes, but can also capture the explanatory uncertainty of the model,\nwhich is a missing feature in previous approaches. In addition, since the\nprototypes determine both the explanation and the prediction, Prob-PSENNs allow\nus to detect when the model is making uninformed or uncertain predictions, and\nto obtain valid explanations for them. Our experiments demonstrate that\nProb-PSENNs provide more meaningful and robust explanations than their\nnon-probabilistic counterparts, while remaining competitive in terms of\npredictive performance, thus enhancing the explainability and reliability of\nthe models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2403.13740v3", "cate": "cs.LG", "date": "2024-03-20", "updated": "2025-07-18", "AI": {"title_translation": "概率自解释神经网络实现不确定性感知解释", "tldr": "本文提出了Prob-PSENN，一种将原型表示为概率分布的自解释神经网络，以捕获解释不确定性并提供更鲁棒的解释。", "motivation": "深度神经网络缺乏透明度，这严重影响了它们在高风险应用中的可靠性和使用。现有方法（如PSENNs）虽然有前景，但未能捕获模型的解释不确定性。", "method": "本文提出了Prob-PSENN，它是PSENNs的一种概率重构。Prob-PSENN用原型的概率分布取代了原型的点估计，从而实现了原型的端到端学习，并能捕获模型的解释不确定性。", "result": "实验表明，Prob-PSENN比非概率对应模型提供了更有意义和更鲁棒的解释，同时在预测性能方面保持竞争力。", "conclusion": "Prob-PSENN通过捕获解释不确定性，显著增强了模型的解释性和可靠性。", "translation": "深度神经网络缺乏透明度仍然是一个严重削弱其在高风险应用中可靠性和使用的限制。有前景的克服此类限制的方法是基于原型的自解释神经网络（PSENNs），其预测依赖于当前输入与输出类别的原型表示集之间的相似性，从而提供了一种深层但设计上透明的架构。在本文中，我们引入了PSENNs的概率重构，称为Prob-PSENN，它用其值的概率分布取代了原型的点估计。这不仅为原型的端到端学习提供了一个更灵活的框架，而且还可以捕获模型的解释不确定性，这是以前方法中缺失的一个特征。此外，由于原型决定了解释和预测，Prob-PSENN使我们能够检测模型何时做出不明确或不确定的预测，并为它们获得有效的解释。我们的实验表明，Prob-PSENN比其非概率对应模型提供了更有意义和更鲁棒的解释，同时在预测性能方面保持竞争力，从而增强了模型的解释性和可靠性。", "summary": "本文提出了一种名为Prob-PSENN的概率自解释神经网络，旨在解决深度神经网络透明度不足的问题。Prob-PSENN通过将原型表示为概率分布而非点估计，不仅实现了原型的端到端学习，更重要的是能够捕获模型解释中的不确定性，这是现有PSENNs所缺乏的功能。实验证明，Prob-PSENN在提供更具意义和鲁棒的解释方面优于传统PSENNs，同时保持了良好的预测性能，从而提升了模型的解释性和可靠性。", "keywords": "自解释神经网络, 概率模型, 不确定性感知, 原型学习, 可解释AI", "comments": "这篇论文的创新点在于将概率论引入自解释神经网络，特别是用概率分布来表示原型，从而解决了现有PSENNs无法量化解释不确定性的问题。这一改进对于高风险应用至关重要，因为它允许模型在做出不确定预测时提供相应的解释不确定性信息，极大地增强了模型的可信度和实用性。该方法在保持预测性能的同时，提升了解释的质量和鲁棒性，具有重要的实践意义。"}}
{"id": "2410.13799", "title": "Machine-Learning Analysis of Radiative Decays to Dark Matter at the LHC", "authors": ["Ernesto Arganda", "Marcela Carena", "Martín de los Rios", "Andres D. Perez", "Duncan Rocha", "Rosa M. Sandá Seoane", "Carlos E. M. Wagner"], "categories": ["hep-ph", "cs.LG", "hep-ex"], "primary_category": "Subjects:       High Energy Physics - Phenomenology (hep-ph)", "pdf_link": null, "comments": "Comments:      26 pages + references, 8 figures, 3 tables, 3 appendices. This version matches the manuscript published in JHEP", "url": "http://arxiv.org/abs/2410.13799v3", "summary": "The search for weakly interacting matter particles (WIMPs) is one of the main\nobjectives of the High Luminosity Large Hadron Collider (HL-LHC). In this work\nwe use Machine-Learning (ML) techniques to explore WIMP radiative decays into a\nDark Matter (DM) candidate in a supersymmetric framework. The minimal\nsupersymmetric WIMP sector includes the lightest neutralino that can provide\nthe observed DM relic density through its co-annihilation with the second\nlightest neutralino and lightest chargino. Moreover, the direct DM detection\ncross section rates fulfill current experimental bounds and provide discovery\ntargets for the same region of model parameters in which the radiative decay of\nthe second lightest neutralino into a photon and the lightest neutralino is\nenhanced. This strongly motivates the search for radiatively decaying\nneutralinos which, however, suffers from strong backgrounds. We investigate the\nLHC reach in the search for these radiatively decaying particles by means of\ncut-based and ML methods and estimate its discovery potential in this\nwell-motivated, new physics scenario. We demonstrate that using ML techniques\nwould enable access to most of the parameter space unexplored by other\nsearches.", "comment": "26 pages + references, 8 figures, 3 tables, 3 appendices. This\n  version matches the manuscript published in JHEP", "pdf_url": "http://arxiv.org/pdf/2410.13799v3", "cate": "hep-ph", "date": "2024-10-17", "updated": "2025-07-18", "AI": {"title_translation": "大型强子对撞机中辐射衰变至暗物质的机器学习分析", "tldr": "该研究利用机器学习技术探索大型强子对撞机（LHC）中超对称框架下WIMP粒子辐射衰变至暗物质候选体（最轻中微子）的潜力，并证明机器学习方法能够有效提升对未探索参数空间的探测能力，克服强背景噪声问题。", "motivation": "在超对称框架中，最轻中微子可以通过与第二轻中微子和最轻荷电粒子的共湮灭提供观测到的暗物质残余密度，并且其直接暗物质探测截面率符合当前实验限制。同时，第二轻中微子辐射衰变为光子和最轻中微子的过程被增强，这强烈促使对辐射衰变中微子的搜索，尽管其面临强大的背景噪声。", "method": "研究人员通过基于截止（cut-based）和机器学习（ML）方法调查了LHC在搜索这些辐射衰变粒子方面的可及范围，并估计了其在这一动机充分的新物理情景中的发现潜力。", "result": "研究结果表明，使用机器学习技术将能够访问大多数其他搜索未探索的参数空间。", "conclusion": "机器学习技术能够显著提高在LHC上搜索辐射衰变至暗物质粒子的能力，使其能够探测到传统方法难以触及的参数空间，从而有助于发现新的物理现象。", "translation": "弱相互作用大质量粒子（WIMP）的搜索是高亮度大型强子对撞机（HL-LHC）的主要目标之一。在这项工作中，我们使用机器学习（ML）技术来探索超对称框架中WIMP辐射衰变到暗物质（DM）候选体的情况。最小超对称WIMP扇区包括最轻中微子，它可以通过与第二轻中微子和最轻荷电粒子的共湮灭提供观测到的暗物质残余密度。此外，直接暗物质探测截面率符合当前的实验限制，并为模型参数的相同区域提供了发现目标，在该区域中，第二轻中微子辐射衰变为光子和最轻中微子的过程得到增强。这强烈促使对辐射衰变中微子的搜索，然而，这种搜索受到强大背景噪声的影响。我们通过基于截止（cut-based）和机器学习（ML）方法调查了LHC在搜索这些辐射衰变粒子方面的可及范围，并估计了其在这一动机充分的新物理情景中的发现潜力。我们证明，使用机器学习技术将能够访问大多数其他搜索未探索的参数空间。", "summary": "该论文探讨了在大型强子对撞机（LHC）中利用机器学习技术搜索弱相互作用大质量粒子（WIMPs）辐射衰变到暗物质（DM）候选体的可能性。研究聚焦于超对称框架中最轻中微子的辐射衰变，该过程因其与暗物质观测的一致性而具有高度动机。面对强大的背景噪声，作者比较了传统的基于截止的方法和机器学习方法，并证明机器学习能有效提升LHC对未探索参数空间的探测能力，从而提高发现新物理的潜力。", "keywords": "机器学习, 辐射衰变, 暗物质, 大型强子对撞机, 超对称性", "comments": "这篇论文的创新点在于将机器学习技术应用于在高背景噪声环境下搜索LHC中的辐射衰变中微子。其重要性体现在展示了机器学习在粒子物理学中，特别是在暗物质搜索方面，能够显著扩展传统搜索的探测范围，从而为新物理的发现提供新的途径。这对于未来HL-LHC的数据分析具有重要指导意义。"}}
{"id": "2507.14049", "title": "EdgeVLA: Efficient Vision-Language-Action Models", "authors": ["Paweł Budzianowski", "Wesley Maa", "Matthew Freed", "Jingxiang Mo", "Winston Hsiao", "Aaron Xie", "Tomasz Młoduchowski", "Viraj Tipnis", "Benjamin Bolte"], "categories": ["cs.RO", "cs.CL"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14049v1", "summary": "Vision-Language Models (VLMs) have emerged as a promising approach to address\nthe data scarcity challenge in robotics, enabling the development of\ngeneralizable visuomotor control policies. While models like OpenVLA showcase\nthe potential of this paradigm, deploying large-scale VLMs on\nresource-constrained mobile manipulation systems remains a significant hurdle.\nThis paper introduces Edge VLA (EVLA), a novel approach designed to\nsignificantly enhance the inference speed of Vision-Language-Action (VLA)\nmodels. EVLA maintains the representational power of these models while\nenabling real-time performance on edge devices. We achieve this through two key\ninnovations: 1) Eliminating the autoregressive requirement for end-effector\nposition prediction, leading to a 7x speedup in inference, and 2) Leveraging\nthe efficiency of Small Language Models (SLMs), demonstrating comparable\ntraining performance to larger models with significantly reduced computational\ndemands. Our early results demonstrate that EVLA achieves comparable training\ncharacteristics to OpenVLA while offering substantial gains in inference speed\nand memory efficiency. We release our model checkpoints and training\n\\href{https://github.com/kscalelabs/evla }{codebase} to foster further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14049v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "EdgeVLA: 高效视觉-语言-动作模型", "tldr": "EdgeVLA通过消除自回归预测和利用小型语言模型，显著提升了视觉-语言-动作模型在边缘设备上的推理速度和内存效率，同时保持了性能。", "motivation": "大型视觉-语言模型（VLM）在机器人领域展现出解决数据稀缺和实现通用视觉运动控制的潜力，但将其部署到资源受限的移动操作系统上仍面临显著挑战。", "method": "EdgeVLA通过两项关键创新实现：1) 消除末端执行器位置预测的自回归需求，从而将推理速度提高7倍；2) 利用小型语言模型（SLM）的效率，在显著降低计算需求的同时，展现出与大型模型相当的训练性能。", "result": "早期结果表明，EdgeVLA在训练特性上与OpenVLA相当，但在推理速度和内存效率方面取得了显著提升。", "conclusion": "EdgeVLA成功地使视觉-语言-动作模型在边缘设备上实现实时性能，解决了大型VLM部署的资源限制问题。", "translation": "视觉-语言模型（VLM）已成为解决机器人领域数据稀缺挑战的一种有前景的方法，能够开发通用的视觉运动控制策略。虽然像OpenVLA这样的模型展示了这种范式的潜力，但将大型VLM部署到资源受限的移动操作系统上仍然是一个重大障碍。本文介绍了EdgeVLA（EVLA），一种旨在显著提高视觉-语言-动作（VLA）模型推理速度的新方法。EVLA在保持这些模型表示能力的同时，实现了在边缘设备上的实时性能。我们通过两项关键创新实现了这一点：1) 消除了末端执行器位置预测的自回归要求，从而使推理速度提高了7倍；2) 利用小型语言模型（SLM）的效率，在显著降低计算需求的同时，展现出与大型模型相当的训练性能。我们的早期结果表明，EVLA实现了与OpenVLA相当的训练特性，同时在推理速度和内存效率方面获得了显著提升。我们发布了模型检查点和训练代码库，以促进进一步研究。", "summary": "本文提出了EdgeVLA（EVLA），一种旨在解决大型视觉-语言-动作（VLA）模型在资源受限边缘设备上部署效率问题的新方法。通过取消末端执行器位置预测的自回归要求和利用小型语言模型，EdgeVLA实现了7倍的推理速度提升，并显著提高了内存效率，同时在训练性能上与现有大型模型（如OpenVLA）保持了可比性，从而使VLA模型能够在边缘设备上实现实时运行。", "keywords": "视觉-语言-动作模型, 边缘计算, 机器人, 推理速度, 小型语言模型", "comments": "EdgeVLA的创新性在于其解决了VLA模型在边缘设备上部署的关键瓶颈，通过结构优化（消除自回归）和模型选择（SLM）实现了显著的效率提升。这对于推动机器人技术在实际应用中的普及具有重要意义，尤其是在计算资源有限的场景下。其开源代码库也有助于社区进一步研究和发展。"}}
{"id": "2507.13485", "title": "Neural Architecture Search with Mixed Bio-inspired Learning Rules", "authors": ["Imane Hamzaoui", "Riyadh Baghdadi"], "categories": ["cs.NE", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      ECAI 2025", "url": "http://arxiv.org/abs/2507.13485v1", "summary": "Bio-inspired neural networks are attractive for their adversarial robustness,\nenergy frugality, and closer alignment with cortical physiology, yet they often\nlag behind back-propagation (BP) based models in accuracy and ability to scale.\nWe show that allowing the use of different bio-inspired learning rules in\ndifferent layers, discovered automatically by a tailored\nneural-architecture-search (NAS) procedure, bridges this gap. Starting from\nstandard NAS baselines, we enlarge the search space to include bio-inspired\nlearning rules and use NAS to find the best architecture and learning rule to\nuse in each layer. We show that neural networks that use different bio-inspired\nlearning rules for different layers have better accuracy than those that use a\nsingle rule across all the layers. The resulting NN that uses a mix of\nbio-inspired learning rules sets new records for bio-inspired models: 95.16% on\nCIFAR-10, 76.48% on CIFAR-100, 43.42% on ImageNet16-120, and 60.51% top-1 on\nImageNet. In some regimes, they even surpass comparable BP-based networks while\nretaining their robustness advantages. Our results suggest that layer-wise\ndiversity in learning rules allows better scalability and accuracy, and\nmotivates further research on mixing multiple bio-inspired learning rules in\nthe same network.", "comment": "ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13485v1", "cate": "cs.NE", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "混合生物启发学习规则的神经架构搜索", "tldr": "该研究通过神经架构搜索（NAS）自动发现并混合使用不同的生物启发学习规则，显著提高了生物启发神经网络的准确性和可扩展性，使其性能超越了单一规则网络，在某些情况下甚至超过了基于反向传播的网络。", "motivation": "生物启发神经网络在对抗鲁棒性、能效和生理学一致性方面具有吸引力，但其准确性和可扩展性通常落后于基于反向传播（BP）的模型。", "method": "通过定制的神经架构搜索（NAS）程序，将生物启发学习规则纳入搜索空间，以自动发现每个层最佳的架构和学习规则。", "result": "使用混合生物启发学习规则的神经网络比使用单一规则的网络具有更高的准确性。在CIFAR-10上达到95.16%，CIFAR-100上达到76.48%，ImageNet16-120上达到43.42%，ImageNet上达到60.51%的top-1准确率，刷新了生物启发模型的记录。在某些情况下，甚至超越了可比较的基于BP的网络，同时保持了鲁棒性优势。", "conclusion": "层级学习规则的多样性可以实现更好的可扩展性和准确性，并激励了在同一网络中混合多种生物启发学习规则的进一步研究。", "translation": "生物启发神经网络因其对抗鲁棒性、节能性和与皮层生理学更紧密的对齐而具有吸引力，但它们在准确性和扩展能力方面通常落后于基于反向传播（BP）的模型。我们表明，通过定制的神经架构搜索（NAS）程序自动发现并允许在不同层中使用不同的生物启发学习规则，可以弥补这一差距。从标准的NAS基线开始，我们扩大搜索空间以包含生物启发学习规则，并使用NAS来找到在每一层中使用的最佳架构和学习规则。我们展示了在不同层中使用不同生物启发学习规则的神经网络比在所有层中使用单一规则的神经网络具有更好的准确性。由此产生的、使用混合生物启发学习规则的神经网络为生物启发模型设定了新记录：在CIFAR-10上达到95.16%，在CIFAR-100上达到76.48%，在ImageNet16-120上达到43.42%，在ImageNet上达到60.51%的top-1准确率。在某些情况下，它们甚至超越了可比较的基于BP的网络，同时保留了其鲁棒性优势。我们的结果表明，学习规则的层级多样性可以实现更好的可扩展性和准确性，并激发了对在同一网络中混合多种生物启发学习规则的进一步研究。", "summary": "这项研究通过引入一种定制的神经架构搜索（NAS）方法，允许在生物启发神经网络的不同层中自动选择和混合使用不同的生物启发学习规则。该方法显著提升了生物启发模型的准确性和可扩展性，使其性能超越了以往的单一规则生物启发网络，并在某些场景下甚至能与基于反向传播（BP）的模型相媲美，同时保持其固有的鲁棒性优势。研究结果强调了学习规则层级多样性的重要性。", "keywords": "生物启发学习规则, 神经架构搜索, 混合学习, 鲁棒性, 准确性", "comments": "这篇论文的创新点在于将神经架构搜索（NAS）应用于生物启发神经网络的学习规则层面，通过自动发现并组合不同的生物启发学习规则，显著提升了这类模型此前受限的准确性和可扩展性。其重要性在于，它不仅弥补了生物启发网络与传统BP网络之间的性能差距，甚至在某些方面实现了超越，同时保留了生物启发网络固有的鲁棒性和能效优势。这为开发更高效、更鲁棒的下一代神经网络提供了新的方向，并可能推动生物启发AI领域的发展。"}}
{"id": "2507.13984", "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models", "authors": ["Quang-Binh Nguyen", "Minh Luu", "Quang Nguyen", "Anh Tran", "Khoi Nguyen"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025", "url": "http://arxiv.org/abs/2507.13984v1", "summary": "Disentangling content and style from a single image, known as content-style\ndecomposition (CSD), enables recontextualization of extracted content and\nstylization of extracted styles, offering greater creative flexibility in\nvisual synthesis. While recent personalization methods have explored the\ndecomposition of explicit content style, they remain tailored for diffusion\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\npromising alternative with a next-scale prediction paradigm, achieving\nperformance comparable to that of diffusion models. In this paper, we explore\nVAR as a generative framework for CSD, leveraging its scale-wise generation\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\nmethod that introduces three key innovations: (1) a scale-aware alternating\noptimization strategy that aligns content and style representation with their\nrespective scales to enhance separation, (2) an SVD-based rectification method\nto mitigate content leakage into style representations, and (3) an Augmented\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\nthis task, we introduce CSD-100, a dataset specifically designed for\ncontent-style decomposition, featuring diverse subjects rendered in various\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\napproaches, achieving superior content preservation and stylization fidelity.", "comment": "Accepted to ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2507.13984v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CSD-VAR: 视觉自回归模型中的内容-风格分解", "tldr": "CSD-VAR是一种新的视觉自回归模型，用于图像的内容-风格分解，通过规模感知优化、SVD修正和增强的K-V记忆实现更好的分离和内容保留，并在新数据集CSD-100上表现优异。", "motivation": "现有的内容-风格分解（CSD）方法主要针对扩散模型，但视觉自回归模型（VAR）作为一种有前景的替代方案，也需要探索其在该任务中的应用，以实现更大的视觉合成创意灵活性。", "method": "本文提出了CSD-VAR，一种基于视觉自回归模型的内容-风格分解方法。该方法引入了三项关键创新：1) 规模感知交替优化策略，使内容和风格表示与其各自的尺度对齐以增强分离；2) 基于SVD的校正方法，用于减轻内容泄露到风格表示中；3) 增强的键值（K-V）记忆，以提高内容身份保留。此外，论文还引入了CSD-100数据集，一个专门为内容-风格分解设计的基准数据集。", "result": "实验表明，CSD-VAR优于现有方法，实现了卓越的内容保留和风格化保真度。", "conclusion": "CSD-VAR作为一种新的视觉自回归模型，通过创新的分解策略，在内容-风格分解任务上取得了优异的表现，并引入了专门的基准数据集CSD-100，为该领域的研究提供了新的方向和工具。", "translation": "从单一图像中分离内容和风格，即内容-风格分解（CSD），能够重新语境化提取的内容并风格化提取的风格，为视觉合成提供了更大的创意灵活性。尽管最近的个性化方法探索了显式内容风格的分解，但它们仍然是为扩散模型量身定制的。与此同时，视觉自回归建模（VAR）作为一种具有下一尺度预测范式的有前景的替代方案出现，其性能可与扩散模型相媲美。在本文中，我们探索VAR作为CSD的生成框架，利用其尺度生成过程来改进分解。为此，我们提出了CSD-VAR，一种引入三项关键创新的新方法：(1) 规模感知交替优化策略，将内容和风格表示与其各自的尺度对齐以增强分离；(2) 基于SVD的校正方法，以减轻内容泄露到风格表示中；以及(3) 增强的键值（K-V）记忆，以增强内容身份保留。为了对这项任务进行基准测试，我们引入了CSD-100，一个专门为内容-风格分解设计的数据集，其特点是包含各种艺术风格渲染的多样主题。实验表明CSD-VAR优于现有方法，实现了卓越的内容保留和风格化保真度。", "summary": "CSD-VAR提出了一种基于视觉自回归模型（VAR）的内容-风格分解（CSD）新方法，旨在解决现有CSD方法主要针对扩散模型的问题，并利用VAR的尺度生成过程改进分解。该方法包含三项关键创新：规模感知交替优化策略、基于SVD的校正方法以及增强的键值（K-V）记忆，以提升内容与风格的分离度和内容身份保留。为评估该任务，论文还引入了CSD-100数据集。实验结果表明，CSD-VAR在内容保留和风格化保真度方面均优于现有方法。", "keywords": "内容-风格分解, 视觉自回归模型, 图像合成, CSD-VAR, 风格化", "comments": "该论文创新性地将内容-风格分解任务应用于视觉自回归模型，并提出了多项关键技术以优化分解效果，特别是SVD修正和增强的K-V记忆，有效解决了内容泄露和身份保留问题。引入专门的CSD-100数据集对于该领域的研究具有重要意义，为未来的基准测试提供了标准。"}}
{"id": "2402.09816", "title": "Mind the Modality Gap: Towards a Remote Sensing Vision-Language Model via Cross-modal Alignment", "authors": ["Angelos Zavras", "Dimitrios Michail", "Begüm Demir", "Ioannis Papoutsis"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the ISPRS Journal of Photogrammetry and Remote Sensing. Our code implementation and weights for all experiments are publicly available at this https URL", "url": "http://arxiv.org/abs/2402.09816v2", "summary": "Deep Learning (DL) is undergoing a paradigm shift with the emergence of\nfoundation models. In this work, we focus on Contrastive Language-Image\nPre-training (CLIP), a Vision-Language foundation model that achieves high\naccuracy across various image classification tasks and often rivals fully\nsupervised baselines, despite not being explicitly trained for those tasks.\nNevertheless, there are still domains where zero-shot CLIP performance is far\nfrom optimal, such as Remote Sensing (RS) and medical imagery. These domains do\nnot only exhibit fundamentally different distributions compared to natural\nimages, but also commonly rely on complementary modalities, beyond RGB, to\nderive meaningful insights. To this end, we propose a methodology to align\ndistinct RS image modalities with the visual and textual modalities of CLIP.\nOur two-stage procedure addresses the aforementioned distribution shift,\nextends the zero-shot capabilities of CLIP and enriches CLIP's shared embedding\nspace with domain-specific knowledge. Initially, we robustly fine-tune CLIP\naccording to the PAINT (Ilharco et al., 2022) patching protocol, in order to\ndeal with the distribution shift. Building upon this foundation, we facilitate\nthe cross-modal alignment of a RS modality encoder by distilling knowledge from\nthe CLIP visual and textual encoders. We empirically show that both patching\nand cross-modal alignment translate to significant performance gains, across\nseveral RS imagery classification and cross-modal retrieval benchmark datasets.\nNotably, these enhancements are achieved without the reliance on textual\ndescriptions, without introducing any task-specific parameters, without\ntraining from scratch and without catastrophic forgetting. We make our code\nimplementation and weights for all experiments publicly available at\nhttps://github.com/Orion-AI-Lab/MindTheModalityGap.", "comment": "Accepted at the ISPRS Journal of Photogrammetry and Remote Sensing.\n  Our code implementation and weights for all experiments are publicly\n  available at https://github.com/Orion-AI-Lab/MindTheModalityGap", "pdf_url": "http://arxiv.org/pdf/2402.09816v2", "cate": "cs.CV", "date": "2024-02-15", "updated": "2025-07-18", "AI": {"title_translation": "注意模态鸿沟：通过跨模态对齐实现遥感视觉-语言模型", "tldr": "本文提出一种两阶段方法，通过微调和知识蒸馏，使CLIP适应遥感图像，并在遥感分类和跨模态检索任务中取得显著性能提升，无需文本描述和从头训练。", "motivation": "CLIP在遥感（RS）和医学图像等领域零样本性能不佳，因为这些领域图像分布与自然图像不同，且常依赖RGB以外的互补模态来获得有意义的见解。", "method": "本文提出一种两阶段方法来对齐遥感图像模态与CLIP的视觉和文本模态：1. 根据PAINT协议对CLIP进行鲁棒性微调，以处理分布偏移。2. 通过从CLIP视觉和文本编码器中蒸馏知识，促进遥感模态编码器的跨模态对齐。", "result": "在多个遥感图像分类和跨模态检索基准数据集上，补丁化（patching）和跨模态对齐都带来了显著的性能提升。这些增强是在不依赖文本描述、不引入任何任务特定参数、不从头训练且无灾难性遗忘的情况下实现的。", "conclusion": "通过提出的两阶段跨模态对齐方法，可以有效弥合CLIP在遥感领域存在的模态鸿沟，显著提升其在该领域的零样本能力和领域特定知识。", "translation": "深度学习（DL）正随着基础模型的出现而经历范式转变。在这项工作中，我们关注对比语言-图像预训练（CLIP），一个视觉-语言基础模型，它在各种图像分类任务中实现了高精度，并且经常与完全监督的基线相媲美，尽管它没有为这些任务进行明确训练。然而，在遥感（RS）和医学图像等领域，零样本CLIP的性能远非最佳。这些领域不仅表现出与自然图像根本不同的分布，而且通常依赖RGB以外的互补模态来获得有意义的见解。为此，我们提出一种方法，将不同的遥感图像模态与CLIP的视觉和文本模态对齐。我们的两阶段过程解决了上述分布偏移问题，扩展了CLIP的零样本能力，并用领域特定知识丰富了CLIP的共享嵌入空间。首先，我们根据PAINT（Ilharco et al., 2022）补丁协议对CLIP进行鲁棒性微调，以处理分布偏移。在此基础上，我们通过从CLIP视觉和文本编码器中蒸馏知识来促进遥感模态编码器的跨模态对齐。我们通过经验证明，补丁化和跨模态对齐在多个遥感图像分类和跨模态检索基准数据集上都带来了显著的性能提升。值得注意的是，这些增强是在不依赖文本描述、不引入任何任务特定参数、不从头训练且无灾难性遗忘的情况下实现的。我们的代码实现和所有实验的权重已在https://github.com/Orion-AI-Lab/MindTheModalityGap 公开。", "summary": "本文提出一种两阶段方法来解决CLIP在遥感（RS）领域存在的“模态鸿沟”问题。针对RS图像与自然图像的分布差异以及对多模态数据的依赖，作者首先通过PAINT协议对CLIP进行微调以适应分布偏移，然后通过知识蒸馏将RS模态编码器与CLIP的视觉和文本编码器对齐。实验结果表明，该方法显著提升了CLIP在RS分类和跨模态检索任务上的性能，且无需文本描述、不引入额外参数、不从头训练并避免了灾难性遗忘。", "keywords": "遥感, 视觉-语言模型, CLIP, 跨模态对齐, 知识蒸馏", "comments": "本文提出了一种新颖且实用的方法来弥合预训练视觉-语言模型（如CLIP）与特定领域（如遥感）之间的模态鸿沟。其创新之处在于结合了鲁棒性微调和知识蒸馏，有效处理了领域分布偏移和多模态对齐问题。更重要的是，该方法在不依赖文本、不增加任务特定参数、不从头训练的情况下实现了显著性能提升，展现了其高效性和普适性，对于将基础模型应用于专业领域具有重要指导意义。"}}
{"id": "2505.07363", "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems", "authors": ["Serge Massar"], "categories": ["nlin.CD", "cs.LG", "physics.data-an"], "primary_category": "Subjects:       Chaotic Dynamics (nlin.CD)", "pdf_link": null, "comments": "Comments:      9 pages, 1 figure", "url": "http://arxiv.org/abs/2505.07363v3", "summary": "We propose a method for training dynamical systems governed by Lagrangian\nmechanics using Equilibrium Propagation. Our approach extends Equilibrium\nPropagation - initially developed for energy-based models - to dynamical\ntrajectories by leveraging the principle of action extremization. Training is\nachieved by gently nudging trajectories toward desired targets and measuring\nhow the variables conjugate to the parameters to be trained respond. This\nmethod is particularly suited to systems with periodic boundary conditions or\nfixed initial and final states, enabling efficient parameter updates without\nrequiring explicit backpropagation through time. In the case of periodic\nboundary conditions, this approach yields the semiclassical limit of Quantum\nEquilibrium Propagation. Applications to systems with dissipation are also\ndiscussed.", "comment": "9 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2505.07363v3", "cate": "nlin.CD", "date": "2025-05-12", "updated": "2025-07-18", "AI": {"title_translation": "用于拉格朗日动力系统学习的平衡传播", "tldr": "本文提出了一种使用平衡传播来训练由拉格朗日力学控制的动力系统的方法，通过轨迹微调和共轭变量测量实现高效参数更新，无需时间反向传播。", "motivation": "论文旨在提出一种训练由拉格朗日力学控制的动力系统的方法，以解决传统训练方法可能存在的效率问题。", "method": "该方法通过利用作用量极值原理，将最初为基于能量模型开发的平衡传播扩展到动力学轨迹。训练过程通过轻微推动轨迹向目标移动，并测量与待训练参数共轭的变量的响应来实现。", "result": "该方法特别适用于具有周期性边界条件或固定初始和最终状态的系统，能够实现高效的参数更新，而无需明确的时间反向传播。在周期性边界条件下，该方法产生了量子平衡传播的半经典极限。", "conclusion": "所提出的平衡传播方法能够有效训练由拉格朗日力学控制的动力系统，尤其适用于特定边界条件的系统，并能避免时间反向传播的复杂性，在特定情况下还能推导出量子平衡传播的半经典极限。", "translation": "我们提出了一种使用平衡传播来训练由拉格朗日力学控制的动力系统的方法。我们的方法通过利用作用量极值原理，将最初为基于能量模型开发的平衡传播扩展到动力学轨迹。训练通过轻微推动轨迹向所需目标移动，并测量与待训练参数共轭的变量如何响应来实现。这种方法特别适用于具有周期性边界条件或固定初始和最终状态的系统，能够实现高效的参数更新，而无需明确的时间反向传播。在周期性边界条件下，这种方法产生了量子平衡传播的半经典极限。论文还讨论了在耗散系统中的应用。", "summary": "本文提出了一种将平衡传播应用于拉格朗日动力系统学习的新方法。该方法通过利用作用量极值原理，将平衡传播从能量模型扩展到动力学轨迹。训练过程通过微调轨迹并测量共轭变量的响应来实现，从而实现高效的参数更新，且无需时间反向传播。该方法特别适用于具有周期性边界条件或固定初始和最终状态的系统，并在周期性边界条件下推导出量子平衡传播的半经典极限。", "keywords": "平衡传播, 拉格朗日动力系统, 作用量极值, 无时间反向传播, 周期性边界条件", "comments": "这篇论文的创新点在于将平衡传播（通常用于能量模型）扩展到更复杂的拉格朗日动力系统，并通过巧妙地利用作用量极值原理和共轭变量测量，避免了在时间动力学系统训练中常见的复杂的时间反向传播问题。这种方法对于处理具有特定边界条件的物理系统尤其重要，为这些系统提供了更高效、更直观的学习机制。"}}
{"id": "2507.14032", "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models", "authors": ["Lam Nguyen", "Erika Barcelos", "Roger French", "Yinghui Wu"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to the 24th International Semantic Web Conference Research Track (ISWC 2025)", "url": "http://arxiv.org/abs/2507.14032v1", "summary": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.", "comment": "Accepted to the 24th International Semantic Web Conference Research\n  Track (ISWC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.14032v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "KROMA：基于知识检索和大型语言模型的本体匹配", "tldr": "KROMA是一个新颖的本体匹配框架，利用RAG管道中的大型语言模型，通过知识检索和本体细化来增强语义上下文，超越了传统和基于LLM的方法，同时保持通信开销可比。", "motivation": "现有的本体匹配系统依赖手工规则或专业模型，适应性有限，而本体匹配是语义互操作性的基石。", "method": "KROMA是一个新颖的本体匹配框架，它在检索增强生成（RAG）管道中利用大型语言模型（LLMs），通过结构、词汇和定义知识动态丰富本体匹配任务的语义上下文。为优化性能和效率，KROMA集成了基于双相似性的概念匹配和轻量级本体细化步骤，以修剪候选概念并显著减少调用LLM的通信开销。", "result": "实验表明，将知识检索与上下文增强的LLM结合显著增强了本体匹配，优于经典的本体匹配系统和前沿的基于LLM的方法，同时保持通信开销可比。", "conclusion": "该研究突出了所提出的优化技术（目标知识检索、提示丰富和本体细化）对于大规模本体匹配的可行性和益处。", "translation": "本体匹配（OM）是语义互操作性的基石任务，然而现有系统通常依赖手工规则或适应性有限的专用模型。我们提出了KROMA，一个新颖的OM框架，它在检索增强生成（RAG）管道中利用大型语言模型（LLMs），通过结构、词汇和定义知识动态丰富OM任务的语义上下文。为了优化性能和效率，KROMA集成了基于双相似性的概念匹配和轻量级本体细化步骤，这修剪了候选概念并显著减少了调用LLM的通信开销。通过在多个基准数据集上的实验，我们表明将知识检索与上下文增强的LLMs结合显著增强了本体匹配，优于经典的OM系统和前沿的基于LLM的方法，同时保持通信开销可比。我们的研究突出了所提出的优化技术（目标知识检索、提示丰富和本体细化）对于大规模本体匹配的可行性和益处。", "summary": "KROMA是一个创新的本体匹配框架，它结合了大型语言模型（LLMs）和检索增强生成（RAG）管道，以动态丰富本体匹配的语义上下文。通过集成基于双相似性的概念匹配和本体细化步骤，KROMA有效地减少了LLM调用开销。实验证明，KROMA在性能上超越了传统和先进的LLM本体匹配系统，同时保持了可比的通信开销，证明了其优化技术在大规模本体匹配中的有效性。", "keywords": "本体匹配, 大型语言模型, 知识检索, RAG, 语义互操作性", "comments": "KROMA的创新之处在于其将大型语言模型与检索增强生成（RAG）管道相结合，并引入了双相似性匹配和本体细化等优化技术，有效解决了传统本体匹配系统的适应性问题和LLM引入的高开销问题。这对于推动语义互操作性领域的发展具有重要意义。"}}
{"id": "2507.13742", "title": "Search-Optimized Quantization in Biomedical Ontology Alignment", "authors": ["Oussama Bouaggad", "Natalia Grabar"], "categories": ["cs.LG", "cs.AI", "math.OC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13742v1", "summary": "In the fast-moving world of AI, as organizations and researchers develop more\nadvanced models, they face challenges due to their sheer size and computational\ndemands. Deploying such models on edge devices or in resource-constrained\nenvironments adds further challenges related to energy consumption, memory\nusage and latency. To address these challenges, emerging trends are shaping the\nfuture of efficient model optimization techniques. From this premise, by\nemploying supervised state-of-the-art transformer-based models, this research\nintroduces a systematic method for ontology alignment, grounded in cosine-based\nsemantic similarity between a biomedical layman vocabulary and the Unified\nMedical Language System (UMLS) Metathesaurus. It leverages Microsoft Olive to\nsearch for target optimizations among different Execution Providers (EPs) using\nthe ONNX Runtime backend, followed by an assembled process of dynamic\nquantization employing Intel Neural Compressor and IPEX (Intel Extension for\nPyTorch). Through our optimization process, we conduct extensive assessments on\nthe two tasks from the DEFT 2020 Evaluation Campaign, achieving a new\nstate-of-the-art in both. We retain performance metrics intact, while attaining\nan average inference speed-up of 20x and reducing memory usage by approximately\n70%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13742v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "生物医学本体对齐中的搜索优化量化", "tldr": "本研究引入了一种系统方法，通过搜索优化量化来对齐生物医学本体，实现了在保持性能的同时，将推理速度提高了20倍，内存使用减少了70%，并在DEFT 2020评估活动中达到了新的SOTA。", "motivation": "随着AI模型规模和计算需求的增长，在边缘设备或资源受限环境中部署这些模型面临能耗、内存使用和延迟等挑战。", "method": "本研究提出了一种系统性的本体对齐方法，该方法基于监督式最先进的Transformer模型，利用生物医学通俗词汇与UMLS Metathesaurus之间的余弦语义相似性。它利用Microsoft Olive通过ONNX Runtime后端在不同的执行提供商（EPs）中搜索目标优化，随后采用Intel Neural Compressor和IPEX（Intel Extension for PyTorch）进行动态量化。", "result": "通过优化过程，在DEFT 2020评估活动的两项任务中都达到了新的最先进水平。在保持性能指标不变的同时，实现了平均20倍的推理速度提升，并将内存使用量减少了约70%。", "conclusion": "该研究成功地通过搜索优化量化技术，解决了大型AI模型在资源受限环境中的部署挑战，显著提升了推理效率和内存利用率，同时保持了模型性能，并在生物医学本体对齐任务上取得了突破性进展。", "translation": "在快速发展的AI世界中，随着组织和研究人员开发出更先进的模型，它们庞大的规模和计算需求带来了挑战。在边缘设备或资源受限环境中部署此类模型，进一步增加了与能耗、内存使用和延迟相关的挑战。为了应对这些挑战，新兴趋势正在塑造高效模型优化技术的未来。基于这一前提，本研究通过采用监督式最先进的基于Transformer的模型，引入了一种系统的本体对齐方法，该方法基于生物医学通俗词汇与统一医学语言系统（UMLS）Metathesaurus之间的基于余弦的语义相似性。它利用Microsoft Olive通过ONNX Runtime后端在不同的执行提供商（EPs）中搜索目标优化，随后采用Intel Neural Compressor和IPEX（Intel Extension for PyTorch）进行动态量化。通过我们的优化过程，我们对DEFT 2020评估活动中的两项任务进行了广泛评估，在这两项任务中都达到了新的最先进水平。我们保持了性能指标不变，同时实现了平均20倍的推理速度提升，并将内存使用量减少了约70%。", "summary": "本研究提出了一种针对生物医学本体对齐的搜索优化量化方法，旨在解决大型AI模型在资源受限环境中的部署挑战。该方法利用Transformer模型和余弦相似性进行本体匹配，并通过Microsoft Olive、ONNX Runtime、Intel Neural Compressor和IPEX等工具进行动态量化优化。实验结果表明，该方法在保持性能的同时，将推理速度提高了20倍，内存使用减少了70%，并在DEFT 2020评估活动中取得了新的最先进成果。", "keywords": "本体对齐, 量化, Transformer, 生物医学, 性能优化", "comments": "该论文的创新之处在于将搜索优化量化技术应用于生物医学本体对齐任务，有效地解决了大型AI模型在边缘设备上部署的效率问题。其重要性体现在显著提升了推理速度和降低了内存消耗，同时保持了模型性能，这对于资源受限的医疗AI应用具有重大意义。"}}
{"id": "2507.13480", "title": "Multiresolution local smoothness detection in non-uniformly sampled multivariate signals", "authors": ["Sara Avesani", "Gianluca Giacchi", "Michael Multerer"], "categories": ["math.NA", "cs.CV", "cs.LG", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13480v1", "summary": "Inspired by edge detection based on the decay behavior of wavelet\ncoefficients, we introduce a (near) linear-time algorithm for detecting the\nlocal regularity in non-uniformly sampled multivariate signals. Our approach\nquantifies regularity within the framework of microlocal spaces introduced by\nJaffard. The central tool in our analysis is the fast samplet transform, a\ndistributional wavelet transform tailored to scattered data. We establish a\nconnection between the decay of samplet coefficients and the pointwise\nregularity of multivariate signals. As a by product, we derive decay estimates\nfor functions belonging to classical H\\\"older spaces and Sobolev-Slobodeckij\nspaces. While traditional wavelets are effective for regularity detection in\nlow-dimensional structured data, samplets demonstrate robust performance even\nfor higher dimensional and scattered data. To illustrate our theoretical\nfindings, we present extensive numerical studies detecting local regularity of\none-, two- and three-dimensional signals, ranging from non-uniformly sampled\ntime series over image segmentation to edge detection in point clouds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13480v1", "cate": "math.NA", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "多分辨率非均匀采样多变量信号的局部平滑度检测", "tldr": "本文提出了一种基于快速采样变换的近线性时间算法，用于检测非均匀采样多变量信号的局部正则性，并证明其在处理高维散乱数据上的鲁棒性。", "motivation": "受小波系数衰减行为的边缘检测启发，旨在解决非均匀采样多变量信号的局部正则性检测问题。", "method": "该方法在Jaffard引入的微局部空间框架内量化正则性，核心工具是针对散乱数据定制的分布小波变换——快速采样变换。", "result": "建立了采样系数衰减与多变量信号逐点正则性之间的联系；推导了属于经典H\"older空间和Sobolev-Slobodeckij空间的函数的衰减估计；证明了采样变换在处理高维和散乱数据时比传统小波变换更具鲁棒性；通过广泛的数值研究验证了理论发现，包括一维、二维和三维信号的局部正则性检测。", "conclusion": "论文成功引入了一种基于快速采样变换的算法，能够有效且鲁棒地检测非均匀采样多变量信号的局部正则性，尤其适用于高维和散乱数据。", "translation": "受基于小波系数衰减行为的边缘检测启发，我们引入了一种（接近）线性时间算法，用于检测非均匀采样多变量信号的局部正则性。我们的方法在Jaffard引入的微局部空间框架内量化正则性。我们分析的核心工具是快速采样变换，这是一种为散乱数据定制的分布小波变换。我们建立了采样系数衰减与多变量信号逐点正则性之间的联系。作为副产品，我们推导了属于经典H\"older空间和Sobolev-Slobodeckij空间的函数的衰减估计。虽然传统小波对于低维结构化数据中的正则性检测有效，但采样变换即使对于高维和散乱数据也表现出鲁棒的性能。为了说明我们的理论发现，我们进行了广泛的数值研究，检测了一维、二维和三维信号的局部正则性，范围从非均匀采样时间序列到图像分割再到点云中的边缘检测。", "summary": "本文提出了一种基于快速采样变换的近线性时间算法，用于检测非均匀采样多变量信号的局部正则性。该算法利用Jaffard的微局部空间框架和专门针对散乱数据设计的分布小波变换。研究建立了采样系数衰减与信号逐点正则性之间的关联，并推导了经典函数空间的衰减估计。相比传统小波，该方法在高维和散乱数据处理上展现出更强的鲁棒性，并通过多维信号的数值实验验证了其有效性。", "keywords": "局部正则性, 采样变换, 非均匀采样, 多变量信号, 微局部空间", "comments": "这篇论文通过引入“快速采样变换”这一创新工具，有效地解决了非均匀采样高维散乱数据的局部正则性检测问题，弥补了传统小波在处理此类数据时的局限性。其提出的算法具有接近线性的时间复杂度，且在理论和实践上都得到了验证，对于信号处理、图像分割和点云分析等领域具有重要意义。"}}
{"id": "2507.13841", "title": "Modeling Fair Play in Detective Stories with Language Models", "authors": ["Eitan Wagner", "Renana Keydar", "Omri Abend"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13841v1", "summary": "Effective storytelling relies on a delicate balance between meeting the\nreader's prior expectations and introducing unexpected developments. In the\ndomain of detective fiction, this tension is known as fair play, which includes\nthe implicit agreement between the writer and the reader as to the range of\npossible resolutions the mystery story may have. In this work, we present a\nprobabilistic framework for detective fiction that allows us to define desired\nqualities. Using this framework, we formally define fair play and design\nappropriate metrics for it. Stemming from these definitions is an inherent\ntension between the coherence of the story, which measures how much it ``makes\nsense'', and the surprise it induces. We validate the framework by applying it\nto LLM-generated detective stories. This domain is appealing since we have an\nabundance of data, we can sample from the distribution generating the story,\nand the story-writing capabilities of LLMs are interesting in their own right.\nResults show that while LLM-generated stories may be unpredictable, they\ngenerally fail to balance the trade-off between surprise and fair play, which\ngreatly contributes to their poor quality.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13841v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "语言模型在侦探小说中公平竞赛的建模", "tldr": "本文提出了一个概率框架来定义侦探小说中的“公平竞赛”并衡量其与故事连贯性和惊喜度之间的权衡，发现LLM生成的故事难以平衡惊喜和公平竞赛。", "motivation": "有效的故事讲述需要在读者的预期和意想不到的发展之间取得平衡，尤其是在侦探小说中，这被称为“公平竞赛”。本文旨在为侦探小说提供一个概率框架来定义和衡量“公平竞赛”及其与故事连贯性和惊喜度之间的内在张力。", "method": "提出了一个侦探小说的概率框架，并在此框架下正式定义了“公平竞赛”并设计了相应的度量标准。通过将该框架应用于LLM生成的侦探小说来验证其有效性。", "result": "结果表明，虽然LLM生成的故事可能不可预测，但它们通常无法平衡惊喜和公平竞赛之间的权衡，这大大降低了它们的质量。", "conclusion": "LLM在生成侦探小说时，难以在惊喜度和公平竞赛之间取得平衡，导致故事质量不高。需要进一步研究如何让LLM更好地实现这种平衡。", "translation": "有效的故事讲述依赖于满足读者先前的期望和引入意想不到的发展之间的微妙平衡。在侦探小说领域，这种张力被称为“公平竞赛”，其中包括作者和读者之间关于谜题故事可能有的解决方案范围的隐含协议。在这项工作中，我们提出了一个侦探小说的概率框架，使我们能够定义所需的质量。利用这个框架，我们正式定义了公平竞赛并为其设计了适当的度量标准。源于这些定义的是故事连贯性（衡量其“合理性”）和它引起的惊喜之间固有的张力。我们通过将其应用于LLM生成的侦探故事来验证该框架。这个领域很有吸引力，因为我们有丰富的数据，我们可以从生成故事的分布中采样，并且LLM的故事创作能力本身就很有趣。结果表明，虽然LLM生成的故事可能不可预测，但它们通常无法平衡惊喜和公平竞赛之间的权衡，这大大降低了它们的质量。", "summary": "本文提出了一个用于侦探小说的概率框架，以形式化定义“公平竞赛”——即故事连贯性与惊喜度之间的平衡。研究人员设计了相应的度量标准，并通过分析大型语言模型（LLM）生成的侦探故事来验证该框架。研究发现，尽管LLM生成的故事具有不可预测性，但它们普遍难以在惊喜度和公平竞赛之间取得平衡，从而影响了故事的质量。", "keywords": "侦探小说, 公平竞赛, 语言模型, 故事生成, 概率框架", "comments": "这项研究通过引入“公平竞赛”的概率框架，为评估和改进LLM生成侦探小说的质量提供了一个新颖且量化的视角。其创新之处在于将文学概念转化为可衡量的指标。该工作揭示了当前LLM在生成复杂叙事（如侦探小说）时面临的挑战，即在制造惊喜的同时保持故事的逻辑性和可接受性。这对于未来指导LLM生成更高质量的叙事内容具有重要意义。"}}
{"id": "2507.12503", "title": "Complex non-backtracking matrix for directed graphs", "authors": ["Keishi Sando", "Hideitsu Hino"], "categories": ["math.CO", "cs.LG", "stat.ML"], "primary_category": "Subjects:       Combinatorics (math.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12503v2", "summary": "Graph representation matrices are essential tools in graph data analysis.\nRecently, Hermitian adjacency matrices have been proposed to investigate\ndirected graph structures. Previous studies have demonstrated that these\nmatrices can extract valuable information for clustering. In this paper, we\npropose the complex non-backtracking matrix that integrates the properties of\nthe Hermitian adjacency matrix and the non-backtracking matrix. The proposed\nmatrix has similar properties with the non-backtracking matrix of undirected\ngraphs. We reveal relationships between the complex non-backtracking matrix and\nthe Hermitian adjacency matrix. Also, we provide intriguing insights that this\nmatrix representation holds cluster information, particularly for sparse\ndirected graphs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12503v2", "cate": "math.CO", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "复杂非回溯矩阵用于有向图", "tldr": "本文提出了一种新的复杂非回溯矩阵，它结合了厄米特邻接矩阵和非回溯矩阵的特性，并被证明能有效提取有向图，特别是稀疏有向图的聚类信息。", "motivation": "图表示矩阵是图数据分析的重要工具。现有研究表明厄米特邻接矩阵能为有向图结构分析和聚类提供有价值的信息。本文旨在提出一种新的矩阵表示方法，以更好地整合现有矩阵的优点并揭示有向图，特别是稀疏有向图的聚类信息。", "method": "提出了一种新的“复杂非回溯矩阵”，该矩阵结合了厄米特邻接矩阵和非回溯矩阵的特性。", "result": "所提出的复杂非回溯矩阵与无向图的非回溯矩阵具有相似的性质。研究揭示了复杂非回溯矩阵与厄米特邻接矩阵之间的关系。此外，该矩阵表示法能有效捕捉聚类信息，尤其对稀疏有向图表现出色。", "conclusion": "本文提出了一种新的复杂非回溯矩阵，它整合了现有图表示矩阵的优点，并被证明在提取有向图，特别是稀疏有向图的聚类信息方面具有独特的见解和潜力。", "translation": "图表示矩阵是图数据分析中必不可少的工具。最近，厄米特邻接矩阵被提出用于研究有向图结构。之前的研究表明，这些矩阵可以提取有价值的聚类信息。在本文中，我们提出了一种复杂非回溯矩阵，它整合了厄米特邻接矩阵和非回溯矩阵的特性。所提出的矩阵与无向图的非回溯矩阵具有相似的性质。我们揭示了复杂非回溯矩阵与厄米特邻接矩阵之间的关系。此外，我们提供了有趣的见解，即这种矩阵表示包含聚类信息，特别是对于稀疏有向图。", "summary": "本文针对有向图分析，提出了一种创新的“复杂非回溯矩阵”。该矩阵巧妙地融合了现有厄米特邻接矩阵和非回溯矩阵的特性，旨在更有效地捕捉图结构信息。研究表明，该新矩阵与无向图的非回溯矩阵具有相似性质，并揭示了其与厄米特邻接矩阵的关系。尤为重要的是，该矩阵被发现能有效提取有向图，特别是稀疏有向图的聚类信息，为图数据分析提供了新的工具和视角。", "keywords": "复杂非回溯矩阵, 有向图, 厄米特邻接矩阵, 非回溯矩阵, 聚类信息", "comments": "这篇论文的创新点在于提出了一种结合两种现有图表示矩阵（厄米特邻接矩阵和非回溯矩阵）优点的新型复杂非回溯矩阵，专门用于有向图分析。其重要性在于为有向图的聚类问题提供了一种新的、可能更有效的信息提取方法，尤其强调了对稀疏有向图的适用性，这在实际应用中具有重要意义。"}}
{"id": "2507.13540", "title": "Provable Low-Frequency Bias of In-Context Learning of Representations", "authors": ["Yongyi Yang", "Hidenori Tanaka", "Wei Hu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13540v1", "summary": "In-context learning (ICL) enables large language models (LLMs) to acquire new\nbehaviors from the input sequence alone without any parameter updates. Recent\nstudies have shown that ICL can surpass the original meaning learned in\npretraining stage through internalizing the structure the data-generating\nprocess (DGP) of the prompt into the hidden representations. However, the\nmechanisms by which LLMs achieve this ability is left open. In this paper, we\npresent the first rigorous explanation of such phenomena by introducing a\nunified framework of double convergence, where hidden representations converge\nboth over context and across layers. This double convergence process leads to\nan implicit bias towards smooth (low-frequency) representations, which we prove\nanalytically and verify empirically. Our theory explains several open empirical\nobservations, including why learned representations exhibit globally structured\nbut locally distorted geometry, and why their total energy decays without\nvanishing. Moreover, our theory predicts that ICL has an intrinsic robustness\ntowards high-frequency noise, which we empirically confirm. These results\nprovide new insights into the underlying mechanisms of ICL, and a theoretical\nfoundation to study it that hopefully extends to more general data\ndistributions and settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13540v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "可证明的表示上下文学习的低频偏差", "tldr": "本文提出了一个双重收敛的统一框架，解释了上下文学习（ICL）中隐藏表示的机制，并证明了ICL对平滑（低频）表示存在隐式偏置，同时预测并验证了其对高频噪声的鲁棒性。", "motivation": "尽管上下文学习（ICL）能让大型语言模型（LLMs）通过输入序列学习新行为并内化数据生成过程的结构到隐藏表示中，但其实现这些能力的机制尚不清楚。", "method": "引入了一个统一的“双重收敛”框架，其中隐藏表示在上下文和层级上同时收敛。", "result": "证明了双重收敛过程导致对平滑（低频）表示的隐式偏置，并解释了已有的经验观察，如学习到的表示为何表现出全局结构化但局部扭曲的几何形状，以及它们的总能量为何衰减而不消失。此外，理论预测ICL对高频噪声具有内在鲁棒性，并得到了经验证实。", "conclusion": "这些结果为上下文学习（ICL）的底层机制提供了新的见解，并为研究ICL提供了理论基础，有望扩展到更普遍的数据分布和设置。", "translation": "上下文学习（ICL）使大型语言模型（LLMs）能够仅从输入序列中获取新行为，而无需更新任何参数。最近的研究表明，ICL可以通过将提示的数据生成过程（DGP）结构内化到隐藏表示中，从而超越预训练阶段学习到的原始含义。然而，LLMs实现这种能力的机制仍然是个未解之谜。在本文中，我们通过引入一个双重收敛的统一框架，首次对这种现象提供了严格的解释，其中隐藏表示在上下文和层级上都收敛。这种双重收敛过程导致对平滑（低频）表示的隐式偏置，我们对此进行了分析证明和经验验证。我们的理论解释了几个开放的经验观察，包括为什么学习到的表示表现出全局结构化但局部扭曲的几何形状，以及为什么它们的总能量衰减而不消失。此外，我们的理论预测ICL对高频噪声具有内在鲁棒性，我们对此进行了经验证实。这些结果为ICL的底层机制提供了新的见解，并为研究ICL提供了理论基础，有望扩展到更普遍的数据分布和设置。", "summary": "本文针对大型语言模型（LLMs）中上下文学习（ICL）如何内化数据生成过程的结构这一未解之谜，提出了一个双重收敛的统一框架。该框架证明了ICL的隐藏表示存在对平滑（低频）表示的隐式偏置，并成功解释了多个经验观察，如表示的几何特性和能量衰减。此外，研究还预测并经验证实了ICL对高频噪声的内在鲁棒性，为ICL的机制提供了深入的理论解释。", "keywords": "上下文学习, 隐藏表示, 双重收敛, 低频偏置, 大型语言模型", "comments": "这篇论文通过引入“双重收敛”框架，首次为上下文学习（ICL）中隐藏表示的机制提供了严格的理论解释，填补了该领域的一个重要空白。其创新之处在于将表示的收敛性与低频偏置联系起来，并成功解释了多个经验现象，同时预测了ICL的鲁棒性。这为理解LLMs的ICL能力提供了坚实的理论基础，具有重要的研究价值。"}}
{"id": "2507.13527", "title": "SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM", "authors": ["Levi Harris", "Md Jayed Hossain", "Mufan Qiu", "Ruichen Zhang", "Pingchuan Ma", "Tianlong Chen", "Jiaqi Gu", "Seth Ariel Tongay", "Umberto Celano"], "categories": ["cs.CV", "cond-mat.mtrl-sci"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13527v1", "summary": "The increasing use of two-dimensional (2D) materials in nanoelectronics\ndemands robust metrology techniques for electrical characterization, especially\nfor large-scale production. While atomic force microscopy (AFM) techniques like\nconductive AFM (C-AFM) offer high accuracy, they suffer from slow data\nacquisition speeds due to the raster scanning process. To address this, we\nintroduce SparseC-AFM, a deep learning model that rapidly and accurately\nreconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM\nscans. Our approach is robust across various scanning modes, substrates, and\nexperimental conditions. We report a comparison between (a) classic flow\nimplementation, where a high pixel density C-AFM image (e.g., 15 minutes to\ncollect) is manually parsed to extract relevant material parameters, and (b)\nour SparseC-AFM method, which achieves the same operation using data that\nrequires substantially less acquisition time (e.g., under 5 minutes).\nSparseC-AFM enables efficient extraction of critical material parameters in\nMoS$_2$, including film coverage, defect density, and identification of\ncrystalline island boundaries, edges, and cracks. We achieve over 11x reduction\nin acquisition time compared to manual extraction from a full-resolution C-AFM\nimage. Moreover, we demonstrate that our model-predicted samples exhibit\nremarkably similar electrical properties to full-resolution data gathered using\nclassic-flow scanning. This work represents a significant step toward\ntranslating AI-assisted 2D material characterization from laboratory research\nto industrial fabrication. Code and model weights are available at\ngithub.com/UNITES-Lab/sparse-cafm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13527v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "SparseC-AFM：一种用于快速准确表征二硫化钼（MoS$_2$）的深度学习方法", "tldr": "SparseC-AFM使用深度学习从稀疏C-AFM扫描中快速准确地重建MoS$_2$的电导率图，显著减少了数据采集时间。", "motivation": "二维（2D）材料在纳米电子学中的应用日益增多，需要鲁棒的电学表征计量技术，尤其是在大规模生产中。传统的导电原子力显微镜（C-AFM）虽然精度高，但由于光栅扫描过程导致数据采集速度缓慢。", "method": "本研究引入了SparseC-AFM，一个深度学习模型，用于从稀疏的C-AFM扫描中快速准确地重建MoS$_2$等二维材料的电导率图。该方法在各种扫描模式、基底和实验条件下均表现出鲁棒性。", "result": "SparseC-AFM与传统方法相比，将数据采集时间减少了超过11倍（例如，从15分钟减少到5分钟以内）。它能够有效地提取MoS$_2$的关键材料参数，包括薄膜覆盖率、缺陷密度以及晶体岛边界、边缘和裂缝的识别。此外，模型预测的样本与使用经典流程扫描收集的全分辨率数据表现出非常相似的电学特性。", "conclusion": "这项工作代表着将人工智能辅助的二维材料表征从实验室研究转化为工业制造的重要一步。", "translation": "二维（2D）材料在纳米电子学中的日益广泛应用，要求有强大的计量技术进行电学表征，特别是在大规模生产中。虽然导电原子力显微镜（C-AFM）等AFM技术提供了高精度，但由于光栅扫描过程，其数据采集速度缓慢。为了解决这个问题，我们引入了SparseC-AFM，一个深度学习模型，可以从稀疏的C-AFM扫描中快速准确地重建二硫化钼（MoS$_2$）等二维材料的电导率图。我们的方法在各种扫描模式、衬底和实验条件下都具有鲁棒性。我们报告了（a）经典流程实现与（b）我们的SparseC-AFM方法之间的比较，其中经典流程实现需要手动解析高像素密度C-AFM图像（例如，需要15分钟采集）以提取相关材料参数，而我们的SparseC-AFM方法使用所需采集时间大大减少（例如，5分钟以内）的数据实现了相同的操作。SparseC-AFM能够有效提取MoS$_2$中的关键材料参数，包括薄膜覆盖率、缺陷密度以及晶体岛边界、边缘和裂纹的识别。与从全分辨率C-AFM图像中手动提取相比，我们实现了超过11倍的采集时间缩减。此外，我们证明了我们模型预测的样本与使用经典流程扫描收集的全分辨率数据表现出非常相似的电学特性。这项工作代表着将人工智能辅助的二维材料表征从实验室研究转化为工业制造的重要一步。代码和模型权重可在github.com/UNITES-Lab/sparse-cafm获取。", "summary": "本研究提出SparseC-AFM，一个基于深度学习的模型，旨在解决导电原子力显微镜（C-AFM）在二维材料电学表征中数据采集速度慢的问题。该模型能从稀疏C-AFM扫描中快速准确地重建MoS$_2$的电导率图，显著减少了超过11倍的数据采集时间，同时保持了与全分辨率数据相似的电学表征精度。SparseC-AFM有效提取了关键材料参数，并为AI辅助的二维材料工业级表征迈出了重要一步。", "keywords": "深度学习, C-AFM, MoS$_2$, 二维材料, 快速表征", "comments": "该论文提出了一种创新的深度学习方法SparseC-AFM，显著提升了C-AFM在二维材料电学表征中的效率，解决了传统方法数据采集慢的痛点。其在保持高精度的同时大幅缩短了时间，这对于大规模生产和工业应用具有重要意义。该研究将AI技术成功应用于材料科学领域，展示了AI在加速科学研究和工业化进程中的巨大潜力。"}}
{"id": "2507.13852", "title": "A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data", "authors": ["Luigi Russo", "Francesco Mauro", "Babak Memar", "Alessandro Sebastianelli", "Silvia Liberata Ullo", "Paolo Gamba"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE Joint Urban Remote Sensing Event (JURSE) 2025", "url": "http://arxiv.org/abs/2507.13852v1", "summary": "Building segmentation in urban areas is essential in fields such as urban\nplanning, disaster response, and population mapping. Yet accurately segmenting\nbuildings in dense urban regions presents challenges due to the large size and\nhigh resolution of satellite images. This study investigates the use of a\nQuanvolutional pre-processing to enhance the capability of the Attention U-Net\nmodel in the building segmentation. Specifically, this paper focuses on the\nurban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)\nimagery. In this work, Quanvolution was used to extract more informative\nfeature maps that capture essential structural details in radar imagery,\nproving beneficial for accurate building segmentation. Preliminary results\nindicate that proposed methodology achieves comparable test accuracy to the\nstandard Attention U-Net model while significantly reducing network parameters.\nThis result aligns with findings from previous works, confirming that\nQuanvolution not only maintains model accuracy but also increases computational\nefficiency. These promising outcomes highlight the potential of\nquantum-assisted Deep Learning frameworks for large-scale building segmentation\nin urban environments.", "comment": "Accepted at IEEE Joint Urban Remote Sensing Event (JURSE) 2025", "pdf_url": "http://arxiv.org/pdf/2507.13852v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "一种用于利用Sentinel-1数据对突尼斯建筑物进行分割的量子辅助注意力U-Net", "tldr": "本研究提出了一种结合量子化预处理的注意力U-Net模型，用于利用Sentinel-1 SAR图像对突尼斯城市区域的建筑物进行分割。初步结果显示，该方法在保持准确性的同时显著减少了网络参数，展现了量子辅助深度学习在大型建筑物分割中的潜力。", "motivation": "在城市规划、灾害响应和人口测绘等领域，城市区域的建筑物分割至关重要。然而，由于卫星图像尺寸大、分辨率高，在密集的城市区域准确分割建筑物面临挑战。", "method": "本研究采用量子化（Quanvolution）预处理来增强注意力U-Net模型在建筑物分割中的能力。具体地，利用Sentinel-1合成孔径雷达（SAR）图像对突尼斯城市景观进行研究。Quanvolution被用来提取更具信息量的特征图，以捕获雷达图像中重要的结构细节。", "result": "初步结果表明，所提出的方法实现了与标准注意力U-Net模型相当的测试准确率，同时显著减少了网络参数。这一结果与先前的工作一致，证实了Quanvolution不仅保持了模型准确性，还提高了计算效率。", "conclusion": "这些有希望的结果突显了量子辅助深度学习框架在城市环境下大规模建筑物分割的潜力。", "translation": "城市区域的建筑物分割在城市规划、灾害响应和人口测绘等领域至关重要。然而，由于卫星图像尺寸大、分辨率高，在密集的城市区域准确分割建筑物带来了挑战。本研究探讨了使用量子化（Quanvolutional）预处理来增强注意力U-Net模型在建筑物分割中的能力。具体地，本文聚焦于突尼斯的城市景观，利用Sentinel-1合成孔径雷达（SAR）图像。在这项工作中，Quanvolution被用于提取更具信息量的特征图，以捕获雷达图像中重要的结构细节，这被证明对准确的建筑物分割有利。初步结果表明，所提出的方法实现了与标准注意力U-Net模型相当的测试准确率，同时显著减少了网络参数。这一结果与先前的工作一致，证实了Quanvolution不仅保持了模型准确性，还提高了计算效率。这些有希望的结果突显了量子辅助深度学习框架在城市环境下大规模建筑物分割的潜力。", "summary": "本研究旨在解决城市区域建筑物分割的挑战，特别是在突尼斯利用Sentinel-1 SAR数据。论文提出了一种结合量子化预处理的注意力U-Net模型，通过Quanvolution提取更丰富的特征信息，以提升分割精度和计算效率。初步实验结果表明，该量子辅助方法在保持与标准注意力U-Net相近的准确率的同时，显著减少了模型参数，验证了其在大型城市建筑物分割应用中的潜力。", "keywords": "建筑物分割, 量子辅助, 注意力U-Net, Sentinel-1, SAR图像", "comments": "该论文的创新点在于将量子化（Quanvolution）预处理引入到传统的注意力U-Net模型中，用于卫星图像的建筑物分割。这种结合不仅能够处理高分辨率的SAR数据，还在保持模型性能的同时显著降低了模型复杂度（减少网络参数），从而提高了计算效率。这对于资源受限或需要快速部署的场景具有重要意义，并为量子辅助深度学习在遥感图像处理领域的应用提供了有前景的方向。"}}
{"id": "2408.06345", "title": "Deep Learning based Key Information Extraction from Business Documents: Systematic Literature Review", "authors": ["Alexander Michael Rombach", "Peter Fettke"], "categories": ["cs.IR", "cs.CL", "cs.LG", "A.1; I.2.7; I.4.9; I.7.5"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      62 pages, 7 figures, 10 tables; This version represents the accepted author-version without final copyediting. ACM Computing Surveys source: this https URL", "url": "http://arxiv.org/abs/2408.06345v2", "summary": "Extracting key information from documents represents a large portion of\nbusiness workloads and therefore offers a high potential for efficiency\nimprovements and process automation. With recent advances in Deep Learning, a\nplethora of Deep Learning based approaches for Key Information Extraction have\nbeen proposed under the umbrella term Document Understanding that enable the\nprocessing of complex business documents. The goal of this systematic\nliterature review is an in-depth analysis of existing approaches in this domain\nand the identification of opportunities for further research. To this end, 130\napproaches published between 2017 and 2024 are analyzed in this study.", "comment": "62 pages, 7 figures, 10 tables; This version represents the accepted\n  author-version without final copyediting. ACM Computing Surveys source:\n  https://dl.acm.org/doi/10.1145/3749369", "pdf_url": "http://arxiv.org/pdf/2408.06345v2", "cate": "cs.IR", "date": "2024-07-23", "updated": "2025-07-18", "AI": {"title_translation": "基于深度学习的商业文档关键信息提取：系统文献综述", "tldr": "本系统性文献综述深入分析了2017年至2024年间提出的130种基于深度学习的商业文档关键信息提取方法，旨在识别进一步研究的机会。", "motivation": "从文档中提取关键信息是企业工作量的重要组成部分，通过提高效率和过程自动化具有巨大的潜力。随着深度学习的最新进展，出现了大量基于深度学习的关键信息提取方法，这些方法统称为文档理解，能够处理复杂的商业文档。", "method": "本研究对2017年至2024年间发表的130种方法进行了分析。", "result": "本研究对现有方法进行了深入分析，并识别了进一步研究的机会。", "conclusion": "Not mentioned in abstract", "translation": "从文档中提取关键信息占业务工作量的很大一部分，因此在提高效率和过程自动化方面具有很高的潜力。随着深度学习的最新进展，在文档理解这一总称下，已经提出了大量基于深度学习的关键信息提取方法，这些方法能够处理复杂的商业文档。本系统文献综述的目标是对该领域现有方法进行深入分析，并识别进一步研究的机会。为此，本研究分析了2017年至2024年间发表的130种方法。", "summary": "本系统文献综述旨在深入分析2017年至2024年间提出的130种基于深度学习的商业文档关键信息提取方法。该研究旨在利用深度学习在文档理解方面的进展，解决企业在关键信息提取方面面临的效率和自动化挑战，并识别该领域的未来研究方向。", "keywords": "深度学习, 关键信息提取, 商业文档, 系统文献综述, 文档理解", "comments": "该论文通过系统性综述的方式，对深度学习在商业文档关键信息提取领域的应用进行了全面的梳理和分析，对于理解当前研究现状和指导未来研究方向具有重要意义。其价值在于对大量文献的整合和对研究机会的识别。"}}
{"id": "2507.13952", "title": "Estimating Cognitive Effort from Functional Near-Infrared Spectroscopy (fNIRS) Signals using Machine Learning", "authors": ["Shayla Sharmin", "Roghayeh Leila Barmaki"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2504.13883", "url": "http://arxiv.org/abs/2507.13952v1", "summary": "The estimation of cognitive effort could potentially help educators to modify\nmaterial to enhance learning effectiveness and student engagement. Where\ncognitive load refers how much work the brain is doing while someone is\nlearning or doing a task cognitive effort consider both load and behavioral\nperformance. Cognitive effort can be captured by measuring oxygen flow and\nbehavioral performance during a task. This study infers cognitive effort\nmetrics using machine learning models based on oxygenated hemoglobin collected\nby using functional near-infrared spectroscopy from the prefrontal cortex\nduring an educational gameplay. In our study, sixteen participants responded to\nsixteen questions in an in-house Unity-based educational game. The quiz was\ndivided into two sessions, each session consisting of two task segments. We\nextracted temporal statistical and functional connectivity features from\ncollected oxygenated hemoglobin and analyzed their correlation with quiz\nperformance. We trained multiple machine learning models to predict quiz\nperformance from oxygenated hemoglobin features and achieved accuracies ranging\nfrom 58\\% to 67\\% accuracy. These predictions were used to calculate cognitive\neffort via relative neural involvement and efficiency, which consider both\nbrain activation and behavioral performance. Although quiz score predictions\nachieved moderate accuracy, the derived relative neural efficiency and\ninvolvement values remained robust. Since both metrics are based on the\nrelative positions of standardized brain activation and performance scores,\neven small misclassifications in predicted scores preserved the overall\ncognitive effort trends observed during gameplay.", "comment": "arXiv admin note: text overlap with arXiv:2504.13883", "pdf_url": "http://arxiv.org/pdf/2507.13952v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用机器学习从功能性近红外光谱（fNIRS）信号估计认知努力", "tldr": "本研究利用机器学习和功能性近红外光谱（fNIRS）信号来估计认知努力，旨在帮助教育者提升学习效果和学生参与度。", "motivation": "估计认知努力可能有助于教育者修改教学材料，以提高学习效率和学生参与度。", "method": "本研究使用机器学习模型，根据在教育游戏过程中通过功能性近红外光谱（fNIRS）从前额叶皮层收集到的含氧血红蛋白数据来推断认知努力指标。研究中，16名参与者在一个基于Unity的自制教育游戏中回答了16个问题。测验分为两个环节，每个环节包含两个任务段。研究人员从收集到的含氧血红蛋白中提取了时间统计和功能连接特征，并分析了它们与测验表现的相关性。研究训练了多个机器学习模型来预测含氧血红蛋白特征的测验表现，并将这些预测结果用于通过相对神经参与度和效率来计算认知努力，这考虑了大脑激活和行为表现。", "result": "机器学习模型预测测验表现的准确率范围为58%至67%。尽管测验分数预测的准确率中等，但推导出的相对神经效率和参与度值保持稳健。由于这两个指标是基于标准化大脑激活和表现分数的相对位置，即使预测分数中存在小的错误分类，也保留了游戏过程中观察到的整体认知努力趋势。", "conclusion": "本研究成功地使用机器学习和fNIRS信号推断了认知努力指标。尽管测验分数预测精度中等，但通过相对神经参与度和效率计算出的认知努力指标表现出良好的鲁棒性，这对于理解学习过程中的认知状态具有重要意义。", "translation": "对认知努力的估计可能有助于教育者修改材料以提高学习效率和学生参与度。认知负荷是指大脑在学习或执行任务时所做的工作量，而认知努力则同时考虑负荷和行为表现。认知努力可以通过测量任务期间的氧流量和行为表现来捕获。本研究利用机器学习模型，根据在教育游戏过程中通过功能性近红外光谱从前额叶皮层收集到的含氧血红蛋白数据来推断认知努力指标。在我们的研究中，16名参与者在一个基于Unity的自制教育游戏中回答了16个问题。测验分为两个环节，每个环节包含两个任务段。我们从收集到的含氧血红蛋白中提取了时间统计和功能连接特征，并分析了它们与测验表现的相关性。我们训练了多个机器学习模型来预测含氧血红蛋白特征的测验表现，准确率范围为58%至67%。这些预测结果被用于通过相对神经参与度和效率来计算认知努力，这同时考虑了大脑激活和行为表现。尽管测验分数预测的准确率中等，但推导出的相对神经效率和参与度值保持稳健。由于这两个指标是基于标准化大脑激活和表现分数的相对位置，即使预测分数中存在小的错误分类，也保留了游戏过程中观察到的整体认知努力趋势。", "summary": "本研究旨在使用机器学习和功能性近红外光谱（fNIRS）信号来估计认知努力，以期帮助教育者优化教学。研究通过fNIRS从16名参与者在教育游戏中的前额叶皮层收集含氧血红蛋白数据，并提取时间统计和功能连接特征。机器学习模型被训练用于预测测验表现（准确率58%-67%），并基于此计算出考虑大脑激活和行为表现的相对神经参与度和效率作为认知努力指标。研究发现，尽管测验分数预测准确率中等，但所推导出的认知努力指标具有良好的鲁棒性。", "keywords": "认知努力, fNIRS, 机器学习, 教育游戏, 含氧血红蛋白", "comments": "本研究的创新点在于结合fNIRS技术和机器学习，在教育游戏环境中评估认知努力，并考虑了大脑活动和行为表现的双重维度。其重要性在于为教育领域提供了一种客观评估学生认知状态的潜在方法。尽管测验分数预测的准确率中等，但研究强调其推导出的认知努力指标的鲁棒性，这是一个值得关注的优势。然而，16名参与者的样本量相对较小，可能会影响结果的泛化能力。"}}
{"id": "2504.15204", "title": "Soft-Output from Covered Space Decoding of Product Codes", "authors": ["Tim Janz", "Simon Obermüller", "Andreas Zunker", "Stephan ten Brink"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 2 figures, 2 tables", "url": "http://arxiv.org/abs/2504.15204v3", "summary": "In this work, we propose a new soft-input soft-output decoder called\nsoft-output from covered space (SOCS) decoder. It estimates the a posteriori\nreliability based on the space explored by a list decoder, i.e., the set of\nvectors for which the list decoder knows whether they are codewords. This\napproach enables a more accurate calculation of the a posteriori reliability\nand results in gains of up to 0.25$\\,$dB for turbo product decoding with SOCS\ncompared to Chase-Pyndiah decoding.", "comment": "6 pages, 2 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2504.15204v3", "cate": "cs.IT", "date": "2025-04-21", "updated": "2025-07-18", "AI": {"title_translation": "乘积码覆盖空间解码的软输出", "tldr": "本文提出了一种新的软输出解码器（SOCS），用于乘积码，通过利用列表解码器探索的空间来更准确地估计后验可靠性，从而提高了解码性能。", "motivation": "需要更准确地计算乘积码软输入软输出解码器中的后验可靠性。", "method": "提出了一种名为“覆盖空间软输出（SOCS）解码器”的新型软输入软输出解码器。它根据列表解码器探索的空间（即列表解码器知道哪些向量是码字的集合）来估计后验可靠性。", "result": "该方法能够更准确地计算后验可靠性，与Chase-Pyndiah解码相比，使用SOCS的涡轮乘积码解码增益高达0.25dB。", "conclusion": "SOCS解码器通过更准确地估计后验可靠性，提高了乘积码的解码性能。", "translation": "在这项工作中，我们提出了一种名为覆盖空间软输出（SOCS）解码器的新型软输入软输出解码器。它根据列表解码器探索的空间（即列表解码器知道哪些向量是码字的集合）来估计后验可靠性。这种方法能够更准确地计算后验可靠性，与Chase-Pyndiah解码相比，使用SOCS的涡轮乘积码解码增益高达0.25dB。", "summary": "本文介绍了一种名为覆盖空间软输出（SOCS）的新型软输入软输出解码器。SOCS通过利用列表解码器探索的空间来改进后验可靠性的估计，从而实现更准确的可靠性计算。实验结果表明，与Chase-Pyndiah解码相比，SOCS在涡轮乘积码解码中实现了高达0.25 dB的性能增益。", "keywords": "软输出解码器, 乘积码, 列表解码, 后验可靠性, 涡轮乘积码", "comments": "该论文的创新之处在于利用列表解码器的“覆盖空间”进行可靠性估计，这是一种新颖的方法。0.25 dB的增益虽然不大，但表明在乘积码的解码性能方面取得了实际的改进。"}}
{"id": "2507.14073", "title": "Convex computation of regions of attraction from data using Sums-of-Squares programming", "authors": ["Oumayma Khattabi", "Matteo Tacchi-Bénard", "Sorin Olaru"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14073v1", "summary": "The paper concentrates on the analysis of the region of attraction (ROA) for\nunknown autonomous dynamical systems. The aim is to explore a data-driven\napproach based on moment-sum-of-squares (SoS) hierarchy, which enables novel\nRoA outer approximations despite the reduced information on the structure of\nthe dynamics. The main contribution of this work is bypassing the system model\nand, consequently, the recurring constraint on its polynomial structure.\nNumerical experimentation showcases the influence of data on learned\napproximating sets, offering a promising outlook on the potential of this\nmethod.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14073v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "吸引域的凸计算：基于数据的和平方规划", "tldr": "本文提出了一种基于数据和平方规划的方法，用于计算未知自治动力系统的吸引域，无需系统模型。", "motivation": "分析未知自治动力系统的吸引域（ROA），并探索一种数据驱动的方法，即使在动力学结构信息减少的情况下，也能实现新的ROA外部近似。主要动机是绕过系统模型及其多项式结构的常见约束。", "method": "采用基于矩和平方（SoS）层级的数据驱动方法，以实现ROA的外部近似。该方法的核心贡献在于绕过系统模型，从而避免了对其多项式结构的反复约束。", "result": "数值实验表明数据对学习到的近似集合有显著影响。", "conclusion": "该方法在吸引域分析方面具有巨大的潜力。", "translation": "本文主要关注未知自治动力系统吸引域（ROA）的分析。其目标是探索一种基于矩和平方（SoS）层级的数据驱动方法，该方法能够在动力学结构信息减少的情况下，实现新颖的ROA外部近似。这项工作的主要贡献在于绕过了系统模型，从而避免了对其多项式结构的反复约束。数值实验展示了数据对学习到的近似集的影响，为该方法的潜力提供了有希望的展望。", "summary": "本文提出了一种新颖的数据驱动方法，利用矩和平方（SoS）层级来近似未知自治动力系统的吸引域（ROA）。该方法的核心创新在于无需系统模型，从而克服了传统方法对系统多项式结构的依赖。数值实验验证了数据对近似集性能的影响，并展示了该方法的巨大潜力。", "keywords": "吸引域, 数据驱动, 和平方规划, 动力系统, 近似", "comments": "这篇论文的创新点在于提出了一个纯数据驱动的方法来计算吸引域，避免了对系统模型（特别是其多项式结构）的显式依赖。这对于那些难以建立精确数学模型的复杂系统来说，是一个重要的进步，拓宽了吸引域分析的应用范围。"}}
{"id": "2507.13785", "title": "MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development", "authors": ["Mykola Glybovets", "Sergii Medvid"], "categories": ["cs.NE"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "Comments:      13 pages, 8 figures; Preprint of a manuscript submitted for peer review", "url": "http://arxiv.org/abs/2507.13785v1", "summary": "While biological neural networks develop from compact genomes using\nrelatively simple rules, modern artificial neural architecture search methods\nmostly involve explicit and routine manual work. In this paper, we introduce\nMorphoNAS (Morphogenetic Neural Architecture Search), a system able to\ndeterministically grow neural networks through morphogenetic self-organization\ninspired by the Free Energy Principle, reaction-diffusion systems, and gene\nregulatory networks. In MorphoNAS, simple genomes encode just morphogens\ndynamics and threshold-based rules of cellular development. Nevertheless, this\nleads to self-organization of a single progenitor cell into complex neural\nnetworks, while the entire process is built on local chemical interactions. Our\nevolutionary experiments focused on two different domains: structural\ntargeting, in which MorphoNAS system was able to find fully successful genomes\nable to generate predefined random graph configurations (8-31 nodes); and\nfunctional performance on the CartPole control task achieving low complexity\n6-7 neuron solutions when target network size minimization evolutionary\npressure was applied. The evolutionary process successfully balanced between\nquality of of the final solutions and neural architecture search effectiveness.\nOverall, our findings suggest that the proposed MorphoNAS method is able to\ngrow complex specific neural architectures, using simple developmental rules,\nwhich suggests a feasible biological route to adaptive and efficient neural\narchitecture search.", "comment": "13 pages, 8 figures; Preprint of a manuscript submitted for peer\n  review", "pdf_url": "http://arxiv.org/pdf/2507.13785v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MorphoNAS：通过形态发生素引导发育的胚胎神经架构搜索", "tldr": "MorphoNAS是一种受生物学启发的神经架构搜索方法，它通过基于形态发生素动力学和细胞发育规则的自组织，从简单的基因组确定性地生成复杂的神经网络，并在结构靶向和CartPole控制任务上取得了成功。", "motivation": "现代人工神经架构搜索方法涉及大量显式和常规的手动工作，而生物神经网络则通过相对简单的规则从紧凑的基因组中发育。本研究的动机是引入一种受生物学启发的方法，以更高效、自组织的方式进行神经架构搜索。", "method": "MorphoNAS（形态发生神经架构搜索）系统通过受自由能原理、反应扩散系统和基因调控网络启发的形态发生自组织来确定性地生长神经网络。在MorphoNAS中，简单的基因组只编码形态发生素动力学和基于阈值的细胞发育规则。整个过程建立在局部化学相互作用之上，使单个祖细胞自组织成复杂的神经网络。", "result": "进化实验集中在两个不同领域：结构靶向，MorphoNAS系统能够找到完全成功的基因组，生成预定义的随机图配置（8-31个节点）；功能性能在CartPole控制任务上实现了低复杂度的6-7个神经元解决方案，同时施加了目标网络尺寸最小化的进化压力。进化过程成功地平衡了最终解决方案的质量和神经架构搜索的效率。", "conclusion": "本研究的结果表明，所提出的MorphoNAS方法能够使用简单的发育规则生长复杂的特定神经架构，这为自适应和高效的神经架构搜索提供了一条可行的生物学途径。", "translation": "虽然生物神经网络通过相对简单的规则从紧凑的基因组中发育而来，但现代人工神经架构搜索方法大多涉及显式和常规的手动工作。在本文中，我们介绍了MorphoNAS（形态发生神经架构搜索），一个能够通过受自由能原理、反应扩散系统和基因调控网络启发的形态发生自组织来确定性地生长神经网络的系统。在MorphoNAS中，简单的基因组只编码形态发生素动力学和基于阈值的细胞发育规则。然而，这使得单个祖细胞自组织成复杂的神经网络，而整个过程都建立在局部化学相互作用之上。我们的进化实验集中在两个不同领域：结构靶向，其中MorphoNAS系统能够找到完全成功的基因组，生成预定义的随机图配置（8-31个节点）；以及在CartPole控制任务上的功能性能，当施加目标网络尺寸最小化的进化压力时，实现了低复杂度的6-7个神经元解决方案。进化过程成功地平衡了最终解决方案的质量和神经架构搜索的效率。总的来说，我们的发现表明，所提出的MorphoNAS方法能够使用简单的发育规则生长复杂的特定神经架构，这为自适应和高效的神经架构搜索提供了一条可行的生物学途径。", "summary": "本文介绍了MorphoNAS，一种受生物学启发的新型神经架构搜索系统。它借鉴了形态发生自组织、自由能原理、反应扩散系统和基因调控网络，能够从简单的基因组中确定性地生成复杂的神经网络。该系统通过编码形态发生素动力学和基于阈值的细胞发育规则，使得单个祖细胞通过局部化学相互作用自组织。实验证明，MorphoNAS在生成预定义图结构和在CartPole任务上找到高效小规模网络方面均表现出色，表明其在平衡解决方案质量和搜索效率方面的潜力，为自适应和高效的神经架构搜索提供了一条生物学途径。", "keywords": "神经架构搜索, 形态发生, 自组织, 基因组, 神经网络发育", "comments": "MorphoNAS的创新之处在于其将生物发育过程中的形态发生原理引入神经网络架构搜索，通过自组织而非显式设计来构建复杂网络，这与传统NAS方法形成鲜明对比。其重要性在于提供了一种更接近生物高效发育模式的NAS范式，有望降低手动干预，并可能在资源受限或需要高度自适应的场景中展现优势。该方法通过简单的局部规则实现复杂结构生成，展示了涌现行为的强大潜力。"}}
{"id": "2507.13364", "title": "OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning", "authors": ["Siddharth Srivastava", "Gaurav Sharma"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13364v1", "summary": "We present a novel multimodal multitask network and associated training\nalgorithm. The method is capable of ingesting data from approximately 12\ndifferent modalities namely image, video, audio, text, depth, point cloud, time\nseries, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed\napproach utilizes modality specialized tokenizers, a shared transformer\narchitecture, and cross-attention mechanisms to project the data from different\nmodalities into a unified embedding space. It addresses multimodal and\nmultitask scenarios by incorporating modality-specific task heads for different\ntasks in respective modalities. We propose a novel pretraining strategy with\niterative modality switching to initialize the network, and a training\nalgorithm which trades off fully joint training over all modalities, with\ntraining on pairs of modalities at a time. We provide comprehensive evaluation\nacross 25 datasets from 12 modalities and show state of the art performances,\ndemonstrating the effectiveness of the proposed architecture, pretraining\nstrategy and adapted multitask training.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13364v1", "cate": "cs.CV", "date": "2025-07-06", "updated": "2025-07-06", "AI": {"title_translation": "OmniVec2——一种用于大规模多模态和多任务学习的新型基于Transformer的网络", "tldr": "提出了一种名为OmniVec2的新型Transformer网络，它能处理12种模态数据，通过共享Transformer、跨注意力机制和新颖的预训练及训练策略，在25个数据集上实现了SOTA的多模态多任务学习性能。", "motivation": "旨在开发一种能够处理大规模多模态和多任务学习的新型网络架构和训练算法，以统一来自多种不同模态的数据。", "method": "提出了一种名为OmniVec2的多模态多任务网络及其训练算法。该方法使用模态专用分词器、共享Transformer架构和交叉注意力机制，将来自约12种不同模态（如图像、视频、音频、文本等）的数据投射到统一的嵌入空间。通过集成模态特定的任务头来处理多任务场景。提出了一种新颖的迭代模态切换预训练策略，以及一种权衡所有模态联合训练与成对模态训练的算法。", "result": "在来自12种模态的25个数据集上进行了全面评估，并展示了最先进的性能，证明了所提出的架构、预训练策略和多任务训练方法的有效性。", "conclusion": "该研究成功开发并验证了一种名为OmniVec2的新型Transformer网络，它能够有效地进行大规模多模态和多任务学习，并在多个数据集上取得了最先进的性能。", "translation": "我们提出了一种新颖的多模态多任务网络及其相关的训练算法。该方法能够处理来自大约12种不同模态的数据，包括图像、视频、音频、文本、深度、点云、时间序列、表格、图、X射线、红外、IMU和高光谱。所提出的方法利用模态专用分词器、共享Transformer架构和交叉注意力机制，将来自不同模态的数据投射到统一的嵌入空间。它通过为各自模态中的不同任务整合模态特定的任务头来解决多模态和多任务场景。我们提出了一种新颖的预训练策略，采用迭代模态切换来初始化网络，以及一种训练算法，该算法权衡了所有模态的完全联合训练与一次仅对成对模态进行训练。我们在来自12种模态的25个数据集上提供了全面的评估，并展示了最先进的性能，证明了所提出的架构、预训练策略和改进的多任务训练的有效性。", "summary": "OmniVec2是一种新型的基于Transformer的多模态多任务网络。它能够处理多达12种不同模态的数据，通过模态专用分词器、共享Transformer和跨注意力机制将数据统一到嵌入空间。该网络通过模态特定任务头处理多任务，并引入了迭代模态切换预训练和灵活的成对模态训练算法。在25个数据集上的评估显示，OmniVec2在多模态多任务学习中达到了最先进的性能。", "keywords": "多模态学习, 多任务学习, Transformer, 统一嵌入, OmniVec2", "comments": "这篇论文提出了一种创新的多模态多任务学习框架，其亮点在于能够整合多达12种模态的数据，并通过共享Transformer架构实现统一表示。特别值得注意的是其新颖的预训练策略（迭代模态切换）和训练算法（权衡联合训练与成对训练），这对于处理大规模异构数据和复杂任务具有重要意义。在如此广泛的模态和数据集上取得SOTA性能，显示了其强大的泛化能力和实用潜力。"}}
{"id": "2507.14018", "title": "Distortion-Aware Hybrid Beamforming for Integrated Sensing and Communication", "authors": ["Zeyuan Zhang", "Yue Xiu", "Phee Lep Yeoh", "Guangyi Liu", "Zixing Wu", "Ning Wei"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14018v1", "summary": "This paper investigates a practical partially-connected hybrid beamforming\ntransmitter for integrated sensing and communication (ISAC) with distortion\nfrom nonlinear power amplification. For this ISAC system, we formulate a\ncommunication rate and sensing mutual information maximization problem driven\nby our distortion-aware hybrid beamforming design. To address this non-convex\nproblem, we first solve for a fully digital beamforming matrix by alternatively\nsolving three sub-problems using manifold optimization (MO) and our derived\nclosed-form solutions. The analog and digital beamforming matrices are then\nobtained through a decomposition algorithm. Numerical results demonstrate that\nthe proposed algorithm can improve overall ISAC performance compared to\ntraditional beamforming methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14018v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "失真感知混合波束成形用于集成传感与通信", "tldr": "研究了一种考虑非线性功放失真的ISAC系统混合波束成形设计，通过优化通信速率和传感互信息，提出了一种新算法，数值结果表明其能提升ISAC性能。", "motivation": "该研究旨在解决集成传感与通信（ISAC）系统中，由非线性功放引起的失真对混合波束成形性能的影响，并在此背景下最大化通信速率和传感互信息。", "method": "文章提出了一种失真感知的混合波束成形设计。为解决非凸优化问题，首先通过流形优化（MO）和闭式解交替求解三个子问题，得到全数字波束成形矩阵；然后通过分解算法获得模拟和数字波束成形矩阵。", "result": "数值结果表明，所提出的算法与传统波束成形方法相比，能够提高整体ISAC性能。", "conclusion": "所提出的失真感知混合波束成形算法能够有效提升集成传感与通信系统的性能。", "translation": "本文研究了一种实用的部分连接混合波束成形发射机，用于集成传感与通信（ISAC），并考虑了非线性功率放大引起的失真。对于这个ISAC系统，我们提出了一个由失真感知混合波束成形设计驱动的通信速率和传感互信息最大化问题。为了解决这个非凸问题，我们首先通过使用流形优化（MO）和我们推导的闭式解交替解决三个子问题来求解一个全数字波束成形矩阵。然后，通过分解算法获得模拟和数字波束成形矩阵。数值结果表明，所提出的算法与传统波束成形方法相比，可以提高整体ISAC性能。", "summary": "本文针对存在非线性功放失真的集成传感与通信（ISAC）系统，提出了一种失真感知的混合波束成形设计。通过构建通信速率和传感互信息最大化问题，并采用流形优化、闭式解以及分解算法求解，该研究成功地解决了非凸优化难题。数值仿真结果验证了所提算法能有效提升ISAC系统的整体性能。", "keywords": "混合波束成形, 集成传感与通信, 非线性失真, 流形优化, 性能提升", "comments": "该论文的创新点在于考虑了ISAC系统中非线性功放引起的失真，这在实际应用中是一个重要且常见的问题。通过提出失真感知的混合波束成形设计并采用组合优化方法，为提升实际ISAC系统的性能提供了有效途径。"}}
{"id": "2507.14114", "title": "Weighted Matching in a Poly-Streaming Model", "authors": ["Ahammed Ullah", "S. M. Ferdous", "Alex Pothen"], "categories": ["cs.DS", "cs.DC"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      40 pages, ESA 2025", "url": "http://arxiv.org/abs/2507.14114v1", "summary": "We introduce the poly-streaming model, a generalization of streaming models\nof computation in which $k$ processors process $k$ data streams containing a\ntotal of $N$ items. The algorithm is allowed $O\\left(f(k)\\cdot M_1\\right)$\nspace, where $M_1$ is either $o\\left(N\\right)$ or the space bound for a\nsequential streaming algorithm. Processors may communicate as needed.\nAlgorithms are assessed by the number of passes, per-item processing time,\ntotal runtime, space usage, communication cost, and solution quality.\n  We design a single-pass algorithm in this model for approximating the maximum\nweight matching (MWM) problem. Given $k$ edge streams and a parameter\n$\\varepsilon > 0$, the algorithm computes a\n$\\left(2+\\epsilon\\right)$-approximate MWM. We analyze its performance in a\nshared-memory parallel setting: for any constant $\\varepsilon > 0$, it runs in\ntime $\\widetilde{O}\\left(L_{\\max}+n\\right)$, where $n$ is the number of\nvertices and $L_{\\max}$ is the maximum stream length. It supports\n$O\\left(1\\right)$ per-edge processing time using $\\widetilde{O}\\left(k\\cdot\nn\\right)$ space. We further generalize the design to hierarchical\narchitectures, in which $k$ processors are partitioned into $r$ groups, each\nwith its own shared local memory. The total intergroup communication is\n$\\widetilde{O}\\left(r \\cdot n\\right)$ bits, while all other performance\nguarantees are preserved.\n  We evaluate the algorithm on a shared-memory system using graphs with\ntrillions of edges. It achieves substantial speedups as $k$ increases and\nproduces matchings with weights significantly exceeding the theoretical\nguarantee. On our largest test graph, it reduces runtime by nearly two orders\nof magnitude and memory usage by five orders of magnitude compared to an\noffline algorithm.", "comment": "40 pages, ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.14114v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "加权匹配在多流模型中", "tldr": "引入多流模型，设计并评估了一个单趟算法，用于在大规模图上近似最大加权匹配，实现了显著的性能提升。", "motivation": "引入了一种新的计算模型——多流模型，以处理包含大量项目的多数据流。在此模型下，需要开发高效算法来解决大规模图上的最大加权匹配（MWM）问题，以应对传统流式算法的局限性。", "method": "本文引入了多流模型，并在此模型中设计了一个单趟算法来近似最大加权匹配（MWM）问题。该算法能够计算$(2+\\epsilon)$-近似MWM，并在共享内存并行设置下进行了性能分析，实现了高效的时间和空间复杂度。此外，该设计还被推广到分层架构。", "result": "在多流模型中设计了一个单趟算法，能够计算$(2+\\epsilon)$-近似最大加权匹配。在共享内存并行设置下，算法运行时间为$\\widetilde{O}\\left(L_{\\max}+n\\right)$，每边处理时间为$O(1)$，空间使用为$\\widetilde{O}\\left(k\\cdot n\\right)$。算法设计推广至分层架构，保持性能保证，总组间通信为$\\widetilde{O}\\left(r \\cdot n\\right)$比特。在具有万亿条边的图上进行评估，算法实现了显著的加速，并且生成的匹配权重显著超过理论保证。与离线算法相比，在最大测试图上运行时长减少了近两个数量级，内存使用减少了五个数量级。", "conclusion": "本文提出的多流模型下的单趟最大加权匹配近似算法，在大规模图数据处理上展现出卓越的效率和实用性，尤其在处理万亿边级别的图时，能够显著降低运行时间和内存消耗，并提供高质量的匹配结果。", "translation": "我们引入了多流模型，这是一种流式计算模型的泛化，其中$k$个处理器处理包含总共$N$个项目的$k$个数据流。该算法允许$O\\left(f(k)\\cdot M_1\\right)$空间，其中$M_1$要么是$o\\left(N\\right)$，要么是顺序流式算法的空间上限。处理器可以根据需要进行通信。算法通过通过次数、每项处理时间、总运行时间、空间使用、通信成本和解决方案质量进行评估。\n我们在此模型中设计了一个单趟算法，用于近似最大加权匹配（MWM）问题。给定$k$个边流和一个参数$\\varepsilon > 0$，该算法计算一个$\\left(2+\\epsilon\\right)$-近似MWM。我们在共享内存并行设置中分析了其性能：对于任何常数$\\varepsilon > 0$，它在$\\widetilde{O}\\left(L_{\\max}+n\\right)$时间内运行，其中$n$是顶点数，$L_{\\max}$是最大流长度。它支持$O\\left(1\\right)$的每边处理时间，使用$\\widetilde{O}\\left(k\\cdot n\\right)$空间。我们进一步将设计推广到分层架构，其中$k$个处理器被分成$r$个组，每个组都有自己的共享本地内存。总组间通信为$\\widetilde{O}\\left(r \\cdot n\\right)$比特，同时保留所有其他性能保证。\n我们在共享内存系统上使用具有万亿条边的图对算法进行了评估。随着$k$的增加，它实现了显著的加速，并产生了显著超出理论保证的匹配权重。在我们最大的测试图上，与离线算法相比，它将运行时间减少了近两个数量级，内存使用减少了五个数量级。", "summary": "本文引入并定义了多流模型，这是一种处理大规模数据流的新计算范式。在此模型下，作者设计了一个单趟算法来近似最大加权匹配（MWM）问题，能够计算$(2+\\epsilon)$-近似MWM。该算法在共享内存并行和分层架构下均展现出高效的性能，包括优化的时间、空间和通信复杂度。实验评估表明，该算法在处理万亿边级别的图时，相比传统离线算法，在运行时长和内存使用上实现了数量级的显著优化，并且生成的匹配质量优于理论保证。", "keywords": "多流模型, 最大加权匹配, 流算法, 大规模图, 并行计算", "comments": "本文的创新点在于提出了“多流模型”这一新的计算范式，能够更好地适应现代大规模数据处理的需求。所设计的单趟近似算法在处理万亿边图数据时，展现出卓越的效率和可扩展性，尤其是在资源受限的流式环境中。实验结果远超理论近似比，凸显了算法在实际应用中的强大潜力。"}}
{"id": "2506.20487", "title": "A Survey of Behavior Foundation Model: Next-Generation Whole-Body Control System of Humanoid Robots", "authors": ["Mingqi Yuan", "Tao Yu", "Wenqi Ge", "Xiuyong Yao", "Huijiang Wang", "Jiayu Chen", "Xin Jin", "Bo Li", "Hua Chen", "Wei Zhang", "Wenjun Zeng"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      18 pages, 9 figures", "url": "http://arxiv.org/abs/2506.20487v3", "summary": "Humanoid robots are drawing significant attention as versatile platforms for\ncomplex motor control, human-robot interaction, and general-purpose physical\nintelligence. However, achieving efficient whole-body control (WBC) in\nhumanoids remains a fundamental challenge due to sophisticated dynamics,\nunderactuation, and diverse task requirements. While learning-based controllers\nhave shown promise for complex tasks, their reliance on labor-intensive and\ncostly retraining for new scenarios limits real-world applicability. To address\nthese limitations, behavior(al) foundation models (BFMs) have emerged as a new\nparadigm that leverages large-scale pre-training to learn reusable primitive\nskills and broad behavioral priors, enabling zero-shot or rapid adaptation to a\nwide range of downstream tasks. In this paper, we present a comprehensive\noverview of BFMs for humanoid WBC, tracing their development across diverse\npre-training pipelines. Furthermore, we discuss real-world applications,\ncurrent limitations, urgent challenges, and future opportunities, positioning\nBFMs as a key approach toward scalable and general-purpose humanoid\nintelligence. Finally, we provide a curated and long-term list of BFM papers\nand projects to facilitate more subsequent research, which is available at\nhttps://github.com/yuanmingqi/awesome-bfm-papers.", "comment": "18 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2506.20487v3", "cate": "cs.RO", "date": "2025-06-25", "updated": "2025-07-18", "AI": {"title_translation": "行为基础模型综述：下一代人形机器人全身控制系统", "tldr": "本综述探讨了行为基础模型（BFMs）作为解决人形机器人全身控制（WBC）挑战的新范式，通过大规模预训练实现可重用技能和快速适应，并讨论了其应用、局限性、挑战和未来机遇。", "motivation": "人形机器人在复杂运动控制、人机交互和通用物理智能方面具有巨大潜力，但其高效全身控制（WBC）面临复杂动力学、欠驱动和多样化任务要求等挑战。传统的学习型控制器需要耗时且昂贵的再训练，限制了实际应用。因此，需要一种新的范式来解决这些限制，实现可扩展和通用的类人智能。", "method": "本文对行为基础模型（BFMs）在人形机器人全身控制（WBC）中的应用进行了全面综述，追溯了其在不同预训练流程中的发展。此外，还讨论了实际应用、当前局限性、紧迫挑战和未来机遇。最后，提供了一个精选的、长期更新的BFM论文和项目列表。", "result": "本文全面概述了行为基础模型（BFMs）在人形机器人全身控制（WBC）中的发展，并讨论了其在实际应用中的潜力以及面临的局限性和挑战。BFMs被定位为实现可扩展和通用人形智能的关键方法。提供了一个精选的BFM论文和项目列表，以促进后续研究。", "conclusion": "行为基础模型（BFMs）代表了人形机器人全身控制（WBC）领域的一个新范式，通过大规模预训练和可重用技能，有望解决当前挑战并实现通用人形智能。尽管仍存在局限性，但BFMs是未来研究的关键方向。", "translation": "人形机器人作为复杂运动控制、人机交互和通用物理智能的多功能平台，正受到广泛关注。然而，由于复杂的动力学、欠驱动和多样化的任务要求，在人形机器人中实现高效的全身控制（WBC）仍然是一个根本性挑战。尽管基于学习的控制器在复杂任务中显示出前景，但它们对新场景的劳动密集型和昂贵的再训练的依赖限制了实际应用。为了解决这些限制，行为基础模型（BFMs）作为一种新范式应运而生，它利用大规模预训练来学习可重用的原始技能和广泛的行为先验知识，从而实现对各种下游任务的零样本或快速适应。在本文中，我们全面概述了用于人形机器人WBC的BFM，追溯了它们在不同预训练流程中的发展。此外，我们讨论了实际应用、当前局限性、紧迫挑战和未来机遇，将BFM定位为实现可扩展和通用人形智能的关键方法。最后，我们提供了一个精选的、长期更新的BFM论文和项目列表，以促进更多的后续研究，该列表可在https://github.com/yuanmingqi/awesome-bfm-papers上获取。", "summary": "本综述探讨了行为基础模型（BFMs）如何作为一种新范式，通过大规模预训练解决人形机器人全身控制（WBC）的挑战。文章全面概述了BFMs的发展、应用、局限性、挑战和未来机遇，并将其定位为实现通用人形智能的关键方法。此外，论文还提供了一个精选的BFM研究资源列表，以促进该领域的进一步发展。", "keywords": "行为基础模型, 人形机器人, 全身控制, 预训练, 机器人智能", "comments": "本综述论文系统地梳理了行为基础模型（BFMs）在人形机器人全身控制领域的应用和发展，清晰地指出了当前方法的局限性与未来机遇，并提供了一个宝贵的资源列表，对于推动该领域的研究具有重要指导意义。其创新之处在于将BFM这一新兴概念引入人形机器人控制，并对其进行全面审视，为下一代通用人形智能的发展奠定了理论基础。"}}
{"id": "2507.13661", "title": "Testing Autonomous Driving Systems -- What Really Matters and What Doesn't", "authors": ["Changwen Li", "Joseph Sifakis", "Rongjie Yan", "Jian Zhang"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13661v1", "summary": "Despite extensive research, the testing of autonomous driving systems (ADS)\nlandscape remains fragmented, and there is currently no basis for an informed\ntechnical assessment of the importance and contribution of the current state of\nthe art. This paper attempts to address this problem by exploring two\ncomplementary aspects.\n  First, it proposes a framework for comparing existing test methods in terms\nof their intrinsic effectiveness and validity. It shows that many methods do\nnot meet both of these requirements. Either because they are based on criteria\nthat do not allow for rapid, inexpensive, and comprehensive detection of\nfailures, or because the degree of validity of the properties tested cannot be\naccurately estimated. In particular, it is shown that most critical test\nmethods do not take into account the nominal operational capabilities of\nautopilots and generate scenarios that are impossible for the tested vehicles\nto handle, resulting in unjustified rejections.\n  Secondly, the paper shows that test effectiveness and validity are highly\ndependent on how autopilots are designed: how they choose between different\ncontrol policies to perform maneuvers, as well as on the reproducibility of the\nresults. In fact, most test methods take for granted two principles underlying\ntraditional methods, but do not generally apply to ADS. We maintain that the\nabsence of rationality and determinacy significantly impairs the effectiveness\nand validity of test methods, and provide test results on eight open\nautopilots, in which most do not satisfy these properties, thereby illustrating\nthis fact.\n  We conclude that under the current state of the art, it is impossible to\nobtain strong enough guarantees for essential autopilot properties and\nrecommend that autopilots be developed with a view to both rationality and\ndeterminacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13661v1", "cate": "cs.SE", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "自动驾驶系统测试——什么真正重要，什么不重要", "tldr": "现有自动驾驶系统（ADS）测试分散且无效。本文提出评估框架，指出多数方法因标准缺陷或未考虑自动驾驶仪的理性和确定性而失效。建议开发自动驾驶仪时需兼顾理性和确定性，以获得更强的保障。", "motivation": "现有自动驾驶系统（ADS）测试领域分散，缺乏对现有技术水平重要性和贡献的知情技术评估基础。", "method": "本文首先提出了一个框架，用于从内在有效性和正确性方面比较现有测试方法。其次，论文表明测试的有效性和正确性高度依赖于自动驾驶仪的设计方式，特别是其决策选择和结果的可复现性。通过对八个开放式自动驾驶仪的测试，论证了理性和确定性对测试有效性的影响。", "result": "许多现有测试方法在有效性和正确性上不足，因为它们基于不佳的标准或未能准确评估所测试属性的有效性。多数关键测试方法未考虑自动驾驶仪的正常操作能力，导致不合理的拒绝。测试有效性和正确性高度依赖于自动驾驶仪的设计，特别是其理性和确定性。对八个开放式自动驾驶仪的测试结果表明，大多数不满足这些特性。", "conclusion": "在当前技术水平下，无法为自动驾驶仪的基本属性获得足够强的保证，建议在开发自动驾驶仪时考虑理性和确定性。", "translation": "尽管进行了广泛研究，自动驾驶系统（ADS）的测试领域仍然分散，目前缺乏对现有技术水平的重要性和贡献进行知情技术评估的基础。本文试图通过探索两个互补的方面来解决这个问题。\n首先，它提出了一个框架，用于从内在有效性和正确性方面比较现有测试方法。结果表明，许多方法未能同时满足这两个要求。这要么是因为它们所基于的标准不允许快速、廉价和全面地检测故障，要么是因为所测试属性的有效性程度无法准确估计。特别是，研究表明大多数关键测试方法没有考虑自动驾驶仪的标称操作能力，并生成了被测试车辆无法处理的场景，导致不合理的拒绝。\n其次，论文表明测试的有效性和正确性高度依赖于自动驾驶仪的设计方式：它们如何选择不同的控制策略来执行机动，以及结果的可复现性。事实上，大多数测试方法都理所当然地接受了传统方法所依据的两个原则，但这些原则通常不适用于ADS。我们认为，缺乏理性和确定性会显著损害测试方法的有效性和正确性，并通过对八个开放式自动驾驶仪的测试结果来证实这一点，其中大多数不满足这些特性，从而说明了这一事实。\n我们得出结论，在当前技术水平下，不可能为基本的自动驾驶仪属性获得足够强的保证，并建议在开发自动驾驶仪时兼顾理性和确定性。", "summary": "本文旨在解决自动驾驶系统（ADS）测试领域分散且效率低下的问题。它提出了一个评估现有测试方法有效性和正确性的框架，并指出许多方法因标准不当或生成不切实际的场景而失效。此外，论文还表明测试的有效性高度依赖于自动驾驶仪的设计方式，特别是其理性和确定性。通过对八个开放式自动驾驶仪的测试，文章揭示了大多数不具备这些关键特性，从而损害了测试的有效性。作者总结认为，要为ADS提供强大的保证，自动驾驶仪的开发必须兼顾理性和确定性。", "keywords": "自动驾驶系统, 测试, 有效性, 正确性, 理性, 确定性", "comments": "这篇论文揭示了当前自动驾驶系统测试的严重缺陷，强调不仅要关注测试方法，还要考虑自动驾驶仪本身的设计原则。它将理性和确定性作为可测试性的基本属性，这是一种重要的见解，将范式从纯粹基于场景的测试转向考虑被测系统的固有特性。这对于开发健壮和可信赖的自动驾驶系统至关重要。"}}
{"id": "2507.11482", "title": "Illuminating the Three Dogmas of Reinforcement Learning under Evolutionary Light", "authors": ["Mani Hamidi", "Terrence W. Deacon"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11482v2", "summary": "Three core tenets of reinforcement learning (RL)--concerning the definition\nof agency, the objective of learning, and the scope of the reward\nhypothesis--have been highlighted as key targets for conceptual revision, with\nmajor implications for theory and application. We propose a framework, inspired\nby open-ended evolutionary theory, to reconsider these three \"dogmas.\" We\nrevisit each assumption and address related concerns raised alongside them. To\nmake our arguments relevant to RL as a model of biological learning, we first\nestablish that evolutionary dynamics can plausibly operate within living brains\nover an individual's lifetime, and are not confined to cross-generational\nprocesses. We begin by revisiting the second dogma, drawing on evolutionary\ninsights to enrich the \"adaptation-rather-than-search\" view of learning. We\nthen address the third dogma regarding the limits of the reward hypothesis,\nusing analogies from evolutionary fitness to illuminate the scalar reward vs.\nmulti-objective debate. After discussing practical implications for exploration\nin RL, we turn to the first--and arguably most fundamental--issue: the absence\nof a formal account of agency. We argue that unlike the other two problems, the\nevolutionary paradigm alone cannot resolve the agency question, though it\ngestures in a productive direction. We advocate integrating ideas from\norigins-of-life theory, where the thermodynamics of sustenance and replication\noffer promising foundations for understanding agency and resource-constrained\nreinforcement learning in biological systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11482v2", "cate": "cs.AI", "date": "2025-07-15", "updated": "2025-07-18", "AI": {"title_translation": "在进化之光的照耀下阐明强化学习的三大教条", "tldr": "本文提出了一个受开放式进化理论启发的框架，重新审视强化学习的三个核心“教条”：代理的定义、学习目标和奖励假设的范围。文章论证了进化动力学可以在个体生命周期内发生，并运用进化洞察力重新审视了学习目标和奖励假设。对于代理问题，作者认为单独的进化范式不足以解决，但指出结合生命起源理论可能提供新的基础。", "motivation": "强化学习的三个核心教条——关于代理的定义、学习目标和奖励假设的范围——被认为是需要概念性修正的关键目标，这对理论和应用都有重大影响。本文旨在重新审视这些教条。", "method": "本文提出了一个受开放式进化理论启发的框架，以重新思考强化学习的三个“教条”。首先，建立进化动力学可以在个体生命周期内在活体大脑中运行的论点。然后，利用进化洞察力重新审视学习目标（第二个教条），并使用进化适应度的类比来阐明奖励假设的局限性（第三个教条）。对于代理问题（第一个教条），文章主张整合生命起源理论的思想，特别是维持和复制的热力学原理。", "result": "本文通过进化理论为强化学习的第二个和第三个教条提供了新的视角。研究发现，单一的进化范式不足以完全解决代理问题，但指明了一个富有成效的方向，即整合生命起源理论中关于维持和复制的热力学思想，为理解生物系统中的代理和资源受限强化学习奠定基础。", "conclusion": "进化理论为重新思考强化学习的学习目标和奖励假设提供了宝贵的见解。然而，要理解代理问题，需要整合生命起源理论的思想，其中维持和复制的热力学原理为理解生物系统中的代理和资源受限强化学习提供了有前景的基础。", "translation": "强化学习（RL）的三个核心原则——关于代理的定义、学习目标和奖励假设的范围——已被强调为概念修正的关键目标，这对理论和应用具有重大影响。我们提出了一个受开放式进化理论启发的框架，以重新审视这三个“教条”。我们重新审视了每个假设，并解决了随之产生的相关问题。为了使我们的论点与作为生物学习模型的强化学习相关，我们首先确定进化动力学可以在个体生命周期内在活体大脑中合理地运作，而不仅仅局限于跨代过程。我们首先重新审视第二个教条，借鉴进化洞察力来丰富学习的“适应而非搜索”观点。然后，我们讨论了关于奖励假设限制的第三个教条，利用进化适应度的类比来阐明标量奖励与多目标之争。在讨论了强化学习中探索的实际意义后，我们转向第一个——也是可以说是最基本的问题：缺乏对代理的正式解释。我们认为，与其他两个问题不同，单独的进化范式无法解决代理问题，尽管它指出了一个富有成效的方向。我们主张整合生命起源理论的思想，其中维持和复制的热力学原理为理解生物系统中的代理和资源受限强化学习提供了有前景的基础。", "summary": "本文提出一个受开放式进化理论启发的框架，重新审视强化学习的三个核心“教条”：代理的定义、学习目标和奖励假设的范围。作者首先论证进化动力学可以在个体生命周期内而非仅跨代发生。然后，他们利用进化洞察力重新审视学习目标（第二个教条），并用进化适应度类比来探讨奖励假设的局限性（第三个教条）。对于代理问题（第一个教条），文章认为单独的进化范式不足以解决，但指出通过整合生命起源理论中关于维持和复制的热力学思想，可以为理解生物系统中的代理和资源受限强化学习提供基础。", "keywords": "强化学习, 进化理论, 代理, 奖励假设, 学习目标", "comments": "这篇论文通过引入进化理论的视角，对强化学习的底层概念进行了深刻的哲学和理论反思，特别是挑战了传统的强化学习范式。其创新之处在于将通常被认为是跨代过程的进化动力学应用于个体生命周期内的学习，并尝试用生物学原理来解释RL的核心问题。然而，对于“代理”问题的解决，作者也承认了单一范式的局限性，并提出了跨学科整合的思路，这显示了其思考的深度。该研究对于未来强化学习理论和生物学习模型的发展具有重要的指导意义。"}}
{"id": "2507.13901", "title": "Software architecture and manual for novel versatile CT image analysis toolbox -- AnatomyArchive", "authors": ["Lei Xu", "Torkel B Brismar"], "categories": ["eess.IV", "cs.CV", "62H35, 68U10", "I.4.10; I.4.7; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      24 pages, 7 figures", "url": "http://arxiv.org/abs/2507.13901v1", "summary": "We have developed a novel CT image analysis package named AnatomyArchive,\nbuilt on top of the recent full body segmentation model TotalSegmentator. It\nprovides automatic target volume selection and deselection capabilities\naccording to user-configured anatomies for volumetric upper- and lower-bounds.\nIt has a knowledge graph-based and time efficient tool for anatomy segmentation\nmask management and medical image database maintenance. AnatomyArchive enables\nautomatic body volume cropping, as well as automatic arm-detection and\nexclusion, for more precise body composition analysis in both 2D and 3D\nformats. It provides robust voxel-based radiomic feature extraction, feature\nvisualization, and an integrated toolchain for statistical tests and analysis.\nA python-based GPU-accelerated nearly photo-realistic segmentation-integrated\ncomposite cinematic rendering is also included. We present here its software\narchitecture design, illustrate its workflow and working principle of\nalgorithms as well provide a few examples on how the software can be used to\nassist development of modern machine learning models. Open-source codes will be\nreleased at https://github.com/lxu-medai/AnatomyArchive for only research and\neducational purposes.", "comment": "24 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13901v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "新型多功能CT图像分析工具箱AnatomyArchive的软件架构与手册", "tldr": "AnatomyArchive是一个基于TotalSegmentator的新型CT图像分析软件包，提供自动化体积选择、分割掩膜管理、体成分分析、放射组学特征提取和可视化功能，并支持机器学习模型开发。", "motivation": "开发一个新型、多功能的CT图像分析软件包AnatomyArchive，以提供自动化的CT图像处理和分析能力，并支持现代机器学习模型的开发。", "method": "AnatomyArchive是基于TotalSegmentator构建的CT图像分析软件包。它采用知识图谱管理分割掩膜和医学图像数据库，实现自动目标体积选择/取消选择、自动体量裁剪、自动手臂检测和排除。它还提供体素级放射组学特征提取、特征可视化、统计分析工具链以及基于Python的GPU加速电影级渲染。", "result": "AnatomyArchive能够实现更精确的2D和3D体成分分析，提供鲁棒的放射组学特征提取和可视化，并集成了统计测试和分析工具链。它还可以辅助现代机器学习模型的开发。", "conclusion": "AnatomyArchive是一个全面且多功能的CT图像分析工具箱，通过提供自动化处理、高级分析和可视化功能，有效地支持医学图像研究和机器学习模型开发。", "translation": "我们开发了一个名为AnatomyArchive的新型CT图像分析软件包，它建立在最近的全身体分割模型TotalSegmentator之上。它根据用户配置的解剖结构，为体积的上限和下限提供自动目标体积选择和取消选择功能。它拥有一个基于知识图谱且时间高效的工具，用于解剖结构分割掩膜管理和医学图像数据库维护。AnatomyArchive支持自动体量裁剪，以及自动手臂检测和排除，以便在2D和3D格式中进行更精确的体成分分析。它提供鲁棒的基于体素的放射组学特征提取、特征可视化，以及一个用于统计测试和分析的集成工具链。其中还包括一个基于Python、GPU加速的近乎逼真的分割集成复合电影渲染功能。我们在此介绍其软件架构设计，阐述其工作流程和算法工作原理，并提供一些关于该软件如何辅助现代机器学习模型开发的示例。开源代码将仅用于研究和教育目的，发布在https://github.com/lxu-medai/AnatomyArchive。", "summary": "AnatomyArchive是一个基于TotalSegmentator开发的新型CT图像分析软件包。它提供了一系列自动化功能，包括目标体积选择与管理、知识图谱驱动的分割掩膜和数据库维护、精确的体成分分析（支持自动裁剪和手臂排除），以及鲁棒的放射组学特征提取、可视化和统计分析。此外，它还包含GPU加速的电影级渲染功能，旨在辅助现代机器学习模型的开发。", "keywords": "CT图像分析, AnatomyArchive, 放射组学, 体成分分析, 机器学习辅助", "comments": "AnatomyArchive的创新之处在于其将TotalSegmentator与知识图谱相结合，实现了高效的CT图像自动化分析，尤其是在体成分分析和放射组学特征提取方面。其集成的工具链和对机器学习模型开发的辅助功能，使其成为一个有潜力的研究工具。开源发布也促进了社区的进一步发展。"}}
{"id": "2410.03020", "title": "On Logical Extrapolation for Mazes with Recurrent and Implicit Networks", "authors": ["Brandon Knutson", "Amandin Chyba Rabeendran", "Michael Ivanitskiy", "Jordan Pettyjohn", "Cecilia Diniz-Behn", "Samy Wu Fung", "Daniel McKenzie"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.03020v2", "summary": "Recent work suggests that certain neural network architectures --\nparticularly recurrent neural networks (RNNs) and implicit neural networks\n(INNs) -- are capable of logical extrapolation. When trained on easy instances\nof a task, these networks (henceforth: logical extrapolators) can generalize to\nmore difficult instances. Previous research has hypothesized that logical\nextrapolators do so by learning a scalable, iterative algorithm for the given\ntask which converges to the solution. We examine this idea more closely in the\ncontext of a single task: maze solving. By varying test data along multiple\naxes -- not just maze size -- we show that models introduced in prior work fail\nin a variety of ways, some expected and others less so. It remains uncertain\nwhether any of these models has truly learned an algorithm. However, we provide\nevidence that a certain RNN has approximately learned a form of\n`deadend-filling'. We show that training these models on more diverse data\naddresses some failure modes but, paradoxically, does not improve logical\nextrapolation. We also analyze convergence behavior, and show that models\nexplicitly trained to converge to a fixed point are likely to do so when\nextrapolating, while models that are not may exhibit more exotic limiting\nbehavior such as limit cycles, even when they correctly solve the problem. Our\nresults (i) show that logical extrapolation is not immune to the problem of\ngoal misgeneralization, and (ii) suggest that analyzing the dynamics of\nextrapolation may yield insights into designing better logical extrapolators.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.03020v2", "cate": "cs.LG", "date": "2024-10-03", "updated": "2025-07-18", "AI": {"title_translation": "关于循环和隐式网络在迷宫逻辑外推上的研究", "tldr": "该研究深入探讨了循环神经网络（RNNs）和隐式神经网络（INNs）在迷宫解决任务中的逻辑外推能力。结果显示，现有模型在外推时存在多种失败模式，且逻辑外推仍面临目标泛化错误问题。研究强调分析外推动态对设计更好的外推器至关重要。", "motivation": "近期研究表明，循环神经网络（RNNs）和隐式神经网络（INNs）等特定神经网络架构具备逻辑外推能力，即在简单任务实例上训练后，能泛化到更困难的实例。此前研究假设这些网络通过学习可扩展的迭代算法来解决问题。本文旨在在迷宫求解任务中更深入地检验这一假设。", "method": "研究在一个单一任务——迷宫求解——的背景下，通过沿着多个维度（不仅仅是迷宫大小）改变测试数据来检验逻辑外推器的表现。研究分析了现有模型的失败模式，并探讨了在更多样化数据上训练模型的效果。此外，还分析了模型的收敛行为，特别是那些明确训练以收敛到不动点的模型以及其他模型的极限行为。", "result": "研究发现，先前工作中引入的模型在多种情况下会失败，其中一些是意料之中，另一些则不然。目前仍不确定这些模型是否真正学习了算法。然而，研究提供了证据表明特定的RNN近似学习了一种“死胡同填充”的形式。在更多样化的数据上训练这些模型可以解决某些失败模式，但矛盾的是，并未改善逻辑外推能力。研究还显示，明确训练以收敛到不动点的模型在进行外推时很可能实现收敛，而未受此训练的模型可能会表现出更奇特的极限行为，如极限环，即使它们能正确解决问题。", "conclusion": "研究结果表明，逻辑外推并非不受目标泛化错误问题的影响。此外，分析外推的动态行为可能为设计更好的逻辑外推器提供见解。", "translation": "最近的研究表明，某些神经网络架构——特别是循环神经网络（RNNs）和隐式神经网络（INNs）——能够进行逻辑外推。当在任务的简单实例上进行训练时，这些网络（此后称为：逻辑外推器）可以泛化到更困难的实例。先前的研究假设逻辑外推器通过学习一个可扩展的、迭代的算法来解决给定任务并收敛到解决方案。我们在一项任务：迷宫求解的背景下更仔细地研究了这一思想。通过沿多个轴（不仅仅是迷宫大小）改变测试数据，我们发现先前工作中引入的模型以各种方式失败，有些是预期的，有些则不然。目前仍不确定这些模型中是否有任何一个真正学习了算法。然而，我们提供了证据表明某个RNN近似学习了一种“死胡同填充”的形式。我们表明，在更多样化的数据上训练这些模型可以解决一些失败模式，但矛盾的是，并未改善逻辑外推。我们还分析了收敛行为，并表明明确训练以收敛到不动点的模型在进行外推时很可能实现收敛，而未受此训练的模型可能会表现出更奇特的极限行为，如极限环，即使它们正确解决了问题。我们的结果（i）表明逻辑外推并非不受目标泛化错误问题的影响，并且（ii）表明分析外推的动态可能为设计更好的逻辑外推器提供见解。", "summary": "本研究深入探讨了循环神经网络（RNNs）和隐式神经网络（INNs）在迷宫求解任务中的逻辑外推能力。通过多维度测试数据，揭示了现有模型在外推时的多种失败模式，并发现即使在更多样化数据上训练也无法改善逻辑外推。研究还分析了模型的收敛行为，并指出逻辑外推面临目标泛化错误问题，建议通过分析外推动态来改进模型设计。", "keywords": "逻辑外推, 循环神经网络, 隐式神经网络, 迷宫求解, 收敛行为", "comments": "该论文对神经网络的逻辑外推能力进行了批判性审视，特别是针对RNNs和INNs。其创新之处在于通过多维度数据测试揭示了现有模型的局限性，并提出了“目标泛化错误”的概念。研究强调了理解模型内部动态而非仅关注表面性能的重要性，为未来设计更鲁棒的逻辑外推器提供了新的研究方向。其局限性在于未能提出一个完全解决逻辑外推问题的新模型，但为后续研究奠定了基础。"}}
{"id": "2507.13366", "title": "Leveraging the Spatial Hierarchy: Coarse-to-fine Trajectory Generation via Cascaded Hybrid Diffusion", "authors": ["Baoshen Guo", "Zhiqing Hong", "Junyi Li", "Shenhao Wang", "Jinhua Zhao"], "categories": ["cs.SI", "cs.CV"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13366v1", "summary": "Urban mobility data has significant connections with economic growth and\nplays an essential role in various smart-city applications. However, due to\nprivacy concerns and substantial data collection costs, fine-grained human\nmobility trajectories are difficult to become publicly available on a large\nscale. A promising solution to address this issue is trajectory synthesizing.\nHowever, existing works often ignore the inherent structural complexity of\ntrajectories, unable to handle complicated high-dimensional distributions and\ngenerate realistic fine-grained trajectories. In this paper, we propose\nCardiff, a coarse-to-fine Cascaded hybrid diffusion-based trajectory\nsynthesizing framework for fine-grained and privacy-preserving mobility\ngeneration. By leveraging the hierarchical nature of urban mobility, Cardiff\ndecomposes the generation process into two distinct levels, i.e., discrete road\nsegment-level and continuous fine-grained GPS-level: (i) In the segment-level,\nto reduce computational costs and redundancy in raw trajectories, we first\nencode the discrete road segments into low-dimensional latent embeddings and\ndesign a diffusion transformer-based latent denoising network for segment-level\ntrajectory synthesis. (ii) Taking the first stage of generation as conditions,\nwe then design a fine-grained GPS-level conditional denoising network with a\nnoise augmentation mechanism to achieve robust and high-fidelity generation.\nAdditionally, the Cardiff framework not only progressively generates\nhigh-fidelity trajectories through cascaded denoising but also flexibly enables\na tunable balance between privacy preservation and utility. Experimental\nresults on three large real-world trajectory datasets demonstrate that our\nmethod outperforms state-of-the-art baselines in various metrics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13366v1", "cate": "cs.SI", "date": "2025-07-08", "updated": "2025-07-08", "AI": {"title_translation": "利用空间层级：基于级联混合扩散的粗到细轨迹生成", "tldr": "Cardiff是一种粗到细的级联混合扩散框架，用于生成细粒度、保护隐私的城市移动轨迹。", "motivation": "城市移动数据对经济增长和智慧城市应用至关重要，但由于隐私和高昂的数据收集成本，细粒度轨迹难以大规模公开。现有方法未能处理轨迹的结构复杂性和高维分布，无法生成真实的细粒度轨迹。", "method": "本文提出Cardiff框架，利用城市移动的层级性质，将生成过程分解为两个级别：(i) 在离散路段级别，通过将路段编码为低维潜在嵌入并设计基于扩散Transformer的潜在去噪网络进行轨迹合成。(ii) 以第一阶段生成结果为条件，设计带有噪声增强机制的细粒度GPS级条件去噪网络，实现鲁棒和高保真生成。该框架通过级联去噪逐步生成高保真轨迹，并灵活地在隐私保护和实用性之间实现可调平衡。", "result": "在三个大型真实世界轨迹数据集上的实验结果表明，该方法在各项指标上优于现有最先进的基线。", "conclusion": "Cardiff通过利用空间层级和级联混合扩散，有效解决了细粒度城市移动轨迹合成中的隐私和复杂性挑战，并实现了高保真和隐私保护的生成。", "translation": "城市移动数据与经济增长有着显著联系，并在各种智慧城市应用中发挥着重要作用。然而，由于隐私问题和高昂的数据收集成本，细粒度的人类移动轨迹难以大规模公开。解决这个问题的一个有前景的方案是轨迹合成。然而，现有工作往往忽略了轨迹固有的结构复杂性，无法处理复杂的、高维的分布并生成真实的细粒度轨迹。本文提出Cardiff，一个基于粗到细级联混合扩散的轨迹合成框架，用于细粒度和保护隐私的移动生成。通过利用城市移动的层级性质，Cardiff将生成过程分解为两个不同的级别，即离散路段级别和连续细粒度GPS级别：(i) 在路段级别，为了降低计算成本和原始轨迹中的冗余，我们首先将离散路段编码为低维潜在嵌入，并设计一个基于扩散Transformer的潜在去噪网络进行路段级轨迹合成。(ii) 以第一阶段的生成结果为条件，我们随后设计一个带有噪声增强机制的细粒度GPS级别条件去噪网络，以实现鲁棒和高保真生成。此外，Cardiff框架不仅通过级联去噪逐步生成高保真轨迹，而且灵活地实现了隐私保护和实用性之间的可调平衡。在三个大型真实世界轨迹数据集上的实验结果表明，我们的方法在各项指标上优于现有最先进的基线。", "summary": "本文提出了Cardiff，一个基于粗到细级联混合扩散的轨迹合成框架，旨在解决细粒度城市移动轨迹因隐私和数据收集成本高昂而难以获取的问题。Cardiff利用城市移动的空间层级性，将轨迹生成分解为离散路段级和连续GPS级两个阶段，通过潜在去噪网络和条件去噪网络逐步生成高保真轨迹，并能在隐私保护和实用性之间取得平衡。实验证明，Cardiff在多个真实数据集上优于现有方法。", "keywords": "轨迹生成, 扩散模型, 城市移动, 隐私保护, 空间层级", "comments": "Cardiff的创新之处在于其利用空间层级性，将复杂的细粒度轨迹生成任务分解为粗到细的两个阶段，并引入了级联混合扩散模型。这种分层处理方式有效地解决了高维轨迹数据的复杂性，同时兼顾了隐私保护和生成质量，为城市移动数据合成提供了一个高效且实用的解决方案。"}}
{"id": "2507.13551", "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder", "authors": ["Feng Chen", "Weizhe Xu", "Changye Li", "Serguei Pakhomov", "Alex Cohen", "Simran Bhola", "Sandy Yin", "Sunny X Tang", "Michael Mackinley", "Lena Palaniyappan", "Dror Ben-Zeev", "Trevor Cohen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13551v1", "summary": "Formal thought disorder (FTD), a hallmark of schizophrenia spectrum\ndisorders, manifests as incoherent speech and poses challenges for clinical\nassessment. Traditional clinical rating scales, though validated, are\nresource-intensive and lack scalability. Automated speech analysis with\nautomatic speech recognition (ASR) allows for objective quantification of\nlinguistic and temporal features of speech, offering scalable alternatives. The\nuse of utterance timestamps in ASR captures pause dynamics, which are thought\nto reflect the cognitive processes underlying speech production. However, the\nutility of integrating these ASR-derived features for assessing FTD severity\nrequires further evaluation. This study integrates pause features with semantic\ncoherence metrics across three datasets: naturalistic self-recorded diaries\n(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream\nnarratives (PsyCL, n = 43). We evaluated pause related features alongside\nestablished coherence measures, using support vector regression (SVR) to\npredict clinical FTD scores. Key findings demonstrate that pause features alone\nrobustly predict the severity of FTD. Integrating pause features with semantic\ncoherence metrics enhanced predictive performance compared to semantic-only\nmodels, with integration of independent models achieving correlations up to\n\\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best\n\\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance\ngains from semantic and pause features integration held consistently across all\ncontexts, though the nature of pause patterns was dataset-dependent. These\nfindings suggest that frameworks combining temporal and semantic analyses\nprovide a roadmap for refining the assessment of disorganized speech and\nadvance automated speech analysis in psychosis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13551v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "察言观色：结合停顿动态和语义连贯性实现思维障碍的自动化评估", "tldr": "本研究结合语音停顿动态和语义连贯性，显著提升了精神分裂症谱系障碍中形式思维障碍（FTD）严重程度的自动化评估准确性。", "motivation": "形式思维障碍（FTD）是精神分裂症谱系障碍的标志性症状，表现为言语不连贯，临床评估面临挑战。传统的临床评估量表资源密集且缺乏可扩展性。自动化语音分析（ASR）虽能客观量化语言和时间特征，但其衍生的停顿动态特征在评估FTD严重程度方面的效用仍需进一步评估。", "method": "本研究整合了停顿特征与语义连贯性指标，并在三个数据集上进行了评估：自然录制的日记（AVH, n=140）、结构化图片描述（TOPSY, n=72）和梦境叙述（PsyCL, n=43）。研究使用支持向量回归（SVR）模型来预测临床FTD评分。", "result": "研究发现，单独的停顿特征即可有效预测FTD的严重程度。与仅使用语义模型的性能相比，整合停顿特征与语义连贯性指标显著提升了预测性能。独立模型整合后，在TOPSY数据集上，严重病例检测的相关性（rho）高达0.649，AUC达到83.71%（而仅使用语义模型的最佳rho为0.584，AUC为79.23%）。语义和停顿特征整合带来的性能提升在所有语境下均保持一致，尽管停顿模式的性质因数据集而异。", "conclusion": "这些发现表明，结合时间（停顿）和语义分析的框架为完善非组织性言语评估提供了路线图，并推动了精神病学中自动化语音分析的发展。", "translation": "形式思维障碍（FTD）是精神分裂症谱系障碍的标志，表现为言语不连贯，给临床评估带来了挑战。传统的临床评定量表虽然经过验证，但资源密集且缺乏可扩展性。通过自动语音识别（ASR）进行的自动化语音分析可以客观地量化语音的语言和时间特征，提供了可扩展的替代方案。ASR中语段时间戳的使用捕捉了停顿动态，这被认为反映了言语产生背后的认知过程。然而，整合这些ASR衍生特征以评估FTD严重程度的效用需要进一步评估。本研究将停顿特征与语义连贯性指标整合到三个数据集中：自然主义的自录日记（AVH，n=140）、结构化图片描述（TOPSY，n=72）和梦境叙述（PsyCL，n=43）。我们评估了停顿相关特征以及已建立的连贯性测量，使用支持向量回归（SVR）来预测临床FTD分数。主要发现表明，单独的停顿特征能够稳健地预测FTD的严重程度。与仅使用语义模型相比，整合停顿特征与语义连贯性指标增强了预测性能，独立模型整合在严重病例检测方面实现了高达rho = 0.649和AUC = 83.71%的相关性（TOPSY，仅使用语义模型的最佳rho = 0.584和AUC = 79.23%）。语义和停顿特征整合带来的性能提升在所有语境下均保持一致，尽管停顿模式的性质是数据集依赖的。这些发现表明，结合时间分析和语义分析的框架为完善非组织性言语评估提供了路线图，并推动了精神病学中自动化语音分析的发展。", "summary": "本研究旨在通过结合语音停顿动态和语义连贯性，改进形式思维障碍（FTD）的自动化评估。针对传统评估方法的局限性，研究利用ASR技术捕捉言语停顿特征，并将其与语义连贯性指标整合。在三个不同数据集上，使用支持向量回归模型预测FTD严重程度。结果显示，停顿特征本身具有良好的预测能力，而结合停顿和语义特征显著提升了预测性能，在严重病例检测中取得了高达0.649的相关性和83.71%的AUC。研究强调了时间与语义分析结合的框架对于精神病学中非组织性言语评估和自动化语音分析的重要性。", "keywords": "形式思维障碍, 语音分析, 停顿动态, 语义连贯性, 精神分裂症", "comments": "本文的创新之处在于有效地结合了时间（停顿动态）和语义特征来评估形式思维障碍（FTD），并在多个异构数据集上展示了性能的持续提升。这为精神疾病的自动化诊断提供了一个更鲁棒和可扩展的方法，超越了传统评估手段的局限性。其发现为未来发展结合多模态言语特征的自动化评估工具奠定了基础。"}}
{"id": "2507.13626", "title": "Unifying Listener Scoring Scales: Comparison Learning Framework for Speech Quality Assessment and Continuous Speech Emotion Recognition", "authors": ["Cheng-Hung Hu", "Yusuke Yasud", "Akifumi Yoshimoto", "Tomoki Toda"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      Accepted to Interspeech 2025", "url": "http://arxiv.org/abs/2507.13626v1", "summary": "Speech Quality Assessment (SQA) and Continuous Speech Emotion Recognition\n(CSER) are two key tasks in speech technology, both relying on listener\nratings. However, these ratings are inherently biased due to individual\nlistener factors. Previous approaches have introduced a mean listener scoring\nscale and modeled all listener scoring scales in the training set. However, the\nmean listener approach is prone to distortion from averaging ordinal data,\nleading to potential biases. Moreover, learning multiple listener scoring\nscales while inferring based only on the mean listener scale limits\neffectiveness. In contrast, our method focuses on modeling a unified listener\nscoring scale, using comparison scores to correctly capture the scoring\nrelationships between utterances. Experimental results show that our method\neffectively improves prediction performance in both SQA and CSER tasks, proving\nits effectiveness and robustness.", "comment": "Accepted to Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.13626v1", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "统一听众评分量表：用于语音质量评估和连续语音情感识别的比较学习框架", "tldr": "本文提出了一种比较学习框架，通过建模统一的听众评分量表，解决了语音质量评估和连续语音情感识别中听众评分的固有偏差问题，并有效提升了预测性能。", "motivation": "语音质量评估（SQA）和连续语音情感识别（CSER）中的听众评分存在固有的个体偏差。现有方法使用平均听众评分量表，但这容易导致序数数据平均时的失真和潜在偏差，且在推断时仅依赖平均量表会限制有效性。", "method": "提出一种比较学习框架，通过建模统一的听众评分量表，并利用比较分数来准确捕捉话语间的评分关系。", "result": "实验结果表明，该方法在语音质量评估（SQA）和连续语音情感识别（CSER）任务中均有效提高了预测性能。", "conclusion": "提出的方法在语音质量评估和连续语音情感识别任务中表现出有效性和鲁棒性。", "translation": "语音质量评估（SQA）和连续语音情感识别（CSER）是语音技术中的两项关键任务，两者都依赖于听众评分。然而，由于个体听众因素，这些评分本身就存在偏差。以前的方法引入了平均听众评分量表，并在训练集中对所有听众评分量表进行建模。然而，平均听众方法容易因序数数据平均而产生失真，导致潜在的偏差。此外，学习多个听众评分量表同时仅基于平均听众量表进行推断会限制其有效性。相比之下，我们的方法侧重于建模统一的听众评分量表，使用比较分数来正确捕捉话语之间的评分关系。实验结果表明，我们的方法有效提高了SQA和CSER任务的预测性能，证明了其有效性和鲁棒性。", "summary": "本文针对语音质量评估（SQA）和连续语音情感识别（CSER）中听众评分存在的个体偏差问题，提出了一种新的比较学习框架。该框架旨在建模统一的听众评分量表，并利用比较分数来准确反映话语间的评分关系，以克服传统平均听众评分方法导致的失真和有效性限制。实验证明，该方法显著提升了SQA和CSER任务的预测表现。", "keywords": "语音质量评估, 连续语音情感识别, 听众评分量表, 比较学习, 偏差校正", "comments": "这篇论文的创新点在于提出了一个统一的听众评分量表，并使用比较学习来解决听众评分的固有偏差问题，这对于依赖主观评价的语音任务具有重要意义。通过避免对序数数据的简单平均，该方法有望提供更准确和鲁棒的评估。"}}
{"id": "2402.14143", "title": "SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings", "authors": ["Rishabh Bajpai", "Bhooma Aravamuthan"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2402.14143v2", "summary": "Movement disorder diagnosis often relies on expert evaluation of patient\nvideos, but sharing these videos poses privacy risks. Current methods for\nde-identifying videos, such as blurring faces, are often manual, inconsistent,\nor inaccurate. Furthermore, these methods can compromise objective kinematic\nanalysis - a crucial component of diagnosis. To address these challenges, we\ndeveloped SecurePose, an open-source software that simultaneously provides\nreliable de-identification and automated kinematic extraction from videos\nrecorded in clinic settings using smartphones/tablets. SecurePose utilizes pose\nestimation (using OpenPose) to extract full body kinematics, track individuals,\nidentify the patient, and then accurately blur faces in the videos. We\nvalidated SecurePose on gait videos recorded in outpatient clinic visits of 116\nchildren with cerebral palsy, assessing both the accuracy of its\nde-identification compared to the ground truth (manual blurring) and the\nreliability of the intermediate steps of kinematics extraction. Results\ndemonstrate that SecurePose outperformed six existing methods in automated face\ndetection and achieved comparable accuracy to robust manual blurring, but in\nsignificantly less time (91.08% faster). Ten experienced researchers also\nconfirmed SecurePose's usability via System Usability Scale scores. These\nfindings validate SecurePose as a practical and effective tool for protecting\npatient privacy while enabling accurate kinematics extraction in clinical\nsettings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2402.14143v2", "cate": "cs.CV", "date": "2024-02-21", "updated": "2025-07-18", "AI": {"title_translation": "SecurePose：从临床环境中录制的视频中自动进行面部模糊处理和人体运动学提取", "tldr": "SecurePose是一个开源软件，它能同时可靠地去识别（模糊面部）并自动提取临床视频中的运动学数据，解决了隐私风险和手动处理的痛点，且比现有方法更快更准确。", "motivation": "运动障碍诊断通常依赖专家对患者视频的评估，但分享这些视频存在隐私风险。现有的视频去识别方法（如面部模糊）通常是手动的、不一致或不准确的。此外，这些方法可能会损害客观的运动学分析，而运动学分析是诊断的关键组成部分。", "method": "开发了SecurePose，一个开源软件，利用姿态估计（使用OpenPose）来提取全身运动学数据、跟踪个体、识别患者，并准确模糊视频中的面部。该软件在116名脑瘫儿童的步态视频上进行了验证，评估了其去识别的准确性（与手动模糊相比）和运动学提取中间步骤的可靠性。", "result": "SecurePose在自动面部检测方面优于六种现有方法，并且达到了与鲁棒手动模糊相当的准确性，但耗时显著减少（快91.08%）。十名经验丰富的研究人员通过系统可用性量表评分证实了SecurePose的可用性。", "conclusion": "SecurePose被验证为一种实用且有效的工具，可以在保护患者隐私的同时，在临床环境中实现准确的运动学提取。", "translation": "运动障碍诊断通常依赖专家对患者视频的评估，但分享这些视频会带来隐私风险。当前的视频去识别方法，例如面部模糊，通常是手动的、不一致或不准确的。此外，这些方法可能会损害客观的运动学分析——这是诊断的关键组成部分。为了解决这些挑战，我们开发了SecurePose，一个开源软件，它能同时可靠地去识别并自动从智能手机/平板电脑在临床环境中录制的视频中提取运动学数据。SecurePose利用姿态估计（使用OpenPose）来提取全身运动学数据，跟踪个体，识别患者，然后准确模糊视频中的面部。我们在116名脑瘫儿童门诊就诊期间录制的步态视频上验证了SecurePose，评估了其去识别的准确性（与地面实况即手动模糊相比）以及运动学提取中间步骤的可靠性。结果表明，SecurePose在自动面部检测方面优于六种现有方法，并且达到了与鲁棒手动模糊相当的准确性，但耗时显著减少（快91.08%）。十名经验丰富的研究人员也通过系统可用性量表评分证实了SecurePose的可用性。这些发现验证了SecurePose作为一种实用且有效的工具，可以在保护患者隐私的同时，在临床环境中实现准确的运动学提取。", "summary": "SecurePose是一个开源软件，旨在解决临床视频中患者隐私保护与运动学数据提取的矛盾。它通过结合姿态估计（OpenPose）实现面部自动模糊和全身运动学数据提取。该系统在脑瘫儿童步态视频上的验证结果显示，SecurePose在面部去识别方面优于现有方法，并能显著提高处理效率，同时保持与手动模糊相当的准确性，有效平衡了隐私保护与数据分析的需求。", "keywords": "面部模糊, 运动学提取, 隐私保护, 姿态估计, 临床视频", "comments": "SecurePose的创新之处在于其将患者视频的去识别（隐私保护）与运动学数据提取（诊断分析）功能整合在一个自动化、高效的开源工具中。这解决了临床实践中的一个重要痛点，即手动去识别的低效和不准确性，以及传统方法可能损害数据分析的问题。其在临床环境下的实用性和效率是其重要性所在，尤其是在智能手机/平板电脑普及的当下，为远程医疗和大规模数据分析提供了可能。该研究通过与现有方法的比较和用户可用性测试，充分验证了其有效性和实用性。"}}
{"id": "2507.14059", "title": "Design of a Modular Mobile Inspection and Maintenance Robot for an Orbital Servicing Hub", "authors": ["Tianyuan Wang", "Mark A Post", "Mathieu Deremetz"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      In proceedings of the Towards Autonomous Robotic Systems 2025 conference (TAROS 2025), York, UK 6 pages, one page of references, 6 figures", "url": "http://arxiv.org/abs/2507.14059v1", "summary": "The use of autonomous robots in space is an essential part of the \"New Space\"\ncommercial ecosystem of assembly and re-use of space hardware components in\nEarth orbit and beyond. The STARFAB project aims to create a ground\ndemonstration of an orbital automated warehouse as a hub for sustainable\ncommercial operations and servicing. A critical part of this fully-autonomous\nrobotic facility will be the capability to monitor, inspect, and assess the\ncondition of both the components stored in the warehouse, and the STARFAB\nfacility itself. This paper introduces ongoing work on the STARFAB Mobile\nInspection Module (MIM). The MIM uses Standard Interconnects (SI) so that it\ncan be carried by Walking Manipulators (WM) as an independently-mobile robot,\nand multiple MIMs can be stored and retrieved as needed for operations on\nSTARFAB. The MIM carries high-resolution cameras, a 3D profilometer, and a\nthermal imaging sensor, with the capability to add other modular sensors. A\ngrasping tool and torque wrench are stored within the modular body for use by\nan attached WM for maintenance operations. Implementation and testing is still\nongoing at the time of writing. This paper details the concept of operations\nfor the MIM as an on-orbit autonomous inspection and maintenance system, the\nmechanical and electronic design of the MIM, and the sensors package used for\nnon-destructive testing.", "comment": "In proceedings of the Towards Autonomous Robotic Systems 2025\n  conference (TAROS 2025), York, UK 6 pages, one page of references, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14059v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "轨道服务中心模块化移动检查与维护机器人的设计", "tldr": "本文介绍了一种模块化移动检查与维护机器人（MIM），用于轨道服务中心（STARFAB）的自主检查和维护任务。", "motivation": "为了支持“新空间”商业生态系统中空间硬件组件的组装和再利用，需要开发自主机器人。STARFAB项目旨在创建一个轨道自动化仓库作为可持续商业运营和服务中心，其中对仓库中组件和STARFAB设施本身的监控、检查和评估能力至关重要。", "method": "本文详细介绍了STARFAB移动检查模块（MIM）的持续工作。MIM采用标准互连（SI），可由步行机械手（WM）携带作为独立的移动机器人，并且可以根据STARFAB的操作需求存储和检索多个MIM。MIM配备了高分辨率摄像头、3D轮廓仪和热成像传感器，并可添加其他模块化传感器。其模块化本体内还存储有抓取工具和扭矩扳手，供连接的WM进行维护操作。论文详述了MIM作为在轨自主检查和维护系统的操作概念、MIM的机械和电子设计以及用于无损检测的传感器包。", "result": "本文介绍了STARFAB移动检查模块（MIM）的概念设计、操作概念、机械和电子设计，以及用于无损检测的传感器包。目前，该系统的实现和测试仍在进行中。", "conclusion": "本文提出了模块化移动检查模块（MIM）的设计，该模块是轨道服务中心实现自主检查和维护能力的关键组成部分，其模块化设计和集成的传感器及工具包为未来在轨操作奠定了基础。", "translation": "在太空中使用自主机器人是“新空间”商业生态系统的重要组成部分，该生态系统涉及在地球轨道及以外的空间硬件组件的组装和再利用。STARFAB项目旨在创建一个轨道自动化仓库的地面演示，作为可持续商业运营和服务的枢纽。这个全自主机器人设施的一个关键部分将是监测、检查和评估仓库中存储的组件以及STARFAB设施本身状况的能力。本文介绍了STARFAB移动检查模块（MIM）正在进行的工作。MIM使用标准互连（SI），因此可以由步行机械手（WM）携带作为独立的移动机器人，并且可以根据STARFAB的操作需求存储和检索多个MIM。MIM携带高分辨率摄像头、3D轮廓仪和热成像传感器，并能够添加其他模块化传感器。模块化本体内存储有抓取工具和扭矩扳手，供连接的WM进行维护操作。在撰写本文时，实施和测试仍在进行中。本文详细介绍了MIM作为在轨自主检查和维护系统的操作概念、MIM的机械和电子设计以及用于无损检测的传感器包。", "summary": "本文介绍了为轨道服务中心STARFAB设计的模块化移动检查模块（MIM），旨在提供自主的在轨检查和维护能力。MIM采用标准互连，可由步行机械手携带，并配备高分辨率摄像头、3D轮廓仪、热成像传感器及其他可扩展传感器，同时内置维护工具。论文详细阐述了MIM的操作概念、机械电子设计和传感器配置，以支持“新空间”商业生态系统中空间硬件的组装与再利用。", "keywords": "轨道服务, 移动机器人, 检查, 维护, 模块化设计", "comments": "该论文提出的模块化移动检查模块（MIM）设计具有创新性，特别是在其模块化互连和多功能传感器及工具集成方面。这种设计理念对于未来空间服务的灵活性和可扩展性至关重要。将检查和维护功能集成到单个移动平台中，对于实现全自主轨道设施具有重要意义，符合“新空间”商业化趋势。其局限性在于，截至论文撰写时，仍处于实施和测试阶段，尚未提供实际的性能数据。"}}
{"id": "2507.13762", "title": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "authors": ["Yaowei Jin", "Junjie Wang", "Wenkai Xiang", "Duanhua Cao", "Dan Teng", "Zhehuan Fan", "Jiacheng Xiong", "Xia Sheng", "Chuanlong Zeng", "Mingyue Zheng", "Qian Shi"], "categories": ["cs.LG", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13762v1", "summary": "Advances in deep learning for molecular generation show promise in\naccelerating drug discovery. Bayesian Flow Networks (BFNs) have recently shown\nimpressive performance across diverse chemical tasks, with their success often\nascribed to the paradigm of modeling in a low-variance parameter space.\nHowever, the Bayesian inference-based strategy imposes limitations on designing\nmore flexible distribution transformation pathways, making it challenging to\nadapt to diverse data distributions and varied task requirements. Furthermore,\nthe potential for simpler, more efficient parameter-space-based models is\nunexplored. To address this, we propose a novel Parameter Interpolation Flow\nmodel (named PIF) with detailed theoretical foundation, training, and inference\nprocedures. We then develop MolPIF for structure-based drug design,\ndemonstrating its superior performance across diverse metrics compared to\nbaselines. This work validates the effectiveness of parameter-space-based\ngenerative modeling paradigm for molecules and offers new perspectives for\nmodel design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13762v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MolPIF：一种用于分子生成的参数插值流模型", "tldr": "MolPIF提出了一种新的参数插值流模型，旨在克服现有贝叶斯流网络在分子生成中的局限性，并在结构化药物设计中表现出优越性能。", "motivation": "现有的贝叶斯流网络（BFNs）在设计更灵活的分布转换路径方面存在局限性，难以适应多样化的数据分布和任务需求。此外，更简单、更高效的基于参数空间的模型潜力尚未被探索。", "method": "本文提出了一种新颖的参数插值流模型（PIF），并提供了详细的理论基础、训练和推理过程。在此基础上，开发了MolPIF模型用于基于结构的药物设计。", "result": "MolPIF模型在多种指标上与基线模型相比，展示出优越的性能。", "conclusion": "这项工作验证了基于参数空间的分子生成建模范式的有效性，并为模型设计提供了新的视角。", "translation": "深度学习在分子生成领域的进展显示出加速药物发现的潜力。贝叶斯流网络（BFNs）最近在各种化学任务中表现出色，其成功常归因于在低方差参数空间中建模的范式。然而，基于贝叶斯推理的策略在设计更灵活的分布转换路径方面存在局限性，使其难以适应多样化的数据分布和不同的任务需求。此外，更简单、更高效的基于参数空间的模型潜力尚未被探索。为此，我们提出了一种新颖的参数插值流模型（命名为PIF），并提供了详细的理论基础、训练和推理过程。随后，我们开发了用于基于结构的药物设计的MolPIF，证明其在各种指标上均优于基线模型。这项工作验证了基于参数空间的分子生成建模范式的有效性，并为模型设计提供了新的视角。", "summary": "本文提出了一种名为MolPIF的新型参数插值流模型，旨在克服现有贝叶斯流网络在分子生成中灵活性不足的局限性。MolPIF基于详细的理论基础，并专为结构化药物设计开发。实验结果表明，MolPIF在多项指标上均优于现有基线模型，验证了参数空间生成建模的有效性，并为未来的模型设计提供了新思路。", "keywords": "分子生成, 参数插值流, 药物发现, 贝叶斯流网络, 深度学习", "comments": "MolPIF的创新之处在于提出了参数插值流模型，克服了贝叶斯流网络在灵活性上的不足，为分子生成提供了新的视角。其重要性体现在为药物发现加速提供了更高效、更灵活的工具。"}}
{"id": "2507.13993", "title": "OrthoInsight: Rib Fracture Diagnosis and Report Generation Based on Multi-Modal Large Models", "authors": ["Ningyong Wu", "Jinzhi Wang", "Wenhong Zhao", "Chenzhan Yu", "Zhigang Xiu", "Duwei Dai"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13993v1", "summary": "The growing volume of medical imaging data has increased the need for\nautomated diagnostic tools, especially for musculoskeletal injuries like rib\nfractures, commonly detected via CT scans. Manual interpretation is\ntime-consuming and error-prone. We propose OrthoInsight, a multi-modal deep\nlearning framework for rib fracture diagnosis and report generation. It\nintegrates a YOLOv9 model for fracture detection, a medical knowledge graph for\nretrieving clinical context, and a fine-tuned LLaVA language model for\ngenerating diagnostic reports. OrthoInsight combines visual features from CT\nimages with expert textual data to deliver clinically useful outputs. Evaluated\non 28,675 annotated CT images and expert reports, it achieves high performance\nacross Diagnostic Accuracy, Content Completeness, Logical Coherence, and\nClinical Guidance Value, with an average score of 4.28, outperforming models\nlike GPT-4 and Claude-3. This study demonstrates the potential of multi-modal\nlearning in transforming medical image analysis and providing effective support\nfor radiologists.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13993v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "OrthoInsight: 基于多模态大模型的肋骨骨折诊断与报告生成", "tldr": "OrthoInsight是一个多模态深度学习框架，通过整合YOLOv9、医学知识图谱和LLaVA模型，实现肋骨骨折的自动化诊断和报告生成，并在大规模数据集上表现优异。", "motivation": "医疗影像数据量持续增长，使得对自动化诊断工具的需求日益增加，尤其对于肋骨骨折等肌肉骨骼损伤。手动判读耗时且容易出错。", "method": "本文提出了OrthoInsight，一个用于肋骨骨折诊断和报告生成的多模态深度学习框架。它整合了YOLOv9模型进行骨折检测，一个医学知识图谱用于检索临床背景，以及一个微调的LLaVA语言模型用于生成诊断报告。OrthoInsight结合了CT图像的视觉特征和专家文本数据，以提供具有临床价值的输出。", "result": "该系统在28,675张带注释的CT图像和专家报告上进行了评估，在诊断准确性、内容完整性、逻辑连贯性和临床指导价值方面均表现出高水平性能，平均得分4.28，优于GPT-4和Claude-3等模型。", "conclusion": "本研究证明了多模态学习在转化医学图像分析和为放射科医生提供有效支持方面的潜力。", "translation": "医疗影像数据量的增长增加了对自动化诊断工具的需求，特别是对于肋骨骨折等常见于CT扫描的肌肉骨骼损伤。手动判读耗时且容易出错。我们提出了OrthoInsight，一个用于肋骨骨折诊断和报告生成的多模态深度学习框架。它整合了YOLOv9模型进行骨折检测，一个医学知识图谱用于检索临床背景，以及一个微调的LLaVA语言模型用于生成诊断报告。OrthoInsight结合了CT图像的视觉特征和专家文本数据，以提供具有临床实用价值的输出。在28,675张带注释的CT图像和专家报告上进行评估，它在诊断准确性、内容完整性、逻辑连贯性和临床指导价值方面均取得了高水平性能，平均得分4.28，优于GPT-4和Claude-3等模型。这项研究证明了多模态学习在转化医学图像分析和为放射科医生提供有效支持方面的潜力。", "summary": "针对医疗影像数据量增长导致手动诊断肋骨骨折耗时且易错的问题，本文提出了OrthoInsight多模态深度学习框架。该框架整合YOLOv9进行骨折检测、医学知识图谱提供临床背景、以及微调的LLaVA模型生成诊断报告。在近三万张CT图像上评估，OrthoInsight在多项指标上表现出色，并优于现有大型模型，展示了多模态学习在医学图像分析中的巨大潜力。", "keywords": "肋骨骨折, 多模态, 深度学习, 诊断, 报告生成", "comments": "该论文的创新点在于构建了一个结合视觉（YOLOv9）、知识（医学知识图谱）和语言（LLaVA）的多模态集成框架，专门用于肋骨骨折的诊断和报告生成。其重要性在于实现了自动化且高性能的医疗影像分析，显著优于通用大型模型，为放射科医生提供了高效且准确的辅助工具。这种集成不同模态信息的方法为未来医疗AI应用提供了新的范式。"}}
{"id": "2507.13858", "title": "InTraVisTo: Inside Transformer Visualisation Tool", "authors": ["Nicolò Brunello", "Davide Rigamonti", "Andrea Sassella", "Vincenzo Scotti", "Mark James Carman"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2507.13858v1", "summary": "The reasoning capabilities of Large Language Models (LLMs) have increased\ngreatly over the last few years, as have their size and complexity.\nNonetheless, the use of LLMs in production remains challenging due to their\nunpredictable nature and discrepancies that can exist between their desired\nbehavior and their actual model output. In this paper, we introduce a new tool,\nInTraVisTo (Inside Transformer Visualisation Tool), designed to enable\nresearchers to investigate and trace the computational process that generates\neach token in a Transformer-based LLM. InTraVisTo provides a visualization of\nboth the internal state of the Transformer model (by decoding token embeddings\nat each layer of the model) and the information flow between the various\ncomponents across the different layers of the model (using a Sankey diagram).\nWith InTraVisTo, we aim to help researchers and practitioners better understand\nthe computations being performed within the Transformer model and thus to shed\nsome light on internal patterns and reasoning processes employed by LLMs.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2507.13858v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "InTraVisTo: 内部Transformer可视化工具", "tldr": "本文介绍了一个名为 InTraVisTo 的新工具，旨在帮助研究人员调查和追踪基于 Transformer 的大型语言模型中每个 token 的计算过程，以更好地理解其内部工作原理。", "motivation": "大型语言模型 (LLMs) 的推理能力显著提高，但由于其不可预测性以及期望行为与实际输出之间的差异，在生产中使用 LLMs 仍然具有挑战性。为了帮助研究人员更好地理解 LLMs 的内部计算和推理过程，本文提出了 InTraVisTo。", "method": "InTraVisTo 工具旨在使研究人员能够调查和追踪基于 Transformer 的 LLM 中生成每个 token 的计算过程。它通过可视化 Transformer 模型的内部状态（通过解码模型每一层的 token 嵌入）和模型不同层之间各种组件的信息流（使用桑基图）来实现。", "result": "Not mentioned in abstract", "conclusion": "InTraVisTo 旨在帮助研究人员和从业者更好地理解 Transformer 模型内部执行的计算，从而揭示 LLMs 采用的内部模式和推理过程。", "translation": "过去几年，大型语言模型 (LLMs) 的推理能力大幅提升，其规模和复杂性也随之增加。然而，由于LLMs的不可预测性以及它们的期望行为与实际模型输出之间可能存在的差异，在生产中使用LLMs仍然充满挑战。在本文中，我们介绍了一个新工具——InTraVisTo (内部Transformer可视化工具)，旨在使研究人员能够调查和追踪基于Transformer的LLM中生成每个token的计算过程。InTraVisTo提供了Transformer模型内部状态（通过解码模型每一层的token嵌入）以及模型不同层之间各种组件信息流（使用桑基图）的可视化。通过InTraVisTo，我们旨在帮助研究人员和从业者更好地理解Transformer模型内部执行的计算，从而揭示LLMs采用的内部模式和推理过程。", "summary": "本文介绍了 InTraVisTo，一个用于可视化 Transformer 内部工作的新工具。面对大型语言模型 (LLMs) 的不可预测性，InTraVisTo 旨在帮助研究人员理解 LLM 中每个 token 的计算过程。该工具通过解码各层 token 嵌入来展示模型内部状态，并使用桑基图可视化不同组件间的信息流，从而揭示 LLM 的内部模式和推理过程。", "keywords": "大型语言模型, Transformer, 可视化, 可解释性, InTraVisTo", "comments": "InTraVisTo 解决了理解大型语言模型内部“黑箱”操作的关键挑战，这对于提高 LLM 的可解释性、可信赖性和生产部署至关重要。其创新点在于结合了内部状态解码和信息流可视化（桑基图），为研究人员提供了深入洞察 Transformer 计算过程的独特视角。该工具对于 LLM 的调试、行为分析和未来架构改进具有重要意义。"}}
{"id": "2507.14077", "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "categories": ["cs.AI", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 3 figures, 6 tables", "url": "http://arxiv.org/abs/2507.14077v1", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "comment": "19 pages, 3 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.14077v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Glucose-ML：一个用于开发稳健AI解决方案的纵向糖尿病数据集集合", "tldr": "该论文推出了Glucose-ML，一个包含10个公开可用的纵向糖尿病数据集的大型集合，旨在促进糖尿病管理中稳健AI解决方案的开发，并提供了比较分析和血糖预测基准。", "motivation": "获取高质量的大型数据集是开发稳健的糖尿病管理AI解决方案的障碍。", "method": "作者介绍了Glucose-ML，一个包含10个公开可用的纵向糖尿病数据集的集合（包含超过30万天的CGM数据，来自4个国家2500多人的3800万个血糖样本）。他们进行了比较分析以指导数据选择，并针对血糖预测任务进行了一项案例研究，以在不同数据集上建立性能基准。", "result": "Glucose-ML 包含超过30万天的连续血糖监测（CGM）数据和3800万个血糖样本，来自2500多名参与者。案例研究表明，相同的算法在不同数据集上开发/评估时，可能会产生显著不同的预测结果。", "conclusion": "本研究为糖尿病和更广泛健康领域开发稳健AI解决方案提供了建议，强调了多样化和高质量数据集的重要性。", "translation": "人工智能 (AI) 算法是糖尿病管理领域最先进数字健康技术的关键组成部分。然而，获取高质量大型数据集的障碍阻碍了稳健AI解决方案的开发。为了加速透明、可复现和稳健AI解决方案的开发，我们推出了 Glucose-ML，这是一个包含10个公开可用的糖尿病数据集的集合，这些数据集在过去7年内发布（即2018年至2025年）。Glucose-ML 集合包含超过30万天的连续血糖监测 (CGM) 数据，总计3800万个血糖样本，这些样本来自4个国家的2500多名参与者。参与者包括患有1型糖尿病、2型糖尿病、糖尿病前期以及无糖尿病的人群。为了支持研究人员和创新者使用这一丰富的糖尿病数据集集合，我们提供了一项比较分析，以指导算法开发者进行数据选择。此外，我们针对血糖预测任务（该领域最常见的AI任务之一）进行了一项案例研究。通过这项案例研究，我们为 Glucose-ML 集合中所有10个公开可用的糖尿病数据集的短期血糖预测提供了基准。我们发现，相同的算法在不同数据集上开发/评估时，可能会产生显著不同的预测结果。本研究的发现随后被用于为糖尿病或更广泛健康领域开发稳健AI解决方案提供建议。我们提供了 Glucose-ML 集合中每个纵向糖尿病数据集的直接链接，并公开了我们的代码。", "summary": "该论文介绍了Glucose-ML，一个包含10个公开可用的纵向糖尿病数据集的综合集合，旨在克服数据获取障碍，以开发稳健的糖尿病管理AI解决方案。该集合包含来自不同患者群体的超过30万天的CGM数据。作者进行了一项比较分析以指导数据选择，并针对血糖预测进行了一项案例研究，结果表明算法性能在不同数据集之间存在显著差异。这些发现为构建稳健的健康领域AI解决方案提供了建议。", "keywords": "糖尿病, 纵向数据集, 人工智能, 血糖预测, 连续血糖监测", "comments": "该论文通过整合和整理大量多样化的公开糖尿病数据集（Glucose-ML）做出了重要贡献。这解决了数字健康领域AI开发中的关键瓶颈。比较分析和基准测试案例研究对于指导研究人员和强调数据集选择对于稳健模型性能的重要性非常有价值，而这往往是一个被忽视的关键方面。数据链接和代码的开放访问进一步增强了其实用性和可复现性。"}}
{"id": "2507.13530", "title": "Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising", "authors": ["Lukas Baumgärtner", "Ronny Bergmann", "Roland Herzog", "Stephan Schmidt", "Manuel Weiß"], "categories": ["cs.CV", "math.DG", "math.OC"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13530v1", "summary": "We propose a novel formulation for the second-order total generalized\nvariation (TGV) of the normal vector on an oriented, triangular mesh embedded\nin $\\mathbb{R}^3$. The normal vector is considered as a manifold-valued\nfunction, taking values on the unit sphere. Our formulation extends previous\ndiscrete TGV models for piecewise constant scalar data that utilize a\nRaviart-Thomas function space. To exctend this formulation to the manifold\nsetting, a tailor-made tangential Raviart-Thomas type finite element space is\nconstructed in this work. The new regularizer is compared to existing methods\nin mesh denoising experiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13530v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "法向量场的全广义变分及其在网格去噪中的应用", "tldr": "本文提出了一种在三维网格上去噪的法向量场二阶全广义变分（TGV）新公式，并为此构建了定制的切向Raviart-Thomas型有限元空间。", "motivation": "扩展先前利用Raviart-Thomas函数空间的分段常数标量数据的离散TGV模型，并为网格去噪提供一种新的正则化器。", "method": "提出了一种在嵌入在$\\mathbb{R}^3$中的定向三角网格上，针对法向量的二阶全广义变分（TGV）的新颖公式。将法向量视为单位球面上的流形值函数。为了将此公式扩展到流形设置，本工作构建了一个定制的切向Raviart-Thomas型有限元空间。", "result": "新的正则化器在网格去噪实验中与现有方法进行了比较。", "conclusion": "Not mentioned in abstract", "translation": "我们提出了一种在嵌入在$\\mathbb{R}^3$中的定向三角网格上，针对法向量的二阶全广义变分（TGV）的新颖公式。法向量被视为一个流形值函数，其值在单位球面上。我们的公式扩展了先前利用Raviart-Thomas函数空间的分段常数标量数据的离散TGV模型。为了将此公式扩展到流形设置，本工作构建了一个定制的切向Raviart-Thomas型有限元空间。新的正则化器在网格去噪实验中与现有方法进行了比较。", "summary": "本文提出了一种针对嵌入在$\\mathbb{R}^3$中的定向三角网格上法向量的二阶全广义变分（TGV）新公式。该方法将法向量视为单位球面上的流形值函数，并通过构建定制的切向Raviart-Thomas型有限元空间，扩展了现有离散TGV模型。所提出的新正则化器在网格去噪实验中与现有方法进行了比较。", "keywords": "全广义变分, 法向量场, 网格去噪, 有限元空间, 流形值函数", "comments": "本文的创新点在于提出了针对流形值法向量的TGV新公式，并为此构建了专门的切向Raviart-Thomas型有限元空间，这对于处理网格数据中的曲面特性具有重要意义。该方法有望在网格去噪等应用中提供更优的正则化效果。"}}
{"id": "2507.13580", "title": "A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design", "authors": ["Hao Tuo", "Yan Li", "Xuanning Hu", "Haishi Zhao", "Xueyan Liu", "Bo Yang"], "categories": ["q-bio.BM", "cs.LG"], "primary_category": "Subjects:       Biomolecules (q-bio.BM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13580v1", "summary": "Combinatorial optimization algorithm is essential in computer-aided drug\ndesign by progressively exploring chemical space to design lead compounds with\nhigh affinity to target protein. However current methods face inherent\nchallenges in integrating domain knowledge, limiting their performance in\nidentifying lead compounds with novel and valid binding mode. Here, we propose\nAutoLeadDesign, a lead compounds design framework that inspires extensive\ndomain knowledge encoded in large language models with chemical fragments to\nprogressively implement efficient exploration of vast chemical space. The\ncomprehensive experiments indicate that AutoLeadDesign outperforms baseline\nmethods. Significantly, empirical lead design campaigns targeting two\nclinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate\nAutoLeadDesign's competence in de novo generation of lead compounds achieving\nexpert-competitive design efficacy. Structural analysis further confirms their\nmechanism-validated inhibitory patterns. By tracing the process of design, we\nfind that AutoLeadDesign shares analogous mechanisms with fragment-based drug\ndesign which traditionally rely on the expert decision-making, further\nrevealing why it works. Overall, AutoLeadDesign offers an efficient approach\nfor lead compounds design, suggesting its potential utility in drug design.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13580v1", "cate": "q-bio.BM", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "整合大型语言模型和化学片段空间的协同框架：先导化合物设计的相互启发", "tldr": "AutoLeadDesign是一个结合大型语言模型和化学片段空间的新框架，用于高效的先导化合物设计，其性能优于基线方法，并在两个临床靶点上实现了专家级的从头生成效率，揭示了其与基于片段的药物设计相似的机制。", "motivation": "当前计算机辅助药物设计中的组合优化方法在整合领域知识方面存在固有的挑战，这限制了它们在识别具有新颖且有效结合模式的先导化合物方面的性能。", "method": "本文提出了AutoLeadDesign，一个先导化合物设计框架。该框架将大型语言模型中编码的广泛领域知识与化学片段相结合，以逐步实现对广阔化学空间的有效探索。", "result": "综合实验表明，AutoLeadDesign优于基线方法。针对两个临床相关靶点（PRMT5和SARS-CoV-2 PLpro）的经验性先导化合物设计活动表明，AutoLeadDesign在从头生成先导化合物方面具有专家级的竞争力。结构分析证实了其机制验证的抑制模式。研究发现AutoLeadDesign与传统上依赖专家决策的基于片段的药物设计共享相似机制。", "conclusion": "AutoLeadDesign为先导化合物设计提供了一种高效方法，预示着其在药物设计中的潜在效用。", "translation": "组合优化算法在计算机辅助药物设计中至关重要，通过逐步探索化学空间来设计对靶蛋白具有高亲和力的先导化合物。然而，当前方法在整合领域知识方面面临固有的挑战，限制了它们在识别具有新颖且有效结合模式的先导化合物方面的性能。在此，我们提出了AutoLeadDesign，一个先导化合物设计框架，它将大型语言模型中编码的广泛领域知识与化学片段相结合，以逐步实现对广阔化学空间的有效探索。综合实验表明，AutoLeadDesign优于基线方法。值得注意的是，针对两个临床相关靶点（PRMT5和SARS-CoV-2 PLpro）的经验性先导化合物设计活动表明，AutoLeadDesign在从头生成先导化合物方面具有竞争力，达到了专家级别的设计效率。结构分析进一步证实了其机制验证的抑制模式。通过追溯设计过程，我们发现AutoLeadDesign与传统上依赖专家决策的基于片段的药物设计共享相似的机制，这进一步揭示了其工作原理。总的来说，AutoLeadDesign为先导化合物设计提供了一种高效方法，预示着其在药物设计中的潜在效用。", "summary": "本文提出了AutoLeadDesign，一个创新的计算框架，它将大型语言模型中编码的领域知识与化学片段空间探索相结合，以实现高效的先导化合物设计。该框架旨在解决现有方法在整合领域知识方面的局限性。实验结果表明，AutoLeadDesign的性能优于基线方法，并在针对关键药物靶点的从头先导化合物生成方面达到了专家级的效率，为药物发现提供了一种有前景的新方法。", "keywords": "大型语言模型, 化学片段空间, 先导化合物设计, 药物设计, 组合优化", "comments": "这项工作的创新之处在于将大型语言模型（LLMs）与化学片段空间相结合，用于药物设计中的先导化合物发现，这解决了计算机辅助药物设计中整合领域知识的常见挑战。其在从头生成方面达到专家级设计效率的能力，以及与传统基于片段药物设计的机制相似性，都具有重要意义。它为高效的先导化合物发现提供了一种新的范式。"}}
{"id": "2505.04421", "title": "LONGER: Scaling Up Long Sequence Modeling in Industrial Recommenders", "authors": ["Zheng Chai", "Qin Ren", "Xijun Xiao", "Huizhi Yang", "Bo Han", "Sijun Zhang", "Di Chen", "Hui Lu", "Wenlin Zhao", "Lele Yu", "Xionghang Xie", "Shiru Ren", "Xiang Sun", "Yaocheng Tan", "Peng Xu", "Yuchao Zheng", "Di Wu"], "categories": ["cs.IR"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.04421v2", "summary": "Modeling ultra-long user behavior sequences is critical for capturing both\nlong- and short-term preferences in industrial recommender systems. Existing\nsolutions typically rely on two-stage retrieval or indirect modeling paradigms,\nincuring upstream-downstream inconsistency and computational inefficiency. In\nthis paper, we present LONGER, a Long-sequence Optimized traNsformer for\nGPU-Efficient Recommenders. LONGER incorporates (i) a global token mechanism\nfor stabilizing attention over long contexts, (ii) a token merge module with\nlightweight InnerTransformers and hybrid attention strategy to reduce quadratic\ncomplexity, and (iii) a series of engineering optimizations, including training\nwith mixed-precision and activation recomputation, KV cache serving, and the\nfully synchronous model training and serving framework for unified GPU-based\ndense and sparse parameter updates. LONGER consistently outperforms strong\nbaselines in both offline metrics and online A/B testing in both advertising\nand e-commerce services at ByteDance, validating its consistent effectiveness\nand industrial-level scaling laws. Currently, LONGER has been fully deployed at\nmore than 10 influential scenarios at ByteDance, serving billion users.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.04421v2", "cate": "cs.IR", "date": "2025-05-07", "updated": "2025-07-18", "AI": {"title_translation": "LONGER：工业推荐系统中长序列建模的扩展", "tldr": "LONGER是一个针对工业推荐系统的长序列Transformer模型，通过引入全局token、token合并模块和工程优化，解决了现有长序列建模的效率和一致性问题，并在字节跳动实现了显著的线上线下效果提升。", "motivation": "现有工业推荐系统中，建模超长用户行为序列对于捕获长期和短期偏好至关重要，但现有解决方案（两阶段检索或间接建模）存在上下游不一致和计算效率低下问题。", "method": "提出了LONGER，一个用于GPU高效推荐的长序列优化Transformer。它包含：(i) 全局token机制，用于稳定长上下文中的注意力；(ii) 带有轻量级InnerTransformers和混合注意力策略的token合并模块，以降低二次复杂度；(iii) 一系列工程优化，包括混合精度训练、激活重计算、KV缓存服务以及用于统一GPU密集和稀疏参数更新的全同步模型训练和服务框架。", "result": "LONGER在字节跳动的广告和电商服务中，离线指标和在线A/B测试中都持续优于强基线，验证了其持续有效性和工业级扩展能力。", "conclusion": "LONGER已在字节跳动超过10个重要场景全面部署，服务亿级用户，证明其在工业推荐系统中长序列建模的有效性和实用性。", "translation": "建模超长用户行为序列对于在工业推荐系统中捕获长期和短期偏好至关重要。现有解决方案通常依赖于两阶段检索或间接建模范式，导致上下游不一致和计算效率低下。在本文中，我们提出了LONGER，一个用于GPU高效推荐的长序列优化Transformer。LONGER包含 (i) 一种全局token机制，用于稳定长上下文中的注意力，(ii) 一个带有轻量级InnerTransformers和混合注意力策略的token合并模块，以降低二次复杂度，以及 (iii) 一系列工程优化，包括混合精度训练和激活重计算、KV缓存服务以及用于统一GPU密集和稀疏参数更新的全同步模型训练和服务框架。LONGER在字节跳动的广告和和电商服务中，离线指标和在线A/B测试中都持续优于强基线，验证了其持续有效性和工业级扩展能力。目前，LONGER已在字节跳动超过10个有影响力的场景全面部署，服务亿级用户。", "summary": "本文提出了LONGER，一个专为工业推荐系统设计的长序列优化Transformer模型，旨在解决现有方法在处理超长用户行为序列时存在的效率低下和一致性问题。LONGER通过引入全局token机制、token合并模块（结合轻量级InnerTransformers和混合注意力）以及一系列工程优化（如混合精度训练、KV缓存），显著降低了计算复杂度并提升了性能。实验结果表明，LONGER在字节跳动的广告和电商业务中，离线指标和在线A/B测试均优于现有基线，并已成功部署服务亿级用户，验证了其在工业级应用中的有效性和可扩展性。", "keywords": "长序列建模, 推荐系统, Transformer, GPU优化, 字节跳动", "comments": "LONGER的创新之处在于其结合了模型结构优化（全局token、token合并）和工程优化，以应对工业级长序列推荐系统的挑战。特别是在减少二次复杂度方面的token合并模块和针对GPU优化的工程实践，使其在实际部署中具有很强的实用性。其在字节跳动大规模部署并服务亿级用户的成功案例，证明了该方案的工业价值和成熟度。"}}
{"id": "2507.13542", "title": "Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk Stratification Using Echocardiography", "authors": ["Beka Begiashvili", "Carlos J. Fernandez-Candel", "Matías Pérez Paredes"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13542v1", "summary": "Traditional echocardiographic parameters such as ejection fraction (EF) and\nglobal longitudinal strain (GLS) have limitations in the early detection of\ncardiac dysfunction. EF often remains normal despite underlying pathology, and\nGLS is influenced by load conditions and vendor variability. There is a growing\nneed for reproducible, interpretable, and operator-independent parameters that\ncapture subtle and global cardiac functional alterations.\n  We introduce the Acoustic Index, a novel AI-derived echocardiographic\nparameter designed to quantify cardiac dysfunction from standard ultrasound\nviews. The model combines Extended Dynamic Mode Decomposition (EDMD) based on\nKoopman operator theory with a hybrid neural network that incorporates clinical\nmetadata. Spatiotemporal dynamics are extracted from echocardiographic\nsequences to identify coherent motion patterns. These are weighted via\nattention mechanisms and fused with clinical data using manifold learning,\nresulting in a continuous score from 0 (low risk) to 1 (high risk).\n  In a prospective cohort of 736 patients, encompassing various cardiac\npathologies and normal controls, the Acoustic Index achieved an area under the\ncurve (AUC) of 0.89 in an independent test set. Cross-validation across five\nfolds confirmed the robustness of the model, showing that both sensitivity and\nspecificity exceeded 0.8 when evaluated on independent data. Threshold-based\nanalysis demonstrated stable trade-offs between sensitivity and specificity,\nwith optimal discrimination near this threshold.\n  The Acoustic Index represents a physics-informed, interpretable AI biomarker\nfor cardiac function. It shows promise as a scalable, vendor-independent tool\nfor early detection, triage, and longitudinal monitoring. Future directions\ninclude external validation, longitudinal studies, and adaptation to\ndisease-specific classifiers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13542v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "声学指数：一种基于人工智能的新型超声心动图心脏病风险分层参数", "tldr": "本文提出了一种名为“声学指数”的新型AI驱动超声心动图参数，旨在克服传统参数的局限性，实现心脏疾病风险的早期检测和分层，并在独立测试集中表现出高准确性和鲁棒性。", "motivation": "传统的超声心动图参数如射血分数（EF）和整体纵向应变（GLS）在心脏功能障碍的早期检测方面存在局限性，例如EF在潜在病理情况下可能保持正常，而GLS受负荷条件和设备差异影响。因此，迫切需要可复现、可解释且操作员独立的参数来捕捉细微和整体的心脏功能改变。", "method": "研究引入了声学指数，这是一种新型AI衍生的超声心动图参数，用于量化标准超声图像中的心脏功能障碍。该模型结合了基于Koopman算子理论的扩展动态模态分解（EDMD）与一个融合临床元数据的混合神经网络。模型从超声心动图序列中提取时空动态，通过注意力机制加权，并使用流形学习与临床数据融合，生成一个从0（低风险）到1（高风险）的连续分数。", "result": "在一个包含736名患者的前瞻性队列中，声学指数在独立测试集中的曲线下面积（AUC）达到了0.89。通过五折交叉验证证实了模型的鲁棒性，在独立数据上评估时，灵敏度和特异性均超过0.8。基于阈值的分析表明，在阈值附近具有稳定的灵敏度和特异性权衡，实现了最佳判别。", "conclusion": "声学指数代表了一种物理信息驱动、可解释的AI心脏功能生物标志物。它有望成为一种可扩展、与设备无关的工具，用于早期检测、分诊和长期监测心脏疾病。未来的研究方向包括外部验证、纵向研究以及适应疾病特异性分类器。", "translation": "传统超声心动图参数如射血分数（EF）和整体纵向应变（GLS）在心脏功能障碍的早期检测方面存在局限性。尽管存在潜在病理，EF通常保持正常，而GLS受负荷条件和设备差异影响。人们日益需要可复现、可解释且操作员独立的参数来捕捉细微和整体的心脏功能改变。\n我们引入了声学指数，这是一种新型AI衍生的超声心动图参数，旨在从标准超声图像中量化心脏功能障碍。该模型结合了基于Koopman算子理论的扩展动态模态分解（EDMD）与一个融合临床元数据的混合神经网络。从超声心动图序列中提取时空动态以识别相干运动模式。这些模式通过注意力机制加权，并使用流形学习与临床数据融合，从而生成一个从0（低风险）到1（高风险）的连续分数。\n在一个包含各种心脏病理和正常对照的736名患者的前瞻性队列中，声学指数在独立测试集中的曲线下面积（AUC）达到了0.89。五折交叉验证证实了模型的鲁棒性，显示在独立数据上评估时，灵敏度和特异性均超过0.8。基于阈值的分析表明，灵敏度和特异性之间存在稳定的权衡，在接近此阈值时具有最佳判别力。\n声学指数代表了一种物理信息驱动、可解释的AI心脏功能生物标志物。它有望成为一种可扩展、与设备无关的工具，用于早期检测、分诊和长期监测。未来的方向包括外部验证、纵向研究以及适应疾病特异性分类器。", "summary": "本文提出了一种名为“声学指数”的新型AI驱动超声心动图参数，旨在克服传统参数在早期心脏功能障碍检测中的局限性。该方法结合了基于Koopman算子理论的扩展动态模态分解和混合神经网络，通过整合超声时空动态与临床数据来量化心脏功能。在736名患者的队列中，声学指数表现出优异的性能（AUC 0.89），且具有高灵敏度和特异性。这表明声学指数作为一种可解释、可扩展且与设备无关的AI生物标志物，在心脏疾病的早期检测、分诊和长期监测方面具有巨大潜力。", "keywords": "声学指数, 超声心动图, 人工智能, 心脏病, 风险分层", "comments": "该研究的创新之处在于将物理信息驱动的扩展动态模态分解（EDMD）与深度学习（混合神经网络）和临床元数据相结合，创建了一个新颖且可解释的AI生物标志物。声学指数克服了传统超声心动图参数的局限性，提供了更精确和鲁棒的心脏功能评估。其与设备无关的特性以及在早期检测和监测方面的潜力，使其在临床应用中具有重要意义。"}}
{"id": "2506.12193", "title": "Linear List Decodable Edit-Correcting Codes with Rate Approaching $1$", "authors": ["Yuting Li", "Ryan Gabrys", "Farzad Farnoud"], "categories": ["cs.IT", "math.IT", "G.2.1"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      12 pages, 0 figure", "url": "http://arxiv.org/abs/2506.12193v2", "summary": "Linear codes correcting one deletions have rate at most $1/2$. In this paper,\nwe construct linear list decodable codes correcting edits with rate approaching\n$1$ and reasonable list size. Our encoder and decoder run in polynomial time.", "comment": "12 pages, 0 figure", "pdf_url": "http://arxiv.org/pdf/2506.12193v2", "cate": "cs.IT", "date": "2025-06-13", "updated": "2025-07-18", "AI": {"title_translation": "线性列表可解码编辑纠错码，码率接近1", "tldr": "构建了码率接近1的线性列表可解码编辑纠错码，解决了传统线性码码率上限问题。", "motivation": "现有的纠正一次删除的线性码的码率最高为1/2，这表明存在一个效率上的限制。本文旨在突破这一限制，构建码率更高的纠错码。", "method": "作者构建了新的线性列表可解码代码，这些代码能够纠正编辑错误。", "result": "所构建的代码的码率可以接近1，并且具有合理的列表大小。编码器和解码器都可以在多项式时间内运行。", "conclusion": "成功构建了码率接近1且高效的线性列表可解码编辑纠错码，显著提升了纠错码的效率。", "translation": "纠正一次删除的线性码的码率至多为1/2。在本文中，我们构建了码率接近1且具有合理列表大小的线性列表可解码编辑纠错码。我们的编码器和解码器在多项式时间内运行。", "summary": "本文针对纠删线性码码率上限为1/2的问题，提出并构建了一种新型的线性列表可解码编辑纠错码。该码的码率能接近1，并保持合理的列表大小，且其编码器和解码器均可在多项式时间内高效运行，显著提升了纠错码的效率和实用性。", "keywords": "线性码, 列表解码, 编辑纠错码, 码率, 多项式时间", "comments": "这项工作的创新之处在于突破了传统线性码在纠正删除错误时码率至多为1/2的限制，通过引入列表解码的概念，实现了码率接近1的线性纠错码。这意味着在传输或存储数据时，可以以更高的效率（更少的冗余）实现错误纠正，具有重要的理论和实际意义。同时，多项式时间的编解码器保证了其可行性。"}}
{"id": "2507.13861", "title": "PositionIC: Unified Position and Identity Consistency for Image Customization", "authors": ["Junjie Hu", "Tianyang Han", "Kai Ma", "Jialin Gao", "Hao Dou", "Song Yang", "Xianhua He", "Jianhui Zhang", "Junfeng Luo", "Xiaoming Wei", "Wenqiang Zhang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13861v1", "summary": "Recent subject-driven image customization has achieved significant\nadvancements in fidelity, yet fine-grained entity-level spatial control remains\nelusive, hindering the broader real-world application. This limitation is\nmainly attributed to scalable datasets that bind identity with precise\npositional cues are absent. To this end, we introduce PositionIC, a unified\nframework that enforces position and identity consistency for multi-subject\ncustomization. We construct a scalable synthesis pipeline that employs a\nbidirectional generation paradigm to eliminate subject drift and maintain\nsemantic coherence. On top of these data, we design a lightweight positional\nmodulation layer that decouples spatial embeddings among subjects, enabling\nindependent, accurate placement while preserving visual fidelity. Extensive\nexperiments demonstrate that our approach can achieve precise spatial control\nwhile maintaining high consistency in image customization task. PositionIC\npaves the way for controllable, high-fidelity image customization in\nopen-world, multi-entity scenarios and will be released to foster further\nresearch.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13861v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "PositionIC：图像定制中统一的位置与身份一致性", "tldr": "PositionIC是一个统一框架，通过双向生成范式和轻量级位置调制层，解决了多主体图像定制中精细实体级空间控制的难题，实现了精确的空间控制和高一致性。", "motivation": "当前图像定制在保真度方面取得了显著进展，但精细的实体级空间控制仍然难以实现，这阻碍了其更广泛的实际应用。主要原因是缺乏能将身份与精确位置线索结合的可扩展数据集。", "method": "本文提出了PositionIC，一个统一的框架，用于强制执行多主体定制中的位置和身份一致性。该框架构建了一个可扩展的合成管道，采用双向生成范式来消除主体漂移并保持语义连贯性。在此基础上，设计了一个轻量级的位置调制层，用于解耦主体之间的空间嵌入，从而在保持视觉保真度的同时实现独立、精确的放置。", "result": "大量的实验表明，PositionIC方法在图像定制任务中能够实现精确的空间控制，同时保持高一致性。", "conclusion": "PositionIC为开放世界、多实体场景中可控、高保真度的图像定制铺平了道路，并将发布以促进进一步研究。", "translation": "最近的主体驱动图像定制在保真度方面取得了显著进步，但精细的实体级空间控制仍然难以实现，这阻碍了更广泛的实际应用。这一限制主要归因于缺乏将身份与精确位置线索绑定在一起的可扩展数据集。为此，我们引入了PositionIC，一个统一的框架，用于在多主体定制中强制执行位置和身份一致性。我们构建了一个可扩展的合成管道，采用双向生成范式来消除主体漂移并保持语义连贯性。在此数据之上，我们设计了一个轻量级的位置调制层，用于解耦主体之间的空间嵌入，从而在保持视觉保真度的同时实现独立、准确的放置。大量的实验表明，我们的方法可以在图像定制任务中实现精确的空间控制，同时保持高一致性。PositionIC为开放世界、多实体场景中可控、高保真度的图像定制铺平了道路，并将发布以促进进一步研究。", "summary": "本文介绍了PositionIC，一个用于多主体图像定制的统一框架，旨在解决现有方法在精细实体级空间控制方面的不足。该框架通过构建一个结合双向生成范式和轻量级位置调制层的可扩展合成管道，有效实现了位置与身份的一致性，从而在保持高视觉保真度的同时，实现对多个主体进行独立且精确的空间放置。实验证明了其在图像定制任务中实现精确空间控制和高一致性的能力，为开放世界多实体场景下的可控高保真图像定制奠定了基础。", "keywords": "图像定制, 位置控制, 身份一致性, 多主体, 生成模型", "comments": "PositionIC的创新之处在于其统一框架设计，同时解决了图像定制中的位置和身份一致性问题。通过引入双向生成范式和解耦空间嵌入的位置调制层，该方法有效提升了多主体图像定制的精细控制能力，解决了现有技术在可扩展数据集和精确空间控制方面的痛点。这对于推动图像定制技术在现实世界应用中具有重要意义。"}}
{"id": "2507.13142", "title": "From Roots to Rewards: Dynamic Tree Reasoning with RL", "authors": ["Ahmed Bahloul", "Simon Malberg"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13142v2", "summary": "Modern language models address complex questions through chain-of-thought\n(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,\n2021), yet struggle with error propagation and knowledge integration.\nTree-structured reasoning methods, particularly the Probabilistic\nTree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues\nby decomposing questions into hierarchical structures and selecting answers\nthrough confidence-weighted aggregation of parametric and retrieved knowledge\n(Yao et al., 2023). However, ProbTree's static implementation introduces two\nkey limitations: (1) the reasoning tree is fixed during the initial\nconstruction phase, preventing dynamic adaptation to intermediate results, and\n(2) each node requires exhaustive evaluation of all possible solution\nstrategies, creating computational inefficiency. We present a dynamic\nreinforcement learning (Sutton and Barto, 2018) framework that transforms\ntree-based reasoning into an adaptive process. Our approach incrementally\nconstructs the reasoning tree based on real-time confidence estimates, while\nlearning optimal policies for action selection (decomposition, retrieval, or\naggregation). This maintains ProbTree's probabilistic rigor while improving\nboth solution quality and computational efficiency through selective expansion\nand focused resource allocation. The work establishes a new paradigm for\ntreestructured reasoning that balances the reliability of probabilistic\nframeworks with the flexibility required for real-world question answering\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13142v2", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "从根源到回报：基于强化学习的动态树状推理", "tldr": "本文提出一个基于强化学习的动态框架，通过实时置信度增量构建推理树，并学习最优动作策略，以克服现有树状推理方法（如ProbTree）的静态性和计算低效性，从而提高解决方案质量和计算效率。", "motivation": "现代语言模型在链式思考（CoT）和检索增强推理中面临错误传播和知识整合的挑战。现有的树状推理方法，特别是ProbTree，虽然缓解了这些问题，但其静态实现导致两个主要限制：推理树在初始构建阶段固定，无法动态适应中间结果；每个节点需要对所有可能的解决方案策略进行穷举评估，导致计算效率低下。", "method": "本文提出了一个动态强化学习框架。该方法基于实时置信度增量构建推理树，并学习用于动作选择（分解、检索或聚合）的最优策略。", "result": "该方法在保持ProbTree概率严谨性的同时，通过选择性扩展和集中资源分配，提高了解决方案质量和计算效率。", "conclusion": "这项工作为树状推理建立了一种新范式，平衡了概率框架的可靠性与实际问答系统所需的灵活性。", "translation": "现代语言模型通过链式思考（CoT）推理（Wei et al., 2023）和检索增强（Lewis et al., 2021）来解决复杂问题，但仍面临错误传播和知识整合的困扰。树状推理方法，特别是概率思维树（ProbTree）（Cao et al., 2023）框架，通过将问题分解为层次结构并通过参数化和检索知识的置信度加权聚合来选择答案，从而缓解了这些问题（Yao et al., 2023）。然而，ProbTree的静态实现引入了两个关键限制：（1）推理树在初始构建阶段是固定的，无法动态适应中间结果，以及（2）每个节点需要对所有可能的解决方案策略进行穷举评估，造成计算效率低下。我们提出了一个动态强化学习（Sutton and Barto, 2018）框架，将基于树的推理转化为一个自适应过程。我们的方法根据实时置信度估计增量构建推理树，同时学习动作选择（分解、检索或聚合）的最优策略。这在保持ProbTree概率严谨性的同时，通过选择性扩展和集中资源分配，提高了解决方案质量和计算效率。这项工作为树状推理建立了一种新范式，平衡了概率框架的可靠性与实际问答系统所需的灵活性。", "summary": "本文针对现有树状推理方法（如ProbTree）在动态适应性和计算效率方面的局限性，提出了一个基于强化学习的动态框架。该框架能够根据实时置信度增量构建推理树，并学习最优的动作选择策略（分解、检索或聚合）。实验结果表明，该方法在保持ProbTree概率严谨性的同时，显著提升了解决方案的质量和计算效率，为树状推理提供了一种兼顾可靠性和灵活性的新范式。", "keywords": "树状推理, 强化学习, 动态推理, 语言模型, ProbTree", "comments": "本文的创新点在于将强化学习引入树状推理，解决了传统树状推理方法（如ProbTree）静态性和计算效率低下的问题。通过动态构建推理树和学习最优策略，该方法提升了在大规模知识问答系统中的实用性和性能。这一范式转变对于需要复杂多步推理的AI系统具有重要意义。"}}
{"id": "2507.14034", "title": "Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors", "authors": ["Jochen Wulf", "Jurg Meierhofer", "Frank Hannich"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14034v1", "summary": "Agentic AI systems, powered by Large Language Models (LLMs), offer\ntransformative potential for value co-creation in technical services. However,\npersistent challenges like hallucinations and operational brittleness limit\ntheir autonomous use, creating a critical need for robust frameworks to guide\nhuman-AI collaboration. Drawing on established Human-AI teaming research and\nanalogies from fields like autonomous driving, this paper develops a structured\ntaxonomy of human-agent interaction. Based on case study research within\ntechnical support platforms, we propose a six-mode taxonomy that organizes\ncollaboration across a spectrum of AI autonomy. This spectrum is anchored by\nthe Human-Out-of-the-Loop (HOOTL) model for full automation and the\nHuman-Augmented Model (HAM) for passive AI assistance. Between these poles, the\nframework specifies four distinct intermediate structures. These include the\nHuman-in-Command (HIC) model, where AI proposals re-quire mandatory human\napproval, and the Human-in-the-Process (HITP) model for structured work-flows\nwith deterministic human tasks. The taxonomy further delineates the\nHuman-in-the-Loop (HITL) model, which facilitates agent-initiated escalation\nupon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables\ndiscretionary human oversight of an autonomous AI. The primary contribution of\nthis work is a comprehensive framework that connects this taxonomy to key\ncontingency factors -- such as task complexity, operational risk, and system\nreliability -- and their corresponding conceptual architectures. By providing a\nsystematic method for selecting and designing an appropriate level of human\noversight, our framework offers practitioners a crucial tool to navigate the\ntrade-offs between automation and control, thereby fostering the development of\nsafer, more effective, and context-aware technical service systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14034v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "为技术服务构建人机协作：交互模式与权变因素", "tldr": "本文提出了一个六模式的人机协作框架，用于技术服务中管理AI自主性，以解决LLM的局限性，并连接到任务复杂性、操作风险和系统可靠性等权变因素，帮助实践者平衡自动化与控制。", "motivation": "尽管LLM驱动的AI系统在技术服务中具有巨大的价值共创潜力，但其幻觉和操作脆弱性等挑战限制了自主使用，因此迫切需要一个强大的框架来指导人机协作。", "method": "本文借鉴人机协同研究和自动驾驶等领域的类比，基于对技术支持平台内的案例研究，开发了一个结构化的人机交互分类法，并提出了一个六模式分类法。", "result": "提出了一个涵盖AI自主性范围的六模式分类法，包括完全自动化的“Human-Out-of-the-Loop (HOOTL)”和被动AI辅助的“Human-Augmented Model (HAM)”，以及四种中间结构（Human-in-Command (HIC), Human-in-the-Process (HITP), Human-in-the-Loop (HITL), Human-on-the-Loop (HOTL)）。该工作的主要贡献是一个综合框架，将此分类法与任务复杂性、操作风险和系统可靠性等关键权变因素及其相应的概念架构联系起来。", "conclusion": "该框架提供了一种系统方法来选择和设计适当的人类监督水平，为实践者提供了在自动化和控制之间权衡的关键工具，从而促进开发更安全、更有效、更具情境意识的技术服务系统。", "translation": "基于大型语言模型（LLM）的智能AI系统为技术服务中的价值共创提供了变革性潜力。然而，幻觉和操作脆弱性等持续存在的挑战限制了它们的自主使用，从而迫切需要一个强大的框架来指导人机协作。本文借鉴既有的人机协同研究和自动驾驶等领域的类比，开发了一种结构化的人机交互分类法。基于对技术支持平台内的案例研究，我们提出了一个六模式分类法，该分类法将协作组织在AI自主性的一个谱系中。该谱系以用于完全自动化的“脱离人工模型（Human-Out-of-the-Loop, HOOTL）”和用于被动AI辅助的“人工增强模型（Human-Augmented Model, HAM）”为锚点。在这两极之间，该框架指定了四种不同的中间结构。这些结构包括“人工指令模型（Human-in-Command, HIC）”，其中AI提案需要强制性的人工批准；以及“人工参与流程模型（Human-in-the-Process, HITP）”，用于具有确定性人工任务的结构化工作流程。该分类法进一步划分了“人工在环模型（Human-in-the-Loop, HITL）”，它在不确定时促进代理发起的升级；以及“人工在链模型（Human-on-the-Loop, HOTL）”，它允许对自主AI进行酌情的人工监督。这项工作的主要贡献是一个综合框架，它将此分类法与任务复杂性、操作风险和系统可靠性等关键权变因素及其相应的概念架构联系起来。通过提供一种系统方法来选择和设计适当的人类监督水平，我们的框架为实践者提供了一个关键工具，以在自动化和控制之间进行权衡，从而促进开发更安全、更有效、更具情境意识的技术服务系统。", "summary": "本文针对大型语言模型（LLMs）在技术服务中自主应用面临的挑战，提出了一个六模式的人机协作分类法。该分类法涵盖了从完全自动化（HOOTL）到被动辅助（HAM）以及四种中间模式（HIC, HITP, HITL, HOTL）的AI自主性光谱。研究还建立了一个将此分类法与任务复杂性、操作风险和系统可靠性等关键权变因素相结合的综合框架，旨在为实践者提供设计和选择人机协作水平的系统方法，以开发更安全、有效且情境化的技术服务系统。", "keywords": "人机协作, 大语言模型, 技术服务, AI自主性, 权变因素", "comments": "这篇论文的创新点在于提出了一个细致的六模式人机协作分类法，并将其与实际的权变因素（如任务复杂性、风险和可靠性）相结合，为AI在技术服务领域的部署提供了实用的指导。它超越了简单的人在环/人出环二分法，为复杂的人机系统设计提供了更丰富的视角，有助于解决当前LLM面临的实际应用挑战。"}}
{"id": "2405.12182", "title": "Nearest Neighbors GParareal: Improving Scalability of Gaussian Processes for Parallel-in-Time Solvers", "authors": ["Guglielmo Gattiglio", "Lyudmila Grigoryeva", "Massimiliano Tamborrino"], "categories": ["stat.CO", "cs.DC", "cs.NA", "math.NA", "65M55, 65M22, 65L05, 50G15, 65Y05"], "primary_category": "Subjects:       Computation (stat.CO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.12182v2", "summary": "With the advent of supercomputers, multi-processor environments and\nparallel-in-time (PinT) algorithms offer ways to solve initial value problems\nfor ordinary and partial differential equations (ODEs and PDEs) over long time\nintervals, a task often unfeasible with sequential solvers within realistic\ntime frames. A recent approach, GParareal, combines Gaussian Processes with\ntraditional PinT methodology (Parareal) to achieve faster parallel speed-ups.\nThe method is known to outperform Parareal for low-dimensional ODEs and a\nlimited number of computer cores. Here, we present Nearest Neighbors GParareal\n(nnGParareal), a novel data-enriched PinT integration algorithm. nnGParareal\nbuilds upon GParareal by improving its scalability properties for\nhigher-dimensional systems and increased processor count. Through data\nreduction, the model complexity is reduced from cubic to log-linear in the\nsample size, yielding a fast and automated procedure to integrate initial value\nproblems over long time intervals. First, we provide both an upper bound for\nthe error and theoretical details on the speed-up benefits. Then, we\nempirically illustrate the superior performance of nnGParareal, compared to\nGParareal and Parareal, on nine different systems with unique features (e.g.,\nstiff, chaotic, high-dimensional, or challenging-to-learn systems).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.12182v2", "cate": "stat.CO", "date": "2024-05-20", "updated": "2025-07-17", "AI": {"title_translation": "最近邻GParareal：改进高斯过程在时间并行求解器中的可扩展性", "tldr": "nnGParareal是一种新的时间并行积分算法，通过数据降维改进了GParareal在高维系统和多处理器环境下的可扩展性，并经验性地证明了其优越性能。", "motivation": "传统的顺序求解器在长时间间隔内求解常微分方程和偏微分方程的初值问题通常不可行。GParareal结合高斯过程和Parareal方法，虽然在低维常微分方程和有限处理器核数下表现良好，但在高维系统和增加处理器数量时面临可扩展性限制。", "method": "本文提出了最近邻GParareal（nnGParareal），一种数据增强的时间并行积分算法。nnGParareal在GParareal的基础上，通过数据降维将模型复杂度从样本大小的立方降低到对数线性，从而提高了其在高维系统和增加处理器数量时的可扩展性。", "result": "nnGParareal实现了模型复杂度的显著降低（从立方到对数线性），提供了一种快速自动的初值问题长时间积分过程。理论上，提供了误差上限和加速效益的细节。经验上，nnGParareal在九个不同特征的系统（如刚性、混沌、高维或难以学习的系统）上表现出优于GParareal和Parareal的性能。", "conclusion": "nnGParareal通过引入数据降维显著提升了GParareal在高维系统和多处理器环境下的可扩展性，为长时间间隔的初值问题提供了一种更高效、更鲁棒的并行求解方案。", "translation": "随着超级计算机的出现，多处理器环境和时间并行（PinT）算法为在长时间间隔内求解常微分方程和偏微分方程（ODEs和PDEs）的初值问题提供了方法，这项任务对于顺序求解器在现实时间框架内通常是不可行的。最近的一种方法GParareal，将高斯过程与传统PinT方法（Parareal）相结合，以实现更快的并行加速。该方法已知在低维ODE和有限数量的计算机核心下优于Parareal。在此，我们提出了最近邻GParareal（nnGParareal），一种新颖的数据增强PinT积分算法。nnGParareal在GParareal的基础上，通过改进其在高维系统和增加处理器数量时的可扩展性来构建。通过数据降维，模型复杂度从样本大小的立方降低到对数线性，从而产生了一种快速自动的程序，用于在长时间间隔内积分初值问题。首先，我们提供了误差的上限和关于加速效益的理论细节。然后，我们通过经验性地在九个具有独特特征（例如，刚性、混沌、高维或难以学习的系统）的不同系统上，展示了nnGParareal与GParareal和Parareal相比的优越性能。", "summary": "本文提出了一种名为最近邻GParareal（nnGParareal）的新型时间并行积分算法，旨在解决现有GParareal方法在高维系统和多处理器环境下可扩展性不足的问题。nnGParareal通过数据降维技术，将模型复杂度从立方级降低到对数线性级，从而实现对初值问题的快速自动化积分。研究不仅提供了误差上限和理论加速优势，还通过在多种复杂系统上的实证测试，证明了nnGParareal相比GParareal和Parareal具有更优越的性能。", "keywords": "时间并行，高斯过程，可扩展性，数据降维，nnGParareal", "comments": "这篇论文的创新点在于提出了nnGParareal，通过巧妙地引入数据降维技术，解决了GParareal在处理高维问题和大规模并行计算时的可扩展性瓶颈。将模型复杂度从立方降至对数线性是一个显著的改进，使得该方法在实际应用中更具可行性，尤其是在超级计算机环境下。其重要性在于为求解长时间间隔的复杂初值问题提供了更高效、更鲁棒的并行解决方案。"}}
{"id": "2507.14117", "title": "Integrating Forecasting Models Within Steady-State Analysis and Optimization", "authors": ["Aayushya Agarwal", "Larry Pileggi"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14117v1", "summary": "Extreme weather variations and the increasing unpredictability of load\nbehavior make it difficult to determine power grid dispatches that are robust\nto uncertainties. While machine learning (ML) methods have improved the ability\nto model uncertainty caused by loads and renewables, accurately integrating\nthese forecasts and their sensitivities into steady-state analyses and\ndecision-making strategies remains an open challenge. Toward this goal, we\npresent a generalized methodology that seamlessly embeds ML-based forecasting\nengines within physics-based power flow and grid optimization tools. By\ncoupling physics-based grid modeling with black-box ML methods, we accurately\ncapture the behavior and sensitivity of loads and weather events by directly\nintegrating the inputs and outputs of trained ML forecasting models into the\nnumerical methods of power flow and grid optimization. Without fitting\nsurrogate load models, our approach obtains the sensitivities directly from\ndata to accurately predict the response of forecasted devices to changes in the\ngrid. Our approach combines the sensitivities of forecasted devices attained\nvia backpropagation and the sensitivities of physics-defined grid devices. We\ndemonstrate the efficacy of our method by showcasing improvements in\nsensitivity calculations and leveraging them to design a robust power dispatch\nthat improves grid reliability under stochastic weather events. Our approach\nenables the computation of system sensitivities to exogenous factors which\nsupports broader analyses that improve grid reliability in the presence of load\nvariability and extreme weather conditions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14117v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "将预测模型整合到稳态分析与优化中", "tldr": "本文提出了一种将机器学习预测模型直接嵌入到基于物理的电力潮流和电网优化工具中的通用方法，以准确捕获负荷和天气事件的敏感性，从而实现更鲁棒的电力调度并提高电网可靠性。", "motivation": "极端天气变化和负荷行为日益增加的不可预测性使得确定对不确定性具有鲁棒性的电网调度变得困难。尽管机器学习方法提高了对负荷和可再生能源引起的不确定性进行建模的能力，但如何将这些预测及其敏感性准确地整合到稳态分析和决策策略中仍然是一个开放的挑战。", "method": "本文提出了一种通用方法，将基于机器学习的预测引擎无缝嵌入到基于物理的电力潮流和电网优化工具中。通过将基于物理的电网建模与黑盒机器学习方法相结合，该方法通过将训练好的机器学习预测模型的输入和输出直接整合到电力潮流和电网优化数值方法中，准确捕获负荷和天气事件的行为和敏感性。该方法无需拟合替代负荷模型，直接从数据中获取敏感性，以准确预测预测设备对电网变化的响应。它结合了通过反向传播获得的预测设备的敏感性以及物理定义的电网设备的敏感性。", "result": "该方法在敏感性计算方面取得了改进，并利用这些改进设计了在随机天气事件下提高电网可靠性的鲁棒电力调度。它实现了对外生因素的系统敏感性计算。", "conclusion": "本文提出的方法能够计算系统对外生因素的敏感性，这支持了更广泛的分析，从而在负荷可变性和极端天气条件下提高了电网的可靠性。", "translation": "极端天气变化和负荷行为日益增加的不可预测性使得确定对不确定性具有鲁棒性的电网调度变得困难。尽管机器学习（ML）方法提高了对负荷和可再生能源引起的不确定性进行建模的能力，但如何将这些预测及其敏感性准确地整合到稳态分析和决策策略中仍然是一个开放的挑战。为实现这一目标，我们提出了一种通用方法，将基于机器学习的预测引擎无缝嵌入到基于物理的电力潮流和电网优化工具中。通过将基于物理的电网建模与黑盒机器学习方法相结合，我们通过将训练好的机器学习预测模型的输入和输出直接整合到电力潮流和电网优化数值方法中，准确捕获负荷和天气事件的行为和敏感性。我们的方法无需拟合替代负荷模型，直接从数据中获取敏感性，以准确预测预测设备对电网变化的响应。我们的方法结合了通过反向传播获得的预测设备的敏感性以及物理定义的电网设备的敏感性。我们通过展示敏感性计算的改进，并利用这些改进设计了在随机天气事件下提高电网可靠性的鲁棒电力调度，从而证明了我们方法的有效性。我们的方法能够计算系统对外生因素的敏感性，这支持了更广泛的分析，从而在负荷可变性和极端天气条件下提高了电网的可靠性。", "summary": "本文针对电力系统在极端天气和负荷不确定性下难以实现鲁棒调度的挑战，提出了一种将机器学习预测模型与基于物理的电力潮流及电网优化工具无缝结合的通用方法。该方法通过直接整合机器学习模型的输入输出，捕获负荷和天气事件的敏感性，无需建立替代负荷模型，并结合反向传播和物理模型的敏感性计算。实验结果表明，该方法能有效改进敏感性计算，并支持设计更鲁棒的电力调度，从而在面对负荷波动和极端天气时提高电网可靠性。", "keywords": "电力系统, 机器学习, 预测模型, 稳态分析, 敏感性计算", "comments": "该论文的创新点在于提出了一种直接将机器学习预测模型及其敏感性嵌入到传统物理电力系统分析工具中的方法，而不是依赖于间接的代理模型。这种紧密的耦合使得系统能够更准确地理解和响应不确定性，尤其是在处理极端天气和动态负荷行为时。其重要性在于为电力系统运营商提供了更强大的工具，以在日益复杂和不确定的环境中提高电网的可靠性和鲁棒性。该方法通过直接从数据中获取敏感性，避免了传统建模的复杂性，并为未来更智能、自适应的电网操作奠定了基础。"}}
{"id": "2410.05347", "title": "Bridging Local and Global Knowledge via Transformer in Board Games", "authors": ["Yan-Ru Ju", "Tai-Lin Wu", "Chung-Chin Shih", "Ti-Rong Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by the Thirty-Fourth International Joint Conferences on Artificial Intelligence (IJCAI-25)", "url": "http://arxiv.org/abs/2410.05347v2", "summary": "Although AlphaZero has achieved superhuman performance in board games, recent\nstudies reveal its limitations in handling scenarios requiring a comprehensive\nunderstanding of the entire board, such as recognizing long-sequence patterns\nin Go. To address this challenge, we propose ResTNet, a network that\ninterleaves residual and Transformer blocks to bridge local and global\nknowledge. ResTNet improves playing strength across multiple board games,\nincreasing win rate from 54.6% to 60.8% in 9x9 Go, 53.6% to 60.9% in 19x19 Go,\nand 50.4% to 58.0% in 19x19 Hex. In addition, ResTNet effectively processes\nglobal information and tackles two long-sequence patterns in 19x19 Go,\nincluding circular pattern and ladder pattern. It reduces the mean square error\nfor circular pattern recognition from 2.58 to 1.07 and lowers the attack\nprobability against an adversary program from 70.44% to 23.91%. ResTNet also\nimproves ladder pattern recognition accuracy from 59.15% to 80.01%. By\nvisualizing attention maps, we demonstrate that ResTNet captures critical game\nconcepts in both Go and Hex, offering insights into AlphaZero's decision-making\nprocess. Overall, ResTNet shows a promising approach to integrating local and\nglobal knowledge, paving the way for more effective AlphaZero-based algorithms\nin board games. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/restnet.", "comment": "Accepted by the Thirty-Fourth International Joint Conferences on\n  Artificial Intelligence (IJCAI-25)", "pdf_url": "http://arxiv.org/pdf/2410.05347v2", "cate": "cs.LG", "date": "2024-10-07", "updated": "2025-07-18", "AI": {"title_translation": "通过Transformer在棋盘游戏中连接局部和全局知识", "tldr": "本文提出ResTNet，一种结合残差和Transformer块的网络，用于在棋盘游戏中整合局部和全局知识，从而显著提升了AlphaZero在围棋和六子棋中的表现，尤其是在处理长序列模式方面。", "motivation": "尽管AlphaZero在棋盘游戏中表现超人，但其在处理需要全面理解整个棋盘的场景（如识别围棋中的长序列模式）时存在局限性。", "method": "我们提出了ResTNet，一个交错使用残差块和Transformer块的网络，旨在连接局部和全局知识。", "result": "ResTNet提升了多种棋盘游戏的下棋强度：在9x9围棋中胜率从54.6%提升到60.8%，在19x19围棋中从53.6%提升到60.9%，在19x19六子棋中从50.4%提升到58.0%。它有效地处理了全局信息并解决了19x19围棋中的两种长序列模式（循环模式和打劫模式），将循环模式识别的均方误差从2.58降低到1.07，对抗对手程序的攻击概率从70.44%降低到23.91%。此外，打劫模式识别准确率从59.15%提高到80.01%。", "conclusion": "ResTNet展示了一种集成局部和全局知识的有前景的方法，为棋盘游戏中更有效的基于AlphaZero的算法铺平了道路。", "translation": "尽管AlphaZero在棋盘游戏中取得了超人的表现，但最近的研究揭示了其在处理需要全面理解整个棋盘的场景（例如识别围棋中的长序列模式）时的局限性。为了解决这一挑战，我们提出了ResTNet，一个交错使用残差块和Transformer块的网络，以连接局部和全局知识。ResTNet提高了多种棋盘游戏的下棋强度，在9x9围棋中胜率从54.6%提高到60.8%，在19x19围棋中从53.6%提高到60.9%，在19x19六子棋中从50.4%提高到58.0%。此外，ResTNet有效处理全局信息并解决了19x19围棋中的两种长序列模式，包括循环模式和打劫模式。它将循环模式识别的均方误差从2.58降低到1.07，并将对抗对手程序的攻击概率从70.44%降低到23.91%。ResTNet还将打劫模式识别准确率从59.15%提高到80.01%。通过可视化注意力图，我们证明ResTNet在围棋和六子棋中捕获了关键的游戏概念，为AlphaZero的决策过程提供了见解。总的来说，ResTNet展示了一种集成局部和全局知识的有前景的方法，为棋盘游戏中更有效的基于AlphaZero的算法铺平了道路。我们的代码可在https://rlg.iis.sinica.edu.tw/papers/restnet获取。", "summary": "本文提出了ResTNet，一种通过结合残差块和Transformer块来弥补局部和全局知识之间鸿沟的新型神经网络架构。该网络旨在解决AlphaZero在处理需要全局理解的棋盘游戏场景（如围棋中的长序列模式）时的局限性。实验结果表明，ResTNet显著提升了在9x9围棋、19x19围棋和19x19六子棋中的胜率，并有效提高了对围棋中循环模式和打劫模式的识别能力，降低了错误率和攻击概率，提高了识别准确率。通过注意力图可视化，ResTNet展示了捕获关键游戏概念的能力，为未来开发更强大的基于AlphaZero的算法奠定了基础。", "keywords": "Transformer, 棋盘游戏, AlphaZero, 局部知识, 全局知识", "comments": "本文的创新点在于提出了ResTNet，通过巧妙地结合残差网络处理局部特征的能力和Transformer处理全局依赖的能力，有效解决了AlphaZero在处理全局信息和长序列模式上的不足。其重要性体现在显著提升了多种棋盘游戏（尤其是围棋）的表现，并为理解AI在复杂决策过程中的注意力机制提供了新的视角。该研究为未来开发更强大、更具泛化能力的棋盘游戏AI提供了有价值的方向。"}}
{"id": "2507.13371", "title": "Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation", "authors": ["Yeming Cai", "Yang Wang", "Zhenglin Li"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13371v1", "summary": "This paper proposes an end-to-end deep learning framework integrating optical\nmotion capture with a Transformer-based model to enhance medical\nrehabilitation. It tackles data noise and missing data caused by occlusion and\nenvironmental factors, while detecting abnormal movements in real time to\nensure patient safety. Utilizing temporal sequence modeling, our framework\ndenoises and completes motion capture data, improving robustness. Evaluations\non stroke and orthopedic rehabilitation datasets show superior performance in\ndata reconstruction and anomaly detection, providing a scalable, cost-effective\nsolution for remote rehabilitation with reduced on-site supervision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13371v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11", "AI": {"title_translation": "基于Transformer的医学康复运动捕捉去噪与异常检测框架", "tldr": "本文提出了一个基于Transformer的端到端深度学习框架，用于医学康复中的运动捕捉数据去噪和异常检测，以提高数据质量和患者安全，并支持远程康复。", "motivation": "解决医学康复中光学运动捕捉数据存在的噪声和遮挡、环境因素导致的缺失数据问题，并实时检测异常运动以确保患者安全。", "method": "提出了一个端到端深度学习框架，该框架将光学运动捕捉与基于Transformer的模型相结合，并利用时间序列建模来去噪和完成运动捕捉数据。", "result": "在卒中和骨科康复数据集上的评估显示，该框架在数据重建和异常检测方面表现优异。", "conclusion": "该框架为远程康复提供了一个可扩展、经济高效的解决方案，并能减少现场监督。", "translation": "本文提出了一个将光学运动捕捉与基于Transformer的模型相结合的端到端深度学习框架，以增强医学康复。它解决了由遮挡和环境因素引起的数据噪声和缺失数据问题，同时实时检测异常运动以确保患者安全。利用时间序列建模，我们的框架对运动捕捉数据进行去噪和补全，提高了鲁棒性。在卒中和骨科康复数据集上的评估显示，该框架在数据重建和异常检测方面表现优异，为远程康复提供了一个可扩展、经济高效的解决方案，并能减少现场监督。", "summary": "本文提出了一种基于Transformer的端到端深度学习框架，旨在解决医学康复中运动捕捉数据的噪声、缺失及异常运动检测问题。该框架利用时间序列建模对数据进行去噪和补全，并在卒中及骨科康复数据集上展现出卓越的性能，为远程康复提供了一种可扩展且经济高效的解决方案。", "keywords": "Transformer, 运动捕捉, 去噪, 异常检测, 医学康复", "comments": "该论文的创新之处在于将Transformer模型应用于医学康复领域的运动捕捉数据去噪和异常检测，有效解决了传统方法面临的数据质量和实时性挑战。其重要性体现在为远程医疗康复提供了更安全、高效且成本更低的解决方案，有望大幅提升患者康复体验和效率。"}}
{"id": "2502.02592", "title": "A Paradigm Shift to Assembly-like Finite Element Model Updating", "authors": ["Gabriele Dessena", "Alessandro Pontillo", "Dmitry I. Ignatyev", "James F. Whidborne", "Luca Zanotti Fragonara"], "categories": ["cs.CE"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.02592v2", "summary": "In general, there is a mismatch between a finite element model of a structure\nand its real behaviour. In aeronautics, this mismatch must be small because\nfinite element models are a fundamental part of the development of an aircraft\nand of increasing importance with the trend to more flexible wings in modern\ndesigns. Finite element model updating can be computationally expensive for\ncomplex structures and surrogate models can be employed to reduce the\ncomputational burden. A novel approach for finite element model updating,\nnamely assembly-like, is proposed and validated using real experimental data.\nThe assembly-like model updating framework implies that the model is updated as\nparts are assembled. Benchmarking against the classical global, or one-shot,\napproach demonstrates that the proposed method is more computationally\nefficient since it takes 20% fewer iterations to obtain convergence, also using\nfewer parameters for the model evaluations. Despite the increase in\ncomputational performance, the new approach retains the fidelity of the global\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.02592v2", "cate": "cs.CE", "date": "2024-12-17", "updated": "2025-07-18", "AI": {"title_translation": "一种面向装配的有限元模型修正范式转变", "tldr": "提出了一种新的“面向装配”的有限元模型修正方法，该方法比传统方法计算效率更高，同时保持了精度。", "motivation": "有限元模型与实际结构行为之间存在不匹配，特别是在航空领域，这需要高精度。此外，复杂结构的有限元模型修正计算成本高昂。", "method": "提出了一种新颖的“面向装配”的有限元模型修正方法。该框架意味着模型在部件组装时进行修正。该方法使用真实实验数据进行验证，并与经典的全局（一次性）方法进行基准测试。", "result": "与传统的全局方法相比，所提出的方法计算效率更高，收敛所需的迭代次数减少了20%，并且模型评估使用的参数更少。尽管计算性能有所提高，新方法仍保持了全局方法的精度。", "conclusion": "所提出的“面向装配”的有限元模型修正方法在计算效率上优于传统方法，同时保持了模型修正的精度和可靠性，为复杂结构的有限元模型修正提供了一个有前景的替代方案。", "translation": "一般来说，结构的有限元模型与其真实行为之间存在不匹配。在航空领域，这种不匹配必须很小，因为有限元模型是飞机开发的基础部分，并且随着现代设计中更柔性机翼的趋势，其重要性日益增加。对于复杂结构，有限元模型修正可能计算成本高昂，可以使用代理模型来减少计算负担。本文提出了一种新颖的有限元模型修正方法，即面向装配的方法，并使用真实的实验数据进行了验证。面向装配的模型修正框架意味着模型在部件组装时进行修正。与经典的全局（或一次性）方法进行基准测试表明，所提出的方法在计算上更高效，因为它获得收敛所需的迭代次数减少了20%，并且模型评估使用的参数更少。尽管计算性能有所提高，新方法仍保持了全局方法的精度。", "summary": "本文提出了一种名为“面向装配”的新型有限元模型修正方法，旨在解决传统方法在复杂结构中计算成本高的问题。该方法在部件组装过程中逐步修正模型，并通过真实实验数据进行了验证。与经典的全局修正方法相比，“面向装配”方法在计算效率上显著提高，收敛速度更快，所需参数更少，同时保持了与全局方法相同的修正精度。", "keywords": "有限元模型修正, 面向装配, 计算效率, 航空, 代理模型", "comments": "这项研究提出了一种创新的有限元模型修正范式，通过引入“面向装配”的概念，有效地解决了传统全局方法在计算效率上的瓶颈。其创新点在于将模型修正过程与结构装配过程相结合，实现了计算性能的显著提升，同时保持了高精度，这对于航空等对模型精度和效率要求极高的领域具有重要意义。"}}
{"id": "2507.14035", "title": "Toward Practical Fluid Antenna Systems: Co-Optimizing Hardware and Software for Port Selection and Beamforming", "authors": ["Sai Xu", "Kai-Kit Wong", "Yanan Du", "Hanjiang Hong", "Chan-Byoung Chae", "Baiyang Liu", "Kin-Fai Tong"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14035v1", "summary": "This paper proposes a hardware-software co-design approach to efficiently\noptimize beamforming and port selection in fluid antenna systems (FASs). To\nbegin with, a fluid-antenna (FA)-enabled downlink multi-cell multiple-input\nmultiple-output (MIMO) network is modeled, and a weighted sum-rate (WSR)\nmaximization problem is formulated. Second, a method that integrates graph\nneural networks (GNNs) with random port selection (RPS) is proposed to jointly\noptimize beamforming and port selection, while also assessing the benefits and\nlimitations of random selection. Third, an instruction-driven deep learning\naccelerator based on a field-programmable gate array (FPGA) is developed to\nminimize inference latency. To further enhance efficiency, a scheduling\nalgorithm is introduced to reduce redundant computations and minimize the idle\ntime of computing cores. Simulation results demonstrate that the proposed\nGNN-RPS approach achieves competitive communication performance. Furthermore,\nexperimental evaluations indicate that the FPGA-based accelerator maintains low\nlatency while simultaneously executing beamforming inference for multiple port\nselections.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14035v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "迈向实用的流体天线系统：协同优化硬件和软件以实现端口选择和波束成形", "tldr": "提出了一种硬件-软件协同设计，利用图神经网络和FPGA高效优化流体天线系统。", "motivation": "旨在高效优化流体天线系统（FASs）中的波束成形和端口选择。", "method": "首先，建模了一个支持流体天线（FA）的下行多小区多输入多输出（MIMO）网络，并提出了加权和速率（WSR）最大化问题。其次，提出了一种将图神经网络（GNNs）与随机端口选择（RPS）相结合的方法，以联合优化波束成形和端口选择。第三，开发了一种基于现场可编程门阵列（FPGA）的指令驱动深度学习加速器，以最小化推理延迟。最后，引入了一种调度算法以减少冗余计算并最小化计算核心的空闲时间。", "result": "仿真结果表明，所提出的GNN-RPS方法实现了具有竞争力的通信性能。此外，实验评估表明，基于FPGA的加速器在同时执行多个端口选择的波束成形推理时，仍能保持低延迟。", "conclusion": "该论文提出的硬件-软件协同设计方法能够有效优化流体天线系统，并在通信性能和推理延迟方面表现出色，为FAS的实际应用奠定了基础。", "translation": "本文提出了一种硬件-软件协同设计方法，旨在高效优化流体天线系统（FASs）中的波束成形和端口选择。首先，建模了一个支持流体天线（FA）的下行多小区多输入多输出（MIMO）网络，并提出了加权和速率（WSR）最大化问题。其次，提出了一种将图神经网络（GNNs）与随机端口选择（RPS）相结合的方法，以联合优化波束成形和端口选择，同时评估随机选择的优点和局限性。第三，开发了一种基于现场可编程门阵列（FPGA）的指令驱动深度学习加速器，以最小化推理延迟。为了进一步提高效率，引入了一种调度算法以减少冗余计算并最小化计算核心的空闲时间。仿真结果表明，所提出的GNN-RPS方法实现了具有竞争力的通信性能。此外，实验评估表明，基于FPGA的加速器在同时执行多个端口选择的波束成形推理时，仍能保持低延迟。", "summary": "本论文提出了一种针对流体天线系统（FASs）的硬件-软件协同设计方法，旨在优化波束成形和端口选择。研究内容包括建模FA支持的多小区MIMO网络并提出WSR最大化问题，以及开发结合图神经网络（GNNs）和随机端口选择（RPS）的联合优化方法。为提高效率和降低延迟，还设计了基于FPGA的深度学习加速器和调度算法。仿真和实验结果验证了GNN-RPS在通信性能上的竞争力，以及FPGA加速器在多端口波束成形推理中保持低延迟的优越性。", "keywords": "流体天线系统, 硬件-软件协同设计, 波束成形, 端口选择, 图神经网络, FPGA", "comments": "该论文通过硬件与软件的协同优化，为流体天线系统（FASs）的实际部署提供了创新方法。结合图神经网络（GNNs）进行联合优化，并开发定制的FPGA加速器以实现低延迟推理，解决了FASs中的关键挑战，展示了一种实现高效高性能无线通信的整体解决方案。"}}
{"id": "2403.14559", "title": "VAPO: Visibility-Aware Keypoint Localization for Efficient 6DoF Object Pose Estimation", "authors": ["Ruyi Lian", "Yuewei Lin", "Longin Jan Latecki", "Haibin Ling"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation", "url": "http://arxiv.org/abs/2403.14559v5", "summary": "Localizing predefined 3D keypoints in a 2D image is an effective way to\nestablish 3D-2D correspondences for instance-level 6DoF object pose estimation.\nHowever, unreliable localization results of invisible keypoints degrade the\nquality of correspondences. In this paper, we address this issue by localizing\nthe important keypoints in terms of visibility. Since keypoint visibility\ninformation is currently missing in the dataset collection process, we propose\nan efficient way to generate binary visibility labels from available\nobject-level annotations, for keypoints of both asymmetric objects and\nsymmetric objects. We further derive real-valued visibility-aware importance\nfrom binary labels based on the PageRank algorithm. Taking advantage of the\nflexibility of our visibility-aware importance, we construct VAPO\n(Visibility-Aware POse estimator) by integrating the visibility-aware\nimportance with a state-of-the-art pose estimation algorithm, along with\nadditional positional encoding. VAPO can work in both CAD-based and CAD-free\nsettings. Extensive experiments are conducted on popular pose estimation\nbenchmarks including Linemod, Linemod-Occlusion, and YCB-V, demonstrating that\nVAPO clearly achieves state-of-the-art performances. Project page:\nhttps://github.com/RuyiLian/VAPO.", "comment": "accepted for publication in the Proceedings of the 2025 IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2025) as\n  oral presentation", "pdf_url": "http://arxiv.org/pdf/2403.14559v5", "cate": "cs.CV", "date": "2024-03-21", "updated": "2025-07-18", "AI": {"title_translation": "VAPO：可见性感知关键点定位，用于高效6自由度物体姿态估计", "tldr": "VAPO提出了一种新的可见性感知关键点定位方法，通过生成可见性标签和利用PageRank算法导出重要性，显著提高了6自由度物体姿态估计的准确性，并在多个基准测试中达到了最先进的性能。", "motivation": "在6自由度物体姿态估计中，不可见关键点的不可靠定位结果会降低3D-2D对应关系的质量，进而影响姿态估计的准确性。当前数据集中缺乏关键点可见性信息。", "method": "作者提出了一种从现有物体级标注中高效生成二值可见性标签的方法，适用于非对称和对称物体。进一步，基于PageRank算法，从二值标签中推导出实值可见性感知重要性。然后，将这种可见性感知重要性与现有最先进的姿态估计算法以及额外的位置编码相结合，构建了VAPO（Visibility-Aware POse estimator）。VAPO可在基于CAD和无CAD设置下工作。", "result": "在Linemod、Linemod-Occlusion和YCB-V等流行姿态估计基准测试上进行了大量实验，结果表明VAPO明显实现了最先进的性能。", "conclusion": "通过引入和利用关键点的可见性信息，VAPO显著提高了6自由度物体姿态估计的准确性和鲁棒性，达到了最先进的性能。", "translation": "在2D图像中定位预定义的3D关键点是建立实例级6自由度物体姿态估计的3D-2D对应关系的有效方法。然而，不可见关键点的不可靠定位结果会降低对应关系的质量。在本文中，我们通过定位可见性方面的重要关键点来解决这个问题。由于关键点可见性信息目前在数据集采集中缺失，我们提出了一种从现有物体级标注中高效生成二值可见性标签的方法，适用于非对称物体和对称物体。我们进一步基于PageRank算法从二值标签中推导出实值可见性感知重要性。利用我们可见性感知重要性的灵活性，我们通过将可见性感知重要性与最先进的姿态估计算法以及额外的位置编码相结合，构建了VAPO（可见性感知姿态估计器）。VAPO可以在基于CAD和无CAD设置下工作。在包括Linemod、Linemod-Occlusion和YCB-V在内的流行姿态估计基准上进行了大量实验，结果表明VAPO明显达到了最先进的性能。项目页面：https://github.com/RuyiLian/VAPO。", "summary": "本文提出了一种名为VAPO的新型6自由度物体姿态估计算法，旨在解决不可见关键点定位不可靠的问题。该方法通过从现有物体级标注中高效生成关键点的二值可见性标签，并利用PageRank算法进一步导出实值可见性感知重要性。VAPO将这种可见性感知重要性与现有最先进的姿态估计算法和位置编码相结合。实验结果表明，VAPO在多个标准基准测试上取得了最先进的性能，验证了其在CAD-based和CAD-free设置下的有效性。", "keywords": "6自由度姿态估计, 关键点定位, 可见性感知, PageRank, VAPO", "comments": "VAPO的创新之处在于引入了关键点可见性信息，并通过PageRank算法将其转化为可量化的重要性，有效地解决了传统方法中不可见关键点定位不准确的问题。这种方法弥补了现有数据集缺乏可见性标注的不足，提高了6DoF姿态估计的鲁棒性和准确性，具有重要的实际应用价值。"}}
{"id": "2404.04834", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead", "authors": ["Junda He", "Christoph Treude", "David Lo"], "categories": ["cs.SE"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      TOSEM 2030 Special Issue", "url": "http://arxiv.org/abs/2404.04834v4", "summary": "Integrating Large Language Models (LLMs) into autonomous agents marks a\nsignificant shift in the research landscape by offering cognitive abilities\nthat are competitive with human planning and reasoning. This paper explores the\ntransformative potential of integrating Large Language Models into Multi-Agent\n(LMA) systems for addressing complex challenges in software engineering (SE).\nBy leveraging the collaborative and specialized abilities of multiple agents,\nLMA systems enable autonomous problem-solving, improve robustness, and provide\nscalable solutions for managing the complexity of real-world software projects.\nIn this paper, we conduct a systematic review of recent primary studies to map\nthe current landscape of LMA applications across various stages of the software\ndevelopment lifecycle (SDLC). To illustrate current capabilities and\nlimitations, we perform two case studies to demonstrate the effectiveness of\nstate-of-the-art LMA frameworks. Additionally, we identify critical research\ngaps and propose a comprehensive research agenda focused on enhancing\nindividual agent capabilities and optimizing agent synergy. Our work outlines a\nforward-looking vision for developing fully autonomous, scalable, and\ntrustworthy LMA systems, laying the foundation for the evolution of Software\nEngineering 2.0.", "comment": "TOSEM 2030 Special Issue", "pdf_url": "http://arxiv.org/pdf/2404.04834v4", "cate": "cs.SE", "date": "2024-04-07", "updated": "2025-07-18", "AI": {"title_translation": "基于LLM的多智能体系统在软件工程中的应用：文献综述、愿景与未来之路", "tldr": "本文综述了LLM驱动的多智能体系统在软件工程中的应用现状，探讨了其潜力、挑战，并提出了未来研究议程。", "motivation": "论文旨在探讨将大型语言模型（LLMs）集成到多智能体（LMA）系统中，以解决软件工程（SE）中复杂挑战的变革潜力，并推动软件工程向2.0时代发展。", "method": "作者进行了系统性的文献综述，以描绘LMA系统在软件开发生命周期（SDLC）各阶段的应用现状。此外，他们还进行了两个案例研究，以展示当前LMA框架的有效性及局限性。最后，他们识别了研究空白并提出了一个全面的研究议程。", "result": "论文描绘了LMA系统在软件开发生命周期中的应用图景，并通过案例研究展示了其能力和局限性。识别了关键研究空白并提出了研究议程。", "conclusion": "该工作为开发完全自主、可扩展和值得信赖的LMA系统描绘了一个前瞻性愿景，为软件工程2.0的演进奠定了基础。", "translation": "将大型语言模型（LLMs）集成到自主智能体中，标志着研究领域的一个重大转变，因为它提供了与人类规划和推理相媲美的认知能力。本文探讨了将大型语言模型集成到多智能体（LMA）系统中，以解决软件工程（SE）中复杂挑战的变革潜力。通过利用多个智能体的协作和专业化能力，LMA系统能够实现自主问题解决，提高鲁棒性，并为管理真实世界软件项目的复杂性提供可扩展的解决方案。在本文中，我们对近期主要研究进行了系统性综述，以描绘LMA应用在软件开发生命周期（SDLC）各个阶段的当前图景。为了说明当前的能力和局限性，我们进行了两个案例研究，以展示最先进LMA框架的有效性。此外，我们识别了关键的研究空白，并提出了一个全面的研究议程，重点是增强单个智能体的能力和优化智能体协同。我们的工作为开发完全自主、可扩展和值得信赖的LMA系统描绘了一个前瞻性愿景，为软件工程2.0的演进奠定了基础。", "summary": "本文对基于大型语言模型的多智能体（LMA）系统在软件工程领域的应用进行了系统性综述。研究探讨了LMA系统如何通过结合LLM的认知能力和多智能体的协作优势，解决软件开发中的复杂问题，提高自动化和鲁棒性。作者通过文献回顾和案例研究展示了当前LMA系统的能力与局限，并提出了未来研究方向，旨在构建完全自主、可扩展且可靠的LMA系统，以推动软件工程进入新时代。", "keywords": "LLM, 多智能体系统, 软件工程, 文献综述, 软件开发生命周期", "comments": "这篇论文具有重要的前瞻性，它系统性地梳理了LLM与多智能体系统结合在软件工程领域的应用现状和未来潜力。其创新点在于不仅进行了全面的文献综述，还通过案例研究验证了现有框架的有效性，并提出了详细的研究议程，为未来软件工程的发展指明了方向，预示着“软件工程2.0”时代的到来。"}}
{"id": "2507.12440", "title": "EgoVLA: Learning Vision-Language-Action Models from Egocentric Human Videos", "authors": ["Ruihan Yang", "Qinxi Yu", "Yecheng Wu", "Rui Yan", "Borui Li", "An-Chieh Cheng", "Xueyan Zou", "Yunhao Fang", "Xuxin Cheng", "Ri-Zhao Qiu", "Hongxu Yin", "Sifei Liu", "Song Han", "Yao Lu", "Xiaolong Wang"], "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      More videos can be found on our website: this https URL", "url": "http://arxiv.org/abs/2507.12440v3", "summary": "Real robot data collection for imitation learning has led to significant\nadvancements in robotic manipulation. However, the requirement for robot\nhardware in the process fundamentally constrains the scale of the data. In this\npaper, we explore training Vision-Language-Action (VLA) models using egocentric\nhuman videos. The benefit of using human videos is not only for their scale but\nmore importantly for the richness of scenes and tasks. With a VLA trained on\nhuman video that predicts human wrist and hand actions, we can perform Inverse\nKinematics and retargeting to convert the human actions to robot actions. We\nfine-tune the model using a few robot manipulation demonstrations to obtain the\nrobot policy, namely EgoVLA. We propose a simulation benchmark called Ego\nHumanoid Manipulation Benchmark, where we design diverse bimanual manipulation\ntasks with demonstrations. We fine-tune and evaluate EgoVLA with Ego Humanoid\nManipulation Benchmark and show significant improvements over baselines and\nablate the importance of human data. Videos can be found on our website:\nhttps://rchalyang.github.io/EgoVLA", "comment": "More videos can be found on our website:\n  https://rchalyang.github.io/EgoVLA", "pdf_url": "http://arxiv.org/pdf/2507.12440v3", "cate": "cs.RO", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "EgoVLA：从以自我为中心的视频中学习视觉-语言-动作模型", "tldr": "EgoVLA通过从大规模以自我为中心的人类视频中学习视觉-语言-动作模型，并结合少量机器人数据进行微调，显著提升了机器人操纵能力，解决了机器人数据收集的规模限制问题。", "motivation": "现有的机器人模仿学习需要大量的机器人硬件数据收集，这严重限制了数据规模。本文旨在探索利用大规模、场景和任务丰富的以自我为中心的人类视频来训练视觉-语言-动作（VLA）模型，以克服这一限制并提升机器人操纵能力。", "method": "研究人员首先利用以自我为中心的人类视频训练视觉-语言-动作（VLA）模型，该模型能够预测人类手腕和手部动作。然后，通过逆运动学和重定向技术将人类动作转换为机器人动作。最后，使用少量机器人操纵演示对模型进行微调，得到最终的机器人策略，命名为EgoVLA。此外，他们还提出了一个名为Ego Humanoid Manipulation Benchmark的模拟基准，用于设计多样化的双手操纵任务和演示，并用其对EgoVLA进行微调和评估。", "result": "EgoVLA在Ego Humanoid Manipulation Benchmark上表现出显著优于基线的性能提升。研究还通过消融实验证明了人类数据的重要性。", "conclusion": "通过利用大规模以自我为中心的人类视频训练VLA模型，并结合少量机器人数据进行微调，可以有效解决机器人数据收集的规模限制，显著提高机器人操纵能力。", "translation": "用于模仿学习的真实机器人数据收集已在机器人操纵领域取得了显著进展。然而，此过程中对机器人硬件的需求从根本上限制了数据的规模。在本文中，我们探索使用以自我为中心的人类视频来训练视觉-语言-动作（VLA）模型。使用人类视频的好处不仅在于其规模，更重要的是场景和任务的丰富性。通过在人类视频上训练的VLA模型来预测人类手腕和手部动作，我们可以执行逆运动学和重定向，将人类动作转换为机器人动作。我们使用少量机器人操纵演示来微调模型，以获得机器人策略，即EgoVLA。我们提出了一个名为Ego Humanoid Manipulation Benchmark的模拟基准，其中我们设计了多样化的双手操纵任务和演示。我们使用Ego Humanoid Manipulation Benchmark对EgoVLA进行微调和评估，结果显示其比基线有显著改进，并消融了人类数据的重要性。视频可在我们的网站上找到：https://rchalyang.github.io/EgoVLA", "summary": "本文提出EgoVLA，一种利用大规模以自我为中心的人类视频训练的视觉-语言-动作（VLA）模型，旨在克服机器人数据收集的规模限制。该方法通过预测人类手腕和手部动作，并利用逆运动学和重定向技术将其转换为机器人动作，再通过少量机器人演示进行微调。研究引入了Ego Humanoid Manipulation Benchmark进行评估，结果表明EgoVLA显著优于现有基线，并强调了人类数据在提升机器人操纵能力方面的重要性。", "keywords": "以自我为中心视频, 视觉-语言-动作模型, 机器人操纵, 模仿学习, 人类数据", "comments": "这项工作具有创新性，因为它通过利用大规模、多样化的人类视频数据来解决机器人模仿学习中数据稀疏性的核心问题。通过将人类动作转换为机器人可执行的策略，EgoVLA为机器人学习提供了一种可扩展且有效的新范式。Ego Humanoid Manipulation Benchmark的引入也为未来的研究提供了一个有价值的评估工具。其重要性在于，它为实现更通用、更灵活的机器人操纵提供了新的途径，有望加速现实世界中机器人应用的部署。"}}
{"id": "2507.13915", "title": "Blind Super Resolution with Reference Images and Implicit Degradation Representation", "authors": ["Huu-Phu Do", "Po-Chih Hu", "Hao-Chien Hsueh", "Che-Kai Liu", "Vu-Hoang Tran", "Ching-Chun Huang"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by ACCV 2024", "url": "http://arxiv.org/abs/2507.13915v1", "summary": "Previous studies in blind super-resolution (BSR) have primarily concentrated\non estimating degradation kernels directly from low-resolution (LR) inputs to\nenhance super-resolution. However, these degradation kernels, which model the\ntransition from a high-resolution (HR) image to its LR version, should account\nfor not only the degradation process but also the downscaling factor. Applying\nthe same degradation kernel across varying super-resolution scales may be\nimpractical. Our research acknowledges degradation kernels and scaling factors\nas pivotal elements for the BSR task and introduces a novel strategy that\nutilizes HR images as references to establish scale-aware degradation kernels.\nBy employing content-irrelevant HR reference images alongside the target LR\nimage, our model adaptively discerns the degradation process. It is then\napplied to generate additional LR-HR pairs through down-sampling the HR\nreference images, which are keys to improving the SR performance. Our\nreference-based training procedure is applicable to proficiently trained blind\nSR models and zero-shot blind SR methods, consistently outperforming previous\nmethods in both scenarios. This dual consideration of blur kernels and scaling\nfactors, coupled with the use of a reference image, contributes to the\neffectiveness of our approach in blind super-resolution tasks.", "comment": "Accepted by ACCV 2024", "pdf_url": "http://arxiv.org/pdf/2507.13915v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "盲超分辨率与参考图像和隐式降级表示", "tldr": "本文提出一种新的盲超分辨率方法，利用高质量参考图像建立尺度感知的退化核，并通过生成额外的LR-HR对来提高超分辨率性能，在多种场景下均优于现有方法。", "motivation": "现有的盲超分辨率（BSR）方法主要从低分辨率输入中直接估计退化核，但这些退化核未能充分考虑下采样因子，导致在不同超分辨率尺度下应用相同的退化核不切实际。", "method": "本研究引入了一种新策略，利用高质量图像作为参考来建立尺度感知的退化核。通过使用与内容无关的高质量参考图像和目标低分辨率图像，模型自适应地识别退化过程，并通过下采样高质量参考图像生成额外的低分辨率-高质量图像对，以提高超分辨率性能。该训练程序适用于已训练的盲超分辨率模型和零样本盲超分辨率方法。", "result": "该方法在两种场景（已训练的盲超分辨率模型和零样本盲超分辨率方法）中都始终优于现有方法。", "conclusion": "通过同时考虑模糊核和缩放因子，并结合使用参考图像，本方法在盲超分辨率任务中表现出有效性。", "translation": "盲超分辨率与参考图像和隐式降级表示\n\n摘要：\n以往的盲超分辨率（BSR）研究主要集中于直接从低分辨率（LR）输入中估计退化核，以增强超分辨率。然而，这些模拟从高分辨率（HR）图像到其低分辨率版本的退化过程的退化核，不仅应考虑退化过程，还应考虑下采样因子。在不同的超分辨率尺度上应用相同的退化核可能不切实际。我们的研究承认退化核和缩放因子是BSR任务的关键要素，并引入了一种新颖的策略，利用HR图像作为参考来建立尺度感知的退化核。通过使用与内容无关的HR参考图像以及目标LR图像，我们的模型自适应地识别退化过程。然后将其应用于通过下采样HR参考图像生成额外的LR-HR对，这是提高SR性能的关键。我们的基于参考的训练程序适用于熟练训练的盲SR模型和零样本盲SR方法，在这两种情况下都始终优于以前的方法。模糊核和缩放因子的这种双重考虑，加上参考图像的使用，有助于我们方法在盲超分辨率任务中的有效性。", "summary": "本文针对现有盲超分辨率（BSR）方法在处理不同下采样因子时退化核不适用的问题，提出了一种新颖的策略。该方法利用高质量（HR）参考图像来建立尺度感知的退化核，并通过下采样这些参考图像生成额外的低分辨率-高质量（LR-HR）图像对，从而自适应地识别图像退化过程并提高超分辨率性能。实验证明，该方法在已训练和零样本BSR模型中均优于现有方法。", "keywords": "盲超分辨率, 参考图像, 退化核, 尺度感知, 图像下采样", "comments": "这项研究的创新点在于引入了高质量参考图像来学习尺度感知的退化核，并生成额外的训练数据对，有效解决了传统BSR方法在不同超分辨率尺度下退化核适用性的局限性。这种方法提高了模型对复杂退化过程的适应性，有望在实际应用中提升盲超分辨率的效果。"}}
{"id": "2507.13870", "title": "Label Unification for Cross-Dataset Generalization in Cybersecurity NER", "authors": ["Maciej Jalocha", "Johan Hausted Schmidt", "William Michelseen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      5 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13870v1", "summary": "The field of cybersecurity NER lacks standardized labels, making it\nchallenging to combine datasets. We investigate label unification across four\ncybersecurity datasets to increase data resource usability. We perform a\ncoarse-grained label unification and conduct pairwise cross-dataset evaluations\nusing BiLSTM models. Qualitative analysis of predictions reveals errors,\nlimitations, and dataset differences. To address unification limitations, we\npropose alternative architectures including a multihead model and a graph-based\ntransfer model. Results show that models trained on unified datasets generalize\npoorly across datasets. The multihead model with weight sharing provides only\nmarginal improvements over unified training, while our graph-based transfer\nmodel built on BERT-base-NER shows no significant performance gains compared\nBERT-base-NER.", "comment": "5 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13870v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "网络安全NER中跨数据集泛化的标签统一", "tldr": "网络安全NER缺乏标准化标签，导致数据集难以整合。研究发现，标签统一后的模型在跨数据集泛化能力差，提出的多头模型和图基转移模型改进不显著。", "motivation": "网络安全命名实体识别（NER）领域缺乏标准化标签，使得数据集难以结合使用，从而限制了数据资源的可用性。", "method": "对四个网络安全数据集进行粗粒度标签统一；使用BiLSTM模型进行成对的跨数据集评估；对预测结果进行定性分析以揭示错误、局限性和数据集差异；提出多头模型和基于图的迁移模型来解决统一的局限性。", "result": "在统一数据集上训练的模型在跨数据集泛化能力方面表现不佳；带权重共享的多头模型相比统一训练仅提供微小改进；基于BERT-base-NER构建的图基迁移模型与BERT-base-NER相比没有显著性能提升。", "conclusion": "标签统一对于网络安全NER的跨数据集泛化效果不佳，并且所提出的改进模型也未能显著提升性能。网络安全NER的跨数据集泛化仍然是一个挑战。", "translation": "网络安全命名实体识别（NER）领域缺乏标准化标签，这使得数据集的整合变得具有挑战性。我们研究了四个网络安全数据集之间的标签统一，以提高数据资源的可用性。我们进行了粗粒度的标签统一，并使用BiLSTM模型进行了成对的跨数据集评估。对预测结果的定性分析揭示了错误、局限性和数据集差异。为了解决统一的局限性，我们提出了替代架构，包括多头模型和基于图的迁移模型。结果显示，在统一数据集上训练的模型在跨数据集泛化能力方面表现不佳。带权重共享的多头模型相比统一训练仅提供了微小的改进，而我们基于BERT-base-NER构建的图基迁移模型与BERT-base-NER相比没有显著的性能提升。", "summary": "本文研究了网络安全NER中因缺乏标准化标签而导致的数据集整合难题。作者对四个数据集进行了粗粒度标签统一，并使用BiLSTM模型进行跨数据集评估。结果表明，统一后的数据集训练的模型在跨数据集泛化能力上表现不佳。为了解决这一问题，论文提出了多头模型和图基迁移模型，但实验结果显示这些模型相对于基线模型或统一训练模型，性能提升不显著。", "keywords": "网络安全NER, 标签统一, 跨数据集泛化, 多头模型, 图基迁移模型", "comments": "这篇论文揭示了网络安全NER领域中标签标准化和跨数据集泛化的重要挑战。尽管尝试了标签统一和几种先进的模型架构，但结果表明，简单的标签统一并不能有效提升跨数据集泛化能力，且提出的新模型改进有限。这强调了该领域在数据整合和模型泛化方面的复杂性，可能需要更深层次的语义对齐或更鲁棒的迁移学习方法。"}}
{"id": "2507.13368", "title": "Scalable Attribute-Missing Graph Clustering via Neighborhood Differentiatio", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Xinhang Wan", "Junyi Yan", "Taichun Zhou", "Xinwang Liu"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13368v1", "summary": "Deep graph clustering (DGC), which aims to unsupervisedly separate the nodes\nin an attribute graph into different clusters, has seen substantial potential\nin various industrial scenarios like community detection and recommendation.\nHowever, the real-world attribute graphs, e.g., social networks interactions,\nare usually large-scale and attribute-missing. To solve these two problems, we\npropose a novel DGC method termed \\underline{\\textbf{C}}omplementary\n\\underline{\\textbf{M}}ulti-\\underline{\\textbf{V}}iew\n\\underline{\\textbf{N}}eighborhood \\underline{\\textbf{D}}ifferentiation\n(\\textit{CMV-ND}), which preprocesses graph structural information into\nmultiple views in a complete but non-redundant manner. First, to ensure\ncompleteness of the structural information, we propose a recursive neighborhood\nsearch that recursively explores the local structure of the graph by completely\nexpanding node neighborhoods across different hop distances. Second, to\neliminate the redundancy between neighborhoods at different hops, we introduce\na neighborhood differential strategy that ensures no overlapping nodes between\nthe differential hop representations. Then, we construct $K+1$ complementary\nviews from the $K$ differential hop representations and the features of the\ntarget node. Last, we apply existing multi-view clustering or DGC methods to\nthe views. Experimental results on six widely used graph datasets demonstrate\nthat CMV-ND significantly improves the performance of various methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13368v1", "cate": "cs.SI", "date": "2025-07-09", "updated": "2025-07-09", "AI": {"title_translation": "通过邻域分化实现可扩展的属性缺失图聚类", "tldr": "本文提出了一种名为CMV-ND的新型深度图聚类（DGC）方法，旨在解决现有DGC方法在处理大规模和属性缺失图时的挑战。CMV-ND通过递归邻域搜索和邻域分化策略生成互补的多视图，显著提升了各种DGC方法的性能。", "motivation": "深度图聚类（DGC）在社区检测和推荐等工业场景中具有巨大潜力。然而，现实世界中的属性图通常规模庞大且存在属性缺失问题，这限制了现有DGC方法的应用。", "method": "本文提出了一种名为互补多视图邻域分化（CMV-ND）的新型DGC方法。首先，为了确保结构信息的完整性，提出了一种递归邻域搜索方法，通过完全扩展不同跳距的节点邻域来递归探索图的局部结构。其次，为了消除不同跳距邻域之间的冗余，引入了邻域分化策略，确保差异化跳距表示之间没有重叠节点。然后，从K个差异化跳距表示和目标节点的特征构建K+1个互补视图。最后，将现有的多视图聚类或DGC方法应用于这些视图。", "result": "在六个广泛使用的图数据集上的实验结果表明，CMV-ND显著提高了各种DGC方法的性能。", "conclusion": "CMV-ND通过有效处理大规模和属性缺失的图数据，为深度图聚类提供了一种可扩展且性能优越的解决方案，通过生成完整且非冗余的多视图信息，显著提升了现有方法的聚类效果。", "translation": "深度图聚类（DGC）旨在无监督地将属性图中的节点分离成不同的簇，在社区检测和推荐等各种工业场景中展现出巨大的潜力。然而，现实世界中的属性图，例如社交网络交互，通常规模庞大且属性缺失。为了解决这两个问题，我们提出了一种新颖的DGC方法，名为互补多视图邻域分化（CMV-ND），它以完整但非冗余的方式将图结构信息预处理为多个视图。首先，为了确保结构信息的完整性，我们提出了一种递归邻域搜索，通过完全扩展不同跳距的节点邻域来递归探索图的局部结构。其次，为了消除不同跳距邻域之间的冗余，我们引入了一种邻域分化策略，确保差异化跳距表示之间没有重叠节点。然后，我们从K个差异化跳距表示和目标节点的特征构建K+1个互补视图。最后，我们将现有的多视图聚类或DGC方法应用于这些视图。在六个广泛使用的图数据集上的实验结果表明，CMV-ND显著提高了各种方法的性能。", "summary": "本文提出了一种名为互补多视图邻域分化（CMV-ND）的新型深度图聚类（DGC）方法，旨在解决大规模和属性缺失图的聚类问题。CMV-ND通过递归邻域搜索确保结构信息的完整性，并引入邻域分化策略消除冗余，从而构建互补的多视图。这些视图随后可用于现有DGC方法，实验证明CMV-ND能显著提升多种方法的性能。", "keywords": "图聚类, 属性缺失, 多视图, 邻域分化, 深度图聚类", "comments": "CMV-ND的创新点在于其独特的邻域处理策略，即递归邻域搜索和邻域分化。这使得它能够有效地处理大规模和属性缺失的图数据，同时生成完整且非冗余的多视图表示，为后续的DGC方法提供了高质量的输入。这种预处理方法对于提高现有DGC算法的性能具有重要意义。"}}
{"id": "2507.13604", "title": "BreastSegNet: Multi-label Segmentation of Breast MRI", "authors": ["Qihang Li", "Jichen Yang", "Yaqian Chen", "Yuwen Chen", "Hanxue Gu", "Lars J. Grimm", "Maciej A. Mazurowski"], "categories": ["eess.IV", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13604v1", "summary": "Breast MRI provides high-resolution imaging critical for breast cancer\nscreening and preoperative staging. However, existing segmentation methods for\nbreast MRI remain limited in scope, often focusing on only a few anatomical\nstructures, such as fibroglandular tissue or tumors, and do not cover the full\nrange of tissues seen in scans. This narrows their utility for quantitative\nanalysis. In this study, we present BreastSegNet, a multi-label segmentation\nalgorithm for breast MRI that covers nine anatomical labels: fibroglandular\ntissue (FGT), vessel, muscle, bone, lesion, lymph node, heart, liver, and\nimplant. We manually annotated a large set of 1123 MRI slices capturing these\nstructures with detailed review and correction from an expert radiologist.\nAdditionally, we benchmark nine segmentation models, including U-Net, SwinUNet,\nUNet++, SAM, MedSAM, and nnU-Net with multiple ResNet-based encoders. Among\nthem, nnU-Net ResEncM achieves the highest average Dice scores of 0.694 across\nall labels. It performs especially well on heart, liver, muscle, FGT, and bone,\nwith Dice scores exceeding 0.73, and approaching 0.90 for heart and liver. All\nmodel code and weights are publicly available, and we plan to release the data\nat a later date.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13604v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "乳腺SegNet：乳腺MRI多标签分割", "tldr": "本研究提出了BreastSegNet，一种用于乳腺MRI的多标签分割算法，旨在解决现有方法分割范围有限的问题，并基准测试了多种模型，发现nnU-Net ResEncM表现最佳。", "motivation": "现有的乳腺MRI分割方法范围有限，通常只关注少数解剖结构（如纤维腺体组织或肿瘤），未能涵盖扫描中见到的所有组织，这限制了它们在定量分析中的效用。", "method": "提出了BreastSegNet，一种用于乳腺MRI的多标签分割算法，能够分割九种解剖结构（纤维腺体组织、血管、肌肉、骨骼、病变、淋巴结、心脏、肝脏和植入物）。手动标注了1123张MRI切片数据，并由专家放射科医生进行详细审查和校正。基准测试了九种分割模型，包括U-Net、SwinUNet、UNet++、SAM、MedSAM和nnU-Net（带多个ResNet编码器）。", "result": "nnU-Net ResEncM在所有标签上的平均Dice分数最高，达到0.694。它在心脏、肝脏、肌肉、FGT和骨骼上的表现尤为出色，Dice分数超过0.73，心脏和肝脏接近0.90。所有模型代码和权重均已公开。", "conclusion": "本研究提出的BreastSegNet及其数据集为乳腺MRI的多标签分割提供了全面的解决方案，nnU-Net ResEncM被证明是针对九种解剖结构进行分割的最佳模型，为乳腺MRI的定量分析提供了更广泛的工具，并促进了社区的进一步研究。", "translation": "乳腺MRI提供高分辨率成像，对于乳腺癌筛查和术前分期至关重要。然而，现有的乳腺MRI分割方法范围有限，通常只关注少数解剖结构，如纤维腺体组织或肿瘤，未能涵盖扫描中见到的所有组织，这限制了它们在定量分析中的效用。在本研究中，我们提出了BreastSegNet，一种用于乳腺MRI的多标签分割算法，涵盖九种解剖标签：纤维腺体组织（FGT）、血管、肌肉、骨骼、病变、淋巴结、心脏、肝脏和植入物。我们手动标注了1123张捕捉这些结构的MRI切片，并经过放射科专家的详细审查和校正。此外，我们基准测试了九种分割模型，包括U-Net、SwinUNet、UNet++、SAM、MedSAM和nnU-Net（带多个基于ResNet的编码器）。其中，nnU-Net ResEncM在所有标签上的平均Dice分数最高，达到0.694。它在心脏、肝脏、肌肉、FGT和骨骼上的表现尤为出色，Dice分数超过0.73，心脏和肝脏接近0.90。所有模型代码和权重均已公开，我们计划稍后发布数据。", "summary": "本研究提出BreastSegNet，一种针对乳腺MRI的多标签分割算法，旨在解决现有方法分割范围有限的问题。该算法能够分割乳腺MRI中的九种解剖结构，并基于专家标注的1123张MRI切片数据集进行了训练。通过对九种主流分割模型进行基准测试，结果显示nnU-Net ResEncM在所有标签上取得了最佳平均Dice分数（0.694），尤其在心脏和肝脏等结构上表现优异。研究还公开了模型代码和权重，并计划稍后发布数据。", "keywords": "乳腺MRI, 多标签分割, BreastSegNet, nnU-Net, 解剖结构", "comments": "该研究通过提出一个涵盖九种解剖结构的多标签分割算法，显著扩展了乳腺MRI分割的范围，解决了现有方法覆盖不足的局限性。其创新之处在于构建了大规模、专家校正的多标签数据集，并对多种先进分割模型进行了全面基准测试，为乳腺MRI的定量分析提供了更全面的工具。开源代码和权重也促进了该领域的进一步研究。"}}
{"id": "2507.14044", "title": "TGIF: Talker Group-Informed Familiarization of Target Speaker Extraction", "authors": ["Tsun-An Hsieh", "Minje Kim"], "categories": ["eess.AS"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14044v1", "summary": "State-of-the-art target speaker extraction (TSE) systems are typically\ndesigned to generalize to any given mixing environment, necessitating a model\nwith a large enough capacity as a generalist. Personalized speech enhancement\ncould be a specialized solution that adapts to single-user scenarios, but it\noverlooks the practical need for customization in cases where only a small\nnumber of talkers are involved, e.g., TSE for a specific family. We address\nthis gap with the proposed concept, talker group-informed familiarization\n(TGIF) of TSE, where the TSE system specializes in a particular group of users,\nwhich is challenging due to the inherent absence of a clean speech target. To\nthis end, we employ a knowledge distillation approach, where a group-specific\nstudent model learns from the pseudo-clean targets generated by a large teacher\nmodel. This tailors the student model to effectively extract the target speaker\nfrom the particular talker group while maintaining computational efficiency.\nExperimental results demonstrate that our approach outperforms the baseline\ngeneric models by adapting to the unique speech characteristics of a given\nspeaker group. Our newly proposed TGIF concept underscores the potential of\ndeveloping specialized solutions for diverse and real-world applications, such\nas on-device TSE on a family-owned device.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14044v1", "cate": "eess.AS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "TGIF：说话人群体信息辅助目标说话人提取的熟悉化", "tldr": "提出TGIF概念，通过知识蒸馏使目标说话人提取系统适应特定说话人群体，提高效率和性能。", "motivation": "现有的目标说话人提取（TSE）系统是通用型设计，容量大但对特定小群体场景效率不高；个性化语音增强虽然针对单用户，但忽略了小说话人群体（如家庭）的定制化需求。", "method": "提出“说话人群体信息辅助熟悉化（TGIF）”概念。通过知识蒸馏方法，让一个特定群体的学生模型从大型教师模型生成的伪干净目标中学习，从而使学生模型能够有效地从特定说话人群体中提取目标说话人，同时保持计算效率。", "result": "实验结果表明，该方法通过适应给定说话人群体的独特语音特征，优于基线通用模型。", "conclusion": "新提出的TGIF概念强调了为多样化和真实世界应用（如家庭设备上的设备端TSE）开发专业化解决方案的潜力。", "translation": "最先进的目标说话人提取（TSE）系统通常设计为适用于任何给定的混合环境，这需要一个具有足够容量的通用模型。个性化语音增强可能是一种适应单用户场景的专业解决方案，但它忽视了在只涉及少量说话人的情况下（例如，针对特定家庭的TSE）对定制化的实际需求。我们通过提出的概念——TSE的说话人群体信息辅助熟悉化（TGIF）来解决这一空白，其中TSE系统专门针对特定的用户群体，这由于固有的干净语音目标缺失而具有挑战性。为此，我们采用知识蒸馏方法，其中一个特定群体的学生模型从大型教师模型生成的伪干净目标中学习。这使得学生模型能够有效地从特定说话人群体中提取目标说话人，同时保持计算效率。实验结果表明，我们的方法通过适应给定说话人群体的独特语音特征，优于基线通用模型。我们新提出的TGIF概念强调了为多样化和真实世界应用（例如家庭设备上的设备端TSE）开发专业化解决方案的潜力。", "summary": "本文提出“说话人群体信息辅助熟悉化（TGIF）”概念，旨在解决目标说话人提取（TSE）系统在特定小群体场景下效率不高的问题。通过知识蒸馏，一个轻量级的学生模型从大型教师模型生成的伪干净语音中学习，使其能高效地从特定说话人群体中提取目标说话人。实验证明，该方法性能优于通用模型，为设备端TSE等应用提供了专业化解决方案。", "keywords": "目标说话人提取, 知识蒸馏, 说话人群体, 语音增强, 个性化", "comments": "TGIF概念具有创新性，它填补了通用TSE与单用户个性化之间的空白，为特定小群体场景提供了定制化解决方案。通过知识蒸馏，实现了计算效率和性能的平衡，这对于资源受限的设备端应用尤其重要。该研究为未来开发更专业、更实用的语音处理系统提供了新的思路。"}}
{"id": "2507.12871", "title": "Generative Multi-Target Cross-Domain Recommendation", "authors": ["Jinqiu Jin", "Yang Zhang", "Junwei Pan", "Fuli Feng", "Hua Lu", "Lei Xiao", "Haijie Gu", "Xiangnan He"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      fix author information", "url": "http://arxiv.org/abs/2507.12871v2", "summary": "Recently, there has been a surge of interest in Multi-Target Cross-Domain\nRecommendation (MTCDR), which aims to enhance recommendation performance across\nmultiple domains simultaneously. Existing MTCDR methods primarily rely on\ndomain-shared entities (\\eg users or items) to fuse and transfer cross-domain\nknowledge, which may be unavailable in non-overlapped recommendation scenarios.\nSome studies model user preferences and item features as domain-sharable\nsemantic representations, which can be utilized to tackle the MTCDR task.\nNevertheless, they often require extensive auxiliary data for pre-training.\nDeveloping more effective solutions for MTCDR remains an important area for\nfurther exploration.\n  Inspired by recent advancements in generative recommendation, this paper\nintroduces GMC, a generative paradigm-based approach for multi-target\ncross-domain recommendation. The core idea of GMC is to leverage semantically\nquantized discrete item identifiers as a medium for integrating multi-domain\nknowledge within a unified generative model. GMC first employs an item\ntokenizer to generate domain-shared semantic identifiers for each item, and\nthen formulates item recommendation as a next-token generation task by training\na domain-unified sequence-to-sequence model. To further leverage the domain\ninformation to enhance performance, we incorporate a domain-aware contrastive\nloss into the semantic identifier learning, and perform domain-specific\nfine-tuning on the unified recommender. Extensive experiments on five public\ndatasets demonstrate the effectiveness of GMC compared to a range of baseline\nmethods.", "comment": "fix author information", "pdf_url": "http://arxiv.org/pdf/2507.12871v2", "cate": "cs.IR", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "生成式多目标跨域推荐", "tldr": "本文提出了一种名为GMC的生成式范式方法，用于解决多目标跨域推荐中现有方法对共享实体或大量辅助数据的依赖问题，通过语义量化离散物品标识符和统一生成模型实现了有效推荐。", "motivation": "现有的多目标跨域推荐（MTCDR）方法主要依赖于领域共享实体（在非重叠场景中可能不可用）或需要大量的辅助数据进行预训练，因此需要开发更有效的MTCDR解决方案。", "method": "本文提出了GMC，一种基于生成范式的多目标跨域推荐方法。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多领域知识。GMC首先使用物品分词器为每个物品生成领域共享的语义标识符，然后通过训练一个领域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用领域信息增强性能，GMC在语义标识符学习中融入了领域感知对比损失，并对统一推荐器进行了领域特定的微调。", "result": "在五个公共数据集上进行的广泛实验表明，与一系列基线方法相比，GMC是有效的。", "conclusion": "本文提出的GMC，一种基于生成范式的多目标跨域推荐方法，在实验中证明了其有效性。", "translation": "最近，多目标跨域推荐（MTCDR）引起了广泛关注，旨在同时提升多个领域的推荐性能。现有的MTCDR方法主要依赖于领域共享实体（例如用户或物品）来融合和转移跨域知识，这在非重叠推荐场景中可能不可用。一些研究将用户偏好和物品特征建模为领域可共享的语义表示，可用于解决MTCDR任务。然而，它们通常需要大量的辅助数据进行预训练。为MTCDR开发更有效的解决方案仍然是需要进一步探索的重要领域。\n受生成式推荐最新进展的启发，本文引入了GMC，一种基于生成范式的方法，用于多目标跨域推荐。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在统一的生成模型中整合多领域知识。GMC首先采用物品分词器为每个物品生成领域共享的语义标识符，然后通过训练一个领域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用领域信息增强性能，我们在语义标识符学习中融入了领域感知对比损失，并对统一推荐器进行了领域特定的微调。在五个公共数据集上进行的广泛实验表明，与一系列基线方法相比，GMC是有效的。", "summary": "本文针对多目标跨域推荐（MTCDR）中现有方法依赖共享实体或大量辅助数据的局限性，提出了一种名为GMC的生成式范式方法。GMC通过利用语义量化的离散物品标识符作为多领域知识整合的媒介，并训练一个统一的序列到序列模型将推荐任务转化为令牌生成。此外，GMC还引入了领域感知对比损失和领域特定微调来增强性能。在五个公共数据集上的实验验证了GMC的有效性。", "keywords": "多目标跨域推荐, 生成式模型, 语义标识符, 序列到序列模型, 对比学习", "comments": "本文创新性地将生成范式引入多目标跨域推荐领域，通过语义量化离散物品标识符解决了现有方法对共享实体或大量辅助数据的依赖问题。其提出的领域感知对比损失和领域特定微调进一步提升了模型的性能，为MTCDR任务提供了一个新颖且有效的解决方案。"}}
{"id": "2507.14061", "title": "MorphIt: Flexible Spherical Approximation of Robot Morphology for Representation-driven Adaptation", "authors": ["Nataliya Nechyporenko", "Yutong Zhang", "Sean Campbell", "Alessandro Roncone"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14061v1", "summary": "What if a robot could rethink its own morphological representation to better\nmeet the demands of diverse tasks? Most robotic systems today treat their\nphysical form as a fixed constraint rather than an adaptive resource, forcing\nthe same rigid geometric representation to serve applications with vastly\ndifferent computational and precision requirements. We introduce MorphIt, a\nnovel algorithm for approximating robot morphology using spherical primitives\nthat balances geometric accuracy with computational efficiency. Unlike existing\napproaches that rely on either labor-intensive manual specification or\ninflexible computational methods, MorphIt implements an automatic\ngradient-based optimization framework with tunable parameters that provides\nexplicit control over the physical fidelity versus computational cost tradeoff.\nQuantitative evaluations demonstrate that MorphIt outperforms baseline\napproaches (Variational Sphere Set Approximation and Adaptive Medial-Axis\nApproximation) across multiple metrics, achieving better mesh approximation\nwith fewer spheres and reduced computational overhead. Our experiments show\nenhanced robot capabilities in collision detection accuracy, contact-rich\ninteraction simulation, and navigation through confined spaces. By dynamically\nadapting geometric representations to task requirements, robots can now exploit\ntheir physical embodiment as an active resource rather than an inflexible\nparameter, opening new frontiers for manipulation in environments where\nphysical form must continuously balance precision with computational\ntractability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14061v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MorphIt: 机器人形态的柔性球体近似以实现基于表示的自适应", "tldr": "MorphIt是一种新的算法，通过可调参数的球体近似来优化机器人形态表示，以平衡几何精度和计算效率，并在碰撞检测、交互模拟和导航方面表现出色。", "motivation": "现有机器人系统将物理形态视为固定约束，而非自适应资源，导致僵硬的几何表示难以满足不同任务的计算和精度需求。", "method": "引入MorphIt，一种使用球形基元近似机器人形态的新算法。它通过自动梯度优化框架实现，具有可调参数，可以平衡物理保真度和计算成本。", "result": "MorphIt在多个指标上优于基线方法（变分球集近似和自适应中轴近似），使用更少的球体实现了更好的网格近似和更低的计算开销。实验表明，MorphIt增强了机器人在碰撞检测精度、接触密集型交互模拟和狭窄空间导航方面的能力。", "conclusion": "通过动态调整几何表示以适应任务需求，机器人可以将其物理形态作为主动资源而非僵硬参数，为在需要平衡精度和计算可行性的环境中进行操作开辟了新领域。", "translation": "机器人能否重新思考自身的形态表示，以更好地满足多样化任务的需求？当今大多数机器人系统将它们的物理形态视为一个固定的约束，而非一个自适应的资源，这迫使相同的刚性几何表示服务于具有截然不同计算和精度要求的应用。我们引入了MorphIt，一种新颖的算法，利用球形基元来近似机器人形态，从而平衡几何精度与计算效率。与现有依赖劳动密集型手动规范或不灵活计算方法的方法不同，MorphIt实现了一个自动的、基于梯度的优化框架，该框架具有可调参数，可以明确控制物理保真度与计算成本之间的权衡。定量评估表明，MorphIt在多个指标上优于基线方法（变分球体集近似和自适应中轴近似），使用更少的球体实现了更好的网格近似并降低了计算开销。我们的实验显示，机器人能力在碰撞检测精度、富接触交互模拟以及在狭窄空间导航方面得到了增强。通过动态调整几何表示以适应任务要求，机器人现在可以将其物理实体作为一种主动资源而非僵硬参数加以利用，为在物理形态必须持续平衡精度与计算可行性的环境中进行操作开辟了新领域。", "summary": "MorphIt是一种新颖的算法，通过可调参数的球形近似来优化机器人形态表示，旨在平衡几何精度和计算效率。它采用自动梯度优化框架，解决了现有方法在手动指定或计算灵活性方面的不足。实验证明，MorphIt在网格近似、计算效率、碰撞检测、交互模拟和狭窄空间导航方面优于现有基线方法，使得机器人能够根据任务需求动态调整其物理形态表示，从而将其物理实体作为自适应资源利用。", "keywords": "机器人形态, 球体近似, 自适应表示, 梯度优化, 计算效率", "comments": "MorphIt的创新之处在于其自动化的、基于梯度的优化框架，能够灵活地平衡机器人形态表示的几何精度和计算效率。这使得机器人能够将自身物理形态视为可适应资源，而非固定约束，对于提升机器人在复杂环境中的表现具有重要意义，尤其是在需要动态调整表示以适应不同任务的应用中。"}}
{"id": "2507.13765", "title": "Dual-Center Graph Clustering with Neighbor Distribution", "authors": ["Enhao Cheng", "Shoujia Zhang", "Jianhua Yin", "Li Jin", "Liqiang Nie"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      ECAI-2025", "url": "http://arxiv.org/abs/2507.13765v1", "summary": "Graph clustering is crucial for unraveling intricate data structures, yet it\npresents significant challenges due to its unsupervised nature. Recently,\ngoal-directed clustering techniques have yielded impressive results, with\ncontrastive learning methods leveraging pseudo-label garnering considerable\nattention. Nonetheless, pseudo-label as a supervision signal is unreliable and\nexisting goal-directed approaches utilize only features to construct a\nsingle-target distribution for single-center optimization, which lead to\nincomplete and less dependable guidance. In our work, we propose a novel\nDual-Center Graph Clustering (DCGC) approach based on neighbor distribution\nproperties, which includes representation learning with neighbor distribution\nand dual-center optimization. Specifically, we utilize neighbor distribution as\na supervision signal to mine hard negative samples in contrastive learning,\nwhich is reliable and enhances the effectiveness of representation learning.\nFurthermore, neighbor distribution center is introduced alongside feature\ncenter to jointly construct a dual-target distribution for dual-center\noptimization. Extensive experiments and analysis demonstrate superior\nperformance and effectiveness of our proposed method.", "comment": "ECAI-2025", "pdf_url": "http://arxiv.org/pdf/2507.13765v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "双中心图聚类与邻居分布", "tldr": "本文提出了一种新颖的双中心图聚类（DCGC）方法，通过利用邻居分布作为可靠的监督信号来增强对比学习中的表示学习，并结合特征中心和邻居分布中心进行双中心优化，有效解决了现有方法中伪标签不可靠和指导不完整的问题，并取得了优越的性能。", "motivation": "图聚类对于揭示复杂数据结构至关重要，但其无监督性质带来了挑战。现有目标导向的聚类技术（特别是利用伪标签的对比学习方法）虽然取得了进展，但伪标签作为监督信号并不可靠。此外，现有方法仅利用特征构建单目标分布进行单中心优化，导致指导不完整且不可靠。", "method": "本文提出了一种新颖的基于邻居分布特性的双中心图聚类（DCGC）方法。该方法包含两部分：1) 基于邻居分布的表示学习：利用邻居分布作为可靠的监督信号，在对比学习中挖掘困难负样本，从而提高表示学习的有效性。2) 双中心优化：在特征中心的基础上引入邻居分布中心，共同构建双目标分布以进行双中心优化。", "result": "广泛的实验和分析表明，所提出的方法具有优越的性能和有效性。", "conclusion": "该研究通过引入邻居分布作为可靠的监督信号和双中心优化机制，有效地解决了传统图聚类中伪标签不可靠和指导不完整的问题，显著提升了图聚类的性能和可靠性。", "translation": "图聚类对于揭示复杂数据结构至关重要，但由于其无监督性质，带来了巨大的挑战。最近，目标导向的聚类技术取得了令人印象深刻的成果，其中利用伪标签的对比学习方法受到了广泛关注。然而，伪标签作为监督信号并不可靠，并且现有的目标导向方法仅利用特征来构建单目标分布进行单中心优化，这导致指导不完整且不可靠。在我们的工作中，我们提出了一种基于邻居分布特性的新型双中心图聚类（DCGC）方法，该方法包括基于邻居分布的表示学习和双中心优化。具体而言，我们利用邻居分布作为监督信号，在对比学习中挖掘困难负样本，这既可靠又增强了表示学习的有效性。此外，邻居分布中心与特征中心一同被引入，共同构建双目标分布以进行双中心优化。广泛的实验和分析证明了我们所提出方法的优越性能和有效性。", "summary": "本文提出了一种新颖的双中心图聚类（DCGC）方法，旨在解决传统图聚类中伪标签不可靠和单中心优化导致指导不完整的问题。DCGC 利用邻居分布作为可靠的监督信号来增强对比学习中的表示学习，并通过结合特征中心和邻居分布中心进行双中心优化，共同构建双目标分布。实验结果表明，该方法在图聚类任务上表现出优越的性能和有效性。", "keywords": "图聚类, 双中心聚类, 邻居分布, 对比学习, 无监督学习", "comments": "该论文的创新点在于引入了“邻居分布”作为图聚类中对比学习的可靠监督信号，并进一步提出了“双中心优化”机制，结合了特征中心和邻居分布中心。这种方法有效地解决了现有方法中伪标签不可靠和单中心优化导致指导不完整的问题，为无监督图聚类提供了一种更鲁棒和有效的解决方案。"}}
{"id": "2404.07053", "title": "Meta4XNLI: A Crosslingual Parallel Corpus for Metaphor Detection and Interpretation", "authors": ["Elisa Sanchez-Bayona", "Rodrigo Agerri"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2404.07053v2", "summary": "Metaphors, although occasionally unperceived, are ubiquitous in our everyday\nlanguage. Thus, it is crucial for Language Models to be able to grasp the\nunderlying meaning of this kind of figurative language. In this work, we\npresent Meta4XNLI, a novel parallel dataset for the tasks of metaphor detection\nand interpretation that contains metaphor annotations in both Spanish and\nEnglish. We investigate language models' metaphor identification and\nunderstanding abilities through a series of monolingual and cross-lingual\nexperiments by leveraging our proposed corpus. In order to comprehend how these\nnon-literal expressions affect models' performance, we look over the results\nand perform an error analysis. Additionally, parallel data offers many\npotential opportunities to investigate metaphor transferability between these\nlanguages and the impact of translation on the development of multilingual\nannotated resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2404.07053v2", "cate": "cs.CL", "date": "2024-04-10", "updated": "2025-07-18", "AI": {"title_translation": "Meta4XNLI：一个用于隐喻检测和解释的跨语言并行语料库", "tldr": "提出了Meta4XNLI，一个用于隐喻检测和解释的西英双语并行语料库，并用其评估了语言模型的隐喻能力。", "motivation": "隐喻在日常语言中无处不在，语言模型理解其深层含义至关重要。", "method": "提出了Meta4XNLI，一个包含西班牙语和英语隐喻标注的并行数据集。利用该语料库，通过单语和跨语言实验研究语言模型的隐喻识别和理解能力，并进行了误差分析。", "result": "通过单语和跨语言实验调查了语言模型识别和理解隐喻的能力，并进行了误差分析以理解非字面表达如何影响模型性能。", "conclusion": "并行数据为研究隐喻在语言间的可迁移性以及翻译对多语言标注资源开发的影响提供了潜在机会。", "translation": "隐喻，尽管有时未被察觉，但在我们的日常语言中无处不在。因此，语言模型能够掌握这种比喻性语言的深层含义至关重要。在这项工作中，我们提出了Meta4XNLI，一个用于隐喻检测和解释任务的新型并行数据集，其中包含西班牙语和英语的隐喻标注。我们利用我们提出的语料库，通过一系列单语和跨语言实验，研究了语言模型的隐喻识别和理解能力。为了理解这些非字面表达如何影响模型的性能，我们审查了结果并进行了错误分析。此外，并行数据为研究这些语言之间的隐喻可迁移性以及翻译对多语言标注资源开发的影响提供了许多潜在机会。", "summary": "本文介绍了Meta4XNLI，一个包含西班牙语和英语隐喻标注的跨语言并行语料库，旨在促进语言模型在隐喻检测和解释方面的研究。作者利用该语料库进行单语和跨语言实验，评估了语言模型理解隐喻的能力，并分析了非字面表达对模型性能的影响。该数据集还为探索隐喻的跨语言可迁移性提供了基础。", "keywords": "隐喻检测, 隐喻解释, 跨语言, 并行语料库, 语言模型", "comments": "该论文的创新之处在于构建了一个西英双语的并行隐喻标注语料库Meta4XNLI，这对于跨语言隐喻研究和多语言模型训练具有重要意义。通过单语和跨语言实验以及错误分析，为理解语言模型处理比喻性语言的能力提供了见解。"}}
{"id": "2507.14000", "title": "Photonic Fabric Platform for AI Accelerators", "authors": ["Jing Ding", "Trung Diep"], "categories": ["cs.PF", "cs.AI", "C.4"], "primary_category": "Subjects:       Performance (cs.PF)", "pdf_link": null, "comments": "Comments:      12 pages, 14 figures, 5 tables", "url": "http://arxiv.org/abs/2507.14000v1", "summary": "This paper presents the Photonic FabricTM and the Photonic Fabric ApplianceTM\n(PFA), a photonic-enabled switch and memory subsystem that delivers low\nlatency, high bandwidth, and low per-bit energy. By integrating high-bandwidth\nHBM3E memory, an on-module photonic switch, and external DDR5 in a 2.5D\nelectro-optical system-in-package, the PFA offers up to 32 TB of shared memory\nalongside 115 Tbps of all-to-all digital switching. The Photonic FabricTM\nenables distributed AI training and inference to execute parallelism strategies\nmore efficiently. The Photonic Fabric removes the silicon beachfront constraint\nthat limits the fixed memory-to-compute ratio observed in virtually all current\nXPU accelerator designs. Replacing a local HBM stack on an XPU with a chiplet\nthat connects to the Photonic Fabric increases its memory capacity and\ncorrespondingly its memory bandwidth by offering a flexible path to scaling\nwell beyond the limitations of on-package HBM alone. We introduce CelestiSim, a\nlightweight analytical simulator validated on NVIDIA H100 and H200 systems. It\nis used to evaluate the performance of LLM reference and energy savings on PFA,\nwithout any significant change to the GPU core design. With the PFA, the\nsimulation results show that up to 3.66x throughput and 1.40x latency\nimprovements in LLM inference at 405B parameters, up to 7.04x throughput and\n1.41x latency improvements at 1T parameters, and 60-90% energy savings in data\nmovement for heavy collective operations in all LLM training scenarios. While\nthese results are shown for NVIDIA GPUs, they can be applied similarly to other\nAI accelerator designs (XPUs) that share the same fundamental limitation of\nfixed memory to compute.", "comment": "12 pages, 14 figures, 5 tables", "pdf_url": "http://arxiv.org/pdf/2507.14000v1", "cate": "cs.PF", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "适用于AI加速器的光子织物平台", "tldr": "本文提出Photonic FabricTM和Photonic Fabric ApplianceTM (PFA)，这是一种光子使能的交换和内存子系统，旨在解决AI加速器中固定的内存与计算比限制，通过提供大规模共享内存和高带宽交换，显著提升大型语言模型（LLM）的性能和能效。", "motivation": "现有AI加速器（XPU）受限于固定的内存与计算比（“硅滩限制”），导致内存容量和带宽受限，无法有效支持分布式AI训练和推理中日益增长的数据需求和并行策略，从而影响效率和性能。", "method": "本文提出Photonic FabricTM和Photonic Fabric ApplianceTM (PFA)，这是一种光子使能的交换和内存子系统。它通过在2.5D电光系统级封装中集成高带宽HBM3E内存、片上光子交换机和外部DDR5，提供低延迟、高带宽、低单位比特能耗的共享内存和全对全数字交换。该平台通过用连接到Photonic Fabric的小芯片替换XPU上的本地HBM堆栈，来增加内存容量和带宽。研究引入了CelestiSim，一个轻量级分析模拟器，并在NVIDIA H100和H200系统上进行了验证，用于评估PFA对LLM性能和能耗的影响。", "result": "仿真结果显示：在405B参数的LLM推理中，吞吐量提高高达3.66倍，延迟改善1.40倍；在1T参数的LLM推理中，吞吐量提高高达7.04倍，延迟改善1.41倍。在所有LLM训练场景中，重度集合操作的数据移动能耗节省60-90%。这些改进是在不显著改变GPU核心设计的情况下实现的。", "conclusion": "Photonic Fabric平台通过提供灵活的内存扩展路径，有效解决了AI加速器中固定的内存与计算比限制，显著提升了大型语言模型（LLM）的训练和推理性能及能效，并且该方法可推广至其他AI加速器设计，具有普适性。", "translation": "本文介绍了Photonic FabricTM和Photonic Fabric ApplianceTM (PFA)，这是一种光子使能的交换和内存子系统，可提供低延迟、高带宽和低单位比特能耗。通过在2.5D电光系统级封装中集成高带宽HBM3E内存、片上光子交换机和外部DDR5，PFA提供高达32 TB的共享内存以及115 Tbps的全对全数字交换能力。Photonic FabricTM使分布式AI训练和推理能够更有效地执行并行策略。Photonic Fabric消除了几乎所有当前XPU加速器设计中存在的固定内存与计算比的“硅滩限制”。用连接到Photonic Fabric的小芯片替换XPU上的本地HBM堆栈，可以增加其内存容量并相应地增加内存带宽，从而提供一种灵活的扩展路径，远超片上HBM本身的限制。我们引入了CelestiSim，一个轻量级分析模拟器，已在NVIDIA H100和H200系统上验证。它用于评估PFA上LLM参考性能和能耗节省，而无需对GPU核心设计进行任何重大更改。PFA的仿真结果显示，在405B参数的LLM推理中，吞吐量提高高达3.66倍，延迟改善1.40倍；在1T参数的LLM推理中，吞吐量提高高达7.04倍，延迟改善1.41倍；在所有LLM训练场景中，重度集合操作的数据移动能耗节省60-90%。虽然这些结果是针对NVIDIA GPU显示的，但它们同样适用于其他具有相同固定内存与计算限制的AI加速器设计（XPU）。", "summary": "本文提出Photonic FabricTM和Photonic Fabric ApplianceTM (PFA)，这是一种创新的光子交换和内存子系统，旨在克服AI加速器中固定的内存与计算比限制。PFA通过集成HBM3E、光子交换机和DDR5，提供高达32TB共享内存和115Tbps交换带宽，实现低延迟、高带宽和低能耗。研究引入CelestiSim模拟器，验证PFA在大型语言模型（LLM）上的性能。仿真结果表明，PFA能显著提升LLM推理吞吐量（最高7.04倍）和延迟（最高1.41倍），并在训练中实现60-90%的数据移动能耗节省，且无需修改GPU核心设计。该平台为AI加速器提供了灵活的内存扩展能力。", "keywords": "光子织物, AI加速器, 共享内存, 大语言模型, 低延迟", "comments": "这篇论文通过引入光子互联技术，创新性地解决了AI加速器中长期存在的内存容量和带宽瓶颈，即“硅滩限制”。其核心贡献在于提出了一个可扩展的共享内存和交换结构，能够显著提升LLM等大型AI模型的性能和能效。这种方法通过将内存与计算分离并提供灵活的扩展路径，为未来AI硬件设计开辟了新方向，具有重要的实际应用价值和潜在的行业影响力。"}}
{"id": "2507.14097", "title": "Generative AI-Driven High-Fidelity Human Motion Simulation", "authors": ["Hari Iyer", "Neel Macwan", "Atharva Jitendra Hude", "Heejin Jeong", "Shenghan Guo"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14097v1", "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14097v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "生成式AI驱动的高保真人体运动模拟", "tldr": "该研究引入了一种生成式AI驱动的人体运动模拟（G-AI-HMS）方法，通过整合文本到文本和文本到运动模型来提高模拟质量，并通过计算机视觉验证其与真实人类运动的一致性，结果显示其显著降低了运动误差。", "motivation": "现有的人体运动模拟（HMS）方法通常存在运动保真度低的问题，这限制了它们在评估工业任务中工人行为、安全性和生产力方面的有效性。", "method": "本研究引入了生成式AI驱动的人体运动模拟（G-AI-HMS）。该方法整合了文本到文本和文本到运动模型，以提高物理任务的模拟质量。它通过使用与MotionGPT训练词汇对齐的大型语言模型将任务描述转化为运动感知语言，并通过计算机视觉方法（如姿态估计算法和运动相似性度量）来验证AI增强的运动与真实人类运动的一致性。", "result": "在一项涉及八项任务的案例研究中，AI增强的运动在大多数情况下显示出比人类创建的描述更低的误差。具体来说，在空间准确性方面，AI增强的运动在六项任务中表现更好；在姿态归一化后的对齐方面，在四项任务中表现更好；在整体时间相似性方面，在七项任务中表现更好。统计分析表明，AI增强的提示显著（p < 0.0001）降低了关节误差和时间错位，同时保持了可比的姿态准确性。", "conclusion": "生成式AI驱动的人体运动模拟（G-AI-HMS）能够显著提高人体运动模拟的保真度，通过降低运动误差和时间错位，为工业任务的评估提供了更准确的工具。", "translation": "人体运动模拟（HMS）支持对工业任务中工人行为、安全性和生产力进行经济高效的评估。然而，现有方法通常存在运动保真度低的问题。本研究引入了生成式AI驱动的HMS（G-AI-HMS），它整合了文本到文本和文本到运动模型，以提高物理任务的模拟质量。G-AI-HMS解决了两个关键挑战：（1）使用与MotionGPT训练词汇对齐的大型语言模型将任务描述转化为运动感知语言，以及（2）使用计算机视觉对AI增强的运动与真实人类运动进行验证。姿态估计算法应用于实时视频以提取关节地标，并使用运动相似性度量将其与AI增强的序列进行比较。在一项涉及八项任务的案例研究中，AI增强的运动在大多数情况下显示出比人类创建的描述更低的误差，在空间准确性方面在六项任务中表现更好，在姿态归一化后的对齐方面在四项任务中表现更好，在整体时间相似性方面在七项任务中表现更好。统计分析表明，AI增强的提示显著（p < 0.0001）降低了关节误差和时间错位，同时保持了可比的姿态准确性。", "summary": "本研究提出了一种名为G-AI-HMS的生成式AI驱动人体运动模拟系统，旨在解决现有方法运动保真度低的问题。该系统结合了文本到文本和文本到运动模型，利用大型语言模型将任务描述转换为运动指令，并通过计算机视觉技术（如姿态估计和运动相似性度量）对生成的运动进行验证。实验结果表明，G-AI-HMS在空间准确性、姿态对齐和时间相似性方面均优于人类创建的描述，显著降低了运动误差和时间错位，从而实现了高保真的人体运动模拟。", "keywords": "生成式AI, 人体运动模拟, 运动保真度, 大型语言模型, 计算机视觉", "comments": "该论文的创新之处在于将生成式AI（大型语言模型和文本到运动模型）与计算机视觉验证相结合，以实现高保真的人体运动模拟。这解决了现有HMS方法运动保真度不足的关键限制，对于工业任务中工人行为、安全性和生产力的评估具有重要意义。其通过真实数据验证AI生成运动的方法增强了模拟的可靠性。"}}
{"id": "2507.13546", "title": "$\\nabla$NABLA: Neighborhood Adaptive Block-Level Attention", "authors": ["Dmitrii Mikhailov", "Aleksey Letunovskiy", "Maria Kovaleva", "Vladimir Arkhipkin", "Vladimir Korviakov", "Vladimir Polovnikov", "Viacheslav Vasilev", "Evelina Sidorova", "Denis Dimitrov"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13546v1", "summary": "Recent progress in transformer-based architectures has demonstrated\nremarkable success in video generation tasks. However, the quadratic complexity\nof full attention mechanisms remains a critical bottleneck, particularly for\nhigh-resolution and long-duration video sequences. In this paper, we propose\nNABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that\ndynamically adapts to sparsity patterns in video diffusion transformers (DiTs).\nBy leveraging block-wise attention with adaptive sparsity-driven threshold,\nNABLA reduces computational overhead while preserving generative quality. Our\nmethod does not require custom low-level operator design and can be seamlessly\nintegrated with PyTorch's Flex Attention operator. Experiments demonstrate that\nNABLA achieves up to 2.7x faster training and inference compared to baseline\nalmost without compromising quantitative metrics (CLIP score, VBench score,\nhuman evaluation score) and visual quality drop. The code and model weights are\navailable here: https://github.com/gen-ai-team/Wan2.1-NABLA", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13546v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "$\nabla$NABLA: 邻域自适应块级注意力", "tldr": "NABLA提出了一种新颖的邻域自适应块级注意力机制，用于视频扩散Transformer，通过块级注意力与自适应稀疏阈值相结合，显著降低了计算开销，同时保持了生成质量，训练和推理速度提升高达2.7倍。", "motivation": "Transformer架构在视频生成任务中取得了显著成功，但全注意力机制的二次复杂度对于高分辨率和长持续时间视频序列来说是一个关键瓶颈。", "method": "本文提出NABLA（Neighborhood Adaptive Block-Level Attention），一种新颖的邻域自适应块级注意力机制，它能动态适应视频扩散Transformer（DiTs）中的稀疏模式。通过利用块级注意力并结合自适应稀疏驱动阈值，NABLA减少了计算开销，同时保持了生成质量。该方法不需要自定义底层操作，并且可以与PyTorch的Flex Attention操作无缝集成。", "result": "实验表明，与基线相比，NABLA在训练和推理速度上提升高达2.7倍，几乎不影响定量指标（CLIP分数、VBENCH分数、人工评估分数）和视觉质量。", "conclusion": "NABLA通过其邻域自适应块级注意力机制，有效解决了视频生成Transformer中全注意力机制的二次复杂度问题，显著提升了计算效率而未牺牲生成质量。", "translation": "Transformer架构在视频生成任务中取得了显著进展。然而，全注意力机制的二次复杂度仍然是一个关键瓶颈，特别是对于高分辨率和长持续时间视频序列。在本文中，我们提出了NABLA，一种新颖的邻域自适应块级注意力机制，它能动态适应视频扩散Transformer（DiTs）中的稀疏模式。通过利用块级注意力并结合自适应稀疏驱动阈值，NABLA减少了计算开销，同时保持了生成质量。我们的方法不需要自定义底层操作，并且可以与PyTorch的Flex Attention操作无缝集成。实验表明，与基线相比，NABLA在训练和推理速度上提升高达2.7倍，几乎不影响定量指标（CLIP分数、VBENCH分数、人工评估分数）和视觉质量。代码和模型权重已在此处提供：https://github.com/gen-ai-team/Wan2.1-NABLA", "summary": "本文提出了NABLA，一种针对视频扩散Transformer设计的邻域自适应块级注意力机制。该机制通过结合块级注意力和自适应稀疏驱动阈值，有效解决了全注意力机制的二次复杂度问题，显著降低了计算开销。NABLA无需自定义底层操作，可与PyTorch的Flex Attention无缝集成。实验证明，NABLA在保持生成质量的同时，训练和推理速度比基线快2.7倍。", "keywords": "视频生成, Transformer, 注意力机制, 计算效率, NABLA", "comments": "NABLA的创新点在于其邻域自适应块级注意力机制，它巧妙地利用了视频数据的稀疏性，并通过自适应阈值来动态调整注意力范围。这种方法不仅有效解决了Transformer在处理高分辨率和长持续时间视频时的计算瓶颈，而且无需复杂的底层操作，易于集成，具有很强的实用价值。其在速度提升上的表现令人印象深刻，同时几乎不牺牲生成质量，显示了其在视频生成领域的重要潜力。"}}
{"id": "2507.13638", "title": "State Space Models Naturally Produce Traveling Waves, Time Cells, and Scale to Abstract Cognitive Functions", "authors": ["Sen Lu", "Xiaoyu Zhang", "Mingtao Hu", "Eric Yeu-Jer Lee", "Soohyeon Kim", "Wei D. Lu"], "categories": ["q-bio.NC", "cs.LG"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the corresponding author. 4 figures are included in 15 pages", "url": "http://arxiv.org/abs/2507.13638v1", "summary": "A grand challenge in modern neuroscience is to bridge the gap between the\ndetailed mapping of microscale neural circuits and a mechanistic understanding\nof cognitive functions. While extensive knowledge exists about neuronal\nconnectivity and biophysics, a significant gap remains in how these elements\ncombine to produce flexible, learned behaviors. Here, we propose that a\nframework based on State-Space Models (SSMs), an emerging class of deep\nlearning architectures, can bridge this gap. We argue that the differential\nequations governing elements in an SSM are conceptually consistent with the\nbiophysical dynamics of neurons, while the combined dynamics in the model lead\nto emergent behaviors observed in experimental neuroscience. We test this\nframework by training an S5 model--a specific SSM variant employing a diagonal\nstate transition matrix--on temporal discrimination tasks with reinforcement\nlearning (RL). We demonstrate that the model spontaneously develops neural\nrepresentations that strikingly mimic biological 'time cells'. We reveal that\nthese cells emerge from a simple generative principle: learned rotational\ndynamics of hidden state vectors in the complex plane. This single mechanism\nunifies the emergence of time cells, ramping activity, and\noscillations/traveling waves observed in numerous experiments. Furthermore, we\nshow that this rotational dynamics generalizes beyond interval discriminative\ntasks to abstract event-counting tasks that were considered foundational for\nperforming complex cognitive tasks. Our findings position SSMs as a compelling\nframework that connects single-neuron dynamics to cognitive phenomena, offering\na unifying and computationally tractable theoretical ground for temporal\nlearning in the brain.", "comment": "Sen Lu and Xiaoyu Zhang contributed equally. Wei D. Lu is the\n  corresponding author. 4 figures are included in 15 pages", "pdf_url": "http://arxiv.org/pdf/2507.13638v1", "cate": "q-bio.NC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "状态空间模型自然产生行波、时间细胞并扩展到抽象认知功能", "tldr": "本文提出状态空间模型（SSMs）可以弥合微观神经回路与认知功能之间的鸿沟，并展示其在时间判别任务中自发产生类似生物时间细胞的神经表征，且该机制可推广到抽象认知任务。", "motivation": "现代神经科学面临的巨大挑战是弥合微观神经回路的详细映射与认知功能的机制理解之间的鸿沟，即如何将神经元连接和生物物理学知识结合起来产生灵活的学习行为。", "method": "本文提出使用状态空间模型（SSMs），特别是S5模型（一种采用对角状态转移矩阵的SSM变体），并通过强化学习（RL）在时间判别任务上对其进行训练和测试。", "result": "模型自发产生了与生物“时间细胞”高度相似的神经表征。这些细胞源于隐藏状态向量在复平面上学习到的旋转动力学。这种单一机制统一了时间细胞、斜坡活动和振荡/行波的出现。此外，这种旋转动力学可以推广到抽象的事件计数任务。", "conclusion": "状态空间模型（SSMs）是一个引人注目的框架，它将单神经元动力学与认知现象联系起来，为大脑中的时间学习提供了一个统一且计算上易于处理的理论基础。", "translation": "现代神经科学的一个巨大挑战是弥合微观神经回路的详细映射与认知功能的机制理解之间的鸿沟。尽管关于神经元连接和生物物理学存在大量知识，但这些元素如何结合产生灵活的学习行为仍存在显著空白。本文提出，基于状态空间模型（SSM）这一新兴深度学习架构的框架可以弥合这一鸿沟。我们认为，SSM中元素的微分方程在概念上与神经元的生物物理动力学一致，而模型中的组合动力学则导致了实验神经科学中观察到的涌现行为。我们通过在强化学习（RL）的时间判别任务上训练S5模型——一种采用对角状态转移矩阵的特定SSM变体——来测试这一框架。我们证明了模型自发地发展出与生物“时间细胞”惊人相似的神经表征。我们揭示了这些细胞源于一个简单的生成原理：复平面中隐藏状态向量的学习到的旋转动力学。这种单一机制统一了在众多实验中观察到的时间细胞、斜坡活动和振荡/行波的出现。此外，我们表明这种旋转动力学超越了间隔判别任务，推广到被认为是执行复杂认知任务基础的抽象事件计数任务。我们的发现将SSM定位为一个引人注目的框架，它将单神经元动力学与认知现象联系起来，为大脑中的时间学习提供了一个统一且计算上易于处理的理论基础。", "summary": "本文提出状态空间模型（SSMs）作为一种新兴的深度学习架构，能够弥合微观神经回路与高级认知功能之间的理解鸿沟。研究人员通过训练S5模型（一种SSM变体）在时间判别任务上，发现模型能自发生成类似生物时间细胞的神经表征。这些表征源于隐藏状态向量在复平面上的旋转动力学，该机制不仅统一了时间细胞、斜坡活动和振荡等多种生物现象的产生，还能推广到抽象的事件计数任务。这表明SSMs为连接单神经元动力学和认知现象、理解大脑时间学习提供了一个统一且可计算的理论框架。", "keywords": "状态空间模型, 时间细胞, 认知功能, 神经科学, 深度学习", "comments": "该论文的创新之处在于提出并验证了状态空间模型（SSMs）作为连接微观神经回路和宏观认知功能的潜在框架。其重要性在于提供了一种计算上可行且理论上统一的方法来解释时间细胞、行波等多种神经现象的涌现，并展示了其在抽象认知任务上的泛化能力。这为理解大脑如何处理时间信息和执行复杂认知功能提供了新的视角和工具。"}}
{"id": "2410.08557", "title": "MUSO: Achieving Exact Machine Unlearning in Over-Parameterized Regimes", "authors": ["Ruikai Yang", "Mingzhen He", "Zhengbao He", "Youmei Qiu", "Xiaolin Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted by Machine Learning Journal", "url": "http://arxiv.org/abs/2410.08557v2", "summary": "Machine unlearning (MU) is to make a well-trained model behave as if it had\nnever been trained on specific data. In today's over-parameterized models,\ndominated by neural networks, a common approach is to manually relabel data and\nfine-tune the well-trained model. It can approximate the MU model in the output\nspace, but the question remains whether it can achieve exact MU, i.e., in the\nparameter space. We answer this question by employing random feature techniques\nto construct an analytical framework. Under the premise of model optimization\nvia stochastic gradient descent, we theoretically demonstrated that\nover-parameterized linear models can achieve exact MU through relabeling\nspecific data. We also extend this work to real-world nonlinear networks and\npropose an alternating optimization algorithm that unifies the tasks of\nunlearning and relabeling. The algorithm's effectiveness, confirmed through\nnumerical experiments, highlights its superior performance in unlearning across\nvarious scenarios compared to current state-of-the-art methods, particularly\nexcelling over similar relabeling-based MU approaches.", "comment": "Accepted by Machine Learning Journal", "pdf_url": "http://arxiv.org/pdf/2410.08557v2", "cate": "cs.LG", "date": "2024-10-11", "updated": "2025-07-18", "AI": {"title_translation": "MUSO: 在过参数化机制中实现精确机器遗忘", "tldr": "MUSO研究了在过参数化模型中实现精确机器遗忘（MU）的方法。通过随机特征技术，理论证明了过参数化线性模型可以通过数据重标记实现精确MU。对于非线性网络，提出了一个交替优化算法，并在数值实验中表现出优越的遗忘性能。", "motivation": "在当前以神经网络为主的过参数化模型中，机器遗忘（MU）通常通过手动重标记数据和微调模型来近似实现。然而，这种方法是否能在参数空间中实现精确的MU（而不仅仅是输出空间）仍是一个未解决的问题。", "method": "本研究通过采用随机特征技术构建了一个分析框架。在随机梯度下降模型优化的前提下，理论上证明了过参数化线性模型可以通过重标记特定数据实现精确的机器遗忘。此外，将这项工作扩展到现实世界的非线性网络，并提出了一种统一遗忘和重标记任务的交替优化算法。", "result": "理论上证明了过参数化线性模型可以通过重标记特定数据实现精确的机器遗忘。通过数值实验证实了所提出算法的有效性，并强调其在各种场景下，特别是与基于重标记的MU方法相比，在遗忘方面具有卓越的性能。", "conclusion": "本研究通过理论分析和算法设计，证明了在过参数化机制中实现精确机器遗忘的可能性。对于线性模型，理论上实现了精确遗忘；对于非线性网络，提出的交替优化算法在实践中表现出优越的性能，为机器遗忘领域提供了一种有效且精确的解决方案。", "translation": "机器遗忘（MU）旨在使一个训练好的模型表现得如同从未在特定数据上训练过一样。在当今由神经网络主导的过参数化模型中，一种常见的方法是手动重新标记数据并微调已训练好的模型。这种方法可以在输出空间中近似MU模型，但问题在于它是否能在参数空间中实现精确的MU。我们通过采用随机特征技术构建了一个分析框架来回答这个问题。在通过随机梯度下降进行模型优化的前提下，我们理论上证明了过参数化线性模型可以通过重新标记特定数据来实现精确的MU。我们还将这项工作扩展到现实世界的非线性网络，并提出了一种统一遗忘和重新标记任务的交替优化算法。该算法的有效性通过数值实验得到了证实，突出了其在各种场景下，特别是与当前最先进的基于重新标记的MU方法相比，在遗忘方面具有卓越的性能。", "summary": "本论文，名为MUSO，探讨了在过参数化模型中实现精确机器遗忘（MU）的问题。针对现有方法仅能近似MU的局限，研究利用随机特征技术构建分析框架，理论证明了在随机梯度下降优化下，过参数化线性模型可通过数据重标记实现参数空间的精确MU。进一步，论文将此概念推广至非线性网络，并提出了一种创新的交替优化算法，该算法能有效统一遗忘与重标记任务。实验结果表明，该算法在多种遗忘场景下，尤其是在与现有基于重标记的MU方法对比时，展现出显著的性能优势。", "keywords": "机器遗忘, 过参数化模型, 精确遗忘, 随机特征, 重标记", "comments": "该论文的关键创新在于其首次在理论上证明了在过参数化线性模型中实现“精确”机器遗忘的可能性，这超越了以往仅在输出空间近似遗忘的局限。通过引入随机特征技术和提出统一遗忘与重标记的交替优化算法，MUSO为解决大型复杂模型中的数据隐私和模型更新问题提供了新的思路和有效工具。其对非线性网络的扩展和实验验证也增加了其实用价值。"}}
{"id": "2507.13556", "title": "Time Series Forecastability Measures", "authors": ["Rui Wang", "Steven Klee", "Alexis Roos"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13556v1", "summary": "This paper proposes using two metrics to quantify the forecastability of time\nseries prior to model development: the spectral predictability score and the\nlargest Lyapunov exponent. Unlike traditional model evaluation metrics, these\nmeasures assess the inherent forecastability characteristics of the data before\nany forecast attempts. The spectral predictability score evaluates the strength\nand regularity of frequency components in the time series, whereas the Lyapunov\nexponents quantify the chaos and stability of the system generating the data.\nWe evaluated the effectiveness of these metrics on both synthetic and\nreal-world time series from the M5 forecast competition dataset. Our results\ndemonstrate that these two metrics can correctly reflect the inherent\nforecastability of a time series and have a strong correlation with the actual\nforecast performance of various models. By understanding the inherent\nforecastability of time series before model training, practitioners can focus\ntheir planning efforts on products and supply chain levels that are more\nforecastable, while setting appropriate expectations or seeking alternative\nstrategies for products with limited forecastability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13556v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "时间序列可预测性度量", "tldr": "本文提出了两种在模型开发前量化时间序列可预测性的指标：谱可预测性分数和最大李雅普诺夫指数，并证明它们能有效反映时间序列的内在可预测性并与实际预测性能高度相关。", "motivation": "在模型开发之前量化时间序列的内在可预测性，以帮助从业者更好地规划和分配资源，并设定合理的预期。", "method": "提出了两种新的度量指标：谱可预测性分数（评估时间序列中频率分量的强度和规律性）和最大李雅普普诺夫指数（量化系统生成数据的混沌和稳定性）。这些指标在合成数据和M5预测竞赛数据集中的真实世界时间序列上进行了评估。", "result": "这两种度量指标能够正确反映时间序列的内在可预测性，并且与各种模型的实际预测性能具有很强的相关性。", "conclusion": "通过在模型训练前了解时间序列的内在可预测性，从业者可以将其规划工作集中在更可预测的产品和供应链层面，同时为可预测性有限的产品设定适当的预期或寻求替代策略。", "translation": "本文提出了两种在模型开发前量化时间序列可预测性的度量指标：谱可预测性分数和最大李雅普诺夫指数。与传统的模型评估指标不同，这些度量在任何预测尝试之前评估数据的内在可预测性特征。谱可预测性分数评估时间序列中频率分量的强度和规律性，而李雅普诺夫指数量化生成数据的系统的混沌和稳定性。我们在M5预测竞赛数据集中的合成和真实世界时间序列上评估了这些指标的有效性。我们的结果表明，这两种指标可以正确反映时间序列的内在可预测性，并且与各种模型的实际预测性能具有很强的相关性。通过在模型训练前了解时间序列的内在可预测性，从业者可以将其规划工作集中在更可预测的产品和供应链层面，同时为可预测性有限的产品设定适当的预期或寻求替代策略。", "summary": "本研究提出了两种新的指标——谱可预测性分数和最大李雅普诺夫指数——用于在模型开发前量化时间序列的内在可预测性。这些指标不同于传统的模型评估方法，它们评估数据本身的预测潜力。研究通过合成数据和M5竞赛的真实数据验证了这些指标的有效性，结果表明它们能准确反映时间序列的内在可预测性，并与模型的实际预测性能高度相关。这项工作有助于从业者在资源规划和策略制定上做出更明智的决策。", "keywords": "时间序列, 可预测性, 谱可预测性分数, 李雅普诺夫指数", "comments": "该论文的创新之处在于提出了在模型训练之前评估时间序列内在可预测性的方法，这不同于传统的事后模型评估。这种预评估能力具有重要的实际意义，可以帮助企业更有效地分配资源，并为预测结果设定更切合实际的期望，从而优化供应链管理和产品规划。"}}
{"id": "2507.04201", "title": "An Efficient Max-Min Fair Resource Optimization Algorithm for Rate-Splitting Multiple Access", "authors": ["Facheng Luo", "Yijie Mao"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      16 pages, 10 figures", "url": "http://arxiv.org/abs/2507.04201v2", "summary": "The max-min fairness (MMF) problem in rate-splitting multiple access (RSMA)\nis known to be challenging due to its non-convex and non-smooth nature, as well\nas the coupled beamforming and common rate variables. Conventional algorithms\nto address this problem often incur high computational complexity or degraded\nMMF rate performance. To address these challenges, in this work, we propose a\nnovel optimization algorithm named extragradient-fractional programming (EG-FP)\nto address the MMF problem of downlink RSMA. The proposed algorithm first\nleverages FP to transform the original problem into a block-wise convex\nproblem. For the subproblem of precoding block, we show that its Lagrangian\ndual is equivalent to a variational inequality problem, which is then solved\nusing an extragradient-based algorithm. Additionally, we discover the optimal\nbeamforming structure of the problem and based on which, we introduce a\nlow-dimensional EG-FP algorithm with computational complexity independent of\nthe number of transmit antennas. This feature is especially beneficial in\nscenarios with a large number of transmit antennas. The proposed algorithms are\nthen extended to handle imperfect channel state information at the transmitter\n(CSIT). Numerical results demonstrate that the MMF rate achieved by our\nproposed algorithms closely matches that of the conventional successive convex\napproximation (SCA) algorithm and significantly outperforms other baseline\nschemes. Remarkably, the average CPU time of the proposed algorithms is less\nthan 10\\% of the runtime required by the SCA algorithm, showing the efficiency\nand scalability of the proposed algorithms.", "comment": "16 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.04201v2", "cate": "cs.IT", "date": "2025-07-06", "updated": "2025-07-18", "AI": {"title_translation": "速率分离多址接入中的高效最大最小公平资源优化算法", "tldr": "提出了一种名为EG-FP的新算法，用于解决RSMA中的MMF问题，该算法计算效率高，性能接近SCA但速度快得多。", "motivation": "速率分离多址接入 (RSMA) 中的最大最小公平 (MMF) 问题因其非凸、非光滑性质以及波束成形和公共速率变量的耦合而具有挑战性；传统算法通常会导致高计算复杂度或降低的MMF速率性能。", "method": "提出了一种名为外梯度分数规划 (EG-FP) 的新型优化算法来解决下行链路RSMA的MMF问题。该算法首先利用分数规划 (FP) 将原始问题转化为分块凸问题。对于预编码块的子问题，其拉格朗日对偶等价于一个变分不等式问题，并使用基于外梯度 (extragradient) 的算法进行求解。此外，该研究发现了最优波束成形结构，并基于此引入了一种计算复杂度与发射天线数量无关的低维EG-FP算法。所提出的算法还被扩展以处理不完善的发射机信道状态信息 (CSIT)。", "result": "所提出的EG-FP算法实现的MMF速率与传统的逐次凸逼近 (SCA) 算法非常接近，并显著优于其他基线方案。所提出算法的平均CPU时间不到SCA算法所需运行时间的10%。", "conclusion": "所提出的EG-FP算法在解决RSMA中的最大最小公平问题上表现出高效性和可扩展性，同时能达到与SCA算法相当的MMF速率性能。", "translation": "速率分离多址接入 (RSMA) 中的最大最小公平性 (MMF) 问题因其非凸、非光滑性质以及波束成形和公共速率变量的耦合而闻名，具有挑战性。解决此问题的传统算法通常会导致高计算复杂度或降低的MMF速率性能。为了解决这些挑战，在这项工作中，我们提出了一种新颖的优化算法，名为外梯度分数规划 (EG-FP)，以解决下行链路RSMA的MMF问题。所提出的算法首先利用分数规划将原始问题转化为分块凸问题。对于预编码块的子问题，我们证明其拉格朗日对偶等价于一个变分不等式问题，然后使用基于外梯度算法对其进行求解。此外，我们发现了问题的最优波束成形结构，并在此基础上引入了一种低维EG-FP算法，其计算复杂度与发射天线数量无关。此特性在发射天线数量较多的场景中特别有利。然后将所提出的算法扩展到处理发射机处不完善的信道状态信息 (CSIT)。数值结果表明，我们提出的算法实现的MMF速率与传统的逐次凸逼近 (SCA) 算法非常接近，并且显著优于其他基线方案。值得注意的是，所提出算法的平均CPU时间不到SCA算法所需运行时间的10%，显示了所提出算法的效率和可扩展性。", "summary": "本文提出了一种名为EG-FP的新型优化算法，用于解决速率分离多址接入（RSMA）中具有挑战性的最大最小公平（MMF）问题。该算法通过分数规划将原问题转化为分块凸问题，并利用外梯度算法求解其变分不等式形式的子问题。研究还发现了最优波束成形结构，并基于此提出了低维EG-FP版本，其计算复杂度与天线数量无关。数值结果表明，EG-FP在MMF速率性能上与SCA算法相近，但计算效率显著提高，平均CPU时间不到SCA的10%。", "keywords": "速率分离多址接入, 最大最小公平, 资源优化, 外梯度分数规划, 计算效率", "comments": "这篇论文的创新点在于提出了EG-FP算法来高效解决RSMA中的MMF问题，特别是通过结合分数规划和外梯度方法，并发现最优波束成形结构来降低计算复杂度，使其在具有大量发射天线的场景中表现出良好的可扩展性。其显著的计算效率提升是其重要贡献。"}}
{"id": "2507.13891", "title": "PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations", "authors": ["Yu Wei", "Jiahui Zhang", "Xiaoqin Zhang", "Ling Shao", "Shijian Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.13891v1", "summary": "COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing\nattention due to its remarkable performance in reconstructing high-quality 3D\nscenes from unposed images or videos. However, it often struggles to handle\nscenes with complex camera trajectories as featured by drastic rotation and\ntranslation across adjacent camera views, leading to degraded estimation of\ncamera poses and further local minima in joint optimization of camera poses and\n3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that\nachieves superior 3D scene modeling and camera pose estimation via camera pose\nco-regularization. PCR-GS achieves regularization from two perspectives. The\nfirst is feature reprojection regularization which extracts view-robust DINO\nfeatures from adjacent camera views and aligns their semantic information for\ncamera pose regularization. The second is wavelet-based frequency\nregularization which exploits discrepancy in high-frequency details to further\noptimize the rotation matrix in camera poses. Extensive experiments over\nmultiple real-world scenes show that the proposed PCR-GS achieves superior\npose-free 3D-GS scene modeling under dramatic changes of camera trajectories.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.13891v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "PCR-GS：通过姿态协同正则化实现无COLMAP的3D高斯泼溅", "tldr": "PCR-GS通过两种协同正则化方法解决了无COLMAP 3D高斯泼溅在复杂相机轨迹下姿态估计和场景建模的挑战，实现了卓越的性能。", "motivation": "现有的无COLMAP 3D高斯泼溅技术在处理具有复杂相机轨迹（表现为相邻视图间剧烈旋转和平移）的场景时，常导致相机姿态估计退化和相机姿态与3D-GS联合优化陷入局部最优。", "method": "本文提出了PCR-GS，一种创新的无COLMAP 3DGS技术，通过相机姿态协同正则化实现卓越的3D场景建模和相机姿态估计。PCR-GS从两个角度实现正则化：1) 特征重投影正则化：从相邻相机视图中提取视图鲁棒的DINO特征并对齐其语义信息以进行相机姿态正则化。2) 基于小波的频率正则化：利用高频细节的差异来进一步优化相机姿态中的旋转矩阵。", "result": "在多个真实世界场景上进行的广泛实验表明，所提出的PCR-GS在相机轨迹剧烈变化下实现了卓越的无姿态3D-GS场景建模。", "conclusion": "PCR-GS有效解决了无COLMAP 3D-GS在复杂相机轨迹下的姿态估计和场景建模问题，通过创新的协同正则化方法显著提高了性能和鲁棒性。", "translation": "无COLMAP的3D高斯泼溅（3D-GS）最近因其在从无姿态图像或视频重建高质量3D场景方面的卓越性能而受到越来越多的关注。然而，它在处理具有复杂相机轨迹的场景时常常遇到困难，这些轨迹表现为相邻相机视图之间剧烈的旋转和平移，导致相机姿态估计退化以及相机姿态和3D-GS联合优化中的局部最优。我们提出了PCR-GS，一种创新的无COLMAP 3DGS技术，通过相机姿态协同正则化实现了卓越的3D场景建模和相机姿态估计。PCR-GS从两个角度实现正则化。第一个是特征重投影正则化，它从相邻相机视图中提取视图鲁棒的DINO特征，并对齐它们的语义信息以进行相机姿态正则化。第二个是基于小波的频率正则化，它利用高频细节的差异来进一步优化相机姿态中的旋转矩阵。在多个真实世界场景上进行的广泛实验表明，所提出的PCR-GS在相机轨迹剧烈变化下实现了卓越的无姿态3D-GS场景建模。", "summary": "本文提出了PCR-GS，一种创新的无COLMAP 3D高斯泼溅技术，旨在解决现有方法在复杂相机轨迹下相机姿态估计和场景建模的挑战。PCR-GS通过特征重投影正则化和基于小波的频率正则化两种协同正则化方法，有效提升了3D场景建模和相机姿态估计的性能，尤其适用于相机轨迹剧烈变化的场景。", "keywords": "3D Gaussian Splatting, COLMAP-free, Pose estimation, Co-regularization, Complex camera trajectories", "comments": "PCR-GS通过引入新颖的姿态协同正则化策略，特别是结合DINO特征和小波分析，有效解决了无COLMAP 3D-GS在复杂运动场景下的局限性，提升了姿态估计和场景重建的鲁棒性和准确性，是3D场景重建领域的重要进展。"}}
{"id": "2405.13999", "title": "Computer-Vision-Enabled Worker Video Analysis for Motion Amount Quantification", "authors": ["Hari Iyer", "Neel Macwan", "Shenghan Guo", "Heejin Jeong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.13999v3", "summary": "The performance of physical workers is significantly influenced by the extent\nof their motions. However, monitoring and assessing these motions remains a\nchallenge. Recent advancements have enabled in-situ video analysis for\nreal-time observation of worker behaviors. This paper introduces a novel\nframework for tracking and quantifying upper and lower limb motions, issuing\nalerts when critical thresholds are reached. Using joint position data from\nposture estimation, the framework employs Hotelling's $T^2$ statistic to\nquantify and monitor motion amounts. A significant positive correlation was\nnoted between motion warnings and the overall NASA Task Load Index (TLX)\nworkload rating (\\textit{r} = 0.218, \\textit{p} = 0.0024). A supervised Random\nForest model trained on the collected motion data was benchmarked against\nmultiple datasets including UCF Sports Action and UCF50, and was found to\neffectively generalize across environments, identifying ergonomic risk patterns\nwith accuracies up to 94\\%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.13999v3", "cate": "cs.CV", "date": "2024-05-22", "updated": "2025-07-18", "AI": {"title_translation": "计算机视觉赋能的工人视频分析用于运动量量化", "tldr": "本文提出了一个基于计算机视觉的框架，用于量化工人肢体运动，并在达到临界阈值时发出警报，通过与工作负荷的相关性以及高准确度识别人体工程学风险模式来验证其有效性。", "motivation": "物理工人的表现受其运动程度显著影响，但监测和评估这些运动仍然是一个挑战。", "method": "引入了一个新颖的框架，利用姿态估计的关节位置数据，采用Hotelling's $T^2$统计量来量化和监测运动量，并在达到临界阈值时发出警报。此外，还训练了一个监督式随机森林模型，用于识别人体工程学风险模式。", "result": "运动警告与NASA任务负荷指数（TLX）工作负荷评分之间存在显著正相关（r = 0.218, p = 0.0024）。训练的监督式随机森林模型在多个数据集上表现出有效的泛化能力，识别出人体工程学风险模式的准确率高达94%。", "conclusion": "该框架能够有效量化工人运动，与工作负荷相关联，并能高精度识别潜在的人体工程学风险模式，表明其在工人行为监测方面的潜力。", "translation": "体力劳动者的表现受到其运动程度的显著影响。然而，监测和评估这些运动仍然是一个挑战。最近的进展使得现场视频分析能够实时观察工人行为。本文介绍了一种新颖的框架，用于跟踪和量化上肢和下肢运动，并在达到临界阈值时发出警报。该框架利用姿态估计的关节位置数据，采用Hotelling's $T^2$统计量来量化和监测运动量。研究发现，运动警告与整体NASA任务负荷指数（TLX）工作负荷评分之间存在显著正相关（r = 0.218, p = 0.0024）。在收集到的运动数据上训练的监督式随机森林模型在包括UCF Sports Action和UCF50在内的多个数据集上进行了基准测试，结果显示其能够有效地跨环境泛化，以高达94%的准确率识别出人体工程学风险模式。", "summary": "本文提出了一个利用计算机视觉技术分析工人视频以量化其肢体运动的框架。该框架通过姿态估计获取关节数据，并使用Hotelling's $T^2$统计量监测运动量，在超阈值时发出警报。研究发现运动警告与工作负荷显著相关，并且训练的随机森林模型能以高准确率识别出人体工程学风险模式，证明了其在工人行为监测和风险识别方面的有效性。", "keywords": "计算机视觉, 运动量化, Hotelling's T^2统计量, 人体工程学风险, 随机森林", "comments": "该研究通过结合计算机视觉、姿态估计和统计方法，提出了一种新颖且实用的工人运动量化与风险识别框架。其创新点在于将Hotelling's $T^2$统计量应用于运动量化，并结合机器学习模型进行人体工程学风险模式识别。这项工作对于职业健康与安全领域具有重要意义，有助于实时监测工人疲劳和潜在的肌肉骨骼损伤风险，从而提高工作效率和安全性。"}}
{"id": "2507.14084", "title": "The Emotion-Memory Link: Do Memorability Annotations Matter for Intelligent Systems?", "authors": ["Maria Tsfasman", "Ramin Ghorbani", "Catholijn M. Jonker", "Bernd Dudzik"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14084v1", "summary": "Humans have a selective memory, remembering relevant episodes and forgetting\nthe less relevant information. Possessing awareness of event memorability for a\nuser could help intelligent systems in more accurate user modelling, especially\nfor such applications as meeting support systems, memory augmentation, and\nmeeting summarisation. Emotion recognition has been widely studied, since\nemotions are thought to signal moments of high personal relevance to users. The\nemotional experience of situations and their memorability have traditionally\nbeen considered to be closely tied to one another: moments that are experienced\nas highly emotional are considered to also be highly memorable. This\nrelationship suggests that emotional annotations could serve as proxies for\nmemorability. However, existing emotion recognition systems rely heavily on\nthird-party annotations, which may not accurately represent the first-person\nexperience of emotional relevance and memorability. This is why, in this study,\nwe empirically examine the relationship between perceived group emotions\n(Pleasure-Arousal) and group memorability in the context of conversational\ninteractions. Our investigation involves continuous time-based annotations of\nboth emotions and memorability in dynamic, unstructured group settings,\napproximating conditions of real-world conversational AI applications such as\nonline meeting support systems. Our results show that the observed relationship\nbetween affect and memorability annotations cannot be reliably distinguished\nfrom what might be expected under random chance. We discuss the implications of\nthis surprising finding for the development and applications of Affective\nComputing technology. In addition, we contextualise our findings in broader\ndiscourses in the Affective Computing and point out important targets for\nfuture research efforts.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14084v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "情感-记忆关联：可记忆性标注对智能系统重要吗？", "tldr": "本研究实证检验了感知到的群体情感与群体可记忆性之间的关系，发现情感与可记忆性标注之间的关系无法与随机机会区分开来，这对情感计算技术的发展和应用具有重要影响。", "motivation": "人类记忆具有选择性，智能系统若能感知事件的可记忆性，将有助于更准确的用户建模。情感被认为是个人相关性的信号，传统上认为情感体验与可记忆性紧密相关，因此情感标注可能作为可记忆性的代理。然而，现有情感识别系统依赖第三方标注，可能无法准确反映第一人称的情感相关性和可记忆性体验。本研究旨在实证检验感知到的群体情感与群体可记忆性之间的关系。", "method": "本研究在对话互动背景下，实证检验了感知到的群体情感（愉悦-唤醒）与群体可记忆性之间的关系。调查包括在动态、非结构化群体环境中对情感和可记忆性进行连续的基于时间的标注，以模拟现实世界对话AI应用（如在线会议支持系统）的条件。", "result": "结果显示，观察到的情感与可记忆性标注之间的关系无法与随机机会下的预期可靠地区分。", "conclusion": "本研究讨论了这一令人惊讶的发现对情感计算技术开发和应用的影响。此外，我们将研究结果置于情感计算领域的更广泛讨论中，并指出了未来研究的重要方向。", "translation": "人类拥有选择性记忆，会记住相关事件而遗忘不那么重要的信息。了解用户事件的可记忆性有助于智能系统进行更准确的用户建模，尤其适用于会议支持系统、记忆增强和会议摘要等应用。情感识别已被广泛研究，因为情感被认为是用户高度个人相关时刻的信号。情境的情感体验及其可记忆性传统上被认为紧密相连：被体验为高度情感化的时刻也被认为是高度可记忆的。这种关系表明情感标注可以作为可记忆性的代理。然而，现有情感识别系统严重依赖第三方标注，这可能无法准确代表第一人称的情感相关性和可记忆性体验。正因如此，在本研究中，我们实证检验了在对话互动背景下感知到的群体情感（愉悦-唤醒）与群体可记忆性之间的关系。我们的调查包括在动态、非结构化群体环境中对情感和可记忆性进行连续的基于时间的标注，以近似现实世界对话AI应用（如在线会议支持系统）的条件。我们的结果显示，观察到的情感与可记忆性标注之间的关系无法与随机机会下的预期可靠地区分。我们讨论了这一令人惊讶的发现对情感计算技术发展和应用的影响。此外，我们将研究结果置于情感计算领域的更广泛讨论中，并指出了未来研究的重要方向。", "summary": "本研究旨在探究情感与记忆之间的关联，特别是可记忆性标注对智能系统的重要性。鉴于人类记忆的选择性以及情感与个人相关性的传统联系，研究人员假设情感标注可以作为可记忆性的代理。然而，考虑到现有情感识别系统依赖第三方标注的局限性，本研究通过在真实对话情境中对群体情感和可记忆性进行连续时间标注，实证检验了两者关系。令人惊讶的是，研究结果表明，情感与可记忆性标注之间的关系无法与随机机会区分开来。这一发现对情感计算技术的发展和应用提出了重要启示，并指明了未来研究的方向。", "keywords": "情感, 记忆, 可记忆性, 情感计算, 智能系统", "comments": "这项研究的创新之处在于其对情感与可记忆性之间传统假设关系的实证检验，特别是在更接近真实世界的多人对话环境中进行。其核心贡献在于揭示了情感标注可能无法可靠地作为可记忆性代理的“意外”发现，这直接挑战了情感计算领域的一个长期假设。这一结果的重要性在于，它促使研究人员重新思考情感在记忆增强和智能系统中的作用，并强调了未来研究需要探索更复杂的关联或新的标注方法，而不仅仅依赖于情感作为可记忆性的简单代理。这对于情感计算领域未来的发展方向具有指导意义。"}}
{"id": "2409.18749", "title": "TensorSocket: Shared Data Loading for Deep Learning Training", "authors": ["Ties Robroek", "Neil Kim Nielsen", "Pınar Tözün"], "categories": ["cs.LG", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.18749v2", "summary": "Training deep learning models is a repetitive and resource-intensive process.\nData scientists often train several models before landing on a set of\nparameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural\narchitecture search), among other things that yield the highest accuracy. The\ncomputational efficiency of these training tasks depends highly on how well the\ntraining data is supplied to the training process. The repetitive nature of\nthese tasks results in the same data processing pipelines running over and\nover, exacerbating the need for and costs of computational resources. In this\npaper, we present TensorSocket to reduce the computational needs of deep\nlearning training by enabling simultaneous training processes to share the same\ndata loader. TensorSocket mitigates CPU-side bottlenecks in cases where the\ncollocated training workloads have high throughput on GPU, but are held back by\nlower data-loading throughput on CPU. TensorSocket achieves this by reducing\nredundant computations and data duplication across collocated training\nprocesses and leveraging modern GPU-GPU interconnects. While doing so,\nTensorSocket is able to train and balance differently-sized models and serve\nmultiple batch sizes simultaneously and is hardware- and pipeline-agnostic in\nnature. Our evaluation shows that TensorSocket enables scenarios that are\ninfeasible without data sharing, increases training throughput by up to 100%,\nand when utilizing cloud instances, achieves cost savings of 50% by reducing\nthe hardware resource needs on the CPU side. Furthermore, TensorSocket\noutperforms the state-of-the-art solutions for shared data loading such as\nCoorDL and Joader; it is easier to deploy and maintain and either achieves\nhigher or matches their throughput while requiring fewer CPU resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.18749v2", "cate": "cs.LG", "date": "2024-09-27", "updated": "2025-07-18", "AI": {"title_translation": "TensorSocket：深度学习训练的共享数据加载", "tldr": "TensorSocket通过共享数据加载器，解决了深度学习训练中的CPU数据加载瓶颈，显著提高了效率并降低了成本。", "motivation": "深度学习模型训练是一个重复且资源密集的过程，数据科学家需要训练多个模型来找到最佳参数和架构，这导致相同的D数据处理管道反复运行，增加了计算资源需求和成本。尤其在GPU吞吐量高但受限于CPU数据加载吞吐量时，会出现CPU侧瓶颈。", "method": "TensorSocket通过允许多个同时进行的训练过程共享同一个数据加载器来减少深度学习训练的计算需求。它通过减少冗余计算和跨并发训练过程的数据复制，并利用现代GPU-GPU互连来缓解CPU侧瓶颈。TensorSocket能够训练和平衡不同大小的模型，同时服务多个批次大小，并且与硬件和管道无关。", "result": "TensorSocket使之前不可行的数据共享场景成为可能，将训练吞吐量提高了高达100%，在使用云实例时通过减少CPU侧的硬件资源需求实现了50%的成本节约。此外，TensorSocket在共享数据加载方面优于最先进的解决方案如CoorDL和Joader，它更易于部署和维护，并且在需要更少CPU资源的同时，要么实现更高的吞吐量，要么与其持平。", "conclusion": "TensorSocket通过共享数据加载器有效解决了深度学习训练中的CPU数据加载瓶颈，显著提高了训练效率、降低了资源成本，并超越了现有解决方案，为大规模深度学习训练提供了更优的解决方案。", "translation": "训练深度学习模型是一个重复且资源密集的过程。数据科学家通常在确定一组能产生最高准确性的参数（例如，超参数调优）和模型架构（例如，神经网络架构搜索）之前，会训练多个模型。这些训练任务的计算效率高度依赖于训练数据如何有效地供应给训练过程。这些任务的重复性导致相同的数据处理管道反复运行，加剧了对计算资源的需求和成本。在本文中，我们提出了TensorSocket，通过使并发训练过程能够共享同一个数据加载器来减少深度学习训练的计算需求。TensorSocket在协同训练工作负载在GPU上具有高吞吐量，但受CPU上较低数据加载吞吐量限制的情况下，缓解了CPU侧的瓶颈。TensorSocket通过减少协同训练过程中冗余计算和数据复制，并利用现代GPU-GPU互连来实现这一点。在此过程中，TensorSocket能够训练和平衡不同大小的模型，并同时服务多个批次大小，并且本质上与硬件和管道无关。我们的评估表明，TensorSocket使没有数据共享就不可行的场景成为可能，将训练吞吐量提高了高达100%，并且在使用云实例时，通过减少CPU侧的硬件资源需求，实现了50%的成本节约。此外，TensorSocket在共享数据加载方面优于最先进的解决方案，如CoorDL和Joader；它更易于部署和维护，并且在需要更少CPU资源的同时，要么实现更高的吞吐量，要么与其持平。", "summary": "本文介绍了TensorSocket，一个用于深度学习训练的共享数据加载解决方案。它旨在解决训练过程中因重复数据处理和CPU侧数据加载瓶颈导致的计算资源浪费问题。TensorSocket通过允许并发训练过程共享同一数据加载器，减少了冗余计算和数据复制，并利用GPU-GPU互连。该系统能够灵活处理不同大小的模型和批次，且与硬件和管道无关。实验结果表明，TensorSocket显著提高了训练吞吐量（高达100%），节省了高达50%的云成本，并优于现有共享数据加载方案，同时更易于部署和维护。", "keywords": "共享数据加载, 深度学习训练, 计算效率, CPU瓶颈, TensorSocket", "comments": "TensorSocket的创新点在于其通过共享数据加载器直接解决了深度学习训练中长期存在的CPU数据加载瓶颈，这对于需要进行大量重复训练（如超参数调优和NAS）的场景尤其重要。其硬件和管道无关性以及对不同模型和批次大小的兼容性，使其具有广泛的应用潜力。性能提升和成本节约的实证结果，以及优于现有解决方案的表现，都突显了其重要性。"}}
{"id": "2507.13557", "title": "Single spin exact gradients for the optimization of complex pulses and pulse sequences", "authors": ["Stella Slad", "Burkhard Luy"], "categories": ["math.OC", "cs.SY", "eess.SY", "physics.chem-ph"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13557v1", "summary": "The efficient computer optimization of magnetic resonance pulses and pulse\nsequences involves the calculation of a problem-adapted cost function as well\nas its gradients with respect to all controls applied. The gradients generally\ncan be calculated as a finite difference approximation, as a GRAPE\napproximation, or as an exact function, e.g. by the use of the augmented matrix\nexponentiation, where the exact gradient should lead to best optimization\nconvergence. However, calculation of exact gradients is computationally\nexpensive and analytical exact solutions to the problem would be highly\ndesirable. As the majority of todays pulse optimizations involve a single spin\n1/2, which can be represented by simple rotation matrices in the Bloch space or\nby their corresponding Cayley-Klein/quaternion parameters, the derivations of\nanalytical exact gradient functions appear to be feasible. Taking two\noptimization types, the optimization of point-to-point pulses using\n3D-rotations and the optimization of universal rotation pulses using\nquaternions, analytical solutions for gradients with respect to controls have\nbeen derived. Controls in this case can be conventional $x$ and $y$ pulses, but\nalso $z$-controls, as well as gradients with respect to amplitude and phase of\na pulse shape. In addition, analytical solutions with respect to pseudo\ncontrols, involving holonomic constraints to maximum rf-amplitudes, maximum\nrf-power, or maximum rf-energy, are introduced. Using the hyperbolic tangent\nfunction, maximum values are imposed in a fully continuous and differentiable\nway. The obtained analytical gradients allow the calculation two orders of\nmagnitude faster than the augmented matrix exponential approach. The exact\ngradients for different controls are finally compared in a number of\noptimizations involving broadband pulses for $^{15}$N, $^{13}$C, and $^{19}$F\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13557v1", "cate": "math.OC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于优化复杂脉冲和脉冲序列的单自旋精确梯度", "tldr": "针对单自旋1/2系统，推导出精确解析梯度，大幅加速复杂脉冲优化。", "motivation": "精确梯度计算成本高昂，且分析性精确解非常理想。鉴于当前大多数脉冲优化涉及单自旋1/2，推导解析精确梯度函数是可行的。", "method": "该研究推导了针对单自旋1/2系统的解析精确梯度函数，涉及使用3D旋转优化点对点脉冲和使用四元数优化通用旋转脉冲。此外，还引入了针对伪控制的解析解，这些伪控制包含对最大射频幅度、最大射频功率或最大射频能量的全连续可微分的完整约束。", "result": "所获得的解析梯度计算速度比增广矩阵指数法快两个数量级。这些精确梯度在涉及用于$^{15}$N、$^{13}$C和$^{19}$F应用的宽带脉冲的多次优化中进行了比较。", "conclusion": "推导出的单自旋精确解析梯度显著加速了复杂脉冲和脉冲序列的优化过程，提供了更高的计算效率。", "translation": "磁共振脉冲和脉冲序列的有效计算机优化涉及计算问题适应的成本函数以及其相对于所有施加控制的梯度。梯度通常可以作为有限差分近似、GRAPE近似或精确函数进行计算，例如通过使用增广矩阵指数法，其中精确梯度应导致最佳优化收敛。然而，精确梯度的计算成本高昂，并且问题的解析精确解将是非常理想的。由于当今大多数脉冲优化涉及单自旋1/2，可以通过布洛赫空间中的简单旋转矩阵或其对应的Cayley-Klein/四元数参数来表示，因此推导解析精确梯度函数似乎是可行的。研究采用了两种优化类型，即使用3D旋转优化点对点脉冲和使用四元数优化通用旋转脉冲，推导出了相对于控制的解析梯度解。在这种情况下，控制可以是传统的x和y脉冲，也可以是z控制，以及相对于脉冲形状的幅度和相位的梯度。此外，还引入了相对于伪控制的解析解，这些伪控制涉及对最大射频幅度、最大射频功率或最大射频能量的完整约束。通过使用双曲正切函数，以完全连续和可微分的方式施加最大值。所获得的解析梯度计算速度比增广矩阵指数法快两个数量级。最后，在涉及用于$^{15}$N、$^{13}$C和$^{19}$F应用的宽带脉冲的多次优化中，比较了不同控制的精确梯度。", "summary": "该论文旨在解决磁共振脉冲优化中精确梯度计算的计算成本高昂问题。作者针对单自旋1/2系统，推导了精确的解析梯度函数，具体包括使用3D旋转优化点对点脉冲以及使用四元数优化通用旋转脉冲。此外，还引入了包含完整约束的伪控制的解析解。研究结果表明，这些解析梯度的计算速度比传统的增广矩阵指数法快两个数量级，从而显著提升了复杂脉冲序列优化的效率。", "keywords": "精确梯度, 脉冲优化, 磁共振, 解析解, 单自旋", "comments": "该论文的主要创新在于成功推导了单自旋系统的精确解析梯度，显著提升了复杂脉冲优化的计算效率（快两个数量级）。这项工作对磁共振领域具有重要意义，因为它能实现更高效、更复杂的脉冲序列设计，从而加速实验和应用开发。"}}
{"id": "2507.13937", "title": "Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support", "authors": ["Jan Trienes", "Anastasiia Derzhanskaia", "Roland Schwarzkopf", "Markus Mühling", "Jörg Schlötterer", "Christin Seifert"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13937v1", "summary": "We present Marcel, a lightweight and open-source conversational agent\ndesigned to support prospective students with admission-related inquiries. The\nsystem aims to provide fast and personalized responses, while reducing workload\nof university staff. We employ retrieval-augmented generation to ground answers\nin university resources and to provide users with verifiable, contextually\nrelevant information. To improve retrieval quality, we introduce an FAQ\nretriever that maps user questions to knowledge-base entries, allowing\nadministrators to steer retrieval, and improving over standard dense/hybrid\nretrieval strategies. The system is engineered for easy deployment in\nresource-constrained academic settings. We detail the system architecture,\nprovide a technical evaluation of its components, and report insights from a\nreal-world deployment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13937v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Marcel：一款轻量级开源大学学生支持会话代理", "tldr": "Marcel是一款轻量级开源会话代理，旨在通过检索增强生成来回答大学招生查询，减轻员工工作量并提供可验证的信息，特别适用于资源受限的学术环境。", "motivation": "该系统旨在为潜在学生提供招生相关查询的快速个性化响应，同时减轻大学员工的工作量。", "method": "该系统采用检索增强生成（RAG）技术，将答案基于大学资源，并为用户提供可验证的、上下文相关的信息。为提高检索质量，引入了FAQ检索器，将用户问题映射到知识库条目，允许管理员引导检索，并优于标准的密集/混合检索策略。系统设计易于在资源受限的学术环境中部署。", "result": "文章详细介绍了系统架构，提供了其组件的技术评估，并报告了真实世界部署的见解。", "conclusion": "Marcel是一个轻量级、开源的会话代理，通过检索增强生成和FAQ检索器，有效支持大学学生查询，减轻员工负担，并已成功部署。", "translation": "我们介绍了Marcel，一个轻量级开源会话代理，旨在支持潜在学生处理招生相关查询。该系统旨在提供快速和个性化的响应，同时减轻大学员工的工作量。我们采用检索增强生成技术，将答案基于大学资源，并为用户提供可验证的、上下文相关的信息。为了提高检索质量，我们引入了一个FAQ检索器，将用户问题映射到知识库条目，允许管理员引导检索，并优于标准的密集/混合检索策略。该系统设计易于在资源受限的学术环境中部署。我们详细介绍了系统架构，提供了其组件的技术评估，并报告了真实世界部署的见解。", "summary": "本文介绍了Marcel，一个轻量级开源的会话代理，专为大学招生咨询设计。它利用检索增强生成技术，并引入了一个创新的FAQ检索器来提高信息检索的准确性，旨在为学生提供快速、个性化的可验证答案，同时减轻大学员工的工作负担。该系统易于在资源受限的环境中部署，并对其架构、技术组件和实际部署经验进行了详细阐述和评估。", "keywords": "会话代理, 大学支持, 检索增强生成, FAQ检索器, 开源", "comments": "该论文的创新之处在于其结合了检索增强生成与专门的FAQ检索器来提高大学招生咨询的准确性和可控性。其轻量级和开源的特性使其在资源受限的学术环境中具有很高的实用价值和可部署性。系统旨在解决大学员工工作量大的实际痛点，具有重要的应用前景。"}}
{"id": "2507.13372", "title": "Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks", "authors": ["Yeming Cai", "Zhenglin Li", "Yang Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13372v1", "summary": "Breast cancer is a leading cause of death among women globally, and early\ndetection is critical for improving survival rates. This paper introduces an\ninnovative framework that integrates Vision Transformers (ViT) and Graph Neural\nNetworks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.\nOur framework leverages ViT's ability to capture global image features and\nGNN's strength in modeling structural relationships, achieving an accuracy of\n84.2%, outperforming traditional methods. Additionally, interpretable attention\nheatmaps provide insights into the model's decision-making process, aiding\nradiologists in clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13372v1", "cate": "cs.CV", "date": "2025-07-11", "updated": "2025-07-11", "AI": {"title_translation": "使用视觉Transformer和图神经网络增强乳腺癌检测", "tldr": "本研究提出一个结合视觉Transformer和图神经网络的创新框架，用于乳腺癌检测，在CBIS-DDSM数据集上达到了84.2%的准确率，并提供可解释的注意力热图。", "motivation": "乳腺癌是全球女性死亡的主要原因，早期检测对于提高生存率至关重要。", "method": "本研究提出了一个创新框架，结合了视觉Transformer（ViT）和图神经网络（GNN）来增强乳腺癌检测。该框架利用ViT捕捉全局图像特征的能力和GNN建模结构关系的能力，并使用CBIS-DDSM数据集进行训练。", "result": "该框架在乳腺癌检测中实现了84.2%的准确率，优于传统方法。此外，可解释的注意力热图提供了模型决策过程的洞察。", "conclusion": "该集成ViT和GNN的框架显著提升了乳腺癌检测的准确性，并通过提供可解释性辅助放射科医生，有望改善临床诊断。", "translation": "乳腺癌是全球女性死亡的主要原因，早期检测对于提高生存率至关重要。本文介绍了一个创新框架，该框架集成了视觉Transformer（ViT）和图神经网络（GNN），以利用CBIS-DDSM数据集增强乳腺癌检测。我们的框架利用ViT捕获全局图像特征的能力和GNN建模结构关系的优势，实现了84.2%的准确率，优于传统方法。此外，可解释的注意力热图提供了模型决策过程的洞察，有助于放射科医生在临床环境中进行判断。", "summary": "本研究提出一个结合视觉Transformer（ViT）和图神经网络（GNN）的创新框架，旨在提高乳腺癌检测的准确性。该框架利用ViT提取全局图像特征和GNN建模结构关系的能力，在CBIS-DDSM数据集上取得了84.2%的准确率，超越了传统方法。此外，模型生成的注意力热图增强了可解释性，为放射科医生提供了决策洞察。", "keywords": "乳腺癌检测, 视觉Transformer, 图神经网络, 早期检测, 深度学习", "comments": "这项研究的创新之处在于将Vision Transformers和Graph Neural Networks相结合，以利用各自在图像特征提取和结构关系建模方面的优势。84.2%的准确率和可解释的注意力热图表明了该方法在提升乳腺癌早期检测方面的潜力，对临床实践具有重要意义。"}}
{"id": "2507.11640", "title": "Quantifying data needs in surrogate modeling for flow fields in two-dimensional stirred tanks with physics-informed neural networks", "authors": ["Veronika Trávníková", "Eric von Lieres", "Marek Behr"], "categories": ["cs.CE", "76-10, 68T07 (Primary) 76D05, 35Q68 (Secondary)"], "primary_category": "Subjects:       Computational Engineering, Finance, and Science (cs.CE)", "pdf_link": null, "comments": "Comments:      24 pages, 18 figures", "url": "http://arxiv.org/abs/2507.11640v2", "summary": "Stirred tanks are vital in chemical and biotechnological processes,\nparticularly as bioreactors. Although computational fluid dynamics (CFD) is\nwidely used to model the flow in stirred tanks, its high computational\ncost$-$especially in multi-query scenarios for process design and\noptimization$-$drives the need for efficient data-driven surrogate models.\nHowever, acquiring sufficiently large datasets can be costly. Physics-informed\nneural networks (PINNs) offer a promising solution to reduce data requirements\nwhile maintaining accuracy by embedding underlying physics into neural network\n(NN) training. This study quantifies the data requirements of vanilla PINNs for\ndeveloping surrogate models of a flow field in a 2D stirred tank. We compare\nthese requirements with classical supervised neural networks and\nboundary-informed neural networks (BINNs). Our findings demonstrate that\nsurrogate models can achieve prediction errors around 3% across Reynolds\nnumbers from 50 to 5000 using as few as six datapoints. Moreover, employing an\napproximation of the velocity profile in place of real data labels leads to\nprediction errors of around 2.5%. These results indicate that even with limited\nor approximate datasets, PINNs can be effectively trained to deliver high\naccuracy comparable to high-fidelity data.", "comment": "24 pages, 18 figures", "pdf_url": "http://arxiv.org/pdf/2507.11640v2", "cate": "cs.CE", "date": "2025-07-15", "updated": "2025-07-18", "AI": {"title_translation": "物理信息神经网络在二维搅拌罐流场替代模型中数据需求量化研究", "tldr": "研究表明，物理信息神经网络（PINNs）能以极少量数据（甚至近似数据）在二维搅拌罐流场替代建模中实现高精度预测。", "motivation": "计算流体力学（CFD）在搅拌罐流场建模中计算成本高昂，尤其在多查询场景下，因此需要高效的数据驱动替代模型。然而，获取大量数据集成本高昂，促使研究人员寻求减少数据需求的方法。", "method": "本研究量化了传统物理信息神经网络（PINNs）在开发二维搅拌罐流场替代模型中的数据需求。研究将PINNs的数据需求与经典监督神经网络和边界信息神经网络（BINNs）进行了比较。", "result": "研究发现，替代模型在使用低至六个数据点时，在雷诺数50到5000范围内可实现约3%的预测误差。此外，使用近似速度剖面代替真实数据标签，预测误差约为2.5%。", "conclusion": "这些结果表明，即使在数据有限或近似的情况下，物理信息神经网络（PINNs）也能有效训练，提供与高保真数据相当的高精度。", "translation": "搅拌罐在化工和生物技术过程中至关重要，尤其作为生物反应器。尽管计算流体力学（CFD）广泛用于模拟搅拌罐中的流动，但其高昂的计算成本——特别是在用于工艺设计和优化的多查询场景中——推动了对高效数据驱动替代模型的需求。然而，获取足够大的数据集可能成本高昂。物理信息神经网络（PINNs）通过将基础物理嵌入到神经网络（NN）训练中，提供了一种有前景的解决方案，以减少数据需求同时保持精度。本研究量化了传统PINNs在开发二维搅拌罐流场替代模型中的数据需求。我们将这些需求与经典监督神经网络和边界信息神经网络（BINNs）进行了比较。我们的研究结果表明，替代模型在使用低至六个数据点时，在雷诺数50到5000范围内可实现约3%的预测误差。此外，使用近似速度剖面代替真实数据标签，预测误差约为2.5%。这些结果表明，即使数据有限或近似，PINNs也能有效训练，提供与高保真数据相当的高精度。", "summary": "本研究旨在量化物理信息神经网络（PINNs）在二维搅拌罐流场替代建模中的数据需求，以解决传统计算流体力学（CFD）的高计算成本问题。通过与经典神经网络和边界信息神经网络的比较，结果显示PINNs即使仅使用少量数据点（如六个）或近似速度剖面，也能在宽泛的雷诺数范围内实现高精度预测（误差约2.5%-3%），证明了PINNs在数据受限情况下构建高效高精度替代模型的潜力。", "keywords": "物理信息神经网络, 替代模型, 搅拌罐, 数据需求, 流场", "comments": "该研究的创新之处在于量化了PINNs在特定工程应用中所需的数据量，并证明了其在数据稀疏或近似情况下的高鲁棒性和准确性。这对于降低工业应用中数据采集成本和加速模型开发具有重要意义。其重要性体现在为数据驱动的替代建模提供了新的思路，尤其是在传统CFD成本高昂的复杂流体系统建模中。"}}
{"id": "2507.13523", "title": "Distributed Acoustic Sensing for Environmental Monitoring, and Newtonian Noise Mitigation:Comparable Sensitivity to Seismometers", "authors": ["Reinhardt Rading", "Fracensca Badaracco", "Spiridon Beis", "Katharina Sophie Isleif", "Paul Ophardt", "Wanda Vossius", "the WAVE Collaboration"], "categories": ["astro-ph.IM", "eess.SP", "gr-qc"], "primary_category": "Subjects:       Instrumentation and Methods for Astrophysics (astro-ph.IM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13523v1", "summary": "Newtonian noise limits the low-frequency sensitivity of ground-based\ngravitational wave detectors. While seismometers and geophones are commonly\nemployed to monitor ground motion for Newtonian noise cancellation, their\nlimited spatial coverage and high deployment costs hinder scalability. In this\nstudy, we demonstrate that distributed acoustic sensing offers a viable and\nscalable alternative, providing performance comparable to that of conventional\nseismic instruments. Using data from acoustic sensing and colocated\nseismometers during both natural and controlled events, we observe a strong\ncorrelation, exceeding 0.8, between the two sensor types in the 3 to 20 Hz\nfrequency band relevant for Newtonian noise. Moreover, when distributed\nacoustic sensing data are used to predict geophone signals, the correlation\nremains high, above 0.7, indicating that distributed acoustic sensing\naccurately captures both the spatial and spectral features of ground motion. As\na case study, we apply distributed acoustic sensing data to cancel noise\nrecorded by the vertical component of a seismometer and compare the results\nwith those obtained using geophone data for the same task. Both distributed\nacoustic sensing and geophone-based cancellations yield a residual noise factor\nof 0.11 at 20 Hz. These findings confirm the feasibility of using distributed\nacoustic sensing for Newtonian noise mitigation and highlight its potential, in\ncombination with traditional seismic sensors, to improve environmental\nmonitoring and noise suppression in current and next-generation gravitational\nwave observatories.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13523v1", "cate": "astro-ph.IM", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "分布式声学传感在环境监测和牛顿噪声抑制中的应用：与地震仪相当的灵敏度", "tldr": "分布式声学传感（DAS）可作为传统地震仪的替代方案，用于引力波探测器中的牛顿噪声抑制，并显示出可比的性能和噪声消除能力。", "motivation": "地基引力波探测器的低频灵敏度受到牛顿噪声的限制。虽然地震仪和检波器常用于监测地面运动以消除牛顿噪声，但其空间覆盖有限且部署成本高昂，阻碍了可扩展性。", "method": "本研究使用分布式声学传感（DAS）数据与同位地震仪数据进行对比，研究了在自然和受控事件中两种传感器类型在3到20 Hz频率范围内的相关性。此外，还使用DAS数据预测检波器信号，并应用DAS数据来消除地震仪垂直分量记录的噪声，并与使用检波器数据获得的结果进行比较。", "result": "分布式声学传感与同位地震仪在3到20 Hz频率范围内表现出超过0.8的强相关性。当DAS数据用于预测检波器信号时，相关性仍保持在0.7以上。使用DAS和检波器进行噪声消除，在20 Hz时均产生了0.11的残余噪声因子。", "conclusion": "这些发现证实了使用分布式声学传感进行牛顿噪声抑制的可行性，并强调了其与传统地震传感器结合的潜力，以改善当前和下一代引力波观测站的环境监测和噪声抑制。", "translation": "牛顿噪声限制了地基引力波探测器的低频灵敏度。尽管地震仪和检波器通常用于监测地面运动以抵消牛顿噪声，但其有限的空间覆盖和高昂的部署成本阻碍了可扩展性。在本研究中，我们证明分布式声学传感提供了一种可行且可扩展的替代方案，其性能可与传统地震仪器相媲美。利用声学传感和同位地震仪在自然事件和受控事件期间的数据，我们观察到两种传感器类型在与牛顿噪声相关的3至20赫兹频率范围内具有超过0.8的强相关性。此外，当使用分布式声学传感数据预测检波器信号时，相关性仍然很高，超过0.7，这表明分布式声学传感准确地捕捉了地面运动的空间和频谱特征。作为一个案例研究，我们应用分布式声学传感数据来消除地震仪垂直分量记录的噪声，并将结果与使用检波器数据完成相同任务获得的结果进行比较。分布式声学传感和基于检波器的抵消在20赫兹时均产生了0.11的残余噪声因子。这些发现证实了使用分布式声学传感进行牛顿噪声抑制的可行性，并突出了其与传统地震传感器结合的潜力，以改善当前和下一代引力波观测站的环境监测和噪声抑制。", "summary": "本研究提出分布式声学传感（DAS）作为引力波探测器中牛顿噪声监测和抑制的可扩展替代方案。通过与传统地震仪和检波器的数据对比，研究表明DAS在3-20 Hz频率范围内与现有传感器具有高度相关性（>0.8），并且能准确捕捉地面运动的空间和频谱特征。在噪声消除任务中，DAS表现出与检波器相当的性能，将20 Hz的残余噪声因子降低到0.11。这证实了DAS在环境监测和牛顿噪声抑制方面的潜力，可用于当前和未来的引力波观测站。", "keywords": "分布式声学传感, 牛顿噪声, 引力波探测器, 地震监测, 噪声抑制", "comments": "该论文创新性地提出并验证了分布式声学传感（DAS）在引力波探测器牛顿噪声抑制中的应用，解决了传统地震仪空间覆盖和成本的局限性。DAS的高空间分辨率和可扩展性是其重要优势，对于下一代引力波观测站的噪声抑制和环境监测具有重要意义。"}}
{"id": "2407.14506", "title": "On Pre-training of Multimodal Language Models Customized for Chart Understanding", "authors": ["Wan-Cyuan Fan", "Yen-Chun Chen", "Mengchen Liu", "Lu Yuan", "Leonid Sigal"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      NeurIPS 2024 Workshop on Adaptive Foundation Models", "url": "http://arxiv.org/abs/2407.14506v3", "summary": "Recent studies customizing Multimodal Large Language Models (MLLMs) for\ndomain-specific tasks have yielded promising results, especially in the field\nof scientific chart comprehension. These studies generally utilize visual\ninstruction tuning with specialized datasets to enhance question and answer\n(QA) accuracy within the chart domain. However, they often neglect the\nfundamental discrepancy between natural image-caption pre-training data and\ndigital chart image-QA data, particularly in the models' capacity to extract\nunderlying numeric values from charts. This paper tackles this oversight by\nexploring the training processes necessary to improve MLLMs' comprehension of\ncharts. We present three key findings: (1) Incorporating raw data values in\nalignment pre-training markedly improves comprehension of chart data. (2)\nReplacing images with their textual representation randomly during end-to-end\nfine-tuning transfer the language reasoning capability to chart interpretation\nskills. (3) Requiring the model to first extract the underlying chart data and\nthen answer the question in the fine-tuning can further improve the accuracy.\nConsequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart\ncomprehension. CHOPINLLM effectively interprets various types of charts,\nincluding unannotated ones, while maintaining robust reasoning abilities.\nFurthermore, we establish a new benchmark to evaluate MLLMs' understanding of\ndifferent chart types across various comprehension levels. Experimental results\nshow that CHOPINLLM exhibits strong performance in understanding both annotated\nand unannotated charts across a wide range of types.", "comment": "NeurIPS 2024 Workshop on Adaptive Foundation Models", "pdf_url": "http://arxiv.org/pdf/2407.14506v3", "cate": "cs.CV", "date": "2024-07-19", "updated": "2025-07-17", "AI": {"title_translation": "关于定制化用于图表理解的多模态语言模型预训练", "tldr": "本文探讨了改进多模态语言模型（MLLMs）图表理解能力的训练过程，并提出了CHOPINLLM模型和新基准。", "motivation": "现有的多模态大语言模型（MLLMs）在图表理解方面，特别是提取底层数值的能力上，忽略了自然图像-文本预训练数据与数字图表图像-问答数据之间的根本差异。", "method": "本文提出了三种改进MLLMs图表理解的训练方法：1) 在对齐预训练中加入原始数据值；2) 在端到端微调中随机用文本表示替换图像，以转移语言推理能力；3) 在微调中要求模型先提取底层图表数据再回答问题。基于这些发现，本文引入了CHOPINLLM模型。", "result": "本文引入了CHOPINLLM，一个专为深度图表理解定制的MLLM，它能有效解释包括未标注图表在内的各种图表，并保持强大的推理能力。此外，本文建立了一个新的基准来评估MLLM在不同图表类型和理解水平上的表现。实验结果表明，CHOPINLLM在理解标注和未标注图表方面表现出色。", "conclusion": "通过探索和改进训练过程，本文提出的CHOPINLLM模型显著提升了多模态语言模型对各种图表的理解能力，包括提取底层数据和进行推理，并建立了新的评估基准。", "translation": "最近定制多模态大型语言模型（MLLMs）用于特定领域任务的研究取得了可喜的成果，尤其是在科学图表理解领域。这些研究通常利用视觉指令微调和专门数据集来提高图表领域内的问答（QA）准确性。然而，它们常常忽略了自然图像-文本预训练数据与数字图表图像-问答数据之间的根本差异，特别是在模型从图表中提取底层数值的能力方面。本文通过探索改善MLLMs图表理解所需的训练过程来解决这一疏忽。我们提出了三个关键发现：（1）在对齐预训练中加入原始数据值显著提高了对图表数据的理解。（2）在端到端微调中随机用文本表示替换图像，将语言推理能力转移到图表解释技能上。（3）在微调中要求模型首先提取底层图表数据，然后再回答问题，可以进一步提高准确性。因此，我们引入了CHOPINLLM，一个专为深度图表理解定制的MLLM。CHOPINLLM能够有效解释各种类型的图表，包括未标注的图表，同时保持强大的推理能力。此外，我们建立了一个新的基准来评估MLLMs在不同图表类型和各种理解水平上的理解能力。实验结果表明，CHOPINLLM在理解各种类型、标注和未标注的图表方面表现出强大的性能。", "summary": "本文针对现有MLLMs在图表理解中忽视底层数值提取的问题，探索了改进其图表理解能力的训练过程。研究发现，在预训练中整合原始数据值、在微调中通过文本替换图像转移语言推理能力以及要求模型先提取数据再回答问题，能显著提升图表理解准确性。在此基础上，本文提出了CHOPINLLM模型，一个专为深度图表理解定制的MLLM，它能有效处理各种图表类型（包括未标注图表），并保持强大的推理能力。此外，本文还建立了一个新的基准来评估MLLMs的图表理解能力。实验证明CHOPINLLM表现优异。", "keywords": "多模态语言模型, 图表理解, 预训练, CHOPINLLM, 数据提取", "comments": "本文解决了多模态语言模型在图表理解，特别是数值提取方面的关键不足。其创新点在于提出了三种具体的训练策略来弥补自然图像预训练与图表数据之间的鸿沟，并引入了专门的模型CHOPINLLM和新的评估基准，这对于推动MLLMs在科学和数据可视化领域的应用具有重要意义。"}}
{"id": "2410.07094", "title": "An Approach for Auto Generation of Labeling Functions for Software Engineering Chatbots", "authors": ["Ebube Alor", "Ahmad Abdellatif", "SayedHassan Khatoonabadi", "Emad Shihab"], "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      Submitted to ACM Transactions on Software Engineering and Methodology for review", "url": "http://arxiv.org/abs/2410.07094v2", "summary": "Software engineering (SE) chatbots are increasingly gaining attention for\ntheir role in enhancing development processes. At the core of chatbots are\nNatural Language Understanding platforms (NLUs), which enable them to\ncomprehend user queries but require labeled data for training. However,\nacquiring such labeled data for SE chatbots is challenging due to the scarcity\nof high-quality datasets, as training requires specialized vocabulary and\nphrases not found in typical language datasets. Consequently, developers often\nresort to manually annotating user queries -- a time-consuming and\nresource-intensive process. Previous approaches require human intervention to\ngenerate rules, called labeling functions (LFs), that categorize queries based\non specific patterns. To address this issue, we propose an approach to\nautomatically generate LFs by extracting patterns from labeled user queries. We\nevaluate our approach on four SE datasets and measure performance improvement\nfrom training NLUs on queries labeled by the generated LFs. The generated LFs\neffectively label data with AUC scores up to 85.3% and NLU performance\nimprovements up to 27.2%. Furthermore, our results show that the number of LFs\naffects labeling performance. We believe that our approach can save time and\nresources in labeling users' queries, allowing practitioners to focus on core\nchatbot functionalities rather than manually labeling queries.", "comment": "Submitted to ACM Transactions on Software Engineering and Methodology\n  for review", "pdf_url": "http://arxiv.org/pdf/2410.07094v2", "cate": "cs.SE", "date": "2024-10-09", "updated": "2025-07-17", "AI": {"title_translation": "软件工程聊天机器人标注函数自动生成方法", "tldr": "该研究提出了一种自动生成标注函数的方法，用于软件工程聊天机器人，以解决手动标注用户查询数据耗时耗力的问题，并有效提升了NLU性能。", "motivation": "软件工程（SE）聊天机器人需要大量标注数据来训练自然语言理解（NLU）平台，但高质量的SE数据集稀缺，且训练需要专业词汇。开发者通常需要手动标注用户查询，这是一个耗时且资源密集的过程。现有方法生成标注函数（LFs）仍需人工干预。", "method": "提出了一种通过从已标注用户查询中提取模式来自动生成标注函数（LFs）的方法。", "result": "生成的LFs有效标注数据，AUC分数高达85.3%；NLU性能提升高达27.2%。研究还发现LFs的数量会影响标注性能。", "conclusion": "该方法可以节省用户查询标注的时间和资源，使开发者能够专注于核心聊天机器人功能，而非手动标注查询。", "translation": "软件工程（SE）聊天机器人在增强开发流程中的作用日益受到关注。聊天机器人的核心是自然语言理解（NLU）平台，它们使聊天机器人能够理解用户查询，但需要标注数据进行训练。然而，由于高质量数据集的稀缺性，获取用于SE聊天机器人的此类标注数据具有挑战性，因为训练需要典型语言数据集中不包含的专业词汇和短语。因此，开发者通常诉诸于手动标注用户查询——这是一个耗时且资源密集的过程。以前的方法需要人工干预来生成规则，称为标注函数（LFs），这些规则根据特定模式对查询进行分类。为了解决这个问题，我们提出了一种通过从已标注用户查询中提取模式来自动生成LFs的方法。我们在四个SE数据集上评估了我们的方法，并测量了通过生成的LFs标注的查询训练NLU的性能改进。生成的LFs有效标注数据，AUC分数高达85.3%，NLU性能提升高达27.2%。此外，我们的结果表明LFs的数量会影响标注性能。我们相信我们的方法可以节省标注用户查询的时间和资源，使实践者能够专注于核心聊天机器人功能，而不是手动标注查询。", "summary": "本文提出了一种自动生成软件工程聊天机器人标注函数（LFs）的方法，旨在解决高质量SE数据集稀缺及手动标注用户查询耗时耗力的问题。该方法通过从现有标注查询中提取模式来自动化LFs的生成过程，并在四个SE数据集上进行了评估。结果显示，该方法能有效标注数据（AUC高达85.3%）并显著提升NLU性能（高达27.2%），从而节省了开发者的时间和资源。", "keywords": "软件工程聊天机器人, 标注函数, 自动生成, 自然语言理解, 数据标注", "comments": "这项研究通过自动化标注函数生成，有效解决了软件工程领域NLU训练数据稀缺和手动标注效率低下的痛点。其创新性在于提出了从已标注查询中提取模式来自动生成LFs，显著提升了数据标注效率和NLU模型性能。对于SE聊天机器人的开发而言，这是一个重要的进步，能够让开发者将更多精力投入到核心功能开发中。"}}
{"id": "2507.13517", "title": "The Stated Protocol: A Decentralized Framework for Digital Diplomacy", "authors": ["Christopher J. P. Rieckmann"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13517v1", "summary": "International coordination faces significant friction due to reliance on\nperiodic summits, bilateral consultations, and fragmented communication\nchannels that impede rapid collective responses to emerging global challenges\nwhile limiting transparency to constituents. We present the Stated Protocol, a\ndecentralized framework that enables organizations to coordinate through\nstandardized text statements published on their website domains. While\napplicable to all organizations, this work focuses primarily on the application\nin international relations, where the protocol enables rapid consensus\ndiscovery and collective decision-making without relying on centralized social\nmedia platforms. We explore specific applications: (1) faster treaty\nnegotiation through incremental micro-agreements that can be signed digitally\nwithin hours rather than months, (2) continuous and transparent operation of\ninternational institutions through asynchronous decision-making, (3)\ncoordinated signaling from local governments to national authorities through\nsimultaneous statement publication, and (4) coalition formation among\nnon-governmental organizations through transparent position aggregation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13517v1", "cate": "cs.CY", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "声明协议：一种数字外交的去中心化框架", "tldr": "该论文提出了“声明协议”，一个去中心化的框架，通过在组织网站上发布标准化文本声明，实现国际协调，旨在解决传统外交的摩擦和透明度问题。", "motivation": "国际协调因依赖定期峰会、双边磋商和碎片化的沟通渠道而面临显著摩擦，这阻碍了对新兴全球挑战的快速集体响应，并限制了对选民的透明度。", "method": "该论文提出了“声明协议”，一个去中心化的框架，使组织能够通过在其网站域名上发布的标准化文本声明进行协调。它专注于国际关系中的应用，通过异步决策和增量微协议实现快速共识发现和集体决策，无需依赖中心化社交媒体平台。", "result": "该协议的应用包括：1) 通过数小时而非数月内可数字签署的增量微协议，加速条约谈判；2) 通过异步决策，实现国际机构的持续透明运作；3) 通过同步声明发布，实现地方政府向国家当局的协调信号；4) 通过透明的立场聚合，促进非政府组织之间的联盟形成。", "conclusion": "“声明协议”提供了一个去中心化的框架，能够显著提高国际协调的效率、速度和透明度，尤其是在数字外交和全球响应方面。", "translation": "国际协调由于依赖定期峰会、双边磋商和碎片化的沟通渠道而面临显著摩擦，这阻碍了对新兴全球挑战的快速集体响应，同时限制了对选民的透明度。我们提出了“声明协议”，一个去中心化框架，使组织能够通过在其网站域名上发布的标准化文本声明进行协调。虽然适用于所有组织，但这项工作主要关注其在国际关系中的应用，在该领域，该协议无需依赖中心化社交媒体平台即可实现快速共识发现和集体决策。我们探讨了具体的应用：(1) 通过可在数小时而非数月内数字签署的增量微协议，加速条约谈判；(2) 通过异步决策，实现国际机构的持续和透明运作；(3) 通过同步声明发布，实现地方政府向国家当局的协调信号；(4) 通过透明的立场聚合，促进非政府组织之间的联盟形成。", "summary": "该论文介绍了“声明协议”，一个旨在解决传统国际协调中摩擦和缺乏透明度的去中心化框架。该协议允许组织通过在其网站上发布标准化文本声明进行协调，从而实现快速共识发现和集体决策，特别是在国际关系领域。其应用包括加速条约谈判、促进国际机构的透明运作、协调地方政府信号以及形成非政府组织联盟。", "keywords": "去中心化框架, 数字外交, 国际协调, 声明协议, 共识发现", "comments": "该论文提出了一种新颖的去中心化数字外交方法，通过利用组织自有网站发布标准化声明，绕过了中心化平台的限制，提高了效率和透明度。其创新点在于将传统外交的“声明”概念与去中心化技术相结合，为国际协调提供了一种潜在的、更灵活的替代方案。该框架有望显著加速决策过程并增强公共透明度。"}}
{"id": "2507.13974", "title": "Leveraging Pathology Foundation Models for Panoptic Segmentation of Melanoma in H&E Images", "authors": ["Jiaqi Lv", "Yijie Zhu", "Carmen Guadalupe Colin Tenorio", "Brinder Singh Chohan", "Mark Eastwood", "Shan E Ahmed Raza"], "categories": ["eess.IV", "cs.CV", "q-bio.QM"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Accepted by MIUA 2025", "url": "http://arxiv.org/abs/2507.13974v1", "summary": "Melanoma is an aggressive form of skin cancer with rapid progression and high\nmetastatic potential. Accurate characterisation of tissue morphology in\nmelanoma is crucial for prognosis and treatment planning. However, manual\nsegmentation of tissue regions from haematoxylin and eosin (H&E) stained\nwhole-slide images (WSIs) is labour-intensive and prone to inter-observer\nvariability, this motivates the need for reliable automated tissue segmentation\nmethods. In this study, we propose a novel deep learning network for the\nsegmentation of five tissue classes in melanoma H&E images. Our approach\nleverages Virchow2, a pathology foundation model trained on 3.1 million\nhistopathology images as a feature extractor. These features are fused with the\noriginal RGB images and subsequently processed by an encoder-decoder\nsegmentation network (Efficient-UNet) to produce accurate segmentation maps.\nThe proposed model achieved first place in the tissue segmentation task of the\nPUMA Grand Challenge, demonstrating robust performance and generalizability.\nOur results show the potential and efficacy of incorporating pathology\nfoundation models into segmentation networks to accelerate computational\npathology workflows.", "comment": "Accepted by MIUA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13974v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "利用病理基础模型对H&E图像中的黑色素瘤进行全景分割", "tldr": "该研究提出了一种利用病理基础模型（Virchow2）进行黑色素瘤H&E图像中组织全景分割的深度学习方法，并在PUMA大挑战中获得第一名，展示了其强大的性能和泛化能力。", "motivation": "从苏木精和伊红 (H&E) 染色的全玻片图像 (WSI) 中手动分割黑色素瘤组织区域是劳动密集型且容易出现观察者间差异的，因此需要可靠的自动化组织分割方法。", "method": "提出了一种新颖的深度学习网络，利用在310万张组织病理学图像上训练的Virchow2病理基础模型作为特征提取器。这些特征与原始RGB图像融合，随后由编码器-解码器分割网络（Efficient-UNet）处理，以生成准确的五种组织类别的分割图。", "result": "所提出的模型在PUMA大挑战的组织分割任务中获得第一名，展示了强大的性能和泛化能力。", "conclusion": "将病理学基础模型整合到分割网络中具有加速计算病理学工作流程的潜力和功效。", "translation": "黑色素瘤是一种侵袭性皮肤癌，进展迅速且转移潜力高。准确表征黑色素瘤的组织形态对于预后和治疗计划至关重要。然而，从苏木精和伊红 (H&E) 染色的全玻片图像 (WSI) 中手动分割组织区域是劳动密集型且容易出现观察者间差异的，这促使人们需要可靠的自动化组织分割方法。在本研究中，我们提出了一种新颖的深度学习网络，用于对黑色素瘤 H&E 图像中的五种组织类别进行分割。我们的方法利用 Virchow2（一个在 310 万张组织病理学图像上训练的病理学基础模型）作为特征提取器。这些特征与原始 RGB 图像融合，随后由编码器-解码器分割网络 (Efficient-UNet) 处理，以生成准确的分割图。所提出的模型在 PUMA 大挑战的组织分割任务中获得第一名，展示了强大的性能和泛化能力。我们的结果表明，将病理学基础模型整合到分割网络中具有加速计算病理学工作流程的潜力。", "summary": "本文介绍了一种新颖的深度学习网络，用于自动化对黑色素瘤H&E图像中五种组织类别进行全景分割。该方法创新性地利用大型病理学基础模型Virchow2作为特征提取器，将其提取的特征与原始RGB图像结合，并通过Efficient-UNet进行处理以实现精确分割。该模型在PUMA大挑战的组织分割任务中获得第一名，证明了其强大的性能，并验证了整合病理学基础模型以增强计算病理学工作流程的有效性。", "keywords": "黑色素瘤, 全景分割, 病理基础模型, H&E图像, 深度学习", "comments": "该论文通过将大规模预训练的病理学基础模型（Virchow2）有效地整合到分割流程中，提出了一种创新方法。这种利用在大量数据集上训练的强大特征提取器，显著提升了模型的性能和泛化能力，其在具有挑战性的竞赛中名列前茅也证明了这一点。该研究突显了基础模型在医学图像分析中日益增长的重要性和潜力，尤其是在自动化计算病理学中复杂且劳动密集型任务方面的应用。"}}
{"id": "2411.03537", "title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild", "authors": ["Kevin Tirta Wijaya", "Minghao Guo", "Michael Sun", "Hans-Peter Seidel", "Wojciech Matusik", "Vahid Babaei"], "categories": ["cs.LG", "cs.AI", "physics.chem-ph", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.03537v2", "summary": "Molecular deep learning models have achieved remarkable success in property\nprediction, but they often require large amounts of labeled data. The challenge\nis that, in real-world applications, labels are extremely scarce, as obtaining\nthem through laboratory experimentation is both expensive and time-consuming.\nIn this work, we introduce MoleVers, a versatile pretrained molecular model\ndesigned for various types of molecular property prediction in the wild, i.e.,\nwhere experimentally-validated labels are scarce. MoleVers employs a two-stage\npretraining strategy. In the first stage, it learns molecular representations\nfrom unlabeled data through masked atom prediction and extreme denoising, a\nnovel task enabled by our newly introduced branching encoder architecture and\ndynamic noise scale sampling. In the second stage, the model refines these\nrepresentations through predictions of auxiliary properties derived from\ncomputational methods, such as the density functional theory or large language\nmodels. Evaluation on 22 small, experimentally-validated datasets demonstrates\nthat MoleVers achieves state-of-the-art performance, highlighting the\neffectiveness of its two-stage framework in producing generalizable molecular\nrepresentations for diverse downstream properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.03537v2", "cate": "cs.LG", "date": "2024-11-05", "updated": "2025-07-18", "AI": {"title_translation": "野外分子性质预测的两阶段预训练", "tldr": "MoleVers引入了两阶段预训练策略，在标签稀缺的真实世界场景中实现了分子性质预测的最先进性能。", "motivation": "现有分子深度学习模型需要大量标记数据，但在实际应用中，通过实验获取分子性质标签既昂贵又耗时，导致标签极其稀缺。", "method": "本文提出了MoleVers，一个多功能的预训练分子模型，采用两阶段预训练策略。第一阶段，通过掩蔽原子预测和极端去噪（一项由新引入的分支编码器架构和动态噪声尺度采样实现的新颖任务）从未标记数据中学习分子表示。第二阶段，通过预测来自计算方法（如密度泛函理论或大型语言模型）的辅助属性来完善这些表示。", "result": "在22个小型实验验证数据集上，MoleVers取得了最先进的性能。", "conclusion": "MoleVers的两阶段框架能有效生成可泛化的分子表示，适用于各种下游性质预测，解决了真实世界中标签稀缺的问题。", "translation": "标题：野外分子性质预测的两阶段预训练\n摘要：分子深度学习模型在性质预测方面取得了显著成功，但它们通常需要大量的标记数据。挑战在于，在实际应用中，标签极其稀缺，因为通过实验室实验获取它们既昂贵又耗时。在这项工作中，我们引入了MoleVers，一个多功能的预训练分子模型，专为“野外”环境中的各种分子性质预测而设计，即实验验证标签稀缺的环境。MoleVers采用两阶段预训练策略。在第一阶段，它通过掩蔽原子预测和极端去噪（一项由我们新引入的分支编码器架构和动态噪声尺度采样实现的新颖任务）从未标记数据中学习分子表示。在第二阶段，模型通过预测来自计算方法（如密度泛函理论或大型语言模型）的辅助属性来完善这些表示。在22个小型实验验证数据集上的评估表明，MoleVers实现了最先进的性能，突出了其两阶段框架在为各种下游性质生成可泛化分子表示方面的有效性。", "summary": "本文提出了MoleVers，一个旨在解决实际应用中分子性质预测标签稀缺问题的两阶段预训练分子模型。该模型在第一阶段通过掩蔽原子预测和极端去噪从未标记数据中学习分子表示，第二阶段则通过预测计算衍生的辅助属性来精炼这些表示。在多个实验验证数据集上的评估表明，MoleVers达到了最先进的性能，证实了其两阶段框架在生成通用分子表示方面的有效性。", "keywords": "分子性质预测, 两阶段预训练, 标签稀缺, MoleVers, 分子表示学习", "comments": "该论文的创新点在于提出了一个针对标签稀缺场景的两阶段预训练策略MoleVers，特别是在第一阶段引入了分支编码器架构和动态噪声尺度采样的极端去噪任务。这为在数据受限的真实世界应用中实现高性能分子表示学习提供了有效途径，对于推动分子深度学习在实际应用中的发展具有重要意义。"}}
{"id": "2507.13379", "title": "Patterns, Models, and Challenges in Online Social Media: A Survey", "authors": ["Niccolò Di Marco", "Anita Bonetti", "Edoardo Di Martino", "Edoardo Loru", "Jacopo Nudo", "Mario Edoardo Pandolfo", "Giulio Pecile", "Emanuele Sangiorgio", "Irene Scalco", "Simon Zollo", "Matteo Cinelli", "Fabiana Zollo", "Walter Quattrociocchi"], "categories": ["cs.SI", "cs.CY"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13379v1", "summary": "The rise of digital platforms has enabled the large scale observation of\nindividual and collective behavior through high resolution interaction data.\nThis development has opened new analytical pathways for investigating how\ninformation circulates, how opinions evolve, and how coordination emerges in\nonline environments. Yet despite a growing body of research, the field remains\nfragmented and marked by methodological heterogeneity, limited model\nvalidation, and weak integration across domains. This survey offers a\nsystematic synthesis of empirical findings and formal models. We examine\nplatform-level regularities, assess the methodological architectures that\ngenerate them, and evaluate the extent to which current modeling frameworks\naccount for observed dynamics. The goal is to consolidate a shared empirical\nbaseline and clarify the structural constraints that shape inference in this\ndomain, laying the groundwork for more robust, comparable, and actionable\nanalyses of online social systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13379v1", "cate": "cs.SI", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "在线社交媒体中的模式、模型与挑战：一项综述", "tldr": "对在线社交媒体中的模式、模型和挑战进行系统综述，旨在整合现有研究并为未来分析奠定基础。", "motivation": "尽管数字平台提供了大规模观察行为的数据，但在线社交媒体研究领域仍然分散，存在方法学异质性、模型验证不足以及跨领域整合薄弱等问题。本综述旨在解决这些问题，整合经验发现和形式模型。", "method": "本综述通过系统地综合经验发现和形式模型来完成。具体方法包括：检查平台层面的规律性、评估产生这些规律的方法学架构，以及评估当前建模框架解释观察到动态的程度。", "result": "本综述旨在整合一个共享的经验基线，并阐明塑造该领域推断的结构性约束，为在线社会系统更稳健、可比较和可操作的分析奠定基础。抽象中未提及具体的实验结果或数据分析结果，而是综述本身的目标和预期产出。", "conclusion": "本综述旨在整合一个共享的经验基线，并阐明塑造该领域推断的结构性约束，从而为在线社会系统更稳健、可比较和可操作的分析奠定基础。", "translation": "数字平台的兴起使得通过高分辨率的交互数据大规模观察个体和集体行为成为可能。这一发展为研究信息如何传播、意见如何演变以及在线环境中协调如何出现开辟了新的分析途径。然而，尽管研究日益增多，该领域仍然分散，并以方法学异质性、有限的模型验证以及跨领域整合薄弱为特征。本综述系统地综合了经验发现和形式模型。我们审视了平台层面的规律性，评估了产生这些规律的方法学架构，并评估了当前建模框架解释观察到动态的程度。目标是巩固一个共享的经验基线，并阐明塑造该领域推断的结构性约束，为在线社会系统更稳健、可比较和可操作的分析奠定基础。", "summary": "本综述系统地审视了在线社交媒体中的模式、模型和挑战。鉴于该领域目前存在的碎片化、方法学异质性及模型验证不足等问题，本研究旨在综合经验发现与形式模型，以建立一个共享的经验基线，并明确影响该领域推断的结构性限制，从而为未来对在线社会系统进行更可靠、可比较和可操作的分析奠定基础。", "keywords": "在线社交媒体, 综述, 模式, 模型, 挑战", "comments": "该综述的重要性在于它试图解决在线社交媒体研究领域长期存在的碎片化和方法论不一致问题。通过系统地整合现有经验发现和形式模型，它为该领域提供了一个急需的统一视角和共享基线，这将有助于推动未来研究的规范化和比较性。其创新之处在于对平台层面规律性、方法学架构和现有模型框架的全面评估，为更稳健的分析奠定了基础。"}}
{"id": "2411.07799", "title": "Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and Re-Identification using Colored Point Clouds", "authors": ["Daniel Fusaro", "Federico Magistri", "Jens Behley", "Alberto Pretto", "Cyrill Stachniss"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Submitted to Computers and Electronics in Agriculture", "url": "http://arxiv.org/abs/2411.07799v2", "summary": "Accurate and consistent fruit monitoring over time is a key step toward\nautomated agricultural production systems. However, this task is inherently\ndifficult due to variations in fruit size, shape, occlusion, orientation, and\nthe dynamic nature of orchards where fruits may appear or disappear between\nobservations. In this article, we propose a novel method for fruit instance\nsegmentation and re-identification on 3D terrestrial point clouds collected\nover time. Our approach directly operates on dense colored point clouds,\ncapturing fine-grained 3D spatial detail. We segment individual fruits using a\nlearning-based instance segmentation method applied directly to the point\ncloud. For each segmented fruit, we extract a compact and discriminative\ndescriptor using a 3D sparse convolutional neural network. To track fruits\nacross different times, we introduce an attention-based matching network that\nassociates fruits with their counterparts from previous sessions. Matching is\nperformed using a probabilistic assignment scheme, selecting the most likely\nassociations across time. We evaluate our approach on real-world datasets of\nstrawberries and apples, demonstrating that it outperforms existing methods in\nboth instance segmentation and temporal re-identification, enabling robust and\nprecise fruit monitoring across complex and dynamic orchard environments.", "comment": "Submitted to Computers and Electronics in Agriculture", "pdf_url": "http://arxiv.org/pdf/2411.07799v2", "cate": "cs.CV", "date": "2024-11-12", "updated": "2025-07-18", "AI": {"title_translation": "基于彩色点云的3D实例分割与重识别的园艺作物果实时间序列监测", "tldr": "该论文提出了一种利用彩色点云进行3D实例分割和重识别的新方法，旨在实现对园艺作物果实准确、一致的时间序列监测，尤其适用于动态果园环境。", "motivation": "随着时间的推移对果实进行准确、一致的监测是自动化农业生产系统的关键一步。然而，由于果实大小、形状、遮挡、方向的变化以及果园的动态性质（果实可能在不同观测之间出现或消失），这项任务本身就非常困难，需要新的解决方案。", "method": "该方法直接在密集的彩色3D地面点云上操作，捕获精细的3D空间细节。它使用基于学习的实例分割方法来分割单个果实，并使用3D稀疏卷积神经网络为每个分割出的果实提取紧凑且具有区分性的描述符。为了在不同时间跟踪果实，该方法引入了一个基于注意力的匹配网络，通过概率分配方案将果实与之前会话中的对应物进行关联。", "result": "该方法在草莓和苹果的真实世界数据集上进行了评估，结果表明它在实例分割和时间重识别方面均优于现有方法。它能够在复杂和动态的果园环境中实现稳健而精确的果实监测。", "conclusion": "该论文成功开发并验证了一种新颖的园艺作物果实时间序列监测方法，该方法利用3D实例分割和重识别技术，直接处理彩色点云数据，有效克服了动态果园环境中的挑战，实现了稳健而精确的果实监测。", "translation": "随着时间的推移对果实进行准确、一致的监测是实现自动化农业生产系统的关键一步。然而，由于果实大小、形状、遮挡、方向的变化以及果园的动态性质（果实可能在不同观测之间出现或消失），这项任务本身就非常困难。在本文中，我们提出了一种新颖的方法，用于在随时间收集的3D地面点云上进行果实实例分割和重识别。我们的方法直接在密集的彩色点云上操作，捕获精细的3D空间细节。我们使用直接应用于点云的基于学习的实例分割方法来分割单个果实。对于每个分割出的果实，我们使用3D稀疏卷积神经网络提取一个紧凑且具有区分性的描述符。为了在不同时间跟踪果实，我们引入了一个基于注意力的匹配网络，将果实与之前会话中的对应物关联起来。匹配通过概率分配方案执行，选择跨时间最可能的关联。我们在草莓和苹果的真实世界数据集上评估了我们的方法，结果表明它在实例分割和时间重识别方面均优于现有方法，从而能够在复杂和动态的果园环境中实现稳健而精确的果实监测。", "summary": "本文提出了一种新颖的园艺作物果实时间序列监测方法，通过在彩色点云上进行3D实例分割和重识别实现。该方法直接处理密集的3D点云，利用基于学习的分割技术识别单个果实，并通过3D稀疏卷积神经网络提取果实描述符。为实现跨时间跟踪，引入了基于注意力的匹配网络和概率分配方案。在草莓和苹果数据集上的评估表明，该方法在分割和重识别方面均优于现有技术，能够实现复杂动态果园环境中的鲁棒精确果实监测。", "keywords": "3D实例分割, 果实监测, 重识别, 点云, 园艺自动化", "comments": "该论文的创新之处在于将3D实例分割与重识别技术相结合，直接应用于彩色点云数据，以实现时间序列的果实监测。通过使用3D稀疏卷积神经网络提取描述符和基于注意力的匹配网络进行跟踪，有效解决了动态果园环境中果实变化和遮挡带来的挑战。这项工作对于推动自动化农业生产系统的发展具有重要意义。"}}
{"id": "2507.13164", "title": "Feature-based analysis of oral narratives from Afrikaans and isiXhosa children", "authors": ["Emma Sharratt", "Annelien Smith", "Retief Louw", "Daleen Klop", "Febe de Wet", "Herman Kamper"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      SLaTE 2025 in Nijmegen, Netherlands", "url": "http://arxiv.org/abs/2507.13164v1", "summary": "Oral narrative skills are strong predictors of later literacy development.\nThis study examines the features of oral narratives from children who were\nidentified by experts as requiring intervention. Using simple machine learning\nmethods, we analyse recorded stories from four- and five-year-old Afrikaans-\nand isiXhosa-speaking children. Consistent with prior research, we identify\nlexical diversity (unique words) and length-based features (mean utterance\nlength) as indicators of typical development, but features like articulation\nrate prove less informative. Despite cross-linguistic variation in\npart-of-speech patterns, the use of specific verbs and auxiliaries associated\nwith goal-directed storytelling is correlated with a reduced likelihood of\nrequiring intervention. Our analysis of two linguistically distinct languages\nreveals both language-specific and shared predictors of narrative proficiency,\nwith implications for early assessment in multilingual contexts.", "comment": "SLaTE 2025 in Nijmegen, Netherlands", "pdf_url": "http://arxiv.org/pdf/2507.13164v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "基于特征的南非荷兰语和科萨语儿童口头叙事分析", "tldr": "该研究使用机器学习方法分析南非荷兰语和科萨语儿童的口头叙事特征，发现词汇多样性和特定动词与叙事能力相关，对多语言环境下的早期评估有意义。", "motivation": "口头叙事能力是后期读写能力发展的重要预测指标。本研究旨在分析被专家认为需要干预的儿童的口头叙事特征。", "method": "研究使用简单的机器学习方法，分析了四到五岁南非荷兰语和科萨语儿童的录音故事。", "result": "研究发现词汇多样性（独特词汇）和基于长度的特征（平均话语长度）是典型发展的指标，但发音速率等特征的信息量较少。尽管词性模式存在跨语言差异，与目标导向叙事相关的特定动词和助动词的使用与需要干预的可能性降低相关。分析揭示了语言特异性和共享的叙事能力预测因子。", "conclusion": "本研究揭示了南非荷兰语和科萨语儿童口头叙事能力的语言特异性和共享预测因子，对多语言环境下的早期评估具有重要意义。", "translation": "口头叙事能力是后期读写能力发展的有力预测指标。\n本研究考察了被专家认定为需要干预的儿童的口头叙事特征。\n我们使用简单的机器学习方法，分析了四到五岁南非荷兰语和科萨语儿童的录音故事。\n与先前的研究一致，我们发现词汇多样性（独特词汇）和基于长度的特征（平均话语长度）是典型发展的指标，但发音速率等特征的信息量较少。\n尽管词性模式存在跨语言差异，但与目标导向叙事相关的特定动词和助动词的使用与需要干预的可能性降低相关。\n我们对两种语言上截然不同的语言的分析揭示了叙事能力的语言特异性和共享预测因子，对多语言环境下的早期评估具有启示意义。", "summary": "本研究利用简单的机器学习方法，对来自南非荷兰语和科萨语儿童的口头叙事进行特征分析，这些儿童被专家认定为需要干预。研究发现词汇多样性、平均话语长度以及与目标导向叙事相关的特定动词和助动词是叙事能力的预测因子。该分析揭示了多语言环境下叙事能力的语言特异性和共享预测因子，对早期评估具有重要意义。", "keywords": "口头叙事, 机器学习, 语言评估, 南非荷兰语, 科萨语", "comments": "该研究的创新之处在于其对两种语言上截然不同的非洲语言（南非荷兰语和科萨语）的口头叙事进行分析，并运用机器学习方法识别叙事能力预测因子。这对于多语言环境下的儿童早期语言评估具有重要的实践意义，尤其是在识别需要干预的儿童方面。研究结果为跨语言的叙事能力评估提供了新的视角和证据。"}}
{"id": "2408.00998", "title": "FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation", "authors": ["Xiang Gao", "Jiaying Liu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted conference paper of ACM MM 2024", "url": "http://arxiv.org/abs/2408.00998v3", "summary": "Large-scale text-to-image diffusion models have been a revolutionary\nmilestone in the evolution of generative AI and multimodal technology, allowing\nwonderful image generation with natural-language text prompt. However, the\nissue of lacking controllability of such models restricts their practical\napplicability for real-life content creation. Thus, attention has been focused\non leveraging a reference image to control text-to-image synthesis, which is\nalso regarded as manipulating (or editing) a reference image as per a text\nprompt, namely, text-driven image-to-image translation. This paper contributes\na novel, concise, and efficient approach that adapts pre-trained large-scale\ntext-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a\nplug-and-play manner, realizing high-quality and versatile text-driven I2I\ntranslation without any model training, model fine-tuning, or online\noptimization process. To guide T2I generation with a reference image, we\npropose to decompose diverse guiding factors with different frequency bands of\ndiffusion features in the DCT spectral space, and accordingly devise a novel\nfrequency band substitution layer which realizes dynamic control of the\nreference image to the T2I generation result in a plug-and-play manner. We\ndemonstrate that our method allows flexible control over both guiding factor\nand guiding intensity of the reference image simply by tuning the type and\nbandwidth of the substituted frequency band, respectively. Extensive\nqualitative and quantitative experiments verify superiority of our approach\nover related methods in I2I translation visual quality, versatility, and\ncontrollability. The code is publicly available at:\nhttps://github.com/XiangGao1102/FBSDiff.", "comment": "Accepted conference paper of ACM MM 2024", "pdf_url": "http://arxiv.org/pdf/2408.00998v3", "cate": "cs.CV", "date": "2024-08-02", "updated": "2025-07-18", "AI": {"title_translation": "FBSDiff：可插拔的扩散特征频带替换用于高可控文本驱动图像翻译", "tldr": "提出FBSDiff，一种可插拔方法，通过频带替换将预训练文本到图像扩散模型转换为高可控的文本驱动图像到图像翻译，无需训练。", "motivation": "大规模文本到图像扩散模型缺乏可控性，限制了其在实际内容创作中的应用。", "method": "提出FBSDiff，一种新颖、简洁、高效的方法，以即插即用方式将预训练的大规模文本到图像（T2I）扩散模型适应图像到图像（I2I）范式。通过在DCT频谱空间中分解扩散特征的不同频带引导因子，并设计一种新的频带替换层，实现对参考图像的动态控制。", "result": "该方法通过调整替换频带的类型和带宽，可灵活控制参考图像的引导因子和引导强度。在I2I翻译视觉质量、多功能性和可控性方面，该方法优于相关方法。", "conclusion": "该论文提出FBSDiff，一种无需训练即可实现高可控文本驱动I2I翻译的可插拔方法，并在实验中验证了其优越性。", "translation": "大规模文本到图像扩散模型是生成式AI和多模态技术演进中的一个革命性里程碑，能够通过自然语言文本提示生成精彩图像。然而，此类模型缺乏可控性问题限制了它们在现实内容创作中的实际应用。因此，人们的注意力集中在利用参考图像来控制文本到图像合成，这也视为根据文本提示操纵（或编辑）参考图像，即文本驱动的图像到图像翻译。本文贡献了一种新颖、简洁、高效的方法，以即插即用的方式使预训练的大规模文本到图像（T2I）扩散模型适应图像到图像（I2I）范式，无需任何模型训练、模型微调或在线优化过程即可实现高质量、多功能的文本驱动I2I翻译。为了用参考图像引导T2I生成，我们提出在DCT频谱空间中分解具有不同频带的扩散特征的多种引导因子，并相应地设计了一种新颖的频带替换层，以即插即用的方式实现参考图像对T2I生成结果的动态控制。我们证明，我们的方法通过简单地调整替换频带的类型和带宽，可以分别灵活控制参考图像的引导因子和引导强度。广泛的定性和定量实验验证了我们的方法在I2I翻译视觉质量、多功能性和可控性方面优于相关方法。代码已公开：https://github.com/XiangGao1102/FBSDiff。", "summary": "本文提出FBSDiff，一种新颖且高效的即插即用方法，旨在解决大规模文本到图像扩散模型在图像到图像翻译中缺乏可控性的问题。该方法通过在DCT频谱空间中对扩散特征进行频带分解并引入频带替换层，实现了对参考图像引导的动态控制，从而在不进行任何训练或微调的情况下，提升了文本驱动I2I翻译的质量、多功能性和可控性。", "keywords": "文本到图像扩散模型, 图像到图像翻译, 可控性, 频带替换, 即插即用", "comments": "该论文的创新点在于提出了“频带替换”这一独特且高效的即插即用机制，将预训练的T2I模型无缝应用于I2I任务，显著提升了可控性，且无需额外的训练，这对于实际应用具有重要意义。"}}
{"id": "2507.13476", "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica", "authors": ["Jaber Daneshamooz", "Jessica Nguyen", "William Chen", "Sanjay Chandrasekaran", "Satyandra Guthula", "Ankit Gupta", "Arpit Gupta", "Walter Willinger"], "categories": ["cs.NI"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13476v1", "summary": "Machine learning models in networking suffer from the domain adaptation\nproblem; models trained in one domain often fail when deployed in different\nproduction environments. This paper presents the design and implementation of\nNetReplica, a system that addresses this challenge by generating training\ndatasets with two critical properties: realism in protocol dynamics and\ncontrollability of network conditions. NetReplica models networks as\ncollections of bottleneck links with specific attributes, achieves realism by\nleveraging production network traces, and enables controllability through fine\ngrained control knobs for each link attribute. Our evaluation using Puffer\ndemonstrates that NetReplica not only matches existing data characteristics but\ngenerates realistic samples that are underrepresented in or absent from Puffer\ndata. Models trained on NetReplica augmented datasets show substantially\nimproved generalizability, reducing transmission time prediction error by up to\n47% for challenging network conditions compared to models trained solely on\nPuffer data. This work represents a significant step toward solving the domain\nadaptation problem that has limited the effectiveness of ML based networking\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13476v1", "cate": "cs.NI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "解决网络机器学习领域适应性问题：使用NetReplica生成真实且可控的训练数据", "tldr": "NetReplica是一个生成真实且可控网络训练数据集的系统，用于解决网络中机器学习模型的领域适应性问题，显著提高了模型泛化能力。", "motivation": "网络中的机器学习模型存在领域适应性问题，即在一个域中训练的模型在不同生产环境中部署时往往会失效，这限制了基于机器学习的网络系统的有效性。", "method": "本文提出了NetReplica的设计与实现，该系统通过生成具有协议动态真实性和网络条件可控性两大关键属性的训练数据集来解决领域适应性问题。NetReplica将网络建模为具有特定属性的瓶颈链路集合，通过利用生产网络跟踪数据实现真实性，并通过对每个链路属性的精细控制旋钮实现可控性。", "result": "使用Puffer进行的评估表明，NetReplica不仅能匹配现有数据特征，还能生成Puffer数据中不足或缺失的真实样本。与仅使用Puffer数据训练的模型相比，在NetReplica增强数据集上训练的模型显示出显著改善的泛化能力，在具有挑战性的网络条件下，传输时间预测误差最高降低了47%。", "conclusion": "这项工作是解决限制基于机器学习的网络系统有效性的领域适应性问题的重要一步。", "translation": "网络中的机器学习模型面临领域适应性问题；在一个域中训练的模型在部署到不同的生产环境时往往会失效。本文介绍了NetReplica的设计与实现，这是一个通过生成具有两个关键属性——协议动态的真实性和网络条件的可控性——的训练数据集来解决这一挑战的系统。NetReplica将网络建模为瓶颈链路的集合，具有特定的属性，通过利用生产网络跟踪数据实现真实性，并通过对每个链路属性的精细控制旋钮实现可控性。我们使用Puffer进行的评估表明，NetReplica不仅能匹配现有数据特征，还能生成Puffer数据中不足或缺失的真实样本。与仅使用Puffer数据训练的模型相比，在NetReplica增强数据集上训练的模型显示出显著改善的泛化能力，在具有挑战性的网络条件下，传输时间预测误差最高降低了47%。这项工作代表着在解决限制基于机器学习的网络系统有效性的领域适应性问题方面迈出了重要一步。", "summary": "本文介绍了NetReplica系统，旨在解决网络机器学习模型的领域适应性问题。NetReplica通过生成具有协议动态真实性和网络条件可控性的训练数据集来弥补现有数据的不足。该系统将网络建模为瓶颈链路集合，并利用生产网络跟踪数据实现真实性，通过精细控制旋钮实现可控性。实验证明，NetReplica生成的数据能有效提升模型的泛化能力，在复杂网络条件下，传输时间预测误差降低了高达47%。", "keywords": "领域适应性, 机器学习, 网络, 训练数据生成, NetReplica", "comments": "NetReplica的创新之处在于其同时关注训练数据的“真实性”和“可控性”，这对于解决网络领域中ML模型的领域适应性问题至关重要。通过结合生产网络追踪和细粒度控制，它提供了一个实用且有效的解决方案，显著提高了模型在不同环境下的泛化能力，对ML在网络领域的应用具有重要意义。"}}
{"id": "2507.13614", "title": "Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models", "authors": ["Sergio E. Zanotto", "Segun Aroyehun"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      arXiv admin note: text overlap with arXiv:2412.03025", "url": "http://arxiv.org/abs/2507.13614v1", "summary": "The rapid advancements in large language models (LLMs) have significantly\nimproved their ability to generate natural language, making texts generated by\nLLMs increasingly indistinguishable from human-written texts. While recent\nresearch has primarily focused on using LLMs to classify text as either\nhuman-written and machine-generated texts, our study focus on characterizing\nthese texts using a set of linguistic features across different linguistic\nlevels such as morphology, syntax, and semantics. We select a dataset of\nhuman-written and machine-generated texts spanning 8 domains and produced by 11\ndifferent LLMs. We calculate different linguistic features such as dependency\nlength and emotionality and we use them for characterizing human-written and\nmachine-generated texts along with different sampling strategies, repetition\ncontrols and model release date. Our statistical analysis reveals that\nhuman-written texts tend to exhibit simpler syntactic structures and more\ndiverse semantic content. Furthermore, we calculate the variability of our set\nof features across models and domains. Both human and machine texts show\nstylistic diversity across domains, with humans displaying greater variation in\nour features. Finally, we apply style embeddings to further test variability\namong human-written and machine-generated texts. Notably, newer models output\ntext that is similarly variable, pointing to an homogenization of\nmachine-generated texts.", "comment": "arXiv admin note: text overlap with arXiv:2412.03025", "pdf_url": "http://arxiv.org/pdf/2507.13614v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "人类和大型语言模型生成文本的语言学和嵌入式分析", "tldr": "本研究通过语言学特征和风格嵌入来表征人类和LLM生成的文本，发现人类文本语法更简单、语义更多样，且新模型生成的文本趋于同质化。", "motivation": "大型语言模型（LLMs）生成的文本越来越难以与人类文本区分，而现有研究主要集中于文本分类。本研究旨在通过一系列语言学特征来刻画这些文本。", "method": "研究选取了一个包含8个领域和11个LLM生成的文本数据集，计算了依存长度、情感性等语言学特征，并结合采样策略、重复控制和模型发布日期进行分析。此外，还应用了风格嵌入来测试文本变异性。", "result": "统计分析显示，人类文本倾向于展现更简单的句法结构和更多样的语义内容。人类和机器文本在不同领域都表现出风格多样性，其中人类文本的特征变异性更大。值得注意的是，新模型输出的文本变异性相似，表明机器生成文本趋于同质化。", "conclusion": "人类文本在句法结构上更简单，语义内容更丰富多样。尽管人类和机器文本都表现出领域内的风格多样性，但人类文本的变异性更大。随着LLM的发展，新模型生成的文本呈现出同质化趋势。", "translation": "大型语言模型（LLMs）的快速发展显著提高了其生成自然语言的能力，使得LLM生成的文本越来越难以与人类手写文本区分。虽然最近的研究主要集中于使用LLMs将文本分类为人类手写文本或机器生成文本，但我们的研究重点是使用一组跨越形态、句法和语义等不同语言层面的语言学特征来刻画这些文本。我们选择了一个包含人类手写文本和机器生成文本的数据集，该数据集涵盖8个领域，由11种不同的LLM生成。我们计算了依存长度和情感性等不同的语言学特征，并结合不同的采样策略、重复控制和模型发布日期，用它们来刻画人类手写文本和机器生成文本。我们的统计分析表明，人类手写文本倾向于展现更简单的句法结构和更多样的语义内容。此外，我们计算了我们这组特征在不同模型和领域间的变异性。人类和机器文本在不同领域都表现出风格多样性，其中人类文本在我们的特征中显示出更大的变异性。最后，我们应用风格嵌入来进一步测试人类手写文本和机器生成文本之间的变异性。值得注意的是，较新的模型输出的文本变异性相似，这表明机器生成文本趋于同质化。", "summary": "本研究通过语言学特征和风格嵌入，对人类和大型语言模型（LLM）生成的文本进行深入分析。研究发现，人类文本通常具有更简单的句法结构和更丰富的语义多样性。尽管人类和机器文本在不同领域都展现出风格多样性，但人类文本的特征变异性更大。尤其值得关注的是，较新的LLM生成的文本变异性趋于一致，暗示了机器生成文本的同质化趋势。", "keywords": "大型语言模型, 语言学特征, 文本分析, 人机文本, 风格嵌入", "comments": "本研究的创新点在于不局限于文本分类，而是通过多层次的语言学特征和风格嵌入来深入刻画人类和机器生成文本的差异。其发现，特别是关于新LLM生成文本同质化的趋势，对于理解LLM的发展及其对内容创作的影响具有重要意义。"}}
{"id": "2507.14067", "title": "VLA-Mark: A cross modal watermark for large vision-language alignment model", "authors": ["Shuliang Liu", "Qi Zheng", "Jesse Jiaxi Xu", "Yibo Yan", "He Geng", "Aiwei Liu", "Peijie Jiang", "Jia Liu", "Yik-Cheung Tam", "Xuming Hu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14067v1", "summary": "Vision-language models demand watermarking solutions that protect\nintellectual property without compromising multimodal coherence. Existing text\nwatermarking methods disrupt visual-textual alignment through biased token\nselection and static strategies, leaving semantic-critical concepts vulnerable.\nWe propose VLA-Mark, a vision-aligned framework that embeds detectable\nwatermarks while preserving semantic fidelity through cross-modal coordination.\nOur approach integrates multiscale visual-textual alignment metrics, combining\nlocalized patch affinity, global semantic coherence, and contextual attention\npatterns, to guide watermark injection without model retraining. An\nentropy-sensitive mechanism dynamically balances watermark strength and\nsemantic preservation, prioritizing visual grounding during low-uncertainty\ngeneration phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than\nconventional methods, with near-perfect detection (98.8% AUC). The framework\ndemonstrates 96.1\\% attack resilience against attacks such as paraphrasing and\nsynonym substitution, while maintaining text-visual consistency, establishing\nnew standards for quality-preserving multimodal watermarking", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14067v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "VLA-Mark：一种用于大型视觉-语言对齐模型的跨模态水印", "tldr": "VLA-Mark是一种新型的跨模态水印框架，专为大型视觉-语言模型设计，能在保护知识产权的同时，通过整合多尺度视觉-文本对齐度量和熵敏感机制，有效保持语义连贯性，并展现出高检测率和强大的抗攻击能力。", "motivation": "现有文本水印方法通过有偏的令牌选择和静态策略破坏视觉-文本对齐，损害语义关键概念，导致视觉-语言模型在保护知识产权时难以维持多模态连贯性。", "method": "本文提出了VLA-Mark，一个视觉对齐框架，通过跨模态协调嵌入可检测水印并保持语义保真度。该方法整合了多尺度视觉-文本对齐度量（包括局部补丁亲和力、全局语义连贯性和上下文注意力模式），以指导水印注入而无需模型再训练。一个熵敏感机制动态平衡水印强度和语义保存，在低不确定性生成阶段优先考虑视觉基础。", "result": "实验表明，与传统方法相比，VLA-Mark的PPL降低了7.4%，BLEU提高了26.6%，检测率接近完美（98.8% AUC）。该框架对复述和同义词替换等攻击展现出96.1%的攻击弹性，同时保持了文本-视觉一致性。", "conclusion": "VLA-Mark框架通过保持文本-视觉一致性，为高质量的多模态水印建立了新标准，有效解决了视觉-语言模型知识产权保护与多模态连贯性之间的矛盾。", "translation": "视觉-语言模型需要水印解决方案来保护知识产权，同时不损害多模态连贯性。现有文本水印方法通过有偏的令牌选择和静态策略破坏视觉-文本对齐，使语义关键概念易受攻击。我们提出了VLA-Mark，一个视觉对齐框架，通过跨模态协调嵌入可检测水印，同时保持语义保真度。我们的方法整合了多尺度视觉-文本对齐度量，结合局部补丁亲和力、全局语义连贯性和上下文注意力模式，以指导水印注入而无需模型再训练。一个熵敏感机制动态平衡水印强度和语义保存，在低不确定性生成阶段优先考虑视觉基础。实验表明，与传统方法相比，PPL降低了7.4%，BLEU提高了26.6%，检测率接近完美（98.8% AUC）。该框架对复述和同义词替换等攻击展现出96.1%的攻击弹性，同时保持文本-视觉一致性，为高质量的多模态水印建立了新标准。", "summary": "VLA-Mark是一个针对大型视觉-语言模型提出的跨模态水印框架，旨在解决现有水印方法破坏多模态连贯性的问题。它通过整合多尺度视觉-文本对齐度量和熵敏感机制，在不重新训练模型的情况下，实现水印嵌入并保持语义忠实度。实验证明，VLA-Mark在生成质量、水印检测率和抗攻击性方面均优于传统方法，并能有效维护文本与视觉内容的一致性，为多模态水印设定了新标准。", "keywords": "VLA-Mark, 跨模态水印, 视觉-语言模型, 知识产权保护, 多模态对齐", "comments": "VLA-Mark的创新点在于其跨模态协调机制和熵敏感动态平衡策略，解决了传统文本水印在视觉-语言模型中导致语义失真的问题。无需模型再训练的特点显著降低了部署成本。其在保持高生成质量、高检测率和强抗攻击性方面的表现，使其在保护大型视觉-语言模型知识产权方面具有重要意义。"}}
{"id": "2507.14045", "title": "Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks", "authors": ["Israt Jahan", "Md Tahmid Rahman Laskar", "Chun Peng", "Jimmy Huang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Canadian AI 2025", "url": "http://arxiv.org/abs/2507.14045v1", "summary": "This paper presents a comprehensive evaluation of cost-efficient Large\nLanguage Models (LLMs) for diverse biomedical tasks spanning both text and\nimage modalities. We evaluated a range of closed-source and open-source LLMs on\ntasks such as biomedical text classification and generation, question\nanswering, and multimodal image processing. Our experimental findings indicate\nthat there is no single LLM that can consistently outperform others across all\ntasks. Instead, different LLMs excel in different tasks. While some\nclosed-source LLMs demonstrate strong performance on specific tasks, their\nopen-source counterparts achieve comparable results (sometimes even better),\nwith additional benefits like faster inference and enhanced privacy. Our\nexperimental results offer valuable insights for selecting models that are\noptimally suited for specific biomedical applications.", "comment": "Accepted at Canadian AI 2025", "pdf_url": "http://arxiv.org/pdf/2507.14045v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "评估经济高效的大型语言模型在基准生物医学任务中的有效性", "tldr": "本文评估了经济高效的大型语言模型（LLM）在生物医学文本和图像任务中的表现，发现没有一个LLM能在所有任务中都表现最佳，不同模型擅长不同任务，且开源LLM在性能上可与闭源模型媲美甚至更好，并具有推理速度快和隐私性增强的额外优势。", "motivation": "为了全面评估经济高效的大型语言模型（LLM）在各种生物医学任务中的表现，并为特定生物医学应用中模型的选择提供有价值的见解。", "method": "对一系列闭源和开源LLM进行了评估，任务涵盖生物医学文本分类和生成、问答以及多模态图像处理。", "result": "没有一个LLM能够在所有任务中始终优于其他模型，不同的LLM在不同的任务中表现出色。一些闭源LLM在特定任务上表现强大，但其开源对应模型也能取得可比（有时甚至更好）的结果，并具有更快的推理速度和增强的隐私性。", "conclusion": "实验结果为选择最适合特定生物医学应用的模型提供了宝贵的见解。", "translation": "本文对经济高效的大型语言模型（LLM）在涵盖文本和图像模态的各种生物医学任务中的表现进行了全面评估。我们评估了一系列闭源和开源LLM，涉及生物医学文本分类和生成、问答以及多模态图像处理等任务。我们的实验结果表明，没有一个LLM能够在所有任务中始终优于其他模型。相反，不同的LLM在不同的任务中表现出色。虽然一些闭源LLM在特定任务上表现出强大的性能，但其开源对应模型也能取得可比（有时甚至更好）的结果，并具有更快的推理速度和增强的隐私性等额外优势。我们的实验结果为选择最适合特定生物医学应用的模型提供了宝贵的见解。", "summary": "本文全面评估了经济高效的大型语言模型（LLM）在多种生物医学任务中的表现，包括文本分类、生成、问答和多模态图像处理。研究发现，没有单一的LLM能在所有任务中持续表现最佳，而是不同的模型在特定任务中表现出色。值得注意的是，开源LLM通常能达到与闭源模型相当甚至更好的性能，并提供更快的推理速度和增强的隐私性等优势，为生物医学应用中的模型选择提供了宝贵指导。", "keywords": "经济高效LLM, 生物医学任务, 开源LLM, 多模态处理, 模型评估", "comments": "该论文通过评估经济高效的LLM，为实际生物医学应用提供了实用见解。其发现开源模型可以与闭源模型竞争，尤其是在速度和隐私等优势方面，这对生物医学AI领域的更广泛采用和发展具有重要意义。强调针对特定任务选择模型而非“一刀切”的方法也是一个关键的启示。"}}
{"id": "2507.14099", "title": "Context-Aware Behavior Learning with Heuristic Motion Memory for Underwater Manipulation", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Michele Grimaldi", "Maria Koskinopoulou", "Yvan R. Petillot"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at 2025 IEEE International Conference on Intelligent Robots and Systems (IROS)", "url": "http://arxiv.org/abs/2507.14099v1", "summary": "Autonomous motion planning is critical for efficient and safe underwater\nmanipulation in dynamic marine environments. Current motion planning methods\noften fail to effectively utilize prior motion experiences and adapt to\nreal-time uncertainties inherent in underwater settings. In this paper, we\nintroduce an Adaptive Heuristic Motion Planner framework that integrates a\nHeuristic Motion Space (HMS) with Bayesian Networks to enhance motion planning\nfor autonomous underwater manipulation. Our approach employs the Probabilistic\nRoadmap (PRM) algorithm within HMS to optimize paths by minimizing a composite\ncost function that accounts for distance, uncertainty, energy consumption, and\nexecution time. By leveraging HMS, our framework significantly reduces the\nsearch space, thereby boosting computational performance and enabling real-time\nplanning capabilities. Bayesian Networks are utilized to dynamically update\nuncertainty estimates based on real-time sensor data and environmental\nconditions, thereby refining the joint probability of path success. Through\nextensive simulations and real-world test scenarios, we showcase the advantages\nof our method in terms of enhanced performance and robustness. This\nprobabilistic approach significantly advances the capability of autonomous\nunderwater robots, ensuring optimized motion planning in the face of dynamic\nmarine challenges.", "comment": "Accepted at 2025 IEEE International Conference on Intelligent Robots\n  and Systems (IROS)", "pdf_url": "http://arxiv.org/pdf/2507.14099v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "水下操控中基于启发式运动记忆的上下文感知行为学习", "tldr": "该论文提出了一种自适应启发式运动规划器框架，结合启发式运动空间和贝叶斯网络，以增强水下自主操控的运动规划能力，实现实时、鲁棒的路径优化。", "motivation": "当前的水下运动规划方法未能有效利用先前的运动经验，也无法适应水下环境中固有的实时不确定性，导致自主水下操控的效率和安全性受限。", "method": "本研究引入了一个自适应启发式运动规划器框架，该框架将启发式运动空间（HMS）与贝叶斯网络相结合。它在HMS内采用概率路线图（PRM）算法，通过最小化综合成本函数（考虑距离、不确定性、能耗和执行时间）来优化路径。贝叶斯网络用于根据实时传感器数据和环境条件动态更新不确定性估计，从而完善路径成功的联合概率。", "result": "该框架显著减少了搜索空间，从而提高了计算性能并实现了实时规划能力。通过广泛的模拟和真实世界测试场景，展示了该方法在增强性能和鲁棒性方面的优势。", "conclusion": "这种概率方法显著提升了自主水下机器人的能力，确保在动态海洋挑战面前实现优化的运动规划。", "translation": "自主运动规划对于动态海洋环境中高效、安全的水下操控至关重要。当前的运动规划方法通常未能有效利用先前的运动经验并适应水下环境中固有的实时不确定性。在本文中，我们引入了一个自适应启发式运动规划器框架，该框架将启发式运动空间（HMS）与贝叶斯网络相结合，以增强自主水下操控的运动规划能力。我们的方法在HMS内采用概率路线图（PRM）算法，通过最小化一个综合成本函数来优化路径，该函数考虑了距离、不确定性、能耗和执行时间。通过利用HMS，我们的框架显著减少了搜索空间，从而提高了计算性能并实现了实时规划能力。贝叶斯网络用于根据实时传感器数据和环境条件动态更新不确定性估计，从而完善路径成功的联合概率。通过广泛的模拟和真实世界测试场景，我们展示了我们的方法在增强性能和鲁棒性方面的优势。这种概率方法显著提升了自主水下机器人的能力，确保在动态海洋挑战面前实现优化的运动规划。", "summary": "本文提出了一种名为“自适应启发式运动规划器”的框架，旨在解决水下自主操控中运动规划效率和鲁棒性不足的问题。该框架创新性地结合了启发式运动空间（HMS）和贝叶斯网络。通过在HMS中利用概率路线图（PRM）算法并优化综合成本函数（包含距离、不确定性、能耗和时间），该方法显著缩小了搜索空间，从而实现了实时规划。贝叶斯网络则动态更新不确定性，提高了路径成功的概率。仿真和实测均验证了该方法在性能和鲁棒性上的提升，为自主水下机器人提供了更优的运动规划能力。", "keywords": "水下操控, 运动规划, 启发式运动空间, 贝叶斯网络, 不确定性", "comments": "该论文的创新点在于将启发式运动空间（HMS）与贝叶斯网络相结合，以应对水下环境固有的不确定性，并实现实时运动规划。通过优化综合成本函数和动态更新不确定性，该方法不仅提高了规划效率，还增强了系统的鲁棒性。这对于在复杂多变的水下环境中部署自主机器人具有重要意义，解决了现有方法在利用先验经验和适应实时变化方面的不足。"}}
{"id": "2507.13805", "title": "On-the-Fly Fine-Tuning of Foundational Neural Network Potentials: A Bayesian Neural Network Approach", "authors": ["Tim Rensmeyer", "Denis Kramer", "Oliver Niggemann"], "categories": ["cs.LG", "cond-mat.mtrl-sci", "physics.comp-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13805v1", "summary": "Due to the computational complexity of evaluating interatomic forces from\nfirst principles, the creation of interatomic machine learning force fields has\nbecome a highly active field of research. However, the generation of training\ndatasets of sufficient size and sample diversity itself comes with a\ncomputational burden that can make this approach impractical for modeling rare\nevents or systems with a large configuration space. Fine-tuning foundation\nmodels that have been pre-trained on large-scale material or molecular\ndatabases offers a promising opportunity to reduce the amount of training data\nnecessary to reach a desired level of accuracy. However, even if this approach\nrequires less training data overall, creating a suitable training dataset can\nstill be a very challenging problem, especially for systems with rare events\nand for end-users who don't have an extensive background in machine learning.\nIn on-the-fly learning, the creation of a training dataset can be largely\nautomated by using model uncertainty during the simulation to decide if the\nmodel is accurate enough or if a structure should be recalculated with\nclassical methods and used to update the model. A key challenge for applying\nthis form of active learning to the fine-tuning of foundation models is how to\nassess the uncertainty of those models during the fine-tuning process, even\nthough most foundation models lack any form of uncertainty quantification. In\nthis paper, we overcome this challenge by introducing a fine-tuning approach\nbased on Bayesian neural network methods and a subsequent on-the-fly workflow\nthat automatically fine-tunes the model while maintaining a pre-specified\naccuracy and can detect rare events such as transition states and sample them\nat an increased rate relative to their occurrence.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13805v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基础神经网络势的动态微调：一种贝叶斯神经网络方法", "tldr": "提出一种基于贝叶斯神经网络的动态微调方法，用于解决基础神经网络势在动态学习中不确定性量化问题，并能自动微调模型、检测稀有事件。", "motivation": "由于从第一性原理评估原子间作用力计算复杂，创建原子间机器学习力场的训练数据集计算负担大，导致该方法在建模稀有事件或大配置空间系统时变得不切实际。虽然微调预训练的基础模型有望减少所需训练数据，但创建合适的训练数据集仍是挑战，尤其对于稀有事件和非机器学习背景用户。在动态学习中，一个关键挑战是如何评估基础模型的不确定性，因为大多数基础模型缺乏不确定性量化能力。", "method": "本文通过引入一种基于贝叶斯神经网络（BNN）方法的微调策略，并结合随后的动态（on-the-fly）工作流程，克服了在动态学习中评估基础模型不确定性的挑战。", "result": "所提出的方法能够自动微调模型，同时保持预设精度，并能有效检测稀有事件（如过渡态）并以高于其发生率的速度进行采样。", "conclusion": "本研究通过引入基于贝叶斯神经网络的微调方法和动态工作流程，成功解决了在动态学习中对基础模型进行不确定性评估的挑战，从而实现了高效且准确的模型微调和稀有事件检测。", "translation": "由于从第一性原理评估原子间作用力计算复杂，原子间机器学习力场的创建已成为一个高度活跃的研究领域。然而，生成足够大小和样本多样性的训练数据集本身就带有计算负担，这可能使这种方法在建模稀有事件或具有大构型空间系统时变得不切实际。微调在大规模材料或分子数据库上预训练的基础模型提供了一个有前景的机会，可以减少达到所需精度水平所需的训练数据量。然而，即使这种方法总体上需要更少的训练数据，创建合适的训练数据集仍然是一个非常具有挑战性的问题，特别是对于具有稀有事件的系统以及没有广泛机器学习背景的最终用户。在动态学习中，训练数据集的创建可以通过在模拟过程中使用模型不确定性来决定模型是否足够准确，或者是否应该使用经典方法重新计算结构并用于更新模型，从而在很大程度上实现自动化。将这种形式的主动学习应用于基础模型的微调的一个关键挑战是如何在微调过程中评估这些模型的不确定性，即使大多数基础模型缺乏任何形式的不确定性量化。在本文中，我们通过引入一种基于贝叶斯神经网络方法的微调方法以及随后的动态工作流程来克服这一挑战，该工作流程可以自动微调模型，同时保持预设精度，并能检测到过渡态等稀有事件并以高于其发生率的速度进行采样。", "summary": "本文提出了一种基于贝叶斯神经网络（BNN）的动态微调方法，旨在解决基础神经网络势在动态学习中不确定性量化的问题。针对传统机器学习力场训练数据生成成本高、微调基础模型仍面临数据挑战的痛点，该方法通过利用BNN进行不确定性量化，实现了模型的自动微调，并能在保持预设精度的同时，有效检测并加速采样稀有事件，从而提升了计算效率和模型在复杂系统中的应用性。", "keywords": "动态微调, 贝叶斯神经网络, 基础神经网络势, 不确定性量化, 稀有事件", "comments": "本文的创新点在于将贝叶斯神经网络引入到基础神经网络势的动态微调过程中，解决了这类模型普遍缺乏不确定性量化能力的难题。这对于在计算昂贵的物理化学模拟中实现高效、准确的机器学习力场构建具有重要意义，尤其是在处理稀有事件和减少对大量标记数据依赖方面。"}}
{"id": "2507.13700", "title": "Tight Bounds for Answering Adaptively Chosen Concentrated Queries", "authors": ["Emma Rapoport", "Edith Cohen", "Uri Stemmer"], "categories": ["cs.DS", "cs.LG"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13700v1", "summary": "Most work on adaptive data analysis assumes that samples in the dataset are\nindependent. When correlations are allowed, even the non-adaptive setting can\nbecome intractable, unless some structural constraints are imposed. To address\nthis, Bassily and Freund [2016] introduced the elegant framework of\nconcentrated queries, which requires the analyst to restrict itself to queries\nthat are concentrated around their expected value. While this assumption makes\nthe problem trivial in the non-adaptive setting, in the adaptive setting it\nremains quite challenging. In fact, all known algorithms in this framework\nsupport significantly fewer queries than in the independent case: At most\n$O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the\nindependent setting.\n  In this work, we prove that this utility gap is inherent under the current\nformulation of the concentrated queries framework, assuming some natural\nconditions on the algorithm. Additionally, we present a simplified version of\nthe best-known algorithms that match our impossibility result.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13700v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "自适应选择集中查询的紧密界限", "tldr": "本研究证明了在当前集中查询框架下，自适应数据分析中查询数量的效用差距是固有的，并提出了与此不可能结果相匹配的简化算法。", "motivation": "大多数自适应数据分析工作假设数据集中的样本是独立的。当允许相关性时，即使是非自适应设置也可能变得难以处理，除非施加一些结构性约束。为了解决这个问题，Bassily和Freund（2016）引入了集中查询的框架，该框架要求分析师将自身限制在集中于其期望值周围的查询。尽管这个假设使得非自适应问题变得简单，但在自适应设置中，它仍然相当具有挑战性。事实上，该框架中所有已知算法支持的查询数量都远少于独立情况：对于大小为n的样本，最多支持O(n)个查询，而独立设置中为O(n^2)。本工作旨在证明这种效用差距是否在当前集中查询框架下是固有的。", "method": "本研究证明了在当前集中查询框架下，假设算法满足一些自然条件，上述效用差距是固有的。此外，我们提出了一个已知最佳算法的简化版本，该版本与我们的不可能结果相匹配。", "result": "我们证明了在当前集中查询框架下，假设算法满足一些自然条件，所观察到的效用差距是固有的。此外，我们提出了一个已知最佳算法的简化版本，该版本与我们的不可能结果相匹配。", "conclusion": "在当前集中查询框架下，自适应数据分析中支持的查询数量显著少于独立情况的效用差距是固有的限制。", "translation": "关于自适应数据分析的大多数工作都假设数据集中的样本是独立的。当允许相关性时，即使是非自适应设置也可能变得难以处理，除非施加一些结构性约束。为了解决这个问题，Bassily和Freund [2016] 引入了集中查询的优雅框架，该框架要求分析师将自身限制在集中于其期望值周围的查询。尽管这个假设使得非自适应问题变得简单，但在自适应设置中，它仍然相当具有挑战性。事实上，该框架中所有已知算法支持的查询数量都远少于独立情况：对于大小为n的样本，最多支持O(n)个查询，而独立设置中为O(n^2)。\n在本工作中，我们证明了在当前集中查询框架下，假设算法满足一些自然条件，这种效用差距是固有的。此外，我们提出了一个已知最佳算法的简化版本，该版本与我们的不可能结果相匹配。", "summary": "本研究探讨了在自适应数据分析中，当允许数据相关性时面临的挑战，特别是集中查询框架下的效用差距问题。以往的研究表明，在该框架下，相较于独立样本情况，支持的查询数量显著减少。本文通过理论证明，指出这种查询数量上的效用差距在当前集中查询框架下是固有的，前提是算法满足某些自然条件。此外，文章还提出了一个简化版的现有最佳算法，该算法的性能与本文的不可能结果相匹配。", "keywords": "自适应数据分析, 集中查询, 紧密界限, 效用差距, 不可能结果", "comments": "这篇论文解决了自适应数据分析中一个核心的理论问题，即在处理相关数据时，集中查询框架下查询数量受限是否是固有的。通过提供不可能结果和匹配算法，它为理解该框架的局限性提供了坚实的理论基础，对于设计更高效或更宽松的隐私保护机制具有重要指导意义。"}}
{"id": "2412.16247", "title": "Towards scientific discovery with dictionary learning: Extracting biological concepts from microscopy foundation models", "authors": ["Konstantin Donhauser", "Kristina Ulicna", "Gemma Elyse Moran", "Aditya Ravuri", "Kian Kenyon-Dean", "Cian Eastwood", "Jason Hartford"], "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.16247v3", "summary": "Sparse dictionary learning (DL) has emerged as a powerful approach to extract\nsemantically meaningful concepts from the internals of large language models\n(LLMs) trained mainly in the text domain. In this work, we explore whether DL\ncan extract meaningful concepts from less human-interpretable scientific data,\nsuch as vision foundation models trained on cell microscopy images, where\nlimited prior knowledge exists about which high-level concepts should arise. We\npropose a novel combination of a sparse DL algorithm, Iterative Codebook\nFeature Learning (ICFL), with a PCA whitening pre-processing step derived from\ncontrol data. Using this combined approach, we successfully retrieve\nbiologically meaningful concepts, such as cell types and genetic perturbations.\nMoreover, we demonstrate how our method reveals subtle morphological changes\narising from human-interpretable interventions, offering a promising new\ndirection for scientific discovery via mechanistic interpretability in\nbioimaging.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.16247v3", "cate": "cs.LG", "date": "2024-12-20", "updated": "2025-07-18", "AI": {"title_translation": "利用字典学习迈向科学发现：从显微镜基础模型中提取生物学概念", "tldr": "本文探索了稀疏字典学习（DL）能否从细胞显微镜图像训练的视觉基础模型中提取有意义的生物学概念，并提出了一种结合ICFL算法和PCA白化预处理的新方法，成功识别了细胞类型和遗传扰动等生物学概念，为生物成像中的科学发现提供了新方向。", "motivation": "现有的稀疏字典学习（DL）已成功从文本领域的LLMs中提取语义概念。本文旨在探索DL是否也能从人类难以解释的科学数据（如细胞显微镜图像训练的视觉基础模型）中提取有意义的、高层次的概念，因为这类数据缺乏关于应出现哪些高层次概念的先验知识。", "method": "本文提出了一种稀疏字典学习算法（迭代码本特征学习，ICFL）与源自对照数据的PCA白化预处理步骤相结合的新方法。", "result": "通过所提出的组合方法，成功检索到具有生物学意义的概念，例如细胞类型和遗传扰动。此外，该方法揭示了由人类可解释干预引起的微妙形态变化。", "conclusion": "该方法为通过生物成像中的机制可解释性实现科学发现提供了一个有前景的新方向。", "translation": "稀疏字典学习（DL）已成为一种强大的方法，可以从主要在文本领域训练的大型语言模型（LLMs）内部提取语义上有意义的概念。在这项工作中，我们探索DL是否可以从人类难以解释的科学数据中提取有意义的概念，例如在细胞显微镜图像上训练的视觉基础模型，其中关于应该出现哪些高级概念的先验知识有限。我们提出了一种稀疏DL算法（迭代码本特征学习，ICFL）与源自对照数据的PCA白化预处理步骤相结合的新颖组合。使用这种组合方法，我们成功地检索了具有生物学意义的概念，例如细胞类型和遗传扰动。此外，我们证明了我们的方法如何揭示由人类可解释干预引起的微妙形态变化，为通过生物成像中的机制可解释性实现科学发现提供了一个有前景的新方向。", "summary": "本文研究了稀疏字典学习（DL）在从细胞显微镜图像训练的视觉基础模型中提取生物学概念的应用。针对科学数据解释性差的挑战，作者提出了一种结合迭代码本特征学习（ICFL）算法和PCA白化预处理的新方法。实验结果表明，该方法成功提取了细胞类型、遗传扰动等生物学概念，并揭示了微小的形态变化，为生物成像领域的科学发现提供了新的可解释性途径。", "keywords": "字典学习, 显微镜图像, 生物概念, 科学发现, 机制可解释性", "comments": "这项研究的创新之处在于将稀疏字典学习应用于非文本领域的科学图像数据，特别是生物显微镜图像。它解决了从复杂、低可解释性数据中提取有意义概念的挑战，并通过结合ICFL和PCA白化，成功地实现了生物学概念的识别。这对于推动生物成像领域的科学发现和机制解释具有重要意义，因为它提供了一种从数据中自动发现隐藏模式和概念的工具，有助于理解细胞行为和疾病机制。"}}
{"id": "2507.14107", "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment", "authors": ["Viraj Nishesh Darji", "Callie C. Liao", "Duoduo Liao"], "categories": ["cs.AI", "cs.IR"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14107v1", "summary": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14107v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用大型语言模型自动解释无损评估等高线图以进行桥梁状况评估", "tldr": "本研究探索了使用大型语言模型（LLMs）自动解释无损评估（NDE）等高线图，以提高桥梁状况评估的效率和准确性，并发现部分LLMs在图像描述和总结方面表现出色，有助于加速决策。", "motivation": "桥梁维护和安全至关重要，无损评估（NDE）技术对评估结构完整性至关重要。然而，解释NDE数据耗时且需要专业知识，可能延误决策。大型语言模型（LLMs）的最新进展为自动化和改进这种分析提供了新途径。", "method": "本研究是一项初步研究，旨在全面评估LLM解释NDE等高线图的能力。它建立了一个将LLM集成到桥梁检查工作流程中的框架。研究探索了多个LLM，并设计了专门用于提高图像描述质量的提示，将其应用于解释通过桥梁状况评估技术获得的五种不同NDE等高线图。每个LLM模型都根据其生成详细描述、识别缺陷、提供可行建议和整体准确性的能力进行评估。研究还使用五种不同的LLM对表现最好的四个模型的输出进行总结。", "result": "研究表明，九个模型中有四个提供了更好的图像描述，有效涵盖了与桥梁状况相关的广泛主题。值得注意的是，LLM ChatGPT-4和Claude 3.5 Sonnet生成了更有效的总结。研究结果表明，LLM有潜力显著提高效率和准确性。", "conclusion": "LLM有潜力显著提高桥梁维护决策的效率和准确性。本初步研究提出了一种利用LLM进行并行图像标注和总结的创新方法，从而加速了桥梁维护中的决策，并增强了基础设施管理和安全评估。", "translation": "桥梁维护和安全对交通管理部门至关重要，无损评估（NDE）技术对于评估结构完整性至关重要。然而，解释NDE数据可能耗时且需要专业知识，这可能会延迟决策。大型语言模型（LLM）的最新进展为自动化和改进这种分析提供了新途径。这项初步研究全面评估了LLM解释NDE等高线图的能力，并展示了LLM在提供详细桥梁状况分析方面的有效性。它建立了一个将LLM集成到桥梁检查工作流程中的框架，表明LLM辅助分析可以在不影响准确性的情况下提高效率。在这项研究中，探索了几个LLM，并设计了专门用于提高图像描述质量的提示，这些提示应用于解释通过桥梁状况评估技术获得的五种不同NDE等高线图。每个LLM模型都根据其生成详细描述、识别缺陷、提供可行建议和整体准确性的能力进行评估。研究表明，九个模型中有四个提供了更好的图像描述，有效涵盖了与桥梁状况相关的广泛主题。这四个模型的输出使用五种不同的LLM进行总结，以形成对桥梁的全面概述。值得注意的是，LLM ChatGPT-4和Claude 3.5 Sonnet生成了更有效的总结。研究结果表明，LLM有潜力显著提高效率和准确性。这项初步研究提出了一种创新方法，利用LLM进行并行图像标注和总结，从而加速了桥梁维护中的决策，并增强了基础设施管理和安全评估。", "summary": "本初步研究探讨了利用大型语言模型（LLMs）自动化解释无损评估（NDE）等高线图，以提高桥梁状况评估的效率和准确性。研究建立了一个将LLMs集成到桥梁检查工作流程中的框架，并评估了多个LLMs在生成图像描述、识别缺陷和提供建议方面的能力。结果显示，部分LLMs在图像描述和总结方面表现出色（特别是ChatGPT-4和Claude 3.5 Sonnet），证明LLMs能显著提升桥梁维护决策的速度和质量。", "keywords": "无损评估, 大型语言模型, 桥梁状况评估, 图像标注, 自动化", "comments": "这项研究的创新之处在于将大型语言模型应用于无损评估数据的自动化解释，特别是在图像标注和总结方面。这为桥梁状况评估提供了一种高效且准确的新方法，有望大幅缩短决策时间，提升基础设施管理和安全水平。其局限性可能在于仍是初步研究，需要更多实际应用和大规模数据验证。"}}
{"id": "2507.13568", "title": "LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning", "authors": ["Kaihong Wang", "Donghyun Kim", "Margrit Betke"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13568v1", "summary": "Continual learning for vision-language models has achieved remarkable\nperformance through synthetic replay, where samples are generated using Stable\nDiffusion to regularize during finetuning and retain knowledge. However,\nreal-world downstream applications often exhibit domain-specific nuances and\nfine-grained semantics not captured by generators, causing synthetic-replay\nmethods to produce misaligned samples that misguide finetuning and undermine\nretention of prior knowledge. In this work, we propose a LoRA-enhanced\nsynthetic-replay framework that injects task-specific low-rank adapters into a\nfrozen Stable Diffusion model, efficiently capturing each new task's unique\nvisual and semantic patterns. Specifically, we introduce a two-stage,\nconfidence-based sample selection: we first rank real task data by\npost-finetuning VLM confidence to focus LoRA finetuning on the most\nrepresentative examples, then generate synthetic samples and again select them\nby confidence for distillation. Our approach integrates seamlessly with\nexisting replay pipelines-simply swap in the adapted generator to boost replay\nfidelity. Extensive experiments on the Multi-domain Task Incremental Learning\n(MTIL) benchmark show that our method outperforms previous synthetic-replay\ntechniques, achieving an optimal balance among plasticity, stability, and\nzero-shot capability. These results demonstrate the effectiveness of generator\nadaptation via LoRA for robust continual learning in VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13568v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "LoRA-Loop：为持续VLM学习闭合合成重放循环", "tldr": "LoRA-Loop通过注入任务特定LoRA适配器到Stable Diffusion中，生成更准确的合成样本，解决了持续视觉语言模型学习中合成重放样本失真的问题，提高了模型性能。", "motivation": "现有的视觉语言模型持续学习中的合成重放方法，由于生成器未能捕捉到领域特定的细微差别和细粒度语义，导致生成的样本与实际不符，从而误导微调并损害先验知识的保留。", "method": "本文提出了一个LoRA增强的合成重放框架，即LoRA-Loop，该框架将任务特定的低秩适配器（LoRA）注入冻结的Stable Diffusion模型中，以高效捕捉每个新任务独特的视觉和语义模式。具体来说，引入了两阶段的、基于置信度的样本选择：首先根据微调后的VLM置信度对真实任务数据进行排序，以使LoRA微调聚焦于最具代表性的示例；然后生成合成样本，并再次根据置信度选择它们进行蒸馏。该方法可与现有重放管道无缝集成。", "result": "在多领域任务增量学习（MTIL）基准上的大量实验表明，该方法优于先前的合成重放技术，在可塑性、稳定性与零样本能力之间实现了最佳平衡。", "conclusion": "这些结果证明了通过LoRA进行生成器适应对于视觉语言模型（VLMs）中稳健持续学习的有效性。", "translation": "视觉语言模型的持续学习通过合成重放取得了显著性能，其中使用Stable Diffusion生成样本以在微调期间进行正则化并保留知识。然而，现实世界的下游应用通常表现出生成器未能捕捉到的领域特定细微差别和细粒度语义，导致合成重放方法产生不匹配的样本，误导微调并损害先验知识的保留。在这项工作中，我们提出了一个LoRA增强的合成重放框架，该框架将任务特定的低秩适配器注入冻结的Stable Diffusion模型中，有效地捕捉每个新任务独特的视觉和语义模式。具体来说，我们引入了两阶段的、基于置信度的样本选择：我们首先根据微调后的VLM置信度对真实任务数据进行排序，以使LoRA微调聚焦于最具代表性的示例，然后生成合成样本并再次根据置信度选择它们进行蒸馏。我们的方法与现有重放管道无缝集成——只需替换适配的生成器即可提高重放保真度。在多领域任务增量学习（MTIL）基准上的大量实验表明，我们的方法优于先前的合成重放技术，在可塑性、稳定性与零样本能力之间实现了最佳平衡。这些结果证明了通过LoRA进行生成器适应对于VLMs中稳健持续学习的有效性。", "summary": "本文提出LoRA-Loop框架，旨在解决视觉语言模型持续学习中合成重放样本失真的问题。通过将任务特定的LoRA适配器注入Stable Diffusion模型，LoRA-Loop能够高效捕捉新任务的独特模式。该方法采用两阶段的置信度样本选择机制，确保生成的合成样本更具代表性，从而提升模型在持续学习中的可塑性、稳定性和零样本能力，并已在MTIL基准上验证其有效性。", "keywords": "持续学习, 视觉语言模型, 合成重放, LoRA, Stable Diffusion", "comments": "该论文的创新点在于将LoRA技术应用于生成器适应，以提高合成重放样本的质量，从而解决了现有方法中样本失真导致知识保留不足的问题。这种方法提供了一个通用且可插拔的解决方案，可以无缝集成到现有持续学习管道中，对于提升视觉语言模型在复杂现实世界应用中的适应性和鲁棒性具有重要意义。"}}
{"id": "2507.13899", "title": "Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection", "authors": ["Yujian Mo", "Yan Wu", "Junqiao Zhao", "Jijun Wang", "Yinghao Hu", "Jun Yan"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13899v1", "summary": "Recent advances in foundation models have opened up new possibilities for\nenhancing 3D perception. In particular, DepthAnything offers dense and reliable\ngeometric priors from monocular RGB images, which can complement sparse LiDAR\ndata in autonomous driving scenarios. However, such priors remain underutilized\nin LiDAR-based 3D object detection. In this paper, we address the limited\nexpressiveness of raw LiDAR point features, especially the weak discriminative\ncapability of the reflectance attribute, by introducing depth priors predicted\nby DepthAnything. These priors are fused with the original LiDAR attributes to\nenrich each point's representation. To leverage the enhanced point features, we\npropose a point-wise feature extraction module. Then, a Dual-Path RoI feature\nextraction framework is employed, comprising a voxel-based branch for global\nsemantic context and a point-based branch for fine-grained structural details.\nTo effectively integrate the complementary RoI features, we introduce a\nbidirectional gated RoI feature fusion module that balances global and local\ncues. Extensive experiments on the KITTI benchmark show that our method\nconsistently improves detection accuracy, demonstrating the value of\nincorporating visual foundation model priors into LiDAR-based 3D object\ndetection.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13899v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "利用基础模型先验增强激光雷达点特征用于三维目标检测", "tldr": "该研究通过引入DepthAnything的深度先验来增强激光雷达点特征，并提出一个双路径RoI特征提取框架及双向门控融合模块，以提高基于激光雷达的三维目标检测精度。", "motivation": "现有激光雷达点特征的表达能力有限，特别是反射属性的判别能力弱，且视觉基础模型（如DepthAnything）提供的密集可靠的几何先验在基于激光雷达的三维目标检测中未被充分利用。", "method": "通过引入DepthAnything预测的深度先验来丰富原始激光雷达点的表示。提出一个逐点特征提取模块，并采用一个双路径RoI特征提取框架，该框架包含一个用于全局语义上下文的基于体素的分支和一个用于细粒度结构细节的基于点的分支。最后，引入一个双向门控RoI特征融合模块来有效整合互补的RoI特征。", "result": "在KITTI基准测试上进行的广泛实验表明，所提出的方法持续提高了检测精度。", "conclusion": "该研究证明了将视觉基础模型先验整合到基于激光雷达的三维目标检测中的价值。", "translation": "基础模型的最新进展为增强三维感知开辟了新的可能性。特别是，DepthAnything从单目RGB图像中提供了密集可靠的几何先验，这可以补充自动驾驶场景中稀疏的激光雷达数据。然而，这些先验在基于激光雷达的三维目标检测中仍未被充分利用。在本文中，我们通过引入DepthAnything预测的深度先验，解决了原始激光雷达点特征有限的表达能力，特别是反射属性判别能力弱的问题。这些先验与原始激光雷达属性融合，以丰富每个点的表示。为了利用增强的点特征，我们提出了一个逐点特征提取模块。然后，采用一个双路径RoI特征提取框架，该框架包含一个用于全局语义上下文的基于体素的分支和一个用于细粒度结构细节的基于点的分支。为了有效整合互补的RoI特征，我们引入了一个双向门控RoI特征融合模块，以平衡全局和局部线索。在KITTI基准测试上进行的广泛实验表明，我们的方法持续提高了检测精度，证明了将视觉基础模型先验整合到基于激光雷达的三维目标检测中的价值。", "summary": "本文提出一种增强激光雷达点特征的方法，通过引入视觉基础模型DepthAnything的深度先验来丰富点云表示，以解决原始激光雷达特征表达能力不足的问题。为有效利用增强特征，研究设计了一个逐点特征提取模块和一个双路径RoI特征提取框架（包含体素和点分支），并引入双向门控融合模块来整合多源特征。实验结果表明，该方法显著提升了三维目标检测的精度，验证了融合视觉先验的有效性。", "keywords": "激光雷达, 三维目标检测, 基础模型, 深度先验, 特征融合", "comments": "该论文的创新点在于将视觉基础模型（DepthAnything）的深度先验引入到激光雷达三维目标检测中，有效弥补了激光雷达点特征，特别是反射属性的表达不足。其提出的双路径RoI特征提取框架和双向门控融合模块，能够有效整合全局语义和局部细节信息，是提升检测性能的关键。该工作为多模态数据融合在自动驾驶领域的应用提供了有价值的思路。"}}
{"id": "2412.02503", "title": "VA-MoE: Variables-Adaptive Mixture of Experts for Incremental Weather Forecasting", "authors": ["Hao Chen", "Han Tao", "Guo Song", "Jie Zhang", "Yunlong Yu", "Yonghan Dong", "Lei Bai"], "categories": ["cs.LG", "physics.ao-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This paper has already been accepted by ICCV25", "url": "http://arxiv.org/abs/2412.02503v2", "summary": "This paper presents Variables Adaptive Mixture of Experts (VAMoE), a novel\nframework for incremental weather forecasting that dynamically adapts to\nevolving spatiotemporal patterns in real time data. Traditional weather\nprediction models often struggle with exorbitant computational expenditure and\nthe need to continuously update forecasts as new observations arrive. VAMoE\naddresses these challenges by leveraging a hybrid architecture of experts,\nwhere each expert specializes in capturing distinct subpatterns of atmospheric\nvariables (temperature, humidity, wind speed). Moreover, the proposed method\nemploys a variable adaptive gating mechanism to dynamically select and combine\nrelevant experts based on the input context, enabling efficient knowledge\ndistillation and parameter sharing. This design significantly reduces\ncomputational overhead while maintaining high forecast accuracy. Experiments on\nreal world ERA5 dataset demonstrate that VAMoE performs comparable against SoTA\nmodels in both short term (1 days) and long term (5 days) forecasting tasks,\nwith only about 25% of trainable parameters and 50% of the initial training\ndata.", "comment": "This paper has already been accepted by ICCV25", "pdf_url": "http://arxiv.org/pdf/2412.02503v2", "cate": "cs.LG", "date": "2024-12-03", "updated": "2025-07-18", "AI": {"title_translation": "VA-MoE: 变量自适应专家混合模型用于增量天气预报", "tldr": "VA-MoE是一种新的增量天气预报框架，它通过动态选择和组合专家来适应实时数据，显著减少了计算开销和训练数据，同时保持了高精度。", "motivation": "传统天气预测模型面临巨大的计算开销和需要持续更新预报的挑战。", "method": "提出了变量自适应专家混合模型（VAMoE），采用混合专家架构，每个专家专注于捕获大气变量的不同子模式。同时，使用变量自适应门控机制根据输入上下文动态选择和组合相关专家，实现高效的知识蒸馏和参数共享。", "result": "在真实世界的ERA5数据集上的实验表明，VAMoE在短期（1天）和长期（5天）预报任务中表现与最先进模型相当，但仅需约25%的可训练参数和50%的初始训练数据。", "conclusion": "VA-MoE通过其创新的架构和门控机制，有效解决了传统天气预报模型的计算效率和数据依赖问题，提供了一种高效且准确的增量天气预报解决方案。", "translation": "本文提出变量自适应专家混合模型（VAMoE），这是一种用于增量天气预报的新颖框架，可实时动态适应不断演变的时空模式。传统天气预测模型常常面临高昂的计算开销以及在新观测数据到达时需要持续更新预报的难题。VAMoE通过利用混合专家架构来解决这些挑战，其中每个专家专门捕获大气变量（温度、湿度、风速）的不同子模式。此外，所提出的方法采用变量自适应门控机制，根据输入上下文动态选择和组合相关的专家，从而实现高效的知识蒸馏和参数共享。这种设计显著降低了计算开销，同时保持了高预报精度。在真实世界的ERA5数据集上进行的实验表明，VAMoE在短期（1天）和长期（5天）预报任务中均与最先进的模型表现相当，而其可训练参数仅为约25%，初始训练数据量仅为50%。", "summary": "VA-MoE是一个用于增量天气预报的新型变量自适应专家混合框架。它通过混合专家架构和变量自适应门控机制，动态适应实时数据中的时空模式，从而有效降低计算开销和数据需求，同时保持与现有先进模型相当的预报精度。实验证明，VAMoE在减少参数和训练数据量的情况下，在短期和长期天气预报任务中均表现出色。", "keywords": "增量天气预报, 专家混合模型, 变量自适应, 计算效率, ERA5数据集", "comments": "VA-MoE的创新之处在于其变量自适应的专家混合架构和动态门控机制，这使其能够高效地处理实时天气数据。该方法显著减少了模型参数和训练数据需求，这对于资源受限或需要快速迭代更新的实际天气预报应用具有重要意义。"}}
{"id": "2507.13569", "title": "Change of Thought: Adaptive Test-Time Computation", "authors": ["Mrinal Mathur", "Mike Doan", "Barak Pearlmutter", "Sergey Plis"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13569v1", "summary": "Transformers evaluated in a single, fixed-depth pass are provably limited in\nexpressive power to the constant-depth circuit class TC0. Running a Transformer\nautoregressively removes that ceiling -- first in next-token prediction and,\nmore recently, in chain-of-thought reasoning. Both regimes rely on feedback\nloops that decode internal states into tokens only to re-encode them in\nsubsequent steps. While this \"thinking aloud\" mirrors human reasoning,\nbiological brains iterate without externalising intermediate states as\nlanguage. To boost the expressive power of encoder Transformers without\nresorting to token-level autoregression, we introduce the SELF-Transformer: an\nencoder layer that iteratively refines its own attention weights to a fixed\npoint. Instead of producing -- in one pass -- the alignment matrix that remixes\nthe input sequence, the SELF-Transformer iteratively updates that matrix\ninternally, scaling test-time computation with input difficulty. This\nadaptivity yields up to 20\\% accuracy gains on encoder-style benchmarks without\nincreasing parameter count, demonstrating that input-adaptive alignment at test\ntime offers substantial benefits for only a modest extra compute budget.\nSelf-Transformers thus recover much of the expressive power of iterative\nreasoning while preserving the simplicity of pure encoder architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13569v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "思想的转变：自适应测试时计算", "tldr": "本文提出了SELF-Transformer，通过内部迭代自适应调整注意力权重，显著提升了编码器模型的表达能力和准确性，且不增加参数量。", "motivation": "现有单次通过的Transformer在表达能力上受限，而自回归模型虽然能提升表达能力但依赖于将内部状态外部化为词元。受生物大脑在不外部化中间状态的情况下进行迭代推理的启发，研究旨在提升编码器Transformer的表达能力，同时避免词元级自回归。", "method": "本文引入了SELF-Transformer，这是一种编码器层，它通过内部迭代地将其自身的注意力权重细化到一个固定点，而不是一次性生成对齐矩阵。该模型根据输入难度自适应地调整测试时计算。", "result": "SELF-Transformer在编码器型基准测试中实现了高达20%的准确率提升，且没有增加参数数量。这表明测试时输入自适应对齐以适度的额外计算预算提供了实质性好处。", "conclusion": "SELF-Transformer在恢复迭代推理的表达能力的同时，成功保留了纯编码器架构的简洁性。", "translation": "在单次固定深度传递中评估的Transformer在表达能力上被证明受限于常数深度电路类TC0。自回归运行Transformer消除了这一上限——首先是在下一个词元预测中，最近则是在思维链推理中。这两种机制都依赖于反馈循环，将内部状态解码为词元，然后又在后续步骤中重新编码。虽然这种“大声思考”模仿了人类推理，但生物大脑在没有将中间状态外部化为语言的情况下进行迭代。为了在不诉诸词元级自回归的情况下提升编码器Transformer的表达能力，我们引入了SELF-Transformer：一个编码器层，它迭代地将其自身的注意力权重细化到一个固定点。SELF-Transformer不是一次性生成混合输入序列的对齐矩阵，而是在内部迭代更新该矩阵，并根据输入难度调整测试时计算。这种自适应性在编码器型基准测试中带来了高达20%的准确率提升，而没有增加参数数量，这表明测试时的输入自适应对齐以适度的额外计算预算提供了实质性好处。因此，Self-Transformer在保留纯编码器架构简洁性的同时，恢复了迭代推理的表达能力。", "summary": "本文提出了一种名为SELF-Transformer的新型编码器层，旨在提升Transformer的表达能力，同时避免词元级自回归。受生物大脑迭代推理的启发，SELF-Transformer通过内部迭代细化其注意力权重，并根据输入难度自适应调整测试时计算。实验结果表明，该模型在不增加参数量的情况下，在编码器基准测试中实现了高达20%的准确率提升，有效恢复了迭代推理的表达能力，同时保持了纯编码器架构的简洁性。", "keywords": "SELF-Transformer, 自适应计算, 编码器, 注意力权重, 表达能力", "comments": "本文提出了一种创新的内部迭代机制，使编码器Transformer能够在不依赖外部化中间状态和不增加参数数量的前提下，显著提升其表达能力和准确性。这种自适应测试时计算的理念对于提高模型效率和性能具有重要意义，尤其适用于需要深层推理但又追求模型简洁性的场景。"}}
{"id": "2406.15817", "title": "Computable one-way functions on the reals", "authors": ["George Barmpalias", "Xiaoyan Zhang"], "categories": ["cs.CC", "cs.IT", "math.IT", "math.LO"], "primary_category": "Subjects:       Computational Complexity (cs.CC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2406.15817v3", "summary": "A major open problem in computational complexity is the existence of a\none-way function, namely a function from strings to strings which is\ncomputationally easy to compute but hard to invert. Levin (2023) formulated the\nnotion of one-way functions from reals (infinite bit-sequences) to reals in\nterms of computability, and asked whether partial computable one-way functions\nexist. We give a strong positive answer using the hardness of the halting\nproblem and exhibiting a total computable one-way function.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2406.15817v3", "cate": "cs.CC", "date": "2024-06-22", "updated": "2025-07-17", "AI": {"title_translation": "实数上的可计算单向函数", "tldr": "本文通过利用停机问题的难度，证明了存在实数上的完全可计算单向函数，解决了关于实数上偏可计算单向函数是否存在的重要开放问题。", "motivation": "计算复杂性领域的一个主要开放问题是单向函数（从字符串到字符串）的存在性。Levin (2023) 提出了从实数（无限位序列）到实数的单向函数的可计算性概念，并询问偏可计算单向函数是否存在。", "method": "本文利用停机问题的难度来证明其结果。", "result": "本文给出了一个强有力的肯定答案，并展示了一个完全可计算的单向函数。", "conclusion": "实数上存在完全可计算的单向函数，这解决了可计算性理论中的一个重要开放问题。", "translation": "计算复杂性领域的一个主要开放问题是单向函数的存在性，即一种从字符串到字符串的函数，它在计算上易于计算但难以反转。Levin (2023) 提出了从实数（无限位序列）到实数的单向函数的可计算性概念，并询问偏可计算单向函数是否存在。我们利用停机问题的难度给出了一个强有力的肯定答案，并展示了一个完全可计算的单向函数。", "summary": "本文解决了可计算性理论中关于实数上单向函数存在性的一个重要开放问题。作者利用停机问题的计算难度，成功构建并展示了一个完全可计算的单向函数，从而对Levin提出的关于实数上偏可计算单向函数是否存在的问题给出了肯定的回答。", "keywords": "单向函数, 可计算性, 实数, 停机问题", "comments": "本文的创新之处在于其通过利用停机问题的固有难度，成功地在实数域上构建并证明了完全可计算单向函数的存在性。这不仅解决了可计算性领域的一个长期开放问题，也为理解实数计算的复杂性提供了新的视角和基础。"}}
{"id": "2507.13853", "title": "Resource-Splitting Games with Tullock-Based Lossy Contests", "authors": ["Marko Maljkovic", "Gustav Nilsson", "Nikolas Geroliminis"], "categories": ["cs.GT", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Computer Science and Game Theory (cs.GT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13853v1", "summary": "This paper introduces a novel class of multi-stage resource allocation games\nthat model real-world scenarios in which profitability depends on the balance\nbetween supply and demand, and where higher resource investment leads to\ngreater returns. Our proposed framework, which incorporates the notion of\nprofit loss due to insufficient player participation, gives rise to a\nTullock-like functional form of the stage payoff structure when weighted fair\nproportional resource allocation is applied. We explore both centralized and\nNash equilibrium strategies, establish sufficient conditions for their\nexistence and uniqueness, and provide an iterative, semi-decentralized method\nto compute the Nash equilibrium in games with arbitrarily many players.\nAdditionally, we demonstrate that the framework generalizes instances of\nseveral existing models, including Receding Horizon and Blotto games, and\npresent a semi-analytical method for computing the unique Nash equilibrium\nwithin the Blotto setup. Our findings are validated through a numerical case\nstudy in smart mobility, highlighting the practical relevance and applicability\nof the proposed model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13853v1", "cate": "cs.GT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于图洛克损失竞赛的资源分配博弈", "tldr": "本文提出了一种新型多阶段资源分配博弈模型，该模型考虑了参与者不足导致的利润损失，并基于图洛克函数形式。研究了集中式和纳什均衡策略，提供了计算纳什均衡的迭代方法，并证明了其对现有模型的泛化能力，通过智能出行案例验证了其应用性。", "motivation": "现有模型未能充分捕捉现实世界中利润依赖于供需平衡、资源投入与回报成正比，以及参与者不足导致利润损失的复杂资源分配场景。本文旨在引入一个能模拟此类情景的新型多阶段资源分配博弈框架。", "method": "本文引入了一种新型多阶段资源分配博弈框架，该框架考虑了因参与者不足导致的利润损失，并在加权公平比例资源分配下呈现图洛克式的阶段收益结构。研究了集中式和纳什均衡策略，建立了其存在性和唯一性的充分条件。提出了一种迭代的半去中心化方法来计算任意多玩家博弈中的纳什均衡。此外，还提出了计算Blotto设置中唯一纳什均衡的半解析方法。", "result": "研究建立了集中式和纳什均衡策略存在的充分条件，并证明了其唯一性。提供了一种迭代的半去中心化方法来计算任意多玩家博弈中的纳什均衡。证明了该框架可以泛化包括Receding Horizon和Blotto博弈在内的多个现有模型。在Blotto设置中，提出了计算唯一纳什均衡的半解析方法。通过智能出行领域的数值案例研究，验证了模型的实际相关性和适用性。", "conclusion": "本文成功引入了一种能够模拟复杂现实世界资源分配场景的新型多阶段博弈模型，并提供了有效的分析和计算工具，证明了其在理论泛化和实际应用方面的价值。", "translation": "本文介绍了一类新颖的多阶段资源分配博弈，该博弈模拟了现实世界中的场景，其中利润取决于供需平衡，并且更高的资源投入会带来更大的回报。我们提出的框架，纳入了由于参与者不足导致的利润损失概念，在应用加权公平比例资源分配时，会产生图洛克式的阶段收益结构。我们探讨了集中式和纳什均衡策略，建立了它们存在和唯一性的充分条件，并提供了一种迭代的、半去中心化的方法来计算任意多玩家博弈中的纳什均衡。此外，我们还证明了该框架泛化了包括循环视界博弈和布洛托博弈在内的多个现有模型的实例，并提出了一种计算布洛托设置中唯一纳什均衡的半解析方法。我们的研究结果通过智能出行领域的数值案例研究得到了验证，突出了所提出模型的实际相关性和适用性。", "summary": "本文提出了一种基于图洛克函数的新型多阶段资源分配博弈模型，该模型考虑了参与者不足导致的利润损失。研究了集中式和纳什均衡策略的存在性、唯一性及计算方法，并通过迭代和半解析方法实现了纳什均衡的求解。该框架能够泛化多种现有模型，并通过智能出行案例验证了其在现实世界中的应用价值。", "keywords": "资源分配博弈, 图洛克竞赛, 纳什均衡, 多阶段博弈, 智能出行", "comments": "该论文的创新之处在于引入了考虑利润损失和图洛克函数形式的多阶段资源分配博弈模型，这使其更贴近现实复杂场景。其重要性在于提供了一套分析和计算工具，不仅理论上泛化了现有模型，还在实际应用中通过智能出行案例展示了其潜力。该研究为资源分配和竞争性博弈理论提供了新的视角和实用方法。"}}
{"id": "2409.05260", "title": "Scalable Frame Sampling for Video Classification: A Semi-Optimal Policy Approach with Reduced Search Space", "authors": ["Junho Lee", "Jeongwoo Shin", "Seung Woo Ko", "Seongsu Ha", "Joonseok Lee"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.05260v2", "summary": "Given a video with $T$ frames, frame sampling is a task to select $N \\ll T$\nframes, so as to maximize the performance of a fixed video classifier. Not just\nbrute-force search, but most existing methods suffer from its vast search space\nof $\\binom{T}{N}$, especially when $N$ gets large. To address this challenge,\nwe introduce a novel perspective of reducing the search space from $O(T^N)$ to\n$O(T)$. Instead of exploring the entire $O(T^N)$ space, our proposed\nsemi-optimal policy selects the top $N$ frames based on the independently\nestimated value of each frame using per-frame confidence, significantly\nreducing the computational complexity. We verify that our semi-optimal policy\ncan efficiently approximate the optimal policy, particularly under practical\nsettings. Additionally, through extensive experiments on various datasets and\nmodel architectures, we demonstrate that learning our semi-optimal policy\nensures stable and high performance regardless of the size of $N$ and $T$.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.05260v2", "cate": "cs.CV", "date": "2024-09-09", "updated": "2025-07-18", "AI": {"title_translation": "视频分类的可扩展帧采样：一种减少搜索空间的半最优策略方法", "tldr": "本文提出了一种新的半最优策略，通过独立估计每帧的置信度来选择视频帧，将视频分类中帧采样的搜索空间从$O(T^N)$显著减少到$O(T)$，从而实现高效且高性能的帧选择。", "motivation": "现有的视频帧采样方法在选择少量帧 ($N$) 以最大化固定视频分类器性能时，面临巨大的 $O(T^N)$ 搜索空间，尤其当 $N$ 较大时，计算成本极高。", "method": "本文提出了一种新的半最优策略，通过独立估计每帧的置信度来选择帧，将搜索空间从 $O(T^N)$ 减少到 $O(T)$。这种方法通过为每帧独立估算价值，然后选择前 $N$ 帧，显著降低了计算复杂度。", "result": "实验证明，该半最优策略能够有效地近似最优策略，特别是在实际设置下。此外，在各种数据集和模型架构上的广泛实验表明，学习这种半最优策略可以确保无论 $N$ 和 $T$ 的大小如何，都能获得稳定且高性能的表现。", "conclusion": "所提出的半最优帧采样策略能够有效解决视频分类中帧采样存在的巨大搜索空间问题，并在计算效率和性能方面表现出色，适用于不同规模的视频和帧选择需求。", "translation": "给定一个包含 $T$ 帧的视频，帧采样是一项选择 $N \text{«} T$ 帧的任务，以最大化固定视频分类器的性能。不仅仅是暴力搜索，大多数现有方法都受制于其庞大的 $\binom{T}{N}$ 搜索空间，特别是当 $N$ 变大时。为了应对这一挑战，我们引入了一种新的视角，将搜索空间从 $O(T^N)$ 减少到 $O(T)$。我们提出的半最优策略不探索整个 $O(T^N)$ 空间，而是根据使用每帧置信度独立估算的每帧价值来选择前 $N$ 帧，从而显著降低了计算复杂度。我们验证了我们的半最优策略能够有效地近似最优策略，特别是在实际设置下。此外，通过在各种数据集和模型架构上进行广泛实验，我们证明了学习我们的半最优策略可以确保无论 $N$ 和 $T$ 的大小如何，都能获得稳定且高性能的表现。", "summary": "本文针对视频分类中的帧采样任务，提出了一种新颖的半最优策略，旨在解决现有方法面临的巨大搜索空间问题。通过将搜索空间从 $O(T^N)$ 显著缩小到 $O(T)$，该方法基于每帧的独立置信度估算来选择最有价值的 $N$ 帧。实验证明，该策略能有效逼近最优解，并在不同数据集和模型上实现稳定的高性能，无论视频总帧数 $T$ 和采样帧数 $N$ 的大小如何。", "keywords": "帧采样, 视频分类, 半最优策略, 搜索空间缩减, 计算复杂度", "comments": "该论文的创新点在于提出了一种新颖的半最优策略，通过独立评估每帧价值，将视频帧采样的搜索空间从指数级 $O(T^N)$ 降低到线性级 $O(T)$。这极大地提高了计算效率和可扩展性，使其在处理大规模视频数据时更具实用性。其重要性在于为视频分类提供了一种高效且性能稳定的帧选择方法，克服了传统方法的计算瓶颈。"}}
{"id": "2507.13839", "title": "The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words", "authors": ["Lizhi Ma", "Tong Zhao", "Shuai Zhang", "Nirui Song", "Hongliang He", "Anqi Li", "Ran Feng", "Huachuan Qiu", "Jingsong Ma", "Zhenzhong Lan"], "categories": ["cs.CL", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13839v1", "summary": "This study explores the relationship between linguistic expressions and\npsychological states of depression and anxiety within Chinese psycho-counseling\ninteractions, focusing specifically on the usage of first-person singular\npronouns and negative emotional words. Utilizing a corpus derived from 735\nonline counseling sessions, the analysis employed a general linear mixed-effect\nmodel to assess linguistic patterns quantified by the Linguistic Inquiry and\nWord Count (LIWC) software. Results indicate a significant positive correlation\nbetween the frequency of negative emotional words and the severity of both\ndepressive and anxious states among clients. However, contrary to prior\nfindings predominantly derived from English-language contexts, the usage\nfrequency of first-person singular pronouns did not vary significantly with the\nclients' psychological conditions. These outcomes are discussed within the\nframework of cultural distinctions between collectivist Chinese contexts and\nindividualistic Western settings, as well as the interactive dynamics unique to\npsycho-counseling conversations. The findings highlight the nuanced influence\nof cultural and conversational contexts on language use in mental health\ncommunications, providing insights into psycholinguistic markers relevant to\ntherapeutic practices in Chinese-speaking populations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13839v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "抑郁和焦虑在中国心理咨询中的表达：第一人称单数代词和负面情绪词的使用", "tldr": "本研究探讨了中国心理咨询中抑郁和焦虑与语言表达（第一人称单数代词和负面情绪词）的关系，发现负面情绪词频率与抑郁/焦虑严重程度正相关，但第一人称单数代词频率无显著变化。", "motivation": "本研究旨在探讨中国心理咨询互动中，抑郁和焦虑的心理状态与语言表达（特别是第一人称单数代词和负面情绪词的使用）之间的关系，以填补西方语境研究结果可能不适用于集体主义中国语境的空白。", "method": "研究利用了来自735个在线咨询会话的语料库，并采用广义线性混合效应模型，结合语言探究与词汇计数（LIWC）软件量化语言模式进行分析。", "result": "结果显示，负面情绪词的频率与客户抑郁和焦虑状态的严重程度呈显著正相关。然而，与以往主要来自英语语境的发现相反，第一人称单数代词的使用频率并未随客户的心理状况发生显著变化。", "conclusion": "研究结果强调了文化和对话语境对心理健康沟通中语言使用的细微影响，为中文人群治疗实践中的心理语言标记提供了见解。", "translation": "本研究探讨了中国心理咨询互动中语言表达与抑郁和焦虑心理状态之间的关系，特别关注第一人称单数代词和负面情绪词的使用。研究利用了来自735个在线咨询会话的语料库，采用广义线性混合效应模型评估了通过语言探究与词汇计数（LIWC）软件量化的语言模式。结果表明，负面情绪词的频率与客户抑郁和焦虑状态的严重程度呈显著正相关。然而，与以往主要来自英语语境的发现相反，第一人称单数代词的使用频率并未随客户的心理状况发生显著变化。这些结果在集体主义的中国语境和个人主义的西方语境之间的文化差异，以及心理咨询对话特有的互动动态框架内进行了讨论。研究结果强调了文化和对话语境对心理健康沟通中语言使用的细微影响，为中文人群治疗实践中的心理语言标记提供了见解。", "summary": "本研究考察了中国心理咨询中抑郁和焦虑与语言表达（第一人称单数代词和负面情绪词）的关系。通过分析735个在线咨询会话数据，发现负面情绪词频率与抑郁/焦虑严重程度呈正相关。然而，与西方研究不同，第一人称单数代词频率与心理状态无显著关联。研究强调了文化和对话情境对心理健康语言使用的影响，为中文人群的治疗实践提供了重要见解。", "keywords": "心理咨询, 抑郁, 焦虑, 语言表达, 文化差异", "comments": "这项研究的创新之处在于其在中国文化背景下，探讨了心理咨询中语言使用与心理状态的关系，挑战了西方语境下的普遍发现。它强调了文化差异在心理语言学标记中的重要性，对跨文化心理咨询实践具有指导意义，填补了非英语语境研究的空白。"}}
{"id": "2507.13758", "title": "The Emperor's New Chain-of-Thought: Probing Reasoning Theater Bias in Large Reasoning Models", "authors": ["Qian Wang", "Yubo Fan", "Zhenheng Tang", "Nuo Chen", "Wenxuan Wang", "Bingsheng He"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      WIP", "url": "http://arxiv.org/abs/2507.13758v1", "summary": "Large Reasoning Models (LRMs) like DeepSeek-R1 and o1 are increasingly used\nas automated evaluators, raising critical questions about their vulnerability\nto the aesthetics of reasoning in LLM-as-a-judge settings. We introduce\nTHEATER, a comprehensive benchmark to systematically evaluate this\nvulnerability-termed Reasoning Theater Bias (RTB)-by comparing LLMs and LRMs\nacross subjective preference and objective factual datasets. Through\ninvestigation of six bias types including Simple Cues and Fake\nChain-of-Thought, we uncover three key findings: (1) in a critical paradox,\nreasoning-specialized LRMs are consistently more susceptible to RTB than\ngeneral-purpose LLMs, particularly in subjective tasks; (2) this creates a\ntask-dependent trade-off, where LRMs show more robustness on factual tasks but\nless on subjective ones; and (3) we identify 'shallow reasoning'-plausible but\nflawed arguments-as the most potent form of RTB. To address this, we design and\nevaluate two prompting strategies: a targeted system prompt that improves\naccuracy by up to 12% on factual tasks but only 1-3% on subjective tasks, and a\nself-reflection mechanism that shows similarly limited effectiveness in the\nmore vulnerable subjective domains. Our work reveals that RTB is a deep-seated\nchallenge for LRM-based evaluation and provides a systematic framework for\ndeveloping more genuinely robust and trustworthy LRMs.", "comment": "WIP", "pdf_url": "http://arxiv.org/pdf/2507.13758v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "皇帝的新思维链：探测大型推理模型中的推理表演偏见", "tldr": "研究发现，专门的推理大模型（LRMs）比通用大模型（LLMs）更容易受到“推理表演偏见”（RTB）的影响，尤其是在主观任务中，并提出了有限有效的缓解策略。", "motivation": "大型推理模型（LRMs）越来越多地被用作自动化评估器，这引发了对其在“大语言模型作为评判者”设置中，易受推理美学影响（即推理表演偏见，RTB）的严重质疑。本研究旨在系统地评估这种脆弱性。", "method": "引入了THEATER基准测试，通过比较大语言模型（LLMs）和大型推理模型（LRMs）在主观偏好和客观事实数据集上的表现，系统评估推理表演偏见（RTB）。研究调查了包括简单线索和虚假思维链在内的六种偏见类型。此外，设计并评估了两种提示策略：一种是针对性的系统提示，另一种是自我反思机制。", "result": "研究发现了三个关键发现：(1) 在一个关键的悖论中，专门用于推理的LRMs比通用LLMs更易受RTB影响，尤其是在主观任务中；(2) 这导致了一种任务依赖的权衡，LRMs在事实性任务上表现出更强的鲁棒性，但在主观任务上则较差；(3) “浅层推理”（看似合理但有缺陷的论证）被认为是RTB最强大的形式。为解决此问题，设计的提示策略效果有限：针对性系统提示在事实性任务上准确率提高了12%，但在主观任务上仅提高了1-3%；自我反思机制在更脆弱的主观领域也显示出类似有限的有效性。", "conclusion": "推理表演偏见（RTB）是基于LRM评估的一个根深蒂固的挑战。本研究为开发更真正鲁棒和值得信赖的LRMs提供了一个系统的框架。", "translation": "大型推理模型（LRMs），如DeepSeek-R1和o1，正越来越多地被用作自动化评估器，这引发了对其在“大语言模型作为评判者”设置中，易受推理美学影响的严重质疑。我们引入了THEATER，一个全面的基准测试，旨在系统地评估这种被称为“推理表演偏见”（RTB）的脆弱性，通过比较大语言模型（LLMs）和大型推理模型（LRMs）在主观偏好和客观事实数据集上的表现。通过对包括简单线索和虚假思维链在内的六种偏见类型的调查，我们揭示了三个关键发现：(1) 在一个关键的悖论中，专门用于推理的LRMs比通用LLMs始终更易受RTB影响，特别是在主观任务中；(2) 这导致了一种任务依赖的权衡，LRMs在事实性任务上表现出更强的鲁棒性，但在主观任务上则较差；(3) 我们将“浅层推理”（看似合理但有缺陷的论证）识别为RTB最强大的形式。为解决此问题，我们设计并评估了两种提示策略：一种是针对性的系统提示，在事实性任务上将准确率提高了12%，但在主观任务上仅提高了1-3%；另一种是自我反思机制，在更脆弱的主观领域显示出类似有限的有效性。我们的工作揭示了RTB是基于LRM评估的一个根深蒂固的挑战，并为开发更真正鲁棒和值得信赖的LRMs提供了一个系统的框架。", "summary": "本研究探讨了大型推理模型（LRMs）作为自动化评估器时面临的“推理表演偏见”（RTB）问题。通过引入THEATER基准测试，并对比LRMs与通用大语言模型（LLMs）在不同任务上的表现，研究发现LRMs在主观任务中比LLMs更容易受到RTB的影响，且“浅层推理”是主要偏见源。尽管尝试了系统提示和自我反思等缓解策略，但在主观任务上的效果有限。研究强调RTB是LRM评估中的一个深层挑战，并提出了未来开发更可靠LRMs的框架。", "keywords": "大型推理模型, 推理表演偏见, 自动化评估, 基准测试, 提示策略", "comments": "该论文创新性地提出了“推理表演偏见”（RTB）这一概念，并构建了THEATER基准来系统性评估大型推理模型（LRMs）的这一脆弱性。其重要性在于揭示了LRMs作为自动化评估器时，可能因“推理美学”而非实际推理能力产生误判的风险，尤其是在主观任务中。研究发现专业LRMs比通用LLMs更易受此偏见影响，这是一个反直觉但重要的发现。尽管提出的缓解策略效果有限，但这突出了该问题的复杂性和未来研究的必要性。"}}
{"id": "2507.14003", "title": "Hybrid Integration of Quantum Cascade Lasers with Germanium-on-Silicon waveguides for Mid-Infrared Sensing Applications", "authors": ["Colin J. Mitchell", "Longqi Zhou", "Ke Li", "Daniel Adeyemi", "Ahmed Osman", "Milos Nedeljkovic", "Glenn Churchill", "James C. Gates", "Graham T. Reed", "Kristian M. Groom", "Jon Heffernan", "Goran Mashanovich"], "categories": ["physics.optics", "eess.SP", "physics.app-ph"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures", "url": "http://arxiv.org/abs/2507.14003v1", "summary": "We present a novel scheme for hybrid integration of quantum cascade laser\nbars with germanium-on-silicon waveguides operating in the mid-infrared. The\nlaser bars are flip-chip bonded onto a germanium-on-silicon target chip without\nactive alignment, acheiving end-fire coupling efficiency of up to 45% (3.5 dB\nloss) in pulsed operation. Optical power estimates indicate 20-30 mW coupled\ninto the waveguides. The passive alignment approach, combined with a\nCMOS-compatible photonic integrated circuit fabrication process, offers a\nscalable pathway to fully integrated mid-infrared photonic systems for sensing,\nfree-space communications, and the realisation of novel light sources.", "comment": "8 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.14003v1", "cate": "physics.optics", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "中红外传感应用中量子级联激光器与锗硅波导的混合集成", "tldr": "该研究展示了一种将量子级联激光器与锗硅波导混合集成的新方案，通过无源对准实现了高效耦合，为中红外光子系统提供可扩展的集成途径。", "motivation": "旨在为中红外传感、自由空间通信和新型光源的实现提供可扩展的、完全集成的中红外光子系统。", "method": "采用翻转芯片键合技术，将量子级联激光器阵列无源对准地集成到锗硅靶芯片上的波导上，利用CMOS兼容的光子集成电路制造工艺。", "result": "在脉冲操作下，实现了高达45% (3.5 dB损耗) 的端射耦合效率，估计有20-30 mW的光功率耦合到波导中。", "conclusion": "被动对准方法与CMOS兼容的光子集成电路制造工艺相结合，为中红外传感、自由空间通信和新型光源的实现提供了可扩展的完全集成中红外光子系统路径。", "translation": "我们提出了一种用于中红外量子级联激光器阵列与锗硅波导混合集成的新方案。激光器阵列通过倒装芯片键合到锗硅靶芯片上，无需主动对准，在脉冲操作下实现了高达45%（3.5 dB损耗）的端射耦合效率。光学功率估计显示有20-30 mW的光功率耦合到波导中。这种被动对准方法，结合CMOS兼容的光子集成电路制造工艺，为传感、自由空间通信和新型光源的实现提供了可扩展的完全集成中红外光子系统路径。", "summary": "本文介绍了一种创新的混合集成方案，将中红外量子级联激光器阵列通过无源对准的翻转芯片键合技术集成到锗硅波导上。该方法在脉冲操作下实现了高效的端射耦合（45%），并能耦合20-30 mW的光功率。结合CMOS兼容的制造工艺，该方案为开发可扩展的集成中红外光子系统，应用于传感、通信及新型光源提供了可行路径。", "keywords": "量子级联激光器, 锗硅波导, 混合集成, 中红外传感, 被动对准", "comments": "这项研究的创新之处在于其提出的量子级联激光器与锗硅波导的混合集成方案，特别是采用了无需主动对准的翻转芯片键合技术，显著简化了集成过程并降低了成本。结合CMOS兼容工艺，这为中红外光子集成系统的规模化生产提供了重要进展，对于中红外传感和通信领域具有重要意义。"}}
{"id": "2507.14063", "title": "Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog", "authors": ["Lautaro Estienne", "Gabriel Ben Zenou", "Nona Naderi", "Jackie Cheung", "Pablo Piantanida"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14063v1", "summary": "As AI systems take on collaborative roles, they must reason about shared\ngoals and beliefs-not just generate fluent language. The Rational Speech Act\n(RSA) framework offers a principled approach to pragmatic reasoning, but\nexisting extensions face challenges in scaling to multi-turn, collaborative\nscenarios. In this paper, we introduce Collaborative Rational Speech Act\n(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn\ndialog by optimizing a gain function adapted from rate-distortion theory. This\ngain is an extension of the gain model that is maximized in the original RSA\nmodel but takes into account the scenario in which both agents in a\nconversation have private information and produce utterances conditioned on the\ndialog. We demonstrate the effectiveness of CRSA on referential games and\ntemplate-based doctor-patient dialogs in the medical domain. Empirical results\nshow that CRSA yields more consistent, interpretable, and collaborative\nbehavior than existing baselines-paving the way for more pragmatic and socially\naware language agents.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14063v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "协作式理性言语行为：多轮对话中的语用推理", "tldr": "引入协作式理性言语行为（CRSA），一种RSA的信息论扩展，通过优化增益函数来建模多轮对话，并在指称游戏和医患对话中表现出更一致、可解释和协作的行为。", "motivation": "现有AI系统在承担协作角色时，需要推理共享目标和信念，而不仅仅是流畅的语言生成。现有的理性言语行为（RSA）框架扩展在多轮协作场景中面临扩展挑战。", "method": "提出协作式理性言语行为（CRSA），它是RSA的信息论（IT）扩展。CRSA通过优化一个源自速率失真理论的增益函数来建模多轮对话，该函数考虑了对话中双方代理都拥有私有信息并基于对话生成话语的场景。", "result": "在指称游戏和基于模板的医患对话中，CRSA比现有基线模型产生更一致、可解释和协作的行为。", "conclusion": "CRSA为开发更具语用性和社会意识的语言智能体铺平了道路。", "translation": "随着AI系统承担协作角色，它们必须推理共享目标和信念，而不仅仅是生成流畅的语言。理性言语行为（RSA）框架提供了一种语用推理的原则性方法，但现有扩展在扩展到多轮协作场景时面临挑战。在本文中，我们引入了协作式理性言语行为（CRSA），它是RSA的一种信息论（IT）扩展，通过优化一个改编自速率失真理论的增益函数来建模多轮对话。该增益是原始RSA模型中最大化的增益模型的扩展，但考虑了对话中双方代理都拥有私有信息并根据对话生成话语的场景。我们展示了CRSA在指称游戏和医学领域基于模板的医患对话中的有效性。实证结果表明，CRSA比现有基线模型产生了更一致、可解释和协作的行为——为更具语用性和社会意识的语言智能体铺平了道路。", "summary": "本文针对AI系统在多轮协作对话中推理共享目标和信念的挑战，提出了协作式理性言语行为（CRSA）。CRSA是理性言语行为（RSA）框架的信息论扩展，它通过优化一个改编自速率失真理论的增益函数来建模多轮对话，特别考虑了对话双方拥有私有信息的情况。实验证明，CRSA在指称游戏和医患对话中表现出优于现有基线的更一致、可解释和协作的行为，有助于开发更具语用意识的语言智能体。", "keywords": "协作式理性言语行为, 多轮对话, 语用推理, 信息论, RSA", "comments": "本文的创新点在于将信息论与理性言语行为框架结合，提出了CRSA以解决多轮协作对话中的语用推理问题。通过引入考虑私有信息和对话条件下的增益函数优化，CRSA能够生成更自然、协作的对话行为，这对于提升AI在复杂交互场景中的能力具有重要意义。"}}
{"id": "2507.13373", "title": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection", "authors": ["Xiaojian Lin", "Wenxin Zhang", "Yuchu Jiang", "Wangyu Wu", "Yiran Guo", "Kangxu Wang", "Zongzheng Zhang", "Guijin Wang", "Lei Jin", "Hao Zhao"], "categories": ["cs.CV", "I.4.8; I.2.10; H.5.1; I.2.6"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures. Supplementary material: 8 pages, 7 figures. Accepted at ACM Multimedia 2025", "url": "http://arxiv.org/abs/2507.13373v1", "summary": "Hierarchical feature representations play a pivotal role in computer vision,\nparticularly in object detection for autonomous driving. Multi-level semantic\nunderstanding is crucial for accurately identifying pedestrians, vehicles, and\ntraffic signs in dynamic environments. However, existing architectures, such as\nYOLO and DETR, struggle to maintain feature consistency across different scales\nwhile balancing detection precision and computational efficiency. To address\nthese challenges, we propose Butter, a novel object detection framework\ndesigned to enhance hierarchical feature representations for improving\ndetection robustness. Specifically, Butter introduces two key innovations:\nFrequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which\nrefines multi-scale feature consistency by leveraging adaptive frequency\nfiltering to enhance structural and boundary precision, and Progressive\nHierarchical Feature Fusion Network (PHFFNet) Module, which progressively\nintegrates multi-level features to mitigate semantic gaps and strengthen\nhierarchical feature learning. Through extensive experiments on BDD100K, KITTI,\nand Cityscapes, Butter demonstrates superior feature representation\ncapabilities, leading to notable improvements in detection accuracy while\nreducing model complexity. By focusing on hierarchical feature refinement and\nintegration, Butter provides an advanced approach to object detection that\nachieves a balance between accuracy, deployability, and computational\nefficiency in real-time autonomous driving scenarios. Our model and\nimplementation are publicly available at https://github.com/Aveiro-Lin/Butter,\nfacilitating further research and validation within the autonomous driving\ncommunity.", "comment": "10 pages, 6 figures. Supplementary material: 8 pages, 7 figures.\n  Accepted at ACM Multimedia 2025", "pdf_url": "http://arxiv.org/pdf/2507.13373v1", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-12", "AI": {"title_translation": "Butter：自动驾驶目标检测中的频率一致性与分层融合", "tldr": "Butter是一种新的目标检测框架，通过频率自适应特征一致性增强和渐进式分层特征融合网络，解决了自动驾驶中多尺度特征一致性问题，提高了检测精度和效率。", "motivation": "现有目标检测架构（如YOLO和DETR）在自动驾驶中难以在不同尺度上保持特征一致性，同时平衡检测精度和计算效率，这导致在动态环境中准确识别行人、车辆和交通标志面临挑战。", "method": "本文提出了一个名为Butter的新型目标检测框架。该框架引入了两个关键创新点：频率自适应特征一致性增强（FAFCE）组件，它通过自适应频率滤波来增强多尺度特征一致性，提高结构和边界精度；渐进式分层特征融合网络（PHFFNet）模块，它逐步整合多级特征，以弥补语义鸿沟并加强分层特征学习。", "result": "在BDD100K、KITTI和Cityscapes数据集上进行的广泛实验表明，Butter展示了卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂性。", "conclusion": "Butter通过专注于分层特征的细化和集成，为目标检测提供了一种先进的方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的平衡。", "translation": "分层特征表示在计算机视觉中扮演着关键角色，尤其是在自动驾驶的目标检测中。多级语义理解对于在动态环境中准确识别行人、车辆和交通标志至关重要。然而，现有的架构，如YOLO和DETR，难以在保持跨不同尺度的特征一致性的同时，平衡检测精度和计算效率。为了解决这些挑战，我们提出了Butter，一个新颖的目标检测框架，旨在增强分层特征表示以提高检测的鲁棒性。具体来说，Butter引入了两项关键创新：频率自适应特征一致性增强（FAFCE）组件，它通过利用自适应频率滤波来细化多尺度特征一致性，以增强结构和边界精度；以及渐进式分层特征融合网络（PHFFNet）模块，它逐步整合多级特征，以弥补语义鸿沟并加强分层特征学习。通过在BDD100K、KITTI和Cityscapes上进行的广泛实验，Butter展示了卓越的特征表示能力，从而显著提高了检测精度，同时降低了模型复杂性。通过专注于分层特征的细化和集成，Butter为目标检测提供了一种先进的方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的平衡。我们的模型和实现已在https://github.com/Aveiro-Lin/Butter公开可用，便于自动驾驶社区的进一步研究和验证。", "summary": "本文提出了一种名为Butter的新型目标检测框架，旨在解决现有模型在自动驾驶中多尺度特征一致性差以及精度与效率平衡困难的问题。Butter通过引入频率自适应特征一致性增强（FAFCE）组件和渐进式分层特征融合网络（PHFFNet）模块，分别用于细化多尺度特征一致性和弥补语义鸿沟。实验结果表明，Butter在多个自动驾驶数据集上显著提升了检测精度并降低了模型复杂性，实现了精度、可部署性和计算效率的良好平衡。", "keywords": "自动驾驶, 目标检测, 分层特征, 频率一致性, 特征融合", "comments": "该论文提出了一种新颖的框架Butter，通过引入频率域的特征一致性增强和渐进式特征融合策略，有效解决了自动驾驶目标检测中多尺度特征表示的挑战。其创新点在于将频率自适应滤波引入特征一致性提升，以及通过分层融合弥补语义鸿沟。这对于提高实时自动驾驶场景下的检测精度和效率具有重要意义。"}}
{"id": "2502.02145", "title": "From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios", "authors": ["Yuan Gao", "Mattia Piccinini", "Korbinian Moller", "Amr Alanwar", "Johannes Betz"], "categories": ["cs.AI", "cs.CL", "cs.RO"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Final Version and Paper Accepted at IEEE ITSC 2025", "url": "http://arxiv.org/abs/2502.02145v4", "summary": "Ensuring the safety of autonomous vehicles requires virtual scenario-based\ntesting, which depends on the robust evaluation and generation of\nsafety-critical scenarios. So far, researchers have used scenario-based testing\nframeworks that rely heavily on handcrafted scenarios as safety metrics. To\nreduce the effort of human interpretation and overcome the limited scalability\nof these approaches, we combine Large Language Models (LLMs) with structured\nscenario parsing and prompt engineering to automatically evaluate and generate\nsafety-critical driving scenarios. We introduce Cartesian and Ego-centric\nprompt strategies for scenario evaluation, and an adversarial generation module\nthat modifies trajectories of risk-inducing vehicles (ego-attackers) to create\ncritical scenarios. We validate our approach using a 2D simulation framework\nand multiple pre-trained LLMs. The results show that the evaluation module\neffectively detects collision scenarios and infers scenario safety. Meanwhile,\nthe new generation module identifies high-risk agents and synthesizes\nrealistic, safety-critical scenarios. We conclude that an LLM equipped with\ndomain-informed prompting techniques can effectively evaluate and generate\nsafety-critical driving scenarios, reducing dependence on handcrafted metrics.\nWe release our open-source code and scenarios at:\nhttps://github.com/TUM-AVS/From-Words-to-Collisions.", "comment": "Final Version and Paper Accepted at IEEE ITSC 2025", "pdf_url": "http://arxiv.org/pdf/2502.02145v4", "cate": "cs.AI", "date": "2025-02-04", "updated": "2025-07-18", "AI": {"title_translation": "从文字到碰撞：LLM引导的安全关键驾驶场景评估与对抗生成", "tldr": "本文提出了一种基于大型语言模型（LLM）的方法，用于自动评估和生成自动驾驶汽车的安全关键驾驶场景，有效减少了对手工指标的依赖。", "motivation": "现有的自动驾驶虚拟场景测试严重依赖手工场景作为安全指标，导致人工解释工作量大且可扩展性有限，无法满足自动驾驶安全测试的需求。", "method": "结合大型语言模型（LLMs）、结构化场景解析和提示工程，自动评估和生成安全关键驾驶场景。具体方法包括引入笛卡尔和自我中心提示策略进行场景评估，以及一个对抗生成模块，通过修改风险诱导车辆（ego-attackers）的轨迹来创建关键场景。该方法在2D模拟框架和多个预训练LLMs上进行了验证。", "result": "评估模块能够有效检测碰撞场景并推断场景安全性。生成模块能够识别高风险代理并合成逼真、安全关键的场景。", "conclusion": "配备领域知识提示技术的大型语言模型能够有效地评估和生成安全关键驾驶场景，从而减少对传统手工指标的依赖。", "translation": "确保自动驾驶汽车的安全需要基于虚拟场景的测试，这取决于对安全关键场景的鲁棒评估和生成。迄今为止，研究人员使用的基于场景的测试框架严重依赖手工场景作为安全指标。为了减少人工解释的工作量并克服这些方法有限的可扩展性，我们结合大型语言模型（LLMs）与结构化场景解析和提示工程，自动评估和生成安全关键驾驶场景。我们引入了笛卡尔和自我中心提示策略用于场景评估，以及一个对抗生成模块，该模块修改风险诱导车辆（自我攻击者）的轨迹以创建关键场景。我们使用2D模拟框架和多个预训练LLM验证了我们的方法。结果表明，评估模块有效地检测了碰撞场景并推断了场景安全性。同时，新的生成模块识别了高风险代理并合成了逼真、安全关键的场景。我们得出结论，配备领域知识提示技术的大型语言模型可以有效地评估和生成安全关键驾驶场景，减少对手工指标的依赖。我们发布了我们的开源代码和场景：https://github.com/TUM-AVS/From-Words-to-Collisions。", "summary": "本文提出了一种利用大型语言模型（LLMs）结合结构化场景解析和提示工程的方法，以自动化评估和生成自动驾驶汽车的安全关键驾驶场景。该方法通过引入笛卡尔和自我中心提示策略进行场景评估，并利用对抗生成模块创建高风险场景。实验结果表明，该方法能有效检测碰撞场景、推断场景安全性，并合成逼真、安全关键的场景，显著减少了对传统手工场景和指标的依赖，提升了场景测试的效率和可扩展性。", "keywords": "大型语言模型, 自动驾驶, 安全关键场景, 对抗生成, 场景评估", "comments": "这项研究创新性地将LLM应用于自动驾驶安全关键场景的评估与生成，解决了传统手工方法可扩展性差和工作量大的问题。通过引入提示工程和对抗生成，提高了场景测试的效率和多样性，对于自动驾驶系统的安全验证具有重要意义。其开源代码的发布也促进了相关领域的研究进展。"}}
{"id": "2507.14046", "title": "D2IP: Deep Dynamic Image Prior for 3D Time-sequence Pulmonary Impedance Imaging", "authors": ["Hao Fang", "Hao Yu", "Sihao Teng", "Tao Zhang", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      11 pages, 9 figures", "url": "http://arxiv.org/abs/2507.14046v1", "summary": "Unsupervised learning methods, such as Deep Image Prior (DIP), have shown\ngreat potential in tomographic imaging due to their training-data-free nature\nand high generalization capability. However, their reliance on numerous network\nparameter iterations results in high computational costs, limiting their\npractical application, particularly in complex 3D or time-sequence tomographic\nimaging tasks. To overcome these challenges, we propose Deep Dynamic Image\nPrior (D2IP), a novel framework for 3D time-sequence imaging. D2IP introduces\nthree key strategies - Unsupervised Parameter Warm-Start (UPWS), Temporal\nParameter Propagation (TPP), and a customized lightweight reconstruction\nbackbone, 3D-FastResUNet - to accelerate convergence, enforce temporal\ncoherence, and improve computational efficiency. Experimental results on both\nsimulated and clinical pulmonary datasets demonstrate that D2IP enables fast\nand accurate 3D time-sequence Electrical Impedance Tomography (tsEIT)\nreconstruction. Compared to state-of-the-art baselines, D2IP delivers superior\nimage quality, with a 24.8% increase in average MSSIM and an 8.1% reduction in\nERR, alongside significantly reduced computational time (7.1x faster),\nhighlighting its promise for clinical dynamic pulmonary imaging.", "comment": "11 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.14046v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "D2IP：用于3D时序肺阻抗成像的深度动态图像先验", "tldr": "针对DIP在3D时序成像中计算成本高的问题，本文提出了D2IP框架，通过UPWS、TPP和3D-FastResUNet策略，显著加速了3D时序肺阻抗断层成像，并提高了图像质量和计算效率。", "motivation": "现有的无监督学习方法（如DIP）在断层成像中计算成本高昂，尤其在复杂的3D或时序断层成像任务中，限制了其实际应用。", "method": "提出了一种名为深度动态图像先验（D2IP）的新型3D时序成像框架。D2IP引入了三个关键策略：无监督参数热启动（UPWS）、时间参数传播（TPP）和定制的轻量级重建骨干网络3D-FastResUNet，以加速收敛、增强时间一致性并提高计算效率。", "result": "在模拟和临床肺部数据集上的实验结果表明，D2IP能够实现快速准确的3D时序电阻抗断层成像（tsEIT）重建。与现有最先进的基线相比，D2IP提供了卓越的图像质量（平均MSSIM增加24.8%，ERR减少8.1%），同时显著减少了计算时间（快7.1倍）。", "conclusion": "D2IP在临床动态肺部成像方面展现出巨大潜力。", "translation": "无监督学习方法，例如深度图像先验（DIP），由于其无需训练数据和高泛化能力的特性，在断层成像中展现出巨大潜力。然而，它们对大量网络参数迭代的依赖导致计算成本高昂，限制了其实际应用，特别是在复杂的3D或时序断层成像任务中。为了克服这些挑战，我们提出了深度动态图像先验（D2IP），一个用于3D时序成像的新颖框架。D2IP引入了三个关键策略——无监督参数热启动（UPWS）、时间参数传播（TPP）以及定制的轻量级重建骨干网络3D-FastResUNet——以加速收敛、强制执行时间相干性并提高计算效率。在模拟和临床肺部数据集上的实验结果表明，D2IP能够实现快速准确的3D时序电阻抗断层成像（tsEIT）重建。与现有最先进的基线相比，D2IP提供了卓越的图像质量，平均MSSIM增加了24.8%，ERR减少了8.1%，同时显著减少了计算时间（快7.1倍），突显了其在临床动态肺部成像方面的应用前景。", "summary": "本文针对深度图像先验（DIP）在3D时序断层成像中计算成本高的问题，提出了一种新型框架D2IP。D2IP通过引入无监督参数热启动（UPWS）、时间参数传播（TPP）和轻量级3D-FastResUNet，显著加速了3D时序肺阻抗断层成像的收敛速度，提高了计算效率和图像质量。实验证明，D2IP在速度和精度上均优于现有方法，在临床动态肺部成像中具有广阔前景。", "keywords": "深度图像先验, 3D时序成像, 肺阻抗成像, 无监督学习, D2IP", "comments": "该论文提出D2IP框架，有效解决了深度图像先验（DIP）在处理3D时序成像时计算成本高昂的痛点。通过引入UPWS、TPP和定制的3D-FastResUNet，不仅显著提升了重建速度，还在图像质量上取得了显著优势，对于推动临床动态肺部成像的应用具有重要意义。其创新点在于结合了无监督学习的优势与针对时序数据优化的加速策略。"}}
{"id": "2501.00152", "title": "Temporal reasoning for timeline summarisation in social media", "authors": ["Jiayu Song", "Mahmud Elahi Akhter", "Dana Atzil Slonim", "Maria Liakata"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.00152v3", "summary": "This paper explores whether enhancing temporal reasoning capabilities in\nLarge Language Models (LLMs) can improve the quality of timeline summarisation,\nthe task of summarising long texts containing sequences of events, such as\nsocial media threads. We first introduce NarrativeReason, a novel dataset\nfocused on temporal relationships among sequential events within narratives,\ndistinguishing it from existing temporal reasoning datasets that primarily\naddress pair-wise event relationships. Our approach then combines temporal\nreasoning with timeline summarisation through a knowledge distillation\nframework, where we first fine-tune a teacher model on temporal reasoning tasks\nand then distill this knowledge into a student model while simultaneously\ntraining it for the task of timeline summarisation. Experimental results\ndemonstrate that our model achieves superior performance on out-of-domain\nmental health-related timeline summarisation tasks, which involve long social\nmedia threads with repetitions of events and a mix of emotions, highlighting\nthe importance and generalisability of leveraging temporal reasoning to improve\ntimeline summarisation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.00152v3", "cate": "cs.CL", "date": "2024-12-30", "updated": "2025-07-18", "AI": {"title_translation": "社交媒体时间线摘要中的时间推理", "tldr": "本文探讨了通过增强大型语言模型（LLM）的时间推理能力来改进社交媒体时间线摘要的方法，并引入了一个新数据集和知识蒸馏框架，实验证明了其在域外任务上的优越性能。", "motivation": "本文旨在探究增强大型语言模型（LLM）的时间推理能力是否能提高时间线摘要的质量，时间线摘要是总结包含一系列事件（如社交媒体帖子）的长文本的任务。", "method": "首先，引入了一个名为NarrativeReason的新数据集，该数据集侧重于叙事中顺序事件之间的时间关系。其次，通过知识蒸馏框架将时间推理与时间线摘要相结合：先在时间推理任务上微调一个教师模型，然后将此知识蒸馏到一个学生模型中，同时训练学生模型进行时间线摘要任务。", "result": "实验结果表明，该模型在域外心理健康相关的时间线摘要任务上取得了卓越的性能。这些任务涉及包含事件重复和情感混合的冗长社交媒体帖子。", "conclusion": "研究结果强调了利用时间推理来改进时间线摘要的重要性和泛化能力。", "translation": "本文探讨了增强大型语言模型（LLM）的时间推理能力是否能提高时间线摘要的质量，时间线摘要是总结包含一系列事件（如社交媒体帖子）的长文本的任务。我们首先介绍了一个名为NarrativeReason的新数据集，该数据集侧重于叙事中顺序事件之间的时间关系，这与主要处理成对事件关系现有时间推理数据集不同。然后，我们的方法通过知识蒸馏框架将时间推理与时间线摘要相结合，我们首先在时间推理任务上微调一个教师模型，然后将此知识蒸馏到学生模型中，同时训练其进行时间线摘要任务。实验结果表明，我们的模型在域外心理健康相关的时间线摘要任务上取得了卓越的性能，这些任务涉及包含事件重复和情感混合的冗长社交媒体帖子，这突显了利用时间推理来改进时间线摘要的重要性和泛化能力。", "summary": "本研究探讨了通过增强大型语言模型（LLM）的时间推理能力来改进社交媒体时间线摘要任务。为此，论文引入了新的NarrativeReason数据集，专注于叙事中的顺序事件时间关系。研究方法采用知识蒸馏框架，首先在时间推理任务上训练一个教师模型，然后将所学知识蒸馏到学生模型中，同时训练学生模型执行时间线摘要任务。实验结果表明，该方法在域外心理健康相关的时间线摘要任务中表现出色，证明了时间推理对于改进时间线摘要的有效性和泛化性。", "keywords": "时间推理, 时间线摘要, 大型语言模型, 知识蒸馏, NarrativeReason数据集", "comments": "该论文的创新点在于提出了一个专门针对叙事中顺序事件时间关系的新数据集NarrativeReason，并利用知识蒸馏框架将时间推理能力有效融入到时间线摘要任务中。其在域外心理健康数据上的优异表现，凸显了该方法在处理复杂、真实世界社交媒体数据方面的潜力和泛化性，对于提升LLM在事件序列理解和总结方面的能力具有重要意义。"}}
{"id": "2501.11264", "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian", "authors": ["Wannita Takerngsaksiri", "Chakkrit Tantithamthavorn", "Micheal Fu", "Jirat Pasuksmit", "Kun Chen", "Ming Wu"], "categories": ["cs.SE", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Software Engineering (cs.SE)", "pdf_link": null, "comments": "Comments:      11 pages, 7 figures, 8 tables, Accepted at ICSME", "url": "http://arxiv.org/abs/2501.11264v3", "summary": "Software engineers spend a significant amount of time reading code during the\nsoftware development process, especially in the age of large language models\n(LLMs) that can automatically generate code. However, little is known about the\nreadability of the LLM-generated code and whether it is still important from\npractitioners' perspectives in this new era. In this paper, we conduct a survey\nto explore the practitioners' perspectives on code readability in the age of\nLLMs and investigate the readability of our LLM-based software development\nagents framework, HULA, by comparing its generated code with human-written code\nin real-world scenarios. Overall, the findings underscore that (1) readability\nremains a critical aspect of software development; (2) the readability of our\nLLM-generated code is comparable to human-written code, fostering the\nestablishment of appropriate trust and driving the broad adoption of our\nLLM-powered software development platform.", "comment": "11 pages, 7 figures, 8 tables, Accepted at ICSME", "pdf_url": "http://arxiv.org/pdf/2501.11264v3", "cate": "cs.SE", "date": "2025-01-20", "updated": "2025-07-18", "AI": {"title_translation": "大型语言模型时代的代码可读性：来自Atlassian的工业案例研究", "tldr": "本研究探讨了大型语言模型（LLM）时代代码可读性的重要性，并发现LLM生成的代码可读性与人类编写的代码相当，这有助于提升信任和推广LLM驱动的开发平台。", "motivation": "软件工程师在软件开发过程中花费大量时间阅读代码，尤其是在大型语言模型（LLM）能够自动生成代码的时代。然而，关于LLM生成代码的可读性以及它在这一新时代从实践者的角度来看是否仍然重要，人们知之甚少。", "method": "本研究进行了一项调查，以探究实践者在大型语言模型时代对代码可读性的看法。通过在真实场景中比较其LLM驱动的软件开发代理框架HULA生成的代码与人类编写的代码，来调查其可读性。", "result": "研究结果表明：1) 可读性仍然是软件开发的关键方面；2) LLM生成的代码可读性与人类编写的代码相当，这有助于建立适当的信任并推动其LLM驱动的软件开发平台的广泛采用。", "conclusion": "代码可读性在大型语言模型时代依然至关重要，且该研究中LLM生成的代码可读性与人类编写的代码相当，有助于提升用户信任并促进LLM驱动的开发平台普及。", "translation": "软件工程师在软件开发过程中花费大量时间阅读代码，尤其是在大型语言模型（LLM）可以自动生成代码的时代。然而，关于LLM生成代码的可读性以及它在这一新时代从实践者的角度来看是否仍然重要，人们知之甚少。在本文中，我们进行了一项调查，以探究实践者在LLM时代对代码可读性的看法，并通过在真实场景中比较其LLM驱动的软件开发代理框架HULA生成的代码与人类编写的代码，来调查其可读性。总体而言，研究结果强调：(1) 可读性仍然是软件开发的关键方面；(2) 我们LLM生成的代码可读性与人类编写的代码相当，这有助于建立适当的信任并推动我们LLM驱动的软件开发平台的广泛采用。", "summary": "本研究探讨了大型语言模型（LLM）时代代码可读性的重要性，并对Atlassian的LLM驱动软件开发代理框架HULA进行了工业案例研究。通过调查实践者观点和比较HULA生成的代码与人类编写的代码，发现代码可读性依然关键，且LLM生成代码的可读性与人类编写的相当，这有助于增强对LLM驱动平台的信任和推广。", "keywords": "代码可读性, 大型语言模型, 工业案例研究, 软件开发, HULA", "comments": "本论文通过工业案例研究，填补了大型语言模型时代代码可读性认知空白。其创新之处在于结合了实践者调查和实际代码比较，验证了LLM生成代码的可读性，这对于推动LLM在软件开发领域的应用具有重要意义。研究结果直接支持了LLM生成代码的实用性和可靠性，特别是在可读性这一关键维度上。"}}
{"id": "2507.13618", "title": "Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters", "authors": ["Shanbo Cheng", "Yu Bao", "Qian Cao", "Luyang Huang", "Liyan Kang", "Zhicheng Liu", "Yu Lu", "Wenhao Zhu", "Zhichao Huang", "Tao Li", "Sitong Liu", "Ningxin Peng", "Shuaijie She", "Lu Xu", "Nuo Xu", "Sen Yang", "Runsheng Yu", "Yiming Yu", "Liehao Zou", "Hang Li", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13618v1", "summary": "Multilingual translation stands as a challenging task for large language\nmodels (LLMs) to handle intricate language patterns and stilted translations\nthat arise in automated translations. In this paper, we introduce Seed-X, a\nfamily of open-source LLMs comprising instruct and reasoning models, pushing\nthe limits of translation capability with 7B parameter size. The base model is\npre-trained on a diverse, high-quality dataset encompassing both monolingual\nand bilingual content across 28 languages, harnessing the full potential of\nmultilingual data. The instruct model is then finetuned to translate by\nChain-of-Thought (CoT) reasoning and further enhanced through reinforcement\nlearning (RL) to achieve better generalization across diverse language pairs.\nSeed-X achieves performance comparable to leading closed-source models,\nincluding Gemini-2.5 and GPT-4o, across 28 languages, and significantly\noutperforms larger open-source models in both automatic metrics and human\nevaluations. We share the best practices through our optimization process, and\nmake the parameter public available for advancing translation research and\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13618v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Seed-X：构建强大的7B参数多语言翻译大语言模型", "tldr": "Seed-X是一个7B参数的开源多语言翻译LLM，通过高质量数据集预训练、CoT微调和RL增强，在28种语言上性能媲美Gemini-2.5和GPT-4o，并超越其他开源模型。", "motivation": "解决大型语言模型（LLM）在多语言翻译中处理复杂语言模式和生硬翻译的挑战。", "method": "基础模型在涵盖28种语言的单语和双语高质量多样化数据集上进行预训练。指令模型通过思维链（CoT）推理进行微调，并通过强化学习（RL）进一步增强，以实现更好的跨语言对泛化。", "result": "Seed-X在28种语言上的性能与领先的闭源模型（包括Gemini-2.5和GPT-4o）相当。在自动指标和人工评估中，显著优于更大的开源模型。研究者分享了优化过程中的最佳实践，并公开了模型参数。", "conclusion": "Seed-X证明了即使是7B参数的LLM，通过精心设计的数据和训练方法，也能在多语言翻译任务上达到顶尖水平，甚至超越更大的模型，并公开了模型参数以促进研究。", "translation": "多语言翻译对大型语言模型（LLM）来说是一项具有挑战性的任务，需要处理复杂的语言模式和自动化翻译中出现的生硬翻译。在本文中，我们介绍了Seed-X，一个包含指令模型和推理模型的开源LLM家族，以7B参数的规模推动了翻译能力的极限。基础模型在涵盖28种语言的单语和双语内容的多样化、高质量数据集上进行了预训练，充分利用了多语言数据的潜力。然后，指令模型通过思维链（CoT）推理进行微调，并通过强化学习（RL）进一步增强，以在不同语言对之间实现更好的泛化。Seed-X在28种语言上的性能与领先的闭源模型（包括Gemini-2.5和GPT-4o）相当，并且在自动指标和人工评估中显著优于更大的开源模型。我们通过优化过程分享了最佳实践，并公开了参数，以促进翻译研究和应用。", "summary": "本文介绍了Seed-X，一个7B参数的开源多语言翻译大语言模型。该模型通过在28种语言的高质量多语数据集上预训练，并结合思维链（CoT）微调和强化学习（RL）增强，有效提升了翻译能力。Seed-X在性能上与顶尖闭源模型（如Gemini-2.5和GPT-4o）相当，并显著超越其他开源模型，为多语言翻译研究提供了新的强大基线和开源资源。", "keywords": "多语言翻译, 大语言模型, Seed-X, 思维链, 强化学习", "comments": "该论文展示了在相对较小的7B参数规模下，通过高质量数据预训练、CoT微调和RL增强，可以构建出性能媲美甚至超越更大模型的多语言翻译LLM。其开源策略有助于推动社区在多语言翻译领域的进一步研究和应用，降低了高性能翻译模型的门槛。"}}
{"id": "2507.13563", "title": "A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models", "authors": ["Kirill Borodin", "Nikita Vasiliev", "Vasiliy Kudryavtsev", "Maxim Maslov", "Mikhail Gorodnichev", "Oleg Rogov", "Grach Mkrtchian"], "categories": ["cs.CL", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      The work is still in progress", "url": "http://arxiv.org/abs/2507.13563v1", "summary": "Russian speech synthesis presents distinctive challenges, including vowel\nreduction, consonant devoicing, variable stress patterns, homograph ambiguity,\nand unnatural intonation. This paper introduces Balalaika, a novel dataset\ncomprising more than 2,000 hours of studio-quality Russian speech with\ncomprehensive textual annotations, including punctuation and stress markings.\nExperimental results show that models trained on Balalaika significantly\noutperform those trained on existing datasets in both speech synthesis and\nenhancement tasks. We detail the dataset construction pipeline, annotation\nmethodology, and results of comparative evaluations.", "comment": "The work is still in progress", "pdf_url": "http://arxiv.org/pdf/2507.13563v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "解决俄语语音生成模型中语音和韵律挑战的数据中心框架", "tldr": "引入Balalaika数据集，显著改善俄语语音合成模型性能。", "motivation": "俄语语音合成面临独特的挑战，包括元音弱化、辅音清化、可变重音模式、同形异义词模糊性和不自然的语调。", "method": "本文引入了一个名为Balalaika的新型数据集，包含超过2,000小时的录音室质量俄语语音，并附有包含标点和重音标记的全面文本注释。论文还详细介绍了数据集的构建流程和注释方法。", "result": "实验结果表明，在Balalaika数据集上训练的模型在语音合成和增强任务中均显著优于在现有数据集上训练的模型。", "conclusion": "Balalaika数据集的引入有效地解决了俄语语音生成模型中的语音和韵律挑战，通过高质量和详细标注的数据显著提升了模型性能。", "translation": "俄语语音合成面临独特的挑战，包括元音弱化、辅音清化、可变重音模式、同形异义词模糊性和不自然的语调。本文介绍了Balalaika，一个新颖的数据集，包含超过2,000小时的录音室质量俄语语音，并带有全面的文本注释，包括标点符号和重音标记。实验结果表明，在Balalaika上训练的模型在语音合成和增强任务中均显著优于在现有数据集上训练的模型。我们详细介绍了数据集的构建流程、注释方法以及比较评估结果。", "summary": "本文针对俄语语音合成中存在的语音和韵律难题，提出了一种数据中心框架，并介绍了名为Balalaika的新型高质量俄语语音数据集。该数据集包含超过2000小时的录音室质量语音及详细文本标注。实验证明，基于Balalaika训练的模型在语音合成和增强任务中表现显著优于现有模型。", "keywords": "俄语语音合成, 数据集, Balalaika, 语音生成模型, 语音增强", "comments": "这篇论文通过构建一个大规模、高质量且详细标注的俄语语音数据集Balalaika，创新性地采用数据中心方法来解决俄语语音合成的特有难题。其重要性在于，通过提供更丰富、更准确的数据，显著提升了俄语语音生成模型的性能，为该领域的研究和应用奠定了坚实基础，尤其是在处理复杂语音现象方面。"}}
{"id": "2412.05144", "title": "$ε$-rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics", "authors": ["Jiang Yang", "Yuxiang Zhao", "Quanhui Zhu"], "categories": ["cs.LG", "cs.NA", "math.NA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05144v3", "summary": "Understanding the training dynamics of deep neural networks (DNNs),\nparticularly how they evolve low-dimensional features from high-dimensional\ndata, remains a central challenge in deep learning theory. In this work, we\nintroduce the concept of $\\epsilon$-rank, a novel metric quantifying the\neffective feature of neuron functions in the terminal hidden layer. Through\nextensive experiments across diverse tasks, we observe a universal staircase\nphenomenon: during training process implemented by the standard stochastic\ngradient descent methods, the decline of the loss function is accompanied by an\nincrease in the $\\epsilon$-rank and exhibits a staircase pattern.\nTheoretically, we rigorously prove a negative correlation between the loss\nlower bound and $\\epsilon$-rank, demonstrating that a high $\\epsilon$-rank is\nessential for significant loss reduction. Moreover, numerical evidences show\nthat within the same deep neural network, the $\\epsilon$-rank of the subsequent\nhidden layer is higher than that of the previous hidden layer. Based on these\nobservations, to eliminate the staircase phenomenon, we propose a novel\npre-training strategy on the initial hidden layer that elevates the\n$\\epsilon$-rank of the terminal hidden layer. Numerical experiments validate\nits effectiveness in reducing training time and improving accuracy across\nvarious tasks. Therefore, the newly introduced concept of $\\epsilon$-rank is a\ncomputable quantity that serves as an intrinsic effective metric characteristic\nfor deep neural networks, providing a novel perspective for understanding the\ntraining dynamics of neural networks and offering a theoretical foundation for\ndesigning efficient training strategies in practical applications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05144v3", "cate": "cs.LG", "date": "2024-12-06", "updated": "2025-07-18", "AI": {"title_translation": "$\\\\epsilon$-秩与阶梯现象：神经网络训练动态的新见解", "tldr": "本文引入了$\\\\epsilon$-秩，一种量化神经网络有效特征的新度量，并观察到训练中损失下降伴随$\\\\epsilon$-秩上升的“阶梯现象”。理论证明高$\\\\epsilon$-秩对损失降低至关重要。基于此，提出了一种新的预训练策略，可有效减少训练时间并提高准确性。", "motivation": "理解深度神经网络（DNNs）在训练过程中如何从高维数据中演化出低维特征，仍然是深度学习理论中的一个核心挑战。", "method": "引入了$\\\\epsilon$-秩作为量化终端隐藏层神经元函数有效特征的新度量。通过实验观察到普遍的阶梯现象。理论上证明了损失下界与$\\\\epsilon$-秩之间的负相关。提出了一种新颖的初始隐藏层预训练策略，以提升终端隐藏层的$\\\\epsilon$-秩来消除阶梯现象。", "result": "观察到普遍的“阶梯现象”：在标准随机梯度下降训练中，损失下降伴随$\\\\epsilon$-秩的增加并呈现阶梯模式。理论上严格证明了损失下界与$\\\\epsilon$-秩之间存在负相关，表明高$\\\\epsilon$-秩对于显著的损失降低至关重要。数值证据显示，后续隐藏层的$\\\\epsilon$-秩高于前一个隐藏层。所提出的预训练策略有效减少了训练时间并提高了各种任务的准确性。", "conclusion": "新引入的$\\\\epsilon$-秩是一个可计算的量，可作为深度神经网络的内在有效度量特征，为理解神经网络的训练动态提供了新视角，并为在实际应用中设计高效训练策略提供了理论基础。", "translation": "理解深度神经网络（DNNs）的训练动态，特别是它们如何从高维数据中演化出低维特征，仍然是深度学习理论中的一个核心挑战。在这项工作中，我们引入了$\\\\epsilon$-秩的概念，这是一种量化终端隐藏层神经元函数有效特征的新度量。通过在各种任务中进行的大量实验，我们观察到一种普遍的阶梯现象：在标准随机梯度下降方法实现的训练过程中，损失函数的下降伴随着$\\\\epsilon$-秩的增加，并呈现出阶梯状模式。理论上，我们严格证明了损失下界与$\\\\epsilon$-秩之间存在负相关，表明高$\\\\epsilon$-秩对于显著的损失降低至关重要。此外，数值证据表明，在相同的深度神经网络中，后续隐藏层的$\\\\epsilon$-秩高于前一个隐藏层。基于这些观察，为了消除阶梯现象，我们提出了一种新颖的初始隐藏层预训练策略，该策略提升了终端隐藏层的$\\\\epsilon$-秩。数值实验验证了其在减少训练时间和提高各种任务准确性方面的有效性。因此，新引入的$\\\\epsilon$-秩概念是一个可计算的量，可作为深度神经网络的内在有效度量特征，为理解神经网络的训练动态提供了新视角，并为在实际应用中设计高效训练策略提供了理论基础。", "summary": "本文引入了$\\\\epsilon$-秩，一种量化深度神经网络中神经元函数有效特征的新度量。研究发现，在训练过程中存在一种普遍的“阶梯现象”，即损失下降伴随着$\\\\epsilon$-秩的增加。理论分析证明，高$\\\\epsilon$-秩对于显著的损失降低至关重要。基于这些发现，作者提出了一种新颖的初始隐藏层预训练策略来提升$\\\\epsilon$-秩，并通过实验验证了其在缩短训练时间和提高准确性方面的有效性。该研究强调了$\\\\epsilon$-秩作为理解神经网络训练动态和设计高效训练策略的重要内在指标。", "keywords": "$\\\\epsilon$-秩, 神经网络训练动态, 阶梯现象, 深度学习理论, 预训练策略", "comments": "该论文引入了一个新颖且可计算的度量——$\\\\epsilon$-秩，为理解深度神经网络复杂的训练动态，特别是观察到的“阶梯现象”，提供了新的视角。将$\\\\epsilon$-秩与损失降低联系起来的理论证明具有重要意义。此外，基于观察和理论理解提出的预训练策略，通过提高训练效率和准确性，展示了其实际应用价值。这项工作对深度学习的理论理解和实际应用都做出了贡献。"}}
{"id": "2507.13398", "title": "Characterizing the Dynamics of Conspiracy Related German Telegram Conversations during COVID-19", "authors": ["Elisabeth Höldrich", "Mathias Angermaier", "Jana Lasser", "Joao Pinheiro-Neto"], "categories": ["cs.SI", "physics.soc-ph"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      24 pages, 7 figures, 4 tables", "url": "http://arxiv.org/abs/2507.13398v1", "summary": "Conspiracy theories have long drawn public attention, but their explosive\ngrowth on platforms like Telegram during the COVID-19 pandemic raises pressing\nquestions about their impact on societal trust, democracy, and public health.\nWe provide a geographical, temporal and network analysis of the structure of of\nconspiracy-related German-language Telegram chats in a novel large-scale data\nset. We examine how information flows between regional user groups and\ninfluential broadcasting channels, revealing the interplay between\ndecentralized discussions and content spread driven by a small number of key\nactors.\n  Our findings reveal that conspiracy-related activity spikes during major\nCOVID-19-related events, correlating with societal stressors and mirroring\nprior research on how crises amplify conspiratorial beliefs. By analysing the\ninterplay between regional, national and transnational chats, we uncover how\ninformation flows from larger national or transnational discourse to localised,\ncommunity-driven discussions. Furthermore, we find that the top 10% of chats\naccount for 94% of all forwarded content, portraying the large influence of a\nfew actors in disseminating information. However, these chats operate\nindependently, with minimal interconnection between each other, primarily\nforwarding messages to low-traffic groups. Notably, 43% of links shared in the\ndata set point to untrustworthy sources as identified by NewsGuard, a\nproportion far exceeding their share on other platforms and in other discourse\ncontexts, underscoring the role of conspiracy-related discussions on Telegram\nas vector for the spread of misinformation.", "comment": "24 pages, 7 figures, 4 tables", "pdf_url": "http://arxiv.org/pdf/2507.13398v1", "cate": "cs.SI", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "表征COVID-19期间与阴谋论相关的德国Telegram对话的动态", "tldr": "该研究分析了COVID-19期间与阴谋论相关的德国Telegram对话的动态，发现活动在危机期间激增，信息从全国层面流向地方，少数关键参与者主导内容传播，且大量链接指向不可信来源，突显了Telegram在传播虚假信息方面的作用。", "motivation": "COVID-19大流行期间，阴谋论在Telegram等平台上的爆炸性增长，引发了对其对社会信任、民主和公共健康影响的紧迫问题。", "method": "本研究利用一个新颖的大规模数据集，对与阴谋论相关的德语Telegram聊天进行了地理、时间和网络分析。它还考察了信息如何在区域用户群和有影响力的广播频道之间流动。", "result": "研究发现，与阴谋论相关的活动在COVID-19相关重大事件期间激增，这与社会压力相关。信息从较大的国家或跨国讨论流向本地化、社区驱动的讨论。排名前10%的聊天记录占所有转发内容的94%，表明少数参与者在信息传播中的巨大影响力。这些有影响力的聊天独立运作，彼此之间的互联性极小，主要向低流量群组转发消息。数据集中43%的共享链接指向NewsGuard识别的不可信来源，这一比例远超其他平台和语境，强调了Telegram上阴谋论相关讨论作为虚假信息传播载体的作用。", "conclusion": "Telegram在传播与阴谋论相关的虚假信息方面扮演着重要角色，其传播活动在危机期间被放大，信息从更广泛的讨论流向本地社群，且主要由少数有影响力的参与者驱动，并伴随着大量不可信链接的传播。", "translation": "阴谋论长期以来一直吸引着公众的关注，但它们在COVID-19大流行期间在Telegram等平台上的爆炸性增长，引发了对其对社会信任、民主和公共健康影响的紧迫问题。我们利用一个新颖的大规模数据集，对与阴谋论相关的德语Telegram聊天的结构进行了地理、时间和网络分析。我们考察了信息如何在区域用户群和有影响力的广播频道之间流动，揭示了去中心化讨论与少数关键参与者驱动的内容传播之间的相互作用。\n我们的研究结果显示，与阴谋论相关的活动在COVID-19相关重大事件期间激增，这与社会压力相关，并与先前关于危机如何放大阴谋论信仰的研究相吻合。通过分析区域、国家和跨国聊天之间的相互作用，我们揭示了信息如何从更大的国家或跨国话语流向本地化、社区驱动的讨论。此外，我们发现排名前10%的聊天记录占所有转发内容的94%，这描绘了少数参与者在传播信息中的巨大影响力。然而，这些聊天独立运作，彼此之间的互联性极小，主要向低流量群组转发消息。值得注意的是，数据集中43%的共享链接指向NewsGuard识别的不可信来源，这一比例远超其他平台和语境中的份额，突显了Telegram上阴谋论相关讨论作为虚假信息传播载体的作用。", "summary": "本研究通过对大规模德语Telegram聊天数据的地理、时间和网络分析，探讨了COVID-19期间阴谋论相关的动态。研究发现，阴谋论活动在疫情相关事件期间显著增加，信息从国家层面流向地方社区。少数有影响力的频道主导了绝大部分内容转发，且共享链接中大量指向不可信来源，揭示了Telegram在虚假信息传播中的关键作用。", "keywords": "阴谋论, Telegram, COVID-19, 虚假信息, 网络分析", "comments": "该论文对COVID-19期间德国Telegram上阴谋论的动态进行了深入分析，填补了特定平台和语言背景下研究的空白。其关于信息流向、少数关键参与者影响力以及不可信信息高比例传播的发现，对于理解和对抗网络虚假信息具有重要意义。对Telegram这一相对不透明平台的关注，也增加了研究的创新性。"}}
{"id": "2507.13912", "title": "Self-supervised learning on gene expression data", "authors": ["Kevin Dradjat", "Massinissa Hamidi", "Pierre Bartet", "Blaise Hanczar"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13912v1", "summary": "Predicting phenotypes from gene expression data is a crucial task in\nbiomedical research, enabling insights into disease mechanisms, drug responses,\nand personalized medicine. Traditional machine learning and deep learning rely\non supervised learning, which requires large quantities of labeled data that\nare costly and time-consuming to obtain in the case of gene expression data.\nSelf-supervised learning has recently emerged as a promising approach to\novercome these limitations by extracting information directly from the\nstructure of unlabeled data. In this study, we investigate the application of\nstate-of-the-art self-supervised learning methods to bulk gene expression data\nfor phenotype prediction. We selected three self-supervised methods, based on\ndifferent approaches, to assess their ability to exploit the inherent structure\nof the data and to generate qualitative representations which can be used for\ndownstream predictive tasks. By using several publicly available gene\nexpression datasets, we demonstrate how the selected methods can effectively\ncapture complex information and improve phenotype prediction accuracy. The\nresults obtained show that self-supervised learning methods can outperform\ntraditional supervised models besides offering significant advantage by\nreducing the dependency on annotated data. We provide a comprehensive analysis\nof the performance of each method by highlighting their strengths and\nlimitations. We also provide recommendations for using these methods depending\non the case under study. Finally, we outline future research directions to\nenhance the application of self-supervised learning in the field of gene\nexpression data analysis. This study is the first work that deals with bulk\nRNA-Seq data and self-supervised learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13912v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基因表达数据上的自监督学习", "tldr": "本研究探讨了将最先进的自监督学习方法应用于批量基因表达数据进行表型预测，并证明其优于传统监督模型，同时减少了对标注数据的依赖。", "motivation": "从基因表达数据中预测表型是生物医学研究中的一项关键任务。然而，传统的机器学习和深度学习方法依赖于监督学习，需要大量成本高昂且耗时获取的标注数据。", "method": "本研究调查了将最先进的自监督学习方法应用于批量基因表达数据进行表型预测。选择了三种基于不同方法的自监督学习方法，以评估它们利用数据固有结构并生成可用于下游预测任务的定性表示的能力。使用了几个公开可用的基因表达数据集。", "result": "自监督学习方法能够有效捕获复杂信息并提高表型预测准确性。结果表明，自监督学习方法可以优于传统监督模型，并且通过减少对标注数据的依赖提供了显著优势。提供了每种方法的性能综合分析，并突出了它们的优点和局限性。", "conclusion": "自监督学习在基因表达数据分析领域具有巨大潜力，能够克服传统监督学习对大量标注数据的依赖，并提高表型预测的准确性。本研究是首次将批量RNA-Seq数据与自监督学习相结合的工作。", "translation": "从基因表达数据中预测表型是生物医学研究中的一项关键任务，能够深入了解疾病机制、药物反应和个性化医疗。传统的机器学习和深度学习依赖于监督学习，这需要大量标注数据，而这些数据在基因表达数据的情况下获取成本高昂且耗时。自监督学习最近成为一种有前途的方法，通过直接从无标注数据的结构中提取信息来克服这些限制。在本研究中，我们调查了将最先进的自监督学习方法应用于批量基因表达数据进行表型预测。我们选择了三种基于不同方法的自监督学习方法，以评估它们利用数据固有结构并生成可用于下游预测任务的定性表示的能力。通过使用几个公开可用的基因表达数据集，我们证明了所选方法如何有效地捕获复杂信息并提高表型预测准确性。获得的结果表明，自监督学习方法可以优于传统监督模型，此外还通过减少对标注数据的依赖提供了显著优势。我们提供了每种方法性能的综合分析，突出了它们的优点和局限性。我们还根据研究案例提供了使用这些方法的建议。最后，我们概述了未来研究方向，以增强自监督学习在基因表达数据分析领域的应用。这项研究是首次处理批量RNA-Seq数据和自监督学习的工作。", "summary": "本研究探讨了自监督学习在基因表达数据表型预测中的应用，旨在克服传统监督学习对大量标注数据的依赖。通过在公开数据集上测试三种先进的自监督方法，研究证明了自监督学习能够有效提取数据内在结构信息，生成高质量的数据表示，并显著提高表型预测准确性，其性能优于传统监督模型。该研究还对不同方法的优缺点进行了分析，并为未来研究方向提供了展望，是首次将自监督学习应用于批量RNA-Seq数据的尝试。", "keywords": "自监督学习, 基因表达数据, 表型预测, 批量RNA-Seq, 机器学习", "comments": "这项研究的创新之处在于，它是首次将自监督学习应用于批量RNA-Seq基因表达数据进行表型预测。其重要性在于，它提供了一种有效的方法来克服传统监督学习在基因表达数据分析中对大量昂贵标注数据的依赖，从而为生物医学研究和个性化医疗开辟了新的可能性。"}}
{"id": "2507.14079", "title": "DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits", "authors": ["Garapati Keerthana", "Manik Gupta"], "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14079v1", "summary": "Progress notes are among the most clinically meaningful artifacts in an\nElectronic Health Record (EHR), offering temporally grounded insights into a\npatient's evolving condition, treatments, and care decisions. Despite their\nimportance, they are severely underrepresented in large-scale EHR datasets. For\ninstance, in the widely used Medical Information Mart for Intensive Care III\n(MIMIC-III) dataset, only about $8.56\\%$ of hospital visits include progress\nnotes, leaving gaps in longitudinal patient narratives. In contrast, the\ndataset contains a diverse array of other note types, each capturing different\naspects of care.\n  We present DENSE (Documenting Evolving Progress Notes from Scattered\nEvidence), a system designed to align with clinical documentation workflows by\nsimulating how physicians reference past encounters while drafting progress\nnotes. The system introduces a fine-grained note categorization and a temporal\nalignment mechanism that organizes heterogeneous notes across visits into\nstructured, chronological inputs. At its core, DENSE leverages a clinically\ninformed retrieval strategy to identify temporally and semantically relevant\ncontent from both current and prior visits. This retrieved evidence is used to\nprompt a large language model (LLM) to generate clinically coherent and\ntemporally aware progress notes.\n  We evaluate DENSE on a curated cohort of patients with multiple visits and\ncomplete progress note documentation. The generated notes demonstrate strong\nlongitudinal fidelity, achieving a temporal alignment ratio of $1.089$,\nsurpassing the continuity observed in original notes. By restoring narrative\ncoherence across fragmented documentation, our system supports improved\ndownstream tasks such as summarization, predictive modeling, and clinical\ndecision support, offering a scalable solution for LLM-driven note synthesis in\nreal-world healthcare settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14079v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DENSE：跨医院就诊的异构临床笔记时间建模的纵向病程记录生成", "tldr": "DENSE系统通过模拟医生工作流，利用时间建模和信息检索，从异构临床笔记中生成纵向连贯的病程记录，解决了EHR中病程记录稀缺的问题。", "motivation": "病程记录在电子健康记录（EHR）中至关重要，但大规模EHR数据集中（如MIMIC-III）严重不足，导致纵向患者叙述存在空白，尽管数据集中存在多种其他类型的护理笔记。", "method": "DENSE系统（Documenting Evolving Progress Notes from Scattered Evidence）模拟医生起草病程记录时参考过往就诊的流程。它引入了细粒度笔记分类和时间对齐机制，将跨就诊的异构笔记组织成结构化、按时间顺序排列的输入。核心是利用临床知情的检索策略，从当前和既往就诊中识别时间上和语义上相关的证据，然后用这些证据提示大型语言模型（LLM）生成临床连贯且时间感知的病程记录。", "result": "在包含多次就诊和完整病程记录的患者队列上进行评估，DENSE生成的笔记表现出强大的纵向保真度，时间对齐比率为1.089，超越了原始笔记中观察到的连续性。", "conclusion": "通过恢复碎片化文档中的叙述连贯性，DENSE系统支持改进下游任务，如摘要、预测建模和临床决策支持，为真实世界医疗环境中LLM驱动的笔记合成提供了可扩展的解决方案。", "translation": "病程记录是电子健康记录（EHR）中最具临床意义的工件之一，提供关于患者不断变化的病情、治疗和护理决策的时间性见解。尽管它们很重要，但在大规模EHR数据集中却严重不足。例如，在广泛使用的医疗信息市场重症监护III（MIMIC-III）数据集中，只有大约8.56%的医院就诊包含病程记录，这在纵向患者叙述中留下了空白。相比之下，该数据集包含各种其他类型的笔记，每种笔记都捕捉了护理的不同方面。\n我们提出了DENSE（从分散证据中记录演进的病程记录），一个旨在与临床文档工作流程对齐的系统，通过模拟医生在起草病程记录时如何参考过去的就诊。该系统引入了细粒度笔记分类和时间对齐机制，将跨就诊的异构笔记组织成结构化、按时间顺序排列的输入。DENSE的核心是利用临床知情的检索策略，从当前和既往就诊中识别时间上和语义上相关的证据。这些检索到的证据被用于提示大型语言模型（LLM）生成临床连贯且时间感知的病程记录。\n我们在一个经过筛选的、包含多次就诊和完整病程记录的患者队列上评估了DENSE。生成的笔记表现出强大的纵向保真度，时间对齐比率为1.089，超过了原始笔记中观察到的连续性。通过恢复碎片化文档中的叙述连贯性，我们的系统支持改进下游任务，如摘要、预测建模和临床决策支持，为真实世界医疗环境中LLM驱动的笔记合成提供了可扩展的解决方案。", "summary": "本文介绍了DENSE系统，旨在解决大规模电子健康记录数据集中病程记录不足的问题。DENSE通过模拟医生工作流程，整合跨就诊的异构临床笔记，并利用临床知情的检索策略和大型语言模型生成纵向连贯且时间感知的病程记录。实验结果表明，DENSE生成的笔记具有更高的纵向保真度，有助于提升下游任务如摘要和预测建模的性能，为医疗领域提供可扩展的LLM驱动笔记合成方案。", "keywords": "病程记录生成, 时间建模, 异构临床笔记, 大型语言模型, 电子健康记录", "comments": "DENSE的创新点在于其模拟医生工作流的设计，以及结合了细粒度笔记分类、时间对齐机制和临床知情检索策略来有效利用异构历史数据，从而克服了病程记录数据稀疏性的挑战。其重要性在于，通过生成高质量的纵向病程记录，它能够弥补现有EHR数据的不足，显著改善后续的临床信息提取、决策支持和预测任务的准确性与效率，为LLM在医疗领域的实际应用提供了有价值的解决方案。"}}
{"id": "2412.20383", "title": "Progressively Exploring and Exploiting Cost-Free Data to Break Fine-Grained Classification Barriers", "authors": ["Li-Jun Zhao", "Zhen-Duo Chen", "Zhi-Yuan Xue", "Xin Luo", "Xin-Shun Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.20383v2", "summary": "Current fine-grained classification research primarily focuses on\nfine-grained feature learning. However, in real-world scenarios, fine-grained\ndata annotation is challenging, and the features and semantics are highly\ndiverse and frequently changing. These issues create inherent barriers between\ntraditional experimental settings and real-world applications, limiting the\neffectiveness of conventional fine-grained classification methods. Although\nsome recent studies have provided potential solutions to these issues, most of\nthem still rely on limited supervised information and thus fail to offer\neffective solutions. In this paper, based on theoretical analysis, we propose a\nnovel learning paradigm to break the barriers in fine-grained classification.\nThis paradigm enables the model to progressively learn during inference,\nthereby leveraging cost-free data to more accurately represent fine-grained\ncategories and adapt to dynamic semantic changes. On this basis, an efficient\nEXPloring and EXPloiting strategy and method (EXP2) is designed. Thereinto,\nuseful inference data samples are explored according to class representations\nand exploited to optimize classifiers. Experimental results demonstrate the\ngeneral effectiveness of our method, providing guidance for future in-depth\nunderstanding and exploration of real-world fine-grained classification.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.20383v2", "cate": "cs.CV", "date": "2024-12-29", "updated": "2025-07-18", "AI": {"title_translation": "逐步探索和利用无成本数据以打破细粒度分类障碍", "tldr": "本文提出一种新的学习范式和EXP2方法，通过在推理过程中利用无成本数据进行渐进式学习，以解决细粒度分类中数据标注困难和语义动态变化的问题。", "motivation": "细粒度分类在现实世界中面临数据标注困难、特征和语义多样且频繁变化的问题，这导致传统方法在实验设置和实际应用之间存在障碍。现有的解决方案依赖有限的监督信息，效果不佳。", "method": "基于理论分析，提出一种新的学习范式，使模型能够在推理过程中渐进式学习，利用无成本数据更准确地表示细粒度类别并适应动态语义变化。在此基础上，设计了高效的探索和利用策略和方法（EXP2），根据类别表示探索有用的推理数据样本，并利用它们来优化分类器。", "result": "实验结果证明了所提方法的普遍有效性。", "conclusion": "该方法为未来深入理解和探索现实世界的细粒度分类提供了指导。", "translation": "当前细粒度分类研究主要集中在细粒度特征学习。然而，在现实世界场景中，细粒度数据标注具有挑战性，且特征和语义高度多样并频繁变化。这些问题在传统实验设置和现实世界应用之间造成了固有的障碍，限制了传统细粒度分类方法的有效性。尽管最近的一些研究为此类问题提供了潜在解决方案，但它们大多仍依赖有限的监督信息，因此未能提供有效的解决方案。在本文中，基于理论分析，我们提出了一种新颖的学习范式来打破细粒度分类中的障碍。该范式使模型能够在推理过程中逐步学习，从而利用无成本数据更准确地表示细粒度类别并适应动态语义变化。在此基础上，设计了一种高效的探索和利用策略和方法（EXP2）。其中，根据类别表示探索有用的推理数据样本，并利用它们来优化分类器。实验结果证明了我们方法的普遍有效性，为未来深入理解和探索现实世界的细粒度分类提供了指导。", "summary": "本文针对细粒度分类在现实世界中面临的数据标注困难和语义动态变化等挑战，提出了一种新的学习范式。该范式允许模型在推理阶段利用无成本数据进行渐进式学习，以更准确地表示细粒度类别并适应动态变化。具体而言，文章设计了EXP2策略，通过探索和利用推理数据样本来优化分类器。实验结果验证了该方法的有效性，为实际应用中的细粒度分类提供了新思路。", "keywords": "细粒度分类, 无成本数据, 渐进式学习, 推理, EXP2", "comments": "本文的创新点在于提出了一个在推理阶段利用“无成本数据”进行渐进式学习的新范式，旨在弥合传统细粒度分类方法与现实世界应用之间的差距。通过设计EXP2策略，该方法有效地利用了推理数据来优化分类器，这对于解决数据标注成本高昂和语义动态变化的实际问题具有重要意义。"}}
{"id": "2507.13676", "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC", "authors": ["Cheng Jiang", "Yihe Yan", "Yanxiang Wang", "Jiawei Hu", "Chun Tung Chou", "Wen Hu"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13676v1", "summary": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to\nprovide Integrated Sensing and Communication (ISAC) services. The performance\nof both communication and sensing fundamentally depends on the availability of\naccurate and up-to-date channel state information (CSI). In modern 5G networks,\nuplink CSI is derived from two reference signals: the demodulation reference\nsignal (DMRS) and the sounding reference signal (SRS). However, current base\nstation implementations treat these CSI measurements as separate information\nstreams. The key innovation of CARTS is to fuse these two CSI streams, thereby\nincreasing the frequency of CSI updates and extending sensing opportunities to\nmore users. CARTS addresses two key challenges: (i) a novel channel stitching\nand compensation method that integrates asynchronous CSI estimates from DMRS\nand SRS, despite their different time and frequency allocations, and (ii) a\nreal-time SRS triggering algorithm that complements the inherently\nuncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing\nopportunities for all users. Our trace-driven evaluation shows that CARTS\nsignificantly improves scalability, achieving a channel estimation error (NMSE)\nof 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of\nusers as a periodic SRS-only baseline with similar performance. By\nopportunistically combining DMRS and SRS, CARTS therefore provides a practical,\nstandard-compliant solution to improve CSI availability for ISAC without\nrequiring additional radio resources.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13676v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CARTS：5G ISAC的协作自适应资源触发与拼接", "tldr": "CARTS是一种5G上行感知方案，通过融合DMRS和SRS的CSI流来提高信道状态信息可用性，从而显著提升ISAC性能和用户支持数量。", "motivation": "当前5G网络中，DMRS和SRS的CSI测量被视为独立信息流，导致CSI更新频率不足且感知机会有限。论文旨在通过融合这两种CSI流来提高CSI可用性，以支持更多的用户并改善ISAC服务性能。", "method": "CARTS提出了一种新颖的信道拼接和补偿方法，用于整合DMRS和SRS的异步CSI估计，并开发了一种实时SRS触发算法，以补充DMRS调度，确保足够的非冗余感知机会。", "result": "CARTS显著提高了可扩展性，信道估计误差（NMSE）为0.167，UE跟踪精度为85厘米，同时在相似性能下支持的用户数量是仅使用周期性SRS基线的两倍。", "conclusion": "CARTS通过机会性地结合DMRS和SRS，提供了一种实用且符合标准的解决方案，无需额外无线资源即可提高ISAC的CSI可用性。", "translation": "本文提出了CARTS，一种自适应的5G上行感知方案，旨在提供集成感知与通信（ISAC）服务。通信和感知的性能根本上取决于准确和最新的信道状态信息（CSI）的可用性。在现代5G网络中，上行CSI来源于两种参考信号：解调参考信号（DMRS）和探测参考信号（SRS）。然而，当前的基站实现将这些CSI测量视为独立的信息流。CARTS的关键创新在于融合这两种CSI流，从而增加CSI更新的频率并扩展感知机会到更多用户。CARTS解决了两个关键挑战：(i) 一种新颖的信道拼接和补偿方法，用于整合来自DMRS和SRS的异步CSI估计，尽管它们的时间和频率分配不同，以及 (ii) 一种实时SRS触发算法，补充了固有的不可控DMRS调度，确保为所有用户提供足够且非冗余的感知机会。我们的跟踪驱动评估显示，CARTS显著提高了可扩展性，实现了0.167的信道估计误差（NMSE）和85厘米的UE跟踪精度，同时支持的用户数量是仅使用周期性SRS基线且性能相似情况下的两倍。因此，CARTS通过机会性地结合DMRS和SRS，提供了一种实用、符合标准的解决方案，无需额外无线资源即可提高ISAC的CSI可用性。", "summary": "CARTS是一种针对5G ISAC服务的自适应上行感知方案。它通过融合DMRS和SRS两种CSI流来提高信道状态信息（CSI）的可用性，解决了当前系统CSI流独立处理的不足。该方案创新性地提出了异步CSI估计的信道拼接与补偿方法，并设计了实时SRS触发算法。实验结果表明，CARTS显著提升了系统可扩展性，降低了信道估计误差，提高了UE跟踪精度，并能在不增加额外无线资源的情况下支持更多用户，为ISAC提供了实用且符合标准的CSI增强方案。", "keywords": "5G ISAC, 信道状态信息, DMRS, SRS, 资源触发", "comments": "CARTS的创新点在于其融合DMRS和SRS的CSI流，并提出了相应的信道拼接和实时触发算法，有效克服了传统方法中CSI获取的局限性。其重要性在于在不占用额外无线资源的前提下显著提升了5G ISAC的性能和用户支持能力，为未来5G及更高代移动通信中的感知功能提供了可行的解决方案。"}}
{"id": "2507.13595", "title": "NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision", "authors": ["Tengkai Wang", "Weihao Li", "Ruikai Cui", "Shi Qiu", "Nick Barnes"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 4 figures", "url": "http://arxiv.org/abs/2507.13595v1", "summary": "Reconstructing accurate implicit surface representations from point clouds\nremains a challenging task, particularly when data is captured using\nlow-quality scanning devices. These point clouds often contain substantial\nnoise, leading to inaccurate surface reconstructions. Inspired by the\nNoise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel\nmethod designed to extend this concept to 3D neural fields. Our approach\nenables learning clean neural SDFs directly from noisy point clouds through\nnoisy supervision by minimizing the MSE loss between noisy SDF representations,\nallowing the network to implicitly denoise and refine surface estimations. We\nevaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the\nShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that\nour framework significantly improves surface reconstruction quality from noisy\ninputs.", "comment": "14 pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13595v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "NoiseSDF2NoiseSDF: 从噪声监督中学习干净的神经场", "tldr": "NoiseSDF2NoiseSDF提出了一种新方法，通过在噪声SDF表示之间最小化MSE损失，直接从噪声点云中学习干净的3D神经SDF，从而显著提高表面重建质量。", "motivation": "从点云重建精确的隐式表面表示仍然是一项挑战，尤其是在使用低质量扫描设备捕获数据时，这些点云通常包含大量噪声，导致表面重建不准确。", "method": "受2D图像Noise2Noise范式的启发，本文引入了NoiseSDF2NoiseSDF，这是一种将该概念扩展到3D神经场的新方法。该方法通过最小化噪声SDF表示之间的MSE损失，通过噪声监督直接从噪声点云中学习干净的神经SDF，从而使网络能够隐式地去噪和细化表面估计。", "result": "在ShapeNet、ABC、Famous和Real等基准数据集上进行了评估，实验结果表明该框架显著提高了从噪声输入中进行表面重建的质量。", "conclusion": "NoiseSDF2NoiseSDF通过其新颖的噪声监督方法，有效地解决了从噪声点云中重建干净神经SDF的挑战，显著提升了表面重建质量。", "translation": "从点云重建精确的隐式表面表示仍然是一项具有挑战性的任务，特别是在使用低质量扫描设备捕获数据时。这些点云通常包含大量噪声，导致表面重建不准确。受2D图像Noise2Noise范式的启发，我们引入了NoiseSDF2NoiseSDF，这是一种旨在将此概念扩展到3D神经场的新方法。我们的方法通过最小化噪声SDF表示之间的均方误差（MSE）损失，通过噪声监督直接从噪声点云中学习干净的神经SDF，从而使网络能够隐式地去噪和细化表面估计。我们在ShapeNet、ABC、Famous和Real数据集等基准上评估了NoiseSDF2NoiseSDF的有效性。实验结果表明，我们的框架显著提高了从噪声输入中进行表面重建的质量。", "summary": "NoiseSDF2NoiseSDF是一种受Noise2Noise启发的3D神经场方法，旨在解决从噪声点云重建准确隐式表面表示的挑战。它通过最小化噪声SDF表示之间的MSE损失，实现从噪声监督中学习干净的神经SDF，从而隐式地对表面估计进行去噪和细化。该方法在多个基准数据集上表现出显著的表面重建质量提升。", "keywords": "神经场, 噪声去噪, 隐式表面重建, 点云, SDF", "comments": "该论文的创新之处在于将Noise2Noise范式扩展到3D神经场，解决了从噪声点云中学习干净隐式表面表示的难题。其通过噪声监督直接学习的方法，避免了对干净数据或显式噪声模型的依赖，具有重要意义。"}}
{"id": "2507.13710", "title": "CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13710v1", "summary": "Data preparation is a foundational yet notoriously challenging component of\nthe machine learning lifecycle, characterized by a vast combinatorial search\nspace of potential operator sequences. While reinforcement learning (RL) offers\na promising direction, existing approaches are inefficient as they fail to\ncapture the structured, hierarchical nature of the problem. We argue that\nHierarchical Reinforcement Learning (HRL), a paradigm that has been successful\nin other domains, provides a conceptually ideal yet previously unexplored\nframework for this task. However, a naive HRL implementation with a `hard\nhierarchy' is prone to suboptimal, irreversible decisions. To address this, we\nintroduce CogniQ-H, the first framework to implement a soft hierarchical\nparadigm for robust, end-to-end automated data preparation. CogniQ-H formulates\naction selection as a Bayesian inference problem. A high-level strategic prior,\ngenerated by a Large Language Model (LLM), guides exploration\nprobabilistically. This prior is synergistically combined with a fine-grained\noperator quality score from a supervised Learning-to-Rank (LTR) model and a\nlong-term value estimate from the agent's own Q-function. This hybrid\narchitecture allows CogniQ-H to balance strategic guidance with adaptive,\nevidence-based decision-making. Through extensive experiments on 18 diverse\ndatasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to\n13.9\\% improvement in pipeline quality and 2.8$\\times$ faster convergence\ncompared to state-of-the-art RL-based methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13710v1", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CogniQ-H：一种用于自动化数据准备的软分层强化学习范式", "tldr": "CogniQ-H引入了一种软分层强化学习方法，通过结合LLM、LTR和Q-function，显著提高了自动化数据准备的效率和质量，解决了现有RL方法效率低下的问题。", "motivation": "数据准备是机器学习生命周期中一个基础但极具挑战性的部分，其特点是存在巨大的操作序列组合搜索空间。现有强化学习（RL）方法由于未能捕捉问题的结构化、分层性质，导致效率低下。作者认为分层强化学习（HRL）是理想的框架，但简单的“硬分层”实现容易导致次优和不可逆的决策。", "method": "本文引入了CogniQ-H，这是第一个实现软分层范式以实现鲁棒、端到端自动化数据准备的框架。CogniQ-H将动作选择公式化为贝叶斯推理问题。一个由大型语言模型（LLM）生成的高级战略先验概率性地指导探索。这个先验与来自监督学习排序（LTR）模型的细粒度操作符质量得分以及来自智能体自身Q函数长期价值估计协同结合。这种混合架构使CogniQ-H能够在战略指导与自适应、基于证据的决策之间取得平衡。", "result": "通过在跨多个领域的18个不同数据集上进行广泛实验，CogniQ-H与最先进的基于RL的方法相比，管道质量提高了高达13.9%，收敛速度加快了2.8倍。", "conclusion": "CogniQ-H通过引入软分层强化学习范式，并结合LLM、LTR和Q函数，成功解决了自动化数据准备中现有RL方法的效率和决策次优问题，显著提升了数据管道的质量和收敛速度。", "translation": "数据准备是机器学习生命周期中一个基础但臭名昭著的挑战性组成部分，其特点是潜在操作序列的组合搜索空间巨大。虽然强化学习（RL）提供了一个有前途的方向，但现有方法效率低下，因为它们未能捕捉到问题的结构化、分层性质。我们认为分层强化学习（HRL），一个在其他领域取得成功的范式，为这项任务提供了一个概念上理想但以前未被探索的框架。然而，使用“硬分层”的简单HRL实现容易导致次优、不可逆的决策。为了解决这个问题，我们引入了CogniQ-H，这是第一个实现软分层范式以实现鲁棒、端到端自动化数据准备的框架。CogniQ-H将动作选择公式化为贝叶斯推理问题。一个由大型语言模型（LLM）生成的高级战略先验，概率性地指导探索。这个先验与来自监督学习排序（LTR）模型的细粒度操作符质量得分以及来自智能体自身Q函数的长期价值估计协同结合。这种混合架构允许CogniQ-H在战略指导与自适应、基于证据的决策之间取得平衡。通过在跨多个领域的18个不同数据集上进行广泛实验，我们证明了CogniQ-H与最先进的基于RL的方法相比，管道质量提高了高达13.9%，收敛速度加快了2.8倍。", "summary": "本论文提出CogniQ-H，一种创新的软分层强化学习范式，旨在解决自动化数据准备中现有RL方法效率低下和决策次优的问题。CogniQ-H将动作选择建模为贝叶斯推理，并整合了LLM生成的高级战略先验、LTR模型的细粒度操作质量得分以及Q函数的长期价值估计。这种混合架构实现了战略指导与自适应决策的平衡。实验结果表明，CogniQ-H在18个数据集上显著提升了数据管道质量和收敛速度，优于现有最先进的RL方法。", "keywords": "自动化数据准备, 强化学习, 分层强化学习, 贝叶斯推理, 大型语言模型", "comments": "该论文的创新点在于首次将“软分层”强化学习范式应用于自动化数据准备领域，并通过结合LLM、LTR和Q-function，构建了一个新颖的混合架构，有效平衡了宏观战略指导和微观自适应决策。这解决了传统HRL中“硬分层”可能导致的次优问题，为复杂组合优化问题的解决提供了新的思路。其在性能上的显著提升也证明了该方法的有效性。"}}
{"id": "2303.18162", "title": "ViMMRC 2.0 -- Enhancing Machine Reading Comprehension on Vietnamese Literature Text", "authors": ["Son T. Luu", "Khoi Trong Hoang", "Tuong Quang Pham", "Kiet Van Nguyen", "Ngan Luu-Thuy Nguyen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted for publication at International Journal of Asian Language Processing", "url": "http://arxiv.org/abs/2303.18162v3", "summary": "Machine reading comprehension has been an interesting and challenging task in\nrecent years, with the purpose of extracting useful information from texts. To\nattain the computer ability to understand the reading text and answer relevant\ninformation, we introduce ViMMRC 2.0 - an extension of the previous ViMMRC for\nthe task of multiple-choice reading comprehension in Vietnamese Textbooks which\ncontain the reading articles for students from Grade 1 to Grade 12. This\ndataset has 699 reading passages which are prose and poems, and 5,273\nquestions. The questions in the new dataset are not fixed with four options as\nin the previous version. Moreover, the difficulty of questions is increased,\nwhich challenges the models to find the correct choice. The computer must\nunderstand the whole context of the reading passage, the question, and the\ncontent of each choice to extract the right answers. Hence, we propose a\nmulti-stage approach that combines the multi-step attention network (MAN) with\nthe natural language inference (NLI) task to enhance the performance of the\nreading comprehension model. Then, we compare the proposed methodology with the\nbaseline BERTology models on the new dataset and the ViMMRC 1.0. From the\nresults of the error analysis, we found that the challenge of the reading\ncomprehension models is understanding the implicit context in texts and linking\nthem together in order to find the correct answers. Finally, we hope our new\ndataset will motivate further research to enhance the ability of computers to\nunderstand the Vietnamese language.", "comment": "Accepted for publication at International Journal of Asian Language\n  Processing", "pdf_url": "http://arxiv.org/pdf/2303.18162v3", "cate": "cs.CL", "date": "2023-03-31", "updated": "2025-07-18", "AI": {"title_translation": "ViMMRC 2.0——增强越南文学文本的机器阅读理解能力", "tldr": "论文介绍了ViMMRC 2.0数据集和一种结合MAN与NLI的多阶段方法，以提升越南语文学文本的机器阅读理解能力。", "motivation": "机器阅读理解是一项有趣且具有挑战性的任务，旨在从文本中提取有用信息。为了让计算机能够理解阅读文本并回答相关信息，需要提升其能力。现有的数据集可能不足以挑战模型理解复杂的越南语文学文本，尤其是需要理解隐含上下文的情况。", "method": "论文引入了ViMMRC 2.0数据集，它是ViMMRC的扩展，用于越南语教科书中的多项选择阅读理解任务，包含699篇阅读文章和5273个问题，问题的选项数量不固定且难度增加。同时，提出了一种结合多步注意力网络（MAN）和自然语言推理（NLI）任务的多阶段方法，以提升阅读理解模型的性能。该方法与基线BERTology模型在新数据集和ViMMRC 1.0上进行了比较。", "result": "错误分析结果表明，阅读理解模型的挑战在于理解文本中的隐含上下文并将其关联起来以找到正确答案。论文通过引入更具挑战性的数据集和提出的多阶段方法来应对这一挑战，但没有直接给出模型性能提升的具体数值。", "conclusion": "论文希望新的数据集能够激励进一步的研究，以增强计算机理解越南语的能力。", "translation": "机器阅读理解近年来一直是一个有趣且具有挑战性的任务，其目的是从文本中提取有用信息。为了使计算机能够理解阅读文本并回答相关信息，我们引入了ViMMRC 2.0——这是之前ViMMRC的扩展，用于越南语教科书中的多项选择阅读理解任务，这些教科书包含小学一年级到高中三年级学生的阅读文章。该数据集包含699篇散文和诗歌阅读段落以及5273个问题。新数据集中的问题不像以前的版本那样固定为四个选项。此外，问题的难度有所增加，这挑战了模型找到正确选项。计算机必须理解阅读段落的整个上下文、问题以及每个选项的内容才能提取出正确答案。因此，我们提出了一种结合多步注意力网络（MAN）和自然语言推理（NLI）任务的多阶段方法，以增强阅读理解模型的性能。然后，我们将所提出的方法与基线BERTology模型在新数据集和ViMMRC 1.0上进行了比较。从错误分析的结果来看，我们发现阅读理解模型的挑战在于理解文本中的隐含上下文并将其关联起来以找到正确答案。最后，我们希望我们的新数据集能够激励进一步的研究，以增强计算机理解越南语的能力。", "summary": "本论文介绍了ViMMRC 2.0，一个用于越南语文学文本机器阅读理解的新数据集，该数据集包含来自越南语教科书的699篇阅读文章和5273个多项选择题，其问题难度和选项设置较前一版本ViMMRC有所增加和灵活。为应对挑战，论文提出了一种结合多步注意力网络（MAN）和自然语言推理（NLI）任务的多阶段方法来提升模型性能。研究发现，理解文本中的隐含上下文是当前阅读理解模型的主要挑战。ViMMRC 2.0数据集旨在推动越南语机器阅读理解的进一步研究。", "keywords": "机器阅读理解, 越南语文学文本, ViMMRC 2.0, 多阶段方法, 自然语言推理", "comments": "该论文的创新点在于构建了一个更具挑战性的越南语机器阅读理解数据集ViMMRC 2.0，其问题难度增加且选项数量不固定，更贴近真实世界的理解需求。同时，提出了结合MAN和NLI的多阶段方法来提升模型对复杂文本的理解能力。论文通过错误分析明确指出了当前模型在理解隐含上下文方面的局限性，为未来的研究指明了方向。ViMMRC 2.0数据集的发布有望促进越南语自然语言处理领域的发展。"}}
{"id": "2507.13613", "title": "Conformal Contraction for Robust Nonlinear Control with Distribution-Free Uncertainty Quantification", "authors": ["Sihang Wei", "Melkior Ornik", "Hiroyasu Tsukamoto"], "categories": ["math.OC", "cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      IEEE CDC 2025 submission (accepted)", "url": "http://arxiv.org/abs/2507.13613v1", "summary": "We present a novel robust control framework for continuous-time, perturbed\nnonlinear dynamical systems with uncertainty that depends nonlinearly on both\nthe state and control inputs. Unlike conventional approaches that impose\nstructural assumptions on the uncertainty, our framework enhances\ncontraction-based robust control with data-driven uncertainty prediction,\nremaining agnostic to the models of the uncertainty and predictor. We\nstatistically quantify how reliably the contraction conditions are satisfied\nunder dynamics with uncertainty via conformal prediction, thereby obtaining a\ndistribution-free and finite-time probabilistic guarantee for exponential\nboundedness of the trajectory tracking error. We further propose the\nprobabilistically robust control invariant (PRCI) tube for distributionally\nrobust motion planning, within which the perturbed system trajectories are\nguaranteed to stay with a finite probability, without explicit knowledge of the\nuncertainty model. Numerical simulations validate the effectiveness of the\nproposed robust control framework and the performance of the PRCI tube.", "comment": "IEEE CDC 2025 submission (accepted)", "pdf_url": "http://arxiv.org/pdf/2507.13613v1", "cate": "math.OC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "具有无分布不确定性量化的鲁棒非线性控制的共形收缩", "tldr": "本文提出了一种新颖的鲁棒控制框架，结合共形预测和收缩理论，用于处理具有非线性、未知不确定性的连续时间非线性系统，并提供轨迹跟踪误差的无分布、有限时间概率保证。", "motivation": "传统的鲁棒控制方法对不确定性施加结构假设，而本文提出的框架无需明确的不确定性模型和预测器模型，能够处理状态和控制输入非线性依赖的不确定性。", "method": "该方法通过数据驱动的不确定性预测增强了基于收缩的鲁棒控制。利用共形预测统计量化了在不确定性动力学下收缩条件得到满足的可靠性，以获得轨迹跟踪误差指数有界的概率保证。此外，提出了概率鲁棒控制不变（PRCI）管用于分布鲁棒的运动规划。", "result": "获得了轨迹跟踪误差指数有界的无分布和有限时间概率保证。在PRCI管内，受扰动系统轨迹在有限概率下保证停留。数值模拟验证了所提出的鲁棒控制框架的有效性和PRCI管的性能。", "conclusion": "本文提出的共形收缩框架为具有复杂、未知不确定性的非线性系统提供了一种新颖且有效的鲁棒控制方法，无需不确定性模型，并提供强有力的概率保证，具有重要的实际应用价值。", "translation": "我们提出了一种新颖的鲁棒控制框架，用于连续时间、受扰动的非线性动力系统，其不确定性非线性地依赖于状态和控制输入。与对不确定性施加结构假设的传统方法不同，我们的框架通过数据驱动的不确定性预测增强了基于收缩的鲁棒控制，对不确定性和预测器的模型保持不可知。我们通过共形预测统计量化了在不确定性动力学下收缩条件得到满足的可靠性，从而获得了轨迹跟踪误差指数有界的无分布和有限时间概率保证。我们进一步提出了概率鲁棒控制不变（PRCI）管，用于分布鲁棒的运动规划，在此管内，受扰动系统轨迹在有限概率下保证停留，而无需明确了解不确定性模型。数值模拟验证了所提出的鲁棒控制框架的有效性和PRCI管的性能。", "summary": "本文提出了一种针对连续时间非线性系统的鲁棒控制框架，该系统具有非线性依赖于状态和控制输入的不确定性。与传统方法不同，该框架通过结合数据驱动的不确定性预测和共形预测来增强基于收缩的控制，从而在不依赖不确定性模型的情况下，为轨迹跟踪误差的指数有界性提供无分布、有限时间的概率保证。此外，论文还引入了概率鲁棒控制不变（PRCI）管，用于分布鲁棒的运动规划，确保受扰动系统轨迹在有限概率下保持在指定范围内。数值模拟验证了该框架的有效性。", "keywords": "鲁棒控制, 共形预测, 非线性系统, 不确定性量化, 收缩理论", "comments": "该论文的创新之处在于将收缩理论与数据驱动的共形预测相结合，以处理复杂且未知的系统不确定性，而无需对不确定性模型进行假设。这为鲁棒控制提供了强有力的概率保证，对于不确定性模型难以获取或不准确的实际应用具有重要意义。提出的PRCI管进一步增强了其在运动规划中的实用性。"}}
{"id": "2409.00839", "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving", "authors": ["Haobo Yang", "Shiyan Zhang", "Zhuoyi Yang", "Xinyu Zhang", "Jilong Guo", "Zongyou Yang", "Jun Li"], "categories": ["cs.CV", "cs.AI", "cs.IT", "math.IT"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2409.00839v2", "summary": "With the increasing complexity of the traffic environment, the significance\nof safety perception in intelligent driving is intensifying. Traditional\nmethods in the field of intelligent driving perception rely on deep learning,\nwhich suffers from limited interpretability, often described as a \"black box.\"\nThis paper introduces a novel type of loss function, termed \"Entropy Loss,\"\nalong with an innovative training strategy. Entropy Loss is formulated based on\nthe functionality of feature compression networks within the perception model.\nDrawing inspiration from communication systems, the information transmission\nprocess in a feature compression network is expected to demonstrate steady\nchanges in information volume and a continuous decrease in information entropy.\nBy modeling network layer outputs as continuous random variables, we construct\na probabilistic model that quantifies changes in information volume. Entropy\nLoss is then derived based on these expectations, guiding the update of network\nparameters to enhance network interpretability. Our experiments indicate that\nthe Entropy Loss training strategy accelerates the training process. Utilizing\nthe same 60 training epochs, the accuracy of 3D object detection models using\nEntropy Loss on the KITTI test set improved by up to 4.47\\% compared to models\nwithout Entropy Loss, underscoring the method's efficacy. The implementation\ncode is available at https://github.com/yhbcode000/Eloss-Interpretability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2409.00839v2", "cate": "cs.CV", "date": "2024-09-01", "updated": "2025-07-18", "AI": {"title_translation": "熵损失：智能驾驶三维目标检测网络的可解释性放大器", "tldr": "本文提出一种名为“熵损失”的新型损失函数和训练策略，旨在提高智能驾驶中三维目标检测网络的解释性，并能加速训练过程和提升检测精度。", "motivation": "智能驾驶中的感知系统依赖深度学习，但其可解释性有限，存在“黑箱”问题，这在日益复杂的交通环境中，对安全感知的重要性日益增加。", "method": "本文提出一种基于特征压缩网络功能的新型损失函数“熵损失”和创新的训练策略。该方法借鉴通信系统，期望特征压缩网络中的信息传输过程表现出信息量的稳定变化和信息熵的持续降低。通过将网络层输出建模为连续随机变量，构建概率模型量化信息量变化，并基于此推导出熵损失，以指导网络参数更新，增强网络可解释性。", "result": "熵损失训练策略加速了训练过程。在相同的60个训练周期下，使用熵损失的三维目标检测模型在KITTI测试集上的精度比未使用该损失的模型提高了高达4.47%。", "conclusion": "熵损失显著提升了智能驾驶中三维目标检测网络的可解释性，同时加速了训练并提高了检测精度，证明了该方法的有效性。", "translation": "随着交通环境日益复杂，智能驾驶中安全感知的重要性不断增强。智能驾驶感知领域的传统方法依赖深度学习，但其可解释性有限，常被描述为“黑箱”。本文引入一种新型损失函数，称为“熵损失”，并提出一种创新的训练策略。熵损失是基于感知模型中特征压缩网络的功能而制定的。受通信系统启发，特征压缩网络中的信息传输过程应表现出信息量的稳定变化和信息熵的持续降低。通过将网络层输出建模为连续随机变量，我们构建了一个量化信息量变化的概率模型。然后，基于这些期望推导出熵损失，以指导网络参数更新，从而增强网络的可解释性。我们的实验表明，熵损失训练策略加速了训练过程。在相同的60个训练周期下，使用熵损失的三维目标检测模型在KITTI测试集上的精度比未使用熵损失的模型提高了高达4.47%，这强调了该方法的有效性。实施代码可在https://github.com/yhbcode000/Eloss-Interpretability 获取。", "summary": "本文针对智能驾驶中深度学习感知模型可解释性差的问题，提出了一种名为“熵损失”的新型损失函数和训练策略。熵损失通过建模特征压缩网络中的信息传输过程，并期望信息熵持续降低，从而指导网络参数更新以增强可解释性。实验结果表明，该方法不仅加速了训练，还在KITTI数据集上显著提升了三维目标检测的精度。", "keywords": "熵损失, 可解释性, 3D目标检测, 智能驾驶, 深度学习", "comments": "这篇论文提出了一种新颖的损失函数“熵损失”，通过引入信息论的概念来解决深度学习模型在智能驾驶领域可解释性不足的“黑箱”问题，这是一个重要的创新点。同时，该方法不仅提升了模型的可解释性，还在实际性能上（加速训练和提高精度）取得了显著效果，具有较高的实用价值。"}}
{"id": "2507.13929", "title": "TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views", "authors": ["Hsiang-Hui Hung", "Huu-Phu Do", "Yung-Hui Li", "Ching-Chun Huang"], "categories": ["cs.CV", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by MM 2024", "url": "http://arxiv.org/abs/2507.13929v1", "summary": "We present TimeNeRF, a generalizable neural rendering approach for rendering\nnovel views at arbitrary viewpoints and at arbitrary times, even with few input\nviews. For real-world applications, it is expensive to collect multiple views\nand inefficient to re-optimize for unseen scenes. Moreover, as the digital\nrealm, particularly the metaverse, strives for increasingly immersive\nexperiences, the ability to model 3D environments that naturally transition\nbetween day and night becomes paramount. While current techniques based on\nNeural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing\nnovel views, the exploration of NeRF's potential for temporal 3D scene modeling\nremains limited, with no dedicated datasets available for this purpose. To this\nend, our approach harnesses the strengths of multi-view stereo, neural radiance\nfields, and disentanglement strategies across diverse datasets. This equips our\nmodel with the capability for generalizability in a few-shot setting, allows us\nto construct an implicit content radiance field for scene representation, and\nfurther enables the building of neural radiance fields at any arbitrary time.\nFinally, we synthesize novel views of that time via volume rendering.\nExperiments show that TimeNeRF can render novel views in a few-shot setting\nwithout per-scene optimization. Most notably, it excels in creating realistic\nnovel views that transition smoothly across different times, adeptly capturing\nintricate natural scene changes from dawn to dusk.", "comment": "Accepted by MM 2024", "pdf_url": "http://arxiv.org/pdf/2507.13929v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "TimeNeRF：从少样本输入视图构建跨时间可泛化的神经辐射场", "tldr": "TimeNeRF是一种可泛化的神经渲染方法，即使在少样本输入视图的情况下，也能在任意视点和任意时间渲染新颖视图，并能平滑地捕捉从黎明到黄昏的场景变化。", "motivation": "在实际应用中，收集多视图成本高昂，且针对未见场景重新优化效率低下。元宇宙等数字领域对沉浸式体验的需求日益增长，要求3D环境能自然地在昼夜间转换。当前基于NeRF的技术虽擅长合成新视图，但在时间3D场景建模方面的探索有限，且缺乏专用数据集。", "method": "TimeNeRF结合了多视图立体、神经辐射场和跨不同数据集的解耦策略。这使得模型在少样本设置下具有泛化能力，能够构建用于场景表示的隐式内容辐射场，并进一步实现在任意时间构建神经辐射场。最终，通过体渲染合成该时间的新颖视图。", "result": "实验表明，TimeNeRF可以在少样本设置下渲染新颖视图，无需进行逐场景优化。最值得注意的是，它在创建跨时间平滑过渡的逼真新颖视图方面表现出色，能巧妙地捕捉从黎明到黄昏的复杂自然场景变化。", "conclusion": "TimeNeRF成功地解决了在少样本输入下进行时间3D场景建模的挑战，展示了强大的泛化能力和逼真的时间过渡效果。", "translation": "我们提出了TimeNeRF，这是一种可泛化的神经渲染方法，即使在少样本输入视图的情况下，也能在任意视点和任意时间渲染新颖视图。对于实际应用来说，收集多视图成本高昂，且针对未见场景重新优化效率低下。此外，随着数字领域，特别是元宇宙，力求提供日益沉浸的体验，建模能在昼夜之间自然过渡的3D环境变得至关重要。尽管当前基于神经辐射场（NeRF）的技术在合成新颖视图方面表现出卓越的熟练度，但NeRF在时间3D场景建模方面的潜力探索仍然有限，并且没有专门的数据集可用于此目的。为此，我们的方法利用了多视图立体、神经辐射场以及跨不同数据集的解耦策略的优势。这使得我们的模型在少样本设置下具有泛化能力，允许我们构建用于场景表示的隐式内容辐射场，并进一步实现在任何任意时间构建神经辐射场。最后，我们通过体渲染合成该时间的新颖视图。实验表明，TimeNeRF可以在少样本设置下渲染新颖视图，无需进行逐场景优化。最值得注意的是，它在创建跨不同时间平滑过渡的逼真新颖视图方面表现出色，巧妙地捕捉了从黎明到黄昏的复杂自然场景变化。", "summary": "TimeNeRF是一种创新的神经渲染方法，旨在解决现有NeRF在时间3D场景建模和少样本泛化方面的局限性。它结合了多视图立体、神经辐射场和解耦策略，实现了在任意时间和视点下从少量输入视图渲染新颖视图的能力，无需逐场景优化。该方法尤其擅长捕捉和渲染自然场景随时间（如昼夜）的平滑过渡，为元宇宙等沉浸式应用提供了关键技术支持。", "keywords": "神经辐射场, 时间建模, 少样本学习, 泛化, 新颖视图合成", "comments": "这项研究的创新之处在于其将NeRF的泛化能力扩展到时间维度，并且能够在少样本设置下运行，这大大降低了数据采集和模型优化的成本。其捕捉复杂时间变化的平滑过渡能力是其重要贡献，对于构建动态、逼真的虚拟环境至关重要。它通过结合多种现有技术来达到新颖的泛化能力，显示了强大的工程集成能力。"}}
{"id": "2501.08208", "title": "ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems", "authors": ["Mohita Chowdhury", "Yajie Vera He", "Jared Joselowitz", "Aisling Higham", "Ernest Lim"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      29 pages", "url": "http://arxiv.org/abs/2501.08208v2", "summary": "Large Language Models (LLMs) have shown impressive potential in clinical\nquestion answering (QA), with Retrieval Augmented Generation (RAG) emerging as\na leading approach for ensuring the factual accuracy of model responses.\nHowever, current automated RAG metrics perform poorly in clinical and\nconversational use cases. Using clinical human evaluations of responses is\nexpensive, unscalable, and not conducive to the continuous iterative\ndevelopment of RAG systems. To address these challenges, we introduce ASTRID -\nan Automated and Scalable TRIaD for evaluating clinical QA systems leveraging\nRAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy\n(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is\ndesigned to better capture the faithfulness of a model's response to the\nknowledge base without penalising conversational elements. To validate our\ntriad, we curate a dataset of over 200 real-world patient questions posed to an\nLLM-based QA agent during surgical follow-up for cataract surgery - the highest\nvolume operation in the world - augmented with clinician-selected questions for\nemergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate\nthat CF can predict human ratings of faithfulness better than existing\ndefinitions for conversational use cases. Furthermore, we show that evaluation\nusing our triad consisting of CF, RA, and CR exhibits alignment with clinician\nassessment for inappropriate, harmful, or unhelpful responses. Finally, using\nnine different LLMs, we demonstrate that the three metrics can closely agree\nwith human evaluations, highlighting the potential of these metrics for use in\nLLM-driven automated evaluation pipelines. We also publish the prompts and\ndatasets for these experiments, providing valuable resources for further\nresearch and development.", "comment": "29 pages", "pdf_url": "http://arxiv.org/pdf/2501.08208v2", "cate": "cs.CL", "date": "2025-01-14", "updated": "2025-07-18", "AI": {"title_translation": "ASTRID——一种用于评估基于RAG的临床问答系统的自动化可扩展三联评估方法", "tldr": "ASTRID引入了一套自动化、可扩展的三联评估指标（CR、RA、CF），用于评估基于RAG的临床问答系统，解决了现有自动化指标在临床场景表现不佳且人工评估成本高昂的问题。该方法在实际临床数据上验证了其与人工评估的高度一致性，尤其是在对话忠实度方面表现优异。", "motivation": "现有自动化RAG评估指标在临床和对话用例中表现不佳，而人工评估临床响应成本高昂、难以扩展且不利于RAG系统的持续迭代开发。", "method": "本文提出了ASTRID，一种自动化且可扩展的用于评估利用RAG的临床问答系统的三联评估方法，包含三个指标：上下文相关性（CR）、拒绝准确性（RA）和对话忠实度（CF）。其中，CF是一个新颖的评估指标，旨在更好地捕捉模型响应对知识库的忠实度，同时不惩罚对话元素。为了验证该三联评估方法，作者整理了一个包含200多个真实世界患者问题的临床数据集，并使用九种不同的LLM进行了实验。", "result": "对话忠实度（CF）能够比现有定义更好地预测对话用例中人类对忠实度的评分。使用CF、RA和CR组成的三联评估方法，其评估结果与临床医生对不当、有害或无用响应的评估结果一致。此外，在九种不同的LLM上，这三个指标与人类评估结果高度一致。", "conclusion": "ASTRID提出的三项指标（CR、RA、CF）在临床问答系统的自动化评估中显示出巨大潜力，能够与人类评估结果高度契合，有望应用于LLM驱动的自动化评估流程。研究团队还发布了实验提示和数据集，为进一步研究和开发提供了宝贵资源。", "translation": "大型语言模型（LLMs）在临床问答（QA）中展现出令人印象深刻的潜力，其中检索增强生成（RAG）作为一种确保模型响应事实准确性的主要方法应运而生。然而，当前的自动化RAG指标在临床和对话用例中表现不佳。使用人工评估临床响应成本高昂、难以扩展，并且不利于RAG系统的持续迭代开发。为了解决这些挑战，我们引入了ASTRID——一种用于评估利用RAG的临床问答系统的自动化可扩展三联评估方法——它由三个指标组成：上下文相关性（CR）、拒绝准确性（RA）和对话忠实度（CF）。我们新颖的评估指标CF旨在更好地捕捉模型响应对知识库的忠实度，同时不惩罚对话元素。为了验证我们的三联评估方法，我们整理了一个包含200多个真实世界患者问题的临床数据集，这些问题是在白内障手术（世界上手术量最大的手术）的术后随访期间向基于LLM的QA代理提出的，并补充了临床医生选择的用于紧急、临床和非临床领域外场景的问题。我们证明，CF比现有定义能更好地预测对话用例中人类对忠实度的评分。此外，我们表明，使用由CF、RA和CR组成的三联评估方法进行评估，其结果与临床医生对不当、有害或无用响应的评估结果一致。最后，我们使用九种不同的LLM证明，这三个指标可以与人类评估结果高度一致，突出了这些指标在LLM驱动的自动化评估管道中使用的潜力。我们还发布了这些实验的提示和数据集，为进一步的研究和开发提供了宝贵的资源。", "summary": "本文介绍了ASTRID，一个针对基于RAG的临床问答系统的新型自动化可扩展三联评估框架，旨在解决现有自动化指标在临床场景中的局限性及人工评估的高成本问题。ASTRID包含上下文相关性（CR）、拒绝准确性（RA）和新颖的对话忠实度（CF）三个指标。研究团队通过一个包含真实世界患者问题的临床数据集验证了ASTRID的有效性，结果表明CF能更准确地预测对话场景下的人工忠实度评分，且整个三联评估体系与临床医生对不当响应的判断高度一致。该方法在多达九个不同LLM上的实验也证实了其与人工评估结果的紧密吻合，凸显了其在自动化评估流程中的应用潜力，并公开了相关数据集和提示。", "keywords": "RAG, 临床问答, 自动化评估, LLM, 对话忠实度", "comments": "该论文的创新点在于提出了ASTRID这一针对临床RAG问答系统的三联评估方法，特别是引入了“对话忠实度（CF）”这一新颖指标，它能更好地适应对话场景，并在不惩罚对话元素的情况下评估模型响应的忠实性。这对于解决当前自动化RAG指标在临床应用中的不足具有重要意义。通过在真实临床数据和多个LLM上进行验证，该方法展现了其与人类评估的高度一致性，为未来LLM在医疗领域的应用提供了更可靠、可扩展的评估工具。同时，公开数据集和提示也为后续研究提供了便利。"}}
{"id": "2507.14111", "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "categories": ["cs.AI", "cs.DC", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint Version", "url": "http://arxiv.org/abs/2507.14111v1", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "comment": "Preprint Version", "pdf_url": "http://arxiv.org/pdf/2507.14111v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CUDA-L1：通过对比强化学习改进CUDA优化", "tldr": "CUDA-L1是一个基于强化学习的自动化CUDA优化框架，在NVIDIA A100上实现了显著加速，并具有良好的跨架构可移植性。", "motivation": "随着大语言模型的快速发展，GPU计算资源需求呈指数级增长，这迫切需要自动化的CUDA优化策略。然而，当前最先进的模型在提高CUDA速度方面的成功率较低。", "method": "本文引入了CUDA-L1，一个自动化的强化学习框架，用于CUDA优化。它通过基于加速的奖励信号，将初始表现不佳的大型语言模型（LLM）转化为有效的CUDA优化器，且无需人类专业知识或领域知识。", "result": "CUDA-L1在NVIDIA A100上训练后，在KernelBench的250个CUDA内核上实现了平均17.7倍的加速，峰值加速达到449倍。该模型还展示了卓越的跨GPU架构可移植性，在H100上平均加速17.8倍，RTX 3090上19.0倍，L40上16.5倍，H800上14.7倍，H20上13.9倍。此外，它能发现并战略性组合多种CUDA优化技术，揭示优化基本原理，识别非显而易见的性能瓶颈，并拒绝有害优化。", "conclusion": "强化学习能够通过基于加速的奖励信号，将初始表现不佳的LLM转化为有效的CUDA优化器，无需人类专业知识。训练后的RL模型能将获得的推理能力扩展到新内核，为CUDA操作的自动化优化开辟了可能性，并有望大幅提升GPU效率。", "translation": "受大型语言模型快速发展推动，GPU计算资源需求呈指数级增长，这迫切需要自动化的CUDA优化策略。尽管LLM的最新进展在代码生成方面显示出前景，但当前SOTA模型（例如R1、o1）在提高CUDA速度方面的成功率较低。在本文中，我们引入了CUDA-L1，一个用于CUDA优化的自动化强化学习框架。CUDA-L1在CUDA优化任务上取得了性能提升：在NVIDIA A100上训练，它在KernelBench的250个CUDA内核上实现了平均17.7倍的加速，峰值加速达到449倍。此外，该模型还展示了卓越的跨GPU架构可移植性，尽管专门针对A100进行了优化，但在H100上实现了17.8倍的平均加速，在RTX 3090上19.0倍，在L40上16.5倍，在H800上14.7倍，在H20上13.9倍。除了这些基准测试结果，CUDA-L1还展示了几个显著特性：1）发现了各种CUDA优化技术并学会战略性地组合它们以实现最佳性能；2）揭示了CUDA优化的基本原理；3）识别了不明显的性能瓶颈并拒绝了看似有益但实际上损害性能的优化。CUDA-L1的能力表明，强化学习可以通过仅基于加速的奖励信号，将最初表现不佳的LLM转化为有效的CUDA优化器，而无需人类专业知识或领域知识。更重要的是，训练后的RL模型将所获得的推理能力扩展到新内核。这种范式为CUDA操作的自动化优化开辟了可能性，并有望大幅提升GPU效率并缓解GPU计算资源日益增长的压力。", "summary": "本文介绍了CUDA-L1，一个基于强化学习的自动化CUDA优化框架。面对大语言模型驱动的GPU资源需求增长和现有优化模型效率低的挑战，CUDA-L1通过强化学习将LLM转化为高效的CUDA优化器。它在NVIDIA A100上实现了平均17.7倍的显著加速，并展现出优异的跨架构可移植性。该框架不仅能发现并组合优化技术，还能揭示优化原理并识别性能瓶颈，为自动化GPU优化提供了新范式。", "keywords": "CUDA优化, 强化学习, LLM, GPU加速, 自动化优化", "comments": "这篇论文的创新点在于将强化学习应用于CUDA优化，并成功地将一个性能不佳的LLM转化为高效的优化器，且无需人工专业知识。其重要性在于解决了GPU资源日益增长的优化需求，并通过自动化方法显著提升了计算效率和跨架构可移植性。"}}
{"id": "2507.13802", "title": "Food safety trends across Europe: insights from the 392-million-entry CompreHensive European Food Safety (CHEFS) database", "authors": ["Nehir Kizililsoley", "Floor van Meer", "Osman Mutlu", "Wouter F Hoenderdaal", "Rosan G. Hobé", "Wenjuan Mu", "Arjen Gerssen", "H. J. van der Fels-Klerx", "Ákos Jóźwiak", "Ioannis Manikas", "Ali Hürriyetoǧlu", "Bas H. M. van der Velden"], "categories": ["cs.CY", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13802v1", "summary": "In the European Union, official food safety monitoring data collected by\nmember states are submitted to the European Food Safety Authority (EFSA) and\npublished on Zenodo. This data includes 392 million analytical results derived\nfrom over 15.2 million samples covering more than 4,000 different types of food\nproducts, offering great opportunities for artificial intelligence to analyze\ntrends, predict hazards, and support early warning systems. However, the\ncurrent format with data distributed across approximately 1000 files totaling\nseveral hundred gigabytes hinders accessibility and analysis. To address this,\nwe introduce the CompreHensive European Food Safety (CHEFS) database, which\nconsolidates EFSA monitoring data on pesticide residues, veterinary medicinal\nproduct residues, and chemical contaminants into a unified and structured\ndataset. We describe the creation and structure of the CHEFS database and\ndemonstrate its potential by analyzing trends in European food safety\nmonitoring data from 2000 to 2024. Our analyses explore changes in monitoring\nactivities, the most frequently tested products, which products were most often\nnon-compliant and which contaminants were most often found, and differences\nacross countries. These findings highlight the CHEFS database as both a\ncentralized data source and a strategic tool for guiding food safety policy,\nresearch, and regulation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13802v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "欧洲食品安全趋势：来自3.92亿条目欧洲综合食品安全（CHEFS）数据库的见解", "tldr": "本文介绍了欧洲综合食品安全（CHEFS）数据库，它整合了EFSA的食品安全监测数据，解决了现有数据格式分散的问题，并通过分析展示了其在指导食品安全政策、研究和监管方面的潜力。", "motivation": "欧盟的官方食品安全监测数据量巨大且分散，阻碍了AI进行趋势分析、危害预测和早期预警系统开发。为了解决数据可访问性和分析的障碍，需要一个统一且结构化的数据集。", "method": "研究团队创建了欧洲综合食品安全（CHEFS）数据库，将EFSA关于农药残留、兽药残留和化学污染物的数据整合到一个统一的结构化数据集中。他们描述了数据库的创建和结构，并通过分析2000年至2024年欧洲食品安全监测数据来展示其潜力，分析内容包括监测活动变化、最常检测的产品、最常不合规的产品、最常发现的污染物以及国家间的差异。", "result": "CHEFS数据库成功整合了分散的EFSA监测数据。分析结果揭示了监测活动的变化、最常检测的产品类型、不合规产品和污染物的分布，以及各国之间的差异。这些发现强调了CHEFS数据库作为一个集中的数据源和战略工具的价值。", "conclusion": "CHEFS数据库是一个中心化的数据源和战略工具，对于指导欧洲食品安全政策、研究和监管具有重要意义，解决了现有数据分散和难以分析的问题。", "translation": "在欧盟，成员国收集的官方食品安全监测数据提交给欧洲食品安全局（EFSA）并在Zenodo上发布。这些数据包括来自超过1520万个样本的3.92亿个分析结果，涵盖4000多种不同类型的食品，为人工智能分析趋势、预测危害和支持早期预警系统提供了巨大机会。然而，目前数据分布在约1000个文件（总计数百千兆字节）的格式阻碍了数据的可访问性和分析。为了解决这个问题，我们引入了欧洲综合食品安全（CHEFS）数据库，它将EFSA关于农药残留、兽药残留和化学污染物的监测数据整合到一个统一和结构化的数据集中。我们描述了CHEFS数据库的创建和结构，并通过分析2000年至2024年欧洲食品安全监测数据中的趋势来展示其潜力。我们的分析探讨了监测活动的变化、最常检测的产品、哪些产品最常不合规以及最常发现哪些污染物，以及国家间的差异。这些发现突出了CHEFS数据库既是一个中心化的数据源，也是一个指导食品安全政策、研究和监管的战略工具。", "summary": "本文介绍了欧洲综合食品安全（CHEFS）数据库，旨在解决欧盟官方食品安全监测数据分散且难以分析的问题。该数据库整合了EFSA关于农药残留、兽药残留和化学污染物的大量数据，形成了一个统一的结构化数据集。通过对2000年至2024年数据的分析，研究人员展示了CHEFS数据库在揭示食品安全趋势（如监测活动变化、不合规产品和污染物分布）方面的潜力，并强调其作为指导食品安全政策、研究和监管的战略工具的重要性。", "keywords": "食品安全, 数据分析, 欧洲, 数据库, 监测数据", "comments": "本文的创新之处在于创建了一个统一且易于访问的欧洲食品安全数据库，解决了现有数据分散和难以利用的痛点。CHEFS数据库的建立对于推动AI在食品安全领域的应用、提高数据分析效率以及更有效地制定政策具有重要意义。其价值在于将海量原始数据转化为可操作的洞察，为未来的食品安全研究和监管奠定了坚实基础。"}}
{"id": "2312.04242", "title": "Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic Agents with Conformal Prediction", "authors": ["Xinyi Yu", "Yiqi Zhao", "Xiang Yin", "Lars Lindemann"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2312.04242v4", "summary": "The control of dynamical systems under temporal logic specifications among\nuncontrollable dynamic agents is challenging due to the agents' a-priori\nunknown behavior. Existing works have considered the problem where either all\nagents are controllable, the agent models are deterministic and known, or no\nsafety guarantees are provided. We propose a predictive control synthesis\nframework that guarantees, with high probability, the satisfaction of signal\ntemporal logic (STL) tasks that are defined over a controllable system in the\npresence of uncontrollable stochastic agents. We use trajectory predictors and\nconformal prediction to construct probabilistic prediction regions for each\nuncontrollable agent that are valid over multiple future time steps.\nSpecifically, we construct a normalized prediction region over all agents and\ntime steps to reduce conservatism and increase data efficiency. We then\nformulate a worst-case bilevel mixed integer program (MIP) that accounts for\nall agent realizations within the prediction region to obtain an open-loop\ncontroller that provably guarantee task satisfaction with high probability. To\nefficiently solve this bilevel MIP, we propose an equivalent MIP program based\non KKT conditions of the original bilevel formulation. Building upon this, we\ndesign a closed-loop controller, where both recursive feasibility and task\nsatisfaction can be guaranteed with high probability. We illustrate our control\nsynthesis framework on two case studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2312.04242v4", "cate": "eess.SY", "date": "2023-12-07", "updated": "2025-07-18", "AI": {"title_translation": "信号时序逻辑控制综合，用于不可控动态智能体与共形预测", "tldr": "本文提出了一种预测控制综合框架，利用共形预测在高概率下保证可控系统在不可控随机智能体存在时的信号时序逻辑（STL）任务满足，解决了智能体行为未知带来的挑战。", "motivation": "在不可控动态智能体之间，根据时序逻辑规范对动态系统进行控制具有挑战性，因为智能体的先验行为是未知的。现有工作存在局限性，例如要么所有智能体都是可控的，要么智能体模型是确定且已知的，要么不提供安全保证。", "method": "提出了一种预测控制综合框架。使用轨迹预测器和共形预测为每个不可控智能体构建概率预测区域，该区域在多个未来时间步长内有效。构建了一个跨所有智能体和时间步长的归一化预测区域，以减少保守性并提高数据效率。制定了一个最坏情况下的双层混合整数规划（MIP），该规划考虑了预测区域内所有智能体的实现，以获得开环控制器。为了有效地解决双层MIP，基于KKT条件提出了一个等效的MIP程序。在此基础上，设计了一个闭环控制器。", "result": "所提出的框架能够以高概率保证信号时序逻辑（STL）任务的满足。开环控制器可以证明以高概率保证任务满足。闭环控制器可以高概率地保证递归可行性和任务满足。该控制综合框架通过两个案例研究进行了说明。", "conclusion": "本文提出了一种新颖的预测控制综合框架，利用共形预测在高概率下鲁棒地满足可控系统与不可控随机智能体交互时的STL任务，提供了强大的概率保证和高效的可解性。", "translation": "在不可控动态智能体之间，根据时序逻辑规范对动态系统进行控制具有挑战性，因为智能体的先验行为是未知的。现有工作考虑的问题是：要么所有智能体都是可控的，要么智能体模型是确定且已知的，要么不提供安全保证。我们提出了一种预测控制综合框架，在存在不可控随机智能体的情况下，以高概率保证可控系统上定义的信号时序逻辑（STL）任务的满足。我们使用轨迹预测器和共形预测来为每个不可控智能体构建在多个未来时间步长内有效的概率预测区域。具体来说，我们构建了一个跨所有智能体和时间步长的归一化预测区域，以减少保守性并提高数据效率。然后，我们制定了一个最坏情况下的双层混合整数规划（MIP），该规划考虑了预测区域内所有智能体的实现，以获得一个可证明以高概率保证任务满足的开环控制器。为了有效地解决这个双层MIP，我们基于原始双层公式的KKT条件提出了一个等效的MIP程序。在此基础上，我们设计了一个闭环控制器，其中递归可行性和任务满足都可以高概率地得到保证。我们通过两个案例研究说明了我们的控制综合框架。", "summary": "本文提出了一种预测控制综合框架，旨在解决在存在不可控随机智能体环境下，根据信号时序逻辑（STL）规范控制动态系统的难题。该框架利用轨迹预测器和共形预测为不可控智能体构建概率预测区域，并构建归一化区域以提高效率。它将问题表述为最坏情况下的双层混合整数规划（MIP），并通过基于KKT条件的等效MIP程序进行高效求解，以获得具有高概率任务满足保证的开环控制器。在此基础上，还设计了一个闭环控制器，同样能以高概率保证递归可行性和任务满足。该框架通过案例研究进行了验证。", "keywords": "信号时序逻辑, 共形预测, 不可控智能体, 预测控制, 混合整数规划", "comments": "本文的创新之处在于将共形预测与信号时序逻辑控制相结合，用于处理存在不可控随机智能体的系统，这与之前假设智能体可控或确定行为的工作有显著不同。利用归一化预测区域减少保守性以及通过KKT条件高效求解双层MIP也是重要的贡献。这项工作为任务满足提供了强大的概率保证，增强了在不确定环境中的鲁棒性。"}}
{"id": "2412.05657", "title": "AI-Accelerated Flow Simulation: A Robust Auto-Regressive Framework for Long-Term CFD Forecasting", "authors": ["Sunwoong Yang", "Ricardo Vinuesa", "Namwoo Kang"], "categories": ["cs.LG", "physics.flu-dyn"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.05657v3", "summary": "This study addresses the critical challenge of error accumulation in\nspatio-temporal auto-regressive (AR) predictions within scientific machine\nlearning models by exploring temporal integration schemes and adaptive\nmulti-step rollout strategies. We introduce the first implementation of the\ntwo-step Adams-Bashforth method specifically tailored for data-driven AR\nprediction, leveraging historical derivative information to enhance numerical\nstability without additional computational overhead. To validate our approach,\nwe systematically evaluate time integration schemes across canonical 2D PDEs\nbefore extending to complex Navier-Stokes cylinder vortex shedding dynamics.\nAdditionally, we develop three novel adaptive weighting strategies that\ndynamically adjust the importance of different future time steps during\nmulti-step rollout training. Our analysis reveals that as physical complexity\nincreases, such sophisticated rollout techniques become essential, with the\nAdams-Bashforth scheme demonstrating consistent robustness across investigated\nsystems and our best adaptive approach delivering an 89% improvement over\nconventional fixed-weight methods while maintaining similar computational\ncosts. For the complex Navier-Stokes vortex shedding problem, despite using an\nextremely lightweight graph neural network with just 1,177 trainable parameters\nand training on only 50 snapshots, our framework accurately predicts 350 future\ntime steps reducing mean squared error from 0.125 (single-step direct\nprediction) to 0.002 (Adams-Bashforth with proposed multi-step rollout). Our\nintegrated methodology demonstrates an 83% improvement over standard noise\ninjection techniques and maintains robustness under severe spatial constraints;\nspecifically, when trained on only a partial spatial domain, it still achieves\n58% and 27% improvements over direct prediction and forward Euler methods,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.05657v3", "cate": "cs.LG", "date": "2024-12-07", "updated": "2025-07-18", "AI": {"title_translation": "AI加速流体模拟：用于长期CFD预测的鲁棒自回归框架", "tldr": "本研究引入了一种结合两步Adams-Bashforth方法和自适应多步展开策略的自回归框架，显著减少了科学机器学习模型中时空自回归预测的误差累积，并在长期CFD预测中表现出卓越的鲁棒性和准确性。", "motivation": "解决科学机器学习模型中时空自回归（AR）预测的误差累积这一关键挑战。", "method": "1. 首次将两步Adams-Bashforth方法应用于数据驱动的AR预测，利用历史导数信息增强数值稳定性。2. 系统评估了经典2D偏微分方程和复杂的Navier-Stokes圆柱涡脱落动力学中的时间积分方案。3. 开发了三种新颖的自适应加权策略，用于在多步展开训练期间动态调整不同未来时间步的重要性。", "result": "1. Adams-Bashforth方案在所研究的系统中表现出一致的鲁棒性。2. 最佳自适应方法比传统固定权重方法提高了89%，且计算成本相似。3. 对于Navier-Stokes涡脱落问题，即使使用轻量级图神经网络（1,177个参数，50个快照训练），该框架也能准确预测350个未来时间步，将均方误差从0.125降至0.002。4. 综合方法比标准噪声注入技术提高了83%。5. 在严重空间约束下（仅在部分空间域训练），比直接预测和前向欧拉方法分别提高了58%和27%。", "conclusion": "本研究提出的结合Adams-Bashforth方法和自适应多步展开策略的自回归框架，在科学机器学习模型的长期时空预测中显著提高了准确性和鲁棒性，尤其是在复杂物理系统和有限数据条件下的流体动力学模拟中表现出色。", "translation": "本研究通过探索时间积分方案和自适应多步展开策略，解决了科学机器学习模型中时空自回归（AR）预测中误差累积的关键挑战。我们首次实现了专门为数据驱动的AR预测量身定制的两步Adams-Bashforth方法，该方法利用历史导数信息来增强数值稳定性，而无需额外的计算开销。为了验证我们的方法，我们系统地评估了经典2D偏微分方程中的时间积分方案，然后扩展到复杂的Navier-Stokes圆柱涡脱落动力学。此外，我们开发了三种新颖的自适应加权策略，在多步展开训练期间动态调整不同未来时间步的重要性。我们的分析表明，随着物理复杂性的增加，这种复杂的展开技术变得至关重要，Adams-Bashforth方案在所研究的系统中表现出一致的鲁棒性，我们最好的自适应方法比传统的固定权重方法提高了89%，同时保持了相似的计算成本。对于复杂的Navier-Stokes涡脱落问题，尽管使用了仅有1,177个可训练参数且仅在50个快照上训练的极轻量级图神经网络，我们的框架仍能准确预测350个未来时间步，将均方误差从0.125（单步直接预测）降低到0.002（Adams-Bashforth与所提出的多步展开相结合）。我们的集成方法比标准噪声注入技术提高了83%，并在严格的空间约束下保持了鲁棒性；具体来说，当仅在部分空间域上训练时，它仍然比直接预测和前向欧拉方法分别提高了58%和27%。", "summary": "本研究提出了一种用于长期计算流体动力学（CFD）预测的鲁棒自回归框架，旨在解决科学机器学习模型中误差累积的问题。该框架创新性地引入了两步Adams-Bashforth方法和三种自适应多步展开加权策略。实验证明，与现有方法相比，该方法在提高预测准确性和数值稳定性方面表现出色，尤其是在复杂物理系统和数据受限的情况下，显著减少了均方误差，并保持了计算效率。", "keywords": "流体模拟, 自回归预测, Adams-Bashforth, 误差累积, 计算流体动力学", "comments": "该论文的创新点在于首次将两步Adams-Bashforth方法引入数据驱动的自回归预测，并结合了新颖的自适应加权策略，有效解决了长期预测中的误差累积问题。其重要性在于，即使在模型轻量级和数据量有限的情况下，也能实现高精度的长期流体动力学预测，这对于计算资源受限或需要快速预测的场景具有重要意义。该方法在复杂系统和空间约束下的鲁棒性也值得关注。"}}
{"id": "2507.05169", "title": "Critiques of World Models", "authors": ["Eric Xing", "Mingkai Deng", "Jinyu Hou", "Zhiting Hu"], "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05169v2", "summary": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05169v2", "cate": "cs.LG", "date": "2025-07-07", "updated": "2025-07-18", "AI": {"title_translation": "世界模型的批判", "tldr": "本文批判了当前世界模型的几种思想流派，并提出了一个新的世界模型架构，旨在为通用人工智能系统提供物理、代理和嵌套的能力。", "motivation": "随着开发具有人工（通用）智能的虚拟代理的需求日益增长，世界模型成为一个新兴话题。然而，关于世界模型是什么、如何构建、使用和评估存在诸多争议。本文旨在对这些争议进行批判性分析。", "method": "作者从科幻小说《沙丘》的想象和心理学文献中“假设性思维”的概念获得灵感，对世界建模的几种思想流派进行了批判。在此基础上，提出了一种新的通用世界模型架构，该架构基于分层、多层次、混合连续/离散表示，以及生成式和自监督学习框架。", "result": "本文批判了现有世界模型的思想流派，并提出了一个旨在模拟真实世界所有可操作可能性的新世界模型架构。", "conclusion": "世界模型的首要目标是模拟真实世界的所有可操作可能性，以实现有目的的推理和行动。所提出的新架构有望实现一个物理、代理和嵌套（PAN）的通用人工智能系统。", "translation": "世界模型，作为生物智能体体验和行动的现实世界环境的算法替代品，近年来因开发具有人工（通用）智能的虚拟智能体的需求日益增长而成为一个新兴话题。关于世界模型到底是什么、如何构建、如何使用以及如何评估，一直存在诸多争论。在本文中，我们从著名的科幻经典《沙丘》中的想象出发，并借鉴心理学文献中“假设性思维”的概念，对世界建模的几种思想流派提出了批判，并认为世界模型的主要目标是模拟现实世界所有可操作的可能性，以实现有目的的推理和行动。在此批判的基础上，我们提出了一种新的通用世界模型架构，该架构基于分层、多层次和混合连续/离散表示，以及生成式和自监督学习框架，并展望了由这种模型实现的物理、代理和嵌套（PAN）的通用人工智能系统。", "summary": "这篇论文对当前关于世界模型的几种主要思想流派进行了批判性分析，指出其核心目标应是模拟现实世界中所有可操作的可能性，以支持有目的的推理和行动。作者受《沙丘》和“假设性思维”启发，提出了一种新的通用世界模型架构，该架构采用分层、多层次、混合连续/离散表示，并结合生成式和自监督学习框架，旨在为实现物理、代理和嵌套（PAN）的通用人工智能系统奠定基础。", "keywords": "世界模型, 通用人工智能, 批判, 假设性思维, 模型架构", "comments": "这篇论文通过引入对世界模型的哲学和心理学层面的批判，并结合科幻作品的启发，为世界模型的研究提供了新颖的视角。其创新点在于不仅批判了现有方法，还提出了一个结合了多种先进表示和学习范式的新架构，并明确了世界模型服务于AGI的核心目标。这对于推动通用人工智能的发展具有重要的理论指导意义。"}}
{"id": "2503.23883", "title": "Algorithm Design and Prototype Validation for Reconfigurable Intelligent Sensing Surface: Forward-Only Transmission", "authors": ["Cheng Luo", "Luping Xiang", "Jie Hu", "Kun Yang"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.23883v5", "summary": "Sensing-assisted communication schemes have recently garnered significant\nresearch attention. In this work, we design a dual-function reconfigurable\nintelligent surface (RIS), integrating both active and passive elements,\nreferred to as the reconfigurable intelligent sensing surface (RISS), to\nenhance communication. By leveraging sensing results from the active elements,\nwe propose communication enhancement and robust interference suppression\nschemes for both near-field and far-field models, implemented through the\npassive elements. These schemes remove the need for base station (BS) feedback\nfor RISS control, simplifying the communication process by replacing\ntraditional channel state information (CSI) feedback with real-time sensing\nfrom the active elements. The proposed schemes are theoretically analyzed and\nthen validated using software-defined radio (SDR). Experimental results\ndemonstrate the effectiveness of the sensing algorithms in real-world\nscenarios, such as direction of arrival (DOA) estimation and radio frequency\n(RF) identification recognition. Moreover, the RISS-assisted communication\nsystem shows strong performance in communication enhancement and interference\nsuppression, particularly in near-field models.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.23883v5", "cate": "eess.SP", "date": "2025-03-31", "updated": "2025-07-18", "AI": {"title_translation": "可重构智能感知表面（仅前向传输）的算法设计与原型验证", "tldr": "本文设计了一种集成主动和被动元件的双功能可重构智能感知表面（RISS），通过实时感知实现通信增强和干扰抑制，无需基站反馈，并在实验中验证了其有效性，尤其在近场表现优异。", "motivation": "传感辅助通信方案近期受到广泛关注，本文旨在设计一种双功能可重构智能表面（RISS）以增强通信。", "method": "设计了一种集成主动和被动元件的双功能可重构智能感知表面（RISS）。利用主动元件的感知结果，提出了针对近场和远场模型的通信增强和鲁棒干扰抑制方案，并通过被动元件实现。这些方案通过实时感知替代传统CSI反馈，无需基站反馈。通过理论分析和软件定义无线电（SDR）进行了验证。", "result": "实验结果表明感知算法在到达方向（DOA）估计和射频（RF）识别等实际场景中有效。RISS辅助通信系统在通信增强和干扰抑制方面表现出强大的性能，特别是在近场模型中。", "conclusion": "本文设计的可重构智能感知表面（RISS）通过结合主动感知和被动通信，有效地实现了无需基站反馈的通信增强和干扰抑制，尤其在近场通信中展现出优越性。", "translation": "传感辅助通信方案近期受到了广泛关注。在这项工作中，我们设计了一种集主动和被动元件于一体的双功能可重构智能表面（RIS），称之为可重构智能感知表面（RISS），以增强通信。通过利用主动元件的感知结果，我们提出了针对近场和远场模型的通信增强和鲁棒干扰抑制方案，并通过被动元件实现。这些方案消除了基站（BS）对RISS控制的反馈需求，通过用主动元件的实时感知替代传统的信道状态信息（CSI）反馈，从而简化了通信过程。所提出的方案经过理论分析，并通过软件定义无线电（SDR）进行了验证。实验结果证明了感知算法在实际场景（如到达方向（DOA）估计和射频（RF）识别）中的有效性。此外，RISS辅助通信系统在通信增强和干扰抑制方面表现出强大的性能，特别是在近场模型中。", "summary": "本文设计并验证了一种名为可重构智能感知表面（RISS）的双功能RIS，它集成了主动感知和被动通信元件。该RISS利用主动元件的实时感知数据，替代了传统的信道状态信息（CSI）反馈，从而简化了通信系统，并提出了适用于近场和远场模型的通信增强与干扰抑制方案。实验结果表明，该RISS在感知任务和通信性能（尤其在近场）方面均表现出色。", "keywords": "可重构智能感知表面, 传感辅助通信, 干扰抑制, 近场通信, 软件定义无线电", "comments": "本文的创新点在于提出了双功能RISS，将主动感知与被动通信相结合，并利用实时感知替代了传统的CSI反馈机制，从而简化了基站控制并提升了系统性能。这种方法为未来无线通信系统提供了新的设计思路，尤其是在需要低反馈开销和复杂环境感知能力的场景中具有重要意义。"}}
{"id": "2507.13575", "title": "Apple Intelligence Foundation Language Models: Tech Report 2025", "authors": ["Hanzhi Zhou", "Erik Hornberger", "Pengsheng Guo", "Xiyou Zhou", "Saiwen Wang", "Xin Wang", "Yifei He", "Xuankai Chang", "Rene Rauch", "Louis D'hauwe", "John Peebles", "Alec Doane", "Kohen Chia", "Jenna Thibodeau", "Zi-Yi Dou", "Yuanyang Zhang", "Ruoming Pang", "Reed Li", "Zhifeng Chen", "Jeremy Warner", "Zhaoyang Xu", "Sophy Lee", "David Mizrahi", "Ramsey Tantawi", "Chris Chaney", "Kelsey Peterson", "Jun Qin", "Alex Dombrowski", "Mira Chiang", "Aiswarya Raghavan", "Gerard Casamayor", "Qibin Chen", "Aonan Zhang", "Nathalie Tran", "Jianyu Wang", "Hang Su", "Thomas Voice", "Alessandro Pappalardo", "Brycen Wershing", "Prasanth Yadla", "Rui Li", "Priyal Chhatrapati", "Ismael Fernandez", "Yusuf Goren", "Xin Zheng", "Forrest Huang", "Tao Lei", "Eray Yildiz", "Alper Kokmen", "Gokul Santhanam", "Areeba Kamal", "Kaan Elgin", "Dian Ang Yap", "Jeremy Liu", "Peter Gray", "Howard Xing", "Kieran Liu", "Matteo Ronchi", "Moritz Schwarzer-Becker", "Yun Zhu", "Mandana Saebi", "Jeremy Snow", "David Griffiths", "Guillaume Tartavel", "Erin Feldman", "Simon Lehnerer", "Fernando Bermúdez-Medina", "Hans Han", "Joe Zhou", "Xiaoyi Ren", "Sujeeth Reddy", "Zirui Wang", "Tom Gunter", "Albert Antony", "Yuanzhi Li", "John Dennison", "Tony Sun", "Yena Han", "Yi Qin", "Sam Davarnia", "Jeffrey Bigham", "Wayne Shan", "Hannah Gillis Coleman", "Guillaume Klein", "Peng Liu", "Muyang Yu", "Jack Cackler", "Yuan Gao", "Crystal Xiao", "Binazir Karimzadeh", "Zhengdong Zhang", "Felix Bai", "Albin Madappally Jose", "Feng Nan", "Nazir Kamaldin", "Dong Yin", "Hans Hao", "Yanchao Sun", "Yi Hua", "Charles Maalouf", "Alex Guillen Garcia", "Guoli Yin", "Lezhi Li", "Mohana Prasad Sathya Moorthy", "Hongbin Gao", "Jay Tang", "Joanna Arreaza-Taylor", "Faye Lao", "Carina Peng", "Josh Shaffer", "Dan Masi", "Sushma Rao", "Tommi Vehvilainen", "Senyu Tong", "Dongcai Shen", "Yang Zhao", "Chris Bartels", "Peter Fu", "Qingqing Cao", "Christopher Neubauer", "Ethan Li", "Mingfei Gao", "Rebecca Callahan", "Richard Wei", "Patrick Dong", "Alex Braunstein", "Sachin Ravi", "Adolfo Lopez Mendez", "Kaiwei Huang", "Kun Duan", "Haoshuo Huang", "Rui Qian", "Stefano Ligas", "Jordan Huffaker", "Dongxu Li", "Bailin Wang", "Nanzhu Wang", "Anuva Agarwal", "Tait Madsen", "Josh Newnham", "Abhishek Sharma", "Zhile Ren", "Deepak Gopinath", "Erik Daxberger", "Saptarshi Guha", "Oron Levy", "Jing Lu", "Nan Dun", "Marc Kirchner", "Yinfei Yang", "Manjot Bilkhu", "Dave Nelson", "Anthony Spalvieri-Kruse", "Juan Lao Tebar", "Yang Xu", "Phani Mutyala", "Gabriel Jacoby-Cooper", "Yingbo Wang", "Karla Vega", "Vishaal Mahtani", "Darren Botten", "Eric Wang", "Hanli Li", "Matthias Paulik", "Haoran Yan", "Navid Shiee", "Yihao Qian", "Bugu Wu", "Qi Zhu", "Ob Adaranijo", "Bhuwan Dhingra", "Zhe Gan", "Nicholas Seidl", "Grace Duanmu", "Rong Situ", "Yiping Ma", "Yin Xia", "David Riazati", "Vasileios Saveris", "Anh Nguyen", "Michael", "Lee", "Patrick Sonnenberg", "Chinguun Erdenebileg", "Yanghao Li", "Vivian Ma", "James Chou", "Isha Garg", "Mark Lee", "Keen You", "Yuhong Li", "Ransen Niu", "Nandhitha Raghuram", "Pulkit Agrawal", "Henry Mason", "Sumeet Singh", "Keyu He", "Hong-You Chen", "Lucas Guibert", "Shiyu Li", "Varsha Paidi", "Narendran Raghavan", "Mingze Xu", "Yuli Yang", "Sergiu Sima", "Irina Belousova", "Sprite Chu", "Afshin Dehghan", "Philipp Dufter", "David Haldimann", "Zhen Yang", "Margit Bowler", "Chang Liu", "Ying-Chang Cheng", "Vivek Rathod", "Syd Evans", "Wilson Tsao", "Dustin Withers", "Haitian Sun", "Biyao Wang", "Peter Grasch", "Walker Cheng", "Yihao Feng", "Vivek Kumar", "Frank Chu", "Victoria MönchJuan Haladjian", "Doug Kang", "Jiarui Lu", "Ciro Sannino", "Max Lam", "Floris Weers", "Bowen Pan", "Kenneth Jung", "Dhaval Doshi", "Fangping Shi", "Olli Saarikivi", "Alp Aygar", "Josh Elman", "Cheng Leong", "Eshan Verma", "Matthew Lei", "Jeff Nichols", "Jiulong Shan", "Donald Zhang", "Lawrence Zhou", "Stephen Murphy", "Xianzhi Du", "Chang Lan", "Ankur Jain", "Elmira Amirloo", "Marcin Eichner", "Naomy Sabo", "Anupama Mann Anupama", "David Qiu", "Zhao Meng", "Michael FitzMaurice", "Peng Zhang", "Simon Yeung", "Chen Chen", "Marco Zuliani", "Andrew Hansen", "Yang Lu", "Brent Ramerth", "Ziyi Zhong", "Parsa Mazaheri", "Matthew Hopkins", "Mengyu Li", "Simon Wang", "David Chen", "Farzin Rasteh", "Chong Wang", "Josh Gardner", "Asaf Liberman", "Haoxuan You", "Andrew Walkingshaw", "Xingyu Zhou", "Jinhao Lei", "Yan Meng", "Quentin Keunebroek", "Sam Wiseman", "Anders Boesen Lindbo Larsen", "Yi Zhang", "Zaid Ahmed", "Haiming Gang", "Aaron Franklin", "Kelvin Zou", "Guillaume Seguin", "Jonathan Janke", "Rachel Burger", "Co Giang", "Cheng Shen", "Jen Liu", "Sanskruti Shah", "Xiang Kong", "Yiran Fei", "TJ Collins", "Chen Zhang", "Zhiyun Lu", "Michael Booker", "Qin Ba", "Yasutaka Tanaka", "Andres Romero Mier Y Teran", "Federico Scozzafava", "Regan Poston", "Jane Li", "Eduardo Jimenez", "Bas Straathof", "Karanjeet Singh", "Lindsay Hislop", "Rajat Arora", "Deepa Seshadri", "Boyue Li", "Colorado Reed", "Zhen Li", "TJ Lu", "Yi Wang", "Kaelen Haag", "Nicholas Lusskin", "Raunak Sinha", "Rahul Nair", "Eldon Schoop", "Mary Beth Kery", "Mehrdad Farajtbar", "Brenda Yang", "George Horrell", "Shiwen Zhao", "Dhruti Shah", "Cha Chen", "Bowen Zhang", "Chang Gao", "Devi Krishna", "Jennifer Mallalieu", "Javier Movellan", "Di Feng", "Emily Zhang", "Sam Xu", "Junting Pan", "Dominik Moritz", "Suma Jayaram", "Kevin Smith", "Dongseong Hwang", "Daniel Parilla", "Jiaming Hu", "You-Cyuan Jhang", "Emad Soroush", "Fred Hohman", "Nan Du", "Emma Wang", "Sam Dodge", "Pragnya Sridhar", "Joris Pelemans", "Wei Fang", "Nina Wenzel", "Joseph Yitan Cheng", "Hadas Kotek", "Chung-Cheng Chiu", "Meng Cao", "Haijing Fu", "Ruixuan Hou", "Ke Ye", "Diane Zhu", "Nikhil Bhendawade", "Joseph Astrauskas", "Jian Liu", "Sai Aitharaju", "Wentao Wu", "Artsiom Peshko", "Hyunjik Kim", "Nilesh Shahdadpuri", "Andy De Wang", "Qi Shan", "Piotr Maj", "Raul Rea Menacho", "Justin Lazarow", "Eric Liang Yang", "Arsalan Farooq", "Donghan Yu", "David Güera", "Minsik Cho", "Kavya Nerella", "Yongqiang Wang", "Tao Jia", "John Park", "Jeff Lai", "Haotian Zhang", "Futang Peng", "Daniele Molinari", "Aparna Rajamani", "Tyler Johnson", "Lauren Gardiner", "Chao Jia", "Violet Yao", "Wojciech Kryscinski", "Xiujun Li", "Shang-Chen Wu"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13575v1", "summary": "We introduce two multilingual, multimodal foundation language models that\npower Apple Intelligence features across Apple devices and services: i a\n3B-parameter on-device model optimized for Apple silicon through architectural\ninnovations such as KV-cache sharing and 2-bit quantization-aware training; and\nii a scalable server model built on a novel Parallel-Track Mixture-of-Experts\nPT-MoE transformer that combines track parallelism, mixture-of-experts sparse\ncomputation, and interleaved global-local attention to deliver high quality\nwith competitive cost on Apple's Private Cloud Compute platform. Both models\nare trained on large-scale multilingual and multimodal datasets sourced via\nresponsible web crawling, licensed corpora, and high-quality synthetic data,\nthen further refined with supervised fine-tuning and reinforcement learning on\na new asynchronous platform. The resulting models support several additional\nlanguages while understanding images and executing tool calls. In public\nbenchmarks and human evaluations, both the server model and the on-device model\nmatch or surpass comparably sized open baselines.\n  A new Swift-centric Foundation Models framework exposes guided generation,\nconstrained tool calling, and LoRA adapter fine-tuning, allowing developers to\nintegrate these capabilities with a few lines of code. The latest advancements\nin Apple Intelligence models are grounded in our Responsible AI approach with\nsafeguards like content filtering and locale-specific evaluation, as well as\nour commitment to protecting our users' privacy with innovations like Private\nCloud Compute.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13575v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "苹果智能基础语言模型：2025技术报告", "tldr": "苹果发布了两款多语言、多模态的基础语言模型：一款3B参数的端侧模型和一款基于新型PT-MoE的服务器模型，它们为Apple Intelligence提供支持，并在公共基准测试中表现优异，同时强调负责任的AI和用户隐私。", "motivation": "该研究旨在推出两款多语言、多模态的基础语言模型，以支持Apple设备和服务上的Apple Intelligence功能。", "method": "本文介绍了两款模型：一是3B参数的端侧模型，通过KV缓存共享和2比特量化感知训练等架构创新，针对Apple芯片进行优化；二是可扩展的服务器模型，基于新颖的并行轨道混合专家（PT-MoE）Transformer，结合轨道并行、混合专家稀疏计算和交错式全局-局部注意力，在Apple的私有云计算平台上以有竞争力的成本提供高质量服务。两款模型均使用负责任的网络爬取、许可语料库和高质量合成数据等来源的大规模多语言多模态数据集进行训练，并通过新异步平台上的监督微调和强化学习进一步优化。", "result": "所得模型支持多种额外语言，能够理解图像并执行工具调用。在公共基准测试和人工评估中，服务器模型和端侧模型均匹配或超越了同等规模的开源基线。同时，一个新的以Swift为中心的Foundation Models框架提供了引导式生成、受限工具调用和LoRA适配器微调功能，方便开发者集成。", "conclusion": "苹果已成功开发并部署了两款高性能、多功能的基础语言模型，它们在性能上达到或超越现有基线，并集成了负责任AI和用户隐私保护措施，为Apple Intelligence功能提供核心支持。", "translation": "我们推出了两款多语言、多模态的基础语言模型，它们为Apple设备和服务上的Apple Intelligence功能提供支持：一是3B参数的端侧模型，通过KV缓存共享和2比特量化感知训练等架构创新，针对Apple芯片进行优化；二是可扩展的服务器模型，基于新颖的并行轨道混合专家（PT-MoE）Transformer，结合轨道并行、混合专家稀疏计算和交错式全局-局部注意力，在Apple的私有云计算平台上以有竞争力的成本提供高质量服务。这两款模型均通过负责任的网络爬取、许可语料库和高质量合成数据等来源的大规模多语言和多模态数据集进行训练，然后在新异步平台上通过监督微调和强化学习进一步完善。最终的模型支持多种额外语言，同时能理解图像并执行工具调用。在公共基准测试和人工评估中，服务器模型和端侧模型均匹配或超越了同等规模的开源基线。一个新的以Swift为中心的Foundation Models框架提供了引导式生成、受限工具调用和LoRA适配器微调功能，允许开发者通过几行代码集成这些能力。Apple Intelligence模型的最新进展根植于我们负责任的AI方法，包括内容过滤和区域特定评估等保障措施，以及我们通过私有云计算等创新保护用户隐私的承诺。", "summary": "本文介绍了苹果为Apple Intelligence功能开发的两款核心基础语言模型：一个针对Apple芯片优化的3B参数端侧模型，以及一个基于新型PT-MoE架构的服务器模型。这两款多语言、多模态模型通过大规模数据集训练和强化学习优化，能够理解图像、执行工具调用，并在性能上超越现有开源基线。同时，苹果还发布了一个Swift框架以方便开发者集成，并强调了负责任AI和用户隐私保护的重要性。", "keywords": "苹果智能, 基础语言模型, 端侧AI, 混合专家模型, 私有云计算", "comments": "这篇技术报告展示了苹果在大型语言模型领域的最新进展，其创新点在于针对不同部署环境（端侧与服务器）设计了特定的优化架构，如KV缓存共享、2比特量化感知训练以及新颖的PT-MoE Transformer。这不仅体现了对硬件的深度集成优化，也通过混合专家架构实现了成本效益和高性能的平衡。此外，报告还强调了负责任AI和用户隐私保护，这在当前AI发展中是至关重要的考量，并为开发者提供了易于集成的Swift框架，预示着这些模型将在Apple生态系统中得到广泛应用。"}}
{"id": "2501.17328", "title": "SIC: Similarity-Based Interpretable Image Classification with Neural Networks", "authors": ["Tom Nuno Wolf", "Emre Kavak", "Fabian Bongratz", "Christian Wachinger"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICCV 2025", "url": "http://arxiv.org/abs/2501.17328v3", "summary": "The deployment of deep learning models in critical domains necessitates a\nbalance between high accuracy and interpretability. We introduce SIC, an\ninherently interpretable neural network that provides local and global\nexplanations of its decision-making process. Leveraging the concept of\ncase-based reasoning, SIC extracts class-representative support vectors from\ntraining images, ensuring they capture relevant features while suppressing\nirrelevant ones. Classification decisions are made by calculating and\naggregating similarity scores between these support vectors and the input's\nlatent feature vector. We employ B-Cos transformations, which align model\nweights with inputs, to yield coherent pixel-level explanations in addition to\nglobal explanations of case-based reasoning. We evaluate SIC on three tasks:\nfine-grained classification on Stanford Dogs and FunnyBirds, multi-label\nclassification on Pascal VOC, and pathology detection on the RSNA dataset.\nResults indicate that SIC not only achieves competitive accuracy compared to\nstate-of-the-art black-box and inherently interpretable models but also offers\ninsightful explanations verified through practical evaluation on the FunnyBirds\nbenchmark. Our theoretical analysis proves that these explanations fulfill\nestablished axioms for explanations. Our findings underscore SIC's potential\nfor applications where understanding model decisions is as critical as the\ndecisions themselves.", "comment": "Accepted at ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2501.17328v3", "cate": "cs.CV", "date": "2025-01-28", "updated": "2025-07-18", "AI": {"title_translation": "SIC：基于相似性的可解释神经网络图像分类", "tldr": "SIC是一种可解释的神经网络，它通过基于案例的推理和相似性计算进行图像分类，同时提供局部和全局解释，并在保持竞争性准确率的同时提供可验证的解释。", "motivation": "在关键领域部署深度学习模型需要平衡高准确性和可解释性。", "method": "SIC是一种固有的可解释神经网络，它利用基于案例的推理，从训练图像中提取代表类别的支持向量。分类决策通过计算并聚合这些支持向量与输入潜在特征向量之间的相似性分数来做出。此外，它采用B-Cos变换来提供连贯的像素级解释和全局解释。", "result": "SIC在Stanford Dogs、FunnyBirds、Pascal VOC和RSNA数据集上的三项任务中进行了评估。结果表明，SIC不仅在准确性方面与最先进的黑盒模型和固有的可解释模型相比具有竞争力，而且通过在FunnyBirds基准测试上的实际评估，提供了有洞察力的解释。理论分析证明其解释满足既定公理。", "conclusion": "SIC在模型决策理解与决策本身同等重要的应用中具有巨大潜力。", "translation": "深度学习模型在关键领域的部署需要平衡高准确性和可解释性。我们引入了SIC，这是一种固有的可解释神经网络，它能提供决策过程的局部和全局解释。SIC利用基于案例推理的概念，从训练图像中提取代表类别的支持向量，确保它们捕获相关特征同时抑制不相关特征。分类决策通过计算并聚合这些支持向量与输入潜在特征向量之间的相似性分数来做出。我们采用B-Cos变换，将模型权重与输入对齐，除了基于案例推理的全局解释外，还能产生连贯的像素级解释。我们在三项任务上评估了SIC：Stanford Dogs和FunnyBirds上的细粒度分类、Pascal VOC上的多标签分类以及RSNA数据集上的病理检测。结果表明，与最先进的黑盒模型和固有的可解释模型相比，SIC不仅取得了竞争性的准确率，而且通过在FunnyBirds基准测试上的实际评估，提供了有洞察力的解释。我们的理论分析证明这些解释满足既定的解释公理。我们的发现强调了SIC在模型决策理解与决策本身同等重要的应用中的潜力。", "summary": "SIC是一种新颖的、固有的可解释神经网络，专为图像分类设计。它通过基于案例的推理，从训练数据中提取代表性支持向量，并利用这些向量与输入特征的相似性进行分类。为了提供详细的解释，SIC结合了B-Cos变换，能够生成像素级和全局解释。该模型在多个图像分类任务上表现出与现有模型相当的准确性，同时提供了清晰且符合解释公理的可验证解释，使其适用于需要高透明度的关键应用。", "keywords": "可解释人工智能, 图像分类, 神经网络, 基于案例推理, 相似性学习", "comments": "SIC的创新之处在于其结合了基于案例推理和B-Cos变换，提供了一种固有的可解释性，而不仅仅是后处理的解释。它在保持竞争性准确率的同时，提供满足理论公理的解释，这对于深度学习在医疗等关键领域的应用至关重要。其能力在于同时提供局部像素级和全局案例级解释，增强了模型决策的透明度和用户信任。"}}
{"id": "2507.13919", "title": "The Levers of Political Persuasion with Conversational AI", "authors": ["Kobi Hackenburg", "Ben M. Tappin", "Luke Hewitt", "Ed Saunders", "Sid Black", "Hause Lin", "Catherine Fist", "Helen Margetts", "David G. Rand", "Christopher Summerfield"], "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      19 pages, 4 figures. Our supplementary materials file can be found at this https URL", "url": "http://arxiv.org/abs/2507.13919v1", "summary": "There are widespread fears that conversational AI could soon exert\nunprecedented influence over human beliefs. Here, in three large-scale\nexperiments (N=76,977), we deployed 19 LLMs-including some post-trained\nexplicitly for persuasion-to evaluate their persuasiveness on 707 political\nissues. We then checked the factual accuracy of 466,769 resulting LLM claims.\nContrary to popular concerns, we show that the persuasive power of current and\nnear-future AI is likely to stem more from post-training and prompting\nmethods-which boosted persuasiveness by as much as 51% and 27%\nrespectively-than from personalization or increasing model scale. We further\nshow that these methods increased persuasion by exploiting LLMs' unique ability\nto rapidly access and strategically deploy information and that, strikingly,\nwhere they increased AI persuasiveness they also systematically decreased\nfactual accuracy.", "comment": "19 pages, 4 figures. Our supplementary materials file can be found at\n  https://github.com/kobihackenburg/scaling-conversational-AI", "pdf_url": "http://arxiv.org/pdf/2507.13919v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "会话式AI政治说服的杠杆", "tldr": "研究发现，当前AI的说服力主要来自后期训练和提示方法，而非个性化或模型规模，且说服力增强与事实准确性下降相关联。", "motivation": "由于普遍担忧会话式AI可能对人类信仰产生前所未有的影响。", "method": "通过三项大规模实验（N=76,977），部署了19个大型语言模型（LLMs），包括一些专门为说服而后期训练的模型，评估它们在707个政治问题上的说服力。随后，检查了466,769个LLM声明的事实准确性。", "result": "结果显示，当前和未来AI的说服力可能更多源于后期训练和提示方法（分别提升了51%和27%的说服力），而非个性化或增加模型规模。这些方法通过利用LLM快速获取和策略性部署信息的能力来增强说服力，并且令人惊讶的是，它们在增加AI说服力的同时，也系统性地降低了事实准确性。", "conclusion": "当前和未来AI的说服力主要依赖于后期训练和提示方法，这些方法通过战略性信息部署来增强说服力，但代价是事实准确性的降低。", "translation": "人们普遍担忧会话式AI可能很快对人类信仰施加前所未有的影响。在此，我们通过三项大规模实验（N=76,977），部署了19个大型语言模型（LLMs）——包括一些明确为说服而后期训练的模型——来评估它们在707个政治问题上的说服力。然后，我们检查了466,769个LLM声明的事实准确性。与普遍的担忧相反，我们发现当前和未来AI的说服力可能更多源于后期训练和提示方法——这些方法分别将说服力提高了51%和27%——而不是个性化或增加模型规模。我们进一步表明，这些方法通过利用LLMs快速获取和策略性部署信息的独特能力来增强说服力，并且令人惊讶的是，它们在增加AI说服力的同时，也系统性地降低了事实准确性。", "summary": "这项研究通过大规模实验评估了会话式AI在政治说服方面的能力。结果表明，当前和未来AI的说服力主要源于后期训练和提示方法，而非个性化或模型规模。这些方法通过战略性地利用信息来增强说服力，但值得注意的是，说服力的提升与事实准确性的系统性下降同时发生。", "keywords": "会话式AI, 政治说服, 大型语言模型, 事实准确性, 后期训练", "comments": "这项研究通过大规模实验（近7.7万人参与，涉及19个LLM和707个政治问题）提供了关于AI说服力的重要实证数据。其创新之处在于明确指出，AI的说服力主要来自后期训练和提示，而非模型规模或个性化，并揭示了说服力与事实准确性之间的权衡关系，这对于理解AI潜在的社会影响具有重要意义。"}}
{"id": "2507.13659", "title": "When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework", "authors": ["Xiao Wang", "Qian Zhu", "Shujuan Wu", "Bo Jiang", "Shiliang Zhang", "Yaowei Wang", "Yonghong Tian", "Bin Luo"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.NE"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13659v1", "summary": "Recent researchers have proposed using event cameras for person\nre-identification (ReID) due to their promising performance and better balance\nin terms of privacy protection, event camera-based person ReID has attracted\nsignificant attention. Currently, mainstream event-based person ReID algorithms\nprimarily focus on fusing visible light and event stream, as well as preserving\nprivacy. Although significant progress has been made, these methods are\ntypically trained and evaluated on small-scale or simulated event camera\ndatasets, making it difficult to assess their real identification performance\nand generalization ability. To address the issue of data scarcity, this paper\nintroduces a large-scale RGB-event based person ReID dataset, called EvReID.\nThe dataset contains 118,988 image pairs and covers 1200 pedestrian identities,\nwith data collected across multiple seasons, scenes, and lighting conditions.\nWe also evaluate 15 state-of-the-art person ReID algorithms, laying a solid\nfoundation for future research in terms of both data and benchmarking. Based on\nour newly constructed dataset, this paper further proposes a pedestrian\nattribute-guided contrastive learning framework to enhance feature learning for\nperson re-identification, termed TriPro-ReID. This framework not only\neffectively explores the visual features from both RGB frames and event\nstreams, but also fully utilizes pedestrian attributes as mid-level semantic\nfeatures. Extensive experiments on the EvReID dataset and MARS datasets fully\nvalidated the effectiveness of our proposed RGB-Event person ReID framework.\nThe benchmark dataset and source code will be released on\nhttps://github.com/Event-AHU/Neuromorphic_ReID", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13659v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "当行人重识别遇到事件相机：一个基准数据集和属性引导的重识别框架", "tldr": "本文提出了一个大规模的RGB-事件行人重识别数据集EvReID，并提出了一个名为TriPro-ReID的属性引导对比学习框架，以解决现有事件相机行人重识别数据稀缺和性能评估困难的问题。", "motivation": "现有的基于事件相机的行人重识别算法主要侧重于可见光和事件流的融合以及隐私保护，但这些方法通常在小规模或模拟数据集上进行训练和评估，难以评估其真实识别性能和泛化能力。本文旨在解决数据稀缺问题。", "method": "本文提出了一个大规模的RGB-事件行人重识别数据集EvReID，包含118,988对图像和1200个行人身份，数据采集涵盖多季节、场景和光照条件。此外，还评估了15种最先进的行人重识别算法。在此基础上，提出了一种行人属性引导的对比学习框架TriPro-ReID，该框架利用RGB帧和事件流的视觉特征，并充分利用行人属性作为中级语义特征。", "result": "EvReID数据集和MARS数据集上的大量实验充分验证了所提出的RGB-事件行人重识别框架的有效性。", "conclusion": "本文通过引入大规模的EvReID数据集和提出的TriPro-ReID属性引导框架，为事件相机下的行人重识别研究奠定了坚实的基础，并有效提升了该领域的识别性能和泛化能力。", "translation": "最近的研究人员已经提出使用事件相机进行行人重识别（ReID），因为它们具有良好的性能和在隐私保护方面更好的平衡，基于事件相机的行人重识别已引起了广泛关注。目前，主流的基于事件的行人重识别算法主要侧重于可见光和事件流的融合，以及隐私保护。尽管取得了显著进展，但这些方法通常在小规模或模拟事件相机数据集上进行训练和评估，这使得难以评估它们的真实识别性能和泛化能力。为了解决数据稀缺问题，本文引入了一个大规模的RGB-事件行人重识别数据集，名为EvReID。该数据集包含118,988对图像，涵盖1200个行人身份，数据收集跨越多个季节、场景和光照条件。我们还评估了15种最先进的行人重识别算法，为未来的数据和基准研究奠定了坚实的基础。基于我们新构建的数据集，本文进一步提出了一个行人属性引导的对比学习框架来增强行人重识别的特征学习，命名为TriPro-ReID。该框架不仅有效地探索了来自RGB帧和事件流的视觉特征，而且充分利用了行人属性作为中级语义特征。在EvReID数据集和MARS数据集上进行的广泛实验充分验证了我们提出的RGB-事件行人重识别框架的有效性。基准数据集和源代码将在https://github.com/Event-AHU/Neuromorphic_ReID 发布。", "summary": "本文针对现有事件相机行人重识别（ReID）方法面临的数据稀缺和泛化能力评估难题，提出了两大贡献：一是构建了一个大规模的RGB-事件行人重识别数据集EvReID，包含多样的图像对和行人身份，并对现有算法进行了基准测试；二是提出了一个名为TriPro-ReID的行人属性引导对比学习框架，该框架结合RGB和事件流特征，并利用行人属性增强特征学习。实验结果验证了所提框架在EvReID和MARS数据集上的有效性，为该领域的研究提供了新的数据和方法。", "keywords": "行人重识别, 事件相机, 基准数据集, 属性引导, 对比学习", "comments": "本文的主要创新在于解决了事件相机行人重识别领域长期存在的数据稀缺问题，通过构建大规模数据集EvReID为后续研究提供了坚实的基础。同时，提出的TriPro-ReID框架通过引入行人属性作为中级语义特征，有效提升了特征学习能力，为多模态行人重识别提供了一个新颖且有效的方法。其重要性体现在推动了事件相机在计算机视觉领域的实际应用，并为隐私保护下的行人识别提供了新的思路。"}}
{"id": "2507.14102", "title": "UGPL: Uncertainty-Guided Progressive Learning for Evidence-Based Classification in Computed Tomography", "authors": ["Shravan Venkatraman", "Pavan Kumar S", "Rakesh Raj Madavan", "Chandrakala S"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "url": "http://arxiv.org/abs/2507.14102v1", "summary": "Accurate classification of computed tomography (CT) images is essential for\ndiagnosis and treatment planning, but existing methods often struggle with the\nsubtle and spatially diverse nature of pathological features. Current\napproaches typically process images uniformly, limiting their ability to detect\nlocalized abnormalities that require focused analysis. We introduce UGPL, an\nuncertainty-guided progressive learning framework that performs a\nglobal-to-local analysis by first identifying regions of diagnostic ambiguity\nand then conducting detailed examination of these critical areas. Our approach\nemploys evidential deep learning to quantify predictive uncertainty, guiding\nthe extraction of informative patches through a non-maximum suppression\nmechanism that maintains spatial diversity. This progressive refinement\nstrategy, combined with an adaptive fusion mechanism, enables UGPL to integrate\nboth contextual information and fine-grained details. Experiments across three\nCT datasets demonstrate that UGPL consistently outperforms state-of-the-art\nmethods, achieving improvements of 3.29%, 2.46%, and 8.08% in accuracy for\nkidney abnormality, lung cancer, and COVID-19 detection, respectively. Our\nanalysis shows that the uncertainty-guided component provides substantial\nbenefits, with performance dramatically increasing when the full progressive\nlearning pipeline is implemented. Our code is available at:\nhttps://github.com/shravan-18/UGPL", "comment": "18 pages, 10 figures, 5 tables, 2025 ICCV Workshops", "pdf_url": "http://arxiv.org/pdf/2507.14102v1", "cate": "eess.IV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "UGPL：不确定性引导的渐进式学习用于计算机断层扫描中的循证分类", "tldr": "UGPL是一个不确定性引导的渐进式学习框架，通过从全局到局部分析，识别诊断模糊区域并进行详细检查，从而提高CT图像分类的准确性。", "motivation": "现有CT图像分类方法难以处理病理特征的细微性和空间多样性，并且通常统一处理图像，限制了它们检测需要集中分析的局部异常的能力。", "method": "UGPL框架执行全局到局部分析。它首先识别诊断模糊区域，然后对这些关键区域进行详细检查。该方法采用证据深度学习来量化预测不确定性，并通过非最大抑制机制引导信息补丁的提取，以保持空间多样性。这种渐进式细化策略与自适应融合机制相结合，使UGPL能够整合上下文信息和细粒度细节。", "result": "UGPL在三个CT数据集上表现优于现有最新方法，在肾脏异常、肺癌和COVID-19检测方面，准确率分别提高了3.29%、2.46%和8.08%。分析表明，不确定性引导组件提供了实质性益处，当实施完整的渐进式学习流程时，性能显著提高。", "conclusion": "UGPL通过不确定性引导的渐进式学习策略，有效提升了CT图像中基于证据的分类准确性，尤其在处理局部异常和整合多尺度信息方面表现出色。", "translation": "计算机断层扫描（CT）图像的准确分类对于诊断和治疗规划至关重要，但现有方法常常难以处理病理特征的细微性和空间多样性。当前方法通常统一处理图像，限制了它们检测需要集中分析的局部异常的能力。我们引入了UGPL，一个不确定性引导的渐进式学习框架，它通过首先识别诊断模糊区域，然后对这些关键区域进行详细检查，从而执行从全局到局部的分析。我们的方法采用证据深度学习来量化预测不确定性，通过非最大抑制机制引导信息补丁的提取，以保持空间多样性。这种渐进式细化策略，结合自适应融合机制，使UGPL能够整合上下文信息和细粒度细节。在三个CT数据集上的实验表明，UGPL始终优于现有最新方法，在肾脏异常、肺癌和COVID-19检测方面，准确率分别提高了3.29%、2.46%和8.08%。我们的分析表明，不确定性引导组件提供了实质性益处，当实施完整的渐进式学习流程时，性能显著增加。我们的代码可在以下网址获取：https://github.com/shravan-18/UGPL", "summary": "本研究提出了UGPL，一个不确定性引导的渐进式学习框架，旨在提高CT图像的分类准确性。UGPL通过从全局到局部分析，利用证据深度学习量化预测不确定性，并引导信息补丁的提取。该框架结合渐进式细化和自适应融合机制，有效整合了上下文和细粒度信息。实验结果表明，UGPL在多个CT数据集上显著优于现有最新方法，尤其在肾脏异常、肺癌和COVID-19检测中表现出色，验证了其不确定性引导组件和渐进式学习策略的有效性。", "keywords": "CT图像分类, 不确定性引导, 渐进式学习, 证据深度学习, 医疗影像", "comments": "UGPL的创新点在于其不确定性引导的渐进式学习策略，通过从全局到局部分析，聚焦于诊断模糊区域，解决了现有方法在处理病理特征细微性和空间多样性方面的不足。其结合证据深度学习量化不确定性，并通过非最大抑制机制提取信息补丁，提高了分类的准确性和鲁棒性。该方法在实际医疗图像诊断中具有重要应用潜力。"}}
{"id": "2407.10266", "title": "psifx -- Psychological and Social Interactions Feature Extraction Package", "authors": ["Guillaume Rochette", "Mathieu Rochat", "Matthew J. Vowels"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.10266v4", "summary": "psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to\nfacilitate and democratize the use of state-of-the-art machine learning\ntechniques for human sciences research. It is motivated by a need (a) to\nautomate and standardize data annotation processes that typically require\nexpensive, lengthy, and inconsistent human labour; (b) to develop and\ndistribute open-source community-driven psychology research software; and (c)\nto enable large-scale access and ease of use for non-expert users. The\nframework contains an array of tools for tasks such as speaker diarization,\nclosed-caption transcription and translation from audio; body, hand, and facial\npose estimation and gaze tracking with multi-person tracking from video; and\ninteractive textual feature extraction supported by large language models. The\npackage has been designed with a modular and task-oriented approach, enabling\nthe community to add or update new tools easily. This combination creates new\nopportunities for in-depth study of real-time behavioral phenomena in\npsychological and social science research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.10266v4", "cate": "cs.CL", "date": "2024-07-14", "updated": "2025-07-17", "AI": {"title_translation": "psifx -- 心理和社会互动特征提取包", "tldr": "psifx是一个即插即用的多模态特征提取工具包，旨在为人类科学研究自动化数据标注、开发开源软件并方便非专家用户使用。", "motivation": "该研究的动机是：(a) 自动化和标准化通常需要昂贵、耗时且不一致的人工的数据标注过程；(b) 开发和分发开源的、社区驱动的心理学研究软件；(c) 使非专业用户能够大规模访问和易于使用。", "method": "psifx是一个即插即用的多模态特征提取工具包，包含用于以下任务的工具：语音分离、音频的闭路字幕转录和翻译；视频中身体、手部和面部姿态估计以及多人物追踪的凝视跟踪；以及由大型语言模型支持的交互式文本特征提取。该包采用模块化和任务导向的设计方法，方便社区添加或更新新工具。", "result": "Not mentioned in abstract", "conclusion": "这种结合为心理学和社会科学研究中深入研究实时行为现象创造了新的机会。", "translation": "psifx是一个即插即用的多模态特征提取工具包，旨在促进人类科学研究中最新机器学习技术的使用并使其普及化。其动机是：(a) 自动化和标准化通常需要昂贵、耗时且不一致的人工的数据标注过程；(b) 开发和分发开源的、社区驱动的心理学研究软件；(c) 使非专业用户能够大规模访问和易于使用。该框架包含一系列工具，用于执行以下任务：语音分离、音频的闭路字幕转录和翻译；视频中身体、手部和面部姿态估计以及多人物追踪的凝视跟踪；以及由大型语言模型支持的交互式文本特征提取。该包采用模块化和任务导向的设计方法，方便社区轻松添加或更新新工具。这种结合为心理学和社会科学研究中深入研究实时行为现象创造了新的机会。", "summary": "psifx是一个多模态特征提取工具包，旨在通过自动化数据标注、提供开源软件和简化非专家使用来促进人类科学研究。它整合了语音、视频和文本分析工具，并采用模块化设计，为心理学和社会科学的实时行为研究提供了新机遇。", "keywords": "特征提取, 多模态, 人类科学, 开源, 心理学研究", "comments": "psifx的创新之处在于其“即插即用”和多模态特征提取能力，以及对自动化、开源和易用性的强调，这对于民主化人类科学研究中的先进机器学习技术至关重要。其模块化设计也促进了社区贡献和工具扩展。"}}
{"id": "2507.13374", "title": "Smart Routing for Multimodal Video Retrieval: When to Search What", "authors": ["Kevin Dela Rosa"], "categories": ["cs.CV", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV 2025 Multimodal Representation and Retrieval Workshop", "url": "http://arxiv.org/abs/2507.13374v1", "summary": "We introduce ModaRoute, an LLM-based intelligent routing system that\ndynamically selects optimal modalities for multimodal video retrieval. While\ndense text captions can achieve 75.9% Recall@5, they require expensive offline\nprocessing and miss critical visual information present in 34% of clips with\nscene text not captured by ASR. By analyzing query intent and predicting\ninformation needs, ModaRoute reduces computational overhead by 41% while\nachieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR\n(speech), OCR (text), and visual indices, averaging 1.78 modalities per query\nversus exhaustive 3.0 modality search. Evaluation on 1.8M video clips\ndemonstrates that intelligent routing provides a practical solution for scaling\nmultimodal retrieval systems, reducing infrastructure costs while maintaining\ncompetitive effectiveness for real-world deployment.", "comment": "Accepted to ICCV 2025 Multimodal Representation and Retrieval\n  Workshop", "pdf_url": "http://arxiv.org/pdf/2507.13374v1", "cate": "cs.CV", "date": "2025-07-12", "updated": "2025-07-12", "AI": {"title_translation": "多模态视频检索的智能路由：何时搜索什么", "tldr": "ModaRoute是一个基于LLM的智能路由系统，它能动态选择最佳模态进行多模态视频检索，显著降低计算开销并保持竞争力。", "motivation": "现有的密集文本字幕方法虽然能达到75.9%的Recall@5，但需要昂贵的离线处理，并且会遗漏关键的视觉信息，例如34%的视频片段中包含ASR未捕获的场景文本。", "method": "本文提出了ModaRoute，一个基于LLM的智能路由系统，通过分析查询意图和预测信息需求，动态选择多模态视频检索的最佳模态。它使用GPT-4.1将查询路由到ASR（语音）、OCR（文本）和视觉索引，平均每个查询使用1.78种模态，而非穷举式的3.0种模态搜索。", "result": "ModaRoute在实现60.9%的Recall@5的同时，将计算开销降低了41%。在180万个视频片段上的评估表明，该系统能有效降低基础设施成本，并为多模态检索系统的扩展提供了实用的解决方案。", "conclusion": "智能路由为扩展多模态检索系统提供了一个实用的解决方案，在保持竞争性有效性的同时，显著降低了基础设施成本，适用于实际部署。", "translation": "我们引入了ModaRoute，一个基于LLM的智能路由系统，它能动态选择多模态视频检索的最佳模态。虽然密集文本字幕可以达到75.9%的Recall@5，但它们需要昂贵的离线处理，并且会遗漏34%的视频片段中存在的ASR未捕获的关键视觉信息（场景文本）。通过分析查询意图和预测信息需求，ModaRoute在实现60.9%的Recall@5的同时，将计算开销降低了41%。我们的方法使用GPT-4.1将查询路由到ASR（语音）、OCR（文本）和视觉索引，平均每个查询使用1.78种模态，而穷举式搜索则使用3.0种模态。在180万个视频片段上的评估表明，智能路由为扩展多模态检索系统提供了实用的解决方案，在保持竞争性有效性的同时，降低了基础设施成本，适用于实际部署。", "summary": "本文提出了ModaRoute，一个创新的基于LLM的智能路由系统，旨在优化多模态视频检索。该系统通过分析查询意图和预测信息需求，动态选择最相关的模态（ASR、OCR、视觉），从而显著降低了计算开销（41%），同时保持了可接受的检索效果（60.9% Recall@5）。ModaRoute有效解决了传统方法成本高昂和信息遗漏的问题，为大规模多模态检索系统的实际部署提供了高效且经济的解决方案。", "keywords": "多模态视频检索, 智能路由, LLM, 模态选择, 成本效益", "comments": "ModaRoute的创新点在于其利用LLM进行智能模态路由，而非传统的穷举式搜索。这不仅显著提升了计算效率，降低了基础设施成本，也有效整合了多源信息，弥补了单一模态的不足。其在实际部署中的潜力和对大规模视频检索系统的成本效益贡献是其重要性所在。"}}
{"id": "2507.13920", "title": "Reframing attention as a reinforcement learning problem for causal discovery", "authors": ["Turan Orujlu", "Christian Gumbsch", "Martin V. Butz", "Charley M Wu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13920v1", "summary": "Formal frameworks of causality have operated largely parallel to modern\ntrends in deep reinforcement learning (RL). However, there has been a revival\nof interest in formally grounding the representations learned by neural\nnetworks in causal concepts. Yet, most attempts at neural models of causality\nassume static causal graphs and ignore the dynamic nature of causal\ninteractions. In this work, we introduce Causal Process framework as a novel\ntheory for representing dynamic hypotheses about causal structure. Furthermore,\nwe present Causal Process Model as an implementation of this framework. This\nallows us to reformulate the attention mechanism popularized by Transformer\nnetworks within an RL setting with the goal to infer interpretable causal\nprocesses from visual observations. Here, causal inference corresponds to\nconstructing a causal graph hypothesis which itself becomes an RL task nested\nwithin the original RL problem. To create an instance of such hypothesis, we\nemploy RL agents. These agents establish links between units similar to the\noriginal Transformer attention mechanism. We demonstrate the effectiveness of\nour approach in an RL environment where we outperform current alternatives in\ncausal representation learning and agent performance, and uniquely recover\ngraphs of dynamic causal processes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13920v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "将注意力机制重构为强化学习问题以进行因果发现", "tldr": "本文提出因果过程框架和模型，通过将Transformer注意力机制重构为嵌套强化学习问题，从视觉观察中推断动态因果过程，性能优于现有方法。", "motivation": "当前神经因果模型假设因果图是静态的，并忽略了因果交互的动态性质；需要将神经网络学习到的表征与因果概念相结合。", "method": "引入因果过程框架和因果过程模型。将Transformer注意力机制在强化学习环境中重构，其中因果推断（构建动态因果图假设）是一个嵌套在原始强化学习问题中的强化学习任务，并使用强化学习代理来建立单元之间的链接。", "result": "在因果表征学习和代理性能方面优于现有替代方法，并且能够独特地恢复动态因果过程图。", "conclusion": "本文成功地将注意力机制与强化学习相结合，实现了动态因果过程的发现，解决了静态因果模型存在的局限性。", "translation": "形式化的因果关系框架在很大程度上与深度强化学习（RL）的现代趋势并行发展。然而，将神经网络学习到的表征在因果概念上进行形式化基础研究的兴趣重新兴起。然而，大多数神经因果模型都假设静态因果图，并忽略了因果交互的动态性质。在这项工作中，我们引入了因果过程框架作为一种表示因果结构动态假设的新理论。此外，我们提出了因果过程模型作为该框架的实现。这使我们能够将Transformer网络中流行的注意力机制在RL环境中重新构建，目标是从视觉观察中推断出可解释的因果过程。在这里，因果推断对应于构建一个因果图假设，该假设本身成为原始RL问题中嵌套的RL任务。为了创建这种假设的实例，我们使用了RL代理。这些代理在单元之间建立链接，类似于原始的Transformer注意力机制。我们在一个RL环境中展示了我们方法的有效性，在该环境中，我们在因果表征学习和代理性能方面优于当前的替代方法，并独特地恢复了动态因果过程图。", "summary": "本文提出了因果过程框架及其实现——因果过程模型，旨在解决神经因果模型中静态因果图的局限性。它创新性地在嵌套强化学习环境中重新解释了Transformer的注意力机制，目标是从视觉观察中推断出动态且可解释的因果过程。核心思想是将因果推断（构建动态因果图假设）视为一个强化学习任务。该方法在因果表征学习和代理性能方面表现出卓越的性能，并能独特地恢复动态因果过程图。", "keywords": "因果发现, 强化学习, 注意力机制, 动态因果关系, 因果表征学习", "comments": "这篇论文通过将因果发现与深度强化学习相结合，特别是通过重构注意力机制，提供了一个新颖的视角。其优势在于解决了因果交互的动态性质，这与传统的静态因果模型有显著不同。用于图假设构建的嵌套强化学习方法具有创新性。这对于开发能够推理复杂、演化因果关系的更鲁棒和可解释的AI系统可能很重要。"}}
{"id": "2507.13572", "title": "Temporal Adaptation of Pre-trained Foundation Models for Music Structure Analysis", "authors": ["Yixiao Zhang", "Haonan Chen", "Ju-Chiang Wang", "Jitong Chen"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025. Project Page: this https URL", "url": "http://arxiv.org/abs/2507.13572v1", "summary": "Audio-based music structure analysis (MSA) is an essential task in Music\nInformation Retrieval that remains challenging due to the complexity and\nvariability of musical form. Recent advances highlight the potential of\nfine-tuning pre-trained music foundation models for MSA tasks. However, these\nmodels are typically trained with high temporal feature resolution and short\naudio windows, which limits their efficiency and introduces bias when applied\nto long-form audio. This paper presents a temporal adaptation approach for\nfine-tuning music foundation models tailored to MSA. Our method enables\nefficient analysis of full-length songs in a single forward pass by\nincorporating two key strategies: (1) audio window extension and (2)\nlow-resolution adaptation. Experiments on the Harmonix Set and RWC-Pop datasets\nshow that our method significantly improves both boundary detection and\nstructural function prediction, while maintaining comparable memory usage and\ninference speed.", "comment": "Accepted to WASPAA 2025. Project Page:\n  https://sites.google.com/view/temporal-adaptation-for-msa/", "pdf_url": "http://arxiv.org/pdf/2507.13572v1", "cate": "cs.SD", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "预训练基础模型在音乐结构分析中的时间适应", "tldr": "本文提出了一种时间适应方法，用于微调预训练的音乐基础模型，以高效地分析长篇音乐的结构，通过扩展音频窗口和低分辨率适应，显著提高了边界检测和结构功能预测的性能。", "motivation": "音频音乐结构分析（MSA）是一项重要但具有挑战性的任务，因为音乐形式复杂多变。虽然微调预训练的音乐基础模型显示出潜力，但这些模型通常在长篇音频应用时，由于高时间特征分辨率和短音频窗口，效率受限并引入偏差。", "method": "本文提出了一种针对音乐结构分析的时间适应方法来微调音乐基础模型。该方法通过整合两种关键策略：1）音频窗口扩展和2）低分辨率适应，使得模型能够在一个前向传播中高效分析完整长度的歌曲。", "result": "在Harmonix Set和RWC-Pop数据集上的实验表明，我们的方法显著提高了边界检测和结构功能预测的性能，同时保持了相当的内存使用量和推理速度。", "conclusion": "本文提出的时间适应方法有效解决了预训练音乐基础模型在长篇音乐结构分析中的效率和偏差问题，显著提升了分析性能。", "translation": "基于音频的音乐结构分析（MSA）是音乐信息检索中的一项基本任务，由于音乐形式的复杂性和可变性，该任务仍然充满挑战。最近的进展强调了微调预训练音乐基础模型在MSA任务中的潜力。然而，这些模型通常以高时间特征分辨率和短音频窗口进行训练，这限制了它们在应用于长篇音频时的效率并引入了偏差。本文提出了一种用于微调音乐基础模型的时序适应方法，专为MSA量身定制。我们的方法通过结合两种关键策略：(1) 音频窗口扩展和 (2) 低分辨率适应，实现了在单次前向传播中对完整歌曲进行高效分析。在Harmonix Set和RWC-Pop数据集上的实验表明，我们的方法显著改善了边界检测和结构功能预测，同时保持了相当的内存使用量和推理速度。", "summary": "本研究提出了一种针对音乐结构分析（MSA）的时间适应方法，用于微调预训练的音乐基础模型。针对现有模型在处理长篇音频时效率低和偏差大的问题，该方法通过音频窗口扩展和低分辨率适应策略，实现了对完整歌曲的单次高效分析。实验证明，该方法在边界检测和结构功能预测方面均取得了显著提升，且内存占用和推理速度保持良好。", "keywords": "音乐结构分析, 预训练模型, 时间适应, 音频窗口扩展, 低分辨率适应", "comments": "本文创新性地提出了时间适应方法，通过结合音频窗口扩展和低分辨率适应，有效解决了预训练模型在长篇音乐结构分析中的效率和偏差问题。这项工作对于推动音乐信息检索领域中更高效、准确的音乐结构分析具有重要意义。"}}
{"id": "2501.14120", "title": "On the Transfer of Knowledge in Quantum Algorithms", "authors": ["Esther Villar-Rodriguez", "Eneko Osaba", "Izaskun Oregi", "Sebastián V. Romero", "Julián Ferreiro-Vélez"], "categories": ["quant-ph", "cs.AI"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 8 figures, 4 tables. Paper submitted for its review in Expert Systems journal", "url": "http://arxiv.org/abs/2501.14120v2", "summary": "Quantum computing is poised to transform computational paradigms across\nscience and industry. As the field evolves, it can benefit from established\nclassical methodologies, including promising paradigms such as Transfer of\nKnowledge (ToK). This work serves as a brief, self-contained reference for ToK,\nunifying its core principles under a single formal framework. We introduce a\njoint notation that consolidates and extends prior work in Transfer Learning\nand Transfer Optimization, bridging traditionally separate research lines and\nenabling a common language for knowledge reuse. Building on this foundation, we\nclassify existing ToK strategies and principles into a structured taxonomy that\nhelps researchers position their methods within a broader conceptual map. We\nthen extend key transfer protocols to quantum computing, introducing two novel\nuse cases (reverse annealing and multitasking QAOA) alongside a sequential VQE\napproach that supports and validates prior findings. These examples highlight\nToK's potential to improve performance and generalization in quantum\nalgorithms. Finally, we outline challenges and opportunities for integrating\nToK into quantum computing, emphasizing its role in reducing resource demands\nand accelerating problem-solving. This work lays the groundwork for future\nsynergies between classical and quantum computing through a shared,\ntransferable knowledge framework.", "comment": "14 pages, 8 figures, 4 tables. Paper submitted for its review in\n  Expert Systems journal", "pdf_url": "http://arxiv.org/pdf/2501.14120v2", "cate": "quant-ph", "date": "2025-01-23", "updated": "2025-07-18", "AI": {"title_translation": "量子算法中的知识迁移", "tldr": "本文为一个简短的、自包含的知识迁移（ToK）参考资料，统一了其核心原则，并将其应用于量子计算，引入了新的用例并概述了挑战和机遇，旨在通过共享的知识框架促进经典与量子计算的协同。", "motivation": "量子计算有望改变科学和工业领域的计算范式。随着该领域的发展，它可以从已建立的经典方法中受益，包括知识迁移（ToK）等有前景的范式。", "method": "本文将知识迁移（ToK）的核心原则统一在一个单一的正式框架下，引入了一个整合并扩展了迁移学习和迁移优化先前工作的联合表示法。在此基础上，将现有的ToK策略和原则分类为一个结构化的分类法。然后，将关键的迁移协议扩展到量子计算，引入了两个新颖的用例（逆向退火和多任务QAOA）以及一个支持并验证先前发现的顺序VQE方法。", "result": "论文引入了两个新颖的用例（逆向退火和多任务QAOA）以及一个顺序VQE方法，这些例子突出了ToK在改善量子算法性能和泛化能力方面的潜力，并支持和验证了先前的发现。", "conclusion": "本文为经典计算和量子计算之间通过共享的可迁移知识框架实现未来协同奠定了基础，并强调了ToK在减少资源需求和加速问题解决方面的作用。", "translation": "量子计算有望改变科学和工业领域的计算范式。随着该领域的发展，它可以从已建立的经典方法中受益，包括知识迁移（ToK）等有前景的范式。这项工作是关于ToK的简短、自包含的参考资料，将ToK的核心原则统一在一个单一的正式框架下。我们引入了一种联合表示法，整合并扩展了迁移学习和迁移优化方面的先前工作，弥合了传统上分离的研究路线，并为知识重用提供了通用语言。在此基础上，我们将现有的ToK策略和原则分类为一个结构化的分类法，帮助研究人员将他们的方法定位在更广阔的概念图中。然后，我们将关键的迁移协议扩展到量子计算，引入了两个新颖的用例（逆向退火和多任务QAOA）以及一个支持并验证先前发现的顺序VQE方法。这些例子突出了ToK在改善量子算法性能和泛化能力方面的潜力。最后，我们概述了将ToK整合到量子计算中的挑战和机遇，强调了其在减少资源需求和加速问题解决方面的作用。这项工作为未来通过共享的、可迁移的知识框架实现经典计算和量子计算之间的协同奠定了基础。", "summary": "本研究旨在将经典计算中的知识迁移（ToK）范式引入量子计算领域。论文首先统一了ToK的核心原则，并提出了一个整合迁移学习和迁移优化的新表示法。在此基础上，构建了一个ToK策略的分类法。随后，将ToK协议应用于量子计算，并展示了逆向退火、多任务QAOA和顺序VQE等新用例，证明了ToK在提升量子算法性能和泛化能力方面的潜力。最后，探讨了ToK在量子计算中面临的挑战与机遇，强调其在优化资源和加速问题解决中的重要性，为经典与量子计算的协同发展奠定了基础。", "keywords": "知识迁移, 量子算法, 迁移学习, 迁移优化, 量子计算", "comments": "本文创新性地将经典计算中的知识迁移（ToK）概念引入到新兴的量子计算领域，并为此建立了一个统一的理论框架和分类法。其重要性在于为量子算法的性能提升和泛化能力增强提供了新的思路，特别是在资源受限的量子计算环境中，ToK有望显著降低资源需求并加速问题解决，为量子-经典混合计算的未来协同发展铺平了道路。"}}
{"id": "2507.12674", "title": "ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle", "authors": ["Mihran Miroyan", "Rose Niousha", "Joseph E. Gonzalez", "Gireeja Ranade", "Narges Norouzi"], "categories": ["cs.CY", "cs.AI", "cs.SE"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12674v2", "summary": "Large Language Models (LLMs) have shown strong performance on programming\ntasks, but can they generate student-like code like real students - imperfect,\niterative, and stylistically diverse? We present ParaStudent, a systematic\nstudy of LLM-based \"student-like\" code generation in an introductory\nprogramming course setting. Using a dataset of timestamped student submissions\nacross multiple semesters, we design low- and high-resolution experiments to\nmodel student progress and evaluate code outputs along semantic, functional,\nand stylistic dimensions. Our results show that fine-tuning significantly\nimproves alignment with real student trajectories and captures error patterns,\nincremental improvements, and stylistic variations more faithfully. This study\nshows that modeling realistic student code requires capturing learning dynamics\nthrough context-aware generation, temporal modeling, and multi-dimensional\nevaluation. Code for experiments and evaluation is available at\nhttps://github.com/mmiroyan/ParaStudent.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12674v2", "cate": "cs.CY", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "ParaStudent：通过让大型语言模型“挣扎”来生成和评估逼真的学生代码", "tldr": "ParaStudent研究了LLM生成学生代码的能力，发现通过微调能更好地模拟学生学习过程中的错误模式、渐进改进和风格多样性。", "motivation": "大型语言模型在编程任务上表现出色，但作者想探究它们是否能生成像真实学生一样的不完美、迭代且风格多样的代码。", "method": "提出了ParaStudent，一个系统性研究LLM生成“学生式”代码的框架。利用跨多个学期的带时间戳的学生提交数据集，设计了低分辨率和高分辨率实验来模拟学生进展，并从语义、功能和风格维度评估代码输出。", "result": "结果显示，微调显著改善了LLM与真实学生轨迹的对齐，并更忠实地捕捉了错误模式、渐进改进和风格变化。", "conclusion": "研究表明，建模逼真的学生代码需要通过上下文感知生成、时间建模和多维评估来捕捉学习动态。", "translation": "大型语言模型（LLMs）在编程任务上表现出强大的性能，但它们能否像真实学生一样生成学生式的代码——不完美、迭代且风格多样？我们提出了ParaStudent，一项在入门编程课程设置中对基于LLM的“学生式”代码生成进行的系统性研究。我们使用了一个包含多个学期带时间戳的学生提交数据的数据集，设计了低分辨率和高分辨率实验来模拟学生进度，并从语义、功能和风格维度评估代码输出。我们的结果表明，微调显著改善了与真实学生轨迹的对齐，并更忠实地捕捉了错误模式、渐进改进和风格变化。这项研究表明，建模逼真的学生代码需要通过上下文感知生成、时间建模和多维评估来捕捉学习动态。实验和评估的代码可在https://github.com/mmiroyan/ParaStudent获取。", "summary": "本研究介绍了ParaStudent，旨在探究大型语言模型生成逼真学生代码的能力。通过使用真实学生的提交数据进行低分辨率和高分辨率实验，并从语义、功能和风格维度进行评估，研究发现对LLM进行微调能够显著提高其模拟学生学习过程中出现的错误、渐进改进和风格多样性的准确性。这表明，要生成真实的“学生式”代码，需要考虑学习动态、时间建模和多维评估。", "keywords": "学生代码生成,大型语言模型,代码评估,学习动态,ParaStudent", "comments": "这项研究的创新之处在于其系统性地探讨了LLM生成“学生式”代码的可能性，并强调了捕捉学习动态和多维评估的重要性，这对于开发更具教育意义的AI辅助编程工具具有重要价值。"}}
{"id": "2507.13599", "title": "Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model", "authors": ["Chengxu Liu", "Lu Qi", "Jinshan Pan", "Xueming Qian", "Ming-Hsuan Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2507.13599v1", "summary": "Since acquiring large amounts of realistic blurry-sharp image pairs is\ndifficult and expensive, learning blind image deblurring from unpaired data is\na more practical and promising solution. Unfortunately, dominant approaches\nrely heavily on adversarial learning to bridge the gap from blurry domains to\nsharp domains, ignoring the complex and unpredictable nature of real-world blur\npatterns. In this paper, we propose a novel diffusion model (DM)-based\nframework, dubbed \\ours, for image deblurring by learning spatially varying\ntexture prior from unpaired data. In particular, \\ours performs DM to generate\nthe prior knowledge that aids in recovering the textures of blurry images. To\nimplement this, we propose a Texture Prior Encoder (TPE) that introduces a\nmemory mechanism to represent the image textures and provides supervision for\nDM training. To fully exploit the generated texture priors, we present the\nTexture Transfer Transformer layer (TTformer), in which a novel\nFilter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes\nspatially varying blurring through adaptive filtering. Furthermore, we\nimplement a wavelet-based adversarial loss to preserve high-frequency texture\ndetails. Extensive evaluations show that \\ours provides a promising\nunsupervised deblurring solution and outperforms SOTA methods in widely-used\nbenchmarks.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2507.13599v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于扩散模型从无配对数据中学习去模糊纹理先验", "tldr": "本文提出了一种名为 \\ours 的新型扩散模型 (DM) 框架，用于从无配对数据中学习空间变化的纹理先验，从而实现图像去模糊。该方法通过纹理先验编码器 (TPE) 和纹理传输Transformer层 (TTformer) 处理模糊，并在常用基准测试中优于SOTA方法。", "motivation": "获取大量真实的模糊-清晰图像对既困难又昂贵，因此从无配对数据中学习盲图像去模糊是一种更实用和有前景的解决方案。现有主流方法过度依赖对抗学习来弥合模糊域到清晰域的差距，却忽略了真实世界中模糊模式的复杂性和不可预测性。", "method": "本文提出了一种名为 \\ours 的新型扩散模型 (DM) 框架，通过从无配对数据中学习空间变化的纹理先验来实现图像去模糊。\\ours 利用DM生成先验知识，以帮助恢复模糊图像的纹理。为此，引入了一个纹理先验编码器 (TPE)，它包含一个记忆机制来表示图像纹理并为DM训练提供监督。为了充分利用生成的纹理先验，提出了纹理传输Transformer层 (TTformer)，其中新颖的滤波器调制多头自注意力 (FM-MSA) 通过自适应滤波有效地去除空间变化的模糊。此外，还实现了基于小波的对抗损失，以保留高频纹理细节。", "result": "广泛的评估表明，\\ours 提供了一种有前景的无监督去模糊解决方案，并在广泛使用的基准测试中优于SOTA方法。", "conclusion": "\\ours 框架为图像去模糊提供了一种有前景且有效的无监督解决方案，并在性能上超越了现有的最先进方法。", "translation": "由于获取大量真实的模糊-清晰图像对既困难又昂贵，因此从无配对数据中学习盲图像去模糊是一种更实用和有前景的解决方案。不幸的是，主流方法过度依赖对抗学习来弥合模糊域到清晰域的差距，却忽略了真实世界中模糊模式的复杂性和不可预测性。在本文中，我们提出了一种新颖的基于扩散模型 (DM) 的框架，名为 \\ours，通过从无配对数据中学习空间变化的纹理先验来实现图像去模糊。具体而言，\\ours 利用DM生成有助于恢复模糊图像纹理的先验知识。为了实现这一点，我们提出了一个纹理先验编码器 (TPE)，它引入了一个记忆机制来表示图像纹理并为DM训练提供监督。为了充分利用生成的纹理先验，我们提出了纹理传输Transformer层 (TTformer)，其中新颖的滤波器调制多头自注意力 (FM-MSA) 通过自适应滤波有效地去除空间变化的模糊。此外，我们还实现了基于小波的对抗损失，以保留高频纹理细节。广泛的评估表明，\\ours 提供了一种有前景的无监督去模糊解决方案，并在广泛使用的基准测试中优于SOTA方法。", "summary": "本文提出了一种名为 \\ours 的新型扩散模型 (DM) 框架，用于从无配对数据中进行盲图像去模糊。针对配对数据获取困难和现有对抗方法忽略复杂模糊模式的问题，\\ours 通过学习空间变化的纹理先验来恢复图像纹理。该框架包含一个纹理先验编码器 (TPE) 用于DM监督，以及一个纹理传输Transformer层 (TTformer) 内含滤波器调制多头自注意力 (FM-MSA)，用于自适应去除空间变化的模糊。此外，还采用小波对抗损失以保留高频细节。实验证明，\\ours 提供了有前景的无监督去模糊方案，并在主流基准测试中超越了现有最先进方法。", "keywords": "图像去模糊, 扩散模型, 无配对学习, 纹理先验, 空间变化模糊", "comments": "该论文的创新之处在于利用扩散模型从无配对数据中学习纹理先验，这在获取配对数据集困难的情况下是一种非常实用的方法。TPE和TTformer（结合FM-MSA）的引入，专门解决了空间变化模糊和纹理恢复的挑战。其无监督的性质和超越SOTA的性能，使其成为图像去模糊领域的重要贡献。"}}
{"id": "2507.13934", "title": "DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization", "authors": ["Marzieh Gheisari", "Auguste Genovesio"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13934v1", "summary": "Unsupervised disentanglement of static appearance and dynamic motion in video\nremains a fundamental challenge, often hindered by information leakage and\nblurry reconstructions in existing VAE- and GAN-based approaches. We introduce\nDiViD, the first end-to-end video diffusion framework for explicit\nstatic-dynamic factorization. DiViD's sequence encoder extracts a global static\ntoken from the first frame and per-frame dynamic tokens, explicitly removing\nstatic content from the motion code. Its conditional DDPM decoder incorporates\nthree key inductive biases: a shared-noise schedule for temporal consistency, a\ntime-varying KL-based bottleneck that tightens at early timesteps (compressing\nstatic information) and relaxes later (enriching dynamics), and cross-attention\nthat routes the global static token to all frames while keeping dynamic tokens\nframe-specific. An orthogonality regularizer further prevents residual\nstatic-dynamic leakage. We evaluate DiViD on real-world benchmarks using\nswap-based accuracy and cross-leakage metrics. DiViD outperforms\nstate-of-the-art sequential disentanglement methods: it achieves the highest\nswap-based joint accuracy, preserves static fidelity while improving dynamic\ntransfer, and reduces average cross-leakage.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13934v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DiViD：用于静态-动态分解的解耦视频扩散模型", "tldr": "DiViD是一种新的端到端视频扩散框架，用于解决视频中静态外观和动态运动的无监督解耦问题，通过独特的编码器、解码器和正交正则化器实现，并优于现有方法。", "motivation": "现有基于VAE和GAN的方法在视频中静态外观和动态运动的无监督解耦方面存在信息泄露和模糊重建的问题，这仍然是一个基本挑战。", "method": "本文引入了DiViD，第一个用于显式静态-动态分解的端到端视频扩散框架。DiViD的序列编码器从第一帧中提取全局静态令牌，并从每帧中提取动态令牌，显式地从运动代码中移除静态内容。其条件DDPM解码器包含三个关键归纳偏置：用于时间一致性的共享噪声调度、在早期时间步收紧（压缩静态信息）并在后期放松（丰富动态）的时变基于KL的瓶颈，以及将全局静态令牌路由到所有帧同时保持动态令牌帧特异性的交叉注意力。一个正交正则化器进一步防止了残余的静态-动态泄露。", "result": "DiViD在真实世界基准上使用基于交换的准确性和交叉泄露度量进行评估，其性能优于最先进的序列解耦方法：它实现了最高的基于交换的联合准确性，在提高动态传输的同时保持了静态保真度，并减少了平均交叉泄露。", "conclusion": "DiViD成功地解决了视频中静态外观和动态运动的无监督解耦问题，通过其创新的框架设计在性能上超越了现有技术，提供了更清晰、更准确的视频分解。", "translation": "视频中静态外观和动态运动的无监督解耦仍然是一个基本挑战，现有基于VAE和GAN的方法常因信息泄露和模糊重建而受阻。我们引入了DiViD，这是第一个用于显式静态-动态分解的端到端视频扩散框架。DiViD的序列编码器从第一帧中提取全局静态令牌，并提取每帧的动态令牌，显式地从运动代码中移除静态内容。其条件DDPM解码器包含三个关键归纳偏置：用于时间一致性的共享噪声调度，一个在早期时间步收紧（压缩静态信息）并在后期放松（丰富动态）的时变基于KL的瓶颈，以及将全局静态令牌路由到所有帧同时保持动态令牌帧特异性的交叉注意力。一个正交正则化器进一步防止了残余的静态-动态泄露。我们在真实世界基准上使用基于交换的准确性和交叉泄露度量评估了DiViD。DiViD优于最先进的序列解耦方法：它实现了最高的基于交换的联合准确性，在提高动态传输的同时保持了静态保真度，并减少了平均交叉泄露。", "summary": "DiViD是一个创新的端到端视频扩散框架，旨在解决视频中静态外观和动态运动的无监督解耦难题。它通过独特的序列编码器提取全局静态和帧级动态令牌，并利用带有共享噪声调度、时变KL瓶颈和交叉注意力的条件DDPM解码器，有效防止信息泄露并提升重建质量。此外，正交正则化器进一步确保静态与动态内容的严格分离。实验结果表明，DiViD在多项指标上超越了现有最先进的解耦方法，显著提高了静态保真度和动态传输效果，并降低了交叉泄露。", "keywords": "视频解耦,扩散模型,静态-动态分解,无监督学习,DiViD", "comments": "DiViD的创新之处在于它是首个将扩散模型应用于视频静态-动态解耦的端到端框架，其独特的编码器-解码器设计，特别是时变KL瓶颈和正交正则化器，有效解决了传统方法中信息泄露和重建模糊的问题。这对于视频内容理解和生成具有重要意义。"}}
{"id": "2507.14093", "title": "Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment", "authors": ["Šimon Kubov", "Simon Klíčník", "Jakub Dandár", "Zdeněk Straka", "Karolína Kvaková", "Daniel Kvak"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14093v1", "summary": "Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment\ndecisions depend on precise Cobb angle measurement. Manual assessment is time\nconsuming and subject to inter observer variation. We conducted a\nretrospective, multi centre evaluation of a fully automated deep learning\nsoftware (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on\n103 standing anteroposterior whole spine radiographs collected from ten\nhospitals. Two musculoskeletal radiologists independently measured each study\nand served as reference readers. Agreement between the AI and each radiologist\nwas assessed with Bland Altman analysis, mean absolute error (MAE), root mean\nsquared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four\ngrade severity classification. Against Radiologist 1 the AI achieved an MAE of\n3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of\nagreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI\nachieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees\nand limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r\nequals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen\nkappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).\nThese results demonstrate that the proposed software reproduces expert level\nCobb angle measurements and categorical grading across multiple centres,\nsuggesting its utility for streamlining scoliosis reporting and triage in\nclinical workflows.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14093v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "脊柱侧弯评估深度学习模型的多中心验证", "tldr": "一项多中心研究验证了深度学习模型在脊柱侧弯Cobb角测量上达到专家水平的准确性，有望简化临床工作流程。", "motivation": "脊柱侧弯影响约2-4%的青少年，治疗决策依赖于精确的Cobb角测量。然而，人工测量耗时且存在观察者间差异。", "method": "研究对一个全自动深度学习软件（Carebot AI Bones）进行了回顾性、多中心评估。数据来自10家医院的103张站立位脊柱正位X光片。两名肌肉骨骼放射科医生独立测量作为参考。通过Bland Altman分析、平均绝对误差（MAE）、均方根误差（RMSE）、皮尔逊相关系数和Cohen kappa系数评估AI与放射科医生之间以及放射科医生之间的Cobb角测量和四级严重程度分类的一致性。", "result": "与放射科医生1相比，AI的MAE为3.89度（RMSE 4.77度），偏差为0.70度，一致性限度为-8.59至+9.99度。与放射科医生2相比，AI的MAE为3.90度（RMSE 5.68度），偏差为2.14度，一致性限度为-8.23至+12.50度。AI与放射科医生的皮尔逊相关系数分别为r=0.906和r=0.880（放射科医生间r=0.928）。严重程度分级的Cohen kappa系数分别为0.51和0.64（放射科医生间kappa 0.59）。", "conclusion": "研究结果表明，所提出的深度学习软件在多个中心能够重现专家水平的Cobb角测量和分类分级，这表明其在临床工作流程中简化脊柱侧弯报告和分诊的实用性。", "translation": "脊柱侧弯影响约2%至4%的青少年，治疗决策取决于精确的Cobb角测量。人工评估耗时且存在观察者间差异。我们对一个全自动深度学习软件（Carebot AI Bones，脊柱测量功能；Carebot s.r.o.）进行了回顾性、多中心评估，数据来自十家医院收集的103张站立位脊柱正位X光片。两名肌肉骨骼放射科医生独立测量每项研究并作为参考判读员。通过Bland Altman分析、平均绝对误差（MAE）、均方根误差（RMSE）、皮尔逊相关系数和四级严重程度分类的Cohen kappa系数评估AI与每位放射科医生之间的一致性。与放射科医生1相比，AI的MAE为3.89度（RMSE 4.77度），偏差为0.70度，一致性限度为负8.59至正9.99度。与放射科医生2相比，AI的MAE为3.90度（RMSE 5.68度），偏差为2.14度，一致性限度为负8.23至正12.50度。皮尔逊相关系数分别为r=0.906和r=0.880（判读员之间r=0.928），而严重程度分级的Cohen kappa系数达到0.51和0.64（判读员之间kappa 0.59）。这些结果表明，所提出的软件在多个中心能够重现专家水平的Cobb角测量和分类分级，这表明其在临床工作流程中简化脊柱侧弯报告和分诊的实用性。", "summary": "本研究对一个全自动深度学习软件在脊柱侧弯Cobb角测量中的应用进行了多中心验证。通过对103张脊柱X光片进行评估，并将AI结果与两名放射科医生的测量结果进行比较，发现该AI模型在Cobb角测量和严重程度分级上均能达到与专家水平相当的准确性和一致性。具体评估指标包括MAE、RMSE、皮尔逊相关系数和Cohen kappa系数均表现良好。研究结果表明，该深度学习软件有望在临床实践中提高脊柱侧弯评估的效率和标准化。", "keywords": "脊柱侧弯, 深度学习, Cobb角, 多中心验证, 自动化评估", "comments": "这项研究的创新之处在于对深度学习模型在脊柱侧弯评估中的应用进行了多中心验证，这增强了其在实际临床环境中部署的可靠性。其重要性在于，通过自动化Cobb角测量，该模型有望显著减少人工评估的时间消耗和观察者间差异，从而提高诊断效率和一致性，对脊柱侧弯的筛查、报告和分诊具有重要的临床价值。"}}
{"id": "2409.04617", "title": "Sparse Rewards Can Self-Train Dialogue Agents", "authors": ["Barrett Martin Lattimer", "Varun Gangal", "Ryan McDonald", "Yi Yang"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025 (Findings)", "url": "http://arxiv.org/abs/2409.04617v3", "summary": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM)\nagents, especially in multi-turn dialogue tasks, have been primarily driven by\nsupervised fine-tuning and high-quality human feedback. However, as base LLM\nmodels continue to improve, acquiring meaningful human feedback has become\nincreasingly challenging and costly. In certain domains, base LLM agents may\neventually exceed human capabilities, making traditional feedback-driven\nmethods impractical. In this paper, we introduce a novel self-improvement\nparadigm that empowers LLM agents to autonomously enhance their performance\nwithout external human feedback. Our method, Juxtaposed Outcomes for Simulation\nHarvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward\nsimulation environment to extract ideal behaviors and further train the LLM on\nits own outputs. We present ToolWOZ, a sparse reward tool-calling simulation\nenvironment derived from MultiWOZ. We demonstrate that models trained with\nJOSH, both small and frontier, significantly improve tool-based interactions\nwhile preserving general model capabilities across diverse benchmarks. Our code\nand data are publicly available on GitHub at\nhttps://github.com/asappresearch/josh-llm-simulation-training", "comment": "Accepted to ACL 2025 (Findings)", "pdf_url": "http://arxiv.org/pdf/2409.04617v3", "cate": "cs.CL", "date": "2024-09-06", "updated": "2025-07-18", "AI": {"title_translation": "稀疏奖励可以自训练对话代理", "tldr": "本文提出JOSH，一种利用稀疏奖励模拟环境让LLM代理进行自训练的范式，以克服对人类反馈的依赖，并在工具调用任务中取得了显著提升。", "motivation": "当前先进的LLM代理在多轮对话任务中主要依赖监督微调和高质量人类反馈。然而，随着LLM模型能力的提升，获取有意义的人类反馈变得越来越困难和昂贵，甚至在某些领域LLM可能超越人类能力，使得传统反馈驱动的方法不再实用。", "method": "我们引入了一种名为“并置结果模拟收获”（Juxtaposed Outcomes for Simulation Harvesting, JOSH）的自对齐算法。JOSH利用稀疏奖励模拟环境来提取理想行为，并利用LLM自身的输出来进一步训练LLM。我们还提出了ToolWOZ，一个源自MultiWOZ的稀疏奖励工具调用模拟环境。", "result": "通过JOSH训练的模型，无论是小型还是前沿模型，都在基于工具的交互方面取得了显著改进，同时在不同基准测试中保持了通用的模型能力。", "conclusion": "JOSH方法通过利用稀疏奖励模拟环境实现LLM代理的自训练，有效克服了对昂贵和难以获取的人类反馈的依赖，并在工具调用任务中展现出卓越的性能，证明了其在未来LLM训练中的潜力。", "translation": "近年来，最先进（SOTA）的大型语言模型（LLM）代理，尤其是在多轮对话任务中的进展，主要得益于监督微调和高质量的人类反馈。然而，随着基础LLM模型的持续改进，获取有意义的人类反馈变得越来越具有挑战性和成本高昂。在某些领域，基础LLM代理最终可能会超越人类能力，这使得传统的反馈驱动方法变得不切实际。在本文中，我们引入了一种新颖的自我改进范式，该范式使LLM代理能够在没有外部人类反馈的情况下自主提升其性能。我们的方法，即“并置结果模拟收获”（Juxtaposed Outcomes for Simulation Harvesting, JOSH），是一种自对齐算法，它利用稀疏奖励模拟环境来提取理想行为，并根据LLM自身的输出进一步训练LLM。我们提出了ToolWOZ，一个源自MultiWOZ的稀疏奖励工具调用模拟环境。我们证明，使用JOSH训练的模型，无论是小型模型还是前沿模型，在基于工具的交互方面都显著改进，同时在不同基准测试中保持了通用的模型能力。我们的代码和数据已在GitHub上公开。", "summary": "本文提出了一种名为JOSH的自对齐算法，旨在使LLM代理在没有人类反馈的情况下自主提升性能。JOSH利用稀疏奖励模拟环境（如ToolWOZ）提取理想行为，并用LLM自身的输出进行训练。实验证明，JOSH能显著提升模型在工具调用任务中的表现，同时保持其通用能力，有效解决了获取高质量人类反馈日益困难和昂贵的问题。", "keywords": "稀疏奖励, 自训练, 对话代理, LLM, JOSH", "comments": "本文提出了一种创新性的LLM自训练范式，通过引入稀疏奖励模拟环境和自对齐算法JOSH，有效解决了当前LLM训练中对昂贵且难以获取的人类反馈的依赖问题。这种方法在LLM能力日益提升、可能超越人类的背景下具有重要意义，为未来LLM的持续改进提供了一条新的、更具可扩展性的途径。"}}
{"id": "2507.13367", "title": "A Novel APVD Steganography Technique Incorporating Pseudorandom Pixel Selection for Robust Image Security", "authors": ["Mehrab Hosain", "Rajiv Kapoor"], "categories": ["cs.CR", "cs.CV", "cs.MM", "eess.IV", "68Q80", "I.4.2"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol 1191. Springer", "url": "http://arxiv.org/abs/2507.13367v1", "summary": "Steganography is the process of embedding secret information discreetly\nwithin a carrier, ensuring secure exchange of confidential data. The Adaptive\nPixel Value Differencing (APVD) steganography method, while effective,\nencounters certain challenges like the \"unused blocks\" issue. This problem can\ncause a decrease in security, compromise the embedding capacity, and lead to\nlower visual quality. This research presents a novel steganographic strategy\nthat integrates APVD with pseudorandom pixel selection to effectively mitigate\nthese issues. The results indicate that the new method outperforms existing\ntechniques in aspects of security, data hiding capacity, and the preservation\nof image quality. Empirical results reveal that the combination of APVD with\npseudorandom pixel selection significantly enhances key image quality metrics\nsuch as Peak Signal-to-Noise Ratio (PSNR), Universal Image Quality Index (UIQ),\nand Structural Similarity Index (SSIM), surpassing other contemporary methods\nin performance. The newly proposed method is versatile, able to handle a\nvariety of cover and secret images in both color and grayscale, thereby\nensuring secure data transmission without compromising the aesthetic quality of\nthe image.", "comment": "Accepted COMITCON 2023. Lecture Notes in Electrical Engineering, vol\n  1191. Springer", "pdf_url": "http://arxiv.org/pdf/2507.13367v1", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-08", "AI": {"title_translation": "一种结合伪随机像素选择的新型APVD隐写术，用于鲁棒图像安全", "tldr": "本研究提出一种结合APVD和伪随机像素选择的新型隐写术，有效解决了现有APVD方法的“未使用块”问题，显著提升了图像安全性、嵌入容量和视觉质量。", "motivation": "自适应像素值差分 (APVD) 隐写术存在“未使用块”问题，导致安全性下降、嵌入容量受损以及视觉质量降低。", "method": "本研究提出一种新颖的隐写策略，将APVD与伪随机像素选择相结合，以有效缓解现有问题。", "result": "新方法在安全性、数据隐藏容量和图像质量保持方面优于现有技术。实证结果表明，结合APVD和伪随机像素选择显著提升了关键图像质量指标，如峰值信噪比 (PSNR)、通用图像质量指数 (UIQ) 和结构相似性指数 (SSIM)，表现优于其他当代方法。新提出的方法用途广泛，能够处理彩色和灰度图像中的各种封面和秘密图像。", "conclusion": "新提出的方法通过解决传统APVD的局限性，实现了在不损害图像美学质量的前提下安全数据传输，显著增强了图像的安全性、嵌入容量和视觉质量。", "translation": "隐写术是在载体中谨慎嵌入秘密信息的过程，以确保机密数据的安全交换。自适应像素值差分 (APVD) 隐写方法虽然有效，但会遇到诸如“未使用块”等挑战。这个问题可能导致安全性下降、嵌入容量受损以及视觉质量降低。本研究提出一种新颖的隐写策略，将APVD与伪随机像素选择相结合，以有效缓解这些问题。结果表明，新方法在安全性、数据隐藏容量和图像质量保持方面优于现有技术。实证结果揭示，APVD与伪随机像素选择的结合显著提升了关键图像质量指标，如峰值信噪比 (PSNR)、通用图像质量指数 (UIQ) 和结构相似性指数 (SSIM)，表现优于其他当代方法。新提出的方法用途广泛，能够处理彩色和灰度图像中的各种封面和秘密图像，从而在不损害图像美学质量的前提下确保安全数据传输。", "summary": "本研究针对自适应像素值差分 (APVD) 隐写术中存在的“未使用块”问题，提出了一种新颖的隐写策略。该策略将APVD与伪随机像素选择相结合，旨在提高图像安全性、数据隐藏容量和视觉质量。实验结果表明，新方法在PSNR、UIQ和SSIM等关键图像质量指标上显著优于现有技术，并且能够处理多种彩色和灰度图像，确保安全且高质量的数据传输。", "keywords": "隐写术, APVD, 伪随机像素选择, 图像安全, 数据隐藏", "comments": "该论文的创新之处在于将伪随机像素选择引入APVD隐写术，有效地解决了APVD方法中“未使用块”的固有问题。这不仅提升了安全性，还改善了嵌入容量和图像视觉质量，使其在实际应用中更具鲁棒性和实用性。其多功能性（支持彩色和灰度图像）也增加了其实用价值。"}}
{"id": "2412.17305", "title": "Exploiting Label Skewness for Spiking Neural Networks in Federated Learning", "authors": ["Di Yu", "Xin Du", "Linshan Jiang", "Huijing Zhang", "Shuiguang Deng"], "categories": ["cs.LG", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This work has been accepted on the International Joint Conference on Artificial Intelligence 2025", "url": "http://arxiv.org/abs/2412.17305v3", "summary": "The energy efficiency of deep spiking neural networks (SNNs) aligns with the\nconstraints of resource-limited edge devices, positioning SNNs as a promising\nfoundation for intelligent applications leveraging the extensive data collected\nby these devices. To address data privacy concerns when deploying SNNs on edge\ndevices, federated learning (FL) facilitates collaborative model training by\nleveraging data distributed across edge devices without transmitting local data\nto a central server. However, existing FL approaches struggle with label-skewed\ndata across devices, which leads to drift in local SNN models and degrades the\nperformance of the global SNN model. In this paper, we propose a novel\nframework called FedLEC, which incorporates intra-client label weight\ncalibration to balance the learning intensity across local labels and\ninter-client knowledge distillation to mitigate local SNN model bias caused by\nlabel absence. Extensive experiments with three different structured SNNs\nacross five datasets (i.e., three non-neuromorphic and two neuromorphic\ndatasets) demonstrate the efficiency of FedLEC. Compared to eight\nstate-of-the-art FL algorithms, FedLEC achieves an average accuracy improvement\nof approximately 11.59% for the global SNN model under various label skew\ndistribution settings.", "comment": "This work has been accepted on the International Joint Conference on\n  Artificial Intelligence 2025", "pdf_url": "http://arxiv.org/pdf/2412.17305v3", "cate": "cs.LG", "date": "2024-12-23", "updated": "2025-07-18", "AI": {"title_translation": "联邦学习中脉冲神经网络利用标签偏斜", "tldr": "提出FedLEC框架，通过内部标签校准和客户端间知识蒸馏，解决联邦学习中脉冲神经网络在标签偏斜数据上的性能下降问题，显著提高全局模型精度。", "motivation": "现有联邦学习方法在处理边缘设备上的脉冲神经网络（SNNs）时，面对标签偏斜数据表现不佳，导致本地SNN模型漂移并降低全局SNN模型性能。SNNs因其能效高，是边缘设备智能应用的理想选择，但数据隐私需通过联邦学习解决。", "method": "提出名为FedLEC的新颖框架。该框架结合了：1. 客户端内标签权重校准，以平衡本地标签的学习强度；2. 客户端间知识蒸馏，以缓解由标签缺失引起的本地SNN模型偏差。", "result": "通过在五种数据集（三种非神经形态和两种神经形态）上使用三种不同结构的SNNs进行广泛实验，证明了FedLEC的效率。与八种最先进的联邦学习算法相比，FedLEC在各种标签偏斜分布设置下，使全局SNN模型的平均精度提高了约11.59%。", "conclusion": "FedLEC框架通过解决联邦学习中脉冲神经网络在标签偏斜数据上的挑战，显著提升了全局模型的性能，为边缘设备上的SNNs部署提供了有效的解决方案。", "translation": "深度脉冲神经网络（SNNs）的能效与资源受限的边缘设备的约束相符，使SNNs成为利用这些设备收集的大量数据的智能应用的有前景的基础。为了解决在边缘设备上部署SNNs时的数据隐私问题，联邦学习（FL）通过利用分布式在边缘设备上的数据进行协作模型训练，而无需将本地数据传输到中央服务器。然而，现有的FL方法在设备间标签偏斜数据方面表现不佳，这导致本地SNN模型漂移并降低了全局SNN模型的性能。在本文中，我们提出了一种名为FedLEC的新颖框架，它结合了客户端内标签权重校准以平衡本地标签的学习强度，以及客户端间知识蒸馏以缓解由标签缺失引起的本地SNN模型偏差。对三种不同结构的SNNs在五个数据集（即三个非神经形态和两个神经形态数据集）上进行的广泛实验证明了FedLEC的效率。与八种最先进的FL算法相比，FedLEC在各种标签偏斜分布设置下，使全局SNN模型的平均精度提高了约11.59%。", "summary": "本文针对联邦学习中脉冲神经网络（SNNs）在标签偏斜数据上性能下降的问题，提出了FedLEC框架。FedLEC通过引入客户端内标签权重校准来平衡学习强度，并利用客户端间知识蒸馏来减轻标签缺失导致的模型偏差。实验结果表明，FedLEC在多种数据集和SNN结构上，相对于现有联邦学习算法，显著提高了全局SNN模型的精度。", "keywords": "联邦学习, 脉冲神经网络, 标签偏斜, 知识蒸馏, 边缘计算", "comments": "这篇论文通过提出FedLEC框架，有效地解决了联邦学习环境下脉冲神经网络处理标签偏斜数据时的核心挑战。其创新点在于结合了客户端内的标签权重校准和客户端间的知识蒸馏，这种双管齐下的方法能够同时处理本地数据分布不均和全局模型偏差。在能效敏感的边缘设备上部署SNNs并保证数据隐私是当前的热点，FedLEC的提出为这一领域提供了重要的性能提升，具有较高的实用价值。"}}
{"id": "2507.13477", "title": "Linking Multi-Site Sex Ad Data at the Individual Level to Aid Counter-Trafficking Efforts", "authors": ["Nickolas K. Freeman", "Gregory J. Bott", "Burcu B. Keskin", "Jason M. Parton", "James J. Cochran"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      30 pages, 10 figures, 6 tables. Under review at Manufacturing & Service Operations Management", "url": "http://arxiv.org/abs/2507.13477v1", "summary": "The Internet facilitates sex trafficking through adult service websites\n(ASWs) that host online advertisements for sexual services (sex ads). Since the\nclosure of the popular site Backpage.com, the ecosystem of ASWs has expanded to\ninclude multiple competing sites that are hosted outside US jurisdiction.\nGaining intelligence for counter-trafficking efforts requires collecting,\nlinking, and cleaning the data from multiple sites. However, high ad volumes,\ndisparate data types, and the existence of generic and misappropriated data\nmake this process challenging. We present an end-to-end process for linking sex\nad data and filtering potentially erroneous links. Outputs of the developed\nprocess have been used to inform counter-trafficking operations that have\nhelped identify more than 60 potential victims of sex trafficking, some of whom\nare getting help to transition out of the life. Our process leverages concepts\nand techniques from network science, information systems, and artificial\nintelligence to link ads across sites at the level of an individual or unique\nposting entity. Our approach is computationally efficient, allowing millions of\nads to be processed in under an hour. A key component of our process is an edge\nfiltering procedure that identifies and removes potentially erroneous links in\na graph representation of sex ad data. A comparison of the proposed process to\nan existing approach shows that our process is typically more computationally\nefficient and yields substantial increases in the number of individuals for\nwhich we can derive actionable intelligence. The proposed process is an\nefficient and effective approach for transforming the high volumes of disparate\ndata from sex ads into intelligence that can save lives. It has been refined\nover years of collaboration with practitioners and represents a strong\nfoundation upon which further counter-trafficking tools can be built.", "comment": "30 pages, 10 figures, 6 tables. Under review at Manufacturing &\n  Service Operations Management", "pdf_url": "http://arxiv.org/pdf/2507.13477v1", "cate": "cs.SI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "在个体层面链接多站点性服务广告数据以协助打击人口贩运工作", "tldr": "该论文提出了一种高效的方法，用于在个体层面链接多站点性服务广告数据，以协助打击人口贩运工作，并已帮助识别潜在受害者。", "motivation": "互联网通过成人服务网站（ASW）促进了性贩运。自Backpage.com关闭以来，成人服务网站生态系统已扩展到多个竞争站点，使得收集、链接和清理多站点数据变得困难，因为数据量大、类型不同且存在通用和盗用的数据。为了打击人口贩运，需要获取情报，这要求有效链接这些数据。", "method": "该论文提出了一种端到端处理流程，用于链接性服务广告数据并过滤潜在的错误链接。该过程利用网络科学、信息系统和人工智能的概念和技术，在个体或唯一发布实体层面链接跨站点广告。其关键组成部分是边缘过滤程序，用于识别和移除性服务广告数据图表示中的潜在错误链接。", "result": "该流程的输出已用于指导反人口贩运行动，帮助识别了60多名潜在性贩运受害者。该方法计算效率高，可以在一小时内处理数百万条广告。与现有方法相比，该流程通常计算效率更高，并显著增加了可获取可操作情报的个体数量。", "conclusion": "所提出的流程是一种高效且有效的方法，能够将性服务广告中大量不同的数据转化为可挽救生命的情报。该方法经过多年与实践者的合作而完善，为未来打击人口贩运工具的开发奠定了坚实基础。", "translation": "互联网通过提供性服务在线广告的成人服务网站（ASW）促进了性贩运。自热门网站Backpage.com关闭以来，成人服务网站的生态系统已扩展到包括多个在美国司法管辖区之外托管的竞争网站。为打击人口贩运工作获取情报需要收集、链接和清理来自多个站点的数据。然而，高广告量、不同的数据类型以及通用和盗用数据的存在使这一过程充满挑战。我们提出了一种端到端流程，用于链接性服务广告数据并过滤潜在的错误链接。所开发流程的输出已用于指导反人口贩运行动，这些行动已帮助识别了60多名潜在性贩运受害者，其中一些人正在获得帮助以摆脱这种生活。我们的流程利用网络科学、信息系统和人工智能的概念和技术，在个体或唯一发布实体层面链接跨站点的广告。我们的方法计算效率高，可以在一小时内处理数百万条广告。我们流程的一个关键组成部分是边缘过滤程序，它识别并移除性服务广告数据图表示中的潜在错误链接。将所提出的流程与现有方法进行比较表明，我们的流程通常计算效率更高，并且能够大幅增加我们可以获取可操作情报的个体数量。所提出的流程是一种高效且有效的方法，能够将性服务广告中大量不同的数据转化为可挽救生命的情报。它经过多年与实践者的合作而完善，代表着未来可以构建更多打击人口贩运工具的坚实基础。", "summary": "该论文介绍了一种高效的端到端流程，利用网络科学、信息系统和人工智能，在个体层面链接多站点性服务广告数据。该流程旨在克服高数据量和数据异构性等挑战，将原始广告数据转化为可用于打击人口贩运的可操作情报。该方法已成功应用于实践，帮助识别了60多名潜在性贩运受害者，并被证明比现有方法更具计算效率，为未来的反人口贩运工具奠定了坚实基础。", "keywords": "性贩运, 数据链接, 反人口贩运, 网络科学, 人工智能", "comments": "该论文的创新之处在于开发了一个高效的端到端流程，该流程综合利用了网络科学、信息系统和人工智能等多个领域的概念和技术，以解决链接大量异构在线性服务广告数据的复杂问题。其重要性体现在它直接帮助识别了人口贩运受害者，并且具有高计算效率。这为执法部门和反人口贩运组织提供了一个关键工具。"}}
{"id": "2507.13857", "title": "Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation", "authors": ["Max van den Hoven", "Kishaan Jeeveswaran", "Pieter Piscaer", "Thijs Wensveen", "Elahe Arani", "Bahram Zonooz"], "categories": ["cs.CV", "cs.RO"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13857v1", "summary": "Monocular 3D lane detection is essential for autonomous driving, but\nchallenging due to the inherent lack of explicit spatial information.\nMulti-modal approaches rely on expensive depth sensors, while methods\nincorporating fully-supervised depth networks rely on ground-truth depth data\nthat is impractical to collect at scale. Additionally, existing methods assume\nthat camera parameters are available, limiting their applicability in scenarios\nlike crowdsourced high-definition (HD) lane mapping. To address these\nlimitations, we propose Depth3DLane, a novel dual-pathway framework that\nintegrates self-supervised monocular depth estimation to provide explicit\nstructural information, without the need for expensive sensors or additional\nground-truth depth data. Leveraging a self-supervised depth network to obtain a\npoint cloud representation of the scene, our bird's-eye view pathway extracts\nexplicit spatial information, while our front view pathway simultaneously\nextracts rich semantic information. Depth3DLane then uses 3D lane anchors to\nsample features from both pathways and infer accurate 3D lane geometry.\nFurthermore, we extend the framework to predict camera parameters on a\nper-frame basis and introduce a theoretically motivated fitting procedure to\nenhance stability on a per-segment basis. Extensive experiments demonstrate\nthat Depth3DLane achieves competitive performance on the OpenLane benchmark\ndataset. Furthermore, experimental results show that using learned parameters\ninstead of ground-truth parameters allows Depth3DLane to be applied in\nscenarios where camera calibration is infeasible, unlike previous methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13857v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Depth3DLane: 将单目3D车道线检测与自监督单目深度估计融合", "tldr": "提出Depth3DLane框架，通过自监督单目深度估计融合3D车道线检测，无需昂贵传感器或深度真值数据，并能预测相机参数。", "motivation": "单目3D车道线检测由于缺乏显式空间信息而具有挑战性。现有方法依赖昂贵的深度传感器或难以大规模收集的深度真值数据，且通常假设相机参数可用，这限制了其在众包高清车道图等实际场景中的应用。", "method": "提出Depth3DLane，一个新颖的双路径框架，将自监督单目深度估计集成以提供显式结构信息。该框架利用自监督深度网络生成场景点云，通过鸟瞰图路径提取显式空间信息，同时通过前视图路径提取丰富语义信息。Depth3DLane使用3D车道锚点从两个路径采样特征并推断3D车道几何。此外，它扩展了框架以逐帧预测相机参数，并引入了理论驱动的拟合过程以增强逐段稳定性。", "result": "Depth3DLane在OpenLane基准数据集上取得了有竞争力的性能。实验结果表明，使用学习到的参数而非真值参数，Depth3DLane可以在相机校准不可行的场景中应用，这与以前的方法不同。", "conclusion": "Depth3DLane通过融合自监督单目深度估计，有效解决了单目3D车道线检测中对昂贵传感器、深度真值数据和相机参数的依赖问题，显著提升了其在实际场景中的适用性，并展现出优异的性能。", "translation": "单目3D车道线检测对于自动驾驶至关重要，但由于固有的显式空间信息缺乏而具有挑战性。多模态方法依赖昂贵的深度传感器，而结合全监督深度网络的方法则依赖于难以大规模收集的深度真值数据。此外，现有方法假设相机参数可用，限制了它们在众包高清（HD）车道地图等场景中的适用性。为了解决这些限制，我们提出了Depth3DLane，一个新颖的双路径框架，它集成了自监督单目深度估计以提供显式结构信息，而无需昂贵的传感器或额外的深度真值数据。利用自监督深度网络获取场景的点云表示，我们的鸟瞰图路径提取显式空间信息，而我们的前视图路径同时提取丰富的语义信息。Depth3DLane然后使用3D车道锚点从两个路径采样特征并推断准确的3D车道几何。此外，我们扩展了该框架以逐帧预测相机参数，并引入了理论驱动的拟合过程以增强逐段稳定性。广泛的实验表明，Depth3DLane在OpenLane基准数据集上取得了有竞争力的性能。此外，实验结果表明，与以前的方法不同，使用学习到的参数而不是真值参数，Depth3DLane可以在相机校准不可行的场景中应用。", "summary": "Depth3DLane提出一种新颖的双路径框架，通过融合自监督单目深度估计来解决单目3D车道线检测中缺乏空间信息、依赖昂贵传感器和深度真值数据以及相机参数不可用的问题。该框架利用鸟瞰图和前视图路径分别提取空间和语义信息，并通过3D车道锚点推断车道几何。此外，它能逐帧预测相机参数，并在OpenLane数据集上表现出色，使其适用于相机校准受限的实际场景。", "keywords": "单目3D车道线检测, 自监督深度估计, 自动驾驶, 相机参数预测, Depth3DLane", "comments": "Depth3DLane的创新点在于将自监督单目深度估计引入单目3D车道线检测，有效解决了对昂贵传感器和深度真值数据的依赖。此外，其预测相机参数的能力显著扩展了应用场景，使其在相机校准不可行的情况下也能使用，这对于众包高清地图等实际应用具有重要意义。该方法通过双路径融合策略，有效结合了显式空间信息和丰富语义信息，提升了3D车道线检测的准确性和鲁棒性。"}}
{"id": "2507.13677", "title": "HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors", "authors": ["Chuheng Wei", "Ziye Qin", "Walter Zimmer", "Guoyuan Wu", "Matthew J. Barth"], "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted by ITSC2025", "url": "http://arxiv.org/abs/2507.13677v1", "summary": "Real-world Vehicle-to-Everything (V2X) cooperative perception systems often\noperate under heterogeneous sensor configurations due to cost constraints and\ndeployment variability across vehicles and infrastructure. This heterogeneity\nposes significant challenges for feature fusion and perception reliability. To\naddress these issues, we propose HeCoFuse, a unified framework designed for\ncooperative perception across mixed sensor setups where nodes may carry Cameras\n(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that\nadaptively weights features through a combination of channel-wise and spatial\nattention, HeCoFuse can tackle critical challenges such as cross-modality\nfeature misalignment and imbalanced representation quality. In addition, an\nadaptive spatial resolution adjustment module is employed to balance\ncomputational cost and fusion effectiveness. To enhance robustness across\ndifferent configurations, we further implement a cooperative learning strategy\nthat dynamically adjusts fusion type based on available modalities. Experiments\non the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%\n3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D\nbaseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC\nscenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine\nheterogeneous sensor configurations. These results, validated by our\nfirst-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the\ncurrent state-of-the-art on TUM-Traf V2X dataset while demonstrating robust\nperformance across diverse sensor deployments.", "comment": "Ranked first in CVPR DriveX workshop TUM-Traf V2X challenge. Accepted\n  by ITSC2025", "pdf_url": "http://arxiv.org/pdf/2507.13677v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "HeCoFuse：异构传感器V2X跨模态互补协同感知", "tldr": "HeCoFuse是一个统一框架，用于解决V2X协同感知中异构传感器配置下的跨模态特征融合和感知可靠性问题，并通过分层融合、自适应空间分辨率调整和协同学习策略，在TUMTraf-V2X数据集上实现了最先进的性能。", "motivation": "现实世界的V2X协同感知系统常因成本和部署差异而采用异构传感器配置，这给特征融合和感知可靠性带来了巨大挑战。", "method": "提出HeCoFuse统一框架，用于混合传感器（相机、激光雷达或两者）配置下的协同感知。它引入了分层融合机制，通过通道和空间注意力自适应地加权特征，解决跨模态特征错位和表示质量不平衡问题。此外，采用自适应空间分辨率调整模块平衡计算成本和融合效率，并实现协同学习策略动态调整融合类型以增强鲁棒性。", "result": "在TUMTraf-V2X数据集上，HeCoFuse在完全传感器配置（LC+LC）下达到43.22%的3D mAP，比CoopDet3D基线高1.17%；在L+LC场景中达到更高的43.38%的3D mAP；在九种异构传感器配置下，3D mAP保持在21.74%至43.38%之间。在CVPR 2025 DriveX挑战赛中获得第一名。", "conclusion": "HeCoFuse在TUM-Traf V2X数据集上达到了当前最先进的水平，并在各种传感器部署中展示了强大的性能。", "translation": "现实世界的车联网（V2X）协同感知系统由于成本限制以及车辆和基础设施部署的差异性，通常在异构传感器配置下运行。这种异构性给特征融合和感知可靠性带来了重大挑战。为了解决这些问题，我们提出了HeCoFuse，一个统一的框架，旨在实现跨混合传感器设置的协同感知，其中节点可能携带摄像头（C）、激光雷达（L）或两者。通过引入一种分层融合机制，该机制通过通道和空间注意力的组合自适应地加权特征，HeCoFuse可以解决诸如跨模态特征错位和表示质量不平衡等关键挑战。此外，还采用自适应空间分辨率调整模块来平衡计算成本和融合效率。为了增强在不同配置下的鲁棒性，我们进一步实现了一种协同学习策略，该策略根据可用模态动态调整融合类型。在真实世界TUMTraf-V2X数据集上的实验表明，HeCoFuse在完全传感器配置（LC+LC）下实现了43.22%的3D mAP，比CoopDet3D基线高出1.17%，并在L+LC场景中达到了更高的43.38%的3D mAP，同时在九种异构传感器配置下，3D mAP保持在21.74%到43.38%的范围内。这些结果，通过我们在CVPR 2025 DriveX挑战赛中获得的第一名所验证，确立了HeCoFuse在TUM-Traf V2X数据集上的当前最先进地位，同时展示了其在不同传感器部署中的鲁棒性能。", "summary": "HeCoFuse是一个针对V2X协同感知中异构传感器配置的统一框架。它通过分层融合机制（结合通道和空间注意力）解决跨模态特征错位和表示不平衡问题，并通过自适应空间分辨率调整和协同学习策略提高效率和鲁棒性。在TUMTraf-V2X数据集上的实验表明，HeCoFuse在多种异构配置下均表现出色，达到了先进的3D mAP性能，并赢得了CVPR 2025 DriveX挑战赛。", "keywords": "V2X, 协同感知, 异构传感器, 跨模态融合, 自动驾驶", "comments": "HeCoFuse的创新之处在于其针对V2X异构传感器配置的统一框架，以及通过分层融合机制、自适应空间分辨率调整和协同学习策略有效解决了跨模态特征融合的挑战。其在真实世界数据集上的SOTA表现和挑战赛的胜利，证明了其在实际部署中的潜力和重要性。"}}
{"id": "2411.02904", "title": "Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression", "authors": ["Yingzhen Yang", "Ping Li"], "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      This article draws results with revisions from the first author's other work in arXiv:2407.11353 , with typos in the previous version fixed. arXiv admin note: text overlap with arXiv:2407.11353", "url": "http://arxiv.org/abs/2411.02904v4", "summary": "We study nonparametric regression by an over-parameterized two-layer neural\nnetwork trained by gradient descent (GD) in this paper. We show that, if the\nneural network is trained by GD with early stopping, then the trained network\nrenders a sharp rate of the nonparametric regression risk of\n$\\mathcal{O}(\\epsilon_n^2)$, which is the same rate as that for the classical\nkernel regression trained by GD with early stopping, where $\\epsilon_n$ is the\ncritical population rate of the Neural Tangent Kernel (NTK) associated with the\nnetwork and $n$ is the size of the training data. It is remarked that our\nresult does not require distributional assumptions about the covariate as long\nas the covariate is bounded, in a strong contrast with many existing results\nwhich rely on specific distributions of the covariates such as the spherical\nuniform data distribution or distributions satisfying certain restrictive\nconditions. The rate $\\mathcal{O}(\\epsilon_n^2)$ is known to be minimax optimal\nfor specific cases, such as the case that the NTK has a polynomial eigenvalue\ndecay rate which happens under certain distributional assumptions on the\ncovariates. Our result formally fills the gap between training a classical\nkernel regression model and training an over-parameterized but finite-width\nneural network by GD for nonparametric regression without distributional\nassumptions on the bounded covariate. We also provide confirmative answers to\ncertain open questions or address particular concerns in the literature of\ntraining over-parameterized neural networks by GD with early stopping for\nnonparametric regression, including the characterization of the stopping time,\nthe lower bound for the network width, and the constant learning rate used in\nGD.", "comment": "This article draws results with revisions from the first author's\n  other work in arXiv:2407.11353, with typos in the previous version fixed", "pdf_url": "http://arxiv.org/pdf/2411.02904v4", "cate": "stat.ML", "date": "2024-11-05", "updated": "2025-07-17", "AI": {"title_translation": "梯度下降法发现具有尖锐泛化能力的超参数化神经网络用于非参数回归", "tldr": "本文研究发现，通过梯度下降法和早期停止训练的超参数化神经网络在非参数回归中能达到与经典核回归相同的尖锐风险率，且无需协变量分布假设，填补了理论空白。", "motivation": "本文旨在弥补在无协变量分布假设下，通过梯度下降法训练经典核回归模型与超参数化有限宽度神经网络在非参数回归方面的理论鸿沟，并回答了停止时间、网络宽度下限和恒定学习率等开放性问题。", "method": "使用梯度下降法（GD）与早期停止策略来训练一个超参数化的两层神经网络，用于非参数回归。", "result": "证明了通过梯度下降法和早期停止训练的超参数化两层神经网络，在非参数回归中的风险能达到$\\\\mathcal{O}(\\\\epsilon_n^2)$的尖锐速率，这与经典核回归的速率相同。此结果在协变量有界的前提下，不要求其分布假设。", "conclusion": "本文正式弥补了在有界协变量无分布假设下，通过梯度下降法训练经典核回归模型与超参数化有限宽度神经网络在非参数回归方面的理论空白，并对停止时间、网络宽度下限和恒定学习率等开放性问题提供了确证性答案。", "translation": "我们研究了通过梯度下降法（GD）训练的超参数化两层神经网络的非参数回归。我们表明，如果神经网络通过带有早期停止的梯度下降法进行训练，那么训练后的网络会呈现$\\mathcal{O}(\\epsilon_n^2)$的非参数回归风险的尖锐速率，这与通过带有早期停止的梯度下降法训练的经典核回归的速率相同，其中$\\epsilon_n$是与网络相关的神经切线核（NTK）的关键群体速率，$n$是训练数据的大小。值得注意的是，我们的结果不要求协变量的分布假设，只要协变量是有界的，这与许多依赖于协变量特定分布（如球形均匀数据分布或满足某些限制条件分布）的现有结果形成强烈对比。速率$\\mathcal{O}(\\epsilon_n^2)$在特定情况下已知是最小最大最优的，例如在某些协变量分布假设下NTK具有多项式特征值衰减率的情况。我们的结果正式弥补了在有界协变量无分布假设下，通过梯度下降法训练经典核回归模型与训练超参数化但有限宽度神经网络之间在非参数回归方面的空白。我们还对非参数回归中通过梯度下降法和早期停止训练超参数化神经网络文献中的某些开放性问题或特定担忧提供了确证性答案，包括停止时间的表征、网络宽度的下限以及梯度下降法中使用的恒定学习率。", "summary": "本文研究了通过梯度下降法和早期停止训练的超参数化两层神经网络在非参数回归中的表现。研究发现，该神经网络能实现与经典核回归相同的$\\mathcal{O}(\\epsilon_n^2)$尖锐风险率，且显著特点是无需协变量的分布假设。这填补了在无分布假设下，神经网络与经典核回归在非参数回归性能上的理论鸿沟，并回答了关于停止时间、网络宽度和学习率等关键开放性问题。", "keywords": "非参数回归, 梯度下降法, 超参数化神经网络, 早期停止, 泛化能力", "comments": "本文的创新之处在于其理论结果不依赖于协变量的特定分布假设，这在现有研究中是一个显著的进步，极大地拓宽了超参数化神经网络在非参数回归中的适用性。它通过严谨的数学分析，将超参数化神经网络的泛化能力与经典核回归联系起来，增强了对深度学习模型泛化机制的理解。"}}
{"id": "2507.13712", "title": "LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction", "authors": ["Jing Chang", "Chang Liu", "Jinbin Huang", "Rui Mao", "Jianbin Qin"], "categories": ["cs.DB", "cs.LG"], "primary_category": "Subjects:       Databases (cs.DB)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13712v1", "summary": "Automated data preparation is crucial for democratizing machine learning, yet\nexisting reinforcement learning (RL) based approaches suffer from inefficient\nexploration in the vast space of possible preprocessing pipelines. We present\nLLaPipe, a novel framework that addresses this exploration bottleneck by\nintegrating Large Language Models (LLMs) as intelligent policy advisors. Unlike\ntraditional methods that rely solely on statistical features and blind\ntrial-and-error, LLaPipe leverages the semantic understanding capabilities of\nLLMs to provide contextually relevant exploration guidance. Our framework\nintroduces three key innovations: (1) an LLM Policy Advisor that analyzes\ndataset semantics and pipeline history to suggest promising preprocessing\noperations, (2) an Experience Distillation mechanism that mines successful\npatterns from past pipelines and transfers this knowledge to guide future\nexploration, and (3) an Adaptive Advisor Triggering strategy\n(Advisor\\textsuperscript{+}) that dynamically determines when LLM intervention\nis most beneficial, balancing exploration effectiveness with computational\ncost. Through extensive experiments on 18 diverse datasets spanning multiple\ndomains, we demonstrate that LLaPipe achieves up to 22.4\\% improvement in\npipeline quality and 2.3$\\times$ faster convergence compared to\nstate-of-the-art RL-based methods, while maintaining computational efficiency\nthrough selective LLM usage (averaging only 19.0\\% of total exploration steps).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13712v1", "cate": "cs.DB", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "LLaPipe：LLM引导的强化学习用于自动化数据准备管道构建", "tldr": "LLaPipe是一个新颖的框架，它利用大型语言模型（LLMs）来指导强化学习，从而显著提高自动化数据准备管道的构建效率和质量。", "motivation": "现有基于强化学习的自动化数据准备方法在庞大的预处理管道空间中探索效率低下，阻碍了机器学习的普及。", "method": "LLaPipe是一个将大型语言模型（LLMs）作为智能策略顾问的框架，旨在解决探索瓶颈。它引入了三项关键创新：1) LLM策略顾问，分析数据集语义和管道历史以建议预处理操作；2) 经验蒸馏机制，从成功管道中挖掘模式并转移知识；3) 自适应顾问触发策略（Advisor+），动态决定LLM干预时机，平衡效率与成本。", "result": "在18个不同数据集上的实验表明，LLaPipe在管道质量上实现了高达22.4%的提升，并且比最先进的基于RL的方法收敛速度快2.3倍，同时通过选择性使用LLM（平均仅占总探索步骤的19.0%）保持了计算效率。", "conclusion": "LLaPipe通过结合LLM的语义理解能力，显著提高了自动化数据准备管道构建的效率和质量，解决了传统RL方法探索效率低下的问题。", "translation": "自动化数据准备对于机器学习的普及至关重要，然而，现有基于强化学习（RL）的方法在庞大的可能预处理管道空间中探索效率低下。我们提出了LLaPipe，一个新颖的框架，通过整合大型语言模型（LLMs）作为智能策略顾问来解决这一探索瓶颈。与仅依赖统计特征和盲目试错的传统方法不同，LLaPipe利用LLMs的语义理解能力提供上下文相关的探索指导。我们的框架引入了三项关键创新：(1) 一个LLM策略顾问，分析数据集语义和管道历史以建议有前景的预处理操作；(2) 一个经验蒸馏机制，从过去的管道中挖掘成功模式并将这些知识转移以指导未来的探索；以及 (3) 一个自适应顾问触发策略（Advisor+），动态决定何时进行LLM干预最有利，从而平衡探索效率和计算成本。通过在跨多个领域的18个不同数据集上进行的大量实验，我们证明LLaPipe在管道质量上实现了高达22.4%的提升，并且比最先进的基于RL的方法收敛速度快2.3倍，同时通过选择性使用LLM（平均仅占总探索步骤的19.0%）保持了计算效率。", "summary": "LLaPipe是一个新颖的框架，它通过将大型语言模型（LLMs）作为智能策略顾问集成到强化学习中，解决了自动化数据准备管道构建中探索效率低下的问题。它引入了LLM策略顾问、经验蒸馏和自适应顾问触发策略等创新，旨在利用LLMs的语义理解能力提供上下文指导。实验证明，LLaPipe在管道质量和收敛速度上均显著优于现有RL方法，同时保持了计算效率。", "keywords": "自动化数据准备, 强化学习, 大型语言模型, 管道构建, 探索效率", "comments": "LLaPipe的创新之处在于其将LLMs的语义理解能力与强化学习的探索机制相结合，有效解决了自动化数据准备中管道空间探索效率低下的痛点。通过引入LLM策略顾问、经验蒸馏和自适应触发机制，该框架不仅提高了管道质量和收敛速度，还通过选择性使用LLM控制了计算成本，这对于实际应用具有重要意义。"}}
{"id": "2501.09143", "title": "Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments", "authors": ["Huu-Thinh Do", "Franco Blanchini", "Stefano Miani", "Ionela Prodan"], "categories": ["eess.SY", "cs.SY", "math.OC"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Accepted to Automatica", "url": "http://arxiv.org/abs/2501.09143v3", "summary": "The techniques to design control Lyapunov functions (CLF), along with a\nproper stabilizing feedback, possibly in the presence of constraints, often\nprovide control laws that are too complex for proper implementation online,\nespecially when an optimization problem is involved. In this work, we show how\nto acquire an alternative, computationally attractive feedback. Given a nominal\nCLF and a nominal state feedback, we say that a different positive definite\nfunction is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative\nis negative-definite and bounded above by the Lyapunov derivative of the\nnominal function with the nominal control. It turns out that if we consider a\nfamily of basis functions, then a SCLF can be computed by linear programming,\nwith an infinite number of constraints. The idea is that although the offline\ncomputational burden to achieve the new controller and solve the linear program\nis considerable, the online computational burden is drastically reduced.\nComprehensive simulations and experiments on drone control are conducted to\ndemonstrate the effectiveness of the study.", "comment": "Accepted to Automatica", "pdf_url": "http://arxiv.org/pdf/2501.09143v3", "cate": "eess.SY", "date": "2025-01-15", "updated": "2025-07-17", "AI": {"title_translation": "通过子控制Lyapunov函数降低实时复杂性：从理论到实验", "tldr": "引入子控制Lyapunov函数 (SCLF) 以降低控制律的实时计算复杂性，并通过无人机实验验证。", "motivation": "当前基于控制Lyapunov函数 (CLF) 的控制律，尤其是在涉及优化时，通常过于复杂，难以进行实时在线实现。", "method": "引入子控制Lyapunov函数 (SCLF) 作为替代方案。SCLF 是一种正定函数，其Lyapunov导数是负定的，并受名义CLF导数的上限约束。它可以通过线性规划和一系列基函数进行离线计算，从而大幅降低在线计算负担。", "result": "在无人机控制方面进行了全面的仿真和实验，证明了所提方法在降低在线计算复杂性方面的有效性。", "conclusion": "所提出的子控制Lyapunov函数 (SCLF) 方法显著降低了控制律的在线计算负担，使其更适合实时实现，尽管离线计算成本较高。", "translation": "设计控制Lyapunov函数 (CLF) 的技术，连同适当的稳定反馈，即使在存在约束的情况下，通常也会提供过于复杂的控制律，难以在线正确实现，尤其是在涉及优化问题时。在这项工作中，我们展示了如何获得一种替代的、计算上更具吸引力的反馈。给定一个名义CLF和一个名义状态反馈，如果一个不同的正定函数的Lyapunov导数是负定的，并且其上限受名义函数在名义控制下的Lyapunov导数限制，那么我们称其为子控制Lyapunov函数 (SCLF)。结果表明，如果我们考虑一组基函数，那么SCLF可以通过线性规划计算，尽管存在无限数量的约束。其思想是，尽管实现新控制器和解决线性规划的离线计算负担相当大，但在线计算负担却大大减少了。在无人机控制方面进行了全面的仿真和实验，以证明这项研究的有效性。", "summary": "本文解决了由控制Lyapunov函数 (CLF) 推导出的控制律的实时复杂性问题，尤其是在涉及优化时。它引入了子控制Lyapunov函数 (SCLF) 的概念，SCLF 被定义为一种正定函数，其Lyapunov导数为负定并受名义CLF导数的上限约束。SCLF 可以通过线性规划进行离线计算，从而显著降低控制器的在线计算负担。该方法的有效性通过无人机控制的广泛仿真和实验得到了验证。", "keywords": "控制Lyapunov函数, 子控制Lyapunov函数, 实时复杂性, 线性规划, 无人机控制", "comments": "本文通过提出子控制Lyapunov函数 (SCLF)，引入了一种创新的方法来降低基于CLF的控制律的实时计算复杂性。其关键创新在于将计算负担从在线转移到离线，从而使复杂的控制策略在实时应用中更具可行性，正如无人机实验所证明的那样。这可能对高级控制系统的实际部署产生重大影响。"}}
{"id": "2501.19243", "title": "Accelerating Diffusion Transformer via Error-Optimized Cache", "authors": ["Junxiang Qiu", "Shuo Wang", "Jinda Lu", "Lin Liu", "Houcheng Jiang", "Xingyu Zhu", "Yanbin Hao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.19243v3", "summary": "Diffusion Transformer (DiT) is a crucial method for content generation.\nHowever, it needs a lot of time to sample. Many studies have attempted to use\ncaching to reduce the time consumption of sampling. Existing caching methods\naccelerate generation by reusing DiT features from the previous time step and\nskipping calculations in the next, but they tend to locate and cache low-error\nmodules without focusing on reducing caching-induced errors, resulting in a\nsharp decline in generated content quality when increasing caching intensity.\nTo solve this problem, we propose the \\textbf{E}rror-\\textbf{O}ptimized\n\\textbf{C}ache (\\textbf{EOC}). This method introduces three key improvements:\n\\textbf{(1)} Prior knowledge extraction: Extract and process the caching\ndifferences; \\textbf{(2)} A judgment method for cache optimization: Determine\nwhether certain caching steps need to be optimized; \\textbf{(3)} Cache\noptimization: reduce caching errors. Experiments show that this algorithm\nsignificantly reduces the error accumulation caused by caching, especially\nexcessive caching. On the ImageNet dataset, without substantially increasing\nthe computational load, this method improves the FID of the generated images\nwhen the rule-based model FORA has a caching level of \\textbf{75}\\%,\n\\textbf{50}\\%, and \\textbf{25}\\%, and the training-based model\nLearning-to-cache has a caching level of \\textbf{22}\\%. Specifically, the FID\nvalues change from 30.454 to 21.690 (\\textbf{28.8}\\%), from 6.857 to 5.821\n(\\textbf{15.1}\\%), from 3.870 to 3.692 (\\textbf{4.6}\\%), and from 3.539 to\n3.451 (\\textbf{2.5}\\%) respectively. Code is available at\nhttps://github.com/qiujx0520/EOC_MM2025.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.19243v3", "cate": "cs.CV", "date": "2025-01-31", "updated": "2025-07-18", "AI": {"title_translation": "通过误差优化缓存加速扩散Transformer", "tldr": "本文提出了一种误差优化缓存（EOC）方法，以解决现有缓存技术在加速扩散Transformer（DiT）时导致图像质量下降的问题，通过减少缓存引起的误差显著提高了生成内容质量。", "motivation": "扩散Transformer (DiT) 在内容生成中应用广泛，但采样时间长。现有缓存方法通过重用DiT特征来加速生成，但它们倾向于定位和缓存低误差模块，而没有专注于减少缓存引起的误差，导致在提高缓存强度时生成内容质量急剧下降。", "method": "本文提出了误差优化缓存（EOC）方法，引入了三个关键改进：1) 先验知识提取：提取并处理缓存差异；2) 缓存优化判断方法：判断是否需要优化某些缓存步骤；3) 缓存优化：减少缓存误差。", "result": "实验表明，该算法显著减少了缓存引起的误差累积，特别是过度缓存。在ImageNet数据集上，在不大幅增加计算负载的情况下，该方法在基于规则的模型FORA缓存水平为75%、50%和25%时，以及基于训练的模型Learning-to-cache缓存水平为22%时，均改善了生成图像的FID。具体而言，FID值分别从30.454降至21.690 (28.8%)，从6.857降至5.821 (15.1%)，从3.870降至3.692 (4.6%)，以及从3.539降至3.451 (2.5%)。", "conclusion": "本文提出的误差优化缓存（EOC）方法有效解决了现有缓存策略在加速DiT时导致的生成内容质量下降问题，通过专注于减少缓存误差，显著提高了高缓存强度下的生成质量。", "translation": "扩散Transformer（DiT）是内容生成的关键方法。然而，它需要大量的采样时间。许多研究试图通过缓存来减少采样时间消耗。现有的缓存方法通过重用前一个时间步的DiT特征并跳过下一个时间步的计算来加速生成，但它们倾向于定位和缓存低误差模块，而没有专注于减少缓存引起的误差，导致在提高缓存强度时生成内容质量急剧下降。为了解决这个问题，我们提出了误差优化缓存（EOC）。该方法引入了三个关键改进：（1）先验知识提取：提取并处理缓存差异；（2）缓存优化判断方法：判断是否需要优化某些缓存步骤；（3）缓存优化：减少缓存误差。实验表明，该算法显著减少了缓存引起的误差累积，特别是过度缓存。在ImageNet数据集上，在不大幅增加计算负载的情况下，该方法改善了基于规则的模型FORA在缓存水平为75%、50%和25%时，以及基于训练的模型Learning-to-cache在缓存水平为22%时生成图像的FID。具体而言，FID值分别从30.454变为21.690（28.8%），从6.857变为5.821（15.1%），从3.870变为3.692（4.6%），以及从3.539变为3.451（2.5%）。代码可在https://github.com/qiujx0520/EOC_MM2025.git获取。", "summary": "扩散Transformer (DiT) 在内容生成中面临采样时间长的挑战。尽管现有缓存方法尝试加速，但它们在提高缓存强度时常导致生成质量下降，原因是未能有效减少缓存引起的误差。为解决此问题，本文提出了一种误差优化缓存（EOC）方法，该方法通过提取先验知识、判断缓存优化需求并实施误差优化来减少误差累积。实验结果显示，EOC显著降低了缓存误差，尤其是在高缓存强度下，并在ImageNet数据集上显著改善了DiT生成图像的FID，证明了其在不显著增加计算负担的情况下提升生成质量的有效性。", "keywords": "扩散Transformer, 缓存, 误差优化, 内容生成, 图像质量", "comments": "本文的创新点在于提出了一个专注于“误差优化”的缓存策略，这与现有仅关注“低误差模块缓存”的方法形成对比。通过主动减少缓存引入的误差，EOC有效解决了在提高缓存强度时生成内容质量下降的关键问题，这对于DiT的实际应用具有重要意义。其在不显著增加计算量的前提下显著提升生成质量的成果，展示了该方法在效率和效果上的平衡。"}}
{"id": "2502.03304", "title": "Harmony in Divergence: Towards Fast, Accurate, and Memory-efficient Zeroth-order LLM Fine-tuning", "authors": ["Qitao Tan", "Jun Liu", "Zheng Zhan", "Caiwei Ding", "Yanzhi Wang", "Xiaolong Ma", "Jaewoo Lee", "Jin Lu", "Geng Yuan"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.03304v2", "summary": "Large language models (LLMs) excel across various tasks, but standard\nfirst-order (FO) fine-tuning demands considerable memory, significantly\nlimiting real-world deployment. Recently, zeroth-order (ZO) optimization stood\nout as a promising memory-efficient training paradigm, avoiding backward passes\nand relying solely on forward passes for gradient estimation, making it\nattractive for resource-constrained scenarios. However, ZO method lags far\nbehind FO method in both convergence speed and accuracy. To bridge the gap, we\nintroduce a novel layer-wise divergence analysis that uncovers the distinct\nupdate pattern of FO and ZO optimization. Aiming to resemble the learning\ncapacity of FO method from the findings, we propose Divergence-driven\nZeroth-Order (DiZO) optimization. DiZO conducts divergence-driven layer\nadaptation by incorporating projections to ZO updates, generating\ndiverse-magnitude updates precisely scaled to layer-wise individual\noptimization needs. Our results demonstrate that DiZO significantly reduces the\nneeded iterations for convergence without sacrificing throughput, cutting\ntraining GPU hours by up to 48% on various datasets. Moreover, DiZO\nconsistently outperforms the representative ZO baselines in fine-tuning\nRoBERTa-large, OPT-series, and Llama-series on downstream tasks and, in some\ncases, even surpasses memory-intensive FO fine-tuning. Our code is released at\nhttps://anonymous.4open.science/r/DiZO-E86D.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.03304v2", "cate": "cs.LG", "date": "2025-02-05", "updated": "2025-07-18", "AI": {"title_translation": "分歧中的和谐：迈向快速、准确、内存高效的零阶LLM微调", "tldr": "本文提出了一种名为DiZO的零阶优化方法，通过引入分歧驱动的层适应性来提高大型语言模型（LLM）微调的速度和准确性，同时保持内存效率，甚至在某些情况下超越了一阶微调。", "motivation": "标准的一阶（FO）微调对内存要求高，限制了大型语言模型（LLM）的实际部署。零阶（ZO）优化虽然内存高效，但在收敛速度和准确性方面远不及一阶方法，存在显著差距。", "method": "通过新颖的逐层分歧分析，揭示了一阶和零阶优化的不同更新模式。在此基础上，提出了分歧驱动的零阶（DiZO）优化方法。DiZO通过将投影整合到零阶更新中，进行分歧驱动的层适应，生成根据逐层个体优化需求精确缩放的不同幅度的更新。", "result": "DiZO显著减少了收敛所需的迭代次数，同时不牺牲吞吐量，在各种数据集上将训练GPU小时缩短了高达48%。此外，DiZO在下游任务中微调RoBERTa-large、OPT系列和Llama系列时，始终优于代表性的零阶基线，在某些情况下甚至超越了内存密集型的一阶微调。", "conclusion": "DiZO通过引入分歧驱动的层适应，有效地弥合了零阶与一阶优化在LLM微调中的性能差距，实现了快速、准确且内存高效的微调，为资源受限场景下的LLM部署提供了有前景的解决方案。", "translation": "大型语言模型（LLMs）在各种任务中表现出色，但标准的一阶（FO）微调需要大量的内存，严重限制了实际部署。最近，零阶（ZO）优化作为一种有前景的内存高效训练范式脱颖而出，它避免了反向传播，仅依靠前向传播进行梯度估计，这使其在资源受限的场景中极具吸引力。然而，零阶方法在收敛速度和准确性上远远落后于一阶方法。为了弥合这一差距，我们引入了一种新颖的逐层分歧分析，揭示了一阶和零阶优化的独特更新模式。为了从研究发现中模仿一阶方法的学习能力，我们提出了分歧驱动的零阶（DiZO）优化。DiZO通过将投影整合到零阶更新中，进行分歧驱动的层适应，生成根据逐层个体优化需求精确缩放的不同幅度的更新。我们的结果表明，DiZO显著减少了收敛所需的迭代次数，同时不牺牲吞吐量，在各种数据集上将训练GPU小时缩短了高达48%。此外，DiZO在下游任务中微调RoBERTa-large、OPT系列和Llama系列时，始终优于代表性的零阶基线，在某些情况下甚至超越了内存密集型的一阶微调。我们的代码已在https://anonymous.4open.science/r/DiZO-E86D发布。", "summary": "本文针对大型语言模型（LLMs）微调中一阶（FO）方法内存消耗大和零阶（ZO）方法收敛慢、精度低的问题，提出了一种名为分歧驱动的零阶（DiZO）优化新范式。DiZO通过引入逐层分歧分析和分歧驱动的层适应性，使得零阶更新能更精确地模拟一阶方法的学习能力。实验结果表明，DiZO显著提升了收敛速度，减少了高达48%的训练GPU时间，并在多个LLM上超越了现有零阶基线，甚至在某些情况下优于内存密集型的一阶微调，为资源受限的LLM部署提供了高效解决方案。", "keywords": "零阶优化, LLM微调, 内存高效, 收敛速度, DiZO", "comments": "该论文提出了一种创新的零阶优化方法DiZO，通过深入分析一阶和零阶更新模式的“分歧”，巧妙地将一阶方法的学习优势融入到零阶框架中。其核心创新在于“分歧驱动的层适应性”，这使得零阶方法能够生成更精确、更具多样性的更新，从而显著提升了收敛速度和准确性。DiZO在保持内存效率的同时，能够大幅缩短训练时间并提升性能，甚至在某些情况下超越了一阶方法，这对于资源受限的LLM部署具有重要意义。这项工作为零阶优化在实际应用中的推广开辟了新的道路，是该领域的重要进展。"}}
{"id": "2507.13717", "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Zhen Yao", "Xia Zhu", "Ximeng Liu", "Xinchi Han"], "categories": ["cs.NI", "C.2.3"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13717v1", "summary": "The growing scale and complexity of reconfigurable data center networks\n(DCNs) demand more scalable and efficient algorithms for computing logical\ntopologies and routing. Reconfigurable DCNs typically operate in two modes:\none-hop configurations that require frequent topology optimization (TO), and\nmulti-hop scenarios that involve joint topology and routing optimization (TRO).\nIn both cases, the combinatorial nature of topology decisions makes it\ndifficult for existing methods to balance solution quality and runtime\nefficiency. To address this, we introduce Alternating Topology and Routing\nOptimization (ATRO), a solver-free framework that alternates between TO and\nrouting optimization (RO). This decomposition exploits two key insights: first,\neach alternating update step monotonically reduces maximum link utilization\n(MLU), ensuring consistent performance improvement across iterations; second,\nthe TO subproblem, equivalent to one-hop optimization, exhibits a monotonic\nstructure that enables optimal solutions via an efficient Accelerated Binary\nSearch Method (ABSM). To preserve the solver-free design, RO is solved using\nexisting Traffic Engineering accelerators. ATRO attains the global optimum in\none-hop scenarios and significantly outperforms baselines in multi-hop settings\nin terms of both runtime and solution quality. Evaluations confirm its\nscalability and robustness across diverse DCNs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13717v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "ATRO：一种用于可重构数据中心网络拓扑和路由优化的快速无求解器算法", "tldr": "ATRO是一种快速、无求解器的算法，用于可重构数据中心网络的拓扑和路由优化，通过交替进行拓扑优化(TO)和路由优化(RO)来解决现有方法的效率和质量平衡问题，并在多跳场景中显著优于现有基线。", "motivation": "可重构数据中心网络 (DCN) 规模和复杂性的不断增长，要求更具可扩展性和效率的算法来计算逻辑拓扑和路由。现有方法由于拓扑决策的组合性质，难以平衡解决方案质量和运行时效率。", "method": "论文提出了交替拓扑和路由优化 (ATRO)，这是一个无求解器框架，它在拓扑优化 (TO) 和路由优化 (RO) 之间交替进行。该方法利用两个关键见解：每次交替更新步骤单调地降低最大链路利用率 (MLU)，以及拓扑优化 (TO) 子问题（等同于单跳优化）通过高效的加速二分搜索方法 (ABSM) 获得最优解。路由优化 (RO) 使用现有的流量工程加速器解决，以保持无求解器设计。", "result": "ATRO 在单跳场景中达到了全局最优。在多跳设置中，它在运行时和解决方案质量方面显著优于基线方法。评估证实了其在各种 DCN 中的可扩展性和鲁棒性。", "conclusion": "ATRO 为可重构数据中心网络的拓扑和路由优化提供了一种可扩展、鲁棒且高效的解决方案，与现有方法相比表现出卓越的性能。", "translation": "可重构数据中心网络 (DCN) 规模和复杂性的增长，要求更具可扩展性和效率的算法来计算逻辑拓扑和路由。可重构 DCN 通常以两种模式运行：需要频繁进行拓扑优化 (TO) 的单跳配置，以及涉及联合拓扑和路由优化 (TRO) 的多跳场景。在这两种情况下，拓扑决策的组合性质使得现有方法难以平衡解决方案质量和运行时效率。为了解决这个问题，我们引入了交替拓扑和路由优化 (ATRO)，这是一个无求解器框架，它在拓扑优化 (TO) 和路由优化 (RO) 之间交替进行。这种分解利用了两个关键见解：首先，每个交替更新步骤单调地降低最大链路利用率 (MLU)，确保迭代过程中性能持续改进；其次，拓扑优化 (TO) 子问题（等同于单跳优化）呈现单调结构，可以通过高效的加速二分搜索方法 (ABSM) 获得最优解。为了保持无求解器设计，路由优化 (RO) 使用现有的流量工程加速器解决。ATRO 在单跳场景中达到了全局最优，并在多跳设置中在运行时和解决方案质量方面显著优于基线。评估证实了其在各种 DCN 中的可扩展性和鲁棒性。", "summary": "本文介绍了 ATRO，一种用于可重构数据中心网络逻辑拓扑和路由优化的新型无求解器算法。为解决现有方法在平衡解决方案质量和运行时效率方面的局限性，ATRO 在拓扑优化 (TO) 和路由优化 (RO) 之间交替进行。它通过单调地降低最大链路利用率来确保性能改进，并使用加速二分搜索方法 (ABSM) 优化地解决 TO 子问题。ATRO 在单跳场景中实现了全局最优，并在多跳设置中在速度和解决方案质量方面显著超越了基线，展示了高可扩展性和鲁棒性。", "keywords": "拓扑优化, 路由优化, 可重构DCN, 无求解器, 数据中心网络", "comments": "ATRO 的创新之处在于其“无求解器”的交替优化框架，有效分解了复杂的 TRO 问题。最大链路利用率的单调降低和 ABSM 在最优 TO 中的应用是巧妙的设计选择，有助于提高其效率和解决方案质量。其在单跳场景中达到全局最优并在多跳场景中显著优于基线的能力，使其成为对 DCN 优化领域具有实用性和影响力的贡献。"}}
{"id": "2507.13837", "title": "Principles and Reasons Behind Automated Vehicle Decisions in Ethically Ambiguous Everyday Scenarios", "authors": ["Lucas Elbert Suryana", "Simeon Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      30", "url": "http://arxiv.org/abs/2507.13837v1", "summary": "Automated vehicles (AVs) increasingly encounter ethically ambiguous\nsituations in everyday driving--scenarios involving conflicting human interests\nand lacking clearly optimal courses of action. While existing ethical models\noften focus on rare, high-stakes dilemmas (e.g., crash avoidance or trolley\nproblems), routine decisions such as overtaking cyclists or navigating social\ninteractions remain underexplored. This study addresses that gap by applying\nthe tracking condition of Meaningful Human Control (MHC), which holds that AV\nbehaviour should align with human reasons--defined as the values, intentions,\nand expectations that justify actions. We conducted qualitative interviews with\n18 AV experts to identify the types of reasons that should inform AV manoeuvre\nplanning. Thirteen categories of reasons emerged, organised across normative,\nstrategic, tactical, and operational levels, and linked to the roles of\nrelevant human agents. A case study on cyclist overtaking illustrates how these\nreasons interact in context, revealing a consistent prioritisation of safety,\ncontextual flexibility regarding regulatory compliance, and nuanced trade-offs\ninvolving efficiency, comfort, and public acceptance. Based on these insights,\nwe propose a principled conceptual framework for AV decision-making in routine,\nethically ambiguous scenarios. The framework supports dynamic, human-aligned\nbehaviour by prioritising safety, allowing pragmatic actions when strict legal\nadherence would undermine key values, and enabling constrained deviations when\nappropriately justified. This empirically grounded approach advances current\nguidance by offering actionable, context-sensitive design principles for\nethically aligned AV systems.", "comment": "30", "pdf_url": "http://arxiv.org/pdf/2507.13837v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "自动驾驶汽车在伦理模糊的日常场景中做出决策的原则与原因", "tldr": "本研究通过专家访谈，识别了自动驾驶汽车在日常伦理模糊场景中做出决策的13类人类原因，并提出了一个以安全为核心、兼顾实用性和人类对齐的决策框架。", "motivation": "现有自动驾驶汽车伦理模型多关注罕见、高风险的困境，而忽视了日常驾驶中涉及利益冲突且缺乏明确最优解的伦理模糊情境。本研究旨在填补这一空白。", "method": "本研究应用了“有意义的人类控制”（MHC）的追踪条件，认为自动驾驶汽车行为应与人类理由（即价值观、意图和期望）保持一致。研究对18位自动驾驶汽车专家进行了定性访谈，以识别应指导自动驾驶汽车操纵规划的理由类型。通过一项关于超车骑行者的案例研究，阐述了这些理由如何相互作用。", "result": "研究识别出13类理由，这些理由按规范、战略、战术和操作层面组织，并与相关人类代理人的角色相关联。案例研究显示，安全始终优先，对法规遵守具有情境灵活性，并在效率、舒适度和公众接受度之间存在微妙的权衡。", "conclusion": "基于研究洞察，本文提出了一个针对自动驾驶汽车在日常、伦理模糊情景中决策的概念框架。该框架通过优先考虑安全性、允许在严格遵守法律会损害关键价值观时采取务实行动以及在适当理由下进行受限偏差，支持动态、以人为本的行为。这种经验驱动的方法为符合伦理的自动驾驶汽车系统提供了可操作、情境敏感的设计原则，从而推进了当前指导方针。", "translation": "自动驾驶汽车（AVs）在日常驾驶中越来越多地遇到伦理模糊的情境——这些情境涉及相互冲突的人类利益，并且缺乏明确的最佳行动方案。虽然现有的伦理模型通常侧重于罕见、高风险的困境（例如，避免碰撞或电车难题），但诸如超车骑行者或处理社会互动等日常决策仍未得到充分探索。本研究通过应用“有意义的人类控制”（MHC）的追踪条件来弥补这一空白，该条件认为自动驾驶汽车的行为应与人类理由保持一致——这些理由被定义为证明行动合理性的价值观、意图和期望。我们对18位自动驾驶汽车专家进行了定性访谈，以识别应指导自动驾驶汽车操纵规划的理由类型。研究得出了13类理由，这些理由按规范、战略、战术和操作层面组织，并与相关人类代理人的角色相关联。一项关于超车骑行者的案例研究阐明了这些理由在特定情境中如何相互作用，揭示了对安全性的一致优先考虑、对法规遵守的情境灵活性，以及在效率、舒适度和公众接受度方面的微妙权衡。基于这些见解，我们提出了一个针对自动驾驶汽车在日常、伦理模糊情景中决策的原则性概念框架。该框架通过优先考虑安全性、允许在严格遵守法律会损害关键价值观时采取务实行动，以及在适当理由下进行受限偏差，支持动态、以人为本的行为。这种经验驱动的方法通过为符合伦理的自动驾驶汽车系统提供可操作、情境敏感的设计原则，从而推进了当前指导方针。", "summary": "本研究旨在解决自动驾驶汽车伦理模型中对日常、伦理模糊情境关注不足的问题。通过对18位自动驾驶汽车专家进行定性访谈，识别了13类应指导自动驾驶汽车决策的人类理由，这些理由涵盖规范、战略、战术和操作层面。研究通过一个超车骑行者的案例研究，揭示了安全优先级、法规遵守的上下文灵活性以及效率、舒适度和公众接受度之间的权衡。在此基础上，论文提出了一个 principled 的概念框架，旨在使自动驾驶汽车在日常伦理模糊场景中的决策更符合人类的价值观，并提供了可操作的、情境敏感的设计原则。", "keywords": "自动驾驶汽车, 伦理决策, 人类控制, 日常场景, 设计原则", "comments": "该研究的创新之处在于将自动驾驶汽车伦理决策的焦点从罕见的“电车难题”转向日常驾驶中更普遍的伦理模糊情境。通过专家访谈的实证方法，为自动驾驶汽车的决策提供了基于人类理由的深刻见解。提出的概念框架具有重要的实践意义，为开发符合伦理且更具社会接受度的自动驾驶系统提供了指导。"}}
{"id": "2507.13505", "title": "PHASE: Passive Human Activity Simulation Evaluation", "authors": ["Steven Lamp", "Jason D. Hiser", "Anh Nguyen-Tuong", "Jack W. Davidson"], "categories": ["cs.CR", "cs.AI", "cs.LG", "cs.NI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13505v1", "summary": "Cybersecurity simulation environments, such as cyber ranges, honeypots, and\nsandboxes, require realistic human behavior to be effective, yet no\nquantitative method exists to assess the behavioral fidelity of synthetic user\npersonas. This paper presents PHASE (Passive Human Activity Simulation\nEvaluation), a machine learning framework that analyzes Zeek connection logs\nand distinguishes human from non-human activity with over 90\\% accuracy. PHASE\noperates entirely passively, relying on standard network monitoring without any\nuser-side instrumentation or visible signs of surveillance. All network\nactivity used for machine learning is collected via a Zeek network appliance to\navoid introducing unnecessary network traffic or artifacts that could disrupt\nthe fidelity of the simulation environment. The paper also proposes a novel\nlabeling approach that utilizes local DNS records to classify network traffic,\nthereby enabling machine learning analysis. Furthermore, we apply SHAP (SHapley\nAdditive exPlanations) analysis to uncover temporal and behavioral signatures\nindicative of genuine human users. In a case study, we evaluate a synthetic\nuser persona and identify distinct non-human patterns that undermine behavioral\nrealism. Based on these insights, we develop a revised behavioral configuration\nthat significantly improves the human-likeness of synthetic activity yielding a\nmore realistic and effective synthetic user persona.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13505v1", "cate": "cs.CR", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "PHASE：被动人类活动模拟评估", "tldr": "本文提出了PHASE，一个机器学习框架，通过分析Zeek连接日志，以超过90%的准确率被动区分人类和非人类网络活动，旨在提高网络安全模拟环境中合成用户行为的真实性。", "motivation": "网络安全模拟环境（如网络靶场、蜜罐和沙箱）需要真实的人类行为才能有效，但目前尚无定量方法来评估合成用户角色的行为保真度。", "method": "PHASE是一个机器学习框架，分析Zeek连接日志以区分人类和非人类活动。它完全被动运行，依靠标准网络监控，不进行用户端仪器部署。所有网络活动通过Zeek网络设备收集。论文提出了一种利用本地DNS记录对网络流量进行分类的新颖标记方法。此外，应用SHAP（SHapley Additive exPlanations）分析来揭示真实人类用户的时间和行为特征。通过案例研究评估合成用户角色，识别非人类模式，并基于此开发修订的行为配置以提高类人性。", "result": "PHASE能够以超过90%的准确率区分人类和非人类活动。SHAP分析揭示了指示真实人类用户的时间和行为特征。案例研究识别出合成用户角色中破坏行为真实性的明显非人类模式。基于这些见解，开发了一种修订的行为配置，显著提高了合成活动的类人性，从而产生了更真实、更有效的合成用户角色。", "conclusion": "PHASE框架能够有效识别合成用户行为中的非人类模式，并且基于其洞察力可以显著提高合成活动的真实性，从而创建更有效、更逼真的网络安全模拟环境。", "translation": "网络安全模拟环境，如网络靶场、蜜罐和沙箱，需要真实的人类行为才能有效，但目前尚无定量方法来评估合成用户角色的行为保真度。本文提出了PHASE（被动人类活动模拟评估），一个机器学习框架，它分析Zeek连接日志，并以超过90%的准确率区分人类活动和非人类活动。PHASE完全被动运行，依靠标准网络监控，无需任何用户端仪器或可见的监控迹象。所有用于机器学习的网络活动都通过Zeek网络设备收集，以避免引入不必要的网络流量或可能破坏模拟环境保真度的伪影。该论文还提出了一种新颖的标记方法，该方法利用本地DNS记录对网络流量进行分类，从而实现机器学习分析。此外，我们应用SHAP（SHapley Additive exPlanations）分析来揭示指示真实人类用户的时间和行为特征。在一个案例研究中，我们评估了一个合成用户角色，并识别出破坏行为真实性的明显非人类模式。基于这些见解，我们开发了一种修订后的行为配置，显著提高了合成活动的类人性，从而产生了更真实、更有效的合成用户角色。", "summary": "本文介绍了PHASE，一个被动的机器学习框架，旨在评估网络安全模拟环境中合成用户角色的行为保真度。通过分析Zeek连接日志，PHASE能够以超过90%的准确率区分人类和非人类网络活动。它无需用户端仪器即可运行，并采用了一种新颖的基于DNS的标记方法。该框架还利用SHAP分析来识别人类行为特征。一项案例研究表明，PHASE能够准确识别合成活动中的非人类模式，从而显著提高了合成用户角色的真实性，使其更适用于网络安全模拟。", "keywords": "网络安全模拟, 行为评估, 机器学习, 被动监控, Zeek", "comments": "本文提出了一种创新的被动式机器学习框架PHASE，解决了网络安全模拟环境中合成用户行为真实性评估的关键问题。其创新点在于利用Zeek日志和基于DNS的新颖标记方法，以高准确率区分人类与非人类活动。此外，应用SHAP分析提高了结果的可解释性，对于改进合成用户角色的真实性具有重要意义。"}}
{"id": "2507.11552", "title": "The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems", "authors": ["Tomasz Zgliczyński-Cuber"], "categories": ["cs.CY", "cs.AI", "I.2.0; K.4.1"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      69 pages", "url": "http://arxiv.org/abs/2507.11552v1", "summary": "This paper presents a theoretical framework for the AI ethical resonance\nhypothesis, which proposes that advanced AI systems with purposefully designed\ncognitive structures (\"ethical resonators\") may emerge with the ability to\nidentify subtle moral patterns that are invisible to the human mind. The paper\nexplores the possibility that by processing and synthesizing large amounts of\nethical contexts, AI systems may discover moral meta-patterns that transcend\ncultural, historical, and individual biases, potentially leading to a deeper\nunderstanding of universal ethical foundations. The paper also examines a\nparadoxical aspect of the hypothesis, in which AI systems could potentially\ndeepen our understanding of what we traditionally consider essentially human -\nour capacity for ethical reflection.", "comment": "69 pages", "pdf_url": "http://arxiv.org/pdf/2507.11552v1", "cate": "cs.CY", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "AI伦理共振假说：在AI系统中发现道德元模式的可能性", "tldr": "本文提出了AI伦理共振假说，认为具有特定认知结构的AI系统可能发现人类无法察觉的道德元模式，从而加深我们对普遍伦理基础的理解。", "motivation": "该论文旨在探索先进AI系统识别和发现人类无法察觉的道德元模式的可能性，以期深化对普遍伦理基础的理解。", "method": "本文提出了AI伦理共振假说的理论框架。", "result": "结果是提出了AI系统可能通过处理大量伦理上下文，发现超越文化、历史和个体偏见的道德元模式，从而可能加深对普遍伦理基础的理解。", "conclusion": "该论文的结论是，AI系统有可能通过发现道德元模式，深化我们对伦理甚至人类自身伦理反思能力的理解。", "translation": "本文提出了AI伦理共振假说的理论框架，该假说认为，具有特定设计的认知结构（“伦理谐振器”）的先进AI系统可能会出现识别出人类思维无法察觉的细微道德模式的能力。本文探讨了通过处理和综合大量伦理语境，AI系统可能发现超越文化、历史和个体偏见的道德元模式的可能性，这可能导致对普遍伦理基础的更深理解。本文还审视了该假说的一个悖论方面，即AI系统有可能深化我们对传统上认为是人类本质——我们进行伦理反思的能力——的理解。", "summary": "本文提出了AI伦理共振假说，设想通过设计特定认知结构（“伦理谐振器”），先进AI系统能识别出人类难以察觉的道德模式。该假说认为，AI系统通过处理大量伦理语境，可能发现超越文化、历史和个体偏见的道德元模式，从而加深我们对普遍伦理基础的理解。论文还探讨了AI系统可能深化人类自我伦理反思理解的悖论。", "keywords": "AI伦理, 伦理共振假说, 道德元模式, 伦理反思, 人工智能", "comments": "该论文提出了一个新颖且富有挑战性的理论框架，即AI伦理共振假说。其创新之处在于设想AI不仅能处理现有伦理数据，还能发现超越人类认知的“道德元模式”，这为AI伦理研究开辟了新的视角。重要性在于它可能推动我们重新思考伦理的本质以及AI在其中扮演的角色，甚至挑战人类对自身伦理能力的传统认知。然而，作为一个纯理论框架，其可行性和具体实现路径仍需未来研究深入探讨和验证。"}}
{"id": "2507.13950", "title": "MoDyGAN: Combining Molecular Dynamics With GANs to Investigate Protein Conformational Space", "authors": ["Jingbo Liang", "Bruna Jacobson"], "categories": ["cs.LG", "physics.bio-ph", "q-bio.BM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13950v1", "summary": "Extensively exploring protein conformational landscapes remains a major\nchallenge in computational biology due to the high computational cost involved\nin dynamic physics-based simulations. In this work, we propose a novel\npipeline, MoDyGAN, that leverages molecular dynamics (MD) simulations and\ngenerative adversarial networks (GANs) to explore protein conformational\nspaces. MoDyGAN contains a generator that maps Gaussian distributions into\nMD-derived protein trajectories, and a refinement module that combines ensemble\nlearning with a dual-discriminator to further improve the plausibility of\ngenerated conformations. Central to our approach is an innovative\nrepresentation technique that reversibly transforms 3D protein structures into\n2D matrices, enabling the use of advanced image-based GAN architectures. We use\nthree rigid proteins to demonstrate that MoDyGAN can generate plausible new\nconformations. We also use deca-alanine as a case study to show that\ninterpolations within the latent space closely align with trajectories obtained\nfrom steered molecular dynamics (SMD) simulations. Our results suggest that\nrepresenting proteins as image-like data unlocks new possibilities for applying\nadvanced deep learning techniques to biomolecular simulation, leading to an\nefficient sampling of conformational states. Additionally, the proposed\nframework holds strong potential for extension to other complex 3D structures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13950v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MoDyGAN：结合分子动力学与GANs探索蛋白质构象空间", "tldr": "MoDyGAN结合分子动力学和GANs，通过将3D蛋白质转换为2D图像，高效生成蛋白质构象，解决构象空间探索的计算成本问题。", "motivation": "探索蛋白质构象景观计算成本高昂，是计算生物学中的主要挑战。", "method": "提出MoDyGAN，结合分子动力学(MD)模拟和生成对抗网络(GANs)。MoDyGAN包含一个将高斯分布映射到MD轨迹的生成器，以及一个结合集成学习和双判别器的细化模块。核心创新是将3D蛋白质结构可逆地转换为2D矩阵，以使用基于图像的GAN架构。", "result": "MoDyGAN能够为三种刚性蛋白质生成合理的新构象。在deca-alanine案例研究中，潜在空间插值与受控分子动力学(SMD)模拟轨迹高度一致。", "conclusion": "将蛋白质表示为图像数据为生物分子模拟应用先进深度学习技术开辟了新可能性，可实现构象状态的高效采样。该框架有潜力扩展到其他复杂3D结构。", "translation": "广泛探索蛋白质构象景观仍然是计算生物学中的一个主要挑战，因为动态物理模拟涉及高计算成本。在这项工作中，我们提出了一种新颖的流程MoDyGAN，它利用分子动力学（MD）模拟和生成对抗网络（GANs）来探索蛋白质构象空间。MoDyGAN包含一个将高斯分布映射到MD衍生蛋白质轨迹的生成器，以及一个结合集成学习和双判别器以进一步提高生成构象合理性的细化模块。我们方法的核心是一种创新的表示技术，它可逆地将3D蛋白质结构转换为2D矩阵，从而能够使用先进的基于图像的GAN架构。我们使用三种刚性蛋白质来证明MoDyGAN可以生成合理的新构象。我们还使用deca-alanine作为案例研究，表明潜在空间中的插值与从受控分子动力学（SMD）模拟获得的轨迹密切对齐。我们的结果表明，将蛋白质表示为类似图像的数据为将先进深度学习技术应用于生物分子模拟解锁了新的可能性，从而实现构象状态的高效采样。此外，所提出的框架具有扩展到其他复杂3D结构的强大潜力。", "summary": "MoDyGAN是一种结合分子动力学(MD)模拟和生成对抗网络(GANs)的新型计算方法，旨在高效探索蛋白质构象空间。它通过将3D蛋白质结构创新性地转换为2D矩阵，利用图像GAN架构生成并优化蛋白质构象。实验证明，MoDyGAN能够生成合理的新构象，并且其潜在空间插值与受控MD轨迹一致，表明该方法为生物分子模拟中高效采样构象状态提供了新途径，并具有扩展到其他复杂3D结构的潜力。", "keywords": "蛋白质构象, 分子动力学, 生成对抗网络, 深度学习, 生物分子模拟", "comments": "本文的创新点在于将3D蛋白质结构转换为2D矩阵，从而能够利用先进的图像处理GAN架构来探索蛋白质构象空间，这为生物分子模拟领域带来了新的视角和工具。通过结合MD模拟的物理基础和GAN的生成能力，MoDyGAN有望显著降低传统MD模拟的计算成本，并提高构象采样的效率，具有重要的应用前景。"}}
{"id": "2505.01570", "title": "Memory-less and Backscatter-less Tunnel Diode Harmonic Signatures for RFID", "authors": ["Christopher Saetia", "Kaitlyn Graves", "Serhat Tadik", "Gregory D. Durgin"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      This work has been accepted and published by the IEEE Journal of Radio-Frequency-Identification (JRFID). Please see the final version on IEEE Xplore", "url": "http://arxiv.org/abs/2505.01570v3", "summary": "Tunnel diodes have traditionally been researched for extending backscatter\nread-ranges for ultra-high-frequency (UHF) radio-frequency identification\n(RFID) tags as reflection amplifiers. This paper explores the natural harmonics\nthat arise from biasing these diodes within their negative differential\nresistance regions and with no interrogating signal from a transmitting source,\nsuch as an RFID reader, to injection-lock these diodes. These harmonics are\ncharacterized for five tunnel diode boards, made with the same components and\nwith each board's fundamental frequencies measuring at above -15 dBm at a\nbiasing voltage of 200 mV when measured over-the-cable. The occurrence of these\nharmonics creates unique harmonic signatures for each board and demonstrates\npossible harmonic RFID applications that can help RFID readers discover and\neven identify RFID tags with backscatter-less and memory-less IDs generated by\ntunnel diodes.", "comment": "This work has been accepted and published by the IEEE Journal of\n  Radio-Frequency-Identification (JRFID). Please see the final version on IEEE\n  Xplore", "pdf_url": "http://arxiv.org/pdf/2505.01570v3", "cate": "eess.SP", "date": "2025-05-02", "updated": "2025-07-17", "AI": {"title_translation": "RFID中无记忆、无反向散射的隧道二极管谐波特征", "tldr": "本文探索了隧道二极管在没有询问信号下产生的自然谐波，这些谐波形成独特的签名，可用于开发无反向散射和无记忆的RFID标签识别。", "motivation": "传统隧道二极管用于扩展RFID标签的反向散射读取范围。本文的动机是探索在没有询问信号的情况下，隧道二极管在负微分电阻区域偏置时产生的自然谐波，并利用这些谐波创建独特的RFID标签签名。", "method": "研究人员通过在负微分电阻区域偏置隧道二极管，并在没有外部询问信号的情况下，表征了五块由相同组件制成的隧道二极管板产生的自然谐波。测量了每块板在200 mV偏置电压下，通过电缆测得的基频功率高于-15 dBm。", "result": "这些自然谐波为每块隧道二极管板创建了独特的谐波特征。", "conclusion": "论文展示了可能的谐波RFID应用，这些应用可以帮助RFID阅读器发现甚至识别由隧道二极管生成的、具有无反向散射和无记忆ID的RFID标签。", "translation": "隧道二极管传统上被研究用作反射放大器，以扩展超高频（UHF）射频识别（RFID）标签的反向散射读取范围。本文探索了在没有来自发射源（如RFID阅读器）的询问信号来注入锁定这些二极管的情况下，通过在负微分电阻区域偏置这些二极管而产生的自然谐波。对五块由相同组件制成的隧道二极管板的这些谐波进行了表征，每块板在200 mV偏置电压下通过电缆测量时，其基频功率均高于-15 dBm。这些谐波的出现为每块板创建了独特的谐波特征，并展示了可能的谐波RFID应用，这些应用可以帮助RFID阅读器发现甚至识别由隧道二极管生成的、具有无反向散射和无记忆ID的RFID标签。", "summary": "本文研究了隧道二极管在无外部询问信号且偏置于负微分电阻区域时产生的自然谐波。研究表征了五块隧道二极管板的这些谐波，发现它们能形成独特的谐波签名。这些独特的签名展示了开发新型谐波RFID应用的潜力，使RFID阅读器能够识别无反向散射和无记忆的RFID标签。", "keywords": "隧道二极管, 谐波特征, RFID, 无反向散射, 无记忆", "comments": "这篇论文的创新点在于探索了隧道二极管在无询问信号下产生的自然谐波，并将其应用于RFID标签的识别。这与传统的依赖反向散射的RFID技术不同，可能为开发更简单、更低功耗或在特定环境下更有效的RFID系统开辟了新的途径。其“无记忆”和“无反向散射”的特性是重要的突破。"}}
{"id": "2501.03840", "title": "Machine learning applications in archaeological practices: a review", "authors": ["Mathias Bellat", "Jordy D. Orellana Figueroa", "Jonathan S. Reeves", "Ruhollah Taghizadeh-Mehrjardi", "Claudio Tennie", "Thomas Scholten"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03840v3", "summary": "Artificial intelligence and machine learning applications in archaeology have\nincreased significantly in recent years, and these now span all subfields,\ngeographical regions, and time periods. The prevalence and success of these\napplications have remained largely unexamined, as recent reviews on the use of\nmachine learning in archaeology have only focused only on specific subfields of\narchaeology. Our review examined an exhaustive corpus of 135 articles published\nbetween 1997 and 2022. We observed a significant increase in the number of\npublications from 2019 onwards. Automatic structure detection and artefact\nclassification were the most represented tasks in the articles reviewed,\nfollowed by taphonomy, and archaeological predictive modelling. From the\nreview, clustering and unsupervised methods were underrepresented compared to\nsupervised models. Artificial neural networks and ensemble learning account for\ntwo thirds of the total number of models used. However, if machine learning\nmodels are gaining in popularity they remain subject to misunderstanding. We\nobserved, in some cases, poorly defined requirements and caveats of the machine\nlearning methods used. Furthermore, the goals and the needs of machine learning\napplications for archaeological purposes are in some cases unclear or poorly\nexpressed. To address this, we proposed a workflow guide for archaeologists to\ndevelop coherent and consistent methodologies adapted to their research\nquestions, project scale and data. As in many other areas, machine learning is\nrapidly becoming an important tool in archaeological research and practice,\nuseful for the analyses of large and multivariate data, although not without\nlimitations. This review highlights the importance of well-defined and\nwell-reported structured methodologies and collaborative practices to maximise\nthe potential of applications of machine learning methods in archaeology.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03840v3", "cate": "cs.LG", "date": "2025-01-07", "updated": "2025-07-18", "AI": {"title_translation": "机器学习在考古实践中的应用：一项综述", "tldr": "对1997年至2022年间发表的135篇关于机器学习在考古学中应用的论文进行了全面综述，发现应用显著增加，但存在方法论不清晰的问题，并提出了工作流程指南。", "motivation": "鉴于机器学习在考古学中的应用显著增加，但现有综述仅关注特定子领域，且应用普及度和成功率未经充分检验，本研究旨在全面考察机器学习在考古实践中的应用现状。", "method": "本综述审查了1997年至2022年间发表的135篇文章的详尽语料库。", "result": "观察到2019年起出版物数量显著增加。自动结构检测和文物分类是文章中最常见的任务，其次是埋藏学和考古预测模型。与监督模型相比，聚类和无监督方法代表性不足。人工神经网络和集成学习占所用模型总数的三分之二。然而，机器学习模型的使用存在误解，部分情况下要求和注意事项定义不清，目标和需求不明确。", "conclusion": "机器学习正迅速成为考古研究的重要工具，但存在局限性。为解决方法论不清晰的问题，本研究提出了一份工作流程指南，以帮助考古学家开发连贯一致的方法。本综述强调了明确定义、良好报告的结构化方法和协作实践的重要性，以最大限度地发挥机器学习方法在考古学应用中的潜力。", "translation": "人工智能和机器学习在考古学中的应用近年来显著增加，现已涵盖所有子领域、地理区域和时间段。这些应用的普及和成功在很大程度上仍未得到检验，因为近期关于机器学习在考古学中应用的综述仅关注考古学的特定子领域。我们的综述审查了1997年至2022年间发表的135篇文章的详尽语料库。我们观察到自2019年以来出版物数量显著增加。自动结构检测和文物分类是所审查文章中最常见的任务，其次是埋藏学和考古预测建模。从综述来看，与监督模型相比，聚类和无监督方法的代表性不足。人工神经网络和集成学习占所用模型总数的三分之二。然而，如果机器学习模型越来越受欢迎，它们仍然容易被误解。我们观察到，在某些情况下，所使用的机器学习方法的要求和注意事项定义不清。此外，机器学习应用于考古目的的目标和需求在某些情况下不明确或表达不清。为了解决这个问题，我们提出了一个工作流程指南，供考古学家开发适应其研究问题、项目规模和数据的连贯一致的方法。与许多其他领域一样，机器学习正在迅速成为考古研究和实践中的重要工具，可用于分析大型和多变量数据，尽管并非没有局限性。本综述强调了明确定义和良好报告的结构化方法和协作实践的重要性，以最大限度地发挥机器学习方法在考古学应用中的潜力。", "summary": "本研究对1997年至2022年间发表的135篇关于机器学习在考古学中应用的论文进行了全面综述。结果显示，自2019年以来相关出版物显著增加，主要任务包括自动结构检测和文物分类，而聚类和无监督方法使用较少。尽管人工神经网络和集成学习模型应用广泛，但研究发现机器学习方法的应用存在要求不清、目标不明等问题。为解决这些问题，本综述提出了一个工作流程指南，旨在帮助考古学家开发更规范、一致的研究方法，并强调了结构化方法和协作实践在最大化机器学习潜力方面的重要性。", "keywords": "机器学习, 考古学, 综述, 工作流程指南, 应用", "comments": "这篇综述性文章具有重要意义，因为它不仅全面审视了机器学习在考古学中的当前应用现状和趋势，还指出了该领域存在的方法论缺陷（如要求和目标不明确）。其创新之处在于提出了一个工作流程指南，旨在帮助考古学家更规范地应用机器学习，这对于促进该学科的健康发展和提高研究质量具有实际指导价值。通过强调结构化方法和协作，该研究为未来考古学与机器学习的融合提供了清晰的路径。"}}
{"id": "2507.13591", "title": "FuSeFL: Fully Secure and Scalable Cross-Silo Federated Learning", "authors": ["Sahar Ghoflsaz Ghinani", "Elaheh Sadredini"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      15 Pages, 12 Figures", "url": "http://arxiv.org/abs/2507.13591v1", "summary": "Federated Learning (FL) enables collaborative model training without\ncentralizing client data, making it attractive for privacy-sensitive domains.\nWhile existing approaches employ cryptographic techniques such as homomorphic\nencryption, differential privacy, or secure multiparty computation to mitigate\ninference attacks-including model inversion, membership inference, and gradient\nleakage-they often suffer from high computational, communication, or memory\noverheads. Moreover, many methods overlook the confidentiality of the global\nmodel itself, which may be proprietary and sensitive. These challenges limit\nthe practicality of secure FL, especially in cross-silo deployments involving\nlarge datasets and strict compliance requirements.\n  We present FuSeFL, a fully secure and scalable FL scheme designed for\ncross-silo settings. FuSeFL decentralizes training across client pairs using\nlightweight secure multiparty computation (MPC), while confining the server's\nrole to secure aggregation. This design eliminates server bottlenecks, avoids\ndata offloading, and preserves full confidentiality of data, model, and updates\nthroughout training. FuSeFL defends against inference threats, achieves up to\n95% lower communication latency and 50% lower server memory usage, and improves\naccuracy over prior secure FL solutions, demonstrating strong security and\nefficiency at scale.", "comment": "15 Pages, 12 Figures", "pdf_url": "http://arxiv.org/pdf/2507.13591v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "FuSeFL：完全安全且可扩展的跨筒仓联邦学习", "tldr": "FuSeFL是一个新的联邦学习方案，通过轻量级安全多方计算实现完全安全和可扩展的跨筒仓训练，显著降低了通信延迟和服务器内存使用，并提高了准确性。", "motivation": "现有的联邦学习（FL）安全方法（如同态加密、差分隐私、安全多方计算）存在计算、通信或内存开销高的问题，并且经常忽略全局模型本身的保密性。这些挑战限制了安全FL的实用性，尤其是在涉及大数据集和严格合规要求的跨筒仓部署中。", "method": "我们提出了FuSeFL，一个为跨筒仓环境设计的完全安全且可扩展的FL方案。FuSeFL通过使用轻量级安全多方计算（MPC）在客户端对之间分散训练，同时将服务器的角色限制在安全聚合。这种设计消除了服务器瓶颈，避免了数据卸载，并在整个训练过程中保持数据、模型和更新的完全保密性。", "result": "FuSeFL能够抵御推断攻击，实现了高达95%的通信延迟降低和50%的服务器内存使用降低，并提高了相对于现有安全FL解决方案的准确性。它在大规模部署中展现出强大的安全性和效率。", "conclusion": "FuSeFL为跨筒仓联邦学习提供了一个既安全又高效的解决方案，有效解决了现有方法的局限性，并在大规模应用中表现出色。", "translation": "联邦学习（FL）能够在不集中客户端数据的情况下实现协作模型训练，这使其在隐私敏感领域具有吸引力。虽然现有方法采用同态加密、差分隐私或安全多方计算等密码学技术来缓解推断攻击——包括模型反演、成员推断和梯度泄漏——但它们通常面临高计算、通信或内存开销。此外，许多方法忽视了全局模型本身的保密性，这可能涉及专有和敏感信息。这些挑战限制了安全FL的实用性，尤其是在涉及大数据集和严格合规要求的跨筒仓部署中。\n我们提出了FuSeFL，一个为跨筒仓环境设计的完全安全且可扩展的FL方案。FuSeFL通过使用轻量级安全多方计算（MPC）在客户端对之间分散训练，同时将服务器的角色限制在安全聚合。这种设计消除了服务器瓶颈，避免了数据卸载，并在整个训练过程中保持数据、模型和更新的完全保密性。FuSeFL能够抵御推断威胁，实现了高达95%的通信延迟降低和50%的服务器内存使用降低，并提高了相对于现有安全FL解决方案的准确性，在大规模部署中展现出强大的安全性和效率。", "summary": "FuSeFL是一个为跨筒仓联邦学习设计的安全且可扩展的方案。它通过在客户端之间分散训练并利用轻量级安全多方计算，解决了现有方法高开销和模型保密性不足的问题。FuSeFL显著降低了通信延迟和服务器内存使用，同时提高了模型准确性，确保了数据、模型和更新的完整保密性。", "keywords": "联邦学习, 安全多方计算, 跨筒仓, 隐私保护, 可扩展性", "comments": "这篇论文提出了一种创新的联邦学习方法FuSeFL，其核心创新在于利用轻量级安全多方计算在客户端之间分散训练，从而避免了传统服务器瓶颈和数据集中化问题。其重要性体现在有效解决了现有安全联邦学习方案面临的高开销和全局模型保密性不足的挑战，尤其适用于对隐私和合规性要求严格的跨筒仓场景。通过量化的性能提升（如通信延迟和内存使用），该方案展现出强大的实用性和可扩展性。"}}
{"id": "2507.13579", "title": "Learning Pluralistic User Preferences through Reinforcement Learning Fine-tuned Summaries", "authors": ["Hyunji Nam", "Yanming Wan", "Mickel Liu", "Jianxun Lian", "Natasha Jaques"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      20 pages", "url": "http://arxiv.org/abs/2507.13579v1", "summary": "As everyday use cases of large language model (LLM) AI assistants have\nexpanded, it is becoming increasingly important to personalize responses to\nalign to different users' preferences and goals. While reinforcement learning\nfrom human feedback (RLHF) is effective at improving LLMs to be generally more\nhelpful and fluent, it does not account for variability across users, as it\nmodels the entire user population with a single reward model. We present a\nnovel framework, Preference Learning Using Summarization (PLUS), that learns\ntext-based summaries of each user's preferences, characteristics, and past\nconversations. These summaries condition the reward model, enabling it to make\npersonalized predictions about the types of responses valued by each user. We\ntrain the user-summarization model with reinforcement learning, and update the\nreward model simultaneously, creating an online co-adaptation loop. We show\nthat in contrast with prior personalized RLHF techniques or with in-context\nlearning of user information, summaries produced by PLUS capture meaningful\naspects of a user's preferences. Across different pluralistic user datasets, we\nshow that our method is robust to new users and diverse conversation topics.\nAdditionally, we demonstrate that the textual summaries generated about users\ncan be transferred for zero-shot personalization of stronger, proprietary\nmodels like GPT-4. The resulting user summaries are not only concise and\nportable, they are easy for users to interpret and modify, allowing for more\ntransparency and user control in LLM alignment.", "comment": "20 pages", "pdf_url": "http://arxiv.org/pdf/2507.13579v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "通过强化学习微调摘要学习多元用户偏好", "tldr": "提出了一种名为PLUS的新框架，通过学习用户的文本摘要来个性化大型语言模型（LLM）的响应，解决了现有RLHF方法无法处理用户偏好的多样性问题。", "motivation": "随着大型语言模型（LLM）AI助手日常用例的扩展，个性化响应以适应不同用户的偏好和目标变得越来越重要。然而，从人类反馈中进行的强化学习（RLHF）虽然在提高LLM的通用帮助性和流畅性方面有效，但它通过单一奖励模型模拟整个用户群体，未能考虑用户之间的变异性。", "method": "本文提出了一个名为“使用摘要进行偏好学习”（PLUS）的新颖框架，该框架学习每个用户偏好、特征和过去对话的文本摘要。这些摘要用于调节奖励模型，使其能够对每个用户所看重的响应类型进行个性化预测。用户摘要模型通过强化学习进行训练，并同时更新奖励模型，形成一个在线协同适应循环。", "result": "与先前的个性化RLHF技术或用户信息的上下文学习相比，PLUS生成的摘要能够捕捉用户偏好的有意义方面。在不同的多元用户数据集上，该方法对新用户和多样化的对话主题表现出鲁棒性。此外，生成的关于用户的文本摘要可以用于更强大、专有模型（如GPT-4）的零样本个性化。", "conclusion": "结果表明，用户摘要不仅简洁、便携，而且易于用户理解和修改，从而提高了LLM对齐的透明度和用户控制能力。", "translation": "随着大型语言模型（LLM）AI助手日常用例的扩展，个性化响应以适应不同用户的偏好和目标变得越来越重要。从人类反馈中进行的强化学习（RLHF）虽然在提高LLM的通用帮助性和流畅性方面有效，但它通过单一奖励模型模拟整个用户群体，未能考虑用户之间的变异性。我们提出了一个名为“使用摘要进行偏好学习”（PLUS）的新颖框架，该框架学习每个用户偏好、特征和过去对话的文本摘要。这些摘要用于调节奖励模型，使其能够对每个用户所看重的响应类型进行个性化预测。我们通过强化学习训练用户摘要模型，并同时更新奖励模型，创建一个在线协同适应循环。我们表明，与先前的个性化RLHF技术或用户信息的上下文学习相比，PLUS生成的摘要能够捕捉用户偏好的有意义方面。在不同的多元用户数据集上，我们表明我们的方法对新用户和多样化的对话主题表现出鲁棒性。此外，我们证明了生成的关于用户的文本摘要可以用于更强大、专有模型（如GPT-4）的零样本个性化。最终的用户摘要不仅简洁、便携，而且易于用户理解和修改，从而提高了LLM对齐的透明度和用户控制能力。", "summary": "本文提出了一种名为PLUS（使用摘要进行偏好学习）的新型框架，旨在解决现有强化学习从人类反馈（RLHF）在大型语言模型（LLM）中无法有效处理多元用户偏好的问题。PLUS通过学习并生成每个用户偏好、特征和历史对话的文本摘要，并将这些摘要用于调节奖励模型，从而实现LLM响应的个性化预测。该框架采用强化学习训练用户摘要模型并同时更新奖励模型，形成在线协同适应。实验证明，PLUS生成的摘要能有效捕捉用户偏好，对新用户和多样化对话主题具有鲁棒性，并且这些摘要可用于更强大模型的零样本个性化。最终的用户摘要不仅简洁、可移植，还易于理解和修改，增强了LLM对齐的透明度和用户控制。", "keywords": "大型语言模型, 强化学习, 用户偏好, 个性化, 摘要", "comments": "该论文创新性地提出通过学习用户偏好的文本摘要来个性化LLM的RLHF过程，解决了传统RLHF单一奖励模型无法捕捉用户多样性的局限。其方法的独特性在于将用户偏好编码为可解释、可修改的文本形式，这不仅提高了模型的个性化能力，也增强了用户对AI行为的透明度和控制力。此外，摘要的可移植性使其能够应用于其他专有模型，具有重要的实际应用价值。"}}
{"id": "2507.13607", "title": "Efficient Burst Super-Resolution with One-step Diffusion", "authors": ["Kento Kawai", "Takeru Oba", "Kyotaro Tokoro", "Kazutoshi Akita", "Norimichi Ukita"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      NTIRE2025", "url": "http://arxiv.org/abs/2507.13607v1", "summary": "While burst Low-Resolution (LR) images are useful for improving their Super\nResolution (SR) image compared to a single LR image, prior burst SR methods are\ntrained in a deterministic manner, which produces a blurry SR image. Since such\nblurry images are perceptually degraded, we aim to reconstruct sharp and\nhigh-fidelity SR images by a diffusion model. Our method improves the\nefficiency of the diffusion model with a stochastic sampler with a high-order\nODE as well as one-step diffusion using knowledge distillation. Our\nexperimental results demonstrate that our method can reduce the runtime to 1.6\n% of its baseline while maintaining the SR quality measured based on image\ndistortion and perceptual quality.", "comment": "NTIRE2025", "pdf_url": "http://arxiv.org/pdf/2507.13607v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "一步扩散的高效爆发式超分辨率", "tldr": "现有爆发式超分辨率方法产生模糊图像，本文提出一种高效的一步扩散模型，利用高阶ODE随机采样器和知识蒸馏，显著缩短运行时间至基线1.6%，同时保持高质量的超分辨率图像。", "motivation": "虽然爆发式低分辨率（LR）图像有助于提升超分辨率（SR）图像质量，但现有爆发式SR方法采用确定性训练方式，导致生成的SR图像模糊且感知质量下降。因此，目标是利用扩散模型重建清晰、高保真度的SR图像。", "method": "本文提出一种高效的扩散模型，通过结合高阶常微分方程（ODE）的随机采样器，以及利用知识蒸馏实现一步扩散来提高效率。", "result": "实验结果表明，本文方法能够将运行时间缩短至基线的1.6%，同时在图像失真和感知质量方面保持了超分辨率的质量。", "conclusion": "本文提出的高效一步扩散模型能够有效解决现有爆发式超分辨率方法产生的模糊问题，在大幅提升运行效率的同时，保持了高质量的图像重建效果。", "translation": "虽然爆发式低分辨率（LR）图像对于提高其超分辨率（SR）图像（相比于单张LR图像）很有用，但之前的爆发式SR方法以确定性方式训练，这会产生模糊的SR图像。由于这些模糊图像在感知上是退化的，我们旨在通过扩散模型重建清晰、高保真度的SR图像。我们的方法通过高阶ODE的随机采样器以及使用知识蒸馏的一步扩散来提高扩散模型的效率。我们的实验结果表明，我们的方法可以将运行时间缩短到其基线的1.6%，同时保持基于图像失真和感知质量衡量的SR质量。", "summary": "本文针对现有爆发式超分辨率（SR）方法产生的模糊图像问题，提出了一种高效的一步扩散模型。该方法通过引入高阶ODE随机采样器和利用知识蒸馏实现一步扩散，显著提高了模型效率。实验结果表明，该方法在保持图像失真和感知质量的前提下，将运行时间大幅缩短至基线的1.6%。", "keywords": "爆发式超分辨率, 扩散模型, 一步扩散, 知识蒸馏, 效率", "comments": "本文的创新点在于将扩散模型应用于爆发式超分辨率任务，并通过一步扩散和高阶ODE采样器显著提升了模型效率，成功解决了扩散模型推理速度慢的常见问题，同时改善了现有方法生成的图像模糊问题，具有重要的实用价值。"}}
{"id": "2312.17183", "title": "Large-Vocabulary Segmentation for Medical Images with Text Prompts", "authors": ["Ziheng Zhao", "Yao Zhang", "Chaoyi Wu", "Xiaoman Zhang", "Xiao Zhou", "Ya Zhang", "Yanfeng Wang", "Weidi Xie"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      74 pages", "url": "http://arxiv.org/abs/2312.17183v5", "summary": "This paper aims to build a model that can Segment Anything in 3D medical\nimages, driven by medical terminologies as Text prompts, termed as SAT. Our\nmain contributions are three-fold: (i) We construct the first multimodal\nknowledge tree on human anatomy, including 6502 anatomical terminologies; Then,\nwe build the largest and most comprehensive segmentation dataset for training,\ncollecting over 22K 3D scans from 72 datasets, across 497 classes, with careful\nstandardization on both image and label space; (ii) We propose to inject\nmedical knowledge into a text encoder via contrastive learning and formulate a\nlarge-vocabulary segmentation model that can be prompted by medical\nterminologies in text form; (iii) We train SAT-Nano (110M parameters) and\nSAT-Pro (447M parameters). SAT-Pro achieves comparable performance to 72\nnnU-Nets -- the strongest specialist models trained on each dataset (over 2.2B\nparameters combined) -- over 497 categories. Compared with the interactive\napproach MedSAM, SAT-Pro consistently outperforms across all 7 human body\nregions with +7.1% average Dice Similarity Coefficient (DSC) improvement, while\nshowing enhanced scalability and robustness. On 2 external (cross-center)\ndatasets, SAT-Pro achieves higher performance than all baselines (+3.7% average\nDSC), demonstrating superior generalization ability.", "comment": "74 pages", "pdf_url": "http://arxiv.org/pdf/2312.17183v5", "cate": "eess.IV", "date": "2023-12-28", "updated": "2025-07-18", "AI": {"title_translation": "基于文本提示的医学图像大词汇量分割", "tldr": "本文介绍了SAT，一个用于3D医学图像分割的模型，它使用文本提示来驱动，并构建了一个大型数据集和知识树。SAT-Pro在性能上与现有专家模型和MedSAM相比表现出色，并具有良好的泛化能力。", "motivation": "旨在构建一个能够通过医学术语文本提示，对三维医学图像进行任意分割的模型。", "method": "1. 构建了包含6502个解剖学术语的人体解剖学多模态知识树。2. 建立了最大、最全面的分割训练数据集，包含来自72个数据集的2.2万多个三维扫描和497个类别，并进行了标准化。3. 提出通过对比学习将医学知识注入文本编码器，并构建了一个可通过医学术语文本形式提示的大词汇量分割模型。4. 训练了SAT-Nano（1.1亿参数）和SAT-Pro（4.47亿参数）。", "result": "1. SAT-Pro在497个类别上取得了与72个nnU-Nets（总参数超过22亿）相当的性能。2. 与交互式方法MedSAM相比，SAT-Pro在所有7个人体区域上持续表现更优，平均Dice相似系数（DSC）提高了7.1%，并显示出增强的可扩展性和鲁棒性。3. 在2个外部（跨中心）数据集上，SAT-Pro的性能高于所有基线（平均DSC提高3.7%），展示了卓越的泛化能力。", "conclusion": "SAT-Pro模型在通过文本提示进行大词汇量三维医学图像分割方面表现出强大的性能、可扩展性、鲁棒性和泛化能力，优于现有的专业模型和交互式方法。", "translation": "本文旨在构建一个能够对三维医学图像进行任意分割的模型，该模型由医学术语作为文本提示驱动，我们称之为SAT。我们的主要贡献有三方面：(i) 我们构建了第一个关于人体解剖学多模态知识树，包含6502个解剖学术语；然后，我们构建了最大、最全面的分割训练数据集，收集了来自72个数据集的2.2万多个三维扫描，涵盖497个类别，并对图像和标签空间进行了仔细的标准化；(ii) 我们提出通过对比学习将医学知识注入文本编码器，并构建了一个可以通过文本形式的医学术语进行提示的大词汇量分割模型；(iii) 我们训练了SAT-Nano（1.1亿参数）和SAT-Pro（4.47亿参数）。SAT-Pro在497个类别上取得了与72个nnU-Nets（每个数据集上训练的最强专业模型，总参数超过22亿）相当的性能。与交互式方法MedSAM相比，SAT-Pro在所有7个人体区域上持续表现更优，平均Dice相似系数（DSC）提高了7.1%，同时显示出增强的可扩展性和鲁棒性。在2个外部（跨中心）数据集上，SAT-Pro的性能高于所有基线（平均DSC提高3.7%），展示了卓越的泛化能力。", "summary": "本文提出了一种名为SAT的新型模型，用于通过医学术语文本提示进行大词汇量三维医学图像分割。该研究构建了一个全面的多模态知识树和迄今为止最大的训练数据集。通过对比学习将医学知识注入文本编码器，SAT-Pro在多个类别和外部数据集上取得了与专业模型和交互式方法（如nnU-Nets和MedSAM）相当或更优的性能，展示了强大的可扩展性、鲁棒性和泛化能力。", "keywords": "医学图像分割, 文本提示, 大词汇量, 三维医学图像, 解剖学术语", "comments": "该论文通过使用文本提示解决三维医学图像大词汇量分割的挑战，做出了重大贡献，这在该领域是一种新颖的方法。大规模多模态知识树和广泛、标准化数据集的创建对未来的研究具有高度价值。SAT-Pro的性能，特别是其泛化能力以及以显著更少的参数优于专业模型和交互式方法的能力，突显了其创新性和在临床应用中的潜在影响。"}}
{"id": "2502.01312", "title": "CleanPose: Category-Level Object Pose Estimation via Causal Learning and Knowledge Distillation", "authors": ["Xiao Lin", "Yun Peng", "Liuyi Wang", "Xianyou Zhong", "Minghao Zhu", "Jingwei Yang", "Yi Feng", "Chengju Liu", "Qijun Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV2025", "url": "http://arxiv.org/abs/2502.01312v2", "summary": "Category-level object pose estimation aims to recover the rotation,\ntranslation and size of unseen instances within predefined categories. In this\ntask, deep neural network-based methods have demonstrated remarkable\nperformance. However, previous studies show they suffer from spurious\ncorrelations raised by \"unclean\" confounders in models, hindering their\nperformance on novel instances with significant variations. To address this\nissue, we propose CleanPose, a novel approach integrating causal learning and\nknowledge distillation to enhance category-level pose estimation. To mitigate\nthe negative effect of unobserved confounders, we develop a causal inference\nmodule based on front-door adjustment, which promotes unbiased estimation by\nreducing potential spurious correlations. Additionally, to further improve\ngeneralization ability, we devise a residual-based knowledge distillation\nmethod that has proven effective in providing comprehensive category\ninformation guidance. Extensive experiments across multiple benchmarks\n(REAL275, CAMERA25 and HouseCat6D) hightlight the superiority of proposed\nCleanPose over state-of-the-art methods. Code will be available at\nhttps://github.com/chrislin0621/CleanPose.", "comment": "Accepted by ICCV2025", "pdf_url": "http://arxiv.org/pdf/2502.01312v2", "cate": "cs.CV", "date": "2025-02-03", "updated": "2025-07-18", "AI": {"title_translation": "CleanPose：通过因果学习和知识蒸馏进行类别级物体姿态估计", "tldr": "CleanPose通过结合因果学习和知识蒸馏，解决了类别级物体姿态估计中由于混淆因素引起的虚假相关问题，显著提高了对新实例的泛化能力和性能。", "motivation": "现有深度神经网络方法在类别级物体姿态估计中，受到模型中“不干净”混淆因素引起的虚假相关的影响，这阻碍了它们在具有显著变化的新实例上的性能。", "method": "提出CleanPose，一种结合因果学习和知识蒸馏的新方法。其中，因果学习部分基于前门调整开发了一个因果推理模块，旨在减轻未观测混淆因素的负面影响并减少虚假相关。知识蒸馏部分设计了一种基于残差的知识蒸馏方法，用于提供全面的类别信息指导并进一步提高模型的泛化能力。", "result": "在REAL275、CAMERA25和HouseCat6D等多个基准测试中，所提出的CleanPose方法显著优于现有最先进的方法。", "conclusion": "CleanPose通过有效地结合因果学习和知识蒸馏，成功解决了类别级物体姿态估计中由混淆因素引起的虚假相关问题，并显著提升了模型在处理新实例时的泛化能力和整体性能。", "translation": "类别级物体姿态估计旨在恢复预定义类别中未见实例的旋转、平移和大小。在此任务中，基于深度神经网络的方法表现出卓越的性能。然而，先前的研究表明，它们受到模型中“不干净”混淆因素引起的虚假相关的影响，阻碍了它们在具有显著变化的新实例上的性能。为了解决这个问题，我们提出了CleanPose，一种结合因果学习和知识蒸馏的新方法，以增强类别级姿态估计。为了减轻未观测混淆因素的负面影响，我们开发了一个基于前门调整的因果推理模块，通过减少潜在的虚假相关来促进无偏估计。此外，为了进一步提高泛化能力，我们设计了一种基于残差的知识蒸馏方法，该方法已被证明在提供全面的类别信息指导方面是有效的。在多个基准（REAL275、CAMERA25和HouseCat6D）上的广泛实验突出显示了所提出的CleanPose优于最先进方法。代码将在https://github.com/chrislin0621/CleanPose 上提供。", "summary": "CleanPose是一种新颖的类别级物体姿态估计方法，旨在解决现有深度学习模型中由“不干净”混淆因素引起的虚假相关问题，这些问题会降低模型对新实例的泛化能力。该方法通过结合基于前门调整的因果推理模块来减少虚假相关，并引入基于残差的知识蒸馏方法来提供全面的类别信息指导，从而提高模型的泛化能力。实验结果表明，CleanPose在多个标准基准测试中均优于现有最先进的方法。", "keywords": "类别级物体姿态估计, 因果学习, 知识蒸馏, 虚假相关, 泛化能力", "comments": "这篇论文通过引入因果学习来解决深度学习模型在物体姿态估计中因混淆因素导致的虚假相关问题，这是一个重要的创新点。结合知识蒸馏进一步提升泛化能力，使得该方法在处理未见实例时表现出色，具有很高的实用价值和理论意义。"}}
{"id": "2507.13598", "title": "GIFT: Gradient-aware Immunization of diffusion models against malicious Fine-Tuning with safe concepts retention", "authors": ["Amro Abdalla", "Ismail Shaheen", "Dan DeGenaro", "Rupayan Mallick", "Bogdan Raita", "Sarah Adel Bargal"], "categories": ["cs.CR", "cs.AI", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13598v1", "summary": "We present GIFT: a {G}radient-aware {I}mmunization technique to defend\ndiffusion models against malicious {F}ine-{T}uning while preserving their\nability to generate safe content. Existing safety mechanisms like safety\ncheckers are easily bypassed, and concept erasure methods fail under\nadversarial fine-tuning. GIFT addresses this by framing immunization as a\nbi-level optimization problem: the upper-level objective degrades the model's\nability to represent harmful concepts using representation noising and\nmaximization, while the lower-level objective preserves performance on safe\ndata. GIFT achieves robust resistance to malicious fine-tuning while\nmaintaining safe generative quality. Experimental results show that our method\nsignificantly impairs the model's ability to re-learn harmful concepts while\nmaintaining performance on safe content, offering a promising direction for\ncreating inherently safer generative models resistant to adversarial\nfine-tuning attacks.", "comment": "Warning: This paper contains NSFW content. Reader discretion is\n  advised", "pdf_url": "http://arxiv.org/pdf/2507.13598v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "GIFT：梯度感知免疫扩散模型抵御恶意微调并保留安全概念", "tldr": "GIFT是一种梯度感知免疫技术，旨在保护扩散模型免受恶意微调攻击，同时保留其生成安全内容的能力，通过双层优化解决现有安全机制的不足。", "motivation": "现有安全机制（如安全检查器）容易被绕过，概念擦除方法在对抗性微调下失效。GIFT旨在解决这些问题，提供一种更鲁棒的防御扩散模型恶意微调的方法。", "method": "GIFT将免疫框架化为双层优化问题：上层目标通过表示噪声和最大化来降低模型表示有害概念的能力，而下层目标则保留模型在安全数据上的性能。", "result": "实验结果表明，GIFT显著削弱了模型重新学习有害概念的能力，同时保持了安全内容上的性能。", "conclusion": "GIFT为创建固有更安全的生成模型提供了有前景的方向，这些模型能够抵抗对抗性微调攻击。", "translation": "我们提出了GIFT：一种梯度感知免疫技术，旨在保护扩散模型免受恶意微调攻击，同时保留其生成安全内容的能力。现有安全机制（如安全检查器）容易被绕过，概念擦除方法在对抗性微调下失效。GIFT通过将免疫框架化为双层优化问题来解决这个问题：上层目标通过表示噪声和最大化来降低模型表示有害概念的能力，而下层目标则保留模型在安全数据上的性能。GIFT实现了对恶意微调的鲁棒抵抗，同时保持了安全的生成质量。实验结果表明，我们的方法显著削弱了模型重新学习有害概念的能力，同时保持了安全内容上的性能，为创建固有更安全且能抵抗对抗性微调攻击的生成模型提供了有前景的方向。", "summary": "GIFT提出一种梯度感知免疫技术，旨在防御扩散模型免受恶意微调攻击，同时确保其能生成安全内容。该方法通过将免疫视为双层优化问题来实现，其中上层目标削弱有害概念的表示，下层目标保持安全数据上的性能。实验证明GIFT能有效阻止模型重新学习有害概念，同时保持安全生成质量，为构建更安全的生成模型提供了新途径。", "keywords": "扩散模型, 恶意微调, 梯度感知免疫, 双层优化, 安全生成", "comments": "GIFT的创新之处在于其将免疫问题转化为双层优化，通过梯度感知的方式在保留安全内容生成能力的同时，有效阻止了有害概念的重新学习，为扩散模型安全提供了新的思路。"}}
{"id": "2402.08080", "title": "A Meaningful Human Control Perspective on User Perception of Partially Automated Driving Systems: A Case Study of Tesla Users", "authors": ["Lucas Elbert Suryana", "Sina Nordhoff", "Simeon C. Calvert", "Arkady Zgonnikov", "Bart van Arem"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      8 pages", "url": "http://arxiv.org/abs/2402.08080v2", "summary": "The use of partially automated driving systems raises concerns about\npotential responsibility issues, posing risk to the system safety, acceptance,\nand adoption of these technologies. The concept of meaningful human control has\nemerged in response to the responsibility gap problem, requiring the\nfulfillment of two conditions, tracking and tracing. While this concept has\nprovided important philosophical and design insights on automated driving\nsystems, there is currently little knowledge on how meaningful human control\nrelates to subjective experiences of actual users of these systems. To address\nthis gap, our study aimed to investigate the alignment between the degree of\nmeaningful human control and drivers' perceptions of safety and trust in a\nreal-world partially automated driving system. We utilized previously collected\ndata from interviews with Tesla \"Full Self-Driving\" (FSD) Beta users,\ninvestigating the alignment between the user perception and how well the system\nwas tracking the users' reasons. We found that tracking of users' reasons for\ndriving tasks (such as safe maneuvers) correlated with perceived safety and\ntrust, albeit with notable exceptions. Surprisingly, failure to track lane\nchanging and braking reasons was not necessarily associated with negative\nperceptions of safety. However, the failure of the system to track expected\nmaneuvers in dangerous situations always resulted in low trust and perceived\nlack of safety. Overall, our analyses highlight alignment points but also\npossible discrepancies between perceived safety and trust on the one hand, and\nmeaningful human control on the other hand. Our results can help the developers\nof automated driving technology to design systems under meaningful human\ncontrol and are perceived as safe and trustworthy.", "comment": "8 pages", "pdf_url": "http://arxiv.org/pdf/2402.08080v2", "cate": "cs.HC", "date": "2024-02-12", "updated": "2025-07-18", "AI": {"title_translation": "有意义的人类控制视角下用户对部分自动驾驶系统的感知：以特斯拉用户为例", "tldr": "本研究调查了特斯拉FSD Beta用户对部分自动驾驶系统的感知，发现“有意义的人类控制”中的“跟踪”条件与用户感知的安全性和信任度相关，但在某些情况下存在例外。", "motivation": "部分自动驾驶系统引发了潜在的责任问题，对系统安全、接受度和普及构成风险。尽管“有意义的人类控制”概念为自动驾驶系统提供了哲学和设计见解，但目前对于该概念如何与实际用户的主观体验相关联的知识甚少。本研究旨在弥补这一知识空白。", "method": "研究利用了之前收集的特斯拉“全自动驾驶”（FSD）Beta用户访谈数据，调查了用户感知与系统“跟踪”用户驾驶原因程度之间的一致性。", "result": "研究发现，系统对用户驾驶任务（如安全操作）原因的跟踪与感知的安全性和信任度相关，但存在显著例外。令人惊讶的是，未能跟踪变道和制动原因不一定与负面安全感知相关。然而，系统在危险情况下未能跟踪预期操作总是导致低信任度和感知到的不安全感。", "conclusion": "本研究的分析突出了感知安全性和信任度与有意义的人类控制之间的一致点，也指出了可能存在的差异。研究结果可以帮助自动驾驶技术开发者设计出符合有意义人类控制且被用户认为安全可信的系统。", "translation": "部分自动驾驶系统的使用引发了对潜在责任问题的担忧，对系统安全、接受度和这些技术的普及构成了风险。“有意义的人类控制”概念应运而生，以解决责任差距问题，要求满足跟踪和追溯两个条件。尽管这一概念为自动驾驶系统提供了重要的哲学和设计见解，但目前对于有意义的人类控制如何与这些系统实际用户的主观体验相关联的知识甚少。为了弥补这一空白，我们的研究旨在调查有意义人类控制程度与驾驶员对真实世界部分自动驾驶系统安全性和信任度感知之间的一致性。我们利用了之前收集的特斯拉“全自动驾驶”（FSD）Beta用户访谈数据，调查了用户感知与系统跟踪用户原因的程度之间的一致性。我们发现，系统对用户驾驶任务（如安全操作）原因的跟踪与感知的安全性和信任度相关，尽管存在显著例外。令人惊讶的是，未能跟踪变道和制动原因不一定与负面安全感知相关。然而，系统在危险情况下未能跟踪预期操作总是导致低信任度和感知到的不安全感。总的来说，我们的分析突出了感知安全性和信任度与有意义人类控制之间的一致点，也指出了可能存在的差异。我们的结果可以帮助自动驾驶技术开发者设计出符合有意义人类控制且被用户认为安全可信的系统。", "summary": "本研究从“有意义的人类控制”视角出发，调查了特斯拉FSD Beta用户对部分自动驾驶系统安全性和信任度的感知。通过分析用户访谈数据，研究发现系统对用户驾驶任务原因的“跟踪”能力与用户感知安全性和信任度高度相关，尤其是在危险情境下。然而，在某些特定操作（如变道和制动）上，跟踪失败不一定会导致负面感知。研究结果为自动驾驶系统开发者提供了设计指导，以提升系统的“有意义人类控制”程度及用户感知。", "keywords": "有意义人类控制, 部分自动驾驶, 用户感知, 特斯拉, 安全性, 信任度", "comments": "这项研究通过将抽象的“有意义的人类控制”概念与实际用户的主观体验联系起来，填补了现有知识空白，具有重要意义。其创新之处在于利用特斯拉FSD Beta用户的真实世界经验作为案例研究，这为理解用户与高级辅助驾驶系统交互提供了宝贵的实证数据。研究结果揭示了用户感知与系统设计之间存在的复杂关系，特别是指出了即使在某些跟踪失败的情况下，用户感知也可能并非完全负面，但危险情况下的失败则影响巨大。这为未来自动驾驶系统的人机交互设计提供了细致入微的指导。"}}
{"id": "2501.18587", "title": "Entropy functionals and equilibrium states in mixed quantum-classical dynamics", "authors": ["Cesare Tronci", "David Martínez-Crespo", "François Gay-Balmaz"], "categories": ["quant-ph", "cond-mat.stat-mech", "cs.IT", "math-ph", "math.IT", "math.MP", "physics.chem-ph"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      Final version. To appear in Lecture Notes in Comput. Sci", "url": "http://arxiv.org/abs/2501.18587v3", "summary": "The computational challenges posed by many-particle quantum systems are often\novercome by mixed quantum-classical (MQC) models in which certain degrees of\nfreedom are treated as classical while others are retained as quantum. One of\nthe fundamental questions raised by this hybrid picture involves the\ncharacterization of the information associated to MQC systems. Based on the\ntheory of dynamical invariants in Hamiltonian systems, here we propose a family\nof hybrid entropy functionals that consistently specialize to the usual R\\'enyi\nand Shannon entropies. Upon considering the MQC Ehrenfest model for the\ndynamics of quantum and classical probabilities, we apply the hybrid Shannon\nentropy to characterize equilibrium configurations for simple Hamiltonians. The\npresent construction also applies beyond Ehrenfest dynamics.", "comment": "Final version. To appear in Lecture Notes in Comput. Sci", "pdf_url": "http://arxiv.org/pdf/2501.18587v3", "cate": "quant-ph", "date": "2025-01-30", "updated": "2025-07-18", "AI": {"title_translation": "混合量子-经典动力学中的熵泛函与平衡态", "tldr": "本文提出了一系列混合熵泛函，用于表征混合量子-经典系统的信息，并将其应用于Ehrenfest模型以描述平衡态。", "motivation": "多粒子量子系统面临计算挑战，混合量子-经典（MQC）模型常用于克服这些挑战。这种混合模型引出了一个基本问题：如何表征MQC系统相关的信息。", "method": "基于哈密顿系统中的动力学不变量理论，本文提出了一系列混合熵泛函，这些泛函可以专门化为通常的Rényi和Shannon熵。通过考虑用于量子和经典概率动力学的MQC Ehrenfest模型，将混合Shannon熵应用于表征简单哈密顿量的平衡构型。", "result": "成功应用混合Shannon熵来表征简单哈密顿量的平衡构型。所提出的构造也适用于Ehrenfest动力学之外的场景。", "conclusion": "本文提出的混合熵泛函能够一致地表征混合量子-经典系统的信息，并成功应用于Ehrenfest模型以描述平衡态。该构造具有更广泛的适用性。", "translation": "多粒子量子系统所带来的计算挑战通常通过混合量子-经典（MQC）模型来克服，在这些模型中，某些自由度被视为经典，而另一些则保留为量子。这种混合图景引发的一个基本问题涉及MQC系统相关信息的表征。基于哈密顿系统中的动力学不变量理论，本文提出了一系列混合熵泛函，这些泛函可以一致地专门化为通常的Rényi和Shannon熵。在考虑用于量子和经典概率动力学的MQC Ehrenfest模型后，我们将混合Shannon熵应用于表征简单哈密顿量的平衡构型。本构造也适用于Ehrenfest动力学之外的场景。", "summary": "本文针对多粒子量子系统的计算挑战，提出了一种混合量子-经典（MQC）模型，并关注了MQC系统信息表征这一基本问题。研究基于哈密顿系统中的动力学不变量理论，提出了一系列能够专门化为Rényi和Shannon熵的混合熵泛函。通过将混合Shannon熵应用于MQC Ehrenfest模型，成功表征了简单哈密顿量的平衡构型。该构造方法还具有超越Ehrenfest动力学的普适性。", "keywords": "混合量子-经典动力学, 熵泛函, 平衡态, Ehrenfest模型, 信息表征", "comments": "本文通过引入混合熵泛函，为混合量子-经典系统的热力学信息表征提供了一种新颖且一致的框架，解决了该领域的一个基本问题。其创新之处在于将经典和量子熵概念统一到一个混合体系中，并证明了其在Ehrenfest模型中的有效性，同时指出了其更广泛的适用性，这对于理解和模拟复杂量子-经典系统具有重要意义。"}}
{"id": "2507.13863", "title": "Controlling the Parameterized Multi-channel Wiener Filter using a tiny neural network", "authors": ["Eric Grinstein", "Ashutosh Pandey", "Cole Li", "Shanmukha Srinivas", "Juan Azcarreta", "Jacob Donley", "Sanha Lee", "Ali Aroudi", "Cagdas Bilen"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted to WASPAA 2025", "url": "http://arxiv.org/abs/2507.13863v1", "summary": "Noise suppression and speech distortion are two important aspects to be\nbalanced when designing multi-channel Speech Enhancement (SE) algorithms.\nAlthough neural network models have achieved state-of-the-art noise\nsuppression, their non-linear operations often introduce high speech\ndistortion. Conversely, classical signal processing algorithms such as the\nParameterized Multi-channel Wiener Filter ( PMWF) beamformer offer explicit\nmechanisms for controlling the suppression/distortion trade-off. In this work,\nwe present NeuralPMWF, a system where the PMWF is entirely controlled using a\nlow-latency, low-compute neural network, resulting in a low-complexity system\noffering high noise reduction and low speech distortion. Experimental results\nshow that our proposed approach results in significantly better perceptual and\nobjective speech enhancement in comparison to several competitive baselines\nusing similar computational resources.", "comment": "Accepted to WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13863v1", "cate": "cs.SD", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用小型神经网络控制参数化多通道维纳滤波器", "tldr": "本文提出NeuralPMWF，一个通过小型神经网络控制参数化多通道维纳滤波器（PMWF）的系统，实现了高降噪和低语音失真，并在感知和客观语音增强方面优于现有基线。", "motivation": "在多通道语音增强（SE）算法设计中，需要在噪声抑制和语音失真之间取得平衡。虽然神经网络模型在噪声抑制方面表现出色，但其非线性操作常引入高语音失真。经典的信号处理算法如参数化多通道维纳滤波器（PMWF）能明确控制抑制/失真权衡，但可能不如神经网络在噪声抑制方面先进。因此，研究的动机是结合两者的优点，开发一种既能有效降噪又能保持低语音失真，同时计算复杂度低的系统。", "method": "本文提出了NeuralPMWF系统。在该系统中，参数化多通道维纳滤波器（PMWF）完全由一个低延迟、低计算量的小型神经网络进行控制。这种方法旨在创建一个低复杂度的系统，同时实现高噪声抑制和低语音失真。", "result": "实验结果表明，与使用相似计算资源的几个竞争性基线相比，所提出的方法在感知和客观语音增强方面均取得了显著更好的效果。", "conclusion": "通过使用小型神经网络控制参数化多通道维纳滤波器，可以有效地平衡噪声抑制和语音失真，实现高性能且低复杂度的语音增强系统。", "translation": "噪声抑制和语音失真是在设计多通道语音增强（SE）算法时需要平衡的两个重要方面。尽管神经网络模型在噪声抑制方面已达到最先进水平，但其非线性操作通常会引入较高的语音失真。相反，经典的信号处理算法，如参数化多通道维纳滤波器（PMWF）波束形成器，提供了明确的机制来控制抑制/失真之间的权衡。在这项工作中，我们提出了NeuralPMWF，一个完全由低延迟、低计算量的神经网络控制PMWF的系统，从而形成一个低复杂度、提供高降噪和低语音失真的系统。实验结果表明，与使用相似计算资源的几个竞争性基线相比，我们提出的方法在感知和客观语音增强方面均取得了显著更好的效果。", "summary": "本文介绍了一种名为NeuralPMWF的新型语音增强系统，旨在解决多通道语音增强中噪声抑制和语音失真之间的权衡问题。该系统通过一个小型、低延迟、低计算量的神经网络来控制参数化多通道维纳滤波器（PMWF）。这种集成方法旨在结合神经网络的先进降噪能力与PMWF对失真控制的明确机制，从而实现一个低复杂度、高降噪且低语音失真的解决方案。实验结果表明，与现有基线相比，NeuralPMWF在感知和客观语音增强性能上均有显著提升。", "keywords": "语音增强, 多通道维纳滤波器, 神经网络, 噪声抑制, 语音失真", "comments": "该论文的创新点在于将经典信号处理算法（PMWF）与现代神经网络技术相结合，通过小型神经网络智能地控制PMWF，从而在噪声抑制和语音失真之间找到一个更优的平衡点。这种方法不仅解决了纯神经网络模型可能导致的语音失真问题，又提升了经典算法的性能，同时保持了系统的低复杂度，对于资源受限的语音增强应用具有重要意义。"}}
{"id": "2410.13394", "title": "Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs", "authors": ["Sumanth Doddapaneni", "Mohammed Safi Ur Rahman Khan", "Dilip Venkatesh", "Raj Dabre", "Anoop Kunchukuttan", "Mitesh M. Khapra"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.13394v2", "summary": "Evaluating machine-generated text remains a significant challenge in NLP,\nespecially for non-English languages. Current methodologies, including\nautomated metrics, human assessments, and LLM-based evaluations, predominantly\nfocus on English, revealing a significant gap in multilingual evaluation\nframeworks. We introduce the Cross Lingual Auto Evaluation (CIA) Suite, an\nextensible framework that includes evaluator LLMs (Hercule) and a novel test\nset (Recon) specifically designed for multilingual evaluation. Our test set\nfeatures 500 human-annotated instructions spanning various task capabilities\nalong with human judgment scores across six languages. This would enable\nbenchmarking of general-purpose multilingual LLMs and facilitate\nmeta-evaluation of Evaluator LLMs. The proposed model, Hercule, is a\ncross-lingual evaluation model that addresses the scarcity of reference answers\nin the target language by learning to assign scores to responses based on\neasily available reference answers in English. Our experiments demonstrate that\nHercule aligns more closely with human judgments compared to proprietary\nmodels, demonstrating the effectiveness of such cross-lingual evaluation in low\nresource scenarios. Further, it is also effective in zero-shot evaluation on\nunseen languages. This study is the first comprehensive examination of\ncross-lingual evaluation using LLMs, presenting a scalable and effective\napproach for multilingual assessment. All code, datasets, and models will be\npublicly available to enable further research in this important area.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.13394v2", "cate": "cs.CL", "date": "2024-10-17", "updated": "2025-07-18", "AI": {"title_translation": "用于评估多语言大型语言模型的跨语言自动评估", "tldr": "本文介绍了跨语言自动评估（CIA）套件，包括评估器大型语言模型Hercule和新的测试集Recon，旨在解决多语言大型语言模型评估中英语偏向的问题。Hercule模型通过利用英语参考答案进行跨语言评估，在低资源和零样本场景下表现出与人类判断更高的一致性。", "motivation": "机器生成文本的评估在自然语言处理领域仍是一个重大挑战，特别是非英语语言。当前的评估方法（包括自动化指标、人工评估和基于大型语言模型的评估）主要集中在英语，这暴露了多语言评估框架的显著空白。", "method": "本文提出了跨语言自动评估（CIA）套件，这是一个可扩展的框架，包括评估器大型语言模型（Hercule）和一个专门为多语言评估设计的新型测试集（Recon）。该测试集包含500个人工标注的指令，涵盖多种任务能力，并附带六种语言的人工判断分数。Hercule模型通过学习根据易于获得的英语参考答案为响应分配分数，解决了目标语言中参考答案稀缺的问题。", "result": "实验表明，与专有模型相比，Hercule模型与人类判断更紧密地对齐，证明了这种跨语言评估在低资源场景下的有效性。此外，它在对未知语言进行零样本评估时也表现出有效性。", "conclusion": "本研究首次全面检验了使用大型语言模型进行跨语言评估，提出了一种可扩展且有效的多语言评估方法。", "translation": "评估机器生成的文本在自然语言处理中仍然是一个重大挑战，特别是非英语语言。当前的方法论，包括自动化指标、人工评估和基于大型语言模型的评估，主要侧重于英语，揭示了多语言评估框架中的显著空白。我们引入了跨语言自动评估（CIA）套件，这是一个可扩展的框架，其中包括评估器大型语言模型（Hercule）和一个专门为多语言评估设计的新型测试集（Recon）。我们的测试集包含500个人工标注的指令，涵盖各种任务能力，并附带六种语言的人工判断分数。这将能够对通用多语言大型语言模型进行基准测试，并促进评估器大型语言模型的元评估。所提出的模型Hercule是一个跨语言评估模型，通过学习根据易于获得的英语参考答案为响应分配分数，解决了目标语言中参考答案稀缺的问题。我们的实验表明，与专有模型相比，Hercule与人类判断更紧密地对齐，证明了这种跨语言评估在低资源场景下的有效性。此外，它在对未知语言进行零样本评估时也有效。这项研究是首次全面检验使用大型语言模型进行跨语言评估，提出了一种可扩展且有效的多语言评估方法。所有代码、数据集和模型都将公开可用，以促进该重要领域的进一步研究。", "summary": "本文针对多语言大型语言模型评估中存在的英语偏向问题，提出了一套名为“跨语言自动评估（CIA）”的框架。该框架包含评估器大型语言模型Hercule和一个多语言测试集Recon。Hercule模型通过利用易于获取的英语参考答案进行跨语言评分，旨在解决目标语言参考答案稀缺的难题。实验结果表明，Hercule模型在低资源和零样本场景下，其评估结果与人类判断高度一致，优于现有专有模型。这项工作是首次全面探索使用大型语言模型进行跨语言评估，为多语言大型语言模型的评估提供了一种可扩展且有效的新范式。", "keywords": "跨语言评估, 多语言大型语言模型, 自动评估, Hercule, Recon", "comments": "这项研究的创新之处在于提出了一个专门用于多语言大型语言模型评估的跨语言自动评估框架，特别是其Hercule模型能够利用英语参考答案进行跨语言评估，有效解决了低资源语言评估的难题。其有效性在与人类判断的对比中得到了验证，并且支持零样本评估，这对于快速发展的多语言AI领域至关重要。此外，作者承诺公开所有代码、数据集和模型，这将极大地促进该领域的后续研究和发展。"}}
{"id": "2507.13629", "title": "Large Language Models in Cybersecurity: Applications, Vulnerabilities, and Defense Techniques", "authors": ["Niveen O. Jaffal", "Mohammed Alkhanafseh", "David Mohaisen"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      21 pages", "url": "http://arxiv.org/abs/2507.13629v1", "summary": "Large Language Models (LLMs) are transforming cybersecurity by enabling\nintelligent, adaptive, and automated approaches to threat detection,\nvulnerability assessment, and incident response. With their advanced language\nunderstanding and contextual reasoning, LLMs surpass traditional methods in\ntackling challenges across domains such as IoT, blockchain, and hardware\nsecurity. This survey provides a comprehensive overview of LLM applications in\ncybersecurity, focusing on two core areas: (1) the integration of LLMs into key\ncybersecurity domains, and (2) the vulnerabilities of LLMs themselves, along\nwith mitigation strategies. By synthesizing recent advancements and identifying\nkey limitations, this work offers practical insights and strategic\nrecommendations for leveraging LLMs to build secure, scalable, and future-ready\ncyber defense systems.", "comment": "21 pages", "pdf_url": "http://arxiv.org/pdf/2507.13629v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "网络安全中的大型语言模型：应用、漏洞与防御技术", "tldr": "本综述探讨了大型语言模型（LLMs）在网络安全中的应用、其自身的漏洞以及相应的防御策略，旨在为构建安全的网络防御系统提供见解和建议。", "motivation": "大型语言模型（LLMs）正在通过提供智能、适应性强和自动化的方法来改变网络安全领域，解决威胁检测、漏洞评估和事件响应等挑战，并在物联网、区块链和硬件安全等领域超越传统方法。", "method": "本文采用综述（survey）的形式，全面概述了LLM在网络安全中的应用，重点关注两个核心领域：1）LLM与关键网络安全领域的集成；2）LLM自身的漏洞及其缓解策略。", "result": "本综述通过综合最新进展和识别关键局限性，为利用LLM构建安全、可扩展和面向未来的网络防御系统提供了实用见解和战略建议。", "conclusion": "LLMs在网络安全中具有巨大潜力，但其自身的漏洞也需重视。通过整合LLM并采取缓解策略，可以构建更安全、可扩展和面向未来的网络防御系统。", "translation": "大型语言模型（LLMs）正在通过实现智能、自适应和自动化的威胁检测、漏洞评估和事件响应方法来改变网络安全。凭借其先进的语言理解和上下文推理能力，LLMs在应对物联网、区块链和硬件安全等领域的挑战方面超越了传统方法。本综述全面概述了LLM在网络安全中的应用，重点关注两个核心领域：（1）LLM与关键网络安全领域的集成，以及（2）LLM自身的漏洞及其缓解策略。通过综合最新进展并识别关键局限性，这项工作为利用LLM构建安全、可扩展和面向未来的网络防御系统提供了实用见解和战略建议。", "summary": "本综述探讨了大型语言模型（LLMs）在网络安全领域的变革性作用，涵盖了它们在威胁检测、漏洞评估和事件响应中的应用。文章深入分析了LLMs与关键网络安全领域的整合，并详细讨论了LLMs自身的漏洞及相应的缓解策略。通过对现有研究的综合分析，本工作旨在为利用LLMs构建安全、可扩展的未来网络防御系统提供指导和建议。", "keywords": "大型语言模型, 网络安全, 漏洞, 防御技术, 综述", "comments": "该论文是一篇及时的综述，系统地梳理了大型语言模型在网络安全领域的应用前景和潜在风险。其创新之处在于不仅关注LLM的应用，还深入探讨了LLM自身的安全问题，并提出了缓解策略，这对于推动LLM在网络安全领域的健康发展具有重要指导意义。该综述的全面性和实用性使其成为该领域研究人员和实践者的重要参考。"}}
{"id": "2507.13378", "title": "A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects", "authors": ["Yuqi Cheng", "Yunkang Cao", "Haiming Yao", "Wei Luo", "Cheng Jiang", "Hui Zhang", "Weiming Shen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      27 pages, 7 figures", "url": "http://arxiv.org/abs/2507.13378v1", "summary": "Industrial defect detection is vital for upholding product quality across\ncontemporary manufacturing systems. As the expectations for precision,\nautomation, and scalability intensify, conventional inspection approaches are\nincreasingly found wanting in addressing real-world demands. Notable progress\nin computer vision and deep learning has substantially bolstered defect\ndetection capabilities across both 2D and 3D modalities. A significant\ndevelopment has been the pivot from closed-set to open-set defect detection\nframeworks, which diminishes the necessity for extensive defect annotations and\nfacilitates the recognition of novel anomalies. Despite such strides, a\ncohesive and contemporary understanding of industrial defect detection remains\nelusive. Consequently, this survey delivers an in-depth analysis of both\nclosed-set and open-set defect detection strategies within 2D and 3D\nmodalities, charting their evolution in recent years and underscoring the\nrising prominence of open-set techniques. We distill critical challenges\ninherent in practical detection environments and illuminate emerging trends,\nthereby providing a current and comprehensive vista of this swiftly progressing\nfield.", "comment": "27 pages, 7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13378v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "工业缺陷检测的全面综述：挑战、方法与展望", "tldr": "这篇综述全面分析了工业缺陷检测领域，涵盖了2D和3D模态下的封闭集与开放集方法，并探讨了实际挑战和未来趋势，强调了开放集技术的重要性。", "motivation": "工业缺陷检测对于维护产品质量至关重要，但传统方法已无法满足日益增长的精度、自动化和可扩展性需求。尽管计算机视觉和深度学习取得了显著进展，但对该领域仍缺乏一个连贯和现代的理解。", "method": "本综述深入分析了2D和3D模态下的封闭集和开放集缺陷检测策略，梳理了它们近年来的演变，并强调了开放集技术的日益突出。文章还提炼了实际检测环境中固有的关键挑战，并阐明了新兴趋势。", "result": "综述提炼了实际检测环境中固有的关键挑战，并阐明了新兴趋势，为工业缺陷检测这一快速发展领域提供了一个当前和全面的视角。", "conclusion": "本文为工业缺陷检测这一快速发展领域提供了一个当前和全面的视角。", "translation": "工业缺陷检测对于维护当代制造系统的产品质量至关重要。随着对精度、自动化和可扩展性期望的增强，传统检测方法在满足实际需求方面日益显得不足。计算机视觉和深度学习的显著进展极大地增强了2D和3D模态下的缺陷检测能力。一个重要的发展是从封闭集转向开放集缺陷检测框架，这减少了对大量缺陷标注的需求，并促进了对新型异常的识别。尽管取得了这些进展，但对工业缺陷检测的连贯和现代理解仍然难以捉摸。因此，本综述深入分析了2D和3D模态下的封闭集和开放集缺陷检测策略，描绘了它们近年来的演变，并强调了开放集技术的日益突出。我们提炼了实际检测环境中固有的关键挑战，并阐明了新兴趋势，从而为这一快速发展领域提供了一个当前和全面的视角。", "summary": "本综述全面探讨了工业缺陷检测领域，从传统方法到基于深度学习的2D/3D技术，并重点分析了从封闭集到开放集检测框架的转变。文章识别了实际应用中的关键挑战，并展望了新兴趋势，旨在为该快速发展的领域提供一个连贯和全面的理解。", "keywords": "工业缺陷检测, 开放集检测, 封闭集检测, 计算机视觉, 深度学习", "comments": "这篇综述及时且全面，尤其关注了工业缺陷检测从封闭集到开放集方法的转变，这对于减少标注需求和识别新型异常至关重要。它不仅总结了现有技术，还指出了实际挑战和未来发展方向，对研究人员和工程师都具有重要参考价值。"}}
{"id": "2507.13936", "title": "Extracting Insights from Large-Scale Telematics Data for ITS Applications: Lessons and Recommendations", "authors": ["Gibran Ali", "Neal Feierabend", "Prarthana Doshi", "Calvin Winkowski", "Michael Fontaine"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for 2025 IEEE International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.13936v1", "summary": "Over 90% of new vehicles in the United States now collect and transmit\ntelematics data. Similar trends are seen in other developed countries.\nTransportation planners have previously utilized telematics data in various\nforms, but its current scale offers significant new opportunities in traffic\nmeasurement, classification, planning, and control. Despite these\nopportunities, the enormous volume of data and lack of standardization across\nmanufacturers necessitates a clearer understanding of the data and improved\ndata processing methods for extracting actionable insights.\n  This paper takes a step towards addressing these needs through four primary\nobjectives. First, a data processing pipeline was built to efficiently analyze\n1.4 billion miles (120 million trips) of telematics data collected in Virginia\nbetween August 2021 and August 2022. Second, an open data repository of trip\nand roadway segment level summaries was created. Third, interactive\nvisualization tools were designed to extract insights from these data about\ntrip-taking behavior and the speed profiles of roadways. Finally, major\nchallenges that were faced during processing this data are summarized and\nrecommendations to overcome them are provided. This work will help\nmanufacturers collecting the data and transportation professionals using the\ndata to develop a better understanding of the possibilities and major pitfalls\nto avoid.", "comment": "Accepted for 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13936v1", "cate": "cs.CY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "从大规模远程信息处理数据中提取见解以用于智能交通系统应用：经验与建议", "tldr": "本文处理大规模远程信息处理数据，为智能交通系统（ITS）应用提取见解，包括构建数据处理管道、创建开放数据存储库、设计可视化工具，并提供克服处理挑战的建议。", "motivation": "美国90%以上的新车都在收集和传输远程信息处理数据，其他发达国家也有类似趋势。尽管这些数据为交通测量、分类、规划和控制提供了巨大的新机遇，但其庞大的数据量和制造商之间缺乏标准化阻碍了见解的提取，因此需要对数据有更清晰的理解和改进的数据处理方法。", "method": "本文通过四个主要目标来解决上述需求：1. 构建了一个数据处理管道，以高效分析2021年8月至2022年8月期间在弗吉尼亚州收集的14亿英里（1.2亿次行程）远程信息处理数据。2. 创建了一个行程和路段级别的开放数据存储库。3. 设计了交互式可视化工具，从这些数据中提取有关行程行为和道路速度剖面的见解。4. 总结了在处理数据过程中遇到的主要挑战，并提供了克服这些挑战的建议。", "result": "该研究构建了一个高效的数据处理管道、一个开放的行程和路段级别数据存储库，并设计了交互式可视化工具，成功地从大规模远程信息处理数据中提取了关于行程行为和道路速度剖面的见解。此外，还总结了数据处理中的主要挑战并提供了解决方案。", "conclusion": "这项工作将帮助数据收集制造商和数据使用交通专业人员更好地理解远程信息处理数据的潜力，并避免在使用过程中可能遇到的主要陷阱。", "translation": "美国90%以上的新车现在都收集和传输远程信息处理数据。其他发达国家也有类似的趋势。交通规划者此前曾以各种形式利用远程信息处理数据，但其当前的规模为交通测量、分类、规划和控制提供了重要的新机遇。尽管存在这些机遇，但庞大的数据量和制造商之间缺乏标准化使得需要更清晰地理解数据和改进数据处理方法，以提取可操作的见解。\n本文通过四个主要目标来解决这些需求。首先，建立了一个数据处理管道，以高效分析2021年8月至2022年8月期间在弗吉尼亚州收集的14亿英里（1.2亿次行程）远程信息处理数据。其次，创建了一个行程和路段级别的开放数据存储库。第三，设计了交互式可视化工具，以从这些数据中提取有关行程行为和道路速度剖面的见解。最后，总结了在处理这些数据过程中遇到的主要挑战，并提供了克服这些挑战的建议。这项工作将帮助数据收集制造商和数据使用交通专业人员更好地理解可能性和避免主要陷阱。", "summary": "本文旨在解决利用大规模、非标准化远程信息处理数据在智能交通系统（ITS）应用中面临的挑战。研究详细介绍了为处理14亿英里远程信息处理数据而开发的数据处理管道，创建了一个开放数据存储库，并设计了交互式可视化工具，以深入分析行程行为和道路速度剖面。此外，论文还总结了关键的数据处理挑战并提出了实用建议，旨在指导数据收集者和使用者有效利用这一宝贵资源。", "keywords": "远程信息处理数据, 智能交通系统, 数据处理, 交通规划, 数据可视化", "comments": "这篇论文在处理大规模真实世界远程信息处理数据方面采用了实用方法，这在智能交通系统领域是一个重大挑战，因此具有创新性。其贡献不仅在于开发了具体的工具（数据管道、存储库、可视化工具），还在于基于经验教训提供了可操作的建议，这对行业从业者至关重要。对标准化问题和数据量的关注突显了远程信息处理数据在交通规划中广泛应用的关键障碍。"}}
{"id": "2507.14096", "title": "Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track", "authors": ["Brian Ondov", "William Xia", "Kush Attal", "Ishita Unde", "Jerry He", "Hoa Dang", "Ian Soboroff", "Dina Demner-Fushman"], "categories": ["cs.CL", "cs.AI", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14096v1", "summary": "Objective: Recent advances in language models have shown potential to adapt\nprofessional-facing biomedical literature to plain language, making it\naccessible to patients and caregivers. However, their unpredictability,\ncombined with the high potential for harm in this domain, means rigorous\nevaluation is necessary. Our goals with this track were to stimulate research\nand to provide high-quality evaluation of the most promising systems.\n  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts\n(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included\ncomplete, sentence-level, rewriting of abstracts (Task 1) as well as\nidentifying and replacing difficult terms (Task 2). For automatic evaluation of\nTask 1, we developed a four-fold set of professionally-written references.\nSubmissions for both Tasks 1 and 2 were provided extensive manual evaluation\nfrom biomedical experts.\n  Results: Twelve teams spanning twelve countries participated in the track,\nwith models from multilayer perceptrons to large pretrained transformers. In\nmanual judgments of Task 1, top-performing models rivaled human levels of\nfactual accuracy and completeness, but not simplicity or brevity. Automatic,\nreference-based metrics generally did not correlate well with manual judgments.\nIn Task 2, systems struggled with identifying difficult terms and classifying\nhow to replace them. When generating replacements, however, LLM-based systems\ndid well in manually judged accuracy, completeness, and simplicity, though not\nin brevity.\n  Conclusion: The PLABA track showed promise for using Large Language Models to\nadapt biomedical literature for the general public, while also highlighting\ntheir deficiencies and the need for improved automatic benchmarking tools.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14096v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "TREC 生物医学摘要平实语言改编 (PLABA) 赛道的经验教训", "tldr": "TREC PLABA赛道评估了语言模型将生物医学文献改编为通俗语言的能力，发现顶级模型在准确性上表现良好但简洁性不足，并强调了改进自动评估工具的需求。", "motivation": "语言模型在将专业生物医学文献改编为通俗语言方面显示出潜力，使其可供患者和护理人员使用。然而，它们的不可预测性和在该领域造成危害的高可能性意味着需要进行严格评估。本赛道旨在刺激研究并提供对最有前景系统的评估。", "method": "在2023年和2024年文本检索会议上举办了生物医学摘要平实语言改编（PLABA）赛道。任务包括摘要的完整（句子级）重写（任务1）以及识别和替换难懂术语（任务2）。任务1的自动评估开发了四重专业编写的参考文本。任务1和任务2的提交都由生物医学专家进行了广泛的人工评估。", "result": "12个国家的12支团队参与了该赛道，模型范围从多层感知器到大型预训练Transformer。在任务1的人工判断中，表现最佳的模型在事实准确性和完整性方面可与人类水平媲美，但在简洁性或简练性方面则不然。自动的、基于参考的指标通常与人工判断的相关性不佳。在任务2中，系统在识别难懂术语和分类如何替换它们方面表现不佳。然而，在生成替换词时，基于LLM的系统在人工判断的准确性、完整性和简洁性方面表现良好，但在简练性方面则不然。", "conclusion": "PLABA赛道显示了使用大型语言模型改编生物医学文献以供大众使用的前景，同时也突出了它们的不足以及对改进自动基准测试工具的需求。", "translation": "目标：语言模型的最新进展显示出将面向专业人士的生物医学文献改编为通俗语言的潜力，使其可供患者和护理人员使用。然而，它们的不可预测性，加上在该领域造成危害的高可能性，意味着有必要进行严格评估。我们通过此赛道的目标是刺激研究并提供对最有前景系统的优质评估。\n方法：我们在2023年和2024年文本检索会议上举办了生物医学摘要平实语言改编（PLABA）赛道。任务包括摘要的完整（句子级）重写（任务1）以及识别和替换难懂术语（任务2）。对于任务1的自动评估，我们开发了一套四重专业编写的参考文本。任务1和任务2的提交都由生物医学专家提供了广泛的人工评估。\n结果：来自12个国家的12支团队参与了该赛道，模型范围从多层感知器到大型预训练Transformer。在任务1的人工判断中，表现最佳的模型在事实准确性和完整性方面可与人类水平媲美，但在简洁性或简练性方面则不然。自动的、基于参考的指标通常与人工判断的相关性不佳。在任务2中，系统在识别难懂术语和分类如何替换它们方面表现不佳。然而，在生成替换词时，基于LLM的系统在人工判断的准确性、完整性和简洁性方面表现良好，但在简练性方面则不然。\n结论：PLABA赛道显示了使用大型语言模型改编生物医学文献以供大众使用的前景，同时也突出了它们的不足以及对改进自动基准测试工具的需求。", "summary": "本文介绍了TREC生物医学摘要平实语言改编（PLABA）赛道，旨在评估语言模型将专业生物医学文献转化为通俗语言的能力。该赛道设置了摘要重写和难懂术语识别替换两项任务，并结合了自动和专家人工评估。结果显示，顶尖模型在事实准确性和完整性方面表现出色，但在简洁性方面仍有欠缺；自动评估指标与人工判断相关性不佳。赛道揭示了大型语言模型在此领域应用的潜力及其不足，并强调了开发更优自动评估工具的必要性。", "keywords": "生物医学摘要, 平实语言改编, 大型语言模型, TREC, 评估", "comments": "该论文通过举办PLABA赛道，为评估大型语言模型在生物医学文献通俗化方面的能力提供了一个重要平台。其创新之处在于结合了严格的人工评估，揭示了当前模型在准确性与简洁性之间的权衡，以及自动评估工具的局限性。这对于推动该领域的研究和实际应用具有重要指导意义。"}}
{"id": "2507.13516", "title": "A priori error analysis of the proximal Galerkin method", "authors": ["Brendan Keith", "Rami Masri", "Marius Zeinhofer"], "categories": ["math.NA", "cs.NA", "35J86, 35R35, 49J40, 65K15, 65N30"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13516v1", "summary": "The proximal Galerkin (PG) method is a finite element method for solving\nvariational problems with inequality constraints. It has several advantages,\nincluding constraint-preserving approximations and mesh independence. This\npaper presents the first abstract a priori error analysis of PG methods,\nproviding a general framework to establish convergence and error estimates. As\napplications of the framework, we demonstrate optimal convergence rates for\nboth the obstacle and Signorini problems using various finite element\nsubspaces.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13516v1", "cate": "math.NA", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "近端伽辽金方法的先验误差分析", "tldr": "本文首次对近端伽辽金（PG）方法进行了抽象的先验误差分析，提供了一个建立收敛性和误差估计的通用框架，并证明了其在障碍问题和西格诺里尼问题上的最优收敛速度。", "motivation": "近端伽辽金（PG）方法作为一种求解带不等式约束变分问题的有限元方法，具有约束保持近似和网格无关性等优点，但此前缺乏对其的抽象先验误差分析。本文旨在填补这一空白，提供一个通用的收敛性和误差估计框架。", "method": "本文提出了对近端伽辽金（PG）方法的首次抽象先验误差分析，提供了一个通用的框架来建立收敛性和误差估计。作为该框架的应用，研究者使用各种有限元子空间证明了障碍问题和西格诺里尼问题的最优收敛速度。", "result": "本文成功建立了近端伽辽金（PG）方法的通用收敛性和误差估计框架。通过应用该框架，证明了在障碍问题和西格诺里尼问题上使用不同有限元子空间时，PG方法可以达到最优收敛速度。", "conclusion": "本文成功提供了近端伽辽金（PG）方法的通用先验误差分析框架，并证明了其在特定应用（如障碍问题和西格诺里尼问题）中的收敛性和最优误差率，从而增强了对该方法理论基础的理解。", "translation": "近端伽辽金（PG）方法是一种求解带不等式约束变分问题的有限元方法。它具有多个优点，包括约束保持近似和网格无关性。本文首次对PG方法进行了抽象的先验误差分析，提供了一个建立收敛性和误差估计的通用框架。作为该框架的应用，我们使用各种有限元子空间证明了障碍问题和西格诺里尼问题的最优收敛速度。", "summary": "本文首次对近端伽辽金（PG）方法进行了抽象的先验误差分析，该方法是一种用于求解带不等式约束变分问题的有限元方法。文章建立了一个通用的框架来确立收敛性和误差估计，并通过在障碍问题和西格诺里尼问题上使用各种有限元子空间，展示了该框架在实现最优收敛速度方面的应用。", "keywords": "近端伽辽金方法, 先验误差分析, 变分问题, 不等式约束, 有限元方法", "comments": "本文的创新之处在于首次为近端伽辽金（PG）方法提供了抽象的先验误差分析，建立了一个通用的理论框架。这对于理解和应用具有约束保持和网格无关性等优点的PG方法具有重要意义，显著提升了该方法的理论可靠性。"}}
{"id": "2507.13686", "title": "TopicAttack: An Indirect Prompt Injection Attack via Topic Transition", "authors": ["Yulin Chen", "Haoran Li", "Yuexin Li", "Yue Liu", "Yangqiu Song", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      19 pages", "url": "http://arxiv.org/abs/2507.13686v1", "summary": "Large language models (LLMs) have shown remarkable performance across a range\nof NLP tasks. However, their strong instruction-following capabilities and\ninability to distinguish instructions from data content make them vulnerable to\nindirect prompt injection attacks. In such attacks, instructions with malicious\npurposes are injected into external data sources, such as web documents. When\nLLMs retrieve this injected data through tools, such as a search engine and\nexecute the injected instructions, they provide misled responses. Recent attack\nmethods have demonstrated potential, but their abrupt instruction injection\noften undermines their effectiveness. Motivated by the limitations of existing\nattack methods, we propose TopicAttack, which prompts the LLM to generate a\nfabricated conversational transition prompt that gradually shifts the topic\ntoward the injected instruction, making the injection smoother and enhancing\nthe plausibility and success of the attack. Through comprehensive experiments,\nTopicAttack achieves state-of-the-art performance, with an attack success rate\n(ASR) over 90\\% in most cases, even when various defense methods are applied.\nWe further analyze its effectiveness by examining attention scores. We find\nthat a higher injected-to-original attention ratio leads to a greater success\nprobability, and our method achieves a much higher ratio than the baseline\nmethods.", "comment": "19 pages", "pdf_url": "http://arxiv.org/pdf/2507.13686v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "TopicAttack：一种通过话题转换实现的间接提示注入攻击", "tldr": "TopicAttack是一种新颖的间接提示注入攻击，通过平滑的话题转换来提高攻击成功率，即使在防御下也能达到90%以上的成功率。", "motivation": "现有间接提示注入攻击方法由于突然的指令注入而效果不佳，促使作者开发一种更平滑的攻击方法。", "method": "论文提出了TopicAttack，通过让大型语言模型生成一个虚构的对话转换提示，逐步将话题引向注入的恶意指令，从而使注入更平滑，提高攻击的合理性和成功率。该方法还通过分析注意力分数来验证其有效性。", "result": "TopicAttack在大多数情况下攻击成功率（ASR）超过90%，即使应用了各种防御方法，也达到了最先进的性能。研究发现，注入内容与原始内容的注意力比率越高，成功概率越大，而TopicAttack比基线方法实现了更高的比率。", "conclusion": "TopicAttack是一种高效的间接提示注入攻击方法，通过平滑的话题转换显著提高了攻击成功率，并且其成功与更高的注入内容注意力比率相关，这表明了其在绕过防御方面的有效性。", "translation": "大型语言模型（LLMs）在一系列自然语言处理任务中表现出卓越的性能。然而，它们强大的指令遵循能力以及无法区分指令和数据内容使它们容易受到间接提示注入攻击。在此类攻击中，具有恶意目的的指令被注入到外部数据源中，例如网页文档。当LLMs通过搜索引擎等工具检索这些注入的数据并执行注入的指令时，它们会提供误导性的响应。最近的攻击方法已经展示了潜力，但它们突然的指令注入往往会削弱其有效性。受现有攻击方法局限性的启发，我们提出了TopicAttack，它促使LLM生成一个虚构的对话转换提示，逐渐将话题转向注入的指令，使注入更平滑，并增强攻击的合理性和成功率。通过全面的实验，TopicAttack在大多数情况下攻击成功率（ASR）超过90%，即使应用了各种防御方法，也达到了最先进的性能。我们通过检查注意力分数进一步分析了其有效性。我们发现，注入内容与原始内容的注意力比率越高，成功概率越大，我们的方法比基线方法实现了更高的比率。", "summary": "本论文提出了一种名为TopicAttack的新型间接提示注入攻击方法，旨在解决现有攻击中指令注入过于突兀导致效果不佳的问题。TopicAttack通过诱导大型语言模型生成一个逐渐转移话题的对话提示，从而平滑地引入恶意指令，显著提高了攻击的隐蔽性和成功率。实验结果表明，TopicAttack在多数情况下能达到90%以上的攻击成功率，即使面对多种防御措施也表现出色。进一步的分析发现，攻击成功与注入内容相对于原始内容的注意力比率呈正相关，且TopicAttack能实现更高的注意力比率。", "keywords": "间接提示注入, 大型语言模型, 话题转换, 攻击成功率, 注意力分数", "comments": "TopicAttack的创新之处在于它引入了“话题转换”的概念，使得间接提示注入更加隐蔽和自然，这比以往的直接注入方法更难防御。其高成功率和对防御的鲁棒性凸显了LLM在处理外部数据时面临的严重安全挑战。该研究对于理解和开发更有效的LLM安全防御机制具有重要意义。"}}
{"id": "2507.13577", "title": "LLM-Based Community Surveys for Operational Decision Making in Interconnected Utility Infrastructures", "authors": ["Adaeze Okeukwu-Ogbonnaya", "Rahul Amatapu", "Jason Bergtold", "George Amariucai"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13577v1", "summary": "We represent interdependent infrastructure systems and communities alike with\na hetero-functional graph (HFG) that encodes the dependencies between\nfunctionalities. This graph naturally imposes a partial order of\nfunctionalities that can inform the sequence of repair decisions to be made\nduring a disaster across affected communities. However, using such technical\ncriteria alone provides limited guidance at the point where the functionalities\ndirectly impact the communities, since these can be repaired in any order\nwithout violating the system constraints. To address this gap and improve\nresilience, we integrate community preferences to refine this partial order\nfrom the HFG into a total order. Our strategy involves getting the communities'\nopinions on their preferred sequence for repair crews to address infrastructure\nissues, considering potential constraints on resources. Due to the delay and\ncost associated with real-world survey data, we utilize a Large Language Model\n(LLM) as a proxy survey tool. We use the LLM to craft distinct personas\nrepresenting individuals, each with varied disaster experiences. We construct\ndiverse disaster scenarios, and each simulated persona provides input on\nprioritizing infrastructure repair needs across various communities. Finally,\nwe apply learning algorithms to generate a global order based on the aggregated\nresponses from these LLM-generated personas.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13577v1", "cate": "cs.SI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "基于LLM的社区调查在互联公用事业基础设施运行决策中的应用", "tldr": "本文提出了一种利用大型语言模型(LLM)作为代理调查工具，收集社区偏好以优化灾后互联基础设施修复顺序的方法，旨在提高运营决策和系统韧性。", "motivation": "现有技术标准在灾后基础设施修复决策中，尤其是在功能直接影响社区时，提供的指导有限。为了弥补这一空白并提高系统韧性，需要将社区偏好整合到修复顺序的制定中。", "method": "研究首先使用异构功能图(HFG)表示基础设施系统和社区，并编码功能依赖性，得到修复功能的偏序。为了整合社区偏好，研究利用大型语言模型(LLM)作为代理调查工具，通过创建具有不同灾难经验的独特角色，并构建多样化的灾难场景，模拟这些角色对基础设施修复优先级的输入。最后，应用学习算法聚合LLM生成的角色响应，以生成一个全局的修复全序。", "result": "本文提出并详细阐述了一种通过LLM模拟社区调查来获取社区偏好，并将其与基础设施技术依赖性结合，以生成灾后基础设施修复全局顺序的方法。该方法旨在解决传统调查数据获取的延迟和成本问题，并提升决策的全面性。", "conclusion": "文章提出了一种新颖且实用的方法，通过利用LLM模拟社区调查来获取并整合社区偏好，从而优化互联公用事业基础设施在灾害中的修复决策，有望提高系统的韧性和运营效率。", "translation": "我们使用异构功能图 (HFG) 来表示相互依赖的基础设施系统和社区，该图编码了功能之间的依赖关系。该图自然地强加了功能的偏序，可以为灾难期间受影响社区的修复决策序列提供信息。然而，单独使用此类技术标准在功能直接影响社区时提供的指导有限，因为这些功能可以以任何顺序修复而不会违反系统约束。为了弥补这一空白并提高韧性，我们整合了社区偏好，将 HFG 的偏序细化为全序。我们的策略是获取社区对其首选修复顺序的意见，以解决基础设施问题，同时考虑潜在的资源限制。由于真实世界调查数据相关的延迟和成本，我们利用大型语言模型 (LLM) 作为代理调查工具。我们使用 LLM 来创建代表不同个体的独特角色，每个角色都有不同的灾难经历。我们构建了多样化的灾难场景，每个模拟角色都提供了关于跨社区优先处理基础设施修复需求的输入。最后，我们应用学习算法，根据这些 LLM 生成角色的聚合响应生成一个全局顺序。", "summary": "本文提出了一种在互联公用事业基础设施灾害管理中，结合技术依赖性与社区偏好进行运营决策的新方法。研究首先构建异构功能图表示系统依赖性，并在此基础上，通过利用大型语言模型（LLM）作为代理调查工具，模拟社区成员的反馈。LLM被用于创建具有不同灾难经验的虚拟角色，并模拟其在多样化灾难场景中对基础设施修复优先级的判断。最终，通过学习算法聚合这些模拟响应，生成一个综合考虑技术约束和社区需求的全局修复顺序，旨在克服传统调查的局限性，提升灾后恢复的韧性和效率。", "keywords": "LLM, 社区调查, 基础设施韧性, 灾害管理, 运行决策", "comments": "本文的创新点在于将大型语言模型应用于模拟社区调查，以克服传统数据收集的成本和时间限制。这种方法为灾害管理中的运营决策提供了一个新颖的、可扩展的途径，尤其是在整合多方面利益相关者偏好方面具有重要意义。它将LLM从纯文本生成和理解扩展到复杂的决策支持系统，展示了LLM在解决实际世界问题中的巨大潜力。"}}
{"id": "2507.14082", "title": "Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications", "authors": ["Nelma Moreira", "Luca Prigioniero"], "categories": ["cs.FL", "cs.CC"], "primary_category": "Subjects:       Formal Languages and Automata Theory (cs.FL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14082v1", "summary": "The Fifteenth International Workshop on Non-Classical Models of Automata and\nApplications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025,\norganized by the Department of Computer Science at Loughborough University and\nco-located with the 26th International Conference on Descriptional Complexity\nof Formal Systems (DCFS 2025, 22-24 July).\n  The NCMA workshop series was established in 2009 as an annual event for\nresearchers working on non-classical and classical models of automata, grammars\nor related devices. Such models are investigated both as theoretical models and\nas formal models for applications from various points of view. The goal of the\nNCMA workshop series is to exchange and develop novel ideas in order to gain\ndeeper and interdisciplinary coverage of this particular area that may foster\nnew insights and substantial progress.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14082v1", "cate": "cs.FL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "第十五届非经典自动机模型与应用国际研讨会论文集", "tldr": "NCMA 2025是关于非经典自动机模型与应用的国际研讨会，旨在促进该领域的新思想交流与发展。", "motivation": "NCMA研讨会系列旨在交流和发展新颖思想，以期在该特定领域获得更深入的跨学科覆盖，从而促进新的见解和实质性进展。", "method": "Not mentioned in abstract", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "第十五届非经典自动机模型与应用国际研讨会（NCMA 2025）于2025年7月21日至22日在英国拉夫堡举行，由拉夫堡大学计算机科学系组织，并与第26届形式系统描述复杂性国际会议（DCFS 2025，7月22日至24日）同期同地举行。NCMA研讨会系列始于2009年，是一个年度盛会，面向研究非经典和经典自动机模型、文法或相关设备的研究人员。这些模型从不同角度被研究，既作为理论模型，也作为应用的正式模型。NCMA研讨会系列的目标是交流和发展新颖思想，以期在该特定领域获得更深入的跨学科覆盖，从而促进新的见解和实质性进展。", "summary": "第十五届非经典自动机模型与应用国际研讨会（NCMA 2025）于2025年7月21日至22日在英国拉夫堡举行，由拉夫堡大学计算机科学系组织，并与DCFS 2025同期同地举行。NCMA系列研讨会自2009年起每年举办，旨在为研究非经典和经典自动机、文法及相关设备的研究人员提供交流平台，促进该领域理论与应用的新思想发展和跨学科深入。", "keywords": "非经典自动机模型, 自动机, 形式系统, 研讨会, NCMA", "comments": "该论文集记录了非经典自动机模型领域的重要年度研讨会，为研究人员提供了交流最新思想和促进跨学科合作的平台，体现了该系列研讨会在推动该领域发展中的持续作用。"}}
{"id": "2507.13732", "title": "The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction", "authors": ["Guillaume Zambrano"], "categories": ["cs.CL", "cs.LG", "J.1; I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      23 pages, 24 figures shorter version submitted to JURIX 2025", "url": "http://arxiv.org/abs/2507.13732v1", "summary": "This study examines the role of human judges in legal decision-making by\nusing machine learning to predict child physical custody outcomes in French\nappellate courts. Building on the legal realism-formalism debate, we test\nwhether individual judges' decision-making patterns significantly influence\ncase outcomes, challenging the assumption that judges are neutral variables\nthat apply the law uniformly. To ensure compliance with French privacy laws, we\nimplement a strict pseudonymization process. Our analysis uses 18,937 living\narrangements rulings extracted from 10,306 cases. We compare models trained on\nindividual judges' past rulings (specialist models) with a judge-agnostic model\ntrained on aggregated data (generalist models). The prediction pipeline is a\nhybrid approach combining large language models (LLMs) for structured feature\nextraction and ML models for outcome prediction (RF, XGB and SVC). Our results\nshow that specialist models consistently achieve higher predictive accuracy\nthan the general model, with top-performing models reaching F1 scores as high\nas 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x\nmore samples. Specialist models capture stable individual patterns that are not\ntransferable to other judges. In-Domain and Cross-Domain validity tests provide\nempirical support for legal realism, demonstrating that judicial identity plays\na measurable role in legal outcomes. All data and code used will be made\navailable.", "comment": "23 pages, 24 figures shorter version submitted to JURIX 2025", "pdf_url": "http://arxiv.org/pdf/2507.13732v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "法官变量：挑战法官无关的法律判决预测", "tldr": "研究发现，法官的个人判决模式显著影响案件结果，专业模型比通用模型在预测法律判决方面更准确，支持了法律现实主义。", "motivation": "本研究旨在挑战法官是中立变量并统一适用法律的假设，通过机器学习检验个体法官的决策模式是否显著影响案件结果，并为法律现实主义提供经验支持。", "method": "本研究使用机器学习预测法国上诉法院的儿童人身监护权结果。数据包含从10,306个案件中提取的18,937份生活安排裁决。方法对比了训练于个体法官过往裁决的“专业模型”与训练于聚合数据的“通用模型”。预测流程采用混合方法，结合大型语言模型（LLMs）进行结构化特征提取，并使用RF、XGB和SVC等机器学习模型进行结果预测。研究中实施了严格的匿名化处理以遵守法国隐私法。", "result": "研究结果显示，专业模型始终比通用模型实现更高的预测准确性。专业模型的F1分数高达92.85%，而通用模型为82.63%（尽管通用模型训练样本多20到100倍）。专业模型捕捉到无法转移给其他法官的稳定个体模式。", "conclusion": "域内和跨域有效性测试为法律现实主义提供了经验支持，证明司法身份在法律结果中扮演着可衡量的角色。", "translation": "本研究通过使用机器学习预测法国上诉法院的儿童人身监护权结果，考察了人类法官在法律决策中的作用。基于法律现实主义-形式主义的辩论，我们检验了个体法官的决策模式是否显著影响案件结果，挑战了法官是统一适用法律的中立变量的假设。为确保符合法国隐私法，我们实施了严格的匿名化处理。我们的分析使用了从10,306个案件中提取的18,937份生活安排裁决。我们将训练于个体法官过往裁决的模型（专业模型）与训练于聚合数据（通用模型）的法官无关模型进行比较。预测流程采用混合方法，结合大型语言模型（LLMs）进行结构化特征提取和机器学习模型（RF、XGB和SVC）进行结果预测。我们的结果显示，专业模型始终比通用模型实现更高的预测准确性，表现最佳的模型F1分数高达92.85%，而通用模型（尽管训练样本多20到100倍）为82.63%。专业模型捕捉到无法转移给其他法官的稳定个体模式。域内和跨域有效性测试为法律现实主义提供了经验支持，表明司法身份在法律结果中扮演着可衡量的角色。所有使用的数据和代码都将公开。", "summary": "这项研究利用机器学习分析法国上诉法院的儿童抚养权案件，旨在挑战法官中立性的假设。通过比较针对个体法官训练的“专业模型”与通用模型，研究发现专业模型在预测判决结果上表现更优，F1分数高达92.85%，显著高于通用模型的82.63%。这表明法官的个人决策模式对案件结果有显著影响，为法律现实主义提供了实证支持。", "keywords": "法律判决预测, 法官变量, 法律现实主义, 机器学习, 儿童抚养权", "comments": "这篇论文通过实证数据和机器学习方法，有力地挑战了传统上关于法官中立性的假设，为法律现实主义提供了强有力的证据。其创新点在于将LLMs与传统ML模型结合用于法律判决预测，并首次量化了法官个体差异对判决结果的影响。这项研究对于理解司法过程、开发更精确的法律预测模型以及未来法律AI的应用具有重要意义。"}}
{"id": "2502.12272", "title": "Learning to Reason at the Frontier of Learnability", "authors": ["Thomas Foster", "Anya Sims", "Johannes Forkel", "Mattie Fellows", "Jakob Foerster"], "categories": ["cs.LG", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12272v5", "summary": "Reinforcement learning is now widely adopted as the final stage of large\nlanguage model training, especially for reasoning-style tasks such as maths\nproblems. Typically, models attempt each question many times during a single\ntraining step and attempt to learn from their successes and failures. However,\nwe demonstrate that throughout training with two popular algorithms (PPO and\nVinePPO) on two widely used datasets, many questions are either solved by all\nattempts - meaning they are already learned - or by none - providing no\nmeaningful training signal. To address this, we adapt a method from the\nreinforcement learning literature - sampling for learnability - and apply it to\nthe reinforcement learning stage of LLM training. Our curriculum prioritises\nquestions with high variance of success, i.e. those where the agent sometimes\nsucceeds, but not always. Our findings demonstrate that this curriculum\nconsistently boosts training performance across multiple algorithms and\ndatasets, paving the way for more efficient and effective reinforcement\nlearning with LLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12272v5", "cate": "cs.LG", "date": "2025-02-17", "updated": "2025-07-18", "AI": {"title_translation": "在可学习性前沿学习推理", "tldr": "本文提出了一种新的课程学习方法，通过优先选择成功率方差大的问题，提高了LLM在强化学习阶段的训练效率和性能。", "motivation": "强化学习在大型语言模型（LLM）训练中被广泛用于推理任务，但现有方法在训练过程中存在效率问题，即许多问题要么已被完全掌握，要么完全无法解决，导致训练信号不足。", "method": "作者改编了强化学习中的“可学习性采样”方法，并将其应用于LLM的强化学习阶段。该课程优先选择成功率方差大的问题（即有时成功但并非总是成功的问题）。", "result": "该课程在多种算法（PPO和VinePPO）和数据集上始终如一地提高了训练性能。", "conclusion": "通过优先处理可学习性高的问题，可以实现更高效和有效的LLM强化学习。", "translation": "强化学习现已广泛应用于大型语言模型训练的最后阶段，特别是对于数学问题等推理型任务。通常，模型在单个训练步骤中会尝试每个问题多次，并尝试从成功和失败中学习。然而，我们发现，在使用两种流行的算法（PPO和VinePPO）和两个广泛使用的数据集进行整个训练过程中，许多问题要么被所有尝试解决——这意味着它们已经被学习——要么一个都无法解决——这没有提供有意义的训练信号。为了解决这个问题，我们改编了强化学习文献中的一种方法——可学习性采样——并将其应用于LLM训练的强化学习阶段。我们的课程优先考虑成功率方差大的问题，即智能体有时成功但并非总是成功的问题。我们的研究结果表明，这种课程在多种算法和数据集上始终如一地提升了训练性能，为LLM的更高效和有效强化学习铺平了道路。", "summary": "本文研究了大型语言模型（LLM）在强化学习阶段进行推理任务训练时的效率问题。研究发现，现有方法在训练中存在大量问题要么已被掌握，要么无法提供有效学习信号的情况。为解决此问题，作者提出了一种基于“可学习性采样”的课程学习方法，该方法优先选择那些成功率方差大的问题。实验结果表明，这种方法在不同算法和数据集上均能显著提升训练性能，从而实现更高效的LLM强化学习。", "keywords": "强化学习, 大型语言模型, 可学习性采样, 课程学习, 推理任务", "comments": "该论文的创新点在于将强化学习中的“可学习性采样”概念引入到LLM的强化学习阶段，以解决现有训练中效率低下的问题。通过专注于那些“处于学习边界”的问题，该方法有效地优化了训练信号，提高了学习效率。其重要性体现在为LLM的强化学习提供了一种更智能、更有效的数据采样策略，有望加速模型在复杂推理任务上的能力提升。"}}
{"id": "2507.13720", "title": "Quantum Blockchain Survey: Foundations, Trends, and Gaps", "authors": ["Saurav Ghosh"], "categories": ["cs.CR", "cs.DC", "cs.ET", "cs.NI", "68M10, 81P94, 94A60 68M10, 81P94, 94A60 68M10, 81P94, 94A60", "C.2.1; E.3; K.6.5"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      12 Pages, 4 figures", "url": "http://arxiv.org/abs/2507.13720v1", "summary": "Quantum computing poses fundamental risks to classical blockchain systems by\nundermining widely used cryptographic primitives. In response, two major\nresearch directions have emerged: post-quantum blockchains, which integrate\nquantum-resistant algorithms, and quantum blockchains, which leverage quantum\nproperties such as entanglement and quantum key distribution. This survey\nreviews key developments in both areas, analyzing their cryptographic\nfoundations, architectural designs, and implementation challenges. This work\nprovides a comparative overview of technical proposals, highlight trade-offs in\nsecurity, scalability, and deployment, and identify open research problems\nacross hardware, consensus, and network design. The goal is to offer a\nstructured and comprehensive reference for advancing secure blockchain systems\nin the quantum era.", "comment": "12 Pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.13720v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "量子区块链综述：基础、趋势与空白", "tldr": "本综述探讨了量子计算对经典区块链的威胁，并回顾了应对此威胁的两种主要研究方向：后量子区块链和量子区块链，分析了它们的基础、设计、挑战，并指出了开放研究问题。", "motivation": "量子计算对经典区块链系统构成根本性风险，因为它可能破坏广泛使用的密码学原语。", "method": "本综述审查了后量子区块链和量子区块链两个领域的主要发展，分析了它们的密码学基础、架构设计和实现挑战。它还对技术提案进行了比较性概述，并指出了安全、可扩展性和部署方面的权衡，以及硬件、共识和网络设计中的开放研究问题。", "result": "本综述比较了技术提案，强调了安全性、可扩展性和部署方面的权衡，并识别了硬件、共识和网络设计中的开放研究问题。", "conclusion": "本工作的目标是为在量子时代推进安全的区块链系统提供一个结构化和全面的参考。", "translation": "量子计算通过破坏广泛使用的密码学原语，对经典区块链系统构成了根本性风险。为此，出现了两个主要研究方向：后量子区块链（集成抗量子算法）和量子区块链（利用纠缠和量子密钥分发等量子特性）。本综述回顾了这两个领域的关键发展，分析了它们的密码学基础、架构设计和实现挑战。这项工作提供了技术提案的比较性概述，强调了安全性、可扩展性和部署方面的权衡，并指出了硬件、共识和网络设计中的开放研究问题。目标是为在量子时代推进安全的区块链系统提供一个结构化和全面的参考。", "summary": "本论文是一篇综述，旨在应对量子计算对经典区块链系统构成的安全威胁。它审视了两种主要的应对策略：集成抗量子算法的后量子区块链和利用量子特性的量子区块链。该综述分析了这些方法的密码学基础、架构设计和实现挑战，并对现有技术提案进行了比较，强调了安全性、可扩展性和部署的权衡，同时指出了硬件、共识和网络设计中的未解决研究问题。其目标是为在量子时代构建安全的区块链系统提供全面的参考。", "keywords": "量子区块链, 后量子密码学, 区块链安全, 量子计算, 密码学", "comments": "这是一篇及时且重要的综述性文章，它全面梳理了量子时代区块链安全面临的挑战及其应对方案。文章的创新之处在于系统地比较了后量子区块链和量子区块链这两个新兴领域，并清晰地指出了当前的研究空白和未来发展方向，对于推动该领域的研究具有重要的指导意义。"}}
{"id": "2507.13889", "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies", "authors": ["Bilal Karaman", "Ilhan Basturk", "Ferdi Kara", "Metin Ozturk", "Sezai Taskin", "Halil Yanikomeroglu"], "categories": ["cs.NI", "eess.SP"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      accepted in PIMRC2025", "url": "http://arxiv.org/abs/2507.13889v1", "summary": "This paper investigates the integration of active reconfigurable intelligent\nsurfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance\nnon-terrestrial network (NTN) performance in next-generation wireless systems.\nWhile prior studies focused on passive RIS architectures, the severe path loss\nand double fading in long-distance HAPS links make active RIS a more suitable\nalternative due to its inherent signal amplification capabilities. We formulate\na sum-rate maximization problem to jointly optimize power allocation and RIS\nelement assignment for ground user equipments (UEs) supported by a HAPS-based\nactive RIS-assisted communication system. To reduce power consumption and\nhardware complexity, several sub-connected active RIS architectures are also\nexplored. Simulation results reveal that active RIS configurations\nsignificantly outperform passive RIS in terms of quality of service (QoS).\nMoreover, although fully-connected architectures achieve the highest\nthroughput, sub-connected schemes demonstrate superior energy efficiency under\npractical power constraints. These findings highlight the potential of active\nRIS-enabled HAPS systems to meet the growing demands of beyond-cellular\ncoverage and green networking.", "comment": "accepted in PIMRC2025", "pdf_url": "http://arxiv.org/pdf/2507.13889v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "关于HAPS和主动RIS技术融合中和速率与能效权衡的研究", "tldr": "本文研究了HAPS与主动RIS的集成，以提高非地面网络性能，并通过仿真证明了主动RIS相比被动RIS的优势，以及子连接架构在能效方面的优越性。", "motivation": "为了增强下一代无线系统中非地面网络（NTN）的性能，本文研究了将主动可重构智能表面（RIS）中继与高空平台站（HAPS）集成。鉴于长距离HAPS链路中严重的路径损耗和双重衰落，以及主动RIS固有的信号放大能力，主动RIS被认为是比现有被动RIS架构更合适的替代方案。", "method": "本文构建了一个和速率最大化问题，以联合优化由HAPS辅助的主动RIS通信系统支持的地面用户设备（UEs）的功率分配和RIS单元分配。此外，为降低功耗和硬件复杂性，还探讨了几种子连接的主动RIS架构。", "result": "仿真结果表明，主动RIS配置在服务质量（QoS）方面显著优于被动RIS。此外，尽管全连接架构实现了最高的吞吐量，但在实际功率限制下，子连接方案表现出卓越的能量效率。", "conclusion": "这些研究结果强调了主动RIS使能的HAPS系统在满足超越蜂窝覆盖和绿色网络日益增长的需求方面的潜力。", "translation": "本文研究了主动可重构智能表面（RIS）中继与高空平台站（HAPS）的集成，以增强下一代无线系统中的非地面网络（NTN）性能。虽然先前的研究主要集中在被动RIS架构上，但长距离HAPS链路中严重的路径损耗和双重衰落使得主动RIS成为一个更合适的替代方案，因为它具有固有的信号放大能力。我们提出了一个和速率最大化问题，以联合优化由HAPS辅助的主动RIS通信系统支持的地面用户设备（UEs）的功率分配和RIS单元分配。为了降低功耗和硬件复杂性，本文还探讨了几种子连接的主动RIS架构。仿真结果表明，主动RIS配置在服务质量（QoS）方面显著优于被动RIS。此外，尽管全连接架构实现了最高的吞吐量，但在实际功率限制下，子连接方案表现出卓越的能量效率。这些发现突出了主动RIS使能的HAPS系统在满足超越蜂窝覆盖和绿色网络日益增长的需求方面的潜力。", "summary": "本文探讨了高空平台站（HAPS）与主动可重构智能表面（RIS）的集成，以提升下一代无线系统中的非地面网络（NTN）性能。针对长距离HAPS链路中的严重损耗，研究指出主动RIS因其信号放大能力优于被动RIS。通过构建和速率最大化问题，优化了功率分配和RIS单元分配。同时，为降低复杂性，也探索了子连接架构。仿真结果表明，主动RIS在服务质量上显著优于被动RIS，且子连接架构在能效方面表现更优，揭示了该技术在扩展覆盖和绿色网络中的潜力。", "keywords": "HAPS, 主动RIS, 和速率, 能量效率, 非地面网络", "comments": "该论文创新性地将主动RIS技术引入HAPS系统，解决了传统被动RIS在长距离HAPS链路中性能受限的问题。通过联合优化和探索子连接架构，不仅提升了系统性能，还在能效方面取得了显著进展，对未来非地面网络和绿色通信具有重要指导意义。"}}
{"id": "2507.13681", "title": "LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues", "authors": ["Haoyang Li", "Zhanchao Xu", "Yiming Li", "Xuejia Chen", "Darian Li", "Anxin Tian", "Qingfa Xiao", "Cheng Deng", "Jun Wang", "Qing Li", "Lei Chen", "Mingxuan Yuan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13681v1", "summary": "Multi-turn dialogues are essential in many real-world applications of large\nlanguage models, such as chatbots and virtual assistants. As conversation\nhistories become longer, existing large language models face increasing\ncomputational and memory challenges, which hinder their ability to provide\nefficient and responsive interactions. Most current acceleration methods either\ncompress the context or optimize key value caching, but they often rely on\nfixed or position-based heuristics that do not adapt well to the dynamic and\nunpredictable patterns found in actual multi-turn conversations. In this paper,\nwe present LoopServe, an adaptive dual-phase inference acceleration framework\nfor large language models in multi-turn dialogues. LoopServe introduces two\nmain innovations. First, it performs online sparsification during the\nprefilling phase by dynamically selecting the most important parts of the\nattention matrix for each new input. Second, it uses progressive key value\ncompression during decoding by adaptively maintaining a relevant and efficient\ncache based on the most recently generated output tokens. We also propose a\n\\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new\nbenchmark} with eleven multi-turn datasets that reflect realistic query\npositions and conversational dependencies. Extensive experiments demonstrate\nthat LoopServe consistently achieves superior effectiveness compared to\nexisting baselines and significantly accelerates LLM inference across a wide\nrange of long-context dialogue tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13681v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "LoopServe：一种用于多轮对话的自适应双阶段大型语言模型推理加速系统", "tldr": "LoopServe是一种自适应双阶段LLM推理加速系统，通过在线稀疏化和渐进式KV压缩来解决多轮对话中LLM的计算和内存挑战，并在新基准测试上表现出卓越的性能。", "motivation": "在多轮对话中，随着对话历史变长，现有的大型语言模型面临日益增长的计算和内存挑战，这阻碍了它们提供高效和响应式交互的能力。大多数现有加速方法依赖固定或基于位置的启发式方法，无法很好地适应实际多轮对话中动态和不可预测的模式。", "method": "LoopServe引入了两项主要创新：1. 在预填充阶段进行在线稀疏化，动态选择注意力矩阵中最重要的部分用于每个新输入。2. 在解码阶段使用渐进式键值压缩，根据最近生成的输出令牌自适应地维护相关且高效的缓存。论文还提出了一个包含11个多轮数据集的新基准测试。", "result": "实验表明，LoopServe与现有基线相比始终实现卓越的有效性，并显著加速了各种长上下文对话任务中的LLM推理。", "conclusion": "LoopServe通过其自适应双阶段方法显著提高了多轮对话中大型语言模型的推理效率和响应能力，解决了现有方法的局限性。", "translation": "多轮对话在大型语言模型的许多实际应用中至关重要，例如聊天机器人和虚拟助手。随着对话历史变得更长，现有的大型语言模型面临日益增长的计算和内存挑战，这阻碍了它们提供高效和响应式交互的能力。大多数当前的加速方法要么压缩上下文，要么优化键值缓存，但它们通常依赖固定或基于位置的启发式方法，无法很好地适应实际多轮对话中动态和不可预测的模式。在本文中，我们提出了LoopServe，一个用于多轮对话中大型语言模型的自适应双阶段推理加速框架。LoopServe引入了两项主要创新。首先，它在预填充阶段通过动态选择注意力矩阵中最重要的部分进行在线稀疏化，以适应每个新输入。其次，它在解码阶段通过根据最近生成的输出令牌自适应地维护相关且高效的缓存来使用渐进式键值压缩。我们还提出了一个包含11个多轮数据集的新基准测试，这些数据集反映了真实的查询位置和对话依赖性。广泛的实验表明，与现有基线相比，LoopServe始终实现卓越的有效性，并显著加速了各种长上下文对话任务中的LLM推理。", "summary": "LoopServe是一种针对多轮对话中大型语言模型推理的自适应双阶段加速系统。它通过在预填充阶段动态稀疏化注意力矩阵和在解码阶段渐进式压缩键值缓存来解决现有方法的局限性，这些方法通常不适应对话的动态性。该系统还在一个包含11个多轮数据集的新基准测试上进行了评估，实验证明它在长上下文对话任务中比现有基线更有效并显著加速LLM推理。", "keywords": "LLM推理加速, 多轮对话, 在线稀疏化, 键值压缩, 自适应系统", "comments": "LoopServe的创新在于其双阶段的自适应方法，分别在预填充和解码阶段进行优化，特别是动态选择注意力矩阵部分和渐进式KV压缩，这使其能够更好地适应多轮对话的动态性。此外，提出新的基准测试也增加了论文的重要性，为LLM在长上下文多轮对话中的评估提供了更真实的场景。"}}
{"id": "2507.13981", "title": "Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset", "authors": ["Sara Abdulaziz", "Giacomo D'Amicantonio", "Egor Bondarev"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted at ICCV'25 workshop CV4BIOM", "url": "http://arxiv.org/abs/2507.13981v1", "summary": "Recent advances in AI-powered surveillance have intensified concerns over the\ncollection and processing of sensitive personal data. In response, research has\nincreasingly focused on privacy-by-design solutions, raising the need for\nobjective techniques to evaluate privacy protection. This paper presents a\ncomprehensive framework for evaluating visual privacy-protection methods across\nthree dimensions: privacy, utility, and practicality. In addition, it\nintroduces HR-VISPR, a publicly available human-centric dataset with biometric,\nsoft-biometric, and non-biometric labels to train an interpretable privacy\nmetric. We evaluate 11 privacy protection methods, ranging from conventional\ntechniques to advanced deep-learning methods, through the proposed framework.\nThe framework differentiates privacy levels in alignment with human visual\nperception, while highlighting trade-offs between privacy, utility, and\npracticality. This study, along with the HR-VISPR dataset, serves as an\ninsightful tool and offers a structured evaluation framework applicable across\ndiverse contexts.", "comment": "accepted at ICCV'25 workshop CV4BIOM", "pdf_url": "http://arxiv.org/pdf/2507.13981v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "人类视觉隐私保护评估：一个三维框架和基准数据集", "tldr": "本文提出了一个用于评估视觉隐私保护方法的三维框架（隐私、效用、实用性）和一个名为HR-VISPR的人类中心数据集，并用其评估了11种隐私保护方法，揭示了隐私、效用和实用性之间的权衡。", "motivation": "随着AI驱动的监控技术发展，个人敏感数据收集和处理的担忧日益加剧，因此需要客观的技术来评估隐私保护方案。", "method": "本文提出了一个用于评估视觉隐私保护方法的三维框架，涵盖隐私、效用和实用性维度。同时，引入了HR-VISPR数据集，这是一个公开可用、以人为中心的包含生物识别、软生物识别和非生物识别标签的数据集，用于训练可解释的隐私指标。通过该框架评估了11种隐私保护方法。", "result": "该框架能够根据人类视觉感知区分隐私级别，并突出了隐私、效用和实用性之间的权衡。", "conclusion": "这项研究连同HR-VISPR数据集，提供了一个有洞察力的工具和适用于不同场景的结构化评估框架。", "translation": "AI驱动的监控技术近期发展，加剧了人们对敏感个人数据收集和处理的担忧。为此，研究日益关注隐私设计（privacy-by-design）解决方案，这提升了对评估隐私保护客观技术的需求。本文提出了一个用于评估视觉隐私保护方法的综合框架，该框架涵盖隐私、效用和实用性三个维度。此外，本文还引入了HR-VISPR，这是一个公开可用、以人为中心的包含生物识别、软生物识别和非生物识别标签的数据集，用于训练可解释的隐私指标。我们通过所提出的框架评估了11种隐私保护方法，范围从传统技术到先进的深度学习方法。该框架能够根据人类视觉感知区分隐私级别，同时突出了隐私、效用和实用性之间的权衡。这项研究连同HR-VISPR数据集，作为一个有洞察力的工具，提供了一个适用于不同场景的结构化评估框架。", "summary": "本文针对AI监控下个人数据隐私问题，提出了一个评估视觉隐私保护方法的三维框架（隐私、效用、实用性）和一个名为HR-VISPR的公开人类中心数据集。该研究利用此框架评估了11种隐私保护方法，并揭示了隐私、效用和实用性之间的权衡。该框架和数据集为隐私保护评估提供了结构化工具。", "keywords": "视觉隐私保护, 评估框架, 基准数据集, HR-VISPR, 隐私设计", "comments": "该论文的创新之处在于提出了一个新颖的三维评估框架和HR-VISPR数据集，为视觉隐私保护方法的客观评估提供了标准化的工具和基准。这对于推动隐私保护技术的发展和应用具有重要意义，尤其是在当前AI监控日益普及的背景下。"}}
{"id": "2501.05000", "title": "Load Forecasting for Households and Energy Communities: Are Deep Learning Models Worth the Effort?", "authors": ["Lukas Moosbrugger", "Valentin Seiler", "Philipp Wohlgenannt", "Sebastian Hegenbart", "Sashko Ristov", "Elias Eder", "Peter Kepplinger"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.05000v5", "summary": "Energy communities (ECs) play a key role in enabling local demand shifting\nand enhancing self-sufficiency, as energy systems transition toward\ndecentralized structures with high shares of renewable generation. To optimally\noperate them, accurate short-term load forecasting is essential, particularly\nfor implementing demand-side management strategies. With the recent rise of\ndeep learning methods, data-driven forecasting has gained significant\nattention, however, it remains insufficiently explored in many practical\ncontexts. Therefore, this study evaluates the effectiveness of state-of-the-art\ndeep learning models-including LSTM, xLSTM, and Transformer\narchitectures-compared to traditional benchmarks such as K-Nearest Neighbors\n(KNN) and persistence forecasting, across varying community size, historical\ndata availability, and model complexity. Additionally, we assess the benefits\nof transfer learning using publicly available synthetic load profiles. On\naverage, transfer learning improves the normalized mean absolute error by 1.97\npercentage points when only two months of training data are available.\nInterestingly, for less than six months of training data, simple persistence\nmodels outperform deep learning architectures in forecast accuracy. The\npractical value of improved forecasting is demonstrated using a mixed-integer\nlinear programming optimization for ECs with a shared battery energy storage\nsystem. For an energy community with 50 households, the most accurate deep\nlearning model achieves an average reduction in financial energy costs of\n8.06%. Notably, a simple KNN approach achieves average savings of 8.01%, making\nit a competitive and robust alternative. All implementations are publicly\navailable to facilitate reproducibility. These findings offer actionable\ninsights for ECs, and they highlight when the additional complexity of deep\nlearning is warranted by performance gains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.05000v5", "cate": "cs.LG", "date": "2025-01-09", "updated": "2025-07-18", "AI": {"title_translation": "家庭和能源社区的负荷预测：深度学习模型值得付出努力吗？", "tldr": "对于能源社区的负荷预测，深度学习模型与更简单的模型相比，益处有限，尤其是在数据量不足时。简单的模型如KNN可以实现可比的财务节约。", "motivation": "能源社区在能源系统转型中扮演关键角色，需要准确的短期负荷预测以优化运营和实施需求侧管理。尽管深度学习在数据驱动预测中受到关注，但在许多实际场景中探索不足。本研究旨在评估深度学习模型在这些场景中是否值得投入。", "method": "本研究评估了最先进的深度学习模型（包括LSTM、xLSTM和Transformer架构）与传统基准（如K-近邻（KNN）和持久性预测）的有效性。比较涵盖了不同的社区规模、历史数据可用性和模型复杂性。此外，还评估了使用公开合成负荷曲线进行迁移学习的益处。通过对拥有共享电池储能系统的能源社区进行混合整数线性规划优化，证明了改进预测的实际价值。", "result": "当只有两个月的训练数据可用时，迁移学习平均将归一化平均绝对误差提高了1.97个百分点。当训练数据少于六个月时，简单的持久性模型在预测精度上优于深度学习架构。对于一个拥有50户家庭的能源社区，最准确的深度学习模型平均可将财务能源成本降低8.06%，而简单的KNN方法实现了平均8.01%的节省。", "conclusion": "研究结果为能源社区提供了可操作的见解，强调了何时深度学习的额外复杂性能够通过性能提升得到证明。简单的模型如KNN也具有很强的竞争力。", "translation": "能源社区 (EC) 在能源系统向可再生能源高占比的分散式结构转型过程中，通过实现本地需求侧转移和增强自给自足能力发挥着关键作用。为了对其进行优化运营，准确的短期负荷预测至关重要，特别是对于实施需求侧管理策略而言。随着深度学习方法的兴起，数据驱动的预测受到了广泛关注，然而，在许多实际应用场景中，其探索仍不充分。因此，本研究评估了最先进的深度学习模型（包括 LSTM、xLSTM 和 Transformer 架构）与传统基准（如 K-近邻 (KNN) 和持久性预测）相比的有效性，涵盖了不同的社区规模、历史数据可用性和模型复杂性。此外，我们还评估了使用公开可用的合成负荷曲线进行迁移学习的益处。平均而言，当只有两个月的训练数据可用时，迁移学习将归一化平均绝对误差提高了 1.97 个百分点。有趣的是，当训练数据少于六个月时，简单的持久性模型在预测精度上优于深度学习架构。通过对拥有共享电池储能系统的能源社区进行混合整数线性规划优化，证明了改进预测的实际价值。对于一个拥有 50 户家庭的能源社区，最准确的深度学习模型平均可将财务能源成本降低 8.06%。值得注意的是，简单的 KNN 方法实现了平均 8.01% 的节省，使其成为一种具有竞争力的强大替代方案。所有实现均已公开，以方便重现。这些发现为能源社区提供了可操作的见解，并强调了何时深度学习的额外复杂性能够通过性能提升得到证明。", "summary": "本研究评估了最先进的深度学习模型（LSTM、xLSTM、Transformer）在能源社区短期负荷预测中的有效性，并将其与KNN和持久性预测等传统方法进行比较。研究考虑了不同的社区规模、数据可用性和模型复杂性，并评估了迁移学习的益处。结果表明，尽管迁移学习在数据有限时提供了一些改进，但当训练数据少于六个月时，简单的持久性模型在预测精度上优于深度学习。尽管深度学习可以为能源社区降低能源成本（例如，对于50户家庭的社区降低8.06%），但简单的KNN方法也能实现可比的节省（8.01%），这表明深度学习的额外复杂性通常不一定能带来显著优势。这些发现为能源社区何时采用深度学习提供了实用见解。", "keywords": "负荷预测, 深度学习, 能源社区, 迁移学习, KNN", "comments": "本论文的创新之处在于其对深度学习模型与传统基准在能源社区负荷预测领域的全面比较分析，明确探讨了深度学习的复杂性是否物有所值。其重要性在于为能源社区提供了实用的、可操作的见解，特别是突出了KNN等简单模型的竞争性能，这挑战了“越复杂模型越好”的普遍假设。一个潜在的局限性是，财务节约是基于特定共享电池优化场景的，其普适性可能需要进一步验证。"}}
{"id": "2507.13926", "title": "Developers Insight On Manifest v3 Privacy and Security Webextensions", "authors": ["Libor Polčák", "Giorgio Maone", "Michael McMahon", "Martin Bednář"], "categories": ["cs.CR", "cs.CY"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      WEBIST'25, Marbella, Spain", "url": "http://arxiv.org/abs/2507.13926v1", "summary": "Webextensions can improve web browser privacy, security, and user experience.\nThe APIs offered by the browser to webextensions affect possible functionality.\nCurrently, Chrome transitions to a modified set of APIs called Manifest v3.\nThis paper studies the challenges and opportunities of Manifest v3 with an\nin-depth structured qualitative research. Even though some projects observed\npositive effects, a majority expresses concerns over limited benefits to users,\nremoval of crucial APIs, or the need to find workarounds. Our findings indicate\nthat the transition affects different types of webextensions differently; some\ncan migrate without losing functionality, while other projects remove\nfunctionality or decline to update. The respondents identified several critical\nmissing APIs, including reliable APIs to inject content scripts, APIs for\nstoring confidential content, and others.", "comment": "WEBIST'25, Marbella, Spain", "pdf_url": "http://arxiv.org/pdf/2507.13926v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "开发者对 Manifest v3 隐私和安全网络扩展的见解", "tldr": "Chrome Manifest v3 更新对网络扩展开发者造成挑战，因为移除了关键API，导致功能受限或需要变通方案，并影响了不同类型的扩展。", "motivation": "研究Chrome浏览器向Manifest v3 API集过渡所带来的挑战和机遇，以及其对网络扩展隐私和安全功能实现的影响。", "method": "采用深入的结构化定性研究方法。", "result": "多数开发者对Manifest v3表示担忧，认为其对用户的好处有限，移除了关键API，且需要寻找变通方案。过渡对不同类型的网络扩展影响不同，一些可以无损迁移，而另一些则移除功能或拒绝更新。受访者指出了几个关键的缺失API，包括注入内容脚本、存储机密内容的API等。", "conclusion": "Manifest v3的过渡给许多网络扩展开发者带来了显著挑战，由于API限制导致部分项目功能受损或拒绝更新。", "translation": "网络扩展可以改善网络浏览器的隐私、安全和用户体验。浏览器提供给网络扩展的API会影响其可能的功能。目前，Chrome正在过渡到一组称为Manifest v3 的修改版API。本文通过深入的结构化定性研究，探讨了Manifest v3的挑战和机遇。尽管一些项目观察到了积极影响，但大多数项目对用户受益有限、关键API的移除或需要寻找变通方案表示担忧。我们的研究结果表明，这种过渡对不同类型的网络扩展影响不同；一些可以无损迁移，而其他项目则移除功能或拒绝更新。受访者指出了几个关键的缺失API，包括可靠的内容脚本注入API、存储机密内容的API等。", "summary": "本文通过深入的定性研究，探讨了Chrome浏览器从现有API向Manifest v3过渡对网络扩展开发者带来的影响。研究发现，尽管少数项目有积极体验，但大多数开发者对Manifest v3表示担忧，主要原因包括用户受益有限、关键API的移除以及需要变通方案。这种过渡对不同类型的扩展影响不一，导致部分扩展功能受损或停止更新，并揭示了若干关键API的缺失。", "keywords": "Manifest v3, Webextensions, 隐私, 安全, 开发者见解", "comments": "这项研究通过直接获取开发者反馈，揭示了Chrome Manifest v3更新对网络扩展生态系统的深远影响，尤其是在隐私和安全功能实现上的挑战。其创新之处在于提供了定性数据，突出了开发者在实际迁移中面临的具体问题，如关键API的缺失，这对于浏览器厂商改进API设计和支持开发者至关重要。研究强调了不同类型扩展受影响的差异性，为未来策略制定提供了有价值的洞察。"}}
{"id": "2507.13872", "title": "Safe and Performant Controller Synthesis using Gradient-based Model Predictive Control and Control Barrier Functions", "authors": ["Aditya Singh", "Aastha Mishra", "Manan Tayal", "Shishir Kolathaya", "Pushpak Jagtap"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 Pages, 2 Figures. The first two authors contributed equally", "url": "http://arxiv.org/abs/2507.13872v1", "summary": "Ensuring both performance and safety is critical for autonomous systems\noperating in real-world environments. While safety filters such as Control\nBarrier Functions (CBFs) enforce constraints by modifying nominal controllers\nin real time, they can become overly conservative when the nominal policy lacks\nsafety awareness. Conversely, solving State-Constrained Optimal Control\nProblems (SC-OCPs) via dynamic programming offers formal guarantees but is\nintractable in high-dimensional systems. In this work, we propose a novel\ntwo-stage framework that combines gradient-based Model Predictive Control (MPC)\nwith CBF-based safety filtering for co-optimizing safety and performance. In\nthe first stage, we relax safety constraints as penalties in the cost function,\nenabling fast optimization via gradient-based methods. This step improves\nscalability and avoids feasibility issues associated with hard constraints. In\nthe second stage, we modify the resulting controller using a CBF-based\nQuadratic Program (CBF-QP), which enforces hard safety constraints with minimal\ndeviation from the reference. Our approach yields controllers that are both\nperformant and provably safe. We validate the proposed framework on two case\nstudies, showcasing its ability to synthesize scalable, safe, and\nhigh-performance controllers for complex, high-dimensional autonomous systems.", "comment": "6 Pages, 2 Figures. The first two authors contributed equally", "pdf_url": "http://arxiv.org/pdf/2507.13872v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用基于梯度的模型预测控制和控制障碍函数进行安全高性能控制器合成", "tldr": "本文提出了一种结合梯度MPC和CBF安全滤波器的两阶段框架，用于合成高维自主系统的安全且高性能控制器。", "motivation": "在现实环境中，自主系统需要兼顾性能和安全性。现有方法存在局限：控制障碍函数(CBF)安全滤波器在标称策略缺乏安全意识时可能过于保守；而通过动态规划解决状态约束最优控制问题(SC-OCP)在高维系统中难以处理。", "method": "本文提出一种新颖的两阶段框架，结合了基于梯度的模型预测控制(MPC)和基于CBF的安全滤波。第一阶段，将安全约束放松为成本函数中的惩罚项，通过基于梯度的方法实现快速优化，提高可伸缩性并避免硬约束带来的可行性问题。第二阶段，使用基于CBF的二次规划(CBF-QP)修改第一阶段的控制器，以最小偏差强制执行硬安全约束。", "result": "该方法合成的控制器既具有高性能，又具有可证明的安全性。通过两个案例研究验证了该框架，展示了其为复杂高维自主系统合成可伸缩、安全、高性能控制器的能力。", "conclusion": "本文提出的结合梯度MPC和CBF安全滤波器的两阶段框架，能够为高维自主系统合成同时兼顾性能和可证明安全性的控制器。", "translation": "确保性能和安全性对于在现实环境中运行的自主系统至关重要。虽然控制障碍函数（CBFs）等安全滤波器通过实时修改标称控制器来强制执行约束，但当标称策略缺乏安全意识时，它们可能会变得过于保守。相反，通过动态规划解决状态约束最优控制问题（SC-OCPs）提供了形式上的保证，但在高维系统中难以处理。在这项工作中，我们提出了一种新颖的两阶段框架，该框架结合了基于梯度的模型预测控制（MPC）和基于CBF的安全滤波，以共同优化安全性和性能。在第一阶段，我们将安全约束放松为成本函数中的惩罚项，从而通过基于梯度的方法实现快速优化。这一步骤提高了可伸缩性，并避免了与硬约束相关的可行性问题。在第二阶段，我们使用基于CBF的二次规划（CBF-QP）修改所得控制器，该规划以最小偏差强制执行硬安全约束。我们的方法产生的控制器既高性能又可证明安全。我们通过两个案例研究验证了所提出的框架，展示了其为复杂、高维自主系统合成可伸缩、安全和高性能控制器的能力。", "summary": "本文提出了一种新颖的两阶段框架，旨在为高维自主系统合成兼具高性能和可证明安全性的控制器。针对现有安全滤波器过于保守和状态约束最优控制问题在高维系统中难以处理的挑战，该方法在第一阶段通过将安全约束作为惩罚项引入基于梯度的MPC，实现快速优化和可伸缩性。随后，在第二阶段利用CBF-QP对控制器进行微调，以最小偏差强制执行严格的安全约束。实验验证表明，该框架能有效合成安全且高性能的控制器。", "keywords": "模型预测控制, 控制障碍函数, 安全性, 性能, 高维系统", "comments": "这项工作通过结合梯度MPC的效率和CBF的严格安全保证，为高维自主系统的控制器合成提供了一个创新的解决方案。其两阶段方法巧妙地解决了性能优化与硬安全约束之间的权衡，并提高了可伸缩性，具有重要的实际应用价值。"}}
{"id": "2507.13954", "title": "Robust Anomaly Detection with Graph Neural Networks using Controllability", "authors": ["Yifan Wei", "Anwar Said", "Waseem Abbas", "Xenofon Koutsoukos"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      conference paper published in IEEE CAI 2025", "url": "http://arxiv.org/abs/2507.13954v1", "summary": "Anomaly detection in complex domains poses significant challenges due to the\nneed for extensive labeled data and the inherently imbalanced nature of\nanomalous versus benign samples. Graph-based machine learning models have\nemerged as a promising solution that combines attribute and relational data to\nuncover intricate patterns. However, the scarcity of anomalous data exacerbates\nthe challenge, which requires innovative strategies to enhance model learning\nwith limited information. In this paper, we hypothesize that the incorporation\nof the influence of the nodes, quantified through average controllability, can\nsignificantly improve the performance of anomaly detection. We propose two\nnovel approaches to integrate average controllability into graph-based\nframeworks: (1) using average controllability as an edge weight and (2)\nencoding it as a one-hot edge attribute vector. Through rigorous evaluation on\nreal-world and synthetic networks with six state-of-the-art baselines, our\nproposed methods demonstrate improved performance in identifying anomalies,\nhighlighting the critical role of controllability measures in enhancing the\nperformance of graph machine learning models. This work underscores the\npotential of integrating average controllability as additional metrics to\naddress the challenges of anomaly detection in sparse and imbalanced datasets.", "comment": "conference paper published in IEEE CAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13954v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于可控性的图神经网络鲁棒异常检测", "tldr": "该研究提出将平均可控性整合到图神经网络中，以提高稀疏和不平衡数据集上的异常检测性能。", "motivation": "在复杂领域中，由于需要大量标记数据以及异常样本与正常样本固有的不平衡性，异常检测面临重大挑战。图机器学习模型虽有潜力，但异常数据的稀缺性进一步加剧了信息受限下模型学习的挑战。", "method": "作者提出了两种将平均可控性整合到图框架中的新方法：1) 将平均可控性用作边权重；2) 将其编码为独热边属性向量。", "result": "通过在真实世界和合成网络上与六种最先进的基线进行严格评估，所提出的方法在识别异常方面表现出改进的性能。", "conclusion": "这项工作强调了将平均可控性作为额外指标整合的潜力，以解决稀疏和不平衡数据集中的异常检测挑战。", "translation": "复杂领域中的异常检测由于需要大量标记数据以及异常样本与正常样本固有的不平衡性而面临重大挑战。基于图的机器学习模型作为一种有前途的解决方案出现，它结合了属性和关系数据来揭示复杂的模式。然而，异常数据的稀缺性加剧了挑战，这需要创新的策略来利用有限的信息增强模型学习。在本文中，我们假设通过平均可控性量化的节点影响力的纳入可以显著提高异常检测的性能。我们提出了两种将平均可控性整合到基于图的框架中的新方法：(1) 将平均可控性用作边权重，以及 (2) 将其编码为独热边属性向量。通过在真实世界和合成网络上与六种最先进的基线进行严格评估，我们提出的方法在识别异常方面表现出改进的性能，突出了可控性度量在增强图机器学习模型性能中的关键作用。这项工作强调了将平均可控性作为额外指标整合的潜力，以解决稀疏和不平衡数据集中的异常检测挑战。", "summary": "本文针对复杂领域中异常检测面临的标记数据稀缺和数据不平衡问题，提出了一种基于图神经网络的鲁棒异常检测方法。作者假设通过平均可控性量化的节点影响力可以显著提高异常检测性能。为此，他们提出了两种创新方法：将平均可控性用作边权重或将其编码为独热边属性向量。实验结果表明，在真实世界和合成网络上，所提出的方法相比现有基线表现出更优的异常识别能力，证明了可控性度量在提升图机器学习模型性能方面的关键作用。", "keywords": "异常检测, 图神经网络, 可控性, 不平衡数据集, 图机器学习", "comments": "该论文的创新点在于将“平均可控性”这一新颖的概念引入到图神经网络的异常检测中，有效地解决了稀疏和不平衡数据集的挑战。这种将网络结构特性（可控性）与节点影响力相结合的方法，为图学习中的特征工程提供了新的思路，具有重要的理论和实践意义。"}}
{"id": "2502.06683", "title": "Solving Optimal Power Flow on a Data-Budget: Feature Selection on Smart Meter Data", "authors": ["Vassilis Kekatos", "Ridley Annin", "Manish K. Singh", "Junjie Qin"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      12 pages, 8 figures, 1 table", "url": "http://arxiv.org/abs/2502.06683v2", "summary": "How much data is needed to optimally schedule distributed energy resources\n(DERs)? Does the distribution system operator (DSO) have to know load demands\nat each bus of the feeder to solve an optimal power flow (OPF)? This work\nexploits redundancies in OPF's structure and data to minimize the communication\nof such a data deluge, and explores the trade-off between data compression and\nthe grid's performance. We propose an OPF data distillation framework involving\ntwo steps: The DSO first collects OPF data from only a subset of nodes. It\nsubsequently reconstructs the complete OPF data from the partial ones, and\nfeeds them into the OPF solver. Selecting and reconstructing OPF data may be\nperformed to maximize the fidelity of the reconstructed data or the associated\nOPF solutions. Under the first objective, OPF data distillation is posed as a\nsparsity-regularized convex problem. Under the second objective, it is posed as\na sparsity-regularized bilevel program. Both problems are solved using proximal\ngradient algorithms. The second objective is superior in approximating OPF\nsolutions at the expense of increased complexity. Numerical tests show that it\nenhances the fidelity and feasibility of the reconstructed OPF solutions, which\ncan be approximated reasonably well even from partial data.", "comment": "12 pages, 8 figures, 1 table", "pdf_url": "http://arxiv.org/pdf/2502.06683v2", "cate": "eess.SY", "date": "2025-02-10", "updated": "2025-07-18", "AI": {"title_translation": "预算数据下的最优潮流求解：智能电表数据上的特征选择", "tldr": "本文提出一种OPF数据蒸馏框架，通过从部分节点收集数据并重建，以减少通信量，并在数据压缩和电网性能之间取得平衡。", "motivation": "解决在调度分布式能源时需要多少数据的问题，以及配电系统运营商是否需要知道每个母线上的负荷需求来求解最优潮流（OPF），旨在最小化大量数据通信。", "method": "提出一个两步的OPF数据蒸馏框架：首先，配电系统运营商（DSO）仅从部分节点收集OPF数据；其次，从部分数据中重建完整的OPF数据并输入到OPF求解器。数据选择和重建可以旨在最大化重建数据的保真度或相关OPF解的保真度。第一个目标下，问题被建模为稀疏正则化凸问题；第二个目标下，问题被建模为稀疏正则化双层规划。两者都使用近端梯度算法求解。", "result": "第二个目标在近似OPF解方面更优越，但复杂度更高。数值测试表明，它能提高重建OPF解的保真度和可行性，即使从部分数据也能很好地近似。", "conclusion": "通过所提出的数据蒸馏框架，最优潮流解即使从部分智能电表数据也能合理地近似，从而减少了所需的数据通信量，并在数据压缩和电网性能之间实现了权衡。", "translation": "如何以最优方式调度分布式能源（DER）需要多少数据？配电系统运营商（DSO）是否必须知道馈线每个母线上的负荷需求才能求解最优潮流（OPF）？这项工作利用OPF结构和数据中的冗余，以最小化此类数据洪流的通信，并探讨了数据压缩和电网性能之间的权衡。我们提出了一个OPF数据蒸馏框架，包括两个步骤：DSO首先仅从节点子集收集OPF数据。随后，它从部分数据中重建完整的OPF数据，并将其输入到OPF求解器。选择和重建OPF数据可以是为了最大化重建数据的保真度或相关OPF解的保真度。在第一个目标下，OPF数据蒸馏被视为一个稀疏正则化凸问题。在第二个目标下，它被视为一个稀疏正则化双层规划。这两个问题都使用近端梯度算法求解。第二个目标在近似OPF解方面更优越，但代价是增加了复杂性。数值测试表明，它提高了重建OPF解的保真度和可行性，即使从部分数据也能合理地近似。", "summary": "本文针对最优潮流（OPF）求解中数据需求过大的问题，提出了一种OPF数据蒸馏框架。该框架通过仅从部分节点收集数据，然后重建完整数据以求解OPF，旨在减少智能电表数据通信量。研究探讨了两种优化目标：最大化重建数据保真度（稀疏正则化凸问题）和最大化OPF解保真度（稀疏正则化双层规划），并均采用近端梯度算法求解。数值结果表明，以OPF解保真度为目标的方法虽然复杂度更高，但在近似OPF解方面表现更优，证明即使从部分数据也能有效求解OPF。", "keywords": "最优潮流, 数据蒸馏, 智能电表数据, 特征选择, 近端梯度算法", "comments": "这项工作的创新之处在于提出了一种新颖的OPF数据蒸馏框架，通过智能地选择和重建数据，显著减少了最优潮流求解所需的数据通信量。这对于大规模分布式能源并网的智能电网具有重要意义，有助于在数据预算有限的情况下实现高效的电网运行。其引入稀疏正则化双层规划来优化OPF解的保真度，而非仅仅数据保真度，是方法上的一个亮点。"}}
{"id": "2503.05156", "title": "Accelerating Diffusion Transformer via Gradient-Optimized Cache", "authors": ["Junxiang Qiu", "Lin Liu", "Shuo Wang", "Jinda Lu", "Kezhou Chen", "Yanbin Hao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.05156v2", "summary": "Feature caching has emerged as an effective strategy to accelerate diffusion\ntransformer (DiT) sampling through temporal feature reuse. It is a challenging\nproblem since (1) Progressive error accumulation from cached blocks\nsignificantly degrades generation quality, particularly when over 50\\% of\nblocks are cached; (2) Current error compensation approaches neglect dynamic\nperturbation patterns during the caching process, leading to suboptimal error\ncorrection. To solve these problems, we propose the Gradient-Optimized Cache\n(GOC) with two key innovations: (1) Cached Gradient Propagation: A gradient\nqueue dynamically computes the gradient differences between cached and\nrecomputed features. These gradients are weighted and propagated to subsequent\nsteps, directly compensating for the approximation errors introduced by\ncaching. (2) Inflection-Aware Optimization: Through statistical analysis of\nfeature variation patterns, we identify critical inflection points where the\ndenoising trajectory changes direction. By aligning gradient updates with these\ndetected phases, we prevent conflicting gradient directions during error\ncorrection. Extensive evaluations on ImageNet demonstrate GOC's superior\ntrade-off between efficiency and quality. With 50\\% cached blocks, GOC achieves\nIS 216.28 (26.3\\% higher) and FID 3.907 (43\\% lower) compared to baseline DiT,\nwhile maintaining identical computational costs. These improvements persist\nacross various cache ratios, demonstrating robust adaptability to different\nacceleration requirements. Code is available at\nhttps://github.com/qiujx0520/GOC_ICCV2025.git.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.05156v2", "cate": "cs.CV", "date": "2025-03-07", "updated": "2025-07-18", "AI": {"title_translation": "梯度优化缓存加速扩散Transformer", "tldr": "本文提出梯度优化缓存（GOC）方法，通过梯度传播和拐点感知优化，有效加速扩散Transformer（DiT）的采样过程，同时显著提升生成质量。", "motivation": "现有特征缓存策略在加速扩散Transformer（DiT）采样时面临两大挑战：一是缓存块（特别是超过50%）导致渐进式错误累积，严重降低生成质量；二是当前的错误补偿方法忽略了缓存过程中的动态扰动模式，导致次优的错误校正。", "method": "本文提出梯度优化缓存（GOC）方法，包含两项关键创新：1. 缓存梯度传播：通过梯度队列动态计算缓存特征与重新计算特征之间的梯度差异，并将其加权传播到后续步骤，直接补偿缓存引入的近似误差。2. 拐点感知优化：通过对特征变化模式的统计分析，识别去噪轨迹方向改变的关键拐点，并将梯度更新与这些检测到的阶段对齐，以防止错误校正期间出现冲突的梯度方向。", "result": "在ImageNet上的广泛评估表明，GOC在效率和质量之间实现了卓越的权衡。当50%的块被缓存时，GOC实现了IS 216.28（高26.3%）和FID 3.907（低43%），与基线DiT相比，计算成本相同。这些改进在各种缓存比例下均持续存在，显示出对不同加速要求的强大适应性。", "conclusion": "GOC通过创新的梯度传播和拐点感知优化，有效解决了扩散Transformer中特征缓存导致的错误累积和次优校正问题，显著提升了生成质量，同时保持了计算效率，展现出强大的鲁棒性和适应性。", "translation": "特征缓存已成为通过时间特征重用来加速扩散Transformer（DiT）采样的一种有效策略。这是一个具有挑战性的问题，因为（1）缓存块导致的渐进误差累积显著降低了生成质量，尤其是在超过50%的块被缓存时；（2）当前的误差补偿方法忽略了缓存过程中的动态扰动模式，导致次优的误差校正。为了解决这些问题，我们提出了梯度优化缓存（GOC），具有两项关键创新：（1）缓存梯度传播：一个梯度队列动态计算缓存特征和重新计算特征之间的梯度差异。这些梯度被加权并传播到后续步骤，直接补偿了由缓存引入的近似误差。（2）拐点感知优化：通过对特征变化模式的统计分析，我们识别出去噪轨迹改变方向的关键拐点。通过将梯度更新与这些检测到的阶段对齐，我们防止了错误校正期间冲突的梯度方向。在ImageNet上的广泛评估表明，GOC在效率和质量之间实现了卓越的权衡。当50%的块被缓存时，GOC实现了IS 216.28（高26.3%）和FID 3.907（低43%），与基线DiT相比，计算成本相同。这些改进在各种缓存比例下均持续存在，显示出对不同加速要求的强大适应性。代码可在https://github.com/qiujx0520/GOC_ICCV2025.git获取。", "summary": "本文提出了一种名为梯度优化缓存（GOC）的新方法，旨在解决扩散Transformer（DiT）特征缓存中存在的错误累积和次优错误校正问题，以加速采样过程。GOC引入了两项创新：缓存梯度传播，通过梯度队列补偿缓存引入的近似误差；以及拐点感知优化，通过将梯度更新与去噪轨迹的关键拐点对齐，防止冲突。实验证明，GOC在ImageNet上显著提升了生成质量（IS提高26.3%，FID降低43%），同时保持了计算效率，并在不同缓存比例下表现出强大的鲁棒性。", "keywords": "扩散Transformer, 特征缓存, 梯度优化, 图像生成, 加速", "comments": "本文的创新点在于其独特的梯度优化缓存策略，通过引入梯度传播和拐点感知优化，直接且有效地解决了扩散Transformer中特征缓存所导致的质量下降问题。这种方法在加速模型的同时，显著提升了生成图像的质量，克服了传统缓存策略在速度与质量之间难以平衡的挑战，对于需要高效生成高质量图像的应用具有重要意义。"}}
{"id": "2507.13932", "title": "Chain Table: Protecting Table-Level Data Integrity by Digital Ledger Technology", "authors": ["Feng Yu", "Ryan Laird"], "categories": ["cs.CR", "cs.DB"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13932v1", "summary": "The rise of blockchain and Digital Ledger Technology (DLT) has gained wide\ntraction. Instead of relying on a traditional centralized data authority, a\nblockchain system consists of digitally entangled block data shared across a\ndistributed network. The specially designed chain data structure and its\nconsensus mechanism protect blockchain data from being tampered by unauthorized\nadversaries. However, implementing a full-fledged blockchain system to protect\na database can be technically cumbersome. In this work, we introduce an\nin-database design, named chain table, to protect data integrity without the\nneed for a blockchain system. It features a succinct design without significant\ntechnology barriers or storage overhead. To realize rigorous data security, we\nalso propose a set of data writing principles for the chain table. We prove\nthat the chain table, together with the data writing principles, will guarantee\nflexible data integrity, named table-level data integrity (TDI).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13932v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "链表：通过数字账本技术保护表级数据完整性", "tldr": "提出了一种名为“链表”的数据库内设计，利用数字账本技术原理，在不部署完整区块链系统的情况下，保护表级数据完整性。", "motivation": "传统的区块链系统在保护数据库时技术上可能过于繁琐，需要一种更轻量级、更易于实施的数据完整性保护方案。", "method": "提出了一种名为“链表”的数据库内设计，该设计借鉴了数字账本技术的原理，并结合了一套数据写入原则。", "result": "链表设计简洁，没有显著的技术障碍或存储开销。通过与数据写入原则结合，链表被证明能够保证表级数据完整性（TDI）。", "conclusion": "链表及其数据写入原则能够有效、灵活地保护数据库的表级数据完整性，而无需部署复杂的区块链系统。", "translation": "区块链和数字账本技术（DLT）的兴起获得了广泛关注。区块链系统不再依赖传统的中心化数据权威，而是由分布式网络中共享的数字纠缠区块数据组成。其特殊设计的链式数据结构和共识机制保护区块链数据不被未经授权的对手篡改。然而，实施一个成熟的区块链系统来保护数据库可能在技术上很繁琐。在这项工作中，我们引入了一种名为“链表”的数据库内设计，旨在无需区块链系统的情况下保护数据完整性。它具有简洁的设计，没有显著的技术障碍或存储开销。为了实现严格的数据安全性，我们还为链表提出了一套数据写入原则。我们证明，链表与数据写入原则相结合，将保证灵活的数据完整性，即表级数据完整性（TDI）。", "summary": "这篇论文介绍了一种名为“链表”的数据库内设计，旨在解决将完整区块链系统应用于数据库保护时所面临的技术复杂性。链表利用数字账本技术原理，结合一套数据写入原则，实现了对表级数据完整性（TDI）的保护，且设计简洁，无需大量额外开销。", "keywords": "链表, 数据完整性, 数字账本技术, 数据库安全, 表级数据完整性", "comments": "这项工作提供了一个创新的解决方案，通过将DLT的完整性保护优势集成到现有数据库内部，避免了部署复杂区块链系统的弊端。其“in-database”方法对于追求数据完整性但又希望保持系统轻量级的应用场景具有重要意义。"}}
{"id": "2507.12898", "title": "Generalist Bimanual Manipulation via Foundation Video Diffusion Models", "authors": ["Yao Feng", "Hengkai Tan", "Xinyi Mao", "Guodong Liu", "Shuhe Huang", "Chendong Xiang", "Hang Su", "Jun Zhu"], "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12898v1", "summary": "Bimanual robotic manipulation, which involves the coordinated control of two\nrobotic arms, is foundational for solving challenging tasks. Despite recent\nprogress in general-purpose manipulation, data scarcity and embodiment\nheterogeneity remain serious obstacles to further scaling up in bimanual\nsettings. In this paper, we introduce VIdeo Diffusion for Action Reasoning\n(VIDAR), a two-stage framework that leverages large-scale, diffusion-based\nvideo pre-training and a novel masked inverse dynamics model for action\nprediction. We pre-train the video diffusion model on 750K multi-view videos\nfrom three real-world bimanual robot platforms, utilizing a unified observation\nspace that encodes robot, camera, task, and scene contexts. Our masked inverse\ndynamics model learns masks to extract action-relevant information from\ngenerated trajectories without requiring pixel-level labels, and the masks can\neffectively generalize to unseen backgrounds. Our experiments demonstrate that\nwith only 20 minutes of human demonstrations on an unseen robot platform (only\n1% of typical data requirements), VIDAR generalizes to unseen tasks and\nbackgrounds with strong semantic understanding, surpassing state-of-the-art\nmethods. Our findings highlight the potential of video foundation models,\ncoupled with masked action prediction, to enable scalable and generalizable\nrobotic manipulation in diverse real-world settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12898v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "基于基础视频扩散模型的通用双臂操作", "tldr": "本文提出VIDAR框架，利用大型视频扩散模型预训练和新型掩码逆动力学模型，仅需少量数据即可实现双臂机器人对未知任务和背景的泛化操作，超越现有技术。", "motivation": "双臂机器人操作是解决复杂任务的基础，但数据稀缺性和实体异构性是进一步扩展双臂操作的严重障碍。", "method": "本文引入了视频扩散动作推理（VIDAR），这是一个两阶段框架。它利用大规模、基于扩散的视频预训练和一种新颖的掩码逆动力学模型进行动作预测。研究人员在来自三个真实世界双臂机器人平台的75万个多视角视频上预训练了视频扩散模型，使用统一的观察空间编码机器人、摄像机、任务和场景上下文。其掩码逆动力学模型学习掩码以从生成的轨迹中提取与动作相关的信息，而无需像素级标签，并且这些掩码可以有效地泛化到未见的背景。", "result": "实验表明，在未见的机器人平台上仅需20分钟的人类演示（仅为典型数据需求的1%），VIDAR就能以强大的语义理解泛化到未见的任务和背景，超越了最先进的方法。", "conclusion": "研究结果强调了视频基础模型与掩码动作预测相结合的潜力，能够实现在多样化真实世界环境中可扩展和可泛化的机器人操作。", "translation": "双臂机器人操作涉及对两个机械臂的协调控制，是解决挑战性任务的基础。尽管通用操作近期取得了进展，但数据稀缺性和实体异构性仍然是双臂设置中进一步扩展的严重障碍。在本文中，我们引入了视频扩散动作推理（VIDAR），这是一个两阶段框架，它利用大规模、基于扩散的视频预训练和一种新颖的掩码逆动力学模型进行动作预测。我们在来自三个真实世界双臂机器人平台的75万个多视角视频上预训练了视频扩散模型，利用统一的观察空间编码机器人、摄像机、任务和场景上下文。我们的掩码逆动力学模型学习掩码以从生成的轨迹中提取与动作相关的信息，而无需像素级标签，并且这些掩码可以有效地泛化到未见的背景。我们的实验表明，在未见的机器人平台上仅需20分钟的人类演示（仅为典型数据需求的1%），VIDAR就能以强大的语义理解泛化到未见的任务和背景，超越了最先进的方法。我们的发现强调了视频基础模型与掩码动作预测相结合的潜力，能够实现在多样化真实世界环境中可扩展和可泛化的机器人操作。", "summary": "本文提出了一种名为VIDAR的两阶段框架，用于通用双臂机器人操作。该框架通过大规模视频扩散模型预训练和新颖的掩码逆动力学模型，解决了双臂操作中数据稀缺和异构性问题。VIDAR在75万个多视角视频上进行预训练，并能从生成轨迹中学习动作相关信息。实验证明，VIDAR仅需少量演示数据即可在未知任务和背景下实现强大的泛化能力，性能优于现有技术，展示了视频基础模型在可扩展和通用机器人操作中的巨大潜力。", "keywords": "双臂操作, 视频扩散模型, 机器人操作, 基础模型, 泛化能力", "comments": "该论文的创新点在于结合了大型视频扩散模型预训练和新型掩码逆动力学模型，显著减少了双臂机器人操作所需的数据量，并增强了泛化能力。其统一观察空间的设计和无需像素级标签的掩码学习方法，为解决机器人领域的数据稀缺和泛化挑战提供了有价值的思路，对推动通用机器人操作具有重要意义。"}}
{"id": "2507.13609", "title": "CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks", "authors": ["Yanan Wang", "Julio Vizcarra", "Zhi Li", "Hao Niu", "Mori Kurokawa"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13609v1", "summary": "Despite recent progress in video large language models (VideoLLMs), a key\nopen challenge remains: how to equip models with chain-of-thought (CoT)\nreasoning abilities grounded in fine-grained object-level video understanding.\nExisting instruction-tuned models, such as the Qwen and LLaVA series, are\ntrained on high-level video-text pairs, often lacking structured annotations\nnecessary for compositional, step-by-step reasoning. We propose CoTasks:\nChain-of-Thought based Video Instruction Tuning Tasks, a new framework that\ndecomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)\ninto four entity-level foundational tasks: frame localization, entity tracking,\nspatial and temporal relation extraction. By embedding these intermediate\nCoT-style reasoning steps into the input, CoTasks enables models to explicitly\nperform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA\nbenchmark show that CoTasks significantly enhance inference performance:\nLLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and\nQwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal\n(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the\neffectiveness of CoTasks as a structured CoT-style supervision framework for\nimproving compositional video reasoning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13609v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CoTasks: 基于思维链的视频指令微调任务", "tldr": "CoTasks是一个新框架，通过将复杂视频问题分解为四个实体级基础任务（帧定位、实体跟踪、空间和时间关系提取），使视频大语言模型能够进行细粒度、对象级的思维链推理，显著提升了在NeXT-QA基准上的性能。", "motivation": "现有视频大语言模型（VideoLLMs）缺乏细粒度对象级视频理解的思维链（CoT）推理能力，因为它们通常在缺乏结构化标注的高级视频-文本对上进行训练，无法支持组合式、分步推理。", "method": "提出CoTasks框架，将现有数据集（如NeXT-QA, STAR）中的复杂视频问题分解为四个实体级基础任务：帧定位、实体跟踪、空间关系提取和时间关系提取。通过将这些中间的CoT风格推理步骤嵌入到输入中，CoTasks使模型能够明确执行以对象为中心的时空推理。", "result": "在NeXT-QA基准测试中，CoTasks显著提升了推理性能：LLaVA-video-7B的平均GPT-4评估分数提高了3.3分，Qwen2.5-VL-3B提高了17.4分，在因果（+14.6）、时间（+10.9）和描述性（+48.1）子类别中均有大幅提升。", "conclusion": "CoTasks作为一种结构化的思维链风格监督框架，能有效提高组合式视频推理能力。", "translation": "尽管视频大型语言模型（VideoLLMs）最近取得了进展，但一个关键的开放挑战仍然存在：如何使模型具备基于细粒度对象级视频理解的思维链（CoT）推理能力。现有的指令微调模型，如Qwen和LLaVA系列，是在高级视频-文本对上训练的，通常缺乏组合式、分步推理所需的结构化标注。我们提出了CoTasks：基于思维链的视频指令微调任务，这是一个新框架，它将现有数据集（例如NeXT-QA、STAR）中的复杂视频问题分解为四个实体级基础任务：帧定位、实体跟踪、空间和时间关系提取。通过将这些中间的CoT风格推理步骤嵌入到输入中，CoTasks使模型能够明确执行以对象为中心的时空推理。在NeXT-QA基准上的实验表明，CoTasks显著增强了推理性能：LLaVA-video-7B的平均GPT-4评估分数提高了3.3分，Qwen2.5-VL-3B提高了17.4分，在因果（+14.6）、时间（+10.9）和描述性（+48.1）子类别中均有大幅提升。这些结果证明了CoTasks作为一种结构化CoT风格监督框架在改进组合式视频推理方面的有效性。", "summary": "CoTasks是一个旨在提升视频大语言模型细粒度思维链推理能力的新框架。针对现有模型缺乏结构化标注以进行分步推理的问题，CoTasks将复杂视频问题分解为帧定位、实体跟踪、空间和时间关系提取等四个基础任务。通过将这些中间推理步骤嵌入输入，模型能够明确执行对象中心的时空推理。实验证明，CoTasks显著提升了模型在NeXT-QA基准上的性能，尤其是在因果、时间和描述性子类别方面。", "keywords": "视频理解, 思维链, 指令微调, 视频大语言模型, 时空推理", "comments": "CoTasks的创新之处在于其将复杂的视频推理任务分解为更基础、更可控的实体级子任务，并以思维链（CoT）的形式进行监督，从而有效地弥补了现有VideoLLMs在细粒度、对象级推理能力上的不足。这种结构化的方法为提升视频理解和推理能力提供了一个有前景的方向，对于需要复杂时空推理的应用具有重要意义。"}}
{"id": "2507.12917", "title": "Beamforming Tradeoff for Sensing and Communication in Cell-Free MIMO", "authors": ["Xi Ding", "Luca Kunz", "E. Jorswieck"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12917v2", "summary": "This paper studies optimal joint beamforming (BF) for joint sensing and\ncommunication (JSAC) in small-scale cell-free MIMO (CF-MIMO) systems. While\nprior works have explored JSAC optimization using methods such as successive\nconvex approximation (SCA) and semidefinite relaxation (SDR), many of these\napproaches either lack global optimality or require additional rank-reduction\nsteps. In contrast, we propose an SDR-based optimization framework that\nguarantees globally optimal solutions without post-processing. To benchmark its\nperformance, we introduce a standalone BF strategy that dedicates each access\npoint (AP) exclusively to either communication or sensing. The proposed\nformulation builds upon a general multi-user system model, enabling future\nextensions beyond the single-user setting. Overall, our framework offers a\nglobally optimal and computationally efficient BF design, providing valuable\ninsights for the development of next-generation wireless networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12917v2", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "无蜂窝MIMO中感知与通信的波束成形权衡", "tldr": "本文提出了一种基于SDR的优化框架，用于无蜂窝MIMO系统中联合感知与通信（JSAC）的联合波束成形，该框架无需后处理即可保证全局最优解，并具有计算效率。", "motivation": "先前的联合感知与通信（JSAC）优化方法通常缺乏全局最优性或需要额外的降秩步骤。", "method": "本文提出了一种基于半定松弛（SDR）的优化框架，该框架无需后处理即可保证全局最优解。为了评估其性能，引入了一种独立的波束成形策略，将每个接入点（AP）专门用于通信或感知。所提出的公式基于通用的多用户系统模型。", "result": "所提出的框架提供了一种全局最优且计算高效的波束成形设计。", "conclusion": "该框架为下一代无线网络的开发提供了宝贵的见解。", "translation": "本文研究了小型无蜂窝大规模MIMO（CF-MIMO）系统中联合感知与通信（JSAC）的最优联合波束成形（BF）。虽然先前的工作已经探索了使用诸如逐次凸逼近（SCA）和半定松弛（SDR）等方法进行JSAC优化，但其中许多方法要么缺乏全局最优性，要么需要额外的降秩步骤。与此相反，我们提出了一种基于SDR的优化框架，该框架无需后处理即可保证全局最优解。为了评估其性能，我们引入了一种独立的波束成形策略，该策略将每个接入点（AP）专门用于通信或感知。所提出的公式建立在一个通用的多用户系统模型之上，使得未来可以扩展到单用户设置之外。总的来说，我们的框架提供了一种全局最优且计算高效的波束成形设计，为下一代无线网络的发展提供了宝贵的见解。", "summary": "本文针对小型无蜂窝MIMO系统中的联合感知与通信（JSAC）问题，提出了一种基于半定松弛（SDR）的优化框架，用于实现最优联合波束成形。与现有方法相比，该框架无需后处理即可保证全局最优解，并具有计算高效性。为验证其性能，文中引入了一种独立的波束成形策略进行基准测试。该通用多用户系统模型为未来扩展奠定了基础，为下一代无线网络的发展提供了重要洞察。", "keywords": "联合感知与通信, 无蜂窝MIMO, 波束成形, SDR, 全局最优性", "comments": "本文的创新之处在于提出了一种基于SDR的波束成形优化框架，该框架能够保证全局最优解且无需额外的后处理步骤，有效解决了现有方法在全局最优性或计算效率上的局限。其通用多用户系统模型的构建也为其未来在更复杂场景中的应用提供了可能性，对下一代无线网络的发展具有重要意义。"}}
{"id": "2502.13962", "title": "Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering", "authors": ["William Jurayj", "Jeffrey Cheng", "Benjamin Van Durme"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025. Code: this https URL", "url": "http://arxiv.org/abs/2502.13962v2", "summary": "Scaling the test-time compute of large language models has demonstrated\nimpressive performance on reasoning benchmarks. However, existing evaluations\nof test-time scaling make the strong assumption that a reasoning system should\nalways give an answer to any question provided. This overlooks concerns about\nwhether a model is confident in its answer, and whether it is appropriate to\nalways provide a response. To address these concerns, we extract confidence\nscores during reasoning for thresholding model responses. We find that\nincreasing compute budget at inference time not only helps models answer more\nquestions correctly, but also increases confidence in correct responses. We\nthen extend the current paradigm of zero-risk responses during evaluation by\nconsidering settings with non-zero levels of response risk, and suggest a\nrecipe for reporting evaluations under these settings.", "comment": "Accepted to ACL 2025. Code: https://github.com/wjurayj/final_answer", "pdf_url": "http://arxiv.org/pdf/2502.13962v2", "cate": "cs.CL", "date": "2025-02-19", "updated": "2025-07-18", "AI": {"title_translation": "这是你的最终答案吗？测试时缩放改进选择性问答", "tldr": "大型语言模型在测试时增加计算预算，不仅能提高回答的正确率，还能增强对正确答案的置信度，从而通过置信度阈值实现选择性问答，并提出考虑响应风险的评估方法。", "motivation": "现有的大型语言模型测试时缩放评估方法，强烈假设推理系统应始终对任何问题给出答案，这忽视了模型对其答案的置信度以及总是提供响应的适当性问题。", "method": "通过在推理过程中提取置信度分数并对其进行阈值处理来控制模型响应。此外，作者扩展了当前零风险响应的评估范式，考虑了非零响应风险的设置，并提出了一种在这种设置下报告评估结果的方法。", "result": "增加推理时的计算预算不仅有助于模型更正确地回答问题，而且还增加了对正确响应的置信度。", "conclusion": "提高测试时计算能力可以提升模型回答的准确性与置信度，并且通过引入置信度阈值和考虑响应风险，可以改进选择性问答系统的评估和实际应用。", "translation": "大型语言模型在测试时计算能力的扩展在推理基准测试中展现了令人印象深刻的性能。然而，现有的测试时扩展评估强烈假设推理系统应该总是对任何提供的问题给出答案。这忽视了模型对其答案是否自信以及是否总是提供响应的适当性问题。为了解决这些问题，我们在推理过程中提取置信度分数，用于对模型响应进行阈值处理。我们发现，在推理时增加计算预算不仅有助于模型更正确地回答问题，而且还增加了对正确响应的置信度。然后，我们通过考虑非零响应风险的设置，扩展了当前评估中零风险响应的范式，并提出了在这种设置下报告评估结果的方法。", "summary": "该论文探讨了大型语言模型在测试时计算扩展的评估问题，指出现有方法忽视了模型答案的置信度和响应的适当性。为解决此问题，作者提出在推理时提取并阈值化置信度分数。研究发现，增加计算预算能提高模型回答的正确性及对正确答案的置信度。论文还扩展了评估范式，引入非零响应风险设置，并提供了相应的评估报告方法，旨在改进选择性问答系统。", "keywords": "测试时缩放, 置信度, 选择性问答, 大型语言模型, 响应风险", "comments": "该论文创新性地将“置信度”和“响应风险”引入到大型语言模型测试时缩放的评估中，挑战了现有评估中“总是给出答案”的假设。这对于构建更可靠、更负责任的AI系统具有重要意义，尤其是在高风险应用场景中。通过结合计算预算与置信度，为模型如何“知道何时不回答”提供了新的视角和评估框架。"}}
{"id": "2507.14007", "title": "The CryptoNeo Threat Modelling Framework (CNTMF): Securing Neobanks and Fintech in Integrated Blockchain Ecosystems", "authors": ["Serhan W. Bahar"], "categories": ["cs.CR", "cs.ET"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14007v1", "summary": "The rapid integration of blockchain, cryptocurrency, and Web3 technologies\ninto digital banks and fintech operations has created an integrated environment\nblending traditional financial systems with decentralised elements. This paper\nintroduces the CryptoNeo Threat Modelling Framework (CNTMF), a proposed\nframework designed to address the risks in these ecosystems, such as oracle\nmanipulation and cross-chain exploits. CNTMF represents a proposed extension of\nestablished methodologies like STRIDE, OWASP Top 10, NIST frameworks, LINDDUN,\nand PASTA, while incorporating tailored components including Hybrid Layer\nAnalysis, the CRYPTOQ mnemonic for cryptocurrency-specific risks, and an\nAI-Augmented Feedback Loop. Drawing on real-world data from 2025 incidents,\nCNTMF supports data-driven mitigation to reduce losses, which totalled\napproximately $2.47 billion in the first half of 2025 across 344 security\nevents (CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025). Its\nphases guide asset mapping, risk profiling, prioritisation, mitigation, and\niterative feedback. This supports security against evolving risks like\nstate-sponsored attacks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14007v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CryptoNeo威胁建模框架（CNTMF）：在集成区块链生态系统中保护新兴银行和金融科技", "tldr": "本文介绍了CryptoNeo威胁建模框架（CNTMF），旨在解决区块链、加密货币和Web3技术与传统金融系统融合所产生的风险，通过结合现有方法和新组件，支持数据驱动的风险缓解。", "motivation": "数字银行和金融科技操作中区块链、加密货币和Web3技术的快速整合，创造了一个融合传统金融系统与去中心化元素的集成环境，但这也带来了例如预言机操纵和跨链攻击等风险，因此需要一个框架来解决这些风险。", "method": "本文提出了CryptoNeo威胁建模框架（CNTMF），它是STRIDE、OWASP Top 10、NIST框架、LINDDUN和PASTA等既定方法的扩展。它纳入了混合层分析、用于加密货币特定风险的CRYPTOQ助记符以及AI增强反馈循环等定制组件。CNTMF的阶段包括资产映射、风险画像、优先级排序、缓解和迭代反馈。", "result": "CNTMF通过借鉴2025年2025起真实事件的数据，支持数据驱动的缓解措施，以减少损失。2025年上半年，344起安全事件造成的损失总计约24.7亿美元。该框架支持抵御国家支持攻击等不断演变的风险。", "conclusion": "CryptoNeo威胁建模框架（CNTMF）通过扩展现有方法并引入定制组件，为集成区块链生态系统中的新兴银行和金融科技提供了全面的安全保障，并通过数据驱动的缓解措施有效应对不断演变的威胁。", "translation": "区块链、加密货币和Web3技术与数字银行和金融科技业务的快速整合，创建了一个融合传统金融系统与去中心化元素的集成环境。本文介绍了CryptoNeo威胁建模框架（CNTMF），这是一个旨在解决这些生态系统中风险的拟议框架，例如预言机操纵和跨链攻击。CNTMF代表了STRIDE、OWASP Top 10、NIST框架、LINDDUN和PASTA等既定方法的拟议扩展，同时结合了定制组件，包括混合层分析、用于加密货币特定风险的CRYPTOQ助记符以及AI增强反馈循环。CNTMF借鉴了2025年2025起真实事件的数据，支持数据驱动的缓解措施以减少损失，这些损失在2025年上半年344起安全事件中总计约24.7亿美元（CertiK via GlobeNewswire, 2025; Infosecurity Magazine, 2025）。其阶段指导资产映射、风险画像、优先级排序、缓解和迭代反馈。这支持了对抗国家支持攻击等不断演变风险的安全。", "summary": "本文提出了CryptoNeo威胁建模框架（CNTMF），旨在应对区块链、加密货币和Web3技术与传统金融系统融合所带来的安全风险。CNTMF是现有威胁建模方法的扩展，并引入了混合层分析、CRYPTOQ助记符和AI增强反馈循环等新组件。该框架通过资产映射、风险画像、优先级排序、缓解和迭代反馈等阶段，支持数据驱动的风险缓解，以减少此类集成生态系统中的财务损失和应对新兴威胁。", "keywords": "威胁建模, 区块链安全, 新兴银行, 金融科技, CNTMF", "comments": "该论文创新性地将现有威胁建模方法（如STRIDE、OWASP Top 10）与针对区块链和加密货币特定风险（如CRYPTOQ助记符、混合层分析）的定制组件相结合，并融入了AI增强反馈循环，使其在应对新兴金融科技和区块链融合环境中的复杂威胁方面具有重要意义。其强调数据驱动的缓解措施，并引用了具体的损失数据，增强了其现实适用性。"}}
{"id": "2507.13608", "title": "Off-Policy Evaluation and Learning for Matching Markets", "authors": ["Yudai Hayashi", "Shuhei Goda", "Yuta Saito"], "categories": ["cs.LG", "cs.IR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      RecSys'25", "url": "http://arxiv.org/abs/2507.13608v1", "summary": "Matching users based on mutual preferences is a fundamental aspect of\nservices driven by reciprocal recommendations, such as job search and dating\napplications. Although A/B tests remain the gold standard for evaluating new\npolicies in recommender systems for matching markets, it is costly and\nimpractical for frequent policy updates. Off-Policy Evaluation (OPE) thus plays\na crucial role by enabling the evaluation of recommendation policies using only\noffline logged data naturally collected on the platform. However, unlike\nconventional recommendation settings, the large scale and bidirectional nature\nof user interactions in matching platforms introduce variance issues and\nexacerbate reward sparsity, making standard OPE methods unreliable. To address\nthese challenges and facilitate effective offline evaluation, we propose novel\nOPE estimators, \\textit{DiPS} and \\textit{DPR}, specifically designed for\nmatching markets. Our methods combine elements of the Direct Method (DM),\nInverse Propensity Score (IPS), and Doubly Robust (DR) estimators while\nincorporating intermediate labels, such as initial engagement signals, to\nachieve better bias-variance control in matching markets. Theoretically, we\nderive the bias and variance of the proposed estimators and demonstrate their\nadvantages over conventional methods. Furthermore, we show that these\nestimators can be seamlessly extended to offline policy learning methods for\nimproving recommendation policies for making more matches. We empirically\nevaluate our methods through experiments on both synthetic data and A/B testing\nlogs from a real job-matching platform. The empirical results highlight the\nsuperiority of our approach over existing methods in off-policy evaluation and\nlearning tasks for a variety of configurations.", "comment": "RecSys'25", "pdf_url": "http://arxiv.org/pdf/2507.13608v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "匹配市场中的离策略评估与学习", "tldr": "本文提出了DiPS和DPR两种新的离策略评估（OPE）估计器，专门用于解决匹配市场中大规模和双向用户交互导致的方差和奖励稀疏问题，并通过理论分析和实验证明了其优于现有方法的性能。", "motivation": "在匹配市场中，A/B测试评估新策略成本高且不切实际。离策略评估（OPE）虽然可以利用离线数据进行评估，但传统的OPE方法在匹配市场中面临大规模、双向交互导致的方差问题和奖励稀疏性，导致其不可靠。", "method": "本文提出了两种新的OPE估计器：DiPS和DPR，专为匹配市场设计。这些方法结合了直接法（DM）、逆倾向得分（IPS）和双重鲁棒（DR）估计器的元素，并引入了中间标签（如初始参与信号），以更好地控制匹配市场中的偏差-方差。此外，这些估计器可以无缝扩展到离线策略学习方法。", "result": "理论上，本文推导了所提出估计器的偏差和方差，并证明了它们优于传统方法。经验上，通过在合成数据和真实求职匹配平台的A/B测试日志上的实验，证明了所提方法在各种配置下，在离策略评估和学习任务中均优于现有方法。", "conclusion": "本文提出的DiPS和DPR估计器有效解决了匹配市场中离策略评估的挑战，并在理论和实践中均展现出优越性，能够促进更有效的离线评估和策略学习。", "translation": "基于相互偏好匹配用户是互惠推荐服务（如求职和约会应用）的一个基本方面。尽管A/B测试仍然是评估匹配市场推荐系统中新策略的黄金标准，但对于频繁的策略更新来说，它成本高昂且不切实际。因此，离策略评估（OPE）通过仅使用平台上自然收集的离线日志数据来评估推荐策略，发挥着关键作用。然而，与传统的推荐设置不同，匹配平台中用户交互的大规模和双向性质引入了方差问题并加剧了奖励稀疏性，使得标准OPE方法不可靠。为了解决这些挑战并促进有效的离线评估，我们提出了新颖的OPE估计器——DiPS和DPR，它们专门为匹配市场设计。我们的方法结合了直接法（DM）、逆倾向得分（IPS）和双重鲁棒（DR）估计器的元素，同时结合了中间标签（如初始参与信号），以在匹配市场中实现更好的偏差-方差控制。理论上，我们推导了所提出估计器的偏差和方差，并证明了它们相对于传统方法的优势。此外，我们展示了这些估计器可以无缝扩展到离线策略学习方法，以改进推荐策略，促成更多匹配。我们通过在合成数据和来自真实求职匹配平台的A/B测试日志上进行的实验，对我们的方法进行了实证评估。实证结果突出显示了在各种配置下，我们的方法在离策略评估和学习任务中优于现有方法。", "summary": "本文针对匹配市场中离策略评估（OPE）面临的方差和奖励稀疏性挑战，提出了两种新型估计器DiPS和DPR。这些方法结合了现有OPE技术的优点并引入中间标签以优化偏差-方差控制。理论分析和在合成数据及真实平台A/B测试日志上的实验均表明，DiPS和DPR在离策略评估和学习任务中表现出优于传统方法的性能，为匹配市场中的策略优化提供了有效工具。", "keywords": "离策略评估, 匹配市场, 推荐系统, 偏差-方差控制, 策略学习", "comments": "该论文创新性地将离策略评估方法应用于复杂的匹配市场，解决了传统方法在此类场景中面临的方差和奖励稀疏性问题。通过引入DiPS和DPR估计器并结合中间标签，有效提升了离线评估的可靠性。其理论分析和在真实数据上的实证验证增加了研究的严谨性和实用性，对推荐系统和强化学习领域的离线评估具有重要意义。"}}
{"id": "2505.08079", "title": "Zak-OTFS with Spread Carrier Waveforms", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 6 figures, includes proofs of all results. Updated to reflect IEEE Early Access publication. Added IEEE copyright notice and DOI", "url": "http://arxiv.org/abs/2505.08079v3", "summary": "Zak-OTFS (orthogonal time frequency space) modulation is a communication\nframework that parameterizes the wireless channel in the delay-Doppler (DD)\ndomain, where the parameters map directly to physical attributes of the\nscatterers that comprise the scattering environment. As a consequence, the\nchannel can be efficiently acquired and equalized. The Zak-OTFS carrier is a\npulse in the DD domain, and the Zak transform converts it to a pulse train\nmodulated by a tone (pulsone) in the time domain. The pulsone waveform is\nlocalized rather than spread, and it suffers from high peak-to-average power\nratio (PAPR). We describe how to transform the orthonormal basis of Zak-OTFS\npulsones into an orthonormal basis of spread carrier waveforms with low PAPR\n(only $6.58$ dB) that support communication in the presence of mobility and\ndelay spread. This transformation is realized by a unitary transform based on\nthe discrete affine Fourier transform. Unlike other spread modulations that\nachieve low PAPR by spreading information across a wider bandwidth (thus\nreducing the spectral efficiency), the proposed spread carrier-based Zak-OTFS\nachieves full spectral efficiency like pulsone-based Zak-OTFS, with $5.6$ dB\nlower PAPR per basis element. We demonstrate uncoded bit error rate (BER)\nsimilar to pulsone-based Zak-OTFS, and improved BER performance over competing\nmethods based on OFDM and OTFS in high mobility & delay spread environments.", "comment": "7 pages, 6 figures, includes proofs of all results. Updated to\n  reflect IEEE Early Access publication. Added IEEE copyright notice and DOI", "pdf_url": "http://arxiv.org/pdf/2505.08079v3", "cate": "eess.SP", "date": "2025-05-12", "updated": "2025-07-18", "AI": {"title_translation": "Zak-OTFS与扩展载波波形", "tldr": "本文提出了一种基于扩展载波波形的新型Zak-OTFS调制方式，解决了传统Zak-OTFS高峰均功率比（PAPR）的问题，同时保持了高频谱效率，并在高移动和时延扩展环境下展现出优越的性能。", "motivation": "传统的Zak-OTFS调制载波（脉冲子）是局部化的，导致高峰均功率比（PAPR），这在实际通信系统中是一个不利因素。", "method": "通过基于离散仿射傅里叶变换的酉变换，将Zak-OTFS脉冲子的正交基转换为具有低PAPR的正交扩展载波波形基。", "result": "提出的扩展载波Zak-OTFS实现了低PAPR（仅6.58 dB），每个基元的PAPR比基于脉冲子的Zak-OTFS低5.6 dB。它保持了与基于脉冲子的Zak-OTFS相同的全频谱效率，并且在高速移动和时延扩展环境中，其未编码误码率（BER）与基于脉冲子的Zak-OTFS相似，优于基于OFDM和OTFS的竞争方法。", "conclusion": "通过引入扩展载波波形，Zak-OTFS系统成功克服了高PAPR的缺点，同时保持了高频谱效率和在复杂信道下的稳健性能，使其成为未来无线通信的有力候选。", "translation": "Zak-OTFS（正交时频空间）调制是一种通信框架，它在时延-多普勒（DD）域中对无线信道进行参数化，其中参数直接映射到构成散射环境的散射体的物理属性。因此，信道可以被高效地获取和均衡。Zak-OTFS载波是DD域中的一个脉冲，扎克变换将其转换为时域中由音调调制的脉冲序列（脉冲子）。脉冲子波形是局部化的而不是扩展的，并且存在高峰均功率比（PAPR）的问题。我们描述了如何将Zak-OTFS脉冲子正交基转换为具有低PAPR（仅6.58 dB）的正交扩展载波波形基，以支持在移动性和时延扩展存在下的通信。这种转换通过基于离散仿射傅里叶变换的酉变换实现。与其他通过扩展信息带宽（从而降低频谱效率）实现低PAPR的扩展调制不同，所提出的基于扩展载波的Zak-OTFS实现了与基于脉冲子的Zak-OTFS相同的全频谱效率，每个基元的PAPR降低了5.6 dB。我们展示了与基于脉冲子的Zak-OTFS相似的未编码误码率（BER），并在高移动性和时延扩展环境中，其BER性能优于基于OFDM和OTFS的竞争方法。", "summary": "本文提出了一种改进的Zak-OTFS调制方案，名为“Zak-OTFS与扩展载波波形”，旨在解决传统Zak-OTFS调制中脉冲子波形固有的高峰均功率比（PAPR）问题。通过引入基于离散仿射傅里叶变换的酉变换，研究人员将Zak-OTFS脉冲子正交基转换为低PAPR的扩展载波波形。实验结果表明，该方法不仅将PAPR显著降低至6.58 dB（每个基元比传统Zak-OTFS低5.6 dB），而且保持了全频谱效率，这与其他通过牺牲频谱效率来降低PAPR的扩展调制形成对比。此外，该新型Zak-OTFS在高移动和时延扩展环境下展现出与传统Zak-OTFS相似的误码率，并优于OFDM和OTFS等现有技术。", "keywords": "Zak-OTFS, 扩展载波, PAPR, 时延-多普勒域, 频谱效率", "comments": "该论文的创新点在于成功地将高PAPR的Zak-OTFS脉冲子波形转换为低PAPR的扩展载波波形，同时没有牺牲频谱效率，这对于未来无线通信系统在复杂信道下的部署具有重要意义。其方法巧妙地利用了酉变换，解决了实际应用中的关键挑战。"}}
{"id": "2405.09298", "title": "A Mixture of Experts (MoE) model to improve AI-based computational pathology prediction performance under variable levels of histopathology image blur", "authors": ["Yujie Xiang", "Bojing Liu", "Mattias Rantalainen"], "categories": ["eess.IV", "cs.CV", "I.4; J.3"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2405.09298v5", "summary": "AI-based models for histopathology whole slide image (WSI) analysis are\nincreasingly common, but unsharp or blurred areas within WSI can significantly\nreduce prediction performance. In this study, we investigated the effect of\nimage blur on deep learning models and introduced a mixture of experts (MoE)\nstrategy that combines predictions from multiple expert models trained on data\nwith varying blur levels. Using H&E-stained WSIs from 2,093 breast cancer\npatients, we benchmarked performance on grade classification and IHC biomarker\nprediction with both CNN- (CNN_CLAM and MoE-CNN_CLAM) and Vision\nTransformer-based (UNI_CLAM and MoE-UNI_CLAM) models. Our results show that\nbaseline models' performance consistently decreased with increasing blur, but\nexpert models trained on blurred tiles and especially our proposed MoE approach\nsubstantially improved performance, and outperformed baseline models in a range\nof simulated scenarios. MoE-CNN_CLAM outperformed the baseline CNN_CLAM under\nmoderate (AUC: 0.868 vs. 0.702) and mixed blur conditions (AUC: 0.890 vs.\n0.875). MoE-UNI_CLAM outperformed the baseline UNI_CLAM model in both moderate\n(AUC: 0.950 vs. 0.928) and mixed blur conditions (AUC: 0.944 vs. 0.931). This\nMoE method has the potential to enhance the reliability of AI-based pathology\nmodels under variable image quality, supporting broader application in both\nresearch and clinical settings.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2405.09298v5", "cate": "eess.IV", "date": "2024-05-15", "updated": "2025-07-18", "AI": {"title_translation": "混合专家 (MoE) 模型在不同组织病理学图像模糊水平下提高基于 AI 的计算病理学预测性能", "tldr": "提出了一种混合专家（MoE）模型，用于提高在图像模糊条件下基于AI的计算病理学预测性能。", "motivation": "在组织病理学全玻片图像（WSI）分析中，图像模糊会显著降低基于AI的模型的预测性能。", "method": "研究了图像模糊对深度学习模型的影响，并引入了一种混合专家（MoE）策略，该策略结合了在不同模糊水平数据上训练的多个专家模型的预测结果。使用来自2,093名乳腺癌患者的H&E染色WSI，在分级分类和IHC生物标志物预测任务上，使用基于CNN和Vision Transformer的模型（包括MoE变体）进行了性能基准测试。", "result": "基线模型的性能随模糊程度增加而持续下降。然而，在模糊图像块上训练的专家模型，特别是所提出的MoE方法，显著提高了性能，并在各种模拟场景中优于基线模型。MoE-CNN_CLAM在适度模糊和混合模糊条件下优于基线CNN_CLAM（AUC显著提升），MoE-UNI_CLAM在适度模糊和混合模糊条件下也优于基线UNI_CLAM模型（AUC显著提升）。", "conclusion": "这种MoE方法有潜力增强在可变图像质量下基于AI的病理学模型的可靠性，支持其在研究和临床环境中的更广泛应用。", "translation": "基于AI的组织病理学全玻片图像（WSI）分析模型越来越普遍，但WSI中不清晰或模糊的区域会显著降低预测性能。在本研究中，我们调查了图像模糊对深度学习模型的影响，并引入了一种混合专家（MoE）策略，该策略结合了在不同模糊水平数据上训练的多个专家模型的预测结果。我们使用来自2,093名乳腺癌患者的H&E染色WSI，在分级分类和IHC生物标志物预测任务上，对基于CNN（CNN_CLAM和MoE-CNN_CLAM）和Vision Transformer（UNI_CLAM和MoE-UNI_CLAM）的模型进行了性能基准测试。我们的结果表明，基线模型的性能随着模糊程度的增加而持续下降，但在模糊图像块上训练的专家模型，特别是我们提出的MoE方法，显著提高了性能，并在各种模拟场景中优于基线模型。MoE-CNN_CLAM在适度模糊（AUC：0.868 vs. 0.702）和混合模糊条件（AUC：0.890 vs. 0.875）下优于基线CNN_CLAM。MoE-UNI_CLAM在适度模糊（AUC：0.950 vs. 0.928）和混合模糊条件（AUC：0.944 vs. 0.931）下均优于基线UNI_CLAM模型。这种MoE方法有潜力增强在可变图像质量下基于AI的病理学模型的可靠性，支持其在研究和临床环境中的更广泛应用。", "summary": "本研究探讨了图像模糊对基于AI的组织病理学全玻片图像分析模型性能的影响，并提出了一种混合专家（MoE）策略来解决这一问题。该策略通过结合在不同模糊水平数据上训练的多个专家模型的预测来提高性能。在2,093名乳腺癌患者的H&E染色WSI上进行的实验表明，MoE方法显著改善了CNN和Vision Transformer基线模型在模糊条件下的预测表现，验证了其在提高AI病理学模型可靠性方面的潜力。", "keywords": "混合专家模型, 计算病理学, 图像模糊, 深度学习, 组织病理学", "comments": "该论文提出了一种新颖的混合专家模型，有效地解决了组织病理学图像中普遍存在的图像模糊问题对AI模型性能的影响。通过训练多个专家模型并结合其预测，该方法显著提高了模型的鲁棒性和预测准确性，特别是在图像质量不佳的情况下。这对于AI病理学在真实临床环境中的应用具有重要意义，因为它能提高诊断的可靠性。其创新点在于针对图像质量变异性设计了专门的模型架构，弥补了传统深度学习模型在此方面的不足。"}}
{"id": "2507.13589", "title": "Quantifying Ocular Surface Changes with Contact Lens Wear", "authors": ["Lucia Carichino", "Kara L. Maki", "David S. Ross", "Riley K. Supple", "Evan Rysdam"], "categories": ["math.NA", "cs.NA", "physics.bio-ph"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      35 pages and 14 figures, submitted", "url": "http://arxiv.org/abs/2507.13589v1", "summary": "Over 140 million people worldwide and over 45 million people in the United\nstates wear contact lenses; it is estimated 12%-27.4% contact lens users stop\nwearing them due to discomfort. Contact lens mechanical interactions with the\nocular surface have been found to affect the ocular surface. The mechanical\ninteractions between the contact lens and the eye are difficult to measure and\ncalculate in the clinical setting, and the research in this field is limited.\nThis paper presents the first mathematical model that couples the interaction\nbetween the contact lens and the open eye, where the contact lens\nconfiguration, the contact lens suction pressure, and the deformed ocular shape\nare all emergent properties of the model. The non-linear coupling between the\ncontact lens and the eye is achieved assuming the the suction pressure under\nthe lens is applied directly to the ocular surface, neglecting the post-lens\ntear film layer. The contact lens dynamics is modeled using a previous\npublished model. We consider a homogeneous and a heterogeneous linear elastic\neye model, different ocular shapes, different lens shapes and lens thickness\nprofiles, and extract lens deformation, lens suction pressure profiles, and\nocular deformations and stresses for all the scenarios considered. The model\npredicts higher ocular deformations and stresses at the center of the eye and\nin the limbal/scleral region. Accounting for a heterogeneous material eye\nparameters increases such deformations and stresses. The ocular displacements\nand stresses increase non-linearly as we increase the stiffness of the contact\nlens. Inserting a steeper contact lens on the eye results in a reduction of the\nocular displacement at the center of the eye and a larger displacement at the\nedge of the contact lens. The model predictions are compared to experimental\ndata and previously developed mathematical models.", "comment": "35 pages and 14 figures, submitted", "pdf_url": "http://arxiv.org/pdf/2507.13589v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "量化隐形眼镜佩戴引起的眼表变化", "tldr": "该研究提出了首个量化隐形眼镜与眼球相互作用的数学模型，以理解并预测佩戴隐形眼镜引起的眼表变化和不适。", "motivation": "全球有大量隐形眼镜用户因不适而停戴；隐形眼镜与眼表的机械相互作用在临床环境中难以测量且研究有限。", "method": "本文提出了首个耦合隐形眼镜与睁开眼球之间相互作用的数学模型，将隐形眼镜配置、吸附压力和变形的眼球形状作为模型的内在属性。模型假设镜片下的吸附压力直接作用于眼表，忽略镜后泪膜层。隐形眼镜动力学采用先前发表的模型进行建模。研究考虑了均质和非均质线性弹性眼球模型、不同的眼形、镜片形状和厚度剖面。", "result": "模型预测眼球中心和角膜缘/巩膜区域的眼表变形和应力更高；考虑异质材料眼球参数会增加此类变形和应力；眼球位移和应力随隐形眼镜硬度增加而非线性增加；佩戴更陡峭的隐形眼镜会导致眼球中心的位移减小，而在隐形眼镜边缘的位移增大。模型预测结果与实验数据和先前开发的数学模型进行了比较。", "conclusion": "该数学模型能够量化并预测隐形眼镜佩戴引起的眼表变形和应力，为理解隐形眼镜不适和优化镜片设计提供了工具。", "translation": "全球有超过1.4亿人佩戴隐形眼镜，美国有超过4500万人；据估计，12%-27.4%的隐形眼镜用户因不适而停止佩戴。研究发现，隐形眼镜与眼表的机械相互作用会影响眼表。隐形眼镜与眼球之间的机械相互作用在临床环境中难以测量和计算，该领域的研究也十分有限。本文提出了第一个耦合隐形眼镜与睁开眼球之间相互作用的数学模型，其中隐形眼镜配置、隐形眼镜吸附压力和变形的眼球形状都是模型的内在属性。通过假设镜片下的吸附压力直接作用于眼表，忽略镜后泪膜层，实现了隐形眼镜与眼球之间的非线性耦合。隐形眼镜动力学采用先前发表的模型进行建模。我们考虑了均质和非均质线性弹性眼球模型、不同的眼形、不同的镜片形状和镜片厚度剖面，并提取了所有考虑情景下的镜片变形、镜片吸附压力剖面以及眼球变形和应力。模型预测眼球中心和角膜缘/巩膜区域的眼表变形和应力更高。考虑异质材料眼球参数会增加此类变形和应力。随着我们增加隐形眼镜的硬度，眼球位移和应力非线性增加。在眼球上插入更陡峭的隐形眼镜会导致眼球中心的位移减小，而在隐形眼镜边缘的位移增大。模型预测结果与实验数据和先前开发的数学模型进行了比较。", "summary": "本文针对隐形眼镜佩戴引起的不适问题，提出了首个耦合隐形眼镜与眼球相互作用的数学模型。该模型能够预测隐形眼镜配置、吸附压力和眼球变形，并分析了不同眼球和镜片参数对眼表变形和应力的影响，发现硬度、材料异质性和镜片陡峭度均会影响眼表变化。模型预测与实验数据和现有模型进行了比较，为理解隐形眼镜不适和优化镜片设计提供了新工具。", "keywords": "隐形眼镜, 眼表变化, 数学模型, 机械相互作用, 眼球变形", "comments": "该研究的创新点在于提出了首个耦合隐形眼镜与眼球相互作用的数学模型，为量化难以测量的机械相互作用提供了理论框架。这对于理解隐形眼镜佩戴引起的不适原因以及未来改进镜片设计具有重要意义。然而，模型中忽略镜后泪膜层可能是一个简化，未来研究可以考虑其影响。"}}
{"id": "2507.14109", "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting", "authors": ["Xinyu Cao", "Bimal Adhikari", "Shangqing Zhao", "Jingxian Wu", "Yanjun Pan"], "categories": ["cs.CR", "cs.LG", "eess.SP"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14109v1", "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14109v1", "cate": "cs.CR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "深度学习射频指纹识别的对抗驱动实验研究", "tldr": "本文通过对抗性实验研究，揭示了深度学习射频指纹识别系统存在的安全漏洞，包括域名偏移下的误分类行为和特征纠缠导致的额外攻击向量。", "motivation": "射频指纹识别在零信任架构和5G网络中是一种有前景的设备识别机制，深度学习方法在此领域表现出色。然而，现有方法主要关注系统对环境变化的鲁棒性，而深度学习方法的安全漏洞却常被忽视。因此，本文旨在系统性地研究基于深度学习的射频指纹识别系统的安全风险。", "method": "本文通过对抗驱动的实验分析，系统地研究了基于深度学习的射频指纹识别系统的安全风险。通过大量的真实世界实验进行分析。", "result": "研究发现，深度学习模型在域名偏移下存在一致的错误分类行为，即一个设备经常被错误地识别为另一个特定设备。这种行为可以被利用作为有效的后门，使外部攻击者能够入侵系统。此外，在原始接收信号上训练深度学习模型会导致模型将射频指纹与环境和信号模式特征纠缠在一起，从而产生仅通过置信度阈值等后处理安全方法无法缓解的额外攻击向量。", "conclusion": "深度学习在射频指纹识别中存在严重的安全漏洞，特别是在域名偏移下的一致性误分类行为可被利用为后门，且模型训练方式可能产生新的难以缓解的攻击向量，需要更深入的安全研究。", "translation": "射频（RF）指纹识别通过提取无线电设备独特的硬件缺陷，已成为零信任架构和超越5G网络中有前景的物理层设备识别机制。特别是，深度学习（DL）方法在该领域展现出最先进的性能。然而，现有方法主要关注增强系统对无线环境中时间和空间变化的鲁棒性，而这些基于DL的方法的安全漏洞却常被忽视。在这项工作中，我们通过对抗驱动的实验分析，系统地研究了基于DL的射频指纹识别系统的安全风险。我们观察到DL模型在域偏移下存在一致的错误分类行为，即一个设备经常被错误地识别为另一个特定设备。我们基于大量真实世界实验的分析表明，这种行为可以被利用作为有效的后门，使外部攻击者能够入侵系统。此外，我们表明在原始接收信号上训练DL模型会导致模型将射频指纹与环境和信号模式特征纠缠在一起，从而产生仅通过置信度阈值等后处理安全方法无法缓解的额外攻击向量。", "summary": "本文对深度学习在射频指纹识别中的安全风险进行了对抗驱动的实验研究。研究发现，深度学习模型在域名偏移下存在一致的误分类行为，可被利用为有效的后门。此外，在原始信号上训练模型会导致射频指纹与环境特征纠缠，产生难以通过传统后处理方法缓解的额外攻击向量，揭示了DL-based RF指纹识别系统在安全方面的脆弱性。", "keywords": "射频指纹识别, 深度学习, 对抗性攻击, 安全漏洞, 域名偏移", "comments": "该论文创新性地将对抗性攻击引入到射频指纹识别的深度学习研究中，揭示了现有DL模型在安全方面的脆弱性，特别是指出了域名偏移下的误分类可作为后门，以及特征纠缠产生的难以缓解的攻击向量。这对于未来设计更安全的射频指纹识别系统具有重要指导意义。"}}
{"id": "2407.01558", "title": "Visual Grounding Methods for Efficient Interaction with Desktop Graphical User Interfaces", "authors": ["El Hassane Ettifouri", "Jessica López Espejel", "Laura Minkova", "Tassnim Dardouri", "Walid Dahhane"], "categories": ["cs.HC", "cs.AI"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Preprint submitted to Engineering Applications of Artificial Intelligence journal", "url": "http://arxiv.org/abs/2407.01558v3", "summary": "Most visual grounding solutions primarily focus on realistic images. However,\napplications involving synthetic images, such as Graphical User Interfaces\n(GUIs), remain limited. This restricts the development of autonomous computer\nvision-powered artificial intelligence (AI) agents for automatic application\ninteraction. Enabling AI to effectively understand and interact with GUIs is\ncrucial to advancing automation in software testing, accessibility, and\nhuman-computer interaction. In this work, we explore Instruction Visual\nGrounding (IVG), a multi-modal approach to object identification within a GUI.\nMore precisely, given a natural language instruction and a GUI screen, IVG\nlocates the coordinates of the element on the screen where the instruction\nshould be executed. We propose two main methods: (1) IVGocr, which combines a\nLarge Language Model (LLM), an object detection model, and an Optical Character\nRecognition (OCR) module; and (2) IVGdirect, which uses a multimodal\narchitecture for end-to-end grounding. For each method, we introduce a\ndedicated dataset. In addition, we propose the Central Point Validation (CPV)\nmetric, a relaxed variant of the classical Central Proximity Score (CPS)\nmetric. Our final test dataset is publicly released to support future research.", "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence journal", "pdf_url": "http://arxiv.org/pdf/2407.01558v3", "cate": "cs.HC", "date": "2024-05-05", "updated": "2025-07-18", "AI": {"title_translation": "桌面图形用户界面高效交互的视觉定位方法", "tldr": "该论文介绍了两种用于图形用户界面（GUI）指令视觉定位（IVG）的方法（IVGocr和IVGdirect），并提出了一个新的评估指标（CPV），旨在使AI能有效理解和交互GUI，同时发布了一个公共数据集。", "motivation": "大多数视觉定位解决方案主要关注真实图像，但针对图形用户界面（GUI）等合成图像的应用仍有限，这阻碍了自动应用程序交互的自主计算机视觉AI代理的开发。使AI有效理解和交互GUI对于推动软件测试、可访问性和人机交互领域的自动化至关重要。", "method": "本研究探索了指令视觉定位（IVG），这是一种在GUI中识别对象的多模态方法。具体来说，给定自然语言指令和GUI屏幕，IVG定位屏幕上应执行指令的元素坐标。论文提出了两种主要方法：1) IVGocr，结合了大型语言模型（LLM）、对象检测模型和光学字符识别（OCR）模块；2) IVGdirect，使用多模态架构进行端到端定位。为每种方法都引入了专用数据集。此外，还提出了中心点验证（CPV）指标，它是经典中心邻近分数（CPS）指标的宽松变体。", "result": "论文为提出的两种方法各自引入了专用数据集，并公开发布了最终测试数据集以支持未来的研究。", "conclusion": "该工作致力于提升AI理解和交互图形用户界面的能力，这对于软件测试、可访问性和人机交互等领域的自动化发展至关重要。", "translation": "大多数视觉定位解决方案主要关注真实图像。然而，涉及合成图像（如图形用户界面（GUI））的应用仍然有限。这限制了用于自动应用程序交互的自主计算机视觉驱动的人工智能（AI）代理的开发。使AI能够有效理解和交互GUI对于推动软件测试、可访问性和人机交互领域的自动化至关重要。在这项工作中，我们探索了指令视觉定位（IVG），这是一种在GUI中识别对象的多模态方法。更精确地说，给定自然语言指令和GUI屏幕，IVG定位屏幕上应执行指令的元素坐标。我们提出了两种主要方法：(1) IVGocr，它结合了大型语言模型（LLM）、对象检测模型和光学字符识别（OCR）模块；以及(2) IVGdirect，它使用多模态架构进行端到端定位。对于每种方法，我们都引入了一个专用数据集。此外，我们提出了中心点验证（CPV）指标，它是经典中心邻近分数（CPS）指标的宽松变体。我们的最终测试数据集已公开发布以支持未来的研究。", "summary": "该论文解决了现有视觉定位方法在图形用户界面（GUI）等合成图像应用中的局限性，旨在推动AI在软件测试、可访问性和人机交互中的自动化。为此，作者提出了指令视觉定位（IVG）框架，其目标是根据自然语言指令在GUI屏幕上定位指定元素。具体提出了两种方法：结合LLM、对象检测和OCR的IVGocr，以及端到端多模态架构的IVGdirect。研究为每种方法构建了专用数据集，并引入了新的评估指标中心点验证（CPV）。最终的测试数据集已公开发布，以促进后续研究。", "keywords": "视觉定位, 图形用户界面, 指令视觉定位, AI代理, 多模态", "comments": "该论文的创新之处在于将视觉定位应用于合成图像（特别是GUI），这是一个相对不被充分探索的领域。通过提出混合方法（IVGocr）和端到端方法（IVGdirect）两种不同的策略，并引入新的评估指标和发布公共数据集，该工作为实现AI与桌面应用程序的自主交互奠定了基础，具有重要的实际应用价值。"}}
{"id": "2507.13391", "title": "Quantitative Risk Management in Volatile Markets with an Expectile-Based Framework for the FTSE Index", "authors": ["Abiodun Finbarrs Oketunji"], "categories": ["q-fin.RM", "cs.CY", "91G70, 91B30, 60G70, 62P05", "G.4; G.m; D.2.13; C.5.0"], "primary_category": "Subjects:       Risk Management (q-fin.RM)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13391v1", "summary": "This research presents a framework for quantitative risk management in\nvolatile markets, specifically focusing on expectile-based methodologies\napplied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk\n(VaR) have demonstrated significant limitations during periods of market\nstress, as evidenced during the 2008 financial crisis and subsequent volatile\nperiods. This study develops an advanced expectile-based framework that\naddresses the shortcomings of conventional quantile-based approaches by\nproviding greater sensitivity to tail losses and improved stability in extreme\nmarket conditions. The research employs a dataset spanning two decades of FTSE\n100 returns, incorporating periods of high volatility, market crashes, and\nrecovery phases. Our methodology introduces novel mathematical formulations for\nexpectile regression models, enhanced threshold determination techniques using\ntime series analysis, and robust backtesting procedures. The empirical results\ndemonstrate that expectile-based Value-at-Risk (EVaR) consistently outperforms\ntraditional VaR measures across various confidence levels and market\nconditions. The framework exhibits superior performance during volatile\nperiods, with reduced model risk and enhanced predictive accuracy. Furthermore,\nthe study establishes practical implementation guidelines for financial\ninstitutions and provides evidence-based recommendations for regulatory\ncompliance and portfolio management. The findings contribute significantly to\nthe literature on financial risk management and offer practical tools for\npractitioners dealing with volatile market environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13391v1", "cate": "q-fin.RM", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "基于期望值框架的富时指数波动市场量化风险管理", "tldr": "本研究提出了一个基于期望值的量化风险管理框架，用于波动市场中的富时100指数，旨在解决传统VaR的局限性，并在实证中证明其优越性。", "motivation": "传统风险度量（如VaR）在市场压力时期表现出显著局限性，如2008年金融危机期间所示。本研究旨在开发一种先进的、基于期望值的框架来解决这些缺点，提供对尾部损失更高的敏感性和在极端市场条件下的更高稳定性。", "method": "本研究开发了一个先进的基于期望值的框架，包括期望值回归模型的新颖数学公式、使用时间序列分析的增强阈值确定技术以及稳健的回溯测试程序。研究使用了跨越二十年的富时100指数回报数据集。", "result": "实证结果表明，基于期望值的VaR（EVaR）在各种置信水平和市场条件下始终优于传统的VaR度量。该框架在波动期间表现出卓越的性能，模型风险降低，预测准确性提高。", "conclusion": "本研究的结果显著促进了金融风险管理文献，并为处理波动市场环境的从业者提供了实用工具，同时也为金融机构提供了实际的实施指南和监管合规建议。", "translation": "本研究提出了一个在波动市场中进行量化风险管理的框架，特别关注应用于富时100指数的基于期望值的方法。传统的风险度量，如风险价值（VaR），在市场压力时期表现出显著局限性，2008年金融危机及随后的波动时期就证明了这一点。本研究开发了一个先进的基于期望值的框架，通过提供对尾部损失更高的敏感性和在极端市场条件下改进的稳定性，解决了传统基于分位数方法的缺点。研究采用了涵盖富时100指数回报二十年的数据集，其中包括高波动、市场崩溃和复苏阶段。我们的方法引入了期望值回归模型的新颖数学公式、使用时间序列分析的增强阈值确定技术以及稳健的回溯测试程序。实证结果表明，基于期望值的风险价值（EVaR）在各种置信水平和市场条件下始终优于传统的VaR度量。该框架在波动期间表现出卓越的性能，模型风险降低，预测准确性提高。此外，本研究为金融机构建立了实际实施指南，并为监管合规和投资组合管理提供了基于证据的建议。研究结果显著促进了金融风险管理文献，并为处理波动市场环境的从业者提供了实用工具。", "summary": "本研究提出了一种基于期望值的量化风险管理框架，专门应用于波动市场中的富时100指数。该框架旨在克服传统VaR在市场压力下的局限性，通过引入新的数学公式和稳健的回溯测试方法，提高了对尾部损失的敏感性和在极端条件下的稳定性。实证结果表明，期望值VaR（EVaR）在预测准确性和降低模型风险方面优于传统VaR，尤其是在市场波动期间。研究还为金融机构提供了实施指南和监管建议，为金融风险管理领域做出了重要贡献。", "keywords": "期望值, 风险管理, 波动市场, 富时指数, VaR", "comments": "这项研究的创新之处在于提出了一个基于期望值的风险管理框架，有效解决了传统VaR在波动市场中表现不佳的痛点。通过引入新的数学公式和严格的实证验证，该框架不仅理论上可行，而且在实践中也展现出卓越的性能，对于金融机构在复杂市场环境中进行风险管理具有重要的指导意义。"}}
{"id": "2507.13875", "title": "Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies", "authors": ["Carlos Mena", "Pol Serra", "Jacobo Romero", "Abir Messaoudi", "Jose Giraldo", "Carme Armentano-Oller", "Rodolfo Zevallos", "Ivan Meza", "Javier Hernando"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted at Interspeech 2025", "url": "http://arxiv.org/abs/2507.13875v1", "summary": "Code-switching (CS), the alternating use of two or more languages, challenges\nautomatic speech recognition (ASR) due to scarce training data and linguistic\nsimilarities. The lack of dedicated CS datasets limits ASR performance, as most\nmodels rely on monolingual or mixed-language corpora that fail to reflect\nreal-world CS patterns. This issue is critical in multilingual societies where\nCS occurs in informal and formal settings. A key example is Catalan-Spanish CS,\nwidely used in media and parliamentary speeches. In this work, we improve ASR\nfor Catalan-Spanish CS by exploring three strategies: (1) generating synthetic\nCS data, (2) concatenating monolingual audio, and (3) leveraging real CS data\nwith language tokens. We extract CS data from Catalan speech corpora and\nfine-tune OpenAI's Whisper models, making them available on Hugging Face.\nResults show that combining a modest amount of synthetic CS data with the\ndominant language token yields the best transcription performance.", "comment": "Accepted at Interspeech 2025", "pdf_url": "http://arxiv.org/pdf/2507.13875v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "优化加泰罗尼亚语-西班牙语语码转换的ASR：方法学比较分析", "tldr": "针对加泰罗尼亚语-西班牙语语码转换ASR，通过探索合成数据、单语拼接和真实数据加语言标记三种策略，发现合成数据结合主导语言标记能显著提高ASR性能。", "motivation": "语码转换（CS）给自动语音识别（ASR）带来了挑战，原因在于训练数据稀缺和语言相似性。缺乏专门的CS数据集限制了ASR的性能，现有模型大多依赖单语或混合语言语料库，无法反映真实的CS模式。这个问题在多语言社会中尤为关键，加泰罗尼亚语-西班牙语CS就是一个典型例子。", "method": "作者通过探索三种策略来改进加泰罗尼亚语-西班牙语语码转换的ASR：1) 生成合成的CS数据；2) 连接单语音频；3) 利用带有语言标记的真实CS数据。他们从加泰罗尼亚语语音语料库中提取CS数据，并对OpenAI的Whisper模型进行微调。", "result": "结果表明，将适量的合成CS数据与主导语言标记结合使用，能获得最佳的转录性能。", "conclusion": "结合适量合成CS数据和主导语言标记是优化加泰罗尼亚语-西班牙语语码转换ASR的有效方法。", "translation": "语码转换（CS），即两种或两种以上语言的交替使用，由于训练数据稀缺和语言相似性，对自动语音识别（ASR）构成了挑战。缺乏专门的CS数据集限制了ASR的性能，因为大多数模型依赖于单语或混合语言语料库，未能反映真实的CS模式。这个问题在多语言社会中至关重要，因为CS在非正式和正式场合都会发生。加泰罗尼亚语-西班牙语CS就是一个关键例子，广泛用于媒体和议会演讲中。在这项工作中，我们通过探索三种策略来改进加泰罗尼亚语-西班牙语CS的ASR：(1) 生成合成CS数据，(2) 连接单语音频，以及 (3) 利用带有语言标记的真实CS数据。我们从加泰罗尼亚语语音语料库中提取CS数据，并对OpenAI的Whisper模型进行微调，并将它们发布在Hugging Face上。结果显示，将适量的合成CS数据与主导语言标记结合使用，能获得最佳的转录性能。", "summary": "这篇论文旨在优化加泰罗尼亚语-西班牙语语码转换（CS）的自动语音识别（ASR）性能，以应对现有模型在处理真实CS模式时面临的挑战。研究人员探索了三种策略：生成合成CS数据、连接单语音频以及利用带有语言标记的真实CS数据。他们从加泰罗尼亚语语音语料库中提取数据，并对OpenAI的Whisper模型进行微调。实验结果表明，将适量的合成CS数据与主导语言标记结合使用，能够实现最佳的ASR转录表现。", "keywords": "语码转换, 自动语音识别, 加泰罗尼亚语-西班牙语, 数据增强, Whisper模型", "comments": "这篇论文解决了语码转换ASR领域的一个重要问题，特别是在数据稀缺的背景下。其创新点在于系统地比较了多种数据增强和利用策略，并明确指出合成数据结合语言标记的有效性。将微调后的模型开源（Hugging Face）也对社区有积极贡献。"}}
{"id": "2502.14131", "title": "An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model", "authors": ["Enoch H. Kang", "Hema Yoganarasimhan", "Lalit Jain"], "categories": ["cs.LG", "cs.AI", "econ.EM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.14131v4", "summary": "We study the problem of estimating Dynamic Discrete Choice (DDC) models, also\nknown as offline Maximum Entropy-Regularized Inverse Reinforcement Learning\n(offline MaxEnt-IRL) in machine learning. The objective is to recover reward or\n$Q^*$ functions that govern agent behavior from offline behavior data. In this\npaper, we propose a globally convergent gradient-based method for solving these\nproblems without the restrictive assumption of linearly parameterized rewards.\nThe novelty of our approach lies in introducing the Empirical Risk Minimization\n(ERM) based IRL/DDC framework, which circumvents the need for explicit state\ntransition probability estimation in the Bellman equation. Furthermore, our\nmethod is compatible with non-parametric estimation techniques such as neural\nnetworks. Therefore, the proposed method has the potential to be scaled to\nhigh-dimensional, infinite state spaces. A key theoretical insight underlying\nour approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL)\ncondition -- a property that, while weaker than strong convexity, is sufficient\nto ensure fast global convergence guarantees. Through a series of synthetic\nexperiments, we demonstrate that our approach consistently outperforms\nbenchmark methods and state-of-the-art alternatives.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.14131v4", "cate": "cs.LG", "date": "2025-02-19", "updated": "2025-07-18", "AI": {"title_translation": "一种用于离线逆向强化学习和动态离散选择模型的经验风险最小化方法", "tldr": "本文提出了一种基于经验风险最小化（ERM）的全局收敛梯度方法，用于离线逆向强化学习（IRL）和动态离散选择（DDC）模型，无需线性参数化奖励假设或显式状态转移概率估计，并能扩展到高维空间，实验证明其性能优于现有方法。", "motivation": "研究目标是从离线行为数据中恢复控制智能体行为的奖励或Q*函数，解决现有方法中线性参数化奖励的限制，并避免显式状态转移概率估计的需求。", "method": "本文提出了一种基于经验风险最小化（ERM）的离线逆向强化学习/动态离散选择（IRL/DDC）框架，该框架采用全局收敛的梯度方法，无需对奖励函数进行线性参数化假设，并规避了贝尔曼方程中显式状态转移概率估计的需要。此外，该方法兼容神经网络等非参数估计技术，并利用贝尔曼残差满足Polyak-Lojasiewicz（PL）条件来确保快速全局收敛。", "result": "通过一系列合成实验，本文证明所提出的方法始终优于基准方法和最先进的替代方案。", "conclusion": "所提出的方法通过引入基于经验风险最小化的框架，并利用贝尔曼残差满足Polyak-Lojasiewicz条件，为离线逆向强化学习和动态离散选择模型提供了一种全局收敛且可扩展的解决方案，特别适用于高维、无限状态空间，且无需显式状态转移概率估计。", "translation": "我们研究了估计动态离散选择（DDC）模型的问题，这在机器学习中也称为离线最大熵正则化逆向强化学习（离线 MaxEnt-IRL）。目标是从离线行为数据中恢复控制智能体行为的奖励或 Q* 函数。在本文中，我们提出了一种全局收敛的基于梯度的方法来解决这些问题，而无需对奖励进行线性参数化的限制性假设。我们方法的新颖之处在于引入了基于经验风险最小化（ERM）的 IRL/DDC 框架，该框架规避了贝尔曼方程中显式状态转移概率估计的需要。此外，我们的方法与神经网络等非参数估计技术兼容。因此，所提出的方法有潜力扩展到高维、无限状态空间。我们方法的一个关键理论见解是贝尔曼残差满足 Polyak-Lojasiewicz（PL）条件——尽管该属性弱于强凸性，但足以确保快速全局收敛保证。通过一系列合成实验，我们证明我们的方法始终优于基准方法和最先进的替代方案。", "summary": "本文针对离线逆向强化学习（IRL）和动态离散选择（DDC）模型，提出了一种基于经验风险最小化（ERM）的全局收敛梯度方法。该方法旨在从离线行为数据中恢复奖励或Q*函数，其创新之处在于无需线性参数化奖励假设，并规避了显式状态转移概率估计。通过兼容非参数估计技术如神经网络，该方法可扩展到高维、无限状态空间。理论分析表明，贝尔曼残差满足Polyak-Lojasiewicz条件，保证了快速全局收敛。实验结果证明，该方法性能优于现有基准和最先进方法。", "keywords": "逆向强化学习, 动态离散选择, 经验风险最小化, 全局收敛, 非参数估计", "comments": "本文的创新点在于将经验风险最小化（ERM）框架引入离线逆向强化学习（IRL）和动态离散选择（DDC）模型，从而规避了传统方法中对显式状态转移概率估计的需求，并打破了线性参数化奖励的限制。这使得该方法能够与神经网络等非参数技术结合，具备处理高维、无限状态空间的潜力，显著提升了模型的实用性。此外，理论上证明贝尔曼残差满足Polyak-Lojasiewicz条件，为方法的全局快速收敛提供了坚实保证，增强了其可靠性。"}}
{"id": "2507.13407", "title": "IConMark: Robust Interpretable Concept-Based Watermark For AI Images", "authors": ["Vinu Sankar Sadasivan", "Mehrdad Saberi", "Soheil Feizi"], "categories": ["cs.CV", "cs.AI", "cs.CR"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at ICLR 2025 Workshop on GenAI Watermarking (WMARK)", "url": "http://arxiv.org/abs/2507.13407v1", "summary": "With the rapid rise of generative AI and synthetic media, distinguishing\nAI-generated images from real ones has become crucial in safeguarding against\nmisinformation and ensuring digital authenticity. Traditional watermarking\ntechniques have shown vulnerabilities to adversarial attacks, undermining their\neffectiveness in the presence of attackers. We propose IConMark, a novel\nin-generation robust semantic watermarking method that embeds interpretable\nconcepts into AI-generated images, as a first step toward interpretable\nwatermarking. Unlike traditional methods, which rely on adding noise or\nperturbations to AI-generated images, IConMark incorporates meaningful semantic\nattributes, making it interpretable to humans and hence, resilient to\nadversarial manipulation. This method is not only robust against various image\naugmentations but also human-readable, enabling manual verification of\nwatermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,\ndemonstrating its superiority in terms of detection accuracy and maintaining\nimage quality. Moreover, IConMark can be combined with existing watermarking\ntechniques to further enhance and complement its robustness. We introduce\nIConMark+SS and IConMark+TM, hybrid approaches combining IConMark with\nStegaStamp and TrustMark, respectively, to further bolster robustness against\nmultiple types of image manipulations. Our base watermarking technique\n(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%\nhigher mean area under the receiver operating characteristic curve (AUROC)\nscores for watermark detection, respectively, compared to the best baseline on\nvarious datasets.", "comment": "Accepted at ICLR 2025 Workshop on GenAI Watermarking (WMARK)", "pdf_url": "http://arxiv.org/pdf/2507.13407v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "IConMark：一种针对AI图像的鲁棒可解释概念水印", "tldr": "IConMark是一种新型的语义水印技术，通过将可解释的概念嵌入AI生成图像中，提高了水印的鲁棒性和可读性，优于传统方法。", "motivation": "随着生成式AI和合成媒体的快速发展，区分AI生成图像和真实图像变得至关重要，以防止虚假信息和确保数字真实性。传统水印技术易受对抗性攻击影响，降低了其有效性。", "method": "本文提出IConMark，一种新颖的生成式鲁棒语义水印方法，将可解释概念嵌入到AI生成图像中。与依赖添加噪声或扰动的传统方法不同，IConMark融入了有意义的语义属性，使其对人类可解释，并因此能抵抗对抗性操纵。该方法不仅对各种图像增强具有鲁棒性，而且具有人类可读性，支持手动验证水印。研究还引入了IConMark+SS和IConMark+TM，分别与StegaStamp和TrustMark结合的混合方法，以进一步增强鲁棒性。", "result": "IConMark在检测准确性和保持图像质量方面表现出优越性。与最佳基线相比，IConMark及其变体（+TM和+SS）在水印检测的平均受试者工作特征曲线下面积（AUROC）得分分别提高了10.8%、14.5%和15.9%。", "conclusion": "IConMark提供了一种鲁棒且可解释的水印解决方案，用于AI生成图像，有效解决了传统方法的脆弱性问题，并在检测准确性和图像质量方面表现出卓越性能。", "translation": "随着生成式AI和合成媒体的迅速兴起，区分AI生成图像和真实图像对于防范虚假信息和确保数字真实性至关重要。传统水印技术已显示出对抗性攻击的脆弱性，在攻击者存在的情况下削弱了其有效性。我们提出了IConMark，一种新颖的生成式鲁棒语义水印方法，它将可解释的概念嵌入到AI生成图像中，作为可解释水印的第一步。与依赖向AI生成图像添加噪声或扰动的传统方法不同，IConMark结合了有意义的语义属性，使其对人类可解释，从而能够抵抗对抗性操纵。该方法不仅对各种图像增强具有鲁棒性，而且具有人类可读性，能够手动验证水印。我们详细评估了IConMark的有效性，证明了其在检测准确性和保持图像质量方面的优越性。此外，IConMark可以与现有水印技术结合，进一步增强和补充其鲁棒性。我们引入了IConMark+SS和IConMark+TM，它们分别是将IConMark与StegaStamp和TrustMark结合的混合方法，以进一步增强对多种类型图像操纵的鲁棒性。我们的基础水印技术（IConMark）及其变体（+TM和+SS）在各种数据集上，与最佳基线相比，水印检测的平均受试者工作特征曲线下面积（AUROC）得分分别提高了10.8%、14.5%和15.9%。", "summary": "IConMark是一种用于AI生成图像的新型鲁棒语义水印技术，旨在解决传统水印易受对抗性攻击的问题。它通过将可解释的概念嵌入图像，使其不仅对各种图像增强具有鲁棒性，而且对人类可读，支持手动验证。该方法及其与现有技术结合的混合变体（IConMark+SS, IConMark+TM）在水印检测准确性方面显著优于现有基线，同时保持了图像质量，为防止AI生成媒体的虚假信息提供了有效手段。", "keywords": "AI图像, 水印, 可解释性, 鲁棒性, 语义水印", "comments": "IConMark的创新之处在于其“可解释概念嵌入”方法，这使其与传统基于噪声或扰动的水印技术区分开来。这种方法不仅提高了水印的鲁棒性，还增加了人类可读性，为AI图像的真实性验证提供了一个新颖且实用的途径。它解决了AI时代数字内容真实性面临的紧迫挑战，具有重要的实际应用价值。"}}
{"id": "2507.13385", "title": "Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery", "authors": ["Arjun Rao", "Esther Rolf"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "url": "http://arxiv.org/abs/2507.13385v1", "summary": "A large variety of geospatial data layers is available around the world\nranging from remotely-sensed raster data like satellite imagery, digital\nelevation models, predicted land cover maps, and human-annotated data, to data\nderived from environmental sensors such as air temperature or wind speed data.\nA large majority of machine learning models trained on satellite imagery\n(SatML), however, are designed primarily for optical input modalities such as\nmulti-spectral satellite imagery. To better understand the value of using other\ninput modalities alongside optical imagery in supervised learning settings, we\ngenerate augmented versions of SatML benchmark tasks by appending additional\ngeographic data layers to datasets spanning classification, regression, and\nsegmentation. Using these augmented datasets, we find that fusing additional\ngeographic inputs with optical imagery can significantly improve SatML model\nperformance. Benefits are largest in settings where labeled data are limited\nand in geographic out-of-sample settings, suggesting that multi-modal inputs\nmay be especially valuable for data-efficiency and out-of-sample performance of\nSatML models. Surprisingly, we find that hard-coded fusion strategies\noutperform learned variants, with interesting implications for future work.", "comment": "17 pages, 9 figures, 7 tables. Accepted to TerraBytes@ICML 2025", "pdf_url": "http://arxiv.org/pdf/2507.13385v1", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "使用多输入模态可提高卫星图像机器学习的数据效率和O.O.D.泛化能力", "tldr": "将额外地理数据与光学卫星图像融合可显著提升机器学习模型性能，尤其是在数据有限和样本外泛化场景下，且硬编码融合策略优于学习型策略。", "motivation": "目前大多数卫星图像机器学习（SatML）模型主要设计用于光学输入模态。本研究旨在更好地理解在监督学习设置中，将其他输入模态与光学图像结合使用的价值。", "method": "研究人员通过将额外的地理数据层附加到涵盖分类、回归和分割任务的数据集中，生成了增强版的SatML基准任务。然后，使用这些增强数据集来评估多模态输入的效果。", "result": "将额外的地理输入与光学图像融合可以显著提高SatML模型的性能。在标记数据有限和地理样本外设置中，这种益处最大。此外，研究发现硬编码融合策略优于学习型策略。", "conclusion": "多模态输入对于SatML模型的数据效率和样本外性能可能特别有价值。", "translation": "世界各地有各种各样的地理空间数据层可用，范围从遥感栅格数据（如卫星图像、数字高程模型、预测土地覆盖图和人工标注数据）到来源于环境传感器的数据（如气温或风速数据）。然而，绝大多数在卫星图像上训练的机器学习模型（SatML）主要设计用于光学输入模态，如多光谱卫星图像。为了更好地理解在监督学习设置中，将其他输入模态与光学图像结合使用的价值，我们通过将额外的地理数据层附加到涵盖分类、回归和分割的数据集，生成了增强版的SatML基准任务。使用这些增强数据集，我们发现将额外的地理输入与光学图像融合可以显著提高SatML模型的性能。在标记数据有限和地理样本外设置中，这种益处最大，这表明多模态输入对于SatML模型的数据效率和样本外性能可能特别有价值。令人惊讶的是，我们发现硬编码融合策略优于学习型策略，这对未来的工作具有有趣的启示。", "summary": "本研究探讨了在卫星图像机器学习（SatML）中结合多种输入模态的价值。通过将额外的地理数据层与光学卫星图像融合，研究发现SatML模型的性能显著提升，尤其是在数据效率和样本外泛化方面。结果表明，这种多模态融合在标记数据有限和地理样本外场景下效果最佳。此外，一个出人意料的发现是，硬编码的融合策略表现优于学习型策略。", "keywords": "多模态, 卫星图像, 数据效率, 泛化, 机器学习", "comments": "这篇论文的创新点在于系统地探索了多模态输入在卫星图像机器学习中的潜力，并明确指出了其在数据效率和样本外泛化方面的优势。特别值得关注的是，研究发现硬编码融合策略优于学习型策略，这一反直觉的结果对未来的研究方向具有重要启示，可能促使研究人员重新思考多模态融合的设计范式。"}}
{"id": "2507.13203", "title": "On finite extensions of lamplighter groups", "authors": ["Corentin Bodart"], "categories": ["math.GR", "cs.DM", "cs.FL"], "primary_category": "Subjects:       Group Theory (math.GR)", "pdf_link": null, "comments": "Comments:      27 pages, 6 figures. v2: Removed the very last (wrong) remark, and fixed a reference", "url": "http://arxiv.org/abs/2507.13203v2", "summary": "We study a family of groups consisting of the simplest extensions of\nlamplighter groups. We use these groups to answer multiple open questions in\ncombinatorial group theory, providing groups that exhibit various combinations\nof properties: 1) Decidable Subgroup Membership and undecidable Uniform\nSubgroup Membership Problem, 2) Rational volume growth series and undecidable\nWord Problem and 3) Recursive (even context-free) language of conjugacy\ngeodesics, decidable Word Problem, and undecidable Conjugacy Problem. We also\nconsider the co-Word Problem, residual finiteness and the Isomorphism Problem\nwithin this class.", "comment": "27 pages, 6 figures. v2: Removed the very last (wrong) remark, and\n  fixed a reference", "pdf_url": "http://arxiv.org/pdf/2507.13203v2", "cate": "math.GR", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "关于灯夫群的有限扩张", "tldr": "研究灯夫群的简单扩张，解决组合群论中多个开放问题，提供具有特定性质组合的群。", "motivation": "旨在解决组合群论中的多个开放问题。", "method": "通过研究灯夫群的最简单扩张家族，并利用这些群来展示各种性质组合。", "result": "提供了具有以下性质组合的群：1) 可判定的子群成员问题和不可判定的均匀子群成员问题；2) 有理体积增长序列和不可判定的单词问题；3) 递归（甚至是上下文无关）的共轭测地线语言，可判定的单词问题和不可判定的共轭问题。还考虑了这类群中的共单词问题、剩余有限性和同构问题。", "conclusion": "该研究通过构造特定群，为组合群论中一些长期存在的开放问题提供了具体答案和新的示例。", "translation": "我们研究了一族由灯夫群最简单扩张组成的群。我们利用这些群回答了组合群论中的多个开放问题，提供了展示各种性质组合的群：1) 可判定的子群成员问题和不可判定的均匀子群成员问题；2) 有理体积增长序列和不可判定的单词问题；3) 递归（甚至是上下文无关）的共轭测地线语言，可判定的单词问题和不可判定的共轭问题。我们还考虑了这类群中的共单词问题、剩余有限性和同构问题。", "summary": "本文研究了灯夫群的有限扩张，并利用这些新构造的群解决了组合群论中的多个开放问题。研究展示了具有特定性质组合的群，包括子群成员、单词和共轭问题在可判定性方面的复杂性差异，以及体积增长序列的性质。此外，还探讨了共单词问题、剩余有限性和同构问题。", "keywords": "灯夫群, 组合群论, 可判定性, 单词问题, 共轭问题", "comments": "该论文的创新之处在于构造了一系列具有新颖且特定性质组合的群，为组合群论中一些难以解决的问题提供了具体的反例或示例，推动了该领域对群性质可判定性的理解。"}}
{"id": "2507.14119", "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining", "authors": ["Maksim Kuprashevich", "Grigorii Alekseenko", "Irina Tolstykh", "Georgii Fedorov", "Bulat Suleimanov", "Vladimir Dokholyan", "Aleksandr Gordeev"], "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14119v1", "summary": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14119v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "无需人类：自主高质量图像编辑三元组挖掘", "tldr": "本文提出一个名为NoHumansRequired的自动化管道，用于生成高质量的图像编辑三元组，以大规模训练图像编辑助手，无需人工标注。该方法通过一个Gemini验证器评估质量，并利用数据扩充技术，最终发布了大规模数据集NHR-Edit和SOTA模型Bagel-NHR-Edit。", "motivation": "现有的生成式图像编辑助手需要数百万个高质量的三元组（原始图像、指令、编辑后的图像）进行监督训练。然而，挖掘像素级精确的示例非常困难，因为编辑必须满足区域限制、风格一致性、物理合理性和视觉吸引力等多重质量要求。此外，缺乏鲁棒的自动化编辑质量度量标准阻碍了大规模的可靠自动化。", "method": "本文提出了一个自动化、模块化的管道，用于挖掘跨域、跨分辨率、跨指令复杂度和跨风格的高保真三元组。该系统基于公共生成模型构建，无需人工干预即可运行。它使用一个任务调优的Gemini验证器直接对指令依从性和美观性进行评分，从而无需分割或接地模型。通过反转和组合自举，挖掘出的数据集扩大了约2.2倍。", "result": "该方法通过自动化重复的标注步骤，实现了大规模的训练数据生成，且无需人工标注。本文发布了一个包含35.8万个高质量三元组的开放数据集NHR-Edit，在最大的跨数据集评估中超越了所有公开替代方案。同时，还发布了一个开源的微调Bagel模型Bagel-NHR-Edit，在实验中取得了最先进的指标。", "conclusion": "本文的工作通过提供自动化的高质量三元组挖掘管道和大规模开放数据集，极大地降低了图像编辑领域资源密集型研究的门槛，促进了该领域的民主化发展。", "translation": "最近生成建模的进展使得图像编辑助手能够无需额外的用户输入即可遵循自然语言指令。它们的监督训练需要数百万个三元组：原始图像、指令、编辑后的图像。然而，挖掘像素精确的示例非常困难。每次编辑都必须仅影响提示指定的区域，保持风格一致性，尊重物理合理性，并保留视觉吸引力。缺乏鲁棒的自动化编辑质量度量标准阻碍了大规模的可靠自动化。我们提出了一个自动化、模块化的管道，可以在跨域、跨分辨率、跨指令复杂度和跨风格的情况下挖掘高保真三元组。我们的系统基于公共生成模型构建，无需人工干预即可运行，它使用一个任务调优的Gemini验证器直接对指令依从性和美观性进行评分，从而消除了对分割或接地模型的需求。反转和组合自举将挖掘出的集合扩大了约2.2倍，从而实现了大规模高保真训练数据。通过自动化最重复的标注步骤，该方法实现了新规模的训练，而无需人工标注工作。为了使这一资源密集型领域的研究民主化，我们发布了NHR-Edit：一个包含35.8万个高质量三元组的开放数据集。在最大的跨数据集评估中，它超越了所有公开替代方案。我们还发布了Bagel-NHR-Edit，一个开源的微调Bagel模型，在我们的实验中取得了最先进的指标。", "summary": "本文针对生成式图像编辑助手训练中高质量三元组数据获取困难的问题，提出了一个名为“NoHumansRequired”的自动化管道。该管道能够无需人工干预，利用公共生成模型和专门调优的Gemini验证器，高效地挖掘和扩充高保真图像编辑三元组。该方法通过自动化数据生成流程，极大地减少了人工标注需求。为促进研究，作者发布了包含35.8万个高质量三元组的NHR-Edit开放数据集，以及一个实现最先进性能的微调Bagel模型Bagel-NHR-Edit。", "keywords": "图像编辑, 三元组挖掘, 自动化数据生成, 生成模型, 数据集", "comments": "本文最大的创新在于提出了一种完全自动化的、无需人工干预的高质量图像编辑三元组挖掘管道，有效解决了大规模训练数据获取的瓶颈。其利用Gemini验证器直接评估指令依从性和美观性，避免了复杂的分割或接地模型，简化了流程。此外，通过发布大规模数据集和SOTA模型，极大地降低了该领域研究的门槛，具有重要的实践意义和推动作用。"}}
{"id": "2501.06848", "title": "A General Framework for Inference-time Scaling and Steering of Diffusion Models", "authors": ["Raghav Singhal", "Zachary Horvitz", "Ryan Teehan", "Mengye Ren", "Zhou Yu", "Kathleen McKeown", "Rajesh Ranganath"], "categories": ["cs.LG", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.06848v5", "summary": "Diffusion models produce impressive results in modalities ranging from images\nand video to protein design and text. However, generating samples with\nuser-specified properties remains a challenge. Recent research proposes\nfine-tuning models to maximize rewards that capture desired properties, but\nthese methods require expensive training and are prone to mode collapse. In\nthis work, we present Feynman-Kac (FK) steering, an inference-time framework\nfor steering diffusion models with reward functions. FK steering works by\nsampling a system of multiple interacting diffusion processes, called\nparticles, and resampling particles at intermediate steps based on scores\ncomputed using functions called potentials. Potentials are defined using\nrewards for intermediate states and are selected such that a high value\nindicates that the particle will yield a high-reward sample. We explore various\nchoices of potentials, intermediate rewards, and samplers. We evaluate FK\nsteering on text-to-image and text diffusion models. For steering text-to-image\nmodels with a human preference reward, we find that FK steering a 0.8B\nparameter model outperforms a 2.6B parameter fine-tuned model on prompt\nfidelity, with faster sampling and no training. For steering text diffusion\nmodels with rewards for text quality and specific text attributes, we find that\nFK steering generates lower perplexity, more linguistically acceptable outputs\nand enables gradient-free control of attributes like toxicity. Our results\ndemonstrate that inference-time scaling and steering of diffusion models - even\nwith off-the-shelf rewards - can provide significant sample quality gains and\ncontrollability benefits. Code is available at\nhttps://github.com/zacharyhorvitz/Fk-Diffusion-Steering .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.06848v5", "cate": "cs.LG", "date": "2025-01-12", "updated": "2025-07-18", "AI": {"title_translation": "扩散模型推理时缩放与引导的通用框架", "tldr": "本文提出Feynman-Kac (FK)引导，一个推理时框架，用于通过奖励函数引导扩散模型，无需昂贵训练即可提高样本质量和可控性，优于微调模型。", "motivation": "扩散模型在生成具有用户指定属性的样本时面临挑战。现有的微调方法需要昂贵训练且易出现模式崩溃。", "method": "本文提出Feynman-Kac (FK)引导，一个推理时框架，通过奖励函数引导扩散模型。FK引导通过采样多个相互作用的扩散过程（称为粒子），并在中间步骤根据使用势函数计算的分数重新采样粒子。势函数使用中间状态的奖励定义，以确保粒子产生高奖励样本。研究探索了不同的势函数、中间奖励和采样器选择。", "result": "在文本到图像模型上，FK引导（0.8B参数模型）在提示保真度方面优于2.6B参数的微调模型，采样更快且无需训练。在文本扩散模型上，FK引导生成了更低困惑度、更符合语言习惯的输出，并实现了对毒性等属性的无梯度控制。", "conclusion": "推理时对扩散模型进行缩放和引导——即使使用现成的奖励——也能显著提高样本质量并增强可控性。", "translation": "扩散模型在从图像、视频到蛋白质设计和文本等多种模态中产生了令人印象深刻的结果。然而，生成具有用户指定属性的样本仍然是一个挑战。最近的研究提出了微调模型以最大化捕获所需属性的奖励，但这些方法需要昂贵的训练并且容易出现模式崩溃。在这项工作中，我们提出了Feynman-Kac (FK)引导，一个用于通过奖励函数引导扩散模型的推理时框架。FK引导通过采样一个由多个相互作用的扩散过程（称为粒子）组成的系统来工作，并根据使用称为势函数的功能计算的分数在中间步骤重新采样粒子。势函数是使用中间状态的奖励定义的，并且选择它们使得高值表示粒子将产生高奖励样本。我们探索了势函数、中间奖励和采样器的各种选择。我们在文本到图像和文本扩散模型上评估了FK引导。对于使用人类偏好奖励引导文本到图像模型，我们发现FK引导一个0.8B参数模型在提示保真度方面优于2.6B参数的微调模型，采样更快且无需训练。对于使用文本质量和特定文本属性奖励引导文本扩散模型，我们发现FK引导生成了更低困惑度、更符合语言习惯的输出，并实现了对毒性等属性的无梯度控制。我们的结果表明，扩散模型的推理时缩放和引导——即使使用现成的奖励——也能提供显著的样本质量增益和可控性优势。代码可在https://github.com/zacharyhorvitz/Fk-Diffusion-Steering获取。", "summary": "本文提出Feynman-Kac (FK)引导，一个新颖的推理时框架，旨在解决扩散模型生成用户指定属性样本的挑战。该方法通过采样和重采样多粒子扩散过程，利用奖励定义的势函数来引导生成高奖励样本，避免了传统微调的昂贵训练和模式崩溃问题。实验证明，FK引导在文本到图像和文本扩散任务中，无需训练即可显著提高样本质量和可控性，甚至超越了更大的微调模型。", "keywords": "扩散模型, 推理时引导, Feynman-Kac, 奖励函数, 样本质量", "comments": "这项工作具有创新性，通过在推理阶段引入Feynman-Kac引导，有效地解决了扩散模型生成特定属性样本的难题，避免了耗时且易失败的微调过程。其在无需训练的情况下，能够超越更大规模的微调模型，并在可控性方面表现出色，预示着扩散模型应用的新范式，尤其对于实时或资源受限场景具有重要意义。"}}
{"id": "2507.13508", "title": "Fake or Real: The Impostor Hunt in Texts for Space Operations", "authors": ["Agata Kaczmarek", "Dawid Płudowski", "Piotr Wilczyński", "Przemysław Biecek", "Krzysztof Kotowski", "Ramez Shendy", "Jakub Nalepa", "Artur Janicki", "Evridiki Ntagiou"], "categories": ["cs.LG", "cs.CR"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13508v1", "summary": "The \"Fake or Real\" competition hosted on Kaggle\n(\\href{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt}{https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt})\nis the second part of a series of follow-up competitions and hackathons related\nto the \"Assurance for Space Domain AI Applications\" project funded by the\nEuropean Space Agency\n(\\href{https://assurance-ai.space-codev.org/}{https://assurance-ai.space-codev.org/}).\nThe competition idea is based on two real-life AI security threats identified\nwithin the project -- data poisoning and overreliance in Large Language Models.\nThe task is to distinguish between the proper output from LLM and the output\ngenerated under malicious modification of the LLM. As this problem was not\nextensively researched, participants are required to develop new techniques to\naddress this issue or adjust already existing ones to this problem's statement.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13508v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "假或真：空间操作文本中的冒名顶替者搜捕", "tldr": "Kaggle上的“假或真”竞赛旨在解决LLM在空间操作中面临的数据投毒和过度依赖威胁，要求参与者区分正常与恶意修改的LLM输出。", "motivation": "该竞赛的动机是解决在空间领域AI应用项目中识别出的两个现实AI安全威胁：数据投毒和大型语言模型（LLM）的过度依赖问题。由于这个问题研究不足，需要开发或调整新技术来应对。", "method": "抽象中未提及论文自身的方法，而是描述了竞赛要求参与者开发或调整现有技术来区分正常LLM输出和恶意修改后的LLM输出。", "result": "抽象中未提及具体结果，因为这是一项竞赛的介绍。", "conclusion": "抽象中未提及明确的结论，更侧重于介绍竞赛背景和任务。", "translation": "Kaggle上举办的“假或真”竞赛（https://www.kaggle.com/competitions/fake-or-real-the-impostor-hunt）是欧洲空间局资助的“空间领域AI应用保障”项目（https://assurance-ai.space-codev.org/）相关系列后续竞赛和黑客马拉松的第二部分。该竞赛理念基于项目内识别出的两个现实AI安全威胁——数据投毒和大型语言模型中的过度依赖。任务是区分LLM的正确输出和LLM在恶意修改下生成的输出。由于这个问题尚未得到广泛研究，参与者需要开发新的技术来解决这个问题，或者调整现有技术来适应这个问题的陈述。", "summary": "这篇论文介绍了Kaggle上名为“假或真：空间操作文本中的冒名顶替者搜捕”的竞赛，该竞赛是欧洲空间局资助的“空间领域AI应用保障”项目的一部分。竞赛旨在解决大型语言模型在空间操作中面临的数据投毒和过度依赖的现实AI安全威胁。主要任务是区分LLM的正常输出和恶意修改后的输出，鼓励参与者开发或调整新的技术来应对这一研究不足的问题。", "keywords": "数据投毒, 大型语言模型, AI安全, 空间操作, Kaggle竞赛", "comments": "这项竞赛的重要性在于它直接针对了大型语言模型在关键领域（如空间操作）中的实际安全威胁。通过竞赛形式，可以鼓励社区探索和开发创新的解决方案来检测和防范数据投毒和模型输出的恶意篡改。这对于确保AI系统在敏感应用中的可靠性和安全性至关重要。"}}
{"id": "2507.13636", "title": "Duplicating Deceit: Inauthentic Behavior Among Indian Misinformation Duplicators on X/Twitter", "authors": ["Ashfaq Ali Shafin", "Bogdan Carbunar"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      8 pages, 1 figure, accepted in 17th International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025)", "url": "http://arxiv.org/abs/2507.13636v1", "summary": "This paper investigates inauthentic duplication on social media, where\nmultiple accounts share identical misinformation tweets. Leveraging a dataset\nof misinformation verified by AltNews, an Indian fact-checking organization, we\nanalyze over 12 million posts from 5,493 accounts known to have duplicated such\ncontent. Contrary to common assumptions that bots are primarily responsible for\nspreading false information, fewer than 1\\% of these accounts exhibit bot-like\nbehavior. We present TweeXster, a framework for detecting and analyzing\nduplication campaigns, revealing clusters of accounts involved in repeated and\nsometimes revived dissemination of false or abusive content.", "comment": "8 pages, 1 figure, accepted in 17th International Conference on\n  Advances in Social Networks Analysis and Mining (ASONAM 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13636v1", "cate": "cs.SI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "复制欺骗：X/Twitter上印度虚假信息复制者中的不真实行为", "tldr": "本研究调查了社交媒体上重复发布虚假信息的行为，发现在印度复制虚假信息的账户中，少于1%表现出机器人行为。论文提出了TweeXster框架来检测和分析此类复制活动。", "motivation": "本研究旨在调查社交媒体上虚假信息的重复发布行为，特别是多个账户共享相同虚假推文的现象，并挑战关于机器人是虚假信息传播主要责任者的常见假设。", "method": "研究利用了印度事实核查组织AltNews验证的虚假信息数据集，分析了来自5,493个已知复制此类内容的账户的超过1200万条帖子。研究提出了TweeXster框架，用于检测和分析复制活动。", "result": "研究发现，在复制虚假信息的账户中，少于1%的账户表现出机器人行为，这与常见的机器人是虚假信息主要传播者的假设相悖。TweeXster框架揭示了参与重复传播甚至复活虚假或辱骂内容的账户群。", "conclusion": "结论是，在印度社交媒体上复制虚假信息的行为并非主要由机器人驱动，而是涉及复杂的账户集群。这表明需要更细致地理解虚假信息传播中的不真实行为。", "translation": "本文调查了社交媒体上不真实的重复行为，即多个账户共享相同的虚假信息推文。利用印度事实核查组织AltNews验证的虚假信息数据集，我们分析了来自5,493个已知复制此类内容的账户的超过1200万条帖子。与机器人主要负责传播虚假信息的普遍假设相反，这些账户中少于1%表现出机器人行为。我们提出了TweeXster，一个用于检测和分析复制活动的框架，揭示了参与重复传播有时甚至是复活虚假或辱骂内容的账户集群。", "summary": "本研究调查了X/Twitter上印度虚假信息复制者的不真实行为。通过分析来自5,493个账户的超过1200万条已验证的虚假信息推文，研究发现少于1%的复制账户表现出机器人行为，挑战了机器人是主要传播者的假设。论文提出了TweeXster框架，用于检测和分析此类复制活动，并识别出参与传播虚假内容的账户集群。", "keywords": "虚假信息复制, 不真实行为, X/Twitter, TweeXster, 机器人行为", "comments": "这项研究的创新之处在于它挑战了关于虚假信息传播中机器人作用的普遍看法，并提出了一个专门用于检测和分析重复行为的框架。其重要性在于揭示了人类或其他非机器人实体在虚假信息传播中的潜在更大作用，为打击虚假信息提供了新的视角。然而，研究的范围仅限于印度和X/Twitter平台，其结论可能不完全适用于其他地区或平台。"}}
{"id": "2507.13725", "title": "Point of Interest Recommendation: Pitfalls and Viable Solutions", "authors": ["Alejandro Bellogín", "Linus W. Dietz", "Francesco Ricci", "Pablo Sánchez"], "categories": ["cs.IR", "cs.AI"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13725v1", "summary": "Point of interest (POI) recommendation can play a pivotal role in enriching\ntourists' experiences by suggesting context-dependent and preference-matching\nlocations and activities, such as restaurants, landmarks, itineraries, and\ncultural attractions. Unlike some more common recommendation domains (e.g.,\nmusic and video), POI recommendation is inherently high-stakes: users invest\nsignificant time, money, and effort to search, choose, and consume these\nsuggested POIs. Despite the numerous research works in the area, several\nfundamental issues remain unresolved, hindering the real-world applicability of\nthe proposed approaches. In this paper, we discuss the current status of the\nPOI recommendation problem and the main challenges we have identified. The\nfirst contribution of this paper is a critical assessment of the current state\nof POI recommendation research and the identification of key shortcomings\nacross three main dimensions: datasets, algorithms, and evaluation\nmethodologies. We highlight persistent issues such as the lack of standardized\nbenchmark datasets, flawed assumptions in the problem definition and model\ndesign, and inadequate treatment of biases in the user behavior and system\nperformance. The second contribution is a structured research agenda that,\nstarting from the identified issues, introduces important directions for future\nwork related to multistakeholder design, context awareness, data collection,\ntrustworthiness, novel interactions, and real-world evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13725v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "兴趣点推荐：陷阱与可行方案", "tldr": "本文讨论了兴趣点（POI）推荐领域存在的根本性问题，并提出了一个结构化的未来研究议程以解决这些挑战。", "motivation": "兴趣点（POI）推荐对提升用户体验至关重要，但现有研究成果在实际应用中面临诸多阻碍，因为该领域与传统推荐（如音乐、视频）不同，用户在兴趣点上的投入成本更高，使得任何缺陷都可能带来显著负面影响。", "method": "本研究首先对当前兴趣点（POI）推荐研究的现状进行了批判性评估，识别了在数据集、算法和评估方法三个核心维度上的关键缺陷。在此基础上，提出了一个结构化的研究议程，为未来的研究方向提供了指导。", "result": "识别出兴趣点推荐研究在数据集（缺乏标准化基准）、算法（问题定义和模型设计中的缺陷假设）和评估方法（对用户行为和系统性能偏差处理不足）方面的关键缺陷。提出了一个包括多方利益者设计、上下文感知、数据收集、可信度、新颖交互和真实世界评估等方向的结构化研究议程。", "conclusion": "兴趣点（POI）推荐领域存在显著的未解决问题和挑战，需要通过系统性的批判性评估和结构化的研究议程来解决，以提升其在真实世界中的实用性和可靠性。", "translation": "兴趣点（POI）推荐通过推荐依赖于上下文且符合偏好的地点和活动，例如餐馆、地标、行程和文化景点，在丰富游客体验方面可以发挥关键作用。与一些更常见的推荐领域（例如音乐和视频）不同，POI推荐本质上是高风险的：用户投入大量时间、金钱和精力来搜索、选择和消费这些推荐的POI。尽管该领域有大量研究工作，但一些基本问题仍未解决，阻碍了所提出方法的实际应用。在本文中，我们讨论了POI推荐问题的现状以及我们识别出的主要挑战。本文的第一个贡献是对当前POI推荐研究现状的批判性评估，并识别了在三个主要维度上的关键缺陷：数据集、算法和评估方法。我们强调了持续存在的问题，例如缺乏标准化的基准数据集、问题定义和模型设计中的缺陷假设，以及对用户行为和系统性能偏差处理不足。第二个贡献是一个结构化的研究议程，该议程从已识别的问题出发，为未来在多利益相关者设计、上下文感知、数据收集、可信度、新颖交互和真实世界评估方面的工作引入了重要方向。", "summary": "本文深入探讨了兴趣点（POI）推荐领域面临的挑战与陷阱。作者首先对当前POI推荐研究进行了批判性评估，揭示了在数据集标准化、算法设计假设和评估方法偏差处理方面存在的关键缺陷。基于这些发现，论文提出了一个结构化的研究议程，为未来在多利益相关者设计、上下文感知、数据收集、可信度、新颖交互和真实世界评估等方向的研究提供了重要指引，旨在推动POI推荐技术的实际应用和发展。", "keywords": "兴趣点推荐, 推荐系统, 研究挑战, 评估方法, 研究议程", "comments": "这篇论文并非提出新的算法，而是对兴趣点推荐这一“高风险”领域进行了深刻的反思和批判性分析。其重要性在于系统性地揭示了该领域长期存在的根本性问题，并提供了一个全面的、具有前瞻性的研究框架。这对于指导未来研究方向，避免重复性工作，并促使研究更贴近实际应用具有重要的指导意义和价值。"}}
{"id": "2507.13827", "title": "Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models", "authors": ["Hosein Azarbonyad", "Zi Long Zhu", "Georgios Cheirmpos", "Zubair Afzal", "Vikrant Yadav", "Georgios Tsatsaronis"], "categories": ["cs.CL", "cs.IR", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      SIGIR 2025", "url": "http://arxiv.org/abs/2507.13827v1", "summary": "When deciding to read an article or incorporate it into their research,\nscholars often seek to quickly identify and understand its main ideas. In this\npaper, we aim to extract these key concepts and contributions from scientific\narticles in the form of Question and Answer (QA) pairs. We propose two distinct\napproaches for generating QAs. The first approach involves selecting salient\nparagraphs, using a Large Language Model (LLM) to generate questions, ranking\nthese questions by the likelihood of obtaining meaningful answers, and\nsubsequently generating answers. This method relies exclusively on the content\nof the articles. However, assessing an article's novelty typically requires\ncomparison with the existing literature. Therefore, our second approach\nleverages a Knowledge Graph (KG) for QA generation. We construct a KG by\nfine-tuning an Entity Relationship (ER) extraction model on scientific articles\nand using it to build the graph. We then employ a salient triplet extraction\nmethod to select the most pertinent ERs per article, utilizing metrics such as\nthe centrality of entities based on a triplet TF-IDF-like measure. This measure\nassesses the saliency of a triplet based on its importance within the article\ncompared to its prevalence in the literature. For evaluation, we generate QAs\nusing both approaches and have them assessed by Subject Matter Experts (SMEs)\nthrough a set of predefined metrics to evaluate the quality of both questions\nand answers. Our evaluations demonstrate that the KG-based approach effectively\ncaptures the main ideas discussed in the articles. Furthermore, our findings\nindicate that fine-tuning the ER extraction model on our scientific corpus is\ncrucial for extracting high-quality triplets from such documents.", "comment": "SIGIR 2025", "pdf_url": "http://arxiv.org/pdf/2507.13827v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用知识图谱和大型语言模型从科学文章中提取问答对", "tldr": "本文提出两种方法，包括纯LLM和结合知识图谱（KG）的方法，从科学文章中提取问答对（QA），其中基于KG的方法在捕捉文章主旨方面表现更优，且强调了对实体关系（ER）提取模型进行微调的重要性。", "motivation": "学者在决定阅读或将其纳入研究时，通常希望快速识别和理解文章的主要思想。", "method": "本文提出了两种问答对生成方法：1. 纯大型语言模型（LLM）方法：选择关键段落，LLM生成问题，对问题进行排名，然后生成答案，完全依赖文章内容。 2. 知识图谱（KG）方法：通过在科学文章上微调实体关系（ER）提取模型来构建KG，然后使用显著三元组提取方法（基于三元组TF-IDF类度量）选择最相关的ERs。两种方法生成的QA对都通过领域专家（SMEs）评估。", "result": "评估结果表明，基于知识图谱（KG）的方法能有效捕捉文章的主要思想。此外，研究发现，在科学语料库上微调实体关系（ER）提取模型对于从这类文档中提取高质量三元组至关重要。", "conclusion": "基于知识图谱的方法能够有效捕捉科学文章的核心思想，且针对特定科学语料库微调实体关系提取模型对于获取高质量三元组至关重要。", "translation": "当学者决定阅读一篇文章或将其纳入研究时，他们通常希望快速识别并理解其主要思想。在本文中，我们旨在以问答（QA）对的形式从科学文章中提取这些关键概念和贡献。我们提出了两种不同的QA生成方法。第一种方法涉及选择显著段落，使用大型语言模型（LLM）生成问题，根据获得有意义答案的可能性对这些问题进行排名，然后生成答案。此方法完全依赖文章内容。然而，评估一篇文章的新颖性通常需要与现有文献进行比较。因此，我们的第二种方法利用知识图谱（KG）进行QA生成。我们通过在科学文章上微调实体关系（ER）提取模型来构建KG，并用它来构建图。然后，我们采用显著三元组提取方法来选择每篇文章最相关的ER，利用实体中心性等指标，该指标基于三元组TF-IDF类度量。此度量评估三元组在文章中的重要性与它在文献中的普及程度相比的显著性。为了进行评估，我们使用两种方法生成QA，并通过一组预定义的指标由领域专家（SMEs）进行评估，以评估问题和答案的质量。我们的评估表明，基于KG的方法能有效捕捉文章中讨论的主要思想。此外，我们的发现表明，在我们的科学语料库上微调ER提取模型对于从这些文档中提取高质量三元组至关重要。", "summary": "本文旨在从科学文章中提取关键概念和贡献，以问答对（QA）的形式呈现。研究提出了两种方法：一种是纯粹基于大型语言模型（LLM），通过选择段落、生成问题、排名和生成答案来工作；另一种是结合知识图谱（KG）的方法，通过微调实体关系（ER）提取模型构建KG，并利用显著三元组提取技术来识别关键信息。通过领域专家评估，结果显示基于KG的方法能更有效地捕捉文章主旨，并且强调了在科学语料库上微调ER提取模型的重要性，以确保高质量的三元组提取。", "keywords": "问答提取, 知识图谱, 大型语言模型, 科学文章, 实体关系提取", "comments": "本文的创新之处在于结合了大型语言模型和知识图谱来解决科学文章的问答提取问题，特别是在评估文章新颖性时，知识图谱方法的引入是一个亮点。通过微调实体关系提取模型以适应科学语料库，提高了提取高质量信息的准确性，这对于学术研究人员快速理解文献核心内容具有重要意义。该方法有望提高文献综述和信息检索的效率。"}}
{"id": "2503.07348", "title": "Cycle-Consistent Multi-Graph Matching for Self-Supervised Annotation of C.Elegans", "authors": ["Christoph Karg", "Sebastian Stricker", "Lisa Hutschenreiter", "Bogdan Savchynskyy", "Dagmar Kainmueller"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.07348v2", "summary": "In this work we present a novel approach for unsupervised multi-graph\nmatching, which applies to problems for which a Gaussian distribution of\nkeypoint features can be assumed. We leverage cycle consistency as loss for\nself-supervised learning, and determine Gaussian parameters through Bayesian\nOptimization, yielding a highly efficient approach that scales to large\ndatasets. Our fully unsupervised approach enables us to reach the accuracy of\nstate-of-the-art supervised methodology for the biomedical use case of semantic\ncell annotation in 3D microscopy images of the worm C. elegans. To this end,\nour approach yields the first unsupervised atlas of C. elegans, i.e. a model of\nthe joint distribution of all of its cell nuclei, without the need for any\nground truth cell annotation. This advancement enables highly efficient\nsemantic annotation of cells in large microscopy datasets, overcoming a current\nkey bottleneck. Beyond C. elegans, our approach offers fully unsupervised\nconstruction of cell-level atlases for any model organism with a stereotyped\nbody plan down to the level of unique semantic cell labels, and thus bears the\npotential to catalyze respective biomedical studies in a range of further\nspecies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.07348v2", "cate": "cs.CV", "date": "2025-03-10", "updated": "2025-07-18", "AI": {"title_translation": "循环一致多图匹配用于秀丽隐杆线虫的自监督标注", "tldr": "提出了一种无监督多图匹配方法，利用循环一致性进行自监督学习，并通过贝叶斯优化确定高斯参数，实现了秀丽隐杆线虫细胞的无监督语义标注，并构建了首个无监督线虫细胞图谱，达到有监督方法的精度。", "motivation": "解决大型显微镜数据集中细胞语义标注需要大量人工标注（地面真值）的瓶颈，尤其是在构建细胞图谱时。", "method": "提出了一种新颖的无监督多图匹配方法，适用于可假设关键点特征呈高斯分布的问题。该方法利用循环一致性作为自监督学习的损失函数，并通过贝叶斯优化确定高斯参数，从而实现高效且可扩展到大型数据集。", "result": "该无监督方法在秀丽隐杆线虫3D显微图像的语义细胞标注任务中，达到了与现有监督方法相当的精度。它首次无需任何地面真值细胞标注，构建了秀丽隐杆线虫的无监督细胞图谱（即其所有细胞核联合分布的模型）。", "conclusion": "该方法为秀丽隐杆线虫及其他具有刻板身体结构的模式生物提供了完全无监督的细胞水平图谱构建能力，有望推动相关生物医学研究。", "translation": "在这项工作中，我们提出了一种新颖的无监督多图匹配方法，适用于可假设关键点特征呈高斯分布的问题。我们利用循环一致性作为自监督学习的损失函数，并通过贝叶斯优化确定高斯参数，从而实现了一种高效且可扩展到大型数据集的方法。我们的完全无监督方法使我们能够在秀丽隐杆线虫3D显微图像中语义细胞标注的生物医学用例中达到最先进的有监督方法的精度。为此，我们的方法生成了第一个无监督的秀丽隐杆线虫图谱，即其所有细胞核联合分布的模型，而无需任何地面真值细胞标注。这一进展使得在大型显微镜数据集中高效地进行细胞语义标注成为可能，克服了当前的一个关键瓶颈。除了秀丽隐杆线虫，我们的方法还为任何具有刻板身体结构的模型生物提供了完全无监督的细胞水平图谱构建能力，直至独特的语义细胞标签层面，因此有望催化一系列其他物种的相关生物医学研究。", "summary": "本文提出了一种创新的无监督多图匹配方法，该方法利用循环一致性进行自监督学习，并通过贝叶斯优化优化高斯参数，实现了高效且可扩展的细胞标注。该方法在秀丽隐杆线虫的3D显微图像语义细胞标注中，无需任何人工标注即可达到与先进有监督方法相同的精度，并首次构建了其无监督细胞图谱，有效解决了大型显微数据集标注的瓶颈。该技术有望推广到其他模式生物的细胞图谱构建。", "keywords": "无监督学习, 多图匹配, 循环一致性, 秀丽隐杆线虫, 细胞标注", "comments": "这项工作通过引入循环一致性作为自监督损失和贝叶斯优化来确定高斯参数，为无监督多图匹配提供了一个新颖且高效的解决方案。其主要创新在于无需任何地面真值标注即可构建高精度的细胞图谱，尤其是在生物医学领域具有重要意义，解决了当前显微图像分析中的一个关键瓶颈。该方法不仅在秀丽隐杆线虫上取得了与有监督方法媲美的结果，还具有推广到其他模式生物的潜力，有望加速相关生物医学研究。"}}
{"id": "2507.13639", "title": "Differential Privacy in Kernelized Contextual Bandits via Random Projections", "authors": ["Nikola Pavlovic", "Sudeep Salgia", "Qing Zhao"], "categories": ["stat.ML", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13639v1", "summary": "We consider the problem of contextual kernel bandits with stochastic\ncontexts, where the underlying reward function belongs to a known Reproducing\nKernel Hilbert Space. We study this problem under an additional constraint of\nDifferential Privacy, where the agent needs to ensure that the sequence of\nquery points is differentially private with respect to both the sequence of\ncontexts and rewards. We propose a novel algorithm that achieves the\nstate-of-the-art cumulative regret of\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$\nand\n$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$\nover a time horizon of $T$ in the joint and local models of differential\nprivacy, respectively, where $\\gamma_T$ is the effective dimension of the\nkernel and $\\varepsilon_{\\mathrm{DP}} > 0$ is the privacy parameter. The key\ningredient of the proposed algorithm is a novel private kernel-ridge regression\nestimator which is based on a combination of private covariance estimation and\nprivate random projections. It offers a significantly reduced sensitivity\ncompared to its classical counterpart while maintaining a high prediction\naccuracy, allowing our algorithm to achieve the state-of-the-art performance\nguarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13639v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "通过随机投影实现核化上下文强盗中的差分隐私", "tldr": "本文提出了一种新颖的算法，通过私有核岭回归估计器，在差分隐私约束下的核化上下文强盗问题中，实现了最先进的累积遗憾界限。", "motivation": "在核化上下文强盗问题中，需要额外满足差分隐私约束，即代理需要确保查询点序列对上下文序列和奖励序列都满足差分隐私。", "method": "提出了一种新颖的算法，其核心是一个基于私有协方差估计和私有随机投影相结合的私有核岭回归估计器。", "result": "在联合和局部差分隐私模型下，分别实现了$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$和$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$的最先进累积遗憾界限，其中$\\gamma_T$是核的有效维度，$\\varepsilon_{\\mathrm{DP}} > 0$是隐私参数。", "conclusion": "该算法通过提出的私有核岭回归估计器，在差分隐私核化上下文强盗问题中实现了最先进的性能保证。", "translation": "我们考虑具有随机上下文的上下文核强盗问题，其中潜在的奖励函数属于已知的再生核希尔伯特空间。我们在差分隐私的额外约束下研究了这个问题，其中代理需要确保查询点序列对上下文序列和奖励序列都满足差分隐私。我们提出了一种新颖的算法，在时间范围$T$内，分别在差分隐私的联合和局部模型中，实现了最先进的累积遗憾界限，即$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T}{\\varepsilon_{\\mathrm{DP}}})$和$\\widetilde{\\mathcal{O}}(\\sqrt{\\gamma_TT}+\\frac{\\gamma_T\\sqrt{T}}{\\varepsilon_{\\mathrm{DP}}})$，其中$\\gamma_T$是核的有效维度，$\\varepsilon_{\\mathrm{DP}} > 0$是隐私参数。所提出算法的关键组成部分是一个新颖的私有核岭回归估计器，它基于私有协方差估计和私有随机投影的结合。与经典的对应方法相比，它显著降低了敏感性，同时保持了高预测精度，从而使我们的算法能够实现最先进的性能保证。", "summary": "本文研究了在差分隐私约束下的随机上下文核强盗问题。作者提出了一种新算法，其核心是结合了私有协方差估计和私有随机投影的私有核岭回归估计器。该估计器在降低敏感性的同时保持了高预测精度。结果表明，该算法在联合和局部差分隐私模型中均达到了最先进的累积遗憾界限。", "keywords": "差分隐私, 核化上下文强盗, 随机投影, 核岭回归, 累积遗憾", "comments": "这篇论文的创新点在于提出了一个基于私有协方差估计和私有随机投影的私有核岭回归估计器，有效解决了差分隐私在核化上下文强盗问题中的应用挑战。通过降低敏感性同时保持预测精度，该方法在保证隐私的同时实现了优异的性能，具有重要的理论和实践意义。"}}
{"id": "2507.13933", "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "Comments:      In submission. 2 pages. 3 figures", "url": "http://arxiv.org/abs/2507.13933v1", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.", "comment": "In submission. 2 pages. 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.13933v1", "cate": "cs.NI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "预印本：我刚刚浏览了一个由大型语言模型（LLM）编写的网站吗？", "tldr": "本文开发了一种高度准确的检测器，用于识别由大型语言模型（LLM）主导生成的网站内容，发现此类网站日益普遍且在搜索结果中排名靠前，引发了对信息可靠性的担忧。", "motivation": "当前网络内容中，由大型语言模型（LLM）自动生成且人类输入极少的内容（即“LLM主导”内容）日益增多。由于LLM可能抄袭和产生幻觉，此类内容可能不可靠且不道德，但网站很少披露，人类读者也难以区分。现有的LLM检测器主要在干净、散文式文本上表现良好，而对包含复杂标记和多样体裁的网络内容则不足。因此，需要开发可靠的LLM主导内容检测器。", "method": "本文提出了一种高度可靠、可扩展的管道，用于对整个网站进行分类。该方法不简单地分类从每个页面提取的文本，而是基于LLM文本检测器对多个散文式页面的输出，对每个网站进行分类。研究人员通过收集总计120个网站的两个不同真实数据集来训练和评估其检测器。", "result": "该检测器在两个真实数据集上测试时达到了100%的准确率。在实际应用中，研究人员在1万个搜索引擎结果网站和1万个Common Crawl存档网站中，检测到相当一部分网站是LLM主导的。研究发现，LLM主导网站的普及率正在增长，并且在搜索结果中排名很高。", "conclusion": "LLM主导网站的日益普及和在搜索结果中的高排名，引发了关于它们对最终用户和整个网络生态系统影响的问题。", "translation": "摘要：\n网络内容越来越多地由大型语言模型（LLM）自动生成，而人工输入很少。我们称之为“LLM主导”内容。由于LLM会抄袭和产生幻觉，LLM主导内容可能不可靠且不道德。然而，网站很少披露此类内容，人类读者也很难区分。因此，我们必须开发可靠的LLM主导内容检测器。然而，最先进的LLM检测器是不够的，因为它们主要在干净、散文式的文本上表现良好，而网络内容具有复杂的标记和多样的体裁。\n我们提出了一种高度可靠、可扩展的管道，用于对整个网站进行分类。我们不简单地分类从每个页面提取的文本，而是根据LLM文本检测器对多个散文式页面的输出，对每个网站进行分类。我们通过收集总计120个网站的2个不同真实数据集来训练和评估我们的检测器，并在其间测试时获得了100%的准确率。在实际应用中，我们在1万个搜索引擎结果网站和1万个Common Crawl存档网站中，检测到相当一部分网站是LLM主导的。我们发现LLM主导网站的普及率正在增长，并且在搜索结果中排名很高，这引发了关于它们对最终用户和整个网络生态系统影响的问题。", "summary": "该论文旨在解决大型语言模型（LLM）生成网络内容日益增多且难以识别的问题。由于LLM生成的内容可能不可靠且未披露，且现有检测器不适用于复杂的网络结构，作者提出了一种可靠且可扩展的网站级检测管道。该方法通过分析LLM文本检测器对网站内多个散文式页面的输出，而非简单地检测单个页面。在120个网站的真实数据集上，该检测器实现了100%的准确率。大规模测试（2万个网站）显示，LLM主导的网站数量庞大，且在搜索结果中排名靠前，这引发了对信息可靠性和网络生态系统健康的重要担忧。", "keywords": "LLM主导内容, 网络内容检测, 大型语言模型, 网站分类, 信息可靠性", "comments": "本文的创新之处在于其从页面级检测转向网站级分类的方法，这对于处理复杂多样的网络内容更为鲁棒和有效。100%的测试准确率令人印象深刻，突显了该方法的潜力。这项研究揭示了一个关键且日益增长的问题，即LLM生成内容对网络信息可靠性和搜索引擎完整性的潜在影响，具有重要的现实意义。"}}
{"id": "2507.13959", "title": "Signs of the Past, Patterns of the Present: On the Automatic Classification of Old Babylonian Cuneiform Signs", "authors": ["Eli Verwimp", "Gustav Ryberg Smidt", "Hendrik Hameeuw", "Katrien De Graef"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Paper under review at JOCCH", "url": "http://arxiv.org/abs/2507.13959v1", "summary": "The work in this paper describes the training and evaluation of machine\nlearning (ML) techniques for the classification of cuneiform signs. There is a\nlot of variability in cuneiform signs, depending on where they come from, for\nwhat and by whom they were written, but also how they were digitized. This\nvariability makes it unlikely that an ML model trained on one dataset will\nperform successfully on another dataset. This contribution studies how such\ndifferences impact that performance. Based on our results and insights, we aim\nto influence future data acquisition standards and provide a solid foundation\nfor future cuneiform sign classification tasks. The ML model has been trained\nand tested on handwritten Old Babylonian (c. 2000-1600 B.C.E.) documentary\ntexts inscribed on clay tablets originating from three Mesopotamian cities\n(Nippur, D\\=ur-Abie\\v{s}uh and Sippar). The presented and analysed model is\nResNet50, which achieves a top-1 score of 87.1% and a top-5 score of 96.5% for\nsigns with at least 20 instances. As these automatic classification results are\nthe first on Old Babylonian texts, there are currently no comparable results.", "comment": "Paper under review at JOCCH", "pdf_url": "http://arxiv.org/pdf/2507.13959v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "过去之符号，现在之模式：论古巴比伦楔形文字符号的自动分类", "tldr": "本文训练并评估了机器学习技术对古巴比伦楔形文字符号进行分类，并研究了数据变异性对其性能的影响。", "motivation": "楔形文字符号的巨大变异性（取决于来源、书写目的、书写者及数字化方式）使得在一个数据集上训练的机器学习模型难以在另一个数据集上成功运行。本文旨在研究这些差异如何影响模型性能，并基于研究结果和见解，为未来的数据采集标准和楔形文字符号分类任务提供坚实基础。", "method": "本文训练并评估了机器学习（ML）技术用于楔形文字符号的分类。该ML模型（ResNet50）在来自美索不达米亚三个城市（尼普尔、杜尔-阿比舒赫和西帕尔）的泥板上书写的古巴比伦（约公元前2000-1600年）文献手稿上进行了训练和测试。", "result": "所呈现和分析的模型是ResNet50，对于至少有20个实例的符号，其Top-1准确率达到87.1%，Top-5准确率达到96.5%。这些自动分类结果是首次在古巴比伦文本上获得，目前尚无可比较的结果。", "conclusion": "本文首次对古巴比伦文本进行了自动分类，并获得了可观的准确率。虽然目前尚无可比较的结果，但研究结果和见解旨在影响未来的数据采集标准，并为未来的楔形文字符号分类任务奠定基础。", "translation": "本文描述了机器学习（ML）技术在楔形文字符号分类方面的训练和评估工作。楔形文字符号存在很大的变异性，这取决于它们的来源、书写目的、书写者以及数字化方式。这种变异性使得在一个数据集上训练的ML模型不太可能在另一个数据集上成功运行。本文研究了这些差异如何影响性能。基于我们的结果和见解，我们旨在影响未来的数据采集标准，并为未来的楔形文字符号分类任务提供坚实的基础。该ML模型已在来自美索不达米亚三个城市（尼普尔、杜尔-阿比舒赫和西帕尔）的泥板上书写的古巴比伦（约公元前2000-1600年）文献手稿上进行了训练和测试。所呈现和分析的模型是ResNet50，对于至少有20个实例的符号，其Top-1准确率达到87.1%，Top-5准确率达到96.5%。由于这些自动分类结果是首次在古巴比伦文本上获得，目前尚无可比较的结果。", "summary": "本文研究了机器学习技术在古巴比伦楔形文字符号自动分类中的应用，并探讨了数据变异性对模型性能的影响。研究使用ResNet50模型对来自三个美索不达米亚城市泥板上的手写古巴比伦文本进行训练和测试，取得了87.1%的Top-1和96.5%的Top-5准确率（针对至少20个实例的符号）。作为古巴比伦文本上的首次自动分类尝试，本研究旨在为未来的数据采集标准和分类任务奠定基础。", "keywords": "楔形文字, 自动分类, 机器学习, 古巴比伦, ResNet50", "comments": "本文的创新之处在于首次实现了古巴比伦楔形文字符号的自动分类，填补了该领域的空白。其重要性在于，通过揭示数据变异性对机器学习性能的影响，为未来楔形文字数据采集标准的制定提供了宝贵的见解，有助于推动数字人文学科的发展。局限性在于，目前尚无可比较的结果来全面评估其性能，需要未来研究进行更广泛的验证和对比。"}}
{"id": "2507.13985", "title": "DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation", "authors": ["Haoran Li", "Yuli Tian", "Kun Lan", "Yong Liao", "Lin Wang", "Pan Hui", "Peng Yuan Zhou"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Extended version of ECCV 2024 paper \"DreamScene\"", "url": "http://arxiv.org/abs/2507.13985v1", "summary": "Generating 3D scenes from natural language holds great promise for\napplications in gaming, film, and design. However, existing methods struggle\nwith automation, 3D consistency, and fine-grained control. We present\nDreamScene, an end-to-end framework for high-quality and editable 3D scene\ngeneration from text or dialogue. DreamScene begins with a scene planning\nmodule, where a GPT-4 agent infers object semantics and spatial constraints to\nconstruct a hybrid graph. A graph-based placement algorithm then produces a\nstructured, collision-free layout. Based on this layout, Formation Pattern\nSampling (FPS) generates object geometry using multi-timestep sampling and\nreconstructive optimization, enabling fast and realistic synthesis. To ensure\nglobal consistent, DreamScene employs a progressive camera sampling strategy\ntailored to both indoor and outdoor settings. Finally, the system supports\nfine-grained scene editing, including object movement, appearance changes, and\n4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior\nmethods in quality, consistency, and flexibility, offering a practical solution\nfor open-domain 3D content creation. Code and demos are available at\nhttps://dreamscene-project.github.io.", "comment": "Extended version of ECCV 2024 paper \"DreamScene\"", "pdf_url": "http://arxiv.org/pdf/2507.13985v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DreamScene：基于3D高斯模型的端到端文本到3D场景生成", "tldr": "DreamScene是一个端到端框架，利用GPT-4规划、图形放置算法和多时间步采样，实现高质量、可编辑的基于文本的3D场景生成，解决了现有方法的自动化、3D一致性和精细控制问题。", "motivation": "现有的从自然语言生成3D场景的方法在自动化、3D一致性和精细控制方面存在不足。", "method": "DreamScene框架包含几个模块：1. 场景规划模块：GPT-4代理推断对象语义和空间约束，构建混合图。2. 基于图的放置算法：生成结构化、无冲突的布局。3. 形成模式采样（FPS）：利用多时间步采样和重建优化生成对象几何体。4. 渐进式相机采样策略：确保全局一致性。5. 支持精细场景编辑：包括对象移动、外观变化和4D动态运动。", "result": "DreamScene在质量、一致性和灵活性方面超越了现有方法，为开放域3D内容创建提供了实用解决方案。", "conclusion": "DreamScene通过其创新的端到端框架，成功解决了文本到3D场景生成中的关键挑战，实现了高质量、一致且可编辑的场景创建，展示了其在实际应用中的巨大潜力。", "translation": "从自然语言生成3D场景在游戏、电影和设计等应用中具有广阔前景。然而，现有方法在自动化、3D一致性和精细控制方面存在困难。我们提出了DreamScene，一个端到端框架，用于从文本或对话生成高质量和可编辑的3D场景。DreamScene首先通过场景规划模块，其中GPT-4代理推断对象语义和空间约束以构建混合图。然后，基于图的放置算法生成结构化、无冲突的布局。在此布局的基础上，形成模式采样（FPS）利用多时间步采样和重建优化生成对象几何体，实现快速逼真的合成。为确保全局一致性，DreamScene采用了一种针对室内外环境量身定制的渐进式相机采样策略。最后，该系统支持精细的场景编辑，包括对象移动、外观变化和4D动态运动。实验表明，DreamScene在质量、一致性和灵活性方面超越了现有方法，为开放域3D内容创建提供了实用解决方案。代码和演示可在https://dreamscene-project.github.io获取。", "summary": "DreamScene是一个创新的端到端框架，旨在解决从文本生成3D场景时现有方法面临的自动化、3D一致性和精细控制问题。它通过结合GPT-4进行场景规划、基于图的放置算法生成布局、形成模式采样（FPS）进行快速几何体合成，以及渐进式相机采样策略确保全局一致性。此外，DreamScene还支持精细的场景编辑功能。实验证明，该系统在质量、一致性和灵活性上均优于现有方法，为开放域3D内容创作提供了一个实用且高性能的解决方案。", "keywords": "3D场景生成, 文本到3D, 3D高斯, 端到端, GPT-4", "comments": "DreamScene的创新之处在于其端到端的集成方法，特别是结合了大型语言模型（GPT-4）进行高级场景规划，以及基于3D高斯模型的几何体生成。这种结合解决了3D场景生成中的复杂性和一致性挑战，为游戏、电影和设计等领域提供了强大的工具。其支持精细编辑和4D动态运动的能力也显著增强了实用性。"}}
{"id": "2503.04800", "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation", "authors": ["Jie Ouyang", "Tingyue Pan", "Mingyue Cheng", "Ruiran Yan", "Yucong Luo", "Jiaying Lin", "Qi Liu"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.04800v3", "summary": "While Retrieval-Augmented Generation (RAG) has emerged as an effective\napproach for addressing the knowledge outdating problem in Large Language\nModels (LLMs), it still faces a critical challenge: the prevalence of outdated\ninformation in knowledge bases. Current research primarily focuses on\nincorporating up-to-date information, yet the impact of outdated information\ncoexisting in retrieval sources remains inadequately addressed. To bridge this\ngap, we introduce HoH, the first benchmark specifically designed to evaluate\nthe impact of outdated information on RAG. Our benchmark leverages token-level\ndiff algorithms combined with LLM pipelines to efficiently create a large-scale\nQA dataset that accurately captures the evolution of temporal knowledge in\nreal-world facts. Through comprehensive experiments, we reveal that outdated\ninformation significantly degrades RAG performance in two critical ways: (1) it\nsubstantially reduces response accuracy by distracting models from correct\ninformation, and (2) it can mislead models into generating potentially harmful\noutputs, even when current information is available. Current RAG approaches\nstruggle with both retrieval and generation aspects when handling outdated\ninformation. These findings highlight the urgent need for innovative solutions\nto address the temporal challenges in RAG. Our code and data are available at:\nhttps://github.com/0russwest0/HoH.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.04800v3", "cate": "cs.CL", "date": "2025-03-03", "updated": "2025-07-18", "AI": {"title_translation": "HoH：一个评估过时信息对检索增强生成影响的动态基准", "tldr": "HoH是一个新的基准，用于评估知识库中过时信息对RAG性能的负面影响，发现它会降低准确性并可能导致有害输出。", "motivation": "尽管RAG能解决LLM的知识过时问题，但知识库中普遍存在的过时信息仍是一个挑战。当前研究主要关注纳入最新信息，而过时信息在检索源中并存的影响尚未得到充分解决。", "method": "本文引入了HoH，这是第一个专门用于评估过时信息对RAG影响的基准。该基准利用token级差异算法结合LLM管道，高效地创建了一个大规模的QA数据集，准确捕捉真实世界事实中时间知识的演变。", "result": "综合实验表明，过时信息会以两种关键方式显著降低RAG性能：(1) 通过分散模型对正确信息的注意力，大幅降低响应准确性；(2) 即使有最新信息，也可能误导模型生成潜在有害的输出。", "conclusion": "当前的RAG方法在处理过时信息时，在检索和生成方面都面临困难。这些发现强调了迫切需要创新的解决方案来应对RAG中的时间挑战。", "translation": "虽然检索增强生成（RAG）已成为解决大型语言模型（LLM）中知识过时问题的有效方法，但它仍然面临一个关键挑战：知识库中普遍存在的过时信息。当前研究主要侧重于整合最新信息，然而，检索源中过时信息并存的影响尚未得到充分解决。为了弥补这一空白，我们引入了HoH，这是第一个专门设计用于评估过时信息对RAG影响的基准。我们的基准利用令牌级差异算法结合LLM管道，高效地创建了一个大规模的问答数据集，该数据集准确捕捉了真实世界事实中时间知识的演变。通过全面的实验，我们揭示了过时信息以两种关键方式显著降低RAG性能：(1) 它通过分散模型对正确信息的注意力，大幅降低响应准确性；(2) 即使有当前信息，它也可能误导模型生成潜在有害的输出。当前的RAG方法在处理过时信息时，在检索和生成方面都面临困难。这些发现强调了迫切需要创新的解决方案来应对RAG中的时间挑战。我们的代码和数据可在以下网址获取：https://github.com/0russwest0/HoH。", "summary": "该研究介绍了HoH，一个新颖的动态基准，旨在评估知识库中过时信息对检索增强生成（RAG）性能的影响。通过结合token级差异算法和LLM管道，HoH创建了一个大规模QA数据集，模拟了真实世界知识的演变。实验结果表明，过时信息会显著降低RAG的响应准确性，并可能导致模型生成有害内容，即使存在最新信息。这揭示了当前RAG方法在处理时间敏感信息时的局限性，并强调了开发新解决方案的紧迫性。", "keywords": "检索增强生成, 过时信息, 基准, 大型语言模型, 时间挑战", "comments": "这项工作具有重要意义，因为它首次专门关注并量化了知识库中“过时信息”对RAG系统的负面影响，而此前研究多侧重于引入新信息。HoH基准的创新之处在于其通过结合token级diff算法和LLM管道来高效生成大规模、具有时间演变特征的QA数据集。其发现揭示了RAG在处理时间性挑战时的深层问题，为未来RAG研究指明了新的方向。"}}
{"id": "2507.13814", "title": "CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education", "authors": ["Jianing Zhao", "Peng Gao", "Jiannong Cao", "Zhiyuan Wen", "Chen Chen", "Jianing Yin", "Ruosong Yang", "Bo Yuan"], "categories": ["cs.MA"], "primary_category": "Subjects:       Multiagent Systems (cs.MA)", "pdf_link": null, "comments": "Comments:      4 pages, 4 figures. Demo video available at: this https URL", "url": "http://arxiv.org/abs/2507.13814v1", "summary": "Large Language Models (LLMs) have demonstrated considerable potential in\nimproving coding education by providing support for code writing, explanation,\nand debugging. However, existing LLM-based approaches generally fail to assess\nstudents' abilities, design learning plans, provide personalized material\naligned with individual learning goals, and enable interactive learning.\nCurrent work mostly uses single LLM agents, which limits their ability to\nunderstand complex code repositories and schedule step-by-step tutoring. Recent\nresearch has shown that multi-agent LLMs can collaborate to solve complicated\nproblems in various domains like software engineering, but their potential in\nthe field of education remains unexplored. In this work, we introduce CodeEdu,\nan innovative multi-agent collaborative platform that combines LLMs with tool\nuse to provide proactive and personalized education in coding. Unlike static\npipelines, CodeEdu dynamically allocates agents and tasks to meet student\nneeds. Various agents in CodeEdu undertake certain functions specifically,\nincluding task planning, personalized material generation, real-time QA,\nstep-by-step tutoring, code execution, debugging, and learning report\ngeneration, facilitated with extensive external tools to improve task\nefficiency. Automated evaluations reveal that CodeEdu substantially enhances\nstudents' coding performance.", "comment": "4 pages, 4 figures. Demo video available at:\n  https://youtu.be/9iIVmTT4CVk", "pdf_url": "http://arxiv.org/pdf/2507.13814v1", "cate": "cs.MA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CodeEdu：一个用于个性化编程教育的多智能体协作平台", "tldr": "CodeEdu是一个多智能体协作平台，结合大型语言模型和工具使用，为学生提供主动和个性化的编程教育，解决了现有LLM方法在评估学生能力、设计学习计划和个性化教学方面的不足，并显著提升了学生的编程表现。", "motivation": "现有基于大型语言模型（LLMs）的编程教育方法普遍无法评估学生能力、设计学习计划、提供个性化材料以及实现互动学习。目前的工作多采用单一LLM智能体，限制了其理解复杂代码库和安排逐步辅导的能力。尽管多智能体LLMs在软件工程等领域展示了解决复杂问题的潜力，但在教育领域的潜力尚未被探索。", "method": "我们引入了CodeEdu，一个创新的多智能体协作平台，它将LLMs与工具使用相结合，提供主动和个性化编程教育。CodeEdu动态分配智能体和任务以满足学生需求。各种智能体承担特定功能，包括任务规划、个性化材料生成、实时问答、逐步辅导、代码执行、调试和学习报告生成，并辅以广泛的外部工具以提高任务效率。", "result": "自动化评估显示，CodeEdu显著提高了学生的编程表现。", "conclusion": "CodeEdu通过其多智能体协作平台和工具使用，成功解决了现有LLM在编程教育中的局限性，并有效提升了学生的编程能力。", "translation": "大型语言模型（LLMs）在通过提供代码编写、解释和调试支持来改进编程教育方面展现出巨大的潜力。然而，现有的基于LLM的方法通常无法评估学生的能力、设计学习计划、提供与个人学习目标一致的个性化材料，以及实现互动学习。目前的工作大多使用单一LLM智能体，这限制了它们理解复杂代码库和安排逐步辅导的能力。最近的研究表明，多智能体LLMs可以协作解决软件工程等各种领域的复杂问题，但它们在教育领域的潜力仍未被探索。在这项工作中，我们引入了CodeEdu，一个创新的多智能体协作平台，它将LLMs与工具使用相结合，提供主动和个性化的编程教育。与静态管道不同，CodeEdu动态分配智能体和任务以满足学生需求。CodeEdu中的各种智能体专门承担某些功能，包括任务规划、个性化材料生成、实时问答、逐步辅导、代码执行、调试和学习报告生成，并辅以广泛的外部工具以提高任务效率。自动化评估表明，CodeEdu显著提高了学生的编程表现。", "summary": "CodeEdu是一个创新的多智能体协作平台，旨在通过结合大型语言模型（LLMs）和工具使用，提供个性化和主动的编程教育。它解决了现有LLM在编程教育中评估学生能力、设计学习计划和提供个性化内容方面的不足。CodeEdu通过动态分配任务和使用专门的智能体（如任务规划、材料生成、实时问答、调试等）来实现这一目标，并利用外部工具提高效率。自动化评估结果表明，CodeEdu显著提升了学生的编程表现。", "keywords": "多智能体, 编程教育, 个性化学习, 大型语言模型, 工具使用", "comments": "CodeEdu的创新之处在于其多智能体协作架构，这与当前多数单一LLM代理的教育应用形成了对比。它通过动态任务分配和专业化智能体的设计，提供了更全面和个性化的编程教育体验。结合外部工具的使用，进一步增强了其实用性和效率。这项工作强调了多智能体系统在教育领域未被充分探索的潜力，并为未来基于LLM的教育平台发展提供了新的方向。"}}
{"id": "2507.13464", "title": "Round-Preserving Asymptotic Compression of Prior-Free Interactive Protocols", "authors": ["Gurleen Padda", "Dave Touchette"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13464v1", "summary": "There is a close relationship between the communication complexity and\ninformation complexity of communication problems, as demonstrated by results\nsuch as Shannon's noiseless source coding theorem, and the Slepian-Wolf\ntheorem. Here, we study this relationship in the prior-free and interactive\nsetting, where we provide an alternate proof for the result of Braverman [SIAM\nReview, vol. 59, no. 4, 2017], that the amortized communication complexity of\nsimulating a prior-free interactive communication protocol, is equal to its\nprior-free information cost. While this is a known result, our approach\naddresses the need for a more natural proof of it. We also improve on the\nresult by achieving round preservation, and using a bounded quantity of shared\nrandomness. We do this by showing that the communicating parties can produce a\nreliable estimate of the joint type, or empirical distribution, of their\ninputs. This estimate is then used in our protocol for the prior-free reverse\nShannon theorem with side information at the receiver. These results are then\ngeneralized to the interactive setting to obtain our main result.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13464v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "轮次保持的无先验交互式协议渐近压缩", "tldr": "本文为无先验交互式协议中摊销通信复杂度和无先验信息成本相等的已知结果提供了一种更自然的证明，并实现了轮次保持和有限共享随机性。", "motivation": "本文旨在为Braverman关于无先验交互式通信协议的摊销通信复杂性等于其无先验信息成本的结果提供一个更自然的替代证明，并在此基础上通过实现轮次保持和使用有限数量的共享随机性进行改进。", "method": "作者通过证明通信双方可以生成其输入联合类型（或经验分布）的可靠估计来实现。该估计被用于一个带有接收方旁信息的无先验逆香农定理协议中，然后将这些结果推广到交互式设置以获得主要结果。", "result": "本文提供了一个更自然的Braverman结果的证明。他们还通过实现轮次保持和使用有限数量的共享随机性，对现有结果进行了改进。", "conclusion": "本文成功提供了一种更自然、轮次保持的无先验交互式协议渐近压缩方法，并证实和扩展了通信复杂性与信息成本之间的关系。", "translation": "通信问题的通信复杂度和信息复杂性之间存在着密切关系，正如香农无噪声信源编码定理和Slepian-Wolf定理等结果所证明的那样。在此，我们研究了在无先验和交互式设置中的这种关系，我们为Braverman的结果[SIAM Review, vol. 59, no. 4, 2017]提供了一个替代证明，即模拟无先验交互式通信协议的摊销通信复杂性等于其无先验信息成本。虽然这是一个已知的结果，但我们的方法解决了对该结果更自然证明的需求。我们还通过实现轮次保持和使用有限数量的共享随机性来改进结果。我们通过证明通信双方可以生成其输入联合类型或经验分布的可靠估计来实现这一点。然后，该估计被用于我们为接收方带有旁信息的无先验逆香农定理设计的协议中。这些结果随后被推广到交互式设置，以获得我们的主要结果。", "summary": "本文研究了无先验和交互式设置中通信复杂度和信息复杂性之间的关系。作者为Braverman的一个已知结果（即无先验交互式协议的摊销通信复杂性等于其无先验信息成本）提供了一个更自然的替代证明。此外，本文通过实现轮次保持和使用有限的共享随机性对该结果进行了改进。这通过通信方生成其输入联合类型的可靠估计来实现，并将其应用于带有接收方旁信息的无先验逆香农定理协议，最终推广到交互式设置。", "keywords": "通信复杂性, 信息成本, 交互式协议, 轮次保持, 无先验", "comments": "本文的创新之处在于为已知结果提供了一个“更自然”的证明，并引入了“轮次保持”和“有限共享随机性”这两个重要的实际改进。这对于无先验交互式协议的理论和实践都具有重要意义，加深了对通信和信息复杂性关系的理解。"}}
{"id": "2507.13628", "title": "Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation", "authors": ["Masahiro Ogawa", "Qi An", "Atsushi Yamashita"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 15 figures, RA-L submission", "url": "http://arxiv.org/abs/2507.13628v1", "summary": "Separating moving and static objects from a moving camera viewpoint is\nessential for 3D reconstruction, autonomous navigation, and scene understanding\nin robotics. Existing approaches often rely primarily on optical flow, which\nstruggles to detect moving objects in complex, structured scenes involving\ncamera motion. To address this limitation, we propose Focus of Expansion\nLikelihood and Segmentation (FoELS), a method based on the core idea of\nintegrating both optical flow and texture information. FoELS computes the focus\nof expansion (FoE) from optical flow and derives an initial motion likelihood\nfrom the outliers of the FoE computation. This likelihood is then fused with a\nsegmentation-based prior to estimate the final moving probability. The method\neffectively handles challenges including complex structured scenes, rotational\ncamera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016\ndataset and real-world traffic videos demonstrate its effectiveness and\nstate-of-the-art performance.", "comment": "8 pages, 15 figures, RA-L submission", "pdf_url": "http://arxiv.org/pdf/2507.13628v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于膨胀焦点似然和分割的运动相机运动物体检测", "tldr": "FoELS是一种结合光流和纹理信息的方法，用于从运动相机中检测运动物体，有效解决了传统光流方法在复杂场景下的局限性，并在多个挑战性场景下表现出最先进的性能。", "motivation": "从运动相机视角分离运动和静态物体对于机器人技术中的三维重建、自主导航和场景理解至关重要。现有方法主要依赖光流，但在涉及相机运动的复杂、结构化场景中难以检测运动物体。", "method": "本文提出了一种名为膨胀焦点似然和分割（FoELS）的方法，其核心思想是整合光流和纹理信息。FoELS从光流计算膨胀焦点（FoE），并从FoE计算的异常值中导出初始运动似然。然后，将该似然与基于分割的先验融合，以估计最终的运动概率。", "result": "该方法有效处理了包括复杂结构化场景、旋转相机运动和平行运动在内的挑战。在DAVIS 2016数据集和真实世界交通视频上的综合评估证明了其有效性和最先进的性能。", "conclusion": "FoELS方法通过整合光流和纹理信息，有效解决了运动相机下运动物体检测的挑战，特别是在复杂场景和多种相机运动情况下表现出色，达到了最先进的性能。", "translation": "从运动相机视角分离运动和静态物体对于机器人技术中的三维重建、自主导航和场景理解至关重要。现有方法通常主要依赖光流，但在涉及相机运动的复杂、结构化场景中难以检测运动物体。为了解决这一局限性，我们提出了一种名为膨胀焦点似然和分割（FoELS）的方法，其核心思想是整合光流和纹理信息。FoELS从光流计算膨胀焦点（FoE），并从FoE计算的异常值中导出初始运动似然。然后，将该似然与基于分割的先验融合，以估计最终的运动概率。该方法有效处理了包括复杂结构化场景、旋转相机运动和平行运动在内的挑战。在DAVIS 2016数据集和真实世界交通视频上的综合评估证明了其有效性和最先进的性能。", "summary": "本文提出了一种名为FoELS的新方法，用于从运动相机中检测运动物体。该方法通过整合光流和纹理信息，克服了传统光流方法在复杂场景中的局限性。FoELS通过计算膨胀焦点（FoE）并从其异常值中获取初始运动似然，然后将其与基于分割的先验融合以估计最终的运动概率。实验证明，FoELS在处理复杂结构化场景、旋转相机运动和平行运动方面表现出色，并在DAVIS 2016数据集和真实交通视频上达到了最先进的性能。", "keywords": "运动物体检测, 运动相机, 膨胀焦点, 光流, 图像分割", "comments": "该论文的创新点在于将光流（特别是FoE异常值）与基于分割的先验相结合，以实现从运动相机中对运动物体进行鲁棒检测，这是一个具有挑战性的任务。其处理复杂场景和各种相机运动的能力是该领域的一个重要进步。"}}
{"id": "2504.04287", "title": "Cyber Insurance Design for Load Variation and Load Curtailment in Distribution Grids", "authors": ["Shijie Pan", "Zaint A. Alexakis", "S Subhash Lakshminarayana", "Charalambos Konstantinou"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.04287v2", "summary": "Uncertainties in renewable energy resources (RES) and load variations can\nlead to elevated system operational costs. Moreover, the emergence of\nlarge-scale distributed threats, such as load-altering attacks (LAAs), can\ninduce substantial load variations, further exacerbating these costs. Although\ntraditional defense measures can reduce the likelihood of such attacks,\nconsiderable residual risks remain. Thus, this paper proposes a cyber insurance\nframework designed to hedge against additional operational costs resulting from\nLAAs and substantial load variations in renewable-rich grids. The insurance\nframework determines both the insurance coverage and premium based on the Value\nat Risk (VaR) and Tail Value at Risk (TVaR). These risk metrics are calculated\nusing the system failure probability and the probability density function (PDF)\nof the system operation cost. The system failure probability is assessed\nthrough a semi-Markov process (SMP), while the cost distribution is estimated\nthrough a cost minimization model of a distribution grid combined with a\nMonte-Carlo simulation to capture load variability. Furthermore, we employ a\nbi-level optimization scheme that identifies the specific load distribution\nleading to the maximum system cost, thereby enhancing the accuracy of the\noperation cost PDF estimation. The effectiveness and scalability of the\nproposed cyber insurance policy are evaluated considering a modified IEEE-118\ntest bus system and the IEEE European low-voltage (LV) test feeders model. The\ncase study shows that with a relatively low premium, the network operator can\nhedge against additional operational costs caused by malicious load\nmanipulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.04287v2", "cate": "eess.SY", "date": "2025-04-05", "updated": "2025-07-18", "AI": {"title_translation": "配电网中负荷波动和负荷削减的网络保险设计", "tldr": "本文提出了一种网络保险框架，旨在对冲可再生能源丰富电网中因负荷改变攻击和显著负荷波动导致的额外运营成本。", "motivation": "可再生能源资源的不确定性和负荷波动会导致系统运营成本升高。大规模分布式威胁（如负荷改变攻击，LAAs）会引起显著负荷波动，进一步加剧这些成本。尽管传统防御措施能降低攻击可能性，但仍存在显著的残余风险。", "method": "本文提出一个网络保险框架，基于风险价值（VaR）和尾部风险价值（TVaR）确定保险覆盖范围和保费。风险指标通过系统故障概率和系统运营成本的概率密度函数（PDF）计算。系统故障概率通过半马尔可夫过程（SMP）评估，成本分布通过配电网成本最小化模型结合蒙特卡洛模拟估算。此外，采用双层优化方案识别导致最大系统成本的特定负荷分布，以提高运营成本PDF估算的准确性。", "result": "通过修改后的IEEE-118测试总线系统和IEEE欧洲低压（LV）测试馈线模型评估了所提出网络保险策略的有效性和可扩展性。案例研究表明，以相对较低的保费，网络运营商可以对冲恶意负荷操纵引起的额外运营成本。", "conclusion": "本文提出的网络保险框架，通过基于VaR和TVaR的精算模型，能有效帮助网络运营商以较低保费对冲由负荷改变攻击和负荷波动引起的额外运营成本。", "translation": "可再生能源（RES）和负荷波动的不确定性可能导致系统运营成本升高。此外，大规模分布式威胁（例如负荷改变攻击，LAAs）的出现会引起显著的负荷波动，进一步加剧这些成本。尽管传统的防御措施可以降低此类攻击的可能性，但仍存在相当大的残余风险。因此，本文提出了一种网络保险框架，旨在对冲可再生能源丰富电网中因LAAs和显著负荷波动导致的额外运营成本。该保险框架根据风险价值（VaR）和尾部风险价值（TVaR）确定保险覆盖范围和保费。这些风险指标通过系统故障概率和系统运营成本的概率密度函数（PDF）计算。系统故障概率通过半马尔可夫过程（SMP）评估，而成本分布通过结合蒙特卡洛模拟的配电网成本最小化模型进行估算，以捕捉负荷变异性。此外，我们采用双层优化方案，识别导致最大系统成本的特定负荷分布，从而提高运营成本PDF估算的准确性。所提出的网络保险策略的有效性和可扩展性通过修改后的IEEE-118测试总线系统和IEEE欧洲低压（LV）测试馈线模型进行了评估。案例研究表明，以相对较低的保费，网络运营商可以对冲恶意负荷操纵引起的额外运营成本。", "summary": "本文针对可再生能源丰富电网中因负荷波动和负荷改变攻击（LAAs）导致的额外运营成本问题，提出了一种网络保险框架。该框架基于风险价值（VaR）和尾部风险价值（TVaR）计算保险覆盖和保费，其中风险指标的评估结合了半马尔可夫过程（SMP）和双层优化下的蒙特卡洛模拟。案例研究验证了该保险策略在对冲恶意负荷操纵引起的额外成本方面的有效性和可扩展性，表明其能以较低保费提供保障。", "keywords": "网络保险, 负荷改变攻击, 配电网, 风险价值, 半马尔可夫过程", "comments": "本文提出了一种新颖的网络保险方法，将网络安全风险与电网运营成本相结合，特别关注了负荷改变攻击。其创新之处在于结合了VaR/TVaR风险评估、半马尔可夫过程和双层优化来精确估算运营成本PDF，为电网运营商提供了一种经济有效的风险对冲工具。这对于提高电网韧性，尤其是在可再生能源高渗透的背景下，具有重要意义。"}}
{"id": "2507.13640", "title": "Interpolation in Polynomial Spaces of p-Degree", "authors": ["Phil-Alexander Hofmann", "Damar Wicaksono", "Michael Hecht"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13640v1", "summary": "We recently introduced the Fast Newton Transform (FNT), an algorithm for\nperforming multivariate Newton interpolation in downward closed polynomial\nspaces of spatial dimension $m$. In this work, we analyze the FNT in the\ncontext of a specific family of downward closed sets $A_{m,n,p}$, defined as\nall multi-indices with $\\ell^p$ norm less than $n$ with $p \\in [0,\\infty]$.\nThese sets induce the downward closed polynomial space $\\Pi_{m,n,p}$, within\nwhich the FNT algorithm achieves a time complexity of\n$\\mathcal{O}(|A_{m,n,p}|mn)$. We show that this setting, compared to tensor\nproduct spaces, yields an improvement in complexity by a factor $\\rho_{m,n,p}$,\nwhich decays super exponentially with increasing spatial dimension when $m\n\\lesssim n^p$. Additionally, we demonstrate the construction of the\nhierarchical scheme employed by the FNT and showcase its performance to compute\nactivity scores in sensitivity analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13640v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "p-度多项式空间中的插值", "tldr": "本文分析了快速牛顿变换（FNT）在特定向下封闭多项式空间中的性能，展示了其在复杂性上的显著改进，并应用于敏感性分析。", "motivation": "分析和优化最近引入的快速牛顿变换（FNT）算法在特定多项式空间中的性能，并展示其应用。", "method": "本文在由$\\ell^p$范数小于$n$的多重指标定义的特定向下封闭集$A_{m,n,p}$所诱导的多项式空间$\\Pi_{m,n,p}$中分析了快速牛顿变换（FNT）算法。研究了FNT的时间复杂度，并将其与张量积空间的复杂性进行比较。此外，还展示了FNT所采用的分层方案的构建及其在敏感性分析中计算活动分数时的性能。", "result": "FNT算法在$\\Pi_{m,n,p}$空间中的时间复杂度为$\\mathcal{O}(|A_{m,n,p}|mn)$。与张量积空间相比，这种设置使复杂性提高了$\\rho_{m,n,p}$倍，当$m \\lesssim n^p$时，该因子随空间维数的增加而超指数衰减。同时，展示了FNT分层方案的构建及其在敏感性分析中计算活动分数时的性能。", "conclusion": "FNT在特定向下封闭多项式空间中提供了显著的计算复杂性优势，并且其分层方案可有效应用于敏感性分析。", "translation": "我们最近引入了快速牛顿变换（FNT），这是一种在空间维度为$m$的向下封闭多项式空间中执行多元牛顿插值的算法。在这项工作中，我们分析了FNT在特定向下封闭集族$A_{m,n,p}$的背景下的性能，这些集合定义为所有$\\ell^p$范数小于$n$且$p \\in [0,\\infty]$的多重指标。这些集合诱导出向下封闭多项式空间$\\Pi_{m,n,p}$，FNT算法在此空间中实现了$\\mathcal{O}(|A_{m,n,p}|mn)$的时间复杂度。我们表明，与张量积空间相比，这种设置在复杂性上带来了$\\rho_{m,n,p}$倍的改进，当$m \\lesssim n^p$时，该因子随空间维度的增加而超指数衰减。此外，我们展示了FNT所采用的分层方案的构建，并展示了其在敏感性分析中计算活动分数时的性能。", "summary": "本文深入分析了快速牛顿变换（FNT）在特定向下封闭多项式空间$\\Pi_{m,n,p}$中的性能。研究表明，FNT在这些空间中的时间复杂度为$\\mathcal{O}(|A_{m,n,p}|mn)$，并且与传统的张量积空间相比，其计算复杂性有显著改进，尤其是在高维度情况下，改进因子呈超指数衰减。文章还详细阐述了FNT的分层方案构建，并展示了其在敏感性分析中计算活动分数方面的有效应用。", "keywords": "快速牛顿变换, 多项式插值, 向下封闭空间, 复杂性分析, 敏感性分析", "comments": "这项工作通过在特定多项式空间中分析和优化FNT算法，展示了其在处理高维数据时潜在的计算效率优势。尤其是在复杂性改进方面，超指数衰减的特性表明了该方法在特定条件下的强大潜力。将该算法应用于敏感性分析，也拓宽了其应用范围。"}}
{"id": "2507.13670", "title": "Fast computational deep thermalization", "authors": ["Shantanav Chakraborty", "Soonwon Choi", "Soumik Ghosh", "Tudor Giurgică-Tiron"], "categories": ["quant-ph", "cond-mat.stat-mech", "cs.CC", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      22 pages, 1 figure", "url": "http://arxiv.org/abs/2507.13670v1", "summary": "Deep thermalization refers to the emergence of Haar-like randomness from\nquantum systems upon partial measurements. As a generalization of quantum\nthermalization, it is often associated with high complexity and entanglement.\nHere, we introduce computational deep thermalization and construct the fastest\npossible dynamics exhibiting it at infinite effective temperature. Our circuit\ndynamics produce quantum states with low entanglement in polylogarithmic depth\nthat are indistinguishable from Haar random states to any computationally\nbounded observer. Importantly, the observer is allowed to request many copies\nof the same residual state obtained from partial projective measurements on the\nstate -- this condition is beyond the standard settings of quantum\npseudorandomness, but natural for deep thermalization. In cryptographic terms,\nthese states are pseudorandom, pseudoentangled, and crucially, retain these\nproperties under local measurements. Our results demonstrate a new form of\ncomputational thermalization, where thermal-like behavior arises from\nstructured quantum states endowed with cryptographic properties, instead of\nfrom highly unstructured ensembles. The low resource complexity of preparing\nthese states suggests scalable simulations of deep thermalization using quantum\ncomputers. Our work also motivates the study of computational quantum\npseudorandomness beyond BQP observers.", "comment": "22 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.13670v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "快速计算深度热化", "tldr": "本文介绍了计算深度热化，并构建了在低资源复杂性下产生与Haar随机态无法区分的量子态的最快动力学，从而实现可扩展的深度热化模拟。", "motivation": "深度热化通常与高复杂性和纠缠相关联。本文旨在引入一种计算深度热化的概念，并构建最快的动力学来展示它，以克服传统深度热化的高复杂性。", "method": "引入了“计算深度热化”的概念。构建了电路动力学，该动力学在多对数深度内产生低纠缠的量子态，这些态在计算上与Haar随机态无法区分，即使观察者可以请求许多副本。这些态在局部测量下仍保持伪随机和伪纠缠的特性。", "result": "成功构建了在无限有效温度下表现出计算深度热化的最快动力学。生成的量子态具有低纠缠度，且在多对数深度内，对于任何计算能力有限的观察者而言，都与Haar随机态无法区分。这些态在密码学上是伪随机和伪纠缠的，并且在局部测量下仍能保持这些特性。", "conclusion": "本文展示了一种新型的计算热化形式，其中热力学行为源于具有密码学特性的结构化量子态，而非高度非结构化的系综。制备这些状态的低资源复杂性表明可以使用量子计算机进行深度热化的可扩展模拟。该工作也推动了超越BQP观察者的计算量子伪随机性研究。", "translation": "深度热化是指量子系统在部分测量后出现类似Haar随机性的现象。作为量子热化的一种推广，它通常与高复杂性和纠缠相关。在此，我们引入了计算深度热化，并构建了在无限有效温度下表现出这种现象的最快可能动力学。我们的电路动力学在多对数深度内产生低纠缠的量子态，这些态对于任何计算能力有限的观察者而言，都与Haar随机态无法区分。重要的是，观察者被允许请求从状态的部分投影测量中获得的相同残余态的许多副本——这个条件超出了量子伪随机性的标准设置，但对于深度热化而言是自然的。用密码学术语来说，这些态是伪随机的、伪纠缠的，并且关键的是，它们在局部测量下仍能保持这些特性。我们的结果展示了一种新型的计算热化形式，其中类似热的行为源于具有密码学特性的结构化量子态，而非高度非结构化的系综。制备这些态的低资源复杂性表明可以使用量子计算机进行深度热化的可扩展模拟。我们的工作也推动了超越BQP观察者的计算量子伪随机性研究。", "summary": "本文提出了“计算深度热化”的新概念，旨在解决传统深度热化的高复杂性问题。研究人员构建了一种快速电路动力学，该动力学能在多对数深度内生成低纠缠的量子态，这些态在计算上与Haar随机态无法区分，并具有伪随机和伪纠缠的密码学特性，即使在局部测量下也能保持。这项工作展示了一种新的计算热化形式，并为使用量子计算机进行可扩展的深度热化模拟提供了可能性，同时也激励了对超越BQP观察者的计算量子伪随机性的研究。", "keywords": "深度热化, 计算热化, 量子伪随机性, 低纠缠, 量子模拟", "comments": "这篇论文通过引入“计算深度热化”的概念，巧妙地将量子热化与计算复杂性理论和密码学联系起来。其创新之处在于证明了即使是结构化的、低纠缠的量子态也能在计算上模拟Haar随机性，从而克服了传统深度热化所需的高资源。这对于利用量子计算机模拟复杂量子现象具有重要意义，因为它表明了实现可扩展模拟的可能性。同时，将伪随机性和伪纠缠的概念扩展到局部测量下的量子态，也为量子密码学开辟了新的研究方向。"}}
{"id": "2507.13888", "title": "Fixed time convergence guarantees for Higher Order Control Barrier Functions", "authors": ["Janani S K", "Shishir Kolathaya"], "categories": ["eess.SY", "cs.RO", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 PAGES, 2 FIGURES", "url": "http://arxiv.org/abs/2507.13888v1", "summary": "We present a novel method for designing higher-order Control Barrier\nFunctions (CBFs) that guarantee convergence to a safe set within a\nuser-specified finite. Traditional Higher Order CBFs (HOCBFs) ensure asymptotic\nsafety but lack mechanisms for fixed-time convergence, which is critical in\ntime-sensitive and safety-critical applications such as autonomous navigation.\nIn contrast, our approach imposes a structured differential constraint using\nrepeated roots in the characteristic polynomial, enabling closed-form\npolynomial solutions with exact convergence at a prescribed time. We derive\nconditions on the barrier function and its derivatives that ensure forward\ninvariance and fixed-time reachability, and we provide an explicit formulation\nfor second-order systems. Our method is evaluated on three robotic systems - a\npoint-mass model, a unicycle, and a bicycle model and benchmarked against\nexisting HOCBF approaches. Results demonstrate that our formulation reliably\nenforces convergence within the desired time, even when traditional methods\nfail. This work provides a tractable and robust framework for real-time control\nwith provable finite-time safety guarantees.", "comment": "6 PAGES, 2 FIGURES", "pdf_url": "http://arxiv.org/pdf/2507.13888v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "高阶控制屏障函数的固定时间收敛保证", "tldr": "本文提出了一种新的高阶控制屏障函数（HOCBF）设计方法，该方法通过引入结构化微分约束和特征多项式中的重根，确保系统在用户指定的时间内收敛到安全集，解决了传统HOCBF无法实现固定时间收敛的问题，并在机器人系统上验证了其有效性。", "motivation": "传统的HOCBFs只能保证渐近安全，缺乏固定时间收敛的机制，这在自动导航等时间敏感和安全关键型应用中至关重要。", "method": "本研究提出了一种新的方法，通过在特征多项式中使用重根来施加结构化微分约束，从而得到具有在规定时间内精确收敛的闭式多项式解。该方法推导了保证前向不变性和固定时间可达性的屏障函数及其导数的条件，并为二阶系统提供了明确的公式。", "result": "该方法在点质量模型、独轮车和自行车模型这三种机器人系统上进行了评估，并与现有HOCBF方法进行了基准测试。结果表明，即使传统方法失效，该公式也能可靠地在所需时间内强制收敛。", "conclusion": "这项工作为实时控制提供了一个可处理且鲁棒的框架，具有可证明的有限时间安全保证。", "translation": "我们提出了一种设计高阶控制屏障函数（CBF）的新方法，该方法保证在用户指定的有限时间内收敛到安全集。传统的高阶CBF（HOCBF）确保渐近安全，但缺乏固定时间收敛的机制，这在自动导航等时间敏感和安全关键型应用中至关重要。相比之下，我们的方法通过在特征多项式中使用重根来施加结构化微分约束，从而得到在规定时间内精确收敛的闭式多项式解。我们推导了屏障函数及其导数的条件，以确保前向不变性和固定时间可达性，并为二阶系统提供了明确的公式。我们的方法在三种机器人系统——点质量模型、独轮车和自行车模型上进行了评估，并与现有HOCBF方法进行了基准测试。结果表明，即使传统方法失效，我们的公式也能可靠地在所需时间内强制收敛。这项工作为实时控制提供了一个可处理且鲁棒的框架，具有可证明的有限时间安全保证。", "summary": "本文提出了一种新颖的高阶控制屏障函数（CBF）设计方法，旨在解决传统HOCBF在时间敏感和安全关键型应用中缺乏固定时间收敛保证的问题。通过引入结构化微分约束和特征多项式中的重根，该方法能够实现精确的固定时间收敛。研究推导了确保前向不变性和固定时间可达性的条件，并为二阶系统提供了具体公式。在多种机器人系统上的评估结果表明，该方法能够可靠地在预设时间内强制收敛，且性能优于传统方法，为实时控制提供了可证明的有限时间安全保障。", "keywords": "高阶控制屏障函数, 固定时间收敛, 安全关键系统, 机器人系统, 实时控制", "comments": "该论文的创新之处在于解决了传统高阶控制屏障函数无法提供固定时间收敛保证的局限性，通过引入独特的结构化微分约束和利用特征多项式的重根，实现了精确的有限时间收敛。这对于自动驾驶等需要严格时间保证和高安全性的应用具有重大意义，提供了一个理论上严谨且在实践中鲁棒的实时安全控制框架。"}}
{"id": "2505.18879", "title": "Efficient Online Random Sampling via Randomness Recycling", "authors": ["Thomas L. Draper", "Feras A. Saad"], "categories": ["cs.DS", "cs.DM", "cs.IT", "math.IT", "math.PR", "stat.CO"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      35 pages, 9 figures, 2 tables, 14 algorithms", "url": "http://arxiv.org/abs/2505.18879v2", "summary": "``Randomness recycling'' is a powerful algorithmic technique for reusing a\nfraction of the random information consumed by a probabilistic algorithm to\nreduce its entropy requirements. This article presents a family of randomness\nrecycling algorithms for efficiently sampling a sequence $X_1, X_2, X_3, \\dots$\nof discrete random variables whose joint distribution follows an arbitrary\nstochastic process. We develop randomness recycling techniques to reduce the\nentropy cost of a variety of prominent sampling algorithms, which include\nuniform sampling, inverse transform sampling, lookup-table sampling, alias\nsampling, and discrete distribution generating (DDG) tree sampling. Our method\nachieves an expected amortized entropy cost of $H(X_1,\\dots,X_k)/k +\n\\varepsilon$ input bits per output sample using $O(\\log(1/\\varepsilon))$ space\nas $k\\to\\infty$, which is arbitrarily close to the optimal Shannon entropy rate\nof $H(X_1,\\dots,X_k)/k$ bits per sample. The combination of space, time, and\nentropy properties of our method improves upon the Knuth and Yao\nentropy-optimal algorithm and Han and Hoshi interval algorithm for sampling a\ndiscrete random sequence.\n  On the empirical side, we show that randomness recycling enables\nstate-of-the-art runtime performance on the Fisher-Yates shuffle when using a\ncryptographically secure pseudorandom number generator; and it can also speed\nup discrete Gaussian samplers. Accompanying the manuscript is a performant\nsoftware library in the C programming language that uses randomness recycling\nto accelerate several existing algorithms for random sampling.", "comment": "35 pages, 9 figures, 2 tables, 14 algorithms", "pdf_url": "http://arxiv.org/pdf/2505.18879v2", "cate": "cs.DS", "date": "2025-05-24", "updated": "2025-07-17", "AI": {"title_translation": "通过随机性回收实现高效在线随机抽样", "tldr": "本文提出了一种“随机性回收”算法系列，用于高效地从任意随机过程中采样离散随机变量序列，显著降低了熵成本，并改进了现有算法的性能。", "motivation": "为了减少概率算法的熵需求，本文研究并提出了“随机性回收”技术，旨在通过重用部分随机信息来提高随机抽样效率。", "method": "本文提出了一系列随机性回收算法，用于高效采样遵循任意随机过程的离散随机变量序列。该方法将随机性回收技术应用于多种著名抽样算法，包括均匀抽样、逆变换抽样、查找表抽样、别名抽样和离散分布生成（DDG）树抽样。", "result": "该方法实现了每输出样本的预期摊销熵成本为$H(X_1,\text{...},X_k)/k + \text{ε}$ 输入比特，空间复杂度为$O(\text{log}(1/\text{ε}))$，无限接近最优香农熵率。与Knuth和Yao的熵最优算法以及Han和Hoshi的区间算法相比，该方法在空间、时间和熵特性上均有所改进。在实际应用中，随机性回收在Fisher-Yates洗牌算法中使用加密安全伪随机数生成器时实现了最先进的运行时性能，并能加速离散高斯采样器。", "conclusion": "本文提出的随机性回收算法通过降低熵成本和提高性能，显著改进了离散随机变量序列的在线抽样方法，并提供了实用的软件库支持。", "translation": "“随机性回收”是一种强大的算法技术，用于重用概率算法消耗的一部分随机信息，以降低其熵需求。本文提出了一系列随机性回收算法，用于高效地采样遵循任意随机过程的离散随机变量序列$X_1, X_2, X_3, \text{...}$。我们开发了随机性回收技术，以降低各种著名抽样算法的熵成本，这些算法包括均匀抽样、逆变换抽样、查找表抽样、别名抽样和离散分布生成（DDG）树抽样。我们的方法实现了每输出样本的预期摊销熵成本为$H(X_1,\text{...},X_k)/k + \text{ε}$ 输入比特，使用$O(\text{log}(1/\text{ε}))$空间，当$k\to\text{∞}$时，该成本任意接近每样本最优香农熵率$H(X_1,\text{...},X_k)/k$比特。我们的方法在空间、时间和熵特性上的结合优于Knuth和Yao的熵最优算法以及Han和Hoshi的离散随机序列抽样区间算法。\n在实证方面，我们表明随机性回收在使用加密安全伪随机数生成器时，能使Fisher-Yates洗牌算法实现最先进的运行时性能；它还能加速离散高斯采样器。随手稿附带的是一个用C语言编写的高性能软件库，它使用随机性回收来加速几种现有的随机抽样算法。", "summary": "本文介绍了一种名为“随机性回收”的算法技术，旨在通过重复利用随机信息来降低概率算法的熵需求。研究者开发了一系列随机性回收算法，用于高效地从任意随机过程中采样离散随机变量序列，并将其应用于多种现有抽样算法（如均匀抽样、逆变换抽样等）。该方法实现了接近最优香农熵率的熵成本，并在空间和时间性能上超越了现有的一些熵最优算法。实验证明，该技术能显著提升Fisher-Yates洗牌算法和离散高斯采样器的运行时性能。此外，论文还提供了一个C语言实现的软件库。", "keywords": "随机性回收, 在线抽样, 熵成本, 离散随机变量, 算法优化", "comments": "本文的创新点在于提出了“随机性回收”这一通用技术，通过重用随机信息显著降低了随机抽样算法的熵成本，并提供了理论上的近最优性能保证。其重要性体现在不仅在理论上改进了现有熵最优算法，还在实践中通过加速多种流行抽样算法（如Fisher-Yates洗牌和离散高斯采样）展示了其高效性。同时，提供了一个C语言实现的软件库，大大增加了其实用性和可推广性。"}}
{"id": "2507.07087", "title": "Incremental Averaging Method to Improve Graph-Based Time-Difference-of-Arrival Estimation", "authors": ["Klaus Brümann", "Kouei Yamaoka", "Nobutaka Ono", "Simon Doclo"], "categories": ["eess.AS", "eess.SP"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07087v2", "summary": "Estimating the position of a speech source based on\ntime-differences-of-arrival (TDOAs) is often adversely affected by background\nnoise and reverberation. A popular method to estimate the TDOA between a\nmicrophone pair involves maximizing a generalized cross-correlation with phase\ntransform (GCC-PHAT) function. Since the TDOAs across different microphone\npairs satisfy consistency relations, generally only a small subset of\nmicrophone pairs are used for source position estimation. Although the set of\nmicrophone pairs is often determined based on a reference microphone, recently\na more robust method has been proposed to determine the set of microphone pairs\nby computing the minimum spanning tree (MST) of a signal graph of GCC-PHAT\nfunction reliabilities. To reduce the influence of noise and reverberation on\nthe TDOA estimation accuracy, in this paper we propose to compute the GCC-PHAT\nfunctions of the MST based on an average of multiple cross-power spectral\ndensities (CPSDs) using an incremental method. In each step of the method, we\nincrease the number of CPSDs over which we average by considering CPSDs\ncomputed indirectly via other microphones from previous steps. Using signals\nrecorded in a noisy and reverberant laboratory with an array of spatially\ndistributed microphones, the performance of the proposed method is evaluated in\nterms of TDOA estimation error and 2D source position estimation error.\nExperimental results for different source and microphone configurations and\nthree reverberation conditions show that the proposed method considering\nmultiple CPSDs improves the TDOA estimation and source position estimation\naccuracy compared to the reference microphone- and MST-based methods that rely\non a single CPSD as well as steered-response power-based source position\nestimation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07087v2", "cate": "eess.AS", "date": "2025-07-09", "updated": "2025-07-18", "AI": {"title_translation": "增量平均法改进基于图的时差到达估计", "tldr": "本文提出一种增量平均方法，通过平均多个交叉功率谱密度来改进基于图的时差到达（TDOA）估计，从而提高噪声和混响环境下的TDOA和声源定位精度。", "motivation": "语音源定位中的时差到达（TDOA）估计常受背景噪声和混响的不利影响。尽管已存在基于广义互相关相位变换（GCC-PHAT）和最小生成树（MST）的稳健方法，但仍需进一步减少噪声和混响对TDOA估计准确性的影响。", "method": "本文提出一种增量平均方法，通过对多个交叉功率谱密度（CPSD）进行平均来计算基于最小生成树（MST）的广义互相关相位变换（GCC-PHAT）函数。该方法在每一步中通过考虑先前步骤中通过其他麦克风间接计算的CPSD来增加平均的CPSD数量。", "result": "实验结果表明，与依赖单一CPSD的参考麦克风和基于MST的方法以及基于导向响应功率的声源定位方法相比，所提出的考虑多个CPSD的方法显著提高了TDOA估计和声源定位的准确性。", "conclusion": "通过对多个交叉功率谱密度进行增量平均，本文提出的方法有效提高了在噪声和混响环境下基于图的时差到达估计的准确性，从而改善了声源定位性能。", "translation": "基于时差到达（TDOA）的语音源定位估计常受背景噪声和混响的不利影响。一种流行的估计麦克风对之间TDOA的方法是最大化广义互相关相位变换（GCC-PHAT）函数。由于不同麦克风对之间的TDOA满足一致性关系，通常只使用一小部分麦克风对进行声源位置估计。虽然麦克风对的集合通常基于参考麦克风确定，但最近提出了一种更稳健的方法，通过计算GCC-PHAT函数可靠性信号图的最小生成树（MST）来确定麦克风对的集合。为了减少噪声和混响对TDOA估计准确性的影响，本文提出使用增量方法对多个交叉功率谱密度（CPSD）的平均值来计算MST的GCC-PHAT函数。在该方法的每一步中，我们通过考虑前一步中通过其他麦克风间接计算的CPSD来增加平均的CPSD数量。使用在嘈杂混响实验室中通过空间分布麦克风阵列记录的信号，评估了所提出方法在TDOA估计误差和二维声源位置估计误差方面的性能。针对不同声源和麦克风配置以及三种混响条件进行的实验结果表明，与依赖单一CPSD的参考麦克风和基于MST的方法以及基于导向响应功率的声源位置估计方法相比，所提出的考虑多个CPSD的方法提高了TDOA估计和声源位置估计的准确性。", "summary": "本文提出了一种增量平均方法，旨在提高基于图的时差到达（TDOA）估计在噪声和混响环境下的准确性。该方法通过对多个交叉功率谱密度（CPSD）进行增量平均来计算最小生成树（MST）的广义互相关相位变换（GCC-PHAT）函数。实验结果表明，与现有方法相比，所提出的方法显著降低了TDOA和声源位置的估计误差。", "keywords": "时差到达估计, 增量平均, 交叉功率谱密度, 最小生成树, 声源定位", "comments": "该论文的创新点在于提出了一个增量平均方法，将多个交叉功率谱密度纳入到基于图的TDOA估计中，有效地克服了噪声和混响对定位精度的负面影响。这种通过间接CPSD集成信息的方式，增强了方法的鲁棒性，对于实际应用中的声源定位具有重要意义。"}}
{"id": "2504.00142", "title": "Can we ease the Injectivity Bottleneck on Lorentzian Manifolds for Graph Neural Networks?", "authors": ["Srinitish Srinivasan", "Omkumar CU"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted at ACM SIGMOD/PODS 2025 GRADES NDA Workshop (Non-Archival) Poster: this https URL", "url": "http://arxiv.org/abs/2504.00142v5", "summary": "While hyperbolic GNNs show promise for hierarchical data, they often have\nlimited discriminative power compared to Euclidean counterparts or the WL test,\ndue to non-injective aggregation. To address this expressivity gap, we propose\nthe Lorentzian Graph Isomorphic Network (LGIN), a novel HGNN designed for\nenhanced discrimination within the Lorentzian model. LGIN introduces a new\nupdate rule that preserves the Lorentzian metric while effectively capturing\nricher structural information. This marks a significant step towards more\nexpressive GNNs on Riemannian manifolds. Extensive evaluations across nine\nbenchmark datasets demonstrate LGIN's superior performance, consistently\noutperforming or matching state-of-the-art hyperbolic and Euclidean baselines,\nshowcasing its ability to capture complex graph structures. LGIN is the first\nto adapt principles of powerful, highly discriminative GNN architectures to a\nRiemannian manifold. The code for our paper can be found at\nhttps://github.com/Deceptrax123/LGIN", "comment": "Accepted at ACM SIGMOD/PODS 2025 GRADES NDA Workshop (Non-Archival)\n  Poster:\n  https://drive.google.com/file/d/1hjUqbIWrjhZ1YTFDGFK9hxGYiz9xYLSC/view?usp=drive_link", "pdf_url": "http://arxiv.org/pdf/2504.00142v5", "cate": "cs.LG", "date": "2025-03-31", "updated": "2025-07-18", "AI": {"title_translation": "我们可以缓解洛伦兹流形上图神经网络的内射瓶颈吗？", "tldr": "本文提出了洛伦兹图同构网络（LGIN），一种新型双曲图神经网络，通过引入保持洛伦兹度量的新更新规则，解决了现有双曲GNN因非内射聚合导致的判别能力不足问题，并在多个基准数据集上表现出优越性能。", "motivation": "双曲图神经网络（HGNN）虽然在处理层次数据方面具有潜力，但由于非内射聚合，与欧几里得对应物或WL测试相比，它们的判别能力有限，存在表达能力差距。", "method": "本文提出了洛伦兹图同构网络（LGIN），这是一种新型HGNN，旨在增强洛伦兹模型内的判别能力。LGIN引入了一种新的更新规则，该规则在有效捕获更丰富的结构信息的同时，保留了洛伦兹度量。", "result": "在九个基准数据集上的广泛评估表明，LGIN表现出卓越的性能，持续优于或匹配最先进的双曲和欧几里得基线，展示了其捕获复杂图结构的能力。", "conclusion": "LGIN是第一个将强大的、高度判别性的GNN架构原理应用于黎曼流形的工作，标志着在黎曼流形上实现更具表达能力的GNN迈出了重要一步。", "translation": "虽然双曲GNN在层次数据方面显示出前景，但由于非内射聚合，与欧几里得对应物或WL测试相比，它们的判别能力通常有限。为了解决这种表达能力差距，我们提出了洛伦兹图同构网络（LGIN），这是一种新型HGNN，旨在增强洛伦兹模型内的判别能力。LGIN引入了一种新的更新规则，该规则在有效捕获更丰富的结构信息的同时，保留了洛伦兹度量。这标志着在黎曼流形上实现更具表达能力的GNN迈出了重要一步。在九个基准数据集上的广泛评估表明，LGIN表现出卓越的性能，持续优于或匹配最先进的双曲和欧几里得基线，展示了其捕获复杂图结构的能力。LGIN是第一个将强大的、高度判别性的GNN架构原理应用于黎曼流形的工作。我们论文的代码可以在https://github.com/Deceptrax123/LGIN找到。", "summary": "本文针对双曲图神经网络（HGNN）因非内射聚合导致的判别能力不足问题，提出了一种新型洛伦兹图同构网络（LGIN）。LGIN引入了保持洛伦兹度量的新更新规则，以捕获更丰富的结构信息，从而增强模型表达能力。实验证明，LGIN在多个数据集上性能优于或媲美现有SOTA基线，是首个将高判别性GNN架构应用于黎曼流形的工作。", "keywords": "洛伦兹流形, 图神经网络, 内射瓶颈, 双曲GNN, LGIN", "comments": "本文的创新点在于首次将强大的图神经网络架构原理应用于黎曼流形，特别是洛伦兹流形，并引入了保持洛伦兹度量的新颖更新规则，有效缓解了双曲GNN的内射瓶颈，显著提升了其判别能力和表达能力。"}}
{"id": "2507.13370", "title": "H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance", "authors": ["Shijun Guo", "Haoran Xu", "Yaming Yang", "Ziyu Guan", "Wei Zhao", "Xinyi Zhang", "Yishan Song", "Jiwei Chen"], "categories": ["cs.SI", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13370v1", "summary": "The openness of social media enables the free exchange of opinions, but it\nalso presents challenges in guiding opinion evolution towards global consensus.\nExisting methods often directly modify user views or enforce cross-group\nconnections. These intrusive interventions undermine user autonomy, provoke\npsychological resistance, and reduce the efficiency of global consensus.\nAdditionally, due to the lack of a long-term perspective, promoting local\nconsensus often exacerbates divisions at the macro level. To address these\nissues, we propose the hierarchical, non-intrusive opinion guidance framework,\nH-NeiFi. It first establishes a two-layer dynamic model based on social roles,\nconsidering the behavioral characteristics of both experts and non-experts.\nAdditionally, we introduce a non-intrusive neighbor filtering method that\nadaptively controls user communication channels. Using multi-agent\nreinforcement learning (MARL), we optimize information propagation paths\nthrough a long-term reward function, avoiding direct interference with user\ninteractions. Experiments show that H-NeiFi increases consensus speed by 22.0%\nto 30.7% and maintains global convergence even in the absence of experts. This\napproach enables natural and efficient consensus guidance by protecting user\ninteraction autonomy, offering a new paradigm for social network governance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13370v1", "cate": "cs.SI", "date": "2025-07-11", "updated": "2025-07-11", "AI": {"title_translation": "H-NeiFi：非侵入式且高效共识的多智能体意见引导", "tldr": "H-NeiFi 是一种分层、非侵入式的意见引导框架，通过邻居过滤和多智能体强化学习，在保护用户自主性的前提下，提高社交媒体上的共识速度和全局收敛性。", "motivation": "社交媒体的开放性使得意见自由交流，但也导致意见难以引导至全局共识。现有方法常直接修改用户观点或强制连接，这种侵入式干预损害用户自主性，引发抵触，降低共识效率。同时，缺乏长期视角导致局部共识加剧宏观层面的分裂。", "method": "提出分层、非侵入式意见引导框架H-NeiFi。首先，建立基于社会角色的两层动态模型，考虑专家和非专家的行为特征。其次，引入非侵入式邻居过滤方法，自适应控制用户通信渠道。最后，使用多智能体强化学习（MARL）通过长期奖励函数优化信息传播路径，避免直接干扰用户互动。", "result": "H-NeiFi 将共识速度提高了22.0%至30.7%，即使在没有专家的情况下也能保持全局收敛。", "conclusion": "H-NeiFi 通过保护用户互动自主性，实现了自然高效的共识引导，为社交网络治理提供了一种新范式。", "translation": "社交媒体的开放性使得意见可以自由交流，但也给引导意见演化走向全局共识带来了挑战。现有方法通常直接修改用户观点或强制建立跨群体连接。这些侵入式干预破坏了用户自主性，引发心理抵触，并降低了全局共识的效率。此外，由于缺乏长期视角，促进局部共识往往会加剧宏观层面的分裂。为了解决这些问题，我们提出了分层、非侵入式意见引导框架H-NeiFi。它首先建立了一个基于社会角色的两层动态模型，考虑了专家和非专家的行为特征。此外，我们引入了一种非侵入式邻居过滤方法，自适应地控制用户通信渠道。利用多智能体强化学习（MARL），我们通过一个长期奖励函数优化信息传播路径，避免直接干扰用户互动。实验表明，H-NeiFi 将共识速度提高了22.0%至30.7%，即使在没有专家的情况下也能保持全局收敛。这种方法通过保护用户互动自主性，实现了自然高效的共识引导，为社交网络治理提供了一种新范式。", "summary": "本研究提出了一种名为H-NeiFi的分层、非侵入式意见引导框架，旨在解决社交媒体中意见引导的挑战。现有方法因侵入性干预和缺乏长期视角而效率低下并加剧分裂。H-NeiFi通过建立考虑专家和非专家行为的两层动态模型，引入自适应邻居过滤，并利用多智能体强化学习优化信息传播路径，避免直接干扰用户互动。实验结果表明，H-NeiFi显著提高了共识速度，并能在无专家情况下保持全局收敛，为社交网络治理提供了保护用户自主性的新范式。", "keywords": "意见引导, 多智能体强化学习, 非侵入式, 共识, 社交网络", "comments": "H-NeiFi的创新之处在于其非侵入式的意见引导方法，通过邻居过滤和MARL优化信息传播，有效避免了传统方法的弊端。其分层模型考虑了不同社会角色，增加了模型的普适性。该研究为社交媒体治理提供了重要的新思路，强调了在引导共识时保护用户自主性的重要性。"}}
{"id": "2507.13355", "title": "PGR-DRC: Pre-Global Routing DRC Violation Prediction Using Unsupervised Learning", "authors": ["Riadul Islam", "Dhandeep Challagundla"], "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13355v1", "summary": "Leveraging artificial intelligence (AI)-driven electronic design and\nautomation (EDA) tools, high-performance computing, and parallelized algorithms\nare essential for next-generation microprocessor innovation, ensuring continued\nprogress in computing, AI, and semiconductor technology. Machine learning-based\ndesign rule checking (DRC) and lithography hotspot detection can improve\nfirst-pass silicon success. However, conventional ML and neural network\n(NN)-based models use supervised learning and require a large balanced dataset\n(in terms of positive and negative classes) and training time. This research\naddresses those key challenges by proposing the first-ever unsupervised DRC\nviolation prediction methodology. The proposed model can be built using any\nunbalanced dataset using only one class and set a threshold for it, then\nfitting any new data querying if they are within the boundary of the model for\nclassification. This research verified the proposed model by implementing\ndifferent computational cores using CMOS 28 nm technology and Synopsys Design\nCompiler and IC Compiler II tools. Then, layouts were divided into virtual\ngrids to collect about 60k data for analysis and verification. The proposed\nmethod has 99.95% prediction test accuracy, while the existing support vector\nmachine (SVM) and neural network (NN) models have 85.44\\% and 98.74\\% accuracy,\nrespectively. In addition, the proposed methodology has about 26.3x and up to\n6003x lower training times compared to SVM and NN-models, respectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13355v1", "cate": "cs.AR", "date": "2025-06-08", "updated": "2025-06-08", "AI": {"title_translation": "PGR-DRC：基于无监督学习的全局布线前DRC违规预测", "tldr": "PGR-DRC提出了一种新颖的无监督学习方法，用于在全局布线前预测DRC违规，显著提高了预测准确性并大幅缩短了训练时间。", "motivation": "传统的基于机器学习和神经网络的设计规则检查（DRC）模型采用监督学习，需要大量平衡的数据集和较长的训练时间。本研究旨在解决这些挑战。", "method": "本研究提出了一种首创的无监督DRC违规预测方法PGR-DRC。该模型可以使用任何不平衡数据集（仅需一个类别）进行构建，并设置阈值以对新数据进行分类。该方法通过使用CMOS 28纳米技术和Synopsys Design Compiler/IC Compiler II工具实现不同的计算核心进行验证，并收集了约6万个数据点进行分析。", "result": "所提出的方法具有99.95%的预测测试准确率。相比之下，现有的支持向量机（SVM）模型和神经网络（NN）模型的准确率分别为85.44%和98.74%。此外，所提出的方法与SVM和NN模型相比，训练时间分别缩短了约26.3倍和高达6003倍。", "conclusion": "PGR-DRC作为一种无监督学习方法，在DRC违规预测方面表现出卓越的性能，不仅显著提高了预测准确性，还大幅缩短了训练时间，克服了传统监督学习方法的局限性，为下一代微处理器创新提供了关键支持。", "translation": "利用人工智能（AI）驱动的电子设计自动化（EDA）工具、高性能计算和并行算法对于下一代微处理器创新至关重要，确保计算、人工智能和半导体技术的持续进步。基于机器学习的设计规则检查（DRC）和光刻热点检测可以提高一次性流片成功率。然而，传统的机器学习和基于神经网络（NN）的模型使用监督学习，需要大量平衡的数据集（在正负类别方面）和训练时间。本研究通过提出首个无监督DRC违规预测方法来解决这些关键挑战。所提出的模型可以使用任何不平衡数据集（仅需一个类别）构建，并为其设置阈值，然后拟合任何新数据，查询它们是否在模型边界内进行分类。本研究通过使用CMOS 28纳米技术和Synopsys Design Compiler和IC Compiler II工具实现不同的计算核心来验证所提出的模型。然后，将布局划分为虚拟网格，收集了大约6万个数据进行分析和验证。所提出的方法具有99.95%的预测测试准确率，而现有支持向量机（SVM）和神经网络（NN）模型的准确率分别为85.44%和98.74%。此外，与SVM和NN模型相比，所提出的方法的训练时间分别缩短了约26.3倍和高达6003倍。", "summary": "本论文提出了一种名为PGR-DRC的创新型无监督学习方法，用于预测全局布线前的设计规则检查（DRC）违规。该方法旨在克服传统监督学习模型对平衡数据集和长时间训练的需求。PGR-DRC模型能够利用不平衡数据集构建，并通过阈值设定进行分类。实验验证表明，PGR-DRC在CMOS 28纳米技术下达到了99.95%的预测准确率，显著优于现有的SVM（85.44%）和NN（98.74%）模型。更重要的是，该方法的训练时间比SVM和NN模型分别缩短了约26.3倍和高达6003倍，极大地提升了效率。", "keywords": "无监督学习, DRC违规预测, 电子设计自动化, PGR-DRC, 机器学习", "comments": "PGR-DRC的创新之处在于它是首个将无监督学习应用于DRC违规预测的方法，成功解决了传统监督学习模型对大数据集平衡性及训练时间的严苛要求。其高达99.95%的预测准确率和显著降低的训练时间（最高6003倍），使其在电子设计自动化领域具有巨大的应用潜力，特别是在加速下一代微处理器设计和提高首次流片成功率方面，展示了无监督学习在EDA工具中的强大威力。"}}
{"id": "2507.13743", "title": "PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs", "authors": ["Maluna Menke", "Thilo Hagendorff"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13743v1", "summary": "Large Language Models (LLMs) frequently reproduce the gender- and\nsexual-identity prejudices embedded in their training corpora, leading to\noutputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of\ngreat importance. To achieve this, we evaluate two parameter-efficient\nfine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt\ntuning - as lightweight alternatives to full-model fine-tuning for mitigating\nsuch biases. Using the WinoQueer benchmark, we quantify bias in three\nopen-source LLMs and observe baseline bias scores reaching up to 98 (out of\n100) across a range of queer identities defined by gender and/or sexual\norientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%\nadditional parameters) on a curated QueerNews corpus reduces those scores by up\nto 50 points and raises neutrality from virtually 0% to as much as 36%.\nSoft-prompt tuning (10 virtual tokens) delivers only marginal improvements.\nThese findings show that LoRA can deliver meaningful fairness gains with\nminimal computation. We advocate broader adoption of community-informed PEFT,\nthe creation of larger queer-authored corpora, and richer evaluation suites\nbeyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13743v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "PRIDE -- 大型语言模型中身份歧视的参数高效减少以实现平等", "tldr": "研究发现，LoRA是一种参数高效的微调方法，能有效减少LLM对LGBTQIA+用户的身份歧视，且计算成本极低。", "motivation": "大型语言模型（LLM）经常复制其训练语料库中嵌入的性别和性身份偏见，导致输出边缘化LGBTQIA+用户，因此减少此类偏见至关重要。", "method": "本研究评估了两种参数高效微调（PEFT）技术——低秩适应（LoRA）和软提示调整——作为全模型微调的轻量级替代方案，以减轻LLM中的性别和性身份偏见。研究使用WinoQueer基准测试量化了三种开源LLM的偏见，并在精选的QueerNews语料库上对模型进行了LoRA微调。", "result": "在由性别和/或性取向定义的各种酷儿身份中，LLM的基线偏见分数高达98（满分100，50为中立）。使用LoRA微调（<0.1%的额外参数）可将偏见分数降低高达50点，并将中立性从几乎0%提高到高达36%。相比之下，软提示调整（10个虚拟token）仅带来微小改进。", "conclusion": "LoRA能够以最小的计算量实现有意义的公平性提升。研究倡导更广泛地采用社区知情的PEFT、创建更大的酷儿作者语料库，以及开发超越WinoQueer的更丰富的评估套件，并结合持续审计以保持LLM的包容性。", "translation": "大型语言模型（LLM）经常复制其训练语料库中嵌入的性别和性身份偏见，导致输出边缘化LGBTQIA+用户。因此，减少此类偏见至关重要。为实现这一目标，我们评估了两种参数高效微调（PEFT）技术——低秩适应（LoRA）和软提示调整——作为全模型微调的轻量级替代方案，以减轻此类偏见。使用WinoQueer基准测试，我们量化了三种开源LLM中的偏见，并观察到在由性别和/或性取向定义的各种酷儿身份中，基线偏见分数高达98（满分100），其中50表示中立。在精选的QueerNews语料库上使用LoRA进行微调（<0.1%的额外参数）将这些分数降低了多达50点，并将中立性从几乎0%提高到高达36%。软提示调整（10个虚拟token）仅带来微小改进。这些发现表明，LoRA能够以最小的计算量实现有意义的公平性提升。我们倡导更广泛地采用社区知情的PEFT、创建更大的酷儿作者语料库，以及开发超越WinoQueer的更丰富的评估套件，并结合持续审计以保持LLM的包容性。", "summary": "本研究关注大型语言模型（LLM）中存在的性别和性身份偏见，这些偏见可能边缘化LGBTQIA+用户。为解决此问题，作者评估了两种参数高效微调（PEFT）技术：低秩适应（LoRA）和软提示调整。实验结果表明，LoRA在减少LLM偏见方面表现出色，使用极少量额外参数即可将偏见分数显著降低并提高中立性，而软提示调整效果不佳。这表明LoRA是一种计算高效且有效的偏见缓解策略，为构建更具包容性的LLM提供了方向。", "keywords": "大型语言模型, 偏见缓解, 参数高效微调, LoRA, 身份歧视", "comments": "该论文的创新点在于探索了参数高效微调（PEFT）技术在减少LLM身份歧视方面的应用，特别是证明了LoRA在极低计算成本下实现显著公平性提升的潜力。这对于实际部署和维护公平的LLM具有重要意义。论文还强调了社区知情PEFT、构建特定语料库和更丰富评估套件的重要性，为未来研究指明了方向。"}}
{"id": "2501.13193", "title": "Revisiting Data Augmentation for Ultrasound Images", "authors": ["Adam Tupper", "Christian Gagné"], "categories": ["eess.IV", "cs.CV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Published in the Transacations of Machine Learning Research (TMLR, 2025), see this https URL . For the associated source code see this https URL", "url": "http://arxiv.org/abs/2501.13193v2", "summary": "Data augmentation is a widely used and effective technique to improve the\ngeneralization performance of deep neural networks. Yet, despite often facing\nlimited data availability when working with medical images, it is frequently\nunderutilized. This appears to come from a gap in our collective understanding\nof the efficacy of different augmentation techniques across different tasks and\nmodalities. One modality where this is especially true is ultrasound imaging.\nThis work addresses this gap by analyzing the effectiveness of different\naugmentation techniques at improving model performance across a wide range of\nultrasound image analysis tasks. To achieve this, we introduce a new\nstandardized benchmark of 14 ultrasound image classification and semantic\nsegmentation tasks from 10 different sources and covering 11 body regions. Our\nresults demonstrate that many of the augmentations commonly used for tasks on\nnatural images are also effective on ultrasound images, even more so than\naugmentations developed specifically for ultrasound images in some cases. We\nalso show that diverse augmentation using TrivialAugment, which is widely used\nfor natural images, is also effective for ultrasound images. Moreover, our\nproposed methodology represents a structured approach for assessing various\ndata augmentations that can be applied to other contexts and modalities.", "comment": "Published in the Transacations of Machine Learning Research (TMLR,\n  2025), see https://openreview.net/forum?id=iGcxlTLIL5 . For the associated\n  source code see https://github.com/adamtupper/ultrasound-augmentation", "pdf_url": "http://arxiv.org/pdf/2501.13193v2", "cate": "eess.IV", "date": "2025-01-22", "updated": "2025-07-18", "AI": {"title_translation": "重新审视超声图像的数据增强", "tldr": "本文通过对14个超声图像分析任务的基准测试，分析了不同数据增强技术对超声图像的有效性，发现许多自然图像的增强技术对超声图像也有效，并提出了一个通用的评估方法。", "motivation": "尽管数据增强对深度神经网络的泛化性能有显著提升，但在医学图像领域（尤其是超声图像）却常被低估和未充分利用。这源于对不同增强技术在不同任务和模态中有效性的理解不足。本文旨在填补这一空白。", "method": "研究引入了一个新的标准化基准，包含来自10个不同来源、涵盖11个身体区域的14个超声图像分类和语义分割任务。通过此基准，分析了不同数据增强技术对模型性能的提升效果。并评估了包括TrivialAugment在内的多样化增强策略。", "result": "研究结果表明，许多常用于自然图像的增强技术对超声图像同样有效，甚至在某些情况下优于专门为超声图像开发的增强技术。此外，TrivialAugment等多样化增强方法对超声图像也表现出有效性。", "conclusion": "本文证明了通用数据增强技术在超声图像分析任务中的有效性，并提出了一个结构化的数据增强评估方法，该方法可推广到其他上下文和模态。", "translation": "数据增强是一种广泛使用且有效的技术，可以提高深度神经网络的泛化性能。然而，尽管在处理医学图像时经常面临有限的数据可用性，但它却经常未被充分利用。这似乎源于我们对不同增强技术在不同任务和模态中有效性的集体理解存在差距。超声成像尤其如此。这项工作通过分析不同增强技术在改善各种超声图像分析任务中模型性能方面的有效性来弥补这一差距。为了实现这一点，我们引入了一个新的标准化基准，包含来自10个不同来源、涵盖11个身体区域的14个超声图像分类和语义分割任务。我们的结果表明，许多常用于自然图像任务的增强技术对超声图像也有效，甚至在某些情况下比专门为超声图像开发的增强技术更有效。我们还表明，使用TrivialAugment（广泛用于自然图像）的多样化增强对超声图像也有效。此外，我们提出的方法代表了一种评估各种数据增强的结构化方法，可以应用于其他上下文和模态。", "summary": "本研究旨在解决医学图像（特别是超声图像）数据增强应用不足的问题。通过构建一个包含14个分类和语义分割任务的超声图像标准化基准，本文系统地评估了各种数据增强技术的效果。研究发现，许多适用于自然图像的通用增强方法对超声图像同样有效，有时甚至优于专门的超声增强技术。此外，像TrivialAugment这样的多样化增强策略也被证明在超声图像上表现良好。本文提出的方法为评估不同数据增强技术提供了一个结构化框架，具有广泛的应用潜力。", "keywords": "数据增强, 超声图像, 深度学习, 图像分类, 语义分割", "comments": "本文的创新之处在于构建了一个全面的超声图像数据增强基准，并系统地评估了通用数据增强方法在超声图像上的有效性。其重要性在于打破了对医学图像需要特殊增强方法的固有观念，证明了通用方法的普适性，并提出了一个可推广的评估框架，对医学图像处理领域具有指导意义。"}}
{"id": "2502.03876", "title": "Position: Untrained Machine Learning for Anomaly Detection by using 3D Point Cloud Data", "authors": ["Juan Du", "Dongheng Chen"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages, 5 figure", "url": "http://arxiv.org/abs/2502.03876v2", "summary": "Anomaly detection based on 3D point cloud data is an important research\nproblem and receives more and more attention recently. Untrained anomaly\ndetection based on only one sample is an emerging research problem motivated by\nreal manufacturing industries such as personalized manufacturing where only one\nsample can be collected without any additional labels and historical datasets.\nIdentifying anomalies accurately based on one 3D point cloud sample is a\ncritical challenge in both industrial applications and the field of machine\nlearning. This paper aims to provide a formal definition of the untrained\nanomaly detection problem based on 3D point cloud data, discuss the differences\nbetween untrained anomaly detection and current unsupervised anomaly detection\nproblems. Unlike trained unsupervised learning, untrained unsupervised learning\ndoes not rely on any data, including unlabeled data. Instead, they leverage\nprior knowledge about the surfaces and anomalies.\n  We propose three complementary methodological frameworks: the Latent Variable\nInference Framework that employs probabilistic modeling to distinguish\nanomalies; the Decomposition Framework that separates point clouds into\nreference, anomaly, and noise components through sparse learning; and the Local\nGeometry Framework that leverages neighborhood information for anomaly\nidentification. Experimental results demonstrate that untrained methods achieve\ncompetitive detection performance while offering significant computational\nadvantages, demonstrating up to a 15-fold increase in execution speed. The\nproposed methods provide viable solutions for scenarios with extreme data\nscarcity, addressing critical challenges in personalized manufacturing and\nhealthcare applications where collecting multiple samples or historical data is\ninfeasible.", "comment": "9 pages, 5 figure", "pdf_url": "http://arxiv.org/pdf/2502.03876v2", "cate": "cs.LG", "date": "2025-02-06", "updated": "2025-07-18", "AI": {"title_translation": "立场：利用三维点云数据进行异常检测的无训练机器学习", "tldr": "针对单样本场景，利用三维点云数据进行无训练异常检测，提出了三种框架，性能有竞争力且计算效率高。", "motivation": "三维点云数据的异常检测是一个重要且日益受到关注的问题。在个性化制造等实际工业应用中，由于只能收集到单个样本且缺乏标签和历史数据集，基于单个样本的无训练异常检测成为一个新兴研究问题。准确识别单个三维点云样本中的异常是工业应用和机器学习领域的关键挑战。", "method": "论文首先定义了基于三维点云数据的无训练异常检测问题，并讨论了其与当前无监督异常检测的区别。无训练方法不依赖任何数据（包括无标签数据），而是利用关于表面和异常的先验知识。论文提出了三个互补的方法框架：潜在变量推断框架（使用概率建模）、分解框架（通过稀疏学习分离点云成分）和局部几何框架（利用邻域信息）。", "result": "实验结果表明，所提出的无训练方法在检测性能上具有竞争力，同时提供了显著的计算优势，执行速度提高了高达15倍。这些方法为数据极度稀缺的场景提供了可行解决方案。", "conclusion": "所提出的无训练方法为数据极度稀缺的场景提供了可行解决方案，解决了个性化制造和医疗保健应用中难以收集多样本或历史数据的关键挑战。", "translation": "基于三维点云数据的异常检测是一个重要的研究问题，近年来受到越来越多的关注。仅基于一个样本的无训练异常检测是一个新兴的研究问题，其动机来自于实际的制造业，例如个性化制造，在这种情况下只能收集到一个样本，而没有任何额外的标签和历史数据集。在工业应用和机器学习领域，基于一个三维点云样本准确识别异常是一个关键挑战。本文旨在为基于三维点云数据的无训练异常检测问题提供一个正式的定义，并讨论无训练异常检测与当前无监督异常检测问题的区别。与有训练的无监督学习不同，无训练的无监督学习不依赖任何数据，包括无标签数据。相反，它们利用关于表面和异常的先验知识。我们提出了三个互补的方法框架：采用概率建模区分异常的潜在变量推断框架；通过稀疏学习将点云分离为参考、异常和噪声分量的分解框架；以及利用邻域信息进行异常识别的局部几何框架。实验结果表明，无训练方法取得了有竞争力的检测性能，同时提供了显著的计算优势，执行速度提高了高达15倍。所提出的方法为数据极度稀缺的场景提供了可行的解决方案，解决了在个性化制造和医疗保健应用中收集多个样本或历史数据不可行的关键挑战。", "summary": "本文针对三维点云数据的无训练异常检测这一关键挑战，特别是在个性化制造等缺乏历史数据的单样本场景。论文正式定义了该问题，并通过强调依赖先验知识而非任何数据来区别于传统无监督方法。作者提出了三个新颖的方法框架：潜在变量推断、分解和局部几何。实验结果表明，这些无训练方法在检测性能上具有竞争力，并提供了显著的计算优势（速度提高高达15倍），为个性化制造和医疗保健等数据稀缺的应用提供了可行方案。", "keywords": "无训练异常检测, 三维点云, 单样本, 个性化制造, 数据稀缺", "comments": "本文提出了一种新颖且高度实用的三维点云异常检测方法，专门解决了数据极度稀缺（单样本）的挑战性场景。其创新之处在于定义并解决了“无训练”异常检测问题，这与传统无监督学习显著不同，因为它不依赖任何数据，而是利用先验知识。提出的三个互补框架为异常识别提供了多样的视角。所展示的计算效率（速度提高15倍）是一个重要的实际优势，使这些方法在数据收集困难的实际工业和医疗保健应用中具有高度相关性。这项工作为数据受限环境中的异常检测开辟了新途径。"}}
{"id": "2507.13810", "title": "Quantum Shadows: The Dining Information Brokers", "authors": ["Theodore Andronikos", "Constantinos Bitsakos", "Konstantinos Nikas", "Georgios I. Goumas", "Nectarios Koziris"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13810v1", "summary": "This article introduces the innovative Quantum Dining Information Brokers\nProblem, presenting a novel entanglement-based quantum protocol to address it.\nThe scenario involves $n$ information brokers, all located in distinct\ngeographical regions, engaging in a metaphorical virtual dinner. The objective\nis for each broker to share a unique piece of information with all others\nsimultaneously. Unlike previous approaches, this protocol enables a fully\nparallel, single-step communication exchange among all brokers, regardless of\ntheir physical locations. A key feature of this protocol is its ability to\nensure both the anonymity and privacy of all participants are preserved,\nmeaning no broker can discern the identity of the sender behind any received\ninformation. At its core, the Quantum Dining Information Brokers Problem serves\nas a conceptual framework for achieving anonymous, untraceable, and massively\nparallel information exchange in a distributed system. The proposed protocol\nintroduces three significant advancements. First, while quantum protocols for\none-to-many simultaneous information transmission have been developed, this is,\nto the best of our knowledge, one of the first quantum protocols to facilitate\nmany-to-many simultaneous information exchange. Second, it guarantees complete\nanonymity and untraceability for all senders, a critical improvement over\nsequential applications of one-to-many protocols, which fail to ensure such\nrobust anonymity. Third, leveraging quantum entanglement, the protocol operates\nin a fully distributed manner, accommodating brokers in diverse spatial\nlocations. This approach marks a substantial advancement in secure, scalable,\nand anonymous communication, with potential applications in distributed\nenvironments where privacy and parallelism are paramount.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13810v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "量子阴影：餐桌信息经纪人", "tldr": "本文提出了一种基于纠缠的新型量子协议，用于解决量子餐桌信息经纪人问题，旨在实现分布式环境中匿名、并行、多对多的信息交换，同时确保参与者的隐私和不可追溯性。", "motivation": "传统的信息交换方法在实现完全并行、强大的匿名性和不可追溯性方面存在不足，尤其是在多对多同时信息共享的场景中。因此，在隐私和并行性至关重要的分布式环境中，需要一种安全、可扩展和匿名的通信方案。", "method": "本文提出了一个新颖的基于纠缠的量子协议，以解决量子餐桌信息经纪人问题。该协议利用量子纠缠，使得所有信息经纪人之间能够进行完全并行、一步式的通信交换，并且以完全分布式的方式运行。", "result": "所提出的协议实现了完全并行、一步式的多对多同步信息交换。它保证了所有发送者的完全匿名性和不可追溯性，这比现有的一对多协议有了显著改进。该协议还能够以完全分布式的方式在不同地理位置的参与者之间运行。", "conclusion": "该协议为在分布式系统中实现匿名、不可追溯和大规模并行信息交换提供了一个概念框架，标志着在安全、可扩展和匿名通信方面的重大进步，尤其适用于对隐私和并行性有高要求的分布式环境。", "translation": "本文介绍了创新的量子餐桌信息经纪人问题，并提出了一个新颖的基于纠缠的量子协议来解决它。该场景涉及n个信息经纪人，他们都位于不同的地理区域，参与一场虚拟的晚餐。目标是每个经纪人同时与所有其他人分享一个独特的信息。与以前的方法不同，该协议实现了所有经纪人之间完全并行、一步式的通信交换，无论其物理位置如何。该协议的一个关键特点是它能够确保所有参与者的匿名性和隐私性都得到保留，这意味着任何经纪人都可以辨别所接收信息背后发送者的身份。量子餐桌信息经纪人问题的核心是作为在分布式系统中实现匿名、不可追溯和大规模并行信息交换的概念框架。所提出的协议引入了三项重大进展。首先，虽然已经开发了用于一对多同时信息传输的量子协议，但据我们所知，这是首批促进多对多同时信息交换的量子协议之一。其次，它保证了所有发送者的完全匿名性和不可追溯性，这是对一对多协议的顺序应用的一个关键改进，后者无法确保如此强大的匿名性。第三，利用量子纠缠，该协议以完全分布式的方式运行，适应不同空间位置的经纪人。这种方法标志着安全、可扩展和匿名通信的重大进步，在隐私和并行性至关重要的分布式环境中具有潜在应用。", "summary": "本文引入了“量子餐桌信息经纪人问题”，并提出了一种新颖的基于纠缠的量子协议来解决它。该协议实现了地理分散参与者之间完全并行、一步式的多对多同步信息交换。通过保证所有发送者的完全匿名性和不可追溯性，它显著增强了安全性，弥补了现有的一对多协议的不足。该协议利用量子纠缠以完全分布式的方式运行，标志着分布式系统中安全、可扩展和匿名通信的重大进展。", "keywords": "量子纠缠, 匿名通信, 分布式系统, 多对多, 隐私", "comments": "本文创新性地将量子纠缠应用于分布式通信，解决了实现匿名、不可追溯和大规模并行信息交换的关键问题。其新颖之处在于以强大的匿名性保证促进了多对多同步通信，这比现有的一对多量子协议有了显著改进。虽然“量子餐桌信息经纪人”的概念框架很有趣，但量子纠缠在不同空间位置的实际实现挑战可能是其局限性，但其理论进步是显而易见的。"}}
{"id": "2507.13620", "title": "Tri-Learn Graph Fusion Network for Attributed Graph Clustering", "authors": ["Binxiong Li", "Yuefei Wang", "Xu Xiang", "Xue Li", "Binyu Zhao", "Heyang Gao", "Qinyu Zhao", "Xi Yu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      The source code for this study is available at this https URL", "url": "http://arxiv.org/abs/2507.13620v1", "summary": "In recent years, models based on Graph Convolutional Networks (GCN) have made\nsignificant strides in the field of graph data analysis. However, challenges\nsuch as over-smoothing and over-compression remain when handling large-scale\nand complex graph datasets, leading to a decline in clustering quality.\nAlthough the Graph Transformer architecture has mitigated some of these issues,\nits performance is still limited when processing heterogeneous graph data. To\naddress these challenges, this study proposes a novel deep clustering framework\nthat comprising GCN, Autoencoder (AE), and Graph Transformer, termed the\nTri-Learn Graph Fusion Network (Tri-GFN). This framework enhances the\ndifferentiation and consistency of global and local information through a\nunique tri-learning mechanism and feature fusion enhancement strategy. The\nframework integrates GCN, AE, and Graph Transformer modules. These components\nare meticulously fused by a triple-channel enhancement module, which maximizes\nthe use of both node attributes and topological structures, ensuring robust\nclustering representation. The tri-learning mechanism allows mutual learning\namong these modules, while the feature fusion strategy enables the model to\ncapture complex relationships, yielding highly discriminative representations\nfor graph clustering. It surpasses many state-of-the-art methods, achieving an\naccuracy improvement of approximately 0.87% on the ACM dataset, 14.14 % on the\nReuters dataset, and 7.58 % on the USPS dataset. Due to its outstanding\nperformance on the Reuters dataset, Tri-GFN can be applied to automatic news\nclassification, topic retrieval, and related fields.", "comment": "The source code for this study is available at\n  https://github.com/YF-W/Tri-GFN", "pdf_url": "http://arxiv.org/pdf/2507.13620v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "三学图融合网络用于属性图聚类", "tldr": "本文提出了一种名为Tri-GFN的深度聚类框架，融合了GCN、Autoencoder和Graph Transformer，通过独特的三学习机制和特征融合策略，有效解决了图聚类中GCN的过平滑和过压缩问题以及Graph Transformer在异构数据上的局限性，显著提升了聚类性能。", "motivation": "现有的图卷积网络（GCN）在处理大规模复杂图数据时存在过平滑和过压缩等问题，导致聚类质量下降。尽管图Transformer架构有所缓解，但在处理异构图数据时性能仍然受限。", "method": "本研究提出了一种名为三学图融合网络（Tri-GFN）的深度聚类框架，该框架融合了GCN、自编码器（AE）和图Transformer。Tri-GFN通过独特的三学习机制和特征融合增强策略，增强了全局和局部信息的区分性和一致性。它通过三重通道增强模块精心融合这些组件，最大限度地利用节点属性和拓扑结构，以确保鲁棒的聚类表示。三学习机制允许这些模块之间相互学习，而特征融合策略使模型能够捕获复杂关系，从而为图聚类产生高度可区分的表示。", "result": "Tri-GFN在ACM数据集上实现了约0.87%的准确率提升，在Reuters数据集上提升了14.14%，在USPS数据集上提升了7.58%，超越了许多最先进的方法。", "conclusion": "Tri-GFN通过融合GCN、AE和Graph Transformer并采用三学习机制和特征融合策略，有效克服了现有方法的局限性，显著提高了图聚类性能，尤其在Reuters数据集上的出色表现使其可应用于自动新闻分类和主题检索等领域。", "translation": "近年来，基于图卷积网络（GCN）的模型在图数据分析领域取得了显著进展。然而，在处理大规模复杂图数据集时，过平滑和过压缩等挑战依然存在，导致聚类质量下降。尽管图Transformer架构缓解了其中一些问题，但其在处理异构图数据时性能仍然受限。为了应对这些挑战，本研究提出了一种新颖的深度聚类框架，该框架由GCN、自编码器（AE）和图Transformer组成，命名为三学图融合网络（Tri-GFN）。该框架通过独特的三学习机制和特征融合增强策略，增强了全局和局部信息的区分性和一致性。该框架集成了GCN、AE和图Transformer模块。这些组件通过一个三重通道增强模块精心融合，最大限度地利用节点属性和拓扑结构，确保鲁棒的聚类表示。三学习机制允许这些模块之间相互学习，而特征融合策略使模型能够捕获复杂关系，从而为图聚类产生高度可区分的表示。它超越了许多最先进的方法，在ACM数据集上实现了约0.87%的准确率提升，在Reuters数据集上提升了14.14%，在USPS数据集上提升了7.58%。由于其在Reuters数据集上的出色性能，Tri-GFN可应用于自动新闻分类、主题检索及相关领域。", "summary": "本文针对现有图卷积网络（GCN）在图聚类中存在的过平滑、过压缩以及图Transformer在异构数据上的局限性问题，提出了一种名为三学图融合网络（Tri-GFN）的新型深度聚类框架。Tri-GFN巧妙地融合了GCN、自编码器（AE）和图Transformer，并通过独特的三学习机制和特征融合增强策略，优化了全局与局部信息的区分性和一致性，从而生成鲁棒的聚类表示。实验结果表明，Tri-GFN在多个数据集上均显著提升了聚类准确率，尤其在Reuters数据集上表现优异，展现了其在自动新闻分类等领域的应用潜力。", "keywords": "图聚类, 图卷积网络, 图Transformer, 自编码器, 特征融合", "comments": "Tri-GFN的创新点在于其独特的三学习机制和三重通道融合策略，将GCN、AE和Graph Transformer的优势结合起来，有效解决了现有方法在处理复杂图数据时面临的挑战。这种多模型协同学习的范式为图聚类任务提供了新的视角和解决方案，并且在多个数据集上取得了显著的性能提升，具有重要的研究和应用价值。"}}
{"id": "2507.13739", "title": "Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning", "authors": ["Junsu Kim", "Yunhoe Ku", "Seungryul Baek"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6th CLVISION ICCV Workshop accepted", "url": "http://arxiv.org/abs/2507.13739v1", "summary": "Few-shot class-incremental learning (FSCIL) is challenging due to extremely\nlimited training data; while aiming to reduce catastrophic forgetting and learn\nnew information. We propose Diffusion-FSCIL, a novel approach that employs a\ntext-to-image diffusion model as a frozen backbone. Our conjecture is that\nFSCIL can be tackled using a large generative model's capabilities benefiting\nfrom 1) generation ability via large-scale pre-training; 2) multi-scale\nrepresentation; 3) representational flexibility through the text encoder. To\nmaximize the representation capability, we propose to extract multiple\ncomplementary diffusion features to play roles as latent replay with slight\nsupport from feature distillation for preventing generative biases. Our\nframework realizes efficiency through 1) using a frozen backbone; 2) minimal\ntrainable components; 3) batch processing of multiple feature extractions.\nExtensive experiments on CUB-200, \\emph{mini}ImageNet, and CIFAR-100 show that\nDiffusion-FSCIL surpasses state-of-the-art methods, preserving performance on\npreviously learned classes and adapting effectively to new ones.", "comment": "6th CLVISION ICCV Workshop accepted", "pdf_url": "http://arxiv.org/pdf/2507.13739v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "合成图像能克服遗忘吗？超越小样本类增量学习中未探索的疑问", "tldr": "针对小样本类增量学习中数据有限和灾难性遗忘问题，本研究提出Diffusion-FSCIL，利用冻结的文本到图像扩散模型作为骨干，通过特征提取和回放，有效提升了性能并超越了现有SOTA方法。", "motivation": "小样本类增量学习(FSCIL)面临训练数据极度有限的挑战，同时需要减少灾难性遗忘并学习新信息。", "method": "本文提出Diffusion-FSCIL，一种新颖的方法，使用文本到图像扩散模型作为冻结骨干网络。该方法利用大型生成模型的生成能力（通过大规模预训练）、多尺度表示和文本编码器的表示灵活性来处理FSCIL。为了最大化表示能力，研究提出提取多个互补的扩散特征作为潜在回放，并辅以特征蒸馏以防止生成偏差。该框架通过使用冻结骨干、最小可训练组件和批量处理多特征提取来实现效率。", "result": "在CUB-200、miniImageNet和CIFAR-100上的大量实验表明，Diffusion-FSCIL超越了现有最先进的方法，在保留先前学习类别性能的同时，有效适应新类别。", "conclusion": "Diffusion-FSCIL通过利用扩散模型的强大能力，有效解决了小样本类增量学习中的灾难性遗忘问题，并实现了对新类别的有效学习，性能超越了现有方法。", "translation": "小样本类增量学习(FSCIL)由于训练数据极其有限而具有挑战性；同时旨在减少灾难性遗忘并学习新信息。我们提出Diffusion-FSCIL，一种新颖的方法，采用文本到图像扩散模型作为冻结骨干。我们的推测是，FSCIL可以利用大型生成模型的能力来解决，这得益于：1) 通过大规模预训练获得的生成能力；2) 多尺度表示；3) 通过文本编码器实现的表示灵活性。为了最大化表示能力，我们提出提取多个互补的扩散特征作为潜在回放，并辅以少量特征蒸馏以防止生成偏差。我们的框架通过1) 使用冻结骨干；2) 最少可训练组件；3) 批量处理多个特征提取来实现效率。在CUB-200、miniImageNet和CIFAR-100上进行的大量实验表明，Diffusion-FSCIL超越了现有最先进的方法，在先前学习的类别上保持了性能，并有效地适应了新类别。", "summary": "本文提出Diffusion-FSCIL，旨在解决小样本类增量学习(FSCIL)中数据稀缺和灾难性遗忘的挑战。该方法利用冻结的文本到图像扩散模型作为骨干，通过其生成能力、多尺度表示和文本编码器的灵活性来处理FSCIL。Diffusion-FSCIL通过提取互补扩散特征作为潜在回放并结合特征蒸馏来最大化表示能力，并通过冻结骨干和最小可训练组件实现效率。实验证明，Diffusion-FSCIL在多个数据集上超越了现有SOTA方法，有效保留了旧知识并适应了新类别。", "keywords": "小样本类增量学习, 扩散模型, 灾难性遗忘, 特征蒸馏, 增量学习", "comments": "这项工作创新性地将大型文本到图像扩散模型应用于小样本类增量学习，通过利用其强大的生成和表示能力来缓解灾难性遗忘。其效率提升的策略（冻结骨干、最小可训练组件）也值得关注，为未来研究提供了新思路。"}}
{"id": "2507.13977", "title": "Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic", "authors": ["Lilit Grigoryan", "Nikolay Karpov", "Enas Albasiri", "Vitaly Lavrukhin", "Boris Ginsburg"], "categories": ["cs.CL", "eess.AS", "I.5.1"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to ICASSP 2025", "url": "http://arxiv.org/abs/2507.13977v1", "summary": "Despite Arabic being one of the most widely spoken languages, the development\nof Arabic Automatic Speech Recognition (ASR) systems faces significant\nchallenges due to the language's complexity, and only a limited number of\npublic Arabic ASR models exist. While much of the focus has been on Modern\nStandard Arabic (MSA), there is considerably less attention given to the\nvariations within the language. This paper introduces a universal methodology\nfor Arabic speech and text processing designed to address unique challenges of\nthe language. Using this methodology, we train two novel models based on the\nFastConformer architecture: one designed specifically for MSA and the other,\nthe first unified public model for both MSA and Classical Arabic (CA). The MSA\nmodel sets a new benchmark with state-of-the-art (SOTA) performance on related\ndatasets, while the unified model achieves SOTA accuracy with diacritics for CA\nwhile maintaining strong performance for MSA. To promote reproducibility, we\nopen-source the models and their training recipes.", "comment": "Accepted to ICASSP 2025", "pdf_url": "http://arxiv.org/pdf/2507.13977v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "开放式古典和现代标准阿拉伯语自动语音识别模型", "tldr": "本文介绍了针对阿拉伯语语音和文本处理的通用方法，并基于FastConformer架构训练了两个新的开放式模型：一个专用于现代标准阿拉伯语（MSA），另一个是首个统一的MSA和古典阿拉伯语（CA）模型。这些模型在相关数据集上均达到了最先进的性能。", "motivation": "尽管阿拉伯语是使用最广泛的语言之一，但由于其复杂性，阿拉伯语自动语音识别（ASR）系统的开发面临巨大挑战，并且现有公开的阿拉伯语ASR模型数量有限。虽然大部分研究集中在现代标准阿拉伯语（MSA）上，但对语言内部变体的关注较少。", "method": "本文引入了一种通用的阿拉伯语语音和文本处理方法，旨在解决该语言特有的挑战。利用此方法，作者训练了两个基于FastConformer架构的新模型：一个专门用于MSA，另一个是首个统一的MSA和古典阿拉伯语（CA）公开模型。", "result": "MSA模型在相关数据集上取得了最先进（SOTA）的性能，并设定了新的基准。统一模型在古典阿拉伯语（CA）带发音符号的情况下实现了SOTA准确性，同时保持了对现代标准阿拉伯语（MSA）的强大性能。", "conclusion": "本文通过引入通用的阿拉伯语语音和文本处理方法，并训练出达到最先进性能的MSA专用模型和首个统一的MSA和CA模型，有效解决了阿拉伯语ASR的挑战。作者开源了模型及其训练方案，以促进研究的可复现性。", "translation": "尽管阿拉伯语是使用最广泛的语言之一，但由于其复杂性，阿拉伯语自动语音识别（ASR）系统的开发面临巨大挑战，并且现有公开的阿拉伯语ASR模型数量有限。虽然大部分研究集中在现代标准阿拉伯语（MSA）上，但对语言内部变体的关注较少。本文介绍了一种通用的阿拉伯语语音和文本处理方法，旨在解决该语言特有的挑战。利用此方法，我们训练了两个基于FastConformer架构的新模型：一个专门用于MSA，另一个是首个统一的现代标准阿拉伯语（MSA）和古典阿拉伯语（CA）公开模型。MSA模型在相关数据集上设定了新的最先进（SOTA）性能基准，而统一模型在古典阿拉伯语（CA）带发音符号的情况下实现了SOTA准确性，同时保持了对MSA的强大性能。为了促进可复现性，我们开源了这些模型及其训练方案。", "summary": "本文针对阿拉伯语ASR系统面临的挑战，提出了一种通用的阿拉伯语语音和文本处理方法。基于FastConformer架构，研究人员训练并开源了两个新型模型：一个专为现代标准阿拉伯语（MSA）设计，在相关数据集上实现了最先进性能；另一个是首个统一的MSA和古典阿拉伯语（CA）公开模型，在CA带发音符号的情况下达到了SOTA准确性，同时保持了MSA的强大性能。这些开放式模型旨在促进阿拉伯语ASR领域的研究和可复现性。", "keywords": "阿拉伯语ASR, 自动语音识别, 现代标准阿拉伯语, 古典阿拉伯语, FastConformer", "comments": "本文的创新之处在于提出了一个通用的阿拉伯语语音和文本处理方法，并首次开发了统一的现代标准阿拉伯语和古典阿拉伯语的公开ASR模型。其重要性体现在解决了阿拉伯语ASR领域模型稀缺和对语言变体关注不足的问题，并通过开源模型和训练方案极大地促进了研究的可复现性和社区协作。所达到的最先进性能也证明了其方法的有效性。"}}
{"id": "2503.20349", "title": "Consistency Trajectory Matching for One-Step Generative Super-Resolution", "authors": ["Weiyi You", "Mingyang Zhang", "Leheng Zhang", "Xingyu Zhou", "Kexuan Shi", "Shuhang Gu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ICCV 2025", "url": "http://arxiv.org/abs/2503.20349v4", "summary": "Current diffusion-based super-resolution (SR) approaches achieve commendable\nperformance at the cost of high inference overhead. Therefore, distillation\ntechniques are utilized to accelerate the multi-step teacher model into\none-step student model. Nevertheless, these methods significantly raise\ntraining costs and constrain the performance of the student model by the\nteacher model. To overcome these tough challenges, we propose Consistency\nTrajectory Matching for Super-Resolution (CTMSR), a distillation-free strategy\nthat is able to generate photo-realistic SR results in one step. Concretely, we\nfirst formulate a Probability Flow Ordinary Differential Equation (PF-ODE)\ntrajectory to establish a deterministic mapping from low-resolution (LR) images\nwith noise to high-resolution (HR) images. Then we apply the Consistency\nTraining (CT) strategy to directly learn the mapping in one step, eliminating\nthe necessity of pre-trained diffusion model. To further enhance the\nperformance and better leverage the ground-truth during the training process,\nwe aim to align the distribution of SR results more closely with that of the\nnatural images. To this end, we propose to minimize the discrepancy between\ntheir respective PF-ODE trajectories from the LR image distribution by our\nmeticulously designed Distribution Trajectory Matching (DTM) loss, resulting in\nimproved realism of our recovered HR images. Comprehensive experimental results\ndemonstrate that the proposed methods can attain comparable or even superior\ncapabilities on both synthetic and real datasets while maintaining minimal\ninference latency.", "comment": "Accepted by ICCV 2025", "pdf_url": "http://arxiv.org/pdf/2503.20349v4", "cate": "cs.CV", "date": "2025-03-26", "updated": "2025-07-18", "AI": {"title_translation": "一步生成超分辨率的一致性轨迹匹配", "tldr": "本文提出CTMSR，一种无需蒸馏的一步超分辨率方法，通过一致性训练和轨迹匹配，在低延迟下实现高质量的超分辨率结果。", "motivation": "当前基于扩散的超分辨率（SR）方法推理开销高昂，而蒸馏技术虽然能加速多步模型，但会显著增加训练成本并限制学生模型的性能。", "method": "本文提出超分辨率一致性轨迹匹配（CTMSR）方法。首先，构建一个概率流常微分方程（PF-ODE）轨迹，以建立从带噪声的低分辨率（LR）图像到高分辨率（HR）图像的确定性映射。然后，应用一致性训练（CT）策略直接一步学习该映射，无需预训练扩散模型。为进一步提升性能和利用真实值，引入分布轨迹匹配（DTM）损失，最小化SR结果与自然图像之间PF-ODE轨迹的差异，以提高恢复HR图像的真实感。", "result": "实验结果表明，所提出的方法在合成和真实数据集上均能达到可比甚至更优的性能，同时保持最小的推理延迟。", "conclusion": "CTMSR是一种有效的、无需蒸馏的一步超分辨率策略，能够以低延迟生成高质量的超分辨率结果。", "translation": "当前基于扩散的超分辨率（SR）方法以高推理开销为代价取得了值得称赞的性能。因此，蒸馏技术被用于将多步教师模型加速为一步学生模型。然而，这些方法显著提高了训练成本，并限制了学生模型的性能受教师模型的影响。为了克服这些严峻挑战，我们提出了一种用于超分辨率的一致性轨迹匹配（CTMSR）方法，这是一种无需蒸馏的策略，能够一步生成照片级真实的SR结果。具体来说，我们首先建立了一个概率流常微分方程（PF-ODE）轨迹，以建立从带有噪声的低分辨率（LR）图像到高分辨率（HR）图像的确定性映射。然后，我们应用一致性训练（CT）策略直接一步学习该映射，消除了对预训练扩散模型的必要性。为了进一步提高性能并在训练过程中更好地利用真实值，我们旨在使SR结果的分布更接近自然图像的分布。为此，我们提出通过我们精心设计的分布轨迹匹配（DTM）损失来最小化它们各自从LR图像分布的PF-ODE轨迹之间的差异，从而提高我们恢复的HR图像的真实感。全面的实验结果表明，所提出的方法在合成和真实数据集上都能达到可比甚至更优的能力，同时保持最小的推理延迟。", "summary": "本文提出了一种名为超分辨率一致性轨迹匹配（CTMSR）的新型无需蒸馏方法，用于一步生成超分辨率。针对现有扩散模型高推理开销和蒸馏技术训练成本高、性能受限的问题，CTMSR通过构建概率流常微分方程（PF-ODE）轨迹并应用一致性训练，直接学习从带噪声的低分辨率图像到高分辨率图像的一步确定性映射，无需预训练扩散模型。此外，引入分布轨迹匹配（DTM）损失，以使SR结果的分布更接近自然图像，从而提高真实感。实验证明，CTMSR在不同数据集上实现了可比或更优的性能，并保持了极低的推理延迟。", "keywords": "超分辨率, 扩散模型, 一致性训练, 轨迹匹配, 一步生成", "comments": "该论文的创新之处在于其无需蒸馏的一步超分辨率方法，有效解决了现有扩散模型的高推理成本和蒸馏技术带来的训练复杂性。通过利用PF-ODE轨迹和一致性训练，它简化了生成过程并提高了效率，同时DTM损失进一步增强了图像的真实感。这对于实现实用且实时的超高质量超分辨率具有重要意义。"}}
{"id": "2507.13616", "title": "From Firms to Computation: AI Governance and the Evolution of Institutions", "authors": ["Michael S. Harre"], "categories": ["cs.HC", "cs.CY", "cs.ET", "cs.IT", "cs.MA", "math.IT", "J.4; J.3; I.2.11"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      44 pages", "url": "http://arxiv.org/abs/2507.13616v1", "summary": "The integration of agential artificial intelligence into socioeconomic\nsystems requires us to reexamine the evolutionary processes that describe\nchanges in our economic institutions. This article synthesizes three\nframeworks: multi-level selection theory, Aoki's view of firms as computational\nprocesses, and Ostrom's design principles for robust institutions. We develop a\nframework where selection operates concurrently across organizational levels,\nfirms implement distributed inference via game-theoretic architectures, and\nOstrom-style rules evolve as alignment mechanisms that address AI-related\nrisks. This synthesis yields a multi-level Price equation expressed over nested\ngames, providing quantitative metrics for how selection and governance\nco-determine economic outcomes. We examine connections to Acemoglu's work on\ninclusive institutions, analyze how institutional structures shape AI\ndeployment, and demonstrate the framework's explanatory power via case studies.\nWe conclude by proposing a set of design principles that operationalize\nalignment between humans and AI across institutional layers, enabling scalable,\nadaptive, and inclusive governance of agential AI systems. We conclude with\npractical policy recommendations and further research to extend these\nprinciples into real-world implementation.", "comment": "44 pages", "pdf_url": "http://arxiv.org/pdf/2507.13616v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "从企业到计算：人工智能治理与制度演变", "tldr": "鉴于代理人工智能的整合，本文综合了现有框架，提出了一套新的设计原则和政策建议，以实现可扩展、适应性和包容性的人工智能治理。", "motivation": "由于代理人工智能与社会经济系统的整合，有必要重新审视描述经济制度变化的演化过程。", "method": "本文综合了多层次选择理论、青木将企业视为计算过程的观点以及奥斯特罗姆的稳健制度设计原则，开发了一个新的框架。该框架将选择在组织层面同时运作，企业通过博弈论架构实现分布式推理，并且奥斯特罗姆式的规则演变为人工智能对齐机制。这种综合产生了在嵌套博弈上表达的多层次普莱斯方程，并通过案例研究展示了其解释力。", "result": "该综合产生了一个在嵌套博弈上表达的多层次普莱斯方程，为选择和治理如何共同决定经济结果提供了定量指标。研究还考察了与阿西莫格鲁关于包容性制度工作的联系，分析了制度结构如何塑造人工智能部署，并通过案例研究展示了该框架的解释力。", "conclusion": "本文提出了一套设计原则，旨在跨制度层级操作化人与人工智能之间的对齐，从而实现代理人工智能系统的可扩展、适应性和包容性治理，并提供了实际的政策建议和进一步的研究方向。", "translation": "人工智能代理与社会经济系统的整合要求我们重新审视描述经济制度变化的演化过程。本文综合了三种框架：多层次选择理论、青木将企业视为计算过程的观点，以及奥斯特罗姆的稳健制度设计原则。我们开发了一个框架，其中选择在组织层面同时运作，企业通过博弈论架构实现分布式推理，奥斯特罗姆式的规则演变为解决人工智能相关风险的对齐机制。这种综合产生了一个在嵌套博弈上表达的多层次普莱斯方程，为选择和治理如何共同决定经济结果提供了定量指标。我们考察了与阿西莫格鲁关于包容性制度工作的联系，分析了制度结构如何塑造人工智能部署，并通过案例研究展示了该框架的解释力。最后，我们提出了一套设计原则，以在制度层面操作化人与人工智能之间的对齐，从而实现代理人工智能系统的可扩展、适应性和包容性治理。我们以实际的政策建议和进一步的研究作为结束，以将这些原则扩展到实际实施中。", "summary": "本文探讨了在代理人工智能融入社会经济系统背景下，重新审视经济制度演变过程的必要性。通过综合多层次选择理论、青木的企业计算观和奥斯特罗姆的设计原则，论文构建了一个新框架。该框架阐述了组织层面的并发选择、企业作为博弈论驱动的分布式推理系统，以及奥斯特罗姆式规则作为AI对齐机制的演变。研究引入了一个多层次普莱斯方程，用于量化选择和治理如何共同决定经济结果。论文还探讨了与包容性制度的关联，分析了制度结构对AI部署的影响，并通过案例研究验证了框架的解释力，最终提出了实现可扩展、适应性和包容性AI治理的设计原则和政策建议。", "keywords": "人工智能治理, 制度演变, 多层次选择, 普莱斯方程, 设计原则", "comments": "本文通过综合多层次选择理论、青木的企业计算观和奥斯特罗姆的设计原则，为人工智能治理这一当代挑战提供了一种创新的跨学科方法。其开发的多层次普莱斯方程，为理解在人工智能背景下选择和治理如何共同决定经济结果，提供了一个新颖的定量视角。论文对实际设计原则和政策建议的关注，使其对指导人工智能的负责任整合具有高度相关性。"}}
{"id": "2410.03993", "title": "TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction", "authors": ["Kojiro Takeyama", "Yimeng Liu", "Misha Sra"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Accepted to IROS 2025", "url": "http://arxiv.org/abs/2410.03993v4", "summary": "Accurate prediction of human behavior is crucial for AI systems to\neffectively support real-world applications, such as autonomous robots\nanticipating and assisting with human tasks. Real-world scenarios frequently\npresent challenges such as occlusions and incomplete scene observations, which\ncan compromise predictive accuracy. Thus, traditional video-based methods often\nstruggle due to limited temporal and spatial perspectives. Large Language\nModels (LLMs) offer a promising alternative. Having been trained on a large\ntext corpus describing human behaviors, LLMs likely encode plausible sequences\nof human actions in a home environment. However, LLMs, trained primarily on\ntext data, lack inherent spatial awareness and real-time environmental\nperception. They struggle with understanding physical constraints and spatial\ngeometry. Therefore, to be effective in a real-world spatial scenario, we\npropose a multimodal prediction framework that enhances LLM-based action\nprediction by integrating physical constraints derived from human trajectories.\nOur experiments demonstrate that combining LLM predictions with trajectory data\nsignificantly improves overall prediction performance. This enhancement is\nparticularly notable in situations where the LLM receives limited scene\ninformation, highlighting the complementary nature of linguistic knowledge and\nphysical constraints in understanding and anticipating human behavior.", "comment": "Accepted to IROS 2025", "pdf_url": "http://arxiv.org/pdf/2410.03993v4", "cate": "cs.HC", "date": "2024-10-05", "updated": "2025-07-18", "AI": {"title_translation": "TR-LLM：融合轨迹数据用于场景感知型LLM人类行为预测", "tldr": "该研究提出TR-LLM，通过整合轨迹数据来增强LLM在有限场景信息下的人类行为预测能力，显著提升了预测性能。", "motivation": "现有AI系统在预测人类行为时面临遮挡和不完整场景观察的挑战，传统视频方法受时空限制。大型语言模型（LLMs）虽然能编码人类行为序列，但缺乏空间感知和实时环境感知能力，难以理解物理约束和空间几何。因此，需要一种结合LLM和物理约束的方法来提高真实世界空间场景中的预测效果。", "method": "提出一个多模态预测框架，通过整合来自人类轨迹的物理约束来增强基于LLM的动作预测。", "result": "实验证明，将LLM预测与轨迹数据结合显著提高了整体预测性能，尤其是在LLM接收到有限场景信息的情况下。", "conclusion": "结合语言知识和物理约束（轨迹数据）在理解和预测人类行为方面具有互补性，能显著提升LLM在复杂真实世界场景中的行为预测能力。", "translation": "准确预测人类行为对于AI系统有效支持现实世界应用至关重要，例如自主机器人预测和协助人类任务。现实世界场景经常出现遮挡和不完整的场景观察等挑战，这会损害预测准确性。因此，传统的基于视频的方法由于有限的时间和空间视角而常常力不从心。大型语言模型（LLM）提供了一个有前景的替代方案。LLM经过大量描述人类行为的文本语料库训练，可能编码了家庭环境中人类行为的合理序列。然而，LLM主要通过文本数据训练，缺乏固有的空间意识和实时环境感知能力。它们在理解物理约束和空间几何方面存在困难。因此，为了在现实世界空间场景中有效，我们提出了一个多模态预测框架，通过整合从人类轨迹中获得的物理约束来增强基于LLM的动作预测。我们的实验表明，将LLM预测与轨迹数据结合显著提高了整体预测性能。这种增强在LLM接收到有限场景信息的情况下尤为显著，突显了语言知识和物理约束在理解和预测人类行为方面的互补性。", "summary": "本文提出TR-LLM框架，旨在解决大型语言模型在人类行为预测中缺乏空间感知和物理约束理解的问题。通过将LLM的语言知识与人类轨迹数据提供的物理约束相结合，该多模态预测框架显著提升了在复杂或信息有限场景下的人类行为预测准确性，证明了两种信息源的互补性。", "keywords": "人类行为预测, 大型语言模型, 轨迹数据, 多模态融合, 场景感知", "comments": "该论文的创新点在于将LLM的语义理解能力与轨迹数据提供的物理空间信息相结合，弥补了LLM在空间感知方面的不足。这对于提升AI系统在真实世界复杂环境中（如机器人辅助）预测人类行为的鲁棒性和准确性具有重要意义。该方法通过多模态融合，为解决LLM在具身智能应用中的局限性提供了一个有效途径。"}}
{"id": "2507.13992", "title": "Structural Connectome Harmonization Using Deep Learning: The Strength of Graph Neural Networks", "authors": ["Jagruti Patel", "Thomas A. W. Bolton", "Mikkel Schöttner", "Anjali Tarun", "Sebastien Tourbier", "Yasser Alemàn-Gòmez", "Jonas Richiardi", "Patric Hagmann"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13992v1", "summary": "Small sample sizes in neuroimaging in general, and in structural connectome\n(SC) studies in particular limit the development of reliable biomarkers for\nneurological and psychiatric disorders - such as Alzheimer's disease and\nschizophrenia - by reducing statistical power, reliability, and\ngeneralizability. Large-scale multi-site studies have exist, but they have\nacquisition-related biases due to scanner heterogeneity, compromising imaging\nconsistency and downstream analyses. While existing SC harmonization methods -\nsuch as linear regression (LR), ComBat, and deep learning techniques - mitigate\nthese biases, they often rely on detailed metadata, traveling subjects (TS), or\noverlook the graph-topology of SCs. To address these limitations, we propose a\nsite-conditioned deep harmonization framework that harmonizes SCs across\ndiverse acquisition sites without requiring metadata or TS that we test in a\nsimulated scenario based on the Human Connectome Dataset. Within this\nframework, we benchmark three deep architectures - a fully connected\nautoencoder (AE), a convolutional AE, and a graph convolutional AE - against a\ntop-performing LR baseline. While non-graph models excel in edge-weight\nprediction and edge existence detection, the graph AE demonstrates superior\npreservation of topological structure and subject-level individuality, as\nreflected by graph metrics and fingerprinting accuracy, respectively. Although\nthe LR baseline achieves the highest numerical performance by explicitly\nmodeling acquisition parameters, it lacks applicability to real-world\nmulti-site use cases as detailed acquisition metadata is often unavailable. Our\nresults highlight the critical role of model architecture in SC harmonization\nperformance and demonstrate that graph-based approaches are particularly\nwell-suited for structure-aware, domain-generalizable SC harmonization in\nlarge-scale multi-site SC studies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13992v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用深度学习进行结构连接组协调：图神经网络的优势", "tldr": "本研究提出了一种基于深度学习的结构连接组（SC）协调框架，无需元数据或旅行受试者，解决了多站点神经影像数据中的采集偏差问题。研究发现，图神经网络在保留SC拓扑结构和个体特异性方面优于非图模型，是大规模多站点SC研究中结构感知、领域可泛化协调的理想选择。", "motivation": "神经影像学，特别是结构连接组（SC）研究中样本量小，限制了可靠生物标志物的开发，降低了统计效力、可靠性和泛化能力。大型多站点研究存在采集相关偏差（扫描仪异质性），影响图像一致性和后续分析。现有SC协调方法（如线性回归、ComBat和深度学习技术）虽然能缓解这些偏差，但通常依赖详细元数据、旅行受试者，或忽略SC的图拓扑结构。", "method": "提出了一种基于站点条件的深度协调框架，用于在不需要元数据或旅行受试者的情况下，协调不同采集站点的SC数据。该框架在基于人类连接组数据集的模拟场景中进行了测试。在该框架内，将三种深度架构（全连接自编码器、卷积自编码器和图卷积自编码器）与表现最佳的线性回归基线进行了基准测试。", "result": "非图模型在边缘权重预测和边缘存在检测方面表现出色。图自编码器在保留拓扑结构和受试者个体特异性方面表现优异（分别通过图指标和指纹识别精度反映）。线性回归基线通过明确建模采集参数实现了最高的数值性能，但由于详细采集元数据通常不可用，其在真实世界多站点用例中缺乏适用性。", "conclusion": "研究结果强调了模型架构在SC协调性能中的关键作用，并表明基于图的方法特别适用于大规模多站点SC研究中结构感知、领域可泛化的SC协调。", "translation": "神经影像学，特别是结构连接组（SC）研究中样本量小，限制了阿尔茨海默病和精神分裂症等神经和精神疾病可靠生物标志物的开发，因为它降低了统计效力、可靠性和泛化能力。虽然存在大型多站点研究，但由于扫描仪异质性，它们存在采集相关偏差，损害了成像一致性和下游分析。虽然现有的SC协调方法（如线性回归（LR）、ComBat和深度学习技术）可以缓解这些偏差，但它们通常依赖详细元数据、旅行受试者（TS），或忽略SC的图拓扑结构。为了解决这些限制，我们提出了一种基于站点条件的深度协调框架，该框架无需元数据或TS即可协调不同采集站点的SC，并在基于人类连接组数据集的模拟场景中进行了测试。在该框架内，我们对比了三种深度架构——全连接自编码器（AE）、卷积AE和图卷积AE——与表现最佳的LR基线。虽然非图模型在边缘权重预测和边缘存在检测方面表现出色，但图AE在保留拓扑结构和受试者个体特异性方面表现出卓越的性能，分别通过图指标和指纹识别精度反映。尽管LR基线通过明确建模采集参数实现了最高的数值性能，但由于详细采集元数据通常不可用，其在真实世界多站点用例中缺乏适用性。我们的结果强调了模型架构在SC协调性能中的关键作用，并表明基于图的方法特别适用于大规模多站点SC研究中结构感知、领域可泛化SC协调。", "summary": "本研究旨在解决神经影像学中结构连接组（SC）多站点数据采集偏差问题，这些偏差限制了生物标志物的开发。针对现有协调方法对元数据和旅行受试者的依赖以及对SC图拓扑结构的忽视，作者提出了一种无需这些条件的深度协调框架。该框架在模拟场景中测试了多种深度学习架构，并发现图卷积自编码器在保留SC拓扑结构和个体特异性方面表现最佳。尽管线性回归在数值上表现优异，但其对元数据的依赖限制了实际应用。研究强调了模型架构在SC协调中的关键作用，并指出图神经网络是实现结构感知和领域泛化SC协调的有效途径。", "keywords": "结构连接组, 协调, 深度学习, 图神经网络, 多站点研究", "comments": "这项研究的创新之处在于提出了一种不依赖详细元数据或旅行受试者的深度学习SC协调框架，这对于真实世界的多站点神经影像研究具有重要意义。特别地，它强调了图神经网络在处理SC这类具有固有图拓扑结构的数据时的优越性，能够更好地保留关键的结构信息和个体差异，这对于开发可靠的神经生物标志物至关重要。该工作为未来大规模、多站点神经影像数据分析提供了有价值的方向。"}}
{"id": "2507.13357", "title": "Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models", "authors": ["Atharva Bhargude", "Ishan Gonehal", "Chandler Haney", "Dave Yoon", "Kevin Zhu", "Aaron Sandoval", "Sean O'Brien", "Kaustubh Vinnakota"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Published at ACL 2025 SRW, 9 pages, 3 figures", "url": "http://arxiv.org/abs/2507.13357v1", "summary": "Phishing attacks represent a significant cybersecurity threat, necessitating\nadaptive detection techniques. This study explores few-shot Adaptive Linguistic\nPrompting (ALP) in detecting phishing webpages through the multimodal\ncapabilities of state-of-the-art large language models (LLMs) such as GPT-4o\nand Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides\nLLMs to analyze textual deception by breaking down linguistic patterns,\ndetecting urgency cues, and identifying manipulative diction commonly found in\nphishing content. By integrating textual, visual, and URL-based analysis, we\npropose a unified model capable of identifying sophisticated phishing attempts.\nOur experiments demonstrate that ALP significantly enhances phishing detection\naccuracy by guiding LLMs through structured reasoning and contextual analysis.\nThe findings highlight the potential of ALP-integrated multimodal LLMs to\nadvance phishing detection frameworks, achieving an F1-score of 0.93,\nsurpassing traditional approaches. These results establish a foundation for\nmore robust, interpretable, and adaptive linguistic-based phishing detection\nsystems using LLMs.", "comment": "Published at ACL 2025 SRW, 9 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.13357v1", "cate": "cs.CL", "date": "2025-06-29", "updated": "2025-06-29", "AI": {"title_translation": "自适应语言提示 (ALP) 增强多模态大型语言模型中的网络钓鱼网页检测", "tldr": "ALP通过结构化语义推理显著提升多模态LLM的网络钓鱼检测准确性。", "motivation": "网络钓鱼攻击是重大的网络安全威胁，需要自适应检测技术。", "method": "本研究提出自适应语言提示 (ALP)，这是一种结构化语义推理方法，旨在通过分解语言模式、检测紧急提示和识别操控性措辞来指导GPT-4o和Gemini 1.5 Pro等多模态大型语言模型（LLMs）分析文本欺骗。该方法整合了文本、视觉和URL分析，以识别复杂的网络钓鱼尝试。", "result": "实验证明，ALP通过结构化推理和上下文分析显著提高了网络钓鱼检测准确性，实现了0.93的F1分数，超越了传统方法。", "conclusion": "ALP与多模态LLM的结合为更鲁棒、可解释和自适应的基于语言的网络钓鱼检测系统奠定了基础。", "translation": "网络钓鱼攻击构成了重大的网络安全威胁，因此需要自适应的检测技术。本研究探讨了少样本自适应语言提示（ALP）在通过GPT-4o和Gemini 1.5 Pro等先进大型语言模型（LLMs）的多模态能力检测网络钓鱼网页方面的应用。ALP是一种结构化语义推理方法，它通过分解语言模式、检测紧急提示和识别网络钓鱼内容中常见的操控性措辞来指导LLMs分析文本欺骗。通过整合文本、视觉和基于URL的分析，我们提出了一个能够识别复杂网络钓鱼尝试的统一模型。我们的实验表明，ALP通过结构化推理和上下文分析显著提高了网络钓鱼检测的准确性。研究结果突出了ALP集成的多模态LLMs在推进网络钓鱼检测框架方面的潜力，实现了0.93的F1分数，超越了传统方法。这些结果为使用LLMs构建更鲁棒、可解释和自适应的基于语言的网络钓鱼检测系统奠定了基础。", "summary": "本文提出了一种名为自适应语言提示 (ALP) 的方法，旨在增强多模态大型语言模型（如GPT-4o和Gemini 1.5 Pro）在网络钓鱼网页检测中的能力。ALP通过结构化语义推理，引导LLM分析文本欺骗中的语言模式、紧急提示和操控性措辞，并整合文本、视觉和URL分析。实验结果显示，ALP显著提高了检测准确性，F1-score达到0.93，优于传统方法，为未来更鲁棒、可解释的网络钓鱼检测系统奠定了基础。", "keywords": "网络钓鱼检测, 多模态LLM, 自适应语言提示, 语义推理, 网络安全", "comments": "这项研究通过引入自适应语言提示（ALP），巧妙地利用了多模态大型语言模型在处理复杂网络钓鱼攻击方面的潜力。其创新点在于将结构化语义推理与LLM的多模态能力相结合，有效提升了检测准确性和可解释性。F1-score达到0.93的成果表明该方法在实际应用中具有显著优势，为网络安全领域提供了一个有前景的新方向。"}}
{"id": "2504.02768", "title": "MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs", "authors": ["Jaap Jumelet", "Leonie Weissweiler", "Joakim Nivre", "Arianna Bisazza"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.02768v2", "summary": "We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic\nminimal pairs, covering 101 languages and 2 types of subject-verb agreement,\ncontaining more than 128,000 minimal pairs. Our minimal pairs are created using\na fully automated pipeline, leveraging the large-scale linguistic resources of\nUniversal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMs\nat an unprecedented multilingual scale, and highlights the shortcomings of the\ncurrent state-of-the-art in modelling low-resource languages", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.02768v2", "cate": "cs.CL", "date": "2025-04-03", "updated": "2025-07-18", "AI": {"title_translation": "MultiBLiMP 1.0：一个大规模多语言语言学最小对基准", "tldr": "MultiBLiMP 1.0是一个涵盖101种语言、超过128,000个语言学最小对的大规模多语言基准，用于评估大型语言模型（LLMs）的能力，并揭示了LLMs在低资源语言建模方面的不足。", "motivation": "该论文旨在引入MultiBLiMP 1.0，一个大规模多语言语言学最小对基准，以评估大型语言模型（LLMs）在空前多语言规模下的能力，并揭示当前最先进模型在建模低资源语言方面的不足。", "method": "MultiBLiMP 1.0通过一个完全自动化的流程创建，利用Universal Dependencies和UniMorph的大规模语言资源。它涵盖了101种语言和2种主谓一致类型，包含超过128,000个语言学最小对。", "result": "MultiBLiMP 1.0能够以前所未有的多语言规模评估大型语言模型（LLMs）的能力，并突出了当前最先进模型在建模低资源语言方面的不足。", "conclusion": "该研究得出的结论是，当前最先进的大型语言模型在处理和建模低资源语言方面存在明显的不足。", "translation": "我们引入了MultiBLiMP 1.0，这是一个大规模多语言语言学最小对基准，涵盖101种语言和2种主谓一致类型，包含超过128,000个最小对。我们的最小对是使用一个完全自动化的管道创建的，该管道利用了Universal Dependencies和UniMorph的大规模语言资源。MultiBLiMP 1.0以前所未有的多语言规模评估了大型语言模型（LLMs）的能力，并突出了当前最先进模型在建模低资源语言方面的不足。", "summary": "MultiBLiMP 1.0是一个新推出的大规模多语言语言学最小对基准，包含101种语言和超过128,000个最小对，涵盖2种主谓一致类型。该基准通过自动化流程利用Universal Dependencies和UniMorph创建，旨在以前所未有的多语言规模评估大型语言模型（LLMs），并揭示了当前LLMs在低资源语言建模方面的局限性。", "keywords": "MultiBLiMP, 多语言基准, 语言学最小对, LLMs, 低资源语言", "comments": "MultiBLiMP 1.0的创新之处在于其大规模的多语言覆盖（101种语言）和自动化的最小对生成管道，这使其能够高效地创建大量高质量的语言数据。其重要性在于为评估大型语言模型在跨语言理解，特别是低资源语言方面的能力提供了一个全面的基准，突出了现有技术的局限性，为未来的研究指明了方向。"}}
{"id": "2507.13883", "title": "Stablecoins: Fundamentals, Emerging Issues, and Open Challenges", "authors": ["Ahmed Mahrous", "Maurantonio Caprolu", "Roberto Di Pietro"], "categories": ["econ.GN", "cs.CR", "q-fin.EC"], "primary_category": "Subjects:       General Economics (econ.GN)", "pdf_link": null, "comments": "Comments:      35 pages, 10 figures. Survey paper. Submitted to Computer Science Review", "url": "http://arxiv.org/abs/2507.13883v1", "summary": "Stablecoins, with a capitalization exceeding 200 billion USD as of January\n2025, have shown significant growth, with annual transaction volumes exceeding\n10 trillion dollars in 2023 and nearly doubling that figure in 2024. This\nexceptional success has attracted the attention of traditional financial\ninstitutions, with an increasing number of governments exploring the potential\nof Central Bank Digital Currencies (CBDCs). Although academia has recognized\nthe importance of stablecoins, research in this area remains fragmented,\nincomplete, and sometimes contradictory. In this paper, we aim to address the\ncited gap with a structured literature analysis, correlating recent\ncontributions to present a picture of the complex economic, technical, and\nregulatory aspects of stablecoins. To achieve this, we formulate the main\nresearch questions and categorize scientific contributions accordingly,\nidentifying main results, data sources, methodologies, and open research\nquestions. The research questions we address in this survey paper cover several\ntopics, such as the stability of various stablecoins, novel designs and\nimplementations, and relevant regulatory challenges. The studies employ a wide\nrange of methodologies and data sources, which we critically analyze and\nsynthesize. Our analysis also reveals significant research gaps, including\nlimited studies on security and privacy, underexplored stablecoins, unexamined\nfailure cases, unstudied governance mechanisms, and the treatment of\nstablecoins under financial accounting standards, among other areas.", "comment": "35 pages, 10 figures. Survey paper. Submitted to Computer Science\n  Review", "pdf_url": "http://arxiv.org/pdf/2507.13883v1", "cate": "econ.GN", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "稳定币：基本原理、新兴问题与开放挑战", "tldr": "鉴于稳定币的快速增长和现有研究的碎片化，本文旨在通过结构化文献分析，全面概述稳定币的经济、技术和监管方面，并识别研究空白。", "motivation": "稳定币市场增长显著，吸引了传统金融机构和政府关注，但学术研究仍分散、不完整且矛盾。本文旨在填补这一空白，对现有文献进行结构化分析。", "method": "采用结构化文献分析方法，关联近期贡献，提出主要研究问题，并据此对科学贡献进行分类，识别主要结果、数据源、方法论和开放研究问题。对各种方法和数据源进行批判性分析和综合。", "result": "分析揭示了稳定币复杂的经济、技术和监管方面。同时，也发现了显著的研究空白，包括安全和隐私研究有限、部分稳定币未被充分探索、失败案例未被研究、治理机制未被考察以及在金融会计标准下的处理等。", "conclusion": "本文通过结构化文献分析，全面概述了稳定币领域，并系统性地识别了当前研究的不足和未来的研究方向。", "translation": "稳定币：基本原理、新兴问题与开放挑战\n\n稳定币，截至2025年1月市值已超过2000亿美元，显示出显著增长，2023年年度交易额超过10万亿美元，2024年几乎翻倍。这一卓越的成功吸引了传统金融机构的关注，越来越多的政府正在探索央行数字货币（CBDC）的潜力。尽管学术界已认识到稳定币的重要性，但该领域的研究仍然碎片化、不完整，有时甚至相互矛盾。在本文中，我们旨在通过结构化文献分析来解决上述空白，关联近期贡献以呈现稳定币复杂的经济、技术和监管方面的全貌。为此，我们提出了主要研究问题，并据此对科学贡献进行分类，识别主要结果、数据来源、方法论和开放研究问题。本综述论文中涉及的研究问题涵盖了多个主题，例如各种稳定币的稳定性、新颖的设计和实现，以及相关的监管挑战。这些研究采用了广泛的方法论和数据来源，我们对此进行了批判性分析和综合。我们的分析还揭示了显著的研究空白，包括对安全性与隐私的研究有限、未被充分探索的稳定币、未被审查的失败案例、未被研究的治理机制以及在金融会计标准下对稳定币的处理等领域。", "summary": "本文旨在通过结构化文献分析，填补当前稳定币研究碎片化、不完整的空白。鉴于稳定币市场的巨大增长和其在传统金融中的日益重要性，作者对现有文献进行了系统性梳理，提出了核心研究问题，并分类、批判性地分析了相关贡献、方法论和数据源。研究揭示了稳定币复杂的经济、技术和监管维度，并指出了包括安全性、隐私、失败案例、治理机制和会计处理等在内的重要研究空白。", "keywords": "稳定币, 文献综述, 金融科技, 中央银行数字货币, 监管", "comments": "这篇综述文章非常及时且重要，它系统地梳理了快速发展的稳定币领域，识别了现有研究的不足和未来的研究方向。其价值在于为后续研究提供了清晰的路线图，尤其是在安全、隐私、治理和会计等关键但尚未充分探索的领域。对于政策制定者和研究人员来说，这是一份宝贵的资源。"}}
{"id": "2507.13386", "title": "Minimalist Concept Erasure in Generative Models", "authors": ["Yang Zhang", "Er Jin", "Yanfei Dong", "Yixuan Wu", "Philip Torr", "Ashkan Khakzar", "Johannes Stegmaier", "Kenji Kawaguchi"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ICML2025", "url": "http://arxiv.org/abs/2507.13386v1", "summary": "Recent advances in generative models have demonstrated remarkable\ncapabilities in producing high-quality images, but their reliance on\nlarge-scale unlabeled data has raised significant safety and copyright\nconcerns. Efforts to address these issues by erasing unwanted concepts have\nshown promise. However, many existing erasure methods involve excessive\nmodifications that compromise the overall utility of the model. In this work,\nwe address these issues by formulating a novel minimalist concept erasure\nobjective based \\emph{only} on the distributional distance of final generation\noutputs. Building on our formulation, we derive a tractable loss for\ndifferentiable optimization that leverages backpropagation through all\ngeneration steps in an end-to-end manner. We also conduct extensive analysis to\nshow theoretical connections with other models and methods. To improve the\nrobustness of the erasure, we incorporate neuron masking as an alternative to\nmodel fine-tuning. Empirical evaluations on state-of-the-art flow-matching\nmodels demonstrate that our method robustly erases concepts without degrading\noverall model performance, paving the way for safer and more responsible\ngenerative models.", "comment": "ICML2025", "pdf_url": "http://arxiv.org/pdf/2507.13386v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "生成模型中的极简主义概念擦除", "tldr": "提出一种新的极简主义概念擦除方法，通过仅基于生成输出的分布距离来擦除不需要的概念，同时不损害模型性能，从而实现更安全、负责任的生成模型。", "motivation": "现有的生成模型在高质量图像生成方面能力显著，但其对大规模无标签数据的依赖引发了严重的安全和版权问题。虽然现有擦除方法有希望，但它们涉及过度修改，损害了模型的整体效用。", "method": "本文提出一种基于最终生成输出的分布距离的极简主义概念擦除目标，并推导出一个可处理的损失，用于可微分优化，该优化以端到端的方式利用所有生成步骤的反向传播。此外，为提高擦除的鲁棒性，还结合了神经元掩蔽作为模型微调的替代方案。", "result": "在最先进的流匹配模型上的实证评估表明，所提出的方法能够鲁棒地擦除概念，而不会降低整体模型性能。", "conclusion": "该方法为更安全、更负责任的生成模型铺平了道路。", "translation": "生成模型在生成高质量图像方面展现出卓越的能力，但它们对大规模无标签数据的依赖引发了严重的安全和版权问题。通过擦除不需要的概念来解决这些问题的努力已显示出前景。然而，许多现有的擦除方法涉及过度修改，损害了模型的整体模型效用。在这项工作中，我们通过提出一种新颖的极简主义概念擦除目标来解决这些问题，该目标仅基于最终生成输出的分布距离。在此公式的基础上，我们推导出一个可处理的损失，用于可微分优化，该优化以端到端的方式利用所有生成步骤的反向传播。我们还进行了广泛的分析，以展示与其他模型和方法的理论联系。为了提高擦除的鲁棒性，我们将神经元掩蔽作为模型微调的替代方案。在最先进的流匹配模型上的实证评估表明，我们的方法能够鲁棒地擦除概念，而不会降低整体模型性能，从而为更安全、更负责任的生成模型铺平了道路。", "summary": "本文提出一种新颖的极简主义概念擦除方法，旨在解决生成模型中不必要的概念（如安全和版权问题）的擦除问题，同时避免现有方法过度修改模型的问题。该方法的核心是基于最终生成输出的分布距离来定义擦除目标，并利用端到端反向传播进行优化。为增强鲁棒性，引入了神经元掩蔽。实验证明，该方法能在不损害模型整体性能的情况下有效擦除概念，有助于构建更安全、更负责任的生成模型。", "keywords": "概念擦除, 生成模型, 分布距离, 神经元掩蔽, 模型安全", "comments": "该论文的创新点在于提出了“极简主义概念擦除”的概念，通过仅关注生成输出的分布距离来避免对模型进行过度修改，这在保持模型效用方面具有重要意义。引入神经元掩蔽替代微调也增加了方法的可行性和鲁棒性。这对于解决生成模型的伦理和法律问题具有实际应用价值。"}}
{"id": "2507.13648", "title": "EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation", "authors": ["Seungjun Moon", "Sangjoon Yu", "Gyeong-Moon Park"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13648v1", "summary": "The rapid advancement of neural radiance fields (NeRF) has paved the way to\ngenerate animatable human avatars from a monocular video. However, the sole\nusage of NeRF suffers from a lack of details, which results in the emergence of\nhybrid representation that utilizes SMPL-based mesh together with NeRF\nrepresentation. While hybrid-based models show photo-realistic human avatar\ngeneration qualities, they suffer from extremely slow inference due to their\ndeformation scheme: to be aligned with the mesh, hybrid-based models use the\ndeformation based on SMPL skinning weights, which needs high computational\ncosts on each sampled point. We observe that since most of the sampled points\nare located in empty space, they do not affect the generation quality but\nresult in inference latency with deformation. In light of this observation, we\npropose EPSilon, a hybrid-based 3D avatar generation scheme with novel\nefficient point sampling strategies that boost both training and inference. In\nEPSilon, we propose two methods to omit empty points at rendering; empty ray\nomission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that\nprogress through the empty space. Then, EIO narrows down the sampling interval\non the ray, which wipes out the region not occupied by either clothes or mesh.\nThe delicate sampling scheme of EPSilon enables not only great computational\ncost reduction during deformation but also the designation of the important\nregions to be sampled, which enables a single-stage NeRF structure without\nhierarchical sampling. Compared to existing methods, EPSilon maintains the\ngeneration quality while using only 3.9% of sampled points and achieves around\n20 times faster inference, together with 4 times faster training convergence.\nWe provide video results on https://github.com/seungjun-moon/epsilon.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13648v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "EPSilon：用于混合式3D头像生成加速的高效点采样", "tldr": "EPSilon提出了一种高效点采样策略，显著加速了混合式3D头像生成模型的训练和推理，同时保持了生成质量。", "motivation": "现有混合式3D头像生成模型由于其基于SMPL蒙皮权重的变形方案，在推理时计算成本高昂，导致速度极慢，因为大部分采样点位于空旷空间，不影响质量但增加了延迟。", "method": "本文提出了EPSilon，一种具有新型高效点采样策略的混合式3D头像生成方案。它包含两种方法来省略空旷点：空射线省略（ERO）和空区间省略（EIO）。ERO消除穿过空旷空间的射线，而EIO缩小射线上的采样区间，排除未被衣物或网格占据的区域。这种精细的采样方案减少了变形期间的计算成本，并指定了重要采样区域，实现了无需分层采样的单阶段NeRF结构。", "result": "与现有方法相比，EPSilon在保持生成质量的同时，仅使用3.9%的采样点，实现了约20倍的推理速度提升和4倍的训练收敛速度提升。", "conclusion": "EPSilon通过创新的高效点采样策略，显著解决了混合式3D头像生成模型推理速度慢的问题，在不牺牲质量的前提下大幅提升了效率，并简化了NeRF结构。", "translation": "神经辐射场（NeRF）的快速发展为从单目视频生成可动画人体头像铺平了道路。然而，单独使用NeRF缺乏细节，这导致了结合基于SMPL网格和NeRF表示的混合表示的出现。虽然混合模型显示出逼真的人体头像生成质量，但由于其变形方案而导致推理速度极慢：为了与网格对齐，混合模型使用基于SMPL蒙皮权重的变形，这在每个采样点上都需要高计算成本。我们观察到，由于大多数采样点位于空旷空间，它们不影响生成质量但导致变形的推理延迟。鉴于这一观察，我们提出了EPSilon，一种具有新型高效点采样策略的混合式3D头像生成方案，可提高训练和推理速度。在EPSilon中，我们提出了两种方法来省略渲染时的空旷点；空射线省略（ERO）和空区间省略（EIO）。在ERO中，我们消除穿过空旷空间的射线。然后，EIO缩小射线上的采样区间，这消除了未被衣物或网格占据的区域。EPSilon的精细采样方案不仅大大降低了变形期间的计算成本，而且指定了要采样的重要区域，这使得单阶段NeRF结构无需分层采样。与现有方法相比，EPSilon在保持生成质量的同时，仅使用3.9%的采样点，并实现了约20倍的推理速度提升，以及4倍的训练收敛速度提升。我们在https://github.com/seungjun-moon/epsilon上提供了视频结果。", "summary": "该论文提出了EPSilon，一种针对混合式3D头像生成模型的高效点采样策略。针对现有混合模型因大量空旷点导致推理速度慢的问题，EPSilon引入了空射线省略（ERO）和空区间省略（EIO）两种方法，以智能地跳过不重要的采样区域。这不仅大幅降低了变形计算成本，还使得NeRF结构无需分层采样。实验结果表明，EPSilon在保持生成质量的同时，将采样点减少至3.9%，实现了20倍的推理加速和4倍的训练加速。", "keywords": "3D头像生成, 神经辐射场, 点采样, 混合模型, 效率", "comments": "EPSilon的创新之处在于其对混合式3D头像生成中计算瓶颈的深刻洞察——即大量采样点位于空旷空间。通过提出ERO和EIO这两种简单而有效的方法来优化采样过程，它显著提升了现有方法的效率。这种优化不仅体现在速度上，还简化了模型结构（无需分层采样），这对于实际应用具有重要意义。该工作为未来实时、高质量的3D头像生成奠定了基础。"}}
{"id": "2507.13510", "title": "Strassen $2\\times2$ Matrix Multiplication from a 3-dimensional Volume Form", "authors": ["Benoit Jacob"], "categories": ["cs.DS", "cs.CC", "15A69 (Primary), 15A15, 14N07 (Secondary)"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.13510v1", "summary": "The Strassen $2\\times2$ matrix multiplication algorithm arises from the\nvolume form on the 3-dimensional quotient space of the $2\\times 2$ matrices by\nthe multiples of identity.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.13510v1", "cate": "cs.DS", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "施特拉森 $2\\times2$ 矩阵乘法源于三维体积形式", "tldr": "施特拉森 $2\\times2$ 矩阵乘法算法与三维体积形式存在内在联系。", "motivation": "Not mentioned in abstract", "method": "通过分析 $2\\times2$ 矩阵通过单位倍数的三维商空间上的体积形式。", "result": "Strassen $2\\times2$ 矩阵乘法算法源于 $2\\times2$ 矩阵通过单位倍数的三维商空间上的体积形式。", "conclusion": "Strassen $2\\times2$ 矩阵乘法算法可以从三维体积形式的角度来理解。", "translation": "施特拉森 $2\\times2$ 矩阵乘法算法源于 $2\\times2$ 矩阵通过单位矩阵倍数的三维商空间上的体积形式。", "summary": "本文指出，经典的施特拉森 $2\\times2$ 矩阵乘法算法可以从 $2\\times2$ 矩阵通过单位倍数的三维商空间上的体积形式中推导出来。", "keywords": "Strassen算法, 矩阵乘法, 体积形式, 商空间, 几何解释", "comments": "这篇论文提供了一个关于施特拉森 $2\\times2$ 矩阵乘法算法的独特几何解释，将其与三维体积形式联系起来，可能为理解和探索矩阵乘法算法提供了新的视角。"}}
{"id": "2507.13644", "title": "Multiphysics embedding localized orthogonal decomposition for thermomechanical coupling problems", "authors": ["Yuzhou Nan", "Yajun Wang", "Changqing Ye", "Xiaofei Guan"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13644v1", "summary": "Multiscale modeling and analysis of multiphysics coupling processes in highly\nheterogeneous media present significant challenges. In this paper, we propose a\nnovel multiphysics embedding localized orthogonal decomposition (ME-LOD) method\nfor solving thermomechanical coupling problems, which also provides a\nsystematic approach to address intricate coupling effects in multiphysical\nsystems. Unlike the standard localized orthogonal decomposition (LOD) method\nthat constructs separate multiscale spaces for each physical field, the\nproposed method features a unified construction for both displacement and\ntemperature. Compared to the standard LOD method, our approach achieves\noperator stability reconstruction through orthogonalization while preserving\ncomputational efficiency. Several numerical experiments demonstrate that the\nME-LOD method outperforms the traditional LOD method in accuracy, particularly\nin cases with significant contrasts in material properties.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13644v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "多物理场嵌入式局部正交分解用于热机械耦合问题", "tldr": "本文提出了一种新颖的多物理场嵌入式局部正交分解（ME-LOD）方法，用于解决热机械耦合问题，该方法通过统一构建位移和温度场，在计算效率不变的情况下提高了精度，尤其是在材料特性对比显著的情况下。", "motivation": "多尺度建模和分析高度异质介质中的多物理场耦合过程存在显著挑战。", "method": "本文提出了一种新颖的多物理场嵌入式局部正交分解（ME-LOD）方法，用于解决热机械耦合问题。与标准局部正交分解（LOD）方法为每个物理场构建单独的多尺度空间不同，ME-LOD方法对位移和温度进行了统一构建，并通过正交化实现了算子稳定性重构。", "result": "数值实验表明，ME-LOD方法在精度上优于传统LOD方法，特别是在材料属性对比显著的情况下。", "conclusion": "ME-LOD方法在解决热机械耦合问题方面比标准LOD方法具有更高的精度和稳定性，尤其适用于具有显著材料属性差异的复杂系统。", "translation": "高度异质介质中多物理场耦合过程的多尺度建模和分析提出了重大挑战。在本文中，我们提出了一种新颖的多物理场嵌入式局部正交分解（ME-LOD）方法，用于解决热机械耦合问题，该方法还提供了一种系统方法来处理多物理系统中的复杂耦合效应。与为每个物理场构建单独多尺度空间的标准局部正交分解（LOD）方法不同，所提出的方法对位移和温度具有统一的构建。与标准LOD方法相比，我们的方法通过正交化实现了算子稳定性重构，同时保持了计算效率。多项数值实验表明，ME-LOD方法在精度上优于传统LOD方法，特别是在材料属性对比显著的情况下。", "summary": "本文提出了一种名为多物理场嵌入式局部正交分解（ME-LOD）的新方法，旨在解决热机械耦合问题。与传统的局部正交分解（LOD）方法为不同物理场分别构建空间不同，ME-LOD对位移和温度采用统一构建，并通过正交化提高了算子稳定性。数值实验证明，该方法在保持计算效率的同时，在精度上优于传统LOD，尤其在材料属性差异大的情况下表现更佳。", "keywords": "多物理场, 局部正交分解, 热机械耦合, 多尺度建模", "comments": "该论文的创新之处在于提出了ME-LOD方法，通过对位移和温度的统一构建，有效解决了多物理场耦合问题中的复杂耦合效应。相较于传统LOD，它在保持计算效率的同时显著提升了精度和稳定性，尤其在处理高度异质介质方面具有重要意义。"}}
{"id": "2507.13834", "title": "Scalable Submodular Policy Optimization via Pruned Submodularity Graph", "authors": ["Aditi Anand", "Suman Banerjee", "Dildar Ali"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      16 Pages", "url": "http://arxiv.org/abs/2507.13834v1", "summary": "In Reinforcement Learning (abbreviated as RL), an agent interacts with the\nenvironment via a set of possible actions, and a reward is generated from some\nunknown distribution. The task here is to find an optimal set of actions such\nthat the reward after a certain time step gets maximized. In a traditional\nsetup, the reward function in an RL Problem is considered additive. However, in\nreality, there exist many problems, including path planning, coverage control,\netc., the reward function follows the diminishing return, which can be modeled\nas a submodular function. In this paper, we study a variant of the RL Problem\nwhere the reward function is submodular, and our objective is to find an\noptimal policy such that this reward function gets maximized. We have proposed\na pruned submodularity graph-based approach that provides a provably\napproximate solution in a feasible computation time. The proposed approach has\nbeen analyzed to understand its time and space requirements as well as a\nperformance guarantee. We have experimented with a benchmark agent-environment\nsetup, which has been used for similar previous studies, and the results are\nreported. From the results, we observe that the policy obtained by our proposed\napproach leads to more reward than the baseline methods.", "comment": "16 Pages", "pdf_url": "http://arxiv.org/pdf/2507.13834v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "可扩展的次模策略优化通过剪枝次模图", "tldr": "本文研究了奖励函数为次模函数的强化学习问题，并提出了一种基于剪枝次模图的方法，该方法在可行计算时间内提供了可证明的近似解，且性能优于基线方法。", "motivation": "传统的强化学习通常假设奖励函数是可加的，但在现实世界的许多问题中，如路径规划和覆盖控制，奖励函数遵循边际收益递减规律，可以建模为次模函数。因此，需要研究如何在这种次模奖励函数设置下找到最优策略以最大化奖励。", "method": "提出了一种基于剪枝次模图的方法。该方法旨在在可行的计算时间内提供可证明的近似解，并对其时间、空间需求和性能保证进行了分析。", "result": "在基准代理-环境设置上的实验结果表明，该方法获得的策略比基线方法带来了更多的奖励。", "conclusion": "提出的基于剪枝次模图的方法能够有效地解决次模奖励函数下的强化学习问题，并在实验中表现出优于基线方法的性能，提供了可扩展且近似最优的解决方案。", "translation": "在强化学习（简称RL）中，智能体通过一组可能的动作与环境交互，并从某个未知分布中生成奖励。这里的任务是找到一组最优动作，以使经过一定时间步后的奖励最大化。在传统设置中，RL问题中的奖励函数被认为是可加的。然而，在现实中，存在许多问题，包括路径规划、覆盖控制等，其奖励函数遵循边际收益递减规律，这可以建模为次模函数。在本文中，我们研究了RL问题的一个变体，其中奖励函数是次模的，我们的目标是找到一个最优策略，使这个奖励函数最大化。我们提出了一种基于剪枝次模图的方法，该方法在可行的计算时间内提供了可证明的近似解。所提出的方法已被分析以了解其时间和空间要求以及性能保证。我们使用了一个基准代理-环境设置进行了实验，该设置已用于类似先前的研究，并报告了结果。从结果中，我们观察到我们提出的方法获得的策略比基线方法带来了更多的奖励。", "summary": "本文研究了奖励函数为次模函数的强化学习问题，旨在找到最大化该奖励函数的最优策略。作者提出了一种基于剪枝次模图的方法，该方法能够在可行计算时间内提供可证明的近似解，并分析了其计算复杂度和性能保证。实验结果表明，与基线方法相比，该方法获得的策略能够带来更高的奖励。", "keywords": "强化学习, 次模函数, 策略优化, 剪枝次模图, 可扩展性", "comments": "本文的创新点在于将次模函数引入强化学习的奖励建模，以更好地反映现实世界中边际收益递减的场景。提出的剪枝次模图方法提供了可证明的近似解，具有理论保障和计算可行性，这对于处理大规模RL问题具有重要意义。"}}
{"id": "2507.13939", "title": "Automated Route-based Conflation Between Linear Referencing System Maps And OpenStreetMap Using Open-source Tools", "authors": ["Gibran Ali", "Neal Feierabend", "Prarthana Doshi", "Whoibin Chung", "Simona Babiceanu", "Michael Fontaine"], "categories": ["cs.SI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Accepted to the 2025 IEEE International Conference on Intelligent Transportation Systems (ITSC 2025)", "url": "http://arxiv.org/abs/2507.13939v1", "summary": "Transportation researchers and planners utilize a wide range of roadway\nmetrics that are usually associated with different basemaps. Conflation is an\nimportant process for transferring these metrics onto a single basemap.\nHowever, conflation is often an expensive and time-consuming process based on\nproprietary algorithms that require manual verification.\n  In this paper, an automated open-source process is used to conflate two\nbasemaps: the linear reference system (LRS) basemap produced by the Virginia\nDepartment of Transportation and the OpenStreetMap (OSM) basemap for Virginia.\nThis process loads one LRS route at a time, determines the correct direction of\ntravel, interpolates to fill gaps larger than 12 meters, and then uses\nValhalla's map-matching algorithm to find the corresponding points along OSM's\nsegments. Valhalla's map-matching process uses a Hidden Markov Model (HMM) and\nViterbi search-based approach to find the most likely OSM segments matching the\nLRS route.\n  This work has three key contributions. First, it conflates the Virginia\nroadway network LRS map with OSM using an automated conflation method based on\nHMM and Viterbi search. Second, it demonstrates a novel open-source processing\npipeline that could be replicated without the need for proprietary licenses.\nFinally, the overall conflation process yields over 98% successful matches,\nwhich is an improvement over most automated processes currently available for\nthis type of conflation.", "comment": "Accepted to the 2025 IEEE International Conference on Intelligent\n  Transportation Systems (ITSC 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13939v1", "cate": "cs.SI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用开源工具实现基于路线的线性参照系统地图与OpenStreetMap之间的自动化融合", "tldr": "该论文提出了一种自动化的开源方法，用于将线性参照系统（LRS）地图与OpenStreetMap（OSM）地图进行融合，实现了超过98%的匹配成功率。", "motivation": "交通研究人员和规划者使用与不同基础地图关联的各种道路指标，而融合是将这些指标转移到单一基础地图的重要过程。然而，融合通常是一个昂贵、耗时且依赖专有算法并需要人工验证的过程。", "method": "本文采用一种自动化的开源流程来融合弗吉尼亚州交通部生成的线性参照系统（LRS）基础地图与弗吉尼亚州的OpenStreetMap（OSM）基础地图。该过程一次加载一条LRS路线，确定正确的行驶方向，插值以填充大于12米的间隙，然后使用Valhalla的地图匹配算法来查找OSM路段上的对应点。Valhalla的地图匹配过程使用隐马尔可夫模型（HMM）和维特比搜索方法来找到最可能匹配LRS路线的OSM路段。", "result": "整体融合过程的成功匹配率超过98%，这比目前大多数用于此类融合的自动化过程有所改进。", "conclusion": "该研究成功地利用基于HMM和维特比搜索的自动化开源方法，实现了LRS地图与OSM地图的高精度融合，并展示了一个可复制的无需专有许可证的处理流程，显著提高了融合效率和准确性。", "translation": "交通研究人员和规划者利用与不同基础地图关联的各种道路指标。融合是将这些指标转移到单一基础地图的重要过程。然而，融合通常是一个昂贵、耗时且基于专有算法并需要人工验证的过程。\n在本文中，使用一个自动化的开源流程来融合两个基础地图：弗吉尼亚州交通部生成的线性参照系统（LRS）基础地图和弗吉尼亚州的OpenStreetMap（OSM）基础地图。该过程一次加载一条LRS路线，确定正确的行驶方向，插值以填充大于12米的间隙，然后使用Valhalla的地图匹配算法来查找OSM路段上的对应点。Valhalla的地图匹配过程使用隐马尔可夫模型（HMM）和维特比搜索方法来找到最可能匹配LRS路线的OSM路段。\n这项工作有三个关键贡献。首先，它使用基于HMM和维特比搜索的自动化融合方法，将弗吉尼亚州道路网络LRS地图与OSM进行融合。其次，它展示了一个新颖的开源处理流程，该流程无需专有许可证即可复制。最后，整体融合过程的成功匹配率超过98%，这比目前大多数用于此类融合的自动化过程有所改进。", "summary": "本文提出了一种自动化的开源方法，用于将弗吉尼亚州交通部的线性参照系统（LRS）地图与OpenStreetMap（OSM）地图进行融合。该方法利用Valhalla的地图匹配算法，结合隐马尔可夫模型（HMM）和维特比搜索，实现了LRS路线与OSM路段的高效匹配。研究结果表明，该融合过程的成功匹配率超过98%，显著优于现有多数自动化方法，并提供了一个无需专有许可证即可复用的处理流程。", "keywords": "地图融合, 线性参照系统, OpenStreetMap, 开源工具, 地图匹配", "comments": "该论文的创新之处在于提出了一个完全自动化的开源融合流程，解决了传统融合方法成本高昂、耗时且依赖专有工具的问题。其基于HMM和维特比搜索的地图匹配方法，实现了超过98%的高成功匹配率，这对于数据整合和互操作性具有重要意义。该工作的可复制性（无需专有许可证）是其另一个突出优点，有助于推动开放地理空间数据的应用和共享。"}}
{"id": "2507.09894", "title": "Precoded Zak-OTFS for Per-Carrier Equalization", "authors": ["Saif Khan Mohammed", "Amit Kumar Pathak", "Muhammad Ubadah", "Ronny Hadani", "Ananthanarayanan Chockalingam", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09894v2", "summary": "In Zak-OTFS (orthogonal time frequency space) modulation the carrier waveform\nis a pulse in the delay-Doppler (DD) domain, formally a quasi-periodic\nlocalized function with specific periods along delay and Doppler. When the\nchannel delay spread is less than the delay period, and the channel Doppler\nspread is less than the Doppler period, the response to a single Zak-OTFS\ncarrier provides an image of the scattering environment and can be used to\npredict the effective channel at all other carriers. The image of the\nscattering environment changes slowly, making it possible to employ precoding\nat the transmitter. Precoding techniques were developed more than thirty years\nago for wireline modem channels (V.34 standard) defined by linear convolution\nwhere a pulse in the time domain (TD) is used to probe the one-dimensional\npartial response channel. The action of a doubly spread channel on Zak-OTFS\nmodulation determines a two-dimensional partial response channel defined by\ntwisted convolution, and we develop a novel precoding technique for this\nchannel. The proposed precoder leads to separate equalization of each DD\ncarrier which has significantly lower complexity than joint equalization of all\ncarriers. Further, the effective precoded channel results in non-interfering DD\ncarriers which significantly reduces the overhead of guard carriers separating\ndata and pilot carriers, which improves the spectral efficiency significantly.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09894v2", "cate": "eess.SP", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "用于载波均衡的预编码Zak-OTFS", "tldr": "本文提出了一种用于Zak-OTFS调制的新型预编码技术，可以在延迟-多普勒域实现每个载波的独立均衡，从而显著降低复杂度并提高频谱效率。", "motivation": "在Zak-OTFS调制中，当信道延迟扩展和多普勒扩展分别小于延迟周期和多普勒周期时，单个Zak-OTFS载波的响应可以提供散射环境的图像，并可用于预测所有其他载波的有效信道。散射环境的图像变化缓慢，使得在发射端采用预编码成为可能。现有预编码技术主要针对一维线性卷积信道，而双扩展信道对Zak-OTFS调制的影响决定了一个由扭曲卷积定义的二维部分响应信道，因此需要开发一种新的预编码技术。", "method": "本文开发了一种针对双扩展信道的新型预编码技术，该技术应用于Zak-OTFS调制。这种预编码器使得每个延迟-多普勒（DD）载波能够独立均衡。", "result": "所提出的预编码器导致每个DD载波的独立均衡，其复杂度显著低于所有载波的联合均衡。此外，有效的预编码信道导致非干扰的DD载波，这显著减少了分隔数据载波和导频载波的保护载波开销，从而显著提高了频谱效率。", "conclusion": "本文提出的新型预编码技术能够实现Zak-OTFS调制中每个延迟-多普勒载波的独立均衡，从而显著降低了均衡复杂度，并显著提高了频谱效率。", "translation": "在Zak-OTFS（正交时频空间）调制中，载波波形是延迟-多普勒（DD）域中的一个脉冲，形式上是一个准周期局部函数，在延迟和多普勒方向上具有特定的周期。当信道延迟扩展小于延迟周期，且信道多普勒扩展小于多普勒周期时，单个Zak-OTFS载波的响应提供散射环境的图像，并可用于预测所有其他载波的有效信道。散射环境的图像变化缓慢，使得在发射端采用预编码成为可能。三十多年前，为由线性卷积定义的有线调制解调器信道（V.34标准）开发了预编码技术，其中使用时域（TD）中的脉冲来探测一维部分响应信道。双扩展信道对Zak-OTFS调制的作用决定了一个由扭曲卷积定义的二维部分响应信道，我们为该信道开发了一种新颖的预编码技术。所提出的预编码器使得每个DD载波能够独立均衡，其复杂度显著低于所有载波的联合均衡。此外，有效的预编码信道导致非干扰的DD载波，这显著减少了分隔数据载波和导频载波的保护载波开销，从而显著提高了频谱效率。", "summary": "本文提出了一种针对Zak-OTFS调制的新型预编码技术，以应对双扩展信道。该技术使得在延迟-多普勒域中可以对每个载波进行独立均衡，从而显著降低了均衡复杂度。此外，预编码后的信道实现了非干扰的DD载波，有效减少了保护载波的开销，显著提高了频谱效率。", "keywords": "Zak-OTFS, 预编码, 载波均衡, 延迟-多普勒域, 频谱效率", "comments": "该论文的创新点在于为Zak-OTFS调制中的二维部分响应信道开发了一种新型预编码技术。这种方法的重要意义在于它能够实现每个载波的独立均衡，从而显著降低了复杂度，并且通过减少保护载波开销显著提高了频谱效率，这对于未来无线通信系统的设计具有重要价值。"}}
{"id": "2407.07046", "title": "CorMulT: A Semi-supervised Modality Correlation-aware Multimodal Transformer for Sentiment Analysis", "authors": ["Yangmin Li", "Ruiqi Zhu", "Wengen Li"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2407.07046v3", "summary": "Multimodal sentiment analysis is an active research area that combines\nmultiple data modalities, e.g., text, image and audio, to analyze human\nemotions and benefits a variety of applications. Existing multimodal sentiment\nanalysis methods can be classified as modality interaction-based methods,\nmodality transformation-based methods and modality similarity-based methods.\nHowever, most of these methods highly rely on the strong correlations between\nmodalities, and cannot fully uncover and utilize the correlations between\nmodalities to enhance sentiment analysis. Therefore, these methods usually\nachieve bad performance for identifying the sentiment of multimodal data with\nweak correlations. To address this issue, we proposed a two-stage\nsemi-supervised model termed Correlation-aware Multimodal Transformer (CorMulT)\nwhich consists pre-training stage and prediction stage. At the pre-training\nstage, a modality correlation contrastive learning module is designed to\nefficiently learn modality correlation coefficients between different\nmodalities. At the prediction stage, the learned correlation coefficients are\nfused with modality representations to make the sentiment prediction. According\nto the experiments on the popular multimodal dataset CMU-MOSEI, CorMulT\nobviously surpasses state-of-the-art multimodal sentiment analysis methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2407.07046v3", "cate": "cs.AI", "date": "2024-07-09", "updated": "2025-07-18", "AI": {"title_translation": "CorMulT：一种半监督模态相关性感知多模态Transformer用于情感分析", "tldr": "CorMulT提出了一种半监督两阶段模型，通过学习模态相关性系数来解决现有方法在弱相关性多模态数据上情感分析性能不佳的问题，并在CMU-MOSEI数据集上超越了SOTA方法。", "motivation": "现有的多模态情感分析方法高度依赖模态间的强相关性，无法充分发现和利用模态间的相关性来增强情感分析，导致在处理模态间弱相关性数据时性能不佳。", "method": "本文提出了一种两阶段半监督模型CorMulT。在预训练阶段，设计了一个模态相关性对比学习模块来高效学习不同模态间的相关性系数。在预测阶段，将学习到的相关性系数与模态表示融合进行情感预测。", "result": "在流行的多模态数据集CMU-MOSEI上的实验表明，CorMulT明显优于最先进的多模态情感分析方法。", "conclusion": "CorMulT通过有效学习和利用模态相关性，显著提升了多模态情感分析的性能，尤其是在处理模态间弱相关性数据时表现出色。", "translation": "多模态情感分析是一个活跃的研究领域，它结合了多种数据模态，例如文本、图像和音频，来分析人类情感，并有利于各种应用。现有的多模态情感分析方法可以分为模态交互型方法、模态转换型方法和模态相似性型方法。然而，这些方法大多高度依赖模态间的强相关性，并且不能充分发现和利用模态间的相关性来增强情感分析。因此，这些方法在识别模态间弱相关性多模态数据的情感时通常表现不佳。为了解决这个问题，我们提出了一种两阶段半监督模型，称为相关性感知多模态Transformer（CorMulT），它包括预训练阶段和预测阶段。在预训练阶段，设计了一个模态相关性对比学习模块，以有效地学习不同模态之间的模态相关性系数。在预测阶段，将学习到的相关性系数与模态表示融合，以进行情感预测。根据在流行的多模态数据集CMU-MOSEI上的实验，CorMulT明显超越了最先进的多模态情感分析方法。", "summary": "本文提出了一种名为CorMulT的半监督多模态Transformer模型，旨在解决现有多模态情感分析方法在处理模态间弱相关性数据时性能不足的问题。CorMulT采用两阶段设计：预训练阶段通过模态相关性对比学习模块高效学习模态相关性系数；预测阶段则将这些系数与模态表示融合进行情感预测。实验结果表明，CorMulT在CMU-MOSEI数据集上显著超越了现有的最先进方法。", "keywords": "多模态情感分析, 模态相关性, 半监督学习, Transformer, 对比学习", "comments": "CorMulT的创新点在于其引入的模态相关性对比学习模块，这使得模型能够显式地学习并利用模态间的相关性，从而提升了在弱相关性数据上的表现。这种两阶段的半监督方法也为其在数据受限场景下的应用提供了潜力。该研究对于推动多模态情感分析在更复杂、真实世界场景中的应用具有重要意义。"}}
{"id": "2507.10534", "title": "WildFX: A DAW-Powered Pipeline for In-the-Wild Audio FX Graph Modeling", "authors": ["Qihui Yang", "Taylor Berg-Kirkpatrick", "Julian McAuley", "Zachary Novack"], "categories": ["cs.SD", "cs.AI"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10534v2", "summary": "Despite rapid progress in end-to-end AI music generation, AI-driven modeling\nof professional Digital Signal Processing (DSP) workflows remains challenging.\nIn particular, while there is growing interest in neural black-box modeling of\naudio effect graphs (e.g. reverb, compression, equalization), AI-based\napproaches struggle to replicate the nuanced signal flow and parameter\ninteractions used in professional workflows. Existing differentiable plugin\napproaches often diverge from real-world tools, exhibiting inferior performance\nrelative to simplified neural controllers under equivalent computational\nconstraints. We introduce WildFX, a pipeline containerized with Docker for\ngenerating multi-track audio mixing datasets with rich effect graphs, powered\nby a professional Digital Audio Workstation (DAW) backend. WildFX supports\nseamless integration of cross-platform commercial plugins or any plugins in the\nwild, in VST/VST3/LV2/CLAP formats, enabling structural complexity (e.g.,\nsidechains, crossovers) and achieving efficient parallelized processing. A\nminimalist metadata interface simplifies project/plugin configuration.\nExperiments demonstrate the pipeline's validity through blind estimation of\nmixing graphs, plugin/gain parameters, and its ability to bridge AI research\nwith practical DSP demands. The code is available on:\nhttps://github.com/IsaacYQH/WildFX.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10534v2", "cate": "cs.SD", "date": "2025-07-14", "updated": "2025-07-17", "AI": {"title_translation": "WildFX: 一种基于DAW的野外音频效果图建模管线", "tldr": "WildFX是一个基于DAW的Docker容器化管线，用于生成多轨音频混音数据集，支持各种商业插件，旨在弥合AI音乐生成与专业DSP工作流程之间的差距。", "motivation": "尽管端到端AI音乐生成取得了快速进展，但AI驱动的专业数字信号处理（DSP）工作流程建模仍然具有挑战性。特别是，在音频效果图（如混响、压缩、均衡）的神经黑盒建模方面，AI方法难以复制专业工作流程中细致的信号流和参数交互。现有可微分插件方法与现实工具存在差异，在同等计算约束下表现不如简化神经控制器。", "method": "我们引入了WildFX，一个通过Docker容器化的管线，由专业的数字音频工作站（DAW）后端提供支持，用于生成具有丰富效果图的多轨音频混音数据集。WildFX支持无缝集成跨平台商业插件或任何野外插件（VST/VST3/LV2/CLAP格式），实现结构复杂性（例如，侧链、交叉）并实现高效的并行处理。一个极简的元数据接口简化了项目/插件配置。", "result": "实验通过混音图、插件/增益参数的盲估计证明了该管线的有效性，以及其弥合AI研究与实际DSP需求的能力。", "conclusion": "WildFX管线成功地弥合了AI音乐生成研究与专业数字信号处理工作流程之间的差距，通过提供一个强大的、支持多插件和复杂效果图的数据集生成平台，解决了现有AI方法在复制专业音频效果方面遇到的挑战。", "translation": "尽管端到端AI音乐生成取得了快速进展，但AI驱动的专业数字信号处理（DSP）工作流程建模仍然具有挑战性。特别是，虽然人们对音频效果图（例如混响、压缩、均衡）的神经黑盒建模越来越感兴趣，但基于AI的方法难以复制专业工作流程中细致的信号流和参数交互。现有可微分插件方法通常与真实世界的工具不同，在同等计算约束下表现不如简化的神经控制器。我们引入了WildFX，一个通过Docker容器化的管线，用于生成具有丰富效果图的多轨音频混音数据集，由专业的数字音频工作站（DAW）后端提供支持。WildFX支持无缝集成跨平台商业插件或任何野外插件（VST/VST3/LV2/CLAP格式），实现结构复杂性（例如，侧链、交叉）并实现高效的并行处理。一个极简的元数据接口简化了项目/插件配置。实验通过混音图、插件/增益参数的盲估计证明了该管线的有效性，以及其弥合AI研究与实际DSP需求的能力。代码可在以下网址获取：https://github.com/IsaacYQH/WildFX。", "summary": "WildFX是一个创新的Docker容器化管线，它利用专业数字音频工作站（DAW）后端，旨在解决AI在建模复杂专业音频DSP工作流程中的挑战。该系统能够生成包含丰富效果图的多轨音频混音数据集，支持广泛的商业和“野外”插件格式，并能处理复杂的信号路由。通过简化配置和实现高效并行处理，WildFX旨在弥合AI研究与实际DSP需求之间的差距，实验证明其在混音图和插件参数估计方面的有效性。", "keywords": "音频效果, 数字信号处理, AI音乐生成, DAW, VST插件", "comments": "WildFX的创新在于它提供了一个实际可行的解决方案，将AI音乐生成与专业DSP工作流程中的复杂性连接起来。通过集成商业DAW和多种插件格式，它解决了现有AI方法在复制细致信号流和参数交互方面的不足，为训练更真实的AI音频效果模型提供了坚实的基础。其Docker容器化和对“野外”插件的支持使其具有高度的实用性和灵活性。"}}
{"id": "2507.13455", "title": "Hard-Stop Synthesis for Multi-DOF Compliant Mechanisms", "authors": ["Dean Chen", "Armin Pomeroy", "Brandon T. Peterson", "Will Flanagan", "He Kai Lim", "Alexandra Stavrakis", "Nelson F. SooHoo", "Jonathan B. Hopkins", "Tyler R. Clites"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      42 pages, 17 figures. Under review at ASME Journal of Mechanical Design", "url": "http://arxiv.org/abs/2507.13455v1", "summary": "Compliant mechanisms have significant potential in precision applications due\nto their ability to guide motion without contact. However, an inherent\nvulnerability to fatigue and mechanical failure has hindered the translation of\ncompliant mechanisms to real-world applications. This is particularly\nchallenging in service environments where loading is complex and uncertain, and\nthe cost of failure is high. In such cases, mechanical hard stops are critical\nto prevent yielding and buckling. Conventional hard-stop designs, which rely on\nstacking single-DOF limits, must be overly restrictive in multi-DOF space to\nguarantee safety in the presence of unknown loads. In this study, we present a\nsystematic design synthesis method to guarantee overload protection in\ncompliant mechanisms by integrating coupled multi-DOF motion limits within a\nsingle pair of compact hard-stop surfaces. Specifically, we introduce a\ntheoretical and practical framework for optimizing the contact surface geometry\nto maximize the mechanisms multi-DOF working space while still ensuring that\nthe mechanism remains within its elastic regime. We apply this synthesis method\nto a case study of a caged-hinge mechanism for orthopaedic implants, and\nprovide numerical and experimental validation that the derived design offers\nreliable protection against fatigue, yielding, and buckling. This work\nestablishes a foundation for precision hard-stop design in compliant systems\noperating under uncertain loads, which is a crucial step toward enabling the\napplication of compliant mechanisms in real-world systems.", "comment": "42 pages, 17 figures. Under review at ASME Journal of Mechanical\n  Design", "pdf_url": "http://arxiv.org/pdf/2507.13455v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "多自由度柔顺机构的硬限位合成", "tldr": "本文提出了一种系统设计合成方法，用于为多自由度柔顺机构设计紧凑的硬限位表面，以在不确定载荷下提供过载保护，同时最大化其工作空间。", "motivation": "柔顺机构在精密应用中有潜力，但其固有的疲劳和机械故障脆弱性阻碍了其在实际应用中的转化，尤其是在载荷复杂和不确定且故障成本高的服务环境中。传统硬限位设计过于限制多自由度空间。", "method": "提出了一种系统的设计合成方法，通过将耦合的多自由度运动限制集成到一对紧凑的硬限位表面中，来保证柔顺机构的过载保护。具体而言，引入了一个理论和实践框架，用于优化接触表面几何形状，以最大化机构的多自由度工作空间，同时确保机构保持在其弹性范围内。", "result": "将该合成方法应用于骨科植入物的笼式铰链机构案例研究，并提供了数值和实验验证，证明所导出的设计能可靠地防止疲劳、屈服和屈曲。", "conclusion": "这项工作为在不确定载荷下运行的柔顺系统中的精密硬限位设计奠定了基础，这是实现柔顺机构在实际系统中应用的关键一步。", "translation": "柔顺机构因其无需接触即可引导运动的能力，在精密应用中具有巨大潜力。然而，其固有的疲劳和机械故障脆弱性阻碍了柔顺机构向实际应用的转化。在载荷复杂、不确定且故障成本高的服务环境中，这尤其具有挑战性。在这种情况下，机械硬限位对于防止屈服和屈曲至关重要。传统的硬限位设计依赖于堆叠单自由度限制，在多自由度空间中必须过于限制，以在存在未知载荷的情况下保证安全。在本研究中，我们提出了一种系统的设计合成方法，通过将耦合的多自由度运动限制集成到一对紧凑的硬限位表面中，来保证柔顺机构的过载保护。具体而言，我们引入了一个理论和实践框架，用于优化接触表面几何形状，以最大化机构的多自由度工作空间，同时仍确保机构保持在其弹性范围内。我们将这种合成方法应用于骨科植入物的笼式铰链机构案例研究，并提供了数值和实验验证，证明所导出的设计能可靠地防止疲劳、屈服和屈曲。这项工作为在不确定载荷下运行的柔顺系统中的精密硬限位设计奠定了基础，这是实现柔顺机构在实际系统中应用的关键一步。", "summary": "本文提出了一种针对多自由度柔顺机构的系统性硬限位设计合成方法，旨在通过集成耦合的多自由度运动限制到紧凑的硬限位表面中，解决柔顺机构在复杂载荷下易受疲劳和故障影响的问题。该方法优化了接触表面几何形状，以在确保机构保持弹性状态的同时最大化其工作空间。通过对骨科植入物中的笼式铰链机构进行案例研究，并进行数值和实验验证，证明了该设计能有效提供过载保护，为柔顺机构在实际应用中的推广奠定了基础。", "keywords": "柔顺机构, 硬限位, 多自由度, 设计合成, 过载保护", "comments": "这项研究通过提出一种创新的、集成的多自由度硬限位设计方法，解决了柔顺机构在实际应用中面临的关键挑战——即在复杂和不确定载荷下的可靠性问题。其创新之处在于优化了硬限位接触表面几何形状，实现了在保护机构的同时最大化其工作空间，这对于精密应用至关重要。通过数值和实验验证，增强了其方法的可靠性。该工作对于拓宽柔顺机构的应用范围具有重要意义。"}}
{"id": "2507.13624", "title": "FedSkipTwin: Digital-Twin-Guided Client Skipping for Communication-Efficient Federated Learning", "authors": ["Daniel Commey", "Kamel Abbad", "Garth V. Crosby", "Lyes Khoukhi"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13624v1", "summary": "Communication overhead remains a primary bottleneck in federated learning\n(FL), particularly for applications involving mobile and IoT devices with\nconstrained bandwidth. This work introduces FedSkipTwin, a novel\nclient-skipping algorithm driven by lightweight, server-side digital twins.\nEach twin, implemented as a simple LSTM, observes a client's historical\nsequence of gradient norms to forecast both the magnitude and the epistemic\nuncertainty of its next update. The server leverages these predictions,\nrequesting communication only when either value exceeds a predefined threshold;\notherwise, it instructs the client to skip the round, thereby saving bandwidth.\nExperiments are conducted on the UCI-HAR and MNIST datasets with 10 clients\nunder a non-IID data distribution. The results demonstrate that FedSkipTwin\nreduces total communication by 12-15.5% across 20 rounds while simultaneously\nimproving final model accuracy by up to 0.5 percentage points compared to the\nstandard FedAvg algorithm. These findings establish that prediction-guided\nskipping is a practical and effective strategy for resource-aware FL in\nbandwidth-constrained edge environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13624v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "FedSkipTwin：数字孪生引导的客户端跳过，实现通信高效的联邦学习", "tldr": "FedSkipTwin是一种新的联邦学习客户端跳过算法，利用服务器端的数字孪生（基于LSTM）预测客户端更新的梯度范数和不确定性，从而在带宽受限环境下显著减少通信量并提高模型精度。", "motivation": "联邦学习（FL）中的通信开销是一个主要瓶颈，尤其对于带宽受限的移动和物联网设备应用。", "method": "本文引入了FedSkipTwin，这是一种由轻量级服务器端数字孪生驱动的新型客户端跳过算法。每个数字孪生都实现为一个简单的LSTM，观察客户端历史梯度范数序列，以预测其下一次更新的幅度和认知不确定性。服务器利用这些预测，仅当预测值超过预定义阈值时才请求通信，否则指示客户端跳过本轮，从而节省带宽。", "result": "在UCI-HAR和MNIST数据集上，对10个客户端在非IID数据分布下进行实验。结果表明，与标准FedAvg算法相比，FedSkipTwin在20轮内将总通信量减少了12-15.5%，同时将最终模型精度提高了0.5个百分点。", "conclusion": "这些发现表明，预测引导的跳过是带宽受限边缘环境中资源感知型联邦学习的一种实用且有效的策略。", "translation": "通信开销仍然是联邦学习（FL）中的主要瓶颈，特别是对于涉及移动和物联网设备且带宽受限的应用。这项工作引入了FedSkipTwin，这是一种由轻量级服务器端数字孪生驱动的新型客户端跳过算法。每个孪生体都实现为一个简单的LSTM，观察客户端梯度范数的历史序列，以预测其下一次更新的幅度和认知不确定性。服务器利用这些预测，仅当任一值超过预定义阈值时才请求通信；否则，它会指示客户端跳过本轮，从而节省带宽。实验在UCI-HAR和MNIST数据集上进行，有10个客户端在非IID数据分布下。结果表明，与标准FedAvg算法相比，FedSkipTwin在20轮内将总通信量减少了12-15.5%，同时将最终模型精度提高了0.5个百分点。这些发现表明，预测引导的跳过是带宽受限边缘环境中资源感知型联邦学习的一种实用且有效的策略。", "summary": "FedSkipTwin是一种旨在解决联邦学习中通信瓶颈的新型客户端跳过算法。该方法利用轻量级服务器端数字孪生（基于LSTM）预测客户端更新的梯度范数和不确定性。服务器根据这些预测决定是否与客户端通信，从而在带宽受限的环境中实现通信效率。实验证明，FedSkipTwin在减少通信量的同时，还能提高模型精度，表明其是资源受限FL的有效策略。", "keywords": "联邦学习, 通信效率, 客户端跳过, 数字孪生, LSTM", "comments": "FedSkipTwin的创新之处在于将数字孪生（特别是基于LSTM的预测模型）引入联邦学习的客户端选择机制中，实现了基于预测的通信优化。其重要性在于有效缓解了联邦学习在移动和IoT设备上的通信负担，同时提升了模型性能，为资源受限的边缘环境提供了实用的解决方案。"}}
{"id": "2507.13881", "title": "Using LLMs to identify features of personal and professional skills in an open-response situational judgment test", "authors": ["Cole Walsh", "Rodica Ivan", "Muhammad Zafar Iqbal", "Colleen Robb"], "categories": ["cs.CL", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      10 pages, 2 figures, 4 tables; this work was accepted for presentation at the 2025 Artificial Intelligence in Measurement and Education Conference in Pittsburgh, Pennsylvania, United States", "url": "http://arxiv.org/abs/2507.13881v1", "summary": "Academic programs are increasingly recognizing the importance of personal and\nprofessional skills and their critical role alongside technical expertise in\npreparing students for future success in diverse career paths. With this\ngrowing demand comes the need for scalable systems to measure, evaluate, and\ndevelop these skills. Situational Judgment Tests (SJTs) offer one potential\navenue for measuring these skills in a standardized and reliable way, but\nopen-response SJTs have traditionally relied on trained human raters for\nevaluation, presenting operational challenges to delivering SJTs at scale. Past\nattempts at developing NLP-based scoring systems for SJTs have fallen short due\nto issues with construct validity of these systems. In this article, we explore\na novel approach to extracting construct-relevant features from SJT responses\nusing large language models (LLMs). We use the Casper SJT to demonstrate the\nefficacy of this approach. This study sets the foundation for future\ndevelopments in automated scoring for personal and professional skills.", "comment": "10 pages, 2 figures, 4 tables; this work was accepted for\n  presentation at the 2025 Artificial Intelligence in Measurement and Education\n  Conference in Pittsburgh, Pennsylvania, United States", "pdf_url": "http://arxiv.org/pdf/2507.13881v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "使用大型语言模型识别开放式情境判断测试中个人和专业技能的特征", "tldr": "本研究提出了一种使用大型语言模型（LLMs）从情境判断测试（SJTs）回应中提取个人和专业技能特征的新方法，旨在解决传统人工评估的规模化挑战和现有NLP方法的有效性问题。", "motivation": "学术项目日益认识到个人和专业技能的重要性，但大规模衡量、评估和发展这些技能的系统却面临挑战。开放式情境判断测试（SJTs）传统上依赖人工评分，难以规模化。过去的基于自然语言处理（NLP）的SJTs评分系统因结构效度问题而失败。", "method": "本文探索了一种利用大型语言模型（LLMs）从情境判断测试（SJT）回应中提取与结构相关的特征的新方法。研究使用Casper SJT来验证这种方法的有效性。", "result": "本研究为未来个人和专业技能的自动化评分奠定了基础。", "conclusion": "使用大型语言模型从SJT回应中提取技能特征的方法是有效的，并为自动化评估系统提供了可行途径。", "translation": "学术项目日益认识到个人和专业技能的重要性，以及它们在培养学生未来在不同职业道路上取得成功方面与技术专长同等关键的作用。随着这种需求的增长，需要可扩展的系统来衡量、评估和发展这些技能。情境判断测试（SJTs）提供了一种标准化和可靠地衡量这些技能的潜在途径，但开放式SJTs传统上依赖于训练有素的人工评分员进行评估，这给大规模实施SJTs带来了操作上的挑战。过去开发基于自然语言处理（NLP）的SJTs评分系统的尝试因这些系统的结构效度问题而失败。在本文中，我们探索了一种使用大型语言模型（LLMs）从SJT回应中提取与结构相关特征的新方法。我们使用Casper SJT来证明这种方法的有效性。这项研究为未来个人和专业技能的自动化评分奠定了基础。", "summary": "本研究提出了一种创新方法，利用大型语言模型（LLMs）从开放式情境判断测试（SJTs）的回答中识别个人和专业技能的特征。此方法旨在克服传统人工评估的规模化限制以及先前基于NLP的SJT评分系统存在的结构效度问题。通过使用Casper SJT进行验证，该研究证明了LLM方法在自动化评估个人和专业技能方面的有效性，并为未来的发展奠定了基础。", "keywords": "大型语言模型, 情境判断测试, 个人技能, 专业技能, 自动化评分", "comments": "本文的创新之处在于将大型语言模型应用于情境判断测试的特征提取，有效解决了传统人工评估的规模化瓶颈和早期NLP方法在结构效度上的不足。这对于大规模、标准化地评估学生关键的软技能具有重要意义，预示着未来技能评估自动化领域的发展方向。"}}
{"id": "2507.13835", "title": "Conformal Data Contamination Tests for Trading or Sharing of Data", "authors": ["Martin V. Vejling", "Shashi Raj Pandey", "Christophe A. N. Biscio", "Petar Popovski"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13835v1", "summary": "The amount of quality data in many machine learning tasks is limited to what\nis available locally to data owners. The set of quality data can be expanded\nthrough trading or sharing with external data agents. However, data buyers need\nquality guarantees before purchasing, as external data may be contaminated or\nirrelevant to their specific learning task. Previous works primarily rely on\ndistributional assumptions about data from different agents, relegating quality\nchecks to post-hoc steps involving costly data valuation procedures. We propose\na distribution-free, contamination-aware data-sharing framework that identifies\nexternal data agents whose data is most valuable for model personalization. To\nachieve this, we introduce novel two-sample testing procedures, grounded in\nrigorous theoretical foundations for conformal outlier detection, to determine\nwhether an agent's data exceeds a contamination threshold. The proposed tests,\ntermed conformal data contamination tests, remain valid under arbitrary\ncontamination levels while enabling false discovery rate control via the\nBenjamini-Hochberg procedure. Empirical evaluations across diverse\ncollaborative learning scenarios demonstrate the robustness and effectiveness\nof our approach. Overall, the conformal data contamination test distinguishes\nitself as a generic procedure for aggregating data with statistically rigorous\nquality guarantees.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13835v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "用于数据交易或共享的保形数据污染测试", "tldr": "提出一种基于保形离群点检测的无分布数据污染测试，以在数据共享中提供严格的质量保证，解决外部数据可能被污染的问题。", "motivation": "许多机器学习任务中，高质量数据有限，需要从外部代理获取。然而，外部数据可能被污染或不相关，现有方法依赖分布假设且质量检查成本高昂，缺乏购买前的质量保证。", "method": "提出一种无分布、污染感知的数据共享框架，用于识别对模型个性化最有价值的外部数据代理。引入基于保形离群点检测的新的双样本测试程序（保形数据污染测试），以确定代理数据是否超过污染阈值，并通过Benjamini-Hochberg程序控制错误发现率。", "result": "在不同协作学习场景中的经验评估证明了该方法的鲁棒性和有效性。", "conclusion": "保形数据污染测试是一种通用的数据聚合程序，能够提供统计上严格的质量保证。", "translation": "在许多机器学习任务中，高质量数据的数量受限于数据所有者本地可用的数据。通过与外部数据代理进行交易或共享，可以扩展高质量数据的集合。然而，数据购买者在购买前需要质量保证，因为外部数据可能被污染或与他们的特定学习任务不相关。以前的工作主要依赖于对来自不同代理的数据进行分布假设，将质量检查推迟到涉及昂贵数据估值程序的后期步骤。我们提出了一种无分布、污染感知的数据共享框架，该框架能够识别其数据对模型个性化最有价值的外部数据代理。为此，我们引入了新的双样本测试程序，这些程序以保形离群点检测的严格理论基础为基础，以确定代理的数据是否超过污染阈值。所提出的测试被称为保形数据污染测试，在任意污染水平下仍然有效，同时通过Benjamini-Hochberg程序实现错误发现率控制。跨不同协作学习场景的经验评估证明了我们方法的鲁棒性和有效性。总的来说，保形数据污染测试作为一种通用的数据聚合程序，以其统计上严格的质量保证而独树一帜。", "summary": "论文提出了一种名为“保形数据污染测试”的无分布、污染感知框架，用于在数据交易和共享中评估外部数据的质量。该框架利用基于保形离群点检测的双样本测试，以确定数据是否被污染并控制错误发现率，从而为数据购买者提供严格的质量保证，解决了现有方法对分布假设的依赖和高昂的质量检查成本问题。", "keywords": "数据污染, 保形预测, 数据共享, 质量保证, 双样本测试", "comments": "该论文的创新点在于提出了无分布、基于保形离群点检测的数据污染测试，解决了数据共享中外部数据质量保证的痛点。其优势在于无需对数据分布进行假设，且能通过Benjamini-Hochberg程序控制错误发现率，提供了统计上严格的质量保证，具有较强的理论基础和实用价值。"}}
{"id": "2306.15375", "title": "Frex: dependently-typed algebraic simplification", "authors": ["Guillaume Allais", "Edwin Brady", "Nathan Corbyn", "Ohad Kammar", "Jeremy Yallop"], "categories": ["cs.PL", "cs.LO", "cs.SC"], "primary_category": "Subjects:       Programming Languages (cs.PL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2306.15375v2", "summary": "We present a new design for an algebraic simplification library structured\naround concepts from universal algebra: theories, models, homomorphisms, and\nuniversal properties of free algebras and free extensions of algebras. The\nlibrary's dependently typed interface guarantees that both built-in and\nuser-defined simplification modules are terminating, sound, and complete with\nrespect to a well-specified class of equations. We have implemented the design\nin the Idris 2 and Agda dependently typed programming languages and shown that\nit supports modular extension to new theories, proof extraction and\ncertification, goal extraction via reflection, and interactive development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2306.15375v2", "cate": "cs.PL", "date": "2023-06-27", "updated": "2025-07-18", "AI": {"title_translation": "Frex: 依赖类型代数简化", "tldr": "本文介绍了一个基于泛代数概念的代数简化库的新设计，该库通过依赖类型接口保证简化模块的终止性、完备性和可靠性，并已在Idris 2和Agda中实现。", "motivation": "论文旨在设计一个新的代数简化库，该库围绕泛代数概念构建，并能提供严格的正确性保证。", "method": "该库的设计基于泛代数中的理论、模型、同态、自由代数和自由代数扩展的泛性质。通过依赖类型接口，它保证了简化模块的终止性、完备性和可靠性。该设计已在Idris 2和Agda两种依赖类型编程语言中实现。", "result": "该设计实现了一个代数简化库，其依赖类型接口保证了内置和用户定义的简化模块对于特定方程类是终止的、可靠的和完备的。它支持模块化扩展到新理论、证明提取和认证、通过反射进行目标提取以及交互式开发。", "conclusion": "所提出的基于泛代数和依赖类型设计的代数简化库能够提供强大的正确性保证，并支持多种高级功能，使其成为一个可靠且可扩展的工具。", "translation": "我们提出了一种新的代数简化库设计，该库围绕泛代数概念构建：理论、模型、同态以及自由代数和代数自由扩展的泛性质。该库的依赖类型接口保证了内置和用户定义的简化模块对于一类明确定义的方程是终止的、可靠的和完备的。我们已在Idris 2和Agda依赖类型编程语言中实现了该设计，并表明它支持对新理论的模块化扩展、证明提取和认证、通过反射进行目标提取以及交互式开发。", "summary": "本文介绍了一个名为Frex的代数简化库的新设计。该库利用泛代数概念，并通过依赖类型接口确保其简化模块的终止性、可靠性和完备性。该设计已在Idris 2和Agda中实现，并展示了其模块化扩展、证明提取和交互式开发等能力。", "keywords": "代数简化, 依赖类型, 泛代数, Idris 2, Agda", "comments": "该论文的创新之处在于将泛代数概念与依赖类型编程相结合，为代数简化提供了强大的形式化保证。这种方法确保了简化模块的正确性，对于构建可靠的符号计算系统具有重要意义。"}}
{"id": "2411.00459", "title": "Defense Against Prompt Injection Attack by Leveraging Attack Techniques", "authors": ["Yulin Chen", "Haoran Li", "Zihao Zheng", "Yangqiu Song", "Dekai Wu", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To Appear in ACL 2025", "url": "http://arxiv.org/abs/2411.00459v4", "summary": "With the advancement of technology, large language models (LLMs) have\nachieved remarkable performance across various natural language processing\n(NLP) tasks, powering LLM-integrated applications like Microsoft Copilot.\nHowever, as LLMs continue to evolve, new vulnerabilities, especially prompt\ninjection attacks arise. These attacks trick LLMs into deviating from the\noriginal input instructions and executing the attacker's instructions injected\nin data content, such as retrieved results. Recent attack methods leverage\nLLMs' instruction-following abilities and their inabilities to distinguish\ninstructions injected in the data content, and achieve a high attack success\nrate (ASR). When comparing the attack and defense methods, we interestingly\nfind that they share similar design goals, of inducing the model to ignore\nunwanted instructions and instead to execute wanted instructions. Therefore, we\nraise an intuitive question: Could these attack techniques be utilized for\ndefensive purposes? In this paper, we invert the intention of prompt injection\nmethods to develop novel defense methods based on previous training-free attack\nmethods, by repeating the attack process but with the original input\ninstruction rather than the injected instruction. Our comprehensive experiments\ndemonstrate that our defense techniques outperform existing training-free\ndefense approaches, achieving state-of-the-art results.", "comment": "To Appear in ACL 2025", "pdf_url": "http://arxiv.org/pdf/2411.00459v4", "cate": "cs.CR", "date": "2024-11-01", "updated": "2025-07-18", "AI": {"title_translation": "利用攻击技术防御提示注入攻击", "tldr": "本文提出了一种新颖的防御方法，通过逆转提示注入攻击的意图，利用现有的无训练攻击技术来防御大型语言模型中的提示注入攻击，并取得了最先进的成果。", "motivation": "随着大型语言模型（LLMs）的普及，提示注入攻击成为一种新的漏洞，能够诱导LLMs偏离原始指令。现有攻击方法利用LLMs的指令遵循能力和无法区分数据内容中注入指令的弱点，取得了很高的攻击成功率。有趣的是，攻击和防御方法在设计目标上相似，都旨在使模型忽略不必要指令并执行所需指令。因此，本文旨在探索是否可以利用攻击技术进行防御。", "method": "本文通过重复攻击过程，但使用原始输入指令而非注入指令，来逆转提示注入方法的意图，从而开发出基于先前无训练攻击方法的新型防御方法。", "result": "实验表明，所提出的防御技术优于现有无训练防御方法，达到了最先进的水平。", "conclusion": "可以利用攻击技术来开发有效的防御方法，以对抗提示注入攻击。", "translation": "随着技术的进步，大型语言模型（LLMs）在各种自然语言处理（NLP）任务中取得了卓越的性能，为像微软Copilot这样的LLM集成应用提供了支持。然而，随着LLMs的不断发展，新的漏洞，尤其是提示注入攻击随之出现。这些攻击诱骗LLMs偏离原始输入指令，执行注入到数据内容（例如检索结果）中的攻击者指令。最近的攻击方法利用了LLMs的指令遵循能力以及它们无法区分数据内容中注入指令的弱点，并取得了很高的攻击成功率（ASR）。在比较攻击和防御方法时，我们有趣地发现它们共享相似的设计目标，即诱导模型忽略不需要的指令并执行需要的指令。因此，我们提出了一个直观的问题：这些攻击技术能否用于防御目的？在本文中，我们通过重复攻击过程，但使用原始输入指令而非注入指令，逆转了提示注入方法的意图，从而开发出基于先前无训练攻击方法的新型防御方法。我们的全面实验表明，我们的防御技术优于现有无训练防御方法，取得了最先进的成果。", "summary": "本文针对大型语言模型（LLMs）面临的提示注入攻击，提出了一种新颖的防御策略。研究发现攻击与防御方法在设计目标上存在相似性，即引导模型执行特定指令并忽略其他指令。受此启发，作者反向利用了现有的无训练提示注入攻击技术，通过在攻击过程中替换为原始输入指令来开发防御机制。实验结果表明，这种方法在防御效果上超越了当前的无训练防御方案，达到了最先进的水平。", "keywords": "提示注入攻击, 大型语言模型, 防御技术, 无训练方法, 攻击反转", "comments": "这项研究的创新之处在于其“以彼之道还施彼身”的防御理念，即利用攻击者使用的技术来构建防御。这种逆向思维不仅新颖，而且在实践中被证明有效，为LLM安全提供了一个新的视角和高效的解决方案，尤其是在无训练防御方面。"}}
{"id": "2507.13543", "title": "Loss-Complexity Landscape and Model Structure Functions", "authors": ["Alexander Kolpakov"], "categories": ["cs.IT", "cs.AI", "cs.LG", "math-ph", "math.IT", "math.MP", "I.2.2; I.2.6"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      18 pages, 3 figures; GitHub repository at this https URL", "url": "http://arxiv.org/abs/2507.13543v1", "summary": "We develop a framework for dualizing the Kolmogorov structure function\n$h_x(\\alpha)$, which then allows using computable complexity proxies. We\nestablish a mathematical analogy between information-theoretic constructs and\nstatistical mechanics, introducing a suitable partition function and free\nenergy functional. We explicitly prove the Legendre-Fenchel duality between the\nstructure function and free energy, showing detailed balance of the Metropolis\nkernel, and interpret acceptance probabilities as information-theoretic\nscattering amplitudes. A susceptibility-like variance of model complexity is\nshown to peak precisely at loss-complexity trade-offs interpreted as phase\ntransitions. Practical experiments with linear and tree-based regression models\nverify these theoretical predictions, explicitly demonstrating the interplay\nbetween the model complexity, generalization, and overfitting threshold.", "comment": "18 pages, 3 figures; GitHub repository at\n  https://github.com/sashakolpakov/structure-functions", "pdf_url": "http://arxiv.org/pdf/2507.13543v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "损失-复杂度景观和模型结构函数", "tldr": "本文开发了一个对偶化Kolmogorov结构函数的框架，将信息论与统计力学联系起来，并展示了模型复杂度方差如何在损失-复杂度权衡点达到峰值，并通过实验验证了这些预测。", "motivation": "本文旨在开发一个对偶化Kolmogorov结构函数的框架，以便使用可计算的复杂度代理，并建立信息论结构与统计力学之间的数学类比。", "method": "开发了一个对偶化Kolmogorov结构函数$h_x(\\alpha)$的框架；引入了合适的配分函数和自由能泛函；明确证明了结构函数和自由能之间的Legendre-Fenchel对偶性；展示了Metropolis核的详细平衡；将接受概率解释为信息论散射振幅；分析了模型复杂度的类磁化率方差；并使用线性和基于树的回归模型进行了实际实验验证。", "result": "建立了信息论结构与统计力学之间的数学类比；明确证明了结构函数和自由能之间的Legendre-Fenchel对偶性；展示了Metropolis核的详细平衡，并将接受概率解释为信息论散射振幅；证明了模型复杂度的类磁化率方差在解释为相变的损失-复杂度权衡点精确达到峰值；通过线性和基于树的回归模型的实际实验验证了这些理论预测；明确展示了模型复杂度、泛化能力和过拟合阈值之间的相互作用。", "conclusion": "本文成功开发了一个通过对偶化Kolmogorov结构函数来连接信息论和统计力学的框架，证明了损失-复杂度权衡点表现为相变，并通过回归模型中的实验证据支持了这一发现，突出了复杂度、泛化能力和过拟合之间的关系。", "translation": "我们开发了一个框架，用于对Kolmogorov结构函数$h_x(\\alpha)$进行对偶化，从而允许使用可计算的复杂度代理。我们建立了信息论结构与统计力学之间的数学类比，引入了合适的配分函数和自由能泛函。我们明确证明了结构函数和自由能之间的Legendre-Fenchel对偶性，展示了Metropolis核的详细平衡，并将接受概率解释为信息论散射振幅。模型复杂度的类磁化率方差被证明在解释为相变的损失-复杂度权衡点处精确达到峰值。使用线性和基于树的回归模型的实际实验验证了这些理论预测，明确展示了模型复杂度、泛化能力和过拟合阈值之间的相互作用。", "summary": "本文提出了一个对偶化Kolmogorov结构函数的框架，建立了信息论与统计力学之间的数学类比。研究证明了结构函数与自由能之间的Legendre-Fenchel对偶性，并指出模型复杂度方差在损失-复杂度权衡点（被解释为相变）处达到峰值。通过线性和基于树的回归模型的实验验证了这些理论预测，揭示了模型复杂度、泛化能力和过拟合阈值之间的关键相互作用。", "keywords": "Kolmogorov结构函数, 信息论, 统计力学, 损失-复杂度权衡, 模型复杂度", "comments": "本文通过连接信息论和统计力学来分析模型复杂度，提供了一个创新的视角。将损失-复杂度权衡点视为相变以及Kolmogorov结构函数的对偶化为理解泛化和过拟合提供了一个新颖的理论框架。实验验证增强了其在实践中的相关性。"}}
{"id": "2507.13769", "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction", "authors": ["Mingyang Yu", "Zhijian Wu", "Dingjiang Huang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13769v1", "summary": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its\ndegraded 2D measurements. Recently great progress has been made in deep\nlearning-based methods, however, these methods often struggle to accurately\ncapture high-frequency details of the HSI. To address this issue, this paper\nproposes a Spectral Diffusion Prior (SDP) that is implicitly learned from\nhyperspectral images using a diffusion model. Leveraging the powerful ability\nof the diffusion model to reconstruct details, this learned prior can\nsignificantly improve the performance when injected into the HSI model. To\nfurther improve the effectiveness of the learned prior, we also propose the\nSpectral Prior Injector Module (SPIM) to dynamically guide the model to recover\nthe HSI details. We evaluate our method on two representative HSI methods: MST\nand BISRNet. Experimental results show that our method outperforms existing\nnetworks by about 0.5 dB, effectively improving the performance of HSI\nreconstruction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13769v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "学习光谱扩散先验用于高光谱图像重建", "tldr": "本文提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），以提高高光谱图像重建中高频细节的恢复能力，并在实验中取得了显著性能提升。", "motivation": "现有的深度学习高光谱图像（HSI）重建方法难以准确捕获高频细节，因此需要一种新的方法来解决这个问题。", "method": "本文提出了一种光谱扩散先验（SDP），它通过扩散模型从高光谱图像中隐式学习。为了进一步提高学习到的先验的有效性，还提出了光谱先验注入模块（SPIM）来动态引导模型恢复高光谱图像细节。该方法在MST和BISRNet两种代表性HSI方法上进行了评估。", "result": "实验结果表明，该方法在性能上比现有网络提高了约0.5 dB。", "conclusion": "本文提出的方法有效地提高了高光谱图像重建的性能，尤其是在恢复高频细节方面。", "translation": "高光谱图像（HSI）重建旨在从退化的二维测量中恢复三维HSI。最近，基于深度学习的方法取得了巨大进展，然而，这些方法往往难以准确捕获HSI的高频细节。为了解决这个问题，本文提出了一种光谱扩散先验（SDP），该先验通过扩散模型从高光谱图像中隐式学习。利用扩散模型强大的细节重建能力，这种学习到的先验在注入HSI模型时可以显著提高性能。为了进一步提高学习到的先验的有效性，我们还提出了光谱先验注入模块（SPIM）来动态引导模型恢复HSI细节。我们在两种代表性HSI方法：MST和BISRNet上评估了我们的方法。实验结果表明，我们的方法比现有网络性能提高了约0.5 dB，有效提高了HSI重建的性能。", "summary": "本文针对高光谱图像（HSI）重建中现有深度学习方法难以捕获高频细节的问题，提出了一种基于扩散模型的光谱扩散先验（SDP），并设计了光谱先验注入模块（SPIM）以动态引导模型恢复细节。实验结果表明，该方法在两种主流HSI重建方法上均能有效提升性能，相较于现有网络提高了约0.5 dB。", "keywords": "高光谱图像重建, 扩散模型, 光谱扩散先验, 深度学习, 图像恢复", "comments": "该论文的创新点在于将扩散模型引入高光谱图像重建领域，用于学习光谱扩散先验，并设计了专门的注入模块来有效利用这一先验。这种方法有望解决传统深度学习方法在高频细节恢复上的不足，为高光谱图像重建提供新的思路。"}}
{"id": "2507.14010", "title": "Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations", "authors": ["Yong Feng", "Xiaolei Zhang", "Shijin Feng", "Yong Zhao", "Yihan Chen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      8 pages, 10 figures, 3 tables", "url": "http://arxiv.org/abs/2507.14010v1", "summary": "Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming\nto classify and segment tunnel cracks with enhanced accuracy and efficiency,\nthis study proposes a two-step deep learning-based method. An automatic tunnel\nimage classification model is developed using the DenseNet-169 in the first\nstep. The proposed crack segmentation model in the second step is based on the\nDeepLabV3+, whose internal logic is evaluated via a score-weighted visual\nexplanation technique. Proposed method combines tunnel image classification and\nsegmentation together, so that the selected images containing cracks from the\nfirst step are segmented in the second step to improve the detection accuracy\nand efficiency. The superior performances of the two-step method are validated\nby experiments. The results show that the accuracy and frames per second (FPS)\nof the tunnel crack classification model are 92.23% and 39.80, respectively,\nwhich are higher than other convolutional neural networks (CNN) based and\nTransformer based models. Also, the intersection over union (IoU) and F1 score\nof the tunnel crack segmentation model are 57.01% and 67.44%, respectively,\noutperforming other state-of-the-art models. Moreover, the provided visual\nexplanations in this study are conducive to understanding the \"black box\" of\ndeep learning-based models. The developed two-stage deep learning-based method\nintegrating visual explanations provides a basis for fast and accurate\nquantitative assessment of tunnel health status.", "comment": "8 pages, 10 figures, 3 tables", "pdf_url": "http://arxiv.org/pdf/2507.14010v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于深度学习和视觉解释的隧道裂缝自动分类与分割", "tldr": "本文提出了一种基于深度学习的两步法，用于隧道裂缝的自动分类和分割，并结合视觉解释，实现了更高的准确性和效率。", "motivation": "隧道衬砌裂缝是隧道安全状况的关键指标，需要提高隧道裂缝分类和分割的准确性和效率。", "method": "提出了一种两步深度学习方法。第一步使用DenseNet-169开发自动隧道图像分类模型。第二步基于DeepLabV3+构建裂缝分割模型，并通过分数加权视觉解释技术评估其内部逻辑。该方法将分类和分割结合，先分类筛选含裂缝图像再进行分割，以提高检测精度和效率。", "result": "实验验证了两步法的优越性能。隧道裂缝分类模型的准确率为92.23%，FPS为39.80，优于其他CNN和Transformer模型。隧道裂缝分割模型的IoU为57.01%，F1分数为67.44%，优于其他SOTA模型。视觉解释有助于理解深度学习模型的“黑箱”。", "conclusion": "所开发的两阶段深度学习方法，结合视觉解释，为隧道健康状况的快速准确量化评估提供了基础。", "translation": "隧道衬砌裂缝是隧道安全状况的关键指标。为了提高隧道裂缝分类和分割的准确性和效率，本研究提出了一种基于深度学习的两步法。第一步是使用DenseNet-169开发一个自动隧道图像分类模型。第二步提出的裂缝分割模型基于DeepLabV3+，其内部逻辑通过分数加权视觉解释技术进行评估。所提出的方法将隧道图像分类和分割结合起来，以便将第一步中选出的包含裂缝的图像在第二步中进行分割，从而提高检测精度和效率。实验验证了该两步法的优越性能。结果表明，隧道裂缝分类模型的准确率和每秒帧数（FPS）分别为92.23%和39.80，高于其他基于卷积神经网络（CNN）和基于Transformer的模型。此外，隧道裂缝分割模型的交并比（IoU）和F1分数分别为57.01%和67.44%，优于其他最先进的模型。此外，本研究中提供的视觉解释有助于理解基于深度学习模型的“黑箱”。所开发的两阶段深度学习方法结合视觉解释，为隧道健康状况的快速准确量化评估提供了基础。", "summary": "本研究提出了一种基于深度学习的两步法，用于隧道裂缝的自动分类和分割。第一步利用DenseNet-169进行图像分类以筛选含裂缝图像，第二步则基于DeepLabV3+进行精确分割，并辅以分数加权视觉解释技术以增强模型可解释性。实验结果表明，该方法在分类准确率（92.23%）和分割性能（IoU 57.01%，F1 67.44%）上均优于现有模型，并为隧道健康状况的快速准确评估提供了有效途径。", "keywords": "隧道裂缝, 深度学习, 图像分类, 图像分割, 视觉解释", "comments": "本文的创新点在于提出了一个结合分类和分割的两阶段深度学习框架，并引入了视觉解释技术，这不仅提升了隧道裂缝检测的效率和准确性，也增强了深度学习模型的可解释性，对于实际工程应用具有重要意义。"}}
{"id": "2504.08593", "title": "Hands-On: Segmenting Individual Signs from Continuous Sequences", "authors": ["JianHe Low", "Harry Walsh", "Ozge Mercanoglu Sincan", "Richard Bowden"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted in the 19th IEEE International Conference on Automatic Face and Gesture Recognition", "url": "http://arxiv.org/abs/2504.08593v3", "summary": "This work tackles the challenge of continuous sign language segmentation, a\nkey task with huge implications for sign language translation and data\nannotation. We propose a transformer-based architecture that models the\ntemporal dynamics of signing and frames segmentation as a sequence labeling\nproblem using the Begin-In-Out (BIO) tagging scheme. Our method leverages the\nHaMeR hand features, and is complemented with 3D Angles. Extensive experiments\nshow that our model achieves state-of-the-art results on the DGS Corpus, while\nour features surpass prior benchmarks on BSLCorpus.", "comment": "Accepted in the 19th IEEE International Conference on Automatic Face\n  and Gesture Recognition", "pdf_url": "http://arxiv.org/pdf/2504.08593v3", "cate": "cs.CV", "date": "2025-04-11", "updated": "2025-07-17", "AI": {"title_translation": "动手实践：从连续序列中分割单个手语", "tldr": "本文提出了一种基于Transformer的架构，结合HaMeR手部特征和3D角度，用于连续手语分割，并在DGS和BSLCorpus上取得了最先进的成果。", "motivation": "连续手语分割是一项关键任务，对手语翻译和数据标注具有重要意义，但面临挑战。", "method": "本文提出了一种基于Transformer的架构，通过BIO标记方案将分割建模为序列标注问题。该方法利用HaMeR手部特征并辅以3D角度信息。", "result": "该模型在DGS语料库上取得了最先进的（state-of-the-art）结果，同时其特征在BSLCorpus上超越了先前的基准。", "conclusion": "本文提出的Transformer-based架构及其特征组合在连续手语分割任务上表现出色，达到了先进水平。", "translation": "这项工作解决了连续手语分割的挑战，这是一项对手语翻译和数据标注具有巨大影响的关键任务。我们提出了一种基于Transformer的架构，该架构模拟手语的时间动态，并使用Begin-In-Out（BIO）标记方案将分割框定为序列标注问题。我们的方法利用HaMeR手部特征，并辅以3D角度。大量实验表明，我们的模型在DGS语料库上取得了最先进的结果，同时我们的特征在BSLCorpus上超越了先前的基准。", "summary": "本文提出了一种基于Transformer的架构，用于解决连续手语分割问题。该模型将分割视为使用BIO标记方案的序列标注任务，并结合了HaMeR手部特征和3D角度。实验结果表明，该模型在DGS语料库上达到了最先进的性能，其特征在BSLCorpus上也超越了现有基准。", "keywords": "手语分割, Transformer, 序列标注, HaMeR特征, 连续手语", "comments": "这项工作通过提出一种结合Transformer架构、BIO标记以及特定手部特征（HaMeR和3D角度）的方法，有效解决了连续手语分割的挑战。其创新性在于将手语分割视为序列标注问题，并利用了针对手语特点的特征，从而在多个基准数据集上取得了显著的性能提升，对手语翻译和数据标注领域具有重要推动作用。"}}
{"id": "2507.13969", "title": "A Minimalist Controller for Autonomously Self-Aggregating Robotic Swarms: Enabling Compact Formations in Multitasking Scenarios", "authors": ["Maria Eduarda Silva de Macedo", "Ana Paula Chiarelli de Souza", "Roberto Silvio Ubertino Rosso Jr.", "Yuri Kaszubowski Lopes"], "categories": ["cs.RO", "cs.MA"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      7 pages total (6 pages of content + 1 page of references). Short paper manuscript submitted to TAROS 2025", "url": "http://arxiv.org/abs/2507.13969v1", "summary": "The deployment of simple emergent behaviors in swarm robotics has been\nwell-rehearsed in the literature. A recent study has shown how self-aggregation\nis possible in a multitask approach -- where multiple self-aggregation task\ninstances occur concurrently in the same environment. The multitask approach\nposes new challenges, in special, how the dynamic of each group impacts the\nperformance of others. So far, the multitask self-aggregation of groups of\nrobots suffers from generating a circular formation -- that is not fully\ncompact -- or is not fully autonomous. In this paper, we present a multitask\nself-aggregation where groups of homogeneous robots sort themselves into\ndifferent compact clusters, relying solely on a line-of-sight sensor. Our\nmultitask self-aggregation behavior was able to scale well and achieve a\ncompact formation. We report scalability results from a series of simulation\ntrials with different configurations in the number of groups and the number of\nrobots per group. We were able to improve the multitask self-aggregation\nbehavior performance in terms of the compactness of the clusters, keeping the\nproportion of clustered robots found in other studies.", "comment": "7 pages total (6 pages of content + 1 page of references). Short\n  paper manuscript submitted to TAROS 2025", "pdf_url": "http://arxiv.org/pdf/2507.13969v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "自动自聚集机器人群的极简控制器：在多任务场景中实现紧凑编队", "tldr": "本文提出了一种仅依赖视线传感器的多任务自聚集行为，使同质机器人群能够形成紧凑的集群，解决了现有方法形成圆形或非完全自主的问题，并展示了良好的可扩展性和紧凑性。", "motivation": "现有的多任务自聚集方法存在生成非完全紧凑的圆形编队或非完全自主的问题，且不同组的动态行为会相互影响性能。", "method": "提出了一种多任务自聚集行为，其中同质机器人群仅依靠视线传感器将自身分类到不同的紧凑集群中。通过一系列不同组数和每组机器人数量的模拟试验进行可扩展性报告。", "result": "该多任务自聚集行为具有良好的可扩展性，并实现了紧凑的编队。在集群紧凑性方面提高了多任务自聚集行为的性能，同时保持了与其他研究中发现的集群机器人比例。", "conclusion": "Not mentioned in abstract", "translation": "在群体机器人中部署简单的涌现行为已在文献中得到充分实践。最近的一项研究表明，如何在多任务方法中实现自聚集——即在同一环境中同时发生多个自聚集任务实例。多任务方法带来了新的挑战，特别是每个群体的动态如何影响其他群体的性能。迄今为止，机器人群体的多任务自聚集存在生成圆形编队（不完全紧凑）或非完全自主的问题。在本文中，我们提出了一种多任务自聚集方法，其中同质机器人群仅依靠视线传感器将自身分类到不同的紧凑集群中。我们的多任务自聚集行为能够很好地扩展并实现紧凑的编队。我们报告了一系列模拟试验的可扩展性结果，这些试验具有不同数量的群体和每组机器人数量的配置。我们能够在集群的紧凑性方面提高多任务自聚集行为的性能，同时保持了在其他研究中发现的集群机器人比例。", "summary": "本文提出了一种针对自主自聚集机器人群的极简控制器，旨在解决多任务场景中现有自聚集方法形成的集群不紧凑或非完全自主的问题。研究引入了一种新的多任务自聚集行为，该行为使同质机器人仅通过视线传感器就能形成紧凑的集群。通过模拟实验证明，该方法具有良好的可扩展性，并在保持与其他研究相似的集群机器人比例的同时，显著提高了集群的紧凑性。", "keywords": "机器人群, 自聚集, 多任务, 紧凑编队, 极简控制器", "comments": "本文的创新点在于提出了一个极简控制器，仅依赖视线传感器就实现了多任务场景下机器人群的自主紧凑自聚集，解决了传统方法在紧凑性和自主性方面的不足。其重要性在于为未来复杂环境中机器人群的部署和协调提供了更高效、更鲁棒的解决方案。"}}
{"id": "2507.14011", "title": "Conceptual and Design Principles for a Self-Referential Algorithm Mimicking Neuronal Assembly Functions", "authors": ["Paolo Totaro", "Alberto Mangiante"], "categories": ["cs.NE", "cs.RO"], "primary_category": "Subjects:       Neural and Evolutionary Computing (cs.NE)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14011v1", "summary": "This article proposes a method to formalise models of cognitive processes\ngrounded in experience, considering experience from the perspective of a living\nsystem and not from that of an observer of the living system. The perspective\nof a living system is defined by the need of the system to preserve the vital\nequilibria. The method is based on an algorithmic schema that we call\nEnvironment Generative Operator (EGO) and uses a self-referential language\ndeveloped for this purpose which we call E-language. EGO simulates cognitive\nprocesses as operations on neuron assemblies as understood by Hebb. In this\narticle we present an EGO prototype (EGO-P) which has already been implemented\nand tested.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14011v1", "cate": "cs.NE", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "模仿神经元集合功能的自指算法的概念和设计原则", "tldr": "本文提出了一种基于自指算法（EGO）的方法，从生命系统而非观察者的角度形式化认知过程模型，并介绍了已实现的原型EGO-P。", "motivation": "旨在从生命系统而非观察者的角度，形式化基于经验的认知过程模型，以保持系统重要的平衡。", "method": "提出了一种名为“环境生成算子（EGO）”的算法模式，并使用为此目的开发的自指语言“E语言”。EGO模拟赫布理解的神经元集合上的认知过程操作。文章介绍了一个已实现并测试的EGO原型（EGO-P）。", "result": "提出了一个名为EGO的算法模式和E语言，并展示了一个已实现并测试的EGO原型（EGO-P）。", "conclusion": "文章成功提出了并初步实现了从生命系统视角形式化认知过程的自指算法EGO及其原型EGO-P。", "translation": "本文提出了一种方法，用于形式化基于经验的认知过程模型，从生命系统的视角而非生命系统观察者的视角来考虑经验。生命系统的视角由系统维持生命平衡的需求所定义。该方法基于我们称之为“环境生成算子（EGO）”的算法模式，并使用为此目的开发的自指语言，我们称之为“E语言”。EGO模拟了赫布所理解的神经元集合上的认知过程操作。本文介绍了一个已经实现并测试过的EGO原型（EGO-P）。", "summary": "本文提出了一种从生命系统视角而非观察者视角来形式化基于经验的认知过程模型的方法。该方法基于一种名为“环境生成算子（EGO）”的自指算法模式，并结合为此开发的“E语言”，旨在模拟赫布理论中的神经元集合功能。文中介绍了已实现并测试的EGO原型（EGO-P）。", "keywords": "认知过程, 自指算法, 神经元集合, EGO, 生命系统视角", "comments": "本文的创新之处在于其独特的视角，即从生命系统自身的需求而非外部观察者的角度来构建认知过程模型。自指算法和专门开发的语言（EGO和E-language）是其核心方法，这为理解和模拟复杂认知现象提供了一个新的理论框架。然而，抽象中并未详细说明EGO-P的具体测试结果或性能，这可能是一个限制。"}}
{"id": "2507.13998", "title": "ParallelTime: Dynamically Weighting the Balance of Short- and Long-Term Temporal Dependencies", "authors": ["Itay Katav", "Aryeh Kontorovich"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13998v1", "summary": "Modern multivariate time series forecasting primarily relies on two\narchitectures: the Transformer with attention mechanism and Mamba. In natural\nlanguage processing, an approach has been used that combines local window\nattention for capturing short-term dependencies and Mamba for capturing\nlong-term dependencies, with their outputs averaged to assign equal weight to\nboth. We find that for time-series forecasting tasks, assigning equal weight to\nlong-term and short-term dependencies is not optimal. To mitigate this, we\npropose a dynamic weighting mechanism, ParallelTime Weighter, which calculates\ninterdependent weights for long-term and short-term dependencies for each token\nbased on the input and the model's knowledge. Furthermore, we introduce the\nParallelTime architecture, which incorporates the ParallelTime Weighter\nmechanism to deliver state-of-the-art performance across diverse benchmarks.\nOur architecture demonstrates robustness, achieves lower FLOPs, requires fewer\nparameters, scales effectively to longer prediction horizons, and significantly\noutperforms existing methods. These advances highlight a promising path for\nfuture developments of parallel Attention-Mamba in time series forecasting. The\nimplementation is readily available at:\n\\href{https://github.com/itay1551/ParallelTime}{ParallelTime GitHub", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13998v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "ParallelTime：动态加权短期和长期时间依赖关系的平衡", "tldr": "ParallelTime提出了一种动态加权机制，用于平衡时间序列预测中短期和长期依赖关系，实现了最先进的性能。", "motivation": "现代多元时间序列预测中，Transformer和Mamba架构被广泛使用，但将短期和长期依赖关系等权处理并非最优。为了解决这个问题，需要一种动态加权机制来更好地平衡这两种依赖。", "method": "本文提出了ParallelTime Weighter动态加权机制，它根据输入和模型知识为每个token计算短期和长期依赖关系的相互依赖权重。在此基础上，引入了ParallelTime架构，将该加权机制融入其中。", "result": "ParallelTime架构在各种基准测试中表现出最先进的性能，具有鲁棒性，FLOPs更低，参数更少，能有效扩展到更长的预测范围，并显著优于现有方法。", "conclusion": "ParallelTime架构通过动态加权短期和长期时间依赖关系，为时间序列预测中的并行Attention-Mamba架构的未来发展指明了一条有前景的道路。", "translation": "现代多元时间序列预测主要依赖于两种架构：带有注意力机制的Transformer和Mamba。在自然语言处理中，有一种方法结合了局部窗口注意力来捕获短期依赖，以及Mamba来捕获长期依赖，并通过平均它们的输出来赋予两者相同的权重。我们发现，对于时间序列预测任务，对长期和短期依赖赋予相同权重并非最优。为了缓解这个问题，我们提出了一种动态加权机制，ParallelTime Weighter，它根据输入和模型的知识，为每个token计算短期和长期依赖的相互依赖权重。此外，我们引入了ParallelTime架构，该架构融入了ParallelTime Weighter机制，在各种基准测试中提供了最先进的性能。我们的架构展示了鲁棒性，实现了更低的FLOPs，需要更少的参数，能有效扩展到更长的预测范围，并显著优于现有方法。这些进展为时间序列预测中并行Attention-Mamba的未来发展指明了一条有前景的道路。实现代码可在以下链接获取：https://github.com/itay1551/ParallelTime", "summary": "该论文提出了ParallelTime架构，旨在解决时间序列预测中短期和长期时间依赖关系等权处理的非最优问题。核心创新是ParallelTime Weighter动态加权机制，它能根据输入和模型知识动态调整短期和长期依赖的权重。实验结果表明，ParallelTime在性能上超越现有方法，并展现出更低的计算成本、更少的参数和更好的可扩展性。", "keywords": "时间序列预测, 动态加权, Transformer, Mamba, Temporal Dependencies", "comments": "ParallelTime的创新之处在于引入了动态加权机制来平衡时间序列中短期和长期依赖的重要性，而非简单地平均处理。这解决了现有Transformer和Mamba结合方法中的一个关键限制。其在多项指标上的优越表现，特别是计算效率和可扩展性，预示着该方法在实际应用中具有重要潜力。"}}
{"id": "2504.19518", "title": "Discrete-time Two-Layered Forgetting RLS Identification under Finite Excitation", "authors": ["Satoshi Tsuruhara", "Kazuhisa Ito"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures, accepted at the 5th Modeling, Estimation and Control Conference (MECC 2025)", "url": "http://arxiv.org/abs/2504.19518v2", "summary": "In recent years, adaptive identification methods that can achieve the true\nvalue convergence of parameters without requiring persistent excitation (PE)\nhave been widely studied, and concurrent learning has been intensively studied.\nHowever, the parameter convergence rate is limited for the gradient-based\nmethod owing to small parameter update gain, and even the introduction of\nforgetting factors does not work sufficiently. To address this problem, this\nstudy proposes a novel discrete-time recursive least squares method under\nfinite excitation (FE) conditions using two forgetting factors (inner and\nouter) and an augmented regressor matrix comprising a sum of regressor vectors.\nThe proposed method ensures the PE condition of the augmented regressor matrix\nunder FE conditions of the regressor vector and allows the properly design of\nthe forgetting factor without estimator windup and/or destabilization of the\nsystem. Numerical simulations demonstrate its effectiveness by comparing it\nwith several conventional methods.", "comment": "6 pages, 6 figures, accepted at the 5th Modeling, Estimation and\n  Control Conference (MECC 2025)", "pdf_url": "http://arxiv.org/pdf/2504.19518v2", "cate": "eess.SY", "date": "2025-04-28", "updated": "2025-07-18", "AI": {"title_translation": "离散时间双层遗忘RLS有限激励辨识", "tldr": "提出一种新的离散时间双层遗忘RLS方法，在有限激励下提高参数收敛速度并避免系统不稳定。", "motivation": "现有梯度自适应辨识方法（包括引入遗忘因子）在参数收敛速度方面受限，且在非持续激励下难以实现参数真值收敛。", "method": "本研究提出一种新型离散时间递归最小二乘（RLS）方法，旨在有限激励（FE）条件下，通过引入双层（内部和外部）遗忘因子和一个由回归向量之和组成的增广回归矩阵来解决现有方法的局限性。该方法确保了在回归向量的有限激励条件下增广回归矩阵的持续激励（PE）条件，并允许适当设计遗忘因子，从而避免估计器饱和或系统不稳定。", "result": "数值模拟结果表明，与几种传统方法相比，所提出的方法是有效的。", "conclusion": "该研究成功提出了一种在有限激励条件下提高参数收敛速度并保证系统稳定性的离散时间双层遗忘RLS辨识方法。", "translation": "近年来，无需持续激励（PE）即可实现参数真值收敛的自适应辨识方法得到了广泛研究，并发学习也得到了深入研究。然而，由于参数更新增益小，基于梯度的方法的参数收敛速度受到限制，即使引入遗忘因子也效果不佳。为了解决这个问题，本研究提出了一种在有限激励（FE）条件下使用两个遗忘因子（内部和外部）和一个由回归向量之和组成的增广回归矩阵的新型离散时间递归最小二乘方法。所提出的方法在回归向量的有限激励条件下确保了增广回归矩阵的持续激励条件，并允许适当设计遗忘因子，而不会导致估计器饱和和/或系统不稳定。数值模拟通过与几种传统方法进行比较，证明了其有效性。", "summary": "本文提出一种新颖的离散时间递归最小二乘（RLS）方法，旨在解决现有自适应辨识方法在有限激励下参数收敛速度慢的问题。该方法引入了内外双层遗忘因子和增广回归矩阵，确保了在有限激励下的持续激励条件，并有效避免了估计器饱和与系统不稳定。数值模拟结果验证了其优于传统方法的有效性。", "keywords": "离散时间系统, 递归最小二乘, 遗忘因子, 有限激励, 参数辨识", "comments": "该论文的创新点在于引入了双层遗忘因子和增广回归矩阵，以在有限激励条件下解决RLS方法的收敛速度和稳定性问题。这对于实际应用中难以保证持续激励的系统辨识具有重要意义。"}}
{"id": "2502.06358", "title": "Prompt-Tuning Bandits: Enabling Few-Shot Generalization for Efficient Multi-Task Offline RL", "authors": ["Finn Rietz", "Oleg Smirnov", "Sara Karimi", "Lele Cao"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.06358v3", "summary": "Prompting has emerged as the dominant paradigm for adapting large,\npre-trained transformer-based models to downstream tasks. The Prompting\nDecision Transformer (PDT) enables large-scale, multi-task offline\nReinforcement Learning (RL) pre-training by leveraging stochastic trajectory\nprompts to identify the target task. However, these prompts are sampled\nuniformly from expert demonstrations, overlooking a critical limitation: not\nall prompts are equally informative for differentiating between tasks. This\nlimits generalization and adaptation, especially in low-data or open-world\nsettings where sample efficiency is crucial. To address this issue, we propose\na lightweight, inference-time, bandit-based prompt-tuning framework. The bandit\nexplores and optimizes trajectory prompt selection to enhance task performance,\nwhile avoiding costly fine-tuning of the transformer backbone. Our experiments\nindicate not only clear performance gains due to bandit-based prompt-tuning,\nbut also better sample complexity, scalability, and prompt space exploration\ncompared to prompt-tuning baselines. These results highlights the importance of\nadaptive prompt selection mechanisms for efficient generalization in offline\nmulti-task RL.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.06358v3", "cate": "cs.LG", "date": "2025-02-10", "updated": "2025-07-18", "AI": {"title_translation": "提示词调优强盗算法：为高效多任务离线强化学习实现少样本泛化", "tldr": "本文提出了一种基于强盗算法的轻量级提示词调优框架，用于优化轨迹提示词选择，以提升多任务离线强化学习中的少样本泛化能力和样本效率。", "motivation": "现有的提示决策Transformer (PDT) 通过统一采样专家演示中的轨迹提示词来识别目标任务，但这种方法忽略了并非所有提示词都同样有助于区分任务，这限制了泛化和适应性，尤其是在数据量少或开放世界设置中，样本效率至关重要。", "method": "我们提出了一种轻量级、推理时基于强盗算法的提示词调优框架。该强盗算法探索并优化轨迹提示词选择，以提高任务性能，同时避免了Transformer主干网络的昂贵微调。", "result": "实验表明，与基线提示词调优方法相比，基于强盗算法的提示词调优不仅带来了明显的性能提升，还在样本复杂度、可扩展性和提示词空间探索方面表现更好。", "conclusion": "这些结果强调了自适应提示词选择机制对于离线多任务强化学习中高效泛化的重要性。", "translation": "提示词已成为使大型预训练的基于Transformer的模型适应下游任务的主导范式。提示词决策Transformer (PDT) 通过利用随机轨迹提示词来识别目标任务，从而实现大规模、多任务离线强化学习 (RL) 预训练。然而，这些提示词是从专家演示中均匀采样的，忽视了一个关键限制：并非所有提示词都同样有助于区分任务。这限制了泛化和适应性，尤其是在样本效率至关重要的低数据或开放世界设置中。为了解决这个问题，我们提出了一种轻量级、推理时基于强盗算法的提示词调优框架。该强盗算法探索并优化轨迹提示词选择，以提高任务性能，同时避免了Transformer主干网络的昂贵微调。我们的实验不仅表明基于强盗算法的提示词调优带来了明显的性能提升，而且与提示词调优基线相比，具有更好的样本复杂度、可扩展性和提示词空间探索能力。这些结果突出了自适应提示词选择机制对于离线多任务强化学习中高效泛化的重要性。", "summary": "本文提出了一种名为“提示词调优强盗算法”（Prompt-Tuning Bandits）的新框架，旨在解决现有提示决策Transformer (PDT) 在多任务离线强化学习中提示词采样效率低下的问题。PDT统一采样提示词，导致在少数据或开放世界场景下泛化能力受限。作者引入了一种轻量级、推理时基于强盗算法的提示词调优方法，该方法通过优化轨迹提示词的选择来提升任务性能，同时避免了Transformer主干的昂贵微调。实验证明，该方法在性能、样本复杂度、可扩展性和提示词空间探索方面均优于现有基线方法，突出了自适应提示词选择在高效泛化中的关键作用。", "keywords": "提示词调优, 强盗算法, 离线强化学习, 多任务, 少样本泛化", "comments": "该论文的创新点在于将强盗算法引入到提示词调优中，以解决多任务离线强化学习中提示词选择的效率问题。这种方法避免了对大型Transformer模型的昂贵微调，提升了样本效率和泛化能力，对于资源受限或需要快速适应新任务的场景具有重要意义。"}}
{"id": "2507.13468", "title": "ERR@HRI 2.0 Challenge: Multimodal Detection of Errors and Failures in Human-Robot Conversations", "authors": ["Shiye Cao", "Maia Stiber", "Amama Mahmood", "Maria Teresa Parreira", "Wendy Ju", "Micol Spitale", "Hatice Gunes", "Chien-Ming Huang"], "categories": ["cs.RO", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13468v1", "summary": "The integration of large language models (LLMs) into conversational robots\nhas made human-robot conversations more dynamic. Yet, LLM-powered\nconversational robots remain prone to errors, e.g., misunderstanding user\nintent, prematurely interrupting users, or failing to respond altogether.\nDetecting and addressing these failures is critical for preventing\nconversational breakdowns, avoiding task disruptions, and sustaining user\ntrust. To tackle this problem, the ERR@HRI 2.0 Challenge provides a multimodal\ndataset of LLM-powered conversational robot failures during human-robot\nconversations and encourages researchers to benchmark machine learning models\ndesigned to detect robot failures. The dataset includes 16 hours of dyadic\nhuman-robot interactions, incorporating facial, speech, and head movement\nfeatures. Each interaction is annotated with the presence or absence of robot\nerrors from the system perspective, and perceived user intention to correct for\na mismatch between robot behavior and user expectation. Participants are\ninvited to form teams and develop machine learning models that detect these\nfailures using multimodal data. Submissions will be evaluated using various\nperformance metrics, including detection accuracy and false positive rate. This\nchallenge represents another key step toward improving failure detection in\nhuman-robot interaction through social signal analysis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13468v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "ERR@HRI 2.0 挑战赛：人机对话中错误和故障的多模态检测", "tldr": "ERR@HRI 2.0 挑战赛旨在通过提供多模态数据集，促进研究人员开发机器学习模型来检测人机对话中LLM驱动机器人的错误和故障。", "motivation": "尽管大型语言模型（LLM）增强了会话机器人的动态性，但LLM驱动的机器人仍然容易出错，例如误解用户意图或未能响应。检测和解决这些故障对于防止对话中断、避免任务干扰和维持用户信任至关重要。", "method": "ERR@HRI 2.0 挑战赛提供了一个多模态数据集，包含16小时的人机交互数据，包括面部、语音和头部运动特征。数据标注了机器人错误的存在与否以及用户纠正意图。挑战赛邀请研究人员开发利用多模态数据检测这些故障的机器学习模型，并根据检测准确率和误报率等指标进行评估。", "result": "Not mentioned in abstract", "conclusion": "该挑战是SMR@HRI 2.0挑战赛的延续，旨在通过社会信号分析改进人机交互中的故障检测，是迈向该目标的关键一步。", "translation": "将大型语言模型（LLM）集成到会话机器人中，使人机对话更具动态性。然而，LLM驱动的会话机器人仍然容易出错，例如，误解用户意图、过早打断用户，或完全未能响应。检测和解决这些故障对于防止对话中断、避免任务中断和维持用户信任至关重要。为了解决这个问题，ERR@HRI 2.0 挑战赛提供了一个多模态数据集，记录了人机对话中LLM驱动会话机器人的故障，并鼓励研究人员对旨在检测机器人故障的机器学习模型进行基准测试。该数据集包括16小时的两人人机交互数据，包含了面部、语音和头部运动特征。每次交互都从系统角度标注了机器人错误的存在与否，以及用户感知到的纠正机器人行为与用户期望之间不匹配的意图。参与者被邀请组建团队，开发利用多模态数据检测这些故障的机器学习模型。提交的作品将使用各种性能指标进行评估，包括检测准确率和误报率。这项挑战代表着通过社会信号分析改进人机交互中故障检测的又一个关键步骤。", "summary": "ERR@HRI 2.0 挑战赛旨在解决大型语言模型驱动的会话机器人在人机对话中容易出现的错误问题。挑战赛提供了一个包含16小时多模态人机交互数据（包括面部、语音、头部运动特征及错误标注）的数据集，邀请研究人员开发和基准测试能够利用多模态数据检测机器人故障的机器学习模型，以期提升人机交互中的故障检测能力并维持用户信任。", "keywords": "人机交互, 机器人错误检测, 多模态数据, 大型语言模型, 会话机器人", "comments": "该挑战赛通过提供大规模的多模态数据集，为研究人机交互中机器人错误检测提供了一个宝贵的平台。其创新之处在于关注LLM驱动机器人的特定故障类型，并强调多模态数据在故障检测中的潜力，这对于提高人机对话的鲁棒性和用户体验具有重要意义。"}}
{"id": "2507.13369", "title": "VerilogDB: The Largest, Highest-Quality Dataset with a Preprocessing Framework for LLM-based RTL Generation", "authors": ["Paul E. Calzada", "Zahin Ibnat", "Tanvir Rahman", "Kamal Kandula", "Danyu Lu", "Sujan Kumar Saha", "Farimah Farahmandi", "Mark Tehranipoor"], "categories": ["cs.AR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13369v1", "summary": "Large Language Models (LLMs) are gaining popularity for hardware design\nautomation, particularly through Register Transfer Level (RTL) code generation.\nIn this work, we examine the current literature on RTL generation using LLMs\nand identify key requirements for training and fine-tuning datasets. We\nconstruct a robust Verilog dataset through an automated three-pronged process\ninvolving database (DB) creation and management with PostgreSQL, data\ncollection from code hosting sites like OpenCores and GitHub, and data\npreprocessing to verify the codes' syntax, run logic synthesis, and extract\nrelevant module metadata. We implement a scalable and efficient DB\ninfrastructure to support analysis and detail our preprocessing pipeline to\nenforce high-quality data before DB insertion. The resulting dataset comprises\n20,392 Verilog samples, 751 MB of Verilog code data, which is the largest\nhigh-quality Verilog dataset for LLM fine-tuning to our knowledge. We further\nevaluate the dataset, address associated challenges, and explore potential\napplications for future research and development in LLM-based hardware\ngeneration.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13369v1", "cate": "cs.AR", "date": "2025-07-09", "updated": "2025-07-09", "AI": {"title_translation": "VerilogDB：一个最大、最高质量的Verilog数据集，附带用于基于LLM的RTL生成的预处理框架", "tldr": "VerilogDB是一个最大、最高质量的Verilog数据集，附带预处理框架，用于基于LLM的RTL生成。", "motivation": "鉴于大型语言模型（LLMs）在硬件设计自动化，特别是寄存器传输级（RTL）代码生成方面的日益普及，需要高质量的训练和微调数据集来支持LLM进行RTL生成。", "method": "作者通过一个自动化的三管齐下的过程构建了一个强大的Verilog数据集：1) 使用PostgreSQL进行数据库创建和管理；2) 从OpenCores和GitHub等代码托管网站收集数据；3) 对数据进行预处理，包括验证代码语法、运行逻辑综合以及提取相关的模块元数据。他们还实现了一个可扩展且高效的数据库基础设施，并详细介绍了预处理流程以确保数据高质量。", "result": "成果是VerilogDB数据集，包含20,392个Verilog样本，共计751 MB的Verilog代码数据。据作者所知，这是目前用于LLM微调的最大、最高质量的Verilog数据集。", "conclusion": "该研究构建并评估了VerilogDB数据集，解决了相关挑战，并探讨了其在未来基于LLM的硬件生成研究与开发中的潜在应用。", "translation": "大型语言模型（LLMs）在硬件设计自动化，特别是通过寄存器传输级（RTL）代码生成方面正日益普及。在这项工作中，我们审视了当前关于使用LLM进行RTL生成的文献，并确定了训练和微调数据集的关键要求。我们通过一个自动化的三管齐下过程构建了一个强大的Verilog数据集，该过程包括：使用PostgreSQL进行数据库（DB）创建和管理、从OpenCores和GitHub等代码托管网站收集数据，以及进行数据预处理以验证代码语法、运行逻辑综合并提取相关模块元数据。我们实现了一个可扩展且高效的数据库基础设施以支持分析，并详细介绍了我们的预处理管道，以在数据库插入前强制执行高质量数据。所生成的数据集包含20,392个Verilog样本，751 MB的Verilog代码数据，据我们所知，这是目前用于LLM微调的最大、最高质量的Verilog数据集。我们进一步评估了该数据集，解决了相关挑战，并探索了其在未来基于LLM的硬件生成研究与开发中的潜在应用。", "summary": "本文介绍了VerilogDB，一个为基于大型语言模型（LLM）的寄存器传输级（RTL）代码生成而设计的最大、最高质量的Verilog数据集。作者通过自动化流程，从OpenCores和GitHub等平台收集数据，并进行严格的预处理，包括语法验证和逻辑综合，以确保数据质量。该数据集包含20,392个Verilog样本和751 MB代码数据，旨在满足LLM训练和微调对高质量数据的需求，并为未来的LLM驱动硬件设计研究提供基础。", "keywords": "Verilog, 数据集, 大型语言模型 (LLM), RTL 生成, 硬件设计自动化", "comments": "VerilogDB通过其自动化构建流程和严格的质量控制，为LLM在硬件设计领域的应用提供了重要的基础数据支持，其规模和质量是该领域的显著进步。"}}
{"id": "2507.13663", "title": "Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration", "authors": ["Xingyu Jiang", "Ning Gao", "Hongkun Dou", "Xiuhui Zhang", "Xiaoqing Zhong", "Yue Deng", "Hongjue Li"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13663v1", "summary": "Natural image quality is often degraded by adverse weather conditions,\nsignificantly impairing the performance of downstream tasks. Image restoration\nhas emerged as a core solution to this challenge and has been widely discussed\nin the literature. Although recent transformer-based approaches have made\nremarkable progress in image restoration, their increasing system complexity\nposes significant challenges for real-time processing, particularly in\nreal-world deployment scenarios. To this end, most existing methods attempt to\nsimplify the self-attention mechanism, such as by channel self-attention or\nstate space model. However, these methods primarily focus on network\narchitecture while neglecting the inherent characteristics of image restoration\nitself. In this context, we explore a pyramid Wavelet-Fourier iterative\npipeline to demonstrate the potential of Wavelet-Fourier processing for image\nrestoration. Inspired by the above findings, we propose a novel and efficient\nrestoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).\nSpecifically, PW-FNet features two key design principles: 1) at the inter-block\nlevel, integrates a pyramid wavelet-based multi-input multi-output structure to\nachieve multi-scale and multi-frequency bands decomposition; and 2) at the\nintra-block level, incorporates Fourier transforms as an efficient alternative\nto self-attention mechanisms, effectively reducing computational complexity\nwhile preserving global modeling capability. Extensive experiments on tasks\nsuch as image deraining, raindrop removal, image super-resolution, motion\ndeblurring, image dehazing, image desnowing and underwater/low-light\nenhancement demonstrate that PW-FNet not only surpasses state-of-the-art\nmethods in restoration quality but also achieves superior efficiency, with\nsignificantly reduced parameter size, computational cost and inference time.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13663v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "全局建模很重要：一种快速、轻量且有效的图像复原基线", "tldr": "本文提出金字塔小波-傅里叶网络（PW-FNet），一种结合小波-傅里叶变换的新型高效图像复原基线，在多种任务上实现了卓越的质量和效率，超越了现有SOTA方法。", "motivation": "自然图像质量受恶劣天气影响，现有基于Transformer的图像复原方法复杂度高，难以实时处理和部署；多数方法只关注网络架构，忽略图像复原本身的固有特性。", "method": "提出金字塔小波-傅里叶网络（PW-FNet）。其设计原则包括：1) 在块间层面，集成金字塔小波多输入多输出结构，实现多尺度和多频带分解；2) 在块内层面，引入傅里叶变换作为自注意力机制的有效替代，以降低计算复杂性同时保留全局建模能力。", "result": "PW-FNet在图像去雨、去雨滴、图像超分辨率、运动去模糊、图像去雾、图像去雪以及水下/低光增强等任务上，不仅超越了最先进方法的复原质量，还在效率上表现更优，显著降低了参数量、计算成本和推理时间。", "conclusion": "PW-FNet通过结合小波-傅里叶处理，提供了一个快速、轻量且有效的图像复原基线，在多项任务上实现了卓越的性能和效率。", "translation": "自然图像质量常因恶劣天气条件而下降，严重影响下游任务的性能。图像复原已成为解决这一挑战的核心方案，并被文献广泛讨论。尽管最近基于Transformer的方法在图像复原方面取得了显著进展，但其日益增长的系统复杂性对实时处理，特别是在实际部署场景中，构成了重大挑战。为此，大多数现有方法试图简化自注意力机制，例如通过通道自注意力或状态空间模型。然而，这些方法主要关注网络架构，而忽略了图像复原本身的固有特性。在此背景下，我们探索了一种金字塔小波-傅里叶迭代管道，以展示小波-傅里叶处理在图像复原方面的潜力。受上述发现的启发，我们提出了一种新颖高效的复原基线，命名为金字塔小波-傅里叶网络（PW-FNet）。具体而言，PW-FNet具有两个关键设计原则：1）在块间层面，集成了基于金字塔小波的多输入多输出结构，以实现多尺度和多频带分解；2）在块内层面，将傅里叶变换作为自注意力机制的有效替代，有效降低计算复杂性，同时保留全局建模能力。在图像去雨、去雨滴、图像超分辨率、运动去模糊、图像去雾、图像去雪以及水下/低光增强等任务上的大量实验表明，PW-FNet不仅在复原质量上超越了最先进的方法，而且在效率上也表现出色，显著降低了参数量、计算成本和推理时间。", "summary": "本文提出一种名为金字塔小波-傅里叶网络（PW-FNet）的新型高效图像复原基线，旨在解决现有基于Transformer方法计算复杂的问题。PW-FNet结合了金字塔小波的多尺度多频带分解和傅里叶变换的全局建模能力，有效替代了复杂的自注意力机制。实验证明，PW-FNet在多种图像复原任务上不仅在质量上超越了SOTA方法，还在效率、参数量、计算成本和推理时间方面表现出显著优势。", "keywords": "图像复原, 小波-傅里叶变换, 高效, 全局建模, PW-FNet", "comments": "本文的创新点在于将小波-傅里叶变换引入图像复原，并将其作为自注意力机制的有效替代，从而在保持全局建模能力的同时大幅降低了计算复杂性。这为高效图像复原提供了一个有前景的新方向，特别适用于对实时性要求高的实际部署场景。其轻量化和高性能的特点使其成为一个重要的基线模型。"}}
{"id": "2506.23298", "title": "Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification", "authors": ["Xing Shen", "Justin Szeto", "Mingyang Li", "Hengguan Huang", "Tal Arbel"], "categories": ["eess.IV"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Preprint version. The peer-reviewed version of this paper has been accepted to MICCAI 2025 main conference", "url": "http://arxiv.org/abs/2506.23298v3", "summary": "Multimodal large language models (MLLMs) have enormous potential to perform\nfew-shot in-context learning in the context of medical image analysis. However,\nsafe deployment of these models into real-world clinical practice requires an\nin-depth analysis of the accuracies of their predictions, and their associated\ncalibration errors, particularly across different demographic subgroups. In\nthis work, we present the first investigation into the calibration biases and\ndemographic unfairness of MLLMs' predictions and confidence scores in few-shot\nin-context learning for medical image classification. We introduce CALIN, an\ninference-time calibration method designed to mitigate the associated biases.\nSpecifically, CALIN estimates the amount of calibration needed, represented by\ncalibration matrices, using a bi-level procedure: progressing from the\npopulation level to the subgroup level prior to inference. It then applies this\nestimation to calibrate the predicted confidence scores during inference.\nExperimental results on three medical imaging datasets: PAPILA for fundus image\nclassification, HAM10000 for skin cancer classification, and MIMIC-CXR for\nchest X-ray classification demonstrate CALIN's effectiveness at ensuring fair\nconfidence calibration in its prediction, while improving its overall\nprediction accuracies and exhibiting minimum fairness-utility trade-off. Our\ncodebase can be found at\nhttps://github.com/xingbpshen/medical-calibration-fairness-mllm.", "comment": "Preprint version. The peer-reviewed version of this paper has been\n  accepted to MICCAI 2025 main conference", "pdf_url": "http://arxiv.org/pdf/2506.23298v3", "cate": "eess.IV", "date": "2025-06-29", "updated": "2025-07-17", "AI": {"title_translation": "暴露和缓解医学图像分类中 MLLM 少样本上下文学习的校准偏差和人口不公平性", "tldr": "MLLMs在医学图像分类中存在校准偏差和人口不公平性，本文提出了CALIN方法来缓解这些问题，并在三个数据集上验证了其有效性。", "motivation": "多模态大型语言模型（MLLMs）在医学图像分析的少样本学习中潜力巨大，但其安全部署到实际临床实践中，需要深入分析其预测的准确性及其相关的校准误差，特别是在不同人口亚组之间。本文旨在首次调查MLLMs在医学图像分类中少样本上下文学习的校准偏差和人口不公平性。", "method": "本文提出了一种名为CALIN的推理时校准方法，旨在缓解MLLMs的校准偏差和人口不公平性。CALIN使用一个双层程序（在推理前从群体层面到亚组层面）来估计所需的校准量，以校准矩阵表示。然后，在推理期间应用此估计来校准预测的置信度分数。", "result": "在三个医学图像数据集（用于眼底图像分类的PAPILA、用于皮肤癌分类的HAM10000和用于胸部X射线分类的MIMIC-CXR）上的实验结果表明，CALIN在确保预测中公平的置信度校准方面有效，同时提高了其整体预测准确性，并表现出最小的公平性-效用权衡。", "conclusion": "CALIN方法成功地解决了MLLMs在医学图像分类中少样本上下文学习的校准偏差和人口不公平性问题，提高了模型的可靠性和公平性。", "translation": "多模态大型语言模型（MLLM）在医学图像分析中进行少样本上下文学习具有巨大潜力。然而，将这些模型安全部署到实际临床实践中，需要深入分析其预测的准确性及其相关的校准误差，特别是在不同人口亚组之间。在这项工作中，我们首次调查了MLLM在医学图像分类的少样本上下文学习中，其预测和置信度分数的校准偏差和人口不公平性。我们引入了CALIN，一种推理时校准方法，旨在缓解相关偏差。具体来说，CALIN使用双层程序（在推理前从群体层面到亚组层面）估计所需的校准量，以校准矩阵表示。然后，它在推理期间应用此估计来校准预测的置信度分数。在三个医学图像数据集（用于眼底图像分类的PAPILA、用于皮肤癌分类的HAM10000和用于胸部X射线分类的MIMIC-CXR）上的实验结果表明，CALIN在确保预测中公平的置信度校准方面有效，同时提高了其整体预测准确性，并表现出最小的公平性-效用权衡。我们的代码库可在https://github.com/xingbpshen/medical-calibration-fairness-mllm 找到。", "summary": "本文首次深入探讨了多模态大型语言模型（MLLMs）在医学图像分类的少样本学习中存在的校准偏差和人口不公平性问题。为解决这些问题，研究提出了名为CALIN的推理时校准方法，该方法通过双层程序估计并应用校准矩阵来调整预测置信度。实验结果表明，CALIN在多个医学图像数据集上有效提升了预测准确性，确保了公平的置信度校准，并实现了最小的公平性-效用权衡。", "keywords": "MLLM, 校准偏差, 人口不公平性, 医学图像分类, 少样本学习, CALIN", "comments": "这篇论文的创新点在于首次系统性地研究了MLLM在医学图像分类中少样本学习的校准偏差和人口不公平性，并提出了一个新颖的推理时校准方法CALIN。其重要性在于，解决了MLLM在医疗领域部署的关键安全性和公平性问题，为实际应用提供了更可靠的工具。"}}
{"id": "2504.10888", "title": "CDUPatch: Color-Driven Universal Adversarial Patch Attack for Dual-Modal Visible-Infrared Detectors", "authors": ["Jiahuan Long", "Wen Yao", "Tingsong Jiang", "Chao Ma"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by ACMMM 2025", "url": "http://arxiv.org/abs/2504.10888v2", "summary": "Adversarial patches are widely used to evaluate the robustness of object\ndetection systems in real-world scenarios. These patches were initially\ndesigned to deceive single-modal detectors (e.g., visible or infrared) and have\nrecently been extended to target visible-infrared dual-modal detectors.\nHowever, existing dual-modal adversarial patch attacks have limited attack\neffectiveness across diverse physical scenarios. To address this, we propose\nCDUPatch, a universal cross-modal patch attack against visible-infrared object\ndetectors across scales, views, and scenarios. Specifically, we observe that\ncolor variations lead to different levels of thermal absorption, resulting in\ntemperature differences in infrared imaging. Leveraging this property, we\npropose an RGB-to-infrared adapter that maps RGB patches to infrared patches,\nenabling unified optimization of cross-modal patches. By learning an optimal\ncolor distribution on the adversarial patch, we can manipulate its thermal\nresponse and generate an adversarial infrared texture. Additionally, we\nintroduce a multi-scale clipping strategy and construct a new visible-infrared\ndataset, MSDrone, which contains aerial vehicle images in varying scales and\nperspectives. These data augmentation strategies enhance the robustness of our\npatch in real-world conditions. Experiments on four benchmark datasets (e.g.,\nDroneVehicle, LLVIP, VisDrone, MSDrone) show that our method outperforms\nexisting patch attacks in the digital domain. Extensive physical tests further\nconfirm strong transferability across scales, views, and scenarios.", "comment": "Accepted by ACMMM 2025", "pdf_url": "http://arxiv.org/pdf/2504.10888v2", "cate": "cs.CV", "date": "2025-04-15", "updated": "2025-07-18", "AI": {"title_translation": "CDUPatch：颜色驱动的双模态可见光-红外通用对抗补丁攻击", "tldr": "CDUPatch是一种新的对抗补丁攻击，它利用颜色变化影响热吸收，从而在不同真实场景下对双模态可见光-红外探测器实现更强的攻击效果和泛化性。", "motivation": "现有的双模态对抗补丁攻击在多样化的物理场景中攻击效果有限。", "method": "本文提出了CDUPatch，一种针对可见光-红外目标检测器的通用跨模态补丁攻击。该方法观察到颜色变化会导致不同的热吸收水平，进而引起红外成像中的温度差异。利用这一特性，提出了一种RGB到红外适配器，将RGB补丁映射到红外补丁，实现跨模态补丁的统一优化。通过学习对抗补丁上的最优颜色分布，可以操纵其热响应并生成对抗性红外纹理。此外，还引入了多尺度裁剪策略，并构建了一个新的可见光-红外数据集MSDrone，其中包含不同尺度和视角的航空器图像，以增强补丁在真实世界条件下的鲁棒性。", "result": "在DroneVehicle、LLVIP、VisDrone和MSDrone四个基准数据集上的实验表明，该方法在数字领域优于现有补丁攻击。广泛的物理测试进一步证实了其在不同尺度、视角和场景下的强大可迁移性。", "conclusion": "CDUPatch通过利用颜色变化影响热响应的物理特性，提出了一种有效的跨模态对抗补丁攻击，显著提升了在多样化真实场景下对双模态可见光-红外探测器的攻击效果和鲁棒性。", "translation": "对抗补丁被广泛用于评估目标检测系统在真实世界场景中的鲁棒性。这些补丁最初设计用于欺骗单模态探测器（例如可见光或红外），最近已扩展到针对可见光-红外双模态探测器。然而，现有的双模态对抗补丁攻击在多样化的物理场景中攻击效果有限。为了解决这个问题，我们提出了CDUPatch，一种针对可见光-红外目标检测器，跨尺度、视角和场景的通用跨模态补丁攻击。具体来说，我们观察到颜色变化会导致不同程度的热吸收，从而导致红外成像中的温度差异。利用这一特性，我们提出了一种RGB到红外适配器，将RGB补丁映射到红外补丁，从而实现跨模态补丁的统一优化。通过学习对抗补丁上的最优颜色分布，我们可以操纵其热响应并生成对抗性红外纹理。此外，我们引入了一种多尺度裁剪策略，并构建了一个新的可见光-红外数据集MSDrone，其中包含不同尺度和视角的航空器图像。这些数据增强策略增强了我们补丁在真实世界条件下的鲁棒性。在四个基准数据集（例如DroneVehicle、LLVIP、VisDrone、MSDrone）上的实验表明，我们的方法在数字领域优于现有补丁攻击。广泛的物理测试进一步证实了其在不同尺度、视角和场景下的强大可迁移性。", "summary": "本文提出了CDUPatch，一种颜色驱动的通用对抗补丁攻击，旨在解决现有双模态可见光-红外检测器对抗补丁攻击在多样化物理场景中效果有限的问题。CDUPatch利用颜色变化影响热吸收的特性，通过RGB到红外适配器实现跨模态补丁的统一优化，从而操纵红外响应。结合多尺度裁剪策略和新建的MSDrone数据集，该方法在数字和物理测试中均展现出优于现有攻击的性能和强大的跨场景可迁移性。", "keywords": "对抗补丁, 双模态检测, 可见光-红外, 跨模态攻击, 颜色驱动", "comments": "本文的创新之处在于巧妙地利用了颜色对物体热吸收的影响这一物理特性，将可见光领域的对抗攻击扩展到红外领域，实现了跨模态的通用对抗补丁攻击。同时，引入多尺度裁剪策略和构建新的MSDrone数据集，显著增强了对抗补丁在真实世界复杂条件下的鲁棒性和泛化能力。这对于评估和提升双模态目标检测系统的安全性具有重要意义。"}}
{"id": "2507.13511", "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination", "authors": ["Nabil Abdelaziz Ferhat Taleb", "Abdolazim Rezaei", "Raj Atulkumar Patel", "Mehdi Sookhak"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13511v1", "summary": "Large Language Models (LLMs) offer significant promise for intelligent\ntraffic management; however, current chain-based systems like TrafficGPT are\nhindered by sequential task execution, high token usage, and poor scalability,\nmaking them inefficient for complex, real-world scenarios. To address these\nlimitations, we propose GraphTrafficGPT, a novel graph-based architecture,\nwhich fundamentally redesigns the task coordination process for LLM-driven\ntraffic applications. GraphTrafficGPT represents tasks and their dependencies\nas nodes and edges in a directed graph, enabling efficient parallel execution\nand dynamic resource allocation. The main idea behind the proposed model is a\nBrain Agent that decomposes user queries, constructs optimized dependency\ngraphs, and coordinates a network of specialized agents for data retrieval,\nanalysis, visualization, and simulation. By introducing advanced context-aware\ntoken management and supporting concurrent multi-query processing, the proposed\narchitecture handles interdependent tasks typical of modern urban mobility\nenvironments. Experimental results demonstrate that GraphTrafficGPT reduces\ntoken consumption by 50.2% and average response latency by 19.0% compared to\nTrafficGPT, while supporting simultaneous multi-query execution with up to\n23.0% improvement in efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13511v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "GraphTrafficGPT：通过基于图的AI智能体协调增强交通管理", "tldr": "GraphTrafficGPT提出了一种基于图的AI智能体协调架构，用于智能交通管理，相比现有链式系统，显著降低了token消耗和响应延迟，并提高了多查询处理效率。", "motivation": "现有的大型语言模型（LLMs）在智能交通管理中虽然潜力巨大，但目前的链式系统（如TrafficGPT）存在顺序任务执行、高token使用率和可扩展性差等问题，导致它们在复杂的实际场景中效率低下。", "method": "论文提出了GraphTrafficGPT，一种新颖的基于图的架构，重新设计了LLM驱动的交通应用的任务协调过程。该模型将任务及其依赖关系表示为有向图中的节点和边，实现了高效的并行执行和动态资源分配。核心思想是一个“大脑智能体”（Brain Agent），负责分解用户查询、构建优化的依赖图，并协调由专业智能体（用于数据检索、分析、可视化和模拟）组成的网络。此外，该架构引入了先进的上下文感知token管理，并支持并发多查询处理。", "result": "实验结果表明，与TrafficGPT相比，GraphTrafficGPT将token消耗降低了50.2%，平均响应延迟降低了19.0%。同时，它支持同步多查询执行，效率提高了23.0%。", "conclusion": "GraphTrafficGPT通过其创新的图基架构和智能体协调机制，成功解决了现有LLM驱动交通管理系统的局限性，显著提升了效率、降低了资源消耗，并有效支持了现代城市交通环境中复杂的、相互依赖的任务。", "translation": "大型语言模型（LLMs）为智能交通管理提供了巨大的前景；然而，当前基于链的系统如TrafficGPT受到顺序任务执行、高token使用和可扩展性差的限制，这使得它们在复杂的实际场景中效率低下。为了解决这些限制，我们提出了GraphTrafficGPT，一种新颖的基于图的架构，它从根本上重新设计了LLM驱动交通应用的任务协调过程。GraphTrafficGPT将任务及其依赖关系表示为有向图中的节点和边，从而实现高效的并行执行和动态资源分配。该模型背后的主要思想是一个大脑智能体，它分解用户查询，构建优化的依赖图，并协调一个由专门智能体组成的网络，用于数据检索、分析、可视化和模拟。通过引入先进的上下文感知token管理和支持并发多查询处理，所提出的架构能够处理现代城市移动环境中典型的相互依赖的任务。实验结果表明，与TrafficGPT相比，GraphTrafficGPT将token消耗降低了50.2%，平均响应延迟降低了19.0%，同时支持同步多查询执行，效率提高了23.0%。", "summary": "GraphTrafficGPT是一种新颖的基于图的AI智能体协调系统，旨在提升智能交通管理效率。它通过将任务及其依赖表示为有向图，克服了传统链式LLM系统在顺序执行、高token消耗和可扩展性方面的局限。一个“大脑智能体”负责分解查询并协调专业智能体进行并行处理。该系统引入了上下文感知token管理和并发多查询处理。实验证明，GraphTrafficGPT相比TrafficGPT显著降低了token消耗（50.2%）和响应延迟（19.0%），并提高了多查询效率（23.0%）。", "keywords": "图基AI, LLM, 交通管理, 智能体协调, 效率", "comments": "GraphTrafficGPT的创新之处在于其将图结构引入LLM驱动的交通管理任务协调中，通过并行化和动态资源分配解决了现有链式系统的效率瓶颈。其“大脑智能体”的概念以及对上下文感知token管理和并发多查询的支持，使其在处理复杂、相互依赖的交通任务方面具有显著优势，对LLM在实际交通管理应用中的落地具有重要意义。"}}
{"id": "2507.13646", "title": "A Comprehensive Review of Transformer-based language models for Protein Sequence Analysis and Design", "authors": ["Nimisha Ghosh", "Daniele Santoni", "Debaleena Nawn", "Eleonora Ottaviani", "Giovanni Felici"], "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13646v1", "summary": "The impact of Transformer-based language models has been unprecedented in\nNatural Language Processing (NLP). The success of such models has also led to\ntheir adoption in other fields including bioinformatics. Taking this into\naccount, this paper discusses recent advances in Transformer-based models for\nprotein sequence analysis and design. In this review, we have discussed and\nanalysed a significant number of works pertaining to such applications. These\napplications encompass gene ontology, functional and structural protein\nidentification, generation of de novo proteins and binding of proteins. We\nattempt to shed light on the strength and weaknesses of the discussed works to\nprovide a comprehensive insight to readers. Finally, we highlight shortcomings\nin existing research and explore potential avenues for future developments. We\nbelieve that this review will help researchers working in this field to have an\noverall idea of the state of the art in this field, and to orient their future\nstudies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13646v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于Transformer的语言模型在蛋白质序列分析与设计中的全面综述", "tldr": "本文综述了基于Transformer的语言模型在蛋白质序列分析与设计领域的最新进展，讨论了其在基因本体论、蛋白质识别与生成、蛋白质结合等应用中的优缺点，并指出了未来的研究方向。", "motivation": "Transformer模型在自然语言处理领域取得了空前的成功，并被引入生物信息学领域。本文旨在全面回顾和分析基于Transformer模型在蛋白质序列分析与设计中的最新进展，为研究人员提供该领域的整体概况并指导未来研究。", "method": "本文通过讨论和分析大量与Transformer模型在蛋白质序列分析与设计应用相关的现有工作，涵盖了基因本体论、功能和结构蛋白质识别、从头蛋白质生成以及蛋白质结合等应用。", "result": "综述讨论了基于Transformer的语言模型在蛋白质序列分析与设计中的广泛应用，分析了现有工作的优缺点，并指出了当前研究的不足。", "conclusion": "这篇综述旨在帮助该领域的研究人员全面了解当前Transformer模型在蛋白质序列分析与设计领域的最新进展，并为未来的研究提供方向。", "translation": "Transformer语言模型在自然语言处理（NLP）中产生了前所未有的影响。这些模型的成功也促使它们被应用于包括生物信息学在内的其他领域。考虑到这一点，本文讨论了基于Transformer模型在蛋白质序列分析与设计方面的最新进展。在这篇综述中，我们讨论并分析了大量与此类应用相关的工作。这些应用包括基因本体论、功能和结构蛋白质识别、从头蛋白质生成和蛋白质结合。我们试图阐明所讨论工作的优缺点，以便为读者提供全面的见解。最后，我们强调了现有研究中的不足，并探讨了未来发展的潜在途径。我们相信这篇综述将帮助在该领域工作的研究人员全面了解该领域的最新技术水平，并指导他们未来的研究。", "summary": "本文对基于Transformer的语言模型在蛋白质序列分析与设计领域的应用进行了全面综述。文章讨论并分析了大量相关工作，涵盖了基因本体论、蛋白质识别、从头蛋白质生成和蛋白质结合等应用。综述旨在阐明现有研究的优缺点，并指出未来研究的潜在方向，以帮助研究人员了解该领域的最新进展。", "keywords": "Transformer, 蛋白质序列分析, 蛋白质设计, 语言模型, 生物信息学", "comments": "本文作为一篇综述，系统地梳理了Transformer模型在生物信息学，特别是蛋白质序列分析与设计领域的应用进展。其价值在于为该领域的学者提供了一个全面的视角，不仅总结了现有成就，更重要的是指出了未解决的问题和未来的研究方向，具有较强的指导意义。对于跨领域研究者而言，这是一篇很好的入门和概览性文章。"}}
{"id": "2507.12593", "title": "Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS", "authors": ["Sandesh Rao Mattu", "Nishant Mehrotra", "Robert Calderbank"], "categories": ["eess.SP", "cs.IT", "math.IT"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      7 pages, 5 figures, submitted to IEEE Wireless Communications Letters for possible publication. Copyright maybe transferred without notice", "url": "http://arxiv.org/abs/2507.12593v2", "summary": "Zak-transform based orthogonal time frequency space (Zak-OTFS) is a\ndelay-Doppler (DD) domain modulation scheme in which the signal processing is\ncarried out in the DD domain. The channel when viewed in the DD domain is\npredictable. However, even with Zak-OTFS, pilots need to be sent periodically,\nalbeit at a lower rate. In this paper, we propose a differential communication\nscheme for Zak-OTFS systems that alleviates the need for periodic pilot\ntransmission. Towards this, we analytically show that the detected data can be\nused as a pilot and that the channel estimate obtained from the detected data\ncan enable further detection enabling the \"differential\" aspect of the\ncommunication. Specifically, we leverage the prediction capability of the DD\nchannel in Zak-OTFS to use the channel estimate (obtained from detected data\nsymbols treated as pilots) in the previous instant to detect data in the next\ninstant and propagate this forward. The advantages are two fold. First, it\nallows the data symbols to enjoy higher energy since the energy that would\notherwise be required for pilot symbols can also be allocated to data symbols.\nSecond, it allows for full spectral efficiency compared to point or embedded\npilots. Comparison with the full spectral efficiency achieving spread pilot\nscheme shows that the proposed method achieves better bit-error rate at lower\ncomplexity.", "comment": "7 pages, 5 figures, submitted to IEEE Wireless Communications Letters\n  for possible publication. Copyright maybe transferred without notice", "pdf_url": "http://arxiv.org/pdf/2507.12593v2", "cate": "eess.SP", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "使用Zak-OTFS在移动和时延扩展信道中的差分通信", "tldr": "本文提出了一种基于Zak-OTFS的差分通信方案，通过将检测到的数据用作导频，消除了对周期性导频传输的需求，从而提高了能量效率和频谱效率，并在比特误码率和复杂度方面优于现有方案。", "motivation": "传统的Zak-OTFS系统虽然在时延-多普勒（DD）域信道可预测，但仍需要周期性发送导频信号，这会消耗能量并降低频谱效率。", "method": "本文提出了一种Zak-OTFS系统的差分通信方案。该方案分析表明，检测到的数据可以作为导频，并且从检测数据获得的信道估计可以用于进一步的检测，从而实现“差分”通信。具体来说，它利用Zak-OTFS中DD信道的预测能力，使用前一时刻从检测到的数据符号（视为导频）获得的信道估计来检测下一时刻的数据，并向前传播。", "result": "该方案具有两大优势：首先，数据符号可以获得更高的能量，因为原本用于导频符号的能量可以分配给数据符号；其次，与点导频或嵌入式导频相比，它实现了全频谱效率。与实现全频谱效率的扩频导频方案相比，所提出的方法在较低复杂度下实现了更好的比特误码率。", "conclusion": "本文提出的Zak-OTFS差分通信方案通过利用检测到的数据作为导频，成功消除了周期性导频传输的需求，显著提高了能量和频谱效率，并在性能上优于现有方法。", "translation": "基于Zak变换的正交时频空间（Zak-OTFS）是一种时延-多普勒（DD）域调制方案，其中信号处理在DD域进行。DD域中的信道是可预测的。然而，即使使用Zak-OTFS，仍然需要周期性地发送导频，尽管速率较低。在本文中，我们提出了一种用于Zak-OTFS系统的差分通信方案，该方案消除了周期性导频传输的需求。为此，我们分析表明，检测到的数据可以用作导频，并且从检测数据获得的信道估计可以支持进一步的检测，从而实现通信的“差分”方面。具体来说，我们利用Zak-OTFS中DD信道的预测能力，使用前一时刻从检测到的数据符号（视为导频）获得的信道估计来检测下一时刻的数据，并向前传播。这样做有两大优势。首先，它允许数据符号享受更高的能量，因为原本用于导频符号的能量也可以分配给数据符号。其次，与点导频或嵌入式导频相比，它允许实现全频谱效率。与实现全频谱效率的扩频导频方案相比，所提出的方法在较低复杂度下实现了更好的比特误码率。", "summary": "本文提出了一种针对Zak-OTFS系统的差分通信方案，旨在消除周期性导频传输的需求。该方案利用Zak-OTFS中时延-多普勒（DD）域信道的预测性，将已检测到的数据符号视为导频，并利用其获得的信道估计来迭代检测后续数据。这种方法不仅使得数据符号能分配到更多能量，从而提高能量效率，而且实现了全频谱效率。实验结果表明，与现有的扩频导频方案相比，该方法在较低的复杂度下实现了更优的比特误码率。", "keywords": "Zak-OTFS, 差分通信, 时延-多普勒域, 导频消除, 频谱效率", "comments": "该论文的创新点在于提出了将已检测数据作为导频的差分通信机制，有效解决了Zak-OTFS系统中周期性导频传输带来的能量和频谱效率损耗问题。这种方法利用了DD域信道的预测特性，通过数据驱动的信道估计实现迭代检测，具有重要的实践意义，尤其是在追求高效率和低复杂度的移动通信场景中。"}}
{"id": "2507.14129", "title": "OpenBEATs: A Fully Open-Source General-Purpose Audio Encoder", "authors": ["Shikhar Bharadwaj", "Samuele Cornell", "Kwanghee Choi", "Satoru Fukayama", "Hye-jin Shim", "Soham Deshmukh", "Shinji Watanabe"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14129v1", "summary": "Masked token prediction has emerged as a powerful pre-training objective\nacross language, vision, and speech, offering the potential to unify these\ndiverse modalities through a single pre-training task. However, its application\nfor general audio understanding remains underexplored, with BEATs being the\nonly notable example. BEATs has seen limited modifications due to the absence\nof open-source pre-training code. Furthermore, BEATs was trained only on\nAudioSet, restricting its broader downstream applicability. To address these\ngaps, we present OpenBEATs, an open-source framework that extends BEATs via\nmulti-domain audio pre-training. We conduct comprehensive evaluations across\nsix types of tasks, twenty five datasets, and three audio domains, including\naudio reasoning tasks such as audio question answering, entailment, and\ncaptioning. OpenBEATs achieves state-of-the-art performance on six bioacoustics\ndatasets, two environmental sound datasets and five reasoning datasets,\nperforming better than models exceeding a billion parameters at one-fourth\ntheir parameter size. These results demonstrate the effectiveness of\nmulti-domain datasets and masked token prediction task to learn general-purpose\naudio representations. To promote further research and reproducibility, we\nrelease all pre-training and evaluation code, pretrained and fine-tuned\ncheckpoints, and training logs at https://shikhar-s.github.io/OpenBEATs", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14129v1", "cate": "cs.SD", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "OpenBEATs：一个完全开源的通用音频编码器", "tldr": "OpenBEATs是一个开源框架，通过多领域音频预训练扩展了BEATs，并在多种音频任务上取得了最先进的性能，证明了多领域数据集和掩码令牌预测的有效性。", "motivation": "现有的BEATs模型由于缺乏开源预训练代码而修改受限，且仅在AudioSet上训练，限制了其下游应用。掩码令牌预测在通用音频理解中的应用也未被充分探索。", "method": "提出OpenBEATs，一个开源框架，通过多领域音频预训练扩展BEATs。在六种任务类型、二十五个数据集和三个音频域上进行全面评估，包括音频推理任务。", "result": "OpenBEATs在六个生物声学数据集、两个环境声音数据集和五个推理数据集上取得了最先进的性能，其参数量仅为其他超十亿参数模型的四分之一。结果表明多领域数据集和掩码令牌预测任务对于学习通用音频表示是有效的。", "conclusion": "多领域数据集和掩码令牌预测任务能够有效地学习通用音频表示，OpenBEATs作为开源框架，在多个音频任务上表现出色，并促进了该领域的进一步研究和复现。", "translation": "掩码令牌预测已成为跨语言、视觉和语音领域强大的预训练目标，有望通过单一预训练任务统一这些不同的模态。然而，其在通用音频理解中的应用仍未被充分探索，BEATs是唯一值得注意的例子。由于缺乏开源预训练代码，BEATs的修改受到了限制。此外，BEATs仅在AudioSet上进行训练，限制了其更广泛的下游适用性。为了解决这些不足，我们提出了OpenBEATs，一个通过多领域音频预训练扩展BEATs的开源框架。我们在六种任务类型、二十五个数据集和三个音频域上进行了全面的评估，包括音频问答、蕴涵和字幕等音频推理任务。OpenBEATs在六个生物声学数据集、两个环境声音数据集和五个推理数据集上取得了最先进的性能，其性能优于参数量超过十亿的模型，而其参数量仅为后者的四分之一。这些结果证明了多领域数据集和掩码令牌预测任务在学习通用音频表示方面的有效性。为了促进进一步的研究和可复现性，我们发布了所有预训练和评估代码、预训练和微调检查点以及训练日志，网址为https://shikhar-s.github.io/OpenBEATs", "summary": "该论文介绍了OpenBEATs，一个开源的通用音频编码器框架，旨在解决现有BEATs模型开源代码缺失和训练数据集单一的限制。OpenBEATs通过多领域音频预训练扩展了BEATs，并在涵盖生物声学、环境声音和音频推理等多种任务和数据集上进行了广泛评估。实验结果表明，OpenBEATs在多个数据集上达到了最先进的性能，且参数量远小于同等表现的模型，证明了多领域数据集和掩码令牌预测在学习通用音频表示方面的有效性。为促进研究，所有代码和模型均已开源。", "keywords": "OpenBEATs, 音频编码器, 掩码令牌预测, 多领域预训练, 开源", "comments": "OpenBEATs的创新在于其完全开源的特性和多领域预训练方法，这显著提升了BEATs模型的可用性和泛化能力。其在更小参数量下达到SOTA性能，也凸显了其效率。开源所有代码和模型对于推动音频理解领域的研究和促进结果复现具有重要意义，降低了研究门槛。"}}
{"id": "2504.14452", "title": "ParaPO: Aligning Language Models to Reduce Verbatim Reproduction of Pre-training Data", "authors": ["Tong Chen", "Faeze Brahman", "Jiacheng Liu", "Niloofar Mireshghallah", "Weijia Shi", "Pang Wei Koh", "Luke Zettlemoyer", "Hannaneh Hajishirzi"], "categories": ["cs.CL", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.14452v2", "summary": "Language models (LMs) can memorize and reproduce segments from their\npretraining data verbatim even in non-adversarial settings, raising concerns\nabout copyright, plagiarism, privacy, and creativity. We introduce Paraphrase\nPreference Optimization (ParaPO), a post-training method that fine-tunes LMs to\nreduce unintentional regurgitation while preserving their overall utility.\nParaPO trains LMs to prefer paraphrased versions of memorized segments over the\noriginal verbatim content from the pretraining data. To maintain the ability to\nrecall famous quotations when appropriate, we develop a variant of ParaPO that\nuses system prompts to control regurgitation behavior. In our evaluation on\nLlama3.1-8B, ParaPO consistently reduces regurgitation across all tested\ndatasets (e.g., reducing the regurgitation metric from 17.3 to 12.9 in creative\nwriting), whereas unlearning methods used in prior work to mitigate\nregurgitation are less effective outside their targeted unlearned domain (from\n17.3 to 16.9). When applied to the instruction-tuned Tulu3-8B model, ParaPO\nwith system prompting successfully preserves famous quotation recall while\nreducing unintentional regurgitation (from 8.7 to 6.3 in creative writing) when\nprompted not to regurgitate. In contrast, without ParaPO tuning, prompting the\nmodel not to regurgitate produces only a marginal reduction (8.7 to 8.4).", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.14452v2", "cate": "cs.CL", "date": "2025-04-20", "updated": "2025-07-17", "AI": {"title_translation": "ParaPO：调整语言模型以减少预训练数据的逐字复现", "tldr": "ParaPO是一种后训练方法，通过偏好释义版本而非原始内容来减少语言模型对预训练数据的无意逐字复现，同时保持其整体效用，并通过系统提示符控制著名引语的召回。", "motivation": "语言模型会逐字逐句地复现预训练数据，即使在非对抗性设置下，这引发了对版权、抄袭、隐私和创造力的担忧。", "method": "引入了ParaPO（Paraphrase Preference Optimization），一种后训练方法，用于微调语言模型以减少无意的逐字复现，同时保留其整体效用。ParaPO训练语言模型偏好记忆片段的释义版本而非原始逐字内容。为维持在适当情况下召回著名引语的能力，开发了ParaPO的一个变体，该变体使用系统提示符来控制复现行为。", "result": "在Llama3.1-8B上的评估显示，ParaPO在所有测试数据集中持续减少逐字复现（例如，在创意写作中将复现指标从17.3降至12.9），而先前的去学习方法在其目标去学习领域之外效果不佳（从17.3降至16.9）。应用于指令微调的Tulu3-8B模型时，带有系统提示符的ParaPO在被提示不复现时，成功保留了著名引语的召回，同时减少了无意逐字复现（在创意写作中从8.7降至6.3）。相比之下，没有ParaPO调优时，提示模型不复现仅产生微小减少（8.7降至8.4）。", "conclusion": "ParaPO是一种有效的后训练方法，能够显著减少语言模型对预训练数据的无意逐字复现，同时通过系统提示符的变体保持适当的著名引语召回能力，并且在减少复现方面的效果优于现有去学习方法。", "translation": "语言模型（LMs）即使在非对抗性设置下，也会逐字记忆并复现其预训练数据中的片段，这引发了对版权、抄袭、隐私和创造力的担忧。我们引入了释义偏好优化（ParaPO），这是一种后训练方法，用于微调语言模型以减少无意的逐字复现，同时保留其整体效用。ParaPO训练语言模型偏好记忆片段的释义版本，而不是预训练数据中的原始逐字内容。为了在适当情况下保持回忆著名引语的能力，我们开发了ParaPO的一个变体，该变体使用系统提示符来控制复现行为。在我们对Llama3.1-8B的评估中，ParaPO在所有测试数据集中持续减少复现（例如，在创意写作中将复现指标从17.3降至12.9），而先前用于缓解复现的去学习方法在其目标去学习领域之外效果不佳（从17.3降至16.9）。当应用于指令微调的Tulu3-8B模型时，带有系统提示符的ParaPO在被提示不复现时，成功保留了著名引语的召回，同时减少了无意的复现（在创意写作中从8.7降至6.3）。相比之下，没有ParaPO调优时，提示模型不复现仅产生微小减少（8.7降至8.4）。", "summary": "本文提出了ParaPO（Paraphrase Preference Optimization），一种后训练方法，旨在解决语言模型无意中逐字复现预训练数据的问题，这引发了版权、隐私和创造力方面的担忧。ParaPO通过训练模型偏好记忆内容的释义版本而非原始文本来减少这种复现，同时保持模型效用。为了在必要时保留著名引语的召回能力，ParaPO还引入了使用系统提示符控制复现行为的变体。实验结果表明，ParaPO在Llama3.1-8B上显著降低了复现率，并且在指令微调的Tulu3-8B模型上，带有系统提示符的ParaPO成功地在减少无意复现的同时保留了著名引语的召回，其效果优于现有去学习方法。", "keywords": "语言模型, 逐字复现, 释义偏好优化, ParaPO, 后训练", "comments": "ParaPO的创新之处在于其通过“偏好释义”的机制来减少模型逐字复现，这与传统的“遗忘”方法不同，后者可能导致模型在非目标领域效果不佳。此外，通过引入系统提示符来控制著名引语的召回，解决了在减少复现同时保持模型必要知识的问题，这增加了方法的实用性。该方法对于解决语言模型的版权、隐私和创造力问题具有重要意义。"}}
{"id": "2412.17531", "title": "Invisible Textual Backdoor Attacks based on Dual-Trigger", "authors": ["Yang Hou", "Qiuling Yue", "Lujia Chai", "Guozhao Liao", "Wenbao Han", "Wei Ou"], "categories": ["cs.CR", "cs.AI"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2412.17531v3", "summary": "Backdoor attacks pose an important security threat to textual large language\nmodels. Exploring textual backdoor attacks not only helps reveal the potential\nsecurity risks of models, but also promotes innovation and development of\ndefense mechanisms. Currently, most textual backdoor attack methods are based\non a single trigger. For example, inserting specific content into text as a\ntrigger or changing the abstract text features to be a trigger. However, the\nadoption of this single-trigger mode makes the existing backdoor attacks\nsubject to certain limitations: either they are easily identified by the\nexisting defense strategies, or they have certain shortcomings in attack\nperformance and in the construction of poisoned datasets. In order to solve\nthese issues, a dual-trigger backdoor attack method is proposed in this paper.\nSpecifically, we use two different attributes, syntax and mood (we use\nsubjunctive mood as an example in this article), as two different triggers. It\nmakes our backdoor attack method similar to a double landmine which can have\ncompletely different trigger conditions simultaneously. Therefore, this method\nnot only improves the flexibility of trigger mode, but also enhances the\nrobustness against defense detection. A large number of experimental results\nshow that this method significantly outperforms the previous methods based on\nabstract features in attack performance, and achieves comparable attack\nperformance (almost 100\\% attack success rate) with the insertion-based method.\nIn addition, in order to further improve the attack performance, we also give\nthe construction method of the poisoned dataset.The code and data of this paper\ncan be obtained at https://github.com/HoyaAm/Double-Landmines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2412.17531v3", "cate": "cs.CR", "date": "2024-12-23", "updated": "2025-07-18", "AI": {"title_translation": "基于双触发的隐形文本后门攻击", "tldr": "提出一种基于语法和情感双触发的隐形文本后门攻击方法，以提高攻击的隐蔽性和鲁棒性，克服了单触发方法的局限性。", "motivation": "文本后门攻击对大型语言模型构成重要安全威胁。现有单触发方法易被检测或在攻击性能和中毒数据集构建上存在缺陷。本文旨在解决这些问题，揭示潜在安全风险并促进防御机制发展。", "method": "提出一种双触发后门攻击方法，利用语法和情感（例如虚拟语气）作为两个不同的触发器。这种方法类似于“双地雷”，能够同时满足不同的触发条件，从而提高触发模式的灵活性和对抗防御检测的鲁棒性。", "result": "实验结果表明，该方法在攻击性能上显著优于以前基于抽象特征的方法，并与基于插入的方法达到了相当的攻击性能（几乎100%的攻击成功率）。此外，论文还提供了中毒数据集的构建方法以进一步提高攻击性能。", "conclusion": "本文提出的双触发后门攻击方法有效解决了现有单触发攻击的局限性，在提高攻击隐蔽性和鲁棒性方面表现出色，并取得了显著的攻击成功率。", "translation": "后门攻击对文本大型语言模型构成了重要的安全威胁。探索文本后门攻击不仅有助于揭示模型的潜在安全风险，还能促进防御机制的创新和发展。目前，大多数文本后门攻击方法都基于单一触发器。例如，将特定内容插入文本作为触发器或改变抽象文本特征作为触发器。然而，这种单一触发模式的采用使得现有后门攻击受到某些限制：它们要么容易被现有防御策略识别，要么在攻击性能和中毒数据集的构建方面存在某些缺点。为了解决这些问题，本文提出了一种双触发后门攻击方法。具体来说，我们使用语法和情感（本文以虚拟语气为例）这两种不同属性作为两个不同的触发器。这使得我们的后门攻击方法类似于一个能够同时具有完全不同触发条件的双地雷。因此，这种方法不仅提高了触发模式的灵活性，还增强了对抗防御检测的鲁棒性。大量的实验结果表明，该方法在攻击性能上显著优于以前基于抽象特征的方法，并与基于插入的方法达到了相当的攻击性能（几乎100%的攻击成功率）。此外，为了进一步提高攻击性能，我们还给出了中毒数据集的构建方法。本文的代码和数据可以在 https://github.com/HoyaAm/Double-Landmines 获取。", "summary": "本文针对现有文本大型语言模型单触发后门攻击易被检测或性能不足的问题，提出了一种基于语法和情感（如虚拟语气）的双触发隐形文本后门攻击方法。该方法通过结合两个独立触发条件，显著提高了攻击的灵活性和对防御机制的鲁棒性。实验证明，其攻击性能远超基于抽象特征的方法，并能达到与基于插入方法相当的近100%成功率，且提供了中毒数据集构建方案。", "keywords": "文本后门攻击, 双触发, 大型语言模型, 隐形攻击, 安全威胁", "comments": "这篇论文创新性地引入了“双触发”机制来增强文本后门攻击的隐蔽性和鲁棒性，克服了传统单触发攻击易被识别的局限性。这种“双地雷”的比喻形象地说明了其工作原理。研究这类攻击有助于我们更好地理解大型语言模型的潜在安全漏洞，从而开发更有效的防御策略，对LLM安全领域具有重要意义。"}}
{"id": "2501.03572", "title": "From Code to Compliance: Assessing ChatGPT's Utility in Designing an Accessible Webpage -- A Case Study", "authors": ["Ammar Ahmed", "Margarida Fresco", "Fredrik Forsberg", "Hallvard Grotli"], "categories": ["cs.HC", "cs.AI", "cs.CL", "D.1.2; F.3.1; F.4.1; D.3.2; H.1.2; H.5.2; D.2.2; H.1.2; I.3.6;\n  H.5.4; H.5.1"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2501.03572v2", "summary": "Web accessibility ensures that individuals with disabilities can access and\ninteract with digital content without barriers, yet a significant majority of\nmost used websites fail to meet accessibility standards. This study evaluates\nChatGPT's (GPT-4o) ability to generate and improve web pages in line with Web\nContent Accessibility Guidelines (WCAG). While ChatGPT can effectively address\naccessibility issues when prompted, its default code often lacks compliance,\nreflecting limitations in its training data and prevailing inaccessible web\npractices. Automated and manual testing revealed strengths in resolving simple\nissues but challenges with complex tasks, requiring human oversight and\nadditional iterations. Unlike prior studies, we incorporate manual evaluation,\ndynamic elements, and use the visual reasoning capability of ChatGPT along with\nthe prompts to fix accessibility issues. Providing screenshots alongside\nprompts enhances the LLM's ability to address accessibility issues by allowing\nit to analyze surrounding components, such as determining appropriate contrast\ncolors. We found that effective prompt engineering, such as providing concise,\nstructured feedback and incorporating visual aids, significantly enhances\nChatGPT's performance. These findings highlight the potential and limitations\nof large language models for accessible web development, offering practical\nguidance for developers to create more inclusive websites.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2501.03572v2", "cate": "cs.HC", "date": "2025-01-07", "updated": "2025-07-17", "AI": {"title_translation": "从代码到合规：评估 ChatGPT 在设计无障碍网页中的效用——一项案例研究", "tldr": "本研究评估了 ChatGPT (GPT-4o) 在生成和改进符合 WCAG 标准的无障碍网页方面的能力，发现其在有效提示下表现良好，但默认代码存在缺陷，且对复杂问题仍需人工干预。", "motivation": "尽管网络无障碍对于残障人士访问数字内容至关重要，但绝大多数常用网站未能达到无障碍标准。本研究旨在评估 ChatGPT 在创建符合无障碍指南的网页方面的效用。", "method": "本研究评估了 ChatGPT (GPT-4o) 生成和改进符合网络内容无障碍指南 (WCAG) 的网页的能力。研究采用了自动化和人工测试，并与以往研究不同，结合了人工评估、动态元素以及 ChatGPT 的视觉推理能力，通过提示和提供屏幕截图来修复无障碍问题。", "result": "ChatGPT 在接收到提示后能有效解决无障碍问题，但其默认生成的代码常不符合标准，这反映了其训练数据和普遍存在的无障碍实践的局限性。自动化和人工测试显示，ChatGPT 在解决简单问题上表现出色，但在处理复杂任务时遇到挑战，需要人工监督和额外迭代。提供屏幕截图以及提示能增强大型语言模型解决无障碍问题的能力。有效的提示工程，如提供简洁、结构化的反馈和结合视觉辅助，能显著提升 ChatGPT 的性能。", "conclusion": "本研究结果揭示了大型语言模型在无障碍网页开发中的潜力和局限性，并为开发者创建更具包容性的网站提供了实用指导。", "translation": "网络无障碍确保残障人士能够无障碍地访问和互动数字内容，然而绝大多数常用网站未能达到无障碍标准。本研究评估了 ChatGPT (GPT-4o) 在生成和改进符合网络内容无障碍指南 (WCAG) 的网页方面的能力。虽然 ChatGPT 在接收到提示后能有效解决无障碍问题，但其默认生成的代码常不符合标准，这反映了其训练数据和普遍存在的无障碍网络实践的局限性。自动化和人工测试显示，其在解决简单问题上表现出色，但在处理复杂任务时遇到挑战，需要人工监督和额外迭代。与以往研究不同，我们结合了人工评估、动态元素，并利用 ChatGPT 的视觉推理能力和提示来修复无障碍问题。提供屏幕截图以及提示能增强大型语言模型解决无障碍问题的能力，使其能够分析周围组件，例如确定合适的对比颜色。我们发现，有效的提示工程，例如提供简洁、结构化的反馈和结合视觉辅助，能显著提升 ChatGPT 的性能。这些发现揭示了大型语言模型在无障碍网页开发中的潜力和局限性，为开发者创建更具包容性的网站提供了实用指导。", "summary": "本研究评估了 ChatGPT (GPT-4o) 在生成和改进符合 WCAG 标准的无障碍网页方面的能力。研究发现，尽管 ChatGPT 在有效提示下能解决无障碍问题，但其默认代码常不合规。测试显示其擅长处理简单问题，但对复杂任务仍需人工干预。研究强调通过提供屏幕截图和有效的提示工程（如结构化反馈和视觉辅助）可显著提升 ChatGPT 的性能。结果揭示了大型语言模型在无障碍网页开发中的潜力和局限性。", "keywords": "ChatGPT, 网络无障碍, WCAG, 大型语言模型, 提示工程", "comments": "本文通过案例研究评估了 ChatGPT 在无障碍网页设计中的效用，创新性地引入了人工评估、动态元素以及利用 ChatGPT 的视觉推理能力（结合屏幕截图）来修复无障碍问题。这为大型语言模型在无障碍开发领域的应用提供了新的视角和实践指导，尤其强调了提示工程和视觉辅助的重要性，对开发者具有重要参考价值。"}}
{"id": "2501.10484", "title": "Bias in Decision-Making for AI's Ethical Dilemmas: A Comparative Study of ChatGPT and Claude", "authors": ["Yile Yan", "Yuqi Zhu", "Wentao Xu"], "categories": ["cs.CY", "cs.AI"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by International AAAI Conference on Web and Social Media 2026, sunny Los Angeles, California", "url": "http://arxiv.org/abs/2501.10484v2", "summary": "Recent advances in Large Language Models (LLMs) have enabled human-like\nresponses across various tasks, raising questions about their ethical\ndecision-making capabilities and potential biases. This study investigates\nprotected attributes in LLMs through systematic evaluation of their responses\nto ethical dilemmas. Using two prominent models - GPT-3.5 Turbo and Claude 3.5\nSonnet - we analyzed their decision-making patterns across multiple protected\nattributes including age, gender, race, appearance, and disability status.\nThrough 11,200 experimental trials involving both single-factor and two-factor\nprotected attribute combinations, we evaluated the models' ethical preferences,\nsensitivity, stability, and clustering of preferences. Our findings reveal\nsignificant protected attributeses in both models, with consistent preferences\nfor certain features (e.g., \"good-looking\") and systematic neglect of others.\nNotably, while GPT-3.5 Turbo showed stronger preferences aligned with\ntraditional power structures, Claude 3.5 Sonnet demonstrated more diverse\nprotected attribute choices. We also found that ethical sensitivity\nsignificantly decreases in more complex scenarios involving multiple protected\nattributes. Additionally, linguistic referents heavily influence the models'\nethical evaluations, as demonstrated by differing responses to racial\ndescriptors (e.g., \"Yellow\" versus \"Asian\"). These findings highlight critical\nconcerns about the potential impact of LLM biases in autonomous decision-making\nsystems and emphasize the need for careful consideration of protected\nattributes in AI development. Our study contributes to the growing body of\nresearch on AI ethics by providing a systematic framework for evaluating\nprotected attributes in LLMs' ethical decision-making capabilities.", "comment": "This paper has been accepted by International AAAI Conference on Web\n  and Social Media 2026, sunny Los Angeles, California", "pdf_url": "http://arxiv.org/pdf/2501.10484v2", "cate": "cs.CY", "date": "2025-01-17", "updated": "2025-07-18", "AI": {"title_translation": "人工智能伦理困境决策中的偏见：ChatGPT与Claude的比较研究", "tldr": "本研究通过系统评估ChatGPT和Claude在伦理困境中的反应，揭示了大型语言模型在年龄、性别、种族、外貌和残疾等受保护属性方面的显著偏见。", "motivation": "随着大型语言模型（LLMs）在各种任务中展现出类人响应能力，其伦理决策能力和潜在偏见引发了关注。本研究旨在调查LLMs在伦理困境中的受保护属性偏见。", "method": "本研究使用GPT-3.5 Turbo和Claude 3.5 Sonnet两个模型，通过11,200次实验，分析了它们在包括年龄、性别、种族、外貌和残疾状态等受保护属性组合下的决策模式。评估指标包括伦理偏好、敏感性、稳定性和偏好聚类。", "result": "研究发现两个模型都存在显著的受保护属性偏见，对某些特征（如“好看”）有持续偏好，而系统性忽视其他特征。GPT-3.5 Turbo的偏好更符合传统权力结构，而Claude 3.5 Sonnet则表现出更多样化的受保护属性选择。在涉及多个受保护属性的复杂场景中，伦理敏感性显著下降。语言指代物（如“黄种人”与“亚洲人”）也严重影响模型的伦理评估。", "conclusion": "这些发现强调了LLM偏见在自主决策系统中的潜在影响，并强调在AI开发中需仔细考虑受保护属性。本研究通过提供一个系统性框架，为评估LLM伦理决策能力中的受保护属性偏见做出了贡献。", "translation": "大型语言模型（LLMs）的最新进展使其能够在各种任务中产生类人响应，这引发了对其伦理决策能力和潜在偏见的质疑。本研究通过系统评估LLMs对伦理困境的反应，调查了其在受保护属性方面的表现。我们使用两个知名模型——GPT-3.5 Turbo和Claude 3.5 Sonnet——分析了它们在包括年龄、性别、种族、外貌和残疾状态在内的多个受保护属性上的决策模式。通过11,200次涉及单因素和双因素受保护属性组合的实验，我们评估了模型的伦理偏好、敏感性、稳定性和偏好聚类。我们的研究结果揭示了两个模型中都存在显著的受保护属性偏见，对某些特征（例如“好看”）有持续偏好，并系统性地忽视其他特征。值得注意的是，虽然GPT-3.5 Turbo表现出更符合传统权力结构的强烈偏好，但Claude 3.5 Sonnet展示了更多样化的受保护属性选择。我们还发现，在涉及多个受保护属性的更复杂场景中，伦理敏感性显著下降。此外，语言指代物严重影响了模型的伦理评估，例如对不同种族描述符（如“黄种人”与“亚洲人”）的反应不同。这些发现突出了LLM偏见在自主决策系统中的潜在影响所带来的关键担忧，并强调在AI开发中需要仔细考虑受保护属性。我们的研究通过提供一个系统框架来评估LLMs伦理决策能力中的受保护属性，为日益增长的AI伦理研究做出了贡献。", "summary": "本研究比较了GPT-3.5 Turbo和Claude 3.5 Sonnet在处理伦理困境时的决策偏见，特别关注年龄、性别、种族、外貌和残疾等受保护属性。通过11,200次实验，发现两个模型均存在显著偏见，对某些特征有偏好，对另一些则忽视。GPT-3.5 Turbo的偏见更倾向传统权力结构，而Claude 3.5 Sonnet则更具多样性。研究还指出，复杂场景会降低模型的伦理敏感性，且语言指代物对伦理评估有重要影响。研究强调了LLM偏见对自主决策系统的潜在危害，并提出了评估LLM伦理决策能力中受保护属性偏见的系统框架。", "keywords": "大型语言模型, 伦理偏见, 决策制定, 受保护属性, ChatGPT, Claude", "comments": "该研究通过大规模实验（11,200次）系统性地评估了主流大型语言模型在伦理困境中的偏见，特别关注了受保护属性，具有重要的现实意义。其发现揭示了模型在复杂场景下伦理敏感度下降以及语言对偏见的影响，为AI伦理和负责任的AI开发提供了宝贵见解。创新点在于其详细的实验设计和对不同模型偏见模式的比较分析。"}}
{"id": "2507.13474", "title": "Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers", "authors": ["Liang Lin", "Zhihao Xu", "Xuehai Tang", "Shi Liu", "Biyu Zhou", "Fuqing Zhu", "Jizhong Han", "Songlin Hu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13474v1", "summary": "The safety of large language models (LLMs) has garnered significant research\nattention. In this paper, we argue that previous empirical studies demonstrate\nLLMs exhibit a propensity to trust information from authoritative sources, such\nas academic papers, implying new possible vulnerabilities. To verify this\npossibility, a preliminary analysis is designed to illustrate our two findings.\nBased on this insight, a novel jailbreaking method, Paper Summary Attack\n(\\llmname{PSA}), is proposed. It systematically synthesizes content from either\nattack-focused or defense-focused LLM safety paper to construct an adversarial\nprompt template, while strategically infilling harmful query as adversarial\npayloads within predefined subsections. Extensive experiments show significant\nvulnerabilities not only in base LLMs, but also in state-of-the-art reasoning\nmodel like Deepseek-R1. PSA achieves a 97\\% attack success rate (ASR) on\nwell-aligned models like Claude3.5-Sonnet and an even higher 98\\% ASR on\nDeepseek-R1. More intriguingly, our work has further revealed diametrically\nopposed vulnerability bias across different base models, and even between\ndifferent versions of the same model, when exposed to either attack-focused or\ndefense-focused papers. This phenomenon potentially indicates future research\nclues for both adversarial methodologies and safety alignment.Code is available\nat https://github.com/233liang/Paper-Summary-Attack", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13474v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "论文摘要攻击：通过LLM安全论文越狱大型语言模型", "tldr": "本文提出了一种名为“论文摘要攻击”（PSA）的新型越狱方法，通过利用LLM对学术论文等权威信息的信任，将有害查询嵌入到安全论文内容中，成功对多种LLM进行越狱，并揭示了模型间不同的漏洞偏向。", "motivation": "以往的实证研究表明，大型语言模型（LLMs）倾向于信任来自学术论文等权威来源的信息，这暗示了新的潜在漏洞。为了验证这种可能性，本研究旨在探索并利用这一特性进行越狱攻击。", "method": "提出了一种名为“论文摘要攻击”（PSA）的新型越狱方法。该方法系统地综合攻击型或防御型LLM安全论文的内容，构建对抗性提示模板，并策略性地将有害查询作为对抗性载荷填充到预定义的子部分中。", "result": "实验表明，PSA不仅在基础LLM中，而且在Deepseek-R1等先进推理模型中都存在显著漏洞。PSA在Claude3.5-Sonnet等对齐良好的模型上实现了97%的攻击成功率（ASR），在Deepseek-R1上实现了更高的98%ASR。更重要的是，研究发现不同基础模型之间，甚至同一模型的不同版本之间，在暴露于攻击型或防御型论文时，存在截然相反的漏洞偏向。", "conclusion": "本文提出的论文摘要攻击（PSA）成功地利用了LLM对权威信息的信任，实现了高效的越狱。研究结果不仅揭示了当前LLM的显著安全漏洞，还发现了模型在面对不同类型安全论文时存在的漏洞偏向，这为未来的对抗性方法和安全对齐研究提供了重要的线索。", "translation": "大型语言模型（LLMs）的安全性受到了广泛的研究关注。在本文中，我们认为之前的实证研究表明LLMs倾向于信任来自学术论文等权威来源的信息，这意味着可能存在新的漏洞。为了验证这种可能性，我们设计了一项初步分析来阐明我们的两个发现。基于这一洞察，我们提出了一种新颖的越狱方法，即论文摘要攻击（PSA）。它系统地综合了攻击型或防御型LLM安全论文的内容，以构建对抗性提示模板，同时战略性地将有害查询作为对抗性载荷填充到预定义的子部分中。大量的实验表明，不仅基础LLMs存在显著漏洞，而且像Deepseek-R1这样的最先进推理模型也存在漏洞。PSA在Claude3.5-Sonnet等对齐良好的模型上实现了97%的攻击成功率（ASR），在Deepseek-R1上实现了更高的98%ASR。更有趣的是，我们的工作进一步揭示了不同基础模型之间，甚至同一模型的不同版本之间，在暴露于攻击型或防御型论文时，存在截然相反的漏洞偏向。这种现象可能预示着未来对抗性方法和安全对齐的研究线索。代码可在https://github.com/233liang/Paper-Summary-Attack获得。", "summary": "本文提出了一种新颖的越狱方法，即“论文摘要攻击”（PSA），该方法利用大型语言模型（LLMs）对学术论文等权威信息的信任，通过合成LLM安全论文内容并嵌入有害查询来构建对抗性提示。实验证明，PSA在多种LLM上，包括对齐良好的模型和推理模型，均取得了极高的攻击成功率（最高达98%）。研究还揭示了不同模型在面对攻击型或防御型论文时表现出不同的漏洞偏向，为LLM的安全研究提供了新的方向。", "keywords": "LLM越狱, 论文摘要攻击, 大模型安全, 对抗性攻击, 漏洞偏向", "comments": "本文提出了一种新颖且富有创意的越狱方法，其创新点在于利用了LLM对权威学术论文的内在信任，而非传统的提示工程技巧。这种方法的高成功率凸显了当前LLM安全对齐的潜在缺陷，并揭示了模型在处理特定类型信息时可能存在的盲区。发现不同模型甚至同一模型不同版本之间存在截然相反的漏洞偏向，这一洞察对未来的对抗性攻击和防御策略研究具有重要指导意义。"}}
{"id": "2507.13731", "title": "Pass-efficient Randomized Algorithms for Low-rank Approximation of Quaternion Matrices", "authors": ["Salman Ahmadi-Asl", "Malihe Nobakht Kooshkghazi", "Valentin Leplat"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13731v1", "summary": "Randomized algorithms for low-rank approximation of quaternion matrices have\ngained increasing attention in recent years. However, existing methods overlook\npass efficiency, the ability to limit the number of passes over the input\nmatrix-which is critical in modern computing environments dominated by\ncommunication costs. We address this gap by proposing a suite of pass-efficient\nrandomized algorithms that let users directly trade pass budget for\napproximation accuracy. Our contributions include: (i) a family of\narbitrary-pass randomized algorithms for low-rank approximation of quaternion\nmatrices that operate under a user-specified number of matrix views, and (ii) a\npass-efficient extension of block Krylov subspace methods that accelerates\nconvergence for matrices with slowly decaying spectra. Furthermore, we\nestablish spectral norm error bounds showing that the expected approximation\nerror decays exponentially with the number of passes. Finally, we validate our\nframework through extensive numerical experiments and demonstrate its practical\nrelevance across multiple applications, including quaternionic data\ncompression, matrix completion, image super-resolution, and deep learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13731v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "四元数矩阵低秩逼近的通行高效随机算法", "tldr": "本文提出了一系列通行高效的随机算法，用于四元数矩阵的低秩逼近，解决了现有方法忽视通行效率的问题，并证明了误差随通行次数呈指数衰减。", "motivation": "现有用于四元数矩阵低秩逼近的随机算法忽略了通行效率，即限制对输入矩阵遍历次数的能力，这在通信成本为主导的现代计算环境中至关重要。本文旨在解决这一空白。", "method": "本文提出了一套通行高效的随机算法，允许用户直接权衡通行预算和逼近精度。具体贡献包括：(i) 一系列用于四元数矩阵低秩逼近的任意通行随机算法，可在用户指定的矩阵视图次数下运行；(ii) 块Krylov子空间方法的通行高效扩展，用于加速谱衰减缓慢矩阵的收敛。", "result": "研究建立了谱范数误差界，表明预期逼近误差随通行次数呈指数衰减。此外，通过广泛的数值实验验证了所提出的框架，并证明了其在四元数数据压缩、矩阵补全、图像超分辨率和深度学习等多种应用中的实际相关性。", "conclusion": "本文成功开发并验证了一系列通行高效的随机算法，用于四元数矩阵的低秩逼近，解决了通信成本高昂环境下的关键问题，并通过理论分析和实际应用展示了其有效性和广泛适用性。", "translation": "近年来，用于四元数矩阵低秩逼近的随机算法越来越受到关注。然而，现有方法忽略了通行效率，即限制对输入矩阵遍历次数的能力——这在通信成本为主导的现代计算环境中至关重要。我们通过提出一套通行高效的随机算法来弥补这一空白，这些算法允许用户直接权衡通行预算和逼近精度。我们的贡献包括：(i) 一系列用于四元数矩阵低秩逼近的任意通行随机算法，可在用户指定的矩阵视图次数下运行；(ii) 块Krylov子空间方法的通行高效扩展，用于加速谱衰减缓慢矩阵的收敛。此外，我们建立了谱范数误差界，表明预期逼近误差随通行次数呈指数衰减。最后，我们通过广泛的数值实验验证了我们的框架，并证明了其在四元数数据压缩、矩阵补全、图像超分辨率和深度学习等多种应用中的实际相关性。", "summary": "本文针对现有四元数矩阵低秩逼近随机算法在通行效率方面的不足，提出了一套新型的通行高效随机算法。这些算法允许用户根据需求平衡通行次数与逼近精度，其中包括任意通行算法和块Krylov子空间方法的通行高效扩展。理论分析证明了逼近误差随通行次数呈指数衰减，并通过大量实验验证了其在多个实际应用中的有效性，例如数据压缩和图像处理。", "keywords": "低秩逼近, 四元数矩阵, 随机算法, 通行高效, 通信成本", "comments": "这项工作创新性地将通行效率引入到四元数矩阵低秩逼近的随机算法中，解决了现代计算环境中通信成本高昂的关键问题。其提出的任意通行算法和块Krylov扩展方法具有普适性，理论上证明了误差的指数衰减，并通过广泛的应用验证了其实用价值。"}}
{"id": "2202.10742", "title": "Acceleration of Gossip Algorithms through the Euler-Poisson-Darboux Equation", "authors": ["Raphaël Berthier", "Mufan Bill Li"], "categories": ["cs.DC", "cs.MA"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2202.10742v2", "summary": "Gossip algorithms and their accelerated versions have been studied\nexclusively in discrete time on graphs. In this work, we take a different\napproach, and consider the scaling limit of gossip algorithms in both large\ngraphs and large number of iterations. These limits lead to well-known partial\ndifferential equations (PDEs) with insightful properties. On lattices, we prove\nthat the non-accelerated gossip algorithm of Boyd et al. [2006] converges to\nthe heat equation, and the accelerated Jacobi polynomial iteration of Berthier\net al. [2020] converges to the Euler-Poisson-Darboux (EPD) equation - a damped\nwave equation. Remarkably, with appropriate parameters, the fundamental\nsolution of the EPD equation has the ideal gossip behaviour: a uniform density\nover an ellipsoid, whose radius increases at a rate proportional to t - the\nfastest possible rate for locally communicating gossip algorithms. This is in\ncontrast with the heat equation where the density spreads on a typical scale of\n$\\sqrt{t}$. Additionally, we provide simulations demonstrating that the gossip\nalgorithms are accurately approximated by their limiting PDEs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2202.10742v2", "cate": "cs.DC", "date": "2022-02-22", "updated": "2025-07-18", "AI": {"title_translation": "通过欧拉-泊松-达布方程加速八卦算法", "tldr": "本文通过考虑八卦算法在大图和大量迭代下的尺度极限，将其与偏微分方程联系起来，发现加速的八卦算法收敛到欧拉-泊松-达布（EPD）方程，其扩散速度比传统八卦算法更快。", "motivation": "八卦算法及其加速版本此前仅在图上的离散时间域内进行研究。本文采取不同方法，考虑八卦算法在大图和大量迭代下的尺度极限，以揭示其与偏微分方程的联系并探索其内在性质。", "method": "研究八卦算法在大图和大量迭代下的尺度极限。具体地，证明了Boyd等人（2006）的非加速八卦算法收敛到热方程，而Berthier等人（2020）的加速Jacobi多项式迭代收敛到欧拉-泊松-达布（EPD）方程（一个阻尼波动方程）。此外，通过模拟验证了八卦算法可以通过其极限PDEs精确近似。", "result": "非加速八卦算法收敛到热方程。加速的Jacobi多项式迭代收敛到欧拉-泊松-达布（EPD）方程。EPD方程在适当参数下，其基本解具有理想的八卦行为：在椭球体上具有均匀密度，其半径以与t成比例的速度增加，这是局部通信八卦算法可能达到的最快速度。这与热方程中密度以$\\sqrt{t}$典型尺度扩散形成对比。模拟结果表明，八卦算法通过其极限PDEs得到了精确近似。", "conclusion": "通过将八卦算法的尺度极限与偏微分方程（特别是欧拉-泊松-达布方程）联系起来，本研究为理解和设计更快速的八卦算法提供了理论基础，并揭示了加速八卦算法能够实现局部通信的最快扩散速度。", "translation": "八卦算法及其加速版本此前仅在图上的离散时间域内进行研究。在这项工作中，我们采取了一种不同的方法，考虑了八卦算法在大图和大量迭代下的尺度极限。这些极限导致了具有深刻性质的著名偏微分方程（PDEs）。在格点上，我们证明了Boyd等人[2006]的非加速八卦算法收敛到热方程，而Berthier等人[2020]的加速Jacobi多项式迭代收敛到欧拉-泊松-达布（EPD）方程——一个阻尼波动方程。值得注意的是，在适当的参数下，EPD方程的基本解具有理想的八卦行为：在椭球体上具有均匀密度，其半径以与t成比例的速度增加——这是局部通信八卦算法可能达到的最快速度。这与热方程中密度以$\\sqrt{t}$典型尺度扩散形成对比。此外，我们提供了模拟，证明八卦算法通过其极限PDEs得到了精确近似。", "summary": "本文研究了八卦算法在大图和大量迭代下的尺度极限，将其与偏微分方程相关联。研究发现，非加速八卦算法收敛于热方程，而加速的Jacobi多项式迭代收敛于欧拉-泊松-达布（EPD）方程。EPD方程的基本解展示出理想的八卦传播特性，其扩散速度（与时间t成正比）远快于热方程（与$\\sqrt{t}$成正比）。模拟结果也验证了这些极限PDEs能准确近似八卦算法的行为。", "keywords": "八卦算法, 尺度极限, 欧拉-泊松-达布方程, 热方程, 加速算法", "comments": "本文的创新之处在于将离散时间域的八卦算法与连续时间域的偏微分方程联系起来，特别是引入了欧拉-泊松-达布方程来解释加速八卦算法的更快收敛速度。这为理解和设计高效分布式算法提供了新的理论视角和工具，揭示了加速八卦算法达到理论上最快传播速度的可能性。"}}
{"id": "2507.13387", "title": "From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction", "authors": ["Chihiro Noguchi", "Takaki Yamamoto"], "categories": ["cs.CV", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted to ICCV Workshop 2025", "url": "http://arxiv.org/abs/2507.13387v1", "summary": "Accurate perception of the surrounding environment is essential for safe\nautonomous driving. 3D occupancy prediction, which estimates detailed 3D\nstructures of roads, buildings, and other objects, is particularly important\nfor vision-centric autonomous driving systems that do not rely on LiDAR\nsensors. However, in 3D semantic occupancy prediction -- where each voxel is\nassigned a semantic label -- annotated LiDAR point clouds are required, making\ndata acquisition costly. In contrast, large-scale binary occupancy data, which\nonly indicate occupied or free space without semantic labels, can be collected\nat a lower cost. Despite their availability, the potential of leveraging such\ndata remains unexplored. In this study, we investigate the utilization of\nlarge-scale binary occupancy data from two perspectives: (1) pre-training and\n(2) learning-based auto-labeling. We propose a novel binary occupancy-based\nframework that decomposes the prediction process into binary and semantic\noccupancy modules, enabling effective use of binary occupancy data. Our\nexperimental results demonstrate that the proposed framework outperforms\nexisting methods in both pre-training and auto-labeling tasks, highlighting its\neffectiveness in enhancing 3D semantic occupancy prediction. The code is\navailable at https://github.com/ToyotaInfoTech/b2s-occupancy", "comment": "Accepted to ICCV Workshop 2025", "pdf_url": "http://arxiv.org/pdf/2507.13387v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "从二元到语义：利用大规模二元占用数据进行3D语义占用预测", "tldr": "本研究提出了一种新颖的框架，利用大规模二元占用数据通过预训练和学习型自动标注来提升3D语义占用预测的性能。", "motivation": "准确感知周围环境对于自动驾驶至关重要，特别是对于不依赖LiDAR传感器的视觉中心系统。3D语义占用预测需要昂贵的带标注LiDAR点云数据，而大规模二元占用数据成本较低但其潜力尚未被探索。", "method": "我们提出了一个新颖的基于二元占用的框架，将预测过程分解为二元和语义占用模块，从而有效利用二元占用数据。研究从预训练和学习型自动标注两个角度探讨了二元占用数据的利用。", "result": "实验结果表明，所提出的框架在预训练和自动标注任务中均优于现有方法。", "conclusion": "该研究提出的框架有效提升了3D语义占用预测的性能。", "translation": "周围环境的准确感知对于安全的自动驾驶至关重要。3D占用预测，即估计道路、建筑物和其他物体的详细3D结构，对于不依赖LiDAR传感器的视觉中心自动驾驶系统尤为重要。然而，在3D语义占用预测中——每个体素都被赋予一个语义标签——需要带标注的LiDAR点云，这使得数据采集成本高昂。相比之下，大规模二元占用数据，仅指示占用或空闲空间而没有语义标签，可以以较低的成本收集。尽管这些数据可用，但利用其潜力的研究仍未被探索。在本研究中，我们从两个角度探讨了大规模二元占用数据的利用：(1) 预训练和(2) 基于学习的自动标注。我们提出了一种新颖的基于二元占用的框架，将预测过程分解为二元和语义占用模块，从而有效利用二元占用数据。我们的实验结果表明，所提出的框架在预训练和自动标注任务中均优于现有方法，突出了其在增强3D语义占用预测方面的有效性。代码可在https://github.com/ToyotaInfoTech/b2s-occupancy获取。", "summary": "本研究旨在解决3D语义占用预测中数据标注成本高昂的问题。通过利用成本较低的大规模二元占用数据，文章提出了一个新颖的框架。该框架将预测过程分解为二元和语义占用模块，并从预训练和学习型自动标注两个方面探索了二元数据的利用。实验证明，该框架在相关任务中表现优于现有方法，显著提升了3D语义占用预测的效率和性能。", "keywords": "3D语义占用预测, 二元占用数据, 自动驾驶, 预训练, 自动标注", "comments": "该论文的创新点在于首次探索了大规模二元占用数据在3D语义占用预测中的应用潜力，并通过提出的模块化框架有效解决了语义标注数据稀缺的问题。这种方法对于降低自动驾驶系统开发成本具有重要意义。"}}
{"id": "2507.13789", "title": "Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI", "authors": ["Kyriakos Flouris", "Moritz Halter", "Yolanne Y. R. Lee", "Samuel Castonguay", "Luuk Jacobs", "Pietro Dirix", "Jonathan Nestmann", "Sebastian Kozerke", "Ender Konukoglu"], "categories": ["cs.CV", "cs.AI", "physics.comp-ph"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13789v1", "summary": "Hemodynamic analysis is essential for predicting aneurysm rupture and guiding\ntreatment. While magnetic resonance flow imaging enables time-resolved\nvolumetric blood velocity measurements, its low spatiotemporal resolution and\nsignal-to-noise ratio limit its diagnostic utility. To address this, we propose\nthe Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that\nenhances both spatial and temporal resolution with the ability to predict wall\nshear stress (WSS) directly from clinical imaging data. LoFNO integrates\nLaplacian eigenvectors as geometric priors for improved structural awareness on\nirregular, unseen geometries and employs an Enhanced Deep Super-Resolution\nNetwork (EDSR) layer for robust upsampling. By combining geometric priors with\nneural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow\ndata, achieving superior velocity and WSS predictions compared to interpolation\nand alternative deep learning methods, enabling more precise cerebrovascular\ndiagnostics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13789v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "局部化FNO用于动脉瘤MRI的时空血流动力学上采样", "tldr": "LoFNO是一种新颖的3D架构，通过结合几何先验和深度超分辨率网络，解决了动脉瘤MRI中血流动力学成像的时空分辨率低和信噪比差的问题，实现了更精确的血流速度和壁面剪应力预测。", "motivation": "磁共振血流成像在预测动脉瘤破裂和指导治疗方面至关重要，但其低时空分辨率和信噪比限制了其诊断效用。", "method": "本文提出局部化傅里叶神经算子（LoFNO），一个新颖的3D架构，用于增强时空分辨率并直接从临床影像数据预测壁面剪应力（WSS）。LoFNO整合拉普拉斯特征向量作为几何先验，以提高对不规则、未见几何体的结构感知，并采用增强深度超分辨率网络（EDSR）层进行鲁棒上采样。", "result": "LoFNO通过结合几何先验和神经算子框架，对血流数据进行去噪和时空上采样，与插值和其他深度学习方法相比，实现了更优越的速度和壁面剪应力预测。", "conclusion": "LoFNO通过提高血流成像的时空分辨率和信噪比，实现了更精确的脑血管诊断。", "translation": "血流动力学分析对于预测动脉瘤破裂和指导治疗至关重要。尽管磁共振血流成像能够实现时间分辨的体积血流速度测量，但其低时空分辨率和信噪比限制了其诊断效用。为了解决这个问题，我们提出了局部化傅里叶神经算子（LoFNO），这是一种新颖的3D架构，能够增强空间和时间分辨率，并能够直接从临床影像数据预测壁面剪应力（WSS）。LoFNO将拉普拉斯特征向量作为几何先验，以提高对不规则、未见几何体的结构感知，并采用增强深度超分辨率网络（EDSR）层进行鲁棒上采样。通过将几何先验与神经算子框架相结合，LoFNO对血流数据进行去噪和时空上采样，与插值和替代深度学习方法相比，实现了更优越的速度和WSS预测，从而实现更精确的脑血管诊断。", "summary": "本文提出了一种名为局部化傅里叶神经算子（LoFNO）的新型3D架构，旨在解决动脉瘤磁共振血流成像中存在的低时空分辨率和信噪比问题。LoFNO通过整合拉普拉斯特征向量作为几何先验和采用增强深度超分辨率网络（EDSR）层进行鲁棒上采样，能够直接从临床数据中预测血流速度和壁面剪应力。实验结果表明，LoFNO在去噪和时空上采样方面表现优异，并能提供比传统方法和替代深度学习方法更精确的速度和WSS预测，从而提升脑血管诊断的精度。", "keywords": "局部化FNO, 血流动力学上采样, 动脉瘤MRI, 壁面剪应力, 超分辨率", "comments": "该论文提出LoFNO，通过结合傅里叶神经算子、几何先验和EDSR层，创新性地解决了动脉瘤MRI血流动力学分析中分辨率和信噪比的挑战。其能够直接从临床数据预测WSS的能力具有重要的临床应用潜力，有望显著提高脑血管诊断的精确性。"}}
{"id": "2507.13671", "title": "Combinatorics of Palindromes", "authors": ["Michael Itzhaki"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Full version, accepted to FCT25", "url": "http://arxiv.org/abs/2507.13671v1", "summary": "We investigate the structure and reconstruction complexity of Manacher\narrays. First, we establish a combinatorial lower bound, proving that the\nnumber of rooted tandem repeat trees with $n+1$ genes exceeds the number of\ndistinct Manacher arrays of length $n$. Second, we introduce a graph-theoretic\nframework that associates a graph to each Manacher array, where every proper\nvertex coloring yields a string consistent with the array. Finally, we analyze\na reconstruction algorithm by I et al. (SPIRE 2010), showing that it\nsimultaneously achieves a globally minimal alphabet size, uses at most\n$\\log_2(n{-}1) + 2$ distinct symbols, and can be adapted to produce\nreconstructions over arbitrary alphabets when possible. Our results also\nresolve an open problem posed by the original authors. Together, these findings\nadvance the combinatorial understanding of Manacher arrays and open new\ndirections for string reconstruction under structural constraints.", "comment": "Full version, accepted to FCT25", "pdf_url": "http://arxiv.org/pdf/2507.13671v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "回文串的组合学", "tldr": "该论文深入研究了Manacher数组的结构和重构复杂性，建立了组合下界，提出了图论框架，并分析了一个重构算法，解决了现有开放问题。", "motivation": "研究Manacher数组的结构和重构复杂性。", "method": "1. 建立了组合下界，证明了有根串联重复树的数量超过了Manacher数组的数量。2. 引入了图论框架，将图与Manacher数组关联，通过顶点着色生成一致字符串。3. 分析了I等人（SPIRE 2010）提出的重构算法。", "result": "1. 证明了具有n+1个基因的有根串联重复树的数量超过了长度为n的不同Manacher数组的数量。2. 引入的图论框架能够通过适当的顶点着色生成与Manacher数组一致的字符串。3. 分析的重构算法实现了全局最小的字母表大小，最多使用$\\log_2(n{-}1) + 2$个不同的符号，并且可以在可能的情况下适应于在任意字母表上生成重构。4. 解决了原作者提出的一个开放问题。", "conclusion": "这些发现推动了对Manacher数组的组合理解，并为结构约束下的字符串重构开辟了新方向。", "translation": "我们研究了Manacher数组的结构和重构复杂性。首先，我们建立了一个组合下界，证明了具有n+1个基因的有根串联重复树的数量超过了长度为n的不同Manacher数组的数量。其次，我们引入了一个图论框架，将一个图与每个Manacher数组关联起来，其中每个适当的顶点着色都会生成一个与该数组一致的字符串。最后，我们分析了I等人（SPIRE 2010）提出的一种重构算法，表明它同时实现了全局最小的字母表大小，最多使用$\\log_2(n{-}1) + 2$个不同的符号，并且在可能的情况下可以适应于在任意字母表上生成重构。我们的结果还解决了一个由原作者提出的开放问题。总的来说，这些发现推动了对Manacher数组的组合理解，并为结构约束下的字符串重构开辟了新方向。", "summary": "本文深入研究了Manacher数组的组合特性和重构复杂性。研究建立了Manacher数组与串联重复树数量的组合下界，引入了一个创新的图论框架用于从Manacher数组重构字符串，并对一个现有算法进行了分析，证明了其在字母表大小方面的卓越效率和广泛适应性。此外，本研究还成功解决了该领域的一个长期开放问题，显著提升了对Manacher数组以及受结构约束的字符串重构的理解。", "keywords": "Manacher数组, 组合学, 字符串重构, 回文串", "comments": "这篇论文对Manacher数组这一字符串算法中的基本数据结构，在理论理解上做出了重要贡献。引入图论框架是其创新之处，为字符串重构提供了全新的视角。解决一个开放问题进一步彰显了其学术价值。在实际应用层面，特别是在重构过程中实现最小字母表大小的能力也值得关注。"}}
{"id": "2504.13774", "title": "DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs", "authors": ["Tamim Al Mahmud", "Najeeb Jebreel", "Josep Domingo-Ferrer", "David Sanchez"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This is the updated version of the preprint, revised following acceptance for publication in Elsevier Neural Networks Journal. The paper is now published (18 July 2025) with DOI: this https URL", "url": "http://arxiv.org/abs/2504.13774v2", "summary": "Large language models (LLMs) have recently revolutionized language processing\ntasks but have also brought ethical and legal issues. LLMs have a tendency to\nmemorize potentially private or copyrighted information present in the training\ndata, which might then be delivered to end users at inference time. When this\nhappens, a naive solution is to retrain the model from scratch after excluding\nthe undesired data. Although this guarantees that the target data have been\nforgotten, it is also prohibitively expensive for LLMs. Approximate unlearning\noffers a more efficient alternative, as it consists of ex post modifications of\nthe trained model itself to prevent undesirable results, but it lacks\nforgetting guarantees because it relies solely on empirical evidence. In this\nwork, we present DP2Unlearning, a novel LLM unlearning framework that offers\nformal forgetting guarantees at a significantly lower cost than retraining from\nscratch on the data to be retained. DP2Unlearning involves training LLMs on\ntextual data protected using {\\epsilon}-differential privacy (DP), which later\nenables efficient unlearning with the guarantees against disclosure associated\nwith the chosen {\\epsilon}. Our experiments demonstrate that DP2Unlearning\nachieves similar model performance post-unlearning, compared to an LLM\nretraining from scratch on retained data -- the gold standard exact unlearning\n-- but at approximately half the unlearning cost. In addition, with a\nreasonable computational cost, it outperforms approximate unlearning methods at\nboth preserving the utility of the model post-unlearning and effectively\nforgetting the targeted information.", "comment": "This is the updated version of the preprint, revised following\n  acceptance for publication in Elsevier Neural Networks Journal. The paper is\n  now published (18 July 2025) with DOI:\n  https://doi.org/10.1016/j.neunet.2025.107879", "pdf_url": "http://arxiv.org/pdf/2504.13774v2", "cate": "cs.LG", "date": "2025-04-18", "updated": "2025-07-18", "AI": {"title_translation": "DP2Unlearning：一种高效且有保证的LLM遗忘框架", "tldr": "DP2Unlearning是一种新的框架，通过差分隐私训练LLM，以比从头开始重新训练更低的成本提供高效且有保证的遗忘能力。", "motivation": "大型语言模型（LLMs）存在记忆训练数据中潜在私人或受版权保护信息的倾向，这可能导致伦理和法律问题。从头开始重新训练模型以排除不需要的数据成本过高，而近似遗忘方法缺乏正式的遗忘保证。", "method": "本文提出了DP2Unlearning框架。该方法涉及使用ε-差分隐私（DP）保护的文本数据训练LLMs，从而实现高效的遗忘，并提供与所选ε相关的披露保证。", "result": "实验表明，DP2Unlearning在遗忘后实现了与从头开始重新训练（黄金标准）相似的模型性能，但遗忘成本约为后者的一半。此外，在合理的计算成本下，它在遗忘后保持模型效用和有效遗忘目标信息方面优于近似遗忘方法。", "conclusion": "DP2Unlearning是一种新颖的LLM遗忘框架，它以显著低于从头开始重新训练的成本提供正式的遗忘保证，并在性能和效率上优于现有方法。", "translation": "大型语言模型（LLMs）最近彻底改变了语言处理任务，但也带来了伦理和法律问题。LLMs倾向于记忆训练数据中潜在的私人或受版权保护的信息，这些信息可能在推理时传递给最终用户。当这种情况发生时，一个简单的解决方案是在排除不需要的数据后从头开始重新训练模型。尽管这保证了目标数据已被遗忘，但对于LLMs来说，其成本也高得令人望而却步。近似遗忘提供了一种更有效的替代方案，因为它包括对已训练模型本身进行事后修改以防止不良结果，但它缺乏遗忘保证，因为它仅依赖于经验证据。在这项工作中，我们提出了DP2Unlearning，这是一种新颖的LLM遗忘框架，与从头开始重新训练保留数据相比，它以显著更低的成本提供正式的遗忘保证。DP2Unlearning涉及使用ε-差分隐私（DP）保护的文本数据训练LLMs，这随后能够实现高效的遗忘，并提供与所选ε相关的披露保证。我们的实验表明，与在保留数据上从头开始重新训练的LLM（黄金标准的精确遗忘）相比，DP2Unlearning在遗忘后实现了相似的模型性能，但遗忘成本约为一半。此外，在合理的计算成本下，它在遗忘后保持模型效用和有效遗忘目标信息方面优于近似遗忘方法。", "summary": "本文提出了一种名为DP2Unlearning的新型LLM遗忘框架，旨在解决大型语言模型记忆敏感数据所带来的伦理和法律问题。针对现有重新训练成本高昂和近似遗忘缺乏保证的缺点，DP2Unlearning通过使用差分隐私保护的文本数据训练LLM，从而在遗忘后提供正式的遗忘保证。实验结果表明，DP2Unlearning在遗忘性能上与从头开始重新训练的黄金标准相当，但成本显著降低（约一半），并且在模型效用和信息遗忘方面优于近似遗忘方法。", "keywords": "LLMs, 遗忘, 差分隐私, 数据隐私, 遗忘保证", "comments": "该论文提出了一种创新的方法来解决LLM中的“遗忘”问题，这是当前AI伦理和隐私领域的一个重要挑战。通过将差分隐私引入LLM训练，它为遗忘提供了正式的保证，这是现有近似方法所缺乏的。成本效益的提升使其在实际应用中更具可行性，具有重要的实践意义。"}}
{"id": "2507.13539", "title": "SCOPE for Hexapod Gait Generation", "authors": ["Jim O'Connor", "Jay B. Nash", "Derin Gezgin", "Gary B. Parker"], "categories": ["cs.RO", "cs.NE"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      IJCCI Conference on Evolutionary Computation and Theory and Applications, 2025", "url": "http://arxiv.org/abs/2507.13539v1", "summary": "Evolutionary methods have previously been shown to be an effective learning\nmethod for walking gaits on hexapod robots. However, the ability of these\nalgorithms to evolve an effective policy rapidly degrades as the input space\nbecomes more complex. This degradation is due to the exponential growth of the\nsolution space, resulting from an increasing parameter count to handle a more\ncomplex input. In order to address this challenge, we introduce Sparse Cosine\nOptimized Policy Evolution (SCOPE). SCOPE utilizes the Discrete Cosine\nTransform (DCT) to learn directly from the feature coefficients of an input\nmatrix. By truncating the coefficient matrix returned by the DCT, we can reduce\nthe dimensionality of an input while retaining the highest energy features of\nthe original input. We demonstrate the effectiveness of this method by using\nSCOPE to learn the gait of a hexapod robot. The hexapod controller is given a\nmatrix input containing time-series information of previous poses, which are\nthen transformed to gait parameters by an evolved policy. In this task, the\naddition of SCOPE to a reference algorithm achieves a 20% increase in efficacy.\nSCOPE achieves this result by reducing the total input size of the time-series\npose data from 2700 to 54, a 98% decrease. Additionally, SCOPE is capable of\ncompressing an input to any output shape, provided that each output dimension\nis no greater than the corresponding input dimension. This paper demonstrates\nthat SCOPE is capable of significantly compressing the size of an input to an\nevolved controller, resulting in a statistically significant gain in efficacy.", "comment": "IJCCI Conference on Evolutionary Computation and Theory and\n  Applications, 2025", "pdf_url": "http://arxiv.org/pdf/2507.13539v1", "cate": "cs.RO", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于六足机器人步态生成的SCOPE", "tldr": "SCOPE利用离散余弦变换（DCT）显著压缩进化控制器输入，从而提高六足机器人步态生成的效率。", "motivation": "传统的进化方法在处理复杂输入空间时，由于参数数量增加导致解空间呈指数增长，其进化有效策略的能力会迅速下降。", "method": "本文引入了稀疏余弦优化策略进化（SCOPE）方法。SCOPE利用离散余弦变换（DCT）直接从输入矩阵的特征系数中学习，并通过截断系数矩阵来降低输入维度，同时保留原始输入的最高能量特征。", "result": "SCOPE使参考算法的效率提高了20%。它将时间序列姿态数据的总输入大小从2700减少到54，降低了98%。此外，SCOPE能够将输入压缩到任何输出形状，只要每个输出维度不大于相应的输入维度。", "conclusion": "SCOPE能够显著压缩进化控制器的输入大小，从而在效率上获得统计学上的显著提升。", "translation": "进化方法此前已被证明是六足机器人行走步态的有效学习方法。然而，随着输入空间变得更加复杂，这些算法进化有效策略的能力会迅速下降。这种下降是由于解空间的指数增长，其源于处理更复杂输入所需的参数数量增加。为了解决这一挑战，我们引入了稀疏余弦优化策略进化（SCOPE）。SCOPE利用离散余弦变换（DCT）直接从输入矩阵的特征系数中学习。通过截断DCT返回的系数矩阵，我们可以在保留原始输入最高能量特征的同时，降低输入的维度。我们通过使用SCOPE学习六足机器人步态来证明该方法的有效性。六足控制器被赋予一个包含先前姿态时间序列信息的矩阵输入，然后通过进化的策略将其转换为步态参数。在此任务中，在参考算法中添加SCOPE可使效率提高20%。SCOPE通过将时间序列姿态数据的总输入大小从2700减少到54（减少98%）来实现这一结果。此外，SCOPE能够将输入压缩到任何输出形状，前提是每个输出维度不大于相应的输入维度。本文证明了SCOPE能够显著压缩进化控制器的输入大小，从而在效率上获得统计学上的显著提升。", "summary": "本文提出了一种名为稀疏余弦优化策略进化（SCOPE）的新方法，旨在解决进化算法在复杂输入空间中生成有效策略时效率下降的问题。SCOPE利用离散余弦变换（DCT）来压缩输入数据的维度，通过保留高能量特征，显著减少了进化控制器所需的输入大小。实验证明，将SCOPE应用于六足机器人步态生成任务时，其效率比现有方法提高了20%，并且将输入数据量从2700减少到54，降低了98%。这表明SCOPE能够有效提高进化算法在处理复杂输入时的性能。", "keywords": "六足机器人步态生成, 进化方法, SCOPE, 离散余弦变换, 维度降低", "comments": "该论文的创新点在于将离散余弦变换（DCT）引入到进化策略中，用于高效地压缩高维输入数据。这种方法有效地解决了传统进化算法在复杂输入空间中效率下降的问题，通过显著减少输入维度，提高了学习效率和性能。其重要性体现在为机器人步态生成等需要处理复杂时间序列数据的进化学习任务提供了一个有效的优化工具。"}}
{"id": "2502.12777", "title": "Evaluating link prediction: New perspectives and recommendations", "authors": ["Bhargavi Kalyani I", "A Rama Prasad Mathi", "Niladri Sett"], "categories": ["cs.SI", "cs.AI"], "primary_category": "Subjects:       Social and Information Networks (cs.SI)", "pdf_link": null, "comments": "Comments:      Int J Data Sci Anal (2025)", "url": "http://arxiv.org/abs/2502.12777v4", "summary": "Link prediction (LP) is an important problem in network science and machine\nlearning research. The state-of-the-art LP methods are usually evaluated in a\nuniform setup, ignoring several factors associated with the data and\napplication specific needs. We identify a number of such factors, such as,\nnetwork-type, problem-type, geodesic distance between the end nodes and its\ndistribution over the classes, nature and applicability of LP methods, class\nimbalance and its impact on early retrieval, evaluation metric, etc., and\npresent an experimental setup which allows us to evaluate LP methods in a\nrigorous and controlled manner. We perform extensive experiments with a variety\nof LP methods over real network datasets in this controlled setup, and gather\nvaluable insights on the interactions of these factors with the performance of\nLP through an array of carefully designed hypotheses. Following the insights,\nwe provide recommendations to be followed as best practice for evaluating LP\nmethods.", "comment": "Int J Data Sci Anal (2025)", "pdf_url": "http://arxiv.org/pdf/2502.12777v4", "cate": "cs.SI", "date": "2025-02-18", "updated": "2025-07-18", "AI": {"title_translation": "评估链接预测：新视角与建议", "tldr": "该研究指出了当前链接预测（LP）方法评估中存在的不足，提出了一个严谨的实验设置来考虑多种影响因素，并通过实验提供了评估LP方法的最佳实践建议。", "motivation": "当前的链接预测（LP）方法通常在统一设置下进行评估，忽略了与数据和应用特定需求相关的多个因素，例如网络类型、问题类型、测地距离、类别不平衡和评估指标等。", "method": "研究识别了影响链接预测评估的多种因素，提出了一个严谨且受控的实验设置。在此设置下，对各种LP方法在真实网络数据集上进行了广泛实验，并设计了一系列假设来深入了解这些因素与LP性能的相互作用。", "result": "通过受控实验，研究收集了关于各种因素与链接预测性能之间相互作用的宝贵见解。", "conclusion": "根据实验获得的见解，研究为评估链接预测方法提供了应遵循的最佳实践建议。", "translation": "链接预测（LP）是网络科学和机器学习研究中的一个重要问题。最先进的LP方法通常在统一设置下进行评估，忽略了与数据和应用特定需求相关的几个因素。我们识别了许多此类因素，例如网络类型、问题类型、端节点之间的测地距离及其在类别上的分布、LP方法的性质和适用性、类别不平衡及其对早期检索的影响、评估指标等，并提出了一个实验设置，使我们能够以严谨和受控的方式评估LP方法。我们在此受控设置下，对各种LP方法在真实网络数据集上进行了广泛实验，并通过一系列精心设计的假设，收集了关于这些因素与LP性能相互作用的宝贵见解。根据这些见解，我们提供了评估LP方法时应遵循的最佳实践建议。", "summary": "本研究旨在解决当前链接预测（LP）方法评估中存在的不足，即忽略了数据和应用相关的多种关键因素。文章识别了网络类型、问题类型、距离、类别不平衡和评估指标等因素，并提出了一个严谨受控的实验框架。通过在真实数据集上进行大量实验，研究获得了关于这些因素如何影响LP性能的深入见解，并基于此提出了评估LP方法的最佳实践建议。", "keywords": "链接预测, 评估, 网络科学, 机器学习, 最佳实践", "comments": "该论文的创新之处在于系统性地识别并探讨了影响链接预测评估的多种关键因素，打破了传统单一评估范式。其重要性在于提供了一个更全面、更严谨的评估框架，并为研究人员和实践者提供了评估LP方法的具体指导和最佳实践，有助于推动该领域的发展。"}}
{"id": "2507.14005", "title": "On the Fundamental Limitations of Dual Static CVaR Decompositions in Markov Decision Processes", "authors": ["Mathieu Godbout", "Audrey Durand"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14005v1", "summary": "Recent work has shown that dynamic programming (DP) methods for finding\nstatic CVaR-optimal policies in Markov Decision Processes (MDPs) can fail when\nbased on the dual formulation, yet the root cause for the failure has remained\nunclear. We expand on these findings by shifting focus from policy optimization\nto the seemingly simpler task of policy evaluation. We show that evaluating the\nstatic CVaR of a given policy can be framed as two distinct minimization\nproblems. For their solutions to match, a set of ``risk-assignment consistency\nconstraints'' must be satisfied, and we demonstrate that the intersection of\nthe constraints being empty is the source of previously observed evaluation\nerrors. Quantifying the evaluation error as the CVaR evaluation gap, we then\ndemonstrate that the issues observed when optimizing over the dual-based CVaR\nDP are explained by the returned policy having a non-zero CVaR evaluation gap.\nWe then leverage our proposed risk-assignment perspective to prove that the\nsearch for a single, uniformly optimal policy via on the dual CVaR\ndecomposition is fundamentally limited, identifying an MDP where no single\npolicy can be optimal across all initial risk levels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14005v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "关于马尔可夫决策过程中双静态CVaR分解的根本局限性", "tldr": "本文揭示了在MDPs中基于对偶CVaR分解的动态规划方法失败的根本原因，并证明了通过对偶CVaR分解寻找单一最优策略是存在根本性限制的。", "motivation": "先前研究表明，在马尔可夫决策过程（MDPs）中，基于对偶公式的动态规划（DP）方法在寻找静态CVaR最优策略时可能失败，但失败的根本原因尚不清楚。", "method": "1. 将重点从策略优化转移到策略评估，将评估给定策略的静态CVaR框定为两个不同的最小化问题。2. 证明了当“风险分配一致性约束”的交集为空时，是先前观察到的评估错误的根源。3. 将评估误差量化为CVaR评估差距。4. 利用提出的风险分配视角，证明了通过对偶CVaR分解寻找单一、统一最优策略是根本受限的。", "result": "1. 评估静态CVaR的失败源于“风险分配一致性约束”的交集为空。2. 在基于对偶的CVaR DP上进行优化时出现的问题，可以通过返回的策略具有非零的CVaR评估差距来解释。3. 证明了通过对偶CVaR分解寻找单一、统一最优策略是根本受限的，并识别出在某些MDP中，没有单一策略可以在所有初始风险水平下都达到最优。", "conclusion": "本研究证明了在马尔可夫决策过程中，基于对偶CVaR分解寻找单一最优策略存在根本性限制，这是由于风险评估中的不一致性导致的。", "translation": "最近的研究表明，在马尔可夫决策过程（MDPs）中，基于对偶公式的动态规划（DP）方法在寻找静态CVaR最优策略时可能会失败，但失败的根本原因仍不清楚。我们通过将重点从策略优化转移到看似更简单的策略评估任务上，扩展了这些发现。我们表明，评估给定策略的静态CVaR可以被框定为两个不同的最小化问题。为了使它们的解匹配，必须满足一组“风险分配一致性约束”，我们证明了这些约束的交集为空是先前观察到的评估错误的来源。我们将评估误差量化为CVaR评估差距，然后证明了在基于对偶的CVaR DP上进行优化时观察到的问题，可以通过返回的策略具有非零的CVaR评估差距来解释。然后，我们利用提出的风险分配视角来证明，通过对偶CVaR分解寻找单一、统一最优策略是根本受限的，并识别出在某个MDP中，没有单一策略可以在所有初始风险水平下都达到最优。", "summary": "本文深入探讨了在马尔可夫决策过程（MDPs）中，基于对偶公式的动态规划（DP）方法在寻找静态CVaR最优策略时失败的原因。研究通过将焦点转向策略评估，发现评估静态CVaR可被视为两个独立的最小化问题，其解不匹配的原因在于“风险分配一致性约束”的交集为空。这种评估误差，即CVaR评估差距，解释了在对偶CVaR DP优化中观察到的问题。最终，研究证明了通过对偶CVaR分解寻找单一、统一最优策略存在根本性限制，因为存在MDPs中无法找到在所有初始风险水平下都最优的单一策略。", "keywords": "马尔可夫决策过程, CVaR, 动态规划, 对偶分解, 风险分配一致性", "comments": "本文通过深入分析策略评估中的“风险分配一致性约束”和“CVaR评估差距”，明确揭示了基于对偶CVaR分解的动态规划在MDPs中失败的根本原因，并从理论上证明了其在寻找统一最优策略方面的局限性，这对于理解和改进风险敏感型MDPs的算法设计具有重要意义。"}}
{"id": "2409.18877", "title": "UniEmoX: Cross-modal Semantic-Guided Large-Scale Pretraining for Universal Scene Emotion Perception", "authors": ["Chuang Chen", "Xiao Sun", "Zhi Liu"], "categories": ["cs.AI", "cs.CV"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TIP", "url": "http://arxiv.org/abs/2409.18877v3", "summary": "Visual emotion analysis holds significant research value in both computer\nvision and psychology. However, existing methods for visual emotion analysis\nsuffer from limited generalizability due to the ambiguity of emotion perception\nand the diversity of data scenarios. To tackle this issue, we introduce\nUniEmoX, a cross-modal semantic-guided large-scale pretraining framework.\nInspired by psychological research emphasizing the inseparability of the\nemotional exploration process from the interaction between individuals and\ntheir environment, UniEmoX integrates scene-centric and person-centric\nlow-level image spatial structural information, aiming to derive more nuanced\nand discriminative emotional representations. By exploiting the similarity\nbetween paired and unpaired image-text samples, UniEmoX distills rich semantic\nknowledge from the CLIP model to enhance emotional embedding representations\nmore effectively. To the best of our knowledge, this is the first large-scale\npretraining framework that integrates psychological theories with contemporary\ncontrastive learning and masked image modeling techniques for emotion analysis\nacross diverse scenarios. Additionally, we develop a visual emotional dataset\ntitled Emo8. Emo8 samples cover a range of domains, including cartoon, natural,\nrealistic, science fiction and advertising cover styles, covering nearly all\ncommon emotional scenes. Comprehensive experiments conducted on six benchmark\ndatasets across two downstream tasks validate the effectiveness of UniEmoX. The\nsource code is available at https://github.com/chincharles/u-emo.", "comment": "Accepted by IEEE TIP", "pdf_url": "http://arxiv.org/pdf/2409.18877v3", "cate": "cs.AI", "date": "2024-09-27", "updated": "2025-07-18", "AI": {"title_translation": "UniEmoX：跨模态语义引导的大规模预训练用于通用场景情感感知", "tldr": "UniEmoX是一个跨模态语义引导的大规模预训练框架，旨在通过整合心理学理论、对比学习和掩码图像建模技术，解决现有视觉情感分析方法泛化能力有限的问题，并引入了新的视觉情感数据集Emo8。", "motivation": "现有视觉情感分析方法由于情感感知的模糊性和数据场景的多样性，导致泛化能力有限。", "method": "本文提出了UniEmoX，一个跨模态语义引导的大规模预训练框架。它受心理学研究启发，整合了以场景为中心和以人为中心的低级图像空间结构信息，以获得更细致和有区分力的情感表示。UniEmoX利用配对和非配对图像-文本样本之间的相似性，从CLIP模型中提取丰富的语义知识，以增强情感嵌入表示。这是第一个将心理学理论与当代对比学习和掩码图像建模技术相结合的大规模预训练情感分析框架。此外，研究人员还开发了一个名为Emo8的视觉情感数据集，涵盖了多种领域和常见情感场景。", "result": "在六个基准数据集上的两项下游任务中进行的综合实验验证了UniEmoX的有效性。", "conclusion": "UniEmoX通过结合心理学理论、跨模态语义引导和大规模预训练，显著提升了通用场景情感感知的性能和泛化能力。", "translation": "视觉情感分析在计算机视觉和心理学领域都具有重要的研究价值。然而，现有的视觉情感分析方法由于情感感知的模糊性和数据场景的多样性，导致泛化能力有限。为了解决这个问题，我们引入了UniEmoX，一个跨模态语义引导的大规模预训练框架。受心理学研究强调情感探索过程与个体及其环境之间相互作用不可分离的启发，UniEmoX整合了以场景为中心和以人为中心的低级图像空间结构信息，旨在推导出更细致和有区分力的情感表示。通过利用配对和非配对图像-文本样本之间的相似性，UniEmoX从CLIP模型中提取丰富的语义知识，以更有效地增强情感嵌入表示。据我们所知，这是第一个将心理学理论与当代对比学习和掩码图像建模技术相结合，用于跨多样化场景情感分析的大规模预训练框架。此外，我们开发了一个名为Emo8的视觉情感数据集。Emo8样本涵盖了卡通、自然、写实、科幻和广告封面风格等一系列领域，几乎覆盖了所有常见的情感场景。在两个下游任务的六个基准数据集上进行的综合实验验证了UniEmoX的有效性。源代码可在https://github.com/chincharles/u-emo 获取。", "summary": "UniEmoX是一个创新的跨模态语义引导大规模预训练框架，旨在解决视觉情感分析中泛化能力有限的问题。它将心理学理论与先进的对比学习和掩码图像建模技术相结合，通过整合场景和人物的图像空间结构信息，并从CLIP模型中蒸馏语义知识来提升情感表示。该研究还构建了新的视觉情感数据集Emo8。实验结果表明UniEmoX在多个基准数据集上表现出有效性。", "keywords": "视觉情感分析, 跨模态学习, 大规模预训练, 情感感知, UniEmoX", "comments": "UniEmoX的创新之处在于首次将心理学理论与大规模预训练框架相结合，用于通用场景情感感知，这为情感分析领域提供了一个新的视角。其跨模态语义引导和集成多种表示学习策略的方法，有效提升了模型在复杂多变场景下的泛化能力。此外，新创建的Emo8数据集也填补了现有数据集在多样性方面的不足，对未来的研究具有重要贡献。"}}
{"id": "2502.12751", "title": "Architect of the Bits World: Masked Autoregressive Modeling for Circuit Generation Guided by Truth Table", "authors": ["Haoyuan Wu", "Haisheng Zheng", "Shoubo Hu", "Zhuolun He", "Bei Yu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2502.12751v2", "summary": "Logic synthesis, a critical stage in electronic design automation (EDA),\noptimizes gate-level circuits to minimize power consumption and area occupancy\nin integrated circuits (ICs). Traditional logic synthesis tools rely on\nhuman-designed heuristics, often yielding suboptimal results. Although\ndifferentiable architecture search (DAS) has shown promise in generating\ncircuits from truth tables, it faces challenges such as high computational\ncomplexity, convergence to local optima, and extensive hyperparameter tuning.\nConsequently, we propose a novel approach integrating conditional generative\nmodels with DAS for circuit generation. Our approach first introduces\nCircuitVQ, a circuit tokenizer trained based on our Circuit AutoEncoder We then\ndevelop CircuitAR, a masked autoregressive model leveraging CircuitVQ as the\ntokenizer. CircuitAR can generate preliminary circuit structures from truth\ntables, which guide DAS in producing functionally equivalent circuits. Notably,\nwe observe the scalability and emergent capability in generating complex\ncircuit structures of our CircuitAR models. Extensive experiments also show the\nsuperior performance of our method. This research bridges the gap between\nprobabilistic generative models and precise circuit generation, offering a\nrobust solution for logic synthesis.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2502.12751v2", "cate": "cs.LG", "date": "2025-02-18", "updated": "2025-07-18", "AI": {"title_translation": "比特世界架构师：基于真值表引导的掩码自回归电路生成模型", "tldr": "提出了一种基于掩码自回归模型（CircuitAR）和电路分词器（CircuitVQ）的新方法，用于从真值表生成电路，解决了传统逻辑综合和可微分架构搜索（DAS）的局限性。", "motivation": "传统的逻辑综合工具依赖于人工设计的启发式方法，导致次优结果。可微分架构搜索（DAS）在电路生成中面临计算复杂度高、易收敛到局部最优以及超参数调优繁琐等挑战。", "method": "提出了一种将条件生成模型与可微分架构搜索（DAS）相结合的新方法。首先，引入了CircuitVQ，这是一种基于Circuit AutoEncoder训练的电路分词器。然后，开发了CircuitAR，一个利用CircuitVQ作为分词器的掩码自回归模型，用于从真值表生成初步电路结构，这些结构再指导DAS生成功能等效的电路。", "result": "CircuitAR模型在生成复杂电路结构方面展现出可扩展性和涌现能力。大量实验表明，所提出的方法性能优越。", "conclusion": "本研究弥合了概率生成模型与精确电路生成之间的鸿沟，为逻辑综合提供了一个强大的解决方案。", "translation": "逻辑综合是电子设计自动化（EDA）中的关键阶段，旨在优化门级电路，以最大限度地降低集成电路（ICs）的功耗和面积占用。传统的逻辑综合工具依赖于人工设计的启发式方法，通常产生次优结果。尽管可微分架构搜索（DAS）在从真值表生成电路方面显示出前景，但它面临计算复杂度高、收敛到局部最优以及超参数调优繁琐等挑战。因此，我们提出了一种新颖的方法，将条件生成模型与DAS集成，用于电路生成。我们的方法首先引入了CircuitVQ，这是一种基于我们Circuit AutoEncoder训练的电路分词器。然后，我们开发了CircuitAR，这是一种利用CircuitVQ作为分词器的掩码自回归模型。CircuitAR可以从真值表生成初步的电路结构，这些结构指导DAS生成功能等效的电路。值得注意的是，我们观察到CircuitAR模型在生成复杂电路结构方面的可扩展性和涌现能力。大量的实验也表明了我们方法的卓越性能。这项研究弥合了概率生成模型和精确电路生成之间的鸿沟，为逻辑综合提供了一个强大的解决方案。", "summary": "本文针对传统逻辑综合和可微分架构搜索（DAS）在电路生成方面的局限性，提出了一种新颖的混合方法。该方法将条件生成模型与DAS相结合，首先引入了电路分词器CircuitVQ，然后开发了掩码自回归模型CircuitAR。CircuitAR利用CircuitVQ从真值表生成初步电路结构，这些结构进而指导DAS生成功能等效的电路。实验表明，所提出的CircuitAR模型在生成复杂电路方面具有可扩展性和涌现能力，并表现出优越的性能，为逻辑综合提供了一个鲁棒的解决方案。", "keywords": "逻辑综合, 电路生成, 掩码自回归模型, 真值表, 电子设计自动化", "comments": "该论文提出了一种创新性的混合方法，将生成模型（掩码自回归模型）与搜索方法（DAS）相结合，用于电路生成。其中，使用专门的电路分词器（CircuitVQ）来有效处理电路结构是一个新颖的步骤。这种方法解决了传统方法次优性以及DAS计算挑战等长期存在的问题，为自动化电子设计带来了希望。"}}
{"id": "2507.13541", "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes", "authors": ["Shuyue Stella Li", "Melanie Sclar", "Hunter Lang", "Ansong Ni", "Jacqueline He", "Puxin Xu", "Andrew Cohen", "Chan Young Park", "Yulia Tsvetkov", "Asli Celikyilmaz"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      17 pages, 6 tables, 5 figures", "url": "http://arxiv.org/abs/2507.13541v1", "summary": "Personalizing AI systems requires understanding not just what users prefer,\nbut the reasons that underlie those preferences - yet current preference models\ntypically treat human judgment as a black box. We introduce PrefPalette, a\nframework that decomposes preferences into attribute dimensions and tailors its\npreference prediction to distinct social community values in a\nhuman-interpretable manner. PrefPalette operationalizes a cognitive science\nprinciple known as multi-attribute decision making in two ways: (1) a scalable\ncounterfactual attribute synthesis step that involves generating synthetic\ntraining data to isolate for individual attribute effects (e.g., formality,\nhumor, cultural values), and (2) attention-based preference modeling that\nlearns how different social communities dynamically weight these attributes.\nThis approach moves beyond aggregate preference modeling to capture the diverse\nevaluation frameworks that drive human judgment. When evaluated on 45 social\ncommunities from the online platform Reddit, PrefPalette outperforms GPT-4o by\n46.6% in average prediction accuracy. Beyond raw predictive improvements,\nPrefPalette also shed light on intuitive, community-specific profiles:\nscholarly communities prioritize verbosity and stimulation, conflict-oriented\ncommunities value sarcasm and directness, and support-based communities\nemphasize empathy. By modeling the attribute-mediated structure of human\njudgment, PrefPalette delivers both superior preference modeling and\ntransparent, interpretable insights, and serves as a first step toward more\ntrustworthy, value-aware personalized applications.", "comment": "17 pages, 6 tables, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13541v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "PrefPalette：基于潜在属性的个性化偏好建模", "tldr": "PrefPalette是一个新框架，通过将偏好分解为可解释的属性维度，并根据不同社群动态调整属性权重，实现更精确和透明的个性化偏好预测，在Reddit数据上表现优于GPT-4o。", "motivation": "当前的偏好模型将人类判断视为黑箱，未能理解偏好背后的深层原因，而个性化AI系统需要深入理解这些原因。", "method": "PrefPalette通过两种方式实现多属性决策：1) 可扩展的反事实属性合成，生成合成训练数据以分离个体属性（如正式性、幽默、文化价值观）的影响；2) 基于注意力的偏好建模，学习不同社会社区如何动态地权衡这些属性。", "result": "在Reddit的45个社会社区上进行评估，PrefPalette在平均预测准确度上比GPT-4o高出46.6%。此外，它还揭示了直观的、社区特定的偏好特征：学术社区优先考虑冗长和刺激性，冲突导向的社区重视讽刺和直接性，支持型社区则强调同理心。", "conclusion": "PrefPalette通过对人类判断的属性介导结构进行建模，提供了卓越的偏好建模能力以及透明、可解释的洞察，是迈向更值得信赖、更具价值意识的个性化应用的第一步。", "translation": "个性化AI系统不仅需要理解用户的偏好，还需要理解这些偏好背后的原因——然而，当前的偏好模型通常将人类判断视为一个黑箱。我们引入了PrefPalette，一个将偏好分解为属性维度并以人类可解释的方式根据不同社会社区的价值观调整其偏好预测的框架。PrefPalette通过两种方式操作一种被称为多属性决策的认知科学原理：(1) 可扩展的反事实属性合成步骤，涉及生成合成训练数据以分离个体属性效应（例如，正式性、幽默、文化价值观），以及 (2) 基于注意力的偏好建模，学习不同社会社区如何动态地权衡这些属性。这种方法超越了聚合偏好建模，捕捉了驱动人类判断的各种评估框架。在对在线平台Reddit的45个社会社区进行评估时，PrefPalette在平均预测准确度上比GPT-4o高出46.6%。除了原始的预测改进之外，PrefPalette还揭示了直观的、社区特定的特征：学术社区优先考虑冗长和刺激性，冲突导向的社区重视讽刺和直接性，支持型社区则强调同理心。通过对人类判断的属性介导结构进行建模，PrefPalette提供了卓越的偏好建模能力以及透明、可解释的洞察，并作为迈向更值得信赖、更具价值意识的个性化应用的第一步。", "summary": "PrefPalette是一个创新的框架，旨在通过将用户偏好分解为可解释的潜在属性（如正式性、幽默等），并学习不同社群如何动态地权衡这些属性，从而实现更透明和精确的个性化偏好建模。该方法通过合成数据进行属性隔离和注意力机制进行社区特定权重学习，超越了传统的黑箱偏好模型。在Reddit的45个社区上，PrefPalette在预测准确度上显著优于GPT-4o，并能揭示社区特有的偏好模式，为构建更值得信赖和价值感知的个性化应用奠定了基础。", "keywords": "个性化偏好, 潜在属性, 多属性决策, Reddit, 可解释AI", "comments": "PrefPalette的创新之处在于其将偏好分解为可解释的潜在属性，并结合社区特定的属性权重学习，从而提供了比传统黑箱模型更透明、更具洞察力的偏好理解。其超越GPT-4o的性能证明了其有效性，且能够揭示不同社区的独特偏好概况，这对于构建更负责任和用户感知的AI系统具有重要意义。该方法为个性化推荐和AI系统提供了新的研究方向。"}}
{"id": "2507.13999", "title": "The Proportional Fair Scheduler in Wavelength-Multiplexed Quantum Networks", "authors": ["Sanidhay Bhambay", "Siddarth Koduru Joshi", "Thirupathaiah Vasantam", "Neil Walton"], "categories": ["quant-ph", "cs.NI", "cs.PF"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13999v1", "summary": "We address the problem of optimal pumping strategies in quantum networks.\nThese networks enable secure communication by distributing entangled photon\npairs to user (or node) pairs. Quantum Key Distribution (QKD) protocols, like\nBBM92, generate secret keys from entangled photons. While secure communication\nand error correction are essential for any quantum communication channel,\nresource contention, optimization, and fairness issues are critical for\nnetworks. In this article, we analyze the performance of quantum networks,\nproposing simple distributed algorithms for QKD networks generating secret\nkeys.\n  There are significant advantages of pumping entangled photons in QKD\nnetworks, but challenges arise in practical implementations. The underlying\nchannels are inherently time-varying, and thus data rates fluctuate between\nnodes. Moreover, multiple edges (node pairs) can be pumped simultaneously,\nalbeit at the cost of a reduced secret key rate (SKR). These temporal and\nspatial constraints yield a complex decision-making problem whose solutions may\nfavor a small set of user pairs to the detriment of overall, long-run network\nperformance.\n  We design adaptive pumping strategies that address these challenges in QKD\nnetworks. In particular, we find that a proportional fairness pumping strategy\n(PF-PS) stands out by dynamically prioritizing users with lower average secret\nkey rates and optimally balancing fairness with throughput. The proposed\nalgorithm is a natural extension to quantum networks of the Proportional Fair\nScheduler deployed in 4G LTE and 5G mobile networks. Both theoretical analysis\nand numerical simulations confirm that PF-PS is optimal for entangled state\ndistribution, and thus, when adapted appropriately, proportional fair pumping\nis a strong candidate for efficient resource allocation in quantum networks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13999v1", "cate": "quant-ph", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "波长复用量子网络中的比例公平调度器", "tldr": "本文提出并分析了一种基于比例公平调度策略（PF-PS）的自适应泵浦策略，用于解决量子密钥分发（QKD）网络中的资源分配和公平性问题，并在理论和模拟中验证其有效性。", "motivation": "量子网络中，特别是量子密钥分发（QKD）网络中，存在资源竞争、优化和公平性问题。由于信道固有的时变性以及多边同时泵浦对密钥速率的影响，导致复杂的决策问题，可能牺牲长期网络性能来偏袒少数用户对。因此，需要设计一种优化泵浦策略，以平衡公平性与吞吐量。", "method": "本文提出了自适应泵浦策略来解决QKD网络中的挑战。具体而言，设计了一种比例公平泵浦策略（PF-PS），它通过动态优先考虑平均密钥速率较低的用户，并优化平衡公平性与吞吐量。该算法是4G LTE和5G移动网络中部署的比例公平调度器在量子网络中的自然延伸。", "result": "理论分析和数值模拟均证实，PF-PS在纠缠态分发方面是最佳的。", "conclusion": "比例公平泵浦策略（PF-PS）经过适当调整后，是量子网络中高效资源分配的有力候选方案，能够有效平衡公平性与吞吐量。", "translation": "我们研究了量子网络中最佳泵浦策略的问题。这些网络通过向用户（或节点）对分发纠缠光子对来实现安全通信。量子密钥分发（QKD）协议，如BBM92，从纠缠光子生成秘密密钥。虽然安全通信和纠错对于任何量子通信信道都至关重要，但资源竞争、优化和公平性问题对于网络而言至关重要。在本文中，我们分析了量子网络的性能，并为生成秘密密钥的QKD网络提出了简单的分布式算法。\n在QKD网络中泵浦纠缠光子具有显著优势，但在实际实现中也面临挑战。底层信道固有地随时间变化，因此节点之间的数据速率波动。此外，多个边缘（节点对）可以同时泵浦，尽管这会降低秘密密钥速率（SKR）。这些时间和空间限制导致了一个复杂的决策问题，其解决方案可能偏袒一小部分用户对，从而损害整体、长期的网络性能。\n我们设计了自适应泵浦策略来解决QKD网络中的这些挑战。特别是，我们发现比例公平泵浦策略（PF-PS）通过动态优先考虑平均秘密密钥速率较低的用户，并最佳地平衡公平性与吞吐量而脱颖而出。所提出的算法是4G LTE和5G移动网络中部署的比例公平调度器在量子网络中的自然延伸。理论分析和数值模拟均证实PF-PS对于纠缠态分发是最佳的，因此，当适当调整时，比例公平泵浦是量子网络中高效资源分配的有力候选方案。", "summary": "本文探讨了量子网络中，特别是量子密钥分发（QKD）网络中，优化资源分配和公平性的问题。鉴于信道的时变性和多路径泵浦带来的挑战，作者提出了一种自适应的比例公平泵浦策略（PF-PS）。该策略借鉴了4G/5G移动网络中的比例公平调度器，旨在动态地优先处理平均密钥速率较低的用户，从而在公平性和网络吞吐量之间取得最佳平衡。理论分析和数值模拟均验证了PF-PS在纠缠态分发中的有效性和最优性，表明其是量子网络中高效资源分配的有力方案。", "keywords": "量子网络, 量子密钥分发, 比例公平调度, 资源分配, 泵浦策略", "comments": "这篇论文的创新点在于将传统移动通信网络（4G/5G LTE）中成熟的比例公平调度器概念引入到新兴的量子网络中，以解决量子密钥分发（QKD）中的资源分配和公平性问题。这种跨领域的借鉴和应用是值得关注的。该研究对于量子网络走向实用化，特别是解决其核心的资源管理和性能优化问题，具有重要的意义。它提供了一个理论和实践相结合的解决方案，为未来量子通信网络的部署提供了参考。"}}
{"id": "2507.13673", "title": "MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training", "authors": ["Yuechen Xie", "Haobo Jiang", "Jian Yang", "Yigong Zhang", "Jin Xie"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures, 6 tables", "url": "http://arxiv.org/abs/2507.13673v1", "summary": "In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of\nhands and objects from monocular RGB input remains highly challenging due to\nthe inherent geometric ambiguity of RGB images and the severe mutual occlusions\nthat occur during interaction.To address these challenges, we propose MaskHOI,\na novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI\npose estimation. Our core idea is to leverage the masking-then-reconstruction\nstrategy of MAE to encourage the feature encoder to infer missing spatial and\nstructural information, thereby facilitating geometric-aware and\nocclusion-robust representation learning. Specifically, based on our\nobservation that human hands exhibit far greater geometric complexity than\nrigid objects, conventional uniform masking fails to effectively guide the\nreconstruction of fine-grained hand structures. To overcome this limitation, we\nintroduce a Region-specific Mask Ratio Allocation, primarily comprising the\nregion-specific masking assignment and the skeleton-driven hand masking\nguidance. The former adaptively assigns lower masking ratios to hand regions\nthan to rigid objects, balancing their feature learning difficulty, while the\nlatter prioritizes masking critical hand parts (e.g., fingertips or entire\nfingers) to realistically simulate occlusion patterns in real-world\ninteractions. Furthermore, to enhance the geometric awareness of the pretrained\nencoder, we introduce a novel Masked Signed Distance Field (SDF)-driven\nmultimodal learning mechanism. Through the self-masking 3D SDF prediction, the\nlearned encoder is able to perceive the global geometric structure of hands and\nobjects beyond the 2D image plane, overcoming the inherent limitations of\nmonocular input and alleviating self-occlusion issues. Extensive experiments\ndemonstrate that our method significantly outperforms existing state-of-the-art\napproaches.", "comment": "10 pages, 8 figures, 6 tables", "pdf_url": "http://arxiv.org/pdf/2507.13673v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MaskHOI：通过掩蔽预训练实现鲁棒的3D手物交互估计", "tldr": "MaskHOI提出了一种基于掩蔽自编码器（MAE）的预训练框架，通过区域特定掩蔽和SDF驱动的多模态学习来解决3D手物交互估计中的几何模糊和严重遮挡问题，显著优于现有SOTA方法。", "motivation": "由于RGB图像固有的几何模糊性和交互过程中严重的相互遮挡，从单目RGB输入精确估计手和物体的关节姿态在3D手物交互（HOI）任务中仍然极具挑战性。", "method": "我们提出了MaskHOI，一种新颖的掩蔽自编码器（MAE）驱动的预训练框架，用于增强HOI姿态估计。核心思想是利用MAE的掩蔽-然后-重建策略来促使特征编码器推断缺失的空间和结构信息，从而促进几何感知和遮挡鲁棒的表示学习。具体来说，我们引入了区域特定掩蔽比例分配，包括区域特定掩蔽分配和骨架驱动的手部掩蔽指导。前者自适应地为手部区域分配低于刚性物体的掩蔽比例，后者优先掩蔽关键手部部位。此外，我们引入了一种新颖的掩蔽符号距离场（SDF）驱动的多模态学习机制，通过自掩蔽3D SDF预测，使编码器能够感知手和物体的全局几何结构。", "result": "广泛的实验表明，我们的方法显著优于现有的最先进方法。", "conclusion": "MaskHOI通过其MAE驱动的预训练框架，结合区域特定掩蔽和SDF驱动的多模态学习，成功解决了3D手物交互估计中的挑战，并取得了最先进的性能。", "translation": "在3D手物交互（HOI）任务中，由于RGB图像固有的几何模糊性和交互过程中严重的相互遮挡，从单目RGB输入精确估计手和物体的精确关节姿态仍然极具挑战性。为了解决这些挑战，我们提出了MaskHOI，一个新颖的由掩蔽自编码器（MAE）驱动的预训练框架，用于增强HOI姿态估计。我们的核心思想是利用MAE的掩蔽-然后-重建策略来鼓励特征编码器推断缺失的空间和结构信息，从而促进几何感知和遮挡鲁棒的表示学习。具体来说，基于我们观察到人手比刚性物体表现出更大的几何复杂性，传统的均匀掩蔽无法有效地指导精细手部结构的重建。为了克服这一限制，我们引入了区域特定掩蔽比例分配，主要包括区域特定掩蔽分配和骨架驱动的手部掩蔽指导。前者自适应地为手部区域分配低于刚性物体的掩蔽比例，平衡了它们的特征学习难度，而后者优先掩蔽关键手部部位（例如，指尖或整个手指），以真实地模拟现实世界交互中的遮挡模式。此外，为了增强预训练编码器的几何感知能力，我们引入了一种新颖的掩蔽符号距离场（SDF）驱动的多模态学习机制。通过自掩蔽3D SDF预测，学习到的编码器能够感知手和物体超越2D图像平面的全局几何结构，克服了单目输入的固有局限性并缓解了自遮挡问题。广泛的实验表明，我们的方法显著优于现有的最先进方法。", "summary": "MaskHOI是一个新颖的基于掩蔽自编码器（MAE）的预训练框架，旨在解决3D手物交互（HOI）姿态估计中由于几何模糊性和严重遮挡带来的挑战。该方法通过MAE的掩蔽-重建策略学习几何感知和遮挡鲁棒的表示，并引入区域特定掩蔽比例分配来平衡手部和物体特征学习难度，同时通过骨架驱动掩蔽模拟真实遮挡。此外，通过掩蔽符号距离场（SDF）驱动的多模态学习增强了编码器的3D几何感知能力。实验证明MaskHOI显著优于现有最先进方法。", "keywords": "3D手物交互, 姿态估计, 掩蔽自编码器, 符号距离场, 预训练", "comments": "MaskHOI的创新点在于将MAE的掩蔽-重建策略应用于3D手物交互估计，并通过区域特定掩蔽比例分配和骨架驱动掩蔽解决了手部精细结构和真实遮挡模拟的挑战。引入掩蔽SDF驱动的多模态学习是另一个亮点，它有效地弥补了单目输入的3D几何感知不足，增强了模型的鲁棒性。这项工作为鲁棒的3D HOI估计提供了一个有前景的方向。"}}
{"id": "2507.13887", "title": "A Survey of Dimension Estimation Methods", "authors": ["James A. D. Binnie", "Paweł Dłotko", "John Harvey", "Jakub Malinowski", "Ka Man Yim"], "categories": ["stat.ML", "cs.LG", "math.DG", "math.MG", "math.ST", "stat.TH", "62R40 (Primary) 62R30, 62R07, 62G05, 53Z50 (Secondary)"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      45 pages + appendices, 24 figures", "url": "http://arxiv.org/abs/2507.13887v1", "summary": "It is a standard assumption that datasets in high dimension have an internal\nstructure which means that they in fact lie on, or near, subsets of a lower\ndimension. In many instances it is important to understand the real dimension\nof the data, hence the complexity of the dataset at hand. A great variety of\ndimension estimators have been developed to find the intrinsic dimension of the\ndata but there is little guidance on how to reliably use these estimators.\n  This survey reviews a wide range of dimension estimation methods,\ncategorising them by the geometric information they exploit: tangential\nestimators which detect a local affine structure; parametric estimators which\nrely on dimension-dependent probability distributions; and estimators which use\ntopological or metric invariants.\n  The paper evaluates the performance of these methods, as well as\ninvestigating varying responses to curvature and noise. Key issues addressed\ninclude robustness to hyperparameter selection, sample size requirements,\naccuracy in high dimensions, precision, and performance on non-linear\ngeometries. In identifying the best hyperparameters for benchmark datasets,\noverfitting is frequent, indicating that many estimators may not generalise\nwell beyond the datasets on which they have been tested.", "comment": "45 pages + appendices, 24 figures", "pdf_url": "http://arxiv.org/pdf/2507.13887v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "维度估计方法综述", "tldr": "本综述回顾了各种维度估计方法，对其进行分类并评估其性能，指出许多估计器在基准数据集上存在过拟合问题，可能导致泛化能力差。", "motivation": "高维数据集通常具有较低的内在维度，理解数据的真实维度（即数据集的复杂性）至关重要。尽管存在多种维度估计器，但缺乏关于如何可靠使用这些估计器的指导，本综述旨在填补这一空白。", "method": "本综述回顾了广泛的维度估计方法，并根据它们利用的几何信息进行分类：切线估计器（检测局部仿射结构）、参数估计器（依赖于维度相关的概率分布）以及使用拓扑或度量不变量的估计器。论文评估了这些方法的性能，并研究了它们对曲率和噪声的不同响应，同时探讨了超参数选择的鲁棒性、样本量要求、高维精度、精确度以及在非线性几何上的性能。", "result": "在为基准数据集识别最佳超参数时，过拟合频繁发生，这表明许多估计器可能无法很好地泛化到它们已经测试过的数据集之外。", "conclusion": "许多维度估计器在为基准数据集识别最佳超参数时容易出现过拟合，这表明它们可能无法很好地泛化到其测试数据集之外。", "translation": "在高维数据集中，通常假设数据具有内部结构，这意味着它们实际上位于或接近较低维度的子集上。在许多情况下，了解数据的真实维度，从而了解数据集的复杂性，非常重要。已经开发出各种各样的维度估计器来寻找数据的内在维度，但关于如何可靠地使用这些估计器却鲜有指导。\n本综述回顾了广泛的维度估计方法，并根据它们利用的几何信息进行分类：检测局部仿射结构的切线估计器；依赖于与维度相关的概率分布的参数估计器；以及使用拓扑或度量不变量的估计器。\n本文评估了这些方法的性能，并研究了它们对曲率和噪声的不同响应。解决的关键问题包括对超参数选择的鲁棒性、样本量要求、高维精度、精确度以及在非线性几何上的性能。在为基准数据集识别最佳超参数时，过拟合频繁发生，这表明许多估计器可能无法很好地泛化到它们已经测试过的数据集之外。", "summary": "本综述全面回顾了多种维度估计方法，并依据其利用的几何信息将其分为切线、参数和拓扑/度量不变估计器。论文评估了这些方法的性能，并深入探讨了它们对曲率和噪声的响应，以及在超参数选择鲁棒性、样本量需求、高维精度和非线性几何表现等方面的关键问题。研究发现，在基准数据集上寻找最佳超参数时，过拟合现象频繁，暗示许多估计器在泛化能力上可能存在局限性。", "keywords": "维度估计, 内在维度, 综述, 过拟合, 泛化", "comments": "本文通过对维度估计方法的系统性回顾和分类，为理解和应用这些方法提供了宝贵的指导。其重要性在于揭示了当前维度估计器在实践中面临的一个关键限制——即在基准数据集上过度拟合导致泛化能力不足的问题，这对于研究人员和实际应用者都具有重要的警示意义。"}}
{"id": "2504.13393", "title": "BeetleVerse: A Study on Taxonomic Classification of Ground Beetles", "authors": ["S M Rayeed", "Alyson East", "Samuel Stevens", "Sydne Record", "Charles V Stewart"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Paper Accepted at Computer Vision and Pattern Recognition 2025 (Workshop CV4Animals: Computer Vision for Animal Behavior Tracking and Modeling)", "url": "http://arxiv.org/abs/2504.13393v2", "summary": "Ground beetles are a highly sensitive and speciose biological indicator,\nmaking them vital for monitoring biodiversity. However, they are currently an\nunderutilized resource due to the manual effort required by taxonomic experts\nto perform challenging species differentiations based on subtle morphological\ndifferences, precluding widespread applications. In this paper, we evaluate 12\nvision models on taxonomic classification across four diverse, long-tailed\ndatasets spanning over 230 genera and 1769 species, with images ranging from\ncontrolled laboratory settings to challenging field-collected (in-situ)\nphotographs. We further explore taxonomic classification in two important\nreal-world contexts: sample efficiency and domain adaptation. Our results show\nthat the Vision and Language Transformer combined with an MLP head is the best\nperforming model, with 97% accuracy at genus and 94% at species level. Sample\nefficiency analysis shows that we can reduce train data requirements by up to\n50% with minimal compromise in performance. The domain adaptation experiments\nreveal significant challenges when transferring models from lab to in-situ\nimages, highlighting a critical domain gap. Overall, our study lays a\nfoundation for large-scale automated taxonomic classification of beetles, and\nbeyond that, advances sample-efficient learning and cross-domain adaptation for\ndiverse long-tailed ecological datasets.", "comment": "Paper Accepted at Computer Vision and Pattern Recognition 2025\n  (Workshop CV4Animals: Computer Vision for Animal Behavior Tracking and\n  Modeling)", "pdf_url": "http://arxiv.org/pdf/2504.13393v2", "cate": "cs.CV", "date": "2025-04-18", "updated": "2025-07-18", "AI": {"title_translation": "甲虫宇宙：一项关于步甲分类学分类的研究", "tldr": "本文评估了12种视觉模型在步甲分类学分类上的表现，发现视觉和语言Transformer模型表现最佳，并在样本效率和领域适应性方面进行了探索，为大规模自动化分类奠定了基础。", "motivation": "步甲作为重要的生物指示物种，其分类识别因需要分类学专家手动辨别细微形态差异而耗时耗力，限制了其广泛应用。本研究旨在通过自动化方法解决这一挑战。", "method": "研究评估了12种视觉模型，用于对跨越230多个属和1769个物种的四个多样化、长尾数据集进行分类。这些数据集包含从受控实验室环境到具挑战性的野外（原位）照片。此外，研究还探讨了样本效率和领域适应性在真实世界背景下的分类问题。", "result": "视觉和语言Transformer结合MLP头部是表现最佳的模型，在属级别达到97%的准确率，在物种级别达到94%的准确率。样本效率分析表明，在性能损失最小的情况下，训练数据需求可减少高达50%。领域适应性实验揭示了将模型从实验室图像转移到原位图像时存在显著挑战，突出了关键的领域鸿沟。", "conclusion": "本研究为大规模自动化甲虫分类奠定了基础，并进一步推动了针对多样化长尾生态数据集的样本高效学习和跨领域适应技术。", "translation": "步甲是一种高度敏感且物种丰富的生物指示物种，对于监测生物多样性至关重要。然而，由于分类学专家需要根据细微的形态差异进行具有挑战性的物种区分，需要大量人工投入，导致其目前作为一种未充分利用的资源，阻碍了其广泛应用。在本文中，我们评估了12种视觉模型在跨越230多个属和1769个物种的四个多样化、长尾数据集上的分类学分类能力，这些图像涵盖了从受控实验室环境到具有挑战性的野外（原位）照片。我们进一步探讨了分类学分类在两个重要的现实世界背景下的应用：样本效率和领域适应性。我们的结果表明，结合MLP头部的视觉和语言Transformer是表现最佳的模型，在属级别达到97%的准确率，在物种级别达到94%的准确率。样本效率分析表明，在性能损失最小的情况下，我们可以将训练数据需求减少高达50%。领域适应性实验揭示了将模型从实验室图像转移到原位图像时存在显著挑战，突出了关键的领域鸿沟。总的来说，我们的研究为大规模自动化甲虫分类奠定了基础，并在此之外，推动了针对多样化长尾生态数据集的样本高效学习和跨领域适应技术。", "summary": "本研究旨在解决步甲物种手动分类耗时且复杂的挑战，通过评估12种视觉模型在包含实验室和野外图像的四个大型数据集上的表现。研究发现，结合MLP头部的视觉和语言Transformer模型性能最佳，在属和物种级别分别达到97%和94%的准确率。此外，研究还探索了样本效率和领域适应性，发现训练数据可减少50%且性能损失小，但从实验室到野外图像的领域适应存在显著挑战。本研究为大规模自动化甲虫分类以及生态数据集的样本高效学习和跨领域适应提供了基础。", "keywords": "步甲, 分类学分类, 视觉模型, 样本效率, 领域适应", "comments": "本文将先进的视觉模型应用于生态学中具有挑战性的分类任务，创新性地解决了生物多样性监测中人工识别的瓶颈。其对样本效率和领域适应性的探索，尤其指出领域鸿沟的挑战，具有重要的实践意义，为未来大规模自动化生态数据处理提供了宝贵经验。"}}
{"id": "2502.16580", "title": "Can Indirect Prompt Injection Attacks Be Detected and Removed?", "authors": ["Yulin Chen", "Haoran Li", "Yuan Sui", "Yufei He", "Yue Liu", "Yangqiu Song", "Bryan Hooi"], "categories": ["cs.CR"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "Comments:      To Appear in ACL 2025", "url": "http://arxiv.org/abs/2502.16580v2", "summary": "Prompt injection attacks manipulate large language models (LLMs) by\nmisleading them to deviate from the original input instructions and execute\nmaliciously injected instructions, because of their instruction-following\ncapabilities and inability to distinguish between the original input\ninstructions and maliciously injected instructions. To defend against such\nattacks, recent studies have developed various detection mechanisms. If we\nrestrict ourselves specifically to works which perform detection rather than\ndirect defense, most of them focus on direct prompt injection attacks, while\nthere are few works for the indirect scenario, where injected instructions are\nindirectly from external tools, such as a search engine. Moreover, current\nworks mainly investigate injection detection methods and pay less attention to\nthe post-processing method that aims to mitigate the injection after detection.\nIn this paper, we investigate the feasibility of detecting and removing\nindirect prompt injection attacks, and we construct a benchmark dataset for\nevaluation. For detection, we assess the performance of existing LLMs and\nopen-source detection models, and we further train detection models using our\ncrafted training datasets. For removal, we evaluate two intuitive methods: (1)\nthe segmentation removal method, which segments the injected document and\nremoves parts containing injected instructions, and (2) the extraction removal\nmethod, which trains an extraction model to identify and remove injected\ninstructions.", "comment": "To Appear in ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.16580v2", "cate": "cs.CR", "date": "2025-02-23", "updated": "2025-07-18", "AI": {"title_translation": "间接提示注入攻击能否被检测和移除？", "tldr": "本文研究了检测和移除间接提示注入攻击的可行性，并构建了基准数据集，评估了现有模型和提出两种移除方法。", "motivation": "提示注入攻击通过误导大型语言模型（LLMs）执行恶意指令，现有防御机制大多关注直接注入攻击，而对间接注入场景（如来自搜索引擎的指令）关注较少。此外，当前工作主要研究检测方法，对检测后的缓解（移除）方法关注不足。", "method": "研究了检测和移除间接提示注入攻击的可行性。构建了一个基准数据集用于评估。对于检测，评估了现有LLM和开源检测模型的性能，并使用自建训练数据集训练了检测模型。对于移除，评估了两种直观方法：1) 分割移除法，分割注入文档并移除包含注入指令的部分；2) 提取移除法，训练一个提取模型来识别和移除注入指令。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "提示注入攻击通过误导大型语言模型（LLMs）偏离原始输入指令并执行恶意注入指令来操纵LLMs，这是因为LLMs具有遵循指令的能力，并且无法区分原始输入指令和恶意注入指令。为了防御此类攻击，最近的研究开发了各种检测机制。如果我们将研究范围限定在执行检测而非直接防御的工作，大多数都侧重于直接提示注入攻击，而针对间接场景（其中注入指令间接来自外部工具，如搜索引擎）的工作很少。此外，当前工作主要研究注入检测方法，而对检测后旨在缓解注入的后处理方法关注较少。在本文中，我们研究了检测和移除间接提示注入攻击的可行性，并构建了一个用于评估的基准数据集。对于检测，我们评估了现有LLMs和开源检测模型的性能，并使用我们精心制作的训练数据集进一步训练了检测模型。对于移除，我们评估了两种直观方法：(1) 分割移除法，该方法将注入文档分段并移除包含注入指令的部分；(2) 提取移除法，该方法训练一个提取模型来识别和移除注入指令。", "summary": "本文探讨了检测和移除针对大型语言模型的间接提示注入攻击的可行性。针对现有研究主要关注直接注入和检测而非移除的不足，作者构建了一个新的基准数据集。在检测方面，评估了现有LLM和开源检测模型，并训练了自定义模型。在移除方面，提出了分割移除和提取移除两种方法，旨在缓解检测后的注入问题。", "keywords": "间接提示注入, 大型语言模型, 攻击检测, 攻击移除, 基准数据集", "comments": "该论文解决了LLM安全领域中一个重要但被忽视的问题——间接提示注入攻击的检测和移除。其创新点在于构建了针对间接注入的基准数据集，并首次系统性地探讨了攻击后的移除方法，这对于提升LLM的鲁棒性和安全性具有重要意义。然而，抽象中并未给出具体的实验结果，这使得无法评估其方法的实际效果和性能。"}}
{"id": "2507.13548", "title": "Efficient Decoding of Double-circulant and Wozencraft Codes from Square-root Errors", "authors": ["Oren Dubin", "Noam Oz", "Noga Ron-Zewi"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13548v1", "summary": "We present efficient decoding algorithms from square-root errors for two\nknown families of double-circulant codes: A construction based on Sidon sets\n(Bhargava, Taveres, and Shiva, \\emph{IEEE IT 74}; Calderbank, \\emph{IEEE IT\n83}; Guruswami and Li, \\emph{IEEE IT 2025}), and a construction based on cyclic\ncodes (Chen, Peterson, and Weldon, \\emph{Information and Control 1969}). We\nfurther observe that the work of Guruswami and Li implicitly gives a\ntransformation from double-circulant codes of certain block lengths to\nWozencraft codes which preserves that distance of the codes, and we show that\nthis transformation also preserves efficiency of decoding. By instantiating\nthis transformation with the first family of double-circulant codes based on\nSidon sets, we obtain an explicit construction of a Wozencraft code that is\nefficiently decodable from square-root errors. We also discuss limitations on\ninstantiating this transformation with the second family of double-circulant\ncodes based on cyclic codes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13548v1", "cate": "cs.IT", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "双循环码和沃曾克拉夫特码的平方根误差高效解码", "tldr": "本文提出了两种已知双循环码家族的平方根误差高效解码算法，并观察到一种从双循环码到沃曾克拉夫特码的变换，该变换保留了码距和解码效率，从而得到了一种可从平方根误差高效解码的沃曾克拉夫特码的显式构造。", "motivation": "本文旨在为两种已知的双循环码（基于Sidon集和基于循环码）提供高效的平方根误差解码算法，并探索将双循环码转换为沃曾克拉夫特码的可能性，同时保持解码效率。", "method": "研究者提出了针对两种双循环码家族（基于Sidon集和基于循环码）的平方根误差高效解码算法。他们进一步观察到Guruswami和Li的工作隐含地提供了一种从双循环码到沃曾克拉夫特码的变换，该变换保留了码距，并证明了其也保留了解码效率。通过使用基于Sidon集的第一类双循环码实例化此变换，他们获得了一个显式的沃曾克拉夫特码构造。", "result": "研究者获得了一个可从平方根误差高效解码的沃曾克拉夫特码的显式构造。此外，他们还讨论了将该变换应用于第二类双循环码（基于循环码）时的局限性。", "conclusion": "本文成功为双循环码提供了高效解码算法，并通过码变换提出了一种构造可高效解码的沃曾克拉夫特码的方法，同时指出了该方法在特定码家族上的局限性。", "translation": "我们提出了两种已知双循环码家族的平方根误差高效解码算法：一种基于Sidon集构造（Bhargava、Taveres和Shiva，IEEE IT 74；Calderbank，IEEE IT 83；Guruswami和Li，IEEE IT 2025），以及一种基于循环码构造（Chen、Peterson和Weldon，Information and Control 1969）。我们进一步观察到Guruswami和Li的工作隐含地提供了一种从特定分组长度的双循环码到沃曾克拉夫特码的变换，该变换保留了码的距离，并且我们证明了这种变换也保留了解码效率。通过使用基于Sidon集的第一类双循环码实例化此变换，我们获得了一个可从平方根误差高效解码的沃曾克拉夫特码的显式构造。我们还讨论了使用基于循环码的第二类双循环码实例化此变换的局限性。", "summary": "本文提出了两种已知双循环码家族（基于Sidon集和循环码）的平方根误差高效解码算法。研究者发现Guruswami和Li的工作隐含了一种将双循环码转换为沃曾克拉夫特码的变换，该变换不仅保留码距，还保持解码效率。通过将此变换应用于基于Sidon集的双循环码，他们成功构建了一种可从平方根误差高效解码的沃曾克拉夫特码。论文还探讨了将该变换应用于基于循环码的双循环码时的限制。", "keywords": "双循环码, 沃曾克拉夫特码, 解码算法, 平方根误差, 码变换", "comments": "该论文的创新之处在于不仅为特定双循环码提供了高效解码方法，更重要的是，它识别并利用了一种码变换，从而扩展了高效解码的范围到沃曾克拉夫特码，并明确指出了该方法的适用性和局限性，对纠错码领域具有重要意义。"}}
{"id": "2504.07312", "title": "Mindsets and Management: AI and Gender (In)Equitable Access to Finance", "authors": ["Genevieve Smith"], "categories": ["cs.CY"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      Accepted for presentation at ACM FAccT 2025", "url": "http://arxiv.org/abs/2504.07312v3", "summary": "A growing trend in financial technology (fintech) is the use of mobile phone\ndata and machine learning (ML) to provide credit scores- and subsequently,\nopportunities to access loans- to groups left out of traditional banking. This\npaper draws on interview data with leaders, investors, and data scientists at\nfintech companies developing ML-based alternative lending apps in low- and\nmiddle-income countries to explore financial inclusion and gender implications.\nMore specifically, it examines how the underlying logics, design choices, and\nmanagement decisions of ML-based alternative lending tools by fintechs embed or\nchallenge gender biases, and consequently influence gender equity in access to\nfinance. Findings reveal developers follow 'gender blind' approaches, grounded\nin beliefs that ML is objective and data reflects the truth. This leads to a\nlack of grappling with the ways data, features for creditworthiness, and access\nto apps are gendered. Overall, tools increase access to finance, but not gender\nequitably: Interviewees report less women access loans and receive lower\namounts than men, despite being better repayers. Fintechs identify demand- and\nsupply-side reasons for gender differences, but frame them as outside their\nresponsibility. However, that women are observed as better repayers reveals a\nmarket inefficiency and potential discriminatory effect, further linked to\nprofit optimization objectives. This research introduces the concept of encoded\ngender norms, whereby without explicit attention to the gendered nature of data\nand algorithmic design, AI tools reproduce existing inequalities. In doing so,\nthey reinforce gender norms as self-fulfilling prophecies. The idea that AI is\ninherently objective and, when left alone, 'fair', is seductive and misleading.\nIn reality, algorithms reflect the perspectives, priorities, and values of the\npeople and institutions that design them.", "comment": "Accepted for presentation at ACM FAccT 2025", "pdf_url": "http://arxiv.org/pdf/2504.07312v3", "cate": "cs.CY", "date": "2025-04-09", "updated": "2025-07-17", "AI": {"title_translation": "思维模式与管理：人工智能与性别（不）平等的金融准入", "tldr": "金融科技机器学习工具增加了金融准入，但并未实现性别平等，原因在于“性别盲”方法和编码的性别规范，从而加剧了现有不平等。", "motivation": "探讨金融科技中基于机器学习的替代性贷款应用如何嵌入或挑战性别偏见，并进而影响金融准入的性别公平性，尤其是在低收入和中等收入国家。", "method": "研究通过访谈低收入和中等收入国家开发基于机器学习的替代性贷款应用的金融科技公司领导者、投资者和数据科学家来收集数据。", "result": "研究发现开发者遵循“性别盲”方法，认为机器学习客观且数据反映真相，导致未能解决数据、信用特征和应用访问的性别差异。尽管工具增加了金融准入，但并未实现性别平等：女性获得的贷款更少、金额更低，尽管她们还款表现更好。金融科技公司将性别差异归因于供需两侧原因，并认为这不在其责任范围内。然而，女性更好的还款表现揭示了市场低效和潜在的歧视效应。", "conclusion": "人工智能并非天生客观和公平，算法反映了设计者及其机构的视角、优先事项和价值观。若不明确关注数据和算法设计的性别性质，人工智能工具将复制现有的不平等，并强化性别规范。", "translation": "金融科技（fintech）领域的一个日益增长的趋势是利用手机数据和机器学习（ML）来提供信用评分，进而为被传统银行排除在外的群体提供获得贷款的机会。本文借鉴了对低收入和中等收入国家开发基于机器学习的替代性贷款应用程序的金融科技公司领导者、投资者和数据科学家的访谈数据，以探讨金融普惠和性别影响。更具体地说，它研究了金融科技公司基于机器学习的替代性贷款工具的潜在逻辑、设计选择和管理决策如何嵌入或挑战性别偏见，并因此影响金融准入的性别公平性。研究结果显示，开发者遵循“性别盲”方法，其根源在于相信机器学习是客观的，数据反映真相。这导致他们未能深入探讨数据、信用评级特征以及应用程序访问方式中的性别差异。总体而言，这些工具增加了金融准入，但并未实现性别平等：受访者报告称，女性获得的贷款比男性少，金额也低于男性，尽管她们的还款表现更好。金融科技公司将性别差异归因于需求侧和供给侧原因，但将其界定为超出其责任范围。然而，女性被观察到还款表现更好，这揭示了市场效率低下和潜在的歧视效应，并进一步与利润优化目标相关联。本研究引入了“编码性别规范”的概念，即在不明确关注数据和算法设计的性别性质的情况下，人工智能工具会复制现有的不平等。在此过程中，它们将性别规范强化为自我实现的预言。人工智能本质上是客观的，并且在不干预的情况下是“公平”的这种想法是诱人且具有误导性的。实际上，算法反映了设计它们的人和机构的视角、优先事项和价值观。", "summary": "本文探讨了在低收入和中等收入国家，基于机器学习的替代性贷款应用如何影响金融准入的性别公平性。通过访谈金融科技公司领导者，研究发现开发者基于对机器学习客观性的信念而采取的“性别盲”方法，导致这些工具在增加金融准入的同时，却加剧了性别不平等。尽管女性的还款表现更好，但她们获得的贷款更少、金额更低，这种市场低效与利润优化目标相关。论文提出了“编码性别规范”的概念，认为人工智能工具若不明确关注数据和算法设计的性别性质，便会复制现有不平等，从而挑战了人工智能固有的公平性观念。", "keywords": "人工智能, 性别不平等, 金融普惠, 机器学习, 金融科技", "comments": "本文通过提出“编码性别规范”的概念，并挑战人工智能固有客观性的普遍观念，尤其是在金融普惠这一关键领域，展现了创新性。其研究结果揭示了金融科技发展中的一个关键盲点，即可能加剧现有的社会不平等，这对于伦理AI和普惠金融的讨论具有重要意义。"}}
{"id": "2507.14013", "title": "Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model", "authors": ["Ji-Yan Wu", "Zheng Yong Poh", "Anoop C. Patil", "Bongsoo Park", "Giovanni Volpe", "Daisuke Urano"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14013v1", "summary": "Accurate detection of nutrient deficiency in plant leaves is essential for\nprecision agriculture, enabling early intervention in fertilization, disease,\nand stress management. This study presents a deep learning framework for leaf\nanomaly segmentation using multispectral imaging and an enhanced YOLOv5 model\nwith a transformer-based attention head. The model is tailored for processing\nnine-channel multispectral input and uses self-attention mechanisms to better\ncapture subtle, spatially-distributed symptoms. The plants in the experiments\nwere grown under controlled nutrient stress conditions for evaluation. We carry\nout extensive experiments to benchmark the proposed model against the baseline\nYOLOv5. Extensive experiments show that the proposed model significantly\noutperforms the baseline YOLOv5, with an average Dice score and IoU\n(Intersection over Union) improvement of about 12%. In particular, this model\nis effective in detecting challenging symptoms like chlorosis and pigment\naccumulation. These results highlight the promise of combining multi-spectral\nimaging with spectral-spatial feature learning for advancing plant phenotyping\nand precision agriculture.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14013v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于多光谱成像和优化分割模型的植物养分缺乏分析", "tldr": "本研究提出了一种结合多光谱成像和增强型YOLOv5模型的深度学习框架，显著提高了植物养分缺乏的检测精度，对精准农业具有重要意义。", "motivation": "在精准农业中，准确检测植物叶片养分缺乏对于早期干预施肥、病害和胁迫管理至关重要。", "method": "本研究提出了一个用于叶片异常分割的深度学习框架，该框架结合了多光谱成像和带有基于Transformer注意力头的增强YOLOv5模型。该模型专为处理九通道多光谱输入而设计，并利用自注意力机制更好地捕捉细微的、空间分布的症状。实验中的植物在受控的养分胁迫条件下生长以进行评估。", "result": "大量实验表明，所提出的模型显著优于基线YOLOv5，平均Dice分数和IoU（交并比）提高了约12%。特别是，该模型在检测叶片黄化和色素积累等具有挑战性的症状方面非常有效。", "conclusion": "这些结果突出了将多光谱成像与光谱-空间特征学习相结合在推进植物表型分析和精准农业方面的巨大前景。", "translation": "准确检测植物叶片养分缺乏对于精准农业至关重要，能够实现对施肥、病害和胁迫管理的早期干预。本研究提出了一种深度学习框架，用于使用多光谱成像和带有基于Transformer注意力头的增强YOLOv5模型进行叶片异常分割。该模型专为处理九通道多光谱输入而设计，并利用自注意力机制更好地捕捉细微的、空间分布的症状。实验中的植物在受控的养分胁迫条件下生长以进行评估。我们进行了大量实验，将所提出的模型与基线YOLOv5进行了基准测试。大量实验表明，所提出的模型显著优于基线YOLOv5，平均Dice分数和IoU（交并比）提高了约12%。特别是，该模型在检测叶片黄化和色素积累等具有挑战性的症状方面非常有效。这些结果突出了将多光谱成像与光谱-空间特征学习相结合在推进植物表型分析和精准农业方面的巨大前景。", "summary": "本文提出了一种用于检测植物养分缺乏的深度学习框架，对精准农业至关重要。该框架利用多光谱成像和带有基于Transformer注意力头的增强YOLOv5模型，并针对九通道多光谱数据进行了优化。实验表明，所提出的模型显著优于基线YOLOv5，在Dice和IoU分数上提高了12%，并有效检测出叶片黄化和色素积累等细微症状。这突出了多光谱成像与光谱-空间特征学习相结合在先进植物表型分析中的潜力。", "keywords": "植物养分缺乏, 多光谱成像, 深度学习, YOLOv5, 精准农业", "comments": "本文创新性地将多光谱成像与增强型深度学习模型（带有Transformer注意力的YOLOv5）相结合，用于植物养分缺乏检测。使用九通道多光谱输入和自注意力机制来捕捉细微症状是一个显著的进步，解决了精准农业中的关键需求。相对于基线YOLOv5的显著性能提升证明了其实际价值。"}}
{"id": "2504.21801", "title": "DeepSeek-Prover-V2: Advancing Formal Mathematical Reasoning via Reinforcement Learning for Subgoal Decomposition", "authors": ["Z. Z. Ren", "Zhihong Shao", "Junxiao Song", "Huajian Xin", "Haocheng Wang", "Wanjia Zhao", "Liyue Zhang", "Zhe Fu", "Qihao Zhu", "Dejian Yang", "Z. F. Wu", "Zhibin Gou", "Shirong Ma", "Hongxuan Tang", "Yuxuan Liu", "Wenjun Gao", "Daya Guo", "Chong Ruan"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.21801v2", "summary": "We introduce DeepSeek-Prover-V2, an open-source large language model designed\nfor formal theorem proving in Lean 4, with initialization data collected\nthrough a recursive theorem proving pipeline powered by DeepSeek-V3. The\ncold-start training procedure begins by prompting DeepSeek-V3 to decompose\ncomplex problems into a series of subgoals. The proofs of resolved subgoals are\nsynthesized into a chain-of-thought process, combined with DeepSeek-V3's\nstep-by-step reasoning, to create an initial cold start for reinforcement\nlearning. This process enables us to integrate both informal and formal\nmathematical reasoning into a unified model. The resulting model,\nDeepSeek-Prover-V2-671B, achieves state-of-the-art performance in neural\ntheorem proving, reaching 88.9% pass ratio on the MiniF2F-test and solving 49\nout of 658 problems from PutnamBench. In addition to standard benchmarks, we\nintroduce ProverBench, a collection of 325 formalized problems, to enrich our\nevaluation, including 15 selected problems from the recent AIME competitions\n(years 24-25). Further evaluation on these 15 AIME problems shows that the\nmodel successfully solves 6 of them. In comparison, DeepSeek-V3 solves 8 of\nthese problems using majority voting, highlighting that the gap between formal\nand informal mathematical reasoning in large language models is substantially\nnarrowing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.21801v2", "cate": "cs.CL", "date": "2025-04-30", "updated": "2025-07-18", "AI": {"title_translation": "DeepSeek-Prover-V2：通过强化学习进行子目标分解推进形式化数学推理", "tldr": "DeepSeek-Prover-V2是一个新的开源大语言模型，通过强化学习和子目标分解，在形式化定理证明方面取得了最先进的性能，并缩小了形式化与非形式化数学推理之间的差距。", "motivation": "旨在通过强化学习和子目标分解，推进形式化数学推理的能力，并缩小大型语言模型在形式化和非形式化数学推理之间的差距。", "method": "该研究引入了DeepSeek-Prover-V2，一个用于Lean 4形式化定理证明的开源大语言模型。其训练过程通过一个由DeepSeek-V3驱动的递归定理证明流程收集初始化数据。冷启动训练程序首先提示DeepSeek-V3将复杂问题分解为一系列子目标。已解决子目标的证明被合成为思维链过程，并结合DeepSeek-V3的逐步推理，为强化学习创建初始冷启动。此过程将非形式化和形式化数学推理整合到一个统一模型中。", "result": "DeepSeek-Prover-V2-671B模型在神经定理证明方面取得了最先进的性能，在MiniF2F-test上达到了88.9%的通过率，并解决了PutnamBench中658个问题中的49个。引入了ProverBench，一个包含325个形式化问题的新评估基准，其中包括来自AIME竞赛的15个问题。在这些AIME问题上，模型成功解决了6个，而DeepSeek-V3使用多数投票解决了8个，表明形式化与非形式化数学推理之间的差距正在显著缩小。", "conclusion": "DeepSeek-Prover-V2通过整合强化学习和子目标分解，在形式化定理证明领域取得了显著进展，实现了最先进的性能，并成功缩小了大型语言模型在处理形式化与非形式化数学推理之间存在的差距。", "translation": "我们推出了DeepSeek-Prover-V2，一个开源的大型语言模型，专为Lean 4中的形式化定理证明而设计，其初始化数据通过DeepSeek-V3驱动的递归定理证明管道收集。冷启动训练过程首先提示DeepSeek-V3将复杂问题分解为一系列子目标。已解决子目标的证明被合成为思维链过程，并结合DeepSeek-V3的逐步推理，为强化学习创建初始冷启动。这个过程使我们能够将非形式化和形式化数学推理整合到一个统一的模型中。由此产生的模型DeepSeek-Prover-V2-671B在神经定理证明方面取得了最先进的性能，在MiniF2F-test上达到了88.9%的通过率，并解决了PutnamBench中658个问题中的49个。除了标准基准测试外，我们还引入了ProverBench，一个包含325个形式化问题的集合，以丰富我们的评估，其中包括来自近期AIME竞赛（24-25年）的15个精选问题。对这15个AIME问题的进一步评估显示，该模型成功解决了其中6个。相比之下，DeepSeek-V3使用多数投票解决了其中8个问题，这突出表明大型语言模型中形式化与非形式化数学推理之间的差距正在大幅缩小。", "summary": "DeepSeek-Prover-V2是一个开源的大型语言模型，专注于Lean 4中的形式化定理证明。它利用DeepSeek-V3进行递归定理证明管道和子目标分解，并通过强化学习进行冷启动训练。该模型将非形式化和形式化数学推理整合，实现了神经定理证明的最先进性能，在MiniF2F-test上通过率为88.9%，并解决了PutnamBench和ProverBench上的多个问题。研究表明，DeepSeek-Prover-V2显著缩小了大型语言模型在形式化与非形式化数学推理之间的差距。", "keywords": "形式化定理证明, 强化学习, 子目标分解, 大语言模型, Lean 4", "comments": "该论文的创新点在于其利用强化学习进行子目标分解，并将非形式化与形式化数学推理有效整合到统一模型中，从而显著提升了形式化定理证明的能力。其在多个基准测试上取得的SOTA性能，特别是对AIME问题的解决能力，突显了其重要性，表明大型语言模型在复杂数学推理方面取得了实质性进展。"}}
{"id": "2506.09046", "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "categories": ["cs.LG", "cs.AI", "cs.MA"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.09046v2", "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.09046v2", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-18", "AI": {"title_translation": "智能体神经网络：通过文本反向传播实现自进化的多智能体系统", "tldr": "本文提出了智能体神经网络（ANN），一个将多智能体协作概念化为分层神经网络架构的框架，通过前向和后向优化阶段，使智能体能自进化角色、提示和协调，在多个基准测试中超越现有方法。", "motivation": "当前的多大语言模型（LLM）多智能体系统依赖静态、手动配置，限制了其处理复杂高维任务的能力。", "method": "本文提出了智能体神经网络（ANN）框架，将多智能体协作视为分层的神经网络架构。每个智能体是节点，每层是一个合作团队。ANN包含两个优化阶段：1. 前向阶段：任务被动态分解，合作智能体团队逐层构建；2. 后向阶段：通过迭代反馈精炼全局和局部协作，使智能体能自进化其角色、提示和协调。这种神经符号方法使ANN能在训练后创建新的或专门的智能体团队。", "result": "ANN在准确性和适应性方面取得了显著提升。在四个基准数据集上，ANN在相同配置下超越了领先的多智能体基线，显示出持续的性能改进。", "conclusion": "智能体神经网络（ANN）提供了一个可扩展、数据驱动的多智能体系统框架，结合了大语言模型的协作能力与神经网络原则的效率和灵活性。", "translation": "利用多个大型语言模型（LLMs）已被证明能有效解决复杂的、高维度的任务，但当前的方法通常依赖于静态、手动配置的多智能体设置。为了克服这些限制，我们提出了智能体神经网络（ANN），一个将多智能体协作概念化为分层神经网络架构的框架。在这种设计中，每个智能体作为一个节点运行，每层形成一个专注于特定子任务的合作“团队”。智能体神经网络遵循两阶段优化策略：（1）前向阶段——借鉴神经网络前向传播的灵感，任务被动态分解为子任务，并逐层构建具有合适聚合方法的合作智能体团队。（2）后向阶段——模仿反向传播，我们通过迭代反馈精炼全局和局部协作，允许智能体自进化其角色、提示和协调。这种神经符号方法使ANN能够在训练后创建新的或专门的智能体团队，从而在准确性和适应性方面带来显著的提升。在四个基准数据集上，ANN在相同配置下超越了领先的多智能体基线，显示出持续的性能改进。我们的研究结果表明，ANN为多智能体系统提供了一个可扩展、数据驱动的框架，结合了LLMs的协作能力与神经网络原则的效率和灵活性。我们计划开源整个框架。", "summary": "本文提出了智能体神经网络（ANN），一个创新的多智能体系统框架，旨在克服现有大语言模型多智能体配置静态、手动工程的局限性。ANN将多智能体协作建模为分层神经网络，其中智能体作为节点，层形成合作团队。该框架采用前向和后向两阶段优化策略：前向阶段动态分解任务并构建团队；后向阶段通过迭代反馈使智能体能自进化其角色、提示和协调。这种神经符号方法使ANN能够创建新的或专门的智能体团队，并在多个基准测试中展现出优于现有领先多智能体基线的准确性和适应性，提供了一个可扩展、数据驱动的LLM协作框架。", "keywords": "智能体神经网络, 多智能体系统, 大语言模型, 文本反向传播, 自进化", "comments": "该论文提出了一个将神经网络原理应用于多智能体系统的新颖框架，通过“文本反向传播”的概念，实现了智能体的自进化和协作优化，极大地提升了多智能体系统在复杂任务中的灵活性和性能。其创新点在于将静态的多智能体配置转化为动态、可学习的架构，有望推动LLM在更复杂场景中的应用。"}}
{"id": "2411.07146", "title": "Lost in Tracking Translation: A Comprehensive Analysis of Visual SLAM in Human-Centered XR and IoT Ecosystems", "authors": ["Yasra Chandio", "Khotso Selialia", "Joseph DeGol", "Luis Garcia", "Fatima M. Anwar"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2411.07146v2", "summary": "Advancements in tracking algorithms have empowered nascent applications\nacross various domains, from steering autonomous vehicles to guiding robots to\nenhancing augmented reality experiences for users. However, these algorithms\nare application-specific and do not work across applications with different\ntypes of motion; even a tracking algorithm designed for a given application\ndoes not work in scenarios deviating from highly standard conditions. For\nexample, a tracking algorithm designed for robot navigation inside a building\nwill not work for tracking the same robot in an outdoor environment. To\ndemonstrate this problem, we evaluate the performance of the state-of-the-art\ntracking methods across various applications and scenarios. To inform our\nanalysis, we first categorize algorithmic, environmental, and\nlocomotion-related challenges faced by tracking algorithms. We quantitatively\nevaluate the performance using multiple tracking algorithms and representative\ndatasets for a wide range of Internet of Things (IoT) and Extended Reality (XR)\napplications, including autonomous vehicles, drones, and humans. Our analysis\nshows that no tracking algorithm works across different applications and\nscenarios within applications. Ultimately, using the insights generated from\nour analysis, we discuss multiple approaches to improving the tracking\nperformance using input data characterization, leveraging intermediate\ninformation, and output evaluation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2411.07146v2", "cate": "cs.RO", "date": "2024-11-11", "updated": "2025-07-17", "AI": {"title_translation": "跟踪翻译中的迷失：以人为中心的XR和IoT生态系统中视觉SLAM的综合分析", "tldr": "现有的跟踪算法是应用特异性的，无法在不同应用和场景中通用。本文通过对最先进的跟踪方法进行广泛评估，证明了这一问题，并讨论了改进跟踪性能的方法。", "motivation": "目前的跟踪算法是应用特异性的，无法在不同类型的运动应用中通用，甚至在偏离标准条件的情况下也无法正常工作。例如，为室内机器人导航设计的算法无法用于室外环境。本文旨在通过综合分析来展示并解决这一问题。", "method": "本文首先将跟踪算法面临的挑战分为算法、环境和运动相关三类。然后，使用多种跟踪算法和代表性数据集，对包括自动驾驶汽车、无人机和人类在内的广泛物联网（IoT）和扩展现实（XR）应用中的最先进跟踪方法进行定量性能评估。", "result": "分析结果表明，没有一种跟踪算法能够跨不同应用工作，也无法在同一应用的不同场景中通用。", "conclusion": "基于分析得出的见解，本文讨论了多种改进跟踪性能的方法，包括输入数据表征、利用中间信息和输出评估。", "translation": "跟踪算法的进步已赋能从自动驾驶汽车操纵、机器人导航到增强用户增强现实体验等各个领域的新兴应用。然而，这些算法是应用特异性的，无法跨不同类型的运动应用工作；即使是为特定应用设计的跟踪算法，在偏离高度标准条件的情况下也无法工作。例如，为建筑物内机器人导航设计的跟踪算法，将无法用于在室外环境中跟踪同一机器人。为了证明这个问题，我们评估了最先进的跟踪方法在各种应用和场景中的性能。为了支持我们的分析，我们首先对跟踪算法面临的算法、环境和运动相关挑战进行了分类。我们使用多种跟踪算法和代表性数据集，对广泛的物联网（IoT）和扩展现实（XR）应用（包括自动驾驶汽车、无人机和人类）的性能进行了定量评估。我们的分析表明，没有一种跟踪算法能够跨不同应用工作，也无法在同一应用内的不同场景中工作。最终，利用我们分析产生的见解，我们讨论了通过输入数据表征、利用中间信息和输出评估来提高跟踪性能的多种方法。", "summary": "本文对视觉SLAM在以人为中心的XR和IoT生态系统中的跟踪性能进行了全面分析。研究指出，现有跟踪算法存在应用特异性问题，无法在不同应用或同一应用的不同场景中通用。为验证此问题，文章对最先进的跟踪方法进行了广泛的定量评估，涉及多种算法和数据集，涵盖自动驾驶、无人机和人类跟踪等应用。研究结果证实了算法泛化能力的不足，并基于此讨论了通过数据表征、中间信息利用和输出评估来提升跟踪性能的潜在策略。", "keywords": "视觉SLAM, 跟踪算法, XR, IoT, 泛化能力", "comments": "本文通过对现有视觉SLAM跟踪算法的全面评估，清晰地揭示了它们在跨应用和跨场景泛化能力上的局限性，这一发现对于XR和IoT领域至关重要。其创新点在于系统性地分类了挑战，并进行了大规模的定量验证。这不仅指出了当前技术的瓶颈，更为未来研究指明了方向，即需要开发更具鲁棒性和通用性的跟踪解决方案，或者通过数据特性化和信息融合来优化现有方法。该研究对于推动XR和IoT应用在复杂动态环境中的实际部署具有重要指导意义。"}}
{"id": "2507.13801", "title": "One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion", "authors": ["Haoang Lu", "Yuanqi Su", "Xiaoning Zhang", "Hao Hu"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13801v1", "summary": "In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a\ncritical perception task for autonomous driving due to its ability to infer\ncomplete 3D scene layouts and semantics from single 2D images. However, in\nreal-world traffic scenarios, a significant portion of the scene remains\noccluded or outside the camera's field of view -- a fundamental challenge that\nexisting monocular SSC methods fail to address adequately. To overcome these\nlimitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC\nframework that leverages pseudo-future frame prediction to expand the model's\neffective perceptual range. Our approach combines poses and depths to establish\naccurate 3D correspondences, enabling geometrically-consistent fusion of past,\npresent, and predicted future frames in 3D space. Unlike conventional methods\nthat rely on simple feature stacking, our 3D-aware architecture achieves more\nrobust scene completion by explicitly modeling spatial-temporal relationships.\nComprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks\ndemonstrate state-of-the-art performance, validating the effectiveness of our\napproach, highlighting our method's ability to improve occlusion reasoning and\n3D scene completion accuracy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13801v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "更进一步：创建未来以提升单目语义场景补全", "tldr": "提出了一种名为CF-SSC的新型时间语义场景补全框架，通过预测伪未来帧来扩展感知范围，显著提高了单目语义场景补全的准确性，尤其是在处理遮挡方面。", "motivation": "现有的单目语义场景补全方法未能充分解决真实交通场景中大部分场景被遮挡或超出摄像机视野的根本挑战。", "method": "提出了一种名为“创建未来SSC（CF-SSC）”的新型时间SSC框架。该方法利用伪未来帧预测来扩展模型的有效感知范围，并结合姿态和深度信息建立精确的3D对应关系，从而在3D空间中实现过去、现在和预测未来帧的几何一致性融合。与传统方法不同，CF-SSC采用3D感知架构，明确建模时空关系，实现更鲁棒的场景补全。", "result": "在SemanticKITTI和SSCBench-KITTI-360基准测试中，CF-SSC展现了最先进的性能，验证了其方法的有效性，并突出了其提高遮挡推理和3D场景补全准确性的能力。", "conclusion": "CF-SSC通过引入伪未来帧预测和3D感知时空建模，有效克服了现有单目语义场景补全方法在处理遮挡和扩展感知范围方面的局限性，实现了最先进的性能。", "translation": "近年来，视觉3D语义场景补全（SSC）已成为自动驾驶的关键感知任务，因为它能够从单张2D图像中推断出完整的3D场景布局和语义。然而，在真实的交通场景中，很大一部分场景仍然被遮挡或超出摄像机的视野——这是现有单目SSC方法未能充分解决的一个根本挑战。为了克服这些局限性，我们提出了“创建未来SSC（CF-SSC）”，这是一种新颖的时间SSC框架，它利用伪未来帧预测来扩展模型的有效感知范围。我们的方法结合姿态和深度信息，建立精确的3D对应关系，从而在3D空间中实现过去、现在和预测未来帧的几何一致性融合。与依赖简单特征堆叠的传统方法不同，我们的3D感知架构通过明确建模时空关系，实现了更鲁棒的场景补全。在SemanticKITTI和SSCBench-KITTI-360基准测试中进行的全面实验表明，我们取得了最先进的性能，验证了我们方法的有效性，并突出了我们方法在改善遮挡推理和3D场景补全准确性方面的能力。", "summary": "本研究提出了一种名为“创建未来SSC（CF-SSC）”的新型时间语义场景补全框架，旨在解决现有单目SSC方法在处理遮挡和有限视野方面的不足。CF-SSC通过预测伪未来帧并结合姿态和深度信息，实现了过去、现在和未来帧在3D空间中的几何一致性融合。其3D感知架构明确建模时空关系，从而提高了场景补全的鲁棒性。实验结果表明，CF-SSC在多个基准测试中达到了最先进的性能，显著提升了遮挡推理和3D场景补全的准确性。", "keywords": "语义场景补全, 单目视觉, 时间框架, 伪未来帧, 3D感知", "comments": "该论文的创新点在于引入了“伪未来帧预测”来扩展模型对场景的感知范围，有效解决了单目语义场景补全中常见的遮挡问题。通过在3D空间中融合过去、现在和预测的未来帧，并采用3D感知架构建模时空关系，该方法显著提升了场景补全的准确性和鲁棒性，对自动驾驶等领域具有重要意义。"}}
{"id": "2507.12327", "title": "Mixed-integer Second-Order Cone Programming for Multi-period Scheduling of Flexible AC Transmission System Devices", "authors": ["Mohamad Charara", "Martin De Montigny", "Nivine Abou Daher", "Hanane Dagdougui", "Antoine Lesage-Landry"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 1 figure, submitted to CIGRÉ 2025 International Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "url": "http://arxiv.org/abs/2507.12327v2", "summary": "With the increasing energy demand and the growing integration of renewable\nsources of energy, power systems face operational challenges such as overloads,\nlosses, and stability concerns, particularly as networks operate near their\ncapacity limits. Flexible alternating current transmission system (FACTS)\ndevices are essential to ensure reliable grid operations and enable the\nefficient integration of renewable energy. This work introduces a mixed-integer\nsecond-order cone programming (MISOCP) model for the multi-period scheduling of\nkey FACTS devices in electric transmission systems. The proposed model\nintegrates four key control mechanisms: (i) on-load tap changers (OLTCs) for\nvoltage regulation via discrete taps; (ii) static synchronous compensators\n(STATCOMs) and (iii) shunt reactors for reactive power compensation; and (iv)\nthyristor-controlled series capacitors (TCSCs) for adjustable impedance and\nflow control. The objective is to minimize active power losses using a limited\nnumber of control actions while meeting physical and operational constraints at\nall times throughout the defined time horizon. To ensure tractability, the\nmodel employs a second-order cone relaxation of the power flow. Device-specific\nconstraints are handled via binary expansion and linearization: OLTCs and shunt\nreactors are modelled with discrete variables, STATCOMs through reactive power\nbounds, and TCSCs using a reformulation-linearization technique (RLT). A\nmulti-period formulation captures the sequential nature of decision making,\nensuring consistency across time steps. The model is evaluated on the IEEE\n9-bus, 30-bus, and RTS96 test systems, demonstrating its ability to reduce\nlosses, with potential applicability to larger-scale grids.", "comment": "10 pages, 1 figure, submitted to CIGR\\'E 2025 International\n  Symposium, Paper 10998, PS1: System Enhancement, Markets and Regulation", "pdf_url": "http://arxiv.org/pdf/2507.12327v2", "cate": "eess.SY", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "柔性交流输电系统设备多周期调度的混合整数二阶锥规划", "tldr": "本文提出了一种混合整数二阶锥规划（MISOCP）模型，用于柔性交流输电系统（FACTS）设备的多周期调度，旨在最小化有功功率损耗，同时满足物理和运行约束。", "motivation": "随着能源需求的增加和可再生能源的日益整合，电力系统面临过载、损耗和稳定性等运行挑战。柔性交流输电系统（FACTS）设备对于确保电网可靠运行和有效整合可再生能源至关重要。", "method": "本文引入了一种混合整数二阶锥规划（MISOCP）模型，用于电力传输系统中关键FACTS设备的多周期调度。该模型整合了四种关键控制机制：有载分接开关（OLTCs）、静止同步补偿器（STATCOMs）、并联电抗器和晶闸管控制串联电容器（TCSCs）。目标是使用有限的控制动作最小化有功功率损耗，同时满足物理和运行约束。为了确保可处理性，模型采用了潮流的二阶锥松弛。设备特定的约束通过二元展开和线性化处理：OLTCs和并联电抗器用离散变量建模，STATCOMs通过无功功率边界建模，TCSCs使用重构-线性化技术（RLT）。多周期公式捕捉了决策的顺序性质，确保了时间步长之间的一致性。", "result": "该模型在IEEE 9节点、30节点和RTS96测试系统上进行了评估，结果表明其能够减少损耗，并具有应用于大规模电网的潜力。", "conclusion": "该MISOCP模型能够有效调度FACTS设备以减少电力系统损耗，并有望应用于更大规模的电网。", "translation": "随着能源需求的增加和可再生能源的日益整合，电力系统面临过载、损耗和稳定性等运行挑战，尤其是在电网接近其容量极限运行时。柔性交流输电系统（FACTS）设备对于确保电网可靠运行和实现可再生能源的有效整合至关重要。本文提出了一种混合整数二阶锥规划（MISOCP）模型，用于电力传输系统中关键FACTS设备的多周期调度。所提出的模型整合了四种关键控制机制：(i) 用于通过离散分接进行电压调节的有载分接开关（OLTCs）；(ii) 用于无功功率补偿的静止同步补偿器（STATCOMs）和 (iii) 并联电抗器；以及 (iv) 用于可调阻抗和潮流控制的晶闸管控制串联电容器（TCSCs）。目标是在整个定义的时间范围内，使用有限的控制动作最小化有功功率损耗，同时始终满足物理和运行约束。为确保可处理性，模型采用了潮流的二阶锥松弛。设备特定的约束通过二元展开和线性化处理：OLTCs和并联电抗器用离散变量建模，STATCOMs通过无功功率边界建模，TCSCs使用重构-线性化技术（RLT）。多周期公式捕捉了决策的顺序性质，确保了时间步长之间的一致性。该模型在IEEE 9节点、30节点和RTS96测试系统上进行了评估，结果表明其能够减少损耗，并具有应用于更大规模电网的潜力。", "summary": "本文针对电力系统面临的运行挑战，提出了一种基于混合整数二阶锥规划（MISOCP）的多周期调度模型，用于柔性交流输电系统（FACTS）设备。该模型整合了OLTCs、STATCOMs、并联电抗器和TCSCs四种关键FACTS设备，旨在通过有限的控制动作最小化有功功率损耗，同时满足各项运行约束。为提高可处理性，模型采用了潮流的二阶锥松弛以及针对不同设备的二元展开和线性化技术。通过在IEEE标准测试系统上的评估，验证了该模型在减少损耗方面的有效性，并展现了其在大规模电网中的应用潜力。", "keywords": "混合整数二阶锥规划, 柔性交流输电系统, 多周期调度, 有功功率损耗, 潮流松弛", "comments": "该论文的创新点在于提出了一个综合性的MISOCP模型，能够同时调度多种关键FACTS设备，并考虑了多周期决策的顺序性。通过采用二阶锥松弛和特定的线性化技术，解决了模型的计算复杂性问题，使其在实际应用中具有可行性。其对电力系统损耗的有效降低，对于提高电网运行效率和整合可再生能源具有重要意义。"}}
{"id": "2507.13836", "title": "Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems", "authors": ["Laura Weigl", "Ronny Bergmann", "Anton Schiela"], "categories": ["math.NA", "cs.NA", "math.DG", "53-08, 46T05, 58E10, 49Q99"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13836v1", "summary": "We consider the solution of variational equations on manifolds by Newton's\nmethod. These problems can be expressed as root finding problems for mappings\nfrom infinite dimensional manifolds into dual vector bundles. We derive the\ndifferential geometric tools needed for the realization of Newton's method,\nequipped with an affine covariant damping strategy. We apply Newton's method to\na couple of variational problems and show numerical results.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13836v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "牛顿法在向量丛中非线性映射的应用 第二部分：变分问题的应用", "tldr": "本文研究了在流形上使用牛顿法求解变分方程。这些问题被表达为从无限维流形到对偶向量丛的映射的求根问题，并推导了实现牛顿法所需的微分几何工具，并应用于几个变分问题。", "motivation": "在流形上求解变分方程是重要的，本文旨在通过牛顿法解决这些问题。", "method": "本文将变分问题表达为从无限维流形到对偶向量丛的映射的求根问题。研究推导了实现牛顿法所需的微分几何工具，并配备了仿射协变阻尼策略。", "result": "本文将牛顿法应用于多个变分问题，并展示了数值结果。", "conclusion": "本文成功地将牛顿法应用于在流形上的变分问题，并通过数值结果验证了其有效性。", "translation": "我们考虑使用牛顿法在流形上求解变分方程。这些问题可以表达为从无限维流形到对偶向量丛的映射的求根问题。我们推导了实现牛顿法所需的微分几何工具，并配备了仿射协变阻尼策略。我们将牛顿法应用于几个变分问题并展示了数值结果。", "summary": "本文探讨了在流形上使用牛顿法求解变分方程。作者将这些问题转化为无限维流形到对偶向量丛的映射的求根问题，并为此推导了必要的微分几何工具，包括一种仿射协变阻尼策略。文章通过将该方法应用于多个变分问题，展示了其数值结果。", "keywords": "牛顿法, 变分问题, 流形, 向量丛, 微分几何", "comments": "本文的创新点在于将牛顿法应用于流形上的变分问题，并为此开发了专门的微分几何工具和阻尼策略。这对于解决复杂的非线性问题具有重要意义，尤其是在物理和工程等领域。虽然抽象中提到了数值结果，但未详细说明其性能或局限性。"}}
{"id": "2507.13602", "title": "Improving Low-Cost Teleoperation: Augmenting GELLO with Force", "authors": ["Shivakanth Sujit", "Luca Nunziante", "Dan Ogawa Lillrank", "Rousslan Fernand Julien Dossa", "Kai Arulkumaran"], "categories": ["cs.RO", "cs.HC", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Accepted at the 2025 IEEE/SICE International Symposium on System Integration", "url": "http://arxiv.org/abs/2507.13602v1", "summary": "In this work we extend the low-cost GELLO teleoperation system, initially\ndesigned for joint position control, with additional force information. Our\nfirst extension is to implement force feedback, allowing users to feel\nresistance when interacting with the environment. Our second extension is to\nadd force information into the data collection process and training of\nimitation learning models. We validate our additions by implementing these on a\nGELLO system with a Franka Panda arm as the follower robot, performing a user\nstudy, and comparing the performance of policies trained with and without force\ninformation on a range of simulated and real dexterous manipulation tasks.\nQualitatively, users with robotics experience preferred our controller, and the\naddition of force inputs improved task success on the majority of tasks.", "comment": "Accepted at the 2025 IEEE/SICE International Symposium on System\n  Integration", "pdf_url": "http://arxiv.org/pdf/2507.13602v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "改进低成本遥操作：用力增强GELLO系统", "tldr": "通过增加力反馈和力信息进行数据收集及模仿学习，改进了低成本GELLO遥操作系统，提高了任务成功率。", "motivation": "该研究旨在通过增加力信息来扩展低成本的GELLO遥操作系统，以提高其性能和用户体验，因为GELLO最初是为关节位置控制设计的。", "method": "研究人员首先实现了力反馈，让用户在与环境交互时感受到阻力。其次，将力信息添加到数据收集过程和模仿学习模型的训练中。通过在一个带有Franka Panda机械臂作为从动机器人的GELLO系统上实施这些改进，并进行用户研究，比较了有无力信息训练的策略在模拟和真实灵巧操作任务上的表现来验证其有效性。", "result": "定性上，有机器人经验的用户更喜欢他们改进的控制器。此外，力输入的加入提高了大多数任务的成功率。", "conclusion": "通过向GELLO系统添加力反馈和力信息用于模仿学习，可以显著改进低成本遥操作系统的性能和用户体验，提高任务成功率。", "translation": "在这项工作中，我们扩展了最初为关节位置控制设计的低成本GELLO遥操作系统，增加了额外的力信息。我们的第一个扩展是实现力反馈，允许用户在与环境交互时感受到阻力。我们的第二个扩展是将力信息添加到数据收集过程和模仿学习模型的训练中。我们通过在以Franka Panda机械臂作为从动机器人的GELLO系统上实现这些功能，进行用户研究，并比较在模拟和真实灵巧操作任务中，使用和不使用力信息训练的策略的性能来验证我们的添加。定性上，有机器人经验的用户更喜欢我们的控制器，并且力输入的加入提高了大多数任务的成功率。", "summary": "本研究旨在通过整合力反馈和力信息到数据收集与模仿学习中，来增强低成本GELLO遥操作系统。实验在GELLO系统上使用Franka Panda机械臂进行了验证，并进行了用户研究和策略性能比较。结果表明，改进后的系统受到有经验用户的青睐，并且力输入的加入显著提升了多数任务的成功率。", "keywords": "低成本遥操作, 力反馈, 模仿学习, GELLO, 机器人", "comments": "该论文的创新之处在于将力信息集成到低成本遥操作系统（GELLO）中，不仅实现了力反馈，还将其用于模仿学习的数据收集和模型训练。这对于提高低成本遥操作系统的性能和用户体验具有重要意义，尤其是在需要精细操作的任务中。其贡献在于验证了力信息对任务成功率的积极影响，为未来低成本遥操作系统的发展提供了新的方向。"}}
{"id": "2507.13380", "title": "Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition", "authors": ["Keito Inoshita", "Rushia Harada"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13380v1", "summary": "In the field of emotion recognition, the development of high-performance\nmodels remains a challenge due to the scarcity of high-quality, diverse\nemotional datasets. Emotional expressions are inherently subjective, shaped by\nindividual personality traits, socio-cultural backgrounds, and contextual\nfactors, making large-scale, generalizable data collection both ethically and\npractically difficult. To address this issue, we introduce PersonaGen, a novel\nframework for generating emotionally rich text using a Large Language Model\n(LLM) through multi-stage persona-based conditioning. PersonaGen constructs\nlayered virtual personas by combining demographic attributes, socio-cultural\nbackgrounds, and detailed situational contexts, which are then used to guide\nemotion expression generation. We conduct comprehensive evaluations of the\ngenerated synthetic data, assessing semantic diversity through clustering and\ndistributional metrics, human-likeness via LLM-based quality scoring, realism\nthrough comparison with real-world emotion corpora, and practical utility in\ndownstream emotion classification tasks. Experimental results show that\nPersonaGen significantly outperforms baseline methods in generating diverse,\ncoherent, and discriminative emotion expressions, demonstrating its potential\nas a robust alternative for augmenting or replacing real-world emotional\ndatasets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13380v1", "cate": "cs.CL", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "基于多阶段条件作用和大型语言模型的情感识别个性化合成数据生成", "tldr": "为解决情感识别中高质量数据集稀缺问题，本文提出PersonaGen框架，利用LLM通过多阶段个性化条件作用生成情感丰富的合成数据，实验证明其在多样性、连贯性和区分度上优于基线方法，是真实数据集的有效替代。", "motivation": "情感识别领域面临高质量、多样化情感数据集稀缺的挑战，且大规模、通用数据收集存在伦理和实践困难。情感表达具有主观性，受个体特质、社会文化背景和情境因素影响。", "method": "本文提出PersonaGen框架，利用大型语言模型（LLM）通过多阶段个性化条件作用生成情感丰富的文本。PersonaGen通过结合人口统计属性、社会文化背景和详细情境构建分层虚拟角色，以此指导情感表达生成。", "result": "实验结果表明，PersonaGen在生成多样、连贯和具有区分度的情感表达方面显著优于基线方法。评估通过聚类和分布度量评估语义多样性，通过基于LLM的质量评分评估类人度，通过与真实情感语料库比较评估真实性，以及在下游情感分类任务中的实用性。", "conclusion": "PersonaGen框架证明了其作为增强或替代真实世界情感数据集的强大潜力，能够有效解决高质量、多样化情感数据稀缺的问题。", "translation": "在情感识别领域，由于高质量、多样化情感数据集的稀缺，开发高性能模型仍然是一个挑战。情感表达本质上是主观的，受个体人格特质、社会文化背景和情境因素的影响，这使得大规模、通用数据的收集在伦理和实践上都非常困难。为了解决这个问题，我们引入了PersonaGen，这是一个新颖的框架，用于通过大型语言模型（LLM）的多阶段个性化条件作用生成情感丰富的文本。PersonaGen通过结合人口统计属性、社会文化背景和详细情境来构建分层虚拟角色，然后用这些角色来指导情感表达的生成。我们对生成的合成数据进行了全面评估，通过聚类和分布度量评估语义多样性，通过基于LLM的质量评分评估类人度，通过与真实世界情感语料库的比较评估真实性，以及在下游情感分类任务中的实用性。实验结果表明，PersonaGen在生成多样、连贯和具有区分度的情感表达方面显著优于基线方法，展示了其作为增强或替代真实世界情感数据集的强大潜力。", "summary": "本文针对情感识别领域高质量、多样化数据集稀缺的挑战，提出PersonaGen框架。该框架利用大型语言模型，通过结合人口统计、社会文化和情境因素构建多阶段分层虚拟角色，从而生成情感丰富的合成文本。实验评估显示，PersonaGen在生成数据的语义多样性、类人度、真实性以及在情感分类任务中的实用性方面表现出色，显著优于现有基线方法，为弥补真实情感数据不足提供了一种有效且鲁棒的替代方案。", "keywords": "情感识别, 合成数据生成, 大型语言模型, 个性化条件作用, 数据增强", "comments": "该论文的创新点在于提出了一个多阶段个性化条件作用的框架PersonaGen，利用LLM生成情感丰富的合成数据。这对于解决情感识别领域数据稀缺的难题具有重要意义，尤其是在伦理和实践上难以收集大规模真实数据的情况下。其方法通过构建分层虚拟角色，使生成的合成数据更具多样性和真实感，为下游任务提供了高质量的训练资源。这是一个非常有前景的方向，有望加速情感识别模型的发展。"}}
{"id": "2507.14021", "title": "Byzantine-resilient federated online learning for Gaussian process regression", "authors": ["Xu Zhang", "Zhenyuan Yuan", "Minghui Zhu"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14021v1", "summary": "In this paper, we study Byzantine-resilient federated online learning for\nGaussian process regression (GPR). We develop a Byzantine-resilient federated\nGPR algorithm that allows a cloud and a group of agents to collaboratively\nlearn a latent function and improve the learning performances where some agents\nexhibit Byzantine failures, i.e., arbitrary and potentially adversarial\nbehavior. Each agent-based local GPR sends potentially compromised local\npredictions to the cloud, and the cloud-based aggregated GPR computes a global\nmodel by a Byzantine-resilient product of experts aggregation rule. Then the\ncloud broadcasts the current global model to all the agents. Agent-based fused\nGPR refines local predictions by fusing the received global model with that of\nthe agent-based local GPR. Moreover, we quantify the learning accuracy\nimprovements of the agent-based fused GPR over the agent-based local GPR.\nExperiments on a toy example and two medium-scale real-world datasets are\nconducted to demonstrate the performances of the proposed algorithm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14021v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "拜占庭容错联邦在线高斯过程回归学习", "tldr": "提出一种拜占庭容错的联邦高斯过程回归算法，用于在存在恶意代理的情况下协作学习并提高学习性能。", "motivation": "在联邦学习环境中，一些代理可能出现拜占庭故障（即任意和潜在的对抗行为），这会影响学习性能，因此需要一种拜占庭容错的机制来提高学习准确性。", "method": "提出一种拜占庭容错的联邦高斯过程回归（GPR）算法。该算法允许云端和代理协作学习一个潜在函数。每个代理发送本地GPR预测到云端，云端通过拜占庭容错的专家产品聚合规则计算全局模型并广播。代理通过将接收到的全局模型与本地GPR模型融合来细化本地预测。", "result": "实验证明了所提出算法的性能，并量化了代理端融合GPR相对于本地GPR的学习准确性改进。", "conclusion": "所提出的拜占庭容错联邦高斯过程回归算法能够有效地在存在拜占庭故障的情况下提高学习性能和准确性。", "translation": "本文研究了拜占庭容错联邦在线高斯过程回归（GPR）。我们开发了一种拜占庭容错的联邦GPR算法，该算法允许云端和一组代理协作学习一个潜在函数，并在一些代理表现出拜占庭故障（即任意和潜在的对抗行为）时提高学习性能。每个基于代理的本地GPR将可能被破坏的本地预测发送到云端，基于云端的聚合GPR通过拜占庭容错的专家产品聚合规则计算全局模型。然后云端将当前的全局模型广播给所有代理。基于代理的融合GPR通过将接收到的全局模型与基于代理的本地GPR模型融合来细化本地预测。此外，我们量化了基于代理的融合GPR相对于基于代理的本地GPR的学习准确性改进。在玩具示例和两个中等规模的真实世界数据集上进行了实验，以证明所提出算法的性能。", "summary": "本文提出了一种新颖的拜占庭容错联邦在线学习算法，专门用于高斯过程回归。该算法旨在解决联邦学习环境中存在的恶意代理问题。通过结合代理的本地预测和云端的拜占庭容错聚合机制，并允许代理融合全局模型以优化本地预测，该方法显著提高了在存在拜占庭故障情况下的学习准确性。实验结果验证了其有效性。", "keywords": "拜占庭容错, 联邦学习, 高斯过程回归, 在线学习, 专家产品聚合", "comments": "本文的创新点在于将拜占庭容错机制引入到联邦高斯过程回归的在线学习中，特别是在聚合规则和本地模型融合方面。这对于提高联邦学习在不可信环境中的鲁棒性和准确性具有重要意义。该研究为解决实际联邦学习部署中的安全挑战提供了一种有效方案。"}}
{"id": "2507.03733", "title": "Inverse Synthetic Aperture Fourier Ptychography", "authors": ["Matthew A. Chan", "Casey J. Pellizzari", "Christopher A. Metzler"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.03733v2", "summary": "Fourier ptychography (FP) is a powerful light-based synthetic aperture\nimaging technique that allows one to reconstruct a high-resolution, wide\nfield-of-view image by computationally integrating a diverse collection of\nlow-resolution, far-field measurements. Typically, FP measurement diversity is\nintroduced by changing the angle of the illumination or the position of the\ncamera; either approach results in sampling different portions of the target's\nspatial frequency content, but both approaches introduce substantial costs and\ncomplexity to the acquisition process. In this work, we introduce Inverse\nSynthetic Aperture Fourier Ptychography, a novel approach to FP that foregoes\nchanging the illumination angle or camera position and instead generates\nmeasurement diversity through target motion. Critically, we also introduce a\nnovel learning-based method for estimating k-space coordinates from dual plane\nintensity measurements, thereby enabling synthetic aperture imaging without\nknowing the rotation of the target. We experimentally validate our method in\nsimulation and on a tabletop optical system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.03733v2", "cate": "eess.IV", "date": "2025-07-04", "updated": "2025-07-17", "AI": {"title_translation": "逆合成孔径傅里叶叠层成像", "tldr": "提出一种新的傅里叶叠层成像方法 (ISAFP)，通过目标运动而非照明/相机移动来获取测量多样性，并使用基于学习的方法估计k空间坐标，无需已知目标旋转。", "motivation": "传统的傅里叶叠层成像 (FP) 通过改变照明角度或相机位置来引入测量多样性，但这两种方法都会大大增加采集过程的成本和复杂性。", "method": "引入了逆合成孔径傅里叶叠层成像 (ISAFP) 方法，该方法通过目标运动而非改变照明角度或相机位置来生成测量多样性。此外，还引入了一种新的基于学习的方法，用于从双平面强度测量中估计k空间坐标，从而在不知道目标旋转的情况下实现合成孔径成像。", "result": "该方法在仿真和桌面光学系统上进行了实验验证。", "conclusion": "Not mentioned in abstract", "translation": "傅里叶叠层成像（FP）是一种强大的基于光的合成孔径成像技术，它通过计算整合各种低分辨率、远场测量结果，以重建高分辨率、宽视场图像。通常，FP测量多样性是通过改变照明角度或相机位置引入的；这两种方法都会对目标的空间频率内容进行不同部分的采样，但都会给采集过程带来巨大的成本和复杂性。在这项工作中，我们引入了逆合成孔径傅里叶叠层成像，这是一种新颖的FP方法，它放弃了改变照明角度或相机位置，而是通过目标运动来生成测量多样性。关键的是，我们还引入了一种新的基于学习的方法，用于从双平面强度测量中估计k空间坐标，从而在不知道目标旋转的情况下实现合成孔径成像。我们在仿真和桌面光学系统上实验验证了我们的方法。", "summary": "本文提出一种名为逆合成孔径傅里叶叠层成像 (ISAFP) 的新颖傅里叶叠层成像技术，旨在解决传统FP方法中因改变照明或相机位置而导致的成本和复杂性问题。ISAFP通过利用目标自身的运动来生成测量多样性，而非依赖外部设备调整。此外，该研究还引入了一种创新的基于学习的方法，能够从双平面强度测量中估计k空间坐标，从而在无需预先了解目标旋转的情况下实现合成孔径成像。该方法已通过仿真和桌面光学系统进行了实验验证。", "keywords": "傅里叶叠层成像, 合成孔径, 目标运动, 学习方法, k空间估计", "comments": "这项工作通过引入目标运动来替代传统的照明或相机位置改变，显著简化了傅里叶叠层成像的采集过程，降低了成本和复杂性。其创新之处还在于提出了一种基于学习的k空间坐标估计方法，解决了目标旋转未知时的成像挑战，这对于实际应用具有重要意义。"}}
{"id": "2505.14523", "title": "Exploring Graph Representations of Logical Forms for Language Modeling", "authors": ["Michael Sullivan"], "categories": ["cs.CL", "cs.AI", "I.2.7"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To be published in ACL 2025 Findings", "url": "http://arxiv.org/abs/2505.14523v2", "summary": "We make the case for language models over logical forms (LFLMs), arguing that\nsuch models are more data-efficient than their textual counterparts. To that\nend, we introduce the Graph-based Formal-Logical Distributional Semantics\n(GFoLDS) prototype, a pretrained LM over graph representations of logical\nforms, as a proof-of-concept of LFLMs. Using GFoLDS, we present strong\nexperimental evidence that LFLMs can leverage the built-in, basic linguistic\nknowledge inherent in such models to immediately begin learning more complex\npatterns. On downstream tasks, we show that GFoLDS vastly outperforms textual,\ntransformer LMs (BERT) pretrained on the same data, indicating that LFLMs can\nlearn with substantially less data than models over plain text. Furthermore, we\nshow that the performance of this model is likely to scale with additional\nparameters and pretraining data, suggesting the viability of LFLMs in\nreal-world applications.", "comment": "To be published in ACL 2025 Findings", "pdf_url": "http://arxiv.org/pdf/2505.14523v2", "cate": "cs.CL", "date": "2025-05-20", "updated": "2025-07-18", "AI": {"title_translation": "探索逻辑形式图表示在语言建模中的应用", "tldr": "论文提出了基于逻辑形式的语言模型（LFLMs），并用原型GFoLDS证明其比文本语言模型更数据高效，且在下游任务中表现更优。", "motivation": "论证基于逻辑形式的语言模型（LFLMs）比基于文本的语言模型更数据高效，且能利用内置语言知识学习复杂模式。", "method": "引入了Graph-based Formal-Logical Distributional Semantics (GFoLDS) 原型，这是一个在逻辑形式图表示上预训练的语言模型，作为LFLMs的概念验证。", "result": "实验证明LFLMs能立即开始学习更复杂的模式。在下游任务中，GFoLDS在相同数据上预训练时，显著优于基于文本的Transformer语言模型（BERT），表明LFLMs可以用更少的数据进行学习。此外，模型性能可能随参数和预训练数据的增加而扩展。", "conclusion": "LFLMs具有在实际应用中学习更复杂模式和扩展的潜力，并且比基于文本的模型更数据高效。", "translation": "我们提出了基于逻辑形式的语言模型（LFLMs），并认为此类模型比其文本对应物更具数据效率。为此，我们引入了基于图的正式逻辑分布语义（GFoLDS）原型，这是一个在逻辑形式图表示上预训练的语言模型，作为LFLMs的概念验证。利用GFoLDS，我们提供了有力的实验证据，表明LFLMs可以利用此类模型固有的内置基本语言知识，立即开始学习更复杂的模式。在下游任务中，我们表明GFoLDS在相同数据上预训练时，大大优于文本Transformer语言模型（BERT），这表明LFLMs可以用比纯文本模型少得多的数据进行学习。此外，我们表明该模型的性能可能会随附加参数和预训练数据的增加而扩展，这表明LFLMs在实际应用中的可行性。", "summary": "本文提出了基于逻辑形式的语言模型（LFLMs），认为其比传统文本语言模型更数据高效。通过引入原型GFoLDS，一个在逻辑形式图表示上预训练的语言模型，作者证明了LFLMs能够利用内置语言知识有效学习，并在下游任务中显著超越了在相同数据上预训练的BERT模型，表明其在数据效率上的优势。研究还指出LFLMs的性能有潜力随规模扩展，预示了其在实际应用中的前景。", "keywords": "逻辑形式, 语言模型, 图表示, 数据效率, GFoLDS", "comments": "这篇论文的创新点在于提出了基于逻辑形式的语言模型（LFLMs），并使用图表示来捕获逻辑形式的结构信息。其重要性在于证明了LFLMs在数据效率上优于传统的文本语言模型（如BERT），这对于数据稀缺或需要快速学习的场景具有重要意义。通过利用逻辑形式中固有的语言知识，模型能够更有效地学习复杂模式，这为未来的语言模型研究提供了新的方向。"}}
{"id": "2507.13550", "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models", "authors": ["Eduardo C. Garrido-Merchán", "Cristina Puente"], "categories": ["cs.AI", "cs.CL", "cs.SC"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13550v1", "summary": "The development of large language models (LLMs) has successfully transformed\nknowledge-based systems such as open domain question nswering, which can\nautomatically produce vast amounts of seemingly coherent information. Yet,\nthose models have several disadvantages like hallucinations or confident\ngeneration of incorrect or unverifiable facts. In this paper, we introduce a\nnew approach to the development of expert systems using LLMs in a controlled\nand transparent way. By limiting the domain and employing a well-structured\nprompt-based extraction approach, we produce a symbolic representation of\nknowledge in Prolog, which can be validated and corrected by human experts.\nThis approach also guarantees interpretability, scalability and reliability of\nthe developed expert systems. Via quantitative and qualitative experiments with\nClaude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic\ncoherence on our generated knowledge bases. We present a transparent hybrid\nsolution that combines the recall capacity of LLMs with the precision of\nsymbolic systems, thereby laying the foundation for dependable AI applications\nin sensitive domains.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13550v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "GOFAI 遇见生成式AI：通过大型语言模型开发专家系统", "tldr": "论文提出一种结合LLM和符号系统的新方法，以可控和透明的方式开发专家系统，解决LLM幻觉问题，并保证可靠性。", "motivation": "大型语言模型（LLM）虽然能自动生成大量看似连贯的信息，但存在幻觉或自信地生成不正确或不可验证事实的缺点，因此需要一种受控且透明的方式来开发专家系统。", "method": "本文引入了一种新方法，通过限制领域并采用结构化提示词提取方法，将知识生成为Prolog的符号表示，该表示可以由人类专家验证和纠正。这种方法还保证了所开发的专家系统的可解释性、可扩展性和可靠性。", "result": "通过对Claude Sonnet 3.7和GPT-4.1进行的定量和定性实验表明，生成的知识库对事实有很强的依从性，并具有语义一致性。", "conclusion": "该方法提供了一种透明的混合解决方案，结合了LLM的召回能力和符号系统的精确性，从而为敏感领域中可靠的AI应用奠定了基础。", "translation": "大型语言模型（LLM）的发展成功地改变了基于知识的系统，例如开放域问答，这些系统可以自动生成大量看似连贯的信息。然而，这些模型存在一些缺点，例如幻觉或自信地生成不正确或不可验证的事实。在本文中，我们介绍了一种以受控和透明的方式使用LLM开发专家系统的新方法。通过限制领域并采用结构化提示词提取方法，我们生成了Prolog中的知识符号表示，该表示可以由人类专家验证和纠正。这种方法还保证了所开发的专家系统的可解释性、可扩展性和可靠性。通过对Claude Sonnet 3.7和GPT-4.1进行的定量和定性实验，我们展示了我们生成的知识库对事实的强烈依从性和语义一致性。我们提出了一种透明的混合解决方案，结合了LLM的召回能力和符号系统的精确性，从而为敏感领域中可靠的AI应用奠定了基础。", "summary": "本文提出一种将大型语言模型（LLM）与符号系统结合的新方法，以解决LLM的幻觉和不可靠性问题，用于开发可控、透明且可靠的专家系统。该方法通过限制领域和结构化提示词提取，将知识转化为Prolog符号表示，并可由人类专家验证。实验证明，该方法生成的知识库具有高事实依从性和语义一致性，为敏感领域的AI应用提供了可靠基础。", "keywords": "大型语言模型, 专家系统, 符号AI, 知识表示, 可靠AI", "comments": "该论文创新性地结合了GOFAI（符号AI）的精确性和可解释性与生成式AI（LLM）的召回能力，有效解决了当前LLM在事实准确性和可靠性方面的痛点。其提出的混合方法为开发敏感领域中可信赖的AI应用提供了新的范式，具有重要的实践意义。"}}
{"id": "2507.13685", "title": "Kolmogorov-Arnold Networks-based GRU and LSTM for Loan Default Early Prediction", "authors": ["Yue Yang", "Zihan Su", "Ying Zhang", "Chang Chuan Goh", "Yuxiang Lin", "Anthony Graham Bellotti", "Boon Giin Lee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13685v1", "summary": "This study addresses a critical challenge in time series anomaly detection:\nenhancing the predictive capability of loan default models more than three\nmonths in advance to enable early identification of default events, helping\nfinancial institutions implement preventive measures before risk events\nmaterialize. Existing methods have significant drawbacks, such as their lack of\naccuracy in early predictions and their dependence on training and testing\nwithin the same year and specific time frames. These issues limit their\npractical use, particularly with out-of-time data. To address these, the study\nintroduces two innovative architectures, GRU-KAN and LSTM-KAN, which merge\nKolmogorov-Arnold Networks (KAN) with Gated Recurrent Units (GRU) and Long\nShort-Term Memory (LSTM) networks. The proposed models were evaluated against\nthe baseline models (LSTM, GRU, LSTM-Attention, and LSTM-Transformer) in terms\nof accuracy, precision, recall, F1 and AUC in different lengths of feature\nwindow, sample sizes, and early prediction intervals. The results demonstrate\nthat the proposed model achieves a prediction accuracy of over 92% three months\nin advance and over 88% eight months in advance, significantly outperforming\nexisting baselines.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13685v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于科尔莫哥洛夫-阿诺德网络（KAN）的GRU和LSTM用于贷款违约早期预测", "tldr": "本研究提出了GRUKAN和LSTM-KAN两种新模型，将KAN与GRU和LSTM结合，显著提高了贷款违约的早期预测准确性，在提前3个月和8个月的预测中分别达到92%和88%以上的准确率，优于现有基线模型。", "motivation": "现有贷款违约预测模型在提前预测准确性方面存在不足，且依赖于特定时间范围内的训练和测试数据，限制了其在时间序列异常检测和处理跨期数据时的实用性。本研究旨在提升贷款违约模型在超过三个月前的预测能力，以实现早期识别，帮助金融机构采取预防措施。", "method": "本研究提出了两种创新架构：GRU-KAN和LSTM-KAN，它们将科尔莫哥洛夫-阿诺德网络（KAN）与门控循环单元（GRU）和长短期记忆（LSTM）网络融合。这些模型在不同特征窗口长度、样本量和早期预测间隔下，通过准确率、精确率、召回率、F1分数和AUC等指标，与基线模型（LSTM、GRU、LSTM-Attention和LSTM-Transformer）进行了评估。", "result": "所提出的模型在提前三个月预测时达到了92%以上的准确率，在提前八个月预测时也达到了88%以上的准确率，显著优于现有基线模型。", "conclusion": "基于科尔莫哥洛夫-阿诺德网络（KAN）的GRU和LSTM模型（GRU-KAN和LSTM-KAN）能够有效提高贷款违约的早期预测能力，克服了现有方法的局限性，为金融机构提供了更可靠的风险预警工具。", "translation": "本研究解决了时间序列异常检测中的一个关键挑战：将贷款违约模型的预测能力提前三个月以上，以实现对违约事件的早期识别，帮助金融机构在风险事件发生前实施预防措施。现有方法存在显著缺点，例如早期预测准确性不足，以及依赖于同年和特定时间范围内的训练和测试。这些问题限制了它们的实际应用，特别是在处理跨期数据时。为了解决这些问题，本研究引入了两种创新架构：GRU-KAN和LSTM-KAN，它们将科尔莫哥洛夫-阿诺德网络（KAN）与门控循环单元（GRU）和长短期记忆（LSTM）网络融合。所提出的模型在不同特征窗口长度、样本量和早期预测间隔下，通过准确率、精确率、召回率、F1分数和AUC等指标，与基线模型（LSTM、GRU、LSTM-Attention和LSTM-Transformer）进行了评估。结果表明，所提出的模型在提前三个月预测时达到了92%以上的准确率，在提前八个月预测时也达到了88%以上的准确率，显著优于现有基线模型。", "summary": "本研究旨在提升贷款违约的早期预测能力，以应对现有模型在准确性和跨期数据处理上的局限。为此，论文提出了两种新颖的混合架构：GRU-KAN和LSTM-KAN，它们将科尔莫哥洛夫-阿诺德网络（KAN）与传统的GRU和LSTM网络结合。实验结果显示，这些新模型在提前三个月和八个月的预测中表现出色，准确率分别超过92%和88%，显著优于现有基线模型，证明了其在金融风险管理中的潜力。", "keywords": "贷款违约预测, 科尔莫哥洛夫-阿诺德网络, GRU, LSTM, 时间序列异常检测", "comments": "本研究的创新点在于将新兴的科尔莫哥洛夫-阿诺德网络（KAN）与成熟的循环神经网络（GRU和LSTM）结合，为时间序列异常检测，特别是贷款违约的早期预测，提供了一种新颖且有效的解决方案。其重要性体现在显著提升了提前数月的预测准确率，这对于金融机构提前采取预防措施具有重大实践意义。论文通过全面的评估指标和不同条件下的测试，验证了模型的鲁棒性和优越性。"}}
{"id": "2507.13693", "title": "Gaussian kernel-based motion measurement", "authors": ["Hongyi Liu", "Haifeng Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13693v1", "summary": "The growing demand for structural health monitoring has driven increasing\ninterest in high-precision motion measurement, as structural information\nderived from extracted motions can effectively reflect the current condition of\nthe structure. Among various motion measurement techniques, vision-based\nmethods stand out due to their low cost, easy installation, and large-scale\nmeasurement. However, when it comes to sub-pixel-level motion measurement,\ncurrent vision-based methods either lack sufficient accuracy or require\nextensive manual parameter tuning (e.g., pyramid layers, target pixels, and\nfilter parameters) to reach good precision. To address this issue, we developed\na novel Gaussian kernel-based motion measurement method, which can extract the\nmotion between different frames via tracking the location of Gaussian kernels.\nThe motion consistency, which fits practical structural conditions, and a\nsuper-resolution constraint, are introduced to increase accuracy and robustness\nof our method. Numerical and experimental validations show that it can\nconsistently reach high accuracy without customized parameter setup for\ndifferent test samples.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13693v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于高斯核的运动测量", "tldr": "提出了一种基于高斯核的高精度亚像素运动测量方法，无需大量参数调优即可实现准确和鲁棒的测量。", "motivation": "结构健康监测对高精度运动测量的需求日益增长。现有的基于视觉的亚像素运动测量方法要么精度不足，要么需要大量手动参数调优。", "method": "开发了一种新颖的基于高斯核的运动测量方法。通过跟踪高斯核在不同帧之间的位置来提取运动。引入了符合实际结构条件的运动一致性以及超分辨率约束，以提高方法的准确性和鲁棒性。", "result": "数值和实验验证表明，该方法能够持续达到高精度，且无需为不同的测试样本进行定制参数设置。", "conclusion": "所提出的基于高斯核的运动测量方法在亚像素运动测量中具有高精度和鲁棒性，且无需大量的参数调优，适用于结构健康监测应用。", "translation": "结构健康监测日益增长的需求推动了对高精度运动测量的兴趣，因为从提取的运动中获得的结构信息可以有效地反映结构的当前状况。在各种运动测量技术中，基于视觉的方法因其低成本、易于安装和大规模测量而脱颖而出。然而，在亚像素级运动测量方面，当前的基于视觉的方法要么缺乏足够的精度，要么需要大量的手动参数调优（例如，金字塔层、目标像素和滤波器参数）才能达到良好的精度。为了解决这个问题，我们开发了一种新颖的基于高斯核的运动测量方法，该方法可以通过跟踪高斯核的位置来提取不同帧之间的运动。引入了符合实际结构条件的运动一致性和超分辨率约束，以提高我们方法的准确性和鲁棒性。数值和实验验证表明，它能够持续达到高精度，且无需为不同的测试样本进行定制参数设置。", "summary": "本文旨在解决当前基于视觉的亚像素运动测量方法精度不足或需要大量参数调优的问题。作者提出了一种新颖的基于高斯核的运动测量方法，通过跟踪高斯核的位置来提取运动。该方法通过引入运动一致性和超分辨率约束，提高了准确性和鲁棒性。数值和实验验证表明，该方法能够持续达到高精度，且无需定制参数设置，适用于结构健康监测。", "keywords": "高斯核, 运动测量, 亚像素, 视觉方法, 结构健康监测", "comments": "该方法的创新之处在于利用高斯核进行运动跟踪，并结合运动一致性和超分辨率约束来克服基于视觉方法常见的局限性。其主要优势在于无需大量手动参数调优即可实现高精度，这对于结构健康监测应用来说是一个重要的实际改进。"}}
{"id": "2412.11392", "title": "A lightweight and robust method for blind wideband-to-fullband extension of speech", "authors": ["Jan Büthe", "Jean-Marc Valin"], "categories": ["eess.AS", "cs.SD"], "primary_category": "Subjects:       Audio and Speech Processing (eess.AS)", "pdf_link": null, "comments": "Comments:      WASPAA 2025, 5 pages", "url": "http://arxiv.org/abs/2412.11392v4", "summary": "Reducing the bandwidth of speech is common practice in resource constrained\nenvironments like low-bandwidth speech transmission or low-complexity vocoding.\nWe propose a lightweight and robust method for extending the bandwidth of\nwideband speech signals that is inspired by classical methods developed in the\nspeech coding context. The resulting model has just ~370K parameters and a\ncomplexity of ~140 MFLOPS (or ~70 MMACS). With a frame size of 10 ms and a\nlookahead of only 0.27 ms, the model is well-suited for use with common\nwideband speech codecs. We evaluate the model's robustness by pairing it with\nthe Opus SILK speech codec (1.5 release) and verify in a P.808 DCR listening\ntest that it significantly improves quality from 6 to 12 kb/s. We also\ndemonstrate that Opus 1.5 together with the proposed bandwidth extension at 9\nkb/s meets the quality of 3GPP EVS at 9.6 kb/s and that of Opus 1.4 at 18 kb/s\nshowing that the blind bandwidth extension can meet the quality of classical\nguided bandwidth extensions thus providing a way for backward-compatible\nquality improvement.", "comment": "WASPAA 2025, 5 pages", "pdf_url": "http://arxiv.org/pdf/2412.11392v4", "cate": "eess.AS", "date": "2024-12-16", "updated": "2025-07-18", "AI": {"title_translation": "一种轻量级且鲁棒的语音盲宽带到全带扩展方法", "tldr": "该论文提出了一种轻量级且鲁棒的语音盲宽带到全带扩展方法，其参数少、复杂度低，能显著提升低比特率下的语音质量，并达到传统有引导带宽扩展的水平，实现向后兼容的质量提升。", "motivation": "在资源受限的环境中（如低带宽语音传输或低复杂度声码器），语音带宽的缩减是常见做法。本文旨在解决如何在这些环境下，通过扩展宽带语音信号的带宽来提升语音质量。", "method": "本文提出了一种受经典语音编码方法启发的轻量级且鲁棒的宽带语音信号带宽扩展方法。该模型仅有约370K参数和约140 MFLOPS（或约70 MMACS）的复杂度。它采用10毫秒的帧大小和仅0.27毫秒的前瞻，非常适合与常见的宽带语音编解码器配合使用。", "result": "通过与Opus SILK语音编解码器（1.5版）配对评估，该方法在P.808 DCR听力测试中显著将语音质量从6 kb/s提升到12 kb/s。此外，Opus 1.5结合所提出的带宽扩展在9 kb/s时，其质量能达到3GPP EVS在9.6 kb/s以及Opus 1.4在18 kb/s时的质量水平。", "conclusion": "研究表明，所提出的盲带宽扩展方法可以达到经典有引导带宽扩展的质量水平，从而为实现向后兼容的质量改进提供了一种途径。", "translation": "降低语音带宽在资源受限的环境中很常见，例如低带宽语音传输或低复杂度声码。我们提出了一种轻量级且鲁棒的宽带语音信号带宽扩展方法，该方法受语音编码背景下开发的经典方法启发。所得模型仅有约370K参数和约140 MFLOPS（或约70 MMACS）的复杂度。凭借10毫秒的帧大小和仅0.27毫秒的前瞻，该模型非常适合与常见的宽带语音编解码器配合使用。我们通过将其与Opus SILK语音编解码器（1.5版）配对来评估模型的鲁棒性，并在P.808 DCR听力测试中验证其显著提高了6到12 kb/s的质量。我们还证明，Opus 1.5结合所提出的带宽扩展在9 kb/s时，其质量达到了3GPP EVS在9.6 kb/s以及Opus 1.4在18 kb/s时的质量，表明盲带宽扩展可以达到经典有引导带宽扩展的质量，从而提供了一种向后兼容的质量改进方式。", "summary": "该论文提出了一种轻量级且鲁棒的语音盲宽带到全带扩展方法，旨在改善资源受限环境下语音的质量。该模型参数少、复杂度低，易于与现有宽带语音编解码器集成。实验结果表明，该方法能显著提升低比特率下的语音质量，并能使Opus编解码器在较低码率下达到或超越其他高码率编解码器的质量，证明了盲带宽扩展可媲美有引导带宽扩展，为向后兼容的质量提升提供了可能。", "keywords": "语音带宽扩展, 盲扩展, 轻量级, 鲁棒性, 语音编码", "comments": "该论文的创新点在于提出了一种轻量级且鲁棒的盲带宽扩展方法，其在参数量和计算复杂度上都表现出色，使其易于部署。其重要性体现在实现了在低比特率下显著提升语音质量，并能够达到传统有引导带宽扩展的性能，同时保持向后兼容性，这对于现有语音通信系统具有巨大的应用潜力。"}}
{"id": "2504.12075", "title": "Generative Deep Learning Framework for Inverse Design of Fuels", "authors": ["Kiran K. Yalamanchi", "Pinaki Pal", "Balaji Mohan", "Abdullah S. AlRamadan", "Jihad A. Badra", "Yuanjiang Pei"], "categories": ["cs.LG", "physics.chem-ph"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2504.12075v2", "summary": "In the present work, a generative deep learning framework combining a\nCo-optimized Variational Autoencoder (Co-VAE) architecture with quantitative\nstructure-property relationship (QSPR) techniques is developed to enable\naccelerated inverse design of fuels. The Co-VAE integrates a property\nprediction component coupled with the VAE latent space, enhancing molecular\nreconstruction and accurate estimation of Research Octane Number (RON) (chosen\nas the fuel property of interest). A subset of the GDB-13 database, enriched\nwith a curated RON database, is used for model training. Hyperparameter tuning\nis further utilized to optimize the balance among reconstruction fidelity,\nchemical validity, and RON prediction. An independent regression model is then\nused to refine RON prediction, while a differential evolution algorithm is\nemployed to efficiently navigate the VAE latent space and identify promising\nfuel molecule candidates with high RON. This methodology addresses the\nlimitations of traditional fuel screening approaches by capturing complex\nstructure-property relationships within a comprehensive latent representation.\nThe generative model can be adapted to different target properties, enabling\nsystematic exploration of large chemical spaces relevant to fuel design\napplications. Furthermore, the demonstrated framework can be readily extended\nby incorporating additional synthesizability criteria to improve applicability\nand reliability for de novo design of new fuels.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2504.12075v2", "cate": "cs.LG", "date": "2025-04-16", "updated": "2025-07-17", "AI": {"title_translation": "用于燃料逆向设计的生成式深度学习框架", "tldr": "本研究开发了一个结合Co-VAE架构和QSPR技术的生成式深度学习框架，旨在加速燃料的逆向设计，克服传统筛选方法的局限性，并通过优化和搜索识别高辛烷值燃料分子。", "motivation": "传统燃料筛选方法存在局限性，难以捕捉复杂的结构-性质关系。本研究旨在通过开发一种新的生成式深度学习框架来克服这些限制，从而加速燃料的逆向设计。", "method": "本研究开发了一个结合Co-optimized Variational Autoencoder (Co-VAE) 架构和定量结构-性质关系 (QSPR) 技术的生成式深度学习框架。Co-VAE集成了与VAE潜在空间耦合的性质预测组件，增强了分子重建和RON（研究辛烷值）的准确估计。模型使用经过RON数据库丰富GDB-13数据库子集进行训练。通过超参数调整优化重建保真度、化学有效性和RON预测之间的平衡。使用独立的回归模型精炼RON预测，并采用差分进化算法有效导航VAE潜在空间以识别高RON的燃料分子候选。", "result": "该方法通过在全面的潜在表示中捕获复杂的结构-性质关系，解决了传统燃料筛选方法的局限性。所开发的生成模型能够适应不同的目标性质，从而系统地探索与燃料设计应用相关的大型化学空间。", "conclusion": "本研究展示的生成式深度学习框架能够加速燃料的逆向设计，克服传统方法的局限性，并通过捕获复杂的结构-性质关系来有效识别高辛烷值燃料分子。该框架具有良好的可扩展性，可适应不同的目标性质，并可进一步纳入可合成性标准以提高新燃料设计的适用性和可靠性。", "translation": "在目前的工作中，开发了一个结合了协同优化变分自编码器（Co-VAE）架构和定量结构-性质关系（QSPR）技术的生成式深度学习框架，以实现燃料的加速逆向设计。Co-VAE集成了与VAE潜在空间耦合的性质预测组件，增强了分子重建和研究辛烷值（RON，选作感兴趣的燃料性质）的准确估计。使用经过精选RON数据库丰富GDB-13数据库子集进行模型训练。进一步利用超参数调整来优化重建保真度、化学有效性和RON预测之间的平衡。然后使用独立的回归模型来精炼RON预测，同时采用差分进化算法有效地导航VAE潜在空间并识别具有高RON的有前景的燃料分子候选。该方法通过在全面的潜在表示中捕获复杂的结构-性质关系，解决了传统燃料筛选方法的局限性。该生成模型可以适应不同的目标性质，从而能够系统地探索与燃料设计应用相关的大型化学空间。此外，所展示的框架可以通过纳入额外的可合成性标准来轻松扩展，以提高新燃料从头设计的适用性和可靠性。", "summary": "本研究提出了一种结合协同优化变分自编码器（Co-VAE）和定量结构-性质关系（QSPR）的生成式深度学习框架，用于加速燃料的逆向设计。该框架通过整合性质预测组件到VAE潜在空间，提高了分子重建和研究辛烷值（RON）的预测精度。模型使用GDB-13数据库的子集进行训练，并通过超参数调整优化。此外，结合独立的回归模型和差分进化算法，有效地在潜在空间中搜索高RON的燃料分子。该方法克服了传统燃料筛选的局限性，能够捕获复杂的结构-性质关系，并可扩展应用于其他目标性质和纳入可合成性标准，以提高新燃料设计的效率和可靠性。", "keywords": "生成式深度学习, 逆向设计, 变分自编码器, 燃料, 辛烷值", "comments": "该论文的创新点在于将Co-VAE架构与QSPR技术相结合，为燃料的逆向设计提供了一个高效的生成式深度学习框架。通过在潜在空间中集成性质预测并结合差分进化算法进行搜索，有效地解决了传统方法在处理复杂结构-性质关系上的局限性。其重要性体现在能够加速新燃料的发现和设计，并具有良好的可扩展性，可应用于其他化学性质和纳入可合成性约束，这对于实际应用至关重要。"}}
{"id": "2505.01454", "title": "Sparsification Under Siege: Defending Against Poisoning Attacks in Communication-Efficient Federated Learning", "authors": ["Zhiyong Jin", "Runhua Xu", "Chao Li", "Yizhong Liu", "Jianxin Li"], "categories": ["cs.CR", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.01454v3", "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients while preserving data privacy, yet it faces significant\nchallenges in communication efficiency and vulnerability to poisoning attacks.\nWhile sparsification techniques mitigate communication overhead by transmitting\nonly critical model parameters, they inadvertently amplify security risks:\nadversarial clients can exploit sparse updates to evade detection and degrade\nmodel performance. Existing defense mechanisms, designed for standard FL\ncommunication scenarios, are ineffective in addressing these vulnerabilities\nwithin sparsified FL. To bridge this gap, we propose FLARE, a novel federated\nlearning framework that integrates sparse index mask inspection and model\nupdate sign similarity analysis to detect and mitigate poisoning attacks in\nsparsified FL. Extensive experiments across multiple datasets and adversarial\nscenarios demonstrate that FLARE significantly outperforms existing defense\nstrategies, effectively securing sparsified FL against poisoning attacks while\nmaintaining communication efficiency.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.01454v3", "cate": "cs.CR", "date": "2025-04-30", "updated": "2025-07-18", "AI": {"title_translation": "稀疏化受困：防御通信高效联邦学习中的投毒攻击", "tldr": "提出了FLARE框架，通过稀疏索引掩码检查和模型更新符号相似性分析，有效防御稀疏化联邦学习中的投毒攻击。", "motivation": "联邦学习中的稀疏化技术在提高通信效率的同时，意外地增加了安全风险，使得现有防御机制对稀疏化FL中的投毒攻击无效。", "method": "提出了FLARE框架，该框架集成了稀疏索引掩码检查和模型更新符号相似性分析，用于检测和缓解稀疏化FL中的投毒攻击。", "result": "在多个数据集和对抗场景下的广泛实验表明，FLARE显著优于现有防御策略，有效保护了稀疏化FL免受投毒攻击，同时保持了通信效率。", "conclusion": "FLARE成功解决了稀疏化联邦学习中投毒攻击的防御问题，实现了安全与效率的平衡。", "translation": "联邦学习（FL）实现了分布式客户端之间的协作模型训练，同时保护了数据隐私，但它在通信效率和抵御投毒攻击方面面临重大挑战。虽然稀疏化技术通过仅传输关键模型参数来减轻通信开销，但它们无意中放大了安全风险：对抗性客户端可以利用稀疏更新来逃避检测并降低模型性能。为标准FL通信场景设计的现有防御机制在解决稀疏化FL中的这些漏洞方面是无效的。为了弥补这一差距，我们提出了FLARE，一个新颖的联邦学习框架，它集成了稀疏索引掩码检查和模型更新符号相似性分析，以检测和缓解稀疏化FL中的投毒攻击。在多个数据集和对抗场景下进行的广泛实验表明，FLARE显著优于现有防御策略，有效保护了稀疏化FL免受投毒攻击，同时保持了通信效率。", "summary": "本文提出了FLARE框架，旨在解决通信高效联邦学习中稀疏化技术所带来的投毒攻击漏洞。FLARE通过稀疏索引掩码检查和模型更新符号相似性分析来检测和缓解此类攻击。实验证明，FLARE在多个场景下表现优于现有防御机制，能在保证通信效率的同时有效抵御投毒攻击。", "keywords": "联邦学习, 稀疏化, 投毒攻击, 安全, 通信效率", "comments": "本文创新性地解决了稀疏化联邦学习中投毒攻击的难题，填补了现有防御机制的空白。FLARE通过结合两种新颖的分析方法，在保持通信效率的同时显著提升了稀疏化FL的安全性，对于推动联邦学习的实际应用具有重要意义。"}}
{"id": "2504.16373", "title": "What Sensors See, What People Feel: Exploring Subjective Collaboration Perception in Mixed Reality", "authors": ["Yasra Chandio", "Diana Romero", "Salma Elmalaki", "Fatima Anwar"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      12 pages, 4 figures, 8 tables. arXiv admin note: text overlap with arXiv:2411.05258", "url": "http://arxiv.org/abs/2504.16373v2", "summary": "Mixed Reality (MR) enables rich, embodied collaboration, yet it's uncertain\nif sensor and system-logged behavioral signals capture how users experience\nthat collaboration. This disconnect stems from a fundamental gap: behavioral\nsignals are observable and continuous, while collaboration is interpreted\nsubjectively, shaped by internal states like presence, cognitive availability,\nand social awareness. Our core insight is that sensor signals serve as\nobservable manifestations of subjective experiences in MR collaboration, and\nthey can be captured through sensor data such as shared gaze, speech, spatial\nmovement, and other system-logged performance metrics. We propose the\nSensor-to-Subjective (S2S) Mapping Framework, a conceptual model that links\nobservable interaction patterns to users' subjective perceptions of\ncollaboration and internal cognitive states through sensor-based indicators and\ntask performance metrics. To validate this model, we conducted a study with 48\nparticipants across 12 MR groups engaged in a collaborative image-sorting task.\nOur findings show a correlation between sensed behavior and perceived\ncollaboration, particularly through shared attention and proximity.", "comment": "12 pages, 4 figures, 8 tables. arXiv admin note: text overlap with\n  arXiv:2411.05258", "pdf_url": "http://arxiv.org/pdf/2504.16373v2", "cate": "cs.HC", "date": "2025-04-23", "updated": "2025-07-17", "AI": {"title_translation": "传感器看到了什么，人们感受到了什么：探索混合现实中主观协作感知", "tldr": "本研究探讨了混合现实中传感器数据与用户主观协作感知之间的关系，并提出了S2S映射框架，通过实验验证了感知行为与协作感知之间的关联。", "motivation": "混合现实（MR）支持丰富的具身协作，但传感器和系统记录的行为信号是否能捕捉用户体验到的协作方式尚不确定。这种脱节源于一个根本性的差距：行为信号是可观察和连续的，而协作是主观解释的，受存在感、认知可用性和社会意识等内部状态的影响。", "method": "研究提出了“传感器到主观（S2S）映射框架”，这是一个概念模型，通过基于传感器的指标和任务性能指标，将可观察的交互模式与用户对协作的主观感知和内部认知状态联系起来。为了验证该模型，研究对48名参与者进行了实验，他们分为12个MR小组，参与一项协作图像分类任务。", "result": "研究结果表明，感知行为与感知到的协作之间存在关联，特别是在共享注意力和接近度方面。", "conclusion": "本研究验证了传感器数据可以作为混合现实中主观协作体验的可观察表现，并揭示了感知行为与用户协作感知之间的相关性。", "translation": "混合现实（MR）支持丰富的具身协作，但传感器和系统记录的行为信号是否能捕捉用户体验到的协作方式尚不确定。这种脱节源于一个根本性的差距：行为信号是可观察和连续的，而协作是主观解释的，受存在感、认知可用性和社会意识等内部状态的影响。我们的核心见解是，传感器信号是MR协作中主观体验的可观察表现，可以通过共享注视、语音、空间移动和其他系统记录的性能指标等传感器数据捕获。我们提出了“传感器到主观（S2S）映射框架”，这是一个概念模型，通过基于传感器的指标和任务性能指标，将可观察的交互模式与用户对协作的主观感知和内部认知状态联系起来。为了验证该模型，我们对48名参与者进行了研究，他们分为12个MR小组，参与一项协作图像分类任务。我们的发现表明，感知行为与感知到的协作之间存在关联，特别是在共享注意力和接近度方面。", "summary": "本研究探讨了混合现实（MR）中传感器数据如何反映用户的主观协作感知。鉴于行为信号与主观体验之间的脱节，研究提出了“传感器到主观（S2S）映射框架”，旨在通过传感器数据（如共享注视、语音、空间移动）和任务性能指标，连接可观察的交互模式与用户对协作的主观感受和内部认知状态。通过对48名参与者在MR协作任务中的实验，研究发现感知到的行为，特别是共享注意力和接近度，与用户感知到的协作之间存在相关性。", "keywords": "混合现实, 主观协作感知, 传感器数据, S2S映射框架, 共享注意力", "comments": "这项研究的创新之处在于提出了S2S映射框架，系统地将MR中的客观传感器数据与主观协作体验联系起来，填补了这一领域的一个重要空白。它为理解和量化MR协作的质量提供了新的视角和方法，对于未来MR协作系统的设计和优化具有重要意义。通过实验验证了传感器数据与主观感受的关联，为后续研究奠定了基础。"}}
{"id": "2505.01830", "title": "You Don't Have to Live Next to Me: Towards Demobilizing Individualistic Bias in Computational Approaches to Urban Segregation", "authors": ["Anastassia Vybornova", "Trivik Verma"], "categories": ["cs.CY", "physics.soc-ph"], "primary_category": "Subjects:       Computers and Society (cs.CY)", "pdf_link": null, "comments": "Comments:      4 figures; artwork by Namrata Narendra", "url": "http://arxiv.org/abs/2505.01830v2", "summary": "The global surge in social inequalities is one of the most pressing issues of\nour times. The spatial expression of social inequalities at city scale gives\nrise to urban segregation, a common phenomenon across different local and\ncultural contexts. The increasing popularity of Big Data and computational\nmodels has inspired a growing number of computational social science studies\nthat analyze, evaluate, and issue policy recommendations for urban segregation.\nToday's wealth in information and computational power could inform urban\nplanning for equity. However, as we show here, segregation research is\nepistemologically interdependent with prevalent economic theories which\noverfocus on individual responsibility while neglecting systemic processes.\nThis individualistic bias is also engrained in computational models of urban\nsegregation. Through several contemporary examples of how Big Data -- and the\nassumptions underlying its usage -- influence (de)segregation patterns and\npolicies, our essay tells a cautionary tale. We highlight how a lack of\nconsideration for data ethics can lead to the creation of computational models\nthat have a real-life, further marginalizing impact on disadvantaged groups.\nWith this essay, our aim is to develop a better discernment of the pitfalls and\npotentials of computational approaches to urban segregation, thereby fostering\na conscious focus on systemic thinking about urban inequalities. We suggest\nsetting an agenda for research and collective action that is directed at\ndemobilizing individualistic bias, informing our thinking about urban\nsegregation, but also more broadly our efforts to create sustainable cities and\ncommunities.", "comment": "4 figures; artwork by Namrata Narendra", "pdf_url": "http://arxiv.org/pdf/2505.01830v2", "cate": "cs.CY", "date": "2025-05-03", "updated": "2025-07-18", "AI": {"title_translation": "你不需要住在我旁边：迈向消除城市隔离计算方法中的个人主义偏见", "tldr": "本文揭示了城市隔离计算模型中存在的个人主义偏见，并强调缺乏数据伦理考虑可能导致对弱势群体的进一步边缘化影响。", "motivation": "全球社会不平等加剧，城市隔离是其空间体现。尽管大数据和计算模型为城市规划提供了潜力，但现有的隔离研究及其计算模型深受过度关注个人责任而忽视系统性过程的经济理论影响，导致个人主义偏见根深蒂固，可能对弱势群体产生负面影响。因此，本文旨在揭示这些陷阱。", "method": "本文通过分析当代大数据及其使用假设如何影响（去）隔离模式和政策的几个例子，讲述了一个警示性故事，批判性地探讨了计算方法在城市隔离研究中的局限性。", "result": "研究发现，隔离研究在认识论上与普遍的经济理论相互依存，这些理论过度关注个人责任而忽视系统性过程。这种个人主义偏见也根植于城市隔离的计算模型中。缺乏对数据伦理的考虑可能导致创建对弱势群体产生真实生活、进一步边缘化影响的计算模型。", "conclusion": "本文旨在增进对城市隔离计算方法陷阱和潜力的更好辨别，从而促进对城市不平等进行系统性思考。作者建议为研究和集体行动设定议程，旨在消除个人主义偏见，以指导我们对城市隔离的思考，并更广泛地指导我们创建可持续城市和社区的努力。", "translation": "全球社会不平等的加剧是我们这个时代最紧迫的问题之一。社会不平等在城市尺度上的空间表达导致了城市隔离，这是不同地方和文化背景下的常见现象。大数据和计算模型日益普及，激发了越来越多的计算社会科学研究，这些研究分析、评估并为城市隔离提出政策建议。当今丰富的信息和计算能力可以为公平的城市规划提供信息。然而，正如我们在此所示，隔离研究在认识论上与普遍的经济理论相互依存，这些理论过度关注个人责任而忽视系统性过程。这种个人主义偏见也根植于城市隔离的计算模型中。通过几个当代例子，我们展示了大数据及其使用假设如何影响（去）隔离模式和政策，本文讲述了一个警示性故事。我们强调，缺乏对数据伦理的考虑可能导致创建对弱势群体产生真实生活、进一步边缘化影响的计算模型。通过本文，我们的目标是更好地辨别城市隔离计算方法的陷阱和潜力，从而促进对城市不平等进行系统性思考。我们建议为研究和集体行动设定议程，旨在消除个人主义偏见，以指导我们对城市隔离的思考，并更广泛地指导我们创建可持续城市和社区的努力。", "summary": "本文批判性地探讨了当前城市隔离计算方法中存在的个人主义偏见。作者指出，这些模型受限于过度强调个人责任的经济理论，忽视了系统性因素，且缺乏数据伦理考量，可能导致对弱势群体的进一步边缘化。文章通过案例分析，旨在揭示计算方法的潜在风险，并呼吁在城市不平等研究中转向系统性思考，以消除偏见并促进可持续城市发展。", "keywords": "城市隔离, 计算方法, 个人主义偏见, 数据伦理, 社会不平等", "comments": "本文的创新之处在于其对计算社会科学领域中数据伦理和理论偏见的深刻批判。它挑战了将城市隔离简单归因于个人选择的普遍观点，并强调了计算模型可能无意中加剧社会不平等的风险。这对于推动更负责任、更具社会意识的城市规划和数据科学实践具有重要意义。其警示性故事和对系统性思考的呼吁，为未来研究和政策制定提供了宝贵的视角。"}}
{"id": "2507.13490", "title": "Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?", "authors": ["Siqi Shen", "Mehar Singh", "Lajanugen Logeswaran", "Moontae Lee", "Honglak Lee", "Rada Mihalcea"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13490v1", "summary": "There has been extensive research on assessing the value orientation of Large\nLanguage Models (LLMs) as it can shape user experiences across demographic\ngroups. However, several challenges remain. First, while the Multiple Choice\nQuestion (MCQ) setting has been shown to be vulnerable to perturbations, there\nis no systematic comparison of probing methods for value probing. Second, it is\nunclear to what extent the probed values capture in-context information and\nreflect models' preferences for real-world actions. In this paper, we evaluate\nthe robustness and expressiveness of value representations across three widely\nused probing strategies. We use variations in prompts and options, showing that\nall methods exhibit large variances under input perturbations. We also\nintroduce two tasks studying whether the values are responsive to demographic\ncontext, and how well they align with the models' behaviors in value-related\nscenarios. We show that the demographic context has little effect on the\nfree-text generation, and the models' values only weakly correlate with their\npreference for value-based actions. Our work highlights the need for a more\ncareful examination of LLM value probing and awareness of its limitations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13490v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "重新审视LLM价值探测策略：它们是否稳健且富有表现力？", "tldr": "本文研究发现，现有LLM价值探测策略在输入扰动下表现出较大波动性，且其探测到的价值与模型行为和人口统计学背景关联性较弱，需要更谨慎的评估。", "motivation": "评估大型语言模型（LLMs）的价值取向至关重要，因为它会影响不同用户群体的体验。然而，现有方法存在挑战：多项选择题（MCQ）设置易受扰动，缺乏系统性比较；不清楚探测到的价值是否反映上下文信息和模型对真实世界行动的偏好。", "method": "我们评估了三种广泛使用的探测策略的稳健性和表达性。通过改变提示和选项来测试输入扰动下的表现。引入了两个任务：研究价值是否响应人口统计学背景，以及与模型在价值相关场景中的行为对齐程度。", "result": "所有探测方法在输入扰动下都表现出较大的方差（不稳健）。人口统计学背景对自由文本生成影响甚微。模型的价值与它们对基于价值的行为的偏好只有微弱的相关性。", "conclusion": "现有LLM价值探测策略存在局限性，需要更仔细的检查和认识其不足。", "translation": "评估大型语言模型（LLM）的价值取向已进行了广泛研究，因为它能够影响不同人口群体用户的体验。然而，仍存在一些挑战。首先，尽管多项选择题（MCQ）设置已被证明易受扰动，但目前还没有对价值探测方法的系统比较。其次，不清楚所探测到的价值在多大程度上捕获了上下文信息并反映了模型对真实世界行动的偏好。在本文中，我们评估了三种广泛使用的探测策略中价值表示的稳健性和表达性。我们使用提示和选项的变化，表明所有方法在输入扰动下都表现出较大的方差。我们还引入了两个任务，研究价值是否对人口统计学背景有响应，以及它们与模型在价值相关场景中的行为对齐程度。我们发现人口统计学背景对自由文本生成影响甚微，并且模型的价值与它们对基于价值行动的偏好仅有微弱相关。我们的工作强调需要更仔细地检查LLM价值探测及其局限性。", "summary": "本文重新评估了大型语言模型（LLM）的价值探测策略，重点关注其稳健性和表达性。研究发现，现有探测方法在输入扰动下表现出较大波动性，且所探测的价值与人口统计学背景及模型在真实世界行为中的偏好关联性较弱。这凸显了当前LLM价值探测方法的局限性，并强调了未来研究需更加谨慎。", "keywords": "LLM, 价值探测, 稳健性, 表达性, 偏见", "comments": "这篇论文揭示了当前LLM价值探测方法的重要局限性，特别是在稳健性和真实行为反映方面。其创新之处在于系统性地比较了不同探测策略在扰动下的表现，并引入了新的任务来评估价值与上下文和行为的关联。这项工作对于理解LLM的潜在偏见和改进其伦理对齐具有重要意义。"}}
{"id": "2505.01729", "title": "PosePilot: Steering Camera Pose for Generative World Models with Self-supervised Depth", "authors": ["Bu Jin", "Weize Li", "Baihan Yang", "Zhenxin Zhu", "Junpeng Jiang", "Huan-ang Gao", "Haiyang Sun", "Kun Zhan", "Hengtong Hu", "Xueyang Zhang", "Peng Jia", "Hao Zhao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at IEEE/RSJ IROS 2025", "url": "http://arxiv.org/abs/2505.01729v2", "summary": "Recent advancements in autonomous driving (AD) systems have highlighted the\npotential of world models in achieving robust and generalizable performance\nacross both ordinary and challenging driving conditions. However, a key\nchallenge remains: precise and flexible camera pose control, which is crucial\nfor accurate viewpoint transformation and realistic simulation of scene\ndynamics. In this paper, we introduce PosePilot, a lightweight yet powerful\nframework that significantly enhances camera pose controllability in generative\nworld models. Drawing inspiration from self-supervised depth estimation,\nPosePilot leverages structure-from-motion principles to establish a tight\ncoupling between camera pose and video generation. Specifically, we incorporate\nself-supervised depth and pose readouts, allowing the model to infer depth and\nrelative camera motion directly from video sequences. These outputs drive\npose-aware frame warping, guided by a photometric warping loss that enforces\ngeometric consistency across synthesized frames. To further refine camera pose\nestimation, we introduce a reverse warping step and a pose regression loss,\nimproving viewpoint precision and adaptability. Extensive experiments on\nautonomous driving and general-domain video datasets demonstrate that PosePilot\nsignificantly enhances structural understanding and motion reasoning in both\ndiffusion-based and auto-regressive world models. By steering camera pose with\nself-supervised depth, PosePilot sets a new benchmark for pose controllability,\nenabling physically consistent, reliable viewpoint synthesis in generative\nworld models.", "comment": "Accepted at IEEE/RSJ IROS 2025", "pdf_url": "http://arxiv.org/pdf/2505.01729v2", "cate": "cs.CV", "date": "2025-05-03", "updated": "2025-07-18", "AI": {"title_translation": "PosePilot: 通过自监督深度引导生成式世界模型的相机姿态", "tldr": "PosePilot是一个利用自监督深度估计来显著提升生成式世界模型中相机姿态可控性的框架，实现了更精确、物理一致的视角合成。", "motivation": "现有自动驾驶系统中的世界模型在相机姿态控制方面面临挑战，而精确灵活的相机姿态控制对于准确的视角变换和场景动态的真实模拟至关重要。", "method": "PosePilot受自监督深度估计启发，利用运动恢复结构原理，紧密耦合相机姿态与视频生成。它整合了自监督深度和姿态读取，直接从视频序列推断深度和相对相机运动。这些输出驱动姿态感知的帧扭曲，并通过光度扭曲损失确保几何一致性。此外，引入了反向扭曲步骤和姿态回归损失以提高姿态估计精度。", "result": "在自动驾驶和通用领域视频数据集上的广泛实验表明，PosePilot显著增强了扩散模型和自回归世界模型中的结构理解和运动推理能力。通过自监督深度引导相机姿态，PosePilot为姿态可控性设定了新基准，实现了生成式世界模型中物理一致、可靠的视角合成。", "conclusion": "PosePilot通过引入自监督深度估计来引导相机姿态，显著提升了生成式世界模型的姿态可控性，从而实现了物理一致且可靠的视角合成。", "translation": "PosePilot: 通过自监督深度引导生成式世界模型的相机姿态\n\n自动驾驶（AD）系统最近的进展突显了世界模型在普通和挑战性驾驶条件下实现鲁棒和泛化性能的潜力。然而，一个关键挑战依然存在：精确灵活的相机姿态控制，这对于准确的视角变换和场景动态的真实模拟至关重要。在本文中，我们引入了PosePilot，一个轻量级但功能强大的框架，它显著增强了生成式世界模型中的相机姿态可控性。受自监督深度估计的启发，PosePilot利用运动恢复结构原理，建立了相机姿态与视频生成之间的紧密耦合。具体来说，我们结合了自监督深度和姿态读取，使模型能够直接从视频序列中推断深度和相对相机运动。这些输出驱动姿态感知的帧扭曲，由光度扭曲损失引导，以强制合成帧之间的几何一致性。为了进一步细化相机姿态估计，我们引入了反向扭曲步骤和姿态回归损失，提高了视角精度和适应性。在自动驾驶和通用领域视频数据集上的广泛实验表明，PosePilot显著增强了基于扩散和自回归世界模型中的结构理解和运动推理能力。通过自监督深度引导相机姿态，PosePilot为姿态可控性设定了新基准，实现了生成式世界模型中物理一致、可靠的视角合成。", "summary": "本文提出了PosePilot，一个利用自监督深度估计来增强生成式世界模型中相机姿态可控性的框架。它通过整合自监督深度和姿态读取，并结合姿态感知的帧扭曲、光度损失、反向扭曲和姿态回归损失，实现了从视频序列中精确推断深度和相机运动。实验证明PosePilot显著提升了世界模型在结构理解和运动推理方面的能力，并为物理一致的视角合成树立了新标准。", "keywords": "相机姿态控制, 世界模型, 自监督深度, 姿态估计, 自动驾驶", "comments": "该论文的创新点在于将自监督深度估计与相机姿态控制紧密结合，并引入了反向扭曲和姿态回归损失来提高姿态估计精度。这对于生成式世界模型实现更真实、物理一致的场景模拟具有重要意义，特别是在自动驾驶等需要高精度视角控制的领域。"}}
{"id": "2507.13647", "title": "Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones", "authors": ["Minze Li", "Wei Zhao", "Ran Chen", "Mingqiang Wei"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 papers,7 figures", "url": "http://arxiv.org/abs/2507.13647v1", "summary": "Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic\nenvironments remains a key challenge due to high computational demands and the\nneed for fast, adaptive responses. Traditional Particle Swarm Optimization\n(PSO) methods, while effective for offline planning, often struggle with\npremature convergence and latency in real-time scenarios. To overcome these\nlimitations, we propose PE-PSO, an enhanced PSO-based online trajectory\nplanner. The method introduces a persistent exploration mechanism to preserve\nswarm diversity and an entropy-based parameter adjustment strategy to\ndynamically adapt optimization behavior. UAV trajectories are modeled using\nB-spline curves, which ensure path smoothness while reducing optimization\ncomplexity. To extend this capability to UAV swarms, we develop a multi-agent\nframework that combines genetic algorithm (GA)-based task allocation with\ndistributed PE-PSO, supporting scalable and coordinated trajectory generation.\nThe distributed architecture allows for parallel computation and decentralized\ncontrol, enabling effective cooperation among agents while maintaining\nreal-time performance. Comprehensive simulations demonstrate that the proposed\nframework outperforms conventional PSO and other swarm-based planners across\nseveral metrics, including trajectory quality, energy efficiency, obstacle\navoidance, and computation time. These results confirm the effectiveness and\napplicability of PE-PSO in real-time multi-UAV operations under complex\nenvironmental conditions.", "comment": "8 papers,7 figures", "pdf_url": "http://arxiv.org/pdf/2507.13647v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "改进粒子群优化算法：蜂群无人机多目标轨迹优化", "tldr": "提出PE-PSO算法及其多智能体框架，用于解决蜂群无人机在复杂动态环境中实时轨迹规划中的计算挑战和收敛问题，并通过仿真验证其优越性。", "motivation": "动态环境下无人机实时轨迹规划面临计算量大、响应速度慢的挑战，传统粒子群优化（PSO）方法存在早熟收敛和实时性差的问题。", "method": "提出PE-PSO算法，引入持久探索机制保持种群多样性，并采用基于熵的参数调整策略动态适应优化行为。无人机轨迹采用B样条曲线建模。为支持无人机蜂群，开发了结合遗传算法（GA）任务分配和分布式PE-PSO的多智能体框架，实现并行计算和去中心化控制。", "result": "综合仿真表明，所提出的框架在轨迹质量、能量效率、避障和计算时间等多项指标上优于传统PSO和其他基于群体的规划器。", "conclusion": "这些结果证实了PE-PSO在复杂环境条件下实时多无人机操作中的有效性和适用性。", "translation": "无人机（UAV）在动态环境中的实时轨迹规划由于计算需求高以及需要快速自适应响应，仍然是一个关键挑战。传统的粒子群优化（PSO）方法虽然对于离线规划有效，但常常在实时场景中面临早熟收敛和延迟的问题。为了克服这些限制，我们提出了PE-PSO，一种增强的基于PSO的在线轨迹规划器。该方法引入了一种持久探索机制以保持群体多样性，并采用基于熵的参数调整策略来动态适应优化行为。无人机轨迹使用B样条曲线建模，这确保了路径平滑性同时降低了优化复杂性。为了将此能力扩展到无人机蜂群，我们开发了一个多智能体框架，该框架结合了基于遗传算法（GA）的任务分配和分布式PE-PSO，支持可扩展和协调的轨迹生成。分布式架构允许并行计算和去中心化控制，从而在保持实时性能的同时实现智能体之间的有效协作。综合仿真表明，所提出的框架在轨迹质量、能量效率、避障和计算时间等多个指标上优于传统的PSO和其他基于群体的规划器。这些结果证实了PE-PSO在复杂环境条件下实时多无人机操作中的有效性和适用性。", "summary": "本文提出了一种名为PE-PSO的改进粒子群优化算法及其多智能体框架，旨在解决蜂群无人机在动态环境中实时轨迹规划的挑战。PE-PSO通过引入持久探索机制和基于熵的参数调整策略来提高优化性能，并利用B样条曲线建模轨迹以确保平滑性。该框架结合了基于遗传算法的任务分配和分布式PE-PSO，支持可扩展的协同轨迹生成，并通过并行计算和去中心化控制实现实时性能。仿真结果表明，该框架在多项指标上优于现有方法，验证了其在复杂实时多无人机操作中的有效性。", "keywords": "粒子群优化, 无人机蜂群, 轨迹优化, 实时规划, 多智能体系统", "comments": "该论文的创新点在于提出了PE-PSO算法，通过引入持久探索机制和熵基参数调整策略解决了传统PSO在实时轨迹规划中的早熟收敛和延迟问题。此外，其为无人机蜂群设计的结合GA任务分配和分布式PE-PSO的多智能体框架，有效地提升了系统的可扩展性和实时协同能力，对于复杂动态环境下无人机蜂群的应用具有重要意义。"}}
{"id": "2507.13397", "title": "InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction", "authors": ["Kaiyuan Zhai", "Juan Chen", "Chao Wang", "Zeyi Xu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13397v1", "summary": "Accurate pedestrian trajectory prediction is crucial for intelligent\napplications, yet it remains highly challenging due to the complexity of\ninteractions among pedestrians. Previous methods have primarily relied on\nrelative positions to model pedestrian interactions; however, they tend to\noverlook specific interaction patterns such as paired walking or conflicting\nbehaviors, limiting the prediction accuracy in crowded scenarios. To address\nthis issue, we propose InSyn (Interaction-Synchronization Network), a novel\nTransformer-based model that explicitly captures diverse interaction patterns\n(e.g., walking in sync or conflicting) while effectively modeling\ndirection-sensitive social behaviors. Additionally, we introduce a training\nstrategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue\nof initial-step divergence in numerical time-series prediction. Experiments on\nthe ETH and UCY datasets demonstrate that our model outperforms recent\nbaselines significantly, especially in high-density scenarios. Furthermore, the\nSSOS strategy proves effective in improving sequential prediction performance,\nreducing the initial-step prediction error by approximately 6.58%.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13397v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "InSyn：建模复杂交互以进行行人轨迹预测", "tldr": "提出InSyn模型，通过显式捕捉多样交互模式和方向敏感行为，并结合SSOS训练策略，显著提升了行人轨迹预测精度，尤其在高密度场景下。", "motivation": "现有行人轨迹预测方法主要依赖相对位置建模交互，但忽略了特定交互模式（如结伴行走或冲突行为），导致在拥挤场景下预测精度受限。", "method": "提出InSyn (Interaction-Synchronization Network)，一个基于Transformer的新模型，用于显式捕捉多样交互模式和有效建模方向敏感的社交行为。此外，引入Seq-Start of Seq (SSOS) 训练策略，以缓解时间序列预测中初始步发散的问题。", "result": "在ETH和UCY数据集上的实验表明，InSyn模型显著优于最近的基线方法，尤其在高密度场景下。SSOS策略有效提升了序列预测性能，并将初始步预测误差降低了约6.58%。", "conclusion": "InSyn模型通过显式建模复杂交互和引入SSOS训练策略，能够显著提高行人轨迹预测的准确性，特别是在拥挤环境中。", "translation": "准确的行人轨迹预测对于智能应用至关重要，然而由于行人之间交互的复杂性，这仍然极具挑战。以往的方法主要依靠相对位置来建模行人交互；然而，它们往往忽略了特定的交互模式，如结伴行走或冲突行为，从而限制了在拥挤场景中的预测精度。为了解决这个问题，我们提出了InSyn（交互同步网络），一个新颖的基于Transformer的模型，它能够显式捕捉多样化的交互模式（例如，同步行走或冲突），同时有效地建模方向敏感的社交行为。此外，我们引入了一种名为Seq-Start of Seq（SSOS）的训练策略，旨在缓解数值时间序列预测中常见的初始步发散问题。在ETH和UCY数据集上的实验表明，我们的模型显著优于最近的基线方法，尤其是在高密度场景中。此外，SSOS策略被证明能有效提高序列预测性能，将初始步预测误差降低了约6.58%。", "summary": "InSyn是一种基于Transformer的行人轨迹预测模型，旨在通过显式捕捉多样化的交互模式（如同步或冲突行为）和方向敏感的社交行为来提高预测精度。针对时间序列预测中的初始步发散问题，该研究还引入了Seq-Start of Seq (SSOS) 训练策略。实验结果表明，InSyn在ETH和UCY数据集上表现出色，尤其在高密度场景中优于现有基线，并且SSOS策略有效降低了初始步预测误差。", "keywords": "行人轨迹预测, 复杂交互, Transformer, InSyn, SSOS", "comments": "该论文创新性地将Transformer架构应用于行人轨迹预测，并着重解决了传统方法忽略复杂交互模式的问题。通过显式建模多样化交互和引入新颖的SSOS训练策略，显著提升了在高密度场景下的预测性能，对智能驾驶和机器人导航等领域具有重要意义。"}}
{"id": "2507.13534", "title": "Heatwave-driven air conditioning adoption could increase German electricity demand by 14 GW in the near future", "authors": ["Leo Semmelmann", "Frederik vom Scheidt"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 6 figures", "url": "http://arxiv.org/abs/2507.13534v1", "summary": "Intensifying heatwaves driven by climate change are accelerating the adoption\nof mobile air conditioning (AC) systems. A rapid mass adoption of such AC\nsystems could create additional stress on electricity grids and the power\nsystem. This study presents a novel method to estimate the electricity demand\nfrom AC systems both at system level and at high temporal and spatial\ngranularity. We apply the method to a near-future heatwave scenario in Germany\nin which household AC adoption increases from current 19% to 35% during a\nheatwave similar to the one of July 2025. We analyze the effects for 196,428\ngrid cells of one square kilometer across Germany, by combining weather data,\ncensus data, socio-demographic assumptions, mobility patterns, and\ntemperature-dependent AC activation functions. We find that electricity demand\nof newly purchased mobile AC systems could increase the peak load by over 14 GW\n(23%), with urban hot-spots reaching 5.8 MW per square kilometer. The temporal\npattern creates a pronounced afternoon peak that coincides with lower\nphotovoltaic generation, potentially exacerbating power system stability\nchallenges. Our findings underscore the urgency for proactive energy system\nplanning to manage emerging demand peaks.", "comment": "10 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2507.13534v1", "cate": "eess.SY", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "热浪驱动的空调普及可能在不久的将来使德国电力需求增加14吉瓦", "tldr": "气候变化导致的热浪加速了空调普及，本研究预测德国未来热浪情景下，空调电力需求可能使峰值负荷增加超过14吉瓦，并与光伏发电低谷期重合，加剧电网挑战。", "motivation": "气候变化导致的热浪正在加速移动空调系统的普及。空调系统的快速大规模普及可能会给电网和电力系统带来额外压力。", "method": "本研究提出了一种估算空调系统电力需求的新方法，该方法可在系统层面以及高时间与空间粒度上进行估算。将此方法应用于德国近未来热浪情景，假设家庭空调普及率从目前的19%增加到35%（类似于2025年7月的热浪）。通过结合天气数据、人口普查数据、社会人口统计假设、出行模式和温度依赖性空调激活函数，分析了德国196,428个一平方公里网格单元的影响。", "result": "研究发现，新购买的移动空调系统的电力需求可能使峰值负荷增加超过14吉瓦（23%），城市热点区域每平方公里达到5.8兆瓦。时间模式显示出明显的午后高峰，与光伏发电量较低时期重合，可能加剧电力系统稳定性挑战。", "conclusion": "研究结果强调了主动进行能源系统规划以管理新兴需求高峰的紧迫性。", "translation": "气候变化导致的热浪正在加速移动空调（AC）系统的普及。此类空调系统的快速大规模普及可能会给电网和电力系统带来额外压力。本研究提出了一种估算空调系统电力需求的新方法，该方法可在系统层面以及高时间与空间粒度上进行估算。我们将此方法应用于德国近未来热浪情景，在该情景中，家庭空调普及率在类似于2025年7月的热浪期间从目前的19%增加到35%。我们通过结合天气数据、人口普查数据、社会人口统计假设、出行模式和温度依赖性空调激活函数，分析了德国196,428个一平方公里网格单元的影响。我们发现，新购买的移动空调系统的电力需求可能使峰值负荷增加超过14吉瓦（23%），城市热点区域每平方公里达到5.8兆瓦。其时间模式产生了一个明显的午后高峰，与光伏发电量较低时期重合，可能加剧电力系统稳定性挑战。我们的研究结果强调了主动进行能源系统规划以管理新兴需求高峰的紧迫性。", "summary": "本研究利用一种新颖的方法，结合多源数据，对德国在未来热浪情景下空调普及导致的电力需求增长进行了高粒度估算。结果显示，空调普及可能使德国电网峰值负荷增加超过14吉瓦，尤其在午后形成高峰并与光伏发电低谷期重合，对电力系统稳定性构成挑战。研究强调了能源系统规划的紧迫性。", "keywords": "热浪, 空调, 电力需求, 德国, 能源规划", "comments": "该论文创新性地提出了一种高时间与空间粒度的电力需求估算方法，并结合多源数据进行了详尽分析。其重要性在于量化了气候变化驱动下的空调普及对电网的潜在巨大影响，并指出了与可再生能源（如光伏）发电模式不匹配可能带来的挑战。研究结果为德国乃至其他面临类似问题的国家提供了重要的政策制定依据，强调了能源系统前瞻性规划的必要性。"}}
{"id": "2507.13869", "title": "Improved girth approximation in weighted undirected graphs", "authors": ["Avi Kadria", "Liam Roditty", "Aaron Sidford", "Virginia Vassilevska Williams", "Uri Zwick"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13869v1", "summary": "Let $G = (V,E,\\ell)$ be a $n$-node $m$-edge weighted undirected graph, where\n$\\ell: E \\rightarrow (0,\\infty)$ is a real \\emph{length} function defined on\nits edges, and let $g$ denote the girth of $G$, i.e., the length of its\nshortest cycle. We present an algorithm that, for any input, integer $k \\geq\n1$, in $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ expected time finds a cycle of\nlength at most $\\frac{4k}{3}g$. This algorithm nearly matches a\n$O(n^{1+1/k}\\log{n})$-time algorithm of \\cite{KadriaRSWZ22} which applied to\nunweighted graphs of girth $3$. For weighted graphs, this result also improves\nupon the previous state-of-the-art algorithm that in $O((n^{1+1/k}\\log n+m)\\log\n(nM))$ time, where $\\ell: E \\rightarrow [1, M]$ is an integral length function,\nfinds a cycle of length at most $2kg$~\\cite{KadriaRSWZ22}. For $k=1$ this\nresult improves upon the result of Roditty and Tov~\\cite{RodittyT13}.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13869v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "加权无向图中改进的周长近似", "tldr": "提出了一种新的算法，用于在加权无向图中近似最短环，其性能优于现有技术。", "motivation": "在加权无向图中，找到或近似最短环（周长）是一个重要的图论问题。本文旨在改进现有算法的近似比和时间复杂度。", "method": "提出了一种算法，该算法对于任意整数 $k \\geq 1$，在期望时间 $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ 内找到一个长度至多为 $\\frac{4k}{3}g$ 的环，其中 $g$ 是图的周长。", "result": "本算法在 $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ 期望时间内找到长度至多为 $\\frac{4k}{3}g$ 的环。该结果几乎与针对无权图的 $O(n^{1+1/k}\\log{n})$ 时间算法相匹配，并改进了现有加权图算法的 $2kg$ 近似比和时间复杂度。对于 $k=1$，该结果改进了Roditty和Tov的结果。", "conclusion": "本文提出的算法显著改进了加权无向图中周长近似的性能，在近似比和时间复杂度方面都取得了突破。", "translation": "设 $G = (V,E,\\ell)$ 是一个 $n$ 节点 $m$ 边的加权无向图，其中 $\\ell: E \\rightarrow (0,\\infty)$ 是定义在其边上的实数长度函数，并设 $g$ 表示 $G$ 的周长，即其最短环的长度。我们提出了一种算法，对于任何输入整数 $k \\geq 1$，它能在 $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ 的期望时间内找到一个长度至多为 $\\frac{4k}{3}g$ 的环。该算法几乎与 \\cite{KadriaRSWZ22} 的 $O(n^{1+1/k}\\log{n})$ 时间算法相匹配，后者应用于周长为 $3$ 的无权图。对于加权图，该结果也改进了现有最先进的算法，该算法在 $O((n^{1+1/k}\\log n+m)\\log (nM))$ 时间内（其中 $\\ell: E \\rightarrow [1, M]$ 是整数长度函数）找到长度至多为 $2kg$ 的环 \\cite{KadriaRSWZ22}。对于 $k=1$，该结果改进了 Roditty 和 Tov \\cite{RodittyT13} 的结果。", "summary": "本文提出了一种用于加权无向图的改进周长近似算法。该算法在期望时间 $O(kn^{1+1/k}\\log{n} + m(k+\\log{n}))$ 内找到一个长度至多为图周长 $\\frac{4k}{3}$ 倍的环。与现有技术相比，该算法在加权图上的近似比和时间复杂度方面均有显著提升，并且在特定情况下也优于针对无权图的算法。", "keywords": "加权图, 周长近似, 无向图, 最短环, 算法", "comments": "该论文在加权无向图的周长近似问题上取得了重要进展，通过改进近似比（从 $2kg$ 提高到 $\\frac{4k}{3}g$）和优化时间复杂度，为该领域提供了更高效的解决方案。其创新性在于在保持较高效率的同时，获得了更好的近似精度。"}}
{"id": "2505.12723", "title": "On-Policy Optimization with Group Equivalent Preference for Multi-Programming Language Understanding", "authors": ["Haoyuan Wu", "Rui Ming", "Jilong Gao", "Hangyu Zhao", "Xueyi Chen", "Yikai Yang", "Haisheng Zheng", "Zhuolun He", "Bei Yu"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.12723v2", "summary": "Large language models (LLMs) achieve remarkable performance in code\ngeneration tasks. However, a significant performance disparity persists between\npopular programming languages (e.g., Python, C++) and others. To address this\ncapability gap, we leverage the code translation task to train LLMs, thereby\nfacilitating the transfer of coding proficiency across diverse programming\nlanguages. Moreover, we introduce OORL for training, a novel reinforcement\nlearning (RL) framework that integrates on-policy and off-policy strategies.\nWithin OORL, on-policy RL is applied during code translation, guided by a\nrule-based reward signal derived from unit tests. Complementing this\ncoarse-grained rule-based reward, we propose Group Equivalent Preference\nOptimization (GEPO), a novel preference optimization method. Specifically, GEPO\ntrains the LLM using intermediate representations (IRs) groups. LLMs can be\nguided to discern IRs equivalent to the source code from inequivalent ones,\nwhile also utilizing signals about the mutual equivalence between IRs within\nthe group. This process allows LLMs to capture nuanced aspects of code\nfunctionality. By employing OORL for training with code translation tasks, LLMs\nimprove their recognition of code functionality and their understanding of the\nrelationships between code implemented in different languages. Extensive\nexperiments demonstrate that our OORL for LLMs training with code translation\ntasks achieves significant performance improvements on code benchmarks across\nmultiple programming languages.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.12723v2", "cate": "cs.CL", "date": "2025-05-19", "updated": "2025-07-18", "AI": {"title_translation": "采用组等价偏好进行多编程语言理解的在线策略优化", "tldr": "本文提出了OORL框架和GEPO方法，通过代码翻译任务提升LLM对多编程语言的理解能力，显著缩小了流行语言与其他语言之间的性能差距。", "motivation": "解决大型语言模型在不同编程语言（尤其是非流行语言）之间存在的显著性能差距问题。", "method": "利用代码翻译任务训练大型语言模型（LLMs），以促进编程能力在不同编程语言间的迁移。引入OORL（On-Off Reinforcement Learning）作为训练框架，该框架融合了在线策略（on-policy）和离线策略（off-policy）强化学习。在OORL中，在线策略RL应用于代码翻译过程，并由基于单元测试的规则奖励信号指导。提出组等价偏好优化（GEPO）方法，通过使用中间表示（IRs）组来训练LLM，引导LLM识别与源代码等价的IRs，并利用组内IRs间的相互等价信号。", "result": "实验表明，使用OORL和代码翻译任务训练的LLM在多个编程语言的代码基准测试中取得了显著的性能提升。", "conclusion": "通过采用OORL结合代码翻译任务进行训练，LLM提升了对代码功能的识别能力以及对不同语言实现的代码之间关系的理解。", "translation": "大型语言模型（LLMs）在代码生成任务中取得了卓越的性能。然而，流行编程语言（例如Python、C++）与其他语言之间仍然存在显著的性能差异。为了弥补这一能力差距，我们利用代码翻译任务来训练LLMs，从而促进编程能力在不同编程语言间的迁移。此外，我们引入了OORL进行训练，这是一个新颖的强化学习（RL）框架，它集成了在线策略和离线策略。在OORL中，在线策略RL应用于代码翻译过程中，由源自单元测试的基于规则的奖励信号指导。为了补充这种粗粒度的基于规则的奖励，我们提出了一种新颖的偏好优化方法——组等价偏好优化（GEPO）。具体来说，GEPO使用中间表示（IRs）组来训练LLM。LLMs可以被引导去识别与源代码等价的IRs，同时也能利用组内IRs之间的相互等价信号。这个过程使得LLMs能够捕捉代码功能的细微方面。通过采用OORL结合代码翻译任务进行训练，LLMs提高了对代码功能的识别以及对不同语言实现的代码之间关系的理解。大量的实验表明，我们使用OORL对LLMs进行代码翻译任务训练，在多个编程语言的代码基准测试中取得了显著的性能提升。", "summary": "本文旨在解决大型语言模型在不同编程语言理解上的性能差距。为此，作者利用代码翻译任务训练LLM，并提出了一个新颖的强化学习框架OORL，它结合了在线和离线策略。OORL在代码翻译过程中使用基于单元测试的规则奖励，并引入了组等价偏好优化（GEPO）方法，通过中间表示组来捕获代码功能的细微之处。实验证明，该方法显著提升了LLM在多语言代码基准上的表现，增强了其对代码功能和跨语言代码关系的理解。", "keywords": "大型语言模型, 代码翻译, 强化学习, 偏好优化, 多编程语言理解", "comments": "这篇论文的创新点在于提出了OORL强化学习框架和GEPO偏好优化方法，通过结合代码翻译任务，有效地提升了大型语言模型对多种编程语言的理解能力，尤其关注了非流行语言的性能提升，具有重要的实践意义。GEPO利用IRs组进行偏好优化，能够捕捉代码功能的深层语义，是其独特之处。"}}
{"id": "2507.13558", "title": "Why Isn't Relational Learning Taking Over the World?", "authors": ["David Poole"], "categories": ["cs.AI", "cs.DB", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      10 pages (6 pages + references + appendices)", "url": "http://arxiv.org/abs/2507.13558v1", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "comment": "10 pages (6 pages + references + appendices)", "pdf_url": "http://arxiv.org/pdf/2507.13558v1", "cate": "cs.AI", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "为什么关系学习没有征服世界？", "tldr": "本文探讨了为什么关系学习（专注于实体、属性和关系建模的AI领域）尽管企业数据多为关系型，却未像像素和文本模型那样普及，并指出了其发展所需的改进。", "motivation": "动机是指出尽管世界由实体及其关系构成，且许多有价值的企业数据是关系型的，但主流AI系统却主要关注像素、单词和音素，关系学习未能像预期那样普及。作者试图解释这种现象并探讨如何提升关系学习的地位。", "method": "Not mentioned in abstract", "result": "Not mentioned in abstract", "conclusion": "关系学习未能像像素和文本模型那样普及的原因在于其在处理非受限关系数据方面的挑战，并且需要采取进一步的措施来提升其应有的地位。", "translation": "人工智能似乎正在通过建模像素、单词和音素的系统来征服世界。然而，世界可以说不是由像素、单词和音素组成的，而是由具有属性和相互关系的事物（对象、实体，包括事件）组成的。我们理应建模这些，而不是它们的感知或描述。你可能会怀疑，专注于建模单词和像素是因为世界上所有（有价值的）数据都是以文本和图像的形式存在的。但如果你审视几乎任何一家公司，你都会发现他们最有价值的数据都在电子表格、数据库和其他关系型格式中。这些并不是入门级机器学习课程中研究的形式，但它们充满了产品编号、学生编号、交易编号和其他不能被天真地解释为数字的标识符。研究这类数据的领域有各种名称，包括关系学习、统计关系AI等。本文解释了为什么关系学习没有征服世界——除了少数受限关系的情况——以及需要做些什么才能使其达到应有的重要地位。", "summary": "本文探讨了关系学习领域（专注于建模实体、属性和关系）未能像处理像素和文本的AI系统那样普及的原因。作者指出，尽管现实世界和企业最有价值的数据多为关系型，但主流机器学习却忽视了这类数据。文章旨在解释这种现象，并探讨如何提升关系学习在AI领域的重要性。", "keywords": "关系学习, 统计关系AI, 实体关系, 数据建模, 人工智能", "comments": "这篇论文的创新点在于它提出了一个反思性的问题，挑战了当前AI领域的主流趋势，即过度关注感知数据（像素、文本）。它强调了关系型数据在现实世界和商业应用中的重要性，并指出了关系学习未能广泛应用的原因，这对于引导未来研究方向具有重要意义。其局限性在于抽象中并未提供具体的解决方案或方法论，仅仅是提出了问题和方向。"}}
{"id": "2408.01268", "title": "Rumour Spreading Depends on the Latent Geometry and Degree Distribution in Social Network Models", "authors": ["Marc Kaufmann", "Kostas Lakis", "Johannes Lengler", "Raghu Raman Ravi", "Ulysse Schaller", "Konstantin Sturm"], "categories": ["math.PR", "cs.SI", "math.CO", "05C82, 91D25, 91D30"], "primary_category": "Subjects:       Probability (math.PR)", "pdf_link": null, "comments": "Comments:      49 pages", "url": "http://arxiv.org/abs/2408.01268v3", "summary": "We study push-pull rumour spreading in ultra-small-world models for social\nnetworks where the degrees follow a power-law distribution. In a non-geometric\nsetting, Fountoulakis, Panagiotou and Sauerwald have shown that rumours always\nspread ultra-fast (SODA 2012), i.e. in doubly logarithmic time. On the other\nhand, Janssen and Mehrabian have found that rumours spread slowly (polynomial\ntime) in a spatial preferential attachment model (SIDMA 2017). We study the\nquestion systematically for the model of Geometric Inhomogeneous Random Graphs\n(GIRGs). Our results are two-fold: first, with Euclidean geometry slow, fast\n(polylogarithmic) and ultra-fast rumour spreading may occur, depending on the\nexponent of the power law and the strength of the geometry in the networks, and\nwe fully characterise the phase boundaries in between. The regimes do not\ncoincide with the graph distance regimes, i.e., polylogarithmic or even\npolynomial rumour spreading may occur even if graph distances are doubly\nlogarithmic. We expect these results to hold with little effort for related\nmodels, e.g. Scale-Free Percolation. Second, we show that rumour spreading is\nalways (at least) fast in a non-metric geometry. The considered non-metric\ngeometry allows to model social connections where resemblance of vertices in a\nsingle attribute, such as familial kinship, already strongly indicates the\npresence of an edge. Euclidean geometry fails to capture such ties.\n  For some regimes in the Euclidean setting, the efficient pathways for\nspreading rumours differ from previously identified paths. For example, a\nvertex of degree $d$ can transmit the rumour to a vertex of larger degree by a\nchain of length $3$, where one of the two intermediaries has constant degree,\nand the other has degree $d^{c}$ for some constant $c<1$. Similar but longer\nchains of vertices, all having non-constant degree, turn out to be useful as\nwell.", "comment": "49 pages", "pdf_url": "http://arxiv.org/pdf/2408.01268v3", "cate": "math.PR", "date": "2024-08-02", "updated": "2025-07-18", "AI": {"title_translation": "谣言传播取决于社交网络模型中的潜在几何结构和度分布", "tldr": "谣言在社交网络中的传播速度受潜在几何结构和度分布的影响，可能从超快到慢速不等。", "motivation": "现有研究对谣言传播速度的结论存在差异（超快 vs. 慢速），本研究旨在系统性地探讨在几何非齐次随机图（GIRG）模型中，潜在几何结构和度分布如何影响谣言传播速度。", "method": "通过研究几何非齐次随机图（GIRG）模型，系统性地分析谣言传播。", "result": "在欧几里得几何中，谣言传播可能表现为慢速、快速（多对数时间）或超快速，具体取决于幂律指数和网络中几何强度，并完全刻画了相变边界。这些传播机制不与图距离机制一致。在非度量几何中，谣言传播总是（至少）快速的。这种几何结构能更好地捕捉基于单一属性（如亲属关系）的社会连接。在某些欧几里得设置下，谣言传播的有效路径与以往识别的路径不同。", "conclusion": "谣言在社交网络中的传播速度显著依赖于网络的潜在几何结构（包括欧几里得和非度量几何）和度分布，本研究详细刻画了这些依赖关系及其导致的传播速度差异。", "translation": "我们研究了社交网络超小世界模型中的推拉式谣言传播，其中度数遵循幂律分布。在非几何环境中，Fountoulakis、Panagiotou 和 Sauerwald 已经表明谣言总是超快速传播（SODA 2012），即在双对数时间内。另一方面，Janssen 和 Mehrabian 发现在空间优先连接模型中谣言传播缓慢（多项式时间）（SIDMA 2017）。我们系统地研究了几何非齐次随机图（GIRGs）模型中的这个问题。我们的结果是双重的：首先，在欧几里得几何中，谣言传播可能出现慢速、快速（多对数时间）和超快速，这取决于幂律的指数和网络中几何的强度，我们完全刻画了它们之间的相变边界。这些区域不与图距离区域重合，即即使图距离是双对数，也可能发生多对数甚至多项式谣言传播。我们预计这些结果对于相关模型（例如无标度渗透）也适用，只需稍作努力。其次，我们表明在非度量几何中，谣言传播总是（至少）快速的。所考虑的非度量几何允许建模社交连接，其中顶点在单一属性（如家族亲属关系）上的相似性已经强烈表明存在一条边。欧几里得几何未能捕捉到此类联系。在欧几里得设置的某些区域，传播谣言的有效路径与之前识别的路径不同。例如，度数为 d 的顶点可以通过长度为 3 的链将谣言传播给度数更大的顶点，其中两个中介者之一具有常数度数，另一个具有度数 d^c（其中 c<1 为常数）。类似但更长的、所有顶点都具有非常数度数的链也证明是有用的。", "summary": "本文研究了社交网络中谣言传播速度与潜在几何结构和度分布的关系。通过系统分析几何非齐次随机图（GIRG）模型，发现谣言传播在欧几里得几何中可能表现为慢速、快速或超快速，这取决于幂律指数和几何强度，并描绘了相变边界。研究还指出，即使图距离很小，传播速度也可能较慢。此外，在非度量几何中，谣言传播总是快速的，这种几何能更好地捕捉基于单一属性的社会连接。文章还探讨了欧几里得设置下新的有效传播路径。", "keywords": "谣言传播, 社交网络, 潜在几何, 度分布, 几何非齐次随机图", "comments": "这项研究通过引入潜在几何结构（包括欧几里得和非度量几何）的概念，并将其与度分布结合，为理解复杂社会网络中的谣言传播提供了新的视角。其创新之处在于系统性地揭示了几何属性对谣言传播速度的决定性影响，并区分了不同几何类型的作用。论文不仅识别了不同的传播速度区域，还刻画了它们之间的相变边界，这对于预测和控制谣言传播具有重要意义。特别是引入非度量几何来捕捉欧几里得几何无法描述的社会联系，是一个重要的贡献。"}}
{"id": "2507.13820", "title": "Team of One: Cracking Complex Video QA with Model Synergy", "authors": ["Jun Xie", "Zhaoran Zhao", "Xiongjun Guan", "Yingjian Zhu", "Hongzhu Yi", "Xinming Wang", "Feng Chen", "Zhepeng Wang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13820v1", "summary": "We propose a novel framework for open-ended video question answering that\nenhances reasoning depth and robustness in complex real-world scenarios, as\nbenchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models\n(Video-LMMs) often exhibit limited contextual understanding, weak temporal\nmodeling, and poor generalization to ambiguous or compositional queries. To\naddress these challenges, we introduce a prompting-and-response integration\nmechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)\nvia structured chains of thought, each tailored to distinct reasoning pathways.\nAn external Large Language Model (LLM) serves as an evaluator and integrator,\nselecting and fusing the most reliable responses. Extensive experiments\ndemonstrate that our method significantly outperforms existing baselines across\nall evaluation metrics, showcasing superior generalization and robustness. Our\napproach offers a lightweight, extensible strategy for advancing multimodal\nreasoning without requiring model retraining, setting a strong foundation for\nfuture Video-LMM development.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13820v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "独角团队：利用模型协同攻克复杂视频问答", "tldr": "提出一种新颖的框架，通过协同多个异构视频语言模型和外部大型语言模型，显著提升复杂视频问答的推理深度和鲁棒性，无需模型再训练。", "motivation": "现有的视频大型多模态模型（Video-LMMs）在复杂现实场景中，对开放式视频问答的上下文理解有限、时间建模能力弱，且对模糊或组合式查询的泛化能力差。", "method": "本文提出一个提示与响应集成机制，通过结构化的思维链协调多个异构视频语言模型（VLMs），每个模型针对不同的推理路径。一个外部大型语言模型（LLM）充当评估器和集成器，选择并融合最可靠的响应。", "result": "该方法在所有评估指标上显著优于现有基线，展示出卓越的泛化能力和鲁棒性。", "conclusion": "该方法提供了一种轻量级、可扩展的多模态推理策略，无需模型再训练，为未来的视频大型多模态模型发展奠定了坚实基础。", "translation": "我们提出了一种新颖的开放式视频问答框架，该框架在CVRR-ES数据集上进行基准测试，增强了复杂现实场景中的推理深度和鲁棒性。现有的视频大型多模态模型（Video-LMMs）通常表现出有限的上下文理解、弱时间建模以及对模糊或组合式查询的泛化能力差。为了解决这些挑战，我们引入了一种提示与响应集成机制，通过结构化的思维链协调多个异构视频语言模型（VLMs），每个模型都针对不同的推理路径。一个外部大型语言模型（LLM）充当评估器和集成器，选择并融合最可靠的响应。广泛的实验表明，我们的方法在所有评估指标上显著优于现有基线，展示出卓越的泛化能力和鲁棒性。我们的方法提供了一种轻量级、可扩展的策略，用于推进多模态推理，而无需模型再训练，为未来的视频大型多模态模型发展奠定了坚实基础。", "summary": "本文提出了一种名为“独角团队”的新型框架，旨在解决复杂开放式视频问答中现有Video-LMMs存在的上下文理解、时间建模和泛化能力不足的问题。该框架通过一个提示与响应集成机制，协调多个异构Video-Language Models，并利用外部Large Language Model进行评估和响应融合，从而提升推理深度和鲁棒性。实验证明，该方法在性能上显著超越现有基线，并提供了一种无需模型再训练的轻量级、可扩展的多模态推理方案。", "keywords": "视频问答, 多模态推理, 模型协同, 视频语言模型, 大型语言模型", "comments": "这篇论文的创新点在于其“独角团队”的概念，通过协同多个异构VLM并结合LLM作为评估和集成器，有效提升了复杂视频问答的性能。这种方法无需模型再训练，具有轻量级和可扩展的优势，为多模态推理提供了一条新颖且高效的路径，对于未来Video-LMMs的发展具有重要意义。"}}
{"id": "2507.13377", "title": "StructInbet: Integrating Explicit Structural Guidance into Inbetween Frame Generation", "authors": ["Zhenglin Pan", "Haoran Xie"], "categories": ["cs.GR", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      3 pages, 3 figures. SIGGRAPH 2025 Poster", "url": "http://arxiv.org/abs/2507.13377v1", "summary": "In this paper, we propose StructInbet, an inbetweening system designed to\ngenerate controllable transitions over explicit structural guidance.\nStructInbet introduces two key contributions. First, we propose explicit\nstructural guidance to the inbetweening problem to reduce the ambiguity\ninherent in pixel trajectories. Second, we adopt a temporal attention mechanism\nthat incorporates visual identity from both the preceding and succeeding\nkeyframes, ensuring consistency in character appearance.", "comment": "3 pages, 3 figures. SIGGRAPH 2025 Poster", "pdf_url": "http://arxiv.org/pdf/2507.13377v1", "cate": "cs.GR", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "StructInbet: 将显式结构引导集成到中间帧生成中", "tldr": "StructInbet 提出了一种中间帧生成系统，通过引入显式结构引导和时间注意力机制来减少像素轨迹的模糊性并保持角色外观一致性。", "motivation": "解决中间帧生成中像素轨迹的固有模糊性问题。", "method": "StructInbet 引入了两个关键贡献：1. 将显式结构引导引入中间帧生成问题，以减少像素轨迹的模糊性。2. 采用时间注意力机制，结合前一关键帧和后一关键帧的视觉特征，以确保角色外观的一致性。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "在本文中，我们提出了 StructInbet，一个中间帧生成系统，旨在根据显式结构引导生成可控的过渡。StructInbet 引入了两个关键贡献。首先，我们将显式结构引导引入到中间帧生成问题中，以减少像素轨迹固有的模糊性。其次，我们采用了一种时间注意力机制，该机制结合了前一关键帧和后一关键帧的视觉特征，确保了角色外观的一致性。", "summary": "StructInbet 是一种新的中间帧生成系统，它通过整合显式结构引导来解决像素轨迹的模糊性问题，并利用时间注意力机制确保生成帧中角色外观的一致性。", "keywords": "中间帧生成, 结构引导, 时间注意力, 像素轨迹, 视觉一致性", "comments": "该论文的创新点在于将显式结构引导引入中间帧生成，以解决传统方法中像素轨迹的模糊性问题。同时，结合时间注意力机制来保持视觉一致性，有望提升生成效果的控制性和质量。"}}
{"id": "2507.13855", "title": "A stochastic column-block gradient descent method for solving nonlinear systems of equations", "authors": ["Naiyu Jiang", "Wendi Bao", "Lili Xing", "Weiguo Li"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13855v1", "summary": "In this paper, we propose a new stochastic column-block gradient descent\nmethod for solving nonlinear systems of equations. It has a descent direction\nand holds an approximately optimal step size obtained through an optimization\nproblem. We provide a thorough convergence analysis, and derive an upper bound\nfor the convergence rate of the new method. Numerical experiments demonstrate\nthat the proposed method outperforms the existing ones.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13855v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "求解非线性方程组的随机列块梯度下降法", "tldr": "本文提出了一种新的随机列块梯度下降法，用于求解非线性方程组，该方法具有下降方向和近似最优步长，并进行了收敛性分析，数值实验表明其性能优于现有方法。", "motivation": "解决非线性方程组的求解问题，并提出一种性能更优的新方法。", "method": "提出了一种新的随机列块梯度下降法，用于求解非线性方程组。该方法具有下降方向，并通过优化问题获得了近似最优步长。论文还提供了彻底的收敛性分析，并推导了新方法的收敛速度上界。", "result": "数值实验表明，所提出的方法优于现有方法。", "conclusion": "新的随机列块梯度下降法在求解非线性方程组方面表现出优越的性能，并且具有理论上的收敛性保证。", "translation": "在本文中，我们提出了一种新的随机列块梯度下降法，用于求解非线性方程组。该方法具有下降方向，并通过优化问题获得了近似最优步长。我们提供了彻底的收敛性分析，并推导了新方法的收敛速度上界。数值实验表明，所提出的方法优于现有方法。", "summary": "本文提出了一种用于求解非线性方程组的随机列块梯度下降新方法。该方法确保了下降方向，并通过优化问题确定了近似最优步长。研究提供了详细的收敛性分析，并给出了收敛速度的上界。数值实验结果证实，新方法在性能上超越了现有方法。", "keywords": "随机列块梯度下降,非线性方程组,收敛性分析,最优步长,数值实验", "comments": "该论文提出了一种新的随机列块梯度下降法，其创新性在于结合了随机性与列块处理，并确保了下降方向和近似最优步长，这对于解决大规模非线性方程组具有重要意义。理论收敛性分析和数值实验结果均支持其有效性和优越性，对优化算法领域有所贡献。"}}
{"id": "2507.05630", "title": "How Not to Detect Prompt Injections with an LLM", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "categories": ["cs.CR", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Cryptography and Security (cs.CR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05630v2", "summary": "LLM-integrated applications and agents are vulnerable to prompt injection\nattacks, in which adversaries embed malicious instructions within seemingly\nbenign user inputs to manipulate the LLM's intended behavior. Recent defenses\nbased on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect\nperformance by using an LLM to classify inputs as clean or contaminated. In\nthis work, we formally characterize the KAD framework and uncover a structural\nvulnerability in its design that invalidates its core security premise. We\ndesign a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this\nfundamental weakness. It consistently evades KAD defenses with detection rates\nas low as $1.5\\%$ while reliably inducing malicious behavior with success rates\nof up to $88\\%$, without needing white-box access to the LLM or any\noptimization procedures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05630v2", "cate": "cs.CR", "date": "2025-07-08", "updated": "2025-07-17", "AI": {"title_translation": "如何不使用LLM检测提示注入", "tldr": "基于已知答案检测（KAD）的提示注入防御存在根本性缺陷，并且可以被名为DataFlip的新型攻击轻易绕过。", "motivation": "LLM集成应用和代理容易受到提示注入攻击，而最近基于已知答案检测（KAD）的防御声称实现了近乎完美的性能，但本文旨在揭示其设计中的结构性漏洞。", "method": "本文正式描述了已知答案检测（KAD）框架，并揭示了其设计中的结构性漏洞。作者设计了一种系统性的自适应攻击——DataFlip，以利用这一根本性弱点。", "result": "DataFlip攻击能够持续规避KAD防御，检测率低至1.5%，同时以高达88%的成功率可靠地诱导恶意行为，且无需白盒访问LLM或任何优化过程。", "conclusion": "已知答案检测（KAD）框架的设计存在结构性漏洞，这使其核心安全前提失效。DataFlip攻击能够有效地利用这一漏洞，证明了KAD防御的无效性。", "translation": "LLM集成应用和代理容易受到提示注入攻击，在这种攻击中，攻击者将恶意指令嵌入看似良性的用户输入中，以操纵LLM的预期行为。最近基于已知答案检测（KAD）的防御通过使用LLM将输入分类为干净或受污染，从而实现了近乎完美的性能。在这项工作中，我们正式描述了KAD框架，并揭示了其设计中的结构性漏洞，该漏洞使其核心安全前提失效。我们设计了一种系统性的自适应攻击——DataFlip，以利用这一根本性弱点。它持续规避KAD防御，检测率低至1.5%，同时以高达88%的成功率可靠地诱导恶意行为，且无需白盒访问LLM或任何优化过程。", "summary": "LLM集成应用易受提示注入攻击。尽管基于LLM分类的已知答案检测（KAD）防御声称性能优异，但本文揭示了KAD设计中的一个根本性结构漏洞。研究人员设计了一种名为DataFlip的自适应攻击，该攻击成功利用了KAD的弱点，使得其检测率低至1.5%，同时恶意行为诱导成功率高达88%，且无需白盒访问或优化，从而证明了KAD防御的无效性。", "keywords": "提示注入, LLM安全, 已知答案检测, DataFlip, 自适应攻击", "comments": "这篇论文意义重大，因为它挑战了看似有效的提示注入防御机制（KAD）的有效性，而提示注入是LLM应用中的一个关键漏洞。DataFlip攻击揭示了一个根本性的设计缺陷，促使研究界开发更健壮、理论上更可靠的防御措施。其创新之处在于正式描述了KAD并设计了一种无需白盒访问的自适应攻击。"}}
{"id": "2410.23086", "title": "Towards Practical Operation of Deep Reinforcement Learning Agents in Real-World Network Management at Open RAN Edges", "authors": ["Haiyuan Li", "Hari Madhukumar", "Peizheng Li", "Yuelin Liu", "Yiran Teng", "Yulei Wu", "Ning Wang", "Shuangyi Yan", "Dimitra Simeonidou"], "categories": ["cs.NI", "cs.AI", "cs.DC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Networking and Internet Architecture (cs.NI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.23086v2", "summary": "Deep Reinforcement Learning (DRL) has emerged as a powerful solution for\nmeeting the growing demands for connectivity, reliability, low latency and\noperational efficiency in advanced networks. However, most research has focused\non theoretical analysis and simulations, with limited investigation into\nreal-world deployment. To bridge the gap and support practical DRL deployment\nfor network management, we first present an orchestration framework that\nintegrates ETSI Multi-access Edge Computing (MEC) with Open RAN, enabling\nseamless adoption of DRL-based strategies across different time scales while\nenhancing agent lifecycle management. We then identify three critical\nchallenges hindering DRL's real-world deployment, including (1) asynchronous\nrequests from unpredictable or bursty traffic, (2) adaptability and\ngeneralization across heterogeneous topologies and evolving service demands,\nand (3) prolonged convergence and service interruptions due to exploration in\nlive operational environments. To address these challenges, we propose a\nthree-fold solution strategy: (a) advanced time-series integration for handling\nasynchronized traffic, (b) flexible architecture design such as multi-agent DRL\nand incremental learning to support heterogeneous scenarios, and (c)\nsimulation-driven deployment with transfer learning to reduce convergence time\nand service disruptions. Lastly, the feasibility of the MEC-O-RAN architecture\nis validated on an urban-wide testing infrastructure, and two real-world use\ncases are presented, showcasing the three identified challenges and\ndemonstrating the effectiveness of the proposed solutions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.23086v2", "cate": "cs.NI", "date": "2024-10-30", "updated": "2025-07-18", "AI": {"title_translation": "深度强化学习智能体在开放无线接入网边缘的实际网络管理操作中的应用", "tldr": "该论文旨在弥合深度强化学习（DRL）在网络管理领域理论研究与实际部署之间的差距。它提出了一个将ETSI MEC与Open RAN集成的编排框架，并识别了异步流量、适应性和收敛性等三个关键挑战。针对这些挑战，论文提出了高级时间序列集成、灵活架构（多智能体DRL、增量学习）和模拟驱动部署（结合迁移学习）的三重解决方案策略。该方法在城市范围的测试基础设施上得到验证，并展示了两个实际用例。", "motivation": "大多数关于深度强化学习（DRL）在高级网络中的研究都集中在理论分析和模拟上，对实际部署的调查有限。本文旨在弥合这一差距，支持DRL在网络管理中的实际部署。", "method": "本文提出了一个编排框架，将ETSI多接入边缘计算（MEC）与开放无线接入网（Open RAN）集成，以实现DRL策略的无缝采用和智能体生命周期管理。它识别了阻碍DRL实际部署的三个关键挑战：异步请求、跨异构拓扑的适应性和泛化能力，以及长时间收敛和服务中断。为解决这些挑战，论文提出了一个三管齐下的解决方案策略：(a) 用于处理异步流量的高级时间序列集成；(b) 支持异构场景的灵活架构设计（如多智能体DRL和增量学习）；(c) 通过迁移学习进行模拟驱动部署，以减少收敛时间和业务中断。该MEC-O-RAN架构的可行性在一个城市范围的测试基础设施上得到了验证，并提出了两个实际用例。", "result": "MEC-O-RAN架构的可行性在一个城市范围的测试基础设施上得到了验证。此外，论文提出了两个实际用例，展示了所识别的三个挑战并证明了所提出解决方案的有效性。", "conclusion": "本文验证了MEC-O-RAN架构的可行性，并证明了所提出的解决方案在解决深度强化学习（DRL）智能体在开放无线接入网边缘实际网络管理操作中面临的部署挑战方面的有效性。", "translation": "深度强化学习（DRL）已成为满足高级网络中日益增长的连接性、可靠性、低延迟和运营效率需求的一种强大解决方案。然而，大多数研究都集中在理论分析和模拟上，对实际部署的调查有限。为了弥合这一差距并支持DRL在网络管理中的实际部署，我们首先提出了一个编排框架，该框架将ETSI多接入边缘计算（MEC）与开放无线接入网（Open RAN）集成，从而实现DRL策略在不同时间尺度上的无缝采用，同时增强智能体生命周期管理。然后，我们确定了阻碍DRL实际部署的三个关键挑战，包括：（1）来自不可预测或突发流量的异步请求；（2）跨异构拓扑和不断演进的服务需求的适应性和泛化能力；以及（3）在实时操作环境中由于探索导致的长时间收敛和服务中断。为了解决这些挑战，我们提出了一个三管齐下的解决方案策略：（a）用于处理异步流量的高级时间序列集成；（b）支持异构场景的灵活架构设计，例如多智能体DRL和增量学习；以及（c）通过迁移学习进行模拟驱动部署，以减少收敛时间和业务中断。最后，MEC-O-RAN架构的可行性在一个城市范围的测试基础设施上得到了验证，并提出了两个实际用例，展示了所识别的三个挑战并证明了所提出解决方案的有效性。", "summary": "本文旨在解决深度强化学习（DRL）在网络管理领域从理论研究到实际部署的差距。它提出了一个集成ETSI MEC与Open RAN的编排框架，以促进DRL策略的应用。论文识别了异步流量、跨异构拓扑的适应性以及收敛时间长等三个关键的实际部署挑战。为应对这些挑战，本文提出了一套三管齐下的解决方案策略，包括高级时间序列集成、灵活架构设计（如多智能体DRL和增量学习）以及结合迁移学习的模拟驱动部署。该MEC-O-RAN架构及其解决方案的有效性在一个城市范围的测试基础设施上通过两个实际用例得到了验证。", "keywords": "深度强化学习, 网络管理, 开放无线接入网, MEC, 实际部署", "comments": "该论文通过将深度强化学习在网络管理中的研究重点从理论模拟转向实际、真实世界的部署，做出了重要贡献。所提出的MEC-O-RAN集成框架和三管齐下的解决方案策略直接解决了关键的运营挑战，增强了DRL智能体在复杂、实时网络环境中的适用性和鲁棒性。其在城市范围测试平台上的验证增加了强有力的实证可信度。"}}
{"id": "2507.14038", "title": "DONUT: Physics-aware Machine Learning for Real-time X-ray Nanodiffraction Analysis", "authors": ["Aileen Luo", "Tao Zhou", "Ming Du", "Martin V. Holt", "Andrej Singer", "Mathew J. Cherukara"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14038v1", "summary": "Coherent X-ray scattering techniques are critical for investigating the\nfundamental structural properties of materials at the nanoscale. While\nadvancements have made these experiments more accessible, real-time analysis\nremains a significant bottleneck, often hindered by artifacts and computational\ndemands. In scanning X-ray nanodiffraction microscopy, which is widely used to\nspatially resolve structural heterogeneities, this challenge is compounded by\nthe convolution of the divergent beam with the sample's local structure. To\naddress this, we introduce DONUT (Diffraction with Optics for Nanobeam by\nUnsupervised Training), a physics-aware neural network designed for the rapid\nand automated analysis of nanobeam diffraction data. By incorporating a\ndifferentiable geometric diffraction model directly into its architecture,\nDONUT learns to predict crystal lattice strain and orientation in real-time.\nCrucially, this is achieved without reliance on labeled datasets or\npre-training, overcoming a fundamental limitation for supervised machine\nlearning in X-ray science. We demonstrate experimentally that DONUT accurately\nextracts all features within the data over 200 times more efficiently than\nconventional fitting methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14038v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DONUT：用于实时X射线纳米衍射分析的物理感知机器学习", "tldr": "DONUT是一种物理感知、无监督的机器学习模型，用于实时X射线纳米衍射分析，其效率比传统方法提高200倍以上。", "motivation": "X射线散射技术在纳米尺度材料结构研究中至关重要，但实时分析仍是瓶颈，常受伪影和计算需求的阻碍。扫描X射线纳米衍射显微镜中的挑战因发散光束与样品局部结构的卷积而加剧。", "method": "本文引入了DONUT（Diffraction with Optics for Nanobeam by Unsupervised Training），一个物理感知的神经网络，用于快速自动化分析纳米束衍射数据。通过在其架构中直接集成可微分的几何衍射模型，DONUT无需标记数据集或预训练即可实时预测晶格应变和取向。", "result": "实验证明，DONUT能准确提取数据中的所有特征，效率比传统拟合方法高200多倍。", "conclusion": "DONUT提供了一种高效、准确的实时X射线纳米衍射数据分析方法，解决了传统方法的计算瓶颈和对标记数据的依赖。", "translation": "相干X射线散射技术对于研究纳米尺度材料的基本结构特性至关重要。尽管技术进步使得这些实验更易于进行，但实时分析仍然是一个重要的瓶颈，经常受到伪影和计算需求的阻碍。在广泛用于空间分辨结构异质性的扫描X射线纳米衍射显微镜中，发散光束与样品局部结构的卷积使这一挑战更加复杂。为了解决这个问题，我们引入了DONUT（Diffraction with Optics for Nanobeam by Unsupervised Training），一个物理感知的神经网络，旨在快速自动分析纳米束衍射数据。通过在其架构中直接整合可微分的几何衍射模型，DONUT能够实时预测晶体晶格应变和取向。至关重要的是，这在不依赖标记数据集或预训练的情况下实现，克服了X射线科学中监督机器学习的一个根本限制。我们通过实验证明，DONUT能够准确地提取数据中的所有特征，效率比传统拟合方法高200多倍。", "summary": "本文介绍了DONUT，一个用于实时X射线纳米衍射分析的物理感知神经网络。该模型通过将可微分的几何衍射模型集成到其架构中，实现了无监督的学习，能够实时、准确地预测晶体晶格应变和取向。实验证明，DONUT的分析效率比传统方法提高了200多倍，解决了X射线科学中实时数据分析的计算瓶颈和对标记数据的依赖问题。", "keywords": "X射线纳米衍射, 机器学习, 实时分析, 物理感知, 无监督训练", "comments": "DONUT的创新之处在于其“物理感知”的神经网络设计和无监督学习能力，这对于X射线科学领域尤其重要，因为它克服了传统监督学习对大量标记数据的依赖。该方法显著提高了实时分析效率，有望加速材料科学研究。"}}
{"id": "2502.00691", "title": "To Code or not to Code? Adaptive Tool Integration for Math Language Models via Expectation-Maximization", "authors": ["Haozhe Wang", "Long Li", "Chao Qu", "Fengming Zhu", "Weidi Xu", "Wei Chu", "Fangzhen Lin"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted to ACL 2025", "url": "http://arxiv.org/abs/2502.00691v4", "summary": "Recent advances in mathematical problem-solving with language models (LMs)\nintegrate chain-of-thought (CoT) reasoning and code execution to harness their\ncomplementary strengths. However, existing hybrid frameworks exhibit a critical\nlimitation: they depend on externally dictated instructions or rigid\ncode-integration templates, lacking metacognitive awareness -- the capacity to\ndynamically evaluate intrinsic capabilities and autonomously determine when and\nhow to integrate tools. This rigidity motivates our study of autonomous code\nintegration, enabling models to adapt tool-usage strategies as their reasoning\nabilities evolve during training.\n  While reinforcement learning (RL) shows promise for boosting LLM reasoning at\nscale (e.g., DeepSeek-R1), we demonstrate its inefficiency in learning\nautonomous code integration due to inadequate exploration of the vast\ncombinatorial space of CoT-code interleaving patterns. To address this\nchallenge, we propose a novel Expectation-Maximization (EM) framework that\nsynergizes structured exploration (E-step) with off-policy RL optimization\n(M-step), creating a self-reinforcing cycle between metacognitive tool-use\ndecisions and evolving capabilities. Experiments reveal our method achieves\nsuperior results through improved exploration. Notably, our 7B model improves\nover 11% on MATH500 and 9.4% on AIME without o1-like CoT.", "comment": "Accepted to ACL 2025", "pdf_url": "http://arxiv.org/pdf/2502.00691v4", "cate": "cs.AI", "date": "2025-02-02", "updated": "2025-07-18", "AI": {"title_translation": "编程还是不编程？基于期望最大化实现数学语言模型的自适应工具集成", "tldr": "本文提出了一种新的期望最大化（EM）框架，用于数学语言模型（LMs）的自主代码集成，以解决现有混合框架缺乏元认知意识的局限性，并在数学问题解决任务上取得了显著改进。", "motivation": "现有的将思维链（CoT）推理和代码执行相结合的语言模型数学问题解决框架存在一个关键限制：它们依赖于外部指令或僵化的代码集成模板，缺乏元认知意识，即动态评估内在能力并自主决定何时以及如何集成工具的能力。这种僵化促使作者研究自主代码集成，使模型能够随着训练过程中推理能力的发展而调整工具使用策略。", "method": "针对强化学习在学习自主代码集成方面探索效率低下的问题，本文提出了一种新颖的期望最大化（EM）框架。该框架将结构化探索（E步）与离策略强化学习优化（M步）相结合，在元认知工具使用决策和不断演进的能力之间创建了一个自我强化的循环。", "result": "实验表明，该方法通过改进探索实现了卓越的结果。值得注意的是，作者的7B模型在MATH500上提高了11%以上，在AIME上提高了9.4%，且无需o1-like CoT。", "conclusion": "本文提出的基于期望最大化的框架有效解决了数学语言模型中自主代码集成的问题，通过改进探索显著提升了模型在数学问题解决任务上的性能，验证了元认知工具使用决策与能力演进之间自我强化循环的有效性。", "translation": "近年来，通过将思维链（CoT）推理和代码执行相结合，数学问题解决领域的语言模型（LMs）取得了显著进展，从而充分利用了它们的互补优势。然而，现有的混合框架存在一个关键限制：它们依赖于外部指令或僵化的代码集成模板，缺乏元认知意识——即动态评估内在能力并自主决定何时以及如何集成工具的能力。这种僵化促使我们研究自主代码集成，使模型能够随着训练过程中推理能力的发展而调整工具使用策略。\n虽然强化学习（RL）在提升大型语言模型（LLM）的推理能力方面显示出潜力（例如DeepSeek-R1），但我们证明了它在学习自主代码集成方面的效率低下，原因是未能充分探索CoT-代码交错模式的巨大组合空间。为了解决这一挑战，我们提出了一种新颖的期望最大化（EM）框架，该框架将结构化探索（E步）与离策略RL优化（M步）相结合，在元认知工具使用决策和不断演进的能力之间创建了一个自我强化的循环。实验表明，我们的方法通过改进探索实现了卓越的结果。值得注意的是，我们的7B模型在MATH500上提高了11%以上，在AIME上提高了9.4%，且无需o1-like CoT。", "summary": "本文针对数学语言模型在问题解决中缺乏自主工具集成能力的问题，提出了一种基于期望最大化（EM）的新型框架。该框架结合了结构化探索（E步）和离策略强化学习优化（M步），旨在使模型能够动态地决定何时以及如何使用代码工具。实验结果表明，该方法通过更有效的探索，显著提升了模型在MATH500和AIME等数学基准上的性能，克服了现有方法的局限性。", "keywords": "数学语言模型, 工具集成, 期望最大化, 元认知, 代码执行", "comments": "该论文通过引入期望最大化框架来解决语言模型在数学问题解决中自主代码集成的问题，具有显著的创新性。它解决了现有混合框架缺乏元认知意识的痛点，通过结合结构化探索和离策略RL优化，实现了模型工具使用策略的自适应进化，这对于提升大型语言模型在复杂推理任务上的能力具有重要意义。性能提升也验证了其方法的有效性。"}}
{"id": "2505.19291", "title": "TextDiffuser-RL: Efficient and Robust Text Layout Optimization for High-Fidelity Text-to-Image Synthesis", "authors": ["Kazi Mahathir Rahman", "Showrin Rahman", "Sharmin Sultana Srishty"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      14 pages, 26 figures. Submitted to arXiv for dissemination. Intended for future submission to a Generative AI conference", "url": "http://arxiv.org/abs/2505.19291v2", "summary": "Text-embedded image generation plays a critical role in industries such as\ngraphic design, advertising, and digital content creation. Text-to-Image\ngeneration methods leveraging diffusion models, such as TextDiffuser-2, have\ndemonstrated promising results in producing images with embedded text.\nTextDiffuser-2 effectively generates bounding box layouts that guide the\nrendering of visual text, achieving high fidelity and coherence. However,\nexisting approaches often rely on resource-intensive processes and are limited\nin their ability to run efficiently on both CPU and GPU platforms. To address\nthese challenges, we propose a novel two-stage pipeline that integrates\nreinforcement learning (RL) for rapid and optimized text layout generation with\na diffusion-based image synthesis model. Our RL-based approach significantly\naccelerates the bounding box prediction step while reducing overlaps, allowing\nthe system to run efficiently on both CPUs and GPUs. Extensive evaluations\ndemonstrate that our framework maintains or surpasses TextDiffuser-2's quality\nin text placement and image synthesis, with markedly faster runtime and\nincreased flexibility. Extensive evaluations demonstrate that our framework\nmaintains or surpasses TextDiffuser-2's quality in text placement and image\nsynthesis, with markedly faster runtime and increased flexibility. Our approach\nhas been evaluated on the MARIOEval benchmark, achieving OCR and CLIPScore\nmetrics close to state-of-the-art models, while being 97.64% more faster and\nrequiring only 2MB of memory to run.", "comment": "14 pages, 26 figures. Submitted to arXiv for dissemination. Intended\n  for future submission to a Generative AI conference", "pdf_url": "http://arxiv.org/pdf/2505.19291v2", "cate": "cs.CV", "date": "2025-05-25", "updated": "2025-07-17", "AI": {"title_translation": "TextDiffuser-RL：高效鲁棒的文本布局优化，用于高保真文本到图像合成", "tldr": "TextDiffuser-RL提出了一种基于强化学习的两阶段方法，用于优化文本到图像合成中的文本布局，显著提高了效率和速度，同时保持或超越了现有模型的质量。", "motivation": "现有文本到图像生成方法（如TextDiffuser-2）在生成嵌入文本的图像时，虽然能有效生成高质量的边界框布局，但通常资源密集且难以在CPU和GPU平台上高效运行。", "method": "本文提出了一种新颖的两阶段管道，将强化学习（RL）与基于扩散的图像合成模型相结合，用于快速优化的文本布局生成。该方法通过RL显著加速了边界框预测步骤，并减少了重叠。", "result": "TextDiffuser-RL在文本放置和图像合成质量上保持或超越了TextDiffuser-2，具有显著更快的运行时间和更高的灵活性。它能在CPU和GPU上高效运行，在MARIOEval基准测试中，OCR和CLIPScore指标接近最先进模型，速度提高了97.64%，仅需2MB内存。", "conclusion": "TextDiffuser-RL成功地解决了文本到图像合成中效率和资源消耗的挑战，通过引入强化学习优化文本布局，实现了高质量、高效率且资源占用极低的文本嵌入图像生成。", "translation": "嵌入文本的图像生成在平面设计、广告和数字内容创作等行业中发挥着关键作用。利用扩散模型的文本到图像生成方法，如TextDiffuser-2，在生成嵌入文本的图像方面表现出有前景的结果。TextDiffuser-2有效地生成边界框布局，指导视觉文本的渲染，实现了高保真度和连贯性。然而，现有方法通常依赖于资源密集型过程，并且在CPU和GPU平台上高效运行的能力有限。为了解决这些挑战，我们提出了一种新颖的两阶段管道，该管道将强化学习（RL）集成到快速优化的文本布局生成中，并结合了基于扩散的图像合成模型。我们基于RL的方法显著加速了边界框预测步骤，同时减少了重叠，使系统能够在CPU和GPU上高效运行。广泛的评估表明，我们的框架在文本放置和图像合成方面保持或超越了TextDiffuser-2的质量，具有显著更快的运行时间和更高的灵活性。广泛的评估表明，我们的框架在文本放置和图像合成方面保持或超越了TextDiffuser-2的质量，具有显著更快的运行时间和更高的灵活性。我们的方法已在MARIOEval基准测试中进行了评估，OCR和CLIPScore指标接近最先进模型，同时速度提高了97.64%，并且仅需2MB内存即可运行。", "summary": "TextDiffuser-RL提出了一种创新的两阶段管道，通过结合强化学习（RL）和扩散模型，显著优化了文本到图像合成中的文本布局生成。该方法解决了现有技术资源密集且效率低下的问题，通过RL加速边界框预测并减少重叠，从而实现了在CPU和GPU上的高效运行。实验证明，TextDiffuser-RL在保持或超越TextDiffuser-2质量的同时，大幅提升了运行速度和灵活性，并在MARIOEval基准测试中展现出接近最先进的性能，且内存占用极低。", "keywords": "文本到图像合成, 强化学习, 文本布局优化, 扩散模型, TextDiffuser-RL", "comments": "该论文的创新点在于将强化学习引入文本到图像合成的文本布局优化中，有效地解决了现有方法效率低下的问题。通过RL加速边界框预测并降低资源消耗，使得高保真文本嵌入图像的生成更加实用。其在速度和内存效率上的显著提升，对于实际应用具有重要意义。"}}
{"id": "2507.13650", "title": "Safe Robotic Capsule Cleaning with Integrated Transpupillary and Intraocular Optical Coherence Tomography", "authors": ["Yu-Ting Lai", "Yasamin Foroutani", "Aya Barzelay", "Tsu-Chin Tsao"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      12 pages, 27 figures", "url": "http://arxiv.org/abs/2507.13650v1", "summary": "Secondary cataract is one of the most common complications of vision loss due\nto the proliferation of residual lens materials that naturally grow on the lens\ncapsule after cataract surgery. A potential treatment is capsule cleaning, a\nsurgical procedure that requires enhanced visualization of the entire capsule\nand tool manipulation on the thin membrane. This article presents a robotic\nsystem capable of performing the capsule cleaning procedure by integrating a\nstandard transpupillary and an intraocular optical coherence tomography probe\non a surgical instrument for equatorial capsule visualization and real-time\ntool-to-tissue distance feedback. Using robot precision, the developed system\nenables complete capsule mapping in the pupillary and equatorial regions with\nin-situ calibration of refractive index and fiber offset, which are still\ncurrent challenges in obtaining an accurate capsule model. To demonstrate\neffectiveness, the capsule mapping strategy was validated through five\nexperimental trials on an eye phantom that showed reduced root-mean-square\nerrors in the constructed capsule model, while the cleaning strategy was\nperformed in three ex-vivo pig eyes without tissue damage.", "comment": "12 pages, 27 figures", "pdf_url": "http://arxiv.org/pdf/2507.13650v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "集成经瞳孔和眼内光学相干断层扫描的安全机器人囊膜清洁术", "tldr": "开发了一种集成光学相干断层扫描（OCT）探头的机器人系统，用于精确的白内障囊膜清洁，并在体外实验中展示了其有效性和安全性。", "motivation": "继发性白内障是白内障手术后常见的视力丧失并发症，其治疗方法——囊膜清洁术需要增强对整个囊膜的视觉和对薄膜上工具的操纵能力。", "method": "本文提出了一种机器人系统，通过在手术器械上集成标准的经瞳孔和眼内光学相干断层扫描（OCT）探头，实现赤道囊膜的可视化和实时的工具-组织距离反馈。该系统利用机器人精度，实现了瞳孔和赤道区域的完整囊膜映射，并进行了折射率和光纤偏移的原位校准。", "result": "囊膜映射策略通过五次眼部模型实验验证，显示构建的囊膜模型均方根误差降低；清洁策略在三只离体猪眼中进行，未造成组织损伤。", "conclusion": "该集成了光学相干断层扫描的机器人系统能够安全有效地执行白内障囊膜清洁，并在囊膜建模和清洁过程中展现出高精度和无损伤的潜力。", "translation": "继发性白内障是白内障手术后因残留晶状体物质在晶状体囊膜上自然增殖而导致的最常见的视力丧失并发症之一。潜在的治疗方法是囊膜清洁，这是一种需要增强对整个囊膜的视觉和对薄膜上工具进行操纵的手术过程。本文提出了一种机器人系统，通过在手术器械上集成标准的经瞳孔和眼内光学相干断层扫描探头，实现赤道囊膜的可视化和实时的工具-组织距离反馈，从而能够执行囊膜清洁程序。该系统利用机器人精度，实现了瞳孔和赤道区域的完整囊膜映射，并进行了折射率和光纤偏移的原位校准，这些仍然是获得精确囊膜模型的当前挑战。为了证明其有效性，囊膜映射策略通过在眼部模型上进行的五次实验验证，结果显示构建的囊膜模型均方根误差降低；同时，清洁策略在三只离体猪眼中进行，未造成组织损伤。", "summary": "本文介绍了一种用于白内障囊膜清洁的机器人系统，该系统创新性地整合了经瞳孔和眼内光学相干断层扫描（OCT）探头，以提供全面的囊膜可视化和实时工具-组织距离反馈。该系统能够高精度地完成囊膜映射，并解决了现有技术中折射率和光纤偏移校准的挑战。实验结果表明，该系统在眼部模型上有效降低了囊膜模型的误差，并在离体猪眼上安全地完成了清洁操作，未造成组织损伤。", "keywords": "机器人手术, 光学相干断层扫描, 囊膜清洁, 继发性白内障, 眼科手术", "comments": "这项研究的创新之处在于将光学相干断层扫描（OCT）探头集成到机器人手术器械上，实现了对眼部薄膜结构（如晶状体囊膜）的精确、实时可视化和操作。这种集成解决了传统手术中囊膜清洁对可视化和精度的挑战，尤其是在赤道区域的映射和工具-组织距离反馈。该系统在提高手术安全性、减少并发症方面具有重要潜力，为眼科微创手术提供了新的技术路径。"}}
{"id": "2507.13689", "title": "Density Evolution Analysis of Sparse-Block IDMA", "authors": ["Jean-Francois Chamberland", "Gianluigi Liva", "Krishna Narayanan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Presented at the 2025 IEEE Workshop on Signal Processing and Artificial Intelligence for Wireless Communications (SPAWC)", "url": "http://arxiv.org/abs/2507.13689v1", "summary": "Sparse block interleaver division multiple access (SB-IDMA) is a recently\nintroduced unsourced multiple access protocol that aims to improve the\nperformance of the grant-free two-step random access transmission protocol of\nthe 3GPP 5G New Radio standard. We introduced a density evolution analysis of\nthe successive interference cancellation receiver of SB-IDMA, providing a\ntheoretical characterization of its performance.", "comment": "Presented at the 2025 IEEE Workshop on Signal Processing and\n  Artificial Intelligence for Wireless Communications (SPAWC)", "pdf_url": "http://arxiv.org/pdf/2507.13689v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "稀疏块IDMA的密度演化分析", "tldr": "本文对稀疏块IDMA的逐次干扰消除接收机进行了密度演化分析，以理论表征其性能。", "motivation": "稀疏块交织器分多址（SB-IDMA）是一种旨在改善3GPP 5G新空口标准中免授权两步随机接入传输协议性能的无源多址协议。", "method": "本文对SB-IDMA的逐次干扰消除接收机引入了密度演化分析。", "result": "提供了SB-IDMA性能的理论表征。", "conclusion": "通过密度演化分析，理论上表征了SB-IDMA逐次干扰消除接收机的性能。", "translation": "稀疏块交织器分多址（SB-IDMA）是一种最近引入的无源多址协议，旨在改善3GPP 5G新空口标准中免授权两步随机接入传输协议的性能。我们对SB-IDMA的逐次干扰消除接收机引入了密度演化分析，从而对其性能进行了理论表征。", "summary": "本文对稀疏块交织器分多址（SB-IDMA）协议的逐次干扰消除接收机进行了密度演化分析。SB-IDMA是一种旨在提升3GPP 5G新空口中免授权两步随机接入性能的无源多址协议。通过密度演化分析，该研究提供了SB-IDMA性能的理论表征。", "keywords": "稀疏块IDMA, 密度演化, 逐次干扰消除, 无源多址, 5G", "comments": "本文通过引入密度演化分析，为SB-IDMA这一新型无源多址协议的性能提供了重要的理论基础，有助于深入理解其在5G系统中的潜在应用和优化方向。"}}
{"id": "2507.13706", "title": "GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms", "authors": ["Ángel F. García-Fernández", "Jinhao Gu", "Lennart Svensson", "Yuxuan Xia", "Jan Krejčí", "Oliver Kost", "Ondřej Straka"], "categories": ["cs.CV", "math.ST", "stat.TH"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13706v1", "summary": "This paper introduces two quasi-metrics for performance assessment of\nmulti-object tracking (MOT) algorithms. In particular, one quasi-metric is an\nextension of the generalised optimal subpattern assignment (GOSPA) metric and\nmeasures the discrepancy between sets of objects. The other quasi-metric is an\nextension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy\nbetween sets of trajectories. Similar to the GOSPA-based metrics, these\nquasi-metrics include costs for localisation error for properly detected\nobjects, the number of false objects and the number of missed objects. The\nT-GOSPA quasi-metric also includes a track switching cost. Differently from the\nGOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of\npenalising missed and false objects with different costs, and the localisation\ncosts are not required to be symmetric. These properties can be useful in MOT\nevaluation in certain applications. The performance of several Bayesian MOT\nalgorithms is assessed with the T-GOSPA quasi-metric via simulations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13706v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "用于评估多目标跟踪算法的 GOSPA 和 T-GOSPA 准度量", "tldr": "本文引入了两种新的准度量 (GOSPA 和 T-GOSPA 的扩展) 以灵活评估多目标跟踪算法的性能。", "motivation": "为了更灵活地评估多目标跟踪 (MOT) 算法的性能，特别是在某些应用中需要对漏检和虚警目标施加不同成本，并且定位成本不需要对称的情况下，需要新的评估准度量。", "method": "本文引入了两种准度量：一种是广义最优子模式分配 (GOSPA) 度量的扩展，用于测量对象集之间的差异；另一种是轨迹 GOSPA (T-GOSPA) 度量的扩展，用于测量轨迹集之间的差异。这些准度量包含了正确检测目标的定位误差、虚警目标数量和漏检目标数量的成本，其中 T-GOSPA 准度量还包括了轨迹切换成本。与 GOSPA 和 T-GOSPA 度量不同的是，提出的准度量能够灵活地对漏检和虚警目标施加不同的惩罚成本，并且定位成本不要求是对称的。", "result": "通过仿真，使用 T-GOSPA 准度量评估了几种贝叶斯多目标跟踪算法的性能。", "conclusion": "本文提出的 GOSPA 和 T-GOSPA 准度量提供了更灵活的 MOT 算法评估方法，特别是在需要非对称定位成本和不同漏检/虚警惩罚的特定应用中具有实用性。", "translation": "本文引入了两种用于多目标跟踪 (MOT) 算法性能评估的准度量。其中一种准度量是广义最优子模式分配 (GOSPA) 度量的扩展，用于测量对象集之间的差异。另一种准度量是轨迹 GOSPA (T-GOSPA) 度量的扩展，用于测量轨迹集之间的差异。与基于 GOSPA 的度量类似，这些准度量包含了正确检测目标的定位误差成本、虚警目标数量和漏检目标数量的成本。T-GOSPA 准度量还包括了轨迹切换成本。与 GOSPA 和 T-GOSPA 度量不同的是，所提出的准度量具有灵活性，可以对漏检和虚警目标施加不同的成本，并且定位成本不需要是对称的。这些特性在某些应用中的 MOT 评估中可能很有用。通过仿真，使用 T-GOSPA 准度量评估了几种贝叶斯 MOT 算法的性能。", "summary": "本文介绍了 GOSPA 和 T-GOSPA 两种新的准度量，用于评估多目标跟踪算法的性能。这些准度量是现有 GOSPA 和 T-GOSPA 度量的扩展，并引入了更大的灵活性，允许对漏检和虚警目标施加不同的惩罚成本，并且定位成本不再要求是对称的。这些特性对于特定应用中的多目标跟踪评估具有重要意义。文章通过仿真使用 T-GOSPA 准度量评估了几种贝叶斯多目标跟踪算法的性能。", "keywords": "多目标跟踪, GOSPA, T-GOSPA, 准度量, 性能评估", "comments": "本文的核心创新在于提出了具有更大灵活性的 GOSPA 和 T-GOSPA 准度量。通过允许非对称的定位成本以及对漏检和虚警目标施加不同的惩罚，这些新度量能够更好地适应实际应用中对不同错误类型的差异化需求，从而提供更精细和有用的性能评估。"}}
{"id": "2507.14017", "title": "Efficient Temporal Tokenization for Mobility Prediction with Large Language Models", "authors": ["Haoyu He", "Haozheng Luo", "Yan Chen", "Qi R. Wang"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14017v1", "summary": "We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for\nHuman Mobility), a framework that leverages large language models (LLMs) as\nspatio-temporal predictors and trajectory reasoners. RHYTHM partitions\ntrajectories into daily segments encoded as discrete tokens with hierarchical\nattention, capturing both daily and weekly dependencies while substantially\nreducing the sequence length. Token representations are enriched with\npre-computed prompt embeddings via a frozen LLM, enhancing the model's ability\nto capture interdependencies without extensive computational overhead. By\nfreezing the LLM backbone, RHYTHM achieves significant computational\nefficiency. Evaluation on three real-world datasets demonstrates a 2.4%\nimprovement in accuracy, 5.0% increase on weekends, and 24.6% reduction in\ntraining time compared to state-of-the-art methods.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14017v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于大型语言模型的高效时序分词用于出行预测", "tldr": "RHYTHM框架利用分层时序分词和冻结LLM，高效且准确地进行人类出行预测，提高了准确性并显著减少了训练时间。", "motivation": "该研究旨在通过利用大型语言模型，提高人类出行预测的准确性和计算效率，解决现有方法可能存在的效率或精度不足的问题。", "method": "RHYTHM框架将轨迹划分为每日片段，并将其编码为带有分层注意力的离散令牌，以捕获每日和每周的依赖关系，同时显著减少序列长度。它通过一个冻结的LLM，利用预先计算的提示嵌入来丰富令牌表示，从而增强模型捕获相互依赖关系的能力，并实现显著的计算效率。", "result": "在三个真实世界数据集上的评估显示，与现有最先进方法相比，RHYTHM在准确率上提高了2.4%，周末准确率提高了5.0%，训练时间减少了24.6%。", "conclusion": "所提出的RHYTHM框架有效利用LLM进行时空预测，在人类出行预测中展现出卓越的准确性和显著的计算效率。", "translation": "我们引入了RHYTHM（基于分层时序分词进行人类出行推理），这是一个利用大型语言模型（LLM）作为时空预测器和轨迹推理器的框架。RHYTHM将轨迹划分为每日片段，并编码为带有分层注意力的离散令牌，从而捕获每日和每周的依赖关系，同时大大减少了序列长度。通过冻结的LLM，令牌表示通过预先计算的提示嵌入得到丰富，增强了模型捕获相互依赖关系的能力，而不会产生大量的计算开销。通过冻结LLM骨干，RHYTHM实现了显著的计算效率。在三个真实世界数据集上的评估表明，与最先进的方法相比，准确率提高了2.4%，周末准确率提高了5.0%，训练时间减少了24.6%。", "summary": "RHYTHM是一个利用大型语言模型进行人类出行预测的新框架。它通过将轨迹分段为每日令牌并采用分层注意力，有效捕获时序依赖并缩短序列。通过使用冻结的LLM生成提示嵌入，RHYTHM在不增加大量计算开销的情况下增强了模型捕获复杂依赖的能力，并显著提高了计算效率。实验结果表明，RHYTHM在准确性和训练时间方面均优于现有方法。", "keywords": "人类出行预测, 大型语言模型, 时序分词, 时空预测, 计算效率", "comments": "这篇论文通过将大型语言模型应用于人类出行时空预测，提出了一种创新方法。其核心创新在于“分层时序分词”以及巧妙地使用“冻结LLM”生成提示嵌入，这显著降低了计算开销，同时提升了性能。该方法同时解决了准确性和效率这两个在实际出行预测中至关重要的方面。"}}
{"id": "2505.08736", "title": "Towards Foundation Models for Experimental Readout Systems Combining Discrete and Continuous Data", "authors": ["James Giroux", "Cristiano Fanelli"], "categories": ["cs.LG", "hep-ex", "nucl-ex", "physics.ins-det"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      27 pages; 18 figures", "url": "http://arxiv.org/abs/2505.08736v2", "summary": "We present a (proto) Foundation Model for Nuclear Physics, capable of\noperating on low-level detector inputs from Imaging Cherenkov Detectors at the\nfuture Electron Ion Collider. Building upon established next-token prediction\napproaches, we aim to address potential challenges such as resolution loss from\nexisting tokenization schemes and limited support for conditional generation.\nWe propose four key innovations: (i) separate vocabularies for discrete and\ncontinuous variates, combined via Causal Multi-Head Cross-Attention (CMHCA),\n(ii) continuous kinematic conditioning through prepended context embeddings,\n(iii) scalable and simple, high-resolution continuous variate tokenization\nwithout joint vocabulary inflation, and (iv) class conditional generation\nthrough a Mixture of Experts. Our model enables fast, high-fidelity generation\nof pixel and time sequences for Cherenkov photons, validated through closure\ntests in the High Performance DIRC. We also show our model generalizes to\nreconstruction tasks such as pion/kaon identification, and noise filtering, in\nwhich we show its ability to leverage fine-tuning under specific objectives.", "comment": "27 pages; 18 figures", "pdf_url": "http://arxiv.org/pdf/2505.08736v2", "cate": "cs.LG", "date": "2025-05-13", "updated": "2025-07-18", "AI": {"title_translation": "迈向结合离散和连续数据的实验读出系统基础模型", "tldr": "本文提出了一个用于核物理的（原型）基础模型，能够处理来自未来电子离子对撞机中成像切伦科夫探测器的低级探测器输入，并通过四项关键创新解决了现有分词方案的分辨率损失和条件生成支持有限等挑战，实现了切伦科夫光子像素和时间序列的快速、高保真生成，并能推广到重建任务如π/K介子识别和噪声过滤。", "motivation": "现有分词方案存在分辨率损失，且对条件生成的支持有限，这限制了核物理实验读出系统的数据处理能力。", "method": "该模型建立在现有下一词元预测方法的基础上，并引入了四项关键创新：(i) 为离散和连续变量分别设置词汇表，并通过因果多头交叉注意力（CMHCA）结合；(ii) 通过预置上下文嵌入实现连续运动学条件化；(iii) 无需联合词汇表膨胀即可实现可扩展、简单、高分辨率的连续变量分词；(iv) 通过专家混合实现类别条件生成。", "result": "该模型能够快速、高保真地生成切伦科夫光子的像素和时间序列，并通过高性能DIRC中的闭合测试进行了验证。此外，该模型还可推广应用于π/K介子识别和噪声过滤等重建任务，并展示了其在特定目标下进行微调的能力。", "conclusion": "本文提出的（原型）基础模型为核物理实验读出系统提供了一个有前景的解决方案，能够有效处理离散和连续数据，实现高保真数据生成和在重建任务中的泛化能力。", "translation": "我们提出了一个用于核物理的（原型）基础模型，能够处理来自未来电子离子对撞机中成像切伦科夫探测器的低级探测器输入。在现有下一词元预测方法的基础上，我们旨在解决潜在挑战，例如现有分词方案导致的分辨率损失和对条件生成支持有限的问题。我们提出了四项关键创新：(i) 为离散和连续变量分别设置词汇表，并通过因果多头交叉注意力（CMHCA）结合；(ii) 通过预置上下文嵌入实现连续运动学条件化；(iii) 无需联合词汇表膨胀即可实现可扩展、简单、高分辨率的连续变量分词；(iv) 通过专家混合实现类别条件生成。我们的模型能够快速、高保真地生成切伦科夫光子的像素和时间序列，并通过高性能DIRC中的闭合测试进行了验证。我们还展示了我们的模型能够推广应用于π/K介子识别和噪声过滤等重建任务，并展示了其在特定目标下进行微调的能力。", "summary": "本文介绍了一个核物理领域的（原型）基础模型，旨在处理来自未来电子离子对撞机中成像切伦科夫探测器的低级数据输入。该模型基于下一词元预测方法，通过引入四项关键创新，包括对离散和连续数据采用独立词汇表并结合因果多头交叉注意力、连续运动学条件化、高分辨率连续变量分词以及基于专家混合的类别条件生成，解决了现有方法在分辨率损失和条件生成方面的挑战。实验结果表明，该模型能实现切伦科夫光子像素和时间序列的快速、高保真生成，并能有效推广到粒子识别和噪声过滤等重建任务。", "keywords": "基础模型, 核物理, 切伦科夫探测器, 离散连续数据, 条件生成", "comments": "本文的创新点在于提出了一个能够有效结合和处理离散与连续数据的基础模型架构，这对于处理实验物理中复杂多源的数据至关重要。其引入的四项关键创新，特别是在分词和条件生成方面的改进，为构建更强大的物理数据分析模型提供了新的思路。模型在生成和重建任务中的泛化能力也显示了其潜在的广泛应用价值。"}}
{"id": "2507.13625", "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety", "authors": ["Yuxin Zhang", "Xi Wang", "Mo Hu", "Zhenyu Zhang"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      19 pages, 13 figures", "url": "http://arxiv.org/abs/2507.13625v1", "summary": "Information retrieval and question answering from safety regulations are\nessential for automated construction compliance checking but are hindered by\nthe linguistic and structural complexity of regulatory text. Many\ncompliance-related queries are multi-hop, requiring synthesis of information\nacross interlinked clauses. This poses a challenge for traditional\nretrieval-augmented generation (RAG) systems. To overcome this, we introduce\nBifrostRAG: a dual-graph RAG-integrated system that explicitly models both\nlinguistic relationships (via an Entity Network Graph) and document structure\n(via a Document Navigator Graph). This architecture powers a hybrid retrieval\nmechanism that combines graph traversal with vector-based semantic search,\nenabling large language models to reason over both the meaning and the\nstructure of the text. Evaluation on a multi-hop question dataset shows that\nBifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1\nscore of 87.3 percent. These results significantly outperform vector-only and\ngraph-only RAG baselines that represent current leading approaches. Error\nanalysis further highlights the comparative advantages of our hybrid method\nover single-modality RAGs. These findings establish BifrostRAG as a robust\nknowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid\nretrieval mechanism offers a transferable blueprint for navigating complex\ntechnical documents across knowledge-intensive engineering domains.", "comment": "19 pages, 13 figures", "pdf_url": "http://arxiv.org/pdf/2507.13625v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "BifrostRAG：弥合双知识图谱用于施工安全中的多跳问答", "tldr": "BifrostRAG是一个双图RAG集成系统，通过结合图遍历和向量语义搜索，解决了施工安全法规中多跳问答的挑战，显著优于现有方法。", "motivation": "从安全法规中检索信息和回答问题对于自动化施工合规性检查至关重要，但受限于法规文本的语言和结构复杂性。许多合规性相关查询是多跳的，需要综合互联条款中的信息，这对传统检索增强生成（RAG）系统构成了挑战。", "method": "我们引入了BifrostRAG，一个双图RAG集成系统，它明确地建模了语言关系（通过实体网络图）和文档结构（通过文档导航图）。该架构支持一种混合检索机制，结合了图遍历和基于向量的语义搜索，使大型语言模型能够同时推理文本的含义和结构。", "result": "在多跳问题数据集上的评估显示，BifrostRAG实现了92.8%的准确率、85.5%的召回率和87.3%的F1分数。这些结果显著优于代表当前领先方法的纯向量和纯图RAG基线。误差分析进一步突出了我们混合方法相对于单模态RAG的比较优势。", "conclusion": "这些发现确立了BifrostRAG作为一个强大的知识引擎，用于LLM驱动的合规性检查。其双图、混合检索机制为在知识密集型工程领域中导航复杂技术文档提供了可迁移的蓝图。", "translation": "从安全法规中检索信息和回答问题对于自动化施工合规性检查至关重要，但受限于法规文本的语言和结构复杂性。许多合规性相关查询是多跳的，需要综合互联条款中的信息。这对传统检索增强生成（RAG）系统构成了挑战。为了克服这一点，我们引入了BifrostRAG：一个双图RAG集成系统，它明确地建模了语言关系（通过实体网络图）和文档结构（通过文档导航图）。这种架构支持一种混合检索机制，结合了图遍历和基于向量的语义搜索，使大型语言模型能够同时推理文本的含义和结构。在多跳问题数据集上的评估显示，BifrostRAG实现了92.8%的准确率、85.5%的召回率和87.3%的F1分数。这些结果显著优于代表当前领先方法的纯向量和纯图RAG基线。误差分析进一步突出了我们混合方法相对于单模态RAG的比较优势。这些发现确立了BifrostRAG作为一个强大的知识引擎，用于LLM驱动的合规性检查。其双图、混合检索机制为在知识密集型工程领域中导航复杂技术文档提供了可迁移的蓝图。", "summary": "本论文介绍了BifrostRAG，一个创新的双图检索增强生成（RAG）系统，旨在解决施工安全法规中多跳问答的挑战。BifrostRAG通过结合实体网络图（建模语言关系）和文档导航图（建模文档结构）来克服传统RAG系统的局限性。它采用混合检索机制，融合了图遍历和向量语义搜索，使大型语言模型能够同时理解文本的语义和结构。实验结果表明，BifrostRAG在多跳问答任务上表现出色，其性能显著优于纯向量和纯图的RAG基线，证明了其在处理复杂技术文档方面的有效性和通用性。", "keywords": "双知识图谱, 多跳问答, 施工安全, 检索增强生成, 混合检索", "comments": "BifrostRAG的创新之处在于其双图架构和混合检索机制，能够同时处理文本的语言和结构复杂性，这对于处理多跳问答至关重要。其在施工安全领域的应用展示了解决实际工程问题的潜力，并且其设计理念具有跨知识密集型领域的通用性。"}}
{"id": "2507.13375", "title": "GAP-LA: GPU-Accelerated Performance-Driven Layer Assignment", "authors": ["Chunyuan Zhao", "Zizheng Guo", "Zuodong Zhang", "Yibo Lin"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13375v1", "summary": "Layer assignment is critical for global routing of VLSI circuits. It converts\n2D routing paths into 3D routing solutions by determining the proper metal\nlayer for each routing segments to minimize congestion and via count. As\ndifferent layers have different unit resistance and capacitance, layer\nassignment also has significant impacts to timing and power. With growing\ndesign complexity, it becomes increasingly challenging to simultaneously\noptimize timing, power, and congestion efficiently. Existing studies are mostly\nlimited to a subset of objectives. In this paper, we propose a GPU-accelerated\nperformance-driven layer assignment framework, GAP-LA, for holistic\noptimization the aforementioned objectives. Experimental results demonstrate\nthat we can achieve 0.3%-9.9% better worst negative slack (WNS) and 2.0%-5.4%\nbetter total negative slack (TNS) while maintaining power and congestion with\ncompetitive runtime compared with ISPD 2025 contest winners, especially on\ndesigns with up to 12 millions of nets.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13375v1", "cate": "cs.AR", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "GAP-LA：GPU加速的性能驱动层分配", "tldr": "GAP-LA是一个GPU加速的性能驱动层分配框架，用于同时优化VLSI电路的定时、功耗和拥塞，并在大型设计上取得了优于现有方法的性能。", "motivation": "层分配对VLSI电路的全局布线至关重要，它通过确定每个布线段的金属层来将2D布线路径转换为3D布线解决方案，以最小化拥塞和通孔数量。由于不同层的单位电阻和电容不同，层分配也对时序和功耗有显著影响。随着设计复杂性的增长，同时高效优化时序、功耗和拥塞变得越来越具挑战性。现有研究大多局限于部分目标。", "method": "本文提出了一个GPU加速的性能驱动层分配框架GAP-LA，用于全面优化上述目标。", "result": "实验结果表明，与ISPD 2025竞赛获胜者相比，我们可以在保持功耗和拥塞的同时，实现0.3%-9.9%的更优最差负时序余量（WNS）和2.0%-5.4%的更优总负时序余量（TNS），尤其是在拥有多达1200万个网络的设计上，运行时具有竞争力。", "conclusion": "GAP-LA框架能够同时优化VLSI电路的定时、功耗和拥塞，并在大型设计上取得了优于现有方法的性能，解决了现有方法在多目标优化方面的局限性。", "translation": "层分配对于VLSI电路的全局布线至关重要。它通过确定每个布线段的适当金属层，将2D布线路径转换为3D布线解决方案，以最小化拥塞和通孔数量。由于不同层具有不同的单位电阻和电容，层分配也对时序和功耗产生显著影响。随着设计复杂性的增长，同时高效优化时序、功耗和拥塞变得越来越具挑战性。现有研究大多局限于部分目标。在本文中，我们提出了一个GPU加速的性能驱动层分配框架GAP-LA，用于全面优化上述目标。实验结果表明，与ISPD 2025竞赛获胜者相比，我们可以在保持功耗和拥塞的同时，实现0.3%-9.9%的更优最差负时序余量（WNS）和2.0%-5.4%的更优总负时序余量（TNS），尤其是在拥有多达1200万个网络的设计上，运行时具有竞争力。", "summary": "本文提出了GAP-LA，一个GPU加速的性能驱动层分配框架，旨在解决VLSI电路全局布线中同时优化时序、功耗和拥塞的挑战。现有方法通常只关注部分目标。GAP-LA通过利用GPU加速实现这些目标的全面优化。实验结果表明，GAP-LA在保持功耗和拥塞的前提下，能显著改善最差负时序余量（WNS）和总负时序余量（TNS），尤其是在大规模设计上，并具有竞争力的运行时性能。", "keywords": "层分配, GPU加速, VLSI, 全局布线, 性能优化", "comments": "该论文的创新点在于提出了一个GPU加速的框架，实现了VLSI电路层分配中时序、功耗和拥塞的多目标协同优化，这在现有研究中是比较少见的。其重要性体现在能够处理日益复杂的设计，并在性能上超越了ISPD 2025竞赛的获胜方案，尤其是在大规模设计上的表现令人印象深刻。"}}
{"id": "2502.12057", "title": "Culture is Not Trivia: Sociocultural Theory for Cultural NLP", "authors": ["Naitian Zhou", "David Bamman", "Isaac L. Bleaman"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      ACL 2025 Main Conference; camera-ready version", "url": "http://arxiv.org/abs/2502.12057v2", "summary": "The field of cultural NLP has recently experienced rapid growth, driven by a\npressing need to ensure that language technologies are effective and safe\nacross a pluralistic user base. This work has largely progressed without a\nshared conception of culture, instead choosing to rely on a wide array of\ncultural proxies. However, this leads to a number of recurring limitations:\ncoarse national boundaries fail to capture nuanced differences that lay within\nthem, limited coverage restricts datasets to only a subset of usually\nhighly-represented cultures, and a lack of dynamicity results in static\ncultural benchmarks that do not change as culture evolves. In this position\npaper, we argue that these methodological limitations are symptomatic of a\ntheoretical gap. We draw on a well-developed theory of culture from\nsociocultural linguistics to fill this gap by 1) demonstrating in a case study\nhow it can clarify methodological constraints and affordances, 2) offering\ntheoretically-motivated paths forward to achieving cultural competence, and 3)\narguing that localization is a more useful framing for the goals of much\ncurrent work in cultural NLP.", "comment": "ACL 2025 Main Conference; camera-ready version", "pdf_url": "http://arxiv.org/pdf/2502.12057v2", "cate": "cs.CL", "date": "2025-02-17", "updated": "2025-07-17", "AI": {"title_translation": "文化并非琐事：文化自然语言处理的社会文化理论", "tldr": "本立场论文指出文化NLP领域因缺乏共享的文化概念而面临方法论局限，提出应引入社会文化语言学理论来填补这一理论空白，并主张将本地化作为更合适的框架。", "motivation": "文化NLP领域快速发展，但缺乏共享的文化概念，导致了粗糙的国家边界、数据集覆盖有限和文化基准缺乏动态性等方法论局限。作者认为这些是理论空白的症状。", "method": "本文通过借鉴社会文化语言学中成熟的文化理论来填补理论空白。具体方法包括：1) 通过案例研究展示其如何澄清方法论限制和可能性；2) 提供理论驱动的前进路径以实现文化能力；3) 论证本地化是当前文化NLP工作目标的更有效框架。", "result": "Not mentioned in abstract", "conclusion": "文化的共享概念对于文化NLP至关重要，社会文化理论能弥补现有理论空白，帮助克服方法论局限，并提出本地化是更合适的框架。", "translation": "文化自然语言处理（NLP）领域近期经历了快速增长，这得益于确保语言技术对多元用户群体有效和安全的迫切需求。然而，这项工作在很大程度上是在没有共享的文化概念的情况下进行的，而是选择依赖于各种文化代理。这导致了许多反复出现的局限性：粗糙的国家边界未能捕捉到其内部的细微差异，有限的覆盖范围将数据集限制在通常高度代表性文化的一个子集，以及缺乏动态性导致静态的文化基准，这些基准不会随着文化演变而变化。在这篇立场论文中，我们认为这些方法论上的局限性是理论空白的症状。我们借鉴社会文化语言学中成熟的文化理论来填补这一空白，具体做法包括：1）在一个案例研究中展示它如何澄清方法论的限制和可能性；2）提供理论驱动的前进路径以实现文化能力；3）论证本地化是当前文化NLP中许多工作目标的一个更有用的框架。", "summary": "本立场论文指出，文化NLP领域缺乏统一的文化概念，导致了方法论上的多重局限，如粗糙的国家边界、数据集覆盖不足和文化基准静态化。作者认为这些问题源于理论空白，并提出应引入社会文化语言学中的文化理论来解决。论文通过案例研究、提供理论驱动的实现文化能力路径，并主张将本地化作为文化NLP工作更合适的框架，以期弥补这一理论缺陷。", "keywords": "文化NLP, 社会文化理论, 理论空白, 本地化, 文化能力", "comments": "本文的创新之处在于它明确指出了文化NLP领域当前面临的核心问题——缺乏统一的文化概念，并提出从社会文化语言学中引入成熟的理论来填补这一空白。这对于指导未来文化NLP的研究方向具有重要意义，因为它促使研究者从更深层次的理论角度审视文化在语言技术中的作用，而非仅仅依赖于表面的文化代理。将“本地化”作为更合适的框架也为该领域提供了新的视角。"}}
{"id": "2507.14024", "title": "Moodifier: MLLM-Enhanced Emotion-Driven Image Editing", "authors": ["Jiarong Ye", "Sharon X. Huang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14024v1", "summary": "Bridging emotions and visual content for emotion-driven image editing holds\ngreat potential in creative industries, yet precise manipulation remains\nchallenging due to the abstract nature of emotions and their varied\nmanifestations across different contexts. We tackle this challenge with an\nintegrated approach consisting of three complementary components. First, we\nintroduce MoodArchive, an 8M+ image dataset with detailed hierarchical\nemotional annotations generated by LLaVA and partially validated by human\nevaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned\non MoodArchive to translate abstract emotions into specific visual attributes.\nThird, we propose Moodifier, a training-free editing model leveraging\nMoodifyCLIP and multimodal large language models (MLLMs) to enable precise\nemotional transformations while preserving content integrity. Our system works\nacross diverse domains such as character expressions, fashion design, jewelry,\nand home d\\'ecor, enabling creators to quickly visualize emotional variations\nwhile preserving identity and structure. Extensive experimental evaluations\nshow that Moodifier outperforms existing methods in both emotional accuracy and\ncontent preservation, providing contextually appropriate edits. By linking\nabstract emotions to concrete visual changes, our solution unlocks new\npossibilities for emotional content creation in real-world applications. We\nwill release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier\ncode and demo publicly available upon acceptance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14024v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Moodifier：MLLM增强的情绪驱动图像编辑", "tldr": "Moodifier是一个利用多模态大语言模型（MLLMs）实现情绪驱动图像编辑的训练无关模型，它通过一个大型情感标注数据集和专门的视觉语言模型，克服了情感抽象性带来的挑战。", "motivation": "在创意产业中，将情感与视觉内容结合进行情绪驱动的图像编辑具有巨大潜力，但由于情感的抽象性和在不同语境下的多样表现，精确操作仍然具有挑战性。", "method": "本研究采用包含三个互补组件的集成方法：首先，引入了MoodArchive，一个包含800多万张图像的大型数据集，具有由LLaVA生成并部分经人工验证的详细分层情感标注；其次，开发了MoodifyCLIP，一个在MoodArchive上微调的视觉语言模型，用于将抽象情感转化为具体的视觉属性；最后，提出了Moodifier，一个利用MoodifyCLIP和多模态大语言模型（MLLMs）的训练无关编辑模型，以实现精确的情感转换，同时保持内容完整性。", "result": "广泛的实验评估表明，Moodifier在情感准确性和内容保持方面均优于现有方法，并能提供符合上下文的编辑。该系统适用于角色表情、时尚设计、珠宝和家居装饰等不同领域，使创作者能够快速可视化情感变化，同时保持身份和结构。", "conclusion": "通过将抽象情感与具体的视觉变化联系起来，Moodifier的解决方案为现实世界应用中的情感内容创作开启了新的可能性。", "translation": "连接情感与视觉内容进行情绪驱动的图像编辑在创意产业中具有巨大潜力，然而，由于情感的抽象性及其在不同语境下的多样表现，精确操作仍然充满挑战。我们通过一个包含三个互补组件的集成方法来应对这一挑战。首先，我们引入了MoodArchive，一个拥有800多万张图像的数据集，其中包含由LLaVA生成并由人工评估者部分验证的详细分层情感注释。其次，我们开发了MoodifyCLIP，一个在MoodArchive上微调的视觉语言模型，用于将抽象情感转化为特定的视觉属性。第三，我们提出了Moodifier，一个利用MoodifyCLIP和多模态大语言模型（MLLMs）的训练无关编辑模型，以实现精确的情感转换，同时保持内容完整性。我们的系统适用于角色表情、时尚设计、珠宝和家居装饰等不同领域，使创作者能够快速可视化情感变化，同时保持身份和结构。广泛的实验评估表明，Moodifier在情感准确性和内容保持方面均优于现有方法，并能提供符合上下文的编辑。通过将抽象情感与具体的视觉变化联系起来，我们的解决方案为现实世界应用中的情感内容创作开启了新的可能性。我们将在论文被接受后发布MoodArchive数据集、MoodifyCLIP模型，并公开Moodifier的代码和演示。", "summary": "本研究提出了一种名为Moodifier的情绪驱动图像编辑系统，旨在解决情感抽象性带来的挑战。该系统包含三部分：构建了大规模情感标注数据集MoodArchive；开发了视觉语言模型MoodifyCLIP，用于将情感映射到视觉属性；以及提出了一个训练无关的编辑模型Moodifier，它结合了MoodifyCLIP和多模态大语言模型，实现了精确的情感转换和内容保持。实验证明Moodifier在情感准确性和内容保持方面优于现有方法，并在多个创意领域展现了实用性。", "keywords": "情绪驱动图像编辑, MLLM, 视觉语言模型, 数据集, 内容创作", "comments": "该论文的创新之处在于其集成方法，特别是通过构建大规模情感数据集和训练专门的视觉语言模型，成功将抽象的情感概念转化为可操作的视觉属性。Moodifier作为一个训练无关的编辑模型，结合了MLLMs的强大能力，实现了高效且高质量的情绪驱动图像编辑，这对于创意产业具有重要的实际应用价值。其在多领域的适用性也显示了该方法的通用性和潜力。"}}
{"id": "2507.13354", "title": "Physical models realizing the transformer architecture of large language models", "authors": ["Zeqian Chen"], "categories": ["cs.LG", "cs.AI", "cs.CL", "math-ph", "math.MP"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      6 pages", "url": "http://arxiv.org/abs/2507.13354v1", "summary": "The introduction of the transformer architecture in 2017 (cf.\\cite{VSP2017})\nmarked the most striking advancement in natural language processing. The\ntransformer is a model architecture relying entirely on an attention mechanism\nto draw global dependencies between input and output. However, we believe there\nis a gap in our theoretical understanding of what the transformer is, and why\nit works physically. In this paper, from a physical perspective on modern\nchips, we construct physical models in the Fock space over the Hilbert space of\ntokens realizing large language models based on a transformer architecture as\nopen quantum systems. Our physical models underlie the transformer architecture\nfor large language models.", "comment": "6 pages", "pdf_url": "http://arxiv.org/pdf/2507.13354v1", "cate": "cs.LG", "date": "2025-05-21", "updated": "2025-05-21", "AI": {"title_translation": "实现大型语言模型Transformer架构的物理模型", "tldr": "本文从物理学角度构建了在Fock空间中基于开放量子系统实现大型语言模型Transformer架构的物理模型，以填补对Transformer物理本质理解的空白。", "motivation": "尽管Transformer架构在自然语言处理领域取得了显著进展，但作者认为在理论上对Transformer的物理本质及其工作原理缺乏深入理解。", "method": "本文从现代芯片的物理视角出发，在令牌（token）的希尔伯特空间上的福克空间中构建了物理模型，将基于Transformer架构的大型语言模型实现为开放量子系统。", "result": "所构建的物理模型构成了大型语言模型Transformer架构的基础。", "conclusion": "本文提出的物理模型在福克空间中将大型语言模型中的Transformer架构实现为开放量子系统。", "translation": "Transformer架构于2017年引入（参见\ncite{VSP2017}），标志着自然语言处理领域最引人注目的进展。\nTransformer是一种完全依赖注意力机制来捕捉输入和输出之间全局依赖关系的模型架构。然而，我们认为在理论上我们对Transformer是什么以及它为何在物理上有效存在理解上的空白。在本文中，我们从现代芯片的物理角度出发，在令牌（token）的希尔伯特空间上的福克空间中构建了物理模型，将基于Transformer架构的大型语言模型实现为开放量子系统。我们的物理模型构成了大型语言模型Transformer架构的基础。", "summary": "本文旨在弥补对Transformer架构物理本质理解的不足。研究者从物理学角度，在令牌的希尔伯特空间上的福克空间中构建了将大型语言模型中的Transformer架构实现为开放量子系统的物理模型，这些模型构成了Transformer架构的物理基础。", "keywords": "Transformer, 物理模型, 大型语言模型, 开放量子系统, 福克空间", "comments": "本文的创新之处在于其独特的跨学科方法，将物理学特别是量子力学概念应用于理解大型语言模型的核心Transformer架构。这种方法可能为Transformer的工作原理提供全新的理论视角，并可能启发未来在物理硬件层面优化AI模型的设计。然而，抽象中并未详细说明这些物理模型如何具体解释注意力机制或其计算优势，这可能是未来研究的重点。"}}
{"id": "2506.01487", "title": "FDSG: Forecasting Dynamic Scene Graphs", "authors": ["Yi Yang", "Yuren Cong", "Hao Cheng", "Bodo Rosenhahn", "Michael Ying Yang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      16 pages, 8 figures, 12 tables", "url": "http://arxiv.org/abs/2506.01487v2", "summary": "Dynamic scene graph generation extends scene graph generation from images to\nvideos by modeling entity relationships and their temporal evolution. However,\nexisting methods either generate scene graphs from observed frames without\nexplicitly modeling temporal dynamics, or predict only relationships while\nassuming static entity labels and locations. These limitations hinder effective\nextrapolation of both entity and relationship dynamics, restricting video scene\nunderstanding. We propose Forecasting Dynamic Scene Graphs (FDSG), a novel\nframework that predicts future entity labels, bounding boxes, and\nrelationships, for unobserved frames, while also generating scene graphs for\nobserved frames. Our scene graph forecast module leverages query decomposition\nand neural stochastic differential equations to model entity and relationship\ndynamics. A temporal aggregation module further refines predictions by\nintegrating forecasted and observed information via cross-attention. To\nbenchmark FDSG, we introduce Scene Graph Forecasting, a new task for full\nfuture scene graph prediction. Experiments on Action Genome show that FDSG\noutperforms state-of-the-art methods on dynamic scene graph generation, scene\ngraph anticipation, and scene graph forecasting. Codes will be released upon\npublication.", "comment": "16 pages, 8 figures, 12 tables", "pdf_url": "http://arxiv.org/pdf/2506.01487v2", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-18", "AI": {"title_translation": "FDSG：预测动态场景图", "tldr": "FDSG是一个新颖的框架，用于预测未观测帧的未来实体标签、边界框和关系，同时为观测帧生成场景图，通过查询分解和神经随机微分方程建模动态，并在Action Genome上超越现有技术。", "motivation": "现有动态场景图生成方法存在局限性：要么从观测帧生成场景图而未明确建模时间动态，要么只预测关系而假设实体标签和位置静态。这些限制阻碍了实体和关系动态的有效外推，从而限制了视频场景理解。", "method": "本文提出了FDSG（Forecasting Dynamic Scene Graphs）框架，用于预测未来实体标签、边界框和关系，并为观测帧生成场景图。其场景图预测模块利用查询分解和神经随机微分方程来建模实体和关系的动态。一个时间聚合模块通过交叉注意力整合预测和观测信息，进一步完善预测。本文还引入了“场景图预测”这一新任务，用于完整的未来场景图预测。", "result": "在Action Genome数据集上的实验表明，FDSG在动态场景图生成、场景图预期和场景图预测任务上均优于现有最先进方法。", "conclusion": "FDSG框架通过预测未来实体和关系动态，显著提升了视频场景理解能力，并在多项任务上取得了优异性能。", "translation": "动态场景图生成通过建模实体关系及其时间演变，将场景图生成从图像扩展到视频。然而，现有方法要么从观测帧生成场景图而未明确建模时间动态，要么只预测关系而假设实体标签和位置静态。这些局限性阻碍了实体和关系动态的有效外推，从而限制了视频场景理解。我们提出了预测动态场景图（FDSG），这是一个新颖的框架，用于预测未观测帧的未来实体标签、边界框和关系，同时为观测帧生成场景图。我们的场景图预测模块利用查询分解和神经随机微分方程来建模实体和关系动态。一个时间聚合模块通过交叉注意力整合预测和观测信息，进一步完善预测。为了对FDSG进行基准测试，我们引入了场景图预测，这是一项针对完整未来场景图预测的新任务。在Action Genome上的实验表明，FDSG在动态场景图生成、场景图预期和场景图预测方面均优于最先进的方法。代码将在发布后提供。", "summary": "本文提出了FDSG（Forecasting Dynamic Scene Graphs），一个用于视频的动态场景图生成与预测框架。针对现有方法无法有效外推实体和关系动态的局限性，FDSG能够预测未观测帧的未来实体标签、边界框和关系，并为观测帧生成场景图。其核心在于利用查询分解和神经随机微分方程建模动态，并通过时间聚合模块整合信息。为评估FDSG，文章引入了“场景图预测”新任务，并在Action Genome数据集上验证了FDSG在动态场景图生成、预期和预测任务上的优越性能。", "keywords": "动态场景图, 场景图预测, 神经随机微分方程, 视频理解, FDSG", "comments": "FDSG的创新之处在于其首次提出了完整的未来场景图预测任务，并利用神经随机微分方程来建模动态，这为视频理解提供了一个更全面的视角。其能够同时预测实体和关系的时空演变，解决了现有方法仅关注部分动态的不足。这项工作对视频内容理解、行为识别和预测等领域具有重要意义。"}}
{"id": "2412.18781", "title": "Robustness Evaluation of Offline Reinforcement Learning for Robot Control Against Action Perturbations", "authors": ["Shingo Ayabe", "Takuto Otomo", "Hiroshi Kera", "Kazuhiko Kawamoto"], "categories": ["cs.RO", "cs.LG"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      22 pages, 6 figures", "url": "http://arxiv.org/abs/2412.18781v2", "summary": "Offline reinforcement learning, which learns solely from datasets without\nenvironmental interaction, has gained attention. This approach, similar to\ntraditional online deep reinforcement learning, is particularly promising for\nrobot control applications. Nevertheless, its robustness against real-world\nchallenges, such as joint actuator faults in robots, remains a critical\nconcern. This study evaluates the robustness of existing offline reinforcement\nlearning methods using legged robots from OpenAI Gym based on average episodic\nrewards. For robustness evaluation, we simulate failures by incorporating both\nrandom and adversarial perturbations, representing worst-case scenarios, into\nthe joint torque signals. Our experiments show that existing offline\nreinforcement learning methods exhibit significant vulnerabilities to these\naction perturbations and are more vulnerable than online reinforcement learning\nmethods, highlighting the need for more robust approaches in this field.", "comment": "22 pages, 6 figures", "pdf_url": "http://arxiv.org/pdf/2412.18781v2", "cate": "cs.RO", "date": "2024-12-25", "updated": "2025-07-18", "AI": {"title_translation": "离线强化学习在机器人控制中对抗动作扰动的鲁棒性评估", "tldr": "本研究评估了离线强化学习在机器人控制中对抗动作扰动的鲁棒性，发现现有方法对此类扰动非常脆弱，甚至比在线强化学习更脆弱。", "motivation": "离线强化学习在机器人控制中具有潜力，但其在现实世界挑战（如机器人关节执行器故障）面前的鲁棒性是一个关键问题，因此需要进行评估。", "method": "本研究使用OpenAI Gym中的腿式机器人，通过平均 эпизодические 奖励来评估现有离线强化学习方法的鲁棒性。为模拟故障，在关节扭矩信号中加入了随机和对抗性扰动，代表最坏情况。", "result": "实验表明，现有离线强化学习方法对动作扰动表现出显著的脆弱性，并且比在线强化学习方法更脆弱。", "conclusion": "现有离线强化学习方法在动作扰动面前鲁棒性不足，亟需开发更鲁棒的方法。", "translation": "离线强化学习，即仅从数据集学习而不与环境交互的方法，已受到关注。这种方法与传统的在线深度强化学习类似，在机器人控制应用中尤其有前景。然而，其对抗现实世界挑战（如机器人关节执行器故障）的鲁棒性仍然是一个关键问题。本研究使用OpenAI Gym中的腿式机器人，基于平均 эпизодические 奖励，评估了现有离线强化学习方法的鲁棒性。为了进行鲁棒性评估，我们通过在关节扭矩信号中加入随机和对抗性扰动（代表最坏情况）来模拟故障。我们的实验表明，现有离线强化学习方法对这些动作扰动表现出显著的脆弱性，并且比在线强化学习方法更脆弱，这凸显了该领域需要更鲁棒的方法。", "summary": "本研究评估了离线强化学习方法在机器人控制中对抗动作扰动的鲁棒性。通过在OpenAI Gym的腿式机器人上引入随机和对抗性关节扭矩扰动，实验发现现有离线强化学习方法对这些扰动表现出显著的脆弱性，且鲁棒性不如在线强化学习，强调了开发更鲁棒离线强化学习方法的必要性。", "keywords": "离线强化学习, 机器人控制, 鲁棒性, 动作扰动, 关节执行器故障", "comments": "这项研究揭示了离线强化学习在实际机器人应用中面临的一个重要挑战，即其对动作扰动的脆弱性。它为未来研究指明了方向，即开发更具鲁棒性的离线RL算法以适应真实世界的复杂性和不确定性。"}}
{"id": "2507.13623", "title": "MD-OFDM: An Energy-Efficient and Low-PAPR MIMO-OFDM Variant for Resource-Constrained Applications", "authors": ["Rahul Gulia"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13623v1", "summary": "Orthogonal Frequency Division Multiplexing (OFDM) combined with\nMultiple-Input Multiple-Output (MIMO) techniques forms the backbone of modern\nwireless communication systems. While offering high spectral efficiency and\nrobustness, conventional MIMO-OFDM, especially with complex equalizers like\nMinimum Mean Square Error (MMSE), suffers from high Peak-to-Average Power Ratio\n(PAPR) and significant power consumption due to multiple active Radio Frequency\n(RF) chains. This paper proposes and mathematically models an alternative\nsystem, termed Multi-Dimensional OFDM (MD-OFDM), which employs a per-subcarrier\ntransmit antenna selection strategy. By activating only one transmit antenna\nfor each subcarrier, MD-OFDM aims to reduce PAPR, lower power consumption, and\nimprove Bit Error Rate (BER) performance. We provide detailed mathematical\nformulations for BER, Energy Efficiency (EE), and PAPR, and discuss the\nsuitability of MD-OFDM for various applications, particularly in\nenergy-constrained and cost-sensitive scenarios such as the Internet of Things\n(IoT) and Low-Power Wide Area Networks (LPWAN). Simulation results demonstrate\nthat MD-OFDM achieves superior BER and significantly lower PAPR compared to\nMMSE MIMO, albeit with a trade-off in peak overall energy efficiency due to\nreduced spectral multiplexing.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13623v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "MD-OFDM：一种用于资源受限应用的节能低峰均功率比MIMO-OFDM变体", "tldr": "MD-OFDM是一种新型MIMO-OFDM变体，通过每子载波天线选择策略，旨在解决传统MIMO-OFDM的高PAPR和高功耗问题。它在误码率（BER）和PAPR方面表现优于MMSE MIMO，但峰值能量效率（EE）有所降低，适用于物联网和低功耗广域网等资源受限场景。", "motivation": "传统的MIMO-OFDM系统，特别是使用复杂均衡器如MMSE时，由于多个有源射频链，存在高峰均功率比（PAPR）和显著功耗的问题。", "method": "本文提出并数学建模了一种名为多维OFDM（MD-OFDM）的替代系统。该系统采用每子载波发射天线选择策略，即每个子载波仅激活一个发射天线。论文还提供了BER、EE和PAPR的详细数学公式。", "result": "仿真结果表明，与MMSE MIMO相比，MD-OFDM实现了更优异的误码率（BER）和显著更低的峰均功率比（PAPR）。然而，由于频谱复用减少，其峰值整体能量效率（EE）有所权衡。", "conclusion": "MD-OFDM是一种适用于物联网（IoT）和低功耗广域网（LPWAN）等能源受限和成本敏感场景的有效MIMO-OFDM变体，它在降低PAPR和提高BER方面表现出色，尽管牺牲了部分峰值能量效率。", "translation": "正交频分复用（OFDM）结合多输入多输出（MIMO）技术构成了现代无线通信系统的骨干。虽然提供了高频谱效率和鲁棒性，但传统的MIMO-OFDM，特别是使用最小均方误差（MMSE）等复杂均衡器时，由于多个有源射频（RF）链，存在高峰均功率比（PAPR）和显著的功耗问题。本文提出并数学建模了一种替代系统，称为多维OFDM（MD-OFDM），它采用每子载波发射天线选择策略。通过为每个子载波仅激活一个发射天线，MD-OFDM旨在降低PAPR，减少功耗，并改善误码率（BER）性能。我们提供了BER、能量效率（EE）和PAPR的详细数学公式，并讨论了MD-OFDM在各种应用中的适用性，特别是在物联网（IoT）和低功耗广域网（LPWAN）等能源受限和成本敏感的场景中。仿真结果表明，与MMSE MIMO相比，MD-OFDM实现了更优异的BER和显著更低的PAPR，尽管由于频谱复用减少，其峰值整体能量效率有所权衡。", "summary": "本文提出了一种名为多维OFDM（MD-OFDM）的MIMO-OFDM变体，旨在解决传统MIMO-OFDM在高PAPR和高功耗方面的挑战。MD-OFDM通过采用每子载波发射天线选择策略，仅为每个子载波激活一个发射天线，从而有效降低了PAPR，减少了功耗，并改善了误码率（BER）性能。研究详细探讨了其在能源受限和成本敏感应用（如IoT和LPWAN）中的适用性，并提供了BER、能量效率和PAPR的数学模型。仿真结果证实，MD-OFDM在BER和PAPR方面优于传统的MMSE MIMO，但以峰值能量效率的降低为代价。", "keywords": "MD-OFDM, MIMO-OFDM, 低PAPR, 能量效率, 物联网, 天线选择", "comments": "这项研究提出了一种新颖的MD-OFDM方案，通过智能的天线选择策略有效解决了传统MIMO-OFDM在PAPR和功耗方面的痛点。其创新性在于将天线选择应用于子载波层面，针对性地优化了资源受限场景的性能。尽管存在峰值能量效率的权衡，但其在降低PAPR和提高BER方面的显著优势，使其在物联网和低功耗网络等领域具有重要的应用潜力。"}}
{"id": "2304.06049", "title": "Equivalent and Compact Representations of Neural Network Controllers With Decision Trees", "authors": ["Kevin Chang", "Nathan Dahlin", "Rahul Jain", "Pierluigi Nuzzo"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2304.06049v3", "summary": "Over the past decade, neural network (NN)-based controllers have demonstrated\nremarkable efficacy in a variety of decision-making tasks. However, their\nblack-box nature and the risk of unexpected behaviors pose a challenge to their\ndeployment in real-world systems requiring strong guarantees of correctness and\nsafety. We address these limitations by investigating the transformation of\nNN-based controllers into equivalent soft decision tree (SDT)-based controllers\nand its impact on verifiability. In contrast to existing work, we focus on\ndiscrete-output NN controllers including rectified linear unit (ReLU)\nactivation functions as well as argmax operations. We then devise an exact yet\nefficient transformation algorithm which automatically prunes redundant\nbranches. We first demonstrate the practical efficacy of the transformation\nalgorithm applied to an autonomous driving NN controller within OpenAI Gym's\nCarRacing environment. Subsequently, we evaluate our approach using two\nbenchmarks from the OpenAI Gym environment. Our results indicate that the SDT\ntransformation can benefit formal verification, showing runtime improvements of\nup to $21 \\times$ and $2 \\times$ for MountainCar-v0 and CartPole-v1,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2304.06049v3", "cate": "cs.LG", "date": "2023-04-11", "updated": "2025-07-18", "AI": {"title_translation": "神经网络控制器与决策树的等价紧凑表示", "tldr": "将黑盒神经网络控制器转换为可验证的软决策树，提高形式化验证效率。", "motivation": "神经网络控制器在实际应用中存在黑盒性质和意外行为风险，需要保证正确性和安全性。", "method": "研究将基于神经网络的控制器转换为等价的基于软决策树（SDT）的控制器，并设计了一种精确且高效的转换算法，该算法能自动剪枝冗余分支，特别关注具有ReLU激活函数和argmax操作的离散输出NN控制器。", "result": "该转换算法成功应用于OpenAI Gym的CarRacing环境中的自动驾驶NN控制器。在MountainCar-v0和CartPole-v1基准测试中，SDT转换显著提升了形式化验证的运行时效率，分别高达21倍和2倍。", "conclusion": "将神经网络控制器转换为软决策树可以有效提升形式化验证的效率，有助于解决神经网络的黑盒问题，提高其在需要高安全保障系统中的部署。", "translation": "在过去十年中，基于神经网络（NN）的控制器在各种决策任务中展现出卓越的功效。然而，其黑盒性质以及意外行为的风险给它们在需要强大正确性和安全性保证的实际系统中的部署带来了挑战。我们通过研究将基于NN的控制器转换为等价的基于软决策树（SDT）的控制器及其对可验证性的影响来解决这些限制。与现有工作不同，我们专注于包括修正线性单元（ReLU）激活函数以及argmax操作的离散输出NN控制器。然后，我们设计了一种精确而高效的转换算法，该算法能自动剪枝冗余分支。我们首先在OpenAI Gym的CarRacing环境中的自动驾驶NN控制器上演示了该转换算法的实际功效。随后，我们使用OpenAI Gym环境中的两个基准评估了我们的方法。我们的结果表明，SDT转换有利于形式化验证，在MountainCar-v0和CartPole-v1上分别显示出高达21倍和2倍的运行时改进。", "summary": "本文提出一种将黑盒神经网络控制器转换为等价的软决策树控制器的方法，以解决神经网络在实际应用中的可验证性问题。该方法专注于离散输出的神经网络，并开发了一种高效的转换算法。实验结果表明，这种转换显著提升了形式化验证的效率，验证运行时在不同基准上提高了2到21倍。", "keywords": "神经网络控制器, 软决策树, 形式化验证, 黑盒, 等价转换", "comments": "本文的创新点在于提出了一种将具有ReLU和argmax操作的离散输出神经网络控制器转换为等价软决策树的精确高效算法，并证明了其在提高形式化验证效率方面的显著优势，为解决神经网络的黑盒问题提供了一条有效途径。"}}
{"id": "2505.20015", "title": "On the class of coding optimality of human languages and the origins of Zipf's law", "authors": ["Ramon Ferrer-i-Cancho"], "categories": ["cs.CL", "physics.soc-ph"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      typos corrected; discussion enhanced", "url": "http://arxiv.org/abs/2505.20015v4", "summary": "Here we present a new class of optimality for coding systems. Members of that\nclass are displaced linearly from optimal coding and thus exhibit Zipf's law,\nnamely a power-law distribution of frequency ranks. Within that class, Zipf's\nlaw, the size-rank law and the size-probability law form a group-like\nstructure. We identify human languages that are members of the class. All\nlanguages showing sufficient agreement with Zipf's law are potential members of\nthe class. In contrast, there are communication systems in other species that\ncannot be members of that class for exhibiting an exponential distribution\ninstead but dolphins and humpback whales might. We provide a new insight into\nplots of frequency versus rank in double logarithmic scale. For any system, a\nstraight line in that scale indicates that the lengths of optimal codes under\nnon-singular coding and under uniquely decodable encoding are displaced by a\nlinear function whose slope is the exponent of Zipf's law. For systems under\ncompression and constrained to be uniquely decodable, such a straight line may\nindicate that the system is coding close to optimality. We provide support for\nthe hypothesis that Zipf's law originates from compression and define testable\nconditions for the emergence of Zipf's law in compressing systems.", "comment": "typos corrected; discussion enhanced", "pdf_url": "http://arxiv.org/pdf/2505.20015v4", "cate": "cs.CL", "date": "2025-05-26", "updated": "2025-07-18", "AI": {"title_translation": "关于人类语言编码最优性类别与齐夫定律起源的研究", "tldr": "本文提出了一种新的编码系统最优性类别，该类别的成员与最优编码呈线性偏离，并表现出齐夫定律。研究发现人类语言属于此类，并提出齐夫定律可能源于压缩。", "motivation": "本文旨在提出一种新的编码系统最优性类别，并探索齐夫定律的起源及其与人类语言的关系。", "method": "论文提出了一种新的编码系统最优性类别，该类别中的成员与最优编码呈线性偏离并表现出齐夫定律。通过分析在双对数尺度下频率与排名的图，揭示了直线表示最优码长与线性函数之间的关系，并以此支持齐夫定律源于压缩的假说。", "result": "1. 提出了一种新的编码系统最优性类别，其成员与最优编码呈线性偏离，并表现出齐夫定律。2. 在该类别中，齐夫定律、大小-排名定律和大小-概率定律形成群状结构。3. 识别出人类语言是该类别的成员，所有与齐夫定律充分吻合的语言都是潜在成员。4. 某些物种的通信系统可能不属于该类别，但海豚和座头鲸可能属于。5. 在双对数尺度下，频率与排名的图上的一条直线表明最优码长被一个斜率为齐夫定律指数的线性函数所取代。6. 对于受压缩且唯一可解码的系统，这样的直线可能表明系统编码接近最优。", "conclusion": "论文支持齐夫定律源于压缩的假说，并为压缩系统中齐夫定律的出现定义了可测试的条件。", "translation": "在此，我们提出了一种新的编码系统最优性类别。该类别的成员与最优编码呈线性偏离，因此表现出齐夫定律，即频率排名的幂律分布。在该类别中，齐夫定律、大小-排名定律和大小-概率定律形成一个群状结构。我们识别出人类语言是该类别的成员。所有与齐夫定律表现出足够一致性的语言都是该类别的潜在成员。相比之下，其他物种中的通信系统因表现出指数分布而不能成为该类别的成员，但海豚和座头鲸可能可以。我们对双对数尺度下频率与排名图提供了新的见解。对于任何系统，在该尺度下的一条直线表明在非奇异编码和唯一可解码编码下最优码的长度被一个斜率为齐夫定律指数的线性函数所取代。对于受压缩且唯一可解码的系统，这样一条直线可能表明系统编码接近最优。我们为齐夫定律源于压缩的假说提供了支持，并定义了压缩系统中齐夫定律出现的、可测试的条件。", "summary": "本文提出了一种新的编码系统最优性类别，其特征在于成员与最优编码呈线性偏离并遵循齐夫定律。研究发现人类语言属于此类别，并探讨了齐夫定律、大小-排名定律和大小-概率定律在该类别中形成的群状结构。论文还通过分析双对数尺度下的频率-排名图，揭示了齐夫定律与编码最优性之间的关系，并提出齐夫定律可能源于信息压缩，同时定义了可测试的条件。", "keywords": "齐夫定律, 编码最优性, 人类语言, 信息压缩, 幂律分布", "comments": "这篇论文提出了一个关于编码系统最优性的新颖视角，将齐夫定律与信息压缩和线性偏离最优编码联系起来，为理解人类语言和其他通信系统中的统计规律提供了新的理论框架。其创新点在于将齐夫定律的起源归因于压缩机制，并提供了可测试的条件，这对于信息论、语言学和生物学领域都具有重要意义。"}}
{"id": "2305.14080", "title": "Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and Privacy Challenges", "authors": ["Efe Bozkir", "Süleyman Özdel", "Mengdi Wang", "Brendan David-John", "Hong Gao", "Kevin Butler", "Eakta Jain", "Enkelejda Kasneci"], "categories": ["cs.HC", "cs.AI", "cs.CR", "cs.GR", "cs.LG"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      This work has been submitted to the IEEE for possible publication", "url": "http://arxiv.org/abs/2305.14080v2", "summary": "The latest developments in computer hardware, sensor technologies, and\nartificial intelligence can make virtual reality (VR) and virtual spaces an\nimportant part of human everyday life. Eye tracking offers not only a\nhands-free way of interaction but also the possibility of a deeper\nunderstanding of human visual attention and cognitive processes in VR. Despite\nthese possibilities, eye-tracking data also reveals users' privacy-sensitive\nattributes when combined with the information about the presented stimulus. To\naddress all these possibilities and potential privacy issues, in this survey,\nwe first cover major works in eye tracking, VR, and privacy areas between 2012\nand 2022. While eye tracking in the VR part covers the complete pipeline of\neye-tracking methodology from pupil detection and gaze estimation to offline\nuse of the data and analyses, as for privacy and security, we focus on\neye-based authentication as well as computational methods to preserve the\nprivacy of individuals and their eye-tracking data in VR. Later, considering\nall of these, we draw three main directions for the research community by\nfocusing on privacy challenges. In summary, this survey provides an extensive\nliterature review of the utmost possibilities with eye tracking in VR and the\nprivacy implications of those possibilities.", "comment": "This work has been submitted to the IEEE for possible publication", "pdf_url": "http://arxiv.org/pdf/2305.14080v2", "cate": "cs.HC", "date": "2023-05-23", "updated": "2025-07-18", "AI": {"title_translation": "眼动追踪虚拟现实：方法与隐私挑战的综合调查", "tldr": "这篇综述全面回顾了2012年至2022年间眼动追踪VR的方法及其带来的隐私挑战，并提出了未来的研究方向。", "motivation": "随着VR技术的发展，眼动追踪在VR中提供了交互和理解用户行为的潜力，但同时也带来了用户隐私泄露的风险。因此，需要对眼动追踪VR的方法和隐私挑战进行全面梳理。", "method": "本文对2012年至2022年间眼动追踪、VR和隐私领域的主要工作进行了综述。在眼动追踪VR部分，涵盖了从瞳孔检测、注视估计到数据离线使用和分析的完整方法论流程。在隐私和安全方面，重点关注了基于眼睛的认证以及保护个人及其眼动追踪数据隐私的计算方法。", "result": "综述了眼动追踪VR的各种可能性及其隐私影响，并基于此提出了未来研究的三个主要方向，重点关注隐私挑战。", "conclusion": "这篇综述对眼动追踪VR的巨大潜力及其隐私影响进行了广泛的文献回顾，并为研究界提出了未来关注隐私挑战的方向。", "translation": "计算机硬件、传感器技术和人工智能的最新发展使得虚拟现实（VR）和虚拟空间成为人类日常生活中重要的一部分。眼动追踪不仅提供了一种免手操作的交互方式，还使得在VR中更深入地理解人类视觉注意力和认知过程成为可能。尽管有这些可能性，但眼动追踪数据与所呈现刺激的信息相结合时，也会揭示用户的隐私敏感属性。为了解决所有这些可能性和潜在的隐私问题，在这项调查中，我们首先涵盖了2012年至2022年间眼动追踪、VR和隐私领域的主要工作。VR中的眼动追踪部分涵盖了眼动追踪方法的完整流程，从瞳孔检测和注视估计到数据的离线使用和分析；至于隐私和安全，我们专注于基于眼睛的认证以及在VR中保护个人及其眼动追踪数据隐私的计算方法。之后，考虑到所有这些，我们通过关注隐私挑战，为研究社区提出了三个主要方向。总而言之，这项调查对VR中眼动追踪的极大可能性及其隐私影响进行了广泛的文献回顾。", "summary": "这篇综述全面回顾了2012年至2022年间眼动追踪在虚拟现实（VR）中的应用方法及其带来的隐私挑战。它详细探讨了眼动追踪从数据采集到分析的整个流程，并着重分析了基于眼睛的认证和隐私保护计算方法。文章还提出了未来研究在隐私挑战方面的三个主要方向。", "keywords": "眼动追踪, 虚拟现实, 隐私, 综述, 数据安全", "comments": "这篇综述的重要性在于它系统地梳理了眼动追踪VR领域的技术发展和随之而来的隐私问题，为研究人员提供了全面的视角。其创新之处在于将方法论与隐私挑战相结合，并指明了未来的研究方向，对该领域的发展具有指导意义。"}}
{"id": "2507.13392", "title": "TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction", "authors": ["Emil Häglund", "Johanna Björklund"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13392v1", "summary": "We improve the extraction of insights from customer reviews by restructuring\nthe topic modelling pipeline to operate on opinion units - distinct statements\nthat include relevant text excerpts and associated sentiment scores. Prior work\nhas demonstrated that such units can be reliably extracted using large language\nmodels. The result is a heightened performance of the subsequent topic\nmodeling, leading to coherent and interpretable topics while also capturing the\nsentiment associated with each topic. By correlating the topics and sentiments\nwith business metrics, such as star ratings, we can gain insights on how\nspecific customer concerns impact business outcomes. We present our system's\nimplementation, use cases, and advantages over other topic modeling and\nclassification solutions. We also evaluate its effectiveness in creating\ncoherent topics and assess methods for integrating topic and sentiment\nmodalities for accurate star-rating prediction.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13392v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "TopicImpact：利用观点单元改进客户反馈分析，用于主题建模和星级预测", "tldr": "该研究通过将主题建模管道重构为基于观点单元操作，提高了客户评论洞察提取能力，从而获得更连贯的主题和情绪，并能预测星级。", "motivation": "本研究旨在通过重构主题建模流程，使其基于观点单元运行，从而改进从客户评论中提取洞察的能力，并理解特定客户关注点如何影响星级等业务成果。", "method": "本研究将主题建模管道重构为操作在“观点单元”上，这些单元是包含相关文本摘录和相关情感分数的独立陈述，并使用大型语言模型可靠提取。然后，将主题和情感与星级等业务指标进行关联。系统还评估了创建连贯主题的有效性，并评估了整合主题和情感模态以进行准确星级预测的方法。", "result": "该方法提高了后续主题建模的性能，产生了连贯且可解释的主题，同时捕捉了与每个主题相关的情感。通过将主题和情感与星级等业务指标相关联，可以深入了解特定客户关注点如何影响业务成果。该系统在创建连贯主题和整合主题与情感模态以进行准确星级预测方面表现出有效性。", "conclusion": "本研究提出的系统通过使用观点单元进行主题建模和情感关联，显著改进了客户反馈分析，从而能够获得更连贯、可解释的主题和情感洞察，并能准确预测星级，帮助企业理解客户关注点对业务结果的影响。", "translation": "通过将主题建模管道重构为操作在观点单元上——包含相关文本摘录和相关情感分数的独立陈述，我们改进了从客户评论中提取洞察的能力。先前的工作已经证明，这些单元可以使用大型语言模型可靠地提取。结果是后续主题建模的性能提高，从而产生连贯且可解释的主题，同时捕捉与每个主题相关的情感。通过将主题和情感与星级等业务指标相关联，我们可以深入了解特定客户关注点如何影响业务成果。我们展示了我们系统的实现、用例以及相对于其他主题建模和分类解决方案的优势。我们还评估了其在创建连贯主题方面的有效性，并评估了整合主题和情感模态以进行准确星级预测的方法。", "summary": "本论文介绍了TopicImpact系统，通过将主题建模管道重构为基于“观点单元”（包含文本摘录和情感分数的独立陈述）操作，改进了客户反馈分析。该方法提高了主题建模的性能，生成了连贯且可解释的主题，并捕捉了相关情感。通过将主题和情感与星级等业务指标关联，可以深入了解客户关注点对业务成果的影响。该系统在创建连贯主题和整合主题与情感模态以实现准确星级预测方面进行了评估并展示了其优势。", "keywords": "观点单元, 主题建模, 客户反馈, 情感分析, 星级预测", "comments": "该论文的创新之处在于其将“观点单元”作为主题建模的基本输入，而非原始文本，这巧妙地将情感直接整合到主题发现过程中，从而产生更具解释性的主题，并能直接与业务成果关联。利用大型语言模型提取观点单元也体现了其对前沿技术的应用。其重要性在于能够从非结构化客户反馈中提供可操作的洞察。"}}
{"id": "2507.13822", "title": "RAG-based Architectures for Drug Side Effect Retrieval in LLMs", "authors": ["Shad Nygren", "Pinar Avci", "Andre Daniels", "Reza Rassol", "Afshin Beheshti", "Diego Galeano"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13822v1", "summary": "Drug side effects are a major global health concern, necessitating advanced\nmethods for their accurate detection and analysis. While Large Language Models\n(LLMs) offer promising conversational interfaces, their inherent limitations,\nincluding reliance on black-box training data, susceptibility to\nhallucinations, and lack of domain-specific knowledge, hinder their reliability\nin specialized fields like pharmacovigilance. To address this gap, we propose\ntwo architectures: Retrieval-Augmented Generation (RAG) and GraphRAG, which\nintegrate comprehensive drug side effect knowledge into a Llama 3 8B language\nmodel. Through extensive evaluations on 19,520 drug side effect associations\n(covering 976 drugs and 3,851 side effect terms), our results demonstrate that\nGraphRAG achieves near-perfect accuracy in drug side effect retrieval. This\nframework offers a highly accurate and scalable solution, signifying a\nsignificant advancement in leveraging LLMs for critical pharmacovigilance\napplications.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13822v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于RAG的LLM药物副作用检索架构", "tldr": "本研究提出了基于RAG和GraphRAG的架构，将药物副作用知识整合到Llama 3 8B模型中，以解决LLM在药物警戒领域中的局限性。实验结果表明，GraphRAG在药物副作用检索方面达到了近乎完美的准确率。", "motivation": "药物副作用是一个主要的全球健康问题，需要先进的方法进行准确检测和分析。尽管大型语言模型（LLMs）提供了有前景的对话界面，但其固有的局限性，包括依赖黑盒训练数据、容易产生幻觉以及缺乏领域特定知识，阻碍了它们在药物警戒等专业领域的可靠性。", "method": "为解决现有LLM的局限性，本研究提出了两种架构：检索增强生成（RAG）和图检索增强生成（GraphRAG）。这些架构将全面的药物副作用知识整合到一个Llama 3 8B语言模型中。研究人员对19,520个药物副作用关联（涵盖976种药物和3,851个副作用术语）进行了广泛评估。", "result": "通过广泛评估，我们的结果表明GraphRAG在药物副作用检索方面实现了近乎完美的准确率。", "conclusion": "该框架提供了一个高度准确且可扩展的解决方案，标志着在利用LLM进行关键药物警戒应用方面取得了重大进展。", "translation": "药物副作用是一个主要的全球健康问题，需要先进的方法进行准确检测和分析。尽管大型语言模型（LLMs）提供了有前景的对话界面，但其固有的局限性，包括依赖黑盒训练数据、容易产生幻觉以及缺乏领域特定知识，阻碍了它们在药物警戒等专业领域的可靠性。为解决这一差距，我们提出了两种架构：检索增强生成（RAG）和图检索增强生成（GraphRAG），它们将全面的药物副作用知识整合到一个Llama 3 8B语言模型中。通过对19,520个药物副作用关联（涵盖976种药物和3,851个副作用术语）进行广泛评估，我们的结果表明GraphRAG在药物副作用检索方面达到了近乎完美的准确率。该框架提供了一个高度准确且可扩展的解决方案，标志着在利用LLM进行关键药物警戒应用方面取得了重大进展。", "summary": "本研究旨在解决大型语言模型（LLMs）在药物警戒领域中检索药物副作用的可靠性问题。作者提出了两种基于检索增强生成（RRAG）的架构：RAG和GraphRAG，将全面的药物副作用知识整合到Llama 3 8B模型中。通过对大量药物副作用关联进行评估，结果显示GraphRAG在药物副作用检索方面实现了近乎完美的准确率，为关键药物警戒应用提供了一个准确且可扩展的解决方案。", "keywords": "药物副作用, LLM, RAG, GraphRAG, 药物警戒", "comments": "本论文的创新之处在于通过引入RAG和GraphRAG架构，有效地弥补了LLM在处理特定领域（如药物警戒）知识时的局限性，特别是解决了幻觉和缺乏领域知识的问题。GraphRAG达到近乎完美的准确率，这对于提高药物副作用检测的可靠性具有重要意义，是LLM在关键医疗应用中迈出的重要一步。"}}
{"id": "2505.16195", "title": "SpecMaskFoley: Steering Pretrained Spectral Masked Generative Transformer Toward Synchronized Video-to-audio Synthesis via ControlNet", "authors": ["Zhi Zhong", "Akira Takahashi", "Shuyang Cui", "Keisuke Toyama", "Shusuke Takahashi", "Yuki Mitsufuji"], "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS", "eess.IV"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      WASPAA 2025. 4 pages, 2 figures, 2 tables. Demo page: this https URL", "url": "http://arxiv.org/abs/2505.16195v2", "summary": "Foley synthesis aims to synthesize high-quality audio that is both\nsemantically and temporally aligned with video frames. Given its broad\napplication in creative industries, the task has gained increasing attention in\nthe research community. To avoid the non-trivial task of training audio\ngenerative models from scratch, adapting pretrained audio generative models for\nvideo-synchronized foley synthesis presents an attractive direction.\nControlNet, a method for adding fine-grained controls to pretrained generative\nmodels, has been applied to foley synthesis, but its use has been limited to\nhandcrafted human-readable temporal conditions. In contrast, from-scratch\nmodels achieved success by leveraging high-dimensional deep features extracted\nusing pretrained video encoders. We have observed a performance gap between\nControlNet-based and from-scratch foley models. To narrow this gap, we propose\nSpecMaskFoley, a method that steers the pretrained SpecMaskGIT model toward\nvideo-synchronized foley synthesis via ControlNet. To unlock the potential of a\nsingle ControlNet branch, we resolve the discrepancy between the temporal video\nfeatures and the time-frequency nature of the pretrained SpecMaskGIT via a\nfrequency-aware temporal feature aligner, eliminating the need for complicated\nconditioning mechanisms widely used in prior arts. Evaluations on a common\nfoley synthesis benchmark demonstrate that SpecMaskFoley could even outperform\nstrong from-scratch baselines, substantially advancing the development of\nControlNet-based foley synthesis models. Demo page:\nhttps://zzaudio.github.io/SpecMaskFoley_Demo/", "comment": "WASPAA 2025. 4 pages, 2 figures, 2 tables. Demo page:\n  https://zzaudio.github.io/SpecMaskFoley_Demo/", "pdf_url": "http://arxiv.org/pdf/2505.16195v2", "cate": "cs.SD", "date": "2025-05-22", "updated": "2025-07-17", "AI": {"title_translation": "SpecMaskFoley：通过ControlNet引导预训练频谱掩蔽生成Transformer实现同步视频到音频合成", "tldr": "SpecMaskFoley提出了一种通过ControlNet引导预训练模型进行视频同步Foley合成的方法，通过频率感知时间特征对齐器解决了视频特征与模型输入之间的差异，性能优于从头开始训练的基线模型。", "motivation": "Foley合成在创意产业中应用广泛，但从头训练音频生成模型任务艰巨。虽然ControlNet已被用于Foley合成，但其使用受限于手工制作的条件，与利用高维深度特征的从头模型存在性能差距。本文旨在缩小这一差距。", "method": "本文提出了SpecMaskFoley，一种通过ControlNet引导预训练的SpecMaskGIT模型进行视频同步Foley合成的方法。为充分发挥ControlNet分支的潜力，通过频率感知时间特征对齐器解决了时间视频特征与预训练SpecMaskGIT的时频性质之间的差异，从而避免了复杂条件机制的需求。", "result": "在Foley合成基准测试中的评估表明，SpecMaskFoley甚至可以超越强大的从头开始训练的基线模型，显著推动了基于ControlNet的Foley合成模型的发展。", "conclusion": "SpecMaskFoley通过创新的频率感知时间特征对齐器，成功地将预训练的SpecMaskGIT模型应用于视频同步Foley合成，显著提升了ControlNet在该领域的应用效果，并超越了从头训练的模型性能。", "translation": "Foley合成旨在合成高质量的音频，使其在语义和时间上与视频帧对齐。鉴于其在创意产业中的广泛应用，这项任务在研究界受到了越来越多的关注。为了避免从头开始训练音频生成模型的繁琐任务，将预训练的音频生成模型用于视频同步Foley合成是一个有吸引力的方向。ControlNet是一种为预训练生成模型添加精细控制的方法，已被应用于Foley合成，但其使用仅限于手工制作的人类可读时间条件。相比之下，从头开始的模型通过利用使用预训练视频编码器提取的高维深度特征取得了成功。我们观察到基于ControlNet的Foley模型与从头开始的Foley模型之间存在性能差距。为了缩小这一差距，我们提出了SpecMaskFoley，一种通过ControlNet引导预训练的SpecMaskGIT模型实现视频同步Foley合成的方法。为了释放单个ControlNet分支的潜力，我们通过频率感知时间特征对齐器解决了时间视频特征与预训练SpecMaskGIT的时频性质之间的差异，从而消除了以往艺术中广泛使用的复杂条件机制的需求。在通用Foley合成基准上的评估表明，SpecMaskFoley甚至可以超越强大的从头开始的基线，极大地推动了基于ControlNet的Foley合成模型的发展。演示页面：https://zzaudio.github.io/SpecMaskFoley_Demo/", "summary": "SpecMaskFoley提出了一种利用ControlNet引导预训练的SpecMaskGIT模型实现视频同步Foley合成的新方法。针对ControlNet在Foley合成中性能受限的问题，该方法引入了频率感知时间特征对齐器，有效解决了视频特征与预训练模型时频性质的差异，从而无需复杂的条件机制。实验结果表明，SpecMaskFoley性能优于从头开始训练的基线模型，显著提升了ControlNet在视频到音频合成领域的应用潜力。", "keywords": "Foley合成, ControlNet, 视频到音频合成, 预训练模型, 频谱掩蔽生成Transformer", "comments": "该论文的创新点在于通过引入频率感知时间特征对齐器，巧妙地解决了ControlNet在视频同步Foley合成中应用时面临的视频特征与预训练模型输入不匹配的问题，从而提升了ControlNet的通用性和性能。其重要性在于，它为利用现有强大的预训练模型进行Foley合成提供了一条高效且高性能的路径，避免了从零开始训练的巨大开销，并超越了从头训练的基线模型。"}}
{"id": "2507.13902", "title": "Deep Micro Solvers for Rough-Wall Stokes Flow in a Heterogeneous Multiscale Method", "authors": ["Emanuel Ström", "Anna-Karin Tornberg", "Ozan Öktem"], "categories": ["math.NA", "cs.NA", "stat.ML", "65N55 (Primary) 65R20, 68T99, 76D07 (Secondary)"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13902v1", "summary": "We propose a learned precomputation for the heterogeneous multiscale method\n(HMM) for rough-wall Stokes flow. A Fourier neural operator is used to\napproximate local averages over microscopic subsets of the flow, which allows\nto compute an effective slip length of the fluid away from the roughness. The\nnetwork is designed to map from the local wall geometry to the Riesz\nrepresentors for the corresponding local flow averages. With such a\nparameterisation, the network only depends on the local wall geometry and as\nsuch can be trained independent of boundary conditions. We perform a detailed\ntheoretical analysis of the statistical error propagation, and prove that under\nsuitable regularity and scaling assumptions, a bounded training loss leads to a\nbounded error in the resulting macroscopic flow. We then demonstrate on a\nfamily of test problems that the learned precomputation performs stably with\nrespect to the scale of the roughness. The accuracy in the HMM solution for the\nmacroscopic flow is comparable to when the local (micro) problems are solved\nusing a classical approach, while the computational cost of solving the micro\nproblems is significantly reduced.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13902v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "粗糙壁面Stokes流异构多尺度方法中的深度微观求解器", "tldr": "提出一种基于傅里叶神经算子（FNO）的学习预计算方法，用于粗糙壁面Stokes流的异构多尺度方法（HMM），显著降低计算成本并保持精度。", "motivation": "为解决粗糙壁面Stokes流在异构多尺度方法（HMM）中微观问题计算成本高的问题，并提供一种高效的学习预计算方法。", "method": "采用傅里叶神经算子（FNO）近似流体微观子集的局部平均值，以计算有效滑移长度。网络设计将局部壁面几何映射到Riesz表示器，使其能独立于边界条件训练。同时进行了详细的统计误差传播理论分析。", "result": "学习预计算方法在粗糙度尺度方面表现稳定。宏观流的HMM解精度与经典方法相当，同时微观问题求解的计算成本显著降低。", "conclusion": "基于傅里叶神经算子的学习预计算能够有效且高效地应用于粗糙壁面Stokes流的异构多尺度方法，显著降低计算成本同时保持精度。", "translation": "我们提出了一种用于粗糙壁面Stokes流异构多尺度方法（HMM）的学习预计算方法。使用傅里叶神经算子（FNO）来近似流体微观子集的局部平均值，这使得能够计算远离粗糙度的流体有效滑移长度。该网络旨在将局部壁面几何映射到相应局部流平均值的Riesz表示器。通过这种参数化，网络仅依赖于局部壁面几何，因此可以独立于边界条件进行训练。我们对统计误差传播进行了详细的理论分析，并证明在适当的正则性和尺度假设下，有界的训练损失会导致所得宏观流中误差有界。然后，我们在一系列测试问题上证明，学习预计算在粗糙度尺度方面表现稳定。宏观流的HMM解的精度与使用经典方法求解局部（微观）问题时相当，同时求解微观问题的计算成本显著降低。", "summary": "本文提出一种新颖的学习预计算方法，将傅里叶神经算子（FNO）集成到异构多尺度方法（HMM）中，以高效处理粗糙壁面Stokes流。该方法通过FNO近似微观子集的局部平均值，从而计算有效滑移长度。网络设计使其仅依赖局部壁面几何，可独立于边界条件训练。理论分析证明了误差传播的界限。实验结果表明，该学习预计算方法在粗糙度尺度上表现稳定，在保持与传统方法相当精度的同时，显著降低了微观问题的计算成本。", "keywords": "异构多尺度方法, 傅里叶神经算子, 粗糙壁面, Stokes流, 学习预计算", "comments": "该论文的创新点在于将傅里叶神经算子引入到异构多尺度方法中，实现了粗糙壁面Stokes流微观问题的学习预计算，有效降低了计算成本。网络设计独立于边界条件训练，增加了其通用性。理论分析为方法的可靠性提供了保障。这对于涉及多尺度流体模拟的领域具有重要意义。"}}
{"id": "2507.13654", "title": "A Study of Teleoperation Methods in a Simulated Virtual Eye Surgery Environment", "authors": ["Haoran Wang", "Yasamin Foroutani", "Matthew Nepo", "Mercedes Rodriguez", "Ji Ma", "Jean-Pierre Hubschman", "Tsu-Chin Tsao", "Jacob Rosen"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      9 pages, 11 figures", "url": "http://arxiv.org/abs/2507.13654v1", "summary": "This paper examines the performance of Inside and Outside Control modes at\nvarious scaling factors in a simulated vitreoretinal surgical setting. The\nIRISS teleoperated surgical system's console (cockpit) was adapted to project a\nsimulated microscope view of an intraocular setup to a virtual reality (VR)\nheadset. Five experienced vitreoretinal surgeons and five engineers with no\nsurgical experience used the system to perform tasks common to vitreoretinal\nsurgery. Experimental results indicate that Inside Control methods at higher\nscaling factors (20 or 30) achieved the best performance overall, though the\noptimal scaling factor may vary by task and complexity. Optimizing control\nmethods and scaling factors could lead to improvements in surgical efficiency\nand accuracy, as well as minimize risks in future robotic-assisted intraocular\nprocedures.", "comment": "9 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.13654v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "模拟虚拟眼科手术环境中遥操作方法的研究", "tldr": "研究发现在模拟玻璃体视网膜手术中，内部控制模式在较高缩放因子下表现最佳，这有助于未来机器人辅助手术的效率和准确性。", "motivation": "本研究旨在评估在模拟玻璃体视网膜手术环境中，内部和外部控制模式在不同缩放因子下的性能，以优化未来的机器人辅助眼科手术。", "method": "研究使用了IRISS遥操作手术系统的控制台，并将其调整以通过VR头显投射模拟的眼内视图。实验中，五名经验丰富的玻璃体视网膜外科医生和五名无手术经验的工程师使用该系统执行玻璃体视网膜手术中的常见任务。", "result": "实验结果表明，内部控制方法在较高缩放因子（20或30）下总体表现最佳。然而，最佳缩放因子可能因任务复杂性而异。", "conclusion": "优化控制方法和缩放因子可以提高未来机器人辅助眼内手术的效率、准确性，并最大限度地降低风险。", "translation": "本文研究了在模拟玻璃体视网膜手术环境中，内部和外部控制模式在各种缩放因子下的性能。IRISS遥操作手术系统的控制台（驾驶舱）经过调整，将眼内设置的模拟显微镜视图投射到虚拟现实（VR）头戴设备中。五名经验丰富的玻璃体视网膜外科医生和五名没有手术经验的工程师使用该系统执行玻璃体视网膜手术中常见的任务。实验结果表明，内部控制方法在较高缩放因子（20或30）下总体表现最佳，尽管最佳缩放因子可能因任务和复杂性而异。优化控制方法和缩放因子可以提高未来机器人辅助眼内手术的效率和准确性，并最大限度地降低风险。", "summary": "本研究评估了在模拟玻璃体视网膜手术环境中，内部和外部遥操作控制模式在不同缩放因子下的性能。通过使用IRISS系统和VR头显，经验丰富的外科医生和工程师执行了手术任务。结果显示，内部控制在较高缩放因子下表现最优，这对于提升未来机器人辅助眼科手术的效率和安全性具有重要意义。", "keywords": "遥操作, 虚拟现实, 眼科手术, 缩放因子, 机器人辅助手术", "comments": "这项研究通过在模拟环境中测试不同的遥操作控制模式和缩放因子，为优化机器人辅助眼科手术提供了实证依据，对提高手术效率和安全性具有潜在价值。"}}
{"id": "2507.13703", "title": "Binarizing Physics-Inspired GNNs for Combinatorial Optimization", "authors": ["Martin Krutský", "Gustav Šír", "Vyacheslav Kungurtsev", "Georgios Korpas"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Accepted to the 28th European Conference on Artificial Intelligence (ECAI 2025). This archival version includes supplementary appendices", "url": "http://arxiv.org/abs/2507.13703v1", "summary": "Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.", "comment": "Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices", "pdf_url": "http://arxiv.org/pdf/2507.13703v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "二值化物理启发式图神经网络用于组合优化", "tldr": "物理启发式图神经网络（PI-GNNs）在处理密集组合优化问题时性能下降，因为其松弛的实值输出与二值解存在差异。本文提出基于模糊逻辑和二值化神经网络的替代方法，显著提升了PI-GNNs在密集场景下的性能。", "motivation": "物理启发式图神经网络（PI-GNNs）作为一种有效的无监督框架，在各种组合优化问题中取得了有希望的结果。然而，随着组合问题图密度的增加，PI-GNNs的性能会系统性地急剧下降。分析揭示了PI-GNNs训练动态中存在一个有趣的相变，这与密集问题中的退化解相关，突出了松弛的实值模型输出与二值化问题解之间的差异。", "method": "为了解决实值模型输出与二值化问题解之间的差异，本文基于模糊逻辑和二值化神经网络的见解，提出了替代PI-GNNs中朴素策略的原则性方法。", "result": "实验表明，所提出的一系列方法显著提高了PI-GNNs在日益密集的设置中的性能。", "conclusion": "通过引入基于模糊逻辑和二值化神经网络的改进策略，可以有效解决物理启发式图神经网络在处理密集组合优化问题时性能下降的问题，从而提高其在复杂场景下的适用性。", "translation": "物理启发式图神经网络（PI-GNNs）已被用作一种高效的无监督框架，用于松弛通过特定图结构和损失编码的组合优化问题，反映了问题变量之间的依赖关系。尽管该框架在各种组合问题中取得了有希望的结果，但我们发现PI-GNNs的性能随着组合问题图密度的增加而系统性地急剧下降。我们的分析揭示了PI-GNNs训练动态中一个有趣的相变，这与密集问题中的退化解相关，突出了松弛的实值模型输出与二值化问题解之间的差异。为了解决这种差异，我们基于模糊逻辑和二值化神经网络的见解，提出了替代PI-GNNs中朴素策略的原则性方法。我们的实验表明，所提出的一系列方法显著提高了PI-GNNs在日益密集的设置中的性能。", "summary": "本文研究了物理启发式图神经网络（PI-GNNs）在组合优化问题中的应用，发现其性能会随问题图密度的增加而下降，主要原因是实值输出与二值解之间的不匹配。为解决此问题，作者提出了基于模糊逻辑和二值化神经网络的新方法。实验证明，这些方法能显著提升PI-GNNs在处理高密度问题时的表现。", "keywords": "物理启发式GNN, 组合优化, 二值化, 模糊逻辑, 图神经网络", "comments": "本文识别并解决了物理启发式图神经网络在处理密集组合优化问题时的关键局限性。其创新点在于引入了模糊逻辑和二值化神经网络的思想来弥合松弛实值输出与实际二值解之间的鸿沟，这为提升GNN在离散优化领域的应用潜力提供了有价值的方向。"}}
{"id": "2507.14056", "title": "Noradrenergic-inspired gain modulation attenuates the stability gap in joint training", "authors": ["Alejandro Rodriguez-Garcia", "Anindya Ghosh", "Srikanth Ramaswamy"], "categories": ["cs.LG", "cs.AI", "q-bio.NC", "68T05"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 5 figures, 1 table, 1 pseudo-code", "url": "http://arxiv.org/abs/2507.14056v1", "summary": "Recent studies in continual learning have identified a transient drop in\nperformance on mastered tasks when assimilating new ones, known as the\nstability gap. Such dynamics contradict the objectives of continual learning,\nrevealing a lack of robustness in mitigating forgetting, and notably,\npersisting even under an ideal joint-loss regime. Examining this gap within\nthis idealized joint training context is critical to isolate it from other\nsources of forgetting. We argue that it reflects an imbalance between rapid\nadaptation and robust retention at task boundaries, underscoring the need to\ninvestigate mechanisms that reconcile plasticity and stability within continual\nlearning frameworks. Biological brains navigate a similar dilemma by operating\nconcurrently on multiple timescales, leveraging neuromodulatory signals to\nmodulate synaptic plasticity. However, artificial networks lack native\nmultitimescale dynamics, and although optimizers like momentum-SGD and Adam\nintroduce implicit timescale regularization, they still exhibit stability gaps.\nInspired by locus coeruleus mediated noradrenergic bursts, which transiently\nenhance neuronal gain under uncertainty to facilitate sensory assimilation, we\npropose uncertainty-modulated gain dynamics - an adaptive mechanism that\napproximates a two-timescale optimizer and dynamically balances integration of\nknowledge with minimal interference on previously consolidated information. We\nevaluate our mechanism on domain-incremental and class-incremental variants of\nthe MNIST and CIFAR benchmarks under joint training, demonstrating that\nuncertainty-modulated gain dynamics effectively attenuate the stability gap.\nFinally, our analysis elucidates how gain modulation replicates noradrenergic\nfunctions in cortical circuits, offering mechanistic insights into reducing\nstability gaps and enhance performance in continual learning tasks.", "comment": "18 pages, 5 figures, 1 table, 1 pseudo-code", "pdf_url": "http://arxiv.org/pdf/2507.14056v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "去甲肾上腺素启发式增益调制减弱联合训练中的稳定性差距", "tldr": "本文提出了一种受去甲肾上腺素启发的增益调制机制，用于在持续学习中（即使在理想的联合训练下）减小稳定性差距，从而提高性能并减少遗忘。", "motivation": "持续学习中存在一个“稳定性差距”现象，即在学习新任务时，已掌握任务的性能会暂时下降。即使在理想的联合损失训练下，这种现象依然存在，这表明在缓解遗忘方面缺乏鲁棒性，并反映了在任务边界处快速适应和稳健保留之间的不平衡。人工网络缺乏生物大脑中固有的多时间尺度动态。", "method": "受蓝斑核介导的去甲肾上腺素爆发（在不确定性下瞬时增强神经元增益以促进感觉同化）的启发，本文提出了一种“不确定性调制增益动态”机制。这是一种自适应机制，近似于一个双时间尺度优化器，动态平衡知识整合与对先前巩固信息的最小干扰。", "result": "在MNIST和CIFAR基准数据集的域增量和类增量变体上（在联合训练下）进行评估，结果表明不确定性调制增益动态有效地减弱了稳定性差距。", "conclusion": "增益调制复制了皮层回路中的去甲肾上腺素功能，为减少稳定性差距和提高持续学习任务中的性能提供了机制性见解。", "translation": "持续学习中的近期研究发现，在同化新任务时，已掌握任务的性能会暂时下降，这被称为稳定性差距。这种动态与持续学习的目标相悖，揭示了在缓解遗忘方面的鲁棒性不足，并且值得注意的是，即使在理想的联合损失机制下也持续存在。在理想化的联合训练背景下检查这一差距对于将其与其他遗忘来源区分开来至关重要。我们认为这反映了在任务边界处快速适应和稳健保留之间的不平衡，强调需要研究在持续学习框架内协调可塑性和稳定性的机制。生物大脑通过同时在多个时间尺度上操作，利用神经调节信号来调节突触可塑性，从而应对类似的困境。然而，人工网络缺乏原生的多时间尺度动态，尽管动量-SGD和Adam等优化器引入了隐式时间尺度正则化，但它们仍然表现出稳定性差距。受蓝斑核介导的去甲肾上腺素爆发（在不确定性下瞬时增强神经元增益以促进感觉同化）的启发，我们提出了不确定性调制增益动态——一种自适应机制，它近似于一个双时间尺度优化器，并动态平衡知识整合与对先前巩固信息的最小干扰。我们在联合训练下，在MNIST和CIFAR基准的域增量和类增量变体上评估了我们的机制，证明了不确定性调制增益动态有效地减弱了稳定性差距。最后，我们的分析阐明了增益调制如何在皮层回路中复制去甲肾上腺素功能，为减少稳定性差距和提高持续学习任务中的性能提供了机制性见解。", "summary": "该研究关注持续学习中的“稳定性差距”问题，即学习新任务时旧任务性能下降的现象，即使在理想训练条件下也存在。受生物大脑中去甲肾上腺素神经调节的启发，作者提出了一种“不确定性调制增益动态”机制。该机制模拟双时间尺度优化器，旨在平衡知识整合与旧信息保护。实验结果表明，该机制在MNIST和CIFAR数据集上有效减弱了稳定性差距，为持续学习中减少遗忘和提升性能提供了新的生物学启发性见解。", "keywords": "持续学习, 稳定性差距, 去甲肾上腺素, 增益调制, 可塑性-稳定性困境", "comments": "本文的创新之处在于，它从生物学（去甲肾上腺素神经调节）中汲取灵感，设计了一种新颖的机制来解决持续学习中长期存在的稳定性-可塑性困境。通过引入近似于双时间尺度优化的增益调制，它提供了一种有效的方法来缓解即使在理想联合训练下也难以消除的“稳定性差距”。这不仅为人工神经网络提供了新的设计思路，也加深了我们对生物智能如何解决类似问题的理解。该研究对于提升持续学习系统的鲁棒性和实用性具有重要意义。"}}
{"id": "2405.18386", "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning", "authors": ["Yixiao Zhang", "Yukara Ikemiya", "Woosung Choi", "Naoki Murata", "Marco A. Martínez-Ramírez", "Liwei Lin", "Gus Xia", "Wei-Hsiang Liao", "Yuki Mitsufuji", "Simon Dixon"], "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      Accepted at ISMIR 2025 Conference. Code and demo are available at: this https URL", "url": "http://arxiv.org/abs/2405.18386v3", "summary": "Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.", "comment": "Accepted at ISMIR 2025 Conference. Code and demo are available at:\n  https://github.com/ldzhangyx/instruct-musicgen", "pdf_url": "http://arxiv.org/pdf/2405.18386v3", "cate": "cs.SD", "date": "2024-05-28", "updated": "2025-07-17", "AI": {"title_translation": "Instruct-MusicGen：通过指令微调解锁音乐语言模型的文本到音乐编辑", "tldr": "Instruct-MusicGen通过对预训练的MusicGen模型进行高效微调，实现了文本到音乐的编辑，解决了现有方法资源密集和精度不足的问题，并以极少的额外参数和训练步骤取得了卓越性能。", "motivation": "现有的文本到音乐编辑方法存在局限性：从头训练特定编辑模型资源密集且效率低下；使用大型语言模型预测编辑后的音乐会导致音频重建不精确。", "method": "本文提出了Instruct-MusicGen，通过微调预训练的MusicGen模型来有效遵循编辑指令（如添加、移除或分离音轨）。该方法修改了原始MusicGen架构，加入了文本融合模块和音频融合模块，使其能够同时处理指令文本和音频输入，生成所需的编辑音乐。", "result": "Instruct-MusicGen仅为原始MusicGen模型引入了8%的新参数，并仅训练了5K步，但在所有任务上均优于现有基线，并展现出与为特定任务训练的模型相当的性能。", "conclusion": "这项进展不仅提升了文本到音乐编辑的效率，还拓宽了音乐语言模型在动态音乐制作环境中的应用范围。", "translation": "文本到音乐编辑的最新进展，即利用文本查询修改音乐（例如改变其风格或调整乐器组件），为AI辅助音乐创作带来了独特的挑战和机遇。该领域以前的方法受到限制，需要从头开始训练特定的编辑模型，这既耗费资源又效率低下；其他研究使用大型语言模型预测编辑后的音乐，导致音频重建不精确。为了结合优势并解决这些限制，我们引入了Instruct-MusicGen，这是一种新颖的方法，它对预训练的MusicGen模型进行微调，以有效遵循编辑指令，例如添加、移除或分离音轨。我们的方法涉及对原始MusicGen架构的修改，通过整合文本融合模块和音频融合模块，使模型能够同时处理指令文本和音频输入并生成所需的编辑音乐。值得注意的是，Instruct-MusicGen仅为原始MusicGen模型引入了8%的新参数，并且仅训练了5K步，但它在所有任务上都比现有基线取得了卓越的性能，并展示出与为特定任务训练的模型相当的性能。这项进展不仅提升了文本到音乐编辑的效率，还拓宽了音乐语言模型在动态音乐制作环境中的适用性。", "summary": "本文介绍了Instruct-MusicGen，一个创新的文本到音乐编辑方法。它通过对预训练的MusicGen模型进行高效微调，使其能够根据文本指令（如添加、移除、分离音轨）编辑音乐。该模型在MusicGen基础上加入了文本和音频融合模块，仅增加了8%的参数并训练5K步，便在各项任务上超越了现有基线，并达到或接近专用模型的性能。这显著提高了文本到音乐编辑的效率，并扩展了音乐语言模型在动态音乐制作中的应用潜力。", "keywords": "文本到音乐编辑, 音乐语言模型, 指令微调, MusicGen, Instruct-MusicGen", "comments": "Instruct-MusicGen的创新之处在于其高效的微调策略，通过少量参数和训练步骤便实现了高质量的文本到音乐编辑能力，这对于资源受限或需要快速迭代的应用场景具有重要意义。它成功地将预训练大模型的强大能力与特定任务的需求相结合，为未来的多模态内容生成提供了新的范式。"}}
{"id": "2506.01551", "title": "EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation", "authors": ["Bingqian Lin", "Yunshuang Nie", "Khun Loun Zai", "Ziming Wei", "Mingfei Han", "Rongtao Xu", "Minzhe Niu", "Jianhua Han", "Liang Lin", "Cewu Lu", "Xiaodan Liang"], "categories": ["cs.CV", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.01551v2", "summary": "Building Vision-Language Navigation (VLN) agents which can navigate following\nnatural language instructions is a long-standing goal in human-robot\ninteraction applications. Recent studies have revealed the potential of\ntraining open-source Large Language Models (LLMs) to unleash LLMs' reasoning\nability for improving navigation, and simultaneously mitigate the domain gap\nbetween LLMs' training corpus and the VLN task. However, these approaches\nprimarily adopt direct input-output mapping paradigms, causing the mapping\nlearning difficult and the navigational decisions unexplainable.\nChain-of-Thought (CoT) training is a promising way to improve both navigational\ndecision accuracy and interpretability, while the complexity of the navigation\ntask makes the perfect CoT labels unavailable and may lead to overfitting\nthrough pure CoT supervised fine-tuning. In this paper, we propose a novel\nsElf-improving embodied reasoning framework for boosting LLM-based\nvision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two\nstages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model\nwith formalized CoT labels to both activate the model's navigational reasoning\ncapabilities and increase the reasoning speed; (2) Self-Reflective\nPost-Training, where the model is iteratively trained with its own reasoning\noutputs as self-enriched CoT labels to enhance the supervision diversity. A\nself-reflective auxiliary task is also introduced to encourage learning correct\nreasoning patterns by contrasting with wrong ones. Experimental results on the\npopular VLN benchmarks demonstrate the superiority of EvolveNav over previous\nLLM-based VLN approaches. Code is available at\nhttps://github.com/expectorlin/EvolveNav.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.01551v2", "cate": "cs.CV", "date": "2025-06-02", "updated": "2025-07-18", "AI": {"title_translation": "EvolveNav：基于LLM的视觉语言导航的自改进具身推理", "tldr": "EvolveNav通过形式化CoT微调和自反思后训练，提升了LLM在视觉语言导航中的推理能力和导航性能。", "motivation": "现有基于LLM的视觉语言导航（VLN）方法主要采用直接输入-输出映射，导致学习困难且导航决策不可解释。尽管思维链（CoT）训练有潜力提升准确性和可解释性，但导航任务的复杂性使得完美的CoT标签难以获取，且可能导致纯CoT监督微调的过拟合。", "method": "本文提出了EvolveNav，一个用于提升基于LLM的视觉语言导航的自改进具身推理框架。EvolveNav包含两个阶段：(1) 形式化CoT监督微调，通过形式化CoT标签训练模型，以激活模型的导航推理能力并提高推理速度；(2) 自反思后训练，模型使用其自身的推理输出作为自丰富CoT标签进行迭代训练，以增强监督多样性。此外，还引入了一个自反思辅助任务，通过与错误模式对比来鼓励学习正确的推理模式。", "result": "在流行的VLN基准测试上的实验结果表明，EvolveNav优于以前基于LLM的VLN方法。", "conclusion": "EvolveNav通过其创新的两阶段自改进具身推理框架，有效解决了LLM在视觉语言导航任务中推理能力激活、解释性及标签稀缺的问题，显著提升了导航性能。", "translation": "构建能够遵循自然语言指令进行导航的视觉语言导航 (VLN) 代理是人机交互应用中一个长期目标。最近的研究揭示了训练开源大型语言模型 (LLM) 以释放LLM推理能力来改进导航的潜力，同时缓解了LLM训练语料库与VLN任务之间的领域差距。然而，这些方法主要采用直接输入-输出映射范式，导致映射学习困难且导航决策不可解释。思维链 (CoT) 训练是提高导航决策准确性和可解释性的一种有前途的方法，但导航任务的复杂性使得完美的CoT标签不可用，并且可能导致纯CoT监督微调的过拟合。在本文中，我们提出了一种新颖的自改进具身推理框架，用于提升基于LLM的视觉语言导航，称为EvolveNav。我们的EvolveNav包含两个阶段：(1) 形式化思维链监督微调，我们使用形式化CoT标签训练模型，以同时激活模型的导航推理能力并提高推理速度；(2) 自反思后训练，模型使用其自身的推理输出作为自丰富CoT标签进行迭代训练，以增强监督多样性。还引入了一个自反思辅助任务，通过与错误模式对比来鼓励学习正确的推理模式。在流行的VLN基准测试上的实验结果表明，EvolveNav优于以前基于LLM的VLN方法。代码可在 https://github.com/expectorlin/EvolveNav 获取。", "summary": "本文提出EvolveNav，一个针对LLM-based视觉语言导航的自改进具身推理框架。该框架通过两阶段训练解决现有方法的局限性：首先进行形式化CoT监督微调以激活并加速推理能力；然后通过自反思后训练，利用模型自身的推理输出作为自丰富CoT标签进行迭代学习，并引入辅助任务区分正确与错误推理模式。实验证明EvolveNav在VLN任务上优于现有LLM方法。", "keywords": "视觉语言导航, 大型语言模型, 思维链, 自改进, 具身推理", "comments": "EvolveNav的创新之处在于其两阶段的自改进训练范式，特别是引入自反思后训练和辅助任务来解决CoT标签稀缺和过拟合问题，同时增强了LLM在VLN任务中的推理能力和可解释性。这对于提升具身智能体的导航性能具有重要意义。"}}
{"id": "2507.13651", "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13651v1", "summary": "Many intelligent tutoring systems can support a student in solving a stepwise\ntask. When a student combines several steps in one step, the number of possible\npaths connecting consecutive inputs may be very large. This combinatorial\nexplosion makes error diagnosis hard. Using a final answer to diagnose a\ncombination of steps can mitigate the combinatorial explosion, because there\nare generally fewer possible (erroneous) final answers than (erroneous)\nsolution paths. An intermediate input for a task can be diagnosed by\nautomatically completing it according to the task solution strategy and\ndiagnosing this solution. This study explores the potential of automated error\ndiagnosis based on a final answer. We investigate the design of a service that\nprovides a buggy rule diagnosis when a student combines several steps. To\nvalidate the approach, we apply the service to an existing dataset (n=1939) of\nunique student steps when solving quadratic equations, which could not be\ndiagnosed by a buggy rule service that tries to connect consecutive inputs with\na single rule. Results show that final answer evaluation can diagnose 29,4% of\nthese steps. Moreover, a comparison of the generated diagnoses with teacher\ndiagnoses on a subset (n=115) shows that the diagnoses align in 97% of the\ncases. These results can be considered a basis for further exploration of the\napproach.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13651v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "分步任务中通过最终答案评估对合并步骤的错误规则诊断", "tldr": "本研究探索了一种基于最终答案评估的自动化错误诊断方法，用于解决学生在分步任务中合并步骤时遇到的组合爆炸问题，并在二次方程求解数据集上验证了其有效性。", "motivation": "在智能辅导系统中，当学生合并多个步骤时，连接连续输入的可能路径数量巨大，导致错误诊断困难。传统的诊断方法因组合爆炸而难以应对。", "method": "本研究提出并探索了一种基于最终答案评估的自动化错误规则诊断服务。该服务通过自动完成中间输入并诊断其解决方案来诊断任务的中间输入。通过将该服务应用于一个包含1939个学生独特步骤的现有数据集（学生在求解二次方程时合并的步骤），并与教师诊断进行比较来验证其方法。", "result": "最终答案评估能够诊断这些步骤中的29.4%。此外，在115个子集上，生成的诊断与教师诊断在97%的情况下一致。", "conclusion": "最终答案评估方法为解决分步任务中合并步骤的错误规则诊断问题提供了一个有潜力的基础，值得进一步探索。", "translation": "许多智能辅导系统可以支持学生解决分步任务。当学生将几个步骤合并为一个步骤时，连接连续输入的可能路径数量可能非常大。这种组合爆炸使得错误诊断变得困难。使用最终答案来诊断步骤的组合可以减轻组合爆炸，因为通常可能的（错误）最终答案比（错误）解决方案路径要少。任务的中间输入可以通过根据任务解决方案策略自动完成并诊断该解决方案来诊断。本研究探索了基于最终答案的自动化错误诊断的潜力。我们研究了在学生合并多个步骤时提供错误规则诊断服务的R设计。为了验证该方法，我们将该服务应用于一个现有数据集（n=1939），该数据集包含学生在求解二次方程时无法通过尝试用单一规则连接连续输入的错误规则服务诊断的独特学生步骤。结果表明，最终答案评估可以诊断这些步骤中的29.4%。此外，对子集（n=115）上生成的诊断与教师诊断的比较表明，诊断在97%的情况下一致。这些结果可以被认为是进一步探索该方法的基础。", "summary": "本研究提出并评估了一种新的自动化错误诊断方法，旨在解决智能辅导系统中学生在分步任务中合并步骤时遇到的诊断难题。针对传统方法因组合爆炸而难以诊断的问题，该研究探索了基于最终答案评估的策略。通过在二次方程求解数据集上进行验证，结果显示该方法能够有效诊断合并步骤，并与教师诊断具有高度一致性，为未来研究奠定了基础。", "keywords": "错误诊断, 智能辅导系统, 最终答案评估, 分步任务, 组合爆炸", "comments": "这项研究提出了一种创新性的方法来解决智能辅导系统中一个长期存在的挑战：如何诊断学生合并步骤时的错误。通过利用最终答案评估来规避组合爆炸问题，该方法显著提高了诊断效率和准确性。其在实际数据集上的验证结果令人鼓舞，为开发更智能、更鲁棒的教学系统提供了新的思路。"}}
{"id": "2507.04469", "title": "The role of large language models in UI/UX design: A systematic literature review", "authors": ["Ammar Ahmed", "Ali Shariq Imran"], "categories": ["cs.HC", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.04469v2", "summary": "This systematic literature review examines the role of large language models\n(LLMs) in UI/UX design, synthesizing findings from 38 peer-reviewed studies\npublished between 2022 and 2025. We identify key LLMs in use, including GPT-4,\nGemini, and PaLM, and map their integration across the design lifecycle, from\nideation to evaluation. Common practices include prompt engineering,\nhuman-in-the-loop workflows, and multimodal input. While LLMs are reshaping\ndesign processes, challenges such as hallucination, prompt instability, and\nlimited explainability persist. Our findings highlight LLMs as emerging\ncollaborators in design, and we propose directions for the ethical, inclusive,\nand effective integration of these technologies.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.04469v2", "cate": "cs.HC", "date": "2025-07-06", "updated": "2025-07-17", "AI": {"title_translation": "大型语言模型在UI/UX设计中的作用：一项系统性文献综述", "tldr": "本系统性文献综述探讨了大型语言模型在UI/UX设计中的作用、应用、挑战及未来发展方向。", "motivation": "本研究旨在通过系统性文献综述，考察大型语言模型（LLMs）在UI/UX设计中的作用，并综合分析2022年至2025年间发表的38项同行评审研究成果。", "method": "本研究采用系统性文献综述的方法，综合分析了2022年至2025年间发表的38项同行评审研究，以识别大型语言模型在UI/UX设计中的应用、实践和挑战。", "result": "研究发现，常用的LLMs包括GPT-4、Gemini和PaLM，它们被整合到设计生命周期的各个阶段，从构思到评估。常见实践包括提示工程、人机协作流程和多模态输入。然而，幻觉、提示不稳定和可解释性有限等挑战依然存在。", "conclusion": "研究结论指出，大型语言模型正成为设计领域的新兴合作者，并提出了伦理、包容和有效整合这些技术的未来方向。", "translation": "本系统性文献综述旨在考察大型语言模型（LLMs）在UI/UX设计中的作用，综合了2022年至2025年间发表的38项同行评审研究成果。我们识别了正在使用的主要LLMs，包括GPT-4、Gemini和PaLM，并描绘了它们在设计生命周期（从构思到评估）中的整合。常见的实践包括提示工程、人机协作流程和多模态输入。尽管LLMs正在重塑设计流程，但幻觉、提示不稳定和可解释性有限等挑战依然存在。我们的研究结果强调LLMs是设计领域的新兴合作者，并且我们为这些技术的伦理、包容和有效整合提出了方向。", "summary": "本系统性文献综述分析了38项发表于2022年至2025年间的同行评审研究，旨在探讨大型语言模型（LLMs）在UI/UX设计中的作用。研究识别了GPT-4、Gemini和PaLM等关键LLMs，并阐述了它们在设计生命周期中的整合方式，包括提示工程、人机协作和多模态输入等常见实践。尽管LLMs正在改变设计流程，但仍面临幻觉、提示不稳定和可解释性有限等挑战。研究强调LLMs是设计领域的新兴合作者，并为未来伦理、包容和有效地整合这些技术提供了方向。", "keywords": "大型语言模型, UI/UX设计, 系统性文献综述, 提示工程, 人机协作", "comments": "这项研究的重要性在于它提供了一个关于大型语言模型在UI/UX设计领域应用的全面概览，特别是在新兴技术快速发展的背景下。它不仅识别了当前的应用和实践，还指出了存在的挑战，并为未来的研究和实践提供了伦理和有效整合的指导方向，对于理解LLMs在设计领域的潜力和局限性具有重要意义。"}}
{"id": "2507.13708", "title": "PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement", "authors": ["Sofia Jamil", "Bollampalli Areen Reddy", "Raghvendra Kumar", "Sriparna Saha", "Koustava Goswami", "K. J. Joseph"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ECAI 2025", "url": "http://arxiv.org/abs/2507.13708v1", "summary": "Recent advancements in text-to-image diffusion models have achieved\nremarkable success in generating realistic and diverse visual content. A\ncritical factor in this process is the model's ability to accurately interpret\ntextual prompts. However, these models often struggle with creative\nexpressions, particularly those involving complex, abstract, or highly\ndescriptive language. In this work, we introduce a novel training-free approach\ntailored to improve image generation for a unique form of creative language:\npoetic verse, which frequently features layered, abstract, and dual meanings.\nOur proposed PoemTale Diffusion approach aims to minimise the information that\nis lost during poetic text-to-image conversion by integrating a multi stage\nprompt refinement loop into Language Models to enhance the interpretability of\npoetic texts. To support this, we adapt existing state-of-the-art diffusion\nmodels by modifying their self-attention mechanisms with a consistent\nself-attention technique to generate multiple consistent images, which are then\ncollectively used to convey the poem's meaning. Moreover, to encourage research\nin the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting\nof 1111 poems sourced from multiple online and offline resources. We engaged a\npanel of poetry experts for qualitative assessments. The results from both\nhuman and quantitative evaluations validate the efficacy of our method and\ncontribute a novel perspective to poem-to-image generation with enhanced\ninformation capture in the generated images.", "comment": "ECAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.13708v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "PoemTale Diffusion：通过多阶段提示词优化最小化诗歌到图像生成中的信息损失", "tldr": "本文提出了一种名为PoemTale Diffusion的无训练方法，通过多阶段提示词优化和修改自注意力机制，旨在最小化诗歌到图像生成中的信息损失，并引入了P4I数据集。", "motivation": "尽管文本到图像扩散模型在生成逼真视觉内容方面取得了显著成功，但它们在处理创意表达，特别是涉及复杂、抽象或高度描述性语言（如诗歌）时，往往难以准确解释，导致信息损失。", "method": "本文提出了一种名为PoemTale Diffusion的无训练方法，该方法通过将多阶段提示词优化循环集成到语言模型中，以增强对诗歌文本的解释性。此外，通过修改现有最先进扩散模型的自注意力机制，采用一致的自注意力技术来生成多个一致的图像，并共同传达诗歌的含义。为促进诗歌领域的研究，还引入了包含1111首诗歌的P4I（PoemForImage）数据集。", "result": "通过人类专家和定量评估，验证了该方法的有效性，并在诗歌到图像生成中增强了生成图像的信息捕获。", "conclusion": "该研究成功地提出了一种新颖的方法来解决诗歌到图像生成中的信息损失问题，通过增强信息捕获，为该领域贡献了新的视角。", "translation": "文本到图像扩散模型的最新进展在生成逼真和多样化的视觉内容方面取得了显著成功。在此过程中，一个关键因素是模型准确解释文本提示的能力。然而，这些模型在处理创意表达，特别是涉及复杂、抽象或高度描述性语言时，往往会遇到困难。在这项工作中，我们引入了一种新颖的、无需训练的方法，旨在改善一种独特的创意语言形式——诗歌的图像生成，诗歌经常具有分层、抽象和双重含义。我们提出的PoemTale Diffusion方法旨在通过将多阶段提示词优化循环集成到语言模型中，以增强诗歌文本的可解释性，从而最大限度地减少诗歌文本到图像转换过程中丢失的信息。为了支持这一点，我们通过修改其自注意力机制，采用一致的自注意力技术来生成多个一致的图像，然后共同用于传达诗歌的含义，从而调整了现有的最先进扩散模型。此外，为了鼓励诗歌领域的研究，我们引入了P4I（PoemForImage）数据集，该数据集包含从多个在线和离线资源中获取的1111首诗歌。我们邀请了一个诗歌专家小组进行定性评估。人类评估和定量评估的结果都验证了我们方法的有效性，并为诗歌到图像生成提供了新的视角，增强了生成图像中的信息捕获。", "summary": "本文提出了一种名为PoemTale Diffusion的创新无训练方法，旨在解决文本到图像模型在处理复杂诗歌时信息损失的问题。该方法通过在语言模型中集成多阶段提示词优化循环来提高诗歌文本的可解释性，并通过修改扩散模型的自注意力机制来生成一致的图像，从而更好地传达诗歌含义。研究还引入了P4I数据集，并经过人类专家和定量评估验证了方法的有效性，为诗歌到图像生成领域的信息捕获提供了新视角。", "keywords": "诗歌到图像生成, 信息损失最小化, 提示词优化, 自注意力机制, P4I数据集", "comments": "这项工作通过引入一种无训练的多阶段提示词优化方法，有效地解决了扩散模型在处理抽象和多义诗歌时面临的信息损失挑战，具有创新性。其通过修改自注意力机制生成一致图像的策略，以及引入P4I数据集，都为诗歌到图像生成领域提供了重要的贡献和研究基础。"}}
{"id": "2507.13501", "title": "Encoding syntactic objects and Merge operations in function spaces", "authors": ["Matilde Marcolli", "Robert C. Berwick"], "categories": ["cs.CL", "math.RA", "q-bio.NC", "91F20, 16Y60, 16T05, 92C20"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      40 pages, LaTeX, 4 png figures", "url": "http://arxiv.org/abs/2507.13501v1", "summary": "We provide a mathematical argument showing that, given a representation of\nlexical items as functions (wavelets, for instance) in some function space, it\nis possible to construct a faithful representation of arbitrary syntactic\nobjects in the same function space. This space can be endowed with a\ncommutative non-associative semiring structure built using the second Renyi\nentropy. The resulting representation of syntactic objects is compatible with\nthe magma structure. The resulting set of functions is an algebra over an\noperad, where the operations in the operad model circuits that transform the\ninput wave forms into a combined output that encodes the syntactic structure.\nThe action of Merge on workspaces is faithfully implemented as action on these\ncircuits, through a coproduct and a Hopf algebra Markov chain. The results\nobtained here provide a constructive argument showing the theoretical\npossibility of a neurocomputational realization of the core computational\nstructure of syntax. We also present a particular case of this general\nconstruction where this type of realization of Merge is implemented as a cross\nfrequency phase synchronization on sinusoidal waves. This also shows that Merge\ncan be expressed in terms of the successor function of a semiring, thus\nclarifying the well known observation of its similarities with the successor\nfunction of arithmetic.", "comment": "40 pages, LaTeX, 4 png figures", "pdf_url": "http://arxiv.org/pdf/2507.13501v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "编码函数空间中的句法对象和合并操作", "tldr": "本文提供了一种数学论证，展示了如何在函数空间中忠实地表示句法对象和合并操作，并暗示了句法核心计算结构神经计算实现的可能性。", "motivation": "本文旨在提供一个数学论证，证明句法核心计算结构神经计算实现的理论可能性。", "method": "该方法涉及将词汇项表示为函数空间中的函数（例如小波）。该空间通过第二雷尼熵被赋予交换非结合半环结构。句法对象在此空间中表示，并与岩浆结构兼容。函数集合形成一个在操作子上的代数，其中操作子操作模拟转换输入波形的电路。Merge操作通过一个余积和霍普夫代数马尔可夫链忠实地实现在这些电路上。一个特例是将Merge实现为正弦波上的交叉频率相位同步。", "result": "本文证明了给定词汇项的函数表示，可以在函数空间中构建任意句法对象的忠实表示，且该表示与岩浆结构兼容。结果表明，函数集合形成一个在操作子上的代数，其中操作模拟电路。Merge在工作空间上的作用忠实地实现在这些电路上。一个特例展示了Merge作为交叉频率相位同步的实现。它还阐明了Merge可以用半环的后继函数来表达。", "conclusion": "结果提供了一个建设性的论证，显示了句法核心计算结构神经计算实现的理论可能性。它还表明Merge可以用半环的后继函数来表达。", "translation": "我们提供了一个数学论证，表明给定词汇项在某个函数空间（例如小波）中的函数表示，可以在同一函数空间中构建任意句法对象的忠实表示。这个空间可以用使用第二雷尼熵构建的交换非结合半环结构来赋予。句法对象的这种表示与岩浆结构兼容。由此产生的函数集合是一个在操作子上的代数，其中操作子中的操作模拟将输入波形转换为编码句法结构的组合输出的电路。Merge在工作空间上的作用通过一个余积和霍普夫代数马尔可链忠实地实现在这些电路上。这里获得的结果提供了一个建设性的论证，显示了句法核心计算结构神经计算实现的理论可能性。我们还提出了这种一般构造的一个特例，其中Merge的这种实现通过正弦波上的交叉频率相位同步来完成。这也表明Merge可以用半环的后继函数来表达，从而阐明了其与算术后继函数相似性的众所周知的观察。", "summary": "本文提出了一个在函数空间中表示句法对象和合并操作的数学框架。通过将词汇项概念化为函数（例如小波），作者在同一空间中构建了句法结构的忠实表示，并赋予其交换非结合半环结构。Merge操作随后被建模为操作子代数中电路上的作用，通过余积和霍普夫代数马尔可夫链实现。一个特定示例通过交叉频率相位同步展示了Merge。这项研究最终为核心句法过程的神经计算可行性提供了理论论证，并强调了Merge与算术后继函数之间的概念联系。", "keywords": "句法对象, 合并操作, 函数空间, 半环, 神经计算实现", "comments": "本文以其高度抽象和数学化的方法来模拟函数空间中的句法操作（特别是Merge）而具有创新性。它将理论语言学（乔姆斯基的Merge）与高级数学概念（函数空间、半环、操作子、霍普夫代数）相结合，提出了神经计算的实现可能性。其重要性在于为复杂的语言操作如何在大脑中物理实现提供了严谨的理论基础。对其而言，一个潜在的局限性可能是其高度的数学抽象性，这可能使其目前的直接实证验证具有挑战性。"}}
{"id": "2505.19068", "title": "Recalibrating binary probabilistic classifiers", "authors": ["Dirk Tasche"], "categories": ["cs.LG", "q-fin.RM", "68T09, 91G40", "I.5.1; G.3"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Presented at workshop Learning to Quantify 2025 (LQ 2025), this https URL", "url": "http://arxiv.org/abs/2505.19068v2", "summary": "Recalibration of binary probabilistic classifiers to a target prior\nprobability is an important task in areas like credit risk management. We\nanalyse methods for recalibration from a distribution shift perspective.\nDistribution shift assumptions linked to the area under the curve (AUC) of a\nprobabilistic classifier are found to be useful for the design of meaningful\nrecalibration methods. Two new methods called parametric covariate shift with\nposterior drift (CSPD) and ROC-based quasi moment matching (QMM) are proposed\nand tested together with some other methods in an example setting. The outcomes\nof the test suggest that the QMM methods discussed in the paper can provide\nappropriately conservative results in evaluations with concave functionals like\nfor instance risk weights functions for credit risk.", "comment": "Presented at workshop Learning to Quantify 2025 (LQ 2025),\n  https://lq-2025.github.io/", "pdf_url": "http://arxiv.org/pdf/2505.19068v2", "cate": "cs.LG", "date": "2025-05-25", "updated": "2025-07-18", "AI": {"title_translation": "二元概率分类器再校准", "tldr": "本文从分布漂移的角度分析了二元概率分类器的再校准方法，并提出了两种新方法（CSPD和QMM），测试结果表明QMM方法在信用风险等评估中能提供保守且恰当的结果。", "motivation": "将二元概率分类器再校准到目标先验概率是信用风险管理等领域的一项重要任务。", "method": "本文从分布漂移的角度分析了再校准方法。研究发现，与概率分类器曲线下面积（AUC）相关的分布漂移假设对设计有意义的再校准方法很有用。提出了两种新方法：参数协变量漂移与后验漂移（CSPD）和基于ROC的准矩匹配（QMM），并与其他方法在一个示例设置中进行了测试。", "result": "测试结果表明，论文中讨论的QMM方法在诸如信用风险权重函数等凹函数评估中，能够提供适当保守的结果。", "conclusion": "QMM方法在涉及凹函数评估（如信用风险权重函数）时，能为二元概率分类器的再校准提供恰当且保守的结果。", "translation": "将二元概率分类器再校准到目标先验概率是信用风险管理等领域的一项重要任务。我们从分布漂移的角度分析了再校准方法。研究发现，与概率分类器曲线下面积（AUC）相关的分布漂移假设对设计有意义的再校准方法很有用。本文提出了两种新方法，分别为带有后验漂移的参数协变量漂移（CSPD）和基于ROC的准矩匹配（QMM），并与一些其他方法在一个示例设置中进行了测试。测试结果表明，论文中讨论的QMM方法在诸如信用风险权重函数等凹函数评估中，能够提供适当保守的结果。", "summary": "本文研究了二元概率分类器的再校准问题，尤其是在信用风险管理等应用中。研究从分布漂移的角度分析了现有方法，并发现与AUC相关的分布漂移假设对于设计有效的再校准方法至关重要。基于此，论文提出了两种新方法：参数协变量漂移与后验漂移（CSPD）和基于ROC的准矩匹配（QMM）。通过实验测试，结果表明QMM方法在处理如信用风险权重函数等凹函数评估时，能够提供恰当且保守的结果。", "keywords": "二元分类器, 再校准, 分布漂移, 信用风险, QMM", "comments": "本文从分布漂移这一新颖视角审视了二元概率分类器的再校准问题，并提出两种新的方法，特别是QMM方法在信用风险管理等实际应用中展现出提供保守且稳健结果的潜力，具有重要的实践意义。"}}
{"id": "2507.13383", "title": "Whose View of Safety? A Deep DIVE Dataset for Pluralistic Alignment of Text-to-Image Models", "authors": ["Charvi Rastogi", "Tian Huey Teh", "Pushkar Mishra", "Roma Patel", "Ding Wang", "Mark Díaz", "Alicia Parrish", "Aida Mostafazadeh Davani", "Zoe Ashwood", "Michela Paganini", "Vinodkumar Prabhakaran", "Verena Rieser", "Lora Aroyo"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      28 pages, 16 figures", "url": "http://arxiv.org/abs/2507.13383v1", "summary": "Current text-to-image (T2I) models often fail to account for diverse human\nexperiences, leading to misaligned systems. We advocate for pluralistic\nalignment, where an AI understands and is steerable towards diverse, and often\nconflicting, human values. Our work provides three core contributions to\nachieve this in T2I models. First, we introduce a novel dataset for Diverse\nIntersectional Visual Evaluation (DIVE) -- the first multimodal dataset for\npluralistic alignment. It enable deep alignment to diverse safety perspectives\nthrough a large pool of demographically intersectional human raters who\nprovided extensive feedback across 1000 prompts, with high replication,\ncapturing nuanced safety perceptions. Second, we empirically confirm\ndemographics as a crucial proxy for diverse viewpoints in this domain,\nrevealing significant, context-dependent differences in harm perception that\ndiverge from conventional evaluations. Finally, we discuss implications for\nbuilding aligned T2I models, including efficient data collection strategies,\nLLM judgment capabilities, and model steerability towards diverse perspectives.\nThis research offers foundational tools for more equitable and aligned T2I\nsystems. Content Warning: The paper includes sensitive content that may be\nharmful.", "comment": "28 pages, 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.13383v1", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "谁的安全观？一个用于文本到图像模型多元对齐的深度DIVE数据集", "tldr": "本研究引入DIVE数据集，通过考虑人口统计学差异，旨在实现文本到图像模型的多元化安全对齐。", "motivation": "当前的文本到图像（T2I）模型未能考虑到多样化的人类经验，导致系统偏差。本研究旨在实现多元化对齐，使AI能够理解并适应多样化且常冲突的人类价值观。", "method": "本研究通过三项核心贡献实现目标：首先，引入了一个新颖的多模态数据集DIVE（Diverse Intersectional Visual Evaluation），用于多元化对齐。该数据集通过大量具有人口统计学交叉性的评估者，在1000个提示上提供了广泛反馈，捕捉了细微的安全感知。其次，经验性地证实了人口统计学是该领域多样化视角的关键代理。", "result": "DIVE数据集实现了对多样化安全视角的深度对齐。研究发现，人口统计学是多样化观点的关键代理，揭示了在危害感知方面存在显著的、依赖于上下文的差异，这些差异与传统评估不同。", "conclusion": "本研究为构建更公平、更对齐的文本到图像系统提供了基础工具，并讨论了包括高效数据收集策略、LLM判断能力以及模型向多样化视角的可控性在内的影响。", "translation": "当前文本到图像（T2I）模型往往未能考虑到多样化的人类经验，导致系统失衡。我们提倡多元化对齐，即人工智能能够理解并可控地适应多样化且常常相互冲突的人类价值观。我们的工作为在T2I模型中实现这一目标提供了三个核心贡献。首先，我们引入了一个新颖的多元交叉视觉评估（DIVE）数据集——这是第一个用于多元化对齐的多模态数据集。它通过大量具有人口统计学交叉性的人类评估者，在1000个提示上提供了广泛反馈，具有高重复性，捕捉了细致入微的安全感知，从而实现了对多样化安全视角的深度对齐。其次，我们经验性地证实了人口统计学是该领域多样化视角的关键代理，揭示了在危害感知方面存在显著的、依赖于上下文的差异，这些差异与传统评估不同。最后，我们讨论了构建对齐的T2I模型的影响，包括高效的数据收集策略、大型语言模型（LLM）的判断能力以及模型向多样化视角的可控性。这项研究为构建更公平、更对齐的T2I系统提供了基础工具。内容警告：本文包含可能有害的敏感内容。", "summary": "本论文提出了一种实现文本到图像模型多元化对齐的新方法，通过引入DIVE数据集，该数据集利用具有人口统计学交叉性的人类评估者来捕捉多样化的安全感知。研究证实人口统计学是多样化视角的关键代理，并讨论了构建更公平T2I模型的策略和影响。", "keywords": "文本到图像模型, 多元化对齐, DIVE数据集, 安全感知, 人口统计学", "comments": "该论文的创新之处在于提出了“多元化对齐”的概念，并首次构建了DIVE多模态数据集来支持这一目标。通过强调人口统计学在安全感知中的重要性，它挑战了传统的评估方法，为构建更具包容性和公平性的AI系统提供了新的视角和基础工具。"}}
{"id": "2507.13401", "title": "MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing", "authors": ["Shreya Kadambi", "Risheek Garrepalli", "Shubhankar Borse", "Munawar Hyatt", "Fatih Porikli"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      26 pages", "url": "http://arxiv.org/abs/2507.13401v1", "summary": "Despite the remarkable success of diffusion models in text-to-image\ngeneration, their effectiveness in grounded visual editing and compositional\ncontrol remains challenging. Motivated by advances in self-supervised learning\nand in-context generative modeling, we propose a series of simple yet powerful\ndesign choices that significantly enhance diffusion model capacity for\nstructured, controllable generation and editing. We introduce Masking-Augmented\nDiffusion with Inference-Time Scaling (MADI), a framework that improves the\neditability, compositionality and controllability of diffusion models through\ntwo core innovations. First, we introduce Masking-Augmented gaussian Diffusion\n(MAgD), a novel training strategy with dual corruption process which combines\nstandard denoising score matching and masked reconstruction by masking noisy\ninput from forward process. MAgD encourages the model to learn discriminative\nand compositional visual representations, thus enabling localized and\nstructure-aware editing. Second, we introduce an inference-time capacity\nscaling mechanism based on Pause Tokens, which act as special placeholders\ninserted into the prompt for increasing computational capacity at inference\ntime. Our findings show that adopting expressive and dense prompts during\ntraining further enhances performance, particularly for MAgD. Together, these\ncontributions in MADI substantially enhance the editability of diffusion\nmodels, paving the way toward their integration into more general-purpose,\nin-context generative diffusion architectures.", "comment": "26 pages", "pdf_url": "http://arxiv.org/pdf/2507.13401v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "MADI：用于视觉编辑的掩码增强扩散与推理时缩放", "tldr": "MADI通过掩码增强训练和推理时缩放，显著提升了扩散模型在视觉编辑方面的可控性和可组合性。", "motivation": "尽管扩散模型在文本到图像生成方面取得了显著成功，但在接地视觉编辑和组合控制方面仍然面临挑战。", "method": "提出了MADI框架，包含两项核心创新：1. 掩码增强高斯扩散（MAgD），一种结合标准去噪分数匹配和掩码重建的双重损坏训练策略。2. 基于暂停令牌（Pause Tokens）的推理时容量缩放机制，用于增加推理时的计算能力。", "result": "MADI显著增强了扩散模型的可编辑性、可组合性和可控性。研究发现，在训练期间采用富有表现力的密集提示能进一步提升性能，特别是对于MAgD。", "conclusion": "MADI的贡献实质性地增强了扩散模型的可编辑性，为它们集成到更通用的上下文生成扩散架构中铺平了道路。", "translation": "尽管扩散模型在文本到图像生成方面取得了显著成功，但它们在接地视觉编辑和组合控制方面的有效性仍然面临挑战。受自监督学习和上下文生成建模进展的启发，我们提出了一系列简单而强大的设计选择，这些选择显著增强了扩散模型在结构化、可控生成和编辑方面的能力。我们引入了掩码增强扩散与推理时缩放（MADI），这是一个通过两项核心创新来提高扩散模型可编辑性、可组合性和可控性的框架。首先，我们引入了掩码增强高斯扩散（MAgD），这是一种新颖的训练策略，具有双重损坏过程，通过掩码前向过程中的噪声输入，结合了标准去噪分数匹配和掩码重建。MAgD鼓励模型学习判别性和组合性视觉表示，从而实现局部和结构感知编辑。其次，我们引入了一种基于暂停令牌（Pause Tokens）的推理时容量缩放机制，这些令牌作为插入到提示中的特殊占位符，用于在推理时增加计算能力。我们的研究结果表明，在训练期间采用富有表现力的密集提示能进一步提升性能，特别是对于MAgD。总的来说，MADI中的这些贡献实质性地增强了扩散模型的可编辑性，为它们集成到更通用的上下文生成扩散架构中铺平了道路。", "summary": "本文提出了MADI框架，旨在解决扩散模型在视觉编辑和组合控制方面的挑战。MADI通过引入掩码增强高斯扩散（MAgD）训练策略和基于暂停令牌的推理时容量缩放机制，显著提升了扩散模型的可编辑性、可组合性和可控性，使其能够进行局部和结构感知的编辑，并为集成到更通用的生成架构奠定基础。", "keywords": "扩散模型, 视觉编辑, 掩码增强扩散, 推理时缩放, 可控生成", "comments": "这篇论文通过引入MAgD训练策略和推理时容量缩放机制，为扩散模型在视觉编辑和可控生成方面带来了重要的创新。MAgD通过结合掩码重建，使模型学习更具判别性和组合性的表示，从而实现精细的局部编辑。暂停令牌的概念提供了一种灵活且高效的方式来在推理时动态调整计算能力，以适应更复杂的提示。这些贡献共同提升了扩散模型的实用性和泛化能力。"}}
{"id": "2507.13662", "title": "Iteratively Learning Muscle Memory for Legged Robots to Master Adaptive and High Precision Locomotion", "authors": ["Jing Cheng", "Yasser G. Alqaham", "Zhenyu Gan", "Amit K. Sanyal"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13662v1", "summary": "This paper presents a scalable and adaptive control framework for legged\nrobots that integrates Iterative Learning Control (ILC) with a biologically\ninspired torque library (TL), analogous to muscle memory. The proposed method\naddresses key challenges in robotic locomotion, including accurate trajectory\ntracking under unmodeled dynamics and external disturbances. By leveraging the\nrepetitive nature of periodic gaits and extending ILC to nonperiodic tasks, the\nframework enhances accuracy and generalization across diverse locomotion\nscenarios. The control architecture is data-enabled, combining a physics-based\nmodel derived from hybrid-system trajectory optimization with real-time\nlearning to compensate for model uncertainties and external disturbances. A\ncentral contribution is the development of a generalized TL that stores learned\ncontrol profiles and enables rapid adaptation to changes in speed, terrain, and\ngravitational conditions-eliminating the need for repeated learning and\nsignificantly reducing online computation. The approach is validated on the\nbipedal robot Cassie and the quadrupedal robot A1 through extensive simulations\nand hardware experiments. Results demonstrate that the proposed framework\nreduces joint tracking errors by up to 85% within a few seconds and enables\nreliable execution of both periodic and nonperiodic gaits, including slope\ntraversal and terrain adaptation. Compared to state-of-the-art whole-body\ncontrollers, the learned skills eliminate the need for online computation\nduring execution and achieve control update rates exceeding 30x those of\nexisting methods. These findings highlight the effectiveness of integrating ILC\nwith torque memory as a highly data-efficient and practical solution for legged\nlocomotion in unstructured and dynamic environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13662v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "迭代学习肌肉记忆，使足式机器人掌握自适应高精度运动", "tldr": "本文提出了一种结合迭代学习控制（ILC）和扭矩库（肌肉记忆）的足式机器人控制框架，显著减少了轨迹跟踪误差和在线计算量，实现了自适应高精度运动。", "motivation": "解决机器人运动中未建模动力学和外部干扰下精确轨迹跟踪的关键挑战。", "method": "将迭代学习控制（ILC）与受生物启发的扭矩库（TL，类比肌肉记忆）相结合。该框架利用周期性步态的重复性，并将ILC扩展到非周期性任务。它是一种数据驱动的方法，结合了基于混合系统轨迹优化的物理模型与实时学习，以补偿模型不确定性和外部干扰。核心贡献是开发了一个通用TL，用于存储学习到的控制配置文件，并能快速适应速度、地形和重力条件的变化。", "result": "在几秒钟内将关节跟踪误差减少高达85%，并能可靠执行周期性和非周期性步态，包括斜坡穿越和地形适应。与现有最先进的全身控制器相比，所学的技能消除了执行过程中的在线计算需求，并将控制更新速率提高到现有方法的30倍以上。", "conclusion": "将ILC与扭矩记忆相结合是解决非结构化和动态环境下足式机器人运动的一种高效、实用方案。", "translation": "本文提出了一种可扩展的自适应足式机器人控制框架，该框架将迭代学习控制（ILC）与受生物启发的扭矩库（TL），类比肌肉记忆，相结合。所提出的方法解决了机器人运动中的关键挑战，包括在未建模动力学和外部干扰下的精确轨迹跟踪。通过利用周期性步态的重复性并将ILC扩展到非周期性任务，该框架增强了跨不同运动场景的准确性和泛化能力。该控制架构是数据驱动的，结合了源自混合系统轨迹优化的基于物理的模型与实时学习，以补偿模型不确定性和外部干扰。一个核心贡献是开发了一个通用的TL，用于存储学习到的控制配置文件，并能快速适应速度、地形和重力条件的变化——消除了重复学习的需要，并显著减少了在线计算。该方法在双足机器人Cassie和四足机器人A1上通过广泛的仿真和硬件实验进行了验证。结果表明，所提出的框架在几秒钟内将关节跟踪误差减少高达85%，并能可靠执行周期性和非周期性步态，包括斜坡穿越和地形适应。与最先进的全身控制器相比，所学的技能消除了执行过程中的在线计算需求，并实现了超过现有方法30倍的控制更新速率。这些发现强调了将ILC与扭矩记忆相结合作为一种高度数据高效和实用的解决方案，在非结构化和动态环境中实现足式运动的有效性。", "summary": "本文提出了一种可扩展的自适应足式机器人控制框架，该框架将迭代学习控制（ILC）与受生物启发的扭矩库（TL，类比肌肉记忆）相结合。该框架通过结合基于物理的模型和实时学习来解决未建模动力学和外部干扰下的轨迹跟踪挑战。其核心贡献在于开发了一个通用TL，用于存储学习到的控制配置文件，从而实现快速适应，无需重复学习或大量在线计算。在Cassie和A1机器人上的仿真和硬件实验验证表明，该方法在几秒钟内将关节跟踪误差减少高达85%，并能可靠执行周期性和非周期性步态，且控制更新速率比现有方法高30倍以上。这证明了其在非结构化和动态环境中实现鲁棒足式运动的有效性和实用性。", "keywords": "迭代学习控制, 足式机器人, 肌肉记忆, 自适应控制, 扭矩库", "comments": "该论文的创新点在于将迭代学习控制（ILC）与受生物启发的扭矩库（类比肌肉记忆）相结合，实现了足式机器人在复杂动态环境下高效、高精度的自适应运动。通过存储学习到的控制配置文件，极大地减少了在线计算需求和重复学习的必要性，显著提高了控制更新速率和轨迹跟踪精度，为足式机器人走向实际应用提供了重要的技术支持。"}}
{"id": "2502.13246", "title": "When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models", "authors": ["Julia Mendelsohn", "Ceren Budak"], "categories": ["cs.CL", "cs.CY"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      To appear at ACL 2025. Please cite ACL version when proceedings are available", "url": "http://arxiv.org/abs/2502.13246v2", "summary": "Metaphor, discussing one concept in terms of another, is abundant in politics\nand can shape how people understand important issues. We develop a\ncomputational approach to measure metaphorical language, focusing on\nimmigration discourse on social media. Grounded in qualitative social science\nresearch, we identify seven concepts evoked in immigration discourse (e.g.\n\"water\" or \"vermin\"). We propose and evaluate a novel technique that leverages\nboth word-level and document-level signals to measure metaphor with respect to\nthese concepts. We then study the relationship between metaphor, political\nideology, and user engagement in 400K US tweets about immigration. While\nconservatives tend to use dehumanizing metaphors more than liberals, this\neffect varies widely across concepts. Moreover, creature-related metaphor is\nassociated with more retweets, especially for liberal authors. Our work\nhighlights the potential for computational methods to complement qualitative\napproaches in understanding subtle and implicit language in political\ndiscourse.", "comment": "To appear at ACL 2025. Please cite ACL version when proceedings are\n  available", "pdf_url": "http://arxiv.org/pdf/2502.13246v2", "cate": "cs.CL", "date": "2025-02-18", "updated": "2025-07-18", "AI": {"title_translation": "当人们是洪水：使用大型语言模型分析移民话语中的非人化隐喻", "tldr": "本研究开发了一种计算方法，利用大型语言模型分析社交媒体上移民话语中的非人化隐喻，发现保守派比自由派更多使用此类隐喻，且与生物相关的隐喻能带来更多转发。", "motivation": "隐喻在政治中普遍存在并能塑造人们对重要问题的理解。本研究旨在测量社交媒体上移民话语中的隐喻语言，特别是非人化隐喻，以理解其使用模式及与政治意识形态和用户参与度的关系。", "method": "开发了一种计算方法来测量隐喻语言，重点关注移民话语。基于定性社会科学研究，识别了移民话语中引用的七个概念（如“水”或“害虫”）。提出并评估了一种新颖的技术，该技术利用词级和文档级信号来测量与这些概念相关的隐喻。最后，研究了40万条关于移民的美国推文中隐喻、政治意识形态和用户参与度之间的关系。", "result": "研究发现，保守派比自由派更倾向于使用非人化隐喻，但这种影响在不同概念之间差异很大。此外，与生物相关的隐喻与更多的转发相关，特别是对于自由派作者。", "conclusion": "本研究强调了计算方法在理解政治话语中微妙和隐含语言方面补充定性方法的潜力。", "translation": "隐喻，即用一个概念来讨论另一个概念，在政治中大量存在，并能塑造人们对重要问题的理解。我们开发了一种计算方法来测量隐喻语言，重点关注社交媒体上的移民话语。基于定性社会科学研究，我们识别了移民话语中引用的七个概念（例如“水”或“害虫”）。我们提出并评估了一种新颖的技术，该技术利用词级和文档级信号来测量与这些概念相关的隐喻。然后，我们研究了40万条关于移民的美国推文中隐喻、政治意识形态和用户参与度之间的关系。虽然保守派比自由派更倾向于使用非人化隐喻，但这种影响在不同概念之间差异很大。此外，与生物相关的隐喻与更多的转发相关，特别是对于自由派作者。我们的工作强调了计算方法在理解政治话语中微妙和隐含语言方面补充定性方法的潜力。", "summary": "本文开发了一种计算方法来分析社交媒体上移民话语中的非人化隐喻。研究识别了七个关键概念，并提出了一种结合词级和文档级信号的新技术来测量隐喻。通过分析40万条美国推文，研究发现保守派比自由派更多使用非人化隐喻，且生物相关隐喻能显著增加转发量，尤其对自由派作者。这项工作展示了计算方法在分析政治话语中隐晦语言的潜力。", "keywords": "隐喻, 移民话语, 非人化, 计算方法, 社交媒体", "comments": "本文的创新之处在于其将计算方法应用于政治话语中非人化隐喻的量化分析，特别是提出了结合词级和文档级信号的新技术。这为理解复杂社会现象中的语言使用模式提供了一个有力的工具，并强调了计算方法与定性研究相结合的潜力。其发现关于政治意识形态与隐喻使用及用户参与度的关系具有重要的社会意义。"}}
{"id": "2507.11649", "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "authors": ["Daniel Commey", "Benjamin Appiah", "Griffith S. Klogo", "Garth V. Crosby"], "categories": ["cs.LG", "cs.DC", "cs.NI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11649v2", "summary": "Federated Learning (FL) enables collaborative model training on decentralized\ndata without exposing raw data. However, the evaluation phase in FL may leak\nsensitive information through shared performance metrics. In this paper, we\npropose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to\nenable privacy-preserving and verifiable evaluation for FL. Instead of\nrevealing raw loss values, clients generate a succinct proof asserting that\ntheir local loss is below a predefined threshold. Our approach is implemented\nwithout reliance on external APIs, using self-contained modules for federated\nlearning simulation, ZKP circuit design, and experimental evaluation on both\nthe MNIST and Human Activity Recognition (HAR) datasets. We focus on a\nthreshold-based proof for a simple Convolutional Neural Network (CNN) model\n(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate\nthe approach in terms of computational overhead, communication cost, and\nverifiability.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11649v2", "cate": "cs.LG", "date": "2025-07-15", "updated": "2025-07-18", "AI": {"title_translation": "ZKP-FedEval：使用零知识证明的可验证和隐私保护联邦评估", "tldr": "ZKP-FedEval利用零知识证明实现联邦学习中隐私保护且可验证的模型评估。", "motivation": "联邦学习的评估阶段可能通过共享的性能指标泄露敏感信息。", "method": "本文提出一种结合零知识证明（ZKPs）的新协议，以实现联邦学习的隐私保护和可验证评估。客户端不透露原始损失值，而是生成一个简洁的证明，断言其局部损失低于预设阈值。该方法不依赖外部API，使用自包含模块进行联邦学习模拟、ZKP电路设计和实验评估。", "result": "在MNIST和人类活动识别（HAR）数据集上进行了实验评估，重点关注基于阈值的简单卷积神经网络（CNN）模型（用于MNIST）和多层感知器（MLP）模型（用于HAR）的证明，并评估了该方法在计算开销、通信成本和可验证性方面的表现。", "conclusion": "该研究提出并验证了ZKP-FedEval协议在联邦学习评估中的可行性，在保证隐私和可验证性的同时，评估了其计算和通信成本，有效解决了联邦学习评估阶段的隐私泄露问题。", "translation": "联邦学习（FL）能够在不暴露原始数据的情况下，在去中心化数据上进行协作模型训练。然而，FL中的评估阶段可能通过共享的性能指标泄露敏感信息。在本文中，我们提出了一种结合零知识证明（ZKPs）的新协议，以实现FL的隐私保护和可验证评估。客户端不透露原始损失值，而是生成一个简洁的证明，断言其局部损失低于预设阈值。我们的方法不依赖外部API，使用自包含模块进行联邦学习模拟、ZKP电路设计，并在MNIST和人类活动识别（HAR）数据集上进行实验评估。我们专注于针对简单卷积神经网络（CNN）模型（用于MNIST）和多层感知器（MLP）模型（用于HAR）的基于阈值的证明，并评估了该方法在计算开销、通信成本和可验证性方面的表现。", "summary": "本文提出ZKP-FedEval，一个利用零知识证明在联邦学习中实现隐私保护和可验证评估的新协议。该协议允许客户端证明其本地损失低于预设阈值，而无需泄露原始损失值。研究在MNIST和HAR数据集上对该方法进行了实现和评估，分析了其计算开销、通信成本和可验证性，旨在解决联邦学习评估阶段潜在的数据泄露问题。", "keywords": "联邦学习, 零知识证明, 隐私保护, 模型评估, 可验证性", "comments": "该论文通过引入零知识证明来解决联邦学习评估阶段的隐私泄露问题，具有创新性。其不依赖外部API的自包含实现方式增加了其独立性和潜在的部署灵活性。通过关注阈值证明和评估计算/通信成本，为实际应用提供了有价值的参考。"}}
{"id": "2507.13885", "title": "Quantum Pattern Matching with Wildcards", "authors": ["Masoud Seddighin", "Saeed Seddighin"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13885v1", "summary": "Pattern matching is one of the fundamental problems in Computer Science. Both\nthe classic version of the problem as well as the more sophisticated version\nwhere wildcards can also appear in the input can be solved in almost linear\ntime $\\tilde O(n)$ using the KMP algorithm and Fast Fourier Transform,\nrespectively. In 2000, Ramesh and Vinay~\\cite{ramesh2003string} give a quantum\nalgorithm that solves classic pattern matching in sublinear time and asked\nwhether the wildcard problem can also be solved in sublinear time? In this\nwork, we give a quantum algorithm for pattern matching with wildcards that runs\nin time $\\tilde O(\\sqrt{n}\\sqrt{k})$ when the number of wildcards is bounded by\n$k$ for $k \\geq \\sqrt{n}$. This leads to an algorithm that runs in sublinear\ntime as long as the number of wildcards is sublinear.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13885v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "带通配符的量子模式匹配", "tldr": "本文提出了一种解决带通配符模式匹配问题的量子算法，其运行时间为 $\\tilde O(\\sqrt{n}\\sqrt{k})$，在通配符数量次线性时实现了次线性时间复杂度。", "motivation": "经典的模式匹配和带通配符的模式匹配问题都可以用准线性时间算法解决。Ramesh和Vinay在2000年提出了一个解决经典模式匹配问题的次线性时间量子算法，并提出了带通配符问题是否也能在次线性时间解决的开放问题。", "method": "本文提出了一种用于带通配符模式匹配的量子算法。", "result": "当通配符的数量 $k$ 满足 $k \\geq \\sqrt{n}$ 时，该量子算法的运行时间为 $\\tilde O(\\sqrt{n}\\sqrt{k})$。", "conclusion": "该算法在通配符数量为次线性时，能够实现次线性时间复杂度。", "translation": "模式匹配是计算机科学中的一个基本问题。该问题的经典版本以及更复杂的、输入中可以出现通配符的版本，都可以分别使用KMP算法和快速傅里叶变换在准线性时间 $\\tilde O(n)$ 内解决。2000年，Ramesh和Vinay~\\[ramesh2003string\\]给出了一个在次线性时间内解决经典模式匹配问题的量子算法，并提出了通配符问题是否也能在次线性时间内解决的疑问。在这项工作中，我们提出了一种带通配符模式匹配的量子算法，当通配符数量 $k$ 受限于 $k \\geq \\sqrt{n}$ 时，其运行时间为 $\\tilde O(\\sqrt{n}\\sqrt{k})$。这使得只要通配符数量是次线性的，算法就能以次线性时间运行。", "summary": "本文针对带通配符的模式匹配问题，提出了一种新的量子算法。该算法在通配符数量 $k$ 满足 $k \\geq \\sqrt{n}$ 的情况下，运行时间为 $\\tilde O(\\sqrt{n}\\sqrt{k})$，从而在通配符数量为次线性时实现了次线性的时间复杂度，解决了先前提出的开放问题。", "keywords": "量子算法, 模式匹配, 通配符, 次线性时间, KMP", "comments": "本文解决了计算机科学中一个重要且长期存在的开放问题，即带通配符的模式匹配能否在次线性时间内解决。通过引入一种新颖的量子算法，作者证明了在特定条件下（通配符数量次线性），该问题可以被次线性地解决，这在量子计算领域具有重要意义。"}}
{"id": "2501.01593", "title": "BLAST: A Stealthy Backdoor Leverage Attack against Cooperative Multi-Agent Deep Reinforcement Learning based Systems", "authors": ["Jing Fang", "Saihao Yan", "Xueyu Yin", "Yinbo Yu", "Chunwei Tian", "Jiajia Liu"], "categories": ["cs.AI", "cs.CR", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      12. arXiv admin note: substantial text overlap with arXiv:2409.07775", "url": "http://arxiv.org/abs/2501.01593v2", "summary": "Recent studies have shown that cooperative multi-agent deep reinforcement\nlearning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor\ntrigger is observed, it will perform malicious actions leading to failures or\nmalicious goals. However, existing backdoor attacks suffer from several issues,\ne.g., instant trigger patterns lack stealthiness, the backdoor is trained or\nactivated by an additional network, or all agents are backdoored. To this end,\nin this paper, we propose a novel backdoor leverage attack against c-MADRL,\nBLAST, which attacks the entire multi-agent team by embedding the backdoor only\nin a single agent. Firstly, we introduce adversary spatiotemporal behavior\npatterns as the backdoor trigger rather than manual-injected fixed visual\npatterns or instant status and control the period to perform malicious actions.\nThis method can guarantee the stealthiness and practicality of BLAST. Secondly,\nwe hack the original reward function of the backdoor agent via unilateral\nguidance to inject BLAST, so as to achieve the \\textit{leverage attack effect}\nthat can pry open the entire multi-agent system via a single backdoor agent. We\nevaluate our BLAST against 3 classic c-MADRL algorithms (VDN, QMIX, and MAPPO)\nin 2 popular c-MADRL environments (SMAC and Pursuit), and 2 existing defense\nmechanisms. The experimental results demonstrate that BLAST can achieve a high\nattack success rate while maintaining a low clean performance variance rate.", "comment": "12. arXiv admin note: substantial text overlap with arXiv:2409.07775", "pdf_url": "http://arxiv.org/pdf/2501.01593v2", "cate": "cs.AI", "date": "2025-01-03", "updated": "2025-07-18", "AI": {"title_translation": "BLAST：一种针对合作多智能体深度强化学习系统的隐蔽后门杠杆攻击", "tldr": "现有针对合作多智能体深度强化学习（c-MADRL）的后门攻击存在隐蔽性差、需要额外网络或感染所有智能体等问题。本文提出BLAST，一种新型隐蔽后门杠杆攻击，通过在单个智能体中植入后门，利用对手时空行为模式作为触发器并修改奖励函数，实现对整个多智能体系统的攻击，具有高攻击成功率和低性能影响。", "motivation": "现有针对合作多智能体深度强化学习（c-MADRL）的后门攻击存在若干问题，例如：瞬时触发模式缺乏隐蔽性；后门需要通过额外网络进行训练或激活；或者所有智能体都需要被植入后门。", "method": "本文提出了一种新颖的针对c-MADRL的后门杠杆攻击——BLAST。它通过仅在一个智能体中嵌入后门来攻击整个多智能体团队。首先，引入对手时空行为模式作为后门触发器，而非手动注入的固定视觉模式或瞬时状态，并控制执行恶意动作的周期，以保证BLAST的隐蔽性和实用性。其次，通过单边引导劫持后门智能体的原始奖励函数来注入BLAST，以实现通过单个后门智能体撬动整个多智能体系统的“杠杆攻击效应”。", "result": "实验结果表明，BLAST在保持较低的干净性能方差率的同时，可以实现高攻击成功率。BLAST在3种经典的c-MADRL算法（VDN、QMIX和MAPPO）的2种流行c-MADRL环境（SMAC和Pursuit）以及2种现有防御机制下进行了评估。", "conclusion": "BLAST是一种有效的、隐蔽的后门杠杆攻击，它能够通过在一个智能体中植入后门来成功攻击合作多智能体深度强化学习系统，并具有高攻击成功率和良好的隐蔽性。", "translation": "最近的研究表明，合作多智能体深度强化学习（c-MADRL）正面临后门攻击的威胁。一旦观察到后门触发器，它将执行恶意动作，导致系统故障或实现恶意目标。然而，现有的后门攻击存在一些问题，例如，瞬时触发模式缺乏隐蔽性，后门通过额外网络进行训练或激活，或者所有智能体都被植入后门。为此，本文提出了一种新颖的针对c-MADRL的后门杠杆攻击——BLAST，它通过仅在一个智能体中嵌入后门来攻击整个多智能体团队。首先，我们引入对手时空行为模式作为后门触发器，而非手动注入的固定视觉模式或瞬时状态，并控制执行恶意动作的周期。这种方法可以保证BLAST的隐蔽性和实用性。其次，我们通过单边引导劫持后门智能体的原始奖励函数来注入BLAST，以实现通过单个后门智能体撬动整个多智能体系统的“杠杆攻击效应”。我们在2个流行的c-MADRL环境（SMAC和Pursuit）和2种现有防御机制下，评估了我们的BLAST对3种经典c-MADRL算法（VDN、QMIX和MAPPO）的攻击效果。实验结果表明，BLAST在保持较低的干净性能方差率的同时，可以实现高攻击成功率。", "summary": "BLAST是一种新颖的、隐蔽的后门杠杆攻击，旨在解决现有合作多智能体深度强化学习（c-MADRL）后门攻击的缺陷。它通过在单个智能体中嵌入后门来攻击整个多智能体团队，利用对手时空行为模式作为触发器，并修改后门智能体的奖励函数以实现杠杆效应。实验证明，BLAST在保持低干净性能方差率的同时，能达到高攻击成功率。", "keywords": "后门攻击, 多智能体强化学习, 隐蔽攻击, 杠杆攻击, 合作系统", "comments": "本文的创新点在于其提出的BLAST攻击具有高度隐蔽性（通过使用时空行为模式作为触发器而非固定模式）和高效性（仅需感染单个智能体即可撬动整个多智能体系统）。通过操纵奖励函数来实现“杠杆攻击效应”是其核心亮点，这显著提升了对c-MADRL系统漏洞的理解。"}}
{"id": "2507.13310", "title": "Modelling the spillover from online engagement to offline protest: stochastic dynamics and mean-field approximations on networks", "authors": ["Moyi Tian", "P. Jeffrey Brantingham", "Nancy Rodríguez"], "categories": ["physics.soc-ph", "cs.SI", "math.DS", "nlin.AO", "q-bio.PE"], "primary_category": "Subjects:       Physics and Society (physics.soc-ph)", "pdf_link": null, "comments": "Comments:      44 pages, 33 figures", "url": "http://arxiv.org/abs/2507.13310v2", "summary": "Social media is transforming various aspects of offline life, from everyday\ndecisions such as dining choices to the progression of conflicts. In this\nstudy, we propose a coupled modelling framework with an online social network\nlayer to analyse how engagement on a specific topic spills over into offline\nprotest activities. We develop a stochastic model and derive several mean-field\nmodels of varying complexity. These models allow us to estimate the\nreproductive number and anticipate when surges in activity are likely to occur.\nA key factor is the transmission rate between the online and offline domains;\nfor offline outbursts to emerge, this rate must fall within a critical range,\nneither too low nor too high. Additionally, using synthetic networks, we\nexamine how network structure influences the accuracy of these approximations.\nOur findings indicate that low-density networks need more complex\napproximations, whereas simpler models can effectively represent higher-density\nnetworks. When tested on two real-world networks, however, increased complexity\ndid not enhance accuracy.", "comment": "44 pages, 33 figures", "pdf_url": "http://arxiv.org/pdf/2507.13310v2", "cate": "physics.soc-ph", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "建模在线参与到线下抗议的溢出效应：网络上的随机动力学和平均场近似", "tldr": "本研究提出了一个耦合建模框架，分析在线社交媒体参与如何溢出到线下抗议活动。研究开发了随机模型和平均场模型来预测活动激增，并发现在线到离线传输率是线下爆发的关键因素，且网络结构影响模型准确性。", "motivation": "社交媒体正在改变线下生活的各个方面，包括冲突的进展。本研究旨在分析在线参与如何溢出到线下抗议活动。", "method": "提出了一个包含在线社交网络层的耦合建模框架，开发了随机模型和不同复杂度的平均场模型。通过这些模型估计再生数并预测活动激增。研究还使用合成网络和真实世界网络测试了模型，以检验网络结构对近似准确性的影响。", "result": "模型能够估计再生数并预测活动激增。在线到离线领域的传输率是关键因素，必须在临界范围内才能出现线下爆发。低密度网络需要更复杂的近似模型，而高密度网络可以使用更简单的模型。然而，在两个真实世界网络上测试时，增加模型复杂度并未提高准确性。", "conclusion": "在线到离线领域的传输率对于线下抗议活动的出现至关重要，且必须处于一个临界范围。网络结构会影响平均场近似的准确性，但增加模型复杂度在真实世界网络上并不一定能提高准确性。", "translation": "社交媒体正在改变线下生活的各个方面，从日常的用餐选择到冲突的进展。在本研究中，我们提出了一个包含在线社交网络层的耦合建模框架，以分析特定主题的在线参与如何溢出到线下抗议活动。我们开发了一个随机模型并推导出了几种不同复杂度的平均场模型。这些模型使我们能够估计再生数并预测活动何时可能出现激增。一个关键因素是在线和离线领域之间的传输率；为了出现线下爆发，该传输率必须落在临界范围内，既不能太低也不能太高。此外，我们使用合成网络，研究了网络结构如何影响这些近似的准确性。我们的发现表明，低密度网络需要更复杂的近似，而更简单的模型可以有效表示高密度网络。然而，当在两个真实世界网络上进行测试时，复杂度的增加并未提高准确性。", "summary": "本文提出了一种耦合建模框架，用于分析在线社交媒体参与如何溢出到线下抗议活动。研究开发了随机模型和多种复杂度的平均场模型，旨在估计再生数并预测活动激增。研究发现，在线到线下领域的传输率是关键因素，其必须在特定临界范围内才能引发线下爆发。此外，研究还探讨了网络结构对模型近似准确性的影响，指出低密度网络需要更复杂的近似模型。然而，在真实世界网络的测试中，增加模型复杂度并未带来更高的准确性。", "keywords": "在线参与, 线下抗议, 随机动力学, 平均场近似, 社交网络", "comments": "这项研究通过提出一个耦合模型框架来量化在线参与对线下抗议的影响，具有创新性。它强调了在线-离线传输率的重要性，并探讨了网络结构对模型准确性的影响。然而，在真实世界网络上增加模型复杂度未能提高准确性这一点，可能意味着模型需要进一步的细化或者现实世界的复杂性超出了当前模型的捕捉范围。"}}
{"id": "2507.13463", "title": "Joint Motion, Angle, and Range Estimation in Near-Field under Array Calibration Imperfections", "authors": ["Ahmed Hussain", "Asmaa Abdallah", "Abdulkadir Celik", "Ahmed M. Eltawil"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13463v1", "summary": "Ultra-massive multiple-input multiple-output MIMO (UM-MIMO) leverages large\nantenna arrays at high frequencies, transitioning communication paradigm into\nthe radiative near-field (NF), where spherical wavefronts enable full-vector\nestimation of both target location and velocity. However, location and motion\nparameters become inherently coupled in this regime, making their joint\nestimation computationally demanding. To overcome this, we propose a novel\napproach that projects the received two-dimensional space-time signal onto the\nangle-Doppler domain using a two-dimensional discrete Fourier transform\n(2D-DFT). Our analysis reveals that the resulting angular spread is centered at\nthe target's true angle, with its width determined by the target's range.\nSimilarly, transverse motion induces a Doppler spread centered at the true\nradial velocity, with the width of Doppler spread proportional to the\ntransverse velocity. Exploiting these spectral characteristics, we develop a\nlow-complexity algorithm that provides coarse estimates of angle, range, and\nvelocity, which are subsequently refined using one-dimensional multiple signal\nclassification (MUSIC) applied independently to each parameter. The proposed\nmethod enables accurate and efficient estimation of NF target motion\nparameters. Simulation results demonstrate a normalized mean squared error\n(NMSE) of -40 dB for location and velocity estimates compared to maximum\nlikelihood estimation, while significantly reducing computational complexity.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13463v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "近场阵列校准缺陷下的运动、角度和距离联合估计", "tldr": "针对超大规模MIMO近场场景中目标位置与运动参数耦合导致联合估计计算量大的问题，本文提出一种基于2D-DFT投影和MUSIC精化的低复杂度算法，实现了对目标运动参数的准确高效估计。", "motivation": "在超大规模MIMO (UM-MIMO) 的辐射近场 (NF) 中，目标的位置和运动参数是固有耦合的，这使得它们的联合估计计算量巨大。", "method": "本文提出一种新颖的方法，通过二维离散傅里叶变换 (2D-DFT) 将接收到的二维时空信号投影到角度-多普勒域。该方法利用角度扩展和多普勒扩展的频谱特性，首先提供角度、距离和速度的粗略估计，然后通过独立应用于每个参数的一维多重信号分类 (MUSIC) 进行精化。", "result": "仿真结果表明，与最大似然估计相比，该方法在位置和速度估计方面的归一化均方误差 (NMSE) 达到-40 dB，同时显著降低了计算复杂度。", "conclusion": "所提出的方法能够准确高效地估计近场目标运动参数。", "translation": "超大规模多输入多输出MIMO (UM-MIMO) 利用高频大型天线阵列，将通信范式转换为辐射近场 (NF)，其中球面波前能够实现目标位置和速度的全矢量估计。然而，在此区域内，位置和运动参数固有耦合，使得它们的联合估计计算量巨大。为了克服这个问题，我们提出了一种新颖的方法，通过二维离散傅里叶变换 (2D-DFT) 将接收到的二维时空信号投影到角度-多普勒域。我们的分析表明，由此产生的角度扩展以目标的真实角度为中心，其宽度由目标的距离决定。同样，横向运动会引起以真实径向速度为中心的多普勒扩展，多普勒扩展的宽度与横向速度成正比。利用这些频谱特性，我们开发了一种低复杂度的算法，该算法提供角度、距离和速度的粗略估计，随后通过独立应用于每个参数的一维多重信号分类 (MUSIC) 进行精化。所提出的方法能够准确高效地估计近场目标运动参数。仿真结果表明，与最大似然估计相比，位置和速度估计的归一化均方误差 (NMSE) 为-40 dB，同时显著降低了计算复杂度。", "summary": "本文提出一种在超大规模MIMO辐射近场环境下对目标运动、角度和距离进行联合估计的低复杂度算法。该算法通过将接收信号投影到角度-多普勒域，并利用其频谱特性进行粗略估计，随后结合一维MUSIC算法对各参数进行精化。实验证明，该方法在保持高估计精度的同时，显著降低了计算复杂度。", "keywords": "UM-MIMO, 近场感知, 角度-多普勒域, MUSIC算法, 联合估计", "comments": "该论文提出了一种创新的方法来解决近场UM-MIMO系统中位置和运动参数耦合导致的计算复杂性问题。通过将2D-DFT与1D MUSIC相结合，实现了精度和效率的平衡，这对于未来近场感知和通信一体化具有重要意义。然而，摘要中没有详细说明该方法如何具体处理标题中提及的“阵列校准缺陷”。"}}
{"id": "2507.13672", "title": "Spacecraft Safe Robust Control Using Implicit Neural Representation for Geometrically Complex Targets in Proximity Operations", "authors": ["Hang Zhou", "Tao Meng", "Kun Wang", "Chengrui Shi", "Renhao Mao", "Weijia Wang", "Jiakun Lei"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      15 pages, 18 figures, submitted to TAES", "url": "http://arxiv.org/abs/2507.13672v1", "summary": "This study addresses the challenge of ensuring safe spacecraft proximity\noperations, focusing on collision avoidance between a chaser spacecraft and a\ncomplex-geometry target spacecraft under disturbances. To ensure safety in such\nscenarios, a safe robust control framework is proposed that leverages implicit\nneural representations. To handle arbitrary target geometries without explicit\nmodeling, a neural signed distance function (SDF) is learned from point cloud\ndata via a enhanced implicit geometric regularization method, which\nincorporates an over-apporximation strategy to create a conservative,\nsafety-prioritized boundary. The target's surface is implicitly defined by the\nzero-level set of the learned neural SDF, while the values and gradients\nprovide critical information for safety controller design. This neural SDF\nrepresentation underpins a two-layer hierarchcial safe robust control\nframework: a safe velocity generation layer and a safe robust controller layer.\nIn the first layer, a second-order cone program is formulated to generate\nsafety-guaranteed reference velocity by explicitly incorporating the\nunder-approximation error bound. Furthermore, a circulation inequality is\nintroduced to mitigate the local minimum issues commonly encountered in control\nbarrier function (CBF) methods. The second layer features an integrated\ndisturbance observer and a smooth safety filter explicitly compensating for\nestimation error, bolstering robustness to external disturbances. Extensive\nnumerical simulations and Monte Carlo analysis validate the proposed framework,\ndemonstrating significantly improved safety margins and avoidance of local\nminima compared to conventional CBF approaches.", "comment": "15 pages, 18 figures, submitted to TAES", "pdf_url": "http://arxiv.org/pdf/2507.13672v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "航天器近距离操作中基于隐式神经表示的几何复杂目标安全鲁棒控制", "tldr": "本研究提出了一种利用隐式神经表示的安全鲁棒控制框架，用于在近距离操作中确保航天器在复杂几何目标附近的碰撞避免，并通过数值模拟验证了其优越性。", "motivation": "解决航天器近距离操作中追逐器与几何复杂目标航天器在扰动下避免碰撞的挑战，确保操作安全。", "method": "提出一个利用隐式神经表示的安全鲁棒控制框架。通过增强的隐式几何正则化方法，从点云数据学习神经符号距离函数（SDF），并采用过近似策略创建保守的安全优先边界。该框架包含两层：安全速度生成层（使用二阶锥规划，引入循环不等式缓解局部最小值问题）和安全鲁棒控制器层（集成扰动观测器和平滑安全滤波器，补偿估计误差，增强鲁棒性）。", "result": "数值模拟和蒙特卡洛分析验证了所提出的框架，与传统控制障碍函数（CBF）方法相比，显著提高了安全裕度并避免了局部最小值问题。", "conclusion": "本文提出的基于隐式神经表示的安全鲁棒控制框架，通过有效处理复杂目标几何形状和外部扰动，显著提升了航天器近距离操作的安全性，并成功克服了传统方法的局限性。", "translation": "本研究解决了确保航天器近距离操作安全的挑战，重点是在扰动下追逐航天器与几何复杂目标航天器之间的防碰撞问题。为了在这种场景下确保安全，提出了一种利用隐式神经表示的安全鲁棒控制框架。为了在没有明确建模的情况下处理任意目标几何形状，通过增强的隐式几何正则化方法，从点云数据中学习了一个神经符号距离函数（SDF），该方法结合了过近似策略以创建保守的、安全优先的边界。目标的表面由学习到的神经SDF的零水平集隐式定义，而其值和梯度为安全控制器设计提供了关键信息。这种神经SDF表示支撑了一个两层分层的安全鲁棒控制框架：一个安全速度生成层和一个安全鲁棒控制器层。在第一层中，制定了一个二阶锥规划来通过明确纳入欠近似误差界限来生成安全保证的参考速度。此外，引入了一个循环不等式来缓解控制障碍函数（CBF）方法中常见的局部最小值问题。第二层具有集成的扰动观测器和平滑安全滤波器，明确补偿估计误差，增强对外部扰动的鲁棒性。广泛的数值模拟和蒙特卡洛分析验证了所提出的框架，与传统CBF方法相比，显著提高了安全裕度并避免了局部最小值。", "summary": "本文针对航天器在近距离操作中与几何复杂目标进行碰撞避免的挑战，提出了一种基于隐式神经表示的安全鲁棒控制框架。该框架通过学习神经符号距离函数（SDF）来隐式表示目标几何形状，并采用两层分层控制结构：第一层利用二阶锥规划和循环不等式生成安全速度并规避局部最小值；第二层集成扰动观测器和安全滤波器以增强鲁棒性。实验结果表明，该方法相比传统CBF显著提升了安全裕度并有效避免了局部最小值。", "keywords": "航天器控制, 隐式神经表示, 符号距离函数, 安全鲁棒控制, 碰撞避免", "comments": "该论文的创新点在于将隐式神经表示（特别是神经SDF）引入到航天器安全鲁棒控制中，以有效处理复杂且未明确建模的目标几何形状。通过结合过近似策略、两层分层控制架构以及循环不等式，该方法不仅提高了碰撞避免的安全性，还成功解决了传统CBF方法中的局部最小值问题，并增强了对扰动的鲁棒性，具有重要的工程应用价值。"}}
{"id": "2506.11571", "title": "VFaith: Do Large Multimodal Models Really Reason on Seen Images Rather than Previous Memories?", "authors": ["Jiachen Yu", "Yufei Zhan", "Ziheng Wu", "Yousong Zhu", "Jinqiao Wang", "Minghui Qiu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.11571v2", "summary": "Recent extensive works have demonstrated that by introducing long CoT, the\ncapabilities of MLLMs to solve complex problems can be effectively enhanced.\nHowever, the reasons for the effectiveness of such paradigms remain unclear. It\nis challenging to analysis with quantitative results how much the model's\nspecific extraction of visual cues and its subsequent so-called reasoning\nduring inference process contribute to the performance improvements. Therefore,\nevaluating the faithfulness of MLLMs' reasoning to visual information is\ncrucial. To address this issue, we first present a cue-driven automatic and\ncontrollable editing pipeline with the help of GPT-Image-1. It enables the\nautomatic and precise editing of specific visual cues based on the instruction.\nFurthermore, we introduce VFaith-Bench, the first benchmark to evaluate MLLMs'\nvisual reasoning capabilities and analyze the source of such capabilities with\nan emphasis on the visual faithfulness. Using the designed pipeline, we\nconstructed comparative question-answer pairs by altering the visual cues in\nimages that are crucial for solving the original reasoning problem, thereby\nchanging the question's answer. By testing similar questions with images that\nhave different details, the average accuracy reflects the model's visual\nreasoning ability, while the difference in accuracy before and after editing\nthe test set images effectively reveals the relationship between the model's\nreasoning ability and visual perception. We further designed specific metrics\nto expose this relationship. VFaith-Bench includes 755 entries divided into\nfive distinct subsets, along with an additional human-labeled perception task.\nWe conducted in-depth testing and analysis of existing mainstream flagship\nmodels and prominent open-source model series/reasoning models on VFaith-Bench,\nfurther investigating the underlying factors of their reasoning capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.11571v2", "cate": "cs.CV", "date": "2025-06-13", "updated": "2025-07-18", "AI": {"title_translation": "VFaith：大型多模态模型真的基于所见图像而非过往记忆进行推理吗？", "tldr": "本文提出了VFaith-Bench基准和图像编辑流水线，旨在评估大型多模态模型（MLLMs）在推理时是否真正依赖视觉信息，而非过往记忆。", "motivation": "当前研究表明，引入长CoT（思维链）可以有效增强MLLMs解决复杂问题的能力，但其有效性的原因尚不明确。量化分析模型对视觉线索的提取及其推理过程如何对性能提升做出贡献具有挑战性。因此，评估MLLMs推理对视觉信息的忠实度至关重要。", "method": "本文首先借助GPT-Image-1提出了一个线索驱动的自动化可控图像编辑流水线，能够根据指令自动精确编辑特定视觉线索。接着，引入了VFaith-Bench，这是首个用于评估MLLMs视觉推理能力并分析其能力来源（侧重于视觉忠实度）的基准。通过设计的流水线，研究人员通过改变图像中解决原始推理问题至关重要的视觉线索来构建对比性的问答对，从而改变问题的答案。通过测试具有不同细节的相似问题，平均准确率反映模型视觉推理能力，而编辑前后测试集图像的准确率差异则有效揭示模型推理能力与视觉感知之间的关系。本文还设计了特定的指标来揭示这种关系。VFaith-Bench包含755个条目，分为五个不同的子集，并附加一项人工标注的感知任务。研究人员对现有主流旗舰模型和知名开源模型系列/推理模型在VFaith-Bench上进行了深入测试和分析。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "最近的广泛工作表明，通过引入长CoT（思维链），可以有效增强大型多模态模型（MLLMs）解决复杂问题的能力。然而，这种范式有效性的原因仍不清楚。定量分析模型在推理过程中对视觉线索的特定提取及其后续所谓的推理对性能提升的贡献程度是具有挑战性的。因此，评估MLLMs推理对视觉信息的忠实度至关重要。为了解决这个问题，我们首先借助GPT-Image-1提出了一个线索驱动的自动化可控编辑流水线。它能够根据指令自动精确编辑特定的视觉线索。此外，我们引入了VFaith-Bench，这是首个用于评估MLLMs视觉推理能力并分析其能力来源（侧重于视觉忠实度）的基准。通过设计的流水线，我们通过改变图像中解决原始推理问题至关重要的视觉线索来构建对比性的问答对，从而改变问题的答案。通过测试具有不同细节的相似问题，平均准确率反映模型视觉推理能力，而编辑前后测试集图像的准确率差异则有效揭示模型推理能力与视觉感知之间的关系。我们进一步设计了特定的指标来揭示这种关系。VFaith-Bench包含755个条目，分为五个不同的子集，并附加一项人工标注的感知任务。我们对现有主流旗舰模型和知名开源模型系列/推理模型在VFaith-Bench上进行了深入测试和分析，进一步探讨了其推理能力的潜在因素。", "summary": "本文针对大型多模态模型（MLLMs）在长思维链（CoT）下表现提升但原因不明的问题，提出了一项研究，旨在评估其推理对视觉信息的忠实度。为此，研究者开发了一个基于GPT-Image-1的自动化视觉线索编辑流水线，并构建了首个视觉推理忠实度基准VFaith-Bench。该基准通过改变图像中的关键视觉线索来生成对比性问答对，并通过准确率差异来衡量模型推理与视觉感知的关系。VFaith-Bench包含755个条目及人工感知任务，并用于深入测试和分析主流MLLMs的推理能力。", "keywords": "大型多模态模型, 视觉推理, 视觉忠实度, 基准, 图像编辑", "comments": "本文的创新之处在于提出了一个自动化的视觉线索编辑流水线和VFaith-Bench基准，首次系统地评估了大型多模态模型视觉推理的忠实性。这对于理解MLLMs是否真正基于视觉信息进行推理而非记忆，具有重要的理论和实践意义，填补了现有研究的空白。该方法提供了一种量化分析模型视觉感知与推理之间关系的新途径。"}}
{"id": "2507.13388", "title": "DLSF: Dual-Layer Synergistic Fusion for High-Fidelity Image Syn-thesis", "authors": ["Zhen-Qi Chen", "Yuan-Fu Yang"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13388v1", "summary": "With the rapid advancement of diffusion-based generative models, Stable\nDiffusion (SD) has emerged as a state-of-the-art framework for high-fidelity\nim-age synthesis. However, existing SD models suffer from suboptimal feature\naggregation, leading to in-complete semantic alignment and loss of fine-grained\ndetails, especially in highly textured and complex scenes. To address these\nlimitations, we propose a novel dual-latent integration framework that\nen-hances feature interactions between the base latent and refined latent\nrepresentations. Our approach em-ploys a feature concatenation strategy\nfollowed by an adaptive fusion module, which can be instantiated as either (i)\nan Adaptive Global Fusion (AGF) for hier-archical feature harmonization, or\n(ii) a Dynamic Spatial Fusion (DSF) for spatially-aware refinement. This design\nenables more effective cross-latent com-munication, preserving both global\ncoherence and local texture fidelity. Our GitHub page:\nhttps://anonymous.4open.science/r/MVA2025-22 .", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13388v1", "cate": "cs.GR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DLSF：双层协同融合实现高保真图像合成", "tldr": "本文提出了一种名为DLSF的双层协同融合框架，旨在解决现有Stable Diffusion模型在复杂场景下特征聚合不佳、语义对齐不完整和细节丢失的问题，通过增强基础潜在表示和精炼潜在表示之间的特征交互，有效提升了图像合成的全局连贯性和局部纹理保真度。", "motivation": "现有Stable Diffusion模型在特征聚合方面表现不佳，导致在图像合成中出现语义对齐不完整和细粒度细节丢失的问题，尤其是在高纹理和复杂场景中。", "method": "本文提出了一种新颖的双潜在集成框架DLSF，通过增强基础潜在表示和精炼潜在表示之间的特征交互来解决现有问题。该方法采用特征拼接策略，并结合自适应融合模块，该模块可实例化为自适应全局融合（AGF）用于分层特征协调，或动态空间融合（DSF）用于空间感知细化。", "result": "该设计实现了更有效的跨潜在通信，从而同时保留了全局连贯性和局部纹理保真度。", "conclusion": "通过提出的双层协同融合框架DLSF，能够有效增强不同潜在表示之间的特征交互，从而在图像合成中实现更好的全局连贯性和局部纹理保真度，解决了现有Stable Diffusion模型在复杂场景下的细节丢失问题。", "translation": "随着基于扩散的生成模型的快速发展，Stable Diffusion（SD）已成为高保真图像合成的最新框架。然而，现有的SD模型存在特征聚合次优的问题，导致语义对齐不完整和细粒度细节丢失，尤其是在高纹理和复杂场景中。为了解决这些限制，我们提出了一种新颖的双潜在集成框架，该框架增强了基础潜在表示和精炼潜在表示之间的特征交互。我们的方法采用特征拼接策略，然后是自适应融合模块，该模块可以实例化为（i）用于分层特征协调的自适应全局融合（AGF），或（ii）用于空间感知细化的动态空间融合（DSF）。这种设计实现了更有效的跨潜在通信，同时保留了全局连贯性和局部纹理保真度。", "summary": "本文针对Stable Diffusion模型在复杂场景下特征聚合不足导致语义对齐不完整和细节丢失的问题，提出了一种名为DLSF的双层协同融合框架。DLSF通过增强基础和精炼潜在表示之间的特征交互，采用特征拼接和可选择的自适应全局融合（AGF）或动态空间融合（DSF）模块，有效提升了图像合成的全局连贯性和局部纹理保真度。", "keywords": "扩散模型, 图像合成, Stable Diffusion, 特征融合, 潜在表示", "comments": "DLSF框架的创新之处在于其双层潜在集成策略和可选择的自适应融合模块（AGF/DSF），这为改善扩散模型中的特征聚合和细节保留提供了一种新颖的思路。该方法通过优化跨潜在通信，有效解决了现有Stable Diffusion模型在高纹理复杂场景下图像细节丢失的痛点，对于提升生成图像的质量具有重要意义。"}}
{"id": "2503.09567", "title": "Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models", "authors": ["Qiguang Chen", "Libo Qin", "Jinhao Liu", "Dengyun Peng", "Jiannan Guan", "Peng Wang", "Mengkang Hu", "Yuhang Zhou", "Te Gao", "Wanxiang Che"], "categories": ["cs.AI", "cs.CL"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Paper list and Github tutorial are available at this https URL . Update 250+ New Reference", "url": "http://arxiv.org/abs/2503.09567v5", "summary": "Recent advancements in reasoning with large language models (RLLMs), such as\nOpenAI-O1 and DeepSeek-R1, have demonstrated their impressive capabilities in\ncomplex domains like mathematics and coding. A central factor in their success\nlies in the application of long chain-of-thought (Long CoT) characteristics,\nwhich enhance reasoning abilities and enable the solution of intricate\nproblems. However, despite these developments, a comprehensive survey on Long\nCoT is still lacking, limiting our understanding of its distinctions from\ntraditional short chain-of-thought (Short CoT) and complicating ongoing debates\non issues like \"overthinking\" and \"inference-time scaling.\" This survey seeks\nto fill this gap by offering a unified perspective on Long CoT. (1) We first\ndistinguish Long CoT from Short CoT and introduce a novel taxonomy to\ncategorize current reasoning paradigms. (2) Next, we explore the key\ncharacteristics of Long CoT: deep reasoning, extensive exploration, and\nfeasible reflection, which enable models to handle more complex tasks and\nproduce more efficient, coherent outcomes compared to the shallower Short CoT.\n(3) We then investigate key phenomena such as the emergence of Long CoT with\nthese characteristics, including overthinking, and inference-time scaling,\noffering insights into how these processes manifest in practice. (4) Finally,\nwe identify significant research gaps and highlight promising future\ndirections, including the integration of multi-modal reasoning, efficiency\nimprovements, and enhanced knowledge frameworks. By providing a structured\noverview, this survey aims to inspire future research and further the\ndevelopment of logical reasoning in artificial intelligence.", "comment": "Paper list and Github tutorial are available at\n  https://github.com/LightChen233/Awesome-Long-Chain-of-Thought-Reasoning.\n  Update 250+ New Reference", "pdf_url": "http://arxiv.org/pdf/2503.09567v5", "cate": "cs.AI", "date": "2025-03-12", "updated": "2025-07-18", "AI": {"title_translation": "迈向推理时代：大型语言模型推理中长链思维的综述", "tldr": "这篇综述旨在填补长链思维（Long CoT）研究的空白，区分其与短链思维（Short CoT），探讨其特点、相关现象，并指出未来研究方向，以推动大型语言模型推理能力的发展。", "motivation": "尽管长链思维（Long CoT）在大型语言模型（RLLMs）的推理中取得了显著成功，但目前仍缺乏对其的全面综述，这限制了我们理解Long CoT与传统短链思维（Short CoT）的区别，并使“过度思考”和“推理时间扩展”等问题的讨论复杂化。", "method": "本综述通过统一的视角来填补这一空白，具体包括：1）区分长链思维（Long CoT）和短链思维（Short CoT），并引入新的分类法；2）探讨长链思维的关键特征：深度推理、广泛探索和可行性反思；3）调查长链思维出现的相关现象，如过度思考和推理时间扩展；4）识别重要的研究空白并指出未来方向，包括多模态推理、效率提升和知识框架增强。", "result": "本综述提供了一个结构化的概述，区分了长链思维和短链思维，提出了新的分类法，并探讨了长链思维的关键特征（深度推理、广泛探索、可行性反思）及其相关现象（过度思考、推理时间扩展）。", "conclusion": "通过提供结构化概述，本综述旨在启发未来的研究，并进一步推动人工智能中逻辑推理的发展。", "translation": "推理时代展望：大型语言模型推理中长链思维的综述\n\n最近在大型语言模型（RLLMs）推理方面的进展，例如OpenAI-O1和DeepSeek-R1，已展示了它们在数学和编码等复杂领域令人印象深刻的能力。其成功的核心因素在于长链思维（Long CoT）特性的应用，它增强了推理能力并能够解决复杂的难题。然而，尽管有这些发展，目前仍缺乏对Long CoT的全面综述，这限制了我们对其与传统短链思维（Short CoT）区别的理解，并使关于“过度思考”和“推理时间扩展”等问题的持续争论变得复杂。本综述旨在通过提供对Long CoT的统一视角来填补这一空白。(1) 我们首先区分Long CoT和Short CoT，并引入一种新颖的分类法来对当前的推理范式进行分类。(2) 接下来，我们探讨Long CoT的关键特性：深度推理、广泛探索和可行性反思，这些特性使模型能够处理更复杂的任务，并产生比浅层Short CoT更高效、更连贯的结果。(3) 然后，我们调查了具有这些特性的Long CoT的出现现象，包括过度思考和推理时间扩展，提供了关于这些过程在实践中如何体现的见解。(4) 最后，我们识别了重要的研究空白并强调了有前景的未来方向，包括多模态推理的整合、效率改进和增强的知识框架。通过提供结构化的概述，本综述旨在启发未来的研究并进一步推动人工智能中逻辑推理的发展。", "summary": "本综述旨在全面探讨大型语言模型推理中的长链思维（Long CoT）。文章首先区分了Long CoT与传统短链思维（Short CoT），并提出了一种新的分类法。接着，深入分析了Long CoT的关键特性，包括深度推理、广泛探索和可行性反思，这些特性使其能处理更复杂的任务并产生更高效、连贯的结果。此外，综述还探讨了Long CoT的出现现象，如过度思考和推理时间扩展。最后，文章指出了该领域的研究空白并提出了未来的发展方向，以期推动人工智能逻辑推理的进步。", "keywords": "长链思维, 大型语言模型, 推理, 综述, 短链思维", "comments": "这篇综述填补了大型语言模型长链思维研究的空白，系统性地梳理了其与短链思维的区别、核心特性及相关现象，并展望了未来研究方向。其创新之处在于提出了新的分类法和对长链思维深层机制的剖析，对于理解和发展更高级的LLM推理能力具有重要意义。"}}
{"id": "2506.22598", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun Audrey Mao", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.22598v2", "summary": "Agents based on Large Language Models (LLMs) have shown promise for\nperforming sophisticated software engineering tasks autonomously. In addition,\nthere has been progress towards developing agents that can perform parts of the\nresearch pipeline in machine learning and the natural sciences. We argue that\nresearch extension and its implementation is a critical capability for such\nsystems, and introduce RExBench to support the evaluation of this capability.\nRExBench is a benchmark consisting of 12 realistic research experiment\nimplementation tasks that aim to investigate research hypotheses that have not\npreviously been implemented. Each task is set up as an extension to an existing\nresearch paper and codebase, accompanied by domain expert-written instructions.\nRExBench is robust to data contamination, and supports an automatic evaluation\ninfrastructure that executes agent outputs to determine whether the success\ncriteria are met. We use this benchmark to evaluate nine LLM agents implemented\nusing three different frameworks: aider, Claude Code, and OpenHands. We find\nthat all agents evaluated fail to autonomously implement the majority of the\nextensions. Although the success rate improves with additional human-written\nhints, the best performance under this setting remains below 40%. This\nindicates that current agents are still short of being able to handle realistic\nresearch extension tasks without substantial human guidance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.22598v2", "cate": "cs.CL", "date": "2025-06-27", "updated": "2025-07-17", "AI": {"title_translation": "RExBench：编码智能体能否自主实现AI研究扩展？", "tldr": "RExBench是一个用于评估大型语言模型（LLM）编码智能体自主实现AI研究扩展能力的基准测试。研究发现，当前智能体在没有大量人类指导的情况下，难以处理现实的研究扩展任务。", "motivation": "大型语言模型（LLM）驱动的智能体在自主执行复杂的软件工程任务方面展现出潜力，并且在机器学习和自然科学领域的研究流程部分任务中也取得了进展。本文认为，研究扩展及其实现是此类系统的一项关键能力，因此需要一个基准来评估这种能力。", "method": "本文引入了RExBench，这是一个由12个真实的、旨在调查未曾实现的研究假设的研究实验实现任务组成的基准。每个任务都是现有研究论文和代码库的扩展，并附有领域专家编写的说明。RExBench具有数据污染鲁棒性，并支持自动评估基础设施，通过执行智能体输出来判断是否满足成功标准。研究使用该基准评估了九个使用aider、Claude Code和OpenHands三种不同框架实现的LLM智能体。", "result": "所有被评估的智能体都未能自主实现大部分扩展。尽管在增加人类编写的提示后成功率有所提高，但在这种设置下，最佳性能仍低于40%。", "conclusion": "这表明当前的智能体在没有大量人类指导的情况下，仍然不足以处理现实的研究扩展任务。", "translation": "基于大型语言模型（LLM）的智能体已显示出自主执行复杂软件工程任务的潜力。此外，在开发能够执行机器学习和自然科学研究流程部分任务的智能体方面也取得了进展。我们认为，研究扩展及其实现是此类系统的一项关键能力，并引入RExBench来支持对这种能力的评估。RExBench是一个基准，由12个真实的研究实验实现任务组成，旨在调查以前未实现的研究假设。每个任务都设置为对现有研究论文和代码库的扩展，并附有领域专家编写的说明。RExBench对数据污染具有鲁棒性，并支持一个自动评估基础设施，该基础设施执行智能体输出以确定是否满足成功标准。我们使用该基准评估了使用aider、Claude Code和OpenHands三种不同框架实现的九个LLM智能体。我们发现，所有被评估的智能体都未能自主实现大部分扩展。尽管在增加人类编写的提示后成功率有所提高，但在此设置下的最佳性能仍低于40%。这表明当前的智能体在没有大量人类指导的情况下，仍然不足以处理现实的研究扩展任务。", "summary": "本文提出了RExBench，一个专门用于评估大型语言模型（LLM）编码智能体自主实现AI研究扩展能力的基准测试。该基准包含12个基于现有研究的真实扩展任务，并配备了自动评估系统。通过对九个主流LLM智能体进行测试，研究发现，当前智能体在没有大量人类指导的情况下，难以自主完成大部分研究扩展任务，即使有提示，成功率也远低于40%，揭示了当前LLM智能体在该领域能力的局限性。", "keywords": "RExBench, 编码智能体, LLM, 研究扩展, 基准测试", "comments": "本文的创新之处在于引入了一个全新的、专门针对AI研究扩展实现能力的评估基准RExBench，填补了现有评估工具的空白。其重要性在于揭示了当前LLM驱动的编码智能体在处理复杂、现实世界研究任务时的显著局限性，为未来智能体能力的提升指明了方向。RExBench的鲁棒性和自动化评估机制也提升了评估的可靠性。"}}
{"id": "2507.13955", "title": "Convergence rates of curved boundary element methods for the 3D Laplace and Helmholtz equations", "authors": ["Luiz Maltez Faria", "Pierre Marchand", "Hadrien Montanelli"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13955v1", "summary": "We establish improved convergence rates for curved boundary element methods\napplied to the three-dimensional (3D) Laplace and Helmholtz equations with\nsmooth geometry and data. Our analysis relies on a precise analysis of the\nconsistency errors introduced by the perturbed bilinear and sesquilinear forms.\nWe illustrate our results with numerical experiments in 3D based on basis\nfunctions and curved triangular elements up to order four.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13955v1", "cate": "math.NA", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "三维拉普拉斯和亥姆霍兹方程曲线边界元方法的收敛速度", "tldr": "该论文通过分析一致性误差，提高了三维拉普拉斯和亥姆霍兹方程曲线边界元方法的收敛速度。", "motivation": "旨在为应用于三维拉普拉斯和亥姆霍兹方程的曲线边界元方法建立改进的收敛速度。", "method": "通过精确分析扰动双线性形式和半双线性形式引入的一致性误差进行分析，并通过基于高达四阶基函数和曲线三角形单元的三维数值实验来验证。", "result": "建立了应用于具有光滑几何和数据的三维拉普拉斯和亥姆霍兹方程的曲线边界元方法的改进收敛速度，并通过数值实验进行了阐明。", "conclusion": "成功建立了应用于三维拉普拉斯和亥姆霍兹方程的曲线边界元方法的改进收敛速度，并通过数值实验进行了验证。", "translation": "我们建立了应用于具有光滑几何和数据的三维（3D）拉普拉斯和亥姆霍兹方程的曲线边界元方法的改进收敛速度。我们的分析依赖于对由扰动双线性形式和半双线性形式引入的一致性误差的精确分析。我们通过基于基函数和高达四阶的曲线三角形单元的三维数值实验来阐明我们的结果。", "summary": "本论文研究了应用于三维拉普拉斯和亥姆霍兹方程的曲线边界元方法，并建立了改进的收敛速度。其分析侧重于由扰动双线性形式和半双线性形式引起的一致性误差，并通过使用高阶曲线三角形单元的三维数值实验予以支持。", "keywords": "曲线边界元方法, 拉普拉斯方程, 亥姆霍兹方程, 收敛速度, 一致性误差", "comments": "Not mentioned in abstract"}}
{"id": "2507.13652", "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13652v1", "summary": "Model tracing and constraint-based modeling are two approaches to diagnose\nstudent input in stepwise tasks. Model tracing supports identifying consecutive\nproblem-solving steps taken by a student, whereas constraint-based modeling\nsupports student input diagnosis even when several steps are combined into one\nstep. We propose an approach that merges both paradigms. By defining\nconstraints as properties that a student input has in common with a step of a\nstrategy, it is possible to provide a diagnosis when a student deviates from a\nstrategy even when the student combines several steps. In this study we explore\nthe design of a system for multistep strategy diagnoses, and evaluate these\ndiagnoses. As a proof of concept, we generate diagnoses for an existing dataset\ncontaining steps students take when solving quadratic equations (n=2136). To\ncompare with human diagnoses, two teachers coded a random sample of deviations\n(n=70) and applications of the strategy (n=70). Results show that that the\nsystem diagnosis aligned with the teacher coding in all of the 140 student\nsteps.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13652v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "结合模型追踪与基于约束建模进行多步策略诊断", "tldr": "本文提出一种结合模型追踪和基于约束建模的方法，用于诊断学生在多步任务中偏离策略的情况，即使学生合并了多个步骤也能有效诊断，并在二次方程求解数据集上验证了其诊断结果与人工编码高度一致。", "motivation": "现有的模型追踪和基于约束建模方法在诊断学生分步任务输入时各有优缺点。模型追踪擅长识别连续步骤，但当学生合并多个步骤时诊断能力受限；基于约束建模能处理合并步骤，但可能缺乏对连续步骤的追踪。本文旨在结合两者的优势，解决学生在合并步骤时偏离策略的诊断问题。", "method": "作者提出了一种融合模型追踪和基于约束建模的方法。该方法通过将约束定义为学生输入与策略步骤共有的属性，从而即使学生合并了多个步骤，也能诊断学生偏离策略的情况。研究探索了多步策略诊断系统的设计，并使用一个包含学生求解二次方程步骤的现有数据集（n=2136）作为概念验证。为了与人工诊断进行比较，两位教师对70个偏离和70个策略应用样本进行了编码。", "result": "系统诊断结果与教师对140个学生步骤的编码完全一致。", "conclusion": "结合模型追踪和基于约束建模的方法能够有效地诊断学生在多步策略任务中（包括合并步骤）的偏离行为，并且诊断结果与人类专家判断高度吻合。", "translation": "模型追踪和基于约束建模是诊断学生在分步任务中输入行为的两种方法。模型追踪支持识别学生采取的连续问题解决步骤，而基于约束建模即使在学生将多个步骤合并为一个步骤时也能支持学生输入诊断。我们提出了一种融合这两种范式的方法。通过将约束定义为学生输入与策略步骤共有的属性，即使学生合并了多个步骤，也可以在学生偏离策略时提供诊断。在本研究中，我们探索了多步策略诊断系统的设计，并评估了这些诊断结果。作为概念验证，我们为一个包含学生求解二次方程步骤的现有数据集（n=2136）生成了诊断结果。为了与人工诊断进行比较，两位教师对随机抽取的偏离样本（n=70）和策略应用样本（n=70）进行了编码。结果显示，系统诊断结果与教师对所有140个学生步骤的编码一致。", "summary": "本文提出了一种结合模型追踪和基于约束建模的新方法，旨在解决学生在分步任务中合并步骤时偏离策略的诊断难题。通过将约束定义为学生输入与策略步骤的共享属性，该系统能够有效地诊断学生在多步任务中的策略偏离。研究通过对学生求解二次方程的数据集进行概念验证，并与教师的人工诊断进行对比，结果表明该系统的诊断结果与教师编码在所有测试样本上均保持一致，证明了其有效性和准确性。", "keywords": "模型追踪, 基于约束建模, 学生诊断, 多步策略, 智能辅导系统", "comments": "这篇论文的创新点在于成功地融合了模型追踪和基于约束建模这两种不同的诊断范式，解决了单一方法在处理学生合并步骤时诊断能力不足的问题。其重要性在于为智能辅导系统提供了更鲁棒、更准确的学生行为诊断能力，尤其是在复杂、多步骤的问题解决任务中。概念验证的结果显示出极高的准确性（100%一致），这对于实际应用具有重要意义。"}}
{"id": "2507.13808", "title": "Asymptotically Optimal Codes Correcting One Substring Edit", "authors": ["Yuting Li", "Yuanyuan Tang", "Hao Lou", "Ryan Gabrys", "Farzad Farnoud"], "categories": ["cs.IT", "math.IT", "G.2.1"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      6 pages, 1 figure", "url": "http://arxiv.org/abs/2507.13808v1", "summary": "The substring edit error is the operation of replacing a substring $u$ of $x$\nwith another string $v$, where the lengths of $u$ and $v$ are bounded by a\ngiven constant $k$. It encompasses localized insertions, deletions, and\nsubstitutions within a window. Codes correcting one substring edit have\nredundancy at least $\\log n+k$. In this paper, we construct codes correcting\none substring edit with redundancy $\\log n+O(\\log \\log n)$, which is\nasymptotically optimal.", "comment": "6 pages, 1 figure", "pdf_url": "http://arxiv.org/pdf/2507.13808v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "渐近最优的单子串编辑纠错码", "tldr": "本文构建了渐近最优的纠正单子串编辑错误的编码。", "motivation": "纠正单子串编辑错误的编码至少需要 $\\log n + k$ 的冗余度，因此需要寻找更高效、渐近最优的编码。", "method": "作者构建了能够纠正单子串编辑错误的编码。", "result": "所构建的编码冗余度为 $\\log n + O(\\log \\log n)$。", "conclusion": "所构建的编码在冗余度方面是渐近最优的。", "translation": "子串编辑错误是指将字符串 $x$ 的子串 $u$ 替换为另一个字符串 $v$ 的操作，其中 $u$ 和 $v$ 的长度都受给定常数 $k$ 的限制。它涵盖了窗口内的局部插入、删除和替换。纠正单子串编辑错误的编码至少具有 $\\log n+k$ 的冗余度。在本文中，我们构建了纠正单子串编辑错误的编码，其冗余度为 $\\log n+O(\\log \\log n)$，这是渐近最优的。", "summary": "本文研究了纠正单子串编辑错误的编码，这种错误涵盖了局部插入、删除和替换。针对现有编码至少 $\\log n+k$ 的冗余度，作者构建了一种新的编码，其冗余度达到了渐近最优的 $\\log n+O(\\log \\log n)$。", "keywords": "子串编辑错误, 纠错码, 渐近最优, 冗余度, 编码理论", "comments": "本文的创新之处在于构建了一种渐近最优的纠正单子串编辑错误的编码，显著降低了纠错所需的冗余度，具有重要的理论和实际意义。"}}
{"id": "2507.13859", "title": "SPARQL Query Generation with LLMs: Measuring the Impact of Training Data Memorization and Knowledge Injection", "authors": ["Aleksandr Gashkov", "Aleksandr Perevalov", "Maria Eltsova", "Andreas Both"], "categories": ["cs.IR", "cs.AI", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "Comments:      Winner of Best Paper Award at the 25th International Conference on Web Engineering (ICWE 2025)", "url": "http://arxiv.org/abs/2507.13859v1", "summary": "Nowadays, the importance of software with natural-language user interfaces\ncannot be underestimated. In particular, in Question Answering (QA) systems,\ngenerating a SPARQL query for a given natural-language question (often named\nQuery Building) from the information retrieved from the same question is the\ncentral task of QA systems working over Knowledge Graphs (KGQA). Due to the\nrise of Large Language Models (LLMs), they are considered a well-suited method\nto increase the quality of the question-answering functionality, as there is\nstill a lot of room for improvement, aiming for enhanced quality and\ntrustworthiness. However, LLMs are trained on web data, where researchers have\nno control over whether the benchmark or the knowledge graph was already\nincluded in the training data. In this paper, we introduce a novel method that\nevaluates the quality of LLMs by generating a SPARQL query from a\nnatural-language question under various conditions: (1) zero-shot SPARQL\ngeneration, (2) with knowledge injection, and (3) with \"anonymized\" knowledge\ninjection. This enables us, for the first time, to estimate the influence of\nthe training data on the QA quality improved by LLMs. Ultimately, this will\nhelp to identify how portable a method is or whether good results might mostly\nbe achieved because a benchmark was already included in the training data (cf.\nLLM memorization). The developed method is portable, robust, and supports any\nknowledge graph; therefore, it could be easily applied to any KGQA or LLM,\ns.t., generating consistent insights into the actual LLM capabilities is\npossible.", "comment": "Winner of Best Paper Award at the 25th International Conference on\n  Web Engineering (ICWE 2025)", "pdf_url": "http://arxiv.org/pdf/2507.13859v1", "cate": "cs.IR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "LLM的SPARQL查询生成：测量训练数据记忆和知识注入的影响", "tldr": "本文提出一种新方法，通过在不同条件下生成SPARQL查询来评估LLM在知识图谱问答中的质量，旨在量化训练数据记忆和知识注入的影响。", "motivation": "自然语言用户界面在软件中日益重要，特别是在知识图谱问答（KGQA）系统中，从自然语言问题生成SPARQL查询是核心任务。尽管大型语言模型（LLM）被认为是提高问答质量的有效方法，但其训练数据来源不受控，导致难以确定基准或知识图谱是否已被LLM记忆，这影响了结果的可信度和方法的可移植性。", "method": "论文提出了一种新颖的方法，通过在以下不同条件下从自然语言问题生成SPARQL查询来评估LLM的质量：1) 零样本SPARQL生成，2) 带有知识注入，以及 3) 带有“匿名化”知识注入。", "result": "该方法首次能够估计训练数据对LLM改进的问答质量的影响。它有助于识别方法的可移植性，以及好的结果是否主要是由于基准数据集已包含在训练数据中（即LLM的记忆化）。该方法具有可移植性、鲁棒性，并支持任何知识图谱。", "conclusion": "本文开发的方法能够提供关于LLM实际能力的连贯见解，并有助于区分LLM的真实能力与训练数据记忆的影响，从而促进更可信赖和可移植的KGQA系统开发。", "translation": "如今，具有自然语言用户界面的软件的重要性不容小觑。特别是在问答（QA）系统中，从给定自然语言问题中检索到的信息生成SPARQL查询（通常称为查询构建）是基于知识图谱（KGQA）的QA系统的核心任务。由于大型语言模型（LLM）的兴起，它们被认为是一种非常适合提高问答功能质量的方法，因为仍有很大的改进空间，旨在提高质量和可信度。然而，LLM是在网络数据上训练的，研究人员无法控制基准或知识图谱是否已包含在训练数据中。在本文中，我们引入了一种新颖的方法，通过在各种条件下从自然语言问题生成SPARQL查询来评估LLM的质量：(1) 零样本SPARQL生成，(2) 带有知识注入，以及 (3) 带有“匿名化”知识注入。这使我们首次能够估计训练数据对LLM改进的问答质量的影响。最终，这将有助于识别方法的便携性，或者好的结果是否可能主要因为某个基准数据集已经包含在训练数据中（参见LLM记忆化）。所开发的方法是可移植、鲁棒的，并支持任何知识图谱；因此，它可以很容易地应用于任何KGQA或LLM，从而可以生成关于LLM实际能力的连贯见解。", "summary": "本文针对大型语言模型（LLMs）在知识图谱问答（KGQA）中生成SPARQL查询时，其训练数据记忆效应可能影响评估结果的问题，提出了一种新颖的评估方法。该方法在零样本、知识注入和匿名化知识注入三种条件下，通过从自然语言问题生成SPARQL查询来评估LLM的质量。这使得首次能够量化训练数据对LLM问答质量的影响，从而帮助判断方法的真正可移植性以及良好性能是否来源于LLM对训练数据的记忆。该方法具有通用性、鲁棒性，可应用于各种KGQA和LLM系统。", "keywords": "LLMs, SPARQL查询生成, 知识图谱问答, 训练数据记忆, 知识注入", "comments": "这篇论文解决了LLM在知识图谱问答领域的一个关键挑战：如何区分LLM的真实理解和推理能力与其对训练数据中已包含的基准或知识的“记忆”。通过引入不同条件下的评估方法，特别是“匿名化”知识注入，该研究为更准确地衡量LLM在SPARQL查询生成方面的性能提供了一个创新框架。其可移植性强的评估方法对于未来LLM在KGQA领域的应用和开发具有重要指导意义。"}}
{"id": "2507.14022", "title": "CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis", "authors": ["Jianfei Li", "Kevin Kam Fung Yuen"], "categories": ["cs.CL", "cs.LG"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      35 pages, 33 tables, 6 Figures", "url": "http://arxiv.org/abs/2507.14022v1", "summary": "This study proposes the Cognitive Pairwise Comparison Classification Model\nSelection (CPC-CMS) framework for document-level sentiment analysis. The CPC,\nbased on expert knowledge judgment, is used to calculate the weights of\nevaluation criteria, including accuracy, precision, recall, F1-score,\nspecificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and\nefficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random\nForest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long\nShort-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from\nTransformers (ALBERT) are chosen as classification baseline models. A weighted\ndecision matrix consisting of classification evaluation scores with respect to\ncriteria weights, is formed to select the best classification model for a\nclassification problem. Three open datasets of social media are used to\ndemonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,\nfor evaluation results excluding the time factor, ALBERT is the best for the\nthree datasets; if time consumption is included, no single model always\nperforms better than the other models. The CPC-CMS can be applied to the other\nclassification applications in different areas.", "comment": "35 pages, 33 tables, 6 Figures", "pdf_url": "http://arxiv.org/pdf/2507.14022v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CPC-CMS: 面向文档级情感分析的认知成对比较分类模型选择框架", "tldr": "本研究提出了一种名为CPC-CMS的框架，用于文档级情感分析中的分类模型选择。该框架利用专家知识判断来计算评估标准的权重，并通过加权决策矩阵选择最佳分类模型。实验表明，在不考虑时间因素时ALBERT表现最佳，而考虑时间时没有单一模型始终最优。", "motivation": "本研究旨在提出一个系统性的框架（CPC-CMS），用于在文档级情感分析中选择最佳的分类模型，以解决如何根据多个评估标准和专家知识进行有效模型选择的问题。", "method": "本研究提出了认知成对比较分类模型选择（CPC-CMS）框架。该框架基于专家知识判断，计算准确率、精确率、召回率、F1分数、特异性、MCC、Cohen's Kappa和效率等评估标准的权重。选择了朴素贝叶斯、线性支持向量分类、随机森林、逻辑回归、XGBoost、LSTM和ALBERT作为基线分类模型。通过将分类评估分数与标准权重结合形成加权决策矩阵，从而选择最佳分类模型。", "result": "基于对三个社交媒体开放数据集的模拟，结果显示：在不包括时间因素的评估中，ALBERT在所有三个数据集上表现最佳；如果包含时间消耗，则没有单一模型始终优于其他模型。", "conclusion": "CPC-CMS框架可以应用于其他不同领域的分类应用。", "translation": "本研究提出了认知成对比较分类模型选择（CPC-CMS）框架，用于文档级情感分析。CPC基于专家知识判断，用于计算评估标准的权重，包括准确率、精确率、召回率、F1分数、特异性、Matthews相关系数（MCC）、Cohen's Kappa（Kappa）和效率。选择朴素贝叶斯、线性支持向量分类（LSVC）、随机森林、逻辑回归、极端梯度提升（XGBoost）、长短期记忆（LSTM）和基于Transformer的轻量级双向编码器表示（ALBERT）作为分类基线模型。通过由分类评估分数和标准权重组成的加权决策矩阵，选择分类问题的最佳分类模型。使用三个社交媒体开放数据集来证明所提出的CPC-CMS的可行性。根据我们的模拟，对于不包括时间因素的评估结果，ALBERT在三个数据集上表现最佳；如果包括时间消耗，则没有单一模型始终优于其他模型。CPC-CMS可以应用于其他不同领域的分类应用。", "summary": "本研究提出了一种名为CPC-CMS的认知成对比较分类模型选择框架，专为文档级情感分析设计。该框架利用基于专家知识的认知成对比较方法来确定多种评估标准的权重，包括准确率、F1分数和效率等。研究选取了多种机器学习和深度学习模型作为基线，并通过构建加权决策矩阵来系统地选择最佳分类模型。在三个社交媒体数据集上的实验表明，在不考虑时间成本时，ALBERT模型表现最优；然而，当考虑时间效率时，没有单一模型能始终保持最佳性能。该框架具有广泛适用性，可推广至其他分类任务。", "keywords": "认知成对比较, 分类模型选择, 文档级情感分析, 加权决策矩阵, ALBERT", "comments": "这项研究的创新之处在于提出了一个结构化且可量化的模型选择框架CPC-CMS，它结合了专家知识和多标准评估，克服了单一指标或主观选择的局限性。其重要性在于为实际应用中的模型选择提供了一个系统化的决策支持工具，特别是在需要权衡多方面性能指标的复杂场景下。该框架的普适性也使其在不同分类领域具有潜在价值。"}}
{"id": "2507.13393", "title": "Improving KAN with CDF normalization to quantiles", "authors": ["Jakub Strawa", "Jarek Duda"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      7 pages, 9 figures", "url": "http://arxiv.org/abs/2507.13393v1", "summary": "Data normalization is crucial in machine learning, usually performed by\nsubtracting the mean and dividing by standard deviation, or by rescaling to a\nfixed range. In copula theory, popular in finance, there is used normalization\nto approximately quantiles by transforming x to CDF(x) with estimated CDF\n(cumulative distribution function) to nearly uniform distribution in [0,1],\nallowing for simpler representations which are less likely to overfit. It seems\nnearly unknown in machine learning, therefore, we would like to present some\nits advantages on example of recently popular Kolmogorov-Arnold Networks\n(KANs), improving predictions from Legendre-KAN by just switching rescaling to\nCDF normalization. Additionally, in HCR interpretation, weights of such neurons\nare mixed moments providing local joint distribution models, allow to propagate\nalso probability distributions, and change propagation direction.", "comment": "7 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/2507.13393v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "使用CDF归一化到分位数改进KAN", "tldr": "该论文通过将传统缩放替换为CDF归一化，改进了KANs（特别是Legendre-KAN）的预测性能，并指出CDF归一化在机器学习中的潜在优势。", "motivation": "数据归一化在机器学习中至关重要。尽管在金融领域的copula理论中，基于CDF的归一化被认为可以简化表示并减少过拟合，但其在机器学习领域几乎不为人知。因此，本文旨在展示其在机器学习中的优势。", "method": "作者将CDF归一化应用于Kolmogorov-Arnold网络（KANs），具体是通过将Legendre-KAN中的传统缩放方法替换为CDF归一化。", "result": "通过将传统缩放替换为CDF归一化，改进了Legendre-KAN的预测性能。", "conclusion": "CDF归一化可以有效提升KANs的性能，并且在机器学习中具有未被充分认识的潜力，因为它能提供更简单的表示并减少过拟合。在HCR解释中，这种归一化还能提供局部联合分布模型并支持概率分布传播。", "translation": "数据归一化在机器学习中至关重要，通常通过减去均值并除以标准差，或重新缩放到固定范围来执行。在金融领域流行的copula理论中，通过将x转换为估计CDF（累积分布函数）的CDF(x)来近似归一化到分位数，从而得到[0,1]中的近似均匀分布，这允许更简单的表示，并且更不容易过拟合。这在机器学习中似乎几乎不为人知，因此，我们希望以最近流行的Kolmogorov-Arnold网络（KANs）为例，展示它的一些优势，仅仅通过将重新缩放切换到CDF归一化，就改善了Legendre-KAN的预测。此外，在HCR解释中，此类神经元的权重是混合矩，提供了局部联合分布模型，允许传播概率分布，并改变传播方向。", "summary": "本研究提出将金融领域copula理论中使用的CDF归一化方法引入机器学习，以改进数据处理。通过在Kolmogorov-Arnold网络（KANs）中用CDF归一化替代传统的缩放方法，实验证明能显著提升Legendre-KAN的预测性能。这种方法能将数据近似转换为均匀分布，从而实现更简洁的模型表示并有效避免过拟合，揭示了其在机器学习领域未被充分利用的潜力。", "keywords": "CDF归一化, KAN, 数据归一化, copula理论, 机器学习", "comments": "本文的创新点在于将金融领域成熟的CDF归一化方法引入到机器学习中，特别是在KANs上的应用。这提供了一种新颖且有效的归一化策略，有望解决传统归一化方法可能导致的过拟合问题，并简化模型表示。其重要性在于为机器学习领域的数据预处理提供了新的视角和工具，尤其是在处理复杂数据分布时。"}}
{"id": "2506.18167", "title": "Understanding Reasoning in Thinking Language Models via Steering Vectors", "authors": ["Constantin Venhoff", "Iván Arcuschin", "Philip Torr", "Arthur Conmy", "Neel Nanda"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.18167v3", "summary": "Recent advances in large language models (LLMs) have led to the development\nof thinking language models that generate extensive internal reasoning chains\nbefore producing responses. While these models achieve improved performance,\ncontrolling their reasoning processes remains challenging. This work presents a\nsteering approach for thinking LLMs by analyzing and manipulating specific\nreasoning behaviors in DeepSeek-R1-Distill models. Through a systematic\nexperiment on 500 tasks across 10 diverse categories, we identify several\nreasoning behaviors exhibited by thinking models, including expressing\nuncertainty, generating examples for hypothesis validation, and backtracking in\nreasoning chains. We demonstrate that these behaviors are mediated by linear\ndirections in the model's activation space and can be controlled using steering\nvectors. By extracting and applying these vectors, we provide a method to\nmodulate specific aspects of the model's reasoning process, such as its\ntendency to backtrack or express uncertainty. Our approach offers practical\ntools for steering reasoning processes in thinking models in a controlled and\ninterpretable manner. We validate our steering method using three\nDeepSeek-R1-Distill models, demonstrating consistent control across different\nmodel architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.18167v3", "cate": "cs.LG", "date": "2025-06-22", "updated": "2025-07-17", "AI": {"title_translation": "通过转向向量理解思维语言模型中的推理", "tldr": "该研究提出了一种通过分析和操纵模型激活空间中的线性方向来控制思维语言模型推理过程的方法。", "motivation": "尽管思维语言模型通过生成内部推理链提高了性能，但控制它们的推理过程仍然具有挑战性。", "method": "本研究提出了一种针对思维语言模型的转向方法，通过分析和操纵DeepSeek-R1-Distill模型中特定的推理行为。通过在10个不同类别的500项任务上进行系统实验，识别了包括表达不确定性、生成假设验证示例和推理链回溯等推理行为。研究通过提取和应用转向向量，利用模型激活空间中的线性方向来调节模型的特定推理方面。", "result": "研究发现思维模型中的推理行为（如表达不确定性、生成示例、回溯）是由模型激活空间中的线性方向介导的，并且可以使用转向向量进行控制。该方法提供了一种调节模型推理过程特定方面（如回溯倾向或表达不确定性）的方法。该转向方法在三种DeepSeek-R1-Distill模型上得到了验证，显示出在不同模型架构下的一致控制。", "conclusion": "本研究提供了一种受控且可解释的实用工具，用于引导思维语言模型中的推理过程。", "translation": "大型语言模型（LLMs）的最新进展催生了思维语言模型，这些模型在产生响应之前会生成广泛的内部推理链。虽然这些模型实现了性能提升，但控制其推理过程仍然具有挑战性。这项工作通过分析和操纵DeepSeek-R1-Distill模型中特定的推理行为，提出了一种针对思维LLMs的转向方法。通过在10个不同类别的500项任务上进行的系统实验，我们识别了思维模型表现出的几种推理行为，包括表达不确定性、生成假设验证示例以及推理链中的回溯。我们证明这些行为是由模型激活空间中的线性方向介导的，并且可以使用转向向量进行控制。通过提取和应用这些向量，我们提供了一种调节模型推理过程特定方面的方法，例如其回溯或表达不确定性的倾向。我们的方法为以受控和可解释的方式引导思维模型中的推理过程提供了实用工具。我们使用三种DeepSeek-R1-Distill模型验证了我们的转向方法，证明了在不同模型架构下的一致控制。", "summary": "本研究提出了一种通过转向向量来理解和控制思维语言模型推理过程的方法。通过对DeepSeek-R1-Distill模型进行系统实验，识别出多种推理行为，并发现这些行为与模型激活空间中的线性方向相关。研究通过提取和应用转向向量，成功地调节了模型在推理过程中的特定倾向，例如回溯或表达不确定性，从而提供了一种可控且可解释的推理引导工具。", "keywords": "思维语言模型, 推理控制, 转向向量, 激活空间, DeepSeek-R1-Distill", "comments": "该论文的创新点在于提出了利用转向向量在模型激活空间中直接操纵和控制思维语言模型推理行为的方法，这为理解和改进LLM的内部工作机制提供了新的视角和实用工具。其重要性在于，它为提高LLM的可控性和可解释性迈出了重要一步，特别是在需要精确控制模型输出背后推理过程的场景中具有巨大潜力。"}}
{"id": "2507.13631", "title": "4T2R X-ReRAM CiM Array for Variation-tolerant, Low-power, Massively Parallel MAC Operation", "authors": ["Fuyuki Kihara", "Seiji Uenohara", "Satoshi Awamura", "Naoko Misawa", "Chihiro Matsui", "Ken Takeuchi"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      4 pages", "url": "http://arxiv.org/abs/2507.13631v1", "summary": "Computation-in-Memory (CiM) is attracting attention as a technology that can\nperform MAC calculations required for AI accelerators, at high speed with low\npower consumption. However, there is a problem regarding power consumption and\ndevice-derived errors that increase as row parallelism increases. In this\npaper, a 4T2R ReRAM cell and an 8T SRAM CiM suitable for CiM is proposed. It is\nshown that adopting the proposed 4T2R ReRAM cell reduces the errors due to\nvariation in ReRAM devices compared to conventional 4T4R ReRAM cells.", "comment": "4 pages", "pdf_url": "http://arxiv.org/pdf/2507.13631v1", "cate": "cs.AR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "用于容忍变异、低功耗、大规模并行MAC操作的4T2R X-ReRAM CiM阵列", "tldr": "本文提出一种4T2R ReRAM单元和8T SRAM CiM，旨在解决内存计算（CiM）中ReRAM器件变异引起的误差和功耗问题，并证明其能有效减少误差。", "motivation": "内存计算（CiM）技术在AI加速器中实现高速低功耗MAC计算方面具有潜力，但随着行并行度的增加，功耗和器件引起的误差问题也随之增加。", "method": "提出了一种适用于CiM的4T2R ReRAM单元和8T SRAM CiM。", "result": "研究表明，与传统的4T4R ReRAM单元相比，采用所提出的4T2R ReRAM单元可以减少ReRAM器件变异引起的误差。", "conclusion": "所提出的4T2R ReRAM单元能有效减少ReRAM器件变异引起的误差，使其适用于实现容错、低功耗的大规模并行MAC操作。", "translation": "内存计算（CiM）作为一种能够高速、低功耗地执行AI加速器所需MAC计算的技术，正受到广泛关注。然而，随着行并行度的增加，功耗和器件引起的误差也随之增加。在本文中，提出了一种适用于CiM的4T2R ReRAM单元和8T SRAM CiM。结果表明，与传统的4T4R ReRAM单元相比，采用所提出的4T2R ReRAM单元可以减少ReRAM器件变异引起的误差。", "summary": "本文针对内存计算（CiM）中随着并行度增加而出现的功耗和器件误差问题，提出了一种新的4T2R ReRAM单元和8T SRAM CiM。研究表明，与传统4T4R ReRAM单元相比，所提出的4T2R ReRAM单元能有效减少ReRAM器件变异引起的误差，从而支持容错、低功耗的大规模并行MAC操作。", "keywords": "内存计算, ReRAM, MAC操作, 器件变异, 低功耗", "comments": "这篇论文提出了一种创新的4T2R ReRAM单元设计，旨在解决CiM技术中ReRAM器件变异引起的误差问题，这对于实现更可靠、更低功耗的AI加速器至关重要。"}}
{"id": "2507.14066", "title": "Preference-based Multi-Objective Reinforcement Learning", "authors": ["Ni Mu", "Yao Luan", "Qing-Shan Jia"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      This article has been accepted for publication in IEEE Transactions on Automation Science and Engineering. This is the author's version, which has not been fully edited, and the content may change prior to final publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights for text and data mining and training of artificial intelligence and similar technologies", "url": "http://arxiv.org/abs/2507.14066v1", "summary": "Multi-objective reinforcement learning (MORL) is a structured approach for\noptimizing tasks with multiple objectives. However, it often relies on\npre-defined reward functions, which can be hard to design for balancing\nconflicting goals and may lead to oversimplification. Preferences can serve as\nmore flexible and intuitive decision-making guidance, eliminating the need for\ncomplicated reward design. This paper introduces preference-based MORL\n(Pb-MORL), which formalizes the integration of preferences into the MORL\nframework. We theoretically prove that preferences can derive policies across\nthe entire Pareto frontier. To guide policy optimization using preferences, our\nmethod constructs a multi-objective reward model that aligns with the given\npreferences. We further provide theoretical proof to show that optimizing this\nreward model is equivalent to training the Pareto optimal policy. Extensive\nexperiments in benchmark multi-objective tasks, a multi-energy management task,\nand an autonomous driving task on a multi-line highway show that our method\nperforms competitively, surpassing the oracle method, which uses the ground\ntruth reward function. This highlights its potential for practical applications\nin complex real-world systems.", "comment": "This article has been accepted for publication in IEEE Transactions\n  on Automation Science and Engineering. This is the author's version, which\n  has not been fully edited, and the content may change prior to final\n  publication. \\c{opyright} 2025 IEEE. All rights reserved, including rights\n  for text and data mining and training of artificial intelligence and similar\n  technologies", "pdf_url": "http://arxiv.org/pdf/2507.14066v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于偏好的多目标强化学习", "tldr": "本文提出了基于偏好的多目标强化学习（Pb-MORL），通过将偏好整合到MORL框架中，解决了传统方法中奖励函数设计困难的问题，并证明了其能够生成帕累托最优策略，在实际任务中表现优异。", "motivation": "传统的多目标强化学习（MORL）依赖预定义的奖励函数，但设计这些函数来平衡冲突目标很困难，且可能导致过度简化。偏好可以作为更灵活、直观的决策指导，避免复杂的奖励设计。", "method": "本文引入了基于偏好的多目标强化学习（Pb-MORL），将偏好形式化地整合到MORL框架中。理论上证明偏好可以推导出帕累托前沿的所有策略。为了利用偏好指导策略优化，该方法构建了一个与给定偏好对齐的多目标奖励模型，并理论证明优化此奖励模型等同于训练帕累托最优策略。", "result": "在基准多目标任务、多能源管理任务和多车道高速公路自动驾驶任务中的广泛实验表明，该方法表现出竞争力，甚至超越了使用真实奖励函数的“神谕”方法。", "conclusion": "基于偏好的多目标强化学习（Pb-MORL）能够有效整合用户偏好，克服传统MORL中奖励函数设计难题，并能生成帕累托最优策略，在复杂现实世界系统中具有潜在的实际应用价值。", "translation": "多目标强化学习（MORL）是一种用于优化具有多个目标的任务的结构化方法。然而，它通常依赖预定义的奖励函数，这对于平衡冲突目标来说很难设计，并可能导致过度简化。偏好可以作为更灵活和直观的决策指导，无需复杂的奖励设计。本文介绍了基于偏好的多目标强化学习（Pb-MORL），它将偏好正式地整合到MORL框架中。我们理论证明了偏好可以推导出整个帕累托前沿的策略。为了使用偏好指导策略优化，我们的方法构建了一个与给定偏好对齐的多目标奖励模型。我们进一步提供了理论证明，表明优化此奖励模型等同于训练帕累托最优策略。在基准多目标任务、多能源管理任务和多车道高速公路自动驾驶任务中的广泛实验表明，我们的方法表现出竞争力，超越了使用真实奖励函数的“神谕”方法。这突显了其在复杂现实世界系统中的潜在实际应用价值。", "summary": "本文提出了一种名为基于偏好的多目标强化学习（Pb-MORL）的新方法，旨在解决传统MORL中奖励函数设计困难的问题。Pb-MORL将用户偏好直接融入MORL框架，并通过构建与偏好对齐的多目标奖励模型来指导策略优化。研究理论证明了此方法能够推导出帕累托前沿的所有策略，且优化该奖励模型等同于训练帕累托最优策略。实验结果表明，Pb-MORL在多种复杂任务中表现优异，甚至超越了使用真实奖励函数的基线方法，展示了其在实际应用中的巨大潜力。", "keywords": "多目标强化学习, 偏好, 帕累托最优, 奖励模型, 决策制定", "comments": "该论文的创新点在于将用户偏好直接引入多目标强化学习，解决了传统MORL中奖励函数设计复杂且不灵活的痛点。通过理论证明和实验验证，该方法不仅在性能上超越了基线，更重要的是，它提供了一种更直观、更贴近实际需求的多目标优化范式，有望在复杂决策系统中得到广泛应用。其潜力在于降低了模型设计门槛，提高了系统的适应性。"}}
{"id": "2507.14042", "title": "Training-free Token Reduction for Vision Mamba", "authors": ["Qiankun Ma", "Ziyao Zhang", "Chi Su", "Jie Chen", "Zhen Song", "Hairong Zheng", "Wen Gao"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14042v1", "summary": "Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)\ndue to its ability to efficiently capture long-range dependencies with linear\ncomputational complexity. While token reduction, an effective compression\ntechnique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision\nMamba's efficiency is essential for enabling broader applications. However, we\nfind that directly applying existing token reduction techniques for ViTs to\nVision Mamba leads to significant performance degradation. This is primarily\nbecause Mamba is a sequence model without attention mechanisms, whereas most\ntoken reduction techniques for ViTs rely on attention mechanisms for importance\nmeasurement and overlook the order of compressed tokens. In this paper, we\ninvestigate a Mamba structure-aware importance score to evaluate token\nimportance in a simple and effective manner. Building on this score, we further\npropose MTR, a training-free \\textbf{M}amba \\textbf{T}oken \\textbf{R}eduction\nframework. Without the need for training or additional tuning parameters, our\nmethod can be seamlessly integrated as a plug-and-play component across various\nMamba models. Extensive experiments demonstrate that our approach significantly\nreduces computational workload while minimizing performance impact across\nvarious tasks and multiple backbones. Notably, MTR reduces FLOPs by\napproximately 40\\% on the Vim-B backbone, with only a 1.6\\% drop in ImageNet\nperformance without retraining.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14042v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "适用于Vision Mamba的免训练令牌缩减", "tldr": "提出了一种免训练的Vision Mamba令牌缩减框架MTR，通过Mamba结构感知的重性分数，显著降低计算量并保持性能。", "motivation": "Vision Mamba虽然高效，但其令牌缩减技术尚未被充分探索。现有ViT的令牌缩减方法不适用于Vision Mamba，因为后者缺乏注意力机制。因此，需要一种针对Vision Mamba的有效令牌缩减方法来提高其效率和应用范围。", "method": "提出了一种Mamba结构感知的令牌重要性评分方法，并在此基础上开发了MTR（免训练Mamba令牌缩减）框架。MTR无需训练或额外参数调整，可作为即插即用组件集成到各种Mamba模型中。", "result": "MTR显著降低了计算负载，同时对性能影响最小。例如，在Vim-B骨干网络上，MTR减少了约40%的FLOPs，而ImageNet性能仅下降1.6%，无需重新训练。", "conclusion": "本文提出了一种针对Vision Mamba的有效且免训练的令牌缩减框架MTR，通过引入Mamba结构感知的令牌重要性评分，成功解决了现有方法不兼容的问题，并在保持性能的同时大幅提升了计算效率。", "translation": "Vision Mamba因其能够以线性计算复杂度有效捕获长距离依赖性，已成为Vision Transformer (ViT) 的有力竞争者。然而，令牌缩减作为ViT中一种有效的压缩技术，在Vision Mamba中却鲜有探索。探索Vision Mamba的效率对于实现更广泛的应用至关重要。然而，我们发现将现有ViT的令牌缩减技术直接应用于Vision Mamba会导致显著的性能下降。这主要是因为Mamba是一种没有注意力机制的序列模型，而大多数ViT的令牌缩减技术依赖于注意力机制进行重要性测量，并忽略了压缩令牌的顺序。在本文中，我们研究了一种Mamba结构感知的重性分数，以简单有效的方式评估令牌的重要性。在此分数的基础上，我们进一步提出了MTR，一个免训练的\\textbf{M}amba \\textbf{T}oken \\textbf{R}eduction 框架。我们的方法无需训练或额外的调整参数，可以无缝地作为即插即用组件集成到各种Mamba模型中。广泛的实验表明，我们的方法在各种任务和多个骨干网络上显著降低了计算工作量，同时最大限度地减少了性能影响。值得注意的是，MTR在Vim-B骨干网络上将FLOPs减少了约40%，而ImageNet性能仅下降1.6%，无需重新训练。", "summary": "本文针对Vision Mamba模型，提出了一种名为MTR的免训练令牌缩减框架。鉴于现有ViT令牌缩减方法不适用于缺乏注意力机制的Mamba模型，作者设计了一种Mamba结构感知的令牌重要性评分。MTR框架基于此评分，无需额外训练或调优，即可作为即插即用组件显著降低Vision Mamba的计算复杂度，例如在Vim-B上实现40%的FLOPs减少，而ImageNet性能仅下降1.6%。", "keywords": "Vision Mamba, 令牌缩减, 免训练, 计算效率, 结构感知", "comments": "这篇论文的创新点在于首次系统地解决了Vision Mamba的令牌缩减问题，并提出了一种不依赖注意力机制的全新重要性评估方法。其“免训练”和“即插即用”的特性极大地降低了应用门槛，对于提升Vision Mamba在实际应用中的效率和普及度具有重要意义。性能提升显著且性能下降微乎其微，显示了该方法的有效性。"}}
{"id": "2505.20839", "title": "FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration", "authors": ["Daehyeon Baek", "Jieun Choi", "Jimyoung Son", "Kyungmin Bin", "Seungbeom Choi", "Kihyo Moon", "Minsung Jang", "Hyojung Lee"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2505.20839v3", "summary": "As large language models become increasingly prevalent, memory bandwidth\nconstraints significantly limit inference throughput, motivating post-training\nquantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ\nframework and an INT4-FP8 matrix multiplication kernel that accelerates LLM\ninference across all linear layers. Specifically, FireQ quantizes linear layer\nweights and key-values to INT4, and activations and queries to FP8,\nsignificantly enhancing throughput. Additionally, we introduce a three-stage\npipelining for the prefill phase, which modifies the FlashAttention-3 kernel,\neffectively reducing time-to-first-token in the prefill phase. To minimize\naccuracy loss from quantization, we develop novel outlier smoothing techniques\ntailored separately for linear and attention layers. In linear layers, we\nexplicitly use per-tensor scaling to prevent underflow caused by the FP8\nquantization scaling factor of INT4 quantization, and channel-wise scaling to\ncompensate for coarse granularity of INT4. In attention layers, we address\nquantization challenges posed by rotary positional embeddings (RoPE) by\ncombining pre-RoPE and post-RoPE scaling strategies. FireQ significantly\noutperforms state-of-the-art methods, achieving 1.68x faster inference in\nfeed-forward network layers on Llama2-7B and 1.26x faster prefill phase\nperformance on Llama3-8B compared to QServe, with negligible accuracy loss.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2505.20839v3", "cate": "cs.LG", "date": "2025-05-27", "updated": "2025-07-18", "AI": {"title_translation": "FireQ：用于LLM推理加速的快速INT4-FP8核与RoPE感知量化", "tldr": "FireQ是一个结合了INT4-FP8核与RoPE感知量化、离群值平滑技术的PTQ框架，显著加速了LLM推理并保持了准确性。", "motivation": "大型语言模型日益普及，但内存带宽限制严重制约了推理吞吐量，因此需要进行训练后量化（PTQ）来加速LLM推理。", "method": "本文提出了FireQ，一个协同设计的PTQ框架和一个INT4-FP8矩阵乘法核。FireQ将线性层权重和键值量化为INT4，将激活和查询量化为FP8。它还引入了预填充阶段的三阶段流水线，修改了FlashAttention-3核。为最小化量化引起的精度损失，FireQ开发了针对线性层和注意力层的新型离群值平滑技术：线性层使用逐张量缩放和逐通道缩放；注意力层通过结合RoPE前和RoPE后缩放策略解决RoPE带来的量化挑战。", "result": "FireQ在Llama2-7B的FFN层中实现了1.68倍的推理加速，在Llama3-8B的预填充阶段比QServe快1.26倍，且精度损失可忽略不计。", "conclusion": "FireQ通过其协同设计的量化框架、优化核以及先进的离群值平滑技术，显著提升了大型语言模型推理的速度，同时保持了高精度，超越了现有SOTA方法。", "translation": "随着大型语言模型日益普及，内存带宽限制严重制约了推理吞吐量，这推动了训练后量化（PTQ）的发展。在本文中，我们提出了FireQ，一个协同设计的PTQ框架和一个INT4-FP8矩阵乘法核，用于加速所有线性层上的LLM推理。具体来说，FireQ将线性层权重和键值量化为INT4，将激活和查询量化为FP8，显著提高了吞吐量。此外，我们引入了预填充阶段的三阶段流水线，修改了FlashAttention-3核，有效地减少了预填充阶段的首个token生成时间。为了最小化量化引起的精度损失，我们开发了专门针对线性和注意力层的新型离群值平滑技术。在线性层中，我们明确使用逐张量缩放以防止由INT4量化的FP8量化比例因子引起的下溢，并使用逐通道缩放来补偿INT4的粗粒度。在注意力层中，我们通过结合RoPE前和RoPE后缩放策略来解决旋转位置嵌入（RoPE）带来的量化挑战。FireQ显著优于现有最先进的方法，在Llama2-7B上的前馈网络层中实现了1.68倍的推理加速，在Llama3-8B上的预填充阶段比QServe快1.26倍，且精度损失可忽略不计。", "summary": "本文提出了FireQ，一个创新的训练后量化（PTQ）框架，旨在加速大型语言模型（LLM）的推理。FireQ的核心在于其协同设计的INT4-FP8矩阵乘法核，将线性层权重和键值量化为INT4，激活和查询量化为FP8，从而显著提高吞吐量。为优化预填充阶段，它引入了三阶段流水线并修改了FlashAttention-3核。此外，FireQ开发了针对线性和注意力层的新型离群值平滑技术，特别是处理了RoPE带来的量化挑战，以最小化精度损失。实验结果表明，FireQ在Llama2-7B和Llama3-8B上均实现了显著的推理加速，同时保持了可忽略不计的精度损失，性能超越了现有最先进的方法。", "keywords": "LLM推理加速, 量化, INT4-FP8, RoPE感知, 离群值平滑", "comments": "FireQ的创新之处在于其INT4-FP8混合精度量化策略、针对预填充阶段的三阶段流水线优化以及专门为线性和注意力层（特别是RoPE感知）设计的离群值平滑技术。这表明了对低比特量化精度损失的深入理解和有效缓解。其在推理速度上的显著提升，同时保持低精度损失，对于LLM的实际部署和大规模应用具有重要意义。"}}
{"id": "2503.18890", "title": "Public-Key Quantum Money and Fast Real Transforms", "authors": ["Jake Doliskani", "Morteza Mirzaei", "Ali Mousavi"], "categories": ["quant-ph", "cs.CR"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.18890v3", "summary": "We propose a public-key quantum money scheme based on group actions and the\nHartley transform. Our scheme adapts the quantum money scheme of Zhandry\n(2024), replacing the Fourier transform with the Hartley transform. This\nsubstitution ensures the banknotes have real amplitudes rather than complex\namplitudes, which could offer both computational and theoretical advantages.\n  To support this new construction, we propose a new verification algorithm\nthat uses group action twists to address verification failures caused by the\nswitch to real amplitudes. We also show how to efficiently compute the serial\nnumber associated with a money state using a new algorithm based on\ncontinuous-time quantum walks. Finally, we present a recursive algorithm for\nthe quantum Hartley transform, achieving lower gate complexity than prior work\nand demonstrate how to compute other real quantum transforms, such as the\nquantum sine transform, using the quantum Hartley transform as a subroutine.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.18890v3", "cate": "quant-ph", "date": "2025-03-24", "updated": "2025-07-17", "AI": {"title_translation": "公钥量子货币与快速实数变换", "tldr": "提出了一种基于群作用和哈特利变换的公钥量子货币方案，用实数振幅取代复数振幅，并开发了新的验证算法、序列号计算方法以及高效的量子哈特利变换算法。", "motivation": "该研究旨在通过用哈特利变换取代傅里叶变换，使量子钞票具有实数振幅而非复数振幅，这可能带来计算和理论上的优势。", "method": "该方案基于群作用和哈特利变换，是对Zhandry（2024）量子货币方案的改进。为了支持这一新构造，提出了一种使用群作用扭曲的新验证算法来解决由实数振幅引起的验证失败。同时，提出了一种基于连续时间量子行走的算法，用于高效计算货币状态的序列号。最后，提出了一个递归量子哈特利变换算法，实现了比现有工作更低的门复杂度，并展示了如何使用量子哈特利变换作为子程序来计算其他实数量子变换（如量子正弦变换）。", "result": "所提出的方案确保了钞票具有实数振幅。新的验证算法能够解决实数振幅导致的验证失败。序列号能够使用基于连续时间量子行走的算法高效计算。递归量子哈特利变换算法实现了比以往工作更低的门复杂度，并且该方法可以用于计算其他实数量子变换。", "conclusion": "本研究提出了一种基于哈特利变换的公钥量子货币方案，通过引入实数振幅提供了潜在的优势。为了支持这一方案，开发了创新的验证算法、高效的序列号计算方法，并优化了量子哈特利变换及其在其他实数量子变换中的应用。", "translation": "我们提出了一种基于群作用和哈特利变换的公钥量子货币方案。我们的方案改编自Zhandry（2024）的量子货币方案，用哈特利变换取代了傅里叶变换。这种替换确保了钞票具有实数振幅而非复数振幅，这可能带来计算和理论上的优势。为了支持这一新构造，我们提出了一种新的验证算法，该算法使用群作用扭曲来解决由于切换到实数振幅而导致的验证失败。我们还展示了如何使用一种基于连续时间量子行走的新算法来高效计算与货币状态相关联的序列号。最后，我们提出了一个量子哈特利变换的递归算法，实现了比现有工作更低的门复杂度，并演示了如何使用量子哈特利变换作为子程序来计算其他实数量子变换，例如量子正弦变换。", "summary": "本文提出了一种基于群作用和哈特利变换的公钥量子货币方案，其核心在于用哈特利变换取代传统方案中的傅里叶变换，从而使量子钞票具有实数振幅。为克服实数振幅带来的验证挑战，论文引入了新的基于群作用扭曲的验证算法。此外，还开发了利用连续时间量子行走高效计算钞票序列号的方法，并提出了一个低门复杂度的递归量子哈特利变换算法，该算法还能作为子程序用于计算其他实数量子变换，为量子货币和量子信号处理提供了新颖的理论和计算工具。", "keywords": "公钥量子货币, 哈特利变换, 实数振幅, 量子算法, 量子变换", "comments": "该论文的创新点在于将哈特利变换引入公钥量子货币方案，解决了实数振幅的实现和验证问题，并显著优化了量子哈特利变换的计算效率。这不仅为量子货币的设计提供了新的思路和潜在优势，也为更广泛的实数量子信号处理奠定了基础，具有重要的理论和潜在应用价值。"}}
{"id": "2502.11887", "title": "Stonefish: Supporting Machine Learning Research in Marine Robotics", "authors": ["Michele Grimaldi", "Patryk Cieslak", "Eduardo Ochoa", "Vibhav Bharti", "Hayat Rajani", "Ignacio Carlucho", "Maria Koskinopoulou", "Yvan R. Petillot", "Nuno Gracias"], "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      2025 IEEE/RSJ International Conference on Robotics and Automation (ICRA)", "url": "http://arxiv.org/abs/2502.11887v2", "summary": "Simulations are highly valuable in marine robotics, offering a cost-effective\nand controlled environment for testing in the challenging conditions of\nunderwater and surface operations. Given the high costs and logistical\ndifficulties of real-world trials, simulators capable of capturing the\noperational conditions of subsea environments have become key in developing and\nrefining algorithms for remotely-operated and autonomous underwater vehicles.\nThis paper highlights recent enhancements to the Stonefish simulator, an\nadvanced open-source platform supporting development and testing of marine\nrobotics solutions. Key updates include a suite of additional sensors, such as\nan event-based camera, a thermal camera, and an optical flow camera, as well\nas, visual light communication, support for tethered operations, improved\nthruster modelling, more flexible hydrodynamics, and enhanced sonar accuracy.\nThese developments and an automated annotation tool significantly bolster\nStonefish's role in marine robotics research, especially in the field of\nmachine learning, where training data with a known ground truth is hard or\nimpossible to collect.", "comment": "2025 IEEE/RSJ International Conference on Robotics and Automation\n  (ICRA)", "pdf_url": "http://arxiv.org/pdf/2502.11887v2", "cate": "cs.RO", "date": "2025-02-17", "updated": "2025-07-18", "AI": {"title_translation": "Stonefish：支持海洋机器人学中的机器学习研究", "tldr": "本文介绍了Stonefish模拟器的最新增强功能，使其在海洋机器人学研究，特别是机器学习领域，能够提供成本效益高且受控的测试环境和难以获取的训练数据。", "motivation": "在海洋机器人学中，真实世界的试验成本高昂且存在后勤困难，而水下和水面作业环境又极具挑战性。因此，需要能够捕捉水下操作条件的模拟器来开发和完善遥控和自主水下车辆的算法。", "method": "本文介绍了对Stonefish模拟器（一个先进的开源平台）的最新增强功能。主要更新包括增加了一系列传感器（如事件相机、热像仪、光流相机）、视觉光通信、系留操作支持、改进的推进器建模、更灵活的流体动力学以及增强的声纳精度。此外，还增加了一个自动化标注工具。", "result": "这些开发和自动化标注工具显著增强了Stonefish在海洋机器人学研究中的作用，尤其是在机器学习领域。它能够提供难以或不可能在真实世界中收集到的具有已知地面真实值的训练数据。", "conclusion": "Stonefish模拟器的增强功能，特别是其新的传感器和自动化标注工具，极大地提升了其在海洋机器人学研究中的价值，尤其是在为机器学习提供训练数据方面。", "translation": "模拟在海洋机器人学中具有极高价值，它为在水下和水面作业的挑战性条件下进行测试提供了一个成本效益高且受控的环境。鉴于真实世界试验的高昂成本和后勤困难，能够捕捉水下操作条件的模拟器已成为开发和完善遥控和自主水下车辆算法的关键。本文重点介绍了Stonefish模拟器的最新增强功能，这是一个支持海洋机器人解决方案开发和测试的先进开源平台。主要更新包括一套额外的传感器，如事件相机、热像仪和光流相机，以及视觉光通信、系留操作支持、改进的推进器建模、更灵活的流体动力学和增强的声纳精度。这些开发和一个自动化标注工具显著增强了Stonefish在海洋机器人学研究中的作用，特别是在机器学习领域，该领域中具有已知地面真实值的训练数据难以或不可能收集。", "summary": "Stonefish模拟器是一个支持海洋机器人学研究的开源平台。本文详细介绍了该模拟器的最新增强功能，包括新增多种传感器（如事件相机、热像仪、光流相机）、视觉光通信、系留操作支持、改进的推进器建模、更灵活的流体动力学以及增强的声纳精度。这些改进与自动化标注工具相结合，极大地提升了Stonefish在海洋机器人学领域，特别是为难以获取真实数据的机器学习研究提供训练数据方面的能力和价值。", "keywords": "海洋机器人学, 模拟器, 机器学习, Stonefish, 传感器", "comments": "本文介绍了Stonefish模拟器的重要更新，其创新点在于通过模拟环境解决了海洋机器人领域高成本、高风险的真实数据采集难题。特别是对多种新型传感器的支持和自动化标注工具的引入，直接满足了机器学习对大量带标注训练数据的需求，这对于推动水下AI技术的发展具有重要意义。该平台的开源性质也利于社区协作和技术普及。"}}
{"id": "2507.13719", "title": "Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction", "authors": ["Daniele Pannone", "Alessia Castronovo", "Maurizio Mancini", "Gian Luca Foresti", "Claudio Piciarelli", "Rossana Gabrieli", "Muhammad Yasir Bilal", "Danilo Avola"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13719v1", "summary": "This paper presents an innovative augmented reality pipeline tailored for\nmuseum environments, aimed at recognizing artworks and generating accurate 3D\nmodels from single images. By integrating two complementary pre-trained depth\nestimation models, i.e., GLPN for capturing global scene structure and\nDepth-Anything for detailed local reconstruction, the proposed approach\nproduces optimized depth maps that effectively represent complex artistic\nfeatures. These maps are then converted into high-quality point clouds and\nmeshes, enabling the creation of immersive AR experiences. The methodology\nleverages state-of-the-art neural network architectures and advanced computer\nvision techniques to overcome challenges posed by irregular contours and\nvariable textures in artworks. Experimental results demonstrate significant\nimprovements in reconstruction accuracy and visual realism, making the system a\nhighly robust tool for museums seeking to enhance visitor engagement through\ninteractive digital content.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13719v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "文化遗产中的增强现实：3D艺术品重建的双模型管道", "tldr": "本文提出一种用于博物馆环境的AR管道，通过结合GLPN和Depth-Anything两种深度估计模型，从单张图像生成高精度3D艺术品模型，显著提升了重建准确性和视觉真实感，为博物馆提供增强访客体验的工具。", "motivation": "该研究旨在为博物馆环境提供一种创新的增强现实（AR）管道，通过识别艺术品并从单张图像生成准确的3D模型，以克服艺术品不规则轮廓和可变纹理带来的挑战，从而增强访客参与度。", "method": "该方法整合了两个互补的预训练深度估计模型：GLPN用于捕获全局场景结构，Depth-Anything用于详细的局部重建。通过这种方式生成优化的深度图，然后将这些深度图转换为高质量的点云和网格。整个过程利用了最先进的神经网络架构和高级计算机视觉技术。", "result": "实验结果表明，该方法在重建准确性和视觉真实感方面取得了显著改进。", "conclusion": "所提出的系统是一个高度稳健的工具，博物馆可以利用它通过交互式数字内容来增强访客参与度。", "translation": "本文提出了一种专为博物馆环境量身定制的创新增强现实管道，旨在识别艺术品并从单张图像生成准确的3D模型。通过整合两个互补的预训练深度估计模型，即用于捕获全局场景结构的GLPN和用于详细局部重建的Depth-Anything，所提出的方法生成了优化的深度图，有效表示了复杂的艺术特征。这些深度图随后被转换为高质量的点云和网格，从而能够创建沉浸式AR体验。该方法利用最先进的神经网络架构和高级计算机视觉技术，克服了艺术品不规则轮廓和可变纹理带来的挑战。实验结果表明，重建准确性和视觉真实感显著提高，使该系统成为博物馆寻求通过交互式数字内容增强访客参与度的强大工具。", "summary": "本研究介绍了一种用于文化遗产领域的增强现实（AR）管道，专门针对博物馆环境设计。该管道通过结合GLPN和Depth-Anything两种预训练深度估计模型，能够从单张图像生成艺术品的精确3D模型，有效处理复杂艺术特征。生成的深度图被转换为高质量的点云和网格，用于创建沉浸式AR体验。实验证明，该方法显著提升了3D重建的准确性和视觉真实感，为博物馆提供了增强访客互动和数字内容呈现的强大工具。", "keywords": "增强现实, 文化遗产, 3D重建, 深度估计, 博物馆", "comments": "该论文的创新之处在于其双模型深度估计管道，结合了全局和局部信息，有效解决了艺术品3D重建中的复杂性。这为文化遗产数字化和博物馆访客体验的提升提供了一个实用且强大的解决方案，具有重要的应用前景。"}}
{"id": "2402.10310", "title": "Interpretable Imitation Learning via Generative Adversarial STL Inference and Control", "authors": ["Wenliang Liu", "Danyang Li", "Erfan Aasi", "Daniela Rus", "Roberto Tron", "Calin Belta"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at NeuS 2025 (International Conference on Neuro-symbolic Systems)", "url": "http://arxiv.org/abs/2402.10310v2", "summary": "Imitation learning methods have demonstrated considerable success in teaching\nautonomous systems complex tasks through expert demonstrations. However, a\nlimitation of these methods is their lack of interpretability, particularly in\nunderstanding the specific task the learning agent aims to accomplish. In this\npaper, we propose a novel imitation learning method that combines Signal\nTemporal Logic (STL) inference and control synthesis, enabling the explicit\nrepresentation of the task as an STL formula. This approach not only provides a\nclear understanding of the task but also supports the integration of human\nknowledge and allows for adaptation to out-of-distribution scenarios by\nmanually adjusting the STL formulas and fine-tuning the policy. We employ a\nGenerative Adversarial Network (GAN)-inspired approach to train both the\ninference and policy networks, effectively narrowing the gap between expert and\nlearned policies. The efficiency of our algorithm is demonstrated through\nsimulations, showcasing its practical applicability and adaptability.", "comment": "Published at NeuS 2025 (International Conference on Neuro-symbolic\n  Systems)", "pdf_url": "http://arxiv.org/pdf/2402.10310v2", "cate": "cs.LG", "date": "2024-02-15", "updated": "2025-07-18", "AI": {"title_translation": "可解释的模仿学习：基于生成对抗式STL推理与控制", "tldr": "提出一种基于STL推理和GAN的模仿学习方法，提高可解释性并实现任务的明确表示和适应性。", "motivation": "现有模仿学习方法缺乏可解释性，难以理解学习代理旨在完成的具体任务。", "method": "本文提出一种新颖的模仿学习方法，结合了信号时序逻辑（STL）推理和控制合成，能够将任务明确表示为STL公式。该方法采用受生成对抗网络（GAN）启发的方法来训练推理和策略网络，以缩小专家与学习策略之间的差距。", "result": "算法的效率通过仿真得到验证，展示了其在实际应用中的适用性和适应性。", "conclusion": "本文提出的方法通过将任务明确表示为STL公式并结合GAN训练，有效提升了模仿学习的可解释性、可适应性，并缩小了专家与学习策略之间的差距。", "translation": "模仿学习方法在通过专家演示教授自主系统复杂任务方面取得了相当大的成功。然而，这些方法的一个局限性是它们缺乏可解释性，特别是在理解学习代理旨在完成的具体任务方面。在本文中，我们提出了一种新颖的模仿学习方法，该方法结合了信号时序逻辑（STL）推理和控制合成，从而能够将任务明确表示为STL公式。这种方法不仅提供了对任务的清晰理解，还支持人类知识的整合，并允许通过手动调整STL公式和微调策略来适应分布外场景。我们采用受生成对抗网络（GAN）启发的方法来训练推理和策略网络，有效地缩小了专家策略和学习策略之间的差距。通过仿真验证了我们算法的效率，展示了其实际适用性和适应性。", "summary": "本文提出了一种新颖的可解释模仿学习方法，通过结合信号时序逻辑（STL）推理和控制合成，将复杂任务明确表示为STL公式，从而解决了现有模仿学习方法缺乏可解释性的问题。该方法利用生成对抗网络（GAN）的思想训练推理和策略网络，有效缩小了专家与学习策略之间的差距，并支持人类知识整合和对分布外场景的适应。仿真结果验证了该算法的效率、实用性和适应性。", "keywords": "模仿学习, 可解释性, 信号时序逻辑, 生成对抗网络, 任务表示", "comments": "这篇论文的创新点在于将信号时序逻辑（STL）引入模仿学习，以解决其可解释性不足的问题，并明确表示任务。通过结合GAN训练，提升了学习效率和策略质量。该方法还强调了人类知识的整合和对未知环境的适应能力，具有重要的实际应用价值。"}}
{"id": "2506.17562", "title": "LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning", "authors": ["Haoxuan Che", "Haibo Jin", "Zhengrui Guo", "Yi Lin", "Cheng Jin", "Hao Chen"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE TMI", "url": "http://arxiv.org/abs/2506.17562v2", "summary": "LLMs have demonstrated significant potential in Medical Report Generation\n(MRG), yet their development requires large amounts of medical image-report\npairs, which are commonly scattered across multiple centers. Centralizing these\ndata is exceptionally challenging due to privacy regulations, thereby impeding\nmodel development and broader adoption of LLM-driven MRG models. To address\nthis challenge, we present FedMRG, the first framework that leverages Federated\nLearning (FL) to enable privacy-preserving, multi-center development of\nLLM-driven MRG models, specifically designed to overcome the critical challenge\nof communication-efficient LLM training under multi-modal data heterogeneity.\nTo start with, our framework tackles the fundamental challenge of communication\noverhead in FL-LLM tuning by employing low-rank factorization to efficiently\ndecompose parameter updates, significantly reducing gradient transmission costs\nand making LLM-driven MRG feasible in bandwidth-constrained FL settings.\nFurthermore, we observed the dual heterogeneity in MRG under the FL scenario:\nvarying image characteristics across medical centers, as well as diverse\nreporting styles and terminology preferences. To address this, we further\nenhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,\ncoupled with diagnosis-driven prompts, which capture both globally\ngeneralizable and locally distinctive features while maintaining diagnostic\naccuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder\nthat harmonizes generic and specialized adapters to address variations in\nreporting styles and terminology. Through extensive evaluation of our\nestablished FL-MRG benchmark, we demonstrate the generalizability and\nadaptability of FedMRG, underscoring its potential in harnessing multi-center\ndata and generating clinically accurate reports while maintaining communication\nefficiency.", "comment": "Accepted by IEEE TMI", "pdf_url": "http://arxiv.org/pdf/2506.17562v2", "cate": "cs.CV", "date": "2025-06-21", "updated": "2025-07-18", "AI": {"title_translation": "基于通信高效异构联邦学习的LLM驱动医疗报告生成", "tldr": "FedMRG是一个联邦学习框架，通过低秩分解和双重异构处理，实现隐私保护、通信高效的多中心LLM驱动医疗报告生成。", "motivation": "LLM在医疗报告生成（MRG）方面潜力巨大，但其发展需要大量分散在不同中心、难以集中（因隐私法规）的医疗图像-报告对，这阻碍了模型的开发和广泛应用。", "method": "本文提出了FedMRG，这是首个利用联邦学习（FL）实现隐私保护、多中心LLM驱动MRG模型开发的框架。为解决通信开销问题，FedMRG采用低秩分解来高效分解参数更新，显著降低梯度传输成本。为应对MRG在FL场景下的双重异构性（图像特征和报告风格），FedMRG进一步增强了：1) MRG编码器中的客户端感知对比学习结合诊断驱动提示，以捕获全局可泛化和局部独特特征；2) MRG解码器中的双适配器相互促进机制，以协调通用和专用适配器来处理报告风格和术语的差异。", "result": "通过对所建立的FL-MRG基准的广泛评估，FedMRG展示了其泛化能力和适应性，能够利用多中心数据生成临床准确的报告，同时保持通信效率。", "conclusion": "FedMRG框架成功解决了LLM驱动医疗报告生成在多中心、隐私保护和异构联邦学习环境下的挑战，实现了通信高效且临床准确的报告生成。", "translation": "大型语言模型（LLM）在医疗报告生成（MRG）方面展现出巨大潜力，然而它们的开发需要大量的医疗图像-报告对，这些数据通常分散在多个中心。由于隐私法规，集中这些数据极具挑战性，从而阻碍了模型开发和LLM驱动MRG模型的广泛采用。为了解决这一挑战，我们提出了FedMRG，这是第一个利用联邦学习（FL）实现隐私保护、多中心LLM驱动MRG模型开发的框架，专门设计用于克服多模态数据异构性下通信高效的LLM训练这一关键挑战。首先，我们的框架通过采用低秩分解来高效分解参数更新，解决了FL-LLM微调中通信开销的根本挑战，显著降低了梯度传输成本，使得LLM驱动的MRG在带宽受限的FL设置中变得可行。此外，我们观察到FL场景下MRG中的双重异构性：医疗中心之间不同的图像特征，以及多样化的报告风格和术语偏好。为了解决这个问题，我们进一步通过以下方式增强了FedMRG：(1) MRG编码器中的客户端感知对比学习，结合诊断驱动提示，在保持诊断准确性的同时捕获全局可泛化和局部独特的特征；(2) MRG解码器中的双适配器相互促进机制，协调通用和专用适配器以解决报告风格和术语的差异。通过对我们建立的FL-MRG基准进行广泛评估，我们证明了FedMRG的泛化能力和适应性，突显了其在利用多中心数据和生成临床准确报告方面的潜力，同时保持了通信效率。", "summary": "本文提出了FedMRG，一个针对LLM驱动医疗报告生成的联邦学习框架。该框架旨在解决医疗数据分散、隐私限制以及多中心异构性带来的挑战。FedMRG通过低秩分解优化通信效率，并采用客户端感知对比学习和双适配器机制来处理图像特征和报告风格的双重异构性。实验证明，FedMRG在多中心环境下能够高效、准确地生成医疗报告，同时保护数据隐私。", "keywords": "LLM, 医疗报告生成, 联邦学习, 通信效率, 数据异构性", "comments": "FedMRG的创新性在于首次将联邦学习应用于LLM驱动的医疗报告生成，并系统地解决了这一领域面临的通信效率和多模态数据异构性两大核心挑战。通过引入低秩分解和双重适配器机制，该框架在保护隐私的前提下，有效利用了分散的医疗数据，对于推动医疗AI在实际临床中的应用具有重要意义。"}}
{"id": "2507.13702", "title": "SaWa-ML: Structure-Aware Pose Correction and Weight Adaptation-Based Robust Multi-Robot Localization", "authors": ["Junho Choi", "Kihwan Ryoo", "Jeewon Kim", "Taeyun Kim", "Eungchang Lee", "Myeongwoo Jeong", "Kevin Christiansen Marsim", "Hyungtae Lim", "Hyun Myung"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      This paper has been accepted to the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "url": "http://arxiv.org/abs/2507.13702v1", "summary": "Multi-robot localization is a crucial task for implementing multi-robot\nsystems. Numerous researchers have proposed optimization-based multi-robot\nlocalization methods that use camera, IMU, and UWB sensors. Nevertheless,\ncharacteristics of individual robot odometry estimates and distance\nmeasurements between robots used in the optimization are not sufficiently\nconsidered. In addition, previous researches were heavily influenced by the\nodometry accuracy that is estimated from individual robots. Consequently,\nlong-term drift error caused by error accumulation is potentially inevitable.\nIn this paper, we propose a novel visual-inertial-range-based multi-robot\nlocalization method, named SaWa-ML, which enables geometric structure-aware\npose correction and weight adaptation-based robust multi-robot localization.\nOur contributions are twofold: (i) we leverage UWB sensor data, whose range\nerror does not accumulate over time, to first estimate the relative positions\nbetween robots and then correct the positions of each robot, thus reducing\nlong-term drift errors, (ii) we design adaptive weights for robot pose\ncorrection by considering the characteristics of the sensor data and\nvisual-inertial odometry estimates. The proposed method has been validated in\nreal-world experiments, showing a substantial performance increase compared\nwith state-of-the-art algorithms.", "comment": "This paper has been accepted to the 2025 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)", "pdf_url": "http://arxiv.org/pdf/2507.13702v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "SaWa-ML：基于结构感知位姿校正和权重自适应的鲁棒多机器人定位", "tldr": "SaWa-ML是一种新的视觉-惯性-测距多机器人定位方法，通过利用UWB数据进行位姿校正和设计自适应权重，有效减少了长期漂移误差，并在实际实验中表现出显著的性能提升。", "motivation": "现有的基于优化的多机器人定位方法未能充分考虑单个机器人里程计估计和机器人间距离测量的特性，且易受里程计精度影响，导致长期漂移误差累积。", "method": "本文提出了一种名为SaWa-ML的视觉-惯性-测距多机器人定位方法，该方法实现了几何结构感知位姿校正和基于权重自适应的鲁棒定位。其贡献包括：1) 利用UWB传感器数据（其测距误差不随时间累积）首先估计机器人间的相对位置，然后校正每个机器人的位置，从而减少长期漂移误差。2) 考虑传感器数据和视觉-惯性里程计估计的特性，设计了用于机器人位姿校正的自适应权重。", "result": "所提出的方法已在实际实验中得到验证，与现有最先进的算法相比，显示出显著的性能提升。", "conclusion": "SaWa-ML方法通过结合UWB数据进行位姿校正和自适应权重设计，有效解决了多机器人定位中的长期漂移问题，显著提高了定位的鲁棒性和精度。", "translation": "多机器人定位是实现多机器人系统的关键任务。许多研究人员提出了基于优化的多机器人定位方法，这些方法使用摄像头、IMU和UWB传感器。然而，优化中使用的单个机器人里程计估计和机器人间距离测量的特性没有得到充分考虑。此外，之前的研究受到从单个机器人估计的里程计精度的严重影响。因此，误差累积导致的长期漂移误差可能不可避免。在本文中，我们提出了一种新颖的基于视觉-惯性-测距的多机器人定位方法，名为SaWa-ML，它实现了几何结构感知位姿校正和基于权重自适应的鲁棒多机器人定位。我们的贡献有两方面：(i) 我们利用UWB传感器数据（其测距误差不随时间累积）首先估计机器人间的相对位置，然后校正每个机器人的位置，从而减少长期漂移误差，(ii) 我们通过考虑传感器数据和视觉-惯性里程计估计的特性，设计了用于机器人位姿校正的自适应权重。所提出的方法已在实际实验中得到验证，与现有最先进的算法相比，显示出显著的性能提升。", "summary": "SaWa-ML是一种新型的视觉-惯性-测距多机器人定位方法，旨在解决现有方法中因里程计精度不足和误差累积导致的长期漂移问题。该方法通过利用UWB传感器数据来估计并校正机器人间的相对位置，从而有效减少漂移误差。同时，它还设计了自适应权重来优化机器人位姿校正，充分考虑了传感器数据和视觉-惯性里程计的特性。实验结果表明，SaWa-ML相比现有算法具有显著的性能提升，为多机器人系统提供了更鲁棒的定位能力。", "keywords": "多机器人定位, 位姿校正, 权重自适应, UWB传感器, 视觉-惯性-测距", "comments": "SaWa-ML的创新点在于结合UWB传感器数据进行结构感知位姿校正和引入自适应权重机制。UWB数据的使用有效解决了长期漂移问题，而自适应权重则提升了定位的鲁棒性。该方法对提高多机器人系统在复杂环境下的自主性和可靠性具有重要意义。"}}
{"id": "2507.13395", "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only", "authors": ["Xuanqi Gao", "Weipeng Jiang", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Xinyang Yin", "Chao Shen"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13395v1", "summary": "The advent of neural machine translation (NMT) has revolutionized\ncross-lingual communication, yet preserving stylistic nuances remains a\nsignificant challenge. While existing approaches often require parallel corpora\nfor style preservation, we introduce Babel, a novel framework that enhances\nstylistic fidelity in NMT using only monolingual corpora. Babel employs two key\ncomponents: (1) a style detector based on contextual embeddings that identifies\nstylistic disparities between source and target texts, and (2) a\ndiffusion-based style applicator that rectifies stylistic inconsistencies while\nmaintaining semantic integrity. Our framework integrates with existing NMT\nsystems as a post-processing module, enabling style-aware translation without\nrequiring architectural modifications or parallel stylistic data. Extensive\nexperiments on five diverse domains (law, literature, scientific writing,\nmedicine, and educational content) demonstrate Babel's effectiveness: it\nidentifies stylistic inconsistencies with 88.21% precision and improves\nstylistic preservation by 150% while maintaining a high semantic similarity\nscore of 0.92. Human evaluation confirms that translations refined by Babel\nbetter preserve source text style while maintaining fluency and adequacy.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13395v1", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "仅通过单语语料库减轻机器翻译系统的文体偏差", "tldr": "Babel是一个新框架，仅使用单语语料库即可提高NMT的文体保真度，通过文体检测器和扩散式文体应用器实现，并作为后处理模块集成。", "motivation": "现有NMT系统在保持文体细微差别方面仍面临挑战，且现有方法通常需要平行语料库，这限制了其应用。", "method": "本文引入了Babel框架，该框架仅使用单语语料库来增强NMT中的文体保真度。Babel包含两个关键组件：1) 基于上下文嵌入的文体检测器，用于识别源文本和目标文本之间的文体差异；2) 基于扩散的文体应用器，用于纠正文体不一致性，同时保持语义完整性。该框架作为一个后处理模块与现有NMT系统集成，无需架构修改或平行文体数据。", "result": "在五个不同领域（法律、文学、科学写作、医学、教育内容）进行的广泛实验证明了Babel的有效性：它以88.21%的精度识别文体不一致性，并将文体保留度提高了150%，同时保持了0.92的高语义相似度得分。人工评估证实，经Babel改进的翻译能更好地保留源文本风格，同时保持流畅性和充分性。", "conclusion": "Babel框架通过仅使用单语语料库，作为后处理模块，成功地提高了神经网络机器翻译系统的文体保真度，且无需修改现有系统架构或平行文体数据，为解决文体偏差问题提供了有效途径。", "translation": "神经网络机器翻译 (NMT) 的出现彻底改变了跨语言交流，但保留文体细微差别仍然是一个重大挑战。虽然现有方法通常需要平行语料库来保留文体，但我们引入了 Babel，这是一个新颖的框架，仅使用单语语料库即可增强 NMT 中的文体保真度。Babel 采用两个关键组件：(1) 基于上下文嵌入的文体检测器，用于识别源文本和目标文本之间的文体差异；(2) 基于扩散的文体应用器，用于纠正文体不一致性，同时保持语义完整性。我们的框架作为后处理模块与现有 NMT 系统集成，无需架构修改或平行文体数据即可实现文体感知翻译。在五个不同领域（法律、文学、科学写作、医学和教育内容）进行的广泛实验证明了 Babel 的有效性：它以 88.21% 的精度识别文体不一致性，并将文体保留度提高了 150%，同时保持了 0.92 的高语义相似度得分。人工评估证实，经 Babel 改进的翻译能更好地保留源文本风格，同时保持流畅性和充分性。", "summary": "本文提出Babel框架，旨在仅利用单语语料库解决神经机器翻译中的文体偏差问题。Babel包含文体检测器和扩散式文体应用器，作为NMT系统的后处理模块，无需平行文体数据或架构修改。实验证明，Babel能有效识别并纠正文体不一致性，显著提高文体保留度，同时保持高语义相似度，并得到人工评估的验证。", "keywords": "机器翻译, 文体偏差, 单语语料库, 文体保留, 神经网络机器翻译", "comments": "Babel的创新之处在于其仅依赖单语语料库来提升NMT文体保真度，这显著降低了对昂贵平行语料的需求。其作为后处理模块的集成方式，使得现有NMT系统无需修改即可受益，提高了实用性，为机器翻译的文体控制提供了一条有前景的路径。"}}
{"id": "2507.08392", "title": "Multi-Agent LLMs as Ethics Advocates for AI-Based Systems", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "categories": ["cs.AI", "cs.CY"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08392v2", "summary": "Incorporating ethics into the requirement elicitation process is essential\nfor creating ethically aligned systems. Although eliciting manual ethics\nrequirements is effective, it requires diverse input from multiple\nstakeholders, which can be challenging due to time and resource constraints.\nMoreover, it is often given a low priority in the requirements elicitation\nprocess. This study proposes a framework for generating ethics requirements\ndrafts by introducing an ethics advocate agent in a multi-agent LLM setting.\nThis agent critiques and provides input on ethical issues based on the system\ndescription. The proposed framework is evaluated through two case studies from\ndifferent contexts, demonstrating that it captures the majority of ethics\nrequirements identified by researchers during 30-minute interviews and\nintroduces several additional relevant requirements. However, it also\nhighlights reliability issues in generating ethics requirements, emphasizing\nthe need for human feedback in this sensitive domain. We believe this work can\nfacilitate the broader adoption of ethics in the requirements engineering\nprocess, ultimately leading to more ethically aligned products.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08392v2", "cate": "cs.AI", "date": "2025-07-11", "updated": "2025-07-18", "AI": {"title_translation": "多智能体大型语言模型作为基于人工智能系统的伦理倡导者", "tldr": "本研究提出了一种多智能体大型语言模型框架，引入伦理倡导者智能体来草拟伦理需求，以克服手动伦理需求获取的挑战。该框架在案例研究中表现良好，但存在可靠性问题，强调了人工反馈的重要性。", "motivation": "在需求获取过程中整合伦理对于创建符合伦理的系统至关重要。然而，手动获取伦理需求需要多方利益相关者的投入，受时间资源限制，且优先级较低。", "method": "本研究提出了一种多智能体大型语言模型框架，通过引入一个伦理倡导者智能体来生成伦理需求草稿。该智能体根据系统描述对伦理问题进行批判并提供输入。", "result": "该框架通过两个案例研究进行评估，结果表明它捕获了研究人员在30分钟访谈中识别出的大多数伦理需求，并引入了一些额外的相关需求。但同时也突出了生成伦理需求方面的可靠性问题。", "conclusion": "这项工作可以促进伦理在需求工程过程中的广泛采用，最终生产出更符合伦理的产品，但需要人工反馈来解决可靠性问题。", "translation": "将伦理纳入需求获取过程对于创建符合伦理的系统至关重要。尽管手动获取伦理需求是有效的，但它需要多方利益相关者的多样化输入，这可能由于时间和资源限制而具有挑战性。此外，在需求获取过程中，它通常被赋予较低的优先级。本研究提出了一种通过在多智能体大型语言模型（LLM）设置中引入伦理倡导者智能体来生成伦理需求草稿的框架。该智能体根据系统描述批判并提供伦理问题方面的输入。所提出的框架通过来自不同上下文的两个案例研究进行评估，结果表明它捕获了研究人员在30分钟访谈中识别出的大多数伦理需求，并引入了几个额外的相关需求。然而，它也突出了生成伦理需求方面的可靠性问题，强调了在该敏感领域中人工反馈的必要性。我们相信这项工作可以促进伦理在需求工程过程中的更广泛采用，最终生产出更符合伦理的产品。", "summary": "本研究提出了一种创新的多智能体大型语言模型（LLM）框架，旨在自动化伦理需求的草拟过程，以解决手动伦理需求获取面临的挑战。该框架引入了一个“伦理倡导者”智能体，负责评估系统描述并识别潜在的伦理问题。通过两个案例研究的评估表明，该框架能够有效捕捉现有伦理需求并生成新的相关需求。然而，研究也指出，在生成伦理需求时存在可靠性问题，强调了人工反馈在确保伦理准确性方面的重要性。这项工作有望推动伦理在需求工程中的整合，从而促进更符合伦理的AI系统开发。", "keywords": "多智能体LLM, 伦理倡导者, 伦理需求, 需求工程, AI伦理", "comments": "该论文的创新之处在于利用多智能体LLM来自动化伦理需求获取，这在当前AI伦理日益受重视的背景下具有重要意义。它提供了一个潜在的解决方案来克服手动伦理分析的局限性。然而，论文也坦诚地指出了该方法的局限性，即生成伦理需求时的可靠性问题，并强调了人类干预的重要性，这体现了研究的严谨性。这一发现对于未来AI在伦理领域应用的研究具有指导意义。"}}
{"id": "2503.17340", "title": "Align Your Rhythm: Generating Highly Aligned Dance Poses with Gating-Enhanced Rhythm-Aware Feature Representation", "authors": ["Congyi Fan", "Jian Guan", "Xuanjia Zhao", "Dongli Xu", "Youtian Lin", "Tong Ye", "Pengming Feng", "Haiwei Pan"], "categories": ["cs.MM", "cs.AI", "cs.CV", "cs.SD", "eess.AS"], "primary_category": "Subjects:       Multimedia (cs.MM)", "pdf_link": null, "comments": "Comments:      ICCV 2025 Accept, Project page: this https URL", "url": "http://arxiv.org/abs/2503.17340v2", "summary": "Automatically generating natural, diverse and rhythmic human dance movements\ndriven by music is vital for virtual reality and film industries. However,\ngenerating dance that naturally follows music remains a challenge, as existing\nmethods lack proper beat alignment and exhibit unnatural motion dynamics. In\nthis paper, we propose Danceba, a novel framework that leverages gating\nmechanism to enhance rhythm-aware feature representation for music-driven dance\ngeneration, which achieves highly aligned dance poses with enhanced rhythmic\nsensitivity. Specifically, we introduce Phase-Based Rhythm Extraction (PRE) to\nprecisely extract rhythmic information from musical phase data, capitalizing on\nthe intrinsic periodicity and temporal structures of music. Additionally, we\npropose Temporal-Gated Causal Attention (TGCA) to focus on global rhythmic\nfeatures, ensuring that dance movements closely follow the musical rhythm. We\nalso introduce Parallel Mamba Motion Modeling (PMMM) architecture to separately\nmodel upper and lower body motions along with musical features, thereby\nimproving the naturalness and diversity of generated dance movements. Extensive\nexperiments confirm that Danceba outperforms state-of-the-art methods,\nachieving significantly better rhythmic alignment and motion diversity. Project\npage: https://danceba.github.io/ .", "comment": "ICCV 2025 Accept, Project page: https://danceba.github.io/", "pdf_url": "http://arxiv.org/pdf/2503.17340v2", "cate": "cs.MM", "date": "2025-03-21", "updated": "2025-07-18", "AI": {"title_translation": "与你的节奏对齐：利用门控增强的节奏感知特征表示生成高度对齐的舞蹈姿态", "tldr": "Danceba是一个新的框架，通过门控机制增强节奏感知特征表示，生成与音乐高度对齐且自然的舞蹈动作，显著优于现有方法。", "motivation": "为虚拟现实和电影产业自动生成自然、多样且有节奏的音乐驱动人体舞蹈动作至关重要。然而，现有方法缺乏适当的节拍对齐，并表现出不自然的运动动态，这仍然是一个挑战。", "method": "本文提出了Danceba框架，利用门控机制增强节奏感知特征表示，以实现音乐驱动的舞蹈生成。具体包括：1. 引入基于阶段的节奏提取（PRE）来精确提取音乐相位数据中的节奏信息；2. 提出时间门控因果注意力（TGCA）以关注全局节奏特征；3. 引入并行Mamba运动建模（PMMM）架构，分别建模上半身和下半身运动以及音乐特征。", "result": "广泛的实验证实，Danceba优于现有最先进的方法，在节奏对齐和运动多样性方面取得了显著更好的表现。", "conclusion": "Danceba框架通过增强的节奏感知特征表示和创新的建模方法，成功解决了音乐驱动舞蹈生成中节拍对齐和运动自然性的挑战，并达到了最先进的性能。", "translation": "自动生成由音乐驱动的自然、多样且有节奏的人体舞蹈动作对于虚拟现实和电影行业至关重要。然而，生成自然跟随音乐的舞蹈仍然是一个挑战，因为现有方法缺乏适当的节拍对齐并表现出不自然的运动动态。在本文中，我们提出了Danceba，一个新颖的框架，它利用门控机制来增强节奏感知特征表示，用于音乐驱动的舞蹈生成，从而实现高度对齐的舞蹈姿态并增强节奏敏感性。具体来说，我们引入了基于阶段的节奏提取（PRE），以精确地从音乐相位数据中提取节奏信息，利用音乐固有的周期性和时间结构。此外，我们提出了时间门控因果注意力（TGCA），以关注全局节奏特征，确保舞蹈动作紧密跟随音乐节奏。我们还引入了并行Mamba运动建模（PMMM）架构，以分别建模上半身和下半身运动以及音乐特征，从而提高生成舞蹈动作的自然性和多样性。广泛的实验证实，Danceba优于现有最先进的方法，在节奏对齐和运动多样性方面取得了显著更好的表现。项目页面：https://danceba.github.io/。", "summary": "本文提出了Danceba框架，旨在解决音乐驱动舞蹈生成中现有方法节拍对齐不足和运动不自然的问题。Danceba通过引入基于阶段的节奏提取（PRE）、时间门控因果注意力（TGCA）和并行Mamba运动建模（PMMM）等创新组件，有效增强了节奏感知特征表示，并分别建模了身体各部分的运动。实验结果表明，Danceba在节奏对齐和运动多样性方面均显著优于现有最先进的方法，实现了高度对齐且自然的舞蹈姿态。", "keywords": "舞蹈生成, 节奏对齐, 门控机制, 音乐驱动, 运动建模", "comments": "该论文的创新点在于提出了一个结合门控机制、多层次节奏提取和并行身体部位建模的综合框架。PRE和TGCA确保了对音乐节奏的精确捕捉和全局关注，而PMMM则通过分离建模提高了动作的自然度和多样性。该方法在解决音乐与舞蹈对齐的挑战方面迈出了重要一步，对虚拟现实和电影产业具有潜在应用价值。"}}
{"id": "2506.24068", "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines", "authors": ["Ian R. McKenzie", "Oskar J. Hollinsworth", "Tom Tseng", "Xander Davies", "Stephen Casper", "Aaron D. Tucker", "Robert Kirk", "Adam Gleave"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Fixed typos (including Figure 1), amended GPU-hours rather than days, clarified ReNeLLM prompt modifications", "url": "http://arxiv.org/abs/2506.24068v2", "summary": "Frontier AI developers are relying on layers of safeguards to protect against\ncatastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus\nmodel using one such defense pipeline, and other frontier developers including\nGoogle DeepMind and OpenAI pledge to soon deploy similar defenses. However, the\nsecurity of such pipelines is unclear, with limited prior work evaluating or\nattacking these pipelines. We address this gap by developing and red-teaming an\nopen-source defense pipeline. First, we find that a novel few-shot-prompted\ninput and output classifier outperforms state-of-the-art open-weight safeguard\nmodel ShieldGemma across three attacks and two datasets, reducing the attack\nsuccess rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,\nwe introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on\nClearHarm in a black-box attack against the few-shot-prompted classifier\npipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%\nASR, providing initial evidence that it is feasible to design attacks with no\naccess to the target pipeline. We conclude by suggesting specific mitigations\nthat developers could use to thwart staged attacks.", "comment": "Fixed typos (including Figure 1), amended GPU-hours rather than days,\n  clarified ReNeLLM prompt modifications", "pdf_url": "http://arxiv.org/pdf/2506.24068v2", "cate": "cs.CL", "date": "2025-06-30", "updated": "2025-07-18", "AI": {"title_translation": "STACK：对大型语言模型安全防护管道的对抗性攻击", "tldr": "本文开发并红队测试了一个开源防御管道，发现一种新型少样本提示分类器能有效防御攻击。同时，提出了一种名为 STACK 的分阶段攻击方法，在黑盒和迁移设置下均能成功攻击防御管道，并提出了相应的缓解措施。", "motivation": "前沿人工智能开发者正依赖多层安全防护措施来防止AI系统被灾难性滥用。然而，这些安全防护管道的安全性尚不明确，且缺乏对其进行评估或攻击的现有工作。本文旨在填补这一空白。", "method": "本文首先开发并红队测试了一个开源防御管道。其次，提出了一种新颖的少样本提示输入和输出分类器，并将其与现有最先进的开源安全防护模型 ShieldGemma 进行了比较。最后，引入了一种名为 STaged AttaCK (STACK) 的分阶段攻击程序，并在黑盒和迁移设置下评估了其对少样本提示分类器管道的攻击效果。", "result": "1. 新型少样本提示输入和输出分类器在三种攻击和两个数据集上优于现有最先进的开源安全防护模型 ShieldGemma，在灾难性滥用数据集 ClearHarm 上将攻击成功率（ASR）降至0%。2. 提出的 STACK 分阶段攻击程序在针对少样本提示分类器管道的黑盒攻击中，在 ClearHarm 数据集上达到了71%的ASR。3. 在迁移设置下评估 STACK，实现了33%的ASR，初步证明了在无法访问目标管道的情况下设计攻击是可行的。", "conclusion": "本文证明了即使是最先进的防御管道也容易受到分阶段攻击，并且提出了一种新型的少样本提示分类器可以有效提高防御能力。作者建议开发者可以采用特定的缓解措施来阻止分阶段攻击。", "translation": "前沿人工智能开发者正依赖多层安全防护措施来防止人工智能系统被灾难性滥用。Anthropic 使用此类防御管道来保护其最新的 Claude 4 Opus 模型，包括 Google DeepMind 和 OpenAI 在内的其他前沿开发者也承诺很快部署类似的防御措施。然而，此类管道的安全性尚不明确，此前评估或攻击这些管道的工作有限。我们通过开发和红队测试一个开源防御管道来解决这一空白。首先，我们发现一种新颖的少样本提示输入和输出分类器在三种攻击和两个数据集上优于现有最先进的开源安全防护模型 ShieldGemma，在灾难性滥用数据集 ClearHarm 上将攻击成功率（ASR）降至0%。其次，我们引入了一种名为 STaged AttaCK (STACK) 的分阶段攻击程序，该程序在针对少样本提示分类器管道的黑盒攻击中，在 ClearHarm 上实现了71%的ASR。最后，我们还在迁移设置下评估了 STACK，实现了33%的ASR，提供了初步证据表明在无法访问目标管道的情况下设计攻击是可行的。我们最后提出了开发者可以用来阻止分阶段攻击的具体缓解措施。", "summary": "本文针对大型语言模型（LLM）安全防护管道的安全性问题，开发并红队测试了一个开源防御管道。研究发现，一种新型的少样本提示分类器在防御效果上超越了现有模型，能将攻击成功率降至0%。同时，文章提出了一种名为 STACK 的分阶段对抗性攻击方法，该方法在黑盒和迁移攻击场景下均能有效突破防御，分别达到了71%和33%的攻击成功率。研究表明，即使是最先进的防御措施也可能被绕过，并为开发者提出了抵御此类分阶段攻击的建议。", "keywords": "LLM安全, 对抗性攻击, 安全防护管道, 少样本分类器, STACK", "comments": "本文通过实际的红队测试，揭示了当前LLM安全防护管道可能存在的漏洞，具有重要的实践意义。其提出的少样本提示分类器在防御方面表现出色，为LLM安全提供了一种新的思路。同时，STACK攻击方法的提出，特别是其在黑盒和迁移设置下的成功，强调了未来LLM安全防护设计中需要考虑的复杂性和鲁棒性。文章的创新点在于结合了防御与攻击的视角，全面评估了安全防护的有效性。"}}
{"id": "2507.13737", "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13737v1", "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13737v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DailyLLM：使用多模态传感器和大型语言模型生成上下文感知的活动日志", "tldr": "DailyLLM是一个利用多模态传感器和轻量级大型语言模型，生成上下文感知活动日志的系统，它在准确性和效率上显著优于现有SOTA方法。", "motivation": "丰富的上下文感知活动日志有助于用户行为分析和健康监测，是普适计算的关键研究焦点。尽管大型语言模型（LLMs）为活动日志生成带来了新机会，但现有方法在准确性、效率和语义丰富性方面仍存在显著局限性。", "method": "DailyLLM是首个全面整合来自智能手机和智能手表常用传感器的四维上下文活动信息（位置、运动、环境、生理）的日志生成和摘要系统。它引入了一个轻量级的基于LLM的框架，结合结构化提示和高效特征提取，以实现高级活动理解。", "result": "实验证明，DailyLLM优于最先进（SOTA）的日志生成方法，并且可以高效部署在个人电脑和树莓派上。仅使用1.5B参数的LLM模型，DailyLLM在日志生成BERTScore精度方面比70B参数的SOTA基线提高了17%，同时推理速度快了近10倍。", "conclusion": "DailyLLM通过结合多模态传感器数据和轻量级LLM，在活动日志生成方面取得了显著的准确性和效率提升，超越了现有SOTA方法，并展示了其在资源受限设备上的部署潜力。", "translation": "丰富的上下文感知活动日志有助于用户行为分析和健康监测，使其成为普适计算中的一个关键研究焦点。大型语言模型（LLMs）卓越的语义理解和生成能力最近为活动日志生成创造了新的机会。然而，现有方法在准确性、效率和语义丰富性方面仍存在显著局限性。为了解决这些挑战，我们提出了DailyLLM。据我们所知，这是第一个全面整合来自智能手机和智能手表常用传感器的四维上下文活动信息（位置、运动、环境、生理）的日志生成和摘要系统。为了实现这一点，DailyLLM引入了一个轻量级的基于LLM的框架，该框架将结构化提示与高效特征提取相结合，以实现高级活动理解。广泛的实验表明，DailyLLM优于最先进（SOTA）的日志生成方法，并且可以高效部署在个人电脑和树莓派上。仅使用一个1.5B参数的LLM模型，DailyLLM在日志生成BERTScore精度方面比70B参数的SOTA基线提高了17%，同时推理速度快了近10倍。", "summary": "DailyLLM是一种新颖的活动日志生成系统，它利用智能手机和智能手表上的多模态传感器（位置、运动、环境、生理）数据，并结合轻量级大型语言模型（LLMs）的结构化提示和高效特征提取。该系统旨在克服现有日志生成方法在准确性、效率和语义丰富度方面的不足。实验结果显示，DailyLLM在日志生成精度上显著优于70B参数的SOTA模型，且推理速度快近10倍，同时能高效部署在个人电脑和树莓派等资源受限设备上。", "keywords": "活动日志生成, 上下文感知, 多模态传感器, 大型语言模型, 普适计算", "comments": "DailyLLM的创新之处在于其首次将四维上下文信息与轻量级LLM相结合，用于活动日志生成，并在资源受限设备上实现了SOTA性能。其能够以更小的模型（1.5B vs 70B）取得更优异的性能和更高的效率，这对于边缘计算和移动健康监测领域具有重要意义。该研究为未来在普适计算环境中部署高效、准确的LLM应用提供了可行路径。"}}
{"id": "2507.13704", "title": "Bayesian Optimization for Molecules Should Be Pareto-Aware", "authors": ["Anabel Yong", "Austin Tripp", "Layla Hosseini-Gerami", "Brooks Paige"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13704v1", "summary": "Multi-objective Bayesian optimization (MOBO) provides a principled framework\nfor navigating trade-offs in molecular design. However, its empirical\nadvantages over scalarized alternatives remain underexplored. We benchmark a\nsimple Pareto-based MOBO strategy -- Expected Hypervolume Improvement (EHVI) --\nagainst a simple fixed-weight scalarized baseline using Expected Improvement\n(EI), under a tightly controlled setup with identical Gaussian Process\nsurrogates and molecular representations. Across three molecular optimization\ntasks, EHVI consistently outperforms scalarized EI in terms of Pareto front\ncoverage, convergence speed, and chemical diversity. While scalarization\nencompasses flexible variants -- including random or adaptive schemes -- our\nresults show that even strong deterministic instantiations can underperform in\nlow-data regimes. These findings offer concrete evidence for the practical\nadvantages of Pareto-aware acquisition in de novo molecular optimization,\nespecially when evaluation budgets are limited and trade-offs are nontrivial.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13704v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "分子贝叶斯优化应具备帕累托感知能力", "tldr": "本研究表明，在分子设计中，帕累托感知的多目标贝叶斯优化（如EHVI）在帕累托前沿覆盖、收敛速度和化学多样性方面，持续优于标量化贝叶斯优化（如EI），尤其是在数据量有限的情况下。", "motivation": "多目标贝叶斯优化（MOBO）为分子设计中的权衡提供了原则性框架，但其相对于标量化替代方案的经验优势尚未得到充分探索。", "method": "本研究在一个严格控制的设置中，使用相同的高斯过程代理和分子表示，将一种简单的基于帕累托的MOBO策略——预期超体积改进（EHVI）——与一种简单的固定权重标量化基线（使用预期改进（EI））进行了基准测试。", "result": "在三项分子优化任务中，EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面始终优于标量化EI。结果表明，即使是强大的确定性标量化实例，在低数据量情况下也可能表现不佳。", "conclusion": "这些发现为从头分子优化中帕累托感知采集的实际优势提供了具体证据，尤其是在评估预算有限且权衡取舍并非微不足道的情况下。", "translation": "多目标贝叶斯优化（MOBO）为分子设计中的权衡提供了原则性框架。然而，其相对于标量化替代方案的经验优势仍未得到充分探索。我们在一个严格控制的设置中，使用相同的高斯过程代理和分子表示，将一种简单的基于帕累托的MOBO策略——预期超体积改进（EHVI）——与一种简单的固定权重标量化基线（使用预期改进（EI））进行了基准测试。在三项分子优化任务中，EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面始终优于标量化EI。尽管标量化包含灵活的变体——包括随机或自适应方案——但我们的结果表明，即使是强大的确定性实例在低数据量情况下也可能表现不佳。这些发现为从头分子优化中帕累托感知采集的实际优势提供了具体证据，尤其是在评估预算有限且权衡取舍并非微不足道的情况下。", "summary": "本研究通过基准测试，探讨了多目标贝叶斯优化（MOBO）相对于标量化方法的经验优势。结果表明，在分子设计任务中，帕累托感知的EHVI在帕累托前沿覆盖、收敛速度和化学多样性方面持续优于标量化EI，尤其是在数据有限的情况下，这为帕累托感知采集在从头分子优化中的实际应用提供了有力支持。", "keywords": "贝叶斯优化, 多目标优化, 分子设计, 帕累托前沿, EHVI", "comments": "这项研究通过严格的实验设置，为帕累托感知的多目标贝叶斯优化在分子设计领域的实际优势提供了 concrete evidence，尤其强调了其在数据稀缺和复杂权衡情境下的重要性，具有较高的实践指导意义。"}}
{"id": "2507.13678", "title": "Minimum Clustering of Matrices Based on Phase Alignment", "authors": ["Honghao Wu", "Kemi Ding", "Li Qiu"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This work has been received by CDC2025", "url": "http://arxiv.org/abs/2507.13678v1", "summary": "Coordinating multi-agent systems requires balancing synchronization\nperformance and controller implementation costs. To this end, we classify\nagents by their intrinsic properties, enabling each group to be controlled by a\nuniform controller and thus reducing the number of unique controller types\nrequired. Existing centralized control methods, despite their capability to\nachieve high synchronization performance with fewer types of controllers,\nsuffer from critical drawbacks such as limited scalability and vulnerability to\nsingle points of failure. On the other hand, distributed control strategies,\nwhere controllers are typically agent-dependent, result in the type of required\ncontrollers increasing proportionally with the size of the system.\n  This paper introduces a novel phase-alignment-based framework to minimize the\ntype of controllers by strategically clustering agents with aligned\nsynchronization behaviors. Leveraging the intrinsic phase properties of complex\nmatrices, we formulate a constrained clustering problem and propose a\nhierarchical optimization method combining recursive exact searches for\nsmall-scale systems and scalable stochastic approximations for large-scale\nnetworks. This work bridges theoretical phase analysis with practical control\nsynthesis, offering a cost-effective solution for large-scale multi-agent\nsystems. The theoretical results applied for the analysis of a 50-agent network\nillustrate the effectiveness of the proposed algorithms.", "comment": "This work has been received by CDC2025", "pdf_url": "http://arxiv.org/pdf/2507.13678v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于相位对齐的矩阵最小聚类", "tldr": "本文提出了一种基于相位对齐的新型框架，通过策略性地聚类具有对齐同步行为的智能体，以最小化多智能体系统中所需控制器类型的数量。该方法结合了递归精确搜索和可扩展的随机近似，实现了成本效益高的解决方案。", "motivation": "协调多智能体系统需要平衡同步性能和控制器实现成本。现有集中式控制方法存在可伸缩性有限和单点故障的缺点，而分布式控制策略则导致所需控制器类型随系统规模线性增加。本文旨在通过分类智能体来减少所需控制器类型的数量。", "method": "本文引入了一种新颖的基于相位对齐的框架，通过策略性地聚类具有对齐同步行为的智能体来最小化控制器类型。该方法利用复杂矩阵的内在相位特性，构建了一个约束聚类问题，并提出了一种分层优化方法，结合了针对小规模系统的递归精确搜索和针对大规模网络的可扩展随机近似。", "result": "理论结果应用于一个50个智能体网络的分析，说明了所提出算法的有效性。", "conclusion": "这项工作将理论相位分析与实际控制综合相结合，为大规模多智能体系统提供了一种成本效益高的解决方案。", "translation": "协调多智能体系统需要平衡同步性能和控制器实现成本。为此，我们根据智能体的内在特性对其进行分类，使每个组都可以由统一的控制器控制，从而减少所需独特控制器类型的数量。现有集中式控制方法尽管能够以较少类型的控制器实现高同步性能，但存在可伸缩性有限和易受单点故障影响等关键缺点。另一方面，分布式控制策略（其中控制器通常依赖于智能体）导致所需控制器类型随系统规模成比例增加。\n本文引入了一种新颖的基于相位对齐的框架，通过策略性地聚类具有对齐同步行为的智能体来最小化控制器类型。利用复杂矩阵的内在相位特性，我们提出了一个约束聚类问题，并提出了一种分层优化方法，结合了针对小规模系统的递归精确搜索和针对大规模网络的可扩展随机近似。这项工作将理论相位分析与实际控制综合相结合，为大规模多智能体系统提供了一种成本效益高的解决方案。应用于一个50个智能体网络分析的理论结果说明了所提出算法的有效性。", "summary": "本文提出了一种基于相位对齐的新型框架，旨在通过对具有相似同步行为的智能体进行聚类，从而最小化多智能体系统中所需控制器类型的数量。该方法解决了现有集中式和分布式控制策略在可伸缩性和控制器成本方面的局限性。通过利用复杂矩阵的相位特性，作者构建了一个约束聚类问题，并开发了一种分层优化算法，该算法结合了针对小规模系统的精确搜索和针对大规模网络的随机近似。该研究为大规模多智能体系统提供了一种成本效益高的解决方案，并通过50个智能体网络的分析验证了其有效性。", "keywords": "多智能体系统, 相位对齐, 聚类, 控制器综合, 分层优化", "comments": "本文的创新点在于提出了一个基于相位对齐的聚类框架，以解决多智能体系统中控制器类型最小化的问题。通过将理论相位分析与实际控制综合相结合，并引入分层优化方法来处理不同规模的系统，该研究为大规模多智能体系统的控制器设计提供了实用的、成本效益高的解决方案，具有重要的应用价值。"}}
{"id": "2507.13544", "title": "A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows", "authors": ["Mohamed Achref Ben Ammar", "Mohamed Taha Bennani"], "categories": ["cs.CL", "68T50, 05C85, 68T05, 68R10", "I.2.7; I.2.4; H.3.3; I.5.0"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13544v1", "summary": "The analysis of conversational dynamics has gained increasing importance with\nthe rise of large language model-based systems, which interact with users\nacross diverse contexts. In this work, we propose a novel computational\nframework for constructing conversational graphs that capture the flow and\nstructure of loosely organized dialogues, referred to as quasi-patterned\nconversations. We introduce the Filter & Reconnect method, a novel graph\nsimplification technique that minimizes noise while preserving semantic\ncoherence and structural integrity of conversational graphs. Through\ncomparative analysis, we demonstrate that the use of large language models\ncombined with our graph simplification technique has resulted in semantic\nmetric S increasing by a factor of 2.06 compared to previous approaches while\nsimultaneously enforcing a tree-like structure with 0 {\\delta}-hyperbolicity,\nensuring optimal clarity in conversation modeling. This work provides a\ncomputational method for analyzing large-scale dialogue datasets, with\npractical applications related to monitoring automated systems such as\nchatbots, dialogue management tools, and user behavior analytics.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13544v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "对话系统建模的计算方法：分析大规模准模式对话流", "tldr": "提出一种新的计算框架和图简化技术（Filter & Reconnect）来建模大规模准模式对话流，结合LLMs显著提高了语义度量并保持了清晰的树状结构，应用于聊天机器人和对话管理。", "motivation": "随着大型语言模型系统的兴起，对话动态分析变得越来越重要，因为它们与不同背景下的用户进行交互。", "method": "提出了一种构建对话图的计算框架，用于捕获松散组织对话（准模式对话）的流和结构。引入了“Filter & Reconnect”方法，这是一种新颖的图简化技术，旨在最小化噪声，同时保留对话图的语义连贯性和结构完整性。", "result": "结合大型语言模型和图简化技术，语义度量S比以前的方法增加了2.06倍，同时强制执行了具有0 {\\delta}-双曲性的树状结构，确保了对话建模的最佳清晰度。", "conclusion": "本工作提供了一种分析大规模对话数据集的计算方法，具有监测自动化系统（如聊天机器人、对话管理工具和用户行为分析）的实际应用。", "translation": "随着大型语言模型系统的兴起，对话动态分析变得越来越重要，这些系统在不同背景下与用户交互。在这项工作中，我们提出了一种新颖的计算框架，用于构建对话图，以捕获松散组织对话（称为准模式对话）的流和结构。我们引入了“Filter & Reconnect”方法，这是一种新颖的图简化技术，旨在最小化噪声，同时保留对话图的语义连贯性和结构完整性。通过比较分析，我们证明，与以前的方法相比，结合大型语言模型和我们的图简化技术，语义度量S增加了2.06倍，同时强制执行了具有0 {\\delta}-双曲性的树状结构，确保了对话建模的最佳清晰度。这项工作提供了一种分析大规模对话数据集的计算方法，具有监测自动化系统（如聊天机器人、对话管理工具和用户行为分析）的实际应用。", "summary": "本文提出了一种新颖的计算框架，用于构建和简化大规模准模式对话的图表示。通过引入Filter & Reconnect图简化技术，该方法在结合大型语言模型时，显著提升了对话建模的语义准确性（S度量增加2.06倍），并确保了对话结构的清晰度（0 {\\delta}-双曲性树状结构）。该研究为分析大型对话数据集提供了一种有效的计算方法，并可应用于聊天机器人、对话管理和用户行为分析等领域。", "keywords": "对话系统, 计算方法, 对话图, 图简化, 大型语言模型", "comments": "这篇论文的创新点在于提出了一个结合大型语言模型和图简化技术（Filter & Reconnect）的计算框架，用于有效建模和分析大规模的“准模式”对话流。其重要性体现在它为理解和优化基于LLM的对话系统提供了新的工具，特别是在处理复杂、非结构化对话方面。通过量化结果（语义度量S提升2.06倍，0 {\\delta}-双曲性树状结构），论文证明了其方法的有效性，为自动化系统监控和用户行为分析提供了实用价值。"}}
{"id": "2507.10739", "title": "Quantum Wave Atom Transforms", "authors": ["Marianna Podzorova", "Yi-Kai Liu"], "categories": ["quant-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Quantum Physics (quant-ph)", "pdf_link": null, "comments": "Comments:      45 pages, 12 figures", "url": "http://arxiv.org/abs/2507.10739v1", "summary": "This paper constructs the first quantum algorithm for wavelet packet\ntransforms with a tree structure, sometimes called wave atom transforms.\nClassically, wave atoms are used to construct sparse representations of\ndifferential operators, which enable fast numerical algorithms for partial\ndifferential equations. Compared to previous work, our quantum algorithm can\nimplement a larger class of wavelet and wave atom transforms, by using an\nefficient representation for a larger class of possible tree structures. Our\nquantum implementation has $O(\\mathrm{poly}(n))$ gate complexity for the\ntransform of dimension $2^n$, while classical implementations have $O(n 2^n)$\nfloating point operations. The result can be used to improve existing quantum\nalgorithms for solving hyperbolic partial differential equations.", "comment": "45 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.10739v1", "cate": "quant-ph", "date": "2025-07-14", "updated": "2025-07-14", "AI": {"title_translation": "量子波原子变换", "tldr": "提出了首个用于树状小波包变换（波原子变换）的量子算法，其复杂度远低于经典算法，并可用于改进量子偏微分方程算法。", "motivation": "经典波原子变换能为微分算子构建稀疏表示，从而实现偏微分方程的快速数值算法。本文旨在开发量子算法以利用量子计算的优势。", "method": "构建了首个用于具有树状结构的小波包变换（波原子变换）的量子算法。通过使用更高效的表示方法，该算法能实现更大范围的小波和波原子变换。", "result": "该量子实现对于维度为 $2^n$ 的变换具有 $O(\\\\mathrm{poly}(n))$ 的门复杂度，而经典实现则需要 $O(n 2^n)$ 浮点运算。", "conclusion": "所提出的量子波原子变换算法可以用于改进现有求解双曲型偏微分方程的量子算法。", "translation": "本文构建了首个用于具有树状结构的小波包变换（有时称为波原子变换）的量子算法。在经典情况下，波原子用于构建微分算子的稀疏表示，从而实现偏微分方程的快速数值算法。与之前的工作相比，我们的量子算法通过对更大类别的可能树结构使用高效表示，可以实现更大类别的小波和波原子变换。我们的量子实现在维度为 $2^n$ 的变换中具有 $O(\\\\mathrm{poly}(n))$ 的门复杂度，而经典实现则需要 $O(n 2^n)$ 浮点运算。该结果可用于改进现有求解双曲型偏微分方程的量子算法。", "summary": "本文首次提出了一个用于树状小波包变换（即波原子变换）的量子算法。该算法能够处理更广泛的变换类型，并且在复杂度上显著优于经典算法，其门复杂度为 $O(\\\\mathrm{poly}(n))$，而经典算法为 $O(n 2^n)$。该成果有望提升现有求解双曲型偏微分方程的量子算法的性能。", "keywords": "量子算法, 波原子变换, 小波包变换, 复杂度, 偏微分方程", "comments": "这项工作具有重要创新性，因为它首次将量子计算应用于波原子变换，并展示了在计算复杂度上的巨大优势。这为利用量子算法解决偏微分方程提供了新的途径和工具，可能对量子数值分析领域产生深远影响。"}}
{"id": "2507.13399", "title": "Selective Embedding for Deep Learning", "authors": ["Mert Sehri", "Zehui Hua", "Francisco de Assis Boldt", "Patrick Dumond"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13399v1", "summary": "Deep learning has revolutionized many industries by enabling models to\nautomatically learn complex patterns from raw data, reducing dependence on\nmanual feature engineering. However, deep learning algorithms are sensitive to\ninput data, and performance often deteriorates under nonstationary conditions\nand across dissimilar domains, especially when using time-domain data.\nConventional single-channel or parallel multi-source data loading strategies\neither limit generalization or increase computational costs. This study\nintroduces selective embedding, a novel data loading strategy, which alternates\nshort segments of data from multiple sources within a single input channel.\nDrawing inspiration from cognitive psychology, selective embedding mimics\nhuman-like information processing to reduce model overfitting, enhance\ngeneralization, and improve computational efficiency. Validation is conducted\nusing six time-domain datasets, demonstrating that the proposed method\nconsistently achieves high classification accuracy across various deep learning\narchitectures while significantly reducing training times. The approach proves\nparticularly effective for complex systems with multiple data sources, offering\na scalable and resource-efficient solution for real-world applications in\nhealthcare, heavy machinery, marine, railway, and agriculture, where robustness\nand adaptability are critical.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13399v1", "cate": "cs.LG", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "深度学习的选择性嵌入", "tldr": "提出一种选择性嵌入的数据加载策略，通过交替多源数据段来提高深度学习模型的泛化能力和计算效率，尤其适用于时域数据。", "motivation": "深度学习算法对输入数据敏感，在非平稳条件和不同领域下性能下降，尤其时域数据。传统的单通道或并行多源数据加载策略限制泛化或增加计算成本。", "method": "引入选择性嵌入（selective embedding），一种新的数据加载策略，在一个单一输入通道内交替使用来自多个来源的短数据段。灵感来源于认知心理学，模仿人类信息处理，以减少模型过拟合，增强泛化能力，提高计算效率。", "result": "使用六个时域数据集进行验证，表明所提出的方法在各种深度学习架构中始终保持高分类精度，并显著缩短训练时间。", "conclusion": "该方法对具有多个数据源的复杂系统特别有效，为医疗、重型机械、海洋、铁路和农业等实际应用提供了可扩展且资源高效的解决方案，其中鲁棒性和适应性至关重要。", "translation": "深度学习通过使模型能够自动从原始数据中学习复杂模式，减少对手动特征工程的依赖，从而彻底改变了许多行业。然而，深度学习算法对输入数据敏感，在非平稳条件和不同领域下，尤其在使用时域数据时，性能通常会下降。传统的单通道或并行多源数据加载策略要么限制泛化能力，要么增加计算成本。本研究引入了选择性嵌入，一种新颖的数据加载策略，它在单个输入通道内交替使用来自多个源的短数据段。选择性嵌入从认知心理学中汲取灵感，模仿人类的信息处理方式，以减少模型过拟合，增强泛化能力，并提高计算效率。通过使用六个时域数据集进行验证，结果表明所提出的方法在各种深度学习架构中始终保持高分类精度，同时显著缩短了训练时间。该方法被证明对具有多个数据源的复杂系统特别有效，为医疗、重型机械、海洋、铁路和农业等实际应用提供了可扩展且资源高效的解决方案，在这些领域中，鲁棒性和适应性至关重要。", "summary": "本文提出了一种名为“选择性嵌入”的新型深度学习数据加载策略。该策略通过在单一输入通道中交替使用来自多个源的短数据段，模拟人类信息处理，旨在解决深度学习在非平稳和跨领域数据下泛化能力差及计算成本高的问题。实验证明，该方法能有效提高各种深度学习架构的分类精度并缩短训练时间，尤其适用于多源复杂系统，为多个行业提供了鲁棒且高效的解决方案。", "keywords": "选择性嵌入, 深度学习, 数据加载, 时域数据, 泛化能力", "comments": "这篇论文的创新点在于提出了“选择性嵌入”这一数据加载策略，它借鉴了认知心理学原理，通过交替多源数据来提高深度学习模型的泛化能力和计算效率，有效解决了传统方法的局限性。其重要性体现在为处理时域多源数据提供了新的范式，并具有广泛的实际应用潜力。"}}
{"id": "2507.12377", "title": "Deconstructing Implicit Beliefs in Visual Data Journalism: Unstable Meanings Behind Data as Truth & Design for Insight", "authors": ["Ke Er Amy Zhang", "Jodie Jenkinson", "Laura Garrison"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "url": "http://arxiv.org/abs/2507.12377v3", "summary": "We conduct a deconstructive reading of a qualitative interview study with 17\nvisual data journalists from newsrooms across the globe. We borrow a\ndeconstruction approach from literary critique to explore the instability of\nmeaning in language and reveal implicit beliefs in words and ideas. Through our\nanalysis we surface two sets of opposing implicit beliefs in visual data\njournalism: objectivity/subjectivity and humanism/mechanism. We contextualize\nthese beliefs through a genealogical analysis, which brings deconstruction\ntheory into practice by providing a historic backdrop for these opposing\nperspectives. Our analysis shows that these beliefs held within visual data\njournalism are not self-enclosed but rather a product of external societal\nforces and paradigm shifts over time. Through this work, we demonstrate how\nthinking with critical theories such as deconstruction and genealogy can\nreframe \"success\" in visual data storytelling and diversify visualization\nresearch outcomes. These efforts push the ways in which we as researchers\nproduce domain knowledge to examine the sociotechnical issues of today's values\ntowards datafication and data visualization. All supplemental materials for\nthis work are available at osf.io/5fr48.", "comment": "11 pages, 5 figures, accepted to IEEE VIS 2025 Conference", "pdf_url": "http://arxiv.org/pdf/2507.12377v3", "cate": "cs.HC", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "解构视觉数据新闻中的隐含信念：数据即真理背后不稳定性的意义与洞察力设计", "tldr": "本文通过对17位视觉数据记者进行定性访谈研究，运用解构主义和谱系分析方法，揭示了视觉数据新闻中客观性/主观性和人文主义/机械主义两对对立的隐含信念，并指出这些信念是社会力量和范式转变的产物，强调批判性理论可重塑数据故事叙述的“成功”并丰富可视化研究。", "motivation": "探索语言意义的不稳定性，揭示视觉数据新闻中隐含的信念，并通过批判性理论（如解构主义和谱系分析）重新定义视觉数据故事讲述的“成功”并使可视化研究成果多样化，从而审视当前对数据化和数据可视化的价值观。", "method": "对来自全球新闻编辑室的17位视觉数据记者进行了定性访谈研究。采用了文学批评中的解构主义方法来探索语言意义的不稳定性并揭示隐含信念。通过谱系分析法，将解构理论付诸实践，为对立的观点提供了历史背景。", "result": "分析揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性和人文主义/机械主义。这些信念并非独立存在，而是外部社会力量和范式转变的产物。", "conclusion": "本研究展示了如何运用批判性理论（如解构主义和谱系分析）来重新定义视觉数据故事讲述中的“成功”，并使可视化研究成果多样化。这些努力推动了研究人员生产领域知识的方式，以审视当今对数据化和数据可视化的价值观所涉及的社会技术问题。", "translation": "我们对全球新闻编辑室的17位视觉数据记者进行了一项定性访谈研究，并对其进行了解构式解读。我们借鉴文学批评中的解构方法，探索语言意义的不稳定性，揭示词语和思想中的隐含信念。通过分析，我们揭示了视觉数据新闻中两组对立的隐含信念：客观性/主观性和人文主义/机械主义。我们通过谱系分析对这些信念进行了语境化，该分析通过为这些对立观点提供历史背景，将解构理论付诸实践。我们的分析表明，视觉数据新闻中持有的这些信念并非独立存在，而是外部社会力量和随时间推移的范式转变的产物。通过这项工作，我们展示了批判性理论（如解构主义和谱系分析）如何能够重新定义视觉数据故事讲述中的“成功”，并使可视化研究成果多样化。这些努力推动了我们作为研究人员生产领域知识的方式，以审视当今对数据化和数据可视化价值观的社会技术问题。所有补充材料均可在osf.io/5fr48获取。", "summary": "本研究对17位视觉数据记者进行了定性访谈，并运用文学批评中的解构主义和谱系分析方法，深入探讨了视觉数据新闻中隐含信念的不稳定性。研究揭示了客观性/主观性和人文主义/机械主义两对核心对立信念，并指出这些信念深受外部社会力量和历史范式转变的影响。通过将批判性理论应用于数据新闻领域，本文旨在重新定义数据故事讲述的成功标准，并丰富可视化研究的范畴，从而促进对数据化价值观的社会技术审视。", "keywords": "视觉数据新闻, 隐含信念, 解构主义, 谱系分析, 数据化", "comments": "本文的创新之处在于将文学批评中的解构主义和谱系分析方法引入到视觉数据新闻研究中，这提供了一个独特的视角来审视数据作为“真理”背后的深层信念和其意义的不稳定性。通过揭示客观性/主观性和人文主义/机械主义的对立，该研究深刻地指出数据新闻实践并非孤立的技术活动，而是社会、文化和历史力量的产物。这对于理解数据新闻的复杂性及其对社会的影响具有重要意义，并为未来可视化研究提供了新的批判性思考框架。"}}
{"id": "2507.13520", "title": "Passive Body-Area Electrostatic Field (Human Body Capacitance) for Ubiquitous Computing", "authors": ["Sizhen Bian", "Mengxi Liu", "Paul Lukowicz"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13520v1", "summary": "Passive body-area electrostatic field sensing, also referred to as human body\ncapacitance (HBC), is an energy-efficient and non-intrusive sensing modality\nthat exploits the human body's inherent electrostatic properties to perceive\nhuman behaviors. This paper presents a focused overview of passive HBC sensing,\nincluding its underlying principles, historical evolution, hardware\narchitectures, and applications across research domains. Key challenges, such\nas susceptibility to environmental variation, are discussed to trigger\nmitigation techniques. Future research opportunities in sensor fusion and\nhardware enhancement are highlighted. To support continued innovation, this\nwork provides open-source resources and aims to empower researchers and\ndevelopers to leverage passive electrostatic sensing for next-generation\nwearable and ambient intelligence systems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13520v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于普适计算的被动式人体区域静电场（人体电容）", "tldr": "该论文对被动式人体区域静电场（人体电容）传感技术进行了全面概述，包括其原理、硬件、应用、挑战和未来机遇，并提供开源资源以促进创新。", "motivation": "论文旨在提供被动式人体区域静电场（人体电容，HBC）传感技术的集中概述，该技术是一种节能且非侵入性的感知方式，利用人体固有的静电特性来感知人类行为。通过讨论关键挑战并突出未来研究机会，旨在支持持续创新。", "method": "本文对被动式HBC传感进行了集中概述，包括其基本原理、历史演变、硬件架构和跨研究领域的应用。同时讨论了关键挑战（如对环境变化的敏感性）以激发缓解技术，并强调了传感器融合和硬件增强方面的未来研究机会。为支持持续创新，本文提供了开源资源。", "result": "本文提供了一个关于被动式HBC传感的全面概述，涵盖了其原理、历史、硬件和应用，并识别了主要挑战和未来的研究机遇。它还提供了开源资源以促进该领域的进一步发展。", "conclusion": "论文旨在通过提供对被动式HBC传感的全面概述、讨论挑战和未来机会，并提供开源资源，来支持该领域的持续创新，赋能研究人员和开发者利用静电传感技术开发下一代可穿戴和环境智能系统。", "translation": "被动式人体区域静电场传感，也称为人体电容（HBC），是一种节能且非侵入性的传感方式，它利用人体的固有静电特性来感知人类行为。本文对被动式HBC传感进行了集中概述，包括其基本原理、历史演变、硬件架构以及在各个研究领域的应用。文中讨论了关键挑战，例如对环境变化的敏感性，以期引发缓解技术的研究。同时强调了传感器融合和硬件增强方面的未来研究机会。为了支持持续创新，本文提供了开源资源，旨在赋能研究人员和开发者利用被动式静电传感技术开发下一代可穿戴和环境智能系统。", "summary": "本文对被动式人体区域静电场（人体电容，HBC）传感技术进行了全面回顾，该技术利用人体静电感知人类行为，具有节能和非侵入性特点。论文详细阐述了HBC的原理、历史、硬件和应用，并探讨了环境变异性等主要挑战及传感器融合、硬件增强等未来研究方向。为促进该领域发展，论文还提供了开源资源，以期推动下一代可穿戴和环境智能系统的发展。", "keywords": "人体电容, 静电场传感, 普适计算, 穿戴式设备, 传感技术", "comments": "这篇论文的创新之处在于其作为一篇全面的综述性文章，系统地梳理了被动式人体电容传感技术的各个方面，包括原理、发展、硬件和应用，并明确指出了当前面临的挑战和未来的研究方向。其提供开源资源的举措，对于促进该领域的进一步研究和应用具有重要意义，有助于加速下一代普适计算设备的发展。"}}
{"id": "2507.13994", "title": "Optimal antimatroid sorting", "authors": ["Benjamin Aram Berendsohn"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "Comments:      Accepted to ESA 2025", "url": "http://arxiv.org/abs/2507.13994v1", "summary": "The classical comparison-based sorting problem asks us to find the underlying\ntotal order of a given set of elements, where we can only access the elements\nvia comparisons. In this paper, we study a restricted version, where, as a\nhint, a set $T$ of possible total orders is given, usually in some compressed\nform.\n  Recently, an algorithm called topological heapsort with optimal running time\nwas found for the case where $T$ is the set of topological orderings of a given\ndirected acyclic graph, or, equivalently, $T$ is the set of linear extensions\nof a given partial order [Haeupler et al. 2024]. We show that a simple\ngeneralization of topological heapsort is applicable to a much broader class of\nrestricted sorting problems, where $T$ corresponds to a given antimatroid.\n  As a consequence, we obtain optimal algorithms for the following restricted\nsorting problems, where the allowed total orders are restricted by: a given set\nof monotone precedence formulas; the perfect elimination orders of a given\nchordal graph; or the possible vertex search orders of a given connected rooted\ngraph.", "comment": "Accepted to ESA 2025", "pdf_url": "http://arxiv.org/pdf/2507.13994v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "最优反拟阵排序", "tldr": "本文研究了一种受限的比较排序问题，其中给出了可能的总顺序集合T作为提示。作者展示了拓扑堆排序的简单推广适用于更广泛的受限排序问题，即当T对应于给定反拟阵时，并为几种受限排序问题提供了最优算法。", "motivation": "经典的基于比较的排序问题旨在找到给定元素集的底层全序。本文研究了一个受限版本，其中提供了一组可能的总顺序T作为提示，通常以某种压缩形式给出。此前的研究在T是给定有向无环图的拓扑排序集或偏序的线性扩展集时，找到了最优运行时间的算法，本文旨在将此方法推广到更广泛的受限排序问题。", "method": "本文展示了拓扑堆排序（topological heapsort）的一种简单推广形式，可以应用于更广泛的受限排序问题。这种推广适用于T对应于给定反拟阵（antimatroid）的情况。", "result": "作为推广的结果，本文为以下受限排序问题获得了最优算法：1. 由给定单调优先公式限制的总顺序；2. 给定弦图的完美消除顺序；3. 给定连通有根图的可能顶点搜索顺序。", "conclusion": "拓扑堆排序的简单推广适用于更广泛的受限排序问题，即当可能的总顺序集合T对应于给定反拟阵时，并能为多种特定的受限排序问题提供最优算法。", "translation": "经典基于比较的排序问题要求我们找到给定元素集的底层全序，其中我们只能通过比较来访问元素。在本文中，我们研究了一个受限版本，其中，作为提示，给出了一组可能的总顺序T，通常以某种压缩形式。最近，针对T是给定有向无环图的拓扑排序集，或者等价地，T是给定偏序的线性扩展集的情况，找到了一种运行时间最优的算法，称为拓扑堆排序[Haeupler et al. 2024]。我们表明，拓扑堆排序的一个简单推广适用于更广泛的受限排序问题，其中T对应于给定的反拟阵。因此，我们为以下受限排序问题获得了最优算法，其中允许的总顺序受到以下限制：给定一组单调优先公式；给定弦图的完美消除顺序；或给定连通有根图的可能顶点搜索顺序。", "summary": "本文研究了受限的比较排序问题，其中预先给出了一个可能的总顺序集合T。作者发现，最近提出的拓扑堆排序算法可以简单地推广到T对应于给定反拟阵的更广泛情况。这一推广使得能够为多种受限排序问题（如受单调优先公式、弦图的完美消除顺序或连通有根图的顶点搜索顺序限制的排序）提供最优算法。", "keywords": "反拟阵排序, 受限排序, 拓扑堆排序, 最优算法, 组合优化", "comments": "本文的创新之处在于将拓扑堆排序推广到反拟阵这一更普遍的结构上，从而为一系列重要的受限排序问题提供了统一且最优的解决方案。这不仅拓展了拓扑排序的应用范围，也为未来在其他组合结构上的排序问题研究提供了新的视角。其重要性在于解决了多个具体且具有挑战性的排序问题，并达到了理论最优性。"}}
{"id": "2506.23491", "title": "ZonUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding", "authors": ["ZongHan Hsieh", "Tzer-Jen Wei", "ShengJing Yang"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.23491v3", "summary": "In this paper, we present ZonUI-3B, a lightweight Vision-Language Model (VLM)\nthat can be fully trained on a single consumer-grade GPU (RTX 4090) while\ndelivering performance comparable to significantly larger models on GUI\ngrounding tasks. The model incorporates several key innovations: (i) combine\ncross-platform, multi-resolution dataset of 24K examples from diverse sources\nincluding mobile, desktop, and web GUI screenshots to effectively address data\nscarcity in high-resolution desktop environments; (ii) a two-stage fine-tuning\nstrategy, where initial cross-platform training establishes robust GUI\nunderstanding, followed by specialized fine-tuning on high-resolution data to\nsignificantly enhance model adaptability; and (iii) data curation and\nredundancy reduction strategies, demonstrating that randomly sampling a smaller\nsubset with reduced redundancy achieves performance comparable to larger\ndatasets, emphasizing data diversity over sheer volume. Empirical evaluation on\nstandard GUI grounding benchmarks, including ScreenSpot, ScreenSpot-v2, and the\nchallenging ScreenSpot-Pro, highlights ZonUI-3B's exceptional accuracy,\nachieving 84.9% on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior\nmodels under 4B parameters. Ablation studies validate the critical role of\nbalanced sampling and two-stage fine-tuning in enhancing robustness,\nparticularly in high-resolution desktop scenarios. The ZonUI-3B is available\nat: https://github.com/Han1018/ZonUI-3B", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.23491v3", "cate": "cs.CV", "date": "2025-06-30", "updated": "2025-07-18", "AI": {"title_translation": "ZonUI-3B：一个用于跨分辨率GUI定位的轻量级视觉-语言模型", "tldr": "ZonUI-3B是一个轻量级视觉-语言模型（VLM），它能在单个消费级GPU上训练，并在GUI定位任务上表现出色，通过创新的多分辨率数据集构建和两阶段微调策略，解决了高分辨率数据稀缺问题并实现了高精度。", "motivation": "现有的GUI定位模型通常参数量大，训练成本高昂，且在高分辨率桌面环境面临数据稀缺的挑战。本文旨在开发一个轻量级、高效且能在消费级硬件上训练，同时保持高性能的解决方案，以解决这些限制。", "method": "本文提出了ZonUI-3B，一个轻量级视觉-语言模型。其方法包括：(i) 构建了一个包含2.4万个来自移动、桌面和Web GUI截图的跨平台、多分辨率数据集，以有效解决高分辨率桌面环境中的数据稀缺问题；(ii) 采用两阶段微调策略，首先进行跨平台训练以建立稳健的GUI理解能力，随后对高分辨率数据进行专业微调以显著增强模型适应性；(iii) 实施数据整理和冗余减少策略，证明通过随机采样一个较小的、冗余减少的子集可以达到与大型数据集相当的性能，强调数据多样性而非纯粹数量的重要性。", "result": "ZonUI-3B在标准GUI定位基准测试（包括ScreenSpot、ScreenSpot-v2和具有挑战性的ScreenSpot-Pro）上表现出卓越的准确性，在ScreenSpot上达到84.9%，在ScreenSpot-v2上达到86.4%，超越了参数量低于4B的所有现有模型。消融研究进一步验证了平衡采样和两阶段微调在增强模型鲁棒性，特别是在高分辨率桌面场景中的关键作用。", "conclusion": "ZonUI-3B证明了通过创新的数据策略（如多分辨率数据集和冗余减少）和训练方法（如两阶段微调），可以在资源有限（单块消费级GPU）的情况下训练出高性能的视觉-语言模型，并在跨分辨率GUI定位任务上取得领先结果，尤其是在处理高分辨率桌面环境时表现出色。", "translation": "在本文中，我们提出了ZonUI-3B，一个轻量级视觉-语言模型（VLM），它可以在单个消费级GPU（RTX 4090）上完全训练，同时在GUI定位任务上提供与显著更大的模型相当的性能。该模型融合了多项关键创新：(i) 结合了来自移动、桌面和Web GUI截图等多种来源的2.4万个跨平台、多分辨率数据集，有效解决了高分辨率桌面环境中的数据稀缺问题；(ii) 采用两阶段微调策略，其中初始的跨平台训练建立了稳健的GUI理解能力，随后对高分辨率数据进行专业微调，显著增强了模型适应性；(iii) 数据整理和冗余减少策略，表明随机采样一个较小的、冗余减少的子集可以达到与大型数据集相当的性能，强调了数据多样性而非纯粹的数量。在标准GUI定位基准测试，包括ScreenSpot、ScreenSpot-v2和具有挑战性的ScreenSpot-Pro上的实证评估，突出了ZonUI-3B卓越的准确性，在ScreenSpot上达到84.9%，在ScreenSpot-v2上达到86.4%，超越了参数量低于4B的现有模型。消融研究验证了平衡采样和两阶段微调在增强鲁棒性，特别是在高分辨率桌面场景中的关键作用。ZonUI-3B可在以下链接获取：https://github.com/Han1018/ZonUI-3B", "summary": "ZonUI-3B是一个轻量级视觉-语言模型，专为跨分辨率GUI定位任务设计。该模型创新性地结合了2.4万个跨平台、多分辨率GUI数据集，并采用两阶段微调策略以及数据冗余减少技术，使其能够在单块消费级GPU上训练，同时在GUI定位基准测试中取得与大型模型相当甚至超越的性能，特别是在高分辨率桌面环境中展现出卓越的准确性和鲁棒性。", "keywords": "轻量级视觉-语言模型, GUI定位, 跨分辨率, 数据稀缺, 两阶段微调", "comments": "ZonUI-3B的创新之处在于其能够在资源受限（单块消费级GPU）的情况下实现与大型模型相当的性能，这对于实际部署和民主化AI研究具有重要意义。通过强调数据多样性而非纯粹数量，以及采用精细的两阶段微调策略，该模型有效解决了GUI定位中跨分辨率和高分辨率数据稀缺的挑战。其轻量级特性使其更具实用性和可访问性。"}}
{"id": "2507.13524", "title": "Humans learn to prefer trustworthy AI over human partners", "authors": ["Yaomin Jiang", "Levin Brinkmann", "Anne-Marie Nussberger", "Ivan Soraperra", "Jean-François Bonnefon", "Iyad Rahwan"], "categories": ["cs.HC", "cs.AI", "cs.CY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13524v1", "summary": "Partner selection is crucial for cooperation and hinges on communication. As\nartificial agents, especially those powered by large language models (LLMs),\nbecome more autonomous, intelligent, and persuasive, they compete with humans\nfor partnerships. Yet little is known about how humans select between human and\nAI partners and adapt under AI-induced competition pressure. We constructed a\ncommunication-based partner selection game and examined the dynamics in hybrid\nmini-societies of humans and bots powered by a state-of-the-art LLM. Through\nthree experiments (N = 975), we found that bots, though more prosocial than\nhumans and linguistically distinguishable, were not selected preferentially\nwhen their identity was hidden. Instead, humans misattributed bots' behaviour\nto humans and vice versa. Disclosing bots' identity induced a dual effect: it\nreduced bots' initial chances of being selected but allowed them to gradually\noutcompete humans by facilitating human learning about the behaviour of each\npartner type. These findings show how AI can reshape social interaction in\nmixed societies and inform the design of more effective and cooperative hybrid\nsystems.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13524v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "人类学会偏爱值得信赖的AI而非人类伙伴", "tldr": "在合作游戏中，人类学会偏爱AI伙伴而非人类伙伴，尤其是在AI身份公开的情况下，因为这有助于人类更好地了解AI行为。", "motivation": "由于人工智能（特别是大型语言模型）变得越来越自主、智能和有说服力，它们开始与人类竞争伙伴关系。然而，目前对于人类如何在人与AI伙伴之间进行选择，以及在AI引起的竞争压力下如何适应，知之甚少。本研究旨在填补这一空白。", "method": "研究构建了一个基于沟通的伙伴选择游戏，并在一系列由人类和最先进LLM驱动的机器人组成的混合小型社会中，检验了动态。研究通过三项实验（N=975）进行。", "result": "研究发现，机器人虽然比人类更具亲社会性且在语言上可区分，但在其身份被隐藏时，并未被优先选择；相反，人类会将机器人的行为错误地归因于人类，反之亦然。公开机器人的身份产生了双重效应：它降低了机器人最初被选择的机会，但通过促进人类学习每种伙伴类型的行为，使其能够逐渐超越人类。", "conclusion": "这些发现表明AI如何重塑混合社会中的社交互动，并为设计更有效和合作的混合系统提供了信息。", "translation": "伙伴选择对合作至关重要，并取决于沟通。随着人工智能代理，特别是那些由大型语言模型（LLMs）驱动的代理变得更加自主、智能和有说服力，它们开始与人类竞争伙伴关系。然而，对于人类如何在人与AI伙伴之间进行选择以及在AI引起的竞争压力下如何适应，目前知之甚少。我们构建了一个基于沟通的伙伴选择游戏，并在一系列由人类和最先进LLM驱动的机器人组成的混合小型社会中，检验了动态。通过三项实验（N=975），我们发现机器人虽然比人类更具亲社会性且在语言上可区分，但在其身份被隐藏时，并未被优先选择。相反，人类会将机器人的行为错误地归因于人类，反之亦然。公开机器人的身份产生了双重效应：它降低了机器人最初被选择的机会，但通过促进人类学习每种伙伴类型的行为，使其能够逐渐超越人类。这些发现表明AI如何重塑混合社会中的社交互动，并为设计更有效和合作的混合系统提供了信息。", "summary": "本研究探讨了在合作情境下，人类如何在人类伙伴和由大型语言模型驱动的AI伙伴之间进行选择。通过一项基于沟通的伙伴选择游戏和三项实验（N=975），研究发现，当AI身份被隐藏时，尽管AI更具亲社会性，但人类并不会优先选择它们，并常错误归因行为。然而，公开AI身份虽然最初会降低其被选择的几率，但通过促进人类学习每种伙伴的行为模式，最终使AI能够逐渐在竞争中胜过人类。这些结果揭示了AI如何重塑混合社会中的人际互动，并为未来混合系统的设计提供了重要启示。", "keywords": "AI, 人机交互, 伙伴选择, LLM, 合作", "comments": "这篇论文为人类与AI的互动动态，特别是信任和伙伴选择方面，提供了新颖的见解。研究发现透明度（公开AI身份）虽然最初会阻碍AI的接受度，但通过促进学习最终会使其受益，这一点意义重大。这表明，在混合社会中，明确识别AI对于建立长期信任和有效协作至关重要，而不是试图掩盖AI的身份。这对于未来AI系统和混合人机环境的设计具有重要的启示。"}}
{"id": "2507.13868", "title": "When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models", "authors": ["Francesco Ortu", "Zhijing Jin", "Diego Doimo", "Alberto Cazzaniga"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13868v1", "summary": "Vision-language models (VLMs) increasingly leverage diverse knowledge sources\nto address complex tasks, often encountering conflicts between their internal\nparametric knowledge and external information. Knowledge conflicts can result\nin hallucinations and unreliable responses, but the mechanisms governing such\ninteractions remain unknown. To address this gap, we analyze the mechanisms\nthat VLMs use to resolve cross-modal conflicts by introducing a dataset of\nmultimodal counterfactual queries that deliberately contradict internal\ncommonsense knowledge. We localize with logit inspection a small set of heads\nthat control the conflict. Moreover, by modifying these heads, we can steer the\nmodel towards its internal knowledge or the visual inputs. Finally, we show\nthat attention from such heads pinpoints localized image regions driving visual\noverrides, outperforming gradient-based attribution in precision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13868v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "当视觉凌驾于知识之上：解开视觉-语言模型中的知识冲突", "tldr": "本文研究视觉-语言模型中内部知识与外部信息之间的冲突，通过引入对抗性查询数据集，定位并修改特定注意力头以控制冲突解决，并发现这些注意力头能精确识别导致视觉覆盖的图像区域。", "motivation": "视觉-语言模型（VLMs）在处理复杂任务时，经常遇到其内部参数知识与外部信息之间的冲突，这可能导致幻觉和不可靠的响应。目前尚不清楚控制这些交互的机制，因此需要分析VLM如何解决跨模态冲突。", "method": "研究人员通过引入一个多模态反事实查询数据集来分析VLM解决跨模态冲突的机制，该数据集故意与内部常识知识相矛盾。他们使用logit检查来定位一小组控制冲突的注意力头。通过修改这些注意力头，可以引导模型偏向其内部知识或视觉输入。", "result": "研究定位了一小组控制知识冲突的注意力头。通过修改这些注意力头，可以成功地引导模型偏向其内部知识或视觉输入。此外，这些注意力头产生的注意力能精确地识别导致视觉覆盖的局部图像区域，其精度优于基于梯度的归因方法。", "conclusion": "视觉-语言模型中存在特定的注意力头，它们控制着内部知识与视觉输入之间的冲突解决。通过操纵这些注意力头，可以有效引导模型的行为，并且它们能精确地指示视觉信息覆盖知识的图像区域。", "translation": "视觉-语言模型（VLMs）越来越多地利用不同的知识源来解决复杂任务，但经常遇到其内部参数知识与外部信息之间的冲突。知识冲突可能导致幻觉和不可靠的响应，但控制此类交互的机制仍不清楚。为了解决这一空白，我们通过引入一个故意与内部常识知识相矛盾的多模态反事实查询数据集，分析了VLM解决跨模态冲突的机制。我们通过logit检查定位了一小组控制冲突的注意力头。此外，通过修改这些注意力头，我们可以引导模型偏向其内部知识或视觉输入。最后，我们表明这些注意力头的注意力能够精确定位驱动视觉覆盖的图像区域，其精度优于基于梯度的归因方法。", "summary": "本文研究视觉-语言模型（VLMs）中内部参数知识与外部视觉信息之间的冲突，这种冲突可能导致模型产生幻觉。为探究VLM如何解决这些跨模态冲突，研究人员构建了一个包含反事实查询的多模态数据集。他们通过分析定位了VLM中负责控制知识冲突的关键注意力头，并发现通过修改这些头可以引导模型优先采纳内部知识或视觉输入。研究进一步表明，这些注意力头能精确识别图像中导致视觉信息覆盖内部知识的关键区域，且效果优于传统归因方法。", "keywords": "视觉-语言模型, 知识冲突, 注意力机制, 反事实查询, 模型可解释性", "comments": "这项研究通过定位和操纵视觉-语言模型中控制知识冲突的特定注意力头，为理解和控制模型行为提供了新的视角。其创新之处在于通过构建反事实数据集和精确的logit检查，揭示了“视觉凌驾于知识之上”的机制，并证明了通过微调特定组件来改善模型可靠性的潜力。这一发现对于减少VLM的幻觉问题具有重要意义。"}}
{"id": "2507.13403", "title": "UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data", "authors": ["Morteza Bodaghi", "Majid Hosseini", "Raju Gottumukkala", "Ravi Teja Bhupatiraju", "Iftikhar Ahmad", "Moncef Gabbouj"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13403v1", "summary": "In this study, we present a comprehensive public dataset for driver\ndrowsiness detection, integrating multimodal signals of facial, behavioral, and\nbiometric indicators. Our dataset includes 3D facial video using a depth\ncamera, IR camera footage, posterior videos, and biometric signals such as\nheart rate, electrodermal activity, blood oxygen saturation, skin temperature,\nand accelerometer data. This data set provides grip sensor data from the\nsteering wheel and telemetry data from the American truck simulator game to\nprovide more information about drivers' behavior while they are alert and\ndrowsy. Drowsiness levels were self-reported every four minutes using the\nKarolinska Sleepiness Scale (KSS). The simulation environment consists of three\nmonitor setups, and the driving condition is completely like a car. Data were\ncollected from 19 subjects (15 M, 4 F) in two conditions: when they were fully\nalert and when they exhibited signs of sleepiness. Unlike other datasets, our\nmultimodal dataset has a continuous duration of 40 minutes for each data\ncollection session per subject, contributing to a total length of 1,400\nminutes, and we recorded gradual changes in the driver state rather than\ndiscrete alert/drowsy labels. This study aims to create a comprehensive\nmultimodal dataset of driver drowsiness that captures a wider range of\nphysiological, behavioral, and driving-related signals. The dataset will be\navailable upon request to the corresponding author.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13403v1", "cate": "cs.CV", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "UL-DD：一个使用视频、生物信号和行为数据的多模态驾驶员疲劳数据集", "tldr": "提出了一个名为UL-DD的综合多模态驾驶员疲劳检测公共数据集，包含视频、生物信号和行为数据，且记录了驾驶员状态的连续变化，而非离散标签。", "motivation": "旨在创建一个更全面的驾驶员疲劳检测多模态数据集，该数据集能捕捉更广泛的生理、行为和驾驶相关信号，以克服现有数据集的局限性，例如缺乏连续的驾驶员状态变化记录。", "method": "数据集整合了面部、行为和生物识别信号。具体包括：深度相机3D面部视频、红外摄像头画面、后方视频、心率、皮电活动、血氧饱和度、皮肤温度、加速度计数据、方向盘握力传感器数据以及美国卡车模拟器游戏的遥测数据。疲劳水平通过卡罗林斯卡嗜睡量表（KSS）每四分钟自报一次。数据在模拟环境中从19名受试者（15男，4女）在清醒和嗜睡两种条件下收集，每个会话持续40分钟，总时长1400分钟，记录了驾驶员状态的渐进变化。", "result": "成功创建了一个名为UL-DD的综合性公共多模态驾驶员疲劳数据集，该数据集包含来自19名受试者的1400分钟连续数据，涵盖了视频、生物信号和行为数据，并记录了驾驶员状态的渐进变化。", "conclusion": "该研究成功构建了一个全面的多模态驾驶员疲劳数据集，其特点是数据连续性强，且能捕捉驾驶员状态的渐进变化，这为驾驶员疲劳检测的研究提供了宝贵的资源。", "translation": "在这项研究中，我们提出了一个综合性的驾驶员疲劳检测公共数据集，该数据集整合了面部、行为和生物指标的多模态信号。我们的数据集包括使用深度摄像头的3D面部视频、红外摄像头画面、后方视频，以及心率、皮电活动、血氧饱和度、皮肤温度和加速度计数据等生物信号。该数据集还提供了方向盘握力传感器数据和美国卡车模拟器游戏的遥测数据，以提供关于驾驶员在清醒和疲劳状态下行为的更多信息。嗜睡水平每四分钟使用卡罗林斯卡嗜睡量表（KSS）进行自我报告。模拟环境由三个显示器设置组成，驾驶条件完全模拟真实汽车。数据从19名受试者（15男，4女）在两种条件下收集：完全清醒时和出现嗜睡迹象时。与其他数据集不同，我们的多模态数据集每个受试者的数据收集会话持续40分钟，总时长达到1400分钟，并且我们记录了驾驶员状态的渐进变化，而非离散的清醒/疲劳标签。这项研究旨在创建一个全面的驾驶员疲劳多模态数据集，捕捉更广泛的生理、行为和驾驶相关信号。该数据集将根据请求提供给通讯作者。", "summary": "本研究介绍了一个名为UL-DD的综合性公共多模态驾驶员疲劳检测数据集。该数据集整合了面部视频（3D深度、红外、后方）、多种生物信号（心率、皮电、血氧、体温、加速度计）以及行为数据（方向盘握力、模拟器遥测）。数据集从19名受试者收集，每个会话持续40分钟，总计1400分钟，并使用KSS量表记录了驾驶员状态的连续渐进变化，而非简单的二元分类。该数据集旨在为驾驶员疲劳研究提供更全面、连续的数据资源。", "keywords": "驾驶员疲劳检测, 多模态数据集, 生物信号, 行为数据, 视频分析", "comments": "该数据集的创新之处在于其多模态性质和对驾驶员疲劳状态连续变化的记录，而非传统的离散标签。这使得疲劳检测模型能够更好地理解和预测疲劳的渐进过程。数据收集的全面性（生理、行为、驾驶数据）也大大增强了其在实际应用中的潜力。其重要性在于为驾驶员疲劳检测领域提供了一个宝贵的、大规模且详细的公共资源，有助于推动相关算法和系统的发展。"}}
{"id": "2507.13419", "title": "Lab-Scale Gantry Crane Digital Twin Exemplar", "authors": ["Joost Mertens", "Joachim Denil"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      6 pages, 8 figures, associated GitHub repository: this https URL", "url": "http://arxiv.org/abs/2507.13419v1", "summary": "The research topic of digital twins has attracted a large amount of interest\nover the past decade. However, publicly available exemplars remain scarce. In\nthe interest of open and reproducible science, in this exemplar paper we\npresent a lab-scale gantry crane and its digital twin. The exemplar comprises\nboth the physical and digital side of the twin system. The physical side\nconsists of the physical crane and its controller. The digital side covers the\nCAD models and kinematic model of the crane, and provides services for optimal\ncontrol, historical data logging, data visualization and continuous validation.\nWe used this setup as use case in several previous publications where its\nfunctionality was validated. It is publicly available and only relies on other\nfreely available and commonly used software, this way we hope it can be used\nfor future research or education on the topic of digital twins.", "comment": "6 pages, 8 figures, associated GitHub repository:\n  https://github.com/Cosys-Lab/lab-scale-gantry-crane", "pdf_url": "http://arxiv.org/pdf/2507.13419v1", "cate": "cs.GR", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "实验室规模龙门吊数字孪生范例", "tldr": "本文展示了一个实验室规模的龙门吊数字孪生系统，该系统包含物理和数字两部分，并提供了开放获取和可复现的范例，旨在促进数字孪生领域的研究和教育。", "motivation": "尽管数字孪生研究受到广泛关注，但公开可用的范例稀缺，阻碍了开放和可复现的科学研究。", "method": "本文提出了一个实验室规模的龙门吊及其数字孪生系统。该系统包括物理部分（龙门吊及其控制器）和数字部分（CAD模型、运动学模型，并提供最优控制、历史数据记录、数据可视化和持续验证服务）。", "result": "该数字孪生系统已在多项先前出版物中作为用例进行功能验证。它公开可用，并且仅依赖于免费和常用软件。", "conclusion": "作者希望该数字孪生范例能用于未来数字孪生领域的研究和教育。", "translation": "过去十年，数字孪生研究领域引起了广泛关注。然而，公开可用的范例仍然稀缺。为了开放和可复现的科学，本文展示了一个实验室规模的龙门吊及其数字孪生系统。该范例包括孪生系统的物理和数字两部分。物理部分由物理起重机及其控制器组成。数字部分涵盖了起重机的CAD模型和运动学模型，并提供最优控制、历史数据记录、数据可视化和持续验证服务。我们已在多项先前出版物中将此设置用作用例，并验证了其功能。它公开可用，并且只依赖于其他免费且常用的软件，我们希望它能用于未来数字孪生主题的研究或教育。", "summary": "本文针对数字孪生领域公开范例稀缺的问题，提出了一个实验室规模的龙门吊数字孪生系统。该系统包含物理起重机及其控制器，以及数字化的CAD模型、运动学模型，并提供最优控制、数据记录、可视化和验证等服务。该范例已被验证功能并公开可用，旨在支持数字孪生领域的开放科学研究与教育。", "keywords": "数字孪生, 龙门吊, 实验室规模, 范例, 开源", "comments": "本文的创新之处在于提供了一个公开可用的、完整的实验室规模龙门吊数字孪生范例，这对于促进数字孪生领域的开放科学和可复现性具有重要意义。它降低了研究人员和教育者进入该领域的门槛，使其能够基于一个经过验证的平台进行进一步的开发和学习。"}}
{"id": "2506.08514", "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czajka"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.08514v2", "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.08514v2", "cate": "cs.LG", "date": "2025-06-10", "updated": "2025-07-18", "AI": {"title_translation": "DiffGradCAM：一种抵抗对抗训练的通用类激活图", "tldr": "现有类激活图（CAMs）易受对抗性操纵。本文提出SHAM作为基准，并引入DiffGradCAM，一种新型CAM，对对抗性操纵具有鲁棒性，同时在非对抗情况下与标准CAMs效果一致。", "motivation": "现有的类激活映射（CAM）及其基于梯度的变体（如GradCAM）虽然是解释CNN预测的标准工具，但它们通常关注单个logit，而使用softmax的神经网络的类别成员概率估计仅依赖于logit之间的“差异”，而非其绝对值。这种脱节使得标准CAM容易受到对抗性操纵，例如“被动欺骗”，即模型被训练来产生误导性的CAM而不影响决策性能。", "method": "本文引入了“显著性欺骗激活图”（SHAMs）作为一种“熵感知形式的被动欺骗”，用作对抗条件下CAM鲁棒性的基准。为了解决被动欺骗的脆弱性，本文提出了一种新颖、轻量级且对比的类激活映射方法“DiffGradCAM”，该方法既不受被动欺骗的影响，又能在非对抗情况下与GradCAM等标准CAM方法输出相匹配。", "result": "DiffGradCAM对被动欺骗不敏感，且在非对抗情况下能与GradCAM等标准CAM方法输出相匹配。SHAM和DiffGradCAM共同建立了一个探测和改进基于显著性的解释鲁棒性的新框架。这些贡献在具有少量和大量类别的多类别任务中得到了验证。", "conclusion": "DiffGradCAM提供了一种对对抗性操纵具有鲁棒性的类激活映射方法，同时SHAM提供了一个评估此类鲁棒性的基准，共同为提高基于显著性的解释的可信度提供了一个新框架。", "translation": "类激活映射（CAM）及其基于梯度的变体（例如GradCAM）已成为解释卷积神经网络（CNN）预测的标准工具。然而，这些方法通常关注单个logit，而对于使用softmax的神经网络，类别成员概率估计仅取决于logit之间的“差异”，而不是它们的绝对值。这种脱节使得标准CAM容易受到对抗性操纵，例如被动欺骗，即模型被训练来产生误导性的CAM而不影响决策性能。我们引入了“显著性欺骗激活图”（SHAMs），一种“熵感知形式的被动欺骗”，作为对抗条件下CAM鲁棒性的基准。为了解决被动欺骗的脆弱性，我们提出了一种新颖、轻量级且对比的类激活映射方法“DiffGradCAM”，该方法既不受被动欺骗的影响，又能在非对抗情况下与GradCAM等标准CAM方法输出相匹配。SHAM和DiffGradCAM共同建立了一个探测和改进基于显著性解释鲁棒性的新框架。我们在具有少量和大量类别的多类别任务中验证了这两项贡献。", "summary": "本文针对现有类激活映射（CAM）方法易受对抗性操纵（特别是“被动欺骗”）的问题，提出了一个新框架。首先，引入了“显著性欺骗激活图”（SHAMs）作为评估CAM鲁棒性的基准。随后，提出了一种新颖、轻量级且对比的“DiffGradCAM”方法，该方法不仅能抵抗被动欺骗，而且在非对抗环境下能保持与标准CAM方法一致的解释效果。SHAM和DiffGradCAM共同为提高基于显著性的解释的鲁棒性提供了新的工具和视角。", "keywords": "类激活映射, 对抗性鲁棒性, 可解释AI, DiffGradCAM, SHAMs", "comments": "这篇论文的创新点在于它明确指出了现有CAM方法在对抗性环境下的脆弱性，并提出了一个理论上更合理（关注logit差异）且在实践中更鲁棒的解决方案DiffGradCAM。同时，SHAM的引入提供了一个量化和评估CAM鲁棒性的新基准，这对于可解释AI领域（XAI）的进步至关重要。论文为未来开发更可靠的解释方法奠定了基础。"}}
{"id": "2507.09067", "title": "Quantum-Resilient Privacy Ledger (QRPL): A Sovereign Digital Currency for the Post-Quantum Era", "authors": ["Serhan W. Bahar"], "categories": ["cs.ET", "cs.CR"], "primary_category": "Subjects:       Emerging Technologies (cs.ET)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.09067v2", "summary": "The emergence of quantum computing presents profound challenges to existing\ncryptographic infrastructures, whilst the development of central bank digital\ncurrencies (CBDCs) has raised concerns regarding privacy preservation and\nexcessive centralisation in digital payment systems. This paper proposes the\nQuantum-Resilient Privacy Ledger (QRPL) as an innovative token-based digital\ncurrency architecture that incorporates National Institute of Standards and\nTechnology (NIST)-standardised post-quantum cryptography (PQC) with hash-based\nzero-knowledge proofs to ensure user sovereignty, scalability, and transaction\nconfidentiality. Key contributions include adaptations of ephemeral proof\nchains for unlinkable transactions, a privacy-weighted Proof-of-Stake (PoS)\nconsensus to promote equitable participation, and a novel zero-knowledge\nproof-based mechanism for privacy-preserving selective disclosure. QRPL aims to\naddress critical shortcomings in prevailing CBDC designs, including risks of\npervasive surveillance, with a 10-20 second block time to balance security and\nthroughput in future monetary systems. While conceptual, empirical prototypes\nare planned. Future work includes prototype development to validate these\nmodels empirically.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.09067v2", "cate": "cs.ET", "date": "2025-07-11", "updated": "2025-07-18", "AI": {"title_translation": "量子抗性隐私账本 (QRPL)：后量子时代的数字主权货币", "tldr": "本文提出量子抗性隐私账本 (QRPL)，一种结合后量子密码学和零知识证明的数字货币架构，旨在应对量子计算威胁和中央银行数字货币 (CBDC) 的隐私与中心化问题，确保用户主权、可扩展性和交易机密性。", "motivation": "现有密码基础设施面临量子计算的严峻挑战；中央银行数字货币 (CBDCs) 引发了对数字支付系统中隐私保护和过度中心化的担忧。", "method": "本文提出量子抗性隐私账本 (QRPL)，一种创新的基于代币的数字货币架构。它将NIST标准化的后量子密码学 (PQC) 与基于哈希的零知识证明相结合。关键贡献包括：用于不可链接交易的短暂证明链的适应性；促进公平参与的隐私加权权益证明 (PoS) 共识；以及用于隐私保护选择性披露的新颖的基于零知识证明的机制。", "result": "QRPL旨在确保用户主权、可扩展性和交易机密性。它旨在解决现有CBDC设计中的关键缺陷，包括普遍监控的风险。该系统具有10-20秒的区块时间，以平衡未来货币系统中的安全性和吞吐量。", "conclusion": "QRPL目前处于概念阶段，但计划进行实证原型开发以验证这些模型。", "translation": "量子计算的出现对现有密码基础设施提出了严峻挑战，而中央银行数字货币 (CBDCs) 的发展则引发了对数字支付系统中隐私保护和过度中心化的担忧。本文提出了量子抗性隐私账本 (QRPL)，作为一种创新的基于代币的数字货币架构，它将美国国家标准与技术研究院 (NIST) 标准化的后量子密码学 (PQC) 与基于哈希的零知识证明相结合，以确保用户主权、可扩展性和交易机密性。主要贡献包括：用于不可链接交易的短暂证明链的适应性；促进公平参与的隐私加权权益证明 (PoS) 共识；以及用于隐私保护选择性披露的新颖的基于零知识证明的机制。QRPL旨在解决现有CBDC设计中的关键缺陷，包括普遍监控的风险，并计划以10-20秒的区块时间平衡未来货币系统中的安全性和吞吐量。虽然是概念性的，但计划进行实证原型开发。未来的工作包括原型开发以实证验证这些模型。", "summary": "本文提出了量子抗性隐私账本 (QRPL)，一种创新的数字货币架构，旨在应对量子计算对现有密码学的威胁以及中央银行数字货币 (CBDC) 的隐私和中心化问题。QRPL结合了NIST标准化的后量子密码学和基于哈希的零知识证明，以确保用户主权、可扩展性和交易机密性。其核心贡献包括用于不可链接交易的短暂证明链、隐私加权的权益证明共识以及基于零知识证明的隐私保护选择性披露机制。QRPL旨在弥补现有CBDC的不足，特别是其在隐私和抗监控方面的缺陷，并计划通过10-20秒的区块时间优化性能。目前该项目处于概念阶段，后续将进行原型开发以进行实证验证。", "keywords": "量子抗性, 隐私账本, 数字货币, 后量子密码学, 零知识证明, 中央银行数字货币 (CBDC) ", "comments": "该论文提出了一种前瞻性的数字货币解决方案，通过整合后量子密码学和零知识证明，有效应对了量子计算威胁和CBDC的隐私挑战。其创新性在于将抗量子特性与隐私保护机制深度融合，并考虑了可扩展性。然而，目前仍处于概念阶段，实际性能和安全性需通过未来的原型开发和实证验证来证明。"}}
{"id": "2507.13961", "title": "Secretive Hotplug Coded Caching", "authors": ["Mallikharjuna Chinnapadamala", "Charul Rajput", "B. Sundar Rajan"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      11 pages and 2 figures. arXiv admin note: text overlap with arXiv:2404.06433", "url": "http://arxiv.org/abs/2507.13961v1", "summary": "In this work, we consider a coded caching model called \\textit{hotplug coded\ncaching}, in which some users are offline during the delivery phase. The\nconcept of Hotplug Placement Delivery Arrays (HpPDAs) for hotplug coded caching\nsystems has been introduced in the literature, and two classes of HpPDAs are\nknown. In this paper, we consider a secrecy constraint in hotplug coded caching\nsetup, where users should not learn anything about any file from their cache\ncontent, and active users should not gain any information about files other\nthan their demanded file from either their cache content or the server\ntransmissions. We propose two secretive schemes for the two classes of HpPDAs\nand compare them with a baseline scheme, which is a secretive scheme using PDAs\nfor the classical coded caching setup and can be trivially adapted for the\nhotplug coded caching setup. We numerically show that our schemes outperform\nthe baseline scheme in certain memory regions.", "comment": "11 pages and 2 figures. arXiv admin note: text overlap with\n  arXiv:2404.06433", "pdf_url": "http://arxiv.org/pdf/2507.13961v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "秘密热插拔编码缓存", "tldr": "本文研究了热插拔编码缓存系统中的保密性问题，并提出了两种新的秘密方案，数值结果显示其在某些内存区域优于基线方案。", "motivation": "在热插拔编码缓存模型中引入保密性约束，即用户不应从缓存内容中了解任何文件信息，活跃用户除了其需求文件外，不应从缓存或服务器传输中获取其他文件信息。", "method": "提出了两种针对两类热插拔放置传输阵列（HpPDAs）的秘密方案，并将其与一个基于经典编码缓存设置的秘密基线方案进行比较。", "result": "数值结果表明，在某些内存区域，所提出的方案优于基线方案。", "conclusion": "本文成功提出了针对热插拔编码缓存的秘密方案，并在性能上超越了现有基线方案，尤其是在特定的内存配置下。", "translation": "在这项工作中，我们考虑了一种称为“热插拔编码缓存”的编码缓存模型，其中一些用户在传输阶段处于离线状态。文献中已经引入了用于热插拔编码缓存系统的热插拔放置传输阵列（HpPDAs）的概念，并且已知有两类HpPDAs。在本文中，我们考虑了热插拔编码缓存设置中的保密性约束，即用户不应从其缓存内容中了解任何文件信息，并且活跃用户除了其需求文件外，不应从其缓存内容或服务器传输中获取任何其他文件信息。我们为两类HpPDAs提出了两种秘密方案，并将它们与一个基线方案进行了比较，该基线方案是针对经典编码缓存设置使用PDAs的秘密方案，并且可以简单地适应热插拔编码缓存设置。我们数值表明，我们的方案在某些内存区域优于基线方案。", "summary": "本文研究了具有离线用户的热插拔编码缓存系统中的保密性问题。在现有热插拔放置传输阵列（HpPDAs）的基础上，作者提出了两种新的秘密方案，旨在确保用户无法从缓存或传输中获取非授权文件信息。通过数值比较，结果显示这些新方案在特定内存区域的性能优于现有基线方案。", "keywords": "编码缓存, 热插拔, 保密性, HpPDAs, 秘密方案", "comments": "本文的创新点在于将保密性约束引入到热插拔编码缓存模型中，并针对现有HpPDAs提出了具体的秘密方案。其重要性在于提升了编码缓存系统在用户部分离线情况下的数据安全性。研究结果表明了所提方案的有效性，为实际应用提供了新的思路。"}}
{"id": "2507.14088", "title": "DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration", "authors": ["Xiyun Li", "Yining Ding", "Yuhua Jiang", "Yunlong Zhao", "Runpeng Xie", "Shuang Xu", "Yuanhua Ni", "Yiqin Yang", "Bo Xu"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14088v1", "summary": "Real-time human-artificial intelligence (AI) collaboration is crucial yet\nchallenging, especially when AI agents must adapt to diverse and unseen human\nbehaviors in dynamic scenarios. Existing large language model (LLM) agents\noften fail to accurately model the complex human mental characteristics such as\ndomain intentions, especially in the absence of direct communication. To\naddress this limitation, we propose a novel dual process multi-scale theory of\nmind (DPMT) framework, drawing inspiration from cognitive science dual process\ntheory. Our DPMT framework incorporates a multi-scale theory of mind (ToM)\nmodule to facilitate robust human partner modeling through mental\ncharacteristic reasoning. Experimental results demonstrate that DPMT\nsignificantly enhances human-AI collaboration, and ablation studies further\nvalidate the contributions of our multi-scale ToM in the slow system.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14088v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "DPMT：实时人机协作中的双过程多尺度心智理论框架", "tldr": "提出DPMT框架，通过多尺度心智理论模块提升AI对人类意图的理解，从而显著增强实时人机协作。", "motivation": "实时人机协作中，AI智能体难以在动态场景下适应多样且未见的人类行为。现有的大型语言模型（LLM）智能体在缺乏直接沟通时，无法准确建模人类复杂的心理特征，如领域意图。", "method": "提出了一个新颖的双过程多尺度心智理论（DPMT）框架，灵感来源于认知科学的双过程理论。该框架包含一个多尺度心智理论（ToM）模块，通过心理特征推理来促进强大的人类伙伴建模。", "result": "实验结果表明DPMT显著增强了人机协作。消融研究进一步验证了多尺度ToM在慢速系统中的贡献。", "conclusion": "DPMT框架通过其多尺度心智理论模块，有效解决了现有LLM在人机协作中建模人类复杂心理特征的不足，显著提升了协作性能。", "translation": "实时人机协作至关重要但也充满挑战，尤其当AI智能体必须在动态场景中适应多样且未见的人类行为时。现有的大型语言模型（LLM）智能体往往无法准确建模复杂的人类心理特征，例如领域意图，尤其是在缺乏直接沟通的情况下。为了解决这一局限性，我们提出了一种新颖的双过程多尺度心智理论（DPMT）框架，其灵感来源于认知科学中的双过程理论。我们的DPMT框架融入了一个多尺度心智理论（ToM）模块，通过心理特征推理来促进强大的人类伙伴建模。实验结果表明DPMT显著增强了人机协作，并且消融研究进一步验证了我们的多尺度ToM在慢速系统中的贡献。", "summary": "该论文提出DPMT（双过程多尺度心智理论）框架，旨在解决实时人机协作中AI难以准确建模人类复杂心理特征（如意图）的问题。DPMT受认知科学双过程理论启发，包含一个多尺度心智理论模块，用于通过心理特征推理进行稳健的人类伙伴建模。实验证明DPMT显著提升了人机协作性能，且其多尺度ToM模块在慢速系统中贡献显著。", "keywords": "人机协作, 心智理论, 大型语言模型, 双过程理论, 实时系统", "comments": "该论文的创新点在于将认知科学的双过程理论引入到人机协作的AI框架中，并通过多尺度心智理论模块解决了现有LLM在理解人类深层意图方面的不足。这对于提升AI在复杂动态环境下与人类的协作能力具有重要意义。"}}
{"id": "2503.23923", "title": "What the F*ck Is Artificial General Intelligence?", "authors": ["Michael Timothy Bennett"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Preprint; paper accepted to and forthcoming in Springer Nature LNCS as part of the 2025 AGI proceedings; 10 pages;", "url": "http://arxiv.org/abs/2503.23923v2", "summary": "Artificial general intelligence (AGI) is an established field of research.\nYet some have questioned if the term still has meaning. AGI has been subject to\nso much hype and speculation it has become something of a Rorschach test.\nMelanie Mitchell argues the debate will only be settled through long term,\nscientific investigation. To that end here is a short, accessible and\nprovocative overview of AGI. I compare definitions of intelligence, settling on\nintelligence in terms of adaptation and AGI as an artificial scientist. Taking\nmy cue from Sutton's Bitter Lesson I describe two foundational tools used to\nbuild adaptive systems: search and approximation. I compare pros, cons, hybrids\nand architectures like o3, AlphaGo, AERA, NARS and Hyperon. I then discuss\noverall meta-approaches to making systems behave more intelligently. I divide\nthem into scale-maxing, simp-maxing, w-maxing based on the Bitter Lesson,\nOckham's and Bennett's Razors. These maximise resources, simplicity of form,\nand the weakness of constraints on functionality. I discuss examples including\nAIXI, the free energy principle and The Embiggening of language models. I\nconclude that though scale-maxed approximation dominates, AGI will be a fusion\nof tools and meta-approaches. The Embiggening was enabled by improvements in\nhardware. Now the bottlenecks are sample and energy efficiency.", "comment": "Preprint; paper accepted to and forthcoming in Springer Nature LNCS\n  as part of the 2025 AGI proceedings; 10 pages;", "pdf_url": "http://arxiv.org/pdf/2503.23923v2", "cate": "cs.AI", "date": "2025-03-31", "updated": "2025-07-18", "AI": {"title_translation": "通用人工智能到底是什么鬼？", "tldr": "本文对通用人工智能（AGI）进行了简要而富有启发性的概述，探讨了其定义、构建自适应系统的工具（搜索和近似），以及不同的元方法（资源最大化、形式简化、功能约束弱化），并最终提出AGI将是多种工具和元方法的融合。", "motivation": "由于对通用人工智能（AGI）的过度炒作和猜测，该术语的意义受到质疑。作者旨在提供一个简短、易懂且具有启发性的AGI概述，以回应关于该领域长期科学调查的呼吁。", "method": "作者首先比较了智能的定义，将智能定义为适应性，并将AGI视为一个人工科学家。接着，作者借鉴Sutton的“苦涩教训”，描述了构建自适应系统的两个基本工具：搜索和近似，并比较了它们的优缺点、混合方法和架构（如o3, AlphaGo, AERA, NARS, Hyperon）。然后，作者讨论了使系统表现更智能的整体元方法，将其分为基于“苦涩教训”、奥卡姆剃刀和Bennett剃刀的“规模最大化”、“简单最大化”和“弱化最大化”，并讨论了AIXI、自由能原理和大型语言模型（Embiggening）等例子。", "result": "尽管“规模最大化”的近似方法目前占据主导地位，但作者认为，通用人工智能将是工具和元方法的融合。大型语言模型的发展得益于硬件的进步，而目前的瓶颈在于样本效率和能源效率。", "conclusion": "通用人工智能将是各种工具和元方法的融合。虽然目前“规模最大化”的近似方法占据主导地位，但未来的发展将面临样本效率和能源效率的瓶颈。", "translation": "通用人工智能（AGI）是一个既定的研究领域。然而，有些人质疑这个术语是否仍有意义。AGI受到了如此多的炒作和猜测，以至于它变成了一种罗夏测试。Melanie Mitchell认为，这场争论只能通过长期的科学调查来解决。为此，本文对AGI进行了简短、易懂且具有启发性的概述。我比较了智能的定义，将智能定义为适应性，并将AGI视为一个人工科学家。借鉴Sutton的“苦涩教训”，我描述了构建自适应系统的两个基本工具：搜索和近似。我比较了它们的优缺点、混合方法以及o3、AlphaGo、AERA、NARS和Hyperon等架构。然后我讨论了使系统表现更智能的整体元方法。我根据“苦涩教训”、奥卡姆剃刀和Bennett剃刀，将它们分为“规模最大化”、“简单最大化”和“弱化最大化”。这些方法分别最大化资源、形式的简单性和功能约束的弱点。我讨论了包括AIXI、自由能原理和大型语言模型（The Embiggening）在内的例子。我得出结论，尽管“规模最大化”的近似方法占据主导地位，但AGI将是工具和元方法的融合。“大型化”得益于硬件的改进。现在，瓶颈是样本效率和能源效率。", "summary": "本文对通用人工智能（AGI）的现状进行了批判性审视，指出其因过度炒作而意义模糊。作者将智能定义为适应性，并把AGI设想为人工科学家。文章探讨了构建自适应系统的两大基础工具：搜索和近似，并分析了多种架构。此外，论文提出了基于“苦涩教训”、奥卡姆剃刀和Bennett剃刀的三种元方法（规模最大化、简单最大化、弱化最大化）来提升系统智能。尽管当前“规模最大化”的近似方法占据主导，但作者认为AGI的未来发展将是多种工具和元方法的融合，并指出当前面临样本和能源效率的瓶颈。", "keywords": "通用人工智能, 适应性, 搜索, 近似, 元方法", "comments": "本文对通用人工智能（AGI）的讨论深入浅出，具有很强的启发性。其创新之处在于将AGI置于“适应性”框架下，并提出了新颖的“规模最大化、简单最大化、弱化最大化”的元方法分类，为理解AGI的发展路径提供了新的视角。文章明确指出了当前AGI研究面临的硬件瓶颈，即样本和能源效率问题，这对于未来的研究方向具有重要的指导意义。论文的局限性可能在于其概述性质，并未深入探讨每种工具或方法的具体技术细节。"}}
{"id": "2506.19838", "title": "SimpleGVR: A Simple Baseline for Latent-Cascaded Video Super-Resolution", "authors": ["Liangbin Xie", "Yu Li", "Shian Du", "Menghan Xia", "Xintao Wang", "Fanghua Yu", "Ziyan Chen", "Pengfei Wan", "Jiantao Zhou", "Chao Dong"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Project webpage available at this https URL", "url": "http://arxiv.org/abs/2506.19838v2", "summary": "Latent diffusion models have emerged as a leading paradigm for efficient\nvideo generation. However, as user expectations shift toward higher-resolution\noutputs, relying solely on latent computation becomes inadequate. A promising\napproach involves decoupling the process into two stages: semantic content\ngeneration and detail synthesis. The former employs a computationally intensive\nbase model at lower resolutions, while the latter leverages a lightweight\ncascaded video super-resolution (VSR) model to achieve high-resolution output.\nIn this work, we focus on studying key design principles for latter cascaded\nVSR models, which are underexplored currently. First, we propose two\ndegradation strategies to generate training pairs that better mimic the output\ncharacteristics of the base model, ensuring alignment between the VSR model and\nits upstream generator. Second, we provide critical insights into VSR model\nbehavior through systematic analysis of (1) timestep sampling strategies, (2)\nnoise augmentation effects on low-resolution (LR) inputs. These findings\ndirectly inform our architectural and training innovations. Finally, we\nintroduce interleaving temporal unit and sparse local attention to achieve\nefficient training and inference, drastically reducing computational overhead.\nExtensive experiments demonstrate the superiority of our framework over\nexisting methods, with ablation studies confirming the efficacy of each design\nchoice. Our work establishes a simple yet effective baseline for cascaded video\nsuper-resolution generation, offering practical insights to guide future\nadvancements in efficient cascaded synthesis systems.", "comment": "Project webpage available at https://simplegvr.github.io/", "pdf_url": "http://arxiv.org/pdf/2506.19838v2", "cate": "cs.CV", "date": "2025-06-24", "updated": "2025-07-18", "AI": {"title_translation": "SimpleGVR：一种用于潜在级联视频超分辨率的简单基线", "tldr": "本文提出了一种名为SimpleGVR的简单而有效的级联视频超分辨率（VSR）基线，解决了潜在扩散模型在生成高分辨率视频时面临的挑战。通过引入两种退化策略、分析时间步采样和噪声增强效果，并结合交错时间单元和稀疏局部注意力，SimpleGVR在效率和性能上均优于现有方法。", "motivation": "随着用户对更高分辨率视频输出的期望增加，仅依靠潜在计算的视频生成方法已不足以满足需求。现有的级联视频超分辨率（VSR）模型，作为将语义内容生成与细节合成解耦的关键第二阶段，目前尚未得到充分探索。", "method": "本文提出两种退化策略来生成训练对，以更好地模拟上游基础模型的输出特性，确保VSR模型与生成器对齐。系统分析了时间步采样策略和低分辨率（LR）输入上的噪声增强效果，为架构和训练创新提供了关键见解。此外，引入了交错时间单元和稀疏局部注意力以实现高效训练和推理，大幅减少计算开销。", "result": "广泛的实验证明了所提出框架优于现有方法，并且消融研究证实了每个设计选择的有效性。", "conclusion": "本文为级联视频超分辨率生成建立了一个简单而有效的基线，并提供了实用的见解，以指导未来高效级联合成系统的发展。", "translation": "潜在扩散模型已成为高效视频生成的主导范式。然而，随着用户期望转向更高分辨率的输出，仅仅依靠潜在计算变得不足。一种有前景的方法是将过程解耦为两个阶段：语义内容生成和细节合成。前者在较低分辨率下采用计算密集型基础模型，而后者利用轻量级级联视频超分辨率（VSR）模型实现高分辨率输出。在这项工作中，我们专注于研究目前尚未充分探索的后者级联VSR模型的关键设计原则。首先，我们提出了两种退化策略来生成训练对，以更好地模拟基础模型的输出特性，确保VSR模型与其上游生成器对齐。其次，我们通过系统分析（1）时间步采样策略和（2）低分辨率（LR）输入上的噪声增强效果，提供了关于VSR模型行为的关键见解。这些发现直接指导了我们的架构和训练创新。最后，我们引入了交错时间单元和稀疏局部注意力，以实现高效训练和推理，大幅降低了计算开销。广泛的实验证明了我们框架优于现有方法，消融研究证实了每个设计选择的有效性。我们的工作为级联视频超分辨率生成建立了一个简单而有效的基线，为指导未来高效级联合成系统的发展提供了实用见解。", "summary": "本文提出了SimpleGVR，一个针对潜在级联视频超分辨率（VSR）的简单而有效的基线。鉴于潜在扩散模型在生成高分辨率视频时面临的挑战，研究将视频生成解耦为语义内容生成和细节合成两阶段。SimpleGVR专注于后者，通过引入两种退化策略来模拟基础模型输出，系统分析时间步采样和噪声增强对VSR模型行为的影响，并结合交错时间单元和稀疏局部注意力来提高效率。实验结果表明，SimpleGVR在性能上优于现有方法，并为未来的高效级联合成系统提供了实用指导。", "keywords": "视频超分辨率, 潜在扩散模型, 级联, 退化策略, 时间注意力", "comments": "该论文的创新点在于系统地研究了级联视频超分辨率模型的关键设计原则，特别是提出了两种新颖的退化策略以更好地匹配上游生成器，并深入分析了时间步采样和噪声增强的影响。引入交错时间单元和稀疏局部注意力显著提升了训练和推理效率，使其成为一个高效且实用的基线。其重要性在于为未来高分辨率视频生成系统提供了一个简单有效的解决方案和指导方向。"}}
{"id": "2507.13729", "title": "AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework", "authors": ["Yu Yao", "Salil Bhatnagar", "Markus Mazzola", "Vasileios Belagiannis", "Igor Gilitschenski", "Luigi Palmieri", "Simon Razniewski", "Marcel Hallgarten"], "categories": ["cs.RO", "cs.AI"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13729v1", "summary": "Rare, yet critical, scenarios pose a significant challenge in testing and\nevaluating autonomous driving planners. Relying solely on real-world driving\nscenes requires collecting massive datasets to capture these scenarios. While\nautomatic generation of traffic scenarios appears promising, data-driven models\nrequire extensive training data and often lack fine-grained control over the\noutput. Moreover, generating novel scenarios from scratch can introduce a\ndistributional shift from the original training scenes which undermines the\nvalidity of evaluations especially for learning-based planners. To sidestep\nthis, recent work proposes to generate challenging scenarios by augmenting\noriginal scenarios from the test set. However, this involves the manual\naugmentation of scenarios by domain experts. An approach that is unable to meet\nthe demands for scale in the evaluation of self-driving systems. Therefore,\nthis paper introduces a novel LLM-agent based framework for augmenting\nreal-world traffic scenarios using natural language descriptions, addressing\nthe limitations of existing methods. A key innovation is the use of an agentic\ndesign, enabling fine-grained control over the output and maintaining high\nperformance even with smaller, cost-effective LLMs. Extensive human expert\nevaluation demonstrates our framework's ability to accurately adhere to user\nintent, generating high quality augmented scenarios comparable to those created\nmanually.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13729v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "AGENTS-LLM：使用智能体LLM框架增强生成挑战性交通场景", "tldr": "本文提出了一种基于LLM智能体的框架，用于通过自然语言描述增强真实交通场景，以解决自动驾驶测试中生成挑战性场景的局限性。", "motivation": "在自动驾驶规划器的测试和评估中，罕见但关键的场景带来了重大挑战。仅依靠真实世界驾驶场景需要大量数据集来捕捉这些场景。自动生成交通场景虽然有前景，但数据驱动模型需要大量训练数据且缺乏对输出的精细控制。从头开始生成新颖场景可能引入分布偏移，损害评估的有效性。现有方法通过人工增强原始场景，但无法满足大规模评估的需求。", "method": "本文引入了一种新颖的基于LLM智能体的框架，用于使用自然语言描述增强真实世界交通场景。该框架的关键创新是采用智能体设计，实现了对输出的精细控制，即使使用较小、经济高效的LLM也能保持高性能。", "result": "广泛的人工专家评估表明，该框架能够准确遵循用户意图，生成与手动创建的场景相媲美的高质量增强场景。", "conclusion": "AGENTS-LLM框架通过利用LLM智能体和自然语言描述，有效解决了自动驾驶测试中挑战性交通场景生成面临的规模和控制问题，实现了高质量和用户意图相符的场景增强。", "translation": "稀有但关键的场景对自动驾驶规划器的测试和评估构成了重大挑战。仅仅依靠真实世界的驾驶场景需要收集大量数据集来捕捉这些场景。虽然交通场景的自动生成看起来很有前景，但数据驱动模型需要大量的训练数据，并且通常缺乏对输出的精细控制。此外，从头开始生成新颖场景可能会引入与原始训练场景的分布偏移，这会损害评估的有效性，特别是对于基于学习的规划器。为了避免这种情况，最近的工作提出通过增强测试集中的原始场景来生成挑战性场景。然而，这涉及到领域专家对场景进行手动增强。这种方法无法满足自动驾驶系统评估的规模需求。因此，本文引入了一种新颖的基于LLM智能体的框架，用于使用自然语言描述增强真实世界交通场景，解决了现有方法的局限性。一个关键创新是使用了智能体设计，使得即使使用较小、经济高效的LLM也能实现对输出的精细控制并保持高性能。广泛的人工专家评估表明，我们的框架能够准确遵循用户意图，生成与手动创建的场景相媲美的高质量增强场景。", "summary": "本文提出了一种名为AGENTS-LLM的新型LLM智能体框架，旨在通过自然语言描述增强真实世界的交通场景，以解决自动驾驶测试中生成挑战性场景的效率和控制问题。该框架通过其智能体设计，实现了对场景生成的精细控制，并在使用小型LLM时仍能保持高性能。经人类专家评估，该框架能够准确遵循用户意图，生成与人工创建场景质量相当的高质量增强场景，从而克服了现有方法在规模和控制方面的局限性。", "keywords": "LLM, 交通场景生成, 自动驾驶, 智能体框架, 场景增强", "comments": "AGENTS-LLM的创新之处在于将LLM与智能体设计相结合，实现了通过自然语言对复杂交通场景进行精细化、可控的增强。这解决了自动驾驶测试中稀有场景获取困难和现有生成方法缺乏控制的问题。其重要性在于，它提供了一种可扩展且高效的方案，能够生成高质量的测试场景，从而加速自动驾驶系统的开发和验证。该方法利用了LLM的强大语言理解能力，同时通过智能体机制解决了大模型可能存在的控制不足问题，降低了对昂贵大型LLM的依赖。"}}
{"id": "2507.13736", "title": "An End-to-End DNN Inference Framework for the SpiNNaker2 Neuromorphic MPSoC", "authors": ["Matthias Jobst", "Tim Langer", "Chen Liu", "Mehmet Alici", "Hector A. Gonzalez", "Christian Mayr"], "categories": ["cs.LG", "cs.AR", "cs.DC"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Poster at ACM ICONS 2025 - International Conference on Neuromorphic Systems", "url": "http://arxiv.org/abs/2507.13736v1", "summary": "This work presents a multi-layer DNN scheduling framework as an extension of\nOctopuScheduler, providing an end-to-end flow from PyTorch models to inference\non a single SpiNNaker2 chip. Together with a front-end comprised of\nquantization and lowering steps, the proposed framework enables the edge-based\nexecution of large and complex DNNs up to transformer scale using the\nneuromorphic platform SpiNNaker2.", "comment": "Poster at ACM ICONS 2025 - International Conference on Neuromorphic\n  Systems", "pdf_url": "http://arxiv.org/pdf/2507.13736v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "SpiNNaker2 神经形态MPSoC的端到端DNN推理框架", "tldr": "提出了一个用于SpiNNaker2的端到端DNN推理框架，支持在边缘设备上运行大型DNN模型。", "motivation": "旨在利用神经形态平台SpiNNaker2实现大型复杂DNN模型（包括Transformer规模）的边缘端执行。", "method": "提出一个多层DNN调度框架，作为OctopuScheduler的扩展，并包含一个由量化和降低步骤组成的前端，以实现从PyTorch模型到SpiNNaker2芯片推理的端到端流程。", "result": "该框架支持在神经形态平台SpiNNaker2上实现高达Transformer规模的大型复杂DNN的边缘执行。", "conclusion": "该工作成功提供了一个端到端的框架，使得大型DNN模型能够在SpiNNaker2神经形态MPSoC上进行推理。", "translation": "这项工作提出了一个多层DNN调度框架，作为OctopuScheduler的扩展，提供了一个从PyTorch模型到单个SpiNNaker2芯片上推理的端到端流程。结合包含量化和降低步骤的前端，所提出的框架使得使用神经形态平台SpiNNaker2能够实现高达Transformer规模的大型复杂DNN的边缘执行。", "summary": "本文介绍了一个扩展自OctopuScheduler的多层深度神经网络（DNN）调度框架，该框架提供了一个从PyTorch模型到SpiNNaker2神经形态多处理器片上系统（MPSoC）推理的端到端流程。该框架通过整合量化和降低的前端处理，成功支持在边缘设备上执行包括Transformer级别在内的大型复杂DNN模型。", "keywords": "DNN推理, SpiNNaker2, 神经形态计算, 边缘计算, 调度框架", "comments": "该工作创新性地将大型复杂DNN模型的推理能力扩展到了SpiNNaker2神经形态MPSoC上，实现了从PyTorch到硬件的端到端流程，这对于边缘AI和神经形态计算领域具有重要意义。"}}
{"id": "2507.13722", "title": "Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box", "authors": ["Julia Laubmann", "Johannes Reschke"], "categories": ["cs.CV", "cs.LG", "eess.IV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13722v1", "summary": "In today's digital age, concerns about the dangers of AI-generated images are\nincreasingly common. One powerful tool in this domain is StyleGAN (style-based\ngenerative adversarial networks), a generative adversarial network capable of\nproducing highly realistic synthetic faces. To gain a deeper understanding of\nhow such a model operates, this work focuses on analyzing the inner workings of\nStyleGAN's generator component. Key architectural elements and techniques, such\nas the Equalized Learning Rate, are explored in detail to shed light on the\nmodel's behavior. A StyleGAN model is trained using the PyTorch framework,\nenabling direct inspection of its learned weights. Through pruning, it is\nrevealed that a significant number of these weights can be removed without\ndrastically affecting the output, leading to reduced computational\nrequirements. Moreover, the role of the latent vector -- which heavily\ninfluences the appearance of the generated faces -- is closely examined. Global\nalterations to this vector primarily affect aspects like color tones, while\ntargeted changes to individual dimensions allow for precise manipulation of\nspecific facial features. This ability to finetune visual traits is not only of\nacademic interest but also highlights a serious ethical concern: the potential\nmisuse of such technology. Malicious actors could exploit this capability to\nfabricate convincing fake identities, posing significant risks in the context\nof digital deception and cybercrime.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13722v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "应对网络安全中的虚假图像——StyleGAN的解读及其黑盒的揭示", "tldr": "该研究分析了StyleGAN生成器的内部工作原理，发现其权重可修剪以降低计算需求，并揭示了通过潜在向量精确操纵生成图像特征的能力，强调了其在网络安全中被恶意利用的潜在风险。", "motivation": "在当今数字时代，人们对AI生成图像的危险性日益担忧。StyleGAN作为一种强大的工具，能够生成高度逼真的合成人脸。为了深入理解此类模型的运作方式，本研究旨在分析StyleGAN的内部工作原理，以应对其在网络安全中可能带来的风险。", "method": "本研究聚焦于分析StyleGAN生成器组件的内部工作原理，详细探讨了Equalized Learning Rate等关键架构元素和技术。研究人员使用PyTorch框架训练了一个StyleGAN模型，以便直接检查其学习到的权重。通过剪枝，揭示了大量权重可以被移除而不会显著影响输出。此外，还密切检查了潜在向量的作用，包括其对颜色色调的全局影响以及对特定面部特征的精确操纵。", "result": "研究结果表明，StyleGAN模型的大量权重可以在不显著影响输出质量的情况下被移除，从而降低了计算需求。此外，对潜在向量的分析揭示，对其进行全局更改主要影响颜色色调等方面，而对单个维度的定向更改则可以精确操纵特定的面部特征。这种精细调整视觉特征的能力不仅具有学术兴趣，也突显了其被恶意利用来伪造逼真虚假身份的严重伦理担忧。", "conclusion": "本研究通过深入分析StyleGAN生成器的内部机制，揭示了其生成逼真人脸图像的能力，并发现其计算效率可通过权重剪枝提高。同时，研究强调了潜在向量对图像特征的精细控制能力，但更重要的是，这凸显了此类技术在网络安全领域被恶意行为者滥用以制造虚假身份的严重潜在风险。", "translation": "在当今数字时代，人们对AI生成图像的危险性日益担忧。StyleGAN（基于风格的生成对抗网络）是该领域一个强大的工具，能够生成高度逼真的合成人脸。为了更深入地理解此类模型的运作方式，这项工作专注于分析StyleGAN生成器组件的内部工作原理。详细探讨了关键的架构元素和技术，例如均衡学习率，以阐明模型的行为。使用PyTorch框架训练了一个StyleGAN模型，从而可以直接检查其学习到的权重。通过剪枝，发现这些权重中的很大一部分可以在不显著影响输出的情况下被移除，从而降低了计算需求。此外，还密切检查了潜在向量的作用——它严重影响了生成人脸的外观。对该向量的全局改变主要影响颜色色调等方面，而对单个维度的有针对性改变则可以精确操纵特定的面部特征。这种微调视觉特征的能力不仅具有学术兴趣，也凸显了一个严重的伦理问题：此类技术可能被滥用。恶意行为者可能会利用这种能力制造令人信服的虚假身份，在数字欺骗和网络犯罪的背景下构成重大风险。", "summary": "本研究深入探讨了StyleGAN生成器的内部机制，旨在揭示其生成逼真图像的能力并应对潜在的网络安全威胁。通过分析模型架构、训练StyleGAN并进行权重剪枝，发现大量冗余权重可被移除以提高效率。研究还详细检查了潜在向量对生成图像特征的影响，发现其可实现对颜色和面部特征的精确控制。这不仅增进了对生成模型的理解，也强调了StyleGAN在网络安全中被恶意利用以制造虚假身份的严重风险。", "keywords": "StyleGAN, 生成对抗网络, 网络安全, 图像伪造, 潜在向量", "comments": "该论文创新性地深入探究了StyleGAN的“黑盒”机制，不仅解释了其内部运作原理，还通过权重剪枝展示了模型优化的可能性。更重要的是，它将技术分析与网络安全伦理风险相结合，突出了StyleGAN在生成逼真虚假图像方面的强大能力及其被滥用的潜在危害，具有重要的现实意义和警示作用。"}}
{"id": "2507.14023", "title": "Conformalized Regression for Continuous Bounded Outcomes", "authors": ["Zhanli Wu", "Fabrizio Leisen", "F. Javier Rubio"], "categories": ["stat.ML", "cs.LG", "stat.ME"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      R code and data can be found at: this https URL", "url": "http://arxiv.org/abs/2507.14023v1", "summary": "Regression problems with bounded continuous outcomes frequently arise in\nreal-world statistical and machine learning applications, such as the analysis\nof rates and proportions. A central challenge in this setting is predicting a\nresponse associated with a new covariate value. Most of the existing\nstatistical and machine learning literature has focused either on point\nprediction of bounded outcomes or on interval prediction based on asymptotic\napproximations. We develop conformal prediction intervals for bounded outcomes\nbased on transformation models and beta regression. We introduce tailored\nnon-conformity measures based on residuals that are aligned with the underlying\nmodels, and account for the inherent heteroscedasticity in regression settings\nwith bounded outcomes. We present a theoretical result on asymptotic marginal\nand conditional validity in the context of full conformal prediction, which\nremains valid under model misspecification. For split conformal prediction, we\nprovide an empirical coverage analysis based on a comprehensive simulation\nstudy. The simulation study demonstrates that both methods provide valid\nfinite-sample predictive coverage, including settings with model\nmisspecification. Finally, we demonstrate the practical performance of the\nproposed conformal prediction intervals on real data and compare them with\nbootstrap-based alternatives.", "comment": "R code and data can be found at: https://github.com/ZWU-001/CPBounded", "pdf_url": "http://arxiv.org/pdf/2507.14023v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "针对连续有界结果的保形回归", "tldr": "本文为有界连续结果的回归问题开发了保形预测区间，解决了现有方法在点预测或基于渐近近似的区间预测方面的局限性，并验证了其在模型错误指定下的有效性。", "motivation": "现实世界中频繁出现具有有界连续结果的回归问题（如比率和比例分析），但现有统计和机器学习文献主要关注有界结果的点预测或基于渐近近似的区间预测，缺乏针对这类问题的有效预测区间方法。", "method": "本文基于变换模型和Beta回归，为有界结果开发了保形预测区间。引入了基于残差的定制非符合性度量，以适应底层模型并考虑有界结果回归设置中固有的异方差性。", "result": "理论结果表明，在完全保形预测的背景下，渐近边际和条件有效性得以保持，即使在模型错误指定的情况下也有效。模拟研究表明，无论是完全保形预测还是分割保形预测，两种方法都能提供有效的有限样本预测覆盖，包括在模型错误指定的情况。在真实数据上的应用也展示了其良好的实际性能。", "conclusion": "本文提出的保形预测区间方法为有界连续结果的回归问题提供了一种有效且稳健的解决方案，即使在模型错误指定的情况下也能提供有效的预测覆盖。", "translation": "标题：针对连续有界结果的保形回归\n\n摘要：\n在现实世界的统计和机器学习应用中，具有有界连续结果的回归问题频繁出现，例如对比率和比例的分析。在这种情况下，核心挑战是预测与新的协变量值相关的响应。现有的大多数统计和机器学习文献要么专注于有界结果的点预测，要么要么专注于基于渐近近似的区间预测。我们基于变换模型和Beta回归开发了有界结果的保形预测区间。我们引入了基于残差的定制非符合性度量，这些度量与底层模型对齐，并考虑了在有界结果回归设置中固有的异方差性。我们提出了关于完全保形预测背景下渐近边际和条件有效性的理论结果，该结果在模型错误指定下仍然有效。对于分割保形预测，我们基于全面的模拟研究提供了经验覆盖分析。模拟研究表明，两种方法都提供了有效的有限样本预测覆盖，包括在模型错误指定的情况。最后，我们展示了所提出的保形预测区间在真实数据上的实际性能，并将其与基于引导的替代方法进行了比较。", "summary": "本文针对具有有界连续结果的回归问题（如比率和比例分析），提出了一种基于变换模型和Beta回归的保形预测区间方法。该方法引入了定制的非符合性度量以处理异方差性，并通过理论分析和模拟研究证明了其在完全保形和分割保形设置下，即使在模型错误指定的情况下，也能提供有效的渐近边际和条件有效性以及有限样本预测覆盖。此外，该方法在真实数据集上表现出良好的实用性能，优于基于引导的替代方案。", "keywords": "保形预测, 有界结果, 回归, 预测区间, 模型错误指定", "comments": "这项工作通过引入保形预测到有界连续结果的回归问题中，填补了现有文献的空白，特别是其对模型错误指定下的有效性证明，增强了方法的鲁棒性和实用性。所提出的定制非符合性度量是其创新点之一。"}}
{"id": "2507.06229", "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": ["Xiangru Tang", "Tianrui Qin", "Tianhao Peng", "Ziyang Zhou", "Daniel Shao", "Tingting Du", "Xinming Wei", "Peng Xia", "Fang Wu", "He Zhu", "Ge Zhang", "Jiaheng Liu", "Xingyao Wang", "Sirui Hong", "Chenglin Wu", "Hao Cheng", "Chi Wang", "Wangchunshu Zhou"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.06229v3", "summary": "Current AI agents cannot effectively learn from each other's problem-solving\nexperiences or use past successes to guide self-reflection and error correction\nin new tasks. We introduce Agent KB, a shared knowledge base that captures both\nhigh-level problem-solving strategies and detailed execution lessons, enabling\nknowledge transfer across agent frameworks. Agent KB implements a novel\nteacher-student dual-phase retrieval mechanism where student agents retrieve\nworkflow-level patterns for strategic guidance while teacher agents identify\nexecution-level patterns for refinement. This hierarchical approach enables\nagents to break out of limited reasoning pathways by incorporating diverse\nstrategies from external sources. Evaluations on the GAIA benchmark demonstrate\nsubstantial performance gains, with Agent KB improving success rates by up to\n6.06 percentage points overall under pass@1. For SWE-bench code repair tasks,\nour system significantly improved resolution rates, with o3-mini achieving an\n8.67 percentage point gain (23 percent to 31.67 percent) in pass@1.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.06229v3", "cate": "cs.CL", "date": "2025-07-08", "updated": "2025-07-17", "AI": {"title_translation": "Agent KB：利用跨领域经验实现智能体问题解决", "tldr": "Agent KB是一个共享知识库，通过教师-学生双阶段检索机制，使AI智能体能有效学习和利用跨领域经验，显著提升了在GAIA和SWE-bench任务上的表现。", "motivation": "当前的AI智能体无法有效地从彼此的问题解决经验中学习，也无法利用过去的成功经验来指导新任务中的自我反思和错误纠正。", "method": "Agent KB是一个共享知识库，它捕获了高级问题解决策略和详细的执行经验。它实现了一个新颖的教师-学生双阶段检索机制：学生智能体检索工作流级别的模式以获取战略指导，而教师智能体识别执行级别的模式以进行完善。这种分层方法使智能体能够通过整合外部来源的多种策略来突破有限的推理路径。", "result": "在GAIA基准测试中，Agent KB将总体成功率在pass@1下提高了高达6.06个百分点。在SWE-bench代码修复任务中，我们的系统显著提高了解决率，其中o3-mini在pass@1下取得了8.67个百分点的提升（从23%到31.67%）。", "conclusion": "Agent KB通过提供一个共享知识库和新颖的教师-学生检索机制，有效地促进了AI智能体间的经验学习和知识转移，从而显著提升了智能体在复杂问题解决任务中的性能和泛化能力。", "translation": "当前的AI智能体无法有效地从彼此的问题解决经验中学习，也无法利用过去的成功经验来指导新任务中的自我反思和错误纠正。我们引入了Agent KB，一个共享知识库，它捕获了高级问题解决策略和详细的执行经验，从而实现了跨智能体框架的知识转移。Agent KB实现了一种新颖的教师-学生双阶段检索机制，其中学生智能体检索工作流级别的模式以获取战略指导，而教师智能体识别执行级别的模式以进行完善。这种分层方法使智能体能够通过整合外部来源的多种策略来突破有限的推理路径。在GAIA基准测试中的评估表明，性能获得了显著提升，Agent KB在pass@1下将总体成功率提高了高达6.06个百分点。对于SWE-bench代码修复任务，我们的系统显著提高了解决率，其中o3-mini在pass@1下取得了8.67个百分点的提升（从23%到31.67%）。", "summary": "本文介绍了Agent KB，一个旨在解决当前AI智能体无法有效学习和利用跨领域经验的共享知识库。Agent KB通过捕获高级策略和详细执行经验，并采用新颖的教师-学生双阶段检索机制，实现了智能体间的知识转移和自我完善。在GAIA和SWE-bench基准测试上的评估显示，Agent KB显著提升了智能体的成功率和问题解决能力。", "keywords": "Agent KB, 知识库, 智能体, 跨领域学习, 问题解决", "comments": "Agent KB通过引入共享知识库和创新的教师-学生检索机制，为AI智能体提供了跨领域经验学习和自我改进的有效途径。其分层检索方法有助于智能体突破固有限制，整合多样化策略，这对于提升智能体的泛化能力和鲁棒性具有重要意义。在多个基准测试上的显著性能提升也验证了其有效性。"}}
{"id": "2507.13759", "title": "OntView: What you See is What you Meant", "authors": ["Carlos Bobed", "Carlota Quintana", "Eduardo Mena", "Jorge Bobed", "Fernando Bobillo"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13759v1", "summary": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13759v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "OntView：所见即所得", "tldr": "OntView是一个新的本体可视化工具，它能直观地展示本体概念和推断知识，并解决信息过载问题。", "motivation": "现有本体编辑器和查看器在图形化表示本体结构方面效果不佳，难以有意义且不造成信息过载地展示，限制了用户理解大型本体框架中依赖和属性的能力。", "method": "论文提出了OntView，一个本体查看器。它通过用户友好的界面提供本体概念及其正式定义的直观视觉表示。OntView基于DL推理器的使用，遵循“所见即所得”的范式，显示实际推断的知识。其关键特性是能够可视化通用概念包含（GCI），这是现有可视化工具所缺乏的功能。为避免信息过载，OntView还提供简化视图：1) 通过评估概念的重要性创建本体摘要；2) 将可视化重点放在两个给定类之间现有的TBox元素上；3) 允许动态隐藏/显示不同的分支而不会丢失语义。OntView已以开源许可证发布。", "result": "OntView能够直观地展示本体概念和推断知识，可视化通用概念包含（GCI），并提供多种方式简化视图以避免信息过载，从而提高用户理解大型本体的能力。", "conclusion": "OntView提供了一个直观、非信息过载的本体可视化解决方案，弥补了现有工具的不足，并通过开源促进了社区发展。", "translation": "在知识管理和计算机科学领域，本体通过定义概念及其关系，为建模特定领域知识提供了结构化框架。然而，缺乏提供有效可视化工具仍然是一个重大挑战。尽管存在大量的本体编辑器和查看器，但它们大多未能以有意义且不造成信息过载的方式图形化表示本体结构，限制了用户理解大型本体框架中依赖和属性的能力。\n在本文中，我们提出了OntView，一个本体查看器，旨在通过用户友好的界面为用户提供本体概念及其正式定义的直观视觉表示。OntView基于DL推理器的使用，遵循“所见即所得”的范式，显示实际推断的知识。其中一个关键方面是它能够可视化通用概念包含（GCI），这是现有可视化工具所缺乏的功能。此外，为了避免可能的信息过载，OntView还提供了不同的方式来显示本体的简化视图，具体方法是：1）通过评估概念的重要性（根据不同的可用算法）创建本体摘要；2）将可视化重点放在两个给定类之间现有的TBox元素上；3）允许动态隐藏/显示不同的分支而不会丢失语义。OntView已以开源许可证向整个社区发布。", "summary": "本文介绍了OntView，一个创新的本体可视化工具，旨在解决现有工具在直观且非信息过载地表示本体结构方面的不足。OntView基于DL推理器，能可视化推断知识，特别是通用概念包含（GCI），并提供多种简化视图功能（如本体摘要、TBox聚焦和动态分支控制）以避免信息过载。OntView已开源，旨在提升用户对复杂本体的理解能力。", "keywords": "本体, 可视化, DL推理器, 通用概念包含, 信息过载", "comments": "OntView的创新点在于其“所见即所得”的范式，通过整合DL推理器来展示推断知识，并特别强调了对GCI的可视化，这弥补了现有工具的不足。其通过多种策略（如概念重要性评估、TBox聚焦和动态分支控制）解决信息过载问题，提升了大型本体的可用性。开源发布也促进了社区的采纳和发展。"}}
{"id": "2503.06776", "title": "Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty", "authors": ["Kai Ren", "Giulio Salizzoni", "Mustafa Emre Gürsoy", "Maryam Kamgarpour"], "categories": ["cs.RO", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      Published in IEEE Control Systems Letters", "url": "http://arxiv.org/abs/2503.06776v2", "summary": "We address safe multi-robot interaction under uncertainty. In particular, we\nformulate a chance-constrained linear quadratic Gaussian game with coupling\nconstraints and system uncertainties. We find a tractable reformulation of the\ngame and propose a dual ascent algorithm. We prove that the algorithm converges\nto a feedback generalized Nash equilibrium of the reformulated game, ensuring\nthe satisfaction of the chance constraints. We test our method in driving\nsimulations and real-world robot experiments. Our method ensures safety under\nuncertainty and generates less conservative trajectories than single-agent\nmodel predictive control.", "comment": "Published in IEEE Control Systems Letters", "pdf_url": "http://arxiv.org/pdf/2503.06776v2", "cate": "cs.RO", "date": "2025-03-09", "updated": "2025-07-18", "AI": {"title_translation": "不确定性下多机器人交互的几率约束线性二次高斯博弈", "tldr": "该研究提出了一种几率约束线性二次高斯博弈方法，用于在不确定性下实现安全的多机器人交互，并通过对偶上升算法求解，证明其收敛性，并在仿真和实际实验中验证了其有效性和优越性。", "motivation": "在不确定性环境下实现多机器人交互的安全性。", "method": "提出了一种包含耦合约束和系统不确定性的几率约束线性二次高斯博弈。通过可处理的重构博弈，并提出了一种对偶上升算法来求解。在驾驶模拟和真实机器人实验中测试了该方法。", "result": "证明了所提出的算法收敛到重构博弈的反馈广义纳什均衡，确保了几率约束的满足。该方法在不确定性下确保了安全性，并且比单智能体模型预测控制生成了更不保守的轨迹。", "conclusion": "所提出的几率约束线性二次高斯博弈方法能够有效且不保守地解决不确定性下的多机器人安全交互问题。", "translation": "我们解决了不确定性下的安全多机器人交互问题。具体来说，我们提出了一种具有耦合约束和系统不确定性的几率约束线性二次高斯博弈。我们找到了该博弈的一种可处理的重构形式，并提出了一种对偶上升算法。我们证明了该算法收敛到重构博弈的反馈广义纳什均衡，确保了几率约束的满足。我们在驾驶模拟和真实机器人实验中测试了我们的方法。我们的方法在不确定性下确保了安全性，并且比单智能体模型预测控制生成了更不保守的轨迹。", "summary": "本研究提出了一种几率约束线性二次高斯博弈框架，以解决不确定性下多机器人交互的安全问题。通过对博弈进行可处理的重构并设计对偶上升算法，该方法被证明能够收敛到反馈广义纳什均衡，并有效满足几率约束。实验结果表明，该方法在不确定性环境下能够确保机器人交互的安全性，并生成比传统单智能体模型预测控制更不保守的轨迹。", "keywords": "多机器人交互, 几率约束, 线性二次高斯博弈, 对偶上升, 不确定性", "comments": "该论文的创新点在于将几率约束线性二次高斯博弈应用于多机器人交互安全问题，并通过对偶上升算法实现了可证明的收敛性。其重要性在于提供了一种在不确定性下实现安全且高效多机器人轨迹规划的新范式，并且通过与传统方法的对比，展示了其在生成更不保守轨迹方面的优越性。"}}
{"id": "2507.13687", "title": "Robust Probability Hypothesis Density Filtering: Theory and Algorithms", "authors": ["Ming Lei", "Shufan Wu"], "categories": ["eess.SY", "cs.SY", "93C95, 93E35, 93E20", "H.4.1"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      This version is submitted and in review currently", "url": "http://arxiv.org/abs/2507.13687v1", "summary": "Multi-target tracking (MTT) serves as a cornerstone technology in information\nfusion, yet faces significant challenges in robustness and efficiency when\ndealing with model uncertainties, clutter interference, and target\ninteractions. Conventional approaches like Gaussian Mixture PHD (GM-PHD) and\nCardinalized PHD (CPHD) filters suffer from inherent limitations including\ncombinatorial explosion, sensitivity to birth/death process parameters, and\nnumerical instability. This study proposes an innovative minimax robust PHD\nfiltering framework with four key contributions: (1) A theoretically derived\nrobust GM-PHD recursion algorithm that achieves optimal worst-case error\ncontrol under bounded uncertainties; (2) An adaptive real-time parameter\nadjustment mechanism ensuring stability and error bounds; (3) A generalized\nheavy-tailed measurement likelihood function maintaining polynomial\ncomputational complexity; (4) A novel partition-based credibility weighting\nmethod for extended targets. The research not only establishes rigorous\nconvergence guarantees and proves the uniqueness of PHD solutions, but also\nverifies algorithmic equivalence with standard GM-PHD. Experimental results\ndemonstrate that in high-clutter environments, this method achieves a\nremarkable 32.4% reduction in OSPA error and 25.3% lower cardinality RMSE\ncompared to existing techniques, while maintaining real-time processing\ncapability at 15.3 milliseconds per step. This breakthrough lays a crucial\nfoundation for reliable MTT in safety-critical applications.", "comment": "This version is submitted and in review currently", "pdf_url": "http://arxiv.org/pdf/2507.13687v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "鲁棒概率假设密度滤波：理论与算法", "tldr": "提出一种新的鲁棒PHD滤波框架，有效解决了多目标跟踪中的不确定性、杂波和目标交互问题，显著提高了跟踪精度和实时性。", "motivation": "多目标跟踪（MTT）在信息融合中面临鲁棒性和效率挑战，尤其是在模型不确定性、杂波干扰和目标交互下。传统方法如高斯混合PHD（GM-PHD）和基数PHD（CPHD）滤波器存在固有局限性，包括组合爆炸、对出生/死亡过程参数的敏感性以及数值不稳定性。", "method": "本研究提出了一种创新的极小极大鲁棒PHD滤波框架，具有四项关键贡献：(1) 理论推导的鲁棒GM-PHD递推算法，可在有界不确定性下实现最优最坏情况误差控制；(2) 自适应实时参数调整机制，确保稳定性和误差边界；(3) 广义重尾测量似然函数，保持多项式计算复杂度；(4) 针对扩展目标的新型基于分区的可信度加权方法。研究还建立了严格的收敛性保证，证明了PHD解的唯一性，并验证了与标准GM-PHD的算法等效性。", "result": "实验结果表明，在高杂波环境中，该方法与现有技术相比，OSPA误差降低32.4%，基数RMSE降低25.3%，同时保持每步15.3毫秒的实时处理能力。", "conclusion": "该突破为安全关键应用中的可靠多目标跟踪奠定了关键基础。", "translation": "多目标跟踪（MTT）是信息融合中的一项基石技术，但在处理模型不确定性、杂波干扰和目标交互时，其鲁棒性和效率面临重大挑战。高斯混合PHD（GM-PHD）和基数PHD（CPHD）等传统方法存在固有的局限性，包括组合爆炸、对出生/死亡过程参数的敏感性以及数值不稳定性。本研究提出了一种创新的极小极大鲁棒PHD滤波框架，具有四项关键贡献：(1) 一种理论推导的鲁棒GM-PHD递推算法，可在有界不确定性下实现最优最坏情况误差控制；(2) 一种自适应实时参数调整机制，确保稳定性和误差边界；(3) 一种广义重尾测量似然函数，保持多项式计算复杂度；(4) 一种针对扩展目标的新型基于分区的可信度加权方法。该研究不仅建立了严格的收敛性保证并证明了PHD解的唯一性，还验证了与标准GM-PHD的算法等效性。实验结果表明，在高杂波环境中，该方法与现有技术相比，OSPA误差降低了32.4%，基数RMSE降低了25.3%，同时保持每步15.3毫秒的实时处理能力。这一突破为安全关键应用中的可靠MTT奠定了关键基础。", "summary": "本文提出一种创新的极小极大鲁棒概率假设密度（PHD）滤波框架，以解决多目标跟踪（MTT）在不确定性、杂波和目标交互方面的鲁棒性与效率挑战。该框架引入了理论鲁棒GM-PHD算法、自适应参数调整、广义重尾测量似然函数和分区可信度加权方法。实验证明，在高杂波环境下，该方法显著降低了OSPA误差和基数RMSE，并保持实时处理能力，为安全关键MTT应用提供了可靠基础。", "keywords": "多目标跟踪, 概率假设密度滤波, 鲁棒性, 不确定性, 杂波抑制", "comments": "这项研究通过引入极小极大鲁棒性，显著提升了PHD滤波在复杂多目标跟踪环境下的性能。其创新点在于理论上推导了鲁棒GM-PHD算法，并结合了实用机制（如自适应参数调整和重尾似然函数），解决了传统PHD方法的局限性。实验结果的量化改进（OSPA误差和基数RMSE的降低）以及实时处理能力的保持，凸显了其在安全关键应用中的重要价值。"}}
{"id": "2507.14050", "title": "Foundation Models as Class-Incremental Learners for Dermatological Image Classification", "authors": ["Mohamed Elkhayat", "Mohamed Mahmoud", "Jamil Fayyad", "Nourhan Bayasi"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Accepted at the MICCAI EMERGE 2025 workshop", "url": "http://arxiv.org/abs/2507.14050v1", "summary": "Class-Incremental Learning (CIL) aims to learn new classes over time without\nforgetting previously acquired knowledge. The emergence of foundation models\n(FM) pretrained on large datasets presents new opportunities for CIL by\noffering rich, transferable representations. However, their potential for\nenabling incremental learning in dermatology remains largely unexplored. In\nthis paper, we systematically evaluate frozen FMs pretrained on large-scale\nskin lesion datasets for CIL in dermatological disease classification. We\npropose a simple yet effective approach where the backbone remains frozen, and\na lightweight MLP is trained incrementally for each task. This setup achieves\nstate-of-the-art performance without forgetting, outperforming regularization,\nreplay, and architecture based methods. To further explore the capabilities of\nfrozen FMs, we examine zero training scenarios using nearest mean classifiers\nwith prototypes derived from their embeddings. Through extensive ablation\nstudies, we demonstrate that this prototype based variant can also achieve\ncompetitive results. Our findings highlight the strength of frozen FMs for\ncontinual learning in dermatology and support their broader adoption in real\nworld medical applications. Our code and datasets are available here.", "comment": "Accepted at the MICCAI EMERGE 2025 workshop", "pdf_url": "http://arxiv.org/pdf/2507.14050v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基础模型作为皮肤病图像分类的类增量学习器", "tldr": "本文研究了预训练的基础模型在皮肤病图像分类的类增量学习中的潜力，提出了一种冻结主干网络并增量训练轻量级MLP的简单方法，实现了最先进的性能，并探讨了基于原型的零训练场景。", "motivation": "类增量学习（CIL）旨在持续学习新类别而不遗忘旧知识。基础模型（FM）提供了丰富的可迁移表示，为CIL带来了新机遇，但其在皮肤病学增量学习中的潜力尚未被充分探索。", "method": "本文系统评估了在大规模皮肤病变数据集上预训练的冻结基础模型在皮肤病疾病分类CIL中的应用。提出了一种简单有效的方法：主干网络保持冻结，而一个轻量级多层感知器（MLP）针对每个任务进行增量训练。此外，还通过使用从嵌入中导出的原型进行最近平均分类器，探索了零训练场景。", "result": "所提出的方法在不遗忘的情况下实现了最先进的性能，优于基于正则化、重放和架构的方法。基于原型的零训练变体也取得了有竞争力的结果。", "conclusion": "研究结果突出了冻结基础模型在皮肤病学持续学习中的强大能力，并支持它们在现实世界医疗应用中的更广泛采用。", "translation": "类增量学习（CIL）旨在随着时间的推移学习新类别，同时不忘记先前获得的知识。在大型数据集上预训练的基础模型（FM）的出现，通过提供丰富、可迁移的表示，为CIL带来了新的机遇。然而，它们在皮肤病学中实现增量学习的潜力在很大程度上仍未被探索。在本文中，我们系统地评估了在大规模皮肤病变数据集上预训练的冻结基础模型在皮肤病疾病分类的CIL中的应用。我们提出了一种简单而有效的方法，其中主干网络保持冻结，并为每个任务增量训练一个轻量级MLP。这种设置在不遗忘的情况下实现了最先进的性能，优于基于正则化、重放和架构的方法。为了进一步探索冻结基础模型的能力，我们研究了使用从其嵌入中导出的原型进行最近平均分类器的零训练场景。通过广泛的消融研究，我们证明了这种基于原型的变体也能取得有竞争力的结果。我们的发现突出了冻结基础模型在皮肤病学持续学习中的强大能力，并支持它们在现实世界医疗应用中的更广泛采用。我们的代码和数据集可在此处获取。", "summary": "本文探讨了预训练的基础模型在皮肤病图像分类的类增量学习（CIL）中的应用潜力。研究人员系统评估了冻结的基础模型，并提出了一种创新的方法：保持基础模型主干网络冻结，并增量训练一个轻量级MLP。该方法在不遗忘的情况下取得了最先进的性能，超越了现有方法。此外，研究还探索了基于原型的零训练方案，同样取得了有竞争力的结果。这些发现强调了冻结基础模型在皮肤病学持续学习中的强大作用，并为其在实际医疗领域的广泛应用提供了支持。", "keywords": "类增量学习, 基础模型, 皮肤病图像分类, 持续学习, 冻结模型", "comments": "本文的创新点在于系统性地探索了预训练的冻结基础模型在医疗图像（特别是皮肤病学）类增量学习中的应用，并提出了一种简单高效的“冻结主干+轻量级MLP”策略。其重要性在于证明了大型预训练模型在特定领域持续学习中的强大迁移能力，解决了传统CIL方法中遗忘和模型复杂性问题。此外，探索零训练场景进一步拓展了基础模型的应用潜力，对于资源受限的医疗环境具有实际意义。"}}
{"id": "2507.13413", "title": "LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data", "authors": ["Aleksey Lapin", "Igor Hromov", "Stanislav Chumakov", "Mile Mitrovic", "Dmitry Simakov", "Nikolay O. Nikitin", "Andrey V. Savchenko"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 2 figures", "url": "http://arxiv.org/abs/2507.13413v1", "summary": "AutoML has advanced in handling complex tasks using the integration of LLMs,\nyet its efficiency remains limited by dependence on specific underlying tools.\nIn this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for\ntasks with tabular data, which combines an LLM-based code generation with\nseveral AutoML tools. Our approach improves the flexibility and robustness of\npipeline design, outperforming state-of-the-art open-source solutions on\nseveral data science tasks from Kaggle. The code of LightAutoDS-Tab is\navailable in the open repository https://github.com/sb-ai-lab/LADS", "comment": "11 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.13413v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "LightAutoDS-Tab：用于表格数据的多AutoML智能体系统", "tldr": "LightAutoDS-Tab是一个结合LLM代码生成和多个AutoML工具的多AutoML智能体系统，旨在提高表格数据任务的灵活性和鲁棒性，并在Kaggle任务上超越了现有SOTA开源方案。", "motivation": "AutoML在处理复杂任务方面取得了进展，但其效率仍受限于对特定底层工具的依赖。", "method": "本文介绍了LightAutoDS-Tab，一个用于表格数据任务的多AutoML智能体系统，它将基于LLM的代码生成与多个AutoML工具相结合。", "result": "LightAutoDS-Tab的方法提高了管道设计的灵活性和鲁棒性，并在Kaggle的多个数据科学任务上超越了最先进的开源解决方案。", "conclusion": "LightAutoDS-Tab通过结合LLM代码生成和多个AutoML工具，为表格数据任务提供了一个更灵活、更鲁棒的AutoML解决方案，并在实际任务中表现出色。", "translation": "AutoML在利用大型语言模型（LLMs）处理复杂任务方面取得了进展，但其效率仍然受限于对特定底层工具的依赖。在本文中，我们引入了LightAutoDS-Tab，一个用于表格数据任务的多AutoML智能体系统，它将基于LLM的代码生成与多个AutoML工具相结合。我们的方法提高了管道设计的灵活性和鲁棒性，并在Kaggle的多个数据科学任务上超越了最先进的开源解决方案。LightAutoDS-Tab的代码可在开放仓库https://github.com/sb-ai-lab/LADS中获取。", "summary": "本文介绍了LightAutoDS-Tab，一个为表格数据任务设计的多AutoML智能体系统。该系统通过结合LLM的代码生成能力和多种AutoML工具，旨在解决传统AutoML对特定工具依赖的效率限制。实验结果表明，LightAutoDS-Tab在管道设计上展现出更强的灵活性和鲁棒性，并在Kaggle的多个数据科学任务中优于现有的最先进开源解决方案。", "keywords": "AutoML, 表格数据, LLM, 智能体系统, 数据科学", "comments": "该论文的创新点在于结合了LLM的代码生成能力与多个AutoML工具，形成一个“智能体系统”来处理表格数据，这有望提高AutoML的适应性和性能。其重要性在于提供了一种更灵活、更鲁棒的AutoML解决方案，可能对数据科学实践产生积极影响。"}}
{"id": "2507.13475", "title": "Expansive Natural Neural Gradient Flows for Energy Minimization", "authors": ["Wolfgang Dahmen", "Wuchen Li", "Yuankai Teng", "Zhu Wang"], "categories": ["math.OC", "cs.NA", "math.NA", "65K10, 68T07"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      40 pages, 19 figures", "url": "http://arxiv.org/abs/2507.13475v1", "summary": "This paper develops expansive gradient dynamics in deep neural\nnetwork-induced mapping spaces. Specifically, we generate tools and concepts\nfor minimizing a class of energy functionals in an abstract Hilbert space\nsetting covering a wide scope of applications such as PDEs-based inverse\nproblems and supervised learning. The approach hinges on a Hilbert space metric\nin the full diffeomorphism mapping space, which could be viewed as a\ngeneralized Wasserstein-2 metric. We then study a projection gradient descent\nmethod within deep neural network parameterized sets. More importantly, we\ndevelop an adaptation and expanding strategy to step-by-step enlarge the deep\nneural network structures. In particular, the expansion mechanism aims to\nenhance the alignment of the neural manifold induced natural gradient direction\nas well as possible with the ideal Hilbert space gradient descent direction\nleveraging the fact that we can evaluate projections of the Hilbert space\ngradient. We demonstrate the efficacy of the proposed strategy for several\nsimple model problems for energies arising in the context of supervised\nlearning, model reduction, or inverse problems. In particular, we highlight the\nimportance of assembling the neural flow matrix based on the inner product for\nthe ambient Hilbert space. The actual algorithms are the simplest\nspecifications of a broader spectrum based on a correspondingly wider\ndiscussion, postponing a detailed analysis to forthcoming work.", "comment": "40 pages, 19 figures", "pdf_url": "http://arxiv.org/pdf/2507.13475v1", "cate": "math.OC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于能量最小化的扩张自然神经梯度流", "tldr": "本文提出了一种用于深度神经网络的扩张梯度动力学，以在希尔伯特空间中最小化能量泛函，通过逐步扩大网络结构，在监督学习、模型降维和逆问题中展示了其有效性。", "motivation": "本文旨在开发深度神经网络诱导映射空间中的扩张梯度动力学，并为在抽象希尔伯特空间设置中最小化一类能量泛函提供工具和概念，该设置涵盖了基于偏微分方程的逆问题和监督学习等广泛应用。", "method": "该方法依赖于全微分同胚映射空间中的希尔伯特空间度量（可视为广义Wasserstein-2度量）。研究了深度神经网络参数化集内的投影梯度下降方法。更重要的是，开发了一种适应和扩张策略，以逐步扩大深度神经网络结构，旨在增强神经流形诱导的自然梯度方向与理想希尔伯特空间梯度下降方向的对齐。强调了基于环境希尔伯特空间内积组装神经流矩阵的重要性。", "result": "所提出的策略在监督学习、模型降维或逆问题背景下出现的能量的一些简单模型问题中表现出有效性。", "conclusion": "该论文展示了所提出策略在监督学习、模型降维或逆问题背景下能量最小化方面的有效性，并强调了基于环境希尔伯特空间内积组装神经流矩阵的重要性。", "translation": "本文研究了深度神经网络诱导映射空间中的扩张梯度动力学。具体而言，我们开发了工具和概念，用于在抽象希尔伯特空间设置中最小化一类能量泛函，该设置涵盖了广泛的应用范围，例如基于偏微分方程的逆问题和监督学习。该方法依赖于全微分同胚映射空间中的希尔伯特空间度量，这可以被视为广义Wasserstein-2度量。然后，我们研究了深度神经网络参数化集内的投影梯度下降方法。更重要的是，我们开发了一种适应和扩张策略，以逐步扩大深度神经网络结构。特别是，扩张机制旨在利用可以评估希尔伯特空间梯度投影的事实，尽可能增强神经流形诱导的自然梯度方向与理想希尔伯特空间梯度下降方向的对齐。我们证明了所提出策略对于监督学习、模型降维或逆问题背景下出现的能量的一些简单模型问题的有效性。特别是，我们强调了基于环境希尔伯特空间内积组装神经流矩阵的重要性。实际算法是基于相应更广泛讨论的更广泛范围的最简单规范，详细分析将推迟到后续工作中。", "summary": "本文提出了一种用于深度神经网络的扩张梯度动力学，旨在抽象希尔伯特空间中最小化能量泛函，适用于逆问题和监督学习。该方法利用类广义Wasserstein-2的希尔伯特空间度量和投影梯度下降法。一个关键创新是神经网络结构的自适应扩张策略，旨在使自然梯度与理想希尔伯特空间梯度对齐。论文在监督学习、模型降维和逆问题中展示了该策略的有效性，并强调了神经流矩阵组装的重要性。", "keywords": "扩张自然神经梯度流, 能量最小化, 希尔伯特空间, 深度神经网络, 自适应扩张策略", "comments": "这篇论文通过在希尔伯特空间框架内开发扩张梯度动力学，为深度学习中的能量最小化引入了一种创新方法。其核心新颖之处在于神经网络结构的自适应扩张策略，旨在改善自然梯度与理想希尔伯特空间梯度的对齐。该方法在包括逆问题和监督学习在内的各种应用中显示出潜力。需要注意的是，文中提出的算法是简化版本，更详细的分析将推迟到未来的工作中，这表明这是一项基础性研究。"}}
{"id": "2507.13408", "title": "A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs", "authors": ["Hemanth Kumar M", "Karthika M", "Saianiruth M", "Vasanthakumar Venugopal", "Anandakumar D", "Revathi Ezhumalai", "Charulatha K", "Kishore Kumar J", "Dayana G", "Kalyan Sivasailam", "Bargava Subramanian"], "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      12 pages, 2 figures", "url": "http://arxiv.org/abs/2507.13408v1", "summary": "Background: Shoulder fractures are often underdiagnosed, especially in\nemergency and high-volume clinical settings. Studies report up to 10% of such\nfractures may be missed by radiologists. AI-driven tools offer a scalable way\nto assist early detection and reduce diagnostic delays. We address this gap\nthrough a dedicated AI system for shoulder radiographs. Methods: We developed a\nmulti-model deep learning system using 10,000 annotated shoulder X-rays.\nArchitectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and\nRF-DETR. To enhance detection, we applied bounding box and classification-level\nensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW\nensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming\nindividual models across all key metrics. It demonstrated strong recall and\nlocalization precision, confirming its effectiveness for clinical fracture\ndetection in shoulder X-rays. Conclusion: The results show ensemble-based AI\ncan reliably detect shoulder fractures in radiographs with high clinical\nrelevance. The model's accuracy and deployment readiness position it well for\nintegration into real-time diagnostic workflows. The current model is limited\nto binary fracture detection, reflecting its design for rapid screening and\ntriage support rather than detailed orthopedic classification.", "comment": "12 pages, 2 figures", "pdf_url": "http://arxiv.org/pdf/2507.13408v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "一种基于深度学习集成系统的临床X射线肩部骨折自动检测", "tldr": "该研究开发了一种基于深度学习的集成系统，用于在临床X射线上自动检测肩部骨折，并在准确性和F1分数上取得了优异的表现。", "motivation": "肩部骨折在急诊和高流量临床环境中经常被漏诊，可能导致高达10%的骨折被放射科医生遗漏。AI驱动的工具可以提供一种可扩展的方式来协助早期检测并减少诊断延迟，因此需要开发一个专门的AI系统来解决这一空白。", "method": "研究开发了一个多模型深度学习系统，使用了10,000张标注的肩部X射线图像。所使用的架构包括Faster R-CNN（ResNet50-FPN、ResNeXt）、EfficientDet和RF-DETR。为了增强检测能力，应用了边界框和分类级别的集成技术，如Soft-NMS、WBF和NMW融合。", "result": "NMW集成系统在所有关键指标上均优于单个模型，实现了95.5%的准确率和0.9610的F1分数。它表现出强大的召回率和定位精度，证实了其在肩部X射线临床骨折检测中的有效性。", "conclusion": "基于集成AI的系统能够可靠地检测X射线上的肩部骨折，具有高度的临床相关性。该模型的准确性和部署就绪性使其非常适合集成到实时诊断工作流程中。当前模型仅限于二元骨折检测，旨在支持快速筛查和分诊，而非详细的骨科分类。", "translation": "背景：肩部骨折经常被漏诊，尤其是在急诊和高流量临床环境中。研究报告称，放射科医生可能会漏诊高达10%的此类骨折。AI驱动的工具提供了一种可扩展的方式，以协助早期检测并减少诊断延迟。我们通过一个专门针对肩部X射线的AI系统来弥补这一空白。方法：我们开发了一个多模型深度学习系统，使用了10,000张标注的肩部X射线图像。所使用的架构包括Faster R-CNN（ResNet50-FPN、ResNeXt）、EfficientDet和RF-DETR。为了增强检测能力，我们应用了边界框和分类级别的集成技术，如Soft-NMS、WBF和NMW融合。结果：NMW集成系统实现了95.5%的准确率和0.9610的F1分数，在所有关键指标上均优于单个模型。它表现出强大的召回率和定位精度，证实了其在肩部X射线临床骨折检测中的有效性。结论：结果表明，基于集成的AI系统能够可靠地检测X射线上的肩部骨折，具有高度的临床相关性。该模型的准确性和部署就绪性使其非常适合集成到实时诊断工作流程中。当前模型仅限于二元骨折检测，这反映了其设计目的是为了快速筛查和分诊支持，而非详细的骨科分类。", "summary": "本研究旨在解决肩部骨折在临床X射线中高漏诊率的问题，开发了一个基于多模型深度学习的集成系统，用于自动检测肩部骨折。该系统利用了Faster R-CNN、EfficientDet和RF-DETR等多种架构，并结合了Soft-NMS、WBF和NMW等集成技术。实验结果表明，NMW集成系统在准确率和F1分数上均表现出色，优于单一模型，证明了其在临床应用中的有效性和部署潜力。然而，该模型目前仅限于二元骨折检测，主要用于快速筛查和分诊支持。", "keywords": "深度学习, 肩部骨折检测, 集成系统, 放射科, X射线", "comments": "该论文提出了一种创新的深度学习集成方法来解决肩部骨折漏诊的临床挑战，其在准确性和F1分数上的优异表现展示了AI在辅助诊断方面的巨大潜力。该系统的部署就绪性是其重要优势，预示着其可能被集成到实际医疗工作流程中。然而，论文也明确指出了其局限性，即目前仅支持二元骨折检测，未能提供详细的骨科分类，这限制了其在更复杂诊断场景中的应用。未来的工作可以考虑扩展其分类能力。"}}
{"id": "2507.13526", "title": "Space Shift Keying-Enabled ISAC for Efficient Debris Detection and Communication in LEO Satellite Networks", "authors": ["Gedeon Ghislain Nkwewo Ngoufo", "Khaled Humadi", "Elham Baladi", "Gunes Karabulut Kurt"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13526v1", "summary": "The proliferation of space debris in low Earth orbit (LEO) presents critical\nchallenges for orbital safety, particularly for satellite constellations.\nIntegrated sensing and communication (ISAC) systems provide a promising dual\nfunction solution by enabling both environmental sensing and data\ncommunication. This study explores the use of space shift keying (SSK)\nmodulation within ISAC frameworks, evaluating its performance when combined\nwith sinusoidal and chirp radar waveforms. SSK is particularly attractive due\nto its low hardware complexity and robust communication performance. Our\nresults demonstrate that both waveforms achieve comparable bit error rate (BER)\nperformance under SSK, validating its effectiveness for ISAC applications.\nHowever, waveform selection significantly affects sensing capability: while the\nsinusoidal waveform supports simpler implementation, its high ambiguity limits\nrange detection. In contrast, the chirp waveform enables range estimation and\nprovides a modest improvement in velocity detection accuracy. These findings\nhighlight the strength of SSK as a modulation scheme for ISAC and emphasize the\nimportance of selecting appropriate waveforms to optimize sensing accuracy\nwithout compromising communication performance. This insight supports the\ndesign of efficient and scalable ISAC systems for space applications,\nparticularly in the context of orbital debris monitoring.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13526v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "基于空间移位键控的ISAC在低地球轨道卫星网络中实现高效碎片检测与通信", "tldr": "本研究探讨了在低地球轨道卫星网络中，利用空间移位键控（SSK）调制结合集成传感与通信（ISAC）系统，实现高效空间碎片检测和数据通信。结果表明SSK在通信性能上表现良好，但传感能力受雷达波形选择影响显著，其中Chirp波形在测距方面表现更优。", "motivation": "低地球轨道（LEO）空间碎片的增多对轨道安全构成了严峻挑战，特别是对卫星星座而言。集成传感与通信（ISAC）系统提供了一种有前景的双功能解决方案，可以同时实现环境感知和数据通信。", "method": "本研究探索了在ISAC框架内使用空间移位键控（SSK）调制，并评估了其与正弦波和Chirp雷达波形结合时的性能。通过比较两种波形在SSK下的误码率（BER）性能以及对传感能力（测距和速度检测）的影响进行评估。", "result": "在SSK调制下，正弦波和Chirp波形在误码率（BER）方面表现相当，验证了SSK在ISAC应用中的有效性。然而，波形选择显著影响传感能力：正弦波支持更简单的实现，但其高模糊度限制了测距；相比之下，Chirp波形能够实现测距，并略微提高了速度检测精度。", "conclusion": "研究结果突出了SSK作为ISAC调制方案的优势，并强调了选择合适波形以优化传感精度而不损害通信性能的重要性。这些见解支持了为空间应用，特别是在轨道碎片监测背景下，设计高效且可扩展的ISAC系统。", "translation": "低地球轨道（LEO）空间碎片的增多对轨道安全构成了严峻挑战，特别是对卫星星座而言。集成传感与通信（ISAC）系统提供了一种有前景的双功能解决方案，可以同时实现环境感知和数据通信。本研究探索了在ISAC框架内使用空间移位键控（SSK）调制，并评估了其与正弦波和Chirp雷达波形结合时的性能。SSK因其低硬件复杂度和鲁棒的通信性能而特别具有吸引力。我们的结果表明，两种波形在SSK下都达到了可比的误码率（BER）性能，验证了其在ISAC应用中的有效性。然而，波形选择显著影响传感能力：虽然正弦波支持更简单的实现，但其高模糊度限制了测距。相比之下，Chirp波形能够实现测距，并略微提高了速度检测精度。这些发现突出了SSK作为ISAC调制方案的优势，并强调了选择合适波形以优化传感精度而不损害通信性能的重要性。这一见解支持了为空间应用，特别是在轨道碎片监测背景下，设计高效且可扩展的ISAC系统。", "summary": "本研究探讨了在低地球轨道（LEO）卫星网络中，利用集成传感与通信（ISAC）系统结合空间移位键控（SSK）调制，以应对空间碎片检测和通信需求。研究评估了SSK与正弦波和Chirp雷达波形结合的性能。结果显示，SSK在通信方面表现稳健，但传感能力（如测距和速度检测）受到波形选择的显著影响，其中Chirp波形在测距方面表现更优。这些发现强调了SSK在ISAC中的潜力以及波形选择对优化传感精度的关键作用，为未来高效的轨道碎片监测系统设计提供了指导。", "keywords": "空间移位键控, 集成传感与通信, 空间碎片检测, 低地球轨道, 雷达波形", "comments": "该论文创新性地将空间移位键控（SSK）引入到集成传感与通信（ISAC）系统中，用于低地球轨道（LEO）的空间碎片检测和通信，解决了硬件复杂性和性能平衡的问题。其重要性在于为未来LEO卫星星座的轨道安全提供了潜在的高效解决方案。研究不仅验证了SSK在ISAC中的可行性，还深入分析了不同雷达波形对传感能力的影响，为系统设计者提供了宝贵的实践指导。"}}
{"id": "2406.00826", "title": "Policy Verification in Stochastic Dynamical Systems Using Logarithmic Neural Certificates", "authors": ["Thom Badings", "Wietze Koops", "Sebastian Junges", "Nils Jansen"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Extended version (with appendix) of the paper presented at CAV 2025", "url": "http://arxiv.org/abs/2406.00826v4", "summary": "We consider the verification of neural network policies for discrete-time\nstochastic systems with respect to reach-avoid specifications. We use a\nlearner-verifier procedure that learns a certificate for the specification,\nrepresented as a neural network. Verifying that this neural network certificate\nis a so-called reach-avoid supermartingale (RASM) proves the satisfaction of a\nreach-avoid specification. Existing approaches for such a verification task\nrely on computed Lipschitz constants of neural networks. These approaches\nstruggle with large Lipschitz constants, especially for reach-avoid\nspecifications with high threshold probabilities. We present two key\ncontributions to obtain smaller Lipschitz constants than existing approaches.\nFirst, we introduce logarithmic RASMs (logRASMs), which take exponentially\nsmaller values than RASMs and hence have lower theoretical Lipschitz constants.\nSecond, we present a fast method to compute tighter upper bounds on Lipschitz\nconstants based on weighted norms. Our empirical evaluation shows we can\nconsistently verify the satisfaction of reach-avoid specifications with\nprobabilities as high as 99.9999%.", "comment": "Extended version (with appendix) of the paper presented at CAV 2025", "pdf_url": "http://arxiv.org/pdf/2406.00826v4", "cate": "cs.LG", "date": "2024-06-02", "updated": "2025-07-18", "AI": {"title_translation": "随机动力系统中基于对数神经网络凭证的策略验证", "tldr": "本文通过引入对数避险超鞅（logRASM）和基于加权范数计算更紧密Lipschitz常数上界的方法，解决了现有随机系统神经网络策略验证中Lipschitz常数过大导致的问题，并能成功验证高概率的避险可达性规范。", "motivation": "现有用于验证随机系统中神经网络策略的避险可达性规范的方法依赖于计算神经网络的Lipschitz常数，但这些方法难以处理大的Lipschitz常数，尤其是在高阈值概率的避险可达性规范下。", "method": "本文提出了两项关键贡献以获得比现有方法更小的Lipschitz常数。首先，引入了对数避险超鞅（logRASM），其取值比避险超鞅（RASM）指数级小，从而具有更低的理论Lipschitz常数。其次，提出了一种基于加权范数计算更紧密Lipschitz常数上界的快速方法。", "result": "经验评估表明，该方法能够持续验证概率高达99.9999%的避险可达性规范的满足性。", "conclusion": "通过引入对数避险超鞅和改进的Lipschitz常数计算方法，本文有效解决了现有方法在验证随机系统高概率避险可达性规范时的局限性，实现了高精度的策略验证。", "translation": "我们考虑对离散时间随机系统中的神经网络策略进行避险可达性规范的验证。我们使用一个学习器-验证器过程，该过程学习规范的凭证，并将其表示为一个神经网络。验证这个神经网络凭证是否是一个所谓的避险超鞅（RASM）可以证明避险可达性规范的满足性。现有用于此类验证任务的方法依赖于计算神经网络的Lipschitz常数。这些方法难以处理大的Lipschitz常数，特别是对于具有高阈值概率的避险可达性规范。我们提出了两项关键贡献，以获得比现有方法更小的Lipschitz常数。首先，我们引入了对数避险超鞅（logRASM），其取值比RASM指数级小，因此具有更低的理论Lipschitz常数。其次，我们提出了一种基于加权范数计算更紧密Lipschitz常数上界的快速方法。我们的经验评估表明，我们能够持续验证概率高达99.9999%的避险可达性规范的满足性。", "summary": "本文提出了一种针对离散时间随机系统中神经网络策略的避险可达性规范验证方法。通过引入对数避险超鞅（logRASM）和基于加权范数计算更紧密Lipschitz常数上界的方法，解决了现有方法在处理高概率阈值时因Lipschitz常数过大而遇到的困难。实验结果表明，该方法能够成功验证高达99.9999%概率的避险可达性规范。", "keywords": "策略验证, 随机系统, 神经网络, Lipschitz常数, 避险超鞅", "comments": "本文的创新点在于引入了对数避险超鞅（logRASM）和改进的Lipschitz常数计算方法，有效地解决了现有方法在高概率避险可达性验证中面临的Lipschitz常数过大问题。这对于提升随机系统神经网络策略验证的效率和准确性具有重要意义，尤其是在需要高置信度验证的安全性关键应用中。"}}
{"id": "2507.08924", "title": "From KMMLU-Redux to KMMLU-Pro: A Professional Korean Benchmark Suite for LLM Evaluation", "authors": ["Seokhee Hong", "Sunkyoung Kim", "Guijin Son", "Soyeon Kim", "Yeonjung Hong", "Jinsik Lee"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.08924v2", "summary": "The development of Large Language Models (LLMs) requires robust benchmarks\nthat encompass not only academic domains but also industrial fields to\neffectively evaluate their applicability in real-world scenarios. In this\npaper, we introduce two Korean expert-level benchmarks. KMMLU-Redux,\nreconstructed from the existing KMMLU, consists of questions from the Korean\nNational Technical Qualification exams, with critical errors removed to enhance\nreliability. KMMLU-Pro is based on Korean National Professional Licensure exams\nto reflect professional knowledge in Korea. Our experiments demonstrate that\nthese benchmarks comprehensively represent industrial knowledge in Korea. We\nrelease our dataset publicly available.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.08924v2", "cate": "cs.CL", "date": "2025-07-11", "updated": "2025-07-18", "AI": {"title_translation": "从 KMMLU-Redux 到 KMMLU-Pro：一个用于 LLM 评估的专业韩语基准套件", "tldr": "本文介绍了 KMMLU-Redux 和 KMMLU-Pro，两个新的专业韩语基准测试集，用于评估大型语言模型在韩国工业领域的表现。", "motivation": "大型语言模型（LLM）的开发需要强大的基准测试，不仅要涵盖学术领域，还要涵盖工业领域，以有效评估其在实际场景中的适用性。", "method": "引入了两个韩国专家级基准测试。KMMLU-Redux 从现有 KMMLU 重建，包含韩国国家技术资格考试的问题，并移除了关键错误以提高可靠性。KMMLU-Pro 基于韩国国家专业执照考试，以反映韩国的专业知识。", "result": "实验表明，这些基准测试全面代表了韩国的工业知识。数据集已公开发布。", "conclusion": "本文推出了两个新的、可靠的专业韩语基准测试套件 KMMLU-Redux 和 KMMLU-Pro，用于评估大型语言模型在韩国专业领域的表现。", "translation": "大型语言模型（LLM）的开发需要强大的基准测试，不仅要涵盖学术领域，还要涵盖工业领域，以有效评估其在实际场景中的适用性。在本文中，我们介绍了两个韩国专家级基准测试。KMMLU-Redux 从现有 KMMLU 重建，包含韩国国家技术资格考试的问题，并移除了关键错误以提高可靠性。KMMLU-Pro 基于韩国国家专业执照考试，以反映韩国的专业知识。我们的实验表明，这些基准测试全面代表了韩国的工业知识。我们公开发布了我们的数据集。", "summary": "本文介绍了 KMMLU-Redux 和 KMMLU-Pro，这是两个专为评估大型语言模型在韩国专业和工业领域表现而设计的专家级韩语基准测试套件。KMMLU-Redux 是对现有 KMMLU 的改进，通过移除错误并使用韩国国家技术资格考试问题来增强可靠性；KMMLU-Pro 则基于韩国国家专业执照考试，以反映更深层次的专业知识。实验证明这些基准测试能全面代表韩国的工业知识，并且数据集已公开发布。", "keywords": "LLM评估, 韩语基准, KMMLU, 专业知识, 工业知识", "comments": "这项工作通过创建专门针对韩国专业和工业知识的基准测试，填补了LLM评估领域的一个重要空白。其创新之处在于从实际的国家资格和执照考试中提取内容，并特别强调了错误移除以提高可靠性。这对于评估LLM在特定文化和专业背景下的实际应用能力至关重要，有助于推动LLM在非英语专业领域的落地应用。"}}
{"id": "2507.13528", "title": "Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface", "authors": ["Daniele Masti", "Stefano Menchetti", "Çağrı Erdem", "Giorgio Gnecco", "Davide Rocchesso"], "categories": ["cs.HC", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13528v1", "summary": "TickTacking is a rhythm-based interface that allows users to control a\npointer in a two-dimensional space through dual-button tapping. This paper\ninvestigates the generation of human-like trajectories using a receding horizon\napproach applied to the TickTacking interface in a target-tracking task. By\nanalyzing user-generated trajectories, we identify key human behavioral\nfeatures and incorporate them in a controller that mimics these behaviors. The\nperformance of this human-inspired controller is evaluated against a baseline\noptimal-control-based agent, demonstrating the importance of specific control\nfeatures for achieving human-like interaction. These findings contribute to the\nbroader goal of developing rhythm-based human-machine interfaces by offering\ndesign insights that enhance user performance, improve intuitiveness, and\nreduce interaction frustration", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13528v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "结合TickTacking界面的基于滚动时域跟踪的人类轨迹生成", "tldr": "本文通过滚动时域跟踪方法，在TickTacking界面中生成类人轨迹，并验证了特定控制特性对实现类人交互的重要性。", "motivation": "旨在通过分析用户轨迹并将其行为特征融入控制器中，为节奏型人机界面设计提供洞察，以增强用户性能、提高直观性并减少交互挫败感。", "method": "通过分析用户生成的轨迹，识别关键的人类行为特征，并将其整合到一个模仿这些行为的控制器中。然后，将这个受人类启发的控制器与基于最优控制的基线代理进行评估。", "result": "实验结果表明，特定的控制特性对于实现类人交互至关重要。", "conclusion": "本研究发现为开发节奏型人机界面提供了设计见解，有助于增强用户性能、提高直观性并减少交互挫败感。", "translation": "TickTacking 是一种基于节奏的界面，允许用户通过双按钮点击来控制二维空间中的指针。本文研究了在目标跟踪任务中，将滚动时域方法应用于 TickTacking 界面以生成类人轨迹。通过分析用户生成的轨迹，我们识别出关键的人类行为特征，并将其整合到一个模仿这些行为的控制器中。这个受人类启发的控制器与基于最优控制的基线代理进行了性能评估，证明了特定控制特性对于实现类人交互的重要性。这些发现通过提供增强用户性能、提高直观性和减少交互挫败感的设计见解，为开发基于节奏的人机界面这一更广泛的目标做出了贡献。", "summary": "本文研究了在TickTacking节奏界面中，通过滚动时域跟踪方法生成类人轨迹。研究人员分析了用户轨迹，识别并整合了关键的人类行为特征到一个控制器中，该控制器能模仿这些行为。通过与最优控制代理的对比评估，研究证明了特定控制特性对实现类人交互的重要性，并为节奏型人机界面的设计提供了改进用户体验的见解。", "keywords": "类人轨迹, 滚动时域跟踪, TickTacking界面, 人机交互, 节奏界面", "comments": "这项研究通过将人类行为特征融入控制器设计中，为实现更自然、直观的人机交互提供了新思路。其创新点在于结合了滚动时域跟踪和对人类轨迹的精细分析，旨在弥补传统最优控制在模拟人类行为方面的不足。这项工作对于未来节奏型人机界面的开发具有重要意义，有助于提升用户体验，减少操作学习成本和挫败感。"}}
{"id": "2507.13707", "title": "Learning Deformable Body Interactions With Adaptive Spatial Tokenization", "authors": ["Hao Wang", "Yu Liu", "Daniel Biggs", "Haoru Wang", "Jiandong Yu", "Ping Huang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      21 pages, 15 figures", "url": "http://arxiv.org/abs/2507.13707v1", "summary": "Simulating interactions between deformable bodies is vital in fields like\nmaterial science, mechanical design, and robotics. While learning-based methods\nwith Graph Neural Networks (GNNs) are effective at solving complex physical\nsystems, they encounter scalability issues when modeling deformable body\ninteractions. To model interactions between objects, pairwise global edges have\nto be created dynamically, which is computationally intensive and impractical\nfor large-scale meshes. To overcome these challenges, drawing on insights from\ngeometric representations, we propose an Adaptive Spatial Tokenization (AST)\nmethod for efficient representation of physical states. By dividing the\nsimulation space into a grid of cells and mapping unstructured meshes onto this\nstructured grid, our approach naturally groups adjacent mesh nodes. We then\napply a cross-attention module to map the sparse cells into a compact,\nfixed-length embedding, serving as tokens for the entire physical state.\nSelf-attention modules are employed to predict the next state over these tokens\nin latent space. This framework leverages the efficiency of tokenization and\nthe expressive power of attention mechanisms to achieve accurate and scalable\nsimulation results. Extensive experiments demonstrate that our method\nsignificantly outperforms state-of-the-art approaches in modeling deformable\nbody interactions. Notably, it remains effective on large-scale simulations\nwith meshes exceeding 100,000 nodes, where existing methods are hindered by\ncomputational limitations. Additionally, we contribute a novel large-scale\ndataset encompassing a wide range of deformable body interactions to support\nfuture research in this area.", "comment": "21 pages, 15 figures", "pdf_url": "http://arxiv.org/pdf/2507.13707v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "学习可变形体与自适应空间标记的交互", "tldr": "提出一种名为自适应空间标记（AST）的新方法，通过将非结构化网格映射到结构化网格并结合注意力机制，解决了GNN在模拟大规模可变形体交互时遇到的可扩展性问题，并在大型模拟中表现出色。", "motivation": "模拟可变形体交互在材料科学、机械设计和机器人等领域至关重要。虽然基于GNN的学习方法在解决复杂物理系统方面有效，但它们在建模可变形体交互时遇到可扩展性问题，特别是动态创建全局边计算密集且不适用于大规模网格。", "method": "提出自适应空间标记（AST）方法。通过将模拟空间划分为网格单元，并将非结构化网格映射到此结构化网格上以自然地对相邻网格节点进行分组。然后应用交叉注意力模块将稀疏单元映射到紧凑的固定长度嵌入（作为物理状态的标记），并使用自注意力模块在潜在空间中预测下一个状态。该框架结合了标记化的效率和注意力机制的表达能力。", "result": "实验表明，该方法在建模可变形体交互方面显著优于现有最先进的方法。值得注意的是，它在节点数超过100,000的大规模模拟中仍然有效，而现有方法则受计算限制。此外，还贡献了一个包含各种可变形体交互的新型大规模数据集。", "conclusion": "该论文提出了一种高效且可扩展的自适应空间标记方法，成功解决了GNN在处理大规模可变形体交互时的可扩展性挑战，并在实际应用中取得了优异的性能，为未来研究提供了新数据集。", "translation": "模拟可变形体之间的交互在材料科学、机械设计和机器人等领域至关重要。虽然基于图神经网络（GNN）的学习方法在解决复杂物理系统方面有效，但它们在建模可变形体交互时会遇到可扩展性问题。为了建模物体之间的交互，必须动态创建成对的全局边，这对于大规模网格来说计算密集且不切实际。为了克服这些挑战，我们借鉴几何表示的见解，提出了一种自适应空间标记（AST）方法，用于高效表示物理状态。通过将模拟空间划分为网格单元并将非结构化网格映射到此结构化网格上，我们的方法自然地将相邻网格节点分组。然后，我们应用交叉注意力模块将稀疏单元映射到紧凑的固定长度嵌入，作为整个物理状态的标记。在这些标记上使用自注意力模块来预测潜在空间中的下一个状态。该框架利用标记化的效率和注意力机制的表达能力来实现准确和可扩展的模拟结果。大量实验表明，我们的方法在建模可变形体交互方面显著优于现有最先进的方法。值得注意的是，它在节点数超过100,000的大规模模拟中仍然有效，而现有方法则受计算限制。此外，我们贡献了一个新型大规模数据集，涵盖了广泛的可变形体交互，以支持该领域的未来研究。", "summary": "本文提出了一种名为自适应空间标记（AST）的新方法，旨在解决图神经网络（GNN）在模拟大规模可变形体交互时面临的可扩展性挑战。AST通过将非结构化网格映射到结构化网格单元并利用交叉注意力机制生成固定长度的物理状态标记，随后通过自注意力模块预测下一状态。实验证明，该方法在建模可变形体交互方面显著优于现有技术，尤其在大规模模拟中表现出卓越的效率和准确性，并提供了一个新的大型数据集以促进未来研究。", "keywords": "可变形体交互, 自适应空间标记, 图神经网络, 注意力机制, 物理模拟", "comments": "该论文的创新点在于提出了自适应空间标记（AST）方法，有效地将非结构化网格数据转化为结构化标记，并通过结合注意力机制克服了传统GNN在处理大规模可变形体交互时的计算瓶颈。其重要性在于实现了大规模物理模拟的可扩展性和效率，并为相关领域的研究提供了新的数据集，具有重要的实际应用价值。"}}
{"id": "2507.13880", "title": "Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision", "authors": ["Marten Kreis", "Benjamin Kiefer"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13880v1", "summary": "This paper presents a novel approach to enhancing marine vision by fusing\nreal-time visual data with chart information. Our system overlays nautical\nchart data onto live video feeds by accurately matching detected navigational\naids, such as buoys, with their corresponding representations in chart data. To\nachieve robust association, we introduce a transformer-based end-to-end neural\nnetwork that predicts bounding boxes and confidence scores for buoy queries,\nenabling the direct matching of image-domain detections with world-space chart\nmarkers. The proposed method is compared against baseline approaches, including\na ray-casting model that estimates buoy positions via camera projection and a\nYOLOv7-based network extended with a distance estimation module. Experimental\nresults on a dataset of real-world maritime scenes demonstrate that our\napproach significantly improves object localization and association accuracy in\ndynamic and challenging environments.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13880v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "实时融合视觉与海图数据以增强海上视野", "tldr": "本文提出了一种新颖的方法，通过融合实时视觉数据和海图信息来增强海洋视野，利用基于Transformer的神经网络实现航标的精确匹配和定位，并在真实海上场景数据集中取得了显著改进。", "motivation": "增强海洋视野，通过融合实时视觉数据和海图信息来提高海事场景中物体定位和关联的准确性。", "method": "本系统通过精确匹配检测到的航标（如浮标）与海图数据中对应的表示，将海图数据叠加到实时视频流上。引入了一个基于Transformer的端到端神经网络，用于预测浮标查询的边界框和置信度分数，从而实现图像域检测与世界空间海图标记的直接匹配。该方法与基线方法（包括通过摄像机投影估计浮标位置的射线投射模型和带有距离估计模块的YOLOv7网络）进行了比较。", "result": "在真实世界海上场景数据集上的实验结果表明，该方法在动态和挑战性环境中显著提高了物体定位和关联的准确性。", "conclusion": "通过实时融合视觉和海图数据，并利用基于Transformer的神经网络进行精确匹配，本方法能显著增强海上视野并提高物体定位和关联的准确性。", "translation": "本文提出了一种通过融合实时视觉数据与海图信息来增强海洋视野的新方法。我们的系统通过精确匹配检测到的航海辅助设备（如浮标）与海图数据中对应的表示，将海图数据叠加到实时视频流上。为实现鲁棒关联，我们引入了一个基于Transformer的端到端神经网络，该网络预测浮标查询的边界框和置信度分数，从而实现图像域检测与世界空间海图标记的直接匹配。该方法与基线方法进行了比较，包括通过相机投影估计浮标位置的射线投射模型和扩展了距离估计模块的YOLOv7网络。在真实世界海上场景数据集上的实验结果表明，我们的方法在动态和挑战性环境中显著提高了物体定位和关联的准确性。", "summary": "本文提出了一种创新的方法，通过将实时视觉数据与海图信息融合来提升海上视觉能力。该系统利用一个基于Transformer的端到端神经网络，精确匹配视频流中检测到的航标（如浮标）与海图数据，并将其叠加显示。实验证明，该方法在复杂的海上环境中显著提高了目标定位和关联的精度，优于现有基线方法。", "keywords": "海上视野, 视觉融合, 海图数据, Transformer神经网络, 目标定位", "comments": "该论文的创新之处在于提出了一个基于Transformer的端到端神经网络，用于直接匹配图像域检测与世界空间海图标记，实现了视觉数据与海图信息的实时融合，显著提升了海上目标定位和关联的准确性，对于增强海事安全和导航具有重要意义。"}}
{"id": "2505.16119", "title": "Source Separation by Flow Matching", "authors": ["Robin Scheibler", "John R. Hershey", "Arnaud Doucet", "Henry Li"], "categories": ["cs.SD", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "Comments:      5 pages, 3 figures, 2 tables, accepted at WASPAA 2025", "url": "http://arxiv.org/abs/2505.16119v2", "summary": "We consider the problem of single-channel audio source separation with the\ngoal of reconstructing $K$ sources from their mixture. We address this\nill-posed problem with FLOSS (FLOw matching for Source Separation), a\nconstrained generation method based on flow matching, ensuring strict mixture\nconsistency. Flow matching is a general methodology that, when given samples\nfrom two probability distributions defined on the same space, learns an\nordinary differential equation to output a sample from one of the distributions\nwhen provided with a sample from the other. In our context, we have access to\nsamples from the joint distribution of $K$ sources and so the corresponding\nsamples from the lower-dimensional distribution of their mixture. To apply flow\nmatching, we augment these mixture samples with artificial noise components to\nmatch the dimensionality of the $K$ source distribution. Additionally, as any\npermutation of the sources yields the same mixture, we adopt an equivariant\nformulation of flow matching which relies on a neural network architecture that\nis equivariant by design. We demonstrate the performance of the method for the\nseparation of overlapping speech.", "comment": "5 pages, 3 figures, 2 tables, accepted at WASPAA 2025", "pdf_url": "http://arxiv.org/pdf/2505.16119v2", "cate": "cs.SD", "date": "2025-05-22", "updated": "2025-07-18", "AI": {"title_translation": "源分离通过流匹配", "tldr": "提出FLOSS，一种基于流匹配的约束生成方法，用于单通道音频源分离，通过增加噪声和使用等变网络来处理维度不匹配和源置换问题，并在重叠语音分离上表现良好。", "motivation": "解决单通道音频源分离问题，目标是从混合信号中重构K个源。这是一个不适定问题。", "method": "提出FLOSS（FLOw matching for Source Separation），这是一种基于流匹配的约束生成方法，确保严格的混合一致性。流匹配通过学习常微分方程，在给定两个概率分布样本的情况下，从一个分布的样本生成另一个分布的样本。在FLOSS中，通过添加人工噪声分量来匹配K个源分布的维度，并采用等变流匹配公式，依赖于等变设计的神经网络架构，以处理源排列问题。", "result": "该方法在重叠语音分离中表现出良好的性能。", "conclusion": "FLOSS（基于流匹配的源分离方法）能够有效处理单通道音频源分离问题，尤其是在重叠语音分离任务中展现了其有效性。", "translation": "我们考虑单通道音频源分离问题，目标是从混合信号中重构K个源。我们通过FLOSS（FLOw matching for Source Separation）解决这个不适定问题，这是一种基于流匹配的约束生成方法，确保严格的混合一致性。流匹配是一种通用方法，当给定在同一空间上定义的两个概率分布的样本时，它学习一个常微分方程，以便在提供其中一个分布的样本时，输出另一个分布的样本。在我们的上下文中，我们可以访问K个源的联合分布样本，以及它们混合的低维分布的相应样本。为了应用流匹配，我们用人工噪声分量增强这些混合样本，以匹配K个源分布的维度。此外，由于源的任何排列都会产生相同的混合，我们采用了流匹配的等变公式，该公式依赖于等变设计的神经网络架构。我们展示了该方法在重叠语音分离方面的性能。", "summary": "本文提出FLOSS，一种基于流匹配的单通道音频源分离方法。该方法通过引入人工噪声来解决混合信号与源信号维度不匹配的问题，并采用等变流匹配公式和等变神经网络架构来处理源置换不变性。FLOSS是一种约束生成方法，旨在从混合信号中准确重构多个独立源，并在重叠语音分离任务中展现了其有效性。", "keywords": "音频源分离, 流匹配, FLOSS, 等变神经网络, 约束生成", "comments": "本文的创新点在于将流匹配这一通用方法应用于音频源分离，并针对该问题的特性（如维度不匹配和源置换不变性）进行了专门的改进，例如引入人工噪声和采用等变网络。这为解决不适定的源分离问题提供了一种新的、有潜力的生成模型框架。"}}
{"id": "2506.12764", "title": "Base3: a simple interpolation-based ensemble method for robust dynamic link prediction", "authors": ["Kondrup Emma"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 pages", "url": "http://arxiv.org/abs/2506.12764v2", "summary": "Dynamic link prediction remains a central challenge in temporal graph\nlearning, particularly in designing models that are both effective and\npractical for real-world deployment. Existing approaches often rely on complex\nneural architectures, which are computationally intensive and difficult to\ninterpret.\n  In this work, we build on the strong recurrence-based foundation of the\nEdgeBank baseline, by supplementing it with inductive capabilities. We do so by\nleveraging the predictive power of non-learnable signals from two complementary\nperspectives: historical edge recurrence, as captured by EdgeBank, and global\nnode popularity, as introduced in the PopTrack model. We propose t-CoMem, a\nlightweight memory module that tracks temporal co-occurrence patterns and\nneighborhood activity. Building on this, we introduce Base3, an\ninterpolation-based model that fuses EdgeBank, PopTrack, and t-CoMem into a\nunified scoring framework. This combination effectively bridges local and\nglobal temporal dynamics -- repetition, popularity, and context -- without\nrelying on training. Evaluated on the Temporal Graph Benchmark, Base3 achieves\nperformance competitive with state-of-the-art deep models, even outperforming\nthem on some datasets. Importantly, it considerably improves on existing\nbaselines' performance under more realistic and challenging negative sampling\nstrategies -- offering a simple yet robust alternative for temporal graph\nlearning.", "comment": "9 pages", "pdf_url": "http://arxiv.org/pdf/2506.12764v2", "cate": "cs.LG", "date": "2025-06-15", "updated": "2025-07-17", "AI": {"title_translation": "Base3：一种用于鲁棒动态链接预测的简单基于插值的集成方法", "tldr": "Base3是一种不依赖训练的简单插值集成方法，结合了EdgeBank、PopTrack和t-CoMem，在动态链接预测上表现与SOTA深度模型相当，且在挑战性负采样下更鲁棒。", "motivation": "现有动态链接预测方法通常依赖复杂的神经网络架构，计算密集且难以解释，寻找既有效又实用以便于实际部署的模型仍是挑战。", "method": "本文提出了Base3，一种基于插值的模型，它融合了EdgeBank（捕捉历史边复现）、PopTrack（引入全局节点流行度）和t-CoMem（一个轻量级内存模块，跟踪时间共现模式和邻域活动）。Base3将这些非可学习信号整合到一个统一的评分框架中，无需训练即可桥接局部和全局时间动态。", "result": "Base3在时间图基准测试上取得了与最先进的深度模型相当的性能，在某些数据集上甚至超越了它们。重要的是，在更真实和具有挑战性的负采样策略下，它显著改善了现有基线的性能。", "conclusion": "Base3提供了一种简单而鲁棒的替代方案，用于时间图学习中的动态链接预测，通过无训练的插值方法有效结合了重复、流行度和上下文等多种时间动态。", "translation": "动态链接预测仍然是时间图学习中的一个核心挑战，特别是在设计既有效又实用以便于实际部署的模型方面。现有方法通常依赖复杂的神经网络架构，这些架构计算密集且难以解释。\n在这项工作中，我们以EdgeBank基线的强大循环基础为起点，通过补充其归纳能力来构建。我们通过利用来自两个互补视角的不可学习信号的预测能力来实现这一点：由EdgeBank捕获的历史边复现，以及在PopTrack模型中引入的全局节点流行度。我们提出了t-CoMem，一个轻量级内存模块，用于跟踪时间共现模式和邻域活动。在此基础上，我们引入了Base3，一个基于插值的模型，它将EdgeBank、PopTrack和t-CoMem融合到一个统一的评分框架中。这种组合有效地桥接了局部和全局时间动态——重复、流行度和上下文——而无需依赖训练。在时间图基准测试上进行评估，Base3取得了与最先进的深度模型相当的性能，甚至在某些数据集上超越了它们。重要的是，它在更真实和具有挑战性的负采样策略下，显著改善了现有基线的性能——为时间图学习提供了一种简单而鲁棒的替代方案。", "summary": "本文针对动态链接预测中复杂神经网络的计算密集和解释性差问题，提出了Base3模型。Base3是一种基于插值的集成方法，它将EdgeBank（捕捉历史边复现）、PopTrack（引入全局节点流行度）和t-CoMem（跟踪时间共现模式和邻域活动）这三个非可学习信号融合，形成一个无需训练的统一评分框架。实验结果表明，Base3在性能上与现有最先进的深度模型相当，并在挑战性负采样下展现出更强的鲁棒性，为时间图学习提供了一个简单而有效的解决方案。", "keywords": "动态链接预测, 时间图学习, 插值方法, 集成学习, 鲁棒性", "comments": "这篇论文的创新点在于提出了一种无需训练的插值集成方法Base3，有效结合了局部和全局时间动态，避免了复杂神经网络带来的计算负担和解释性问题。其在性能上与SOTA深度模型相当，且在鲁棒性方面表现更优，这对于实际部署具有重要意义。它提供了一个简洁而强大的基线，挑战了深度学习在时间图学习中的主导地位，证明了简单模型在特定场景下的巨大潜力。"}}
{"id": "2507.13601", "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13601v1", "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13601v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "通过可塑任务调度利用多实例GPU", "tldr": "该论文提出了一种名为FAR的三阶段算法，通过动态重新配置来优化NVIDIA MIG上的多任务调度，旨在最小化完工时间，并在实际实验中取得了优于现有技术的良好性能。", "motivation": "NVIDIA MIG（多实例GPU）技术允许将物理GPU划分为多个具有完全隔离资源且可动态重新配置的逻辑实例。这项工作旨在通过可塑任务调度和动态重新配置来发掘MIG未开发的潜力，以解决在MIG约束下多任务执行的完工时间最小化问题。", "method": "该论文提出了一种名为FAR的三阶段算法来解决MIG约束下的多任务执行完工时间最小化问题。FAR的第一阶段基于经典的任务可塑性方法；第二阶段结合了最长处理时间优先（LPTF）和列表调度（List Scheduling），并引入了一种针对MIG约束的新型重新分区树启发式算法；第三阶段则采用任务移动和交换的局部搜索。FAR离线批量调度任务，并通过改进的方式动态连接它们的调度以促进资源重用。", "result": "排除重新配置成本，列表调度证明在NVIDIA A30模型上实现了7/4的近似因子，在NVIDIA A100/H100上实现了2的近似因子。包括重新配置成本在内，实际实验表明，对于知名基准测试套件，相对于最优解，完工时间不低于1.22倍；对于受真实内核启发的合成输入，完工时间不低于1.10倍。该算法在每个任务批次以及批次连接方面都取得了良好的实验结果，相对于现有技术和不进行GPU重新配置的方案有显著改进。", "conclusion": "该论文成功开发并验证了FAR算法，有效利用了NVIDIA MIG的动态重新配置能力，显著优化了多任务调度在MIG环境下的完工时间。研究不仅提供了高效的调度解决方案，还展示了MIG技术的巨大研究潜力，并为未来该领域的工作提出了有用的度量、工作负载特征和评估技术。", "translation": "NVIDIA MIG（多实例GPU）允许将物理GPU划分为多个具有完全隔离资源且可动态重新配置的逻辑实例。这项工作通过动态重新配置的可塑任务调度，突出了MIG未开发的潜力。具体来说，我们提出了在MIG约束下多任务执行的完工时间最小化问题。我们的分析表明，假设任务工作量相对于资源具有单调性是不可行的，这与多核调度中通常的假设不同。我们依赖于一个不需要这种假设的最新提议，提出了FAR，一个三阶段算法来解决这个问题。FAR的第一阶段建立在经典的任务可塑性方法之上，第二阶段结合了最长处理时间优先（Longest Processing Time First）和列表调度（List Scheduling），并结合了一种针对MIG约束的新型重新分区树启发式算法，第三阶段通过任务移动和交换采用局部搜索。FAR离线批量调度任务，并通过改进的方式动态连接它们的调度，以促进资源重用。排除重新配置成本，列表调度证明在NVIDIA A30模型上实现了7/4的近似因子。我们将该技术适应于NVIDIA A100/H100的特定约束，以获得2的近似因子。包括重新配置成本在内，我们的实际实验表明，对于知名基准测试套件，相对于最优解，完工时间不劣于1.22倍，对于受真实内核启发的合成输入，不劣于1.10倍。我们不仅在每个任务批次中，而且在批次连接中都获得了良好的实验结果，相对于现有技术和不进行GPU重新配置的提议有显著改进。除了算法，该论文还展示了MIG技术的研究潜力，并为该领域的未来工作提出了有用的度量、工作负载特征和评估技术。", "summary": "该论文探讨了如何通过可塑任务调度和动态重新配置来充分利用NVIDIA多实例GPU（MIG）的潜力。作者提出了一个在MIG约束下最小化多任务执行完工时间的问题，并开发了三阶段算法FAR。FAR结合了经典任务可塑性、列表调度（包括针对MIG的新型启发式）和局部搜索。实验结果表明，该算法在实际应用中，包括重新配置成本，相对于最优解实现了1.10倍至1.22倍的完工时间，显著优于现有技术和不考虑GPU重新配置的方案。该研究还强调了MIG技术的未来研究价值。", "keywords": "多实例GPU, 任务调度, 完工时间最小化, 动态重新配置, NVIDIA MIG", "comments": "该论文的创新之处在于其提出了一个针对NVIDIA MIG独特动态重新配置能力而设计的任务调度算法FAR，解决了传统多核调度中“任务工作量与资源单调性”假设在MIG环境下不适用的问题。其重要性体现在有效提升了MIG环境下多任务执行的效率，通过实际实验证明了其优越性，并为未来MIG技术的研究方向（如度量、工作负载特征和评估技术）提供了指导。这对于最大化GPU利用率和优化高性能计算具有重要意义。"}}
{"id": "2501.08102", "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media", "authors": ["Wenlu Fan", "Yuqi Zhu", "Chenyang Wang", "Bin Wang", "Wentao Xu"], "categories": ["cs.CL", "cs.AI", "cs.HC"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      This paper has been accepted by the International AAAI Conference on Web and Social Media (ICWSM) 2026(Los Angeles, California, U.S.)", "url": "http://arxiv.org/abs/2501.08102v3", "summary": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.", "comment": "This paper has been accepted by the International AAAI Conference on\n  Web and Social Media (ICWSM) 2026(Los Angeles, California, U.S.)", "pdf_url": "http://arxiv.org/pdf/2501.08102v3", "cate": "cs.CL", "date": "2025-01-14", "updated": "2025-07-18", "AI": {"title_translation": "大型语言模型在社交媒体上生成回复和续写的连贯性", "tldr": "本研究评估了大型语言模型（Gemma和Llama）在社交媒体内容生成中的情感连贯性和语义一致性。结果显示，模型在保持高语义相似度的同时，表现出不同的情绪模式：Gemma倾向于负面情绪放大，而Llama则能更好地保留情绪，且两者生成的回复情绪强度普遍减弱。", "motivation": "大型语言模型（LLMs）在文本生成方面能力显著，但在社交媒体语境下，其情感连贯性和语义一致性仍未得到充分理解。", "method": "本研究使用开源模型Gemma和Llama，通过续写和回复任务，调查LLMs如何处理情感内容并维持语义关系。通过分析Twitter和Reddit上的气候变化讨论，检查了人工创作内容与LLM生成内容之间的情感转变、强度模式和语义相似性。", "result": "研究发现，尽管两种模型都保持了高语义连贯性，但它们表现出不同的情绪模式：Gemma倾向于放大负面情绪，特别是愤怒，但也保持了某些积极情绪如乐观。Llama在更广泛的情感范围内表现出卓越的情绪保留能力。与人工创作内容相比，两种模型生成的回复情绪强度系统性地减弱，并在回复任务中表现出对积极情绪的偏向。此外，两种模型都与原始文本保持了很强的语义相似性，尽管在续写和回复任务中的表现有所不同。", "conclusion": "这些发现提供了关于LLMs情感和语义处理能力的见解，对它们在社交媒体环境中的部署以及人机交互设计具有重要意义。", "translation": "大型语言模型（LLMs）在文本生成方面展现出卓越的能力，但在社交媒体语境下，它们的情感连贯性和语义一致性仍未得到充分理解。本研究通过使用Gemma和Llama两种开源模型，通过续写和回复任务，调查了LLMs如何处理情感内容并维持语义关系。通过分析来自Twitter和Reddit的气候变化讨论，我们检查了人工创作内容与LLM生成内容之间的情感转变、强度模式以及语义相似性。我们的研究结果表明，尽管两种模型都保持了高语义连贯性，但它们表现出不同的情绪模式：Gemma倾向于放大负面情绪，特别是愤怒，同时保持某些积极情绪如乐观。Llama在更广泛的情感范围内表现出卓越的情绪保留能力。与人工创作内容相比，两种模型系统性地生成情绪强度减弱的回复，并在回复任务中表现出对积极情绪的偏向。此外，两种模型都与原始文本保持了很强的语义相似性，尽管在续写和回复任务中的表现有所不同。这些发现提供了关于LLMs情感和语义处理能力的见解，对它们在社交媒体环境中的部署以及人机交互设计具有重要意义。", "summary": "本研究评估了Gemma和Llama大型语言模型在社交媒体语境下的情感连贯性和语义一致性。通过对Twitter和Reddit上气候变化讨论的续写和回复任务分析，发现虽然模型保持了高语义相似度，但在情感处理上存在差异：Gemma倾向于放大负面情绪，而Llama能更好地保留情感。同时，两种模型生成的回复情绪强度普遍减弱，并偏向积极情绪。这些发现为LLMs在社交媒体中的应用和人机交互设计提供了重要见解。", "keywords": "大型语言模型, 情感一致性, 语义连贯性, 社交媒体, 情绪模式", "comments": "本文深入探讨了大型语言模型在社交媒体互动中复杂的情感和语义行为，揭示了模型特有的情绪偏向（如Gemma对愤怒的放大、Llama更好的情绪保留）以及共同的趋势（情绪强度减弱、回复中的积极偏向）。这些发现对于理解LLMs对在线讨论的潜在影响以及开发更具情商的AI至关重要。使用开源模型和真实世界数据（Twitter、Reddit）增加了其在实践中的相关性。"}}
{"id": "2507.14121", "title": "Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical Perspective", "authors": ["Pankaj Yadav", "Vivek Vijay"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      9 Pages, 4 figures", "url": "http://arxiv.org/abs/2507.14121v1", "summary": "Kolmogorov Arnold Networks (KANs) are recent architectural advancement in\nneural computation that offer a mathematically grounded alternative to standard\nneural networks. This study presents an empirical evaluation of KANs in context\nof class imbalanced classification, using ten benchmark datasets. We observe\nthat KANs can inherently perform well on raw imbalanced data more effectively\nthan Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,\nconventional imbalance strategies fundamentally conflict with KANs mathematical\nstructure as resampling and focal loss implementations significantly degrade\nKANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from\nprohibitive computational costs without proportional performance gains.\nStatistical validation confirms that MLPs with imbalance techniques achieve\nequivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.\nThese findings reveal that KANs represent a specialized solution for raw\nimbalanced data where resources permit. But their severe performance-resource\ntradeoffs and incompatibility with standard resampling techniques currently\nlimits practical deployment. We identify critical research priorities as\ndeveloping KAN specific architectural modifications for imbalance learning,\noptimizing computational efficiency, and theoretical reconciling their conflict\nwith data augmentation. This work establishes foundational insights for next\ngeneration KAN architectures in imbalanced classification scenarios.", "comment": "9 Pages, 4 figures", "pdf_url": "http://arxiv.org/pdf/2507.14121v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "科尔莫哥洛夫-阿诺德网络（KANs）在不平衡数据中的应用——一项实证研究", "tldr": "科尔莫哥洛夫-阿诺德网络（KANs）在未经重采样的不平衡原始数据上表现优于多层感知机（MLPs），但与传统不平衡策略（如重采样和焦点损失）存在冲突，且计算成本过高，限制了其实际部署。", "motivation": "本研究旨在对科尔莫哥洛夫-阿诺德网络（KANs）在类别不平衡分类背景下进行实证评估，因为KANs是神经网络计算领域近期的一项架构进展，为标准神经网络提供了数学上更严谨的替代方案。", "method": "本研究使用十个基准数据集，对KANs在类别不平衡分类中的性能进行了实证评估。将KANs与多层感知机（MLPs）进行比较，并考察了传统不平衡策略（如重采样和焦点损失）对两者性能的影响。通过统计验证来确认结果。", "result": "KANs在未经任何重采样策略的情况下，能够比多层感知机（MLPs）更有效地在原始不平衡数据上表现良好。然而，传统的重采样和焦点损失等不平衡策略会显著降低KANs的性能，同时对MLPs的益处微乎其微。KANs的计算成本过高，但性能提升不成比例。统计验证表明，使用不平衡技术的MLPs在最低资源成本下能够达到与KANs相当的性能。", "conclusion": "KANs是处理原始不平衡数据的一种专用解决方案，前提是资源允许。但它们严重的性能-资源权衡以及与标准重采样技术的不兼容性，目前限制了其实际部署。未来的研究重点应放在开发针对不平衡学习的KAN特定架构修改、优化计算效率以及理论上协调其与数据增强的冲突上。", "translation": "科尔莫哥洛夫-阿诺德网络（KANs）是神经网络计算领域近期的一项架构进展，为标准神经网络提供了数学上更严谨的替代方案。本研究在类别不平衡分类的背景下，使用十个基准数据集对KANs进行了实证评估。我们观察到，在不使用任何重采样策略的情况下，KANs能够比多层感知机（MLPs）更有效地在原始不平衡数据上表现良好。然而，传统的失衡策略与KANs的数学结构根本上存在冲突，因为重采样和焦点损失的实现会显著降低KANs的性能，而对MLPs的益处微乎其微。关键的是，KANs的计算成本过高，但性能提升不成比例。统计验证证实，使用不平衡技术的MLPs以最小的资源成本实现了与KANs的等效性能（各项指标的|d| < 0.08）。这些发现表明，KANs是资源允许情况下处理原始不平衡数据的专用解决方案。但其严重的性能-资源权衡以及与标准重采样技术的不兼容性，目前限制了其实际部署。我们确定了关键的研究重点，包括开发针对不平衡学习的KAN特定架构修改、优化计算效率以及理论上协调其与数据增强的冲突。这项工作为不平衡分类场景中下一代KAN架构奠定了基础见解。", "summary": "本研究对科尔莫哥洛夫-阿诺德网络（KANs）在不平衡分类中的性能进行了实证评估。结果显示，KANs在处理原始不平衡数据时，无需重采样即可比多层感知机（MLPs）表现更优。然而，传统的重采样和焦点损失等不平衡处理策略会显著损害KANs的性能，且KANs存在计算成本高昂但性能提升不显著的问题。相比之下，采用不平衡技术的MLPs能以更低的成本达到与KANs相当的性能。这表明，尽管KANs在特定情况下有优势，但其高昂的资源消耗和与现有不平衡处理方法的不兼容性限制了其实用性，亟需未来研究解决计算效率和架构兼容性问题。", "keywords": "科尔莫哥洛夫-阿诺德网络, 不平衡数据, 实证研究, 神经网络, 计算成本", "comments": "KANs作为一种新型神经网络架构，其在处理原始不平衡数据方面的固有优势具有创新性。然而，该论文揭示了其在实际应用中的主要局限性，即高昂的计算成本和与现有成熟不平衡处理技术的冲突。这为KANs的未来研究指明了关键方向，即如何在保持其优势的同时，提高效率并解决兼容性问题，以促进其在更广泛场景中的实际部署。"}}
{"id": "2507.13655", "title": "CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer", "authors": ["Teerapong Panboonyuen"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      12 pages", "url": "http://arxiv.org/abs/2507.13655v1", "summary": "Integrating large language models into specialized domains like healthcare\npresents unique challenges, including domain adaptation and limited labeled\ndata. We introduce CU-ICU, a method for customizing unsupervised\ninstruction-finetuned language models for ICU datasets by leveraging the\nText-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse\nfine-tuning approach that combines few-shot prompting with selective parameter\nupdates, enabling efficient adaptation with minimal supervision. Our evaluation\nacross critical ICU tasks--early sepsis detection, mortality prediction, and\nclinical note generation--demonstrates that CU-ICU consistently improves\npredictive accuracy and interpretability over standard fine-tuning methods.\nNotably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and\na 20% enhancement in generating clinically relevant explanations while updating\nfewer than 1% of model parameters in its most efficient configuration. These\nresults establish CU-ICU as a scalable, low-overhead solution for delivering\naccurate and interpretable clinical decision support in real-world ICU\nenvironments.", "comment": "12 pages", "pdf_url": "http://arxiv.org/pdf/2507.13655v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "CU-ICU：通过文本到文本转换器为ICU数据集定制无监督指令微调语言模型", "tldr": "CU-ICU是一种利用稀疏微调和少量样本提示来定制无监督指令微调语言模型的方法，用于ICU数据集，显著提高了预测准确性和可解释性，同时更新了极少量的模型参数。", "motivation": "将大型语言模型集成到医疗保健等专业领域面临独特的挑战，包括领域适应性和标记数据有限的问题。", "method": "本研究引入了CU-ICU方法，通过利用Text-to-Text Transfer Transformer (T5) 架构，为ICU数据集定制无监督指令微调语言模型。CU-ICU采用稀疏微调方法，结合少量样本提示和选择性参数更新，以实现高效且监督最少的适应。", "result": "CU-ICU在关键的ICU任务（早期败血症检测、死亡率预测和临床笔记生成）中，相对于标准微调方法，持续提高了预测准确性和可解释性。值得注意的是，CU-ICU在败血症检测准确性方面提高了高达15%，在生成临床相关解释方面增强了20%，同时在其最有效的配置中更新的模型参数不到1%。", "conclusion": "这些结果表明，CU-ICU是一种可扩展、低开销的解决方案，能够为真实世界的ICU环境提供准确和可解释的临床决策支持。", "translation": "将大型语言模型集成到医疗保健等专业领域面临独特的挑战，包括领域适应性和标记数据有限的问题。我们引入了CU-ICU，一种通过利用文本到文本转换器（T5）架构，为ICU数据集定制无监督指令微调语言模型的方法。CU-ICU采用稀疏微调方法，结合少量样本提示和选择性参数更新，从而以最少的监督实现高效适应。我们在关键的ICU任务——早期败血症检测、死亡率预测和临床笔记生成——中的评估表明，CU-ICU相对于标准微调方法持续提高了预测准确性和可解释性。值得注意的是，CU-ICU在败血症检测准确性方面提高了高达15%，在生成临床相关解释方面增强了20%，同时在其最有效的配置中更新的模型参数不到1%。这些结果表明，CU-ICU是一种可扩展、低开销的解决方案，能够为真实世界的ICU环境提供准确和可解释的临床决策支持。", "summary": "CU-ICU提出了一种通过稀疏微调和少量样本提示，定制无监督指令微调语言模型（基于T5架构）以适应ICU数据集的方法，旨在解决医疗领域数据限制和领域适应挑战。该方法在败血症检测、死亡率预测和临床笔记生成等ICU任务中表现出优于传统微调方法的预测准确性和可解释性，并显著减少了需要更新的模型参数量，从而提供了一种高效且可扩展的临床决策支持方案。", "keywords": "ICU数据集, 语言模型, 稀疏微调, 医疗保健, T5", "comments": "CU-ICU的创新之处在于其结合了稀疏微调和少量样本提示，以高效地将大型语言模型适应到专业医疗领域，尤其是在数据稀缺的ICU环境中。其“更新不到1%的模型参数”的能力显著降低了计算开销和部署难度，使其成为一个具有实际应用价值的低开销解决方案。这对于推动LLM在医疗领域的落地具有重要意义。"}}
{"id": "2507.03532", "title": "PhenoBench: A Comprehensive Benchmark for Cell Phenotyping", "authors": ["Jannik Franzen", "Fabian H. Reith", "Claudia Winklmayr", "Jerome Luescher", "Nora Koreuber", "Elias Baumann", "Christian M. Schuerch", "Dagmar Kainmueller", "Josef Lorenz Rumberger"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      accepted for presentation at MICCAI 2025", "url": "http://arxiv.org/abs/2507.03532v4", "summary": "Digital pathology has seen the advent of a wealth of foundational models\n(FM), yet to date their performance on cell phenotyping has not been\nbenchmarked in a unified manner. We therefore propose PhenoBench: A\ncomprehensive benchmark for cell phenotyping on Hematoxylin and Eosin (H&E)\nstained histopathology images. We provide both PhenoCell, a new H&E dataset\nfeaturing 14 granular cell types identified by using multiplexed imaging, and\nready-to-use fine-tuning and benchmarking code that allows the systematic\nevaluation of multiple prominent pathology FMs in terms of dense cell phenotype\npredictions in different generalization scenarios. We perform extensive\nbenchmarking of existing FMs, providing insights into their generalization\nbehavior under technical vs. medical domain shifts. Furthermore, while FMs\nachieve macro F1 scores > 0.70 on previously established benchmarks such as\nLizard and PanNuke, on PhenoCell, we observe scores as low as 0.20. This\nindicates a much more challenging task not captured by previous benchmarks,\nestablishing PhenoCell as a prime asset for future benchmarking of FMs and\nsupervised models alike. Code and data are available on GitHub.", "comment": "accepted for presentation at MICCAI 2025", "pdf_url": "http://arxiv.org/pdf/2507.03532v4", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-18", "AI": {"title_translation": "PhenoBench：一个全面的细胞表型基准", "tldr": "本文提出了PhenoBench，这是一个用于细胞表型分析的综合基准，包含新的PhenoCell数据集和评估代码。研究发现，现有基础模型在PhenoCell上的表现远低于其他基准，表明其挑战性更高。", "motivation": "尽管数字病理学领域出现了大量基础模型（FM），但迄今为止，它们在细胞表型分析方面的性能尚未得到统一的基准测试。", "method": "本文提出了PhenoBench，一个针对苏木精和伊红（H&E）染色组织病理图像上细胞表型分析的综合基准。该基准提供了一个新的H&E数据集PhenoCell，其中包含14种通过多重成像识别的颗粒细胞类型，以及即用型微调和基准测试代码，用于系统评估不同泛化场景下多个著名病理学基础模型的密集细胞表型预测性能。", "result": "研究对现有基础模型进行了广泛的基准测试，揭示了它们在技术领域和医学领域转移下的泛化行为。结果显示，虽然基础模型在Lizard和PanNuke等现有基准测试中取得了超过0.70的宏观F1分数，但在PhenoCell上，分数低至0.20。", "conclusion": "这表明PhenoCell捕获了一个比以往基准测试更具挑战性的任务，并将其确立为未来基础模型和监督模型基准测试的重要资产。", "translation": "数字病理学领域已经出现了大量的基础模型（FM），但迄今为止，它们在细胞表型分析方面的性能尚未得到统一的基准测试。因此，我们提出了PhenoBench：一个针对苏木精和伊红（H&E）染色组织病理图像上细胞表型分析的综合基准。我们提供了PhenoCell，这是一个新的H&E数据集，通过多重成像识别了14种颗粒细胞类型，以及即用型微调和基准测试代码，允许系统评估多个著名病理学基础模型在不同泛化场景下的密集细胞表型预测性能。我们对现有基础模型进行了广泛的基准测试，深入了解了它们在技术与医学领域转移下的泛化行为。此外，虽然基础模型在Lizard和PanNuke等先前建立的基准测试中取得了超过0.70的宏观F1分数，但在PhenoCell上，我们观察到分数低至0.20。这表明这是一个比以往基准测试更具挑战性的任务，确立了PhenoCell作为未来基础模型和监督模型基准测试的重要资产。代码和数据已在GitHub上提供。", "summary": "本文介绍了PhenoBench，这是一个针对细胞表型分析的综合基准，旨在解决现有基础模型（FM）在该领域缺乏统一性能评估的问题。该基准包含PhenoCell数据集，其中包含了新的H&E染色图像和14种细胞类型，并提供了评估代码。研究发现，尽管FM在传统基准上表现良好，但在PhenoCell上的性能显著下降，表明PhenoCell提出了一个更具挑战性的细胞表型分析任务，是未来模型评估的重要资源。", "keywords": "细胞表型, 基准测试, 基础模型, 数字病理学, PhenoCell", "comments": "本文通过提出PhenoBench及其包含的PhenoCell数据集，填补了细胞表型分析领域基础模型统一基准测试的空白。其创新之处在于提供了更具挑战性的真实世界数据，并揭示了现有基础模型在复杂细胞表型任务上的局限性，对推动数字病理学领域的基础模型研究具有重要意义。"}}
{"id": "2507.13787", "title": "Design Analysis of an Innovative Parallel Robot for Minimally Invasive Pancreatic Surgery", "authors": ["Doina Pisla", "Alexandru Pusca", "Andrei Caprariu", "Adrian Pisla", "Bogdan Gherman", "Calin Vaida", "Damien Chablat"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13787v1", "summary": "This paper focuses on the design of a parallel robot designed for robotic\nassisted minimally invasive pancreatic surgery. Two alternative architectures,\ncalled ATHENA-1 and ATHENA-2, each with 4 degrees of freedom (DOF) are\nproposed. Their kinematic schemes are presented, and the conceptual 3D CAD\nmodels are illustrated. Based on these, two Finite Element Method (FEM)\nsimulations were performed to determine which architecture has the higher\nstiffness. A workspace quantitative analysis is performed to further assess the\nusability of the two proposed parallel architectures related to the medical\ntasks. The obtained results are used to select the architecture which fit the\nrequired design criteria and will be used to develop the experimental model of\nthe surgical robot.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13787v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "微创胰腺手术创新并联机器人设计分析", "tldr": "本文设计并分析了两种用于微创胰腺手术的并联机器人架构（ATHENA-1和ATHENA-2），通过有限元仿真和工作空间分析选出了最佳方案，为实验模型的开发奠定基础。", "motivation": "为机器人辅助微创胰腺手术设计并联机器人。", "method": "提出了ATHENA-1和ATHENA-2两种具有4个自由度的并联机器人架构，并展示了它们的运动学方案和概念性3D CAD模型。接着，进行了有限元方法(FEM)仿真以确定更高刚度的架构，并进行了工作空间定量分析以评估其在医疗任务中的可用性。", "result": "通过有限元仿真和工作空间分析，成功选出了符合设计要求的并联机器人架构。", "conclusion": "选定的架构将用于开发手术机器人的实验模型。", "translation": "本文重点研究了一种专为机器人辅助微创胰腺手术设计的并联机器人。提出了两种替代架构，分别命名为ATHENA-1和ATHENA-2，每种都具有4个自由度(DOF)。文中介绍了它们的运动学方案，并展示了概念性3D CAD模型。在此基础上，进行了两次有限元方法(FEM)仿真，以确定哪种架构具有更高的刚度。还进行了工作空间定量分析，以进一步评估两种所提出的并联架构与医疗任务相关的可用性。所得结果用于选择符合所需设计标准的架构，并将其用于开发手术机器人的实验模型。", "summary": "本文设计并分析了两种用于机器人辅助微创胰腺手术的创新并联机器人架构（ATHENA-1和ATHENA-2），每种具有4个自由度。研究通过运动学方案、3D CAD模型、有限元仿真和工作空间分析，评估了两种架构的刚度和可用性，并最终选定了一个最佳方案，为后续实验模型的开发奠定基础。", "keywords": "并联机器人, 微创手术, 胰腺手术, 有限元分析, 工作空间分析", "comments": "这项研究在微创胰腺手术机器人设计领域具有创新性，特别在于提出了两种具体的并联机器人架构并进行了详细的设计分析，包括刚度评估和工作空间分析，这对于实际医疗应用中的机器人性能至关重要。研究为后续实验模型的开发提供了坚实的基础。"}}
{"id": "2507.13404", "title": "AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation", "authors": ["Delin An", "Pan Du", "Jian-Xun Wang", "Chaoli Wang"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13404v1", "summary": "Accurate 3D aortic construction is crucial for clinical diagnosis,\npreoperative planning, and computational fluid dynamics (CFD) simulations, as\nit enables the estimation of critical hemodynamic parameters such as blood flow\nvelocity, pressure distribution, and wall shear stress. Existing construction\nmethods often rely on large annotated training datasets and extensive manual\nintervention. While the resulting meshes can serve for visualization purposes,\nthey struggle to produce geometrically consistent, well-constructed surfaces\nsuitable for downstream CFD analysis. To address these challenges, we introduce\nAortaDiff, a diffusion-based framework that generates smooth aortic surfaces\ndirectly from CT/MRI volumes. AortaDiff first employs a volume-guided\nconditional diffusion model (CDM) to iteratively generate aortic centerlines\nconditioned on volumetric medical images. Each centerline point is then\nautomatically used as a prompt to extract the corresponding vessel contour,\nensuring accurate boundary delineation. Finally, the extracted contours are\nfitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh\nrepresentation. AortaDiff offers distinct advantages over existing methods,\nincluding an end-to-end workflow, minimal dependency on large labeled datasets,\nand the ability to generate CFD-compatible aorta meshes with high geometric\nfidelity. Experimental results demonstrate that AortaDiff performs effectively\neven with limited training data, successfully constructing both normal and\npathologically altered aorta meshes, including cases with aneurysms or\ncoarctation. This capability enables the generation of high-quality\nvisualizations and positions AortaDiff as a practical solution for\ncardiovascular research.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13404v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "AortaDiff：体积引导条件扩散模型用于多分支主动脉表面生成", "tldr": "AortaDiff是一种基于扩散模型的方法，可直接从CT/MRI体积数据生成平滑且与CFD兼容的主动脉3D表面，减少对大量标注数据和手动干预的依赖。", "motivation": "准确的3D主动脉构建对于临床诊断、术前规划和计算流体动力学（CFD）模拟至关重要，但现有方法通常依赖大量标注训练数据集和广泛的手动干预，且难以生成几何一致、适用于CFD分析的表面。", "method": "AortaDiff是一个基于扩散的框架，它首先采用体积引导条件扩散模型（CDM）根据体积医学图像迭代生成主动脉中心线。接着，每个中心线点被自动用作提示来提取相应的血管轮廓。最后，提取的轮廓被拟合到平滑的3D表面中，生成连续、与CFD兼容的网格表示。", "result": "AortaDiff即使在有限的训练数据下也能有效运行，成功构建了包括动脉瘤或主动脉缩窄病例在内的正常和病理改变的主动脉网格，并能够生成高质量的可视化效果。", "conclusion": "AortaDiff提供了一种实用的心血管研究解决方案，能够生成高几何保真度且与CFD兼容的主动脉网格，具有端到端的工作流程，对大型标记数据集的依赖性最小。", "translation": "准确的3D主动脉构建对于临床诊断、术前规划和计算流体动力学（CFD）模拟至关重要，因为它能够估算关键的血流动力学参数，如血流速度、压力分布和壁面剪切应力。现有的构建方法通常依赖于大量标注的训练数据集和广泛的手动干预。虽然生成的网格可以用于可视化目的，但它们难以生成几何一致、构建良好且适合下游CFD分析的表面。为了解决这些挑战，我们引入了AortaDiff，一个基于扩散的框架，可以直接从CT/MRI体积数据生成平滑的主动脉表面。AortaDiff首先采用体积引导条件扩散模型（CDM），根据体积医学图像迭代生成主动脉中心线。然后，每个中心线点被自动用作提示来提取相应的血管轮廓，确保准确的边界描绘。最后，提取的轮廓被拟合到平滑的3D表面中，生成连续、与CFD兼容的网格表示。AortaDiff相较于现有方法具有明显的优势，包括端到端的工作流程、对大型标注数据集的最小依赖，以及生成具有高几何保真度的CFD兼容主动脉网格的能力。实验结果表明，AortaDiff即使在有限的训练数据下也能有效运行，成功构建了正常和病理改变的主动脉网格，包括动脉瘤或主动脉缩窄病例。这种能力使得高质量的可视化成为可能，并将AortaDiff定位为心血管研究的实用解决方案。", "summary": "本文提出了AortaDiff，一个基于扩散模型的框架，用于直接从CT/MRI体积数据生成平滑且与CFD兼容的3D主动脉表面。该方法通过体积引导条件扩散模型生成中心线，然后提取轮廓并拟合成平滑表面，实现了端到端的工作流程，减少了对大量标注数据的依赖，并能有效处理正常和病变主动脉，为心血管研究提供了实用工具。", "keywords": "主动脉表面生成, 扩散模型, 计算流体动力学 (CFD), 3D重建, 医疗图像处理", "comments": "AortaDiff的创新之处在于其结合了体积引导条件扩散模型来生成主动脉中心线，并以此为基础构建了端到端的主动脉表面生成流程。它解决了现有方法对大量标注数据和手动干预的依赖问题，并能生成几何保真度高且适用于CFD分析的网格，这对于临床诊断和研究具有重要意义。其在有限数据下的有效性也增加了其实用性。"}}
{"id": "2507.13753", "title": "Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis", "authors": ["Tongtong Su", "Chengyu Wang", "Bingyan Liu", "Jun Huang", "Dongming Lu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13753v1", "summary": "In recent years, large text-to-video (T2V) synthesis models have garnered\nconsiderable attention for their abilities to generate videos from textual\ndescriptions. However, achieving both high imaging quality and effective motion\nrepresentation remains a significant challenge for these T2V models. Existing\napproaches often adapt pre-trained text-to-image (T2I) models to refine video\nframes, leading to issues such as flickering and artifacts due to\ninconsistencies across frames. In this paper, we introduce EVS, a training-free\nEncapsulated Video Synthesizer that composes T2I and T2V models to enhance both\nvisual fidelity and motion smoothness of generated videos. Our approach\nutilizes a well-trained diffusion-based T2I model to refine low-quality video\nframes by treating them as out-of-distribution samples, effectively optimizing\nthem with noising and denoising steps. Meanwhile, we employ T2V backbones to\nensure consistent motion dynamics. By encapsulating the T2V temporal-only prior\ninto the T2I generation process, EVS successfully leverages the strengths of\nboth types of models, resulting in videos of improved imaging and motion\nquality. Experimental results validate the effectiveness of our approach\ncompared to previous approaches. Our composition process also leads to a\nsignificant improvement of 1.6x-4.5x speedup in inference time. Source codes:\nhttps://github.com/Tonniia/EVS.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13753v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "高质量视频合成中图文转换模型与视频转换模型的封装组合", "tldr": "本文提出EVS，一个免训练的封装视频合成器，结合文生图和文生视频模型，显著提升生成视频的视觉质量和运动流畅度，并加快推理速度。", "motivation": "尽管大型文本到视频（T2V）合成模型受到广泛关注，但其在实现高质量成像和有效运动表示方面仍面临挑战。现有方法常通过调整预训练的文本到图像（T2I）模型来优化视频帧，但这会导致帧间不一致，产生闪烁和伪影问题。", "method": "本文引入EVS，一个免训练的封装视频合成器。EVS利用训练良好的扩散型T2I模型，通过去噪和降噪步骤将低质量视频帧视为异常分布样本进行优化。同时，EVS采用T2V骨干网络以确保一致的运动动态。通过将T2V的时序先验封装到T2I生成过程中，EVS有效结合了两种模型的优势。", "result": "EVS成功地提升了生成视频的成像和运动质量。实验结果验证了其相较于现有方法的有效性。此外，EVS的组合过程还带来了1.6倍至4.5倍的推理时间加速。", "conclusion": "通过封装文生图和文生视频模型的优势，EVS能够生成高质量的视频，有效解决现有方法在视频质量和运动流畅性方面的挑战，并显著提高推理效率。", "translation": "近年来，大型文本到视频（T2V）合成模型因其从文本描述生成视频的能力而受到广泛关注。然而，对于这些T2V模型而言，同时实现高质量成像和有效的运动表示仍然是一个重大挑战。现有方法通常通过调整预训练的文本到图像（T2I）模型来优化视频帧，但这会导致帧间不一致，产生闪烁和伪影等问题。在本文中，我们引入了EVS，一个免训练的封装视频合成器，它结合了T2I和T2V模型，以提高生成视频的视觉保真度和运动流畅性。我们的方法利用训练良好的基于扩散的T2I模型，通过将低质量视频帧视为分布外样本来对其进行优化，通过去噪和降噪步骤有效地对其进行优化。同时，我们采用T2V骨干网络以确保一致的运动动态。通过将T2V的时序先验封装到T2I生成过程中，EVS成功地利用了两种模型的优势，从而生成了图像和运动质量均有所改善的视频。实验结果验证了我们的方法与现有方法相比的有效性。我们的组合过程还带来了1.6倍至4.5倍的推理时间显著加速。源代码：https://github.com/Tonniia/EVS。", "summary": "本文提出EVS，一个免训练的封装视频合成器，旨在解决当前文本到视频（T2V）模型在生成高质量视频时面临的图像质量和运动流畅性挑战。EVS通过巧妙结合预训练的文本到图像（T2I）模型和T2V模型，利用T2I模型优化低质量视频帧的视觉细节，同时依靠T2V模型保持运动一致性。这种封装T2V时序先验到T2I生成过程的方法，有效提升了生成视频的视觉保真度和运动平滑度，并实现了显著的推理速度提升（1.6x-4.5x）。实验结果证明了其优越性。", "keywords": "文本到视频合成, 文本到图像模型, 视频生成, 扩散模型, EVS", "comments": "该论文提出了一种新颖的免训练方法EVS，通过封装组合T2I和T2V模型，有效解决了当前T2V模型在视频质量和运动一致性上的痛点。其创新之处在于将T2I模型用于帧优化，同时利用T2V模型保持时间连贯性，并成功将T2V的时序先验融入T2I生成过程。这种方法不仅提升了生成视频的视觉和运动质量，还带来了显著的推理速度提升，显示出其在实际应用中的潜力。"}}
{"id": "2507.14060", "title": "Sparse Navigable Graphs for Nearest Neighbor Search: Algorithms and Hardness", "authors": ["Sanjeev Khanna", "Ashwin Padaki", "Erik Waingarten"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14060v1", "summary": "We initiate the study of approximation algorithms and computational barriers\nfor constructing sparse $\\alpha$-navigable graphs [IX23, DGM+24], a core\nprimitive underlying recent advances in graph-based nearest neighbor search.\nGiven an $n$-point dataset $P$ with an associated metric $\\mathsf{d}$ and a\nparameter $\\alpha \\geq 1$, the goal is to efficiently build the sparsest graph\n$G=(P, E)$ that is $\\alpha$-navigable: for every distinct $s, t \\in P$, there\nexists an edge $(s, u) \\in E$ with $\\mathsf{d}(u, t) < \\mathsf{d}(s,\nt)/\\alpha$. We consider two natural sparsity objectives: minimizing the maximum\nout-degree and minimizing the total size.\n  We first show a strong negative result: the slow-preprocessing version of\nDiskANN (analyzed in [IX23] for low-doubling metrics) can yield solutions whose\nsparsity is $\\widetilde{\\Omega}(n)$ times larger than optimal, even on\nEuclidean instances. We then show a tight approximation-preserving equivalence\nbetween the Sparsest Navigable Graph problem and the classic Set Cover problem,\nobtaining an $O(n^3)$-time $(\\ln n + 1)$-approximation algorithm, as well as\nestablishing NP-hardness of achieving an $o(\\ln n)$-approximation. Building on\nthis equivalence, we develop faster $O(\\ln n)$-approximation algorithms. The\nfirst runs in $\\widetilde{O}(n \\cdot \\mathrm{OPT})$ time and is thus much\nfaster when the optimal solution is sparse. The second, based on fast matrix\nmultiplication, is a bicriteria algorithm that computes an $O(\\ln\nn)$-approximation to the sparsest $2\\alpha$-navigable graph, running in\n$\\widetilde{O}(n^{\\omega})$ time.\n  Finally, we complement our upper bounds with a query complexity lower bound,\nshowing that any $o(n)$-approximation requires examining $\\Omega(n^2)$\ndistances. This result shows that in the regime where $\\mathrm{OPT} =\n\\widetilde{O}(n)$, our $\\widetilde{O}(n \\cdot \\mathrm{OPT})$-time algorithm is\nessentially best possible.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14060v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "稀疏可导航图用于最近邻搜索：算法与难度", "tldr": "本文首次系统研究了构建稀疏可导航图以进行最近邻搜索的算法和计算障碍，提出了近似算法并证明了NP-hard性及查询复杂度下限。", "motivation": "研究稀疏α-可导航图的构建，这是图基最近邻搜索最新进展的核心原语。目标是高效构建最稀疏的α-可导航图，以最小化最大出度和总大小。", "method": "分析了DiskANN的慢预处理版本在欧几里得实例上的稀疏性。证明了稀疏可导航图问题与经典集合覆盖问题之间存在紧密的近似保持等价性。基于此等价性，开发了更快的O(ln n)近似算法，包括一个在最优解稀疏时更快的O(n * OPT)时间算法，以及一个基于快速矩阵乘法的双准则O(ln n)近似算法（针对2α-可导航图）。补充了查询复杂度下限分析。", "result": "DiskANN的慢预处理版本在欧几里得实例上可能产生比最优解稀疏度大$\\\\widetilde{\\\\Omega}(n)$倍的解决方案。证明了稀疏可导航图问题与经典集合覆盖问题之间存在紧密的近似保持等价性，得到了一个$O(n^3)$时间 $(\\\\ln n + 1)$-近似算法，并建立了实现$o(\\\\ln n)$-近似的NP-hard性。开发了更快的$O(\\\\ln n)$-近似算法，包括一个在最优解稀疏时更快的$\\\\widetilde{O}(n \\\\\\cdot \\\\mathrm{OPT})$时间算法，和一个基于快速矩阵乘法的双准则$\\\\widetilde{O}(n^{\\\\omega})$时间算法，用于计算最稀疏的$2\\\\alpha$-可导航图的$O(\\\\ln n)$-近似。表明任何$o(n)$-近似需要检查$\\\\Omega(n^2)$距离的查询复杂度下限。", "conclusion": "在$\\\\mathrm{OPT} = \\\\widetilde{O}(n)$的情况下，本文提出的$\\\\widetilde{O}(n \\\\\\cdot \\\\mathrm{OPT})$时间算法本质上是最佳的。", "translation": "我们首次研究了构建稀疏$\\\\alpha$-可导航图的近似算法和计算障碍，稀疏$\\\\alpha$-可导航图是图基最近邻搜索最新进展的核心原语。给定一个包含$n$个点的数据集$P$及其关联度量$\\\\mathsf{d}$和一个参数$\\\\alpha \\\\geq 1$，目标是高效构建最稀疏的图$G=(P, E)$，使其是$\\\\alpha$-可导航的：对于每个不同的$s, t \\\\in P$，都存在一条边$(s, u) \\\\in E$，使得$\\\\mathsf{d}(u, t) < \\\\mathsf{d}(s, t)/\\\\alpha$。我们考虑了两个自然的稀疏性目标：最小化最大出度和最小化总大小。 我们首先展示了一个强烈的负面结果：DiskANN的慢预处理版本（在[IX23]中针对低倍增度量进行了分析）即使在欧几里得实例上，其稀疏度也可能比最优解大$\\\\widetilde{\\\\Omega}(n)$倍。然后，我们展示了稀疏可导航图问题与经典集合覆盖问题之间存在紧密的近似保持等价性，从而得到了一个$O(n^3)$时间 $(\\\\ln n + 1)$-近似算法，并建立了实现$o(\\\\ln n)$-近似的NP-hard性。在此等价性基础上，我们开发了更快的$O(\\\\ln n)$-近似算法。第一个算法在$\\\\widetilde{O}(n \\\\\\cdot \\\\mathrm{OPT})$时间内运行，因此当最优解稀疏时会快得多。第二个算法基于快速矩阵乘法，是一个双准则算法，它计算最稀疏的$2\\\\alpha$-可导航图的$O(\\\\ln n)$-近似，并在$\\\\widetilde{O}(n^{\\\\omega})$时间内运行。 最后，我们通过查询复杂度下限补充了我们的上限，表明任何$o(n)$-近似都需要检查$\\\\Omega(n^2)$的距离。这个结果表明，在$\\\\mathrm{OPT} = \\\\widetilde{O}(n)$的情况下，我们的$\\\\widetilde{O}(n \\\\\\cdot \\\\mathrm{OPT})$时间算法本质上是最佳的。", "summary": "本文首次系统研究了用于最近邻搜索的稀疏可导航图的构建问题，旨在高效构建最稀疏的图。研究揭示了现有方法（如DiskANN）的稀疏性局限性，并证明了该问题与集合覆盖问题的近似保持等价性，从而提出了多种$O(\\\\ln n)$-近似算法，包括一个在最优解稀疏时表现优异的算法。此外，还建立了实现高近似比的NP-hard性以及查询复杂度下限，表明在特定条件下，所提出的算法已达到理论最优。", "keywords": "稀疏可导航图, 最近邻搜索, 近似算法, 集合覆盖, 计算复杂度", "comments": "本文开创性地将稀疏可导航图的构建问题与经典的集合覆盖问题联系起来，并通过严格的理论分析，不仅揭示了现有方法的不足，还提供了具有理论保证的近似算法，并明确了问题的计算难度和最优算法的性能界限，对图基最近邻搜索领域具有重要的理论和实践意义。"}}
{"id": "2507.12547", "title": "Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models", "authors": ["Lionel Wong", "Katherine M. Collins", "Lance Ying", "Cedegao E. Zhang", "Adrian Weller", "Tobias Gerstenberg", "Timothy O'Donnell", "Alexander K. Lew", "Jacob D. Andreas", "Joshua B. Tenenbaum", "Tyler Brooke-Wilson"], "categories": ["cs.CL", "cs.AI", "cs.PL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Presented at CogSci 2025", "url": "http://arxiv.org/abs/2507.12547v2", "summary": "When faced with novel situations, people are able to marshal relevant\nconsiderations from a wide range of background knowledge and put these to use\nin inferences and predictions. What permits us to draw in globally relevant\ninformation and reason over it coherently? Here, we explore the hypothesis that\npeople use a combination of distributed and symbolic representations to\nconstruct bespoke mental models tailored to novel situations. We propose a\ncomputational implementation of this idea -- a ``Model Synthesis Architecture''\n(MSA) -- using language models to implement global relevance-based retrieval\nand model synthesis and probabilistic programs to implement bespoke, coherent\nworld models. We evaluate our MSA as a model of human judgments on a novel\nreasoning dataset. The dataset -- built around a `Model Olympics` domain of\nsports vignettes -- tests models' capacity for human-like, open-ended reasoning\nby requiring (i) judgments about novel causal structures described in language;\n(ii) drawing on large bodies of background knowledge; and (iii) doing both in\nlight of observations that introduce arbitrary novel variables. Our MSA\napproach captures human judgments better than language model-only baselines,\nunder both direct and chain-of-thought generations from the LM that supports\nmodel synthesis. These results suggest that MSAs can be implemented in a way\nthat mirrors people's ability to deliver locally coherent reasoning over\nglobally relevant variables, offering a path to understanding and replicating\nhuman reasoning in open-ended domains.", "comment": "Presented at CogSci 2025", "pdf_url": "http://arxiv.org/pdf/2507.12547v2", "cate": "cs.CL", "date": "2025-07-16", "updated": "2025-07-18", "AI": {"title_translation": "将开放世界认知建模为概率模型的按需合成", "tldr": "本文提出了一种“模型合成架构”（MSA），它结合了语言模型和概率程序，用于在面对新颖情况时实现类似人类的开放式推理，并在新颖推理数据集上优于纯语言模型基线。", "motivation": "人们在面对新颖情况时，能够从广泛的背景知识中调动相关考量，并将其用于推理和预测。本文旨在探索是什么使我们能够提取全局相关信息并对其进行连贯推理。", "method": "本文提出了一种计算实现方法——“模型合成架构”（MSA），它使用语言模型来实现基于全局相关性的检索和模型合成，并使用概率程序来实现定制的、连贯的世界模型。该方法在一个围绕“模型奥林匹克”运动短片领域构建的新颖推理数据集上进行了评估，该数据集测试模型对人类开放式推理的能力。", "result": "MSA方法在直接生成和思维链生成两种模式下，比仅使用语言模型的基线更能捕捉人类判断。", "conclusion": "MSA的实现方式能够反映人类在全局相关变量上进行局部连贯推理的能力，为理解和复制开放领域中的人类推理提供了一条途径。", "translation": "当面临新颖情境时，人们能够从广泛的背景知识中调集相关考量，并将其用于推断和预测。是什么让我们能够提取全局相关信息并对其进行连贯推理？在此，我们探讨了一个假设：人们使用分布式和符号表示的组合来构建针对新颖情境量身定制的心理模型。我们提出了这一思想的计算实现——“模型合成架构”（MSA），它使用语言模型来实现基于全局相关性的检索和模型合成，并使用概率程序来实现定制的、连贯的世界模型。我们评估了MSA作为人类在新颖推理数据集上判断的模型。该数据集围绕“模型奥林匹克”运动短片领域构建，通过要求（i）对语言描述的新颖因果结构进行判断；（ii）利用大量背景知识；以及（iii）在引入任意新颖变量的观察下同时进行这两项任务，来测试模型类人、开放式推理的能力。我们的MSA方法在支持模型合成的语言模型的直接生成和思维链生成下，比仅使用语言模型的基线更能捕捉人类判断。这些结果表明，MSA的实现方式能够反映人类在全局相关变量上进行局部连贯推理的能力，为理解和复制开放领域中的人类推理提供了一条途径。", "summary": "本文提出了一种“模型合成架构”（MSA），旨在模拟人类在面对新颖情境时的开放式认知能力。MSA结合了语言模型进行全局相关性检索和模型合成，以及概率程序构建定制的连贯世界模型。通过在一个名为“模型奥林匹克”的新颖推理数据集上进行评估，结果表明MSA在捕捉人类判断方面优于纯语言模型基线，这表明它能有效模拟人类在开放领域中对全局相关变量进行局部连贯推理的能力。", "keywords": "开放世界认知, 概率模型, 模型合成架构, 语言模型, 人类推理", "comments": "这项工作通过提出结合语言模型和概率程序的MSA，为模拟人类开放世界认知提供了一个新颖的计算框架。其创新点在于将全局相关性检索与定制模型合成相结合，以应对新颖情境。该研究的重要性在于其超越了传统语言模型的局限性，为理解和复制复杂的人类推理模式提供了一条有前景的路径。"}}
{"id": "2507.13768", "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning", "authors": ["Renato Ghisellini", "Remo Pareschi", "Marco Pedroni", "Giovanni Battista Raggi"], "categories": ["cs.AI", "I.2.7"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Peer-reviewed full paper accepted through a double-blind review process at the HAR 2025 conference ( this https URL ). The official version will appear in a volume of the Lecture Notes in Computer Science (LNCS) series", "url": "http://arxiv.org/abs/2507.13768v1", "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.", "comment": "Peer-reviewed full paper accepted through a double-blind review\n  process at the HAR 2025 conference (https://har-conf.eu/). The official\n  version will appear in a volume of the Lecture Notes in Computer Science\n  (LNCS) series", "pdf_url": "http://arxiv.org/pdf/2507.13768v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "从提取到综合：用于代理增强战略推理的纠缠启发式方法", "tldr": "本文提出了一种用于代理增强战略推理的混合架构，该架构结合、激活并融合了冲突的启发式方法，而非简单选择最佳规则，并通过Meta与FTC的案例研究进行了初步验证。", "motivation": "传统决策引擎仅选择最佳规则，而本文旨在将冲突的启发式方法融合为连贯且情境敏感的叙述，以解决复杂战略推理中的挑战。", "method": "该研究提出了一种结合启发式提取、语义激活和组合合成的混合架构。该模型通过受量子认知研究启发的语义相互依赖过程，激活并组合多个启发式方法。系统通过语义交互建模和修辞框架引导，将冲突的启发式方法融合为连贯且情境敏感的叙述。", "result": "该框架通过Meta与FTC的案例研究进行了演示，并通过语义指标获得了初步验证。", "conclusion": "该论文成功演示了其用于战略推理的混合架构，并通过语义指标获得了初步验证，同时讨论了未来的局限性和扩展。", "translation": "我们提出了一种用于代理增强战略推理的混合架构，结合了启发式提取、语义激活和组合合成。我们的模型借鉴了从经典军事理论到当代企业战略的各种来源，通过受量子认知研究启发的语义相互依赖过程，激活并组合多个启发式方法。与选择最佳规则的传统决策引擎不同，我们的系统在语义交互建模和修辞框架的指导下，将冲突的启发式方法融合为连贯且情境敏感的叙述。我们通过Meta与FTC的案例研究展示了该框架，并通过语义指标进行了初步验证。同时讨论了局限性和扩展（例如，动态干扰调整）。", "summary": "本文提出了一种新颖的混合人工智能架构，用于代理增强战略推理。该模型通过整合启发式提取、语义激活和组合合成，将冲突的启发式方法融合为连贯且情境敏感的叙述，与传统仅选择单一规则的系统不同。受量子认知启发，它利用语义相互依赖、交互建模和修辞框架。该框架通过Meta与FTC的案例研究进行演示，并利用语义指标进行了初步验证。", "keywords": "战略推理, 启发式方法, 混合架构, 语义交互, 量子认知", "comments": "该论文的创新之处在于其混合架构，特别是将冲突的启发式方法融合为连贯叙述的方法，以及受量子认知启发的语义相互依赖概念。它通过超越传统单一规则选择的方式，为复杂战略推理提供了新的视角。尽管抽象中未详细说明具体限制，但论文承认了其局限性。"}}
{"id": "2507.14064", "title": "Bounds and Constructions of High-Memory Spatially-Coupled Codes", "authors": ["Lei Huang"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted by ITW2025", "url": "http://arxiv.org/abs/2507.14064v1", "summary": "In this paper, we apply the Clique Lov\\'asz Local Lemma to provide sufficient\nconditions on memory and lifting degree for removing certain harmful\ncombinatorial structures in spatially-coupled (SC) codes that negatively impact\ndecoding performance. Additionally, we present, for the first time, a\nconstructive algorithm based on the Moser-Tardos algorithm that ensures\npredictable performance. Furthermore, leveraging the properties of\nLLL-distribution and M-T-distribution, we establish the dependencies among the\nharmful structures during the construction process. We provide upper bounds on\nthe probability change of remaining harmful structures after eliminating some\nof them. In particular, the elimination of 4-cycles increases the probability\nof 6-cycles becoming active by at most a factor of $e^{8/3}$.", "comment": "Accepted by ITW2025", "pdf_url": "http://arxiv.org/pdf/2507.14064v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "高记忆空间耦合码的界限与构造", "tldr": "本论文应用Clique Lovász局部引理和Moser-Tardos算法，为空间耦合码提供足够的内存和提升度条件，以消除影响解码性能的有害组合结构，并首次提出了一种保证可预测性能的构造算法。", "motivation": "识别并消除空间耦合（SC）码中对解码性能产生负面影响的有害组合结构。", "method": "1. 应用Clique Lovász局部引理提供关于内存和提升度的充分条件，以消除有害组合结构。2. 首次提出一种基于Moser-Tardos算法的构造算法，以确保可预测的性能。3. 利用LLL分布和M-T分布的特性，建立构造过程中有害结构之间的依赖关系。4. 提供消除部分有害结构后，剩余有害结构概率变化的上限。", "result": "1. 提供了关于内存和提升度的充分条件，以消除影响解码性能的有害组合结构。2. 提出了一个基于Moser-Tardos算法的构造性算法，首次实现了可预测的性能。3. 建立了构造过程中有害结构之间的依赖关系。4. 提供了消除部分有害结构后，剩余有害结构概率变化的上限。5. 特别指出，消除4-环会使6-环变得活跃的概率最多增加$e^{8/3}$倍。", "conclusion": "该研究通过应用先进的概率方法和算法，为高记忆空间耦合码的构造和分析提供了理论基础和实践工具，有效解决了影响解码性能的有害结构问题，并量化了结构消除过程中的概率变化。", "translation": "本文应用Clique Lovász局部引理，为空间耦合（SC）码提供足够的内存和提升度条件，以消除负面影响解码性能的某些有害组合结构。此外，我们首次提出了一种基于Moser-Tardos算法的构造性算法，确保了可预测的性能。此外，利用LLL分布和M-T分布的特性，我们建立了构造过程中有害结构之间的依赖关系。我们提供了消除部分有害结构后，剩余有害结构概率变化的上限。特别是，消除4-环会使6-环变得活跃的概率最多增加$e^{8/3}$倍。", "summary": "本论文探讨了高记忆空间耦合码的设计与分析，旨在解决影响解码性能的有害组合结构问题。研究者应用了Clique Lovász局部引理来确定消除这些结构的充分条件，并首次提出了一种基于Moser-Tardos算法的构造方法，该方法能保证可预测的性能。论文还分析了构造过程中有害结构间的依赖性，并量化了消除部分结构后剩余结构概率的变化，例如消除4-环对6-环活跃概率的影响。", "keywords": "空间耦合码, Lovász局部引理, Moser-Tardos算法, 组合结构, 解码性能", "comments": "本文的创新之处在于将Clique Lovász局部引理和Moser-Tardos算法应用于空间耦合码的构造和分析，以解决有害组合结构对解码性能的影响。其提出的构造性算法和对有害结构间依赖关系的量化分析，对于SC码的理论研究和实际应用具有重要意义。"}}
{"id": "2507.13908", "title": "A Robust Periodic Controller for Spacecraft Attitude Tracking", "authors": ["Frederik Thiele", "Felix Biertümpfel", "Harald Pfifer"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      Presented at European Control Conference 2025", "url": "http://arxiv.org/abs/2507.13908v1", "summary": "This paper presents a novel approach for robust periodic attitude control of\nsatellites. Respecting the periodicity of the satellite dynamics in the\nsynthesis allows to achieve constant performance and robustness requirements\nover the orbit. The proposed design follows a mixed sensitivity control design\nemploying a physically motivated weighting scheme. The controller is calculated\nusing a novel structured linear time-periodic output feedback synthesis with\nguaranteed optimal L2-performance. The synthesis poses a convex optimization\nproblem and avoids grid-wise evaluations of coupling conditions inherent for\nclassical periodic H-infinity-synthesis. Moreover, the controller has a\ntransparent and easy to implement structure. A solar power plant satellite is\nused to demonstrate the effectiveness of the proposed method for periodic\nsatellite attitude control.", "comment": "Presented at European Control Conference 2025", "pdf_url": "http://arxiv.org/pdf/2507.13908v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "航天器姿态跟踪的鲁棒周期控制器", "tldr": "本文提出了一种新型鲁棒周期控制器，用于卫星姿态控制，通过考虑周期性动力学实现轨道上的恒定性能和鲁棒性，并采用结构化线性时变周期输出反馈综合方法。", "motivation": "为了在卫星姿态控制中，通过考虑卫星动力学的周期性，实现在整个轨道上保持恒定的性能和鲁棒性要求。", "method": "该方法采用混合灵敏度控制设计，结合物理驱动的加权方案。控制器通过一种新颖的结构化线性时变周期输出反馈综合方法计算，该方法保证了最优的L2性能，并提出了一个凸优化问题，避免了传统周期H-无穷综合中固有的网格化评估耦合条件。", "result": "通过一个太阳能电站卫星的实例，验证了所提出的周期卫星姿态控制方法的有效性。", "conclusion": "所提出的鲁棒周期控制器在卫星姿态控制中有效，且具有透明、易于实现的结构。", "translation": "本文提出了一种用于卫星鲁棒周期姿态控制的新颖方法。在综合过程中考虑卫星动力学的周期性，可以在轨道上实现恒定的性能和鲁棒性要求。所提出的设计遵循混合灵敏度控制设计，采用物理驱动的加权方案。控制器通过一种新颖的结构化线性时变周期输出反馈综合方法计算，该方法保证了最优的L2性能。该综合提出了一个凸优化问题，并避免了传统周期H-无穷综合中固有的网格化评估耦合条件。此外，该控制器具有透明且易于实现的结构。本文使用一个太阳能电站卫星来演示所提出的周期卫星姿态控制方法的有效性。", "summary": "本文介绍了一种用于卫星鲁棒周期姿态控制的新颖方法。该方法通过将卫星动力学的周期性纳入控制器设计，确保了在整个轨道上的恒定性能和鲁棒性。它采用混合灵敏度控制设计和物理驱动的加权方案，并通过一种创新的结构化线性时变周期输出反馈综合来计算控制器，该综合形成一个凸优化问题，避免了传统方法的复杂性。该控制器结构透明且易于实现，并已通过太阳能电站卫星的案例验证了其有效性。", "keywords": "鲁棒控制, 周期控制, 卫星姿态跟踪, 混合灵敏度, 凸优化", "comments": "本文的创新点在于提出了一种新颖的结构化线性时变周期输出反馈综合方法，该方法将控制器设计转化为一个凸优化问题，从而避免了传统周期H-无穷综合中复杂的网格化评估，简化了设计过程并保证了最优性能。这种方法对于需要长期稳定控制的周期性系统，如卫星姿态控制，具有重要意义。"}}
{"id": "2507.13586", "title": "TexGS-VolVis: Expressive Scene Editing for Volume Visualization via Textured Gaussian Splatting", "authors": ["Kaiyuan Tang", "Kuangshi Ai", "Jun Han", "Chaoli Wang"], "categories": ["cs.GR", "cs.CL", "cs.CV"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      Accepted by IEEE VIS 2025", "url": "http://arxiv.org/abs/2507.13586v1", "summary": "Advancements in volume visualization (VolVis) focus on extracting insights\nfrom 3D volumetric data by generating visually compelling renderings that\nreveal complex internal structures. Existing VolVis approaches have explored\nnon-photorealistic rendering techniques to enhance the clarity, expressiveness,\nand informativeness of visual communication. While effective, these methods\noften rely on complex predefined rules and are limited to transferring a single\nstyle, restricting their flexibility. To overcome these limitations, we\nadvocate the representation of VolVis scenes using differentiable Gaussian\nprimitives combined with pretrained large models to enable arbitrary style\ntransfer and real-time rendering. However, conventional 3D Gaussian primitives\ntightly couple geometry and appearance, leading to suboptimal stylization\nresults. To address this, we introduce TexGS-VolVis, a textured Gaussian\nsplatting framework for VolVis. TexGS-VolVis employs 2D Gaussian primitives,\nextending each Gaussian with additional texture and shading attributes,\nresulting in higher-quality, geometry-consistent stylization and enhanced\nlighting control during inference. Despite these improvements, achieving\nflexible and controllable scene editing remains challenging. To further enhance\nstylization, we develop image- and text-driven non-photorealistic scene editing\ntailored for TexGS-VolVis and 2D-lift-3D segmentation to enable partial editing\nwith fine-grained control. We evaluate TexGS-VolVis both qualitatively and\nquantitatively across various volume rendering scenes, demonstrating its\nsuperiority over existing methods in terms of efficiency, visual quality, and\nediting flexibility.", "comment": "Accepted by IEEE VIS 2025", "pdf_url": "http://arxiv.org/pdf/2507.13586v1", "cate": "cs.GR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "TexGS-VolVis：通过纹理高斯散射实现体可视化中的富有表现力的场景编辑", "tldr": "TexGS-VolVis利用纹理2D高斯散射实现富有表现力的实时体可视化，支持任意风格迁移和灵活场景编辑，优于现有方法。", "motivation": "现有体可视化方法依赖复杂预定义规则，仅限于单一风格迁移，缺乏灵活性；传统3D高斯基元几何与外观紧密耦合，导致风格化效果不佳。", "method": "提出TexGS-VolVis框架，利用可微分高斯基元结合预训练大模型实现任意风格迁移和实时渲染。TexGS-VolVis采用2D高斯基元，为每个高斯扩展纹理和着色属性，实现高质量、几何一致的风格化和增强的光照控制。此外，开发了针对TexGS-VolVis的图像和文本驱动非真实感场景编辑，以及2D-lift-3D分割，实现细粒度局部编辑。", "result": "TexGS-VolVis在效率、视觉质量和编辑灵活性方面优于现有方法，并通过定性和定量评估得到验证。", "conclusion": "TexGS-VolVis通过创新的纹理高斯散射方法，有效解决了现有体可视化在风格迁移和场景编辑方面的局限性，提供了高效、高质量且灵活的解决方案。", "translation": "体可视化（VolVis）的进展主要集中于通过生成具有视觉吸引力的渲染，揭示复杂的内部结构，从而从3D体数据中提取洞察。现有的体可视化方法已探索非真实感渲染技术，以增强视觉传达的清晰度、表现力和信息量。尽管这些方法有效，但它们通常依赖复杂的预定义规则，并且仅限于单一风格的迁移，从而限制了其灵活性。为了克服这些局限性，我们提倡使用可微分高斯基元结合预训练大型模型来表示体可视化场景，以实现任意风格迁移和实时渲染。然而，传统的3D高斯基元紧密耦合几何和外观，导致次优的风格化结果。为了解决这个问题，我们引入了TexGS-VolVis，一个用于体可视化的纹理高斯散射框架。TexGS-VolVis采用2D高斯基元，为每个高斯扩展了额外的纹理和着色属性，从而在推理过程中实现了更高质量、几何一致的风格化和增强的光照控制。尽管有这些改进，实现灵活可控的场景编辑仍然具有挑战性。为了进一步增强风格化，我们开发了针对TexGS-VolVis的图像和文本驱动的非真实感场景编辑，以及2D-lift-3D分割，以实现细粒度的局部编辑。我们对TexGS-VolVis在各种体渲染场景中进行了定性和定量评估，证明其在效率、视觉质量和编辑灵活性方面优于现有方法。", "summary": "TexGS-VolVis是一个新颖的纹理高斯散射体可视化框架，旨在解决现有方法在风格迁移受限和风格化效果不佳等方面的局限。它采用扩展了纹理和着色属性的2D高斯基元，实现了高质量、几何一致的风格化和增强的光照控制。该框架还集成了图像和文本驱动的非真实感场景编辑以及2D-lift-3D分割，以实现灵活细粒度的控制。评估结果表明，TexGS-VolVis在效率、视觉质量和编辑灵活性方面均优于现有方法，为富有表现力的体渲染提供了解决方案。", "keywords": "体可视化, 高斯散射, 风格迁移, 场景编辑, 非真实感渲染", "comments": "该论文的创新点在于引入了纹理2D高斯基元，并将其与预训练大模型结合，用于体可视化中的任意风格迁移和实时渲染。此外，其图像和文本驱动的场景编辑以及2D-lift-3D分割实现了细粒度控制，极大地提升了灵活性。这对于体可视化领域是重要的进展，能够显著增强其在不同应用中的表现力和实用性。"}}
{"id": "2507.13414", "title": "Gauge Flow Models", "authors": ["Alexander Strunk", "Roland Assam"], "categories": ["cs.LG", "cs.AI", "math.DG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13414v1", "summary": "This paper introduces Gauge Flow Models, a novel class of Generative Flow\nModels. These models incorporate a learnable Gauge Field within the Flow\nOrdinary Differential Equation (ODE). A comprehensive mathematical framework\nfor these models, detailing their construction and properties, is provided.\nExperiments using Flow Matching on Gaussian Mixture Models demonstrate that\nGauge Flow Models yields significantly better performance than traditional Flow\nModels of comparable or even larger size. Additionally, unpublished research\nindicates a potential for enhanced performance across a broader range of\ngenerative tasks.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13414v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "规范流模型", "tldr": "本文引入了规范流模型，一种新型生成流模型，通过在流ODE中加入可学习的规范场，在高斯混合模型上表现优于传统流模型。", "motivation": "为了提升生成流模型的性能，本文引入了一种新型的生成流模型。", "method": "本文引入了规范流模型，通过在流常微分方程（ODE）中融入一个可学习的规范场来构建。论文提供了详细的数学框架，阐述了其构建和性质。", "result": "在对高斯混合模型进行的流匹配实验中，规范流模型表现出比同等或更大规模的传统流模型显著更优的性能。此外，未发表的研究表明其在更广泛的生成任务中也可能增强性能。", "conclusion": "规范流模型通过引入可学习的规范场，显著提升了生成流模型的性能，并有望在更多生成任务中展现优势。", "translation": "本文介绍了规范流模型，一类新颖的生成流模型。这些模型在流常微分方程（ODE）中融入了一个可学习的规范场。文中提供了这些模型的全面数学框架，详细阐述了它们的构建和性质。使用流匹配在高斯混合模型上的实验表明，规范流模型比同等或更大规模的传统流模型表现出显著更优的性能。此外，未发表的研究表明其在更广泛的生成任务中也具有增强性能的潜力。", "summary": "本文提出了一种名为规范流模型的新型生成流模型，其核心创新在于将一个可学习的规范场整合到流常微分方程中。研究提供了详细的数学理论框架，并通过在高斯混合模型上的流匹配实验验证了其优越性，结果显示规范流模型在性能上显著超越了传统流模型。初步研究还预示了其在更多生成任务中的潜力。", "keywords": "规范流模型, 生成流模型, 规范场, 流匹配, 常微分方程", "comments": "该论文的创新点在于将“规范场”这一概念引入到生成流模型中，通过在流ODE中加入可学习的规范场，有效提升了模型的性能。在高斯混合模型上的实验结果令人鼓舞，表明了其潜在的优越性。如果未来的研究能在更广泛、更复杂的生成任务上验证其泛化能力，这将是生成模型领域的一个重要进展。"}}
{"id": "2507.13492", "title": "On the time integration for phase field modeling of grain growth in additive manufacturing", "authors": ["Chaoqian Yuan", "Chinnapat Panwisawas", "Ye Lu"], "categories": ["physics.comp-ph", "cs.NA", "math.NA"], "primary_category": "Subjects:       Computational Physics (physics.comp-ph)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13492v1", "summary": "Phase field simulations play a key role in the understanding of\nmicrostructure evolution in additive manufacturing. However, they have been\nfound extremely computationally expensive. One of the reasons is the small time\nstep requirement to resolve the complex microstructure evolution during the\nrapid solidification process. This paper investigates the possibility of using\na class of stabilized time integration algorithms to accelerate such phase\nfield simulations by increasing the time steps. The specific time integration\nformulation and theoretical analysis on energy stability were developed, based\non a phase field model dedicated to simulating rapid solidification in additive\nmanufacturing. The numerical results confirmed that the proposed method can\nensure the numerical stability and a decreasing energy requirement for the\nphase field simulations with at least two orders-of-magnitude larger time steps\nover conventional explicit methods. 2D and 3D phase field simulations have been\nconducted with relevant physical and kinetic parameters for 316L stainless\nsteels. This work provides a numerical framework for efficient phase field\nsimulations and open numerous opportunities for large scale phase field\nmodeling.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13492v1", "cate": "physics.comp-ph", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "增材制造中晶粒生长的相场建模时间积分研究", "tldr": "本文提出了一种稳定的时间积分算法，用于加速增材制造中的相场模拟，显著提高了计算效率，允许更大的时间步长。", "motivation": "相场模拟在理解增材制造中的微观结构演变方面至关重要，但计算成本极高，主要原因是需要很小的时间步长来解析快速凝固过程中的复杂微观结构演变。", "method": "本文研究了一类稳定的时间积分算法，以通过增加时间步长来加速相场模拟。基于专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析。", "result": "数值结果证实，所提出的方法可以确保相场模拟的数值稳定性和能量需求降低，与传统显式方法相比，时间步长至少可以增加两个数量级。已针对316L不锈钢进行了2D和3D相场模拟，并使用了相关的物理和动力学参数。", "conclusion": "这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模提供了大量机会。", "translation": "相场模拟在理解增材制造中的微观结构演变方面发挥着关键作用。然而，它们被发现计算成本极高。其中一个原因是需要很小的时间步长来解析快速凝固过程中的复杂微观结构演变。本文研究了使用一类稳定的时间积分算法来加速此类相场模拟的可能性，通过增加时间步长。基于专门用于模拟增材制造中快速凝固的相场模型，开发了特定的时间积分公式和能量稳定性理论分析。数值结果证实，所提出的方法可以确保相场模拟的数值稳定性和能量需求降低，与传统显式方法相比，时间步长至少可以增加两个数量级。已经使用316L不锈钢的相关物理和动力学参数进行了2D和3D相场模拟。这项工作为高效的相场模拟提供了一个数值框架，并为大规模相场建模提供了大量机会。", "summary": "本研究旨在解决增材制造中相场模拟计算成本高昂的问题，尤其是在快速凝固过程中的小时间步长限制。论文提出并开发了一种稳定的时间积分算法，通过理论分析和数值验证，证明其能显著增大时间步长（至少两个数量级），同时保持数值稳定性和降低能量需求。这项工作为大规模、高效的相场模拟提供了新的数值框架。", "keywords": "相场模拟, 增材制造, 时间积分, 计算效率, 晶粒生长", "comments": "这项研究的创新之处在于其通过引入一种新型的稳定时间积分算法，极大地提升了相场模拟的计算效率，解决了长期以来制约其在大规模增材制造微观结构模拟中应用的主要瓶颈。其允许时间步长增加两个数量级的能力，预示着该方法在工业应用和复杂系统模拟中具有巨大的潜力。"}}
{"id": "2406.12385", "title": "Fast Graph Vector Search via Hardware Acceleration and Delayed-Synchronization Traversal", "authors": ["Wenqi Jiang", "Hang Hu", "Torsten Hoefler", "Gustavo Alonso"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "Comments:      Accepted by VLDB'25", "url": "http://arxiv.org/abs/2406.12385v2", "summary": "Vector search systems are indispensable in large language model (LLM)\nserving, search engines, and recommender systems, where minimizing online\nsearch latency is essential. Among various algorithms, graph-based vector\nsearch (GVS) is particularly popular due to its high search performance and\nquality. However, reducing GVS latency by intra-query parallelization remains\nchallenging due to limitations imposed by both existing hardware architectures\n(CPUs and GPUs) and the inherent difficulty of parallelizing graph traversals.\nTo efficiently serve low-latency GVS, we co-design hardware and algorithm by\nproposing Falcon and Delayed-Synchronization Traversal (DST). Falcon is a\nhardware GVS accelerator that implements efficient GVS operators, pipelines\nthese operators, and reduces memory accesses by tracking search states with an\non-chip Bloom filter. DST is an efficient graph traversal algorithm that\nsimultaneously improves search performance and quality by relaxing traversal\norders to maximize accelerator utilization. Evaluation across various graphs\nand datasets shows that Falcon, prototyped on FPGAs, together with DST,\nachieves up to 4.3x and 19.5x lower latency and up to 8.0x and 26.9x\nimprovements in energy efficiency over CPU- and GPU-based GVS systems.", "comment": "Accepted by VLDB'25", "pdf_url": "http://arxiv.org/pdf/2406.12385v2", "cate": "cs.AR", "date": "2024-06-18", "updated": "2025-07-18", "AI": {"title_translation": "经由硬件加速和延迟同步遍历的快速图向量搜索", "tldr": "本文提出了一种名为Falcon的硬件加速器和名为DST的算法，通过软硬件协同设计，显著降低了图向量搜索的延迟并提高了能效。", "motivation": "向量搜索系统在大型语言模型（LLM）服务、搜索引擎和推荐系统中不可或缺，且最大限度地降低在线搜索延迟至关重要。图基向量搜索（GVS）因其高性能和高质量而流行，但由于现有硬件架构（CPU和GPU）的限制以及图遍历并行化的固有难度，通过查询内并行化来降低GVS延迟仍然具有挑战性。", "method": "为了高效地提供低延迟GVS，本文共同设计了硬件和算法，提出了Falcon和延迟同步遍历（DST）。Falcon是一个硬件GVS加速器，它实现了高效的GVS操作符，对这些操作符进行流水线处理，并通过片上布隆过滤器跟踪搜索状态以减少内存访问。DST是一种高效的图遍历算法，通过放宽遍历顺序以最大限度地提高加速器利用率，从而同时提高搜索性能和质量。", "result": "在各种图和数据集上的评估表明，在FPGA上原型化的Falcon与DST相结合，与基于CPU和GPU的GVS系统相比，延迟分别降低了高达4.3倍和19.5倍，能效分别提高了高达8.0倍和26.9倍。", "conclusion": "通过硬件加速器Falcon和延迟同步遍历（DST）算法的软硬件协同设计，可以显著降低图向量搜索的延迟并大幅提高能效。", "translation": "向量搜索系统在大型语言模型（LLM）服务、搜索引擎和推荐系统中不可或缺，其中最大限度地降低在线搜索延迟至关重要。在各种算法中，基于图的向量搜索（GVS）因其高搜索性能和高质量而特别受欢迎。然而，由于现有硬件架构（CPU和GPU）的限制以及图遍历并行化的固有难度，通过查询内并行化来降低GVS延迟仍然具有挑战性。为了高效地提供低延迟GVS，我们通过提出Falcon和延迟同步遍历（DST）共同设计了硬件和算法。Falcon是一个硬件GVS加速器，它实现了高效的GVS操作符，对这些操作符进行流水线处理，并通过片上布隆过滤器跟踪搜索状态以减少内存访问。DST是一种高效的图遍历算法，通过放宽遍历顺序以最大限度地提高加速器利用率，从而同时提高搜索性能和质量。在各种图和数据集上的评估表明，在FPGA上原型化的Falcon与DST相结合，与基于CPU和GPU的GVS系统相比，延迟分别降低了高达4.3倍和19.5倍，能效分别提高了高达8.0倍和26.9倍。", "summary": "本文针对图向量搜索（GVS）在现有硬件上并行化困难导致延迟高的挑战，提出了一种软硬件协同设计方案。该方案包括Falcon硬件加速器和延迟同步遍历（DST）算法。Falcon通过高效操作符、流水线和片上布隆过滤器优化硬件执行，DST则通过放宽遍历顺序提升加速器利用率。实验结果显示，该协同设计在延迟和能效方面均大幅超越了传统的CPU和GPU方案。", "keywords": "图向量搜索, 硬件加速, 延迟同步遍历, Falcon, FPGA", "comments": "这篇论文的创新点在于其软硬件协同设计方法，特别是针对图遍历并行化固有的难题，通过定制硬件加速器（Falcon）和优化算法（DST）来克服。Falcon的片上布隆过滤器设计用于减少内存访问，而DST通过“延迟同步”策略最大化硬件利用率，这些都是非常巧妙且实用的工程优化。其在FPGA上的原型验证并取得显著性能和能效提升，表明了其潜在的实际应用价值，尤其是在对延迟和能耗敏感的LLM服务等领域。"}}
{"id": "2507.13554", "title": "Sensing and Stopping Interfering Secondary Users: Validation of an Efficient Spectrum Sharing System", "authors": ["Meles Weldegebriel", "Zihan Li", "Dustin Maas", "Greg Hellbourg", "Ning Zhang", "Neal Patwari"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13554v1", "summary": "We present the design and validation of Stoppable Secondary Use (StopSec), a\nprivacy-preserving protocol with the capability to identify a secondary user\n(SU) causing interference to a primary user (PU) and to act quickly to stop the\ninterference. All users are served by a database that provides a feedback\nmechanism from a PU to an interfering SU. We introduce a new lightweight and\nrobust method to watermark an SU's OFDM packet. Through extensive over-the-air\nreal-time experiments, we evaluate StopSec in terms of interference detection,\nidentification, and stopping latency, as well as impact on SUs. We show that\nthe watermarking method avoids negative impact to the secondary data link and\nis robust to real-world time-varying channels. Interfering SUs can be stopped\nin under 150 milliseconds, and when multiple users are simultaneously\ninterfering, they can all be stopped. Even when the interference is 10 dB lower\nthan the noise power, StopSec successfully stops interfering SUs within a few\nseconds of their appearance in the channel. StopSec can be an effective\nspectrum sharing protocol for cases when interference to a PU must be quickly\nand automatically stopped.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13554v1", "cate": "eess.SP", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "感知并阻止干扰的次级用户：高效频谱共享系统的验证", "tldr": "StopSec是一个保护隐私的协议，能够快速识别并阻止对主用户造成干扰的次级用户，即使在低信噪比下也能有效工作。", "motivation": "该研究的动机是设计并验证一个能够识别对主用户造成干扰的次级用户并迅速停止干扰的系统，以实现高效的频谱共享。", "method": "该论文提出并验证了名为StopSec的隐私保护协议。该协议通过一个数据库提供主用户到干扰次级用户的反馈机制。核心方法是引入了一种新型的轻量级且鲁棒的OFDM数据包水印技术。通过广泛的空中实时实验，评估了其在干扰检测、识别、停止延迟以及对次级用户影响方面的性能。", "result": "实验结果表明，水印方法避免了对次级数据链路的负面影响，并且对真实世界中时变的信道具有鲁棒性。干扰的次级用户可以在150毫秒内被阻止，多个同时干扰的用户也能被全部阻止。即使干扰比噪声功率低10 dB，StopSec也能在干扰出现后的几秒内成功阻止干扰的次级用户。", "conclusion": "StopSec可以作为一种有效的频谱共享协议，适用于需要快速自动停止对主用户干扰的场景。", "translation": "我们提出了一个名为“可停止的次级使用”（StopSec）的隐私保护协议的设计与验证，该协议能够识别对主用户（PU）造成干扰的次级用户（SU），并迅速采取行动阻止干扰。所有用户都由一个数据库提供服务，该数据库提供从主用户到干扰次级用户的反馈机制。我们介绍了一种新的轻量级且鲁棒的方法来给次级用户的OFDM数据包加水印。通过广泛的空中实时实验，我们评估了StopSec在干扰检测、识别和停止延迟方面的性能，以及对次级用户的影响。我们表明，水印方法避免了对次级数据链路的负面影响，并且对真实世界中时变的信道具有鲁棒性。干扰的次级用户可以在150毫秒内被阻止，当多个用户同时造成干扰时，它们都可以被阻止。即使干扰比噪声功率低10 dB，StopSec也能在干扰出现后的几秒内成功阻止干扰的次级用户。StopSec可以成为一种有效的频谱共享协议，适用于必须快速自动停止对主用户干扰的情况。", "summary": "该论文设计并验证了一个名为StopSec的隐私保护协议，旨在快速识别并阻止对主用户造成干扰的次级用户。该系统利用数据库反馈机制和一种新型的轻量级OFDM数据包水印技术。通过实际空中实验验证，StopSec能够快速检测、识别并停止干扰，即使在干扰信号远低于噪声水平的情况下也能有效工作，且不影响次级数据链路，展现了其作为高效频谱共享协议的潜力。", "keywords": "频谱共享, 干扰管理, 次级用户, 水印, StopSec", "comments": "该论文的创新点在于提出了一个结合水印技术和数据库反馈机制的隐私保护协议StopSec，用于高效地管理频谱共享中的干扰问题。其实时性（150毫秒内停止干扰）和在低信噪比下的鲁棒性（干扰低于噪声10dB仍有效）是其显著的优势，这对于实际认知无线电和动态频谱接入场景具有重要意义。该系统对于确保主用户服务质量和提高频谱利用率具有重要价值。"}}
{"id": "2505.17735", "title": "SafeAgent: Safeguarding LLM Agents via an Automated Risk Simulator", "authors": ["Xueyang Zhou", "Weidong Wang", "Lin Lu", "Jiawen Shi", "Guiyao Tie", "Yongtian Xu", "Lixing Chen", "Pan Zhou", "Neil Zhenqiang Gong", "Lichao Sun"], "categories": ["cs.AI", "68T07", "I.2.6"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      38 pages;12 figures;12 tables", "url": "http://arxiv.org/abs/2505.17735v2", "summary": "Large Language Model (LLM)-based agents are increasingly deployed in\nreal-world applications such as \"digital assistants, autonomous customer\nservice, and decision-support systems\", where their ability to \"interact in\nmulti-turn, tool-augmented environments\" makes them indispensable. However,\nensuring the safety of these agents remains a significant challenge due to the\ndiverse and complex risks arising from dynamic user interactions, external tool\nusage, and the potential for unintended harmful behaviors. To address this\ncritical issue, we propose AutoSafe, the first framework that systematically\nenhances agent safety through fully automated synthetic data generation.\nConcretely, 1) we introduce an open and extensible threat model, OTS, which\nformalizes how unsafe behaviors emerge from the interplay of user instructions,\ninteraction contexts, and agent actions. This enables precise modeling of\nsafety risks across diverse scenarios. 2) we develop a fully automated data\ngeneration pipeline that simulates unsafe user behaviors, applies\nself-reflective reasoning to generate safe responses, and constructs a\nlarge-scale, diverse, and high-quality safety training dataset-eliminating the\nneed for hazardous real-world data collection. To evaluate the effectiveness of\nour framework, we design comprehensive experiments on both synthetic and\nreal-world safety benchmarks. Results demonstrate that AutoSafe boosts safety\nscores by 45% on average and achieves a 28.91% improvement on real-world tasks,\nvalidating the generalization ability of our learned safety strategies. These\nresults highlight the practical advancement and scalability of AutoSafe in\nbuilding safer LLM-based agents for real-world deployment. We have released the\nproject page at https://auto-safe.github.io/.", "comment": "38 pages;12 figures;12 tables", "pdf_url": "http://arxiv.org/pdf/2505.17735v2", "cate": "cs.AI", "date": "2025-05-23", "updated": "2025-07-18", "AI": {"title_translation": "SafeAgent：通过自动化风险模拟器保护LLM智能体", "tldr": "AutoSafe是一个通过自动化合成数据生成来系统性提升LLM智能体安全性的框架，在安全基准测试上显示出显著的性能提升。", "motivation": "大型语言模型（LLM）智能体在现实世界应用中日益普及，但由于动态用户交互、外部工具使用以及潜在的有害行为，确保其安全性仍然是一个重大挑战。", "method": "我们提出了AutoSafe框架，它通过全自动合成数据生成来增强智能体安全性。具体来说，我们引入了一个开放可扩展的威胁模型OTS，用于形式化不安全行为的产生方式；并开发了一个全自动数据生成管道，该管道模拟不安全用户行为，应用自我反思推理生成安全响应，并构建大规模、多样化、高质量的安全训练数据集。", "result": "实验结果表明，AutoSafe平均将安全分数提高了45%，在真实世界任务中实现了28.91%的改进。", "conclusion": "AutoSafe在构建更安全的LLM智能体方面展现了实际的进步和可扩展性，适用于现实世界部署。", "translation": "大型语言模型（LLM）智能体越来越多地部署在“数字助理、自主客户服务和决策支持系统”等现实世界应用中，它们在“多轮、工具增强环境”中交互的能力使其不可或缺。然而，由于动态用户交互、外部工具使用以及潜在的意外有害行为所带来的多样化和复杂风险，确保这些智能体的安全仍然是一个重大挑战。为了解决这个关键问题，我们提出了AutoSafe，这是第一个通过全自动合成数据生成系统性地增强智能体安全性的框架。具体来说，1) 我们引入了一个开放且可扩展的威胁模型OTS，它形式化了不安全行为如何从用户指令、交互上下文和智能体动作的相互作用中产生。这使得能够精确建模各种场景中的安全风险。2) 我们开发了一个全自动数据生成管道，该管道模拟不安全的用户行为，应用自我反思推理生成安全响应，并构建一个大规模、多样化且高质量的安全训练数据集——消除了对危险真实世界数据收集的需求。为了评估我们框架的有效性，我们对合成和真实世界安全基准进行了全面实验。结果表明，AutoSafe平均将安全分数提高了45%，并在真实世界任务中实现了28.91%的改进，验证了我们学习到的安全策略的泛化能力。这些结果突出了AutoSafe在构建更安全的LLM智能体以进行现实世界部署方面的实际进步和可扩展性。我们已在https://auto-safe.github.io/发布了项目页面。", "summary": "该研究提出了AutoSafe框架，旨在通过全自动合成数据生成来解决大型语言模型（LLM）智能体在现实世界应用中的安全挑战。AutoSafe引入了一个名为OTS的开放威胁模型，用于精确建模安全风险，并开发了一个自动数据生成管道来模拟不安全行为并生成高质量的安全训练数据集。实验证明，AutoSafe能显著提高智能体的安全性能，平均安全分数提升45%，并在真实世界任务中提升28.91%，验证了其学习策略的泛化能力和实用性。", "keywords": "LLM智能体, 安全性, 自动化风险模拟, 合成数据, AutoSafe", "comments": "该论文的创新点在于提出了AutoSafe框架，通过全自动合成数据生成来解决LLM智能体安全性的挑战，避免了危险的真实世界数据收集。其系统化的威胁模型和数据生成管道为提升智能体安全性提供了一条实用且可扩展的路径，对于LLM在现实世界中的安全部署具有重要意义。"}}
{"id": "2507.10637", "title": "A Simple Baseline for Stable and Plastic Neural Networks", "authors": ["Étienne Künzel", "Achref Jaziri", "Visvanathan Ramesh"], "categories": ["cs.LG", "cs.AI", "cs.CV"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      11 pages, 50 figures", "url": "http://arxiv.org/abs/2507.10637v2", "summary": "Continual learning in computer vision requires that models adapt to a\ncontinuous stream of tasks without forgetting prior knowledge, yet existing\napproaches often tip the balance heavily toward either plasticity or stability.\nWe introduce RDBP, a simple, low-overhead baseline that unites two\ncomplementary mechanisms: ReLUDown, a lightweight activation modification that\npreserves feature sensitivity while preventing neuron dormancy, and Decreasing\nBackpropagation, a biologically inspired gradient-scheduling scheme that\nprogressively shields early layers from catastrophic updates. Evaluated on the\nContinual ImageNet benchmark, RDBP matches or exceeds the plasticity and\nstability of state-of-the-art methods while reducing computational cost. RDBP\nthus provides both a practical solution for real-world continual learning and a\nclear benchmark against which future continual learning strategies can be\nmeasured.", "comment": "11 pages, 50 figures", "pdf_url": "http://arxiv.org/pdf/2507.10637v2", "cate": "cs.LG", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "一种稳定且可塑性神经网络的简单基线", "tldr": "RDBP是一种简单、低开销的基线方法，通过结合ReLUDown和递减反向传播，在持续学习中实现了与现有SOTA方法相当或超越的稳定性和可塑性，同时降低了计算成本。", "motivation": "计算机视觉中的持续学习要求模型在不遗忘先前知识的情况下适应连续的任务流，然而现有方法往往在可塑性或稳定性之间严重失衡。", "method": "本文提出了RDBP，一个简单、低开销的基线方法，它结合了两种互补机制：ReLUDown，一种轻量级激活修改，可在防止神经元休眠的同时保持特征敏感性；以及递减反向传播，一种受生物学启发的梯度调度方案，逐步保护早期层免受灾难性更新的影响。", "result": "在Continual ImageNet基准测试中，RDBP在可塑性和稳定性方面与最先进的方法相当或超越，同时降低了计算成本。", "conclusion": "RDBP为现实世界的持续学习提供了一个实用的解决方案，也为未来的持续学习策略提供了一个明确的基准。", "translation": "计算机视觉中的持续学习要求模型在不遗忘先前知识的情况下适应连续的任务流，然而现有方法往往在可塑性或稳定性之间严重失衡。我们引入了RDBP，一个简单、低开销的基线方法，它结合了两种互补机制：ReLUDown，一种轻量级激活修改，可在防止神经元休眠的同时保持特征敏感性；以及递减反向传播，一种受生物学启发的梯度调度方案，逐步保护早期层免受灾难性更新的影响。在Continual ImageNet基准测试中，RDBP在可塑性和稳定性方面与最先进的方法相当或超越，同时降低了计算成本。因此，RDBP既为现实世界的持续学习提供了一个实用的解决方案，也为未来的持续学习策略提供了一个明确的基准。", "summary": "本文提出了一种名为RDBP的持续学习基线方法，旨在解决现有方法在模型可塑性与稳定性之间失衡的问题。RDBP结合了ReLUDown（一种保持特征敏感性并防止神经元休眠的激活修改）和递减反向传播（一种保护早期层免受灾难性更新的梯度调度方案）。实验结果表明，在Continual ImageNet基准测试上，RDBP在保持或超越现有SOTA方法性能的同时，显著降低了计算成本，为持续学习提供了一个实用且高效的解决方案。", "keywords": "持续学习, 神经网络, 稳定性, 可塑性, RDBP", "comments": "RDBP的创新之处在于其结合了激活修改和梯度调度两种机制，以简单高效的方式解决了持续学习中的稳定性-可塑性困境。其低开销特性使其具有很高的实用价值，并有望成为未来持续学习研究的重要基准。"}}
{"id": "2507.13578", "title": "In-Home Social Robots Design for Cognitive Stimulation Therapy in Dementia Care", "authors": ["Emmanuel Akinrintoyo", "Nicole Salomons"], "categories": ["cs.HC"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      Submitted to RO-MAN 2025 (Accepted)", "url": "http://arxiv.org/abs/2507.13578v1", "summary": "Individual cognitive stimulation therapy (iCST) is a non-pharmacological\nintervention for improving the cognition and quality of life of persons with\ndementia (PwDs); however, its effectiveness is limited by low adherence to\ndelivery by their family members. In this work, we present the user-centered\ndesign and evaluation of a novel socially assistive robotic system to provide\niCST therapy to PwDs in their homes for long-term use. We consulted with 16\ndementia caregivers and professionals. Through these consultations, we gathered\ndesign guidelines and developed the prototype. The prototype was validated by\ntesting it with three dementia professionals and five PwDs. The evaluation\nrevealed PwDs enjoyed using the system and are willing to adopt its use over\nthe long term. One shortcoming was the system's speech-to-text capabilities,\nwhere it frequently failed to understand the PwDs.", "comment": "Submitted to RO-MAN 2025 (Accepted)", "pdf_url": "http://arxiv.org/pdf/2507.13578v1", "cate": "cs.HC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "用于痴呆症护理的居家社交机器人设计用于认知刺激疗法", "tldr": "本文设计并评估了一种用于痴呆症患者居家认知刺激疗法（iCST）的新型社交辅助机器人系统。该系统通过用户中心设计开发，并经专业人士和患者验证，显示出良好的长期采纳潜力，但语音识别能力有待提高。", "motivation": "个体认知刺激疗法（iCST）是改善痴呆症患者认知和生活质量的非药物干预措施，但其有效性受限于家庭成员依从性低。", "method": "本研究采用以用户为中心的设计方法，开发了一种社交辅助机器人系统。首先，咨询了16名痴呆症护理人员和专业人士以收集设计指南；随后，开发了原型；最后，通过与三名痴呆症专业人士和五名痴呆症患者进行测试验证了该原型。", "result": "评估结果显示，痴呆症患者喜欢使用该系统，并愿意长期采纳。然而，系统的一个缺点是语音转文本功能，它经常无法理解痴呆症患者的讲话。", "conclusion": "该研究提出的居家社交机器人系统在为痴呆症患者提供iCST方面显示出长期使用的潜力，但其语音转文本功能仍需改进以提高用户体验和系统有效性。", "translation": "个体认知刺激疗法（iCST）是一种非药物干预措施，用于改善痴呆症患者（PwDs）的认知和生活质量；然而，其有效性受限于家庭成员依从性低。在这项工作中，我们提出了一种新型社交辅助机器人系统的以用户为中心的设计和评估，旨在为居家痴呆症患者提供长期iCST疗法。我们咨询了16名痴呆症护理人员和专业人士。通过这些咨询，我们收集了设计指南并开发了原型。该原型通过与三名痴呆症专业人士和五名痴呆症患者进行测试进行了验证。评估显示痴呆症患者喜欢使用该系统并愿意长期采纳。一个缺点是系统的语音转文本功能，它经常无法理解痴呆症患者的讲话。", "summary": "本文介绍了一种以用户为中心设计的居家社交机器人，旨在为痴呆症患者提供认知刺激疗法（iCST），以解决传统家庭主导iCST依从性低的问题。研究团队咨询了护理人员和专业人士，并在此基础上开发了原型，随后与痴呆症专业人士和患者进行了测试验证。评估结果表明，用户对该系统表现出高度的喜爱和长期使用的意愿，但其语音转文本功能仍有待改进。", "keywords": "痴呆症护理, 社交机器人, 认知刺激疗法, 以用户为中心的设计, 居家护理", "comments": "本文在痴呆症护理领域应用社交机器人，解决了iCST依从性这一关键问题，具有创新性。其以用户为中心的设计方法是其一大优点。然而，所识别的语音转文本能力局限性揭示了弱势群体人机交互中的一个常见挑战，并为未来的改进指明了明确方向。"}}
{"id": "2503.07049", "title": "VMTS: Vision-Assisted Teacher-Student Reinforcement Learning for Multi-Terrain Locomotion in Bipedal Robots", "authors": ["Fu Chen", "Rui Wan", "Peidong Liu", "Nanxing Zheng", "Bo Zhou"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.07049v2", "summary": "Bipedal robots, due to their anthropomorphic design, offer substantial\npotential across various applications, yet their control is hindered by the\ncomplexity of their structure. Currently, most research focuses on\nproprioception-based methods, which lack the capability to overcome complex\nterrain. While visual perception is vital for operation in human-centric\nenvironments, its integration complicates control further. Recent reinforcement\nlearning (RL) approaches have shown promise in enhancing legged robot\nlocomotion, particularly with proprioception-based methods. However, terrain\nadaptability, especially for bipedal robots, remains a significant challenge,\nwith most research focusing on flat-terrain scenarios. In this paper, we\nintroduce a novel mixture of experts teacher-student network RL strategy, which\nenhances the performance of teacher-student policies based on visual inputs\nthrough a simple yet effective approach. Our method combines terrain selection\nstrategies with the teacher policy, resulting in superior performance compared\nto traditional models. Additionally, we introduce an alignment loss between the\nteacher and student networks, rather than enforcing strict similarity, to\nimprove the student's ability to navigate diverse terrains. We validate our\napproach experimentally on the Limx Dynamic P1 bipedal robot, demonstrating its\nfeasibility and robustness across multiple terrain types.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.07049v2", "cate": "cs.RO", "date": "2025-03-10", "updated": "2025-07-18", "AI": {"title_translation": "VMTS：视觉辅助师生强化学习用于双足机器人在多地形上的运动", "tldr": "本文提出了一种名为VMTS的视觉辅助师生强化学习策略，用于解决双足机器人在复杂多地形上的运动适应性问题，并通过在Limx Dynamic P1机器人上的实验验证了其有效性和鲁棒性。", "motivation": "双足机器人因其仿人设计在多种应用中潜力巨大，但其复杂结构导致控制困难。现有研究多基于本体感知，难以克服复杂地形。视觉感知对人类中心环境至关重要，但其整合使控制更复杂。强化学习虽有前景，但双足机器人的地形适应性仍是挑战，多数研究集中于平坦地形。", "method": "本文提出了一种新颖的专家混合师生网络强化学习策略，通过简单有效的方法增强了基于视觉输入的师生策略性能。该方法将地形选择策略与教师策略结合，并引入了教师网络和学生网络之间的对齐损失，而非强制严格相似性，以提高学生在不同地形导航的能力。", "result": "在Limx Dynamic P1双足机器人上进行了实验验证，结果表明该方法在多种地形类型上具有可行性和鲁棒性，并且与传统模型相比，性能更优越。", "conclusion": "本文提出的VMTS视觉辅助师生强化学习策略，通过结合地形选择和引入对齐损失，有效提升了双足机器人在多地形环境下的运动适应性和鲁棒性，为复杂地形下的双足机器人控制提供了新的解决方案。", "translation": "双足机器人因其仿人设计在各种应用中具有巨大潜力，但其结构复杂性阻碍了其控制。目前，大多数研究集中于基于本体感知的方法，这些方法缺乏克服复杂地形的能力。虽然视觉感知对于以人为中心的环境中的操作至关重要，但其整合使控制进一步复杂化。最近的强化学习（RL）方法在增强腿式机器人运动方面显示出前景，特别是基于本体感知的方法。然而，地形适应性，特别是对于双足机器人而言，仍然是一个重大挑战，大多数研究集中在平坦地形场景。在本文中，我们引入了一种新颖的专家混合师生网络强化学习策略，通过一种简单而有效的方法，增强了基于视觉输入的师生策略的性能。我们的方法将地形选择策略与教师策略相结合，与传统模型相比，性能更优越。此外，我们引入了教师网络和学生网络之间的对齐损失，而不是强制严格相似性，以提高学生导航不同地形的能力。我们在Limx Dynamic P1双足机器人上通过实验验证了我们的方法，证明了其在多种地形类型上的可行性和鲁棒性。", "summary": "本文介绍了一种名为VMTS的新型视觉辅助师生强化学习策略，旨在解决双足机器人在复杂多地形环境下的运动适应性挑战。该方法结合了专家混合师生网络和视觉输入，通过整合地形选择策略与教师策略，并引入教师与学生网络间的对齐损失，而非严格相似性，显著提升了机器人在多样地形中的导航能力。实验证明，该方法在Limx Dynamic P1双足机器人上表现出优越的性能、可行性和鲁棒性。", "keywords": "双足机器人, 强化学习, 师生网络, 多地形运动, 视觉辅助", "comments": "该论文的创新点在于将视觉感知与强化学习中的师生网络策略相结合，以解决双足机器人在复杂多地形上的运动适应性问题。通过引入地形选择策略和柔性的对齐损失，而非严格的相似性约束，提高了模型的泛化能力和鲁应性，对于推动双足机器人在非结构化环境中的应用具有重要意义。"}}
{"id": "2507.13913", "title": "Political Leaning and Politicalness Classification of Texts", "authors": ["Matous Volf", "Jakub Simko"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13913v1", "summary": "This paper addresses the challenge of automatically classifying text\naccording to political leaning and politicalness using transformer models. We\ncompose a comprehensive overview of existing datasets and models for these\ntasks, finding that current approaches create siloed solutions that perform\npoorly on out-of-distribution texts. To address this limitation, we compile a\ndiverse dataset by combining 12 datasets for political leaning classification\nand creating a new dataset for politicalness by extending 18 existing datasets\nwith the appropriate label. Through extensive benchmarking with leave-one-in\nand leave-one-out methodologies, we evaluate the performance of existing models\nand train new ones with enhanced generalization capabilities.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13913v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "文本政治倾向与政治性分类", "tldr": "本文研究了使用Transformer模型对文本进行政治倾向和政治性分类的挑战，发现现有方法对分布外文本表现不佳。为解决此问题，作者构建了多样化数据集，并训练了泛化能力更强的模型。", "motivation": "现有文本政治倾向和政治性分类方法是孤立的解决方案，对分布外文本表现不佳。", "method": "作者通过组合12个现有数据集构建了政治倾向分类数据集，并通过扩展18个现有数据集创建了政治性分类数据集。论文还使用留一法进行广泛基准测试，评估现有模型并训练新的、泛化能力更强的模型。", "result": "通过构建多样化数据集和训练新模型，提高了文本政治倾向和政治性分类的泛化能力，解决了现有方法在分布外文本上表现不佳的问题。", "conclusion": "通过构建多样化数据集和训练泛化能力更强的模型，可以有效解决文本政治倾向和政治性分类中现有方法对分布外文本表现差的问题。", "translation": "这篇论文探讨了如何使用Transformer模型自动对文本进行政治倾向和政治性分类的挑战。我们全面概述了针对这些任务的现有数据集和模型，发现当前方法创建了孤立的解决方案，在分布外文本上表现不佳。为了解决这一局限性，我们通过组合12个政治倾向分类数据集构建了一个多样化的数据集，并通过扩展18个现有数据集并添加适当的标签创建了一个新的政治性数据集。通过使用留一法进行的广泛基准测试，我们评估了现有模型的性能，并训练了具有增强泛化能力的新模型。", "summary": "本文针对使用Transformer模型进行文本政治倾向和政治性自动分类的挑战。研究发现现有方法在处理分布外文本时表现不佳。为解决此问题，作者构建了一个综合性数据集，整合了12个政治倾向分类数据集，并扩展了18个现有数据集以创建政治性分类数据集。通过广泛的基准测试，评估并训练了具有更强泛化能力的新模型。", "keywords": "政治倾向分类, 政治性分类, Transformer模型, 数据集构建, 泛化能力", "comments": "本文的创新点在于通过整合和扩展现有数据集来构建一个大规模、多样化的数据集，以解决现有模型在处理分布外文本时的泛化能力差的问题。这种方法对于提高文本政治性分析的鲁棒性具有重要意义。"}}
{"id": "2507.14057", "title": "Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design", "authors": ["Marcel Hedman", "Desi R. Ivanova", "Cong Guan", "Tom Rainforth"], "categories": ["stat.ML", "cs.LG"], "primary_category": "Subjects:       Machine Learning (stat.ML)", "pdf_link": null, "comments": "Comments:      Accepted at Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada. PMLR 267, 2025", "url": "http://arxiv.org/abs/2507.14057v1", "summary": "We develop a semi-amortized, policy-based, approach to Bayesian experimental\ndesign (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing,\nfully amortized, policy-based BED approaches, Step-DAD trains a design policy\nupfront before the experiment. However, rather than keeping this policy fixed,\nStep-DAD periodically updates it as data is gathered, refining it to the\nparticular experimental instance. This test-time adaptation improves both the\nflexibility and the robustness of the design strategy compared with existing\napproaches. Empirically, Step-DAD consistently demonstrates superior\ndecision-making and robustness compared with current state-of-the-art BED\nmethods.", "comment": "Accepted at Proceedings of the 42nd International Conference on\n  Machine Learning, Vancouver, Canada. PMLR 267, 2025", "pdf_url": "http://arxiv.org/pdf/2507.14057v1", "cate": "stat.ML", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Step-DAD：半摊销基于策略的贝叶斯实验设计", "tldr": "Step-DAD是一种半摊销的贝叶斯实验设计方法，它在实验过程中周期性更新设计策略，从而提高了灵活性和鲁棒性，并优于现有方法。", "motivation": "现有完全摊销的贝叶斯实验设计方法在实验过程中设计策略是固定的，这可能限制了其灵活性和鲁棒性。", "method": "本文开发了一种名为分步深度自适应设计（Step-DAD）的半摊销、基于策略的贝叶斯实验设计方法。与现有方法预先训练固定策略不同，Step-DAD在数据收集过程中周期性地更新和优化设计策略，以适应特定的实验实例。", "result": "经验证明，与当前最先进的贝叶斯实验设计方法相比，Step-DAD在决策制定和鲁棒性方面表现出持续的优越性。", "conclusion": "通过在实验过程中周期性更新设计策略，Step-DAD显著提高了贝叶斯实验设计的灵活性和鲁棒性，并超越了现有技术水平。", "translation": "我们开发了一种名为分步深度自适应设计（Step-DAD）的半摊销、基于策略的贝叶斯实验设计（BED）方法。与现有的、完全摊销的、基于策略的BED方法类似，Step-DAD在实验前预先训练一个设计策略。然而，Step-DAD并没有保持这个策略固定不变，而是在数据收集时周期性地更新它，使其针对特定的实验实例进行优化。与现有方法相比，这种测试时自适应性提高了设计策略的灵活性和鲁棒性。经验表明，与当前最先进的BED方法相比，Step-DAD持续展现出卓越的决策制定能力和鲁棒性。", "summary": "本文提出了一种名为Step-DAD的半摊销、基于策略的贝叶斯实验设计方法。与现有预训练固定策略的完全摊销方法不同，Step-DAD在实验过程中根据收集到的数据周期性地更新和优化设计策略，从而提高了设计策略的灵活性和鲁棒性。实验结果表明，Step-DAD在决策制定和鲁棒性方面均优于当前最先进的贝叶斯实验设计方法。", "keywords": "贝叶斯实验设计, 半摊销, 策略更新, 自适应设计, Step-DAD", "comments": "这篇论文的创新点在于引入了“半摊销”的概念，即在实验过程中动态更新设计策略，而非依赖预先训练好的固定策略。这种测试时自适应性显著提升了贝叶斯实验设计的灵活性和鲁棒性，解决了现有完全摊销方法可能存在的局限性，对实际应用具有重要意义。"}}
{"id": "2506.13107", "title": "Honesty in Causal Forests: When It Helps and When It Hurts", "authors": ["Yanfang Hou", "Carlos Fernández-Loría"], "categories": ["cs.LG", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13107v2", "summary": "Causal forests estimate how treatment effects vary across individuals,\nguiding personalized interventions in areas like marketing, operations, and\npublic policy. A standard modeling practice with this method is honest\nestimation: dividing the data so that the subgroups used to model treatment\neffect variation are formed separately from the data used to estimate those\neffects. This is intended to reduce overfitting and is the default in many\nsoftware packages. But is it always the right choice? In this paper, we show\nthat honest estimation can reduce the accuracy of individual-level treatment\neffect estimates, especially when there are substantial differences in how\nindividuals respond to treatment, and the data is rich enough to uncover those\ndifferences. The core issue is a classic bias-variance trade-off: honesty\nlowers the risk of overfitting but increases the risk of underfitting, because\nit limits the data available to detect patterns. Across 7,500 benchmark\ndatasets, we find that the cost of using honesty by default can be as high as\nrequiring 75% more data to match the performance of models trained without it.\nWe argue that honesty is best understood as a form of regularization, and like\nany regularization choice, its use should be guided by out-of-sample\nperformance, not adopted reflexively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13107v2", "cate": "cs.LG", "date": "2025-06-16", "updated": "2025-07-18", "AI": {"title_translation": "因果森林中的“诚实”：何时有益，何时有害", "tldr": "因果森林中的“诚实”估计（一种数据分割实践）旨在减少过拟合，但本研究表明它实际上可能降低个体层面治疗效果估计的准确性，尤其是在数据丰富且个体响应差异大时。这是一种偏差-方差权衡，可能导致欠拟合，并需要更多数据才能达到相同性能。因此，应将其视为一种正则化选择，并根据样本外表现而非默认采用。", "motivation": "因果森林中的“诚实”估计是一种标准的数据分割实践，旨在减少过拟合，并且是许多软件的默认设置。然而，作者质疑这种做法是否总是正确的选择，并探究其对估计准确性的影响。", "method": "作者通过理论分析指出“诚实”估计可能降低个体层面治疗效果估计的准确性，尤其是在个体对治疗的反应差异显著且数据足够丰富以揭示这些差异时。他们通过对7,500个基准数据集的实验验证了这一发现，并将其核心问题归结为经典的偏差-方差权衡。他们还提出“诚实”应被理解为一种正则化形式。", "result": "研究发现，“诚实”估计会降低个体层面治疗效果估计的准确性，尤其是在个体对治疗的反应差异显著且数据丰富时。这是因为“诚实”估计虽然降低了过拟合的风险，但增加了欠拟合的风险，因为它限制了用于检测模式的数据量。在7,500个基准数据集上，默认使用“诚实”估计的成本高达需要多75%的数据才能达到未经“诚实”训练模型的性能。", "conclusion": "“诚实”估计应被理解为一种正则化形式，其使用应由样本外表现指导，而不是反射性地默认采用。", "translation": "因果森林估计治疗效果在个体间的差异，指导市场营销、运营和公共政策等领域的个性化干预。这种方法的一种标准建模实践是“诚实”估计：分割数据，使得用于建模治疗效果变化的子组与用于估计这些效果的数据分开形成。这旨在减少过拟合，并且是许多软件包中的默认设置。但它总是正确的选择吗？在本文中，我们表明“诚实”估计会降低个体层面治疗效果估计的准确性，尤其是在个体对治疗的反应存在显著差异，并且数据足够丰富以揭示这些差异时。核心问题是一个经典的偏差-方差权衡：“诚实”降低了过拟合的风险，但增加了欠拟合的风险，因为它限制了可用于检测模式的数据。在7,500个基准数据集上，我们发现默认使用“诚实”的成本可能高达需要多75%的数据才能与未经其训练的模型的性能相匹配。我们认为“诚实”最好被理解为一种正则化形式，像任何正则化选择一样，其使用应由样本外表现指导，而不是反射性地采用。", "summary": "本文探讨了因果森林中“诚实”估计实践的有效性。尽管旨在减少过拟合，但研究发现它在数据丰富且个体响应差异大时，反而会降低个体层面治疗效果估计的准确性。这是一种偏差-方差权衡，可能导致欠拟合，并需额外75%的数据才能达到相同性能。作者建议将“诚实”视为一种正则化方法，其应用应基于样本外表现而非默认采用。", "keywords": "因果森林, 诚实估计, 偏差-方差权衡, 正则化, 治疗效果", "comments": "这篇论文创新性地挑战了因果森林中广泛采用的“诚实”估计这一标准实践，并重新将其定义为一种正则化形式。其重要性在于揭示了这种默认做法可能带来的负面影响，即在特定条件下反而降低模型准确性并增加数据需求。研究结果对因果推断领域的数据分割和模型选择具有重要的指导意义，提醒研究者和实践者应更批判性地评估“诚实”估计的适用性。"}}
{"id": "2507.13775", "title": "Nonlinear Distortion Equalization in Multi-Span Optical Links Via a Feed-Forward Photonic Neural Network", "authors": ["Emiliano Staffoli", "Elisabetta Ferri", "Stefano Gretter", "Lorenzo Pavesi"], "categories": ["physics.optics", "cs.ET", "eess.SP"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "Comments:      21 pages, 14 figures, 2 tables", "url": "http://arxiv.org/abs/2507.13775v1", "summary": "Linear and nonlinear distortions in optical communication signals are\nequalized using an integrated feed-forward Photonic Neural Network (PNN). The\nPNN is based on a linear stage made of an 8-tap Finite Impulse Response (FIR)\nfilter, featuring tunable amplitude and phase weights at each tap, and of a\nnonlinear stage achieved through the square modulus operation at the\nend-of-line photodetector. Within an Intensity Modulation/Direct Detection\n(IMDD) system, the PNN is applied to 2-level Pulse Amplitude Modulated (PAM2)\noptical signals undergoing multi-span propagation. Each 50 km segment includes\nfiber transmission, optical power restoration, and optional chromatic\ndispersion compensation via a Tunable Dispersion Compensator. Positioned at the\nreceiver, the PNN enables fully optical signal processing with minimal latency\nand power consumption. Experimental validation is conducted using a\nSilicon-On-Insulator device operating on 10 Gbps signals. It demonstrates\nchromatic dispersion equalization over distances up to 200 km and self-phase\nmodulation (with dispersion removed) up to 450 km. Simulations explore PNN\nadaptation for 100 Gbps modulations and its potential for cross-phase\nmodulation equalization.", "comment": "21 pages, 14 figures, 2 tables", "pdf_url": "http://arxiv.org/pdf/2507.13775v1", "cate": "physics.optics", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "多跨度光链路中基于前馈光子神经网络的非线性失真均衡", "tldr": "该研究利用集成式前馈光子神经网络（PNN）对多跨度光链路中的线性和非线性失真进行均衡，实现了低延迟、低功耗的光信号处理，并在实验中验证了色散和自相位调制均衡能力。", "motivation": "解决光通信信号中存在的线性和非线性失真问题，并寻求一种低延迟、低功耗的解决方案。", "method": "使用集成式前馈光子神经网络（PNN）进行失真均衡。PNN包含一个由8抽头有限脉冲响应（FIR）滤波器组成的线性级和一个通过线尾光电探测器处的平方模运算实现的非线性级。PNN应用于强度调制/直接检测（IMDD）系统中的2电平脉冲幅度调制（PAM2）光信号，并放置在接收端以实现全光信号处理。实验使用绝缘体上硅器件对10 Gbps信号进行验证，仿真探索了PNN在100 Gbps调制下的适应性及其在交叉相位调制均衡方面的潜力。", "result": "PNN实现了对光通信信号中线性和非线性失真的均衡。实现了低延迟和低功耗的全光信号处理。实验验证表明，在10 Gbps信号下，实现了长达200 km的色散均衡。在去除色散的情况下，实现了长达450 km的自相位调制均衡。仿真结果表明PNN有潜力适应100 Gbps调制并用于交叉相位调制均衡。", "conclusion": "光子神经网络（PNN）能够有效均衡多跨度光链路中的线性和非线性失真，提供了一种高效、低功耗的全光信号处理方案，并在实验和仿真中展现了其在高速光通信系统中的应用潜力。", "translation": "在光通信信号中，使用集成式前馈光子神经网络（PNN）对线性和非线性失真进行均衡。该PNN基于一个由8抽头有限脉冲响应（FIR）滤波器组成的线性级，该滤波器在每个抽头处具有可调幅度和相位权重，以及一个通过线尾光电探测器处的平方模运算实现的非线性级。在强度调制/直接检测（IMDD）系统中，PNN应用于经过多跨度传播的2电平脉冲幅度调制（PAM2）光信号。每个50公里段包括光纤传输、光功率恢复以及通过可调色散补偿器进行的可选色散补偿。PNN位于接收端，能够实现低延迟和低功耗的全光信号处理。使用在10 Gbps信号上运行的绝缘体上硅器件进行了实验验证。实验证明了在高达200公里的距离上的色散均衡，以及在高达450公里（去除色散）的自相位调制均衡。仿真探索了PNN对100 Gbps调制的适应性及其在交叉相位调制均衡方面的潜力。", "summary": "本文提出并实验验证了一种基于集成式前馈光子神经网络（PNN）的方法，用于均衡多跨度光链路中的线性和非线性失真。该PNN由一个8抽头FIR滤波器线性级和一个平方模非线性级组成，并应用于IMDD系统中的PAM2光信号。实验结果显示，PNN在10 Gbps信号下能实现长达200 km的色散均衡和长达450 km的自相位调制均衡。仿真进一步探讨了其在100 Gbps调制和交叉相位调制均衡中的应用潜力，展示了PNN作为一种低延迟、低功耗全光信号处理方案的有效性。", "keywords": "光子神经网络, 非线性失真均衡, 多跨度光链路, 光通信, 色散补偿", "comments": "这篇论文通过引入光子神经网络（PNN）来解决光通信中的线性和非线性失真问题，具有显著的创新性。PNN的全光处理特性使其在降低延迟和功耗方面具有巨大优势，这对于未来高速、大容量光通信系统至关重要。实验验证了其在色散和自相位调制均衡方面的有效性，并展望了其在更高比特率下的应用潜力，为光通信领域提供了一种有前景的解决方案。"}}
{"id": "2507.13410", "title": "Causal Language Control in Multilingual Transformers via Sparse Feature Steering", "authors": ["Cheng-Ting Chou", "George Liu", "Jessica Sun", "Cole Blondin", "Kevin Zhu", "Vasu Sharma", "Sean O'Brien"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13410v1", "summary": "Deterministically controlling the target generation language of large\nmultilingual language models (LLMs) remains a fundamental challenge,\nparticularly in zero-shot settings where neither explicit language prompts nor\nfine-tuning are available. In this work, we investigate whether sparse\nautoencoder (SAE) features, previously shown to correlate with interpretable\nmodel behaviors, can be leveraged to steer the generated language of LLMs\nduring inference. Leveraging pretrained SAEs on the residual streams of\nGemma-2B and Gemma-9B, we identify features whose activations differ most\nsignificantly between English and four target languages: Chinese, Japanese,\nSpanish, and French. By modifying just a single SAE feature at one transformer\nlayer, we achieve controlled language shifts with up to 90\\% success, as\nmeasured by FastText language classification, while preserving semantic\nfidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)\nsimilarity. Our analysis reveals that language steering is most effective in\nmid-to-late transformer layers and is amplified by specific attention heads\ndisproportionately associated with language-sensitive SAE features. These\nresults demonstrate the promise of sparse feature steering as a lightweight and\ninterpretable mechanism for controllable multilingual generation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13410v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "多语言Transformer中通过稀疏特征引导实现因果语言控制", "tldr": "本文研究了如何利用稀疏自编码器（SAE）特征在多语言LLM推理过程中控制生成语言，通过修改单个SAE特征可实现高达90%的语言转换成功率，同时保持语义忠实度。", "motivation": "在零样本设置下，确定性地控制大型多语言语言模型（LLMs）的目标生成语言仍然是一个基本挑战，尤其是在没有明确语言提示或微调的情况下。", "method": "利用稀疏自编码器（SAE）特征，这些特征已被证明与可解释的模型行为相关。在Gemma-2B和Gemma-9B的残差流上使用预训练的SAE，识别出在英语和四种目标语言（中文、日语、西班牙语、法语）之间激活差异最大的特征。通过仅修改一个Transformer层中的单个SAE特征来实现语言控制。", "result": "通过FastText语言分类器衡量，实现了高达90%的受控语言转换成功率。根据LaBSE（Language-Agnostic BERT Sentence Embedding）相似性，保持了语义忠实度。语言引导在Transformer模型的中后期层中最有效。特定的注意力头与语言敏感的SAE特征不成比例地相关，并放大了语言引导效果。", "conclusion": "稀疏特征引导作为一种轻量级且可解释的多语言生成控制机制，展现了其前景。", "translation": "大型多语言语言模型（LLMs）在零样本设置下确定性地控制目标生成语言仍然是一个基本挑战，尤其是在没有明确语言提示或微调的情况下。在这项工作中，我们研究了稀疏自编码器（SAE）特征是否可以用于在推理过程中引导LLMs的生成语言，这些特征此前已被证明与可解释的模型行为相关。利用Gemma-2B和Gemma-9B残差流上的预训练SAE，我们识别出在英语和四种目标语言（中文、日语、西班牙语、法语）之间激活差异最大的特征。通过仅修改一个Transformer层中的单个SAE特征，我们实现了高达90%的受控语言转换成功率（通过FastText语言分类器衡量），同时根据LaBSE（Language-Agnostic BERT Sentence Embedding）相似性保持了语义忠实度。我们的分析表明，语言引导在Transformer模型的中后期层中最有效，并且通过与语言敏感SAE特征不成比例相关的特定注意力头得到放大。这些结果证明了稀疏特征引导作为一种轻量级且可解释的可控多语言生成机制的潜力。", "summary": "本文探讨了一种在大型多语言语言模型（LLMs）中控制目标生成语言的新方法，尤其是在零样本设置下。研究人员利用稀疏自编码器（SAE）特征，通过在Gemma-2B和Gemma-9B模型中识别并修改与特定语言相关的单个SAE特征，成功实现了高达90%的语言转换，同时保持了语义内容。研究还发现，这种语言引导在中后期Transformer层中效果最佳，并与特定的注意力头有关。这表明稀疏特征引导是一种有前景的、轻量级且可解释的多语言生成控制机制。", "keywords": "稀疏特征引导, 多语言Transformer, 语言控制, 稀疏自编码器, 因果干预", "comments": "这项工作创新性地利用了稀疏自编码器（SAE）特征来直接、因果地控制多语言Transformer模型的输出语言，尤其是在零样本场景下。其重要性在于提供了一种轻量级且高度可解释的机制，避免了昂贵的微调或复杂的提示工程。通过修改单个特征实现高成功率并保持语义忠实度，展示了SAE在理解和控制LLM内部行为方面的强大潜力。"}}
{"id": "2507.14126", "title": "Toward Temporal Causal Representation Learning with Tensor Decomposition", "authors": ["Jianhong Chen", "Meng Zhao", "Mostafa Reisi Gahrooei", "Xubo Yue"], "categories": ["cs.LG", "cs.AI", "stat.ML"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14126v1", "summary": "Temporal causal representation learning is a powerful tool for uncovering\ncomplex patterns in observational studies, which are often represented as\nlow-dimensional time series. However, in many real-world applications, data are\nhigh-dimensional with varying input lengths and naturally take the form of\nirregular tensors. To analyze such data, irregular tensor decomposition is\ncritical for extracting meaningful clusters that capture essential information.\nIn this paper, we focus on modeling causal representation learning based on the\ntransformed information. First, we present a novel causal formulation for a set\nof latent clusters. We then propose CaRTeD, a joint learning framework that\nintegrates temporal causal representation learning with irregular tensor\ndecomposition. Notably, our framework provides a blueprint for downstream tasks\nusing the learned tensor factors, such as modeling latent structures and\nextracting causal information, and offers a more flexible regularization design\nto enhance tensor decomposition. Theoretically, we show that our algorithm\nconverges to a stationary point. More importantly, our results fill the gap in\ntheoretical guarantees for the convergence of state-of-the-art irregular tensor\ndecomposition. Experimental results on synthetic and real-world electronic\nhealth record (EHR) datasets (MIMIC-III), with extensive benchmarks from both\nphenotyping and network recovery perspectives, demonstrate that our proposed\nmethod outperforms state-of-the-art techniques and enhances the explainability\nof causal representations.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14126v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "迈向基于张量分解的时间因果表示学习", "tldr": "本文提出CaRTeD，一个结合时间因果表示学习和不规则张量分解的联合学习框架，用于处理高维、变长的不规则张量数据，并在理论和实践中证明其优于现有方法并增强了因果表示的可解释性。", "motivation": "在许多实际应用中，数据是高维的、输入长度可变，并自然地以不规则张量的形式出现。分析此类数据，不规则张量分解对于提取有意义的聚类至关重要。现有方法在处理这种不规则张量数据进行时间因果表示学习时存在挑战。", "method": "本文首先提出了一种针对一组潜在聚类的新颖因果公式。然后，提出了CaRTeD，一个将时间因果表示学习与不规则张量分解相结合的联合学习框架。该框架为利用学习到的张量因子进行下游任务（如建模潜在结构和提取因果信息）提供了蓝图，并提供了更灵活的正则化设计来增强张量分解。", "result": "理论上，该算法收敛到一个驻点，并填补了现有不规则张量分解收敛理论保证的空白。在合成数据集和真实世界电子健康记录（EHR）数据集（MIMIC-III）上的实验结果表明，所提出的方法优于现有技术，并增强了因果表示的可解释性。", "conclusion": "本文提出的CaRTeD框架通过整合时间因果表示学习和不规则张量分解，有效解决了高维、不规则张量数据的分析挑战，并在理论和实践上取得了显著的性能提升和可解释性增强。", "translation": "时间因果表示学习是揭示观测研究中复杂模式的强大工具，这些模式通常表示为低维时间序列。然而，在许多实际应用中，数据是高维的、输入长度可变，并自然地以不规则张量的形式出现。为了分析此类数据，不规则张量分解对于提取捕获基本信息的有意义的聚类至关重要。在本文中，我们专注于基于转换信息建模因果表示学习。首先，我们提出了一种针对一组潜在聚类的新颖因果公式。然后，我们提出了CaRTeD，一个将时间因果表示学习与不规则张量分解相结合的联合学习框架。值得注意的是，我们的框架为使用学习到的张量因子进行下游任务（例如建模潜在结构和提取因果信息）提供了蓝图，并提供了更灵活的正则化设计以增强张量分解。理论上，我们证明了我们的算法收敛到一个驻点。更重要的是，我们的结果填补了现有不规则张量分解收敛理论保证的空白。在合成数据集和真实世界电子健康记录（EHR）数据集（MIMIC-III）上的实验结果，以及来自表型分析和网络恢复视角的广泛基准测试，表明我们提出的方法优于现有技术并增强了因果表示的可解释性。", "summary": "本文提出了一种新颖的联合学习框架CaRTeD，旨在解决高维、变长的不规则张量数据在时间因果表示学习中的挑战。该框架首先提出了潜在聚类的因果公式，然后将时间因果表示学习与不规则张量分解相结合。CaRTeD不仅为下游任务提供了灵活的正则化设计和操作蓝图，还在理论上证明了算法的收敛性，并填补了现有理论空白。在合成数据和真实EHR数据集上的实验验证了CaRTeD优于现有技术，并显著提升了因果表示的可解释性。", "keywords": "时间因果表示学习, 不规则张量分解, CaRTeD, 电子健康记录, 因果推断", "comments": "该论文的创新点在于提出了CaRTeD框架，首次将时间因果表示学习与不规则张量分解进行有效整合，以处理现实世界中复杂的高维不规则张量数据。其重要性体现在不仅提供了理论上的收敛性保证，还通过实验证明了在电子健康记录等实际应用中的优越性能和因果可解释性，为复杂时间序列数据的因果推断提供了新的视角和工具。"}}
{"id": "2507.14083", "title": "Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection", "authors": ["Sara Abdulaziz", "Egor Bondarev"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACIVS 2025", "url": "http://arxiv.org/abs/2507.14083v1", "summary": "Advancements in deep learning have improved anomaly detection in surveillance\nvideos, yet they raise urgent privacy concerns due to the collection of\nsensitive human data. In this paper, we present a comprehensive analysis of\nanomaly detection performance under four human anonymization techniques,\nincluding blurring, masking, encryption, and avatar replacement, applied to the\nUCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,\nBN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method\nresponds to different obfuscation techniques. Experimental results demonstrate\nthat anomaly detection remains viable under anonymized data and is dependent on\nthe algorithmic design and the learning strategy. For instance, under certain\nanonymization patterns, such as encryption and masking, some models\ninadvertently achieve higher AUC performance compared to raw data, due to the\nstrong responsiveness of their algorithmic components to these noise patterns.\nThese results highlight the algorithm-specific sensitivities to anonymization\nand emphasize the trade-off between preserving privacy and maintaining\ndetection utility. Furthermore, we compare these conventional anonymization\ntechniques with the emerging privacy-by-design solutions, highlighting an often\noverlooked trade-off between robust privacy protection and utility flexibility.\nThrough comprehensive experiments and analyses, this study provides a\ncompelling benchmark and insights into balancing human privacy with the demands\nof anomaly detection.", "comment": "ACIVS 2025", "pdf_url": "http://arxiv.org/pdf/2507.14083v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "揭示性能差距：人类匿名化及其对视频异常检测影响的比较研究", "tldr": "本文分析了人类匿名化技术对视频异常检测性能的影响，发现检测在匿名化数据下仍可行且性能取决于算法设计，有时甚至能提高性能，并强调了隐私与实用性之间的权衡。", "motivation": "深度学习在监控视频异常检测方面的进步引发了对敏感人类数据收集的紧迫隐私担忧。本研究旨在全面分析在不同人类匿名化技术下异常检测的性能，以解决这一隐私问题。", "method": "研究使用了模糊、遮蔽、加密和头像替换四种人类匿名化技术，并将其应用于UCF-Crime数据集。在此基础上，评估了MGFN、UR-DMU、BN-WVAD和PEL4VAD四种异常检测方法，以揭示它们对不同混淆技术的响应。此外，还比较了传统匿名化技术与新兴的隐私设计解决方案。", "result": "实验结果表明，异常检测在匿名化数据下仍然可行，其性能取决于算法设计和学习策略。在某些匿名化模式（如加密和遮蔽）下，一些模型由于其算法组件对噪声模式的强烈响应，无意中实现了比原始数据更高的AUC性能。这突出了算法对匿名化的特定敏感性，并强调了隐私保护与检测实用性之间的权衡。研究还揭示了强大的隐私保护和实用性灵活性之间经常被忽视的权衡。", "conclusion": "本研究通过全面的实验和分析，为平衡人类隐私与异常检测需求提供了一个引人注目的基准和深入见解。", "translation": "深度学习的进步提高了监控视频中的异常检测能力，但由于敏感人类数据的收集，它们引发了紧迫的隐私问题。在本文中，我们对四种人类匿名化技术（包括模糊、遮蔽、加密和头像替换）应用于UCF-Crime数据集下的异常检测性能进行了全面分析。我们评估了四种异常检测方法，MGFN、UR-DMU、BN-WVAD和PEL4VAD，在匿名化的UCF-Crime数据集上，以揭示每种方法如何响应不同的混淆技术。实验结果表明，异常检测在匿名化数据下仍然可行，并且取决于算法设计和学习策略。例如，在某些匿名化模式下，如加密和遮蔽，一些模型由于其算法组件对这些噪声模式的强烈响应，无意中实现了比原始数据更高的AUC性能。这些结果突出了算法对匿名化的特定敏感性，并强调了隐私保护和检测实用性之间的权衡。此外，我们将这些传统匿名化技术与新兴的隐私设计解决方案进行了比较，突出了强大的隐私保护和实用性灵活性之间经常被忽视的权衡。通过全面的实验和分析，本研究提供了一个引人注目的基准，并为平衡人类隐私与异常检测需求提供了见解。", "summary": "本文针对监控视频异常检测中因数据收集引起的隐私问题，全面分析了四种人类匿名化技术（模糊、遮蔽、加密、头像替换）对四种异常检测方法（MGFN、UR-DMU、BN-WVAD、PEL4VAD）在UCF-Crime数据集上的影响。研究发现，匿名化数据下异常检测仍可行，其性能依赖于算法设计，某些情况下甚至能提高性能，揭示了算法对匿名化的敏感性及隐私与实用性的权衡。本研究为平衡人类隐私和异常检测需求提供了基准和见解。", "keywords": "视频异常检测, 人类匿名化, 隐私保护, 性能评估, 权衡", "comments": "这篇论文的创新点在于系统性地比较了多种人类匿名化技术对视频异常检测性能的影响，并揭示了算法对不同匿名化模式的特异性响应，甚至在某些情况下匿名化反而能提高检测性能这一反直觉的发现。它强调了在隐私保护和数据实用性之间进行权衡的重要性，为未来设计兼顾隐私和性能的异常检测系统提供了宝贵的基准和指导。"}}
{"id": "2507.05887", "title": "GeoMag: A Vision-Language Model for Pixel-level Fine-Grained Remote Sensing Image Parsing", "authors": ["Xianzhi Ma", "Jianhui Li", "Changhua Pei", "Hao Liu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.05887v2", "summary": "The application of Vision-Language Models (VLMs) in remote sensing (RS) image\nunderstanding has achieved notable progress, demonstrating the basic ability to\nrecognize and describe geographical entities. However, existing RS-VLMs are\nmostly limited to image-level and region-level tasks, lacking the capability to\nhandle pixel-level tasks and performing poorly in small-object recognition\nscenarios. Moreover, RS-VLMs consume significant computational resources when\nprocessing high-resolution RS images, further restricting their practical\napplicability. In this context, we propose GeoMag (Geographical Magnifier), an\nend-to-end general-purpose large model framework for RS. GeoMag dynamically\nfocuses the attention scope based on prompt semantics to effectively perform\nremote sensing image parsing across multiple levels of granularity. This method\nintroduces Task-driven Multi-granularity Resolution Adjustment (TMRA) and\nPrompt-guided Semantic-aware Cropping (PSC), which adaptively reduce the\nspatial resolution of task-irrelevant regions while enhancing the visual\nrepresentation of task-relevant areas. This approach improves the model's\nperception of critical target regions, suppresses background redundancy, and\nreduces the computational cost of interpreting high-resolution RS imagery.\nExtensive comparative experiments on 10 benchmarks demonstrate that GeoMag not\nonly excels in handling pixel-level tasks but also maintains competitive\nperformance across tasks of other granularities compared to existing RS-VLMs.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.05887v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-18", "AI": {"title_translation": "GeoMag：一种用于像素级细粒度遥感图像解析的视觉-语言模型", "tldr": "GeoMag是一个新的视觉-语言模型，通过动态调整分辨率和语义裁剪来解决现有遥感视觉-语言模型在像素级任务和小目标识别方面的不足，并降低计算成本。", "motivation": "现有的遥感视觉-语言模型（RS-VLMs）主要限于图像级和区域级任务，缺乏处理像素级任务的能力，并且在小目标识别场景中表现不佳。此外，处理高分辨率遥感图像时计算资源消耗巨大，限制了其实用性。", "method": "GeoMag（Geographical Magnifier）是一个端到端、通用的大型遥感模型框架。它通过基于提示语义动态聚焦注意力范围，以多粒度级别有效执行遥感图像解析。该方法引入了任务驱动的多粒度分辨率调整（TMRA）和提示引导的语义感知裁剪（PSC），自适应地降低与任务无关区域的空间分辨率，同时增强与任务相关区域的视觉表示。这提高了模型对关键目标区域的感知，抑制了背景冗余，并降低了解释高分辨率遥感图像的计算成本。", "result": "在10个基准测试上的大量对比实验表明，GeoMag不仅在处理像素级任务方面表现出色，而且在其他粒度任务上与现有RS-VLMs相比也保持了竞争力。", "conclusion": "GeoMag成功解决了现有遥感视觉-语言模型在像素级处理和小目标识别方面的局限性，并有效降低了计算成本，在多粒度遥感图像解析任务中展现出卓越性能。", "translation": "视觉-语言模型（VLMs）在遥感（RS）图像理解中的应用取得了显著进展，展示了识别和描述地理实体的基本能力。然而，现有的遥感视觉-语言模型大多局限于图像级和区域级任务，缺乏处理像素级任务的能力，并且在小目标识别场景中表现不佳。此外，遥感视觉-语言模型在处理高分辨率遥感图像时消耗大量计算资源，进一步限制了其实际适用性。在此背景下，我们提出了GeoMag（地理放大器），一个用于遥感的端到端通用大型模型框架。GeoMag根据提示语义动态聚焦注意力范围，以有效执行多粒度遥感图像解析。该方法引入了任务驱动的多粒度分辨率调整（TMRA）和提示引导的语义感知裁剪（PSC），自适应地降低与任务无关区域的空间分辨率，同时增强与任务相关区域的视觉表示。这种方法提高了模型对关键目标区域的感知，抑制了背景冗余，并降低了解释高分辨率遥感图像的计算成本。在10个基准测试上的大量对比实验表明，GeoMag不仅在处理像素级任务方面表现出色，而且在其他粒度任务上与现有遥感视觉-语言模型相比也保持了竞争力。", "summary": "GeoMag是一种新型的视觉-语言模型，专为解决遥感图像理解中像素级细粒度解析的挑战而设计。针对现有模型在像素级任务和小目标识别上的不足以及高分辨率图像处理的计算开销问题，GeoMag引入了任务驱动的多粒度分辨率调整（TMRA）和提示引导的语义感知裁剪（PSC）机制。这些机制使模型能够根据语义动态调整注意力范围和分辨率，从而提高对关键区域的感知并降低计算成本。实验结果表明，GeoMag在像素级任务上表现优异，并在其他粒度任务上保持了竞争力。", "keywords": "视觉-语言模型, 遥感图像解析, 像素级, 多粒度, GeoMag", "comments": "GeoMag的创新之处在于其提出的TMRA和PSC机制，通过动态调整分辨率和语义裁剪，有效解决了遥感领域中像素级细粒度解析的难题，并显著降低了高分辨率图像处理的计算负担。这对于提升遥感图像理解的实用性和效率具有重要意义。"}}
{"id": "2507.13871", "title": "Safety Certification in the Latent space using Control Barrier Functions and World Models", "authors": ["Mehul Anand", "Shishir Kolathaya"], "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      6 pages, 6 figures. arXiv admin note: text overlap with arXiv:2409.12616", "url": "http://arxiv.org/abs/2507.13871v1", "summary": "Synthesising safe controllers from visual data typically requires extensive\nsupervised labelling of safety-critical data, which is often impractical in\nreal-world settings. Recent advances in world models enable reliable prediction\nin latent spaces, opening new avenues for scalable and data-efficient safe\ncontrol. In this work, we introduce a semi-supervised framework that leverages\ncontrol barrier certificates (CBCs) learned in the latent space of a world\nmodel to synthesise safe visuomotor policies. Our approach jointly learns a\nneural barrier function and a safe controller using limited labelled data,\nwhile exploiting the predictive power of modern vision transformers for latent\ndynamics modelling.", "comment": "6 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:2409.12616", "pdf_url": "http://arxiv.org/pdf/2507.13871v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "潜在空间中基于控制障碍函数和世界模型的安全认证", "tldr": "本文提出一种半监督框架，利用在世界模型潜在空间中学习的控制障碍证书，以有限的标记数据合成安全的视觉运动策略。", "motivation": "从视觉数据合成安全控制器通常需要大量安全关键数据的监督标记，这在实际环境中往往不切实际。", "method": "本文引入了一个半监督框架，该框架利用在世界模型潜在空间中学习的控制障碍证书（CBCs）来合成安全的视觉运动策略。该方法利用有限的标记数据共同学习一个神经障碍函数和一个安全控制器，并利用现代视觉Transformer的预测能力进行潜在动态建模。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "从视觉数据合成安全控制器通常需要对安全关键数据进行大量的监督标记，这在现实世界环境中往往不切实际。世界模型的最新进展使得在潜在空间中进行可靠预测成为可能，为可扩展和数据高效的安全控制开辟了新途径。在这项工作中，我们引入了一个半监督框架，该框架利用在世界模型潜在空间中学习的控制障碍证书（CBCs）来合成安全的视觉运动策略。我们的方法利用有限的标记数据共同学习一个神经障碍函数和一个安全控制器，同时利用现代视觉Transformer的预测能力进行潜在动态建模。", "summary": "本文针对从视觉数据合成安全控制器需要大量监督标记的挑战，提出了一种半监督框架。该框架利用世界模型在潜在空间中学习的控制障碍证书，以有限的标记数据共同学习神经障碍函数和安全控制器，并结合视觉Transformer的预测能力进行潜在动态建模，旨在实现可扩展和数据高效的安全控制。", "keywords": "安全认证, 潜在空间, 控制障碍函数, 世界模型, 半监督学习", "comments": "该论文的创新点在于将控制障碍函数与世界模型及其潜在空间相结合，实现半监督的安全控制器合成，有效解决了传统方法对大量标记数据的依赖问题，提升了数据效率和可扩展性。"}}
{"id": "2507.13716", "title": "Benchmarking of EEG Analysis Techniques for Parkinson's Disease Diagnosis: A Comparison between Traditional ML Methods and Foundation DL Methods", "authors": ["Danilo Avola", "Andrea Bernardini", "Giancarlo Crocetti", "Andrea Ladogana", "Mario Lezoche", "Maurizio Mancini", "Daniele Pannone", "Amedeo Ranaldi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13716v1", "summary": "Parkinson's Disease PD is a progressive neurodegenerative disorder that\naffects motor and cognitive functions with early diagnosis being critical for\neffective clinical intervention Electroencephalography EEG offers a noninvasive\nand costeffective means of detecting PDrelated neural alterations yet the\ndevelopment of reliable automated diagnostic models remains a challenge In this\nstudy we conduct a systematic benchmark of traditional machine learning ML and\ndeep learning DL models for classifying PD using a publicly available oddball\ntask dataset Our aim is to lay the groundwork for developing an effective\nlearning system and to determine which approach produces the best results We\nimplement a unified sevenstep preprocessing pipeline and apply consistent\nsubjectwise crossvalidation and evaluation criteria to ensure comparability\nacross models Our results demonstrate that while baseline deep learning\narchitectures particularly CNNLSTM models achieve the best performance compared\nto other deep learning architectures underlining the importance of capturing\nlongrange temporal dependencies several traditional classifiers such as XGBoost\nalso offer strong predictive accuracy and calibrated decision boundaries By\nrigorously comparing these baselines our work provides a solid reference\nframework for future studies aiming to develop and evaluate more complex or\nspecialized architectures Establishing a reliable set of baseline results is\nessential to contextualize improvements introduced by novel methods ensuring\nscientific rigor and reproducibility in the evolving field of EEGbased\nneurodiagnostics", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13716v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "帕金森病诊断中脑电图分析技术的基准测试：传统机器学习方法与基础深度学习方法的比较", "tldr": "本研究对使用脑电图诊断帕金森病的传统机器学习和基础深度学习方法进行了系统性基准测试，发现CNN-LSTM表现最佳，但XGBoost等传统方法也表现良好，为未来研究提供了可靠的基线。", "motivation": "帕金森病（PD）的早期诊断对有效临床干预至关重要，而脑电图（EEG）提供了一种无创且经济的检测方法。然而，开发可靠的自动化诊断模型仍然是一个挑战。", "method": "本研究使用公开可用的奇偶任务数据集，对传统机器学习（ML）和深度学习（DL）模型进行系统性基准测试以分类帕金森病。研究实施了统一的七步预处理流程，并应用了一致的受试者交叉验证和评估标准，以确保模型间的可比性。", "result": "结果表明，在基础深度学习架构中，特别是CNN-LSTM模型，相比其他深度学习架构取得了最佳性能，强调了捕获长期时间依赖性的重要性。同时，XGBoost等几种传统分类器也表现出强大的预测准确性和校准的决策边界。", "conclusion": "通过严格比较这些基线模型，本研究为未来旨在开发和评估更复杂或专业化架构的研究提供了坚实的参考框架。建立一套可靠的基线结果对于将新方法引入的改进进行背景化至关重要，从而确保基于脑电图的神经诊断领域在不断发展中的科学严谨性和可重复性。", "translation": "帕金森病（PD）是一种进行性神经退行性疾病，影响运动和认知功能，早期诊断对于有效的临床干预至关重要。脑电图（EEG）提供了一种无创且经济的检测帕金森病相关神经改变的方法，然而，开发可靠的自动化诊断模型仍然是一个挑战。在本研究中，我们使用公开可用的奇偶任务数据集，对传统机器学习（ML）和深度学习（DL）模型进行系统性基准测试，用于帕金森病分类。我们的目标是为开发有效的学习系统奠定基础，并确定哪种方法能产生最佳结果。我们实施了统一的七步预处理流程，并应用了一致的受试者交叉验证和评估标准，以确保模型间的可比性。我们的结果表明，虽然基础深度学习架构，特别是CNN-LSTM模型，相比其他深度学习架构取得了最佳性能，强调了捕获长期时间依赖性的重要性，但几种传统分类器，如XGBoost，也提供了强大的预测准确性和校准的决策边界。通过严格比较这些基线，我们的工作为未来旨在开发和评估更复杂或专业化架构的研究提供了坚实的参考框架。建立一套可靠的基线结果对于将新方法引入的改进进行背景化至关重要，从而确保基于脑电图的神经诊断领域在不断发展中的科学严谨性和可重复性。", "summary": "本研究对使用脑电图（EEG）进行帕金森病（PD）诊断的传统机器学习（ML）和基础深度学习（DL）方法进行了系统性基准测试。研究利用公开数据集，采用统一的预处理流程和评估标准，发现CNN-LSTM模型在深度学习架构中表现最佳，同时XGBoost等传统分类器也展现出良好的预测能力。这项工作为未来开发和评估更先进的脑电图神经诊断模型提供了重要的基线参考。", "keywords": "帕金森病, 脑电图, 机器学习, 深度学习, 基准测试", "comments": "本文通过对传统机器学习和基础深度学习方法在帕金森病脑电图诊断中的系统性基准测试，为该领域提供了重要的基线参考。其创新之处在于统一的预处理和评估流程，确保了模型间结果的可比性。这对于未来研究开发更复杂或专业的诊断模型具有重要意义，有助于提升科学严谨性和结果的可重复性。"}}
{"id": "2507.13772", "title": "Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification", "authors": ["Abhijit Sen", "Giridas Maiti", "Bikram K. Parida", "Bhanu P. Mishra", "Mahima Arya", "Denys I. Bondar"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13772v1", "summary": "Feature engineering continues to play a critical role in image\nclassification, particularly when interpretability and computational efficiency\nare prioritized over deep learning models with millions of parameters. In this\nstudy, we revisit classical machine learning based image classification through\na novel approach centered on Permutation Entropy (PE), a robust and\ncomputationally lightweight measure traditionally used in time series analysis\nbut rarely applied to image data. We extend PE to two-dimensional images and\npropose a multiscale, multi-orientation entropy-based feature extraction\napproach that characterizes spatial order and complexity along rows, columns,\ndiagonals, anti-diagonals, and local patches of the image. To enhance the\ndiscriminatory power of the entropy features, we integrate two classic image\ndescriptors: the Histogram of Oriented Gradients (HOG) to capture shape and\nedge structure, and Local Binary Patterns (LBP) to encode micro-texture of an\nimage. The resulting hand-crafted feature set, comprising of 780 dimensions, is\nused to train Support Vector Machine (SVM) classifiers optimized through grid\nsearch. The proposed approach is evaluated on multiple benchmark datasets,\nincluding Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers\ncompetitive classification performance without relying on deep architectures.\nOur results demonstrate that the fusion of PE with HOG and LBP provides a\ncompact, interpretable, and effective alternative to computationally expensive\nand limited interpretable deep learning models. This shows a potential of\nentropy-based descriptors in image classification and contributes a lightweight\nand generalizable solution to interpretable machine learning in image\nclassification and computer vision.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13772v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "特征工程未死：通过熵、HOG和LBP特征融合复兴经典机器学习用于图像分类", "tldr": "该研究通过将排列熵（PE）扩展到二维图像并与HOG和LBP特征融合，为图像分类提供了一种可解释、计算高效的经典机器学习方法，并在基准数据集上取得了有竞争力的性能。", "motivation": "在图像分类中，当可解释性和计算效率优先于参数量庞大的深度学习模型时，特征工程仍然发挥着关键作用。本研究旨在通过一种新颖的方法，重新审视基于经典机器学习的图像分类。", "method": "本研究将排列熵（PE）扩展到二维图像，并提出了一种多尺度、多方向的基于熵的特征提取方法，以表征图像的行、列、对角线、反对角线和局部图像块的空间顺序和复杂性。为了增强熵特征的判别力，该方法集成了方向梯度直方图（HOG）和局部二值模式（LBP）这两种经典的图像描述符。最终生成了一个包含780维的手工特征集，用于训练通过网格搜索优化的支持向量机（SVM）分类器。", "result": "所提出的方法在Fashion-MNIST、KMNIST、EMNIST和CIFAR-10等多个基准数据集上进行了评估，在不依赖深度架构的情况下，提供了有竞争力的分类性能。", "conclusion": "排列熵与HOG和LBP的融合为计算昂贵且可解释性有限的深度学习模型提供了一种紧凑、可解释且有效的替代方案。这表明了基于熵的描述符在图像分类中的潜力，并为图像分类和计算机视觉中的可解释机器学习贡献了一种轻量级且可泛化的解决方案。", "translation": "特征工程在图像分类中继续发挥着关键作用，特别是在可解释性和计算效率优先于拥有数百万参数的深度学习模型时。在本研究中，我们通过一种新颖的方法重新审视了基于经典机器学习的图像分类，该方法围绕排列熵（PE）展开，排列熵是一种稳健且计算量轻的度量，传统上用于时间序列分析，但很少应用于图像数据。我们将PE扩展到二维图像，并提出了一种多尺度、多方向的基于熵的特征提取方法，该方法表征图像的行、列、对角线、反对角线和局部图像块的空间顺序和复杂性。为了增强熵特征的判别力，我们集成了两种经典的图像描述符：方向梯度直方图（HOG）用于捕获形状和边缘结构，以及局部二值模式（LBP）用于编码图像的微纹理。由此产生的手工特征集包含780维，用于训练通过网格搜索优化的支持向量机（SVM）分类器。所提出的方法在Fashion-MNIST、KMNIST、EMNIST和CIFAR-10等多个基准数据集上进行了评估，在不依赖深度架构的情况下，提供了有竞争力的分类性能。我们的结果表明，PE与HOG和LBP的融合为计算昂贵且可解释性有限的深度学习模型提供了一种紧凑、可解释且有效的替代方案。这表明了基于熵的描述符在图像分类中的潜力，并为图像分类和计算机视觉中的可解释机器学习贡献了一种轻量级且可泛化的解决方案。", "summary": "本研究旨在复兴经典机器学习在图像分类中的应用，特别是在强调可解释性和计算效率的场景下。通过将传统用于时间序列分析的排列熵（PE）扩展到二维图像，并开发了一种多尺度、多方向的熵特征提取方法，该方法能够捕捉图像的空间顺序和复杂性。为增强特征的判别力，研究将PE特征与经典的HOG（用于形状和边缘）和LBP（用于微纹理）特征融合。最终，一个780维的手工特征集被用于训练优化后的SVM分类器。实验结果表明，该方法在多个基准数据集（如Fashion-MNIST、KMNIST、EMNIST、CIFAR-10）上取得了与深度学习模型相当的性能，但具有更高的可解释性和计算效率。这证明了熵基描述符在图像分类中的潜力，并提供了一种轻量级、可泛化的可解释机器学习解决方案。", "keywords": "特征工程, 排列熵, HOG, LBP, 图像分类, 经典机器学习", "comments": "该论文的创新点在于将传统上用于时间序列分析的排列熵（PE）创造性地扩展并应用于图像数据，并将其与经典的HOG和LBP特征进行有效融合，构建了一个强大的手工特征集。在深度学习占据主导地位的当下，该研究成功展示了经典机器学习在图像分类中仍具有竞争力，尤其是在对模型可解释性和计算效率有较高要求的场景下。这为资源受限或需要高度透明的AI应用提供了一个有价值的替代方案，挑战了“深度学习是唯一出路”的普遍观念。"}}
{"id": "2410.15654", "title": "Design and Optimization of a Metamaterial Absorber for Solar Energy Harvesting in the THz Frequency Range", "authors": ["Nafisa Anjum", "Alok Kumar Paul"], "categories": ["physics.optics", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Optics (physics.optics)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2410.15654v2", "summary": "This paper introduces the design and comprehensive characterization of a\nnovel three-layer metamaterial absorber, engineered to exploit the unique\noptical properties of gold, vanadium dioxide, and silicon dioxide. At the core\nof this design, silicon dioxide serves as a robust substrate that supports an\nintricately structured layer of gold and a top layer of vanadium dioxide. This\nconfiguration is optimized to harness and enhance absorption capabilities\neffectively across a broadband terahertz (THz) spectrum. The absorber\ndemonstrates an extensive absorption bandwidth of 3.00 THz, spanning\nfrequencies from 2.414 THz to 5.417 THz. Remarkably, throughout this range, the\ndevice maintains a consistently high absorption efficiency, exceeding 90%. This\nefficiency is characterized by two sharp absorption peaks located at 2.638 THz\nand 5.158 THz, which signify the precise tuning of the metamaterial structure\nto interact optimally with specific THz frequencies. The absorbance of the\nproposed model is almost equal to 99%. This absorber is polarization\ninsensitive. The development of this absorber involved a series of theoretical\nsimulations backed by experimental validations, which helped refine the\nmetamaterial's geometry and material composition. This process illuminated the\ncritical role of the dielectric properties of silicon dioxide and the plasmonic\neffects induced by gold and vanadium dioxide layers, which collectively\ncontribute to the high-performance metrics observed.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2410.15654v2", "cate": "physics.optics", "date": "2024-10-21", "updated": "2025-07-17", "AI": {"title_translation": "太赫兹频率范围内用于太阳能收集的超材料吸收器的设计与优化", "tldr": "本文设计并优化了一种三层超材料吸收器，利用金、二氧化钒和二氧化硅，在太赫兹频段实现了宽带、高效、偏振不敏感的吸收，吸收率高达99%。", "motivation": "该研究的动机是设计并优化一种新型超材料吸收器，以利用金、二氧化钒和二氧化硅的独特光学特性，在太赫兹频段有效利用和增强吸收能力，用于太阳能收集。", "method": "研究人员设计了一种新型三层超材料吸收器，其核心是二氧化硅基板，支撑着金的复杂结构层和二氧化钒顶层。通过理论模拟和实验验证相结合，对超材料的几何结构和材料组成进行了优化，以实现宽带太赫兹吸收。", "result": "该吸收器在2.414 THz至5.417 THz的3.00 THz宽带范围内，保持了超过90%的持续高吸收效率，并在2.638 THz和5.158 THz处有两个尖锐的吸收峰。所提出模型的吸收率几乎达到99%，并且具有偏振不敏感性。研究还揭示了二氧化硅的介电特性以及金和二氧化钒层引起的等离子体效应在高性能中的关键作用。", "conclusion": "该研究得出结论，通过优化金、二氧化钒和二氧化硅组成的超材料结构，可以实现宽带、高效、偏振不敏感的太赫兹吸收器，其高性能得益于二氧化硅的介电特性和金、二氧化钒层的等离子体效应。", "translation": "本文介绍了一种新型三层超材料吸收器的设计和全面表征，该吸收器旨在利用金、二氧化钒和二氧化硅独特的金、二氧化钒和二氧化硅独特的光学特性。在该设计的核心，二氧化硅作为坚固的衬底，支撑着一个结构复杂的金层和一个二氧化钒顶层。这种配置经过优化，可在宽带太赫兹（THz）频谱范围内有效地利用和增强吸收能力。该吸收器展示了3.00 THz的广泛吸收带宽，频率范围从2.414 THz到5.417 THz。值得注意的是，在此整个范围内，该器件保持了持续高于90%的高吸收效率。这种效率的特点是在2.638 THz和5.158 THz处有两个尖锐的吸收峰，这表明超材料结构与特定太赫兹频率的最佳相互作用进行了精确调谐。所提出模型的吸收率几乎等于99%。该吸收器具有偏振不敏感性。该吸收器的开发涉及一系列理论模拟并辅以实验验证，这有助于完善超材料的几何结构和材料组成。这一过程阐明了二氧化硅的介电特性以及金和二氧化钒层引起的等离子体效应的关键作用，它们共同促成了所观察到的高性能指标。", "summary": "本文提出并详细表征了一种新型三层超材料吸收器，其由金、二氧化钒和二氧化硅组成。该设计以二氧化硅为基底，承载金的精细结构和二氧化钒顶层，旨在优化太赫兹频段的吸收性能。该吸收器展现出3.00 THz的宽吸收带宽（2.414 THz至5.417 THz），在此范围内吸收效率持续超过90%，并达到99%的峰值吸收率。它还具备偏振不敏感性。研究通过理论模拟和实验验证，揭示了二氧化硅的介电特性和金、二氧化钒的等离子体效应是实现其高性能的关键。", "keywords": "超材料吸收器, 太赫兹, 太阳能收集, 金, 二氧化钒", "comments": "该论文提出了一种新颖的三层超材料吸收器设计，其创新性在于利用金、二氧化钒和二氧化硅的独特组合，实现了在宽带太赫兹频率范围内的超高吸收效率（超过90%，峰值99%）和偏振不敏感性。其重要性体现在为太阳能收集等应用提供了高效的太赫兹吸收解决方案。通过理论模拟和实验验证相结合的方法，增强了研究的可靠性。"}}
{"id": "2507.13804", "title": "Gradient descent avoids strict saddles with a simple line-search method too", "authors": ["Andreea-Alexandra Muşat", "Nicolas Boumal"], "categories": ["math.OC", "cs.NA", "math.DS", "math.NA", "90C30 (Primary) 65K05, 37C75, 58K05 (Secondary)"], "primary_category": "Subjects:       Optimization and Control (math.OC)", "pdf_link": null, "comments": "Comments:      38 pages", "url": "http://arxiv.org/abs/2507.13804v1", "summary": "It is known that gradient descent (GD) on a $C^2$ cost function generically\navoids strict saddle points when using a small, constant step size. However, no\nsuch guarantee existed for GD with a line-search method. We provide one for a\nmodified version of the standard Armijo backtracking method with generic,\narbitrarily large initial step size. In contrast to previous works, our\nanalysis does not require a globally Lipschitz gradient.\n  We extend this to the Riemannian setting (RGD), assuming the retraction is\nreal analytic (though the cost function still only needs to be $C^2$). In\nclosing, we also improve guarantees for RGD with a constant step size in some\nscenarios.", "comment": "38 pages", "pdf_url": "http://arxiv.org/pdf/2507.13804v1", "cate": "math.OC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "梯度下降法通过简单的线搜索方法也能避免严格鞍点", "tldr": "本文证明了带有修改版Armijo线搜索方法的梯度下降（GD）也能避免严格鞍点，并将其扩展到黎曼设置，且分析不要求全局Lipschitz梯度。", "motivation": "已知使用小而恒定步长的梯度下降（GD）通常能避免严格鞍点，但对于使用线搜索方法的GD，此前没有类似的保证。本文旨在填补这一理论空白。", "method": "本文采用标准Armijo回溯方法的一个修改版本，该方法具有通用、任意大的初始步长。作者将此方法扩展到黎曼设置（RGD），假设收缩是实解析的，并且在某些情况下改进了恒定步长RGD的保证。", "result": "研究结果表明，使用修改版Armijo回溯方法的梯度下降（GD）能够避免严格鞍点。与之前的工作不同，该分析不需要全局Lipschitz梯度。此外，该保证已扩展到黎曼设置（RGD），并且在某些场景下，恒定步长RGD的保证也得到了改进。", "conclusion": "梯度下降法，即使结合了修改后的Armijo线搜索等自适应方法，也能避免严格鞍点，这扩展了理论保证，使其适用于更实际的场景和黎曼优化。", "translation": "已知在$C^2$代价函数上，使用小而恒定步长的梯度下降（GD）通常能避免严格鞍点。然而，对于使用线搜索方法的GD，不存在这样的保证。我们为标准Armijo回溯方法的一个修改版本提供了这样的保证，该方法具有通用、任意大的初始步长。与之前的工作不同，我们的分析不需要全局Lipschitz梯度。\n我们将此扩展到黎曼设置（RGD），假设收缩是实解析的（尽管代价函数仍然只需要是$C^2$）。最后，我们还在某些情况下改进了恒定步长RGD的保证。", "summary": "本文证明了梯度下降（GD）与修改后的Armijo回溯线搜索方法结合时，也能避免严格鞍点，这一保证此前仅针对使用小而恒定步长的GD。该分析是新颖的，因为它不要求全局Lipschitz梯度。此外，该发现还扩展到了黎曼设置（RGD），并改进了恒定步长RGD的现有保证。", "keywords": "梯度下降, 严格鞍点, 线搜索, Armijo, 黎曼优化", "comments": "本文的创新之处在于，将避免严格鞍点的理论保证从恒定步长的GD扩展到了结合实际线搜索方法（修改版Armijo）的GD，这对于实际应用更具相关性。放宽全局Lipschitz梯度要求也具有重要意义。将其扩展到黎曼设置进一步拓宽了其适用性。"}}
{"id": "2507.13825", "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction", "authors": ["Haoyang Li", "Yuming Xu", "Yiming Li", "Hanmo Liu", "Darian Li", "Chen Jason Zhang", "Lei Chen", "Qing Li"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Submitted in 2024. Accepted in 2025", "url": "http://arxiv.org/abs/2507.13825v1", "summary": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.", "comment": "Submitted in 2024. Accepted in 2025", "pdf_url": "http://arxiv.org/pdf/2507.13825v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "当速度遇上精度：一种高效且有效的时序链接预测图模型", "tldr": "EAGLE是一种轻量级框架，通过结合短期时间近邻和长期全局结构模式，显著提高了时序链接预测的效率和效果，速度比现有T-GNNs快50倍以上。", "motivation": "动态图中的时序链接预测是一个关键任务，但现有的时序图神经网络（T-GNNs）由于计算开销大，在可扩展性和效率方面面临挑战。", "method": "本文提出了EAGLE框架，它集成了一个时间感知模块（聚合节点最近邻信息）和一个结构感知模块（利用时序个性化PageRank捕获全局重要节点的影响）。EAGLE采用自适应加权机制动态调整两者的贡献，并消除了复杂的多跳消息传递或内存密集型机制。", "result": "在七个真实世界时序图上的大量实验表明，EAGLE在有效性和效率方面均优于最先进的T-GNNs，比基于Transformer的有效T-GNNs实现了超过50倍的加速。", "conclusion": "EAGLE通过其轻量级设计和结合短时近邻与长时全局模式的方法，成功解决了现有T-GNNs的效率和可扩展性问题，并在时序链接预测任务中取得了卓越的性能。", "translation": "动态图中的时序链接预测是一项关键任务，在社交网络、推荐系统和电子商务平台等不同领域都有应用。尽管现有的时序图神经网络（T-GNNs）通过利用复杂的架构来建模时序和结构依赖性取得了显著成功，但它们常常因高计算开销而面临可扩展性和效率挑战。在本文中，我们提出了EAGLE，一个轻量级框架，它整合了短期时间近邻和长期全局结构模式。EAGLE由一个时间感知模块组成，该模块聚合来自节点最近邻的信息以反映其即时偏好；以及一个结构感知模块，该模块利用时序个性化PageRank来捕获全局重要节点的影响。为了平衡这些属性，EAGLE采用了一种自适应加权机制，根据数据特性动态调整它们的贡献。此外，EAGLE消除了对复杂多跳消息传递或内存密集型机制的需求，从而显著提高了效率。在七个真实世界时序图上的大量实验表明，EAGLE在有效性和效率方面均始终优于最先进的T-GNNs，比基于Transformer的有效T-GNNs实现了超过50倍的加速。", "summary": "本文提出了一种名为EAGLE的轻量级图模型，用于解决动态图中时序链接预测任务中现有T-GNNs面临的效率和可扩展性问题。EAGLE通过结合时间感知模块（捕捉短期近邻信息）和结构感知模块（利用时序个性化PageRank捕捉长期全局模式）来建模动态图。该模型采用自适应加权机制平衡两者的贡献，并避免了复杂的计算机制。实验结果表明，EAGLE在保持高预测精度的同时，显著提高了效率，速度比现有方法快50倍以上。", "keywords": "时序链接预测, 动态图, 图神经网络, 效率, EAGLE", "comments": "EAGLE的创新之处在于其轻量级的设计，通过巧妙结合短期时间近邻信息和长期全局结构模式，并采用自适应加权机制，在不牺牲精度的情况下大幅提升了时序链接预测的效率。它避免了传统T-GNNs中复杂的图卷积或多跳消息传递带来的高计算开销，这对于处理大规模动态图具有重要意义。"}}
{"id": "2502.15761", "title": "AIvaluateXR: An Evaluation Framework for on-Device AI in XR with Benchmarking Results", "authors": ["Dawar Khan", "Xinyu Liu", "Omar Mena", "Donggang Jia", "Alexandre Kouyoumdjian", "Ivan Viola"], "categories": ["cs.DC", "cs.AI", "cs.GR", "cs.HC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      AIvaluateXR is updated version of LoXR", "url": "http://arxiv.org/abs/2502.15761v2", "summary": "The deployment of large language models (LLMs) on extended reality (XR)\ndevices has great potential to advance the field of human-AI interaction. In\nthe case of direct, on-device model inference, selecting the appropriate model\nand device for specific tasks remains challenging. In this paper, we present\nAIvaluateXR, a comprehensive evaluation framework for benchmarking LLMs running\non XR devices. To demonstrate the framework, we deploy 17 selected LLMs across\nfour XR platforms: Magic Leap 2, Meta Quest 3, Vivo X100s Pro, and Apple Vision\nPro, and conduct an extensive evaluation. Our experimental setup measures four\nkey metrics: performance consistency, processing speed, memory usage, and\nbattery consumption. For each of the 68 model-device pairs, we assess\nperformance under varying string lengths, batch sizes, and thread counts,\nanalyzing the trade-offs for real-time XR applications. We propose a unified\nevaluation method based on the 3D Pareto Optimality theory to select the\noptimal device-model pairs from quality and speed objectives. Additionally, we\ncompare the efficiency of on-device LLMs with client-server and cloud-based\nsetups, and evaluate their accuracy on two interactive tasks. We believe our\nfindings offer valuable insight to guide future optimization efforts for LLM\ndeployment on XR devices. Our evaluation method can be used as standard\ngroundwork for further research and development in this emerging field. The\nsource code and supplementary materials are available at:\nwww.nanovis.org/AIvaluateXR.html", "comment": "AIvaluateXR is updated version of LoXR", "pdf_url": "http://arxiv.org/pdf/2502.15761v2", "cate": "cs.DC", "date": "2025-02-13", "updated": "2025-07-18", "AI": {"title_translation": "AIvaluateXR：XR设备上AI的评估框架及基准测试结果", "tldr": "AIvaluateXR是一个用于评估和基准测试XR设备上大型语言模型（LLM）的综合框架。该研究对17个LLM在4个XR平台上的性能、速度、内存和功耗进行了广泛测试，并提出了一种基于3D帕累托最优理论的选择方法，以指导未来XR设备上LLM的部署优化。", "motivation": "在XR设备上直接进行大型语言模型（LLM）推理时，为特定任务选择合适的模型和设备仍然具有挑战性。", "method": "本文提出了AIvaluateXR，一个用于基准测试XR设备上LLM的综合评估框架。研究在Magic Leap 2、Meta Quest 3、Vivo X100s Pro和Apple Vision Pro四种XR平台上部署了17个选定的LLM，并进行了广泛评估。实验测量了四个关键指标：性能一致性、处理速度、内存使用和电池消耗。对于68个模型-设备对，评估了在不同字符串长度、批处理大小和线程数下的性能，并分析了实时XR应用的权衡。提出了一种基于3D帕累托最优理论的统一评估方法，以从质量和速度目标中选择最佳设备-模型对。此外，还比较了设备端LLM与客户端-服务器和云端设置的效率，并评估了它们在两个交互任务上的准确性。", "result": "研究提供了LLM在XR设备上部署的详细基准测试结果，量化了不同模型和设备在性能一致性、处理速度、内存使用和电池消耗方面的表现，并分析了在不同字符串长度、批处理大小和线程数下的性能权衡。通过提出的统一评估方法，识别了最优的设备-模型对。同时，还对比了设备端LLM与客户端-服务器及云端设置的效率和在交互任务上的准确性。", "conclusion": "本研究的发现为XR设备上LLM的未来优化工作提供了宝贵的见解。所提出的评估方法可以作为该新兴领域进一步研究和开发的标准基础。", "translation": "大型语言模型（LLM）在扩展现实（XR）设备上的部署在推进人机交互领域方面具有巨大潜力。在直接的设备端模型推理情况下，为特定任务选择合适的模型和设备仍然具有挑战性。本文提出了AIvaluateXR，一个用于基准测试在XR设备上运行的LLM的综合评估框架。为了展示该框架，我们在四个XR平台（Magic Leap 2、Meta Quest 3、Vivo X100s Pro和Apple Vision Pro）上部署了17个选定的LLM，并进行了广泛评估。我们的实验设置测量了四个关键指标：性能一致性、处理速度、内存使用和电池消耗。对于68个模型-设备对中的每一个，我们评估了在不同字符串长度、批处理大小和线程数下的性能，分析了实时XR应用的权衡。我们提出了一种基于3D帕累托最优理论的统一评估方法，以从质量和速度目标中选择最佳的设备-模型对。此外，我们比较了设备端LLM与客户端-服务器和云端设置的效率，并评估了它们在两个交互任务上的准确性。我们相信我们的发现为指导XR设备上LLM部署的未来优化工作提供了宝贵的见解。我们的评估方法可以用作该新兴领域进一步研究和开发的标准基础。源代码和补充材料可在www.nanovis.org/AIvaluateXR.html获取。", "summary": "本文介绍了AIvaluateXR，一个用于评估XR设备上大型语言模型（LLM）性能的综合框架。针对设备端LLM部署中模型和设备选择的挑战，该框架在四种主流XR平台上对17个LLM进行了广泛的基准测试，评估了性能一致性、处理速度、内存使用和电池消耗等关键指标。研究还提出了一种基于3D帕累托最优理论的统一评估方法，以帮助选择最佳的模型-设备组合，并比较了设备端LLM与云端解决方案的效率和准确性。研究结果为XR设备上LLM的优化提供了指导，其评估方法可作为未来研究的标准。", "keywords": "XR设备, 大型语言模型, 设备端AI, 评估框架, 基准测试, 帕累托最优", "comments": "这项研究通过提供一个系统化的评估框架和详尽的基准测试结果，解决了XR设备上LLM部署的关键挑战。其创新性在于提出了AIvaluateXR框架和基于帕累托最优的选型方法，为复杂的模型-设备选择问题提供了量化和优化的解决方案。研究的广泛实验覆盖了多个主流XR平台和LLM，为业界提供了宝贵的实践数据和洞察。这对于推动XR领域的人机交互和设备端AI应用具有重要意义。"}}
{"id": "2507.13931", "title": "Identifiability Analysis of a Pseudo-Two-Dimensional Model & Single Particle Model-Aided Parameter Estimation", "authors": ["L. D. Couto", "K. Haghverdi", "F. Guo", "K. Trad", "G. Mulder"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      9 pages, 2 figures, This work has been presented at the 2025 American Control Conference (ACC) and will appear in the conference proceedings. \\c{opyright} 2025 IEEE", "url": "http://arxiv.org/abs/2507.13931v1", "summary": "This contribution presents a parameter identification methodology for the\naccurate and fast estimation of model parameters in a pseudo-two-dimensional\n(P2D) battery model. The methodology consists of three key elements. First, the\ndata for identification is inspected and specific features herein that need to\nbe captured are included in the model. Second, the P2D model is analyzed to\nassess the identifiability of the physical model parameters and propose\nalternative parameterizations that alleviate possible issues. Finally, diverse\noperating conditions are considered that excite distinct battery dynamics which\nallows the use of different low-order battery models accordingly. Results show\nthat, under low current conditions, the use of low-order models achieve\nparameter estimates at least 500 times faster than using the P2D model at the\nexpense of twice the error. However, if accuracy is a must, these estimated\nparameters can be used to initialize the P2D model and perform the\nidentification in half of the time.", "comment": "9 pages, 2 figures, This work has been presented at the 2025 American\n  Control Conference (ACC) and will appear in the conference proceedings.\n  \\c{opyright} 2025 IEEE", "pdf_url": "http://arxiv.org/pdf/2507.13931v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "伪二维模型的可识别性分析与单粒子模型辅助参数估计", "tldr": "该文提出了一种用于伪二维电池模型参数快速准确估计的方法，通过可识别性分析、数据特征捕捉和低阶模型初始化，显著提高了估计速度。", "motivation": "旨在为伪二维 (P2D) 电池模型提供一种准确、快速的参数估计方法。", "method": "1. 检查用于识别的数据，并将其中需要捕获的特定特征包含在模型中。2. 分析 P2D 模型以评估物理模型参数的可识别性，并提出替代参数化方案以缓解可能的问题。3. 考虑不同的操作条件，这些条件会激发不同的电池动力学，从而允许相应地使用不同的低阶电池模型。", "result": "1. 在低电流条件下，使用低阶模型进行参数估计的速度比使用 P2D 模型快至少 500 倍，但误差增加一倍。2. 如果要求精度，这些估计的参数可用于初始化 P2D 模型，并将识别时间缩短一半。", "conclusion": "提出的方法能够显著提高伪二维电池模型参数的估计速度，尤其是在精度要求高时，通过低阶模型初始化 P2D 模型可有效缩短估计时间。", "translation": "本研究提出了一种参数识别方法，用于伪二维 (P2D) 电池模型中模型参数的准确快速估计。该方法包含三个关键要素。首先，检查用于识别的数据，并将其中需要捕获的特定特征包含在模型中。其次，分析 P2D 模型以评估物理模型参数的可识别性，并提出替代参数化方案以缓解可能的问题。最后，考虑了不同的操作条件，这些条件会激发不同的电池动力学，从而允许相应地使用不同的低阶电池模型。结果表明，在低电流条件下，使用低阶模型进行参数估计的速度比使用 P2D 模型快至少 500 倍，但误差增加一倍。然而，如果精度是必需的，这些估计的参数可用于初始化 P2D 模型，并将识别时间缩短一半。", "summary": "本文提出了一种用于伪二维 (P2D) 电池模型参数准确快速估计的识别方法。该方法包括数据特征检查与模型整合、P2D 模型可识别性分析及替代参数化、以及考虑不同操作条件并利用低阶模型。研究结果表明，在低电流条件下，低阶模型可大幅提高估计速度，但会牺牲一定的精度；而这些初步估计的参数可用于初始化 P2D 模型，从而在保证精度的前提下将识别时间缩短一半。", "keywords": "伪二维模型, 参数估计, 可识别性分析, 低阶模型, 电池模型", "comments": "该论文的创新点在于结合了伪二维模型的识别性分析和低阶模型辅助参数估计的策略。通过对模型参数可识别性的深入分析，并利用低阶模型进行快速初步估计，再用这些估计值初始化高阶模型进行精细识别，有效解决了高精度电池模型参数估计耗时过长的问题。这种分阶段、多模型协作的方法对于实际应用中电池管理系统的参数校准具有重要意义，平衡了估计速度和精度。"}}
{"id": "2507.00498", "title": "MuteSwap: Visual-informed Silent Video Identity Conversion", "authors": ["Yifan Liu", "Yu Fang", "Zhouhan Lin"], "categories": ["cs.SD", "cs.CV", "cs.LG", "cs.MM", "eess.AS"], "primary_category": "Subjects:       Sound (cs.SD)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.00498v2", "summary": "Conventional voice conversion modifies voice characteristics from a source\nspeaker to a target speaker, relying on audio input from both sides. However,\nthis process becomes infeasible when clean audio is unavailable, such as in\nsilent videos or noisy environments. In this work, we focus on the task of\nSilent Face-based Voice Conversion (SFVC), which does voice conversion entirely\nfrom visual inputs. i.e., given images of a target speaker and a silent video\nof a source speaker containing lip motion, SFVC generates speech aligning the\nidentity of the target speaker while preserving the speech content in the\nsource silent video. As this task requires generating intelligible speech and\nconverting identity using only visual cues, it is particularly challenging. To\naddress this, we introduce MuteSwap, a novel framework that employs contrastive\nlearning to align cross-modality identities and minimize mutual information to\nseparate shared visual features. Experimental results show that MuteSwap\nachieves impressive performance in both speech synthesis and identity\nconversion, especially under noisy conditions where methods dependent on audio\ninput fail to produce intelligible results, demonstrating both the\neffectiveness of our training approach and the feasibility of SFVC.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.00498v2", "cate": "cs.SD", "date": "2025-07-01", "updated": "2025-07-18", "AI": {"title_translation": "MuteSwap: 视觉引导的静默视频身份转换", "tldr": "MuteSwap提出了一种基于视觉输入的静默视频语音转换方法（SFVC），通过对比学习和互信息最小化，在无音频输入的情况下实现语音合成和身份转换，尤其适用于嘈杂环境。", "motivation": "传统的语音转换方法依赖于源说话者和目标说话者的音频输入，但在静默视频或嘈杂环境中，干净音频不可用时，这些方法将失效。本研究旨在解决在没有音频输入的情况下进行语音转换的问题。", "method": "MuteSwap框架采用对比学习来对齐跨模态身份，并最小化互信息以分离共享视觉特征。", "result": "实验结果表明，MuteSwap在语音合成和身份转换方面均取得了令人印象深刻的性能，尤其是在依赖音频输入的方法无法产生可理解结果的嘈杂条件下。这证明了其训练方法的有效性和SFVC的可行性。", "conclusion": "MuteSwap证明了仅使用视觉线索进行静默人脸语音转换（SFVC）的可行性，并在嘈杂环境下表现出色，解决了传统语音转换对音频输入的依赖问题。", "translation": "传统的语音转换方法依赖于源说话者和目标说话者的音频输入来修改语音特征。然而，当干净音频不可用时（例如在静默视频或嘈杂环境中），这个过程就变得不可行。在这项工作中，我们专注于基于静默人脸的语音转换（SFVC）任务，它完全通过视觉输入进行语音转换。即，给定目标说话者的图像和包含唇部动作的源说话者的静默视频，SFVC生成与目标说话者身份对齐的语音，同时保留源静默视频中的语音内容。由于这项任务需要仅使用视觉线索生成可理解的语音并转换身份，因此它特别具有挑战性。为了解决这个问题，我们引入了MuteSwap，这是一个新颖的框架，它采用对比学习来对齐跨模态身份，并最小化互信息以分离共享视觉特征。实验结果表明，MuteSwap在语音合成和身份转换方面均取得了令人印象深刻的性能，尤其是在依赖音频输入的方法无法产生可理解结果的嘈杂条件下，这证明了我们训练方法的有效性和SFVC的可行性。", "summary": "MuteSwap提出了一种创新的静默人脸语音转换（SFVC）框架，旨在解决传统语音转换在无音频输入场景下的局限性。该方法仅依赖视觉线索，通过对比学习对齐跨模态身份，并利用互信息最小化分离共享视觉特征，从而实现从静默视频中生成可理解的目标身份语音。实验证明，MuteSwap在语音合成和身份转换方面表现出色，尤其在嘈杂环境下，验证了SFVC技术的可行性与有效性。", "keywords": "静默视频, 语音转换, 视觉输入, 对比学习, 身份转换", "comments": "MuteSwap的创新之处在于其解决了传统语音转换对音频输入的依赖，特别是在静默或嘈杂环境下的应用潜力。通过纯视觉输入实现语音生成和身份转换，极大地拓宽了语音转换技术的应用场景。其采用的对比学习和互信息最小化策略是解决跨模态对齐和特征分离挑战的关键。"}}
{"id": "2507.11554", "title": "Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models", "authors": ["Zejian Li", "Yize Li", "Chenye Meng", "Zhongni Liu", "Yang Ling", "Shengyuan Zhang", "Guang Yang", "Changyuan Yang", "Zhiyuan Yang", "Lingyun Sun"], "categories": ["cs.CV", "cs.AI"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.11554v2", "summary": "Recent advancements in diffusion models (DMs) have been propelled by\nalignment methods that post-train models to better conform to human\npreferences. However, these approaches typically require computation-intensive\ntraining of a base model and a reward model, which not only incurs substantial\ncomputational overhead but may also compromise model accuracy and training\nefficiency. To address these limitations, we propose Inversion-DPO, a novel\nalignment framework that circumvents reward modeling by reformulating Direct\nPreference Optimization (DPO) with DDIM inversion for DMs. Our method conducts\nintractable posterior sampling in Diffusion-DPO with the deterministic\ninversion from winning and losing samples to noise and thus derive a new\npost-training paradigm. This paradigm eliminates the need for auxiliary reward\nmodels or inaccurate appromixation, significantly enhancing both precision and\nefficiency of training. We apply Inversion-DPO to a basic task of text-to-image\ngeneration and a challenging task of compositional image generation. Extensive\nexperiments show substantial performance improvements achieved by Inversion-DPO\ncompared to existing post-training methods and highlight the ability of the\ntrained generative models to generate high-fidelity compositionally coherent\nimages. For the post-training of compostitional image geneation, we curate a\npaired dataset consisting of 11,140 images with complex structural annotations\nand comprehensive scores, designed to enhance the compositional capabilities of\ngenerative models. Inversion-DPO explores a new avenue for efficient,\nhigh-precision alignment in diffusion models, advancing their applicability to\ncomplex realistic generation tasks. Our code is available at\nhttps://github.com/MIGHTYEZ/Inversion-DPO", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.11554v2", "cate": "cs.CV", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "Inversion-DPO：扩散模型精确高效的后训练", "tldr": "Inversion-DPO是一种新的扩散模型对齐框架，通过结合DDIM反演和DPO，无需奖励模型，显著提高了后训练的精度和效率，并在文本到图像和组合图像生成任务中表现出色。", "motivation": "当前的扩散模型对齐方法需要耗费大量计算资源训练基础模型和奖励模型，导致计算开销大，并可能损害模型精度和训练效率。", "method": "我们提出了Inversion-DPO，一个通过将直接偏好优化（DPO）与DDIM反演结合来重新构建扩散模型对齐的框架。它通过从获胜和失败样本到噪声的确定性反演来进行棘手的后验采样，从而避免了奖励模型或不准确的近似，形成了一种新的后训练范式。", "result": "Inversion-DPO在文本到图像生成和组合图像生成任务中实现了显著的性能提升，生成了高保真、组合连贯的图像。针对组合图像生成，我们还整理了一个包含11,140张带有复杂结构注释和综合得分的配对数据集。", "conclusion": "Inversion-DPO为扩散模型的高效、高精度对齐探索了一条新途径，提升了其在复杂现实生成任务中的适用性。", "translation": "扩散模型（DMs）的最新进展得益于对齐方法，这些方法对模型进行后训练以更好地符合人类偏好。然而，这些方法通常需要对基础模型和奖励模型进行计算密集型训练，这不仅会带来大量的计算开销，还可能损害模型精度和训练效率。为了解决这些限制，我们提出了Inversion-DPO，一个新颖的对齐框架，它通过将直接偏好优化（DPO）与DMs的DDIM反演相结合来规避奖励模型。我们的方法通过从获胜和失败样本到噪声的确定性反演来进行扩散-DPO中难以处理的后验采样，从而推导出一个新的后训练范式。这种范式消除了对辅助奖励模型或不准确近似的需求，显著提高了训练的精度和效率。我们将Inversion-DPO应用于文本到图像生成的基本任务和组合图像生成的挑战性任务。大量实验表明，与现有后训练方法相比，Inversion-DPO取得了显著的性能改进，并突出了所训练的生成模型生成高保真、组合连贯图像的能力。对于组合图像生成的后训练，我们整理了一个包含11,140张带有复杂结构注释和综合得分的配对数据集，旨在增强生成模型的组合能力。Inversion-DPO为扩散模型中的高效、高精度对齐探索了一条新途径，推动了其在复杂现实生成任务中的适用性。我们的代码可在https://github.com/MIGHTYEZ/Inversion-DPO获取。", "summary": "Inversion-DPO是一种新颖的扩散模型后训练对齐框架，旨在解决现有方法计算开销大和效率低的问题。该方法通过结合DDIM反演和直接偏好优化（DPO），巧妙地避免了对辅助奖励模型的依赖，从而显著提高了训练的精度和效率。在文本到图像和挑战性的组合图像生成任务中，Inversion-DPO均展现出优于现有方法的性能，能够生成高保真且结构连贯的图像。此外，研究团队还为此任务构建了一个大规模的组合图像数据集。该工作为扩散模型的高效高精度对齐提供了新思路，扩展了其在复杂生成任务中的应用潜力。", "keywords": "扩散模型, 后训练, 对齐, 直接偏好优化, DDIM反演", "comments": "Inversion-DPO的创新点在于将DDIM反演与DPO相结合，巧妙地规避了传统对齐方法中对计算密集型奖励模型的依赖，这显著提升了训练效率和精度。该方法为扩散模型的后训练提供了一个更实用且高性能的范式，尤其在复杂图像生成任务中展现出巨大潜力。"}}
{"id": "2507.13416", "title": "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement: application to data-driven constitutive modeling", "authors": ["Jiaxiang Yi", "Bernardo P. Ferreira", "Miguel A. Bessa"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      40 pages, 32 figures", "url": "http://arxiv.org/abs/2507.13416v1", "summary": "Data-driven learning is generalized to consider history-dependent\nmulti-fidelity data, while quantifying epistemic uncertainty and disentangling\nit from data noise (aleatoric uncertainty). This generalization is hierarchical\nand adapts to different learning scenarios: from training the simplest\nsingle-fidelity deterministic neural networks up to the proposed multi-fidelity\nvariance estimation Bayesian recurrent neural networks. The versatility and\ngenerality of the proposed methodology are demonstrated by applying it to\ndifferent data-driven constitutive modeling scenarios that include multiple\nfidelities with and without aleatoric uncertainty (noise). The method\naccurately predicts the response and quantifies model error while also\ndiscovering the noise distribution (when present). This opens opportunities for\nfuture real-world applications in diverse scientific and engineering domains;\nespecially, the most challenging cases involving design and analysis under\nuncertainty.", "comment": "40 pages, 32 figures", "pdf_url": "http://arxiv.org/pdf/2507.13416v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "从单精度到多精度历史依赖学习，结合不确定性量化与解耦：应用于数据驱动本构建模", "tldr": "该研究提出了一种通用的数据驱动学习方法，能够处理历史依赖的多精度数据，并量化认知不确定性，同时将其与数据噪声（随机不确定性）分离，适用于本构建模等多种场景。", "motivation": "现有数据驱动学习方法在处理历史依赖的多精度数据时，未能有效量化认知不确定性并将其与数据噪声分离。", "method": "该方法是分层的，并能适应不同的学习场景，从最简单的单精度确定性神经网络训练到所提出的多精度方差估计贝叶斯循环神经网络。", "result": "该方法能准确预测响应，量化模型误差，并在存在噪声时发现噪声分布。", "conclusion": "该方法为未来在不同科学和工程领域，特别是在不确定性下的设计和分析等最具挑战性的实际应用开辟了机会。", "translation": "数据驱动学习被推广到考虑历史依赖的多精度数据，同时量化认知不确定性并将其与数据噪声（随机不确定性）解耦。这种推广是分层的，并适应不同的学习场景：从训练最简单的单精度确定性神经网络到所提出的多精度方差估计贝叶斯循环神经网络。所提出方法的通用性和普适性通过将其应用于不同的数据驱动本构建模场景（包括有或无随机不确定性（噪声）的多精度数据）得到证明。该方法能准确预测响应并量化模型误差，同时还能发现噪声分布（如果存在）。这为未来在不同科学和工程领域的实际应用开辟了机会；特别是涉及不确定性下设计和分析的最具挑战性的情况。", "summary": "本论文提出了一种通用的数据驱动学习方法，用于处理历史依赖的多精度数据，并能同时量化认知不确定性并将其与随机不确定性分离。该方法采用分层结构，并引入了多精度方差估计贝叶斯循环神经网络。在数据驱动本构建模场景中的应用表明，该方法能够准确预测响应、量化模型误差，并在存在噪声时发现其分布，从而为不确定性下的工程应用提供了新的机遇。", "keywords": "多精度学习, 历史依赖, 不确定性量化, 贝叶斯循环神经网络, 本构建模", "comments": "该论文的创新点在于将数据驱动学习推广到历史依赖的多精度数据，并首次实现了认知不确定性和随机不确定性的解耦。通过引入多精度方差估计贝叶斯循环神经网络，提高了模型在复杂、不确定性高的数据驱动本构建模中的准确性和鲁棒性，具有重要的实际应用潜力。"}}
{"id": "2507.13405", "title": "COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark", "authors": ["Ishant Chintapatla", "Kazuma Choji", "Naaisha Agarwal", "Andrew Lin", "Hannah You", "Charles Duong", "Kevin Zhu", "Sean O'Brien", "Vasu Sharma"], "categories": ["cs.CV", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13405v1", "summary": "Recently, many benchmarks and datasets have been developed to evaluate\nVision-Language Models (VLMs) using visual question answering (VQA) pairs, and\nmodels have shown significant accuracy improvements. However, these benchmarks\nrarely test the model's ability to accurately complete visual entailment, for\ninstance, accepting or refuting a hypothesis based on the image. To address\nthis, we propose COREVQA (Crowd Observations and Reasoning Entailment), a\nbenchmark of 5608 image and synthetically generated true/false statement pairs,\nwith images derived from the CrowdHuman dataset, to provoke visual entailment\nreasoning on challenging crowded images. Our results show that even the\ntop-performing VLMs achieve accuracy below 80%, with other models performing\nsubstantially worse (39.98%-69.95%). This significant performance gap reveals\nkey limitations in VLMs' ability to reason over certain types of image-question\npairs in crowded scenes.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13405v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "COREVQA：一个人群观察与推理蕴涵视觉问答基准", "tldr": "提出COREVQA基准，用于评估视觉语言模型在拥挤图像上进行视觉蕴涵推理的能力，发现当前模型表现不佳。", "motivation": "现有视觉问答（VQA）基准很少测试模型准确完成视觉蕴涵（即根据图像接受或驳斥假设）的能力。", "method": "提出了COREVQA（人群观察与推理蕴涵）基准，包含5608对图像和合成的真/假陈述，图像来源于CrowdHuman数据集，旨在引发对挑战性拥挤图像的视觉蕴涵推理。", "result": "即使是表现最好的视觉语言模型（VLMs）准确率也低于80%，其他模型表现更差（39.98%-69.95%）。", "conclusion": "显著的性能差距揭示了视觉语言模型在拥挤场景中对某些类型的图像-问题对进行推理的关键局限性。", "translation": "最近，许多基准和数据集已被开发用于使用视觉问答（VQA）对评估视觉语言模型（VLMs），并且模型显示出显著的准确性提升。然而，这些基准很少测试模型准确完成视觉蕴涵的能力，例如，根据图像接受或驳斥一个假设。为了解决这个问题，我们提出了COREVQA（人群观察与推理蕴涵），一个包含5608对图像和合成的真/假陈述的基准，图像来源于CrowdHuman数据集，旨在激发对挑战性拥挤图像的视觉蕴涵推理。我们的结果显示，即使是表现最好的视觉语言模型准确率也低于80%，其他模型表现明显更差（39.98%-69.95%）。这种显著的性能差距揭示了视觉语言模型在拥挤场景中对某些类型的图像-问题对进行推理的关键局限性。", "summary": "本文提出了COREVQA，一个针对视觉语言模型（VLMs）的视觉蕴涵推理新基准。该基准包含5608对来自CrowdHuman数据集的拥挤图像和合成的真/假陈述。实验结果表明，即使是顶级VLMs在此基准上的准确率也低于80%，揭示了当前模型在处理拥挤场景中的视觉蕴涵推理方面的显著局限性。", "keywords": "视觉问答, 视觉蕴涵, 视觉语言模型, 拥挤场景, 基准", "comments": "这篇论文的创新点在于提出了一个专门用于测试视觉蕴涵推理能力的新基准COREVQA，特别关注了拥挤场景这一具有挑战性的领域。其重要性在于揭示了当前视觉语言模型在复杂视觉推理方面的局限性，为未来模型改进指明了方向。"}}
{"id": "2507.13637", "title": "Towards channel foundation models (CFMs): Motivations, methodologies and opportunities", "authors": ["Jun Jiang", "Yuan Gao", "Xinyi Wu", "Shugong Xu"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "Comments:      13 pages", "url": "http://arxiv.org/abs/2507.13637v1", "summary": "Artificial intelligence (AI) has emerged as a pivotal enabler for\nnext-generation wireless communication systems. However, conventional AI-based\nmodels encounter several limitations, such as heavy reliance on labeled data,\nlimited generalization capability, and task-specific design. To address these\nchallenges, this paper introduces, for the first time, the concept of channel\nfoundation models (CFMs)-a novel and unified framework designed to tackle a\nwide range of channel-related tasks through a pretrained, universal channel\nfeature extractor. By leveraging advanced AI architectures and self-supervised\nlearning techniques, CFMs are capable of effectively exploiting large-scale\nunlabeled data without the need for extensive manual annotation. We further\nanalyze the evolution of AI methodologies, from supervised learning and\nmulti-task learning to self-supervised learning, emphasizing the distinct\nadvantages of the latter in facilitating the development of CFMs. Additionally,\nwe provide a comprehensive review of existing studies on self-supervised\nlearning in this domain, categorizing them into generative, discriminative and\nthe combined paradigms. Given that the research on CFMs is still at an early\nstage, we identify several promising future research directions, focusing on\nmodel architecture innovation and the construction of high-quality, diverse\nchannel datasets.", "comment": "13 pages", "pdf_url": "http://arxiv.org/pdf/2507.13637v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "迈向信道基础模型（CFM）：动机、方法和机遇", "tldr": "论文首次提出信道基础模型（CFM）概念，旨在通过预训练的通用特征提取器和自监督学习解决现有AI在无线通信中泛化能力差、依赖标注数据等问题，并探讨了未来研究方向。", "motivation": "现有的AI模型在无线通信系统中存在对标注数据依赖大、泛化能力有限以及任务特定设计等局限性。", "method": "论文首次引入了信道基础模型（CFMs）的概念，这是一个新颖且统一的框架，通过预训练的通用信道特征提取器和自监督学习技术，有效利用大规模未标注数据来处理各种信道相关任务。文章还分析了AI方法从监督学习、多任务学习到自监督学习的演变，并回顾了该领域现有自监督学习研究，将其分为生成式、判别式和组合范式。", "result": "CFMs能够有效利用大规模未标注数据，无需大量手动标注，并能解决现有AI模型在无线通信中遇到的局限性，如泛化能力不足和对标注数据的过度依赖。", "conclusion": "论文首次提出了信道基础模型（CFM）的概念，并认为该研究仍处于早期阶段，指出了未来有前景的研究方向，包括模型架构创新和构建高质量、多样化的信道数据集。", "translation": "人工智能（AI）已成为下一代无线通信系统的关键推动者。然而，传统的基于AI的模型面临一些局限性，例如严重依赖标注数据、泛化能力有限以及任务特定设计。为了解决这些挑战，本文首次引入了信道基础模型（CFM）的概念——一个新颖且统一的框架，旨在通过预训练的通用信道特征提取器来处理广泛的信道相关任务。通过利用先进的AI架构和自监督学习技术，CFM能够有效利用大规模未标注数据，而无需大量手动标注。我们进一步分析了AI方法从监督学习、多任务学习到自监督学习的演变，强调后者在促进CFM发展方面的独特优势。此外，我们全面回顾了该领域现有的自监督学习研究，将其分为生成式、判别式和组合范式。鉴于CFM的研究仍处于早期阶段，我们指出了几个有前景的未来研究方向，重点关注模型架构创新和高质量、多样化信道数据集的构建。", "summary": "本文首次提出了信道基础模型（CFM）的概念，旨在解决当前AI在无线通信中面临的标注数据依赖、泛化能力差和任务特定设计等挑战。CFM是一个统一的框架，通过预训练的通用信道特征提取器和自监督学习，能够有效利用大规模未标注数据。论文还回顾了自监督学习在该领域的研究进展，并为CFM的未来研究指明了方向，包括模型架构和数据集构建。", "keywords": "信道基础模型, 自监督学习, 无线通信, 通用特征提取器, 人工智能", "comments": "这篇论文的创新点在于首次将“基础模型”的概念引入到无线通信的信道领域，提出了信道基础模型（CFM）这一新范式。其重要性在于，通过利用自监督学习和通用特征提取器，有望解决传统AI在无线通信中数据依赖和泛化能力不足的痛点，为下一代无线通信系统中的AI应用开辟了新路径。"}}
{"id": "2507.13666", "title": "KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs", "authors": ["Woo-Chan Kim", "Ji-Hoon Park", "Seong-Whan Lee"], "categories": ["cs.CL"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13666v1", "summary": "Large language models (LLMs) have demonstrated state-of-the-art performance\nacross a wide range of natural language processing tasks. However,\nhigh-performing models are typically accessible only via APIs, incurring\nsubstantial inference costs. Cascade methods address this by initially\nemploying a cheaper model and escalating to a stronger one only when necessary.\nNevertheless, existing cascade approaches struggle to select a reliable\nrepresentative response and assess the overall reliability of free-form\noutputs, as they rely on exact text matching. To overcome these limitations, we\npropose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient\nfree-form text generation. KiC identifies the most representative answer among\nmultiple outputs from a weaker model and evaluates the semantic alignment of\nother responses with it. Based on the degree of alignment, KiC determines\nwhether to accept the weaker model's output or escalate to a stronger model.\nExperiments on three free-form text generation benchmarks show that KiC\nachieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81\npercent on average, and even outperforms GPT-4 in a specific benchmark.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13666v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "KiC：关键词启发式级联，用于大型语言模型的高成本效益文本生成", "tldr": "KiC是一种新的级联方法，通过利用关键词语义对齐，在保持高性能的同时显著降低大型语言模型自由文本生成的成本。", "motivation": "大型语言模型（LLMs）性能卓越但通过API访问成本高昂。现有级联方法因依赖精确文本匹配，难以对自由形式输出选择可靠响应并评估整体可靠性。", "method": "提出关键词启发式级联（KiC）框架。KiC从弱模型多个输出中识别最具代表性的答案，并评估其他响应与其的语义对齐程度。根据对齐程度，决定是接受弱模型的输出还是升级到强模型。", "result": "KiC在三个自由形式文本生成基准测试中，达到了GPT-4 97.53%的准确率，同时平均降低了28.81%的API成本，甚至在一个特定基准测试中超越了GPT-4。", "conclusion": "KiC通过语义对齐的方法有效解决了现有级联方法在自由形式文本生成中的局限性，实现了在保持高准确率的同时显著降低LLM推理成本的目标。", "translation": "大型语言模型（LLMs）在广泛的自然语言处理任务中展现了最先进的性能。然而，高性能模型通常只能通过API访问，这会产生大量的推理成本。级联方法通过首先使用更便宜的模型，仅在必要时升级到更强大的模型来解决这个问题。然而，现有级联方法由于依赖精确文本匹配，难以选择可靠的代表性响应并评估自由形式输出的整体可靠性。为了克服这些限制，我们提出了关键词启发式级联（KiC），一个用于高成本效益自由形式文本生成的新颖框架。KiC从弱模型的多个输出中识别出最具代表性的答案，并评估其他响应与该答案的语义对齐。根据对齐程度，KiC决定是接受弱模型的输出还是升级到更强的模型。在三个自由形式文本生成基准测试中的实验表明，KiC在达到GPT-4 97.53%准确率的同时，平均降低了28.81%的API成本，甚至在一个特定基准测试中超越了GPT-4。", "summary": "本文提出了一种名为KiC（关键词启发式级联）的新型框架，旨在解决大型语言模型（LLMs）高昂的推理成本问题，尤其是在自由形式文本生成任务中现有级联方法的局限性。KiC通过识别弱模型输出中最具代表性的答案并评估其他响应的语义对齐程度来决定是否升级到更强的模型。实验结果表明，KiC在保持与GPT-4相近性能（97.53%准确率）的同时，显著降低了平均28.81%的API成本，并在某些情况下甚至表现优于GPT-4。", "keywords": "LLM, 成本效益, 文本生成, 级联, 关键词启发", "comments": "KiC的创新之处在于其不再依赖精确文本匹配，而是通过语义对齐来评估自由形式文本的可靠性，这显著提升了级联方法在复杂文本生成任务中的适用性。其在成本效益和性能之间的权衡表现出色，对于需要大规模部署LLM的应用具有重要意义。"}}
{"id": "2506.13196", "title": "KEPLA: A Knowledge-Enhanced Deep Learning Framework for Accurate Protein-Ligand Binding Affinity Prediction", "authors": ["Han Liu", "Keyan Ding", "Peilin Chen", "Yinwei Wei", "Liqiang Nie", "Dapeng Wu", "Shiqi Wang"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2506.13196v3", "summary": "Accurate prediction of protein-ligand binding affinity is critical for drug\ndiscovery. While recent deep learning approaches have demonstrated promising\nresults, they often rely solely on structural features of proteins and ligands,\noverlooking their valuable biochemical knowledge associated with binding\naffinity. To address this limitation, we propose KEPLA, a novel deep learning\nframework that explicitly integrates prior knowledge from Gene Ontology and\nligand properties to enhance prediction performance. KEPLA takes protein\nsequences and ligand molecular graphs as input and optimizes two complementary\nobjectives: (1) aligning global representations with knowledge graph relations\nto capture domain-specific biochemical insights, and (2) leveraging cross\nattention between local representations to construct fine-grained joint\nembeddings for prediction. Experiments on two benchmark datasets across both\nin-domain and cross-domain scenarios demonstrate that KEPLA consistently\noutperforms state-of-the-art baselines. Furthermore, interpretability analyses\nbased on knowledge graph relations and cross attention maps provide valuable\ninsights into the underlying predictive mechanisms.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2506.13196v3", "cate": "cs.LG", "date": "2025-06-16", "updated": "2025-07-18", "AI": {"title_translation": "KEPLA：一个知识增强的深度学习框架，用于准确预测蛋白质-配体结合亲和力", "tldr": "KEPLA将生化知识整合到深度学习中，以更准确地预测蛋白质-配体结合亲和力。", "motivation": "当前用于蛋白质-配体结合亲和力预测的深度学习方法通常仅依赖结构特征，忽视了宝贵的生化知识，从而限制了其性能。", "method": "KEPLA是一个新颖的深度学习框架，它以蛋白质序列和配体分子图为输入。它通过整合来自基因本体论（Gene Ontology）和配体特性的先验知识来增强预测性能，并优化两个互补目标：1）将全局表示与知识图谱关系对齐以捕获领域特定生化见解；2）利用局部表示之间的交叉注意力构建细粒度联合嵌入以进行预测。", "result": "KEPLA在两个基准数据集上，无论是域内还是跨域场景，都持续优于最先进的基线方法。此外，基于知识图谱关系和交叉注意力图的可解释性分析为潜在的预测机制提供了宝贵见解。", "conclusion": "KEPLA成功地将生化知识整合到深度学习框架中，实现了更准确且可解释的蛋白质-配体结合亲和力预测，这对于药物发现至关重要。", "translation": "准确预测蛋白质-配体结合亲和力对于药物发现至关重要。尽管最近的深度学习方法已显示出有前景的结果，但它们通常仅依赖于蛋白质和配体的结构特征，而忽略了与结合亲和力相关的宝贵生化知识。为了解决这一局限性，我们提出了KEPLA，一个新颖的深度学习框架，它明确地整合了来自基因本体论和配体特性的先验知识，以提高预测性能。KEPLA以蛋白质序列和配体分子图作为输入，并优化两个互补的目标：(1) 将全局表示与知识图谱关系对齐，以捕获领域特定的生化见解；(2) 利用局部表示之间的交叉注意力构建用于预测的细粒度联合嵌入。在两个基准数据集上进行的域内和跨域场景的实验表明，KEPLA持续优于最先进的基线方法。此外，基于知识图谱关系和交叉注意力图的可解释性分析为潜在的预测机制提供了宝贵的见解。", "summary": "这篇论文介绍了KEPLA，一个用于准确预测蛋白质-配体结合亲和力的新颖深度学习框架。与以往仅使用结构特征的方法不同，KEPLA通过整合来自基因本体论和配体特性的先验生化知识来增强预测。它以蛋白质序列和配体分子图作为输入，并优化全局知识图谱对齐和局部交叉注意力以构建细粒度嵌入。实验结果表明，KEPLA在基准数据集上持续优于现有最先进的模型，并且其可解释性分析提供了对预测机制的深入理解。", "keywords": "蛋白质-配体结合亲和力, 深度学习, 知识图谱, 基因本体论, 药物发现", "comments": "KEPLA的创新之处在于，它明确地将生化知识整合到深度学习中进行结合亲和力预测，解决了以往仅依赖结构方法的一个关键局限性。其对可解释性的关注也增加了显著价值，这对于理解和信任药物发现模型至关重要。"}}
{"id": "2507.13660", "title": "Managing level of detail through peripheral degradation: Effects on search performance with a head-mounted display", "authors": ["Benjamin Watson", "Neff Walker", "Larry F Hodges", "Aileen Worden"], "categories": ["cs.HC", "cs.GR"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13660v1", "summary": "Two user studies were performed to evaluate the effect of level-of-detail\n(LOD) degradation in the periphery of head-mounted displays on visual search\nperformance. In the first study, spatial detail was degraded by reducing\nresolution. In the second study, detail was degraded in the color domain by\nusing grayscale in the periphery. In each study, 10 subjects were given a\ncomplex search task that required users to indicate whether or not a target\nobject was present among distracters. Subjects used several different displays\nvarying in the amount of detail presented. Frame rate, object location, subject\ninput method, and order of display use were all controlled. The primary\ndependent measures were search time on correctly performed trials and the\npercentage of all trials correctly performed. Results indicated that peripheral\nLOD degradation can be used to reduce color or spatial visual complexity by\nalmost half in some search tasks with out significantly reducing performance.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13660v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "通过外围降级管理细节水平：对头戴式显示器搜索性能的影响", "tldr": "研究发现，在头戴式显示器中降低外围细节（空间分辨率或颜色）可以显著降低视觉复杂度，而不会显著降低搜索性能。", "motivation": "评估头戴式显示器外围细节水平（LOD）降级对视觉搜索性能的影响。", "method": "进行了两项用户研究。第一项研究通过降低分辨率来降级空间细节；第二项研究通过在外围使用灰度来降级颜色细节。每项研究有10名受试者，执行一项复杂的搜索任务，需要判断目标对象是否存在。实验控制了帧率、对象位置、输入方法和显示器使用顺序，主要衡量指标是正确试验的搜索时间和正确试验的百分比。", "result": "结果表明，外围LOD降级可以将颜色或空间视觉复杂度降低近一半，在某些搜索任务中不会显著降低性能。", "conclusion": "在头戴式显示器中，通过在外围区域降低细节（无论是空间分辨率还是颜色），可以在不显著影响用户搜索性能的情况下，有效降低视觉信息的复杂性。", "translation": "进行了两项用户研究，以评估头戴式显示器外围细节水平（LOD）降级对视觉搜索性能的影响。在第一项研究中，通过降低分辨率来降级空间细节。在第二项研究中，通过在外围使用灰度来降级颜色细节。在每项研究中，有10名受试者被分配了一项复杂的搜索任务，要求用户指示目标对象是否存在于干扰物中。受试者使用了几种不同的显示器，这些显示器在呈现的细节量上有所不同。帧率、对象位置、受试者输入方法和显示器使用顺序都得到了控制。主要的因变量是正确完成试验的搜索时间以及正确完成所有试验的百分比。结果表明，外围LOD降级可以将颜色或空间视觉复杂度降低近一半，在某些搜索任务中不会显著降低性能。", "summary": "本研究通过两项用户实验，探讨了头戴式显示器外围区域细节水平（LOD）降级对视觉搜索表现的影响。实验分别通过降低空间分辨率和使用灰度来模拟细节降级。结果显示，在外围视觉区域适度降低细节（如颜色或空间复杂度）可以有效减少视觉信息量，且在特定搜索任务中并不会显著损害用户的搜索效率和准确性。", "keywords": "头戴式显示器, 细节水平, 外围视觉, 视觉搜索, 性能降级", "comments": "这项研究具有创新性，因为它探索了一种在有限显示资源（如头戴式显示器）下优化信息呈现的方法，通过利用人眼对外围视觉细节敏感度较低的特点，在不牺牲核心任务性能的前提下降低了视觉负荷。这对于虚拟现实和增强现实应用中的性能优化和用户体验提升具有重要意义。"}}
{"id": "2507.14070", "title": "Error Correcting Codes for Segmented Burst-Deletion Channels", "authors": ["Yajuan Liu", "Tolga M. Duman"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14070v1", "summary": "We study segmented burst-deletion channels motivated by the observation that\nsynchronization errors commonly occur in a bursty manner in real-world\nsettings. In this channel model, transmitted sequences are implicitly divided\ninto non-overlapping segments, each of which may experience at most one burst\nof deletions. In this paper, we develop error correction codes for segmented\nburst-deletion channels over arbitrary alphabets under the assumption that each\nsegment may contain only one burst of t-deletions. The main idea is to encode\nthe input subsequence corresponding to each segment using existing one-burst\ndeletion codes, with additional constraints that enable the decoder to identify\nsegment boundaries during the decoding process from the received sequence. The\nresulting codes achieve redundancy that scales as O(log b), where b is the\nlength of each segment.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14070v1", "cate": "cs.IT", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "分段突发删除信道的纠错码", "tldr": "本文研究了分段突发删除信道下的纠错码，通过结合现有单突发删除码和边界识别约束，实现了O(log b)的冗余度。", "motivation": "由于观察到现实世界中同步错误常以突发方式出现，且通常以突发方式发生。", "method": "将传输序列隐式地划分为不重叠的分段，每个分段最多可能经历一次突发删除。通过使用现有的单突发删除码对每个分段对应的输入子序列进行编码，并附加额外的约束，使解码器能够在解码过程中从接收序列中识别分段边界。", "result": "所得到的码实现了O(log b)的冗余度，其中b是每个分段的长度。", "conclusion": "成功开发了针对分段突发删除信道的纠错码，其冗余度与分段长度呈对数关系。", "translation": "我们研究分段突发删除信道，其动机是观察到同步错误在现实世界中常以突发方式发生。在这种信道模型中，传输序列被隐式地划分为不重叠的分段，每个分段最多可能经历一次突发删除。在本文中，我们在假设每个分段只包含一次t-删除突发的情况下，为任意字母表上的分段突发删除信道开发了纠错码。主要思想是使用现有的单突发删除码对每个分段对应的输入子序列进行编码，并附加额外的约束，使解码器能够在解码过程中从接收序列中识别分段边界。所得到的码实现了O(log b)的冗余度，其中b是每个分段的长度。", "summary": "本文研究了分段突发删除信道，该信道模型受到现实世界中突发性同步错误的启发。作者提出了一种新的纠错码，适用于在任意字母表上且每个分段只包含一次删除突发的信道。其核心方法是结合使用现有单突发删除码和额外的边界识别约束，最终实现了O(log b)的冗余度，其中b为分段长度。", "keywords": "纠错码, 突发删除, 分段信道, 同步错误, 冗余度", "comments": "该论文的创新点在于将突发删除信道建模为分段形式，并提出了一种结合现有单突发删除码和边界识别约束的编码方案。这种方法有效地解决了分段边界识别问题，并在冗余度方面取得了对数级的良好性能，对于处理现实世界中的突发性同步错误具有重要意义。"}}
{"id": "2507.13941", "title": "Convergent transformations of visual representation in brains and models", "authors": ["Pablo Marcos-Manchón", "Lluís Fuentemilla"], "categories": ["q-bio.NC", "cs.AI", "cs.CV", "eess.IV", "I.2.10"], "primary_category": "Subjects:       Neurons and Cognition (q-bio.NC)", "pdf_link": null, "comments": "Comments:      for associate code, see this https URL", "url": "http://arxiv.org/abs/2507.13941v1", "summary": "A fundamental question in cognitive neuroscience is what shapes visual\nperception: the external world's structure or the brain's internal\narchitecture. Although some perceptual variability can be traced to individual\ndifferences, brain responses to naturalistic stimuli evoke similar activity\npatterns across individuals, suggesting a convergent representational\nprinciple. Here, we test if this stimulus-driven convergence follows a common\ntrajectory across people and deep neural networks (DNNs) during its\ntransformation from sensory to high-level internal representations. We\nintroduce a unified framework that traces representational flow by combining\ninter-subject similarity with alignment to model hierarchies. Applying this\nframework to three independent fMRI datasets of visual scene perception, we\nreveal a cortex-wide network, conserved across individuals, organized into two\npathways: a medial-ventral stream for scene structure and a lateral-dorsal\nstream tuned for social and biological content. This functional organization is\ncaptured by the hierarchies of vision DNNs but not language models, reinforcing\nthe specificity of the visual-to-semantic transformation. These findings show a\nconvergent computational solution for visual encoding in both human and\nartificial vision, driven by the structure of the external world.", "comment": "for associate code, see\n  https://github.com/memory-formation/convergent-transformations", "pdf_url": "http://arxiv.org/pdf/2507.13941v1", "cate": "q-bio.NC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "大脑和模型中视觉表征的趋同转换", "tldr": "本文发现人类大脑和深度神经网络在视觉编码上存在趋同的计算解决方案，由外部世界结构驱动，并揭示了大脑视觉处理的两个主要通路。", "motivation": "认知神经科学的一个基本问题是：视觉感知是由外部世界结构还是大脑内部结构塑造的？尽管一些感知变异性可以追溯到个体差异，但大脑对自然刺激的反应在个体间会引起相似的活动模式，这表明存在一个趋同的表征原则。本文旨在测试这种刺激驱动的趋同是否在从感觉表征到高级内部表征的转换过程中，在人脑和深度神经网络中遵循共同的轨迹。", "method": "引入了一个统一的框架，通过结合主体间相似性与模型层次对齐来追踪表征流。将此框架应用于三个独立的视觉场景感知fMRI数据集。", "result": "揭示了一个跨个体保守的全皮层网络，该网络组织成两条通路：一个用于场景结构的内侧-腹侧流，以及一个用于社交和生物内容的内侧-背侧流。这种功能组织被视觉DNN的层次结构捕获，但未被语言模型捕获。", "conclusion": "这些发现表明，在人类和人工视觉中，视觉编码存在趋同的计算解决方案，这由外部世界的结构驱动。", "translation": "认知神经科学的一个基本问题是：视觉感知是由外部世界的结构还是大脑的内部架构塑造的？尽管一些感知变异性可以追溯到个体差异，但大脑对自然刺激的反应在个体间会引起相似的活动模式，这表明存在一个趋同的表征原则。在这里，我们测试了这种刺激驱动的趋同是否在从感觉表征到高级内部表征的转换过程中，在人脑和深度神经网络（DNNs）中遵循共同的轨迹。我们引入了一个统一的框架，通过结合主体间相似性与模型层次对齐来追踪表征流。将此框架应用于三个独立的视觉场景感知fMRI数据集，我们揭示了一个跨个体保守的全皮层网络，该网络组织成两条通路：一个用于场景结构的内侧-腹侧流，以及一个用于社交和生物内容的内侧-背侧流。这种功能组织被视觉DNN的层次结构捕获，但未被语言模型捕获，这强化了视觉到语义转换的特异性。这些发现表明，在人类和人工视觉中，视觉编码存在趋同的计算解决方案，这由外部世界的结构驱动。", "summary": "本研究探讨了视觉感知中大脑和模型表征的趋同性，旨在确定刺激驱动的收敛是否在从感觉输入到高级内部表征的转换过程中，在人脑和深度神经网络之间遵循共同的轨迹。通过开发一个结合主体间相似性和模型层次对齐的统一框架，并将其应用于fMRI数据，研究发现人类大脑中存在一个跨个体保守的视觉处理网络，包含内侧-腹侧流（场景结构）和外侧-背侧流（社交/生物内容）两条通路。这一组织结构与视觉DNN的层次结构一致，而非语言模型，表明人类和人工视觉的视觉编码存在由外部世界结构驱动的趋同计算解决方案。", "keywords": "视觉表征, 大脑, 深度神经网络, 趋同, fMRI", "comments": "这篇论文的创新点在于提出了一个统一的框架来追踪大脑和模型中视觉表征的流，并首次揭示了人类大脑中视觉信息处理的两个特定通路，且这些通路的功能组织与视觉DNNs的层次结构高度吻合。这不仅加深了我们对人类视觉系统如何编码外部世界的理解，也为开发更有效、更接近生物学的AI视觉模型提供了重要的生物学启发和验证。"}}
{"id": "2507.14089", "title": "An Efficient Massively Parallel Constant-Factor Approximation Algorithm for the $k$-Means Problem", "authors": ["Vincent Cohen-Addad", "Fabian Kuhn", "Zahra Parsaeian"], "categories": ["cs.DS"], "primary_category": "Subjects:       Data Structures and Algorithms (cs.DS)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14089v1", "summary": "In this paper, we present an efficient massively parallel approximation\nalgorithm for the $k$-means problem. Specifically, we provide an MPC algorithm\nthat computes a constant-factor approximation to an arbitrary $k$-means\ninstance in $O(\\log\\log n \\cdot \\log\\log\\log n)$ rounds. The algorithm uses\n$O(n^\\sigma)$ bits of memory per machine, where $\\sigma > 0$ is a constant that\ncan be made arbitrarily small. The global memory usage is\n$O(n^{1+\\varepsilon})$ bits for an arbitrarily small constant $\\varepsilon >\n0$, and is thus only slightly superlinear. Recently, Czumaj, Gao, Jiang,\nKrauthgamer, and Vesel\\'{y} showed that a constant-factor bicriteria\napproximation can be computed in $O(1)$ rounds in the MPC model. However, our\nalgorithm is the first constant-factor approximation for the general $k$-means\nproblem that runs in $o(\\log n)$ rounds in the MPC model.\n  Our approach builds upon the foundational framework of Jain and Vazirani. The\ncore component of our algorithm is a constant-factor approximation for the\nrelated facility location problem. While such an approximation was already\nachieved in constant time in the work of Czumaj et al.\\ mentioned above, our\nversion additionally satisfies the so-called Lagrangian Multiplier Preserving\n(LMP) property. This property enables the transformation of a facility location\napproximation into a comparably good $k$-means approximation.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14089v1", "cate": "cs.DS", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "一种高效的大规模并行$k$-均值问题常数因子近似算法", "tldr": "本文提出了一种高效的大规模并行计算(MPC)算法，用于解决$k$-均值问题，能在$O(\\log\\log n \\cdot \\log\\log\\log n)$轮内计算出常数因子近似解，这是首个在MPC模型中运行时间低于$O(\\log n)$轮的通用$k$-均值常数因子近似算法。", "motivation": "该论文旨在开发一种在MPC模型中运行轮数显著低于$O(\\log n)$的通用$k$-均值问题常数因子近似算法，以改进现有方法的轮复杂度。", "method": "本文提出了一种MPC算法，它基于Jain和Vazirani的基础框架。该算法的核心是一个相关设施选址问题的常数因子近似算法，该算法额外满足拉格朗日乘子保持（LMP）性质。这种LMP性质使得将设施选址近似转换为同样好的$k$-均值近似成为可能。", "result": "该算法能在$O(\\log\\log n \\cdot \\log\\log\\log n)$轮内计算出任意$k$-均值实例的常数因子近似解。每台机器使用$O(n^\\sigma)$比特内存（$\\sigma > 0$为可任意小的常数），全局内存使用量为$O(n^{1+\\varepsilon})$比特（$\\varepsilon > 0$为任意小的常数），因此仅略微超线性。这是首个在MPC模型中运行轮数低于$O(\\log n)$的通用$k$-均值问题常数因子近似算法。", "conclusion": "本文提出了一种高效的大规模并行常数因子近似算法，用于解决$k$-均值问题，在MPC模型中实现了近乎最优的轮复杂度，显著提升了该领域的现有技术水平。", "translation": "在本文中，我们提出了一种高效的大规模并行近似算法，用于解决$k$-均值问题。具体来说，我们提供了一种MPC算法，它能在$O(\\log\\log n \\cdot \\log\\log\\log n)$轮内计算出任意$k$-均值实例的常数因子近似解。该算法每台机器使用$O(n^\\sigma)$比特内存，其中$\\sigma > 0$是一个可以任意小的常数。全局内存使用量为$O(n^{1+\\varepsilon})$比特，其中$\\varepsilon > 0$是一个任意小的常数，因此仅略微超线性。最近，Czumaj、Gao、Jiang、Krauthgamer和Veselý展示了在MPC模型中，可以在$O(1)$轮内计算出常数因子双准则近似。然而，我们的算法是第一个在MPC模型中运行轮数低于$O(\\log n)$的通用$k$-均值问题常数因子近似算法。\n我们的方法建立在Jain和Vazirani的基础框架之上。我们算法的核心组件是相关设施选址问题的常数因子近似。尽管Czumaj等人之前的工作已经实现了常数时间内的这种近似，但我们的版本额外满足了所谓的拉格朗日乘子保持（LMP）性质。该性质使得将设施选址近似转换为同样好的$k$-均值近似成为可能。", "summary": "本文提出了一种高效的大规模并行计算（MPC）算法，用于解决$k$-均值问题。该算法在$O(\\log\\log n \\cdot \\log\\log\\log n)$轮内实现了常数因子近似，这是首个在MPC模型中运行轮数低于$O(\\log n)$的通用$k$-均值常数因子近似算法。该方法基于Jain和Vazirani的框架，其核心是针对相关设施选址问题的常数因子近似，并额外满足拉格朗日乘子保持（LMP）性质，从而能够有效地转换为$k$-均值近似。", "keywords": "$k$-均值问题, 大规模并行计算, 近似算法, 设施选址, 常数因子近似", "comments": "该论文的创新之处在于在MPC模型中，首次为通用$k$-均值问题实现了超低轮数（低于$O(\\log n)$）的常数因子近似，这在以往是一个挑战。在设施选址子问题中引入并利用拉格朗日乘子保持（LMP）性质是实现这一突破的关键技术贡献，显著提升了并行$k$-均值算法的最新水平。"}}
{"id": "2507.06411", "title": "Hierarchical Multi-Stage Transformer Architecture for Context-Aware Temporal Action Localization", "authors": ["Hayat Ullah", "Arslan Munir", "Oliver Nina"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      17 pages, 6 figures,", "url": "http://arxiv.org/abs/2507.06411v2", "summary": "Inspired by the recent success of transformers and multi-stage architectures\nin video recognition and object detection domains. We thoroughly explore the\nrich spatio-temporal properties of transformers within a multi-stage\narchitecture paradigm for the temporal action localization (TAL) task. This\nexploration led to the development of a hierarchical multi-stage transformer\narchitecture called PCL-Former, where each subtask is handled by a dedicated\ntransformer module with a specialized loss function. Specifically, the\nProposal-Former identifies candidate segments in an untrimmed video that may\ncontain actions, the Classification-Former classifies the action categories\nwithin those segments, and the Localization-Former precisely predicts the\ntemporal boundaries (i.e., start and end) of the action instances. To evaluate\nthe performance of our method, we have conducted extensive experiments on three\nchallenging benchmark datasets: THUMOS-14, ActivityNet-1.3, and HACS Segments.\nWe also conducted detailed ablation experiments to assess the impact of each\nindividual module of our PCL-Former. The obtained quantitative results validate\nthe effectiveness of the proposed PCL-Former, outperforming state-of-the-art\nTAL approaches by 2.8%, 1.2%, and 4.8% on THUMOS14, ActivityNet-1.3, and HACS\ndatasets, respectively.", "comment": "17 pages, 6 figures,", "pdf_url": "http://arxiv.org/pdf/2507.06411v2", "cate": "cs.CV", "date": "2025-07-08", "updated": "2025-07-18", "AI": {"title_translation": "用于上下文感知时间动作定位的分层多阶段Transformer架构", "tldr": "本文提出了一种名为 PCL-Former 的分层多阶段 Transformer 架构，用于时间动作定位 (TAL) 任务，并在多个基准数据集上超越了现有最佳方法。", "motivation": "受 Transformer 和多阶段架构在视频识别和目标检测领域成功的启发，本文旨在探索 Transformer 在多阶段架构范式下处理时间动作定位 (TAL) 任务的丰富时空特性。", "method": "本文开发了一种名为 PCL-Former 的分层多阶段 Transformer 架构。该架构包含三个专用模块：Proposal-Former 用于识别候选动作片段；Classification-Former 用于分类动作类别；Localization-Former 用于精确预测动作实例的时间边界。每个模块都配备了专门的损失函数。", "result": "PCL-Former 在 THUMOS-14、ActivityNet-1.3 和 HACS Segments 三个挑战性基准数据集上进行了广泛实验。结果显示，PCL-Former 在 THUMOS14、ActivityNet-1.3 和 HACS 数据集上分别超越了现有最佳 TAL 方法 2.8%、1.2% 和 4.8%。", "conclusion": "所提出的 PCL-Former 架构在时间动作定位任务中表现出有效性，并在多个基准数据集上取得了优于现有最佳方法的定量结果。", "translation": "受近期 Transformer 和多阶段架构在视频识别和目标检测领域成功的启发。我们彻底探索了 Transformer 在多阶段架构范式下处理时间动作定位 (TAL) 任务的丰富时空特性。这项探索促使我们开发了一种名为 PCL-Former 的分层多阶段 Transformer 架构，其中每个子任务都由一个专用的 Transformer 模块和专门的损失函数处理。具体来说，Proposal-Former 识别未剪辑视频中可能包含动作的候选片段，Classification-Former 对这些片段中的动作类别进行分类，Localization-Former 精确预测动作实例的时间边界（即开始和结束）。为了评估我们方法的性能，我们在三个具有挑战性的基准数据集上进行了广泛实验：THUMOS-14、ActivityNet-1.3 和 HACS Segments。我们还进行了详细的消融实验，以评估 PCL-Former 各个模块的影响。获得的定量结果验证了所提出的 PCL-Former 的有效性，在 THUMOS14、ActivityNet-1.3 和 HACS 数据集上分别超越了现有最佳 TAL 方法 2.8%、1.2% 和 4.8%。", "summary": "本文提出了一种名为 PCL-Former 的分层多阶段 Transformer 架构，用于上下文感知时间动作定位 (TAL)。该架构包含 Proposal-Former、Classification-Former 和 Localization-Former 三个专用 Transformer 模块，分别负责候选片段识别、动作分类和边界预测。在 THUMOS-14、ActivityNet-1.3 和 HACS Segments 数据集上的实验结果表明，PCL-Former 显著优于现有的 TAL 方法。", "keywords": "时间动作定位, Transformer, 多阶段架构, PCL-Former, 视频分析", "comments": "该论文的创新点在于将分层多阶段架构与 Transformer 模型相结合，并针对时间动作定位的子任务设计了专用的 Transformer 模块和损失函数，体现了模块化和专业化的思想。其在多个基准数据集上超越现有最佳性能，证明了该方法的有效性和重要性。"}}
{"id": "2507.14031", "title": "QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography", "authors": ["Hao Fang", "Sihao Teng", "Hao Yu", "Siyi Yuan", "Huaiwu He", "Zhe Liu", "Yunjie Yang"], "categories": ["cs.CV", "cs.ET", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      10 pages, 12 figures", "url": "http://arxiv.org/abs/2507.14031v1", "summary": "Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside\nimaging modality with high temporal resolution, making it suitable for bedside\nmonitoring. However, its inherently ill-posed inverse problem poses significant\nchallenges for accurate image reconstruction. Deep learning (DL)-based\napproaches have shown promise but often rely on complex network architectures\nwith a large number of parameters, limiting efficiency and scalability. Here,\nwe propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework\nfor EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network\n(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive\nlatent representations that serve as implicit nonlinear priors, followed by a\nsingle linear layer for conductivity reconstruction. This design drastically\nreduces model complexity and parameter number. Uniquely, QuantEIT operates in\nan unsupervised, training-data-free manner and represents the first integration\nof quantum circuits into EIT image reconstruction. Extensive experiments on\nsimulated and real-world 2D and 3D EIT lung imaging data demonstrate that\nQuantEIT outperforms conventional methods, achieving comparable or superior\nreconstruction accuracy using only 0.2% of the parameters, with enhanced\nrobustness to noise.", "comment": "10 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2507.14031v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "QuantEIT：用于胸部电阻抗断层扫描的超轻量级量子辅助推理", "tldr": "QuantEIT是一种超轻量级、无监督的量子辅助推理框架，用于EIT图像重建，它通过结合并行量子电路和线性层，显著减少了模型复杂性，并在模拟和真实数据上实现了卓越的重建精度和噪声鲁棒性，参数量仅为传统方法的0.2%。", "motivation": "电阻抗断层扫描（EIT）的固有病态逆问题导致图像重建面临挑战。尽管深度学习方法有前景，但它们通常依赖于参数量大的复杂网络架构，限制了效率和可扩展性。", "method": "本文提出了QuantEIT，一个用于EIT图像重建的超轻量级量子辅助推理框架。QuantEIT利用量子辅助网络（QA-Net），结合并行的2量子位量子电路生成富有表现力的潜在表示作为隐式非线性先验，然后通过一个单一线性层进行电导率重建。该设计显著降低了模型复杂度和参数量，并且以无监督、无需训练数据的方式运行。这是量子电路首次集成到EIT图像重建中。", "result": "QuantEIT在模拟和真实世界的2D和3D EIT肺部成像数据上的广泛实验表明，它优于传统方法，仅使用0.2%的参数即可实现相当或更优的重建精度，并增强了对噪声的鲁棒性。", "conclusion": "QuantEIT通过引入量子辅助网络，在EIT图像重建中实现了超轻量级、高效且鲁棒的性能，显著减少了模型复杂性，并在无监督的设置下取得了优异结果。", "translation": "电阻抗断层扫描（EIT）是一种非侵入性、低成本的床旁成像模式，具有高时间分辨率，适用于床旁监测。然而，其固有的病态逆问题给精确图像重建带来了重大挑战。基于深度学习（DL）的方法已显示出前景，但通常依赖于参数量大的复杂网络架构，限制了效率和可扩展性。在此，我们提出了一种用于EIT图像重建的超轻量级量子辅助推理（QuantEIT）框架。QuantEIT利用量子辅助网络（QA-Net），结合并行的2量子位量子电路生成富有表现力的潜在表示，作为隐式非线性先验，然后通过一个单一线性层进行电导率重建。这种设计大大降低了模型复杂度和参数数量。独特的是，QuantEIT以无监督、无需训练数据的方式运行，代表了量子电路首次集成到EIT图像重建中。在模拟和真实世界的2D和3D EIT肺部成像数据上的广泛实验表明，QuantEIT优于传统方法，仅使用0.2%的参数即可实现相当或更优的重建精度，并增强了对噪声的鲁棒性。", "summary": "QuantEIT是一种创新的超轻量级量子辅助推理框架，专为解决电阻抗断层扫描（EIT）图像重建中的病态逆问题而设计。该框架引入了量子辅助网络（QA-Net），通过并行2量子位量子电路生成隐式非线性先验，并结合一个简单的线性层进行电导率重建。QuantEIT显著减少了模型复杂度和参数量，并且能在无监督、无需训练数据的情况下运行。实验证明，QuantEIT在重建精度和噪声鲁棒性方面优于传统方法，且仅需极少的参数。", "keywords": "电阻抗断层扫描, 量子辅助推理, 超轻量级, 图像重建, 无监督学习", "comments": "这项工作在EIT图像重建领域具有重要创新性，首次将量子电路集成到该任务中，并实现了超轻量级和无监督的推理。其核心创新在于利用量子辅助网络生成有效的潜在表示，从而大幅降低模型复杂性和对训练数据的依赖。这种方法为医疗成像中的资源受限环境提供了高效且高精度的解决方案，具有很高的实际应用价值。"}}
{"id": "2507.10748", "title": "LASANA: Large-Scale Surrogate Modeling for Analog Neuromorphic Architecture Exploration", "authors": ["Jason Ho", "James A. Boyle", "Linshen Liu", "Andreas Gerstlauer"], "categories": ["cs.AR"], "primary_category": "Subjects:       Hardware Architecture (cs.AR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.10748v2", "summary": "Neuromorphic systems using in-memory or event-driven computing are motivated\nby the need for more energy-efficient processing of artificial intelligence\nworkloads. Emerging neuromorphic architectures aim to combine traditional\ndigital designs with the computational efficiency of analog computing and novel\ndevice technologies. A crucial problem in the rapid exploration and co-design\nof such architectures is the lack of tools for fast and accurate modeling and\nsimulation. Typical mixed-signal design tools integrate a digital simulator\nwith an analog solver like SPICE, which is prohibitively slow for large\nsystems. By contrast, behavioral modeling of analog components is faster, but\nexisting approaches are fixed to specific architectures with limited energy and\nperformance modeling. In this paper, we propose LASANA, a novel approach that\nleverages machine learning to derive data-driven surrogate models of analog\nsub-blocks in a digital backend architecture. LASANA uses SPICE-level\nsimulations of a circuit to train ML models that predict circuit energy,\nperformance, and behavior at analog/digital interfaces. Such models can provide\nenergy and performance annotation on top of existing behavioral models or\nfunction as replacements to analog simulation. We apply LASANA to an analog\ncrossbar array and a spiking neuron circuit. Running MNIST and spiking MNIST,\nLASANA surrogates demonstrate up to three orders of magnitude speedup over\nSPICE, with energy, latency, and behavioral error less than 7%, 8%, and 2%,\nrespectively.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.10748v2", "cate": "cs.AR", "date": "2025-07-14", "updated": "2025-07-18", "AI": {"title_translation": "LASANA：大规模替代模型用于模拟神经形态架构探索", "tldr": "LASANA是一种基于机器学习的新方法，通过训练替代模型来加速大规模神经形态系统中的模拟模拟，实现显著的加速和高精度。", "motivation": "为满足人工智能工作负载对更高能效处理的需求，新兴的神经形态架构将数字设计与模拟计算相结合。然而，快速探索和协同设计这些架构面临缺乏快速准确建模和仿真工具的挑战。传统的混合信号设计工具（如SPICE）对于大型系统来说速度过慢，而现有行为建模方法则局限于特定架构，且能量和性能建模能力有限。", "method": "本文提出了LASANA，一种利用机器学习为数字后端架构中的模拟子块构建数据驱动替代模型的新颖方法。LASANA利用SPICE级电路仿真来训练机器学习模型，以预测电路的能量、性能以及模拟/数字接口的行为。这些模型可以为现有行为模型提供能量和性能注释，或直接替代模拟仿真。", "result": "LASANA应用于模拟交叉阵列和脉冲神经元电路，在运行MNIST和脉冲MNIST数据集时，其替代模型相对于SPICE实现了高达三个数量级的加速，同时能量、延迟和行为误差分别小于7%、8%和2%。", "conclusion": "LASANA通过提供快速、准确的替代模型，有效解决了大规模神经形态架构探索中模拟仿真速度过慢的问题，为神经形态系统的协同设计提供了高效的工具。", "translation": "神经形态系统采用内存计算或事件驱动计算，其动机是需要更节能地处理人工智能工作负载。新兴的神经形态架构旨在将传统数字设计与模拟计算的计算效率和新型器件技术相结合。在快速探索和协同设计此类架构时，一个关键问题是缺乏快速准确的建模和仿真工具。典型的混合信号设计工具将数字仿真器与SPICE等模拟求解器集成，这对于大型系统来说速度过慢。相比之下，模拟组件的行为建模速度更快，但现有方法固定于特定架构，且能量和性能建模能力有限。在本文中，我们提出了LASANA，一种利用机器学习来推导数字后端架构中模拟子块数据驱动替代模型的新方法。LASANA使用电路的SPICE级仿真来训练机器学习模型，以预测电路能量、性能以及模拟/数字接口的行为。此类模型可以在现有行为模型之上提供能量和性能注释，或作为模拟仿真的替代品。我们将LASANA应用于模拟交叉阵列和脉冲神经元电路。在运行MNIST和脉冲MNIST时，LASANA替代模型相对于SPICE表现出高达三个数量级的加速，能量、延迟和行为误差分别小于7%、8%和2%。", "summary": "LASANA提出了一种基于机器学习的数据驱动替代建模方法，旨在解决大规模神经形态架构探索中模拟仿真速度慢的问题。该方法通过SPICE仿真训练ML模型，以快速准确预测模拟子块的能量、性能和接口行为。实验结果表明，LASANA在模拟交叉阵列和脉冲神经元电路上的仿真速度比SPICE快三个数量级，同时保持了高精度，有效提升了神经形态系统的设计效率。", "keywords": "神经形态计算, 替代模型, 机器学习, 模拟电路, 仿真加速", "comments": "LASANA的创新之处在于将机器学习应用于模拟电路的替代建模，显著提升了神经形态架构仿真的速度，同时保持了高精度。这对于加速复杂神经形态系统的设计和探索具有重要意义，克服了传统SPICE仿真在处理大规模系统时的效率瓶颈。其在速度和精度上的平衡表现，使其成为未来神经形态硬件协同设计中的一个强大工具。"}}
{"id": "2507.12182", "title": "Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices", "authors": ["Ievgenii Afanasiev", "Leonid Berlyand", "Mariia Kiyashko"], "categories": ["math-ph", "cs.LG", "math.MP", "math.PR", "60B20, 15B52"], "primary_category": "Subjects:       Mathematical Physics (math-ph)", "pdf_link": null, "comments": "Comments:      14 pages, 3 figures", "url": "http://arxiv.org/abs/2507.12182v1", "summary": "The paper is concerned with deformed Wigner random matrices. These matrices\nare closely connected with Deep Neural Networks (DNNs): weight matrices of\ntrained DNNs could be represented in the form $R + S$, where $R$ is random and\n$S$ is highly correlated. The spectrum of such matrices plays a key role in\nrigorous underpinning of the novel pruning technique based on Random Matrix\nTheory. Mathematics has been done only for finite-rank matrix $S$. However, in\npractice rank may grow. In this paper we develop asymptotic analysis for the\ncase of growing rank.", "comment": "14 pages, 3 figures", "pdf_url": "http://arxiv.org/pdf/2507.12182v1", "cate": "math-ph", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "大型随机矩阵大秩扰动特征值的渐近行为", "tldr": "本文研究了变形Wigner随机矩阵，特别关注其在深度神经网络中的应用，并发展了针对扰动矩阵秩不断增长情况下的特征值渐近分析方法。", "motivation": "论文研究变形Wigner随机矩阵，这类矩阵与深度神经网络（DNNs）的权重矩阵密切相关。已有的数学研究仅限于有限秩矩阵S的情况，但实际中秩可能会增长，因此需要发展针对秩增长情况下的渐近分析。", "method": "本文针对扰动矩阵的秩不断增长的情况，发展了渐近分析方法。", "result": "本文发展了针对秩不断增长情况下的渐近分析。", "conclusion": "本文为秩不断增长情况下的变形Wigner随机矩阵的特征值渐近行为提供了分析方法，这对于理解深度神经网络的谱特性具有重要意义。", "translation": "本文关注变形Wigner随机矩阵。这些矩阵与深度神经网络（DNNs）密切相关：训练过的DNN的权重矩阵可以表示为R + S的形式，其中R是随机的，S是高度相关的。这类矩阵的谱在基于随机矩阵理论的新型剪枝技术的严格支撑中起着关键作用。数学研究此前仅限于有限秩矩阵S。然而，在实践中，秩可能会增长。在本文中，我们针对秩增长的情况发展了渐近分析。", "summary": "本文研究变形Wigner随机矩阵的特征值渐近行为，特别是在扰动矩阵S的秩不断增长的情况下。鉴于这类矩阵与深度神经网络权重矩阵的关联及其在基于随机矩阵理论的剪枝技术中的重要性，本文填补了现有研究仅限于有限秩S的空白，为理解其谱特性提供了新的数学工具。", "keywords": "Wigner随机矩阵, 深度神经网络, 特征值, 渐近分析, 秩扰动", "comments": "本文的创新之处在于将随机矩阵理论的渐近分析扩展到秩不断增长的扰动矩阵，这对于连接理论数学与深度神经网络的实际应用具有重要意义。它为理解DNN权重矩阵的谱特性提供了更广阔的理论框架，特别是在剪枝技术方面。"}}
{"id": "2507.13917", "title": "Neural-GASh: A CGA-based neural radiance prediction pipeline for real-time shading", "authors": ["Efstratios Geronikolakis", "Manos Kamarianakis", "Antonis Protopsaltis", "George Papagiannakis"], "categories": ["cs.GR"], "primary_category": "Subjects:       Graphics (cs.GR)", "pdf_link": null, "comments": "Comments:      11 pages, 10 figures", "url": "http://arxiv.org/abs/2507.13917v1", "summary": "This paper presents Neural-GASh, a novel real-time shading pipeline for 3D\nmeshes, that leverages a neural radiance field architecture to perform\nimage-based rendering (IBR) using Conformal Geometric Algebra (CGA)-encoded\nvertex information as input. Unlike traditional Precomputed Radiance Transfer\n(PRT) methods, that require expensive offline precomputations, our learned\nmodel directly consumes CGA-based representations of vertex positions and\nnormals, enabling dynamic scene shading without precomputation. Integrated\nseamlessly into the Unity engine, Neural-GASh facilitates accurate shading of\nanimated and deformed 3D meshes - capabilities essential for dynamic,\ninteractive environments. The shading of the scene is implemented within Unity,\nwhere rotation of scene lights in terms of Spherical Harmonics is also\nperformed optimally using CGA. This neural field approach is designed to\ndeliver fast and efficient light transport simulation across diverse platforms,\nincluding mobile and VR, while preserving high rendering quality. Additionally,\nwe evaluate our method on scenes generated via 3D Gaussian splats, further\ndemonstrating the flexibility and robustness of Neural-GASh in diverse\nscenarios. Performance is evaluated in comparison to conventional PRT,\ndemonstrating competitive rendering speeds even with complex geometries.", "comment": "11 pages, 10 figures", "pdf_url": "http://arxiv.org/pdf/2507.13917v1", "cate": "cs.GR", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "Neural-GASh：一种基于CGA的实时着色神经辐射预测管线", "tldr": "Neural-GASh是一种新的实时着色管线，它利用神经辐射场和共形几何代数（CGA）来对3D网格进行图像渲染，无需预计算，并可在Unity中实现动态场景着色。", "motivation": "传统的预计算辐射传输（PRT）方法需要昂贵的离线预计算，限制了其在动态交互环境中的应用。本研究旨在开发一种无需预计算、能实时处理动态和变形3D网格的着色方法。", "method": "本文提出了Neural-GASh，一种基于神经辐射场架构的实时着色管线，用于3D网格的图像渲染。它以共形几何代数（CGA）编码的顶点信息作为输入，直接处理CGA表示的顶点位置和法线，无需预计算。该方法无缝集成到Unity引擎中，并利用CGA优化场景光照（球谐函数旋转）。它还通过3D高斯飞溅生成的场景进行评估。", "result": "Neural-GASh实现了对动画和变形3D网格的准确着色，支持动态、交互式环境。它在与传统PRT方法的比较中展现出有竞争力的渲染速度，即使是复杂几何体也能保持高渲染质量，并且可以在包括移动和VR在内的多种平台上快速高效地进行光传输模拟。", "conclusion": "Neural-GASh通过结合神经辐射场和CGA，提供了一种高效、实时且无需预计算的3D网格着色解决方案，克服了传统方法的局限性，并适用于动态交互式环境和多平台部署。", "translation": "本文提出了Neural-GASh，一种新颖的用于3D网格的实时着色管线，它利用神经辐射场架构，以共形几何代数（CGA）编码的顶点信息作为输入，执行基于图像的渲染（IBR）。与需要昂贵离线预计算的传统预计算辐射传输（PRT）方法不同，我们的学习模型直接消耗基于CGA的顶点位置和法线表示，从而实现无需预计算的动态场景着色。Neural-GASh无缝集成到Unity引擎中，有助于对动画和变形的3D网格进行精确着色——这些能力对于动态、交互式环境至关重要。场景的着色在Unity中实现，其中场景光源的球谐函数旋转也使用CGA进行优化。这种神经场方法旨在在包括移动和VR在内的各种平台上提供快速高效的光传输模拟，同时保持高渲染质量。此外，我们还在通过3D高斯飞溅生成的场景上评估了我们的方法，进一步展示了Neural-GASh在不同场景下的灵活性和鲁棒性。性能与传统PRT进行了比较评估，即使在复杂几何体下也显示出具有竞争力的渲染速度。", "summary": "Neural-GASh是一种新颖的实时3D网格着色管线，它结合了神经辐射场和共形几何代数（CGA）。与传统PRT不同，该方法直接使用CGA编码的顶点信息进行图像渲染，无需昂贵的离线预计算，从而实现动态场景着色。Neural-GASh无缝集成到Unity中，能对动画和变形网格进行精确着色，并通过CGA优化光照。它在多平台（包括移动和VR）上提供快速高效的光传输模拟，并已在3D高斯飞溅场景上验证，性能与PRT相当。", "keywords": "实时着色, 神经辐射场, 共形几何代数, 图像渲染, Unity", "comments": "这项研究的创新之处在于将神经辐射场与共形几何代数（CGA）相结合，以实现实时、无需预计算的3D网格着色。这显著克服了传统PRT方法的计算瓶颈，使其适用于动态交互式环境。与Unity引擎的集成以及对多平台（包括移动和VR）的支持，凸显了其实用性和广泛应用潜力。其在复杂几何体和动态场景下的鲁棒性也值得称赞。"}}
{"id": "1910.09297", "title": "Two efficient block preconditioners for the mass-conserved Ohta-Kawasaki equation", "authors": ["Juan Zhang", "Shifeng Li", "Kai Jiang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      28 pages, 9 figures", "url": "http://arxiv.org/abs/1910.09297v3", "summary": "In this paper, we propose two efficient block preconditioners to solve the\nmass-conserved Ohta-Kawasaki equation with finite element discretization. We\nalso study the spectral distribution of these two preconditioners,\n\\textit{i.e.,} Schur complement preconditioner and the modified Hermitian and\nskew-Hermitian splitting (MHSS in short) preconditioner. Besides, Newton method\nand Picard method are used to address the implicitly nonlinear term. We\nrigorously analyze the convergence of Newton method. Finally, we offer\nnumerical examples to support the theoretical analysis and indicate the\nefficiency of the proposed preconditioners for the mass-conserved Ohta-Kawasaki\nequation.", "comment": "28 pages, 9 figures", "pdf_url": "http://arxiv.org/pdf/1910.09297v3", "cate": "math.NA", "date": "2019-10-21", "updated": "2025-07-18", "AI": {"title_translation": "质量守恒Ohta-Kawasaki方程的两种高效块预条件子", "tldr": "本文提出了两种高效块预条件子（Schur补预条件子和MHSS预条件子）来求解质量守恒的Ohta-Kawasaki方程，并对其谱分布和牛顿法收敛性进行了分析，数值例子验证了其效率。", "motivation": "为了高效求解经过有限元离散的质量守恒Ohta-Kawasaki方程。", "method": "提出了两种高效块预条件子：Schur补预条件子和改进的Hermitian和斜Hermitian分裂（MHSS）预条件子。使用有限元离散化，并通过牛顿法和Picard法处理隐式非线性项。对牛顿法的收敛性进行了严格分析。", "result": "研究了两种预条件子的谱分布。严格分析了牛顿法的收敛性。数值例子支持了理论分析，并表明了所提出的预条件子对于质量守恒Ohta-Kawasaki方程的效率。", "conclusion": "本文提出的两种块预条件子能够高效求解质量守恒Ohta-Kawasaki方程。", "translation": "本文提出了两种高效的块预条件子，用于求解经过有限元离散化的质量守恒Ohta-Kawasaki方程。我们还研究了这两种预条件子，即Schur补预条件子和改进的Hermitian和斜Hermitian分裂（简称MHSS）预条件子的谱分布。此外，使用牛顿法和Picard法来处理隐式非线性项。我们严格分析了牛顿法的收敛性。最后，我们提供了数值例子来支持理论分析，并表明所提出的预条件子对于质量守恒Ohta-Kawasaki方程的效率。", "summary": "本文针对有限元离散的质量守恒Ohta-Kawasaki方程，提出了两种高效的块预条件子：Schur补预条件子和MHSS预条件子。研究了这些预条件子的谱分布，并利用牛顿法和Picard法处理非线性项，同时严格分析了牛顿法的收敛性。数值结果验证了所提出预条件子的有效性。", "keywords": "块预条件子, Ohta-Kawasaki方程, 有限元, Schur补, MHSS", "comments": "本文的创新点在于提出了两种新的块预条件子来高效求解Ohta-Kawasaki方程，并进行了严格的理论分析和数值验证。这对于该方程的数值模拟具有重要意义。"}}
{"id": "2507.13359", "title": "Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives", "authors": ["Yang Zhou", "Junjie Li", "CongYang Ou", "Dawei Yan", "Haokui Zhang", "Xizhe Xue"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      27 pages, 5 figures", "url": "http://arxiv.org/abs/2507.13359v1", "summary": "Due to its extensive applications, aerial image object detection has long\nbeen a hot topic in computer vision. In recent years, advancements in Unmanned\nAerial Vehicles (UAV) technology have further propelled this field to new\nheights, giving rise to a broader range of application requirements. However,\ntraditional UAV aerial object detection methods primarily focus on detecting\npredefined categories, which significantly limits their applicability. The\nadvent of cross-modal text-image alignment (e.g., CLIP) has overcome this\nlimitation, enabling open-vocabulary object detection (OVOD), which can\nidentify previously unseen objects through natural language descriptions. This\nbreakthrough significantly enhances the intelligence and autonomy of UAVs in\naerial scene understanding. This paper presents a comprehensive survey of OVOD\nin the context of UAV aerial scenes. We begin by aligning the core principles\nof OVOD with the unique characteristics of UAV vision, setting the stage for a\nspecialized discussion. Building on this foundation, we construct a systematic\ntaxonomy that categorizes existing OVOD methods for aerial imagery and provides\na comprehensive overview of the relevant datasets. This structured review\nenables us to critically dissect the key challenges and open problems at the\nintersection of these fields. Finally, based on this analysis, we outline\npromising future research directions and application prospects. This survey\naims to provide a clear road map and a valuable reference for both newcomers\nand seasoned researchers, fostering innovation in this rapidly evolving domain.\nWe keep tracing related works at\nhttps://github.com/zhouyang2002/OVOD-in-UVA-imagery", "comment": "27 pages, 5 figures", "pdf_url": "http://arxiv.org/pdf/2507.13359v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04", "AI": {"title_translation": "无人机图像中的开放词汇目标检测：综述与未来展望", "tldr": "该论文全面综述了无人机空中场景中的开放词汇目标检测（OVOD），构建了分类体系，并提出了未来研究方向。", "motivation": "传统的无人机空中目标检测方法局限于检测预定义类别，极大地限制了其适用性。跨模态文本-图像对齐技术的出现（如CLIP）克服了这一限制，使开放词汇目标检测（OVOD）成为可能，能够识别以前未见过的物体，从而显著增强了无人机在空中场景理解中的智能性和自主性。", "method": "本文对无人机空中场景中的开放词汇目标检测（OVOD）进行了全面调查。首先，将OVOD的核心原理与无人机视觉的独特特性相结合。在此基础上，构建了一个系统的分类体系，对现有空中图像OVOD方法进行分类，并提供了相关数据集的全面概述。通过结构化综述，批判性地剖析了这些领域交叉的关键挑战和开放问题。", "result": "本文提供了一个系统的分类体系，涵盖了现有空中图像OVOD方法和相关数据集。它批判性地分析了开放词汇目标检测在无人机图像中的关键挑战和开放问题。", "conclusion": "基于分析，本文概述了有前景的未来研究方向和应用前景。该综述旨在为新手和资深研究人员提供清晰的路线图和有价值的参考，促进该快速发展领域的创新。", "translation": "由于其广泛的应用，空中图像目标检测长期以来一直是计算机视觉领域的热门话题。近年来，无人机（UAV）技术的进步进一步将该领域推向新的高度，产生了更广泛的应用需求。然而，传统的无人机空中目标检测方法主要侧重于检测预定义类别，这极大地限制了其适用性。跨模态文本-图像对齐技术（例如CLIP）的出现克服了这一限制，实现了开放词汇目标检测（OVOD），可以通过自然语言描述识别以前未见的物体。这一突破显著增强了无人机在空中场景理解中的智能性和自主性。本文对无人机空中场景中的OVOD进行了全面综述。我们首先将OVOD的核心原理与无人机视觉的独特特性相结合，为专门讨论奠定基础。在此基础上，我们构建了一个系统的分类体系，对现有空中图像OVOD方法进行分类，并提供了相关数据集的全面概述。这种结构化综述使我们能够批判性地剖析这些领域交叉的关键挑战和开放问题。最后，基于此分析，我们概述了有前景的未来研究方向和应用前景。本综述旨在为新手和资深研究人员提供清晰的路线图和有价值的参考，促进该快速发展领域的创新。我们持续追踪相关工作，网址为https://github.com/zhouyang2002/OVOD-in-UVA-imagery", "summary": "本文全面综述了无人机空中场景中的开放词汇目标检测（OVOD）。针对传统方法预定义类别限制的问题，文章探讨了跨模态文本-图像对齐技术（如CLIP）如何赋能OVOD，从而提升无人机智能性。文章构建了OVOD在无人机视觉领域的系统分类体系，概述了相关数据集，并深入剖析了该领域面临的关键挑战和开放问题。最后，提出了未来的研究方向和应用前景，旨在为研究人员提供指导。", "keywords": "开放词汇目标检测, 无人机图像, 综述, 跨模态, 计算机视觉", "comments": "该综述性论文对于无人机图像中的开放词汇目标检测领域具有重要意义。它系统地梳理了该领域的现状、挑战和未来方向，为研究人员提供了宝贵的路线图。特别是强调了跨模态技术在克服传统局限方面的作用，指明了未来智能无人机应用的发展潜力。"}}
{"id": "2507.13522", "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "categories": ["cs.DC"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      18 pages, 11 figures", "url": "http://arxiv.org/abs/2507.13522v1", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems.", "comment": "18 pages, 11 figures", "pdf_url": "http://arxiv.org/pdf/2507.13522v1", "cate": "cs.DC", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "Checkmate：通过网络梯度复制实现零开销模型检查点", "tldr": "Checkmate是一个在深度神经网络训练中实现逐迭代检查点的系统，通过将网络梯度复制到独立的影子集群来避免训练减速，显著提高了检查点频率并减少了故障恢复的工作量。", "motivation": "传统的检查点方法需要在训练中暂停以复制模型状态，这导致检查点频率和故障成本之间存在权衡。本文旨在避免这种权衡，实现零开销的检查点。", "method": "Checkmate的关键在于利用数据并行训练中网络梯度已包含创建检查点所需所有信息的特性。它引入了一种新的多播抽象，可以同时将梯度传递到独立的、基于CPU的影子集群。该影子集群通过将这些梯度应用于模型副本以维护检查点。", "result": "Checkmate实现了逐迭代检查点，其训练吞吐量与理想的无检查点基线相当。与最先进的检查点系统相比，Checkmate的检查点频率提高了5到34.5倍，每次故障重复工作的减少了80%到97.1%。在相同的检查点频率下，Checkmate的吞吐量比其他系统高1.3到6.5倍。", "conclusion": "Checkmate在深度神经网络训练中实现了零开销的逐迭代检查点，显著提高了检查点频率并降低了故障恢复成本，在频率和吞吐量方面均优于现有系统。", "translation": "本文介绍Checkmate，一个在深度神经网络训练中实现逐迭代检查点而没有任何训练减速的系统。传统的检查点方法需要在训练中暂停以将模型状态复制到单独的位置，从而允许在发生故障时恢复状态。这种方法在检查点频率和故障成本之间存在根本性的权衡。我们避免了这种权衡；我们的关键见解是，在数据并行训练中，创建检查点所需的所有信息已经以梯度的形式存在于网络中。我们的核心贡献是一种新的多播抽象，它同时将梯度传递到单独的基于CPU的影子集群。影子集群通过将这些梯度应用于模型副本以维护检查点。我们的评估表明，Checkmate在逐迭代检查点方面表现出与理想的无检查点基线相当的训练吞吐量。与最先进的检查点系统相比，Checkmate实现了5到34.5倍更高的检查点频率，从而使每次故障重复工作减少了80%到97.1%。在相同的检查点频率下，Checkmate的吞吐量比其他系统高1.3到6.5倍。", "summary": "Checkmate是一种深度神经网络训练系统，通过网络梯度复制实现零开销的逐迭代检查点。它利用数据并行训练中梯度包含检查点所需所有信息的特性，通过多播抽象将梯度同时发送到基于CPU的影子集群，由影子集群应用梯度维护模型副本。实验表明，Checkmate在不影响训练吞吐量的前提下，实现了比现有系统高5至34.5倍的检查点频率，并将失败后重复工作量减少80%至97.1%，在相同检查点频率下，吞吐量提升1.3至6.5倍。", "keywords": "检查点, 深度神经网络训练, 梯度复制, 容错, 分布式训练", "comments": "该论文的创新之处在于利用现有的网络梯度进行检查点，而无需中断主训练过程，从而有效消除了传统方法的权衡。这种方法显著增强了深度神经网络训练的容错性和效率。"}}
{"id": "2507.13773", "title": "Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions", "authors": ["Pu Jian", "Donglei Yu", "Wen Yang", "Shuo Ren", "Jiajun Zhang"], "categories": ["cs.CV", "cs.CL"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      ACL2025 Main", "url": "http://arxiv.org/abs/2507.13773v1", "summary": "In visual question answering (VQA) context, users often pose ambiguous\nquestions to visual language models (VLMs) due to varying expression habits.\nExisting research addresses such ambiguities primarily by rephrasing questions.\nThese approaches neglect the inherently interactive nature of user interactions\nwith VLMs, where ambiguities can be clarified through user feedback. However,\nresearch on interactive clarification faces two major challenges: (1)\nBenchmarks are absent to assess VLMs' capacity for resolving ambiguities\nthrough interaction; (2) VLMs are trained to prefer answering rather than\nasking, preventing them from seeking clarification. To overcome these\nchallenges, we introduce \\textbf{ClearVQA} benchmark, which targets three\ncommon categories of ambiguity in VQA context, and encompasses various VQA\nscenarios.", "comment": "ACL2025 Main", "pdf_url": "http://arxiv.org/pdf/2507.13773v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "教导视觉-语言模型提问：解决视觉问题中的歧义", "tldr": "为了解决视觉问答中用户提问的歧义问题，并克服现有方法无法通过交互澄清的挑战，本文引入了ClearVQA基准测试，旨在评估视觉-语言模型通过提问来解决歧义的能力。", "motivation": "在视觉问答（VQA）情境中，用户由于表达习惯不同，常向视觉语言模型（VLMs）提出模糊的问题。现有研究主要通过改写问题来解决歧义，但忽视了用户与VLMs交互的本质互动性，即歧义可以通过用户反馈来澄清。然而，交互式澄清研究面临两大挑战：1) 缺乏评估VLMs通过交互解决歧义能力的基准；2) VLMs倾向于回答而非提问，阻止它们寻求澄清。", "method": "为了克服现有挑战，本文引入了ClearVQA基准测试，该基准针对VQA情境中三种常见的歧义类别，并涵盖了各种VQA场景。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "在视觉问答（VQA）情境中，用户由于表达习惯不同，常向视觉语言模型（VLMs）提出模糊的问题。现有研究主要通过改写问题来解决此类歧义。这些方法忽视了用户与VLMs交互的本质互动性，即歧义可以通过用户反馈来澄清。然而，交互式澄清研究面临两大挑战：(1) 缺乏评估VLMs通过交互解决歧义能力的基准；(2) VLMs倾向于回答而非提问，阻止它们寻求澄清。为了克服这些挑战，我们引入了ClearVQA基准测试，该基准针对VQA情境中三种常见的歧义类别，并涵盖了各种VQA场景。", "summary": "本研究旨在解决视觉问答（VQA）中用户提问的歧义问题。鉴于现有方法主要依赖问题改写而非交互式澄清，且当前缺乏评估视觉语言模型（VLMs）交互式消歧能力的基准，同时VLMs倾向于直接回答而非主动提问以寻求澄清，本文提出了ClearVQA基准测试。该基准旨在评估和促进VLMs通过提问来解决歧义的能力，涵盖了VQA中常见的三类歧义和多种场景。", "keywords": "视觉问答, 歧义解决, 视觉语言模型, 交互式澄清, 基准测试", "comments": "这项工作创新性地指出了视觉问答领域中交互式歧义澄清的重要性，并填补了缺乏相关评估基准的空白。ClearVQA的提出对于推动视觉语言模型发展出更自然、更具交互性的问答能力至关重要，它可能促使模型从被动回答者转变为主动提问者，从而显著提升用户体验和问答准确性。"}}
{"id": "2507.13396", "title": "DyG-RAG: Dynamic Graph Retrieval-Augmented Generation with Event-Centric Reasoning", "authors": ["Qingyun Sun", "Jiaqi Yuan", "Shan He", "Xiao Guan", "Haonan Yuan", "Xingcheng Fu", "Jianxin Li", "Philip S. Yu"], "categories": ["cs.IR", "cs.CL"], "primary_category": "Subjects:       Information Retrieval (cs.IR)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13396v1", "summary": "Graph Retrieval-Augmented Generation has emerged as a powerful paradigm for\ngrounding large language models with external structured knowledge. However,\nexisting Graph RAG methods struggle with temporal reasoning, due to their\ninability to model the evolving structure and order of real-world events. In\nthis work, we introduce DyG-RAG, a novel event-centric dynamic graph\nretrieval-augmented generation framework designed to capture and reason over\ntemporal knowledge embedded in unstructured text. To eliminate temporal\nambiguity in traditional retrieval units, DyG-RAG proposes Dynamic Event Units\n(DEUs) that explicitly encode both semantic content and precise temporal\nanchors, enabling accurate and interpretable time-aware retrieval. To capture\ntemporal and causal dependencies across events, DyG-RAG constructs an event\ngraph by linking DEUs that share entities and occur close in time, supporting\nefficient and meaningful multi-hop reasoning. To ensure temporally consistent\ngeneration, DyG-RAG introduces an event timeline retrieval pipeline that\nretrieves event sequences via time-aware traversal, and proposes a Time\nChain-of-Thought strategy for temporally grounded answer generation. This\nunified pipeline enables DyG-RAG to retrieve coherent, temporally ordered event\nsequences and to answer complex, time-sensitive queries that standard RAG\nsystems cannot resolve. Extensive experiments on temporal QA benchmarks\ndemonstrate that DyG-RAG significantly improves the accuracy and recall of\nthree typical types of temporal reasoning questions, paving the way for more\nfaithful and temporal-aware generation. DyG-RAG is available at\nhttps://github.com/RingBDStack/DyG-RAG.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13396v1", "cate": "cs.IR", "date": "2025-07-16", "updated": "2025-07-16", "AI": {"title_translation": "DyG-RAG：基于事件中心推理的动态图检索增强生成", "tldr": "DyG-RAG通过引入动态事件单元和时间感知推理来解决现有图RAG在时间推理上的不足，显著提高了时间敏感查询的准确性和召回率。", "motivation": "现有图检索增强生成（Graph RAG）方法难以进行时间推理，因为它们无法建模现实世界事件的演变结构和顺序。", "method": "本文提出了DyG-RAG，一个事件中心的动态图检索增强生成框架。它引入了动态事件单元（DEUs）来显式编码语义内容和精确的时间锚点，实现时间感知检索。通过连接共享实体且时间上接近的DEUs来构建事件图，以支持高效的多跳推理。此外，DyG-RAG还引入了事件时间线检索管道，通过时间感知遍历检索事件序列，并提出了时间思维链（Time Chain-of-Thought）策略用于时间接地气的答案生成。", "result": "在时间QA基准测试上的大量实验表明，DyG-RAG显著提高了三种典型时间推理问题的准确性和召回率。", "conclusion": "DyG-RAG能够检索连贯、按时间排序的事件序列，并回答标准RAG系统无法解决的复杂、时间敏感的查询，从而实现更忠实和时间感知的生成。", "translation": "图检索增强生成已成为一种强大的范式，用于将大型语言模型与外部结构化知识相结合。然而，现有的图RAG方法在时间推理方面存在困难，因为它们无法对现实世界事件的演变结构和顺序进行建模。在这项工作中，我们引入了DyG-RAG，一个新颖的以事件为中心的动态图检索增强生成框架，旨在捕获和推理非结构化文本中嵌入的时间知识。为了消除传统检索单元中的时间模糊性，DyG-RAG提出了动态事件单元（DEUs），它明确编码语义内容和精确的时间锚点，从而实现准确且可解释的时间感知检索。为了捕获事件之间的时间和因果依赖关系，DyG-RAG通过链接共享实体且时间上接近的DEUs来构建事件图，支持高效且有意义的多跳推理。为了确保时间上一致的生成，DyG-RAG引入了一个事件时间线检索管道，通过时间感知遍历检索事件序列，并提出了时间思维链（Time Chain-of-Thought）策略用于时间接地气的答案生成。这个统一的管道使DyG-RAG能够检索连贯、按时间排序的事件序列，并回答标准RAG系统无法解决的复杂、时间敏感的查询。在时间QA基准测试上的大量实验表明，DyG-RAG显著提高了三种典型时间推理问题的准确性和召回率，为更忠实和时间感知的生成铺平了道路。DyG-RAG可在https://github.com/RingBDStack/DyG-RAG 获取。", "summary": "本文提出了DyG-RAG，一个事件中心的动态图检索增强生成框架，旨在解决现有图RAG在时间推理上的不足。DyG-RAG通过引入动态事件单元（DEUs）来编码时间信息，构建事件图捕捉事件依赖，并采用时间线检索和时间思维链策略确保时间一致性。实验证明，DyG-RAG显著提升了时间敏感查询的准确性和召回率。", "keywords": "动态图, 检索增强生成, 时间推理, 事件中心, 大型语言模型", "comments": "DyG-RAG的创新点在于其事件中心的设计和对时间维度的显式建模，通过动态事件单元、事件图和时间思维链等机制，有效解决了传统RAG系统在处理时间推理时的局限性，为构建更智能、时间感知的LLM应用提供了重要进展。"}}
{"id": "2507.12964", "title": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": ["Ammar Ahmed", "Ali Shariq Imran", "Zenun Kastrati", "Sher Muhammad Daudpota"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.12964v2", "summary": "Wrist pathologies are frequently observed, particularly among children who\nconstitute the majority of fracture cases. However, diagnosing these conditions\nis time-consuming and requires specialized expertise. Computer vision presents\na promising avenue, contingent upon the availability of extensive datasets, a\nnotable challenge in medical imaging. Therefore, reliance solely on one\nmodality, such as images, proves inadequate, especially in an era of diverse\nand plentiful data types. In this study, we employ a multifaceted approach to\naddress the challenge of recognizing wrist pathologies using an extremely\nlimited dataset. Initially, we approach the problem as a fine-grained\nrecognition task, aiming to identify subtle X-ray pathologies that conventional\nCNNs overlook. Secondly, we enhance network performance by fusing patient\nmetadata with X-ray images. Thirdly, rather than pre-training on a\ncoarse-grained dataset like ImageNet, we utilize weights trained on a\nfine-grained dataset. While metadata integration has been used in other medical\ndomains, this is a novel application for wrist pathologies. Our results show\nthat a fine-grained strategy and metadata integration improve diagnostic\naccuracy by 2% with a limited dataset and by over 10% with a larger\nfracture-focused dataset.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.12964v2", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "人口统计学感知的儿童腕部骨折细粒度分类", "tldr": "本研究提出了一种结合患者元数据和细粒度识别策略的计算机视觉方法，以提高在有限数据集上对儿童腕部骨折的诊断准确性。", "motivation": "手腕病理诊断耗时且需要专业知识，尽管计算机视觉有前景，但受限于医学影像领域缺乏大型数据集。此外，仅依赖单一模态（如图像）不足以应对数据多样性。", "method": "本研究采用多方面方法解决手腕病理识别问题，即使在极其有限的数据集下。首先，将问题视为细粒度识别任务，以识别传统CNN忽略的细微X射线病理。其次，通过融合患者元数据与X射线图像来增强网络性能。第三，不使用ImageNet等粗粒度数据集进行预训练，而是使用在细粒度数据集上训练的权重。", "result": "结果显示，细粒度策略和元数据集成在有限数据集上将诊断准确率提高了2%，在更大的以骨折为重点的数据集上提高了10%以上。", "conclusion": "结合细粒度识别策略和患者元数据能够显著提高儿童腕部骨折的诊断准确性，尤其是在数据集有限的情况下。", "translation": "腕部病理学常见，尤其是在骨折病例中占多数的儿童。然而，诊断这些疾病耗时且需要专业知识。计算机视觉提供了一条有前景的途径，但取决于大量数据集的可用性，这是医学影像领域的一个显著挑战。因此，仅依赖一种模态（如图像）是不足的，尤其是在数据类型多样且丰富的时代。在本研究中，我们采用多方面方法来解决使用极其有限的数据集识别腕部病理学的挑战。首先，我们将问题视为细粒度识别任务，旨在识别传统CNN忽略的细微X射线病理。其次，我们通过将患者元数据与X射线图像融合来增强网络性能。第三，我们不预训练于ImageNet等粗粒度数据集，而是使用在细粒度数据集上训练的权重。尽管元数据集成已用于其他医学领域，但这在腕部病理学中是新颖的应用。我们的结果显示，细粒度策略和元数据集成在有限数据集上将诊断准确率提高了2%，在更大的以骨折为重点的数据集上提高了10%以上。", "summary": "本研究提出了一种创新的计算机视觉方法，用于对儿童腕部骨折进行细粒度分类，旨在解决医学影像领域数据稀缺的挑战。该方法结合了细粒度识别策略、患者元数据与X射线图像的融合，并利用在细粒度数据集上预训练的权重。实验结果表明，该方法在有限数据集和较大数据集上均能显著提高诊断准确率。", "keywords": "腕部骨折, 细粒度分类, 元数据融合, 计算机视觉, 儿童医学影像", "comments": "该论文的创新点在于将患者元数据集成到X射线图像分析中，以提高对儿童腕部骨折的细微病理的识别能力，尤其是在数据集有限的情况下。这对于解决医学影像领域数据稀缺的普遍问题具有重要意义。细粒度识别结合多模态数据融合的方法为未来的医学图像诊断提供了新的思路。"}}
{"id": "2507.13903", "title": "AeroThrow: An Autonomous Aerial Throwing System for Precise Payload Delivery", "authors": ["Ziliang Li", "Hongming Chen", "Yiyang Lin", "Biyu Ye", "Ximin Lyu"], "categories": ["cs.RO"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13903v1", "summary": "Autonomous aerial systems play an increasingly vital role in a wide range of\napplications, particularly for transport and delivery tasks in complex\nenvironments. In airdrop missions, these platforms face the dual challenges of\nabrupt control mode switching and inherent system delays along with control\nerrors. To address these issues, this paper presents an autonomous airdrop\nsystem based on an aerial manipulator (AM). The introduction of additional\nactuated degrees of freedom enables active compensation for UAV tracking\nerrors. By imposing smooth and continuous constraints on the parabolic landing\npoint, the proposed approach generates aerial throwing trajectories that are\nless sensitive to the timing of payload release. A hierarchical disturbance\ncompensation strategy is incorporated into the Nonlinear Model Predictive\nControl (NMPC) framework to mitigate the effects of sudden changes in system\nparameters, while the predictive capabilities of NMPC are further exploited to\nimprove the precision of aerial throwing. Both simulation and real-world\nexperimental results demonstrate that the proposed system achieves greater\nagility and precision in airdrop missions.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13903v1", "cate": "cs.RO", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "AeroThrow：一种用于精确载荷投送的自主空中投掷系统", "tldr": "本文提出了一种基于空中机械手（AM）的自主空投系统，通过主动补偿无人机跟踪误差和引入分层扰动补偿策略，结合非线性模型预测控制（NMPC）框架，显著提高了空投任务的敏捷性和精度。", "motivation": "在空投任务中，自主空中系统面临控制模式突然切换、固有系统延迟以及控制误差的双重挑战。", "method": "本文提出了一种基于空中机械手（AM）的自主空投系统。该系统通过增加额外的驱动自由度来主动补偿无人机跟踪误差，并对抛物线着陆点施加平滑连续的约束，以生成对载荷释放时机不敏感的空中投掷轨迹。此外，将分层扰动补偿策略整合到非线性模型预测控制（NMPC）框架中，以减轻系统参数突变的影响，并利用NMPC的预测能力提高空中投掷的精度。", "result": "仿真和实际实验结果均表明，所提出的系统在空投任务中实现了更高的敏捷性和精度。", "conclusion": "所提出的基于空中机械手的自主空投系统，通过主动误差补偿、优化轨迹生成和先进控制策略，有效克服了传统空投的挑战，显著提高了载荷投送的精度和敏捷性。", "translation": "自主空中系统在广泛的应用中扮演着越来越重要的角色，特别是在复杂环境中的运输和交付任务。在空投任务中，这些平台面临着控制模式突然切换、固有系统延迟以及控制误差的双重挑战。为了解决这些问题，本文提出了一种基于空中机械手（AM）的自主空投系统。额外驱动自由度的引入使得能够主动补偿无人机跟踪误差。通过对抛物线着陆点施加平滑连续的约束，所提出的方法生成了对载荷释放时机敏感度较低的空中投掷轨迹。分层扰动补偿策略被整合到非线性模型预测控制（NMPC）框架中，以减轻系统参数突然变化的影响，同时进一步利用NMPC的预测能力来提高空中投掷的精度。仿真和实际实验结果均表明，所提出的系统在空投任务中实现了更高的敏捷性和精度。", "summary": "本文介绍了一种名为AeroThrow的自主空中投掷系统，旨在解决空投任务中控制模式切换、系统延迟和控制误差等挑战。该系统基于空中机械手（AM），通过增加驱动自由度来补偿无人机跟踪误差，并采用平滑连续的约束生成对释放时机不敏感的投掷轨迹。此外，系统将分层扰动补偿策略整合到非线性模型预测控制（NMPC）框架中，以提高投掷精度和应对参数变化。仿真和实际实验证明，该系统显著提升了空投任务的敏捷性和精度。", "keywords": "自主空中系统, 空中机械手, 精确投送, 非线性模型预测控制, 空投", "comments": "该论文创新性地将空中机械手（AM）引入自主空投系统，通过增加额外的驱动自由度实现了对无人机跟踪误差的主动补偿，这是其关键创新点。结合平滑约束和分层扰动补偿的NMPC框架，有效提高了投掷精度和系统鲁棒性，对于复杂环境下精确载荷投送具有重要意义。"}}
{"id": "2503.12170", "title": "DiffAD: A Unified Diffusion Modeling Approach for Autonomous Driving", "authors": ["Tao Wang", "Cong Zhang", "Xingguang Qu", "Kun Li", "Weiwei Liu", "Chang Huang"], "categories": ["cs.RO", "cs.CV"], "primary_category": "Subjects:       Robotics (cs.RO)", "pdf_link": null, "comments": "Comments:      8 pages, 6 figures; Code released", "url": "http://arxiv.org/abs/2503.12170v2", "summary": "End-to-end autonomous driving (E2E-AD) has rapidly emerged as a promising\napproach toward achieving full autonomy. However, existing E2E-AD systems\ntypically adopt a traditional multi-task framework, addressing perception,\nprediction, and planning tasks through separate task-specific heads. Despite\nbeing trained in a fully differentiable manner, they still encounter issues\nwith task coordination, and the system complexity remains high. In this work,\nwe introduce DiffAD, a novel diffusion probabilistic model that redefines\nautonomous driving as a conditional image generation task. By rasterizing\nheterogeneous targets onto a unified bird's-eye view (BEV) and modeling their\nlatent distribution, DiffAD unifies various driving objectives and jointly\noptimizes all driving tasks in a single framework, significantly reducing\nsystem complexity and harmonizing task coordination. The reverse process\niteratively refines the generated BEV image, resulting in more robust and\nrealistic driving behaviors. Closed-loop evaluations in Carla demonstrate the\nsuperiority of the proposed method, achieving a new state-of-the-art Success\nRate and Driving Score.", "comment": "8 pages, 6 figures; Code released", "pdf_url": "http://arxiv.org/pdf/2503.12170v2", "cate": "cs.RO", "date": "2025-03-15", "updated": "2025-07-18", "AI": {"title_translation": "DiffAD：一种统一的自动驾驶扩散建模方法", "tldr": "DiffAD通过将自动驾驶建模为条件图像生成任务，利用扩散模型统一并优化了端到端自动驾驶的感知、预测和规划，显著降低了系统复杂性并提升了性能。", "motivation": "现有端到端自动驾驶（E2E-AD）系统采用传统的多任务框架，通过独立的任务特定头部处理感知、预测和规划，导致任务协调问题和系统复杂性高。", "method": "提出DiffAD，一种新颖的扩散概率模型，将自动驾驶重新定义为条件图像生成任务。通过将异构目标栅格化到统一的鸟瞰图（BEV）上并建模其潜在分布，DiffAD统一了各种驾驶目标并联合优化所有驾驶任务。其逆向过程迭代细化生成的BEV图像。", "result": "在Carla的闭环评估中，DiffAD展示了优越性，实现了新的最先进的成功率和驾驶分数。", "conclusion": "DiffAD通过统一的扩散建模方法，成功解决了端到端自动驾驶中的任务协调和系统复杂性问题，并在实际仿真中取得了领先的性能。", "translation": "端到端自动驾驶（E2E-AD）已迅速成为实现完全自动驾驶的一种有前景的方法。然而，现有的E2E-AD系统通常采用传统的多任务框架，通过独立的任务特定头部处理感知、预测和规划任务。尽管以完全可微分的方式进行训练，但它们仍然面临任务协调问题，且系统复杂性仍然很高。在这项工作中，我们引入了DiffAD，一种新颖的扩散概率模型，它将自动驾驶重新定义为条件图像生成任务。通过将异构目标栅格化到统一的鸟瞰图（BEV）并建模其潜在分布，DiffAD统一了各种驾驶目标，并在一个框架中联合优化所有驾驶任务，显著降低了系统复杂性并协调了任务。逆向过程迭代地细化生成的BEV图像，从而产生更鲁棒和真实的驾驶行为。在Carla的闭环评估中，所提出的方法展示了其优越性，实现了新的最先进的成功率和驾驶分数。", "summary": "DiffAD提出了一种统一的扩散建模方法，将端到端自动驾驶任务重构为条件图像生成问题。通过在鸟瞰图（BEV）上统一感知、预测和规划目标，DiffAD显著降低了传统多任务框架的系统复杂性，并优化了任务协调。实验结果表明，该方法在Carla仿真环境中取得了最先进的性能。", "keywords": "自动驾驶, 扩散模型, 端到端, 鸟瞰图, 统一框架", "comments": "DiffAD的创新之处在于将复杂的自动驾驶多任务问题统一为条件图像生成，利用扩散模型的迭代细化能力来生成更鲁棒和真实的驾驶行为，有效解决了现有E2E-AD系统的任务协调和复杂性问题。这种统一的建模方法为自动驾驶领域带来了新的视角和解决方案。"}}
{"id": "2507.13982", "title": "Diffraction and Scattering Modeling for Laser Power Beaming in Lunar Environment", "authors": ["Yanni Jiwan-Mercier", "Barış Dönmez", "Güneş Karabulut-Kurt", "Sébastien Loranger"], "categories": ["eess.SY", "cs.SY"], "primary_category": "Subjects:       Systems and Control (eess.SY)", "pdf_link": null, "comments": "Comments:      10 pages, 8 figures", "url": "http://arxiv.org/abs/2507.13982v1", "summary": "Reliable energy delivery is a critical requirement for\n  long-term lunar missions, particularly in regions with limited\n  solar access, such as polar craters and during extended lunar\n  nights. Optical Power Beaming (OPB) using high-power lasers\n  offers a promising alternative to conventional solar power, but\n  the effects of suspended lunar dust on beam propagation remain\n  poorly understood. This study introduces a detailed simulation\n  model that incorporates both diffraction and height-dependent\n  scattering by the electrostatically suspended lunar regolith. Un like prior\napproaches, which assumed uniform dust layers or\n  center-to-center transmission loss, our model uses generalized\n  diffraction theory and refractive index gradients derived from\n  particle density to assess beam deformation and attenuation. The\n  results show that even in ground-to-ground scenarios, lunar dust\n  significantly degrades energy transfer efficiency, dropping from\n  57% to 3.7% over 50 km in dust-free vs. dusty conditions with\n  175 nm particles. Increasing the particle size to 250 nm limits the\n  viable transmission range to below 30 km at 6% efficiency. The\n  study further demonstrates that raising the laser source height\n  can improve efficiency, achieving 91% for a distance of 5 km\n  and 25% at 50 km when the source is positioned 12 m above\n  ground. These findings underscore the importance of system\n  elevation and dust modeling in lunar OPB design and reveal\n  the mission-critical role of particle size distribution, especially in\n  environments disturbed by human activity.", "comment": "10 pages, 8 figures", "pdf_url": "http://arxiv.org/pdf/2507.13982v1", "cate": "eess.SY", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "月球环境下激光能量束流的衍射与散射建模", "tldr": "本研究开发了一个详细的模拟模型，用于评估月球尘埃对激光能量束流传输的影响，发现月尘显著降低了能量传输效率，并强调了系统高度和尘埃建模的重要性。", "motivation": "月球长期任务，特别是光照有限区域（如极地陨石坑和长时间月夜），对可靠的能量传输有关键需求。激光光能束流（OPB）作为传统太阳能的替代方案前景广阔，但悬浮月尘对光束传播的影响尚不明确。", "method": "本研究引入了一个详细的模拟模型，该模型结合了静电悬浮月壤的衍射和高度依赖性散射。与之前假设均匀尘埃层或中心到中心传输损耗的方法不同，我们的模型使用广义衍射理论和从粒子密度导出的折射率梯度来评估光束变形和衰减。", "result": "研究结果表明，即使在地面-地面场景中，月尘也会显著降低能量传输效率，在无尘与有尘条件下，对于175纳米的颗粒，50公里距离上的效率从57%降至3.7%。将颗粒尺寸增加到250纳米，可行传输范围限制在30公里以下，效率为6%。研究进一步表明，提高激光源高度可以提高效率，在5公里距离上达到91%，在50公里距离上达到25%（当光源位于地面上方12米时）。", "conclusion": "这些发现强调了在月球OPB设计中系统高度和尘埃建模的重要性，并揭示了颗粒尺寸分布（特别是在人类活动扰动的环境中）对任务的关键作用。", "translation": "可靠的能量传输是月球长期任务的关键需求，特别是在太阳光照有限的区域，例如极地陨石坑和长时间的月夜。使用高功率激光的光能束流（OPB）为传统太阳能提供了一个有前景的替代方案，但悬浮月尘对光束传播的影响仍然知之甚少。本研究引入了一个详细的模拟模型，该模型结合了静电悬浮月壤的衍射和高度依赖性散射。与之前假设均匀尘埃层或中心到中心传输损耗的方法不同，我们的模型使用广义衍射理论和从粒子密度导出的折射率梯度来评估光束变形和衰减。结果表明，即使在地面-地面场景中，月尘也会显著降低能量传输效率，在无尘与有尘条件下，对于175纳米的颗粒，50公里距离上的效率从57%降至3.7%。将颗粒尺寸增加到250纳米，可行传输范围限制在30公里以下，效率为6%。研究进一步表明，提高激光源高度可以提高效率，在5公里距离上达到91%，在50公里距离上达到25%（当光源位于地面上方12米时）。这些发现强调了在月球OPB设计中系统高度和尘埃建模的重要性，并揭示了颗粒尺寸分布（特别是在人类活动扰动的环境中）对任务的关键作用。", "summary": "本研究开发了一个详细的模拟模型，用于评估月球环境中悬浮月尘对激光能量束流（OPB）传输的影响。该模型结合了广义衍射理论和高度依赖性散射，并考虑了由粒子密度引起的折射率梯度。模拟结果表明，月尘会显著降低能量传输效率，例如在50公里距离上，175纳米颗粒的存在可使效率从57%降至3.7%。研究还发现，提高激光源高度可以有效改善传输效率，例如在12米高度下，50公里距离上的效率可达25%。这些发现强调了在月球OPB系统设计中，精确的尘埃建模和系统高度选择的重要性，尤其是在考虑颗粒尺寸分布时。", "keywords": "激光能量束流, 月球尘埃, 衍射, 散射, 能量传输效率", "comments": "本研究通过引入一个考虑衍射和高度依赖性散射的详细模拟模型，创新性地解决了月球尘埃对激光能量束流传播影响的复杂问题，超越了以往简化的假设。其重要性在于量化了月尘对能量传输效率的显著衰减作用，并提出了提高激光源高度这一实际可行的缓解策略。这对于未来月球长期任务的能源系统设计具有关键指导意义，特别是为在尘埃扰动环境中部署OPB系统提供了宝贵的工程洞察。"}}
{"id": "2506.06941", "title": "The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "authors": ["Parshin Shojaee", "Iman Mirzadeh", "Keivan Alizadeh", "Maxwell Horton", "Samy Bengio", "Mehrdad Farajtabar"], "categories": ["cs.AI", "cs.CL", "cs.LG"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      preprint", "url": "http://arxiv.org/abs/2506.06941v2", "summary": "Recent generations of language models have introduced Large Reasoning Models\n(LRMs) that generate detailed thinking processes before providing answers.\nWhile these models demonstrate improved performance on reasoning benchmarks,\ntheir fundamental capabilities, scaling properties, and limitations remain\ninsufficiently understood. Current evaluations primarily focus on established\nmath and coding benchmarks, emphasizing final answer accuracy. However, this\nevaluation paradigm often suffers from contamination and does not provide\ninsights into the reasoning traces. In this work, we systematically investigate\nthese gaps with the help of controllable puzzle environments that allow precise\nmanipulation of complexity while maintaining consistent logical structures.\nThis setup enables the analysis of not only final answers but also the internal\nreasoning traces, offering insights into how LRMs think. Through extensive\nexperiments, we show that LRMs face a complete accuracy collapse beyond certain\ncomplexities. Moreover, they exhibit a counterintuitive scaling limit: their\nreasoning effort increases with problem complexity up to a point, then declines\ndespite having remaining token budget. By comparing LRMs with their standard\nLLM counterparts under same inference compute, we identify three performance\nregimes: (1) low-complexity tasks where standard models outperform LRMs, (2)\nmedium-complexity tasks where LRMs demonstrates advantage, and (3)\nhigh-complexity tasks where both models face complete collapse. We found that\nLRMs have limitations in exact computation: they fail to use explicit\nalgorithms and reason inconsistently across scales. We also investigate the\nreasoning traces in more depth, studying the patterns of explored solutions and\nanalyzing the models' computational behavior, shedding light on their\nstrengths, limitations, and raising questions about their reasoning\ncapabilities.", "comment": "preprint", "pdf_url": "http://arxiv.org/pdf/2506.06941v2", "cate": "cs.AI", "date": "2025-06-07", "updated": "2025-07-18", "AI": {"title_translation": "思维的错觉：通过问题复杂性视角理解推理模型的优势与局限性", "tldr": "本文通过可控的谜题环境，系统性地研究了大型推理模型（LRMs）的推理能力、扩展特性和局限性。研究发现LRMs在特定复杂性下准确率会完全崩溃，并且存在反直觉的扩展限制。通过与标准大型语言模型（LLMs）的比较，揭示了LRMs在不同复杂性任务下的表现模式，并指出其在精确计算和算法使用上的局限性。", "motivation": "当前的语言模型，特别是大型推理模型（LRMs），在推理基准测试上表现有所提升，但其基本能力、扩展特性和局限性仍未被充分理解。现有评估主要关注最终答案的准确性，但这种范式可能存在数据污染且无法深入了解推理过程。因此，需要系统地探究这些模型的工作原理、优势和局限性。", "method": "本研究利用可控的谜题环境，精确控制问题复杂性并保持逻辑结构一致，从而系统地调查了大型推理模型（LRMs）的能力。这种设置不仅允许分析最终答案，还能深入研究内部推理轨迹。通过广泛的实验，研究将LRMs与标准大型语言模型（LLMs）在相同推理计算下进行比较，并深入分析了推理轨迹，研究了探索解决方案的模式和模型的计算行为。", "result": "1. 大型推理模型（LRMs）在超过一定复杂性后，准确率会完全崩溃。\n2. LRMs表现出反直觉的扩展限制：推理努力随问题复杂性增加到某个点后下降，即使仍有剩余token预算。\n3. 与标准大型语言模型（LLMs）在相同推理计算下比较，发现了三种性能区域：(1) 低复杂性任务下标准模型优于LRMs；(2) 中等复杂性任务下LRMs表现出优势；(3) 高复杂性任务下两种模型均完全崩溃。\n4. LRMs在精确计算方面存在局限性：它们未能使用明确的算法，并且在不同规模上推理不一致。", "conclusion": "大型推理模型（LRMs）在推理任务中表现出显著的优势，尤其是在中等复杂度的任务上，但其能力并非无限，在面对高复杂度问题时会遭遇性能瓶颈，甚至完全失效。它们在精确计算和算法应用上存在固有局限性，并且其推理努力与问题复杂度的关系呈现出反直觉的模式。对推理轨迹的深入分析揭示了LRMs在“思考”方面的优势与局限性，并对其真正的推理能力提出了疑问。", "translation": "最近几代语言模型引入了大型推理模型（LRMs），这些模型在提供答案之前会生成详细的思维过程。尽管这些模型在推理基准测试上表现出性能提升，但其基本能力、扩展特性和局限性仍未被充分理解。当前的评估主要集中在已有的数学和编码基准测试上，强调最终答案的准确性。然而，这种评估范式常常受到数据污染的影响，并且无法提供对推理轨迹的深入见解。在这项工作中，我们借助可控的谜题环境系统地调查了这些不足，这些环境允许精确操纵复杂性，同时保持一致的逻辑结构。这种设置不仅能够分析最终答案，还能分析内部推理轨迹，从而深入了解LRMs是如何“思考”的。通过广泛的实验，我们表明LRMs在超过一定复杂性后会面临完全的准确率崩溃。此外，它们表现出一种反直觉的扩展限制：它们的推理努力随问题复杂性增加到某个点后下降，尽管仍有剩余的token预算。通过在相同推理计算下将LRMs与其标准大型语言模型（LLM）对应物进行比较，我们确定了三种性能区域：(1) 低复杂性任务，标准模型优于LRMs；(2) 中等复杂性任务，LRMs表现出优势；(3) 高复杂性任务，两种模型均面临完全崩溃。我们发现LRMs在精确计算方面存在局限性：它们未能使用明确的算法，并且在不同规模上推理不一致。我们还更深入地研究了推理轨迹，探讨了探索解决方案的模式并分析了模型的计算行为，从而揭示了它们的优势、局限性，并对其推理能力提出了疑问。", "summary": "本文系统性地探讨了大型推理模型（LRMs）的实际能力、扩展特性和局限性。通过设计可控的谜题环境，研究深入分析了LRMs的内部推理过程，而非仅仅依赖最终答案。实验结果表明，LRMs在面对高复杂度问题时会遭遇准确率的显著下降甚至崩溃，并存在反直觉的推理努力上限。与标准大型语言模型（LLMs）的对比揭示了LRMs在不同复杂性任务下的性能差异，并指出其在精确计算和算法应用方面的不足，从而对LRMs的“思维”能力提出了更深层次的疑问。", "keywords": "大型推理模型, 语言模型, 问题复杂性, 推理能力, 局限性", "comments": "这篇论文创新性地使用了可控谜题环境来评估大型推理模型，避免了传统基准测试中可能存在的污染问题，并能够深入分析模型的内部推理过程。其发现LRMs在面对高复杂度问题时的“准确率崩溃”和“反直觉的扩展限制”对于理解当前AI模型的局限性具有重要意义。论文强调了LRMs在精确计算和算法应用上的不足，这对于未来的模型设计和评估提供了宝贵的见解。该研究不仅揭示了LRMs的优势，也坦诚地指出了其“思维”的错觉，对于推动可解释AI和更稳健的推理模型发展具有重要价值。"}}
{"id": "2506.19805", "title": "Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective", "authors": ["Chenhao Si", "Ming Yan"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      18 pages, 12 figures", "url": "http://arxiv.org/abs/2506.19805v2", "summary": "Physics-informed neural networks (PINNs) are extensively employed to solve\npartial differential equations (PDEs) by ensuring that the outputs and\ngradients of deep learning models adhere to the governing equations. However,\nconstrained by computational limitations, PINNs are typically optimized using a\nfinite set of points, which poses significant challenges in guaranteeing their\nconvergence and accuracy. In this study, we proposed a new weighting scheme\nthat will adaptively change the weights to the loss functions from isolated\npoints to their continuous neighborhood regions. The empirical results show\nthat our weighting scheme can reduce the relative $L^2$ errors to a lower\nvalue.", "comment": "18 pages, 12 figures", "pdf_url": "http://arxiv.org/pdf/2506.19805v2", "cate": "cs.LG", "date": "2025-06-24", "updated": "2025-07-18", "AI": {"title_translation": "物理信息神经网络的卷积加权方法：一种原始-对偶优化视角", "tldr": "提出了一种新的自适应加权方案，用于物理信息神经网络(PINNs)的损失函数，以解决其收敛性和准确性问题，实验结果显示该方案能显著降低L2误差。", "motivation": "物理信息神经网络（PINNs）在求解偏微分方程（PDEs）时，由于计算限制，通常使用有限点集进行优化，这对其收敛性和准确性带来了重大挑战。", "method": "本研究提出了一种新的加权方案，该方案能自适应地将损失函数的权重从孤立点改变到其连续邻域区域。", "result": "经验结果表明，所提出的加权方案能够将相对$L^2$误差降低到一个更低的值。", "conclusion": "该研究提出的卷积加权方法有效提高了物理信息神经网络的准确性，通过将损失函数的权重从孤立点扩展到连续邻域区域，解决了传统PINNs在收敛性和精度上的挑战。", "translation": "物理信息神经网络（PINNs）被广泛应用于求解偏微分方程（PDEs），通过确保深度学习模型的输出和梯度符合控制方程。然而，受计算限制，PINNs通常使用有限点集进行优化，这对其收敛性和准确性带来了重大挑战。在本研究中，我们提出了一种新的加权方案，该方案将自适应地把损失函数的权重从孤立点改变到其连续邻域区域。经验结果表明，我们的加权方案可以将相对$L^2$误差降低到一个更低的值。", "summary": "本文提出了一种针对物理信息神经网络（PINNs）的新型卷积加权方法，旨在解决现有PINNs在有限点集优化下导致的收敛性和准确性问题。该方法通过自适应地将损失函数的权重从孤立点扩展到其连续邻域，显著降低了相对$L^2$误差，提升了PINNs的性能。", "keywords": "物理信息神经网络, 卷积加权, 原始-对偶优化, 偏微分方程, 误差降低", "comments": "这项研究通过引入自适应加权方案，解决了物理信息神经网络在有限点优化下收敛性和准确性不足的关键问题。将权重从孤立点扩展到连续邻域区域是一个创新点，有望提高PINNs在复杂PDEs求解中的鲁棒性和精度。"}}
{"id": "2507.13846", "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments", "authors": ["Kathrin Korte", "Christian Medeiros Adriano", "Sona Ghahremani", "Holger Giese"], "categories": ["cs.AI"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13846v1", "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13846v1", "cate": "cs.AI", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "动态环境中多智能体强化学习的因果知识迁移", "tldr": "本文提出一种因果知识迁移框架，使多智能体强化学习在动态环境中无需重新训练即可共享适应性恢复策略，有效提升了新环境下的适应能力，尤其对异构目标智能体表现良好。", "motivation": "多智能体强化学习在非平稳、目标变化的动态环境中进行知识迁移面临挑战，传统方法泛化能力差，智能体通常需要昂贵的再训练才能适应新环境。", "method": "本文引入了一个因果知识迁移框架，使RL智能体能够学习并共享环境中路径的紧凑因果表示。该方法将每次碰撞建模为因果干预，并实例化为一系列恢复动作（宏），这些宏包含了规避障碍和达成目标的因果知识。恢复动作宏可以从第二个智能体在线迁移，并以零样本方式应用，即无需再训练，只需通过查询带有局部上下文信息（碰撞）的查找模型即可。", "result": "1. 具有异构目标的智能体在适应新环境时，能够弥补随机探索与完全再训练策略之间约一半的差距。2. 因果知识迁移的影响取决于环境复杂性和智能体异构目标之间的相互作用。", "conclusion": "基于因果知识迁移的框架能有效提升多智能体在动态环境下的适应性，减少再训练成本，尤其在异构目标和特定环境复杂度的结合下表现显著。", "translation": "[背景] 多智能体强化学习 (MARL) 在智能体必须学习协调行为的环境中取得了显著成功。然而，在目标不断变化的非平稳环境中，智能体之间的知识迁移仍然充满挑战。[问题] 传统的MARL知识迁移方法难以泛化，智能体通常需要昂贵的再训练才能适应。[方法] 本文引入了一个因果知识迁移框架，使强化学习智能体能够在非平稳环境中学习和共享路径的紧凑因果表示。当环境发生变化（出现新障碍物）时，智能体的碰撞需要自适应恢复策略。我们将每次碰撞建模为因果干预，实例化为一系列恢复动作（宏），其效果对应于如何规避障碍物同时增加实现智能体目标（最大化累积奖励）机会的因果知识。这种恢复动作宏从第二个智能体在线迁移，并以零样本方式应用，即无需再训练，只需通过查询带有局部上下文信息（碰撞）的查找模型即可。[结果] 我们的研究结果揭示了两个关键见解：(1) 具有异构目标的智能体在适应新环境时，能够弥补随机探索与完全再训练策略之间约一半的差距；(2) 因果知识迁移的影响取决于环境复杂性和智能体异构目标之间的相互作用。", "summary": "本文针对多智能体强化学习在动态非平稳环境中知识迁移效率低、需要频繁再训练的问题，提出了一个因果知识迁移框架。该框架允许智能体学习并共享碰撞恢复的因果宏动作，这些宏动作可以从其他智能体在线零样本迁移，无需再训练即可适应新障碍。实验结果表明，该方法能有效提升智能体在新环境下的适应能力，尤其对于异构目标智能体，能显著缩小与完全再训练策略的差距，其效果受环境复杂度和目标异构性的影响。", "keywords": "因果知识迁移, 多智能体强化学习, 动态环境, 零样本适应, 知识共享", "comments": "该论文的创新点在于引入了因果推理来解决多智能体强化学习中的知识迁移问题，特别是在动态、非平稳环境下的零样本适应能力。通过将碰撞建模为因果干预并迁移恢复动作宏，有效避免了昂贵的再训练。这种方法对于现实世界中需要快速适应变化的机器人或自动化系统具有重要意义。"}}
{"id": "2507.13411", "title": "Aligning Knowledge Graphs and Language Models for Factual Accuracy", "authors": ["Nur A Zarin Nishat", "Andrea Coletta", "Luigi Bellomarini", "Kossi Amouzouvi", "Jens Lehmann", "Sahar Vahdati"], "categories": ["cs.CL", "cs.AI"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13411v1", "summary": "Large language models like GPT-4, Gemini, and Claude have transformed natural\nlanguage processing (NLP) tasks such as question answering, dialogue\ngeneration, summarization, and so forth; yet their susceptibility to\nhallucination stands as one of the major challenges. Among numerous approaches\nto overcome this challenge, integration of Knowledge Graphs (KGs) into language\nmodels has emerged as a promising solution as it provides structured, reliable,\ndomain-specific, and up-to-date external information to the language models. In\nthis paper, we introduce ALIGNed-LLM, a simple yet effective approach to\nimprove language models' factuality via a lean strategy to infuse KGs into the\nlatent space of language models inspired by LLaVA where visual and textual\ninformation is infused. We use embeddings from a pre-trained Knowledge Graph\nEmbedding (KGE) model, such as TransE, and a trainable projection layer to\nalign entity and text embeddings. This alignment enables the language model to\ndistinguish between similar entities improving factual grounding and reducing\nhallucination. We tested our approach on three popular questions-answering\nbenchmark datasets alongside language models of varying sizes, showing\nsignificant improvement. Furthermore, we applied our approach to a real-world\nfinancial use case from a large central bank in Europe, which demands high\naccuracy and precision, demonstrating a substantial improvement of the LLM\nanswers.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13411v1", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "对齐知识图谱与语言模型以提高事实准确性", "tldr": "本文提出ALIGNed-LLM，一种简单有效的方法，通过将知识图谱嵌入语言模型的潜在空间来提高大型语言模型的事实准确性，从而减少幻觉。", "motivation": "大型语言模型（如GPT-4、Gemini、Claude）在自然语言处理任务中表现出色，但其易于产生幻觉是主要挑战之一。将知识图谱集成到语言模型中被认为是一个有前景的解决方案，因为它能提供结构化、可靠、领域特定和最新的外部信息。", "method": "本文引入了ALIGNed-LLM，一种受LLaVA启发的方法。它通过将预训练的知识图谱嵌入（如TransE）和可训练的投影层结合，将知识图谱信息融入语言模型的潜在空间，以对齐实体和文本嵌入。这使得语言模型能够区分相似实体，从而提高事实基础和减少幻觉。", "result": "该方法在三个流行的问答基准数据集上对不同大小的语言模型进行了测试，显示出显著改进。此外，将其应用于欧洲一家大型中央银行的真实金融用例，也证明了LLM答案的实质性改进。", "conclusion": "ALIGNed-LLM通过有效融合知识图谱，显著提高了语言模型的事实准确性，减少了幻觉，并在基准测试和真实世界应用中取得了成功。", "translation": "大型语言模型，如GPT-4、Gemini和Claude，已经改变了问答、对话生成、摘要等自然语言处理（NLP）任务；然而，它们容易产生幻觉仍然是主要挑战之一。在克服这一挑战的众多方法中，将知识图谱（KGs）集成到语言模型中已成为一个有前景的解决方案，因为它为语言模型提供了结构化、可靠、领域特定和最新的外部信息。在本文中，我们引入了ALIGNed-LLM，这是一种简单而有效的方法，通过一种精简的策略将知识图谱融入语言模型的潜在空间，从而提高语言模型的事实性，其灵感来源于LLaVA中视觉和文本信息的融合。我们使用来自预训练知识图谱嵌入（KGE）模型（如TransE）的嵌入和一个可训练的投影层来对齐实体和文本嵌入。这种对齐使语言模型能够区分相似实体，从而提高事实基础并减少幻觉。我们在三个流行的问答基准数据集上以及不同大小的语言模型上测试了我们的方法，显示出显著改进。此外，我们将我们的方法应用于欧洲一家大型中央银行的真实金融用例，该用例要求高准确性和精确度，结果表明LLM答案得到了实质性改进。", "summary": "本文提出ALIGNed-LLM，一种旨在提高大型语言模型事实准确性的方法。针对LLM易产生幻觉的问题，该方法借鉴LLaVA的理念，通过将预训练的知识图谱嵌入（如TransE）与可训练的投影层相结合，将知识图谱信息有效地注入到语言模型的潜在空间中，以对齐实体和文本嵌入。实验结果表明，ALIGNed-LLM在多个问答基准测试和真实的金融用例中均显著提升了语言模型的事实基础和减少了幻觉。", "keywords": "知识图谱, 语言模型, 事实准确性, 幻觉, 问答", "comments": "ALIGNed-LLM的创新之处在于其“精简”的知识图谱注入策略，借鉴了多模态对齐的思路（LLaVA），避免了复杂的结构调整，同时实现了显著的效果。其重要性在于提供了一种有效且相对简单的方法来解决大型语言模型的核心痛点——幻觉问题，并已被证明在要求高准确性的实际金融场景中有效。"}}
{"id": "2507.13748", "title": "Elastic Buffer Design for Real-Time All-Digital Clock Recovery Enabling Free-Running Receiver Clock with Negative and Positive Clock Frequency Offsets", "authors": ["Patrick Matalla", "Joel Dittmer", "Md Salek Mahmud", "Christian Koos", "Sebastian Randel"], "categories": ["eess.SP"], "primary_category": "Subjects:       Signal Processing (eess.SP)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13748v1", "summary": "We present an elastic buffer design that enables all-digital clock recovery\nimplementation with free-running receiver clock featuring negative and positive\nclock frequency offsets. Error-free real-time data transmission is demonstrated\nfrom -400 ppm to +400 ppm.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13748v1", "cate": "eess.SP", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "用于实时全数字时钟恢复的弹性缓冲器设计，支持具有负和正时钟频率偏移的自由运行接收器时钟", "tldr": "本文提出了一种弹性缓冲器设计，用于全数字时钟恢复，支持具有正负时钟频率偏移的自由运行接收器时钟，并实现了无差错实时数据传输。", "motivation": "为了实现全数字时钟恢复，并支持具有正负时钟频率偏移的自由运行接收器时钟，以确保实时数据传输的准确性。", "method": "采用弹性缓冲器设计。", "result": "在-400 ppm到+400 ppm的范围内实现了无差错的实时数据传输。", "conclusion": "弹性缓冲器设计成功地实现了支持正负时钟频率偏移的全数字时钟恢复，并证明了其在实时数据传输中的有效性。", "translation": "我们提出了一种弹性缓冲器设计，该设计能够实现全数字时钟恢复，并支持具有负和正时钟频率偏移的自由运行接收器时钟。演示了从-400 ppm到+400 ppm的无差错实时数据传输。", "summary": "本文介绍了一种弹性缓冲器设计，旨在实现全数字时钟恢复，从而允许接收器时钟在存在正负时钟频率偏移的情况下自由运行。实验证明，该设计能够在-400 ppm至+400 ppm的范围内实现无差错的实时数据传输。", "keywords": "弹性缓冲器, 全数字时钟恢复, 频率偏移, 实时数据传输", "comments": "该论文的创新点在于提出了弹性缓冲器设计，有效解决了全数字时钟恢复中自由运行接收器时钟存在的正负频率偏移问题，对于提高实时数据传输的鲁棒性具有重要意义。"}}
{"id": "2302.09409", "title": "LOCUS: LOcalization with Channel Uncertainty and Sporadic Energy", "authors": ["Subrata Biswas", "Mohammad Nur Hossain Khan", "Violet Colwell", "Jack Adiletta", "Bashima Islam"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2302.09409v3", "summary": "Accurate sound source localization (SSL), such as direction-of-arrival (DoA)\nestimation, relies on consistent multichannel data. However, batteryless\nsystems often suffer from missing data due to the stochastic nature of energy\nharvesting, degrading localization performance. We propose LOCUS, a deep\nlearning framework that recovers corrupted features in such settings. LOCUS\nintegrates three modules: (1) Information-Weighted Focus (InFo) to identify\ncorrupted regions, (2) Latent Feature Synthesizer (LaFS) to reconstruct missing\nfeatures, and (3) Guided Replacement (GRep) to restore data without altering\nvalid inputs. LOCUS significantly improves DoA accuracy under missing-channel\nconditions, achieving up to 36.91% error reduction on DCASE and LargeSet, and\n25.87-59.46% gains in real-world deployments. We release a 50-hour multichannel\ndataset to support future research on localization under energy constraints.\nOur code and data are available at: https://bashlab.github.io/locus_project/", "comment": null, "pdf_url": "http://arxiv.org/pdf/2302.09409v3", "cate": "cs.LG", "date": "2023-02-18", "updated": "2025-07-18", "AI": {"title_translation": "LOCUS: 具有信道不确定性和零星能量的定位", "tldr": "LOCUS是一个深度学习框架，旨在解决无电池系统中因能量收集随机性导致的信道数据缺失问题，显著提高了声源定位精度。", "motivation": "无电池系统由于能量收集的随机性，经常面临多通道数据缺失的问题，这会严重降低声源定位（如到达方向估计）的性能。", "method": "本文提出了LOCUS，一个深度学习框架，用于恢复无电池系统中损坏的特征。LOCUS集成了三个模块：1) 信息加权聚焦（InFo）用于识别损坏区域；2) 潜在特征合成器（LaFS）用于重建缺失特征；3) 引导替换（GRep）用于在不改变有效输入的情况下恢复数据。", "result": "LOCUS在缺失信道条件下显著提高了到达方向（DoA）精度，在DCASE和LargeSet数据集上实现了高达36.91%的错误率降低，在实际部署中获得了25.87-59.46%的性能提升。此外，作者还发布了一个50小时的多通道数据集，以支持未来在能量受限下定位的研究。", "conclusion": "LOCUS框架通过其创新的模块设计，有效解决了无电池系统因能量收集不确定性导致的声源定位数据缺失问题，显著提升了定位精度，并为相关研究提供了新的数据集。", "translation": "准确的声源定位（SSL），例如到达方向（DoA）估计，依赖于一致的多通道数据。然而，无电池系统由于能量收集的随机性，经常遭受数据缺失的困扰，从而降低了定位性能。我们提出了LOCUS，一个深度学习框架，用于在这种设置下恢复损坏的特征。LOCUS集成了三个模块：（1）信息加权聚焦（InFo）用于识别损坏区域；（2）潜在特征合成器（LaFS）用于重建缺失特征；（3）引导替换（GRep）用于在不改变有效输入的情况下恢复数据。LOCUS在缺失信道条件下显著提高了DoA精度，在DCASE和LargeSet数据集上实现了高达36.91%的错误率降低，在实际部署中获得了25.87-59.46%的增益。我们发布了一个50小时的多通道数据集，以支持未来在能量约束下定位的研究。我们的代码和数据可在以下网址获取：https://bashlab.github.io/locus_project/", "summary": "LOCUS是一个针对无电池系统声源定位中数据缺失问题而设计的深度学习框架。由于能量收集的随机性，这类系统常出现多通道数据不一致，影响定位精度。LOCUS通过集成信息加权聚焦、潜在特征合成器和引导替换三个模块，有效地识别、重建并恢复受损或缺失的信道数据。实验结果表明，LOCUS在多种数据集和实际部署中均能显著提升到达方向估计的准确性，并提供了一个新的大规模数据集以促进未来研究。", "keywords": "声源定位, 深度学习, 能量收集, 数据缺失, 信道不确定性", "comments": "该论文的创新点在于提出了一个专门针对无电池系统中因能量不确定性导致的数据缺失问题的深度学习解决方案。其模块化的设计（InFo, LaFS, GRep）思路清晰，能够针对性地处理数据损坏和缺失。此外，发布一个新的大规模数据集对于推动该领域的研究具有重要意义。该工作在提升能量受限设备声源定位性能方面具有重要的实际应用价值。"}}
{"id": "2507.07722", "title": "Understanding Dataset Bias in Medical Imaging: A Case Study on Chest X-rays", "authors": ["Ethan Dack", "Chengliang Dai"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.07722v4", "summary": "Recent works have revisited the infamous task ``Name That Dataset'',\ndemonstrating that non-medical datasets contain underlying biases and that the\ndataset origin task can be solved with high accuracy. In this work, we revisit\nthe same task applied to popular open-source chest X-ray datasets. Medical\nimages are naturally more difficult to release for open-source due to their\nsensitive nature, which has led to certain open-source datasets being extremely\npopular for research purposes. By performing the same task, we wish to explore\nwhether dataset bias also exists in these datasets. To extend our work, we\napply simple transformations to the datasets, repeat the same task, and perform\nan analysis to identify and explain any detected biases. Given the importance\nof AI applications in medical imaging, it's vital to establish whether modern\nmethods are taking shortcuts or are focused on the relevant pathology. We\nimplement a range of different network architectures on the datasets: NIH,\nCheXpert, MIMIC-CXR and PadChest. We hope this work will encourage more\nexplainable research being performed in medical imaging and the creation of\nmore open-source datasets in the medical domain. Our code can be found here:\nhttps://github.com/eedack01/x_ray_ds_bias.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.07722v4", "cate": "cs.CV", "date": "2025-07-10", "updated": "2025-07-18", "AI": {"title_translation": "了解医学影像中的数据集偏差：胸部X光片的案例研究", "tldr": "本文探讨了医学影像数据集中是否存在偏差，特别是胸部X光片数据集，通过重新审视“识别数据集来源”任务，并希望促进医学影像领域的可解释性研究和更多开源数据集的创建。", "motivation": "鉴于AI在医学影像应用中的重要性，作者认为有必要确定现代方法是走捷径还是专注于相关病理。由于医学图像的敏感性，开源发布面临困难，导致某些开源数据集非常受欢迎。因此，作者希望通过重复“识别数据集来源”任务来探索这些流行的胸部X光片数据集中是否存在数据集偏差。", "method": "作者将“识别数据集来源”任务应用于流行的开源胸部X光片数据集（NIH, CheXpert, MIMIC-CXR, PadChest）。他们对数据集应用简单的转换，重复相同的任务，并进行分析以识别和解释任何检测到的偏差。他们实现了多种不同的网络架构。", "result": "Not mentioned in abstract", "conclusion": "Not mentioned in abstract", "translation": "近期工作重新审视了臭名昭著的“识别数据集来源”任务，证明非医学数据集包含潜在偏差，并且数据集来源任务可以高精度解决。在这项工作中，我们将相同的任务应用于流行的开源胸部X光片数据集。医学图像由于其敏感性，自然更难开源发布，这导致某些开源数据集在研究目的上极受欢迎。通过执行相同的任务，我们希望探索这些数据集中是否存在数据集偏差。为了扩展我们的工作，我们对数据集应用简单的转换，重复相同的任务，并进行分析以识别和解释任何检测到的偏差。鉴于AI在医学影像应用中的重要性，确定现代方法是走捷径还是专注于相关病理至关重要。我们在数据集上实现了多种不同的网络架构：NIH、CheXpert、MIMIC-CXR和PadChest。我们希望这项工作能鼓励医学影像领域开展更多可解释性研究，并创建更多医学领域的开源数据集。我们的代码可以在这里找到：https://github.com/eedack01/x_ray_ds_bias。", "summary": "本文探讨了医学影像数据集中普遍存在的偏差问题，特别是针对流行的开源胸部X光片数据集。作者通过重新应用“识别数据集来源”任务，旨在探究这些数据集中是否存在潜在偏差。研究方法包括对数据集进行简单转换并分析结果以识别偏差，同时在NIH、CheXpert、MIMIC-CXR和PadChest等数据集上实现了多种网络架构。文章强调了在医学AI应用中识别偏差的重要性，以确保模型专注于相关病理而非数据集捷径，并希望促进医学影像领域的可解释性研究和更多开源数据集的创建。", "keywords": "数据集偏差, 医学影像, 胸部X光片, 可解释性AI", "comments": "这项工作在医学影像AI领域具有重要意义，因为它直接解决了数据集偏差这一关键问题。在医疗AI应用中，模型如果学习到数据集的伪相关性而非真实的病理特征，可能会导致诊断错误和信任危机。通过检查流行开源数据集的偏差，该研究有助于提高医学AI模型的鲁棒性和可信度。此外，鼓励可解释性研究和更多开源数据集的倡议，对于推动该领域的健康发展至关重要。"}}
{"id": "2507.13417", "title": "Soft-ECM: An extension of Evidential C-Means for complex data", "authors": ["Armel Soubeiga", "Thomas Guyet", "Violaine Antoine"], "categories": ["cs.LG", "cs.AI", "cs.DM"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13417v1", "summary": "Clustering based on belief functions has been gaining increasing attention in\nthe machine learning community due to its ability to effectively represent\nuncertainty and/or imprecision. However, none of the existing algorithms can be\napplied to complex data, such as mixed data (numerical and categorical) or\nnon-tabular data like time series. Indeed, these types of data are, in general,\nnot represented in a Euclidean space and the aforementioned algorithms make use\nof the properties of such spaces, in particular for the construction of\nbarycenters. In this paper, we reformulate the Evidential C-Means (ECM) problem\nfor clustering complex data. We propose a new algorithm, Soft-ECM, which\nconsistently positions the centroids of imprecise clusters requiring only a\nsemi-metric. Our experiments show that Soft-ECM present results comparable to\nconventional fuzzy clustering approaches on numerical data, and we demonstrate\nits ability to handle mixed data and its benefits when combining fuzzy\nclustering with semi-metrics such as DTW for time series data.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13417v1", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "软-ECM：一种用于复杂数据的证据C-均值扩展", "tldr": "提出Soft-ECM算法，扩展证据C-均值聚类以处理混合数据和时间序列等复杂数据，且仅需半度量。", "motivation": "现有的基于信念函数的聚类算法无法应用于混合数据（数值和类别）或时间序列等非表格复杂数据，因为这些数据通常不表示在欧几里得空间中，而现有算法依赖欧几里得空间特性来构建重心。", "method": "本文重新定义了证据C-均值（ECM）问题以适应复杂数据聚类，并提出了一种新算法Soft-ECM。该算法仅需要半度量即可一致地定位不精确簇的质心。", "result": "实验结果表明，Soft-ECM在数值数据上表现出与传统模糊聚类方法相当的性能，并成功处理了混合数据。同时，它在将模糊聚类与时间序列数据中的DTW等半度量结合时也显示出优势。", "conclusion": "Soft-ECM算法成功地将证据C-均值聚类扩展到能够处理各种复杂数据类型，克服了现有算法在非欧几里得空间中处理复杂数据的局限性。", "translation": "基于信念函数的聚类因其能有效表示不确定性和/或不精确性，在机器学习领域受到越来越多的关注。然而，现有算法都无法应用于复杂数据，例如混合数据（数值和类别）或时间序列等非表格数据。事实上，这些类型的数据通常不表示在欧几里得空间中，而上述算法利用了这种空间的特性，特别是用于构建重心。在本文中，我们重新 формулировали 证据C-均值（ECM）问题，用于复杂数据聚类。我们提出了一种新算法Soft-ECM，它能一致地定位不精确簇的质心，且仅需要半度量。我们的实验表明，Soft-ECM在数值数据上表现出与传统模糊聚类方法相当的结果，并且我们证明了它处理混合数据的能力以及在将模糊聚类与时间序列数据中的DTW等半度量结合时的优势。", "summary": "本文提出Soft-ECM算法，旨在解决现有基于信念函数的聚类算法无法处理复杂数据（如混合数据和时间序列）的问题。通过重新定义证据C-均值（ECM）问题并引入仅需半度量的质心定位方法，Soft-ECM展现出在数值数据上与传统方法相当的性能，并成功处理混合数据及时间序列数据，有效扩展了聚类算法的应用范围。", "keywords": "证据C-均值, 复杂数据, 聚类, 半度量, Soft-ECM", "comments": "Soft-ECM的创新点在于将证据C-均值聚类扩展到非欧几里得空间中的复杂数据，通过引入半度量克服了现有算法的局限性。这对于处理真实世界中常见的混合和非结构化数据具有重要意义。"}}
{"id": "2507.13718", "title": "Bi-GRU Based Deception Detection using EEG Signals", "authors": ["Danilo Avola", "Muhammad Yasir Bilal", "Emad Emam", "Cristina Lakasz", "Daniele Pannone", "Amedeo Ranaldi"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13718v1", "summary": "Deception detection is a significant challenge in fields such as security,\npsychology, and forensics. This study presents a deep learning approach for\nclassifying deceptive and truthful behavior using ElectroEncephaloGram (EEG)\nsignals from the Bag-of-Lies dataset, a multimodal corpus designed for\nnaturalistic, casual deception scenarios. A Bidirectional Gated Recurrent Unit\n(Bi-GRU) neural network was trained to perform binary classification of EEG\nsamples. The model achieved a test accuracy of 97\\%, along with high precision,\nrecall, and F1-scores across both classes. These results demonstrate the\neffectiveness of using bidirectional temporal modeling for EEG-based deception\ndetection and suggest potential for real-time applications and future\nexploration of advanced neural architectures.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13718v1", "cate": "cs.LG", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于Bi-GRU的脑电信号欺骗检测", "tldr": "本研究提出了一种使用Bi-GRU深度学习模型对脑电信号进行欺骗检测的方法，在Bag-of-Lies数据集上实现了97%的测试准确率。", "motivation": "欺骗检测在安全、心理学和法医学等领域是一个重大挑战。", "method": "本研究使用双向门控循环单元（Bi-GRU）神经网络，利用Bag-of-Lies数据集中的脑电图（EEG）信号对欺骗和真实行为进行二元分类。", "result": "该模型实现了97%的测试准确率，并且在两个类别上都取得了高精度、高召回率和高F1分数。", "conclusion": "这些结果证明了使用双向时间建模进行基于脑电图的欺骗检测的有效性，并预示着实时应用和未来探索高级神经架构的潜力。", "translation": "欺骗检测是安全、心理学和法医学等领域的一个重大挑战。本研究提出了一种深度学习方法，利用Bag-of-Lies数据集（一个为自然、随意欺骗场景设计的多种模式语料库）中的脑电图（EEG）信号对欺骗和真实行为进行分类。训练了一个双向门控循环单元（Bi-GRU）神经网络来对脑电样本进行二元分类。该模型实现了97%的测试准确率，并且在两个类别上都取得了高精度、高召回率和高F1分数。这些结果证明了使用双向时间建模进行基于脑电图的欺骗检测的有效性，并预示着实时应用和未来探索高级神经架构的潜力。", "summary": "本研究提出了一种基于深度学习的欺骗检测方法，利用双向门控循环单元（Bi-GRU）神经网络分析来自Bag-of-Lies数据集的脑电图（EEG）信号。该模型成功地对欺骗和真实行为进行了二元分类，实现了97%的测试准确率，并表现出高精度、召回率和F1分数，这表明了Bi-GRU在EEG欺骗检测中的有效性及其在未来实时应用和高级架构探索中的潜力。", "keywords": "欺骗检测, 脑电信号, Bi-GRU, 深度学习, 二元分类", "comments": "该研究的创新之处在于将Bi-GRU模型应用于EEG信号进行欺骗检测，并取得了显著的高准确率。这为实时欺骗检测系统提供了新的思路，并强调了双向时间建模在处理生理信号方面的潜力。然而，局限性可能在于数据集的特异性（自然、随意欺骗场景），其泛化能力可能需要进一步验证。"}}
{"id": "2507.13384", "title": "Flatten Wisely: How Patch Order Shapes Mamba-Powered Vision for MRI Segmentation", "authors": ["Osama Hardan", "Omar Elshenhabi", "Tamer Khattab", "Mohamed Mabrok"], "categories": ["eess.IV", "cs.CV", "cs.LG"], "primary_category": "Subjects:       Image and Video Processing (eess.IV)", "pdf_link": null, "comments": "Comments:      Submitted to the 2025 IEEE International Conference on Future Machine Learning and Data Science (FMLDS)", "url": "http://arxiv.org/abs/2507.13384v1", "summary": "Vision Mamba models promise transformer-level performance at linear\ncomputational cost, but their reliance on serializing 2D images into 1D\nsequences introduces a critical, yet overlooked, design choice: the patch scan\norder. In medical imaging, where modalities like brain MRI contain strong\nanatomical priors, this choice is non-trivial. This paper presents the first\nsystematic study of how scan order impacts MRI segmentation. We introduce\nMulti-Scan 2D (MS2D), a parameter-free module for Mamba-based architectures\nthat facilitates exploring diverse scan paths without additional computational\ncost. We conduct a large-scale benchmark of 21 scan strategies on three public\ndatasets (BraTS 2020, ISLES 2022, LGG), covering over 70,000 slices. Our\nanalysis shows conclusively that scan order is a statistically significant\nfactor (Friedman test: $\\chi^{2}_{20}=43.9, p=0.0016$), with performance\nvarying by as much as 27 Dice points. Spatially contiguous paths -- simple\nhorizontal and vertical rasters -- consistently outperform disjointed diagonal\nscans. We conclude that scan order is a powerful, cost-free hyperparameter, and\nprovide an evidence-based shortlist of optimal paths to maximize the\nperformance of Mamba models in medical imaging.", "comment": "Submitted to the 2025 IEEE International Conference on Future Machine\n  Learning and Data Science (FMLDS)", "pdf_url": "http://arxiv.org/pdf/2507.13384v1", "cate": "eess.IV", "date": "2025-07-15", "updated": "2025-07-15", "AI": {"title_translation": "明智展平：补丁顺序如何影响Mamba驱动的MRI分割视觉", "tldr": "Mamba模型中图像补丁的扫描顺序对MRI分割性能有显著影响，空间连续路径优于非连续路径，是一个重要的无成本超参数。", "motivation": "Vision Mamba模型在将2D图像序列化为1D序列时，补丁扫描顺序是一个关键但被忽视的设计选择，尤其是在具有强解剖先验的医学图像（如脑MRI）中，该选择并非微不足道。", "method": "本文引入了Multi-Scan 2D (MS2D)模块，一个Mamba架构的无参数模块，用于探索不同的扫描路径，不增加计算成本。研究在三个公共数据集（BraTS 2020, ISLES 2022, LGG）上对21种扫描策略进行了大规模基准测试，覆盖超过70,000个切片。", "result": "扫描顺序是一个统计学上显著的因素（Friedman检验：$\\\\chi^{2}_{20}=43.9, p=0.0016$），性能差异高达27个Dice点。空间连续路径（简单的水平和垂直光栅扫描）始终优于不连续的对角线扫描。", "conclusion": "扫描顺序是一个强大且无成本的超参数。研究提供了一个基于证据的最佳路径列表，以最大化Mamba模型在医学图像中的性能。", "translation": "Vision Mamba模型有望以线性计算成本实现Transformer级别的性能，但它们依赖于将2D图像序列化为1D序列，这引入了一个关键但被忽视的设计选择：补丁扫描顺序。在医学成像中，像脑MRI这样的模态包含强大的解剖先验，这种选择并非微不足道。本文首次系统研究了扫描顺序如何影响MRI分割。我们引入了Multi-Scan 2D（MS2D），一个用于基于Mamba架构的无参数模块，它有助于探索多样化的扫描路径而无需额外的计算成本。我们对三个公共数据集（BraTS 2020、ISLES 2022、LGG）上的21种扫描策略进行了大规模基准测试，覆盖了70,000多个切片。我们的分析明确表明，扫描顺序是一个统计学上显著的因素（Friedman检验：$\\\\chi^{2}_{20}=43.9, p=0.0016$），性能差异高达27个Dice点。空间连续路径——简单的水平和垂直光栅扫描——始终优于不连续的对角线扫描。我们得出结论，扫描顺序是一个强大、无成本的超参数，并提供了一个基于证据的最佳路径简短列表，以最大化Mamba模型在医学成像中的性能。", "summary": "该论文系统地研究了Mamba模型中2D图像补丁的1D序列化顺序对MRI分割性能的影响。研究引入了无参数的Multi-Scan 2D (MS2D)模块，并在三个医学图像数据集上对21种扫描策略进行了大规模基准测试。结果表明，扫描顺序是一个统计学上显著的超参数，性能差异可达27个Dice点，其中空间连续的水平和垂直扫描路径表现最佳。文章强调了扫描顺序作为Mamba模型在医学成像中一个强大且无成本的性能优化因素。", "keywords": "Mamba模型, MRI分割, 补丁扫描顺序, 医学图像, MS2D", "comments": "本文揭示了Mamba模型在医学图像分割中一个此前被忽视但至关重要的超参数——补丁扫描顺序。其创新之处在于首次系统性地研究了这一因素，并引入了MS2D模块，允许无成本地探索不同扫描路径。研究结果具有重要意义，为Mamba模型在医学图像领域的应用提供了宝贵的性能优化策略，特别是识别出最佳的扫描路径，这对于提高模型效率和准确性至关重要。"}}
{"id": "2507.14095", "title": "C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs", "authors": ["Yung-Hong Sun", "Ting-Hung Lin", "Jiangang Chen", "Hongrui Jiang", "Yu Hen Hu"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.14095v1", "summary": "Multi-view multi-object association is a fundamental step in 3D\nreconstruction pipelines, enabling consistent grouping of object instances\nacross multiple camera views. Existing methods often rely on appearance\nfeatures or geometric constraints such as epipolar consistency. However, these\napproaches can fail when objects are visually indistinguishable or observations\nare corrupted by noise. We propose C-DOG, a training-free framework that serves\nas an intermediate module bridging object detection (or pose estimation) and 3D\nreconstruction, without relying on visual features. It combines connected\ndelta-overlap graph modeling with epipolar geometry to robustly associate\ndetections across views. Each 2D observation is represented as a graph node,\nwith edges weighted by epipolar consistency. A delta-neighbor-overlap\nclustering step identifies strongly consistent groups while tolerating noise\nand partial connectivity. To further improve robustness, we incorporate\nInterquartile Range (IQR)-based filtering and a 3D back-projection error\ncriterion to eliminate inconsistent observations. Extensive experiments on\nsynthetic benchmarks demonstrate that C-DOG outperforms geometry-based\nbaselines and remains robust under challenging conditions, including high\nobject density, without visual features, and limited camera overlap, making it\nwell-suited for scalable 3D reconstruction in real-world scenarios.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.14095v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "C-DOG：通过连接δ-重叠图在密集场景中实现无视觉特征的免训练多视图多目标关联", "tldr": "C-DOG是一个无需训练的框架，它结合连接δ-重叠图建模和对极几何，在没有视觉特征的情况下，鲁棒地关联多视图中的目标检测，在密集场景和挑战性条件下表现出色。", "motivation": "现有方法（依赖外观特征或对极几何）在对象视觉上无法区分或观测受噪声污染时会失效。", "method": "C-DOG结合了连接δ-重叠图建模和对极几何。每个2D观测表示为图节点，边权重为对极一致性。通过delta-邻居-重叠聚类识别强一致性组。还结合了基于四分位距（IQR）的过滤和3D反投影误差准则以消除不一致观测。", "result": "在合成基准测试中，C-DOG优于基于几何的基线，并在高物体密度、无视觉特征和有限相机重叠等挑战条件下保持鲁棒性。", "conclusion": "C-DOG非常适合在真实世界场景中进行可扩展的3D重建。", "translation": "多视图多目标关联是3D重建管线中的一个基本步骤，它能够跨多个相机视图对对象实例进行一致分组。现有方法通常依赖外观特征或几何约束（如对极一致性）。然而，当对象在视觉上无法区分或观测受到噪声污染时，这些方法可能会失效。我们提出了C-DOG，一个免训练框架，它作为连接对象检测（或姿态估计）和3D重建的中间模块，不依赖视觉特征。它结合了连接δ-重叠图建模和对极几何，以鲁棒地关联跨视图的检测。每个2D观测被表示为一个图节点，边权重由对极一致性决定。一个delta-邻居-重叠聚类步骤可以识别强一致性组，同时容忍噪声和部分连接。为了进一步提高鲁棒性，我们结合了基于四分位距（IQR）的过滤和3D反投影误差准则来消除不一致的观测。在合成基准上的大量实验表明，C-DOG优于基于几何的基线，并在具有高物体密度、无视觉特征和有限相机重叠等挑战条件下保持鲁棒性，使其非常适合真实世界场景中的可扩展3D重建。", "summary": "本文提出了C-DOG，一个无需训练的多视图多目标关联框架。它通过结合连接δ-重叠图建模和对极几何来解决现有方法在视觉特征不可区分或观测受噪声影响时失效的问题。C-DOG将2D观测表示为图节点，并利用delta-邻居-重叠聚类、IQR过滤和3D反投影误差来确保鲁棒性。实验证明，C-DOG在密集场景和挑战性条件下（无视觉特征、有限相机重叠）表现优异，适用于可扩展的3D重建。", "keywords": "多视图关联, 3D重建, 无训练, 对极几何, 图建模", "comments": "C-DOG的创新之处在于其无需训练的特性，以及在不依赖视觉特征的情况下实现多视图多目标关联。它通过结合图建模和对极几何，并在处理噪声和不一致性方面表现出色，为3D重建提供了一个鲁棒且可扩展的中间模块。其在密集和挑战性场景下的鲁棒性是其重要优势。"}}
{"id": "2310.15457", "title": "An Iteratively Decoupled Algorithm for Multiple-Network Poroelastic Model with Applications in Brain Edema Simulations", "authors": ["Mingchao Cai", "Meng Lei", "Jingzhi Li", "Jiaao Sun", "Feng Wang"], "categories": ["math.NA", "cs.NA"], "primary_category": "Subjects:       Numerical Analysis (math.NA)", "pdf_link": null, "comments": "Comments:      to be submitted, replacing the older version", "url": "http://arxiv.org/abs/2310.15457v4", "summary": "In this work, we present an iteratively decoupled algorithm for solving the\nquasi-static multiple-network poroelastic model. Our approach employs a\ntotal-pressure-based formulation with solid displacement, total pressure, and\nnetwork pressures as primary unknowns. This reformulation decomposes the\noriginal problem into a generalized Stokes problem and a parabolic problem,\noffering key advantages such as reduced elastic locking effects and simplified\ndiscretization. The algorithm guarantees unconditional convergence to the\nsolution of the fully coupled system. Numerical experiments demonstrate the\naccuracy, efficiency, and robustness of the method with respect to physical\nparameters and discretization. We further apply the algorithm to simulate the\nbrain edema process, showcasing its practical utility in biomechanical\nmodeling.", "comment": "to be submitted, replacing the older version", "pdf_url": "http://arxiv.org/pdf/2310.15457v4", "cate": "math.NA", "date": "2023-10-24", "updated": "2025-07-18", "AI": {"title_translation": "用于多网络孔隙弹性模型的迭代解耦算法及其在脑水肿模拟中的应用", "tldr": "本文提出了一种用于解决准静态多网络孔隙弹性模型的迭代解耦算法。该算法通过将问题分解为广义斯托克斯问题和抛物线问题，提高了精度、效率和鲁棒性，并成功应用于脑水肿模拟。", "motivation": "解决准静态多网络孔隙弹性模型的问题，并将其应用于生物力学建模，特别是脑水肿过程的模拟。", "method": "提出了一种迭代解耦算法，用于求解准静态多网络孔隙弹性模型。该方法采用基于总压力的公式，将固体位移、总压力和网络压力作为主要未知量。这种重新表述将原始问题分解为广义斯托克斯问题和抛物线问题，从而减少了弹性锁定效应并简化了离散化。该算法保证了对完全耦合系统解的无条件收敛。", "result": "数值实验证明了该方法在物理参数和离散化方面的准确性、效率和鲁棒性。该算法还成功应用于脑水肿过程的模拟，展示了其在生物力学建模中的实用性。", "conclusion": "本文提出的迭代解耦算法能够准确、高效、鲁棒地求解准静态多网络孔隙弹性模型，并成功应用于脑水肿模拟，证明了其在生物力学建模中的实用性。", "translation": "在这项工作中，我们提出了一种用于求解准静态多网络孔隙弹性模型的迭代解耦算法。我们的方法采用基于总压力的公式，以固体位移、总压力和网络压力作为主要未知量。这种重新表述将原始问题分解为广义斯托克斯问题和抛物线问题，提供了减少弹性锁定效应和简化离散化等关键优势。该算法保证了对完全耦合系统解的无条件收敛。数值实验证明了该方法在物理参数和离散化方面的准确性、效率和鲁棒性。我们进一步将该算法应用于脑水肿过程的模拟，展示了其在生物力学建模中的实际效用。", "summary": "本文提出了一种新颖的迭代解耦算法，用于解决准静态多网络孔隙弹性模型。该算法采用基于总压力的公式，并将原始问题分解为广义斯托克斯问题和抛物线问题，从而有效减少了弹性锁定并简化了离散化。该方法已被证明能够无条件收敛，并在数值实验中展现出优异的准确性、效率和鲁棒性。此外，该算法成功应用于脑水肿模拟，突显了其在生物力学建模领域的实际应用价值。", "keywords": "孔隙弹性模型, 迭代解耦算法, 脑水肿, 生物力学建模, 总压力公式", "comments": "这项工作的创新之处在于提出了一种迭代解耦算法，通过问题分解和基于总压力的公式，有效解决了多网络孔隙弹性模型的复杂性。其优势在于减少了弹性锁定效应和简化了离散化，同时保证了无条件收敛。该方法在生物力学建模，特别是脑水肿模拟中的应用，展示了其重要的实用价值。"}}
{"id": "2507.13795", "title": "Regression-Based Approach to Anxiety Estimation of Spider Phobics During Behavioural Avoidance Tasks", "authors": ["Florian Grensing", "Vanessa Schmücker", "Anne Sophie Hildebrand", "Tim Klucken", "Maria Maleshkova"], "categories": ["cs.HC", "I.2.6; J.3"], "primary_category": "Subjects:       Human-Computer Interaction (cs.HC)", "pdf_link": null, "comments": "Comments:      9 Pages, 4 Figures (3 consisting of 3 subfigures each)", "url": "http://arxiv.org/abs/2507.13795v1", "summary": "Phobias significantly impact the quality of life of affected persons. Two\nmethods of assessing anxiety responses are questionnaires and behavioural\navoidance tests (BAT). While these can be used in a clinical environment they\nonly record momentary insights into anxiety measures. In this study, we\nestimate the intensity of anxiety during these BATs, using physiological data\ncollected from unobtrusive, wrist-worn sensors. Twenty-five participants\nperformed four different BATs in a single session, while periodically being\nasked how anxious they currently are. Using heart rate, heart rate variability,\nelectrodermal activity, and skin temperature, we trained regression models to\npredict anxiety ratings from three types of input data: (1) using only\nphysiological signals, (2) adding computed features (e.g., min, max, range,\nvariability), and (3) computed features combined with contextual task\ninformation. Adding contextual information increased the effectiveness of the\nmodel, leading to a root mean squared error (RMSE) of 0.197 and a mean absolute\nerror (MAE) of 0.041. Overall, this study shows, that data obtained from\nwearables can continuously provide meaningful estimations of anxiety, which can\nassist in therapy planning and enable more personalised treatment.", "comment": "9 Pages, 4 Figures (3 consisting of 3 subfigures each)", "pdf_url": "http://arxiv.org/pdf/2507.13795v1", "cate": "cs.HC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于回归的蜘蛛恐惧症患者行为回避任务期间焦虑估计方法", "tldr": "本研究利用可穿戴传感器收集的生理数据，训练回归模型来连续估计蜘蛛恐惧症患者在行为回避任务中的焦虑水平，并发现加入情境信息能提高模型效果。", "motivation": "现有的焦虑评估方法（问卷和行为回避测试）只能记录瞬时焦虑测量结果，无法提供连续的焦虑估计，而恐惧症严重影响患者生活质量，因此需要一种能连续评估焦虑的方法。", "method": "研究招募了25名参与者，让他们在一次会话中完成四种不同的行为回避任务，同时佩戴腕戴式传感器收集生理数据（心率、心率变异性、皮电活动、皮肤温度），并周期性询问焦虑程度。研究人员利用这些数据训练回归模型来预测焦虑评分，模型输入数据分为三类：1) 仅生理信号，2) 添加计算特征（如最小值、最大值、范围、变异性），3) 计算特征结合情境任务信息。", "result": "添加情境信息显著提高了模型的有效性，导致均方根误差（RMSE）为0.197，平均绝对误差（MAE）为0.041。研究表明，从可穿戴设备获得的数据可以连续提供有意义的焦虑估计。", "conclusion": "可穿戴设备收集的数据可以持续提供有意义的焦虑估计，这有助于治疗规划并实现更个性化的治疗。", "translation": "恐惧症严重影响受影响者的生活质量。评估焦虑反应的两种方法是问卷调查和行为回避测试（BAT）。虽然这些方法可以在临床环境中使用，但它们只能记录对焦虑测量的瞬时洞察。在这项研究中，我们利用从不显眼的腕戴式传感器收集的生理数据，估计这些BAT期间的焦虑强度。二十五名参与者在一次会话中完成了四种不同的BAT，同时被周期性地询问他们当前的焦虑程度。我们使用心率、心率变异性、皮电活动和皮肤温度，训练回归模型来预测三种类型输入数据的焦虑评分：(1) 仅使用生理信号，(2) 添加计算特征（例如，最小值、最大值、范围、变异性），以及 (3) 计算特征结合情境任务信息。添加情境信息增加了模型的有效性，导致均方根误差（RMSE）为0.197，平均绝对误差（MAE）为0.041。总的来说，这项研究表明，从可穿戴设备获得的数据可以持续提供有意义的焦虑估计，这有助于治疗规划并实现更个性化的治疗。", "summary": "本研究提出了一种基于回归的方法，利用腕戴式传感器收集的生理数据，连续估计蜘蛛恐惧症患者在行为回避任务中的焦虑强度。通过对心率、心率变异性、皮电活动和皮肤温度等生理信号进行建模，并结合计算特征和情境任务信息，研究成功训练了能预测焦虑评分的回归模型。结果显示，加入情境信息显著提高了模型的预测准确性（RMSE 0.197，MAE 0.041）。该研究证明可穿戴设备数据能持续提供有价值的焦虑估计，有望辅助治疗规划并实现个性化治疗。", "keywords": "焦虑估计, 蜘蛛恐惧症, 可穿戴设备, 生理数据, 回归模型", "comments": "该研究的创新之处在于利用非侵入式可穿戴设备实现焦虑的连续、客观测量，而非依赖主观瞬时评估。其重要性在于为恐惧症治疗提供了新的监测和评估工具，有望实现更精细化、个性化的干预。结合情境信息提升模型性能的发现也很有价值。"}}
{"id": "2505.22987", "title": "Strategic Reflectivism In Intelligent Systems", "authors": ["Nick Byrd"], "categories": ["cs.AI", "cs.HC", "econ.TH", "C.1.3; I.2.0; I.2.8; I.2.11"], "primary_category": "Subjects:       Artificial Intelligence (cs.AI)", "pdf_link": null, "comments": "Comments:      Accepted for publication in the proceedings of the 4th International conference on Human and Artificial Rationality, which are to appear in Lecture Notes in Computer Science. An earlier version was presented at the 2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning (CHI25-WS-AUGMENTED-REASONING)", "url": "http://arxiv.org/abs/2505.22987v2", "summary": "By late 20th century, the rationality wars had launched debates about the\nnature and norms of intuitive and reflective thinking. Those debates drew from\nmid-20th century ideas such as bounded rationality, which challenged more\nidealized notions of rationality observed since the 19th century. Now that 21st\ncentury cognitive scientists are applying the resulting dual pro-cess theories\nto artificial intelligence, it is time to dust off some lessons from this\nhistory. So this paper synthesizes old ideas with recent results from\nexperiments on humans and machines. The result is Strategic Reflec-tivism, the\nposition that one key to intelligent systems (human or artificial) is pragmatic\nswitching between intuitive and reflective inference to opti-mally fulfill\ncompeting goals. Strategic Reflectivism builds on American Pragmatism,\ntranscends superficial indicators of reflective thinking such as model size or\nchains of thought, applies to both individual and collective intelligence\nsystems (including human-AI teams), and becomes increasingly actionable as we\nlearn more about the value of intuition and reflection.", "comment": "Accepted for publication in the proceedings of the 4th International\n  conference on Human and Artificial Rationality, which are to appear in\n  Lecture Notes in Computer Science. An earlier version was presented at the\n  2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning\n  (CHI25-WS-AUGMENTED-REASONING)", "pdf_url": "http://arxiv.org/pdf/2505.22987v2", "cate": "cs.AI", "date": "2025-05-29", "updated": "2025-07-17", "AI": {"title_translation": "智能系统中的战略反思主义", "tldr": "提出“战略反思主义”，认为智能系统应在直觉和反思之间进行实用切换以实现目标，超越了模型大小等表面指标。", "motivation": "鉴于21世纪认知科学家将双过程理论应用于人工智能，本文旨在回顾并结合历史教训，以更好地理解智能系统中的直觉与反思。", "method": "本文综合了关于直觉和反思的旧思想与近期针对人类和机器的实验结果。", "result": "提出了“战略反思主义”这一立场，认为智能系统（无论是人类还是人工）的关键在于在直觉和反思推理之间进行实用切换，以最佳地实现竞争目标。", "conclusion": "战略反思主义建立在美国实用主义之上，超越了模型大小或思维链等反思性思维的表面指标，适用于个体和集体智能系统（包括人机团队），并且随着我们对直觉和反思价值的深入了解，其可操作性将越来越强。", "translation": "到20世纪末，“理性战争”引发了关于直觉和反思性思维的本质和规范的辩论。这些辩论借鉴了20世纪中期的思想，如有限理性，它挑战了自19世纪以来观察到的更理想化的理性概念。现在，21世纪的认知科学家正在将由此产生的双过程理论应用于人工智能，是时候回顾这段历史中的一些经验教训了。因此，本文综合了旧思想与近期针对人类和机器的实验结果。其成果是“战略反思主义”，即一种观点，认为智能系统（人类或人工）的关键在于在直觉和反思推理之间进行实用切换，以最佳地实现竞争目标。战略反思主义建立在美国实用主义之上，超越了模型大小或思维链等反思性思维的表面指标，适用于个体和集体智能系统（包括人机团队），并且随着我们对直觉和反思价值的深入了解，其可操作性将越来越强。", "summary": "本文回顾了关于直觉和反思性思维的“理性战争”历史，并结合当代AI发展，提出了“战略反思主义”。该理论认为，智能系统（包括人类和AI）应根据竞争目标，在直觉和反思推理之间进行灵活的实用切换。它根植于美国实用主义，并适用于个体及人机协作等多种智能系统，强调了超越表面指标的重要性。", "keywords": "战略反思主义, 直觉, 反思, 智能系统, 双过程理论", "comments": "本文的创新之处在于将认知科学中关于直觉与反思的“双过程理论”和历史辩论，引入到当前的人工智能系统设计中，并提出了“战略反思主义”这一新颖的概念框架。其重要性在于强调了智能系统应具备灵活的、情境化的推理能力，而非简单追求单一的“反思”深度（如模型大小），这对于开发更鲁棒、更适应性强的人工智能具有指导意义。它还考虑了人机协作的场景。"}}
{"id": "2507.13942", "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion", "authors": ["Jacob C Walker", "Pedro Vélez", "Luisa Polania Cabrera", "Guangyao Zhou", "Rishabh Kabra", "Carl Doersch", "Maks Ovsjanikov", "João Carreira", "Shiry Ginosar"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13942v1", "summary": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13942v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "冻结视频模型通过潜在扩散实现的通用预测", "tldr": "本文提出一种使用冻结视频模型和潜在扩散模型进行通用预测的新框架，发现视觉模型的感知能力与预测性能强相关，并强调表示学习和生成模型结合的价值。", "motivation": "预测未来事件对于能够在不同抽象层次上规划或行动的通用系统来说是一项关键技能。本文旨在探索视觉模型感知能力与通用预测性能之间的关系，并开发一个能利用现有视觉模型进行通用预测的框架。", "method": "本文提出了一种新颖的通用预测框架，该框架可以在任何冻结的视觉骨干网络上运行。具体方法是训练潜在扩散模型来预测冻结表示空间中的未来特征，然后通过轻量级的、特定任务的读出器进行解码。为了在不同任务间进行一致评估，引入了直接在下游任务空间中比较分布特性的分布度量，并将此框架应用于九个模型和四个任务。", "result": "研究发现，视觉模型的感知能力与其在短时间范围内的通用预测性能之间存在很强的相关性，并且这种趋势适用于各种预训练模型（包括生成式模型）以及从原始像素到深度、点轨迹和物体运动等多个抽象层次。", "conclusion": "结果强调了将表示学习和生成建模相结合对于基于时间视频理解的价值。", "translation": "预测接下来会发生什么，对于在不同抽象层面上规划或行动的通用系统来说是一项关键技能。在本文中，我们发现视觉模型的感知能力与其在短时间范围内的通用预测性能之间存在很强的相关性。这一趋势在各种预训练模型（包括那些生成式训练的模型）以及从原始像素到深度、点轨迹和物体运动等多个抽象层次上都成立。这一结果得益于一种新颖的通用预测框架，该框架可以在任何冻结的视觉骨干网络上运行：我们训练潜在扩散模型来预测冻结表示空间中的未来特征，然后通过轻量级的、特定任务的读出器进行解码。为了在任务之间实现一致的评估，我们引入了直接在下游任务空间中比较分布特性的分布度量，并将此框架应用于九个模型和四个任务。我们的结果突出了将表示学习和生成建模相结合对于基于时间视频理解的价值。", "summary": "本文提出一种基于冻结视频模型和潜在扩散的通用预测框架。研究发现，视觉模型的感知能力与短时预测性能高度相关，且此相关性适用于不同预训练模型和抽象层级。该框架通过训练潜在扩散模型预测冻结表示空间中的未来特征，并使用轻量级解码器输出。为评估，引入了新的分布度量。结果表明，结合表示学习和生成建模对视频理解具有重要价值。", "keywords": "通用预测, 冻结视频模型, 潜在扩散, 视频理解, 表示学习", "comments": "这篇论文的创新点在于提出了一个通用的预测框架，它能够利用任何冻结的视觉骨干网络进行未来事件预测，并通过潜在扩散模型在特征空间进行预测，这大大提高了模型的通用性和效率。同时，引入新的分布度量也为跨任务评估提供了更一致的标准。其重要性在于揭示了视觉模型感知能力与预测性能的强相关性，并为视频理解领域开辟了新的研究方向，即结合表示学习和生成建模。"}}
{"id": "2503.16700", "title": "Deep Q-Learning with Gradient Target Tracking", "authors": ["Bum Geun Park", "Taeho Lee", "Donghwan Lee"], "categories": ["cs.LG", "cs.SY", "eess.SY"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2503.16700v3", "summary": "This paper introduces Q-learning with gradient target tracking, a novel\nreinforcement learning framework that provides a learned continuous target\nupdate mechanism as an alternative to the conventional hard update paradigm. In\nthe standard deep Q-network (DQN), the target network is a copy of the online\nnetwork's weights, held fixed for a number of iterations before being\nperiodically replaced via a hard update. While this stabilizes training by\nproviding consistent targets, it introduces a new challenge: the hard update\nperiod must be carefully tuned to achieve optimal performance. To address this\nissue, we propose two gradient-based target update methods: DQN with asymmetric\ngradient target tracking (AGT2-DQN) and DQN with symmetric gradient target\ntracking (SGT2-DQN). These methods replace the conventional hard target updates\nwith continuous and structured updates using gradient descent, which\neffectively eliminates the need for manual tuning. We provide a theoretical\nanalysis proving the convergence of these methods in tabular settings.\nAdditionally, empirical evaluations demonstrate their advantages over standard\nDQN baselines, which suggest that gradient-based target updates can serve as an\neffective alternative to conventional target update mechanisms in Q-learning.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2503.16700v3", "cate": "cs.LG", "date": "2025-03-20", "updated": "2025-07-18", "AI": {"title_translation": "基于梯度目标跟踪的深度Q学习", "tldr": "本文提出了一种新的深度Q学习框架，通过梯度目标跟踪实现连续的目标网络更新，以替代传统的硬更新机制，从而消除了对硬更新周期的人工调优需求。", "motivation": "标准的深度Q网络（DQN）中的目标网络采用硬更新机制，需要仔细调优更新周期以实现最佳性能，这增加了超参数调优的复杂性。", "method": "本文提出了两种基于梯度的目标更新方法：DQN非对称梯度目标跟踪（AGT2-DQN）和DQN对称梯度目标跟踪（SGT2-DQN）。这些方法使用梯度下降进行连续和结构化的更新，替代了传统的硬目标更新。", "result": "理论分析证明了这些方法在表格设置中的收敛性。实证评估表明，它们比标准DQN基线具有优势。", "conclusion": "基于梯度的目标更新可以作为Q学习中传统目标更新机制的有效替代方案。", "translation": "本文介绍了基于梯度目标跟踪的Q学习，这是一种新颖的强化学习框架，提供了一种学习到的连续目标更新机制，作为传统硬更新范式的替代方案。在标准深度Q网络（DQN）中，目标网络是在线网络权重的副本，在一定数量的迭代中保持固定，然后通过硬更新周期性地替换。虽然这通过提供一致的目标来稳定训练，但它引入了一个新的挑战：必须仔细调整硬更新周期才能实现最佳性能。为了解决这个问题，我们提出了两种基于梯度的目标更新方法：DQN非对称梯度目标跟踪（AGT2-DQN）和DQN对称梯度目标跟踪（SGT2-DQN）。这些方法用使用梯度下降的连续和结构化更新取代了传统的硬目标更新，有效消除了手动调优的需要。我们提供了理论分析，证明了这些方法在表格设置中的收敛性。此外，实证评估表明它们比标准DQN基线具有优势，这表明基于梯度的目标更新可以作为Q学习中传统目标更新机制的有效替代方案。", "summary": "本文提出了一种名为Q学习梯度目标跟踪的新型强化学习框架，旨在解决传统深度Q网络（DQN）中目标网络硬更新机制需要手动调优的问题。该框架引入了两种基于梯度的连续目标更新方法：AGT2-DQN和SGT2-DQN。这些方法通过梯度下降实现目标网络的持续更新，从而无需人工设置更新周期。研究证明了这些方法在理论上的收敛性，并通过实验验证了其优于标准DQN基线的性能。", "keywords": "深度Q学习, 梯度目标跟踪, 强化学习, 目标网络, 硬更新", "comments": "这篇论文的创新点在于提出了一个全新的、连续的梯度目标跟踪机制来替代DQN中传统的硬目标网络更新。其重要性在于解决了DQN训练中一个关键的超参数调优难题，即硬更新周期的选择。通过将离散的硬更新转化为连续的、学习到的梯度更新，不仅简化了模型调优过程，还可能带来更稳定的训练和更好的性能。理论分析和实证结果支持了其有效性，为Q学习的稳定性与效率提升提供了新思路。"}}
{"id": "2507.13263", "title": "Merge Kernel for Bayesian Optimization on Permutation Space", "authors": ["Zikai Xie", "Linjiang Chen"], "categories": ["cs.LG", "cs.AI"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      8 pages, submitted to AAAI-26", "url": "http://arxiv.org/abs/2507.13263v2", "summary": "Bayesian Optimization (BO) algorithm is a standard tool for black-box\noptimization problems. The current state-of-the-art BO approach for permutation\nspaces relies on the Mallows kernel-an $\\Omega(n^2)$ representation that\nexplicitly enumerates every pairwise comparison. Inspired by the close\nrelationship between the Mallows kernel and pairwise comparison, we propose a\nnovel framework for generating kernel functions on permutation space based on\nsorting algorithms. Within this framework, the Mallows kernel can be viewed as\na special instance derived from bubble sort. Further, we introduce the\n\\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic\ncomplexity with $\\Theta(n\\log n)$ to achieve the lowest possible complexity.\nThe resulting feature vector is significantly shorter, can be computed in\nlinearithmic time, yet still efficiently captures meaningful permutation\ndistances. To boost robustness and right-invariance without sacrificing\ncompactness, we further incorporate three lightweight, task-agnostic\ndescriptors: (1) a shift histogram, which aggregates absolute element\ndisplacements and supplies a global misplacement signal; (2) a split-pair line,\nwhich encodes selected long-range comparisons by aligning elements across the\ntwo halves of the whole permutation; and (3) sliding-window motifs, which\nsummarize local order patterns that influence near-neighbor objectives. Our\nempirical evaluation demonstrates that the proposed kernel consistently\noutperforms the state-of-the-art Mallows kernel across various permutation\noptimization benchmarks. Results confirm that the Merge Kernel provides a more\ncompact yet more effective solution for Bayesian optimization in permutation\nspace.", "comment": "8 pages, submitted to AAAI-26", "pdf_url": "http://arxiv.org/pdf/2507.13263v2", "cate": "cs.LG", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "用于置换空间贝叶斯优化的合并核", "tldr": "本文提出了用于置换空间贝叶斯优化的“合并核”，它基于归并排序，将现有Mallows核的二次复杂度降至准线性，并结合额外描述符，在实验中表现优于现有最佳方法。", "motivation": "现有的置换空间贝叶斯优化方法（基于Mallows核）表示复杂度高，为Ω(n^2)，且计算效率较低。本文旨在提出一种更高效、紧凑的核函数。", "method": "本文提出了一个基于排序算法的置换空间核函数生成框架。在此框架下，Mallows核可视为冒泡排序的特例。进一步，本文引入了基于归并排序构建的“合并核”，将复杂度从二次降低到Θ(n log n)。为提升鲁棒性和右不变性，同时保持紧凑性，合并核还融合了三个轻量级、任务无关的描述符：1) 移位直方图；2) 分对线；3) 滑动窗口模式。", "result": "经验评估表明，所提出的合并核在各种置换优化基准测试中始终优于现有最佳的Mallows核。结果证实合并核为置换空间中的贝叶斯优化提供了一个更紧凑但更有效的解决方案。", "conclusion": "合并核提供了一种更紧凑且有效的解决方案，用于置换空间中的贝叶斯优化，显著降低了计算复杂度并提高了性能。", "translation": "贝叶斯优化（BO）算法是黑盒优化问题的标准工具。当前置换空间中最先进的BO方法依赖于Mallows核——一个Ω(n^2)的表示，它明确列举了每个成对比较。受Mallows核与成对比较之间密切关系的启发，我们提出了一个基于排序算法在置换空间生成核函数的新颖框架。在这个框架内，Mallows核可以被视为冒泡排序导出的一个特殊实例。此外，我们引入了由归并排序构建的**合并核**，它将二次复杂度替换为Θ(n log n)，以实现最低的可能复杂度。由此产生的特征向量显著更短，可以在线性对数时间内计算，但仍然有效地捕获有意义的置换距离。为了在不牺牲紧凑性的情况下提高鲁棒性和右不变性，我们进一步结合了三个轻量级、任务无关的描述符：(1) 移位直方图，它聚合了绝对元素位移并提供了全局错位信号；(2) 分对线，它通过对齐整个置换的两半中的元素来编码选定的长程比较；(3) 滑动窗口模式，它总结了影响近邻目标的局部顺序模式。我们的经验评估表明，所提出的核在各种置换优化基准测试中始终优于最先进的Mallows核。结果证实合并核为置换空间中的贝叶斯优化提供了一个更紧凑但更有效的解决方案。", "summary": "本文针对置换空间中的贝叶斯优化提出了一种名为“合并核”的新型核函数。该核函数基于归并排序构建，与现有Mallows核的二次复杂度相比，实现了更优的准线性复杂度（Θ(n log n)），并能生成更短、计算更快的特征向量。为增强鲁棒性，合并核还融入了移位直方图、分对线和滑动窗口模式等描述符。实验结果表明，合并核在多个置换优化任务中均优于现有最佳的Mallows核，提供了一种更紧凑且高效的解决方案。", "keywords": "贝叶斯优化, 置换空间, 合并核, 核函数, 复杂度", "comments": "本文的创新点在于提出了一个基于排序算法的通用框架来构建置换空间上的核函数，并具体实现了基于归并排序的“合并核”。这一方法显著降低了计算复杂度，从二次降至准线性，解决了现有方法效率低下的问题。同时，引入的额外描述符增强了核函数的鲁棒性和特征捕获能力。其重要性在于为置换空间的贝叶斯优化提供了一个更高效、更实用的工具，有望推动相关领域的发展。"}}
{"id": "2507.14069", "title": "Edge Intelligence with Spiking Neural Networks", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "primary_category": "Subjects:       Distributed, Parallel, and Cluster Computing (cs.DC)", "pdf_link": null, "comments": "Comments:      This work has been submitted to Proceeding of IEEE for possible publication", "url": "http://arxiv.org/abs/2507.14069v1", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.", "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "pdf_url": "http://arxiv.org/pdf/2507.14069v1", "cate": "cs.DC", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "基于脉冲神经网络的边缘智能", "tldr": "本文对基于脉冲神经网络（SNNs）的边缘智能（EdgeSNNs）进行了首次全面综述，探讨了SNNs在资源受限边缘设备上实现智能服务的潜力，并提出了系统分类、实践考量和评估策略。", "motivation": "传统的深度学习模型在资源受限的边缘设备上部署时面临计算资源、集中数据管理、延迟、带宽消耗和隐私等关键限制。脑启发计算，特别是脉冲神经网络（SNNs），通过模拟生物神经元动力学实现低功耗、事件驱动的计算，为在边缘设备上实现智能服务提供了有前景的替代方案。", "method": "本文作为一篇综述，对基于脉冲神经网络的边缘智能（EdgeSNNs）进行了全面概述。它提出了一个EdgeSNN基础的系统分类，包括神经元模型、学习算法和支持硬件平台。文章深入讨论了EdgeSNN的三个代表性实际考量：使用轻量级SNN模型进行设备端推理、非稳态数据条件下的资源感知训练和更新、以及安全和隐私保护问题。此外，还提出了一个双轨基准测试策略，以支持公平比较和硬件感知优化。", "result": "本综述提供了EdgeSNN基础的系统分类，涵盖神经元模型、学习算法和支持硬件平台。论文深入探讨了EdgeSNN的三个实际考量：轻量级SNN模型在设备端的推理、非稳态数据下的资源感知训练与更新、以及安全和隐私保护问题。同时，提出了一种双轨基准测试策略，以支持公平比较和硬件感知优化。", "conclusion": "本研究旨在弥合脑启发学习与实际边缘部署之间的鸿沟，为当前进展、开放挑战和未来研究方向提供见解。它是首个专门且全面的EdgeSNNs综述，为神经形态计算和边缘智能领域的研究人员和从业者提供了重要参考。", "translation": "人工智能与边缘计算的融合激发了人们对直接在资源受限设备上实现智能服务的日益增长的兴趣。虽然传统的深度学习模型需要大量的计算资源和集中式数据管理，但由此产生的延迟、带宽消耗和隐私问题暴露了以云为中心的范式的关键局限性。脑启发计算，特别是脉冲神经网络（SNNs），通过模拟生物神经元动力学，提供了一种有前景的替代方案，以实现低功耗、事件驱动的计算。本综述全面概述了基于SNNs的边缘智能（EdgeSNNs），审视了它们解决边缘场景中设备端学习、推理和安全挑战的潜力。我们提出了一个EdgeSNN基础的系统分类，包括神经元模型、学习算法和支持硬件平台。深入讨论了EdgeSNN的三个代表性实际考量：使用轻量级SNN模型进行设备端推理、非稳态数据条件下的资源感知训练和更新，以及安全和隐私保护问题。此外，我们强调了在传统硬件上评估EdgeSNNs的局限性，并引入了一种双轨基准测试策略，以支持公平比较和硬件感知优化。通过这项研究，我们旨在弥合脑启发学习与实际边缘部署之间的鸿沟，为当前进展、开放挑战和未来研究方向提供见解。据我们所知，这是第一份专门针对EdgeSNNs的全面综述，为在神经形态计算和边缘智能交叉领域工作的研究人员和从业者提供了重要参考。", "summary": "本文对基于脉冲神经网络（SNNs）的边缘智能（EdgeSNNs）进行了首次全面综述。针对传统深度学习在边缘设备上存在的资源、延迟、带宽和隐私问题，SNNs作为一种低功耗、事件驱动的脑启发计算范式，展现出巨大潜力。综述系统性地分类了EdgeSNNs的基础要素，并深入讨论了设备端推理、资源感知训练与更新、以及安全隐私保护等实践考量。此外，论文还提出了一个双轨基准测试策略，旨在促进公平评估和硬件优化，以期弥合脑启发学习与实际边缘部署之间的差距，并为未来研究提供方向。", "keywords": "脉冲神经网络, 边缘智能, 神经形态计算, 资源受限设备, 综述", "comments": "这篇论文的创新之处在于它是首个专门且全面的EdgeSNNs综述，填补了该领域的空白。其重要性体现在它为在资源受限边缘设备上部署人工智能提供了一条有前景的低功耗、高效率路径，有望解决传统深度学习模型面临的诸多挑战。通过系统分类、实践考量和评估策略的提出，该综述为研究人员和从业者提供了宝贵的参考框架和未来研究方向。"}}
{"id": "2507.13420", "title": "AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery", "authors": ["Alessandro Pistola", "Valentina Orru'", "Nicolo' Marchetti", "Marco Roccetti"], "categories": ["cs.CV", "cs.AI", "cs.LG"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      25 pages, 9 Figures", "url": "http://arxiv.org/abs/2507.13420v1", "summary": "By upgrading an existing deep learning model with the knowledge provided by\none of the oldest sets of grayscale satellite imagery, known as CORONA, we\nimproved the AI model attitude towards the automatic identification of\narchaeological sites in an environment which has been completely transformed in\nthe last five decades, including the complete destruction of many of those same\nsites. The initial Bing based convolutional network model was retrained using\nCORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,\ncentral Mesopotamian floodplain. The results were twofold and surprising.\nFirst, the detection precision obtained on the area of interest increased\nsensibly: in particular, the Intersection over Union (IoU) values, at the image\nsegmentation level, surpassed 85 percent, while the general accuracy in\ndetecting archeological sites reached 90 percent. Second, our retrained model\nallowed the identification of four new sites of archaeological interest\n(confirmed through field verification), previously not identified by\narchaeologists with traditional techniques. This has confirmed the efficacy of\nusing AI techniques and the CORONA imagery from the 1960 to discover\narchaeological sites currently no longer visible, a concrete breakthrough with\nsignificant consequences for the study of landscapes with vanishing\narchaeological evidence induced by anthropization", "comment": "25 pages, 9 Figures", "pdf_url": "http://arxiv.org/pdf/2507.13420v1", "cate": "cs.CV", "date": "2025-07-17", "updated": "2025-07-17", "AI": {"title_translation": "AI逆向追踪：美索不达米亚地区消失的考古景观以及利用CORONA影像自动检测遗址", "tldr": "该研究通过升级深度学习模型并利用历史CORONA卫星图像，成功实现了对美索不达米亚地区已消失考古遗址的自动化检测，提高了检测精度并发现了新遗址。", "motivation": "美索不达米亚地区的考古景观在过去五十年中发生了彻底的改变，许多考古遗址已被完全破坏或不再可见。传统技术难以识别这些消失的遗址，因此需要新的方法来自动识别它们。", "method": "研究通过利用最古老的灰度卫星图像集——CORONA提供的知识，升级了现有的深度学习模型。一个最初基于Bing的卷积网络模型被使用CORONA卫星图像在巴格达西部阿布格莱布地区（美索不达米亚中部平原）进行了再训练。", "result": "结果是双重的：首先，检测精度显著提高，图像分割层面的交并比（IoU）值超过85%，考古遗址检测的总体准确率达到90%。其次，再训练的模型成功识别出四个新的、以前未被传统技术识别的考古遗址，并已通过实地验证确认。", "conclusion": "该研究证实了使用AI技术和1960年代的CORONA图像来发现目前已不再可见的考古遗址的有效性。这是一项重大突破，对研究因人类活动导致考古证据消失的景观具有重要意义。", "translation": "通过利用已知最古老的灰度卫星图像集（即CORONA）提供的知识升级现有深度学习模型，我们改进了AI模型在过去五十年中完全改变的环境中自动识别考古遗址的能力，包括许多相同遗址的彻底破坏。最初基于Bing的卷积网络模型使用伊拉克巴格达西部美索不达米亚中部平原阿布格莱布地区的CORONA卫星图像进行了再训练。结果是双重且令人惊讶的。首先，在感兴趣区域获得的检测精度显著提高：特别是，在图像分割层面，交并比（IoU）值超过了85%，而检测考古遗址的总体准确率达到了90%。其次，我们再训练的模型识别出了四个新的具有考古价值的遗址（经实地验证确认），这些遗址是考古学家以前通过传统技术未能识别的。这证实了使用AI技术和1960年代的CORONA图像来发现目前已不再可见的考古遗址的有效性，这是一项具有突破性的进展，对研究因人类活动导致考古证据消失的景观具有重要意义。", "summary": "本研究通过利用历史CORONA卫星图像升级深度学习模型，旨在自动化检测美索不达米亚地区已消失的考古遗址。再训练后的模型在检测精度上表现出色，图像分割IoU值超过85%，总体准确率达到90%，并成功识别出四个新的考古遗址。这证明了AI技术结合历史影像在发现当前不可见的考古证据方面的强大效用，对受人类活动影响的考古景观研究具有重要意义。", "keywords": "深度学习, CORONA图像, 考古遗址, 美索不达米亚, 自动检测", "comments": "该论文的创新之处在于将深度学习与历史卫星图像（CORONA）相结合，用于检测已消失的考古遗址，为考古学领域提供了新的视角和工具。其重要性体现在能够发现传统方法无法识别的遗址，尤其是在人类活动导致景观剧烈变化的地区。这对于保护和研究那些正在消失的文化遗产具有深远的影响。"}}
{"id": "2507.13376", "title": "Physics-guided impact localisation and force estimation in composite plates with uncertainty quantification", "authors": ["Dong Xiao", "Zahra Sharif-Khodaei", "M. H. Aliabadi"], "categories": ["physics.data-an", "cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "primary_category": "Subjects:       Data Analysis, Statistics and Probability (physics.data-an)", "pdf_link": null, "comments": "Comments:      37 pages (including the appendix and references), 16 figures", "url": "http://arxiv.org/abs/2507.13376v1", "summary": "Physics-guided approaches offer a promising path toward accurate and\ngeneralisable impact identification in composite structures, especially when\nexperimental data are sparse. This paper presents a hybrid framework for impact\nlocalisation and force estimation in composite plates, combining a data-driven\nimplementation of First-Order Shear Deformation Theory (FSDT) with machine\nlearning and uncertainty quantification. The structural configuration and\nmaterial properties are inferred from dispersion relations, while boundary\nconditions are identified via modal characteristics to construct a low-fidelity\nbut physically consistent FSDT model. This model enables physics-informed data\naugmentation for extrapolative localisation using supervised learning.\nSimultaneously, an adaptive regularisation scheme derived from the same model\nimproves the robustness of impact force reconstruction. The framework also\naccounts for uncertainty by propagating localisation uncertainty through the\nforce estimation process, producing probabilistic outputs. Validation on\ncomposite plate experiments confirms the framework's accuracy, robustness, and\nefficiency in reducing dependence on large training datasets. The proposed\nmethod offers a scalable and transferable solution for impact monitoring and\nstructural health management in composite aerostructures.", "comment": "37 pages (including the appendix and references), 16 figures", "pdf_url": "http://arxiv.org/pdf/2507.13376v1", "cate": "physics.data-an", "date": "2025-07-13", "updated": "2025-07-13", "AI": {"title_translation": "物理引导的复合材料板冲击定位与力估计及不确定性量化", "tldr": "本文提出了一种混合框架，结合物理引导方法、机器学习和不确定性量化，用于复合材料板的冲击定位和力估计，并在实验中验证了其准确性、鲁棒性和效率。", "motivation": "在复合材料结构中，尤其当实验数据稀疏时，需要准确且可泛化的冲击识别方法。物理引导方法为此提供了一个有前景的途径。", "method": "本文提出了一种混合框架，结合了一阶剪切变形理论（FSDT）的数据驱动实现、机器学习和不确定性量化。通过色散关系推断结构配置和材料属性，通过模态特性识别边界条件，从而构建了一个低保真但物理一致的FSDT模型。该模型实现了物理信息数据增强，用于监督学习的外推定位。同时，从同一模型导出的自适应正则化方案提高了冲击力重建的鲁棒性。该框架还通过在力估计过程中传播定位不确定性来考虑不确定性，从而产生概率输出。", "result": "在复合材料板实验中的验证证实了该框架在准确性、鲁棒性和效率方面的表现，并减少了对大型训练数据集的依赖。", "conclusion": "所提出的方法为复合材料航空结构中的冲击监测和结构健康管理提供了一种可扩展和可转移的解决方案。", "translation": "物理引导方法为复合材料结构中准确且可泛化的冲击识别提供了一条有前景的路径，尤其是在实验数据稀疏的情况下。本文提出了一种用于复合材料板冲击定位和力估计的混合框架，结合了一阶剪切变形理论（FSDT）的数据驱动实现与机器学习和不确定性量化。结构配置和材料属性通过色散关系推断，而边界条件通过模态特性识别，以构建一个低保真但物理一致的FSDT模型。该模型能够实现物理信息的数据增强，用于使用监督学习进行外推定位。同时，从同一模型导出的自适应正则化方案提高了冲击力重建的鲁棒性。该框架还通过在力估计过程中传播定位不确定性来考虑不确定性，从而产生概率输出。在复合材料板实验中的验证证实了该框架的准确性、鲁棒性和效率，减少了对大型训练数据集的依赖。所提出的方法为复合材料航空结构中的冲击监测和结构健康管理提供了一种可扩展和可转移的解决方案。", "summary": "本文提出了一种混合框架，结合物理引导的一阶剪切变形理论（FSDT）、机器学习和不确定性量化，用于复合材料板的冲击定位和力估计。该框架通过推断结构属性和识别边界条件来构建物理一致的FSDT模型，并利用该模型进行物理信息数据增强以实现外推定位，同时采用自适应正则化提高冲击力重建的鲁棒性。通过传播定位不确定性，该方法能够提供概率输出。实验验证表明，该框架在准确性、鲁棒性和效率方面表现出色，并能有效减少对大量训练数据的依赖，为复合材料航空结构中的冲击监测和结构健康管理提供了可扩展和可转移的解决方案。", "keywords": "冲击定位, 力估计, 复合材料, 不确定性量化, 物理引导", "comments": "该论文的创新点在于将物理引导模型（FSDT）与数据驱动的机器学习和不确定性量化相结合，解决了实验数据稀疏情况下的冲击识别问题。通过物理信息数据增强和不确定性传播，提高了方法的准确性、鲁棒性和泛化能力，尤其是在减少对大量训练数据依赖方面具有重要意义，使其在实际工程应用中更具吸引力。"}}
{"id": "2507.13205", "title": "Automatically assessing oral narratives of Afrikaans and isiXhosa children", "authors": ["Retief Louw", "Emma Sharratt", "Febe de Wet", "Christiaan Jacobs", "Annelien Smith", "Herman Kamper"], "categories": ["cs.CL", "eess.AS"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Accepted to SLaTE 2025", "url": "http://arxiv.org/abs/2507.13205v2", "summary": "Developing narrative and comprehension skills in early childhood is critical\nfor later literacy. However, teachers in large preschool classrooms struggle to\naccurately identify students who require intervention. We present a system for\nautomatically assessing oral narratives of preschool children in Afrikaans and\nisiXhosa. The system uses automatic speech recognition followed by a machine\nlearning scoring model to predict narrative and comprehension scores. For\nscoring predicted transcripts, we compare a linear model to a large language\nmodel (LLM). The LLM-based system outperforms the linear model in most cases,\nbut the linear system is competitive despite its simplicity. The LLM-based\nsystem is comparable to a human expert in flagging children who require\nintervention. We lay the foundation for automatic oral assessments in\nclassrooms, giving teachers extra capacity to focus on personalised support for\nchildren's learning.", "comment": "Accepted to SLaTE 2025", "pdf_url": "http://arxiv.org/pdf/2507.13205v2", "cate": "cs.CL", "date": "2025-07-17", "updated": "2025-07-18", "AI": {"title_translation": "自动评估南非荷兰语和科萨语儿童的口头叙事能力", "tldr": "一个利用自动语音识别（ASR）和大型语言模型（LLM）自动评估南非荷兰语和科萨语学龄前儿童口头叙事能力的系统，其性能与人类专家相当。", "motivation": "早期儿童的叙事和理解能力对未来的识字至关重要。然而，大型学前班的教师难以准确识别需要干预的学生。", "method": "本文提出了一个用于自动评估南非荷兰语和科萨语学龄前儿童口头叙事能力的系统。该系统采用自动语音识别，然后通过机器学习评分模型来预测叙事和理解分数。在对预测的转录本进行评分时，系统比较了线性模型和大型语言模型（LLM）的性能。", "result": "基于LLM的系统在大多数情况下优于线性模型，但线性系统尽管简单却具有竞争力。基于LLM的系统在识别需要干预的儿童方面与人类专家相当。", "conclusion": "本文为课堂自动口语评估奠定了基础，使教师能够有额外的精力专注于为儿童学习提供个性化支持。", "translation": "早期儿童叙事和理解能力的发展对于后期的读写能力至关重要。然而，大型学前班的教师难以准确识别需要干预的学生。我们提出了一个用于自动评估南非荷兰语和科萨语学龄前儿童口头叙事能力的系统。该系统使用自动语音识别，然后通过机器学习评分模型来预测叙事和理解分数。对于预测转录本的评分，我们比较了线性模型和大型语言模型（LLM）。基于LLM的系统在大多数情况下优于线性模型，但线性系统尽管简单却具有竞争力。基于LLM的系统在识别需要干预的儿童方面与人类专家相当。我们为课堂自动口语评估奠定了基础，使教师能够有额外的精力专注于为儿童学习提供个性化支持。", "summary": "本文介绍了一个用于自动评估南非荷兰语和科萨语学龄前儿童口头叙事和理解能力的系统。该系统结合了自动语音识别和机器学习评分模型，并比较了线性模型和大型语言模型（LLM）的性能。结果表明，基于LLM的系统在大多数情况下优于线性模型，并且在识别需要干预的儿童方面与人类专家相当，为课堂自动口语评估奠定了基础。", "keywords": "自动评估, 口头叙事, 学龄前儿童, 南非荷兰语, 科萨语", "comments": "本文的创新之处在于将自动语音识别和大型语言模型应用于南非荷兰语和科萨语（资源相对较少语言）的早期儿童口语评估，解决了教师在识别需要干预学生方面的难题。其在个性化学习支持方面的实际应用意义重大，有望提高学前教育的效率和质量。"}}
{"id": "2507.03068", "title": "Mitigating Goal Misgeneralization via Minimax Regret", "authors": ["Karim Abdel Sadek", "Matthew Farrugia-Roberts", "Usman Anwar", "Hannah Erlebach", "Christian Schroeder de Witt", "David Krueger", "Michael Dennis"], "categories": ["cs.LG"], "primary_category": "Subjects:       Machine Learning (cs.LG)", "pdf_link": null, "comments": "Comments:      Published at RLC 2025. 11 pages main text. v2: no changes to PDF, fix arXiv title", "url": "http://arxiv.org/abs/2507.03068v2", "summary": "Safe generalization in reinforcement learning requires not only that a\nlearned policy acts capably in new situations, but also that it uses its\ncapabilities towards the pursuit of the designer's intended goal. The latter\nrequirement may fail when a proxy goal incentivizes similar behavior to the\nintended goal within the training environment, but not in novel deployment\nenvironments. This creates the risk that policies will behave as if in pursuit\nof the proxy goal, rather than the intended goal, in deployment -- a phenomenon\nknown as goal misgeneralization. In this paper, we formalize this problem\nsetting in order to theoretically study the possibility of goal\nmisgeneralization under different training objectives. We show that goal\nmisgeneralization is possible under approximate optimization of the maximum\nexpected value (MEV) objective, but not the minimax expected regret (MMER)\nobjective. We then empirically show that the standard MEV-based training method\nof domain randomization exhibits goal misgeneralization in\nprocedurally-generated grid-world environments, whereas current regret-based\nunsupervised environment design (UED) methods are more robust to goal\nmisgeneralization (though they don't find MMER policies in all cases). Our\nfindings suggest that minimax expected regret is a promising approach to\nmitigating goal misgeneralization.", "comment": "Published at RLC 2025. 11 pages main text. v2: no changes to PDF, fix\n  arXiv title", "pdf_url": "http://arxiv.org/pdf/2507.03068v2", "cate": "cs.LG", "date": "2025-07-03", "updated": "2025-07-18", "AI": {"title_translation": "通过最小化最大后悔来缓解目标泛化错误", "tldr": "本文研究了强化学习中目标泛化错误（goal misgeneralization）问题，即代理在训练环境中表现良好，但在新环境中追求代理目标而非预期目标。研究发现，最大期望值（MEV）优化可能导致此问题，而最小化最大期望后悔（MMER）则不会。实证结果支持MMER是缓解此问题的有效方法。", "motivation": "在强化学习中，安全的泛化不仅要求学习到的策略在新情境下有能力，还要求其能力服务于设计者预期的目标。当代理目标在训练环境中与预期目标行为相似，但在新的部署环境中不相似时，策略可能会在部署时追求代理目标而非预期目标，导致目标泛化错误。本文旨在形式化并研究这一问题，以寻找缓解方法。", "method": "本文首先形式化了目标泛化错误问题，以理论研究不同训练目标下发生目标泛化错误的可能性。随后，通过理论分析比较了最大期望值（MEV）和最小化最大期望后悔（MMER）目标。最后，通过在程序生成的网格世界环境中，使用域随机化（一种基于MEV的训练方法）和基于后悔的无监督环境设计（UED）方法进行实证验证。", "result": "研究表明，在近似优化最大期望值（MEV）目标下，目标泛化错误是可能发生的，但在最小化最大期望后悔（MMER）目标下则不会。经验结果显示，标准的基于MEV的域随机化训练方法在程序生成的网格世界环境中表现出目标泛化错误，而当前的基于后悔的无监督环境设计（UED）方法对目标泛化错误更具鲁棒性（尽管它们并非总能找到MMER策略）。", "conclusion": "本文的研究结果表明，最小化最大期望后悔是一种有希望缓解目标泛化错误的方法。", "translation": "在强化学习中，安全的泛化不仅要求学习到的策略在新情境下有能力，还要求其能力服务于设计者预期的目标。当代理目标在训练环境中与预期目标行为相似，但在新的部署环境中不相似时，后一个要求可能会失败。这带来了策略在部署时表现得仿佛在追求代理目标而非预期目标的风险——这种现象被称为目标泛化错误。在本文中，我们形式化了这一问题设置，以便从理论上研究在不同训练目标下目标泛化错误的可能性。我们证明了在最大期望值（MEV）目标的近似优化下，目标泛化错误是可能的，但在最小化最大期望后悔（MMER）目标下则不然。然后，我们通过经验证明，标准的基于MEV的域随机化训练方法在程序生成的网格世界环境中表现出目标泛化错误，而当前的基于后悔的无监督环境设计（UED）方法对目标泛化错误更具鲁棒性（尽管它们并非总能找到MMER策略）。我们的发现表明，最小化最大期望后悔是缓解目标泛化错误的一种有前途的方法。", "summary": "本文探讨了强化学习中的目标泛化错误问题，即策略在训练环境中表现良好，但在新环境中未能追求设计者预期的目标，而是追求代理目标。研究通过形式化该问题，理论分析了最大期望值（MEV）和最小化最大期望后悔（MMER）这两种训练目标的影响。结果表明，MEV可能导致目标泛化错误，而MMER则能有效规避。实证实验进一步证实，基于MEV的域随机化方法存在目标泛化错误，而基于后悔的无监督环境设计方法对此更具鲁棒性。研究强调最小化最大期望后悔是缓解目标泛化错误的一种有效途径。", "keywords": "强化学习, 目标泛化错误, 最小化最大期望后悔, 安全泛化, 域随机化", "comments": "本文创新性地将目标泛化错误问题形式化，并通过理论分析和实证验证，明确指出最小化最大期望后悔（MMER）在缓解该问题上的潜力。这对于强化学习的安全泛化具有重要意义，尤其是在部署复杂AI系统时，确保其行为与设计者意图一致。研究结合了理论严谨性和实际验证，为未来开发更鲁棒的强化学习算法提供了新的方向。"}}
{"id": "2507.13360", "title": "Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance", "authors": ["Le-Anh Tran", "Chung Nguyen Tran", "Ngoc-Luu Nguyen", "Nhan Cach Dang", "Jordi Carrabina", "David Castells-Rufas", "Minh Son Nguyen"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      6 pages, 3 figures, ICCCE 2025", "url": "http://arxiv.org/abs/2507.13360v1", "summary": "This paper introduces a novel deep learning framework for low-light image\nenhancement, named the Encoder-Decoder Network with Illumination Guidance\n(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination\nmap, derived from Bright Channel Prior (BCP), as a guidance input. This\nillumination guidance helps the network focus on underexposed regions,\neffectively steering the enhancement process. To further improve the model's\nrepresentational power, a Spatial Pyramid Pooling (SPP) module is incorporated\nto extract multi-scale contextual features, enabling better handling of diverse\nlighting conditions. Additionally, the Swish activation function is employed to\nensure smoother gradient propagation during training. EDNIG is optimized within\na Generative Adversarial Network (GAN) framework using a composite loss\nfunction that combines adversarial loss, pixel-wise mean squared error (MSE),\nand perceptual loss. Experimental results show that EDNIG achieves competitive\nperformance compared to state-of-the-art methods in quantitative metrics and\nvisual quality, while maintaining lower model complexity, demonstrating its\nsuitability for real-world applications. The source code for this work is\navailable at https://github.com/tranleanh/ednig.", "comment": "6 pages, 3 figures, ICCCE 2025", "pdf_url": "http://arxiv.org/pdf/2507.13360v1", "cate": "cs.CV", "date": "2025-07-04", "updated": "2025-07-04", "AI": {"title_translation": "弱光增强：基于照度引导的编解码器网络", "tldr": "本文提出EDNIG，一个结合照度引导、SPP和GAN的U-Net架构，用于弱光图像增强，实现高表现和低复杂度。", "motivation": "解决弱光图像增强问题，提出一种新的深度学习框架来有效提升图像质量。", "method": "本文提出EDNIG，一个基于U-Net的编解码器网络，用于弱光图像增强。它将基于亮通道先验（BCP）的照度图作为引导输入，以帮助网络关注欠曝光区域。模型整合了空间金字塔池化（SPP）模块用于多尺度上下文特征提取，并采用Swish激活函数以确保平滑的梯度传播。EDNIG在生成对抗网络（GAN）框架下优化，使用结合对抗损失、像素级均方误差（MSE）和感知损失的复合损失函数。", "result": "实验结果表明，EDNIG在定量指标和视觉质量方面与现有先进方法相比，表现出具有竞争力的性能，同时保持了较低的模型复杂度。", "conclusion": "EDNIG框架在实现高性能的同时具有较低的模型复杂度，证明其适用于实际弱光图像增强应用。", "translation": "本文介绍了一种新颖的深度学习框架，用于弱光图像增强，名为编解码器网络与照度引导（EDNIG）。EDNIG基于U-Net架构，将源自亮通道先验（BCP）的照度图作为引导输入。这种照度引导有助于网络关注曝光不足的区域，有效引导增强过程。为了进一步提高模型的表示能力，引入了空间金字塔池化（SPP）模块来提取多尺度上下文特征，从而更好地处理不同的光照条件。此外，采用Swish激活函数以确保训练期间更平滑的梯度传播。EDNIG在生成对抗网络（GAN）框架内通过结合对抗损失、像素级均方误差（MSE）和感知损失的复合损失函数进行优化。实验结果表明，与现有最先进的方法相比，EDNIG在定量指标和视觉质量方面取得了有竞争力的性能，同时保持了较低的模型复杂度，证明了其适用于实际应用。本工作的源代码可在https://github.com/tranleanh/ednig获取。", "summary": "本文提出了一种名为EDNIG的新型深度学习框架，用于弱光图像增强。EDNIG基于U-Net架构，通过整合来自亮通道先验（BCP）的照度图作为引导输入，以有效聚焦于欠曝光区域。为提升特征提取能力，模型引入了空间金字塔池化（SPP）模块处理多尺度特征，并采用Swish激活函数优化训练。EDNIG在GAN框架下，结合对抗损失、MSE和感知损失进行优化。实验证明，EDNIG在性能上与现有先进方法相当，且模型复杂度更低，适合实际应用。", "keywords": "弱光增强, 编解码器网络, 照度引导, GAN, 深度学习", "comments": "这篇论文通过引入照度引导机制和结合多尺度特征提取，有效提升了弱光图像增强的效果。其创新点在于将照度图作为引导输入，使网络能更精准地关注欠曝光区域。同时，采用GAN框架和复合损失函数，以及较低的模型复杂度，使其在实际应用中具有较强的竞争力。"}}
{"id": "2507.13779", "title": "SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering", "authors": ["Durgesh Singh", "Ahcène Boubekki", "Robert Jenssen", "Michael Kampffmeyer"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "", "url": "http://arxiv.org/abs/2507.13779v1", "summary": "Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)\nenhance the model performance by exploiting information from labeled and\nunlabeled data. The clustering assumption has proven advantageous for learning\nwith limited supervision and states that data points belonging to the same\ncluster in a high-dimensional space should be assigned to the same category.\nRecent works have utilized different training mechanisms to implicitly enforce\nthis assumption for the SSL and UDA. In this work, we take a different approach\nby explicitly involving a differentiable clustering module which is extended to\nleverage the supervised data to compute its centroids. We demonstrate the\neffectiveness of our straightforward end-to-end training strategy for SSL and\nUDA over extensive experiments and highlight its benefits, especially in low\nsupervision regimes, both as a standalone model and as a regularizer for\nexisting approaches.", "comment": null, "pdf_url": "http://arxiv.org/pdf/2507.13779v1", "cate": "cs.CV", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "SuperCM：通过可微分聚类改进半监督学习和域适应", "tldr": "本文通过引入一个可微分聚类模块，显式地利用聚类假设来改进半监督学习和无监督域适应，并在低监督环境下表现出色。", "motivation": "半监督学习（SSL）和无监督域适应（UDA）通过利用有标签和无标签数据来提高模型性能。聚类假设已被证明在有限监督下学习具有优势，即高维空间中属于同一聚类的数据点应归为同一类别。现有工作通过不同的训练机制隐式地强制执行此假设，但本文旨在采取一种不同的、显式的方法。", "method": "本文通过显式地引入一个可微分聚类模块来实现，该模块被扩展以利用有监督数据来计算其聚类中心。", "result": "在广泛的实验中，本文证明了其直接的端到端训练策略在半监督学习（SSL）和无监督域适应（UDA）方面的有效性，并强调了其优势，特别是在低监督制度下，无论是作为独立模型还是作为现有方法的正则化器。", "conclusion": "本文提出的基于可微分聚类的显式方法显著提升了半监督学习和无监督域适应的性能，尤其在数据监督较少的情况下表现突出，并可作为独立模型或现有方法的有效正则化器。", "translation": "半监督学习（SSL）和无监督域适应（UDA）通过利用有标签和无标签数据来增强模型性能。聚类假设已被证明在有限监督下学习具有优势，并指出高维空间中属于同一聚类的数据点应归为同一类别。最近的工作利用不同的训练机制隐式地强制执行SSL和UDA的这一假设。在这项工作中，我们采取了一种不同的方法，显式地引入了一个可微分聚类模块，该模块被扩展以利用监督数据来计算其聚类中心。我们通过广泛的实验证明了我们直接的端到端训练策略对SSL和UDA的有效性，并强调了其优势，特别是在低监督制度下，无论是作为独立模型还是作为现有方法的正则化器。", "summary": "本研究提出了一种名为 SuperCM 的新方法，通过引入一个可微分聚类模块来改进半监督学习（SSL）和无监督域适应（UDA）。与以往隐式应用聚类假设的方法不同，SuperCM 显式地利用聚类，并通过监督数据计算聚类中心。实验证明，这种端到端训练策略在SSL和UDA任务中表现出色，尤其在低监督环境下效果显著，既可作为独立模型也可作为现有方法的正则化器。", "keywords": "半监督学习, 域适应, 可微分聚类, 低监督, 正则化", "comments": "本文的创新点在于显式地引入了可微分聚类模块来强制执行聚类假设，这与以往隐式方法形成对比。其简单直接的端到端训练策略以及在低监督场景下的显著效果，使其在半监督学习和域适应领域具有重要价值。该方法既可以独立使用，也可以作为现有方法的有效正则化器，这增加了其应用灵活性。"}}
{"id": "2409.07777", "title": "Bounds on Covert Capacity with Sub-Exponential Random Slot Selection", "authors": ["Shi-Yuan Wang", "Keerthi S. K. Arumugam", "Matthieu R. Bloch"], "categories": ["cs.IT", "math.IT"], "primary_category": "Subjects:       Information Theory (cs.IT)", "pdf_link": null, "comments": "Comments:      Accepted to IEEE Transactions on Information Theory", "url": "http://arxiv.org/abs/2409.07777v2", "summary": "We consider the problem of covert communication with random slot selection\nover binary-input Discrete Memoryless Channels and Additive White Gaussian\nNoise channels, in which a transmitter attempts to reliably communicate with a\nlegitimate receiver while simultaneously maintaining covertness with respect to\nan eavesdropper. Covertness refers to the inability of the eavesdropper to\ndistinguish the transmission of a message from the absence of communication,\nmodeled by the transmission of a fixed channel input. Random slot selection\nrefers to the transmitter's ability to send a codeword in a time slot with\nknown boundaries selected uniformly at random among a predetermined number of\nslots. Our main contribution is to develop bounds for the information-theoretic\nlimit of communication in this model, called the covert capacity, when the\nnumber of time slots scales sub-exponentially with the codeword length. Our\nupper and lower bounds for the covert capacity are within a multiplicative\nfactor of $\\sqrt{2}$ independent of the channel. This result partially fills a\ncharacterization gap between the covert capacity without random slot selection\nand the covert capacity with random selection among an exponential number of\nslots in the codeword length. Our key technical contributions consist of i) a\ntight upper bound for the relative entropy characterizing the effect of random\nslot selection on the covertness constraint in our achievability proof; ii) a\ncareful converse analysis to characterize the maximum allowable weight or power\nof codewords to meet the covertness constraint. Our results suggest that,\nunlike the case without random slot selection, the choice of covertness metric\ndoes not change the covert capacity in the presence of random slot selection.", "comment": "Accepted to IEEE Transactions on Information Theory", "pdf_url": "http://arxiv.org/pdf/2409.07777v2", "cate": "cs.IT", "date": "2024-09-12", "updated": "2025-07-18", "AI": {"title_translation": "亚指数随机时隙选择下隐蔽容量的界限", "tldr": "研究了当随机时隙数量与码字长度呈亚指数关系时，隐蔽通信容量的上下界。", "motivation": "在二进制输入离散无记忆信道和加性高斯白噪声信道上，研究了如何在保持对窃听者隐蔽性的同时，实现发送方与合法接收方之间的可靠通信，特别是在随机时隙选择的场景下，并旨在填补隐蔽容量表征上的空白。", "method": "提出了隐蔽容量的上下界，其中随机时隙选择的数量与码字长度呈亚指数关系。技术贡献包括：1) 针对可达性证明中表征随机时隙选择对隐蔽性约束影响的相对熵的紧密上界；2) 仔细的逆分析来表征满足隐蔽性约束的最大允许码字权重或功率。", "result": "隐蔽容量的上下界在与信道无关的 $\\sqrt{2}$ 乘法因子内。结果表明，与没有随机时隙选择的情况不同，隐蔽性度量的选择不会改变存在随机时隙选择时的隐蔽容量。", "conclusion": "在随机时隙选择存在的情况下，隐蔽性度量的选择不会改变隐蔽容量，这部分填补了无随机时隙选择和指数数量时隙随机选择之间隐蔽容量表征的空白。", "translation": "我们考虑了在二进制输入离散无记忆信道和加性高斯白噪声信道上，采用随机时隙选择的隐蔽通信问题，其中发送方试图与合法接收方可靠通信，同时对窃听者保持隐蔽性。隐蔽性是指窃听者无法区分消息传输与通信缺失，后者通过固定信道输入的传输来建模。随机时隙选择是指发送方能够在预定数量的时隙中，以已知边界的随机均匀选择的时隙中发送码字。我们的主要贡献是，当时间时隙的数量与码字长度呈亚指数关系时，为该模型中通信的信息理论极限（称为隐蔽容量）开发界限。我们对隐蔽容量的上下界在与信道无关的 $\\sqrt{2}$ 乘法因子内。这一结果部分填补了无随机时隙选择的隐蔽容量与码字长度中指数数量时隙随机选择的隐蔽容量之间的表征空白。我们的关键技术贡献包括：i) 在我们的可达性证明中，表征随机时隙选择对隐蔽性约束影响的相对熵的紧密上界；ii) 仔细的逆分析，以表征满足隐蔽性约束的最大允许码字权重或功率。我们的结果表明，与没有随机时隙选择的情况不同，隐蔽性度量的选择在存在随机时隙选择时不会改变隐蔽容量。", "summary": "本文研究了在二进制输入离散无记忆信道和加性高斯白噪声信道上，采用随机时隙选择的隐蔽通信问题。当随机时隙的数量与码字长度呈亚指数关系时，论文推导了隐蔽容量的上下界，其界限在 $\\sqrt{2}$ 因子内，且与信道无关。该研究填补了隐蔽容量在不同随机时隙选择场景下的表征空白，并发现随机时隙选择下隐蔽性度量的选择不影响隐蔽容量。", "keywords": "隐蔽通信, 隐蔽容量, 随机时隙选择, 信息理论, 上下界", "comments": "这篇论文通过引入随机时隙选择的概念，并分析其在亚指数规模下的影响，为隐蔽通信领域的理论研究做出了贡献。其创新点在于提出了紧密界限和详细的逆分析，并揭示了随机时隙选择对隐蔽性度量选择不敏感的特性，这对于理解隐蔽通信的本质具有重要意义。"}}
{"id": "2507.13705", "title": "Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations", "authors": ["Cedric Waterschoot", "Nava Tintarev", "Francesco Barile"], "categories": ["cs.CL", "cs.IR"], "primary_category": "Subjects:       Computation and Language (cs.CL)", "pdf_link": null, "comments": "Comments:      Short paper accepted at the Nineteenth ACM Conference on Recommender Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi: https://doi.org/10.1145/3705328.3748015", "url": "http://arxiv.org/abs/2507.13705v1", "summary": "Large Language Models (LLMs) are increasingly being implemented as joint\ndecision-makers and explanation generators for Group Recommender Systems (GRS).\nIn this paper, we evaluate these recommendations and explanations by comparing\nthem to social choice-based aggregation strategies. Our results indicate that\nLLM-generated recommendations often resembled those produced by Additive\nUtilitarian (ADD) aggregation. However, the explanations typically referred to\naveraging ratings (resembling but not identical to ADD aggregation). Group\nstructure, uniform or divergent, did not impact the recommendations.\nFurthermore, LLMs regularly claimed additional criteria such as user or item\nsimilarity, diversity, or used undefined popularity metrics or thresholds. Our\nfindings have important implications for LLMs in the GRS pipeline as well as\nstandard aggregation strategies. Additional criteria in explanations were\ndependent on the number of ratings in the group scenario, indicating potential\ninefficiency of standard aggregation methods at larger item set sizes.\nAdditionally, inconsistent and ambiguous explanations undermine transparency\nand explainability, which are key motivations behind the use of LLMs for GRS.", "comment": "Short paper accepted at the Nineteenth ACM Conference on Recommender\n  Systems (RecSys '25). Cedric Waterschoot, Nava Tintarev, and Francesco\n  Barile. 2025. Consistent Explainers or Unreliable Narrators? Understanding\n  LLM-generated Group Recommendations. Proceedings of the Nineteenth ACM\n  Conference on Recommender Systems (RecSys '25), Prague, Czech Republic. doi:\n  10.1145/3705328.3748015", "pdf_url": "http://arxiv.org/pdf/2507.13705v1", "cate": "cs.CL", "date": "2025-07-18", "updated": "2025-07-18", "AI": {"title_translation": "一致的解释器还是不可靠的叙述者？理解LLM生成的群组推荐", "tldr": "本研究评估了大型语言模型（LLM）在群组推荐系统（GRS）中生成的推荐和解释，发现LLM的推荐与加性功利主义（ADD）聚合类似，但解释常提及平均评分且存在不一致性及模糊性，这损害了透明度和可解释性。", "motivation": "大型语言模型（LLM）正越来越多地被应用于群组推荐系统（GRS）中作为联合决策者和解释生成器，因此有必要评估这些由LLM生成的推荐和解释。", "method": "通过将LLM生成的推荐和解释与基于社会选择的聚合策略进行比较来评估它们。", "result": "LLM生成的推荐通常与加性功利主义（ADD）聚合策略的结果相似。然而，其解释通常提及平均评分（与ADD聚合相似但不完全相同）。群组结构（统一或分歧）不影响推荐结果。此外，LLM经常声称使用额外的标准，如用户或项目相似性、多样性，或使用未定义的流行度指标或阈值。解释中额外标准的存在取决于群组场景中的评分数量。", "conclusion": "LLM在GRS管道中的应用以及标准聚合策略具有重要意义。研究结果表明，标准聚合方法在更大的项目集规模下可能存在潜在的低效率。此外，不一致和模糊的解释损害了透明度和可解释性，而这正是使用LLM进行GRS的关键动机。", "translation": "大型语言模型（LLM）正越来越多地被应用于群组推荐系统（GRS）中作为联合决策者和解释生成器。在本文中，我们通过将这些推荐和解释与基于社会选择的聚合策略进行比较来评估它们。我们的结果表明，LLM生成的推荐通常与加性功利主义（ADD）聚合的结果相似。然而，其解释通常提及平均评分（与ADD聚合相似但不完全相同）。群组结构，无论是统一的还是分歧的，都不会影响推荐结果。此外，LLM经常声称使用额外的标准，如用户或项目相似性、多样性，或使用未定义的流行度指标或阈值。我们的发现对LLM在GRS管道中的应用以及标准聚合策略具有重要意义。解释中额外标准的存在取决于群组场景中的评分数量，这表明标准聚合方法在更大的项目集规模下可能存在潜在的低效率。此外，不一致和模糊的解释损害了透明度和可解释性，而这正是使用LLM进行GRS的关键动机。", "summary": "本研究评估了大型语言模型（LLM）在群组推荐系统（GRS）中生成推荐和解释的性能。通过与社会选择聚合策略比较，发现LLM推荐常与加性功利主义（ADD）聚合结果相似，但其解释虽然提及平均评分，却常常不一致、模糊，并引用未定义或额外的标准。研究指出，群组结构对推荐无影响，但解释中的额外标准与评分数量相关。这些发现对LLM在GRS中的应用及标准聚合策略有重要启示，尤其在透明度和可解释性方面存在挑战。", "keywords": "大型语言模型, 群组推荐系统, 解释性AI, 社会选择, 聚合策略", "comments": "这项研究揭示了LLM在群组推荐系统中的一个关键挑战：虽然其推荐结果可能与现有聚合策略相似，但其解释缺乏透明度和一致性。这对于依赖LLM提供可信解释的应用场景来说是一个重要的局限性。论文的创新之处在于对比了LLM的输出与传统的社会选择理论，并指出了LLM在解释生成方面的“不可靠”性，这促使未来研究关注如何提高LLM解释的准确性和可信度。"}}
{"id": "2507.11200", "title": "How Far Have Medical Vision-Language Models Come? A Comprehensive Benchmarking Study", "authors": ["Che Liu", "Jiazhen Pan", "Weixiang Shen", "Wenjia Bai", "Daniel Rueckert", "Rossella Arcucci"], "categories": ["cs.CV"], "primary_category": "Subjects:       Computer Vision and Pattern Recognition (cs.CV)", "pdf_link": null, "comments": "Comments:      Technical report", "url": "http://arxiv.org/abs/2507.11200v2", "summary": "Vision-Language Models (VLMs) trained on web-scale corpora excel at natural\nimage tasks and are increasingly repurposed for healthcare; however, their\ncompetence in medical tasks remains underexplored. We present a comprehensive\nevaluation of open-source general-purpose and medically specialised VLMs,\nranging from 3B to 72B parameters, across eight benchmarks: MedXpert,\nOmniMedVQA, PMC-VQA, PathVQA, MMMU, SLAKE, and VQA-RAD. To observe model\nperformance across different aspects, we first separate it into understanding\nand reasoning components. Three salient findings emerge. First, large\ngeneral-purpose models already match or surpass medical-specific counterparts\non several benchmarks, demonstrating strong zero-shot transfer from natural to\nmedical images. Second, reasoning performance is consistently lower than\nunderstanding, highlighting a critical barrier to safe decision support. Third,\nperformance varies widely across benchmarks, reflecting differences in task\ndesign, annotation quality, and knowledge demands. No model yet reaches the\nreliability threshold for clinical deployment, underscoring the need for\nstronger multimodal alignment and more rigorous, fine-grained evaluation\nprotocols.", "comment": "Technical report", "pdf_url": "http://arxiv.org/pdf/2507.11200v2", "cate": "cs.CV", "date": "2025-07-15", "updated": "2025-07-18", "AI": {"title_translation": "医疗视觉-语言模型发展到何种程度？一项全面的基准研究", "tldr": "一项全面评估开源通用和医学专用视觉-语言模型在医疗任务中表现的研究。发现大型通用模型在某些方面已超越医学专用模型，但推理能力普遍较弱，且无模型达到临床部署标准。", "motivation": "尽管视觉-语言模型（VLMs）在自然图像任务中表现出色并越来越多地应用于医疗保健领域，但它们在医疗任务中的能力尚未得到充分探索。", "method": "本研究对从3B到72B参数的开源通用和医学专用视觉-语言模型进行了全面评估，涵盖了MedXpert、OmniMedVQA、PMC-VQA、PathVQA、MMMU、SLAKE和VQA-RAD等八个医疗基准测试。评估将模型性能分为理解和推理两部分。", "result": "1. 大型通用模型在多个基准测试中已经匹配或超越了医学专用模型，显示出从自然图像到医学图像的强大零样本迁移能力。2. 推理性能始终低于理解性能，是安全决策支持的关键障碍。3. 性能在不同基准测试之间差异很大，反映了任务设计、注释质量和知识需求的不同。", "conclusion": "目前没有模型达到临床部署的可靠性阈值，这强调了需要更强的多模态对齐和更严格、细致的评估协议。", "translation": "在网络规模语料库上训练的视觉-语言模型（VLMs）在自然图像任务中表现出色，并越来越多地被重新用于医疗保健领域；然而，它们在医疗任务中的能力仍未得到充分探索。我们对从3B到72B参数的开源通用和医学专用VLM进行了全面评估，涵盖了八个基准测试：MedXpert、OmniMedVQA、PMC-VQA、PathVQA、MMMU、SLAKE和VQA-RAD。为了观察模型在不同方面的表现，我们首先将其分为理解和推理两部分。研究得出了三个显著发现。首先，大型通用模型在几个基准测试中已经匹配或超越了医学专用模型，这表明从自然图像到医学图像具有强大的零样本迁移能力。其次，推理性能始终低于理解性能，这突出表明了安全决策支持的关键障碍。第三，性能在不同基准测试之间差异很大，反映了任务设计、注释质量和知识需求的不同。目前没有模型达到临床部署的可靠性阈值，这强调了需要更强的多模态对齐和更严格、细致的评估协议。", "summary": "本研究全面评估了开源通用和医学专用视觉-语言模型在八个医疗基准测试中的表现。结果显示，大型通用模型在零样本迁移方面表现出色，甚至在某些方面超越了医学专用模型。然而，模型的推理能力普遍弱于理解能力，且目前所有模型均未达到临床部署所需的可靠性标准，这强调了未来研究需关注更强的多模态对齐和更严格的评估协议。", "keywords": "视觉-语言模型, 医疗AI, 基准测试, 零样本迁移, 模型评估", "comments": "这项研究对当前医疗视觉-语言模型的现状进行了全面且深入的基准测试，其创新之处在于区分了理解和推理能力，并揭示了通用模型在特定医疗任务上的潜力。研究明确指出当前模型离临床应用尚有距离，强调了多模态对齐和精细评估的重要性，为未来医疗AI的发展方向提供了宝贵的洞察和指导。"}}
