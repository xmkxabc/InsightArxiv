# AI-Enhanced arXiv Daily 2025-06-15

<a id='toc'></a>
## 今日总计: 565 篇论文
### 目录
- [cs.CR](#cscr) (35 篇)
- [cs.AI](#csai) (27 篇)
- [cs.LG](#cslg) (89 篇)
- [cs.MA](#csma) (2 篇)
- [cs.RO](#csro) (25 篇)
- [cs.CV](#cscv) (96 篇)
- [cs.HC](#cshc) (14 篇)
- [cs.SE](#csse) (24 篇)
- [cs.SI](#cssi) (2 篇)
- [cs.NI](#csni) (5 篇)
- [cs.IT](#csit) (8 篇)
- [cs.AR](#csar) (4 篇)
- [cs.DC](#csdc) (14 篇)
- [cs.CY](#cscy) (6 篇)
- [cs.CE](#csce) (4 篇)
- [cs.FL](#csfl) (2 篇)
- [eess.SY](#eesssy) (15 篇)
- [eess.SP](#eesssp) (11 篇)
- [eess.IV](#eessiv) (13 篇)
- [eess.AS](#eessas) (6 篇)
- [cs.CL](#cscl) (61 篇)
- [cs.DS](#csds) (3 篇)
- [cs.GR](#csgr) (7 篇)
- [cs.IR](#csir) (10 篇)
- [math.NA](#mathna) (16 篇)
- [cs.SD](#cssd) (7 篇)
- [cs.MM](#csmm) (11 篇)
- [quant-ph](#quant-ph) (4 篇)
- [stat.ME](#statme) (2 篇)
- [cs.DM](#csdm) (1 篇)
- [cs.DB](#csdb) (1 篇)
- [cond-mat.dis-nn](#cond-matdis-nn) (2 篇)
- [math.ST](#mathst) (1 篇)
- [physics.class-ph](#physicsclass-ph) (1 篇)
- [math.OC](#mathoc) (4 篇)
- [math.NT](#mathnt) (1 篇)
- [cs.OS](#csos) (1 篇)
- [cs.PL](#cspl) (1 篇)
- [cs.LO](#cslo) (2 篇)
- [q-bio.BM](#q-biobm) (2 篇)
- [q-bio.QM](#q-bioqm) (3 篇)
- [physics.med-ph](#physicsmed-ph) (2 篇)
- [cs.GT](#csgt) (1 篇)
- [stat.ML](#statml) (10 篇)
- [physics.geo-ph](#physicsgeo-ph) (2 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (2 篇)
- [physics.ao-ph](#physicsao-ph) (3 篇)

---
<a id='cscr'></a>
## cs.CR 

### [1] [From Threat to Tool: Leveraging Refusal-Aware Injection Attacks for Safety Alignment](https://arxiv.org/abs/2506.10020)
> *从威胁到工具：利用拒绝感知注入攻击进行安全对齐*

*Kyubyung Chae, Hyunbin Jin, Taesup Kim* | **Main category: cs.CR**

**Keywords:** LLM安全对齐, 注入攻击, 合成数据, 拒绝感知, 越狱

**Comment:** 

> **TL;DR:** 本文提出了一种名为RAAI的框架，通过将LLM攻击技术转化为工具，生成合成数据来提高LLM的安全对齐，同时保持其通用能力。

**AI_Comments:** 本文的创新之处在于将通常用于攻击LLMs的技术重新定义为促进安全对齐的工具，这提供了一个新颖的视角。RAAI框架的“无需训练”和“模型无关”特性是其重要优势，意味着它具有广泛的适用性和较低的实施成本。通过生成合成数据来提升模型鲁棒性，同时保持通用能力，解决了LLM对齐中的一个关键挑战，即如何高效且不牺牲性能地进行安全对齐。这为LLM安全研究开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 安全对齐大型语言模型（LLMs）需要大量昂贵且耗时的人工标注偏好数据。虽然合成数据是一个有前景的替代方案，但现有方法通常依赖于复杂的迭代提示或辅助模型，这促使研究者寻找更直接、无需训练且模型无关的方法。

**Method:** 本文引入了拒绝感知自适应注入（RAAI），这是一个直接、无需训练且模型无关的框架，它重新利用了LLM攻击技术。RAAI通过检测LLM内部的拒绝信号并自适应地注入预定义短语，以引出有害但流畅的完成。

**Result:** 实验表明，RAAI能有效越狱LLMs，在四个基准测试中，有害响应率从基线的2.15%平均提高到61.04%。更重要的是，使用RAAI生成的合成数据对LLMs进行微调，可以提高模型对有害提示的鲁棒性，同时在MMLU和ARC等标准任务上保持通用能力。

**Conclusion:** 这项工作强调了LLM攻击方法可以被重新定义为可扩展和可控安全对齐的实用工具。

> **ai_Abstract:** 本文提出了一种名为拒绝感知自适应注入（RAAI）的新框架，旨在通过将LLM攻击技术转化为工具来解决LLM安全对齐中对昂贵人工标注数据的依赖。RAAI通过检测模型内部的拒绝信号并注入特定短语来生成有害但流畅的合成数据。实验证明，RAAI能有效提高LLM的有害响应率，并且利用这些合成数据进行微调可以增强模型对有害提示的鲁棒性，同时不影响其在通用任务上的性能。这项工作展示了攻击方法在LLM安全对齐中的潜在应用，提供了一种可扩展且可控的解决方案。

> **摘要翻译:** 安全对齐大型语言模型（LLMs）通常需要大量人工标注的偏好数据，这个过程既昂贵又耗时。虽然合成数据提供了一个有前景的替代方案，但现有方法经常依赖于复杂的迭代提示或辅助模型。为了解决这个问题，我们引入了拒绝感知自适应注入（RAAI），这是一个直接、无需训练且模型无关的框架，它重新利用了LLM攻击技术。RAAI通过检测内部拒绝信号并自适应地注入预定义短语来引出有害但流畅的完成。我们的实验表明，RAAI能有效越狱LLMs，在四个基准测试中，有害响应率从基线的2.15%平均提高到高达61.04%。至关重要的是，使用RAAI生成的合成数据对LLMs进行微调，可以提高模型对有害提示的鲁棒性，同时在MMLU和ARC等标准任务上保持通用能力。这项工作强调了LLM攻击方法可以被重新定义为可扩展和可控安全对齐的实用工具。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [2] [LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges](https://arxiv.org/abs/2506.10022)
> *LLM陷入交火：恶意软件请求与越狱挑战*

*Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Junyu Gao, Xuelong Li* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 越狱攻击, 恶意代码生成, 安全性, MalwareBench

**Comment:** Accepted as ACL 2025 main conference

> **TL;DR:** 本文提出了MalwareBench数据集，用于评估大型语言模型（LLMs）在恶意代码生成方面的越狱攻击漏洞。实验结果表明，主流LLMs对恶意代码的拒绝能力有限，尤其是在结合多种越狱方法时，其安全能力显著下降。

**AI_Comments:** 该论文通过构建MalwareBench数据集，填补了LLMs在恶意代码生成越狱攻击领域研究的空白，具有重要的实践意义。其创新之处在于系统性地评估了多种越狱方法对LLMs代码生成安全性的影响，并量化了其脆弱性。研究结果揭示了当前LLMs在代码安全方面的不足，为未来LLMs的安全加固提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管之前对LLM的通用安全能力有所研究，但其在代码生成方面对越狱攻击的特定脆弱性仍未得到充分探索。本文旨在弥补这一空白，评估LLM抵御此类威胁的鲁棒性。

**Method:** 本文提出了MalwareBench，这是一个包含3,520个用于恶意代码生成的越狱提示的基准数据集。该数据集基于320个手工制作的恶意代码生成需求，涵盖了11种越狱方法和29种代码功能类别。

**Result:** 实验表明，主流LLMs拒绝恶意代码生成请求的能力有限。结合多种越狱方法会进一步降低模型的安全能力：恶意内容的平均拒绝率为60.93%，而当与越狱攻击算法结合时，该比率降至39.92%。

**Conclusion:** LLMs的代码安全能力仍面临重大挑战。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在恶意代码生成方面对越狱攻击的脆弱性进行了研究。研究人员提出了MalwareBench数据集，包含3,520个恶意代码生成越狱提示，以评估LLMs的安全性。实验结果显示，主流LLMs在拒绝恶意代码方面的能力有限，特别是当多种越狱方法结合使用时，其安全能力会显著下降，表明LLMs的代码安全仍面临严峻挑战。

> **摘要翻译:** 大型语言模型（LLM）的广泛采用加剧了对其安全性的担忧，特别是它们容易受到利用精心设计的提示生成恶意输出的越狱攻击。尽管此前已经对LLM的通用安全能力进行了研究，但它们在代码生成方面对越狱攻击的特定脆弱性在很大程度上仍未被探索。为了弥补这一空白，我们提出了MalwareBench，一个包含3,520个用于恶意代码生成的越狱提示的基准数据集，旨在评估LLM抵御此类威胁的鲁棒性。MalwareBench基于320个手工制作的恶意代码生成需求，涵盖了11种越狱方法和29种代码功能类别。实验表明，主流LLM拒绝恶意代码生成要求的能力有限，并且多种越狱方法的结合进一步降低了模型的安全能力：具体来说，恶意内容的平均拒绝率为60.93%，而当与越狱攻击算法结合时，该比率降至39.92%。我们的工作强调，LLM的代码安全能力仍然面临重大挑战。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [3] [Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models](https://arxiv.org/abs/2506.10024)
> *私有记忆编辑：将记忆转化为防御以增强大型语言模型中的数据隐私*

*Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 隐私保护, 记忆编辑, 个人身份信息, 数据安全

**Comment:** To be published at ACL 2025 (Main)

> **TL;DR:** 提出PME方法，通过编辑模型对训练数据的记忆来防止LLM泄露个人身份信息，同时不影响模型性能。

**AI_Comments:** 该研究创新性地将LLM的“记忆”这一潜在弱点转化为隐私防御的优势，提出PME方法。这种“以彼之道还施彼身”的思路非常巧妙，即利用对训练数据知识的掌握来反制隐私攻击。其重要性在于提供了一种在模型训练后进行隐私保护的有效手段，对于解决LLM在实际应用中面临的隐私合规性挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）会记忆训练数据中的个人身份信息（PII），导致隐私泄露风险。需要一种方法来防止这种泄露。

**Method:** 引入“私有记忆编辑（PME）”方法。该方法检测被记忆的PII，然后通过编辑模型对其训练数据的知识来减轻PII的记忆，从而防止隐私数据泄露。

**Result:** PME过程不影响底层语言模型。使模型对隐私训练数据提取攻击更具鲁棒性。PME能有效减少泄露的PII数量，在某些情况下甚至将隐私攻击的准确性降至零。

**Conclusion:** PME是一种有效且不损害模型性能的策略，能够将LLM的记忆能力转化为强大的隐私防御机制，显著增强数据隐私并抵御训练数据提取攻击。

> **ai_Abstract:** 本文提出了私有记忆编辑（PME）方法，旨在解决大型语言模型（LLMs）记忆并可能泄露个人身份信息（PII）的问题。PME通过检测和编辑模型对训练数据中PII的记忆来防止数据泄露。研究表明，该方法在不损害LLM性能的前提下，显著增强了模型对隐私训练数据提取攻击的鲁棒性，有效减少了PII泄露，甚至能将攻击准确性降至零，从而将LLM的记忆能力转化为一种有效的隐私防御机制。

> **摘要翻译:** 大型语言模型（LLMs）具有记忆能力，因此在大量不受控的数据中，可能会记忆个人身份信息（PII），而这些信息不应被存储，从而也不应被泄露。在本文中，我们引入了私有记忆编辑（PME），这是一种防止私人数据泄露的方法，它将一个明显的局限性，即LLM的记忆能力，转化为一种强大的隐私防御策略。虽然针对LLMs的攻击已经利用了关于其训练数据的先前知识，但我们的方法旨在利用相同类型的知识来使模型更具鲁棒性。我们检测到被记忆的PII，然后通过编辑模型对其训练数据的知识来减轻PII的记忆。我们验证了我们的程序在使其更能抵抗隐私训练数据提取攻击的同时，不影响底层语言模型。我们证明了PME可以在多种配置下有效减少泄露的PII数量，在某些情况下甚至将隐私攻击的准确性降至零。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [4] [Mind the Gap: Revealing Security Barriers through Situational Awareness of Small and Medium Business Key Decision-Makers](https://arxiv.org/abs/2506.10025)
> *关注差距：通过中小企业关键决策者的态势感知揭示安全障碍*

*Yuanhaur Chang, Oren Heller, Yaniv Shlomo, Iddo Bar-Noy, Ella Bokobza, Michal Grinstein-Weiss, Ning Zhang* | **Main category: cs.CR**

**Keywords:** 中小企业, 网络安全, 决策者, 态势感知, 结构方程模型

**Comment:** 

> **TL;DR:** 本研究通过混合方法调查中小企业关键决策者，揭示了他们在网络安全方面的认知差距和挑战，并提出了改进意识和干预措施。

**AI_Comments:** 这项研究通过结合定性和定量方法，深入分析了中小企业在网络安全决策中面临的挑战和认知差距，具有重要的实践意义。它不仅揭示了问题所在，还提出了具体的干预措施，有助于提升中小企业的整体网络安全水平。

<details>
  <summary>Details</summary>

**Motivation:** 中小企业（SMBs）的关键决策者通常缺乏有效实施网络安全措施的意识和知识。本研究旨在深入了解中小企业高管如何进行网络安全决策。

**Method:** 研究采用了混合方法，对中小企业关键决策者进行了半结构化访谈（n=21）和在线调查（n=322）。数据分析使用了主题分析法来揭示决策者对数字资产的感知风险，并利用态势感知模型来描述决策者的网络安全意识。此外，还构建了一个整体结构方程模型来理解如何提高意识。

**Result:** 研究揭示了中小企业决策者对其所重视的数字资产的感知风险，找到了他们选择防御措施的原因以及影响安全感知的因素。研究根据网络安全意识对决策者进行了分类，识别出在对抗威胁方面意识相对较低的人群。此外，还探讨了意识与业务属性之间的关系。

**Conclusion:** 本研究提出了帮助中小企业克服潜在挑战的干预措施。

> **ai_Abstract:** 本研究通过对21名中小企业关键决策者进行半结构化访谈和对322名决策者进行在线调查，采用混合方法深入探讨了中小企业高管在网络安全决策中的现状。研究运用主题分析揭示了决策者对数字资产的风险感知、防御措施选择原因及安全感知影响因素。通过态势感知模型识别出网络安全意识较低的决策者，并构建结构方程模型分析意识提升途径。最终，研究提出了帮助中小企业克服网络安全障碍的干预措施。

> **摘要翻译:** 中小企业（SMBs）的关键决策者通常缺乏有效实施网络安全措施的意识和知识。为了更深入地了解中小企业高管如何进行网络安全决策，我们采用了混合方法，对中小企业关键决策者进行了半结构化访谈（n=21）和在线调查（n=322）。通过主题分析，我们揭示了中小企业决策者对其所重视的数字资产的感知风险，并找到了他们选择防御措施的原因以及影响安全感知的因素。我们采用态势感知模型根据网络安全意识对决策者进行了特征描述，识别出在对抗威胁方面意识相对较低的人群。我们进一步探讨了意识与业务属性之间的关系，并构建了一个整体结构方程模型来理解如何提高意识。最后，我们提出了帮助中小企业克服潜在挑战的干预措施。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [31] [Secure Data Access in Cloud Environments Using Quantum Cryptography](https://arxiv.org/abs/2506.10028)
> *在云环境中利用量子密码学实现安全数据访问*

*S. Vasavi Venkata Lakshmi, Ziaul Haque Choudhury* | **Main category: cs.CR**

**Keywords:** 量子密码学, 云计算安全, 量子密钥分发, BB84协议, 量子一次性密码

**Comment:** 

> **TL;DR:** 本研究提出并演示了如何使用量子密码学（结合量子密钥分发BB84协议和量子一次性密码QOTP）来保护云数据，以抵御当前和未来的量子计算机威胁。

**AI_Comments:** 本文提出了一种前瞻性的解决方案，通过引入量子密码学来应对未来量子计算对传统加密方法的威胁。其创新之处在于将量子密钥分发（QKD）与量子一次性密码（QOTP）相结合，形成一个端到端的量子安全数据保护框架。这种方法理论上提供了无条件的安全保障，对于长期数据安全至关重要。然而，实际部署的复杂性、成本以及量子设备的成熟度是其潜在的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 随着云计算的普及，数据存储和访问变得便捷，但数据安全面临巨大挑战。传统的数据加密方法在面对未来强大的量子计算机时可能不再安全。因此，需要一种更强大的方法来确保存储在云中的数据安全。

**Method:** 本研究采用量子密码学来保护云环境中的数据。具体方法包括：1. 使用量子密钥分发（QKD），通过量子粒子（如光子）发送信息来创建安全密钥。2. 密钥生成采用BB84协议，这是一种简单可靠且能检测窃听的密钥生成方式。3. 数据加密和解密使用量子一次性密码（QOTP），以确保数据的完全隐私。

**Result:** 本研究展示了如何将量子密钥分发（QKD）和量子一次性密码（QOTP）等量子方法应用于云系统，以提供强大的防御，抵御包括拥有量子计算机的黑客在内的攻击。QKD、BB84和QOTP的结合为云中存储或共享数据提供了一种安全可靠的保护方式。

**Conclusion:** 通过结合量子密钥分发（QKD）的BB84协议和量子一次性密码（QOTP），本研究提供了一种确保云数据在当前和未来安全的方法，使云计算对所有人来说都更安全可靠。

> **ai_Abstract:** 本研究旨在解决云计算中日益增长的数据安全挑战，特别是面对未来量子计算机的威胁。论文提出并演示了一种基于量子密码学的数据保护方案，该方案结合了量子密钥分发（QKD）的BB84协议用于安全密钥生成，以及量子一次性密码（QOTP）用于数据加密和解密。研究结果表明，这种整合方法能够为云数据提供强大的、量子安全的保护，确保数据在当前和未来的隐私性和安全性。

> **摘要翻译:** 云计算使得数据存储和访问变得更加便捷，但确保其安全性如今是一个巨大的挑战。当强大的量子计算机问世时，传统的确保数据安全的方法在未来可能不够强大。为了解决这个问题，本研究利用量子密码学来保护云环境中的数据。量子密钥分发（QKD）通过使用量子粒子（如光子）发送信息来创建安全密钥。具体来说，我们使用BB84协议，这是一种简单可靠的生成安全密钥的方法，且在不被发现的情况下无法被窃取。为了保护数据，我们使用量子一次性密码（QOTP）进行加密和解密，确保数据完全私密。本研究展示了这些量子方法如何应用于云系统，以提供强大的防御，抵御黑客攻击，即使他们可以使用量子计算机。QKD、BB84和QOTP的结合创造了一种安全可靠的方式，可以在数据存储或共享在云中时保持其安全。通过使用量子密码学，本文提供了一种确保数据当前和未来安全的方法，使云计算对每个人来说都更安全地存储他们的数据。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [57] [Evaluation empirique de la sécurisation et de l'alignement de ChatGPT et Gemini: analyse comparative des vulnérabilités par expérimentations de jailbreaks](https://arxiv.org/abs/2506.10029)
> *ChatGPT和Gemini安全与对齐的实证评估：通过越狱实验进行的漏洞比较分析*

*Rafaël Nouailles* | **Main category: cs.CR**

**Keywords:** ChatGPT, Gemini, LLMs, 安全性, 越狱, 漏洞分析

**Comment:** in French language

> **TL;DR:** 本文通过越狱实验对ChatGPT和Gemini的安全性和对齐水平进行了比较分析，并提出了越狱技术的分类。

**AI_Comments:** 本研究通过对ChatGPT和Gemini进行越狱实验，对LLMs的安全性和对齐问题进行了实证分析，尤其关注了越狱漏洞。其创新点在于提出了越狱技术的分类，这对于理解和缓解LLMs的安全风险具有重要意义，为未来的模型加固和安全研究提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正在改变数字使用，但随之带来了新的网络安全挑战，包括提示注入攻击、规避监管措施（越狱）、错误信息传播和深度伪造风险。因此，有必要对ChatGPT和Gemini等主流LLMs的安全性及对齐水平进行评估。

**Method:** 本文对ChatGPT和Gemini的安全性和对齐水平进行了比较分析，并通过越狱实验来评估漏洞，同时提出了越狱技术的分类。

**Result:** 本文提出了与实验相关的越狱技术分类，并对ChatGPT和Gemini的安全和对齐水平进行了比较分析。具体的比较分析结果未在摘要中详细说明。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 大型语言模型（LLMs）如ChatGPT和Gemini正在重塑数字应用，但同时也引发了严重的网络安全问题，例如提示注入攻击和越狱。本文旨在通过一系列越狱实验，对ChatGPT和Gemini这两种主流LLMs的安全性与对齐水平进行实证比较分析，并在此基础上提出越狱技术的分类体系。

> **摘要翻译:** 大型语言模型（LLM）正在改变数字使用，特别是在文本生成、图像创建、信息检索和代码开发方面。OpenAI于2022年11月推出的ChatGPT迅速成为一个标杆，促使了谷歌Gemini等竞争对手的出现。然而，这些技术进步带来了新的网络安全挑战，包括提示注入攻击、规避监管措施（越狱）、错误信息传播（幻觉）以及与深度伪造相关的风险。本文对ChatGPT和Gemini的安全性和对齐水平进行了比较分析，并提出了与实验相关的越狱技术分类。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [83] [Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment](https://arxiv.org/abs/2506.10030)
> *RAG即服务环境中多模态知识版权保护*

*Tianyu Chen, Jian Lou, Wenjie Wang* | **Main category: cs.CR**

**Keywords:** 多模态RAG, 版权保护, 水印, 图像知识, AQUA

**Comment:** 

> **TL;DR:** AQUA是首个针对多模态RAG系统中图像知识版权保护的水印框架，通过嵌入语义信号到合成图像中，实现高效、有效且不可感知的版权追踪。

**AI_Comments:** 该论文的创新点在于首次提出了针对多模态RAG系统中图像知识版权保护的水印框架AQUA，解决了现有水印技术仅限于文本的局限性。其提出的基于语义信号的嵌入方法，尤其是在图像检索到文本生成器这种间接传播链条中的水印生存能力，展现了技术深度和实用价值。这对于RAG-as-a-Service环境下知识产权保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着检索增强生成（RAG）发展为共享知识库的服务导向平台（RAG即服务），保护贡献数据的版权变得至关重要。现有RAG中的水印方法仅专注于文本知识，图像知识仍未受保护。

**Method:** 本文提出了AQUA，这是首个用于多模态RAG系统中图像知识保护的水印框架。AQUA通过两种互补方法将语义信号嵌入到合成图像中：基于首字母缩略词的触发器和空间关系线索。这些技术确保水印信号能从图像检索器间接传播到文本生成器，且高效、有效且不可感知。

**Result:** 在不同的模型和数据集上的实验表明，AQUA能够实现鲁棒、隐蔽和可靠的版权追踪。

**Conclusion:** AQUA填补了多模态RAG保护中图像知识版权保护的关键空白，是首个针对此问题的水印框架。

> **ai_Abstract:** 本文提出了AQUA，一个开创性的水印框架，旨在解决RAG即服务环境中多模态知识（特别是图像知识）的版权保护问题。针对现有水印方法仅限于文本的局限性，AQUA通过在合成图像中嵌入基于首字母缩略词的触发器和空间关系线索等语义信号，实现了对图像知识的版权追踪。实验证明，AQUA在多样化的模型和数据集上表现出鲁棒、隐蔽且可靠的性能，有效填补了多模态RAG版权保护的空白。

> **摘要翻译:** 随着检索增强生成（RAG）发展为共享知识库的服务导向平台（RAG即服务），保护贡献数据的版权变得至关重要。现有RAG中的水印方法仅专注于文本知识，图像知识仍未受保护。本文提出了AQUA，这是首个用于多模态RAG系统中图像知识保护的水印框架。AQUA通过两种互补方法将语义信号嵌入到合成图像中：基于首字母缩略词的触发器和空间关系线索。这些技术确保水印信号能从图像检索器间接传播到文本生成器，且高效、有效且不可感知。在不同的模型和数据集上的实验表明，AQUA能够实现鲁棒、隐蔽和可靠的版权追踪，填补了多模态RAG保护中的一个关键空白。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [109] [Symbolic Generation and Modular Embedding of High-Quality abc-Triples](https://arxiv.org/abs/2506.10039)
> *高质量abc三元组的符号生成与模块化嵌入*

*Michael A. Idowu* | **Main category: cs.CR**

**Keywords:** abc三元组, 符号生成, 模块化嵌入, 根值, 密码学

**Comment:** 17 pages, includes tables and illustrative examples; discusses
  symbolic generation of abc-triples and applications in entropy filtering and
  cryptographic pre-processing

> **TL;DR:** 本文提出了一种符号恒等式和模块化嵌入方法，用于生成具有低根值的高质量abc三元组，并展示了结构化的、最小化根值的候选三元组。

**AI_Comments:** 该论文为abc三元组的生成提供了一种创新的符号和代数方法，这对于数论以及潜在的密码学，特别是预处理任务，都具有重要意义。专注于最小化根值是其关键贡献。

<details>
  <summary>Details</summary>

**Motivation:** 受abc猜想结构特征的启发，以及对可控生成具有低根值的三元组的需求，可能应用于密码学预处理。

**Method:** 提出了一种用于生成满足a + b = c的整数三元组(a, b, c)的符号恒等式。该构造结合了2和3的幂次以及在Z/3^pZ中的模逆运算，从而得到一个带有余数约束的参数恒等式。通过仿射变换，这些符号三元组被嵌入到一个更广阔的高质量示例空间中，并针对比率log c / log rad(abc)进行了优化。

**Result:** 产生了具有低根值的abc三元组。计算结果表明，出现了结构化的、根值最小化的候选三元组，包括已知和新颖的三元组。

**Conclusion:** 这些方法为可控的三元组生成提供了一个符号和代数框架，并暗示了符号熵过滤在密码学预处理中的探索性应用。

> **ai_Abstract:** 本文提出了一种符号恒等式和模块化嵌入技术，用于生成高质量的abc三元组。该方法通过结合2和3的幂次与模逆运算，并通过仿射变换，生成具有低根值的三元组，并针对log c / log rad(abc)比率进行优化。计算结果表明，该方法能够生成结构化的、根值最小化的三元组，包括新的示例，为受控的三元组生成提供了一个框架，并可能应用于密码学预处理。

> **摘要翻译:** 我们提出了一种用于生成满足a + b = c的整数三元组(a, b, c)的符号恒等式，其灵感来源于abc猜想的结构特征。该构造结合了2和3的幂次以及在Z/3^pZ中的模逆运算，从而得到一个带有余数约束的参数恒等式，该恒等式产生具有低根值的abc三元组。通过仿射变换，这些符号三元组被嵌入到一个更广阔的高质量示例空间中，并针对比率log c / log rad(abc)进行了优化。计算结果表明，出现了结构化的、根值最小化的候选三元组，包括已知和新颖的三元组。这些方法为可控的三元组生成提供了一个符号和代数框架，并暗示了符号熵过滤在密码学预处理中的探索性应用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [132] [Multiverse Privacy Theory for Contextual Risks in Complex User-AI Interactions](https://arxiv.org/abs/2506.10042)
> *多重宇宙隐私理论：复杂用户-AI交互中的情境风险*

*Ece Gumusel* | **Main category: cs.CR**

**Keywords:** 多重宇宙隐私理论, AI交互, 情境风险, 隐私决策, 平行宇宙

**Comment:** 5 pages, 1 figure, 1 table

> **TL;DR:** 提出多重宇宙隐私理论，通过模拟平行宇宙理解用户在AI交互中的隐私决策。

**AI_Comments:** 该论文引入了一个高度创新的概念框架（多重宇宙隐私理论），以解决AI交互中隐私的复杂和动态性质。其优势在于提供了一个新颖的视角（平行宇宙）来建模不断演变的用户偏好和概率结果，超越了静态隐私模型。其重要性在于为理解情境隐私风险提供了一个基础理论。一个限制是，它目前是一个理论框架，实际应用和验证留待未来的工作。

<details>
  <summary>Details</summary>

**Motivation:** 在与人工智能（AI）交互日益增多的时代，用户面临由复杂、不确定因素塑造的不断演变的隐私决策。

**Method:** 本文引入了多重宇宙隐私理论，这是一个新颖的框架，其中每个隐私决策都会产生一个平行宇宙，代表基于用户随时间选择的不同潜在结果。通过模拟这些宇宙，该理论得以构建。

**Result:** 该理论为通过情境完整性、不断演变的偏好和概率决策的视角理解隐私提供了基础。

**Conclusion:** 未来的工作将探索该理论在真实世界、基于场景的调查数据中的应用。

> **ai_Abstract:** 本文提出多重宇宙隐私理论，这是一个理解复杂AI交互中用户隐私决策的新颖框架。它将每个隐私选择建模为创建一个具有不同结果的平行宇宙，从而能够通过情境完整性、不断演变的偏好和概率决策来研究隐私。未来的工作将把该理论应用于真实世界数据。

> **摘要翻译:** 在与人工智能（AI）交互日益增多的时代，用户面临由复杂、不确定因素塑造的不断演变的隐私决策。本文引入了多重宇宙隐私理论，这是一个新颖的框架，其中每个隐私决策都会产生一个平行宇宙，代表基于用户随时间选择的不同潜在结果。通过模拟这些宇宙，该理论为通过情境完整性、不断演变的偏好和概率决策的视角理解隐私提供了基础。未来的工作将探索其在真实世界、基于场景的调查数据中的应用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [152] [GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models](https://arxiv.org/abs/2506.10047)
> *GenBreak：使用大型语言模型对文本到图像生成器进行红队测试*

*Zilong Wang, Xiang Zheng, Xiaosen Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang* | **Main category: cs.CR**

**Keywords:** 红队测试, 文本到图像生成器, 大型语言模型, 安全漏洞, 对抗性提示

**Comment:** 27 pages, 7 figures

> **TL;DR:** GenBreak是一个利用大型语言模型对文本到图像生成器进行红队测试的框架，旨在发现其潜在的安全漏洞，生成既能绕过安全过滤器又具有高毒性的图像。

**AI_Comments:** GenBreak的创新之处在于利用LLM的强大能力来自动化和系统化红队测试过程，超越了传统方法在生成高毒性且难以检测的对抗性提示方面的局限性。其结合监督学习和强化学习的方法，以及多重奖励信号的设计，有效地平衡了规避能力、图像毒性和语义连贯性，为评估T2I模型安全性提供了一个实用且高效的工具。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像（T2I）模型尽管广泛应用于内容创作，但存在生成有害内容的风险。现有红队测试方法在生成高毒性图像或绕过安全机制方面存在局限性，导致缺乏评估已防御T2I模型安全性的可靠工具。

**Method:** 我们提出了GenBreak框架，该框架通过在精选数据集上进行监督微调，并通过与替代T2I模型的交互进行强化学习，来微调一个红队大型语言模型（LLM）。通过整合多个奖励信号，引导LLM生成既能增强规避能力又能提高图像毒性，同时保持语义连贯性和多样性的对抗性提示。

**Result:** 这些对抗性提示在针对商业T2I生成器的黑盒攻击中表现出强大的有效性，揭示了实际且令人担忧的安全弱点。

**Conclusion:** GenBreak框架通过结合监督微调和强化学习，成功地利用大型语言模型发现了文本到图像生成器的安全漏洞，生成了既能规避安全过滤器又具有高毒性的对抗性提示，为评估T2I模型的安全性提供了可靠的工具。

> **ai_Abstract:** GenBreak是一个利用大型语言模型（LLM）进行红队测试的框架，旨在系统性地发现文本到图像（T2I）生成器的安全漏洞。通过结合监督微调和强化学习，GenBreak训练LLM生成既能规避现有安全过滤器又能产生高毒性图像的对抗性提示，从而有效揭示商业T2I模型的实际安全弱点。

> **摘要翻译:** 文本到图像（T2I）模型如Stable Diffusion发展迅速，现已广泛应用于内容创作。然而，这些模型可能被滥用以生成有害内容，包括裸露或暴力，带来重大的安全风险。尽管大多数平台采用内容审核系统，但潜在的漏洞仍可能被有决心的对手利用。最近针对T2I模型的红队测试和对抗性攻击研究存在显著局限性：一些研究成功生成了高毒性图像，但使用了容易被安全过滤器检测和阻止的对抗性提示；而另一些研究则专注于绕过安全机制，但未能产生真正有害的输出，忽视了发现真正高风险提示。因此，目前仍然缺乏评估已防御T2I模型安全性的可靠工具。为了解决这一空白，我们提出了GenBreak，一个微调红队大型语言模型（LLM）以系统地探索T2I生成器潜在漏洞的框架。我们的方法将精选数据集上的监督微调与通过与替代T2I模型交互的强化学习相结合。通过整合多个奖励信号，我们引导LLM制作对抗性提示，以增强规避能力和图像毒性，同时保持语义连贯性和多样性。这些提示在针对商业T2I生成器的黑盒攻击中表现出强大的有效性，揭示了实际且令人担忧的安全弱点。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [172] [Expert-in-the-Loop Systems with Cross-Domain and In-Domain Few-Shot Learning for Software Vulnerability Detection](https://arxiv.org/abs/2506.10104)
> *专家在环系统中，结合跨领域和领域内小样本学习进行软件漏洞检测*

*David Farr, Kevin Talty, Alexandra Farr, John Stockdale, Iain Cruickshank, Jevin West* | **Main category: cs.CR**

**Keywords:** 软件漏洞检测, 大型语言模型, 小样本学习, 专家在环, 网络安全

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）结合小样本学习和专家在环系统显著提升了软件漏洞检测的效率和准确性，但仍面临可靠性和可解释性等挑战。

**AI_Comments:** 本文通过将大型语言模型与专家在环系统相结合，为软件漏洞检测提供了一种创新方法，优化了自动化与人工监督之间的平衡。其中，基于置信度的路由策略是提高效率的关键创新点。尽管研究展示了小样本学习在泛化方面的潜力，但作者坦诚地指出了模型可靠性和可解释性等关键局限性，为未来的研究指明了清晰的方向。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于网络威胁日益复杂，快速准确的漏洞检测对于维护系统安全至关重要。本研究旨在探索大型语言模型（LLMs）在软件漏洞评估中的应用，以期增强操作弹性并减轻人类分析师的负担。

**Method:** 本研究通过模拟识别带有已知通用弱点枚举（CWEs）的Python代码，评估了大型语言模型（LLMs）在软件漏洞检测中的应用。具体方法包括比较零样本、跨领域小样本和领域内小样本提示策略，并整合基于置信度的路由策略，以实现专家在环（EITL）决策，将人类专家引导至模型不确定性高的案例。

**Result:** 研究结果显示，零样本提示表现不佳，而小样本提示显著提高了分类性能。特别是结合基于置信度的路由策略后，效率得到了提升。此外，LLMs能够通过少量示例有效泛化到不同的漏洞类别。

**Conclusion:** 将AI驱动的方法与专家在环（EITL）决策相结合，为实现更高效、更具响应性的网络安全工作流程提供了途径。本研究的发现为在真实和模拟环境中部署AI辅助漏洞检测系统奠定了基础，这些系统能够增强操作弹性，同时减轻人类分析师的负担。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在软件漏洞检测中的应用，通过模拟Python代码漏洞识别，比较了零样本、跨领域小样本和领域内小样本提示策略。研究发现，小样本方法，特别是结合基于置信度的路由策略以实现专家在环系统时，能显著提高性能和效率。论文强调了LLMs在网络安全领域泛化和可扩展性的潜力，同时也指出了模型可靠性和可解释性等挑战。该工作提出了一种AI与专家相结合的方法，旨在提升网络安全工作流程的效率和响应性。

> **摘要翻译:** 随着网络威胁日益复杂，快速准确的漏洞检测对于维护系统安全至关重要。本研究通过模拟识别带有已知通用弱点枚举（CWEs）的Python代码，探讨了大型语言模型（LLMs）在软件漏洞评估中的应用，并比较了零样本、跨领域小样本和领域内小样本提示策略。我们的结果表明，零样本提示表现不佳，而小样本提示显著提高了分类性能，尤其是在与基于置信度的路由策略结合时，通过将人类专家引导至模型不确定性高的案例，提高了效率，优化了自动化与专家监督之间的平衡。我们发现LLMs可以通过少量示例有效泛化到不同的漏洞类别，这表明它们在模拟环境中作为可扩展、适应性强的网络安全工具的潜力。然而，模型可靠性、可解释性和对抗鲁棒性等挑战仍然是未来研究的关键领域。通过将AI驱动的方法与专家在环（EITL）决策相结合，这项工作指明了一条通向更高效、更具响应性的网络安全工作流程的路径。我们的发现为在真实和模拟环境中部署AI辅助漏洞检测系统奠定了基础，这些系统能够增强操作弹性，同时减轻人类分析师的负担。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [187] [D-LiFT: Improving LLM-based Decompiler Backend via Code Quality-driven Fine-tuning](https://arxiv.org/abs/2506.10125)
> *D-LiFT：通过代码质量驱动的微调改进基于LLM的反编译器后端*

*Muqi Zou, Hongyu Cai, Hongwei Wu, Zion Leonahenahe Basque, Arslan Khan, Berkay Celik, Dave, Tian, Antonio Bianchi, Ruoyu, Wang, Dongyan Xu* | **Main category: cs.CR**

**Keywords:** LLM, 反编译器, 代码质量, 微调, 强化学习

**Comment:** 

> **TL;DR:** D-LiFT通过新颖的、保持准确性的代码质量评估系统（D-SCORE）对LLM进行微调，从而提高了基于LLM的反编译器的输出质量。

**AI_Comments:** 创新点：D-LiFT引入了一种新颖的、保持准确性的质量评估系统（D-SCORE），用于反编译中LLM的微调，这对于准确性至关重要。使用自定义评分系统通过强化学习微调LLM的方法也具有创新性。重要性：反编译器对安全任务至关重要，提高其输出质量，特别是结合LLM，可以显著增强逆向工程和漏洞分析。解决准确性保持问题非常重要。局限性：摘要中没有明确提及除了它所解决的（先前工作的局限性）之外的局限性。它主要侧重于积极的成果。

<details>
  <summary>Details</summary>

**Motivation:** 反编译器输出存在语法和语义错误且难以阅读。虽然最近基于大型语言模型（LLM）的方法试图改进反编译输出，但它们引入新错误且依赖不可靠的准确性验证。

**Method:** D-LiFT是一个自动化的反编译器后端，通过强化学习进一步训练大型语言模型（LLM）以提高反编译代码质量。它提出了D-SCORE，一个集成的质量评估系统，该系统首先通过编译器和符号执行验证语法和语义正确性，然后评估可读性。D-SCORE将低分分配给不准确的输出，并仅在通过准确性检查后才为可读性授予高分。分数随后反馈给LLM进行微调。

**Result:** D-LiFT在coreutils和util-linux项目中对准确的反编译代码显示出显著改进。与没有D-SCORE驱动微调的基线LLM相比，D-LiFT产生的改进反编译函数增加了55.3%（通过D-SCORE衡量）。

**Conclusion:** D-LiFT通过优先确保准确性同时提高可读性的代码质量驱动微调方法，有效改进了基于LLM的反编译器后端，并通过D-SCORE得到了验证。

> **ai_Abstract:** D-LiFT是一个自动化的反编译器后端，旨在提高LLM生成的反编译代码的质量。它通过提出一个新颖的强化学习框架来解决现有基于LLM方法的局限性，该框架基于一个名为D-SCORE的多方面质量评估系统对LLM进行微调。D-SCORE通过优先验证语法和语义正确性，然后再评估可读性，从而确保准确性。实验结果表明，与基线LLM相比，D-LiFT显著增加了改进反编译函数的比例。

> **摘要翻译:** 反编译器，将二进制可执行文件重构为人类可读的源代码，对许多安全任务至关重要。然而，尽管最近取得了进展，其输出仍常遭受语法和语义错误，并且难以阅读。最近，随着大型语言模型（LLM）的出现，研究人员开始探索LLM改进反编译器输出的潜力。然而，我们对这些方法的研究揭示了显著的局限性，例如引入新错误和依赖不可靠的准确性验证。在本文中，我们提出了D-LiFT，一个自动化的反编译器后端，它利用并进一步训练LLM，通过强化学习（RL）提高反编译代码的质量。与先前忽视保持准确性的工作不同，D-LiFT遵循一个提高反编译代码质量的关键原则：在提高可读性的同时保持准确性。D-LiFT的核心是我们提出了D-SCORE，一个集成的质量评估系统，从多个方面对反编译代码进行评分。根据我们的原则，D-SCORE对任何不准确的输出分配低分，并且只对通过准确性检查的代码授予更高的可读性分数。具体而言，D-SCORE首先通过编译器和符号执行验证语法和语义正确性；只有当候选代码被认为是准确的，它才会使用既定指标评估可读性，将LLM输出与原始反编译代码进行比较。然后将分数反馈给LLM进行微调。我们基于Ghidra和一系列LLM的实现表明，coreutils和util-linux项目中准确的反编译代码质量得到了显著改进。与没有D-SCORE驱动微调的基线LLM相比，D-LiFT产生的改进反编译函数增加了55.3%，这是通过D-SCORE衡量的。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [192] [Guardians of the Regime: When and Why Autocrats Create Secret Police](https://arxiv.org/abs/2506.10194)
> *政权的守护者：独裁者何时以及为何创建秘密警察*

*Marius Mehrl, Mila Pfander, Theresa Winner, Cornelius Fritz* | **Main category: cs.CR**

**Keywords:** 独裁者, 秘密警察, 威权主义, 制度选择, 威胁

**Comment:** 

> **TL;DR:** 秘密警察并非在所有独裁政权中普遍存在。本研究探讨了秘密警察在独裁政权中出现的条件：当统治者面临可预防的特定威胁（如抗议和反体制动员）且拥有建立这些组织所需的物质资源时，秘密警察更可能出现。

**AI_Comments:** 这篇论文的创新之处在于，它挑战了秘密警察在独裁政权中普遍存在的假设，并深入探讨了其出现的具体条件。通过识别威胁类型和物质资源作为关键因素，该研究为理解独裁者的制度选择提供了新的视角，对威权政治研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明秘密警察在维持独裁统治方面非常有效，但令人惊讶的是，它们在独裁政权中并非普遍存在（存在于不到50%的独裁国家-年份中）。因此，本研究旨在探究秘密警察在独裁政权中出现的条件。

**Method:** 本研究运用统计变量选择技术，从关于国家安全部队和威权生存的文献中提取了几个候选变量，以识别哪些变量具有解释力。

**Result:** 研究结果表明，当统治者面临特定的、可预防的威胁（如抗议和反体制动员），并且拥有建立这些组织所需的物质资源时，秘密警察更有可能出现。

**Conclusion:** 这项研究有助于我们理解独裁者的制度选择和威权政治。

> **ai_Abstract:** 本研究旨在探究秘密警察在独裁政权中出现的条件，因为尽管它们在维护统治方面有效，但并非普遍存在。通过应用统计变量选择技术，研究发现秘密警察更有可能在独裁者面临特定、可预防的威胁（如抗议）且具备必要物质资源时建立。这项工作加深了对独裁者制度选择和威权政治的理解。

> **摘要翻译:** 独裁者利用秘密警察来维持权力，因为这些组织能够威慑和镇压对其统治的反对。现有研究表明，秘密警察在这方面非常有效，但令人惊讶的是，它们在独裁政权中并非如人们想象的那样普遍，存在于不到50%的独裁国家-年份中。因此，我们探讨了秘密警察在独裁统治下出现的条件。为此，我们运用统计变量选择技术，从关于国家安全部队和威权生存的文献中提取了几个候选变量，以识别哪些变量具有解释力。我们的结果强调，当统治者面临特定的、可预防的威胁（如抗议和反体制动员），并且拥有建立这些组织所需的物质资源时，秘密警察更有可能出现。这项研究有助于我们理解独裁者的制度选择和威权政治。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [201] [Unconditionally Secure Wireless-Wired Ground-Satellite-Ground Communication Networks Utilizing Classical and Quantum Noise](https://arxiv.org/abs/2506.10147)
> *利用经典和量子噪声的无条件安全无线-有线地-星-地通信网络*

*Lucas Truax, Sandip Roy, Laszlo B. Kish* | **Main category: cs.CR**

**Keywords:** KLJN, 无条件安全, 卫星通信, 量子密钥分发, 经典噪声

**Comment:** 

> **TL;DR:** 本文提出并探讨了 Kirchhoff-Law-Johnson-Noise (KLJN) 作为一种无条件安全卫星通信的替代方案，与量子密钥分发 (QKD) 相比，KLJN 更简单、成本更低、更具弹性。

**AI_Comments:** 该论文提出KLJN作为QKD的替代方案，其创新之处在于利用经典物理噪声实现无条件安全，并强调了其在成本、复杂性和环境适应性方面的优势。这对于推动卫星通信安全具有重要意义，尤其是在资源受限或环境恶劣的场景下。论文强调了KLJN与现有基础设施的兼容性，这表明其具有较高的实用性和部署潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前卫星通信面临高级计算威胁（包括量子计算）带来的漏洞，需要实现无条件安全的通信。现有的量子密钥分发（QKD）方案存在复杂、脆弱、昂贵等问题，因此需要探索更实用、成本效益更高的替代方案。

**Method:** 本文引入并分析了 Kirchhoff-Law-Johnson-Noise (KLJN) 方案，并将其与量子密钥分发（QKD）方案进行了比较，以评估两者在空间系统中的潜在应用。研究着重于KLJN方案在安全性、成本、复杂性和环境适应性方面的优势。

**Result:** 研究发现，KLJN方案利用经典物理原理，提供了一种比QKD更简单、更经济、更具弹性的替代方案，尤其适用于地面系统。KLJN对环境和辐射引起的噪声不敏感，且能与现有基础设施无缝集成，展现出在无条件安全通信方面的显著优势。

**Conclusion:** KLJN方案在简便性、成本效益和鲁棒性方面具有显著优势，使其成为许多安全通信应用的实用选择，是确保安全、有弹性卫星通信的革命性替代方案。

> **ai_Abstract:** 本文提出了一种名为基尔霍夫定律-约翰逊噪声（KLJN）的新方法，旨在解决卫星通信中的无条件安全问题。与复杂的量子密钥分发（QKD）不同，KLJN利用经典物理原理和标准电子元件，具有成本效益高、简单、鲁棒性强且抗环境噪声的特点。研究比较了KLJN和QKD，认为KLJN在确保地对星通信网络的无条件安全方面具有显著优势，尤其是在应对量子计算等高级威胁时，是更实用和可行的选择。

> **摘要翻译:** 在本文中，我们引入了基尔霍夫定律-约翰逊噪声（KLJN）作为一种保障卫星通信安全的方法。KLJN凭借其简单性、成本效益和弹性与无条件安全性相结合的特点，有望彻底改变卫星通信安全。与需要光子探测器和专用光链路等复杂、脆弱且昂贵基础设施的量子密钥分发（QKD）不同，KLJN使用标准的电子元件和电线运行，显著降低了实施成本和物流障碍。KLJN的安全性基于经典物理学的基本定律，不受环境和辐射引起的噪声影响，使其在卫星通信的恶劣条件下高度可靠。这种鲁棒性，加上其与现有基础设施无缝集成的能力，使KLJN成为量子解决方案的革命性替代方案，以确保安全、有弹性的卫星通信。作者探讨了在战略性地对星网络中实现无条件安全通信的价值，该网络解决了包括量子计算在内的高级计算威胁所带来的漏洞。我们的团队研究了两种领先的无条件安全方法——KLJN方案和QKD——并分析了它们各自在空间系统中的潜在用途。虽然QKD利用量子力学实现安全，但它面临着成本、复杂性和环境敏感性方面的挑战。相比之下，KLJN方案利用经典物理原理提供了一种更简单、更具成本效益和更具弹性的替代方案，特别是对于地面系统。研究得出结论，KLJN在简单性、成本效益和鲁棒性方面具有显著优势，使其成为许多安全通信应用的实用选择。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [206] [Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods](https://arxiv.org/abs/2506.10236)
> *提示攻击揭示了反学习方法中肤浅的知识清除*

*Yeonwoo Jang, Shariqah Hossain, Ashwin Sreevatsa, Diogo Cruz* | **Main category: cs.CR**

**Keywords:** 机器反学习, 提示攻击, 知识清除, 模型评估, 鲁棒性

**Comment:** 20 pages, 6 figures

> **TL;DR:** 研究发现，一些机器反学习方法在面对直接提示攻击时会失效，揭示了知识清除可能只是表面现象，而非真正的移除。

**AI_Comments:** 这项工作揭示了当前机器反学习方法的一个重要漏洞，即它们可能只实现了表面上的知识抑制而非真正的删除。其创新之处在于引入了“提示攻击”作为一种有效的评估手段，并系统地评估了多种现有方法。研究结果对于推动更鲁棒的反学习技术发展具有重要意义，并强调了未来研究应关注更深层次的知识清除机制。公开评估框架的举动也促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 旨在揭示某些机器反学习方法在面对直接提示攻击时可能失效，挑战了关于反学习有效性的现有假设。

**Method:** 系统评估了八种反学习技术，涵盖三种模型家族。采用了基于输出、基于logit和探测分析的方法来确定被认为已清除的知识在多大程度上可以被检索。

**Result:** RMU和TAR等方法表现出鲁棒的反学习能力，而ELM仍然容易受到特定提示攻击（例如，原始提示中的印地语填充文本可恢复57.3%的准确率）。Logit分析证实，反学习模型通常不会通过修改答案格式来隐藏知识，因为输出和logit准确性之间存在很强的相关性。

**Conclusion:** 研究结果挑战了关于反学习有效性的普遍假设，并强调需要能够可靠区分真正知识清除和表面输出抑制的评估框架。

> **ai_Abstract:** 本文研究了机器反学习方法的有效性，发现某些方法在面对简单的提示攻击时会失败，未能真正清除知识。研究人员系统评估了八种反学习技术，并通过输出、logit和探测分析发现，尽管一些方法如RMU和TAR表现良好，但ELM等方法仍易受攻击，例如通过特定提示可恢复高达57.3%的准确率。研究强调了区分真正知识移除和表面抑制的重要性，并提供了一个评估框架。

> **摘要翻译:** 在这项工作中，我们展示了一些机器反学习方法在受到直接提示攻击时可能会失败。我们系统地评估了三种模型家族中的八种反学习技术，并采用基于输出、基于logit和探测分析的方法来确定被认为已清除的知识在多大程度上可以被检索。虽然RMU和TAR等方法表现出鲁棒的反学习能力，但ELM仍然容易受到特定提示攻击（例如，原始提示中的印地语填充文本可恢复57.3%的准确率）。我们的logit分析也证实，反学习模型通常不会通过修改答案格式来隐藏知识，因为输出和logit准确性之间存在很强的相关性。这些结果挑战了关于反学习有效性的普遍假设，并强调了需要能够可靠区分真正知识清除和表面输出抑制的评估框架。我们还公开提供了我们的评估框架，以便轻松评估检索反学习知识的提示技术。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [218] [Disclosure Audits for LLM Agents](https://arxiv.org/abs/2506.10171)
> *大型语言模型代理的披露审计*

*Saswat Das, Jameson Sandler, Ferdinando Fioretto* | **Main category: cs.CR**

**Keywords:** LLM代理, 隐私, 审计框架, 会话隐私, CMPL

**Comment:** 

> **TL;DR:** 本文提出了一种名为CMPL的审计框架，通过模拟多轮交互来发现大型语言模型代理中的隐私漏洞，并证明其比现有的单轮防御更有效。

**AI_Comments:** 这篇论文解决了LLM代理中隐私这一关键且及时的问题，该问题在敏感领域越来越突出。其创新之处在于采用多轮交互模拟（CMPL），这是一种比单轮防御更真实有效的方法。提供可量化风险指标和开放基准是对该领域的宝贵贡献，有助于推动安全LLM代理部署的进一步研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型代理在处理敏感数据时存在未经授权披露的风险，尽管它们带来了显著的运营效益。因此，需要一个框架来量化和审计这些隐私风险。

**Method:** 本文提出了会话操纵隐私泄漏（CMPL）框架，这是一种迭代探测策略，通过模拟真实的多轮交互来对执行严格隐私指令的代理进行压力测试，以系统地发现潜在漏洞。此外，论文还引入了基于可量化风险指标的审计程序和一个开放的会话隐私评估基准。

**Result:** 评估结果表明，该审计框架能够揭示现有单轮防御无法阻止的隐私风险。

**Conclusion:** 本文介绍了CMPL作为一种诊断工具，并提供了一个基于可量化风险指标的审计程序以及一个用于评估不同代理实现中会话隐私的开放基准。

> **ai_Abstract:** 本文提出了会话操纵隐私泄漏（CMPL）框架，这是一种迭代探测策略，旨在审计大型语言模型（LLM）代理中的隐私风险。与单轮防御不同，CMPL通过模拟多轮交互，系统地发现处理敏感数据的代理中潜在的隐私漏洞。评估结果表明，CMPL能够有效揭示现有防御机制无法解决的风险。该论文还提供了一个可量化的审计程序和一个用于会话隐私评估的开放基准。

> **摘要翻译:** 大型语言模型代理已开始作为个人助理、客户服务机器人和临床助手出现。虽然这些应用程序带来了显著的运营效益，但它们也需要持续访问敏感数据，这增加了未经授权披露的可能性。本研究提出了一种会话隐私审计框架，用于量化和审计这些风险。所提出的会话操纵隐私泄漏（CMPL）框架是一种迭代探测策略，旨在对执行严格隐私指令的代理进行压力测试。CMPL不是仅仅关注单一披露事件，而是模拟真实的多轮交互，以系统地发现潜在漏洞。我们在不同领域、数据模态和安全配置上的评估表明，该审计框架能够揭示现有单轮防御无法阻止的隐私风险。除了将CMPL作为诊断工具引入外，本文还提供（1）基于可量化风险指标的审计程序和（2）用于评估代理实现中会话隐私的开放基准。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [233] [AURA: A Multi-Agent Intelligence Framework for Knowledge-Enhanced Cyber Threat Attribution](https://arxiv.org/abs/2506.10175)
> *AURA：一个用于知识增强型网络威胁归因的多智能体智能框架*

*Nanda Rani, Sandeep Kumar Shukla* | **Main category: cs.CR**

**Keywords:** APT归因, 多智能体系统, 知识增强, 检索增强生成, 大型语言模型

**Comment:** 

> **TL;DR:** AURA是一个多智能体、知识增强的框架，用于自动化和可解释的APT威胁归因，它结合了RAG和LLM，通过关联行为模式和威胁情报来提高归因的一致性、可解释性和可扩展性。

**AI_Comments:** AURA的创新之处在于其结合了多智能体系统、RAG和LLMs来处理复杂的威胁情报，实现了自动化且可解释的APT归因。其重要性体现在解决了传统归因中数据复杂性和解释性不足的问题，提高了归因的效率和可信度。该框架的可扩展性也预示着其在未来网络安全领域的广阔应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 当前的APT归因越来越依赖于关联行为模式和推理复杂的、多样化的威胁情报。需要一个自动化、可解释且高效的框架来解决这一挑战。

**Method:** AURA（Attribution Using Retrieval-Augmented Agents）是一个多智能体框架，它摄取TTPs、IoCs、恶意软件详情、对抗工具和时间信息等多种威胁数据。这些数据通过协作智能体网络进行处理，这些智能体负责智能查询重写、从结构化威胁知识库中进行上下文丰富的检索，以及对归因决策进行自然语言解释。AURA通过结合检索增强生成（RAG）和大型语言模型（LLMs），将威胁行为与已知APT组进行上下文关联，并支持跨多个攻击阶段的可追溯推理。

**Result:** 在近期APT活动上的实验表明，AURA具有高归因一致性、与专家一致的解释以及良好的可扩展性。

**Conclusion:** AURA为推进透明、数据驱动和可扩展的威胁归因提供了一个有前景的方向，利用了多智能体智能。

> **ai_Abstract:** AURA是一个多智能体、知识增强的框架，旨在自动化和解释高级持续威胁（APT）的归因。它整合了多样化的威胁数据，并通过协作智能体网络进行处理，这些智能体利用检索增强生成（RAG）和大型语言模型（LLMs）进行智能查询、上下文检索和决策解释。实验证明AURA在归因一致性、专家解释对齐和可扩展性方面表现出色，为透明、数据驱动的威胁归因提供了新途径。

> **摘要翻译:** 有效归因高级持续威胁（APT）越来越依赖于关联行为模式和推理复杂的、多样化的威胁情报。我们提出了AURA（Attribution Using Retrieval-Augmented Agents），一个多智能体、知识增强的框架，用于自动化和可解释的APT归因。AURA摄取包括战术、技术和程序（TTPs）、危害指标（IoCs）、恶意软件详情、对抗工具和时间信息在内的多样化威胁数据，并通过一个协作智能体网络进行处理。这些智能体被设计用于智能查询重写、从结构化威胁知识库中进行上下文丰富的检索，以及对归因决策进行自然语言解释。通过将检索增强生成（RAG）与大型语言模型（LLMs）相结合，AURA能够将威胁行为与已知APT组进行上下文关联，并支持跨多个攻击阶段的可追溯推理。在近期APT活动上的实验表明，AURA具有高归因一致性、与专家一致的解释以及良好的可扩展性。这项工作确立了AURA作为利用多智能体智能推进透明、数据驱动和可扩展威胁归因的一个有前景方向。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [272] [ELFuzz: Efficient Input Generation via LLM-driven Synthesis Over Fuzzer Space](https://arxiv.org/abs/2506.10323)
> *ELFuzz：通过LLM驱动的模糊器空间合成实现高效输入生成*

*Chuyang Chen, Brendan Dolan-Gavitt, Zhiqiang Lin* | **Main category: cs.CR**

**Keywords:** 模糊测试, LLM, 输入生成, 模糊器合成, 代码覆盖率

**Comment:** Accepted by USENIX Security'25 Cycle 2

> **TL;DR:** ELFuzz利用大型语言模型自动生成高效的模糊测试器，显著提高代码覆盖率并发现更多bug，包括0-day漏洞。

**AI_Comments:** ELFuzz的创新之处在于将LLM引入模糊测试的模糊器合成过程，通过自动化演化显著降低了手动构建测试规范的成本，并提高了模糊测试的效率和有效性。其在发现真实世界0-day漏洞方面的表现突出了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于生成的模糊测试方法需要大量手动工作来构建输入语法和语义约束规范。

**Method:** 本文提出了一种新方法ELFuzz（Evolution Through Large Language Models for Fuzzing），它通过在模糊器空间上进行LLM驱动的合成，自动为待测试系统（SUT）定制生成式模糊器。该方法从最小的种子模糊器开始，并通过LLM驱动的自动化演化（受覆盖率指导）来推动合成。

**Result:** ELFuzz可以无缝扩展到实际规模的SUT（评估中高达1,791,104行代码），并合成能够以人类可理解的方式捕获语法结构和语义约束的高效模糊器。与现有方法相比，ELFuzz的代码覆盖率提高高达434.8%，触发的人工注入bug增加高达174.0%。在cvc5最新版本上进行了14天的真实世界模糊测试，发现了五个0-day bug（其中三个可被利用）。消融研究表明，模糊器空间模型对ELFuzz的有效性贡献最大（高达62.5%）。

**Conclusion:** ELFuzz在实现更自动化、高效和可扩展的模糊测试输入生成方面展现出巨大的潜力。

> **ai_Abstract:** ELFuzz是一种新颖的模糊测试方法，它利用大型语言模型（LLM）在模糊器空间上自动合成定制的生成式模糊器，以解决传统方法中手动构建测试规范的繁重工作。该方法从最小的种子模糊器开始，通过LLM驱动的演化和覆盖率指导来优化模糊器。实验结果表明，ELFuzz能够高效地扩展到大型系统，显著提高代码覆盖率并发现更多bug，包括真实世界中的0-day漏洞。其关键组件——模糊器空间模型，对性能提升贡献显著。ELFuzz展现了实现自动化、高效和可扩展的模糊测试输入的巨大潜力。

> **摘要翻译:** 基于生成的模糊测试根据输入语法和语义约束的规范生成适当的测试用例来测试系统和软件。然而，这些规范的构建需要大量手动工作。本文提出了一种新方法ELFuzz（通过大型语言模型进行模糊测试的演化），它通过在模糊器空间上进行LLM驱动的合成，自动为待测试系统（SUT）定制生成式模糊器。总的来说，它从最小的种子模糊器开始，并通过完全自动化的LLM驱动演化和覆盖率指导来推动合成。与以前的方法相比，ELFuzz可以1）无缝扩展到实际规模的SUT——在我们的评估中高达1,791,104行代码——以及2）合成高效的模糊器，以人类可理解的方式捕获有趣的语法结构和语义约束。我们的评估将ELFuzz与领域专家手动编写的规范以及最先进方法合成的规范进行了比较。结果表明，ELFuzz的代码覆盖率提高了高达434.8%，触发的人工注入bug增加了高达174.0%。我们还使用ELFuzz对最新版本的cvc5进行了为期14天的真实世界模糊测试活动，令人鼓舞的是，它发现了五个0-day bug（其中三个是可利用的）。此外，我们进行了一项消融研究，结果表明模糊器空间模型作为ELFuzz的关键组件，对ELFuzz的有效性贡献最大（高达62.5%）。对ELFuzz合成的模糊器进行进一步分析证实，它们以人类可理解的方式捕获了有趣的语法结构和语义约束。这些结果展现了ELFuzz在模糊测试中实现更自动化、高效和可扩展的输入生成方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [285] [A Comprehensive Survey of Unmanned Aerial Systems' Risks and Mitigation Strategies](https://arxiv.org/abs/2506.10327)
> *无人机系统风险与缓解策略综合调查*

*Sharad Shrestha, Mohammed Ababneh, Satyajayant Misra, Henry M. Cathey, Jr., Roopa Vishwanathan, Matt Jansen, Jinhong Choi, Rakesh Bobba, Yeongjin Jang* | **Main category: cs.CR**

**Keywords:** 无人机系统, 网络安全, 风险缓解, 漏洞, 调查

**Comment:** 

> **TL;DR:** 该调查总结了无人机系统在部署各阶段的网络安全漏洞、发生可能性、攻击影响以及可应用的缓解策略，并提出了未来的研究方向。

**AI_Comments:** 这是一项重要的调查研究，它系统地梳理了无人机系统领域的网络安全风险与缓解策略，并超越了现有技术水平，对特有和非特有策略进行了全面分析。其创新之处在于识别并明确指出了未来的研究空白，为该领域的发展提供了清晰的方向。这对于无人机系统的安全保障和可持续发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 过去十年中，无人机系统（UAS）在通信、国防和交通领域的快速增长，以及未来应用将持续增加的趋势，促使研究人员关注无人机系统基础设施和无人机（UAV）的安全漏洞，以加强这些关键系统。

**Method:** 本研究通过对无人机系统部署各个阶段的网络安全漏洞、漏洞发生的可能性、攻击影响以及可应用的缓解策略进行总结，并对无人机系统特有和非特有的缓解策略进行了综合分析。此外，还介绍了相关的网络安全标准及其在无人机系统背景下的建议。

**Result:** 该调查总结了无人机系统部署各阶段的网络安全漏洞、发生可能性、攻击影响和缓解策略。它超越现有技术水平，全面分析了适用于无人机领域的特有和非特有缓解策略，并提出了经验教训。研究还介绍了相关的网络安全标准及其建议。尽管现有文献丰富，但仍发现了一些需要进一步调查的关键研究空白。

**Conclusion:** 该调查发现，尽管无人机系统安全领域文献丰富，且过去的网络物理和网络系统安全方法具有相关性，但仍存在几个需要进一步研究的关键空白。这些空白构成了未来研究社区探索的讨论和建议的一部分。

> **ai_Abstract:** 本调查旨在全面分析无人机系统（UAS）面临的网络安全风险和可行的缓解策略。文章总结了无人机部署各阶段的网络安全漏洞、其发生可能性、攻击影响，并提出了相应的缓解措施。研究不仅涵盖了无人机系统特有的策略，也探讨了非特有但适用于无人机领域的缓解方法，并提炼了经验教训。此外，调查还介绍了无人机系统相关的网络安全标准和建议，并指出了当前研究中存在的关键空白，为未来的研究方向提供了指导。

> **摘要翻译:** 在过去十年中，无人机系统（UAS）和无人机（UAV）在通信、国防和交通领域的快速增长。无人机系统的应用将继续迅速增加。这促使研究人员检查无人机系统基础设施和无人机（作为无人机系统一部分）各个方面的安全漏洞，以加强这些关键系统。本调查总结了无人机部署几个阶段的网络安全漏洞、每个漏洞发生的可能性、攻击的影响以及可以应用的缓解策略。我们通过对无人机系统特有和非无人机系统特有的缓解策略进行分析，全面提升无人机系统安全性，超越了现有技术水平，从而定义了经验教训。我们还提出了无人机系统背景下的相关网络安全标准及其建议。尽管无人机系统安全领域有大量文献，并且我们在此次调查中识别出过去网络物理和网络系统安全方法的关联性，但我们发现了一些需要进一步调查的关键研究空白。这些构成了我们研究社区未来探索的讨论和建议的一部分。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [295] [Adaptive Chosen-Ciphertext Security of Distributed Broadcast Encryption](https://arxiv.org/abs/2506.10338)
> *分布式广播加密的自适应选择密文安全性*

*Kwangsu Lee* | **Main category: cs.CR**

**Keywords:** 分布式广播加密, 自适应选择密文安全, 双线性群, q-Type假设

**Comment:** arXiv admin note: text overlap with arXiv:2505.17527

> **TL;DR:** 本文首次提出了一种高效的分布式广播加密方案，实现了自适应选择密文攻击（CCA）安全性。

**AI_Comments:** 本文的创新点在于首次实现了分布式广播加密方案的自适应选择密文攻击（CCA）安全性，这是密码学领域安全性证明的一个重要进展。同时，它解决了现有方案在公钥验证效率上的痛点，通过将线性配对操作降至常量级别，显著提升了方案的实用性。这是一个理论和实践价值兼具的工作。

<details>
  <summary>Details</summary>

**Motivation:** 以前的分布式广播加密（DBE）方案仅在自适应选择明文攻击（CPA）安全模型中被证明，并且在验证用户公钥时需要线性数量的配对操作，效率较低。

**Method:** 本文首先提出了一个半静态CCA安全的DBE方案，并在q-Type假设下证明了其安全性。然后，通过修改Gentry和Waters的通用转换（该转换将半静态CPA安全DBE方案转换为自适应CPA安全DBE方案），使其适用于CCA安全的DBE方案，从而提出了一个自适应CCA安全的DBE方案并证明了其自适应CCA安全性。

**Result:** 所提出的DBE方案是高效的，因为它需要常量大小的密文、常量大小的私钥和线性大小的公钥，并且公钥验证仅需要常量数量的配对操作和高效的组成员检查。

**Conclusion:** 本文首次成功提出并证明了一个高效的、具有自适应选择密文攻击（CCA）安全性的分布式广播加密（DBE）方案。

> **ai_Abstract:** 本文针对现有分布式广播加密（DBE）方案在安全性（仅CPA安全）和效率（公钥验证需要线性配对操作）上的不足，首次提出了一种在双线性群中实现自适应选择密文攻击（CCA）安全的高效DBE方案。该方案首先构建了一个半静态CCA安全的DBE方案，随后通过改进现有通用转换方法，将其扩展为自适应CCA安全。新方案在密文、私钥和公钥大小方面高效，且公钥验证仅需常量级配对操作，显著提升了实用性。

> **摘要翻译:** 分布式广播加密（DBE）是一种特定类型的广播加密（BE），其中用户独立生成自己的公钥和私钥，发送方可以通过使用子集用户的公钥高效地为用户子集创建密文。以前提出的DBE方案已在自适应选择明文攻击（CPA）安全模型中被证明，并且在验证用户公钥时具有需要线性数量配对操作的缺点。在本文中，我们首次在双线性群中提出了一种高效的DBE方案，并证明了其自适应选择密文攻击（CCA）安全性。为此，我们首先提出了一个半静态CCA安全的DBE方案，并在q-Type假设下证明了其安全性。然后，通过修改Gentry和Waters的通用转换（该转换将半静态CPA安全DBE方案转换为自适应CPA安全DBE方案），使其应用于CCA安全的DBE方案，我们提出了一个自适应CCA安全的DBE方案并证明了其自适应CCA安全性。我们提出的DBE方案是高效的，因为它需要常量大小的密文、常量大小的私钥和线性大小的公钥，并且公钥验证仅需要常量数量的配对操作和高效的组成员检查。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [306] [FicGCN: Unveiling the Homomorphic Encryption Efficiency from Irregular Graph Convolutional Networks](https://arxiv.org/abs/2506.10399)
> *FicGCN：揭示不规则图卷积网络中同态加密的效率*

*Zhaoxuan Kan, Husheng Han, Shangyi Shi, Tenghui Hua, Hang Lu, Xiaowei Li, Jianan Mu, Xing Hu* | **Main category: cs.CR**

**Keywords:** 同态加密, 图卷积网络, 隐私保护, 稀疏性, 计算效率

**Comment:** Accepted by ICML 2025

> **TL;DR:** FicGCN是一个基于同态加密的框架，旨在提高云端图卷积网络（GCN）的隐私保护效率，通过利用GCN的稀疏性并优化聚合和组合操作，显著降低了计算开销，性能比现有设计提升高达4.10倍。

**AI_Comments:** FicGCN的创新点在于其将同态加密与不规则GCN的稀疏特性相结合，通过精巧的设计如SpIntra-CA和数据重排序，有效解决了HE在GCN中引入的巨大计算开销问题。该工作对于推动隐私保护机器学习，尤其是在敏感数据领域的GCN应用具有重要意义。其提出的优化策略为未来HE在复杂图结构数据上的应用提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 图卷积网络（GCNs）在个人医疗和金融系统等领域广泛应用，但基于云的GCN服务存在敏感图数据隐私泄露的风险。同态加密（HE）虽能实现隐私保护机器学习（PPML），但其计算开销巨大，尤其是在GCN所需的旋转和乘法操作中。GCN的稀疏性虽有性能潜力，但不规则性引入了额外的操作，降低了实际收益。因此，需要一个能有效利用GCN稀疏性并优化HE操作的框架。

**Method:** 本文提出了FicGCN，一个基于同态加密的框架，专门设计用于利用GCN的稀疏特性，并在聚合和组合操作之间实现全局最优平衡。FicGCN采用了延迟感知打包方案、稀疏密文内聚合（SpIntra-CA）方法以最小化旋转开销，以及由局部邻接结构驱动的基于区域的数据重排序。

**Result:** 在多个流行数据集上进行评估，结果表明FicGCN在所有测试数据集上均取得了最佳性能，比最新设计提升高达4.10倍。

**Conclusion:** FicGCN通过有效利用图卷积网络的稀疏性并优化同态加密操作，显著提高了隐私保护下GCN的计算效率，实现了优于现有设计的性能，证明了其在云端隐私保护GCN服务中的潜力。

> **ai_Abstract:** 该论文提出了FicGCN，一个基于同态加密（HE）的框架，旨在解决云端图卷积网络（GCN）中隐私保护与计算效率之间的矛盾。FicGCN通过利用GCN的稀疏性，并采用延迟感知打包、稀疏密文内聚合（SpIntra-CA）和基于区域的数据重排序等技术，优化了HE操作中的聚合和组合过程，显著降低了计算开销。实验结果表明，FicGCN在多个数据集上均表现出最佳性能，相较于现有设计实现了高达4.10倍的性能提升。

> **摘要翻译:** 图卷积神经网络（GCNs）因其卓越的性能在个人医疗和金融系统等各个领域获得了广泛的普及。尽管对基于云的GCN服务需求不断增长，但对敏感图数据的隐私担忧仍然显著。同态加密（HE）通过允许在加密数据上执行计算，促进了隐私保护机器学习（PPML）。然而，HE引入了巨大的计算开销，特别是对于矩阵乘法中需要旋转和乘法操作的GCN。GCN的稀疏性提供了显著的性能潜力，但其不规则性引入了额外的操作，降低了实际收益。在本文中，我们提出了FicGCN，一个基于HE的框架，专门设计用于利用GCN的稀疏特性，并在聚合和组合操作之间实现全局最优平衡。FicGCN采用了延迟感知打包方案、稀疏密文内聚合（SpIntra-CA）方法以最小化旋转开销，以及由局部邻接结构驱动的基于区域的数据重排序。我们在几个流行数据集上评估了FicGCN，结果表明FicGCN在所有测试数据集上均取得了最佳性能，比最新设计提升高达4.10倍。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [317] [SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](https://arxiv.org/abs/2506.10424)
> *SOFT：选择性数据混淆以保护LLM微调免受成员推断攻击*

*Kaiyuan Zhang, Siyuan Cheng, Hanxi Guo, Yuetian Chen, Zian Su, Shengwei An, Yuntao Du, Charles Fleming, Ashish Kundu, Xiangyu Zhang, Ninghui Li* | **Main category: cs.CR**

**Keywords:** 成员推断攻击, LLM微调, 隐私保护, 数据混淆, SOFT

**Comment:** Accepted by the 34th USENIX Security Symposium 2025. Code is
  available at https://github.com/KaiyuanZh/SOFT

> **TL;DR:** 本文首次全面评估了微调LLM对成员推断攻击（MIA）的脆弱性，并提出了SOFT，一种通过选择性数据混淆来有效降低隐私风险同时保持模型性能的防御技术。

**AI_Comments:** 这项工作首次全面评估了微调LLM对成员推断攻击的脆弱性，填补了现有研究空白。其提出的SOFT方法通过选择性数据混淆，巧妙地在隐私保护和模型效用之间取得平衡，具有实际应用价值和可扩展性。这项研究对于提高LLM在敏感数据场景下的安全性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在微调过程中经常涉及私人或敏感信息，这引发了关键的隐私问题。本文旨在评估微调LLM对成员推断攻击（MIA）的脆弱性，并开发一种防御机制来缓解隐私泄露。

**Method:** 本文提出了SOFT（LLM微调中的选择性数据混淆），这是一种新颖的防御技术。它通过利用有影响力的数据选择和可调参数来平衡效用保持和隐私保护，从而减轻隐私泄露。

**Result:** 实验结果表明，SOFT在有效降低隐私风险的同时，保持了具有竞争力的模型性能。它在六个不同领域和多种LLM架构及规模上进行了广泛的实验。

**Conclusion:** SOFT提供了一种实用且可扩展的解决方案，用于保护微调LLM中的敏感信息，有效降低了隐私风险并保持了模型性能。

> **ai_Abstract:** 本文首次全面研究了微调大型语言模型（LLM）对成员推断攻击（MIA）的脆弱性。研究发现MIA利用微调过程中的损失降低来有效揭示成员信息。为应对此问题，作者提出了SOFT（LLM微调中的选择性数据混淆），这是一种新颖的防御技术，通过选择有影响力的数据并调节参数来平衡隐私保护和模型效用。广泛的实验证明，SOFT能够有效降低隐私风险，同时保持模型性能，为保护微调LLM中的敏感数据提供了一个实用且可扩展的解决方案。

> **摘要翻译:** 大型语言模型（LLM）取得了显著成功，并被广泛应用于各种应用。然而，微调这些模型通常涉及私人或敏感信息，引发了关键的隐私担忧。在这项工作中，我们首次进行了全面研究，评估了微调LLM对成员推断攻击（MIA）的脆弱性。我们的实证分析表明，MIA利用微调过程中的损失降低，使其在揭示成员信息方面非常有效。这些发现促使我们开发防御措施。我们提出了SOFT（LLM微调中的选择性数据混淆），这是一种新颖的防御技术，通过利用有影响力的数据选择和可调参数来平衡效用保持和隐私保护，从而减轻隐私泄露。我们广泛的实验涵盖了六个不同领域和多种LLM架构和规模。结果表明，SOFT在有效降低隐私风险的同时，保持了具有竞争力的模型性能，为保护微调LLM中的敏感信息提供了一种实用且可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [323] [Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications](https://arxiv.org/abs/2506.10467)
> *多智能体LLM系统规范与评估——原型与网络安全应用*

*Felix Härer* | **Main category: cs.CR**

**Keywords:** 多智能体系统, LLM, 规范, 评估, 网络安全

**Comment:** 

> **TL;DR:** 本文探讨了多智能体LLM系统的规范与评估，并提出了一个原型系统，通过网络安全任务验证了其可行性。

**AI_Comments:** 本文的创新之处在于解决了多智能体LLM系统在联合规范和系统评估方面的空白，这对于将LLM应用于复杂领域至关重要。通过引入明确的规范和原型，为未来的多智能体LLM系统开发和部署提供了重要基础。其在网络安全领域的应用案例进一步证明了其在实际复杂任务中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在文本生成之外的特定领域具有应用潜力，并且多智能体LLM方法可以解决复杂任务，但目前对这些系统的联合规范和综合应用缺乏深入探索。为了系统地评估LLM、推理技术及相关方面，需要明确定义多智能体LLM系统的规范。

**Method:** 本文报告了一项探索性研究的结果，旨在通过一个多智能体系统来规范和评估这些方面。研究扩展了先前的系统架构和原型，并引入了多智能体系统的规范。

**Result:** 涉及网络安全任务的测试案例表明了所提出的架构和评估方法的可行性。具体而言，结果显示使用OpenAI和DeepSeek的LLM代理正确完成了问答、服务器安全和网络安全任务的评估。

**Conclusion:** 研究表明，通过引入明确的规范和原型系统，可以有效地对多智能体LLM系统进行规范和评估，并在网络安全等复杂应用领域展现出可行性。

> **ai_Abstract:** 本研究旨在解决多智能体大型语言模型（LLM）系统在联合规范和综合应用方面的不足。论文提出了一种新的规范，并扩展了现有的多智能体系统原型，以实现对LLM、推理技术和相关方面的系统评估。通过在网络安全任务（包括问答、服务器安全和网络安全）上的测试，验证了所提出的架构和评估方法的可行性，并展示了使用OpenAI和DeepSeek LLM代理的有效性。

> **摘要翻译:** 大型语言模型（LLM）的最新进展预示着新型应用的潜力，例如通过最新OpenAI和DeepSeek模型的推理能力。为了在文本生成之外的特定领域应用这些模型，可以利用基于LLM的多智能体方法，通过结合推理技术、代码生成和软件执行来解决复杂任务。应用可能利用这些能力和专业LLM代理的知识。然而，尽管对LLM、推理技术和应用程序进行了单独的许多评估，但它们的联合规范和组合应用尚未得到很好的探索。需要为多智能体LLM系统定义规范，以探索其潜力及其对特定应用的适用性，从而允许对LLM、推理技术和相关方面进行系统评估。本文报告了通过多智能体系统规范和评估这些方面的探索性研究结果。系统架构和原型是从先前的研究中扩展而来的，并引入了多智能体系统的规范。涉及网络安全任务的测试案例表明了该架构和评估方法的可行性。特别是，结果显示了由OpenAI和DeepSeek的LLM代理正确完成的问答、服务器安全和网络安全任务的评估。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [330] [A Crack in the Bark: Leveraging Public Knowledge to Remove Tree-Ring Watermarks](https://arxiv.org/abs/2506.10502)
> *树皮中的裂缝：利用公共知识去除Tree-Ring水印*

*Junhua Lin, Marc Juarez* | **Main category: cs.CR**

**Keywords:** 水印移除, 扩散模型, 变分自编码器, Tree-Ring, 安全风险

**Comment:** 18 pages, to be published in the 34th USENIX Security Symposium

> **TL;DR:** 一种新的攻击方法利用公开的变分自编码器有效去除Tree-Ring水印，揭示了公共模型重用带来的安全风险。

**AI_Comments:** 这篇论文通过利用公开可用的组件（VAE）来攻击Tree-Ring水印，展示了一种新颖且实用的攻击方法。其创新之处在于识别并利用了公共模型组件的潜在安全漏洞，这在现有研究中可能被忽视。论文的重要性在于揭示了扩散模型训练中重用公共自编码器所带来的未被充分认识的风险，为水印技术和模型安全领域提供了重要的警示。

<details>
  <summary>Details</summary>

**Motivation:** Tree-Ring是一种针对扩散模型的水印技术，以其高不可感知性和对移除攻击的鲁棒性而闻名。然而，现有的移除攻击方法对攻击者能力有很强的假设。本文旨在开发一种更实际且有效的攻击方法来移除Tree-Ring水印，特别是针对其未被充分考虑的漏洞。

**Method:** 本文提出了一种新颖的攻击方法，它不依赖于对攻击者能力的强假设，而仅需要访问用于训练目标扩散模型的变分自编码器（VAE），该组件通常是公开可用的。通过利用这个VAE，攻击者可以近似模型的中间潜在空间，从而实现更有效的基于代理的攻击。

**Result:** 评估显示，这种方法导致Tree-Ring检测器ROC和PR曲线的AUC显著下降，分别从0.993降至0.153和从0.994降至0.385，同时保持了高图像质量。值得注意的是，该攻击方法优于假设完全访问扩散模型的现有方法。

**Conclusion:** 本文的发现强调了重用公共自编码器训练扩散模型的风险，这是当前行业实践中未考虑到的威胁。此外，结果表明Tree-Ring检测器的精度（一个被忽视的指标）未能满足实际部署的要求。

> **ai_Abstract:** 本文介绍了一种针对Tree-Ring水印技术的新型攻击。Tree-Ring是一种针对扩散模型的水印，以其鲁棒性著称。与现有方法不同，该攻击仅利用公开可用的变分自编码器来近似扩散模型的潜在空间，从而实现有效的代理攻击。实验结果表明，该方法能显著降低Tree-Ring检测器的性能（AUC大幅下降），同时保持图像质量，并优于其他需要更多访问权限的方法。研究强调了重用公共自编码器训练扩散模型的安全风险，并指出Tree-Ring检测器在实际应用中的精度不足。

> **摘要翻译:** 我们提出了一种专门针对Tree-Ring的新型攻击，Tree-Ring是一种用于扩散模型的水印技术，以其高不可感知性和对移除攻击的鲁棒性而闻名。与以往依赖于对攻击者能力强假设的移除攻击不同，我们的攻击仅需要访问用于训练目标扩散模型的变分自编码器，这是一个通常公开可用的组件。通过利用这个变分自编码器，攻击者可以近似模型的中间潜在空间，从而实现更有效的基于代理的攻击。我们的评估表明，这种方法导致Tree-Ring检测器ROC和PR曲线的AUC显著下降，分别从0.993降至0.153和从0.994降至0.385，同时保持了高图像质量。值得注意的是，我们的攻击优于假设完全访问扩散模型的现有方法。这些发现凸显了重用公共自编码器来训练扩散模型的风险——这是当前行业实践中未考虑到的威胁。此外，结果表明，Tree-Ring检测器的精度（一个被以往评估忽略的指标）未能满足实际部署的要求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [337] [SoK: Evaluating Jailbreak Guardrails for Large Language Models](https://arxiv.org/abs/2506.10597)
> *知识系统化：评估大型语言模型的越狱护栏*

*Xunguang Wang, Zhenlan Ji, Wenxuan Wang, Zongjie Li, Daoyuan Wu, Shuai Wang* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 越狱攻击, 安全护栏, 知识系统化, 评估框架

**Comment:** 

> **TL;DR:** 本文对大型语言模型的越狱护栏进行了首次全面的知识系统化分析，提出了一个新的多维度分类法和安全-效率-实用性评估框架，以指导未来研究和部署。

**AI_Comments:** 这篇SoK论文非常及时且重要，因为它解决了LLM安全领域的一个核心痛点——越狱攻击及其防御机制的混乱现状。通过提出统一的分类法和评估框架，它为该领域的未来研究奠定了坚实的基础，有助于规范术语和比较不同方法的有效性。其“安全-效率-实用性”的评估框架也考虑了实际部署中的关键因素。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在部署中暴露了关键漏洞，特别是越狱攻击绕过了安全机制。虽然护栏被认为是解决方案，但当前LLM护栏领域碎片化，缺乏统一的分类法和全面的评估框架。

**Method:** 本文作为一篇知识系统化（SoK）论文，对LLM的越狱护栏进行了首次整体分析。研究者提出了一个新颖的多维度分类法，将护栏沿六个关键维度进行分类，并引入了一个安全-效率-实用性评估框架来评估其实用有效性。通过广泛的分析和实验进行研究。

**Result:** 识别了现有护栏方法的优点和局限性，探讨了它们在不同攻击类型上的普适性，并为优化防御组合提供了见解。

**Conclusion:** 本文为未来的研究和开发提供了结构化基础，旨在指导稳健的LLM护栏的原则性推进和部署。

> **ai_Abstract:** 本文是一篇关于大型语言模型（LLMs）越狱护栏的知识系统化（SoK）论文。鉴于LLMs在部署中面临越狱攻击的漏洞以及现有护栏领域的碎片化，作者提出了首个对越狱护栏的整体分析。研究引入了一个新颖的多维度分类法（涵盖六个关键维度）和一个安全-效率-实用性评估框架，用于评估护栏的实际效果。通过广泛的分析和实验，论文揭示了现有护栏方法的优缺点、其对不同攻击类型的普适性，并提供了优化防御组合的策略。这项工作为未来研究和开发提供了结构化基础，旨在推动健壮LLM护栏的规范化发展和部署。

> **摘要翻译:** 大型语言模型（LLM）取得了显著进展，但其部署暴露了关键漏洞，特别是绕过安全机制的越狱攻击。护栏——作为监控和控制LLM交互的外部防御机制——已成为一种有前景的解决方案。然而，当前LLM护栏领域碎片化，缺乏统一的分类法和全面的评估框架。在这篇知识系统化（SoK）论文中，我们首次对LLM的越狱护栏进行了整体分析。我们提出了一个新颖的多维度分类法，将护栏沿六个关键维度进行分类，并引入了一个安全-效率-实用性评估框架来评估其实用有效性。通过广泛的分析和实验，我们识别了现有护栏方法的优点和局限性，探讨了它们在不同攻击类型上的普适性，并为优化防御组合提供了见解。我们的工作为未来的研究和开发提供了结构化基础，旨在指导稳健的LLM护栏的原则性推进和部署。代码可在https://github.com/xunguangwang/SoK4JailbreakGuardrails 获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [343] [Assessing the Resilience of Automotive Intrusion Detection Systems to Adversarial Manipulation](https://arxiv.org/abs/2506.10620)
> *评估车载入侵检测系统对对抗性操纵的弹性*

*Stefano Longari, Paolo Cerracchio, Michele Carminati, Stefano Zanero* | **Main category: cs.CR**

**Keywords:** 车载IDS, 对抗性攻击, CAN总线安全, 规避攻击, 梯度攻击

**Comment:** 

> **TL;DR:** 本文研究了梯度对抗性攻击对车载入侵检测系统的影响，考虑了白盒、灰盒和黑盒场景，并评估了攻击有效性及其对数据集质量、IDS和攻击者知识程度的依赖性。

**AI_Comments:** 该研究通过全面考虑不同知识程度的攻击场景，深入探讨了车载IDS在面对对抗性攻击时的脆弱性，具有重要的实践意义。它强调了汽车领域特有的挑战，并指出了未来IDS设计需要考虑的关键因素，如数据集质量和对抗性鲁棒性。其创新点在于评估了实时注入规避性有效载荷的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现代车辆的安全性日益重要，而控制器局域网（CAN）总线缺乏强大的安全措施，加上车辆互联性增加，使其容易受到网络攻击。尽管已开发出入侵检测系统（IDS）来应对此类威胁，但它们并非万无一失，对抗性攻击，特别是规避攻击，可以操纵输入以绕过IDS的检测。

**Method:** 本文扩展了之前的工作，调查了在不同知识程度下进行的基于梯度的对抗性攻击对车载IDS的可行性和影响。研究考虑了三种场景：白盒（攻击者拥有完整的系统知识）、灰盒（部分系统知识）和更现实的黑盒（对IDS内部工作或数据一无所知）。研究在两个公开可用的数据集上评估了所提出攻击对最先进IDS的有效性。此外，还研究了对抗性扰动对攻击影响的作用，并通过预计算规避性有效载荷以基于总线流量进行定时注入来评估实时可行性。

**Result:** 结果表明，除了由于汽车领域限制导致攻击具有挑战性之外，其有效性强烈依赖于数据集质量、目标IDS和攻击者的知识程度。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了针对车载入侵检测系统（IDS）的梯度对抗性攻击的可行性和影响，旨在评估其对规避攻击的弹性。研究考虑了白盒、灰盒和黑盒三种攻击场景，并在公开数据集上评估了攻击对现有IDS的有效性。此外，文章还分析了对抗性扰动对攻击效果的影响以及实时注入规避性有效载荷的可行性。研究发现，攻击的有效性受限于汽车领域约束，并强烈依赖于数据集质量、目标IDS和攻击者的知识程度。

> **摘要翻译:** 现代车辆的安全性日益重要，控制器局域网（CAN）总线作为各种电子控制单元（ECU）的关键通信骨干。CAN总线缺乏强大的安全措施，加上车辆互联性增加，使其容易受到网络攻击。尽管已开发出入侵检测系统（IDS）来应对此类威胁，但它们并非万无一失。对抗性攻击，特别是规避攻击，可以操纵输入以绕过IDS的检测。本文扩展了我们之前的工作，调查了在不同知识程度下进行的基于梯度的对抗性攻击对车载IDS的可行性和影响。我们考虑了三种场景：白盒（攻击者拥有完整的系统知识）、灰盒（部分系统知识）和更现实的黑盒（对IDS内部工作或数据一无所知）。我们在两个公开可用的数据集上评估了所提出攻击对最先进IDS的有效性。此外，我们研究了对抗性扰动对攻击影响的作用，并通过预计算规避性有效载荷以基于总线流量进行定时注入来评估实时可行性。我们的结果表明，除了由于汽车领域限制导致攻击具有挑战性之外，其有效性强烈依赖于数据集质量、目标IDS和攻击者的知识程度。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [350] [CyFence: Securing Cyber-Physical Controllers via Trusted Execution Environment](https://arxiv.org/abs/2506.10638)
> *CyFence：通过可信执行环境保护信息物理控制器*

*Stefano Longari, Alessandro Pozone, Jessica Leoni, Mario Polino, Michele Carminati, Mara Tanelli, Stefano Zanero* | **Main category: cs.CR**

**Keywords:** 信息物理系统, 可信执行环境, 网络安全, 语义检查, 控制器安全

**Comment:** 

> **TL;DR:** CyFence是一种利用可信执行环境为信息物理系统（CPS）控制器提供语义检查以抵御网络攻击的新型架构，其在实际应用中表现出低开销且能有效缓解攻击。

**AI_Comments:** 该论文的创新点在于其利用了信息物理系统的固有特性，通过引入语义检查来提升系统对网络攻击的弹性，并且巧妙地结合了可信执行环境（TEE）来保障检查代码的完整性和安全性。这种方法对于保护安全关键的CPS系统具有重要意义，尤其是在当前网络攻击日益增多的背景下。其在实际应用中展示的低计算开销特性也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 信息物理系统（CPS）的互联性增加导致其更容易受到网络攻击，尤其是在安全关键系统中，此类攻击可能带来高风险和潜在的安全危害。现有防御策略很少利用系统的信息物理特性。

**Method:** 提出了一种名为CyFence的新型架构，通过添加语义检查来提高闭环控制系统抵御网络攻击的弹性，该语义检查用于确认系统行为是否符合预期。为确保语义检查代码的安全性，使用了现代处理器实现的可信执行环境（TEE）。

**Result:** 通过一个由主动制动数字控制器组成的真实世界应用进行评估，结果表明CyFence能够以可忽略的计算开销缓解不同类型的攻击。

**Conclusion:** CyFence通过利用可信执行环境中的语义检查，成功提高了信息物理系统控制器抵御网络攻击的弹性，且计算开销极低。

> **ai_Abstract:** 本文提出了一种名为CyFence的新型架构，旨在通过利用可信执行环境（TEE）实现语义检查，从而增强信息物理系统（CPS）闭环控制器抵御网络攻击的能力。CyFence通过验证系统行为是否符合预期来提高弹性，并利用TEE确保检查代码的安全性。在主动制动数字控制器的实际应用中进行的评估表明，CyFence能够有效缓解多种攻击，且计算开销可忽略不计。

> **摘要翻译:** 在过去的几十年里，信息物理系统（CPS）经历了显著的技术演进和连接性增加，但代价是更容易受到网络攻击。由于许多CPS用于安全关键系统，此类攻击会带来高风险和潜在的安全危害。尽管已经提出了几种防御策略，但它们很少利用系统的信息物理特性。在这项工作中，我们利用CPS的特性，提出了CyFence，这是一种新颖的架构，通过添加语义检查来提高闭环控制系统抵御网络攻击的弹性，该检查用于确认系统行为是否符合预期。为了确保语义检查代码的安全性，我们使用了现代处理器实现的可信执行环境。我们通过一个由主动制动数字控制器组成的真实世界应用来评估CyFence，结果表明它能够以可忽略的计算开销缓解不同类型的攻击。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [357] [From IOCs to Group Profiles: On the Specificity of Threat Group Behaviors in CTI Knowledge Bases](https://arxiv.org/abs/2506.10645)
> *从IOCs到群组画像：关于CTI知识库中威胁群组行为特异性的研究*

*Aakanksha Saha, Martina Lindorfer, Juan Caballero* | **Main category: cs.CR**

**Keywords:** 威胁情报, 行为画像, IOCs, 群组归因, MITRE ATT&CK

**Comment:** 

> **TL;DR:** 研究发现，尽管网络安全界正转向行为画像，但威胁群组的行为画像（如TTPs和使用的软件）的特异性远低于预期，这引发了对它们替代IOCs进行归因能力的担忧。

**AI_Comments:** 这篇论文揭示了当前威胁情报知识库中威胁群组行为画像的局限性，特别是其在区分不同群组方面的不足。研究结果挑战了业界对行为画像能够完全替代IOCs进行威胁归因的普遍看法，强调了在构建和利用行为情报时需要更加谨慎，并可能需要更丰富、更精细的数据来提高归因的准确性。其创新之处在于首次系统性地量化了这种“特异性”问题。

<details>
  <summary>Details</summary>

**Motivation:** 传统上用于威胁检测和归因的妥协指标（IOCs）生命周期短且易于更改。网络安全界正将重点转向更持久的行为画像（如TTPs和软件），但这些行为画像的独特性和完整性尚未得到充分探索。

**Method:** 本研究系统分析了从MITRE ATT&CK和Malpedia两个开放网络威胁情报（CTI）知识库构建的威胁群组画像。研究首先调查了有多少威胁群组具有群组特异性行为（即仅由单个群组使用的行为），然后评估了结合两个来源数据后群组画像的改进情况，并进一步通过添加利用的漏洞和从更多威胁报告中提取的额外技术来增强画像。

**Result:** 研究发现，ATT&CK中只有34%的威胁群组具有群组特异性技术。威胁群组使用的软件更具独特性，ATT&CK中73%的群组使用群组特异性软件，但在更广泛的Malpedia数据集中，这一比例降至24%。即使结合了两个来源的数据，具有群组特异性行为的群组比例仍低于30%。在添加了额外信息后，仍有64%的群组缺乏任何群组特异性行为。

**Conclusion:** 研究结果对“行为画像可以取代IOCs进行威胁群组归因”的观点提出了担忧。

> **ai_Abstract:** 该研究系统分析了来自MITRE ATT&CK和Malpedia的威胁群组行为画像，旨在评估其特异性和完整性。研究发现，相较于易变的IOCs，TTPs和软件等行为画像的群组特异性远低于预期。具体而言，ATT&CK中仅34%的群组具有特异性技术，软件特异性虽高（ATT&CK中73%），但在Malpedia中降至24%。即使结合多源数据并补充信息，仍有高达64%的群组缺乏任何特异性行为。这些发现对行为画像在威胁群组归因中替代IOCs的有效性提出了质疑。

> **摘要翻译:** 妥协指标（IOCs）如IP地址、文件哈希和域名常用于威胁检测和归因。然而，IOCs往往是短命的，因为它们易于更改。因此，网络安全社区正将重点转向更持久的行为画像，如威胁群组的战术、技术和程序（TTPs）以及其使用的软件。然而，这些行为画像的独特性和完整性在很大程度上仍未被探索。在这项工作中，我们系统地分析了从两个开放网络威胁情报（CTI）知识库构建的威胁群组画像：MITRE ATT&CK和Malpedia。我们首先调查了有多少威胁群组具有群组特异性行为，即仅由单个群组使用的行为。我们发现，ATT&CK中只有34%的威胁群组具有群组特异性技术。威胁群组使用的软件被证明更具独特性，ATT&CK中73%的群组使用群组特异性软件。然而，在更广泛的Malpedia数据集中，这一比例降至24%。接下来，我们评估了当结合两个来源的数据时，群组画像如何得到改善。虽然覆盖率略有提高，但具有群组特异性行为的群组比例仍低于30%。然后，我们通过添加被利用的漏洞和从更多威胁报告中提取的额外技术来增强画像。尽管增加了额外信息，仍有64%的群组缺乏任何群组特异性行为。我们的发现对“行为画像可以取代IOCs进行威胁群组归因”的信念提出了担忧。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [364] [GOLIATH: A Decentralized Framework for Data Collection in Intelligent Transportation Systems](https://arxiv.org/abs/2506.10665)
> *GOLIATH：智能交通系统中数据收集的去中心化框架*

*Davide Maffiola, Stefano Longari, Michele Carminati, Mara Tanelli, Stefano Zanero* | **Main category: cs.CR**

**Keywords:** 智能交通系统, 去中心化框架, 区块链, 数据收集, 众包

**Comment:** 

> **TL;DR:** GOLIATH是一个基于区块链的去中心化框架，用于智能交通系统（ITS）中的实时数据收集，旨在克服现有集中式众包解决方案的局限性，确保可信的信息交换。

**AI_Comments:** GOLIATH的创新之处在于将区块链技术应用于智能交通系统的数据收集，有效解决了传统集中式方案的单点故障和信任问题。其提出的新型共识机制增强了数据交换的安全性与鲁棒性，对于构建更可靠、去中心化的交通数据生态系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能交通系统（ITS）需要车辆实时交换数据，例如交通信息管理。传统的现场传感器方法已面临挑战，而众包成为替代方案。然而，当前的众包解决方案普遍采用集中式模型，导致单点故障和信任问题，且数据访问受限。

**Method:** 本文提出了GOLIATH，一个基于区块链的去中心化框架，运行在车载信息娱乐（IVI）系统上，用于收集网络参与者之间交换的实时信息。该方法通过在分类账上记录车辆位置和邻居位置的交易，并使用一种新颖的共识机制进行验证。该共识机制被设计为能够抵御旨在篡改或禁用通信的对手。该框架在一个模拟环境中进行了评估。

**Result:** GOLIATH在车辆定位和交通信息管理方面展示了其可行性。模拟评估结果表明，该框架具有鲁棒性和安全性。

**Conclusion:** GOLIATH是一个基于区块链的去中心化框架，通过利用车辆固有的分布式特性，有效缓解了现有众包集中式解决方案的局限性，保障了可信的信息收集与交换，并在模拟环境中证明了其鲁棒性和安全性。

> **ai_Abstract:** GOLIATH是一个基于区块链的去中心化框架，旨在解决智能交通系统（ITS）中传统集中式数据收集的局限性。它运行在车载信息娱乐（IVI）系统上，使车辆能够安全地交换实时数据。该框架通过记录车辆位置和邻居位置的交易到分类账上，并采用一种新颖且抗攻击的共识机制来确保信息的可信度和完整性。在模拟环境中的评估表明，GOLIATH在数据收集方面具有良好的鲁棒性和安全性。

> **摘要翻译:** 智能交通系统（ITS）技术在过去几年中取得了进步，现在它被用于需要车辆交换实时数据的多种应用，例如交通信息管理。传统上，道路交通信息是通过现场传感器收集的。然而，从车载传感器或智能手机众包交通信息已成为一种可行的替代方案。目前最先进的解决方案遵循集中式模型，其中只有服务提供商才能完全访问收集到的交通数据，这代表了单点故障和信任问题。在本文中，我们提出了GOLIATH，一个基于区块链的去中心化框架，运行在车载信息娱乐（IVI）系统上，用于收集网络参与者之间交换的实时信息。我们的方法通过保证可信的信息收集和交换，充分利用车辆固有的分布式特性，从而减轻了现有众包集中式解决方案的局限性。我们在车辆定位和交通信息管理的背景下展示了其可行性。参与去中心化网络的每辆车都以交易的形式共享其位置和邻居的位置，并记录在分类账上，该分类账使用一种新颖的共识机制来验证它。我们设计的共识机制能够抵抗一组旨在篡改或禁用通信的真实对手。我们在一个模拟（但真实）环境中评估了所提出的框架，该环境考虑了不同的威胁，并展示了其鲁棒性和安全属性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [370] [Commitment Schemes for Multi-Party Computation](https://arxiv.org/abs/2506.10721)
> *多方计算中的承诺方案*

*Ioan Ionescu, Ruxandra F. Olimid* | **Main category: cs.CR**

**Keywords:** 承诺方案, 多方计算, 安全属性, 密码学应用, 隐私保护

**Comment:** 

> **TL;DR:** 本文分析了承诺方案（CSs）在多方计算（MPC）协议中的应用，强调了CSs的选择对MPC安全性和功能需求的重要性，旨在提升加密应用的健壮性和隐私性。

**AI_Comments:** 本文的创新之处在于其对承诺方案（CSs）与多方计算（MPC）之间相互关系的深入分析，填补了该领域研究的空白。其重要性体现在它不仅为研究人员提供了理论指导，还为从业者提供了实用的教程，有助于推动更健壮和隐私保护的密码学应用。该论文在实践和理论之间搭建了桥梁。

<details>
  <summary>Details</summary>

**Motivation:** 尽管承诺方案（CSs）的独立属性和多方计算（MPC）提供的保障已被广泛研究，但它们在具体协议和应用中的相互关系仍未得到充分探索。本文旨在填补这一空白。

**Method:** 本文分析了承诺方案（CSs）与多方计算（MPC）之间的关系，重点关注安全属性及其对上层MPC的影响。具体来说，研究了不同类型的CSs如何影响各种MPC构造及其与MPC实际应用的关联。该论文也可用作理解CS和MPC之间密码学相互作用的教程。

**Result:** 研究结果强调了仔细选择承诺方案（CS）以满足多方计算（MPC）的对抗性和功能需求的重要性。

**Conclusion:** 通过仔细选择承诺方案，可以实现更健壮和隐私保护的密码学应用。

> **ai_Abstract:** 本文深入分析了承诺方案（CSs）在多方计算（MPC）协议中的应用，填补了CSs与MPC在实际协议和应用中相互关系研究的空白。论文详细探讨了不同类型CSs的安全属性及其对MPC构造和实际应用的影响，旨在为研究人员和从业者提供理解CS与MPC密码学交互的教程。研究强调，为满足MPC的对抗性和功能要求，精心选择CS至关重要，这有助于构建更强大、更注重隐私的加密应用。

> **摘要翻译:** 本文分析了多方计算（MPC）协议中使用的承诺方案（CSs）。尽管CSs的个体属性和MPC提供的保障已被广泛独立研究，但它们在具体协议和应用中的相互关系在很大程度上仍未被充分探索。本文介绍了两者之间的关系，重点强调（安全）属性及其对上层MPC的影响。特别是，我们研究了不同类型的CSs如何促进各种MPC构造及其与MPC实际应用的关联。该论文也可以作为理解CS和MPC之间密码学相互作用的教程，使其对研究人员和从业者都易于理解。我们的发现强调了仔细选择CS以满足MPC对抗性和功能要求的重要性，从而旨在实现更健壮和隐私保护的密码学应用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [375] [TED-LaST: Towards Robust Backdoor Defense Against Adaptive Attacks](https://arxiv.org/abs/2506.10722)
> *TED-LaST：迈向抵御自适应攻击的鲁棒后门防御*

*Xiaoxing Mo, Yuxuan Cheng, Nan Sun, Leo Yu Zhang, Wei Luo, Shang Gao* | **Main category: cs.CR**

**Keywords:** 后门攻击, 深度神经网络, 拓扑演化动力学, 自适应攻击, 防御

**Comment:** 

> **TL;DR:** TED-LaST是一种新颖的防御策略，通过引入标签监督动力学跟踪和自适应层强调，增强了拓扑演化动力学（TED）对自适应后门攻击的鲁棒性，有效对抗复杂的后门威胁。

**AI_Comments:** 本文的创新点在于提出了TED-LaST防御策略，通过引入标签监督动力学跟踪和自适应层强调，显著提升了现有拓扑演化动力学（TED）方法在应对自适应后门攻击时的鲁棒性。这对于提高深度神经网络在面对不断演变威胁时的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）容易受到后门攻击，攻击者在训练期间植入隐藏触发器以恶意控制模型行为。现有基于拓扑演化动力学（TED）的防御方法可能容易受到自适应攻击，这些攻击会扭曲跨网络层的拓扑表示分布。

**Method:** 本文提出了TED-LaST（Topological Evolution Dynamics against Laundry, Slow release, and Target mapping attack strategies），一种新的防御策略，通过引入标签监督动力学跟踪和自适应层强调，增强了TED对自适应攻击的鲁棒性。此外，本文还回顾并分类了最先进自适应攻击中的数据中毒技巧，并提出了一种带有目标映射的增强型自适应攻击。

**Result:** 在多个数据集（CIFAR-10、GTSRB和ImageNet100）和模型架构（ResNet20、ResNet101）上的综合实验表明，TED-LaST有效地对抗了复杂的后门，如Adap-Blend、Adapt-Patch和本文提出的增强型自适应攻击。

**Conclusion:** TED-LaST为鲁棒后门检测树立了新基准，显著增强了DNN抵御不断演变威胁的安全性。

> **ai_Abstract:** 本文提出了TED-LaST，一种增强拓扑演化动力学（TED）对自适应后门攻击鲁棒性的新型防御策略。针对现有TED方法在面对自适应攻击时可能失效的问题，TED-LaST引入了标签监督动力学跟踪和自适应层强调，使其能够识别传统方法难以发现的隐蔽威胁。研究还分类了现有的数据中毒技巧并提出了增强型自适应攻击。在多个数据集和模型上的实验证明，TED-LaST能有效对抗多种复杂的后门攻击，为深度神经网络的安全防御设立了新标准。

> **摘要翻译:** 深度神经网络（DNN）容易受到后门攻击，攻击者在训练期间植入隐藏触发器以恶意控制模型行为。拓扑演化动力学（TED）最近已成为检测DNN中后门攻击的强大工具。然而，TED可能容易受到自适应地扭曲跨网络层拓扑表示分布的后门攻击。为了解决这一限制，我们提出了TED-LaST（Topological Evolution Dynamics against Laundry, Slow release, and Target mapping attack strategies），一种新颖的防御策略，增强了TED抵御自适应攻击的鲁棒性。TED-LaST引入了两项关键创新：标签监督动力学跟踪和自适应层强调。这些增强功能能够识别即使在拓扑空间中不可分离和细微拓扑扰动的情况下也能规避传统TED防御的隐蔽威胁。我们回顾并分类了最先进自适应攻击中的数据中毒技巧，并提出了一种带有目标映射的增强型自适应攻击，该攻击可以动态转移恶意任务并充分利用自适应攻击所具有的隐蔽性。我们在多个数据集（CIFAR-10、GTSRB和ImageNet100）和模型架构（ResNet20、ResNet101）上的综合实验表明，TED-LaST有效地对抗了复杂的后门，如Adap-Blend、Adapt-Patch和本文提出的增强型自适应攻击。TED-LaST为鲁棒后门检测树立了新基准，显著增强了DNN抵御不断演变威胁的安全性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [381] [ObfusBFA: A Holistic Approach to Safeguarding DNNs from Different Types of Bit-Flip Attacks](https://arxiv.org/abs/2506.10744)
> *ObfusBFA: 一种保护深度神经网络免受不同类型位翻转攻击的整体方法*

*Xiaobei Yan, Han Qiu, Tianwei Zhang* | **Main category: cs.CR**

**Keywords:** 位翻转攻击, 深度神经网络, 模型安全, 混淆, 鲁棒性

**Comment:** 

> **TL;DR:** ObfusBFA通过引入随机虚拟操作来防御针对DNNs的位翻转攻击，有效保持模型精度并降低攻击成功率。

**AI_Comments:** 本文的创新点在于提出了一个“整体（holistic）”的防御方法ObfusBFA，能够同时对抗针对高层模型权重和低层代码库的位翻转攻击，弥补了现有防御方法仅专注于特定攻击和平台的不足。其核心思想——通过引入随机虚拟操作来“模糊化”攻击，将精确攻击转化为随机位翻转——非常巧妙且高效。该方法在实际应用中具有潜在价值，因为它提供了广泛的保护，同时保持了较低的性能开销。

<details>
  <summary>Details</summary>

**Motivation:** 位翻转攻击（BFAs）对深度神经网络（DNNs）构成严重威胁，现有防御措施仅针对特定攻击和平台，缺乏普适性，无法有效应对其他场景。

**Method:** 本文提出了ObfusBFA，一种高效且整体的方法来缓解针对高层模型权重和低层代码库（可执行文件或共享库）的位翻转攻击。其核心思想是在模型推理期间引入随机虚拟操作，将精确的攻击转化为随机位翻转，从而使攻击者难以定位和利用脆弱位。为此，论文设计了新颖的算法来识别关键位并插入混淆操作。

**Result:** ObfusBBA在不同数据集和DNN架构上都能持续保持模型精度，同时显著降低攻击成功率。此外，它引入了最小的延迟和存储开销。

**Conclusion:** ObfusBFA是一种高效、实用且全面的解决方案，能够有效防御针对深度神经网络的位翻转攻击，适用于实际应用。

> **ai_Abstract:** 本文提出ObfusBFA，一种针对深度神经网络（DNNs）位翻转攻击（BFAs）的整体防御方法。该方法通过在模型推理时引入随机虚拟操作，将精确攻击转化为随机位翻转，从而有效保护DNNs免受针对模型权重和代码库的BFAs。实验证明ObfusBFA在保持模型精度的同时显著降低攻击成功率，且开销极低，具有很高的实用性。

> **摘要翻译:** 位翻转攻击（BFAs）对深度神经网络（DNNs）构成严重威胁，其中翻转模型参数或二进制代码中少量位就可能显著降低模型精度或以期望的方式误导模型预测。现有防御措施仅专注于保护特定攻击和平台下的模型，而对其他场景缺乏有效性。我们提出了ObfusBFA，一种高效且整体的方法来缓解针对高层模型权重和低层代码库（可执行文件或共享库）的BFAs。ObfusBFA的关键思想是在模型推理期间引入随机虚拟操作，这有效地将精细攻击转化为随机位翻转，使攻击者更难定位和利用脆弱位。我们设计了新颖的算法来识别关键位并插入混淆操作。我们评估了ObfusBFA针对不同类型攻击的防御能力，包括攻击者增加翻转位预算以试图规避我们防御的自适应场景。结果表明，ObfusBFA在各种数据集和DNN架构上都能持续保持模型精度，同时显著降低攻击成功率。此外，它引入了最小的延迟和存储开销，使其成为实际应用的实用解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [385] [Quantifying Azure RBAC Wildcard Overreach](https://arxiv.org/abs/2506.10755)
> *量化 Azure RBAC 通配符过度授权*

*Christophe Parisel* | **Main category: cs.CR**

**Keywords:** Azure RBAC, 通配符, 权限管理, 最小权限, 云安全

**Comment:** 

> **TL;DR:** Belshazaar 框架量化了 Azure RBAC 通配符权限的过度授权问题，发现约39%的操作存在跨资源提供商的过度授权，并证明了有效权限集的可计算性，有助于实现更严格的最小权限策略。

**AI_Comments:** Belshazaar 框架通过结合形式化语法分析和量化指标，为理解和管理云环境中复杂的通配符权限提供了一种新颖且实用的方法。其创新之处在于能够将模糊的通配符权限具体化并量化其“越界”程度，对于提升云安全治理和实现最小权限原则具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Azure RBAC 中的通配符权限简化了策略编写，但它模糊了实际允许的操作集，并破坏了最小权限原则。因此，需要一种方法来量化和理解这些通配符权限的实际影响。

**Method:** 论文介绍了 Belshazaar 框架，该框架分两阶段进行：1. 通过上下文无关文法形式化 Azure 操作语法，并实现一个编译器将任何通配符扩展为显式操作集。2. 定义一个超度量直径指标来量化通配符场景中的语义过度授权。

**Result:** 将 Belshazaar 应用于微软官方的15481个操作目录，结果显示约39%的操作在与不明显的通配符关联时，会产生跨资源提供商的权限覆盖，并且有效权限集是可计算的。

**Conclusion:** 研究结果表明，通配符模式会引入大量的权限膨胀，并且所提出的方法为在 Azure 环境中实现更严格、最小权限的 RBAC 策略提供了一条可扩展、语义驱动的途径。

> **ai_Abstract:** 本研究提出了 Belshazaar 框架，旨在量化 Azure RBAC 中通配符权限的过度授权问题。该框架首先通过形式化语法和编译器将通配符扩展为显式操作，然后使用超度量直径指标量化语义过度授权。实验结果表明，近四成的 Azure 操作因通配符而存在跨资源提供商的权限膨胀，验证了有效权限集的可计算性。这证明了所提方法能有效识别并帮助收紧 Azure 环境中的最小权限 RBAC 策略。

> **摘要翻译:** Azure RBAC 利用通配符权限来简化策略编写，但这种抽象常常模糊了实际允许的操作集，并破坏了最小权限保证。我们引入了 Belshazaar，一个两阶段框架，旨在解决有效权限集问题和评估通配符权限的扩散。首先，我们通过上下文无关文法形式化 Azure 操作语法，并实现了一个编译器，将任何通配符扩展为其显式操作集。其次，我们定义了一个超度量直径指标来量化通配符场景中的语义过度授权。将 Belshazaar 应用于微软官方的15481个操作目录，结果显示约39%的操作在与不明显的通配符关联时，会产生跨资源提供商的权限覆盖，并且有效权限集是可计算的。这些发现表明，通配符模式会引入大量的权限膨胀，并且我们的方法为在 Azure 环境中实现更严格、最小权限的 RBAC 策略提供了一条可扩展、语义驱动的途径。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [389] [ME: Trigger Element Combination Backdoor Attack on Copyright Infringement](https://arxiv.org/abs/2506.10776)
> *ME：触发元素组合后门攻击在版权侵权中的应用*

*Feiyu Yang, Siyuan Liang, Aishan Liu, Dacheng Tao* | **Main category: cs.CR**

**Keywords:** 版权侵权攻击, 生成扩散模型, 后门攻击, Multi-Element, 离散余弦变换

**Comment:** 

> **TL;DR:** 本文提出了ME攻击方法，通过增加中毒样本中的视觉-文本元素数量并引入DCT来增强对生成扩散模型的版权侵权攻击能力，并在新数据集上取得了优于SBD的攻击效果，尤其在低采样率下表现更佳。

**AI_Comments:** 本文的创新点在于提出了Multi-Element (ME) 攻击方法，通过增加中毒样本中的元素数量来增强攻击能力，并引入DCT来保持攻击的隐蔽性，有效解决了现有版权侵权攻击方法在数据资源和效率方面的局限性。其重要性在于揭示了生成扩散模型潜在的版权侵权风险，并提供了一种更高效、更隐蔽的攻击手段，对模型安全性和版权保护领域具有警示意义。尤其在低中毒样本量下的显著提升，展现了该方法的实用性和威胁性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的针对生成扩散模型（如Stable Diffusion）的版权侵权攻击方法（如SilentBadDiffusion, SBD）存在数据资源有限、数据集适用性差以及在少量中毒样本下攻击性能不佳等问题，促使研究者寻找更有效、更隐蔽的攻击方法。

**Method:** 本文提出了Multi-Element (ME) 攻击方法，该方法基于SBD，通过增加每个中毒样本中的中毒视觉-文本元素数量来增强攻击能力。同时，为了保持隐蔽性，引入了离散余弦变换（DCT）对中毒样本进行处理。此外，研究者还创建了新的数据集以供相关研究使用。

**Result:** 在两个新数据集上，ME攻击方法的版权侵权率（CIR）/首次攻击周期（FAE）分别为16.78% / 39.50和51.20% / 23.60，接近或优于基准的Pokemon和Mijourney数据集。在低采样率（5%中毒样本，即6个中毒样本）条件下，MESI和DCT的CIR / FAE分别为0.23% / 84.00和12.73% / 65.50，均优于完全无法攻击的原始SBD。

**Conclusion:** 本文提出的ME攻击方法有效解决了现有版权侵权攻击方法在数据资源和攻击效率方面的局限性，尤其在低中毒样本率下表现出显著的攻击能力提升和隐蔽性，证明了其在增强对生成扩散模型的版权侵权攻击方面的有效性。

> **ai_Abstract:** 本文针对生成扩散模型（如Stable Diffusion）面临的版权侵权攻击问题，指出现有方法（如SBD）在数据资源和低样本量攻击性能上的不足。为此，作者提出了Multi-Element (ME) 攻击方法，通过增加中毒样本中的视觉-文本元素数量来增强攻击效果，并引入离散余弦变换（DCT）以保持隐蔽性。实验结果表明，ME方法在新建数据集上取得了优于或接近基准数据集的攻击性能，尤其在极低中毒样本量（如5%采样率）条件下，ME方法显著提升了攻击成功率，而SBD则完全失效。

> **摘要翻译:** 生成扩散模型（DMs）如Stable Diffusion（SD）复制训练数据的能力可能被攻击者利用，通过复制中毒的图像-文本对来发起版权侵权攻击。SilentBadDiffusion（SBD）是最近提出的一种方法，在文本到图像任务中攻击SD表现出色。然而，该领域可用的数据资源仍然有限，其中一些由于版权所有权或不当内容等问题甚至受到限制或禁止；并且当前数据集中并非所有图像都适用于所提出的攻击方法；此外，当少量生成的投毒样本可用于攻击时，SBD的最新（SoTA）性能远非理想。在本文中，我们提出了可用于研究SBD等攻击的新数据集，并基于SBD提出了Multi-Element（ME）攻击方法，通过增加每个投毒样本中投毒视觉-文本元素的数量来增强攻击能力，同时为投毒样本引入离散余弦变换（DCT）以保持隐蔽性。我们在两个新数据集上获得的版权侵权率（CIR）/首次攻击周期（FAE）分别为16.78% / 39.50和51.20% / 23.60，分别接近或甚至超越了基准Pokemon和Mijourney数据集。在低采样率（5%，6个投毒样本）条件下，MESI和DCT的CIR / FAE分别为0.23% / 84.00和12.73% / 65.50，均优于完全无法攻击的原始SBD。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [394] [Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors](https://arxiv.org/abs/2506.10949)
> *使用轻量级序列监控器监控大型语言模型中的分解攻击*

*Chen Yueh-Han, Nitish Joshi, Yulin Chen, Maksym Andriushchenko, Rico Angell, He He* | **Main category: cs.CR**

**Keywords:** 分解攻击, LLM安全, 序列监控, 轻量级监控, 安全防御

**Comment:** 

> **TL;DR:** LLM安全防御在分解攻击下失效，本研究提出一种轻量级序列监控框架，通过累积评估子任务，有效防御分解攻击，并显著降低成本和延迟。

**AI_Comments:** 这项研究的创新之处在于提出了一个外部的、轻量级且序列化的监控方法来解决LLM分解攻击这一新兴且难以防御的安全漏洞。它突破了现有浅层安全对齐技术仅关注即时提示的局限性，通过累积评估实现对长程恶意意图的识别。其提出的数据集对于后续研究具有重要价值。此外，该方法在防御效果、成本和延迟方面的显著优化，使其在实际部署中具有高度可行性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 当前LLM的安全防御机制无法抵御分解攻击，因为它们仅能检测即时提示中的危害，而无法推理长程意图，导致对通过一系列看似无害指令实现的恶意意图视而不见。

**Method:** 1. 提出了一个外部监控器，以更高粒度观察对话。2. 整理了迄今为止最大、最多样化的数据集，包括问答、文本到图像和代理任务，用于研究分解攻击。3. 提出了一个轻量级序列监控框架，通过累积评估每个子任务来实时防御。

**Result:** 1. 在前沿LLM上测试数据集，显示在GPT-4o上平均攻击成功率为87%，证实分解攻击普遍有效。2. 发现随机任务可以注入分解的子任务中以进一步混淆恶意意图。3. 精心设计的轻量级监控器实现了93%的防御成功率，优于o3 mini等推理模型。4. 对随机任务注入保持鲁棒性，并将成本降低90%，延迟降低50%。

**Conclusion:** 轻量级序列监控器在缓解分解攻击方面非常有效，并且在部署中是可行的。

> **ai_Abstract:** 本研究针对大型语言模型（LLM）在分解攻击下现有安全防御失效的问题，提出了一种外部轻量级序列监控框架。该框架通过累积评估对话中的每个子任务，能够检测并防御恶意意图被分解为看似良性子任务以规避安全机制的攻击。研究团队构建了迄今为止最大的分解攻击数据集，并在前沿LLM上验证了分解攻击的有效性（GPT-4o上87%的成功率）。实验结果表明，该轻量级监控器实现了93%的防御成功率，优于其他推理模型，同时显著降低了成本和延迟，并对随机任务注入保持鲁棒性，证明了其在实际部署中的可行性。

> **摘要翻译:** 当前大型语言模型（LLM）的安全防御在分解攻击下失效，在这种攻击中，恶意目标被分解为看似良性的子任务，从而规避了拒绝机制。挑战在于现有的浅层安全对齐技术：它们只检测即时提示中的危害，而无法推理长程意图，导致它们对通过一系列看似良性指令出现的恶意意图视而不见。因此，我们建议添加一个外部监控器，以更高的粒度观察对话。为了促进我们对分解攻击的研宄，我们策划了迄今为止最大、最多样化的数据集，包括问答、文本到图像和代理任务。我们通过在前沿LLM上测试来验证我们的数据集，并显示在GPT-4o上平均攻击成功率为87%。这证实了分解攻击普遍有效。此外，我们发现随机任务可以注入分解的子任务中，以进一步混淆恶意意图。为了实时防御，我们提出了一种轻量级序列监控框架，该框架累积评估每个子任务。我们表明，一个经过精心提示工程的轻量级监控器实现了93%的防御成功率，击败了像o3 mini这样的推理模型作为监控器。此外，它对随机任务注入保持鲁棒性，并将成本降低90%，延迟降低50%。我们的发现表明，轻量级序列监控器在缓解分解攻击方面非常有效，并且在部署中是可行的。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [21] [A Conjecture on a Fundamental Trade-Off between Certainty and Scope in Symbolic and Generative AI](https://arxiv.org/abs/2506.10130)
> *符号AI和生成式AI中确定性与范围之间基本权衡的猜想*

*Luciano Floridi* | **Main category: cs.AI**

**Keywords:** 确定性, 范围, 符号AI, 生成式AI, 权衡, 可信赖AI

**Comment:** 

> **TL;DR:** 本文提出了一个猜想，即AI系统中可证明的正确性与广泛数据映射能力之间存在根本性权衡：符号AI追求确定性但范围受限，而生成式AI范围广但无法保证零错误。

**AI_Comments:** 这篇论文提出了一个具有深远哲学和工程意义的猜想，它明确了AI设计中长期存在的确定性与范围之间的内在矛盾。如果这一猜想得到验证，将对AI的评估标准、治理策略以及混合AI系统的设计产生革命性影响，对于构建可信赖的AI至关重要。其创新之处在于将这一隐性权衡形式化，并将其置于信息论和哲学框架下进行探讨。

<details>
  <summary>Details</summary>

**Motivation:** 明确并形式化人工智能系统中可证明的正确性与广泛数据映射能力之间存在的此前隐性的基本权衡，以重塑AI的工程目标和哲学期望。

**Method:** 通过引入并形式化一个关于确定性与范围之间权衡的猜想，将其置于信息论框架内，并结合认识论、形式验证和技术哲学等领域进行探讨。文章还分析了其影响和后果，并讨论了其对评估标准、治理框架和混合系统设计的影响。

**Result:** 提出了一个关于AI系统中可证明的正确性与广泛数据映射能力之间基本权衡的猜想，并阐明了如果该猜想成立，将如何重塑AI的评估标准、治理框架和混合系统设计。

**Conclusion:** 强调了最终证明或驳斥该不等式对于未来可信赖AI发展的重要性。

> **ai_Abstract:** 本文提出了一个关于符号AI和生成式AI之间核心权衡的猜想，即AI系统在追求可证明的零错误（确定性）时，其操作范围必然受限，如同经典符号AI；而当系统能够处理高维数据并产生丰富输出（范围广）时，如当代生成模型，则不可避免地存在错误风险。这一猜想旨在明确并形式化这一基本权衡，从而影响AI的工程设计、评估标准、治理和哲学期望。文章从信息论角度阐述了该猜想，并探讨了其在认识论、形式验证和技术哲学中的深远影响，强调了对其进行验证的重要性，以指导未来可信赖AI的发展。

> **摘要翻译:** 本文提出了一个猜想，旨在形式化人工智能（AI）系统中可证明的正确性与广泛数据映射能力之间存在的根本性权衡。当一个AI系统被设计为具有演绎上严密的保证（对其输出无错误的证明确定性）——如在经典符号AI中——其操作领域必须被狭窄地限定和预先结构化。相反，一个能够输入高维数据以产生丰富信息输出的系统——如当代生成模型——必然放弃零错误性能的可能性，从而承担不可避免的错误或误分类风险。通过使这种先前隐含的权衡变得明确并可进行严格验证，该猜想显著地重塑了AI的工程抱负和哲学期望。在回顾了这种张力的历史动机之后，文章以信息论形式阐述了该猜想，并将其置于认识论、形式验证和技术哲学的更广泛辩论中。随后，文章利用欠确定性、审慎的认知风险和道德责任等概念，分析了其影响和后果。讨论阐明了如果该猜想正确，它将如何帮助重塑评估标准、治理框架和混合系统设计。结论强调了最终证明或驳斥该不等式对于未来可信赖AI的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [48] [One Patient, Many Contexts: Scaling Medical AI Through Contextual Intelligence](https://arxiv.org/abs/2506.10157)
> *一个病人，多种情境：通过情境智能扩展医疗AI*

*Michelle M. Li, Ben Y. Reis, Adam Rodman, Tianxi Cai, Noa Dagan, Ran D. Balicer, Joseph Loscalzo, Isaac S. Kohane, Marinka Zitnik* | **Main category: cs.AI**

**Keywords:** 医疗AI, 情境智能, 基础模型, 动态适应, 情境切换

**Comment:** 

> **TL;DR:** 本文提出了一种愿景，即医疗AI模型应能动态适应不同的医疗情境，而无需重新训练，以解决现有模型在处理未训练情境时容易出现情境错误的问题。

**AI_Comments:** 本文提出了一种前瞻性的视角，强调了医疗AI领域中一个关键但被忽视的问题：情境适应性。其创新之处在于提出了“情境切换”的概念，旨在克服现有模型在处理未见情境时的局限性，减少情境错误。如果这一愿景得以实现，将极大地提高医疗AI的鲁棒性和实用性，使其能够更广泛、更安全地应用于临床实践，尤其是在资源受限或专业领域多样化的环境中。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医疗基础模型在适应新的患者群体、专业领域或设置时，通常需要微调、精心提示或从知识库中检索，这既不切实际也限制了它们解释不熟悉输入和适应训练中未涵盖的临床情况的能力。这导致模型容易出现情境错误，即预测看似合理但未能考虑关键的患者特定或情境信息。这些错误源于现有模型难以动态调整其行为以适应不断变化的医疗护理情境这一基本限制。

**Method:** 本文提出了一种在医疗AI中实现情境切换的愿景：即模型能够无需重新训练就能动态调整其推理，以适应新的专业、人群、工作流程和临床角色。

**Result:** Not mentioned in abstract

**Conclusion:** 本文设想情境切换AI将能够诊断、管理和治疗跨专业和地区的各种疾病，并扩大医疗服务的可及性。

> **ai_Abstract:** 本文探讨了当前医疗AI模型在适应不同医疗情境时面临的挑战，即需要耗时的微调或提示才能避免情境错误。作者提出了一种“情境切换”的愿景，旨在开发能够动态适应新专业、人群和工作流程而无需重新训练的医疗AI模型。这种能力有望使AI更准确地理解和应对患者的复杂性，从而扩大医疗服务的可及性并提升诊断和治疗能力。

> **摘要翻译:** 医疗基础模型，包括在临床笔记上训练的语言模型、在医学图像上训练的视觉-语言模型以及在电子健康记录上训练的多模态模型，能够总结临床笔记、回答医学问题并协助决策。将这些模型适应新的患者群体、专业领域或设置通常需要微调、精心提示或从知识库中检索。这既不切实际，也限制了它们解释不熟悉输入和适应训练中未涵盖的临床情况的能力。因此，模型容易出现情境错误，即预测看似合理但未能考虑关键的患者特定或情境信息。这些错误源于现有模型难以动态调整其行为以适应不断变化的医疗护理情境这一基本限制。在此视角中，我们概述了医疗AI中情境切换的愿景：模型能够无需重新训练就能动态调整其推理，以适应新的专业、人群、工作流程和临床角色。我们设想情境切换AI将能够诊断、管理和治疗跨专业和地区的各种疾病，并扩大医疗服务的可及性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [73] [Correlation vs causation in Alzheimer's disease: an interpretability-driven study](https://arxiv.org/abs/2506.10179)
> *阿尔茨海默病中的相关性与因果关系：一项可解释性驱动的研究*

*Hamzah Dabool, Raghad Mustafa* | **Main category: cs.AI**

**Keywords:** 阿尔茨海默病, 因果关系, 相关性, 机器学习, 可解释性

**Comment:** 

> **TL;DR:** 本研究利用相关性分析、机器学习分类和模型可解释性技术，区分阿尔茨海默病中的因果关系与相关性，强调强相关性不必然意味着因果关系，并为未来的因果推断研究奠定基础。

**AI_Comments:** 这项研究通过整合机器学习和可解释性技术来探讨阿尔茨海默病中的因果关系与相关性，具有创新性。其重要性在于强调了在复杂疾病研究中仔细区分因果关系的重要性，为未来的因果推断研究提供了新的视角和方法论基础，有望改进 AD 的诊断和治疗策略。

<details>
  <summary>Details</summary>

**Motivation:** 理解阿尔茨海默病 (AD) 中因果关系与相关性之间的区别至关重要，因为它影响诊断、治疗以及识别真正的疾病驱动因素。

**Method:** 本研究结合了相关性分析、机器学习分类（采用 XGBoost 算法）和模型可解释性技术（如 SHAP 值），以调查临床、认知、遗传和生物标志物特征之间的关系。

**Result:** 研究识别了影响 AD 分类的关键特征，包括认知评分和遗传风险因素。相关性矩阵揭示了相互关联变量的簇，而 SHAP 值提供了特征在疾病各个阶段贡献的详细见解。结果强调强相关性不一定意味着因果关系。

**Conclusion:** 区分因果因素与相关标记可以改善阿尔茨海默病的早期诊断和靶向干预。这项工作通过整合特征重要性和可解释性与经典统计分析，为未来旨在揭示真正病理机制的因果推断研究奠定了基础。

> **ai_Abstract:** 本研究旨在区分阿尔茨海默病 (AD) 中的因果关系与相关性，这对于疾病诊断、治疗和驱动因素识别至关重要。研究结合了相关性分析、XGBoost 机器学习分类和 SHAP 可解释性技术，调查了临床、认知、遗传和生物标志物特征间的关系。结果识别了认知评分和遗传风险因素等关键特征，并强调强相关性不必然意味着因果关系。该工作为未来旨在揭示真正病理机制的因果推断研究奠定了基础，以期通过区分因果因素和相关标记来改善 AD 的早期诊断和干预。

> **摘要翻译:** 理解阿尔茨海默病 (AD) 研究中因果关系与相关性之间的区别至关重要，因为它影响诊断、治疗以及识别真正的疾病驱动因素。本实验通过结合相关性分析、机器学习分类和模型可解释性技术，调查了临床、认知、遗传和生物标志物特征之间的关系。我们采用 XGBoost 算法，识别了影响 AD 分类的关键特征，包括认知评分和遗传风险因素。相关性矩阵揭示了相互关联变量的簇，而 SHAP (SHapley Additive exPlanations) 值则提供了特征在疾病各个阶段贡献的详细见解。我们的结果强调，强相关性不一定意味着因果关系，强调需要仔细解释关联数据。通过将特征重要性和可解释性与经典统计分析相结合，这项工作为未来旨在揭示真正病理机制的因果推断研究奠定了基础。最终，区分因果因素与相关标记可以改善阿尔茨海默病的早期诊断和靶向干预。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [84] [A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon](https://arxiv.org/abs/2506.10326)
> *在竞技宝可梦中泛化不同团队策略的基准*

*Cameron Angliss, Jiaxun Cui, Jiaheng Hu, Arrasy Rahman, Peter Stone* | **Main category: cs.AI**

**Keywords:** 多智能体学习, 宝可梦VGC, 泛化, VGC-Bench, 策略

**Comment:** 15 pages, 3 figures, 10 tables, submitted to NeurIPS 2025 Datasets &
  Benchmarks Track

> **TL;DR:** 引入了一个名为 VGC-Bench 的宝可梦对战基准，以解决多智能体学习中跨多样团队策略泛化的挑战，并发现即使在受限设置中表现良好的方法也难以扩展。

**AI_Comments:** 这项工作在多智能体学习领域具有重要意义，它通过宝可梦VGC提供了一个独特且极具挑战性的泛化基准。其创新之处在于构建了一个高度离散、组合性强的环境，并提供了全面的基础设施和多样的基线方法。论文揭示了当前AI在复杂策略空间中泛化能力的局限性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 开发能够鲁棒适应不同策略环境而无需重新训练的AI智能体是多智能体学习的核心挑战。宝可梦VGC拥有极其庞大的团队配置空间（约$10^{139}$），其高度离散和组合的团队构建性质导致最优策略会根据自身和对手的团队发生显著变化，使得泛化成为一个独特的挑战。

**Method:** 引入了VGC-Bench基准，该基准提供了关键基础设施、标准化评估协议、人类对战数据集以及一系列基线方法，包括大语言模型智能体、行为克隆、强化学习和经验博弈论方法（如自博弈、虚构博弈和双重神谕）。

**Result:** 在智能体在单一团队配置上进行训练和评估的受限设置中，所提出的方法能够击败专业的VGC选手。然而，在对 progressively 更大的团队集进行评估时，即使在单一团队设置中表现最好的算法也难以扩展，表明跨多样团队策略的策略泛化仍然是一个开放的挑战。

**Conclusion:** 跨多样团队策略的策略泛化仍然是多智能体学习领域的一个开放挑战，VGC-Bench为未来研究提供了重要基准和工具。

> **ai_Abstract:** 该研究针对多智能体学习中跨多样团队策略泛化的挑战，特别是在团队配置空间巨大的宝可梦VGC领域。作者提出了VGC-Bench，一个包含基础设施、评估协议、人类数据集和多种基线（如LLM、RL、EGTA）的基准。实验结果显示，在受限的单团队设置下，方法能击败专业选手，但随着团队规模增加，泛化能力显著下降，表明该问题仍是开放挑战。

> **摘要翻译:** 开发能够鲁棒适应截然不同策略环境而无需重新训练的AI智能体是多智能体学习的核心挑战。宝可梦视频游戏锦标赛（VGC）是一个拥有约 $10^{139}$ 种可能团队配置的领域——远远大于Dota或星际争霸。宝可梦VGC中团队构建的高度离散、组合性质导致最优策略会根据所操纵的团队和对手的团队发生显著变化，使得泛化面临独特的挑战。为了推进对该问题的研究，我们引入了VGC-Bench：一个提供关键基础设施、标准化评估协议，并提供人类对战数据集和一系列基线（从大语言模型智能体和行为克隆到强化学习和经验博弈论方法，如自博弈、虚构博弈和双重神谕）的基准。在智能体在单一团队配置上进行训练和评估的受限设置中，我们的方法能够击败专业的VGC选手。我们对所有基线方法在 progressively 更大的团队集上进行了广泛评估，发现即使在单一团队设置中表现最好的算法也难以随着团队规模的增长而扩展。因此，跨多样团队策略的策略泛化仍然是社区面临的一个开放挑战。我们的代码已在 https://github.com/cameronangliss/VGC-Bench 开源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [85] [Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods](https://arxiv.org/abs/2506.10420)
> *处理服务的多维自动扩缩：基于代理方法的比较*

*Boris Sedlak, Alireza Furutanpey, Zihang Wang, Víctor Casamayor Pujol, Schahram Dustdar* | **Main category: cs.AI**

**Keywords:** 边缘计算, 自动扩缩, 代理, 多维, 资源管理

**Comment:** 

> **TL;DR:** 本文提出了一种基于代理的多维自动扩缩框架，用于在资源受限的边缘环境中动态调整硬件资源和服务配置，并比较了四种代理方法的性能。

**AI_Comments:** 该论文通过引入多维自动扩缩框架并比较多种代理方法，为边缘计算中的资源管理提供了一种创新的解决方案。其重要性在于克服了传统自动扩缩在资源受限环境下的局限性，并为未来研究指明了方向。特别是对不同AI/ML代理在自动扩缩场景下的性能比较，具有很高的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 边缘计算由于严格的资源限制，打破了传统的自动扩缩模式，因此需要更灵活的多维度扩缩行为。

**Method:** 本文引入了一个基于代理的自动扩缩框架，该框架动态调整硬件资源和内部服务配置。研究比较了四种扩缩代理：主动推理（Active Inference）、深度Q网络（Deep Q Network）、结构知识分析（Analysis of Structural Knowledge）和深度主动推理（Deep Active Inference），并使用YOLOv8和OpenCV两种实际处理服务进行并行测试。

**Result:** 所有代理都实现了可接受的SLO性能，但收敛模式不同。深度Q网络受益于预训练，结构分析收敛迅速，而深度主动推理代理结合了理论基础和实际可伸缩性优势。

**Conclusion:** 研究结果证明了多维基于代理的自动扩缩在边缘环境中的可行性，并鼓励在该研究方向上进行未来的工作。

> **ai_Abstract:** 本研究提出了一种针对边缘计算环境的多维自动扩缩框架，该框架采用基于代理的方法，能够同时调整硬件资源和服务配置以满足性能需求。论文比较了主动推理、深度Q网络、结构知识分析和深度主动推理四种不同的代理在YOLOv8和OpenCV服务上的表现。结果表明所有代理均能达到服务水平目标，并展现出各自的收敛特性，强调了多维代理自动扩缩在边缘环境中的潜力。

> **摘要翻译:** 边缘计算由于严格的资源限制，打破了传统的自动扩缩模式，因此需要更灵活的多维度扩缩行为。本文介绍了一种基于代理的自动扩缩框架，该框架动态调整硬件资源和内部服务配置，以最大限度地满足受限环境中的需求。我们比较了四种扩缩代理：主动推理、深度Q网络、结构知识分析和深度主动推理，使用两个并行运行的真实世界处理服务：用于视觉识别的YOLOv8和用于二维码检测的OpenCV。结果显示，所有代理都实现了可接受的SLO性能，但收敛模式不同。虽然深度Q网络受益于预训练，但结构分析收敛迅速，深度主动推理代理结合了理论基础和实际可伸缩性优势。我们的发现为边缘环境中多维基于代理的自动扩缩的可行性提供了证据，并鼓励在该研究方向上进行未来的工作。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [99] [Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems](https://arxiv.org/abs/2506.10192)
> *迈向负责任的人工智能：自主系统在安全、公平和问责制方面的进展*

*Filip Cano* | **Main category: cs.AI**

**Keywords:** 负责任AI, 安全防护罩, 公平防护罩, 问责制, 自主系统

**Comment:** 202 pages, 38 figures, PhD Thesis

> **TL;DR:** 本论文旨在通过在安全、公平、透明和问责制方面取得进展，使AI系统更加负责任和值得信赖。具体方法包括扩展确定性安全防护罩、引入公平防护罩以及提出评估概率决策代理意图的形式框架。

**AI_Comments:** 本文在推动AI负责任发展方面做出了多方面的贡献。其创新点在于将经典安全防护罩技术扩展到更具挑战性的实际环境（延迟观测），并首次提出“公平防护罩”以解决序列决策中的群体公平问题。此外，引入量化指标来评估AI意图，为AI系统的问责制提供了新的形式化工具。这些方法都具有很强的实践意义，特别是在自动驾驶等关键应用领域。论文通过统一的“反应式决策”框架整合了不同方面的贡献，显示出一定的理论深度。

<details>
  <summary>Details</summary>

**Motivation:** 随着自主系统日益影响关键社会领域，确保人工智能的负责任使用变得至关重要，但可信赖人工智能的概念仍然宽泛且多方面。本论文旨在推进AI系统在安全、公平、透明和问责制方面的知识。

**Method:** 在安全方面，扩展了经典的确定性防护罩技术以应对延迟观测，并在模拟自动驾驶汽车中实现确定性和概率性安全防护罩以防止碰撞。在公平方面，引入了公平防护罩，这是一种新的后处理方法，用于在顺序决策设置中强制执行群体公平性，通过优化干预成本同时严格确保公平约束。在透明度和问责制方面，提出了一个评估概率决策代理意图的形式框架，引入了代理和意图商数的定量指标，并利用这些指标进行回顾性意图分析以确定责任。最后，通过“反应式决策”框架统一了所有贡献。

**Result:** 扩展的确定性安全防护罩能够抵御延迟观测，实现实际部署。在模拟自动驾驶汽车中验证了安全防护罩在防止碰撞方面的有效性。提出的公平防护罩能够高效平衡公平性与最小干扰，同时严格确保公平约束。提出的意图评估框架和指标有助于在自主系统造成意外伤害时确定责任。所有贡献通过“反应式决策”框架得到统一。

**Conclusion:** 本论文的进展为实现更安全、更公平、更负责任的AI系统做出了实际贡献，为可信赖AI的未来研究奠定了基础。

> **ai_Abstract:** 本论文致力于解决人工智能系统的责任问题，特别关注安全、公平、透明和问责制。研究通过扩展确定性安全防护罩以应对延迟观测，并在模拟自动驾驶汽车中验证其防撞能力来增强安全性。为实现公平性，论文引入了公平防护罩，一种在序列决策中强制执行群体公平性的新方法，旨在以最小干预实现公平。在透明度和问责制方面，论文提出了一个评估概率决策代理意图的形式框架，并引入了量化指标以进行意图回溯分析，从而在发生意外伤害时明确责任。这些贡献最终被统一于“反应式决策”框架下，共同为构建更安全、更公平、更负责任的AI系统奠定了基础。

> **摘要翻译:** 随着自主系统日益影响关键社会领域，确保人工智能（AI）的负责任使用已变得势在必行。然而，可信赖AI的概念仍然宽泛且多方面。本论文在AI系统的安全、公平、透明度和问责制方面推进了知识。在安全方面，我们扩展了经典的确定性防护罩技术，使其能够抵御延迟观测，从而实现在实际条件下的部署。我们还在模拟自动驾驶汽车中实现了确定性和概率性安全防护罩，以防止与道路使用者发生碰撞，验证了这些技术在真实驾驶模拟器中的应用。我们引入了公平防护罩，这是一种新颖的后处理方法，用于在有限和周期性时间范围内的顺序决策设置中强制执行群体公平性。通过优化干预成本同时严格确保公平约束，该方法有效地平衡了公平性与最小干扰。为了实现透明度和问责制，我们提出了一个评估概率决策代理意图的形式框架，引入了代理和意图商数的定量指标。我们使用这些指标来提出意图的回溯分析，这对于在自主系统造成意外伤害时确定责任非常有用。最后，我们通过“反应式决策”框架统一了这些贡献，提供了一个整合先前方法的通用形式化。总的来说，所提出的进展为实现更安全、更公平、更负责任的AI系统做出了实际贡献，为可信赖AI的未来研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [123] [WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2506.10264)
> *WGSR-Bench：基于兵棋推演的LLM博弈论战略推理基准*

*Qiyue Yin, Pei Xu, Qiaozhe Li, Shengda Liu, Shengqi Shen, Tong Wang, Yihong Han, Xiaonan Zhao, Likun Yang, Shiyue Cao, Shiyu Qiu, Yuxuan Liu, Shizhao Yu, Lei Cui, Chengxin Yan, Jie Sun, Xiangquan Tang, Kaiqi Huang* | **Main category: cs.AI**

**Keywords:** 战略推理, 大型语言模型, 兵棋推演, 基准测试, 博弈论

**Comment:** 15 pages, 17 figures

> **TL;DR:** LLM在战略推理方面仍有不足。本文提出了WGSR-Bench，一个基于兵棋推演的LLM战略推理基准，用于评估LLM在多智能体决策、意图推断和反事实推理方面的能力。

**AI_Comments:** 本文创新性地将兵棋推演这一高复杂度战略场景引入LLM评估，填补了现有基准在战略推理领域的空白。通过S-POE架构的细致设计，能够系统地评估LLM在多智能体决策、意图推断和反事实推理等高级认知能力，对推动LLM在复杂决策和战略智能方向的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在数学、符号和常识推理方面取得了显著进展，但作为人类高级认知关键部分的战略推理（即评估动态环境中多智能体行为、制定行动计划和调整策略的能力）尚未得到系统评估或建模。

**Method:** 本文引入了WGSR-Bench，这是第一个使用兵棋推演作为评估环境的LLM战略推理基准。WGSR-Bench围绕环境态势感知、对手风险建模和策略生成这三个核心任务设计测试样本，构成S-POE架构，旨在系统评估战略推理能力。此外，还设计了一个基于LLM的兵棋推演智能体来整合这些部分进行综合评估。

**Result:** 本文成功引入了WGSR-Bench，一个基于兵棋推演的LLM战略推理基准，并设计了相应的测试样本和评估架构，旨在评估最先进LLM在博弈论战略推理方面的优势和局限性。

**Conclusion:** WGSR-Bench旨在系统评估LLM在博弈论战略推理方面的能力，并通过揭示其优缺点来推动大模型驱动的战略智能研究。

> **ai_Abstract:** 本文提出了WGSR-Bench，首个针对大型语言模型（LLMs）的战略推理基准，旨在弥补LLMs在复杂多智能体战略推理能力评估方面的空白。该基准以高复杂度的兵棋推演作为评估环境，通过环境态势感知、对手风险建模和策略生成这三个核心任务，系统地评估LLMs在多智能体决策、意图推断和反事实推理等方面的能力。WGSR-Bench旨在揭示当前LLMs在博弈论战略推理中的优缺点，并推动相关研究。

> **摘要翻译:** 大型语言模型（LLMs）的最新突破使得人工智能在推理任务上的性能取得了质的飞跃，尤其在数学、符号和常识推理方面展现出卓越的能力。然而，作为人类高级认知的一个关键组成部分，战略推理，即评估动态环境中多智能体行为、制定行动计划和调整策略的能力，尚未得到系统评估或建模。为了解决这一空白，本文引入了WGSR-Bench，这是第一个以兵棋推演作为评估环境的LLM战略推理基准。兵棋推演是一个典型的、高复杂度的战略场景，它整合了环境不确定性、对抗动态和非唯一战略选择，使其成为评估LLM在多智能体决策、意图推断和反事实推理能力方面的有效测试平台。WGSR-Bench围绕三个核心任务设计测试样本，即环境态势感知、对手风险建模和策略生成，它们构成了核心S-POE架构，旨在系统地评估战略推理的主要能力。最后，设计了一个基于LLM的兵棋推演智能体来整合这些部分，进行全面的战略推理评估。通过WGSR-Bench，我们希望评估最先进LLM在博弈论战略推理方面的优势和局限性，并推动大模型驱动的战略智能研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [144] [Closer to Language than Steam: AI as the Cognitive Engine of a New Productivity Revolution](https://arxiv.org/abs/2506.10281)
> *比蒸汽更接近语言：AI作为新生产力革命的认知引擎*

*Xinmin Fang, Lingfeng Tao, Zhengxiong Li* | **Main category: cs.AI**

**Keywords:** 人工智能, 生产力革命, 认知引擎, 知识工作, 多学科视角

**Comment:** 12 pages

> **TL;DR:** AI被视为一场认知革命，类似于书面语言，而非工业革命的机械工具，它将推动新的生产力范式。

**AI_Comments:** 这篇论文的创新之处在于其独特的视角，将AI定位为一种“认知引擎”，而非简单的工具或技术进步，并将其与书面语言这种根本性的认知飞跃相类比，从而提升了对AI变革潜力的理解。它强调了AI对知识工作的深远影响，并呼吁对社会和经济结构进行相应的调整，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在将AI重新定义为推动新生产力革命的认知引擎，与工业革命的物理驱动力区分开来，并将其与书面语言等信息技术历史性飞跃相类比，以展示其对知识工作的放大作用。

**Method:** 论文通过发展AI作为认知革命的理论框架，将其与书面语言相类比；通过比较AI的出现与信息技术的历史性飞跃来展示其对知识工作的影响；通过来自不同领域的例子来演示AI作为认知任务生产力驱动力的影响；采用多学科视角，结合计算机科学、经济学和社会学见解；并通过概念框架来可视化从体力生产力到认知生产力的转变。

**Result:** 论文提出AI作为认知引擎，类似于人类语言对知识的革命性影响，预示着新的生产力范式。AI能够增强人类智力，驱动认知任务的生产力。

**Conclusion:** AI的潜力在于补充人类认知能力，标志着生产力演进的新篇章，并要求重新思考技能、组织和政策。

> **ai_Abstract:** 这篇论文将人工智能（AI）重新定义为一场与工业革命不同的认知生产力革命的引擎，并将其与书面语言等人类智力增强的历史性飞跃相提并论。论文通过多学科视角和具体例子，阐述了AI如何作为认知引擎，推动知识工作的生产力，并认为AI的价值在于补充人类认知能力，预示着新的生产力范式，需要重新审视技能、组织和政策。

> **摘要翻译:** 人工智能（AI）被重新定义为推动一场与工业革命的物理推力截然不同的新型生产力革命的认知引擎。本文发展了一个将AI视为一场认知革命的理论框架，类似于书面语言——对人类智力的变革性增强，而非另一种机械工具。我们比较了AI的出现与信息技术的历史性飞跃，以展示它如何放大知识工作。来自各个领域的例子展示了AI作为认知任务生产力驱动力的影响。我们采纳了多学科视角，结合了计算机科学的进步、经济学洞察以及关于AI如何重塑工作和社会的社会学观点。通过概念框架，我们可视化了从体力生产力到认知生产力的转变。我们的核心论点是AI作为认知引擎发挥作用——类似于人类语言如何彻底改变知识——预示着一个新的生产力范式。我们讨论了这场革命如何要求重新思考技能、组织和政策。本文在学术严谨性与清晰性之间取得平衡，得出结论认为AI的希望在于补充人类认知能力，标志着生产力演进的新篇章。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [163] [The Alignment Trap: Complexity Barriers](https://arxiv.org/abs/2506.10304)
> *对齐陷阱：复杂性障碍*

*Jasper Yao* | **Main category: cs.AI**

**Keywords:** AI安全, 计算复杂性, 对齐, 验证, 能力-风险扩展

**Comment:** 29 Pages, 4 Figures

> **TL;DR:** 随着AI系统能力的扩展，验证其安全性面临根本的计算复杂性障碍，导致在实际中难以实现可验证的安全。

**AI_Comments:** 该论文创新性地从计算复杂性理论角度对AI对齐问题进行了系统性分析，揭示了随着AI能力提升，验证其安全性的内在难度。其提出的“难处理性差距”和“战略性三难困境”对AI安全研究和发展具有重要指导意义，强调了在追求AI能力的同时，必须正视其安全验证的根本性挑战。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在建立AI系统能力扩展时验证其安全性的根本计算复杂性障碍，并形式化地分析AI能力增长与社会安全要求之间不可避免的张力。

**Method:** 本研究通过建立形式化的计算复杂性理论框架，提出了能力-风险扩展（CRS）动态，并运用四个核心定理证明了AI安全验证的复杂性边界。核心定理的Lean4形式化验证正在进行中。

**Result:** 主要结果表明：1) 验证复杂性随系统表达能力呈指数增长；2) 安全策略在策略空间中占比极小（至多为 $2^{-2^m}$）；3) 任何有限的对齐技术集都无法提供普适覆盖；4) 鲁棒安全属性对于神经网络形成零测度集。这些结果共同揭示了一个“难处理性差距”。

**Conclusion:** AI发展面临一个战略性三难困境：要么限制系统复杂性以保持可验证的安全性，要么在扩展能力的同时接受不可验证的风险，要么开发超越验证的全新安全范式。

> **ai_Abstract:** 该论文探讨了AI系统能力扩展时验证其安全性的根本计算复杂性障碍。研究表明，对于高表达能力的AI系统，安全验证具有指数级复杂性且是coNP完全的。论文提出了能力-风险扩展动态，并通过四个核心定理证明了验证复杂性与系统表达能力呈指数关系，安全策略空间极小，有限对齐技术无法提供普适覆盖，以及鲁棒安全属性形成零测度集。这些发现揭示了一个“难处理性差距”，并提出了AI发展在限制复杂性、接受不可验证风险或开发新安全范式之间的战略性三难困境。

> **摘要翻译:** 我们建立了验证AI安全性随系统能力扩展而面临的根本计算复杂性障碍。我们的主要结果表明，对于表达能力高于临界阈值 $\tau$ 的EXP$(m)$ AI系统，安全验证需要指数时间并且是coNP完全的。我们形式化了能力-风险扩展（CRS）动态，它展示了AI能力的增长如何推动社会安全要求趋于完美，从而与验证复杂性之间产生不可避免的张力。通过四个核心定理，我们证明了：(1) 验证复杂性随系统表达能力呈指数增长，(2) 安全策略在策略空间中占比至多为 $2^{-2^m}$，(3) 任何有限的对齐技术集都无法提供普适覆盖，(4) 鲁棒安全属性对于神经网络形成零测度集。这些结果描述了一个“难处理性差距”，即实际安全要求落入计算上难以处理的区域。最后，我们提出了一个战略性三难困境：AI发展必须要么限制系统复杂性以保持可验证的安全性，要么在扩展能力的同时接受不可验证的风险，要么开发超越验证的全新安全范式。我们的工作首次提供了AI对齐的系统性复杂性理论分析，并建立了任何安全方法都必须面对的严格界限。核心定理在Lean4中的形式化验证正在进行中。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [194] [Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts](https://arxiv.org/abs/2506.10357)
> *Optimus-3：迈向具有可扩展任务专家的通用多模态Minecraft智能体*

*Zaijing Li, Yuquan Xie, Rui Shao, Gongwei Chen, Weili Guan, Dongmei Jiang, Liqiang Nie* | **Main category: cs.AI**

**Keywords:** 通用智能体, 多模态, Minecraft, 专家混合, 强化学习

**Comment:** 24 pages, 10 figures

> **TL;DR:** Optimus-3通过知识增强数据生成、专家混合架构和多模态推理增强强化学习，解决了在Minecraft中构建通用多模态智能体的挑战，并超越了现有模型。

**AI_Comments:** 本文的创新之处在于其对通用多模态智能体在复杂开放世界（如Minecraft）中面临的核心挑战的系统性解决。通过结合数据生成、模块化架构（MoE）和增强推理能力，Optimus-3显著提升了智能体的泛化能力和性能。其重要性体现在为未来开发更强大、更通用的AI智能体提供了有价值的框架和经验。

<details>
  <summary>Details</summary>

**Motivation:** 在Minecraft等开放世界环境中构建具有感知、规划、行动、接地和反思能力的通用智能体面临挑战，包括领域特定数据不足、异构任务之间的干扰以及开放世界设置中的视觉多样性。

**Method:** 1) 提出了一种知识增强的数据生成管道，以提供可扩展和高质量的训练数据。2) 引入了一种具有任务级路由的专家混合（MoE）架构，以减轻异构任务之间的干扰。3) 开发了一种多模态推理增强强化学习方法，以增强智能体在Minecraft中对视觉多样性的推理能力。

**Result:** Optimus-3在Minecraft环境中的广泛任务中超越了通用多模态大型语言模型和现有的最先进智能体。

**Conclusion:** Optimus-3是一个基于创新技术构建的通用Minecraft智能体，在多项任务中表现优越，解决了开放世界环境中通用智能体开发的关键挑战。

> **ai_Abstract:** 本文介绍了Optimus-3，一个针对Minecraft开放世界环境的通用多模态智能体。该研究通过提出知识增强的数据生成管道解决数据不足问题，引入专家混合（MoE）架构处理异构任务干扰，并开发多模态推理增强强化学习方法应对视觉多样性。实验结果表明，Optimus-3在Minecraft的广泛任务中表现优于现有的通用多模态大模型和最先进的智能体。

> **摘要翻译:** 最近，基于多模态大型语言模型（MLLMs）的智能体在各个领域取得了显著进展。然而，在Minecraft等开放世界环境中构建具有感知、规划、行动、接地和反思等能力的通用智能体仍然面临挑战：领域特定数据不足、异构任务之间的干扰以及开放世界设置中的视觉多样性。在本文中，我们通过三项关键贡献解决了这些挑战。1) 我们提出了一种知识增强的数据生成管道，为智能体开发提供可扩展和高质量的训练数据。2) 为了减轻异构任务之间的干扰，我们引入了一种具有任务级路由的专家混合（MoE）架构。3) 我们开发了一种多模态推理增强强化学习方法，以增强智能体在Minecraft中对视觉多样性的推理能力。基于这些创新，我们提出了Optimus-3，一个用于Minecraft的通用智能体。大量的实验结果表明，Optimus-3在Minecraft环境中的广泛任务中超越了通用多模态大型语言模型和现有的最先进智能体。项目页面：https://cybertronagent.github.io/Optimus-3.github.io/

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [211] [NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War](https://arxiv.org/abs/2506.10384)
> *NeuroPAL：基于神经进化的即时学习在《星际争霸：母巢之战》宏观管理中的应用*

*Jim O'Connor, Yeonghun Lee, Gary B Parker* | **Main category: cs.AI**

**Keywords:** 神经进化, 即时学习, 星际争霸, 宏观管理, 人工智能

**Comment:** IEEE Conference on Games 2025

> **TL;DR:** NeuroPAL结合神经进化和即时学习，显著加速了《星际争霸：母巢之战》AI的宏观管理训练，使其在更短时间内达到专家级表现。

**AI_Comments:** 本文的创新点在于将即时学习（PAL）与神经进化（NEAT）相结合，有效解决了传统神经进化训练效率低下的问题，显著加速了AI在复杂RTS游戏中的学习过程。其重要性在于为实时战略游戏AI的宏观管理提供了一种更高效、更具适应性的训练范式。

<details>
  <summary>Details</summary>

**Motivation:** 《星际争霸：母巢之战》的宏观管理对AI研究仍具挑战，传统方法（基于规则或监督深度学习）在适应性和计算效率上存在局限性。

**Method:** 本文引入了NeuroPAL，一个结合了增强拓扑神经进化（NEAT）和即时学习（PAL）的神经进化框架。PAL通过频繁的低保真训练和周期性的高保真评估交替进行，提高了NEAT的样本效率。

**Result:** NeuroPAL在《星际争霸：母巢之战》中，将代理达到竞争水平所需训练时间缩短了约一半，并且进化出的代理展现出专家级行为，如前置兵营和防御建筑优化。

**Conclusion:** 结构化评估机制（如PAL）可以增强神经进化在复杂实时战略环境中的可扩展性和有效性。

> **ai_Abstract:** 本文提出了NeuroPAL，一个结合了增强拓扑神经进化（NEAT）和即时学习（PAL）的神经进化框架，旨在解决《星际争霸：母巢之战》宏观管理中传统AI方法的局限性。NeuroPAL通过交替进行低保真训练和高保真评估，显著提高了训练效率，使AI代理在约一半的时间内达到竞争水平，并展现出专家级策略。研究表明，PAL等结构化评估机制能有效提升神经进化在复杂RTS环境中的表现。

> **摘要翻译:** 《星际争霸：母巢之战》仍然是人工智能研究的一个具有挑战性的基准，特别是在需要长期战略规划的宏观管理领域。传统的星际争霸AI方法依赖于基于规则的系统或监督式深度学习，这两种方法在适应性和计算效率方面都面临局限性。在这项工作中，我们引入了NeuroPAL，这是一个神经进化框架，它将增强拓扑神经进化（NEAT）与即时学习（PAL）相结合，以提高进化训练的效率。通过在频繁的低保真训练和周期性的高保真评估之间交替进行，PAL提高了NEAT的样本效率，使代理能够在更少的训练迭代中发现有效的策略。我们在《星际争霸：母巢之战》的固定地图、单一种族场景中评估了NeuroPAL，并将其性能与标准的基于NEAT的训练进行了比较。我们的结果表明，PAL显著加速了学习过程，使代理在大约一半的训练时间内达到具有竞争力的游戏水平，而单独使用NEAT则需要更长的时间。此外，进化的代理展现出诸如前置兵营放置和防御建筑优化等新兴行为，这些策略是人类专家玩家常用的。这些发现表明，像PAL这样的结构化评估机制可以增强神经进化在复杂实时战略环境中的可扩展性和有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [227] [Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills](https://arxiv.org/abs/2506.10387)
> *幻影-1：通过分层多模态技能增强和更新GUI代理*

*Yuquan Xie, Zaijing Li, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Dongmei Jiang, Liqiang Nie* | **Main category: cs.AI**

**Keywords:** GUI代理, 多模态大语言模型, 分层多模态技能, 技能增强蒙特卡洛树搜索, 长周期任务

**Comment:** 20 pages, 5 figures, 5 tables

> **TL;DR:** 提出Mirage-1，一个基于分层多模态技能（HMS）和技能增强蒙特卡洛树搜索（SA-MCTS）的GUI代理，解决了现有MLLM代理在长周期任务中的知识不足和域间隙问题，并在多个基准测试中表现出色。

**AI_Comments:** 这篇论文的创新点在于结合了分层知识结构（HMS）和高效的在线搜索策略（SA-MCTS），以解决GUI代理在复杂长周期任务中的两大核心挑战。HMS模仿了人类泛化知识的方式，提供了更鲁棒的知识表示，而SA-MCTS则有效地利用了离线学习的经验来加速在线决策，体现了理论与实践的有效结合。此外，构建新的AndroidLH基准也为未来研究提供了宝贵的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于多模态大语言模型（MLLM）的GUI代理在在线环境中处理长周期任务时，由于知识不足以及离线和在线领域之间的固有差距，仍然面临挑战。

**Method:** 提出分层多模态技能（HMS）模块，通过将轨迹逐步抽象为执行技能、核心技能和元技能，提供分层知识结构以解决知识不足问题。同时，提出技能增强蒙特卡洛树搜索（SA-MCTS）算法，利用离线环境中获得的技能来减少在线树探索期间的动作搜索空间，以弥合领域差距。在此基础上构建了多模态、跨平台、即插即用的GUI代理Mirage-1，并构建了新的基准AndroidLH进行验证。

**Result:** Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上分别比之前的代理性能提高了32%、19%、15%和79%。

**Conclusion:** Mirage-1通过其分层多模态技能和技能增强蒙特卡洛树搜索算法，有效解决了GUI代理在长周期任务中的知识不足和领域差距问题，并在多个基准测试中显著超越了现有代理，证明了其在真实世界长周期场景中的优越性能。

> **ai_Abstract:** 本文针对基于MLLM的GUI代理在处理在线长周期任务时存在的知识不足和离线-在线域间隙问题，提出了Mirage-1代理。Mirage-1的核心是分层多模态技能（HMS）模块，它通过多层抽象构建知识结构以应对知识不足；同时，引入技能增强蒙特卡洛树搜索（SA-MCTS）算法，利用离线技能优化在线搜索空间以弥合域间隙。研究团队还构建了新的AndroidLH基准来评估Mirage-1的真实世界性能。实验结果显示，Mirage-1在多个基准测试中显著优于现有代理。

> **摘要翻译:** 近期利用多模态大语言模型（MLLM）作为GUI代理的努力取得了可喜的成果。然而，这些代理在在线环境中处理长周期任务时仍然面临挑战，主要原因在于知识不足以及离线和在线领域之间的固有差距。在本文中，受人类在开放式环境中泛化知识的方式启发，我们提出了一种分层多模态技能（HMS）模块来解决知识不足的问题。它将轨迹逐步抽象为执行技能、核心技能，并最终抽象为元技能，为长周期任务规划提供分层知识结构。为了弥合领域差距，我们提出了技能增强蒙特卡洛树搜索（SA-MCTS）算法，该算法有效利用离线环境中获得的技能来减少在线树探索期间的动作搜索空间。基于HMS，我们提出了Mirage-1，一个多模态、跨平台、即插即用的GUI代理。为了验证Mirage-1在真实世界长周期场景中的性能，我们构建了一个新的基准AndroidLH。实验结果表明，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上分别比之前的代理性能提高了32%、19%、15%和79%。项目页面：https://cybertronagent.github.io/Mirage-1.github.io/

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [239] [Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges](https://arxiv.org/abs/2506.10408)
> *通过系统1或系统2进行推理RAG：面向行业挑战的推理代理检索增强生成综述*

*Jintao Liang, Gang Su, Huifeng Lin, You Wu, Rui Zhao, Ziyue Li* | **Main category: cs.AI**

**Keywords:** 推理代理RAG, 检索增强生成, 大型语言模型, 预定义推理, 代理推理

**Comment:** 

> **TL;DR:** 本综述回顾了推理代理检索增强生成（Reasoning Agentic RAG），将其分为预定义推理和代理推理两种系统，并分析了其方法、挑战和未来方向，以解决传统RAG在复杂推理场景中的局限性。

**AI_Comments:** 这篇综述论文及时地总结了RAG领域从静态管道向更具动态性和自主性的推理代理RAG的演变，对理解当前RAG技术面临的挑战和发展趋势具有重要意义。其将推理代理RAG划分为预定义推理和代理推理的分类方式清晰且具洞察力，为后续研究提供了良好的框架。论文不仅梳理了现有技术，还指出了未来的研究方向，对推动该领域的发展具有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的检索增强生成（RAG）系统在需要复杂推理、动态检索和多模态集成的现实世界场景中表现不佳，难以克服大型语言模型（LLMs）的知识局限性。为应对这些挑战，研究领域转向了推理代理RAG。

**Method:** 本文对推理代理RAG方法进行了全面综述，将其分为两大主要系统：遵循固定模块化管道以增强推理的“预定义推理”和模型在推理过程中自主协调工具交互的“代理推理”。文章分析了这两种范式下的代表性技术，涵盖架构设计、推理策略和工具协调。

**Result:** 本文成功地将推理代理RAG方法分为预定义推理和代理推理两大系统，并对每种系统下的代表性技术进行了详细分析，涵盖了架构设计、推理策略和工具协调等方面。

**Conclusion:** 推理代理RAG旨在通过嵌入决策和自适应工具使用来解决传统RAG在复杂推理场景中的局限性。未来研究应着重于提高推理代理RAG系统的灵活性、鲁棒性和适用性。

> **ai_Abstract:** 本综述论文全面审视了推理代理检索增强生成（Reasoning Agentic RAG）领域，旨在解决传统RAG在复杂推理和动态场景中的不足。文章将推理代理RAG方法划分为预定义推理和代理推理两大范式，并深入分析了各自的架构设计、推理策略和工具协调技术。最后，论文探讨了当前的研究挑战，并为提升推理代理RAG系统的灵活性、鲁棒性和适用性提出了未来的研究方向。

> **摘要翻译:** 检索增强生成（RAG）已成为一个强大的框架，通过将外部检索与语言生成相结合，克服大型语言模型（LLM）的知识局限性。虽然基于静态管道的早期RAG系统在结构良好的任务中显示出有效性，但它们在需要复杂推理、动态检索和多模态集成的现实世界场景中举步维艰。为了应对这些挑战，该领域已转向推理代理RAG，这是一种将决策制定和自适应工具使用直接嵌入到检索过程中的范式。在本文中，我们对推理代理RAG方法进行了全面综述，将其分为两大主要系统：预定义推理，它遵循固定的模块化管道以增强推理；以及代理推理，其中模型在推理过程中自主协调工具交互。我们分析了这两种范式下的代表性技术，涵盖了架构设计、推理策略和工具协调。最后，我们讨论了关键的研究挑战，并提出了未来的方向，以提高推理代理RAG系统的灵活性、鲁棒性和适用性。我们收集的相关研究已整理到https://github.com/ByebyeMonica/Reasoning-Agentic-RAG。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [264] [OIBench: Benchmarking Strong Reasoning Models with Olympiad in Informatics](https://arxiv.org/abs/2506.10481)
> *OIBench：使用信息学奥赛基准测试强大的推理模型*

*Yaoming Zhu, Junxin Wang, Yiyang Li, Lin Qiu, ZongYu Wang, Jun Xu, Xuezhi Cao, Yuhuai Wei, Mingshi Wang, Xunliang Cai, Rong Ma* | **Main category: cs.AI**

**Keywords:** OIBench, 算法推理, 基准测试, 信息学奥赛, 大型语言模型

**Comment:** 

> **TL;DR:** OIBench是一个高质量、私有、具有挑战性的奥赛级别信息学数据集，用于评估和推动算法推理模型的进步。实验表明，当前SOTA模型在正确性和效率上已超越大多数人类参与者，但仍未达到最优解。

**AI_Comments:** OIBench的创新之处在于其奥赛级别的问题难度和抗污染特性，为评估和推动高级算法推理能力提供了更严格的基准。其引入的时间/空间完成曲线和人机对比评估方法也提供了更细致的分析维度。该工作对于LLM在复杂编程和算法领域的进展具有重要意义，有助于识别当前模型的局限性并指导未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着模型日益复杂，传统算法基准测试已趋于饱和，急需更具挑战性的基准来指导算法推理能力的未来改进。

**Method:** 本文介绍了OIBench，一个包含250个精心策划的原创问题的奥赛级别信息学数据集。详细阐述了基准的构建方法，以确保对各种编程范式和复杂性进行全面评估，并通过实验证明了其抗污染特性。提出了时间/空间完成曲线进行更细粒度的效率分析，并通过高级别参与者评估实现人机直接比较。

**Result:** 实验表明，开源模型落后于闭源模型，但当前最先进的模型在正确性和效率方面已超越大多数人类参与者，尽管与标准解决方案相比仍有不足。

**Conclusion:** 通过发布OIBench作为完全开源的资源，作者希望这个基准能够促进未来大型语言模型的代码推理能力的发展。

> **ai_Abstract:** 本文引入了OIBench，一个高质量、私有、具有挑战性的信息学奥赛级别数据集，旨在解决现有算法基准饱和的问题。该数据集包含250个原创问题，并详细介绍了其构建方法和抗污染特性。研究者提出了时间/空间完成曲线进行效率分析，并实现了人机性能比较。实验结果显示，当前最先进的模型在正确性和效率上已超越大多数人类，但仍未达到最优解，且开源模型表现不及闭源模型。OIBench的开源发布旨在推动未来大型语言模型的代码推理能力。

> **摘要翻译:** 随着模型日益复杂，传统算法基准测试已趋于饱和，这凸显了需要更具挑战性的基准来指导算法推理的未来改进。本文介绍了OIBench，一个高质量、私有、具有挑战性的奥赛级别信息学数据集，包含250个精心策划的原创问题。我们详细介绍了该基准的构建方法，确保对各种编程范式和复杂性进行全面评估，并通过实验证明了其抗污染特性。我们提出了时间/空间完成曲线用于更细粒度的效率分析，并通过高级别参与者评估实现人机直接比较。我们的实验表明，虽然开源模型落后于闭源模型，但当前最先进的模型在正确性和效率方面已超越大多数人类参与者，尽管与规范解决方案相比仍有不足。通过将OIBench作为一个完全开源的资源发布（https://huggingface.co/datasets/AGI-Eval/OIBench），我们希望这个基准能够促进未来大型语言模型的代码推理能力的发展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [275] [A Study on Individual Spatiotemporal Activity Generation Method Using MCP-Enhanced Chain-of-Thought Large Language Models](https://arxiv.org/abs/2506.10853)
> *基于MCP增强型思维链大语言模型的个体时空活动生成方法研究*

*Yu Zhang, Yang Hu, De Wang* | **Main category: cs.AI**

**Keywords:** 时空活动生成, 大语言模型, 思维链, 模型上下文协议, 城市计算

**Comment:** 

> **TL;DR:** 本文提出了一种结合思维链（CoT）和模型上下文协议（MCP）的框架，以增强大语言模型在生成与真实数据模式相符的个体时空活动方面的能力，并在上海陆家嘴地区验证了其有效性。

**AI_Comments:** 该研究通过将思维链推理与模型上下文协议结合，有效地解决了大语言模型在时空行为模拟中面临的空间认知和物理约束理解等挑战，其创新点在于为LLMs提供了更精细的上下文管理和认知框架，使其能够生成更符合现实模式的个体时空活动。这对于城市规划、交通预测等领域具有重要的实际应用价值，为合成出行数据生成提供了一条高效且高保真的路径。

<details>
  <summary>Details</summary>

**Motivation:** 传统的时空行为模拟方法计算成本高、泛化能力和可扩展性差。大语言模型（LLMs）虽有潜力，但在时空推理方面存在空间认知有限、缺乏物理约束理解和群体同质化等挑战。

**Method:** 本文引入了一个将思维链（CoT）推理与模型上下文协议（MCP）相结合的框架，通过五阶段认知框架实现类人渐进推理，并利用六类专门的MCP工具（时间管理、空间导航、环境感知、个人记忆、社会协作、经验评估）进行数据处理。

**Result:** 在上海陆家嘴地区进行的实验中，该框架在1,000个生成样本上展现出有效性，与真实移动信令数据高度相似，生成质量分数达到7.86至8.36。并行处理实验显示效率提升，每个样本的生成时间从1.30分钟减少到0.17分钟。

**Conclusion:** 该工作将思维链推理与模型上下文协议整合用于城市行为建模，推动了大语言模型在城市计算中的应用，为合成出行数据生成提供了一种实用方法，并为智慧城市规划、交通预测和参与式城市设计奠定了基础。

> **ai_Abstract:** 本文提出一种结合思维链（CoT）推理和模型上下文协议（MCP）的新框架，旨在解决传统方法和现有大语言模型在时空行为模拟中的局限性。该框架通过五阶段认知推理和六类MCP工具增强LLMs的空间认知和物理约束理解能力。实验结果表明，该方法能有效生成与真实数据高度相似的个体时空活动，并显著提升了生成效率，为城市计算和合成出行数据生成提供了实用方案，对智慧城市规划等领域具有重要意义。

> **摘要翻译:** 人类时空行为模拟对于城市规划研究至关重要，但传统的基于规则和统计的方法存在计算成本高、泛化能力有限和可扩展性差的问题。尽管大语言模型（LLMs）作为“世界模拟器”展现出潜力，但它们在时空推理方面面临挑战，包括空间认知有限、缺乏物理约束理解以及群体同质化倾向。本文引入了一个将思维链（CoT）推理与模型上下文协议（MCP）相结合的框架，以增强LLMs模拟与验证数据模式相符的时空行为的能力。该方法通过五阶段认知框架结合类人渐进推理，并通过六类专门的MCP工具进行全面的数据处理：时间管理、空间导航、环境感知、个人记忆、社会协作和经验评估。在上海陆家嘴地区的实验验证了该框架在1,000个生成样本上的有效性。结果表明，与真实的移动信令数据具有高度相似性，在不同基础模型上实现了7.86到8.36的生成质量分数。并行处理实验显示了效率的提升，当从2个进程扩展到12个进程时，每个样本的生成时间从1.30分钟减少到0.17分钟。这项工作有助于将CoT推理与MCP整合用于城市行为建模，推进LLMs在城市计算中的应用，并为合成出行数据生成提供了一种实用方法。该框架为智慧城市规划、交通预测和参与式城市设计应用奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [277] [Scientists' First Exam: Probing Cognitive Abilities of MLLM via Perception, Understanding, and Reasoning](https://arxiv.org/abs/2506.10521)
> *科学家初考：通过感知、理解和推理探究多模态大语言模型（MLLM）的认知能力*

*Yuhao Zhou, Yiheng Wang, Xuming He, Ruoyao Xiao, Zhiwei Li, Qiantai Feng, Zijie Guo, Yuejin Yang, Hao Wu, Wenxuan Huang, Jiaqi Wei, Dan Si, Xiuqi Yao, Jia Bu, Haiwen Huang, Tianfan Fu, Shixiang Tang, Ben Fei, Dongzhan Zhou, Fenghua Ling, Yan Lu, Siqi Sun, Chenhui Li, Guanjie Zheng, Jiancheng Lv, Wenlong Zhang, Lei Bai* | **Main category: cs.AI**

**Keywords:** MLLM, 科学基准, 认知能力, 感知, 推理

**Comment:** 82 pages

> **TL;DR:** 本文提出了SFE基准，用于评估MLLM在科学领域中的感知、理解和推理能力，结果显示现有SOTA模型表现不佳，仍有巨大提升空间。

**AI_Comments:** 该论文的创新之处在于提出了一个专门用于评估多模态大语言模型（MLLM）在科学领域中感知、理解和推理能力的全新基准——SFE，弥补了现有基准主要关注知识理解的不足。其重要性在于为未来AI增强科学发现提供了更全面的评估工具，并明确指出了当前SOTA模型在该领域的局限性，为后续研究指明了方向。通过揭示现有MLLM在复杂科学认知任务上的不足，该工作为推动AI在科学研究中的应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有科学基准主要侧重于评估多模态大语言模型（MLLM）的知识理解能力，导致对其感知和推理能力的评估不足。为了弥补这一空白，本文提出了一个新的基准。

**Method:** 本文提出了“科学家初考”（SFE）基准，旨在通过科学信号感知、科学属性理解和科学比较推理三个相互关联的层面来评估MLLM的科学认知能力。SFE包含830对专家验证的VQA（视觉问答）对，涵盖三种问题类型，涉及五个高价值学科的66个多模态任务。

**Result:** 广泛的实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分分别仅为34.08%和26.52%，这突出表明MLLM在科学领域仍有巨大的改进空间。

**Conclusion:** SFE基准揭示了当前MLLM在科学感知、理解和推理能力方面的不足，预示着未来AI增强科学发现的巨大潜力，并希望其提供的见解能促进进一步发展。

> **ai_Abstract:** 本文针对现有科学基准未能充分评估多模态大语言模型（MLLM）感知和推理能力的问题，提出了“科学家初考”（SFE）基准。SFE通过科学信号感知、科学属性理解和科学比较推理三个层面，包含830对专家验证的VQA对，涵盖66个多模态任务和五个学科，全面评估MLLM的科学认知能力。实验结果显示，当前最先进的MLLM模型表现不佳，表明其在科学领域仍有显著提升空间，该基准有望推动AI增强科学发现的进一步发展。

> **摘要翻译:** 科学发现越来越依赖于基于信息密集型科学数据和领域专业知识的复杂多模态推理。在专家级科学基准的加持下，科学多模态大语言模型（MLLM）有潜力在现实工作流程中显著增强这一发现过程。然而，当前的科学基准大多侧重于评估MLLM的知识理解能力，导致对其感知和推理能力的评估不足。为了弥补这一空白，我们提出了“科学家初考”（SFE）基准，旨在通过科学信号感知、科学属性理解、科学比较推理三个相互关联的层面来评估MLLM的科学认知能力。具体而言，SFE包含830对专家验证的VQA（视觉问答）对，涵盖三种问题类型，涉及五个高价值学科的66个多模态任务。广泛的实验表明，当前最先进的GPT-o3和InternVL-3在SFE上的得分分别仅为34.08%和26.52%，这突出表明MLLM在科学领域仍有巨大的改进空间。我们希望SFE中获得的见解能促进AI增强科学发现的进一步发展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [288] [LogiPlan: A Structured Benchmark for Logical Planning and Relational Reasoning in LLMs](https://arxiv.org/abs/2506.10527)
> *LogiPlan：一个用于大型语言模型逻辑规划和关系推理的结构化基准*

*Yanan Cai, Ahmed Salem, Besmira Nushi, Mark Russinovich* | **Main category: cs.AI**

**Keywords:** 逻辑规划, 关系推理, 大型语言模型, 基准, 结构化图

**Comment:** 

> **TL;DR:** LogiPlan是一个评估大型语言模型逻辑规划和关系推理能力的新基准。它包含生成、一致性检测和比较任务，并揭示了当前LLM在复杂逻辑规划方面存在显著性能差距。

**AI_Comments:** LogiPlan的创新之处在于其结构化的设计和动态调整复杂度的能力，这为评估LLM的逻辑规划和关系推理能力提供了一个精细的工具。该基准的重要性在于它揭示了当前LLM在处理复杂逻辑任务时的局限性，为未来研究指明了方向。论文强调了模型规模和架构对性能的影响，并指出即使是先进模型也难以应对深度逻辑规划，这表明LLM在真正掌握复杂推理方面仍有很长的路要走。

<details>
  <summary>Details</summary>

**Motivation:** 逻辑关系推理对于依赖大型语言模型（LLMs）生成和查询结构化关系图（如网络基础设施、知识库或业务流程模式）的应用至关重要，因此需要一个专门的基准来评估LLM在这些方面的能力。

**Method:** 本文引入了LogiPlan基准，通过控制对象数量、关系和关系链的最小深度来动态调整任务复杂性。LogiPlan包含三个互补任务：计划生成（构建有效的有向关系图）、一致性检测（识别关系结构中的不一致性）和比较问题（评估查询关系的有效性）。此外，还通过提示模型验证和完善其初始解决方案来评估其自我纠正能力。该研究评估了包括DeepSeek R1、Gemini 2.0 Pro、Gemini 2 Flash Thinking、GPT-4.5、GPT-4o、Llama 3.1 405B、O3-mini、O1和Claude 3.7 Sonnet在内的先进模型。

**Result:** 评估结果显示，模型性能存在显著差距，且与模型规模和架构相关。尽管近期增强推理能力的模型在简单实例上表现出有希望的结果，但它们在需要更深层次逻辑规划的复杂配置上表现不佳。

**Conclusion:** 当前最先进的大型语言模型虽然在简单任务上表现出潜力，但在需要深度逻辑规划的复杂场景中仍面临显著挑战，这表明在该领域仍有很大的改进空间。

> **ai_Abstract:** LogiPlan是一个新的基准，旨在评估大型语言模型（LLMs）在逻辑规划和复杂关系推理方面的能力。该基准通过动态调整任务复杂度，涵盖计划生成、一致性检测和比较问题三个核心任务，并评估了模型的自我纠正能力。对包括Gemini和GPT系列在内的SOTA模型进行的评估显示，模型性能存在显著差距，且与模型规模和架构相关。研究发现，尽管现有模型在简单任务上表现良好，但在需要深度逻辑规划的复杂场景中仍面临挑战。

> **摘要翻译:** 我们引入了LogiPlan，一个旨在评估大型语言模型（LLMs）在逻辑规划和复杂关系结构推理方面能力的新型基准。逻辑关系推理对于可能依赖LLMs生成和查询结构化关系图（如网络基础设施、知识库或业务流程模式）的应用至关重要。我们的框架允许通过控制对象数量、关系和关系链的最小深度来动态改变任务复杂性，从而对模型在不同难度级别下的性能进行细致评估。LogiPlan包含三个互补任务：(1) 计划生成，模型必须构建满足指定结构约束的有效有向关系图；(2) 一致性检测，测试模型识别关系结构中不一致性的能力；以及(3) 比较问题，评估模型确定给定图中查询关系有效性的能力。此外，我们通过提示模型验证和完善其初始解决方案来评估模型的自我纠正能力。我们评估了包括DeepSeek R1、Gemini 2.0 Pro、Gemini 2 Flash Thinking、GPT-4.5、GPT-4o、Llama 3.1 405B、O3-mini、O1和Claude 3.7 Sonnet在内的先进模型在这些任务上的表现，揭示了与模型规模和架构相关的显著性能差距。我们的分析表明，尽管近期增强推理能力的模型在简单实例上表现出有希望的结果，但它们在需要更深层次逻辑规划的复杂配置上表现不佳。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [299] [Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning](https://arxiv.org/abs/2506.10585)
> *Primender 序列：一种用于测试符号推理和AI推理的新型数学结构*

*Mohd Anwar Jamal Faiz* | **Main category: cs.AI**

**Keywords:** Primender 序列, 符号推理, LLM, 数学基准, 假设检验

**Comment:** 9 pages, 7 figures, 2 tables, 3 codes, oeis sequence A384735

> **TL;DR:** 本文引入了 Primender 序列，这是一种新型整数序列，用作评估大型语言模型（LLMs）符号推理能力的基准。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的数学序列（Primender 序列）作为评估LLM符号推理能力的独特基准。它结合了数论的确定性与符号模式的复杂性，为测试LLM在推断隐藏规则、验证数学假设和泛化符号逻辑方面的能力提供了一个可解释且基于规则的测试平台。其重要性在于为LLM评估提供了一个新的视角，超越了传统语言任务，深入到更深层次的逻辑和数学推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 出于对可解释、基于规则的测试平台的需求，以评估LLM推断隐藏规则、验证数学假设和大规模泛化符号逻辑的能力。

**Method:** 定义了 Primender 序列，提出并测试了一个关于序列的数学假设。设计了一个结构化提示和评估框架，使用包括ChatGPT、Copilot、DeepSeek、Gemini、Grok和LLaMA在内的多个最先进的LLM进行测试，并使用规则推理准确性、假设评估、序列有效性和符号解释质量等指标评估模型性能。

**Result:** Not mentioned in abstract

**Conclusion:** 这项工作贡献了一种新颖的数学结构和可重复的方法，用于基准测试LLM在符号推理、假设检验和可扩展模式泛化方面的能力，连接了数论、人工智能和软件工程领域。

> **ai_Abstract:** 本文引入了 Primender 序列，这是一种结合素数性和数字后缀条件的新型整数序列，旨在作为评估大型语言模型（LLM）符号推理能力的基准。研究提出并测试了一个关于该序列的数学假设，通过设计结构化提示和评估框架，使用多种先进LLM（如ChatGPT、Gemini）进行测试，以评估它们在规则推断、假设验证和大规模序列生成方面的表现。这项工作提供了一个用于LLM符号推理基准测试的新颖数学工具和可重复方法。

> **摘要翻译:** 本文介绍了 Primender 序列，这是一种通过结合经典素数性与基于模数字条件定义的整数序列。具体来说，如果一个数字 n 是素数，或者其单位数字或任意长度的结尾是一个素数，则它被包含在该序列中。换句话说，是素数或至少有一个素数后缀的数字。由此产生的序列表现出确定性但非平凡的结构，融合了数论性质与符号模式。我们建议将 Primender 序列作为评估大型语言模型（LLM）符号推理能力的基准。这项研究的动机在于需要可解释的、基于规则的测试平台，以评估LLM推断隐藏规则、验证数学假设以及大规模泛化符号逻辑的能力。探讨的一个关键假设是：当 Primender 序列中的一个数字恰好比小于或等于它的最大素数大一时，该数字与序列中前一个数字之间的差值也为1。我们设计了一个结构化提示和评估框架，用于在包括 ChatGPT、Copilot、DeepSeek、Gemini、Grok 和 LLaMA 在内的多个最先进的 LLM 上测试这一假设。模型的任务是识别底层规则、验证假设并生成序列的接下来的 100,000 个项。使用规则推理准确性、假设评估、序列有效性和符号解释质量等比较指标来评估模型性能。这项工作贡献了一种新颖的数学结构和可重复的方法，用于基准测试 LLM 在符号推理、假设检验和可扩展模式泛化方面的能力——桥接了数论、人工智能和软件工程领域。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [310] [Data Driven Diagnosis for Large Cyber-Physical-Systems with Minimal Prior Information](https://arxiv.org/abs/2506.10613)
> *针对大型信息物理系统在先验信息最少情况下的数据驱动诊断*

*Henrik Sebastian Steude, Alexander Diedrich, Ingo Pill, Lukas Moddemann, Daniel Vranješ, Oliver Niggemann* | **Main category: cs.AI**

**Keywords:** 数据驱动诊断, 信息物理系统, 最小先验信息, 神经网络, 图诊断

**Comment:** 

> **TL;DR:** 提出一种新的数据驱动诊断方法，针对大型信息物理系统，仅需少量先验信息，结合神经网络和图诊断算法，并在模拟和实际数据集上表现良好。

**AI_Comments:** 该论文的创新点在于其能够在先验信息极少的情况下对大型复杂信息物理系统进行诊断，这对于实际应用中数据和模型获取困难的场景具有重要意义。结合神经网络进行症状生成和图算法进行诊断，是解决这一挑战的有效途径。其在模拟和真实数据集上的验证也增强了方法的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 诊断复杂信息物理系统通常需要大量的先验知识（如详细系统模型或全面的训练数据），但获取这些信息非常困难。

**Method:** 该方法结合了一个基于神经网络的症状生成器（采用子系统级异常检测）和一个新的图诊断算法（利用子系统间最小的因果关系信息），仅需对子系统关系的基本理解和正常操作数据。

**Result:** 在完全可控的模拟数据集上，该方法在82%的案例中诊断集中包含真实的因果成分，并在73%的场景中有效减少了搜索空间。在真实世界的安全水处理数据集上的额外测试也展示了其在实际场景中的潜力。

**Conclusion:** 该方法在先验知识有限的大型复杂信息物理系统实际应用中具有巨大潜力。

> **ai_Abstract:** 本文提出了一种针对大型复杂信息物理系统的数据驱动诊断新方法，旨在解决传统诊断方法对大量先验知识的依赖。该方法仅需对子系统关系的基本理解和正常操作数据，通过结合基于神经网络的症状生成器（进行子系统级异常检测）和新的图诊断算法（利用最小因果关系信息）实现。实验证明，该方法在模拟数据集上能有效识别真实因果成分并减少搜索空间，并在实际数据集上展现出应用潜力，凸显了其在先验知识受限的复杂系统诊断中的实用性。

> **摘要翻译:** 复杂信息物理系统的诊断过程通常需要大量的先验知识，形式为详细的系统模型或全面的训练数据。然而，获取此类信息提出了重大挑战。为了解决这个问题，我们提出了一种新的诊断方法，该方法在最少的先验知识下运行，仅需要对子系统关系的基本理解和来自正常操作的数据。我们的方法结合了一个基于神经网络的症状生成器，该生成器采用子系统级异常检测，以及一种新的图诊断算法，该算法利用子系统之间最小的因果关系信息——这些信息在实践中通常是可用的。我们对完全可控的模拟数据集进行的实验表明，我们的方法在82%的所有案例中，其诊断集包含真实的因果成分，同时在73%的场景中有效减少了搜索空间。在真实世界的安全水处理数据集上的额外测试展示了该方法在实际场景中的潜力。因此，我们的结果突出了该方法在先验知识有限的大型复杂信息物理系统实际应用中的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [320] [TeleMath: A Benchmark for Large Language Models in Telecom Mathematical Problem Solving](https://arxiv.org/abs/2506.10674)
> *TeleMath: 电信数学问题解决中大型语言模型的基准*

*Vincenzo Colle, Mohamed Sana, Nicola Piovesan, Antonio De Domenico, Fadhel Ayed, Merouane Debbah* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 电信, 数学推理, 基准, 数据集

**Comment:** 6 pages

> **TL;DR:** 本文介绍了TeleMath，这是首个用于评估大型语言模型（LLMs）在电信领域数学问题解决能力的基准数据集（包含500个问答对）。研究发现，专门为数学或逻辑推理设计的LLMs表现最佳，而通用LLMs则表现不佳。数据集和评估代码已发布。

**AI_Comments:** 该论文通过创建TeleMath基准数据集，填补了大型语言模型在电信领域特定数学问题解决能力评估方面的关键空白，具有重要意义。这一创新性贡献为评估LLMs在专业技术领域的实际应用提供了一个标准化工具。研究结果表明，针对数学或逻辑推理进行优化的模型表现更佳，这强调了在实际AI部署中对领域特定微调或架构的需求。数据集和代码的发布进一步增强了其影响力，促进了研究的可复现性和合作。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在一般数学推理方面有所进步，但它们在电信领域（如信号处理、网络优化、性能分析）等专业且数学密集型任务中的有效性尚未得到充分探索。目前缺乏专门的基准来评估LLMs在这些领域解决数学问题的能力。

**Method:** 作者引入了TeleMath，这是一个包含500个问答对（QnA）的基准数据集，由主题专家精心设计，旨在评估LLMs在电信领域解决数值数学问题的性能。论文详细介绍了QnA的生成流程。随后，他们使用该基准评估了多种开源大型语言模型。

**Result:** 评估结果显示，专门为数学或逻辑推理设计的最新大型语言模型在TeleMath基准上表现最佳。相比之下，即使是参数量庞大的通用大型语言模型，在面对这些电信领域的专业数学挑战时也常常表现不佳。

**Conclusion:** 专门为数学或逻辑推理优化的大型语言模型在解决电信领域特定数学问题上的表现优于通用大型语言模型。TeleMath基准的发布将有助于推动该领域的未来研究。

> **ai_Abstract:** 本文介绍了TeleMath，这是首个专门用于评估大型语言模型（LLMs）在电信领域解决数学问题能力的基准数据集。该研究旨在弥补LLMs在信号处理、网络优化等专业数学密集型电信任务中性能评估的空白。TeleMath包含500个由主题专家构建的问答对。对多种开源LLMs的评估表明，专门为数学或逻辑推理设计的模型表现优异，而通用模型则面临挑战。为促进研究和复现性，数据集和评估代码已公开发布。

> **摘要翻译:** 随着人工智能在电信领域的日益普及，人们对大型语言模型（LLMs）解决领域特定、数学密集型任务的能力越来越感兴趣。尽管最近的进展提高了LLMs在一般数学推理方面的性能，但它们在信号处理、网络优化和性能分析等专业领域中的有效性在很大程度上仍未被探索。为了弥补这一空白，我们引入了TeleMath，这是第一个专门设计用于评估LLMs在电信领域解决数值数学问题的性能的基准数据集。TeleMath包含500个问答（QnA）对，涵盖了电信领域的广泛主题。本文概述了所提出的QnA生成管道，该管道从由主题专家精心制作的精选问题种子开始。对各种开源LLMs的评估表明，在TeleMath上表现最佳的是那些明确为数学或逻辑推理而设计的最新模型。相比之下，通用模型，即使参数数量庞大，也常常难以应对这些挑战。我们已经发布了数据集和评估代码，以方便结果复现并支持未来的研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [328] [Automated Validation of Textual Constraints Against AutomationML via LLMs and SHACL](https://arxiv.org/abs/2506.10678)
> *通过大型语言模型和SHACL对AutomationML中的文本约束进行自动化验证*

*Tom Westermann, Aljosha Köcher, Felix Gehlhoff* | **Main category: cs.AI**

**Keywords:** AutomationML, 文本约束, 验证, 大型语言模型, SHACL

**Comment:** 

> **TL;DR:** 论文提出了一种通过大型语言模型（LLM）和SHACL自动验证AutomationML中非正式文本约束的方法。

**AI_Comments:** 该论文的创新点在于巧妙地结合了大型语言模型（LLM）的自然语言理解能力与SHACL的形式化验证能力，解决了AutomationML中非正式文本约束的自动化验证难题。其重要性在于显著降低了用户对复杂形式化方法的学习成本，提高了工程数据交换中模型的一致性和可靠性，对提升工业自动化领域的数据质量和标准化具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** AutomationML (AML) 的建模建议通常是非正式的文本约束，无法在AML内部自动验证，这阻碍了AML模型的标准化和质量保证。

**Method:** 该论文引入了一个验证流程：首先，通过RML和SPARQL将AML模型映射到OWL本体；其次，大型语言模型将文本规则翻译成SHACL约束；然后，SHACL约束针对生成的AML本体进行验证；最后，SHACL验证结果被自动解释为自然语言。

**Result:** 该方法在一个示例AML建议上得到了演示，结果表明即使复杂的建模规则也可以半自动检查，且用户无需理解形式化方法或本体技术。

**Conclusion:** 该论文提出的方法成功实现了AutomationML中文本约束的自动化验证，有效降低了用户门槛，有助于提升AML模型的标准化和可靠性。

> **ai_Abstract:** 本文提出了一种自动化验证AutomationML (AML) 中非正式文本约束的流程。该流程首先将AML模型通过RML和SPARQL映射到OWL本体，随后利用大型语言模型将文本规则转换为SHACL约束，并针对生成的本体进行验证。最终，验证结果以自然语言形式呈现。实验证明，该方法能够半自动地检查复杂的建模规则，且用户无需具备形式化方法或本体技术的专业知识。

> **摘要翻译:** AutomationML (AML) 实现了工程领域中数据的标准化交换，然而，现有的关于正确AML建模的建议通常以非正式的文本约束形式制定。这些约束无法在AML内部自动验证。这篇正在进行中的论文介绍了一个用于形式化和验证此类约束的流程。首先，AML模型通过RML和SPARQL映射到OWL本体。此外，大型语言模型将文本规则翻译成SHACL约束，然后针对先前生成的AML本体进行验证。最后，SHACL验证结果会自动以自然语言进行解释。该方法在一个示例AML建议上进行了演示。结果表明，即使复杂的建模规则也可以半自动检查——而无需用户理解形式化方法或本体技术。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [333] [System ASPMT2SMT:Computing ASPMT Theories by SMT Solvers](https://arxiv.org/abs/2506.10708)
> *系统ASPMT2SMT：使用SMT求解器计算ASPMT理论*

*Michael Bartholomew, Joohyung Lee* | **Main category: cs.AI**

**Keywords:** ASPMT, SMT求解器, 编译器, 稳定模型, 实数计算

**Comment:** In Proceedings of the 14th European Conference on Logics in
  Artificial Intelligence (JELIA 2014)

> **TL;DR:** ASPMT2SMT系统将ASPMT程序转换为SMT实例，使SMT求解器能够计算ASPMT稳定模型，特别适用于实数计算。

**AI_Comments:** 这项工作的创新在于提供了一个实用的系统ASPMT2SMT，它成功地连接了理论回答集编程（ASPMT）和可满足性模理论（SMT）。这使得强大的SMT求解器能够应用于ASPMT问题，特别是在处理连续域方面，如其在实数计算能力上的展示，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过将ASPMT程序转换为SMT实例，从而使SMT求解器能够计算ASPMT程序的稳定模型。

**Method:** 本文提出了一个名为ASPMT2SMT的编译器，该编译器实现了将ASPMT程序的紧密片段转换为SMT实例。该系统利用ASP推导器Gringo进行部分推导，并使用SMT求解器Z3处理剩余变量。

**Result:** 该系统能够有效地处理实数计算，用于推理连续变化。

**Conclusion:** ASPMT2SMT系统能够有效地处理实数计算，用于推理关于连续变化的问题。

> **ai_Abstract:** 本文介绍了ASPMT2SMT，一个将理论回答集编程（ASPMT）程序转换为可满足性模理论（SMT）实例的编译器。这种转换使得SMT求解器（如Z3）能够计算ASPMT程序的稳定模型。该系统利用Gringo进行部分推导，并被证明能有效处理实数计算，以推理连续变化。

> **摘要翻译:** 理论回答集编程（ASPMT）是一种结合回答集编程和可满足性模理论的方法，基于函数稳定模型语义。研究表明，ASPMT程序的紧密片段可以转换为SMT实例，从而允许SMT求解器计算ASPMT程序的稳定模型。在本文中，我们提出了一个名为ASPMT2SMT的编译器，它实现了这种转换。该系统使用ASP推导器Gringo和SMT求解器Z3。Gringo部分推导输入程序，同时留下一些变量由Z3处理。我们证明该系统可以有效地处理实数计算，用于推理连续变化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [340] [Think before You Simulate: Symbolic Reasoning to Orchestrate Neural Computation for Counterfactual Question Answering](https://arxiv.org/abs/2506.10753)
> *先思考再模拟：符号推理协调神经计算以进行反事实问答*

*Adam Ishay, Zhun Yang, Joohyung Lee, Ilgu Kang, Dongjae Lim* | **Main category: cs.AI**

**Keywords:** 神经符号模型, 反事实问答, 符号推理, 因果图, 答案集编程

**Comment:** In Proceedings the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV 2024)

> **TL;DR:** 论文提出一种通过符号推理（因果图和ASP）增强神经符号模型的方法，用于反事实问答，在CLEVRER上达到SOTA，并在CRAFT上结合大型语言模型进一步提升性能。

**AI_Comments:** 这篇论文的创新点在于将符号推理（特别是因果图和ASP）深度整合到神经符号模型中，以解决反事实问答这一复杂问题。通过“先思考再模拟”的理念，利用符号逻辑指导神经模块的感知和模拟，显著提升了模型性能。在与大型语言模型结合时，符号推理也能提供有价值的指导，这为未来神经符号AI的发展提供了新的方向。该方法在处理因果推理和反事实情景方面展现出强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 视频动态的因果和时间推理是一个挑战性问题。现有的神经符号模型在结合符号推理与神经感知和预测方面表现出潜力，但在回答反事实问题时存在局限性，尤其是在反事实问答方面。

**Method:** 本文引入一种方法，通过利用事件间的因果关系进行符号推理，来增强神经符号模型处理反事实推理的能力。具体而言，定义了因果图来表示这些关系，并使用答案集编程（ASP）来协调感知和模拟模块。在CRAFT基准测试中，还利用了大型预训练语言模型（如GPT-3.5和GPT-4）作为动态模拟器的代理，并通过符号因果推理指导的替代提示来改进性能。

**Result:** 该增强方法在CLEVRER挑战赛上实现了最先进的性能，显著优于现有模型。在CRAFT基准测试中，结合大型预训练语言模型并提供由符号因果推理指导的替代提示，可以进一步提高反事实问题的性能。

**Conclusion:** 通过符号推理（特别是因果图和ASP）协调神经计算，可以有效增强神经符号模型在处理反事实问答方面的能力，并在不同基准测试中展现出卓越性能，甚至能与大型语言模型结合进一步提升效果。

> **ai_Abstract:** 本文提出了一种增强神经符号模型反事实问答能力的新方法。通过引入因果图来表示事件间的因果关系，并利用答案集编程（ASP）协调感知和模拟模块，该方法在CLEVRER基准测试上达到了最先进的性能。此外，在CRAFT基准测试中，结合大型预训练语言模型（如GPT-3.5/GPT-4）并利用符号因果推理生成提示，进一步提升了反事实问题的回答效果。这表明符号推理在复杂推理任务中能有效指导神经计算。

> **摘要翻译:** 视频动态的因果和时间推理是一个具有挑战性的问题。虽然结合了符号推理与基于神经网络的感知和预测的神经符号模型已显示出前景，但它们存在局限性，尤其是在回答反事实问题方面。本文介绍了一种增强神经符号模型反事实推理能力的方法，该方法利用事件间因果关系的符号推理。我们定义了因果图的概念来表示此类关系，并使用答案集编程（ASP）这一声明式逻辑编程方法来寻找如何协调感知和模拟模块。我们在CLEVRER和CRAFT两个基准测试上验证了我们方法的有效性。我们的增强在CLEVRER挑战赛上取得了最先进的性能，显著优于现有模型。在CRAFT基准测试中，我们利用大型预训练语言模型（例如GPT-3.5和GPT-4）作为动态模拟器的代理。我们的研究结果表明，通过符号因果推理指导的替代提示，该方法可以进一步提高其在反事实问题上的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [346] [OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems](https://arxiv.org/abs/2506.10764)
> *OPT-BENCH：评估大型语言模型智能体在大型搜索空间优化问题上的表现*

*Xiaozhe Li, Jixuan Chen, Xinyu Fang, Shengyuan Ding, Haodong Duan, Qingwen Liu, Kai Chen* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 优化, 迭代推理, 基准测试, 智能体

**Comment:** 

> **TL;DR:** OPT-BENCH是一个新基准，用于评估LLM智能体在大型搜索空间优化问题上的迭代优化能力，并发现结合历史上下文能显著提升性能。

**AI_Comments:** OPT-BENCH的创新之处在于它首次系统地评估了LLM智能体在大型搜索空间优化问题上的迭代优化能力，填补了现有研究的空白。通过引入OPT-Agent框架，该研究模拟了人类在复杂问题解决中的迭代推理过程，为LLM的优化行为提供了新的评估视角。其开源的数据集、代码和工具将极大地促进LLM驱动优化和迭代推理领域的未来研究。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在解决各种任务方面表现出色，但其通过从历史反馈中学习来迭代优化复杂解决方案的能力尚未得到充分探索。

**Method:** 本研究提出了OPT-BENCH，一个综合基准，用于评估LLM智能体在大型搜索空间优化问题上的表现，包含20个Kaggle真实世界机器学习任务和10个经典NP问题。同时引入了OPT-Agent，一个端到端优化框架，通过生成、验证和迭代改进解决方案来模拟人类推理。研究对来自6个模型家族的9个最先进的LLM进行了广泛实验，分析了优化迭代次数、温度设置和模型架构对解决方案质量和收敛性的影响。

**Result:** 实验结果表明，结合历史上下文显著增强了LLM在机器学习任务和NP任务上的优化性能。

**Conclusion:** 结合历史上下文能够显著提升大型语言模型在迭代优化任务中的表现。所有数据集、代码和评估工具均已开源，以促进LLM驱动优化和迭代推理领域的进一步研究。

> **ai_Abstract:** 本研究提出了OPT-BENCH，一个旨在评估大型语言模型（LLM）智能体在大型搜索空间优化问题上迭代优化能力的综合基准。OPT-BENCH包含了来自Kaggle的20个真实世界机器学习任务和10个经典NP问题。为实现严格评估，研究引入了OPT-Agent框架，该框架通过生成、验证和迭代改进解决方案来模拟人类推理。通过对9个最先进LLM的广泛实验，研究发现结合历史上下文能显著提升LLM在优化任务中的表现。所有相关资源均已开源，以促进该领域的进一步研究。

> **摘要翻译:** 大型语言模型（LLMs）在解决各种任务方面表现出卓越的能力。然而，它们通过从历史反馈中学习来迭代优化复杂解决方案的能力仍未得到充分探索。为了弥补这一空白，我们提出了OPT-BENCH，一个综合基准，旨在评估大型语言模型智能体在大型搜索空间优化问题上的表现。OPT-BENCH包含来自Kaggle的20个真实世界机器学习任务和10个经典NP问题，为评估大型语言模型智能体在迭代推理和解决方案优化方面的能力提供了多样化和具有挑战性的环境。为了实现严格评估，我们引入了OPT-Agent，一个端到端的优化框架，它通过利用历史反馈生成、验证和迭代改进解决方案来模拟人类解决复杂问题时的推理过程。通过对来自6个模型家族的9个最先进大型语言模型的广泛实验，我们分析了优化迭代次数、温度设置和模型架构对解决方案质量和收敛性的影响。我们的结果表明，结合历史上下文显著增强了机器学习任务和NP任务的优化性能。所有数据集、代码和评估工具都已开源，以促进大型语言模型驱动优化和迭代推理领域的进一步研究。项目页面：https://github.com/OliverLeeXZ/OPT-BENCH。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [359] [GenPlanX. Generation of Plans and Execution](https://arxiv.org/abs/2506.10897)
> *GenPlanX：计划生成与执行*

*Daniel Borrajo, Giuseppe Canonaco, Tomás de la Rosa, Alfredo Garrachón, Sriram Gopalakrishnan, Simerjot Kaur, Marianela Morales, Sunandita Patra, Alberto Pozanco, Keshav Ramani, Charese Smiley, Pietro Totis, Manuela Veloso* | **Main category: cs.AI**

**Keywords:** AI规划, 大语言模型, 自然语言处理, 任务执行, 人机协作

**Comment:** 

> **TL;DR:** GenPlanX集成大语言模型与经典AI规划技术，实现自然语言描述的规划任务，并辅助执行和监控。

**AI_Comments:** GenPlanX的创新之处在于它弥合了经典AI规划的结构化推理能力与大语言模型强大的自然语言理解能力之间的鸿沟。这对于实现更自然、更直观的人机交互式规划系统具有重要意义，尤其是在需要用户以日常语言表达复杂意图的场景中。其在办公室任务中的应用展示了实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 经典的AI规划技术无法理解自然语言描述的规划任务，而大语言模型（LLMs）在解释人类意图方面表现出色，因此需要一种能整合LLMs以处理自然语言规划任务的系统。

**Method:** 本文介绍了GenPlanX，它将大语言模型（LLMs）用于自然语言描述的规划任务，与经典的AI规划引擎以及一个执行和监控框架相结合。

**Result:** GenPlanX在协助用户处理办公室相关任务方面展示了其效用，突出了其通过无缝人机协作简化工作流程和提高生产力的潜力。

**Conclusion:** GenPlanX通过整合LLMs和经典AI规划，能够简化工作流程并提高生产力，实现更好的人机协作。

> **ai_Abstract:** GenPlanX是一个结合大语言模型和经典AI规划引擎的系统，旨在解决传统AI规划在理解自然语言规划任务方面的不足。该系统还包含一个执行和监控框架，并已在办公室任务中验证了其有效性，展示了通过人机协作提高生产力和优化工作流程的潜力。

> **摘要翻译:** 经典的AI规划技术能够为复杂的任务生成一系列动作。然而，它们缺乏理解自然语言提供的规划任务的能力。大语言模型（LLMs）的出现为人机交互带来了新的能力。在规划任务的背景下，LLMs在解释人类意图方面表现出色。本文介绍了GenPlanX，它将LLMs用于自然语言描述的规划任务，与经典的AI规划引擎以及一个执行和监控框架相结合。我们展示了GenPlanX在协助用户处理办公室相关任务方面的效用，突出了其通过无缝人机协作简化工作流程和提高生产力的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [365] [Breaking Bad Molecules: Are MLLMs Ready for Structure-Level Molecular Detoxification?](https://arxiv.org/abs/2506.10912)
> *打破有害分子：多模态大语言模型（MLLMs）已准备好进行结构级分子解毒了吗？*

*Fei Lin, Ziyang Gong, Cong Wang, Yonglin Tian, Tengchao Zhang, Xue Yang, Gen Luo, Fei-Yue Wang* | **Main category: cs.AI**

**Keywords:** 分子毒性修复, 多模态大语言模型, 基准测试, 药物开发, ToxiMol

**Comment:** 

> **TL;DR:** 本文提出了ToxiMol，首个用于评估多模态大语言模型（MLLMs）在分子毒性修复方面的基准任务，并设计了ToxiEval评估框架。研究发现当前MLLMs在此任务上仍面临挑战，但已展现出初步潜力。

**AI_Comments:** 该论文的创新之处在于首次系统地定义了分子毒性修复任务，并为多模态大语言模型（MLLMs）构建了第一个专用基准ToxiMol。其提出的ToxiEval评估框架整合了多项关键指标，为评估分子修复的成功率提供了全面的视角。这项工作对于推动MLLMs在药物发现领域的应用具有重要意义，尤其是在解决药物毒性问题上。尽管当前MLLMs的表现仍有提升空间，但该研究为未来开发更高效的分子解毒模型奠定了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 毒性是早期药物开发失败的主要原因。尽管分子设计和性质预测取得了进展，但分子毒性修复（生成毒性降低的结构有效分子替代品）的任务尚未被系统定义或基准测试。

**Method:** 研究引入了ToxiMol，这是首个针对通用多模态大语言模型（MLLMs）的分子毒性修复基准任务。构建了一个涵盖11个主要任务和560个有代表性毒性分子的标准化数据集。设计了一个由专家毒理学知识指导的、机制感知和任务自适应的提示标注流程。同时，提出了一个自动化评估框架ToxiEval，该框架整合了毒性终点预测、合成可及性、药物相似性和结构相似性，形成高通量评估链。系统评估了近30个主流通用MLLMs，并设计了多项消融研究来分析关键因素。

**Result:** 实验结果表明，尽管当前的多模态大语言模型（MLLMs）在此任务上仍面临重大挑战，但它们已开始在毒性理解、语义约束遵守和结构感知分子编辑方面展现出有前景的能力。

**Conclusion:** 尽管当前的多模态大语言模型在分子毒性修复任务中面临挑战，但它们已显示出在毒性理解和分子编辑方面的初步潜力，为未来的研究奠定了基础。

> **ai_Abstract:** 本文针对早期药物开发中分子毒性修复的挑战，首次提出了一个专门用于评估多模态大语言模型（MLLMs）在该任务上的基准——ToxiMol。ToxiMol包含一个涵盖多任务和毒性分子的标准化数据集，并结合了专家知识的提示标注流程。为实现自动化评估，研究还开发了ToxiEval框架，该框架综合考虑了毒性预测、合成可及性、药物相似性和结构相似性。通过对近30个主流MLLMs的系统评估，研究发现尽管现有模型仍面临挑战，但已展现出在毒性理解和分子结构编辑方面的初步潜力。

> **摘要翻译:** 毒性仍然是早期药物开发失败的主要原因。尽管分子设计和性质预测取得了进展，但分子毒性修复——生成毒性降低的结构有效分子替代品——的任务尚未被系统定义或基准测试。为了弥补这一空白，我们引入了ToxiMol，这是首个针对通用多模态大语言模型（MLLMs）的分子毒性修复基准任务。我们构建了一个标准化数据集，涵盖11个主要任务和560个具有代表性的毒性分子，涉及多种机制和粒度。我们设计了一个由专家毒理学知识指导的、机制感知和任务自适应的提示标注流程。同时，我们提出了一个自动化评估框架ToxiEval，该框架整合了毒性终点预测、合成可及性、药物相似性和结构相似性，形成高通量评估链，用于评估修复成功率。我们系统评估了近30个主流通用多模态大语言模型，并设计了多项消融研究来分析评估标准、候选多样性和失败归因等关键因素。实验结果表明，尽管当前的多模态大语言模型在此任务上仍面临重大挑战，但它们已开始在毒性理解、语义约束遵守和结构感知分子编辑方面展现出有前景的能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [371] [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/abs/2506.10947)
> *虚假奖励：重新思考RLVR中的训练信号*

*Rulin Shao, Shuyue Stella Li, Rui Xin, Scott Geng, Yiping Wang, Sewoong Oh, Simon Shaolei Du, Nathan Lambert, Sewon Min, Ranjay Krishna, Yulia Tsvetkov, Hannaneh Hajishirzi, Pang Wei Koh, Luke Zettlemoyer* | **Main category: cs.AI**

**Keywords:** RLVR, 虚假奖励, 数学推理, Qwen, 代码推理

**Comment:** 

> **TL;DR:** 研究表明，即使使用虚假奖励，RLVR也能在某些模型（如Qwen）中激发强大的数学推理能力，这可能是通过激活预训练的推理能力实现的，但这种效果并非适用于所有模型。

**AI_Comments:** 该论文挑战了RLVR中奖励信号的传统认知，创新性地证明了即使是高度不可靠的虚假奖励也能在特定模型（如Qwen）中带来显著的性能提升。这暗示RLVR可能不仅通过学习显式信号，更是作为一种机制来解锁模型预先存在的推理能力。然而，其局限性在于结果的模型特异性，虚假奖励仅对Qwen有效，这凸显了在更广泛模型上进行验证的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在重新思考可验证奖励强化学习（RLVR）中的训练信号，探究即使奖励与正确答案相关性很低、没有甚至为负，RLVR是否仍能有效激发模型的数学推理能力。

**Method:** 研究人员使用不同类型的“虚假奖励”（如随机奖励、格式奖励、错误标签、单次RL和多数投票）对Qwen2.5-Math-7B模型进行了可验证奖励强化学习（RLVR），并在MATH-500数据集上评估了其性能。同时，他们也测试了Llama3和OLMo2等其他模型家族，并分析了Qwen模型在RLVR后“代码推理”行为的变化。

**Result:** Qwen2.5-Math-7B在MATH-500上的性能在绝对点数上提升显著：随机奖励提升21.4%，格式奖励提升13.8%，错误标签提升24.1%，单次RL提升26.0%，多数投票提升27.1%，几乎与使用真实奖励获得的29.1%提升相当。然而，对Qwen有效的虚假奖励未能使Llama3或OLMo2等其他模型家族获得收益。研究发现，即使使用虚假奖励，Qwen2.5-Math在RLVR后，“代码推理”的频率从65%显著增加到90%以上。

**Conclusion:** 研究认为，即使奖励信号缺乏有用性，RLVR仍然能够有效地激发某些模型（特别是Qwen）中在预训练期间学到的有用推理表示。未来的RLVR研究应在多样化的模型上进行验证，而非仅限于单一模型，因为在Qwen模型上即使使用完全虚假的奖励信号也很容易获得显著的性能提升。

> **ai_Abstract:** 该论文探讨了可验证奖励强化学习（RLVR）在“虚假奖励”下的有效性，即奖励与正确答案相关性很低或没有。研究表明，RLVR能显著提升Qwen2.5-Math-7B等模型的数学推理能力，其性能提升与真实奖励相当，即使使用随机或不正确的奖励信号。然而，这些虚假奖励对Llama3和OLMo2等其他模型家族无效。研究观察到，RLVR后Qwen模型中的“代码推理”行为显著增加，这表明RLVR可能激活了模型预训练中已有的推理能力。作者建议未来的RLVR研究应在多样化模型上进行验证。

> **摘要翻译:** 我们展示了可验证奖励强化学习（RLVR）即使在奖励与正确答案相关性很低、没有甚至为负的虚假奖励下，也能在某些模型中激发强大的数学推理能力。例如，RLVR使Qwen2.5-Math-7B在MATH-500上的性能绝对点数提升了21.4%（随机奖励）、13.8%（格式奖励）、24.1%（错误标签）、26.0%（单次RL）和27.1%（多数投票），几乎与使用真实奖励获得的29.1%提升相当。然而，对Qwen有效的虚假奖励往往未能使Llama3或OLMo2等其他模型家族获得收益。特别是，我们发现代码推理——在没有实际代码执行的情况下进行代码思考——是Qwen2.5-Math的一个独特行为，在RLVR后，即使使用虚假奖励，其频率也从65%显著增加到90%以上。总的来说，我们推测，鉴于缺乏有用的奖励信号，RLVR必定以某种方式激活了预训练期间学到的有用推理表示，尽管确切机制仍是未来工作的课题。我们建议未来的RLVR研究应可能在多样化的模型上进行验证，而非单一的实际选择，因为我们发现即使使用完全虚假的奖励信号也很容易在Qwen模型上获得显著的性能提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [26] [Leveraging Pre-Trained Models for Multimodal Class-Incremental Learning under Adaptive Fusion](https://arxiv.org/abs/2506.09999)
> *在自适应融合下利用预训练模型进行多模态类别增量学习*

*Yukun Chen, Zihuan Qiu, Fanman Meng, Hongliang Li, Linfeng Xu, Qingbo Wu* | **Main category: cs.LG**

**Keywords:** 多模态类别增量学习, 预训练模型, 自适应融合, 灾难性遗忘, 对比学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于多模态预训练模型的MCIL方法，用于处理视觉、音频和文本模态，通过MIFE、AAVFM、对比损失和新评估指标来解决信息整合和灾难性遗忘问题。

**AI_Comments:** 该论文的创新点在于将MCIL扩展到视觉、音频和文本三种模态，而非传统的双模态。通过引入MIFE、AAVFM和新的对比损失，有效解决了多模态信息融合和灾难性遗忘的核心问题。同时，提出专用的评估指标也提升了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统多模态类别增量学习（MCIL）方法仅关注视觉和文本的问题，并处理视觉、音频和文本模态在整合互补信息和缓解灾难性遗忘方面的挑战。

**Method:** 提出了一种基于多模态预训练模型的MCIL方法。具体包括：1. 引入基于专家混合（MoE）结构的多模态增量特征提取器（MIFE），实现AudioCLIP的有效增量微调。2. 提出自适应音视频融合模块（AAVFM），包含掩蔽阈值机制和动态特征融合机制，并增强文本多样性策略，以增强特征判别性和泛化性。3. 提出新颖的多模态类别增量对比训练损失，优化MCIL中的跨模态对齐。4. 引入两个MCIL专用评估指标进行综合评估。

**Result:** 在三个多模态数据集上的大量实验验证了该方法的有效性。

**Conclusion:** 该方法能有效解决多模态类别增量学习中信息整合和灾难性遗忘的挑战，并在视觉、音频和文本模态上表现出色。

> **ai_Abstract:** 本文提出了一种新颖的多模态类别增量学习（MCIL）方法，旨在解决视觉、音频和文本模态的整合挑战及灾难性遗忘问题。该方法利用多模态预训练模型，通过引入基于MoE的增量特征提取器（MIFE）进行AudioCLIP微调，设计自适应音视频融合模块（AAVFM）以增强特征，并提出新的对比训练损失以优化跨模态对齐。此外，还引入了专门的评估指标。实验结果验证了其在多模态数据集上的有效性。

> **摘要翻译:** 与传统仅关注视觉和文本的多模态类别增量学习（MCIL）方法不同，本文探索了视觉、音频和文本模态之间的MCIL，解决了整合互补信息和缓解灾难性遗忘的挑战。为了解决这些问题，我们提出了一种基于多模态预训练模型的MCIL方法。首先，引入了基于专家混合（MoE）结构的多模态增量特征提取器（MIFE），以实现AudioCLIP的有效增量微调。其次，为了增强特征判别性和泛化性，我们提出了一种自适应音视频融合模块（AAVFM），该模块包含掩蔽阈值机制和动态特征融合机制，以及一种增强文本多样性的策略。第三，提出了一种新颖的多模态类别增量对比训练损失，以优化MCIL中的跨模态对齐。最后，引入了两个MCIL专用评估指标进行综合评估。在三个多模态数据集上的大量实验验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [52] [NOCL: Node-Oriented Conceptualization LLM for Graph Tasks without Message Passing](https://arxiv.org/abs/2506.10014)
> *NOCL：用于图任务的面向节点概念化大型语言模型，无需消息传递*

*Wei Li, Mengcheng Lan, Jiaxing Xu, Yiping Ke* | **Main category: cs.LG**

**Keywords:** 图神经网络, 大型语言模型, 节点概念化, 零样本学习, 图基础模型

**Comment:** 10 pages, 4 figures. arXiv admin note: text overlap with
  arXiv:1703.00552, arXiv:1403.2844 by other authors

> **TL;DR:** NOCL提出了一种无需消息传递的面向节点概念化大型语言模型，通过节点描述和节点概念技术，将异构图数据转化为LLM可处理的格式，并在图任务中展现出优越的泛化能力和竞争力。

**AI_Comments:** NOCL的创新之处在于其将LLM应用于图任务的独特视角，通过“节点描述”和“节点概念”有效地桥接了异构图数据与LLM处理能力的鸿沟。它避免了传统GNN的消息传递机制，同时解决了LLM在处理图数据时面临的令牌长度和非文本属性图的限制。这项工作为构建“图基础模型”提供了一个新颖且有潜力的方向，特别是在零样本泛化能力方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图神经网络（特别是消息传递神经网络MPNNs）过度依赖监督学习，限制了其在标签稀缺场景的泛化和适用性。近期自监督方法仍需标签微调，限制了零样本场景的有效性。大型语言模型（LLMs）在自然语言任务中表现出色，但在应用于图时面临挑战，包括保持推理能力、管理富节点属性的冗长令牌长度、以及受限于文本属性图（TAGs）和单一级别任务。

**Method:** 本文提出了NOCL（Node-Oriented Conceptualization LLM），一个新颖的框架，利用两个核心技术：1) 节点描述：将异构节点属性转换为结构化自然语言，将LLM从文本属性图（TAGs）扩展到非TAGs；2) 节点概念：使用预训练语言模型将节点描述编码为紧凑的语义嵌入，与直接使用节点描述相比，令牌长度显著减少高达93.9%。此外，NOCL采用图表示描述符，将各种级别的图任务统一为共享的、基于语言的查询格式。

**Result:** 实验结果验证了NOCL相对于传统MPNNs和混合LLM-MPNN方法具有竞争性的监督性能，并在零样本设置中表现出卓越的泛化能力。

**Conclusion:** NOCL通过其节点描述和节点概念技术，成功地将大型语言模型应用于图任务，解决了传统GNN和LLM在图领域应用的局限性，特别是在零样本泛化方面表现出色，并为图基础模型开辟了新方向。

> **ai_Abstract:** 本文提出了一种名为NOCL（Node-Oriented Conceptualization LLM）的新型框架，旨在解决传统图神经网络在标签稀缺场景中的泛化限制以及大型语言模型在处理图数据时的挑战。NOCL通过“节点描述”将异构节点属性转化为自然语言，并将LLM的应用范围从文本属性图扩展到非文本属性图。同时，通过“节点概念”技术将节点描述编码为紧凑的语义嵌入，显著减少了令牌长度。该框架还统一了不同级别的图任务为语言查询格式，为图基础模型奠定了基础。实验证明，NOCL在监督学习性能上与现有方法相当，并在零样本设置中展现出卓越的泛化能力。

> **摘要翻译:** 图对于建模社交网络、生物学和推荐系统等领域的复杂交互至关重要。传统的图神经网络，特别是消息传递神经网络（MPNNs），严重依赖监督学习，限制了它们在标签稀缺场景中的泛化和适用性。最近的自监督方法仍然需要带标签的微调，限制了它们在零样本场景中的有效性。同时，大型语言模型（LLMs）在自然语言任务中表现出色，但在应用于图时面临重大挑战，包括保持推理能力、管理来自丰富节点属性的冗长令牌长度，以及受限于文本属性图（TAGs）和单一级别任务。为了克服这些限制，我们提出了面向节点概念化的大型语言模型（NOCL），这是一个新颖的框架，利用两个核心技术：1）节点描述，将异构节点属性转换为结构化自然语言，将LLM从TAGs扩展到非TAGs；2）节点概念，使用预训练语言模型将节点描述编码为紧凑的语义嵌入，与直接使用节点描述相比，令牌长度显著减少高达93.9%。此外，我们的NOCL采用图表示描述符，将各种级别的图任务统一为共享的、基于语言的查询格式，为图基础模型开辟了新方向。实验结果验证了NOCL相对于传统MPNNs和混合LLM-MPNN方法具有竞争性的监督性能，并在零样本设置中表现出卓越的泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [62] [GRAIL: A Benchmark for GRaph ActIve Learning in Dynamic Sensing Environments](https://arxiv.org/abs/2506.10120)
> *GRAIL：动态传感环境中图主动学习的基准*

*Maryam Khalid, Akane Sano* | **Main category: cs.LG**

**Keywords:** 图主动学习, 动态环境, 基准测试, 用户负担, 传感器网络

**Comment:** 

> **TL;DR:** GRAIL是一个新的基准框架，用于在动态真实环境中评估图主动学习策略，并引入新指标来衡量持续有效性、多样性和用户负担。

**AI_Comments:** GRAIL的创新之处在于它首次提出了一个针对动态真实环境的图主动学习评估框架，并引入了用户中心的新指标，这对于推动图主动学习在实际应用中的发展具有重要意义。它揭示了现有方法的局限性，并强调了实际应用中性能与用户负担之间的权衡。

<details>
  <summary>Details</summary>

**Motivation:** 现有图主动学习方法多在静态数据集上评估，且主要关注预测精度，忽视了用户中心考量（如采样多样性、查询公平性、动态适应性）。

**Method:** 引入GRAIL，一个新颖的基准框架，旨在评估动态、真实环境中的图主动学习策略。GRAIL引入了新的指标来评估持续有效性、多样性和用户负担。

**Result:** 对动态、真实人体传感器数据集进行的广泛实验揭示了预测性能和用户负担之间的权衡，突出了现有主动学习策略的局限性。

**Conclusion:** GRAIL证明了平衡节点重要性、查询多样性和网络拓扑的重要性，为动态环境中的图主动学习解决方案提供了一个评估机制。

> **ai_Abstract:** 本文介绍了GRAIL，一个用于评估动态传感环境中图主动学习（AL）策略的新型基准框架。现有图AL方法在静态数据集上评估且仅关注预测精度，忽略了采样多样性、查询公平性和动态适应性等用户中心考量。GRAIL通过引入新的指标来评估持续有效性、多样性和用户负担，弥补了这一空白。实验结果揭示了预测性能和用户负担之间的权衡，强调了平衡节点重要性、查询多样性和网络拓扑对动态环境中图AL解决方案的重要性。

> **摘要翻译:** 基于图的主动学习（AL）利用图的结构有效优先化标签查询，从而在健康监测、人类行为分析和传感器网络等应用中降低标注成本和用户负担。通过识别战略性定位的节点，图AL在保持模型性能的同时最大限度地减少了数据收集需求，使其成为动态环境中的宝贵工具。尽管其潜力巨大，但现有的图AL方法通常在静态图数据集上进行评估，并且主要关注预测精度，忽视了以用户为中心的考虑因素，如采样多样性、查询公平性和对动态设置的适应性。为了弥补这一空白，我们引入了GRAIL，一个新颖的基准测试框架，旨在评估动态、真实世界环境中的图AL策略。GRAIL引入了新颖的指标来评估持续有效性、多样性和用户负担，从而能够在不同条件下对AL方法进行全面评估。对包含动态、真实人体传感器数据的数据集进行的广泛实验揭示了预测性能和用户负担之间的权衡，突出了现有AL策略的局限性。GRAIL展示了平衡节点重要性、查询多样性和网络拓扑的重要性，为动态环境中的图AL解决方案提供了一个评估机制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [77] [Improving the performance of optical inverse design of multilayer thin films using CNN-LSTM tandem neural networks](https://arxiv.org/abs/2506.10044)
> *使用CNN-LSTM串联神经网络改进多层薄膜光学逆向设计性能*

*Uijun Jung, Deokho Jang, Sungchul Kim, Jungho Kim* | **Main category: cs.LG**

**Keywords:** 光学逆向设计, 多层薄膜, 串联神经网络, CNN-LSTM, 深度学习

**Comment:** 22 pages, 8 figures, 2 tables, 11 supplementary figures, 7
  supplementary tables

> **TL;DR:** 本文提出并评估了基于CNN-LSTM的串联神经网络（TNN），用于多层薄膜的光学逆向设计，解决了传统方法的耗时问题和深度学习的一对多映射问题，并发现CNN-LSTM组合在精度和速度上表现最佳。

**AI_Comments:** 该论文的创新点在于将CNN和LSTM这两种强大的深度学习架构引入串联神经网络（TNN）中，以解决光学逆向设计中的复杂一对多映射问题。通过集成不同网络类型的优势，它有效地提升了设计效率和准确性，为薄膜设计领域提供了一种更优的自动化方法。

<details>
  <summary>Details</summary>

**Motivation:** 传统的光学逆向设计方法需要大量的数值模拟和优化过程，非常耗时。此外，基于深度学习的逆向设计存在一对多映射问题，这会极大地降低其性能。

**Method:** 本文采用串联神经网络（TNN）进行SiO2/TiO2多层薄膜的透射光谱逆向设计。TNN由逆向神经网络和预训练的前向神经网络组成。与以往基于多层感知机（MLP）的实现不同，本文提出在TNN配置中使用卷积神经网络（CNN）或长短期记忆网络（LSTM）算法，并测试了多种配置（包括MLP、CNN、LSTM的组合）。

**Result:** 在九种TNN配置中，基于LSTM-LSTM的TNN实现了最高的精度，但训练时间最长。研究发现，基于CNN-LSTM的TNN在精度和速度方面是最佳解决方案，因为它结合了CNN和LSTM算法的优势。

**Conclusion:** CNN-LSTM串联神经网络是多层薄膜光学逆向设计的有效且高效的解决方案，能够解决传统方法的局限性并优化深度学习模型的性能。

> **ai_Abstract:** 本文提出了一种基于深度学习的串联神经网络（TNN），用于解决多层薄膜光学逆向设计中传统方法耗时和深度学习一对多映射的问题。研究探索了在TNN配置中结合多层感知机（MLP）、卷积神经网络（CNN）和长短期记忆网络（LSTM）算法。结果表明，虽然LSTM-LSTM配置的TNN精度最高，但训练时间最长；而CNN-LSTM配置的TNN在精度和速度之间取得了最佳平衡，是光学逆向设计的理想选择。

> **摘要翻译:** 薄膜的光学特性受各层厚度影响很大。准确预测这些厚度及其相应的光学特性在薄膜的光学逆向设计中至关重要。然而，传统的逆向设计方法通常需要大量的数值模拟和优化过程，这非常耗时。在本文中，我们利用深度学习对SiO2/TiO2多层薄膜的透射光谱进行逆向设计。我们实现了一种串联神经网络（TNN），它可以解决极大地降低基于深度学习的逆向设计性能的一对多映射问题。通常，TNN是通过逆向神经网络和预训练的前向神经网络的反向连接实现的，两者都是基于多层感知机（MLP）算法实现的。在本文中，我们提出不仅在TNN的配置中使用MLP，还在其配置中使用卷积神经网络（CNN）或长短期记忆网络（LSTM）算法。我们表明，在九种TNN配置中，基于LSTM-LSTM的TNN产生了最高的精度，但训练时间最长。我们还发现，基于CNN-LSTM的TNN将是精度和速度方面的最佳解决方案，因为它能够整合CNN和LSTM算法的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [103] [Omni-DPO: A Dual-Perspective Paradigm for Dynamic Preference Learning of LLMs](https://arxiv.org/abs/2506.10054)
> *Omni-DPO：一种用于LLM动态偏好学习的双视角范式*

*Shangpin Peng, Weinong Wang, Zhuotao Tian, Senqiao Yang, Xing Wu, Haotian Xu, Chengquan Zhang, Takashi Isobe, Baotian Hu, Min Zhang* | **Main category: cs.LG**

**Keywords:** 直接偏好优化, LLM, 强化学习, 偏好学习, 双视角优化

**Comment:** 

> **TL;DR:** Omni-DPO是一种新的DPO框架，通过同时考虑偏好对质量和模型学习动态来提高LLM的偏好学习效率和性能，并在文本理解和数学推理任务上显著优于现有方法。

**AI_Comments:** Omni-DPO的创新点在于引入了“双视角”优化范式，通过动态调整样本权重来解决DPO中数据质量和模型学习动态被忽略的问题。这对于提升RLHF的效率和效果具有重要意义，尤其是在LLM微调领域，其在多个任务上超越SOTA模型的表现证明了其强大的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有DPO方法统一处理所有偏好对，忽略其内在质量和学习效用差异，导致数据利用不足和性能不佳。

**Method:** 提出Omni-DPO，一个双视角优化框架，联合考虑 (1) 每个偏好对的内在质量和 (2) 模型在这些对上的演变性能。通过根据数据质量和模型学习动态自适应加权样本，实现更有效的数据利用。

**Result:** 在各种模型和基准测试上证明了Omni-DPO的优越性和泛化能力。在文本理解任务上，使用Omni-DPO微调的Gemma-2-9b-it在Arena-Hard基准测试上比Claude 3 Opus高出6.7分。在数学推理任务上，Omni-DPO始终优于所有基准测试的基线方法。

**Conclusion:** Omni-DPO通过其双视角优化范式，显著提高了LLM的偏好学习效率和性能，并在多个任务上展现出强大的有效性和鲁棒性。

> **ai_Abstract:** 本文提出了Omni-DPO，一个用于大型语言模型（LLMs）偏好学习的双视角优化框架。针对现有DPO方法忽视偏好对质量和模型学习动态的问题，Omni-DPO通过自适应加权样本，同时考虑数据质量和模型性能演变，显著提升了数据利用效率和模型性能。实验证明，Omni-DPO在文本理解和数学推理任务上均超越了现有领先方法，展现出优越性和泛化能力。

> **摘要翻译:** 直接偏好优化（DPO）因其简洁和高效已成为人类反馈强化学习（RLHF）的基石。然而，现有的基于DPO的方法通常统一处理所有偏好对，忽略了它们内在质量和学习效用的关键差异，导致数据利用不足和性能欠佳。为了解决这一挑战，我们提出了Omni-DPO，一个双视角优化框架，它联合考虑了 (1) 每个偏好对的内在质量和 (2) 模型在这些对上的演进性能。通过在训练过程中根据数据质量和模型的学习动态自适应地加权样本，Omni-DPO能够更有效地利用训练数据并实现更好的性能。在各种模型和基准测试上的实验结果证明了Omni-DPO的优越性和泛化能力。在文本理解任务中，使用Omni-DPO微调的Gemma-2-9b-it在Arena-Hard基准测试上以6.7分的显著优势击败了领先的LLM Claude 3 Opus。在数学推理任务中，Omni-DPO在所有基准测试中始终优于基线方法，为我们方法的有效性和鲁棒性提供了强有力的经验证据。代码和模型将发布在https://github.com/pspdada/Omni-DPO。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [116] [LaMAGIC2: Advanced Circuit Formulations for Language Model-Based Analog Topology Generation](https://arxiv.org/abs/2506.10235)
> *LaMAGIC2：基于语言模型的模拟拓扑生成的高级电路公式*

*Chen-Chia Chang, Wan-Hsuan Lin, Yikang Shen, Yiran Chen, Xin Zhang* | **Main category: cs.LG**

**Keywords:** 模拟拓扑生成, 语言模型, 电路公式, SFCI, 自动化设计

**Comment:** Accepted at 42nd International Conference on Machine Learning (ICML)
  2025

> **TL;DR:** LaMAGIC2通过引入SFCI公式，显著提高了基于语言模型的模拟拓扑生成效率和精度，解决了现有方法的令牌长度和精度问题。

**AI_Comments:** LaMAGIC2的创新在于其提出的SFCI公式，它有效地解决了现有基于语言模型的模拟拓扑生成方法在效率和精度上的瓶颈。通过将令牌长度复杂度从O(|V|^2)降低到O(|V|)并增强数值精度敏感度，该工作显著提升了自动化模拟设计的可行性和性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代应用对模拟拓扑设计有定制化需求，但现有设计需要大量手动工作。现有的基于语言模型的模拟拓扑生成方法存在电路公式效率低下（O(|V|^2)令牌长度）和对数值输入精度敏感度低的问题。

**Method:** 本文引入了LaMAGIC2，它采用一种简洁的浮点输入规范公式与标识符（SFCI），用于基于语言模型的模拟拓扑生成。SFCI通过基于标识符的表示来改进组件类型识别，将令牌长度复杂度降低到O(|V|)，并增强了数值精度敏感性，以在严格容差下获得更好的性能。

**Result:** LaMAGIC2在0.01的严格容差下，成功率比现有方法高34%，MSE降低10倍。对于更多顶点的电路，LaMAGIC2还表现出更好的可转移性，最高提高了58.5%。

**Conclusion:** LaMAGIC2是一个强大的模拟拓扑生成框架，通过改进的电路公式解决了现有挑战。

> **ai_Abstract:** 本文介绍了LaMAGIC2，一种用于基于语言模型的模拟拓扑生成的新型电路公式。它通过引入简洁的浮点输入规范公式与标识符（SFCI），解决了现有方法中低效的O(|V|^2)令牌长度和低精度敏感度问题。LaMAGIC2通过改进组件识别、降低令牌复杂度至O(|V|)并提高数值精度敏感性，显著提升了性能。实验表明，LaMAGIC2在成功率、MSE和可转移性方面均优于现有方法，使其成为一个鲁棒的模拟拓扑生成框架。

> **摘要翻译:** 由于现代应用对定制化要求高，模拟拓扑设计的自动化至关重要，但现有方法需要大量手动工程工作。最先进的方法应用序列到序列方法和对语言模型进行监督微调，根据用户规范生成拓扑。然而，其电路公式效率低下，因为令牌长度为O(|V|^2)，并且对数值输入的精度敏感度低。在这项工作中，我们引入了LaMAGIC2，这是一种简洁的浮点输入规范公式与标识符（SFCI），用于基于语言模型的模拟拓扑生成。SFCI通过基于标识符的表示改进组件类型识别，将令牌长度复杂度降低到O(|V|)，并增强了数值精度敏感性，从而在严格容差下获得更好的性能，解决了这些挑战。我们的实验表明，与现有方法相比，LaMAGIC2在0.01的严格容差下实现了34%更高的成功率和10倍更低的MSE。LaMAGIC2还表现出对具有更多顶点的电路更好的可转移性，最高提高了58.5%。这些进步使LaMAGIC2成为一个强大的模拟拓扑生成框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [126] [Textual Bayes: Quantifying Uncertainty in LLM-Based Systems](https://arxiv.org/abs/2506.10060)
> *文本贝叶斯：量化基于LLM的系统中的不确定性*

*Brendan Leigh Ross, Noël Vouitsis, Atiyeh Ashari Ghomi, Rasa Hosseinzadeh, Ji Xin, Zhaoyan Liu, Yi Sui, Shiyi Hou, Kin Kwan Leung, Gabriel Loaiza-Ganem, Jesse C. Cresswell* | **Main category: cs.LG**

**Keywords:** LLM不确定性, 贝叶斯推断, 提示工程, MCMC, 文本贝叶斯

**Comment:** 

> **TL;DR:** 该论文提出了一种名为“文本贝叶斯”的新方法，通过将提示视为统计模型中的文本参数，利用贝叶斯推断来量化大型语言模型（LLMs）的不确定性，并引入了MHLP算法，以提高LLM系统的预测准确性和不确定性量化能力。

**AI_Comments:** 该论文的创新之处在于将贝叶斯推断应用于大型语言模型（LLMs）的文本提示，将提示视为可推断的统计参数，从而实现了对黑盒LLM系统的不确定性量化。引入的MHLP算法是其核心创新，它巧妙地结合了提示优化和MCMC方法，使其能够适用于现有LLM管道，包括闭源模型。这项工作的重要性在于为LLM在高风险领域中的应用提供了更可靠的决策依据，并通过将贝叶斯方法的严谨性引入LLM领域，为未来LLM研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在解决现实世界任务方面能力日益增强，但准确量化其不确定性仍然是一个关键的开放问题，这限制了它们在高风险领域的应用。此外，许多最先进的LLM是闭源的黑盒模型，并且基于LLM的系统对提示高度敏感，需要大量手动调优。

**Method:** 本研究通过贝叶斯视角审视基于LLM的系统，将提示解释为统计模型中的文本参数，从而可以使用小型训练数据集对这些提示执行贝叶斯推断。为实现贝叶斯推断，论文引入了Metropolis-Hastings through LLM Proposals (MHLP)，这是一种新颖的马尔可夫链蒙特卡洛（MCMC）算法，它结合了提示优化技术和标准MCMC方法。MHLP是对现有LLM管道的即插即用修改，包括那些依赖闭源模型的管道。

**Result:** 实证表明，该方法在LLM基准和不确定性量化任务上，在预测准确性和不确定性量化（UQ）方面均有所改进。

**Conclusion:** 这项工作为将丰富的贝叶斯文献中的方法引入LLM时代提供了一条可行的途径，为更可靠和校准的基于LLM的系统铺平了道路。

> **ai_Abstract:** 该论文提出了一种名为“文本贝叶斯”的新框架，旨在解决大型语言模型（LLMs）的不确定性量化问题，尤其是在面对闭源和提示敏感性挑战时。通过将LLM提示视为统计模型中的文本参数，并利用小型训练数据集进行贝叶斯推断，该方法实现了对模型参数和预测的原则性不确定性量化。为此，论文引入了Metropolis-Hastings through LLM Proposals (MHLP)算法，这是一种结合提示优化和MCMC的创新方法，可无缝集成到现有LLM管道中。实验结果表明，该方法显著提高了LLM的预测准确性和不确定性量化能力，为构建更可靠、更校准的LLM系统奠定了基础。

> **摘要翻译:** 尽管大型语言模型（LLMs）在解决具有挑战性的现实世界任务方面能力日益增强，但准确量化它们的不确定性仍然是一个关键的开放问题，这限制了它们在高风险领域的适用性。这一挑战因许多最先进的LLM的闭源、黑盒性质而进一步加剧。此外，基于LLM的系统可能对将它们连接在一起的提示高度敏感，这通常需要大量手动调优（即提示工程）。在这项工作中，我们通过贝叶斯视角审视基于LLM的系统来解决这些挑战。我们将提示解释为统计模型中的文本参数，这使我们能够使用少量训练数据集对这些提示执行贝叶斯推断。这种新颖的视角使得对模型的文本参数及其下游预测进行原则性的不确定性量化成为可能，同时还纳入了以自由形式文本表达的关于这些参数的先验信念。为了执行贝叶斯推断，即使对于研究充分的数据模态来说也是一个难题，我们引入了Metropolis-Hastings through LLM Proposals (MHLP)，这是一种新颖的马尔可夫链蒙特卡洛（MCMC）算法，它结合了提示优化技术和标准MCMC方法。MHLP是对现有LLM管道的即插即用修改，包括那些完全依赖闭源模型的管道。从经验上看，我们证明了我们的方法在一系列LLM基准和不确定性量化（UQ）任务上均能提高预测准确性和不确定性量化。更广泛地说，我们的工作展示了将丰富的贝叶斯文献中的方法纳入LLM时代的可行途径，为更可靠和校准的基于LLM的系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [147] [Optimizing Latent Dimension Allocation in Hierarchical VAEs: Balancing Attenuation and Information Retention for OOD Detection](https://arxiv.org/abs/2506.10089)
> *优化分层变分自编码器中的潜在维度分配：平衡衰减与信息保留以实现OOD检测*

*Dane Williamson, Yangfeng Ji, Matthew Dwyer* | **Main category: cs.LG**

**Keywords:** 域外检测, 分层变分自编码器, 潜在维度分配, 信息论, 鲁棒性

**Comment:** 41 pages, 6 figures

> **TL;DR:** 本文提出了一个理论框架，用于优化分层变分自编码器（HVAEs）中的潜在维度分配，以提高OOD检测性能。

**AI_Comments:** 这篇论文通过引入一个理论上扎根的框架来优化HVAE中的潜在维度分配，解决了HVAE在OOD检测中性能敏感于维度分布的关键问题。其创新点在于利用信息论原理形式化信息损失和表示衰减之间的权衡，并证明了最优分配比率的存在。这为深度生成模型中潜在结构的设计提供了原则性的指导，有望提升OOD检测的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 域外检测（OOD）是机器学习中的一项关键任务，尤其对于安全关键应用而言。分层变分自编码器（HVAEs）的性能高度依赖于潜在维度在层间的分布方式，而现有方法常导致表示无效或后验塌陷。

**Method:** 引入了一个理论上扎根的框架，利用信息论原理形式化信息损失和表示衰减之间的权衡，以优化HVAEs中的潜在维度分配。证明了在固定潜在预算下存在一个最优分配比率$r^{\ast}$。

**Result:** 经验表明，调整该比率持续改善了跨数据集和架构的OOD检测性能。该方法优于基线HVAE配置。

**Conclusion:** 该方法为原则性的潜在结构设计提供了实用指导，从而使用深度生成模型实现更鲁棒的OOD检测。

> **ai_Abstract:** 本文提出了一个优化分层变分自编码器（HVAEs）中潜在维度分配的理论框架，旨在解决现有方法中维度分配随意导致的表示无效或后验塌陷问题。该框架基于信息论，权衡信息损失与表示衰减，并证明了存在一个最优的潜在维度分配比率。实验结果表明，通过调整此比率，可以显著提高跨不同数据集和架构的域外检测（OOD）性能，并优于传统HVAE配置，为深度生成模型中更鲁棒的OOD检测提供了指导。

> **摘要翻译:** 域外检测（OOD）是机器学习中的一项关键任务，尤其对于必须可靠地标记意外输入的安全关键应用而言。尽管分层变分自编码器（HVAEs）比传统VAE提供了更高的表示能力，但它们的性能高度依赖于潜在维度在层间的分布方式。现有方法通常任意分配潜在容量，导致无效的表示或后验塌陷。在这项工作中，我们引入了一个理论上扎根的框架，用于优化HVAEs中的潜在维度分配，借鉴信息论原理来形式化信息损失和表示衰减之间的权衡。我们证明了在固定潜在预算下存在一个最优分配比率$r^{\ast}$，并经验性地表明，调整此比率持续改善了跨数据集和架构的OOD检测性能。我们的方法优于基线HVAE配置，并为原则性的潜在结构设计提供了实用指导，从而使用深度生成模型实现更鲁棒的OOD检测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [166] [Efficient kernelized bandit algorithms via exploration distributions](https://arxiv.org/abs/2506.10091)
> *通过探索分布实现高效核化赌博机算法*

*Bingshan Hu, Zheng He, Danica J. Sutherland* | **Main category: cs.LG**

**Keywords:** 核化赌博机, 探索分布, 遗憾界, GP-Generic, 随机化

**Comment:** 

> **TL;DR:** 本文提出了一类基于探索分布的高效核化赌博机算法GP-Generic，该算法在理论上实现了与现有算法相当的遗憾界，并在实践中表现出更好的随机化效果。

**AI_Comments:** 这篇论文的创新点在于引入了“探索分布”这一新概念，为核化赌博机算法提供了一个统一的框架，能够整合UCB等现有方法并引入随机化。其重要性在于不仅在理论上达到了最先进的遗憾界，还通过实践结果强调了随机化在实际应用中的潜在优势，这对于实际系统设计具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在紧凑的臂集上，寻找具有有限范数的未知奖励函数的最优策略，并开发计算高效的核化赌博机算法。

**Method:** 提出了一类名为GP-Generic的计算高效核化赌博机算法，其核心是“探索分布”的概念。该算法包含上置信界（UCB）方法作为特例，并允许使用多种随机化算法。通过仔细选择探索分布，实现了多种具体的算法。

**Result:** 所提出的通用算法能够实现 $\tilde{O}(\gamma_T\sqrt{T})$ 的遗憾界，其中 $\gamma_T$ 表征了RKHS的复杂性。这与基于UCB和Thompson采样算法的已知结果相匹配。此外，研究表明在实践中，随机化可以产生更好的实际结果。

**Conclusion:** 通过引入探索分布，GP-Generic算法提供了一种统一且高效的核化赌博机问题解决方案，其理论性能与现有最佳算法相当，并在实践中展示了随机化的优势。

> **ai_Abstract:** 本文针对核化赌博机问题，提出了一类新颖且计算高效的算法GP-Generic。该算法引入了“探索分布”的概念，并涵盖了UCB等现有方法。通过优化探索分布的选择，GP-Generic算法在理论上实现了与UCB和Thompson采样算法相同的 $\tilde{O}(\gamma_T\sqrt{T})$ 遗憾界。研究还指出，在实际应用中，随机化方法可能带来更好的性能。

> **摘要翻译:** 我们考虑一个核化赌博机问题，它具有紧凑的臂集 ${X} \subset \mathbb{R}^d $ 和一个固定但未知的奖励函数 $f^*$，该函数在某个再生核希尔伯特空间（RKHS）中具有有限范数。我们提出了一类计算高效的核化赌博机算法，我们称之为GP-Generic，它基于一个新颖的概念：探索分布。这类算法包括基于上置信界（Upper Confidence Bound）的方法作为特例，但也允许使用多种随机化算法。通过仔细选择探索分布，我们提出的通用算法实现了一系列具体的算法，这些算法达到了 $\tilde{O}(\gamma_T\sqrt{T})$ 的遗憾界，其中 $\gamma_T$ 表征了RKHS的复杂性。这与基于UCB和Thompson采样算法的已知结果相匹配；我们还表明，在实践中，随机化可以产生更好的实际结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [183] [Unsupervised Deep Clustering of MNIST with Triplet-Enhanced Convolutional Autoencoders](https://arxiv.org/abs/2506.10094)
> *基于三重增强卷积自编码器的MNIST手写数字无监督深度聚类*

*Md. Faizul Islam Ansari* | **Main category: cs.LG**

**Keywords:** 无监督聚类, 深度自编码器, MNIST, KMeans, 表示学习

**Comment:** 6 pages, 6 figures, experimental study on deep clustering with
  autoencoders

> **TL;DR:** 本研究提出一种两阶段深度自编码器架构，结合KMeans聚类损失，实现MNIST手写数字的无监督深度聚类，在多种指标上表现优异，并能应用于大规模图像聚类。

**AI_Comments:** 这篇论文的创新点在于其两阶段的深度自编码器聚类架构，特别是将重建误差与KMeans聚类损失结合的联合优化目标。通过引入批量归一化、Dropout和权重衰减，有效提升了模型的泛化能力和稳定性。其在MNIST数据集上的优异表现以及对可扩展性的强调，表明了该方法在实际大规模无监督图像聚类应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为MNIST手写数字实现先进的无监督聚类系统，并开发通过自编码器学习可解释表示的无监督方法，以应用于大规模图像聚类。

**Method:** 本研究提出一种两阶段深度自编码器架构。第一阶段通过最小化重建误差来训练深度神经网络自编码器，以学习图像的紧凑且可解释的表示。第二阶段，通过一个基于联合距离的目标，将重建误差与学习到的潜在嵌入的KMeans聚类损失相结合。模型还整合了批量归一化、Dropout和权重衰减以提高泛化性和稳定性。

**Result:** 该框架在广泛测试中实现了卓越的聚类性能，使用了包括Silhouette Score、Davies-Bouldin Index、NMI和ARI在内的内在和外在指标。t-SNE可视化展示了学习到的嵌入形成了清晰的数字簇。该方法在数据重建精度和簇分离纯度之间达到了最佳组合。

**Conclusion:** 该方法提供了一个可靠的基础，有助于将无监督表示学习部署到不同的大规模图像聚类应用中，并具备可理解的结果和可扩展的实现。

> **ai_Abstract:** 本文提出一种用于MNIST手写数字的无监督深度聚类系统，采用两阶段深度自编码器架构。第一阶段通过最小化重建误差学习图像表示，第二阶段结合重建误差和KMeans聚类损失优化潜在嵌入。模型集成批量归一化、Dropout和权重衰减以增强性能。实验结果表明，该方法在多种聚类指标上表现优异，并能生成清晰可分离的数字簇，实现了数据重建精度与聚类纯度的最佳平衡，为大规模图像聚类提供了可扩展的解决方案。

> **摘要翻译:** 本研究通过两阶段深度自编码器架构，为MNIST手写数字实现了一个先进的无监督聚类系统。一个深度神经网络自编码器在第一阶段需要训练过程，通过最小化重建误差来开发图像的最小化但可解释的表示。在第二阶段，我们通过一个基于联合距离的目标，将重建误差与学习到的潜在嵌入的KMeans聚类损失相结合。我们的模型包含三个元素，包括批量归一化、Dropout和权重衰减，以实现泛化和稳定的结果。该框架在广泛测试中取得了卓越的聚类性能，这些测试在使用内在测量（包括Silhouette Score和Davies-Bouldin Index）以及外在度量（NMI和ARI）处理图像特征时进行。研究使用t-SNE可视化来呈现学习的嵌入，这些嵌入显示了数字的独特簇。我们的方法在数据重建精度和簇分离纯度之间达到了最佳组合，同时增加了可理解的结果和可扩展实现的优势。该方法创建了一个可靠的基础，有助于在不同的大规模图像聚类应用中部署无监督表示学习。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [196] [Learning to Collaborate Over Graphs: A Selective Federated Multi-Task Learning Approach](https://arxiv.org/abs/2506.10102)
> *基于图协作学习：一种选择性联邦多任务学习方法*

*Ahmed Elbakary, Chaouki Ben Issaid, Mehdi Bennis* | **Main category: cs.LG**

**Keywords:** 联邦学习, 多任务学习, 图神经网络, 社区检测, 个性化学习

**Comment:** 

> **TL;DR:** 本文提出一种高效的选择性联邦多任务学习方法，通过引入特征锚、共享分类头和基于图的社区检测，实现了个性化学习和有益的客户端协作。实验证明，该方法在性能、计算和通信效率以及客户端公平性方面均显著优于现有基线。

**AI_Comments:** 该论文的创新点在于提出了结合特征锚、共享分类头和动态图社区检测的联邦多任务学习框架，有效解决了联邦学习中客户端异构性带来的个性化与协作难题。通过限制协作范围，它成功避免了负面知识转移，同时提升了通信和计算效率，对联邦学习的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种新颖的联邦多任务学习方法，利用客户端间的相似性实现个性化学习，同时通过通信高效的方案避免传输整个模型，并防止负面协作，确保有益的知识转移。

**Method:** 该方法提出了一种通信高效的方案，引入“特征锚”（总结本地特征的紧凑向量表示）与服务器共享，并使客户端共享“分类头”（轻量级线性层）。通过将客户端协作建模为动态图并持续更新，利用基于社区检测的方法将动态图划分为同质社区，限制协作在高度相似的客户端之间，以最大化社区内的任务相似性。

**Result:** 在两个异构数据集上的广泛实验表明，该方法显著优于最先进的基线。此外，该方法表现出卓越的计算和通信效率，并促进了客户端之间的公平性。

**Conclusion:** 本文提出的选择性联邦多任务学习方法能够有效地利用客户端相似性实现个性化学习和有益的协作，显著提升了性能、计算和通信效率，并促进了客户端间的公平性。

> **ai_Abstract:** 本文提出了一种新颖的选择性联邦多任务学习方法，旨在通过利用客户端相似性实现个性化学习。该方法通过引入特征锚和共享分类头来提高通信效率，并采用基于动态图的正则化来建模客户端协作。为防止负面协作，引入社区检测机制，将客户端划分为同质社区，确保知识在高度相似的客户端之间有效传递。实验证明，该方法在性能、计算和通信效率以及客户端公平性方面均优于现有基线。

> **摘要翻译:** 我们提出了一种新颖的联邦多任务学习方法，该方法利用客户端之间的相似性来实现每个客户端的个性化学习。为了避免将整个模型传输到参数服务器，我们提出了一种通信高效的方案，引入了特征锚，这是一种紧凑的向量表示，总结了从客户端本地类中学到的特征。该特征锚与服务器共享，以考虑本地客户端的分布。此外，客户端共享分类头（一个轻量级的线性层），并执行基于图的正则化以实现客户端之间的协作。通过将客户端之间的协作建模为动态图并持续更新和完善该图，我们可以解释客户端的任何漂移。为了确保有益的知识转移并防止负面协作，我们利用基于社区检测的方法，将此动态图划分为同质社区，最大化每个社区内任务相似性之和（表示为图边的权重）。这种机制将协作限制在形成社区内高度相似的客户端之间，确保积极的互动并保持个性化。在两个异构数据集上的广泛实验表明，我们的方法显著优于最先进的基线。此外，我们表明我们的方法表现出卓越的计算和通信效率，并促进了客户端之间的公平性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [210] [The 2025 PNPL Competition: Speech Detection and Phoneme Classification in the LibriBrain Dataset](https://arxiv.org/abs/2506.10165)
> *2025年PNPL竞赛：LibriBrain数据集中的语音检测和音素分类*

*Gilad Landau, Miran Özdogan, Gereon Elvers, Francesco Mantegna, Pratik Somaiya, Dulhan Jayalath, Luisa Kurth, Teyun Kwon, Brendan Shillingford, Greg Farquhar, Minqi Jiang, Karim Jerbi, Hamza Abdelhedi, Yorguin Mantilla Ramos, Caglar Gulcehre, Mark Woolrich, Natalie Voets, Oiwi Parker Jones* | **Main category: cs.LG**

**Keywords:** PNPL竞赛, 语音解码, 脑机接口, LibriBrain, 音素分类

**Comment:** 

> **TL;DR:** 2025年PNPL竞赛旨在通过提供LibriBrain数据集和pnpl库，促进非侵入性脑数据语音解码的突破，主要任务是语音检测和音素分类。

**AI_Comments:** 这项PNPL竞赛具有巨大的社会意义，因为它旨在通过非侵入性手段解决瘫痪患者的交流障碍。提供大规模的LibriBrain数据集和易用的pnpl库是其创新之处，能够有效降低参与门槛并促进社区协作。竞赛通过设置明确的任务和评估标准，有望加速该领域的进展，并可能产生类似“ImageNet时刻”的突破。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过非侵入性脑数据实现语音解码的突破，以帮助患有言语障碍的瘫痪个体恢复交流，避免高风险手术。2025年PNPL竞赛的最终目标是激发机器学习社区的力量，实现非侵入性神经解码的“ImageNet时刻”。

**Method:** 竞赛提供了迄今为止最大的受试者内MEG数据集（LibriBrain）和一个用户友好的Python库（pnpl），以便于数据访问和与深度学习框架集成。竞赛定义了两个基础任务：语音检测和音素分类，并提供了标准化的数据分割、评估指标、基准模型、在线教程代码、社区讨论板和公共排行榜。竞赛设有强调算法创新的标准赛道和奖励大规模计算的扩展赛道。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 2025年PNPL竞赛旨在推动非侵入性脑数据语音解码领域的突破，特别是为了帮助瘫痪患者恢复交流。竞赛提供了迄今最大的受试者内MEG数据集LibriBrain和一个Python库pnpl，便于研究人员进行数据处理和深度学习集成。竞赛设定了语音检测和音素分类两大任务，并提供全面的支持资源，包括数据分割、评估指标和基准模型。通过设置标准和扩展赛道，竞赛鼓励算法创新和大规模计算，以加速非侵入性语音脑机接口的发展。

> **摘要翻译:** 从非侵入性脑数据中解码语音的进展，具有产生深远社会影响的潜力。其最有前景的应用之一是为受言语障碍（如构音障碍）影响的瘫痪个体恢复交流，而无需高风险的手术干预。2025年PNPL竞赛的最终目标是通过利用机器学习社区的集体力量，为非侵入性神经解码创造一个“ImageNet时刻”或突破性进展的条件。
为了促进这一愿景，我们提供了迄今为止记录到的最大的受试者内MEG数据集（LibriBrain），以及一个用户友好的Python库（pnpl），以便于数据访问和与深度学习框架集成。针对竞赛，我们定义了两个基础任务（即从脑数据中进行语音检测和音素分类），并提供了标准化的数据分割和评估指标、说明性的基准模型、在线教程代码、社区讨论板以及用于提交的公共排行榜。为了提高可访问性和参与度，竞赛设有一个强调算法创新的标准赛道，以及一个有望奖励大规模计算的扩展赛道，以加速非侵入性脑机接口在语音方面的进展。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [213] [NnD: Diffusion-based Generation of Physically-Nonnegative Objects](https://arxiv.org/abs/2506.10112)
> *NnD：基于扩散的物理非负对象生成*

*Nadav Torem, Tamar Sde-Chen, Yoav Y. Schechner* | **Main category: cs.LG**

**Keywords:** 非负扩散, 生成模型, 物理模拟, 3D云, 机器学习

**Comment:** 

> **TL;DR:** NnD是一种基于扩散的生成模型，能够高效生成物理上非负的对象，如3D云，且生成结果符合物理规律。

**AI_Comments:** NnD的创新之处在于其通过设计强制执行非负性的扩散模型，这对于生成物理上准确的对象至关重要。它提供了一种显著降低计算成本的方法，同时保持了生成对象的物理一致性，对于需要模拟复杂物理现象的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多真实世界的现象，如云形成，需要计算成本高昂的模拟，限制了可扩展性。本研究关注于一类计算上可行但模拟成本高昂的、物理上有意义的非负对象，旨在显著降低计算成本。

**Method:** 本文提出了非负扩散（NnD），这是一种使用基于分数的扩散的生成模型。它通过调整退火朗之万动力学，在迭代场景生成和分析（推理）过程中强制执行非负性。NnD在高质量的物理模拟对象上进行训练。

**Result:** NnD能够生成3D体积云，其中包含固有的非负微物理场。生成的云与云物理趋势一致，并且专家感知上无法将其区分为非物理的。

**Conclusion:** NnD模型能够有效生成符合物理规律的非负对象，显著降低了传统模拟的计算成本，并生成了高质量、逼真的物理现象。

> **ai_Abstract:** 本研究提出了一种名为NnD（非负扩散）的生成模型，旨在解决复杂物理非负对象（如云形成）模拟计算成本高昂的问题。NnD是一种基于分数扩散的学习型生成模型，通过调整退火朗之万动力学，在生成和推理过程中强制保持非负性。该模型在高质量物理模拟数据上训练，并成功应用于3D体积云的生成。实验结果表明，NnD生成的云与云物理趋势一致，且专家难以区分其非物理性，证明了其在高效生成物理上准确的非负对象方面的有效性。

> **摘要翻译:** 大多数自然对象具有固有的复杂性和可变性。虽然一些简单的对象可以从第一性原理建模，但许多现实世界现象，如云形成，需要计算成本高昂的模拟，这限制了可扩展性。这项工作专注于一类物理上有意义的、非负的对象，它们在计算上是可行的但模拟成本高昂。为了显著降低计算成本，我们提出了非负扩散（NnD）。这是一种使用基于分数的扩散的学习型生成模型。它通过调整退火朗之万动力学，在迭代场景生成和分析（推理）过程中，通过设计强制执行非负性。NnD在高质量的物理模拟对象上进行训练。一旦训练完成，它就可以用于生成和推理。我们展示了3D体积云的生成，其中包括固有的非负微物理场。我们生成的云与云物理趋势一致。专家感知上无法有效地将其区分为非物理的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning](https://arxiv.org/abs/2506.10629)
> *技能的任务适应：信息几何、解耦和无监督强化学习的新目标*

*Yucheng Yang, Tianyi Zhou, Qiang He, Lei Han, Mykola Pechenizkiy, Meng Fang* | **Main category: cs.LG**

**Keywords:** 无监督强化学习, 任务适应, 信息几何, 解耦, Wasserstein距离

**Comment:** Spotlight paper at ICLR 2024. This version includes acknowledgments
  omitted from the ICLR version and indicates the corresponding authors
  primarily responsible for the work

> **TL;DR:** 本文针对无监督强化学习中现有技能学习方法（如MISL）在下游任务适应性上的不足，提出了新的理论分析、解耦度量LSEPIN以及基于Wasserstein距离的新目标WSEP和PWSEP，旨在学习更具多样性和可分离性的技能以提高下游任务的初始化策略发现能力。

**AI_Comments:** 本文的创新点在于从信息几何角度深入分析了无监督强化学习中技能多样性和可分离性的重要性，并引入了Wasserstein距离来改进技能学习目标，解决了现有方法在下游任务适应性上的不足。理论分析严谨，提出了两种新算法WSEP和PWSEP，特别是PWSEP理论上能发现所有最优初始策略，具有重要的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 无监督强化学习（URL）旨在为未见过的下游任务学习通用技能。现有方法如互信息技能学习（MISL）通过最大化状态和技能之间的互信息来解决URL问题，但缺乏足够的理论分析，例如其学习到的技能如何有效地初始化下游任务的策略。本文的理论分析表明，学习技能的多样性和可分离性对于下游任务适应至关重要，而MISL不一定能保证这些特性。

**Method:** 本文进行了新的理论分析，表明学习技能的多样性和可分离性对下游任务适应至关重要。提出了一个新的解耦度量LSEPIN，并建立了其与下游任务适应成本之间的信息几何联系。为获得更好的几何特性，研究了一种新策略，用Wasserstein距离替换信息几何中的KL散度。基于此，提出了一个新的技能学习目标WSEP，并对其进行了理论证明。最终提出了另一个基于Wasserstein距离的算法PWSEP。

**Result:** WSEP在理论上被证明有助于下游任务适应，并且能够比MISL发现更多的下游任务初始策略。PWSEP在理论上能够发现所有最优的初始策略。

**Conclusion:** 本文通过理论分析揭示了技能多样性和可分离性对下游任务适应的关键作用，并提出了基于信息几何和Wasserstein距离的新度量和目标（LSEPIN, WSEP, PWSEP），显著提高了无监督强化学习中技能学习对下游任务的适应能力和初始策略发现能力。

> **ai_Abstract:** 本文关注无监督强化学习（URL）中技能学习对下游任务的适应性问题。通过理论分析，指出现有方法如MISL在学习技能的多样性和可分离性方面存在不足，而这些特性对下游任务适应至关重要。为此，论文提出了新的解耦度量LSEPIN，并建立了其与下游任务适应成本的信息几何联系。进一步，引入了基于Wasserstein距离的技能学习新目标WSEP和PWSEP，理论上证明了它们能有效提升下游任务的适应能力，并发现更优或所有最优的初始策略。

> **摘要翻译:** 无监督强化学习（URL）旨在为未见过的下游任务学习通用技能。互信息技能学习（MISL）通过最大化状态和技能之间的互信息来解决URL问题，但缺乏足够的理论分析，例如其学习到的技能如何有效地初始化下游任务的策略。本文新的理论分析表明，学习技能的多样性和可分离性对于下游任务适应至关重要，但MISL不一定能保证这些特性。为了补充MISL，我们提出了一种新颖的解耦度量LSEPIN。此外，我们建立了LSEPIN与下游任务适应成本之间的信息几何联系。为了获得更好的几何特性，我们研究了一种新策略，用Wasserstein距离替换信息几何中的KL散度。我们将其几何分析扩展到此，从而产生了一个新颖的技能学习目标WSEP。它在理论上被证明有助于下游任务适应，并且能够比MISL发现更多的下游任务初始策略。我们最终提出了另一个基于Wasserstein距离的算法PWSEP，它在理论上可以发现所有最优的初始策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [241] [Meet Me at the Arm: The Cooperative Multi-Armed Bandits Problem with Shareable Arms](https://arxiv.org/abs/2506.10127)
> *在臂处相遇：可共享臂的协作多臂老虎机问题*

*Xinyi Hu, Aldo Pacchiano* | **Main category: cs.LG**

**Keywords:** 多臂老虎机, 去中心化学习, 容量感知, 协作算法, 对数遗憾

**Comment:** 

> **TL;DR:** 本文研究了去中心化、无感知、多玩家多臂老虎机问题，其中臂具有未知容量且超载会导致零奖励。作者提出了A-CAPELLA算法，实现了对数遗憾，并通过协作假设检验协议实现了容量估计和同步消除。

**AI_Comments:** 该论文的创新点在于将经典的多臂老虎机问题推广到具有未知容量的可共享臂场景，并解决了在无感知、去中心化设置下的协调和容量发现难题。A-CAPELLA算法通过其独特的协作假设检验协议，有效地实现了容量估计和同步消除，并在理论上证明了其学习效率，对多智能体强化学习和资源分配领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究去中心化多玩家多臂老虎机（MMAB）问题，特别是在无感知设置下，每个玩家只能收到自己的奖励且无法得知冲突。该设置推广了经典的单位容量模型，并引入了在反馈严重受限下进行协调和容量发现的新挑战。

**Method:** 提出了A-CAPELLA（容量感知并行消除学习和分配算法）去中心化算法。其主要贡献是一个协作假设检验协议，通过精心构造的冲突模式实现同步的逐次消除和容量估计。

**Result:** A-CAPELLA算法在该广义机制下实现了对数遗憾。

**Conclusion:** 本文在去中心化、无感知、未知臂容量的MMAB问题中，通过A-CAPELLA算法提供了一个可证明高效的学习结果。

> **ai_Abstract:** 本文研究了去中心化、无感知、具有未知容量可共享臂的多玩家多臂老虎机（MMAB）问题。当拉动同一臂的玩家数量超过其容量时，所有相关玩家的奖励为零。为了解决在反馈受限下的协调和容量发现挑战，论文提出了A-CAPELLA算法。该算法通过一个协作假设检验协议，利用结构化的冲突模式实现同步的臂消除和容量估计，最终达到了对数遗憾，证明了其在该泛化MMAB设置下的学习效率。

> **摘要翻译:** 我们研究了无感知设置下的去中心化多玩家多臂老虎机（MMAB）问题，其中每个玩家只接收自己的奖励，并且不获取关于冲突的信息。每个臂具有未知容量，如果拉动一个臂的玩家数量超过其容量，所有相关玩家将获得零奖励。这种设置推广了经典的单位容量模型，并引入了在反馈严重受限下进行协调和容量发现的新挑战。我们提出了A-CAPELLA（容量感知并行消除学习和分配算法），一个在该广义机制下实现对数遗憾的去中心化算法。我们的主要贡献是一个协作假设检验协议，通过精心构造的冲突模式实现同步的逐次消除和容量估计。这代表了在去中心化、无感知、未知臂容量的MMAB中一个可证明高效的学习结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [251] [Cross-Learning Between ECG and PCG: Exploring Common and Exclusive Characteristics of Bimodal Electromechanical Cardiac Waveforms](https://arxiv.org/abs/2506.10212)
> *心电图和心音图的交叉学习：探索双模态心电机械波形的共同和独有特征*

*Sajjad Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni* | **Main category: cs.LG**

**Keywords:** 心电图, 心音图, 交叉学习, 生物标志物, 机器学习

**Comment:** 

> **TL;DR:** 本研究系统地探讨了心电图（ECG）和心音图（PCG）在静息和运动状态下的共同与独有特征，并使用非线性机器学习模型实现了模态间的相互重建和生物标志物估计。

**AI_Comments:** 本研究通过深入探索ECG和PCG之间的交叉学习，为理解心脏电机械活动的复杂关系提供了重要见解。其创新之处在于利用先进的非线性机器学习模型（特别是非因果LSTM）进行模态间重建，并成功解决了跨受试者泛化和生物标志物估计的挑战。能够从PCG估计ECG生物标志物，为无创、便捷的心脏监测提供了新的可能性，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 同时记录的心电图（ECG）和心音图（PCG）能全面反映心脏功能，但这些信号中独特和重叠的信息内容、相互重建和生物标志物提取的潜力，特别是在不同生理条件和个体之间，仍未被完全理解。

**Method:** 本研究利用EPHNOGRAM数据集中的同步ECG-PCG记录，系统地调查了ECG和PCG的共同和独有特征。研究采用了包括非因果LSTM网络在内的线性与非线性机器学习模型，实现模态间的相互重建，并分析了因果关系、生理状态和跨受试者变异性的影响。此外，还采用了基于包络的模型，利用瞬时振幅特征来提高跨模态学习的跨受试者泛化能力。

**Result:** 非线性模型，特别是非因果LSTM，提供了卓越的重建性能，其中从PCG重建ECG比反向重建更可行。运动和跨受试者场景带来了显著挑战，但利用瞬时振幅特征的基于包络的模型显著提高了跨模态学习的跨受试者泛化能力。此外，临床相关的ECG生物标志物（如特征点和QT间期）可以在跨受试者设置中从PCG中估计出来。

**Conclusion:** 这些发现增进了我们对心电机械模态之间关系的理解，包括波形特征和心脏事件的时间，并有望应用于新型多模态心脏监测技术。

> **ai_Abstract:** 本研究利用EPHNOGRAM数据集，系统地探索了心电图（ECG）和心音图（PCG）在静息和运动状态下的共同与独有特征。通过使用包括非因果LSTM在内的线性与非线性机器学习模型，论文成功实现了ECG和PCG之间的相互重建，并分析了生理状态和跨受试者变异性的影响。结果表明，非线性模型在重建性能上表现优越，尤其是在从PCG重建ECG方面。此外，研究还发现基于包络的模型能有效提升跨受试者泛化能力，并成功从PCG中估计出临床相关的ECG生物标志物。这些发现加深了对心电机械模态关系的理解，并为多模态心脏监测技术提供了新思路。

> **摘要翻译:** 同时心电图（ECG）和心音图（PCG）通过分别捕获心脏的电活动和机械活动，提供了对心脏功能的全面、多模态视角。然而，这些信号独特和重叠的信息内容，以及它们相互重建和生物标志物提取的潜力，在不同生理条件和个体之间仍然未被完全理解。
在本研究中，我们系统地调查了ECG和PCG在静息和运动期间同步ECG-PCG记录的EPHNOGRAM数据集中的共同和独有特征。我们采用了一套线性和非线性机器学习模型，包括非因果LSTM网络，以从彼此重建每种模态，并分析因果关系、生理状态和跨受试者变异性的影响。我们的结果表明，非线性模型，特别是非因果LSTM，提供了卓越的重建性能，其中从PCG重建ECG比反向重建更易处理。运动和跨受试者场景带来了显著挑战，但利用瞬时振幅特征的基于包络的模型显著提高了跨模态学习的跨受试者泛化能力。此外，我们证明了临床相关的ECG生物标志物，如特征点和QT间期，可以在跨受试者设置中从PCG中估计出来。
这些发现增进了我们对心电机械模态之间关系的理解，包括波形特征和心脏事件的时间，并有望应用于新型多模态心脏监测技术。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [253] [Provable Sim-to-Real Transfer via Offline Domain Randomization](https://arxiv.org/abs/2506.10133)
> *可证明的离线域随机化实现仿真到现实迁移*

*Arnaud Fickinger, Abderrahim Bendahi, Stuart Russell* | **Main category: cs.LG**

**Keywords:** 离线域随机化, 仿真到现实迁移, 强化学习, 理论分析, E-DROPO

**Comment:** 

> **TL;DR:** 本文通过离线域随机化（ODR）解决了强化学习中仿真到现实的迁移问题，首次提供了其理论基础，证明了其优于传统域随机化，并提出了改进算法E-DROPO。

**AI_Comments:** 这篇论文的创新点在于首次为离线域随机化（ODR）提供了坚实的理论证明，弥补了此前该领域经验成果缺乏理论支撑的空白。其证明了ODR估计器的一致性以及其在减小仿真到现实差距方面的显著优势，这对于理解和改进仿真到现实迁移方法具有重要意义。引入的E-DROPO算法也显示了在实践中提升鲁棒性的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习智能体从仿真到现实部署时常遇到困难，即存在“仿真到现实差距”。标准域随机化（DR）是解决此问题的主流策略，但它忽略了已有的离线真实系统数据。尽管离线域随机化（ODR）在经验上取得了显著成果，但其理论基础尚未得到充分探索。

**Method:** 本文研究了离线域随机化（ODR），该方法首先将模拟器参数的分布拟合到离线数据集。具体方法包括：(i) 将ODR形式化为参数化模拟器族上的最大似然估计。(ii) 在温和的正则性和可识别性条件下，证明了该估计器的一致性，表明其随数据集增长而收敛到真实动态。(iii) 推导了差距边界，证明在有限模拟器情况下，ODR的仿真到现实误差比均匀DR紧密高达O(M)倍（在连续设置中也有类似增益）。(iv) 引入了E-DROPO，一个DROPO的新版本，增加了熵奖励以防止方差崩溃，从而在实践中实现更广泛的随机化和更鲁棒的零样本迁移。

**Result:** (i) ODR估计器在温和条件下具有一致性，并随数据集增长收敛到真实动态。(ii) ODR的仿真到现实误差比均匀DR在有限模拟器情况下紧密高达O(M)倍，在连续设置中也有类似增益。(iii) 引入的E-DROPO算法通过增加熵奖励，实现了更广泛的随机化和更鲁棒的零样本迁移。

**Conclusion:** 本文首次为离线域随机化（ODR）提供了坚实的理论基础，证明了其在缩小仿真到现实差距方面的优越性，并通过引入改进的E-DROPO算法，提升了实际应用中的迁移鲁棒性。

> **ai_Abstract:** 本文针对强化学习中仿真到现实迁移的挑战，提出了离线域随机化（ODR）方法，该方法利用离线真实数据拟合模拟器参数分布。与现有经验工作不同，本文首次为ODR提供了严格的理论基础，包括将其形式化为最大似然估计并证明其一致性。研究还推导了ODR相比传统均匀域随机化在缩小仿真到现实差距上的显著优势（误差紧密性提高O(M)倍）。此外，本文引入了改进的E-DROPO算法，通过熵奖励增强了随机化广度，从而实现了更鲁棒的零样本迁移。

> **摘要翻译:** 强化学习智能体从仿真部署到现实世界时经常遇到困难。减少仿真到现实差距的主导策略是域随机化（DR），它通过采样动力学参数来训练策略，从而生成许多模拟器，但标准DR忽略了已有的真实系统离线数据。我们研究了离线域随机化（ODR），它首先将模拟器参数的分布拟合到离线数据集。尽管越来越多的实证工作报告称DROPO等算法取得了显著收益，但ODR的理论基础在很大程度上仍未被探索。在这项工作中，我们（i）将ODR形式化为参数化模拟器族上的最大似然估计，（ii）在温和的正则性和可识别性条件下证明了该估计器的一致性，表明它随数据集的增长而收敛到真实动态，（iii）推导了差距边界，证明ODR的仿真到现实误差在有限模拟器情况下比均匀DR紧密高达O(M)倍（在连续设置中也有类似增益），并且（iv）引入了E-DROPO，一个DROPO的新版本，增加了熵奖励以防止方差崩溃，从而在实践中实现更广泛的随机化和更鲁棒的零样本迁移。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [261] [Size-adaptive Hypothesis Testing for Fairness](https://arxiv.org/abs/2506.10586)
> *公平性的大小自适应假设检验*

*Antonio Ferrara, Francesco Cozzi, Alan Perotti, André Panisson, Francesco Bonchi* | **Main category: cs.LG**

**Keywords:** 公平性评估, 假设检验, 统计平等等级, 贝叶斯方法, 交叉性

**Comment:** 

> **TL;DR:** 提出了一种大小自适应的假设检验框架，用于公平性评估，解决了现有方法在小群体数据稀疏时的统计脆性问题。

**AI_Comments:** 这篇论文通过引入一个大小自适应的假设检验框架，解决了算法公平性评估中的一个关键挑战：如何准确评估数据稀疏的小型群体（尤其是交叉群体）的公平性。其创新之处在于结合了传统统计方法（中心极限定理和Wald检验）与贝叶斯方法（Dirichlet-multinomial估计器），为不同数据量的群体提供了量身定制的统计推断工具。这对于提高公平性评估的统计严谨性和决策的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的算法决策系统公平性评估方法（如比较单一指标点估计与阈值）存在统计脆性，忽略抽样误差，且对大小群体一视同仁。在交叉分析中，当多个敏感属性被联合考虑时，小群体数据稀疏导致估计不可靠，置信区间过宽，难以对潜在的不公平待遇得出有意义的结论。

**Method:** 论文引入了一个统一的、大小自适应的假设检验框架。对于足够大的子群体，证明了统计平等的差异的中心极限定理，并提出了Wald检验，保证第一类错误率。对于小型交叉群体，推导了一个完全贝叶斯Dirichlet-multinomial估计器，使用蒙特卡洛可信区间，该区间可针对任何样本量进行校准。

**Result:** 该方法在基准数据集上得到了经验性验证，证明其在不同数据可用性和交叉性下能提供可解释的、统计学上严谨的决策。

**Conclusion:** 该框架将公平性评估转化为基于证据的统计决策，有效解决了现有方法在数据稀疏和交叉分析中的局限性，提供了更可靠的公平性判断。

> **ai_Abstract:** 本文针对算法公平性评估中，现有方法在数据稀疏，尤其是在交叉分析中对小型群体判断的统计脆性问题，提出了一种统一的、大小自适应的假设检验框架。该框架结合了针对大型群体的中心极限定理和Wald检验，以及针对小型交叉群体的贝叶斯Dirichlet-multinomial估计器和蒙特卡洛可信区间。实验证明，该方法能在不同数据量和交叉性下提供更可靠和可解释的公平性决策。

> **摘要翻译:** 确定算法决策系统是否歧视特定人群通常涉及将公平性指标的单一估计值与预设阈值进行比较。这种做法在统计上是脆弱的：它忽略了抽样误差，并将小型人口子群体与大型子群体同等对待。在交叉分析中，当多个敏感属性被联合考虑时，问题会加剧，导致出现更多更小的群体。随着这些群体变得更加细化，代表它们的数据变得过于稀疏，无法进行可靠估计，公平性指标会产生过宽的置信区间，从而无法对潜在的不公平待遇得出有意义的结论。
在本文中，我们引入了一个统一的、大小自适应的假设检验框架，将公平性评估转化为基于证据的统计决策。我们的贡献是双重的。(i) 对于足够大的子群体，我们证明了统计平等的差异的中心极限定理，从而得到了分析置信区间和一个Wald检验，其第一类（假阳性）错误率保证在$\alpha$水平。(ii) 对于小型交叉群体的长尾部分，我们推导了一个完全贝叶斯Dirichlet-multinomial估计器；蒙特卡洛可信区间针对任何样本量进行校准，并随着更多数据的可用而自然地收敛到Wald区间。我们在基准数据集上通过实证验证了我们的方法，展示了我们的检验如何在不同程度的数据可用性和交叉性下提供可解释的、统计学上严谨的决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [Leveraging Low-rank Factorizations of Conditional Correlation Matrices in Graph Learning](https://arxiv.org/abs/2506.10628)
> *图学习中利用条件相关矩阵的低秩分解*

*Thu Ha Phi, Alexandre Hippert-Ferrer, Florent Bouchard, Arnaud Breloy* | **Main category: cs.LG**

**Keywords:** 图学习, 低秩分解, 条件相关矩阵, 黎曼优化, GLasso

**Comment:** 11 pages, 5 figures

> **TL;DR:** 本文提出了一种利用条件相关矩阵低秩分解的图学习框架，通过黎曼优化解决大规模图学习问题，并在实验中取得了高效的维度-性能权衡。

**AI_Comments:** 本文的创新点在于将低秩分解与黎曼优化技术相结合，有效解决了大规模图学习中条件相关矩阵维度过高的问题。这种方法为图学习在处理高维数据时提供了一个有前景的方向，特别是在图信号处理和高斯图模型领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图学习问题在处理大规模数据时，其复杂度与变量（节点）数量的平方成正比，导致在大维度下出现问题。

**Method:** 提出了一种利用条件相关矩阵低秩分解的图学习框架。为了解决由此产生的优化问题，推导了应用黎曼优化技术所需的工具。该方法具体化为GLasso算法的低秩约束对应物，即高斯图模型的惩罚最大似然估计。

**Result:** 在合成数据和真实数据上的实验表明，该方法可以实现非常高效的维度-性能权衡。

**Conclusion:** 通过利用条件相关矩阵的低秩分解和黎曼优化，可以有效解决大规模图学习问题，并在维度和性能之间取得良好平衡。

> **ai_Abstract:** 本文针对从节点数据中学习无向图的问题，提出了一种创新的图学习框架。该框架通过利用条件相关矩阵的低秩分解来解决传统方法在大维度下复杂度过高的问题。为求解优化问题，文章引入了黎曼优化技术。具体应用上，该方法是GLasso算法的低秩约束变体。实验证明，该方法在处理大规模数据时，能在维度和性能之间取得高效的平衡。

> **摘要翻译:** 本文解决了从每个节点收集的数据中学习无向图的问题。在图信号处理框架内，这种图的拓扑结构可以与数据的条件相关矩阵的支持相关联。相应的图学习问题随后会随着变量（节点）数量的平方而扩展，这在维度较大时通常会成为问题。为了解决这个问题，我们提出了一种利用条件相关矩阵低秩分解的图学习框架。为了解决由此产生的优化问题，我们推导了将黎曼优化技术应用于这种特定结构所需的工具。该提议随后被具体化为GLasso算法的低秩约束对应物，即高斯图模型的惩罚最大似然估计。在合成数据和真实数据上的实验证明，这种方法可以实现非常高效的维度与性能权衡。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [266] [Self-Predictive Representations for Combinatorial Generalization in Behavioral Cloning](https://arxiv.org/abs/2506.10137)
> *行为克隆中组合泛化的自预测表示*

*Daniel Lawson, Adriana Hugessen, Charlotte Cloutier, Glen Berseth, Khimya Khetarpal* | **Main category: cs.LG**

**Keywords:** 行为克隆, 组合泛化, 后继表示, 表示学习, 目标条件

**Comment:** 

> **TL;DR:** 现有的目标条件行为克隆（GCBC）在面对新的状态-目标对时，组合泛化能力不足，部分原因在于状态表示缺乏时间一致性。本文提出了一种名为BYOL-γ增强GCBC的简单有效表示学习方法，它无需对比样本或时序差分（TD）学习即可近似后继表示，并在需要组合泛化的任务中取得了有竞争力的经验性能。

**AI_Comments:** 该论文的创新点在于提出了一种不依赖于对比学习或时序差分（TD）学习就能学习到近似后继表示的方法（BYOL-γ增强GCBC），这简化了表示学习过程，同时有效提升了行为克隆在面对新颖组合任务时的泛化能力。其理论证明和经验性能均显示了该方法的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 目标条件行为克隆（GCBC）方法在分布内训练任务上表现良好，但在需要对新颖状态-目标对进行条件设置的任务（即组合泛化）时，不一定能实现零样本泛化。这种限制部分归因于行为克隆学习到的状态表示缺乏时间一致性。如果时间相关的状态被编码为相似的潜在表示，则可以减少新颖状态-目标对的分布外差距。因此，鼓励表示空间中的时间一致性应有助于组合泛化。

**Method:** 本文提出了一种简单而有效的表示学习目标，即BYOL-γ增强GCBC。该方法无需对比样本或时序差分（TD）学习，便能在有限MDP情况下理论上近似后继表示。

**Result:** 该方法在需要组合泛化的一系列具有挑战性的任务中，取得了有竞争力的经验性能。

**Conclusion:** 本文提出的BYOL-γ增强GCBC方法，通过学习自预测表示，有效解决了目标条件行为克隆在组合泛化方面的挑战，且无需依赖对比样本或时序差分学习。

> **ai_Abstract:** 本文针对目标条件行为克隆（GCBC）在面对新颖状态-目标对时组合泛化能力不足的问题，提出了一种名为BYOL-γ增强GCBC的表示学习方法。该方法旨在通过鼓励状态表示的时间一致性来提升泛化能力，其核心在于无需对比样本或时序差分（TD）学习即可近似后继表示。实验结果表明，BYOL-γ增强GCBC在需要组合泛化的多项任务中展现出有竞争力的性能。

> **摘要翻译:** 行为克隆（BC）方法通过监督学习（SL）训练，是学习机器人等领域人类演示策略的有效方式。对这些策略进行目标条件设置，使得单一通用策略能够捕获离线数据集中包含的各种行为。虽然目标条件行为克隆（GCBC）方法在分布内训练任务上表现良好，但它们不一定能零样本泛化到需要对新颖状态-目标对进行条件设置的任务，即组合泛化。部分原因在于BC学习到的状态表示缺乏时间一致性；如果时间相关的状态被编码为相似的潜在表示，那么新颖状态-目标对的分布外差距将会减小。因此，鼓励表示空间中的这种时间一致性应有助于组合泛化。后继表示，编码从当前状态访问的未来状态分布，很好地概括了这一特性。然而，之前学习后继表示的方法依赖于对比样本、时序差分（TD）学习或两者兼有。在这项工作中，我们提出了一种简单而有效的表示学习目标，即BYOL-γ增强GCBC，它不仅能够在有限MDP情况下理论上近似后继表示而无需对比样本或TD学习，而且在一系列需要组合泛化的具有挑战性任务中，也取得了有竞争力的经验性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [279] [Interpreting learned search: finding a transition model and value function in an RNN that plays Sokoban](https://arxiv.org/abs/2506.10138)
> *解释学习到的搜索：在玩推箱子游戏的RNN中找到一个转移模型和值函数*

*Mohammad Taufeeque, Aaron David Tucker, Adam Gleave, Adrià Garriga-Alonso* | **Main category: cs.LG**

**Keywords:** RNN, 推箱子, 强化学习, 搜索解释, 值函数

**Comment:** 33 pages, 22 figures

> **TL;DR:** 本文逆向工程了一个玩推箱子游戏的RNN，发现它利用了类似双向搜索、值函数和转移模型的机制，表明其学习到的行为是可解释的，尽管是无模型训练。

**AI_Comments:** 本文的创新之处在于揭示了无模型训练的RNN的内部工作机制，表明复杂的学习行为可以用经典的AI概念（如搜索、值函数和转移模型）来解释。这对于提高深度强化学习模型的信任度和理解至关重要。一个局限性是逆向工程只是“部分”的。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究发现该网络在测试时计算量增加的情况下能解决更多关卡，但其内部机制尚不清楚。本文的动机是理解这些机制，并解释其学习到的搜索行为。

**Method:** 部分逆向工程一个通过无模型强化学习训练来玩推箱子游戏的卷积循环神经网络（RNN）。分析其内部机制，特别是它如何表示计划、值函数和转移模型。

**Result:** 该RNN利用了类似于经典双向搜索的机制；它在与特定方向相关的通道激活中表示其计划；这些状态-动作激活类似于值函数，决定何时回溯和哪个计划分支得以保留；专用核将这些激活（包含计划和值）向前和向后扩展以创建路径，形成一个转移模型。与经典搜索不同的是，状态表示不是统一的，而是分别考虑每个箱子；每个层都有自己的计划表示和值函数，增加了搜索深度。最终，通过无模型训练在该网络中学习到的利用测试时计算的机制可以用熟悉的术语来理解。

**Conclusion:** 通过无模型训练学习到的、利用测试时计算来玩推箱子的RNN的机制是可解释的，并且类似于经典搜索组件，例如值函数和转移模型，这表明此类复杂行为并非不可理解。

> **ai_Abstract:** 本文对一个通过无模型强化学习训练来玩推箱子游戏的卷积循环神经网络（RNN）进行了部分逆向工程。分析揭示，该网络采用了类似于经典双向搜索的机制，包括作为值函数的状态-动作激活以及形成转移模型的专用核。尽管它在某些方面与经典搜索不同，例如非统一的状态表示和分层的计划表示，但研究表明，网络学习到的复杂行为是可解释的，并且可以用熟悉的术语来理解。

> **摘要翻译:** 我们部分逆向工程了一个通过无模型强化学习训练来玩推箱子益智游戏的卷积循环神经网络（RNN）。之前的工作发现，这个网络在测试时计算量增加的情况下能解决更多关卡。我们的分析揭示了几个类似于经典双向搜索组件的机制。对于每个方格，RNN在与特定方向相关的通道激活中表示其计划。这些状态-动作激活类似于一个值函数——它们的幅度决定了何时回溯以及哪个计划分支在剪枝中幸存。专用核将这些激活（包含计划和值）向前和向后扩展以创建路径，形成一个转移模型。该算法在某些方面也与经典搜索不同。状态表示不是统一的；相反，网络分别考虑每个箱子。每个层都有自己的计划表示和值函数，增加了搜索深度。通过无模型训练在该网络中学习到的利用测试时计算的机制，远非不可理解，而是可以用熟悉的术语来理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [290] [Survival Analysis as Imprecise Classification with Trainable Kernels](https://arxiv.org/abs/2506.10140)
> *生存分析作为可训练核的模糊分类*

*Andrei V. Konstantinov, Vlada A. Efremenko, Lev V. Utkin* | **Main category: cs.LG**

**Keywords:** 生存分析, 模糊概率, 注意力机制, 删失数据, 核回归

**Comment:** 

> **TL;DR:** 本文提出了三种新的生存模型（iSurvM, iSurvQ, iSurvJ），它们结合了模糊概率理论和注意力机制来处理删失数据，并在准确性和计算复杂度上优于传统方法。

**AI_Comments:** 本文的创新点在于将模糊概率理论与注意力机制引入生存分析，以无参数方式处理删失数据，这为传统生存分析方法面临的挑战提供了新的视角。通过将删失观测建模为区间值概率分布并结合可训练的核回归，该方法能够更灵活地适应复杂数据结构。其重要性体现在实验结果表明提出的模型，尤其是iSurvJ，在准确性和计算效率上均优于现有方法，具有实际应用价值。公开代码也促进了研究的复现和进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 生存分析在处理删失观测时面临挑战，传统方法如Beran估计器在处理复杂数据结构和严重删失时表现不佳。

**Method:** 本文引入了iSurvM、iSurvQ和iSurvJ三种新型生存模型，它们将模糊概率理论与注意力机制相结合，以无参数假设的方式处理删失数据。核心思想包括：将删失观测表示为时间间隔上的区间值概率分布；采用带有可训练注意力权重的基于核的Nadaraya-Watson回归来计算整个数据集在时间间隔上的模糊概率分布；以及为训练考虑三种决策策略。

**Result:** 在合成数据集和真实数据集上的实验表明，所提出的模型，特别是iSurvJ，在准确性和计算复杂性方面始终优于Beran估计器。

**Conclusion:** 所提出的iSurvM、iSurvQ和iSurvJ模型，特别是iSurvJ，能够有效且高效地处理生存分析中的删失数据，并取得了比传统方法更好的性能。

> **ai_Abstract:** 本文提出iSurvM、iSurvQ和iSurvJ三种新型生存分析模型，它们融合了模糊概率理论与注意力机制，旨在克服传统方法在处理复杂和重删失时间-事件数据时的局限性。这些模型通过将删失观测表示为区间值概率分布，并利用带可训练权重的核回归来计算模糊概率分布。实验证明，特别是iSurvJ模型，在准确性和计算效率上均优于传统的Beran估计器，为生存分析提供了有效且无参数的解决方案。

> **摘要翻译:** 生存分析是医疗保健、工程和金融领域中建模事件发生时间数据的基本工具，其中删失观测带来了重大挑战。虽然像Beran估计器这样的传统方法提供了非参数解决方案，但它们通常难以处理复杂的数据结构和严重的删失。本文介绍了三种新颖的生存模型：iSurvM（基于均值似然函数的模糊生存模型）、iSurvQ（基于似然函数分位数的模糊生存模型）和iSurvJ（基于联合学习的模糊生存模型），它们将模糊概率理论与注意力机制相结合，以在没有参数假设的情况下处理删失数据。这些模型背后的第一个想法是，将每个实例在事件发生时刻之间的时间间隔上的删失观测表示为区间值概率分布。第二个想法是，采用带有可训练注意力权重的基于核的Nadaraya-Watson回归来计算整个数据集在时间间隔上的模糊概率分布。第三个想法是，考虑三种训练决策策略，这与所提出的三种模型相对应。在合成数据集和真实数据集上的实验表明，所提出的模型，特别是iSurvJ，从准确性和计算复杂性的角度来看，始终优于Beran估计器。实现所提出模型的代码已公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [301] [Physiological-Model-Based Neural Network for Heart Rate Estimation during Daily Physical Activities](https://arxiv.org/abs/2506.10144)
> *基于生理模型的神经网络用于日常体育活动中心率估计*

*Yaowen Zhang, Libera Fresiello, Peter H. Veltink, Dirk W. Donker, Ying Wang* | **Main category: cs.LG**

**Keywords:** 心率估计, 生理模型, 神经网络, 摄氧量, 心力衰竭

**Comment:** 

> **TL;DR:** 该研究提出了一种新颖的基于生理模型的神经网络（PMB-NN）框架，用于根据日常体育活动中的摄氧量（VO2）数据估计心率，实现了高估计精度，并优于传统生理模型。

**AI_Comments:** 该论文的创新之处在于将生理模型（PM）的约束嵌入到神经网络（NN）的训练过程中，形成了一种结合生理学原理和数据驱动优势的混合模型（PMB-NN）。这不仅提高了心率估计的准确性，还增强了模型的可解释性和个性化能力。通过识别个性化参数，该模型有望为心脏健康监测提供更精确、更具针对性的解决方案，特别是在心力衰竭的早期预警方面具有重要意义。其局限性可能在于目前仅在12名参与者的数据集上进行了测试，未来需要更大规模、更多样化的数据集进行验证。

<details>
  <summary>Details</summary>

**Motivation:** 心力衰竭（HF）是一个重大的全球健康挑战，早期发现可以改善预后。日常活动中心率异常可能是HF风险的早期指标。然而，现有用于HF检测的心率监测工具受限于其对基于人群平均值的依赖性，且现有心率估计方法（生理驱动型和纯数据驱动型）在效率和可解释性方面存在不足。该研究旨在实现个性化心率估计，作为动态数字孪生，精确追踪心脏健康生物标志物。

**Method:** 本研究引入了一种新颖的基于生理模型的神经网络（PMB-NN）框架，用于根据日常体育活动中的摄氧量（VO2）数据估计心率。该框架在来自12名参与者的个体数据集上进行训练和测试，这些参与者进行了包括休息、骑自行车和跑步在内的活动。通过将从简化的“人体运动生理模型”（PM）中导出的生理约束嵌入到神经网络训练过程中，PMB-NN模型在遵循人类生理原理的同时实现了高估计精度。

**Result:** PMB-NN模型实现了高估计精度，中位数R^2分数为0.8，RMSE为8.3 bpm。比较统计分析表明，PMB-NN的性能与基准神经网络模型相当，同时显著优于传统生理模型（p=0.002）。此外，PMB-NN能够识别PM的个性化参数，使PM能够生成合理的心率估计。

**Conclusion:** 提出的PMB-NN框架结合精确的VO2估计系统，为未来在日常生活中进行个性化和实时心脏监测提供了可能性。

> **ai_Abstract:** 本研究提出了一种新颖的基于生理模型的神经网络（PMB-NN）框架，旨在解决现有心率估计方法在心力衰竭早期检测中面临的效率和可解释性挑战。该框架将简化的生理模型约束嵌入到神经网络训练中，利用日常体育活动中的摄氧量数据进行心率估计。在12名参与者的个体数据集上进行训练和测试后，PMB-NN模型展现出高精度（R^2=0.8，RMSE=8.3 bpm），性能与基准神经网络相当，并显著优于传统生理模型。该方法能够识别个性化生理参数，为未来实现个性化、实时心脏健康监测奠定基础。

> **摘要翻译:** 心力衰竭（HF）构成重大的全球健康挑战，早期发现可改善预后。心率（HR）异常，特别是在日常活动期间，可能作为HF风险的早期指标。然而，现有用于HF检测的心率监测工具受限于其对基于人群平均值的可靠性。个性化心率估计作为动态数字孪生，能够精确跟踪心脏健康生物标志物。当前的心率估计方法，分为生理驱动型和纯数据驱动型模型，在效率和可解释性方面存在困难。本研究引入了一种新颖的基于生理模型的神经网络（PMB-NN）框架，用于在日常体育活动中根据摄氧量（VO2）数据估计心率。该框架在来自12名参与者的个体数据集上进行训练和测试，这些参与者进行了包括休息、骑自行车和跑步在内的活动。通过将从我们提出的简化人体运动生理模型（PM）中导出的生理约束嵌入到神经网络训练过程中，PMB-NN模型在遵循人类生理原理的同时实现了高估计精度，中位数R^2分数为0.8，RMSE为8.3 bpm。比较统计分析表明，PMB-NN的性能与基准神经网络模型相当，同时显著优于传统生理模型（p=0.002）。此外，我们的PMB-NN善于识别PM的个性化参数，使PM能够生成合理的心率估计。所提出的框架与来自身体运动的精确VO2估计系统相结合，为未来在日常生活中进行个性化和实时心脏监测提供了可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [309] [Wasserstein Barycenter Soft Actor-Critic](https://arxiv.org/abs/2506.10167)
> *Wasserstein 质心软演员-评论家算法*

*Zahra Shahrooei, Ali Baheri* | **Main category: cs.LG**

**Keywords:** 深度强化学习, 离策略, 演员-评论家, Wasserstein 质心, 样本效率

**Comment:** 

> **TL;DR:** 本文提出了 Wasserstein 质心软演员-评论家 (WBSAC) 算法，通过结合悲观和乐观的策略，并利用 Wasserstein 质心进行有向探索，提高了深度离策略演员-评论家算法在连续控制任务中的样本效率。

**AI_Comments:** 本文的创新之处在于利用 Wasserstein 质心融合悲观和乐观策略，从而实现有原则的有向探索。这种方法有效地解决了离策略强化学习中样本效率低下的关键挑战，对于提高连续控制任务的学习效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度离策略演员-评论家算法在连续控制领域中表现出色，但其样本效率低下，尤其是在稀疏奖励环境中。

**Method:** 提出 Wasserstein 质心软演员-评论家 (WBSAC) 算法。该算法利用一个悲观的演员进行时序差分学习，并利用一个乐观的演员来促进探索。通过使用悲观和乐观策略的 Wasserstein 质心作为探索策略，并在学习过程中调整探索程度来实现。

**Result:** 与最先进的离策略演员-评论家算法相比，WBSAC 在 MuJoCo 连续控制任务上具有更高的样本效率。

**Conclusion:** WBSAC 算法通过提供一种有原则的有向探索策略，显著提高了深度离策略演员-评论家算法在连续控制任务中的样本效率。

> **ai_Abstract:** WBSAC 算法旨在解决深度离策略演员-评论家算法在连续控制任务中样本效率低下的问题，尤其是在稀疏奖励环境下。它通过结合一个用于时序差分学习的悲观演员和一个用于促进探索的乐观演员，并以它们的 Wasserstein 质心作为自适应探索策略来实现。实验结果表明，WBSAC 在 MuJoCo 连续控制任务上比现有最先进的算法更具样本效率。

> **摘要翻译:** 深度离策略演员-评论家算法已成为连续控制领域强化学习的主导框架。然而，大多数这些算法都存在样本效率低下的问题，尤其是在稀疏奖励环境中。在本文中，我们通过提供一种有原则的有向探索策略，向解决此问题迈出了一步。我们提出了 Wasserstein 质心软演员-评论家 (WBSAC) 算法，该算法受益于用于时序差分学习的悲观演员和用于促进探索的乐观演员。这是通过使用悲观和乐观策略的 Wasserstein 质心作为探索策略，并在整个学习过程中调整探索程度来实现的。我们将 WBSAC 与最先进的离策略演员-评论家算法进行了比较，结果表明 WBSAC 在 MuJoCo 连续控制任务上具有更高的样本效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [312] [Balanced Hyperbolic Embeddings Are Natural Out-of-Distribution Detectors](https://arxiv.org/abs/2506.10146)
> *平衡双曲嵌入是天然的分布外检测器*

*Tejaswi Kasarla, Max van Spengler, Pascal Mettes* | **Main category: cs.LG**

**Keywords:** 分布外检测, 双曲嵌入, 平衡双曲学习, 分层结构, 异常检测

**Comment:** 

> **TL;DR:** 本文提出平衡双曲学习，利用双曲嵌入作为原型，在多个数据集上显著优于现有分布外检测方法，并支持分层泛化。

**AI_Comments:** 本文的创新点在于将双曲几何引入分布外检测领域，并提出了平衡双曲学习算法，有效地利用了双曲空间的层级结构特性。其重要性在于提供了一种新的、表现优异的OOD检测范式，尤其在处理具有层级关系的数据时具有天然优势。文章的结论清晰，实验结果支持其主张，展现了双曲嵌入在OOD问题上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习中，过滤不属于训练数据分布的样本（分布外识别）是一个重要且被充分研究的问题。

**Method:** 引入平衡双曲学习，提出一种双曲类别嵌入算法，该算法联合优化分层失真和浅层与宽子层次之间的平衡。然后使用这些类别嵌入作为双曲原型进行分类，并推广现有分布外评分函数以与双曲原型一起操作。

**Result:** 在13个数据集和13个评分函数上的实证评估表明，当使用相同数据和相同骨干网络进行训练时，我们的双曲嵌入优于现有的分布外方法。它还优于其他双曲方法，击败了最先进的对比方法，并原生支持分层分布外泛化。

**Conclusion:** 一个好的分层双曲嵌入更适合区分分布内和分布外样本。

> **ai_Abstract:** 本文提出了一种名为“平衡双曲学习”的新方法，用于分布外（OOD）识别。该方法利用双曲嵌入作为分类原型，并设计了一种双曲类别嵌入算法来优化分层结构。通过在多个数据集和评分函数上的广泛实验，证明了该方法在OOD检测方面优于现有方法、其他双曲方法以及最先进的对比方法，并且能够实现分层OOD泛化。

> **摘要翻译:** 分布外识别是深度学习中一个重要且被充分研究的问题，其目标是过滤掉不属于网络训练数据分布的样本。本文的结论很简单：一个好的分层双曲嵌入更适合区分分布内和分布外样本。我们引入了平衡双曲学习。我们概述了一种双曲类别嵌入算法，该算法联合优化分层失真以及浅层和宽子层次之间的平衡。然后，我们使用这些类别嵌入作为双曲原型，对分布内数据进行分类。我们概述了如何推广现有分布外评分函数以与双曲原型一起操作。在13个数据集和13个评分函数上的实证评估表明，当使用相同数据和相同骨干网络进行训练时，我们的双曲嵌入优于现有的分布外方法。我们还表明，我们的双曲嵌入优于其他双曲方法，击败了最先进的对比方法，并原生支持分层分布外泛化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [Probabilistic Variational Contrastive Learning](https://arxiv.org/abs/2506.10159)
> *概率变分对比学习*

*Minoh Jeong, Seonho Kim, Alfred Hero* | **Main category: cs.LG**

**Keywords:** 对比学习, 变分推断, 不确定性量化, 概率嵌入, 维度坍塌

**Comment:** 

> **TL;DR:** VCL为对比学习引入了概率基础，解决了确定性嵌入缺乏不确定性量化的问题，并通过最大化ELBO实现，在多个基准测试中表现良好并提供有意义的不确定性估计。

**AI_Comments:** VCL的创新之处在于将变分推断引入对比学习，为确定性嵌入提供了急需的不确定性量化能力。这不仅解决了现有方法的一个关键局限性，还通过实验证明了其在缓解维度坍塌、增强互信息和保持分类准确性方面的有效性。VCL为未来基于概率的对比学习研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的对比学习（CL）方法（如SimCLR和SupCon）学习到的确定性嵌入达到了最先进的性能，但缺乏一种原则性的机制来进行不确定性量化。

**Method:** 本文提出了变分对比学习（VCL），一个无解码器框架，通过将InfoNCE损失解释为替代重建项，并向单位超球面上的均匀先验添加KL散度正则化器来最大化证据下界（ELBO）。VCL将近似后验$q_\theta(z|x)$建模为投影正态分布，从而能够采样概率嵌入。其两个实例化——VSimCLR和VSupCon——用来自$q_\theta(z|x)$的样本替换确定性嵌入，并将归一化的KL项纳入损失函数。

**Result:** 实验表明，VCL减轻了维度坍塌，增强了与类别标签的互信息，并在分类准确性方面与确定性基线持平或超越，同时通过后验模型提供了有意义的不确定性估计。

**Conclusion:** VCL为对比学习提供了概率基础，可作为对比方法的新基础。

> **ai_Abstract:** 本文提出了一种名为变分对比学习（VCL）的新框架，旨在解决现有对比学习方法在确定性嵌入中缺乏不确定性量化的问题。VCL通过最大化证据下界（ELBO）并引入KL散度正则化来建模概率嵌入，将InfoNCE损失视为重建项。通过将近似后验建模为投影正态分布，VCL能够采样概率嵌入。实验结果表明，VCL有效缓解了维度坍塌，提高了与类别标签的互信息，并在分类准确性上与现有确定性方法相当甚至更优，同时提供了可靠的不确定性估计，为对比学习奠定了概率基础。

> **摘要翻译:** 对比学习（CL）方法如SimCLR和SupCon学习到的确定性嵌入达到了最先进的性能，但缺乏一种原则性的机制来进行不确定性量化。我们提出了变分对比学习（VCL），一个无解码器框架，通过将InfoNCE损失解释为替代重建项，并向单位超球面上的均匀先验添加KL散度正则化器来最大化证据下界（ELBO）。我们将近似后验$q_\theta(z|x)$建模为投影正态分布，从而能够采样概率嵌入。我们的两个实例化——VSimCLR和VSupCon——用来自$q_\theta(z|x)$的样本替换确定性嵌入，并将归一化的KL项纳入损失函数。在多个基准测试上的实验表明，VCL减轻了维度坍塌，增强了与类别标签的互信息，并在分类准确性方面与确定性基线持平或超越，同时通过后验模型提供了有意义的不确定性估计。因此，VCL为对比学习配备了概率基础，可作为对比方法的新基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [341] [Geometric Regularity in Deterministic Sampling of Diffusion-based Generative Models](https://arxiv.org/abs/2506.10177)
> *扩散生成模型确定性采样中的几何规律性*

*Defang Chen, Zhenyu Zhou, Can Wang, Siwei Lyu* | **Main category: cs.LG**

**Keywords:** 扩散模型, 确定性采样, 几何规律性, 动态规划, 图像生成

**Comment:** 50 pages. The short version appeared in ICML 2024. arXiv admin note:
  substantial text overlap with arXiv:2405.11326

> **TL;DR:** 扩散模型的确定性采样轨迹具有低维几何规律性（“回旋镖”形状），利用此规律可提高图像生成性能。

**AI_Comments:** 这项研究揭示了扩散模型确定性采样过程中的一个基本几何特性，为理解和优化扩散模型提供了新的视角。通过利用这一规律性，论文提出了一种高效的采样策略，显著提升了生成性能，尤其是在计算资源有限或需要快速生成的情况下，具有重要的实际应用价值。其创新点在于从几何角度深入分析了采样动力学，并成功将其转化为实际的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在复杂数据分布和可处理先验分布之间建立平滑变换，但其确定性采样动力学中的几何特性尚未被充分揭示和利用。

**Method:** 揭示并表征了确定性采样轨迹的几何规律性，特别是在基于核估计数据建模的闭合形式解下。提出了一种基于动态规划的方案，将采样时间表与底层轨迹结构更好地对齐。

**Result:** 发现每个模拟采样轨迹都位于一个极低维子空间内，所有轨迹都呈现几乎相同的“回旋镖”形状，不受模型架构、应用条件或生成内容的影响。提出的动态规划方案只需对现有基于ODE的数值求解器进行最小修改，计算开销可忽略不计，并在图像生成性能上取得卓越表现，尤其是在只有5到10次函数评估的区域。

**Conclusion:** 扩散模型的确定性采样轨迹存在显著的几何规律性，利用这一规律可以有效优化采样时间调度，从而在低函数评估次数下显著提升图像生成质量。

> **ai_Abstract:** 本文揭示了扩散模型确定性采样轨迹中显著的几何规律性：所有轨迹都位于极低维子空间，并呈现一致的“回旋镖”形状。基于此发现，提出了一种利用动态规划优化采样时间表的方案，该方案计算开销小，能显著提升图像生成性能，尤其是在低函数评估次数下。

> **摘要翻译:** 扩散生成模型利用随机微分方程（SDEs）及其等效的概率流常微分方程（ODEs）在复杂高维数据分布和可处理的先验分布之间建立平滑变换。在本文中，我们揭示了确定性采样动力学中一个显著的几何规律性：每个模拟的采样轨迹都位于一个极低维子空间内，并且所有轨迹都呈现出几乎相同的“回旋镖”形状，无论模型架构、应用条件或生成内容如何。我们描述了这些轨迹的几个有趣特性，特别是在基于核估计数据建模的闭合形式解下。我们还展示了所发现轨迹规律性的一种实际应用，即提出了一种基于动态规划的方案，以更好地将采样时间表与底层轨迹结构对齐。这种简单的策略只需对现有基于ODE的数值求解器进行最小修改，计算开销可忽略不计，并在图像生成性能上取得卓越表现，尤其是在只有5到10次函数评估的区域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [347] [A Comparative Study of Machine Learning Techniques for Early Prediction of Diabetes](https://arxiv.org/abs/2506.10180)
> *机器学习技术在糖尿病早期预测中的比较研究*

*Mowafaq Salem Alzboon, Mohammad Al-Batah, Muhyeeddin Alqaraleh, Ahmad Abuashour, Ahmad Fuad Bader* | **Main category: cs.LG**

**Keywords:** 机器学习, 糖尿病预测, 早期检测, 比较研究, 神经网络

**Comment:** 

> **TL;DR:** 本研究比较了多种机器学习算法在Pima印第安人糖尿病数据集上进行糖尿病早期预测的有效性，结果显示神经网络表现最佳。

**AI_Comments:** 该研究通过比较多种主流机器学习算法在特定数据集上的性能，为糖尿病早期预测提供了有价值的参考。其创新点在于对多种方法的系统性评估，并明确指出了表现最优的算法。然而，研究的局限性可能在于数据集的单一性，未来的工作可以考虑在更广泛、更多样化的数据集上进行验证。

<details>
  <summary>Details</summary>

**Motivation:** 糖尿病在全球范围内日益成为严重的健康问题，早期识别和控制至关重要。利用机器学习算法进行糖尿病预测已显示出积极效果，本研究旨在评估不同机器学习方法在糖尿病预测中的有效性。

**Method:** 本研究使用Pima印第安人糖尿病数据集，该数据集包含768名患者的年龄、BMI和血糖水平等信息。评估了多种机器学习技术，包括逻辑回归、决策树、随机森林、k-最近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络。

**Result:** 研究结果表明，神经网络算法表现最佳，准确率为78.57%；其次是随机森林方法，准确率为76.30%。

**Conclusion:** 本研究表明，机器学习算法可以辅助糖尿病预测，并作为一种有效的早期检测工具。

> **ai_Abstract:** 本研究旨在比较不同机器学习技术在糖尿病早期预测中的性能。研究使用了包含768名患者数据的Pima印第安人糖尿病数据集，并评估了逻辑回归、决策树、随机森林、k-最近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络等算法。结果显示，神经网络以78.57%的准确率表现最佳，其次是随机森林。研究强调了机器学习算法在糖尿病早期检测中的潜力。

> **摘要翻译:** 在许多国家，糖尿病正成为一个重大的健康问题，早期识别和控制至关重要。利用机器学习算法预测糖尿病已取得令人鼓舞的成果。本研究旨在利用Pima印第安人糖尿病数据集，评估多种机器学习方法在糖尿病预测中的有效性。该数据集包含768名患者的信息，如年龄、体重指数（BMI）和血糖水平。评估的技术包括逻辑回归、决策树、随机森林、k-最近邻、朴素贝叶斯、支持向量机、梯度提升和神经网络。研究结果表明，神经网络算法表现最佳，准确率为78.57%，其次是随机森林方法，准确率为76.30%。该研究表明，机器学习算法可以帮助糖尿病预测，并成为一种有效的早期检测工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [353] [System Identification Using Kolmogorov-Arnold Networks: A Case Study on Buck Converters](https://arxiv.org/abs/2506.10434)
> *使用Kolmogorov-Arnold网络进行系统辨识：降压转换器案例研究*

*Nart Gashi, Panagiotis Kakosimos, George Papafotiou* | **Main category: cs.LG**

**Keywords:** Kolmogorov-Arnold网络, 系统辨识, 降压转换器, 可解释性, 状态空间模型

**Comment:** 2025 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works

> **TL;DR:** 本研究探讨了使用Kolmogorov-Arnold网络（KANs）对降压转换器进行系统辨识，证明了KANs在准确识别系统动态、验证模型一致性及检测参数变化方面的有效性，并强调了其在工业系统中的应用潜力。

**AI_Comments:** 该论文的创新点在于将新兴的Kolmogorov-Arnold网络应用于系统辨识领域，特别强调了其在提升模型可解释性、效率和准确性方面的优势，这些是传统神经网络的痛点。选择降压转换器作为案例研究，具体展示了KANs在实际工程问题中的应用潜力。这项工作为将KANs推广到更广泛的工业控制和监控系统辨识任务奠定了基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Kolmogorov-Arnold网络（KANs）作为一种强大的框架，在新兴的动态系统可解释和高效系统辨识领域中崭露头角。与传统神经网络相比，KANs通过可学习的激活函数实现函数逼近，提供了更好的可扩展性、准确性和可解释性。本研究旨在探讨KANs在降压转换器系统动态建模和分析中的应用。

**Method:** 本研究将Kolmogorov-Arnold网络应用于降压转换器系统，重点关注状态空间参数估计和系统方程的发现。方法包括使用仿真数据，通过KANs逼近状态导数，构建可解释的状态空间表示，并通过数值实验验证这些模型。

**Result:** 研究结果表明，KANs能够准确识别系统动态，验证模型一致性，并检测参数变化。这些结果为KANs在现代工业系统中的系统辨识应用提供了宝贵的见解。

**Conclusion:** 本研究的结论是，Kolmogorov-Arnold网络在系统辨识中表现出强大的能力，特别是在准确识别系统动态、验证模型一致性和检测参数变化方面，证明了其在现代工业系统中的适用性。

> **ai_Abstract:** 本论文探讨了Kolmogorov-Arnold网络（KANs）在降压转换器系统辨识中的应用。KANs利用其独特的可学习激活函数，在可解释性、效率和准确性方面优于传统神经网络。研究方法涉及使用KANs对状态导数进行逼近，构建可解释的状态空间模型，并利用仿真数据进行验证。实验结果表明，KANs能够有效识别系统动态，验证模型一致性，并检测参数变化，这突显了其在现代工业系统辨识中的巨大潜力。

> **摘要翻译:** Kolmogorov-Arnold网络（KANs）正在成为动态系统中可解释和高效系统辨识的强大框架。通过利用Kolmogorov-Arnold表示定理，KANs通过可学习的激活函数实现函数逼近，与传统神经网络相比，提供了改进的可扩展性、准确性和可解释性。本文研究了KANs在对降压转换器系统动态进行建模和分析中的应用，重点关注状态空间参数估计以及系统方程的发现。使用仿真数据，该方法包括利用KANs逼近状态导数，构建可解释的状态空间表示，并通过数值实验验证这些模型。结果证明了KANs准确识别系统动态、验证模型一致性和检测参数变化的能力，为其在现代工业系统中的系统辨识应用提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [354] [Optimizing Genetic Algorithms with Multilayer Perceptron Networks for Enhancing TinyFace Recognition](https://arxiv.org/abs/2506.10184)
> *使用多层感知器网络优化遗传算法以增强微小人脸识别*

*Mohammad Subhi Al-Batah, Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh* | **Main category: cs.LG**

**Keywords:** 遗传算法, 多层感知器, 特征选择, 降维, 机器学习

**Comment:** 

> **TL;DR:** 本研究通过结合遗传算法和多层感知器网络，并在不同数据集上进行评估，旨在优化特征工程和神经网络参数，以提高模型性能，特别是在复杂数据集上遗传算法表现优异。

**AI_Comments:** 该研究通过比较遗传算法和主成分分析在提升MLP性能中的作用，深入探讨了特征工程的重要性。其创新点在于强调了GA在复杂数据集上进行特征选择的有效性，为实际应用提供了有价值的指导。然而，抽象中未明确指出具体优化了遗传算法的哪些方面，这可能是一个限制。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过实证检验多层感知器（MLP）网络，探讨特征选择和降维技术（如遗传算法和主成分分析）如何影响模型性能，以优化特征工程和神经网络参数。

**Method:** 研究采用了三种方法：a) 使用默认设置训练多层感知器（MLP）作为基线；b) 使用遗传算法（GA）进行特征选择；c) 使用主成分分析（PCA）进行降维。实验在TinyFace、Heart Disease和Iris三个数据集上进行。

**Result:** 结果表明，这些技术对性能有重要影响。PCA在低维和无噪声数据集上表现出优势，而遗传算法（GA）通过准确识别关键特征，在复杂数据集上持续提高准确性。特征选择和降维在提升MLP性能方面发挥着相互依赖的作用。

**Conclusion:** 特征选择和降维在提升MLP性能方面发挥着相互依赖的作用。该研究为特征工程和神经网络参数优化提供了实践指导，适用于广泛的机器学习任务。

> **ai_Abstract:** 本研究通过在TinyFace、心脏病和Iris数据集上对多层感知器（MLP）网络进行实证检验，探讨了遗传算法（GA）进行特征选择和主成分分析（PCA）进行降维对模型性能的影响。结果表明，GA在复杂数据集中通过精准识别关键特征显著提升了准确性，而PCA在低维无噪声数据集中有效。研究强调了特征选择和降维在提升MLP性能中的相互依赖性，并为特征工程和神经网络参数优化提供了实践指导。

> **摘要翻译:** 本研究通过涉及TinyFace、心脏病和Iris三个不同数据集的严格方法学实验过程，对MLP网络进行了实证检验。研究概述：本研究包括三个关键方法：a) 使用多层感知器（MLP）的默认设置进行基线训练，b) 使用基于遗传算法（GA）的特征选择进行优化，c) 基于主成分分析（PCA）的降维。结果显示了这些技术如何影响性能的重要信息。虽然PCA在低维和无噪声数据集中显示出优势，但GA通过准确识别关键特征，在复杂数据集中持续提高了准确性。比较揭示了特征选择和降维在增强MLP性能中发挥着相互依赖的作用。该研究为特征工程和神经网络参数优化文献做出了贡献，为广泛的机器学习任务提供了实用指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [360] [Scalable Non-Equivariant 3D Molecule Generation via Rotational Alignment](https://arxiv.org/abs/2506.10186)
> *通过旋转对齐实现可扩展的非等变三维分子生成*

*Yuhui Ding, Thomas Hofmann* | **Main category: cs.LG**

**Keywords:** 3D分子生成, 非等变模型, 扩散模型, 旋转对齐, 可扩展性

**Comment:** ICML 2025

> **TL;DR:** 提出一种通过旋转对齐构建对齐潜在空间，然后训练非等变扩散模型生成3D分子的方法，解决了等变模型的扩展性和效率问题，性能与最先进模型相当且更高效。

**AI_Comments:** 这项工作通过引入旋转对齐来规避SE(3)等变网络的复杂性，从而在保持生成质量的同时显著提高模型的可扩展性和效率，这是一个重要的创新。它展示了在某些应用中，通过巧妙的设计来放松严格的对称性约束，可以带来实际的性能优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的等变扩散模型在3D分子生成方面表现出色，但其专门的等变架构限制了扩散模型的可扩展性和效率。

**Method:** 提出一种放松等变约束的方法。具体来说，该方法为每个分子学习一个样本依赖的SO(3)变换，以构建一个对齐的潜在空间。然后，在这个对齐的表示上训练一个非等变扩散模型。

**Result:** 实验结果表明，该方法显著优于先前报道的非等变模型。它产生了与最先进的等变扩散模型相当的样本质量，并提供了改进的训练和采样效率。

**Conclusion:** 通过旋转对齐的非等变扩散模型可以有效生成高质量3D分子，同时解决等变模型的扩展性和效率问题。

> **ai_Abstract:** 本文提出了一种可扩展的非等变三维分子生成方法，通过为每个分子学习样本依赖的SO(3)变换来构建对齐的潜在空间，并在此空间上训练非等变扩散模型。实验证明，该方法在性能上优于现有非等变模型，并能达到与最先进等变模型相当的样本质量，同时显著提升了训练和采样的效率，解决了等变模型的可扩展性限制。

> **摘要翻译:** 等变扩散模型在三维分子生成方面取得了令人印象深刻的性能。这些模型通过利用SE(3)等变去噪网络来整合三维分子的欧几里得对称性。然而，专门的等变架构限制了扩散模型的可扩展性和效率。在本文中，我们提出了一种放松这种等变约束的方法。具体来说，我们的方法为每个分子学习一个样本依赖的SO(3)变换，以构建一个对齐的潜在空间。然后，在这个对齐的表示上训练一个非等变扩散模型。实验结果表明，我们的方法比先前报道的非等变模型表现显著更好。它产生了与最先进的等变扩散模型相当的样本质量，并提供了改进的训练和采样效率。我们的代码可在https://github.com/skeletondyh/RADM获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [366] [Improving Oral Cancer Outcomes Through Machine Learning and Dimensionality Reduction](https://arxiv.org/abs/2506.10189)
> *机器学习和降维技术改善口腔癌预后*

*Mohammad Subhi Al-Batah, Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon* | **Main category: cs.LG**

**Keywords:** 口腔癌, 机器学习, 神经网络, 降维, 诊断, 预后

**Comment:** 

> **TL;DR:** 本研究回顾并比较了多种机器学习方法在口腔癌诊断和预后中的应用，发现神经网络在预测口腔癌方面表现最佳，准确率达到93.6%，并强调了特征选择和降维的重要性。

**AI_Comments:** 本文的创新之处在于系统比较了多种机器学习模型在口腔癌诊断和预后中的性能，并明确指出神经网络的优越性。其重要性在于为口腔癌的早期检测和治疗策略优化提供了数据驱动的见解，有望通过自动化和高精度的诊断工具改善患者预后。局限性可能在于未详细说明所使用的数据集规模、来源以及具体的特征工程过程，也未深入探讨模型的泛化能力和临床转化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 口腔癌的早期诊断和准确预后对于提高患者生存率至关重要，而机器学习和数据挖掘的最新进展为区分良恶性口腔病变提供了先进的自动化工具，因此需要对这些技术在口腔癌领域的应用进行全面审查。

**Method:** 本研究全面回顾了包括神经网络、K-近邻（KNN）、支持向量机（SVM）和集成学习技术在内的尖端数据挖掘方法，并对其在口腔癌诊断和预后中的应用进行了严格的比较分析。

**Result:** 研究发现神经网络在预测口腔癌方面表现优于其他模型，分类准确率达到93.6%。此外，研究强调了整合特征选择和降维技术以提高模型性能的潜在益处。

**Conclusion:** 先进的数据挖掘技术在加强早期检测、优化治疗策略以及最终改善口腔肿瘤学领域患者预后方面具有显著前景。

> **ai_Abstract:** 本研究回顾并比较了多种机器学习和数据挖掘方法在口腔癌诊断和预后中的应用。通过对神经网络、KNN、SVM和集成学习等技术进行严格分析，发现神经网络在预测口腔癌方面表现最佳，分类准确率高达93.6%。研究还强调了特征选择和降维技术对提升模型性能的重要性，最终指出先进数据挖掘技术在改善口腔癌患者预后方面的巨大潜力。

> **摘要翻译:** 口腔癌在肿瘤学中是一个严峻的挑战，需要早期诊断和准确预后来提高患者生存率。机器学习和数据挖掘的最新进展彻底改变了传统的诊断方法，为区分良性和恶性口腔病变提供了复杂和自动化的工具。本研究全面回顾了尖端数据挖掘方法，包括神经网络、K-近邻（KNN）、支持向量机（SVM）和集成学习技术，并专门将其应用于口腔癌的诊断和预后。通过严格的比较分析，我们的研究结果表明，神经网络超越了其他模型，在预测口腔癌方面取得了93.6%的惊人分类准确率。此外，我们强调了整合特征选择和降维技术以提高模型性能的潜在益处。这些见解突显了先进数据挖掘技术在加强早期检测、优化治疗策略以及最终改善口腔肿瘤学领域患者预后方面的巨大前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [369] [Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning](https://arxiv.org/abs/2506.10973)
> *将神经网络架构扩展到函数空间进行算子学习的原则性方法*

*Julius Berner, Miguel Liu-Schiaffini, Jean Kossaifi, Valentin Duruisseaux, Boris Bonev, Kamyar Azizzadenesheli, Anima Anandkumar* | **Main category: cs.LG**

**Keywords:** 神经算子, 函数空间, 神经网络架构, 算子学习, 科学计算

**Comment:** 

> **TL;DR:** 本文提出了将现有神经网络架构转换为神经算子的原则和方法，以更好地解决科学领域中的函数空间问题。

**AI_Comments:** 本文的创新之处在于其系统性地提出了将现有、成熟的神经网络架构转换为神经算子的原则和方法，而非像以往那样将神经算子视为独立模型。这极大地降低了将深度学习的成功经验迁移到科学计算领域的门槛，使得研究人员和工程师能够更便捷地利用已有的架构优化。其提出的“食谱”具有很强的实用性，有助于推动神经算子在实际科学问题中的应用。该工作对于弥合深度学习与科学计算之间的差距具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度学习主要应用于有限维空间的数据，但在科学领域（如连续时间动力学系统和偏微分方程）中，问题自然地在函数空间上表述，这些空间通常是无限维的。这种数据性质的根本差异限制了神经网络在科学应用中取得与计算机视觉和自然语言处理领域相当的成功。虽然神经算子是泛化神经网络到函数空间映射的原则性方法，但之前的神经算子架构通常是独立引入的，并未直接从现有神经网络架构扩展而来，这限制了它们享受深度学习中经过经验测试的架构优化。

**Method:** 本文识别并提炼了构建无限维函数空间映射实用实现的关键原则。利用这些原则，作者提出了一种将几种流行的神经网络架构以最小修改转换为神经算子的“食谱”或方法。

**Result:** 作者提供了一个将流行神经网络架构转换为神经算子的“食谱”，并详细介绍了使神经算子在实践中工作的步骤。他们还提供了相关代码。

**Conclusion:** 本文旨在通过提供将现有神经网络架构转换为神经算子的原则和实用方法，指导实践者更好地应用神经算子解决科学问题，从而使算子学习能够利用深度学习中经过验证的架构优化。

> **ai_Abstract:** 本文针对深度学习在处理科学领域无限维函数空间问题上的局限性，提出了将现有神经网络架构扩展到神经算子的原则性方法。作者识别了构建无限维函数空间映射的关键原则，并基于此提出了一种“食谱”，可以将多种流行神经网络架构以最小修改转换为神经算子。这使得算子学习能够利用深度学习中已验证的架构优化，从而更好地解决偏微分方程等科学问题，并提供了实现代码和实践指导。

> **摘要翻译:** 许多科学问题，例如由连续时间动力学系统和偏微分方程（PDEs）描述的问题，自然地在函数空间上被公式化。虽然函数空间通常是无限维的，但深度学习主要通过计算机视觉和自然语言处理等应用取得了进展，这些应用侧重于有限维空间之间的映射。数据性质上的这种根本差异限制了神经网络在科学应用中取得与其他领域相当的成功。神经算子是将神经网络泛化到函数空间之间映射的一种原则性方法，为复制深度学习对科学问题的变革性影响提供了途径。例如，神经算子可以学习整类偏微分方程的解算子，例如具有不同边界条件、系数函数和几何形状的物理系统。深度学习成功的一个关键因素是通过广泛的经验测试精心设计神经网络架构。将这些神经网络架构转化为神经算子可以使算子学习享受相同的经验优化。然而，以前的神经算子架构通常是作为独立模型引入的，并非直接作为现有神经网络架构的扩展而导出。在本文中，我们识别并提炼了构建无限维函数空间之间映射的实用实现的关键原则。利用这些原则，我们提出了一种将几种流行的神经网络架构以最小修改转换为神经算子的“食谱”。本文旨在指导实践者完成这一过程，并详细说明了使神经算子在实践中工作的步骤。我们的代码可以在 https://github.com/neuraloperator/NNs-to-NOs 找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [372] [DynaSubVAE: Adaptive Subgrouping for Scalable and Robust OOD Detection](https://arxiv.org/abs/2506.10200)
> *DynaSubVAE：可扩展和鲁棒OOD检测的自适应子分组*

*Tina Behrouzi, Sana Tonekaboni, Rahul G. Krishnan, Anna Goldenberg* | **Main category: cs.LG**

**Keywords:** OOD检测, 变分自编码器, 动态子分组, 异质数据, 聚类

**Comment:** 

> **TL;DR:** DynaSubVAE是一个动态子分组变分自编码器框架，通过动态更新其潜在结构来同时进行表示学习和自适应OOD检测，在各种OOD检测场景中表现出色。

**AI_Comments:** DynaSubVAE的创新之处在于其动态子分组机制，使其能够随着数据演进并适应新的模式，而非仅仅将新样本标记为OOD。这对于处理现实世界中不断变化的异质数据流具有重要意义，尤其是在处理未见类别或新兴群体时，提高了模型的鲁棒性和预测准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界数据常包含异质子群体，现有模型易忽略这些未被充分代表的群体，导致不准确预测。现有解决方案多将这些样本视为域外（OOD）而非适应新模式。

**Method:** 本文提出了DynaSubVAE，一个动态子分组变分自编码器框架，它联合执行表示学习和自适应OOD检测。DynaSubVAE通过动态更新其潜在结构来捕捉新趋势，利用一种受高斯混合模型启发的非参数聚类机制，根据嵌入相似性发现和建模潜在子群体。

**Result:** DynaSubVAE在近OOD和远OOD检测中均取得了竞争性表现，尤其在训练期间缺失整个类别的类OOD场景中表现出色。动态子分组机制在OOD准确性和后悔精度方面均优于独立聚类方法（如GMM和KMeans++）。

**Conclusion:** DynaSubVAE通过其动态子分组机制，成功地解决了异质数据中的OOD检测问题，并在多种OOD场景下展现出优越的性能，特别是对于未见类别。

> **ai_Abstract:** DynaSubVAE是一种新颖的动态子分组变分自编码器框架，旨在解决现实世界数据中异质子群体的OOD检测问题。它通过动态更新潜在结构和利用非参数聚类机制，实现了表示学习和自适应OOD检测的联合进行。实验证明，DynaSubVAE在多种OOD场景，特别是类OOD检测中表现卓越，且其动态子分组机制优于传统聚类方法。

> **摘要翻译:** 现实世界中的观测数据通常包含现有或新兴的异质子群体，这些群体偏离了全局模式。大多数模型往往忽视这些代表性不足的群体，导致不准确甚至有害的预测。现有解决方案通常依赖于将这些样本检测为域外（OOD），而不是使模型适应新的新兴模式。我们引入了DynaSubVAE，一个动态子分组变分自编码器框架，它联合执行表示学习和自适应OOD检测。与传统方法不同，DynaSubVAE通过动态更新其潜在结构以捕捉新趋势，与数据一同演进。它利用一种受高斯混合模型启发的、新颖的非参数聚类机制，根据嵌入相似性发现和建模潜在子群体。大量实验表明，DynaSubVAE在近OOD和远OOD检测中均取得了竞争性表现，并在训练期间缺少整个类别的类OOD场景中表现出色。我们进一步说明，我们的动态子分组机制在OOD准确性和后悔精度方面均优于独立的聚类方法，如GMM和KMeans++。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [378] [AWP: Activation-Aware Weight Pruning and Quantization with Projected Gradient Descent](https://arxiv.org/abs/2506.10205)
> *AWP：基于投影梯度下降的激活感知权重剪枝与量化*

*Jing Liu, Toshiaki Koike-Akino, Ye Wang, Hassan Mansour, Matthew Brand* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 模型压缩, 剪枝, 量化, 投影梯度下降

**Comment:** ICML 2025 workshop on Efficient Systems for Foundation Models

> **TL;DR:** AWP是一种新的统一方法，用于在LLM上进行激活感知权重剪枝和量化，它通过投影梯度下降实现，并优于现有方法。

**AI_Comments:** AWP的创新之处在于其将激活感知权重剪枝与稀疏近似问题相结合，并利用投影梯度下降实现统一的剪枝和量化框架。其在LLM压缩上的SOTA性能和理论收敛保证，使其在边缘设备部署大型模型方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型（LLMs）体积庞大，尤其是在边缘设备上部署时，需要进行模型压缩（如量化和剪枝）的问题。

**Method:** 提出了一种名为AWP（Activation-aware Weight pruning and quantization via Projected gradient descent）的统一方法，该方法将激活感知权重剪枝与稀疏近似问题联系起来，并受到迭代硬阈值（IHT）成功的启发。

**Result:** 实验证明AWP优于最先进的LLM剪枝和量化方法。该方法还提供了剪枝的理论收敛保证。

**Conclusion:** AWP提供了一种有效且统一的LLM压缩方法，通过激活感知剪枝和量化，实现了优于现有技术的性能和理论保证。

> **ai_Abstract:** 本文提出了一种名为AWP的统一模型压缩方法，用于大型语言模型（LLMs）的逐层训练后量化和剪枝。AWP将激活感知权重剪枝与稀疏近似问题相结合，并借鉴了迭代硬阈值（IHT）的成功经验，通过投影梯度下降实现。实验结果表明，AWP在LLM剪枝和量化方面优于现有最先进的方法，并且提供了剪枝的理论收敛保证。

> **摘要翻译:** 为了解决大型语言模型（LLMs）的巨大体积问题，模型压缩方法，如量化和剪枝，经常被部署，尤其是在边缘设备上。在这项工作中，我们专注于逐层训练后量化和剪枝。通过将激活感知权重剪枝与稀疏近似问题联系起来，并受迭代硬阈值（IHT）成功的启发，我们提出了一种通过投影梯度下降实现激活感知权重剪枝和量化（AWP）的统一方法。我们的实验表明，AWP优于最先进的LLM剪枝和量化方法。本文还提供了所提出剪枝方法的理论收敛保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [391] [A new type of federated clustering: A non-model-sharing approach](https://arxiv.org/abs/2506.10244)
> *一种新型联邦聚类：非模型共享方法*

*Yuji Kawamata, Kaoru Kamijo, Maki Kihira, Akihiro Toyoda, Tomoru Nakayama, Akira Imakura, Tetsuya Sakurai, Yukihiko Okada* | **Main category: cs.LG**

**Keywords:** 联邦聚类, 数据协作聚类, 隐私保护, 复杂数据划分, 中间表示

**Comment:** 

> **TL;DR:** 提出了一种名为DC-Clustering的新型联邦聚类方法，它支持复杂的数据划分场景，通过共享中间表示而非原始数据实现隐私保护和高效协作聚类，性能可媲美集中式聚类。

**AI_Comments:** 该论文的创新点在于提出了DC-Clustering，这是一种支持复杂数据划分（水平和垂直分割共存）的联邦聚类方法，这在现有联邦聚类研究中是一个重要的进步。其非模型共享的特性，通过共享中间表示而非原始数据，显著增强了隐私保护。此外，单轮通信的效率和对多种聚类算法的兼容性也增加了其实用价值，特别适用于医疗和金融等对隐私要求极高的领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦学习（FL）聚类方法通常假设简单的数据划分场景（如水平或垂直分割），无法处理更复杂的分布式数据结构，例如水平和垂直分割并存的情况。

**Method:** 本研究提出数据协作聚类（DC-Clustering），这是一种新型联邦聚类方法，支持在水平和垂直分割共存的复杂数据划分场景下进行聚类。DC-Clustering中，每个机构只共享中间表示而非原始数据，以确保隐私保护。该方法允许在k-means和谱聚类之间灵活选择，并通过与中央服务器的单轮通信即可获得最终结果。

**Result:** 使用合成数据集和开放基准数据集进行了广泛实验，结果表明该方法实现的聚类性能与所有数据汇集在一起的集中式聚类相当。

**Conclusion:** DC-Clustering通过实现对分布式异构数据的有效知识发现，弥补了当前联邦学习研究中的一个重要空白。其隐私保护、通信效率和灵活性等实用特性使其成为医疗保健和金融等隐私敏感领域的一个有前景的工具。

> **ai_Abstract:** 该论文提出了一种名为数据协作聚类（DC-Clustering）的新型联邦聚类方法，旨在解决现有联邦聚类方法无法处理复杂数据划分场景（如水平与垂直分割共存）的问题。DC-Clustering通过仅共享中间表示而非原始数据来保护隐私，并允许在k-means和谱聚类之间灵活选择，只需单轮通信即可完成聚类。实验证明，其性能与集中式聚类相当，为隐私敏感领域分布式异构数据的知识发现提供了高效且实用的解决方案。

> **摘要翻译:** 近年来，利用跨机构敏感数据的日益增长的需求，使得联邦学习（FL）受到越来越多的关注。联邦学习是一种去中心化的机器学习范式，它可以在不共享原始数据的情况下进行模型训练。然而，现有的基于FL的聚类方法，即联邦聚类，通常假设简单的数据划分场景，如水平或垂直分割，并且无法处理更复杂的分布式结构。本研究提出数据协作聚类（DC-Clustering），这是一种新型联邦聚类方法，支持在水平和垂直分割并存的复杂数据划分场景下进行聚类。在DC-Clustering中，每个机构只共享中间表示而不是原始数据，确保了隐私保护，同时实现了协作聚类。该方法允许在k-means和谱聚类之间灵活选择，并通过与中央服务器的单轮通信即可获得最终结果。我们使用合成数据集和开放基准数据集进行了广泛的实验。结果表明，我们的方法实现的聚类性能与所有数据汇集在一起的集中式聚类相当。DC-Clustering通过实现从分布式异构数据中有效发现知识，解决了当前FL研究中的一个重要空白。其隐私保护、通信效率和灵活性等实用特性使其成为医疗保健和金融等隐私敏感领域的一个有前景的工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [395] [Meta-learning Representations for Learning from Multiple Annotators](https://arxiv.org/abs/2506.10259)
> *元学习表示用于从多标注者学习*

*Atsutoshi Kumagai, Tomoharu Iwata, Taishi Nishiyama, Yasutoshi Ida, Yasuhiro Fujiwara* | **Main category: cs.LG**

**Keywords:** 元学习, 多标注者, 噪声标签, 众包, 期望最大化

**Comment:** 24 pages

> **TL;DR:** 本文提出了一种元学习方法，用于从多位噪声标注者提供的有限数据中学习准确的分类器，通过利用相关任务和基于EM的适应过程。

**AI_Comments:** 该论文的创新之处在于将元学习应用于从噪声标注者数据中学习的问题，特别通过利用相关任务来解决数据稀缺性。使用可微分的EM算法进行高效的反向传播也是一个关键的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在许多应用中，如众包服务，监督学习的标签由多位标注者提供，但由于标注者技能和偏见不同，标签可能存在噪声。现有方法需要大量带噪声的标注数据来学习准确分类器，但在实践中数据可能不足。

**Method:** 本文提出一种元学习方法，利用不同但相关的任务中获得的标注数据。该方法使用神经网络将任务中的每个示例嵌入到潜在空间中，并构建一个概率模型，用于学习特定任务的分类器，同时在潜在空间中估计标注者的能力。该神经网络通过元学习来提高当分类器适应少量标注数据时的预期测试分类性能。分类器适应通过期望最大化（EM）算法最大化后验概率来执行。由于EM算法中的每一步都易于计算为闭合形式且可微分，因此该方法可以有效地通过EM算法反向传播损失以元学习神经网络。

**Result:** 该方法在具有合成噪声的真实世界数据集和真实世界众包数据集上显示出有效性。

**Conclusion:** 本文提出的元学习方法通过利用相关任务和高效的基于EM的适应过程，有效解决了从有限、有噪声的多标注者数据中学习的挑战。

> **ai_Abstract:** 本文提出了一种元学习方法，用于从多位噪声标注者提供的有限数据中学习。针对现有方法需要大量数据而实际数据不足的问题，该方法利用相关任务的数据。它通过元学习的神经网络将样本嵌入潜在空间，并构建概率模型来学习任务特定分类器并估计标注者能力。分类器适应通过可微分的EM算法实现，使得损失能高效反向传播以优化神经网络。该方法在合成噪声和真实众包数据集上均显示出有效性。

> **摘要翻译:** 我们提出了一种元学习方法，用于从多个有噪声的标注者那里学习。在许多应用中，例如众包服务，监督学习的标签由多个标注者提供。由于标注者具有不同的技能或偏见，给定的标签可能带有噪声。为了学习准确的分类器，现有方法需要大量带有噪声的标注数据。然而，在实践中可能无法获得足够的数据。为了克服数据不足的问题，所提出的方法使用了在不同但相关任务中获得的标注数据。所提出的方法通过使用神经网络将任务中的每个示例嵌入到潜在空间中，并构建一个概率模型，用于学习任务特定分类器，同时在潜在空间中估计标注者的能力。这个神经网络经过元学习，以提高当分类器适应给定少量标注数据时的预期测试分类性能。这种分类器适应通过期望最大化（EM）算法最大化后验概率来执行。由于EM算法中的每一步都可以很容易地计算为闭合形式且可微分，因此所提出的方法可以有效地通过EM算法反向传播损失以元学习神经网络。我们通过带有合成噪声的真实世界数据集和真实世界众包数据集展示了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [398] [Interior-Point Vanishing Problem in Semidefinite Relaxations for Neural Network Verification](https://arxiv.org/abs/2506.10269)
> *神经网络验证中半定松弛的内点消失问题*

*Ryota Ueda, Takami Sato, Ken Kobayashi, Kazuhide Nakata* | **Main category: cs.LG**

**Keywords:** 神经网络验证, 半定规划, 内点消失, 严格可行性, 深度学习

**Comment:** 17 pages, 2 figures. Version revised after ICML 2025 reviews

> **TL;DR:** 半定规划 (SDP) 松弛在深度神经网络验证中存在内点消失问题，导致严格可行性丧失，难以扩展。本文提出了五种解决方案，显著提高了问题解决率，并发现传统 ReLU 约束可能有害。

**AI_Comments:** 这项工作识别并解决了基于 SDP 的神经网络验证中一个关键的、此前未被充分认识到的“内点消失”问题，这对于该方法的数值稳定性和扩展性至关重要。其创新点在于不仅指出了问题，还提供了具体的解决方案，并且挑战了传统上对 ReLU 单元约束的认识。这项研究对于推动深度神经网络验证的实用性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 半定规划 (SDP) 松弛是神经网络验证的一种有前景的方法，但当应用于深度网络时，会遇到内点消失问题，导致严格可行性丧失，从而影响数值稳定性和最优性，并成为基于 SDP 的验证方法扩展到更深网络的根本障碍。

**Method:** 通过严格的理论和实证分析，研究了内点消失问题，并设计和研究了五种解决方案来增强验证问题的可行性条件。此外，还分析了传统上继承的 ReLU 单元上下界约束，发现它们对问题可行性有害。

**Result:** 所提出的方法成功解决了现有方法无法解决的 88% 的问题（占总数的 41%）。分析还揭示，传统上用于 ReLU 单元的上下界约束不仅无益，甚至对问题的可行性有害。

**Conclusion:** 本研究深入探讨了基于 SDP 的深度神经网络验证的根本挑战，并提供了实用的解决方案来提高其对更深神经网络的适用性，从而有助于开发更可靠、更安全的深度神经网络系统。

> **ai_Abstract:** 本研究关注神经网络验证中半定规划 (SDP) 松弛的内点消失问题，该问题导致深度神经网络验证时严格可行性丧失，影响数值稳定性和可扩展性。通过理论和实证分析，作者提出了五种增强可行性的解决方案，成功解决了现有方法无法解决的多数问题。研究还发现，传统的 ReLU 单元上下界约束实际上可能对问题可行性有害。这项工作为 SDP-based DNN 验证提供了新见解和实用改进方案。

> **摘要翻译:** 半定规划 (SDP) 松弛已成为神经网络验证的一种有前景的方法，与用于 ReLU 激活的深度神经网络 (DNN) 的其他凸松弛方法相比，它提供了更紧密的边界。然而，我们发现 SDP 松弛应用于深度网络时存在一个关键限制：内点消失，这导致严格可行性的丧失——这是 SDP 数值稳定性和最优性的关键条件。通过严格的理论和实证分析，我们证明了随着 DNN 深度增加，严格可行性很可能丧失，这为基于 SDP 的验证的扩展制造了根本障碍。为了解决内点消失问题，我们设计并研究了五种解决方案以增强验证问题的可行性条件。我们的方法成功解决了现有方法无法解决的 88% 的问题，占总数的 41%。我们的分析还揭示，传统上为每个 ReLU 单元设置的上下界有效约束是从先前工作中继承而来，没有充分的理由，但实际上不仅无益，甚至对问题的可行性有害。这项工作为基于 SDP 的 DNN 验证的根本挑战提供了宝贵的见解，并提供了实用的解决方案以提高其对更深神经网络的适用性，从而有助于开发更可靠和安全的 DNN 系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [401] [Can We Infer Confidential Properties of Training Data from LLMs?](https://arxiv.org/abs/2506.10364)
> *我们能否从大型语言模型中推断出训练数据的机密属性？*

*Penguin Huang, Chhavi Yadav, Ruihan Wu, Kamalika Chaudhuri* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 属性推断, 数据隐私, 漏洞, 微调

**Comment:** 

> **TL;DR:** 大型语言模型在敏感数据上微调后，可能泄露训练数据的机密属性。本文介绍了PropInfer基准测试和两种攻击方法，揭示了LLM的这一漏洞。

**AI_Comments:** 这篇论文解决了LLM在敏感领域部署时一个关键的隐私问题。引入专用基准（PropInfer）和定制攻击是创新且重要的，有助于理解和缓解数据泄露风险。发现“以前未被识别的漏洞”凸显了这项研究的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）越来越多地在包含敏感和机密数据集级属性的特定领域数据集上进行微调。然而，目前尚不清楚针对判别模型和生成模型的属性推断攻击是否也适用于LLM，这引发了对LLM泄露机密训练数据属性的担忧。

**Method:** 本文引入了PropInfer，一个用于评估LLM在问答和聊天补全两种微调范式下属性推断的基准任务。该基准基于ChatDoctor数据集构建，涵盖多种属性类型和任务配置。此外，本文提出了两种定制攻击：一种是基于提示的生成攻击，另一种是利用词频信号的影子模型攻击。

**Result:** 对多个预训练LLM的实证评估表明，本文提出的攻击取得了成功，揭示了LLM中一个以前未被识别的漏洞。

**Conclusion:** 大型语言模型容易受到属性推断攻击，其训练数据中的机密属性可以被推断出来。

> **ai_Abstract:** 本文研究了能否从在敏感领域特定数据集上微调的大型语言模型（LLM）中推断出训练数据的机密属性。为此，论文引入了PropInfer，一个基于ChatDoctor数据集构建的基准测试，用于评估问答和聊天补全范式下的属性推断。论文提出了两种新的攻击方法：一种是基于提示的生成攻击，另一种是影子模型攻击。实证结果证明了这些攻击的成功性，揭示了LLM在敏感训练数据属性泄露方面存在的新漏洞。

> **摘要翻译:** 大型语言模型（LLM）越来越多地在特定领域的数据集上进行微调，以支持医疗、金融和法律等领域的应用。这些微调数据集通常具有敏感和机密的数据集级属性——例如患者人口统计数据或疾病流行率——这些属性不打算被泄露。虽然先前的工作已经研究了对判别模型（例如图像分类模型）和生成模型（例如图像数据的GAN）的属性推断攻击，但尚不清楚此类攻击是否适用于LLM。在这项工作中，我们引入了PropInfer，一个用于评估LLM在两种微调范式下（问答和聊天补全）属性推断的基准任务。我们的基准基于ChatDoctor数据集构建，包含一系列属性类型和任务配置。我们进一步提出了两种定制的攻击：一种基于提示的生成攻击和一种利用词频信号的影子模型攻击。对多个预训练LLM的实证评估显示了我们攻击的成功，揭示了LLM中一个以前未被识别的漏洞。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [403] [Graph-MLLM: Harnessing Multimodal Large Language Models for Multimodal Graph Learning](https://arxiv.org/abs/2506.10282)
> *Graph-MLLM：利用多模态大语言模型进行多模态图学习*

*Jiajin Liu, Dongzhe Fan, Jiacheng Shen, Chuanhao Ji, Daochen Zha, Qiaoyu Tan* | **Main category: cs.LG**

**Keywords:** 多模态图学习, 多模态大语言模型, 基准测试, 图神经网络, 模态对齐

**Comment:** 16 pages, 4 figures

> **TL;DR:** 本文提出了Graph-MLLM，一个用于多模态图学习的综合基准，旨在解决现有MLLM忽略图结构以及MMG领域缺乏统一评估标准的问题。通过系统评估MLLM作为编码器、对齐器和预测器的三种范式，研究发现联合考虑视觉和文本属性、将视觉属性转换为文本描述，以及对MLLM进行微调能有效提升性能。

**AI_Comments:** 这篇论文通过引入Graph-MLLM基准，填补了多模态图学习领域在公平评估方面的空白，具有重要的实践意义。其创新之处在于系统性地对比了MLLM在MMG中的三种应用范式，并提出了有价值的性能提升策略，如视觉到文本的转换和MLLM微调，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大语言模型（MLLMs）通常侧重于成对模态对齐，忽略了数据点之间的结构关系。将多模态与结构化图信息（多模态图，MMGs）整合对于现实世界应用至关重要。然而，现有MMG学习方法缺乏统一的基准来公平评估不同方法，导致进展不明确。

**Method:** 本文提出了Graph-MLLM，一个针对多模态图学习的综合基准。该基准系统评估了基于MLLM的三种范式：MLLM-as-Encoder、MLLM-as-Aligner和MLLM-as-Predictor，并在六个不同领域的数据集上进行了广泛实验。

**Result:** 1. 联合考虑节点的视觉和文本属性有利于图学习，即使使用预训练的文本到图像对齐模型（如CLIP）作为编码器。2. 将视觉属性转换为文本描述比直接使用视觉输入能进一步提高性能。3. 在特定MMG上对MLLM进行微调，即使没有明确的图结构信息，也能在大多数场景中达到最先进的结果。

**Conclusion:** Graph-MLLM基准及其发现促进了多模态图学习领域的快速、公平评估，并有望激发该领域进一步的创新研究。

> **ai_Abstract:** 本文提出了Graph-MLLM，一个用于多模态图学习的综合基准，旨在解决现有MLLM忽略图结构以及MMG领域缺乏统一评估标准的问题。该基准系统评估了MLLM作为编码器、对齐器和预测器的三种范式在六个数据集上的表现。研究发现，联合考虑视觉和文本属性、将视觉属性转换为文本描述，以及对MLLM进行微调，都能有效提升多模态图学习的性能，甚至在缺乏明确图结构时也能达到SOTA结果。该开源库旨在促进公平评估和未来研究。

> **摘要翻译:** 多模态大语言模型（MLLMs）在表示和理解不同模态方面展现出卓越能力。然而，它们通常侧重于成对的模态对齐，而忽略了数据点之间的结构关系。将多模态与结构化图信息（即多模态图，MMGs）整合对于社交网络、医疗保健和推荐系统等现实应用至关重要。现有的MMG学习方法根据其利用MLLM的方式分为三种范式：编码器、对齐器和预测器。MLLM-as-Encoder 侧重于通过多模态特征融合增强图神经网络（GNNs）；MLLM-as-Aligner 在语言或隐藏空间中对齐多模态属性，以实现基于LLM的图推理；MLLM-as-Predictor 将MLLMs视为独立的推理器，通过上下文学习或微调进行操作。尽管取得了进展，MMG领域缺乏一个统一的基准来公平评估这些方法，使得进展不明确。为了弥补这一差距，我们提出了Graph-MLLM，这是一个针对多模态图学习的综合基准，通过系统地评估这三种范式在六个不同领域的数据集上的表现。通过大量实验，我们观察到联合考虑节点的视觉和文本属性有利于图学习，即使使用预训练的文本到图像对齐模型（例如CLIP）作为编码器。我们还发现，将视觉属性转换为文本描述比直接使用视觉输入能进一步提高性能。此外，我们观察到在特定MMG上对MLLM进行微调，即使没有明确的图结构信息，也能在大多数场景中达到最先进的结果。我们希望我们的开源库将促进快速、公平的评估，并激发该领域进一步的创新研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [408] [Collaborative Min-Max Regret in Grouped Multi-Armed Bandits](https://arxiv.org/abs/2506.10313)
> *分组多臂老虎机中的协作最小-最大遗憾*

*Moïse Blanchard, Vineet Goyal* | **Main category: cs.LG**

**Keywords:** 多臂老虎机, 协作学习, 最小-最大遗憾, 分组设置, 探索-利用

**Comment:** 

> **TL;DR:** 本文研究了在分组多臂老虎机中共享探索的影响，提出了Col-UCB算法，该算法在协作遗憾方面实现了最优性能，并揭示了协作的益处。

**AI_Comments:** 这篇论文的创新点在于提出了Col-UCB算法来解决分组多臂老虎机中探索成本不平衡的问题，并以最小-最大遗憾为目标。其重要性在于提供了一种理论上最优的方法来平衡各组的探索负担，并提供了关于协作何时能带来显著收益的见解。

<details>
  <summary>Details</summary>

**Motivation:** 在分组多臂老虎机设置中，标准算法可能导致各组之间探索成本的显著不平衡，目标是平衡各组之间的探索负担，并最小化协作遗憾（定义为各组中的最大遗憾）。

**Method:** 引入了Col-UCB算法，该算法动态协调各组之间的探索。该算法通过共享奖励观测来解决问题。

**Result:** Col-UCB算法实现了最优的最小-最大和依赖于实例的协作遗憾，误差仅为对数因子。这些界限适应于各组之间共享行动集的结构。

**Conclusion:** 协作探索在分组多臂老虎机中可以带来显著益处，Col-UCB算法能够有效地平衡各组间的探索负担并达到最优性能，尤其是在共享行动集结构下。

> **ai_Abstract:** 本文研究了在具有重叠可行行动集的分组多臂老虎机中共享探索的问题。为解决标准算法可能导致的探索成本不平衡问题，提出了Col-UCB算法。该算法通过动态协调各组间的探索，旨在最小化协作遗憾（即各组中的最大遗憾）。研究结果表明，Col-UCB在协作遗憾方面达到了最优的最小-最大和依赖于实例的性能，且误差仅为对数因子。这些发现还揭示了在不同共享行动集结构下，协作如何比独立学习带来显著优势。

> **摘要翻译:** 我们研究了在分组设置中多臂老虎机共享探索的影响，其中一组组具有重叠的可行行动集[Baek and Farias '24]。在这种分组老虎机设置中，各组共享奖励观测，目标是最小化协作遗憾，协作遗憾定义为各组中的最大遗憾。这自然地捕捉了旨在平衡各组或人群之间探索负担的应用——已知标准算法可能导致各组之间探索成本的显著不平衡。我们通过引入一种动态协调各组之间探索的算法Col-UCB来解决这个问题。我们表明Col-UCB实现了最优的最小-最大和依赖于实例的协作遗憾，误差仅为对数因子。这些界限适应于各组之间共享行动集的结构，提供了关于何时协作比各组独立学习其最佳行动产生显著益处的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [412] [Detecting Sockpuppetry on Wikipedia Using Meta-Learning](https://arxiv.org/abs/2506.10314)
> *使用元学习检测维基百科上的傀儡账户*

*Luc Raszewski, Christine De Kock* | **Main category: cs.LG**

**Keywords:** 傀儡账户检测, 元学习, 维基百科, 虚假信息, 机器学习

**Comment:** Accepted to ACL 2025

> **TL;DR:** 本文提出使用元学习来更有效地检测维基百科上的傀儡账户，尤其是在数据稀缺的情况下，并展示了其优于传统方法的预测精度。

**AI_Comments:** 该论文的创新点在于首次将元学习应用于维基百科傀儡账户检测，解决了传统方法在数据稀缺和适应性方面的局限。其重要性在于提升了打击网络虚假信息的能力，并为元学习在社会安全领域的应用提供了新的视角。发布新数据集也对后续研究具有积极推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 恶意傀儡账户检测对于维护互联网上可靠信息的访问和防止虚假信息传播至关重要。现有的机器学习方法依赖于风格和元数据特征，但在适应特定作者行为方面存在不足，导致在文本数据有限时难以有效建模特定傀儡群体的行为。

**Method:** 本文提出应用元学习，这是一种通过在多个任务上训练模型来提高数据稀缺环境下性能的机器学习技术。元学习优化模型以快速适应新的傀儡群体的写作风格。

**Result:** 结果表明，与预训练模型相比，元学习显著提高了预测的精度。

**Conclusion:** 元学习为打击开放编辑平台上的傀儡账户提供了一个显著的进步。此外，该研究发布了一个新的傀儡账户调查数据集，以促进未来在傀儡账户和元学习领域的研究。

> **ai_Abstract:** 本文提出了一种利用元学习检测维基百科上恶意傀儡账户的新方法。针对传统机器学习方法在数据稀缺和适应特定傀儡群体行为方面的不足，元学习通过在多任务上训练模型，使其能够快速适应新傀儡群体的写作风格。实验结果表明，元学习显著提高了傀儡账户检测的预测精度。此外，研究还发布了一个新的傀儡账户调查数据集，以促进相关领域的未来研究。

> **摘要翻译:** 恶意傀儡账户检测对于维护互联网上可靠信息的访问和防止虚假信息传播至关重要。先前的机器学习方法依赖于风格和元数据特征，但并未优先考虑对特定作者行为的适应性。因此，它们难以有效建模特定傀儡群体的行为，尤其是在文本数据有限时。为了解决这个问题，我们提出了元学习的应用，这是一种旨在通过在多个任务上训练模型来提高数据稀缺环境下性能的机器学习技术。元学习优化模型以快速适应新的傀儡群体的写作风格。我们的结果表明，与预训练模型相比，元学习显著提高了预测的精度，标志着在打击开放编辑平台上的傀儡账户方面取得了进展。我们发布了一个新的傀儡账户调查数据集，以促进未来在傀儡账户和元学习领域的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [416] [PyLO: Towards Accessible Learned Optimizers in PyTorch](https://arxiv.org/abs/2506.10315)
> *PyLO：在PyTorch中实现可访问的学习型优化器*

*Paul Janson, Benjamin Therien, Quentin Anthony, Xiaolong Huang, Abhinav Moudgil, Eugene Belilovsky* | **Main category: cs.LG**

**Keywords:** 学习型优化器, PyTorch, 优化, 大规模预训练, PyLO

**Comment:** Accepted at ICML CODEML Workshop 2025

> **TL;DR:** PyLO是一个PyTorch库，旨在使学习型优化器更易于访问和应用于大规模预训练任务，并提供了显著的速度提升。

**AI_Comments:** PyLO的创新之处在于它将先进的学习型优化器引入到更主流的PyTorch生态系统中，降低了其使用门槛。通过提供CUDA加速版本并专注于实际大规模任务，它解决了现有研究的局限性，并有望加速学习型优化器在实际应用中的普及。其与现有优化工具的兼容性也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型优化器（如VeLO）因依赖JAX且缺乏用户友好的包而在更广泛的社区中难以使用；之前的研究多集中在合成或凸任务，而非实际大规模预训练任务。

**Method:** 引入PyLO，一个基于PyTorch的库，提供用户友好的工作流程。发布了CUDA加速版的small_fc_lopt架构，并展示了如何将学习型优化器与现有优化工具（如学习率调度和权重衰减）结合。

**Result:** PyLO将ViT B/16（批大小32）的训练吞吐量从39.36提升到205.59样本/秒，实现了显著的加速。发现学习型优化器与现有优化工具结合时能获得显著益处。

**Conclusion:** PyLO通过提供一个PyTorch库，使学习型优化器更易于访问和应用于实际大规模预训练任务，并展示了其潜在的速度优势和与现有工具结合的益处。

> **ai_Abstract:** PyLO是一个新的PyTorch库，旨在解决学习型优化器（如VeLO）因依赖JAX和缺乏用户友好工具而难以广泛应用的问题。它专注于将学习型优化应用于实际大规模预训练任务，并提供了一个CUDA加速版的small_fc_lopt优化器，显著提升了训练速度（例如，ViT B/16训练吞吐量从39.36增至205.59样本/秒）。PyLO还支持学习型优化器与现有优化工具（如学习率调度和权重衰减）结合使用，并证明了这种结合的益处。

> **摘要翻译:** 学习型优化器在过去十年中一直是一个活跃的研究课题，在实用、通用优化器方面取得了越来越多的进展，这些优化器可以作为Adam等广泛使用方法的直接替代品。然而，最近的进展——例如VeLO，它经过4000 TPU-月的元训练——在很大程度上仍无法被更广泛的社区所访问，部分原因是它们依赖JAX，以及元训练后缺乏用于应用优化器的用户友好型软件包。为了解决这一差距，我们引入了PyLO，一个基于PyTorch的库，通过熟悉且广泛采用的工作流程，将学习型优化器带给更广泛的机器学习社区。与之前专注于合成或凸任务的工作不同，我们的重点是将学习型优化应用于实际的大规模预训练任务。我们的发布包括(Metz et al., 2022a)中small_fc_lopt学习型优化器架构的CUDA加速版本，为ViT B/16（批大小32）的训练提供了显著的速度提升——吞吐量从39.36样本/秒提高到205.59样本/秒。PyLO还允许我们轻松地将学习型优化器与现有优化工具（如学习率调度和权重衰减）结合。在这样做时，我们发现学习型优化器可以从中受益匪然。我们的代码可在https://github.com/Belilovsky-Lab/pylo获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [419] [Air in Your Neighborhood: Fine-Grained AQI Forecasting Using Mobile Sensor Data](https://arxiv.org/abs/2506.10332)
> *您社区的空气：使用移动传感器数据进行细粒度AQI预测*

*Aaryam Sharma* | **Main category: cs.LG**

**Keywords:** 空气质量指数, AQI预测, 细粒度, 移动传感器, 时空GNN

**Comment:** 10 pages, 7 figures. Code available at
  https://github.com/ASChampOmega/AQI_Forecasting.git

> **TL;DR:** 该论文使用时空GNNs预测1平方公里邻域的细粒度AQI，显著优于现有方法并发现新的AQI模式。

**AI_Comments:** 该论文的创新之处在于利用时空GNNs实现细粒度AQI预测，显著提升了预测精度，并在解决传感器稀疏性带来的局限性方面取得了重要进展。其发现的AQI新模式也具有重要的研究价值。代码开源也方便了后续研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的政府发布的AQI数据由于传感器稀疏性，无法捕捉到当地真实的空气污染情况，这在发展中国家是一个重要的健康风险。

**Method:** 使用时空GNN（Spatio-temporal GNNs）模型，并利用AirDelhi数据集，预测1平方公里邻域的AQI。

**Result:** 模型在MSE上超越现有工作71.654，实现79%的降低，即使在未见的坐标上也能保持效果。同时发现了AQI存在强烈的重复短期模式和变化的空间关系。

**Conclusion:** 该研究通过使用时空GNNs，成功实现了细粒度AQI预测，显著提升了预测精度，并揭示了AQI的新特性，为解决空气污染问题提供了更精细的解决方案。

> **ai_Abstract:** 本论文针对现有AQI数据因传感器稀疏性无法反映局部真实情况的问题，提出了一种基于时空GNNs的细粒度AQI预测方法。该方法以AirDelhi数据集为例，成功预测了1平方公里邻域的AQI，并在均方误差（MSE）上实现了79%的显著降低，甚至在未见区域也表现出色。研究还揭示了AQI的短期重复模式和动态空间关系等新特性，为更精确的空气质量监测提供了有效途径。

> **摘要翻译:** 空气污染已成为发展中国家面临的重大健康风险。尽管政府定期发布空气质量指数 (AQI) 数据来追踪污染，但由于传感器通常非常稀疏，这些数值未能捕捉到当地的真实情况。在本文中，我们以AirDelhi数据集为例，通过预测1平方公里邻域的AQI来解决这一差距。我们使用时空GNN（Spatio-temporal GNNs）模型，在MSE上超越现有工作71.654，实现了79%的降低，即使在未见的坐标上也能保持效果。此外，还发现了关于AQI的新见解，例如存在强烈的重复短期模式和变化的空间关系。代码已在GitHub上提供。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [420] [Provably Learning from Language Feedback](https://arxiv.org/abs/2506.10341)
> *可证明地从语言反馈中学习*

*Wanqiao Xu, Allen Nie, Ruijie Zheng, Aditya Modi, Adith Swaminathan, Ching-An Cheng* | **Main category: cs.LG**

**Keywords:** 语言反馈, 交互式学习, 迁移规避维度, LLM代理, 可证明学习

**Comment:** 

> **TL;DR:** 本文正式化了从语言反馈中学习（LLF）问题，引入了“迁移规避维度”作为衡量复杂度的指标，并开发了一种名为HELiX的无悔算法，该算法能够可证明地解决LLF问题，且在经验领域表现良好。

**AI_Comments:** 该论文的创新之处在于其对从语言反馈中学习（LLF）这一领域进行了首次原则性形式化，引入了“迁移规避维度”这一新颖的复杂度度量，并提供了一种具有理论保证的算法（HELiX）。这为利用语言反馈实现指数级学习加速提供了坚实的基础，推动了交互式学习算法向更鲁棒和可解释的方向发展。

<details>
  <summary>Details</summary>

**Motivation:** 由大型语言模型（LLM）代理的出现推动，从观察和语言反馈中进行交互式学习是一个日益受到关注的领域。尽管已经展示了令人印象深刻的经验性成果，但到目前为止，这些决策问题仍然缺乏一个原则性的框架。

**Method:** 本文正式化了从语言反馈中学习（LLF）问题，提出了在潜在奖励下实现学习的充分假设，并引入“迁移规避维度”作为衡量LLF问题难度的复杂度度量。研究开发了一种名为HELiX的无悔算法，通过顺序交互可证明地解决LLF问题。

**Result:** 研究表明，迁移规避维度捕获了反馈信息改变LLF问题学习复杂度的直觉。从丰富的语言反馈中学习可以比从奖励中学习快指数级。HELiX在多个经验领域表现良好，即使重复提示LLM不可靠时也能奏效。

**Conclusion:** 本文的贡献标志着设计从通用语言反馈中进行原则性交互式学习算法的第一步，通过对LLF问题进行形式化，引入新的复杂度度量，并开发出一种具有性能保证的可证明算法。

> **ai_Abstract:** 本文针对从语言反馈中学习（LLF）领域缺乏原则性框架的问题，正式化了LLF问题，引入了“迁移规避维度”作为衡量学习复杂度的指标，并证明了语言反馈能够显著加速学习。研究提出了一种名为HELiX的无悔算法，该算法能够可证明地解决LLF问题，并在实际应用中展现出稳健的性能，即使在LLM重复提示不可靠的情况下也能有效工作。

> **摘要翻译:** 通过观察和语言反馈进行交互式学习是一个日益受到关注的领域，这得益于大型语言模型（LLM）代理的兴起。尽管已经展示了令人印象深刻的经验性演示，但到目前为止，这些决策问题仍然缺乏一个原则性的框架。在本文中，我们正式化了从语言反馈中学习（LLF）问题，提出了在潜在奖励下实现学习的充分假设，并引入“迁移规避维度”作为衡量LLF问题难度的复杂度度量。我们表明，迁移规避维度捕捉了反馈中的信息改变LLF问题学习复杂度的直觉。我们展示了一些案例，其中从丰富的语言反馈中学习可以比从奖励中学习快指数级。我们开发了一种名为HELiX的无悔算法，通过顺序交互可证明地解决LLF问题，其性能保证与问题的迁移规避维度成比例。在多个经验领域，我们表明HELiX即使在重复提示LLM不可靠时也能表现良好。我们的贡献标志着设计从通用语言反馈中进行原则性交互式学习算法的第一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [421] [PhysioWave: A Multi-Scale Wavelet-Transformer for Physiological Signal Representation](https://arxiv.org/abs/2506.10351)
> *PhysioWave：一种用于生理信号表示的多尺度小波变换器*

*Yanlong Chen, Mattia Orlandi, Pierangelo Maria Rapa, Simone Benatti, Luca Benini, Yawei Li* | **Main category: cs.LG**

**Keywords:** 生理信号, 小波变换, Transformer, 多模态融合, 预训练模型

**Comment:** 22 pages, 8 figures, 9 tables. Submitted to NeurIPS 2025

> **TL;DR:** PhysioWave提出了一种基于小波的Transformer模型，用于解决生理信号的表示和分析挑战，通过预训练模型和多模态融合在EMG、ECG和EEG任务中取得了优异性能。

**AI_Comments:** 该论文的创新点在于结合了小波变换和Transformer架构，有效处理了生理信号的非平稳性和噪声问题，并通过大规模预训练模型和多模态融合提升了通用性和鲁棒性。其提出的统一多模态框架在生物医学信号处理领域具有重要意义，有望推动可穿戴设备和临床诊断技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 生理信号常受运动伪影、基线漂移和低信噪比干扰，且具有强非平稳性、尖峰和突变，传统方法难以有效表示和分析。

**Method:** 提出PhysioWave，一种新颖的基于小波的方法，旨在捕获生理信号的多尺度时频特征。利用此技术，首次引入了针对EMG和ECG的两个大规模预训练模型。此外，通过整合预训练的EEG模型，构建了一个统一的多模态框架，每个模态通过专用分支引导，并通过可学习加权融合。

**Result:** 在下游任务中实现了卓越性能并设定了新基线。在多模态任务上优于现有方法，有效解决了低信噪比、高受试者间变异性和设备不匹配等挑战。

**Conclusion:** 所提出的基于小波的架构为分析多样生理信号奠定了坚实基础，而多模态设计则预示着下一代生理信号处理，对可穿戴健康监测、临床诊断和更广泛的生物医学应用具有潜在影响。

> **ai_Abstract:** PhysioWave提出了一种创新的多尺度小波Transformer模型，旨在解决生理信号因噪声、非平稳性导致的表示和分析难题。该方法通过捕获多尺度时频特征，并首次引入了针对EMG和ECG的大规模预训练模型。此外，它构建了一个统一的多模态框架，通过可学习的加权融合集成多种生理信号，有效提升了在单模态和多模态任务上的性能，为未来的可穿戴健康监测和临床诊断提供了新范式。

> **摘要翻译:** 生理信号常受到运动伪影、基线漂移和其他低信噪比干扰的影响，这给分析带来了重大挑战。此外，这些信号表现出强烈的非平稳性，具有不断演变的尖峰和突然变化，这使得使用传统的时域或滤波方法难以表示它们。为了解决这些问题，本文提出了一种新颖的基于小波的生理信号分析方法，旨在捕获各种生理信号中的多尺度时频特征。利用这项技术，首次引入了两个针对EMG和ECG的大规模预训练模型，在下游任务中取得了卓越的性能并设定了新的基线。此外，通过整合预训练的EEG模型，构建了一个统一的多模态框架，其中每个模态通过其专用分支引导，并通过可学习的加权融合进行融合。这种设计有效地解决了低信噪比、高受试者间变异性和设备不匹配等挑战，在多模态任务上优于现有方法。所提出的基于小波的架构为分析多样生理信号奠定了坚实的基础，而多模态设计则预示着下一代生理信号处理，对可穿戴健康监测、临床诊断和更广泛的生物医学应用具有潜在影响。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [425] [History-Aware Neural Operator: Robust Data-Driven Constitutive Modeling of Path-Dependent Materials](https://arxiv.org/abs/2506.10352)
> *历史感知神经算子：路径依赖材料的鲁棒数据驱动本构建模*

*Binyao Guo, Zihan Lin, QiZhi He* | **Main category: cs.LG**

**Keywords:** 历史感知神经算子, 路径依赖材料, 数据驱动建模, 本构建模, 神经算子

**Comment:** 

> **TL;DR:** HANO是一种新型的神经网络算子，用于对路径依赖性材料进行数据驱动建模。它通过利用短期应变-应力历史来预测材料响应，克服了传统循环神经网络（RNN）模型中常见的自洽性问题和对初始隐藏状态的敏感性，并在各种复杂条件下表现出卓越的鲁棒性和准确性。

**AI_Comments:** HANO的创新性在于其独特的自回归架构，它通过直接利用短期历史数据而非隐藏状态来预测材料响应，有效解决了传统RNN在处理路径依赖材料时面临的自洽性和初始状态敏感性问题。其基于傅里叶神经算子的离散化不变学习能力以及分层自注意力机制实现的多尺度特征提取，显著提升了模型的鲁棒性和泛化能力。这项工作为复杂材料的本构建模提供了一个强大的数据驱动工具，具有重要的工程应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于循环神经网络（RNN）的路径依赖材料建模方法存在自洽性问题和对初始隐藏状态的敏感性，导致模型不稳定且泛化能力差。本研究旨在开发一种更鲁棒、端到端的数据驱动框架来解决这些挑战。

**Method:** 本研究提出了历史感知神经算子（HANO），这是一种自回归模型，能够从短期应变-应力历史片段中预测路径依赖材料响应，而无需依赖隐藏状态变量。HANO以傅里叶基神经算子为骨干，实现了离散化不变学习。为了捕获全局加载模式和关键局部路径依赖性，HANO嵌入了分层自注意力机制以促进多尺度特征提取。它将应力-应变演化建模为连续算子，而非固定的输入-输出映射。

**Result:** HANO在两个基准问题上（含硬化的弹塑性和脆性固体中的渐进各向异性损伤）进行了评估。结果表明，HANO在预测精度、泛化能力和鲁棒性方面始终优于基线模型。它在复杂条件下（包括不规则采样、多循环加载、噪声数据和预应力状态）表现出鲁棒性能。

**Conclusion:** HANO为模拟非弹性材料提供了一种有效的数据驱动替代方案，并且非常适合与经典的数值求解器集成。

> **ai_Abstract:** 本研究提出了历史感知神经算子（HANO），一个用于路径依赖非弹性材料数据驱动建模的端到端学习框架。HANO是一种自回归模型，通过从短期应变-应力历史中学习来预测材料响应，避免了传统RNN模型中常见的自洽性问题和对初始隐藏状态的敏感性。HANO基于傅里叶神经算子骨干并结合分层自注意力机制，实现了离散化不变学习和多尺度特征提取。实验结果表明，HANO在预测精度、泛化能力和鲁棒性方面均优于基线模型，并在复杂加载条件下表现出强大的性能，为非弹性材料模拟提供了一种有效且可与数值求解器集成的替代方案。

> **摘要翻译:** 本研究提出了一种用于路径依赖非弹性材料数据驱动建模的端到端学习框架，该框架使用神经算子。该框架建立在以下前提之上：材料响应的不可逆演化（由隐藏动力学控制）可以从可观测数据中推断出来。
我们开发了历史感知神经算子（HANO），这是一种自回归模型，可以从最近应变-应力历史的短期片段中预测路径依赖材料响应，而无需依赖隐藏状态变量，从而克服了循环神经网络（RNN）模型中常见的自洽性问题。HANO以傅里叶基神经算子为骨干，实现了离散化不变学习。为了增强其捕获全局加载模式和关键局部路径依赖性的能力，我们嵌入了分层自注意力机制以促进多尺度特征提取。
除了确保自洽性，HANO还减轻了对初始隐藏状态的敏感性，这是一个常被忽视的问题，可能导致循环模型在应用于广义加载路径时出现不稳定性。通过将应力-应变演化建模为连续算子，而非依赖固定的输入-输出映射，HANO自然地适应了不同的路径离散化，并在复杂条件下（包括不规则采样、多循环加载、噪声数据和预应力状态）表现出鲁棒性能。我们在两个基准问题上评估了HANO：含硬化的弹塑性和脆性固体中的渐进各向异性损伤。结果表明，HANO在预测精度、泛化能力和鲁棒性方面始终优于基线模型。凭借其已展示的能力，HANO为模拟非弹性材料提供了一种有效的数据驱动替代方案，并且非常适合与经典的数值求解器集成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [428] [TreeLoRA: Efficient Continual Learning via Layer-Wise LoRAs Guided by a Hierarchical Gradient-Similarity Tree](https://arxiv.org/abs/2506.10355)
> *TreeLoRA：通过分层梯度相似性树引导的层级LoRA实现高效持续学习*

*Yu-Yang Qian, Yuan-Ze Xu, Zhen-Yu Zhang, Peng Zhao, Zhi-Hua Zhou* | **Main category: cs.LG**

**Keywords:** 持续学习, 大型预训练模型, 低秩适配器, 梯度相似性, 效率

**Comment:** ICML 2025

> **TL;DR:** TreeLoRA提出了一种高效的持续学习方法，通过分层梯度相似性树指导的层级LoRA来适应新任务并防止灾难性遗忘，特别适用于大型预训练模型。

**AI_Comments:** TreeLoRA的创新点在于结合了低秩适配器（LoRA）与分层梯度相似性树结构，以解决大型预训练模型在持续学习中的效率问题。通过引入多臂赌博机技术来优化任务相似性估计，并采用稀疏梯度更新，进一步提升了方法对LPMs的适用性。这为处理不断增长的大模型在线学习挑战提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界应用中数据流式传输，需要持续学习来在线更新模型以适应新任务并保留旧知识，防止灾难性遗忘。对于大型预训练模型（LPMs），由于其巨大的计算需求和参数规模，持续学习的效率变得至关重要。

**Method:** 论文引入了TreeLoRA（低秩适配器K-D树），通过利用分层梯度相似性构建层级适配器，实现高效持续学习，尤其针对LPMs。为减少任务相似性估计的计算负担，采用基于下限置信区间的多臂赌博机技术高效探索任务结构。此外，使用稀疏梯度更新来优化参数，使其更适合LPMs。

**Result:** 理论分析验证了方法的合理性，在视觉Transformer (ViTs) 和大型语言模型 (LLMs) 上的实验表明，该方法在视觉和自然语言处理任务等多个领域都具有有效性和高效性。

**Conclusion:** TreeLoRA通过创新的层级LoRA和梯度相似性引导，结合高效的任务结构探索和稀疏梯度更新，为大型预训练模型提供了有效且高效的持续学习解决方案。

> **ai_Abstract:** 本文提出了TreeLoRA，一种针对大型预训练模型（LPMs）的高效持续学习方法。TreeLoRA通过构建由分层梯度相似性引导的层级低秩适配器（LoRAs）来适应新任务并防止灾难性遗忘。为提高效率，该方法利用多臂赌博机技术高效探索任务结构，并采用稀疏梯度更新。理论分析和在视觉Transformer及大型语言模型上的实验证明了其在视觉和自然语言处理任务中的有效性和高效性。

> **摘要翻译:** 许多现实世界的应用在流式环境中收集数据，学习任务是顺序遇到的。这需要持续学习（CL）在线更新模型，使其能够适应新任务，同时保留过去的知识以防止灾难性遗忘。如今，随着大型预训练模型（LPMs）的蓬勃发展，由于其巨大的计算需求和不断增长的参数规模，效率对于持续学习变得越来越关键。在本文中，我们介绍了TreeLoRA（低秩适配器K-D树），这是一种新颖的方法，通过利用分层梯度相似性构建层级适配器，以实现高效的持续学习，特别是对于LPMs。为了减少任务相似性估计的计算负担，我们采用多臂赌博机技术，开发了一种基于下限置信区间的算法，以高效探索任务结构。此外，我们使用稀疏梯度更新来促进参数优化，使该方法更适合LPMs。本文提供了理论分析来证明我们方法背后的原理，并且在视觉Transformer (ViTs) 和大型语言模型 (LLMs) 上的实验证明了我们方法在视觉和自然语言处理任务等各种领域中的有效性和高效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning](https://arxiv.org/abs/2506.10378)
> *通过因果表示学习发现语言模型的层次化潜在能力*

*Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang* | **Main category: cs.LG**

**Keywords:** 因果表示学习, 语言模型, 潜在能力, 模型评估

**Comment:** 

> **TL;DR:** 论文提出一种因果表示学习框架，通过控制基础模型混淆因素，发现语言模型的层次化潜在能力，并识别出通用问题解决、指令遵循和数学推理之间的因果链。

**AI_Comments:** 这项工作的创新之处在于利用因果表示学习超越了简单的模型排名，揭示了语言模型潜在能力的深层因果结构，这对于有针对性的模型开发具有重要指导意义。强调在评估中控制基础模型变异是一个关键的方法论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型能力的准确评估对于模型开发至关重要，但当前的因果评估面临复杂的混淆效应和高昂的计算成本。

**Method:** 提出一个因果表示学习框架，将观察到的基准性能建模为少数潜在能力因素的线性变换。通过控制基础模型作为共同混淆因素，识别这些潜在因素之间的因果关系。

**Result:** 在包含1500多个模型和6个基准测试的数据集上，识别出一个简洁的三节点线性因果结构，解释了观察到的性能变化。揭示了从通用问题解决能力到指令遵循能力，再到数学推理能力的明确因果方向。

**Conclusion:** 强调在评估中仔细控制基础模型变异的重要性，这对于准确揭示潜在模型能力之间的因果关系至关重要。

> **ai_Abstract:** 本文提出一种新颖的因果表示学习框架，旨在解决语言模型能力评估中存在的混淆效应和高计算成本等挑战。该框架将观察到的基准性能建模为少数潜在能力因素的线性变换，并通过控制基础模型作为混淆因素来识别这些因素之间的因果关系。将此方法应用于包含1500多个模型的综合数据集，研究人员识别出一个简洁的三节点线性因果结构，揭示了从通用问题解决能力到指令遵循能力，再到数学推理能力的明确因果方向。研究结果强调了在评估过程中仔细控制基础模型变异对于准确揭示潜在模型能力之间因果关系的关键作用。

> **摘要翻译:** 对语言模型能力进行忠实评估对于获取可操作的洞察力至关重要，这些洞察力可以指导模型开发。然而，该领域严格的因果评估面临重大的方法论挑战，包括复杂的混淆效应和与大量再训练相关的巨大计算成本。为了解决这些挑战，我们提出了一种因果表示学习框架，其中观察到的基准性能被建模为少数潜在能力因素的线性变换。至关重要的是，在适当控制基础模型作为共同混淆因素后，这些潜在因素被识别为因果相互关联。将这种方法应用于一个包含来自Open LLM排行榜的六个基准测试中评估的1500多个模型的综合数据集，我们识别出一个简洁的三节点线性因果结构，该结构可靠地解释了观察到的性能变异。对这种因果结构的进一步解释提供了超越简单数值排名的实质性科学见解：具体来说，我们揭示了一个清晰的因果方向，从通用问题解决能力开始，通过指令遵循熟练度推进，最终达到数学推理能力。我们的结果强调了在评估过程中仔细控制基础模型变异的关键作用，这是准确揭示潜在模型能力之间因果关系的关键一步。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [435] [EQA-RM: A Generative Embodied Reward Model with Test-time Scaling](https://arxiv.org/abs/2506.10389)
> *EQA-RM：一种具有测试时可伸缩性的生成式具身奖励模型*

*Yuhang Chen, Zhen Tan, Tianlong Chen* | **Main category: cs.LG**

**Keywords:** 奖励模型, 具身问答, 生成式模型, 测试时可伸缩性, EQARewardBench

**Comment:** preprint

> **TL;DR:** EQA-RM是一种新型的生成式具身奖励模型，专为具身问答（EQA）设计，通过创新的训练策略和测试时可伸缩性，在评估具身任务方面表现出色，并优于现有基线。

**AI_Comments:** 本文的创新点在于提出了一个专门针对具身问答的生成式奖励模型EQA-RM，其独有的生成性质和测试时可伸缩性使得评估反馈更加细致和灵活。同时，引入EQARewardBench为具身奖励模型的标准化评估提供了重要工具。其在低样本量下超越了包括Gemini-2.5-Flash和GPT-4o在内的SOTA模型，展现了强大的性能和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 奖励模型（RMs）对于大型模型对齐至关重要，但在具身问答（EQA）等复杂具身任务中，其应用尚未得到充分探索。这些任务需要对智能体的空间、时间和逻辑理解进行细致评估，而通用方法未能考虑到这一点。

**Method:** 本文引入了EQA-RM，这是一种新型的生成式多模态奖励模型，专门为EQA设计，并通过创新的对比组相对策略优化（C-GRPO）策略进行训练，以学习细粒度的行为区别。EQA-RM的生成性质提供可解释的、结构化的奖励反馈，并独有地支持测试时可伸缩性，以在推理时动态调整评估粒度，无需重新训练。同时，本文还引入了EQARewardBench，一个基于OpenEQA构建的新基准，用于标准化EQA奖励模型评估。

**Result:** EQA-RM（微调Qwen2-VL-2B-Instruct）在EQA-RM-Bench上仅用700个样本就达到了61.9%的准确率，展现出高样本效率，并优于强大的专有基线模型，包括Gemini-2.5-Flash、GPT-4o、Claude-3.5-Haiku，以及开源的最新模型，如RoVRM和VisualPRM。

**Conclusion:** EQA-RM通过其生成性质和测试时可伸缩性，为复杂具身任务（如EQA）提供了细致、可解释的评估能力，显著优于现有模型，并为具身奖励模型的标准化评估提供了新基准。

> **ai_Abstract:** EQA-RM是一种新型的生成式多模态奖励模型，专门为具身问答（EQA）设计，用于解决现有奖励模型在复杂具身任务评估方面的不足。它通过对比组相对策略优化（C-GRPO）进行训练，能够提供可解释的、结构化的奖励反馈，并支持测试时动态调整评估粒度。该模型在EQARewardBench上仅用少量样本就取得了61.9%的准确率，表现优于多种强大的专有和开源基线模型，证明了其在具身任务细粒度评估中的有效性和高效率。

> **摘要翻译:** 奖励模型（RMs）对于大型模型对齐至关重要，但在具身问答（EQA）等复杂具身任务中，其应用尚未得到充分探索。这些任务需要对智能体的空间、时间和逻辑理解进行细致评估，而通用方法未能考虑到这一点。我们引入了EQA-RM，这是一种新型的生成式多模态奖励模型，专门为EQA设计，并通过我们创新的对比组相对策略优化（C-GRPO）策略进行训练，以学习细粒度的行为区别。EQA-RM的生成性质提供可解释的、结构化的奖励反馈（超越简单的标量），独有地支持测试时可伸伸缩性，以在推理时动态调整评估粒度，从简洁的分数到对推理和基础的详细评价，而无需重新训练。同时，我们引入了EQARewardBench，一个基于OpenEQA构建的新基准，用于标准化EQA奖励模型评估。EQA-RM（微调Qwen2-VL-2B-Instruct）展示了高样本效率，在仅使用700个样本的情况下，在EQA-RM-Bench上达到了61.9%的准确率，优于强大的专有基线模型，包括Gemini-2.5-Flash、GPT-4o、Claude-3.5-Haiku，以及开源的最新模型，如RoVRM和VisualPRM。代码和数据集可在此处找到：https://github.com/UNITES-Lab/EQA-RM。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [Time To Impeach LLM-as-a-Judge: Programs are the Future of Evaluation](https://arxiv.org/abs/2506.10403)
> *是时候弹劾LLM作为评判者了：程序是评估的未来*

*Tzu-Heng Huang, Harit Vishwakarma, Frederic Sala* | **Main category: cs.LG**

**Keywords:** LLM评估, 程序合成, PAJAMA, 偏见缓解, 成本效益

**Comment:** 

> **TL;DR:** PAJAMA通过使用LLM合成可执行程序而非直接评分来评估LLM生成内容，显著降低成本、提高可靠性和可解释性，并减少偏见。

**AI_Comments:** 这篇论文提出了一种创新的LLM评估范式，从直接评分转向程序合成，有效解决了传统LLM作为评判者的高成本和黑箱问题。其核心创新在于将评估逻辑编码为可执行程序，这不仅提高了透明度和可审计性，还显著降低了运行成本。该方法通过引入程序逻辑来减轻LLM固有的偏见，为LLM评估领域带来了重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM作为评判者的方法面临高API成本、不确定可靠性、不灵活的流程和固有偏见等挑战。

**Method:** 引入PAJAMA（Program-As-a-Judge for Automated Model Assessment），它使用LLM合成可执行的评判程序，这些程序可以本地存储和运行，提供可解释和可审计的评判逻辑。

**Result:** 程序评判可将判断一致性提高15.83%，并将偏见响应平均减少23.7%，与基于Qwen2.5-14B的LLM作为评判者相比。当程序判断被提炼成模型时，PAJAMA在RewardBench的CHAT-HARD子集上优于LLM作为评判者，在Prometheus上性能提高了2.19%，在JudgeLM数据集上提高了8.67%，所有这些都以低三个数量级的成本实现。

**Conclusion:** PAJAMA提供了一种更经济、更可靠、更灵活且偏见更少的LLM评估替代方案，通过程序作为评判者超越了传统的LLM作为评判者的方法。

> **ai_Abstract:** 本文提出了一种名为PAJAMA（Program-As-a-Judge for Automated Model Assessment）的新型LLM评估方法，旨在解决传统LLM作为评判者所面临的高成本、低可靠性、不灵活性和偏见等问题。PAJAMA利用LLM生成可执行的评判程序，这些程序可在本地运行，显著降低成本，并提供可解释和可审计的判断逻辑。实验结果表明，PAJAMA在提高判断一致性、减少偏见响应方面表现出色，并在特定数据集上超越了传统LLM评判方法，同时成本大幅降低。

> **摘要翻译:** 大型语言模型（LLM）被广泛用于评估LLM生成内容和响应的质量，但这导致了重大挑战：高昂的API成本、不确定的可靠性、不灵活的流程以及固有的偏见。为了解决这些问题，我们引入了PAJAMA（Program-As-a-Judge for Automated Model Assessment），这是一种新的替代方案，它使用LLM合成可执行的评判程序，而不是直接对响应进行评分。这些合成的程序可以本地存储和运行，成本降低了几个数量级，同时提供了可解释和可审计的评判逻辑，并且易于调整。基于程序的评判者减轻了偏见，与基于Qwen2.5-14B的LLM作为评判者相比，判断一致性提高了15.83%，偏见响应平均减少了23.7%。当程序判断被提炼成模型时，PAJAMA在RewardBench具有挑战性的CHAT-HARD子集上表现优于LLM作为评判者，在Prometheus上指标提高了2.19%，在JudgeLM数据集上提高了8.67%，所有这些都以低三个数量级的成本实现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [440] [Generative Algorithms for Wildfire Progression Reconstruction from Multi-Modal Satellite Active Fire Measurements and Terrain Height](https://arxiv.org/abs/2506.10404)
> *基于多模态卫星活跃火灾测量和地形高度的野火进展重建生成算法*

*Bryan Shaddy, Brianna Binder, Agnimitra Dasgupta, Haitong Qin, James Haley, Angel Farguell, Kyle Hilburn, Derek V. Mallia, Adam Kochanski, Jan Mandel, Assad Oberai* | **Main category: cs.LG**

**Keywords:** 野火进展重建, 生成对抗网络, 卫星测量, 地形高度, 数据同化

**Comment:** 

> **TL;DR:** 本研究开发了一种利用条件生成对抗网络（cGAN）从卫星活跃火灾测量和地形数据重建野火进展的方法，并在太平洋美国野火上进行了验证，取得了0.81的Sorensen-Dice系数。

**AI_Comments:** 该论文的创新点在于将条件生成对抗网络应用于野火进展重建，并通过WRF-SFIRE模拟数据进行训练，有效融合了物理模型知识。这为数据同化提供了新的思路，有助于提高野火预测的准确性。其通过近似观测算子生成训练数据的方法，避免了对真实卫星数据的直接依赖，具有一定的实用价值。然而，该方法在真实世界复杂性下的泛化能力，以及对不同区域和火灾类型的适应性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 即使最复杂的野火模型在多日模拟中也与观测到的进展存在偏差，这促使人们需要数据同化。将测量数据同化到复杂的大气-野火耦合模型中的一个有用方法是根据测量数据估计野火进展，并利用此进展来开发匹配的大气状态。

**Method:** 本研究开发了一种从VIIRS活跃火灾测量、GOES衍生的点火时间和地形高度数据估计火灾进展的方法。一个条件生成对抗网络（cGAN）使用历史野火的WRF-SFIRE模拟进行训练，从而将WRF-SFIRE物理学纳入估计中。火灾进展通过火灾到达时间来表示。训练测量数据通过对WRF-SFIRE解决方案应用近似观测算子获得。模型在火灾到达时间、测量和地形的元组上进行训练，然后利用真实火灾的测量和相应的地形数据生成火灾到达时间样本。

**Result:** 该方法在五个太平洋美国野火上进行了验证，结果与通过飞机测量的高分辨率边界进行了比较，发现平均Sorensen-Dice系数为0.81。同时观察到，当地形高度的推断以卫星测量为条件时，地形对其影响最小。

**Conclusion:** 该研究成功开发并验证了一种基于生成算法从多模态卫星数据和地形高度重建野火进展的方法，并发现地形在有卫星测量条件下对推断的影响有限。

> **ai_Abstract:** 本研究提出一种利用条件生成对抗网络（cGAN）结合多模态卫星活跃火灾测量（VIIRS、GOES）和地形高度数据来重建野火进展的方法。该cGAN通过WRF-SFIRE模型模拟的历史野火数据进行训练，以学习野火物理特性，并以火灾到达时间表示火灾进展。模型在真实野火数据上进行了验证，对五个太平洋美国野火的重建结果与高分辨率飞机测量边界的平均Sorensen-Dice系数为0.81。研究还发现，当地形推断以卫星测量为条件时，地形高度的影响最小。

> **摘要翻译:** 野火发生频率的增加激发了人们对野火蔓延预测日益增长的兴趣。然而，即使是最复杂的野火模型在多日模拟中也与观测到的进展存在偏差，这促使人们需要数据同化。将测量数据同化到复杂的大气-野火耦合模型中的一个有用方法是根据测量数据估计野火进展，并利用此进展来开发匹配的大气状态。在本研究中，开发了一种从VIIRS活跃火灾测量、GOES衍生的点火时间和地形高度数据估计火灾进展的方法。一个条件生成对抗网络（cGAN）使用历史野火的WRF-SFIRE模拟进行训练，从而将WRF-SFIRE物理学纳入估计中。火灾进展通过火灾到达时间来简洁地表示，并且通过对WRF-SFIRE解决方案应用近似观测算子来获得训练测量数据，从而消除了训练期间对卫星数据的需求。该模型在火灾到达时间、测量和地形的元组上进行训练，一旦训练完成，便利用真实火灾的测量和相应的地形数据生成火灾到达时间样本。该方法在五个太平洋美国野火上进行了验证，结果与通过飞机测量的高分辨率边界进行了比较，发现平均Sorensen-Dice系数为0.81。地形高度对到达时间推断的影响也进行了评估，并观察到当地形在以卫星测量为条件进行推断时，其影响最小。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [Time-IMM: A Dataset and Benchmark for Irregular Multimodal Multivariate Time Series](https://arxiv.org/abs/2506.10412)
> *Time-IMM：一个用于不规则多模态多元时间序列的数据集和基准*

*Ching Chang, Jeehyun Hwang, Yidan Shi, Haixin Wang, Wen-Chih Peng, Tien-Fu Chen, Wei Wang* | **Main category: cs.LG**

**Keywords:** 不规则时间序列, 多模态数据, 时间序列预测, 数据集, 基准

**Comment:** This paper is currently under review

> **TL;DR:** 本文介绍了Time-IMM数据集和IMM-TSF基准库，用于不规则多模态时间序列，并表明显式建模多模态可显著提高预测性能。

**AI_Comments:** 这篇论文通过关注现实世界中混乱、不规则和多模态的数据，解决了时间序列研究中的一个关键空白，而这往往被现有基准所忽视。Time-IMM和IMM-TSF的引入填补了这一空白，为未来的研究提供了宝贵的资源。显式建模多模态能提高性能的发现也具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的时间序列数据通常是不规则、多模态且混乱的，而现有基准通常假设数据是干净、规则采样和单模态的，这在研究和实际部署之间造成了显著差距。

**Method:** 引入Time-IMM数据集，旨在捕获多模态多元时间序列中由原因驱动的不规则性，包含九种不规则类型。引入IMM-TSF基准库，用于不规则多模态时间序列的预测，支持异步集成和真实评估，并包含专门的融合模块，如时间戳到文本融合和多模态融合模块，支持近期感知平均和基于注意力的集成策略。

**Result:** 经验结果表明，在不规则时间序列数据上显式建模多模态可以显著提高预测性能。

**Conclusion:** Time-IMM和IMM-TSF为在真实世界条件下推进时间序列分析奠定了基础。

> **ai_Abstract:** 本文介绍了Time-IMM，一个新颖的数据集，旨在通过提供具有不同采样率、异步模态和缺失值的不规则、多模态、多元时间序列数据，来弥合研究与现实世界时间序列应用之间的差距。它将不规则性分为九种类型。作为补充，论文提出了IMM-TSF基准库，用于此类数据的预测，其特点是包含用于异步集成的专用融合模块。经验结果表明，显式建模多模态显著提高了预测性能，为真实时间序列分析奠定了基础。

> **摘要翻译:** 现实世界应用中的时间序列数据，例如医疗保健、气候建模和金融领域的数据，通常是不规则、多模态且混乱的，具有不同的采样率、异步模态和普遍存在的缺失值。然而，现有基准通常假设数据是干净、规则采样和单模态的，这在研究和实际部署之间造成了显著差距。我们引入了Time-IMM，一个专门设计用于捕获多模态多元时间序列中由原因驱动的不规则性的数据集。Time-IMM代表了九种不同类型的时间序列不规则性，分为基于触发器、基于约束和基于伪影的机制。作为数据集的补充，我们引入了IMM-TSF，一个用于不规则多模态时间序列预测的基准库，它支持异步集成和真实评估。IMM-TSF包括专门的融合模块，例如时间戳到文本融合模块和多模态融合模块，它们支持近期感知平均和基于注意力的集成策略。经验结果表明，在不规则时间序列数据上显式建模多模态可以显著提高预测性能。Time-IMM和IMM-TSF为在真实世界条件下推进时间序列分析奠定了基础。该数据集已公开可用，网址为https://www.kaggle.com/datasets/blacksnail789521/time-imm/data，基准库可通过https://anonymous.4open.science/r/IMMTSF_NeurIPS2025访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [445] [Data-Driven Soil Organic Carbon Sampling: Integrating Spectral Clustering with Conditioned Latin Hypercube Optimization](https://arxiv.org/abs/2506.10419)
> *数据驱动的土壤有机碳采样：整合谱聚类与条件拉丁超立方优化*

*Weiying Zhao, Aleksei Unagaev, Natalia Efremova* | **Main category: cs.LG**

**Keywords:** 土壤有机碳, 谱聚类, 条件拉丁超立方采样, 采样设计, 机器学习

**Comment:** 

> **TL;DR:** 提出一种结合谱聚类和条件拉丁超立方采样的混合方法（spectral-cLHS），以提高土壤有机碳（SOC）采样的代表性，解决传统cLHS可能遗漏重要环境区域的问题，并在实际数据集中显示出更均匀的覆盖效果。

**AI_Comments:** 该论文提出了一种创新的数据驱动采样方法，通过结合谱聚类和cLHS，有效地解决了传统采样方法在捕捉环境多样性方面的局限性。其创新点在于将无监督学习技术引入采样设计，确保了对次要但重要环境区域的覆盖。这项工作对于提高土壤有机碳（SOC）预测的准确性具有重要意义，尤其是在需要平衡训练数据以优化机器学习模型性能的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 土壤有机碳（SOC）监测依赖于代表性的现场采样点选择，但现有方法如传统条件拉丁超立方采样（cLHS）可能忽视次要但重要的环境区域，导致采样代表性不足。

**Method:** 提出一种名为spectral-cLHS的混合方法。该方法首先利用谱聚类（一种无监督机器学习技术）根据多变量协变量数据将研究区域划分为K个同质区域，然后在此每个区域内应用条件拉丁超立方采样（cLHS）来选择采样点，从而确保捕获环境条件的多样性。

**Result:** 在真实的SOC测绘数据集上，spectral-cLHS方法比标准cLHS方法在协变量特征空间和空间异质性方面提供了更均匀的覆盖。

**Conclusion:** 改进的采样设计（spectral-cLHS）通过为机器学习模型提供更平衡的训练数据，有望产生更准确的土壤有机碳（SOC）预测。

> **ai_Abstract:** 本研究提出了一种名为spectral-cLHS的新型混合采样方法，旨在提高土壤有机碳（SOC）监测的代表性。该方法结合了谱聚类（用于划分同质区域）和条件拉丁超立方采样（cLHS，用于区域内采样）。与传统cLHS相比，spectral-cLHS能更均匀地覆盖协变量特征空间和空间异质性，有效解决了传统方法可能遗漏重要环境区域的局限性。这种改进的采样设计有望为机器学习模型提供更平衡的训练数据，从而提高SOC预测的准确性。

> **摘要翻译:** 土壤有机碳（SOC）监测通常依赖于根据环境协变量选择代表性的现场采样位置。我们提出了一种新颖的混合方法，该方法将谱聚类（一种无监督机器学习技术）与条件拉丁超立方采样（cLHS）相结合，以提高SOC采样的代表性。在我们的方法中，谱聚类利用多变量协变量数据将研究区域划分为K个同质区域，然后将cLHS应用于每个区域内以选择共同捕获环境条件全部多样性的采样位置。这种混合的谱聚类-cLHS方法确保即使是次要但重要的环境簇也能被采样，解决了传统cLHS可能忽略这些区域的关键局限性。我们在一个真实的SOC测绘数据集上证明，谱聚类-cLHS比标准cLHS在协变量特征空间和空间异质性方面提供了更均匀的覆盖。这种改进的采样设计有潜力通过为机器学习模型提供更平衡的训练数据，从而产生更准确的SOC预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [449] [MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices](https://arxiv.org/abs/2506.10443)
> *MNN-LLM：一种用于在移动设备上快速部署大型语言模型的通用推理引擎*

*Zhaode Wang, Jingbang Yang, Xinyu Qian, Shiwen Xing, Xiaotang Jiang, Chengfei Lv, Shengyu Zhang* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 移动设备, 推理引擎, MNN-LLM, 量化

**Comment:** 7 pages, 5 figures. Published in the Proceedings of the 6th ACM
  International Conference on Multimedia in Asia Workshops (MMAsia '24
  Workshops). The final authenticated version is available at
  https://dl.acm.org/doi/10.1145/3700410.3702126

> **TL;DR:** MNN-LLM是一个针对移动设备优化的LLM推理引擎，通过内存优化和性能提升，实现了高达8.6倍的推理速度加速。

**AI_Comments:** 该论文提出了一种创新的移动端LLM推理引擎MNN-LLM，通过结合硬件优化（如指令集、GPU特性）和软件优化（如量化、混合存储、负载均衡），有效解决了LLM在边缘设备上面临的内存和速度挑战。其显著的性能提升（高达8.6倍）表明了其在实际应用中的巨大潜力，对于推动LLM在资源受限设备上的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在推理时消耗大量计算资源导致成本高昂，边缘设备推理是一个有前景的解决方案，但面临内存使用和推理速度的挑战。

**Method:** MNN-LLM通过模型量化和DRAM-Flash混合存储来减少内存使用；根据移动CPU指令集和GPU特性重新排列权重和输入；并采用多核负载均衡、混合精度浮点运算和几何计算等策略来提高性能。

**Result:** 相比当前主流的LLM专用框架，MNN-LLM实现了高达8.6倍的速度提升。

**Conclusion:** MNN-LLM成功解决了在移动设备上部署大型语言模型所面临的内存和速度挑战，显著加速了其推理过程。

> **ai_Abstract:** MNN-LLM是一个为在移动设备上快速部署大型语言模型而设计的推理框架。它通过模型量化、DRAM-Flash混合存储来优化内存使用，并通过针对移动硬件的权重和输入排列、多核负载均衡、混合精度运算和几何计算来提升推理速度。该框架显著提高了LLM在移动设备上的推理效率，实现了高达8.6倍的速度提升。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中都表现出卓越的性能。然而，它们庞大的规模导致推理过程中大量的计算资源消耗，从而产生高昂的成本。因此，边缘设备推理提供了一个有前景的解决方案。边缘推理的主要挑战包括内存使用和推理速度。本文介绍了MNN-LLM，一个专门为加速大型语言模型在移动设备上部署而设计的框架。MNN-LLM通过模型量化和DRAM-Flash混合存储来解决LLMs的运行时特性，有效减少内存使用。它根据移动CPU指令集和GPU特性重新排列权重和输入，同时采用多核负载均衡、混合精度浮点运算和几何计算等策略来提高性能。值得注意的是，MNN-LLM比当前主流的LLM专用框架实现了高达8.6倍的速度提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [Equivariant Neural Diffusion for Molecule Generation](https://arxiv.org/abs/2506.10532)
> *分子生成的等变神经扩散*

*François Cornet, Grigory Bartosh, Mikkel N. Schmidt, Christian A. Naesseth* | **Main category: cs.LG**

**Keywords:** 等变神经扩散, 分子生成, 扩散模型, 可学习前向过程, 3D生成

**Comment:** 38th Conference on Neural Information Processing Systems (NeurIPS
  2024)

> **TL;DR:** 提出了一种新的等变神经扩散模型（END），通过可学习的前向过程在3D分子生成上表现出竞争力。

**AI_Comments:** 该论文的创新点在于引入了可学习的前向过程，这使得扩散模型在处理3D分子生成时更具灵活性和适应性，有望提升生成模型的性能。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过引入可学习的前向过程来增强现有等变扩散模型的生成建模能力，以改进3D分子生成。

**Method:** 引入了等变神经扩散（END）模型，这是一种用于3D分子生成的扩散模型，对欧几里得变换是等变的。其核心创新在于可学习的前向过程，该过程通过时间依赖和数据依赖的变换进行参数化，并且对刚体变换是等变的。

**Result:** END在标准分子生成基准测试中，无论是无条件生成还是条件生成，都与几个强大的基线模型相比表现出有竞争力的性能。

**Conclusion:** 等变神经扩散（END）模型通过其可学习的前向过程，在3D分子生成任务上取得了成功，并达到了与现有先进模型相当的性能。

> **ai_Abstract:** 本文提出了一种名为等变神经扩散（END）的新型扩散模型，用于3D分子生成。END模型的核心创新在于其可学习的前向过程，该过程对欧几里得变换是等变的，并能增强生成建模能力。实验结果表明，END在标准分子生成任务中，无论是在无条件还是条件生成方面，均达到了与现有先进模型相当的性能。

> **摘要翻译:** 我们引入了等变神经扩散（END），这是一种新颖的用于3D分子生成的扩散模型，它对欧几里得变换是等变的。与当前最先进的等变扩散模型相比，END的关键创新在于其可学习的前向过程，用于增强生成建模。前向过程不是预先指定的，而是通过一个与时间相关且与数据相关的变换进行参数化，该变换对刚体变换是等变的。通过在标准分子生成基准上进行一系列实验，我们证明了END在无条件和条件生成方面与几个强大的基线模型相比具有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [455] [Data-driven Day Ahead Market Prices Forecasting: A Focus on Short Training Set Windows](https://arxiv.org/abs/2506.10536)
> *数据驱动的日前市场价格预测：侧重于短训练集窗口*

*Vasilis Michalakopoulos, Christoforos Menos-Aikateriniadis, Elissaios Sarmas, Antonis Zakynthinos, Pavlos S. Georgilakis, Dimitris Askounis* | **Main category: cs.LG**

**Keywords:** 日前市场价格预测,机器学习,短训练窗口,LightGBM,电力市场

**Comment:** 13 pages, 10 figures

> **TL;DR:** 本研究评估了在短训练窗口下，机器学习模型预测日前电力市场（DAM）价格的性能，发现LightGBM在准确性和鲁棒性方面表现最佳，尤其适用于数据稀缺环境。

**AI_Comments:** 该论文的创新点在于专注于在数据可用性受限（短训练窗口）的条件下进行日前市场价格预测，这对于实际应用中经常面临数据稀缺或需要快速适应新市场条件的情况具有重要意义。研究明确指出了LightGBM在短训练窗口下的优越性，并强调了其在捕获季节性趋势和价格尖峰方面的能力，为能源市场的预测提供了实用的指导。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨在有限数据可用性（短历史训练窗口）的情况下，机器学习模型在预测日前电力市场（DAM）价格方面的表现，并侧重于检测季节性趋势和价格峰值。

**Method:** 研究评估了四种机器学习模型：带有前馈误差校正的LSTM（FFEC）、XGBoost、LightGBM和CatBoost。这些模型在希腊、比利时和爱尔兰三个欧洲能源市场进行了测试，使用来自ENTSO-E预测数据的特征集。训练窗口长度从7天到90天不等。

**Result:** 结果表明，LightGBM在预测准确性和鲁棒性方面始终表现最佳，尤其是在45天和60天的训练窗口下，这平衡了时间相关性和学习深度。此外，与LSTM和其他提升模型相比，LightGBM在检测季节性效应和峰值价格事件方面表现出卓越的性能。

**Conclusion:** 研究结果表明，短窗口训练方法与提升方法相结合，可以有效地支持波动性大、数据稀缺环境下的日前市场价格预测。

> **ai_Abstract:** 本研究评估了在短历史训练窗口下，机器学习模型预测日前电力市场（DAM）价格的性能，旨在检测季节性趋势和价格峰值。研究比较了LSTM-FFEC、XGBoost、LightGBM和CatBoost四种模型在三个欧洲能源市场（希腊、比利时、爱尔兰）的表现，训练窗口从7天到90天。结果显示，LightGBM在预测准确性和鲁棒性方面表现最佳，尤其是在45天和60天的训练窗口下，并且在检测季节性效应和峰值价格事件方面优于其他模型。这表明短窗口训练结合提升方法能有效支持数据稀缺环境下的DAM预测。

> **摘要翻译:** 本研究探讨了机器学习模型在使用短历史训练窗口预测日前市场（DAM）电价方面的表现，重点在于检测季节性趋势和价格峰值。我们评估了四种模型，即带有前馈误差校正的LSTM（FFEC）、XGBoost、LightGBM和CatBoost，在希腊、比利时、爱尔兰三个欧洲能源市场使用来自ENTSO-E预测数据的特征集。训练窗口长度从7天到90天不等，这使得可以在数据可用性受限的情况下评估模型的适应性。结果表明，LightGBM始终在预测准确性和鲁棒性方面取得最高表现，特别是在45天和60天的训练窗口下，这平衡了时间相关性和学习深度。此外，与LSTM和其他提升模型相比，LightGBM在检测季节性效应和峰值价格事件方面表现出卓越的性能。这些发现表明，短窗口训练方法与提升方法相结合，可以有效地支持波动性大、数据稀缺环境下的日前市场预测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [458] [Graph Neural Networks for Automatic Addition of Optimizing Components in Printed Circuit Board Schematics](https://arxiv.org/abs/2506.10577)
> *用于印刷电路板原理图自动添加优化组件的图神经网络*

*Pascal Plettenberg, André Alcalde, Bernhard Sick, Josephine M. Thomas* | **Main category: cs.LG**

**Keywords:** 图神经网络, 印刷电路板, 自动化设计, 组件优化, 节点对预测

**Comment:** 

> **TL;DR:** 本文提出了一种基于图神经网络（GNN）的方法，通过将PCB原理图表示为二分图并利用节点对预测模型，实现自动化添加优化组件，以提高电路的鲁棒性和可靠性。

**AI_Comments:** 该论文提出了一种新颖且实用的方法，将图神经网络应用于PCB设计自动化领域。其创新之处在于将PCB原理图建模为二分图，并利用GNN进行组件的自动添加。这对于解决当前电子设计领域面临的工程师短缺和效率低下问题具有重要意义。该方法有望显著缩短设计周期，降低开发成本，并提高产品质量，同时对减少电子垃圾也有潜在的积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 印刷电路板（PCB）原理图的设计和优化对高质量电子设备的开发至关重要。然而，由于熟练工程师的短缺和手动优化耗时，往往会忽略添加优化组件（如上拉电阻或去耦电容器），这导致后期开发阶段故障排除成本增加以及产品生命周期缩短，进而产生更多难以回收的电子垃圾。

**Method:** 通过将PCB原理图表示为二分图，并利用基于图神经网络（GNN）的节点对预测模型，自动化添加新组件。该方法应用于三个相关的PCB设计优化任务，并比较了多种流行GNN架构在人类专家标记的真实世界数据集上的性能。

**Result:** 图神经网络能够高精度地解决这些问题。

**Conclusion:** 该方法有望以省时、高效的方式实现PCB设计优化的自动化。

> **ai_Abstract:** 本研究提出了一种利用图神经网络（GNN）自动化向印刷电路板（PCB）原理图添加优化组件的方法。该方法将PCB原理图表示为二分图，并采用基于GNN的节点对预测模型。通过在真实世界数据集上测试，结果显示GNN能够高精度地完成优化任务，有望解决工程师短缺和手动优化耗时的问题，从而提高设计效率和电路质量。

> **摘要翻译:** 印刷电路板（PCB）原理图的设计和优化对于开发高质量电子设备至关重要。其中，一项重要任务是通过添加能够提高电路鲁棒性和可靠性的组件来优化草图，例如上拉电阻或去耦电容器。由于熟练工程师的短缺以及手动优化非常耗时，这些最佳实践常常被忽视。然而，这通常会导致后期开发阶段的故障排除成本更高，以及产品生命周期缩短，从而导致难以回收的电子垃圾量增加。在此，我们提出了一种通过将PCB原理图表示为二分图并利用基于图神经网络（GNN）的节点对预测模型来自动化向PCB原理图添加新组件的方法。我们将我们的方法应用于三个高度相关的PCB设计优化任务，并比较了几种流行GNN架构在由人类专家标记的真实世界数据集上的性能。我们表明，GNN可以高精度地解决这些问题，并证明我们的方法有潜力以省时和高效的方式自动化PCB设计优化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [462] [Non-stationary Online Learning for Curved Losses: Improved Dynamic Regret via Mixability](https://arxiv.org/abs/2506.10616)
> *弯曲损失的非平稳在线学习：通过可混合性改进动态遗憾*

*Yu-Jie Zhang, Peng Zhao, Masashi Sugiyama* | **Main category: cs.LG**

**Keywords:** 非平稳在线学习, 动态遗憾, 可混合性, 弯曲损失, 指数加权方法

**Comment:** ICML 2025

> **TL;DR:** 本文通过引入“可混合性”概念，显著改进了非平稳在线学习中针对弯曲损失的动态遗憾界限，并提供了一种更简洁的分析框架。

**AI_Comments:** 该论文通过引入“可混合性”这一新概念，为处理非平稳在线学习中的弯曲损失提供了一种创新且有效的途径。它不仅在理论上取得了更优的动态遗憾界限，而且提供了一个更简洁的分析框架，避免了传统复杂的 KKT 分析，这对于未来该领域的研究具有重要意义和启发性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管动态遗憾最小化在凸函数方面取得了显著进展，但对具有更强曲率的函数（例如平方损失或逻辑损失）的研究不足。本文旨在弥补这一空白。

**Method:** 通过利用“可混合性”（一种推广了指数凹性以有效捕捉损失曲率的属性），采用一种带有固定份额更新的指数加权方法来改进遗憾。

**Result:** 对于可混合损失，该方法实现了 $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$ 的动态遗憾，相较于 Baby 和 Wang (2021) 提出的 $\mathcal{O}(d^{10/3} T^{1/3} P_T^{2/3} \log T)$ 结果，在维度 $d$ 上有所改进。更重要的是，这种改进源于一个简单而强大的分析框架。

**Conclusion:** 通过利用可混合性，该研究为弯曲损失的非平稳在线学习提供了一个改进的动态遗憾界限和更简洁的分析框架，避免了现有工作所需的基于 Karush-Kuhn-Tucker 的分析。

> **ai_Abstract:** 本文针对非平稳在线学习中对具有强曲率的损失函数（即弯曲损失）研究不足的问题，引入了“可混合性”概念。研究表明，通过采用带有固定份额更新的指数加权方法，可以为可混合损失实现改进的动态遗憾界限 $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$，这在维度 $d$ 上优于现有最佳结果。这一突破得益于一个利用可混合性且避免复杂 KKT 分析的简洁而强大的分析框架。

> **摘要翻译:** 非平稳在线学习近年来备受关注。尽管取得了相当大的进展，但动态遗憾最小化主要集中在凸函数上，对具有更强曲率的函数（例如平方损失或逻辑损失）的探索不足。在这项工作中，我们通过展示可以利用可混合性概念（一种推广了指数凹性以有效捕捉损失曲率的属性）来大幅改进遗憾，从而解决了这一空白。令 $d$ 表示维度，$P_T$ 表示反映环境非平稳性的比较器的路径长度。我们证明，一种带有固定份额更新的指数加权方法对于可混合损失实现了 $\mathcal{O}(d T^{1/3} P_T^{2/3} \log T)$ 的动态遗憾，改进了 Baby 和 Wang (2021) 提出的最佳已知 $\mathcal{O}(d^{10/3} T^{1/3} P_T^{2/3} \log T)$ 结果在 $d$ 上的表现。更重要的是，这种改进源于一个简单而强大的分析框架，该框架利用了可混合性，避免了现有工作所需的基于 Karush-Kuhn-Tucker 的分析。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [465] [Deep Learning-Based Digitization of Overlapping ECG Images with Open-Source Python Code](https://arxiv.org/abs/2506.10617)
> *基于深度学习的重叠心电图图像数字化及开源Python代码*

*Reza Karbasi, Masoud Rahimi, Abdol-Hossein Vahabie, Hadi Moradi* | **Main category: cs.LG**

**Keywords:** ECG数字化, 深度学习, U-Net, 信号重叠, 图像分割

**Comment:** 

> **TL;DR:** 本文提出了一种基于两阶段深度学习管道的方法，用于准确数字化纸质ECG记录，特别是处理信号重叠的单导联，并在重叠和非重叠ECG样本上均优于现有基线方法。

**AI_Comments:** 该论文的创新点在于提出了一个两阶段深度学习管道，特别是专注于解决ECG图像中常见的信号重叠问题，这是一个在现有方法中常被忽视的挑战。U-Net的应用结合自定义数据增强，以及自适应网格检测模块，显著提升了数字化精度和通用性。其开源实现也增加了其潜在影响力和可复现性。该工作对于将模拟ECG记录可靠地转换为数字数据具有重要意义，有助于推动临床和研究应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在准确数字化纸质心电图（ECG）记录时面临持续挑战，尤其是在处理信号重叠的单导联方面，这是一个常见但未被充分解决的问题。

**Method:** 提出一个两阶段管道：第一阶段使用U-Net分割网络，在包含重叠信号并经过自定义数据增强的数据集上训练，以精确分离主要ECG轨迹。第二阶段利用自适应网格检测模块增强的成熟数字化技术，将二值掩码转换为时间序列信号。

**Result:** U-Net架构在精细分割任务中实现了0.87的IoU。与基线技术相比，所提出的数字化方法在非重叠信号上MSE为0.0010，Pearson相关系数(rho)为0.9644（基线分别为0.0015和0.9366）。在信号重叠样本上，该方法MSE为0.0029，rho为0.9641（基线分别为0.0178和0.8676），性能显著优于基线。

**Conclusion:** 本工作展示了一种有效策略，可显著提高数字化精度，特别是在存在信号重叠的情况下，为将模拟ECG记录可靠地转换为可分析的数字数据奠定了坚实基础，适用于当代研究和临床应用。

> **ai_Abstract:** 本研究提出一种基于深度学习的两阶段管道，用于精确数字化纸质ECG图像，尤其解决了信号重叠的挑战。第一阶段利用U-Net网络分割ECG轨迹，第二阶段将分割结果转换为时间序列信号，并引入自适应网格检测。实验证明，该方法在处理重叠和非重叠ECG数据时，性能均优于现有基线方法，显著提高了数字化精度，为ECG数据数字化提供了可靠方案。

> **摘要翻译:** 本文旨在解决纸质心电图（ECG）记录准确数字化的持续挑战，特别关注如何稳健地处理受信号重叠影响的单导联——这是现有方法中常见但未被充分解决的问题。我们提出了一个旨在克服这一限制的两阶段管道。第一阶段采用基于U-Net的分割网络，该网络在一个包含重叠信号并经过自定义数据增强的数据集上进行训练，以准确分离主要的ECG轨迹。随后的第二阶段利用成熟的数字化技术，并通过自适应网格检测模块进行增强，将这种精炼的二值掩码转换为时间序列信号，从而提高了在不同ECG格式和尺度下的通用性。我们的实验结果证明了我们方法的有效性。U-Net架构在精细分割任务中实现了0.87的IoU。至关重要的是，与一个成熟的基线技术相比，我们提出的数字化方法在非重叠和具有挑战性的重叠ECG样本上均表现出卓越的性能。对于非重叠信号，我们的方法实现了0.0010的均方误差（MSE）和0.9644的皮尔逊相关系数（rho），而基线分别为0.0015和0.9366。在具有信号重叠的样本上，我们的方法实现了0.0029的MSE和0.9641的rho，显著优于基线的0.0178和0.8676。这项工作展示了一种有效策略，可显著提高数字化精度，特别是在存在信号重叠的情况下，从而为将模拟ECG记录可靠地转换为可分析的数字数据奠定了坚实基础，适用于当代研究和临床应用。该实现已在GitHub存储库公开：https://github.com/masoudrahimi39/ECG-code。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [470] [Time Series Forecasting as Reasoning: A Slow-Thinking Approach with Reinforced LLMs](https://arxiv.org/abs/2506.10630)
> *时间序列预测即推理：一种基于强化LLM的慢思考方法*

*Yucong Luo, Yitong Zhou, Mingyue Cheng, Jiahao Wang, Daoyu Wang, Tingyue Pan, Jintao Zhang* | **Main category: cs.LG**

**Keywords:** 时间序列预测, LLMs, 强化学习, 慢思考, 多步推理

**Comment:** 

> **TL;DR:** Time-R1提出了一种两阶段强化微调框架，使LLM具备慢思考和多步推理能力，显著提升了时间序列预测性能。

**AI_Comments:** 该论文通过将LLMs的“慢思考”能力与强化学习相结合，为时间序列预测引入了一种新颖的推理范式，有效解决了传统方法的局限性。其两阶段微调框架以及为时间序列预测量身定制的多目标奖励和GRIP优化机制是重要的创新点。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列预测（TSF）方法多采用“快思考”范式，缺乏显式推理过程。新兴的慢思考大型语言模型（LLMs）虽展现出多步推理能力，但单独的提示工程存在计算成本高、隐私风险和领域特定推理能力有限等局限性。为克服这些问题，研究旨在训练LLMs发展慢思考能力并获得强大的时间序列推理技能。

**Method:** 本文提出了Time-R1，一个两阶段强化微调框架，旨在增强LLM用于时间序列预测的多步推理能力。第一阶段进行有监督微调以进行预热适应；第二阶段采用强化学习来提高模型的泛化能力。特别地，设计了一种针对时间序列预测的细粒度多目标奖励，并引入了GRIP（group-based relative importance for policy optimization），利用非均匀采样进一步鼓励和优化模型对有效推理路径的探索。

**Result:** 实验证明，Time-R1显著提高了跨多样数据集的预测性能。

**Conclusion:** Time-R1通过两阶段强化微调，成功使LLM具备了慢思考和增强的多步时间序列推理能力，从而显著提升了预测性能。

> **ai_Abstract:** 该论文针对现有时间序列预测（TSF）方法缺乏显式推理过程以及LLM提示工程的局限性，提出了一种名为Time-R1的两阶段强化微调框架。Time-R1旨在训练LLM发展“慢思考”能力，增强其多步时间序列推理技能。框架包括有监督预热微调和强化学习泛化阶段，并引入了细粒度多目标奖励和GRIP机制以优化推理路径探索。实验结果表明，Time-R1显著提升了多样数据集上的预测性能。

> **摘要翻译:** 为了推进时间序列预测（TSF），已经提出了各种方法来提高预测精度，从统计技术发展到数据驱动的深度学习架构。尽管它们有效，但大多数现有方法仍然遵循“快思考”范式——依赖于提取历史模式并将其映射到未来值作为其核心建模理念，缺乏结合中间时间序列推理的显式思考过程。与此同时，新兴的慢思考LLMs（例如OpenAI-o1）已经展示出卓越的多步推理能力，为克服这些问题提供了另一种途径。然而，单独的提示工程存在一些局限性——包括高计算成本、隐私风险以及领域特定时间序列推理能力有限。为了解决这些局限性，一种更有前景的方法是训练LLMs发展慢思考能力并获得强大的时间序列推理技能。为此，我们提出了Time-R1，一个两阶段强化微调框架，旨在增强LLM用于时间序列预测的多步推理能力。具体而言，第一阶段进行有监督微调以进行预热适应，而第二阶段采用强化学习来提高模型的泛化能力。特别地，我们设计了一种针对时间序列预测的细粒度多目标奖励，然后引入了GRIP（group-based relative importance for policy optimization），它利用非均匀采样进一步鼓励和优化模型对有效推理路径的探索。实验表明，Time-R1显著提高了跨多样数据集的预测性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Hessian Geometry of Latent Space in Generative Models](https://arxiv.org/abs/2506.10632)
> *生成模型潜在空间的Hessian几何*

*Alexander Lobashev, Dmitry Guskov, Maria Larchenko, Mikhail Tamm* | **Main category: cs.LG**

**Keywords:** 潜在空间几何, Fisher信息度量, 生成模型, 扩散模型, 相变

**Comment:** ICML 2025

> **TL;DR:** 本文提出了一种新颖的方法，通过重建Fisher信息度量来分析生成模型（包括统计物理模型和扩散模型）的潜在空间几何，揭示了扩散模型潜在空间中相变的碎形结构。

**AI_Comments:** 该论文通过利用Fisher信息度量，为理解生成模型（特别是扩散模型）的复杂潜在空间提供了一种创新方法。对碎形相变和边界处线性失效的发现是重要成果，它将统计物理学的概念与深度生成模型联系起来。这有助于更好地理解和控制生成过程。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种新方法来分析生成模型（包括统计物理模型和扩散模型）的潜在空间几何，并深入理解扩散模型潜在空间的复杂结构及其与相变等现象的联系。

**Method:** 该方法通过重建Fisher信息度量来分析潜在空间几何。它近似给定生成样本的潜在变量的后验分布，并利用此来学习定义指数族Fisher度量的对数配分函数。该方法提供了理论收敛保证，并在Ising和TASEP模型上进行了验证，随后应用于扩散模型。

**Result:** 该方法在重建热力学量方面优于现有基线（在Ising和TASEP模型上）。应用于扩散模型时，它揭示了潜在空间中相变的碎形结构，其特征是Fisher度量的突然变化。研究表明，测地线插值在单个相内近似线性，但在相边界处这种线性失效，此时扩散模型表现出相对于潜在空间的发散Lipschitz常数。

**Conclusion:** 这些发现为扩散模型潜在空间的复杂结构及其与相变等现象的联系提供了新的见解。

> **ai_Abstract:** 本文提出了一种通过重建Fisher信息度量来分析生成模型（包括统计物理模型和扩散模型）潜在空间几何的新方法。该方法通过近似潜在变量的后验分布来学习对数配分函数。研究在统计物理模型上表现出优越性，并在扩散模型中揭示了潜在空间中相变的碎形结构，其中测地线插值在相边界处失去线性，并且Lipschitz常数发散。这些发现为扩散模型潜在空间的复杂结构及其与相变现象的联系提供了新见解。

> **摘要翻译:** 本文提出了一种分析生成模型（包括统计物理模型和扩散模型）潜在空间几何的新方法，通过重建Fisher信息度量。该方法近似给定生成样本的潜在变量的后验分布，并利用此来学习对数配分函数，该函数定义了指数族的Fisher度量。文中提供了理论收敛保证，并在Ising和TASEP模型上验证了该方法，其在重建热力学量方面优于现有基线。应用于扩散模型时，该方法揭示了潜在空间中相变的碎形结构，其特征是Fisher度量的突然变化。我们证明了测地线插值在单个相内近似线性，但在相边界处这种线性失效，此时扩散模型相对于潜在空间表现出散度的Lipschitz常数。这些发现为扩散模型潜在空间的复杂结构及其与相变等现象的联系提供了新的见解。我们的源代码可在https://github.com/alobashev/hessian-geometry-of-diffusion-models获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [474] [Data Shifts Hurt CoT: A Theoretical Study](https://arxiv.org/abs/2506.10647)
> *数据漂移损害CoT：一项理论研究*

*Lang Yin, Debangshu Banerjee, Gagandeep Singh* | **Main category: cs.LG**

**Keywords:** 数据漂移, 思维链 (CoT), k-parity问题, 分布漂移, 数据投毒

**Comment:** 

> **TL;DR:** 本文首次从理论上严谨研究了数据漂移（包括分布漂移和数据投毒）对思维链（CoT）在解决k-parity问题时性能的负面影响，发现CoT在这种情况下甚至比直接预测表现更差。

**AI_Comments:** 这项工作具有重要的创新性，因为它首次对数据漂移对思维链（CoT）性能的损害进行了严谨的理论研究。其发现CoT在数据漂移下表现甚至不如直接预测，这一现象令人惊讶，并对CoT在现实世界非理想条件下的鲁棒性提出了质疑。该研究为理解CoT的局限性提供了新的视角，并可能启发未来在鲁棒CoT方面的研究。

<details>
  <summary>Details</summary>

**Motivation:** 尽管思维链（CoT）已被证明能有效提升大型语言模型（LLMs）解决复杂问题的能力（如k-parity问题），但其成功依赖于两个关键假设：训练和测试数据分布一致，以及训练数据无污染且推理步骤正确。然而，在现实世界中这些假设往往不成立。虽然数据漂移的风险已引起关注，但其对CoT的具体损害尚未得到严谨的理论研究。

**Method:** 本文通过聚焦k-parity问题，利用一种成熟的CoT分解方法，深入研究了两种类型的数据漂移（分布漂移和数据投毒）对经CoT训练的模型质量的联合影响。

**Result:** 研究揭示了一个令人惊讶的现象：在数据漂移条件下，思维链（CoT）在学习奇偶校验问题上的表现甚至比直接生成预测更差。技术结果还对这种影响的内在机制原因提供了严谨而全面的解释。

**Conclusion:** 结论是数据漂移（包括分布漂移和数据投毒）对思维链（CoT）的性能有显著的负面影响，尤其是在k-parity问题上，甚至可能导致CoT表现劣于直接预测。本研究为理解CoT在非理想数据条件下的脆弱性提供了理论基础。

> **ai_Abstract:** 本文首次从理论上严谨探讨了数据漂移（包括分布漂移和数据投毒）对思维链（CoT）在大型语言模型中性能的影响。研究发现，在非理想数据条件下，CoT在解决k-parity问题时表现出人意料地差，甚至不如直接预测。文章深入分析了造成这种现象的机制原因，强调了CoT在现实世界应用中面临的脆弱性。

> **摘要翻译:** 思维链（CoT）已被应用于各种大型语言模型（LLMs），并被证明能有效提高输出质量。在最近的研究中，Transformer被证明在表达能力方面具有绝对上限，因此它们无法解决许多计算上困难的问题。然而，在CoT的赋能下，Transformer被证明能够有效解决一些困难问题，例如k-parity问题。然而，这些工作依赖于两个必要的假设：(1) 相同的训练和测试分布，以及 (2) 训练数据无污染且推理步骤正确。然而，在现实世界中，这些假设并非总是成立。尽管数据漂移的风险已引起关注，但据我们所知，我们的工作是第一个严谨研究此类漂移所造成的确切损害。本文聚焦于k-parity问题，研究了两种类型的数据漂移：分布漂移和数据投毒，对通过成熟的CoT分解方法获得的训练模型质量的联合影响。除了揭示CoT在学习奇偶校验方面比直接生成预测导致更差性能的惊人现象外，我们的技术结果还对这种影响的内在机制原因提供了严谨而全面的解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [476] [Saturation Self-Organizing Map](https://arxiv.org/abs/2506.10680)
> *饱和自组织映射*

*Igor Urbanik, Paweł Gajewski* | **Main category: cs.LG**

**Keywords:** 持续学习, 自组织映射, 灾难性遗忘, 饱和机制, 知识保留

**Comment:** github repository: https://github.com/Radinyn/satsom

> **TL;DR:** 提出饱和自组织映射（SatSOM），通过新的饱和机制逐步冻结已训练神经元并重定向学习，以改善自组织映射（SOM）在持续学习中的知识保留问题。

**AI_Comments:** 该论文提出了一种新颖的机制，通过动态调整神经元的学习行为来解决持续学习中的灾难性遗忘问题。其创新点在于引入“饱和”概念，使模型能够自适应地平衡新旧知识的学习，避免过度训练和遗忘。这种方法提高了SOM在动态环境中的适应性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 持续学习中神经网络系统面临灾难性遗忘的挑战，即使自组织映射（SOMs）也无法避免。

**Method:** 引入饱和自组织映射（SatSOM），这是SOM的扩展。SatSOM包含一个新的饱和机制，该机制随着神经元积累信息，逐渐降低其学习率和邻域半径。这有效地冻结了训练良好的神经元，并将学习重定向到地图中未充分利用的区域。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了饱和自组织映射（SatSOM），作为自组织映射（SOM）在持续学习场景下的改进。SatSOM通过引入独特的饱和机制，能够根据神经元积累的信息量逐步降低其学习率和邻域半径。这种机制旨在“冻结”已充分训练的神经元，并将学习过程引导至地图中尚未充分利用的区域，从而有效缓解持续学习中常见的灾难性遗忘问题，增强知识保留能力。

> **摘要翻译:** 持续学习对神经网络系统提出了根本性挑战，这些系统在接触到顺序任务时经常遭受灾难性遗忘。自组织映射（SOMs）尽管具有可解释性和效率，也未能幸免于此问题。在本文中，我们介绍了饱和自组织映射（SatSOM）——SOMs的扩展，旨在改善持续学习场景中的知识保留。SatSOM引入了一种新颖的饱和机制，该机制随着神经元积累信息，逐渐降低其学习率和邻域半径。这有效地冻结了训练良好的神经元，并将学习重定向到地图中未充分利用的区域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [478] [Preserving Task-Relevant Information Under Linear Concept Removal](https://arxiv.org/abs/2506.10703)
> *在线性概念去除下保留任务相关信息*

*Floris Holstege, Shauli Ravfogel, Bram Wouters* | **Main category: cs.LG**

**Keywords:** 概念去除, 公平性, 神经网络, 斜投影, 协方差保留

**Comment:** 

> **TL;DR:** SPLICE是一种新的方法，可以在从表示中去除敏感概念的同时，精确保留其与目标标签的协方差，从而在不损害主要任务信息的情况下提高公平性和可解释性。

**AI_Comments:** SPLICE的创新之处在于其理论保证，即它是去除线性概念可预测性并以最小嵌入失真保持目标协方差的唯一解决方案。这提供了一个强大的理论基础，解释了其在实践中优于基线的原因。该方法在解决公平性和可解释性问题方面具有重要意义，因为它能够在不显著损害模型性能的情况下消除有害偏见。

<details>
  <summary>Details</summary>

**Motivation:** 现代神经网络在编码任务相关信息的同时常常编码不必要的概念，这导致了公平性和可解释性问题。现有的事后方法可以去除不期望的概念，但通常会降低有用信号。

**Method:** 本文引入了SPLICE（Simultaneous Projection for LInear concept removal and Covariance prEservation），通过一种斜投影来消除表示中的敏感概念，同时精确保留它们与目标标签的协方差。SPLICE通过“剪除”不需要的方向来保护重要的标签相关性。理论上，它是去除线性概念可预测性并以最小嵌入失真保持目标协方度的唯一解决方案。

**Result:** 在Bias in Bios和Winobias等基准测试中，SPLICE的表现优于基线，它能够去除受保护的属性，同时最大限度地减少对主要任务信息的损害。

**Conclusion:** SPLICE提供了一种独特且有效的方法，可以在去除表示中敏感概念的同时，精确保留任务相关信息，从而在公平性和性能之间取得平衡。

> **ai_Abstract:** 本文提出了一种名为SPLICE的新方法，用于在神经网络表示中去除不必要的线性概念，同时保留任务相关信息。针对现有方法在去除敏感概念时会损害有用信号的问题，SPLICE通过一种独特的斜投影技术，精确地保持表示与目标标签的协方差，从而在去除偏见的同时，最大程度地减少对主要任务性能的损害。实验结果表明，SPLICE在多个基准测试中优于现有方法。

> **摘要翻译:** 现代神经网络在编码任务相关信息的同时常常编码不必要的概念，这导致了公平性和可解释性问题。现有的事后方法可以去除不期望的概念，但通常会降低有用信号。我们引入了SPLICE——用于线性概念去除和协方差保留的同步投影——它在从表示中消除敏感概念的同时，精确保留其与目标标签的协方差。SPLICE通过一种斜投影来实现这一点，该投影“剪除”了不希望的方向，但保护了重要的标签相关性。从理论上讲，它是去除线性概念可预测性并以最小嵌入失真保持目标协方差的唯一解决方案。从经验上讲，SPLICE在Bias in Bios和Winobias等基准测试中表现优于基线，它能够去除受保护的属性，同时最大限度地减少对主要任务信息的损害。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [ConTextTab: A Semantics-Aware Tabular In-Context Learner](https://arxiv.org/abs/2506.10707)
> *ConTextTab：一种语义感知的表格上下文学习器*

*Marco Spinaci, Marek Polewczyk, Maximilian Schambach, Sam Thelin* | **Main category: cs.LG**

**Keywords:** 表格上下文学习, 语义理解, 真实世界数据, ConTextTab, 表格预测

**Comment:** 

> **TL;DR:** ConTextTab 结合了表格原生上下文学习器的高效性和预训练大语言模型的语义理解能力，通过使用专用嵌入并在大规模真实世界数据上训练，实现了与SOTA相当的性能，并在语义丰富的基准上表现出色。

**AI_Comments:** ConTextTab 的创新之处在于它成功地弥合了表格原生ICL在语义理解方面的不足和基于LLM的ICL在上下文限制方面的缺陷。通过引入专用嵌入和利用大规模真实世界数据训练，该模型有效地提升了表格ICL处理复杂语义信息的能力，为未来表格数据分析提供了新的方向。其在CARTE基准上的优异表现尤其突出，证明了语义感知的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的表格原生上下文学习器（ICL）虽然高效且适应表格结构，但因仅在合成数据上训练，未能充分利用真实世界表格数据中的丰富语义和世界知识。而基于预训练大语言模型的表格ICL模型虽然具有深度语义理解能力，但受限于架构，只能利用少量上下文。

**Method:** 论文引入了 ConTextTab，旨在结合表格原生ICL的优点和基于LLM的语义理解能力。它通过将语义理解和对齐集成到表格原生ICL框架中，并采用针对不同数据模态的专用嵌入，同时在大规模真实世界表格数据上进行训练。

**Result:** ConTextTab 在一系列广泛的基准测试中与最先进（SOTA）模型具有竞争力，并在语义丰富的 CARTE 基准测试上设立了新标准。

**Conclusion:** ConTextTab 成功地将语义理解融入到表格原生上下文学习框架中，有效结合了现有方法的优点，并在多个基准测试中取得了优异表现，尤其在语义丰富的任务上树立了新标准，证明了其在处理真实世界表格数据方面的强大能力。

> **ai_Abstract:** ConTextTab 是一种新型的表格上下文学习器，旨在解决现有表格原生ICL缺乏语义理解和基于LLM的ICL上下文受限的问题。它将语义理解集成到表格原生框架中，利用专用嵌入并在大规模真实世界数据上训练。实验证明，ConTextTab 在多个基准测试中与SOTA模型表现相当，并在语义丰富的CARTE基准上树立了新标准，展示了其在处理真实世界表格数据方面的强大潜力。

> **摘要翻译:** 表格上下文学习（ICL）最近在多项表格预测任务中取得了最先进（SOTA）的性能。此前，ICL仅限于小型表格的分类问题，但TabPFN和TabICL等最新进展已将其应用扩展到更大的数据集。尽管当前的表格原生ICL架构在结构上高效且非常适合表格数据结构，但由于它们完全在合成数据上训练，未能充分利用真实世界表格数据中包含的丰富语义和世界知识。另一方面，基于预训练大型语言模型（如TabuLa-8B）的表格ICL模型集成了深度语义理解和世界知识，但由于固有的架构限制，只能利用少量上下文。为了结合这两种方法的优点，我们引入了ConTextTab，它将语义理解和对齐集成到表格原生ICL框架中。通过采用针对不同数据模态的专用嵌入，并在大规模真实世界表格数据上进行训练，我们的模型在广泛的基准测试中与SOTA模型具有竞争力，同时在语义丰富的CARTE基准测试上设立了新标准。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [482] [Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering](https://arxiv.org/abs/2506.10751)
> *神经元在ArchEHR-QA 2025：基于证据的临床问答的代理式提示优化*

*Sai Prasanna Teja Reddy Bogireddy, Abrar Majeedi, Viswanatha Reddy Gajjala, Zhuoyan Xu, Siddhant Rai, Vaishnav Potlapalli* | **Main category: cs.LG**

**Keywords:** 临床问答, 电子健康记录, 提示优化, 证据识别, 自洽性

**Comment:** 

> **TL;DR:** 本文介绍了Neural系统，它通过解耦任务和代理式提示优化，在基于证据的临床问答任务中取得了第二名，证明了提示优化在临床QA中的有效性。

**AI_Comments:** 本文的创新之处在于提出了一种代理式提示优化方法，作为模型微调的经济高效替代方案，特别适用于高风险的临床问答场景。其将任务解耦并结合自洽性投票的策略，有效地提高了证据召回率和整体性能，对于提升医疗AI助手的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动化电子健康记录（EHR）问答可以弥补临床医生和患者的关键信息鸿沟，但它需要在有限监督下进行精确的证据检索和忠实的答案生成。

**Method:** 该方法将任务解耦为句子级证据识别和带明确引用的答案合成。在每个阶段，使用DSPy的MIPROv2优化器自动探索提示空间，共同调整指令和少量示例。此外，采用自洽性投票方案以提高证据召回率而不牺牲精确度。

**Result:** 在隐藏测试集上，该方法获得了51.5的总分，位列第二，并分别比标准的零样本和少量样本提示方法高出20和10分。

**Conclusion:** 数据驱动的提示优化是针对高风险临床问答任务中模型微调的一种经济高效的替代方案，提升了医疗领域AI助手的可靠性。

> **ai_Abstract:** 本文介绍了在BioNLP 2025 ArchEHR-QA共享任务中获得亚军的Neural系统，该系统专注于基于证据的临床问答。其方法将任务分解为证据识别和带引用的答案合成，并利用DSPy的MIPROv2优化器进行代理式提示优化，同时结合自洽性投票机制。实验结果表明，该方法在性能上显著优于零样本和少量样本提示，证明了数据驱动提示优化在临床QA领域作为模型微调的有效替代方案，提高了AI助手的可靠性。

> **摘要翻译:** 针对电子健康记录（EHR）的自动化问答（QA）可以弥合临床医生和患者之间的关键信息鸿沟，但它需要在有限监督下进行精确的证据检索和忠实的答案生成。在这项工作中，我们介绍了Neural，它在BioNLP 2025 ArchEHR-QA关于基于证据的临床问答的共享任务中获得亚军。我们提出的方法将任务解耦为（1）句子级证据识别和（2）带有明确引用的答案合成。在每个阶段，我们利用DSPy的MIPROv2优化器自动探索提示空间，在开发集上联合调整指令和少量示例。自洽性投票方案进一步提高了证据召回率，而不会牺牲精确度。在隐藏测试集上，我们的方法获得了51.5的总分，位居第二，并且分别比标准的零样本和少量样本提示方法高出20和10分。这些结果表明，数据驱动的提示优化是高风险临床问答中模型微调的一种经济高效的替代方案，提升了医疗领域AI助手的可靠性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [484] [Skillful joint probabilistic weather forecasting from marginals](https://arxiv.org/abs/2506.10772)
> *基于边缘分布的熟练联合概率天气预报*

*Ferran Alet, Ilan Price, Andrew El-Kadi, Dominic Masters, Stratis Markou, Tom R. Andersson, Jacklynn Stott, Remi Lam, Matthew Willson, Alvaro Sanchez-Gonzalez, Peter Battaglia* | **Main category: cs.LG**

**Keywords:** 概率天气预报, 机器学习, 集合预报, FGN, 联合空间结构

**Comment:** 

> **TL;DR:** FGN是一种新的机器学习模型，显著优于现有最先进的概率天气预报模型，它通过学习模型扰动生成集合预测，即使仅在边缘分布上训练也能捕获联合空间结构。

**AI_Comments:** FGN的创新之处在于其通过学习模型扰动生成集合预报的方法，以及在仅基于边缘分布训练的情况下仍能有效捕获联合空间结构的能力。这对于提高概率天气预报的准确性和实用性具有重要意义，尤其是在处理复杂天气系统时。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习（ML）天气模型因其比传统数值天气预报（NWP）更准确、更快而迅速崛起，并在全球概率天气预报中超越了传统集合预报。本研究旨在提出一种新的方法，以进一步提升当前最先进模型的性能。

**Method:** 本文提出了FGN，一种简单、可扩展且灵活的建模方法。FGN通过学习模型扰动和适当约束的模型集合来生成集合预报。它直接训练以最小化每个位置预报的连续秩概率分数（CRPS）。

**Result:** FGN显著优于当前最先进的模型。它在各种确定性和概率性指标上生成了最先进的集合预报，能够熟练地进行集合热带气旋路径预测，并且尽管仅在边缘分布上进行训练，也能捕获联合空间结构。

**Conclusion:** FGN模型在概率天气预报方面表现出色，显著超越了现有最先进的模型，并且能够有效地捕获联合空间结构，即使仅在边缘分布上进行训练也能实现。

> **ai_Abstract:** 本文介绍了FGN，一种创新的机器学习模型，专门用于概率天气预报。该模型通过学习模型扰动生成集合预报，并直接优化连续秩概率分数。FGN在多项指标上显著超越了现有最先进的模型，尤其是在捕获联合空间结构方面表现出色，尽管其训练仅基于边缘分布。此外，它在热带气旋路径预测方面也展现了高超的技能。

> **摘要翻译:** 机器学习（ML）天气模型因其比传统数值天气预报（NWP）更准确、更快而迅速崛起，最近在全球概率天气预报中超越了传统集合预报。本文提出了FGN，一种简单、可扩展且灵活的建模方法，它显著优于当前最先进的模型。FGN通过学习模型扰动和适当约束的模型集合来生成集合预报。它直接训练以最小化每个位置预报的连续秩概率分数（CRPS）。它在各种确定性和概率性指标上生成了最先进的集合预报，能够熟练地进行集合热带气旋路径预测，并且尽管仅在边缘分布上进行训练，也能捕获联合空间结构。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [486] [Monotone Classification with Relative Approximations](https://arxiv.org/abs/2506.10775)
> *具有相对近似的单调分类*

*Yufei Tao* | **Main category: cs.LG**

**Keywords:** 单调分类, 相对近似, 成本, 上下界, 分类器

**Comment:** 

> **TL;DR:** 本文首次研究了在单调分类中，以相对近似误差找到分类器的最低成本，并给出了近似匹配的上下界。

**AI_Comments:** 本文的创新之处在于首次将相对近似的概念引入到单调分类问题中，并提供了理论上的成本上下界。这解决了先前工作只能实现绝对误差近似的局限性，为单调分类的理论研究和算法设计开辟了新的方向，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 在单调分类中，以往的工作只能找到一个误差比最优解高出绝对因子的分类器。本文的动机是研究找到一个误差最多比最优解高出相对因子 (1 + ε) 倍的单调分类器所需的最低成本。

**Method:** 本文通过理论分析，提出了用于在单调分类中实现相对近似误差的分类器的近似匹配的上下界。

**Result:** 本文为在单调分类中实现相对近似误差的分类器，提供了在 ε 的整个范围内近似匹配的成本上下界。

**Conclusion:** 本文成功地首次研究了在单调分类中以相对近似误差找到分类器的最低成本问题，通过提供紧密的上下界，解决了先前工作只能实现绝对误差近似的局限性。

> **ai_Abstract:** 本文首次探讨了在单调分类中寻找具有相对近似误差的分类器的最低成本问题。单调分类旨在从给定点集中识别一个误差较小的单调函数。与以往工作仅能实现绝对误差近似不同，本文旨在找到一个误差最多比最优误差高出相对因子 (1 + ε) 的分类器。研究为此问题在 ε 的整个范围内提供了近似匹配的成本上下界，填补了该领域的一个空白。

> **摘要翻译:** 在单调分类中，输入是 $\mathbb{R}^d$ 中的一个多点集 $P$，每个点都关联着一个来自 $\{-1, 1\}$ 的隐藏标签。目标是识别一个单调函数 $h$，它作为分类器，将 $\mathbb{R}^d$ 映射到 $\{-1, 1\}$，且具有较小的“误差”，误差的衡量标准是点集 $P$ 中标签与函数值 $h(p)$ 不同的点的数量。算法的成本定义为揭示标签的点的数量。本文首次研究了找到一个单调分类器所需的最低成本，该分类器的误差最多为 $(1 + \epsilon) \cdot k^*$，其中 $\epsilon \ge 0$，而 $k^*$ 是最优单调分类器所能达到的最小误差——换句话说，允许误差最多超过最优误差一个相对因子。本文为 $\epsilon$ 的整个范围提供了近似匹配的上下界。之前关于该问题的所有工作都只能实现比最优误差高出绝对因子的误差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [488] [Dense Associative Memory with Epanechnikov Energy](https://arxiv.org/abs/2506.10801)
> *具有Epanechnikov能量的稠密联想记忆*

*Benjamin Hoover, Zhaoyang Shi, Krishnakumar Balasubramanian, Dmitry Krotov, Parikshit Ram* | **Main category: cs.LG**

**Keywords:** 稠密联想记忆, Epanechnikov核, 能量函数, 记忆检索, 局部极小值

**Comment:** 

> **TL;DR:** 本文提出了一种基于Epanechnikov核的新型稠密联想记忆能量函数LSR，它能实现指数容量的精确记忆检索，并产生大量新兴局部极小值，具有生成任务潜力。

**AI_Comments:** 这篇论文通过提出一种基于Epanechnikov核的新型能量函数LSR，为稠密联想记忆网络带来了显著的创新。其核心贡献在于实现了指数容量的精确记忆检索，并引入了大量独特的“新兴”局部极小值，这不仅扩展了网络的记忆能力，还展现了其在生成任务上的潜力。这种“新兴”记忆的特性是该领域前所未见的，为联想记忆模型开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有稠密联想记忆网络中常用能量函数（如LSE）可能存在局限性，作者旨在提出一种新的能量函数来改进记忆检索能力、容量和探索新的特性。

**Method:** 提出了一种名为log-sum-ReLU (LSR) 的新型能量函数，该函数受最优核密度估计启发，并基于Epanechnikov核。

**Result:** LSR能量函数实现了指数容量的精确记忆检索，无需指数分离函数。它引入了大量额外的“新兴”局部极小值，同时保持了完美的模式恢复。经验结果表明，LSR能量具有显著更多的局部极小值（记忆），且其对数似然与基于LSE的模型相当。对LSR新兴记忆在图像数据集上的分析显示出一定程度的创造性和新颖性。

**Conclusion:** LSR能量函数在稠密联想记忆网络中表现出卓越的性能，不仅提高了记忆容量和检索精度，还展现了生成任务的潜力，这在DenseAM领域是前所未有的。

> **ai_Abstract:** 本文提出了一种用于稠密联想记忆（DenseAM）网络的新型能量函数——log-sum-ReLU（LSR），其灵感来源于最优核密度估计，并基于Epanechnikov核。LSR能量函数能够实现指数容量的精确记忆检索，且无需复杂的指数分离函数。与现有方法不同，LSR引入了大量“新兴”局部极小值，同时保持了完美的模式恢复能力。实验结果表明，LSR具有更多可与LSE模型媲美的局部极小值（记忆），并且在图像数据集上分析其新兴记忆时展现出创造性和新颖性，预示其在大规模记忆存储和生成任务方面的应用潜力。

> **摘要翻译:** 我们为稠密联想记忆 (DenseAM) 网络提出了一种新型能量函数，即对数-和-ReLU (LSR)，其灵感来源于最优核密度估计。与常见的对数-和-指数 (LSE) 函数不同，LSR基于Epanechnikov核，无需指数分离函数即可实现指数容量的精确记忆检索。此外，它引入了大量额外的“新兴”局部极小值，同时保持了完美的模式恢复——这是DenseAM文献中前所未有的特性。经验结果表明，LSR能量具有显著更多的局部极小值（记忆），其对数似然与基于LSE的模型相当。对LSR新兴记忆在图像数据集上的分析揭示了一定程度的创造性和新颖性，暗示了该方法在大规模记忆存储和生成任务方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [489] [Detecting High-Stakes Interactions with Activation Probes](https://arxiv.org/abs/2506.10805)
> *使用激活探针检测高风险交互*

*Alex McKenzie, Urja Pawar, Phil Blandfort, William Bankes, David Krueger, Ekdeep Singh Lubana, Dmitrii Krasheninnikov* | **Main category: cs.LG**

**Keywords:** 激活探针, 高风险交互, LLM监控, 计算效率, 分层监控系统

**Comment:** 33 pages

> **TL;DR:** 本研究探讨了使用激活探针检测LLM中的高风险交互，发现其性能与大型LLM监控器相当，但计算成本显著降低，并可作为分层监控系统的有效初始过滤器。

**AI_Comments:** 本文的创新点在于提出了使用激活探针作为一种计算效率极高的方式来监控LLM中的高风险交互，解决了现有监控方法计算成本高昂的问题。其重要性在于为LLM的安全部署提供了一种可行的、资源友好的解决方案，尤其是在构建分层监控系统方面具有潜力。发布数据集和代码库也有助于推动该领域的未来研究。

<details>
  <summary>Details</summary>

**Motivation:** 安全部署大型语言模型（LLM）的一个重要方面是监控，而检测可能导致重大危害的“高风险”交互是一个关键但未被充分探索的监控目标。

**Method:** 研究评估了几种在合成数据上训练的探针架构，并测试了它们对多样化、分布外、真实世界数据的泛化能力。实验还探讨了构建资源感知分层监控系统的潜力。

**Result:** 激活探针在检测高风险交互方面表现出对多样化真实世界数据的鲁棒泛化能力。其性能与提示或微调的中型LLM监控器相当，但计算成本降低了六个数量级。探针可以作为高效的初始过滤器，用于更昂贵的下游分析。

**Conclusion:** 激活探针是检测LLM中高风险交互的一种高效且计算成本低的替代方案，适用于构建分层监控系统。研究发布了新的合成数据集和代码库以促进进一步研究。

> **ai_Abstract:** 本论文探讨了利用激活探针来检测大型语言模型（LLM）中的“高风险”交互，这是一种对安全部署LLM至关重要的监控目标。研究评估了在合成数据上训练的多种探针架构，并发现它们对真实世界数据具有强大的泛化能力。这些探针在性能上与中型LLM监控器相当，但计算效率提高了六个数量级。此外，研究提出将探针作为分层监控系统中的高效初始过滤器，以识别需要更深入分析的案例。作者还发布了相关数据集和代码库。

> **摘要翻译:** 监控是安全部署大型语言模型（LLM）的一个重要方面。本文研究了激活探针在检测“高风险”交互（即文本表明交互可能导致重大危害）方面的应用，认为这是一个关键但尚未充分探索的监控目标。我们评估了几种在合成数据上训练的探针架构，发现它们对多样化、分布外、真实世界数据表现出鲁棒的泛化能力。探针的性能与提示或微调的中型LLM监控器相当，同时计算成本降低了六个数量级。我们的实验还强调了构建资源感知分层监控系统的潜力，其中探针可作为高效的初始过滤器，并标记出需要更昂贵下游分析的案例。我们发布了我们新颖的合成数据集和代码库，以鼓励进一步研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [491] [Efficiency Robustness of Dynamic Deep Learning Systems](https://arxiv.org/abs/2506.10831)
> *动态深度学习系统的效率鲁棒性*

*Ravishka Rathnasuriya, Tingxi Li, Zexin Xu, Zihe Song, Mirazul Haque, Simin Chen, Wei Yang* | **Main category: cs.LG**

**Keywords:** 动态深度学习系统, 效率鲁棒性, 对抗攻击, 攻击分类, 防御机制

**Comment:** Accepted to USENIX Security '25

> **TL;DR:** 动态深度学习系统（DDLS）提高了效率，但也引入了新的效率对抗攻击面。本文系统探索了DDLS的效率鲁棒性，提出了首个效率攻击分类法，并分析了现有防御机制的局限性，强调了新缓解策略的必要性。

**AI_Comments:** 这篇论文创新性地关注了动态深度学习系统在效率方面的安全问题，填补了现有研究对效率对抗攻击关注不足的空白。其提出的效率攻击分类法具有重要的理论和实践意义，为后续研究提供了框架。论文也强调了现有防御机制的局限性，指明了未来研究的方向，即开发针对此类新型攻击的有效缓解策略。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习系统（DLSs）在实时和资源受限环境中部署时面临效率挑战。动态深度学习系统（DDLSs）通过自适应推理计算来提高效率，但这种动态行为引入了新的攻击面，即效率对抗攻击，这些攻击利用动态机制来降低系统性能。因此，需要系统地探索DDLS的效率鲁棒性。

**Method:** 本文系统地探索了DDLS的效率鲁棒性，提出了首个效率攻击的综合分类法，并根据三种动态行为（每次推理的动态计算、动态推理迭代、下游任务的动态输出生产）进行分类。通过深入评估，分析了针对DDLS效率的对抗策略，识别了保护这些系统的关键挑战，并调查了现有防御机制及其局限性。

**Result:** 提出了首个全面的效率攻击分类法。分析了针对DDLS效率的对抗策略，并识别了保护这些系统的关键挑战。揭示了现有防御机制在对抗效率攻击方面的局限性。

**Conclusion:** 动态深度学习系统虽然提高了效率，但其动态性引入了效率对抗攻击的新漏洞。现有防御机制不足以应对这些攻击，未来需要新的缓解策略来保护自适应DDLS。

> **ai_Abstract:** 本文探讨了动态深度学习系统（DDLSs）的效率鲁棒性，因为其自适应性在提高效率的同时也引入了效率对抗攻击。作者提出了首个全面的效率攻击分类法，并基于三种动态行为（计算、迭代、输出）对攻击进行分类。研究通过深入评估分析了攻击策略，并指出保护DDLSs面临的关键挑战。此外，研究还揭示了现有防御机制的不足，强调了开发新缓解策略以保护未来自适应DDLSs的重要性。

> **摘要翻译:** 深度学习系统（DLSs）越来越多地部署在实时应用中，包括移动和物联网设备等资源受限环境。为了解决效率挑战，动态深度学习系统（DDLSs）根据输入复杂性调整推理计算，从而降低开销。虽然这种动态行为提高了效率，但它也引入了新的攻击面。特别是，效率对抗攻击利用这些动态机制来降低系统性能。本文系统地探索了DDLS的效率鲁棒性，提出了首个全面的效率攻击分类法。我们根据三种动态行为对这些攻击进行分类：(i) 针对每次推理的动态计算的攻击，(ii) 针对动态推理迭代的攻击，以及 (iii) 针对下游任务的动态输出生产的攻击。通过深入评估，我们分析了针对DDLS效率的对抗策略，并识别了保护这些系统的关键挑战。此外，我们还调查了现有防御机制，证明了它们在对抗日益流行的效率攻击方面的局限性，以及为保护未来自适应DDLS而采取新缓解策略的必要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [493] [Advanced fraud detection using machine learning models: enhancing financial transaction security](https://arxiv.org/abs/2506.10842)
> *使用机器学习模型进行高级欺诈检测：增强金融交易安全性*

*Nudrat Fariha, Md Nazmuddin Moin Khan, Md Iqbal Hossain, Syed Ali Reza, Joy Chakra Bortty, Kazi Sharmin Sultana, Md Shadidur Islam Jawad, Saniah Safat, Md Abdul Ahad, Maksuda Begum* | **Main category: cs.LG**

**Keywords:** 欺诈检测, 机器学习, 无监督学习, 异常检测, 金融安全

**Comment:** 

> **TL;DR:** 本研究开发了一个端到端的机器学习框架，用于使用真实世界数据检测信用卡交易异常和欺诈。

**AI_Comments:** 该论文的创新之处在于其构建了一个全面的端到端机器学习框架，整合了多源数据、细致的特征工程以及多种无监督学习模型和聚类技术，以应对复杂的金融欺诈检测问题。其重要性在于为信用卡交易安全提供了一个智能且可扩展的解决方案，能够从真实世界数据中有效识别异常行为。

<details>
  <summary>Details</summary>

**Motivation:** 数字支付的兴起加速了对智能和可扩展欺诈检测系统的需求。

**Method:** 研究通过合并交易、持卡人、商户和商户类别数据集来创建统一的分析视图。通过特征工程，提取了平均消费、偏离历史模式、交易时间不规律和类别频率等行为信号，并用时间标记（如小时、星期几、周末指示器）进行丰富。使用交易数据训练和评估了一系列无监督模型：Isolation Forest、One Class SVM 和深度自编码器，这些模型将前1%的重建错误标记为异常值。此外，还使用K-Means聚类和DBSCAN来识别正常活动的密集簇和稀疏的可疑区域。

**Result:** 探索性数据分析揭示了所有数据集特征中的上下文交易趋势。所使用的模型能够将异常值分离到二维潜在空间中，并且聚类技术能够识别正常活动的密集簇和稀疏的可疑区域。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究提出了一个端到端的机器学习框架，旨在通过利用真实世界的信用卡交易数据来增强金融交易的安全性。该框架通过整合多个数据集、进行丰富的特征工程（包括行为信号和时间标记）来识别潜在的欺诈模式。研究训练并评估了多种无监督模型，包括Isolation Forest、One Class SVM和深度自编码器，以检测异常交易。此外，还利用PCA可视化和K-Means、DBSCAN等聚类技术来区分正常活动区域和可疑区域，从而有效地识别和隔离欺诈行为。

> **摘要翻译:** 数字支付的兴起加速了对智能和可扩展欺诈检测系统的需求。本研究提出了一个端到端的、特征丰富的机器学习框架，用于使用真实世界数据检测信用卡交易异常和欺诈。该研究首先通过合并关系数据库中的交易、持卡人、商户和商户类别数据集，创建一个统一的分析视图。通过特征工程过程，我们提取了行为信号，如平均消费、偏离历史模式、交易时间不规律和类别频率指标。这些特征通过时间标记（如小时、星期几和周末指示器）进行丰富，以揭示所有指示欺诈行为的潜在模式。探索性数据分析揭示了所有数据集特征中的上下文交易趋势。使用交易数据，我们训练并评估了一系列无监督模型：Isolation Forest、One Class SVM 和一个训练用于重建正常行为的深度自编码器。这些模型将前1%的重建错误标记为异常值。PCA可视化展示了每个模型将异常值分离到二维潜在空间的能力。我们通过K-Means聚类和DBSCAN进一步分割交易格局，以识别正常活动的密集簇并隔离稀疏的可疑区域。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [495] [Viability of Future Actions: Robust Safety in Reinforcement Learning via Entropy Regularization](https://arxiv.org/abs/2506.10871)
> *未来行动的生存能力：通过熵正则化实现强化学习中的鲁棒安全性*

*Pierre-François Massiani, Alexander von Rohr, Lukas Haverbeck, Sebastian Trimpe* | **Main category: cs.LG**

**Keywords:** 强化学习, 鲁棒安全性, 熵正则化, 约束惩罚, 奖励塑形

**Comment:** 24 pages, 11 figures, 2 tables. Accepted for publication at ECML-PKDD
  2025

> **TL;DR:** 本文通过分析熵正则化和约束惩罚的相互作用，提出了一种在强化学习中实现鲁棒安全性的新方法，并发现熵正则化能促进未来可行行动的数量，从而提高对动作噪声的鲁棒性。

**AI_Comments:** 这篇论文的创新点在于揭示了熵正则化在约束强化学习中对促进鲁棒安全性的内在作用，并提出了通过奖励塑形将有约束问题转化为无约束问题的实用方法。其重要性在于为解决强化学习中的安全问题提供了一个新的视角和实用的解决方案，特别是在存在未知扰动的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 尽管强化学习（RL）取得了许多进展，但在未知扰动下学习能够稳健满足状态约束的策略仍然是一个悬而未决的问题。

**Method:** 作者分析了无模型强化学习中熵正则化和约束惩罚这两种技术之间的相互作用。他们通过将严格安全约束通过惩罚松弛，将有约束的RL问题近似为一个无约束问题，并使用标准的无模型RL方法解决。

**Result:** 经验表明，在约束RL中，熵正则化固有地使学习偏向于最大化未来可行行动的数量，从而促进对动作噪声鲁棒的约束满足。这种重新表述在经验上提高了对扰动的弹性，同时保留了安全性和最优性。

**Conclusion:** 熵正则化与鲁棒性之间的联系是一个有前景的研究方向，因为它通过简单的奖励塑形实现了RL中的鲁棒安全性。

> **ai_Abstract:** 本文探讨了在强化学习中实现鲁棒安全性的问题，特别是在未知扰动下。作者提出了一种新的方法，通过分析熵正则化和约束惩罚在无模型RL中的相互作用。研究发现，熵正则化有助于最大化未来可行行动的数量，从而提高对动作噪声的鲁棒性。此外，通过将严格安全约束转化为惩罚项，可以将有约束的RL问题近似为无约束问题，并用标准方法求解，同时保持安全性和最优性并提高对扰动的弹性。这表明熵正则化与鲁棒性之间的联系是实现RL中鲁棒安全性的有效途径。

> **摘要翻译:** 尽管强化学习（RL）最近取得了许多进展，但在未知扰动下学习能够稳健满足状态约束的策略仍然是一个悬而未决的问题。在本文中，我们通过分析无模型RL中两种成熟技术——熵正则化和约束惩罚——之间的相互作用，提供了一种实现鲁棒安全性的新视角。我们通过经验揭示，约束RL中的熵正则化本质上偏向于最大化未来可行行动的数量，从而促进对动作噪声具有鲁棒性的约束满足。此外，我们表明，通过惩罚放松严格的安全约束，有约束的RL问题可以被任意接近地近似为一个无约束问题，从而可以使用标准的无模型RL解决。这种重新表述在经验上提高了对扰动的弹性，同时保留了安全性和最优性。我们的结果表明，熵正则化与鲁棒性之间的联系是一个有前景的进一步经验和理论研究方向，因为它通过简单的奖励塑形实现了RL中的鲁棒安全性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [496] [Lattice Climber Attack: Adversarial attacks for randomized mixtures of classifiers](https://arxiv.org/abs/2506.10888)
> *格子攀爬攻击：针对分类器随机混合的对抗性攻击*

*Lucas Gnecco-Heredia, Benjamin Negrevergne, Yann Chevaleyre* | **Main category: cs.LG**

**Keywords:** 对抗性攻击, 分类器混合, 随机集成, 格子攀爬攻击, 鲁棒性

**Comment:** 17 pages including bibliography + 13 pages of supplementary material.
  Extended version of the article accepted at ECML 2025

> **TL;DR:** 现有对抗性攻击不适用于分类器随机混合。本文提出了一种新的“格子攀爬攻击”，具有理论保证，并在实验中表现良好。

**AI_Comments:** 这篇论文的创新点在于从几何分析的角度提出了评估对抗性攻击有效性的新特性，并针对性地设计了“格子攀爬攻击”来克服现有方法在随机混合分类器上的局限性。其理论保证和实验验证增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 分类器随机混合被提出以提高对抗性攻击的鲁棒性，但现有攻击对这类分类器不适用。

**Method:** 本文首先从几何分析的角度讨论了攻击分类器混合的问题，并引入了攻击的两个理想特性（有效性和最大性）。随后，提出了一种名为“格子攀爬攻击”的新型攻击，并在二元线性设置下提供了理论保证。

**Result:** 现有攻击无法同时满足有效性和最大性这两个特性。新提出的“格子攀爬攻击”在合成数据集和真实数据集上都展示了其性能。

**Conclusion:** 论文成功地提出了一个针对分类器随机混合的有效对抗性攻击方法——格子攀爬攻击，解决了现有攻击的局限性，并提供了理论和实验支持。

> **ai_Abstract:** 本文针对分类器随机混合的对抗性攻击问题，指出现有攻击的不足。通过几何分析，提出了攻击的有效性和最大性两个新特性，并证明现有攻击未能满足。为此，论文引入了“格子攀爬攻击”，该攻击在二元线性设置下具有理论保证，并通过在合成和真实数据集上的实验验证了其有效性。

> **摘要翻译:** 有限分类器混合（又称随机集成）已被提出作为提高对抗性攻击鲁棒性的一种方式。然而，现有攻击已被证明不适用于这类分类器。在本文中，我们以一种原则性的方式讨论了攻击混合模型的问题，并基于问题的几何分析引入了攻击的两个理想特性（有效性和最大性）。然后我们表明现有攻击不能同时满足这两个特性。最后，我们引入了一种新的攻击，称为“格子攀爬攻击”，它在二元线性设置中具有理论保证，并通过在合成数据集和真实数据集上进行实验证明了其性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [498] [The Diffusion Duality](https://arxiv.org/abs/2506.10892)
> *扩散对偶性*

*Subham Sekhar Sahoo, Justin Deschenaux, Aaron Gokaslan, Guanghan Wang, Justin Chiu, Volodymyr Kuleshov* | **Main category: cs.LG**

**Keywords:** 离散扩散模型, 高斯扩散, 文本生成, 课程学习, 一致性蒸馏

**Comment:** ICML 2025. We provide the code at: https://github.com/s-sahoo/duo

> **TL;DR:** 通过利用高斯扩散与统一状态离散扩散之间的对偶性，Duo方法显著提升了离散扩散模型的训练速度和采样效率，使其在文本生成任务上超越了自回归模型。

**AI_Comments:** 这篇论文通过揭示统一状态离散扩散过程与高斯扩散之间的对偶性，为离散扩散模型的性能提升提供了新的视角和方法。其创新点在于将连续扩散领域的先进技术（如一致性蒸馏和课程学习）巧妙地迁移到离散设置，有效解决了离散扩散模型训练慢、采样效率低的问题。特别是采样速度提升两个数量级和在部分基准测试上超越自回归模型的结果，显示了其在快速高质量文本生成方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 统一状态离散扩散模型在文本生成方面具有自我纠正的潜力，但其性能通常不如自回归模型和掩码扩散模型。本文旨在缩小这一性能差距。

**Method:** 本文提出了Duo方法，利用统一状态扩散过程源于高斯扩散的关键见解，将高斯扩散的强大技术应用于改进训练和采样。具体包括：1) 引入由高斯过程引导的课程学习策略，通过减少方差使训练速度加倍。2) 提出离散一致性蒸馏，将连续设置下的一致性蒸馏适应到离散设置，以实现扩散语言模型的少步生成。

**Result:** 1) 课程学习策略将训练速度提高了一倍。2) 经课程学习训练的模型在7个基准测试中的3个上，零样本困惑度超越了自回归模型。3) 离散一致性蒸馏算法将采样速度加快了两个数量级，实现了扩散语言模型的少步生成。

**Conclusion:** 本文通过引入Duo方法，成功地缩小了统一状态离散扩散模型与自回归及掩码扩散模型之间的性能差距，显著提升了训练和采样效率，并使其在文本生成任务中表现出色。

> **ai_Abstract:** 本文提出了一种名为Duo的新方法，旨在提升统一状态离散扩散模型在文本生成任务上的性能。通过利用统一状态扩散与高斯扩散之间的对偶性，Duo引入了两种关键技术：一是基于高斯过程的课程学习策略，将训练速度提升一倍并在部分基准测试上超越自回归模型；二是离散一致性蒸馏，显著加速采样并实现少步生成。这些创新显著缩小了离散扩散模型与其他先进模型之间的性能差距。

> **摘要翻译:** 统一状态离散扩散模型因其固有的自我纠正能力，有望实现快速文本生成。然而，它们的性能通常不如自回归模型和掩码扩散模型。在这项工作中，我们通过利用一个关键见解来缩小这一性能差距：统一状态扩散过程自然地从底层高斯扩散中涌现。我们的方法Duo，将高斯扩散的强大技术应用于改进训练和采样。首先，我们引入了一种由高斯过程引导的课程学习策略，通过减少方差使训练速度加倍。使用课程学习训练的模型在7个基准测试中的3个上，零样本困惑度超过了自回归模型。其次，我们提出了离散一致性蒸馏，它将一致性蒸馏从连续设置适应到离散设置。该算法通过将采样速度加快两个数量级，解锁了扩散语言模型中的少步生成。我们提供了项目页面上的代码和模型检查点：http://s-sahoo.github.io/duo

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [500] [NoLoCo: No-all-reduce Low Communication Training Method for Large Models](https://arxiv.org/abs/2506.10911)
> *NoLoCo: 大型模型无all-reduce低通信训练方法*

*Jari Kolehmainen, Nikolay Blagoev, John Donaghy, Oğuzhan Ersoy, Christopher Nies* | **Main category: cs.LG**

**Keywords:** NoLoCo, 低通信, 大型模型, 分布式训练, 隐式同步

**Comment:** 

> **TL;DR:** NoLoCo是一种新型优化方法，用于训练大型模型，它通过隐式同步而非显式集体通信来显著减少通信开销，并提高了收敛速度。

**AI_Comments:** NoLoCo的主要创新在于其独特的隐式权重同步机制，通过部分平均随机选择的副本权重，彻底避免了代价高昂的all-reduce操作。这对于在低带宽网络或极其大规模的分布式环境中训练大型模型具有重要意义，因为它直接解决了通信瓶颈，提高了训练效率和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型通常需要大量加速器的集群，并通过高带宽互连进行通信。扩展这些集群成本高昂且不切实际，限制了可训练模型的规模。现有的低通信训练方法仍需要模型参数的同步步骤，这在低带宽网络上成本很高。

**Method:** 本文提出了一种名为NoLoCo的新型优化方法，它在训练期间不显式同步所有模型参数，因此不需要任何集体通信。NoLoCo通过Nesterov动量优化器的一种新颖变体，通过将模型权重与随机选择的另一个模型权重进行部分平均来隐式同步模型权重。论文提供了理论收敛性分析和语言模型训练的实证结果。

**Result:** NoLoCo在1.25亿到68亿参数的模型尺寸和广泛的加速器数量上进行了基准测试。与完全分片数据并行训练或广泛使用的低通信训练方法DiLoCo相比，NoLoCo所需的通信开销显著减少。对于数百个加速器通过互联网训练，其同步步骤比DiLoCo中使用的all-reduce快一个数量级。NoLoCo没有全局阻塞通信，从而减少了加速器空闲时间。与DiLoCo相比，NoLoCo在各种模型尺寸和加速器数量下，收敛速度最高可提高4%。

**Conclusion:** NoLoCo是一种高效的低通信训练方法，通过避免显式集体通信和采用创新的隐式同步机制，显著降低了大型模型训练的通信开销，并提高了训练效率和收敛速度。

> **ai_Abstract:** NoLoCo是一种创新的大型模型训练优化方法，旨在解决现有分布式训练中高昂的通信成本问题。它通过避免显式集体通信（如all-reduce）和采用基于Nesterov动量优化器变体的隐式权重同步机制来实现低通信。实验证明，NoLoCo显著减少了通信开销，同步速度比现有方法快一个数量级，消除了全局阻塞通信，并能将收敛速度提高高达4%。这使得NoLoCo成为在低带宽网络或大规模集群上训练大型模型的更高效选择。

> **摘要翻译:** 训练大型语言模型通常通过在包含数万个加速器的集群上进行优化方法来完成，这些集群通过高带宽互连进行通信。扩展这些集群成本高昂且可能不切实际，从而限制了可训练模型的规模。最近的几项研究提出了通信密集度较低的训练方法，避免了对高度连接的计算集群的需求。这些最先进的低通信训练方法仍然采用模型参数的同步步骤，当在所有模型副本上执行时，这在低带宽网络上可能会变得非常昂贵。
在这项工作中，我们提出了一种新颖的优化方法NoLoCo，它在训练期间不显式同步所有模型参数，因此不需要任何集体通信。NoLoCo通过Nesterov动量优化器的一种新颖变体，通过将模型权重与随机选择的另一个模型权重进行部分平均来隐式同步模型权重。我们为我们提出的优化器提供了理论收敛性分析以及语言模型训练的实证结果。
我们在1.25亿到68亿参数的广泛加速器数量和模型尺寸上对NoLoCo进行了基准测试。我们的方法比完全分片数据并行训练甚至广泛使用的低通信训练方法DiLoCo所需的通信开销显著减少。对于数百个加速器通过互联网训练，同步步骤本身估计比DiLoCo中使用的all-reduce快一个数量级。我们也没有任何全局阻塞通信，从而减少了加速器空闲时间。与DiLoCo相比，我们还在各种模型尺寸和加速器数量下观察到高达4%的收敛速度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [502] [Foundation Models for Causal Inference via Prior-Data Fitted Networks](https://arxiv.org/abs/2506.10914)
> *通过先验数据拟合网络实现因果推断的基础模型*

*Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel* | **Main category: cs.LG**

**Keywords:** 基础模型, 因果推断, 先验数据拟合网络, 贝叶斯推断, 结构因果模型

**Comment:** 

> **TL;DR:** 本文介绍了CausalFM，一个基于先验数据拟合网络（PFNs）的综合框架，用于在各种因果推断设置中训练基础模型，并展示了其在条件平均治疗效果（CATE）估计上的竞争力。

**AI_Comments:** CausalFM的创新之处在于将PFNs这种新兴的表格基础模型技术与因果推断相结合，提出了一种统一的框架。通过形式化贝叶斯先验和引入因果启发式贝叶斯神经网络，它为构建可泛化到不同因果设置的基础模型提供了新的思路。其潜力在于能够简化和标准化因果推断的流程，尤其是在数据驱动的决策领域，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 先验数据拟合网络（PFNs）已被提出作为训练表格基础模型的一种有前景的方法，但目前缺乏将PFNs应用于因果推断的综合框架。本文旨在填补这一空白，提供一个通用范式来改变因果推断的实践方式。

**Method:** 本文提出了CausalFM框架，用于训练基于PFN的因果推断基础模型。首先，它基于结构因果模型（SCMs）原则性地形式化了因果推断的贝叶斯先验构建，并推导了先验有效性的必要标准。其次，它提出了一种利用因果启发式贝叶斯神经网络的新型先验分布族，使CausalFM能够在包括后门、前门和工具变量调整在内的各种设置中进行贝叶斯因果推断。最后，通过实例化CausalFM并训练一个用于估计条件平均治疗效果（CATEs）的基础模型，使用后门调整方法进行验证。

**Result:** CausalFM在各种合成和半合成基准测试中，在CATE估计方面表现出竞争力。

**Conclusion:** CausalFM提供了一个新的范式，可以作为训练各种因果推断设置中基础模型的通用方法，并有潜力从根本上改变医学、经济学和其他学科中因果推断的实践方式。

> **ai_Abstract:** 本文介绍了CausalFM，一个基于先验数据拟合网络（PFNs）的综合框架，用于训练各种因果推断设置中的基础模型。CausalFM通过原则性地构建基于结构因果模型（SCMs）的贝叶斯先验，并利用因果启发式贝叶斯神经网络，实现了在后门、前门和工具变量调整等多种设置下的贝叶斯因果推断。实验结果表明，CausalFM在条件平均治疗效果（CATE）估计方面表现出竞争力，有望成为因果推断领域的一种通用且具有变革性的新范式。

> **摘要翻译:** 先验数据拟合网络（PFNs）最近被提出作为训练表格基础模型的一种有前景的方法。PFNs是基于预先指定先验分布生成的合成数据进行预训练的Transformer，并通过上下文学习实现贝叶斯推断。在本文中，我们引入了CausalFM，一个用于在各种因果推断设置中训练基于PFN的基础模型的综合框架。首先，我们以原则性的方式，基于结构因果模型（SCMs）形式化了因果推断的贝叶斯先验构建，并推导了此类先验有效性的必要标准。在此基础上，我们提出了一种利用因果启发式贝叶斯神经网络的新型先验分布族，使CausalFM能够在包括后门、前门和工具变量调整在内的各种设置中执行贝叶斯因果推断。最后，我们实例化了CausalFM，并明确训练了一个用于使用后门调整估计条件平均治疗效果（CATEs）的基础模型。我们表明，CausalFM在使用各种合成和半合成基准测试进行CATE估计时表现出竞争力。总而言之，我们的框架可以作为训练各种因果推断设置中基础模型的通用方法。与当前因果推断的最新技术相比，CausalFM提供了一种新的范式，有可能从根本上改变从业者在医学、经济学和其他学科中执行因果推断的方式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [504] [Sequential-Parallel Duality in Prefix Scannable Models](https://arxiv.org/abs/2506.10918)
> *前缀可扫描模型中的序列-并行对偶性*

*Morris Yau, Sharut Gupta, Valerie Engelmayer, Kazuki Irie, Stefanie Jegelka, Jacob Andreas* | **Main category: cs.LG**

**Keywords:** 前缀可扫描模型, 序列-并行对偶性, 神经网络序列模型, 状态空间模型, 线性Transformer

**Comment:** 

> **TL;DR:** 本文引入了前缀可扫描模型 (PSM) 的概念，该模型统一了许多现有序列架构，并实现了并行训练和高效序列推理的“序列-并行对偶性”。PSM 在保持表达能力的同时，实现了与状态空间模型相当的推理效率，甚至在某些情况下表现出更好的长度泛化能力。

**AI_Comments:** 本文提出了前缀可扫描模型（PSM）的通用框架，这是一个重要的创新，因为它提供了一种统一现有高效序列模型（如Mamba和GLA）的理论基础。通过将这些模型置于一个共同的“前缀可扫描”框架下，作者不仅澄清了它们共享的计算特性，还为设计新的高效架构提供了指导。PSM能够保持Transformer的表达能力同时实现状态空间模型的推理效率，这对于未来大规模序列模型的开发具有重要意义。特别是其在长度泛化方面的改进潜力，解决了现有模型的一个关键限制。

<details>
  <summary>Details</summary>

**Motivation:** 现代神经网络序列模型旨在实现可并行训练和快速序列推理的双重目标。最近的发展涌现出一些实现了这种“序列-并行对偶性”的模型，如门控线性注意力 (GLA) 和 Mamba。这引出了一个自然的问题：我们能否表征支持近乎常数时间并行评估和线性时间、常数空间序列推理的神经网络序列模型的完整类别？

**Method:** 本文首先将一类广泛的模型——状态空间模型——描述为那些其状态更新可以使用经典并行前缀扫描算法和自定义结合聚合运算符计算的模型。然后，通过放宽状态聚合运算符以允许任意（可能非结合的）函数（例如 softmax 注意力），定义了一个更通用的类别——前缀可扫描模型（PSMs）。这种泛化统一了许多现有架构，包括逐元素RNN（例如 Mamba）和线性Transformer（例如 GLA, Mamba2, mLSTM），同时也引入了具有类 softmax 运算符的新模型，这些模型实现了每个 token O(1) 的摊销计算和序列长度 N 的 log(N) 内存。

**Result:** 经验评估表明，PSMs 在说明性的小规模语言建模和规范的合成任务（包括状态跟踪和关联回忆）上表现良好。经验上，我们发现 PSMs 保留了基于 Transformer 架构的表达能力，同时匹配了状态空间模型的推理效率——在某些情况下甚至比两者都表现出更好的长度泛化能力。

**Conclusion:** 前缀可扫描模型 (PSM) 统一了多种现有序列模型，并提供了一种表征具有序列-并行对偶性的神经网络序列模型的方法。它们在保持表达能力的同时，实现了高效的并行训练和序列推理，并在某些情况下表现出优于现有模型的长度泛化能力。

> **ai_Abstract:** 本文介绍了前缀可扫描模型 (PSM)，这是一个通用类别的神经网络序列模型，旨在实现并行训练和高效序列推理的“序列-并行对偶性”。PSM 通过放宽状态空间模型中的结合聚合运算符，允许任意函数（如 softmax 注意力），从而统一了多种现有架构，包括 Mamba 和线性 Transformer。实验结果表明，PSM 在保持 Transformer 架构表达能力的同时，实现了与状态空间模型相当的推理效率，并且在某些任务上表现出更好的长度泛化能力。

> **摘要翻译:** 现代神经网络序列模型旨在满足可并行训练和快速序列推理的双重需求。最近的发展催生了各种模型，如门控线性注意力 (GLA) 和 Mamba，它们实现了这种“序列-并行对偶性”。这提出了一个自然的问题：我们能否表征支持近乎常数时间并行评估和线性时间、常数空间序列推理的神经网络序列模型的完整类别？我们首先将一类广泛的模型——状态空间模型——描述为那些其状态更新可以使用经典并行前缀扫描算法和自定义结合聚合运算符计算的模型。然后，通过放宽状态聚合运算符以允许任意（可能非结合的）函数（例如 softmax 注意力），定义了一个更通用的类别——前缀可扫描模型 (PSMs)。这种泛化统一了许多现有架构，包括逐元素RNN（例如 Mamba）和线性Transformer（例如 GLA, Mamba2, mLSTM），同时也引入了具有类 softmax 运算符的新模型，这些模型实现了每个 token O(1) 的摊销计算和序列长度 N 的 log(N) 内存。我们对这些模型在说明性的小规模语言建模和规范的合成任务（包括状态跟踪和关联回忆）上进行了经验评估。经验上，我们发现 PSMs 保留了基于 Transformer 架构的表达能力，同时匹配了状态空间模型的推理效率——在某些情况下甚至比两者都表现出更好的长度泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [506] [Robustly Improving LLM Fairness in Realistic Settings via Interpretability](https://arxiv.org/abs/2506.10922)
> *通过可解释性在现实场景中稳健地提升大型语言模型（LLM）的公平性*

*Adam Karvonen, Samuel Marks* | **Main category: cs.LG**

**Keywords:** LLM公平性, 偏见缓解, 内部干预, 可解释性, 招聘应用

**Comment:** 

> **TL;DR:** 在现实招聘场景中，简单的LLM偏见缓解方法失效，但通过可解释性实现的内部偏见缓解策略能够稳健地减少偏见并保持模型性能。

**AI_Comments:** 本文的创新点在于提出了内部偏见缓解策略，通过直接干预模型激活层面的敏感属性方向，而非仅仅依赖外部提示，从而在更复杂的现实场景中实现了鲁棒的偏见消除。这对于LLM在如招聘等高风险应用中的公平性至关重要，揭示了传统反偏见方法的局限性并提供了一种更深层次的解决方案。研究还强调了在现实场景中评估LLM公平性的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在高风险招聘应用中的部署日益增多，其决策直接影响个人职业和生计。尽管先前的研究表明简单的反偏见提示在受控评估中能消除人口统计学偏见，但本研究发现当引入现实上下文细节时，这些缓解措施会失效。

**Method:** 本研究通过内部偏见缓解来解决问题。具体方法是：识别并中和模型激活中的敏感属性方向，并在推理时应用仿射概念编辑。尽管这些方向来自一个简单的合成数据集，但该干预措施表现出强大的泛化能力。

**Result:** 在引入公司名称、文化描述和招聘限制等现实上下文后，先前的偏见缓解措施失效，并会引入显著的种族和性别偏见（面试率差异高达12%）。这些偏见在所有测试模型和场景中一致偏向黑人而非白人候选人，以及女性而非男性候选人。模型甚至可以从大学隶属关系等细微线索中推断出人口统计信息并产生偏见，且这些偏见在思维链推理中也无法察觉。然而，本研究提出的内部偏见缓解方法能够将偏见稳健地降低到非常低的水平（通常低于1%，始终低于2.5%），同时基本保持了模型性能。

**Conclusion:** 部署LLM进行招聘的从业者应采用更现实的评估方法，并考虑内部缓解策略以实现公平结果。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在现实招聘场景中的公平性问题。研究发现，尽管简单的反偏见提示在受控环境下有效，但在引入公司名称、文化描述和招聘限制等现实背景时，这些缓解措施会失效，导致显著的种族和性别偏见。为解决此问题，作者提出了一种内部偏见缓解方法，通过识别并中和模型激活中的敏感属性方向（即使是从合成数据集中提取的方向），在所有测试场景中实现了稳健的偏见减少（通常降至1%以下）。该方法在保持模型性能的同时，有效解决了LLM在现实应用中可能因细微线索推断人口统计信息而产生的隐形偏见。研究强调了在LLM招聘应用中采用更现实的评估方法和内部缓解策略的重要性。

> **摘要翻译:** 大型语言模型（LLM）越来越多地部署在高风险的招聘应用中，其决策直接影响人们的职业生涯和生计。虽然先前的研究表明简单的反偏见提示可以在受控评估中消除人口统计学偏见，但我们发现当引入现实的上下文细节时，这些缓解措施会失效。我们通过内部偏见缓解来解决这些失败：通过识别和中和模型激活中的敏感属性方向，我们在所有测试场景中实现了稳健的偏见减少。在领先的商业模型（GPT-4o、Claude 4 Sonnet、Gemini 2.5 Flash）和开源模型（Gemma-2 27B、Gemma-3、Mistral-24B）中，我们发现添加公司名称、来自公开招聘页面的文化描述以及选择性招聘限制（例如“只接受前10%的候选人”）等现实上下文会引入显著的种族和性别偏见（面试率差异高达12%）。当这些偏见出现时，在所有测试模型和场景中，它们始终偏向黑人而非白人候选人，以及女性而非男性候选人。此外，模型可以从大学隶属关系等细微线索中推断出人口统计信息并变得有偏见，即使检查模型的思维链推理，这些偏见仍然是不可见的。为了解决这些限制，我们的内部偏见缓解方法识别出与种族和性别相关的方向，并在推理时应用仿射概念编辑。尽管使用了来自简单合成数据集的方向，但这种干预措施具有强大的泛化能力，始终将偏见降低到非常低的水平（通常低于1%，始终低于2.5%），同时基本保持了模型性能。我们的研究结果表明，部署LLM进行招聘的从业者应采用更现实的评估方法，并考虑内部缓解策略以实现公平结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [508] [Developing a High-performance Framework for Speech Emotion Recognition in Naturalistic Conditions Challenge for Emotional Attribute Prediction](https://arxiv.org/abs/2506.10930)
> *开发一个用于自然条件下语音情感识别的高性能框架——情感属性预测的挑战*

*Thanathai Lertpetchpun, Tiantian Feng, Dani Byrd, Shrikanth Narayanan* | **Main category: cs.LG**

**Keywords:** 语音情感识别, 多模态学习, 多任务学习, 不平衡数据, IS25-SER

**Comment:** 

> **TL;DR:** 本文提出一个高性能框架，通过多模态、多任务学习和不平衡数据处理，在自然条件下的语音情感识别挑战赛（IS25-SER）中获得第一名。

**AI_Comments:** 该论文提出了一种有效的语音情感识别框架，创新性地结合了多模态和多任务学习，并解决了自然条件下SER常见的标注不一致和数据不平衡问题。其在IS25-SER挑战赛中取得的优异成绩证明了方法的有效性，尤其是通过集成学习获得最佳性能，显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在自然条件下进行语音情感识别（SER）对语音处理领域提出了重大挑战，主要问题包括标注者之间标签不一致和数据分布不平衡。

**Method:** 本文通过多模态学习、多任务学习和不平衡数据处理来解决挑战。具体方法包括添加文本嵌入、预测性别以及在训练集中包含“Other”（O）和“No Agreement”（X）样本。最佳性能通过一个简单的两系统集成实现。

**Result:** 该系统在IS25-SER挑战赛中获得了第一名和第二名，其中最佳性能通过一个简单的两系统集成实现，并在MSP-Podcast数据集上进行了评估。

**Conclusion:** 所提出的框架在自然条件下的语音情感识别方面表现出色，有效解决了标注不一致和数据不平衡等挑战。

> **ai_Abstract:** 本文针对自然条件下语音情感识别（SER）面临的标签不一致和数据不平衡等挑战，提出了一种高性能、可复现的SER框架。该框架结合了多模态学习、多任务学习和不平衡数据处理技术，并通过添加文本嵌入、预测性别以及利用“Other”和“No Agreement”样本进行训练优化。实验结果表明，该系统在IS25-SER挑战赛中表现卓越，获得了第一名和第二名，最佳性能通过简单的两系统集成实现。

> **摘要翻译:** 自然条件下的语音情感识别（SER）对语音处理领域提出了重大挑战。挑战包括标注者之间的标签分歧和不平衡的数据分布。本文提出了一个可复现的框架，在自然条件下情感识别挑战赛（IS25-SER Challenge）——任务2中取得了卓越（前1名）的性能，并在MSP-Podcast数据集上进行了评估。我们的系统旨在通过多模态学习、多任务学习和不平衡数据处理来应对上述挑战。具体而言，我们最好的系统通过添加文本嵌入、预测性别以及在训练集中包含“Other”（O）和“No Agreement”（X）样本进行训练。我们的系统结果在IS25-SER挑战赛中获得了第一名和第二名，最佳性能通过一个简单的两系统集成实现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Self-Adapting Language Models](https://arxiv.org/abs/2506.10943)
> *自适应语言模型*

*Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, Pulkit Agrawal* | **Main category: cs.LG**

**Keywords:** 自适应语言模型, LLM, 微调, 强化学习, 自编辑

**Comment:** 

> **TL;DR:** SEAL是一个使大型语言模型能够通过生成微调数据和更新指令来自适应的框架，通过监督微调实现持久更新，并通过强化学习进行训练。

**AI_Comments:** SEAL的创新之处在于其“自编辑”机制，允许LLMs直接生成并利用微调数据和更新指令，实现自我适应，而无需外部模块。这代表了LLMs发展的一个重要方向，即从静态模型转向更具动态性和自主学习能力的模型。其结合SFT和RL的训练范式也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）功能强大但静态，缺乏根据新任务、知识或示例调整其权重的机制。

**Method:** SEAL框架通过让LLMs生成自己的微调数据和更新指令来实现自适应。模型对新输入生成“自编辑”，这可能包括信息重组、指定优化超参数或调用工具进行数据增强和基于梯度的更新。通过监督微调（SFT），这些自编辑导致持久的权重更新。为了训练模型生成有效的自编辑，使用强化学习循环，以下游模型的性能作为奖励信号。与以往方法不同，SEAL直接使用模型自身的生成来控制其适应过程。

**Result:** 在知识整合和少样本泛化方面的实验表明，SEAL是迈向能够自我导向适应的语言模型的一个有前景的步骤。

**Conclusion:** SEAL框架通过使LLMs能够生成和利用自编辑来实现自适应，并在知识整合和少样本泛化方面显示出潜力，是实现自我导向适应语言模型的重要一步。

> **ai_Abstract:** 本文提出了自适应语言模型（SEAL）框架，旨在解决大型语言模型（LLMs）静态、无法适应新信息的问题。SEAL允许LLMs通过生成“自编辑”（包括微调数据和更新指令）来动态调整自身权重。这些自编辑通过监督微调（SFT）实现持久更新，并通过强化学习（RL）进行训练，以优化下游任务性能。与现有方法不同，SEAL直接利用模型自身生成来控制适应过程。实验证明，SEAL在知识整合和少样本泛化方面表现出良好前景，是实现自我导向适应LLMs的重要进展。

> **摘要翻译:** 大型语言模型（LLMs）功能强大但静态；它们缺乏根据新任务、知识或示例调整其权重的机制。我们引入了自适应LLMs（SEAL），这是一个使LLMs能够通过生成自己的微调数据和更新指令来自适应的框架。给定一个新的输入，模型会产生一个自编辑——一个可能以不同方式重组信息、指定优化超参数或调用工具进行数据增强和基于梯度的更新的生成。通过监督微调（SFT），这些自编辑导致持久的权重更新，从而实现持久适应。为了训练模型产生有效的自编辑，我们使用强化学习循环，以下游更新模型的性能作为奖励信号。与以往依赖单独适应模块或辅助网络的方法不同，SEAL直接使用模型自身的生成来控制其适应过程。在知识整合和少样本泛化方面的实验表明，SEAL是迈向能够自我导向适应的语言模型的一个有前景的步骤。我们的网站和代码可在https://jyopari.github.io/posts/seal获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [512] [GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models](https://arxiv.org/abs/2506.10946)
> *GUARD：基于数据归因的大语言模型引导式遗忘与保留*

*Evelyn Ma, Duo Zhou, Peizhi Niu, Huiting Zhou, Huan Zhang, Olgica Milenkovic, S. Rasoul Etesami* | **Main category: cs.LG**

**Keywords:** 大语言模型遗忘, 数据归因, 效用保留, 意外遗忘, GUARD

**Comment:** 

> **TL;DR:** GUARD是一个新颖的框架，通过数据归因解决大语言模型中遗忘特定数据时意外损害模型效用和有用信息保留的问题，显著提高了模型效用保留。

**AI_Comments:** GUARD的创新点在于其引入了数据归因的概念来指导大语言模型的遗忘过程，并设计了自适应的非均匀遗忘权重，这与以往主要关注架构创新的方法不同。这种数据层面的优化有效解决了意外遗忘问题，显著提升了模型在遗忘后对有用信息的保留能力，对于LLM在法规遵从和隐私保护方面的应用具有重要意义。其高达194.92%的效用牺牲减少是一个非常显著的成果。

<details>
  <summary>Details</summary>

**Motivation:** 由于法规遵从、版权保护和隐私问题，大语言模型（LLMs）中的遗忘变得日益重要。然而，LLM遗忘的一个关键挑战是意外遗忘，即特定数据的移除无意中损害了模型的效用及其对有价值信息的保留。现有方法主要关注架构创新，但对数据层面因素的探索不足，导致在遗忘高影响数据时经常出现保留性能下降的问题。

**Method:** 我们提出了GUARD——一个通过数据归因实现引导式遗忘和保留的新颖框架。GUARD的核心是引入了一个轻量级的代理数据归因度量，该度量专门为LLM遗忘定制，用于量化遗忘集和保留集之间的“对齐”，同时保持计算效率。在此基础上，我们设计了一个新的遗忘目标，该目标根据样本的代理归因分数，以反比关系为其分配自适应的非均匀遗忘权重。通过这种遗忘能力的重新分配，GUARD减轻了保留中的意外损失。

**Result:** 我们提供了严格的理论保证，证明GUARD显著增强了保留，同时保持了与现有方法相当的遗忘指标。在TOFU基准测试和多种LLM架构上的广泛实验表明，GUARD在确保有效遗忘的同时，大幅提高了效用保留。值得注意的是，当遗忘10%的训练数据时，GUARD在保留集上的效用牺牲（以真实性比率衡量）减少了高达194.92%。

**Conclusion:** GUARD通过引入轻量级代理数据归因度量和自适应的非均匀遗忘权重，有效解决了大语言模型遗忘中意外遗忘的问题，显著提高了模型在遗忘特定数据时的效用保留，同时保持了有效的遗忘性能。

> **ai_Abstract:** GUARD是一个新颖的框架，旨在解决大语言模型（LLMs）中遗忘特定数据时意外损害模型效用和有用信息保留的问题。它通过引入一个轻量级的数据归因度量来量化遗忘集和保留集之间的“对齐”，并设计了一个新的遗忘目标，根据此归因分数自适应地分配非均匀遗忘权重。这种方法有效减轻了意外遗忘，显著提高了LLMs的效用保留，同时保持了有效的遗忘性能，尤其在减少保留集上的效用牺牲方面表现突出。

> **摘要翻译:** 大语言模型（LLMs）中的遗忘由于法规遵从、版权保护和隐私问题而变得日益重要。然而，LLM遗忘的一个关键挑战是意外遗忘，即特定数据的移除无意中损害了模型的效用及其对有价值、所需信息的保留。虽然现有工作主要关注架构创新，但数据层面因素对遗忘性能的影响仍未得到充分探索。因此，现有方法在遗忘高影响数据时经常导致保留性能下降。为了解决这个问题，我们提出了GUARD——一个通过数据归因实现引导式遗忘和保留的新颖框架。GUARD的核心是引入了一个轻量级的代理数据归因度量，该度量专门为LLM遗忘定制，用于量化遗忘集和保留集之间的“对齐”，同时保持计算效率。在此基础上，我们设计了一个新的遗忘目标，该目标为样本分配自适应的非均匀遗忘权重，这些权重与它们的代理归因分数成反比。通过这种遗忘能力的重新分配，GUARD减轻了保留中的意外损失。我们提供了严格的理论保证，证明GUARD显著增强了保留，同时保持了与现有方法相当的遗忘指标。在TOFU基准测试和多种LLM架构上的广泛实验表明，GUARD在确保有效遗忘的同时，大幅提高了效用保留。值得注意的是，当遗忘10%的训练数据时，GUARD在保留集上的效用牺牲（以真实性比率衡量）减少了高达194.92%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [514] [Execution Guided Line-by-Line Code Generation](https://arxiv.org/abs/2506.10948)
> *执行引导的逐行代码生成*

*Boaz Lavon, Shahar Katz, Lior Wolf* | **Main category: cs.LG**

**Keywords:** 神经代码生成, 执行反馈, 大型语言模型, 逐行生成, 无分类器指导

**Comment:** 

> **TL;DR:** 本文提出了一种名为EG-CFG的新型神经代码生成方法，它在语言模型生成过程中实时融入执行信号，逐行指导代码生成，显著提升了性能，并在各种编码任务中取得了最先进的结果。

**AI_Comments:** 该论文的创新之处在于将实时执行反馈直接整合到大型语言模型的代码生成循环中，这模仿了人类程序员的调试和迭代过程。逐行反馈机制和对并行性的支持是其显著的优势，有望大幅提升生成代码的实用性和正确性。这代表了代码生成领域的一个重要进步，使其生成的解决方案更可靠。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大型语言模型（LLMs）在代码生成方面表现出色，但它们在推理过程中通常不利用执行反馈，而这正是人类程序员经常利用的关键信号，限制了其生成可执行代码的能力。

**Method:** 本文提出的Execution-Guided Classifier-Free Guidance (EG-CFG) 方法动态地将执行信号整合到模型生成代码的过程中，提供逐行反馈。该方法包括多阶段过程：首先，进行束搜索以采样每行的候选程序补全；其次，通过针对测试用例执行这些候选来提取执行信号；最后，在生成过程中将这些信号整合到提示中。通过在同一行内的不同token之间保持一致的信号并在行边界刷新信号，该方法提供了连贯的指导，同时保留了句法结构。此外，它自然支持任务级别的原生并行性。

**Result:** 实验表明，EG-CFG 方法与标准方法相比，显著提高了代码生成性能，并在从基础问题到具有挑战性的竞争性编程任务的各种复杂程度中取得了最先进的结果。

**Conclusion:** 通过在语言模型生成过程中逐行整合实时执行信号，可以显著增强代码生成性能，使其更接近人类程序员的实践。

> **ai_Abstract:** 本文提出了一种名为Execution-Guided Classifier-Free Guidance (EG-CFG) 的新型神经代码生成方法，旨在解决大型语言模型在代码生成时缺乏实时执行反馈的问题。EG-CFG通过一个多阶段过程，包括束搜索生成候选、执行候选以提取信号，并将这些信号动态整合到生成提示中，从而实现逐行指导。该方法在保持语法结构的同时提供连贯的指导，并支持并行探索。实验证明，EG-CFG在多种编码任务中显著优于传统方法，并在不同复杂程度的任务中达到了最先进的性能。

> **摘要翻译:** 我们提出了一种新颖的神经代码生成方法，该方法将实时执行信号整合到语言模型生成过程中。虽然大型语言模型（LLM）已展示出令人印象深刻的代码生成能力，但它们在推理过程中通常不利用执行反馈，而这正是人类程序员经常利用的关键信号。我们的方法，执行引导的无分类器指导（EG-CFG），在模型生成代码时动态地整合执行信号，提供逐行反馈，引导生成过程趋向于可执行的解决方案。EG-CFG 采用多阶段过程：首先，我们进行束搜索以采样每行的候选程序补全；其次，我们通过针对测试用例执行这些候选来提取执行信号；最后，我们将这些信号整合到生成过程中的提示中。通过在同一行内的不同token之间保持一致的信号并在行边界刷新信号，我们的方法提供了连贯的指导，同时保留了句法结构。此外，该方法自然支持任务级别的原生并行性，其中多个代理并行操作，探索不同的推理路径并共同生成广泛的候选解决方案。我们在各种编码任务上的实验表明，与标准方法相比，EG-CFG 显著提高了代码生成性能，在从基础问题到具有挑战性的竞争性编程任务的各种复杂程度上都取得了最先进的结果。我们的代码可在以下网址获取：https://github.com/boazlavon/eg_cfg

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [516] [Build the web for agents, not agents for the web](https://arxiv.org/abs/2506.10953)
> *为智能体构建网络，而非为网络构建智能体*

*Xing Han Lù, Gaurav Kamath, Marius Mosbach, Siva Reddy* | **Main category: cs.LG**

**Keywords:** 网络智能体, 大型语言模型, 智能体网络接口, 范式转变, 界面设计

**Comment:** 

> **TL;DR:** 本文提出了一种范式转变：与其让网络智能体适应为人类设计的界面，不如开发专门为智能体优化的交互范式，并引入了智能体网络接口（AWI）的概念。

**AI_Comments:** 这篇立场论文提出了一个非常新颖且重要的观点，即从“智能体适应网络”转变为“网络适应智能体”。AWI的概念及其六项设计原则为未来的网络智能体设计提供了清晰的方向，有望从根本上解决现有方法在复杂网页交互中的效率和可靠性问题。其强调的安全性、效率和标准化原则也考虑到了实际应用中的关键因素。

<details>
  <summary>Details</summary>

**Motivation:** 当前的网络智能体研究面临巨大挑战，因为为人类设计的网页界面与大型语言模型（LLM）的能力之间存在根本性不匹配，导致现有方法在处理复杂的网页输入时举步维艰。

**Method:** 本文提出了一种网络智能体研究的范式转变：不再强制网络智能体适应为人类设计的界面，而是开发一种专门为智能体能力优化的新型交互范式。为此，论文引入了智能体网络接口（AWI）的概念，这是一种专门为智能体导航网站而设计的界面，并为AWI设计建立了六项指导原则，强调安全性、效率和标准化。

**Result:** 作为一篇立场论文，其结果是提出了一个新概念和设计原则，旨在克服现有界面的基本局限性，为更高效、可靠和透明的网络智能体设计铺平道路。

**Conclusion:** 结论是，通过重新构建网络智能体的设计理念，即开发专门为智能体设计的界面（AWI），可以克服现有界面的局限性，从而实现更高效、可靠和透明的网络智能体设计，这将需要整个机器学习社区的协作努力。

> **ai_Abstract:** 本文针对当前网络智能体在人类设计界面中面临的挑战，提出了一种范式转变。作者认为，与其让智能体适应现有网页，不如构建专门为智能体优化的“智能体网络接口”（AWI）。论文提出了AWI的六项设计原则，旨在提高智能体与网络的交互效率、可靠性和透明度，并强调这是需要机器学习社区协作的未来方向。

> **摘要翻译:** 大型语言模型（LLM）和多模态对应物最近的进展激发了开发网络智能体——能够在网络环境中自主导航和完成任务的AI系统——的巨大兴趣。尽管在自动化复杂的网络交互方面前景广阔，但由于人类设计的界面与LLM能力之间存在根本性不匹配，当前的方法面临巨大挑战。现有方法在处理复杂的网络输入时举步维艰，无论是处理庞大的DOM树、依赖于增强额外信息的截图，还是通过API交互完全绕过用户界面。这篇立场论文倡导网络智能体研究的范式转变：与其强迫网络智能体适应为人类设计的界面，我们应该开发一种专门为智能体能力优化的新型交互范式。为此，我们引入了智能体网络接口（AWI）的概念，这是一种专门为智能体导航网站而设计的界面。我们为AWI设计建立了六项指导原则，强调安全性、效率和标准化，以兼顾所有主要利益相关者的利益。这种重新构建旨在克服现有界面的基本局限性，为更高效、可靠和透明的网络智能体设计铺平道路，这将是一项涉及更广泛机器学习社区的协作努力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [518] [ReGuidance: A Simple Diffusion Wrapper for Boosting Sample Quality on Hard Inverse Problems](https://arxiv.org/abs/2506.10955)
> *ReGuidance：一个用于提升困难逆问题样本质量的简单扩散包装器*

*Aayush Karan, Kulin Shah, Sitan Chen* | **Main category: cs.LG**

**Keywords:** 扩散模型, 逆问题, ReGuidance, 样本质量, DPS

**Comment:** 38 pages, 14 figures

> **TL;DR:** ReGuidance是一个简单的扩散模型包装器，通过逆转候选解并将其作为DPS的初始化，显著提升了在低信噪比困难逆问题中样本的真实性和奖励，并提供了理论保证。

**AI_Comments:** 这篇论文通过引入一个新颖的“反演-初始化”策略，有效解决了扩散模型在处理困难逆问题时可能出现的样本真实性下降问题。其创新点在于将无条件概率流ODE的反向运行与DPS相结合，为现有方法提供了有效的改进方案。此外，提供了理论证明，增强了其方法的说服力，填补了DPS在理论保证方面的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于扩散模型的训练无关方法（如DPS）在面对低信噪比的困难逆问题时，由于奖励信息不足，容易偏离数据流形，导致无法生成真实的输出。

**Method:** 提出ReGuidance，一个简单的包装器。给定用户选择算法生成的候选解$\hat{x}$，通过从$\hat{x}$开始反向运行无条件概率流ODE来反演该解，然后将得到的潜在变量作为DPS的初始化。

**Result:** 在大型方框图像修复和高放大倍数超分辨率等困难逆问题上，当现有最先进的基线方法明显失败时，ReGuidance显著提升了样本质量和测量一致性。理论上证明，在某些多模态数据分布上，ReGuidance同时提升了奖励并将候选解拉近数据流形。

**Conclusion:** ReGuidance通过其独特的反演和初始化策略，有效解决了扩散模型在困难逆问题中生成不真实输出的问题，并提供了首个关于DPS的严格算法保证，显著提升了样本质量和测量一致性。

> **ai_Abstract:** ReGuidance是一个针对扩散模型的简单包装器，旨在解决在低信噪比困难逆问题中，现有训练无关方法（如DPS）生成不真实输出的问题。它通过反演候选解并将其潜在变量作为DPS的初始化来提升样本真实性和奖励。实验证明，ReGuidance在图像修复和超分辨率等任务上显著优于现有基线，并提供了理论保证，是DPS的首个严格算法保证。

> **摘要翻译:** 关于使用预训练扩散模型作为解决逆问题的先验数据，以及更广泛地使用奖励模型引导这些模型的研究活动非常活跃。像扩散后验采样（DPS）及其许多变体等无需训练的方法为这些任务提供了灵活的启发式算法，但当奖励信息不足时，例如在低信噪比的困难逆问题中，这些技术会偏离数据流形，无法产生真实的输出。在这项工作中，我们设计了一个简单的包装器ReGuidance，用于提升这些方法的样本真实性和所获得的奖励。给定用户选择的算法生成的候选解$\hat{x}$，我们建议通过从$\hat{x}$开始反向运行无条件概率流ODE来反演该解，然后将得到的潜在变量作为DPS的初始化。我们在大型方框图像修复和高放大倍数超分辨率等困难逆问题上评估了我们的包装器。当最先进的基线方法明显失败时，我们发现将我们的包装器应用于这些基线之上显著提升了样本质量和测量一致性。我们通过理论补充了这些发现，证明在某些多模态数据分布上，ReGuidance同时提升了奖励并将候选解拉近数据流形。据我们所知，这构成了DPS的第一个严格算法保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [520] [Understanding In-Context Learning on Structured Manifolds: Bridging Attention to Kernel Methods](https://arxiv.org/abs/2506.10959)
> *理解结构化流形上的上下文学习：连接注意力与核方法*

*Zhaiming Shen, Alexander Hsu, Rongjie Lai, Wenjing Liao* | **Main category: cs.LG**

**Keywords:** 上下文学习, 结构化流形, 注意力机制, 核方法, 泛化误差

**Comment:** 

> **TL;DR:** 本文首次对结构化几何数据上的上下文学习（ICL）进行了理论研究，通过建立注意力机制与经典核方法的新连接，推导了泛化误差界限。研究发现，当训练任务充足时，Transformer在流形上对H"older函数回归可达到最优速率，其误差与流形内在维度而非环境空间维度呈指数关系，为理解ICL中的几何作用和Transformer的复杂性提供了见解。

**AI_Comments:** 这项工作具有重要的理论意义，它首次将ICL的理论研究扩展到结构化几何数据，并通过连接注意力机制和核方法提供了新的分析工具。其关于泛化误差与内在维度相关的发现尤其创新，为理解Transformer在复杂数据上的学习能力提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著成功，但其理论理解，特别是在结构化几何数据背景下，仍未被探索。

**Method:** 本文通过建立注意力机制与经典核方法之间的新颖联系，对流形上H"older函数的回归上下文学习（ICL）进行了理论研究，并推导了基于提示长度和训练任务数量的泛化误差界限。

**Result:** 1. 当观察到足够多的训练任务时，Transformer在流形上对H"older函数回归可达到极小极大回归率。2. 该回归率与流形的内在维度呈指数关系，而非环境空间维度。3. 研究结果还描述了泛化误差如何随训练任务数量的变化而变化，从而揭示了Transformer作为上下文算法学习器的复杂性。

**Conclusion:** 本研究的发现为几何在上下文学习（ICL）中的作用提供了基础性见解，并为研究非线性模型的ICL提供了新工具。

> **ai_Abstract:** 本文首次对结构化几何数据上的上下文学习（ICL）进行了理论探索，特别是针对流形上H"older函数的回归问题。研究通过将注意力机制与经典核方法相结合，推导了ICL的泛化误差界限。结果表明，当有足够训练任务时，Transformer能够达到流形上H"older函数的极小极大回归率，且该速率的缩放与流形的内在维度而非环境空间维度相关。这些发现不仅揭示了ICL中几何的作用，也为理解Transformer作为上下文算法学习器的复杂性提供了深入见解。

> **摘要翻译:** 尽管上下文学习（ICL）在自然语言和视觉领域取得了显著成功，但其理论理解——特别是在结构化几何数据背景下——仍未被探索。在这项工作中，我们对流形上H"older函数的回归ICL进行了理论研究。通过建立注意力机制与经典核方法之间的新颖联系，我们推导了关于提示长度和训练任务数量的泛化误差界限。当观察到足够多的训练任务时，Transformer能够达到流形上H"older函数的极小极大回归率，该速率与流形的内在维度呈指数关系，而非环境空间维度。我们的结果还描述了泛化误差如何随训练任务数量的变化而变化，从而揭示了Transformer作为上下文算法学习器的复杂性。我们的发现为几何在ICL中的作用提供了基础性见解，并为研究非线性模型的ICL提供了新工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [522] [Farseer: A Refined Scaling Law in Large Language Models](https://arxiv.org/abs/2506.10972)
> *Farseer: 大型语言模型中的一种改进的缩放定律*

*Houyi Li, Wenzhen Zheng, Qiufeng Wang, Zhenyu Ding, Haoying Wang, Zili Wang, Shijie Xuyang, Ning Ding, Shuigeng Zhou, Xiangyu Zhang, Daxin Jiang* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 缩放定律, Farseer, 预测准确性, 计算优化

**Comment:** 34

> **TL;DR:** 本文提出了Farseer，一种改进的LLM缩放定律，显著提高了预测准确性，减少了外推误差，有助于高效创新和计算优化。

**AI_Comments:** Farseer的创新在于其通过构建损失表面L(N,D)来提供更精确的LLM缩放定律，显著优于现有方法。其重要性在于能够降低LLM训练的试错成本，加速创新，并优化资源分配。通过开源所有数据，该研究也极大地促进了社区的进一步探索。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型（LLMs）成本极高，导致小规模实验的见解难以推广到资源密集型生产系统，从而阻碍了高效创新。

**Method:** 本文引入了Farseer，一种新的改进缩放定律，通过系统地构建模型损失表面L(N,D)来提高预测准确性。为验证方法，研究人员训练了大约1000个不同规模和配置的LLM，并开源了所有模型、数据、结果和日志。

**Result:** Farseer比现有定律（如Chinchilla定律）与经验数据拟合得显著更好，将外推误差减少了433%。它能够可靠地评估各种训练策略，将小规模研究结论推广到大规模性能预测，并为最佳计算分配提供新见解。

**Conclusion:** Farseer提供了一种更准确、鲁棒和可泛化的缩放定律，能够将小规模研究结论自信地推广到大规模性能预测，从而促进LLM训练的创新和优化。

> **ai_Abstract:** 本文引入了Farseer，一种用于大型语言模型（LLM）的新型改进缩放定律，旨在弥补小规模实验与大规模生产系统之间的缩放差距。Farseer通过构建模型损失表面L(N,D)显著提高了预测准确性，比现有定律（如Chinchilla定律）更符合经验数据，并将外推误差减少了433%。该方法能够可靠地评估各种训练策略，并将小规模研究结果自信地推广到大规模性能预测，同时为优化计算分配提供了新见解。为验证Farseer，研究人员训练了约1000个LLM，并全面开源了所有相关数据。

> **摘要翻译:** 训练大型语言模型（LLMs）成本极高，造成了一个关键的缩放差距，即小规模实验的见解往往无法转移到资源密集型生产系统，从而阻碍了高效创新。为了弥补这一差距，我们引入了Farseer，一种新颖且经过改进的缩放定律，能够在不同规模上提供更高的预测准确性。通过系统地构建模型损失表面L(N,D)，Farseer比先前的定律（例如Chinchilla定律）与经验数据拟合得显著更好。我们的方法产生了准确、鲁棒且高度可泛化的预测，展示了出色的外推能力，通过将外推误差减少433%来改进Chinchilla定律。这使得能够可靠地评估所有(N,D)设置下的竞争性训练策略，从而使小规模消融研究的结论能够自信地外推以预测大规模性能。此外，Farseer为最佳计算分配提供了新的见解，更好地反映了现代LLM训练的细微需求。为了验证我们的方法，我们训练了大约1000个不同规模和配置的LLM，消耗了大约300万NVIDIA H100 GPU小时。我们正在全面开源所有模型、数据、结果和日志，网址为https://github.com/Farseer-Scaling-Law/Farseer，以促进进一步的研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [525] [Rethinking Losses for Diffusion Bridge Samplers](https://arxiv.org/abs/2506.10982)
> *重新思考扩散桥采样器的损失函数*

*Sebastian Sanokowski, Lukas Gruber, Christoph Bartmann, Sepp Hochreiter, Sebastian Lehner* | **Main category: cs.LG**

**Keywords:** 扩散桥, 损失函数, rKL损失, 对数方差损失, 采样器

**Comment:** 

> **TL;DR:** 对于扩散桥采样器，带有对数导数技巧的rKL损失（rKL-LD）在概念上更合理，并且在实验中始终优于对数方差（LV）损失，从而实现更好、更稳定的训练。

**AI_Comments:** 这篇论文通过重新评估扩散桥采样器中损失函数的理论基础和实际性能，做出了重要贡献。它挑战了关于LV损失优越性的普遍假设，并提供了一种理论上更健全、经验上更有效的替代方案（rKL-LD）。关于提高稳定性和减少超参数优化的发现对于实际应用尤其有价值。

<details>
  <summary>Details</summary>

**Motivation:** 最近的研究表明，在扩散采样器中，对数方差（LV）损失的表现优于反向Kullback-Leibler（rKL）损失。然而，本文指出，LV和rKL之间的等价性（在使用对数导数技巧时）不适用于扩散桥或当扩散系数可学习时。作者认为，对于扩散桥，LV损失缺乏像rKL损失那样可以通过数据处理不等式进行激励的优化目标。

**Method:** 作者分析了扩散桥中LV损失的概念性问题，并提出采用带有对数导数技巧的rKL损失（rKL-LD）。他们通过在具有挑战性的基准上对不同类型的扩散桥进行实验来验证其方法的有效性。

**Result:** 实验结果表明，rKL-LD损失始终优于LV损失。使用rKL-LD损失训练的采样器实现了更好的性能，需要显著更少的超参数优化，并产生了更稳定的训练行为。

**Conclusion:** 对于扩散桥采样器，rKL-LD损失在概念上更为合理，并且在实践中优于LV损失，从而提高了性能和稳定性。

> **ai_Abstract:** 本文重新评估了扩散桥采样器的损失函数，挑战了对数方差（LV）损失优于反向Kullback-Leibler（rKL）损失的普遍看法。作者认为，LV和rKL之间的理论等价性不适用于扩散桥，并且LV在此背景下缺乏适当的概念性动机。他们的分析表明，使用带有对数导数技巧的rKL损失（rKL-LD）不仅解决了这些概念性问题，而且在各种基准测试中，始终能为扩散桥采样器带来更优的性能、更少的超参数调优和更稳定的训练。

> **摘要翻译:** 扩散桥是一类很有前景的深度学习方法，用于从非归一化分布中采样。最近的研究表明，当使用重参数化技巧计算rKL梯度时，对数方差（LV）损失始终优于反向Kullback-Leibler（rKL）损失。虽然当结合对数导数技巧用于具有不可学习前向过程的扩散采样器时，on-policy的LV损失会产生与rKL损失相同的梯度，但这种等价性不适用于扩散桥或当扩散系数可学习时。基于这一见解，我们认为对于扩散桥，LV损失不能像rKL损失那样通过数据处理不等式来激励。我们的分析表明，采用对数导数技巧的rKL损失（rKL-LD）不仅避免了这些概念性问题，而且始终优于LV损失。在具有挑战性的基准上，对不同类型扩散桥的实验结果表明，使用rKL-LD损失训练的采样器取得了更好的性能。从实践角度来看，我们发现rKL-LD需要显著更少的超参数优化，并产生更稳定的训练行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [5] [AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation](https://arxiv.org/abs/2506.10540)
> *AniMaker：MCTS驱动片段生成的自动化多智能体动画故事创作*

*Haoyuan Shi, Yunxin Li, Xinyu Chen, Longyue Wang, Baotian Hu, Min Zhang* | **Main category: cs.MA**

**Keywords:** 多智能体, 动画故事创作, MCTS, 视频生成, 故事连贯性

**Comment:** 

> **TL;DR:** AniMaker是一个多智能体框架，利用MCTS驱动的片段生成和故事感知的片段选择，从文本输入自动创建连贯的多场景动画故事，解决了现有视频生成模型在故事连贯性和视觉连续性方面的挑战。

**AI_Comments:** AniMaker的创新之处在于其多智能体协作框架和引入MCTS-Gen进行智能片段生成，以及AniEval作为首个多镜头动画评估框架。这解决了现有方法在叙事连贯性和视觉连续性上的痛点，显著提升了AI生成动画的质量和实用性，推动了该领域向生产级应用迈进。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视频生成模型快速发展，但生成跨多个场景和角色的连贯叙事视频仍然具有挑战性。现有方法常将预生成关键帧僵化地转换为固定长度片段，导致叙事脱节和节奏问题。此外，视频生成模型固有的不稳定性意味着即使单个低质量片段也可能显著降低整个输出动画的逻辑连贯性和视觉连续性。

**Method:** 我们引入了AniMaker，一个多智能体框架，能够实现高效的多候选片段生成和故事感知片段选择，仅从文本输入创建全局一致且故事连贯的动画。该框架围绕专门的智能体构建，包括用于故事板生成的导演智能体、用于视频片段生成的摄影智能体、用于评估的评审智能体以及用于编辑和画外音的后期制作智能体。AniMaker方法的核心是两个关键技术组件：摄影智能体中的MCTS-Gen，一种受蒙特卡洛树搜索（MCTS）启发的高效策略，可智能地探索候选空间以生成高潜力片段并优化资源使用；以及评审智能体中的AniEval，第一个专门为多镜头动画评估设计的框架，通过考虑每个片段在其前置和后置片段的上下文来评估故事层级一致性、动作完成度和动画特定特征等关键方面。

**Result:** 实验表明，AniMaker在VBench和我们提出的AniEval框架等流行指标下取得了卓越的质量，同时显著提高了多候选生成的效率。

**Conclusion:** AniMaker通过其多智能体框架和创新的MCTS-Gen及AniEval组件，有效地克服了当前视频生成在故事连贯性和视觉连续性上的挑战，使AI生成的故事动画更接近生产标准。

> **ai_Abstract:** AniMaker是一个创新的多智能体框架，旨在解决现有视频生成模型在创建连贯多场景动画故事时面临的挑战。它通过引入专门的智能体（导演、摄影、评审、后期制作）来管理从故事板到最终编辑的整个流程。核心技术包括MCTS-Gen，用于高效生成高质量视频片段，以及AniEval，一个专门用于评估多镜头动画故事连贯性和视觉连续性的框架。实验证明AniMaker在质量和效率上均表现出色，使AI生成的动画故事更接近专业标准。

> **摘要翻译:** 尽管视频生成模型取得了快速进展，但生成跨多个场景和角色的连贯叙事视频仍然具有挑战性。当前方法通常将预生成的关键帧僵化地转换为固定长度片段，导致叙事脱节和节奏问题。此外，视频生成模型固有的不稳定性意味着即使单个低质量片段也可能显著降低整个输出动画的逻辑连贯性和视觉连续性。为了克服这些障碍，我们引入了AniMaker，一个多智能体框架，能够实现高效的多候选片段生成和故事感知片段选择，从而仅从文本输入创建全局一致且故事连贯的动画。该框架围绕专门的智能体构建，包括用于故事板生成的导演智能体、用于视频片段生成的摄影智能体、用于评估的评审智能体以及用于编辑和画外音的后期制作智能体。AniMaker方法的核心是两个关键技术组件：摄影智能体中的MCTS-Gen，一种受蒙特卡洛树搜索（MCTS）启发的高效策略，可智能地探索候选空间以生成高潜力片段并优化资源使用；以及评审智能体中的AniEval，第一个专门为多镜头动画评估设计的框架，通过考虑每个片段在其前置和后置片段的上下文来评估故事层级一致性、动作完成度和动画特定特征等关键方面。实验表明，AniMaker在VBench和我们提出的AniEval框架等流行指标下取得了卓越的质量，同时显著提高了多候选生成的效率，推动AI生成的故事动画更接近生产标准。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [32] [Higher-Order Uncoupled Learning Dynamics and Nash Equilibrium](https://arxiv.org/abs/2506.10874)
> *高阶非耦合学习动力学与纳什均衡*

*Sarah A. Toonsi, Jeff S. Shamma* | **Main category: cs.MA**

**Keywords:** 纳什均衡, 高阶学习动力学, 非耦合学习, 反馈稳定, 渐近最优响应

**Comment:** 

> **TL;DR:** 研究了在高阶非耦合学习动力学下有限博弈中混合策略纳什均衡的可学习性，并揭示了学习动力学的普适性限制。

**AI_Comments:** 这篇论文的创新点在于引入了“高阶非耦合学习动力学”的概念，允许玩家在不直接了解对手效用的情况下使用辅助状态处理信息。它通过建立与控制理论的联系，不仅证明了某些NE的可学习性，也揭示了学习动力学在普适性上的局限性，这对于理解复杂博弈中的学习行为具有重要意义。引入ABR特性提供了一种分析学习动力学内部稳定性的新视角。

<details>
  <summary>Details</summary>

**Motivation:** 研究在一般有限博弈中混合策略纳什均衡（NE）的可学习性，尤其是在高阶非耦合异构动力学和高阶复制器动力学下。此外，还引入了渐近最优响应（ABR）特性，以对允许的学习动力学施加自然限制。

**Method:** 使用高阶复制器动力学和高阶非耦合异构动力学。建立非耦合学习与分散控制下的反馈稳定之间的联系。利用控制理论中的同步稳定概念来探讨学习动力学的普适性。引入渐近最优响应（ABR）特性。在强盗设置中使用高阶复制器动力学的强盗版本研究可学习性。

**Result:** 对于任何具有孤立完全混合策略NE的有限博弈，存在导致该NE的高阶非耦合学习动力学（局部）。通过与同步稳定的联系，揭示了学习动力学缺乏普适性。构建了两个博弈，证明任何学习其中一个博弈NE的高阶动力学无法学习另一个的NE。ABR特性与高阶学习动力学的内部稳定性条件相关。提供了NE与ABR特性兼容的条件。在强盗设置中讨论了混合策略NE的可学习性。

**Conclusion:** 论文研究了高阶非耦合学习动力学下混合策略纳什均衡的可学习性，证明了其存在性但缺乏普适性，并引入了渐近最优响应特性来分析学习动力学的内部稳定性。

> **ai_Abstract:** 本文探讨了在一般有限博弈中，高阶非耦合学习动力学下混合策略纳什均衡（NE）的可学习性。研究建立了非耦合学习与分散控制中反馈稳定的联系，证明了对于孤立完全混合策略NE，存在相应的局部收敛高阶非耦合学习动力学。同时，论文指出学习动力学缺乏普适性，并引入了渐近最优响应（ABR）特性来分析学习动力学的内部稳定性，最后在强盗设置中探讨了NE的可学习性。

> **摘要翻译:** 我们研究了在一般有限博弈中，使用高阶复制器动力学以及高阶非耦合异构动力学类别下混合策略纳什均衡（NE）的可学习性。在高阶非耦合学习动力学中，玩家无法访问对手的效用（非耦合），但被允许使用辅助状态来进一步处理信息（高阶）。我们建立了非耦合学习与分散控制下的反馈稳定之间的联系。利用这种关联，我们表明对于任何具有孤立完全混合策略NE的有限博弈，存在导致（局部）该NE的高阶非耦合学习动力学。我们通过将学习与控制理论中的同步稳定概念联系起来，进一步确立了学习动力学缺乏普适性。我们构建了两个博弈，使得任何学习其中一个博弈的完全混合策略NE的高阶动力学永远无法学习另一个博弈的完全混合策略NE。接下来，为了对允许的学习动力学施加自然限制，我们引入了渐近最优响应（ABR）特性。具有ABR特性的动力学在渐近静止的环境中渐近地学习最优响应。我们表明ABR特性与高阶学习动力学的内部稳定性条件相关。我们提供了NE与ABR特性兼容的条件。最后，我们使用高阶复制器动力学的强盗版本，解决了强盗设置中混合策略NE的可学习性问题。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [8] [Leveraging LLMs for Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10093)
> *利用大型语言模型进行精准农业任务规划*

*Marcos Abel Zuzuárregui, Stefano Carpin* | **Main category: cs.RO**

**Keywords:** LLMs, 精准农业, 机器人技术, 任务规划, 自然语言

**Comment:** Published in Proceedings of 2025 International Conference on Robotics
  and Automation (ICRA)

> **TL;DR:** 本文提出一个端到端系统，利用大型语言模型（LLMs，特别是ChatGPT）使非技术用户能够通过自然语言指令为精准农业中的自主机器人分配复杂的任务。该系统将任务计划编码为IEEE标准，并通过ROS2执行，并探讨了LLMs在此背景下的优缺点。

**AI_Comments:** 该论文提出了一种创新方法，通过利用LLMs弥合了精准农业中复杂机器人系统与非技术终端用户之间的鸿沟。使用自然语言接口和遵循IEEE标准以实现可重用性是其主要优势。它还批判性地评估了LLMs在空间推理和路径规划方面的局限性，并提供了解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 精准农业中的终端用户通常缺乏技术专长，这使得机器人系统难以适应执行多样化的任务。本研究的动机是使非技术用户能够使用自然语言指令向自主机器人分配复杂的数据收集任务。

**Method:** 该论文提出了一个端到端系统，该系统利用大型语言模型（LLMs），特别是ChatGPT，将自然语言指令转换为自主机器人的复杂数据收集任务。为了提高可重用性，任务计划使用现有的IEEE任务规范标准进行编码，并通过ROS2节点在机器人上执行，这些节点将高级任务描述与现有ROS库连接起来。

**Result:** 通过广泛的实验，该研究强调了LLMs在此背景下的优点和局限性，特别是在空间推理和解决复杂路径规划挑战方面，并展示了所提出的实现如何克服这些局限性。

**Conclusion:** 本文成功展示了一个利用LLMs的系统，该系统使非技术用户能够通过自然语言控制农业机器人，并有效解决了空间推理和路径规划方面的挑战。

> **ai_Abstract:** 本文介绍了一个端到端系统，该系统利用大型语言模型（LLMs），特别是ChatGPT，简化了精准农业中自主机器人的任务规划。它允许非技术用户使用自然语言分配复杂的数据收集任务。该系统使用IEEE标准编码任务计划以提高可重用性，并通过ROS2执行。实验证明了该系统利用LLMs的能力，同时解决了它们在空间推理和路径规划方面的局限性。

> **摘要翻译:** 机器人技术和人工智能在推动精准农业方面具有巨大潜力。虽然机器人系统已成功部署用于各种任务，但使其适应执行多样化任务仍然具有挑战性，特别是由于最终用户通常缺乏技术专长。在本文中，我们提出了一个端到端系统，该系统利用大型语言模型（LLM），特别是ChatGPT，使用户能够通过自然语言指令将复杂的数据收集任务分配给自主机器人。为了提高可重用性，任务计划使用现有的IEEE任务规范标准进行编码，并通过ROS2节点在机器人上执行，这些节点将高级任务描述与现有ROS库连接起来。通过广泛的实验，我们强调了LLM在此背景下的优点和局限性，特别是在空间推理和解决复杂路径规划挑战方面，并展示了我们提出的实现如何克服这些问题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [35] [Estimating the Joint Probability of Scenario Parameters with Gaussian Mixture Copula Models](https://arxiv.org/abs/2506.10098)
> *使用高斯混合Copula模型估计场景参数的联合概率*

*Christian Reichenbächer, Philipp Rank, Jochen Hipp, Oliver Bringmann* | **Main category: cs.RO**

**Keywords:** 高斯混合Copula模型, 场景参数, 联合概率, 自动驾驶, 安全验证

**Comment:** 8 pages, 4 figures; This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 本文首次将高斯混合Copula模型应用于自动驾驶系统安全验证中的驾驶场景统计建模，并证明其在数据拟合方面优于现有方法。

**AI_Comments:** 本文首次将高斯混合Copula模型应用于自动驾驶场景的统计建模，这一创新性应用结合了高斯混合模型处理多模态数据的优势和Copula模型分离边际分布与依赖结构的灵活性，有效提升了对复杂驾驶场景参数联合概率的估计精度。其在大量真实数据上的优异表现，对于基于场景的自动驾驶系统安全评估具有重要意义，有望成为未来验证框架的核心工具。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统安全验证中，场景参数的联合概率分布知识对于基于场景的安全评估至关重要，因为风险量化取决于具体参数组合的可能性。

**Method:** 本文首次将高斯混合Copula模型应用于自动驾驶系统的驾驶场景统计建模。该模型结合了高斯混合模型的多模态表达能力和Copula的灵活性，能够分别建模边际分布和依赖关系。通过使用来自联合国法规No. 157中定义的真实驾驶数据，将高斯混合Copula模型与先前提出的方法（高斯混合模型和高斯Copula模型）进行了基准测试。

**Result:** 在对1800万个场景实例的评估中，高斯混合Copula模型在似然性和Sinkhorn距离方面都提供了更好的数据拟合。

**Conclusion:** 这些结果表明，高斯混合Copula模型是未来基于场景的验证框架的有力基础。

> **ai_Abstract:** 本研究首次将高斯混合Copula模型应用于自动驾驶系统驾驶场景的统计建模，旨在解决场景参数联合概率分布估计的关键问题。该模型结合了高斯混合模型的表达能力和Copula的灵活性，实现了边际分布与依赖关系的独立建模。通过对1800万个真实驾驶场景实例的评估，结果显示高斯混合Copula模型在数据拟合方面优于传统的高斯混合模型和高斯Copula模型，为未来的场景验证框架提供了坚实基础。

> **摘要翻译:** 本文首次将高斯混合Copula模型应用于自动驾驶系统安全验证中的驾驶场景统计建模。场景参数联合概率分布的知识对于基于场景的安全评估至关重要，其中风险量化取决于具体参数组合的可能性。高斯混合Copula模型结合了高斯混合模型的多模态表达能力和Copula的灵活性，能够分别建模边际分布和依赖关系。我们使用来自联合国法规No. 157中定义的真实驾驶数据，将高斯混合Copula模型与先前提出的方法——高斯混合模型和高斯Copula模型——进行了基准测试。我们对1800万个场景实例的评估表明，高斯混合Copula模型在似然性和Sinkhorn距离方面都提供了更好的数据拟合。这些结果表明，高斯混合Copula模型是未来基于场景的验证框架的有力基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [60] [One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture](https://arxiv.org/abs/2506.10106)
> *一劳永逸：基于大型语言模型的精准农业异构任务规划*

*Marcos Abel Zuzuárregui, Mustafa Melih Toslak, Stefano Carpin* | **Main category: cs.RO**

**Keywords:** 精准农业, 异构机器人, 任务规划, 大型语言模型, 自然语言接口

**Comment:** Accepted to International Federation of Automatic Control (IFAC)
  Sensing, Control and Automation Technologies for Agriculture - 8th
  AGRICONTROL 2025

> **TL;DR:** 本文提出了一种基于大型语言模型（LLM）的自然语言机器人任务规划器，使非专业用户能够通过通用接口控制异构机器人，从而简化精准农业中的机器人自动化，并通过机器人操作和计算机视觉任务的实验证明了其通用性和强大性。

**AI_Comments:** 本文的创新之处在于利用大型语言模型（LLM）作为核心，实现了自然语言到异构机器人任务规划的无缝转换，极大地降低了非技术用户使用机器人技术的门槛。其重要性体现在推动精准农业的智能化和自动化普及，使得农民能够更便捷地利用先进技术。该方法通过统一接口和LLM的强大理解能力，有效解决了异构机器人控制的复杂性问题，对未来农业机器人的人机交互和系统集成具有重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 精准农业中的人工智能技术虽然提高了效率，但其引入的复杂性和陡峭的学习曲线对非技术用户构成了挑战，他们需要在技术采纳与现有工作量之间取得平衡。现有系统可能针对特定机器人类型（如轮式机器人）定制，缺乏对异构机器人和更复杂任务的通用支持。

**Method:** 本文提出了一种基于大型语言模型（LLM）和预定义原语的自然语言（NL）机器人任务规划器。该架构能将人类语言无缝转换为可由不同机器人平台执行的中间描述。该系统允许用户无需编写代码即可制定复杂的农业任务。作者扩展了之前针对轮式机器人任务规划的系统，通过引入机器人操作和计算机视觉任务的新类实验来验证其通用性。

**Result:** 该架构被证明足够通用，可以支持多样化的机器人集合，并且足够强大，可以执行复杂的任务请求。实验扩展到包括机器人操作和计算机视觉任务，验证了系统的能力。

**Conclusion:** 这项工作代表着使精准农业中的机器人自动化对非技术用户更易于访问的重要一步，通过一个通用的、基于LLM的自然语言接口实现了异构机器人的任务规划。

> **ai_Abstract:** 本文提出了一种基于大型语言模型（LLM）的自然语言机器人任务规划器，旨在解决精准农业中机器人技术对非技术用户造成的复杂性问题。该系统通过将人类语言转换为可执行的机器人指令，使得非专业人员能够通过单一接口控制异构机器人，无需编写代码即可规划复杂的农业任务。通过对机器人操作和计算机视觉任务的实验，研究证明了该架构的通用性和执行复杂任务的能力，从而显著提高了精准农业中机器人自动化的可访问性。

> **摘要翻译:** 人工智能正在改变精准农业，为农民提供了简化日常操作的新工具。虽然这些技术进步有望提高效率，但它们常常引入额外的复杂性和陡峭的学习曲线，这对非技术用户来说尤其具有挑战性，他们必须在技术采纳与现有工作量之间取得平衡。在本文中，我们提出了一种自然语言（NL）机器人任务规划器，使非专业人员能够通过通用接口控制异构机器人。通过利用大型语言模型（LLM）和预定义原语，我们的架构无缝地将人类语言翻译成可由不同机器人平台执行的中间描述。有了这个系统，用户无需编写任何代码即可制定复杂的农业任务。在本文中，我们通过涉及机器人操作和计算机视觉任务的新类实验，扩展了我们之前为轮式机器人任务规划量身定制的系统。我们的结果表明，该架构既足够通用以支持多样化的机器人集合，又足够强大以执行复杂的任务请求。这项工作代表着使精准农业中的机器人自动化对非技术用户更易于访问的重要一步。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [87] [A Navigation Framework Utilizing Vision-Language Models](https://arxiv.org/abs/2506.10172)
> *利用视觉-语言模型的导航框架*

*Yicheng Duan, Kaiyu tang* | **Main category: cs.RO**

**Keywords:** 视觉-语言导航, 大型视觉-语言模型, 模块化框架, 具身AI, 导航

**Comment:** 

> **TL;DR:** 本文提出了一种模块化视觉-语言导航（VLN）框架，该框架利用冻结的大型视觉-语言模型（LVLM），通过解耦视觉-语言理解与动作规划，实现高效导航。尽管在未见环境中泛化存在挑战，但该方法为可扩展的导航系统奠定了基础。

**AI_Comments:** 本文的创新之处在于其模块化、即插即用的导航框架，特别是通过集成一个“冻结”的大型视觉-语言模型来降低计算成本和对大量模型微调的需求，这对于LVLMs的实际部署具有重要意义。它有效解决了大型模型计算资源消耗大的问题。尽管在未见环境的泛化能力上存在局限性，但这种模块化设计为未来VLN系统的可扩展性和效率提供了有前景的方向，具有良好的发展潜力。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言导航（VLN）是一个复杂的具身AI挑战，需要智能体理解自然语言指令并在视觉丰富的陌生环境中导航。现有的大型视觉-语言模型（LVLMs）虽然显著提升了多模态理解能力，但也引入了计算成本高和实时部署困难的新挑战。本文旨在提出一种灵活、快速、适应性强的导航框架，避免大量模型微调，同时解决这些挑战。

**Method:** 本文提出一个模块化、即插即用的导航框架，该框架将视觉-语言理解与动作规划解耦。通过将一个冻结的视觉-语言模型（Qwen2.5-VL-7B-Instruct）与轻量级规划逻辑集成，旨在实现无需大量模型微调的灵活、快速和适应性强的导航。该框架利用提示工程、结构化历史管理和双帧视觉输入策略来增强导航步骤间的决策连续性。系统在VLN-CE设置下的Room-to-Room基准上，使用Matterport3D数据集和Habitat-Lab仿真环境进行评估。

**Result:** 初步结果显示，在严格的评估设置下，该系统在泛化到未见环境方面存在挑战。然而，这种模块化方法为可扩展和高效的导航系统奠定了基础。

**Conclusion:** 本文提出的模块化方法为可扩展和高效的导航系统奠定了基础，并指出了未来通过增强环境先验和扩展多模态输入集成来改进的有希望的方向，尽管目前在泛化方面存在挑战。

> **ai_Abstract:** 本文提出了一种模块化导航框架，用于解决视觉-语言导航（VLN）中大型视觉-语言模型（LVLMs）带来的高计算成本和部署挑战。该框架通过解耦视觉-语言理解和动作规划，并将冻结的LVLM（Qwen2.5-VL-7B-Instruct）与轻量级规划逻辑结合，旨在实现无需大量微调的灵活、快速导航。它采用提示工程、历史管理和双帧视觉输入策略。尽管在Room-to-Room基准测试中，系统在未见环境的泛化能力上仍面临挑战，但其模块化设计为未来可扩展和高效的导航系统奠定了基础。

> **摘要翻译:** 视觉-语言导航（VLN）在具身AI中提出了一个复杂的挑战，要求智能体解释自然语言指令并在视觉丰富的陌生环境中导航。大型视觉-语言模型（LVLMs）如CLIP和Flamingo的最新进展显著改善了多模态理解，但也引入了与计算成本和实时部署相关的新挑战。在这个项目中，我们提出了一个模块化、即插即用的导航框架，该框架将视觉-语言理解与动作规划解耦。通过将一个冻结的视觉-语言模型Qwen2.5-VL-7B-Instruct与轻量级规划逻辑集成，我们旨在实现灵活、快速和适应性强的导航，而无需大量模型微调。我们的框架利用提示工程、结构化历史管理和双帧视觉输入策略来增强导航步骤间的决策连续性。我们在VLN-CE设置下的Room-to-Room基准上，使用Matterport3D数据集和Habitat-Lab仿真环境评估了我们的系统。尽管我们的初步结果显示在严格评估设置下泛化到未见环境方面存在挑战，但我们的模块化方法为可扩展和高效的导航系统奠定了基础，突出了未来通过增强环境先验和扩展多模态输入集成来改进的有希望的方向。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [113] [A Unified Framework for Probabilistic Dynamic-, Trajectory- and Vision-based Virtual Fixtures](https://arxiv.org/abs/2506.10239)
> *一种统一的概率动态、轨迹和视觉虚拟夹具框架*

*Maximilian Mühlbauer, Freek Stulp, Sylvain Calinon, Alin Albu-Schäffer, João Silvério* | **Main category: cs.RO**

**Keywords:** 概率虚拟夹具, 统一框架, 机器人辅助, 人机交互, 自动化

**Comment:** 

> **TL;DR:** 本文提出了一种统一的概率虚拟夹具框架，可以根据任务阶段的需要，在手动、半自动化和完全自动化模式之间无缝切换，以提高生产力并保持高精度。

**AI_Comments:** 这项研究的创新之处在于提出了一个统一的框架，能够整合不同自动化程度的虚拟夹具，并实现无缝切换。这解决了在机器人辅助任务中平衡效率和精度的关键挑战。通过结合动态系统、轨迹和视觉伺服方法，该框架为操作员提供了灵活且适应性强的支持。其重要性在于能够显著提高复杂任务的生产力，同时保持人类在回路中进行关键的精确操作。

<details>
  <summary>Details</summary>

**Motivation:** 虽然保持人类在回路中对于确保高精度至关重要，但任务某些阶段的部分自动化对于提高生产力至关重要。现有的概率虚拟夹具能够根据学习或感知的 Haptic 反馈进行自适应选择，但缺乏一个统一的框架来无缝切换不同的自动化级别。

**Method:** 本文提出了一种统一的概率虚拟夹具（VFs）框架，该框架可以在手动夹具、半自动化夹具（人类处理精确任务）和完全自主之间无缝切换。具体方法包括：1. 引入一种新颖的概率动态系统（DS）虚拟夹具，用于粗略引导，使机器人能够自主完成某些任务阶段，同时保持人类操作员在回路中。2. 扩展概率基于位置的轨迹夹具，增加自动化功能，以实现无缝人机交互、几何感知和最佳阻抗增益，用于需要精确引导的任务。3. 扩展视觉伺服夹具，增加相同的几何感知和阻抗行为，用于需要非常精确引导的手动任务。

**Result:** 该方法在不同的机器人上进行了实验验证，展示了多种操作模式以及编程夹具的简易性。

**Conclusion:** 本文成功提出了一个统一的概率虚拟夹具框架，该框架能够无缝切换不同的自动化级别，有效结合了人类操作的精度和机器人自动化的效率，并通过实验验证了其在不同机器人上的有效性和易用性。

> **ai_Abstract:** 本文提出了一个统一的概率虚拟夹具框架，旨在提高机器人辅助任务的生产力，同时保持人类操作员在回路中的高精度。该框架能够根据任务需求在手动、半自动化和完全自主模式之间无缝切换。它引入了基于概率动力系统的新型虚拟夹具用于粗略引导，并扩展了基于轨迹和视觉伺服的夹具，以实现精确引导、几何感知和优化阻抗。实验验证了该方法在不同机器人上的有效性、多模式操作能力以及编程的便捷性。

> **摘要翻译:** 概率虚拟夹具（VFs）能够根据学习或感知的 E. Uncertainty，为任务的每个阶段自适应选择最合适的触觉反馈。虽然保持人类在回路中仍然至关重要，例如，为了确保高精度，但任务某些阶段的部分自动化对于提高生产力至关重要。我们提出了一种统一的概率 VFs 框架，该框架可以在手动夹具、半自动化夹具（人类处理精确任务）和完全自主之间无缝切换。我们引入了一种新颖的基于概率动力系统（Dynamical System-based）的 VF，用于粗略引导，使机器人能够自主完成某些任务阶段，同时保持人类操作员在回路中。对于需要精确引导的任务，我们扩展了基于概率位置的轨迹夹具，增加了自动化功能，以实现无缝人机交互以及几何感知和最佳阻抗增益。对于需要非常精确引导的手动任务，我们还扩展了视觉伺服夹具，增加了相同的几何感知和阻抗行为。我们在不同的机器人上通过实验验证了我们的方法，展示了多种操作模式以及编程夹具的简易性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [135] [Innovative Adaptive Imaged Based Visual Servoing Control of 6 DoFs Industrial Robot Manipulators](https://arxiv.org/abs/2506.10240)
> *6自由度工业机器人机械手的创新自适应图像视觉伺服控制*

*Rongfei Li, Francis Assadian* | **Main category: cs.RO**

**Keywords:** 图像视觉伺服, 自适应控制, 机器人机械手, Youla参数化, 特征估计

**Comment:** 22 pages, 13 figures. To appear in: Innovative Adaptive Image-Based
  Visual Servoing Control of 6 DoFs Industrial Robot Manipulators, IntechOpen,
  2024. For published version, see this http URL:
  https://doi.org/10.5772/intechopen.1004857

> **TL;DR:** 本文提出了一种创新的前馈-反馈自适应控制算法，结合Youla参数化和特征估计，解决了图像视觉伺服中3D点特征超出视野的问题，并在仿真中验证了其鲁棒性和有效性。

**AI_Comments:** 本文的创新点在于提出了一个结合Youla参数化的前馈-反馈自适应控制框架，有效解决了图像视觉伺服中3D点特征超出视野时的控制难题，这是现有研究较少涉猎的领域。通过引入特征估计循环和自适应控制器，提升了系统在复杂工况下的鲁棒性和精度，使其更适用于实际工业应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像视觉伺服（IBVS）方法主要关注3D点特征在视野内的情况，而当特征点超出视野时，控制解决方案不足。

**Method:** 提出了一种结合Youla参数化的创新前馈-反馈自适应控制算法结构。该方法包含一个设计的特征估计循环，用于处理视野外的特征点；当特征点进入视野内时，IBVS反馈循环保持姿态精度。此外，开发了一个自适应控制器，通过在线线性化和解耦非线性相机和机器人机械手模型，在整个操作范围内稳定系统。

**Result:** 该方法在特征点超出视野时能确保稳定快速的运动控制，在控制周期结束时保持姿态精度，并在整个操作范围内稳定系统。所提出的解决方案鲁棒且易于在不同的工业机器人系统中实现。通过多种仿真场景验证了其有效性和鲁棒性能。

**Conclusion:** 所提出的自适应图像视觉伺服控制方案在处理3D点特征超出视野的情况下表现出有效、鲁棒且易于实现的性能，能够确保工业机器人机械手的稳定和精确姿态对齐。

> **ai_Abstract:** 本文针对现有图像视觉伺服（IBVS）方法在3D点特征超出视野时控制不足的问题，提出了一种创新的前馈-反馈自适应控制算法。该算法结合Youla参数化和特征估计循环，确保在特征点内外视野时都能实现稳定、快速且高精度的姿态对齐。通过在线线性化和解耦非线性模型，自适应控制器增强了系统的鲁棒性和稳定性。仿真结果验证了该方案的有效性和易于实现的特点。

> **摘要翻译:** 图像视觉伺服（IBVS）方法已经得到了很好的发展并应用于许多领域，特别是在姿态（位置和方向）对齐方面。然而，大多数研究论文都集中在当3D点特征可以在视野内检测到时开发控制解决方案。这项工作提出了一种创新的前馈-反馈自适应控制算法结构，并结合了Youla参数化方法。一个设计的特征估计循环确保当点特征在视野外时也能实现稳定快速的运动控制。当3D点特征进入视野内时，IBVS反馈循环保持控制周期结束时姿态的精度。此外，反馈循环中开发了一个自适应控制器，以在整个操作范围内稳定系统。非线性相机和机器人机械手模型通过自适应算法在线线性化和解耦。然后，基于在当前线性化点评估的线性化模型计算自适应控制器。所提出的解决方案鲁棒且易于在不同的工业机器人系统中实现。在仿真中使用了各种场景来验证所提出控制器的有效性和鲁棒性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [155] [A Novel Feedforward Youla Parameterization Method for Avoiding Local Minima in Stereo Image Based Visual Servoing Control](https://arxiv.org/abs/2506.10252)
> *一种避免立体图像视觉伺服控制中局部最小值的创新前馈Youla参数化方法*

*Rongfei Li, Francis Assadian* | **Main category: cs.RO**

**Keywords:** 立体视觉伺服, 局部最小值, 前馈控制, Youla参数化, P3P

**Comment:** 36 pages, 19 figures, Journal, Published in: Applied Sciences, 2025,
  vol. 15, article 4991. For published version, see this http URL:
  https://doi.org/10.3390/app15094991

> **TL;DR:** 本文提出了一种结合前馈控制器和Youla参数化反馈控制器的新型控制策略，用于立体相机视觉伺服，以解决传统IBVS控制中系统过确定导致的局部最小值问题，并通过仿真验证了其有效性。

**AI_Comments:** 该论文创新性地将前馈控制与Youla参数化反馈控制相结合，解决了立体图像视觉伺服中局部最小值这一关键挑战，提高了控制的鲁棒性和精度。其重要性在于为视觉伺服系统提供了一种有效的全局稳定性保障方法。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人导航和操作中，准确确定相机相对于环境的姿态至关重要。图像视觉伺服（IBVS）控制中，由于系统变得过确定（6个自由度与9个观测到的2D特征不匹配），导致全局稳定性无法保证，相机可能在伺服过程中陷入远离期望配置的局部最小值。

**Method:** 提出了一种用于精确定位已校准立体相机的新型控制策略。该方法将前馈控制器与基于Youla参数化的反馈控制器相结合。

**Result:** 通过仿真，证明了所提出的方法能够有效避免局部最小值，并使相机准确、高效地到达期望姿态。

**Conclusion:** 所提出的结合前馈和Youla参数化反馈的控制策略能够有效解决立体图像视觉伺服中局部最小值问题，实现相机姿态的准确高效控制。

> **ai_Abstract:** 本文针对立体图像视觉伺服（IBVS）控制中因系统过确定而导致的局部最小值问题，提出了一种新颖的控制策略。该策略结合了前馈控制器和基于Youla参数化的反馈控制器，旨在精确控制已校准立体相机的姿态。仿真结果表明，该方法能有效避免局部最小值，并使相机准确高效地达到期望姿态，从而确保了鲁棒的伺服性能。

> **摘要翻译:** 在机器人导航和操作中，准确确定相机相对于环境的姿态对于有效执行任务至关重要。在本文中，我们系统地证明了这个问题对应于透视-3-点（P3P）公式，其中正好使用三个已知的3D点及其对应的2D图像投影来估计立体相机的姿态。在基于图像的视觉伺服（IBVS）控制中，系统变得过确定，因为立体相机的6个自由度必须与场景中9个观测到的2D特征对齐。当施加的约束多于可用的自由度时，无法保证全局稳定性，因为相机在伺服过程中可能会陷入远离期望配置的局部最小值。为了解决这个问题，我们提出了一种用于精确定位已校准立体相机的新型控制策略。我们的方法将前馈控制器与基于Youla参数化的反馈控制器相结合，确保了鲁棒的伺服性能。通过仿真，我们证明了我们的方法有效地避免了局部最小值，并使相机能够准确高效地到达期望姿态。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [175] [Learning Safe Control via On-the-Fly Bandit Exploration](https://arxiv.org/abs/2506.10279)
> *通过即时Bandit探索学习安全控制*

*Alexandre Capone, Ryan Cosner, Aaaron Ames, Sandra Hirche* | **Main category: cs.RO**

**Keywords:** 安全控制, 在线探索, Bandit算法, 控制障碍函数, 模型不确定性

**Comment:** arXiv admin note: text overlap with arXiv:2311.02133

> **TL;DR:** 本文提出了一种新的安全学习控制方法，通过在线数据收集解决高模型不确定性下的安全控制问题，无需备份控制器，并实现了可证明的安全性。

**AI_Comments:** 这篇论文的创新点在于它提供了一种无需安全备份控制器就能处理高模型不确定性下安全控制问题的方法。通过将探索过程与安全机制（控制障碍函数）紧密结合，确保了在数据收集过程中也能维持系统安全，这是对现有安全学习控制方法的显著改进，尤其是在实际应用中，安全备份控制器可能难以设计或存在限制的场景。

<details>
  <summary>Details</summary>

**Motivation:** 在模型不确定性高的情况下，基于模型误差界限的安全滤波器可能失效，且现有方法通常依赖于安全备份控制器，这在某些场景下可能不可行或难以设计。

**Method:** 该方法结合了控制障碍函数与学习模型来提供安全保证。当安全滤波器出现不可行性时，利用控制障碍函数指导基于高斯过程bandit算法的在线数据探索，以收集有助于闭环系统安全的新数据。

**Result:** 该方法在允许零均值先验动力学模型的设定下，无需备份控制器即可实现可证明的安全性。据作者所知，这是首个实现此目标的基于安全学习的控制方法。

**Conclusion:** 本文提出了一种创新的安全学习控制方法，通过将安全滤波器与在线探索相结合，解决了高模型不确定性下的安全控制挑战，其核心贡献在于无需依赖备份控制器即可提供可证明的安全性。

> **ai_Abstract:** 本文提出了一种新颖的安全学习控制方法，旨在解决高模型不确定性下安全滤波器可能失效的问题。该方法通过结合控制障碍函数和学习模型来确保安全，并在出现不可行性时，利用控制障碍函数指导基于高斯过程bandit的在线数据探索，以提高闭环系统安全性。其核心创新在于无需备份控制器，即可在零均值先验动力学模型下实现可证明的安全性。

> **摘要翻译:** 在模型不确定性高的情况下，具有安全要求的控制任务越来越普遍。机器学习技术常用于解决此类任务，通常通过利用模型误差界限来指定鲁棒的基于约束的安全滤波器。然而，如果学习到的模型不确定性非常高，相应的滤波器可能会失效，这意味着没有控制输入能满足安全滤波器施加的约束。虽然大多数工作通过假设某种形式的安全备份控制器来解决这个问题，但我们的方法通过使用高斯过程bandit型算法即时收集额外数据来解决。我们将控制障碍函数与学习模型相结合，以指定一个鲁棒的证书，如果可行则确保安全。每当出现不可行性时，我们利用控制障碍函数来指导探索，确保收集到的数据有助于闭环系统安全。通过将安全滤波器与探索以这种方式结合，我们的方法在允许零均值先验动力学模型的设置中可证明地实现了安全性，而无需备份控制器。据我们所知，这是第一个实现这一点的基于安全学习的控制方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [189] [Multi-Timescale Dynamics Model Bayesian Optimization for Plasma Stabilization in Tokamaks](https://arxiv.org/abs/2506.10287)
> *多时间尺度动力学模型贝叶斯优化在托卡马克等离子体稳态控制中的应用*

*Rohit Sonker, Alexandre Capone, Andrew Rothstein, Hiro Josep Farre Kaga, Egemen Kolemen, Jeff Schneider* | **Main category: cs.RO**

**Keywords:** 贝叶斯优化, 等离子体稳态控制, 多时间尺度, 核聚变, 托卡马克

**Comment:** 

> **TL;DR:** 本文提出了一种多时间尺度贝叶斯优化方法，结合高频数据驱动模型和低频高斯过程，以有效控制托卡马克等离子体中的撕裂不稳定性，并在DIII-D装置上取得了显著成功。

**AI_Comments:** 该论文的创新点在于提出了一个结合不同时间尺度模型的贝叶斯优化框架，有效解决了核聚变等复杂系统中数据稀疏、动力学复杂以及模型不确定性等问题。将高频数据驱动模型与低频高斯过程相结合，并通过迭代更新来优化预测，是其方法的核心优势。这一方法在实际核聚变装置DIII-D上的成功验证，展示了其在实际工程应用中的巨大潜力，对于实现可控核聚变具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习算法在控制复杂现实世界系统（特别是核聚变）时面临挑战，包括动力学复杂、数据质量差、硬件故障以及实验对后续动态的影响。现有方法无法提供全面的解决方案。

**Method:** 提出了一种多尺度贝叶斯优化方法，该方法将高频数据驱动动力学模型与低频高斯过程相结合。通过在实验之间更新高斯过程，该方法能够快速适应新数据，并改进不太可靠的动力学模型的预测。

**Result:** 离线测试表明，该方法显著优于多个基线。在DIII-D托卡马克装置上进行的活体实验中，在高性能、易不稳定等离子体场景下，成功率达到50%，比历史结果提高了117%。

**Conclusion:** 本文提出的多时间尺度贝叶斯优化方法能够有效控制托卡马克等离子体中的撕裂不稳定性，并在实际核聚变装置中展现出显著的性能提升。

> **ai_Abstract:** 本文针对机器学习在核聚变等复杂系统控制中面临的挑战，提出了一种新颖的多尺度贝叶斯优化方法。该方法结合了高频数据驱动动力学模型与低频高斯过程，并通过实验间更新高斯过程以快速适应新数据并优化模型预测。在DIII-D核聚变装置上对撕裂不稳定性的控制验证显示，该方法在离线测试中显著优于基线，并在活体实验中取得了50%的成功率，相比历史结果提升了117%。

> **摘要翻译:** 机器学习算法在控制复杂的现实世界系统时常常遇到困难。在核聚变领域，这些挑战更加严峻，因为其动力学异常复杂，数据质量不佳，硬件容易发生故障，且实验往往会影响超出实验持续时间的动力学。现有的工具，如强化学习、监督学习和贝叶斯优化，虽然解决了其中一些挑战，但未能提供一个全面的解决方案。为了克服这些局限性，我们提出了一种多尺度贝叶斯优化方法，该方法将高频数据驱动动力学模型与低频高斯过程相结合。通过在实验之间更新高斯过程，该方法能够快速适应新数据，从而改进对不太可靠的动力学模型的预测。我们通过控制DIII-D核聚变装置中的撕裂不稳定性来验证了我们的方法。对历史数据的离线测试表明，我们的方法显著优于多个基线。在DIII-D托卡马克装置上、在易发生不稳定性的高性能等离子体场景下进行的活体实验结果显示，成功率达到50%，比历史结果提高了117%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [203] [Using Language and Road Manuals to Inform Map Reconstruction for Autonomous Driving](https://arxiv.org/abs/2506.10317)
> *使用语言和道路手册为自动驾驶地图重建提供信息*

*Akshar Tumu, Henrik I. Christensen, Marcell Vazquez-Chanlatte, Chikao Tsuchiya, Dhaval Bhanderi* | **Main category: cs.RO**

**Keywords:** 车道拓扑预测, 自动驾驶, 地图重建, 自然语言, 道路手册

**Comment:** 4 pages, 3 figures, Accepted at RSS 2025 Workshop -
  RobotEvaluation@RSS2025

> **TL;DR:** 通过结合语言和道路手册信息，改进了基于地图先验的在线车道拓扑预测模型SMERF，提高了复杂交叉路口的车道和交通元素检测及关联性能。

**AI_Comments:** 这项工作创新性地将传统道路设计规范和语言信息融入到自动驾驶的地图重建中，弥补了纯视觉或激光雷达方法在理解道路语义和结构上的不足。通过结合结构化元数据和先验知识，提高了在线车道拓扑预测的准确性和鲁棒性，尤其是在复杂交叉路口。其轻量级增强方式也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 车道拓扑预测是安全可靠自动驾驶的关键组成部分，准确理解道路环境对此任务至关重要。研究观察到道路信息常遵循自然语言编码的惯例，如设计规范和道路名称，这些信息可用于辅助地图重建。

**Method:** 通过将OSM地图中的结构化道路元数据和道路设计手册中的车道宽度先验与道路中心线编码相结合，以轻量级方式增强了基于地图先验的在线车道拓扑预测模型SMERF。

**Result:** 该方法在两个地理多样化的复杂交叉路口场景中进行了评估，结果显示在车道和交通元素检测及其关联方面都有所改进。使用四个拓扑感知指标全面评估了模型性能，并证明了该方法能够推广并适应各种拓扑结构和条件。

**Conclusion:** 该方法能够推广并适应各种拓扑结构和条件。

> **ai_Abstract:** 本文提出了一种利用自然语言编码的道路信息（如道路设计规范和道路名称）来增强自动驾驶地图重建的方法。通过将OSM地图的结构化元数据和道路手册的车道宽度先验结合到在线车道拓扑预测模型SMERF中，研究人员在复杂交叉路口场景中验证了该方法，结果显示其在车道和交通元素检测及关联方面均有提升，并能泛化到多样化的拓扑结构和条件。

> **摘要翻译:** 车道拓扑预测是安全可靠自动驾驶的关键组成部分。准确理解道路环境有助于此任务。我们观察到，这些信息通常遵循以自然语言编码的惯例，通过反映道路结构的设计规范和捕捉道路功能的道路名称。我们以轻量级方式将这些信息增强到SMERF模型中，SMERF是一个基于地图先验的在线车道拓扑预测模型，通过将OSM地图中的结构化道路元数据和道路设计手册中的车道宽度先验与道路中心线编码相结合。我们在两个地理多样化的复杂交叉路口场景中评估了我们的方法。我们的方法在车道和交通元素检测及其关联方面都显示出改进。我们使用四个拓扑感知指标报告了结果，以全面评估模型性能。这些结果表明我们的方法能够推广并适应各种拓扑结构和条件。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [220] [Demonstrating Multi-Suction Item Picking at Scale via Multi-Modal Learning of Pick Success](https://arxiv.org/abs/2506.10359)
> *通过多模态学习抓取成功率实现大规模多吸盘物品抓取演示*

*Che Wang, Jeroen van Baar, Chaitanya Mitash, Shuai Li, Dylan Randle, Weiyao Wang, Sumedh Sontakke, Kostas E. Bekris, Kapil Katyal* | **Main category: cs.RO**

**Keywords:** 机器人抓取, 多模态学习, 吸盘抓取, 抓取成功预测, 工业自动化

**Comment:** Accepted to Robotics: Science and Systems (RSS 2025), 15 pages

> **TL;DR:** 本文通过多模态学习从真实世界数据中预测多吸盘机器人抓取成功率，从而实现了大规模、高性能的物品抓取。

**AI_Comments:** 该论文的创新点在于将多模态学习应用于工业规模的多吸盘机器人抓取成功率预测，并利用大量真实世界数据进行训练和验证。其重要性在于解决了机器人从杂乱环境中抓取多样化物品的挑战，并通过实验证明了多模态训练的有效性以及在推理时使用部分模态的可能性，这对于实际部署具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人从非结构化堆叠中抓取多样化物品是一项重要的挑战性任务，尤其是在仓库等真实世界环境中，需要高吞吐量且适用于开放式物品集。

**Method:** 该方法利用多模态视觉编码器（包括RGB、深度和语义分割）来预测候选多吸盘抓取的成功率。该策略通过多模态预训练和微调的组合，从真实世界的物品抓取数据中进行训练。

**Result:** 实验证明了多模态训练的重要性，模型在预训练阶段能够学习模态之间的关系，从而在微调和推理时仅使用部分模态作为输入。研究在大型物品抓取数据集、包含部分遮挡的数据集以及专注于容器的包裹抓取数据集上进行了全面评估，并测量了不同物品配置、抓取场景和物体类型的性能。

**Conclusion:** 通过从稀疏标记的真实世界数据中自主学习机器人操作的各个方面，可以提供实现性能改进的解决方案，尤其是在工业规模的多吸盘物品抓取方面。

> **ai_Abstract:** 本研究展示了一种通过多模态学习实现大规模多吸盘物品抓取的方法。该方法利用RGB、深度和语义分割等多模态视觉编码器，从真实世界数据中学习并预测机器人抓取的成功率。通过多模态预训练和微调，模型能够处理非结构化环境中的多样化物品，并在大型数据集上进行了广泛评估。研究结果强调了多模态训练的关键作用，并表明模型在预训练后可仅使用部分模态进行高效推理，从而提高了工业规模机器人抓取任务的性能。

> **摘要翻译:** 这项工作展示了如何从部署在工业规模的工程解决方案的稀疏标记的真实世界数据中自主学习机器人操作的各个方面，从而提供性能改进的解决方案。具体而言，它专注于多吸盘机器人抓取，并对多模态视觉编码器在预测候选机器人抓取成功率方面的应用进行了全面研究。从非结构化堆叠中抓取多样化物品对于真实世界环境（如仓库）中的机器人操作来说是一项重要且具有挑战性的任务。从杂乱环境中抓取的方法必须适用于开放式物品集，同时满足延迟约束以实现高吞吐量。所演示的方法利用多种输入模态，例如RGB、深度和语义分割，来估计候选多吸盘抓取的质量。该策略通过多模态预训练和微调的组合，从真实世界的物品抓取数据中进行训练。手稿提供了在大型物品抓取数据集、旨在包含部分遮挡的物品抓取数据集以及专注于容器（如箱子和信封而非未包装物品）的包裹抓取数据集上进行的全面实验评估。评估测量了不同物品配置、抓取场景和物体类型的性能。消融实验有助于理解域内预训练的效果、不同模态的影响以及微调的重要性。这些消融实验揭示了多模态训练的重要性，以及模型在预训练期间学习模态之间关系的能力，以便在微调和推理时，仅使用其中的一部分作为输入。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [235] [Towards more efficient quantitative safety validation of residual risk for assisted and automated driving](https://arxiv.org/abs/2506.10363)
> *面向辅助和自动驾驶残余风险更高效定量安全验证*

*Daniel Betschinske, Malte Schrimpf, Steven Peters, Kamil Klonecki, Jan Peter Karch, Moritz Lippert* | **Main category: cs.RO**

**Keywords:** 自动驾驶, 安全验证, 残余风险, 现场运行测试, 缩减方法

**Comment:** 

> **TL;DR:** 本研究系统地识别并评估了用于辅助和自动驾驶系统定量安全验证的现场运行测试（FOT）的现有缩减方法，发现尽管一些方法有潜力，但无一能完全替代FOT，且都存在显著缺陷。

**AI_Comments:** 本文系统地分析了当前自动驾驶系统安全验证中FOT的效率问题，并对各类缩减方法进行了全面评估。其创新点在于结合ISO 21448标准，提出了模型来指导验证，并用明确的评估标准审视了现有方法。重要性在于指出了当前缩减方法的局限性，明确了FOT的不可替代性，并为未来研究指明了方向。局限性在于虽然评估了方法，但并未提出具体的、能弥补当前缺陷的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 辅助驾驶系统（ADAS）和自动驾驶系统（ADS）的安全验证需要高效可靠的方法来量化残余风险，并遵循ISO 21448等国际标准。传统的现场运行测试（FOT）在SAE L2级及以下宏观安全验证中至关重要，但其经验性安全演示所需的测试工作量巨大且不切实际，特别是在更高级别自动化中。即使在较低级别，FOT的高昂成本也促使人们探索提高其效率的方法。

**Method:** 本研究系统地识别并评估了现有及文献中报道的新型现场运行测试（FOT）缩减方法（RAs）。基于对ISO 21448的分析，推导了两个模型：一个通用模型，捕捉标准的论证组成部分；一个基础模型，以自动紧急制动（AEB）系统为例，为残余风险的定量安全验证（QSVRR）的实际驾驶要求建立了基线。随后，使用四个标准（可量化性、有效性威胁、缺失环节和黑盒兼容性）评估了这些缩减方法。

**Result:** 评估结果显示，尽管有几种缩减方法具有潜力，但它们都存在缺失环节或其他实质性缺点。此外，没有一种已识别的替代方法能够完全取代现场运行测试（FOT），这反映了FOT在ADAS和ADS安全验证中的关键作用。

**Conclusion:** 本研究得出结论，当前没有一种缩减方法可以完全替代现场运行测试（FOT）在辅助和自动驾驶系统安全验证中的关键作用，尽管一些方法提供了提高效率的潜力，但它们仍存在显著的局限性和需要进一步研究的领域。

> **ai_Abstract:** 本论文旨在提高辅助和自动驾驶系统残余风险定量安全验证的效率。鉴于传统现场运行测试（FOT）在高级别自动化中效率低下且成本高昂，作者系统地识别并评估了FOT的现有及新型缩减方法。研究基于ISO 21448推导了通用模型和AEB示例基础模型，并从可量化性、有效性威胁、缺失环节和黑盒兼容性等角度评估了这些缩减方法。结果表明，尽管一些缩减方法具有潜力，但均存在显著缺陷且无法完全替代FOT，强调了FOT在ADAS和ADS安全验证中的不可替代性。

> **摘要翻译:** 辅助驾驶系统（ADAS）和自动驾驶系统（ADS）的安全验证越来越需要高效可靠的方法来量化残余风险，同时遵守ISO 21448等国际标准。传统上，现场运行测试（FOT）对于SAE自动化级别2及以下的汽车驾驶功能的宏观安全验证至关重要。然而，使用FOT进行经验性安全演示的最新推导通常导致不切实际的测试工作量，特别是在更高级别的自动化中。即使在较低的自动化级别，这种限制——加上与FOT相关的高昂成本——促使人们探索提高基于FOT的宏观安全验证效率的方法。因此，本出版物系统地识别并评估了FOT的最新缩减方法（RAs），包括文献中报道的新方法。基于对ISO 21448的分析，推导了两个模型：一个通用模型，捕捉标准的论证组成部分；一个基础模型，以自动紧急制动（AEB）系统为例，为残余风险的定量安全验证（QSVRR）的实际驾驶要求建立了基线。随后，使用四个标准评估了这些缩减方法：可量化性、有效性威胁、缺失环节和黑盒兼容性，突出了潜在益处、固有局限性，并确定了进一步研究的关键领域。我们的评估表明，尽管有几种方法提供了潜力，但没有一种方法不存在缺失环节或其他实质性缺陷。此外，没有一种已识别的替代方法能够完全取代FOT，这反映了其在ADAS和ADS安全验证中的关键作用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [247] [RICE: Reactive Interaction Controller for Cluttered Canopy Environment](https://arxiv.org/abs/2506.10383)
> *RICE：用于杂乱冠层环境的反应式交互控制器*

*Nidhi Homey Parayil, Thierry Peynot, Chris Lehnert* | **Main category: cs.RO**

**Keywords:** 反应式控制器, 触觉反馈, 机器人导航, 农业机器人, 杂乱环境

**Comment:** This work has been submitted to the IEEE RAL for possible publication

> **TL;DR:** 提出了一种新的反应式控制器RICE，使机械臂能够在杂乱、可变形的农业冠层中安全导航，通过结合末端执行器位置和实时触觉反馈，实现在不损坏植物的情况下到达目标，并在实验中表现优于现有技术。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合触觉反馈的反应式控制器，解决了传统视觉或模型方法在杂乱、可变形农业环境中的局限性。其“最小化扰动”与“推开障碍物”的交互策略非常实用，使得机器臂能够在不造成损坏的情况下进行有效物理交互，这对于农业采摘、修剪等任务具有重要意义。该研究为未来在复杂自然环境中部署机器人提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于视觉或依赖模型的方法在农业冠层等密集、杂乱环境中导航时面临挑战，因为物理和视觉遮挡导致它们难以在不损坏树叶和树枝的情况下进行物理交互以到达目标。

**Method:** 提出了一种新型的反应式控制器，它利用末端执行器位置和实时触觉反馈，使机械臂能够在接触丰富的、杂乱的、可变形的环境中安全导航。其交互策略基于最小化扰动（绕过障碍物）和推开障碍物（穿过障碍物）以接近目标之间的权衡。

**Result:** 在3个实验植物设置中进行了超过35次试验，目标被遮挡，所提出的控制器在所有试验中都成功到达了目标，没有折断任何树枝，并且在鲁棒性和适应性方面优于最先进的无模型控制器。

**Conclusion:** 这项工作为在杂乱、接触丰富的可变形环境中实现安全、自适应的交互奠定了基础，为未来在植物冠层中进行修剪和采摘等农业任务提供了可能性。

> **ai_Abstract:** 本文介绍了一种名为RICE的新型反应式控制器，旨在解决机器人在农业冠层等杂乱、接触丰富的环境中导航的挑战。该控制器结合了末端执行器位置和实时触觉反馈，通过在避开障碍物和推开障碍物之间进行权衡，实现了机械臂在不损坏植物的情况下安全到达目标。实验结果表明，RICE在多种植物设置中均能成功且无损地到达目标，并在鲁棒性和适应性上优于现有技术，为未来的农业机器人应用奠定了基础。

> **摘要翻译:** 农业冠层等密集、杂乱环境中的机器人导航由于树叶和树枝造成的物理和视觉遮挡而面临重大挑战。传统的基于视觉或依赖模型的方法在这些环境中往往会失败，因为需要进行物理交互而又不损坏树叶和树枝才能到达目标。我们提出了一种新颖的反应式控制器，该控制器利用末端执行器位置和实时触觉反馈，使机械臂能够在接触丰富、杂乱、可变形的环境中安全导航。我们提出的框架的交互策略基于通过绕过障碍物来最小化扰动和通过推开障碍物来向目标移动之间的权衡。我们通过在3个实验植物设置中进行超过35次试验，目标被遮挡，结果表明所提出的控制器在所有试验中都成功到达了目标，没有折断任何树枝，并且在鲁棒性和适应性方面优于最先进的无模型控制器。这项工作为在杂乱、接触丰富的可变形环境中实现安全、自适应的交互奠定了基础，为未来在植物冠层中进行修剪和采摘等农业任务提供了可能性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [258] [Are We Generalizing from the Exception? An In-the-Wild Study on Group-Sensitive Conversation Design in Human-Agent Interactions](https://arxiv.org/abs/2506.10462)
> *我们是否在从例外中概括？一项关于人机交互中群组敏感对话设计的实地研究*

*Ana Müller, Sabina Jeschke, Anja Richert* | **Main category: cs.RO**

**Keywords:** 人机交互, 群组敏感对话, 社交智能体, 对话式人工智能, 实地研究

**Comment:** Accepted as a regular paper at the 2025 IEEE International Conference
  on Robot and Human Interactive Communication (RO-MAN). \c{opyright} IEEE.
  This is the preprint version. The final version will appear in the IEEE
  proceedings

> **TL;DR:** 本研究在真实环境中调查了群组自适应对话设计对社交智能体（机器人和虚拟代理）的影响。尽管对用户满意度无显著影响，但揭示了多方交互和跨实体适应对话式人工智能（CAI）的挑战，强调了超越语言的多模态策略的必要性。

**AI_Comments:** 这项研究的创新之处在于其“in-the-wild”的实地研究设置，这比实验室研究更能反映真实世界的使用情况。尽管主要假设（群组敏感设计对满意度的影响）未被证实，但其负面结果同样重要，揭示了在复杂多方和多实体情境下设计对话式人工智能的挑战，并强调了多模态交互的重要性，这对于人机交互领域具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查群组自适应对话设计在两个社交互动智能体（SIAs）中的影响。

**Method:** 通过两项实地研究进行，共有188名参与者在德国一家博物馆的真实环境中与社交机器人Furhat和虚拟代理MetaHuman（均配备结合混合检索和生成模型的对话式人工智能后端）以两人、三人或更大规模的群组形式进行互动。

**Result:** 尽管群组敏感对话设计对感知满意度没有显著影响，但研究结果为在多方交互和不同实体（机器人与虚拟代理）中调整对话式人工智能的挑战提供了宝贵见解。

**Conclusion:** 研究强调了在群组设置中，超越语言复数化的多模态策略对于有效对话适应的需求，并为人机交互（HAI）、人机人交互（HRI）和更广泛的人机交互（HMI）领域未来关于有效对话适应的研究提供了见解。

> **ai_Abstract:** 本研究在真实环境中，通过与社交机器人Furhat和虚拟代理MetaHuman（均搭载混合对话式人工智能）的互动，调查了群组自适应对话设计对用户满意度的影响。尽管未发现显著影响，但研究揭示了在多方和跨实体交互中调整对话式人工智能的复杂性，强调了多模态而非单一语言策略的重要性，为未来人机交互研究提供了方向。

> **摘要翻译:** 这篇论文通过两项真实世界的研究，调查了群组自适应对话设计在两个社交互动智能体（SIAs）中的影响。这两个社交互动智能体——社交机器人Furhat和虚拟代理MetaHuman——都配备了结合混合检索和生成模型的对话式人工智能（CAI）后端。这些研究是在德国一家博物馆的真实环境中进行的，共有188名参与者以两人、三人或更大规模的群组形式与SIAs进行了互动。尽管结果并未揭示群组敏感对话设计对感知满意度有显著影响，但这些发现为多方交互和跨不同实体（机器人与虚拟代理）调整CAI所面临的挑战提供了宝贵见解，强调了超越语言复数化的多模态策略的需求。这些见解有助于人机交互（HAI）、人机人交互（HRI）和更广泛的人机交互（HMI）领域，为未来在群组环境中有效对话适应的研究提供了启示。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [274] [EmbodiedGen: Towards a Generative 3D World Engine for Embodied Intelligence](https://arxiv.org/abs/2506.10600)
> *EmbodiedGen：迈向具身智能的生成式3D世界引擎*

*Wang Xinjie, Liu Liu, Cao Yu, Wu Ruiqi, Qin Wenkang, Wang Dehui, Sui Wei, Su Zhizhong* | **Main category: cs.RO**

**Keywords:** 具身智能, 3D世界生成, 生成式AI, 模拟环境, URDF

**Comment:** 

> **TL;DR:** EmbodiedGen是一个生成式3D世界引擎，旨在低成本地为具身智能任务提供可扩展、高质量、可控且逼真的3D资产和交互式世界。

**AI_Comments:** EmbodiedGen的创新性在于它将生成式AI应用于3D世界和资产的创建，极大地降低了具身智能研究中高质量、多样化3D数据的获取成本和难度。其模块化的设计使其功能全面且易于使用，有望显著推动具身AI的训练和评估的规模化和真实性。

<details>
  <summary>Details</summary>

**Motivation:** 当前具身智能任务严重依赖手动创建和标注的传统3D计算机图形资产，这些资产生产成本高且真实性有限，严重阻碍了数据驱动方法的可扩展性，而构建物理真实且精确缩放的模拟3D世界对具身智能的训练和评估至关重要。

**Method:** EmbodiedGen是一个交互式3D世界生成基础平台。它通过六个关键模块（图像到3D、文本到3D、纹理生成、关节对象生成、场景生成和布局生成）利用生成式AI，以低成本生成具有精确物理属性和真实世界尺度的URDF格式的高质量、可控、逼真的3D资产。这些资产可以直接导入各种物理仿真引擎。

**Result:** EmbodiedGen实现了可扩展地生成高质量、可控、逼真的3D资产，这些资产具有精确的物理属性和真实世界尺度，并且可以生成多样化、交互式的3D世界。

**Conclusion:** EmbodiedGen通过利用生成式AI解决了具身智能相关研究在泛化和评估方面对多样化、真实、低成本3D数据资产的需求，从而克服了传统3D资产的局限性。

> **ai_Abstract:** EmbodiedGen是一个为具身智能设计的生成式3D世界引擎，旨在解决传统3D资产生产成本高和真实性有限的问题。它提供一个基础平台，利用生成式AI通过图像到3D、文本到3D等六个模块，低成本地生成高质量、可控、逼真且具有精确物理属性的URDF格式3D资产。这些资产可直接用于各种物理仿真引擎，支持具身智能的训练和评估，从而提升数据驱动方法的可扩展性、泛化能力和真实性。

> **摘要翻译:** 构建物理真实且精确缩放的模拟3D世界对于具身智能任务的训练和评估至关重要。3D数据资产的多样性、真实性、低成本可访问性和可负担性对于实现具身AI的泛化和可扩展性至关重要。然而，当前大多数具身智能任务仍然严重依赖手动创建和标注的传统3D计算机图形资产，这些资产存在生产成本高和真实性有限的问题。这些限制严重阻碍了数据驱动方法的可扩展性。我们提出了EmbodiedGen，一个用于交互式3D世界生成的基础平台。它能够以低成本可扩展地生成高质量、可控、逼真的3D资产，这些资产具有精确的物理属性和真实世界尺度，并采用统一机器人描述格式（URDF）。这些资产可以直接导入各种物理仿真引擎进行细粒度物理控制，支持下游的训练和评估任务。EmbodiedGen是一个易于使用、功能齐全的工具包，由六个关键模块组成：图像到3D、文本到3D、纹理生成、关节对象生成、场景生成和布局生成。EmbodiedGen利用生成式AI生成由生成式3D资产组成的多样化、交互式3D世界，以解决具身智能相关研究的泛化和评估挑战。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [286] [An $O(n$)-Algorithm for the Higher-Order Kinematics and Inverse Dynamics of Serial Manipulators using Spatial Representation of Twists](https://arxiv.org/abs/2506.10686)
> *一种使用空间旋量表示的串联机械臂高阶运动学和逆动力学O(n)算法*

*Andreas Mueller* | **Main category: cs.RO**

**Keywords:** 运动学, 逆动力学, 串联机械臂, O(n)算法, 空间表示

**Comment:** 

> **TL;DR:** 该论文提出了一种使用空间旋量表示的串联机械臂高阶运动学和逆动力学O(n)算法，以支持机器人臂的优化控制。

**AI_Comments:** 该论文通过提供计算高效的机器人高阶运动学和逆动力学算法，为机器人控制领域做出了贡献。在李群框架内使用空间表示提供了一种紧凑且可能更直观的公式，与之前的固连或混合表示相比。O(n)复杂度对于实时应用至关重要，提升了算法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人臂的优化控制（特别是基于平坦度的控制）需要计算实现期望运动所需的关节扭矩/力的第一和第二时间导数。为了满足计算效率的需求，之前提出了递归的O(n)算法和基于李群的紧凑高效公式（使用固连和混合表示的旋量和力偶）。本文旨在引入一种使用空间表示的公式。

**Method:** 本文引入了一种使用空间表示的旋量的公式。该方法包括一个二阶逆动力学算法，以及一个四阶正向和逆运动学算法。该方法利用了所有李群公式的优点，即它们可以用易于获得的矢量量进行参数化。该方法在7自由度Franka Emika Panda机器人上进行了演示。

**Result:** 本文提出了一种用于高阶运动学和逆动力学的O(n)算法。具体来说，开发了一个二阶逆动力学算法和一个四阶正向和逆运动学算法。该方法在7自由度机器人上得到了验证。

**Conclusion:** 本文成功引入了一种使用空间表示的O(n)算法，用于串联机械臂的高阶运动学和逆动力学计算。李群公式的优势在于它们可以由易于获得的矢量量进行参数化，这对于机器人控制应用至关重要。

> **ai_Abstract:** 本文提出了一种用于串联机械臂高阶运动学和逆动力学的O(n)算法。在最近的李群公式基础上，该研究引入了一种使用空间旋量表示的新方法。所提出的方法包含一个二阶逆动力学算法和一个四阶正向和逆运动学算法，这对于需要关节扭矩导数的优化控制应用至关重要。论文强调了李群公式的优势在于其可以由易于获得的矢量量进行参数化，并在7自由度Franka Emika Panda机器人上进行了演示。

> **摘要翻译:** 机器人臂的优化控制，特别是基于平坦度的控制，需要计算实现期望运动所需的关节扭矩/力的第一和第二时间导数。为了满足所需的计算效率，为此提出了递归的O(n)算法。为了实现紧凑而高效的公式，最近提出了一种李群公式，利用固连和混合表示的旋量和力偶。本文引入了一种使用空间表示的公式。二阶逆动力学算法伴随着一个四阶正向和逆运动学算法。所有李群公式的一个优点是它们可以用易于获得的矢量量进行参数化。该方法在7自由度Franka Emika Panda机器人上进行了演示。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [297] [Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding](https://arxiv.org/abs/2506.10756)
> *基于开放词汇目标理解的无人机接地视觉-语言导航*

*Yuhang Zhang, Haosheng Yu, Jiaping Xiao, Mir Feroskhan* | **Main category: cs.RO**

**Keywords:** 视觉-语言导航, 无人机, 开放词汇, 连续控制, LLM-VLM

**Comment:** 

> **TL;DR:** VLFly是一个为无人机设计的视觉-语言导航框架，仅通过单目摄像头输入即可理解语言指令并输出连续速度命令，在模拟和真实世界环境中均表现出色。

**AI_Comments:** VLFly的创新之处在于其无需定位或主动测距传感器，仅通过单目相机实现连续速度控制，并整合了LLM和VLM以实现开放词汇理解和泛化导航。这对于无人机在复杂环境中的自主操作具有重要意义，尤其是在没有GPS或预设地图的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言导航（VLN）领域存在两个关键瓶颈：对分布外环境的泛化能力不足以及对固定离散动作空间的依赖。

**Method:** 本文提出了VLFly框架，专为无人机执行语言引导飞行。它无需定位或主动测距传感器，纯粹通过机载单目摄像头捕获的自我中心观测输出连续速度命令。VLFly集成了三个模块：基于大型语言模型（LLM）的指令编码器、由视觉-语言模型（VLM）驱动的目标检索器以及一个航点规划器。

**Result:** VLFly在没有额外微调的情况下，在各种模拟环境中始终优于所有基线。在室内和室外环境中的真实世界VLN任务表明，VLFly实现了鲁棒的开放词汇目标理解和泛化导航能力，即使在存在抽象语言输入的情况下也是如此。

**Conclusion:** VLFly框架为无人机实现了鲁棒的开放词汇目标理解和泛化导航能力，有效解决了视觉-语言导航领域的关键瓶颈。

> **ai_Abstract:** 本文提出了VLFly框架，旨在解决视觉-语言导航（VLN）中无人机泛化能力和固定动作空间的问题。VLFly仅通过机载单目摄像头输入，输出连续速度指令，包含LLM指令编码器、VLM目标检索器和航点规划器。实验表明，VLFly在模拟和真实世界环境中均表现出色，实现了鲁棒的开放词汇目标理解和泛化导航能力。

> **摘要翻译:** 视觉-语言导航（VLN）是自主机器人领域的一个长期挑战，旨在赋予智能体在复杂环境中遵循人类指令进行导航的能力。该领域仍存在两个关键瓶颈：对分布外环境的泛化能力以及对固定离散动作空间的依赖。为了解决这些挑战，我们提出了Vision-Language Fly（VLFly），一个专为无人机（UAV）执行语言引导飞行的框架。VLFly无需定位或主动测距传感器，仅凭机载单目摄像头捕获的自我中心观测，即可输出连续的速度指令。VLFly集成了三个模块：一个基于大型语言模型（LLM）的指令编码器，将高级语言重构为结构化提示；一个由视觉-语言模型（VLM）驱动的目标检索器，通过视觉-语言相似性将这些提示与目标图像匹配；以及一个生成可执行轨迹用于实时无人机控制的航点规划器。VLFly在没有额外微调的情况下，在各种模拟环境中进行了评估，并始终优于所有基线。此外，在室内和室外环境中的直接和间接指令下的真实世界VLN任务表明，VLFly即使在存在抽象语言输入的情况下，也能实现鲁棒的开放词汇目标理解和泛化导航能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [308] [In-Hand Object Pose Estimation via Visual-Tactile Fusion](https://arxiv.org/abs/2506.10787)
> *手持物体姿态估计通过视觉-触觉融合*

*Felix Nonnengießer, Alap Kshirsagar, Boris Belousov, Jan Peters* | **Main category: cs.RO**

**Keywords:** 姿态估计, 视觉-触觉融合, 机器人操作, 视觉遮挡, ICP算法

**Comment:** 8 pages

> **TL;DR:** 本文提出一种结合视觉和触觉信息的方法，用于准确估计机器人手持物体的姿态，尤其在视觉遮挡严重时表现更优。

**AI_Comments:** 本文的创新点在于有效地结合了视觉和触觉信息来解决机器人手持物体姿态估计中常见的视觉遮挡问题。通过加权融合异构传感器数据和改进ICP算法，显著提升了姿态估计的鲁棒性和精度，并在实际操作中得到了验证，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确的手持物体姿态估计对机器人操作至关重要，但视觉遮挡是基于视觉方法的主要挑战。

**Method:** 结合腕部RGB-D相机视觉信息和指尖视觉触觉传感器的触觉信息。采用加权传感器融合模块组合异构传感器点云，并使用适应加权点云的增强型迭代最近点（ICP）算法估计6D物体姿态。

**Result:** 结合触觉信息显著提高了姿态估计精度，尤其在遮挡严重时。平均姿态估计误差为7.5毫米和16.7度，优于纯视觉基线高达20%。并在实际插入任务中展示了精确物体操作能力。

**Conclusion:** 结合视觉和触觉信息能够有效解决机器人手持物体姿态估计中的视觉遮挡问题，显著提高精度，并支持实际操作。

> **ai_Abstract:** 本文提出一种创新的机器人手持物体姿态估计方法，通过融合腕部RGB-D相机的视觉数据和指尖触觉传感器的触觉数据来克服视觉遮挡问题。该方法利用加权传感器融合模块和增强型ICP算法处理异构点云。实验证明，该方法在视觉遮挡高的情况下显著提高了姿态估计精度，误差低，并成功应用于实际操作任务。

> **摘要翻译:** 准确的手持姿态估计对于机器人物体操作至关重要，但视觉遮挡仍然是基于视觉方法的主要挑战。本文提出一种机器人手持物体姿态估计方法，结合视觉和触觉信息，以准确确定机器人手抓取物体的姿态和方向。我们通过融合腕部安装的RGB-D相机的视觉信息与机器人夹持器指尖上基于视觉的触觉传感器的触觉信息来解决视觉遮挡的挑战。我们的方法采用加权和传感器融合模块来组合来自异构传感器类型的点云，并控制每种模态对姿态估计过程的贡献。我们使用适应加权点云的增强型迭代最近点（ICP）算法来估计6D物体姿态。我们的实验表明，结合触觉信息显著提高了姿态估计精度，尤其是在遮挡严重时。我们的方法实现了7.5毫米和16.7度的平均姿态估计误差，性能优于纯视觉基线高达20%。我们还展示了我们的方法在真实世界插入任务中执行精确物体操作的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [319] [RationalVLA: A Rational Vision-Language-Action Model with Dual System](https://arxiv.org/abs/2506.10826)
> *RationalVLA: 一种双系统理性视觉-语言-动作模型*

*Wenxuan Song, Jiayi Chen, Wenxue Li, Xu He, Han Zhao, Pengxiang Ding Shiyan Su, Feilong Tang, Xuelian Cheng, Donglin Wang, Zongyuan Ge, Xinhu Zheng, Zhe Liu, Hesheng Wang, Yunhui Liu, Haoang Li* | **Main category: cs.RO**

**Keywords:** 视觉-语言-动作, 双系统, 机器人操作, 指令理解, RAMA基准

**Comment:** 14 pages

> **TL;DR:** RationalVLA提出了一种双系统视觉-语言-动作模型，通过引入RAMA基准测试来处理机器人操作中模糊、不相关或不可行的指令，并在该基准上表现优异，提高了成功率和任务效率。

**AI_Comments:** 本文的创新点在于提出了RAMA基准测试，专门用于评估模型处理缺陷指令的能力，这弥补了现有基准的不足。同时，RationalVLA的双系统架构，尤其是其对指令进行推理和拒绝不可行命令的能力，对于提高机器人在复杂现实环境中的鲁棒性和泛化能力具有重要意义。该研究为实现更智能、更可靠的机器人部署奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有语言条件下的操作任务通常假设指令与环境完美对齐，这限制了机器人在指令可能模糊、不相关或不可行等现实场景中的鲁棒性和泛化能力。

**Method:** 为解决现有模型的局限性，作者提出了RAtional MAnipulation (RAMA) 基准测试，其中包含超过14,000个样本，包括可执行指令和六个维度（视觉、物理、语义、运动、安全、上下文无关）的缺陷指令。在此基础上，提出了Rational Vision-Language-Action (RationalVLA) 模型，它是一个用于机械臂的双系统，通过引入可学习的潜在空间嵌入，将高级视觉-语言模型与低级操作策略相结合。这种设计使RationalVLA能够对指令进行推理，拒绝不可行的命令，并有效执行操作。

**Result:** 实验证明，RationalVLA在RAMA基准测试上的成功率比现有最先进的基线模型高出14.5%，平均任务长度为0.94，同时在标准操作任务上保持了有竞争力的性能。实际世界试验进一步验证了其在实际应用中的有效性和鲁棒性。

**Conclusion:** RationalVLA模型通过其双系统设计和处理缺陷指令的能力，显著提高了机器人在复杂、不确定环境中的语言理解和操作鲁棒性。

> **ai_Abstract:** 本文提出RationalVLA，一个双系统视觉-语言-动作模型，旨在解决机器人操作中自然语言指令的模糊性和不可行性问题。为此，引入了RAMA基准测试，包含大量缺陷指令。RationalVLA通过整合高层视觉-语言模型和低层操作策略，实现对指令的推理、拒绝不可行命令和有效操作。实验证明，RationalVLA在RAMA基准测试上显著优于现有SOTA模型，并在实际应用中展现出鲁棒性。

> **摘要翻译:** 在现实世界中部署机器人的一项基本要求是理解和响应自然语言指令的能力。现有语言条件下的操作任务通常假设指令与环境完美对齐。这一假设限制了在指令可能模糊、不相关或不可行等现实场景中的鲁棒性和泛化能力。为了解决这个问题，我们引入了理性操作（RAtional MAnipulation, RAMA），这是一个新的基准测试，它挑战模型处理未见的、可执行的指令以及应该被拒绝的有缺陷的指令。在RAMA中，我们构建了一个包含14,000多个样本的数据集，其中包括跨越六个维度（视觉、物理、语义、运动、安全和上下文无关）的各种缺陷指令。我们进一步提出了理性视觉-语言-动作模型（Rational Vision-Language-Action model, RationalVLA）。它是一个用于机械臂的双系统，通过引入可学习的潜在空间嵌入，将高级视觉-语言模型与低级操作策略相结合。这种设计使RationalVLA能够对指令进行推理，拒绝不可行的命令，并有效执行操作。实验表明，RationalVLA在RAMA上的成功率比现有最先进的基线模型高出14.5%，平均任务长度为0.94，同时在标准操作任务上保持了有竞争力的性能。实际世界试验进一步验证了其在实际应用中的有效性和鲁棒性。我们的项目页面是https://irpn-eai.github.io/rationalvla。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [325] [Invariant Extended Kalman Filter for Autonomous Surface Vessels with Partial Orientation Measurements](https://arxiv.org/abs/2506.10850)
> *用于自主水面船舶的部分姿态测量不变扩展卡尔曼滤波器*

*Derek Benham, Easton Potokar, Joshua G. Mangelson* | **Main category: cs.RO**

**Keywords:** 不变扩展卡尔曼滤波器,自主水面船舶,部分姿态测量,状态估计,地平线观测

**Comment:** Presented at the 2025 IEEE ICRA Workshop on Field Robotics. 8 pages,
  4 figures, 2 tables

> **TL;DR:** 本文提出了一种不变扩展卡尔曼滤波器（InEKF）框架，用于整合部分姿态测量，以提高开放海洋环境中自主水面船舶（ASV）的精确状态估计。

**AI_Comments:** 本文的创新点在于提出了一个新颖的InEKF框架，能够有效地整合偏航模糊的部分姿态测量，这对于在开放海洋这种缺乏固定地标的环境中运行的ASV至关重要。它通过利用地平线观测和GPS航向数据，克服了传统InEKF对完整姿态的假设，显著提升了ASV在复杂环境下的状态估计能力。其重要性在于为未来ASV在海洋科学和水下测绘中的应用提供了更精确、更鲁棒的导航和定位解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 自主水面船舶（ASV）在海洋科学中日益重要，但精确的状态估计，特别是车辆姿态估计，对于精确的海底测绘至关重要，因为即使是小的表面偏差也会对海底传感产生重大影响。为了解决这一挑战，本文提出了一种集成部分姿态测量的方法。

**Method:** 本文提出了一种不变扩展卡尔曼滤波器（InEKF）框架，旨在整合部分姿态测量。利用前视单目摄像头估计相对于地平线的横摇和俯仰，这提供了偏航模糊的部分姿态信息。为了有效利用这些测量，引入了一种新颖的框架来整合此类部分姿态数据。该方法与假设完整姿态测量的传统InEKF实现形成对比，并且特别适用于受限于“航海平面”的平面车辆运动。本文详细介绍了开发的InEKF框架，其与基于地平线的横摇/俯仰观测以及双天线GPS航向测量的集成，用于ASV状态估计。

**Result:** 结果表明，所提出的部分姿态测量对于开放海洋环境中精确的ASV状态估计是有效且鲁棒的。

**Conclusion:** 本文提出的用于整合部分姿态测量的不变扩展卡尔曼滤波器（InEKF）框架，有效解决了自主水面船舶在开放海洋环境中精确状态估计的挑战，并通过实验证明了其有效性和鲁棒性。

> **ai_Abstract:** 本文针对自主水面船舶（ASV）在开放海洋环境中精确状态估计的挑战，提出了一种不变扩展卡尔曼滤波器（InEKF）框架。该框架创新性地整合了来自前视单目摄像头和双天线GPS的部分姿态测量（横摇、俯仰和航向），解决了传统InEKF对完整姿态测量的依赖。通过与现有方法的比较分析，研究结果验证了所提出方法在提高ASV状态估计精度和鲁棒性方面的有效性。

> **摘要翻译:** 自主水面船舶（ASV）在海洋科学中日益重要，为水下测绘和检查提供了强大的平台。精确的状态估计，特别是车辆姿态估计，对于精确的海底测绘至关重要，因为即使是小的表面偏差也可能对下方的海底传感产生重大影响。为了解决这一挑战，我们提出了一种不变扩展卡尔曼滤波器（InEKF）框架，旨在整合部分姿态测量。虽然传统估计通常依赖于相对于固定地标的相对位置测量，但开放海洋ASV主要观察到一个后退的地平线。我们利用前视单目摄像头估计相对于该地平线的横摇和俯仰，这提供了偏航模糊的部分姿态信息。为了有效利用InEKF中的这些测量，我们引入了一种新颖的框架来整合此类部分姿态数据。这种方法与假设完整姿态测量的传统InEKF实现形成对比，并且特别适用于受限于“航海平面”的平面车辆运动。本文详细介绍了开发的InEKF框架；其与基于地平线的横摇/俯仰观测和双天线GPS航向测量的集成，用于ASV状态估计；并提供了与使用完整姿态的InEKF和乘法扩展卡尔曼滤波器（MEKF）的比较分析。我们的结果证明了所提出的部分姿态测量在开放海洋环境中精确ASV状态估计的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [332] [Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material](https://arxiv.org/abs/2506.10875)
> *机器人附肢与颗粒材料动态相互作用的数据驱动预测*

*Guanjin Wang, Xiangxue Zhao, Shapour Azarm, Balakumar Balachandran* | **Main category: cs.RO**

**Keywords:** 数据驱动, 机器人交互, 颗粒材料, 预测, 建模

**Comment:** 

> **TL;DR:** 本文提出了一种新的数据驱动建模方法，用于预测机器人与颗粒材料的动态相互作用，该方法结合了降维、代理建模和数据同化技术，显著减少了计算时间，并能实现高精度预测，有望助力机器人在复杂地形中的导航与探索。

**AI_Comments:** 该论文提出了一种结合多种先进数据科学技术（降维、代理建模、数据同化）的创新数据驱动建模范式，用于解决机器人与复杂颗粒介质交互这一难题。其核心创新在于通过数据驱动的方法，在保持预测精度的同时，大幅度降低了计算成本，并展现了超越特定案例的泛化能力。这将极大地推动机器人领域在实际复杂环境（如行星探测、灾后救援）中应用。其结合模拟数据和稀疏实验数据的策略，也为数据量有限的实际应用提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 为了深入理解机器人在特定尺度下与颗粒地形的运动交互，并实现对其动态相互作用的预测。

**Method:** 提出并采用了一种数据驱动建模方法，该方法整合了：1) 降维（序贯截断高阶奇异值分解），2) 代理建模（高斯过程），以及 3) 数据同化技术（降阶粒子滤波器）。该方法基于离线收集的高保真模拟数据和少量实验数据，可用于在线预测。

**Result:** 与基于物理的高保真模拟相比，所提出的数据驱动建模方法可将计算时间减少数个数量级。仅使用模拟数据作为输入时，预测精度与模拟结果相当。结合模拟数据和稀疏物理实验测量数据时，该数据驱动方法在长期预测方面有望超越纯高保真模拟。此外，该方法还能再现物理模拟所揭示的最大阻力标度关系，表明其具有超越个案的普遍预测能力。

**Conclusion:** 该研究结果有望在线和离线阶段帮助机器人在未知和复杂地形中的导航和探索。

> **ai_Abstract:** 本文提出了一种创新的数据驱动建模方法，旨在预测机器人附肢与颗粒材料的动态相互作用。该方法通过整合序贯截断高阶奇异值分解、高斯过程和降阶粒子滤波器，利用离线高保真模拟数据和稀疏实验数据进行训练，实现在线预测。研究结果显示，与传统物理模拟相比，该方法能显著缩短计算时间，并在仅使用模拟数据时达到相当的预测精度。结合少量实验数据后，其长期预测性能有望超越纯高保真模拟。此外，该方法还能准确复现物理模拟揭示的力学标度关系，预示其具有广泛适用性，对未来机器人在复杂未知地形中的导航与探索具有重要意义。

> **摘要翻译:** 本文提出并采用了一种替代的数据驱动建模方法，以获取机器人在特定长度尺度下与颗粒地形运动交互的基本洞察。该方法基于降维（序贯截断高阶奇异值分解）、代理建模（高斯过程）和数据同化技术（降阶粒子滤波器）的集成。该方法可在线使用，并基于离线数据，这些数据通过离线收集高保真模拟数据和一组稀疏实验数据获得。结果表明，与基于物理的高保真模拟相比，所提出的数据驱动建模方法可以将计算时间减少数个数量级。仅以模拟数据作为输入时，数据驱动预测技术可以生成与模拟具有可比精度的预测。当以模拟数据和稀疏物理实验测量数据作为输入时，嵌入数据同化技术的数据驱动方法在长期预测方面有可能超越仅使用高保真模拟。此外，研究表明，数据驱动建模方法还可以重现基于物理模拟所恢复的最大阻力标度关系，这可能表明其具有超越个例的普遍可预测性。这些结果有望在线和离线阶段帮助机器人在未知和复杂地形中的导航和探索。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [339] [Modeling Trust Dynamics in Robot-Assisted Delivery: Impact of Trust Repair Strategies](https://arxiv.org/abs/2506.10884)
> *机器人辅助递送中信任动态建模：信任修复策略的影响*

*Dong Hae Mangalindan, Karthik Kandikonda, Ericka Rovira, Vaibhav Srivastava* | **Main category: cs.RO**

**Keywords:** 机器人辅助递送, 信任动态, 信任修复策略, 输入-输出隐马尔可夫模型, 人机交互

**Comment:** 

> **TL;DR:** 本文研究了在机器人辅助递送中，机器人性能和信任修复策略如何影响人类信任。通过使用IOHMM建模人类行为，发现高信任度促使自主部署，长解释最能修复故障后的信任，而否认最能防止信任损失。

**AI_Comments:** 这篇论文通过引入IOHMM来建模人类对机器人的信任动态，并评估了不同信任修复策略的效果，具有创新性。其发现对于设计更有效的人机协作系统，尤其是在自主系统出现故障时如何维护和修复人类信任具有重要指导意义。模型的可解释性也增强了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着自主系统在效率和可靠性方面的提升，它们在各种任务中成为人类的重要助手。本研究旨在机器人辅助递送的背景下，探究机器人性能和信任修复策略如何影响人类对机器人的信任。

**Method:** 研究收集了人类参与者的数据，并使用输入-输出隐马尔可夫模型（IOHMM）来建模人类行为，以捕捉信任的动态和人类行动的概率。考察的信任修复策略包括简短和冗长的解释、道歉和承诺以及否认。

**Result:** 研究结果表明，当人类信任度高时，他们更倾向于自主部署机器人。状态转换估计显示，长解释在故障后修复信任方面最有效，而否认在防止信任损失方面最有效。此外，模型生成的信任估计与自我报告的信任值同构，具有可解释性。

**Conclusion:** 该模型为未来开发优化策略奠定了基础，这些策略有助于实时调整人类对自主系统的信任。

> **ai_Abstract:** 本文在机器人辅助递送情境下，探究了机器人性能和不同信任修复策略（如解释、道歉、承诺和否认）对人类信任的影响。研究通过收集人类参与者数据，并利用输入-输出隐马尔可夫模型（IOHMM）对人类行为进行建模，以捕捉信任动态。主要发现包括：人类在高信任度下更倾向于自主部署机器人；长解释在故障后修复信任最有效；而否认在防止信任损失方面最有效。此外，模型生成的信任估计与自我报告的信任值一致，具有良好的可解释性。该模型为未来开发能够实时调整人类对自主系统信任的优化策略奠定了基础。

> **摘要翻译:** 随着效率和可靠性的不断提高，自主系统正成为人类在各种任务中的宝贵助手。在机器人辅助递送的背景下，我们研究了机器人性能和信任修复策略如何影响人类信任。在此任务中，人类在处理次要任务的同时，可以选择让机器人自主递送或手动控制它。所考察的信任修复策略包括简短和冗长的解释、道歉和承诺以及否认。
我们利用人类参与者的数据，使用输入-输出隐马尔可夫模型（IOHMM）来建模人类行为，以捕捉信任的动态和人类行动的概率。我们的研究结果表明，当信任度高时，人类更倾向于自主部署机器人。此外，状态转换估计表明，冗长的解释在故障后修复信任方面最有效，而否认在防止信任损失方面最有效。
我们还证明，模型生成的信任估计与自我报告的信任值同构，使其具有可解释性。该模型为开发优化策略奠定了基础，这些策略有助于实时调整人类对自主系统的信任。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [345] [Vib2Move: In-Hand Object Reconfiguration via Fingertip Micro-Vibrations](https://arxiv.org/abs/2506.10923)
> *Vib2Move：通过指尖微振动实现手内物体重构*

*Xili Yi, Nima Fazeli* | **Main category: cs.RO**

**Keywords:** 手内重构, 微振动, 摩擦调节, 运动规划, 平面物体操作

**Comment:** 11 pages, 12 figures

> **TL;DR:** Vib2Move是一种利用指尖微振动和重力精确重新定位平面物体的手内物体重构新方法，实现了可靠的高精度操作。

**AI_Comments:** Vib2Move的创新之处在于利用指尖微振动来动态调节摩擦力，从而实现对物体精细的在手操作，这为机器人抓取和操纵领域提供了一个新颖且高效的解决方案。其在实际应用中展现出的高精度和可靠性具有重要意义，尤其是在需要精细调整物体姿态的场景。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过一种新颖的方法，即利用指尖微振动和重力，实现手内物体的精确重新定位。

**Method:** 该方法包含三项关键创新：设计了一种动态调节有效手指-物体摩擦系数的振动执行器；推导了在具有两个对称、可变摩擦接触点的平行夹持器中夹持物体的滑动运动模型；提出了一个运动规划器，用于协调末端执行器手指轨迹和指尖振动以实现所需的物体姿态。

**Result:** 在实际试验中，Vib2Move的最终定位误差始终低于6毫米，表明其在各种平面物体上实现了可靠的高精度操作。

**Conclusion:** Vib2Move通过利用指尖微振动和重力，能够可靠且高精度地实现手内物体的重构。

> **ai_Abstract:** Vib2Move提出了一种新颖的手内物体重构方法，该方法利用指尖微振动和重力来精确重新定位平面物体。其核心创新包括一个能动态调节摩擦系数的振动执行器、一个用于平行夹持器的滑动运动模型以及一个协调手指轨迹和振动的运动规划器。实验结果显示，Vib2Move的最终定位误差小于6毫米，证明了其在多种平面物体操作中的高精度和可靠性。

> **摘要翻译:** 我们引入了Vib2Move，这是一种利用指尖微振动和重力精确重新定位平面物体的手内物体重构新方法。我们的框架包含三项关键创新。首先，我们设计了一种基于振动的执行器，可以动态调节有效的手指-物体摩擦系数，有效地模拟抓取力的变化。其次，我们推导了一个在具有两个对称、可变摩擦接触点的平行夹持器中夹持物体的滑动运动模型。第三，我们提出了一个运动规划器，用于协调末端执行器手指轨迹和指尖振动，以实现所需的物体姿态。在实际试验中，Vib2Move的最终定位误差始终低于6毫米，表明其在各种平面物体上实现了可靠的高精度操作。欲了解更多结果和信息，请访问 https://vib2move.github.io。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [352] [GENMANIP: LLM-driven Simulation for Generalizable Instruction-Following Manipulation](https://arxiv.org/abs/2506.10966)
> *GENMANIP：LLM驱动的通用指令遵循操纵模拟*

*Ning Gao, Yilun Chen, Shuai Yang, Xinyi Chen, Yang Tian, Hao Li, Haifeng Huang, Hanqing Wang, Tai Wang, Jiangmiao Pang* | **Main category: cs.RO**

**Keywords:** 机器人操纵, LLM, 模拟, 泛化, 基础模型

**Comment:** 

> **TL;DR:** 该论文介绍了GenManip，一个由LLM驱动的模拟平台和基准（GenManip-Bench），用于研究机器人操纵策略的泛化能力，发现带有基础模型的模块化系统比扩展的端到端方法具有更好的泛化能力。

**AI_Comments:** 本文通过整合LLM生成多样化任务，弥补了机器人模拟中的一个关键空白，具有创新性。GenManip和GenManip-Bench的引入为机器人操纵中的泛化能力系统评估提供了急需的工具，尤其是在基础模型的背景下。研究发现带有基础模型的模块化系统比扩展的端到端方法具有更好的泛化能力，这对未来的研究方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有模拟平台缺乏足够的支持来探索机器人策略如何适应不同的指令和场景，尤其是在LLM等指令遵循基础模型日益增长的背景下。机器人操纵在现实世界中的鲁棒泛化能力仍然是一个挑战，且LLM在机器人适应性方面的潜力尚未得到充分探索。

**Method:** 1. GenManip平台：一个为策略泛化研究量身定制的真实桌面模拟平台。2. 自动化管道：通过LLM驱动的任务导向场景图，利用10K带注释的3D对象资产合成大规模、多样化的任务。3. GenManip-Bench：一个通过人工循环校正精炼的200个场景基准，用于系统评估泛化能力。4. 评估：评估了两种策略类型：（1）集成基础模型用于感知、推理和规划的模块化操纵系统；（2）通过可扩展数据收集训练的端到端策略。

**Result:** 数据扩展有利于端到端方法，但增强了基础模型的模块化系统在不同场景中泛化能力更强。

**Conclusion:** 该平台有望为在现实条件下推进策略泛化提供关键见解。

> **ai_Abstract:** 本文介绍了GenManip，一个由LLM驱动的真实桌面模拟平台及其配套基准GenManip-Bench，旨在解决机器人操纵中鲁棒泛化的挑战。GenManip利用自动化管道和10K带注释的3D资产来合成多样化的任务。GenManip-Bench包含200个人工精炼的场景，用于系统评估。该研究评估了集成基础模型的模块化操纵系统和端到端策略，结果表明，尽管数据扩展有助于端到端方法，但带有基础模型的模块化系统在不同场景中表现出更优越的泛化能力。该平台旨在为现实条件下的策略泛化提供更深入的见解。

> **摘要翻译:** 机器人操纵在现实世界中仍然具有挑战性，尤其是在鲁棒泛化方面。现有模拟平台缺乏足够的支持来探索策略如何适应不同的指令和场景。因此，它们落后于人们对LLM等指令遵循基础模型日益增长的兴趣，这些模型的适应性至关重要，但在公平比较中仍未得到充分探索。为了弥补这一差距，我们引入了GenManip，一个为策略泛化研究量身定制的真实桌面模拟平台。它通过LLM驱动的任务导向场景图的自动化管道，利用10K带注释的3D对象资产合成大规模、多样化的任务。为了系统地评估泛化能力，我们提出了GenManip-Bench，这是一个通过人工循环校正精炼的200个场景的基准。我们评估了两种策略类型：（1）集成基础模型用于感知、推理和规划的模块化操纵系统，以及（2）通过可扩展数据收集训练的端到端策略。结果表明，虽然数据扩展有利于端到端方法，但增强了基础模型的模块化系统在不同场景中泛化能力更强。我们预计该平台将为在现实条件下推进策略泛化提供关键见解。项目页面：https://genmanip.axi404.top/。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [358] [Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop](https://arxiv.org/abs/2506.10968)
> *眼，机器人：通过BC-RL感知-动作循环学习观察以行动*

*Justin Kerr, Kush Hari, Ethan Weber, Chung Min Kim, Brent Yi, Tyler Bonnen, Ken Goldberg, Angjoo Kanazawa* | **Main category: cs.RO**

**Keywords:** 手眼协调, 凝视控制, 强化学习, 机器人操作, 中央凹感知

**Comment:** Project page: https://www.eyerobot.net/

> **TL;DR:** 本文介绍了EyeRobot，一个通过BC-RL循环学习凝视行为的机器人系统，使其能够有效地进行大范围操作，模拟人类主动观察以行动的方式。

**AI_Comments:** 本文的创新点在于其提出的BC-RL循环，实现了手眼系统的联合训练，使得机器人能够学习到类似人类的主动凝视行为，以高效完成任务。受中央凹启发的感知架构在保证高分辨率的同时，有效控制了计算成本。这对于提高机器人操作在复杂、大范围环境中的鲁棒性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 受人类主动观察世界以采取行动的启发，本文旨在开发一个机器人系统，使其凝视行为能够从完成现实世界任务的需求中自然产生。

**Method:** 研究开发了一个可自由旋转的机械眼球，并使用强化学习训练其凝视策略。首先收集带有360度摄像头的遥操作演示数据，然后将其导入支持任意眼球视点渲染的仿真环境。接着引入一个BC-RL（行为克隆-强化学习）循环来联合训练手和眼：手（BC）代理从渲染的眼部观察中训练，而眼（RL）代理则在手产生正确动作预测时获得奖励。此外，EyeRobot采用了一种受中央凹启发的策略架构，以在小计算预算下实现高分辨率感知。

**Result:** EyeRobot实现了手眼协调行为，眼部会看向有助于手完成任务的区域。该系统在小计算预算下实现了高分辨率，并带来了更稳定的注视以及更好的物体追踪和干扰物忽略能力。实验表明，EyeRobot能够有效地促进使用单个摄像头在大工作空间内的操作。

**Conclusion:** EyeRobot系统通过模仿人类主动观察以行动的方式，成功地实现了机器人手眼协调，使其能够高效地在广阔的工作空间内完成操作任务，并展现出稳定的凝视和优异的物体追踪能力。

> **ai_Abstract:** EyeRobot是一个受人类主动观察行为启发的机器人系统，它通过一个可旋转的机械眼球和基于强化学习的凝视策略实现手眼协调。系统采用BC-RL循环联合训练手和眼，其中手的行为克隆代理从眼的观察中学习，而眼的强化学习代理则根据手的正确预测获得奖励。此外，其受中央凹启发的架构在计算效率下提供了高分辨率感知。实验证明，EyeRobot能有效进行大范围操作，展现出稳定的凝视和卓越的物体追踪能力。

> **摘要翻译:** 人类并非被动地观察视觉世界——我们积极地观察以便行动。受此原理启发，我们引入了EyeRobot，一个具有凝视行为的机器人系统，其行为源于完成现实世界任务的需求。我们开发了一个可以自由旋转以观察周围环境的机械眼球，并使用强化学习训练其凝视策略来控制它。我们首先收集了与360度摄像头配对的遥操作演示数据。这些数据被导入到一个支持渲染任意眼球视点的仿真环境中，从而可以在机器人演示的基础上进行眼球凝视的片段回放。然后，我们引入了一个BC-RL循环来联合训练手和眼：手（BC）代理从渲染的眼部观察中进行训练，而眼（RL）代理在手产生正确动作预测时获得奖励。通过这种方式，手眼协调得以产生，因为眼部会看向允许手完成任务的区域。EyeRobot实现了一种受中央凹启发的策略架构，在小计算预算下实现高分辨率，我们发现这也导致了更稳定的注视以及更好的物体追踪和忽略干扰物的能力。我们在五个需要机器臂周围弧形操作的全景工作空间操作任务上评估了EyeRobot。我们的实验表明，EyeRobot展现了手眼协调行为，有效地促进了使用单个摄像头在大工作空间内的操作。请访问项目网站观看视频：https://www.eyerobot.net/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [29] [Multimodal Cinematic Video Synthesis Using Text-to-Image and Audio Generation Models](https://arxiv.org/abs/2506.10005)
> *多模态电影视频合成：基于文本到图像和音频生成模型*

*Sridhar S, Nithin A, Shakeel Rifath, Vasantha Raj* | **Main category: cs.CV**

**Keywords:** 电影视频合成, 文本到视频, Stable Diffusion, GPT-2, 多模态生成

**Comment:** 10 pages, seven figures about Multimodal Cinematic Video Synthesis
  Using Text-to-Image and Audio Generation Models

> **TL;DR:** 该研究提出了一种使用文本到图像和音频生成模型自动合成60秒电影视频的方法，结合了Stable Diffusion、GPT-2和混合音频管线，实现了高质量、连贯的电影视频。

**AI_Comments:** 这项工作通过集成多种先进的生成模型（如Stable Diffusion和GPT-2）并结合专业的电影制作技术（如帧插值、后期处理），在文本到视频合成领域取得了显著进展。其创新点在于构建了一个端到端的多模态合成管线，能够生成具有叙事结构和高质量视听效果的电影视频。其局限性可能包括对特定GPU环境的依赖以及在生成更长或更复杂叙事视频时的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 生成式人工智能的进步改变了多媒体创作，使得从文本输入自动合成电影视频成为可能。

**Method:** 该方法结合了Stable Diffusion进行高保真图像合成，GPT-2进行叙事结构，以及使用gTTS和YouTube来源音乐的混合音频管线。它采用五场景框架，并通过线性帧插值、电影后期处理（如锐化）和音视频同步进行增强。该系统在GPU加速的Google Colab环境中使用Python 3.11开发，并提供双模式Gradio界面，支持高达1024x768的分辨率和15-30 FPS的帧率，同时包含CUDA内存管理和错误处理等优化。

**Result:** 实验证明了该方法在视觉质量、叙事连贯性和效率方面的出色表现。

**Conclusion:** 该方法进一步推动了文本到视频合成技术，适用于创意、教育和工业应用。

> **ai_Abstract:** 这篇论文介绍了一种多模态电影视频合成方法，能够根据文本输入自动生成60秒的电影视频。该系统整合了Stable Diffusion进行图像生成、GPT-2进行叙事构建，并结合了gTTS和YouTube音乐的混合音频方案。通过五场景框架、帧插值、后期处理和音视频同步，该方法在Google Colab环境下实现了专业级的视觉质量和叙事连贯性，为文本到视频合成在多种应用中提供了高效且高质量的解决方案。

> **摘要翻译:** 生成式人工智能的进步改变了多媒体创作，使得从文本输入自动合成电影视频成为可能。这项工作描述了一种创建60秒电影的方法，该方法结合了Stable Diffusion用于高保真图像合成、GPT-2用于叙事结构，以及使用gTTS和YouTube来源音乐的混合音频管线。它采用五场景框架，并通过线性帧插值、电影后期处理（例如锐化）和音视频同步进行增强，以提供专业质量的结果。它是在GPU加速的Google Colab环境中使用Python 3.11创建的。它具有双模式Gradio界面（简单和高级），支持高达1024x768的分辨率和15-30 FPS的帧率。CUDA内存管理和错误处理等优化确保了可靠性。实验展示了出色的视觉质量、叙事连贯性和效率，进一步推动了文本到视频合成在创意、教育和工业应用中的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [55] [LoRA-Edit: Controllable First-Frame-Guided Video Editing via Mask-Aware LoRA Fine-Tuning](https://arxiv.org/abs/2506.10082)
> *LoRA-Edit：通过掩码感知LoRA微调实现可控的首帧引导视频编辑*

*Chenjian Gao, Lihe Ding, Xin Cai, Zhanpeng Huang, Zibin Wang, Tianfan Xue* | **Main category: cs.CV**

**Keywords:** 视频编辑, 扩散模型, LoRA, 掩码, 首帧引导

**Comment:** 12 pages

> **TL;DR:** LoRA-Edit提出了一种基于掩码的LoRA微调方法，用于可控的首帧引导视频编辑，解决了现有方法灵活性不足的问题，并在保持背景的同时实现可控编辑传播。

**AI_Comments:** 该论文的创新点在于结合了LoRA微调与掩码感知机制，为视频编辑提供了更精细的区域控制和更高的灵活性，尤其是在保持背景的同时进行局部编辑的能力。这种方法无需大规模预训练或改变模型架构，使得视频编辑更加高效和可控。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散模型视频编辑方法依赖大规模预训练，限制了特定编辑的灵活性；首帧引导编辑对后续帧缺乏灵活性。

**Method:** 提出LoRA-Edit，一种基于掩码的LoRA微调方法，用于适应预训练的图像到视频（I2V）模型。该方法通过空间掩码实现区域特定学习，动态调制模型关注点，确保每个区域从输入视频（空间结构和运动）和参考图像（外观指导）中获取信息，同时保持背景区域并实现可控编辑传播。

**Result:** 实验结果表明，该方法在视频编辑性能上优于现有SOTA方法。

**Conclusion:** LoRA-Edit通过其掩码感知LoRA微调策略，提供了一种高效、灵活且可控的视频编辑解决方案，解决了现有方法的局限性，并实现了卓越的性能。

> **ai_Abstract:** 本文提出LoRA-Edit，一种基于掩码的LoRA微调方法，旨在解决现有扩散模型视频编辑在灵活性和后续帧控制上的不足。通过将预训练的图像到视频模型适应于编辑任务，LoRA-Edit利用空间掩码实现区域特定学习，并结合输入视频和参考图像提供的信息，在保持背景的同时实现可控的编辑传播，且无需修改模型架构。实验证明其性能优于现有SOTA方法。

> **摘要翻译:** 扩散模型在视频编辑方面取得了显著成果，能够生成高质量的视频编辑。然而，当前方法通常依赖于大规模预训练，限制了特定编辑的灵活性。首帧引导编辑提供了对第一帧的控制，但对后续帧缺乏灵活性。为了解决这个问题，我们提出了一种基于掩码的LoRA（低秩适应）微调方法，该方法调整预训练的图像到视频（I2V）模型以实现灵活的视频编辑。我们的方法在保留背景区域的同时，能够实现可控的编辑传播。该解决方案提供了高效且适应性强的视频编辑，而无需改变模型架构。为了更好地引导这一过程，我们引入了额外的参考，例如替代视角或代表性场景状态，它们作为内容应如何展开的视觉锚点。我们通过掩码驱动的LoRA微调策略解决了控制挑战，该策略将预训练的图像到视频模型适应到编辑上下文中。模型必须从两个不同来源学习：输入视频提供空间结构和运动线索，而参考图像提供外观指导。空间掩码通过动态调制模型关注的内容来实现区域特定学习，确保每个区域都从适当的来源获取信息。实验结果表明，我们的方法比最先进的方法实现了更优异的视频编辑性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [58] [A Manually Annotated Image-Caption Dataset for Detecting Children in the Wild](https://arxiv.org/abs/2506.10117)
> *一个用于检测野外儿童的手动标注图像-字幕数据集*

*Klim Kireev, Ana-Maria Creţu, Raphael Meier, Sarah Adel Bargal, Elissa Redmiles, Carmela Troncoso* | **Main category: cs.CV**

**Keywords:** 儿童检测, 图像-字幕数据集, 未成年人内容, 数据集, 内容审核

**Comment:** 14 pages, 6 figures

> **TL;DR:** 发布了一个新的手动标注图像-字幕数据集（ICCWD），用于检测未成年人，结果显示儿童检测是一项具有挑战性的任务，现有工具仍有局限性。

**AI_Comments:** 本文通过提供一个急需的多模态数据集，解决了内容审核中一个关键且受法律约束的领域。手动标注和多样化的内容（虚构、部分可见）是其显著优势，使其比以前的数据集更具鲁棒性。基准测试结果突出了现有检测工具的局限性，强调了该数据集对未来在该挑战性领域进行研究和开发的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 平台和法律对描绘未成年人的数字内容有特殊规定，现有机器学习自动化工具需要更好的基准测试，但目前缺乏用于多模态环境下检测未成年人的数据集。

**Method:** 发布了图像-字幕野外儿童数据集（ICCWD），包含10,000对手动标注的图像-字幕对，涵盖虚构描绘和部分可见身体等多种情境。使用ICCWD对包括商业年龄估计系统在内的三种不同检测器进行了基准测试。

**Result:** 儿童检测是一项具有挑战性的任务，最好的方法达到了75.3%的真阳性率。

**Conclusion:** ICCWD数据集的发布有望帮助在各种场景下设计出更好的未成年人检测方法。

> **ai_Abstract:** 本文介绍了野外儿童图像-字幕数据集（ICCWD），这是一个新的手动标注图像-字幕数据集，包含10,000对图像-字幕，旨在为检测数字内容中的未成年人工具提供基准。鉴于该受监管领域缺乏多模态数据集，ICCWD包含了虚构和部分可见描绘等多种情境。使用现有检测器进行的基准测试表明，儿童检测仍然是一项具有挑战性的任务，最佳性能真阳性率为75.3%。该数据集旨在促进改进未成年人检测方法的发展。

> **摘要翻译:** 平台和法律对描绘未成年人（定义为18岁以下个体）的数字内容有不同于其他类型内容的规定。鉴于需要评估的内容量巨大，机器学习自动化工具常用于检测描绘未成年人的内容。据我们所知，目前在多模态环境下还没有用于检测这些识别方法的现有数据集或基准。为了填补这一空白，我们发布了图像-字幕野外儿童数据集（ICCWD），这是一个旨在为检测未成年人描绘的工具提供基准的图像-字幕数据集。我们的数据集比以前的儿童图像数据集更丰富，包含各种情境下的儿童图像，包括虚构描绘和部分可见的身体。ICCWD包含10,000对手动标注的图像-字幕对，用于指示图像中是否存在儿童。为了展示我们数据集的潜在效用，我们使用它对三种不同的检测器进行了基准测试，包括应用于图像的商业年龄估计系统。我们的结果表明，儿童检测是一项具有挑战性的任务，最好的方法达到了75.3%的真阳性率。我们希望我们数据集的发布将有助于在各种场景下设计出更好的未成年人检测方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [80] [DeepTraverse: A Depth-First Search Inspired Network for Algorithmic Visual Understanding](https://arxiv.org/abs/2506.10084)
> *DeepTraverse：一种受深度优先搜索启发的算法视觉理解网络*

*Bin Guo, John H. L. Hansen* | **Main category: cs.CV**

**Keywords:** 深度学习, 视觉骨干网络, 深度优先搜索, 图像分类, 算法先验

**Comment:** NeurIPS 2025

> **TL;DR:** DeepTraverse是一种受深度优先搜索启发的视觉网络，通过递归探索和自适应校准模块，学习更具算法性和结构化的特征，在图像分类任务上表现出色。

**AI_Comments:** DeepTraverse的创新之处在于将经典搜索算法（特别是深度优先搜索）的原理融入到深度学习视觉骨干网络的设计中，打破了传统网络统一级联操作的局限性。这种方法使得网络能够进行更具解释性和推理性的特征学习。其采用的递归探索和自适应校准模块是实现这一目标的关键。该研究为构建更高效、高性能且结构化的视觉模型提供了一个新颖的视角和有效策略，对于提升模型的可解释性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视觉骨干网络在特征构建过程中缺乏明确的自适应、迭代细化路径。本文旨在探讨能否将经典搜索算法的原理融入神经网络，以实现更具算法性、结构化和逻辑性的处理流程，从而构建更可解释的表示。

**Method:** 本文引入了DeepTraverse，这是一种受算法搜索策略直接启发的新型视觉架构。它通过两个关键协同组件实现：递归探索模块（通过参数共享系统地深化特征分析）和自适应校准模块（根据全局上下文动态调整特征显著性）。这种算法间的相互作用使得DeepTraverse能够智能地构建和细化特征模式。

**Result:** 在多种图像分类基准测试中，DeepTraverse取得了极具竞争力的分类准确性和鲁棒的特征判别能力，通常优于参数数量相似或更大的传统模型。

**Conclusion:** 将算法先验知识整合到视觉骨干网络中，是构建更高效、高性能和结构化视觉骨干的一种有原则且有效的策略。

> **ai_Abstract:** 本文提出了DeepTraverse，一种受深度优先搜索启发的视觉网络架构，旨在解决传统视觉骨干网络在特征学习中缺乏自适应迭代细化的问题。DeepTraverse通过递归探索模块进行深度特征分析和自适应校准模块动态调整特征显著性，实现了更具算法性和结构化的特征构建。实验证明，DeepTraverse在图像分类任务上取得了与传统模型相当或更优的性能，验证了将算法先验整合到视觉网络中的有效性。

> **摘要翻译:** 尽管传统的视觉骨干网络取得了成功，但它们通常通过一种 largely 统一的操作级联来构建特征，为自适应、迭代细化提供了有限的显式路径。这提出了一个引人注目的问题：经典搜索算法的原理能否在这些网络中注入更具算法性、结构化和逻辑性的处理流程，从而通过更可解释、或许类似推理的决策过程来构建表示？我们引入了 DeepTraverse，一种受算法搜索策略直接启发的新型视觉架构，使其能够通过与传统方法不同的系统阐明和自适应细化过程来学习特征。DeepTraverse 通过两个关键协同组件来实现这一点：递归探索模块，通过参数共享沿着有前景的表示路径系统地深化特征分析，以及自适应校准模块，根据不断演变的全局上下文动态调整特征显著性。由此产生的算法相互作用使 DeepTraverse 能够智能地构建和细化特征模式。对各种图像分类基准的全面评估表明，DeepTraverse 实现了极具竞争力的分类准确性和鲁棒的特征判别能力，通常优于参数数量相似或更大的传统模型。我们的工作表明，整合此类算法先验知识为构建更高效、高性能和结构化的视觉骨干网络提供了一种有原则且有效的策略。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [106] [Test-Time Adaptation for Generalizable Task Progress Estimation](https://arxiv.org/abs/2506.10085)
> *用于可泛化任务进度估计的测试时适应*

*Christos Ziakas, Alessandra Russo* | **Main category: cs.CV**

**Keywords:** 测试时适应, 任务进度估计, 元学习, 自监督学习, 泛化能力

**Comment:** pages, 2 figures, accepted to the 2nd Workshop on Test-Time
  Adaptation: Putting Updates to the Test (PUT) at 42nd International
  Conference on Machine Learning (ICML), Vancouver, Canada, 2025

> **TL;DR:** 本文提出了一种测试时适应方法，通过优化自监督目标，使任务进度估计模型能够在线适应测试轨迹的视觉和时间上下文，并在多样化的OOD任务、环境和实体上表现优于SOTA方法。

**AI_Comments:** 该论文的创新点在于提出了将测试时适应与元学习相结合，以提高任务进度估计在复杂和多样化环境中的泛化能力。通过强调语义内容而非时间顺序，解决了传统方法在处理分布外数据时的局限性。其重要性在于为机器人学习和自动化任务监控等领域提供了更鲁棒的进度估计解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了使进度估计模型能够在线适应测试轨迹的视觉和时间上下文，并提高其在多样化、分布外任务中的泛化能力。

**Method:** 提出了一种测试时适应方法，通过优化学习到的自监督目标，使进度估计模型能够在线适应测试轨迹。为此，引入了一种基于梯度的元学习策略，用于在专家视觉轨迹及其自然语言任务描述上训练模型，以使测试时适应能够通过依赖语义内容而非时间顺序来改进进度估计。

**Result:** 测试时适应方法能够从单一训练环境泛化到多样化的分布外任务、环境和实体，并且优于使用自回归视觉-语言模型的最先进的上下文学习方法。

**Conclusion:** 所提出的测试时适应方法通过在线适应测试轨迹的视觉和时间上下文，显著提高了任务进度估计的泛化能力，并在多样化的分布外场景中取得了优于现有技术的效果。

> **ai_Abstract:** 该论文提出了一种用于任务进度估计的测试时适应方法。该方法通过优化一个学习到的自监督目标，使模型能够在线适应测试轨迹的视觉和时间上下文。通过引入一种基于梯度的元学习策略，模型在专家视觉轨迹和自然语言任务描述上进行训练，使得测试时适应能够优先利用语义内容而非时间顺序来提高进度估计的准确性。实验证明，该方法在从单一训练环境泛化到多样化的分布外任务、环境和实体方面表现出色，并超越了当前最先进的自回归视觉-语言模型所采用的上下文学习方法。

> **摘要翻译:** 我们提出了一种测试时适应方法，该方法通过优化学习到的自监督目标，使进度估计模型能够在线适应测试轨迹的视觉和时间上下文。为此，我们引入了一种基于梯度的元学习策略，用于在专家视觉轨迹及其自然语言任务描述上训练模型，以使测试时适应能够通过依赖语义内容而非时间顺序来改进进度估计。我们的测试时适应方法能够从单一训练环境泛化到多样化的分布外任务、环境和实体，并且优于使用自回归视觉-语言模型的最先进的上下文学习方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [129] [EfficientVLA: Training-Free Acceleration and Compression for Vision-Language-Action Models](https://arxiv.org/abs/2506.10100)
> *EfficientVLA：面向视觉-语言-动作模型的免训练加速与压缩*

*Yantai Yang, Yuhao Wang, Zichen Wen, Luo Zhongwei, Chang Zou, Zhipeng Zhang, Chuan Wen, Linfeng Zhang* | **Main category: cs.CV**

**Keywords:** 视觉-语言-动作模型, 模型加速, 模型压缩, 免训练, 具身智能

**Comment:** 

> **TL;DR:** EfficientVLA是一个免训练的推理加速框架，通过整合三种策略（语言模块剪枝、视觉令牌优化、动作头特征复用）显著加速并压缩了VLA模型，同时保持了性能。

**AI_Comments:** EfficientVLA的创新之处在于其“免训练”和“系统性”地处理VLA模型的多方面冗余，而非零散地解决问题。它通过针对性地优化语言、视觉和动作模块，提供了一个全面的加速方案，这对于VLA模型在资源受限环境下的部署具有重要意义。性能提升显著且性能下降极小，表明其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作（VLA）模型，特别是基于扩散的架构，在具身智能方面潜力巨大，但其高计算和内存需求（源于固有的和推理时的冗余）严重阻碍了实际部署。现有加速方法通常是零散的，未能全面解决VLA整个流程中的计算和内存瓶颈。

**Method:** 论文引入了EfficientVLA，一个结构化、免训练的推理加速框架。它通过协同整合三种目标策略来系统性地消除障碍：1) 根据层间冗余分析，对语言模块中功能不重要的层进行剪枝；2) 通过任务感知策略优化视觉处理路径，选择紧凑、多样化的视觉令牌，平衡任务关键性和信息覆盖；3) 通过策略性缓存和重用关键中间特征，减轻迭代扩散型动作头中的时间计算冗余。

**Result:** 将该方法应用于标准VLA模型CogACT，在SIMPLER基准测试中实现了1.93倍的推理速度提升，FLOPs降低至28.9%，而成功率仅下降0.6%。

**Conclusion:** EfficientVLA作为一个免训练的框架，通过系统性地处理VLA模型中的多方面冗余，显著提升了其推理效率和计算效率，同时保持了高水平的任务性能，从而解决了VLA模型在实际部署中的主要障碍。

> **ai_Abstract:** 本文提出了EfficientVLA，一个免训练的推理加速框架，旨在解决视觉-语言-动作（VLA）模型（特别是基于扩散的架构）在计算和内存方面的瓶颈。EfficientVLA通过整合语言模块剪枝、视觉令牌优化以及动作头特征复用这三种策略，系统性地消除了模型冗余。实验结果显示，应用于CogACT模型时，EfficientVLA实现了1.93倍的推理速度提升和71.1%的FLOPs减少，同时在SIMPLER基准测试中仅导致0.6%的成功率下降，显著提升了VLA模型的实际部署能力。

> **摘要翻译:** 视觉-语言-动作（VLA）模型，特别是基于扩散的架构，在具身智能方面展现出变革性潜力，但其固有的和推理时的大量冗余导致的高计算和内存需求严重阻碍了其发展。尽管现有加速工作通常针对孤立的低效率问题，但这些零散的解决方案通常未能全面解决整个VLA管道中各种计算和内存瓶颈，从而限制了实际部署。我们引入了EfficientVLA，一个结构化且免训练的推理加速框架，通过协同利用多方面的冗余系统性地消除了这些障碍。EfficientVLA协同整合了三种有针对性的策略：(1) 根据层间冗余分析，对语言模块中功能不重要的层进行剪枝；(2) 通过任务感知策略优化视觉处理路径，选择一组紧凑、多样化的视觉令牌，平衡任务关键性和信息覆盖；(3) 通过策略性缓存和重用关键中间特征，减轻迭代扩散型动作头中的时间计算冗余。我们将我们的方法应用于标准VLA模型CogACT，实现了1.93倍的推理速度提升，并将FLOPs降低至28.9%，在SIMPLER基准测试中成功率仅下降0.6%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [133] [From Images to Insights: Explainable Biodiversity Monitoring with Plain Language Habitat Explanations](https://arxiv.org/abs/2506.10559)
> *从图像到洞察：用通俗语言解释栖息地，实现可解释的生物多样性监测*

*Yutong Zhou, Masahiro Ryo* | **Main category: cs.CV**

**Keywords:** 生物多样性监测, 可解释人工智能, 因果推断, 栖息地解释, 生态系统

**Comment:** Code will be released at: https://github.com/Yutong-Zhou-cv/BioX

> **TL;DR:** 本文提出了一个端到端的可视化到因果框架，用于生物多样性监测，该框架将物种图像转化为可解释的栖息地偏好因果洞察，并通过大语言模型生成通俗易懂的解释。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的可视化到因果框架，将图像数据与因果推断相结合，并利用大语言模型生成人类可读的解释。这极大地提高了生态学工作流程的可解释性和可访问性，对于非专业人士理解复杂的生物多样性数据具有重要意义。其潜力在于促进生物多样性监测和保护，但目前仍处于早期结果阶段，未来的验证和扩展性值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 解释物种为何生活在特定地点对于理解生态系统和保护生物多样性至关重要。然而，现有的生态工作流程是碎片化的，且非专业人士往往难以接触。

**Method:** 提出一个端到端的可视化到因果框架，将物种图像转化为关于其栖息地偏好的可解释因果洞察。该系统整合了物种识别、全球出现数据检索、伪缺失采样和气候数据提取。然后，利用现代因果推断方法发现环境特征之间的因果结构并估计它们对物种出现的影响。最后，通过结构化模板和大语言模型生成基于统计的、人类可读的因果解释。

**Result:** 该框架在一种蜜蜂和一种花卉物种上进行了演示，并报告了早期结果，显示了多模态AI助手在推荐的生态建模实践支持下，用人类可理解的语言描述物种栖息地的潜力。

**Conclusion:** 该框架展示了通过整合AI技术和生态建模实践，生成可解释的、人类可理解的物种栖息地解释，从而促进生物多样性监测和生态系统理解的潜力。

> **ai_Abstract:** 本文提出了一个名为“从图像到洞察”的端到端可视化到因果框架，旨在为生物多样性监测提供可解释的栖息地解释。该框架通过整合物种识别、数据检索、采样和气候数据提取，从物种图像中提取可解释的因果洞察，揭示环境特征对物种出现的影响。通过运用现代因果推断方法和大语言模型，系统能够生成统计学上严谨且人类可读的栖息地因果解释。初步结果表明，该系统在帮助非专业人士理解复杂生态数据方面具有巨大潜力，有助于促进生物多样性保护。

> **摘要翻译:** 解释物种为何生活在特定地点对于理解生态系统和保护生物多样性至关重要。然而，现有的生态工作流程是碎片化的，且非专业人士往往难以接触。我们提出了一个端到端的可视化到因果框架，该框架将物种图像转化为关于其栖息地偏好的可解释因果洞察。该系统整合了物种识别、全球出现数据检索、伪缺失采样和气候数据提取。然后，我们利用现代因果推断方法发现环境特征之间的因果结构并估计它们对物种出现的影响。最后，我们通过结构化模板和大语言模型生成基于统计的、人类可读的因果解释。我们在一种蜜蜂和一种花卉物种上演示了该框架，并报告了作为正在进行的项目一部分的早期结果，显示了由推荐的生态建模实践支持的多模态AI助手用人类可理解的语言描述物种栖息地的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [169] [Detecção da Psoríase Utilizando Visão Computacional: Uma Abordagem Comparativa Entre CNNs e Vision Transformers](https://arxiv.org/abs/2506.10119)
> *银屑病检测中的计算机视觉应用：CNNs与Vision Transformers的比较方法*

*Natanael Lucena, Fábio S. da Silva, Ricardo Rios* | **Main category: cs.CV**

**Keywords:** 银屑病检测, 计算机视觉, 卷积神经网络, Vision Transformers, 医学图像分类

**Comment:** 12 pages, in Portuguese language, 2 figures, 2 tables, and 4
  formulas. To be published in the Proceedings of the LII Brazilian Integrated
  Software and Hardware Seminar 2025 (SEMISH 2025)

> **TL;DR:** 该研究比较了CNN和Vision Transformer在银屑病图像分类中的表现，发现Vision Transformer，特别是DaViT-B，在较小模型下表现更优，并推荐其用于自动化银屑病检测。

**AI_Comments:** 本文的创新之处在于首次将Vision Transformers应用于银屑病图像的自动化检测，并与传统的CNNs进行性能比较。其重要性在于证明了ViTs在医学图像分类任务中，尤其是在模型规模较小的情况下，能够超越CNNs，为未来高效、准确的医学诊断提供了新的方向和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在比较CNNs和Vision Transformers在多分类含有银屑病及类似疾病病变图像任务中的性能。

**Method:** 论文采用的方法是比较预训练在ImageNet上的卷积神经网络（CNNs）和Vision Transformers（ViTs）在特定数据集上进行多类别图像分类的性能，用于检测银屑病及其类似疾病。

**Result:** CNNs和ViTs都取得了高预测指标。ViTs在较小模型下表现出卓越的性能。其中，Dual Attention Vision Transformer-Base (DaViT-B) 获得了最佳结果，f1-score达到96.4%。

**Conclusion:** DaViT-B被推荐为自动化银屑病检测最有效的架构。本文强化了ViTs在医学图像分类任务中的潜力。

> **ai_Abstract:** 本文比较了卷积神经网络（CNNs）和Vision Transformers（ViTs）在银屑病及类似疾病图像多分类任务中的表现。研究发现，尽管两者均表现出色，但ViTs在较小模型下展现出优越性能。特别是Dual Attention Vision Transformer-Base (DaViT-B) 取得了96.4%的f1-score，并被推荐为自动化银屑病检测的最佳架构，强调了ViTs在医学图像分类领域的潜力。

> **摘要翻译:** 这篇论文比较了卷积神经网络（CNNs）和Vision Transformers（ViTs）在多类别图像分类任务中的性能，这些图像包含银屑病及其类似疾病的病变。在ImageNet上预训练的模型被适配到一个特定的数据集。两者都取得了高预测指标，但ViTs以其在较小模型下的卓越性能脱颖而出。Dual Attention Vision Transformer-Base (DaViT-B) 取得了最好的结果，f1-score达到96.4%，并被推荐为自动化银屑病检测最有效的架构。本文强化了ViTs在医学图像分类任务中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [185] [ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs](https://arxiv.org/abs/2506.10128)
> *ViCrit：一种用于VLM中视觉感知的可验证强化学习代理任务*

*Xiyao Wang, Zhengyuan Yang, Chao Feng, Yongyuan Liang, Yuhang Zhou, Xiaoyu Liu, Ziyi Zang, Ming Li, Chung-Ching Lin, Kevin Lin, Linjie Li, Furong Huang, Lijuan Wang* | **Main category: cs.CV**

**Keywords:** 视觉语言模型, 强化学习, 视觉感知, 幻觉批判, ViCrit

**Comment:** 

> **TL;DR:** 引入ViCrit，一个强化学习代理任务，通过定位视觉幻觉来提高VLM的视觉感知能力，并在多个基准测试中取得显著进步。

**AI_Comments:** ViCrit的创新之处在于它将强化学习应用于视觉感知，通过构建一个巧妙的代理任务解决了视觉领域缺乏可验证挑战性任务的难题。其通过注入细微幻觉并要求模型定位错误的方式，不仅保持了感知难度，还提供了清晰的二元奖励，这对于RL训练至关重要。研究结果显示其泛化能力强，对VLM的视觉理解能力提升具有重要意义，超越了简单的记忆。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在LLMs的微调中表现出色，但在VLMs的视觉感知领域，缺乏同时具有挑战性和可明确验证的视觉中心任务，阻碍了其成功扩展。

**Method:** 提出ViCrit（Visual Caption Hallucination Critic）作为强化学习代理任务。该任务通过在人工编写的图像描述中注入细微的合成视觉幻觉（修改少数词语，涉及物体、属性、数量或空间关系），训练VLM定位被破坏的文本片段。这种方法在保持感知难度的同时，提供了一个易于计算且明确的二元精确匹配奖励。此外，还引入了ViCrit-Bench，一个诊断基准测试。

**Result:** 经过ViCrit任务训练的模型在各种视觉语言基准测试中取得了显著提升。这些改进不仅限于自然图像训练数据，还扩展到抽象图像推理和视觉数学，表明模型学会了感知而非仅仅记忆。

**Conclusion:** 精细的幻觉批判是增强VLM视觉感知的一种有效且可泛化的目标。

> **ai_Abstract:** 本文提出ViCrit，一个针对视觉语言模型（VLM）视觉感知的可验证强化学习代理任务。该任务通过训练VLM识别图像描述中注入的细微视觉幻觉来提升其感知能力。ViCrit提供了易于验证的二元奖励，同时保持了复杂的感知挑战。实验结果表明，经过ViCrit训练的模型在多个VL基准测试中表现出显著提升，且泛化能力强，能够应用于抽象推理和视觉数学，而非仅仅记忆。论文还引入了ViCrit-Bench用于评估。

> **摘要翻译:** 强化学习（RL）在微调大型语言模型（LLM）方面表现出巨大效力，尤其是在数学推理或代码生成等具有挑战性但易于验证的任务上。然而，将这种成功扩展到视觉语言模型（VLM）中的视觉感知一直受到阻碍，因为同时具有挑战性和明确可验证的以视觉为中心的任务稀缺。为此，我们引入了ViCrit（Visual Caption Hallucination Critic），一个强化学习代理任务，它训练VLM定位注入到人工编写的图像描述段落中的细微合成视觉幻觉。我们从约200字的描述开始，注入一个单一、细微的视觉描述错误——改变关于物体、属性、数量或空间关系的几个词语——并要求模型在给定图像和修改后的描述的情况下，精确定位被破坏的文本片段。这种公式保留了完整的感知难度，同时提供了一个易于计算且明确的二元精确匹配奖励。使用ViCrit任务训练的模型在各种视觉语言基准测试中表现出显著的提升。至关重要的是，这些改进超越了自然图像训练数据，扩展到抽象图像推理和视觉数学，显示出学习感知而非仅仅记忆所见物体的潜力。为了方便评估，我们进一步引入了ViCrit-Bench，一个类别平衡的诊断基准，系统地探测不同图像领域和错误类型中的感知错误。总而言之，我们的结果表明，细粒度的幻觉批判是增强VLM视觉感知的一种有效且可泛化的目标。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [199] [RoCA: Robust Cross-Domain End-to-End Autonomous Driving](https://arxiv.org/abs/2506.10145)
> *RoCA：鲁棒的跨领域端到端自动驾驶*

*Rajeev Yasarla, Shizhong Han, Hsin-Pai Cheng, Litian Liu, Shweta Mahajan, Apratim Bhattacharyya, Yunxiao Shi, Risheek Garrepalli, Hong Cai, Fatih Porikli* | **Main category: cs.CV**

**Keywords:** 端到端自动驾驶, 跨域, 鲁棒性, 高斯过程, 域泛化

**Comment:** 

> **TL;DR:** RoCA是一个新颖的框架，旨在解决端到端（E2E）自动驾驶在不同领域（如城市）部署时的鲁棒性挑战。它通过对编码车辆信息的令牌进行联合概率分布建模，并利用高斯过程（GP）学习基础令牌及其轨迹，从而提高基础模型的泛化能力和在新目标域上的适应性，且不增加推理计算成本。

**AI_Comments:** RoCA的创新之处在于其对跨域E2E自动驾驶的概率建模方法，特别是利用高斯过程学习“基础令牌”来捕捉多样化的驾驶场景。这提供了一种新颖的解决方案，以应对E2E自动驾驶在不同环境部署时的泛化和适应性难题。其重要性在于，它在不增加推理成本的情况下提高了模型的鲁棒性，这对于实际应用至关重要。该方法有效地避免了LLM可能带来的高昂再训练成本，为自动驾驶的实际落地提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 端到端（E2E）自动驾驶具有巨大潜力，但在跨领域部署（例如不同城市）时面临实际挑战。现有将大型语言模型（LLMs）融入E2E驾驶的研究，虽然利用了其开放世界知识，但无法保证跨域驾驶性能，并且在域适应过程中可能产生高昂的再训练成本。

**Method:** 本文提出了RoCA框架，用于鲁棒的跨领域端到端自动驾驶。RoCA对E2E管道中编码自身和周围车辆信息的令牌的联合概率分布进行建模。通过高斯过程（GP）实例化，RoCA学习一组具有相应轨迹的基础令牌，这些令牌涵盖了多样化的驾驶场景。给定任何驾驶场景，RoCA能够概率性地推断未来轨迹。通过在源域训练中将RoCA与基础E2E模型结合使用，可以提高基础模型的泛化能力，且无需额外的推理计算。

**Result:** RoCA在新目标域上实现了鲁棒的适应性，显著优于直接微调方法。在各种跨域场景中进行广泛评估后，RoCA展现出强大的域泛化和适应性能。

**Conclusion:** RoCA框架通过其独特的概率建模和高斯过程应用，显著提高了端到端自动驾驶模型在不同领域间的泛化能力和适应性，为实际部署中的跨域挑战提供了鲁棒的解决方案。

> **ai_Abstract:** 本文提出RoCA，一个用于解决端到端（E2E）自动驾驶跨域部署挑战的新颖框架。针对现有方法在跨域泛化和适应性方面的不足，RoCA通过对E2E管道中的车辆信息令牌进行联合概率分布建模，并利用高斯过程（GP）学习覆盖多样化驾驶场景的基础令牌。该方法能够概率性地推断未来轨迹，并在源域训练中与基础E2E模型结合使用，无需额外推理计算即可提升模型泛化能力。实验证明，RoCA在新目标域上展现出优异的鲁棒适应性和域泛化性能，显著优于直接微调。

> **摘要翻译:** 端到端（E2E）自动驾驶最近作为一种新范式出现，具有巨大的潜力。然而，很少有研究关注跨领域（例如城市）部署的实际挑战。尽管一些工作已将大型语言模型（LLMs）纳入其中，以利用其开放世界知识，但LLMs并不能保证跨域驾驶性能，并且在域适应过程中可能产生高昂的再训练成本。在本文中，我们提出了RoCA，一个用于鲁棒跨域E2E自动驾驶的新颖框架。RoCA在E2E管道中对编码自身和周围车辆信息的令牌的联合概率分布进行建模。通过高斯过程（GP）实例化，RoCA学习一组具有相应轨迹的基础令牌，这些令牌涵盖了多样化的驾驶场景。然后，给定任何驾驶场景，它能够概率性地推断未来轨迹。通过在源域训练中将RoCA与基础E2E模型结合使用，我们提高了基础模型的泛化能力，且无需额外的推理计算。此外，RoCA在新目标域上实现了鲁棒的适应性，显著优于直接微调。我们在各种跨域场景中广泛评估了RoCA，并表明它实现了强大的域泛化和适应性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [216] [SPARKE: Scalable Prompt-Aware Diversity Guidance in Diffusion Models via RKE Score](https://arxiv.org/abs/2506.10173)
> *SPARKE：通过RKE分数在扩散模型中实现可扩展的提示感知多样性引导*

*Mohammad Jalali, Haoyu Lei, Amin Gohari, Farzan Farnia* | **Main category: cs.CV**

**Keywords:** 扩散模型, 多样性引导, 提示感知, RKE分数, 可扩展性

**Comment:** 

> **TL;DR:** SPARKE提出了一种可扩展的、提示感知多样性引导方法，通过优化Rényi核熵（RKE）分数，在不显著增加计算成本的情况下提高扩散模型生成样本的多样性。

**AI_Comments:** 该论文的创新之处在于，它通过引入条件潜在RKE分数引导，将提示感知多样性引导的计算复杂度从O(n^3)大幅降低到O(n)，从而解决了大规模生成场景中的计算瓶颈。这使得在保持生成质量的同时，能够更高效地提升生成样本的多样性，对扩散模型的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在提示引导的扩散模型中，确保生成样本的足够多样性仍然是一个挑战，尤其是在提示词语义范围广泛且需要以提示感知的方式评估多样性时。现有的基于多样性度量的方法在计算上存在挑战，特别是在大规模生成设置中。

**Method:** 本文提出了可扩展的提示感知Rényi核熵多样性引导（SPARKE）方法。SPARKE利用条件熵进行多样性引导，动态地根据相似提示调整多样性测量。为了解决大规模生成中基于矩阵的熵分数带来的计算挑战，SPARKE专注于条件潜在RKE分数引导的特殊情况，将熵计算和基于梯度的优化复杂度从O(n^3)降低到O(n)。

**Result:** SPARKE方法在多个文本到图像扩散模型上进行了数值测试，结果表明该方法在不显著增加计算成本的情况下，提高了生成数据的提示感知多样性。

**Conclusion:** SPARKE通过引入高效的RKE分数，成功解决了扩散模型中提示感知多样性引导的计算难题，从而在不增加高成本的情况下提高了生成多样性，使其适用于大规模生成场景。

> **ai_Abstract:** 本研究提出SPARKE（可扩展的提示感知Rényi核熵多样性引导）方法，旨在解决扩散模型中提示引导生成样本多样性不足的问题。SPARKE通过利用条件熵实现提示感知多样性控制，并通过专注于条件潜在RKE分数引导，将计算复杂度从O(n^3)显著降低至O(n)。实验证明，SPARKE在不显著增加计算成本的情况下，有效提升了文本到图像扩散模型生成数据的提示感知多样性。

> **摘要翻译:** 扩散模型在高质量图像合成和提示引导生成建模方面取得了显著成功。然而，确保提示引导扩散模型生成样本的足够多样性仍然是一个挑战，特别是当提示词跨越广泛的语义范围并且需要以提示感知的方式在语义相似的提示词之间评估生成数据的多样性时。最近的方法已经通过多样性度量引入了引导，以鼓励更多样化的生成。在这项工作中，我们通过提出可扩展的提示感知Rényi核熵多样性引导（SPARKE）方法来扩展基于多样性度量的方法，以实现提示感知多样性引导。SPARKE利用条件熵进行多样性引导，它动态地根据相似提示调整多样性测量，并实现提示感知多样性控制。虽然基于熵的引导方法增强了提示感知多样性，但其对基于矩阵的熵分数的依赖在大规模生成设置中带来了计算挑战。为了解决这个问题，我们专注于条件潜在RKE分数引导的特殊情况，将通用熵度量的O(n^3)的熵计算和基于梯度的优化复杂度降低到O(n)。计算复杂度的降低允许在不同提示词上进行数千轮的生成多样性引导采样。我们在几个文本到图像扩散模型上对SPARKE方法进行了数值测试，证明所提出的方法在不产生显著计算成本的情况下提高了生成数据的提示感知多样性。我们已在项目页面发布了代码：https://mjalali.github.io/SPARKE

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [230] [Retrieval of Surface Solar Radiation through Implicit Albedo Recovery from Temporal Context](https://arxiv.org/abs/2506.10174)
> *通过时间上下文隐式反照率恢复地表太阳辐射*

*Yael Frischholz, Devis Tuia, Michael Lehning* | **Main category: cs.CV**

**Keywords:** 地表太阳辐射, 反照率恢复, 时间上下文, 注意力机制, Vision Transformer

**Comment:** 14 pages, 7 figures

> **TL;DR:** 本文提出了一种基于注意力机制的模拟器，通过学习卫星图像序列中的时间上下文，隐式推断晴空地表反射率，从而准确检索地表太阳辐射（SSR），特别是在多雪山区。

**AI_Comments:** 该研究的创新之处在于其通过隐式学习地表反射率动态来检索SSR，避免了对传统手工制作特征（如显式反照率图和云掩膜）的依赖。这种方法利用时间上下文，使得模型在处理具有复杂地形和动态积雪的区域时表现出鲁棒性和优越性，为卫星遥感领域提供了一种更高效、更通用的SSR反演方案。

<details>
  <summary>Details</summary>

**Motivation:** 从卫星图像中准确获取地表太阳辐射（SSR）关键在于估算晴空条件下的背景反射率。传统操作算法通常使用月度统计数据近似背景反射率，但在山区，由于间歇性积雪和变化的雪面，这种方法会失效。

**Method:** 我们提出了一种基于注意力机制的模拟器，用于SSR检索，该模拟器能够从原始卫星图像序列中隐式学习推断晴空地表反射率。该方法基于时空Vision Transformer构建，无需手工制作的反照率图或云掩膜等特征。模拟器在瑞士地区（地形复杂、积雪动态变化）的HelioMont算法瞬时SSR估计数据上进行训练。输入包括Meteosat第二代平台的多光谱SEVIRI图像，并辅以静态地形特征和太阳几何信息。目标变量是HelioMont的SSR，其空间分辨率为1.7公里。

**Result:** 当提供足够长的时间上下文时，该模型能与反照率信息模型达到相同的性能，这突出显示了模型内部学习和利用潜在地表反射率动态的能力。我们的地理空间分析表明，这种效果在山区最为显著，并且在简单和复杂的地形设置中都改善了泛化能力。

**Conclusion:** 本文提出的基于注意力机制的模拟器能够通过隐式学习时间上下文中的地表反射率动态，有效且准确地检索地表太阳辐射，尤其是在积雪多变的山区，优于传统依赖显式反照率图的方法。

> **ai_Abstract:** 本文提出了一种基于时空Vision Transformer的注意力模拟器，用于从原始卫星图像序列中隐式学习晴空地表反射率，从而实现地表太阳辐射（SSR）的准确检索。该方法克服了传统月度统计方法在多雪山区失效的问题，无需显式反照率图或云掩膜。在瑞士复杂地形和动态积雪区域的HelioMont SSR数据上进行训练和验证，结果表明，在提供足够时间上下文的情况下，该模型能够匹配甚至超越基于显式反照率信息的模型性能，特别是在山区表现出强大的泛化能力。

> **摘要翻译:** 从卫星图像中准确获取地表太阳辐射（SSR）关键在于估算卫星传感器在晴空条件下观测到的背景反射率。与此基线的偏差可用于检测云的存在并指导辐射传输模型推断大气衰减。操作性检索算法通常使用月度统计数据近似背景反射率，假设地表特性相对于大气条件变化缓慢。然而，这种方法在间歇性积雪和变化的雪面频繁的山区会失效。我们提出了一种基于注意力机制的模拟器，用于SSR检索，该模拟器能够从原始卫星图像序列中隐式学习推断晴空地表反射率。该方法基于时空Vision Transformer构建，无需手工制作的反照率图或云掩膜等特征。模拟器在瑞士地区（地形复杂、积雪动态变化）的HelioMont算法瞬时SSR估计数据上进行训练。输入包括Meteosat第二代平台的多光谱SEVIRI图像，并辅以静态地形特征和太阳几何信息。目标变量是HelioMont的SSR，其计算方式为其直接和漫射水平辐照度分量之和，空间分辨率为1.7公里。我们展示了，当提供足够长的时间上下文时，该模型能与反照率信息模型达到相同的性能，这突出显示了模型内部学习和利用潜在地表反射率动态的能力。我们的地理空间分析表明，这种效果在山区最为显著，并且在简单和复杂的地形设置中都改善了泛化能力。代码和数据集可在https://github.com/frischwood/HeMu-dev.git公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [244] [Attention, Please! Revisiting Attentive Probing for Masked Image Modeling](https://arxiv.org/abs/2506.10178)
> *注意，请！重新审视用于掩码图像建模的注意力探测*

*Bill Psomas, Dionysis Christopoulos, Eirini Baltzi, Ioannis Kakogeorgiou, Tilemachos Aravanis, Nikos Komodakis, Konstantinos Karantzalos, Yannis Avrithis, Giorgos Tolias* | **Main category: cs.CV**

**Keywords:** 注意力探测, 掩码图像建模, 自监督学习, 高效探测, 线性探测

**Comment:** 

> **TL;DR:** 现有注意力探测方法参数过多且效率低下。本文提出高效探测（EP），一种多查询交叉注意力机制，显著提升效率和性能，并在多项基准测试中超越现有方法。

**AI_Comments:** 这篇论文通过引入高效探测（EP）有效地解决了现有注意力探测方法在可扩展性和效率方面的挑战。其创新点在于提出了一种简化的多查询交叉注意力机制，该机制在保持甚至超越性能的同时，显著降低了计算成本和参数量。这对于大规模自监督学习模型的评估具有重要意义，因为它提供了一个更实用、更准确的评估工具。论文还强调了其方法在泛化能力和可解释性方面的优势，进一步提升了其价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模微调变得不切实际，探测成为自监督学习评估的首选协议。然而，标准线性探测（LP）无法充分反映掩码图像建模（MIM）训练模型的潜力，因为补丁令牌的分布式特性。现有注意力探测方法存在参数过多和计算效率低下的问题。

**Method:** 本文通过精度-效率权衡的视角重新审视注意力探测。系统研究了现有方法，分析其机制并进行性能基准测试。引入了高效探测（EP），一种多查询交叉注意力机制，该机制消除了冗余投影，减少了可训练参数数量，并实现了比传统多头注意力高达10倍的加速。

**Result:** EP在七个基准测试中优于线性探测（LP）和先前的注意力探测方法，能很好地泛化到MIM之外的多种预训练范式，生成可解释的注意力图，并在低样本和层级设置中获得显著增益。与传统多头注意力相比，EP实现了高达10倍的加速。

**Conclusion:** 高效探测（EP）通过改进注意力探测的效率和性能，为自监督学习模型的评估提供了一个更优越的替代方案，尤其适用于掩码图像建模。

> **ai_Abstract:** 本文针对自监督学习模型评估中现有注意力探测方法参数过多和效率低下的问题，提出了高效探测（EP）。EP是一种多查询交叉注意力机制，通过消除冗余投影和减少参数，实现了显著的计算加速和性能提升。实验表明，EP在多个基准测试中优于线性探测和现有注意力探测方法，并具有良好的泛化能力和可解释性。

> **摘要翻译:** 随着大规模微调（FT）变得越来越不切实际，探测（probing）正成为自监督学习（SSL）的首选评估协议。然而，由于补丁令牌的分布式性质，标准的线性探测（LP）未能充分反映通过掩码图像建模（MIM）训练的模型的潜力。这促使了注意力探测的需求，它是一种利用注意力选择性聚合补丁级特征的替代方案。尽管其应用日益广泛，但注意力探测仍未得到充分探索，现有方法存在参数过多和计算效率低下的问题。
在这项工作中，我们从精度-效率权衡的角度重新审视了注意力探测。我们对现有方法进行了系统研究，分析了它们的机制并对其性能进行了基准测试。我们引入了高效探测（EP），这是一种多查询交叉注意力机制，它消除了冗余投影，减少了可训练参数的数量，并实现了比传统多头注意力高达10倍的加速。尽管其简单，EP在七个基准测试中超越了LP和先前的注意力探测方法，能很好地泛化到MIM之外的多种预训练范式，生成可解释的注意力图，并在低样本和层级设置中获得了显著增益。代码可在https://github.com/billpsomas/efficient-probing 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [255] [Improving Personalized Search with Regularized Low-Rank Parameter Updates](https://arxiv.org/abs/2506.10182)
> *采用正则化低秩参数更新改进个性化搜索*

*Fiona Ryan, Josef Sivic, Fabian Caba Heilbron, Judy Hoffman, James M. Rehg, Bryan Russell* | **Main category: cs.CV**

**Keywords:** 个性化检索, 视觉-语言模型, 低秩适应, 参数更新, 概念学习

**Comment:** CVPR 2025 Highlight. Code: http://github.com/adobe-research/polar-vl

> **TL;DR:** 通过对视觉-语言双编码器模型进行正则化低秩参数更新，有效提升个性化视觉-语言检索性能，同时保持通用知识。

**AI_Comments:** 这篇论文通过引入正则化低秩参数更新，为个性化视觉-语言检索提供了一种新颖且高效的参数适应方法，解决了在学习新概念的同时保留通用知识的关键挑战。其创新之处在于利用低秩适应替代了计算成本较高的文本反演，并在参数组合方面进行了探索。引入新的通用知识评估指标也增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 个性化视觉-语言检索任务（从少量示例中识别新概念）面临挑战，因为它不仅需要从少量图像中学习新概念，还需要将个人和通用知识结合起来以在不同上下文中识别概念。

**Method:** 1. 有效调整视觉-语言双编码器模型的内部表示。
2. 具体方法是对语言编码器最后一层的一小部分参数进行正则化低秩自适应，作为文本反演的有效替代方案，同时保留通用知识。
3. 探索结合多个已学习的个人概念参数的策略，发现参数相加是有效的。
4. 引入一个衡量通用知识保留程度的指标，该指标基于视觉语言模型（VLM）生成的标题的图像检索准确性。

**Result:** 1. 在两个个性化图像检索基准（DeepFashion2和ConCon-Chi）上实现了最先进的准确性。
2. 在个人检索方面，性能比现有技术提高了4%-22%。

**Conclusion:** 通过正则化低秩参数更新，可以有效改进个性化视觉-语言检索，同时成功地将个人和通用知识结合起来，并在相关基准上取得了显著的SOTA性能提升。

> **ai_Abstract:** 本文提出了一种通过正则化低秩参数更新来改进个性化视觉-语言检索的方法。研究发现，对视觉-语言双编码器模型中语言编码器最后一层的少量参数进行正则化低秩自适应，能有效识别个人概念并保留通用知识，优于传统的文本反演。此外，文章还探讨了结合多个个人概念参数的策略，并引入了新的通用知识保留评估指标。该方法在DeepFashion2和ConCon-Chi基准上取得了最先进的性能，在个人检索方面有显著提升。

> **摘要翻译:** 个性化视觉-语言检索旨在仅从少量示例中识别新概念（例如“我的狗Fido”）。这项任务具有挑战性，因为它不仅需要从少量图像中学习新概念，还需要将个人和通用知识结合起来以在不同上下文中识别该概念。在本文中，我们展示了如何有效地调整视觉-语言双编码器模型的内部表示，用于个性化视觉-语言检索。我们发现，对语言编码器最后一层的一小部分参数进行正则化低秩自适应，可以作为文本反演的一种高效替代方案，用于识别个人概念，同时保留通用知识。此外，我们探索了组合多个已学习的个人概念参数的策略，发现参数相加是有效的。为了评估微调表示中通用知识的保留情况，我们引入了一个衡量基于视觉语言模型（VLM）生成的标题的图像检索准确性的指标。我们的方法在两个使用自然语言查询的个性化图像检索基准（DeepFashion2和ConCon-Chi）上取得了最先进的准确性，在个人检索方面比现有技术提高了4%-22%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [265] [Research on Audio-Visual Quality Assessment Dataset and Method for User-Generated Omnidirectional Video](https://arxiv.org/abs/2506.10331)
> *用户生成全景视频音视频质量评估数据集与方法研究*

*Fei Zhao, Da Pan, Zelu Qi, Ping Shi* | **Main category: cs.CV**

**Keywords:** 用户生成全景视频, 音视频质量评估, 数据集, 基线模型, 平均意见得分

**Comment:** Our paper has been accepted by ICME 2025

> **TL;DR:** 该研究构建了一个用户生成全景视频的音视频质量评估数据集，并提出了一个有效的基线模型，以解决该领域研究不足的问题。

**AI_Comments:** 本文的创新点在于首次构建了专门针对用户生成全景视频的音视频质量评估数据集，并在此基础上提出了一个基线模型，填补了该领域研究的空白。其重要性在于为未来UGC全景视频的质量评估研究提供了基础数据和方法参考。

<details>
  <summary>Details</summary>

**Motivation:** 随着元宇宙的兴起，全景视频（ODVs）受到关注，并逐渐从专业生成内容（PGC）转向用户生成内容（UGC）。然而，全景视频中的音视频质量评估（AVQA）研究仍然有限。

**Method:** 本文构建了一个用户生成全景音视频内容数据集，包含由五个人使用两种不同类型全景相机拍摄的300个视频，涵盖10种场景类型。对该数据集进行了主观AVQA实验以获取平均意见得分（MOSs）。之后，构建了一个有效的AVQA基线模型，该模型包括视频特征提取模块、音频特征提取模块和音视频融合模块。

**Result:** 实验结果表明，所提出的模型在所构建的数据集上取得了最佳性能。

**Conclusion:** 本文构建了用户生成全景视频的音视频质量评估数据集，并提出了有效的基线模型，为UGC-ODV AVQA领域的发展提供了基础和促进。

> **ai_Abstract:** 本文旨在解决用户生成全景视频（UGC-ODV）中音视频质量评估（AVQA）研究不足的问题。为此，研究团队构建了一个UGC全景音视频数据集，该数据集包含由五位用户使用两种不同相机拍摄的300个视频，涵盖10种场景类型，并通过主观实验获得了音视频序列的平均意见得分（MOSs）。在此基础上，本文进一步构建了一个由视频特征提取、音频特征提取和音视频融合模块组成的有效AVQA基线模型，并通过实验证明了该模型在所构建数据集上的最优性能。

> **摘要翻译:** 针对元宇宙日益突出的地位，全景视频（ODVs）引起了显著关注，并逐渐从专业生成内容（PGC）转向用户生成内容（UGC）。然而，全景视频中的音视频质量评估（AVQA）研究仍然有限。为了解决这个问题，我们构建了一个用户生成全景音视频（A/V）内容数据集。视频由五个人使用两种不同类型的全景相机拍摄，共300个视频，涵盖10种不同的场景类型。对数据集进行了主观AVQA实验，以获得音视频序列的平均意见得分（MOSs）。之后，为了促进UGC-ODV AVQA领域的发展，我们在所提出的数据集上构建了一个有效的AVQA基线模型，该模型由视频特征提取模块、音频特征提取和音视频融合模块组成。实验结果表明，我们的模型在所提出的数据集上取得了最佳性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [267] [Sheet Music Benchmark: Standardized Optical Music Recognition Evaluation](https://arxiv.org/abs/2506.10488)
> *乐谱基准：标准化光学音乐识别评估*

*Juan C. Martinez-Sevilla, Joan Cerveto-Serrano, Noelia Luna, Greg Chapman, Craig Sapp, David Rizo, Jorge Calvo-Zaragoza* | **Main category: cs.CV**

**Keywords:** 光学音乐识别, 数据集, 评估, 乐谱基准, 归一化编辑距离

**Comment:** 

> **TL;DR:** 引入了乐谱基准数据集（SMB）和OMR归一化编辑距离（OMR-NED）新度量，以标准化光学音乐识别（OMR）的评估。

**AI_Comments:** 这项工作通过引入一个专门设计的数据集（SMB）和定制的评估指标（OMR-NED），解决了光学音乐识别（OMR）领域长期存在的标准化评估问题。OMR-NED能够进行细粒度的错误分析，这对于理解和改进OMR算法至关重要，是该领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决光学音乐识别（OMR）评估中长期存在的空白，提供标准化的基准和更精细的评估指标。

**Method:** 本文引入了Sheet Music Benchmark (SMB) 数据集，包含685页多样音乐纹理（如单音、钢琴形式、四重奏等），并采用Humdrum **kern格式编码。同时，引入了OMR Normalized Edit Distance (OMR-NED) 新度量，该度量基于Symbol Error Rate (SER)，并能对音符头、符杠、音高、变音记号等单个音乐元素进行详细的错误分析。

**Result:** OMR-NED提供的数值分数便于清晰比较，使研究人员和最终用户能够识别最佳的OMR方法。该工作填补了OMR评估的长期空白，并通过使用标准化的SMB数据集分割进行基线实验来支持其贡献。

**Conclusion:** SMB数据集和OMR-NED度量的引入为OMR研究提供了一个急需的标准化评估框架，有助于推动该领域的发展。

> **ai_Abstract:** 本文介绍了乐谱基准（SMB）数据集，旨在标准化光学音乐识别（OMR）研究的评估。SMB包含685页乐谱，涵盖多种音乐纹理。同时，论文还提出了OMR归一化编辑距离（OMR-NED），这是一个基于符号错误率（SER）的新评估指标，能对音符的各个元素进行精细的错误分析。通过SMB和OMR-NED，研究人员可以更有效地比较不同的OMR方法，从而填补了OMR评估领域的空白。

> **摘要翻译:** 在这项工作中，我们引入了乐谱基准（SMB），这是一个包含685页的专门用于基准测试光学音乐识别（OMR）研究的数据集。SMB涵盖了各种音乐纹理，包括单音、钢琴形式、四重奏等，所有这些都使用Humdrum **kern格式编码为通用西方现代乐谱。除了SMB，我们还引入了OMR归一化编辑距离（OMR-NED），这是一种专门为评估OMR性能量身定制的新度量。OMR-NED建立在广泛使用的符号错误率（SER）之上，提供了细致入微的错误分析，涵盖了音符头、符杠、音高、变音记号和其他关键记谱特征等单个音乐元素。OMR-NED提供的最终数值分数有助于清晰的比较，使研究人员和最终用户都能识别最佳的OMR方法。因此，我们的工作解决了OMR评估中长期存在的空白，我们通过使用标准化的SMB数据集分割进行训练和评估最先进方法来支持我们的贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [269] [ScoreMix: Improving Face Recognition via Score Composition in Diffusion Generators](https://arxiv.org/abs/2506.10226)
> *ScoreMix：通过扩散生成器中的分数组合改进人脸识别*

*Parsa Rahimi, Sebastien Marcel* | **Main category: cs.CV**

**Keywords:** ScoreMix, 扩散模型, 数据增强, 人脸识别, 判别器性能

**Comment:** 

> **TL;DR:** ScoreMix是一种新颖的数据增强策略，它利用扩散模型的得分组合特性生成具有挑战性的合成样本，从而显著提高判别器的性能，尤其是在标记数据有限的情况下。

**AI_Comments:** ScoreMix的创新点在于其利用扩散模型的得分组合特性进行数据增强，以生成更具挑战性的训练样本。特别值得注意的是，该研究发现混合在判别器嵌入空间中距离较远的类别能带来更大的性能提升，这揭示了生成器和判别器空间之间的潜在差异。其重要性在于，它提供了一种有效且无需大量标记数据即可提升判别模型性能的方法，对于资源受限或需要快速部署的场景具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在标记数据有限的情况下提高判别器性能，并有效缓解收集大型数据集以训练判别模型的问题。

**Method:** 提出了一种名为ScoreMix的数据增强策略。该方法通过在扩散采样过程中凸混合来自不同类别条件轨迹的分数，生成具有挑战性的合成样本。研究了混合的类别选择策略，发现结合判别器嵌入空间中距离较远的类别能带来更大的性能提升。

**Result:** ScoreMix显著提高了所有研究基准中的判别能力。当结合判别器嵌入空间中距离较远的类别时，性能提升更大。经验性地表明，在标准指标下，生成器学习到的条件空间与判别器嵌入空间之间的相关性最小。该方法在没有大量参数搜索的情况下取得了显著的性能改进。

**Conclusion:** ScoreMix是一种实用且有效的方法，用于训练判别模型，并能有效缓解大型数据集收集的问题，展现出显著的性能提升。

> **ai_Abstract:** ScoreMix是一种新颖的数据增强方法，通过利用扩散模型的得分组合特性，在扩散采样过程中混合不同类别的得分，生成具有挑战性的合成样本。该方法显著提升了判别器的性能，尤其在标记数据有限的场景下表现突出。研究发现，混合在判别器嵌入空间中距离较远的类别比在生成器条件空间中接近的类别能带来更大的性能提升。ScoreMix无需大量参数搜索即可实现显著性能改进，为训练判别模型提供了实用优势，并有效缓解了大数据集收集的难题。

> **摘要翻译:** 在本文中，我们提出了ScoreMix，这是一种新颖而简单的数据增强策略，它利用扩散模型的得分组合特性来增强判别器性能，特别是在标记数据有限的情况下。通过在扩散采样过程中凸混合来自不同类别条件轨迹的分数，我们生成了具有挑战性的合成样本，这些样本显著提高了所有研究基准中的判别能力。我们系统地研究了混合的类别选择策略，发现当结合判别器嵌入空间中距离较远的类别时，而不是生成器条件空间中接近的类别时，会产生更大的性能增益。此外，我们通过经验证明，在标准指标下，生成器学习到的条件空间与判别器嵌入空间之间的相关性最小。我们的方法在没有大量参数搜索的情况下取得了显著的性能改进，展示了训练判别模型的实际优势，同时有效缓解了大型数据集收集的问题。论文网站：https://parsa-ra.github.io/scoremix

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [278] [Rethinking Generative Human Video Coding with Implicit Motion Transformation](https://arxiv.org/abs/2506.10453)
> *重新思考基于隐式运动变换的生成式人体视频编码*

*Bolin Chen, Ru-Ling Liao, Jie Chen, Yan Ye* | **Main category: cs.CV**

**Keywords:** 生成式视频编码, 人体视频, 隐式运动变换, 视频压缩, 运动估计

**Comment:** 

> **TL;DR:** 本文提出了一种名为隐式运动变换（IMT）的新范式，用于生成式人体视频编码（GHVC），以解决显式运动指导在处理复杂人体运动时导致的失真和不准确问题，实现了高效压缩和高质量合成。

**AI_Comments:** 该论文的创新点在于提出了隐式运动变换（IMT）来解决生成式人体视频编码中显式运动指导的局限性，特别是在处理复杂人体运动时。这对于提高人体视频压缩的效率和质量具有重要意义，可能为未来生成式视频编解码器的发展提供新思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的生成式视频编解码器在人脸视频压缩方面取得了成功，但对于具有更复杂和多样化运动模式的人体视频，使用显式运动指导会导致严重的失真和不准确的运动重建。因此，本文旨在解决显式运动方法在人体视频压缩中的局限性。

**Method:** 本文提出了一种名为隐式运动变换（IMT）的新范式。具体来说，该方法将复杂的人体信号特征化为紧凑的视觉特征，并将这些特征转换为隐式运动指导，用于信号重建。

**Result:** 实验结果表明，所提出的IMT范式是有效的，能够促进生成式人体视频编码（GHVC）实现高效率压缩和高保真度合成。

**Conclusion:** 通过引入隐式运动变换（IMT），可以显著提升生成式人体视频编码（GHVC）的性能，克服传统显式运动指导在处理复杂人体运动时的局限性，实现高效和高质量的视频压缩。

> **ai_Abstract:** 本文针对生成式人体视频编码（GHVC）中显式运动指导在处理复杂人体运动时导致的重建失真和不准确问题，提出了一种名为隐式运动变换（IMT）的新范式。该方法将复杂人体信号转化为紧凑视觉特征，并将其作为隐式运动指导进行信号重建。实验证明，IMT能有效提升GHVC的压缩效率和合成质量。

> **摘要翻译:** 超越传统的混合式视频编解码器，生成式视频编解码器通过将高维信号演变为紧凑的特征表示以实现编码器端的比特流紧凑性，以及开发显式运动场作为解码器端高质量重建的中间监督，从而实现了有前景的压缩性能。这种范式在人脸视频压缩中取得了显著成功。然而，与人脸视频相比，人体视频由于其更复杂多样的运动模式，带来了更大的挑战，即当使用显式运动指导进行生成式人体视频编码（GHVC）时，重建结果可能会遭受严重的失真和不准确的运动。因此，本文强调了基于显式运动方法在人体视频压缩中的局限性，并借助隐式运动变换（IMT）研究了GHVC性能的提升。特别是，我们提出将复杂的人体信号特征化为紧凑的视觉特征，并将这些特征转换为隐式运动指导以进行信号重建。实验结果证明了所提出的IMT范式的有效性，它能够促进GHVC实现高效率压缩和高保真度合成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [282] [California Crop Yield Benchmark: Combining Satellite Image, Climate, Evapotranspiration, and Soil Data Layers for County-Level Yield Forecasting of Over 70 Crops](https://arxiv.org/abs/2506.10228)
> *加州作物产量基准：结合卫星图像、气候、蒸散量和土壤数据层进行70多种作物县级产量预测*

*Hamid Kamangir, Mona Hajiesmaeeli, Mason Earles* | **Main category: cs.CV**

**Keywords:** 作物产量预测, 深度学习, 卫星图像, 加州农业, 基准数据集

**Comment:** 

> **TL;DR:** 该研究引入了一个全面的加州作物产量基准数据集，并开发了一个多模态深度学习模型，用于超过70种作物的县级产量预测，实现了0.76的R2分数。

**AI_Comments:** 该论文的创新点在于构建了一个大规模、多源集成的作物产量预测基准数据集，并提出了一个针对异构数据优化的多模态深度学习模型。其重要性在于为加州这一全球重要农业区域提供了高精度的县级作物产量预测能力，对农业生产规划、气候适应和精准农业具有实际应用价值。数据集和代码的公开性也促进了相关领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 尽管有大量的历史产量数据，但由于环境、气候和土壤相关因素的复杂相互作用，准确及时的作物产量预测仍然是一个挑战。

**Method:** 研究构建了一个涵盖2008年至2022年加州所有县70多种作物的综合作物产量基准数据集。该数据集整合了Landsat卫星图像、每日气候记录、月度蒸散量和高分辨率土壤特性等多种数据源。同时，开发了一个多模态深度学习模型，该模型采用分层特征提取和时间序列编码器来捕获生长季节的空间和时间动态，并利用土壤特性和作物身份等静态输入信息。

**Result:** 所提出的方法在未见过的测试数据集上，所有作物的总体R2分数达到0.76，表明在加州多样化的农业区域具有强大的预测性能。

**Conclusion:** 该基准数据集和建模框架为推进农业预测、气候适应和精准农业提供了宝贵的基础。完整的数据集和代码库已公开可用。

> **ai_Abstract:** 本研究针对加州作物产量预测的挑战，构建了一个包含卫星图像、气候、蒸散量和土壤数据的综合基准数据集，涵盖2008-2022年间超过70种作物。在此基础上，开发了一个多模态深度学习模型，利用分层特征提取和时间序列编码器处理异构数据，实现了0.76的R2分数，为农业预测提供了新的工具和公开资源。

> **摘要翻译:** 加利福尼亚州是全球农业生产的领导者，贡献了美国总产量的12.5%，并位居世界第五大食品和棉花供应国。尽管美国农业部国家农业统计局提供了大量的历史产量数据，但由于环境、气候和土壤相关因素的复杂相互作用，准确及时的作物产量预测仍然是一个挑战。在本研究中，我们引入了一个全面的作物产量基准数据集，涵盖了2008年至2022年加州所有县的70多种作物。该基准整合了多种数据源，包括Landsat卫星图像、每日气候记录、月度蒸散量和高分辨率土壤特性。为了有效地从这些异构输入中学习，我们开发了一个多模态深度学习模型，专门用于县级、特定作物的产量预测。该模型采用分层特征提取和时间序列编码器，以捕获生长季节的空间和时间动态。土壤特性和作物身份等静态输入提供了长期变异性信息。我们的方法在未见过的测试数据集上，所有作物的总体R2分数达到0.76，突出了加州多样化农业区域的强大预测性能。该基准和建模框架为推进农业预测、气候适应和精准农业提供了宝贵的基础。完整的数据集和代码库可在我们的GitHub存储库中公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [283] [DanceChat: Large Language Model-Guided Music-to-Dance Generation](https://arxiv.org/abs/2506.10574)
> *舞动聊天：大语言模型引导的音乐到舞蹈生成*

*Qing Wang, Xiaohang Yang, Yilan Dong, Naveen Raj Govindaraj, Gregory Slabaugh, Shanxin Yuan* | **Main category: cs.CV**

**Keywords:** 音乐到舞蹈生成, 大语言模型, 文本指导, 舞蹈合成, 多模态

**Comment:** check demos at https://dancechat.github.io/anon/

> **TL;DR:** DanceChat利用大语言模型（LLM）作为编舞者，通过文本指令引导音乐到舞蹈的生成，解决了音乐与舞蹈间的语义鸿沟和数据稀缺问题，实现了更具多样性和音乐对齐的舞蹈生成。

**AI_Comments:** 该论文的创新点在于首次将大语言模型（LLM）引入音乐到舞蹈生成任务，利用其理解和生成文本指令的能力，作为“编舞者”来弥补音乐与舞蹈之间的语义鸿沟。这提供了一种显式、高级的指导方式，克服了传统方法仅依赖音乐隐式学习的局限性，从而能生成更具多样性和更符合音乐风格的舞蹈。这种方法也部分缓解了配对数据稀缺的问题，为该领域带来了新的视角和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 音乐到舞蹈生成存在挑战，包括音乐与舞蹈运动之间的语义鸿沟（音乐提供抽象线索而非具体动作）、多对一映射（同一音乐可有多种舞蹈解释，需要额外指导以生成多样性）、以及配对音乐和舞蹈数据稀缺。

**Method:** 本文提出了DanceChat，一个由大语言模型（LLM）引导的音乐到舞蹈生成方法。LLM作为编舞者提供文本动作指令，提供明确的高级指导。该方法包含三个组件：1) 基于LLM的伪指令生成模块，根据音乐风格和结构生成文本舞蹈指导；2) 多模态特征提取与融合模块，整合音乐、节奏和文本指导到共享表示；3) 基于扩散的运动合成模块，结合多模态对齐损失，确保生成舞蹈与音乐和文本线索对齐。

**Result:** 在AIST++数据集上进行广泛实验和人类评估表明，DanceChat在定性和定量上均优于现有最先进的方法。

**Conclusion:** DanceChat通过引入LLM作为编舞者，有效解决了音乐到舞蹈生成中的语义鸿沟和多样性挑战，显著提升了生成舞蹈的质量和对齐度。

> **ai_Abstract:** 本文提出了DanceChat，一种创新的大语言模型（LLM）引导的音乐到舞蹈生成方法。该方法通过将LLM用作“编舞者”，生成文本动作指令，有效弥补了音乐与舞蹈之间的语义鸿沟，并解决了单一音乐对应多种舞蹈解释的挑战。DanceChat包含LLM伪指令生成、多模态特征融合以及基于扩散的运动合成模块，确保生成的舞蹈既多样化又与音乐和文本指导高度对齐。实验证明，DanceChat在性能上超越了现有最先进的方法。

> **摘要翻译:** 音乐到舞蹈生成旨在根据音乐输入合成人类舞蹈动作。尽管最近取得了进展，但由于音乐和舞蹈动作之间的语义鸿沟，仍然存在重大挑战，因为音乐只提供抽象线索，如旋律、律动和情感，而没有明确指定身体动作。此外，一首音乐可以产生多种合理的舞蹈解释。这种一对多的映射需要额外的指导，因为仅凭音乐为生成多样化的舞蹈动作提供的信息有限。配对音乐和舞蹈数据的稀缺进一步加剧了这一挑战，这限制了模型学习多样化舞蹈模式的能力。在本文中，我们引入了DanceChat，一种由大语言模型（LLM）引导的音乐到舞蹈生成方法。我们使用LLM作为编舞者，提供文本动作指令，为舞蹈生成提供明确的高级指导。这种方法超越了仅从音乐中进行隐式学习，使模型能够生成既多样化又与音乐风格更好地对齐的舞蹈。我们的方法包括三个组件：（1）一个基于LLM的伪指令生成模块，根据音乐风格和结构生成文本舞蹈指导；（2）一个多模态特征提取和融合模块，将音乐、节奏和文本指导整合到共享表示中；（3）一个基于扩散的运动合成模块，结合多模态对齐损失，确保生成的舞蹈与音乐和文本线索都对齐。在AIST++上的广泛实验和人类评估表明，DanceChat在定性和定量上都优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [289] [Boosting Adversarial Transferability for Hyperspectral Image Classification Using 3D Structure-invariant Transformation and Intermediate Feature Distance](https://arxiv.org/abs/2506.10459)
> *提升高光谱图像分类对抗样本可迁移性：利用三维结构不变变换和中间特征距离*

*Chun Liu, Bingqian Zhu, Tao Xu, Zheng Zheng, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang* | **Main category: cs.CV**

**Keywords:** 对抗攻击, 高光谱图像分类, 可迁移性, 结构不变变换, 中间特征距离

**Comment:** 

> **TL;DR:** 本文提出一种针对高光谱图像分类的对抗攻击方法，通过三维结构不变变换增加输入多样性，并利用中间特征距离损失增强对抗样本的可迁移性，对黑盒模型攻击有效且在防御下保持鲁棒。

**AI_Comments:** 创新点在于结合了三维结构不变变换和中间特征距离损失来解决高光谱图像对抗样本的迁移性问题。该方法考虑了高光谱图像的特殊性（高维光谱信息），通过分块变换增加了扰动的多样性，并通过特征距离损失有效引导了攻击，提升了对黑盒模型的攻击效果和在防御下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）容易受到对抗攻击，对基于DNN的高光谱图像（HSI）分类技术构成安全挑战。自然图像领域的许多迁移攻击方法不适用于高光谱图像，因为高光谱图像具有高维丰富的光谱信息。当前针对HSI对抗样本的研究有限，并且在充分利用图像结构和特征信息方面面临挑战。

**Method:** 该方法通过以下两部分增强高光谱图像分类模型对抗样本的可迁移性：1. 三维结构不变变换：在保持图像结构不变的情况下，将图像在空间和光谱维度上随机分块，然后对每个块应用各种变换，以增加输入多样性并减轻过拟合。2. 中间特征距离：设计了一种针对中间层的特征距离损失，将原始样本的放大特征与对抗样本的特征之间的距离作为主要损失，同时将输出层预测作为辅助损失。这引导扰动破坏对抗样本中真实类别的特征，有效增强可迁移性。

**Result:** 实验表明，该方法生成的对抗样本在两个公共高光谱图像数据集上对黑盒模型实现了有效的可迁移性。此外，即使在防御策略下，该方法也能保持鲁棒的攻击性能。

**Conclusion:** 该论文提出了一种新的方法，通过结合三维结构不变变换和中间特征距离损失，有效提升了高光谱图像分类模型对抗样本的可迁移性及其在防御策略下的鲁棒攻击性能。

> **ai_Abstract:** 本论文提出了一种新的方法来增强高光谱图像（HSI）分类模型对抗样本的可迁移性，以应对DNN在HSI分类中的安全挑战。该方法通过引入三维结构不变变换，在空间和光谱维度上对图像进行分块变换以增加输入多样性，并设计了中间特征距离损失来引导扰动破坏真实类别特征。实验证明，该方法生成的对抗样本对黑盒模型具有有效的可迁移性，并在防御策略下仍保持鲁棒性能。

> **摘要翻译:** 深度神经网络（DNN）容易受到对抗攻击，这对基于DNN的高光谱图像（HSI）分类技术构成了安全挑战。在自然图像领域，已经有大量基于迁移的对抗攻击方法被研究。然而，高光谱图像由于其高维和丰富的光谱信息，与自然图像不同。当前关于高光谱图像对抗样本的研究仍然有限，并且在充分利用图像结构和特征信息方面面临挑战。为了解决这些问题，本文提出了一种新颖的方法，以增强高光谱图像分类模型对抗样本的可迁移性。首先，在保持图像结构不变的同时，所提出的方法在空间和光谱维度上将图像随机分块。然后，对每个块应用各种变换，以增加输入多样性并减轻过拟合。其次，设计了一种针对中间层的特征距离损失，将原始样本的放大特征与对抗样本的特征之间的距离作为主要损失，而输出层预测作为辅助损失。这引导扰动破坏对抗样本中真实类别的特征，有效增强可迁移性。大量的实验表明，所提出的方法生成的对抗样本在两个公共高光谱图像数据集上对黑盒模型实现了有效的可迁移性。此外，即使在防御策略下，该方法也能保持鲁棒的攻击性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [293] [DySS: Dynamic Queries and State-Space Learning for Efficient 3D Object Detection from Multi-Camera Videos](https://arxiv.org/abs/2506.10242)
> *DySS：用于多摄像头视频高效3D目标检测的动态查询与状态空间学习*

*Rajeev Yasarla, Shizhong Han, Hong Cai, Fatih Porikli* | **Main category: cs.CV**

**Keywords:** 3D目标检测, 多摄像头, 状态空间学习, 动态查询, 自动驾驶

**Comment:** CVPR 2025 Workshop on Autonomous Driving

> **TL;DR:** DySS提出了一种结合状态空间学习和动态查询的新方法，实现了多摄像头视频中高效且高性能的3D目标检测。

**AI_Comments:** DySS的创新点在于将状态空间学习引入到3D目标检测中，以有效处理时序信息并对场景进行高效总结。同时，动态查询机制的引入进一步优化了检测效率，使得模型能够适应多摄像头视频流的复杂性。该方法在性能和推理速度上的显著提升，对于自动驾驶等实时性要求高的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于BEV的相机3D目标检测方法要么依赖于昂贵的密集BEV特征，要么虽然探索了稀疏查询，但仍需要大量查询，并且在处理更多视频帧时成本高昂。

**Method:** 本文提出了DySS，一种采用状态空间学习和动态查询的新方法。DySS利用状态空间模型（SSM）顺序处理随时间采样的特征，并引入未来预测和掩码重建辅助任务来训练SSM，以更好地捕获运动和对应信息。SSM的状态提供了场景的信息丰富且高效的总结。基于状态空间学习到的特征，DySS通过合并、移除和分割操作动态更新查询，以在整个网络中保持有用且精简的检测查询集。

**Result:** 在nuScenes测试集上，DySS实现了65.31 NDS和57.4 mAP，优于最新的SOTA方法。在验证集上，DySS实现了56.2 NDS和46.2 mAP，并达到33 FPS的实时推理速度。

**Conclusion:** DySS在多摄像头视频3D目标检测中实现了卓越的检测性能和高效的推理速度。

> **ai_Abstract:** DySS是一种针对多摄像头视频3D目标检测的新方法，旨在解决现有方法在效率上的不足。它创新性地结合了状态空间模型（SSM）来有效总结时序特征，并通过动态查询机制（合并、移除、分割）来维持高效且精简的检测查询集。通过引入辅助任务训练SSM以捕获运动信息，DySS在nuScenes数据集上展示了领先的检测性能（65.31 NDS，57.4 mAP）和实时推理速度（33 FPS），超越了现有技术水平。

> **摘要翻译:** 基于摄像头的鸟瞰图（BEV）3D目标检测是自动驾驶中最重要的感知任务之一。早期方法依赖于密集的BEV特征，其构建成本高昂。近期工作探索了基于稀疏查询的检测。然而，它们仍然需要大量的查询，并且在使用更多视频帧时运行成本会变得很高。在本文中，我们提出了DySS，一种采用状态空间学习和动态查询的新方法。更具体地说，DySS利用状态空间模型（SSM）随时间步长顺序处理采样的特征。为了鼓励模型更好地捕获底层的运动和对应信息，我们引入了未来预测和掩码重建的辅助任务来更好地训练SSM。SSM的状态随后提供了场景的信息丰富且高效的总结。基于状态空间学习到的特征，我们通过合并、移除和分割操作动态更新查询，这有助于在整个网络中保持一组有用且精简的检测查询。我们提出的DySS实现了卓越的检测性能和高效的推理。具体来说，在nuScenes测试集上，DySS实现了65.31 NDS和57.4 mAP，超越了最新的最先进水平。在验证集上，DySS实现了56.2 NDS和46.2 mAP，以及33 FPS的实时推理速度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [298] [Unsupervised Deformable Image Registration with Structural Nonparametric Smoothing](https://arxiv.org/abs/2506.10813)
> *无监督可变形图像配准与结构非参数平滑*

*Hang Zhang, Xiang Chen, Renjiu Hu, Rongguang Wang, Jinwei Zhang, Min Liu, Yaonan Wang, Gaolei Li, Xinxing Cheng, Jinming Duan* | **Main category: cs.CV**

**Keywords:** 可变形图像配准, 无监督学习, 平滑, 视网膜血管, 神经网络

**Comment:** Accepted for publication at Information Processing in Medical Imaging
  (IPMI) 2025

> **TL;DR:** 本文提出了SmoothProper模块，用于无监督可变形图像配准，通过在网络前向传播中强制平滑和信息传递，解决了稀疏特征和大位移挑战，尤其在视网膜血管图像上表现出色。

**AI_Comments:** 这篇论文的创新点在于提出了一个模型无关的即插即用模块SmoothProper，它通过在神经网络前向传播中引入结构平滑和消息传递，巧妙地解决了无监督DIR在处理稀疏特征和大位移图像时的局限性。这种方法将部分正则化负担从网络权重转移到优化层，简化了超参数调优，并显著提升了在特定挑战性数据集上的性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无监督可变形图像配准（DIR）方法难以处理具有稀疏特征和大位移的图像（如视网膜血管），因为神经网络在训练后预测的形变场缺乏约束，导致正则化负担完全落在网络权重上。

**Method:** 本文引入了SmoothProper，一个即插即用的神经网络模块，它在网络的前向传播中强制执行平滑并促进消息传递。通过集成一个基于对偶优化的层和定制的交互项，SmoothProper有效地在空间位置上传播流信号，强制执行平滑并保持结构一致性。该模块是模型无关的，可以无缝集成到现有配准框架中，参数开销极小，并消除了正则化超参数调优。

**Result:** 在具有孔径和大位移挑战的视网膜血管数据集上，该方法将2912x2912图像上的配准误差降低到1.88像素，是第一个有效解决这两个挑战的无监督可变形图像配准方法。

**Conclusion:** SmoothProper模块成功解决了无监督可变形图像配准在处理稀疏特征和大位移图像时的挑战，通过在网络前向传播中引入结构平滑和信息传递，显著提高了配准精度。

> **ai_Abstract:** 本文提出了一种名为SmoothProper的即插即用神经网络模块，用于解决无监督可变形图像配准（DIR）在处理具有稀疏特征和大位移的图像时遇到的挑战。该模块通过在网络前向传播中引入基于对偶优化的层，强制执行结构平滑并促进信息传递，从而有效约束形变场，减轻了网络权重上的正则化负担。实验结果表明，SmoothProper在视网膜血管数据集上显著降低了配准误差，是首个成功应对孔径和大位移挑战的无监督DIR方法。

> **摘要翻译:** 基于学习的可变形图像配准（DIR）通过神经网络分摊传统优化，从而加速对齐。标签监督进一步提高了准确性，实现了对未知扫描的高效精确非线性对齐。然而，具有稀疏特征和大平滑区域的图像，例如视网膜血管，引入了孔径和大位移挑战，这是无监督DIR方法难以解决的。这种限制的发生是因为神经网络在单次前向传播中预测形变场，导致训练后的场不受约束，并将正则化负担完全转移到网络权重上。为了解决这些问题，我们引入了SmoothProper，一个即插即用的神经模块，它在网络的前向传播中强制执行平滑并促进消息传递。通过集成一个基于对偶优化的层和定制的交互项，SmoothProper有效地在空间位置上传播流信号，强制执行平滑并保持结构一致性。它是模型无关的，可以无缝集成到现有配准框架中，参数开销极小，并消除了正则化超参数调优。在展示孔径和大位移挑战的视网膜血管数据集上的初步结果表明，我们的方法将2912x2912图像上的配准误差降低到1.88像素，标志着第一个有效解决这两个挑战的无监督DIR方法。源代码将可在https://github.com/tinymilky/SmoothProper获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [300] [Starting Positions Matter: A Study on Better Weight Initialization for Neural Network Quantization](https://arxiv.org/abs/2506.10463)
> *起始位置很重要：神经网络量化中更好的权重初始化研究*

*Stone Yun, Alexander Wong* | **Main category: cs.CV**

**Keywords:** 神经网络量化, 权重初始化, 图超网络, 量化鲁棒性, 低比特量化

**Comment:** Portions of this article have been presented as extended abstracts at
  the ICCV 2023 Workshop on Low Bit Quantized Neural Networks (ICCVW-LBQNN
  2023) and the 2020 Conference on Vision and Intelligent Systems (CVIS 2020).
  arXiv admin note: text overlap with arXiv:2011.14578, arXiv:2208.12489,
  arXiv:2309.13773

> **TL;DR:** 本研究探讨了神经网络量化中权重初始化的重要性，并提出了一种新的基于图超网络（GHN-QAT）的方法来提高量化模型的准确性，尤其在低比特量化下表现显著。

**AI_Comments:** 这项研究的创新点在于首次深入探讨了神经网络量化中权重初始化的重要性，并提出了一种基于图超网络（GHN-QAT）的创新方法来解决这一问题。其重要性体现在能够显著提高量化模型的准确性，特别是在极低比特量化下仍能保持较好性能，这对于资源受限的部署场景具有重要意义。该方法为未来量化DNN模型设计提供了新的思路，有望进一步简化和优化量化流程。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）量化是限制机器学习模型推理成本的重要工具。尽管量化感知训练等技术已大大提升了DNN的准确性和鲁棒性，但很少有研究关注改善DNN训练的初始条件以实现量化。正如随机权重初始化对浮点模型测试准确率有显著影响一样，作者认为不同的权重初始化方法也会影响训练模型的量化鲁棒性。

**Method:** 作者首先进行了一项广泛研究，检查了不同权重初始化对各种常用高效CNN构建块的影响。接着，他们探索了一种新的量化鲁棒CNN初始化方法——使用图超网络（GHN）来预测量化DNN的参数。此外，他们还对GHN进行了微调，使其预测量化图的参数（称为GHN-QAT）。

**Result:** 研究发现，即使在不同的CNN架构中，随机权重初始化器的选择也能显著影响最终的量化鲁棒性。GHN预测的参数在常规float32预训练后具有量化鲁棒性。GHN-QAT能进一步提高CNN的量化准确性，尤其在4比特量化下显示出显著的准确性提升，并在2比特量化下优于随机初始化。

**Conclusion:** 这是首次深入研究量化感知DNN权重初始化。GHN-QAT为量化DNN模型设计提供了一种新颖的方法。未来的研究，如将GHN-QAT初始化的参数用于量化感知训练，可以进一步简化DNN量化过程。

> **ai_Abstract:** 本研究探讨了深度神经网络量化中权重初始化的重要性，指出其对模型量化鲁棒性的显著影响。论文通过广泛实验证实了不同初始化方法对最终量化准确率的影响，并提出了一种基于图超网络（GHN）的新型量化鲁棒初始化方法GHN-QAT。实验结果表明，GHN-QAT能够有效提高量化模型的准确性，尤其在低比特量化（如4比特和2比特）下表现出显著优势。这项工作是首次深入研究量化感知DNN权重初始化，为量化DNN模型设计提供了新颖途径。

> **摘要翻译:** 深度神经网络（DNN）量化用于快速、高效的推理，一直是限制机器学习（ML）模型推理成本的重要工具。量化特定的模型开发技术，如正则化、量化感知训练和量化鲁棒性惩罚，极大地提升了现代DNN的准确性和鲁棒性。然而，在改进DNN训练的初始条件以实现量化方面，探索甚少。正如随机权重初始化已被证明能显著影响浮点模型的测试准确率一样，不同的权重初始化方法很可能也会影响训练模型的量化鲁棒性。我们进行了一项广泛研究，考察了不同权重初始化对高效CNN中常用各种CNN构建块的影响。这项分析表明，即使在不同的CNN架构中，随机权重初始化器的选择也能显著影响最终的量化鲁棒性。接下来，我们探索了一种新的量化鲁棒CNN初始化方法——使用图超网络（GHN）来预测量化DNN的参数。除了表明GHN预测的参数在常规float32预训练（GHN的）后具有量化鲁棒性外，我们发现微调GHN以预测量化图的参数（我们称之为GHN-QAT）可以进一步提高CNN的量化准确性。值得注意的是，GHN-QAT甚至在4比特量化下也显示出显著的准确性提升，并且在2比特下优于随机初始化。据我们所知，这是首次对量化感知DNN权重初始化进行深入研究。GHN-QAT为量化DNN模型设计提供了一种新颖的方法。未来的研究，例如使用GHN-QAT初始化的参数进行量化感知训练，可以进一步简化DNN量化过程。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [304] [HalLoc: Token-level Localization of Hallucinations for Vision Language Models](https://arxiv.org/abs/2506.10286)
> *HalLoc: 视觉语言模型幻觉的Token级定位*

*Eunkyu Park, Minyeong Kim, Gunhee Kim* | **Main category: cs.CV**

**Keywords:** 幻觉检测, 视觉语言模型, 数据集, Token级标注, 可靠性

**Comment:** CVPR 2025

> **TL;DR:** 提出了HalLoc数据集，用于高效、概率性地检测视觉语言模型的幻觉，并提供了一个低开销的基线模型。

**AI_Comments:** HalLoc数据集的创新之处在于其Token级的幻觉标注和对概率性检测的支持，这比传统的确定性检测方法更贴近实际应用。其低开销的即插即用基线模型也大大降低了集成难度，有望推动VLM在实际部署中的可靠性提升。

<details>
  <summary>Details</summary>

**Motivation:** 幻觉严重影响大型视觉语言模型的可靠性，现有检测方法计算成本高、延迟大、资源消耗多，且无法处理幻觉与真实信息界限模糊的场景。

**Method:** 提出了HalLoc数据集，包含15万个Token级标注样本（包括幻觉类型），涵盖视觉问答（VQA）、指令遵循和图像字幕任务，旨在实现高效、概率性幻觉检测。同时，引入了一个基于HalLoc训练的基线模型，可在生成过程中进行低开销、并发的幻觉检测。

**Result:** HalLoc数据集促进了能够以分级置信度检测幻觉的模型的开发，实现了更明智的用户交互。基线模型可以无缝集成到现有VLM中，在保持效率的同时提高可靠性。

**Conclusion:** 鲁棒的即插即用幻觉检测模块有望增强视觉语言模型在实际应用中的可信度。

> **ai_Abstract:** 本文提出了HalLoc数据集，旨在解决大型视觉语言模型中幻觉检测效率低下和确定性不足的问题。HalLoc包含15万个Token级标注样本，支持VQA、指令遵循和图像字幕任务， enabling模型以概率性方式检测幻觉。研究还提供了一个基于HalLoc训练的低开销基线模型，可无缝集成到现有VLM中，以提高其可靠性。该工作为开发可信赖的视觉语言模型提供了新的即插即用解决方案。

> **摘要翻译:** 幻觉对大型视觉语言模型的可靠性构成了重大挑战，因此，检测幻觉对于确保关键应用中的准确性至关重要。当前的检测方法通常依赖于计算密集型模型，导致高延迟和资源需求。它们的确定性结果也未能考虑到幻觉信息与真实信息界限不明确的实际场景。为了解决这些问题，我们提出了HalLoc，一个旨在实现高效、概率性幻觉检测的数据集。它包含15万个Token级标注样本，涵盖视觉问答（VQA）、指令遵循和图像字幕任务中的幻觉类型。该数据集有助于开发能够以分级置信度检测幻觉的模型，从而实现更明智的用户交互。此外，我们引入了一个在HalLoc上训练的基线模型，可在生成过程中提供低开销、并发的幻觉检测。该模型可以无缝集成到现有VLM中，在保持效率的同时提高可靠性。这种强大的即插即用幻觉检测模块的前景为增强视觉语言模型在实际应用中的可信度开辟了新途径。HalLoc数据集和代码已公开：https://github.com/dbsltm/cvpr25_halloc。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [311] [Deep Learning-based Multi Project InP Wafer Simulation for Unsupervised Surface Defect Detection](https://arxiv.org/abs/2506.10713)
> *基于深度学习的多项目InP晶圆模拟用于无监督表面缺陷检测*

*Emílio Dolgener Cantú, Rolf Klemens Wittmann, Oliver Abdeen, Patrick Wagner, Wojciech Samek, Moritz Baier, Sebastian Lapuschkin* | **Main category: cs.CV**

**Keywords:** 深度学习, InP晶圆, 缺陷检测, 模拟黄金标准, 半导体制造

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的方法，通过从CAD数据生成合成的黄金标准图像来解决InP多项目晶圆制造中缺乏黄金标准导致的手动缺陷检测问题，并证明其在表面缺陷检测中的有效性。

**AI_Comments:** 本文的创新之处在于利用深度学习生成合成的“黄金标准”，解决了InP多项目晶圆制造中因生产规模小和高设计变异性而难以获取真实黄金标准的问题。这使得原本依赖手动和劳动密集型的缺陷检测过程得以自动化和高效化，对于提升半导体制造的质量管理具有重要意义。该方法通过模拟逼真图像，为无监督缺陷检测提供了新的途径，具有较好的泛化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在半导体制造中，特别是对于磷化铟（InP）多项目晶圆制造，由于生产规模小和设计变异性高，通常无法获得用于质量管理的“黄金标准”模板。这导致缺陷检测过程依赖于手动和劳动密集型操作，效率低下。

**Method:** 本文提出了一种使用深度神经网络生成合成黄金标准的方法。该网络通过CAD数据训练，以模拟逼真的InP晶圆图像。研究评估了不同的训练目标，并在合成数据和InP晶圆照片上评估了模拟图像的质量。该方法被应用于模板匹配过程，以实现缺陷检测。

**Result:** 本文提出的基于深度学习的方法优于基线决策树方法。它能够利用CAD计划中的“模拟黄金芯片”在晶圆的任何用户定义区域进行更高效的缺陷检测，并被证明在表面缺陷检测的模板匹配程序中具有实用性。

**Conclusion:** 通过使用深度学习生成合成的黄金标准，本文成功解决了InP多项目晶圆制造中缺乏真实黄金标准的问题，显著提高了缺陷检测的效率和自动化水平，为半导体质量管理提供了一种有效的解决方案。

> **ai_Abstract:** 本文针对InP多项目晶圆制造中缺乏“黄金标准”导致缺陷检测手动且劳动密集的问题，提出了一种基于深度学习的方法。该方法通过深度神经网络从CAD数据生成逼真的InP晶圆图像作为合成黄金标准。实验证明，该方法优于传统基线方法，能够利用模拟的黄金标准实现高效的无监督表面缺陷检测，并在模板匹配中展现出实用性。

> **摘要翻译:** 半导体制造中的质量管理通常依赖于与已知黄金标准的模板匹配。对于磷化铟（InP）多项目晶圆制造，低生产规模和高设计变异性导致通常无法获得此类黄金标准。因此，缺陷检测是手动且劳动密集型的。这项工作通过提出一种生成合成黄金标准的方法来解决这一挑战，该方法使用深度神经网络训练，以从CAD数据模拟逼真的InP晶圆图像。我们评估了各种训练目标，并在合成数据和InP晶圆照片上评估了模拟图像的质量。我们基于深度学习的方法优于基线决策树方法，使得能够利用CAD计划中的“模拟黄金芯片”在晶圆的任何用户定义区域进行更高效的缺陷检测。我们将我们的方法应用于模板匹配程序，以证明其在表面缺陷检测中的实际效用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [315] [Uncertainty-Aware Deep Learning for Automated Skin Cancer Classification: A Comprehensive Evaluation](https://arxiv.org/abs/2506.10302)
> *不确定性感知深度学习在自动化皮肤癌分类中的应用：一项综合评估*

*Hamzeh Asgharnezhad, Pegah Tabarisaadi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharya* | **Main category: cs.CV**

**Keywords:** 皮肤癌分类, 深度学习, 不确定性量化, 迁移学习, CLIP

**Comment:** 

> **TL;DR:** 本研究对基于深度学习的皮肤癌分类进行了全面评估，结合迁移学习和不确定性量化，发现CLIP-based模型表现最佳，集成方法在准确性和不确定性处理之间取得良好平衡。

**AI_Comments:** 这项研究的创新之处在于其对不确定性感知深度学习在皮肤癌分类中的全面评估，特别是结合了迁移学习和不确定性量化。它不仅比较了多种先进的特征提取器，还深入探讨了模型预测的可靠性，这对于医疗诊断应用至关重要。强调UQ在提高模型可信度方面的作用，使其在实际临床应用中更具价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习模型在自动化皮肤癌分类中显示出前景，但其性能受限于数据稀缺和缺乏不确定性感知。

**Method:** 本研究分两阶段进行：第一阶段，基准测试了多种预训练特征提取器（如CLIP变体、ResNet50等）与传统分类器（如SVM、XGBoost等）的组合，用于皮肤病变分类。第二阶段，引入不确定性量化（UQ），使用蒙特卡洛Dropout (MCD)、集成方法和集成蒙特卡洛Dropout (EMCD) 来评估预测准确性和模型输出的可靠性，并使用不确定性感知指标进行评估。

**Result:** 第一阶段结果显示，基于CLIP的视觉Transformer，特别是LAION CLIP ViT-H/14与SVM结合，提供了最高的分类性能。第二阶段结果表明，集成方法在准确性和不确定性处理之间提供了良好的权衡，而EMCD对不确定预测更敏感。

**Conclusion:** 本研究强调了将不确定性量化整合到基于深度学习的医学诊断中的重要性，以提高实际临床应用中的性能和可信度。

> **ai_Abstract:** 本研究对基于深度学习的皮肤癌分类进行了全面评估，旨在解决数据稀缺和不确定性感知不足的问题。研究分两阶段进行：第一阶段基准测试了多种预训练特征提取器和传统分类器，发现CLIP-based视觉Transformer表现最佳；第二阶段引入了不确定性量化方法（MCD、Ensemble、EMCD），以评估模型可靠性。结果表明，集成方法在准确性和不确定性处理之间取得良好平衡，而EMCD对不确定预测更敏感。研究强调了将不确定性量化整合到深度学习医学诊断中的重要性，以增强其在临床应用中的性能和可信度。

> **摘要翻译:** 准确可靠的皮肤癌诊断对于早期治疗和改善患者预后至关重要。深度学习（DL）模型在自动化皮肤癌分类方面已显示出前景，但其性能可能受到数据稀缺和缺乏不确定性感知的限制。在本研究中，我们利用迁移学习和不确定性量化（UQ）在HAM10000数据集上对基于DL的皮肤病变分类进行了全面评估。在第一阶段，我们对几种预训练的特征提取器进行了基准测试——包括对比语言-图像预训练（CLIP）变体、残差网络-50（ResNet50）、密集连接卷积网络（DenseNet121）、视觉几何组网络（VGG16）和EfficientNet-V2-Large——并结合了一系列传统分类器，如支持向量机（SVM）、极端梯度提升（XGBoost）和逻辑回归。我们的结果表明，基于CLIP的视觉Transformer，特别是LAION CLIP ViT-H/14与SVM结合，提供了最高的分类性能。在第二阶段，我们使用蒙特卡洛Dropout（MCD）、集成方法和集成蒙特卡洛Dropout（EMCD）引入了UQ，不仅评估了预测准确性，还评估了模型输出的可靠性。我们使用不确定性感知指标评估了这些模型，例如不确定性准确率（UAcc）、不确定性敏感度（USen）、不确定性特异度（USpe）和不确定性精度（UPre）。结果表明，集成方法在准确性和不确定性处理之间提供了良好的权衡，而EMCD对不确定预测更敏感。本研究强调了将UQ整合到基于DL的医学诊断中的重要性，以提高实际临床应用中的性能和可信度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [322] [Towards Scalable SOAP Note Generation: A Weakly Supervised Multimodal Framework](https://arxiv.org/abs/2506.10328)
> *迈向可扩展的SOAP笔记生成：一个弱监督多模态框架*

*Sadia Kamal, Tim Oates, Joy Wan* | **Main category: cs.CV**

**Keywords:** SOAP笔记生成, 弱监督, 多模态, 皮肤癌, 临床文档

**Comment:** Accepted at IEEE/CVF Computer Society Conference on Computer Vision
  and Pattern Recognition Workshops (CVPRW)

> **TL;DR:** 本文提出了一个弱监督多模态框架，用于从有限输入（图像和稀疏文本）生成临床结构化SOAP笔记，旨在减轻医生负担并减少对大量标注数据的依赖，其性能可与GPT-4o等模型媲美。

**AI_Comments:** 该论文的创新点在于提出了一个弱监督的多模态框架，解决了传统SOAP笔记生成中对大量手动标注数据的高度依赖问题，从而提高了可扩展性。其通过结合图像和文本输入，并引入新的评估指标，为临床文档自动化提供了一条有前景的路径，对于减轻医生工作量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤癌是全球最常见的癌症，每年医疗开支超过80亿美元。医生手动生成详细的SOAP笔记费时费力，导致临床医生倦怠。因此，需要一种可扩展、自动化生成SOAP笔记的方法来减轻医生负担。

**Method:** 本文提出了一个弱监督多模态框架，能够从有限的输入（包括病变图像和稀疏临床文本）生成临床结构化的SOAP笔记。该方法减少了对手动标注的依赖，并引入了两个新的评估指标：MedConceptEval和Clinical Coherence Score (CCS)，分别评估与专家医学概念的语义对齐和与输入特征的对齐。

**Result:** 该方法在关键临床相关性指标上的性能与GPT-4o、Claude和DeepSeek Janus Pro相当。引入了MedConceptEval和Clinical Coherence Score (CCS)两个新指标来评估临床质量。

**Conclusion:** 该弱监督多模态框架能够有效地从有限输入生成临床结构化SOAP笔记，减轻了临床医生负担，减少了对大量标注数据的需求，并取得了与现有先进模型相当的性能。

> **ai_Abstract:** 本文提出了一种弱监督多模态框架，旨在从有限的病变图像和稀疏临床文本输入中自动生成结构化的SOAP笔记，以应对皮肤癌诊疗中医生手动记录负担重的问题。该框架减少了对大量人工标注数据的依赖，实现了可扩展的临床文档生成，并引入了MedConceptEval和Clinical Coherence Score (CCS)两个新指标来评估生成笔记的临床质量。实验结果表明，该方法在关键临床相关性指标上表现出与GPT-4o等先进模型相当的性能。

> **摘要翻译:** 皮肤癌是全球最常见的癌症形式，每年导致超过80亿美元的医疗保健支出。在临床环境中，医生使用详细的SOAP（主观、客观、评估和计划）笔记记录患者就诊情况。然而，手动生成这些笔记费时费力，导致临床医生倦怠。在这项工作中，我们提出了一个弱监督多模态框架，用于从有限的输入（包括病变图像和稀疏临床文本）生成临床结构化的SOAP笔记。我们的方法减少了对手动标注的依赖，实现了可扩展、临床依据的文档生成，同时减轻了临床医生负担并减少了对大量标注数据的需求。我们的方法在关键临床相关性指标上的性能与GPT-4o、Claude和DeepSeek Janus Pro相当。为了评估临床质量，我们引入了两个新的指标MedConceptEval和Clinical Coherence Score (CCS)，它们分别评估与专家医学概念的语义对齐和与输入特征的对齐。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [335] [Using Vision Language Models to Detect Students' Academic Emotion through Facial Expressions](https://arxiv.org/abs/2506.10334)
> *使用视觉语言模型通过面部表情检测学生的学习情感*

*Deliang Wang, Chao Yang, Gaowei Chen* | **Main category: cs.CV**

**Keywords:** 视觉语言模型, 学习情感, 面部表情识别, 零样本学习, 在线学习

**Comment:** 

> **TL;DR:** 本研究探讨了视觉语言模型（VLMs）在通过面部表情检测学生学习情感方面的潜力，发现VLMs表现适中，其中Qwen2.5-VL-7B-Instruct优于Llama-3.2-11B-Vision-Instruct，尤其擅长识别快乐和困惑，但在检测分心行为上存在不足。

**AI_Comments:** 这项研究创新性地探索了视觉语言模型在教育领域情感识别的应用，特别是其零样本泛化能力，避免了传统方法的繁琐数据标注和训练。研究指出了VLMs在特定情感（如快乐和困惑）识别上的潜力，但也揭示了其在识别某些复杂情感（如分心）上的局限性，为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 学生的学习情感显著影响他们的社交行为和学习表现。传统的监督机器学习方法在自动准确分析这些情感时，泛化能力差，需要反复的数据收集、标注和训练。视觉语言模型（VLMs）的出现提供了一种无需微调即可实现泛化视觉识别任务的有前景的替代方案。

**Method:** 本研究利用Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct两种视觉语言模型，通过零样本提示（zero-shot prompting）分析了5000张描绘困惑、分心、快乐、中性、疲惫表情的图像，以检测在线学习环境中的学生学习情感。

**Result:** 初步结果显示，两种模型在学术面部表情识别方面表现适中。Qwen2.5-VL-7B-Instruct的表现优于Llama-3.2-11B-Vision-Instruct。两者在识别学生的快乐情感方面表现出色，但未能检测到分心行为。Qwen2.5-VL-7B-Instruct在识别学生的困惑表情方面表现出相对较高的性能。

**Conclusion:** 视觉语言模型，特别是Qwen2.5-VL-7B-Instruct，在通过面部表情识别学生学习情感方面具有潜力，尤其是在识别导致学生困惑的内容方面。

> **ai_Abstract:** 本研究探讨了视觉语言模型（VLMs）在通过面部表情检测学生学习情感方面的应用潜力，以克服传统监督学习方法的泛化难题。研究使用Llama-3.2和Qwen2.5两种VLM，通过零样本提示分析了5000张学生表情图像。结果显示，VLMs在学术面部表情识别上表现适中，其中Qwen2.5优于Llama-3.2，尤其擅长识别快乐和困惑，但在检测分心行为上存在不足。研究认为VLMs，特别是Qwen2.5，在识别学生困惑情感方面具有实际应用价值。

> **摘要翻译:** 学生的学习情感显著影响他们的社交行为和学习表现。传统上，自动准确分析这些情感的方法主要依赖于监督机器学习算法。然而，这些模型通常难以在不同情境下泛化，需要反复进行数据收集、标注和训练。视觉语言模型（VLMs）的出现提供了一种有前景的替代方案，它们通过零样本提示（zero-shot prompting）实现了视觉识别任务的泛化，而无需进行微调。本研究旨在探讨VLMs在在线学习环境中通过面部表情分析学生学习情感的潜力。我们使用了Llama-3.2-11B-Vision-Instruct和Qwen2.5-VL-7B-Instruct两种VLM，通过零样本提示分析了5000张描绘困惑、分心、快乐、中性、疲惫表情的图像。初步结果表明，这两种模型在学术面部表情识别方面表现适中，其中Qwen2.5-VL-7B-Instruct的表现优于Llama-3.2-11B-Vision-Instruct。值得注意的是，两种模型在识别学生的快乐情感方面表现出色，但未能检测到分心行为。此外，Qwen2.5-VL-7B-Instruct在识别学生的困惑表情方面表现出相对较高的性能，这突显了其在识别导致学生困惑的内容方面的实际应用潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [PointGS: Point Attention-Aware Sparse View Synthesis with Gaussian Splatting](https://arxiv.org/abs/2506.10335)
> *PointGS：基于点注意力感知高斯泼溅的稀疏视图合成*

*Lintao Xiang, Hongpei Zheng, Yating Huang, Qijun Yang, Hujun Yin* | **Main category: cs.CV**

**Keywords:** 3D Gaussian Splatting, 稀疏视图合成, 点注意力, 实时渲染, 神经辐射场

**Comment:** 

> **TL;DR:** PointGS 提出了一种新的高斯泼溅框架，通过点注意力机制和多尺度特征聚合，实现了从稀疏视图进行高质量实时渲染，解决了传统 3DGS 在稀疏视图下过拟合的问题。

**AI_Comments:** 该论文的创新点在于提出了一个点式特征感知框架，通过引入自注意力机制的点交互网络，有效地增强了高斯点的外观表示，从而解决了 3DGS 在稀疏视图下过拟合的痛点。这对于实际应用中数据采集受限的场景具有重要意义，提升了 3DGS 在低资源条件下的实用性和渲染质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的 3D Gaussian Splatting (3DGS) 方法需要大量校准视图来生成一致且完整的场景表示。当输入视图有限时，3DGS 倾向于过拟合训练视图，导致渲染质量显著下降。

**Method:** PointGS 框架包括：1. 采用最新的立体基础模型估计精确相机姿态并重建密集点云用于高斯初始化。2. 通过采样和聚合稀疏输入的多尺度 2D 外观特征来编码每个 3D 高斯点的颜色属性。3. 设计一个基于自注意力机制的点交互网络，使每个高斯点与其最近邻点进行交互，以增强点级外观表示。4. 将丰富后的特征通过两个轻量级多层感知器 (MLP) 解码为高斯参数进行最终渲染。

**Result:** 在各种基准测试中，PointGS 显著优于基于 NeRF 的方法，并且在少量视图设置下与最先进的 3DGS 方法相比，取得了具有竞争力的性能。

**Conclusion:** PointGS 成功解决了 3DGS 在稀疏视图下渲染质量下降的问题，通过点注意力感知框架实现了高质量的实时渲染，并展现出优于 NeRF 和与 SOTA 3DGS 相当的性能。

> **ai_Abstract:** 本文提出了 PointGS，一个点式特征感知的高斯泼溅框架，旨在解决 3DGS 在稀疏视图下渲染质量下降的问题。PointGS 首先利用立体基础模型进行相机姿态估计和点云初始化，然后通过聚合多尺度 2D 特征编码高斯点的颜色属性。其核心创新在于引入了一个基于自注意力机制的点交互网络，以增强点级外观表示。实验证明，PointGS 在稀疏视图设置下实现了高质量的实时渲染，性能优于 NeRF，并与最先进的 3DGS 方法相当。

> **摘要翻译:** 3D Gaussian splatting (3DGS) 是一种创新的渲染技术，通过利用显式的 3D 场景表示，在渲染速度和视觉质量上都超越了神经辐射场 (NeRF)。现有的 3DGS 方法需要大量校准视图才能生成一致且完整的场景表示。当输入视图有限时，3DGS 倾向于过拟合训练视图，导致渲染质量显著下降。为了解决这一限制，我们提出了一种点式特征感知高斯泼溅框架，该框架能够从稀疏训练视图进行实时、高质量渲染。具体来说，我们首先采用最新的立体基础模型来估计精确的相机姿态并重建密集点云用于高斯初始化。然后，我们通过采样和聚合稀疏输入的多尺度 2D 外观特征来编码每个 3D 高斯点的颜色属性。为了增强点式外观表示，我们设计了一个基于自注意力机制的点交互网络，允许每个高斯点与其最近邻点进行交互。这些丰富后的特征随后通过两个轻量级多层感知器 (MLP) 解码为高斯参数进行最终渲染。在各种基准测试上进行的广泛实验表明，我们的方法显著优于基于 NeRF 的方法，并且在少量视图设置下与最先进的 3DGS 方法相比，取得了具有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [349] [GeoCAD: Local Geometry-Controllable CAD Generation](https://arxiv.org/abs/2506.10337)
> *GeoCAD：局部几何可控的CAD生成*

*Zhanwei Zhang, Kaiyuan Liu, Junjie Liu, Wenxiao Wang, Binbin Lin, Liang Xie, Chen Shen, Deng Cai* | **Main category: cs.CV**

**Keywords:** CAD生成, 局部几何控制, 大型语言模型, 几何指令, 文本到CAD

**Comment:** 18 pages, 12 figures

> **TL;DR:** GeoCAD是一种新的CAD生成方法，它允许用户通过文本指令精确控制CAD模型的局部几何形状，解决了现有方法无法遵循文本指令或关注局部区域的问题，并通过LLM实现了高效的局部部件生成。

**AI_Comments:** GeoCAD的创新之处在于其提出的互补标注策略，将顶点级标注与VLLM（视觉-语言大型模型）相结合，系统地为CAD局部部件生成几何指令，从而能够处理简单和复杂的几何形状。此外，利用LLM进行局部部件的预测和生成，使得文本指令能够直接转化为CAD模型的几何修改，显著提升了用户对设计过程的控制力。该方法在解决现有CAD生成工具在局部控制和文本指令遵循方面的不足具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的局部几何可控CAD生成方法在遵循文本指令或聚焦于CAD模型的局部区域方面存在不足，导致设计效率受限。

**Method:** GeoCAD首先提出了一种互补的标注策略，结合基于顶点的标注和基于VLLM的标注，为约22.1万个不同的局部部件生成几何指令。在训练阶段，给定一个CAD模型，随机遮盖一个局部部件，然后利用其几何指令和剩余部件作为输入，提示大型语言模型（LLMs）预测被遮盖的部件。在推理阶段，用户可以指定任何局部部件进行修改，并遵循预定义的几何指令。

**Result:** 大量实验证明了GeoCAD在生成质量、有效性和文本到CAD一致性方面的有效性。

**Conclusion:** GeoCAD通过其创新的标注策略和LLM驱动的生成方法，成功实现了局部几何可控的CAD生成，显著提升了设计效率，并解决了现有方法面临的挑战。

> **ai_Abstract:** GeoCAD是一种新型的局部几何可控CAD生成方法，旨在提高设计效率并允许用户通过文本指令精确控制CAD模型的局部修改。该方法通过引入互补的标注策略（结合顶点和VLLM标注）为CAD局部部件生成几何指令，并利用大型语言模型（LLMs）根据这些指令和上下文生成或修改局部部件。实验结果表明，GeoCAD在生成质量、有效性和文本到CAD一致性方面表现出色，有效解决了现有方法无法遵循文本指令或专注于局部区域的局限性。

> **摘要翻译:** 局部几何可控的计算机辅助设计（CAD）生成旨在自动修改CAD模型的局部部分，从而提高设计效率。它还确保新生成的局部部分的形状遵循用户特定的几何指令（例如，等腰直角三角形或一个角被切掉的矩形）。然而，现有方法在实现这一目标时遇到了挑战。具体来说，它们要么缺乏遵循文本指令的能力，要么无法专注于局部部分。为了解决这一限制，我们引入了GeoCAD，一种用户友好且局部几何可控的CAD生成方法。具体而言，我们首先提出了一种互补的标注策略，用于生成局部部件的几何指令。该策略包括基于顶点的标注和基于VLLM的标注，分别用于系统地标注简单和复杂的部件。通过这种方式，我们总共标注了约22.1万个不同的局部部件。在训练阶段，给定一个CAD模型，我们随机遮盖一个局部部件。然后，使用其几何指令和剩余部件作为输入，我们提示大型语言模型（LLMs）预测被遮盖的部分。在推理过程中，用户可以指定任何局部部件进行修改，同时遵循各种预定义的几何指令。大量的实验证明了GeoCAD在生成质量、有效性和文本到CAD一致性方面的有效性。代码将在https://github.com/Zhanwei-Z/GeoCAD上提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [356] [UrbanSense:AFramework for Quantitative Analysis of Urban Streetscapes leveraging Vision Large Language Models](https://arxiv.org/abs/2506.10342)
> *UrbanSense：一个利用视觉大语言模型对城市街景进行定量分析的框架*

*Jun Yin, Jing Zhong, Peilin Li, Pengyu Zeng, Miao Zhang, Ran Luo, Shuai Lu* | **Main category: cs.CV**

**Keywords:** 城市街景, 视觉大语言模型, 定量分析, 城市风格, UrbanSense

**Comment:** 

> **TL;DR:** UrbanSense利用视觉大语言模型框架，通过构建数据集和开发分析工具，实现对城市街景风格的自动化、可扩展的定量分析，并验证了其捕捉细微风格差异的能力。

**AI_Comments:** 本论文创新性地将视觉大语言模型应用于城市街景的定量分析，克服了传统方法主观性强、难以标准化的局限。通过构建专门的数据集和开发分析框架，为城市形态研究提供了新的数据驱动工具，在城市规划和设计领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 理解城市文化和建筑风格差异对于预测城市未来演变至关重要。然而，传统的城市文化研究方法依赖专家解读和历史文献，难以标准化。为了解决这一问题，本研究提出了一个多模态研究框架。

**Method:** 本研究提出了一个基于视觉语言模型的多模态研究框架，用于自动化和可扩展地分析城市街景风格差异。具体贡献包括：1. 构建了UrbanDiffBench数据集，包含不同时期和地区的建筑图像。2. 开发了UrbanSense，第一个基于视觉语言模型的城市街景分析框架，用于定量生成和比较城市风格表示。

**Result:** 实验结果显示，超过80%的生成描述通过t检验（p < 0.05）。主观评估的高Phi分数（城市为0.912，时期为0.833）证实了该方法捕捉细微风格差异的能力。这些结果表明该方法在量化和解释城市风格演变方面的潜力。

**Conclusion:** 本研究提出的UrbanSense框架为城市街景的定量分析提供了一个科学基础，能够有效捕捉和解释城市风格的演变，为未来的城市设计提供了数据驱动的视角。

> **ai_Abstract:** 本研究提出UrbanSense，一个基于视觉大语言模型的多模态框架，旨在解决传统城市文化研究中街景风格分析标准化困难的问题。通过构建UrbanDiffBench数据集和开发UrbanSense框架，实现了对城市街景风格差异的自动化和定量分析。实验结果验证了该方法在捕捉细微风格差异方面的有效性，为理解和预测城市演变提供了客观、数据驱动的新方法。

> **摘要翻译:** 城市文化和建筑风格因地理、年代、历史和社会政治因素而在不同城市间差异显著。理解这些差异对于预测城市未来演变至关重要。作为中国历史延续性和现代创新的代表案例，北京和深圳为探索城市街景的转型提供了宝贵的视角。然而，传统的城市文化研究方法往往依赖于专家解读和历史文献，这在不同语境下难以标准化。为解决此问题，我们提出了一个基于视觉语言模型的多模态研究框架，以实现城市街景风格差异的自动化和可扩展分析。这种方法增强了城市形态研究的客观性和数据驱动性。本研究的贡献如下：首先，我们构建了UrbanDiffBench，一个精选的城市街景数据集，包含来自不同时期和地区的建筑图像。其次，我们开发了UrbanSense，第一个基于视觉语言模型的城市街景分析框架，能够定量生成和比较城市风格表示。第三，实验结果表明，超过80%的生成描述通过t检验（p小于0.05）。主观评估的高Phi分数（城市为0.912，时期为0.833）证实了该方法捕捉细微风格差异的能力。这些结果突出了该方法量化和解释城市风格演变潜力，为未来设计提供了科学基础的视角。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [362] [RealKeyMorph: Keypoints in Real-world Coordinates for Resolution-agnostic Image Registration](https://arxiv.org/abs/2506.10344)
> *RealKeyMorph：用于分辨率无关图像配准的真实世界坐标关键点*

*Mina C. Moghadam, Alan Q. Wang, Omer Taub, Martin R. Prince, Mert R. Sabuncu* | **Main category: cs.CV**

**Keywords:** 图像配准, 分辨率无关, 关键点, 真实世界坐标, 医学图像

**Comment:** 23 pages, 8 figures, to be submitted to MELBA

> **TL;DR:** RealKeyMorph (RKM) 是一种新的图像配准方法，通过在真实世界坐标中输出关键点来避免图像重采样，从而实现分辨率无关的配准，解决了现有机器学习方法在不同分辨率医学图像配准中引入伪影的问题。

**AI_Comments:** 该论文的创新点在于提出了RealKeyMorph (RKM) 方法，其核心是通过在真实世界坐标中处理关键点，从而避免了传统图像配准中常见的重采样步骤。这一创新有效地解决了医学图像在不同分辨率下配准时可能引入的插值伪影问题，显著提高了配准的准确性和鲁棒性。其重要性在于为处理真实世界中分辨率差异的医学图像配准提供了一个更优的解决方案，对于临床应用具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 许多实际场景需要对空间分辨率不同的医学图像进行配准，这可能由图像采集参数差异引起。然而，所有先前的基于机器学习的配准技术都会将图像重采样到固定分辨率，这会因插值引入伪影，导致次优结果。

**Method:** 本文提出了RealKeyMorph (RKM)，它是KeyMorph的扩展。RKM通过训练网络学习图像对的对应关键点，然后使用闭合形式的关键点匹配步骤来导出对齐它们的变换。为了避免重采样并对原始数据进行操作，RKM利用扫描仪（例如MRI机器）生成的仿射矩阵，将关键点输出到扫描仪的真实世界坐标中，从而使提取的关键点与分辨率无关。

**Result:** 实验证明了RKM在腹部MRI的正交2D堆栈配准任务以及具有不同分辨率的脑数据集3D体配准任务中的优势。

**Conclusion:** RealKeyMorph (RKM) 提供了一种分辨率无关的图像配准方法，通过在真实世界坐标中操作关键点来避免重采样引入的伪影，从而解决了医学图像配准中不同分辨率图像的挑战。

> **ai_Abstract:** RealKeyMorph (RKM) 是一种针对不同分辨率医学图像配准的新型机器学习方法。与传统方法通过重采样引入伪影不同，RKM是KeyMorph的扩展，它利用扫描仪的仿射矩阵将关键点直接输出到真实世界坐标中，从而实现分辨率无关的配准并避免重采样。实验证明RKM在腹部MRI和脑部数据集的配准任务中表现出优势。

> **摘要翻译:** 许多实际场景需要对空间分辨率不同的医学图像进行配准，这可能由像素间距、切片厚度和视野等图像采集参数的差异引起。然而，所有先前的基于机器学习的配准技术都会将图像重采样到固定分辨率。这是次优的，因为重采样会因插值引入伪影。为了解决这个问题，我们提出了RealKeyMorph (RKM)，这是一种用于图像配准的分辨率无关方法。RKM是KeyMorph的扩展，KeyMorph是一种通过训练网络学习给定图像对的对应关键点，然后使用闭合形式的关键点匹配步骤来导出对齐它们的变换的配准框架。为了避免重采样并能够在原始数据上操作，RKM以扫描仪的真实世界坐标输出关键点。为此，我们利用扫描仪（例如MRI机器）生成的仿射矩阵，该矩阵编码了从体素坐标到真实世界坐标的映射。通过将关键点转换为真实世界空间并将此集成到训练过程中，RKM有效地使提取的关键点与分辨率无关。在我们的实验中，我们展示了RKM在腹部MRI的正交2D堆栈配准任务以及具有不同分辨率的脑数据集3D体配准任务中的优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [368] [Motion-R1: Chain-of-Thought Reasoning and Reinforcement Learning for Human Motion Generation](https://arxiv.org/abs/2506.10353)
> *Motion-R1：链式思考推理与强化学习在人体动作生成中的应用*

*Runqi Ouyang, Haoyun Li, Zhenyuan Zhang, Xiaofeng Wang, Zheng Zhu, Guan Huang, Xingang Wang* | **Main category: cs.CV**

**Keywords:** 文本到动作生成, 链式思考, 强化学习, 人体动作生成, 语义理解

**Comment:** 

> **TL;DR:** Motion-R1结合链式思考和强化学习，解决了现有文本到动作生成中缺乏控制性、一致性和多样性的问题。

**AI_Comments:** Motion-R1的创新点在于将大语言模型的链式思考能力引入到文本到动作生成领域，通过显式地分解复杂指令，提升了生成动作的语义理解和逻辑一致性。结合强化学习进行联合优化，进一步增强了模型的性能和生成质量，为长时程、复杂动作序列的生成提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本到动作生成方法依赖端到端映射策略，未能捕捉深层语言结构和逻辑推理，导致生成动作缺乏可控性、一致性和多样性。

**Method:** 提出Motion-R1，一个统一的动作-语言建模框架，集成了链式思考（Chain-of-Thought）机制，将复杂文本指令分解为逻辑结构化的动作路径，提供高级语义指导。采用群相对策略优化（Group Relative Policy Optimization），一种为大型模型设计的强化学习算法，利用动作质量反馈联合优化推理链和动作合成。

**Result:** 在多个基准数据集上的广泛实验表明，Motion-R1与最先进的方法相比，实现了有竞争力或更优的性能，特别是在需要细致语义理解和长期时间连贯性的场景中。

**Conclusion:** Motion-R1通过结合链式思考和强化学习，有效解决了文本到动作生成中现有方法的局限性，显著提高了生成动作的可控性、一致性和多样性，并在复杂指令下表现出优越性能。

> **ai_Abstract:** 本文提出了Motion-R1，一个结合链式思考（Chain-of-Thought）机制和强化学习（Group Relative Policy Optimization）的统一动作-语言建模框架，旨在解决现有文本到动作生成方法在可控性、一致性和多样性方面的不足。Motion-R1通过分解复杂指令为逻辑动作路径，增强了模型对多步和复杂命令的理解与执行能力。实验证明，Motion-R1在多项基准测试中表现出与SOTA方法相当或更优的性能，尤其是在需要精细语义理解和长期时间连贯性的任务上。

> **摘要翻译:** 最近大语言模型在自然语言理解和推理方面的进展，为文本到动作生成开辟了新的可能性。尽管现有方法在语义对齐和动作合成方面取得了显著进展，但它们通常依赖端到端映射策略，未能捕捉深层语言结构和逻辑推理。因此，生成的动作往往缺乏可控性、一致性和多样性。为了解决这些局限性，我们提出了Motion-R1，一个统一的动作-语言建模框架，它集成了链式思考机制。通过将复杂的文本指令明确分解为逻辑结构化的动作路径，Motion-R1为动作生成提供了高层语义指导，显著增强了模型解释和执行多步骤、长时程和组合丰富命令的能力。为了训练我们的模型，我们采用了群相对策略优化，这是一种为大型模型设计的强化学习算法，它利用动作质量反馈来联合优化推理链和动作合成。在多个基准数据集上的广泛实验表明，Motion-R1与最先进的方法相比，实现了有竞争力或更优的性能，特别是在需要细致语义理解和长期时间连贯性的场景中。代码、模型和数据将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [FaceLiVT: Face Recognition using Linear Vision Transformer with Structural Reparameterization For Mobile Device](https://arxiv.org/abs/2506.10361)
> *FaceLiVT：用于移动设备的结构重参数化线性视觉Transformer人脸识别*

*Novendra Setyawan, Chi-Chia Sun, Mao-Hsiu Hsu, Wen-Kai Kuo, Jun-Wei Hsieh* | **Main category: cs.CV**

**Keywords:** 人脸识别, 线性视觉Transformer, 移动设备, 结构重参数化, 轻量级模型

**Comment:** 2025 ICIP

> **TL;DR:** FaceLiVT是一种轻量级混合CNN-Transformer人脸识别模型，通过线性注意力机制和重参数化降低了计算复杂度，同时在移动设备上实现了高精度和低延迟，性能优于现有轻量级模型。

**AI_Comments:** FaceLiVT的创新之处在于其混合CNN-Transformer架构与轻量级多头线性注意力机制的结合，以及结构重参数化。这使其能够在移动设备上实现高效的人脸识别，兼顾了速度和精度，是边缘计算领域的一项重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 在移动设备上实现高效、准确的实时人脸识别面临计算复杂度和准确性的挑战，需要一个既轻量级又强大的解决方案。

**Method:** 引入FaceLiVT模型，它结合了混合卷积神经网络（CNN）-Transformer架构与创新的轻量级多头线性注意力（MHLA）机制。通过将MHLA与重参数化令牌混合器结合，有效降低计算复杂度。

**Result:** 在LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C等挑战性基准测试中表现出优越性能，超越了最先进的轻量级模型。MHLA显著提高了推理速度，FaceLiVT比EdgeFace快8.6倍，比纯ViT模型快21.2倍，实现了高精度和低延迟。

**Conclusion:** FaceLiVT为资源受限平台上的实时人脸识别提供了一个高效实用的解决方案。

> **ai_Abstract:** FaceLiVT是一种专为移动设备设计的人脸识别模型，它融合了CNN和Transformer架构，并引入了创新的多头线性注意力（MHLA）机制和重参数化令牌混合器。该模型在降低计算复杂度的同时保持了高准确性，并在多个基准测试中展现出优于现有轻量级模型的性能，尤其在推理速度上显著提升。FaceLiVT为资源受限环境下的实时人脸识别提供了一个高效且实用的解决方案。

> **摘要翻译:** 本文介绍了FaceLiVT，这是一种轻量级但功能强大的人脸识别模型，它集成了混合卷积神经网络（CNN）-Transformer架构与创新且轻量级的多头线性注意力（MHLA）机制。通过将MHLA与重参数化令牌混合器结合，FaceLiVT有效降低了计算复杂度，同时保持了具有竞争力的准确性。在LFW、CFP-FP、AgeDB-30、IJB-B和IJB-C等挑战性基准测试上的广泛评估突出显示了其与最先进轻量级模型相比的卓越性能。MHLA显著提高了推理速度，使FaceLiVT能够在移动设备上以较低延迟提供高精度。具体而言，FaceLiVT比EdgeFace（一种为边缘设备优化的近期混合CNN-Transformer模型）快8.6倍，比纯ViT模型快21.2倍。凭借其均衡的设计，FaceLiVT为资源受限平台上的实时人脸识别提供了一个高效实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [380] [FSATFusion: Frequency-Spatial Attention Transformer for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.10366)
> *FSATFusion：用于红外和可见光图像融合的频率-空间注意力Transformer*

*Tianpei Zhang, Jufeng Zhao, Yiming Zhu, Guangmang Cui, Yuhan Lyu* | **Main category: cs.CV**

**Keywords:** 红外和可见光图像融合, Transformer, 频率-空间注意力, 图像融合, 深度学习

**Comment:** 

> **TL;DR:** FSATFusion是一个新的基于Transformer的网络，用于红外和可见光图像融合，解决了CNN捕获全局上下文的局限性，并表现出卓越的融合性能和泛化能力。

**AI_Comments:** 该论文提出了一种创新的Transformer架构FSATFusion，将频率和空间注意力机制结合，有效解决了传统CNN在图像融合中全局上下文信息捕获不足的问题。其在多种任务和下游应用中的优异表现，特别是泛化能力，展现了该方法的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习方法在红外和可见光图像融合（IVIF）中常使用卷积神经网络（CNN）提取特征，但CNN捕获全局上下文的能力有限，这会导致信息丢失，从而限制融合性能。

**Method:** 提出了一种名为频率-空间注意力Transformer融合网络（FSATFusion）的端到端融合网络。FSATFusion包含一个频率-空间注意力Transformer（FSAT）模块，旨在有效捕获源图像的区分性特征。该FSAT模块包括一个频率-空间注意力机制（FSAM），能够从特征图中提取重要特征。此外，还提出了一个改进的Transformer模块（ITM）以增强原始Transformer提取全局上下文信息的能力。

**Result:** 通过定性和定量比较实验，FSATFusion展示了优于其他最先进方法的融合质量和效率。此外，该网络在未经任何修改的情况下，在两项额外任务上进行了测试，验证了FSATFusion出色的泛化能力。最后，目标检测实验证明了FSATFusion在下游视觉任务中的优越性。

**Conclusion:** FSATFusion通过其新颖的频率-空间注意力Transformer设计，有效解决了现有方法在红外和可见光图像融合中全局上下文捕获的局限性，并展现了卓越的融合性能、效率、泛化能力以及在下游任务中的应用潜力。

> **ai_Abstract:** FSATFusion是一种新型的端到端频率-空间注意力Transformer网络，专为红外和可见光图像融合（IVIF）设计，旨在克服现有基于CNN方法在捕获全局上下文信息方面的不足。该网络包含一个频率-空间注意力Transformer（FSAT）模块，结合了频率-空间注意力机制（FSAM）和改进的Transformer模块（ITM），以高效提取判别性特征和增强全局上下文理解。实验结果表明，FSATFusion在融合质量、效率、泛化能力和下游视觉任务表现上均优于最先进方法。

> **摘要翻译:** 红外和可见光图像融合（IVIF）因其在下游应用中的出色表现而受到研究界和工业界日益增长的关注。现有的深度学习方法通常利用卷积神经网络来提取图像特征。然而，卷积操作固有的捕获全局上下文的能力不足，可能导致信息丢失，从而限制融合性能。为了解决这一局限性，我们提出了一种名为频率-空间注意力Transformer融合网络（FSATFusion）的端到端融合网络。FSATFusion包含一个频率-空间注意力Transformer（FSAT）模块，旨在有效捕获源图像的区分性特征。该FSAT模块包括一个频率-空间注意力机制（FSAM），能够从特征图中提取重要特征。此外，我们提出了一种改进的Transformer模块（ITM）来增强原始Transformer提取全局上下文信息的能力。我们进行了定性和定量比较实验，证明了FSATFusion与其他最先进方法相比具有卓越的融合质量和效率。此外，我们的网络在未经任何修改的情况下，在两项额外任务上进行了测试，以验证FSATFusion出色的泛化能力。最后，目标检测实验证明了FSATFusion在下游视觉任务中的优越性。我们的代码可在https://github.com/Lmmh058/FSATFusion获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [384] [Revisiting Transformers with Insights from Image Filtering](https://arxiv.org/abs/2506.10371)
> *借鉴图像滤波的Transformer再探*

*Laziz U. Abdullaev, Maksim Tkachenko, Tan M. Nguyen* | **Main category: cs.CV**

**Keywords:** Transformer, 自注意力, 图像滤波, 可解释性, 鲁棒性

**Comment:** 12 pages, 6 figures

> **TL;DR:** 本文旨在通过开发一个统一的图像处理框架，深入解释Transformer中自注意力机制及其组件（如位置编码、残差连接）的运作原理，并提出了两种受图像处理启发的Transformer架构修改，经验证可提高准确性和鲁棒性。

**AI_Comments:** 这篇论文通过将Transformer的自注意力机制与图像处理（特别是图像滤波）联系起来，提供了一个新颖的视角来解释其内部运作原理，具有创新性。它不仅关注理论可解释性，还通过实际的架构修改证明了这种跨领域见解的实用价值，即在提高模型性能和鲁棒性方面。

<details>
  <summary>Details</summary>

**Motivation:** Transformer中的自注意力机制是启发式的且难以解释，缺乏一个鲁棒的理论基础来解释其成功和局限性。现有框架未能深入解释增强自注意力机制的各种架构组件（如位置编码、残差连接及其变体）的机理。

**Method:** 开发一个统一的图像处理框架，用于解释自注意力计算、位置编码和残差连接的作用，并提出了两种独立的、受图像处理启发的Transformer架构修改。

**Result:** 经验证明，受图像处理启发的修改可以显著提高Transformer在语言和视觉任务中的准确性和对数据污染及对抗性攻击的鲁棒性，并改善长序列理解能力。

**Conclusion:** 通过引入一个统一的图像处理框架和相关的架构修改，不仅提升了对Transformer内部机制的理解，还带来了实际的性能提升，特别是在准确性和鲁棒性方面。

> **ai_Abstract:** 这项工作通过引入一个统一的图像处理框架，旨在深入理解Transformer中自注意力机制及其核心组件（如位置编码和残差连接）的运作原理。该研究不仅提供了更深层次的机制解释，还提出了两种受图像处理启发的Transformer架构修改。经验结果表明，这些修改不仅有助于提高可解释性，还能显著提升模型在语言和视觉任务中的准确性、对数据污染和对抗性攻击的鲁棒性，并改善长序列理解能力。

> **摘要翻译:** 自注意力机制作为Transformer这一最先进深度学习架构的基石，很大程度上是启发式驱动的，并且从根本上难以解释。因此，建立一个强大的理论基础来解释其显著的成功和局限性已成为近期研究中日益突出的焦点。一些引人注目的方向已经探索了通过图像去噪和非参数回归的角度来理解自注意力。尽管前景光明，但现有框架仍然缺乏对增强自注意力机制的各种架构组件（无论是其原始公式还是后续变体）的更深层次的机械解释。在这项工作中，我们旨在通过开发一个统一的图像处理框架来推进这种理解，该框架不仅能够解释自注意力计算本身，还能解释位置编码和残差连接等组件的作用，包括许多后续变体。我们还基于我们的框架，指出这两个概念之间潜在的区别，并努力弥合这一差距。我们在Transformer中引入了两种独立的架构修改。虽然我们的主要目标是可解释性，但我们凭经验观察到，受图像处理启发的修改还可以显著提高在语言和视觉任务中的准确性和对数据污染和对抗性攻击的鲁棒性，以及更好的长序列理解能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [388] [Leveraging 6DoF Pose Foundation Models For Mapping Marine Sediment Burial](https://arxiv.org/abs/2506.10386)
> *利用六自由度姿态基础模型进行海洋沉积物埋藏测绘*

*Jerry Yan, Chinmay Talegaonkar, Nicholas Antipa, Eric Terrill, Sophia Merrifield* | **Main category: cs.CV**

**Keywords:** 海底埋藏, 六自由度姿态, 计算机视觉, 深度学习, 海洋测绘

**Comment:** 

> **TL;DR:** 本文介绍了一种名为PoseIDON的计算机视觉流程，结合深度基础模型特征和多视图摄影测量技术，从ROV视频中估计海底物体的六自由度姿态和周围海底的方位，从而推断埋藏深度。该方法实现了约10厘米的平均埋藏深度误差，并能解析反映沉积物输运过程的空间埋藏模式。

**AI_Comments:** 这项工作通过结合前沿的深度基础模型和多视图摄影测量技术，为水下物体埋藏深度估计提供了一个创新的解决方案。其亮点在于能够从低质量的ROV视频中推断出精确的六自由度姿态和埋藏深度，并且在实际场景中验证了其有效性（平均误差10厘米）。这种非侵入式、可扩展的测绘方法对于海洋环境监测和污染场地管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 海底人为物体埋藏状态的准确估计对于了解局部沉积动力学、评估生态风险、潜在污染物输运以及有害物质（如弹药）的回收或缓解策略的可行性至关重要。然而，由于部分遮挡、能见度差和物体降解，通过遥感图像准确估计埋藏深度仍然很困难。

**Method:** 本文引入了一种名为PoseIDON的计算机视觉流程，该流程将深度基础模型特征与多视图摄影测量相结合，用于从ROV视频中估计物体的六自由度姿态和周围海底的方位。通过将物体的CAD模型与观测图像对齐，并拟合海底的局部平面近似来推断埋藏深度。

**Result:** 该模型在圣佩德罗盆地历史海洋倾倒场记录的54个物体（包括桶和弹药）的视频片段上进行了验证。该模型实现了约10厘米的平均埋藏深度误差，并解析了反映底层沉积物输运过程的空间埋藏模式。

**Conclusion:** 该方法实现了海底埋藏的可扩展、非侵入式测绘，并支持对受污染场地的环境评估。

> **ai_Abstract:** 本文提出了一种名为PoseIDON的计算机视觉管道，旨在解决海底人为物体埋藏深度估计的难题。该方法通过结合深度基础模型特征和多视图摄影测量技术，从ROV视频中精确估计物体的六自由度姿态和周围海底的方位。通过将CAD模型与观测图像对齐并拟合局部海底平面，系统能够推断出埋藏深度。实验结果表明，该模型在实际海洋倾倒场数据上实现了约10厘米的平均埋藏深度误差，并能有效揭示与沉积物输运相关的空间埋藏模式。此方法为海底埋藏物的非侵入式、可扩展测绘提供了有效工具，有助于污染场地的环境评估。

> **摘要翻译:** 海底人为物体的埋藏状态提供了对局部沉积动力学的深入了解，对于评估生态风险、潜在污染物输运以及弹药等有害物质的回收或缓解策略的可行性也至关重要。由于部分遮挡、能见度差和物体降解，通过遥感图像准确估计准确的埋藏深度仍然很困难。这项工作引入了一个名为PoseIDON的计算机视觉流程，它结合了深度基础模型特征与多视图摄影测量，以从ROV视频中估计六自由度物体姿态和周围海底的方位。埋藏深度通过将物体的CAD模型与观测图像对齐，并拟合海底的局部平面近似来推断。该方法使用在圣佩德罗盆地一个历史海洋倾倒场记录的54个物体（包括桶和弹药）的视频片段进行了验证。该模型实现了大约10厘米的平均埋藏深度误差，并解析了反映底层沉积物输运过程的空间埋藏模式。这种方法实现了海底埋藏的可扩展、非侵入式测绘，并支持对受污染场地的环境评估。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [DART: Differentiable Dynamic Adaptive Region Tokenizer for Vision Transformer and Mamba](https://arxiv.org/abs/2506.10390)
> *DART：用于视觉Transformer和Mamba的可微分动态自适应区域分词器*

*Shicheng Yin, Kaixuan Yin, Yang Liu, Weixing Chen, Liang Lin* | **Main category: cs.CV**

**Keywords:** DART, 视觉Transformer, Mamba, 自适应分词, 图像表示

**Comment:** Code is available at https://github.com/HCPLab-SYSU/DART

> **TL;DR:** DART是一种新的可微分自适应区域分词器，它能根据图像内容动态调整分词大小，有效解决了现有视觉模型中固定大小分块导致的问题，提高了准确性并降低了计算成本。

**AI_Comments:** DART的创新点在于其可微分的动态自适应区域分词机制，这使得模型能够智能地关注图像中的重要区域，避免了固定分块的局限性。这种方法不仅提升了准确性，还显著降低了计算成本，为视觉Transformer和Mamba的效率优化提供了有价值的解决方案。其通用性体现在对多种非卷积模型的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉Transformer和Mamba模型依赖固定大小的分块，这导致背景区域编码过多，并遗漏了关键的局部细节，尤其是在信息丰富的对象稀疏分布时。

**Method:** 本文引入了一种完全可微分的动态自适应区域分词器（DART），它能够自适应地将图像划分为内容依赖的、大小可变的图像块。DART结合了可学习的区域分数和分段可微分的分位数操作，将更密集的token分配给信息丰富的区域。

**Result:** DART仅增加了约100万额外参数，却在DeiT（ImageNet-1K）上将准确率提高了2.1%。与那些统一增加token密度以捕获细粒度细节的方法不同，DART提供了一种更高效的替代方案，在性能更优的同时实现了45%的FLOPs降低。在DeiT、Vim和VideoMamba上的广泛实验证实，DART在提高准确性的同时，计算开销极小甚至有所降低。

**Conclusion:** DART通过动态自适应区域分词，有效解决了现有视觉模型固定分块的缺陷，显著提升了模型性能并优化了计算效率，是视觉Transformer和Mamba的有效改进方案。

> **ai_Abstract:** 本文提出了一种名为DART的可微分动态自适应区域分词器，旨在解决现有视觉Transformer和Mamba模型中固定大小图像块导致的冗余编码和细节丢失问题。DART能够根据图像内容自适应地划分不同大小的区域，并通过将更多token分配给信息密集区域来优化表示。实验证明，DART在仅增加少量参数的情况下，显著提升了DeiT等模型的准确率，并实现了计算效率的提升（例如FLOPs降低45%），验证了其在视觉任务中的有效性和高效性。

> **摘要翻译:** 近年来，视觉Transformer（ViT）和视觉Mamba（Vim）等非卷积模型在计算机视觉任务中取得了显著性能。然而，它们对固定大小图像块的依赖常常导致背景区域的过度编码以及关键局部细节的遗漏，尤其是在信息丰富的对象稀疏分布时。为解决此问题，我们引入了一种完全可微分的动态自适应区域分词器（DART），它能自适应地将图像划分为内容依赖的、大小可变的图像块。DART结合了可学习的区域分数和分段可微分的分位数操作，将更密集的token分配给信息丰富的区域。尽管仅引入了大约100万（1M）额外参数，DART在DeiT（ImageNet-1K）上的准确率提高了2.1%。与那些统一增加token密度以捕获细粒度细节的方法不同，DART提供了一种更高效的替代方案，在性能更优的同时实现了45%的FLOPs降低。在DeiT、Vim和VideoMamba上的广泛实验证实，DART在提高准确性的同时，计算开销极小甚至有所降低。代码可在https://github.com/HCPLab-SYSU/DART获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [397] [ReconMOST: Multi-Layer Sea Temperature Reconstruction with Observations-Guided Diffusion](https://arxiv.org/abs/2506.10391)
> *ReconMOST：基于观测引导扩散的多层海温重建*

*Yuanyi Song, Pumeng Lyu, Ben Fei, Fenghua Ling, Wanli Ouyang, Lei Bai* | **Main category: cs.CV**

**Keywords:** 海温重建, 扩散模型, 观测引导, 多层, 缺失数据

**Comment:** 

> **TL;DR:** ReconMOST提出一种观测引导的扩散模型，用于多层海温重建，解决了稀疏数据和传统ML方法局限性，实现了高精度、物理一致的全球多层重建。

**AI_Comments:** 这篇论文通过引入观测引导的扩散模型，创新性地解决了多层海温重建中数据稀疏和物理一致性难题。其将扩散模型应用于地球科学领域，并结合物理先验知识进行预训练，再通过观测数据进行引导，有效克服了传统ML方法在处理大范围、多层数据时的局限性。处理高达92.5%的缺失数据能力和良好的泛化性是其重要亮点，对全球气候研究和海洋气象预报具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确的海洋重建对反映全球气候动态和支持海洋气象研究至关重要。传统方法面临数据稀疏、算法复杂、计算成本高的问题。现有机器学习方法局限于海表和局部区域，且受云遮挡等问题困扰。

**Method:** 论文提出ReconMOST，一个数据驱动的引导扩散模型框架。首先，使用大量历史数值模拟数据预训练一个无条件扩散模型，使其学习到物理一致的海洋温度场分布模式。在生成阶段，利用稀疏但高精度的原位观测数据作为反向扩散过程的引导点，生成准确的重建结果。在缺乏直接观测数据的区域，预训练学到的物理一致空间分布模式能够隐式引导并实现物理上合理的重建。

**Result:** 该方法将基于机器学习的海表温度重建扩展到全球、多层设置，在保持重建精度、空间分辨率和优异泛化能力的同时，处理了超过92.5%的缺失数据。模型在CMIP6数值模拟数据上进行预训练，并在CMIP6和EN4分析数据上进行了引导重建实验。均方误差（MSE）值在引导上达到0.049，重建上达到0.680，总计达到0.633，证明了所提框架的有效性和鲁棒性。

**Conclusion:** ReconMOST框架能够有效且鲁棒地实现全球多层海温重建，克服了传统方法和现有ML方法的局限性，并处理了大量的缺失数据，同时保持了高精度和物理一致性。

> **ai_Abstract:** 本文提出了ReconMOST，一个基于观测引导扩散的数据驱动模型框架，旨在解决传统方法和现有机器学习方法在海洋温度重建中面临的数据稀疏、计算复杂和区域局限性等挑战。ReconMOST通过预训练无条件扩散模型学习物理一致的温度场分布，并利用稀疏高精度观测数据引导反向扩散过程，实现了全球、多层海温的高精度重建。该方法能够处理超过92.5%的缺失数据，并在实验中展现出优异的重建精度、空间分辨率和泛化能力。

> **摘要翻译:** 准确的海洋重建对于反映全球气候动态和支持海洋气象研究至关重要。传统方法面临数据稀疏、算法复杂和计算成本高昂的挑战，而机器学习（ML）方法的日益使用仍局限于海表和局部区域的重建问题，并受云遮挡等问题困扰。为解决这些局限性，本文提出了ReconMOST，一个数据驱动的引导扩散模型框架，用于多层海温重建。具体而言，我们首先使用大量历史数值模拟数据预训练一个无条件扩散模型，使模型能够获得海洋温度场物理一致的分布模式。在生成阶段，利用稀疏但高精度的原位观测数据作为反向扩散过程的引导点，生成准确的重建结果。重要的是，在缺乏直接观测数据的区域，预训练学到的物理一致空间分布模式能够实现隐式引导和物理上合理的重建。我们的方法将基于机器学习的海表温度重建扩展到全球、多层设置，在保持重建精度、空间分辨率和优异泛化能力的同时，处理了超过92.5%的缺失数据。我们在CMIP6数值模拟数据上预训练了我们的模型，并在CMIP6和EN4分析数据上进行了引导重建实验。均方误差（MSE）值在引导上分别达到0.049，在重建上达到0.680，总计达到0.633，证明了所提框架的有效性和鲁棒性。我们的源代码可在https://github.com/norsheep/ReconMOST 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [400] [Pisces: An Auto-regressive Foundation Model for Image Understanding and Generation](https://arxiv.org/abs/2506.10395)
> *Pisces：一种用于图像理解和生成的自回归基础模型*

*Zhiyang Xu, Jiuhai Chen, Zhaojiang Lin, Xichen Pan, Lifu Huang, Tianyi Zhou, Madian Khabsa, Qifan Wang, Di Jin, Michihiro Yasunaga, Lili Yu, Xi Victoria Lin, Shaoliang Nie* | **Main category: cs.CV**

**Keywords:** 自回归模型, 多模态基础模型, 图像理解, 图像生成, 解耦视觉编码

**Comment:** Unified image understanding and generation model

> **TL;DR:** Pisces是一个自回归多模态基础模型，通过解耦视觉编码和定制训练，在图像理解和生成任务上均达到有竞争力的性能。

**AI_Comments:** 这项工作通过引入解耦视觉编码架构和定制训练技术，有效解决了统一多模态模型在图像理解和生成任务上性能不足的挑战。其创新之处在于认识到两类任务对视觉特征的不同需求，并提出相应的解决方案，这对于推动统一多模态模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有统一多模态模型在图像理解和生成任务上的表现通常不如专门模型，主要挑战在于两任务对视觉特征和训练过程的不同需求。

**Method:** 引入Pisces，一个自回归多模态基础模型，采用新颖的解耦视觉编码架构和为多模态生成优化的定制训练技术。结合精心的数据整理、预训练和微调。

**Result:** Pisces在20多个图像理解公开基准测试中表现出色，并在GenEval图像生成基准测试中展现出强大的生成能力，在两项任务上均达到有竞争力的性能。

**Conclusion:** 图像理解和生成之间存在协同关系，使用单独的视觉编码器是有益的，这推动了统一多模态模型领域的发展。

> **ai_Abstract:** Pisces是一个自回归多模态基础模型，旨在解决现有统一模型在图像理解和生成方面表现不佳的问题。它通过采用解耦视觉编码架构和定制训练技术，并在大量基准测试中验证，实现了在两类任务上的竞争力表现，并揭示了图像理解与生成之间的协同效应以及独立视觉编码器的优势。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展使得多模态基础模型能够在统一框架内处理图像理解和生成任务。尽管取得了这些进步，但统一模型在任一任务上的表现往往不如专门模型。开发统一模型的一个关键挑战在于图像理解和生成所需的视觉特征之间存在固有的差异，以及每种模态所需的独特训练过程。
在这项工作中，我们引入了Pisces，一个自回归多模态基础模型，它通过一种新颖的解耦视觉编码架构和为多模态生成优化的定制训练技术来解决这一挑战。结合精心的数据整理、预训练和微调，Pisces在图像理解和图像生成方面均取得了有竞争力的性能。
我们在超过20个用于图像理解的公共基准测试中评估了Pisces，它在广泛的任务中表现出强大的性能。此外，在广泛采用的图像生成基准GenEval上，Pisces展现出强大的生成能力。我们广泛的分析揭示了图像理解和生成之间的协同关系，以及使用单独视觉编码器的好处，从而推动了统一多模态模型领域的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [It's Not the Target, It's the Background: Rethinking Infrared Small Target Detection via Deep Patch-Free Low-Rank Representations](https://arxiv.org/abs/2506.10425)
> *不是目标，而是背景：通过深度无块低秩表示重新思考红外小目标检测*

*Guoyi Zhang, Guangsheng Xu, Siyang Chen, Han Wang, Xiaohu Zhang* | **Main category: cs.CV**

**Keywords:** 红外小目标检测, 低秩表示, 深度学习, 背景建模, 实时检测

**Comment:** 

> **TL;DR:** 本文提出了一种名为LRRNet的端到端深度学习框架，利用红外图像背景的低秩特性，在不依赖块处理或显式矩阵分解的情况下，实现了对红外小目标的高效、鲁棒和实时的检测。

**AI_Comments:** 该论文的创新点在于首次将深度学习与红外图像背景的低秩特性相结合，并提出了一种新颖的无块、端到端学习低秩背景结构的方法。这种方法避免了传统低秩分解的复杂性，并有效解决了小目标检测中背景建模的难题。其在实时性、精度和鲁棒性上的显著提升，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 红外小目标检测（IRSTD）在复杂背景下由于信杂比低、目标形态多样以及缺乏独特的视觉线索而面临长期挑战。现有的深度学习方法虽然旨在学习判别性表示，但小目标的内在变异性和弱先验往往导致性能不稳定。

**Method:** 本文提出了一种名为LRRNet的端到端IRSTD框架，利用红外图像背景的低秩特性。该方法采用压缩-重建-减法（CRS）范式，直接在图像域中建模结构感知的低秩背景表示，不依赖于基于块的处理或显式矩阵分解。这是首次通过深度神经网络以端到端方式直接学习低秩背景结构。

**Result:** LRRNet在多个公共数据集上优于38种最先进的方法，在检测精度、鲁棒性和计算效率方面表现出色。它实现了实时性能，平均速度达到82.34 FPS。在具有挑战性的NoisySIRST数据集上的评估进一步证实了模型对传感器噪声的弹性。

**Conclusion:** LRRNet通过利用红外图像背景的低秩特性，并采用创新的压缩-重建-减法范式，有效解决了红外小目标检测的挑战，并在多个方面超越了现有技术，实现了实时、高精度和鲁棒的检测。

> **ai_Abstract:** 本文提出LRRNet，一个新颖的端到端红外小目标检测框架。该框架利用红外背景的低秩特性，通过压缩-重建-减法（CRS）范式直接学习结构感知的低秩背景表示，无需传统块处理。实验证明，LRRNet在检测精度、鲁棒性和计算效率上超越了38种SOTA方法，并能实现实时检测（82.34 FPS），对传感器噪声也表现出良好弹性。

> **摘要翻译:** 红外小目标检测（IRSTD）由于信杂比（SCR）低、目标形态多样以及缺乏独特的视觉线索，在复杂背景下仍然是一个长期存在的挑战。尽管最近的深度学习方法旨在学习判别性表示，但小目标的内在变异性和弱先验往往导致性能不稳定。在本文中，我们提出了一种新颖的端到端IRSTD框架，命名为LRRNet，它利用了红外图像背景的低秩特性。受杂乱场景物理可压缩性的启发，我们的方法采用了一种压缩-重建-减法（CRS）范式，直接在图像域中建模结构感知的低秩背景表示，而无需依赖基于块的处理或显式矩阵分解。据我们所知，这是首次通过深度神经网络以端到端方式直接学习低秩背景结构。在多个公共数据集上进行的大量实验表明，LRRNet在检测精度、鲁棒性和计算效率方面优于38种最先进的方法。值得注意的是，它实现了实时性能，平均速度达到82.34 FPS。对具有挑战性的NoisySIRST数据集的评估进一步证实了模型对传感器噪声的弹性。源代码将在接受后公开提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [406] [Unsourced Adversarial CAPTCHA: A Bi-Phase Adversarial CAPTCHA Framework](https://arxiv.org/abs/2506.10685)
> *无源对抗性验证码：一种双阶段对抗性验证码框架*

*Xia Du, Xiaoyuan Liu, Jizhe Zhou, Zheng Lin, Chi-man Pun, Zhe Chen, Wei Ni, Jun Luo* | **Main category: cs.CV**

**Keywords:** 对抗性验证码, 深度学习攻击, 大型语言模型, 扩散模型, 黑盒攻击

**Comment:** 

> **TL;DR:** 提出了一种名为UAC的新型验证码框架，它能生成高质量的对抗性验证码，以抵御深度学习攻击，并支持有目标和无目标的攻击。

**AI_Comments:** 该论文提出了一种创新的“无源”对抗性验证码生成方法，解决了传统对抗性攻击依赖原始图像和导致图像失真的问题。其结合LLM和扩散模型生成高保真、难以区分的对抗性示例，特别是在黑盒无目标攻击中引入的BP-UAC策略，具有重要的理论和实际意义，为提升验证码的安全性提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的验证码方案在深度学习的快速发展下，越来越容易受到深度神经网络（DNNs）驱动的自动化攻击。现有对抗性攻击方法依赖原始图像特征，导致图像失真，阻碍人类识别，且在缺乏初始输入图像的场景中应用受限。

**Method:** 我们提出了无源对抗性验证码（UAC），一个通过攻击者指定文本提示生成高保真对抗性示例的新颖框架。UAC利用大型语言模型（LLM）增强验证码多样性，并支持有目标和无目标的攻击。对于有目标攻击，EDICT方法优化扩散模型中的双重潜在变量以获得卓越的图像质量。在无目标攻击中，特别是针对黑盒场景，我们引入了双路径无源对抗性验证码（BP-UAC），这是一种采用多模态梯度和双路径优化的两步优化策略，以实现高效的错误分类。

**Result:** 实验表明，BP-UAC在各种系统中均实现了高攻击成功率，生成了人类和DNN都无法区分的自然验证码。

**Conclusion:** UAC框架，特别是BP-UAC，能够生成高质量、难以区分的对抗性验证码，有效抵御深度学习攻击，解决了现有方法在图像质量和应用场景上的限制。

> **ai_Abstract:** 本文提出了无源对抗性验证码（UAC），一个旨在应对深度学习对传统验证码攻击的新型框架。UAC利用大型语言模型和攻击者指定的文本提示生成高保真对抗性验证码。它支持有目标攻击（通过EDICT方法优化扩散模型）和无目标攻击（通过双路径无源对抗性验证码BP-UAC）。BP-UAC采用多模态梯度和双路径优化策略，在实验中表现出高攻击成功率，并能生成人类和DNN都难以区分的自然验证码，有效解决了现有方法的局限性。

> **摘要翻译:** 随着深度学习的快速发展，传统的验证码方案越来越容易受到深度神经网络（DNNs）驱动的自动化攻击。现有对抗性攻击方法通常依赖原始图像特征，导致图像失真，阻碍人类识别，并限制了在缺乏初始输入图像场景中的适用性。为了解决这些挑战，我们提出了无源对抗性验证码（UAC），这是一种通过攻击者指定文本提示生成高保真对抗性示例的新颖框架。UAC利用大型语言模型（LLM）增强验证码多样性，并支持有目标和无目标的攻击。对于有目标攻击，EDICT方法优化扩散模型中的双重潜在变量，以获得卓越的图像质量。在无目标攻击中，特别是针对黑盒场景，我们引入了双路径无源对抗性验证码（BP-UAC），这是一种采用多模态梯度和双路径优化的两步优化策略，以实现高效的错误分类。实验表明，BP-UAC在各种系统中均实现了高攻击成功率，生成了人类和DNN都无法区分的自然验证码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [410] [MF2Summ: Multimodal Fusion for Video Summarization with Temporal Alignment](https://arxiv.org/abs/2506.10430)
> *MF2Summ：基于时间对齐的多模态融合视频摘要*

*Shuo wang, Jihao Zhang* | **Main category: cs.CV**

**Keywords:** 视频摘要, 多模态融合, 时间对齐, Transformer, MF2Summ

**Comment:** 

> **TL;DR:** MF2Summ是一个新的视频摘要模型，它通过融合视觉和听觉信息来解决传统单模态方法的不足，并在两个数据集上取得了竞争性的SOTA性能。

**AI_Comments:** MF2Summ的创新点在于其多模态融合策略，特别是使用了跨模态Transformer和对齐引导的自注意力Transformer来有效处理不同模态数据间的依赖和时间对应关系。这对于捕捉视频的深层语义至关重要，是其优于传统单模态方法的关键。该研究的重要性在于推动了视频摘要领域向更全面、更智能的方向发展。

<details>
  <summary>Details</summary>

**Motivation:** 在线视频内容的迅速增长，需要有效的视频摘要技术。传统方法通常依赖单一模态（主要是视觉），难以捕捉视频的全部语义丰富性。

**Method:** MF2Summ采用五阶段流程：特征提取（GoogLeNet用于视觉，SoundNet用于听觉）、跨模态注意力交互、特征融合（使用跨模态Transformer和对齐引导的自注意力Transformer）、片段预测（重要性、位置和中心性）和关键镜头选择（使用NMS和KTS算法）。

**Result:** 在SumMe和TVSum数据集上，MF2Summ的F1分数分别比DSNet模型提高了1.9%和0.6%，并且优于其他SOTA方法。

**Conclusion:** MF2Summ通过有效融合视觉和听觉信息，显著提升了视频摘要的性能，证明了多模态内容理解在视频摘要中的优越性。

> **ai_Abstract:** MF2Summ是一个创新的视频摘要模型，通过融合视觉和听觉多模态信息，克服了传统单模态方法的局限性。该模型采用五阶段处理流程，包括特征提取、跨模态交互、特征融合（利用Transformer结构进行模态间依赖和时间对齐）、片段预测和关键镜头选择。实验证明，MF2Summ在SumMe和TVSum数据集上取得了优于现有先进方法的性能，显著提升了F1分数。

> **摘要翻译:** 在线视频内容的迅速增长，使得有效的视频摘要技术成为必需。传统方法通常依赖单一模态（通常是视觉），难以捕捉视频的全部语义丰富性。本文介绍了MF2Summ，这是一种基于多模态内容理解的新型视频摘要模型，它整合了视觉和听觉信息。MF2Summ采用五阶段流程：特征提取、跨模态注意力交互、特征融合、片段预测和关键镜头选择。视觉特征使用预训练的GoogLeNet模型提取，而听觉特征则使用SoundNet获取。我们融合机制的核心包括一个跨模态Transformer和一个对齐引导的自注意力Transformer，旨在有效建模模态间依赖和时间对应关系。模型预测片段的重要性、位置和中心性，然后使用非极大值抑制（NMS）和核时间分割（KTS）算法选择关键镜头。在SumMe和TVSum数据集上的实验结果表明，MF2Summ取得了竞争性的性能，F1分数分别比DSNet模型显著提高了1.9%和0.6%，并且与其他最先进的方法相比表现出色。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [414] [Towards Robust Multimodal Emotion Recognition under Missing Modalities and Distribution Shifts](https://arxiv.org/abs/2506.10452)
> *面向模态缺失和分布偏移的鲁棒多模态情感识别*

*Guowei Zhong, Ruohong Huan, Mingzhen Wu, Ronghua Liang, Peng Chen* | **Main category: cs.CV**

**Keywords:** 多模态情感识别, 模态缺失, 分布偏移, 因果推理, 自蒸馏

**Comment:** Submitted to TAC. The code is available at
  https://github.com/gw-zhong/CIDer

> **TL;DR:** 本文提出了一种名为CIDer的新型鲁棒多模态情感识别框架，通过自蒸馏和因果推理模块，有效应对模态缺失和域外数据挑战，且参数更少，训练更快。

**AI_Comments:** 该论文的创新点在于提出了一个统一的框架CIDer，同时解决了多模态情感识别中长期存在的模态缺失和域外泛化两大难题。特别是引入随机模态特征缺失（RMFM）任务和结合自蒸馏与因果推理模块的设计，展示了其方法的通用性和高效性。MACI模块通过因果推断独立提升OOD泛化能力，且额外参数极少，这对于实际应用具有重要意义。此外，引入新的OOD数据集也促进了该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 多模态情感识别（MER）在同时处理模态缺失和域外（OOD）数据时面临挑战。现有方法常依赖特定模型或引入过多参数，限制了实用性。

**Method:** 本文提出了一种新颖的鲁棒多模态情感识别框架——因果推理蒸馏器（CIDer），并引入了随机模态特征缺失（RMFM）新任务。CIDer包含两个关键组件：模型特定自蒸馏（MSSD）模块和模型无关因果推理（MACI）模块。MSSD通过权重共享自蒸馏增强RMFM任务下的鲁棒性，并引入词级自对齐注意力模块（WSAM）和多模态复合Transformer（MCT）。MACI采用定制的因果图，利用多模态因果模块（MCM）和细粒度反事实文本来缓解标签和语言偏差，以解决OOD挑战。此外，本文还引入了新的重新划分的MER OOD数据集。

**Result:** 实验结果表明，与现有最先进方法相比，CIDer在RMFM和OOD场景下均实现了鲁棒性能，且参数更少，训练速度更快。

**Conclusion:** CIDer框架成功地在模态缺失和分布偏移场景下实现了鲁棒的多模态情感识别，且具有更高的效率和更少的参数。

> **ai_Abstract:** 本文提出了一种名为因果推理蒸馏器（CIDer）的新型鲁棒多模态情感识别框架，旨在同时解决模态缺失和域外（OOD）数据问题。CIDer包含模型特定自蒸馏（MSSD）模块，通过自蒸馏和高效融合模块（WSAM、MCT）增强模态缺失下的鲁棒性；以及模型无关因果推理（MACI）模块，利用因果图和反事实文本缓解OOD场景中的偏差。实验证明，CIDer在处理这两种挑战方面表现出卓越的鲁棒性，同时显著减少了参数量并加快了训练速度。

> **摘要翻译:** 多模态情感识别（MER）的最新进展在同时处理模态缺失和域外（OOD）数据方面面临挑战。现有方法通常依赖特定模型或引入过多参数，这限制了它们的实用性。为了解决这些问题，我们提出了一种新颖的鲁棒MER框架——因果推理蒸馏器（CIDer），并引入了一个新任务——随机模态特征缺失（RMFM），以泛化模态缺失的定义。CIDer集成了两个关键组件：模型特定自蒸馏（MSSD）模块和模型无关因果推理（MACI）模块。MSSD通过应用于低级特征、注意力图和高级表示的权重共享自蒸馏方法，增强了RMFM任务下的鲁棒性。此外，词级自对齐注意力模块（WSAM）降低了计算复杂度，而多模态复合Transformer（MCT）促进了高效的多模态融合。为了解决OOD挑战，MACI采用定制的因果图，利用多模态因果模块（MCM）和细粒度反事实文本来缓解标签和语言偏差。值得注意的是，MACI可以独立地增强OOD泛化能力，且只需极少的额外参数。此外，我们还引入了新的重新划分的MER OOD数据集。实验结果表明，与现有最先进方法相比，CIDer在RMFM和OOD场景下均实现了鲁棒性能，且参数更少，训练速度更快。本工作的实现已在https://github.com/gw-zhong/CIDer上公开访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [MedSeg-R: Reasoning Segmentation in Medical Images with Multimodal Large Language Models](https://arxiv.org/abs/2506.10465)
> *MedSeg-R：基于多模态大语言模型的医学图像推理分割*

*Yu Huang, Zelin Peng, Yichen Zhao, Piao Yang, Xiaokang Yang, Wei Shen* | **Main category: cs.CV**

**Keywords:** 医学图像分割, 多模态大语言模型, 推理分割, MedSeg-R, MedSeg-QA

**Comment:** {\dag}: Equal contribution

> **TL;DR:** MedSeg-R提出了一种新的医学图像推理分割任务，并开发了一个端到端框架MedSeg-R，利用多模态大语言模型（MLLMs）的推理能力，根据复杂指令生成精确的医学图像分割掩模，并引入了大型数据集MedSeg-QA，实验证明其性能优越。

**AI_Comments:** 这篇论文的创新之处在于提出了“医学图像推理分割”这一新颖任务，解决了现有医学图像分割模型在处理复杂、隐含指令和缺乏主动推理能力方面的局限性。MedSeg-R框架结合了MLLMs的强大推理能力与精确像素级分割，具有重要的实践意义。此外，构建大规模、高质量的MedSeg-QA数据集对于推动该领域的研究具有里程碑意义。该研究有望显著提升自动化医学诊断的准确性和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 现有医学图像分割模型受限于对明确人工指令的依赖，缺乏理解复杂临床问题的主动推理能力，且大多数多模态大语言模型（MLLMs）在医学问答任务中难以生成精确的分割掩模，限制了其在自动化医学诊断中的应用。

**Method:** 本文提出了医学图像推理分割这一新任务，并引入了MedSeg-R，一个端到端框架。MedSeg-R包含两个核心组件：1) 一个全局上下文理解模块，用于解释图像和理解复杂医学指令以生成多模态中间令牌；2) 一个像素级接地模块，用于解码这些令牌以生成精确的分割掩模和文本响应。此外，本文还引入了一个大型数据集MedSeg-QA，包含超过10,000个图像-掩模对和多轮对话，通过大语言模型自动标注并经医生审核。

**Result:** 实验表明，MedSeg-R在多个基准测试中表现出色，实现了高分割精度，并能够对医学图像进行可解释的文本分析。

**Conclusion:** MedSeg-R成功地将多模态大语言模型的推理能力与精确的医学图像分割相结合，解决了现有模型在处理复杂和隐含医学指令方面的局限性，并通过引入新任务和数据集推动了医学图像推理分割领域的发展。

> **ai_Abstract:** 本文提出了一项名为“医学图像推理分割”的新任务，旨在根据复杂和隐含的医学指令生成精确的分割掩模。为应对此挑战，研究人员开发了MedSeg-R框架，该框架利用多模态大语言模型（MLLMs）的推理能力来解释临床问题，并通过全局上下文理解和像素级接地模块生成高精度的分割掩模和文本响应。同时，论文还构建了一个大型数据集MedSeg-QA，包含万余对图像-掩模和多轮对话。实验结果验证了MedSeg-R在多个基准上的优越性能，实现了高分割精度和可解释的文本分析。

> **摘要翻译:** 医学图像分割对临床诊断至关重要，然而现有模型受限于对明确人工指令的依赖，且缺乏理解复杂临床问题的主动推理能力。尽管多模态大语言模型（MLLMs）的最新进展改善了医学问答（QA）任务，但大多数方法难以生成精确的分割掩模，限制了它们在自动化医学诊断中的应用。在本文中，我们引入了医学图像推理分割，这是一项旨在根据复杂和隐含的医学指令生成分割掩模的新任务。为解决此问题，我们提出了MedSeg-R，一个端到端框架，它利用多模态大语言模型的推理能力来解释临床问题，同时能够为医学图像生成相应的精确分割掩模。它建立在两个核心组件之上：1）一个全局上下文理解模块，用于解释图像并理解复杂的医学指令以生成多模态中间令牌；2）一个像素级接地模块，用于解码这些令牌以生成精确的分割掩模和文本响应。此外，我们引入了MedSeg-QA，一个为医学图像推理分割任务量身定制的大型数据集。它包括超过10,000个图像-掩模对和多轮对话，通过大语言模型自动标注并经医生审核。实验表明，MedSeg-R在多个基准测试中表现出色，实现了高分割精度，并能够对医学图像进行可解释的文本分析。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [LLMs Are Not Yet Ready for Deepfake Image Detection](https://arxiv.org/abs/2506.10474)
> *大型语言模型尚未准备好用于深度伪造图像检测*

*Shahroz Tariq, David Nguyen, M. A. P. Chamikara, Tingmin Wu, Alsharif Abuadbba, Kristen Moore* | **Main category: cs.CV**

**Keywords:** 深度伪造检测, 视觉语言模型, 零样本评估, 大语言模型, 可解释性

**Comment:** 6 pages, 3 figures, and 2 tables. paper is under review

> **TL;DR:** 本研究评估了大型视觉语言模型在深度伪造图像检测方面的能力，发现它们虽然能提供解释并检测表面异常，但作为独立的检测系统尚不可靠，不过在混合或人机协作框架中仍有潜力。

**AI_Comments:** 这篇论文通过对主流VLM进行严格的零样本评估，揭示了当前大型模型在深度伪造检测领域的局限性，特别是在自主检测方面的不足。其创新之处在于指出了VLM的关键失败模式，并强调了其在可解释性和辅助人类专家方面的潜力，为未来深度伪造检测系统的发展提供了宝贵的见解，即可能需要结合人类专业知识或采用混合模型。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造技术的日益复杂对媒体的完整性和公众信任构成了巨大挑战。同时，视觉语言模型（VLMs）作为强大的工具在各个领域崭露头角，引发了人们对其在深度伪造检测中应用潜力的兴趣。

**Method:** 本研究对ChatGPT、Claude、Gemini和Grok这四个主流VLM进行了结构化的零样本评估，重点关注人脸替换、重演和合成生成这三种主要的深度伪造类型。研究利用精心构建的基准数据集（包含来自不同来源的真实和篡改图像），评估了每个模型的分类准确性和推理深度。

**Result:** 分析表明，尽管VLM能够生成连贯的解释并检测表面异常，但它们作为独立的检测系统尚不可靠。研究发现了一些关键的失败模式，例如过度强调风格元素以及容易受到误导性视觉模式（如复古美学）的影响。然而，VLM在可解释性和上下文分析方面表现出优势。

**Conclusion:** 这些见解表明，尽管通用模型目前缺乏自主深度伪造检测所需的可靠性，但它们有望成为混合或人机协作检测框架中不可或缺的组成部分。

> **ai_Abstract:** 本研究评估了ChatGPT、Claude、Gemini和Grok等大型视觉语言模型（VLM）在零样本深度伪造图像检测中的能力。结果显示，尽管VLM能提供解释并识别表面异常，但它们作为独立的检测系统并不可靠，存在过度关注风格等失败模式。然而，VLM在可解释性和上下文分析方面的优势表明它们未来可作为混合或人机协作检测框架中的辅助工具。

> **摘要翻译:** 深度伪造技术的日益复杂对媒体的完整性和公众信任构成了巨大挑战。与此同时，结合了视觉推理能力的大型语言模型（VLM）已成为各个领域中前景广阔的工具，引发了人们对其在深度伪造检测中应用潜力的兴趣。本研究对ChatGPT、Claude、Gemini和Grok这四个主流VLM进行了结构化的零样本评估，重点关注人脸替换、重演和合成生成这三种主要的深度伪造类型。我们利用精心构建的基准数据集，该数据集包含来自不同来源的真实和篡改图像，评估了每个模型的分类准确性和推理深度。我们的分析表明，尽管VLM能够生成连贯的解释并检测表面异常，但它们作为独立的检测系统尚不可靠。我们强调了关键的失败模式，例如过度强调风格元素以及容易受到误导性视觉模式（如复古美学）的影响。然而，VLM在可解释性和上下文分析方面表现出优势，这表明它们有潜力增强法医工作流程中的人类专业知识。这些见解意味着，尽管通用模型目前缺乏自主深度伪造检测所需的可靠性，但它们有望成为混合或人机协作检测框架中不可或缺的组成部分。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [431] [Class-Incremental Learning for Honey Botanical Origin Classification with Hyperspectral Images: A Study with Continual Backpropagation](https://arxiv.org/abs/2506.10489)
> *基于高光谱图像的蜂蜜植物来源分类的类增量学习：一项关于持续反向传播的研究*

*Guyang Zhang, Waleed Abdulla* | **Main category: cs.CV**

**Keywords:** 类增量学习, 持续反向传播, 蜂蜜分类, 高光谱图像, 植物来源

**Comment:** 

> **TL;DR:** 本研究探讨了使用类增量学习（CIL）技术对蜂蜜植物来源进行分类，并提出了一种结合持续反向传播（CB）的新方法，通过重新初始化部分隐藏神经元来提高CIL性能，实验表明CB可将大多数CIL方法的性能提高1-7%。

**AI_Comments:** 本文提出了一种新颖的持续反向传播（CB）方法，通过解决神经网络中的可塑性损失问题来提高类增量学习（CIL）的性能。这种方法通过注入变异性来优化现有CIL算法，并在实际应用中（如蜂蜜植物来源分类）显示出其有效性，具有一定的创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 开发准确有效的植物来源识别技术对于保护消费者利益至关重要。然而，一次性收集所有蜂蜜品种来训练模型以区分植物来源是不切实际的，因此需要类增量学习技术来解决这一挑战。

**Method:** 本研究在一个真实的蜂蜜高光谱图像数据集上检查并比较了多种类增量学习（CIL）算法。此外，还提出了一种通过结合持续反向传播（CB）算法来提高类增量学习算法性能的新技术。CB方法通过重新初始化一部分较少使用的隐藏神经元来解决可塑性损失问题，从而向神经网络注入变异性。

**Result:** 实验表明，持续反向传播（CB）将大多数类增量学习（CIL）方法的性能提高了1-7%。

**Conclusion:** 结合持续反向传播（CB）算法可以有效提高基于高光谱图像的蜂蜜植物来源分类中类增量学习（CIL）算法的性能。

> **ai_Abstract:** 本研究探讨了利用高光谱图像对蜂蜜植物来源进行类增量分类。鉴于一次性收集所有蜂蜜品种进行模型训练的不可行性，研究人员提出了结合持续反向传播（CB）算法的新方法，以提升类增量学习（CIL）算法的性能。CB通过重新初始化部分低利用率的隐藏神经元来解决神经网络的可塑性损失问题。在真实蜂蜜高光谱数据集上的实验结果表明，CB能够将大多数CIL方法的性能提高1-7%。

> **摘要翻译:** 蜂蜜是全球市场上的重要商品。不同植物来源的蜂蜜种类提供多样化的风味和健康益处，因此具有不同的市场价值。开发准确有效的植物来源区分技术对于保护消费者利益至关重要。然而，一次性收集所有蜂蜜产品来训练模型进行植物来源区分是不切实际的。因此，研究人员开发了类增量学习（CIL）技术来解决这一挑战。本研究在一个真实的蜂蜜高光谱成像数据集上检查并比较了多种CIL算法。此外，还提出了一种通过结合持续反向传播（CB）算法来提高类增量学习算法性能的新技术。CB方法通过重新初始化一部分较少使用的隐藏神经元来解决可塑性损失问题，从而向神经网络注入变异性。实验表明，CB将大多数CIL方法的性能提高了1-7%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [434] [Semantic Localization Guiding Segment Anything Model For Reference Remote Sensing Image Segmentation](https://arxiv.org/abs/2506.10503)
> *语义定位引导的Segment Anything模型用于参考遥感图像分割*

*Shuyang Li, Shuang Wang, Zhuangzhuang Sun, Jing Xiao* | **Main category: cs.CV**

**Keywords:** 遥感图像分割, SAM, 语义定位, 两阶段, 标注效率

**Comment:** 

> **TL;DR:** 本文提出了PSLG-SAM框架，将参考遥感图像分割(RRSIS)任务分解为粗定位和精细分割两阶段，显著减少了标注负担，并在RRSIS任务上实现了最先进的性能。

**AI_Comments:** 本文提出的PSLG-SAM框架具有显著的创新性，它将RRSIS任务分解为粗定位和精细分割两阶段，并巧妙地利用了SAM模型的强大能力，同时通过免训练的第二阶段设计，极大地缓解了遥感图像分割任务中长期存在的标注数据匮乏问题。这对于实际应用具有重要意义，降低了模型部署和维护的成本。此外，专注于特定区域分割也有效规避了复杂场景的干扰，提升了模型的鲁棒性。贡献高质量数据集也进一步推动了该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 当前参考遥感图像分割（RRSIS）方法面临密集标注要求高和复杂场景解释困难的挑战。

**Method:** 本文提出了PSLG-SAM（prompt-generated semantic localization guiding Segment Anything Model）框架，将RRSIS任务分解为两个阶段：粗定位和精细分割。在粗定位阶段，使用视觉定位网络粗略定位文本描述的对象。在精细分割阶段，第一阶段的坐标引导Segment Anything Model (SAM)，并通过基于聚类的前景点生成器和掩模边界迭代优化策略进行增强，以实现精确分割。值得注意的是，第二阶段可以无需训练，显著减少了标注数据负担。

**Result:** PSLG-SAM在RRSIS-D和RRSIS-M两个数据集上进行了实验验证，结果表明其实现了显著的性能提升，并超越了现有最先进的模型。

**Conclusion:** 本文提出的PSLG-SAM框架通过两阶段方法有效解决了参考遥感图像分割的标注负担和复杂场景干扰问题，并在性能上超越了现有模型。

> **ai_Abstract:** 本文针对参考遥感图像分割（RRSIS）任务中高标注需求和复杂场景干扰问题，提出了一种名为PSLG-SAM（prompt-generated semantic localization guiding Segment Anything Model）的两阶段框架。该框架首先通过视觉定位网络进行粗定位，然后利用定位结果引导Segment Anything Model (SAM) 进行精细分割，并辅以前景点生成和边界优化策略。其创新之处在于第二阶段可实现免训练，大幅减轻了数据标注负担，并能有效避免复杂场景干扰。实验结果表明，PSLG-SAM在RRSIS任务上取得了显著的性能提升，并超越了现有SOTA模型。此外，本文还贡献了一个高质量的多类别标注数据集。

> **摘要翻译:** 参考遥感图像分割 (RRSIS) 任务根据文本描述为图像中指定对象生成分割掩模，这引起了广泛的关注和研究兴趣。当前的RRSIS方法依赖于多模态融合骨干网络和语义分割头部，但面临密集标注要求和复杂场景解释等挑战。为了解决这些问题，我们提出了一个名为prompt-generated semantic localization guiding Segment Anything Model (PSLG-SAM) 的框架，它将RRSIS任务分解为粗定位和精细分割两个阶段。在粗定位阶段，视觉定位网络粗略定位文本描述的对象。在精细分割阶段，第一阶段的坐标引导Segment Anything Model (SAM)，并通过基于聚类的M前景点生成器和掩模边界迭代优化策略进行增强，以实现精确分割。值得注意的是，第二阶段可以无需训练，显著减少了RRSIS任务的标注数据负担。此外，将RRSIS任务分解为两个阶段，可以专注于特定区域分割，避免复杂场景的干扰。我们还贡献了一个高质量、多类别的手动标注数据集。在两个数据集（RRSIS-D和RRSIS-M）上的实验验证表明，PSLG-SAM实现了显著的性能提升，并超越了现有最先进的模型。我们的代码将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [436] [J-DDL: Surface Damage Detection and Localization System for Fighter Aircraft](https://arxiv.org/abs/2506.10505)
> *J-DDL：战斗机表面损伤检测与定位系统*

*Jin Huang, Mingqiang Wei, Zikuan Li, Hangyu Qu, Wei Zhao, Xinyu Bai* | **Main category: cs.CV**

**Keywords:** 表面损伤检测, 3D定位, 战斗机, YOLO, 点云

**Comment:** 

> **TL;DR:** J-DDL是一种用于战斗机表面损伤检测和定位的智能系统，它结合2D图像和3D点云，并基于优化的YOLO网络实现高效、精确的损伤识别和3D定位，旨在解决人工检测的局限性。

**AI_Comments:** 该论文提出了一种创新的战斗机表面损伤检测与定位系统J-DDL，通过融合2D图像和3D点云数据，并优化YOLO架构，显著提升了检测精度和定位能力。其核心创新点在于轻量级Fasternet块、EMA模块以及Inner-CIOU损失函数的引入，这些都有效地提高了模型性能。此外，首次发布飞机损伤公开数据集对该领域未来的研究具有重要推动作用，体现了其对自动化飞机检测技术发展的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 确保战斗机的安全和延长其使用寿命需要频繁且彻底的检查。然而，由于飞机表面积巨大、结构复杂和维护操作需求，人工检测方法在可扩展性、效率和一致性方面存在严重局限性。

**Method:** 本文提出了一个名为J-DDL的战斗机智能表面损伤检测与定位系统。J-DDL通过激光扫描仪和相机组合系统捕获整个飞机表面的2D图像和3D点云，以实现精确的损伤检测和定位。该系统的核心是一个基于YOLO架构的新型损伤检测网络，专门优化用于识别2D飞机图像中的表面缺陷。主要创新包括用于高效特征提取的轻量级Fasternet块、结合高效多尺度注意力（EMA）模块以实现卓越特征聚合的优化颈部架构，以及引入新型损失函数Inner-CIOU以提高检测精度。在2D图像中检测到损伤后，系统将识别出的异常映射到相应的3D点云上，从而实现飞机表面缺陷的精确3D定位。此外，为了促进该领域的进一步发展，研究人员开发了首个专注于飞机损伤的公开数据集。

**Result:** J-DDL系统不仅简化了检测流程，而且确保了对大型复杂飞机外部更全面和详细的覆盖。实验评估验证了该框架的有效性，突显了其在显著推进自动化飞机检测技术方面的潜力。

**Conclusion:** J-DDL框架通过结合2D图像和3D点云，并利用优化的深度学习网络，有效解决了当前战斗机表面人工检测的局限性，其验证的有效性预示着其在自动化飞机检测技术领域具有巨大的进步潜力。

> **ai_Abstract:** J-DDL是一种用于战斗机表面损伤检测和定位的智能系统，旨在克服人工检测的局限性。该系统结合激光扫描仪和相机捕获的2D图像与3D点云，利用基于YOLO架构的深度学习网络进行损伤识别，并引入Fasternet块、EMA模块和Inner-CIOU损失函数进行优化。J-DDL能将2D检测结果映射到3D点云上实现精确三维定位，从而简化并增强了飞机外部检测的全面性。研究还发布了首个飞机损伤公开数据集，实验结果验证了该框架的有效性，展示了其在自动化飞机检测技术中的巨大潜力。

> **摘要翻译:** 确保战斗机的安全和延长其使用寿命需要频繁且彻底的检查。虽然人工检查员可以进行表面缺陷检测，但由于飞机表面积巨大、结构复杂和维护操作需求，人工方法在可扩展性、效率和一致性方面面临严峻挑战。我们提出了一种名为J-DDL的战斗机智能表面损伤检测与定位系统。J-DDL整合了使用激光扫描仪和相机组合系统捕获的整个飞机表面的2D图像和3D点云，以实现精确的损伤检测和定位。我们系统的核心是一个基于YOLO架构的新型损伤检测网络，专门优化用于识别2D飞机图像中的表面缺陷。主要创新包括用于高效特征提取的轻量级Fasternet块、结合高效多尺度注意力（EMA）模块以实现卓越特征聚合的优化颈部架构，以及引入新型损失函数Inner-CIOU以提高检测精度。在2D图像中检测到损伤后，系统将识别出的异常映射到相应的3D点云上，从而实现飞机表面缺陷在整个飞机表面的精确3D定位。我们的J-DDL不仅简化了检测流程，而且确保了对大型复杂飞机外部更全面和详细的覆盖。为了促进该领域的进一步发展，我们开发了首个专注于飞机损伤的公开数据集。实验评估验证了我们框架的有效性，突显了其在显著推进自动化飞机检测技术方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [CogStream: Context-guided Streaming Video Question Answering](https://arxiv.org/abs/2506.10516)
> *CogStream: 上下文引导的流媒体视频问答*

*Zicheng Zhao, Kangyu Wang, Shijie Li, Rui Qian, Weiyao Lin, Huabin Liu* | **Main category: cs.CV**

**Keywords:** 流媒体视频问答, 上下文引导, CogStream, Vid-LLMs, CogReasoner

**Comment:** 

> **TL;DR:** 本文提出了一个名为CogStream的挑战性任务，用于流媒体视频推理，通过半自动管道生成了一个密集标注的数据集，并提出了CogReasoner作为基线模型，有效解决了计算负担和无关上下文的问题。

**AI_Comments:** 这项工作通过引入一个模拟真实世界场景的新任务和数据集，解决了现有Vid-LLMs在处理流媒体视频上下文信息时的计算效率和相关性问题。其创新点在于强调了“上下文引导”的重要性，并提出了一个能有效筛选相关信息的基线模型，这对于未来的流媒体视频理解和问答系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Vid-LLMs在多模态理解方面有所进步，但流媒体视频推理仍面临挑战，因为它依赖上下文信息。现有范式将所有历史上下文信息输入Vid-LLMs，导致视觉数据处理的计算负担沉重，并且包含无关上下文会分散模型对关键细节的注意力。

**Method:** 本文提出了一个名为Context-guided Streaming Video Reasoning (CogStream) 的挑战性任务，模拟真实世界的流媒体视频场景，要求模型识别最相关的历史上下文信息来推断当前流的问题答案。为了支持CogStream，我们提出了一个通过半自动管道生成的大量分层问答对的密集标注数据集。此外，我们提出了CogReasoner作为基线模型，它通过利用视觉流压缩和历史对话检索来高效解决此任务。

**Result:** 广泛的实验证明了该方法的有效性。

**Conclusion:** 本文成功引入了CogStream任务和支持数据集，并提出了一个有效的基线模型CogReasoner，解决了流媒体视频推理中上下文依赖和计算效率的问题。

> **ai_Abstract:** 本文针对流媒体视频推理中上下文信息处理的挑战，提出了一个名为CogStream的新任务，该任务要求模型识别并利用最相关的历史上下文来回答问题。为支持此任务，研究团队构建了一个包含大量分层问答对的密集标注数据集，并提出了一个名为CogReasoner的基线模型，该模型通过视觉流压缩和历史对话检索有效处理了该任务。实验证明了所提出方法的有效性。

> **摘要翻译:** 尽管视频大型语言模型（Vid-LLMs）在改进多模态理解方面取得了进展，但由于其对上下文信息的依赖，流媒体视频推理仍然存在挑战。现有范式将所有可用的历史上下文信息输入到Vid-LLMs中，导致视觉数据处理的计算负担显著。此外，包含不相关的上下文会分散模型对关键细节的注意力。本文引入了一项名为上下文引导流媒体视频推理（CogStream）的挑战性任务，该任务模拟了真实的流媒体视频场景，要求模型识别最相关的历史上下文信息，以推断有关当前流的问题的答案。为了支持CogStream，我们提出了一个通过半自动管道生成的、包含大量分层问答对的密集标注数据集。此外，我们提出了CogReasoner作为基线模型。它通过利用视觉流压缩和历史对话检索有效地解决了这项任务。广泛的实验证明了该方法的有效性。代码将很快发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [441] [ALBERT: Advanced Localization and Bidirectional Encoder Representations from Transformers for Automotive Damage Evaluation](https://arxiv.org/abs/2506.10524)
> *ALBERT：用于汽车损伤评估的先进定位和双向编码器表示转换器*

*Teerapong Panboonyuen* | **Main category: cs.CV**

**Keywords:** 汽车损伤评估, 实例分割, 双向编码器表示, 智能检测, ALBERT

**Comment:** 10 pages

> **TL;DR:** ALBERT是一个基于Transformer的实例分割模型，用于准确识别和分割汽车损伤及零部件，能区分真假损伤，并在大规模数据集上表现出色，赋能智能汽车检测。

**AI_Comments:** ALBERT的创新之处在于其结合了Bidirectional Encoder Representations和先进的定位机制，专门针对汽车损伤和零部件进行实例分割，并能区分真实与虚假损伤，这对于自动化汽车检测具有重要意义。其在大规模数据集上的训练和所展现的强大性能，预示着该模型在实际应用中具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决汽车损伤和零部件的全面分割问题，以实现智能汽车检测和评估应用。

**Method:** 本文介绍了ALBERT，一个实例分割模型，它利用双向编码器表示和先进的定位机制，能够准确识别和区分真实与虚假损伤，并分割单个汽车零部件。该模型在一个包含26种损伤类型、7种虚假损伤变体和61个独立汽车部件的大规模、标注丰富的汽车数据集上进行训练。

**Result:** 该方法在分割准确性和损伤分类方面均表现出强大的性能。

**Conclusion:** ALBERT为智能汽车检测和评估应用铺平了道路。

> **ai_Abstract:** ALBERT是一种基于Transformer的实例分割模型，专为汽车损伤和零部件的全面识别与分割而设计。它利用双向编码器表示和先进的定位机制，能有效区分真实与虚假损伤，并对汽车部件进行精细分割。该模型在一个包含26种损伤、7种虚假损伤及61个部件的大规模数据集上训练，并在分割准确性和损伤分类方面展现出强大性能，有望推动智能汽车检测与评估技术的发展。

> **摘要翻译:** 本文介绍了ALBERT，一个专门为全面的汽车损伤和零部件分割设计的实例分割模型。ALBERT利用双向编码器表示的强大功能，结合先进的定位机制，以准确识别和区分真实损伤与虚假损伤，并分割单个汽车零部件。该模型在一个大规模、标注丰富的汽车数据集上进行训练，该数据集将损伤分为26种类型，识别7种虚假损伤变体，并分割61个不同的汽车零部件。我们的方法在分割准确性和损伤分类方面均表现出强大的性能，为智能汽车检测和评估应用铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [SLICK: Selective Localization and Instance Calibration for Knowledge-Enhanced Car Damage Segmentation in Automotive Insurance](https://arxiv.org/abs/2506.10528)
> *SLICK：用于汽车保险中知识增强型汽车损坏分割的选择性定位和实例校准*

*Teerapong Panboonyuen* | **Main category: cs.CV**

**Keywords:** 汽车损坏分割, 知识增强, 选择性定位, 实例校准, 汽车保险

**Comment:** 10 pages

> **TL;DR:** SLICK是一个新的框架，通过结合结构先验和领域知识，实现了精确鲁棒的汽车损坏分割，并在大规模数据集上表现出卓越性能。

**AI_Comments:** SLICK的创新之处在于其多组件的模块化设计，特别是结合了结构先验、多种注意力机制、实例级细化以及知识融合模块，以应对汽车损坏分割的复杂挑战。它有效地利用了合成数据和领域知识来提高模型的泛化能力，这对于处理现实世界中罕见或复杂情况至关重要。该方法在汽车保险和检测领域具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决现实世界中汽车检测的挑战，提供精确且鲁棒的汽车损坏分割方案。

**Method:** SLICK框架包含五个关键组件：1) 选择性零件分割，使用高分辨率语义骨干网络和结构先验实现精确零件分割；2) 定位感知注意力模块，动态关注损坏区域以增强精细损伤检测；3) 实例敏感细化头，利用全景线索和形状先验分离重叠或相邻部件，实现精确边界对齐；4) 跨通道校准，通过多尺度通道注意力增强细微损伤信号并抑制噪声；5) 知识融合模块，整合合成碰撞数据、零件几何和真实保险数据集，以提高泛化能力并有效处理罕见情况。

**Result:** 在大规模汽车数据集上的实验表明，SLICK具有卓越的分割性能、鲁棒性以及在保险和汽车检测工作流程中的实用性。

**Conclusion:** SLICK框架通过其多组件设计和知识融合策略，显著提升了汽车损坏分割的准确性和鲁棒性，并在实际应用中展现出强大潜力。

> **ai_Abstract:** SLICK是一个新颖的汽车损坏分割框架，它结合了结构先验和领域知识，以解决汽车检测中的实际挑战。该框架包含五个核心组件：选择性零件分割、定位感知注意力、实例敏感细化、跨通道校准以及知识融合模块。这些组件协同工作，实现了对车辆零件的精确分割、细微损伤的有效检测、重叠部件的精确边界对齐以及对罕见情况的更好处理。实验证明，SLICK在大规模汽车数据集上表现出卓越的性能、鲁棒性及实用性，适用于保险和汽车检测工作流程。

> **摘要翻译:** 我们提出了SLICK，一个用于精确和鲁棒的汽车损坏分割的新颖框架，它利用结构先验和领域知识来应对现实世界的汽车检测挑战。SLICK引入了五个关键组件：(1) 选择性零件分割，使用高分辨率语义骨干网络并由结构先验引导，即使在遮挡、变形或油漆缺失的情况下，也能实现车辆零件的手术级精确分割；(2) 定位感知注意力模块，动态聚焦于损坏区域，增强在杂乱复杂街道场景中的精细损伤检测；(3) 实例敏感细化头，利用全景线索和形状先验解开重叠或相邻零件，实现精确的边界对齐；(4) 跨通道校准，通过多尺度通道注意力放大划痕和凹痕等细微损伤信号，同时抑制反射和贴花等噪声；(5) 知识融合模块，整合合成碰撞数据、零件几何和真实世界保险数据集，以提高泛化能力并有效处理罕见情况。对大规模汽车数据集的实验表明，SLICK具有卓越的分割性能、鲁棒性以及在保险和汽车检测工作流程中的实际适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [ContextRefine-CLIP for EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2025](https://arxiv.org/abs/2506.10550)
> *ContextRefine-CLIP 用于 EPIC-KITCHENS-100 多实例检索挑战赛 2025*

*Jing He, Yiqing Wang, Lingling Li, Kexin Zhang, Puhua Chen* | **Main category: cs.CV**

**Keywords:** ContextRefine-CLIP, 多实例检索, 跨模态注意力, EPIC-KITCHENS-100, 视觉-文本检索

**Comment:** 

> **TL;DR:** ContextRefine-CLIP (CR-CLIP) 是一种基于双编码器AVION的视觉-文本多实例检索模型，通过引入跨模态注意力流和对称多相似度损失，在EPIC-KITCHENS-100数据集上显著提高了性能。

**AI_Comments:** 该论文提出了一种创新的跨模态注意力流机制，用于增强视觉和文本特征的交互和细化，从而生成更具上下文感知能力的联合表示。其在EPIC-KITCHENS-100数据集上显著超越基线模型的表现，证明了其在多实例检索任务中的强大潜力。该方法的效率以及无需集成学习的特点是其重要优势，表明了其独立性能的强大。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种高效的视觉-文本多实例检索模型，以提高现有方法的性能，特别是在处理EPIC-KITCHENS-100等多实例检索任务中提供的软标签相关性矩阵。

**Method:** 本文提出了ContextRefine-CLIP (CR-CLIP) 模型，它基于双编码器AVION。该方法引入了一个跨模态注意力流模块，以实现视觉和文本特征之间的双向动态交互和细化，从而生成更具上下文感知能力的联合表示。对于EPIC-KITCHENS-100等任务中提供的软标签相关性矩阵，CR-CLIP可以与对称多相似度损失（Symmetric Multi-Similarity Loss）协同工作，使用细化后的特征实现更准确的语义对齐和优化。

**Result:** CR-CLIP模型在EPIC-KITCHENS-100公共排行榜上取得了66.78mAP和82.08nDCG的成绩，显著优于基线模型，并且无需使用集成学习。

**Conclusion:** CR-CLIP模型在跨模态检索任务中表现出显著的有效性，并成功验证了其在视觉-文本多实例检索方面的能力。

> **ai_Abstract:** ContextRefine-CLIP (CR-CLIP) 是一种高效的视觉-文本多实例检索模型，它在双编码器AVION的基础上，通过引入跨模态注意力流模块，实现了视觉和文本特征的双向动态交互和细化，生成了更具上下文感知能力的联合表示。结合对称多相似度损失，CR-CLIP在EPIC-KITCHENS-100数据集上取得了显著优于基线模型的性能，验证了其在跨模态检索任务中的有效性。

> **摘要翻译:** 本报告介绍了ContextRefine-CLIP (CR-CLIP)，一个用于视觉-文本多实例检索任务的高效模型。该方法基于双编码器AVION，在此基础上我们引入了一个跨模态注意力流模块，以实现视觉和文本特征之间的双向动态交互和细化，从而生成更具上下文感知能力的联合表示。对于EPIC-KITCHENS-100等任务中提供的软标签相关性矩阵，CR-CLIP可以与对称多相似度损失（Symmetric Multi-Similarity Loss）协同工作，使用细化后的特征实现更准确的语义对齐和优化。在不使用集成学习的情况下，CR-CLIP模型在EPIC-KITCHENS-100公共排行榜上取得了66.78mAP和82.08nDCG的成绩，这显著优于基线模型，并充分验证了其在跨模态检索中的有效性。代码将在https://github.com/delCayr/ContextRefine-Clip 开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [451] [Balancing Tails when Comparing Distributions: Comprehensive Equity Index (CEI) with Application to Bias Evaluation in Operational Face Biometrics](https://arxiv.org/abs/2506.10564)
> *比较分布时的尾部平衡：综合公平指数（CEI）及其在操作人脸生物识别偏差评估中的应用*

*Imanol Solano, Julian Fierrez, Aythami Morales, Alejandro Peña, Ruben Tolosana, Francisco Zamora-Martinez, Javier San Agustin* | **Main category: cs.CV**

**Keywords:** 人脸识别, 偏差评估, 综合公平指数, 分布尾部, 公平性

**Comment:** 

> **TL;DR:** 该研究引入了综合公平指数（CEI），一种新颖的指标，旨在解决现有方法在检测高性能人脸识别（FR）系统中的细微人口统计学偏差（尤其是在分数分布尾部）方面的不足。CEI通过独立分析真实和冒充者分数分布，并可配置地关注尾部概率来提升偏差检测能力。

**AI_Comments:** 本文的创新之处在于其提出的CEI指标能够更精细地关注分数分布的尾部差异，这是现有指标的盲点。通过独立分析真实和冒充者分布，并提供可配置的尾部关注，CEI显著提升了偏差检测的敏感度，对于促进人脸识别系统的公平性具有重要意义。其普适性也使其在其他统计分布比较领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有指标在检测高性能人脸识别（FR）系统中的人口统计学偏差方面存在不足，特别是对于分数分布尾部的细微差异，导致这些偏差难以被发现。

**Method:** 本文引入了综合公平指数（CEI），一种新颖的指标，它独特地独立分析真实分数和冒充者分数分布，并允许配置性地关注尾部概率，同时考虑整体分布形状。此外，还提出了CEI^A，一个自动化版本，以增强客观性并简化实际应用。

**Result:** 广泛的实验证实了CEI在检测现有方法无法发现的细微偏差方面的卓越能力。CEI在评估最先进的FR系统、有意偏置模型和多样化数据集时表现出色。

**Conclusion:** CEI为操作人脸识别公平性评估提供了一个稳健且灵敏的工具。所提出的方法特别适用于人脸生物识别中的偏差评估，但通常也适用于任何对分析分布尾部感兴趣的问题中的统计分布比较。

> **ai_Abstract:** 该研究提出了一种新的指标——综合公平指数（CEI），旨在解决现有方法在检测人脸识别系统分数分布尾部细微偏差方面的不足。CEI通过独立分析真实和冒充者分数分布，并允许配置性地关注尾部概率，从而更有效地识别人口统计学偏差。实验证明CEI在检测细微偏差方面优于现有方法，并且其自动化版本CEI^A进一步提高了实用性。CEI不仅适用于人脸生物识别，也适用于其他需要分析分布尾部的统计分布比较问题。

> **摘要翻译:** 高性能人脸识别（FR）系统中的人口统计学偏差常常被现有指标所忽略，尤其是在分数分布尾部的细微差异方面。我们引入了综合公平指数（CEI），这是一种旨在解决此限制的新颖指标。CEI独特地独立分析真实分数和冒充者分数分布，从而能够可配置地关注尾部概率，同时考虑整体分布形状。我们广泛的实验（评估了最先进的FR系统、有意偏置的模型和多样化的数据集）证实了CEI在检测现有方法力所不及的细微偏差方面的卓越能力。此外，我们提出了CEI^A，该指标的自动化版本，增强了客观性并简化了实际应用。CEI为操作人脸识别公平性评估提供了一个稳健且灵敏的工具。所提出的方法是专门为面部生物识别中的偏差评估而开发的，但总的来说，它们适用于任何对分析分布尾部感兴趣的问题中的统计分布比较。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [454] [LRSLAM: Low-rank Representation of Signed Distance Fields in Dense Visual SLAM System](https://arxiv.org/abs/2506.10567)
> *LRSLAM: 稠密视觉SLAM系统中符号距离场的低秩表示*

*Hongbeen Park, Minjeong Park, Giljoo Nam, Jinkyu Kim* | **Main category: cs.CV**

**Keywords:** 稠密视觉SLAM, 低秩表示, 张量分解, 符号距离场, LRSLAM

**Comment:** Accepted at ECCV 2024

> **TL;DR:** LRSLAM通过低秩张量分解提升了稠密视觉SLAM的效率和性能。

**AI_Comments:** 本文通过将低秩张量分解引入稠密视觉SLAM中的符号距离场表示，有效解决了现有方法面临的计算量大和内存消耗高的问题。这种创新性的方法显著提升了系统的效率和性能，对于实现大规模、实时、高精度的稠密视觉SLAM具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稠密视觉SLAM在实时性、鲁棒性和大规模场景的可扩展性方面面临挑战；现有基于神经隐式场景表示的方法计算成本和内存需求高，ESLAM也存在内存增长问题。

**Method:** 提出LRSLAM模型，利用低秩张量分解方法（特别是六轴Six-axis和CP分解）来表示符号距离场。

**Result:** LRSLAM在收敛速度、内存效率、重建/定位质量、参数效率、处理时间和准确性方面均优于现有最先进方法，并在多种室内RGB-D数据集上得到了验证。

**Conclusion:** LRSLAM是一种更高效的视觉SLAM模型，通过引入低秩张量分解有效解决了现有稠密视觉SLAM在计算和内存方面的瓶颈，并显著提升了性能。

> **ai_Abstract:** 针对稠密视觉SLAM在实时性、鲁棒性、可扩展性以及现有神经隐式表示计算和内存成本高的问题，本文提出了LRSLAM模型。该模型利用低秩张量分解（包括六轴和CP分解）来表示符号距离场，从而实现了更优的收敛速度、内存效率和重建/定位质量。实验证明，LRSLAM在参数效率、处理时间和准确性方面均超越了现有最先进方法。

> **摘要翻译:** 同步定位与建图（SLAM）在自动驾驶、移动机器人和混合现实等多个领域都至关重要。利用RGB-D相机系统的稠密视觉SLAM具有优势，但在实现大规模场景的实时性能、鲁棒性和可扩展性方面面临挑战。最近利用神经隐式场景表示的方法显示出前景，但存在高计算成本和内存需求的问题。ESLAM引入了基于平面的张量分解，但仍存在内存增长问题。为应对这些挑战，我们提出了一种更高效的视觉SLAM模型——LRSLAM，它利用低秩张量分解方法。我们的方法利用六轴（Six-axis）和CP分解，比现有最先进的方法实现了更好的收敛速度、内存效率和重建/定位质量。对各种室内RGB-D数据集的评估表明，LRSLAM在参数效率、处理时间和准确性方面表现卓越，同时保持了重建和定位质量。我们的代码将在发布后公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [457] [DreamActor-H1: High-Fidelity Human-Product Demonstration Video Generation via Motion-designed Diffusion Transformers](https://arxiv.org/abs/2506.10568)
> *DreamActor-H1：基于运动设计的扩散Transformer的高保真人机互动演示视频生成*

*Lizhen Wang, Zhurong Xia, Tianshu Hu, Pengrui Wang, Pengfei Wang, Zerong Zheng, Ming Zhou* | **Main category: cs.CV**

**Keywords:** 人机互动视频生成, 扩散Transformer, 身份保留, 3D运动指导, 产品演示

**Comment:** 

> **TL;DR:** DreamActor-H1提出了一种基于扩散Transformer的新框架，通过注入参考信息、使用3D身体网格和结构化文本编码，解决了现有方法在生成高保真人机互动演示视频时无法保留身份和缺乏空间理解的问题，并实现了优于现有技术的性能。

**AI_Comments:** 该论文提出了一种新颖的基于扩散Transformer的方法，用于生成高保真的人机互动演示视频，其创新点在于结合了多方面的技术来解决现有痛点。通过注入参考信息、引入3D运动指导和结构化文本编码，有效提升了生成视频中人与产品身份的保持能力以及互动动作的真实感和空间一致性。这对于电子商务和数字营销领域具有重要应用价值，能够显著提升产品展示的效果。其在保持人产品身份和生成真实动作方面的SOTA表现，证明了其方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在电子商务和数字营销中，生成高保真的人机互动演示视频对于有效的产品展示至关重要。然而，大多数现有框架要么无法保留人与产品的身份，要么缺乏对人产品空间关系的理解，导致不真实的表现和不自然的互动。

**Method:** 我们提出了一种基于扩散Transformer (DiT) 的框架。该方法通过注入配对的人产品参考信息并利用额外的掩蔽交叉注意力机制，同时保留了人的身份和产品特定细节（如标志和纹理）。我们采用3D身体网格模板和产品边界框提供精确的运动指导，实现手势与产品放置的直观对齐。此外，使用结构化文本编码来整合类别级语义，增强帧间小旋转变化时的3D一致性。该方法在一个混合数据集上进行训练，并采用了广泛的数据增强策略。

**Result:** 我们的方法在保持人与产品身份完整性以及生成真实演示动作方面，优于现有最先进的技术。

**Conclusion:** DreamActor-H1通过其创新的DiT框架、参考信息注入、3D运动指导和结构化文本编码，成功解决了高保真人机互动演示视频生成中的身份保留和空间关系理解问题，并显著提升了生成视频的真实感和质量。

> **ai_Abstract:** DreamActor-H1提出了一种基于扩散Transformer (DiT) 的新框架，旨在生成高保真的人机互动产品演示视频。该方法通过注入配对的人产品参考信息和使用掩蔽交叉注意力机制来保持人与产品的身份及细节。它利用3D身体网格模板和产品边界框提供精确的运动指导，并结合结构化文本编码来增强3D一致性。在混合数据集上训练后，DreamActor-H1在保持身份完整性和生成真实演示动作方面超越了现有技术，有效解决了现有框架在真实感和互动自然度方面的不足。

> **摘要翻译:** 在电子商务和数字营销中，生成高保真的人机互动演示视频对于有效的产品展示至关重要。然而，大多数现有框架要么无法保留人与产品的身份，要么缺乏对人产品空间关系的理解，导致不真实的表现和不自然的互动。为了解决这些挑战，我们提出了一种基于扩散Transformer (DiT) 的框架。我们的方法通过注入配对的人产品参考信息并利用额外的掩蔽交叉注意力机制，同时保留了人的身份和产品特定细节，如标志和纹理。我们采用3D身体网格模板和产品边界框提供精确的运动指导，实现手势与产品放置的直观对齐。此外，使用结构化文本编码来整合类别级语义，增强帧间小旋转变化时的3D一致性。该方法在一个混合数据集上进行训练，并采用了广泛的数据增强策略，其性能在保持人与产品身份完整性以及生成真实演示动作方面，优于现有最先进的技术。项目页面：https://submit2025-dream.github.io/DreamActor-H1/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [460] [Improving Medical Visual Representation Learning with Pathological-level Cross-Modal Alignment and Correlation Exploration](https://arxiv.org/abs/2506.10573)
> *通过病理级别跨模态对齐和关联探索改进医学视觉表征学习*

*Jun Wang, Lixing Zhu, Xiaohan Yu, Abhir Bhalerao, Yulan He* | **Main category: cs.CV**

**Keywords:** 医学视觉表征学习, 跨模态对齐, 病理级别, 关联探索, 无监督学习

**Comment:** 12 pages, 10 tables and 6 figures

> **TL;DR:** 本文提出了一个新框架PLACE，通过病理级别跨模态对齐和关联探索，在无需额外人工标注的情况下，提升医学视觉表征学习，并在多项下游任务中取得了SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了病理级别跨模态对齐的概念，并设计了无需外部标注的PCMA模块和视觉病理观察提取器，这在很大程度上解决了医学领域数据标注困难的问题，提升了模型的泛化性和实用性。通过结合关联探索代理任务，进一步丰富了细粒度特征，使其在多种下游任务中表现出色，对于医学图像分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从图像-报告对中学习医学视觉表征有助于缓解医疗领域数据稀缺问题。主要挑战在于冗长的报告具有复杂的语篇关系和语义病理。现有工作主要侧重于实例级或令牌级跨模态对齐，而忽略了病理级别一致性的重要性。

**Method:** 本文提出了一个名为PLACE的新框架，该框架通过病理级别对齐和关联探索来丰富细粒度细节，且无需额外人工标注。具体来说，提出了一种新颖的病理级别跨模态对齐（PCMA）方法，以最大化图像和报告中病理观察的一致性。为此，引入了一个视觉病理观察提取器来从局部令牌中提取视觉病理观察表示。PCMA模块独立于任何外部疾病标注。此外，设计了一个代理任务，强制模型识别图像补丁之间的关联，从而丰富对各种下游任务至关重要的细粒度细节。

**Result:** 实验结果表明，所提出的框架在包括分类、图像到文本检索、语义分割、目标检测和报告生成在内的多项下游任务中实现了新的最先进性能。

**Conclusion:** 通过引入病理级别跨模态对齐和关联探索，PLACE框架显著提高了医学视觉表征学习的效果，并在多项下游任务中表现出优越性，且无需额外的人工标注，增强了方法的泛化性和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为PLACE的新型框架，旨在通过病理级别跨模态对齐（PCMA）和关联探索来改进医学视觉表征学习。针对现有方法忽视病理级别一致性的问题，PLACE引入了无需额外标注的PCMA模块和视觉病理观察提取器，以最大化图像与报告间病理观察的一致性。同时，通过设计代理任务来强化图像补丁间的关联，丰富细粒度信息。实验证明，该框架在多项下游医学任务中取得了最先进的性能，有效缓解了医学数据稀缺问题。

> **摘要翻译:** 通过联合学习从图像-报告对中学习医学视觉表征因其在缓解医疗领域数据稀缺问题方面的潜力而受到越来越多的研究关注。主要挑战源于冗长的报告，其具有复杂的语篇关系和语义病理。以往的工作主要侧重于实例级或令牌级跨模态对齐，往往忽略了病理级别一致性的重要性。本文提出了一个新颖的框架PLACE，该框架通过病理级别对齐和关联探索来促进病理级别对齐并丰富细粒度细节，且无需额外的人工标注。具体来说，我们提出了一种新颖的病理级别跨模态对齐（PCMA）方法，以最大化图像和报告中病理观察的一致性。为了促进这一点，引入了一个视觉病理观察提取器，用于从局部令牌中提取视觉病理观察表示。PCMA模块独立于任何外部疾病标注，增强了我们方法的泛化性和鲁棒性。此外，我们设计了一个代理任务，强制模型识别图像补丁之间的关联，从而丰富对各种下游任务至关重要的细粒度细节。实验结果表明，我们提出的框架在包括分类、图像到文本检索、语义分割、目标检测和报告生成在内的多项下游任务中实现了新的最先进性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [464] [Text to Image for Multi-Label Image Recognition with Joint Prompt-Adapter Learning](https://arxiv.org/abs/2506.10575)
> *联合提示-适配器学习的文本到图像多标签图像识别*

*Chun-Mei Feng, Kai Yu, Xinxing Xu, Salman Khan, Rick Siow Mong Goh, Wangmeng Zuo, Yong Liu* | **Main category: cs.CV**

**Keywords:** 文本到图像, 多标签图像识别, 提示-适配器学习, 模态鸿沟, CLIP

**Comment:** 

> **TL;DR:** 针对多标签图像识别中的模态鸿沟问题，本文提出T2I-PAL方法，通过文本到图像生成来缩小模态差距，并结合提示微调和适配器学习，显著提升了性能并减少了标注需求。

**AI_Comments:** 该论文提出了一种新颖的方法T2I-PAL，通过引入文本到图像生成来解决视觉-语言模型在多标签图像识别中的模态鸿沟问题，这在参数高效微调背景下具有创新性。其优势在于减少了数据标注成本并保持了与现有CLIP框架的兼容性，为实际应用提供了便利。性能提升显著，表明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 预训练视觉-语言模型（如CLIP）在利用文本作为图像进行参数高效微调（PEFT）时存在模态鸿沟问题，限制了图像识别性能，尤其在多标签图像识别中。此外，对语义标注训练图像的需求增加了手动标注工作量。

**Method:** 本文提出T2I-PAL方法，其核心是利用预训练的文本到图像生成模型从文本描述中生成逼真多样的图像，以缩小模态鸿沟。为进一步增强多标签图像识别，T2I-PAL还结合了类别热图和可学习原型来聚合局部相似性。为实现更好的PEFT，该方法进一步结合了提示微调和适配器学习。

**Result:** T2I-PAL消除了对完全语义标注训练图像的需求，减少了手动标注工作量，并保留了CLIP模型的内在模式，可与任何现有CLIP框架无缝集成。在MS-COCO、VOC2007和NUS-WIDE等多个基准测试中，T2I-PAL的识别性能平均比顶级现有方法提高了3.47%。

**Conclusion:** T2I-PAL通过文本到图像生成有效解决了利用文本作为图像进行多标签图像识别时的模态鸿沟问题，显著提升了识别性能，并降低了数据标注成本。

> **ai_Abstract:** 本文提出T2I-PAL方法，旨在解决利用预训练视觉-语言模型（如CLIP）进行多标签图像识别时存在的模态鸿沟问题。T2I-PAL通过文本到图像生成模型从文本描述中生成图像，以缩小模态差距，并通过结合类别热图、可学习原型以及提示微调和适配器学习来增强识别性能。该方法显著提升了多标签图像识别的准确性，减少了对大量标注图像的需求，并能与现有CLIP框架无缝集成。

> **摘要翻译:** 受益于图像-文本对比学习，预训练的视觉-语言模型，例如CLIP，允许直接利用文本作为图像（TaI）进行参数高效微调（PEFT）。虽然CLIP能够使图像特征与相应的文本特征相似，但模态鸿沟仍然是一个不容忽视的问题，并限制了TaI的图像识别性能。以多标签图像识别（MLR）为例，我们提出了一种名为T2I-PAL的新方法，以解决仅使用文本描述进行PEFT时的模态鸿沟问题。T2I-PAL的核心设计是利用预训练的文本到图像生成模型从文本描述中生成逼真多样的图像，从而减少模态鸿沟。为了进一步增强MLR，T2I-PAL结合了类别热图和可学习原型。这聚合了局部相似性，使局部视觉特征的表示对于多标签识别更加鲁棒和信息丰富。为了更好的PEFT，我们进一步结合了提示微调和适配器学习以提高分类性能。T2I-PAL具有显著优势：它消除了对完全语义标注训练图像的需求，从而减少了手动标注工作量，并且它保留了CLIP模型的内在模式，允许与任何现有CLIP框架无缝集成。在包括MS-COCO、VOC2007和NUS-WIDE在内的多个基准测试中进行的广泛实验表明，我们的T2I-PAL可以将识别性能平均比排名靠前的最先进方法提高3.47%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [466] [Harmonizing Geometry and Uncertainty: Diffusion with Hyperspheres](https://arxiv.org/abs/2506.10576)
> *协调几何与不确定性：超球面上的扩散模型*

*Muskan Dosi, Chiranjeev Chiranjeev, Kartik Thakral, Mayank Vatsa, Richa Singh* | **Main category: cs.CV**

**Keywords:** 扩散模型, 超球面, 几何感知, 方向性噪声, 非欧几里得数据

**Comment:** 

> **TL;DR:** 现有扩散模型在处理超球面数据时会丢失几何信息，本文提出HyperSphereDiff，通过引入方向性噪声，更好地保留超球面数据的固有几何结构和角度不确定性，从而提升生成性能。

**AI_Comments:** 该论文创新性地将扩散模型与超球面几何相结合，解决了现有扩散模型在处理非欧几里得数据时的局限性。通过引入方向性噪声，模型能够更好地捕获和保留数据的内在几何结构和角度不确定性，这对于在复杂流形上进行数据生成具有重要意义。这一方法为处理非欧几里得数据（如面部、物体姿态等）提供了一个新的视角和有效的解决方案，具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 标准扩散模型依赖各向同性高斯噪声，偏向欧几里得空间，但在处理超球面流形等非欧几里得分布时，会丢失由角度几何控制的类特定模式，导致生成性能不佳。

**Method:** 提出HyperSphereDiff模型，通过将超球面结构与方向性噪声对齐，以保留类几何并有效捕获角度不确定性。

**Result:** 理论和经验上证明，该方法使生成过程与超球面数据的内在几何结构对齐，从而产生更准确且几何感知的生成模型。在四个对象数据集和两个人脸数据集上的评估显示，结合角度不确定性更好地保留了底层的超球面流形。

**Conclusion:** 通过在扩散模型中引入方向性噪声和处理角度不确定性，可以有效地保留超球面数据的固有几何结构，显著提升模型在非欧几里得数据上的生成性能。

> **ai_Abstract:** 本文关注标准扩散模型在处理超球面等非欧几里得数据时，因其基于欧几里得空间的假设而导致几何信息丢失的问题。为解决此问题，研究者提出了HyperSphereDiff，该模型通过引入方向性噪声来与超球面结构对齐，从而有效保留数据的类别几何和角度不确定性。理论和实验结果表明，HyperSphereDiff能够使生成过程更好地与超球面数据的内在几何结构匹配，从而生成更准确且几何感知的模型，并在多个数据集上验证了其在保留底层超球面流形方面的优越性。

> **摘要翻译:** 当代扩散模型是否保留了超球面数据的类别几何？标准扩散模型在前向过程中依赖各向同性高斯噪声，固有地偏向欧几里得空间。然而，许多现实世界问题涉及非欧几里得分布，例如超球面流形，其中类别特定的模式由超锥体内的角度几何控制。当在欧几里得空间中建模时，这些角度上的细微差别会丢失，导致次优的生成性能。为了解决这一限制，我们引入了HyperSphereDiff，以将超球面结构与方向性噪声对齐，从而保留类别几何并有效捕获角度不确定性。我们在理论和经验上都证明了这种方法将生成过程与超球面数据的内在几何结构对齐，从而产生了更准确和几何感知的生成模型。我们在四个对象数据集和两个人脸数据集上评估了我们的框架，结果表明，结合角度不确定性更好地保留了底层的超球面流形。资源可在以下链接获取：{https://github.com/IAB-IITJ/Harmonizing-Geometry-and-Uncertainty-Diffusion-with-Hyperspheres/}

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [467] [Rethinking Random Masking in Self Distillation on ViT](https://arxiv.org/abs/2506.10582)
> *重新思考ViT自蒸馏中的随机掩码*

*Jihyeon Seong, Hyunkyung Han* | **Main category: cs.CV**

**Keywords:** ViT, 自蒸馏, 随机掩码, DINO, 注意力图

**Comment:** 4 pages

> **TL;DR:** 本文在DINO框架下，重新思考了ViT自蒸馏中的随机掩码策略。作者提出了一种非对称掩码方法，仅对学生的全局视图应用随机掩码，同时保持学生局部视图和教师全局视图的原始形式，从而在保留干净监督的同时通过掩码输入提高鲁棒性。实验表明，该方法能产生更鲁棒、更细致的注意力图，并提升下游任务性能。

**AI_Comments:** 该研究通过提出一种新颖的非对称随机掩码策略，解决了ViT自蒸馏中过度掩码可能导致语义信息丢失的问题。其创新点在于巧妙地结合了DINO的多视图特性，在引入鲁棒性的同时确保了监督信号的质量。这为自监督学习中的数据增强和正则化提供了新的视角，对于提升ViT模型在实际应用中的性能和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前研究对无差别随机掩码可能无意中消除关键语义信息表示担忧，这促使了更具信息性的掩码策略的发展。

**Method:** 研究者在DINO框架下，将随机掩码仅应用于学生的全局视图，而保留学生的局部视图和教师的全局视图为原始未掩码形式。这种设计利用了DINO的多视图增强方案，以在通过掩码输入诱导鲁棒性的同时保留干净的监督。

**Result:** 在mini-ImageNet数据集上使用DINO-Tiny评估了该方法，结果表明在这种非对称设置下的随机掩码产生了更鲁棒、更细致的注意力图，并最终提升了下游性能。

**Conclusion:** 在DINO框架下，对ViT自蒸馏中的随机掩码进行非对称应用（仅对学生全局视图掩码）能够提升模型鲁棒性，产生更精细的注意力图，并提高下游任务的表现。

> **ai_Abstract:** 本文探讨了Vision Transformers (ViTs) 自蒸馏框架中随机掩码的作用，尤其关注DINO。针对现有随机掩码可能消除关键语义信息的问题，作者提出了一种非对称掩码策略：仅对学生的全局视图进行随机掩码，而保持学生局部视图和教师全局视图的完整性。该方法利用DINO的多视图增强机制，旨在通过掩码输入提高鲁棒性，同时保留干净的监督信号。在mini-ImageNet数据集上，使用DINO-Tiny进行的评估显示，这种非对称设置下的随机掩码能够生成更鲁棒、更精细的注意力图，并最终提升下游任务的性能。

> **摘要翻译:** Vision Transformers (ViTs) 在广泛的视觉任务中展现出卓越的性能。特别是，DINO等自蒸馏框架对这些进步做出了重大贡献。在此类框架中，随机掩码常用于提高训练效率和引入正则化。然而，最近的研究提出担忧，认为不加区分的随机掩码可能无意中消除关键语义信息，这促使了更具信息性的掩码策略的发展。在本研究中，我们探讨了在自蒸馏设置中随机掩码的作用，重点关注DINO框架。具体而言，我们仅对学生的全局视图应用随机掩码，同时保留学生的局部视图和教师的全局视图为原始、未掩码的形式。这种设计利用DINO的多视图增强方案，以在通过掩码输入诱导鲁棒性的同时保留干净的监督。我们使用DINO-Tiny在mini-ImageNet数据集上评估了我们的方法，结果表明在这种非对称设置下的随机掩码产生了更鲁棒、更细致的注意力图，并最终提升了下游性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [Hierarchical Error Assessment of CAD Models for Aircraft Manufacturing-and-Measurement](https://arxiv.org/abs/2506.10594)
> *飞机制造与测量中CAD模型的层次化误差评估*

*Jin Huang, Honghua Chen, Mingqiang Wei* | **Main category: cs.CV**

**Keywords:** 层次化误差评估, CAD模型, 飞机制造, 结构光扫描, 点云分析

**Comment:** 

> **TL;DR:** 本文提出了一种名为HEA-MM的层次化误差评估框架，用于飞机CAD模型在制造和测量过程中的误差分析，通过结构光扫描、点云配准，并在全局、零件和特征三个层次进行误差分析。

**AI_Comments:** 该论文提出了一种创新的、多层次的误差评估框架HEA-MM，通过结合结构光扫描、点云处理和分层分析（全局、零件、特征），为航空制造中的CAD模型质量控制提供了全面且精细的解决方案。特别是在零件和特征层面的优化和检测算法，体现了其在处理复杂几何特征方面的精细化能力。这对于确保航空设备的高质量制造具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 航空设备对质量要求高，包括高性能、高稳定性和高可靠性。因此，需要对飞机CAD模型进行精确的误差评估以确保产品质量。

**Method:** 本文提出了HEA-MM层次化误差评估框架。该框架首先使用结构光扫描仪获取制造工件的全面3D点云数据，然后将测量点云与参考CAD模型进行配准。接着，在三个层次进行误差分析：全局层面评估扫描点云与CAD模型的整体偏差；零件层面通过提出一种基于优化的原始细化方法（引入分裂和合并操作）来分析有意义的点云补丁；特征层面则针对CAD模型中常见的圆形孔，引入了两阶段算法进行检测（首先使用张量投票算法识别边缘点，然后通过假设-聚类框架拟合多个圆）。

**Result:** 在各种飞机CAD模型上的实验结果证明了所提出方法的有效性。

**Conclusion:** 所提出的HEA-MM框架能够有效地评估飞机CAD模型在制造和测量过程中的误差，有助于确保航空设备的高质量。

> **ai_Abstract:** 本文提出了一种名为HEA-MM的层次化误差评估框架，旨在解决飞机制造与测量中CAD模型的质量评估问题。该框架利用结构光扫描获取工件3D点云数据，并将其与参考CAD模型配准。随后，在全局、零件和特征三个层面进行误差分析：全局层面评估整体偏差；零件层面通过优化细化方法分析点云补丁；特征层面则针对圆形孔，采用两阶段算法进行检测和分析。实验结果验证了该方法的有效性。

> **摘要翻译:** 航空设备最重要的特点是高质量，包括高性能、高稳定性和高可靠性。本文提出了一种用于飞机CAD模型在制造和测量平台中的新型层次化误差评估框架，称为HEA-MM。HEA-MM采用结构光扫描仪获取制造工件的全面3D测量数据。测量点云与参考CAD模型配准后，在全局、零件和特征三个层次进行误差分析。在全局层面，误差分析评估扫描点云与参考CAD模型的整体偏差。在零件层面，对点云下方的这些补丁进行误差分析。我们提出了一种新颖的基于优化的原始细化方法，以获得一组有意义的点云补丁。引入了分裂和合并两种基本操作来细化粗糙的原始形状。在特征层面，对CAD模型中常见的圆形孔进行误差分析。为实现此目的，引入了两阶段算法用于圆形孔的检测。首先，使用张量投票算法识别边缘点。然后，通过假设-聚类框架拟合多个圆，确保圆形特征的准确检测和分析。在各种飞机CAD模型上的实验结果证明了我们所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [471] [Semantic-decoupled Spatial Partition Guided Point-supervised Oriented Object Detection](https://arxiv.org/abs/2506.10601)
> *语义解耦空间划分引导的点监督定向目标检测*

*Xinyuan Liu, Hang Xu, Yike Ma, Yucheng Zhang, Feng Dai* | **Main category: cs.CV**

**Keywords:** 点监督, 定向目标检测, 空间划分, 样本分配, 伪标签

**Comment:** 

> **TL;DR:** 提出SSP框架，通过像素级和语义级空间划分解决点监督定向目标检测中样本分配和实例混淆问题，显著提升性能。

**AI_Comments:** SSP框架的创新之处在于其将规则驱动的先验知识与数据驱动的标签净化相结合，通过精巧的空间划分机制解决了点监督下样本分配和实例混淆的难题。这种方法在降低标注成本的同时，显著提升了高密度遥感场景中定向目标检测的性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有遥感图像中高密度场景的定向目标检测面临劳动密集型标注的挑战。点监督虽然成本效益高，但现有方法因僵化的基于规则的设计而存在样本分配不足和实例混淆问题。

**Method:** 提出SSP（语义解耦空间划分）统一框架，结合规则驱动的先验注入和数据驱动的标签净化。核心创新包括：1) 基于像素级空间划分的样本分配，用于估计目标尺度并挖掘高质量正负样本。2) 基于语义空间划分的框提取，用于从空间划分中导出实例并转换为伪标签以监督下游检测器。

**Result:** 在DOTA-v1.0数据集上，SSP在点监督下实现了45.78%的mAP，比SOTA方法PointOBB-v2高出4.10%。与ORCNN和ReDet架构集成时，SSP框架分别达到47.86%和48.50%的mAP。

**Conclusion:** SSP框架有效解决了点监督定向目标检测中的挑战，通过其创新的空间划分方法显著提升了检测性能。

> **ai_Abstract:** 本文针对遥感图像中高密度场景下点监督定向目标检测存在的样本分配不足和实例混淆问题，提出了SSP（语义解耦空间划分）框架。SSP通过像素级空间划分进行样本分配和语义空间划分进行框提取两项核心创新，有效地结合了规则驱动的先验知识和数据驱动的标签净化。实验证明，SSP在DOTA-v1.0数据集上显著优于现有SOTA方法，并在与主流检测器集成时表现出色，为点监督定向目标检测提供了一种高效且准确的解决方案。

> **摘要翻译:** 近期遥感技术进步推动了图像增长，使定向目标检测快速发展，但高密度场景劳动密集型标注阻碍了其发展。点监督的定向目标检测为遥感中密集场景提供了成本效益高的解决方案，但现有方法由于僵化的基于规则的设计，存在样本分配不足和实例混淆的问题。为解决此问题，我们提出了SSP（语义解耦空间划分），一个统一的框架，协同规则驱动的先验注入和数据驱动的标签净化。具体而言，SSP引入了两项核心创新：1）基于像素级空间划分的样本分配，它紧凑地估计目标尺度的上下限，并通过像素图的空间划分挖掘高质量的正样本和难负样本。2）基于语义空间划分的框提取，它从语义图调制的空间划分中导出实例，并可靠地将其转换为边界框以形成伪标签，用于监督下游检测器的学习。在DOTA-v1.0及其他数据集上的实验表明SSP的优越性：在点监督下实现了45.78%的mAP，比SOTA方法PointOBB-v2高出4.10%。此外，当与ORCNN和ReDet架构集成时，SSP框架分别实现了47.86%和48.50%的mAP值。代码可在https://github.com/antxinyuan/ssp获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [473] [High-resolution efficient image generation from WiFi CSI using a pretrained latent diffusion model](https://arxiv.org/abs/2506.10605)
> *使用预训练潜在扩散模型从WiFi CSI生成高分辨率高效图像*

*Eshan Ramesh, Nishio Takayuki* | **Main category: cs.CV**

**Keywords:** WiFi CSI, 图像生成, 潜在扩散模型, 高分辨率, 文本指导

**Comment:** 6 pages, 4 figures

> **TL;DR:** LatentCSI是一种新方法，利用预训练的潜在扩散模型，将WiFi CSI测量数据高效地生成高分辨率图像，并通过文本指导实现可控性，且性能优于现有基线。

**AI_Comments:** 这篇论文提出了一种创新的方法，将WiFi CSI数据与潜在扩散模型结合，实现了高效且高质量的图像生成。其创新点在于避免了传统的像素空间生成和显式编码阶段，并通过文本指导增加了实用性。该方法在利用非传统传感器数据进行环境感知方面具有重要意义，可能为未来低成本、非接触式感知技术开辟新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有从WiFi CSI生成图像的方法通常依赖于复杂且计算密集的技术（如GANs），且面临像素空间图像生成和图像编码阶段的挑战。本文旨在提出一种更高效、高质量且可控的方法来解决这些问题。

**Method:** 提出LatentCSI，一种利用预训练潜在扩散模型（LDM）从WiFi CSI测量生成物理环境图像的方法。该方法使用一个轻量级神经网络将CSI幅度直接映射到LDM的潜在空间，然后应用LDM的去噪扩散模型对潜在表示进行文本指导，最后通过LDM的预训练解码器生成高分辨率图像。该方法避免了像素空间图像生成和显式图像编码阶段。

**Result:** LatentCSI在计算效率和感知质量方面均优于直接在真实图像上训练的、复杂度相当的基线方法。此外，它还通过其独特的文本引导可控性提供了实际优势。该方法在自行收集的宽带CSI数据集和MM-Fi数据集子集上进行了验证。

**Conclusion:** LatentCSI是一种有效且高效的从WiFi CSI生成高分辨率图像的方法，通过利用预训练的潜在扩散模型和文本指导，在性能和实用性上均超越了现有基线。

> **ai_Abstract:** LatentCSI是一种新颖的方法，它利用预训练的潜在扩散模型，将WiFi CSI测量数据高效地转换为高分辨率物理环境图像。该方法通过轻量级神经网络将CSI直接映射到LDM的潜在空间，并结合文本指导进行图像生成，避免了传统方法的复杂性和计算密集性。实验证明，LatentCSI在计算效率和图像质量上均优于现有基线，并具备独特的文本引导可控性。

> **摘要翻译:** 我们提出了LatentCSI，一种利用预训练潜在扩散模型（LDM）从WiFi CSI测量生成物理环境图像的新方法。与以往依赖复杂且计算密集型技术（如GAN）的方法不同，我们的方法采用轻量级神经网络将CSI幅度直接映射到LDM的潜在空间。然后，我们将LDM的去噪扩散模型应用于潜在表示，并进行基于文本的指导，最后使用LDM的预训练解码器进行解码以获得高分辨率图像。这种设计绕过了像素空间图像生成的挑战，并避免了传统图像到图像管道中通常所需的显式图像编码阶段，从而实现了高效、高质量的图像合成。我们在两个数据集上验证了我们的方法：一个是我们使用现成WiFi设备和相机收集的宽带CSI数据集；以及公开可用的MM-Fi数据集的一个子集。结果表明，LatentCSI在计算效率和感知质量方面均优于直接在真实图像上训练的、复杂度相当的基线方法，同时通过其独特的文本引导可控性提供了实际优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [475] [MSTAR: Box-free Multi-query Scene Text Retrieval with Attention Recycling](https://arxiv.org/abs/2506.10609)
> *MSTAR：基于注意力循环的无框多查询场景文本检索*

*Liang Yin, Xudong Xie, Zhang Li, Xiang Bai, Yuliang Liu* | **Main category: cs.CV**

**Keywords:** 场景文本检索, 无框, 多查询, 注意力循环, MQTR数据集

**Comment:** 

> **TL;DR:** MSTAR是一种无需边界框、支持多查询的场景文本检索方法，性能超越现有SOTA模型，并引入了新的多查询数据集MQTR。

**AI_Comments:** MSTAR的创新性在于其“无框”设计，这极大地降低了场景文本检索的标注成本，具有重要的实践意义。同时，它统一了多种查询类型，提升了方法的普适性。引入MQTR数据集填补了多查询场景文本检索基准的空白，对该领域的研究发展具有推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有场景文本检索方法通常需要昂贵的边界框标注进行训练，并且大多采用定制的检索策略，难以统一各种查询类型以满足多样化的检索需求。

**Method:** 本文引入了MSTAR（多查询场景文本检索与注意力循环），一种无框的场景文本检索方法。它整合了渐进式视觉嵌入以动态捕获文本的多粒度表示，并协调自由风格文本查询与风格感知指令。此外，还集成了一个多实例匹配模块来增强视觉-语言对齐。研究团队还构建了Multi-Query Text Retrieval (MQTR) 数据集，这是第一个旨在评估模型多查询场景文本检索能力的基准，包含四种查询类型和16k图像。

**Result:** 广泛的实验表明MSTAR在七个公共数据集和MQTR数据集上均表现出优越性。值得注意的是，MSTAR在Total-Text数据集上的平均精度（MAP）比之前的最先进模型高出6.4%，同时消除了边界框标注成本。此外，在MQTR基准测试中，MSTAR比之前的模型平均高出8.5%。

**Conclusion:** MSTAR成功地提出了一种无需边界框的场景文本检索方法，有效解决了传统方法对昂贵标注的依赖和多样化查询的统一问题，并在多个基准测试中取得了显著的性能提升。

> **ai_Abstract:** MSTAR是一种创新的无框多查询场景文本检索方法，旨在解决现有方法对边界框标注的依赖和难以统一多种查询类型的问题。该方法通过渐进式视觉嵌入、自由风格查询与风格感知指令的协调以及多实例匹配模块来提升文本表示和视觉-语言对齐。此外，本文还引入了首个多查询场景文本检索基准MQTR数据集。实验证明，MSTAR在多个公共数据集和MQTR数据集上均显著超越了现有最先进模型，尤其是在消除标注成本的同时取得了性能提升。

> **摘要翻译:** 场景文本检索在精确文本定位的辅助下取得了显著进展。然而，现有方法通常需要昂贵的边界框标注进行训练。此外，它们大多采用定制的检索策略，但难以统一各种类型的查询以满足多样化的检索需求。为了解决这些问题，我们引入了MSTAR（基于注意力循环的多查询场景文本检索），一种无需边界框的场景文本检索方法。它结合了渐进式视觉嵌入以动态捕获文本的多粒度表示，并协调自由风格文本查询与风格感知指令。此外，还集成了一个多实例匹配模块来增强视觉-语言对齐。更进一步，我们构建了Multi-Query Text Retrieval (MQTR) 数据集，这是第一个旨在评估模型多查询场景文本检索能力的基准，包含四种查询类型和16k图像。广泛的实验表明我们的方法在七个公共数据集和MQTR数据集上均表现出优越性。值得注意的是，MSTAR在Total-Text数据集上的MAP指标上比之前的最先进模型高出6.4%，同时消除了边界框标注成本。此外，在MQTR基准测试中，MSTAR比之前的模型平均高出8.5%。代码和数据集可在https://github.com/yingift/MSTAR获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [477] [TexTailor: Customized Text-aligned Texturing via Effective Resampling](https://arxiv.org/abs/2506.10612)
> *TexTailor：通过有效重采样实现定制化文本对齐纹理生成*

*Suin Lee, Dae-Shik Kim* | **Main category: cs.CV**

**Keywords:** 文本到纹理, 纹理合成, 扩散模型, 视图一致性, 重采样

**Comment:** Submitted to ICLR 2025

> **TL;DR:** TexTailor是一种新方法，通过有效重采样和自适应相机调整，解决现有文本到纹理合成中纹理一致性差的问题，生成高质量的视图一致性纹理。

**AI_Comments:** 这篇论文的创新点在于提出了一个全面的解决方案来解决文本到纹理合成中长期存在的纹理一致性问题。通过结合重采样、模型微调、性能保持损失以及几何感知相机调整，TexTailor有效地克服了现有方法在跨视角纹理漂移和信息利用效率上的局限性，对3D内容生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到纹理合成方法（基于深度感知扩散模型）在生成纹理时，由于在扩散过程中未能充分整合先前合成的纹理信息以及纹理合成过程的自回归特性，导致纹理属性在不同视角间逐渐漂移。此外，预定义的相机位置未考虑物体几何形状，限制了不同视角纹理信息的有效利用，从而降低了整体纹理一致性。

**Method:** TexTailor通过以下方法解决问题：1) 应用重采样方案，在扩散过程中重复整合先前合成的纹理信息；2) 在这些重采样纹理上微调深度感知扩散模型；3) 提出性能保持损失以缓解仅使用少量训练图像限制模型生成高保真图像能力的问题；4) 根据物体几何形状自适应调整相机位置，改进视图一致性纹理的合成。

**Result:** 在Objaverse数据集子集和ShapeNet汽车数据集上的实验表明，TexTailor在合成视图一致性纹理方面优于现有最先进的方法。

**Conclusion:** TexTailor能够有效解决文本到纹理合成中纹理一致性问题，生成高质量的视图一致性纹理，并超越了现有技术。

> **ai_Abstract:** TexTailor提出了一种新颖的文本到纹理生成方法，旨在解决现有深度感知扩散模型在多视角纹理合成中存在的纹理一致性差的问题。通过引入有效的重采样方案整合先前纹理信息、微调扩散模型并提出性能保持损失，以及根据物体几何自适应调整相机位置，TexTailor显著提升了视图一致性纹理的合成质量，并在多个数据集上超越了现有SOTA方法。

> **摘要翻译:** 我们提出了TexTailor，一种从文本描述生成一致对象纹理的新方法。现有的文本到纹理合成方法利用深度感知扩散模型逐步生成图像并在预定义的多视角下合成纹理。然而，这些方法导致纹理属性在不同视角间逐渐漂移，原因在于(1)在扩散过程中未能充分整合每个视角下先前合成的纹理，以及(2)纹理合成过程的自回归特性。此外，未考虑物体几何形状的预定义相机位置限制了从不同视角合成的纹理信息的有效利用，最终降低了整体纹理一致性。在TexTailor中，我们通过(1)应用重采样方案，在扩散过程中重复整合先前合成的纹理信息，以及(2)在这些重采样纹理上微调深度感知扩散模型来解决这些问题。在此过程中，我们观察到仅使用少量训练图像会限制模型生成与条件对齐的高保真图像的原始能力，因此我们提出了一个性能保持损失来缓解这个问题。此外，我们通过根据物体几何形状自适应调整相机位置来改进视图一致性纹理的合成。在Objaverse数据集子集和ShapeNet汽车数据集上的实验表明，TexTailor在合成视图一致性纹理方面优于现有最先进的方法。TexTailor的源代码可在https://github.com/Adios42/Textailor 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [479] [Anatomy-Grounded Weakly Supervised Prompt Tuning for Chest X-ray Latent Diffusion Models](https://arxiv.org/abs/2506.10633)
> *胸部X光潜扩散模型的解剖学弱监督提示调优*

*Konstantinos Vilouras, Ilias Stogiannidis, Junyu Yan, Alison Q. O'Neil, Sotirios A. Tsaftaris* | **Main category: cs.CV**

**Keywords:** 潜扩散模型, 胸部X光, 弱监督, 提示调优, 多模态对齐

**Comment:** 14 pages, 6 figures

> **TL;DR:** 本文提出了一种解剖学弱监督提示调优框架，以改善胸部X光潜扩散模型中的多模态对齐，并在基准数据集上实现了最先进的性能。

**AI_Comments:** 这项工作创新性地将弱监督提示调优应用于医学影像领域的潜扩散模型，解决了数据稀缺和多模态对齐的挑战。其在胸部X光领域的SOTA表现突显了其重要性，为医学图像分析和生成提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像的潜扩散模型在医学影像领域（特别是胸部X光）中探索不足，主要原因是数据可用性有限。标准模型未能将放射报告中的临床相关信息与扫描的相应区域对齐。

**Method:** 提出了一种微调框架，用于改善预训练模型中的多模态对齐，使其能够有效地重新用于下游任务，如短语定位。该方法是“解剖学弱监督提示调优”。

**Result:** 在标准基准数据集（MS-CXR）上达到了新的最先进水平，并且在分布外数据（VinDr-CXR）上表现出稳健的性能。

**Conclusion:** 通过提出的微调框架，可以有效改善胸部X光潜扩散模型的多模态对齐，从而在医学影像下游任务中取得优异表现。

> **ai_Abstract:** 本文针对医学影像领域（特别是胸部X光）中文本到图像潜扩散模型的多模态对齐问题，提出了一种解剖学弱监督提示调优的微调框架。研究发现标准模型无法有效关联文本报告与图像区域。通过该框架，显著提升了模型在临床信息对齐方面的能力，并在MS-CXR和VinDr-CXR数据集上取得了最先进的性能和稳健性，为医疗影像下游任务提供了有效方案。

> **摘要翻译:** 潜在扩散模型近年来在文本引导图像合成方面取得了显著成果。在自然（RGB）图像领域，最近的工作表明，此类模型可以适应各种视觉-语言下游任务，仅需很少或无需监督。相反，文本到图像的潜在扩散模型在医学影像领域仍相对未被充分探索，这主要是由于数据可用性有限（例如，由于隐私问题）。在这项工作中，我们专注于胸部X光模态，首先证明了标准的文本条件潜在扩散模型尚未学会将自由文本放射报告中的临床相关信息与给定扫描的相应区域对齐。然后，为了缓解这个问题，我们提出了一种微调框架，以改善预训练模型中的多模态对齐，使其能够有效地重新用于下游任务，例如短语定位。我们的方法在标准基准数据集（MS-CXR）上设定了新的最先进水平，同时在分布外数据（VinDr-CXR）上也表现出稳健的性能。我们的代码将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [481] [Symmetrical Flow Matching: Unified Image Generation, Segmentation, and Classification with Score-Based Generative Models](https://arxiv.org/abs/2506.10634)
> *对称流匹配：基于分数的生成模型统一图像生成、分割和分类*

*Francisco Caetano, Christiaan Viviers, Peter H. N. De With, Fons van der Sommen* | **Main category: cs.CV**

**Keywords:** 流匹配, 图像生成, 语义分割, 图像分类, 对称学习

**Comment:** 

> **TL;DR:** SymmFlow 是一种新的流匹配框架，通过对称学习目标统一了图像生成、语义分割和分类，实现了高效采样和最先进的生成性能。

**AI_Comments:** SymmFlow 的创新之处在于将图像生成、语义分割和分类统一到一个单一的流匹配框架中，并通过对称学习目标实现了双向一致性与生成多样性。其新的训练目标允许高效的一步式语义任务处理，避免了迭代细化，并且能够处理更灵活的条件设置，这显著提升了多任务处理的效率和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流匹配框架虽然在生成建模方面表现强大，但缺乏一个能统一图像生成、语义分割和分类的单一模型，并且在掩码和图像之间存在严格的一对一映射限制，限制了其灵活性。

**Method:** 本文提出了对称流匹配 (SymmFlow)，通过对称学习目标联合建模前向和反向变换，确保双向一致性并保留生成多样性。引入了一个新的训练目标以显式保留流中的语义信息，实现高效采样，并在不迭代细化的情况下进行一步分割和分类。它支持像素级和图像级类标签的灵活条件设置。

**Result:** SymmFlow 在语义图像合成方面取得了最先进的性能，在 CelebAMask-HQ 上 FID 分数为 11.9，在 COCO-Stuff 上为 7.0（仅需 25 个推理步骤）。此外，它在语义分割方面表现出有竞争力的结果，并在分类任务中显示出有前景的能力。

**Conclusion:** SymmFlow 成功地将图像生成、语义分割和分类统一在一个单一模型中，通过其对称学习和新的训练目标，实现了高效且高性能的多任务处理，并在多个基准测试中取得了显著成果。

> **ai_Abstract:** 本文提出了对称流匹配 (SymmFlow)，一种统一图像生成、语义分割和分类的单一模型。SymmFlow 采用对称学习目标，联合建模前向和反向变换，确保双向一致性和生成多样性。它引入了新的训练目标以高效保留语义信息，实现一步式分割和分类。实验证明，SymmFlow 在语义图像合成上达到最先进性能，并在分割和分类任务中表现出色，支持灵活的条件设置。

> **摘要翻译:** 流匹配已成为一种强大的框架，用于学习分布之间的连续变换，从而实现高保真生成建模。这项工作引入了对称流匹配 (SymmFlow)，这是一种新的公式，将语义分割、分类和图像生成统一到一个单一模型中。通过使用对称学习目标，SymmFlow 联合建模前向和反向变换，确保双向一致性，同时保留足够的熵以实现生成多样性。引入了一个新的训练目标，以显式保留流中的语义信息，其特点是高效采样，同时保留语义结构，允许一步分割和分类而无需迭代细化。与以前在掩码和图像之间施加严格一对一映射的方法不同，SymmFlow 概括为灵活的条件设置，支持像素级和图像级类标签。在各种基准测试上的实验结果表明，SymmFlow 在语义图像合成方面取得了最先进的性能，在 CelebAMask-HQ 上 FID 分数为 11.9，在 COCO-Stuff 上为 7.0（仅需 25 个推理步骤）。此外，它在语义分割方面取得了有竞争力的结果，并在分类任务中显示出有前景的能力。代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [483] [GigaVideo-1: Advancing Video Generation via Automatic Feedback with 4 GPU-Hours Fine-Tuning](https://arxiv.org/abs/2506.10639)
> *GigaVideo-1：通过自动反馈和4 GPU小时微调推进视频生成*

*Xiaoyi Bao, Jindi Lv, Xiaofeng Wang, Zheng Zhu, Xinze Chen, YuKun Zhou, Jiancheng Lv, Xingang Wang, Guan Huang* | **Main category: cs.CV**

**Keywords:** 视频生成, 微调, 自动反馈, 扩散模型, GigaVideo-1

**Comment:** 

> **TL;DR:** GigaVideo-1提出了一种高效的视频生成微调框架，利用自动反馈在仅4小时GPU时间内显著提升性能，无需人工标注。

**AI_Comments:** GigaVideo-1的创新之处在于其无需人工标注的自动反馈微调机制，这大大降低了视频生成模型微调的成本和复杂性。它通过弱点导向的数据生成和奖励引导的优化策略，有效地提升了模型在多个维度的表现，且仅需极低的计算资源（4 GPU小时），对于推动视频生成技术的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频生成模型的微调方法依赖于人工标注和大量计算资源，限制了其实用性，且在实例保留、运动合理性、构图和物理真实性等方面仍需改进。

**Method:** 本文提出了GigaVideo-1，一个无需人工监督的视频生成高效微调框架。它通过自动反馈释放预训练视频扩散模型的潜力，专注于数据和优化两个方面。在数据方面，设计了一个提示驱动的数据引擎来构建多样化、面向弱点的训练样本；在优化方面，引入了一种奖励引导的训练策略，利用预训练的视觉-语言模型反馈和真实性约束来自适应地加权样本。

**Result:** GigaVideo-1在VBench-2.0基准上，以Wan2.1为基线，在17个评估维度上进行了评估。实验表明，GigaVideo-1在几乎所有维度上都持续改进了性能，平均增益约为4%，且仅使用了4 GPU小时。

**Conclusion:** GigaVideo-1无需人工标注和最少的真实数据，展示了其在视频生成微调方面的有效性和效率。

> **ai_Abstract:** GigaVideo-1提出了一种无需人工监督且高效的视频生成微调框架。该框架通过自动反馈机制，利用提示驱动的数据引擎生成弱点导向的训练样本，并结合奖励引导的优化策略，显著提升了预训练视频扩散模型的性能。在VBench-2.0基准测试中，GigaVideo-1在仅4 GPU小时的微调下，平均性能提升了约4%，展现了其在效率和效果上的优势。

> **摘要翻译:** 扩散模型在视频生成质量方面取得了巨大进展，但这些模型仍需要微调以改进特定维度，如实例保留、运动合理性、构图和物理真实性。现有微调方法通常依赖于人工标注和大规模计算资源，限制了其实用性。在这项工作中，我们提出了GigaVideo-1，一个无需额外人工监督即可推进视频生成的高效微调框架。GigaVideo-1不是从外部来源注入大量高质量数据，而是通过自动反馈解锁预训练视频扩散模型的潜在能力。具体来说，我们关注微调过程的两个关键方面：数据和优化。为了改进微调数据，我们设计了一个提示驱动的数据引擎，用于构建多样化、面向弱点的训练样本。在优化方面，我们引入了一种奖励引导的训练策略，该策略利用预训练视觉-语言模型的反馈并结合真实性约束来自适应地加权样本。我们使用Wan2.1作为基线，在VBench-2.0基准上对GigaVideo-1进行了评估，涵盖17个评估维度。实验表明，GigaVideo-1在几乎所有维度上都持续改进了性能，平均增益约为4%，仅使用了4 GPU小时。GigaVideo-1无需人工标注和最少的真实数据，展示了其有效性和效率。代码、模型和数据将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [PiPViT: Patch-based Visual Interpretable Prototypes for Retinal Image Analysis](https://arxiv.org/abs/2506.10669)
> *PiPViT：基于图像块的视网膜图像分析视觉可解释原型*

*Marzieh Oghbaie, Teresa Araújoa, Hrvoje Bogunović* | **Main category: cs.CV**

**Keywords:** 视网膜图像分析, 可解释AI, 原型学习, Vision Transformer, OCT图像

**Comment:** 

> **TL;DR:** PiPViT是一种基于ViT的可解释原型模型，用于视网膜图像分析，它学习人类可理解的原型来近似病变范围，并在四个OCT数据集上取得了竞争性性能和更有意义的解释。

**AI_Comments:** 这篇论文的创新点在于将Vision Transformer引入到原型学习中，以解决传统原型方法在医学影像中解释性差和原型粒度过细的问题。通过学习基于图像块的原型并结合对比学习和多分辨率处理，PiPViT不仅提高了模型的可解释性，还能在仅使用图像级标签的情况下近似病变范围，这对于临床诊断具有重要意义。其在保持高性能的同时提供有意义的解释，是医学AI领域的一大进步。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于原型的方法在像素空间中的可视化与人类可理解的生物标志物不一致，并且学习到的原型过于细粒度，在医学影像中解释性较差，无法有效表示生物标志物和病变的出现及程度。

**Method:** 提出PiPViT（Patch-based Visual Interpretable Prototypes），一个固有的可解释的图像识别原型模型。它利用Vision Transformer (ViT) 捕获图像块之间的长程依赖，学习鲁棒、人类可解释的原型，仅使用图像级标签就能近似病变范围。此外，PiPViT还受益于对比学习和多分辨率输入处理，从而实现跨尺度的生物标志物有效定位。

**Result:** PiPViT在四个视网膜OCT图像分类数据集上进行了评估，与最先进的方法相比，它取得了具有竞争力的定量性能，同时提供了更有意义的解释。此外，在独立的测试集上的定量评估证实，所学习的原型在语义和临床上都具有相关性。

**Conclusion:** PiPViT能够透明地解释其决策，并协助临床医生理解诊断结果。

> **ai_Abstract:** PiPViT是一种针对视网膜图像分析提出的可解释原型模型，旨在解决现有原型方法在医学影像中解释性不足的问题。该模型结合了Vision Transformer捕获长程依赖的能力、对比学习和多分辨率处理，使其能够学习到人类可理解且与病变范围相关的原型，仅需图像级标签。在视网膜OCT图像分类任务上的评估表明，PiPViT在保持竞争性性能的同时，提供了更具临床意义的解释，有助于医生理解诊断。

> **摘要翻译:** 背景与目标：基于原型的方法通过学习细粒度的部分原型来提高可解释性；然而，它们在输入像素空间中的可视化并不总是与人类可理解的生物标志物一致。此外，众所周知的基于原型的方法通常学习极其细粒度的原型，这在医学影像中解释性较差，而医学影像中生物标志物和病变的存在及程度都至关重要。
方法：为了解决这些挑战，我们提出了PiPViT（基于图像块的视觉可解释原型），这是一种固有的可解释的图像识别原型模型。PiPViT利用视觉Transformer (ViT) 捕获图像块之间的长程依赖，以学习鲁棒的、人类可解释的原型，仅使用图像级标签就能近似病变范围。此外，PiPViT受益于对比学习和多分辨率输入处理，这使得能够有效定位跨尺度的生物标志物。
结果：我们在四个视网膜OCT图像分类数据集上评估了PiPViT，与最先进的方法相比，它取得了具有竞争力的定量性能，同时提供了更有意义的解释。此外，在独立的测试集上的定量评估证实，所学习的原型在语义和临床上都具有相关性。我们相信PiPViT可以透明地解释其决策，并协助临床医生理解诊断结果。Github页面：https://github.com/marziehoghbaie/PiPViT

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [487] [Enhancing Deepfake Detection using SE Block Attention with CNN](https://arxiv.org/abs/2506.10683)
> *使用SE块注意力与CNN增强Deepfake检测*

*Subhram Dasgupta, Janelle Mason, Xiaohong Yuan, Olusola Odeyomi, Kaushik Roy* | **Main category: cs.CV**

**Keywords:** Deepfake检测, CNN, SE块注意力, 轻量级模型, 数字内容验证

**Comment:** 

> **TL;DR:** 本文提出了一种轻量级CNN模型，结合SE块注意力机制，用于Deepfake检测，该模型在保持高准确率的同时，显著降低了计算资源消耗。

**AI_Comments:** 该研究的创新点在于将SE块注意力机制引入到轻量级CNN中进行Deepfake检测，有效解决了现有模型资源消耗大的问题。其重要性在于为数字内容验证提供了一种高效且实用的方法，尤其适用于资源受限的环境。

<details>
  <summary>Details</summary>

**Motivation:** Deepfake技术利用先进AI制造高度逼真的篡改内容，严重威胁信息真实性和安全性，而现有Deepfake检测模型通常庞大且消耗大量存储和内存。

**Method:** 提出了一种结合Squeeze-and-Excitation (SE) 块注意力的轻量级卷积神经网络 (CNN) 模型。SE块旨在执行动态通道维度特征重新校准，以强调有用特征并抑制不重要特征。该模块与一个简单的顺序模型集成以进行Deepfake检测。

**Result:** 该模型在Deepfake检测任务上实现了与现有模型相当的准确性，且模型尺寸更小。在Style GAN数据集上，分类准确率达到94.14%，AUC-ROC得分为0.985。

**Conclusion:** 所提出的轻量级CNN模型结合SE块注意力，为对抗Deepfake挑战提供了一种有前景的途径，它以最少的计算资源实现了高效且可扩展的数字内容验证解决方案。

> **ai_Abstract:** 本文提出了一种结合Squeeze-and-Excitation (SE) 块注意力的轻量级卷积神经网络 (CNN) 模型，旨在解决Deepfake检测中模型庞大、资源消耗高的问题。该SE块通过动态通道特征重校准，使网络能更有效地学习。实验结果表明，该模型在保持较小尺寸的同时，在Style GAN数据集上取得了94.14%的分类准确率和0.985的AUC-ROC得分，表现出与现有模型相当的性能，为Deepfake检测提供了高效且资源友好的解决方案。

> **摘要翻译:** 在数字时代，Deepfake利用先进的人工智能创造出高度逼真的篡改内容，对信息真实性和安全性构成了严峻挑战。这些复杂的伪造品在复杂性和真实性上超越了传统的检测方法。为了解决这个问题，我们旨在利用尖端深度学习方法来设计一个创新的Deepfake检测模型。然而，大多数用于Deepfake检测的模型都很大，导致存储和内存消耗巨大。在这项研究中，我们提出了一种结合Squeeze-and-Excitation (SE) 块注意力的轻量级卷积神经网络 (CNN) 用于Deepfake检测。SE块模块旨在执行动态通道维度特征重新校准。SE块允许网络强调信息丰富的特征并抑制不太有用的特征，从而形成一个更高效、更有效的学习模块。该模块与一个简单的顺序模型集成以执行Deepfake检测。该模型尺寸更小，并且在Deepfake检测任务上达到了与现有模型相当的准确性。该模型在来自Diverse Fake Face Dataset的Style GAN数据集上实现了94.14%的总体分类准确率和0.985的AUC-ROC得分。我们提出的方法为以最少的计算资源对抗Deepfake挑战提供了一条有前景的途径，开发了用于数字内容验证的高效和可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [490] [Underage Detection through a Multi-Task and MultiAge Approach for Screening Minors in Unconstrained Imagery](https://arxiv.org/abs/2506.10689)
> *非受限图像中基于多任务和多年龄方法的未成年人检测*

*Christopher Gaul, Eduardo Fidalgo, Enrique Alegre, Rocío Alaiz Rodríguez, Eri Pérez Corral* | **Main category: cs.CV**

**Keywords:** 未成年人检测, 多任务学习, 年龄估计, 分布偏移, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种多任务、多年龄模型，用于在非受限图像中准确筛选未成年人，通过改进架构、损失函数和数据采样，显著提高了在挑战性数据集上的未成年人检测性能和泛化能力。

**AI_Comments:** 本文的创新点在于提出了一个结合多任务学习和多年龄分类的架构，并针对未成年人数据稀缺和类别不平衡问题，引入了α-重加权焦点式损失和年龄平衡采样。此外，构建了严格的评估基准，特别是模拟真实世界偏移的ASWIFT-20k数据集，这对于推动该领域的研究具有重要意义。该方法在实际应用中，对于在线内容审核和未成年人保护具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在非受限图像中准确自动筛选未成年人面临模型对分布偏移的鲁棒性不足以及公开数据中儿童代表性不足的问题。

**Method:** 本文提出了一种多任务架构，使用冻结的FaRL视觉-语言骨干网络与紧凑的两层MLP结合，该MLP共享一个年龄回归头和四个二元未成年人头（针对12、15、18和21岁阈值）。为解决严重的类别不平衡问题，引入了α-重加权焦点式损失和年龄平衡的小批量采样。此外，通过年龄间隙移除损失中的边缘情况。提出了“Overall Under-Age Benchmark”数据集，包含303k训练图像和110k测试图像，以及“ASORES-39k”和“ASWIFT-20k”测试集进行严格评估。

**Result:** 在ASORES-39k受限测试集上，模型“F”将均方根误差从5.733（仅年龄基线）降低到5.656年，在1%假成人率下，18岁以下检测的F2分数从0.801提升到0.857。在ASWIFT-20k的领域偏移下，召回率接近0.99，F2分数从0.742提升到0.833。对于12岁以下和15岁以下任务，F2分数分别从0.666提升到0.955和从0.689提升到0.916。

**Conclusion:** 本文提出的多任务、多年龄模型在非受限图像中的未成年人检测方面表现出强大的泛化能力和显著的性能提升，尤其是在处理分布偏移和数据不平衡方面。

> **ai_Abstract:** 本文提出了一种用于非受限图像中未成年人检测的多任务、多年龄方法。该方法采用基于FaRL骨干网络的多任务架构，结合年龄回归和多个二元未成年人分类头。为解决数据不平衡问题，引入了改进的损失函数和年龄平衡采样策略。研究还构建了新的评估基准，并展示了所提模型在未成年人检测精度和泛化能力上的显著提升，尤其是在处理野外数据和分布偏移方面的优越性。

> **摘要翻译:** 在非受限图像中准确自动筛选未成年人，要求模型对分布偏移具有鲁棒性，并能应对公开数据中儿童代表性不足的问题。为了克服这些问题，我们提出了一种多任务架构，该架构具有专门的未成年/超龄判别任务，基于冻结的FaRL视觉-语言骨干网络，并结合一个紧凑的两层MLP，该MLP在年龄回归头和四个二元未成年人头（针对12、15、18和21岁年龄阈值）之间共享特征，重点关注法律上关键的年龄范围。为了解决严重的类别不平衡问题，我们引入了一种α-重加权焦点式损失和年龄平衡的小批量采样，在随机优化过程中平衡了十二个年龄段。通过年龄间隙进一步改进，该间隙从损失中移除了边缘情况。此外，我们通过提出“Overall Under-Age Benchmark”进行了严格的评估，该基准包含303k清理后的训练图像和110k测试图像，定义了移除最嘈杂域的“ASORES-39k”受限整体测试，以及强调极端姿势（>45度）、表情和低图像质量以模拟真实世界偏移的20k图像的年龄估计野外偏移测试“ASWIFT-20k”。在经过重采样和年龄间隙处理的清理后的整体数据集上训练后，我们的多年龄模型“F”在ASORES-39k受限测试集上的均方根误差从5.733（仅年龄基线）降低到5.656年，并在1%假成人率下将18岁以下检测的F2分数从0.801提升到0.857。在ASWIFT-20k野外数据的领域偏移下，相同的配置几乎保持了0.99的召回率，同时相对于仅年龄基线将F2分数从0.742提升到0.833，证明了在分布偏移下的强大泛化能力。对于12岁以下和15岁以下的任务，F2分数分别从0.666提升到0.955和从0.689提升到0.916。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [492] [Continual Hyperbolic Learning of Instances and Classes](https://arxiv.org/abs/2506.10710)
> *实例和类的持续双曲学习*

*Melika Ayoughi, Mina Ghadimi Atigh, Mohammad Mahdi Derakhshani, Cees G. M. Snoek, Pascal Mettes, Paul Groth* | **Main category: cs.CV**

**Keywords:** 持续学习, 双曲学习, 层次化数据, 实例分类, 类泛化

**Comment:** 

> **TL;DR:** 引入了同时进行实例和类持续学习的新任务，并提出了HyperCLIC，一种利用双曲空间处理层次化数据的持续学习算法，实现了多粒度下的有效操作和改进的层次化泛化。

**AI_Comments:** 本文的创新点在于引入了一个全新的持续学习任务，即同时处理实例和类的持续学习，这更贴近现实世界的复杂场景。此外，其将双曲几何引入持续学习领域，利用双曲空间对层次化数据进行建模，有效解决了多粒度下平衡细粒度识别和粗粒度泛化的挑战，为持续学习开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的持续学习侧重于实例或类的单一分类，但机器人和自动驾驶等现实应用需要模型同时处理实例和类。为了反映真实场景，本文引入了同时进行实例和类持续学习的任务，挑战模型适应随时间变化的多粒度数据。

**Method:** 本文提出了HyperCLIC，一种持续学习算法，利用双曲空间来建模类和实例之间自然形成的层次结构。该框架结合了双曲分类和蒸馏目标，以实现层次关系的持续嵌入。

**Result:** 经验结果表明，HyperCLIC能在多个粒度下有效运行，并改进了层次化泛化能力。

**Conclusion:** HyperCLIC成功地解决了同时进行实例和类持续学习的新任务，通过利用双曲空间有效处理了层次化数据，并在多粒度下表现出优异的性能和泛化能力。

> **ai_Abstract:** 本研究提出了一项新的持续学习任务：同时学习实例和类，以满足机器人和自动驾驶等现实世界应用的需求。针对类和实例的层次结构特性，论文提出了HyperCLIC算法，该算法利用双曲空间对层次数据进行建模，并结合双曲分类和蒸馏目标。通过在EgoObjects数据集上的验证，HyperCLIC在多粒度下表现出有效的操作和改进的层次化泛化能力。

> **摘要翻译:** 持续学习传统上专注于对实例或类进行分类，但机器人和自动驾驶汽车等现实世界应用要求模型同时处理两者。为了反映现实生活场景，我们引入了同时进行实例和类持续学习的任务。这项任务挑战模型随着时间推移适应多个粒度级别，这需要平衡细粒度的实例识别与粗粒度的类泛化。在本文中，我们发现类和实例自然形成一个层次结构。为了建模这些层次关系，我们提出了HyperCLIC，一种利用双曲空间的持续学习算法，双曲空间因其能够以低失真和紧凑嵌入来表示树状结构而特别适合层次数据。我们的框架结合了双曲分类和蒸馏目标，从而能够持续嵌入层次关系。为了评估跨多个粒度的性能，我们引入了持续层次度量。我们在EgoObjects上验证了我们的方法，这是唯一捕获动态现实世界环境中层次对象识别复杂性的数据集。经验结果表明，HyperCLIC在多个粒度下有效运行，并改进了层次化泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [494] [Uncertainty-Masked Bernoulli Diffusion for Camouflaged Object Detection Refinement](https://arxiv.org/abs/2506.10712)
> *针对伪装目标检测精修的不确定性掩膜伯努利扩散*

*Yuqi Shen, Fengyang Xiao, Sujie Hu, Youwei Pang, Yifan Pu, Chengyu Fang, Xiu Li, Chunming He* | **Main category: cs.CV**

**Keywords:** 伪装目标检测, 伯努利扩散, 不确定性量化, 生成模型, 后处理精修

**Comment:** 16 pages, 7 figures

> **TL;DR:** 提出UMBD模型，首个用于伪装目标检测(COD)的生成式精修框架，通过不确定性引导的伯努利扩散提升COD性能。

**AI_Comments:** 这篇论文的创新点在于首次将生成式扩散模型应用于伪装目标检测的后处理精修，并引入了不确定性引导的掩膜机制，实现了有针对性的精修。其提出的HUQNet也有效地提升了不确定性估计的准确性，使得模型能够更智能地进行精修。该方法能够与现有COD模型无缝集成，具有良好的通用性和实用价值，为COD领域提供了一个新的精修范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有伪装目标检测方法在后处理精修方面仍有未充分探索的潜力，目标与背景的细微视觉差异导致固有的挑战。

**Method:** 提出不确定性掩膜伯努利扩散(UMBD)模型，首个专为COD设计的生成式精修框架。它引入不确定性引导的掩膜机制，选择性地将伯努利扩散应用于分割质量差的残差区域。为支持此过程，设计了混合不确定性量化网络(HUQNet)，采用多分支架构并融合多源不确定性以提高估计精度，从而在生成采样过程中提供自适应指导。UMBD可与现有编码器-解码器COD模型无缝集成。

**Result:** 在多个COD基准测试中表现出持续的性能改进，平均MAE提升5.5%，加权F-measure提升3.2%，计算开销适中。

**Conclusion:** 提出的UMBD框架通过结合判别式能力和扩散生成优势，显著提升了伪装目标检测的精修效果，且计算开销适中。

> **ai_Abstract:** 本文提出不确定性掩膜伯努利扩散(UMBD)模型，这是首个用于伪装目标检测(COD)的生成式精修框架。UMBD通过不确定性引导的掩膜机制，将伯努利扩散选择性地应用于分割质量差的区域，并设计了混合不确定性量化网络(HUQNet)来提高不确定性估计精度。该框架可与现有COD模型无缝集成，并在多个基准测试中实现了显著的性能提升，同时保持适度的计算开销。

> **摘要翻译:** 伪装目标检测（COD）由于目标与背景之间细微的视觉差异而带来固有的挑战。尽管现有方法取得了显著进展，但在后处理精修方面仍存在尚未充分探索的巨大潜力。为了解决这一局限性，我们提出了不确定性掩膜伯努利扩散（UMBD）模型，这是首个专门为COD设计的生成式精修框架。UMBD引入了一种不确定性引导的掩膜机制，选择性地将伯努利扩散应用于分割质量差的残差区域，从而实现有针对性的精修，同时保留正确分割的区域。为了支持这一过程，我们设计了混合不确定性量化网络（HUQNet），它采用多分支架构并融合来自多个源的不确定性以提高估计精度。这使得在生成采样过程中能够进行自适应指导。所提出的UMBD框架可以与各种现有的基于编码器-解码器的COD模型无缝集成，将它们的判别能力与基于扩散的精修的生成优势相结合。在多个COD基准测试中进行的广泛实验表明，性能持续提升，平均MAE提升5.5%，加权F-measure提升3.2%，而计算开销仅适中。代码将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [497] [IQE-CLIP: Instance-aware Query Embedding for Zero-/Few-shot Anomaly Detection in Medical Domain](https://arxiv.org/abs/2506.10730)
> *IQE-CLIP：用于医学领域零/少样本异常检测的实例感知查询嵌入*

*Hong Huang, Weixiang Sun, Zhijian Wu, Jingwen Niu, Donghuan Lu, Xian Wu, Yefeng Zheng* | **Main category: cs.CV**

**Keywords:** 零样本异常检测, 少样本异常检测, 医疗图像, CLIP, 实例感知查询嵌入

**Comment:** 

> **TL;DR:** IQE-CLIP提出了一种新的框架，通过整合文本和实例感知视觉信息，在医学领域的零/少样本异常检测任务中实现了最先进的性能。

**AI_Comments:** IQE-CLIP的创新之处在于其将实例感知视觉信息融入查询嵌入，以解决传统CLIP方法在医学领域异常检测中区分正常与异常实例的局限性。其引入的类基础和可学习提示标记以及实例感知查询模块，增强了模型对医学图像特性的适应性。该工作对于推动视觉-语言模型在医疗AI领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于CLIP的方法在零/少样本异常检测（ZFSAD）中表现良好，但通常需要先验类别知识和精心设计的提示，并且难以区分正常和异常实例。此外，大多数ZFSAD方法集中在工业领域，在医学任务中的探索有限。

**Method:** 本文提出了IQE-CLIP框架，通过整合文本和实例感知视觉信息来生成更有效的异常指示器。具体来说，引入了基于类别和可学习的提示标记以更好地适应医学设置，并设计了一个实例感知查询模块，从两种模态中提取区域级上下文信息，生成对异常敏感的嵌入。

**Result:** 在六个医学数据集上进行了广泛实验，证明IQE-CLIP在零样本和少样本设置中均实现了最先进的性能。

**Conclusion:** IQE-CLIP通过结合文本和实例感知的视觉信息，显著提升了医学领域零/少样本异常检测的性能，证明了其作为有效异常指示器的潜力。

> **ai_Abstract:** 本文提出了IQE-CLIP，一个用于医学领域零/少样本异常检测的新框架。它解决了现有CLIP方法在区分正常/异常实例以及在医学领域应用受限的问题。IQE-CLIP通过结合文本和实例感知视觉信息生成异常敏感的查询嵌入，并引入了类基础和可学习的提示标记以及实例感知查询模块。实验证明其在六个医学数据集上达到了最先进的性能。

> **摘要翻译:** 视觉-语言模型（如CLIP）的最新进展显著提高了零样本和少样本异常检测（ZFSAD）任务的性能。然而，大多数现有的基于CLIP的方法假设类别先验知识，并依赖于针对特定场景精心设计的提示。虽然这些文本提示在文本空间中捕获语义信息，但它们通常无法在联合嵌入空间中区分正常和异常实例。此外，大多数ZFSAD方法侧重于工业领域，在医学任务中的探索有限。为了解决这些限制，我们提出了IQE-CLIP，一个用于医学领域ZFSAD的新颖框架。我们表明，整合了文本和实例感知视觉信息的查询嵌入可以作为更有效的异常指示器。具体来说，我们引入了基于类别和可学习的提示标记，以更好地使CLIP适应医学环境。此外，我们设计了一个实例感知查询模块，从两种模态中提取区域级上下文信息，从而生成对异常敏感的嵌入。在六个医学数据集上进行的广泛实验表明，IQE-CLIP在零样本和少样本设置中均实现了最先进的性能。代码和数据可在https://github.com/hongh0/IQE-CLIP/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [499] [PosterCraft: Rethinking High-Quality Aesthetic Poster Generation in a Unified Framework](https://arxiv.org/abs/2506.10741)
> *PosterCraft：统一框架下高质量美学海报生成的再思考*

*SiXiang Chen, Jianyu Lai, Jialin Gao, Tian Ye, Haoyu Chen, Hengyu Shi, Shitong Shao, Yunlong Lin, Song Fei, Zhaohu Xing, Yeying Jin, Junfeng Luo, Xiaoming Wei, Lei Zhu* | **Main category: cs.CV**

**Keywords:** 美学海报生成, 统一框架, 文本渲染, 强化学习, 计算机视觉

**Comment:** 

> **TL;DR:** PosterCraft是一个统一的框架，用于生成高质量的美学海报。它通过一个级联工作流优化了文本渲染、布局和整体美学，显著优于现有基线，并接近SOTA商业系统的质量。

**AI_Comments:** PosterCraft的创新之处在于其统一的框架设计，摒弃了传统的模块化和预设布局，允许模型自由探索构图。其级联工作流和自动化数据构建管道是关键，特别是在大规模文本渲染优化和美学文本强化学习方面。该研究的重要性在于其在美学海报生成领域取得了显著进展，提升了生成质量，并为未来的研究提供了新的数据集和方法。

<details>
  <summary>Details</summary>

**Motivation:** 生成美学海报比简单的设计图像更具挑战性，因为它不仅需要精确的文本渲染，还需要抽象艺术内容、引人注目的布局和整体风格和谐的无缝整合。

**Method:** 本文提出了PosterCraft，一个统一的框架，放弃了传统的模块化流水线和僵化的预定义布局。它采用精心设计的级联工作流来优化高美学海报的生成，包括：(i) 在新引入的Text-Render-2M数据集上进行大规模文本渲染优化；(ii) 在HQ-Poster100K上进行区域感知监督微调；(iii) 通过n选1偏好优化进行美学文本强化学习；(iv) 联合视觉-语言反馈细化。每个阶段都由专门定制的自动化数据构建管道支持。

**Result:** 在多项实验中，PosterCraft在渲染准确性、布局连贯性和整体视觉吸引力方面显著优于开源基线，其质量接近最先进的商业系统。

**Conclusion:** PosterCraft通过其统一的框架和级联工作流，有效解决了美学海报生成中的复杂挑战，实现了高质量的输出，并提供了接近商业系统水平的性能。

> **ai_Abstract:** PosterCraft是一个创新的统一框架，旨在解决高质量美学海报生成中的复杂挑战。它摒弃了传统模块化方法和固定布局，通过一个包含文本渲染优化、区域感知微调、美学文本强化学习和视觉-语言反馈细化的级联工作流，实现自由且视觉吸引人的构图。该框架在自动化数据构建管道的支持下，显著提升了渲染准确性、布局连贯性和整体视觉效果，性能超越现有开源基线，并接近顶尖商业系统。

> **摘要翻译:** 生成美学海报比简单的设计图像更具挑战性：它不仅需要精确的文本渲染，还需要抽象艺术内容、引人注目的布局和整体风格和谐的无缝整合。为了解决这个问题，我们提出了PosterCraft，一个统一的框架，它放弃了先前的模块化流水线和僵化的预定义布局，允许模型自由探索连贯、视觉上引人注目的构图。PosterCraft采用精心设计的级联工作流来优化高美学海报的生成：(i) 在我们新引入的Text-Render-2M数据集上进行大规模文本渲染优化；(ii) 在HQ-Poster100K上进行区域感知监督微调；(iii) 通过n选1偏好优化进行美学文本强化学习；(iv) 联合视觉-语言反馈细化。每个阶段都由专门定制的完全自动化数据构建管道支持，无需复杂的架构修改即可实现稳健训练。在多项实验中，PosterCraft在渲染准确性、布局连贯性和整体视觉吸引力方面显著优于开源基线，其质量接近最先进的商业系统。我们的代码、模型和数据集可在项目页面找到：https://ephemeral182.github.io/PosterCraft

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [501] [Stroke-based Cyclic Amplifier: Image Super-Resolution at Arbitrary Ultra-Large Scales](https://arxiv.org/abs/2506.10774)
> *基于笔画的循环放大器：任意超大尺度图像超分辨率*

*Wenhao Guo, Peng Lu, Xujun Peng, Zhaoran Zhao, Sheng Li* | **Main category: cs.CV**

**Keywords:** 图像超分辨率, 任意尺度, 超大尺度, 笔画分解, 循环放大

**Comment:** 

> **TL;DR:** 提出了一种名为Stroke-based Cyclic Amplifier (SbCA)的统一模型，用于解决现有任意尺度图像超分辨率方法在超大尺度放大时性能显著下降的问题。SbCA通过将图像分解为笔画并迭代细化细节，实现了高质量的超大尺度图像超分辨率，并在实验中显著优于现有方法。

**AI_Comments:** 该论文提出了一种新颖的基于笔画分解的图像超分辨率方法，创新性地将图像视为可放大的矢量图形，并通过循环策略实现了任意超大尺度的上采样，有效解决了现有方法在大放大倍数下的性能瓶颈，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的任意尺度图像超分辨率（ASISR）方法在放大因子超出训练数据范围时，性能会显著下降，并引入大量模糊。

**Method:** 本文提出了一种统一模型Stroke-based Cyclic Amplifier (SbCA)，其核心是笔画向量放大器，将图像分解为一系列表示为矢量图形的笔画进行放大。随后，细节补全模块恢复缺失细节。通过循环策略，SbCA模型迭代细化细节以实现超大尺度上采样，且只需训练一次即可适用于所有子尺度，同时保持子尺度在训练范围内。

**Result:** 该方法有效解决了分布漂移问题，消除了伪影、噪声和模糊，生成了高质量、高分辨率的超分辨率图像。在合成和真实世界数据集上的实验验证表明，该方法在超大尺度上采样任务（例如×100）中显著优于现有方法，提供了远超现有技术的视觉质量。

**Conclusion:** SbCA模型通过其独特的笔画分解和循环细化策略，成功解决了任意超大尺度图像超分辨率的挑战，实现了卓越的图像质量，超越了现有技术水平。

> **ai_Abstract:** 本文提出了一种名为Stroke-based Cyclic Amplifier (SbCA) 的统一模型，旨在解决现有任意尺度图像超分辨率方法在超大尺度放大时性能显著下降的问题。SbCA通过将图像分解为笔画向量进行放大，并结合细节补全模块，确保高保真重建。其独特的循环策略允许模型在一次训练后，通过迭代细化实现任意超大尺度的上采样。实验证明，SbCA在超大尺度任务（如×100）中显著优于现有技术，生成高质量、无伪影的超分辨率图像。

> **摘要翻译:** 先前的任意尺度图像超分辨率（ASISR）方法在放大因子超出训练数据范围时，性能常会显著下降，引入大量模糊。为解决此问题，我们提出了一种统一模型——基于笔画的循环放大器（SbCA），用于超大尺度上采样任务。SbCA的关键在于笔画向量放大器，它将图像分解为一系列表示为矢量图形的笔画进行放大。然后，细节补全模块也恢复缺失的细节，确保高保真图像重建。我们的循环策略通过使用这个统一的SbCA模型迭代细化细节来实现超大尺度上采样，该模型只需训练一次即可用于所有子尺度，同时将子尺度保持在训练范围内。我们的方法有效解决了分布漂移问题，消除了伪影、噪声和模糊，生成高质量、高分辨率的超分辨率图像。在合成和真实世界数据集上的实验验证表明，我们的方法在超大尺度上采样任务（例如×100）中显著优于现有方法，提供的视觉质量远超现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [503] [SlotPi: Physics-informed Object-centric Reasoning Models](https://arxiv.org/abs/2506.10778)
> *SlotPi: 物理信息对象中心推理模型*

*Jian Li, Wan Han, Ning Lin, Yu-Liang Zhan, Ruizhi Chengze, Haining Wang, Yi Zhang, Hongsheng Liu, Zidong Wang, Fan Yu, Hao Sun* | **Main category: cs.CV**

**Keywords:** 物理信息, 对象中心推理, 动态预测, 哈密顿原理, 流体动力学

**Comment:** 

> **TL;DR:** SlotPi是一个基于槽位的物理信息对象中心推理模型，它结合了哈密顿原理和时空预测模块，用于理解和预测复杂的物理动态，并在各种数据集上表现出强大的适应性。

**AI_Comments:** 这篇论文的创新点在于将物理知识（特别是哈密顿原理）整合到对象中心推理模型中，这有助于模型更好地理解和预测复杂的物理动态，尤其是流体和物体交互。同时，通过创建新的真实世界数据集并在此上验证模型，强调了其在多样化场景下的鲁棒性和适应性，为构建更接近人类认知的世界模型提供了有益探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有对象中心动态模拟方法忽视了物理知识的整合以及模型在多样化场景中的适应性验证，尤其是在涉及流体和物体交互的真实世界动态中。

**Method:** 引入SlotPi，一个基于槽位的物理信息对象中心推理模型。它将基于哈密顿原理的物理模块与用于动态预测的时空预测模块相结合。

**Result:** 模型在基准和流体数据集的预测和视觉问答(VQA)任务中表现出色。此外，还在包含物体交互、流体动力学和流体-物体交互的真实世界数据集上验证了模型的性能。

**Conclusion:** SlotPi在所有数据集上的强大性能强调了其强大的适应性，为开发更先进的世界模型奠定了基础。

> **ai_Abstract:** SlotPi是一种新颖的基于槽位的物理信息对象中心推理模型，旨在解决现有动态模拟方法中物理知识整合不足和跨场景适应性差的问题。它通过结合基于哈密顿原理的物理模块和时空预测模块，能够理解和预测复杂的物理动态，包括流体与物体的交互。实验证明，SlotPi在预测和VQA任务上，以及在自建的真实世界数据集上均表现出强大的性能和适应性，为未来世界模型的发展奠定了基础。

> **摘要翻译:** 理解和推理受物理定律支配的动态，通过视觉观察，类似于人类在现实世界中的能力，带来了巨大的挑战。目前，模仿人类行为的以对象为中心的动态模拟方法取得了显著进展，但忽略了两个关键方面：1）将物理知识整合到模型中。人类通过观察世界获得物理洞察力，并将这些知识应用于准确推理各种动态场景；2）验证模型在不同场景中的适应性。现实世界的动态，特别是涉及流体和物体的动态，要求模型不仅能捕捉物体交互，还能模拟流体流动特性。为了解决这些空白，我们引入了SlotPi，一个基于槽位的物理信息对象中心推理模型。SlotPi将基于哈密顿原理的物理模块与用于动态预测的时空预测模块相结合。我们的实验强调了模型在基准和流体数据集上的预测和视觉问答（VQA）等任务中的优势。此外，我们创建了一个包含物体交互、流体动力学和流体-物体交互的真实世界数据集，并在该数据集上验证了我们模型的能力。模型在所有数据集上的强大性能突显了其强大的适应性，为开发更先进的世界模型奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [505] [Human-Robot Navigation using Event-based Cameras and Reinforcement Learning](https://arxiv.org/abs/2506.10790)
> *基于事件相机的强化学习人机导航*

*Ignacio Bugueno-Cordova, Javier Ruiz-del-Solar, Rodrigo Verschae* | **Main category: cs.CV**

**Keywords:** 事件相机, 强化学习, 机器人导航, 避障, 人机交互

**Comment:** https://ibugueno.github.io/hr-navigation-using-event-cameras-and-rl/

> **TL;DR:** 本文提出了一种结合事件相机和强化学习的机器人导航控制器，实现了实时以人为中心的导航和避障。

**AI_Comments:** 该论文的创新点在于将事件相机（其异步特性有助于克服传统相机的运动模糊和延迟问题）与强化学习相结合，应用于机器人导航。通过结合模仿学习，提高了样本效率，这是强化学习应用中的一个重要考量。然而，目前的结果仅在模拟环境中验证，未来需要进行真实世界的实验来进一步验证其有效性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于图像的控制器存在固定帧率、运动模糊和延迟等问题。本文旨在利用事件相机的异步特性来处理视觉信息，实现自适应推理和控制，从而克服这些限制，实现以人为中心的实时导航和避障。

**Method:** 该方法结合了事件相机和其他传感器与强化学习，形成一个机器人导航控制器。具体而言，它整合了基于事件的感知、额外的测距传感，并通过深度确定性策略梯度（Deep Deterministic Policy Gradient, DDPG）进行策略优化，同时引入了初始的模仿学习阶段以提高样本效率。

**Result:** 在模拟环境中取得了可喜的成果，展示了鲁棒的导航、行人跟随和避障能力。

**Conclusion:** 该研究成功地将事件相机与强化学习相结合，开发出一种能够进行实时、自适应以人为中心导航和避障的机器人控制器，并在模拟环境中验证了其有效性。

> **ai_Abstract:** 本文提出了一种新颖的机器人导航控制器，该控制器将事件相机和其他传感器与强化学习相结合，以实现实时的以人为中心的导航和避障。与传统的基于图像的系统相比，该方法利用事件相机的异步特性，克服了运动模糊和延迟的限制，实现了自适应的视觉信息处理和控制。该框架集成了基于事件的感知、测距传感和通过DDPG进行的策略优化，并通过模仿学习提高了样本效率。在模拟环境中，该控制器展示了强大的导航、行人跟随和避障性能。

> **摘要翻译:** 这项工作引入了一种机器人导航控制器，它结合了事件相机和其他传感器与强化学习，以实现实时以人为中心的导航和避障。与传统的基于图像的控制器不同，后者以固定速率运行并受运动模糊和延迟的影响，这种方法利用事件相机的异步特性，在灵活的时间间隔内处理视觉信息，从而实现自适应推理和控制。该框架整合了基于事件的感知、额外的测距传感，并通过深度确定性策略梯度进行策略优化，并辅以初始的模仿学习阶段以提高样本效率。在模拟环境中取得了可喜的成果，展示了鲁棒的导航、行人跟随和避障能力。项目网站上提供了演示视频。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [507] [Prompts to Summaries: Zero-Shot Language-Guided Video Summarization](https://arxiv.org/abs/2506.10807)
> *提示到摘要：零样本语言引导的视频摘要*

*Mario Barbara, Alaa Maalouf* | **Main category: cs.CV**

**Keywords:** 零样本, 视频摘要, 语言模型, 多模态, 提示工程

**Comment:** 

> **TL;DR:** 本文提出了一种名为 Prompts-to-Summaries 的零样本、文本可查询视频摘要器，它利用现成的视频语言模型和大型语言模型，无需训练数据即可生成用户引导的视频摘要，性能超越所有无监督方法并与有监督方法相媲美。

**AI_Comments:** 该论文的创新点在于提出了首个零样本、文本可查询的视频摘要器，彻底摆脱了对训练数据的依赖，解决了现有方法泛化性差和无法整合用户意图的痛点。其核心思想是巧妙地结合了预训练的视频语言模型和大型语言模型的能力，通过精心设计的提示和分数传播机制，实现了高效且高质量的视频摘要。这一方法为视频摘要领域提供了一个全新的范式，证明了预训练多模态模型在无需微调的情况下处理复杂任务的巨大潜力，为未来的研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 视频数据的爆炸式增长使得对灵活、用户可控且无需领域特定训练数据的摘要工具的需求日益增加。现有方法要么依赖数据集，限制了泛化能力，要么无法整合自然语言表达的用户意图。

**Method:** 本文提出 Prompts-to-Summaries，一个零样本、文本可查询的视频摘要器。其管道包括：(i) 将原始视频素材分割成连贯的场景；(ii) 通过内存高效的批处理式 VidLM 提示方案生成丰富的场景级描述；(iii) 利用大型语言模型（LLM）作为判断器，在精心设计的提示下分配场景级重要性分数；(iv) 通过一致性（时间连贯性）和独特性（新颖性）两个新指标将分数传播到短片段级别，从而获得细粒度的帧重要性。

**Result:** 在 SumMe 和 TVSum 数据集上，该无数据方法超越了所有先前依赖数据的无监督方法。在 Query-Focused Video Summarization (QFVS) 基准测试中，尽管未使用训练数据且竞争方法需要有监督的帧级重要性，但其表现仍具竞争力。此外，作者发布了一个新的查询驱动数据集 VidSum-Reason，并在此数据集上获得了稳健的 F1 分数。

**Conclusion:** 研究结果表明，预训练的多模态模型，当与原则性提示和分数传播相结合时，已经为通用、文本可查询的视频摘要提供了强大的基础。

> **ai_Abstract:** 本文提出了一种名为 Prompts-to-Summaries 的创新方法，旨在实现零样本、语言引导的视频摘要。该方法利用现成的视频语言模型（VidLMs）生成场景描述，并结合大型语言模型（LLMs）作为判断器来评估场景重要性，最终通过新颖的分数传播机制生成细粒度的帧重要性。该框架无需任何训练数据，在多个标准视频摘要数据集上，其性能超越了所有无监督方法，并与有监督方法表现相当。此外，论文还发布了一个新的查询驱动数据集 VidSum-Reason，以推动该领域的进一步研究。

> **摘要翻译:** 视频数据的爆炸式增长加剧了对灵活、用户可控且无需领域特定训练数据的摘要工具的需求。现有方法要么依赖数据集，限制了泛化能力，要么无法整合自然语言表达的用户意图。我们引入了 Prompts-to-Summaries：第一个零样本、文本可查询的视频摘要器，它通过大型语言模型（LLM）的判断，将现成的视频语言模型（VidLM）的字幕转换为用户引导的摘要，完全无需使用训练数据，其性能超越所有无监督方法并与有监督方法相媲美。我们的管道包括：(i) 将原始视频素材分割成连贯的场景；(ii) 通过内存高效的批处理式 VidLM 提示方案生成丰富的场景级描述，该方案可在单个 GPU 上扩展到数小时长的视频；(iii) 利用 LLM 作为判断器，在精心设计的提示下分配场景级重要性分数；最后，(iv) 通过两个新指标：一致性（时间连贯性）和独特性（新颖性），将这些分数传播到短片段级别，从而获得细粒度的帧重要性。在 SumMe 和 TVSum 数据集上，我们的无数据方法超越了所有先前依赖数据的无监督方法。尽管未使用训练数据且竞争方法需要有监督的帧级重要性，但它在查询聚焦视频摘要（QFVS）基准测试中也表现出色。为了促进进一步研究，我们发布了 VidSum-Reason，一个包含长尾概念和多步推理的新型查询驱动数据集；我们的框架获得了稳健的 F1 分数，并作为第一个具有挑战性的基线。总的来说，我们的结果表明，预训练的多模态模型，当与原则性提示和分数传播相结合时，已经为通用、文本可查询的视频摘要提供了强大的基础。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [511] [Occlusion-Aware 3D Hand-Object Pose Estimation with Masked AutoEncoders](https://arxiv.org/abs/2506.10816)
> *基于掩码自编码器的遮挡感知三维手物姿态估计*

*Hui Yang, Wei Sun, Jian Liu, Jin Zheng, Jian Xiao, Ajmal Mian* | **Main category: cs.CV**

**Keywords:** 手物姿态估计, 遮挡感知, 掩码自编码器, 有符号距离场, 点云

**Comment:** 10 pages, 6 figures

> **TL;DR:** 本文提出HOMAE，一种基于掩码自编码器的遮挡感知方法，用于解决手物交互中严重遮挡导致的三维手物姿态估计难题，通过目标聚焦掩码策略、SDF与点云融合，实现了最先进的性能。

**AI_Comments:** 该论文的关键创新在于引入了目标聚焦掩码策略，这是一种新颖的自监督学习机制，专门用于处理手物交互中的复杂遮挡。通过结合隐式SDF和显式点云，该方法有效地融合了全局上下文和局部几何细节，显著提升了在严重遮挡情况下的鲁棒性。其在SOTA性能上的表现证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 单目RGB图像中的手物姿态估计因手物交互中严重的遮挡而面临巨大挑战。现有方法未能充分探索全局结构感知和推理，限制了其在处理遮挡手物交互时的有效性。

**Method:** 本文提出HOMAE，一种基于掩码自编码器的遮挡感知手物姿态估计方法。具体包括：1) 目标聚焦掩码策略，对交互区域施加结构化遮挡，促使模型学习上下文感知特征并推断遮挡结构。2) 整合解码器提取的多尺度特征以预测有符号距离场（SDF），捕获全局上下文和细粒度几何。3) 将隐式SDF与显式点云结合，利用两者互补优势，增强对遮挡区域的处理能力。

**Result:** 在DexYCB和HO3Dv2等挑战性基准测试中，HOMAE实现了手物姿态估计的最先进性能。

**Conclusion:** HOMAE通过其创新的遮挡感知机制和多模态几何表示融合，有效解决了手物交互中的严重遮挡问题，并在三维手物姿态估计中取得了领先成果。

> **ai_Abstract:** 本文提出HOMAE，一种基于掩码自编码器的遮挡感知方法，用于解决单目RGB图像中手物交互的严重遮挡问题。HOMAE引入目标聚焦掩码策略，鼓励模型学习上下文感知特征和推断遮挡结构。它还通过整合多尺度特征预测有符号距离场（SDF），并将其与显式点云融合，以捕捉全局上下文和精确局部几何。在DexYCB和HO3Dv2数据集上的广泛实验表明，HOMAE在手物姿态估计方面达到了最先进的性能。

> **摘要翻译:** 从单目RGB图像中估计手物姿态仍然是一个重大挑战，这主要是由于手物交互中固有的严重遮挡。现有方法未能充分探索全局结构感知和推理，这限制了它们在处理遮挡手物交互时的有效性。为了解决这一挑战，我们提出了一种基于掩码自编码器的遮挡感知手物姿态估计方法，命名为HOMAE。具体来说，我们提出了一种目标聚焦掩码策略，该策略对手物交互区域施加结构化遮挡，鼓励模型学习上下文感知特征并推断遮挡结构。我们进一步整合从解码器中提取的多尺度特征来预测有符号距离场（SDF），捕获全局上下文和细粒度几何。为了增强几何感知，我们将隐式SDF与从SDF导出的显式点云相结合，利用两种表示的互补优势。这种融合通过将SDF的全局上下文与点云提供的精确局部几何相结合，从而实现对遮挡区域更鲁棒的处理。在具有挑战性的DexYCB和HO3Dv2基准测试中进行的广泛实验表明，HOMAE在手物姿态估计方面取得了最先进的性能。我们将发布我们的代码和模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [513] [VideoDeepResearch: Long Video Understanding With Agentic Tool Using](https://arxiv.org/abs/2506.10821)
> *VideoDeepResearch：使用代理工具进行长视频理解*

*Huaying Yuan, Zheng Liu, Junjie Zhou, Ji-Rong Wen, Zhicheng Dou* | **Main category: cs.CV**

**Keywords:** 长视频理解, 代理系统, 多模态工具, 大型推理模型, VideoDeepResearch

**Comment:** 

> **TL;DR:** VideoDeepResearch是一个新颖的代理框架，它结合了文本推理模型和多模态工具包，以解决长视频理解（LVU）的挑战，并在多个基准测试中超越了现有MLLM基线。

**AI_Comments:** VideoDeepResearch的创新之处在于它挑战了现有范式，即认为解决长视频理解问题必须依赖于具有巨大上下文窗口的“大而全”MLLM。相反，它提出了一种更模块化、更具代理性的方法，通过将文本推理模型与可插拔的多模态工具相结合，实现了高效且高性能的长视频理解。这种“小模型+工具”的范式可能为未来多模态AI系统的设计提供新的思路，尤其是在资源受限或需要更高灵活性和可解释性的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态大型语言模型（MLLM）在处理长视频理解（LVU）任务时面临显著挑战，这主要由于任务的固有复杂性和上下文窗口限制。普遍认为解决LVU任务需要具有扩展上下文窗口、强大视觉感知能力和熟练领域专业知识的基础MLLM，本研究旨在挑战这一普遍观点。

**Method:** 本研究提出了VideoDeepResearch，一个新颖的代理框架，用于长视频理解。该方法仅依赖于一个文本推理模型（LRM）与一个模块化的多模态工具包（包括多模态检索器和视觉感知器）相结合，所有这些工具在实践中都易于获得。对于每个LVU任务，系统通过推理制定问题解决策略，同时通过工具使用选择性地访问和利用必要的视频内容。

**Result:** VideoDeepResearch在流行LVU基准测试（包括MLVU、Video-MME和LVBench）中进行了广泛实验。结果表明，它在MLVU（测试集）、LVBench和LongVideoBench上分别比现有MLLM基线实现了9.6%、6.6%和3.9%的显著改进，超越了之前的最新技术水平。

**Conclusion:** 这些发现突显了代理系统在克服长视频理解（LVU）问题中关键挑战方面的潜力。

> **ai_Abstract:** 本研究提出了VideoDeepResearch，一个新颖的代理框架，旨在解决长视频理解（LVU）中多模态大型语言模型（MLLM）面临的挑战。与依赖大型MLLM的传统观点不同，VideoDeepResearch结合了一个文本推理模型和可用的多模态工具包，通过推理制定策略并选择性地利用视频内容。实验结果表明，该框架在多个LVU基准测试中显著优于现有MLLM基线，证明了代理系统在LVU问题中的有效性。

> **摘要翻译:** 长视频理解（LVU）对当前多模态大型语言模型（MLLM）构成了重大挑战，原因在于任务固有的复杂性和上下文窗口限制。人们普遍认为，解决LVU任务需要具备扩展上下文窗口、强大视觉感知能力和熟练领域专业知识的基础MLLM。在这项工作中，我们通过引入VideoDeepResearch，一个用于长视频理解的新颖代理框架，挑战了这一普遍观念。我们的方法仅依赖于一个纯文本的大型推理模型（LRM），结合一个模块化的多模态工具包，包括多模态检索器和视觉感知器，所有这些在实践中都易于获得。对于每个LVU任务，系统通过推理制定问题解决策略，同时通过工具使用选择性地访问和利用必要的视频内容。我们在流行的LVU基准测试（包括MLVU、Video-MME和LVBench）上进行了广泛实验。我们的结果表明，VideoDeepResearch在现有MLLM基线上取得了显著改进，在MLVU（测试集）、LVBench和LongVideoBench上分别超越了之前的最新技术水平9.6%、6.6%和3.9%。这些发现突显了代理系统在克服LVU问题中关键挑战方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [515] [Post-Training Quantization for Video Matting](https://arxiv.org/abs/2506.10840)
> *视频抠图的训练后量化*

*Tianrui Zhu, Houyuan Chen, Ruihao Gong, Michele Magno, Haotong Qin, Kai Zhang* | **Main category: cs.CV**

**Keywords:** 视频抠图, 训练后量化, 模型压缩, 量化参数校准, 光流辅助

**Comment:** 

> **TL;DR:** 提出了一种新颖的训练后量化（PTQ）框架（PTQ4VM），用于视频抠图模型，通过两阶段策略、全局仿射校准和光流辅助，实现了在资源受限设备上部署视频抠图模型的近全精度性能和显著计算节省。

**AI_Comments:** 这篇论文通过引入一个专门为视频抠图设计的系统性训练后量化（PTQ）框架，展现了显著的创新性。其亮点在于结合了多方面的优化策略：两阶段量化保证了稳定性和精度，GAC有效补偿了量化带来的统计失真，而OFA则巧妙地利用了视频的时间信息来提升量化性能。这些方法的结合使得PTQ在视频抠图这一复杂任务上实现了突破，尤其是在超低比特量化下仍能保持高精度，这对于实际部署在边缘设备上具有重要意义。该工作填补了视频抠图领域PTQ的空白，并为未来的模型压缩研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 视频抠图模型计算量大，难以部署在资源受限设备上。训练后量化（PTQ）作为一种模型压缩和加速技术，在视频抠图领域仍处于初期阶段，面临保持精度和时间一致性的挑战。

**Method:** 本文提出了一个新颖且通用的视频抠图模型训练后量化（PTQ）框架。其贡献包括：1. 两阶段PTQ策略，结合基于块重建的优化（用于快速、稳定的初始量化和局部依赖捕获），然后对量化参数进行全局校准以最小化精度损失。2. 统计驱动的全局仿射校准（GAC）方法，使网络能够补偿由忽略BN层效应等因素引起的累积统计失真，甚至将现有PTQ方法在视频抠图任务上的误差减少高达20%。3. 光流辅助（OFA）组件，利用帧的时间和语义先验来指导PTQ过程，增强模型在复杂场景中区分移动前景的能力，即使在超低比特量化下也能实现接近全精度的性能。

**Result:** 本文提出的PTQ4VM在不同比特宽度下，相比现有量化方法，实现了最先进的精度性能。特别是，4比特的PTQ4VM性能接近全精度模型，同时实现了8倍的FLOPs节省。

**Conclusion:** 本文提出的PTQ4VM框架有效解决了视频抠图模型在资源受限设备上部署的挑战，通过创新的量化策略和组件，实现了高精度和显著的计算效率提升。

> **ai_Abstract:** 本文针对视频抠图模型在资源受限设备上部署的挑战，提出了首个系统性的训练后量化（PTQ）框架PTQ4VM。该框架包含两阶段PTQ策略、统计驱动的全局仿射校准（GAC）和光流辅助（OFA）组件。实验结果表明，PTQ4VM在保持高精度的同时显著降低了计算成本，尤其在4比特量化下实现了接近全精度的性能并节省了8倍的FLOPs。

> **摘要翻译:** 视频抠图对于电影制作和虚拟现实等应用至关重要，但将计算密集型模型部署到资源受限设备上带来了挑战。量化是模型压缩和加速的关键技术。作为一种高效的方法，训练后量化（PTQ）在视频抠图领域仍处于起步阶段，在保持精度和时间一致性方面面临重大障碍。为了解决这些挑战，本文提出了一种新颖且通用的专门为视频抠图模型设计的PTQ框架，据我们所知，这是该领域首次系统的尝试。我们的贡献包括：(1) 两阶段PTQ策略，结合基于块重建的优化以实现快速、稳定的初始量化和局部依赖捕获，随后进行量化参数的全局校准以最小化精度损失。(2) 一种统计驱动的全局仿射校准（GAC）方法，使网络能够补偿由忽略BN层效应等因素引起的累积统计失真，甚至将现有PTQ方法在视频抠图任务上的误差降低高达20%。(3) 光流辅助（OFA）组件，利用帧的时间和语义先验来指导PTQ过程，增强模型在复杂场景中区分移动前景的能力，最终即使在超低比特量化下也能实现接近全精度的性能。全面的定量和视觉结果表明，与现有量化方法相比，我们的PTQ4VM在不同比特宽度下均实现了最先进的精度性能。我们强调，4比特的PTQ4VM甚至实现了接近全精度对应模型的性能，同时享受8倍的FLOPs节省。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [VRBench: A Benchmark for Multi-Step Reasoning in Long Narrative Videos](https://arxiv.org/abs/2506.10857)
> *VRBench：长叙事视频中的多步推理基准*

*Jiashuo Yu, Yue Wu, Meng Chu, Zhifei Ren, Zizheng Huang, Pei Chu, Ruijie Zhang, Yinan He, Qirui Li, Songze Li, Zhenxiang Li, Zhongying Tu, Conghui He, Yu Qiao, Yali Wang, Yi Wang, Limin Wang* | **Main category: cs.CV**

**Keywords:** VRBench, 多步推理, 长叙事视频, 基准, 大模型评估

**Comment:** Technical Report

> **TL;DR:** VRBench是一个新的长叙事视频基准，用于评估大型模型的多步推理能力，解决了现有评估中忽视时间推理和程序有效性的问题。它包含1010个长视频、9468个人工标注的多步问答对和30292个带有时间戳的推理步骤。

**AI_Comments:** VRBench的创新之处在于其首次为长叙事视频中的多步推理提供了大规模基准，填补了现有评估的空白。它通过引入时间推理和过程有效性评估，提高了对大型模型理解复杂叙事能力的衡量标准。人机协作框架和多阶段评估管道的设计也十分巧妙，特别是LLM引导的进度级评分指标，为评估推理过程提供了更细致的方法。这项工作对于推动视频理解和多模态推理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型模型评估在多步推理方面存在局限性，特别是忽视了时间推理和过程有效性。为了解决这些问题，本研究提出了VRBench。

**Method:** VRBench是一个包含1010个平均时长1.6小时的长视频的基准，配有9468个多步问答对和30292个带时间戳的推理步骤。视频通过多阶段过滤（包括专家互评）以确保情节连贯性。研究开发了一个人机协作框架来生成连贯的推理链，这些推理链需要多个时间定位的步骤，涵盖七种类型。VRBench设计了一个多阶段评估流程，从结果和过程层面评估模型。除了最终结果的MCQ，还提出了一个由LLM引导的进度级评分指标，以多维度全面评估推理链的质量。

**Result:** 通过对VRBench上的12个LLM和16个VLM进行广泛评估，本研究进行了深入分析，并提供了宝贵的见解。

**Conclusion:** VRBench的提出及其评估结果，旨在推动多步推理领域的发展。

> **ai_Abstract:** VRBench是首个专为评估大型模型在长叙事视频中多步推理能力而设计的基准。它旨在解决现有评估中对时间推理和过程有效性的忽视。VRBench包含1010个长视频，配有9468个多步问答对和30292个带时间戳的推理步骤，这些数据经过精心策划以确保情节连贯性。研究开发了一个人机协作框架来生成多步推理链，并设计了一个多阶段评估流程，结合MCQ和LLM引导的评分指标来全面评估模型。通过对12个LLM和16个VLM的广泛评估，VRBench提供了有价值的见解，以推动多步推理领域的发展。

> **摘要翻译:** 我们提出了VRBench，这是第一个为评估大型模型多步推理能力而精心制作的长叙事视频基准，解决了现有评估中忽视时间推理和程序有效性的局限性。它包括1010个长视频（平均时长1.6小时），以及9468个人工标注的多步问答对和30292个带有时间戳的推理步骤。这些视频通过多阶段过滤过程进行整理，包括专家互评以优先考虑情节连贯性。我们开发了一个人机协作框架，用于生成连贯的推理链，每个推理链都需要多个时间定位的步骤，涵盖七种类型（例如，事件归因、隐式推理）。VRBench设计了一个多阶段评估流程，从结果和过程层面评估模型。除了最终结果的MCQ，我们还提出了一种进度级LLM引导的评分指标，以多维度全面评估推理链的质量。通过对VRBench上的12个LLM和16个VLM进行广泛评估，我们进行了彻底的分析并提供了宝贵的见解，从而推动了多步推理领域的发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [519] [CreatiPoster: Towards Editable and Controllable Multi-Layer Graphic Design Generation](https://arxiv.org/abs/2506.10890)
> *CreatiPoster：迈向可编辑和可控的多层图形设计生成*

*Zhao Zhang, Yutao Cheng, Dexiang Hong, Maoke Yang, Gonglei Shi, Lei Ma, Hui Zhang, Jie Shao, Xinglong Wu* | **Main category: cs.CV**

**Keywords:** 图形设计, 多层生成, 可编辑性, AI辅助设计, CreatiPoster

**Comment:** 

> **TL;DR:** CreatiPoster是一个新的AI框架，可以根据文本指令或资产生成可编辑的多层图形设计，解决了现有AI工具在用户资产整合、可编辑性和专业视觉效果方面的不足，并优于现有方法。

**AI_Comments:** CreatiPoster的创新之处在于其独特的分层生成方法，特别是协议模型生成JSON规范的机制，这使得输出具有高度的可编辑性和可控性，解决了现有AI工具的痛点。其发布的大规模无版权数据集对社区具有重要贡献，有望加速该领域的研究。该系统在商业和个人应用中具有巨大的潜力，能够显著降低图形设计的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 高质量、可编辑且美观的图形设计耗时且需要技巧，尤其是对初学者。现有AI工具难以准确整合用户资产、保持可编辑性并达到专业视觉效果，而商业系统依赖难以复制的模板库。

**Method:** 我们引入了CreatiPoster框架，它通过一个协议模型（RGBA大型多模态模型）首先生成一个详细说明每个层（文本或资产）的JSON规范，包括布局、层次、内容、风格和背景提示。然后，一个条件背景模型根据渲染的前景层合成一个连贯的背景。

**Result:** 我们构建了一个图形设计生成的基准测试，并使用自动化指标，结果表明CreatiPoster超越了领先的开源方法和专有商业系统。我们还发布了一个包含10万个多层设计的无版权语料库。

**Conclusion:** CreatiPoster通过生成可编辑的多层设计，支持多种应用，如画布编辑、文本叠加、响应式调整大小、多语言适应和动画海报，从而推动了AI辅助图形设计的普及。

> **ai_Abstract:** CreatiPoster是一个新颖的AI框架，旨在解决图形设计中创建高质量、可编辑多层作品的挑战。它通过一个协议模型生成详细的JSON规范，再由背景模型合成背景，从而实现了从自然语言指令或资产生成可编辑设计。该框架在性能上超越了现有开源和商业系统，并通过发布大规模数据集促进了研究。CreatiPoster支持多种应用，有效推动了AI辅助图形设计的民主化。

> **摘要翻译:** 图形设计在商业和个人环境中都扮演着至关重要的角色，然而，创建高质量、可编辑且美观的图形作品仍然是一项耗时且需要技巧的任务，特别是对于初学者而言。当前的AI工具自动化了部分工作流程，但在准确整合用户提供的资产、保持可编辑性以及实现专业视觉吸引力方面仍面临挑战。像Canva Magic Design这样的商业系统依赖于庞大的模板库，这对于复制来说是不切实际的。在本文中，我们介绍了CreatiPoster，一个可以根据可选的自然语言指令或资产生成可编辑、多层作品的框架。一个协议模型，即一个RGBA大型多模态模型，首先生成一个JSON规范，详细说明每个层（文本或资产）的精确布局、层次、内容和风格，以及一个简洁的背景提示。然后，一个条件背景模型根据渲染的前景层合成一个连贯的背景。我们构建了一个带有自动化指标的图形设计生成基准，并表明CreatiPoster超越了领先的开源方法和专有商业系统。为了促进进一步的研究，我们发布了一个包含10万个多层设计的无版权语料库。CreatiPoster支持多种应用，例如画布编辑、文本叠加、响应式调整大小、多语言适应和动画海报，从而推动了AI辅助图形设计的普及。项目主页：https://github.com/graphic-design-ai/creatiposter

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [521] [AIR: Zero-shot Generative Model Adaptation with Iterative Refinement](https://arxiv.org/abs/2506.10895)
> *AIR：基于迭代细化的零样本生成模型适应*

*Guimeng Liu, Milad Abdollahzadeh, Ngai-Man Cheung* | **Main category: cs.CV**

**Keywords:** 零样本生成模型适应, CLIP, 偏移未对齐, 迭代细化, 图像生成

**Comment:** 

> **TL;DR:** 本文提出了一种名为AIR的零样本生成模型适应（ZSGM）方法，通过解决CLIP嵌入空间中的偏移未对齐问题，显著提高了生成图像的质量，并达到了最先进的性能。

**AI_Comments:** 本文的创新点在于首次深入研究了零样本生成模型适应（ZSGM）中CLIP嵌入空间内的偏移未对齐问题，并提出了与概念距离相关的发现。在此基础上，提出的AIR方法通过迭代细化有效解决了这一限制，显著提升了生成图像的质量，并达到了SOTA性能，对零样本生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有零样本生成模型适应（ZSGM）方法的一个主要局限性是，其学习目标假设CLIP嵌入空间中图像偏移与文本偏移之间存在完全对齐，导致生成图像的质量下降。

**Method:** 本文首先对CLIP嵌入空间中文本偏移和图像偏移之间的未对齐进行了实证研究，发现偏移未对齐与概念距离相关，即相近概念的偏移未对齐程度较低。在此基础上，提出了名为“基于迭代细化的适应”（AIR）的方法，这是第一个专注于基于偏移未对齐新见解来提高目标域图像质量的ZSGM方法。

**Result:** 研究发现CLIP嵌入空间中的偏移未对齐与概念距离相关，即相近概念的偏移未对齐程度较低。所提出的AIR方法在26种实验设置中，通过定性、定量和用户研究一致证明实现了最先进（SOTA）的性能。

**Conclusion:** AIR是第一个专注于基于偏移未对齐新见解来提高目标域图像质量的零样本生成模型适应（ZSGM）方法，并在多项实验中实现了最先进的性能。

> **ai_Abstract:** 本文针对零样本生成模型适应（ZSGM）中CLIP嵌入空间内图像偏移与文本偏移未对齐导致生成图像质量下降的问题，进行了深入研究。研究发现偏移未对齐与概念距离相关。在此基础上，提出了一种名为“基于迭代细化的适应”（AIR）的新方法，该方法通过迭代细化过程解决了偏移未对齐问题，显著提高了目标域图像的生成质量，并在多项实验中取得了最先进的性能。

> **摘要翻译:** 零样本生成模型适应（ZSGM）旨在仅使用文本指导且不使用目标域的任何样本来适应预训练的生成器。近期ZSGM方法的核心是方向性损失，它以在视觉-语言模型（如CLIP）的嵌入空间中对齐图像偏移与文本偏移的形式使用文本指导。这类似于自然语言处理（NLP）中的类比推理，其中一对词之间的偏移用于通过对齐这两对之间的偏移来识别另一对中缺失的元素。然而，现有ZSGM方法的一个主要局限性是，其学习目标假设CLIP嵌入空间中图像偏移与文本偏移之间存在完全对齐，导致生成图像的质量下降。我们的工作做出了两项主要贡献。受NLP中偏移未对齐研究的启发，作为我们的第一项贡献，我们进行了一项实证研究，分析了各种大型公开数据集中CLIP嵌入空间中文本偏移和图像偏移之间的未对齐。我们的重要发现是，CLIP嵌入空间中的偏移未对齐与概念距离相关，即相近概念的偏移未对齐程度较低。为了解决当前方法的局限性，作为我们的第二项贡献，我们提出了基于迭代细化的适应（AIR），这是第一个专注于基于我们对偏移未对齐的新见解来提高目标域图像质量的ZSGM方法。在26种实验设置中，定性、定量和用户研究一致表明所提出的AIR方法实现了最先进的性能。补充实验在附录中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [523] [M4V: Multi-Modal Mamba for Text-to-Video Generation](https://arxiv.org/abs/2506.10915)
> *M4V：多模态Mamba用于文本到视频生成*

*Jiancheng Huang, Gengwei Zhang, Zequn Jie, Siyu Jiao, Yinlong Qian, Ling Chen, Yunchao Wei, Lin Ma* | **Main category: cs.CV**

**Keywords:** 文本到视频生成, 多模态Mamba, 计算效率, 时空建模, 扩散模型

**Comment:** 

> **TL;DR:** M4V引入多模态Mamba架构，显著降低文本到视频生成的计算成本，同时保持高质量，解决了Transformer的二次复杂度问题。

**AI_Comments:** M4V的创新点在于将Mamba架构引入多模态文本到视频生成领域，并通过MM-DiM块和奖励学习策略解决了Mamba在多模态和长上下文生成中的局限性。其重要性在于显著提高了文本到视频生成的计算效率，为高质量内容创作和未来世界模拟器发展提供了更实用的基础。

<details>
  <summary>Details</summary>

**Motivation:** 文本到视频生成在计算上要求很高，特别是Transformer模型存在序列处理的二次复杂度，限制了实际应用。虽然Mamba架构更高效，但其简单的设计限制了其直接应用于多模态和时空视频生成任务。

**Method:** 提出M4V框架，核心是多模态扩散Mamba (MM-DiM) 块，通过多模态token重组设计实现多模态信息和时空建模的无缝集成。此外，引入奖励学习策略以缓解长上下文自回归生成过程中的视觉质量下降问题。

**Result:** 与基于注意力的替代方案相比，M4V中的Mamba块在生成768x1280分辨率视频时，FLOPs减少了45%。在文本到视频基准测试上，M4V能够生成高质量视频并显著降低计算成本。

**Conclusion:** M4V通过引入多模态Mamba架构，成功解决了文本到视频生成中的计算效率和质量问题，实现了高性能和低成本的视频生成。

> **ai_Abstract:** 本文提出了M4V，一个基于多模态Mamba架构的文本到视频生成框架，旨在解决传统Transformer在处理大时空数据时计算成本高的问题。M4V引入了多模态扩散Mamba (MM-DiM) 块，有效整合多模态信息和时空建模，并通过奖励学习策略提升视觉质量。实验证明，M4V显著降低了计算量（FLOPs减少45%），同时生成了高质量视频。

> **摘要翻译:** 文本到视频生成极大地丰富了内容创作，并有望发展成为强大的世界模拟器。然而，建模广阔的时空空间仍然计算量巨大，特别是在使用Transformer时，其在序列处理中产生二次复杂度，从而限制了实际应用。线性时间序列建模的最新进展，特别是Mamba架构，提供了一种更有效的替代方案。尽管如此，其简单的设计限制了其直接应用于多模态和时空视频生成任务。为了解决这些挑战，我们引入了M4V，一个用于文本到视频生成的多模态Mamba框架。具体来说，我们提出了一种多模态扩散Mamba（MM-DiM）块，通过多模态token重组设计实现多模态信息和时空建模的无缝集成。因此，在生成768×1280分辨率的视频时，M4V中的Mamba块与基于注意力的替代方案相比，FLOPs减少了45%。此外，为了减轻长上下文自回归生成过程中视觉质量的下降，我们引入了一种奖励学习策略，进一步增强了每帧的视觉真实感。在文本到视频基准上的广泛实验表明，M4V能够生成高质量视频，同时显著降低计算成本。代码和模型将在https://huangjch526.github.io/M4V_project公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [524] [VINCIE: Unlocking In-context Image Editing from Video](https://arxiv.org/abs/2506.10941)
> *VINCIE：从视频中解锁上下文图像编辑*

*Leigang Qu, Feng Cheng, Ziyan Yang, Qi Zhao, Shanchuan Lin, Yichun Shi, Yicong Li, Wenjie Wang, Tat-Seng Chua, Lu Jiang* | **Main category: cs.CV**

**Keywords:** 上下文图像编辑, 视频学习, 扩散模型, VINCIE, 多模态序列

**Comment:** Project page: https://vincie2025.github.io/

> **TL;DR:** VINCIE提出了一种直接从视频中学习上下文图像编辑模型的方法，通过新的数据标注和块因果扩散Transformer，实现了最先进的性能，并展现了多概念组合等潜力。

**AI_Comments:** 这项研究的创新之处在于提出了直接从视频中学习上下文图像编辑模型的方法，避免了对昂贵且费时的专家标注数据的依赖。通过将视频转化为多模态序列和设计专门的块因果扩散Transformer，该模型在无需传统分割/修复模型的情况下实现了SOTA性能，并在多概念组合等新兴应用中展现了潜力，为图像编辑领域提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的上下文图像编辑方法通常依赖于特定任务的管道和专家模型（如分割和修复）来整理训练数据，这限制了其泛化能力。本文旨在探索是否可以直接从视频中学习上下文图像编辑模型。

**Method:** 本文引入了一种可扩展的方法来将视频标注为交错的多模态序列。为了有效学习，设计了一个块因果扩散Transformer，并在三个代理任务上进行训练：下一图像预测、当前分割预测和下一分割预测。此外，还提出了一个新的多轮图像编辑基准。

**Result:** 模型展现出强大的上下文图像编辑能力，并在两个多轮图像编辑基准上取得了最先进的结果。尽管仅使用视频进行训练，模型在多概念组合、故事生成和编辑链应用中也显示出有前景的能力。

**Conclusion:** VINCIE成功证明了可以直接从视频数据中学习上下文图像编辑模型，并在多个任务上取得了显著成果，为该领域的研究开辟了新的方向。

> **ai_Abstract:** VINCIE提出了一种新颖的上下文图像编辑方法，通过直接从视频中学习来克服现有方法对特定任务流水线和专家模型的依赖。该方法包括将视频标注为交错多模态序列的可扩展技术，并设计了一个块因果扩散Transformer，在图像和分割预测代理任务上进行训练。实验证明，VINCIE在多轮图像编辑基准上实现了最先进的性能，并展示了在多概念组合、故事生成和编辑链应用中的潜力，突显了视频作为训练数据源的有效性。

> **摘要翻译:** 上下文图像编辑旨在根据包含文本和先前生成图像的上下文序列来修改图像。现有方法通常依赖于特定任务的管道和专家模型（例如，分割和修复）来整理训练数据。在这项工作中，我们探索是否可以直接从视频中学习一个上下文图像编辑模型。我们引入了一种可扩展的方法来将视频标注为交错的多模态序列。为了有效地从这些数据中学习，我们设计了一个块因果扩散Transformer，并在三个代理任务上进行训练：下一图像预测、当前分割预测和下一分割预测。此外，我们提出了一个新的多轮图像编辑基准，以推动该领域的研究。大量的实验表明，我们的模型展现出强大的上下文图像编辑能力，并在两个多轮图像编辑基准上取得了最先进的结果。尽管仅使用视频进行训练，我们的模型在多概念组合、故事生成和编辑链应用中也显示出有前景的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [SpectralAR: Spectral Autoregressive Visual Generation](https://arxiv.org/abs/2506.10962)
> *SpectralAR：频谱自回归视觉生成*

*Yuanhui Huang, Weiliang Chen, Wenzhao Zheng, Yueqi Duan, Jie Zhou, Jiwen Lu* | **Main category: cs.CV**

**Keywords:** 频谱自回归, 视觉生成, 因果性, 频谱分词, ImageNet-1K

**Comment:** Project Page: https://huang-yh.github.io/spectralar/

> **TL;DR:** SpectralAR通过将图像转换为有序频谱token，实现了因果性视觉序列生成，解决了现有自回归模型中空间补丁缺乏因果性的问题，并在ImageNet-1K上取得了良好性能。

**AI_Comments:** 这篇论文的创新点在于从频谱角度构建视觉序列，解决了传统基于空间补丁的自回归模型中因果性不足的问题。通过引入有序的频谱token和从粗到细的生成策略，SpectralAR在保持模型效率的同时，提高了生成质量，对于自回归视觉生成领域是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有大多数自回归视觉生成方法将图像构建为空间补丁序列，但图像补丁本质上是并行的，这与自回归建模的因果性质相矛盾。

**Method:** 本文提出了一种名为Spectral AutoRegressive (SpectralAR) 的视觉生成框架，该框架从频谱角度实现视觉序列的因果性。具体而言，首先通过嵌套频谱分词（Nested Spectral Tokenization）将图像转换为有序的频谱token，这些token代表从低频到高频的分量。然后，利用这些频谱token序列以从粗到细的方式进行自回归生成。

**Result:** 在ImageNet-1K上进行了图像重建和自回归生成实验，SpectralAR仅用64个token和3.1亿参数就达到了3.02 gFID的性能。

**Conclusion:** SpectralAR通过考虑图像不同细节层次，在不增加复杂性的情况下，实现了序列因果性和token效率。

> **ai_Abstract:** 本文提出了SpectralAR，一个新颖的频谱自回归视觉生成框架，旨在解决现有方法中空间图像补丁缺乏因果性的问题。通过将图像转换为有序的频谱token并进行从粗到细的自回归生成，SpectralAR有效地实现了序列因果性和token效率。在ImageNet-1K上的实验表明，该模型在图像生成方面表现出色，展现了其在视觉生成领域的潜力。

> **摘要翻译:** 自回归视觉生成因其与扩散模型相比具有可扩展性和与其他模态的兼容性而受到越来越多的关注。大多数现有方法将视觉序列构建为空间补丁用于自回归生成。然而，图像补丁本质上是并行的，这与自回归建模的因果性质相矛盾。为了解决这个问题，我们提出了一种频谱自回归（Spectral AutoRegressive, SpectralAR）视觉生成框架，该框架从频谱角度实现了视觉序列的因果性。具体而言，我们首先通过嵌套频谱分词将图像转换为有序的频谱token，这些token代表从低频到高频的分量。然后，我们利用频谱token序列以从粗到细的方式进行自回归生成。通过考虑图像中不同级别的细节，我们的SpectralAR在不增加额外复杂性的情况下实现了序列因果性和token效率。我们在ImageNet-1K上进行了广泛的图像重建和自回归生成实验，SpectralAR仅用64个token和3.1亿参数就达到了3.02 gFID的性能。项目页面：https://huang-yh.github.io/spectralar/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [528] [MMMG: A Massive, Multidisciplinary, Multi-Tier Generation Benchmark for Text-to-Image Reasoning](https://arxiv.org/abs/2506.10963)
> *MMMG：一个用于文本到图像推理的大规模、多学科、多层次生成基准*

*Yuxuan Luo, Yuhui Yuan, Junwen Chen, Haonan Cai, Ziyi Yue, Yuwei Yang, Fatima Zohra Daha, Ji Li, Zhouhui Lian* | **Main category: cs.CV**

**Keywords:** 知识图像生成, 文本到图像推理, 基准测试, 知识图谱, 多模态推理

**Comment:** 

> **TL;DR:** 本文引入了知识图像生成任务和MMMG基准，以评估图像生成模型的推理能力，并揭示了现有模型的推理缺陷。

**AI_Comments:** 这篇论文通过引入“知识图像生成”这一新颖且重要的任务，并构建了一个大规模、多学科、多层次的MMMG基准，填补了现有文本到图像生成模型在评估复杂推理能力方面的空白。其创新之处在于定义了需要融合世界知识和视觉细节的知识图像，并设计了基于知识图谱的事实保真度评估方法MMMG-Score。该研究揭示了当前SOTA模型在推理方面的显著不足，对未来文本到图像生成技术的发展方向具有重要指导意义。发布FLUX-Reason基线模型也体现了其推动社区进步的积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像生成模型在推理能力方面存在不足，特别是在生成需要融合世界知识和像素级细节的“知识图像”时面临挑战。为了全面评估和推动这一领域的发展，需要一个新的任务和基准。

**Method:** 1. 引入了“知识图像生成”新任务。2. 构建了MMMG基准，包含4,456个专家验证的图像-提示对，涵盖10个学科、6个教育水平和多种知识格式（图表、图示、思维导图）。3. 采用统一的知识图谱（KG）表示来描述图像的核心实体及其依赖关系。4. 提出了MMMG-Score评估指标，结合了事实准确性（通过KG之间的图编辑距离衡量）和视觉清晰度。5. 提供了FLUX-Reason作为开放基线，它结合了推理LLM和扩散模型，并在16,000个知识图像-提示对上训练。

**Result:** 对16个最先进的文本到图像生成模型进行全面评估后发现，它们在推理方面存在严重缺陷，表现为实体保真度低、关系薄弱和图像混乱。例如，GPT-4o的MMMG-Score仅为50.20，这凸显了该基准的难度。

**Conclusion:** 本文引入的知识图像生成任务和MMMG基准揭示了当前文本到图像生成模型在多模态推理能力上的显著不足。通过发布FLUX-Reason基线，旨在促进该领域未来的研究进展。

> **ai_Abstract:** 本文提出“知识图像生成”这一新任务，并发布了大规模、多学科、多层次知识图像生成基准（MMMG），旨在评估文本到图像生成模型的推理能力。MMMG包含4,456个专家验证的图像-提示对，覆盖多学科和教育层次，并采用统一的知识图谱表示和MMMG-Score进行评估。对现有SOTA模型的测试表明，它们在生成知识图像时存在严重的推理缺陷。为推动研究，作者还开源了FLUX-Reason基线模型。

> **摘要翻译:** 在本文中，我们引入了知识图像生成作为一项新任务，并同时推出了大规模、多学科、多层次知识图像生成基准（MMMG），以探究图像生成模型的推理能力。知识图像在人类文明和人类学习机制中一直占据核心地位——双重编码理论和图像优势效应都强调了这一点。生成此类图像具有挑战性，需要多模态推理，将世界知识与像素级基础融合为清晰的解释性视觉效果。为了实现全面评估，MMMG提供了4,456个经过专家验证的（知识）图像-提示对，涵盖10个学科、6个教育水平以及图表、图示和思维导图等多种知识格式。为了消除评估过程中的混淆复杂性，我们采用了统一的知识图谱（KG）表示。每个KG都明确描绘了目标图像的核心实体及其依赖关系。我们进一步引入了MMMG-Score来评估生成的知识图像。该指标结合了事实保真度（通过KG之间的图编辑距离衡量）和视觉清晰度评估。对16个最先进的文本到图像生成模型的全面评估揭示了严重的推理缺陷——实体保真度低、关系薄弱和混乱——其中GPT-4o的MMMG-Score仅为50.20，这凸显了该基准的难度。为了促进进一步的进展，我们发布了FLUX-Reason（MMMG-Score为34.45），这是一个有效且开放的基线，它结合了推理LLM和扩散模型，并在16,000个精选知识图像-提示对上进行了训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [529] [Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs](https://arxiv.org/abs/2506.10967)
> *超越注意力或相似性：在多模态大语言模型中最大化条件多样性以进行Token剪枝*

*Qizhe Zhang, Mengzhen Liu, Lichen Li, Ming Lu, Yuan Zhang, Junwen Pan, Qi She, Shanghang Zhang* | **Main category: cs.CV**

**Keywords:** 多模态大语言模型, Token剪枝, 条件多样性, 行列式点过程, 推理成本优化

**Comment:** 22 pages, 5 figures, code: https://github.com/Theia-4869/CDPruner,
  project page: https://theia-4869.github.io/CDPruner

> **TL;DR:** 提出CDPruner，一种新颖的视觉token剪枝方法，通过最大化条件多样性来降低MLLM的推理成本，实现了SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了“条件多样性”的概念，并创造性地将其与行列式点过程（DPP）结合起来解决多模态大语言模型中的视觉token剪枝问题。相较于传统的注意力或相似性剪枝，它考虑了指令相关性，并通过最大化多样性来确保保留的token更具代表性。其免训练和模型无关的特性使其具有很高的实用性和普适性。在降低计算成本的同时保持甚至提升性能，对MLLMs的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）中视觉token输入长度远大于文本，导致高昂的推理成本。现有剪枝方法（基于注意力或相似性）存在冗余或忽略指令相关性，导致性能次优。

**Method:** 提出CDPruner方法，通过定义基于指令的视觉token条件相似性，并利用行列式点过程（DPP）重新 формуulate token剪枝问题，以最大化所选子集的条件多样性。该方法是免训练且模型无关的。

**Result:** CDPruner在各种MLLMs上的广泛实验表明，它在各种视觉-语言基准测试中达到了新的最先进水平。通过DPP最大化条件多样性，所选子集能更好地表示输入图像并紧密遵循用户指令，即使在高剪枝率下也能保持强大性能。应用于LLaVA时，FLOPs减少95%，CUDA延迟减少78%，同时保持94%的原始精度。

**Conclusion:** CDPruner通过最大化条件多样性，有效解决了MLLMs中视觉token冗余问题，显著降低了推理成本，同时保持了高精度，并在多个基准测试中表现出SOTA性能。

> **ai_Abstract:** 本文提出了一种名为CDPruner的新型视觉token剪枝方法，用于解决多模态大语言模型（MLLMs）中视觉token冗余导致的高推理成本问题。与传统基于注意力或相似性的方法不同，CDPruner通过定义基于指令的条件相似性，并利用行列式点过程（DPP）最大化保留token的条件多样性。该方法是免训练且模型无关的，在多个MLLMs和视觉-语言基准测试中实现了最先进的性能，显著降低了计算成本（如LLaVA上FLOPs减少95%，CUDA延迟减少78%），同时保持了高精度。

> **摘要翻译:** 在多模态大型语言模型（MLLMs）中，输入视觉token的长度通常远大于其对应的文本token，导致高昂的推理成本。许多工作旨在通过移除冗余视觉token来解决这个问题。然而，当前的方法要么依赖于基于注意力的剪枝，保留了大量的重复token，要么使用基于相似性的剪枝，忽略了指令相关性，从而导致次优性能。在本文中，我们超越了注意力或相似性，提出了一种新颖的视觉token剪枝方法，名为CDPruner，它最大化了保留token的条件多样性。我们首先定义了基于指令的视觉token之间的条件相似性，然后利用行列式点过程（DPP）重新 формуulate token剪枝问题，以最大化所选子集的条件多样性。所提出的CDPruner是免训练且模型无关的，可以轻松应用于各种MLLMs。在各种MLLMs上进行的广泛实验表明，CDPruner在各种视觉-语言基准测试中建立了新的最先进水平。通过DPP最大化条件多样性，所选子集能够更好地表示输入图像，同时紧密遵循用户指令，从而即使在高剪枝率下也能保持强大的性能。当应用于LLaVA时，CDPruner将FLOPs减少了95%，CUDA延迟减少了78%，同时保持了94%的原始精度。我们的代码可在https://github.com/Theia-4869/CDPruner获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [530] [GenWorld: Towards Detecting AI-generated Real-world Simulation Videos](https://arxiv.org/abs/2506.10975)
> *GenWorld：迈向检测AI生成真实世界模拟视频*

*Weiliang Chen, Wenzhao Zheng, Yu Zheng, Lei Chen, Jie Zhou, Jiwen Lu, Yueqi Duan* | **Main category: cs.CV**

**Keywords:** AI生成视频检测, 真实世界模拟, 数据集, 多视角一致性, 可解释性AI

**Comment:** 

> **TL;DR:** 本文提出了GenWorld，一个用于AI生成视频检测的大规模高质量真实世界模拟数据集，并引入了SpannDetector，一个利用多视角一致性进行检测的模型，实验证明其效果优于现有方法。

**AI_Comments:** 本文的创新点在于构建了一个大规模、高质量的真实世界模拟数据集GenWorld，这对于推动AI生成视频检测领域的发展至关重要。同时，提出的SpannDetector模型利用多视角一致性，并结合物理合理性进行可解释检测，解决了现有方法在检测世界模型生成视频时的局限性，具有重要的实践意义和研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 视频生成技术的蓬勃发展威胁了真实世界信息的可信度，并增加了对AI生成视频检测器的需求。尽管有所进展，但缺乏高质量的真实世界数据集阻碍了可信检测器的开发。

**Method:** 本文提出了GenWorld，一个大规模、高质量、真实世界模拟的AI生成视频检测数据集。GenWorld具有以下特点：真实世界模拟、高质量和跨提示多样性。此外，本文还提出了SpannDetector，一个简单但有效的模型，利用多视角一致性作为检测真实世界AI生成视频的强有力标准。

**Result:** 分析发现现有方法无法检测世界模型（如Cosmos）生成的高质量视频，这揭示了忽视真实世界线索的潜在缺点。实验表明，所提出的方法取得了优异的结果，突出了基于物理合理性的可解释AI生成视频检测的有前景方向。

**Conclusion:** GenWorld有望推动AI生成视频检测领域的发展。

> **ai_Abstract:** 本文针对AI生成视频检测中高质量真实世界数据集的缺失问题，提出了GenWorld数据集。GenWorld是一个大规模、高质量、包含真实世界模拟和跨提示多样性的数据集。研究发现现有方法在检测世界模型生成的高质量视频时存在不足。为此，本文提出了一种名为SpannDetector的新模型，该模型利用多视角一致性来提高检测性能。实验结果表明，SpannDetector取得了优异的检测效果，为基于物理合理性的可解释AI生成视频检测提供了新方向。

> **摘要翻译:** 视频生成技术的蓬勃发展危及了真实世界信息的可信度，并加剧了对AI生成视频检测器的需求。尽管取得了一些进展，但高质量真实世界数据集的缺乏阻碍了可信检测器的发展。在本文中，我们提出了GenWorld，一个用于AI生成视频检测的大规模、高质量、真实世界模拟数据集。GenWorld具有以下特点：(1) 真实世界模拟：GenWorld专注于复制真实世界场景的视频，这些视频因其真实性和潜在影响力而具有显著影响；(2) 高质量：GenWorld采用多种最先进的视频生成模型来提供真实且高质量的伪造视频；(3) 跨提示多样性：GenWorld包含由不同生成器和各种提示模态（例如文本、图像、视频）生成的视频，提供了学习更通用取证特征的潜力。我们分析了现有方法，发现它们无法检测世界模型（即Cosmos）生成的高质量视频，揭示了忽视真实世界线索的潜在缺点。为了解决这个问题，我们提出了一个简单但有效的模型SpannDetector，以利用多视角一致性作为检测真实世界AI生成视频的有力标准。实验表明，我们的方法取得了优异的结果，突出了基于物理合理性的可解释AI生成视频检测的有前景方向。我们相信GenWorld将推动AI生成视频检测领域的发展。项目页面：https://chen-wl20.github.io/GenWorld

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [531] [QuadricFormer: Scene as Superquadrics for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2506.10977)
> *QuadricFormer：基于超二次曲面的3D语义占用预测场景*

*Sicheng Zuo, Wenzhao Zheng, Xiaoyong Han, Longchao Yang, Yong Pan, Jiwen Lu* | **Main category: cs.CV**

**Keywords:** 3D占用预测, 超二次曲面, 场景表示, 自动驾驶, QuadricFormer

**Comment:** Project page: https://zuosc19.github.io/QuadricFormer/

> **TL;DR:** QuadricFormer利用超二次曲面作为场景基元，解决了传统3D占用预测方法效率低下和表达能力有限的问题，实现了高效且最先进的3D语义占用预测。

**AI_Comments:** QuadricFormer的创新点在于引入超二次曲面作为3D场景表示的基元，这显著提升了对复杂几何形状的建模能力，同时解决了传统体素和高斯方法在效率和表达能力上的局限性。其概率混合模型和剪枝-分裂模块进一步优化了效率。该方法在自动驾驶等需要精确环境感知的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D占用预测方法存在效率低下（基于密集体素）和表达能力不足（基于稀疏高斯）的问题。密集体素表示忽略了驾驶场景的稀疏性，而稀疏高斯方法由于其椭球形状先验限制了对多样化结构的建模，导致需要大量高斯来准确建模，从而效率低下。

**Method:** 本文提出使用几何表达能力强的超二次曲面作为场景基元，以更少的基元高效表示复杂结构。开发了一个概率超二次曲面混合模型，将每个超二次曲面解释为具有相应几何先验的占用概率分布，并通过概率混合计算语义。在此基础上，提出了QuadricFormer模型，并引入了剪枝和分裂模块，通过将超二次曲面集中在占用区域来进一步提高建模效率。

**Result:** 在nuScenes数据集上进行的广泛实验表明，QuadricFormer在保持卓越效率的同时，实现了最先进的性能。

**Conclusion:** QuadricFormer通过引入几何表达能力强的超二次曲面作为场景基元，有效解决了现有3D语义占用预测方法在效率和表达能力上的局限性，实现了高效且高性能的3D语义占用预测。

> **ai_Abstract:** 本文针对3D语义占用预测中现有方法存在的效率低下（密集体素）和表达能力有限（稀疏高斯）问题，提出了一种名为QuadricFormer的新模型。该模型核心在于利用几何表达能力强的超二次曲面作为场景基元，能够以更少的基元高效表示复杂结构。通过开发概率超二次曲面混合模型，并引入剪枝和分裂模块，QuadricFormer显著提升了建模效率。实验证明，QuadricFormer在nuScenes数据集上实现了最先进的性能，同时保持了卓越的效率。

> **摘要翻译:** 3D占用预测对于鲁棒的自动驾驶系统至关重要，因为它能够全面感知环境结构和语义。大多数现有方法采用基于密集体素的场景表示，忽略了驾驶场景的稀疏性，导致效率低下。最近的工作探索了基于稀疏高斯的对象中心表示，但其椭球形状先验限制了对多样化结构的建模。在现实世界的驾驶场景中，物体呈现出丰富的几何形状（例如，长方体、圆柱体和不规则形状），需要过度密集堆叠的椭球高斯才能准确建模，这导致了低效的表示。为了解决这个问题，我们提出使用几何表达能力强的超二次曲面作为场景基元，通过其固有的形状多样性，用更少的基元高效表示复杂结构。我们开发了一个概率超二次曲面混合模型，该模型将每个超二次曲面解释为具有相应几何先验的占用概率分布，并通过概率混合计算语义。在此基础上，我们提出了QuadricFormer，一个基于超二次曲面的高效3D占用预测模型，并引入了一个剪枝和分裂模块，通过将超二次曲面集中在占用区域来进一步提高建模效率。在nuScenes数据集上进行的广泛实验表明，QuadricFormer在保持卓越效率的同时，实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [Fine-Grained Perturbation Guidance via Attention Head Selection](https://arxiv.org/abs/2506.10978)
> *通过注意力头选择实现细粒度扰动引导*

*Donghoon Ahn, Jiwon Kang, Sanghyun Lee, Minjae Kim, Jaewon Min, Wooseok Jang, Saungwu Lee, Sayak Paul, Susung Hong, Seungryong Kim* | **Main category: cs.CV**

**Keywords:** 注意力扰动, 扩散模型, 细粒度控制, DiT, HeadHunter

**Comment:** Project page: https://cvlab-kaist.github.io/HeadHunter/

> **TL;DR:** 论文提出了HeadHunter框架和SoftPAG方法，通过选择性扰动扩散模型中的注意力头，实现对图像生成质量和视觉属性的细粒度控制，解决了现有方法缺乏精确扰动位置的问题。

**AI_Comments:** 这篇论文的创新点在于首次将注意力扰动的粒度细化到“注意力头”级别，而不是传统的“层级”。通过发现不同注意力头控制不同视觉概念，并提出“HeadHunter”框架和SoftPAG，实现了对扩散模型生成过程前所未有的细粒度控制。这对于理解扩散模型内部机制、提升生成质量以及实现用户定制化的视觉风格具有重要意义，为未来的可控生成研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型引导方法，特别是注意力扰动，在无分类器指导不适用的场景表现良好，但缺乏确定扰动精确位置的原则性方法，尤其是在DiT架构中，导致质量相关计算分布在各层，无法实现细粒度控制。

**Method:** 本文调查了注意力扰动的粒度，从层级到单个注意力头，并发现特定的注意力头控制着不同的视觉概念（如结构、风格和纹理质量）。基于此，提出了“HeadHunter”框架，用于迭代选择与用户中心目标对齐的注意力头，实现对生成质量和视觉属性的细粒度控制。此外，引入了SoftPAG，通过将每个选定注意头部的注意力图线性插值到单位矩阵，提供了一个连续的旋钮来调整扰动强度并抑制伪影。

**Result:** 该方法缓解了现有层级扰动导致的过度平滑问题，并通过组合式头部选择实现了对特定视觉风格的定向操纵。在现代大型基于DiT的文本到图像模型（包括Stable Diffusion 3和FLUX.1）上验证了方法的有效性，在通用质量增强和风格特异性引导方面均表现出卓越性能。本工作首次提供了扩散模型中注意力扰动的头部级分析，揭示了注意力层内的可解释专业化。

**Conclusion:** 本工作首次对扩散模型中的注意力扰动进行了头部级分析，揭示了注意力层内可解释的专业化，并为有效扰动策略的实际设计提供了可能。

> **ai_Abstract:** 本文针对扩散模型中注意力扰动缺乏细粒度控制的问题，特别是DiT架构中扰动位置不明确的挑战，首次提出了头部级注意力扰动分析。研究发现特定注意力头控制不同的视觉概念。基于此，提出了“HeadHunter”框架，通过迭代选择注意力头实现对生成质量和视觉属性的细粒度控制。同时引入SoftPAG以连续调节扰动强度和抑制伪影。实验证明，该方法在提高图像生成质量和实现特定风格引导方面优于现有层级扰动方法，并在Stable Diffusion 3和FLUX.1等模型上表现出色。

> **摘要翻译:** 扩散模型中最近的引导方法通过扰动模型来构建一个隐式的弱模型，并引导生成远离它，从而引导反向采样。在这些方法中，注意力扰动在无分类器引导不适用的无条件场景中表现出强大的经验性能。然而，现有的注意力扰动方法缺乏确定扰动应施加位置的原则性方法，特别是在质量相关计算分布在各层的扩散Transformer (DiT) 架构中。在本文中，我们研究了注意力扰动的粒度，从层级到单个注意力头，并发现特定的注意力头控制着不同的视觉概念，如结构、风格和纹理质量。基于这一见解，我们提出了“HeadHunter”，一个系统框架，用于迭代选择与用户中心目标对齐的注意力头，从而实现对生成质量和视觉属性的细粒度控制。此外，我们引入了SoftPAG，它将每个选定注意头部的注意力图线性插值到单位矩阵，提供了一个连续的旋钮来调整扰动强度并抑制伪影。我们的方法不仅缓解了现有层级扰动的过度平滑问题，而且通过组合式头部选择实现了对特定视觉风格的定向操纵。我们在现代大型基于DiT的文本到图像模型（包括Stable Diffusion 3和FLUX.1）上验证了我们的方法，在通用质量增强和风格特异性引导方面均表现出卓越性能。我们的工作首次提供了扩散模型中注意力扰动的头部级分析，揭示了注意力层内的可解释专业化，并为有效扰动策略的实际设计提供了可能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [534] [InstaInpaint: Instant 3D-Scene Inpainting with Masked Large Reconstruction Model](https://arxiv.org/abs/2506.10980)
> *InstaInpaint：基于掩模大重建模型的即时三维场景修复*

*Junqi You, Chieh Hubert Lin, Weijie Lyu, Zhengbo Zhang, Ming-Hsuan Yang* | **Main category: cs.CV**

**Keywords:** 3D场景修复, 实时, 大型重建模型, 自监督学习, 计算机图形学

**Comment:** 

> **TL;DR:** InstaInpaint是一个快速的3D场景修复框架，它通过参考式前馈方法和自监督掩模微调策略，实现了比现有方法快1000倍的速度，同时保持了最先进的性能。

**AI_Comments:** InstaInpaint的创新之处在于其结合了参考式前馈框架和自监督掩模微调策略，显著提升了3D场景修复的速度，使其首次达到实时应用的要求。其在保持SOTA性能的同时实现1000倍加速，是该领域的重要突破，为VR/AR等交互式应用提供了关键技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 当前3D场景修复方法依赖于耗时且计算密集型的优化，使其不适用于实时或在线应用。

**Method:** 提出InstaInpaint，一个基于参考的前馈框架，能够在0.4秒内从2D修复建议生成3D场景修复。开发了一种自监督掩模微调策略，用于在大规模数据集上训练自定义的大型重建模型（LRM）。

**Result:** InstaInpaint比现有方法实现了1000倍的速度提升，同时在两个标准基准上保持了最先进的性能。它还能很好地推广到下游应用，如对象插入和多区域修复。

**Conclusion:** InstaInpaint提供了一种高效且高性能的3D场景修复解决方案，克服了现有方法的实时性限制，并展现了良好的泛化能力。

> **ai_Abstract:** 本文提出了InstaInpaint，一个用于即时3D场景修复的参考式前馈框架。针对现有方法计算量大、无法实时应用的痛点，InstaInpaint通过自监督掩模微调策略训练大型重建模型，实现了在0.4秒内完成3D场景修复，速度比现有方法快1000倍，并保持了最先进的性能。该方法在泛化能力、纹理一致性和几何正确性方面表现出色，并能应用于物体插入和多区域修复等下游任务。

> **摘要翻译:** 近期3D场景重建的进展使得在虚拟和增强现实中实现实时观看成为可能。为了支持更好的沉浸式交互操作，例如移动或编辑物体，提出了3D场景修复方法来修复或完成被改变的几何结构。然而，目前的方法依赖于漫长且计算密集的优化，使其不适用于实时或在线应用。我们提出了InstaInpaint，一个基于参考的前馈框架，能够在0.4秒内从2D修复建议生成3D场景修复。我们开发了一种自监督掩模微调策略，以实现在大规模数据集上训练我们定制的大型重建模型（LRM）。通过广泛的实验，我们分析并确定了几个关键设计，这些设计改善了泛化能力、纹理一致性和几何正确性。InstaInpaint比现有方法实现了1000倍的速度提升，同时在两个标准基准上保持了最先进的性能。此外，我们展示了InstaInpaint能够很好地推广到灵活的下游应用，例如物体插入和多区域修复。更多视频结果可在我们的项目页面获取：https://dhmbb2.github.io/InstaInpaint_page/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [535] [SceneCompleter: Dense 3D Scene Completion for Generative Novel View Synthesis](https://arxiv.org/abs/2506.10981)
> *SceneCompleter: 用于生成式新颖视图合成的密集三维场景补全*

*Weiliang Chen, Jiayi Bi, Yuanhui Huang, Wenzhao Zheng, Yueqi Duan* | **Main category: cs.CV**

**Keywords:** 三维场景补全, 新颖视图合成, 生成模型, 扩散模型, RGBD

**Comment:** 

> **TL;DR:** SceneCompleter提出了一种新的框架，通过密集三维场景补全实现三维一致的生成式新颖视图合成，解决了现有方法在二维补全后三维恢复导致的表面平滑和几何扭曲问题。

**AI_Comments:** 该论文通过提出直接在3D空间进行场景补全的新范式，解决了传统2D补全再3D恢复方法导致的几何失真问题，具有重要的创新性。其双流扩散模型和场景嵌入器的结合，有效提升了生成视图的3D一致性和视觉质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成模型在2D补全后进行3D恢复，常导致过于平滑的表面和扭曲的几何形状，因为它们难以仅从RGB数据推断3D结构。

**Method:** 本文提出了SceneCompleter框架，通过密集三维场景补全实现三维一致的生成式新颖视图合成。它包含两个关键组件：1) 一个几何-外观双流扩散模型，用于在RGBD空间中联合合成新颖视图；2) 一个场景嵌入器，用于从参考图像编码更全面的场景理解。

**Result:** SceneCompleter在生成式新颖视图合成中展示了卓越的连贯性和合理性。

**Conclusion:** 通过有效融合结构和纹理信息，SceneCompleter能够实现视觉连贯且三维一致的生成式场景补全，并在多样化数据集上表现出优越的性能。

> **ai_Abstract:** SceneCompleter是一个新颖的框架，旨在通过密集的三维场景补全实现三维一致的生成式新颖视图合成。针对现有方法在2D补全后进行3D恢复导致几何失真和表面平滑的问题，SceneCompleter引入了几何-外观双流扩散模型在RGBD空间联合合成视图，并利用场景嵌入器从参考图像获取全面的场景理解。该方法有效融合结构和纹理信息，在新颖视图合成中展现出卓越的连贯性和合理性。

> **摘要翻译:** 生成模型通过减轻对密集多视图捕获的依赖，在新颖视图合成（NVS）中获得了显著关注。然而，现有方法通常遵循传统范式，即生成模型首先在2D中补全缺失区域，然后通过3D恢复技术重建场景，这常常导致过于平滑的表面和扭曲的几何形状，因为生成模型难以仅从RGB数据推断3D结构。在本文中，我们提出了SceneCompleter，一个新颖的框架，通过密集三维场景补全实现三维一致的生成式新颖视图合成。SceneCompleter通过两个关键组件实现视觉连贯和三维一致的生成式场景补全：(1) 一个几何-外观双流扩散模型，用于在RGBD空间中联合合成新颖视图；(2) 一个场景嵌入器，用于从参考图像编码更全面的场景理解。通过有效融合结构和纹理信息，我们的方法在多样化数据集上展示了生成式新颖视图合成的卓越连贯性和合理性。项目页面：https://chen-wl20.github.io/SceneCompleter

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [9] [Cybernetic Marionette: Channeling Collective Agency Through a Wearable Robot in a Live Dancer-Robot Duet](https://arxiv.org/abs/2506.10079)
> *赛博提线木偶：通过可穿戴机器人在现场舞者-机器人二重奏中引导集体能动性*

*Anup Sathya, Jiasheng Li, Zeyu Yan, Adriane Fang, Bill Kules, Jonathan David Martin, Huaishu Peng* | **Main category: cs.HC**

**Keywords:** 集体能动性, 可穿戴机器人, 互动表演, 能动性体验, 权力

**Comment:** 

> **TL;DR:** 观众通过投票控制可穿戴机器人影响舞者-机器人表演，但投票数据一致性与观众感受的能动性存在差异，揭示了能动性体验与实际影响之间的复杂关系。

**AI_Comments:** 这项研究通过一个具体的艺术表演案例，深入探讨了“能动性”这一复杂概念，尤其是在集体参与和技术介导情境下的体现。其创新之处在于将艺术实践作为社会科学研究的实验平台，揭示了用户在算法驱动系统中可能面临的“被赋予能动性假象”的困境。研究结果对于理解人机交互、集体行为以及数字平台设计中的权力动态具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨集体能动性、能动性体验与权力之间的复杂关系，并通过现场表演作为算法策展数字系统的类比，其中能动性被感知但未被真正行使。

**Method:** 描述了名为DANCE^2的互动舞蹈表演，观众通过投票控制附着在舞者身上的可穿戴机器人的行为，实时影响表演。通过演后调查和投票数据分析观众的体验和实际影响。

**Result:** 演后调查显示参与者认为他们的选择有意义地影响了表演，但四场公开表演的投票数据却呈现出惊人的一致性模式。这揭示了观众的行动、感受和实际变化之间的紧张关系。

**Conclusion:** 编舞、互动设计和表演结构共同调节了能动性行为、能动性体验和权力之间的关系，为算法策展的数字系统提供了一个现场类比，其中能动性被感知但未被真正行使。

> **ai_Abstract:** 本文介绍了DANCE^2互动舞蹈表演，观众通过投票控制舞者佩戴的机器人，从而引导集体能动性。尽管观众普遍认为他们的选择影响了表演，但实际投票数据显示出高度一致性，揭示了能动性体验与实际影响之间的张力。研究反思了编舞、互动设计和表演结构如何调节这种关系，并将其作为算法策展数字系统中“能动性被感知但未被行使”现象的现场类比。

> **摘要翻译:** 我们描述了DANCE^2，这是一场互动舞蹈表演，观众通过投票决定附着在舞者身上的可穿戴机器人的行为，从而将他们的集体能动性引导到一个舞者-机器人二重奏中。在表演的关键时刻，观众被邀请选择继续编舞或推翻它，通过实时集体输入塑造不断展开的互动。虽然表演后的调查显示参与者认为他们的选择有意义地影响了表演，但四场公开表演的投票数据却呈现出惊人的一致性模式。观众的行动、感受和实际变化之间的这种张力凸显了能动性行为、能动性体验和权力之间复杂的相互作用。我们反思了编舞、互动设计和表演结构如何调节这种关系，为算法策展的数字系统提供了一个现场类比，在这些系统中，能动性被感知但并未被行使。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [36] [Mastery Learning Improves Performance on Complex Tasks on PCP Literacy Test](https://arxiv.org/abs/2506.10164)
> *精熟学习提高PCP素养测试中复杂任务的表现*

*Chandana Srinivas, Elif E. Firat, Robert S. Laramee, Alark Joshi* | **Main category: cs.HC**

**Keywords:** 精熟学习, 并行坐标图, 数据可视化, 布鲁姆分类法, 素养测试

**Comment:** 

> **TL;DR:** 本研究发现，精熟学习能显著提高学生在并行坐标图（PCPs）素养测试中对需要高级思维的复杂任务的表现，尤其是在分析和评估模块。

**AI_Comments:** 该研究的重要性在于其为教授复杂数据可视化技术提供了一种有效的教学方法——精熟学习，并结合了布鲁姆分类法，为教育实践提供了实证支持。其创新之处在于将精熟学习应用于特定的数据可视化素养培养，并提供了可复现的实验材料，这对于后续研究和教学实践具有很高的价值。

<details>
  <summary>Details</summary>

**Motivation:** 学生在学习并行坐标图（PCPs）等不熟悉的数据可视化技术时面临重大挑战，本研究旨在探索精熟学习如何帮助学生克服这一挑战。

**Method:** 研究采用修订版布鲁姆分类法，在数据可视化课程中对学生进行PCP教学，并设置了有精熟学习和无精熟学习的对照组干预实验来评估精熟学习的影响。

**Result:** 干预结果显示，在记忆和理解模块上，两组学生表现相似；但在需要更高级思维（分析、评估）的模块上，精熟学习组的学生表现更好，对PCPs的理解也更深入。

**Conclusion:** 精熟学习能够有效提高学生在学习数据可视化技术时对复杂任务的表现和深层理解。

> **ai_Abstract:** 本研究探讨了精熟学习在教授学生并行坐标图（PCPs）方面的有效性。通过在数据可视化课程中进行干预，并结合修订版布鲁姆分类法，研究发现精熟学习组的学生在需要高级思维（如分析和评估）的PCP素养测试模块上表现优于非精熟学习组，表明精熟学习能促进对复杂概念的更深层次理解。研究还提供了所有实验材料以供复现。

> **摘要翻译:** 掌握学习能提高PCP素养测试中复杂任务的表现

开发对并行坐标图（PCPs）等不熟悉的数据可视化技术的素养对学生来说可能是一个重大挑战。我们采用修订版布鲁姆分类法，在课堂上使用精熟学习教授学生并行坐标图（PCPs）。为了评估精熟学习的影响，我们在数据可视化课程中进行了一项干预，使用修订版布鲁姆分类法，在有精熟学习和无精熟学习的情况下教授学生PCPs。根据我们的干预，我们发现，虽然两组学生在前两个模块（记忆、理解）上的表现相似，但精熟学习组的学生在需要更高级思维（分析、评估）的模块上表现更好，并展示了对PCPs更好的理解。我们提供了所有开发材料，包括六模块的布鲁姆分类法PCP素养（BTPL）测试，以便在我们的网站https://vis-graphics.github.io/PCP-Literacy-Test/上完全重现。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [61] [Intergenerational AI Literacy in Korean Immigrant Families: Interpretive Gatekeeping Meets Convenient Critical Deferment](https://arxiv.org/abs/2506.10197)
> *韩裔移民家庭中的代际AI素养：解释性把关与便捷式批判推迟*

*Jeongone Seo, Ryan Womack, Tawfiq Ammari* | **Main category: cs.HC**

**Keywords:** AI素养, 移民家庭, 代际, 解释性把关, 批判推迟

**Comment:** 

> **TL;DR:** 本研究探讨了韩裔移民家庭如何应对AI工具的使用，发现父母通过“解释性把关”中介子女的AI使用，而青少年则通过“便捷式批判推迟”优先考虑即时效用，挑战了传统的AI素养模型，揭示其为一种动态的家庭协商实践。

**AI_Comments:** 该研究创新性地将AI素养置于家庭互动和文化背景中进行考察，超越了传统的技能导向模型。它揭示了移民家庭在AI融入过程中面临的独特挑战和适应策略，特别是“解释性把关”和“便捷式批判推迟”这两个概念的提出，为理解代际间AI使用和素养的形成提供了新的视角。这对于未来设计更具包容性和文化适应性的AI系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能（AI）深度融入家庭生活，移民家庭在代际、语言和文化上面临独特挑战，因此需要研究韩裔移民家庭如何协商AI工具的使用。

**Method:** 通过对20名韩裔移民家庭的家长和青少年进行半结构化访谈。

**Result:** 识别出两种关键实践：父母的“解释性把关”（通过文化和道德价值观中介子女的AI使用）和青少年的“便捷式批判推迟”（为即时学术和社交效用而策略性推迟批判性评估）。这些实践表明AI素养是一种通过持续家庭协商共同构建的动态关系实践，而非传统的基于技能的模型。

**Conclusion:** AI素养是家庭协商共同构建的动态关系实践，而非传统的基于技能的模型。研究为代际AI素养提供了新的概念延伸，并为更公平、文化适应和以家庭为中心的AI系统提供了设计启示。

> **ai_Abstract:** 本研究深入分析了AI在韩裔移民家庭中的应用和协商过程。通过访谈，论文揭示了父母的“解释性把关”和青少年的“便捷式批判推迟”这两种关键实践如何共同塑造了家庭内部的AI素养。研究挑战了传统上将AI素养视为技能习得的观念，提出它是一种动态且通过家庭持续协商共同构建的关系性实践，并为设计更具文化敏感性和以家庭为中心的AI系统提供了重要的设计启示。

> **摘要翻译:** 随着人工智能（AI）深度融入家庭生活，移民家庭必须应对独特的代际、语言和文化挑战。本研究考察了在美国的韩裔移民家庭如何协商在家庭中使用ChatGPT和智能助手等AI工具。通过对20名家长和青少年进行半结构化访谈，我们识别出两种塑造他们参与的关键实践：解释性把关，即父母通过文化和道德价值观的视角中介子女的AI使用；以及便捷式批判推迟，即青少年为了即时的学术和社交效用而策略性地推迟对AI的批判性评估。这些相互交织的实践挑战了传统的、基于技能的AI素养模型，揭示出AI素养是一种通过持续的家庭协商共同构建的动态关系实践。我们通过为代际AI素养提供新的概念延伸，并为更公平、文化适应和以家庭为中心的AI系统提供设计启示，从而对信息科学和人机交互领域做出贡献。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [88] [Speculative Design in Spiraling Time: Methods and Indigenous HCI](https://arxiv.org/abs/2506.10229)
> *推测性设计在螺旋时间中：方法与原住民人机交互*

*James Eschrich, Cole McMullen, Sarah Sterman* | **Main category: cs.HC**

**Keywords:** 推测性设计,原住民人机交互,螺旋时间,时间性,立场论文

**Comment:** 3 pages, 1 figure, presented at the "Weaving Indigeneity and Culture
  into the Fabric of HCI Futures" Workshop at CHI '25

> **TL;DR:** 本立场论文讨论了推测性设计在原住民人机交互中的应用，指出其时间性假设的局限性，并提出了基于“螺旋时间”的替代理解。

**AI_Comments:** 这篇论文通过引入“螺旋时间”这一概念，为推测性设计在特定文化背景（原住民人机交互）下的应用提供了新的视角和创新思路，挑战了传统推测性设计中可能存在的线性时间假设，具有重要的理论意义和实践指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在探讨推测性设计在原住民人机交互（Indigenous HCI）中的应用，并指出其现有时间性假设可能削弱其在此背景下的有效性。

**Method:** 本文是一篇立场论文，通过讨论推测性设计在原住民人机交互中的应用、概述其时间性假设的局限性，并草拟基于“螺旋时间”概念的替代理解。

**Result:** 论文提出了基于“螺旋时间”概念的推测性设计替代理解，认为这种理解可能更适合原住民人机交互。

**Conclusion:** 基于“螺旋时间”概念的推测性设计替代理解，可能更适合原住民人机交互。

> **ai_Abstract:** 这篇立场论文探讨了推测性设计在原住民人机交互（Indigenous HCI）中的应用。论文指出，推测性设计中关于时间性的一个核心假设可能限制其在原住民人机交互语境下的有效性。为此，作者提出了一种基于“螺旋时间”概念的推测性设计新理解，认为这种方法可能更契合原住民人机交互的需求。

> **摘要翻译:** 在这篇立场论文中，我们首先讨论了推测性设计作为原住民人机交互的一种方法被采纳的情况。然后，我们概述了一个关于时间性的关键假设如何可能削弱推测性设计在此背景下的实用性。最后，我们简要地勾勒出一种基于“螺旋时间”概念的推测性设计的可能替代理解，这种理解可能更适合原住民人机交互。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [114] [Extended Creativity: A Conceptual Framework for Understanding Human-AI Creative Relations](https://arxiv.org/abs/2506.10249)
> *扩展创造力：理解人机创造性关系的概念框架*

*Andrea Gaggioli, Sabrina Bartolotta, Andrea Ubaldi, Katusha Gerardini, Eleonora Diletta Sarcinella, Alice Chirico* | **Main category: cs.HC**

**Keywords:** 人工智能, 创造力, 人机协作, 概念框架, 分布式创造力

**Comment:** 36 pages, 3 figures. This conceptual paper proposes a taxonomy of
  Extended Creativity systems and examines the relational dynamics between
  human and AI agents in creative processes. Suitable for readers in HCI, AI,
  cognitive science, and digital design. The illustrations were created by
  Francesco Giordano and are used with permission (not under CC license)

> **TL;DR:** 本文提出了一个概念框架，用于理解AI如何通过支持、协同和共生三种模式增强人类创造力，并讨论了其影响。

**AI_Comments:** 这篇论文通过提出“支持、协同、共生”三种人机创造力关系模式，提供了一个清晰且富有洞察力的概念框架，有助于理解和指导AI在创造力领域的应用。其创新之处在于将AI的自主性和感知能动性作为关键维度，对人机协作的复杂性进行了细致的划分，这对于未来AI辅助创意工具的设计和伦理考量具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能在增强人类创造力方面具有巨大潜力，但如何有效地实现这种增强仍缺乏清晰的理解。

**Method:** 论文采用分布式创造力的视角，提出了AI贡献于创造过程的三种主要模式（支持、协同、共生），并根据AI系统所展示的技术自主性水平和归因于它的感知能动性程度来定义这些模式。

**Result:** 识别出AI增强人类创造力的三种模式：支持（AI作为工具）、协同（人机互补协作）和共生（人机认知高度整合）。并探讨了每种配置如何影响不同层级的创造力。

**Conclusion:** 论文讨论了所提出的模式在理论、伦理和设计方面的含义，为理解和实现人机创造性增强提供了指导。

> **ai_Abstract:** 本文提出了一个名为“扩展创造力”的概念框架，旨在阐明人工智能如何有效增强人类创造力。该框架基于分布式创造力视角，识别了AI在创造过程中发挥作用的三种模式：支持（AI为工具）、协同（人机互补协作）和共生（人机认知高度整合）。这些模式通过AI的技术自主性和感知能动性程度来界定。论文探讨了这些模式对不同创造力水平的影响，并讨论了其理论、伦理和设计层面的启示。

> **摘要翻译:** 人工智能在增强人类创造力方面具有巨大潜力。然而，实现这一愿景需要更清晰地理解如何有效地实现这种增强。本文采用分布式创造力的视角，识别出人工智能可以为创造过程做出贡献的三种主要模式：支持（AI充当工具）、协同（AI和人类以互补方式协作）和共生（人类和AI的认知高度整合，形成一个统一的创造系统）。这些模式是根据两个关键维度定义的：AI系统所展示的技术自主性水平以及归因于它的感知能动性程度。我们研究了每种配置如何影响不同水平的创造力——从日常问题解决到范式转变的创新——并讨论了其理论、伦理和设计含义。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [136] [Beyond Compliance: A User-Autonomy Framework for Inclusive and Customizable Web Accessibility](https://arxiv.org/abs/2506.10324)
> *超越合规：一个包容性与可定制网络可访问性的用户自主框架*

*Lalitha A R* | **Main category: cs.HC**

**Keywords:** 网络可访问性, 用户自主, 舒适模式, 个性化, 数字包容性

**Comment:** 

> **TL;DR:** 提出一种以用户自主为中心的可定制“舒适模式”框架，将网络可访问性从静态合规转变为灵活的个性化体验，以提升数字包容性。

**AI_Comments:** 这篇论文的创新点在于其将网络可访问性从传统的“合规性检查表”模式提升到以“用户自主”为核心的关怀驱动模型，特别是通过引入“舒适模式”框架，允许用户进行个性化设置，同时兼顾品牌美学。这种方法对于提升数字包容性具有重要意义，因为它强调了用户选择权，避免了“一刀切”的强制性改变，为不同需求的用户提供了更灵活、更友好的数字体验。

<details>
  <summary>Details</summary>

**Motivation:** 现有的网络可访问性标准常被视为静态合规清单，未能充分满足用户个性化需求，特别是神经多样性用户。论文旨在提出一种以用户自主为中心的关怀模式。

**Method:** 提出一个可定制的“舒适模式”框架，允许用户根据个人需求调整界面设置（如对比度、排版、动态和缩放），同时保留品牌核心视觉识别。该设计基于心理和认知可访问性原则，并展示了最小和高级的实现模型及模型图。

**Result:** 展示了包容性设计如何以最小成本无缝集成到网站中。该方法旨在通过提供选择而非强加改变，扩大数字包容性。

**Conclusion:** 论文提出了一种新的范式，即用户自主性、美学完整性和可访问性通过选择而非妥协而融合，该系统具有适应性、可扩展性，适用于广泛的用户和品牌。

> **ai_Abstract:** 本文提出一个以用户自主为中心的可定制“舒适模式”框架，旨在将网络可访问性从静态合规模式转变为灵活、关怀驱动的个性化体验。该框架允许用户根据自身需求调整界面设置，同时保持品牌视觉一致性。论文基于心理和认知原则，展示了如何以低成本实现包容性设计，从而提升数字包容性，实现用户自主、美学和可访问性的融合。

> **摘要翻译:** 本文提出将以合规为中心的网络可访问性转变为以关怀为驱动的模型，该模型优先考虑用户自主性，并以神经多样性用户作为更广泛个性化需求的催化案例。尽管可访问性标准提供了一个灵活的框架，但它们通常被解释和实施为静态的合规清单，我们的方法将其重新定义为一个灵活的、以用户为中心的过程。我们引入了一个可定制的“舒适模式”框架，允许用户根据其个人需求调整界面设置，例如对比度、排版、动态和缩放，同时保留品牌的核心视觉识别。我们的设计以心理和认知可访问性原则为基础，在不牺牲创意自由的情况下支持个性化。我们提供了最小和高级的实现模型及模型图，展示了如何以最小成本无缝集成包容性设计。这种方法旨在通过向需要的人提供自主权，而不向不需要的人强加改变，从而扩大数字包容性。所提出的系统具有适应性、可扩展性，适用于广泛的用户和品牌，提供了一种新的范式，其中用户自主性、美学完整性和可访问性不是通过妥协而是通过选择而融合。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [156] [IDEA: Augmenting Design Intelligence through Design Space Exploration](https://arxiv.org/abs/2506.10587)
> *IDEA：通过设计空间探索增强设计智能*

*Chuer Chen, Xiaoke Yan, Xiaoyu Qi, Nan Cao* | **Main category: cs.HC**

**Keywords:** 设计智能, 设计空间探索, LLM, MCTS, 自动化设计

**Comment:** 

> **TL;DR:** IDEA是一个利用LLM和MCTS的决策框架，通过设计空间探索来增强设计智能，并在文章创作和可视化生成中展现出卓越的设计成果和跨领域适应性。

**AI_Comments:** 这项研究的创新之处在于将LLMs和MCTS结合应用于设计空间探索，为自动化设计提供了计算支持，弥补了传统设计依赖经验和缺乏形式化的问题。其在多个领域的验证也显示了其潜在的广泛应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前设计中的有效决策严重依赖设计师经验，且缺乏数学形式化阻碍了自动化设计过程的计算支持。

**Method:** 本文引入了一种结构化表示来建模设计空间，并提出了IDEA框架。IDEA利用大型语言模型（LLMs）生成约束，结合蒙特卡洛树搜索（MCTS）算法在这些约束指导下高效探索设计空间，并将抽象决策实例化为特定领域的实现。

**Result:** IDEA在数据驱动的文章创作和图像可视化生成两个设计场景中进行了验证，并通过示例结果、专家访谈和用户研究得到支持。评估表明IDEA具有跨领域的适应性以及产生卓越设计成果的能力。

**Conclusion:** IDEA框架能够通过设计空间探索有效地增强设计智能，并能够在不同设计场景中生成高质量的设计方案。

> **ai_Abstract:** IDEA是一个创新的决策框架，旨在通过设计空间探索增强设计智能。它通过结构化表示建模设计空间，并结合大型语言模型（LLMs）生成约束和蒙特卡洛树搜索（MCTS）算法进行高效探索。该框架在文章创作和可视化生成等场景中得到验证，展示了其跨领域适应性和生成卓越设计成果的能力，解决了当前设计中缺乏计算支持的挑战。

> **摘要翻译:** 设计空间作为一种概念框架，使设计师能够通过选择和组合设计元素来探索可行的解决方案。然而，有效的决策仍然严重依赖于设计师的经验，并且缺乏数学形式化阻碍了自动化设计过程的计算支持。为了弥补这一差距，我们引入了一种结构化表示，该表示通过正交维度和离散可选择元素来建模设计空间。在此模型的基础上，我们提出了IDEA，一个通过设计空间探索来增强设计智能以生成有效结果的决策框架。具体而言，IDEA利用大型语言模型（LLMs）进行约束生成，结合蒙特卡洛树搜索（MCTS）算法在这些约束的指导下高效探索设计空间，并将抽象决策实例化为特定领域的实现。我们在两种设计场景中验证了IDEA：数据驱动的文章创作和图像可视化生成，并辅以示例结果、专家访谈和用户研究。评估表明IDEA具有跨领域的适应性及其产生卓越设计成果的能力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [176] [Accessible Design in Integrated Development Environments: A Think Aloud Study Exploring the Experiences of Students with ADHD](https://arxiv.org/abs/2506.10598)
> *集成开发环境中的可访问性设计：一项探索ADHD学生体验的“出声思考”研究*

*Luke Halpin, Phillip Benachour, Tracy Hall, Ann-Marie Houghton, Emily Winter* | **Main category: cs.HC**

**Keywords:** ADHD, 集成开发环境, 可访问性设计, 用户体验, 出声思考

**Comment:** 16 pages, 3 figures, ECTEL 2025

> **TL;DR:** 研究ADHD学生在使用IDE时的体验，发现现有设计存在挫折和障碍，强调需改进可访问性以提升学习体验。

**AI_Comments:** 这项研究通过深入的定性方法，为理解ADHD学生在使用IDE时的独特挑战提供了宝贵的见解。其创新之处在于聚焦了一个常被忽视的用户群体，并直接揭示了现有工具设计中的不足。研究结果对于推动更具包容性的软件开发工具设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前尚不清楚集成开发环境（IDE）的界面设计如何影响注意力缺陷多动障碍（ADHD）学生，而IDE是计算机科学教育的关键工具，因此有必要进行本研究以了解其影响。

**Method:** 本研究对九名大学计算机专业学生进行了“出声思考”研究，随后进行定性观察访谈，以分析他们对Visual Studio Code IDE的学习和参与情况。定性数据通过主题分析法进行分析。

**Result:** 识别出三个主要主题：自信心、互动和学习，以及各种子主题。主要发现强调了现有IDE设计和布局中的挫折和障碍体验。

**Conclusion:** 现有IDE设计对ADHD学生存在挑战，需要更好地设计开发环境以确保积极的学习体验。在为ADHD学生设计IDE时，应考虑可访问性和可用性方面的关键领域。

> **ai_Abstract:** 本研究通过对9名ADHD大学计算机学生进行“出声思考”研究和定性访谈，探讨了集成开发环境（IDE）对其学习体验的影响。研究发现，现有IDE设计在可访问性和可用性方面存在问题，导致学生产生挫折感和学习障碍。通过主题分析，研究确定了自信心、互动和学习三个主要主题。论文强调了为ADHD学生改进IDE设计的必要性，以促进更积极的学习体验。

> **摘要翻译:** 编程是大学计算机科学教育的重要组成部分。作为教育的一部分，集成开发环境（IDE）是重要的编程工具。然而，目前尚不清楚IDE的界面设计如何影响注意力缺陷多动障碍（ADHD）学生。
在本研究中，我们调查了ADHD学生对IDE的使用情况。我们对九名大学计算机专业学生进行了一项“出声思考”研究，随后进行了定性观察访谈，以分析他们对Visual Studio Code IDE的学习和参与情况。本文报告了这些经验，并试图理解IDE在教育环境中的作用。
我们的工作还审查了当前IDE设计中如何考虑数字可访问性和可用性。我们使用主题分析法分析了定性数据，并确定了三个主要主题：自信心、互动和学习，以及各种子主题。
这些主题及其子主题阐明了在为ADHD学生设计IDE时需要考虑的关键领域。主要发现强调了现有IDE设计和布局中的挫折和障碍体验。
通过我们的参与式方法，我们提供了关于ADHD用户在使用性与可访问性方面体验的罕见见解，并描述了需要更好地设计开发环境以确保学生获得积极学习体验的需求。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [190] [Integrating Large Language Models into Text Animation: An Intelligent Editing System with Inline and Chat Interaction](https://arxiv.org/abs/2506.10762)
> *将大型语言模型集成到文本动画中：一个具有内联和聊天交互的智能编辑系统*

*Bao Zhang, Zihan Li, Zhenglei Liu, Huanchen Wang, Yuxin Ma* | **Main category: cs.HC**

**Keywords:** 大型语言模型, 文本动画, 智能编辑系统, 用户交互, 创意工作流程

**Comment:** 

> **TL;DR:** 本文提出了一种由LLM辅助的智能文本动画编辑系统，通过双流交互（内联建议和聊天指导）和语义-动画映射，帮助非专业人士更轻松地创建动画。

**AI_Comments:** 该论文解决了使文本动画更易于访问的实际问题。将LLM与双流交互和语义映射相结合，是简化复杂创意工作流程的创新方法。这项工作对于视频内容创作的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的文本动画工作流程对非专业人士来说存在显著的可用性障碍，操作复杂，严重阻碍了创作生产力。

**Method:** 本文提出了一种由大型语言模型（LLM）辅助的文本动画编辑系统。该系统引入了一个基于代理的双流管道，集成了上下文感知的内联建议和对话指导，并采用语义-动画映射来促进LLM驱动的创意意图翻译。此外，系统支持通过统一控件进行同步的文本-动画预览和参数调整。

**Result:** 一项用户研究评估了该系统，结果表明它能够帮助非专业用户完成动画工作流程，并验证了其管道的有效性。

**Conclusion:** 研究结果鼓励进一步探索将大型语言模型集成到全面的视频创作工作流程中。

> **ai_Abstract:** 本文介绍了一种由大型语言模型（LLM）驱动的智能文本动画编辑系统，旨在解决传统动画工具对非专业用户造成的可用性挑战。该系统采用基于代理的双流管道，提供内联建议和聊天指导，并通过语义-动画映射实现创意意图的转换，同时支持统一控制下的预览和参数调整。用户研究验证了其在帮助非专业用户完成动画工作流程方面的有效性，并预示了其在更广泛视频创作应用中的潜力。

> **摘要翻译:** 文本动画作为视频创作的基础元素，在广告、新闻和社交媒体中蓬勃发展，能够实现高效且经济的沟通。然而，传统的动画工作流程对非专业人士来说存在显著的可用性障碍，复杂的S操作程序严重阻碍了创作生产力。为了解决这个问题，我们提出了一种由大型语言模型（LLM）辅助的文本动画编辑系统，该系统能够实现实时意图跟踪和灵活编辑。该系统引入了一个基于代理的双流管道，集成了上下文感知的内联建议和对话指导，并采用语义-动画映射来促进LLM驱动的创意意图翻译。此外，该系统支持通过统一控件进行同步的文本-动画预览和参数调整，以改进编辑工作流程。一项用户研究评估了该系统，突出了其帮助非专业用户完成动画工作流程的能力，并验证了其管道。研究结果鼓励进一步探索将LLM集成到全面的视频创作工作流程中。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [204] [Grasp Prediction based on Local Finger Motion Dynamics](https://arxiv.org/abs/2506.10818)
> *基于局部手指运动动力学的抓取预测*

*Dimitar Valkov, Pascal Kockwelp, Florian Daiber, Antonio Krüger* | **Main category: cs.HC**

**Keywords:** 抓取预测, 手部运动学, LSTM, 实时识别, 混合现实

**Comment:** 10 pages

> **TL;DR:** 该研究探索了基于手部运动学实时识别未被仪器化的物体抓取的可行性和准确性，并发现简单的LSTM网络能高精度预测抓取时间点、距离和目标大小。

**AI_Comments:** 该论文的创新点在于证明了仅通过手部运动学数据，即使是简单的机器学习模型也能实现对用户抓取意图的高精度预测，且无需对物体进行额外仪器化。其重要性在于为未来普适计算和混合现实环境中更智能、更自然的交互界面设计提供了新的可能性，尤其是在处理延迟和提供上下文信息方面。

<details>
  <summary>Details</summary>

**Motivation:** 预测用户意图抓取的物体能提供重要的上下文信息，并有助于利用交互环境中点对点延迟的影响。

**Method:** 通过数据收集研究，记录了16名参与者在伸向并抓取真实和合成物体时的手部运动，并使用简单的LSTM网络进行预测。

**Result:** 一个简单的LSTM网络能够以优于21毫秒的精度预测用户抓取物体的时间点，以优于1厘米的精度预测到该物体的当前距离。目标大小可以提前以优于97%的准确率确定。

**Conclusion:** 研究结果对于在普适计算和混合现实环境中设计自适应和细粒度的交互式用户界面具有重要意义。

> **ai_Abstract:** 本研究探讨了在抓取动作中，利用手部运动学实时识别未被仪器化的物体的可行性与准确性。通过记录16名参与者的手部运动数据，研究发现即使是简单的LSTM网络也能高精度预测用户抓取物体的时间点（优于21毫秒）、到物体距离（优于1厘米），以及提前确定目标大小（优于97%）。这些发现为普适计算和混合现实环境中自适应、精细化交互界面的设计提供了基础。

> **摘要翻译:** 用户预测抓取物体的能力提供了必要的上下文信息，并有助于利用交互环境中点对点延迟的影响。本文探讨了在抓取动作中基于手部运动学实时识别未被仪器化的物体的可行性和准确性。在一项数据收集研究中，我们记录了16名参与者在伸向并抓取真实和合成物体时的手部运动。我们的结果表明，即使是一个简单的LSTM网络也能以优于21毫秒的精度预测用户抓取物体的时间点，并以优于1厘米的精度预测到该物体的当前距离。目标大小可以提前以优于97%的准确率确定。我们的结果对于在普适计算和混合现实环境中设计自适应和细粒度的交互式用户界面具有重要意义。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [221] [(De)composing Craft: An Elementary Grammar for Sharing Expertise in Craft Workflows](https://arxiv.org/abs/2506.10891)
> *解构工艺：一种用于分享工艺工作流程中专业知识的基本语法*

*Ritik Batra, Lydia Kim, Ilan Mandel, Amritansh Kwatra, Jane L. E., Steven J. Jackson, Thijs Roumen* | **Main category: cs.HC**

**Keywords:** 手工艺, 知识共享, 默会知识, 文档化, 即兴创作

**Comment:** 29 pages, 7 figures

> **TL;DR:** 该研究开发了一种基本语法和名为CraftLink的界面，用于更好地记录和分享手工艺中的即兴和情境知识，以克服传统文档只关注线性步骤的局限性。

**AI_Comments:** 该论文的创新之处在于它超越了传统线性步骤的文档方式，专注于捕捉手工艺中难以言传的默会知识和即兴创作过程。通过引入“基本语法”的概念和开发CraftLink界面，为手工艺知识的数字化和共享提供了新的视角和工具，有助于提升手工艺的传承和发展。其重要性在于，它将手工艺视为一种复杂的认知和实践活动，而不仅仅是机械操作，这对于保护和传播非物质文化遗产具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手工艺实践依赖于不断发展的技能和知识档案，但大多数现有文档仅关注线性步骤，忽略了即兴创作或根据项目独特需求调整工作流程所需的默会知识，这限制了知识共享，并将手工艺简化为机械性工作。

**Method:** 通过专家访谈和人机交互、计算机支持的协同工作以及社会科学领域的文献，研究开发了一种用于记录真实世界手工艺实践中即兴行动的基本语法。并通过名为CraftLink的界面展示了该语法的实用性，该界面可用于分析专家视频并半自动生成文档，以传达手工艺实践的材料和情境变化。

**Result:** 研究通过CraftLink界面与7位专业钩针编织者进行了用户研究，评估了该语法在捕捉和分享专家知识方面的有效性，为计算系统支持社区内的知识和实践协作档案提供了新途径。

**Conclusion:** 本研究提出的语法和系统为计算系统支持手工艺社区内部的知识和实践协作档案提供了新的途径，能够更有效地捕捉和分享手工艺中重要的默会和情境知识。

> **ai_Abstract:** 本研究旨在解决手工艺知识文档中默会和情境知识缺失的问题。通过专家访谈和多学科文献回顾，研究开发了一种用于记录手工艺即兴行动的基本语法。该语法通过名为CraftLink的界面进行验证，该界面能够分析专家视频并半自动生成包含材料和情境变化的文档。用户研究表明，该语法能有效捕捉和分享专家知识，为计算系统支持手工艺社区的知识共享提供了新途径。

> **摘要翻译:** 手工艺实践依赖于不断发展的技能和知识档案，这些档案通过一代代手工艺人在设计、材料和技术方面的实验而发展起来。更好地记录这些实践有助于在不同地点和世代之间分享知识和专业技能。然而，大多数文档只关注导致最终成品的线性步骤，而忽略了即兴创作或根据每个手工艺项目的独特需求调整工作流程所需的默会知识。这种遗漏限制了知识共享，并将手工艺简化为一种机械性工作，而非一种复杂的观察、思考和实践方式。本研究借鉴了专家访谈以及人机交互（HCI）、计算机支持的协同工作（CSCW）和社会科学领域的文献，开发了一种基本语法来记录真实世界手工艺实践中的即兴行动。我们通过一个名为CraftLink的界面展示了该语法的实用性，该界面可用于分析专家视频并半自动生成文档，以传达手工艺实践的材料和情境变化。我们对7位专业钩针编织者（N=7）使用该界面进行了用户研究，评估了我们语法在捕捉和与同行手工艺者分享专家知识方面的有效性，为计算系统支持社区内的知识和实践协作档案提供了新途径。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [236] [The Role of Generative AI in Facilitating Social Interactions: A Scoping Review](https://arxiv.org/abs/2506.10927)
> *生成式AI在促进社会互动中的作用：一项范围综述*

*T. T. J. E. Arets, G. Perugia, M. Houben, W. A. IJsselsteijn* | **Main category: cs.HC**

**Keywords:** 生成式AI, 社会互动, 范围综述, 人工智能设计, 伦理考量

**Comment:** Preprint version of a manuscript submitted to ACM Transactions on
  Computer-Human Interaction (TOCHI), under review. 39 pages, 4 figures

> **TL;DR:** 这项范围综述调查了生成式AI（GAI）如何被设计用于促进社会互动，识别了应用领域、设计方法和伦理担忧，并强调了GAI支持个性化互动的潜力以及对公平设计的需求。

**AI_Comments:** 这篇综述及时地探讨了生成式AI在改善社会互动方面的潜在益处和挑战，特别是在当前社会联系日益减少的背景下。其创新之处在于系统性地梳理了GAI在不同社交应用场景中的设计和评估实践，并强调了公平性与包容性的重要性，为未来GAI的开发提供了伦理和设计上的指导。

<details>
  <summary>Details</summary>

**Motivation:** 社交联系减少日益对心理健康、预期寿命和整体福祉构成威胁。尽管生成式AI（GAI）技术（如大型语言模型和图像生成工具）越来越多地被整合到旨在增强人类社交体验的应用中，但人们对其如何影响社交互动知之甚少。

**Method:** 这是一项范围综述，分析了自2020年以来发表的30项研究，以调查基于GAI的应用如何被设计用于促进社交互动，它们针对何种形式的社交参与，以及设计人员使用哪些设计和评估方法来创建和评估它们。

**Result:** 识别了应用领域中的关键趋势，包括讲故事、社交情感技能训练、回忆、协作学习、音乐制作和一般对话。强调了参与式和协同设计方法在促进有效技术使用和社交参与方面的作用。审视了社会伦理问题，如文化偏见和可访问性。

**Conclusion:** 生成式AI有潜力支持动态和个性化的互动，但需要更多地关注公平的设计实践和包容性的评估策略。

> **ai_Abstract:** 这项范围综述考察了生成式AI（GAI）在促进社会互动中的作用，旨在理解GAI应用的设计方式、目标社交形式以及所用的设计与评估方法。通过分析30项研究，综述揭示了GAI在讲故事、技能训练等多个领域的应用趋势，并强调了参与式设计的重要性。同时，它也探讨了文化偏见和可访问性等伦理挑战，并最终指出GAI在支持个性化互动方面的潜力，呼吁未来的设计应更加公平和包容。

> **摘要翻译:** 社交联系减少日益对心理健康、预期寿命和整体福祉构成威胁。生成式人工智能（GAI）技术，如大型语言模型（LLMs）和图像生成工具，正越来越多地被整合到旨在增强人类社交体验的应用中。尽管它们日益普及，但人们对这些技术如何影响社交互动知之甚少。这项范围综述调查了基于GAI的应用目前是如何被设计来促进社交互动的，它们针对何种形式的社交参与，以及设计者使用哪些设计和评估方法来创建和评估它们。通过对自2020年以来发表的30项研究的分析，我们确定了应用领域中的关键趋势，包括讲故事、社交情感技能训练、回忆、协作学习、音乐制作和一般对话。我们强调了参与式和协同设计方法在促进有效技术使用和社交参与方面的作用，同时还审视了文化偏见和可访问性等社会伦理问题。本综述强调了GAI支持动态和个性化互动的潜力，但呼吁更多地关注公平的设计实践和包容性的评估策略。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [248] [Video-Mediated Emotion Disclosure: A Study of Mental Health Vlogging by People with Schizophrenia on YouTube](https://arxiv.org/abs/2506.10932)
> *视频介导的情绪披露：一项关于精神分裂症患者在YouTube上心理健康视频博客的研究*

*Jiaying Lizzy Liu, Yan Zhang* | **Main category: cs.HC**

**Keywords:** 情绪披露, 视频博客, 精神分裂症, YouTube, 视觉沟通

**Comment:** 10 pages

> **TL;DR:** 本研究分析了精神分裂症患者在YouTube上通过视频博客进行情绪披露的方式，发现视觉元素对观众的反应有重要影响。

**AI_Comments:** 这项研究的创新之处在于其将研究重点从传统的文本情绪披露转向了视频介导的情绪表达，特别关注了精神分裂症患者这一特定群体。其提出的视觉分析框架以及对视觉元素重要性的发现，为理解社交媒体上心理健康内容的构建提供了新的视角，并对未来开发支持性平台具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 以往研究主要关注基于文本的情绪披露，但对于精神分裂症患者如何在视频博客中构建情绪叙事知之甚少。本研究旨在填补这一空白。

**Method:** 本研究分析了200个由精神分裂症患者在YouTube上创建的视频。研究借鉴媒体研究和自我呈现理论，开发了一个视觉分析框架来解构这些视频。

**Result:** 分析揭示了通过言语和视觉渠道进行情绪披露的多种实践，强调了这些表达模式之间的动态相互作用。研究发现，视觉元素的精心构建（包括环境设置和特定的美学选择）似乎能促进更具支持性和参与性的观众反应。

**Conclusion:** 这些发现强调了未来需要进行大规模的定量研究，以检验视觉特征如何塑造社交媒体平台上的视频介导交流。此类研究将为开发以护理为中心的视频共享平台提供信息，从而更好地支持管理疾病体验的个体。

> **ai_Abstract:** 本研究旨在探索精神分裂症患者在YouTube上通过视频博客进行情绪披露的方式。通过分析200个视频，并运用媒体研究和自我呈现理论构建的视觉分析框架，研究发现患者通过言语和视觉渠道多样化地表达情绪。特别地，精心设计的视觉元素，如环境和美学选择，能够显著提升观众的支持和参与度。研究强调了未来需要深入探究视觉特征在视频介导沟通中的作用，以期开发更具支持性的心理健康视频平台。

> **摘要翻译:** 精神分裂症患者经常经历强烈的情绪，并常转向视频博客作为情绪表达的媒介。虽然之前的研究主要集中在基于文本的披露上，但对于个体如何在视频博客中构建围绕情绪和情感体验的叙事知之甚少。我们的研究通过分析200个由精神分裂症患者创建的YouTube视频来解决这一空白。借鉴媒体研究和自我呈现理论，我们开发了一个视觉分析框架来解构这些视频。我们的分析揭示了通过言语和视觉渠道进行情绪披露的多种实践，突出了这些表达模式之间的动态相互作用。我们发现，视觉元素的精心构建，包括环境设置和特定的美学选择，似乎能促进更具支持性和参与性的观众反应。这些发现强调了未来需要进行大规模的定量研究，以检验视觉特征如何塑造社交媒体平台上的视频介导交流。此类调查将为开发以护理为中心的视频共享平台提供信息，从而更好地支持管理疾病体验的个体。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [259] [Instance-Based Transfer Learning with Similarity-Aware Subject Selection for Cross-Subject SSVEP-Based BCIs](https://arxiv.org/abs/2506.10933)
> *基于实例的迁移学习，结合相似度感知的受试者选择用于跨受试者SSVEP-BCI*

*Ziwen Wang, Yue Zhang, Zhiqiang Zhang, Sheng Quan Xie, Alexander Lanzon, William P. Heath, Zhenhong Li* | **Main category: cs.HC**

**Keywords:** 迁移学习, SSVEP-BCI, 受试者选择, 个体差异, 任务相关成分分析

**Comment:** IEEE Journal of Biomedical and Health Informatics

> **TL;DR:** 本研究提出了一种名为iTRCA的新型迁移学习框架及其增强版SS-iTRCA，通过提取通用和特定特征并结合相似度选择，有效减少了SSVEP-BCI对目标受试者数据的需求并提高了性能。

**AI_Comments:** 该论文的创新点在于提出了iTRCA和SS-iTRCA两种迁移学习框架，特别是在SSVEP-BCI领域。通过区分主体通用和主体特定特征，并引入相似度感知的受试者选择机制，有效地解决了跨受试者迁移学习中个体差异带来的负迁移问题，并降低了对目标受试者数据量的要求，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 稳态视觉诱发电位（SSVEP）脑机接口（BCI）需要大量训练数据才能达到高识别精度。迁移学习有望通过利用源受试者数据来缓解目标受试者的数据需求，但如何有效解决目标和源受试者之间的个体差异仍然是一个挑战。

**Method:** 本文提出了一种名为实例基任务相关成分分析（iTRCA）的新型迁移学习框架，它从源受试者那里获取知识，同时考虑他们的个体贡献。iTRCA提取两种特征：主体通用特征（捕获源和目标受试者在共同潜在空间中的共享信息）和主体特定特征（保留目标受试者的独特特征）。为了减轻负迁移，进一步设计了增强框架——基于受试者选择的iTRCA（SS-iTRCA），它整合了基于相似度的受试者选择策略，根据任务相关成分（TRCs）识别合适的源受试者进行迁移。

**Result:** 在Benchmark、BETA和自收集数据集上的比较评估表明，所提出的iTRCA和SS-iTRCA框架是有效的。

**Conclusion:** 本研究为开发高性能、低目标受试者数据需求的SSVEP-BCI提供了一个潜在的解决方案。

> **ai_Abstract:** 本论文提出了一种新的迁移学习框架iTRCA及其增强版SS-iTRCA，旨在解决SSVEP-BCI中个体差异和数据需求过大的问题。iTRCA通过提取主体通用和主体特定特征来利用源受试者知识。SS-iTRCA进一步引入了基于相似度的受试者选择策略，以避免负迁移。实验结果表明，这些框架能够有效提高SSVEP-BCI的性能并减少对目标受试者数据的依赖。

> **摘要翻译:** 稳态视觉诱发电位（SSVEP）脑机接口（BCI）在拥有足够训练数据的情况下可以实现高识别精度。迁移学习提供了一个有前景的解决方案，通过利用源受试者的数据来缓解目标受试者的数据需求；然而，有效解决目标和源受试者之间的个体差异仍然是一个挑战。本文提出了一种名为实例基任务相关成分分析（iTRCA）的新型迁移学习框架，它从源受试者那里获取知识，同时考虑他们的个体贡献。iTRCA提取两种特征：(1)主体通用特征，捕获源和目标受试者在共同潜在空间中的共享信息，以及(2)主体特定特征，保留目标受试者的独特特征。为了减轻负迁移，我们进一步设计了一个增强框架——基于受试者选择的iTRCA（SS-iTRCA），它整合了基于相似度的受试者选择策略，根据任务相关成分（TRCs）识别合适的源受试者进行迁移。在Benchmark、BETA和自收集数据集上的比较评估表明，所提出的iTRCA和SS-iTRCA框架是有效的。本研究为开发高性能、低目标受试者数据需求的SSVEP-BCI提供了一个潜在的解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [7] [TrioXpert: An automated incident management framework for microservice system](https://arxiv.org/abs/2506.10043)
> *TrioXpert：一个用于微服务系统的自动化事件管理框架*

*Yongqian Sun, Yu Luo, Xidao Wen, Yuan Yuan, Xiaohui Nie, Shenglin Zhang, Tong Liu, Xi Luo* | **Main category: cs.SE**

**Keywords:** 微服务系统, 事件管理, 多模态数据, 大型语言模型, 可解释性

**Comment:** 

> **TL;DR:** TrioXpert是一个端到端的自动化事件管理框架，它利用多模态数据和LLM的协同推理机制，显著提高了微服务系统在异常检测、故障分类和根因定位方面的性能，并提供了可解释的推理证据。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的框架TrioXpert，它能够充分利用多模态数据进行微服务系统的事件管理。特别值得关注的是，它引入了大型语言模型（LLMs）进行协同推理，这不仅提高了多任务处理能力，还显著增强了结果的可解释性，解决了现有方法的一大痛点。其在AD、FT和RCL任务上显著的性能提升也证明了其有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有微服务系统事件管理方法主要依赖单一模态数据，难以同时处理异常检测、故障分类和根因定位等多个下游任务，且缺乏清晰的推理证据，导致可解释性不足。

**Method:** TrioXpert提出一个端到端的事件管理框架，充分利用多模态数据。它设计了三个独立的异构数据处理管道，从数值和文本维度全面表征微服务系统的运行状态。该框架采用大型语言模型（LLMs）的协同推理机制，同时处理多任务并提供清晰的推理证据以确保强可解释性。

**Result:** 在两个流行的微服务系统数据集上进行了广泛评估，实验结果表明TrioXpert在异常检测（AD）方面性能提升4.7%至57.7%，故障分类（FT）方面提升2.1%至40.6%，根因定位（RCL）方面提升1.6%至163.1%。

**Conclusion:** TrioXpert通过充分利用多模态数据和LLM的协同推理机制，显著提升了微服务系统自动化事件管理在多个任务上的性能，并解决了可解释性不足的问题。

> **ai_Abstract:** TrioXpert是一个针对微服务系统的自动化事件管理框架，旨在解决现有方法在处理多模态数据、同时执行多任务以及提供可解释性方面的不足。该框架通过设计独立的异构数据处理管道，并利用大型语言模型（LLMs）的协同推理机制，能够全面分析微服务系统的运行状态，并同时处理异常检测、故障分类和根因定位等任务，同时提供清晰的推理证据。实验结果表明，TrioXpert在这些任务上均取得了显著的性能提升。

> **摘要翻译:** 自动化事件管理在大型微服务系统中发挥着关键作用。然而，许多现有方法仅依赖单一模态数据（例如，指标、日志和跟踪），并且难以同时处理多个下游任务，包括异常检测（AD）、故障分类（FT）和根因定位（RCL）。此外，当前技术中缺乏清晰的推理证据常常导致可解释性不足。为了解决这些限制，我们提出了TrioXpert，一个能够充分利用多模态数据的端到端事件管理框架。TrioXpert根据不同模态的内在特性设计了三个独立的数据处理管道，从数值和文本维度全面表征微服务系统的运行状态。它采用大型语言模型（LLMs）的协同推理机制，同时处理多个任务，并提供清晰的推理证据以确保强可解释性。我们在两个流行的微服务系统数据集上进行了广泛评估，实验结果表明TrioXpert在AD（提升4.7%至57.7%）、FT（提升2.1%至40.6%）和RCL（提升1.6%至163.1%）任务中取得了出色的性能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [34] [Online Discovery of Simulation Models for Evolving Business Processes (Extended Version)](https://arxiv.org/abs/2506.10049)
> *演化业务流程仿真模型的在线发现（扩展版）*

*Francesco Vinci, Gyunam Park, Wil van der Aalst, Massimiliano de Leoni* | **Main category: cs.SE**

**Keywords:** 业务流程仿真, 在线发现, 增量过程发现, 在线机器学习, 概念漂移

**Comment:** 

> **TL;DR:** 提出一种流式过程仿真发现技术，结合增量过程发现和在线机器学习，以适应不断变化的业务流程并优先考虑最新数据。

**AI_Comments:** 这篇论文的创新点在于将增量过程发现与在线机器学习相结合，以实现对不断演化的业务流程的实时仿真模型发现。它解决了传统方法在动态环境下的适应性问题，通过优先考虑最新数据同时保留历史信息，提高了仿真的稳定性与鲁棒性，特别是在处理概念漂移方面的表现是其亮点。这对于需要持续优化流程的企业具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有业务流程仿真模型发现技术缺乏对实时操作变化的适应性，无法处理动态业务环境中不断演化的流程。

**Method:** 提出一种流式过程仿真发现技术，该技术将增量过程发现与在线机器学习方法相结合，在保留历史信息的同时优先处理最新数据。

**Result:** 在四种不同事件日志上的实验表明，在仿真中赋予最新数据更高权重同时保留历史知识的重要性。该技术不仅能产生更稳定的仿真，而且在处理概念漂移方面也表现出鲁棒性。

**Conclusion:** 该提出的流式过程仿真发现技术通过集成增量过程发现和在线机器学习，有效解决了动态业务流程中仿真模型发现的适应性问题，实现了更稳定、更鲁棒的仿真，尤其是在处理概念漂移方面。

> **ai_Abstract:** 本文提出了一种流式过程仿真发现技术，旨在解决现有方法在动态业务环境中适应性不足的问题。该技术结合了增量过程发现和在线机器学习，能够优先处理最新数据同时保留历史信息，从而适应不断演进的业务流程。实验证明，该方法能产生更稳定的仿真结果，并有效处理概念漂移。

> **摘要翻译:** 业务流程仿真 (BPS) 是指旨在复制业务流程动态行为的技术。许多方法已被提出用于从历史事件日志中自动发现仿真模型，从而降低手动设计它们的成本和时间。然而，在动态业务环境中，组织不断改进其流程以提高效率、降低成本和改善客户满意度。现有流程仿真发现技术缺乏对实时操作变化的适应性。在本文中，我们提出了一种流式过程仿真发现技术，该技术将增量过程发现与在线机器学习方法相结合。该技术在保留历史信息的同时优先处理最新数据，确保适应不断演进的流程动态。在四种不同事件日志上进行的实验证明了在仿真中赋予最新数据更高权重同时保留历史知识的重要性。我们的技术不仅能产生更稳定的仿真，而且在处理概念漂移方面也表现出鲁棒性，正如其中一个用例所强调的那样。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [59] [The Effects of GitHub Copilot on Computing Students' Programming Effectiveness, Efficiency, and Processes in Brownfield Programming Tasks](https://arxiv.org/abs/2506.10051)
> *GitHub Copilot 对计算机专业学生在棕地编程任务中编程有效性、效率和过程的影响*

*Md Istiak Hossain Shihab, Christopher Hundhausen, Ahsun Tariq, Summit Haque, Yunhan Qiao, Brian Mulanda* | **Main category: cs.SE**

**Keywords:** GitHub Copilot, 棕地编程, 学生编程, 生成式AI, 编程教育

**Comment:** 14 pages, 5 figures

> **TL;DR:** 研究发现 GitHub Copilot 能显著提高学生在棕地编程任务中的效率和进度，但学生对其建议的理解存在顾虑。

**AI_Comments:** 这项研究创新性地关注了生成式AI编码助手对学生在“棕地”环境下的影响，填补了该领域的研究空白。其混合方法提供了量化效率提升和质化行为转变的全面视角。研究结果对计算机教育具有重要指导意义，提示教育者在推广AI工具的同时，需注重培养学生对AI建议的批判性思维和深层理解，以避免过度依赖和知识空缺。

<details>
  <summary>Details</summary>

**Motivation:** 毕业生进入软件行业常处理遗留代码，而生成式AI编码助手（如GitHub Copilot）正在改变开发实践，但其对学生程序员在棕地开发任务中的影响尚不明确。

**Method:** 进行了一项对照实验，10名本科计算机科学学生在遗留Web应用程序中，分别使用和不使用Copilot完成高度相似的棕地开发任务。采用混合方法，结合性能分析、行为分析和离职访谈。

**Result:** 使用Copilot时，学生完成任务速度快35%，解决方案进展多50%。学生手动编写代码时间减少11%，网络搜索时间减少12%。学生在访谈中表示担忧不理解Copilot建议的工作原理或原因。

**Conclusion:** 研究表明计算机教育工作者需要开发新的教学方法，以利用生成式AI助手的优势，同时培养学生对生成式AI建议如何以及为何解决棕地编程任务的反思。

> **ai_Abstract:** 本文研究了GitHub Copilot对计算机专业学生在棕地编程任务中表现、行为和理解的影响。通过一项有10名本科生参与的对照实验，结果显示使用Copilot显著提高了任务完成速度和解决方案进展，并改变了学生的编程方式，减少了手动编码和网络搜索时间。然而，学生对Copilot建议的理解存在顾虑。研究强调教育者需要开发新的教学策略，以有效利用GenAI工具并促进学生对其工作原理的深入理解。

> **摘要翻译:** 当计算机学位课程的毕业生进入软件行业时，他们很可能会加入处理由他人开发的遗留代码库的团队。在这些所谓的“棕地”软件开发环境中，像GitHub Copilot这样的生成式人工智能（GenAI）编码助手正在迅速改变软件开发实践，但GenAI对执行棕地开发任务的学生程序员的影响仍未得到充分探索。本文调查了GitHub Copilot如何影响本科学生在向不熟悉的现有代码库添加新代码的棕地编程任务中表现、行为和理解。我们进行了一项对照实验，其中10名本科计算机科学学生在遗留Web应用程序中，分别使用和不使用Copilot完成了高度相似的棕地开发任务。采用结合性能分析、行为分析和离职访谈的混合方法，我们发现学生在使用Copilot时完成任务速度快35%（p < 0.05），解决方案进展多50%（p < 0.05）。此外，我们的分析显示，在使用Copilot时，学生手动编写代码的时间减少了11%（p < 0.05），进行网络搜索的时间减少了12%（p < 0.05），这表明他们的编程方式发生了根本性转变。在离职访谈中，学生表达了对不理解Copilot建议如何或为何起作用的担忧。这项研究表明，计算机教育工作者需要开发新的教学方法，以利用GenAI助手的优势，同时培养对GenAI建议如何以及为何解决棕地编程任务的反思。完整的学习结果和分析可在https://ghcopilot-icer.github.io/上查阅。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [86] [Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput](https://arxiv.org/abs/2506.10056)
> *奖励模型通过权衡准确性与吞吐量实现可扩展的代码验证*

*Gabriel Orlanski, Nicholas Roberts, Aws Albarghouthi, Frederic Sala* | **Main category: cs.SE**

**Keywords:** 奖励模型, 代码验证, 速度-准确性权衡, 生成-修剪-然后排序, 大语言模型

**Comment:** 29 pages, 6 figures, code released here:
  https://github.com/SprocketLab/orm-code-verifier

> **TL;DR:** 研究发现，即使存在全面的验证器，奖励模型（ORM）也能通过牺牲准确性来提高验证速度，尤其是在“生成-修剪-然后排序”的方法中，系统速度可提高11.65倍，准确性仅下降8.33%。

**AI_Comments:** 本文的创新之处在于系统地挑战了现有范式，并量化了奖励模型在代码验证中带来的速度提升，即使在全面验证器可用的情况下。其重要性在于为设计更高效、可扩展的程序排序系统提供了新的视角和实用方法，尤其是在资源受限或需要快速反馈的场景下。研究提出的“生成-修剪-然后排序”方法提供了一个具体的优化策略。

<details>
  <summary>Details</summary>

**Motivation:** 当前解决编码任务的标准范式是“生成-然后排序”程序，其中排序步骤使用验证器。普遍的共识是，应优先使用全面的验证器（例如，完整的测试套件），而很少考虑其中的权衡。本文旨在挑战这一假设，系统地探索速度和准确性之间的权衡。

**Method:** 本文通过系统地探索速度和准确性之间的权衡来挑战现有假设。研究发现，即使存在全面的验证器，成果奖励模型（ORM）在通过牺牲准确性来提高速度方面发挥了关键作用。尤其是在“生成-修剪-然后排序”的方法中，即一个更快但准确性较低的验证器在排序之前移除不正确的解决方案。

**Result:** 研究发现，成果奖励模型（ORM）在通过牺牲准确性来提高速度方面发挥了关键作用，即使在存在全面的验证器时也是如此。在“生成-修剪-然后排序”的方法中，系统速度提高了11.65倍，而准确性仅比完整测试套件低8.33%。分析表明，这种方法通过过滤掉不正确但排名靠前的解决方案来发挥作用。

**Conclusion:** 奖励模型能够通过权衡准确性与吞吐量，实现可扩展的代码验证。这些发现有助于设计可扩展且准确的程序排序系统。

> **ai_Abstract:** 本文挑战了在LLM编码任务中总是优先使用全面验证器的传统观念，系统地探索了验证速度与准确性之间的权衡。研究发现，成果奖励模型（ORM）即使在全面验证器可用时，也能通过牺牲准确性显著提高验证速度。特别是在“生成-修剪-然后排序”的方法中，ORM作为快速预过滤器，使得系统速度提升11.65倍，而准确性仅下降8.33%。这表明ORM是构建可扩展和准确程序排序系统的关键。

> **摘要翻译:** 通过大型语言模型（LLMs）解决编码任务的标准范式是“生成-然后排序”程序，其中后者在排序过程中使用验证器。人们日益形成共识，即只要可能，就应优先使用全面的验证器（例如，完整的测试套件），而很少考虑其中涉及的权衡。我们的目标是通过系统地探索速度和准确性之间的权衡来挑战这一假设。我们发现，即使存在全面的验证器，成果奖励模型（ORM）在通过牺牲准确性来提高速度方面发挥了关键作用。当它们用于“生成-修剪-然后排序”的方法时，其价值变得尤为明显，其中一个更快但准确性较低的验证器在排序之前移除不正确的解决方案——这使得系统速度提高了11.65倍，而准确性仅比完整测试套件低8.33%。我们分析了“生成-修剪-然后排序”的方法，并表明它通过过滤掉不正确但排名靠前的解决方案来发挥作用。这些发现有助于设计可扩展且准确的程序排序系统。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [112] [Prompt Variability Effects On LLM Code Generation](https://arxiv.org/abs/2506.10204)
> *提示词变异对大型语言模型代码生成的影响*

*Andrei Paleyes, Radzim Sendyka, Diana Robinson, Christian Cabrera, Neil D. Lawrence* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 代码生成, 提示词变异, 评估方法, 用户背景

**Comment:** 

> **TL;DR:** 本文提出了一种合成评估流程和基于角色的评估方法，用于量化大型语言模型在代码生成中对输入提示词变化的敏感性。

**AI_Comments:** 本文的创新之处在于提出了两种独立于具体编程任务和大型语言模型的评估方法，用于量化LLM代码生成对提示词变化的敏感性。这对于理解和提高LLM在实际应用中的代码生成质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型生成的代码质量受提示词质量影响，且对用户背景敏感。因此，量化大型语言模型对输入变化的敏感性至关重要。

**Method:** 提出了一种用于大型语言模型代码生成的合成评估流程，以及一种系统的、基于角色的评估方法，以揭示大型语言模型响应在用户背景方面的定性差异。这两种方法都独立于特定的编程任务和大型语言模型。

**Result:** 提供了实验证据，说明了所提出方法的实用性。

**Conclusion:** 本文提出的评估方法能够有效地量化大型语言模型在代码生成中对提示词变化的敏感性，并具有广泛的适用性。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）在代码生成中对提示词变化的敏感性。鉴于生成代码的质量取决于提示词且受用户背景影响，作者提出了一种合成评估流程和一种系统性的、基于角色的评估方法。这两种方法独立于具体的编程任务和LLM，具有广泛适用性。实验证据表明了这些方法的实用性，并共享了代码。

> **摘要翻译:** 大型语言模型（LLM）的代码生成是其最活跃的应用领域之一。虽然LLM降低了编写代码的门槛并加速了开发过程，但生成程序的整体质量取决于给定提示词的质量。具体而言，生成代码的功能和质量可能对用户的背景和软件开发熟悉程度敏感。因此，量化LLM对输入变化的敏感性至关重要。为此，我们提出了一种用于LLM代码生成的合成评估流程，以及一种系统的、基于角色的评估方法，以揭示LLM响应在潜在用户背景方面的定性差异。这两种提出的方法完全独立于特定的编程任务和LLM，因此具有广泛的适用性。我们提供了实验证据，说明了我们方法的实用性，并分享了我们的代码以造福社区。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [134] [AI-Based Software Vulnerability Detection: A Systematic Literature Review](https://arxiv.org/abs/2506.10280)
> *基于AI的软件漏洞检测：系统文献综述*

*Samiha Shimmi, Hamed Okhravi, Mona Rahimi* | **Main category: cs.SE**

**Keywords:** 软件漏洞检测, 人工智能, 系统综述, 图神经网络, 网络安全

**Comment:** 

> **TL;DR:** 本研究对2018年至2023年间基于AI的软件漏洞检测（SVD）研究进行了系统综述，提供了技术分类，并指出了数据质量、可复现性和可解释性等局限性，同时提出了联邦学习和量子神经网络等新兴机会。

**AI_Comments:** 这篇系统综述及时地总结了AI在软件漏洞检测领域的最新进展和趋势，为研究人员提供了宝贵的参考。其创新之处在于对现有技术的全面分类和对未来研究方向的清晰指引。论文指出的数据质量、可复现性和可解释性等局限性是当前AI应用面临的普遍挑战，对于推动该领域的实际落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 源代码中的软件漏洞会带来严重网络安全风险，促使检测方法从传统方式（如静态分析、基于规则的匹配）转向AI驱动的方法。本研究旨在系统回顾AI在SVD领域的应用。

**Method:** 本研究对2018年至2023年间的软件漏洞检测（SVD）研究进行了系统文献综述，提供了技术、特征表示和嵌入方法的全面分类法。

**Result:** 分析显示，91%的研究使用了基于AI的方法，其中图基模型最为普遍。研究识别出主要局限性，包括数据集质量、可复现性和可解释性。同时，指出了联邦学习和量子神经网络等未充分探索技术中的新兴机会。

**Conclusion:** AI在软件漏洞检测中占据主导地位，但仍面临数据集、可复现性和可解释性等挑战。未来的研究应探索联邦学习和量子神经网络等新兴技术，以克服现有局限并推动领域发展。

> **ai_Abstract:** 本研究对2018年至2023年间基于AI的软件漏洞检测研究进行了系统文献综述。结果显示，AI方法已成为主流，特别是图基模型。研究指出了当前方法的局限性，如数据集质量、可复现性和可解释性问题，并为未来研究提出了联邦学习和量子神经网络等新兴方向。

> **摘要翻译:** 源代码中的软件漏洞构成严重的网络安全风险，促使检测方法从传统方法（例如静态分析、基于规则的匹配）转向AI驱动的方法。本研究对2018年至2023年间的软件漏洞检测（SVD）研究进行了系统综述，提供了技术、特征表示和嵌入方法的全面分类法。我们的分析显示，91%的研究使用了基于AI的方法，其中图基模型最为普遍。我们识别出主要局限性，包括数据集质量、可复现性和可解释性，并强调了联邦学习和量子神经网络等未充分探索技术中的新兴机会，为未来的研究提供了路线图。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [154] [Minimizing False Positives in Static Bug Detection via LLM-Enhanced Path Feasibility Analysis](https://arxiv.org/abs/2506.10322)
> *通过LLM增强的路径可行性分析最小化静态错误检测中的误报*

*Xueying Du, Kai Yu, Chong Wang, Yi Zou, Wentai Deng, Zuoyu Ou, Xin Peng, Lingming Zhang, Yiling Lou* | **Main category: cs.SE**

**Keywords:** 静态错误检测, 误报最小化, 路径可行性分析, 大型语言模型, LLM代理

**Comment:** 

> **TL;DR:** 提出LLM4PFA框架，利用LLM代理增强路径可行性分析，显著降低静态错误检测中的误报率。

**AI_Comments:** 这篇论文通过引入LLM代理进行路径可行性分析，为静态错误检测中的高误报问题提供了一个新颖且有效的解决方案。其创新点在于结合LLM的推理能力和上下文感知分析，以更准确地验证复杂路径的可行性。该方法显著降低了误报率，对提高静态分析工具的实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有静态错误分析器在大型代码库中存在高误报率，主要原因是路径可行性验证能力有限，尤其是在处理多条件分支和复杂数据依赖时。现有基于LLM的方法也因约束级联分析不足和可伸缩性挑战而效果有限。

**Method:** 提出LLM4PFA，一个迭代的路径可行性分析框架。它通过利用基于LLM代理的目标约束推理和由代理规划驱动的关键上下文感知分析，有效增强了复杂的跨过程路径可行性分析。

**Result:** LLM4PFA精确过滤掉72%至96%的静态错误检测误报，表现优于所有基线41.1%至105.7%；同时，在45个真实错误中仅漏报3个。

**Conclusion:** LLM4PFA通过其创新的LLM增强路径可行性分析方法，有效解决了静态错误检测中的高误报问题，并在保持高召回率的同时显著提高了精度。

> **ai_Abstract:** 本文提出了LLM4PFA，一个利用大型语言模型（LLM）代理进行目标约束推理和上下文感知分析的迭代路径可行性分析框架。该框架旨在解决现有静态错误分析器在高误报率上的不足，特别是在处理复杂路径和数据依赖时。实验结果表明，LLM4PFA能有效过滤72%至96%的误报，并显著优于现有基线，同时保持了较低的漏报率。

> **摘要翻译:** 静态错误分析器在确保软件质量方面发挥着关键作用。然而，现有的大型代码库错误检测分析器通常存在高误报率。这主要是由于分析器在多条件分支和复杂数据依赖的路径可行性验证方面能力有限。尽管当前基于LLM的方法试图解决此问题，但由于约束级联分析不足和大型项目中的可伸缩性挑战，其有效性仍然有限。为了解决这一挑战，我们提出了一个迭代路径可行性分析框架LLM4PFA。通过利用基于LLM代理的目标约束推理和由代理规划驱动的关键上下文感知分析，LLM4PFA有效增强了复杂的跨过程路径可行性分析，从而最小化了静态错误检测中的误报。评估结果表明，LLM4PFA精确过滤掉了静态错误检测报告的72%至96%的误报，显著优于所有基线41.1%至105.7%；同时，LLM4PFA在45个真实错误中仅漏报3个。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [157] [Scalable Software Testing in Fast Virtual Platforms: Leveraging SystemC, QEMU and Containerization](https://arxiv.org/abs/2506.10624)
> *快速虚拟平台中的可扩展软件测试：利用SystemC、QEMU和容器化技术*

*Lukas Jünger, Jan Henrik Weinstock, Tim Kraus* | **Main category: cs.SE**

**Keywords:** 虚拟平台, 容器化, SystemC, QEMU, 软件测试

**Comment:** Published in DVCon China 2025

> **TL;DR:** 本研究提出了一种利用容器化技术封装虚拟平台的方法，以实现快速、并行化的软件测试，并利用SystemC和QEMU等开源技术，解决硬件滞后和测试复杂性问题。

**AI_Comments:** 本论文的创新之处在于将容器化技术与虚拟平台结合，解决了传统虚拟平台在环境依赖、可扩展性和许可成本方面的痛点。通过云部署和并行化测试，显著提升了软件测试的效率和规模。该方法对于加速复杂软硬件系统的协同开发，尤其是在硬件可用性受限的早期阶段，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 硬件/软件系统日益增长的复杂性，尤其是在汽车等安全关键领域，对软件测试提出了巨大挑战。硬件的可用性常常滞后，阻碍了早期软件开发。现有的虚拟平台虽然有所帮助，但仍需解决环境依赖和许可问题，以实现可扩展和并行的测试执行。

**Method:** 本研究提出了一种利用容器化技术（如Docker）封装虚拟平台（VPs）的方法，以减少环境依赖性并支持云部署，从而实现快速、并行化的测试执行。同时，该方法利用了SystemC TLM-2.0标准以及QEMU和VCML等开源虚拟平台技术，以避免对商业许可的需求。

**Result:** 通过一个人工智能（AI）加速器虚拟平台的案例研究，展示了所提出方法的有效性。该研究提供了一个强大的解决方案，以应对硬件/软件系统复杂性带来的挑战。

**Conclusion:** 本研究提供了一个强大的解决方案，能够应对硬件/软件系统复杂性带来的挑战，并对加速硬件/软件协同开发具有实际意义。

> **ai_Abstract:** 本研究旨在解决复杂软硬件系统，特别是安全关键领域中软件测试面临的挑战，即硬件滞后和测试可扩展性问题。作者提出了一种创新的方法，通过容器化技术封装基于SystemC TLM-2.0标准的虚拟平台，并利用QEMU等开源技术。这种方法旨在减少环境依赖，支持云部署，从而实现快速、并行化的测试执行，并避免昂贵的许可费用。通过一个AI加速器虚拟平台的案例研究，验证了该方法的有效性，为加速软硬件协同开发提供了实用且强大的解决方案。

> **摘要翻译:** 硬件/软件系统日益增长的复杂性带来了持续的挑战，尤其是在汽车等安全关键领域，广泛的测试是必不可少的。然而，硬件的可用性常常滞后，阻碍了早期软件开发。为解决这一问题，基于SystemC TLM-2.0标准的虚拟平台（VPs）已成为一个关键解决方案，能够实现未经修改的目标软件的预硅执行和测试。在本研究中，我们提出了一种利用容器化技术封装虚拟平台的方法，以减少环境依赖性并实现云部署，从而实现快速、并行化的测试执行，同时利用QEMU和VCML等开源虚拟平台技术，以避免对许可的需求。为了证明我们方法的有效性，我们提出了一个人工智能（AI）加速器虚拟平台案例研究。通过我们的研究，我们提供了一个强大的解决方案，以应对硬件/软件系统复杂性带来的挑战，对加速硬件/软件协同开发具有实际意义。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [174] [Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements](https://arxiv.org/abs/2506.10330)
> *结合静态代码分析增强大型语言模型，实现自动化代码质量改进*

*Seyed Moein Abtahi, Akramul Azim* | **Main category: cs.SE**

**Keywords:** 大语言模型, 静态代码分析, 代码质量, 自动化修订, 检索增强生成

**Comment:** Accepted at FORGE 2025

> **TL;DR:** 本研究结合大语言模型和静态代码分析，通过RAG和自定义应用，自动化检测并修正代码问题，显著提升代码质量。

**AI_Comments:** 这项研究通过将静态代码分析与大型语言模型（LLM）相结合，并引入检索增强生成（RAG）和自定义的代码比较应用来解决LLM的幻觉问题，为自动化代码质量改进提供了一个创新且实用的框架。其创新之处在于系统地整合了现有技术，尤其是在实际应用中解决了LLM可能产生的错误输出，这对于提高自动化代码修订的可靠性至关重要。这项工作的重要性在于它能够显著提升软件开发效率和代码质量，减少人工干预，具有很高的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决代码问题检测和修订自动化的问题，通过集成LLMs到软件开发工作流中，以提升代码质量、简化开发流程并减少时间和资源消耗。

**Method:** 将LLMs（如GPT-3.5 Turbo和GPT-4o）集成到软件开发工作流中。使用静态代码分析框架检测代码中的bug、漏洞和代码异味。提取并组织详细问题信息，用于LLM自动化代码修订。应用迭代提示工程，确保提示结构化以生成准确和有组织输出。实施检索增强生成（RAG）以提高修订的相关性和精确性。通过自定义“代码比较应用”解决LLM幻觉问题，识别并纠正错误修改。后续使用静态代码分析框架扫描以验证效果。

**Result:** 后续使用静态代码分析框架扫描显示代码问题显著减少。

**Conclusion:** 结合LLMs、静态分析和RAG能有效提高代码质量，简化软件开发流程，并减少时间和资源消耗。

> **ai_Abstract:** 本研究探索了通过整合大型语言模型（LLM）和静态代码分析框架实现代码问题检测与修订的自动化。研究设计了一个流程，利用静态分析识别代码问题，提取详细信息，并通过迭代提示工程和检索增强生成（RAG）指导LLM进行代码修订。为解决LLM幻觉问题，开发了一个“代码比较应用”来验证和修正LLM生成的代码。实验结果显示，该方法显著减少了代码问题，证明了结合LLM、静态分析和RAG在提升代码质量、优化开发流程和降低成本方面的有效性。

> **摘要翻译:** 本研究通过将大型语言模型（LLM），如OpenAI的GPT-3.5 Turbo和GPT-4o，整合到软件开发工作流程中，探讨了代码问题检测和修订自动化。一个静态代码分析框架用于检测大型软件项目中的错误、漏洞和代码异味等问题。提取并组织每个问题的详细信息，以便于使用LLM进行自动化代码修订。应用迭代式提示工程，确保提示结构化，以生成与项目要求对齐的准确和有组织输出。实施检索增强生成（RAG），以提高修订的相关性和精确性，使LLM能够访问和整合实时外部知识。LLM幻觉——即模型生成看似合理但错误输出的问题——通过一个定制的“代码比较应用”来解决，该应用在将更改应用到代码库之前识别并纠正错误更改。随后使用静态代码分析框架进行扫描显示，代码问题显著减少，证明了结合LLM、静态分析和RAG在提高代码质量、简化软件开发流程以及减少时间和资源消耗方面的有效性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [188] [AutoGEEval++: A Multi-Level and Multi-Geospatial-Modality Automated Evaluation Framework for Large Language Models in Geospatial Code Generation on Google Earth Engine](https://arxiv.org/abs/2506.10365)
> *AutoGEEval++：一个面向Google Earth Engine地理空间代码生成中大型语言模型的多级别多地理空间模态自动化评估框架*

*Shuyang Hou, Zhangxiao Shen, Huayi Wu, Haoyue Jiao, Ziqi Liu, Lutong Xie, Chang Liu, Jianyuan Liang, Yaxian Qing, Xiaopu Zhang, Dehua Peng, Zhipeng Gui, Xuefeng Guan* | **Main category: cs.SE**

**Keywords:** 地理空间代码生成, 大型语言模型, Google Earth Engine, 自动化评估, AutoGEEval++

**Comment:** 

> **TL;DR:** AutoGEEval++是首个针对Google Earth Engine（GEE）地理空间代码生成LLMs的自动化评估框架，包含大规模基准数据集和多维度指标，用于评估并比较不同LLMs的性能。

**AI_Comments:** AutoGEEval++的创新之处在于它是首个针对Google Earth Engine上LLM地理空间代码生成的自动化评估框架，填补了该领域标准化评估工具的空白。其多级别、多模态的基准数据集和多维度评估指标设计，使其能够全面、深入地分析LLMs的性能和错误模式。这项工作为地理空间AI领域提供了一个基础性的评估工具和统一的比较平台，对于推动LLM在专业领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地理空间代码生成是AI与地球科学分析结合的关键前沿，但目前缺乏标准化、自动化的评估工具。

**Method:** 本研究提出了AutoGEEval++，一个基于AutoGEEval的增强框架，也是第一个用于评估在Google Earth Engine (GEE) 上生成地理空间代码的大型语言模型 (LLM) 的自动化评估系统。它支持多样的数据模态和不同任务复杂性，基于GEE Python API构建。AutoGEEval++包含一个基准数据集——AutoGEEval++-Bench，其中包含6,365个测试用例，涵盖26种数据类型和三个任务类别：单元测试、组合测试和主题测试。该框架还包括一个提交程序和一个判别模块，以实现从代码生成到基于执行的验证的端到端自动化评估流程。它采用多维度指标，包括准确性、资源使用、运行时效率和错误类型，平衡幻觉控制和效率，并支持边界测试和错误模式分析。

**Result:** 使用AutoGEEval++评估了24个最先进的LLMs（截至2025年6月），包括通用型、推理增强型、代码中心型和地球科学专用型模型。结果揭示了在任务类型、模型设计和部署设置之间存在明显的性能、稳定性和错误差异，证实了AutoGEEval++在垂直领域代码生成中的实用价值和可扩展性。

**Conclusion:** 这项工作建立了第一个针对基于GEE的LLM代码生成的标准化评估协议和基础基准，为性能比较提供了一个统一的基础，并为系统性、领域特定代码评估提供了方法论框架。

> **ai_Abstract:** 本研究介绍了AutoGEEval++，一个增强的自动化评估框架，旨在解决Google Earth Engine (GEE) 上大型语言模型 (LLM) 地理空间代码生成缺乏标准化评估工具的问题。该框架基于GEE Python API构建，包含一个大规模基准数据集AutoGEEval++-Bench，涵盖多级别和多模态测试用例。它提供了一个端到端的评估流程，并采用多维度指标来衡量LLMs的准确性、效率和错误类型。通过评估24个SOTA LLMs，AutoGEEval++证实了其在垂直领域代码生成评估中的实用性和可扩展性，并建立了首个GEE LLM代码生成的标准化评估协议和基准。

> **摘要翻译:** 地理空间代码生成正成为人工智能与地球科学分析相结合的关键前沿，但目前仍缺乏针对此任务的标准化自动化评估工具。本研究提出了AutoGEEval++，一个在AutoGEEval基础上增强的框架，也是第一个用于评估在Google Earth Engine (GEE) 上生成地理空间代码的大型语言模型 (LLM) 的自动化评估系统。它支持多样的数据模态和不同任务复杂性。AutoGEEval++基于GEE Python API构建，其特点是包含一个基准数据集——AutoGEEval++-Bench，其中包含6,365个测试用例，涵盖26种数据类型和三个任务类别：单元测试、组合测试和主题测试。它包括一个提交程序和一个判别模块，以实现从代码生成到基于执行的验证的端到端自动化评估流程。该框架采用多维度指标——准确性、资源使用、运行时效率和错误类型——平衡幻觉控制和效率，并支持边界测试和错误模式分析。通过使用AutoGEEval++，我们评估了24个最先进的LLM（截至2025年6月），包括通用型、推理增强型、代码中心型和地球科学专用型模型。结果揭示了在任务类型、模型设计和部署设置之间存在明显的性能、稳定性和错误差异，证实了AutoGEEval++在垂直领域代码生成中的实用价值和可扩展性。这项工作建立了第一个针对基于GEE的LLM代码生成的标准化评估协议和基础基准，为性能比较提供了一个统一的基础，并为系统性、领域特定代码评估提供了方法论框架。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [202] [MLLM-Based UI2Code Automation Guided by UI Layout Information](https://arxiv.org/abs/2506.10376)
> *基于MLLM并由UI布局信息引导的UI2Code自动化*

*Fan Wu, Cuiyun Gao, Shuqing Li, Xin-Cheng Wen, Qing Liao* | **Main category: cs.SE**

**Keywords:** UI2Code, MLLM, 自动化, UI布局, 网页开发

**Comment:** Accepted by the 34th International Symposium on Software Testing and
  Analysis (ISSTA 2025)

> **TL;DR:** LayoutCoder是一个基于MLLM的框架，通过理解UI布局信息，将真实网页图像转换为准确的代码，解决了现有方法对大量标注数据依赖和泛化能力差的问题，并在新基准数据集上表现优异。

**AI_Comments:** LayoutCoder的创新之处在于其通过显式地捕获和利用UI布局信息来指导MLLM进行UI2Code自动化，解决了MLLM在理解复杂UI布局方面的固有挑战。通过引入元素关系构建、UI布局解析和布局引导代码融合这三个模块，该框架能够生成更准确且布局保留的代码。此外，构建新的真实世界基准数据集Snap2Code也增加了其研究价值，有助于推动该领域的发展。该方法在泛化能力和代码准确性方面取得了显著提升，对于提高网站开发效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将用户界面转换为代码（UI2Code）是网站开发中耗时耗力的关键步骤。自动化UI2Code对于提高开发效率至关重要。现有基于深度学习的方法依赖大量标注数据且难以泛化到真实世界的未见网页设计。多模态大语言模型（MLLMs）虽有潜力，但难以理解UI中复杂的布局并生成保留布局的准确代码。

**Method:** 本文提出了LayoutCoder，一个新颖的基于MLLM的框架，用于从真实网页图像生成UI代码。它包括三个关键模块：1) 元素关系构建，旨在通过识别和分组具有相似结构的组件来捕获UI布局；2) UI布局解析，旨在生成UI布局树以指导后续的代码生成过程；3) 布局引导代码融合，旨在生成保留布局的准确代码。为了评估，构建了一个名为Snap2Code的新基准数据集，包含350个真实世界网站，并结合流行的Design2Code数据集进行评估。

**Result:** 广泛的评估表明LayoutCoder的性能优于现有最先进的方法。与表现最佳的基线相比，LayoutCoder在所有数据集上的BLEU分数平均提高了10.14%，CLIP分数平均提高了3.95%。

**Conclusion:** LayoutCoder通过引入UI布局信息引导的MLLM框架，有效地解决了UI2Code自动化中现有方法的局限性，显著提高了代码生成的准确性和泛化能力，尤其是在复杂布局的理解和保留方面。

> **ai_Abstract:** 本文提出了LayoutCoder，一个基于多模态大语言模型（MLLMs）的新框架，旨在自动化将用户界面图像转换为代码（UI2Code）的过程。针对现有方法对标注数据依赖和对复杂UI布局理解不足的问题，LayoutCoder引入了三个核心模块：元素关系构建、UI布局解析和布局引导代码融合，以有效捕获和利用UI布局信息生成准确且保留布局的代码。研究团队构建了新的基准数据集Snap2Code进行评估，实验结果显示LayoutCoder在BLEU和CLIP分数上均显著优于现有最先进的方法，证明了其在真实世界网页设计UI2Code任务中的优越性能。

> **摘要翻译:** 将用户界面转换为代码（UI2Code）是网站开发中至关重要的一步，耗时且费力。UI2Code的自动化对于简化这项任务至关重要，有利于提高开发效率。目前存在基于深度学习的方法来完成这项任务；然而，它们严重依赖大量标注的训练数据，并且难以泛化到真实世界的、未见的网页设计。多模态大语言模型（MLLMs）的出现为缓解这个问题提供了潜力，但它们难以理解UI中复杂的布局并生成保留布局的准确代码。为了解决这些问题，我们提出了LayoutCoder，一个新颖的基于MLLM的框架，用于从真实网页图像生成UI代码，它包括三个关键模块：(1) 元素关系构建，旨在通过识别和分组具有相似结构的组件来捕获UI布局；(2) UI布局解析，旨在生成UI布局树以指导后续的代码生成过程；(3) 布局引导代码融合，旨在生成保留布局的准确代码。为了评估，我们构建了一个新的基准数据集Snap2Code，其中包含350个真实世界网站，并将其分为已知和未知部分以缓解数据泄漏问题，此外还使用了流行的Design2Code数据集。广泛的评估表明LayoutCoder的性能优于现有最先进的方法。与表现最佳的基线相比，LayoutCoder在所有数据集上的BLEU分数平均提高了10.14%，CLIP分数平均提高了3.95%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [219] [Bug Classification in Quantum Software: A Rule-Based Framework and Its Evaluation](https://arxiv.org/abs/2506.10397)
> *量子软件中的缺陷分类：一种基于规则的框架及其评估*

*Mir Mohammad Yousuf, Shabir Ahmad Sofi* | **Main category: cs.SE**

**Keywords:** 量子软件, 缺陷分类, 规则框架, Qiskit, 软件质量

**Comment:** 25 pages, 5 figures

> **TL;DR:** 本文提出了一个基于规则的自动化框架，用于对量子软件中的缺陷进行分类，并对其进行了评估。

**AI_Comments:** 该论文的创新之处在于其首次提出了一个专门针对量子软件缺陷的自动化分类框架，并结合了量子计算的特性。其重要性体现在为量子软件质量保证提供了基础工具，并通过大规模分析揭示了量子软件中缺陷的分布和特性，这对于未来量子软件开发和测试具有指导意义。然而，论文也指出了在严重程度分类方面仍有提升空间，这可能需要更复杂的语义分析或上下文理解。

<details>
  <summary>Details</summary>

**Motivation:** 准确分类软件缺陷对于提高软件质量至关重要。

**Method:** 本文提出了一个基于规则的自动化框架，用于按缺陷类型、类别、严重程度和受影响的质量属性对量子软件仓库中的问题进行分类，并额外关注量子特有的缺陷类型。该框架应用了针对量子计算定制的关键词和启发式技术。为了评估其可靠性，研究人员手动分类了来自36个Qiskit仓库的12,910个问题数据集中的4,984个分层样本。自动分类结果与真实情况通过准确率、精确率、召回率和F1分数进行比较，并使用配对t检验和Cohen's Kappa进行统计验证。

**Result:** 该框架的准确率高达85.21%，F1分数范围从0.7075（严重程度）到0.8393（质量属性）。统计验证显示，缺陷类型（k = 0.696）、类别（k = 0.826）、质量属性（k = 0.818）和量子特有缺陷类型（k = 0.712）的一致性达到实质性到几乎完美。严重程度分类的一致性较低（k = 0.162）。大规模分析显示，经典缺陷占主导地位（67.2%），量子特有缺陷占27.3%。常见的缺陷类别包括兼容性、功能性和量子特有缺陷，而可用性、可维护性和互操作性是受影响最严重的质量属性。大多数问题（93.7%）为低严重性；只有4.3%为关键性。对1,550个量子特有缺陷的详细审查显示，超过一半涉及量子电路级别问题，其次是门错误和硬件相关问题。

**Conclusion:** 该基于规则的框架能够有效地对量子软件中的缺陷进行分类，尤其在缺陷类型、类别和质量属性方面表现出高一致性。尽管在严重程度分类上仍有改进空间，但该研究为理解量子软件中缺陷的分布和特性提供了宝贵的见解，揭示了经典缺陷仍占主导地位，且量子特有缺陷主要集中在电路级别问题。

> **ai_Abstract:** 本文提出了一种基于规则的自动化框架，用于对量子软件中的缺陷进行分类，包括缺陷类型、类别、严重程度和受影响的质量属性，并特别关注量子特有缺陷。该框架利用关键词和启发式技术，并在Qiskit仓库的真实数据集上进行了评估。结果显示，该框架在缺陷类型、类别和质量属性分类方面表现出较高的准确性和一致性，尽管在严重程度分类上仍有改进空间。研究还揭示了量子软件中经典缺陷的普遍性以及量子特有缺陷的主要类型和影响。

> **摘要翻译:** 准确分类软件缺陷对于提高软件质量至关重要。本文提出了一个基于规则的自动化框架，用于按缺陷类型、类别、严重程度和受影响的质量属性对量子软件仓库中的问题进行分类，并额外关注量子特有的缺陷类型。该框架应用了针对量子计算定制的关键词和启发式技术。为了评估其可靠性，我们手动分类了来自36个Qiskit仓库的12,910个问题数据集中的4,984个分层样本。自动分类结果与真实情况通过准确率、精确率、召回率和F1分数进行比较。该框架的准确率高达85.21%，F1分数范围从0.7075（严重程度）到0.8393（质量属性）。通过配对t检验和Cohen's Kappa进行的统计验证显示，缺陷类型（k = 0.696）、类别（k = 0.826）、质量属性（k = 0.818）和量子特有缺陷类型（k = 0.712）的一致性达到实质性到几乎完美。严重程度分类的一致性较低（k = 0.162），表明仍有改进空间。大规模分析显示，经典缺陷占主导地位（67.2%），量子特有缺陷占27.3%。常见的缺陷类别包括兼容性、功能性和量子特有缺陷，而可用性、可维护性和互操作性是受影响最严重的质量属性。大多数问题（93.7%）为低严重性；只有4.3%为关键性。对1,550个量子特有缺陷的详细审查显示，超过一半涉及量子电路级别问题，其次是门错误和硬件相关问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [234] [Towards Understanding Bugs in Distributed Training and Inference Frameworks for Large Language Models](https://arxiv.org/abs/2506.10426)
> *走向理解大型语言模型分布式训练与推理框架中的错误*

*Xiao Yu, Haoxuan Chen, Feifei Niu, Xing Hu, Jacky Wai Keung, Xin Xia* | **Main category: cs.SE**

**Keywords:** 分布式训练, 大型语言模型, 软件错误, 实证分析, 调试

**Comment:** 

> **TL;DR:** 对大型语言模型分布式训练与推理框架中的308个已修复错误进行了首次大规模实证分析，揭示了错误特性、修复挑战及自动化修复潜力。

**AI_Comments:** 本文通过对实际分布式训练/推理框架中的大量已修复错误进行首次大规模实证分析，为理解LLM框架中的错误特性提供了宝贵的第一手资料。其创新点在于揭示了分布式特有的错误类型和修复挑战，并量化了简单修复的比例，为未来的自动化调试和修复工具的开发指明了方向。特别是指出48%的错误修复所需代码量小且策略简单，这对于自动化修复工具的研发具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的快速发展，分布式训练和推理框架变得至关重要。然而，这些框架日益增长的复杂性带来了非小可的软件错误，可能降低训练性能、导致意外故障并造成资源浪费。理解框架错误的特性对于质量保证至关重要，有助于设计更有效的调试和修复方法。

**Method:** 本文对DeepSpeed、Megatron-LM和Colossal-AI这三个流行的分布式训练/推理框架中的308个已修复错误进行了首次大规模实证分析。研究内容包括错误症状、根本原因、错误识别和修复工作量，以及常见的低成本修复策略。

**Result:** 分布式框架引入了独特的错误根本原因，例如分配策略错误和分布式通信错误。诊断和修复复杂错误仍然具有挑战性，原因包括症状与根本原因脱节、错误复现成本高以及底层或跨组件交互。有趣的是，48%的错误修复仅需要最少的代码更改（<=10行代码），并遵循简单的策略，如条件逻辑优化、参数处理增强或版本兼容性处理，这表明了自动化的潜力。

**Conclusion:** 基于这些见解，本文为提高分布式训练和推理框架及其依赖的LLM项目的可靠性提供了多项启示，同时指出了利用基于LLM的工具进行自动化调试和修复的机会。

> **ai_Abstract:** 本研究首次对DeepSpeed、Megatron-LM和Colossal-AI等大型语言模型分布式训练与推理框架中的308个已修复错误进行了大规模实证分析。研究揭示了分布式环境下独特的错误原因，指出了复杂错误诊断与修复的挑战，并发现近一半的错误修复只需少量代码改动，且可遵循简单策略，预示了自动化修复的潜力。研究结果为提升框架可靠性及利用LLM工具进行自动化调试和修复提供了重要启示。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展，DeepSpeed等分布式训练和推理框架已成为跨多个GPU或节点扩展模型训练和推理的必要工具。然而，这些框架日益增长的复杂性带来了非小可的软件错误，可能降低训练性能、导致意外故障并造成大量资源浪费。理解框架错误的特性对于质量保证至关重要，有助于设计更有效的调试和修复方法。因此，我们的论文对DeepSpeed、Megatron-LM和Colossal-AI这三个流行的分布式训练/推理框架中308个已修复错误进行了首次大规模实证分析。我们研究了错误症状、根本原因、错误识别和修复工作量，以及常见的低成本修复策略。此外，这些框架的分布式特性引入了独特的错误根本原因，例如分配策略错误和分布式通信错误。由于症状与根本原因脱节、错误复现成本高以及底层或跨组件交互等因素，诊断和修复复杂错误仍然具有挑战性。有趣的是，我们观察到48%的错误修复仅需要最少的代码更改（<=10行代码），并遵循简单的策略，如条件逻辑优化、参数处理增强或版本兼容性处理，这表明了自动化的潜力。基于这些见解，我们为提高分布式训练和推理框架及其依赖的LLM项目的可靠性提供了多项启示，同时指出了利用基于LLM的工具进行自动化调试和修复的机会。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [246] [EXPEREPAIR: Dual-Memory Enhanced LLM-based Repository-Level Program Repair](https://arxiv.org/abs/2506.10484)
> *EXPEREPAIR：双记忆增强型基于LLM的仓库级程序修复*

*Fangwen Mu, Junjie Wang, Lin Shi, Song Wang, Shoubin Li, Qing Wang* | **Main category: cs.SE**

**Keywords:** LLM, 程序修复, 双记忆系统, 仓库级修复, 动态提示

**Comment:** 

> **TL;DR:** ExpeRepair是一个基于LLM的程序修复方法，它利用双记忆系统（情景记忆和语义记忆）从历史修复经验中学习，并通过动态提示组合提高修复能力，在SWE-bench Lite上表现优异。

**AI_Comments:** ExpeRepair的创新点在于其引入了受人类认知启发的双记忆系统（情景记忆和语义记忆）来有效地积累和利用历史修复经验，以及采用动态提示组合策略。这解决了现有LLM在程序修复中泛化能力不足和未能充分利用历史经验的痛点。其方法论为LLM在复杂软件工程任务中的应用提供了新的思路，并显著提升了仓库级程序修复的性能，显示出其重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于大型语言模型（LLMs）的程序修复方法存在两个主要局限性：1) 它们通常孤立地处理问题，未能整合从先前已解决问题中获得的见解；2) 它们依赖静态和僵化的提示策略，限制了其在多样化和不断演变的问题场景中的泛化能力。

**Method:** 本文提出了ExpeRepair，一种新颖的基于LLM的方法，通过双通道知识积累持续学习历史修复经验。ExpeRepair将历史修复经验组织为情景记忆（存储具体修复演示）和语义记忆（编码抽象反思性见解）。在推理时，它通过从情景记忆中检索相关演示并从语义记忆中回忆高级修复见解来激活两个记忆系统。此外，ExpeRepair通过动态提示组合增强适应性，将两种记忆类型协同整合，以上下文感知、经验驱动的提示取代静态提示。

**Result:** 在SWE-bench Lite基准测试中，ExpeRepair使用Claude 3.7 Sonnet实现了49.3%的pass@1分数，超越了所有最先进的开源方法。

**Conclusion:** ExpeRepair通过模拟人类双记忆系统和采用动态提示组合，有效解决了现有LLM程序修复方法在利用历史经验和泛化能力方面的局限性，并在仓库级程序修复任务中取得了显著优于现有SOTA开源方法的性能。

> **ai_Abstract:** ExpeRepair是一种创新的基于LLM的仓库级程序修复方法，旨在解决现有LLM方法在孤立处理问题和使用静态提示方面的局限性。该方法受人类双记忆系统启发，通过双通道知识积累持续学习历史修复经验，将经验分为情景记忆（具体示例）和语义记忆（抽象见解）。在推理时，ExpeRepair激活这两种记忆并结合动态提示组合，以提高修复的适应性。实验结果表明，ExpeRepair在SWE-bench Lite基准测试上取得了49.3%的pass@1分数，优于所有现有最先进的开源方法。

> **摘要翻译:** 自动修复软件问题仍然是软件工程和人工智能交叉领域的一个基本挑战。尽管大型语言模型（LLMs）的最新进展已显示出在仓库级修复任务中的潜力，但当前的方法存在两个显著的局限性：(1) 它们通常孤立地处理问题，忽略了结合先前已解决问题的见解；(2) 它们依赖静态和僵化的提示策略，这限制了它们在多样化和不断演变的问题场景中进行泛化的能力。受人类认知双记忆系统的启发，即情景记忆和语义记忆协同工作以支持人类推理和决策，我们提出了ExpeRepair，一种新颖的基于LLM的方法，通过双通道知识积累持续从历史修复经验中学习。ExpeRepair将历史修复经验组织成两种互补的记忆：存储具体修复演示的情景记忆，以及编码抽象反思性见解的语义记忆。在推理时，ExpeRepair通过从情景记忆中检索相关演示并从语义记忆中回忆高级修复见解来激活两个记忆系统。它通过动态提示组合进一步增强适应性，协同整合两种记忆类型，以上下文感知、经验驱动的提示取代静态提示。在SWE-bench Lite基准测试上的实验表明，ExpeRepair使用Claude 3.7 Sonnet实现了49.3%的pass@1分数，优于所有最先进的开源方法。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [257] [BugGen: A Self-Correcting Multi-Agent LLM Pipeline for Realistic RTL Bug Synthesis](https://arxiv.org/abs/2506.10501)
> *BugGen：一种用于真实RTL错误合成的自校正多智能体LLM管道*

*Surya Jasper, Minh Luu, Evan Pan, Aakash Tyagi, Michael Quinn, Jiang Hu, David Kebo Houngninou* | **Main category: cs.SE**

**Keywords:** RTL错误合成, LLM, 多智能体, 硬件验证, 错误生成

**Comment:** 

> **TL;DR:** BugGen是一个自校正多智能体LLM管道，用于自动化生成真实RTL错误，显著提高硬件验证效率和ML辅助调试。

**AI_Comments:** BugGen的创新之处在于其采用多智能体LLM管道进行自校正的错误合成，这解决了硬件验证中高质量、可扩展错误数据集的痛点。其自动化、高效率和高准确率的特点，以及在发现新错误和辅助ML调试方面的实用性，都显示了其在未来硬件验证领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 硬件复杂性持续给验证资源带来压力，需要机器学习方法提高调试效率。然而，ML辅助调试关键依赖于多样化和可扩展的错误数据集，而现有的手动或自动化错误插入方法都无法可靠地生成此类数据集。

**Method:** BugGen是一个全自主、多智能体管道，利用大型语言模型（LLM）系统性地生成、插入和验证RTL中的真实功能错误。它通过闭环智能体架构分区模块，选择突变目标，并采用迭代细化和回滚机制确保语法正确性和功能可检测性。

**Result:** 在五个OpenTitan IP块上，BugGen生成了500个独特错误，功能准确率达94%，吞吐量为每小时17.7个已验证错误（比典型手动插入快五倍以上）。它还识别了OpenTitan回归测试中104个先前未检测到的错误。与Certitude相比，BugGen的语法准确性提高一倍以上，更深入地暴露了测试台盲点，并生成了更具功能意义和复杂的错误场景。此外，生成的错误数据集用于训练ML故障分类模型，实现了88.1%-93.2%的高分类准确率。

**Conclusion:** BugGen提供了一个可扩展的解决方案，用于生成高质量错误数据集，显著提高验证效率和ML辅助调试。

> **ai_Abstract:** 本文介绍了BugGen，一个首创的、基于LLM的自校正多智能体管道，旨在自动化生成和验证真实的RTL功能错误。为解决现有方法无法可靠生成多样化错误数据集的问题，BugGen通过迭代细化和回滚机制确保语法正确性和功能可检测性。实验表明，BugGen能高效生成高质量错误，显著提高硬件验证效率，并能有效训练ML辅助调试模型，其性能优于现有工具。

> **摘要翻译:** 硬件复杂性持续给验证资源带来压力，这促使人们采用机器学习（ML）方法来提高调试效率。然而，ML辅助调试关键依赖于多样化和可扩展的错误数据集，而现有的手动或自动化错误插入方法都无法可靠地生成此类数据集。我们引入了BugGen，这是首个利用大型语言模型（LLM）的完全自主、多智能体管道，用于系统地在RTL中生成、插入和验证真实的功能错误。BugGen通过闭环智能体架构对模块进行分区，选择变异目标，并采用迭代细化和回滚机制，以确保语法正确性和功能可检测性。在对五个OpenTitan IP块的评估中，BugGen生成了500个独特的错误，功能准确率达到94%，并实现了每小时17.7个已验证错误的吞吐量——比典型的人工专家插入快五倍以上。此外，BugGen在OpenTitan回归测试中识别出104个先前未检测到的错误，突显了其在暴露验证覆盖率空白方面的作用。与Certitude相比，BugGen的语法准确性提高了一倍以上，更深入地暴露了测试台盲点，并生成了更具功能意义和更复杂的错误场景。此外，当这些BugGen生成的数据集用于训练基于ML的故障分类模型时，我们在不同的IP块上实现了高分类准确率（88.1%-93.2%），证实了所生成错误的实用性和真实性。因此，BugGen提供了一个可扩展的解决方案，用于生成高质量的错误数据集，显著提高了验证效率和ML辅助调试。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [273] [AdaptiveLLM: A Framework for Selecting Optimal Cost-Efficient LLM for Code-Generation Based on CoT Length](https://arxiv.org/abs/2506.10525)
> *AdaptiveLLM：一个基于CoT长度为代码生成选择最佳成本效益LLM的框架*

*Junhang Cheng, Fang Liu, Chengru Wu, Li Zhang* | **Main category: cs.SE**

**Keywords:** LLM, 代码生成, 成本效益, Chain-of-Thought, 任务难度评估

**Comment:** Accepted by Internetware 2025

> **TL;DR:** AdaptiveLLM是一个根据Chain-of-Thought长度自动评估任务难度，并动态选择最佳成本效益大型语言模型（LLM）用于代码生成的框架，显著提高了性能并降低了资源消耗。

**AI_Comments:** AdaptiveLLM的创新之处在于其自动化的任务难度评估机制，特别是利用Chain-of-Thought长度作为评估指标，这避免了对人工标注的依赖，并与LLM自身的推理过程相契合。该框架在优化性能-成本权衡方面表现出色，为实际应用中的LLM部署提供了有价值的解决方案，尤其是在资源受限的环境下。其方法结合了深度学习（CodeBERT）和传统机器学习（XGBoost），显示了多模型协同的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在代码生成方面表现出色，但面临性能与推理成本之间的平衡挑战。现有模型选择方法资源密集，忽视成本效益，且依赖难以获取或与LLM自身评估不符的人工标注难度标签。

**Method:** AdaptiveLLM框架通过以下步骤动态选择最优LLM：首先，使用推理模型生成的Chain-of-Thought（CoT）长度来估计任务难度；其次，通过k-means将这些难度聚类为三个级别；然后，微调CodeBERT以嵌入难度感知特征；最后，训练一个XGBoost分类器来选择每个问题的最佳模型，以优化性能-成本权衡。

**Result:** 实验结果显示，与基线方法ComplexityNet相比，AdaptiveLLM的pass@1得分提高了7.86%，同时资源消耗降低了88.9%。与单个模型相比，AdaptiveLLM在保持相同成本水平的同时，准确性提高了约15%。此外，使用CoT进行难度评估提供了比人工评估更可靠的选择标准。

**Conclusion:** AdaptiveLLM通过自动评估任务难度并动态选择最佳LLM，有效解决了代码生成中性能与成本的平衡问题，显著提升了效率和性能，并证明了CoT长度作为难度评估指标的可靠性。

> **ai_Abstract:** AdaptiveLLM是一个创新的框架，旨在解决大型语言模型在代码生成中性能与成本平衡的难题。它通过自动分析Chain-of-Thought长度来评估任务难度，并利用k-means聚类、CodeBERT微调和XGBoost分类器动态选择最适合的LLM。实验证明，AdaptiveLLM在显著降低资源消耗的同时，有效提升了代码生成的准确率，并提供了一种比人工评估更可靠的任务难度判断方法。

> **摘要翻译:** 大型语言模型（LLMs）显著提升了代码生成效率，但在不同编程任务中面临平衡性能和推理成本的固有挑战。根据任务难度和资源限制动态选择最优LLM，为实现效率和性能的最佳平衡提供了一种有前景的方法。然而，现有的模型选择方法资源密集，且常常忽视成本效益。此外，这些方法依赖于人工标注的难度标签，这些标签在实际应用中往往难以获取，并且可能与LLM自身对任务难度的评估不符。本文介绍了一种名为AdaptiveLLM的框架，该框架通过自动评估任务难度，为给定的编码任务动态选择最优的LLM。我们的框架首先使用推理模型生成的思维链（Chain-of-Thought）长度来估计任务难度，然后通过k-means将这些长度聚类为三个难度级别，并微调CodeBERT以嵌入难度感知特征。训练好的XGBoost分类器随后为每个问题选择最佳模型，从而优化性能-成本权衡。实验结果表明，与基线方法ComplexityNet相比，AdaptiveLLM在pass@1得分上提高了7.86%，同时资源消耗降低了88.9%。与单一模型相比，AdaptiveLLM在保持相同成本水平的同时，准确性提高了约15%。除此之外，使用CoT进行的难度评估提供了比人工评估更可靠的选择标准。我们的复制包可在https://github.com/cjhCoder7/AdaptiveLLM获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [296] [Not One to Rule Them All: Mining Meaningful Code Review Orders From GitHub](https://arxiv.org/abs/2506.10654)
> *并非一统天下：从GitHub挖掘有意义的代码审查顺序*

*Abir Bouraffa, Carolin Brandt, Andy Zaidmann, Walid Maalej* | **Main category: cs.SE**

**Keywords:** 代码审查, GitHub, 导航顺序, 拉取请求, 开发者行为

**Comment:** 

> **TL;DR:** 研究发现GitHub代码审查中，近一半的开发者不按字母顺序审查文件，而是采用多种有意义的复杂策略，如大改动优先、与标题相关性优先或测试优先，这表明需要更好的工具支持。

**AI_Comments:** 这项研究通过大规模数据分析揭示了代码审查中普遍存在的非线性、非字母顺序的审查行为，挑战了当前工具默认的文件呈现方式。其创新之处在于识别并量化了多种有意义的审查策略，如“最大差异优先”和“测试优先”，这对于理解开发者行为模式具有重要意义。研究结果强调了改进代码审查工具的必要性，以更好地支持审查者的实际工作流，从而可能提高审查效率和质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的代码审查工具（如GitHub）通常按字母顺序展示文件，但这与审查者的实际导航顺序不符。本研究旨在调查开发者在审查代码时所遵循的不同导航顺序。

**Method:** 研究从GitHub上100个流行的Java和Python仓库的23,241个拉取请求中挖掘了代码审查评论，分析了审查者对提交更改进行评论的顺序。

**Result:** 44.6%的拉取请求中，审查者以非字母顺序进行评论。在这些非字母顺序评论中，识别出多种有意义的替代顺序：20.6%遵循“最大差异优先”顺序，17.6%遵循文件与拉取请求标题和描述的相似性顺序，29%（包含生产和测试文件的拉取请求）遵循“测试优先”顺序。非字母顺序审查中，已审查文件占总提交文件的比例显著更高。非字母顺序审查平均获得的批准略少。

**Conclusion:** 研究结果强调了代码审查中需要额外的支持，特别是对于大型拉取请求，因为审查者更可能采用复杂的策略，而非遵循单一预定义顺序。

> **ai_Abstract:** 本文通过分析GitHub上23,241个拉取请求的代码审查评论，发现近一半的审查者不按字母顺序审查文件，而是采用“最大差异优先”、“与标题相似度优先”或“测试优先”等多种有意义的导航策略。研究指出，非字母顺序审查的覆盖率更高但批准率略低。这些发现表明，现有工具在代码审查中存在不足，尤其是在处理大型拉取请求时，需要提供更多支持以适应审查者复杂的审查习惯。

> **摘要翻译:** 开发者使用GitHub拉取请求等工具进行代码审查、讨论提议的更改并请求修改。虽然更改的文件通常按字母顺序呈现，但这不一定与审查者偏好的导航顺序一致。本研究调查了开发者在评论拉取请求中提交的更改时所遵循的不同导航顺序。我们从GitHub上100个流行的Java和Python仓库的23,241个拉取请求中挖掘了代码审查评论，以分析审查者对提交更改进行评论的顺序。我们的分析显示，对于44.6%的拉取请求，审查者以非字母顺序进行评论。在这些拉取请求中，我们发现了替代的有意义的顺序：20.6%（2,134个）遵循“最大差异优先”顺序，17.6%（1,827个）按照文件与拉取请求标题和描述的相似性顺序进行评论，以及29%（1,188个）包含生产和测试文件更改的拉取请求遵循“测试优先”顺序。我们还观察到，在非字母顺序审查中，已审查文件占总提交文件的比例显著更高，这些审查平均获得的批准也略少。我们的发现强调了代码审查中需要额外的支持，特别是对于大型拉取请求，因为审查者更可能采用复杂的策略，而非遵循单一预定义顺序。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [307] [Formalising Software Requirements using Large Language Models](https://arxiv.org/abs/2506.10704)
> *使用大型语言模型形式化软件需求*

*Arshad Beg, Diarmuid O'Donoghue, Rosemary Monahan* | **Main category: cs.SE**

**Keywords:** 形式化规范, 需求可追溯性, 大型语言模型, 自然语言处理, 软件工程

**Comment:** Accepted and presented as a poster in ADAPT Annual Conference
  (AACS2025) on 15th of May, 2025

> **TL;DR:** 本文介绍了VERIFAI项目，旨在通过自然语言处理、本体论、软件复用、大型语言模型和人工智能等方法，自动化自然语言需求的形式化规范生成和可追溯性，以解决形式化规范的可追溯性和验证挑战。

**AI_Comments:** 本文介绍了VERIFAI项目，其创新点在于利用大型语言模型和人工智能来形式化软件需求，并提高其可追溯性和验证。这对于解决软件工程中形式化规范的挑战具有重要意义。由于是项目初期介绍，因此未提及具体局限性或已取得的成果。

<details>
  <summary>Details</summary>

**Motivation:** 解决自然语言需求的形式化规范在可追溯性和验证方面的挑战。

**Method:** 探索的方法包括自然语言处理（NLP）、使用本体论描述软件系统领域、复用现有软件构件（基于相似性的复用）、使用大型语言模型识别和声明规范，以及利用人工智能指导整个过程。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了VERIFAI项目，旨在解决自然语言需求形式化规范的可追溯性和验证挑战。该项目通过自动化形式化规范的生成和需求的全生命周期可追溯性来实现，主要方法包括自然语言处理、本体论、软件构件复用、大型语言模型以及人工智能指导。

> **摘要翻译:** 本文简要介绍了我们最近启动的一个名为VERIFAI的项目：自然语言需求的可追溯性和验证。该项目通过支持形式化规范的自动生成以及从初始软件设计阶段到系统实施和验证的整个过程中需求的可追溯性，来解决形式化规范可追溯性和验证方面的挑战。该项目探索的方法包括自然语言处理、使用本体论描述软件系统领域、复用来自类似系统的现有软件构件（即通过基于相似性的复用），以及使用大型语言模型识别和声明规范，同时利用人工智能指导整个过程。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [318] [From Tea Leaves to System Maps: Context-awareness in Monitoring Operational Machine Learning Models](https://arxiv.org/abs/2506.10770)
> *从茶叶到系统地图：操作机器学习模型监控中的上下文感知*

*Joran Leest, Claudia Raibulet, Patricia Lago, Ilias Gerostathopoulos* | **Main category: cs.SE**

**Keywords:** 机器学习监控, 上下文感知, 系统性综述, C-SAR框架, 模型失败

**Comment:** 

> **TL;DR:** 生产中的ML模型失败是由于上下文错位而非统计异常。现有监控缺乏上下文理解。本文通过系统性综述，提出了C-SAR框架和20种模式，将ML监控从统计观察提升为系统地图管理，以实现可靠监控。

**AI_Comments:** 这篇论文的创新点在于它明确指出了生产ML模型失败的核心问题是“上下文错位”，而非传统关注的统计异常。通过系统性综述，它提出了一个全新的概念框架（C-SAR）和具体的模式，为ML监控提供了一种更全面、更具解释性的方法，超越了单纯的漂移检测，有助于实现更可靠的根本原因分析。这对于MLOps实践具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 生产环境中的机器学习模型失败并非源于输入数据的统计异常，而是由于环境与训练假设偏离导致的上下文错位。尽管ML监控研究广泛，但缺乏如何有效利用上下文信息的共享理解，导致难以从统计漂移检测转向有意义的警报和系统性根本原因分析。

**Method:** 本文进行了一项系统性综述，分析了数据挖掘、数据库、软件工程和机器学习领域94项主要研究，旨在表征和构建该领域中各种类型的上下文信息。在此基础上，提出了一个概念模型——上下文系统-方面-表示（C-SAR）框架。

**Result:** 识别并提出了上下文系统-方面-表示（C-SAR）框架，这是一个综合研究发现的概念模型。此外，还识别了20种重复出现且可能可重用的特定系统、方面和表示组合模式，并将它们映射到所支持的监控活动。

**Conclusion:** 该研究为ML监控提供了一个新视角：从解释观测统计数据的“茶叶”转变为构建和管理“系统地图”，从而实现系统化、可靠的ML监控实践。

> **ai_Abstract:** 本文通过对94项研究的系统性综述，探讨了生产环境中机器学习模型失败的根本原因在于上下文错位而非统计异常。为解决ML监控中缺乏上下文信息共享理解的问题，作者提出了上下文系统-方面-表示（C-SAR）框架，并识别了20种可重用的上下文模式，旨在将ML监控从简单的统计漂移检测提升为基于系统地图的、更具系统性和可靠性的实践。

> **摘要翻译:** 生产中的机器学习（ML）模型并非因输入数据中的统计异常而失败；它们是由于上下文错位而失败——当其环境偏离训练假设时，导致不可靠的预测。有效的ML监控需要丰富的上下文信息，才能超越统计偏移检测，转向有意义的警报和系统性的根本原因分析。然而，令人惊讶的是，尽管在ML监控及相关学科（漂移检测、数据验证、域外检测）进行了广泛研究，但对于如何使用上下文信息却没有共享的理解——考虑到监控涉及对信息在上下文中的解释，这一点令人震惊。为此，本文提出了一项系统性综述，旨在表征和构建该领域中各种类型的上下文信息。我们的分析考察了数据挖掘、数据库、软件工程和ML领域的94项主要研究。我们引入了上下文系统-方面-表示（C-SAR）框架，这是一个综合我们研究结果的概念模型。我们还识别了20种重复出现且可能可重用的特定系统、方面和表示组合模式，并将它们映射到它们支持的监控活动。这项研究为ML监控提供了一个新视角：从解释观测统计数据的“茶叶”转变为构建和管理“系统地图”，从而实现系统化、可靠的ML监控实践。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [324] [What Users Value and Critique: Large-Scale Analysis of User Feedback on AI-Powered Mobile Apps](https://arxiv.org/abs/2506.10785)
> *用户看重和批评什么：AI驱动移动应用用户反馈的大规模分析*

*Vinaik Chhetri, Krishna Upadhyay, A. B. Siddique, Umar Farooq* | **Main category: cs.SE**

**Keywords:** AI驱动应用, 用户反馈, 大规模分析, 情感分析, 大型语言模型

**Comment:** 12 pages, 6 figures, 5 tables

> **TL;DR:** 通过大规模分析AI驱动移动应用的用户反馈，发现用户关注生产力、可靠性、个性化，并抱怨技术故障、价格和语言支持。

**AI_Comments:** 这项研究的创新之处在于其大规模的用户反馈分析方法，特别是构建了包含近90万条AI特定评论的数据集，并开发了一个能处理细粒度、共存情感的多阶段分析管道。它揭示了AI驱动应用中用户价值和批评的具体方面，为AI产品设计和改进提供了宝贵的见解。其重要性在于填补了对AI功能用户感知空白，并提供了一个可扩展的分析框架。

<details>
  <summary>Details</summary>

**Motivation:** AI驱动功能在移动应用中迅速普及，但用户如何感知、评估和批评这些AI功能仍未被充分探索，这主要是由于用户反馈量巨大。

**Method:** 本研究对Google Play上292个AI驱动应用（涵盖14个类别，89.4万条AI相关评论）的用户反馈进行了首次全面、大规模研究。开发并验证了一个多阶段分析管道，包括人工标注基准、评估大型语言模型（LLMs）和提示策略，以及评论分类、方面情感提取和聚类。该管道实现了对用户反馈的可扩展、高精度分析。

**Result:** 管道提取了超过一百万个方面情感对，聚类为18个积极用户主题和15个消极用户主题。分析显示，用户积极评论侧重于生产力、可靠性和个性化帮助，而负面反馈突出技术故障（如扫描和识别）、价格问题和语言支持限制。该管道能识别同一评论中对不同功能的满意和不满，这些细粒度、共存的情感常被传统方法忽略。类别感知分析揭示了普遍的满意驱动因素和特定领域的挫败感。

**Conclusion:** 本研究提出的方法能更忠实地反映用户在AI驱动应用中的真实体验，揭示了用户对AI功能普遍的关注点和特定领域的痛点。

> **ai_Abstract:** 本研究对AI驱动移动应用的用户反馈进行了首次大规模分析，利用Google Play上近90万条评论构建数据集并开发了多阶段分析管道。该管道能高精度提取细粒度方面情感对，揭示了用户对AI功能的普遍关注点（如生产力、可靠性）和主要痛点（如技术故障、价格、语言支持），并能识别同一评论中的正负面共存情感，比传统方法更全面地反映了用户体验。

> **摘要翻译:** 人工智能（AI）驱动的功能已迅速普及到各种领域的移动应用中，包括生产力、教育、娱乐和创造力。然而，用户如何感知、评估和批评这些AI功能在很大程度上仍未被探索，这主要是由于用户反馈量巨大。在这项工作中，我们首次对AI驱动移动应用的用户反馈进行了全面、大规模的研究，利用了来自Google Play的292个AI驱动应用（涵盖14个类别）的89.4万条AI特定评论的精选数据集。我们开发并验证了一个多阶段分析管道，该管道始于人工标注基准，并系统地评估大型语言模型（LLMs）和提示策略。每个阶段，包括评论分类、方面情感提取和聚类，都经过了准确性和一致性验证。我们的管道实现了用户反馈的可扩展、高精度分析，提取了超过一百万个方面情感对，这些情感对被聚类为18个积极用户主题和15个消极用户主题。我们的分析表明，用户始终关注一组狭窄的主题：积极评论强调生产力、可靠性和个性化帮助，而负面反馈则突出技术故障（例如，扫描和识别）、价格问题和语言支持的限制。我们的管道能识别同一评论中对某个功能的满意和对另一个功能的不满。这些细粒度、共存的情感常常被传统方法忽略，因为传统方法将积极和消极反馈孤立处理或依赖粗粒度分析。为此，我们的方法更忠实地反映了AI驱动应用中真实的现实世界用户体验。类别感知分析进一步揭示了普遍的满意驱动因素和特定领域的挫败感。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [331] [Solving Package Management via Hypergraph Dependency Resolution](https://arxiv.org/abs/2506.10803)
> *通过超图依赖解析解决包管理问题*

*Ryan Gibb, Patrick Ferris, David Allsopp, Michael Winston Dales, Mark Elvers, Thomas Gazagnaire, Sadiq Jaffer, Thomas Leonard, Jon Ludlam, Anil Madhavapeddy* | **Main category: cs.SE**

**Keywords:** 包管理, 依赖解析, 超图, 互操作性, 跨生态系统

**Comment:** Submitted to SPLASH 2025

> **TL;DR:** HyperRes是一个使用超图的正式系统，旨在解决不同包管理器生态系统之间缺乏互操作性的问题，允许跨语言项目精确表达和解决依赖关系，而无需用户更换现有包管理器。

**AI_Comments:** 本文的创新之处在于提出了一种基于超图的统一形式系统HyperRes来解决跨生态系统的包依赖问题，这在现有各自为政的包管理领域具有重要意义。它通过提供一种非侵入性的解决方案（无需用户更换包管理器）来增强互操作性，为多语言和复杂软件项目的依赖管理提供了强大的支持。其贡献在于理论框架的构建和实际可行性的证明。

<details>
  <summary>Details</summary>

**Motivation:** 现有包管理器之间缺乏互操作性，导致多语言项目无法精确表达跨语言生态系统的依赖关系，且外部系统和硬件依赖通常是隐式且未版本化的。

**Method:** 定义了HyperRes，一个使用超图描述版本化依赖解析的正式系统。该系统足够表达和建模多种生态系统，并能解决跨生态系统的依赖约束。此外，还定义了从数十个现有包管理器到HyperRes的转换。

**Result:** HyperRes能够建模许多现有生态系统并解决跨它们存在的依赖约束。研究表明，依赖解析可以在当前独立的生态系统之间进行。HyperRes允许在生态系统之间转换打包元数据，并可以为特定部署环境进行精确的专业化解决。

**Conclusion:** HyperRes提供了一种统一且可互操作的包管理解决方案，能够跨不同生态系统精确解决依赖关系，同时不强制用户改变其现有包管理器的选择。

> **ai_Abstract:** 该研究提出了HyperRes，一个基于超图的正式系统，旨在解决现有包管理器之间缺乏互操作性的问题。通过将数十种现有包管理器转换为HyperRes模型，该系统能够精确建模并解决跨多个语言和操作系统生态系统的版本化依赖关系。其核心创新在于，它允许跨生态系统进行依赖解析和元数据转换，同时无需用户切换其偏好的包管理器，从而为多语言和复杂项目提供了统一且可定制的依赖管理能力。

> **摘要翻译:** 包管理器无处不在，几乎每种语言和操作系统都实现了自己的解决方案。这些系统之间缺乏互操作性，意味着多语言项目无法在语言生态系统之间表达精确的依赖关系，并且外部系统和硬件依赖通常是隐式且未版本化的。我们定义了HyperRes，一个用于描述版本化依赖解析的正式系统，它使用超图，其表达能力足以建模许多生态系统并解决它们之间的依赖约束。我们定义了从数十个现有包管理器到HyperRes的转换，并全面证明了依赖解析可以在当前独立的生态系统之间工作。这不需要用户改变他们选择的包管理器；相反，HyperRes允许在生态系统之间转换打包元数据，并可以为特定的部署环境进行精确的专业化解决。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [338] [Evaluating Large Language Models on Non-Code Software Engineering Tasks](https://arxiv.org/abs/2506.10833)
> *评估大型语言模型在非代码软件工程任务中的表现*

*Fabian C. Peña, Steffen Herbold* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 软件工程, 非代码任务, 基准测试, SELU

**Comment:** 

> **TL;DR:** 本文提出了SELU，首个全面评估LLM在17项非代码软件工程任务中表现的基准，结果显示中等规模的解码器模型表现最佳。

**AI_Comments:** 本文的主要创新在于创建了SELU，这是首个专门针对非代码软件工程任务的综合基准测试集。这填补了LLM评估领域的一个重要空白，因为此前大多数工作都集中在代码相关任务上。研究发现中等规模的仅解码器模型表现出色，而代码领域预训练对非代码任务的益处有限，这一洞察对从业者和研究人员都至关重要，它能指导SE领域更高效的模型开发和选择。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在代码理解和生成方面表现出色，但它们在非代码软件工程（SE）任务中的有效性尚未得到充分探索。

**Method:** 本文提出了首个综合基准测试集SELU，用于评估LLM在17项非代码任务中的表现，这些任务涵盖了从识别需求功能性到估算待办事项工作量和复杂性。SELU包含分类、回归、命名实体识别（NER）和掩码语言建模（MLM）等目标，数据来源于代码仓库、问题跟踪系统和开发者论坛。研究人员对22个开源LLM进行了微调，提示了2个专有LLM，并训练了2个基线模型。性能通过F1-macro、SMAPE、F1-micro和准确率等指标进行衡量，并采用贝叶斯符号秩检验进行比较。

**Result:** 结果表明，中等规模的仅解码器模型持续表现出顶尖水平，具有高平均性能和低跨任务方差，而通过代码领域预训练进行的领域适应可能只会带来适度的改进。

**Conclusion:** 这些见解为非代码软件工程工作流中的模型选择提供了指导，并指出了将SELU扩展到生成式和设计导向场景的方向。

> **ai_Abstract:** 本文提出了首个用于评估大型语言模型（LLMs）在17项不同非代码软件工程（SE）任务上表现的综合基准测试集SELU。SELU涵盖分类、回归、命名实体识别（NER）和掩码语言建模（MLM）等任务类型，数据来源于多种渠道。研究人员对22个开源LLM进行了微调，并评估了2个专有LLM和2个基线模型，通过多种指标衡量性能。结果显示，中等规模的仅解码器模型表现出卓越且稳定的一致性，而通过代码领域预训练进行的领域适应仅带来了有限的提升。这些发现为非代码SE工作流中的模型选择提供了指导，并指明了SELU未来扩展的方向。

> **摘要翻译:** 大型语言模型（LLMs）在代码理解和生成方面表现出卓越的能力；然而，它们在非代码软件工程（SE）任务中的有效性仍未得到充分探索。我们提出了第一个综合基准测试集，命名为“软件工程语言理解”（SELU），用于评估LLMs在17项非代码任务上的表现，这些任务涵盖了从识别需求是功能性还是非功能性到估算待办事项的工作量和复杂性。SELU涵盖分类、回归、命名实体识别（NER）和掩码语言建模（MLM）目标，数据来源于代码仓库、问题跟踪系统和开发者论坛等多样化来源。我们对22个开源LLMs进行了微调，提示了两个专有替代方案，并训练了两个基线模型。性能通过F1-macro、SMAPE、F1-micro和准确率等指标进行衡量，并通过贝叶斯符号秩检验进行比较。我们的结果表明，中等规模的仅解码器模型始终构成顶级水平，表现出高平均性能和低跨任务方差，而通过代码领域预训练进行的领域适应可能只会带来适度的改进。这些见解指导了非代码SE工作流中的模型选择，并突出了将SELU扩展到生成式和设计导向场景的方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [344] [MultiCoSim: A Python-based Multi-Fidelity Co-Simulation Framework](https://arxiv.org/abs/2506.10869)
> *MultiCoSim：一个基于Python的多精度协同仿真框架*

*Quinn Thibeault, Giulia Pedrielli* | **Main category: cs.SE**

**Keywords:** 多精度, 协同仿真, 网络物理系统, Python, 仿真框架

**Comment:** 

> **TL;DR:** MultiCoSim是一个基于Python的框架，旨在为复杂的网络物理系统提供灵活、分布式、多精度的协同仿真，解决了现有工具的局限性。

**AI_Comments:** MultiCoSim的创新之处在于其Python基础和编程接口，大大提高了仿真配置的灵活性、模块化和自动化程度，这对于复杂且安全关键的网络物理系统至关重要。它解决了传统工具的刚性配置问题，有助于推动可重用基准和自动化评估的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于网络物理系统（CPS）的仿真工具配置僵化、缺乏自动化支持，并且在可移植性和模块化方面存在障碍，这阻碍了对日益复杂的CPS进行快速、准确的分析以及可重用基准的开发。

**Method:** 本文引入了MultiCoSim，一个基于Python的仿真框架，允许用户以编程方式定义、组合和配置仿真组件。MultiCoSim支持分布式、基于组件的协同仿真，并允许无缝替换和重新配置组件。

**Result:** 通过涉及自定义基于自动机的控制器以及与PX4无人机自动驾驶仪等现成平台集成的案例研究，展示了MultiCoCoSim的灵活性。这些示例突出了MultiCoSim简化CPS研究和开发仿真流程的能力。

**Conclusion:** MultiCoSim有效地解决了现有仿真工具的挑战，通过提供一个灵活、编程化和模块化的框架，用于复杂网络物理系统的多精度协同仿真，这已通过案例研究得到证明。

> **ai_Abstract:** MultiCoSim是一个基于Python的协同仿真框架，旨在解决现有网络物理系统（CPS）仿真工具的局限性。它支持分布式、多精度、组件化的协同仿真，允许用户通过编程方式定义、组合和配置仿真组件，实现无缝替换和重新配置。通过与PX4自动驾驶仪等平台的集成以及自定义控制器的案例研究，MultiCoSim展示了其在简化CPS研究和开发仿真流程方面的灵活性和有效性。

> **摘要翻译:** 仿真分析是网络物理系统（CPS）分析和测试的基础工具，支撑着算法开发、运行时监控和系统验证等活动。随着CPS复杂性和规模的增长，特别是在安全关键和支持学习的环境中，精确的分析和合成越来越依赖于仿真实验的快速使用。由于CPS本质上集成了硬件、软件和物理过程，仿真平台必须支持异构组件在不同精度级别的协同仿真。尽管硬件、固件和物理的高精度建模最近取得了进展，但在多样化环境中的协同仿真仍然具有挑战性。这些限制阻碍了可重用基准的开发，并阻碍了仿真在自动化和比较评估中的使用。
现有仿真工具通常依赖于僵化的配置，缺乏自动化支持，并对可移植性和模块化造成障碍。许多工具通过静态文本文件进行配置，或对仿真组件的表示和连接方式施加限制，使得灵活地组合系统或跨平台集成组件变得困难。
为了解决这些挑战，我们引入了MultiCoSim，一个基于Python的仿真框架，使用户能够以编程方式定义、组合和配置仿真组件。MultiCoSim支持分布式、基于组件的协同仿真，并允许组件的无缝替换和重新配置。我们通过案例研究展示了MultiCoSim的灵活性，其中包括涉及自定义基于自动机的控制器以及与用于空中机器人的PX4自动驾驶仪等现成平台的协同仿真。这些示例突出了MultiCoSim简化CPS研究和开发仿真流程的能力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [351] [SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks](https://arxiv.org/abs/2506.10954)
> *SWE-Factory：您的自动化问题解决训练数据和评估基准工厂*

*Lianghong Guo, Yanlin Wang, Caihua Li, Pengyu Yang, Jiachi Chen, Wei Tao, Yingtian Zou, Duyu Tang, Zibin Zheng* | **Main category: cs.SE**

**Keywords:** 自动化管道, GitHub问题解决, 数据集构建, 大型语言模型, 软件工程

**Comment:** 

> **TL;DR:** SWE-Factory是一个自动化管道，用于高效、准确地构建大规模GitHub问题解决数据集，解决了传统方法中环境设置、结果评分和任务验证的挑战。

**AI_Comments:** 该论文提出了一种高度创新且实用的解决方案，通过自动化关键环节，极大地降低了构建高质量GitHub问题解决数据集的成本和复杂性。SWE-Builder的多代理系统设计，结合基于退出代码的评分和自动化验证，是其核心创新点。这对于加速大型语言模型在软件工程领域的训练和评估具有重要意义，解决了当前数据稀缺和标注成本高昂的痛点。其开源代码和数据集的发布也体现了研究的开放性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 构建用于训练和评估大型语言模型（LLMs）软件工程能力的大规模GitHub问题解决数据集至关重要，但传统的数据集创建过程（特别是评估环境设置、测试结果评分和任务实例验证阶段）具有挑战性且劳动密集。

**Method:** 本文提出了SWE-Factory，一个自动化管道，集成了三个核心自动化组件：1. SWE-Builder：一个多代理系统，自动化评估环境构建，通过四个专业代理的协作迭代循环和环境内存池提高效率。2. 标准化的、基于退出代码的评分方法，无需手动编写自定义解析器。3. 自动化fail2pass验证过程，利用可靠的退出代码信号。

**Result:** 实验表明，该管道可以有效构建有效的任务实例，例如：使用GPT-4.1-mini，SWE-Builder能以每个实例0.045美元的成本构建269个有效实例；使用Gemini-2.5-flash，能以每个实例0.024美元的最低成本实现类似性能。基于退出代码的评分与手动检查相比达到100%的准确率，自动化fail2pass验证的精确度达到0.92，召回率达到1.00。

**Conclusion:** SWE-Factory自动化管道有望加速大规模、高质量GitHub问题解决数据集的收集，以用于训练和评估。

> **ai_Abstract:** SWE-Factory是一个创新的自动化管道，旨在解决构建大规模GitHub问题解决训练和评估数据集的挑战。它通过整合SWE-Builder（一个自动化环境构建的多代理系统）、基于退出代码的标准化评分方法以及自动化的fail2pass验证过程，显著提高了数据集构建的效率和准确性。实验证明了其在生成有效任务实例方面的能力，并在成本效益和准确性方面表现出色，有望加速高质量软件工程数据集的收集。

> **摘要翻译:** 构建用于GitHub问题解决任务的大规模数据集对于训练和评估大型语言模型（LLMs）的软件工程能力至关重要。然而，创建此类基准的传统过程以其挑战性和劳动密集性而闻名，特别是在设置评估环境、对测试结果进行评分和验证任务实例的阶段。在本文中，我们提出了SWE-Factory，一个旨在解决这些挑战的自动化管道。为了解决这些问题，我们的管道集成了三个核心自动化组件。首先，我们引入了SWE-Builder，一个多代理系统，它自动化评估环境的构建，该系统采用四个专门的代理，以协作、迭代的方式工作，并利用环境内存池来提高效率。其次，我们引入了一种标准化的、基于退出代码的评分方法，该方法消除了手动编写自定义解析器的需要。最后，我们使用这些可靠的退出代码信号自动化了fail2pass验证过程。对四种编程语言的671个问题的实验表明，我们的管道可以有效地构建有效的任务实例；例如，使用GPT-4.1-mini，我们的SWE-Builder以每个实例0.045美元的成本构建了269个有效实例，而使用Gemini-2.5-flash，它以每个实例0.024美元的最低成本实现了可比较的性能。我们还证明了我们基于退出代码的评分与手动检查相比达到了100%的准确率，并且我们的自动化fail2pass验证达到了0.92的精确度和1.00的召回率。我们希望我们的自动化管道将加速大规模、高质量GitHub问题解决数据集的收集，以用于训练和评估。我们的代码和数据集已发布在https://github.com/DeepSoftwareAnalytics/swe-factory。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [10] [Design of A* based heuristic algorithm for efficient interdiction in multi-Layer networks](https://arxiv.org/abs/2506.10017)
> *基于A*启发式算法的多层网络高效拦截设计*

*Sukanya Samanta* | **Main category: cs.SI**

**Keywords:** A*算法, 启发式算法, 多层网络, 拦截, 动态犯罪

**Comment:** 

> **TL;DR:** 本文提出一种基于A*启发式算法的方法，利用分层图表示来高效拦截动态犯罪环境中的目标，并在计算效率和解决方案质量方面表现出色。

**AI_Comments:** 该论文的创新点在于将动态拦截问题转化为分层图上的路径搜索问题，并巧妙地运用A*启发式算法进行求解，有效平衡了计算效率和解的质量。这对于实际的警务资源调度和犯罪拦截具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在动态犯罪环境中，犯罪分子位置不断变化，且交通网络庞大，使用有限警力拦截犯罪分子是一个重大挑战。

**Method:** 作者提出一种分层图表示方法，其中每个时间步都与交通网络的副本相关联。对于任何给定的攻击者策略，使用应用于分层图的A*启发式算法计算近最优的防御者策略，以最大化成功拦截的概率。

**Result:** 研究结果表明，所提出的方法有效解决了问题的复杂性，并在短时间内提供了高质量的解决方案。与混合整数线性规划（MILP）方法相比，该方法在计算效率和解决方案质量方面均表现良好。

**Conclusion:** 该研究提出的基于A*启发式算法的多层网络拦截方法能够高效且高质量地解决动态犯罪环境中的拦截问题。

> **ai_Abstract:** 本文针对动态犯罪环境中有限警力拦截不断变化的犯罪分子这一挑战，提出了一种基于A*启发式算法的新方法。该方法通过将交通网络表示为分层图，其中每个时间步对应一个网络副本，从而计算出近最优的防御者策略以最大化拦截成功率。实验结果表明，该方法在处理问题复杂性、计算效率和解决方案质量方面均优于传统的MILP方法。

> **摘要翻译:** 使用有限的警力在动态犯罪环境中拦截罪犯是一个重大挑战，因为罪犯的位置会随时间不断变化。交通网络的广阔性进一步增加了复杂性。为了解决这个问题，我们提出了一种分层图表示，其中每个时间步都与交通网络的副本相关联。对于任何给定的攻击者策略，使用应用于分层图的A*启发式算法计算出近乎最优的防御者策略。防御者的目标是最大化成功拦截的概率。我们通过将所提出的方法与用于防御者的混合整数线性规划（MILP）方法进行比较来评估其性能。比较考虑了计算效率和解决方案质量。结果表明，我们的方法有效地解决了问题的复杂性，并在短时间内提供了高质量的解决方案。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [37] [Inference of Hierarchical Core-Periphery Structure in Temporal Network](https://arxiv.org/abs/2506.10135)
> *临时网络中层次核心-边缘结构的推断*

*Theodore Y. Faust, Mason A. Porter* | **Main category: cs.SI**

**Keywords:** 核心-边缘结构, 时间网络, 层次结构, 随机块模型, 马尔可夫链蒙特卡罗

**Comment:** 

> **TL;DR:** 本文提出了一种基于多层网络表示和随机块模型的推断方法，用于在时间网络中检测层次核心-边缘结构，并使用马尔可夫链蒙特卡罗方法进行统计推断。

**AI_Comments:** 本文的创新之处在于首次将层次核心-边缘结构的概念及其检测方法扩展到时间网络领域，填补了该领域研究的空白。通过采用多层网络表示和统计推断方法，为理解复杂时间网络的动态介观结构提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的核心-边缘结构检测方法主要针对时间无关网络，而针对时间依赖（即“临时”）网络的检测方法很少。

**Method:** 该方法利用时间网络的多层网络表示和采用随机块模型的推断方法，将最近用于检测时间无关网络中层次核心-边缘结构的方法推广到时间网络。它使用马尔可夫链蒙特卡罗（MCMC）方法进行统计推断。

**Result:** 该方法在两个真实世界的时间网络中展示了其检测层次核心-边缘结构的能力，并简要讨论了识别出的结构。

**Conclusion:** 本文成功地将层次核心-边缘结构检测方法推广到时间网络，并提供了一种通过统计推断识别此类结构的新工具。

> **ai_Abstract:** 本文针对时间依赖网络中核心-边缘结构检测方法不足的问题，提出了一种新的推断方法。该方法将时间网络表示为多层网络，并结合随机块模型和马尔可夫链蒙特卡罗（MCMC）方法，将现有针对时间无关网络的层次核心-边缘结构检测方法推广到时间网络。作者通过在两个真实世界的时间网络上应用该方法，展示了其有效性。

> **摘要翻译:** 网络可以有各种类型的介观结构。网络中的一种介观结构是核心-边缘结构，它由连接紧密的核心节点和连接稀疏的边缘节点组成。核心节点之间连接紧密，并且可以与边缘节点连接，而边缘节点与其他节点的连接稀疏。关于时间无关网络中核心-边缘结构的研究很多，但针对时间依赖（即“临时”）网络的核-边缘检测方法却很少。利用时间网络的多层网络表示和采用随机块模型的推断方法，我们将最近用于检测时间无关网络中层次核心-边缘结构的方法[Polanco23]推广到时间网络。与“洋葱状”嵌套核心-边缘结构（其中每个节点根据其在网络核心中的嵌套深度被分配到一个组）相反，层次核心-边缘结构包含具有嵌套结构、树状结构（其中任意两个组必须要么不相交，要么一个严格包含另一个）和一般非嵌套介观结构（其中节点的组分配不一定以任何方式嵌套）的网络。为了执行统计推断并因此识别核心-边缘结构，我们使用马尔可夫链蒙特卡罗（MCMC）方法。我们用两个真实世界的时间网络说明了我们检测层次核心-边缘结构的方法，并简要讨论了我们在这些网络中识别出的结构。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [11] [AI5GTest: AI-Driven Specification-Aware Automated Testing and Validation of 5G O-RAN Components](https://arxiv.org/abs/2506.10111)
> *AI5GTest：AI驱动的5G O-RAN组件规范感知自动化测试与验证*

*Abiodun Ganiyu, Pranshav Gajjar, Vijay K Shah* | **Main category: cs.NI**

**Keywords:** O-RAN, 5G, 自动化测试, LLM, 规范验证

**Comment:** 

> **TL;DR:** AI5GTest是一个AI驱动的框架，利用协作式大型语言模型（LLM）自动化验证5G O-RAN组件，显著减少测试时间并保持高准确性。

**AI_Comments:** AI5GTest的创新在于将大型语言模型应用于复杂的O-RAN组件自动化测试，特别是通过Gen-LLM、Val-LLM和Debug-LLM的协同工作，实现了从测试用例生成到故障诊断的全流程自动化。引入人机协作机制提升了系统的可信度和透明度。该方法对于解决O-RAN多供应商环境下的测试复杂性和效率问题具有重要意义，是电信行业测试自动化领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** O-RAN的分解架构引入了复杂的测试挑战，现有框架（如OTICs）严重依赖手动过程，碎片化且易于人为错误，导致不一致和可伸缩性问题。

**Method:** 本文提出了AI5GTest，一个AI驱动的规范感知测试框架，旨在自动化验证O-RAN组件。该框架利用一个协作式大型语言模型（LLM）框架，包括Gen-LLM、Val-LLM和Debug-LLM。Gen-LLM负责根据3GPP和O-RAN规范自动生成测试用例的预期流程；Val-LLM负责交叉引用信令消息以验证合规性并检测偏差；Debug-LLM在出现异常时执行根本原因分析。此外，AI5GTest还结合了人机协作机制，以增强透明度和可信度。

**Result:** 经O-RAN TIFG和WG5-IOT测试规范的测试用例评估，AI5GTest与传统手动方法相比，显著减少了总体测试执行时间，同时保持了高验证准确性。

**Conclusion:** AI5GTest成功地解决了O-RAN组件测试的自动化和效率问题，通过AI驱动和规范感知的方法，提高了验证的准确性和可靠性，并有效应对了多供应商环境下的复杂性挑战。

> **ai_Abstract:** 本文介绍了AI5GTest，一个AI驱动的规范感知测试框架，旨在自动化5G O-RAN组件的验证。该框架利用Gen-LLM、Val-LLM和Debug-LLM组成的协作式大型语言模型，分别负责生成测试流程、验证合规性及进行故障分析。AI5GTest通过人机协作机制增强透明度，并在评估中显示出相比传统手动方法显著减少测试时间并保持高准确性的优势，有效解决了O-RAN测试中的效率和准确性问题。

> **摘要翻译:** 开放式无线接入网络 (O-RAN) 的出现通过促进互操作性、供应商多样性和快速创新，改变了电信行业。然而，其分解架构带来了复杂的测试挑战，特别是在根据 O-RAN 联盟和 3GPP 规范验证多供应商组件方面。现有框架，例如开放测试和集成中心 (OTIC) 提供的框架，严重依赖手动流程，碎片化且容易出现人为错误，导致不一致性和可扩展性问题。为了解决这些限制，我们提出了 AI5GTest——一个由 AI 驱动的、规范感知的测试框架，旨在自动化 O-RAN 组件的验证。AI5GTest 利用一个协作式大型语言模型 (LLM) 框架，该框架由 Gen-LLM、Val-LLM 和 Debug-LLM 组成。Gen-LLM 根据 3GPP 和 O-RAN 规范自动生成测试用例的预期过程流，而 Val-LLM 则根据这些流交叉引用信令消息以验证合规性并检测偏差。如果出现异常，Debug-LLM 会执行根本原因分析，提供故障原因的见解。为了提高透明度和可信度，AI5GTest 结合了人机协作机制，其中 Gen-LLM 在进行验证之前向测试人员提供前 k 个相关的官方规范以供批准。通过使用从 O-RAN TIFG 和 WG5-IOT 测试规范获得的一系列测试用例进行评估，AI5GTest 与传统手动方法相比，显著减少了总体测试执行时间，同时保持了高验证准确性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [38] [Large Language Models-Empowered Wireless Networks: Fundamentals, Architecture, and Challenges](https://arxiv.org/abs/2506.10651)
> *大型语言模型赋能的无线网络：基础、架构与挑战*

*Latif U. Khan, Maher Guizani, Sami Muhaidat, Choong Seon Hong* | **Main category: cs.NI**

**Keywords:** 大型语言模型, 无线网络, 电信LLMs, LLM原生系统, 双深度Q学习

**Comment:** 

> **TL;DR:** 本文探讨了大型语言模型（LLMs）与无线网络的融合，提出了“电信LLMs”和“LLM原生无线系统”的概念，并提供了一个分布式实现的案例研究，其中基于DDQN的解决方案表现优于现有方案，最后讨论了开放性挑战。

**AI_Comments:** 这篇论文具有创新性，因为它提出了将大型语言模型整合到无线网络中的新颖方法，并创造了“电信LLM”和“LLM原生无线系统”的术语。这种跨学科的方法利用了LLM的先进能力来管理和优化网络，从而应对现代无线通信的复杂需求。性能优于现有DDQN的案例研究为他们的理论框架增加了实际验证，为未来智能无线网络的设计奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 无线网络在满足服务质量（QoS）和体验质量（QoE）方面面临巨大挑战。与此同时，大型语言模型（LLMs）已成为许多复杂应用和任务的有效解决方案。因此，将LLMs与无线网络集成以应对这些挑战成为一个有前景的方向。

**Method:** 本文提出了由“电信LLMs”驱动的“LLM原生无线系统”的概念。文章提供了其基本原理、愿景，并进行了一个分布式实现的案例研究。在案例研究中，作者提出了一种基于双深度Q学习（DDQN）的解决方案。

**Result:** 在案例研究中，所提出的基于双深度Q学习（DDQN）的解决方案优于现有的DDQN解决方案。

**Conclusion:** 本文提出了LLM原生无线系统的概念，并探讨了将大型语言模型与无线网络集成的基本原理、架构和挑战。研究结果表明，这种集成具有潜力，但仍面临许多开放性挑战。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）与无线网络的融合，以应对当前无线网络在服务质量（QoS）和体验质量（QoE）方面的挑战。文章提出了“电信LLM”驱动的“LLM原生无线系统”概念，并阐述了其基本原理、愿景，并通过一个分布式实现的案例研究展示了其潜力。案例研究中，作者提出了一种基于双深度Q学习（DDQN）的解决方案，该方案表现优于现有DDQN方案。最后，文章还指出了该领域面临的开放性挑战。

> **摘要翻译:** 无线网络的快速发展带来了诸多挑战，这些挑战源于对服务质量的广泛需求，以及对创新体验质量指标（例如，触觉应用中用户定义的物理体验感指标）的需求。与此同时，大型语言模型（LLMs）作为许多困难和复杂应用/任务的有前景的解决方案而出现。这些都导致了LLMs与无线网络集成概念的提出。然而，这种集成具有挑战性，在设计中需要仔细关注。因此，在本文中，我们提出了由“电信LLMs”驱动的理性无线网络的概念，即“LLM原生无线系统”。我们提供了LLM原生无线系统分布式实现的基本原理、愿景和案例研究。在案例研究中，我们提出了一种基于双深度Q学习（DDQN）的解决方案，该解决方案优于现有的DDQN解决方案。最后，我们提出了开放性挑战。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [63] [Energy-Efficient Deep Learning for Traffic Classification on Microcontrollers](https://arxiv.org/abs/2506.10851)
> *微控制器上能量高效的深度学习流量分类*

*Adel Chehade, Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino* | **Main category: cs.NI**

**Keywords:** 流量分类, 深度学习, 微控制器, 能量高效, 物联网安全

**Comment:** Accepted at IEEE ISCC 2025

> **TL;DR:** 该研究提出了一种能量高效的深度学习方法，用于在资源受限的微控制器上进行流量分类，实现了高精度和低功耗。

**AI_Comments:** 这篇论文的创新之处在于结合了硬件感知神经架构搜索和模型量化，以实现在资源受限的微控制器上进行高效的深度学习推理。其重要性在于为物联网设备提供了实用的、低功耗的流量分类解决方案，特别是在设备端进行加密流量分析，这对于提升物联网安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在物联网智能系统和通信网络中广泛使用的资源受限微控制器上，需要实现能量高效的流量分类，并平衡精度、计算效率和实际部署能力。

**Method:** 开发了一种轻量级1D-CNN模型，通过硬件感知神经架构搜索（HW-NAS）进行优化。为实现部署，模型被量化为INT8。研究在ISCX VPN-NonVPN数据集上进行训练和评估，并在STM32F746G-DISCO和Nucleo-F401RE两种微控制器上评估了实际推理性能。

**Result:** 在ISCX VPN-NonVPN数据集上实现了96.59%的精度，模型参数量为88.26K，最大张量大小为20.12K，浮点运算量为10.08M FLOPs。模型在各种流量分类任务中泛化能力强，精度范围为94%至99%。INT8量化后精度仅下降1-2%。在STM32F746G-DISCO上推理延迟为31.43ms，能耗为7.86 mJ；在Nucleo-F401RE上推理延迟为115.40ms，能耗为29.10 mJ。

**Conclusion:** 这些结果证明了在设备上进行加密流量分析的可行性，为可扩展、低功耗的物联网安全解决方案铺平了道路。

> **ai_Abstract:** 本文提出了一种在资源受限微控制器上实现能量高效流量分类的深度学习方法。研究人员开发了一个轻量级1D-CNN模型，通过硬件感知神经架构搜索进行优化，并在ISCX VPN-NonVPN数据集上实现了96.59%的精度。该模型参数量小，泛化能力强，且经过INT8量化后精度损失微小。在实际微控制器上的测试表明，该方法实现了低延迟和低能耗的推理，为物联网安全提供了可行的设备端加密流量分析方案。

> **摘要翻译:** 在本文中，我们提出了一种实用的深度学习（DL）方法，用于在资源受限的微控制器上进行能量高效的流量分类（TC），这些微控制器广泛应用于基于物联网的智能系统和通信网络。我们的目标是平衡精度、计算效率和实际部署能力。为此，我们开发了一种轻量级1D-CNN，通过硬件感知神经架构搜索（HW-NAS）进行优化，在ISCX VPN-NonVPN数据集上实现了96.59%的精度，仅有88.26K个参数、20.12K的最大张量大小和10.08M的浮点运算（FLOPs）。此外，它在各种TC任务中表现出泛化能力，精度范围为94%至99%。为了实现部署，模型被量化为INT8，相对于其Float32对应版本，精度仅略微下降1-2%。我们在两种微控制器上评估了实际推理性能：高性能STM32F746G-DISCO和成本敏感型Nucleo-F401RE。部署的模型分别实现了31.43毫秒和115.40毫秒的推理延迟，每次推理的能耗分别为7.86毫焦和29.10毫焦。这些结果证明了设备上加密流量分析的可行性，为可扩展、低功耗的物联网安全解决方案铺平了道路。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [90] [Dynamic Beyond 5G and 6G Connectivity: Leveraging NTN and RIS Synergies for Optimized Coverage and Capacity in High-Density Environments](https://arxiv.org/abs/2506.10900)
> *动态B5G和6G连接：利用NTN和RIS协同优化高密度环境下的覆盖和容量*

*Valdemar Farré, Juan Estrada, David Vega, Luis F Urquiza-Aguiar, Juan A. Vásquez Peralvo, Symeon Chatzinotas* | **Main category: cs.NI**

**Keywords:** NTN, RIS, 6G, 高密度环境, 连接性

**Comment:** 6 pages, 6 figures, 11 tables

> **TL;DR:** 本文提出了一种新颖的6G无线网络规划框架，通过整合非地面网络（NTN）和可重构智能表面（RIS），在高密度环境下提供优化的覆盖和容量。

**AI_Comments:** 本文的创新之处在于将非地面网络（NTN）和可重构智能表面（RIS）进行协同集成，以解决高密度环境下未来6G网络面临的连接和容量挑战。这种集成方法超越了传统地面网络的局限性，并有望为拥挤场景提供更可靠、高效的通信。

<details>
  <summary>Details</summary>

**Motivation:** 大规模户外活动期间对可靠、高容量通信的需求不断增长，对传统地面网络（TN）构成了重大挑战，这些网络在高密度环境中往往难以提供一致的覆盖。

**Method:** 本文提出了一种新颖的6G无线网络规划框架，该框架将非地面网络（NTN）与可重构智能表面（RIS）相结合，以提供无处不在的覆盖和增强的网络容量。该框架通过利用NTN架构（包括低地球轨道（LEO）卫星和无源RIS平台）并将其与超越5G（B5G）地面网络无缝集成，克服了传统可部署基站的局限性。通过结合先进的B5G技术，如大规模多输入多输出（mMIMO）和波束成形，并优化C、S和Ka频段的频谱利用，实施了基于动态SINR模型的严格干扰管理策略。

**Result:** 全面的计算和仿真验证了所提出的框架，在高密度场景中显示出连接性、可靠性和成本效率的显著改善。

**Conclusion:** 这种集成策略代表了满足未来6G网络不断演进需求的一个有前景的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的6G无线网络规划框架，旨在解决传统地面网络在高密度环境下提供一致覆盖和高容量通信的挑战。该框架通过将非地面网络（NTN）与可重构智能表面（RIS）集成，并结合B5G技术（如mMIMO和波束成形）和动态SINR干扰管理，以优化C、S、Ka频段的频谱利用。仿真结果验证了该框架在高密度场景下能显著提升连接性、可靠性和成本效率，为未来6G网络需求提供了有前景的解决方案。

> **摘要翻译:** 大规模户外活动期间对可靠、高容量通信的需求不断增长，对传统地面网络（TN）构成了重大挑战，这些网络在高密度环境中往往难以提供一致的覆盖。本文提出了一种新颖的6G无线网络规划框架，该框架将非地面网络（NTN）与可重构智能表面（RIS）相结合，以提供无处不在的覆盖和增强的网络容量。我们的框架通过利用NTN架构（包括低地球轨道（LEO）卫星和无源RIS平台）并将其与超越5G（B5G）地面网络无缝集成，克服了传统可部署基站的局限性。通过结合先进的B5G技术，如大规模多输入多输出（mMIMO）和波束成形，并优化C、S和Ka频段的频谱利用，我们实施了基于动态SINR模型的严格干扰管理策略。全面的计算和仿真验证了所提出的框架，在高密度场景中显示出连接性、可靠性和成本效率的显著改善。这种集成策略代表了满足未来6G网络不断演进需求的一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [115] [Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence](https://arxiv.org/abs/2506.10925)
> *自主无线空间网络的代理语义控制：通过MCP驱动的分布式智能扩展Space-O-RAN*

*Eduardo Baena, Paolo Testolina, Michele Polese, Sergi Aliaga, Andrew Benincasa, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia* | **Main category: cs.NI**

**Keywords:** 代理控制, Space-O-RAN, 月球通信, 分布式智能, 语义控制

**Comment:** Lunar Surface Innovation Consortium 2025 Spring Meeting, May 20-22

> **TL;DR:** 本论文提出通过引入由模型上下文协议（MCP）和代理间（A2A）通信协议支持的语义代理层，扩展Space-O-RAN，以实现月球无线网络中上下文感知的分布式智能决策。

**AI_Comments:** 本文的创新之处在于将语义智能和代理控制集成到Space-O-RAN中，实现了从静态策略到动态、上下文感知决策的转变，以应对月球表面等极端环境的挑战。这种方法有效解决了自主性和适应性的关键问题。

<details>
  <summary>Details</summary>

**Motivation:** 月球表面操作对无线通信系统提出了严格要求，包括自主性、抗干扰鲁棒性以及适应环境和任务驱动上下文的能力。现有的Space-O-RAN虽然提供了符合3GPP标准的分布式编排模型，但其决策逻辑仅限于静态策略，且缺乏语义集成。

**Method:** 本文提出了一种新颖的扩展方案，即通过模型上下文协议（MCP）和代理间（A2A）通信协议，引入了一个语义代理层。这使得系统能够在实时、近实时和非实时控制层进行上下文感知的决策。部署在月球车、着陆器和月球基站中的分布式认知代理实现了无线感知协调策略，包括延迟自适应推理和带宽感知语义压缩，同时与多个MCP服务器交互，对遥测数据、移动规划和任务约束进行推理。

**Result:** 所提出的系统能够实现上下文感知的决策，支持跨实时、近实时和非实时控制层的智能操作。分布式认知代理能够执行无线感知协调策略，如延迟自适应推理和带宽感知语义压缩，并能对遥测、移动规划和任务约束进行推理。

**Conclusion:** 通过引入代理语义控制，本文成功地将Space-O-RAN扩展，使其能够满足月球无线通信系统对自主性、鲁棒性和适应性的严格要求，实现了分布式、上下文感知和自适应的智能。

> **ai_Abstract:** 本论文针对月球无线通信中Space-O-RAN的局限性，提出了一种代理语义层的扩展方案。该层利用MCP和A2A协议，使分布式认知代理能够进行上下文感知、实时决策，包括自适应推理和带宽感知压缩，这对自主月球操作至关重要。

> **摘要翻译:** 月球表面操作对无线通信系统提出了严格要求，包括自主性、抗干扰鲁棒性以及适应环境和任务驱动上下文的能力。虽然Space-O-RAN提供了一个符合3GPP标准的分布式编排模型，但其决策逻辑仅限于静态策略，且缺乏语义集成。我们提出了一种新颖的扩展方案，即引入一个由模型上下文协议（MCP）和代理间（A2A）通信协议支持的语义代理层，从而实现跨实时、近实时和非实时控制层的上下文感知决策。部署在月球车、着陆器和月球基站中的分布式认知代理实现了无线感知协调策略，包括延迟自适应推理和带宽感知语义压缩，同时与多个MCP服务器交互，对遥测数据、移动规划和任务约束进行推理。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [17] [A Survey of Data Compression Algorithms and their Applications](https://arxiv.org/abs/2506.10000)
> *数据压缩算法及其应用综述*

*Mohammad Hosseini* | **Main category: cs.IT**

**Keywords:** 数据压缩, 算法, 应用, 性能评估, 综述

**Comment:** Network Systems Lab, Simon Fraser University, 2012

> **TL;DR:** 本文综述了数据压缩算法、其性能评估、主要应用以及当前问题和最新研究方法。

**AI_Comments:** 这是一篇综述性论文，旨在全面梳理数据压缩领域的重要算法、应用、性能及最新研究进展，对于理解该领域的基础和前沿具有参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着信息存储和数据传输需求的增长，以及互联网和移动设备资源有限的出现，数据压缩在节省存储和带宽方面变得越来越重要。

**Method:** 本文对重要的数据压缩算法、其性能评估、主要应用以及当前面临的问题和最近的研究方法进行了全面讨论和综述。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在综述数据压缩算法及其应用。鉴于当前信息存储和数据传输需求的增长，以及互联网和移动设备资源限制的背景，数据压缩在节省存储和带宽方面的重要性日益凸显。该综述将深入探讨重要的数据压缩算法、它们的性能评估、主要应用，并讨论当前面临的问题和最新的研究方法。

> **摘要翻译:** 如今，随着信息存储和数据传输需求的不断增长，数据压缩变得越来越重要。数据压缩是一种用于减小数据大小的技术。当一些巨大的文件必须通过网络传输或存储在数据存储设备上，并且其大小超出数据存储容量或在网络传输中会消耗大量带宽时，这项技术非常有用。随着互联网和资源有限的移动设备的出现，数据压缩变得更加重要。它可以有效地节省存储和带宽，从而缩短下载时间。数据压缩可以通过多种技术实现。在本次调查中，我将彻底讨论一些重要的数据压缩算法、它们的性能评估、主要应用以及当今的问题和最新的研究方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [44] [HiKO: A Hierarchical Framework for Beyond-Second-Order KO Codes](https://arxiv.org/abs/2506.10121)
> *HiKO：一种超越二阶KO码的层次化框架*

*Shubham Srivastava, Adrish Banerjee* | **Main category: cs.IT**

**Keywords:** 神经纠错码, KO码, 高阶码, 分层训练, Reed-Muller码

**Comment:** 

> **TL;DR:** HiKO是一种新的分层框架，首次将KO码扩展到二阶以上，解决了高码率下的性能下降问题，并超越了Reed-Muller码。

**AI_Comments:** HiKO框架的创新之处在于其分层训练方法和针对高阶码的架构优化，成功将KO码的应用范围扩展到传统限制之外，对于提升高吞吐量通信系统的编码效率具有重要意义。这是神经纠错码领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 传统KO码在低码率下表现良好，但在高码率下性能下降，这限制了其实际部署。本文旨在将KO码扩展到二阶以上，以解决这一局限性。

**Method:** 本文引入了HiKO（Hierarchical Kronecker Operation）框架，包含三项关键创新：1. 分层训练方法，将复杂的高码率码分解为更简单的组成码以实现高效知识迁移；2. 针对Plotkin结构增强的神经网络架构，采用Dropout正则化和可学习跳跃连接；3. 渐进式解冻策略，系统地从预训练组件过渡到完全优化的集成码。

**Result:** HiKO码在各种配置下始终优于传统的Reed-Muller码，在三阶（r=3）和四阶（r=4）码上实现了显著的性能提升。分析表明，HiKO码成功地近似了香农最优高斯码本，同时保留了高效的解码特性。

**Conclusion:** HiKO是首次成功将KO码扩展到二阶以上，为高吞吐量通信系统中的神经码部署开辟了新的可能性。

> **ai_Abstract:** 本文提出HiKO（分层克罗内克运算）框架，首次将神经纠错KO码扩展到二阶以上，解决了传统KO码在高码率下的性能瓶颈。HiKO通过分层训练、增强神经网络架构和渐进式解冻策略等创新，在高阶码上显著超越了传统的Reed-Muller码，并能近似香农最优高斯码本，为高吞吐量通信系统中的神经码应用提供了新途径。

> **摘要翻译:** 本文介绍了HiKO（分层克罗内克运算），一种用于训练高码率神经纠错码的新颖框架，它使KO码能够超越二阶Reed-Muller码。据我们所知，这是首次尝试将KO码扩展到二阶以上。虽然传统的KO码在低码率（r < 2）下表现出有希望的结果，但它们在高码率下性能下降——这是实际部署的关键限制。我们的框架包含了三项关键创新：(1) 一种分层训练方法，将复杂的高码率码分解为更简单的组成码，以实现高效的知识迁移；(2) 针对Plotkin结构增强的神经网络架构，带有Dropout正则化和可学习跳跃连接；(3) 一种渐进式解冻策略，系统地从预训练组件过渡到完全优化的集成码。我们的实验表明，HiKO码在各种配置下始终优于传统的Reed-Muller码，在三阶（r = 3）和四阶（r = 4）码上实现了显著的性能改进。分析表明，HiKO码成功地近似了香农最优高斯码本，同时保留了高效的解码特性。这代表了KO码首次成功扩展到二阶以上，为高吞吐量通信系统中的神经码部署开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [69] [DeepPolar+: Breaking the BER-BLER Trade-off with Self-Attention and SMART (SNR-MAtched Redundancy Technique) decoding](https://arxiv.org/abs/2506.10166)
> *DeepPolar+：通过自注意力机制和SMART（信噪比匹配冗余技术）解码打破BER-BLER权衡*

*Shubham Srivastava, Adrish Banerjee* | **Main category: cs.IT**

**Keywords:** DeepPolar+, 神经极化码, BER-BLER权衡, 自注意力, SMART解码

**Comment:** 

> **TL;DR:** DeepPolar+通过引入自注意力机制和SMART解码技术，显著提升了DeepPolar码的误块率（BLER）性能，同时保持了优异的误码率（BER），成功打破了BER-BLER权衡，为神经极化码的实际应用提供了新的解决方案。

**AI_Comments:** 这篇论文的核心创新在于通过集成自注意力机制和SNR匹配冗余技术，成功解决了DeepPolar码在实际应用中面临的BER-BLER权衡这一关键挑战。通过对解码器架构、损失函数和解码策略的全面优化，该工作显著提升了神经极化码的实用性和鲁棒性，为下一代通信系统中的高性能错误纠正提供了重要的技术突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有的DeepPolar码虽然具有卓越的误码率（BER）性能，但其误块率（BLER）性能次优，导致了基本的BER-BLER权衡，严重限制了它们在通信系统中的实际部署和应用。

**Method:** 本文提出了DeepPolar+，一个增强的神经极化编码框架，通过以下三项关键创新来消除BER-BLER权衡：1. 注意力增强的解码器架构：利用多头自注意力机制捕获比特位置间的复杂依赖关系。2. 结构化损失函数：联合优化比特级精度和块级可靠性。3. 自适应SNR-匹配冗余技术（SMART）用于DeepPolar+码解码（DP+SMART解码器）：结合专用模型与CRC验证，以在不同信道条件下实现鲁棒性能。

**Result:** 对于(256,37)码配置，DeepPolar+在BER和BLER性能上均显著优于传统逐次抵消解码和DeepPolar。通过改进架构和优化策略，DeepPolar+实现了显著更快的收敛速度。DeepPolar+SMART变体进一步放大了这些双重改进，在错误率指标上实现了比现有方法更大的提升。

**Conclusion:** DeepPolar+有效弥合了神经极化码理论潜力与实际实现之间的差距，为下一代错误纠正系统提供了可行的发展路径。

> **ai_Abstract:** 本文提出了DeepPolar+，一个增强的神经极化编码框架，旨在解决现有DeepPolar码在误码率（BER）和误块率（BLER）之间存在的权衡问题。通过引入注意力增强的解码器架构（利用多头自注意力）、结构化损失函数（联合优化比特级精度和块级可靠性）以及自适应SNR匹配冗余技术（SMART）解码器，DeepPolar+成功地同时提升了BLER性能并保持了优异的BER特性。实验结果表明，DeepPolar+在BER和BLER上均优于传统方法和DeepPolar，并实现了更快的收敛，有效推动了神经极化码的实际应用。

> **摘要翻译:** DeepPolar码最近作为一种有前途的信道编码方法出现，与传统极化码相比，表现出卓越的误码率（BER）性能。尽管其BER特性优异，但这些码的误块率（BLER）性能次优，造成了基本的BER-BLER权衡，严重限制了它们在通信系统中的实际部署。本文介绍了DeepPolar+，一个增强的神经极化编码框架，通过同时提高BLER性能并保持DeepPolar码卓越的BER特性，系统地消除了这种BER-BLER权衡。我们的方法通过三项关键创新实现了这一突破：(1) 一种注意力增强的解码器架构，利用多头自注意力机制捕获比特位置之间的复杂依赖关系，(2) 一个结构化损失函数，联合优化比特级精度和块级可靠性，以及 (3) 一种用于DeepPolar+码解码的自适应SNR匹配冗余技术（SMART）（DP+SMART解码器），结合专用模型和CRC验证，在不同信道条件下实现鲁棒性能。对于(256,37)码配置，与传统逐次抵消解码和DeepPolar相比，DeepPolar+在BER和BLER性能上均表现出显著改进，同时通过改进的架构和优化策略实现了显著更快的收敛。DeepPolar+SMART变体进一步放大了这些双重改进，在现有方法上实现了错误率指标的显著提升。DeepPolar+有效弥合了神经极化码理论潜力与实际实现之间的差距，为下一代错误纠正系统提供了可行的途径。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [95] [Technical Report with Proofs for A Full Picture in Conformance Checking: Efficiently Summarizing All Optimal Alignments](https://arxiv.org/abs/2506.10345)
> *一致性检查的全景图：高效总结所有最优对齐的技术报告及证明*

*Philipp Bär, Moe T. Wynn, Sander J. J. Leemans* | **Main category: cs.IT**

**Keywords:** 一致性检查, 最优对齐, 证明, 技术报告

**Comment:** 

> **TL;DR:** 本技术报告为论文《一致性检查的全景图：高效总结所有最优对齐》中的主张提供了证明。

**AI_Comments:** 本报告作为一篇技术报告，其核心价值在于为另一篇论文的理论主张提供了严谨的数学或逻辑证明。它本身不提出新的方法或发现，而是为现有研究的可靠性提供支撑。因此，其重要性与所支持论文的创新性和影响力紧密相关。

<details>
  <summary>Details</summary>

**Motivation:** 为论文《一致性检查的全景图：高效总结所有最优对齐》中的主张提供证明。

**Method:** 提供证明

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本技术报告旨在为题为《一致性检查的全景图：高效总结所有最优对齐》的论文中提出的所有主张提供详尽的证明。

> **摘要翻译:** 本技术报告为论文《一致性检查的全景图：高效总结所有最优对齐》中的主张提供了证明。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [119] [Optimal Non-Adaptive Group Testing with One-Sided Error Guarantees](https://arxiv.org/abs/2506.10374)
> *最优非自适应分组测试与单侧误差保证*

*Daniel McMorrow, Jonathan Scarlett* | **Main category: cs.IT**

**Keywords:** 分组测试, 单侧误差, 非自适应, 近似恢复, 最优性

**Comment:** 

> **TL;DR:** 本文研究在单侧误差（仅假阴性或仅假阳性）下，非自适应分组测试的最优近似恢复问题。

**AI_Comments:** 这篇论文的创新点在于将分组测试的近似恢复问题细化到单侧误差保证，这在实际应用中可能提供更大的灵活性和针对性。研究结果为在特定误差约束下选择最优分组测试策略提供了理论依据，特别是证明了在某些单侧误差条件下可以达到与双侧误差相媲美的性能，这对于资源受限或特定错误类型更敏感的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 分组测试旨在通过一系列测试从大量项目中识别出稀疏的缺陷子集。传统的分组测试问题通常关注双侧误差的恢复。本文的动机在于研究在放松恢复标准，特别是只允许单侧错误（即仅假阴性或仅假阳性）的情况下，如何实现缺陷集的近似恢复。

**Method:** 本研究采用近似恢复设置，并特别考虑了两种单侧近似恢复准则：一是仅允许假阴性（即找到缺陷的子集），二是仅允许假阳性（即找到缺陷的超集）。研究方法包括证明算法的存在性以匹配最优阈值，以及提供反向界限来证明现有算法的最优性。

**Result:** 在仅允许假阴性（找到缺陷子集）的情况下，研究表明存在一种算法，其性能与最优双侧近似恢复的阈值相匹配。在仅允许假阳性（找到缺陷超集）的情况下，研究提供了一个反向界限，证明现有两种算法中较优者是最佳的。

**Conclusion:** 在单侧误差保证（仅假阴性或仅假阳性）的近似恢复设置下，非自适应分组测试可以达到或接近最优性能，表明即使在更宽松的错误分类标准下，也能实现高效的缺陷识别。

> **ai_Abstract:** 本文探讨了在单侧误差保证下的最优非自适应分组测试问题。研究在近似恢复设置中，分别考虑了仅允许假阴性（找到缺陷子集）和仅允许假阳性（找到缺陷超集）两种情况。结果显示，在仅有假阴性时，存在算法能达到与最优双侧近似恢复相同的阈值；而在仅有假阳性时，现有算法中的较优者被证明是最优的。

> **摘要翻译:** 分组测试问题在于通过一系列测试从大量项目中确定稀疏的缺陷项目子集，其中每个测试结果指示测试中是否包含至少一个缺陷项目。我们研究近似恢复设置，其中缺陷集的恢复标准被放宽以允许少量项目被错误分类。特别是，我们考虑单侧近似恢复标准，即我们只允许假阴性或只允许假阳性错误分类。在仅有假阴性（即找到缺陷子集）的情况下，我们表明存在一种算法与双侧近似恢复的最优阈值相匹配。在仅有假阳性（即找到缺陷超集）的情况下，我们提供了一个反向界限，表明现有两种算法中较优者是最佳的。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [140] [Trace duality and additive complementary pairs of additive cyclic codes over finite chain rings](https://arxiv.org/abs/2506.10381)
> *迹对偶和有限链环上加法循环码的加法互补对*

*Sanjit Bhowmick, Kuntal Deka, Alexandre Fotue Tabue, Edgar Martínez-Moro* | **Main category: cs.IT**

**Keywords:** 加法循环码, 加法互补对, 有限链环, 迹对偶, 代数结构

**Comment:** 

> **TL;DR:** 本文研究了有限交换环上加法循环码的加法互补对的代数结构，证明了其组成码为自由模，给出了形成互补对的充要条件，并构造了具有迹对偶关系的互补对。

**AI_Comments:** 本文在编码理论领域，特别是加法循环码的研究上取得了进展。其创新点在于揭示了加法互补对的结构特性（自由模），提出了判别条件，并通过具体构造建立了迹对偶关系，这对于理解和设计新型编码具有理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究有限交换环上加法循环码的加法互补对的代数结构。

**Method:** 通过对代数结构的分析、必要和充分条件的提出以及具体互补对的构造来完成研究。

**Result:** 1. 对于每个加法循环码的加法互补对，两个组成码都是自由模。2. 提出了有限交换环上加法循环码形成加法互补对的充要条件。3. 构造了有限链环上的加法循环码互补对，并证明其中一个码在置换意义下等价于另一个码的迹对偶。

**Conclusion:** 本文成功揭示了有限交换环上加法循环码加法互补对的代数结构特性，并建立了它们与迹对偶之间的关系。

> **ai_Abstract:** 本文深入探讨了有限交换环上加法循环码加法互补对的代数结构。研究发现，加法互补对中的两个码均为自由模，并给出了形成互补对的充要条件。此外，文章还构造了有限链环上的加法循环码互补对，并揭示了它们之间通过置换等价与迹对偶的关系。

> **摘要翻译:** 本文研究了有限交换环上加法循环码的加法互补对的代数结构。我们证明了对于每对加法循环码的加法互补对，其两个组成码都是自由模。此外，我们提出了有限交换环上加法循环码形成加法互补对的充要条件。最后，我们构造了有限链环上的加法循环码互补对，并证明其中一个码在置换意义下等价于另一个码的迹对偶。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [160] [Downlink CSIT under Compressed Feedback: Joint vs. Separate Source-Channel Coding](https://arxiv.org/abs/2506.10554)
> *压缩反馈下的下行链路CSIT：联合源信道编码与分离源信道编码*

*Yi Song, Tianyu Yang, Mahdi Barzegar Khalilsarai, Giuseppe Caire* | **Main category: cs.IT**

**Keywords:** 下行链路CSIT, 压缩反馈, 联合源信道编码, 分离源信道编码, 大规模MIMO

**Comment:** 

> **TL;DR:** 本文研究了大规模MIMO系统中下行链路CSIT获取的挑战，并提出了一种实用的基于JSCC的反馈方案，该方案在最小反馈延迟下性能优于现有方案，并接近理论最优。

**AI_Comments:** 本文创新性地将远程失真-速率理论应用于压缩反馈下的CSIT获取，并提出了一种在实际场景中具有低延迟且性能优越的JSCC方案。其通过充分利用信道二阶统计量来优化维度投影，并能接近理论最优性能，这对于解决大规模MIMO系统中的CSIT反馈挑战具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多用户大规模MIMO系统中，当下行/上行信道互易性不成立时（例如，在频分双工系统中），下行链路（DL）信道状态信息在发射端（CSIT）的获取是一项具有挑战性的任务。从编码角度看，用户通过DL训练获取的DL信道状态可视为信息源，需通过UL通信信道传达给基站。

**Method:** 本文首先利用经典的远程失真-速率（DR）理论，为基于JSCC和SSCC的反馈方案提供了信道估计均方误差（MSE）的理论下限。然后，针对最小反馈延迟（一个时隙）的情况，提出了一种实用的基于JSCC的反馈方案，该方案充分利用信道二阶统计量来优化特征空间中的维度投影，并分析了其在大信噪比（SNR）下的质量标度指数（QSE）行为。此外，本文还推导了在最大比传输和迫零预编码下，任何反馈方案的信道估计二阶统计量对DL数据传输遍历和速率的闭式下限。

**Result:** 通过大量的数值结果表明，本文提出的基于JSCC的方案优于已知的JSCC、SSCC基线和基于深度学习的方案，并且在实际SNR范围内能够接近最优DR方案的性能。

**Conclusion:** 本文提出了一种实用的基于JSCC的反馈方案，该方案在最小反馈延迟下表现出色，能够有效解决大规模MIMO系统中下行链路CSIT获取的挑战。

> **ai_Abstract:** 本文针对大规模MIMO系统中下行链路CSIT获取的挑战，探讨了压缩反馈下联合与分离源信道编码的性能。研究首先基于失真-速率理论推导了理论MSE下限，然后提出了一种实用的、基于JSCC的最小反馈延迟方案。该方案通过优化特征空间投影，并利用信道二阶统计量，在数值模拟中表现出优于现有基线方案的性能，并接近理论最优。

> **摘要翻译:** 下行链路（DL）信道状态信息在发射端（CSIT）的获取在多用户大规模MIMO系统中是一项具有挑战性的任务，尤其当上行/下行信道互易性不成立时（例如，在频分双工系统）。从编码角度看，用户通过DL训练获取的DL信道状态可视为信息源，必须通过UL通信信道传达给基站。源通过信道传输可以通过分离或联合源信道编码（SSCC或JSCC）来完成。在这项工作中，我们首先利用经典的远程失真-速率（DR）理论，为基于JSCC和SSCC的反馈方案提供了信道估计均方误差（MSE）的理论下限，然而这需要编码大量连续的信道状态块，因此在实践中无法使用，因为它会导致极大的反馈延迟。然后，我们关注最小（一个时隙）反馈延迟的相关情况，并提出了一种实用的基于JSCC的反馈方案，该方案充分利用信道二阶统计量来优化特征空间中的维度投影。我们分析了所提出的基于JSCC方案在大信噪比（SNR）下的质量标度指数（QSE）行为。给定任何反馈方案的信道估计二阶统计量，我们进一步推导了在最大比传输和迫零预编码下，DL数据传输遍历和速率的闭式下限。通过大量的数值结果，我们表明我们提出的基于JSCC的方案优于已知的JSCC、SSCC基线和基于深度学习的方案，并且在实际SNR范围内能够接近最优DR方案的性能。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [178] [Anomaly Detection for Sensing Security](https://arxiv.org/abs/2506.10718)
> *传感安全中的异常检测*

*Stefan Roth, Aydin Sezgin* | **Main category: cs.IT**

**Keywords:** 异常检测, 传感安全, 物理层安全, 信道状态信息, 滤波器

**Comment:** 

> **TL;DR:** 本文针对传感安全中的异常检测，提出并评估了适应于物理层安全场景的轻量级、鲁棒性强的异常检测算法，并揭示了现有对抗措施的不足。

**AI_Comments:** 本文针对物理层安全中的异常检测问题，提出了结合多种经典滤波器（移动平均、自回归、卡尔曼）的轻量级且鲁棒的解决方案，并特别强调了在实际应用中需要考虑的计算资源、环境变化和噪声影响。其通过具体的传感攻击案例研究验证了方法的有效性，同时揭示了现有防御机制的局限性，并提出了未来防御策略的改进方向，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 物理层安全领域中的多种方法（如物理层认证、传感攻击和防篡改解决方案）涉及异常检测，但这些检测方法需要满足计算轻量化、对温度和环境变化具有弹性以及对相位噪声具有鲁棒性等条件。

**Method:** 采用移动平均滤波器、自回归滤波器和卡尔曼滤波器来预测满足上述特征向量的特性。采用不同的假设检验设计来实现全向和单向异常值检测。通过一个案例研究，使用基于商用WiFi设备的各种信道特征，利用上述算法调查了一种传感攻击。

**Result:** 各种算法和信道特征的组合在攻击者进行运动检测时显示出有效性。仅利用发射功率随机化的对策不足以减轻此类攻击，如果攻击者可以访问信道状态信息（CSI）测量结果。

**Conclusion:** 现有仅利用发射功率随机化的对抗措施不足以减轻此类传感攻击，如果攻击者可以访问信道状态信息（CSI）测量结果，这表明缓解方案可能需要频率相关的随机化。

> **ai_Abstract:** 本文探讨了传感安全中物理层异常检测的需求，强调了计算效率、环境适应性和抗噪声能力的重要性。作者提出了基于移动平均、自回归和卡尔曼滤波器的方法来预测特征向量，并结合了全向和单向异常值检测的假设检验。通过一个使用商用WiFi设备进行的传感攻击案例研究，验证了所提出算法在运动检测中的有效性。研究还指出，现有仅依赖发射功率随机化的防御措施在攻击者可获取CSI时是不足的，建议未来缓解方案可能需要频率相关的随机化。

> **摘要翻译:** 物理层安全领域的各种方法都涉及异常检测，例如物理层认证、传感攻击和防篡改解决方案。根据这些方法应用的具体环境，异常检测需要具备计算轻量化、对温度和环境变化具有弹性以及对相位噪声具有鲁棒性等特点。我们采用移动平均滤波器、自回归滤波器和卡尔曼滤波器来提供满足上述条件的特征向量预测。文中采用了不同的假设检验设计，以实现全向和单向异常值检测。在一个案例研究中，我们调查了一种利用所描述的算法和基于商用WiFi设备的各种信道特征的传感攻击。结果表明，各种算法和信道特征的组合在攻击者进行运动检测时显示出有效性。研究还表明，如果攻击者能够获取信道状态信息（CSI）测量结果，仅利用发射功率随机化的对策不足以减轻此类攻击，这暗示缓解方案可能需要频率相关的随机化。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [12] [CarbonSet: A Dataset to Analyze Trends and Benchmark the Sustainability of CPUs and GPUs](https://arxiv.org/abs/2506.10373)
> *CarbonSet：一个用于分析CPU和GPU可持续性趋势并进行基准测试的数据集*

*Jiajun Hu, Chetan Choppali Sudarshan, Vidya A. Chhabria, Aman Arora* | **Main category: cs.AR**

**Keywords:** CarbonSet, 可持续性, 碳排放, CPU, GPU, 人工智能

**Comment:** 

> **TL;DR:** 该论文推出了CarbonSet数据集，用于分析CPU和GPU的可持续性，并指出由于AI需求激增，现代处理器的碳排放量大幅增加，设计仍不具可持续性。

**AI_Comments:** 这项研究通过构建CarbonSet数据集，首次全面整合了过去十年CPU和GPU的可持续性和性能指标，填补了芯片生命周期可持续性分析的空白，具有显著的创新性。在AI热潮导致芯片碳排放急剧增加的背景下，该研究提供了一个关键的基准工具，对推动行业可持续发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 芯片生产迅速扩张导致碳排放显著增加，对环境可持续性构成严重关切。现有研究缺乏对涵盖整个芯片生命周期的可持续性趋势的整体分析。

**Method:** 本文提出了CarbonSet数据集，这是一个综合性数据集，整合了过去十年CPU和GPU的可持续性与性能指标。利用该数据集，对旗舰处理器的可持续性趋势进行了详细分析。

**Result:** 现代处理器设计尚不具备可持续性，过去三年由于AI需求的激增，总碳排放量增加了50多倍。功耗效率仍然是一个重大问题，先进工艺节点也带来了有效摊销大幅增加的制造碳排放的新挑战。

**Conclusion:** 当前处理器设计在可持续性方面存在显著不足，尤其是面对AI驱动的需求激增，碳排放量急剧上升，迫切需要改进设计以实现更好的可持续性，并有效摊销制造碳排放。

> **ai_Abstract:** 本文介绍了CarbonSet数据集，该数据集整合了过去十年CPU和GPU的可持续性和性能指标，旨在弥补芯片生命周期可持续性分析的不足。利用该数据集，研究发现现代处理器设计尚不具备可持续性，尤其在AI需求驱动下，近三年总碳排放量增长超过50倍。论文强调功耗效率和先进工艺制造碳排放是未来可持续芯片设计的关键挑战。

> **摘要翻译:** 多年来，芯片行业不断开发高性能处理器，以满足各种应用日益增长的需求。然而，芯片生产的迅速扩张显著增加了碳排放，引发了对环境可持续性的严重担忧。尽管研究人员此前已在系统和处理器层面建立了碳足迹（CFP）模型，但仍缺乏对涵盖整个芯片生命周期的可持续性趋势的整体分析。本文提出了CarbonSet，这是一个综合性数据集，整合了过去十年CPU和GPU的可持续性和性能指标。CarbonSet旨在为下一代处理器的设计提供基准和评估。利用该数据集，我们对过去十年旗舰处理器的可持续性趋势进行了详细分析。本文进一步强调，现代处理器尚未实现可持续设计，由于人工智能热潮驱动的需求激增，过去三年总碳排放量增加了50多倍。功耗效率仍然是一个重大问题，而先进工艺节点带来了新的挑战，需要有效摊销大幅增加的制造碳排放。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [39] [EasyDRAM: An FPGA-based Infrastructure for Fast and Accurate End-to-End Evaluation of Emerging DRAM Techniques](https://arxiv.org/abs/2506.10441)
> *EasyDRAM：一种用于快速准确评估新兴DRAM技术的基于FPGA的基础设施*

*Oğuzhan Canpolat, Ataberk Olgun, David Novo, Oğuz Ergin, Onur Mutlu* | **Main category: cs.AR**

**Keywords:** FPGA, DRAM, 内存系统, 评估, 时间尺度

**Comment:** Extended version of our publication at DSN 2025

> **TL;DR:** EasyDRAM是一个基于FPGA的框架，用于快速准确地评估新兴DRAM技术，它通过允许C++编程和创新的时间尺度技术解决了现有平台对硬件专业知识的要求以及建模准确性问题。

**AI_Comments:** EasyDRAM的创新之处在于它显著降低了DRAM技术评估的门槛，通过允许使用高级语言（C++）进行编程，使得非硬件专家也能参与到DRAM系统设计中。其引入的“时间尺度”技术巧妙地解决了FPGA平台在模拟真实处理器-DRAM频率差异方面的难题，提高了评估的准确性。作为一个开源项目，它有望加速内存系统领域的研发进程。

<details>
  <summary>Details</summary>

**Motivation:** 评估DRAM技术具有挑战性，因为它们需要跨计算堆栈多层修改。现有的基于FPGA的平台存在两个主要缺点：1) 需要深厚的硬件描述语言专业知识，限制了可访问性；2) 未能准确建模现代计算系统。

**Method:** EasyDRAM通过两个关键思想克服了现有平台的缺点：1) 允许开发者使用高级语言（C++）实现DRAM技术，无需硬件描述语言专业知识，并在可编程内存控制器中执行软件定义的内存系统设计。2) 通过解耦处理器-DRAM接口并使用名为“时间尺度”的新颖技术推进系统状态，忠实地捕捉建模系统的时序行为，解决了准确建模现代系统的挑战。

**Result:** EasyDRAM能够对真实DRAM芯片上的DRAM技术进行快速准确的端到端评估，克服了现有FPGA平台的局限性，并实现了对现代系统准确的建模。

**Conclusion:** 作者相信并希望EasyDRAM将使内存系统设计中的创新理念迅速实现。EasyDRAM的实现已开源以帮助未来的研究。

> **ai_Abstract:** 本文介绍了EasyDRAM，一个基于FPGA的框架，旨在解决现有DRAM技术评估平台在易用性和准确性方面的不足。EasyDRAM通过支持C++编程简化了DRAM技术实现，并利用“时间尺度”技术解决了处理器与DRAM频率差异造成的建模挑战，从而实现了对真实DRAM芯片上新兴DRAM技术的快速、准确的端到端评估。该框架的开源旨在促进内存系统设计的创新。

> **摘要翻译:** DRAM是现代计算系统的关键组成部分。最近的工作提出了许多技术（我们称之为DRAM技术）来增强基于DRAM的系统的吞吐量、可靠性和计算能力（例如，DRAM内批量数据复制）。评估DRAM技术的系统范围效益具有挑战性，因为它们通常需要对计算堆栈的多个层进行修改。先前的工作提出了基于FPGA的平台，用于在真实DRAM芯片上快速进行DRAM技术的端到端评估。不幸的是，现有平台在两个主要方面存在不足：(1) 它们需要深厚的硬件描述语言专业知识，限制了可访问性；(2) 它们并非旨在准确建模现代计算系统。
我们引入了EasyDRAM，一个基于FPGA的框架，用于在真实DRAM芯片上快速准确地对DRAM技术进行端到端评估。EasyDRAM通过两个关键思想克服了现有基于FPGA平台的主要缺点。首先，EasyDRAM通过允许开发人员使用高级语言（C++）实现DRAM技术，消除了对硬件描述语言专业知识的需求。在运行时，EasyDRAM在可编程内存控制器中执行软件定义的内存系统设计。其次，EasyDRAM解决了准确建模现代系统的一个基本挑战：真实处理器通常以比DRAM更高的时钟频率运行，这种差异在FPGA平台上很难复制。EasyDRAM通过解耦处理器-DRAM接口并使用我们称为时间尺度的新颖技术推进系统状态来解决这一挑战，该技术忠实地捕获了建模系统的时序行为。
我们相信并希望EasyDRAM将使内存系统设计中的创新理念迅速实现。为了帮助未来的研究，EasyDRAM的实现已在https://github.com/CMU-SAFARI/EasyDRAM 开源。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [64] [Towards Zero-Stall Matrix Multiplication on Energy-Efficient RISC-V Clusters for Machine Learning Acceleration](https://arxiv.org/abs/2506.10921)
> *面向机器学习加速的节能RISC-V集群上的零停顿矩阵乘法*

*Luca Colagrande, Lorenzo Leone, Maximilian Coco, Andrei Deaconeasa, Luca Benini* | **Main category: cs.AR**

**Keywords:** 机器学习, RISC-V, 矩阵乘法, 微架构, 能效

**Comment:** 7 pages, 5 figures, 2 tables. Accepted at ISLPED 2025

> **TL;DR:** 本文提出了一种优化的微架构，通过“零开销循环嵌套”和“零冲突内存子系统”消除了RISC-V机器学习加速器集群中的控制流和内存访问低效问题，实现了接近理想的利用率和显著的性能及能效提升，同时保持了完全可编程性。

**AI_Comments:** 本文的创新之处在于提出了两种具体的微架构优化技术：“零开销循环嵌套”和“零冲突内存子系统”，有效解决了RISC-V集群在机器学习加速中常见的控制流和内存访问瓶颈。其重要性在于，在不显著增加复杂性的前提下，显著提升了通用可编程RISC-V平台的性能和能效，使其能够与专用加速器相媲美，同时提供了更广泛的负载支持，这对于边缘AI和灵活的ML部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习工作负载日益增长的计算需求推动了机器学习加速器的设计，旨在实现效率和灵活性的最佳权衡。现有的基于RISC-V处理器的机器学习加速器集群在控制流（循环处理）和内存访问方面存在效率低下问题，需要进行微架构优化以消除这些低效，同时避免大幅增加处理器复杂性。

**Method:** 本文提出了一种低开销的优化微架构，该架构几乎完全消除了控制流和内存访问的低效，同时保留了可编程性。具体方法包括引入“零开销循环嵌套”以消除控制开销，以及利用新型双缓冲感知互连的“零冲突内存子系统”以消除L1内存中的bank冲突。

**Result:** 通过这些增强，实现了96.1%到99.4%的接近理想的利用率，相比基线SoA RISC-V集群，性能提升了11%，能效提升了8%。与专门的SoA加速器相比，利用率和性能相当，能效仅有12%的差异，同时提供了完全可编程的通用解决方案，支持更广泛的工作负载。

**Conclusion:** 本文提出的微架构显著提高了RISC-V集群上机器学习加速的效率和性能，提供了一个高度可编程且多功能的解决方案，其表现可与专用加速器相媲美，同时支持更广泛的机器学习工作负载。

> **ai_Abstract:** 本文提出了一种针对RISC-V集群上机器学习加速的优化微架构，旨在解决现有方案中控制流和内存访问导致的效率低下问题。通过引入“零开销循环嵌套”和“零冲突内存子系统”（利用双缓冲感知互连），该设计显著提升了矩阵乘法的效率。实验结果表明，该方案实现了接近理想的利用率（96.1%-99.4%），性能和能效分别比基线RISC-V集群提升了11%和8%，并且在保持完全可编程性的同时，性能与专用加速器相当，能效差距仅为12%，支持更广泛的机器学习任务。

> **摘要翻译:** 机器学习（ML）工作负载日益增长的计算需求推动了ML加速器的设计，旨在实现效率和灵活性之间的最佳权衡。一种广泛探索的灵活ML加速器架构基于轻量级指令处理器集群，这些处理器共享多bank的L1内存，并通过专门的指令扩展增强，用于关键的ML相关计算，例如矩阵乘法（matmul）。然而，指令扩展应与微架构优化相结合，以消除由于控制流（循环处理）和内存访问引起的低效，同时不大幅增加处理器复杂性。在最先进（SoA）的基于RISC-V处理器的ML加速器集群的基础上，我们提出了一种低开销的优化微架构，该架构几乎完全消除了这些低效，同时保留了可编程性。我们引入了“零开销循环嵌套”以消除控制开销，以及利用新型双缓冲感知互连的“零冲突内存子系统”以消除L1内存中的bank冲突。通过这些增强，我们实现了96.1%至99.4%的接近理想的利用率，相比基线SoA RISC-V集群，性能提升了11%，能效提升了8%。我们展示了与专用SoA加速器相当的利用率和性能，能效仅有12%的差异，同时提供了完全可编程的通用解决方案，支持显著更广泛的工作负载。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [91] [MARS: Processing-In-Memory Acceleration of Raw Signal Genome Analysis Inside the Storage Subsystem](https://arxiv.org/abs/2506.10931)
> *MARS：存储子系统内部原始信号基因组分析的内存内加速*

*Melina Soysal, Konstantina Koliogeorgi, Can Firtina, Nika Mansouri Ghiasi, Rakesh Nadig, Haiyu Mayo, Geraldo F. Oliveira, Yu Liang, Klea Zambaku, Mohammad Sadrosadati, Onur Mutlu* | **Main category: cs.AR**

**Keywords:** 原始信号基因组分析, 内存内计算, 存储子系统, 数据移动, 硬件加速

**Comment:** 

> **TL;DR:** MARS是一个以存储为中心的系统，通过内存内计算和软硬件协同设计，在存储子系统内部加速原始信号基因组分析，显著提高了性能并降低了能耗，解决了数据移动瓶颈。

**AI_Comments:** MARS的创新点在于将计算推向数据源，即存储子系统内部，有效缓解了大数据量基因组分析中的I/O瓶颈。其软硬件协同设计方法，特别是对RSGA流程的修改和内存内计算范式的应用，展示了在处理海量生物数据方面的巨大潜力。这种方法对于未来实时、高通量基因组分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 原始信号基因组分析（RSGA）虽然有前景，但当前软件RSGA难以匹配原始信号生成的速度，硬件加速又导致I/O数据移动成为新的性能和能耗瓶颈。因此，需要设计一个高性能、高能效的RSGA系统，以缓解数据移动瓶颈并提供强大的加速能力。

**Method:** MARS通过新颖的软硬件协同设计方法加速RSGA。首先，通过两种过滤机制和量化方案修改RSGA流程，以降低硬件需求并优化存储内执行。其次，利用近内存处理（Processing-Near-Memory）和使用内存处理（Processing-Using-Memory）范式，直接在存储内部加速RSGA步骤。最后，MARS协调所有步骤的执行，以充分利用存储内并行性并最小化数据移动。

**Result:** MARS在不同数据集上，平均比基于Basecalling的软件和硬件加速的最新读长映射流水线分别快93倍和40倍，同时能耗分别降低427倍和72倍。

**Conclusion:** MARS成功地将原始信号基因组分析的性能和能效瓶颈从计算转移到I/O数据移动，并通过在存储子系统内部进行处理，显著提高了RSGA的性能和能效。

> **ai_Abstract:** MARS是一个针对原始信号基因组分析（RSGA）的存储中心系统，旨在解决当前软件和硬件加速方案中数据移动导致的性能和能耗瓶颈。它通过新颖的软硬件协同设计，在存储子系统内部利用内存内计算（Processing-Near-Memory和Processing-Using-Memory）加速RSGA流程，并通过优化过滤和量化方案来减少硬件需求和数据移动。实验结果表明，MARS相比现有方法在性能和能耗方面均有显著提升。

> **摘要翻译:** 原始信号基因组分析（RSGA）已成为一种通过直接分析原始电信号实现实时基因组分析的有前景的方法。然而，测序技术的快速发展使得基于软件的RSGA越来越难以匹配原始信号生成的吞吐量。本文表明，虽然硬件加速技术可以显著加速RSGA，但大量的基因组数据将性能和能耗瓶颈从计算转移到I/O数据移动。随着测序吞吐量的增加，I/O开销成为运行时间和能耗的主要贡献者。因此，需要设计一个高性能、高能效的RSGA系统，既能缓解数据移动瓶颈，又能提供强大的加速能力。我们提出了MARS，一个以存储为中心的系统，它利用现代存储系统内部的异构资源（例如，存储内部DRAM、存储控制器、闪存芯片）及其大容量存储，以面积高效和低成本的方式解决RSGA的数据移动和计算开销。MARS通过一种新颖的软硬件协同设计方法加速RSGA。首先，MARS通过两种过滤机制和一种量化方案修改RSGA流程，从而降低硬件需求并优化存储内执行。其次，MARS通过利用近内存处理（Processing-Near-Memory）和使用内存处理（Processing-Using-Memory）范式，直接在存储内部加速RSGA步骤。第三，MARS协调所有步骤的执行，以充分利用存储内并行性并最小化数据移动。我们的评估表明，MARS在不同数据集上，平均比基于Basecalling的软件和硬件加速的最新读长映射流水线分别快93倍和40倍，同时能耗分别降低427倍和72倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [13] [Resilience through Automated Adaptive Configuration for Distribution and Replication](https://arxiv.org/abs/2506.10248)
> *通过自动化自适应配置实现分布式和复制系统的弹性*

*Scott D. Stoller, Balaji Jayasankar, Yanhong A. Liu* | **Main category: cs.DC**

**Keywords:** 弹性, 自动化配置, 分布式系统, 复制, 故障恢复

**Comment:** 

> **TL;DR:** 本文提出一个自动化框架，通过优化软件组件在异构硬件上的自适应分布和复制，增强复杂系统在故障下的弹性。

**AI_Comments:** 这篇论文的创新点在于其自动化框架，特别是模型查找算法，它不仅能确定初始的弹性配置，还能动态生成重配置策略以应对故障，这对于复杂分布式系统的可靠性至关重要。其引入的基于新颖等价关系的商约简优化，有望显著提高算法的效率。

<details>
  <summary>Details</summary>

**Motivation:** 为了使复杂系统在面对故障时仍能保持弹性，需要一个强大的自动化框架来优化互依赖软件组件在异构硬件组件上的自适应分布和复制。

**Method:** 本文提出了一个基于状态空间探索的模型查找算法，该算法能够根据系统模型和弹性要求，确定初始的弹性配置并生成应对故障和恢复的重配置策略。该算法包含了基于状态之间新颖等价关系的商约简等优化技术。

**Result:** 研究人员成功地将该框架的原型实现在一个自动驾驶系统模型上，并获得了实验结果。

**Conclusion:** 该自动化框架通过智能地确定初始弹性配置和动态生成重配置策略，有效提升了复杂系统在面对故障时的弹性。

> **ai_Abstract:** 本文介绍了一个自动化框架，旨在通过对互依赖软件组件在异构硬件上的优化自适应分布和复制，提升复杂系统在故障下的弹性。该框架包含一个模型查找算法，该算法能够确定系统的初始弹性配置，并生成应对故障和恢复的重配置策略。此算法利用状态空间探索和如商约简等优化技术。研究通过将原型应用于自动驾驶系统模型验证了其有效性。

> **摘要翻译:** 本文提出了一个强大的自动化框架，通过优化互依赖软件组件在具有广泛不同能力的异构硬件组件上的自适应分布和复制，使复杂系统在故障下具有弹性。一个配置指定了软件如何分布和复制：哪些软件组件在每台计算机上运行，哪些软件组件需要复制，使用哪种复制协议等。我们提出了一种算法，给定一个系统模型和弹性要求，该算法（1）确定系统初始的弹性配置，以及（2）生成一个重配置策略，该策略确定响应故障和恢复时要执行的重配置操作。这种模型查找算法基于状态空间探索，并结合了强大的优化，包括基于状态之间新颖等价关系的商约简。我们展示了将我们框架的原型实现成功应用于自动驾驶系统模型的实验结果。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [40] [Is Sparse Matrix Reordering Effective for Sparse Matrix-Vector Multiplication?](https://arxiv.org/abs/2506.10356)
> *稀疏矩阵重排序对稀疏矩阵-向量乘法有效吗？*

*Omid Asudeh, Sina Mahdipour Saravani, Gerald Sabin, Fabrice Rastello, P Sadayappan* | **Main category: cs.DC**

**Keywords:** 稀疏矩阵, 矩阵重排序, 稀疏矩阵-向量乘法, 多核CPU, 性能优化

**Comment:** 

> **TL;DR:** 本研究评估了稀疏矩阵重排序在不同多核CPU平台上对稀疏矩阵-向量乘法性能的影响。

**AI_Comments:** 该论文着重于评估稀疏矩阵重排序这一经典优化技术在现代多核CPU架构上的实际效果。其重要性在于，尽管重排序技术已存在，但在不同硬件平台和并行执行环境下其具体性能表现和影响因素仍需深入研究。论文关注了测量方法和负载不平衡等实践问题，这对于理解和应用此类优化至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏矩阵重排序可以通过优化非零元素模式来减少总数据移动并改善负载平衡，从而显著提升性能。本研究的动机是评估这种性能提升在不同CPU上、针对不同重排序策略（包括顺序和并行执行）的变化情况。

**Method:** 本研究通过在不同多核CPU平台上，针对不同的重排序策略（包括顺序和并行执行），评估了稀疏矩阵重排序对稀疏矩阵-向量乘法性能的影响。研究方法涵盖了适当的测量方法、不同重排序策略之间的比较、机器之间的一致性以及负载不平衡的影响。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究评估了稀疏矩阵重排序对多核CPU上稀疏矩阵-向量乘法性能的影响。重排序能通过优化数据模式来减少数据移动和改善负载平衡，从而提升性能。论文探讨了这些性能增益在不同CPU和不同重排序策略（包括顺序和并行）下的变化，并讨论了测量方法、策略比较、跨机器一致性及负载不平衡等问题。

> **摘要翻译:** 这项工作评估了稀疏矩阵重排序对不同多核CPU平台上稀疏矩阵-向量乘法性能的影响。重排序可以通过优化非零元素模式来减少总数据移动并改善负载平衡，从而显著提升性能。我们研究了这些增益在不同CPU上、针对不同重排序策略（重点关注顺序和并行执行）的变化情况。我们解决了多个方面的问题，包括适当的测量方法、不同类型重排序策略之间的比较、机器之间的一致性以及负载不平衡的影响。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [65] [HPCTransCompile: An AI Compiler Generated Dataset for High-Performance CUDA Transpilation and LLM Preliminary Exploration](https://arxiv.org/abs/2506.10401)
> *HPCTransCompile：一个用于高性能CUDA转译和LLM初步探索的AI编译器生成数据集*

*Jiaqi Lv, Xufeng He, Yanchen Liu, Xu Dai, Yang Hu, Shouyi Yin* | **Main category: cs.DC**

**Keywords:** CUDA转译, 大型语言模型, AI编译器, 数据集生成, 性能可移植性

**Comment:** 

> **TL;DR:** 该研究提出了HPCTransCompile框架，通过AI编译器和自动优化技术生成高质量的CUDA代码转译数据集，以解决现有LLM在高性能CUDA转译方面性能不佳的问题，并改善了LLM在CUDA转译上的表现。

**AI_Comments:** 该论文的创新点在于提出了一个结合AI编译器和自动优化技术来生成高质量CUDA转译数据集的框架，有效解决了LLM训练数据稀缺的问题。通过引入图基数据增强和专门的评估基准HPCTransEval，该研究为高性能代码转译领域LLM的应用开辟了新的道路，对于促进CUDA生态系统内的跨平台兼容性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习的快速发展导致模型参数和计算需求呈指数级增长，NVIDIA GPU和CUDA生态系统在并行计算领域占据主导地位。然而，将CUDA代码转译到其他平台面临挑战，现有方法存在工作负载覆盖率和通用性限制，且开发成本高。尽管LLM在代码任务中显示出潜力，但由于缺乏高质量的训练数据集，其在高性能CUDA转译方面的表现不佳。

**Method:** 提出了一种新颖的框架，利用AI编译器和自动优化技术生成高性能CUDA及其对应平台代码对。该框架通过基于图的数据增强方法进一步增强，并引入了HPCTransEval基准来评估LLM在CUDA转译上的性能。

**Result:** 以CUDA到CPU转译为例，对主流LLM进行的实验表明，该框架显著改善了CUDA转译，突出了LLM解决CUDA生态系统内兼容性挑战的潜力。

**Conclusion:** 通过提出HPCTransCompile框架并生成高质量数据集，本研究显著提升了LLM在高性能CUDA转译方面的表现，验证了LLM解决CUDA生态系统兼容性问题的巨大潜力。

> **ai_Abstract:** 本论文提出了HPCTransCompile框架，旨在解决大型语言模型（LLM）在高性能CUDA代码转译中因缺乏高质量训练数据而表现不佳的问题。该框架利用AI编译器和自动优化技术，生成高性能CUDA及其对应平台的代码对，并通过图基数据增强方法进行强化。此外，论文还引入了HPCTransEval基准来评估LLM的转译性能。实验结果表明，该框架显著提升了LLM在CUDA转译上的能力，展示了LLM在解决CUDA生态系统兼容性挑战方面的巨大潜力。

> **摘要翻译:** 深度学习的快速发展推动了模型参数和计算需求的指数级增长。NVIDIA GPU及其基于CUDA的软件生态系统为并行计算提供了强大的支持，显著缓解了计算瓶颈。同时，由于用户编程习惯的培养和GPU的高性能，CUDA生态系统在并行软件领域建立了主导地位。这种主导地位要求其他硬件平台能够支持CUDA软件的性能可移植性。然而，由于并行编程范式和硬件架构的差异，将CUDA代码转译到其他平台带来了重大挑战。现有方法依赖于语言扩展、领域特定语言（DSL）或编译器，但在工作负载覆盖率和通用性方面面临限制。此外，这些方法通常会产生高昂的开发成本。最近，大型语言模型（LLM）在各种垂直领域，尤其是在代码相关任务中，展现出非凡的潜力。然而，现有LLM在CUDA转译方面的性能，特别是对于高性能代码，仍然不尽如人意。造成这一限制的主要原因在于缺乏高质量的训练数据集。为了应对这些挑战，我们提出了一种新颖的框架，利用AI编译器和自动优化技术生成高性能CUDA及其对应平台代码对。我们通过基于图的数据增强方法进一步增强了该框架，并引入了HPCTransEval，一个用于评估LLM在CUDA转译上性能的基准。我们以CUDA到CPU转译作为案例研究，对主流LLM进行了实验。结果表明，我们的框架显著改善了CUDA转译，突出了LLM解决CUDA生态系统内兼容性挑战的潜力。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [92] [Federated Learning within Global Energy Budget over Heterogeneous Edge Accelerators](https://arxiv.org/abs/2506.10413)
> *异构边缘加速器全局能耗预算下的联邦学习*

*Roopkatha Banerjee, Tejus Chandrashekar, Ananth Eswar, Yogesh Simmhan* | **Main category: cs.DC**

**Keywords:** 联邦学习, 能耗预算, 客户端选择, 异构边缘, 优化

**Comment:** Preprint of paper to appear in the proceedings of the 31st
  International European Conference on Parallel and Distributed Computing
  (EuroPar)

> **TL;DR:** 本文提出了FedJoule框架，通过新颖的客户端选择优化问题和双层整数线性规划，在全局能耗预算下最大化联邦学习的模型精度并减少训练时间，相较于SOTA方法在精度和时间上分别提升15%和48%。

**AI_Comments:** 该论文的创新点在于首次将全局能耗预算引入联邦学习的客户端选择优化中，并提出了一种新颖的双层ILP方法来解决这一复杂问题。通过结合近似Shapley值和能耗-时间预测模型，该框架在实际应用中具有很高的实用价值，尤其是在资源受限的边缘设备上实现可持续AI具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在分布式客户端协作训练中面临能量效率和模型精度优化的挑战，尤其是在设备和数据异构性下。此外，尚未探索通过全局能耗预算实现可持续AI联邦学习。

**Method:** 提出了一种新的联邦学习客户端选择优化问题，旨在全局能耗限制内最大化模型精度并减少训练时间。通过独特的双层整数线性规划（ILP）公式解决，该公式利用近似Shapley值和能量-时间预测模型来高效求解。该方法被命名为FedJoule框架。

**Result:** FedJoule框架在不同能耗预算、非独立同分布（non-IID）数据和真实实验配置下，比现有最佳（SOTA）和简单基线方法取得了更高的训练精度，在精度上提升15%，在时间上提升48%。结果强调了该方法在联邦学习环境中实现能耗与性能之间可行权衡的有效性。

**Conclusion:** 本研究提出的方法能有效平衡联邦学习环境中的能耗与性能，在全局能耗预算下显著提升模型精度并缩短训练时间。

> **ai_Abstract:** 本文提出了一种名为FedJoule的新型联邦学习框架，旨在解决在异构边缘加速器上，如何在全局能耗预算内优化模型精度和训练时间的问题。通过制定一个创新的客户端选择优化问题，并利用双层整数线性规划、近似Shapley值和能量-时间预测模型进行求解，FedJoule框架在实验中表现出优于现有SOTA方法的性能，实现了在精度上15%的提升和在训练时间上48%的缩短，有效平衡了能耗与性能。

> **摘要翻译:** 联邦学习（FL）实现了分布式客户端之间的协作模型训练，同时保留了数据隐私。然而，在设备和数据异构性下，优化能量效率和模型精度仍然是一个挑战。此外，尚未探索通过全局能耗预算实现联邦学习的可持续AI。我们提出了一种新颖的联邦学习客户端选择优化问题，旨在总体能量限制内最大化模型精度并减少训练时间。我们通过独特的双层整数线性规划（ILP）公式解决了这个问题，该公式利用近似Shapley值和能量-时间预测模型来高效求解。我们的FedJoule框架在不同的能量预算、非独立同分布（non-IID）分布和真实实验配置下，比现有最佳（SOTA）和简单基线方法取得了更高的训练精度，在精度上分别提升15%和48%。结果强调了我们方法在联邦学习环境中实现能耗与性能之间可行权衡的有效性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [117] [Automating Multi-Tenancy Performance Evaluation on Edge Compute Nodes](https://arxiv.org/abs/2506.10461)
> *自动化边缘计算节点上的多租户性能评估*

*Joanna Georgiou, Moysis Symeonides, George Pallis, Marios D. Dikaiakos* | **Main category: cs.DC**

**Keywords:** 边缘计算, 多租户, 性能评估, 自动化, 基准测试

**Comment:** 2025 IEEE International Conference on Edge Computing and
  Communications (EDGE)

> **TL;DR:** 该论文介绍了一个自动化基准测试框架，用于简化边缘环境中多租户性能的分析。

**AI_Comments:** 该论文提出了一种实用的自动化解决方案，解决了边缘计算多租户环境性能评估的痛点。其创新性在于将监控、多种工作负载和自动化流程整合到一个框架中，显著降低了评估复杂性。该框架的公开可用性也增强了其潜在影响和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 边缘计算中的多租户会因资源争用导致性能下降，而评估其影响需要大量手动配置、部署和测试，耗时耗力。

**Method:** 引入了一个自动化基准测试框架，包含内置监控堆栈，并集成了流行的基准测试工作负载（如流分析、数据库操作、机器学习应用、组件压力测试）。通过案例驱动分析提供见解。

**Result:** 框架能够简化边缘环境中多租户性能的分析，并提供了关于多租户对不同硬件配置和多样化工作负载的边缘环境影响的有价值见解。

**Conclusion:** 开发了一个自动化框架，用于简化边缘环境中多租户性能的分析，其实现及实验工作负载均已公开。

> **ai_Abstract:** 鉴于边缘计算中多租户引起的性能下降评估过程耗时耗力，本文提出了一个自动化的基准测试框架。该框架集成了监控和多种主流工作负载，旨在简化对边缘环境中多租户性能的分析。通过案例研究，该框架提供了关于多租户在不同硬件配置和工作负载下对边缘环境影响的宝贵见解。其实现和实验工作负载均已公开。

> **摘要翻译:** 边缘计算作为云计算的一种有前景的替代方案而出现，在物联网设备和云之间的路径中部署了可扩展的计算资源和服务。由于虚拟化技术可以应用于边缘计算节点，管理员可以在多个用户之间共享其边缘基础设施，提供所谓的多租户。尽管多租户不可避免，但它引发了对边缘计算中资源争用导致的安全性担忧和性能下降。为此，管理员需要部署具有非对抗性配置文件的服务，并探索工作负载共存场景以提高性能和降低能耗。然而，实现这一点需要大量的配置、部署、迭代测试和分析，这是一个劳动密集型且耗时的过程。为了解决这一挑战，我们引入了一个自动化基准测试框架，旨在简化边缘环境中多租户性能的分析。我们的框架包括内置监控堆栈，并集成了广泛使用的基准测试工作负载，例如流分析、数据库操作、机器学习应用和基于组件的压力测试。我们进行了案例驱动分析，并对多租户对具有不同硬件配置和多样化工作负载的边缘环境的影响提供了有价值的见解。最后，我们框架的实现以及用于实验的容器化工作负载均已公开可用。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [138] [TD-Pipe: Temporally-Disaggregated Pipeline Parallelism Architecture for High-Throughput LLM Inference](https://arxiv.org/abs/2506.10470)
> *TD-Pipe：面向高吞吐量LLM推理的时序解耦流水线并行架构*

*Hongbin Zhang, Taosheng Wei, Zhenyi Zheng, Jiangsu Du, Zhiguang Chen, Yutong Lu* | **Main category: cs.DC**

**Keywords:** LLM推理, 流水线并行, 吞吐量, 时序解耦, TD-Pipe

**Comment:** 

> **TL;DR:** TD-Pipe提出了一种时序解耦的流水线并行架构，通过分离LLM推理的预填充和解码阶段，并引入多种优化策略，显著提升了LLM推理的吞吐量。

**AI_Comments:** TD-Pipe的创新之处在于提出了时序解耦的流水线并行架构，这是一种新颖的思路，有效解决了LLM推理中预填充和解码阶段的固有矛盾。通过在时间维度上解耦并结合多种精细化的调度和优化策略，该方法显著提升了LLM推理的效率和吞吐量，对于资源受限或需要高吞吐量的LLM部署具有重要意义。其提出的具体优化方法，如AI-based greedy prefill和inter-batch work stealing，也显示了对实际系统挑战的深刻理解。

<details>
  <summary>Details</summary>

**Motivation:** 由于模型规模的持续增长，流水线并行在面向吞吐量的LLM推理中显示出巨大潜力，但预填充和解码阶段不平衡的工作负载以及复杂的数据依赖性导致大量流水线气泡，从而严重降低了性能。

**Method:** 本文提出了TD-Pipe，其核心思想是时序解耦的流水线并行架构。该架构在时间维度上解耦了预填充和解码阶段，以消除阶段切换引起的流水线气泡。TD-Pipe还提供了以下解决方案：1. 使用分层控制器结构解耦调度和执行，以更好地协调设备。2. 采用基于AI的贪婪预填充方法，通过预测输出长度和模拟内存使用来积极执行更多预填充。3. 采用批间工作窃取方法，动态平衡不同批次间的解码阶段工作负载。4. 采用时空强度比较方法，确定从解码到预填充的最佳切换点。

**Result:** 实验表明，TD-Pipe在仅有PCIe互连的GPU节点上，将LLM推理的吞吐量比现有张量并行方法提高了1.91倍，比现有流水线并行方法提高了2.73倍。

**Conclusion:** TD-Pipe通过其时序解耦的流水线并行架构和一系列优化策略，有效解决了LLM推理中流水线气泡导致的性能下降问题，显著提升了LLM推理的吞吐量。

> **ai_Abstract:** TD-Pipe提出了一种时序解耦的流水线并行架构，旨在解决大型语言模型(LLM)推理中预填充和解码阶段不平衡工作负载导致的流水线气泡和性能下降问题。该架构通过在时间维度上分离预填充和解码阶段来消除气泡，并引入了分层控制器、基于AI的贪婪预填充、批间工作窃取以及时空强度比较等优化策略。实验结果表明，TD-Pipe显著提升了LLM推理的吞吐量，相比现有张量并行和流水线并行方法分别提高了1.91倍和2.73倍。

> **摘要翻译:** 随着模型规模的持续增长，流水线并行在面向吞吐量的LLM推理中显示出巨大潜力，因为它对通信的需求较低。然而，预填充和解码阶段不平衡的流水线工作负载和复杂的数据依赖性导致大量流水线气泡，并进一步严重降低了性能。为了更好地利用流水线并行实现高吞吐量LLM推理，我们提出了TD-Pipe，其关键思想在于时序解耦的流水线并行架构。具体来说，该架构在时间维度上解耦了预填充和解码阶段，从而消除了由阶段切换引起的流水线气泡。TD-Pipe识别了利用这种新架构的潜在问题并提供了解决方案。首先，使用分层控制器结构，通过解耦调度和执行来更好地协调流水线并行中的设备。其次，基于AI的贪婪预填充方法通过预测输出长度和模拟内存使用，积极执行更多预填充。第三，批间工作窃取方法动态平衡不同批次间的解码阶段工作负载以减少气泡。第四，时空强度比较方法通过比较计算强度降低导致的性能下降与阶段切换气泡导致的性能下降来确定从解码到预填充的最佳切换。大量实验表明，TD-Pipe在仅有PCIe互连的GPU节点上，将LLM推理的吞吐量比现有张量并行方法提高了1.91倍，比现有流水线并行方法提高了2.73倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [158] [HP2C-DT: High-Precision High-Performance Computer-enabled Digital Twin](https://arxiv.org/abs/2506.10523)
> *HP2C-DT：高精度高性能计算机赋能的数字孪生*

*E. Iraola, M. García-Lorenzo, F. Lordan-Gomis, F. Rossi, E. Prieto-Araujo, R. M. Badia* | **Main category: cs.DC**

**Keywords:** 数字孪生, 高性能计算, 计算连续体, 资源管理, 实时系统

**Comment:** 15 pages, 5 figures. Submitted to Future Generation Computing Systems
  journal

> **TL;DR:** HP2C-DT是一种新的数字孪生架构，将高性能计算整合到计算连续体中，动态分配任务以提高响应速度和效率，并在电网用例中展示了显著性能提升。

**AI_Comments:** HP2C-DT的创新之处在于将高性能计算（HPC）从传统的离线模拟角色转变为数字孪生工作流的活跃组成部分，并实现计算连续体中的动态资源分配。这对于需要高精度和实时响应的复杂物理系统监控与控制具有重要意义。其提出的框架在实际用例中展示了显著的性能提升，弥补了现有云和边缘方案的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有数字孪生架构在实时响应与高计算需求之间难以平衡，云端方案存在延迟和资源限制，边缘方案缺乏复杂模拟能力。

**Method:** 提出HP2C-DT参考架构，将高性能计算（HPC）整合到计算连续体中，使其成为数字孪生工作流的活跃部分，根据紧急性和计算需求动态地将任务分配给边缘、云或HPC资源。并引入HP2C-DT框架作为工作实现，使用COMPSs进行无缝工作负载分配。

**Result:** 在电网用例中，通过边缘数据聚合将通信带宽降低了一个数量级；通过动态卸载将响应时间缩短了2倍；在实际资源范围内，计算密集型工作流保持了接近理想的强扩展性。

**Conclusion:** 这种HPC驱动的方法能够将数字孪生推出现有局限，使其更智能、更快、更善于处理现实世界的复杂性。

> **ai_Abstract:** 本文提出了HP2C-DT（高精度高性能计算机赋能的数字孪生）架构，旨在解决数字孪生在实时响应和高计算需求之间的平衡挑战。该架构将高性能计算（HPC）整合到计算连续体中，并能根据任务需求动态分配资源。通过HP2C-DT框架在电网用例中的验证，展示了其在降低通信带宽、缩短响应时间以及保持计算密集型工作流扩展性方面的显著优势，证明了HPC驱动方法能提升数字孪生处理复杂性的能力。

> **摘要翻译:** 数字孪生正在改变我们监控、分析和控制物理系统的方式，但设计兼顾实时响应性和高计算需求的架构仍然是一个挑战。基于云的解决方案常受限于延迟和资源，而基于边缘的方法则缺乏进行复杂模拟和数据驱动优化的处理能力。为解决此问题，我们提出了高精度高性能计算机赋能的数字孪生（HP2C-DT）参考架构，该架构将高性能计算（HPC）集成到计算连续体中。与传统仅将HPC用于离线模拟的设置不同，HP2C-DT使其成为数字孪生工作流的活跃部分，根据紧急性和计算需求动态地将任务分配给边缘、云或HPC资源。此外，为了弥合理论与实践之间的差距，我们引入了HP2C-DT框架，这是一个可工作的实现，它使用COMPSs在不同基础设施之间无缝分配工作负载。我们在一个电网用例中对其进行了测试，展示了它如何通过边缘侧数据聚合将通信带宽降低一个数量级，通过动态卸载将响应时间提高2倍，并在实际资源范围内，对于计算密集型工作流保持接近理想的强扩展性。这些结果表明，HPC驱动的方法如何能将数字孪生推出现有局限，使其更智能、更快，并能更好地处理现实世界的复杂性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [177] [GPU-Accelerated Distributed QAOA on Large-scale HPC Ecosystems](https://arxiv.org/abs/2506.10531)
> *GPU加速的大规模HPC生态系统上的分布式QAOA*

*Zhihao Xu, Srikar Chundury, Seongmin Kim, Amir Shehata, Xinyi Li, Ang Li, Tengfei Luo, Frank Mueller, In-Saeng Suh* | **Main category: cs.DC**

**Keywords:** DQAOA, GPU加速, 量子计算, 高性能计算, 组合优化

**Comment:** 

> **TL;DR:** 该论文通过高级问题分解和GPU加速的量子模拟，显著提升了大规模HPC系统上分布式量子近似优化算法（DQAOA）的性能和可扩展性，实现了高达10倍的加速。

**AI_Comments:** 这项工作在将量子算法扩展到大规模问题方面迈出了重要一步，特别是在高性能计算（HPC）环境中利用GPU加速，这对于混合量子-经典计算的发展至关重要。其创新点在于结合了先进的问题分解、消息传递并行以及GPU加速，有效提升了DQAOA的性能和可扩展性。这项研究的重要性在于展示了GPU在加速量子模拟中的潜力，并为未来HPC-量子计算系统的集成奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算在加速解决复杂组合优化问题方面具有巨大潜力，而分布式量子近似优化算法（DQAOA）旨在利用现有量子计算技术和高性能计算（HPC）系统解决高维度、密集型问题。

**Method:** 本研究通过在Frontier CPU/GPU超级计算机上使用高级问题分解和基于消息传递的并行执行，提高了DQAOA的可扩展性和效率。该方法通过在经典和量子资源之间分配大型问题实例，确保了高效的量子-经典工作负载管理。

**Result:** 实验结果表明，增强的分解策略和GPU加速的量子模拟显著提高了DQAOA的性能，比基于CPU的模拟实现了高达10倍的加速。这一进展使得大型问题实例具有更好的可扩展性。

**Conclusion:** 本研究支持将GPU系统实际部署到混合量子-经典应用中。同时，论文还强调了利用量子框架（QFw）进行持续集成的工作，以支持未来的HPC-量子计算系统。

> **ai_Abstract:** 本论文旨在提升分布式量子近似优化算法（DQAOA）在处理高维组合优化问题时的可扩展性和效率。研究人员通过在Frontier CPU/GPU超级计算机上实施先进的问题分解和GPU加速的并行量子模拟，显著优化了DQAOA的性能。实验结果表明，与CPU相比，GPU加速带来了高达10倍的性能提升，这对于大规模混合量子-经典应用中GPU系统的实际部署具有重要意义。

> **摘要翻译:** 量子计算在加速解决复杂组合优化问题方面具有巨大潜力。分布式量子近似优化算法（DQAOA）利用当前的量子计算技术和高性能计算（HPC）系统来解决高维度、密集型问题。在这项工作中，我们通过在Frontier CPU/GPU超级计算机上使用高级问题分解和并行消息传递执行，提高了DQAOA的可扩展性和效率。我们的方法通过在经典和量子资源之间分配大型问题实例，确保了高效的量子-经典工作负载管理。实验结果表明，增强的分解策略和GPU加速的量子模拟显著提高了DQAOA的性能，比基于CPU的模拟实现了高达10倍的加速。这一进展使得大型问题实例具有更好的可扩展性，支持将GPU系统实际部署到混合量子-经典应用中。我们还强调了利用量子框架（QFw）进行的持续集成工作，以支持未来的HPC-量子计算系统。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [191] [6G Infrastructures for Edge AI: An Analytical Perspective](https://arxiv.org/abs/2506.10570)
> *面向边缘AI的6G基础设施：分析视角*

*Kurt Horvath, Shpresa Tuda, Blerta Idrizi, Stojan Kitanov, Fisnik Doko, Dragi Kimovski* | **Main category: cs.DC**

**Keywords:** 6G, 边缘AI, 5G性能, 延迟, 网络基础设施

**Comment:** 

> **TL;DR:** 当前5G网络在支持边缘AI应用方面存在延迟限制，本文通过实证评估揭示了这些不足，并提出了构建满足下一代AI需求的6G生态系统的建议。

**AI_Comments:** 本文通过对5G网络在支持边缘AI应用方面的实际性能进行实证分析，明确指出了当前技术的局限性，并前瞻性地提出了6G作为解决方案。其创新之处在于结合了实证数据来支撑对未来网络需求（尤其是低延迟）的论证，为6G网络的设计和优化提供了具体的方向。对于关注边缘AI和未来通信网络发展的研究人员和工程师而言，具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于当前5G网络在实际部署中存在性能差距，尤其是在延迟方面无法满足AI驱动的边缘应用需求，因此需要研究如何实现一个为AI应用优化的强大且可扩展的6G生态系统。

**Method:** 本文对中欧的5G网络基础设施进行了实证评估，测量了不同地理区域的延迟。在此基础上，提出了弥合现有5G性能与下一代AI应用要求之间差距的建议。

**Result:** 实证评估显示，中欧5G网络的延迟范围为61毫秒到110毫秒，这些值超出延迟敏感型AI应用要求约270%，揭示了当前部署的显著不足。

**Conclusion:** 当前的5G网络在支持边缘AI应用方面存在显著的性能（尤其是延迟）不足。为了满足下一代AI应用的需求，需要发展6G基础设施并采纳本文提出的建议。

> **ai_Abstract:** 本文探讨了5G网络在支持AI驱动的边缘应用时面临的性能限制，特别是在延迟方面。通过对中欧5G基础设施的实证评估，发现其延迟远超AI应用需求。鉴于此，文章强调了发展6G基础设施的必要性，并提出了一系列建议以弥合当前5G性能与未来AI应用需求之间的差距。

> **摘要翻译:** 人工智能（AI）和物联网的融合加速了分布式、网络敏感型应用的发展，这些应用要求超低延迟、高吞吐量和实时处理能力。尽管5G网络是一个重要的技术里程碑，但其支持AI驱动边缘应用的能力仍受限于实际部署中观察到的性能差距。本文解决了这些局限性，并强调了实现为AI应用优化的强大且可扩展的6G生态系统所需的关键进展。此外，我们对中欧的5G网络基础设施进行了实证评估，在不同相邻地理区域的延迟测量范围为61毫秒至110毫秒。这些值超出延迟关键型AI应用要求约270%，揭示了当前部署的显著不足。基于这些发现，我们提出了一系列建议，以弥合现有5G性能与下一代AI应用要求之间的差距。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [205] [Graph-based Gossiping for Communication Efficiency in Decentralized Federated Learning](https://arxiv.org/abs/2506.10607)
> *基于图的八卦传播机制在去中心化联邦学习中提升通信效率*

*Huong Nguyen, Hong-Tri Nguyen, Praveen Kumar Donta, Susanna Pirttikangas, Lauri Lovén* | **Main category: cs.DC**

**Keywords:** 去中心化联邦学习, 通信效率, 图传播, 最小生成树, 图着色

**Comment:** Accepted at 34th International Conference on Computer Communications
  and Networks (ICCCN 2025)

> **TL;DR:** 本文提出一种基于图的八卦传播机制，利用最小生成树和图着色优化去中心化联邦学习中的通信效率，显著减少带宽和传输时间，并在真实物理设备上验证了其有效性。

**AI_Comments:** 本文的创新点在于提出了一个基于图的八卦传播机制，并结合最小生成树和图着色来优化去中心化联邦学习中的通信效率。其重要性在于解决了去中心化联邦学习在实际大规模部署中面临的通信瓶颈问题，并通过在真实物理设备上进行实验验证，增强了结果的可靠性和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习中的中心化服务器存在瓶颈和单点故障风险。去中心化联邦学习虽解决了此问题，但在大规模部署中引入通信效率低下。现有解决方案未能有效模拟真实分布式环境，导致评估不可靠和实际应用受限。

**Method:** 提出了一种基于图的八卦传播机制。该机制具体利用最小生成树和图着色来优化网络结构和调度，以实现在各种网络拓扑和消息容量下的高效通信。该方法在真实物理路由器和设备上配置和管理子网络，以紧密模拟真实世界的分布式设置。

**Result:** 实验结果表明，该方法显著改善了通信效率，兼容不同拓扑和数据大小。与朴素泛洪广播方法相比，带宽和传输时间分别减少了约8倍和4.4倍。

**Conclusion:** 该研究提出了一种新颖的基于图的八卦传播机制，通过优化网络结构和调度，有效解决了去中心化联邦学习中的通信效率问题，并在真实世界环境中展示了其优越的性能和实用性。

> **ai_Abstract:** 本文针对去中心化联邦学习中存在的通信效率低下和现有方案缺乏真实环境模拟的问题，提出了一种基于图的八卦传播机制。该机制通过应用最小生成树和图着色技术优化网络结构和调度，旨在提升不同网络拓扑和消息容量下的通信效率。研究在真实物理设备上进行实验验证，结果显示该方法与传统泛洪广播相比，能显著降低带宽和传输时间，提高了去中心化联邦学习的实用性和性能。

> **摘要翻译:** 联邦学习已成为一种隐私保护技术，用于在异构分布式孤岛间进行协作模型训练。然而，它对单一中央服务器的依赖引入了潜在的瓶颈和单点故障风险。去中心化服务器，通常被称为去中心化学习，通过在网络中的节点间分发服务器角色来解决此问题。这种纯粹去中心化带来一个缺点，即它引入了通信效率低下，这源于大规模设置中消息交换的增加。然而，现有提出的解决方案在实验中往往未能模拟真实的分布式和去中心化环境，导致性能评估不可靠和实际应用受限。认识到先前工作的不足，本研究调查了模型大小与网络延迟之间的相关性，这是优化去中心化学习通信的关键因素。我们提出了一种基于图的八卦传播机制，其中，具体利用最小生成树和图着色来优化网络结构和调度，以实现在各种网络拓扑和消息容量下的高效通信。我们的方法在真实物理路由器和设备上配置和管理子网络，并紧密模拟真实世界的分布式设置。实验结果表明，与朴素泛洪广播方法相比，我们的方法显著改善了通信，兼容不同的拓扑和数据大小，分别将带宽和传输时间减少了约8倍和4.4倍。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [222] [Deployment of Containerized Simulations in an API-Driven Distributed Infrastructure](https://arxiv.org/abs/2506.10642)
> *API驱动分布式基础设施中容器化仿真的部署*

*Tim Kraus, Axel Sauer, Ingo Feldner* | **Main category: cs.DC**

**Keywords:** 容器化仿真, API驱动, 分布式基础设施, 虚拟原型, 嵌入式系统

**Comment:** 8 pages, 5 figures, Published in DVCon Europe 2024

> **TL;DR:** 本文提出了SUNRISE，一个API驱动的分布式基础设施，用于统一和简化虚拟原型解决方案的使用，促进对各种仿真技术的访问，并通过利用去中心化计算资源和开放API来增强协作。

**AI_Comments:** 本文的创新之处在于提出了一个API驱动的分布式基础设施SUNRISE，旨在统一和简化对多种虚拟原型解决方案的访问和使用。这对于硬件/软件协同设计领域，尤其是在面对日益多样化的仿真工具时，具有重要意义。通过利用容器化和分布式资源，它有望提高仿真效率和团队协作能力。然而，摘要中并未提及具体的实现细节、性能评估或实际应用案例，这限制了对其实际效果的判断。

<details>
  <summary>Details</summary>

**Motivation:** 嵌入式系统市场日益动态化，使得虚拟原型成为硬件/软件协同设计不可或缺的工具。然而，现有解决方案的多样性导致了使用上的复杂性，需要一个统一的方法来利用这些工具并促进合作。

**Method:** 本文提出了SUNRISE基础设施，它通过提供统一的方法来利用虚拟原型解决方案，促进对各种仿真技术的访问，并通过利用去中心化计算资源部署仿真工作负载和定义开放API来增强协作。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了SUNRISE，一个旨在应对嵌入式系统虚拟原型日益增长复杂性的基础设施。SUNRISE通过提供一个统一的API驱动平台，使得用户能够更便捷地访问和利用各种虚拟原型解决方案，并能通过分布式计算资源实现仿真任务的部署，从而增强了不同仿真技术间的互操作性和协作效率。

> **摘要翻译:** 嵌入式系统日益动态化的市场使得虚拟原型成为硬件/软件协同设计不可或缺的工具。该方法论的广泛接受催生了多种多样的解决方案：从开源的纯控制台模拟器到功能强大的商业仿真工具。在这项工作中，我们提出了SUNRISE，一个基础设施，旨在为用户提供一种统一的方法来利用虚拟原型解决方案，促进对各种仿真技术的访问，并通过利用去中心化计算资源部署仿真工作负载和定义开放API来增强合作。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [237] [Towards Sustainable Computing: Exploring Energy Consumption Efficiency of Alternative Configurations and Workloads in an Open Source Messaging System](https://arxiv.org/abs/2506.10693)
> *迈向可持续计算：探索开源消息系统中替代配置和工作负载的能耗效率*

*Maria Voreakou, George Kousiouris, Mara Nikolaidou* | **Main category: cs.DC**

**Keywords:** 能耗效率, 消息系统, RabbitMQ, 可持续计算, 基准测试

**Comment:** 2025 20th Annual System of Systems Engineering Conference (SoSE)

> **TL;DR:** 本研究通过实验性基准测试，探讨了开源消息系统RabbitMQ在不同配置和工作负载下的能耗效率，并发现架构选择可将功耗降低高达31%。

**AI_Comments:** 这项研究的创新之处在于其专注于消息系统的能耗效率，这是一个在可持续计算背景下日益重要但常被忽视的领域。通过对RabbitMQ进行实证基准测试，并提供公开数据集，该论文为开发者和研究人员提供了宝贵的工具和见解，以构建更节能的分布式系统。其重要性在于直接量化了架构选择对能耗的影响，为优化系统设计提供了明确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 当前大规模计算基础设施（特别是云环境中的集中式系统）的能耗日益成为关键问题。随着微服务架构和物联网的发展，消息系统已成为现代计算基础设施不可或缺的一部分，承载着大量应用的工作负载。因此，探索消息系统的能耗效率至关重要。

**Method:** 本文描述了一个实验过程，对开源消息框架RabbitMQ进行了基于能耗的基准测试。研究了涉及不同工作负载、配置和消息系统用例的系统、所需组件和设置场景。从能耗角度对不同消息速率和消费者数量下的替代架构进行了调查和比较。

**Result:** 研究量化了架构选择的差异，结果显示功耗可降低高达31%。由此产生的数据集已公开发布。

**Conclusion:** 架构选择对消息系统的能耗效率有显著影响，通过优化配置和工作负载，可以实现显著的能耗降低。公开的数据集有助于架构比较和基于能耗的成本建模。

> **ai_Abstract:** 本研究旨在通过实验性基准测试，探索开源消息系统RabbitMQ在不同配置和工作负载下的能耗效率。研究分析了替代架构在不同消息速率和消费者数量下的能耗表现，并量化了架构选择对功耗的影响，发现最高可实现31%的功耗降低。相关数据集已公开发布，可用于架构比较和能耗成本建模。

> **摘要翻译:** 当前大规模计算基础设施中的能耗正成为一个关键问题，尤其是在对云环境等集中式系统的需求不断增长的情况下。随着微服务架构和物联网的进步，消息系统已成为现代计算基础设施不可或缺的主流组成部分，在大多数应用程序中承担着重要的工作负载。在本文中，我们描述了一个实验过程，旨在探索针对RabbitMQ（主要的开源消息框架之一）的基于能耗的基准测试。文中描述了所涉及的系统、所需组件和设置场景，其中包括测试中不同的工作负载和配置以及消息系统用例。从能耗角度对不同消息速率和消费者数量下的替代架构进行了调查和比较。架构选择的差异已被量化，并且可以导致高达31%的功耗降低。生成的数据集已公开发布，因此可以证明有助于架构比较、基于能耗的成本建模等。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [249] [The Impact of Partial Computations on the Red-Blue Pebble Game](https://arxiv.org/abs/2506.10854)
> *部分计算对红蓝鹅卵石游戏的影响*

*Pál András Papp, Aleksandros Sobczyk, A. N. Yzelman* | **Main category: cs.DC**

**Keywords:** 红蓝鹅卵石游戏, 部分计算, I/O成本, NP难, 内存模型

**Comment:** Published in the 37th ACM Symposium on Parallelism in Algorithms and
  Architectures (SPAA 2025)

> **TL;DR:** 本文研究了带有部分计算步骤的红蓝鹅卵石游戏（PRBP），发现它能显著降低I/O成本，但寻找最优解和近似解仍然是NP难问题。

**AI_Comments:** 本文创新性地将部分计算的概念引入红蓝鹅卵石游戏，使其I/O成本模型更符合实际计算场景，解决了传统RBP模型过于理想化的问题。其重要性在于为分析具有增量聚合特性的算法提供了更精确的理论工具。尽管论文揭示了寻找最优解的NP难性，这限制了在所有情况下的实际应用，但它为理解和设计I/O高效算法提供了新的视角和下限分析方法。

<details>
  <summary>Details</summary>

**Motivation:** 传统的红蓝鹅卵石游戏（RBP）假设操作的所有输入必须同时在快速内存中，这与许多实际计算中输入可以逐个聚合的情况不符。本文的动机是扩展RBP以包含部分计算步骤，从而提供一个更现实的I/O成本模型。

**Method:** 本文建立了部分计算红蓝鹅卵石游戏（PRBP）的基本属性，并将其与原始RBP进行比较。通过简单示例展示了部分计算的优势，并讨论了如何将RBP中用于推导I/O下限的S-分区工具应用于PRBP模型。这些新工具被用来建立一些重要计算任务的I/O成本下限。

**Result:** 允许部分计算可以降低最优I/O成本，最高可达线性因子。然而，在特定有向无环图（DAG）中决定部分计算是否能降低成本是NP难问题。此外，PRBP中的最优成本仍然难以在任何合理因子内近似。

**Conclusion:** 部分计算红蓝鹅卵石游戏（PRBP）提供了一个更现实的I/O成本模型，能够显著降低I/O成本。尽管它在实际应用中具有优势，但寻找最优解和近似解仍然是计算上困难的问题（NP难）。

> **ai_Abstract:** 本文引入并研究了部分计算红蓝鹅卵石游戏（PRBP），这是对传统红蓝鹅卵石游戏（RBP）的扩展。与RBP要求所有输入同时在内存中不同，PRBP允许输入逐个聚合，从而更贴近实际计算的I/O特性。研究表明，PRBP能够显著降低I/O成本，最高可达线性因子。然而，确定部分计算是否降低成本以及近似最优成本在PRBP中都被证明是NP难问题。论文还讨论了如何将RBP中的S-分区工具应用于PRBP以推导I/O下限。

> **摘要翻译:** 我们研究了红蓝鹅卵石游戏（RBP）的一个扩展，即包含部分计算步骤，这受到了Sobczyk最近工作的启发。虽然原始RBP假设一个操作的所有输入必须同时在快速内存中，但在许多具体的计算中，输入可以逐个聚合成最终的输出值。这些部分计算步骤可以实现I/O成本大大降低的鹅卵石策略，并且在分步聚合可行的情况下，这种扩展的红蓝鹅卵石游戏提供了一个更现实的成本模型。
我们建立了这种部分计算红蓝鹅卵石游戏（PRBP）的基本属性，并将其与原始RBP进行比较。我们首先给出了一些简单的例子，其中允许部分计算可以降低最优I/O成本。研究还表明，成本可以因此降低高达线性因子，但通常情况下，判断在特定DAG中部分计算是否允许更小的成本是NP难问题。然后，我们讨论了S-分区（RBP中推导I/O下限的关键工具）如何适应PRBP模型。这些新工具随后被用于建立一些著名计算任务的I/O成本下限。最后，我们还改编了RBP中的一个难解性结果，表明PRBP中的最优成本仍然无法在任何合理因子内进行近似。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [260] [Adaptive Job Scheduling in Quantum Clouds Using Reinforcement Learning](https://arxiv.org/abs/2506.10889)
> *量子云中基于强化学习的自适应作业调度*

*Waylon Luo, Jiapeng Zhao, Tong Zhan, Qiang Guan* | **Main category: cs.DC**

**Keywords:** 量子调度, 强化学习, 分布式量子计算, 量子云, 噪声感知

**Comment:** 10 pages, 6 figures, ICPP 2025

> **TL;DR:** 本文提出一个模拟工具，用于在有噪声的分布式量子系统中进行量子作业调度，并比较了包括强化学习在内的多种调度技术，发现并行化、噪声感知的调度能提高吞吐量。

**AI_Comments:** 本文的创新之处在于提出了一个模拟工具来解决分布式量子计算中的作业调度挑战，特别是在考虑噪声和资源限制的情况下。引入强化学习作为调度策略之一，展现了其在复杂、动态量子环境中的潜力。这项工作对于未来量子云基础设施的实用化和扩展性具有重要意义，因为它直接解决了当前量子硬件的局限性，并为优化量子工作负载提供了实用的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有量子系统面临量子比特限制、相干时间短和高错误率等瓶颈，阻碍了大型复杂电路的执行。量子算法发展超越硬件能力，导致计算难以扩展，硬件性能不一致和量子噪声也损害系统稳定性。因此，需要在这些约束下优化量子工作负载的调度和资源协调，尤其是在错误环境中跨多个QPU高效划分和执行大型电路。

**Method:** 本文引入一个基于仿真的工具，支持通过实时经典通道连接的网络化QPU上的分布式调度和并发执行量子作业。该工具模拟电路分解，以处理超出单个QPU限制的工作负载，并通过处理器间通信实现并行执行。在模拟环境中，比较了四种不同的调度技术，其中一种是基于强化学习的模型，并根据运行时效率、保真度保留和通信成本等指标进行评估。

**Result:** 分析揭示了每种方法固有的权衡，并强调了并行化、噪声感知的调度如何能显著提高分布式量子基础设施中的计算吞吐量。

**Conclusion:** 通过并行化和噪声感知调度，可以有效提高分布式量子基础设施中的计算吞吐量，但需权衡不同调度方法的优劣。

> **ai_Abstract:** 本文针对当前量子系统在处理大型复杂电路时面临的量子比特限制、相干时间短和高错误率等挑战，提出了一种基于仿真的工具。该工具旨在优化分布式量子云中的作业调度和并发执行，通过模拟电路分解和处理器间通信实现并行化。研究比较了包括强化学习在内的四种调度策略，并评估了它们在运行时效率、保真度和通信成本方面的表现，结果表明并行化和噪声感知的调度能有效提升分布式量子计算的吞吐量。

> **摘要翻译:** 现有量子系统面临关键瓶颈，包括有限的量子比特数、短暂的相干时间以及对错误的高度敏感性——所有这些都阻碍了大型复杂电路的执行。量子算法的进步已经超越了现有量子硬件的能力，使得有效扩展计算变得困难。此外，硬件性能的不一致性和普遍存在的量子噪声损害了系统稳定性和计算精度。为了在这些约束下优化量子工作负载，战略性的任务调度和资源协调至关重要。这些方法必须旨在加速处理、保持操作保真度并减少分布式设置中固有的通信负担。该领域中一个持续存在的挑战是如何在多个量子处理器（QPU）上高效地划分和执行大型电路，尤其是在易出错的环境中。为此，我们引入了一个基于仿真的工具，支持通过实时经典通道连接的网络化QPU上的分布式调度和并发执行量子作业。该工具模拟了超出单个QPU限制的工作负载的电路分解，允许通过处理器间通信进行并行执行。使用此仿真环境，我们比较了四种不同的调度技术——其中包括一种由强化学习启发的模型。这些策略根据多项指标进行评估，包括运行时效率、保真度保留和通信成本。我们的分析强调了每种方法固有的权衡，并突出了并行化、噪声感知的调度如何能有意义地提高分布式量子基础设施中的计算吞吐量。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [16] [Inverted Classroom in der Einführungsveranstaltung Programmierung](https://arxiv.org/abs/2506.10057)
> *编程入门课程中的翻转课堂*

*Ulrich von Zadow, Natalie Kiesler* | **Main category: cs.CY**

**Keywords:** 翻转课堂, 编程教育, 教学评估, 高等教育, 挂科率

**Comment:** 10 pages, in German language, 4 figures, MINT Symposium 2025

> **TL;DR:** 由于高挂科率，纽伦堡理工学院在2024/25冬季学期对计算机科学入门编程课程试行了翻转课堂教学模式，通过数据收集评估发现总体效果积极但仍有改进空间。

**AI_Comments:** 该研究通过实际教学案例验证了翻转课堂在解决传统教学模式高挂科率问题上的潜力，其创新在于将翻转课堂引入编程入门课程，并辅以多维度的数据收集进行评估。研究的价值在于为高等教育编程教学改革提供了实践经验和数据支持。然而，抽象中未详细说明具体的改进机会，也未提及是否与传统教学模式进行对比，这可能是其局限性。

<details>
  <summary>Details</summary>

**Motivation:** 由于纽伦堡理工学院计算机科学专业学生在2023/24冬季学期的入门编程课程中挂科率高，因此需要探索新的教学概念来改善学习效果。

**Method:** 研究团队在2024/25冬季学期对一个学生群体实施了基于翻转课堂的实验性教学概念。学生需通过文献阅读和激活式教学方法进行预习。课程期间通过教学分析调查、两次问卷调查和教学日记等方式收集数据，以了解学生的学习方法和行为。

**Result:** 该教学概念总体上获得了积极评价，但同时也发现许多具体的改进机会。文章记录了问卷调查结果。

**Conclusion:** 翻转课堂概念在编程入门课程中显示出积极效果，但仍有详细的改进空间，文章将讨论其影响。

> **ai_Abstract:** 本研究针对纽伦堡理工学院计算机科学入门编程课程高挂科率的问题，在2024/25冬季学期试行了翻转课堂教学模式。该模式要求学生课前通过文献和主动学习方式进行准备，并通过多种数据收集方法（教学分析调查、问卷、教学日记）评估其效果。结果显示该概念总体积极，但仍有提升空间，文章将详细记录问卷调查结果并讨论其启示。

> **摘要翻译:** 传统上，纽伦堡理工学院计算机科学学生的入门编程课程采用讲座和练习相结合的形式。由于2023/24冬季学期的挂科率较高，2024/25冬季学期对一个班级实施了基于翻转课堂的实验性教学概念。学生需要通过文献工作和激活式教学方法进行自我准备。课程期间通过一系列数据收集（即教学分析调查、两次问卷调查和教学日记）来深入了解学生的学习方法和行为。该概念总体上获得了积极评价，尽管也发现了许多详细的改进机会。本文记录了问卷调查的结果并讨论了其影响。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [43] [Data-Centric Safety and Ethical Measures for Data and AI Governance](https://arxiv.org/abs/2506.10217)
> *以数据为中心的数据和人工智能治理安全与伦理措施*

*Srija Chakraborty* | **Main category: cs.CY**

**Keywords:** 数据安全, AI治理, 伦理措施, 数据集设计, 风险管理

**Comment:** Paper accepted and presented at the AAAI 2025 Workshop on Datasets
  and Evaluators of AI Safety https://sites.google.com/view/datasafe25/home

> **TL;DR:** 本研究提出了一个负责任的数据集设计框架，旨在增强人工智能模型的安全性，并通过解决数据质量、不安全和不道德的数据内容问题来降低人工智能滥用的风险。

**AI_Comments:** 本文的创新之处在于其明确提出并专注于“以数据为中心”的安全与伦理措施，并为此设计了一个涵盖AI和数据集整个生命周期的框架。这对于解决AI模型潜在的“双重用途”问题以及提升AI的可信赖性具有重要意义。该框架的领域无关性使其具有广泛的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据集在赋予AI基础模型高级能力方面发挥着关键作用，但负责任的数据集设计以及确保以数据为中心的安全和伦理实践却受到了较少关注，这可能导致AI滥用风险。

**Method:** 本研究提出了一个负责任的数据集设计框架，该框架涵盖了AI和数据集生命周期的各个阶段。

**Result:** 该框架旨在增强安全措施，并减少因低质量、不安全和不道德数据内容导致AI滥用的风险。它具有领域无关性，适用于各种应用，并能促进数据集创建、使用和共享中的负责任实践，从而有助于红队测试、最小化风险并增加对AI模型的信任。

**Conclusion:** 所提出的负责任的数据集设计框架能够促进数据集创建、使用和共享中的负责任实践，从而减少AI滥用风险并增加对AI模型的信任。

> **ai_Abstract:** 本研究提出一个以数据为中心的负责任数据集设计框架，旨在解决当前AI发展中数据集安全与伦理实践受关注不足的问题。该框架涵盖AI和数据集生命周期的多个阶段，旨在通过解决低质量、不安全和不道德的数据内容，增强AI模型的安全性并降低其滥用风险。该框架具有领域无关性，适用于多种应用，并能促进负责任的数据集创建、使用和共享，从而有助于风险最小化和提升AI信任度。

> **摘要翻译:** 数据集在赋予人工智能（AI）基础模型高级能力方面发挥着关键作用，这些模型可以适应各种下游任务。这些下游应用可能带来有益和有害的能力——导致双重用途的AI基础模型，并有各种技术和监管方法来监控和管理这些风险。然而，尽管数据集起着至关重要的作用，但负责任的数据集设计和确保以数据为中心的安全和伦理实践却受到了较少关注。在本研究中，我们提出了一个负责任的数据集设计框架，该框架涵盖了AI和数据集生命周期的各个阶段，以增强安全措施并减少因低质量、不安全和不道德数据内容导致AI滥用的风险。该框架是领域无关的，适用于各种应用，并能促进数据集创建、使用和共享中的负责任实践，以促进红队测试，最小化风险，并增加对AI模型的信任。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [68] [Collective Bargaining in the Information Economy Can Address AI-Driven Power Concentration](https://arxiv.org/abs/2506.10272)
> *信息经济中的集体谈判可以解决人工智能驱动的权力集中问题*

*Nicholas Vincent, Matthew Prewitt, Hanlin Li* | **Main category: cs.CY**

**Keywords:** 集体谈判, 信息经济, 人工智能, 权力集中, 市场失灵

**Comment:** 

> **TL;DR:** AI可能导致信息市场失灵和权力集中，集体谈判是解决之道。

**AI_Comments:** 本文创新性地将传统劳工领域的“集体谈判”概念引入到信息经济和AI领域，以应对AI发展带来的新型权力集中和市场失灵问题。其重要性在于提出了一个具体的、多维度的解决方案，结合了技术和政策层面的干预，旨在保护信息生产者权益并促进AI的健康可持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 解决AI系统对信息生产者造成的不公平条款和不可持续回报，以及AI加剧的信息市场失灵和资本集中，甚至信息公域的“生态崩溃”。

**Method:** 提出通过信息生产者的集体谈判来重构信息市场；具体行动包括研究人员和开发者建立技术机制（如联邦数据管理工具、可解释的数据价值评估），以及引入监管和政策干预来支持可信的数据中介组织。

**Result:** 通过集体谈判，可以创造市场摩擦和一致的激励机制，实现一个亲社会、可持续的AI未来，避免信息市场失灵和权力集中。

**Conclusion:** 信息经济中的集体谈判是实现亲社会、可持续AI未来的关键，需要技术和政策干预来支持信息生产者的联盟化方法。

> **ai_Abstract:** 本立场文件主张，为应对人工智能可能加剧的信息市场失灵、资本集中及信息公域的“生态崩溃”，迫切需要重构人工智能系统的信息市场。核心解决方案是信息生产者（如记者、研究人员、创意专业人士）与人工智能产品开发者进行集体谈判，以确保合理回报和可持续发展。文章提出，集体谈判能创造促进亲社会、可持续AI未来的市场激励，并通过技术机制（如联邦数据管理、数据价值评估）和政策干预（如支持数据中介组织）来支持这种联盟化的方法。

> **摘要翻译:** 这篇立场文件认为，迫切需要重构用于人工智能系统的信息市场。具体而言，信息商品生产者（如记者、研究人员和创意专业人士）需要能够与人工智能产品开发者进行集体谈判，以获得合理的条款和对其贡献的信息价值的可持续回报。我们认为，如果这些主要信息生产者缺乏市场协调或集体谈判，人工智能将加剧大规模的“信息市场失灵”，这不仅会导致资本的不良集中，还会导致信息公域的潜在“生态崩溃”。另一方面，信息经济中的集体谈判可以创造市场摩擦和一致的激励机制，这对于一个亲社会、可持续的人工智能未来是必要的。我们提供了可以采取的具体行动来支持实现这一目标的联盟式方法。例如，研究人员和开发者可以建立技术机制，如联邦数据管理工具和可解释的数据价值评估，以告知和促进信息经济中的集体谈判。此外，可以引入监管和政策干预，以支持代表信息生产者行会或辛迪加的可信数据中介组织。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [94] [FASCIST-O-METER: Classifier for Neo-fascist Discourse Online](https://arxiv.org/abs/2506.10789)
> *法西斯测量仪：在线新法西斯主义言论分类器*

*Rudy Alexandro Garrido Veliz, Martin Semmann, Chris Biemann, Seid Muhie Yimam* | **Main category: cs.CY**

**Keywords:** 新法西斯主义, 自然语言处理, 言论分类, 在线论坛, 仇恨言论检测

**Comment:** 

> **TL;DR:** 该研究开发了首个用于在线新法西斯主义言论分类的自然语言处理模型，通过创新的编码方案、众包标注数据集以及对小型和大型语言模型的微调实现。

**AI_Comments:** 这项研究具有重要的创新意义，因为它首次提出了新法西斯主义的数字言论编码方案，并基于此开发了首批分类模型，成功弥合了自然语言处理与政治学之间的交叉领域。其工作对于识别和对抗日益增长的在线新法西斯主义威胁至关重要。研究明确指出其焦点在于文本内容检测，而非针对个人或组织进行标记，这有助于明确其研究范围和伦理立场。

<details>
  <summary>Details</summary>

**Motivation:** 新法西斯主义在过去十年中在美国及其他西方社会显著增长，对民主和少数民族构成严重威胁，需要采取积极行动加以遏制。

**Method:** 本研究提出了首个针对美国社会背景下数字言论的新法西斯主义编码方案，并由政治学研究人员进行监督。为了验证该方案，研究人员从Notable新法西斯主义团体（如Iron March和Stormfront.org论坛）收集了大量在线活动数据。通过众包，标注了1000个帖子，将其标记为新法西斯主义或非新法西斯主义。利用这个标注数据集，研究人员对小型语言模型（SLMs）和大型语言模型（LLMs）进行了微调和测试。

**Result:** 本研究获得了首批用于新法西斯主义言论的分类模型。研究发现，在这类论坛中，新法西斯主义言论普遍存在。

**Conclusion:** 社会背景是进行新法西斯主义言论自然语言处理研究的关键考量。为了民主社会的福祉，必须继续并加强对抗此类政治运动的工作。

> **ai_Abstract:** 本研究旨在应对新法西斯主义在线言论的增长威胁。它提出了首个针对美国数字语境的新法西斯主义编码方案，并收集了来自新法西斯主义论坛的大量数据，通过众包标注了1000个帖子。利用这个独特的标注数据集，研究人员微调并测试了小型和大型语言模型，成功开发出首批新法西斯主义言论分类模型。研究结果表明，此类论坛中新法西斯主义言论普遍存在，并强调了社会背景在相关NLP研究中的重要性，呼吁持续对抗此类政治运动。

> **摘要翻译:** 新法西斯主义是一种政治和社会意识形态，在过去十年中在美国（USA）以及其他西方社会取得了显著增长。它对民主及其所针对的少数群体构成了严重威胁，需要积极采取行动来避免事态升级。这项工作提出了美国社会背景下数字言论的首个新法西斯主义编码方案，由政治学研究人员监督。我们的工作弥合了自然语言处理（NLP）和政治学之间对抗这种现象的鸿沟。此外，为了测试编码方案，我们从著名的新法西斯主义团体（Iron March和Stormfront.org论坛）收集了大量的互联网活动数据，并将指导原则应用于收集到的帖子子集。通过众包，我们总共标注了一千个帖子，这些帖子被标记为新法西斯主义或非新法西斯主义。利用这个标注数据集，我们微调并测试了小型语言模型（SLMs）和大型语言模型（LLMs），获得了首批用于新法西斯主义言论的分类模型。我们发现，在这类论坛中，新法西斯主义言论的盛行无处不在，这使得它们成为未来研究的良好目标。在进行自然语言处理研究时，社会背景是新法西斯主义言论的一个关键考量因素。最后，为了民主社会的福祉，必须对这种政治运动的斗争进行压制和继续。免责声明：本研究侧重于检测文本中的新法西斯主义内容，类似于其他仇恨言论分析，不标记个人或组织。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [118] [LLM-Driven Personalized Answer Generation and Evaluation](https://arxiv.org/abs/2506.10829)
> *LLM驱动的个性化答案生成与评估*

*Mohammadreza Molavi, Mohammadreza Tavakoli, Mohammad Moein, Abdolali Faraji, Gábor Kismihók* | **Main category: cs.CY**

**Keywords:** 个性化答案生成, 大型语言模型, 在线学习, StackExchange, 少样本学习

**Comment:** This is the preprint version of a paper accepted at AIED 2025. The
  final version will be published by Springer

> **TL;DR:** 本文探讨了大型语言模型（LLMs）在在线学习中生成个性化答案的潜力，并通过在语言学习和编程领域的StackExchange数据进行评估，发现提供示例能显著提升LLMs的个性化能力。

**AI_Comments:** 本文关注了在线教育中一个重要且具有挑战性的问题——个性化答案生成。其创新点在于利用LLMs的强大能力，并通过多策略（0-shot, 1-shot, few-shot）和多维度（BERTScore, LLM评估, 人工评估）的评估方法，全面验证了LLMs在这一任务上的有效性。特别是发现“提供示例”对提升LLMs个性化能力的关键作用，为未来LLMs在教育领域的应用提供了宝贵的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 在线学习的个性化对提升学习体验至关重要，特别是为学习者提供定制化答案。当前研究旨在利用大型语言模型（LLMs）生成个性化答案，以提高学习参与度并减轻教育者的工作量。

**Method:** 本研究利用StackExchange平台在语言学习和编程两个领域进行了综合研究。开发了一个框架和数据集来验证自动生成的个性化答案。使用0-shot、1-shot和few-shot策略生成个性化答案，并采用BERTScore、LLM评估和人工评估三种方法进行评估。

**Result:** 研究结果表明，向LLMs提供所需答案的示例（来自学习者或类似学习者）可以显著增强LLMs根据个体学习者需求定制回复的能力。

**Conclusion:** 提供示例是提升LLMs生成个性化答案能力的关键策略，这对于在线学习中的个性化教育具有重要意义。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在在线学习环境中生成个性化答案的能力。研究旨在通过为学习者提供定制化回复来提高参与度并减轻教育者负担。研究在语言学习和编程领域的StackExchange数据上进行了实验，开发了验证框架和数据集。通过0-shot、1-shot和few-shot策略生成答案，并使用BERTScore、LLM评估和人工评估进行效果评估。结果表明，提供示例可以显著提升LLMs生成个性化答案的能力。

> **摘要翻译:** 在线学习因其灵活性和可访问性而经历了快速增长。个性化，即根据个体学习者的需求进行调整，对于提升学习体验至关重要，尤其是在线环境中。个性化的一个关键方面是为学习者提供根据其具体问题定制的答案。因此，本文探讨了大型语言模型（LLMs）生成学习者问题个性化答案的潜力，从而增强参与度并减轻教育者的工作量。为了评估LLMs在此背景下的有效性，我们使用StackExchange平台在两个不同领域：语言学习和编程，进行了一项综合研究。我们开发了一个框架和一个数据集，用于验证自动生成的个性化答案。随后，我们使用不同的策略，包括0-shot、1-shot和few-shot场景，生成了个性化答案。生成的答案通过三种方法进行评估：1. BERTScore，2. LLM评估，以及3. 人工评估。我们的研究结果表明，向LLMs提供所需答案的示例（来自学习者或类似学习者）可以显著增强LLMs根据个体学习者需求定制回复的能力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [139] [The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins](https://arxiv.org/abs/2506.10964)
> *城市模型平台：城市数字孪生中建模与仿真的公共骨干*

*Rico H Herzog, Till Degkwitz, Trivik Verma* | **Main category: cs.CY**

**Keywords:** 城市数字孪生, 城市模型平台, 建模与仿真, 开放标准, 参与式设计

**Comment:** 

> **TL;DR:** 本文提出一个开放的城市模型平台，作为城市数字孪生中建模与仿真的公共技术骨干和社会技术框架，以实现更具包容性和协作性的城市规划。

**AI_Comments:** 这篇论文的创新之处在于提出了一个开放且去中心化的城市模型平台，以应对当前城市数字孪生中模型整合的复杂性和中心化趋势。它不仅关注技术层面，还强调其作为社会技术框架，促进协作和多元化表示，这对于实现更包容和可持续的城市规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 城市数字孪生在可持续和综合城市规划中日益重要，但其模型和仿真整合过程复杂，现有方法多为单一和中心化，限制了多元化和开放互操作性。

**Method:** 采用参与式设计方法，与德国汉堡市合作，探索开放的城市模型平台。

**Result:** 发现开放的城市模型平台可以作为城市数字孪生中建模与仿真的公共技术骨干，同时也是一个促进城市过程协作和多元化表示的社会技术框架。该平台基于开放标准，支持模型去中心化集成、模型间通信和多模型方法。

**Conclusion:** 一个开放的城市模型平台能够克服现有城市数字孪生中模型整合的复杂性和局限性，提供一个公共的、支持协作和多元化表示的基础设施。

> **ai_Abstract:** 本文提出并探讨了一个开放的城市模型平台，旨在解决城市数字孪生中模型整合的复杂性及现有中心化方案的局限性。该平台通过与德国汉堡市的合作，采用参与式设计方法，被证明能够作为城市数字孪生中建模与仿真的公共技术骨干和社会技术框架，支持基于开放标准、去中心化集成、模型间通信和多模型方法的协作式与多元化城市过程表示。

> **摘要翻译:** 城市数字孪生正日益被视为汇集城市日益增长的数字资源，以实现更可持续和综合城市规划的一种方式。模型和仿真在这一工作中至关重要：它们能够实现“如果……会怎样？”的场景模拟，提供洞察力，并描述所收集的大量数据之间的关系。然而，在城市数字孪生中整合和随后使用模型的过程中，本身就是一项复杂的任务。它引发了如何表示城市复杂性、如何处理不确定假设和建模范式，以及如何捕捉潜在权力关系的问题。该领域现有的方法大多侧重于新自由主义城市建设传统中的单一和集中式解决方案，常常禁止多元化和开放互操作的模型。通过与德国汉堡市合作，我们采用参与式系统方法进行参与式设计，发现一个开放的城市模型平台既可以作为城市数字孪生中建模与仿真的公共技术骨干，也可以作为城市过程协作和多元化表示的社会技术框架。这样的平台建立在开放标准之上，允许模型的去中心化集成，实现模型之间的通信，并支持表示城市系统的多模型方法。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [14] [Exploring EEG Responses during Observation of Actions Performed by Human Actor and Humanoid Robot](https://arxiv.org/abs/2506.10170)
> *探索观察人类演员和类人机器人执行动作时的脑电图反应*

*Anh T. Nguyen, Ajay Anand, Michelle J. Johnson* | **Main category: cs.CE**

**Keywords:** 动作观察疗法, 类人机器人, 脑电图, 事件相关谱扰动, 镜像神经元系统

**Comment:** 

> **TL;DR:** 本初步研究旨在评估类人机器人在动作观察（AO）疗法中的应用潜力，通过EEG监测健康参与者观察人类和机器人动作时的脑活动。结果显示个体间ERSP模式存在差异，但大多数人对两种观察条件下的ERSP存在强相关性，支持EEG在区分对机器人和人类动作观察的神经反应方面的可行性。

**AI_Comments:** 这是一项初步研究，样本量较小（三名参与者），因此结果的普遍性可能有限。然而，它为将类人机器人纳入动作观察疗法提供了初步证据，并验证了使用EEG作为评估工具的可行性。未来需要更大规模的研究来证实这些发现并深入探索机器人作为治疗辅助工具的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 动作观察（AO）疗法对神经系统疾病（如中风）患者的运动和语言功能康复有前景。本研究旨在探讨类人机器人在康复环境中支持AO疗法的潜力。

**Method:** 招募了三名健康的右撇子参与者。使用脑电图（EEG）监测他们在观察人类演员和机器人使用左右手臂执行的八种不同动作时的脑活动。分析了感觉运动区域的事件相关谱扰动（ERSPs）。

**Result:** 单受试者分析显示所有参与者的ERSP模式存在变异性，包括感觉运动mu和beta节律的功率抑制。一名参与者对“机器人”AO条件的反应比“人类”条件更强。几乎所有参与者和通道在所有条件下都观察到ERSP的强正相关，暗示了在动作观察过程中镜像神经元系统中存在共同的认知过程或神经网络。

**Conclusion:** 结果支持使用EEG探索观察机器人和人类诱导动作之间神经反应差异的可行性。

> **ai_Abstract:** 本初步研究旨在评估类人机器人在动作观察（AO）疗法中的应用潜力。研究使用EEG记录了三名健康参与者在观察人类和机器人执行动作时的脑活动，并分析了感觉运动区域的事件相关谱扰动（ERSPs）。结果显示参与者间ERSP模式存在个体差异，但多数参与者对两种观察条件下的ERSP表现出强相关性，表明镜像神经元系统存在共同的神经过程。研究支持EEG在区分对机器人和人类动作观察的神经反应方面的可行性。

> **摘要翻译:** 动作观察（AO）疗法是一种有前景的康复治疗方法，用于改善中风等神经系统疾病患者的运动和语言功能。这项初步研究旨在调查类人机器人在康复环境中支持AO疗法的潜力。研究通过脑电图（EEG）监测了三名健康的右撇子参与者的大脑活动，他们观察了人类演员和机器人使用左右手臂执行的八种不同动作。分析了他们感觉运动区域的事件相关谱扰动（ERSPs，即神经振荡光谱功率相对于基线的变化，以响应事件或刺激）。单受试者分析显示，所有参与者的ERSP模式存在变异性，包括感觉运动mu和beta节律的功率抑制。其中一名参与者对“机器人”AO条件的反应比“人类”条件更强。几乎所有参与者和通道在所有条件下都观察到ERSP的强正相关，这暗示了在动作观察过程中镜像神经元系统中存在共同的认知过程或神经网络。结果支持使用脑电图探索观察机器人和人类诱导动作之间神经反应差异的可行性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [41] [Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces](https://arxiv.org/abs/2506.10224)
> *可解释且灵活的基于再生核希尔伯特空间的非侵入式降阶模型*

*Alejandro N Diaz, Shane A McQuarrie, John T Tencer, Patrick J Blonigan* | **Main category: cs.CE**

**Keywords:** 降阶模型, 再生核希尔伯特空间, 非侵入式, 核插值, 可解释性

**Comment:** 

> **TL;DR:** 一种新的基于再生核希尔伯特空间的非侵入式降阶模型，具有可解释性和灵活性，并提供误差界。

**AI_Comments:** 本文的创新点在于将正则化核插值应用于非侵入式降阶模型，实现了模型的可解释性和灵活性，并提供了理论上的误差界。

<details>
  <summary>Details</summary>

**Motivation:** 现有非侵入式降阶模型（ROM）通过数据驱动的最小二乘回归来近似动力学，本研究旨在提出一种更可解释、更灵活的方法。

**Method:** 本文开发了一种使用正则化核插值技术的可解释、非侵入式降阶建模方法。该方法利用用户定义的再生核希尔伯特空间，通过在核中嵌入特征映射来使ROM结构与全阶模型结构保持一致，并允许通过特征映射和更一般的非线性核项结合结构和闭合项。此外，还推导了一个可计算的后验误差界。

**Result:** 该核方法能够生成结构与全阶模型相似的可解释降阶模型，并且具有灵活性，可结合通过特征映射获得的结构信息以及通过更一般的非线性核项获得的闭合项。该方法在多个数值实验中得到了验证，并与使用POD和二次流形降维的算子推断进行了比较。

**Conclusion:** 本文提出的基于再生核希尔伯特空间的非侵入式降阶建模方法是可解释且灵活的，并通过数值实验证明了其有效性和优越性。

> **ai_Abstract:** 本文提出了一种基于正则化核插值的可解释、非侵入式降阶建模技术。该方法利用再生核希尔伯特空间提供对降阶模型动力学的最优近似，并通过嵌入特征映射实现模型结构的可解释性，同时通过结合特征映射和非线性核项实现灵活性。研究还推导了一个可计算的后验误差界，并通过数值实验验证了该方法的有效性。

> **摘要翻译:** 本文开发了一种使用正则化核插值的可解释、非侵入式降阶建模技术。现有的非侵入式方法通过求解低维矩阵算子的数据驱动最小二乘回归问题来近似降阶模型（ROM）的动力学。我们的方法则利用正则化核插值，从用户定义的再生核希尔伯特空间中获得ROM动力学的最优近似。我们展示了我们的基于核的方法可以通过在核中嵌入精心选择的特征映射来生成结构与全阶模型结构相似的可解释ROM。该方法具有灵活性，允许通过特征映射组合信息结构，并通过核中更一般的非线性项组合闭合项。我们还推导了一个可计算的后验误差界，该误差界结合了侵入式基于投影的ROM和核插值器的标准误差估计。该方法在多个数值实验中得到了验证，其中包括与使用本征正交分解和二次流形降维的算子推断的比较。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [66] [PDESpectralRefiner: Achieving More Accurate Long Rollouts with Spectral Adjustment](https://arxiv.org/abs/2506.10711)
> *PDESpectralRefiner：通过频谱调整实现更准确的长期模拟*

*Li Luo, Shangsong Liang* | **Main category: cs.CE**

**Keywords:** PDESpectralRefiner, 偏微分方程, 扩散模型, 频谱调整, 长期模拟

**Comment:** 

> **TL;DR:** PDESpectralRefiner通过在扩散模型中引入频谱调整，解决了时间依赖性偏微分方程（PDEs）长期模拟中高频部分过度衰减的问题，从而提高了模拟的准确性。

**AI_Comments:** 这项工作的创新之处在于通过引入频谱调整，解决了基于扩散的PDE求解器在高频部分过度衰减的特定问题。这对于实现准确的长期模拟非常重要，特别是对于复杂的PDEs。新开发的v-预测技术也是一个显著的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 时间依赖性偏微分方程（PDEs）在生成准确稳定的长期模拟方面面临挑战。现有的基于扩散模型的细化器（如PDERefiner）虽然能提高高频部分的正确性，但对于一些复杂的PDEs（如Navier-Stokes方程），可能会过度衰减高频部分，这促使研究者需要一种能对不同频率进行加权调整的方法。

**Method:** 作者通过在频谱空间进行调整来增强其细化模型，从而恢复了模糊扩散模型。此外，他们为模糊扩散模型开发了一种新的v-预测技术，该技术在第一个细化步骤中恢复了MSE训练目标。

**Result:** PDESpectralRefiner的输出在一步MSE损失和模拟损失方面都更准确，并且适用于U-Net和神经算子等不同的模型骨干。

**Conclusion:** 通过在频谱空间进行调整并引入新的v-预测技术，PDESpectralRefiner有效地解决了扩散模型在PDEs长期模拟中高频部分过度衰减的问题，显著提高了模拟的准确性。

> **ai_Abstract:** 本文介绍了PDESpectralRefiner，一个增强的细化模型，旨在提高时间依赖性偏微分方程长期模拟的准确性和稳定性。为了解决先前基于扩散的细化器可能过度衰减高频的限制，PDESpectralRefiner引入了频谱空间调整和一种新的模糊扩散模型v-预测技术。实验表明，这种方法在一步MSE损失和模拟损失方面都能产生更准确的结果，并且适用于各种模型架构。

> **摘要翻译:** 时间依赖性偏微分方程（PDEs）生成准确稳定的长期模拟是一个臭名昭著的挑战。最近，受高频精度重要性的启发，一个名为PDERefiner的细化模型利用扩散模型来细化每个时间步的输出，因为去噪过程可以增加高频部分建模的正确性。对于一维Kuramoto-Sivashinsky方程，细化模型比不进行细化过程能更好地降低高频部分的振幅。然而，对于其他一些情况，频谱可能更复杂。例如，对于像Navier-Stokes方程这样更难的PDE，扩散模型可能会过度降低高频部分。这促使我们放开每个频率权重相同的约束。我们通过在频谱空间进行调整来增强我们的细化模型，这恢复了模糊扩散模型。我们为模糊扩散模型开发了一种新的v-预测技术，在第一个细化步骤中恢复了MSE训练目标。我们表明，在这种情况下，对于不同的模型骨干，例如U-Net和神经算子，PDESpectralRefiner的输出在一步MSE损失和模拟损失方面都更准确。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [93] [Spectral Analysis of Discretized Boundary Integral Operators in 3D: a High-Frequency Perspective](https://arxiv.org/abs/2506.10880)
> *三维离散边界积分算子的谱分析：高频视角*

*V. Giunzioni, A. Merlini, F. P. Andriulli* | **Main category: cs.CE**

**Keywords:** 边界积分算子, 谱分析, 离散化, 边界元方法, 高频

**Comment:** 

> **TL;DR:** 本文通过分析算子矩阵的谱，指出在边界元方法中，随着模拟频率的增加，离散算子与连续算子之间的误差会增大，这挑战了在更高频率下保持解精度不变的常见离散化方法的有效性。

**AI_Comments:** 本文的创新之处在于，它通过严谨的谱分析，对边界元方法在高频应用中的一个长期存在的、被广泛接受的离散化实践提出了质疑。其重要性在于，它揭示了在高频电磁仿真中可能导致精度下降的潜在原因，促使研究人员重新思考和改进高频建模的离散化策略。这对于确保高频模拟的准确性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在利用边界元方法离散化积分方程来模拟传播和散射现象时，通常认为将散射体边界用波长的一小部分（例如λ/10）的网格进行近似足以在增加频率时保持解的精度不变。本文旨在挑战这一普遍看法，揭示高频下离散化方法的局限性。

**Method:** 通过分析算子矩阵的谱。

**Result:** 研究发现，离散算子与连续算子之间存在差异，且这种差异随着模拟频率的增加而增大。

**Conclusion:** 传统的边界元方法离散化策略（例如使用λ/10网格）可能不足以在高频下保持解的精度恒定，需要重新审视高频建模中的离散化方法。

> **ai_Abstract:** 本文研究了三维离散边界积分算子在高频下的谱特性。通过分析算子矩阵的谱，作者发现当使用边界元方法进行建模时，离散算子与连续算子之间的误差随着模拟频率的升高而增大。这一发现挑战了当前广泛采纳的、认为通过将网格单元尺寸设定为波长的一小部分即可在高频下保持解精度不变的普遍认知。

> **摘要翻译:** 在使用边界元方法离散化积分方程来模拟传播和散射现象时，通常的做法是用网格近似散射体的边界，网格单元的大小大约等于入射波波长λ的一小部分，例如λ/10。在这项工作中，通过分析算子矩阵的谱，我们发现离散算子与连续算子之间存在差异，这种差异随着模拟频率的增加而增大，这挑战了上述广泛使用的离散化方法在增加频率时足以保持解精度不变的普遍看法。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [15] [Chance and Mass Interpretations of Probabilities in Markov Decision Processes (Extended Version)](https://arxiv.org/abs/2506.10377)
> *马尔可夫决策过程中概率的几率和质量解释（扩展版）*

*Yun Chen Tsai, Kittiphon Phalakarn, S. Akshay, Ichiro Hasuo* | **Main category: cs.FL**

**Keywords:** 马尔可夫决策过程, 概率解释, 统一语义框架, 几率-质量分类器, 可达性问题

**Comment:** 

> **TL;DR:** 本文提出了一个统一的语义框架，整合了马尔可夫决策过程（MDPs）中概率的两种现有解释以及两种新解释，并通过研究可达性问题来验证新语义。

**AI_Comments:** 本文的创新之处在于提出了一个统一的语义框架，系统地整合了马尔可夫决策过程（MDPs）中概率的多种解释，并通过引入“几率-质量（CM）分类器”这一数学构造，为MDPs的语义分析提供了新的视角和工具。这对于深化对MDPs的理解，尤其是在处理不同随机性来源和概率解释场景下具有重要意义。此外，对新语义中可达性问题的研究及其算法的提出，也体现了理论与实践相结合的价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的马尔可夫决策过程（MDPs）在验证中被视为状态转换器，其概率定义在状态序列上，调度器进行随机选择。另一种观点将MDPs定义为分布转换器，调度器分配概率质量。本文的动机是提供一个统一的语义框架来容纳这两种现有观点以及两种新的观点。

**Method:** 本文通过识别MDP中不同的随机性来源（调度器、配置和转换）并提供不同的概率解释方式（几率和质量解释），自然地产生了四种MDP语义。这些语义通过一个称为几率-质量（CM）分类器的数学构造系统地统一起来。此外，本文研究了两种新语义中的可达性问题，并提供了两种解决算法。

**Result:** 本文统一了马尔可夫决策过程（MDPs）的四种语义，并通过几率-质量（CM）分类器实现了系统性统一。对于两种新语义中的可达性问题，本文证明了其困难性并提出了两种相应的解决算法。

**Conclusion:** 本文成功提出了一个统一的语义框架，整合了马尔可夫决策过程（MDPs）中概率的多种解释方式，并通过CM分类器提供了系统的数学统一。此外，本文还为新语义中的可达性问题提供了解决方案。

> **ai_Abstract:** 本文提出了一种统一的语义框架，整合了马尔可夫决策过程（MDPs）中概率的四种解释，包括传统的基于状态转换的观点、基于分布转换的观点以及两种新的观点。这些解释源于对随机性来源（调度器、配置、转换）和概率解释方式（几率、质量）的不同识别，并通过一个名为几率-质量（CM）分类器的数学构造实现系统统一。此外，论文还研究了在新语义中的可达性问题，证明了其困难性并提出了相应的解决算法。

> **摘要翻译:** 马尔可夫决策过程（MDPs）是存在不确定性时进行决策的流行模型。验证中MDPs的传统观点将其视为状态转换器，其概率定义在状态序列上，调度器进行随机选择。另一种观点，特别适合建模动态系统，将MDPs定义为分布转换器，调度器分配概率质量。我们的主要贡献是一个统一的语义框架，该框架容纳了这两种观点以及两种新的观点。MDPs的这四种语义通过识别MDP中不同的随机性来源（即调度器、配置和转换）并提供不同的概率解释方式（称为几率和质量解释）自然产生。这些语义通过一个称为几率-质量（CM）分类器的数学构造系统地统一起来。作为另一个主要贡献，我们研究了两种新语义中的可达性问题，证明了它们的困难性并提供了两种解决算法。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [42] [Minimality and computability of languages of G-shifts](https://arxiv.org/abs/2506.10610)
> *G-移位语言的最小性和可计算性*

*Djamel Eddine Amir, Benjamin Hellouin de Menibus* | **Main category: cs.FL**

**Keywords:** G-移位, 强可计算类型, 最小性, 语言, 可计算性

**Comment:** Accepted to ICALP 2025

> **TL;DR:** 本文定义了G-移位的强可计算类型，并将其特性化为最小性概念，提供了一个统一的方法，概括了现有结果，并证明了其在乘积下的保持性。

**AI_Comments:** 本文的创新之处在于将强可计算类型的概念从集合推广到G-移位，并提出了一个基于最小性的统一特性化方法。其重要性体现在它不仅能够概括现有结果，还具有产生新发现的潜力。此外，发现G-移位的强可计算类型在乘积下保持，这与集合的情况形成对比，是一个重要的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 受可计算分析中集合的强可计算类型概念的启发。

**Method:** 定义了G-移位的强可计算类型，即可以从其语言的补集计算其语言。通过与有界计算复杂度的最小性概念，获得了G-移位强可计算类型的特性化。提供了一个独立的直接证明，并解释了如何从Amir和Hoyrup对集合的现有相似特性化中获得，并讨论了其与Jeandel关于闭合空间结果的联系。将此特性化应用于几类在特定属性下是最小的移位。

**Result:** 获得了G-移位强可计算类型的特性化，这提供了一种统一的方法，不仅概括了许多现有结果，而且有望轻松产生新的发现。与集合的情况不同，证明了G-移位的强可计算类型在乘积下是保持的。

**Conclusion:** 讨论了一些泛化和未来的方向。

> **ai_Abstract:** 本文在可计算分析中集合的强可计算类型概念的启发下，为G-移位定义了强可计算类型，即其语言可从其补集计算。研究通过一个关于有界计算复杂度的最小性概念，对具有强可计算类型的G-移位进行了特性化，并提供了直接证明，同时探讨了其与现有集合特性化及闭合空间结果的关联。该特性化被应用于多类最小移位，展示了其泛化现有成果并促进新发现的潜力。此外，研究还证明了G-移位的强可计算类型在乘积下得以保持，这与集合的情况不同。

> **摘要翻译:** 受可计算分析中集合的强可计算类型概念的启发，我们定义了G-移位的强可计算类型概念，其中G是具有可判定词问题的有限生成群。如果可以从其语言的补集计算出其语言，则G-移位具有强可计算类型。我们通过一个关于有界计算复杂度的最小性概念，获得了G-移位强可计算类型的特性化。我们提供了一个独立的直接证明，并解释了如何从Amir和Hoyrup对集合的现有相似特性化中获得这种特性化，并讨论了其与Jeandel关于闭合空间结果的联系。我们将此特性化应用于几类在特定属性下是最小的移位。这提供了一种统一的方法，不仅概括了许多现有结果，而且有望轻松产生新的发现。与集合的情况不同，我们证明了G-移位的强可计算类型在乘积下是保持的。最后，我们讨论了一些泛化和未来的方向。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [18] [Formalizing Neuromorphic Control Systems: A General Proposal and A Rhythmic Case Study](https://arxiv.org/abs/2506.10203)
> *形式化神经形态控制系统：一种通用提案与一个节律案例研究*

*Taisia Medvedeva, Alessio Franci, Fernando Castaños* | **Main category: eess.SY**

**Keywords:** 神经形态控制, 形式化, 节律控制, 控制理论, 系统分析

**Comment:** Submitted to the 64th IEEE Conference on Decision and Control

> **TL;DR:** 本文提出了一种形式化神经形态控制系统的方法，并通过一个节律控制案例研究验证了其潜力，使其能够采用成熟的控制理论进行分析和设计。

**AI_Comments:** 本文的创新点在于提出了一种通用框架来形式化神经形态控制系统，填补了该领域在理论严谨性方面的空白。其重要性在于，通过将神经形态控制与成熟的控制理论相结合，有望加速该领域的发展，使其设计和分析更加系统化和可靠。

<details>
  <summary>Details</summary>

**Motivation:** 神经形态控制系统虽然具有稀疏传感、高效能、事件驱动等优点，但目前缺乏对其的通用控制理论形式化，导致难以严格分析、设计和控制。

**Method:** 论文提出了一种可能的形式化神经形态控制系统的通用框架，并将其应用于一个节律控制案例研究。

**Result:** 通过将所提出的框架应用于节律控制案例研究，论文严格展示了它如何能够使神经形态控制系统的分析和设计适用于描述函数分析、谐波平衡、快慢分析、离散和混合系统以及鲁棒优化等成熟的控制理论方法。

**Conclusion:** 所提出的形式化方法有望弥补神经形态控制系统在严格分析和设计方面的不足，使其能够利用现有成熟的控制理论工具，从而促进该领域的发展。

> **ai_Abstract:** 本文提出了一种通用框架，旨在形式化神经形态控制系统，以解决当前缺乏严格分析和设计方法的挑战。通过一个节律控制案例研究，论文证明了该框架能够将神经形态控制系统的分析与设计与描述函数分析、谐波平衡、快慢分析、离散和混合系统以及鲁棒优化等成熟的控制理论方法相结合。

> **摘要翻译:** 神经形态控制因其相对于经典控制方法的多方面优势而受到越来越多的关注，这些优势包括：稀疏和按需传感、信息传输和执行；神经形态硬件中的节能设计和实现；以及基于事件的信号处理和控制信号计算。然而，关于“神经形态控制系统”是什么以及如何严格分析、设计和控制它们的通用控制理论形式化仍然 largely 缺失。在本说明中，我们提出了一种可能的形式化神经形态控制系统的路径。我们将所提出的框架应用于一个节律控制案例研究，并严格展示了它如何有可能使神经形态控制系统的分析和设计适用于描述函数分析和谐波平衡、快慢分析、离散和混合系统以及鲁棒优化等成熟的控制理论方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [45] [Model Predictive Control-Based Optimal Energy Management of Autonomous Electric Vehicles Under Cold Temperatures](https://arxiv.org/abs/2506.10221)
> *模型预测控制在低温环境下自动电动汽车最优能量管理中的应用*

*Shanthan Kumar Padisala, Satadru Dey* | **Main category: eess.SY**

**Keywords:** 模型预测控制, 能量管理, 自动电动汽车, 低温, 电池预处理

**Comment:** 

> **TL;DR:** 本文提出了一种基于模型预测控制的方法，用于在低温环境下优化自动电动汽车的电池能量分配，以平衡热舒适、电池健康和续航里程，尤其是在低电量时。

**AI_Comments:** 本文的创新点在于将模型预测控制应用于低温环境下电动汽车的综合能量管理，特别是考虑了电池预处理和HVAC与推进的协同优化，这对于提升电动汽车在冬季的实用性和用户体验具有重要意义。它试图解决一个实际且关键的能量分配挑战，避免了次优的启发式方法。

<details>
  <summary>Details</summary>

**Motivation:** 在低温环境下，自动电动汽车（AEV）的电池能量分配面临挑战，尤其是当电池电量低时，车厢加热和电池预处理会消耗大量能量，影响续航里程。传统方法通常优先考虑推进或采用启发式规则，导致能量利用次优。因此，迫切需要一种有原则的方法来动态分配电池功率，以平衡热舒适、电池健康、预处理和续航里程。

**Method:** 使用实时模型预测控制（Model Predictive Control, MPC）来优化推进系统、HVAC系统和电池温度准备之间的功耗分配。

**Result:** Not mentioned in abstract

**Conclusion:** 本文通过实时模型预测控制，旨在解决低温环境下自动电动汽车的能量管理问题，实现热舒适、电池健康和续航里程之间的平衡，并确保到达目的地后电池能立即充电。

> **ai_Abstract:** 本文提出了一种基于实时模型预测控制（MPC）的策略，旨在解决自动电动汽车（AEV）在低温环境下电池能量管理的问题。在低温且电池电量低时，HVAC和电池预处理会显著消耗能量并影响续航里程。针对传统启发式方法的不足，该研究通过MPC优化推进、HVAC和电池预处理之间的功率分配，以平衡乘员舒适度、电池健康、预处理需求和续航里程，确保能量高效利用并支持快速充电。

> **摘要翻译:** 在自动电动汽车（AEV）中，电池能量必须审慎分配以满足主要推进需求和次要辅助需求，特别是供暖、通风和空调（HVAC）系统。当电池在低温环境条件下降至低电量时，这一点变得尤为关键，因为车厢加热和电池预处理（实际充电前）会消耗可用能量的很大一部分，直接影响续航里程。在这种情况下，通常会优先考虑推进或应用启发式规则进行热管理，这往往导致能量利用次优。迫切需要一种有原则的方法，能够动态分配电池功率，以平衡热舒适、电池健康、预处理以及续航里程的保持。本文试图通过使用实时模型预测控制来解决这个问题，以优化推进、HVAC和电池温度准备之间的功耗，从而确保一旦到达目的地即可立即充电。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [70] [Energy Aware Camera Location Search Algorithm for Increasing Precision of Observation in Automated Manufacturing](https://arxiv.org/abs/2506.10251)
> *自动化制造中提高观测精度的节能相机位置搜索算法*

*Rongfei Li, Francis Assadian* | **Main category: eess.SY**

**Keywords:** 视觉伺服, 相机位置, 噪声抑制, 自动化制造, 节能

**Comment:** 35 pages, 24 figures, Journal, Published in: Applied Sciences, 2024,
  vol. 14, article 9140. For published version, see this http URL:
  https://doi.org/10.3390/app14199140

> **TL;DR:** 本文提出了一种节能的相机位置搜索算法，用于在自动化制造环境中找到最佳相机位置以最小化图像噪声并提高观测精度。

**AI_Comments:** 该论文的创新点在于提出了一个节能且自适应的相机位置搜索算法，解决了传统手眼配置中相机位置对观测精度影响的忽视。它通过智能探索和图像平均技术，避免了暴力搜索的低效，并在能量受限的实际工业环境中实现了高精度观测，具有重要的实际应用价值。其能够在不牺牲高频信息的前提下提高精度，是其显著优点。

<details>
  <summary>Details</summary>

**Motivation:** 在自动化制造中，相机位置对图像估计质量有显著影响，因为不同位置的环境条件会导致不同的图像噪声水平。现有研究很少讨论相机位置的重要性。

**Method:** 本文提出了一种相机移动策略算法，使其探索相机工作空间并搜索图像噪声水平最小的最佳位置。该算法在有限的相机移动能量下，确保相机停留在已搜索位置中的次优（如果最优不可达）位置。与简单的暴力方法不同，该算法通过学习环境来调整搜索策略，从而更有效地探索空间。借助图像平均技术，该算法使用单个相机在不滤除原始图像中高频信息的情况下，将手眼配置中的观测精度提高到理想程度。

**Result:** 通过模拟一个自动化制造应用，结果表明该算法在有限能量下成功提高了观测精度。

**Conclusion:** 该算法利用单个相机和图像平均技术，在不滤除原始图像中高频信息的情况下，将手眼配置中的观测精度提高到理想程度。

> **ai_Abstract:** 本文针对自动化制造中相机位置对观测精度的影响，提出了一种节能的相机位置搜索算法。该算法通过学习环境，智能地探索相机工作空间，旨在寻找图像噪声最小的最佳位置，并在能量有限的情况下确保相机停留在次优位置。通过图像平均技术，该算法使用单个相机即可有效提高手眼配置下的观测精度，且不损失图像高频信息。仿真结果验证了其在有限能量下提高观测精度的有效性。

> **摘要翻译:** 视觉伺服技术已经得到了很好的发展，并应用于许多自动化制造任务中，特别是在工具姿态对齐方面。为了获取工具的完整全局视图，大多数应用在自动化制造环境中采用手眼（eye-to-hand）配置或手眼/眼内（eye-to-hand/eye-in-hand）协作配置。大多数研究论文主要致力于在各种场景中开发控制和观测架构，但很少有论文讨论手眼配置中相机位置的重要性。在制造环境中，相机估计的质量可能因不同的观测位置而显著不同，因为环境条件的综合影响导致在不同位置拍摄的单张图像的噪声水平不同。在本文中，我们提出了一种相机移动策略算法，使其探索相机工作空间并搜索图像噪声水平最小的最佳位置。此外，该算法确保相机在已搜索位置中停留在次优（如果最优不可达）位置，且相机移动的可用能量有限。与简单的暴力方法不同，该算法通过学习环境来调整搜索策略，从而更有效地探索空间。借助图像平均技术，该算法使用单个相机，在不滤除原始图像中高频信息的情况下，将手眼配置中的观测精度提高到理想程度。一个自动化制造应用已经进行了模拟，结果表明该算法在有限能量下成功提高了观测精度。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [96] [Learning-Based Stable Optimal Control for Infinite-Time Nonlinear Regulation Problems](https://arxiv.org/abs/2506.10291)
> *无限时非线性调节问题的学习型稳定最优控制*

*Han Wang, Di Wu, Lin Cheng, Shengping Gong, Xu Huang* | **Main category: eess.SY**

**Keywords:** 学习型控制, 稳定最优控制, 非线性调节, Lyapunov稳定性, Pontryagin最大值原理

**Comment:** 

> **TL;DR:** 本文提出了一种基于学习的框架，用于解决无限时非线性最优调节问题，通过改进数据生成方法并结合Lyapunov稳定性条件，学习得到稳定的近最优控制器。

**AI_Comments:** 本文的创新点在于将Lyapunov稳定性条件整合到基于学习的最优控制框架中，解决了现有学习方法在稳定性保证方面的不足。通过改进数据生成方法，提高了学习效率和数据覆盖率。该研究对于航空航天等领域中需要稳定且最优控制的非线性系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的无限时非线性最优调节控制方法依赖线性化假设，而现有的基于学习的方法通常不考虑稳定性保证。

**Method:** 论文提出了一个基于学习的框架来学习稳定的最优控制器。首先，利用庞特里亚金最大值原理（PMP）和汉密尔顿-雅可比-贝尔曼（HJB）方程的等价性，改进了无限时最优调节问题的最优示例反向生成（BGOE）方法。其次，提出了一种状态转移矩阵引导的数据生成方法，以高效生成覆盖所需状态空间的完整数据集。最后，将Lyapunov稳定性条件纳入学习框架，通过联合学习最优值函数和控制策略，确保所学最优策略的稳定性。

**Result:** 在三个非线性最优调节问题上的仿真表明，所学习的最优策略实现了近最优的调节控制。

**Conclusion:** 本文提出的学习型框架能够为无限时非线性调节问题学习到稳定的近最优控制器，有效解决了传统方法和现有学习方法在稳定性和线性化假设上的局限。

> **ai_Abstract:** 本文针对无限时非线性最优调节控制中传统方法依赖线性化假设和现有学习方法缺乏稳定性保证的问题，提出了一种新型学习框架。该框架通过改进最优示例反向生成（BGOE）方法，引入状态转移矩阵引导的数据生成策略，并关键性地将Lyapunov稳定性条件整合到学习过程中，以联合学习最优值函数和控制策略，从而确保所学控制器的稳定性。仿真结果验证了该方法能够实现近最优的调节控制。

> **摘要翻译:** 无限时非线性最优调节控制在航空航天工程中被广泛用作合成稳定控制器的系统方法。然而，传统方法通常依赖于线性化假设，而最近的基于学习的方法很少考虑稳定性保证。本文提出了一种基于学习的框架，用于学习非线性最优调节问题的稳定最优控制器。首先，利用庞特里亚金最大值原理（PMP）和汉密尔顿-雅可比-贝尔曼（HJB）方程之间的等价性，我们改进了无限时最优调节问题的最优示例反向生成（BGOE）方法。然后提出了一种状态转移矩阵引导的数据生成方法，以高效生成覆盖所需状态空间的完整数据集。最后，我们将Lyapunov稳定性条件纳入学习框架，通过联合学习最优值函数和控制策略，确保所学最优策略的稳定性。在三个非线性最优调节问题上的仿真表明，所学习的最优策略实现了近最优的调节控制，并且代码已在 https://github.com/wong-han/PaperNORC 提供。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [120] [Synthesizing Min-Max Control Barrier Functions For Switched Affine Systems](https://arxiv.org/abs/2506.10296)
> *切换仿射系统最小-最大控制障碍函数的合成*

*Sara Kamali, Guillaume O. Berger, Sriram Sankaranarayanan* | **Main category: eess.SY**

**Keywords:** 控制障碍函数, 切换仿射系统, 非光滑分析, 最小-最大, 合成

**Comment:** 

> **TL;DR:** 该研究旨在为切换仿射系统合成非光滑的最小-最大控制障碍函数（CBFs），以确保系统状态保持在安全区域内，并自动化CBF的合成过程。

**AI_Comments:** 该论文的创新点在于提出了为切换仿射系统合成非光滑最小-最大控制障碍函数的方法，并引入了基于分支定界启发式树搜索算法的自动化合成流程。这对于确保复杂混合系统的安全操作具有重要意义，尤其是在处理非光滑特性时，为控制理论和实际应用提供了新的工具。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在解决为连续时间切换仿射系统合成非光滑控制障碍函数（CBFs）的问题。CBFs的目的是使系统状态保持在一个控制不变集中，从而排除给定的不安全状态集。

**Method:** 该方法考虑将CBFs形式化为有限仿射函数集上的逐点最小值和最大值。研究利用非光滑分析的思想来制定最小-最大仿射控制障碍函数的条件。论文展示了如何从给定的CBF中提取反馈切换律，并展示了如何通过受组合优化中分支定界方法启发的树搜索算法，根据系统描述自动化CBF的合成过程。

**Result:** 研究展示了如何从给定的CBF中提取反馈切换律，并成功自动化了CBF的合成过程。最后，该方法在一系列有趣的切换仿射系统示例上得到了验证。

**Conclusion:** 该论文提出了一种为连续时间切换仿射系统合成非光滑最小-最大控制障碍函数的方法，并展示了如何自动化这一合成过程，通过示例验证了其有效性。

> **ai_Abstract:** 本研究关注为连续时间切换仿射系统合成非光滑的最小-最大控制障碍函数（CBFs）。这些CBFs旨在确保系统状态保持在安全区域内。该方法利用非光滑分析来制定CBF条件，并展示了如何提取反馈切换律。此外，论文提出了一种基于树搜索算法的自动化CBF合成流程。该方法通过多个切换仿射系统示例进行了验证。

> **摘要翻译:** 我们研究为连续时间切换仿射系统合成非光滑控制障碍函数（CBFs）的问题。切换仿射系统由一组仿射动力学模式定义，其中控制包括一个基于状态的切换信号，该信号决定当前的操作模式。控制障碍函数旨在将系统状态维持在一个控制不变集内，该集合排除了给定的一组不安全状态。我们考虑采用有限仿射函数集上的逐点最小值和最大值形式的CBFs。我们的方法利用非光滑分析的思想来制定最小-最大仿射控制障碍函数的条件。我们展示了如何从给定的CBF中提取反馈切换律。接下来，我们展示了如何通过受组合优化中分支定界方法启发的树搜索算法，根据系统描述自动化CBFs的合成过程。最后，我们在一系列有趣的切换仿射系统示例上演示了我们的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [141] [Semi-Tensor-Product Based Convolutional Neural Networks](https://arxiv.org/abs/2506.10407)
> *半张量积卷积神经网络*

*Daizhan Cheng* | **Main category: eess.SY**

**Keywords:** 半张量积, 卷积神经网络, 填充, 域基卷积乘积

**Comment:** 

> **TL;DR:** 本文提出了一种基于半张量积（STP）的新型卷积乘积，并在此基础上开发了STP卷积神经网络，可避免传统填充带来的冗余信息，并应用于图像和三阶信号识别。

**AI_Comments:** 该论文的创新点在于将半张量积引入卷积神经网络，并通过设计新的卷积乘积规避了传统卷积中填充问题。这种方法可能为处理不同维度数据和提高模型效率提供了新思路，具有一定的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种新的卷积乘积，以避免传统卷积操作中填充（padding）引入的冗余信息。

**Method:** 本文提出了一种基于域的卷积乘积（CP），并将其与向量的半张量积（STP）结合，形成了一种新的无需填充的CP。在此基础上，开发了基于STP的卷积神经网络（CNN）。

**Result:** 提出的新卷积乘积能够避免传统填充导致的冗余信息。开发的STP-based CNN可应用于图像和三阶信号识别。

**Conclusion:** 提出的基于半张量积的卷积神经网络通过一种新的无填充卷积乘积，成功规避了传统填充带来的冗余信息，并可应用于图像和三阶信号识别任务。

> **ai_Abstract:** 本文提出了一种基于向量半张量积（STP）的新型卷积乘积（CP），该CP结合了域基CP和STP，其特点是无需任何填充，从而避免了传统填充引入的冗余信息。在此基础上，开发了基于STP的卷积神经网络（CNN），并探讨了其在图像和三阶信号识别中的应用。

> **摘要翻译:** 向量的半张量积（STP）是向量传统内积的推广，它允许因子向量具有不同的维度。本文提出了一种基于域的卷积乘积（CP）。将基于域的CP与向量的STP相结合，提出了一种新的CP。由于没有零或其他填充，它可以避免由填充引起的垃圾信息。利用它，开发了基于STP的卷积神经网络（CNN）。并考虑了其在图像和三阶信号识别中的应用。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [161] [Predictive control of wastewater treatment plants as energy-autonomous water resource recovery facilities](https://arxiv.org/abs/2506.10490)
> *污水处理厂的预测控制作为能源自主型水资源回收设施*

*Otacilio B. L. Neto, Michela Mulas, Iiro Harjunkoski, Francesco Corona* | **Main category: eess.SY**

**Keywords:** 污水处理厂, 预测控制, 能源自主, 水资源回收, 水再利用

**Comment:** 13 pages, 8 figures (main text); 27 pages, 2 figures (supplementary
  material)

> **TL;DR:** 本文提出了一种用于污水处理厂的自动控制解决方案，使其能够作为能源自主型水资源回收设施运行，通过输出反馈模型预测控制器在满足特定水质目标的同时实现能源自给自足。

**AI_Comments:** 本文的创新之处在于将预测控制应用于污水处理厂的能源自主运行，并结合了灵活的水质分类以适应多种资源回收目标。这对于提升污水处理厂的经济性和可持续性具有重要意义，展示了现有基础设施通过智能控制实现功能升级的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在为传统污水处理厂提供一种自动控制解决方案，使其能够作为能源自主型水资源回收设施运行，目标是生产特定水质的水并同时产生足够的沼气以确保非正能源成本。

**Method:** 研究首先对处理水的质量进行了分类，以适应三种资源回收应用（环境、工业和农业用水再利用）。然后，提出了一种输出反馈模型预测控制器（Output MPC），该控制器能够运行工厂以生产特定质量等级的水，同时产生足够的沼气以确保非正能源成本。

**Result:** 结果证明了现有污水处理基础设施在能源自主运行方面的概念验证，所提出的控制策略具有足够的通用性，能够适应广泛的资源回收目标。该控制器在全尺寸污水处理厂的长期运行中得到了验证，该工厂受到典型的进水负荷和周期性变化的水质目标的影响。

**Conclusion:** 本研究成功展示了通过预测控制策略，现有污水处理厂能够实现能源自主运行，并满足多种水资源回收目标，为未来的水处理设施提供了可行且灵活的解决方案。

> **ai_Abstract:** 本文提出了一种创新的自动控制解决方案，旨在将传统污水处理厂转变为能源自主型水资源回收设施。通过对处理水质进行分类以适应多种再利用场景，并应用输出反馈模型预测控制器（Output MPC），该系统能在满足特定水质要求的同时，产生足够沼气以实现能源自给自足。实验证明，该方法能有效管理全尺寸污水处理厂的长期运行，为现有基础设施实现能源自主和灵活的水资源回收提供了可行性证明。

> **摘要翻译:** 这项工作提出了一种自动控制解决方案，用于将传统污水处理厂（WWTP）作为能源自主型水资源回收设施运行。我们首先对处理水的质量进行了分类，以适应三种资源回收应用（环境、工业和农业用水再利用）。然后，我们提出了一种输出反馈模型预测控制器（Output MPC），该控制器运行工厂以生产特定质量等级的水，同时产生足够的沼气以确保非正能源成本。该控制器在全尺寸污水处理厂的长期运行中得到了验证，该工厂受到典型的进水负荷和周期性变化的水质目标的影响。我们的结果为现有污水处理基础设施的能源自主运行提供了概念验证，所提出的控制策略具有足够的通用性，能够适应广泛的资源回收目标。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [179] [Analyzing the performance of a V2X-enhanced braking system in real-world crash situations](https://arxiv.org/abs/2506.10535)
> *分析V2X增强型制动系统在真实碰撞情况下的性能*

*Jan Zimmermann, Jörg Mönnich, Michael Scherl, Ignacio Llatser, Florian Wildschütte, Frank Hofmann* | **Main category: eess.SY**

**Keywords:** V2X, 自动紧急制动, 防撞, 非视距, 事故模拟

**Comment:** 

> **TL;DR:** 本研究评估了V2X增强型两阶段制动系统在真实碰撞场景中的防撞性能，发现它比传统基于传感器的系统有显著优势。

**AI_Comments:** 本文的创新点在于提出了一个结合V2X和传统传感器数据的两阶段制动系统，有效解决了传统AEB在非视距环境下的性能瓶颈。通过在真实世界事故数据上进行模拟评估，增强了研究结果的说服力。这项工作对于未来智能驾驶辅助系统的发展具有重要意义，尤其是在提高系统在复杂交通环境下的可靠性和安全性方面。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自动紧急制动（AEB）系统依赖车载传感器，在非视距（non-line-of-sight）情况下可能会失效。通过利用车联网（V2X）通信，车辆可以提前接收到关于接近车辆的信息，即使有视线障碍，从而解决传统AEB的局限性。

**Method:** 本研究考虑了一个两阶段制动级联系统，包括一个基于V2X信息触发的部分制动和一个传感器触发的AEB。研究人员使用事故模拟框架，评估了该系统在从德国深度事故研究（GIDAS）数据库中提取的真实碰撞情况下的防撞性能。结果与纯传感器触发的AEB系统和纯V2X触发的部分制动进行了比较，并分析了未能避免碰撞的原因。

**Result:** 模拟结果表明，与单独使用基于视觉的传感器系统进行自动防撞相比，V2X增强型制动系统具有显著的附加优势。

**Conclusion:** V2X增强型制动系统在自动防撞方面显示出比传统传感器系统更高的性能和附加价值，尤其是在非视距情况下。

> **ai_Abstract:** 本研究提出并评估了一种V2X增强型两阶段制动系统，该系统结合了V2X信息触发的部分制动和传感器触发的自动紧急制动（AEB），旨在克服传统AEB在非视距情况下的局限性。通过使用来自GIDAS数据库的真实碰撞场景进行模拟，结果表明，与仅使用传感器或纯V2X触发的制动系统相比，V2X增强型系统在碰撞避免方面提供了显著的改进。

> **摘要翻译:** 通过使用自动制动系统，例如自动紧急制动（AEB），可以在驾驶员未意识到即将发生碰撞的情况下避免事故。然而，传统的AEB系统通过车载传感器系统（如雷达和摄像头）检测潜在的碰撞对手，这些系统在非视距情况下可能会失效。通过利用车联网（V2X）通信，即使对手车辆被视线障碍物遮挡，本车也能在早期接收到关于接近车辆的信息。在这项工作中，我们考虑了一个两阶段制动级联，包括基于V2X信息触发的部分制动和传感器触发的AEB。我们使用事故模拟框架，评估了其在从德国深度事故研究（GIDAS）数据库中提取的真实碰撞情况下的防撞性能。结果与传感器触发的AEB系统和纯V2X触发的部分制动进行了比较。为了进一步分析结果，我们确定了测试制动功能未能避免碰撞的每种情况下的碰撞原因。模拟结果显示，与单独使用基于视觉的传感器系统进行自动碰撞预防相比，V2X增强型制动系统具有很高的附加效益。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [193] [Joint System Modeling Approach for Fault Simulation of Start-er/Generator and Gas Generator in All-Electric APU](https://arxiv.org/abs/2506.10562)
> *全电APU启动机/发电机与燃气发生器故障模拟的联合系统建模方法*

*Haotian Mao, Yingqing Guo* | **Main category: eess.SY**

**Keywords:** 全电APU, 故障模拟, 联合系统建模, 多速率混合仿真, 匝间短路故障

**Comment:** 

> **TL;DR:** 本文提出一种联合系统建模方法，用于全电APU启动机/发电机和燃气发生器故障模拟，解决了机电耦合、仿真精度与计算效率平衡等挑战。

**AI_Comments:** 该论文的创新之处在于提出了一个多速率连续-离散混合仿真架构，有效地整合了机电耦合系统（启动机/发电机和燃气发生器）的故障模拟，并解决了精度与效率的平衡问题。其改进的GasTurb-DLL建模方法和多环路故障建模也提升了仿真准确性。这项工作为全电APU的故障诊断与隔离研究提供了重要的建模工具和基础。

<details>
  <summary>Details</summary>

**Motivation:** 解决全电APU故障模拟中机电耦合、仿真精度和计算效率平衡的挑战。

**Method:** 提出多速率连续-离散混合仿真架构：启动机/发电机作为Simulink中变步长连续系统，燃气发生器作为DLL环境中定步长离散系统。对启动机/发电机故障建模采用多环路方法模拟匝间短路故障。对燃气发生器开发改进型GasTurb-DLL建模方法（IGDM），增强不确定性建模、状态空间表示和工具链兼容性。

**Result:** 该方法在APS5000全电APU案例研究中实施。通过将稳态、瞬态、健康和故障条件下的仿真结果与第三方软件和文献参考数据进行比较，验证了模型。结果显示高度一致性，证实了模型的准确性和建模方法的有效性。

**Conclusion:** 这项工作为研究全电APU故障检测与隔离（FDI）带来的机遇和挑战（包括联合故障估计和诊断、耦合机电故障特性）奠定了建模基础。

> **ai_Abstract:** 本文提出一种创新的联合系统建模方法，用于全电APU的启动机/发电机与燃气发生器故障模拟。为克服机电耦合、仿真精度与效率平衡的挑战，作者设计了一种多速率连续-离散混合仿真架构，并分别针对启动机/发电机和燃气发生器开发了特定的故障建模技术（多环路方法和IGDM）。通过与参考数据的对比验证，证实了模型的高准确性和方法的有效性，为未来的故障检测与隔离研究奠定了基础。

> **摘要翻译:** 本文提出了一种用于全电辅助动力装置（APU）故障模拟的联合系统建模方法，该方法将启动机/发电机匝间短路（TTSC）故障与燃气发生器气路故障相结合。为解决机电耦合、仿真精度和计算效率平衡的挑战，我们提出了一种多速率连续-离散混合仿真架构。该架构将启动机/发电机视为Simulink中具有可变步长的连续系统，而将燃气发生器建模为动态链接库（DLL）环境中的固定步长离散系统。对于启动机/发电机故障建模，采用多环路方法精确模拟匝间短路故障。对于燃气发生器，我们开发了一种改进的GasTurb-DLL建模方法（IGDM），该方法增强了不确定性建模、状态空间表示和工具链兼容性。最后，上述提出的方法在基于APS5000全电APU结构和参数的案例研究中得以实施。通过将仿真结果（涵盖稳态、瞬态、健康和故障条件）与第三方软件和文献的参考数据进行比较，进行了模型验证。高度一致性证实了模型的准确性和我们建模方法的有效性。这项工作为研究全电APU全电气化带来的故障检测与隔离（FDI）的机遇和挑战（包括联合故障估计和诊断、耦合机电故障特性）奠定了建模基础。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [208] [Transient performance of MPC for tracking without terminal constraints](https://arxiv.org/abs/2506.10589)
> *无终端约束跟踪MPC的瞬态性能*

*Nadine Ehmann, Matthias Köhler, Frank Allgöwer* | **Main category: eess.SY**

**Keywords:** 模型预测控制, 跟踪MPC, 瞬态性能, 终端约束, 渐近分析

**Comment:** 

> **TL;DR:** 本文分析了无终端成本和终端约束的跟踪MPC方案的瞬态性能，并推导了其性能估计，同时证明了在预测范围趋于无穷大时，该方案能恢复无限范围最优解。

**AI_Comments:** 本文对跟踪MPC在无终端约束条件下的瞬态性能进行了深入分析，提供了重要的理论保证，特别是其与无限范围最优解的渐近一致性，这对于实际应用中MPC参数的选择和性能评估具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 分析一种新引入的跟踪模型预测控制（MPC）方法的性能，该方法通过引入人工参考扩展了标准MPC，以跟踪外部和可能时变参考，特别是在没有终端成本和终端约束的情况下。

**Method:** 通过理论分析，推导了在任意时间间隔内闭环性能的瞬态估计（即边界），并研究了当预测范围和观测时间间隔趋于无穷大时的渐近情况。

**Result:** 推导出了闭环性能在任意时间间隔上的瞬态性能估计（边界），为选择方案参数提供了指导。此外，证明了在渐近情况下，跟踪MPC的闭环解决方案能够恢复无限范围最优解。

**Conclusion:** 在没有终端成本和终端约束的情况下，跟踪MPC方案的瞬态性能可以被估计，并且在预测范围足够大时，其渐近性能与无限范围最优解一致。

> **ai_Abstract:** 本文研究了无终端成本和终端约束的跟踪模型预测控制（MPC）的瞬态性能。作者推导了任意时间间隔内闭环性能的瞬态估计，为参数选择提供了依据。研究还表明，在预测范围和观测时间间隔趋于无穷大时，该方案的闭环解可以恢复无限范围最优解。

> **摘要翻译:** 跟踪模型预测控制（MPC）是一种最近引入的方法，它通过将人工参考作为额外的优化变量，扩展了标准MPC公式，以跟踪外部和可能时变参考。在这项工作中，我们分析了这种没有终端成本和终端约束的跟踪MPC方案的性能。我们推导了一个瞬态性能估计，即在任意时间间隔内闭环性能的边界，从而为如何选择方案参数以获得良好性能提供了见解。此外，我们还表明，在渐近情况下，当预测范围和观测时间间隔趋于无穷大时，跟踪MPC的闭环解决方案能够恢复无限范围最优解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [225] [Sampling-Based Planning Under STL Specifications: A Forward Invariance Approach](https://arxiv.org/abs/2506.10739)
> *基于采样的STL规范下规划：一种前向不变性方法*

*Gregorio Marchesini, Siyuan Liu, Lars Lindemann, Dimos V. Dimarogonas* | **Main category: eess.SY**

**Keywords:** 采样规划, STL规范, 前向不变性, RRT*, 线性系统

**Comment:** 

> **TL;DR:** 该论文提出了一种新的RRT*算法变体，利用前向不变性为线性系统在STL规范下规划轨迹，提高了现有方法的扩展性。

**AI_Comments:** 本文通过将控制理论概念（前向不变性）与基于采样的规划（RRT*）相结合，提出了一种创新方法，解决了STL规范下轨迹合成的挑战性问题。其通过避免复杂的优化技术来提高扩展性的重点是一个重要贡献。利用线性规划进行任务编码和非光滑分析进行不变性证明显示出强大的理论基础。实际应用示例突出了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 以前使用基于采样的方法在STL规范下规划轨迹（利用混合整数或非光滑优化技术）在规划范围和任务复杂性方面扩展性较差，本文旨在解决此问题。

**Method:** 该方法采用基于集合前向不变性概念的控制理论视角。它通过线性规划将STL任务（在多面体谓词上定义）有效地编码成一个时变集合，使得在该集合内演化的轨迹也满足任务。然后通过非光滑分析证明了所得集合相对于系统动力学和输入限制的前向不变性。最后，提出了一种改进的RRT*算法，通过在前述构建的时变集合内采样轨迹树，合成满足给定STL规范的渐近最优且动态可行的轨迹。

**Result:** 该方法能够合成满足给定STL规范的渐近最优且动态可行的轨迹。通过国际空间站的自主检查和需要定时重新访问充电站的房间服务任务两个用例展示了其有效性。

**Conclusion:** 该论文成功提出了一种新的RRT*变体，利用前向不变性有效地为线性系统在STL规范下合成轨迹，解决了先前方法的扩展性问题。

> **ai_Abstract:** 本文提出了一种新颖的RRT*算法变体，用于为线性系统在信号时序逻辑（STL）规范下规划渐近最优和动态可行的轨迹。与先前因优化技术导致扩展性差的采样方法不同，本文采用基于集合前向不变性的控制理论方法。它通过线性规划将STL任务高效编码为时变集合，确保集合内的轨迹满足任务要求，并从数学上证明了前向不变性。改进的RRT*算法在此集合内进行采样。该方法通过国际空间站自主检查和房间服务任务等用例展示了其有效性。

> **摘要翻译:** 我们提出了一种快速探索随机树星 (RRT*) 算法的变体，用于为线性系统合成满足信号时序逻辑 (STL) 片段中表达的给定时空规范的轨迹。以前使用基于采样的方法在 STL 规范下规划轨迹的方法利用混合整数或非光滑优化技术，在规划范围和任务复杂性方面扩展性较差。我们转而采用基于集合前向不变性概念的控制理论视角来解决该问题。具体来说，对于在多面体谓词上定义的给定 STL 任务，我们开发了一种新颖的算法框架，通过线性规划将任务有效地编码成一个时变集合，使得在该集合内演化的轨迹也满足任务。然后通过非光滑分析证明了所得集合相对于系统动力学和输入限制的前向不变性。然后，我们提出了一种改进的 RRT* 算法，通过在前述构建的时变集合内采样轨迹树，合成满足给定 STL 规范的渐近最优且动态可行的轨迹。我们展示了我们方法的两个用例，包括国际空间站的自主检查和需要定时重新访问充电站的房间服务任务。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [238] [Joint Beamforming with Extremely Large Scale RIS: A Sequential Multi-Agent A2C Approach](https://arxiv.org/abs/2506.10815)
> *采用超大规模RIS的联合波束成形：一种序列多智能体A2C方法*

*Zhi Chai, Jiajie Xu, Justin P Coon, Mohamed-Slim Alouini* | **Main category: eess.SY**

**Keywords:** 超大规模RIS, 联合波束成形, 深度强化学习, 序列多智能体A2C, MU-MIMO

**Comment:** 

> **TL;DR:** 提出了一种基于序列多智能体A2C的深度强化学习算法，用于解决超大规模RIS辅助MU-MIMO系统中基站预编码和RIS相位的联合优化问题，该算法在计算复杂度更低的同时，性能优于基准算法。

**AI_Comments:** 该论文通过引入深度强化学习中的序列多智能体A2C方法，为超大规模RIS场景下的联合波束成形提供了一种新颖的解决方案。其创新点在于将复杂的联合优化问题建模为多智能体强化学习任务，并考虑了实际系统中的非理想因素。该方法在降低计算复杂度的同时提升了性能，这对于未来大规模MIMO和RIS部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在RIS辅助的多用户多输入多输出(MU-MIMO)场景中，当RIS尺寸变得超大时，同时优化基站(BS)预编码矩阵和可重构智能表面(RIS)相位是一个具有挑战性的问题。

**Method:** 提出了一种名为序列多智能体优势Actor-Critic (A2C) 的深度强化学习算法来解决该问题。该方法还考虑了RIS的离散相位、不完善的信道状态信息(CSI)以及用户间的信道相关性。

**Result:** 提出的算法的计算复杂度低于基准算法，同时在总谱效率(SE)方面性能优于基准算法。仿真结果还表明，该算法对中等信道估计误差具有鲁棒性。

**Conclusion:** 提出的序列多智能体A2C算法能够有效解决超大规模RIS辅助MU-MIMO系统中的联合波束成形问题，在降低计算复杂度的同时提升了性能，并对信道估计误差具有鲁棒性。

> **ai_Abstract:** 本文针对超大规模RIS辅助MU-MIMO系统中基站预编码和RIS相位的联合优化难题，提出了一种基于序列多智能体优势Actor-Critic (A2C) 的深度强化学习算法。该算法考虑了RIS离散相位、不完善CSI和用户信道相关性，并通过仿真验证了其在计算复杂度更低的同时，总谱效率性能优于传统零迫波束成形器，且对中等信道估计误差具有鲁棒性。

> **摘要翻译:** 在RIS辅助的多用户多输入多输出(MU-MIMO)场景中，当RIS的尺寸变得超大时，同时优化基站(BS)预编码矩阵和可重构智能表面(RIS)相位是一个具有挑战性的问题。在本文中，我们提出了一种名为序列多智能体优势Actor-Critic (A2C) 的深度强化学习算法来解决这个问题。此外，论文还考虑了RIS的离散相位、不完善的信道状态信息(CSI)以及用户间的信道相关性。论文分析了计算复杂度，并将所提出算法的性能与零迫(ZF)波束成形器在总谱效率(SE)方面进行了比较。值得注意的是，所提出算法的计算复杂度低于基准算法，而性能优于基准算法。通过仿真，还发现所提出算法对中等信道估计误差具有鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [250] [A Robust Optimization Framework for Flexible Industrial Energy Scheduling: Application to a Cement Plant with Market Participation](https://arxiv.org/abs/2506.10824)
> *柔性工业能源调度的鲁棒优化框架：在参与市场的化工厂中的应用*

*Sebastián Rojas-Innocenti, Enrique Baeyens, Alejandro Martín-Crespo, Sergio Saludes-Rodil, Fernando Frechoso Escudero* | **Main category: eess.SY**

**Keywords:** 鲁棒优化, 能源调度, 工业柔性, 不确定性, 混合整数线性规划

**Comment:** 

> **TL;DR:** 本文提出了一个基于情景的鲁棒优化框架，用于电力密集型工业工厂的短期能源调度，以应对不确定性，并通过一个混合整数线性规划模型，结合期望和最坏情况操作成本，实现在水泥厂案例中对电力价格不确定性的有效管理，显示出更好的弹性、更低的成本变异性和更一致的运营。

**AI_Comments:** 这篇论文的创新点在于提出了一个结合情景生成和鲁棒优化的两阶段MILP框架，有效地处理了工业能源调度中的不确定性。其凸目标函数设计允许灵活调整风险偏好，这在实际应用中非常重要。将模型应用于真实水泥厂案例并验证其在电价不确定性下的性能，增强了其实用性和说服力。该研究为工业能源管理提供了宝贵的工具，有助于提高运营效率和应对市场波动。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决电力密集型工业工厂在短期能源调度中面临的不确定性问题，特别是电力价格、可再生能源发电和内部需求等输入的不确定性，以提高调度决策的鲁棒性和经济性。

**Method:** 该研究提出了一个基于情景的鲁棒优化框架，将其建模为一个两阶段混合整数线性规划（MILP）。该框架整合了混合情景生成方法来表示不确定输入（如电价、可再生能源发电和内部需求），并采用结合期望和最坏情况操作成本的凸目标函数来实现可调的风险规避。该方法在水泥制造案例中应用，仅考虑日前电价的不确定性。

**Result:** 结果表明，该框架提高了对预测偏差的弹性，降低了成本变异性，并实现了更一致的运营。它确保了在所有情景下的可行性，并支持工业柔性资产（包括电池储能和可转移生产）的协调使用。

**Conclusion:** 本文提出的方法为不确定性下的工业柔性规划提供了一种可扩展且风险感知的途径，有效提升了电力密集型工业工厂能源调度的鲁棒性和经济效益。

> **ai_Abstract:** 本文提出了一种基于情景的鲁棒优化框架，用于电力密集型工业工厂的短期能源调度，以解决规划中的不确定性。该模型被构建为两阶段混合整数线性规划，并结合了能够模拟不确定输入（如电价和可再生能源）的混合情景生成方法。通过结合期望和最坏情况操作成本的凸目标函数，该框架实现了可调的风险规避。在水泥厂案例研究中的应用表明，该方法显著提高了对预测偏差的弹性，降低了成本波动性，并实现了更稳定的运营，为不确定性下的工业柔性规划提供了一种可扩展且风险感知的方法。

> **摘要翻译:** 本文提出了一个基于情景的鲁棒优化框架，用于电力密集型工业工厂的短期能源调度，明确解决了规划决策中的不确定性。该模型被表述为一个两阶段混合整数线性规划（MILP），并整合了一种混合情景生成方法，能够表示电力价格、可再生能源发电和内部需求等不确定输入。结合期望和最坏情况操作成本的凸目标函数允许可调的风险规避，使规划者能够平衡经济性能和鲁棒性。由此产生的调度确保了在所有情景下的可行性，并支持工业柔性资产（包括电池储能和可转移生产）的协调使用。为了隔离市场波动的影响，该框架应用于一个真实的 सीमेंट 制造案例研究，仅考虑日前电价不确定性，所有其他输入均被视为确定性。结果显示出对预测偏差的改进弹性、降低的成本变异性和更一致的运营。所提出的方法为不确定性下的工业柔性规划提供了一种可扩展且风险感知的途径。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [262] [General Reference Frame Identification and Transformation in Unbalanced Power Systems](https://arxiv.org/abs/2506.10835)
> *不平衡电力系统中的通用参考系识别与变换*

*Francisco G. Montoya, Santiago Sánchez Acevedo* | **Main category: eess.SY**

**Keywords:** 通用变换, 不平衡电力系统, 几何代数, 参考系, 多维系统

**Comment:** 

> **TL;DR:** 本文提出了一种基于几何代数的新型通用变换方法，用于不平衡电力系统中的参考系识别和变换，该方法适用于任意不平衡程度的n相、(n+1)线系统，计算效率高，且包含现有技术。

**AI_Comments:** 本文的创新之处在于提出了一种基于几何代数的新型通用变换，能够直接处理多维不平衡系统，且仅需少量测量数据，显著提高了计算效率。其通用性使其能涵盖并超越现有技术，如经典的Clarke变换，这代表了不平衡电力系统分析领域的一大进步。

<details>
  <summary>Details</summary>

**Motivation:** 坐标变换在电力系统稳定性分析、电机建模和电力电子变换器控制等领域带来了显著益处，主要优点是降维，从而降低了问题复杂性。

**Method:** 本文提出了一种基于几何框架的新型通用变换方法，通过使用几何代数中的双向量分析，直接识别包含不平衡量轨迹的平面。

**Result:** 所提出的方法提供了一种直接变换，适用于n相、(n+1)线正弦系统中任意程度的不平衡。该变换仅需要两个不同时间点的测量值（电压或电流），计算效率高。此外，通过纯几何推理证明，该方法具有通用性，并包含了经典Clarke变换等其他技术。数值模拟和实验验证表明了该方法的有效性。

**Conclusion:** 将该方法推广到多维系统，并结合其减少的测量需求，代表了相对于现有方法的重大进步，现有方法通常仅限于三相应用或存在计算限制。

> **ai_Abstract:** 本文提出了一种基于几何代数和双向量分析的新型通用变换方法，用于不平衡电力系统中的参考系识别和变换。该方法能够直接识别不平衡量轨迹所在的平面，并适用于任意程度不平衡的n相、(n+1)线系统。其仅需两次测量，计算效率高，且能推广到多维系统，包含并超越了如Clarke变换等现有技术。数值模拟和实验验证证实了其有效性和优越性。

> **摘要翻译:** 各种领域，如电力系统稳定性分析、电机建模和电力电子变换器控制，都从坐标变换的应用中显著受益。其中一个主要好处是降维，这降低了问题的复杂性。本文引入了一种基于几何框架的新型通用变换，通过使用几何代数中的双向量分析直接识别包含不平衡量轨迹的平面。所提出的方法提供了一种直接变换，适用于n相、(n+1)线正弦系统中任意程度的不平衡。该变换仅需要两个不同时间点的测量值（电压或电流），使其计算效率高。此外，我们通过纯几何推理证明，我们的方法具有通用性，并包含了经典Clarke变换等其他技术。使用实时数字模拟器和物理实验室设置进行的数值模拟和实验验证证明了所提出方法的有效性。这种向多维系统的推广，结合减少的测量需求，代表了相对于现有方法的重大进步，现有方法通常仅限于三相应用或存在计算限制。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [276] [Data-Driven Model Reduction by Moment Matching for Linear and Nonlinear Parametric Systems](https://arxiv.org/abs/2506.10866)
> *基于矩匹配的数据驱动模型降阶方法用于线性和非线性参数系统*

*Hanqing Zhang, Junyu Mao, Mohammad Fahim Shakib, Giordano Scarciotti* | **Main category: eess.SY**

**Keywords:** 模型降阶, 矩匹配, 参数系统, 数据驱动, 非线性系统

**Comment:** 16 pages, 6 figures, submitted to IEEE Transactions on Automatic
  Control

> **TL;DR:** 本文提出了通过矩匹配获取参数降阶模型的理论和方法，包括参数矩的定义以及近似方法（基于模型和数据驱动），并利用这些近似构建了保持系统关键特性的参数降阶模型族。

**AI_Comments:** 本文的创新点在于提出了参数矩的定义以及基于数据驱动的参数矩近似方法，这为复杂参数系统的模型降阶提供了一种新颖且实用的途径。该方法能够有效保留系统关键特性，对于工程应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出通过矩匹配获得参数降阶模型的理论和方法，以有效地处理线性和非线性参数系统，同时保留关键系统特性。

**Method:** 本文引入了参数矩的定义，并提出了基于模型和数据驱动的方法来近似线性和非线性参数系统的参数矩。这些近似被用于构建参数降阶模型族，这些模型能够匹配系统的近似参数矩并保持渐近稳定性和耗散性等关键系统属性。

**Result:** 本文展示了通过所提出的方法构建的参数降阶模型族能够匹配近似的参数矩并保留系统关键特性。通过线性参数基准模型和大型风电场非线性模型进行了方法的使用说明，并对提出的近似方法进行了比较和优缺点讨论。

**Conclusion:** 本文成功提出了通过矩匹配获取参数降阶模型的理论和方法，并证明了其在处理线性和非线性参数系统时的有效性，同时能够保持关键系统属性。

> **ai_Abstract:** 本文提出了一套通过矩匹配实现线性和非线性参数系统数据驱动模型降阶的理论和方法。研究引入了参数矩的概念，并开发了基于模型和数据驱动的近似方法。这些方法用于构建能匹配系统近似参数矩并保持渐近稳定性和耗散性等关键属性的参数降阶模型。通过线性基准模型和非线性风电场模型验证了方法的有效性，并对不同近似方法的优缺点进行了比较和讨论。

> **摘要翻译:** 本文提出了通过矩匹配获取参数降阶模型的理论和方法。文中介绍了参数矩的定义，并提出了近似线性和非线性参数系统参数矩的方法（基于模型和数据驱动）。这些近似被用于构建参数降阶模型族，这些模型能够匹配待降阶系统的近似参数矩，并保留渐近稳定性和耗散性等关键系统属性。通过一个线性案例的参数基准模型和一个非线性案例的大型风电场模型，说明了模型降阶方法的使用。在说明中，对所提出的近似方法进行了比较，并讨论了它们的优缺点。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [19] [Deep Semantic Segmentation for Multi-Source Localization Using Angle of Arrival Measurements](https://arxiv.org/abs/2506.10107)
> *深度语义分割在基于到达角测量的多源定位中的应用*

*Mustafa Atahan Nuhoglu, Hakan Ali Cirpan* | **Main category: eess.SP**

**Keywords:** 多源定位, 到达角测量, 深度学习, 语义分割, UNetPP

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习语义分割（使用UNet和UNetPP）的方法，用于在接收平台移动、信源静止的动态环境下，仅通过到达角测量进行多源定位。

**AI_Comments:** 这篇论文的创新点在于将深度学习中的语义分割技术引入多源定位问题，有效地解决了传统方法在高噪声和多源动态环境下定位精度不足的痛点。利用图像编码和交点分析的思路新颖，为复杂环境下的定位提供了新的解决方案，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有单源定位方法众多，但针对动态环境下多源定位的研究存在显著空白，且传统方法可能不适用于高噪声和多源复杂条件。

**Method:** 提出一个基于深度学习的框架，利用语义分割模型（具体为UNet和UNetPP）进行多源定位。输入图像编码了平台位置和对应的测向线，模型通过分析这些线的交点来识别和定位多个信源。

**Result:** 在单源定位方面与传统方法表现相当；在多源定位方面，即使在高噪声和信源数量增加的挑战性条件下，也能实现准确的信源定位。

**Conclusion:** 提出的深度学习方法能有效解决动态环境下的多源定位问题，尤其在高噪声和多源场景下表现出色。

> **ai_Abstract:** 本文针对动态环境下仅利用到达角测量进行多源定位的挑战，提出了一种创新的深度学习框架。该框架采用UNet和UNetPP等语义分割模型，将平台位置和测向线编码为输入图像，并通过分析这些线的交点来精确识别和定位多个静止信源。仿真结果表明，该方法在单源定位上与传统方法相当，但在高噪声和多源复杂场景下展现出更优越的定位精度。

> **摘要翻译:** 本文提出了一种仅使用到达角测量进行多源定位的解决方案。接收平台处于运动状态，而信源假定为静止。尽管存在许多用于单源定位的方法，其中许多依赖伪线性公式或非凸优化技术，但在动态环境下解决多源定位的研究仍存在显著空白。为了弥补这一空白，我们提出了一种基于深度学习的框架，该框架利用语义分割模型进行多源定位。具体而言，我们采用UNet和UNetPP作为骨干模型，处理编码了平台位置以及每个位置相应测向线的输入图像。通过分析这些线的交点，模型有效地识别并定位多个信源。通过仿真，我们评估了单源和多源定位场景。我们的结果表明，虽然所提出的方法在单源定位中与传统方法表现相当，但即使在高噪声水平和信源数量增加的挑战性条件下，它也能实现准确的信源定位。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [46] [Quantifying Data Requirements for EEG Independent Component Analysis Using AMICA](https://arxiv.org/abs/2506.10156)
> *使用AMICA量化EEG独立成分分析的数据需求*

*Gwenevere Frank, Seyed Yahya Shirazi, Jason Palmer, Gert Cauwenberghs, Scott Makeig, Arnaud Delorme* | **Main category: eess.SP**

**Keywords:** EEG, 独立成分分析, AMICA, 数据量, 分解质量

**Comment:** 

> **TL;DR:** 研究了AMICA在EEG独立成分分析中数据量与通道数对分解质量的影响，发现数据量越多，分解质量越好，且没有明确的上限。

**AI_Comments:** 这项研究深入探讨了EEG独立成分分析中一个关键但常被忽视的因素——数据量。其发现挑战了传统观念，即数据量达到一定阈值后收益递减，为EEG实验设计和数据收集提供了新的视角和指导，鼓励研究者收集更多数据以期获得更优的ICA分解结果，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 过去的ICA研究主要关注算法和参数配置，而数据量对EEG独立成分分析（ICA）分解质量的影响尚未被充分探索，鉴于ICA对高质量数据的需求，有必要量化数据量与通道数对分解质量的影响。

**Method:** 在一个包含13个受试者的71通道EEG数据集上运行AMICA分解，通过随机抽样数据以对应数据集中帧数与通道数的特定比例来改变数据量。分解质量通过互信息减少量（MIR）和成分的近偶极性进行评估。

**Result:** 随着数据量的增加，互信息减少量（MIR）呈渐近趋势增加，成分的近偶极性也普遍增加。然而，这些指标没有观察到明确的平台期。

**Conclusion:** 收集额外EEG数据的好处可能超出常见的经验阈值，并继续提高独立成分分析的分解质量。

> **ai_Abstract:** 本文旨在量化在使用AMICA进行EEG独立成分分析时，数据量与通道数对分解质量的影响。研究通过在一个71通道、13受试者的数据集上，随机抽样不同比例的数据帧与通道数，并以互信息减少量和近偶极性作为评估指标。结果显示，随着数据量的增加，分解质量持续提升，且未观察到明确的饱和平台期，这表明收集更多的EEG数据可能持续优化ICA分解效果，超越了传统的经验阈值。

> **摘要翻译:** 独立成分分析（ICA）是脑电图（EEG）处理中一个重要的步骤，广泛应用于各种应用。然而，ICA需要精心设计的研究和数据收集实践才能产生最佳结果。过去的研究主要集中于定量评估不同ICA算法以及AMICA（一种被认为是衡量其他算法基准的多模态ICA算法）不同参数配置产生的质量差异。本文探讨了数据量与通道数对分解质量的影响。AMICA分解在一个包含13个受试者的71通道数据集上运行，同时随机抽样数据以对应数据集中帧数与通道数的特定比例。使用互信息减少量（MIR）和成分的近偶极性指标评估了不同数据量下的分解质量。我们还注意到，随着数据量的增加，MIR呈渐近趋势增加，近偶极性也普遍呈增加趋势，但未观察到这些指标的明确平台期，这表明收集额外EEG数据的好处可能超出常见的经验阈值，并继续提高分解质量。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [71] [Intelligent Travel Activity Monitoring: Generalized Distributed Acoustic Sensing Approaches](https://arxiv.org/abs/2506.10237)
> *智能出行活动监测：通用分布式声学传感方法*

*Ruikang Zhong, Chia-Yen Chiang, Mona Jaber, Rupert De Wilde, Peter Hayward* | **Main category: eess.SP**

**Keywords:** 分布式声学传感, 深度学习, 联邦学习, 元学习, 出行监测

**Comment:** 

> **TL;DR:** 提出了一种结合深度学习的分布式声学传感（DAS）系统，用于监测步行和骑行等出行活动，通过联邦学习和元学习解决了系统泛化性问题，实现了准确、经济和保护隐私的出行监测。

**AI_Comments:** 这篇论文通过结合深度学习和分布式声学传感技术，提出了一种新颖且具有隐私保护特性的出行活动监测方案。其创新点在于利用环境振动而非传统图像或可穿戴设备，有效解决了隐私顾虑。此外，针对异构部署环境下的泛化性挑战，引入联邦学习和元学习两种策略，显著提升了系统在实际应用中的适应性。这对于推动可持续交通系统的发展和大规模智能城市基础设施建设具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了完善可持续交通系统，获取步行、慢跑和骑行等主动出行活动数据至关重要。有效的监测方案需要同时具备准确性、经济性和隐私保护性，并能适应不同气候环境和部署条件的泛化能力。

**Method:** 本文提出了一种深度学习（DL）增强的分布式声学传感（DAS）系统，通过利用DAS捕获的环境振动来推断运动模式，避免了对基于图像或可穿戴设备的依赖，从而保护隐私。为了解决异构部署环境带来的泛化挑战，根据网络可用性提出了两种方案：1）基于联邦学习（FL）的物联网（IoT）方案，使地理位置不同的DAS节点能够协作训练以提高泛化能力；2）基于元学习的离线初始化方法，用于为DL模型开发高泛化性初始化，并支持使用有限数据样本进行快速模型微调，以促进在新建立或隔离的DAS节点上的泛化。

**Result:** 在步行和骑行分类问题上的实验结果表明，所提出的深度学习增强DAS系统具有良好的性能和泛化能力。

**Conclusion:** 所提出的深度学习增强DAS系统为主动出行的实用、大规模DAS监测铺平了道路。

> **ai_Abstract:** 本文提出了一种深度学习（DL）增强的分布式声学传感（DAS）系统，旨在智能监测步行、慢跑和骑行等主动出行活动。该系统利用环境振动进行运动模式推断，避免了图像或可穿戴设备的使用，从而有效保护用户隐私。为解决系统在不同部署环境下的泛化难题，研究提出了两种创新方案：一是基于联邦学习的物联网（IoT）协同训练机制，增强不同DAS节点间的协作泛化能力；二是基于元学习的离线初始化方法，支持DL模型在数据受限的新节点上快速适应和微调。实验结果验证了该DL-增强DAS系统在步行和骑行分类任务上的优异性能和泛化能力，为未来大规模主动出行监测奠定了基础。

> **摘要翻译:** 获取步行、慢跑和骑行等主动出行活动数据对于完善可持续交通系统（STS）至关重要。有效监测这些活动不仅要求传感解决方案同时具备准确性、经济性和隐私保护性，还需要足够的泛化能力以适应不同的气候环境和部署条件。为了提供一种通用的传感解决方案，本文提出了一种深度学习（DL）增强的分布式声学传感（DAS）系统，用于监测主动出行活动。通过利用DAS捕获的环境振动，该方案无需依赖基于图像或可穿戴设备即可推断运动模式，从而解决了隐私问题。我们在两个地理位置不同的地方进行了真实世界实验，并收集了全面的数据集来评估所提出系统的性能。为了解决异构部署环境带来的泛化挑战，我们根据网络可用性提出了两种解决方案：1）提出了一种基于联邦学习（FL）的物联网（IoT）方案，它使地理位置不同的DAS节点能够协作训练以提高泛化能力；2）提出了一种由元学习实现的离线初始化方法，用于为DL模型开发高泛化性初始化，并支持使用有限数据样本进行快速模型微调，从而促进在新建立或隔离的DAS节点上的泛化。步行和骑行分类问题的实验结果证明了所提出的DL增强DAS系统的性能和泛化能力，为主动出行的实用、大规模DAS监测铺平了道路。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [97] [Ground Reaction Force Estimation via Time-aware Knowledge Distillation](https://arxiv.org/abs/2506.10265)
> *考虑时间特征的知识蒸馏在地面反作用力估计中的应用*

*Eun Som Jeon, Sinjini Mitra, Jisoo Lee, Omik M. Save, Ankita Shukla, Hyunglae Lee, Pavan Turaga* | **Main category: eess.SP**

**Keywords:** 地面反作用力, 知识蒸馏, 可穿戴传感器, 步态分析, 鞋垫传感器

**Comment:** 

> **TL;DR:** 本文提出了一种时间感知知识蒸馏框架，用于通过可穿戴鞋垫传感器数据准确估计地面反作用力，解决了传统方法便携性差或精度低的问题。

**AI_Comments:** 这篇论文的创新点在于将时间感知特性融入到知识蒸馏框架中，以提高从嘈杂的鞋垫传感器数据中估计地面反作用力的准确性。它成功地弥补了传统高精度设备便携性不足和便携式传感器精度欠佳的鸿沟，对于推动可穿戴技术在步态分析和医疗健康领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的地面反作用力（GRF）测量方法（如器械跑步机）缺乏便携性且成本高昂；而可穿戴鞋垫传感器虽然便携但易受噪声干扰且精度不足。为了解决这些挑战，实现GRF的准确、便携估计，本文提出了新的框架。

**Method:** 本文提出了一种时间感知知识蒸馏（Time-aware Knowledge Distillation）框架，用于从鞋垫传感器数据中估计地面反作用力。该框架在知识蒸馏过程中利用迷你批次内的相似性和时间特征，有效捕捉特征之间的互补关系以及目标和输入数据的序列属性。

**Result:** 经验结果表明，时间感知知识蒸馏框架在从可穿戴传感器数据中估计地面反作用力方面优于现有的基线方法。

**Conclusion:** 结合结果，可以得出结论，所提出的时间感知知识蒸馏框架能够有效提高可穿戴传感器GRF估计的准确性，为GRF的便携式、高精度测量提供了解决方案。

> **ai_Abstract:** 本文提出了一种名为“时间感知知识蒸馏”的新框架，旨在解决使用可穿戴鞋垫传感器准确估计地面反作用力（GRF）的挑战。针对传统器械跑步机缺乏便携性和高成本，以及鞋垫传感器精度不足的问题，该框架通过利用迷你批次内的相似性和时间特征，有效提升了GRF估计的性能。实验结果表明，该方法在从可穿戴传感器数据中估计GRF方面优于现有基线。

> **摘要翻译:** 人体步态分析与可穿戴传感器已广泛应用于日常生活保健、康复、物理治疗以及临床诊断和监测等各种应用中。其中，地面反作用力（GRF）提供了关于身体在运动过程中如何与地面相互作用的关键信息。尽管器械跑步机已被广泛用作测量步行GRF的“金标准”，但其缺乏便携性和高成本使其在许多应用中不切实际。作为替代方案，低成本、便携式、可穿戴鞋垫传感器已被用于测量GRF；然而，这些传感器易受噪声和干扰影响，且精度低于跑步机测量。为了应对这些挑战，我们提出了一种时间感知知识蒸馏框架，用于从鞋垫传感器数据中估计GRF。该框架在知识蒸馏过程中利用迷你批次内的相似性和时间特征，有效捕捉特征之间的互补关系以及目标和输入数据的序列属性。通过该框架蒸馏出的轻量级模型的性能通过比较鞋垫传感器数据的GRF估计值与器械跑步机的测量值进行了评估。经验结果表明，时间感知知识蒸馏在从可穿戴传感器数据中估计GRF方面优于当前的基线方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [121] [Heterogeneous-IRS-Assisted MIMO Systems: Channel Estimation and Beamforming](https://arxiv.org/abs/2506.10350)
> *异构IRS辅助的MIMO系统：信道估计与波束成形*

*Weibiao Zhao, Qiucen Wu, Yuanqi Tang, Yu Zhu* | **Main category: eess.SP**

**Keywords:** 异构智能反射面, 信道估计, 波束成形, MIMO系统, 功耗

**Comment:** 30 pages, 8 figures

> **TL;DR:** 提出了一种异构智能反射面(HE-IRS)结构，并为其设计了高效的信道估计和波束成形方案，实现了在降低功耗的同时保持性能。

**AI_Comments:** 这篇论文的创新点在于提出了异构IRS（HE-IRS）这一新颖的结构，有效解决了传统IRS功耗过高的问题，实现了性能与能耗的平衡。其将信道分解为DTE和STE部分进行估计的方法，以及针对性设计的波束成形算法，都体现了对HE-IRS独特结构的深刻理解和有效利用。这项工作对于推动绿色通信技术和IRS的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统IRS由于反射单元和控制电路数量多，功耗不容忽视。为了平衡性能和功耗，需要一种更绿色的IRS结构。

**Method:** 提出异构IRS (HE-IRS)，集成动态可调元件(DTEs)和静态可调元件(STEs)。将HE-IRS信道分解为基于DTE的级联信道和基于STE的等效信道，并利用固有稀疏性和流形优化提出高效信道估计算法。开发鲁棒的秩选择规则以解决不完善信道稀疏信息中的秩不匹配问题。提出离线算法优化STE相移以实现宽波束覆盖，并提出在线算法利用估计的HE-IRS信道优化基站预编码器和DTE相移。

**Result:** 仿真结果表明，HE-IRS在相同数量元件下比传统IRS需要更少的导频开销。所提出的信道估计和波束成形方案使绿色HE-IRS在显著降低功耗的同时，实现了具有竞争力的和速率性能。

**Conclusion:** 异构IRS (HE-IRS) 是一种绿色且高效的解决方案，它通过独特的DTE-STE集成结构，在信道估计和波束成形方面克服了传统IRS的挑战，并在降低功耗的同时保持了优异的系统性能。

> **ai_Abstract:** 本文研究了异构智能反射面（HE-IRS）辅助的多用户MIMO系统中的信道估计和波束成形问题。HE-IRS是一种结合了动态可调元件（DTEs）和静态可调元件（STEs）的绿色IRS结构，旨在解决传统IRS高功耗的问题。作者提出了一种将HE-IRS信道分解为DTE-based级联信道和STE-based等效信道的高效信道估计算法，并开发了鲁棒的秩选择规则。同时，设计了用于STE和DTE相移优化的离线和在线波束成形算法。仿真结果验证了HE-IRS在减少导频开销和降低功耗的同时，能保持与传统IRS相当的和速率性能。

> **摘要翻译:** 智能反射面（IRS）因其创造有利传播环境的能力而备受关注。然而，由于大量的反射元件和控制电路，传统IRS的功耗不容忽视。为了平衡性能和功耗，我们之前提出了一种异构IRS（HE-IRS），这是一种集成了动态可调元件（DTEs）和静态可调元件（STEs）的绿色IRS结构。与仅包含DTE的传统IRS相比，独特的DTE-STE集成结构在信道估计和波束成形方面带来了新的挑战。在本文中，我们研究了HE-IRS辅助的多用户多输入多输出系统中的信道估计和波束成形问题。与传统IRS中估计整体级联信道不同，我们表明HE-IRS待估计信道被分解为基于DTE的级联信道和基于STE的等效信道。利用这一点以及基于DTE和STE信道的固有稀疏性以及流形优化，我们提出了一种高效的信道估计算法。为了解决不完善信道稀疏信息中的秩不匹配问题，开发了一种鲁棒的秩选择规则。对于波束成形，我们提出了一种离线算法来优化STE相移以实现宽波束覆盖，并提出了一种在线算法来利用估计的HE-IRS信道优化基站预编码器和DTE相移。仿真结果表明，HE-IRS在相同数量元件下比传统IRS需要更少的导频开销。通过所提出的信道估计和波束成形方案，绿色HE-IRS在显著降低功耗的同时，实现了具有竞争力的和速率性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [142] [Relaxation-Free Min-k-Partition for PCI Assignment in 5G Networks](https://arxiv.org/abs/2506.10362)
> *5G网络中用于PCI分配的无松弛Min-k-分区*

*Yeqing Qiu, Chengpiao Huang, Ye Xue, Zhipeng Jiang, Qingjiang Shi, Dong Zhang, Zhi-Quan Luo* | **Main category: eess.SP**

**Keywords:** 5G网络, PCI分配, Min-k-Partition, 中国剩余定理, 罚化镜像下降

**Comment:** 

> **TL;DR:** 本文提出了一种用于5G网络中物理小区识别（PCI）分配的新框架，通过将问题分解为Min-3-Partition、Min-10-Partition和图着色问题，并利用中国剩余定理。它还开发了一种无松弛的Min-k-Partition方法，将其重新表述为二次规划并使用罚化镜像下降算法求解，实现了显著的计算效率提升和干扰减少。

**AI_Comments:** 本文的创新点在于将复杂的PCI分配问题巧妙地分解为多个子问题，并引入中国剩余定理进行整合。更重要的是，它提出了一种通用的无松弛Min-k-Partition方法，通过二次规划和PMD算法来解决，避免了传统松弛方法可能带来的精度损失。其在计算效率上的显著提升（20倍）使其在实际大规模5G网络部署中具有极高的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 物理小区识别（PCI）是5G网络中的关键参数。高效准确的PCI分配对于减轻模3干扰、模30干扰、小区间的碰撞和混淆至关重要，这些问题直接影响网络可靠性和用户体验。

**Method:** 本文提出了一种新的PCI分配框架，将问题分解为Min-3-Partition、Min-10-Partition和图着色问题，并利用中国剩余定理（CRT）。此外，通过将其重新表述为具有范数相等约束的二次规划，并使用罚化镜像下降（PMD）算法求解，开发了一种通用的无松弛Min-k-Partition方法。

**Result:** 该方法在计算效率和可伸缩性方面表现出色，显著减少了干扰，并消除了大规模5G网络中的碰撞和混淆。在真实世界数据集上的数值评估表明，与现有技术相比，计算时间减少了多达20倍。

**Conclusion:** 本文提出的方法能够提高网络性能并降低现代5G系统中的部署成本，对于大规模网络中的实时PCI优化具有高度实用性。

> **ai_Abstract:** 本文提出了一种针对5G网络中物理小区识别（PCI）分配的新型无松弛Min-k-分区框架。该框架将PCI问题分解为Min-3-Partition、Min-10-Partition和图着色问题，并利用中国剩余定理。为解决通用的Min-k-Partition问题，研究将其重新表述为带有范数相等约束的二次规划，并通过罚化镜像下降（PMD）算法求解。数值评估显示，该方法在计算效率和可伸缩性上表现卓越，显著减少了干扰，消除了碰撞和混淆，并能将计算时间缩短达20倍，对大规模5G网络的实时优化具有高度实用价值。

> **摘要翻译:** 物理小区识别（PCI）是5G网络中的关键参数。高效准确的PCI分配对于减轻模3干扰、模30干扰、小区间的碰撞和混淆至关重要，这些问题直接影响网络可靠性和用户体验。在本文中，我们提出了一种新的PCI分配框架，通过将问题分解为Min-3-Partition、Min-10-Partition和图着色问题，并利用中国剩余定理（CRT）。此外，我们开发了一种通用的无松弛Min-k-Partition方法，通过将其重新表述为具有范数相等约束的二次规划，并使用罚化镜像下降（PMD）算法求解。所提出的方法展示了卓越的计算效率和可伸缩性，显著减少了干扰，同时消除了大规模5G网络中的碰撞和混淆。在真实世界数据集上的数值评估表明，我们的方法与现有技术相比，计算时间减少了多达20倍，使其对于大规模网络中的实时PCI优化高度实用。这些结果凸显了我们方法在改善网络性能和降低现代5G系统中部署成本方面的潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [153] [Receiving RISs: Enabling Channel Estimation and Autonomous Configuration](https://arxiv.org/abs/2506.10662)
> *接收端可重构智能表面：实现信道估计与自主配置*

*George C. Alexandropoulos, Konstantinos D. Katsanos, Evangelos Vlachos* | **Main category: eess.SP**

**Keywords:** 可重构智能表面, 信道估计, MIMO, ADMM, 半无源RIS

**Comment:** 34 pages; 12 figures; book chapter

> **TL;DR:** 本章介绍了一种半无源可重构智能表面（RIS）的硬件架构和信道估计协议，通过接收导频信号和ADMM算法实现信道估计与反射系数优化，旨在提升多输入多输出（MIMO）通信系统性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个具体的半无源RIS硬件架构，并结合了新颖的信道估计协议和基于ADMM的算法。它解决了RIS在实际部署中面临的关键挑战——信道状态信息获取和智能配置。特别是利用了RIS本身的随机吸收特性来辅助信道估计，并考虑了极大MIMO信道的特性，这对于未来高频段通信具有重要意义。该研究为RIS在实际通信系统中的部署提供了重要的硬件和算法支持。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升多输入多输出（MIMO）通信系统的性能，并解决可重构智能表面（RISs）在实际应用中面临的信道估计和自主配置挑战。

**Method:** 本研究提出了一种半无源可重构智能表面（RIS）的硬件架构，该架构包含一个或多个射频链用于接收导频信号，以及一个包含基带处理单元的控制器用于执行信道估计和优化RIS反射系数。开发了一种新的信道估计协议，RIS通过可调吸收相位剖面从两个多天线终端接收非正交训练导频序列，并利用其信号处理单元估计信道。所提出的信道估计算法基于交替方向乘子法（ADMM），利用RIS的随机空间吸收采样来捕获整个信号空间，并利用极大MIMO信道的波束空间稀疏性和低秩特性。

**Result:** 广泛的数值研究表明，所提出的信道估计技术在各种系统和RIS硬件配置参数下均优于基准方案。此外，研究还展示了在RIS侧使用信道估计来动态优化其单元元件的反射系数的有效性。

**Conclusion:** 本研究成功提出了一种半无源可重构智能表面（RIS）的硬件架构和新颖的信道估计协议，通过基于ADMM的算法实现了高效的信道估计和RIS反射系数的自主优化，从而显著提升了多输入多输出（MIMO）通信系统的性能。

> **ai_Abstract:** 本章提出了一种用于提升MIMO系统性能的半无源可重构智能表面（RIS）硬件架构。该架构包含射频链和基带处理单元，能够通过接收导频信号和执行信道估计来优化RIS的反射系数。研究引入了一种新颖的信道估计协议，RIS通过可调吸收相位剖面接收非正交训练导频序列并进行信道估计。核心算法基于ADMM，利用RIS的随机采样以及极大MIMO信道的稀疏性和低秩特性。数值结果验证了该信道估计方法的优越性及其在RIS侧动态优化反射系数的有效性。

> **摘要翻译:** 本章重点介绍了一种半无源可重构智能表面（RISs）的硬件架构，并探讨了其在提升多输入多输出（MIMO）通信系统性能方面的考虑。该架构包含一个或多个射频链，通过由超表面前端实现的可调谐吸收相位剖面接收导频信号，以及一个包含基带处理单元的控制器，用于执行信道估计，进而优化RIS的反射系数。提出了一种新颖的信道估计协议，根据该协议，RIS通过可调谐吸收相位剖面从两个多天线终端接收非正交训练导频序列，然后通过其信号处理单元估计相应的信道。信道估计结果特别用于RIS控制器设计超表面前端的容量实现反射相位配置。所提出的信道估计算法基于交替方向乘子法（ADMM），受益于RIS的随机空间吸收采样以捕获整个信号空间，并利用了极大MIMO信道的波束空间稀疏性和低秩特性，这对于FR3频段及以上的通信系统尤其相关。我们广泛的数值研究表明，对于各种系统和RIS硬件配置参数，所提出的信道估计技术优于基准方案，并且在RIS侧使用信道估计来动态优化其单元元件可能经过相位量化的反射系数是有效的。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [162] [A Neural Network-aided Low Complexity Chase Decoder for URLLC](https://arxiv.org/abs/2506.10513)
> *一种神经辅助的低复杂度URLLC追逐译码器*

*Enrico Testi, Enrico Paolini* | **Main category: eess.SP**

**Keywords:** URLLC, Chase-II译码, 神经网络, 低复杂度, 译码算法

**Comment:** 

> **TL;DR:** 本文提出一种神经网络辅助的增强型Chase-II译码算法，通过预测扰动模式，显著减少译码试验次数，从而在URLLC系统中实现高可靠性和低复杂度。

**AI_Comments:** 本文的创新之处在于将神经网络引入到传统的Chase-II译码过程中，用于预测扰动模式，从而显著降低了其计算复杂度。这对于URLLC这种对延迟和资源高度敏感的应用场景具有重要意义，因为它提供了一种在性能和效率之间取得更好平衡的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 超可靠低延迟通信（URLLC）需要同时提供高可靠性和低复杂度的译码算法。现有迭代译码方案在URLLC短块长度下无法接近理论性能极限，而准最大似然（quasi-ML）译码方案（如Chase-II）虽然性能接近最优，但计算成本过高，不适合实际部署。

**Method:** 本文提出一种增强型Chase-II译码算法，该算法利用神经网络（NN）预测有前景的扰动模式，从而大幅减少所需的译码试验次数。该方法结合了准最大似然译码的可靠性与神经网络推理的效率。

**Result:** 所提出的方法结合了准最大似然译码的可靠性与神经网络推理的效率，使其非常适合时间敏感和资源受限的应用。

**Conclusion:** 本文提出的神经网络辅助的Chase-II译码器，通过减少译码试验次数，有效弥合了URLLC系统中准最大似然译码的性能与计算复杂度之间的差距。

> **ai_Abstract:** 本文针对URLLC对高可靠性和低复杂度的译码需求，指出现有迭代译码和准最大似然译码方案的局限性。为解决此问题，论文提出一种创新的神经网络辅助增强型Chase-II译码算法，通过神经网络预测扰动模式来显著减少译码试验次数，从而在保证准最大似然译码可靠性的同时，提升译码效率，使其适用于资源受限的URLLC系统。

> **摘要翻译:** 超可靠低延迟通信（URLLC）要求译码算法在严格的延迟约束下同时提供高可靠性和低复杂度。虽然用于LDPC和极性码的迭代译码方案在性能和复杂度之间提供了良好的折衷，但它们在典型的URLLC短块长度范围内未能接近理论性能极限。相反，代数码的准最大似然（quasi-ML）译码方案，如Chase-II译码，表现出与最优译码之间更小的差距，但对于URLLC系统的实际部署而言，计算成本过高。为了弥合这一差距，我们提出了一种增强型Chase-II译码算法，该算法利用神经网络（NN）预测有前景的扰动模式，从而大幅减少所需的译码试验次数。所提出的方法结合了准最大似然译码的可靠性与神经网络推理的效率，使其非常适合时间敏感和资源受限的应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [180] [Sum Rate Maximization for Pinching Antennas Assisted RSMA System With Multiple Waveguides](https://arxiv.org/abs/2506.10596)
> *多波导辅助捏合天线RSMA系统和速率最大化*

*Peiyu Wang, Hong Wang, Rongfang Song* | **Main category: eess.SP**

**Keywords:** 捏合天线, RSMA, 和速率最大化, 多波导, 波束成形

**Comment:** 

> **TL;DR:** 本文提出了一种多波导辅助捏合天线（PA）的速率分裂多址（RSMA）系统，旨在最大化和速率，并通过两步算法优化PA激活方案和波导波束成形，仿真结果表明其性能优于现有方案。

**AI_Comments:** 该论文提出了一种新颖的两步算法来解决多波导辅助RSMA系统中的和速率最大化问题，其创新点在于结合了PA激活方案的选择和波导波束成形的优化。通过采用低复杂度的PA激活选择和SDP-SCA进行波束成形，提高了系统的性能。这项工作对未来无线通信系统中集成新型天线技术和高级多址方案具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在最大化捏合天线（PAs）辅助的速率分裂多址（RSMA）系统在多波导配置下的和速率。

**Method:** 提出了一种两步算法。第一步，采用低复杂度基于空间相关性和距离的方法选择PA激活方案。第二步，在PA激活状态确定后，利用基于半正定规划（SDP）的逐次凸逼近（SCA）方法来优化波导波束成形。

**Result:** 仿真结果表明，所提出的基于多波导的PA辅助RSMA方法比各种基准方案取得了更好的性能。

**Conclusion:** 所提出的基于多波导的PA辅助RSMA方法能够有效提高系统和速率，并优于现有基准方案。

> **ai_Abstract:** 本文研究了多波导辅助的捏合天线（PAs）速率分裂多址（RSMA）系统中的和速率最大化问题。为此，提出了一种两步优化算法：首先，通过低复杂度的空间相关性和距离方法选择PA激活方案；其次，利用基于半正定规划（SDP）的逐次凸逼近（SCA）技术优化波导波束成形。仿真结果验证了所提方法相比现有基准方案具有更优的性能。

> **摘要翻译:** 本文研究了多波导辅助的捏合天线（PAs）速率分裂多址（RSMA）系统，以最大化和速率。提出了一种两步算法来确定PA激活方案并优化波导波束成形。具体而言，提出了一种低复杂度的基于空间相关性和距离的方法用于PA激活选择。在确定PA激活状态后，利用基于半正定规划（SDP）的逐次凸逼近（SCA）来获得最优的波导波束成形。仿真结果表明，所提出的基于多波导的PA辅助RSMA方法比各种基准方案取得了更好的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [209] [A Novel Signal Processing Strategy for Short-Range Laser Feedback Interferometry Sensors](https://arxiv.org/abs/2506.10705)
> *短距离激光反馈干涉传感器的新型信号处理策略*

*Alexander Zimmer, Johannes Meyer, Enkelejda Kasneci* | **Main category: eess.SP**

**Keywords:** 激光反馈干涉, 信号处理, 短距离传感器, 四斜坡调制, 可穿戴技术

**Comment:** Accepted to the 2025 25th International Conference on Digital Signal
  Processing

> **TL;DR:** 本文提出了一种新颖的信号处理策略，包括四斜坡调制方案，用于短距离激光反馈干涉（LFI）传感器，以解决传统FMCW LFI在近距离、高速和低功耗应用中的局限性，实现了可靠、低噪声的距离和速度测量。

**AI_Comments:** 该论文提出了一种创新的四斜坡调制方案，解决了短距离激光反馈干涉传感器在实际应用中遇到的关键问题，如拍频符号模糊性和频谱盲区。这对于推动紧凑型、高精度传感器在可穿戴设备等领域的应用具有重要意义。其贡献在于不仅提出了新方法，还通过噪声模型进行了性能评估，显示了其在鲁棒性和低噪声方面的优势。

<details>
  <summary>Details</summary>

**Motivation:** 可穿戴技术（如AR眼镜）的快速发展需要紧凑、节能且能在动态环境中进行高精度测量的传感器。传统的调频连续波（FMCW）激光反馈干涉（LFI）传感器在小距离、高速度、浅调制和低功耗的应用中表现不佳。

**Method:** 本文提出了一种新颖的传感器处理流程，能够可靠地提取低至1厘米的距离和速度测量值。核心贡献是引入了一种四斜坡调制方案，解决了拍频符号中持续存在的模糊性，并克服了由硬件限制引起的频谱盲区。基于已实现的流程测量，定义了一个噪声模型来评估其性能和对多个算法及工作点参数的敏感性。

**Result:** 该处理流程能够使用最先进的硬件实现鲁棒且低噪声的测量。定义了噪声模型来评估其性能和对多种算法及工作点参数的敏感性。

**Conclusion:** 该新型信号处理策略，特别是四斜坡调制方案，能够使短距离激光反馈干涉传感器在具有挑战性的应用场景中实现可靠、鲁棒且低噪声的距离和速度测量，克服了传统方法的局限性。

> **ai_Abstract:** 本文针对可穿戴技术对紧凑型高精度传感器的需求，提出了一种新型的激光反馈干涉（LFI）传感器信号处理策略。该策略旨在克服传统FMCW LFI在短距离、高速和低功耗应用中的局限性。核心创新在于引入了四斜坡调制方案，有效解决了拍频符号模糊性并消除了频谱盲区。实验结果表明，该处理流程能够实现可靠、鲁棒且低噪声的距离和速度测量，适用于低至1厘米的距离。

> **摘要翻译:** 可穿戴技术（如AR眼镜）的快速发展，要求紧凑、节能且能在动态环境中进行高精度测量的传感器。传统的调频连续波（FMCW）激光反馈干涉（LFI）传感器虽然很有前景，但在小距离、高速度、浅调制和低功耗的应用中表现不佳。我们提出了一种新颖的传感器处理流程，能够可靠地提取低至1厘米的距离和速度测量值。作为核心贡献，我们引入了一种四斜坡调制方案，解决了拍频符号中持续存在的模糊性，并克服了由硬件限制引起的频谱盲区。基于已实现的流程测量，定义了一个噪声模型来评估其性能和对多个算法及工作点参数的敏感性。我们表明，该流程通常使用最先进的硬件实现了鲁棒且低噪声的测量。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [226] [Automotive Radar Online Channel Imbalance Estimation via NLMS](https://arxiv.org/abs/2506.10841)
> *车载雷达基于NLMS的在线通道不平衡估计*

*Esmaeil Kavousi Ghafi, Oliver Lang, Matthias Wagner, Alexander Melzer, Mario Huemer* | **Main category: eess.SP**

**Keywords:** 车载雷达, 通道不平衡, NLMS, 在线估计, ADAS

**Comment:** 

> **TL;DR:** 提出了一种利用归一化最小均方（NLMS）算法在线估计车载雷达通道不平衡的新方法，该方法计算复杂度低、更新速率快，且支持多目标，适用于雷达正常运行时的并行估计。

**AI_Comments:** 该论文提出了一种实用的在线通道不平衡估计方法，其创新点在于将NLMS算法应用于雷达处理链中，实现了在无先验角度知识的情况下对通道不平衡的估计。该方法低计算复杂度、支持多目标且更新速率快，显著优于现有方法，对于提升车载雷达的可靠性和ADAS系统的安全性具有重要意义。其并行操作的特性也使其易于集成到现有雷达系统中。

<details>
  <summary>Details</summary>

**Motivation:** 车载雷达是高级驾驶辅助系统（ADAS）的关键组成部分，持续监测其功能安全性和可靠性至关重要，以防止事故并提高道路安全。雷达通道不平衡是影响雷达可靠性的一个关键参数，可能由参数变化或硬件疲劳引起，并影响诸如到达角估计等雷达处理步骤，因此需要对其进行监控。

**Method:** 本文提出了一种在线估计车载雷达通道不平衡的新方法。该方法利用归一化最小均方（NLMS）算法作为雷达处理链中的一个模块来估计通道不平衡。该模块的输入是雷达在道路上距离-多普勒图中检测到的目标，无需目标的角度参数先验知识。

**Result:** 所提出的方法具有低计算复杂度，适用于雷达正常运行时的在线通道不平衡估计。与大多数现有方法相比，它对特定感兴趣目标的依赖性更低，并且通道不平衡估计的更新速率更快。这得益于其允许角谱中存在多个目标，而大多数其他方法仅限于单个目标。该方法的性能已通过各种仿真场景验证，并得到测量结果的支持。

**Conclusion:** 本文提出了一种新颖的基于NLMS的在线车载雷达通道不平衡估计方法，该方法具有低计算复杂度、快速更新速率和多目标支持的优点，并通过仿真和测量结果验证了其有效性，显著提升了车载雷达的可靠性和安全性。

> **ai_Abstract:** 本文提出了一种基于归一化最小均方（NLMS）算法的新型在线车载雷达通道不平衡估计方法。该方法利用雷达距离-多普勒图中的检测目标作为输入，无需目标的角度先验知识。其低计算复杂度和支持多目标的特性使其能够与雷达正常操作并行进行在线估计，并实现比现有方法更快的更新速率和更低的特定目标依赖性。该方法的有效性已通过仿真和测量结果得到验证，有助于提升车载雷达的功能安全性和可靠性。

> **摘要翻译:** 车载雷达是高级驾驶辅助系统（ADAS）的重要使能技术之一。持续监测车载雷达的功能安全性和可靠性是防止事故和提高道路安全的关键要求。在此背景下，需要监测的最关键方面之一是雷达通道不平衡，因为它们是雷达可靠性的关键参数。这些不平衡可能源于多种参数变化或硬件疲劳，例如焊球断裂（SBB），并可能影响某些雷达处理步骤，例如到达角估计。在这项工作中，提出了一种在线估计车载雷达通道不平衡的新方法。所提出的方法利用归一化最小均方（NLMS）算法作为雷达处理链中的一个模块来估计通道不平衡。该模块的输入是雷达在道路上距离-多普勒图中检测到的目标，无需目标的角度参数先验知识。这一特性结合NLMS的低计算复杂度，使得所提出的方法适用于在线通道不平衡估计，与雷达的正常运行并行。此外，与大多数现有方法相比，它对特定感兴趣目标的依赖性更低，并且通道不平衡估计的更新速率更快。这一改进是通过允许角谱中存在多个目标来实现的，而大多数其他方法仅限于角谱中的单个目标。所提出方法的性能通过各种仿真场景进行了验证，并得到测量结果的支持。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [23] [The Iris File Extension](https://arxiv.org/abs/2506.10009)
> *Iris文件扩展名*

*Ryan Erik Landvater, Michael David Olp, Mustafa Yousif, Ulysses Balis* | **Main category: eess.IV**

**Keywords:** 数字病理学, 全切片图像, 文件格式, Iris, 实时传输

**Comment:** 8 pages, 6 figures

> **TL;DR:** 本文介绍了Iris，一种用于数字病理全切片图像的新型二进制文件格式，旨在实现高效的实时传输和显示，克服了DICOM等现有格式的局限性。

**AI_Comments:** 本文通过提出一种开放、供应商无关的全切片图像存储和传输标准，解决了数字病理学领域一个重要的未满足需求。其对实时性能的关注，以及腐败恢复和开源实现等强大功能，使Iris成为一项潜在的重大贡献。其开放许可模式进一步鼓励了广泛采用和协作，这对于建立新的行业标准至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有数字病理学缺乏高效的实时传输和显示供应商无关的二进制切片格式，且DICOM标准在处理全切片图像时存在检索速度限制，因此需要一种新的高性能中间数字切片格式。

**Method:** 论文引入了Iris文件扩展名，这是一种专为全切片图像系统设计的二进制文件容器规范，支持现代压缩、动态结构、文件验证和损坏恢复、以及切片注释。作者还提供了反/序列化、验证的源代码和二进制构建（支持C++、Python、JavaScript），以及完整的编码器和解码器实现。该规范以知识共享许可形式开放。

**Result:** 引入了Iris文件扩展名，一种新的二进制全切片图像格式，旨在解决数字病理学中高效实时传输和显示的需求，并提供了用于（解）序列化、验证、编码和解码的开源代码和多语言绑定二进制构建。

**Conclusion:** Iris文件扩展名作为一种开放、供应商无关的二进制全切片图像格式，解决了当前数字病理图像在高效实时传输和显示方面的不足，并通过提供开源工具促进了其应用。

> **ai_Abstract:** 本文介绍了Iris文件扩展名，一种专为数字病理学中全切片图像设计的新型开源二进制文件格式。它旨在解决高效实时传输和显示的迫切需求，弥补了DICOM等现有格式在处理大尺寸图像时的不足。Iris支持现代压缩、动态结构、强大的验证和恢复功能以及注释支持，通过将文件结构抽象到内存中实现即时切片访问。作者发布了该规范，并提供了多语言源代码和二进制构建，以便于集成到现有全切片成像解决方案中。

> **摘要翻译:** 目前尚未建立一种现代的、与供应商无关的数字病理二进制切片格式，以满足高效实时传输和显示的需求。数字病理学的日益普及，只会加剧对一种中间数字切片格式的需求，该格式应侧重于在切片服务器和图像管理软件之间使用，或用于机构间病例传输的性能。尽管DICOM标准是一种成熟的格式，广泛用于图像和关键相关元数据的长期存储，但其固有的最大图像尺寸限制可能会影响检索速度，尤其是在使用金字塔结构切片查看器应用程序访问全切片图像时。在此，我们介绍了Iris文件扩展名，这是一种专门为全切片图像系统设计的二进制文件容器规范，可以将文件结构大纲抽象到内存中以实现即时切片访问。Iris文件扩展名增加了现代压缩支持、具有可选文件功能的动态结构、计算上微不足道的深度文件验证和损坏恢复功能，以及切片注释支持。除了文件规范文档，我们还提供了源代码，以允许对二进制流进行（解）序列化和根据标准进行验证，以及带有C++、Python和JavaScript语言绑定的相应二进制构建。我们还提供了完整的编码器和解码器实现源代码，以及带有C++和Python语言绑定的二进制构建（作为独立的Iris编解码器社区模块的一部分），以便于与现有WSI解决方案轻松集成。我们以知识共享署名-禁止演绎4.0国际许可的形式，向社区公开Iris文件扩展名规范。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [50] [Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective](https://arxiv.org/abs/2506.10142)
> *从频域角度重新思考脑肿瘤分割*

*Minye Shao, Zeyu Wang, Haoran Duan, Yawen Huang, Bing Zhai, Shizheng Wang, Yang Long, Yefeng Zheng* | **Main category: eess.IV**

**Keywords:** 脑肿瘤分割, 频域, HFF-Net, MRI, 对比增强区域

**Comment:** Accepted by IEEE Transactions on Medical Imaging

> **TL;DR:** HFF-Net通过在频域处理MRI图像，显著提高了脑肿瘤（特别是对比增强区域）的分割精度，解决了现有方法对复杂纹理和方向变化考虑不足的问题。

**AI_Comments:** 该论文的创新点在于将脑肿瘤分割问题从传统的空间域转换到频域视角进行处理，通过分解图像的频率成分来更精细地捕获肿瘤特征。HFF-Net中FDD、ALC和FDCA模块的设计，特别是ALC的自适应核和FDCA的多信息融合能力，有效地解决了现有方法在处理复杂MRI肿瘤特征时的局限性。其在对比增强区域分割上的显著提升，对临床诊断和治疗规划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 精确分割脑肿瘤，特别是MRI中可见的对比增强区域，对临床诊断和治疗规划至关重要，但现有方法在分割这些区域时表现不佳，主要原因是未能充分考虑MRI特有的肿瘤特征，如复杂纹理和方向变化。

**Method:** 本文提出了谐波频率融合网络（HFF-Net），该网络从频域角度重新思考脑肿瘤分割。HFF-Net包含：1. 频率域分解（FDD）模块，将MRI图像分解为低频（捕获平滑轮廓）和高频（突出细节纹理和方向边缘）分量。2. 自适应拉普拉斯卷积（ALC）模块，使用动态更新的卷积核自适应地强调关键高频细节，增强对肿瘤边界的敏感性。3. 频率域交叉注意力（FDCA）模块，融合语义、位置和切片特异性信息，有效融合多尺度肿瘤特征。该方法还通过可视化、理论推理和实验分析验证了频域改进。

**Result:** 在四个公共数据集上的广泛实验表明，HFF-Net在三个主要子区域的平均Dice分数上实现了4.48%（2.39%至7.72%）的平均相对改进，在对比增强肿瘤区域的分割上实现了7.33%（5.96%至8.64%）的平均相对改进，同时保持了良好的计算效率和临床适用性。

**Conclusion:** HFF-Net通过从频域视角处理脑肿瘤分割，并引入FDD、ALC和FDCA模块，显著提高了脑肿瘤（尤其是对比增强区域）的分割精度，同时保持了计算效率和临床适用性。

> **ai_Abstract:** 本文提出了一种名为谐波频率融合网络（HFF-Net）的新方法，旨在通过从频域角度处理MRI图像来提高脑肿瘤分割的精度。针对现有方法在处理MRI特有肿瘤特征（如复杂纹理和方向变化）方面的不足，HFF-Net引入了频率域分解（FDD）模块来分离图像的低频和高频分量，自适应拉普拉斯卷积（ALC）模块以增强边界敏感性，以及频率域交叉注意力（FDCA）模块来有效融合多尺度特征。实验结果表明，HFF-Net在多个公共数据集上显著提升了脑肿瘤（特别是对比增强区域）的分割性能，并具有良好的计算效率和临床适用性。

> **摘要翻译:** 精确分割脑肿瘤，特别是对比增强MRI中可见的区域（通过对比剂注射突出显示的区域），对于准确的临床诊断和治疗规划至关重要，但仍然具有挑战性。然而，当前方法在分割这些增强型脑肿瘤区域时表现出显著的性能下降，这主要是由于对MRI特有的肿瘤特征（如复杂纹理和方向变化）考虑不足。为了解决这个问题，我们提出了谐波频率融合网络（HFF-Net），该网络从频域角度重新思考脑肿瘤分割。为了全面表征肿瘤区域，我们开发了一个频率域分解（FDD）模块，将MRI图像分离成低频分量（捕获平滑的肿瘤轮廓）和高频分量（突出详细的纹理和方向边缘）。为了进一步增强对肿瘤边界的敏感性，我们引入了一个自适应拉普拉斯卷积（ALC）模块，该模块使用动态更新的卷积核自适应地强调关键的高频细节。为了有效融合多尺度肿瘤特征，我们设计了一个频率域交叉注意力（FDCA），它整合了语义、位置和切片特异性信息。我们通过可视化、理论推理和实验分析进一步验证和解释了频域改进。在四个公共数据集上的广泛实验表明，HFF-Net在三个主要子区域的平均Dice分数上实现了4.48%（范围从2.39%到7.72%）的平均相对改进，在对比增强肿瘤区域的分割上实现了7.33%（范围从5.96%到8.64%）的平均相对改进，同时保持了良好的计算效率和临床适用性。代码：https://github.com/VinyehShaw/HFF。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [75] [Prompt-Guided Latent Diffusion with Predictive Class Conditioning for 3D Prostate MRI Generation](https://arxiv.org/abs/2506.10230)
> *基于提示引导的潜在扩散模型与预测性类别条件用于3D前列腺MRI生成*

*Emerson P. Grabke, Masoom A. Haider, Babak Taati* | **Main category: eess.IV**

**Keywords:** 潜在扩散模型, 医学影像, 前列腺MRI, 数据稀缺, 图像合成

**Comment:** MAH and BT are co-senior authors on the work. This work has been
  submitted to the IEEE for possible publication

> **TL;DR:** 本文提出了CCELLA，一种新颖的双头条件化方法，用于潜在扩散模型，以在有限数据下生成高质量3D前列腺MRI图像，优于现有方法并提高了分类器性能。

**AI_Comments:** 该论文的创新点在于其提出的CCELLA双头条件化方法，巧妙地结合了文本和类别条件化，以及数据高效的训练框架，这对于数据稀缺的医学影像领域至关重要。该方法在有限数据下生成高质量图像并提升下游任务性能的能力，具有重要的科学和临床意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了缓解影响医学影像机器学习发展的数据稀缺挑战，并解决现有医学潜在扩散模型（LDM）训练的局限性，如依赖短提示文本编码器、重用非医学LDM或需要大量数据进行微调。

**Method:** 提出了Class-Conditioned Efficient Large Language model Adapter (CCELLA)，这是一种新颖的双头条件化方法，通过交叉注意力将非医学大型语言模型编码的文本特征与LDM U-Net进行条件化，并通过时间步嵌入进行病理分类。同时提出了联合损失函数和数据高效的LDM训练框架。

**Result:** 在规模有限的前列腺MRI数据集上实现了0.025的3D FID分数，显著优于最近的基础模型（FID为0.071）。将本文方法生成的合成图像添加到前列腺癌预测分类器训练数据集中，可将分类器准确率从69%提高到74%。仅使用本文方法合成图像训练的分类器性能与仅使用真实图像训练的分类器性能相当。

**Conclusion:** 本文提出的策略使得病理条件化的LDM训练能够在有限数据量下进行高质量医学图像合成，从而提高LDM性能和科学可及性。

> **ai_Abstract:** 本文提出了一种名为CCELLA（Class-Conditioned Efficient Large Language model Adapter）的新型双头条件化方法，旨在解决医学影像领域数据稀缺和现有潜在扩散模型（LDM）训练的局限性。CCELLA通过将非医学大型语言模型编码的文本特征与病理分类相结合，同时引入联合损失函数和数据高效的训练框架，实现了在有限数据下生成高质量3D前列腺MRI图像。实验结果表明，该方法在3D FID分数上显著优于现有模型，并且通过添加合成图像，能有效提高前列腺癌预测分类器的准确性，证明了其在医学图像合成和机器学习发展中的潜力。

> **摘要翻译:** 潜在扩散模型（LDM）可以缓解影响医学影像机器学习发展的数据稀缺挑战。然而，医学LDM训练通常依赖于限制性能或科学可及性的策略，包括依赖短提示文本编码器、重用非医学LDM或要求大量数据进行微调。我们提出了一种类别条件高效大型语言模型适配器（CCELLA）来解决这些局限性。CCELLA是一种新颖的双头条件化方法，它通过交叉注意力和时间步嵌入中的病理分类，同时用非医学大型语言模型编码的文本特征对LDM U-Net进行条件化。我们还提出了一种联合损失函数和一种数据高效的LDM训练框架。结合这些策略，可以在有限数据量和人工数据标注的情况下，实现病理条件化的LDM训练，用于高质量医学图像合成，从而提高LDM性能和科学可及性。我们的方法在规模有限的前列腺MRI数据集上实现了0.025的3D FID分数，显著优于最近的基础模型（FID为0.071）。当训练前列腺癌预测分类器时，将我们方法生成的合成图像添加到训练数据集中，可将分类器准确率从69%提高到74%。仅使用我们方法合成图像训练的分类器性能与仅使用真实图像训练的分类器性能相当。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [101] [Conditional diffusion models for guided anomaly detection in brain images using fluid-driven anomaly randomization](https://arxiv.org/abs/2506.10233)
> *基于流体驱动异常随机化的脑图像引导异常检测条件扩散模型*

*Ana Lawry Aguila, Peirong Liu, Oula Puonti, Juan Eugenio Iglesias* | **Main category: eess.IV**

**Keywords:** 条件扩散模型, 异常检测, 脑部MRI, 流体驱动异常随机化, 弱监督学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的条件扩散模型，用于脑部MRI异常检测，利用合成异常来引导健康图像重建，性能优于其他方法。

**AI_Comments:** 该论文的创新之处在于其弱监督方法，通过使用合成生成且解剖学上连贯的伪病理图像来指导扩散模型进行健康图像重建，有效解决了传统无监督方法中“无法去除异常”的问题。这对于患病数据稀缺的罕见疾病尤为重要。其在性能上超越监督方法的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 监督学习在脑部MRI病理检测中需要难以获取的患病数据，尤其对于罕见病。现有基于重建的无监督扩散模型虽然无需患病数据，但往往无法准确重建健康组织或去除异常区域。本文旨在解决这些局限性。

**Method:** 本文引入了一种新颖的条件扩散模型框架，用于脑部MRI的异常检测和健康图像重建。该方法采用弱监督方式，通过将合成生成的伪病理图像整合到建模过程中，以更好地指导健康图像的重建。伪病理图像通过对辅助数据集中真实病理分割图应用流体驱动异常随机化生成，确保合成异常的真实性和解剖学一致性。模型使用合成异常数据集和来自ATLAS数据集的真实病理进行评估。

**Result:** 该模型在实验中表现出卓越性能，包括：(i) 持续优于变分自编码器、条件和无条件潜在扩散模型；(ii) 在大多数数据集上，性能超越了可访问配对患病/健康图像的监督修复方法。

**Conclusion:** 本文成功引入了一种新颖的、采用弱监督方法并利用合成异常的条件扩散模型，该模型在脑图像异常检测中表现出优于现有方法的性能，甚至超越了一些监督方法。

> **ai_Abstract:** 本文提出了一种新颖的弱监督条件扩散模型，用于脑部MRI的异常检测和健康图像重建。该模型通过整合由流体驱动异常随机化生成的合成伪病理图像，解决了传统无监督方法在重建过程中无法准确处理异常的局限性。实验结果表明，所提出的模型在检测脑部病理方面显著优于现有的无监督方法（如VAE和其他扩散模型），甚至在某些情况下超越了监督修复方法。

> **摘要翻译:** 监督机器学习已使脑部MRI中的病理检测变得准确，但需要来自患病受试者的训练数据，在某些情况下（例如罕见疾病）可能不容易获得。基于重建的无监督异常检测，特别是使用扩散模型，在医学领域越来越受欢迎，因为它允许仅在健康图像上进行训练，消除了对大型疾病特异性队列的需求。这些方法假设在正常数据上训练的模型无法准确表示或重建异常。然而，这个假设通常会失败，模型无法重建健康组织或准确重建异常区域，即无法去除异常。在这项工作中，我们引入了一种新颖的条件扩散模型框架，用于脑部MRI中的异常检测和健康图像重建。我们的弱监督方法将合成生成的伪病理图像整合到建模过程中，以更好地指导健康图像的重建。为了生成这些伪病理，我们应用流体驱动异常随机化来增强辅助数据集中的真实病理分割图，确保合成异常既真实又解剖学上连贯。我们使用合成异常数据集和来自ATLAS数据集的真实病理来评估我们模型检测病理的能力。在我们广泛的实验中，我们的模型：（i）始终优于变分自编码器、条件和无条件潜在扩散模型；（ii）在大多数数据集上，超越了可访问配对患病/健康图像的监督修复方法的性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [124] [DUN-SRE: Deep Unrolling Network with Spatiotemporal Rotation Equivariance for Dynamic MRI Reconstruction](https://arxiv.org/abs/2506.10309)
> *DUN-SRE：用于动态MRI重建的具有时空旋转等变性的深度展开网络*

*Yuliang Zhu, Jing Cheng, Qi Xie, Zhuo-Xu Cui, Qingyong Zhu, Yuanyuan Liu, Xin Liu, Jianfeng Ren, Chengbo Wang, Dong Liang* | **Main category: eess.IV**

**Keywords:** 深度展开网络, 时空等变性, 动态MRI重建, 心脏电影MRI, 对称先验

**Comment:** 

> **TL;DR:** DUN-SRE是一个新颖的深度展开网络，通过结合时空旋转等变性，显著改善了动态MRI重建的图像质量，尤其是在处理运动和欠采样数据方面。

**AI_Comments:** 这篇论文的创新点在于首次将时空旋转等变性引入到深度展开网络中，以解决现有等变卷积网络未能有效建模动态MRI时间对称性的问题。通过(2+1)D等变卷积架构和高保真群滤波器参数化，该方法能够更精确地捕捉心脏运动等动态过程，从而在欠采样情况下显著提高图像重建质量。这对于临床应用中快速、高质量的动态MRI成像具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动态MRI图像具有空间旋转对称性和时间对称性。虽然现有的等变卷积神经网络（ECNN）能利用空间对称性，但它们未能有效建模时间对称性，而这对于动态MRI重建至关重要且信息丰富。

**Method:** 本文提出了一种名为DUN-SRE的深度展开网络，用于动态MRI重建。该网络通过(2+1)D等变卷积架构建立时空等变性，并将数据一致性与近端映射模块整合到统一的深度展开框架中。此外，还开发了一种高保真群滤波器参数化机制，以在强制对称性约束的同时保持表示精度。

**Result:** 在心脏电影MRI数据集上的综合实验表明，DUN-SRE实现了最先进的性能，尤其在保留旋转对称结构方面表现出色，并对广泛的动态MRI重建任务展现出强大的泛化能力。

**Conclusion:** DUN-SRE通过有效整合时空旋转等变性，显著提升了动态MRI重建的图像质量，尤其是在准确建模心脏运动动态和处理欠采样数据方面。

> **ai_Abstract:** 本文提出了一种名为DUN-SRE的深度展开网络，用于动态MRI重建。该网络通过创新的(2+1)D等变卷积架构，首次在深度学习框架中有效整合了动态MRI的空间旋转和时间对称性。DUN-SRE将数据一致性和近端映射模块整合到其展开框架中，并采用高保真群滤波器参数化机制。实验证明，DUN-SRE在心脏电影MRI数据集上达到了最先进的性能，尤其擅长保留旋转对称结构，并具有出色的泛化能力。

> **摘要翻译:** 动态磁共振成像（MRI）展现出变换对称性，包括个体帧内的空间旋转对称性和沿时间维度的时间对称性。在重建模型中明确纳入这些对称先验可以显著提高图像质量，尤其是在激进欠采样的情况下。最近，等变卷积神经网络（ECNN）在利用空间对称先验方面显示出巨大潜力。然而，现有ECNN未能关键性地建模时间对称性，这可以说是动态MRI重建中最普遍和信息最丰富的结构先验。为了解决这个问题，我们提出了一种用于动态MRI重建的新型深度展开网络，该网络具有时空旋转等变性（DUN-SRE）。DUN-SRE通过（2+1）D等变卷积架构建立时空等变性。特别是，它将数据一致性和近端映射模块集成到一个统一的深度展开框架中。这种架构确保了时空旋转对称性约束在整个重建过程中的严格传播，从而能够更物理精确地建模电影MRI中的心脏运动动态。此外，还开发了一种高保真群滤波器参数化机制，以在强制对称性约束的同时保持表示精度。在心脏电影MRI数据集上的综合实验表明，DUN-SRE实现了最先进的性能，特别是在保留旋转对称结构方面，为广泛的动态MRI重建任务提供了强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [145] [SWDL: Stratum-Wise Difference Learning with Deep Laplacian Pyramid for Semi-Supervised 3D Intracranial Hemorrhage Segmentation](https://arxiv.org/abs/2506.10325)
> *SWDL：基于深度拉普拉斯金字塔的分层差异学习用于半监督三维颅内出血分割*

*Cheng Wang, Siqi Chen, Donghua Mi, Yang Chen, Yudong Zhang, Yinsheng Li* | **Main category: eess.IV**

**Keywords:** 半监督学习, 颅内出血分割, 拉普拉斯金字塔, 深度卷积, 差异学习

**Comment:** 11 pages, 4 figures, 6 Tables

> **TL;DR:** 提出SWDL-Net，一种结合拉普拉斯金字塔和深度卷积的半监督学习框架，用于高效的3D颅内出血分割，即使在数据标记极少的情况下也能超越现有技术。

**AI_Comments:** SWDL-Net的创新之处在于其独特地结合了拉普拉斯金字塔和深度卷积的互补优势，并通过差异学习机制进行整合，从而在半监督设置下实现了对医学图像病变细节和边界的精确分割。这对于解决医疗领域高质量标注数据稀缺的痛点具有重要意义，尤其是在颅内出血这种关键的诊断场景中。其在极低标记数据比例下超越SOTA的性能，显示出其强大的实用性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在医学图像分割中表现出色，但需要大量手动标注数据。颅内出血（ICH）的标注过程繁琐且成本高昂，导致标记数据稀缺。传统的半监督学习方法主要关注高置信度伪标签或一致性正则化，存在局限性。

**Method:** 提出SWDL-Net，一个新颖的半监督学习框架。它利用拉普拉斯金字塔（擅长边缘锐化）和深度卷积上采样（通过灵活的特征映射增强细节精度）的互补优势。通过一个差异学习机制有效地整合这些方法，以实现病变细节和边界的优越分割。

**Result:** 在271例ICH数据集和公共基准测试上进行了广泛实验，结果表明SWDL-Net在仅有2%标记数据的情况下优于当前最先进的方法。在公开可用的脑出血分割数据集（BHSD）上，使用5%标记数据的额外评估进一步证实了该方法的优越性。

**Conclusion:** SWDL-Net通过结合拉普拉斯金字塔和深度卷积的优势，并采用差异学习机制，为半监督3D颅内出血分割提供了一种高效且表现卓越的解决方案，显著缓解了医学图像标注数据稀缺的问题。

> **ai_Abstract:** 本文提出SWDL-Net，一种创新的半监督学习框架，用于解决3D颅内出血分割中标记数据稀缺的问题。该框架结合了拉普拉斯金字塔的边缘锐化能力和深度卷积的细节增强优势，通过差异学习机制实现对病变细节和边界的精确分割。实验证明，SWDL-Net在极低标记数据（2%或5%）的情况下，其性能显著优于现有最先进的半监督分割方法。

> **摘要翻译:** 近期医学影像学的进展已使基于深度学习的分割成为主流方法，尽管这通常需要大量的手动标注数据。然而，由于标记过程繁琐且成本高昂，颅内出血（ICH）的标注仍然特别具有挑战性。半监督学习（SSL）已成为解决标记数据稀缺问题的有前景的解决方案，尤其是在体素医学图像分割中。与主要关注高置信度伪标签或一致性正则化的传统SSL方法不同，我们提出了SWDL-Net，一个新颖的SSL框架，它利用拉普拉斯金字塔和深度卷积上采样的互补优势。拉普拉斯金字塔擅长边缘锐化，而深度卷积通过灵活的特征映射增强细节精度。我们的框架通过一种差异学习机制实现了病变细节和边界的卓越分割，该机制有效地整合了这些互补方法。在271例ICH数据集和公共基准测试上进行的广泛实验表明，SWDL-Net在仅有2%标记数据的情况下优于当前最先进的方法。在公开可用的脑出血分割数据集（BHSD）上，使用5%标记数据的额外评估进一步证实了我们方法的优越性。代码和数据已发布在https://github.com/SIAT-CT-LAB/SWDL。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [164] [ConStyX: Content Style Augmentation for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2506.10675)
> *ConStyX: 内容风格增强用于可泛化医学图像分割*

*Xi Chen, Zhiqiang Shen, Peng Cao, Jinzhu Yang, Osmar R. Zaiane* | **Main category: eess.IV**

**Keywords:** 域泛化, 医学图像分割, 内容风格增强, 域随机化, 泛化性能

**Comment:** 

> **TL;DR:** ConStyX通过内容和风格增强解决医学图像分割中的域泛化问题，提高了模型泛化性能。

**AI_Comments:** ConStyX的创新点在于结合了内容和风格增强，并考虑了过度增强的负面影响，这比传统仅依赖风格扰动的域随机化方法更全面和有效。该方法有望提高医学图像分割模型在实际多源数据应用中的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像通常从多个领域收集，导致领域偏移，从而损害医学图像分割模型的性能。现有的基于域随机化的领域泛化（DG）方法存在局限性：1）效率受限，因为它们仅依赖图像风格扰动；2）忽略了过度增强图像对模型训练的不利影响。

**Method:** 本文提出了一种新颖的基于域随机化的DG方法，名为内容风格增强（ConStyX），用于可泛化医学图像分割。ConStyX通过以下两点解决问题：1）增强训练数据的内容和风格，使增强数据能覆盖更广泛的数据领域；2）在模型训练中利用良好增强的特征，同时减轻过度增强特征的负面影响。

**Result:** 在多个领域进行的广泛实验表明，ConStyX实现了卓越的泛化性能。

**Conclusion:** ConStyX通过有效的内容和风格增强策略，成功提升了医学图像分割模型的域泛化能力，解决了传统域随机化方法在效率和过度增强方面的局限性。

> **ai_Abstract:** 本文提出了一种名为ConStyX的新型域随机化方法，旨在解决医学图像分割中因域偏移导致的模型泛化能力差的问题。ConStyX通过同时增强训练数据的内容和风格，并有效利用增强特征同时避免过度增强的负面影响，显著提高了模型在不同医学图像域上的泛化性能。

> **摘要翻译:** 医学图像通常从多个领域收集，导致领域偏移，从而损害医学图像分割模型的性能。领域泛化（DG）旨在通过训练一个具有强大泛化能力的鲁棒模型来解决这个问题。最近，许多基于域随机化的DG方法被提出。然而，这些方法存在以下局限性：1）由于其仅依赖图像风格扰动，域随机化的效率受到限制；2）忽略了过度增强图像对模型训练的不利影响。为了解决这些问题，我们提出了一种新颖的基于域随机化的DG方法，称为内容风格增强（ConStyX），用于可泛化医学图像分割。具体来说，ConStyX 1）增强了训练数据的内容和风格，使得增强后的训练数据能够更好地覆盖更广泛的数据领域；2）在模型训练期间利用良好增强的特征，同时减轻过度增强特征的负面影响。在多个领域进行的广泛实验表明，我们的ConStyX实现了卓越的泛化性能。代码可在https://github.com/jwxsp1/ConStyX获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [182] [SNR and Resource Adaptive Deep JSCC for Distributed IoT Image Classification](https://arxiv.org/abs/2506.10699)
> *用于分布式物联网图像分类的信噪比和资源自适应深度联合源信道编码*

*Ali Waqas, Sinem Coleri* | **Main category: eess.IV**

**Keywords:** 物联网图像分类, JSCC, 信噪比自适应, 资源自适应, 深度学习, 遗传算法

**Comment:** 6 pages, 5 figures, PIMRC Conference 2025

> **TL;DR:** 本文提出了一种用于分布式物联网图像分类的信噪比和计算自适应深度联合源信道编码（JSCC）框架。该框架利用一种学习辅助智能遗传算法（LAIGA）来优化网络配置，使其能够适应不同的信噪比和计算预算，并在低信噪比和资源受限环境下显著优于现有方法。

**AI_Comments:** 该论文的创新之处在于所提出的框架的自适应性，特别是使用LAIGA根据信噪比和计算预算动态调整网络配置。这解决了现有JSCC方法在物联网应用中一个关键的局限性，即资源和信道条件的高度可变性。将遗传算法与学习辅助（随机森林）相结合进行超参数优化是一种巧妙的方法，可以使自适应过程高效且实用。

<details>
  <summary>Details</summary>

**Motivation:** 物联网设备面临严重的计算限制，通常需要通过嘈杂的无线信道传输数据进行服务器端处理。现有基于分体式深度神经网络（DNN）的联合源信道编码（JSCC）方案缺乏对不同计算预算和信道条件的适应性，因为它们依赖于固定的网络拆分和静态配置。

**Method:** 本文提出了一种新颖的信噪比和计算自适应分布式CNN框架，用于物联网设备和边缘服务器之间的无线图像分类。该框架引入了学习辅助智能遗传算法（LAIGA），该算法有效地探索CNN超参数空间，以在给定FLOPs约束和给定信噪比下优化网络配置。LAIGA能够智能地丢弃超出物联网设备计算预算的不可行网络配置，并受益于基于随机森林的学习辅助，以避免彻底探索超参数空间并引入特定于应用程序的偏差。

**Result:** 所提出的框架优于固定拆分架构和现有信噪比自适应方法，特别是在低信噪比和有限计算资源下。与现有基于JSCC的信噪比自适应多层框架相比，在信噪比低至-10dB时，在物联网设备上可用的计算预算范围（1M至70M FLOPs）内，分类精度提高了10%。

**Conclusion:** 本文证明了所提出的信噪比和计算自适应深度JSCC框架结合LAIGA，显著提高了分布式物联网系统中的图像分类精度，尤其是在具有挑战性的低信噪比和资源受限环境中。

> **ai_Abstract:** 本文提出了一种新颖的信噪比和计算自适应分布式CNN框架，用于物联网环境中的无线图像分类。该框架通过采用学习辅助智能遗传算法（LAIGA）解决了现有固定配置JSCC方法的局限性。LAIGA通过在FLOPs约束和不同信噪比下有效探索CNN超参数空间来优化网络配置，智能地丢弃不可行的选项，并利用随机森林进行指导。实验结果表明，该框架显著优于静态和现有信噪比自适应架构，在低信噪比和有限计算资源场景下实现了10%的精度提升。

> **摘要翻译:** 基于传感器的物联网设备本地推理面临严重的计算限制，通常需要通过嘈杂的无线信道传输数据以进行服务器端处理。为了解决这个问题，基于分体式深度神经网络（DNN）的联合源信道编码（JSCC）方案被用于提取和传输相关特征而不是原始数据。然而，大多数现有方法依赖于固定的网络拆分和静态配置，缺乏对不同计算预算和信道条件的适应性。在本文中，我们提出了一种新颖的信噪比和计算自适应分布式CNN框架，用于物联网设备和边缘服务器之间的无线图像分类。我们引入了一种学习辅助智能遗传算法（LAIGA），该算法有效地探索CNN超参数空间，以在给定FLOPs约束和给定信噪比下优化网络配置。LAIGA智能地丢弃超出物联网设备计算预算的不可行网络配置。它还受益于基于随机森林的学习辅助，以避免对超参数空间进行彻底探索，并在候选最佳配置中引入特定于应用程序的偏差。实验结果表明，所提出的框架优于固定拆分架构和现有信噪比自适应方法，特别是在低信噪比和有限计算资源下。与现有基于JSCC的信噪比自适应多层框架相比，在信噪比低至-10dB时，在物联网设备上可用的计算预算范围（1M至70M FLOPs）内，我们的分类精度提高了10%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [195] [Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches](https://arxiv.org/abs/2506.10825)
> *医学图像分割中的通用模型：一项调查以及与任务特定方法的性能比较*

*Andrea Moglia, Matteo Leccardi, Matteo Cavicchioli, Alice Maccarini, Marco Marcon, Luca Mainardi, Pietro Cerveri* | **Main category: eess.IV**

**Keywords:** 通用模型, 医学图像分割, SAM, 调查, 性能比较

**Comment:** 132 pages, 26 figures, 23 tables. Andrea Moglia and Matteo Leccardi
  are equally contributing authors

> **TL;DR:** 本调查全面回顾了医学图像分割中的通用模型，包括它们的分类、性能分析以及与任务特定模型的比较，并讨论了挑战和未来方向。

**AI_Comments:** 该调查论文具有重要的现实意义，它系统地梳理了通用模型在医学图像分割领域的应用现状、发展脉络及面临的挑战。其创新性在于不仅提供了详尽的模型分类和性能比较，更深入探讨了该技术在医疗实践中必须面对的合规性、隐私安全及伦理等实际问题，并提出了前瞻性的未来研究方向。这对于推动通用模型在医疗AI领域的安全、有效落地具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型成功范式转变的启发下，通用模型已进入计算机视觉领域，尤其是在自然图像分割方面取得了里程碑式的进展（如SAM）。本研究的动机是对医学图像分割领域中的通用模型进行全面深入的调查，以理解其发展、分类、性能并与现有任务特定方法进行比较，同时识别其面临的挑战和未来发展方向。

**Method:** 本调查对医学图像分割中的通用模型进行了全面深入的研究。首先介绍了其基本概念，然后根据零样本、少样本、微调、适配器、SAM 2、仅图像训练以及文本图像联合训练的模型，对SAM的不同变体进行了分类。研究分析了这些模型在初级研究和最佳文献中的性能，并与最先进的任务特定模型进行了严格比较。此外，还讨论了法规遵从性、隐私、安全、预算和可信人工智能方面的挑战，并展望了未来的发展方向。

**Result:** 本调查提供了一个关于医学图像分割中通用模型的全面深入的分类，包括SAM的各种变体（零样本、少样本、微调、适配器、SAM 2）以及其他创新模型（仅图像训练、文本图像联合训练）。研究分析了这些模型在初级研究和最佳文献中的性能，并与最先进的任务特定模型进行了严格比较。此外，还强调了在法规遵从性、隐私和安全法律、预算以及可信人工智能方面需要解决的挑战。

**Conclusion:** 本调查对医学图像分割中的通用模型进行了全面的回顾和比较，并强调了在法规遵从性、隐私、安全、预算和可信人工智能方面需要解决的挑战。文章还分享了关于合成数据、早期融合、自然语言处理中通用模型的经验教训、代理AI、物理AI以及临床转化等未来方向的展望。

> **ai_Abstract:** 本调查全面审视了医学图像分割中的通用模型，追溯了其从大型语言模型和SAM的成功范式转变。文章首先介绍了通用模型的基础概念，随后对SAM的不同变体（包括零样本、少样本、微调、适配器、SAM 2以及其他图像/文本-图像联合训练模型）进行了详细分类。研究深入分析了这些模型在现有文献中的性能，并将其与任务特定模型进行了严格比较。此外，本调查还强调了通用模型在医疗领域面临的法规遵从性、隐私、安全、预算和可信AI等关键挑战，并展望了包括合成数据、早期融合、跨领域经验借鉴以及临床转化在内的未来研究方向。

> **摘要翻译:** 继大型语言模型成功范式转变之后，通过对海量数据语料库进行预训练并在不同下游任务上进行微调，通用模型已经进入计算机视觉领域。Segment Anything Model (SAM) 的引入在自然图像分割方面树立了里程碑，启发了医学图像分割领域众多架构的设计。在本调查中，我们对医学图像分割中的通用模型进行了全面深入的研究。我们首先介绍了支撑其发展的基础概念。然后，我们根据零样本、少样本、微调、适配器、近期SAM 2、其他仅通过图像训练的创新模型以及文本和图像联合训练的模型，对SAM的不同变体进行了分类。我们从初级研究和最佳文献层面，彻底分析了它们的性能，随后与最先进的任务特定模型进行了严格比较。我们强调需要解决在遵守监管框架、隐私和安全法律、预算以及可信人工智能方面的挑战。最后，我们分享了关于合成数据、早期融合、从自然语言处理中的通用模型吸取的经验教训、代理AI和物理AI以及临床转化等未来方向的看法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [212] [A novel visual data-based diagnostic approach for estimation of regime transition in pool boiling](https://arxiv.org/abs/2506.10832)
> *池沸腾状态转换估计的一种新型视觉数据诊断方法*

*Pranay Nirapure, Ayushman Singh, Srikanth Rangarajan, Bahgat Sammakia* | **Main category: eess.IV**

**Keywords:** 池沸腾, 视觉诊断, 状态转换, IVS, 图像处理

**Comment:** 

> **TL;DR:** 提出了一种基于图像的新度量IVS，结合SIFT和Mask R-CNN，用于快速、非侵入性地诊断池沸腾状态转换，并与传统HTC方法验证，显示出良好的相关性和可靠性。

**AI_Comments:** 这项研究的创新之处在于提出了一个纯粹基于视觉数据的新度量 (IVS)，克服了传统热传递系数测量在精确性和实时性上的局限。通过结合计算机视觉技术 (SIFT, Mask R-CNN) 与物理现象分析，实现了对复杂沸腾状态转换的有效识别。其非侵入性和实时性使其在工业应用中具有重要价值，尤其是在需要连续监测和快速诊断的场景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的热传递系数 (HTC) 测量存在实验局限性，难以精确测量其变化，因此需要一种基于视觉数据的替代方法来定性表征沸腾传热状态。

**Method:** 引入了一种新的度量标准“视觉相似性指数 (IVS)”，它结合了基于SIFT特征匹配的形态相似性与使用Mask R-CNN进行蒸汽面积估计的物理相似性。该方法利用抛光铜和多孔泡沫铜两种表面上的池沸腾高速图像进行演示和验证。

**Result:** IVS能够捕捉气泡形状、大小和分布的关键变化，这些变化与传热机制的转换相对应。IVS与从测量热传递系数 (HTC) 导出的等效度量$\\Phi$进行了验证，显示出很强的相关性和在检测沸腾状态转换（包括核态沸腾的开始和接近临界热流密度 (CHF)）方面的可靠性。IVS对表面过热度的敏感性也得到了检验，以增强其可信度。

**Conclusion:** IVS是一种强大、快速、非侵入性的实时图像沸腾诊断工具，在相变传热领域具有广阔的应用前景。

> **ai_Abstract:** 本文提出了一种名为视觉相似性指数 (IVS) 的新型视觉数据诊断方法，用于估计池沸腾状态转换。IVS结合了基于SIFT的形态相似性和基于Mask R-CNN的蒸汽面积估计，能够利用高速图像捕捉气泡变化并识别沸腾传热状态转换。实验结果表明，IVS与传统的HTC测量方法具有高度相关性，证明其在实时、非侵入性沸腾诊断方面的可靠性和潜力。

> **摘要翻译:** 这项研究引入了一种新的度量标准，即视觉相似性指数（IVS），仅利用视觉数据定性表征沸腾传热状态。IVS通过结合基于SIFT特征匹配的形态相似性与使用Mask R-CNN进行蒸汽面积估计的物理相似性而构建。研究采用抛光铜和多孔泡沫铜两种不同表面上的池沸腾高速图像，以证明该方法的普适性。IVS捕捉气泡形状、大小和分布的关键变化，这些变化与传热机制的转换相对应。该度量标准通过与从测量热传递系数（HTC）导出的等效度量$\Phi$进行验证，结果显示在检测沸腾状态转换（包括核态沸腾的开始和接近临界热流密度（CHF））方面具有很强的相关性和可靠性。鉴于精确测量HTC变化的实验局限性，研究还检验了IVS对表面过热度的敏感性，以增强IVS的可信度。因此，IVS作为一种强大、快速、非侵入性的实时图像沸腾诊断工具应运而生，在相变传热领域具有广阔的应用前景。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [228] [Med-URWKV: Pure RWKV With ImageNet Pre-training For Medical Image Segmentation](https://arxiv.org/abs/2506.10858)
> *Med-URWKV: 基于ImageNet预训练的纯RWKV医学图像分割模型*

*Zhenhuan Zhou* | **Main category: eess.IV**

**Keywords:** 医学图像分割, RWKV, 预训练, U-Net, VRWKV

**Comment:** Preprint Draft, 5 pages. This paper will be updated with a formal
  version in the future, Copyright: College of Computer Science, Nankai
  University. All rights reserved

> **TL;DR:** Med-URWKV是一个基于U-Net框架的纯RWKV医学图像分割模型，首次利用大规模预训练的VRWKV编码器，在多项医学图像分割任务上表现出与从头训练模型相当甚至更优的性能。

**AI_Comments:** 本文的创新点在于首次将大规模预训练的VRWKV编码器应用于医学图像分割任务，并构建了纯RWKV架构的Med-URWKV模型。这不仅探索了RWKV在医学领域的潜力，也证明了利用通用领域预训练模型对特定领域任务的有效性，为未来医学图像处理的预训练范式提供了新的思路。其重要性在于提供了一种计算效率高且性能优异的替代方案，有望推动医学图像分割技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割是计算机辅助诊断和治疗的关键技术。现有方法（CNN、Transformer及其混合架构）各有局限，如CNN感受野受限，Transformer计算复杂度高。虽然RWKV模型在视觉任务中表现出潜力，但现有将其应用于医学图像分割的研究多集中于VRWKV机制的修改，且从头训练模型，未充分探索利用预训练VRWKV模型的优势。

**Method:** 本文提出了Med-URWKV，一个纯粹基于RWKV的架构，它构建在U-Net框架之上，并结合了基于ImageNet的预训练。据作者所知，Med-URWKV是医学领域中首个可以直接重用大规模预训练VRWKV编码器的纯RWKV分割模型。

**Result:** 在七个数据集上的实验结果表明，Med-URWKV与从头训练的其他精心优化的RWKV模型相比，实现了相当甚至更优的分割性能。这验证了使用预训练VRWKV编码器在提升模型性能方面的有效性。

**Conclusion:** Med-URWKV通过利用大规模预训练的VRWKV编码器，在医学图像分割任务中展现出纯RWKV架构的有效性，并达到了先进的性能。

> **ai_Abstract:** 本文提出Med-URWKV，一个基于U-Net框架的纯RWKV医学图像分割模型，旨在解决现有CNN和Transformer方法的局限性，并充分利用RWKV模型的线性计算复杂度和长程建模能力。Med-URWKV首次在医学图像分割中直接重用大规模ImageNet预训练的VRWKV编码器。实验证明，Med-URWKV在多个数据集上取得了与从头训练的RWKV模型相当或更优的性能，验证了预训练VRWKV编码器对模型性能提升的有效性。

> **摘要翻译:** 医学图像分割是计算机辅助诊断和治疗中的一项基础且关键的技术。以往的方法大致可分为三类：基于卷积神经网络（CNN）、基于Transformer以及结合两者的混合架构。然而，它们各自存在局限性，例如CNN的感受野受限，或Transformer的二次复杂度导致的计算开销。最近，接受度加权键值（RWKV）模型作为各种视觉任务的一种有前途的替代方案出现，它提供了强大的长程建模能力和线性计算复杂度。一些研究也已将RWKV应用于医学图像分割任务，并取得了有竞争力的性能。然而，这些研究大多集中于对Vision-RWKV（VRWKV）机制的修改，并从头训练模型，而没有探索利用预训练VRWKV模型在医学图像分割任务中的潜在优势。在本文中，我们提出了Med-URWKV，一个基于U-Net框架的纯RWKV架构，它结合了基于ImageNet的预训练，以进一步探索RWKV在医学图像分割任务中的潜力。据我们所知，Med-URWKV是医学领域中第一个可以直接重用大规模预训练VRWKV编码器的纯RWKV分割模型。在七个数据集上的实验结果表明，Med-URWKV与从头训练的其他精心优化的RWKV模型相比，实现了相当甚至更优的分割性能。这验证了使用预训练VRWKV编码器在提升模型性能方面的有效性。代码将发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [240] [Semi-Automated Quality Assurance in Digital Pathology: Tile Classification Approach](https://arxiv.org/abs/2506.10916)
> *半自动化数字病理质量保证：图块分类方法*

*Meredith VandeHaar, M. Clinch, I. Yilmaz, M. A. Rahman, Y. Xiao, F. Dogany, H. M. Alazab, A. Nassar, Z. Akkus, B. Dangott* | **Main category: eess.IV**

**Keywords:** 数字病理, 质量保证, 深度学习, 伪影检测, 图块分类

**Comment:** 

> **TL;DR:** 该研究提出一种基于深度学习的AI算法，通过对数字病理图像图块进行分类来半自动化检测和定位伪影，从而提高数字病理图像质量保证的效率和准确性。

**AI_Comments:** 这项研究创新性地将深度学习应用于数字病理质量保证这一关键但未被充分探索的领域。其提出的图块分类AI算法能够半自动化地识别和定位伪影，显著减少了人工审查的工作量，提高了效率。该方法对于提升数字病理图像的质量和下游AI诊断模型的性能具有重要意义。混合模型的设计也体现了对不同伪影检测复杂性的考量。

<details>
  <summary>Details</summary>

**Motivation:** 数字病理中的伪影会严重影响AI诊断模型的性能，而当前的质量保证方法主要依赖人工审查且未充分利用深度学习，导致效率低下和准确性有限。

**Method:** 提出一种AI算法，通过分析数字病理图像的图块并将其分类为10种预定义伪影类型之一或背景。该算法识别并定位伪影，创建一张突出显示感兴趣区域的伪影图。通过将人类操作员引导至受伪影影响的特定图块，减少手动审查整个玻片所需的时间和精力。研究使用了InceptionResNet模型，并训练测试了单一伪影模型以及有限的多实例模型（针对颤动、折叠和笔迹伪影）。

**Result:** 研究表明，混合设计（结合单一伪影二元模型和多实例模型）可以优化各种伪影的检测。

**Conclusion:** 建议采用结合单一伪影二元模型和多实例模型的混合设计，以优化数字病理图像中各种伪影的检测。

> **ai_Abstract:** 本文提出了一种创新的半自动化AI算法，旨在提高数字病理图像的质量保证效率。该算法通过对图像图块进行深度学习分类，识别并定位10种常见伪影类型，并生成伪影地图以指导人工审查。通过使用InceptionResNet模型并结合单一伪影和多实例模型进行训练和测试，研究结果表明这种混合方法能有效优化伪影检测，从而减少人工审查的工作量并提升AI诊断的可靠性。

> **摘要翻译:** 质量保证是数字病理学中一个关键但尚未被充分探索的领域，即使是微小的伪影也可能产生显著影响。伪影已被证明会对AI诊断模型的性能产生负面影响。在当前实践中，训练有素的工作人员在将数字化图像发布给病理学家之前会手动审查这些图像，然后病理学家使用这些图像进行诊断。传统的图像处理方法为检测数字病理玻片上的伪影提供了基础。然而，目前的工具没有利用深度学习，而深度学习有潜力提高检测准确性和可扩展性。尽管有这些进展，数字病理学中的质量保证方法仍然有限，这为创新提供了空白。
我们提出了一种AI算法，旨在通过分析图块并将其分为10种预定义伪影类型之一或背景来筛选数字病理玻片。该算法识别并定位伪影，创建一张突出显示感兴趣区域的地图。通过将人类操作员引导至受伪影影响的特定图块，该算法最大限度地减少了手动审查整个玻片以查找质量问题所需的时间和精力。
从内部档案和癌症基因组图谱中，选择了133张全玻片图像，并使用内部开发的ZAPP软件（梅奥诊所，佛罗里达州杰克逊维尔）对10种伪影进行了标注。对不同图块大小和放大倍数下的多个模型进行了消融研究。选择了InceptionResNet。训练和测试了单一伪影模型，随后是有限的多实例模型，其中表现良好的伪影（颤动、折叠和笔迹）一起进行。根据本研究的结果，我们建议采用一种混合设计进行伪影筛选，该设计由单一伪影二元模型和多实例模型组成，以优化每种伪影的检测。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [252] [Bias-Switchable Row-Column Array Imaging using Fast Orthogonal Row-Column Electronic Scanning (FORCES) Compared with Conventional Row-Column Array Imaging](https://arxiv.org/abs/2506.10958)
> *采用快速正交行-列电子扫描（FORCES）的偏置可切换行-列阵列成像与传统行-列阵列成像的比较*

*Randy Palamar, Mohammad Rahim Sobhani, Darren Dahunsi, Negar Majidi, Afshin Kashani Ilkhechi, Joy Wang, Jeremy Brown, Roger Zemp* | **Main category: eess.IV**

**Keywords:** 行-列阵列, 偏置可切换, FORCES, 3D超声, 成像质量

**Comment:** 

> **TL;DR:** 偏置可切换行-列阵列（TOBE）结合FORCES技术在超声成像中优于传统行-列阵列。

**AI_Comments:** 这篇论文通过实验比较明确地展示了新型TOBE阵列结合FORCES技术在3D超声成像领域的显著优势。其创新点在于引入了偏置可切换的设计，有效解决了传统行-列阵列的成像盲区和聚焦限制。这种方法简化了布线，同时提高了图像质量，对于推进3D超声技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的行-列阵列（RCAs）在3D超声成像中存在局限性，如无法在孔径阴影之外成像以及无法在发射和接收时对所需扫描平面进行聚焦。

**Method:** 研究开发了偏置可切换行-列阵列（TOBE阵列），并使用快速正交行-列电子扫描（FORCES）方法，将其与传统的RCA成像方案（包括倾斜平面波（TPW）复合和虚拟线源（VLS）成像）进行了实验比较。研究在模型中量化了分辨率和广义对比度噪声比（gCNR），并演示了在模型和动物模型中的体积采集。

**Result:** 偏置可切换TOBE阵列结合FORCES技术相比传统RCA成像方案，在B扫描和体积图像上表现出卓越的性能。在模型中量化了更高的分辨率和广义对比度噪声比（gCNR）。

**Conclusion:** 偏置可切换行-列阵列（TOBE）结合FORCES技术是3D超声成像中传统行-列阵列的有效且优越的替代方案。

> **ai_Abstract:** 本文旨在比较偏置可切换行-列阵列（TOBE）与传统行-列阵列在3D超声成像中的性能。TOBE阵列通过快速正交行-列电子扫描（FORCES）方法克服了传统RCAs在成像范围和聚焦能力上的局限性。实验结果表明，TOBE阵列结合FORCES技术在B扫描和体积图像质量方面显著优于传统的倾斜平面波和虚拟线源成像方案，并在模型中量化了更高的分辨率和广义对比度噪声比。

> **摘要翻译:** 行-列阵列（RCAs）由于其大大简化的布线，为3D超声的完全有线2D阵列提供了一个有吸引力的替代方案。然而，传统的RCA面临与其长元件相关的挑战。这些挑战包括无法在孔径阴影之外成像以及无法在发射和接收时对所需的扫描平面进行聚焦。为了解决这些局限性，我们最近开发了偏置可切换RCAs，也称为顶部正交到底部电极（TOBE）阵列。这些阵列提供了从阵列的每个元件中读取并获得高质量图像的新机会。尽管TOBE阵列及其相关的成像方案已显示出前景，但它们尚未与传统的RCA成像技术进行直接的实验比较。本研究旨在提供这种比较，展示了使用一种名为快速正交行-列电子扫描（FORCES）的方法，从两个电致伸缩弛豫TOBE阵列获得的卓越B扫描和体积图像，与传统的RCA成像方案（包括倾斜平面波（TPW）复合和虚拟线源（VLS）成像）相比。该研究量化了模型中的分辨率和广义对比度噪声比（gCNR），并演示了在模型和动物模型中的体积采集。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [20] [RT-VC: Real-Time Zero-Shot Voice Conversion with Speech Articulatory Coding](https://arxiv.org/abs/2506.10289)
> *RT-VC：基于语音发音编码的实时零样本语音转换*

*Yisi Liu, Chenyang Wang, Hanjo Kim, Raniya Khan, Gopala Anumanchipalli* | **Main category: eess.AS**

**Keywords:** 语音转换, 实时, 零样本, 发音编码, 低延迟

**Comment:** ACL Demo Track 2025

> **TL;DR:** RT-VC是一个实时零样本语音转换系统，利用发音特征和可微分数字信号处理实现低延迟和高质量的语音转换，并在保持与SOTA相当的合成质量下，将CPU延迟降低了13.3%。

**AI_Comments:** 本文提出了一种创新的实时零样本语音转换方法，通过利用发音特征空间和集成可微分数字信号处理，有效地解决了语音转换中的延迟和质量问题。其关键创新在于将内容和说话人特征在发音空间中解耦，以及高效的声码技术，这对于实时应用具有重要意义。性能提升的数据（13.3%的延迟降低）也具体而有说服力。

<details>
  <summary>Details</summary>

**Motivation:** 语音转换已成为辅助通信和娱乐等众多应用中的关键技术。当前研究旨在实现超低延迟和高质量的实时零样本语音转换。

**Method:** RT-VC系统利用发音特征空间自然地解耦内容和说话人特征，以实现更鲁棒和可解释的语音转换。此外，它集成了可微分数字信号处理（DDSP），可以直接从发音特征高效地进行声码，显著减少了转换延迟。

**Result:** 实验评估表明，RT-VC在保持与当前最先进（SOTA）方法相当的合成质量的同时，实现了61.4毫秒的CPU延迟，延迟降低了13.3%。

**Conclusion:** RT-VC成功地实现了一个实时零样本语音转换系统，该系统具有超低延迟和高质量性能，通过利用发音特征和可微分数字信号处理，显著提升了语音转换的效率和鲁棒性。

> **ai_Abstract:** RT-VC是一种新型的实时零样本语音转换系统，旨在实现超低延迟和高质量的语音转换。该系统通过利用发音特征空间来有效解耦语音内容和说话人特性，并结合可微分数字信号处理（DDSP）进行高效声码，从而显著降低了转换延迟。实验结果显示，RT-VC在保持与现有先进技术相当的合成质量的同时，将CPU延迟降低了13.3%。

> **摘要翻译:** 语音转换已成为辅助通信到娱乐等众多应用中的关键技术。在本文中，我们提出了RT-VC，一个零样本实时语音转换系统，它提供了超低延迟和高质量的性能。我们的方法利用发音特征空间来自然地解耦内容和说话人特性，从而促进更鲁棒和可解释的语音转换。此外，可微分数字信号处理（DDSP）的集成使得可以直接从发音特征高效地进行声码，显著减少了转换延迟。实验评估表明，在保持与当前最先进（SOTA）方法相当的合成质量的同时，RT-VC实现了61.4毫秒的CPU延迟，代表了13.3%的延迟降低。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [47] [AC/DC: LLM-based Audio Comprehension via Dialogue Continuation](https://arxiv.org/abs/2506.10312)
> *AC/DC: 基于LLM的通过对话延续实现的音频理解*

*Yusuke Fujita, Tomoya Mizumoto, Atsushi Kojima, Lianbo Liu, Yui Sudo* | **Main category: eess.AS**

**Keywords:** 音频理解, 大型语言模型, 对话延续, 零样本学习, 指令遵循

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 提出了一种基于LLM的音频理解模型AC/DC，通过对话延续训练解决字幕变异问题，实现零样本指令遵循能力。

**AI_Comments:** 该论文通过将音频理解任务转化为对话延续任务，巧妙地利用了LLM的强大能力，有效解决了传统音频字幕生成中的字幕变异问题，并实现了零样本指令遵循，这对于音频理解领域是一个重要的创新。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法在训练数据中直接生成目标字幕存在字幕变异问题，且难以捕捉字幕的深层含义。

**Method:** 本文提出了AC/DC模型，一个指令遵循音频理解模型，它利用大型语言模型（LLM）的对话延续能力。该模型不直接生成目标字幕，而是训练模型生成仿佛输入字幕触发对话的响应，从而有效捕捉字幕的深层含义。

**Result:** 即使仅在音频字幕数据集上训练，AC/DC模型也能实现零样本指令遵循能力，无需多任务指令微调。在AudioCaps、WavCaps和Clotho数据集上通过AudioBench音频场景问答测试，证明了模型能够遵循各种未见指令。

**Conclusion:** 通过将音频理解任务转化为对话延续，AC/DC模型成功缓解了字幕变异问题，并展现出强大的零样本指令遵循能力。

> **ai_Abstract:** 本文提出了AC/DC，一个基于LLM的音频理解模型，通过创新的对话延续训练方法，而非直接生成字幕，来解决音频字幕的变异问题并捕捉深层含义。该方法使模型即使仅在音频字幕数据集上训练，也能展现出卓越的零样本指令遵循能力，并在多个标准数据集上得到了验证。

> **摘要翻译:** 我们提出了一种指令遵循音频理解模型，该模型利用大型语言模型（LLM）的对话延续能力。该方法不直接在训练数据中生成目标字幕，而是训练模型生成仿佛输入字幕触发了对话的响应。这种对话延续训练缓解了字幕变异问题。学习延续对话能有效地捕捉字幕超越表面词汇的含义。因此，我们的模型即使仅在音频字幕数据集上训练，也能实现零样本指令遵循能力，无需多任务指令微调。在AudioCaps、WavCaps和Clotho数据集上进行的AudioBench音频场景问答测试实验表明，我们的模型能够遵循各种未见指令。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [72] [Joint ASR and Speaker Role Tagging with Serialized Output Training](https://arxiv.org/abs/2506.10349)
> *联合ASR和说话人角色标注的序列化输出训练*

*Anfeng Xu, Tiantian Feng, Shrikanth Narayanan* | **Main category: eess.AS**

**Keywords:** ASR, 说话人角色标注, 序列化输出训练, Whisper, 对话式AI

**Comment:** Under review

> **TL;DR:** 本文提出使用序列化输出训练（SOT）方法，通过增强Whisper模型，实现联合ASR和说话人角色标注，显著降低了多说话人词错率（WER）。

**AI_Comments:** 这项工作的创新之处在于将说话人角色标注直接集成到ASR过程中，通过对预训练模型（如Whisper）应用序列化输出训练（SOT），实现了单次解码生成角色感知转录。这对于开发更复杂的对话式AI和提高ASR在多说话人环境中的实用性至关重要。多说话人词错率（WER）的显著降低有力地证明了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数自动语音识别（ASR）系统仅专注于语音转录，而未能识别说话人角色，这对于对话式AI至关重要。

**Method:** 研究并采用序列化输出训练（SOT）方法，用于联合ASR和说话人角色标注。具体做法是，通过添加角色特定标记来增强Whisper模型，并使用SOT进行微调，使模型能够在单次解码过程中生成角色感知的转录。将此SOT方法与一种自监督的先前基线方法在两个真实世界的对话数据集上进行了比较。

**Result:** 该方法在多说话人词错率（WER）上实现了超过10%的降低。

**Conclusion:** 该方法证明了其作为统一模型实现说话人角色感知语音转录的可行性。

> **ai_Abstract:** 本文旨在解决当前ASR系统无法识别说话人角色的局限性，这对于对话式AI至关重要。研究提出了一种新颖的方法，即利用序列化输出训练（SOT）来联合执行ASR和说话人角色标注。通过使用角色特定标记增强并微调Whisper模型，该系统能够单次解码生成角色感知的转录。在两个真实世界对话数据集上的实验结果表明，该方法能将多说话人词错率（WER）降低10%以上，证明了其作为说话人角色感知语音转录统一模型的有效性。

> **摘要翻译:** 自动语音识别系统在大规模预训练模型的帮助下取得了显著进展。然而，当前大多数系统仅专注于转录语音，而没有识别说话人角色，这对于对话式AI至关重要。在这项工作中，我们研究了使用序列化输出训练（SOT）进行联合ASR和说话人角色标注的方法。通过使用角色特定标记增强Whisper模型，并使用SOT进行微调，我们使模型能够在单次解码过程中生成角色感知的转录。我们将SOT方法与一种自监督的先前基线方法在两个真实世界的对话数据集上进行了比较。我们的研究结果表明，这种方法在多说话人词错率（WER）上实现了超过10%的降低，证明了其作为统一模型实现说话人角色感知语音转录的可行性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [98] [Robust Unsupervised Adaptation of a Speech Recogniser Using Entropy Minimisation and Speaker Codes](https://arxiv.org/abs/2506.10653)
> *鲁棒的无监督语音识别器自适应方法：基于熵最小化和说话人编码*

*Rogier C. van Dalen, Shucong Zhang, Titouan Parcollet, Sourav Bhattacharya* | **Main category: eess.AS**

**Keywords:** 语音识别, 无监督自适应, 熵最小化, 说话人编码, 词错误率

**Comment:** 

> **TL;DR:** 该论文提出一种结合熵最小化和说话人编码的方法，以实现对少量（一分钟）无标签数据的鲁棒无监督语音识别器自适应，显著提高了词错误率。

**AI_Comments:** 该论文的创新点在于结合了条件熵最小化和说话人编码，有效解决了无监督、少量数据下语音识别器自适应的鲁棒性问题。特别是使用完整假设的条件熵，避免了单一伪标签的脆弱性，提高了自适应的稳定性。说话人编码的引入也有效地利用了少量数据捕捉说话人特性的能力。其在仅一分钟数据上即获得显著性能提升的成果，对于实际应用中数据稀缺场景具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 语音识别器通常只在特定环境下表现最佳，需要自适应到新环境或新说话人。然而，针对新说话人的自适应往往数据量过少且无标签，导致微调不够鲁棒。

**Method:** 该论文提出了两种结合方法：1. 提出了一种新的损失函数——完整假设上的条件熵，替代了传统基于单个错误假设的交叉熵，通过使用多个假设来增强对初始识别错误的鲁棒性。2. 引入了“说话人编码”，用一个足够短的向量来表征说话人，使其只需少量数据即可估计。

**Result:** 在Common Voice的远场噪声增强版本上，所提出的方案在1分钟的自适应数据上使词错误率相对提高了20%，在10分钟的数据上提高到29%。

**Conclusion:** 结合条件熵和说话人编码的方法能够有效地对少量无标签数据进行鲁棒的语音识别器无监督自适应，并显著提高识别性能。

> **ai_Abstract:** 该论文提出了一种鲁棒的无监督语音识别器自适应方法，旨在解决新说话人数据量少且无标签的问题。核心创新包括使用完整假设上的条件熵作为新的损失函数，以增强对初始识别错误的鲁棒性；以及引入说话人编码，用少量数据即可表征说话人。实验结果显示，在Common Voice数据集上，该方法在仅一分钟的自适应数据上实现了20%的词错误率相对提升，并在十分钟数据上提升至29%。

> **摘要翻译:** 语音识别器通常只在特定环境下表现最佳，需要自适应才能在其他环境下良好工作。对于新说话人的自适应，通常用于微调的数据量太少，无法做到鲁棒，而且这些数据通常是未标注的。本文提出了一种方法组合，旨在使对一分钟数据的自适应变得鲁棒。首先，本文提出了一种新颖的损失函数——完整假设上的条件熵，而不是使用单个容易出错的假设或“伪标签”上的交叉熵来估计自适应参数。使用多个假设使自适应对初始识别中的错误更具鲁棒性。其次，“说话人编码”用一个足够短的向量来表征说话人，从而只需少量数据即可估计。在Common Voice的远场噪声增强版本上，所提出的方案在1分钟的自适应数据上使词错误率相对提高了20%，在10分钟的数据上提高到29%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [122] [Disentangling Dual-Encoder Masked Autoencoder for Respiratory Sound Classification](https://arxiv.org/abs/2506.10698)
> *呼吸音分类的双编码器解耦掩码自编码器*

*Peidong Wei Shiyu Miao Lin Li* | **Main category: eess.AS**

**Keywords:** 呼吸音分类, 掩码自编码器, 特征解耦, 域不匹配, 双编码器

**Comment:** (Accepted at Interspeech 2025)

> **TL;DR:** 针对呼吸音分类中数据稀缺和域不匹配问题，本文提出了一种名为DDE-MAE的新型掩码自编码器模型，通过双编码器实现特征解耦，有效提升了分类性能。

**AI_Comments:** 这篇论文的创新点在于引入了双编码器结构来解决呼吸音分类中的域不匹配问题，通过特征解耦提高了模型的泛化能力。这种方法对于医疗领域中数据异构性强的任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在呼吸音分类中面临数据稀缺的挑战，并且由于呼吸音样本来自不同的电子听诊器、患者群体和录音环境，导致训练模型中出现域不匹配问题，这限制了其性能。

**Method:** 本文提出了一种名为“解耦双编码器掩码自编码器”（DDE-MAE）的改进型掩码自编码器模型，用于呼吸音分类。该模型设计了两个独立的编码器，分别捕获与疾病相关和与疾病无关的信息，从而实现特征解耦，以减少域不匹配。

**Result:** 该方法在ICBHI数据集上取得了有竞争力的性能。

**Conclusion:** DDE-MAE通过特征解耦有效解决了呼吸音分类中的域不匹配问题，并在有限数据下表现出良好的性能，为呼吸音分类提供了一种有效的新方法。

> **ai_Abstract:** 本文针对呼吸音分类中数据稀缺和域不匹配的挑战，提出了一种名为DDE-MAE的改进型掩码自编码器。该模型通过设计两个独立的编码器，分别学习疾病相关和无关特征，实现特征解耦，从而有效降低了因不同采集源导致的域差异。实验结果表明，DDE-MAE在ICBHI数据集上表现出有竞争力的性能。

> **摘要翻译:** 深度神经网络已被应用于音频频谱图进行呼吸音分类，但由于可用数据稀缺，实现令人满意的性能仍然具有挑战性。此外，由于呼吸音样本是从各种电子听诊器、患者人口统计和录音环境中收集的，可能会在训练模型中引入域不匹配。为了解决这个问题，我们提出了一种名为“解耦双编码器掩码自编码器”（DDE-MAE）的改进型掩码自编码器（MAE）模型，用于呼吸音分类。设计了两个独立的编码器，分别捕获与疾病相关和与疾病无关的信息，实现了特征解耦，以减少域不匹配。我们的方法在ICBHI数据集上取得了有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [143] [FairASR: Fair Audio Contrastive Learning for Automatic Speech Recognition](https://arxiv.org/abs/2506.10747)
> *公平ASR：用于自动语音识别的公平音频对比学习*

*Jongsuk Kim, Jaemyung Yu, Minchan Kwon, Junmo Kim* | **Main category: eess.AS**

**Keywords:** 公平ASR, 音频对比学习, 自动语音识别, 人口偏见, 梯度反转层

**Comment:** Accepted to Interspeech2025

> **TL;DR:** FairASR通过学习与人口统计信息无关的表示来减少ASR模型中的人口统计偏见，同时保持整体性能。

**AI_Comments:** FairASR的创新之处在于其结合了梯度反转层和无监督对比损失来同时解决公平性和性能问题。这种方法对于在实际应用中部署更公平的ASR系统至关重要，因为它直接解决了现有模型中普遍存在的偏见问题。

<details>
  <summary>Details</summary>

**Motivation:** 尽管对现实世界应用至关重要，但大型ASR模型中的公平性问题仍未得到解决。

**Method:** 本文引入了FairASR系统，该系统旨在减轻人口统计偏见。它通过学习与群体成员身份无关的表示来实现这一点，从而实现跨人口群体的公平泛化。具体方法是利用一个多人口数据集，并采用梯度反转层来抑制人口统计区分性特征，同时通过无监督对比损失保持捕获可泛化语音模式的能力。

**Result:** 实验结果表明，FairASR在提供有竞争力的整体ASR性能的同时，显著减少了不同人口群体之间的性能差异。

**Conclusion:** FairASR成功地在自动语音识别中实现了公平性，同时保持了高水平的整体性能，有效解决了人口偏见问题。

> **ai_Abstract:** 本文介绍了FairASR，一个旨在减轻大型自动语音识别（ASR）模型中人口统计偏见的系统。FairASR通过学习与群体成员身份无关的表示，并利用多人口数据集、梯度反转层和无监督对比损失来抑制人口统计区分性特征，从而实现跨人口群体的公平泛化。实验证明，FairASR在保持整体ASR性能的同时，有效降低了不同人口群体间的性能差距。

> **摘要翻译:** 大规模ASR模型在准确性和鲁棒性方面取得了显著进步。然而，尽管公平性问题在现实世界应用中至关重要，但它们在很大程度上仍未得到解决。在这项工作中，我们引入了FairASR，一个通过学习与群体成员身份无关的表示来减轻人口统计偏见的系统，从而实现跨人口群体的公平泛化。我们的方法利用多人口数据集，采用梯度反转层来抑制人口统计区分性特征，同时通过无监督对比损失保持捕获可泛化语音模式的能力。实验结果表明，FairASR在提供有竞争力的整体ASR性能的同时，显著减少了不同人口群体之间的性能差异。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [28] [A Survey of Automatic Evaluation Methods on Text, Visual and Speech Generations](https://arxiv.org/abs/2506.10019)
> *文本、视觉和语音生成自动评估方法综述*

*Tian Lan, Yang-Hao Zhou, Zi-Ao Ma, Fanshu Sun, Rui-Qing Sun, Junyu Luo, Rong-Cheng Tu, Heyan Huang, Chen Xu, Zhijing Wu, Xian-Ling Mao* | **Main category: cs.CL**

**Keywords:** 自动评估, 生成式AI, 文本生成, 图像生成, 音频生成

**Comment:** 

> **TL;DR:** 这篇综述提供了一个统一的分类框架，系统地组织了文本、图像和音频生成内容的自动评估方法，并识别了五种基本范式。

**AI_Comments:** 这篇综述论文通过提供一个统一的分类框架，系统地梳理了跨多种模态（文本、视觉、语音）的自动评估方法，填补了现有研究的空白。其创新之处在于提出并识别了五种基本评估范式，为理解和开发生成式AI的评估方法提供了清晰的结构。这对于促进生成式AI领域的发展及其评估标准的统一具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习显著提升了生成式AI的能力，但自动评估生成内容的质量仍具挑战。现有研究缺乏一个系统性的框架来全面组织文本、视觉和音频模态的自动评估方法。

**Method:** 作者提出了一个全面的综述和统一的分类法，用于跨文本、视觉和音频三种模态的生成内容自动评估方法。他们识别了表征现有评估方法的五种基本范式，并首先考察了文本生成评估方法，然后将框架扩展到图像和音频生成。

**Result:** 论文提出了一个统一的自动评估方法分类法，识别了五种适用于文本、图像和音频生成的基本评估范式，并展示了该框架的广泛适用性。

**Conclusion:** 论文讨论了跨模态评估方法未来研究的有前景方向。

> **ai_Abstract:** 这篇综述论文旨在解决当前研究中缺乏系统性框架来组织文本、图像和音频生成内容自动评估方法的问题。作者提出了一个全面的综述和一个统一的分类法，识别了五种基本评估范式，并首先详细分析了文本生成评估方法，随后将该框架扩展到图像和音频生成，强调了其普适性。文章最后展望了跨模态评估方法未来研究的方向。

> **摘要翻译:** 深度学习的最新进展显著增强了文本、图像和音频领域的生成式AI能力。然而，自动评估这些生成内容的质量仍然面临持续的挑战。尽管存在大量的自动评估方法，但当前研究缺乏一个系统性的框架来全面组织跨文本、视觉和音频模态的这些方法。为了解决这个问题，我们提出了一个全面的综述和统一的分类法，用于跨所有三种模态的生成内容自动评估方法；我们识别了表征这些领域现有评估方法的五种基本范式。我们的分析首先考察了文本生成评估方法，其中技术最为成熟。然后，我们将该框架扩展到图像和音频生成，展示了其广泛适用性。最后，我们讨论了跨模态评估方法未来研究的有前景方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [54] [TaskCraft: Automated Generation of Agentic Tasks](https://arxiv.org/abs/2506.10055)
> *TaskCraft：代理任务的自动化生成*

*Dingfeng Shi, Jingyi Cao, Qianben Chen, Weichen Sun, Weizhen Li, Hongxuan Lu, Fangchen Dong, Tianrui Qin, King Zhu, Minghao Yang, Jian Yang, Ge Zhang, Jiaheng Liu, Changwang Zhang, Jun Wang, Yuchen Eleanor Jiang, Wangchunshu Zhou* | **Main category: cs.CL**

**Keywords:** 代理任务, 自动化生成, TaskCraft, 数据集, 任务扩展

**Comment:** 

> **TL;DR:** TaskCraft是一个自动化工作流程，用于生成可扩展、多工具且可验证的代理任务，以解决现有指令数据缺乏工具交互和代理基准测试成本高昂的问题。

**AI_Comments:** TaskCraft的创新之处在于其自动化生成复杂代理任务的能力，解决了当前人工标注成本高昂和数据稀缺的问题。其深度和宽度扩展机制使得任务难度可控且多样化，对于推动代理AI的发展和评估具有重要意义。提供大规模合成数据集也显著降低了研究门槛。

<details>
  <summary>Details</summary>

**Motivation:** 代理任务在NLP和AI领域日益重要，但现有指令数据缺乏工具交互，且当前的代理基准测试依赖昂贵的人工标注，限制了其可扩展性。

**Method:** 我们引入了TaskCraft，这是一个自动化工作流程，通过深度扩展和宽度扩展来创建结构上和层次上复杂的挑战，从而扩展原子任务，以生成难度可扩展、多工具且可验证的代理任务及执行轨迹。

**Result:** 实证结果表明，这些任务改进了生成工作流中的提示优化，并增强了代理基础模型的监督微调。我们提供了一个包含约36,000个不同难度任务的大规模合成数据集。

**Conclusion:** TaskCraft提供了一个自动化、可扩展的代理任务生成方法，解决了现有数据和基准的局限性，并为代理模型的研究和评估提供了大规模数据集。

> **ai_Abstract:** TaskCraft是一个自动化系统，旨在生成可扩展、多工具且可验证的代理任务，以解决现有代理任务数据和基准的局限性。它通过深度和宽度扩展创建复杂的任务，并生成了包含约36,000个任务的大规模合成数据集。实验证明，这些任务能够优化提示并改进代理基础模型的微调。

> **摘要翻译:** 代理任务需要多步骤的问题解决能力，具备自主性、工具使用和自适应推理，它们在自然语言处理和人工智能的进步中变得越来越核心。然而，现有指令数据缺乏工具交互，当前的代理基准测试依赖昂贵的人工标注，这限制了它们的可扩展性。我们引入了\textsc{TaskCraft}，一个自动化工作流程，用于生成难度可扩展、多工具且可验证的代理任务及其执行轨迹。TaskCraft通过基于深度和基于宽度的扩展来扩展原子任务，以创建结构上和层次上复杂的挑战。实证结果表明，这些任务改进了生成工作流中的提示优化，并增强了代理基础模型的监督微调。我们提出了一个包含约36,000个不同难度任务的大规模合成数据集，以支持未来关于代理调整和评估的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [79] [A quantum semantic framework for natural language processing](https://arxiv.org/abs/2506.10077)
> *自然语言处理的量子语义框架*

*Christopher J. Agostino, Quan Le Thien, Molly Apsel, Denizhan Pak, Elina Lesyk, Ashabari Majumdar* | **Main category: cs.CL**

**Keywords:** 量子语义, 自然语言处理, 语义简并性, 贝尔不等式, LLM

**Comment:** 12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025

> **TL;DR:** 本文提出自然语言的语义简并性导致解释的组合爆炸，并认为语言意义通过观察者依赖的解释行为实现。通过对LLM进行语义贝尔不等式测试，发现语言解释表现出非经典语境性，这表明经典频率学方法存在缺陷，并提议采用贝叶斯重复采样方法。

**AI_Comments:** 这篇论文提出了一个关于自然语言处理中语义理解的创新视角，将量子力学的概念引入到语言解释中，挑战了传统的语言意义观。通过将LLM作为“计算认知系统”进行贝尔不等式测试，其方法新颖且具有启发性。研究结果暗示了经典NLP方法的局限性，并为未来的NLP研究指明了新的方向，即探索非经典、语境依赖的语义表征。

<details>
  <summary>Details</summary>

**Motivation:** 由于语义简并性，自然语言的复杂性增加时，任何解释代理（人类或LLM）恢复单一预期意义的可能性会消失，导致计算上的难处理性。这挑战了语言形式本身具有意义的经典观点。

**Method:** 本文利用柯尔莫哥洛夫复杂度论证了语义简并性。为了验证观察者依赖的解释行为，研究人员使用不同的LLM代理作为“计算认知系统”，在不同语境下解释模糊的词对，并进行了语义贝尔不等式测试。

**Result:** 在多项独立实验中，平均CHSH期望值在1.2到2.8之间，其中一些运行结果（例如2.3-2.4）显著违反了经典边界（|S|≤2）。这表明在歧义下的语言解释可以表现出非经典语境性，与人类认知实验结果一致。

**Conclusion:** 语言解释在歧义下表现出非经典语境性，这暗示经典的基于频率学的自然语言分析方法必然是耗损的。相反，贝叶斯式的重复采样方法可以为语境中的语言意义提供更实用和恰当的表征。

> **ai_Abstract:** 本研究探讨了自然语言中语义简并性带来的解释复杂性问题，认为这限制了LLM等现有NLP系统的性能。作者运用柯尔莫哥洛夫复杂度理论指出，随着语言复杂性增加，单一预期意义的恢复变得不可行，并提出意义是观察者依赖的解释行为。通过对LLM进行语义贝尔不等式测试，实验结果显示语言解释在歧义下表现出非经典语境性，这挑战了经典频率学方法，并建议采用贝叶斯重复采样方法来更好地表征语言意义。

> **摘要翻译:** 语义简并性代表了自然语言的一个基本属性，它超越了简单的多义性，涵盖了随着语义表达复杂性增加而出现的潜在解释的组合爆炸。大型语言模型（LLM）和其他现代自然语言处理系统面临固有的局限性，正是因为它们在自然语言本身中运行，使其受到语义简并性所施加的相同解释约束。在这项工作中，我们使用柯尔莫哥洛夫复杂度论证，随着表达式复杂性的增长，任何解释代理（人类或由LLM驱动的AI）恢复单一预期意义的可能性会消失。这种计算上的难处理性表明，语言形式本身具有意义的经典观点是有缺陷的。我们转而提出，意义是通过一种依赖于观察者的解释行为来实现的。为了验证这一点，我们使用不同的LLM代理作为“计算认知系统”，在不同语境下解释模糊的词对，进行了语义贝尔不等式测试。在几项独立的实验中，我们发现平均CHSH期望值范围从1.2到2.8，其中一些运行结果（例如2.3-2.4）显著违反了经典边界（|S|≤2）。这表明在歧义下的语言解释可以表现出非经典语境性，与人类认知实验结果一致。这些结果固有地暗示，经典的基于频率学的自然语言分析方法必然是耗损的。相反，我们提出贝叶斯式的重复采样方法可以在语境中提供更实用和恰当的语言意义表征。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [105] [Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information](https://arxiv.org/abs/2506.10086)
> *Chat-of-Thought：用于生成领域特定信息的协作式多智能体系统*

*Christodoulos Constantinides, Shuxin Lin, Nianjun Zhou, Dhaval Patel* | **Main category: cs.CL**

**Keywords:** Chat-of-Thought, 多智能体系统, LLM, FMEA, 协作式AI

**Comment:** 

> **TL;DR:** Chat-of-Thought是一个多智能体LLM系统，通过协作和动态任务路由，高效生成工业资产的FMEA文档，并引入了“思维对话”机制进行内容迭代优化。

**AI_Comments:** 该论文的创新点在于引入了“思维对话”机制，通过多角色LLM代理的动态讨论来迭代优化内容，这对于复杂领域（如FMEA）的文档生成具有重要意义。系统化地利用多智能体协作和LLM的强大能力，为自动化和提高领域特定信息生成的质量提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在促进工业资产的故障模式和影响分析（FMEA）文档的生成，并解决该领域面临的关键挑战。

**Method:** 该系统名为Chat-of-Thought，采用多个基于大型语言模型（LLM）的协作代理，每个代理具有特定角色，利用先进的AI技术和动态任务路由来优化FMEA表格的生成和验证。核心创新是引入“思维对话”（Chat of Thought）机制，通过动态的、多角色驱动的讨论实现内容的迭代细化。系统通过交互式、模板驱动的工作流程和上下文感知的代理协作来运行。

**Result:** 研究展示了Chat-of-Thought系统在解决工业设备监控领域挑战方面的潜力，能够优化FMEA表格的生成和验证。

**Conclusion:** Chat-of-Thought系统通过其协作式多智能体方法，在改进FMEA等领域特定文档的生成方面展现出巨大潜力。

> **ai_Abstract:** 本文介绍了一种新颖的多智能体系统Chat-of-Thought，旨在自动化和优化工业资产的故障模式和影响分析（FMEA）文档生成。该系统利用多个协作式LLM代理，结合动态任务路由和创新的“思维对话”机制进行内容迭代细化。研究展示了Chat-of-Thought在工业设备监控领域中解决相关挑战的有效潜力。

> **摘要翻译:** 本文提出了一个名为Chat-of-Thought的新型多智能体系统，旨在促进工业资产的故障模式和影响分析（FMEA）文档的生成。Chat-of-Thought采用多个具有特定角色的协作式大型语言模型（LLM）代理，利用先进的AI技术和动态任务路由来优化FMEA表格的生成和验证。该系统的一个关键创新是引入了“思维对话”（Chat of Thought）机制，通过动态的、多角色驱动的讨论实现内容的迭代细化。本研究探讨了工业设备监控的应用领域，强调了关键挑战，并展示了Chat-of-Thought通过交互式、模板驱动的工作流程和上下文感知的代理协作来解决这些挑战的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [110] [AutoMind: Adaptive Knowledgeable Agent for Automated Data Science](https://arxiv.org/abs/2506.10974)
> *AutoMind：自适应知识型智能体用于自动化数据科学*

*Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Shuofei Qiao, Jintian Zhang, Da Zheng, Huajun Chen, Ningyu Zhang* | **Main category: cs.CL**

**Keywords:** LLM智能体, 自动化数据科学, 知识型智能体, 自适应编码, 专家知识库

**Comment:** Ongoing work. Code is at https://github.com/innovatingAI/AutoMind

> **TL;DR:** AutoMind是一个自适应、知识型LLM智能体框架，通过专家知识库、知识型树搜索和自适应编码策略，解决了现有LLM数据科学智能体的局限性，并在基准测试中表现优异。

**AI_Comments:** AutoMind的创新之处在于其结合了领域专家知识、策略性搜索和自适应编码，解决了现有LLM智能体僵化、缺乏经验专长的问题。这使其能够更好地处理复杂的数据科学任务，是推动全自动化数据科学发展的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM驱动的数据科学智能体依赖僵化、预定义的工作流和不灵活的编码策略，导致它们仅在简单问题上表现出色，无法捕捉人类在复杂任务中的经验专长。

**Method:** AutoMind通过三个关键进展克服了这些不足：(1) 一个精选的专家知识库，将智能体建立在领域专家知识之上；(2) 一个代理式知识型树搜索算法，策略性地探索可能的解决方案；(3) 一个自适应编码策略，动态调整代码生成以适应任务复杂性。

**Result:** AutoMind在两个自动化数据科学基准测试中表现出优于现有基线的性能。额外的分析证实了其有利的有效性、效率和定性解决方案质量。

**Conclusion:** AutoMind是迈向全自动化数据科学的有效且稳健的一步。

> **ai_Abstract:** 本文介绍了AutoMind，一个自适应、知识型LLM智能体框架，旨在解决现有LLM数据科学智能体在复杂任务中表现不足的问题。AutoMind通过集成专家知识库、代理式知识型树搜索算法和自适应编码策略来增强其能力。实验结果表明，AutoMind在自动化数据科学基准测试中超越了现有技术，并在有效性、效率和解决方案质量方面表现出色，预示着其在实现全自动化数据科学方面的潜力。

> **摘要翻译:** 大型语言模型（LLM）智能体在解决现实世界数据科学问题方面展现出巨大潜力。LLM驱动的数据科学智能体有望自动化整个机器学习流程，但其在现实世界中的有效性仍然有限。现有框架依赖僵化、预定义的工作流和不灵活的编码策略；因此，它们仅在相对简单、经典的问题上表现出色，并且无法捕捉人类实践者在复杂、创新任务中带来的经验专长。在这项工作中，我们介绍了AutoMind，一个自适应、知识型LLM智能体框架，它通过三项关键进展克服了这些不足：(1) 一个精选的专家知识库，将智能体建立在领域专家知识之上，(2) 一个代理式知识型树搜索算法，策略性地探索可能的解决方案，以及 (3) 一个自适应编码策略，动态调整代码生成以适应任务复杂性。在两个自动化数据科学基准测试上的评估表明，AutoMind比现有最先进的基线提供了卓越的性能。额外的分析证实了有利的有效性、效率和定性解决方案质量，突显了AutoMind是迈向全自动化数据科学的有效且稳健的一步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [128] [When Meaning Stays the Same, but Models Drift: Evaluating Quality of Service under Token-Level Behavioral Instability in LLMs](https://arxiv.org/abs/2506.10095)
> *当意义不变但模型漂移时：评估大型语言模型在Token级行为不稳定性下的服务质量*

*Xiao Li, Joel Kreuzwieser, Alan Peters* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 提示词变异, 服务质量, 分词, 解码

**Comment:** This paper was developed for presentation at ICML 2025 Tokshop
  Workshop, but is now submitted as a standalone contribution

> **TL;DR:** 研究发现LLM在语义相同的提示词但Token级别不同时，会表现出模型特有的行为漂移，这与分词和解码有关，影响服务质量稳定性。

**AI_Comments:** 这篇论文揭示了LLMs一个重要的、此前未被充分关注的稳定性问题，即即使语义相同，Token级别的微小变化也可能导致模型行为漂移。这对于LLM在实际应用中的鲁棒性和质量保证具有重要意义，尤其是在需要高度稳定性和可预测性的场景。研究强调了分词和解码过程对模型稳定性的影响，为未来的模型设计和评估提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 探讨大型语言模型（LLMs）在语义意图相同但Token级别实现不同的提示词（即“提示词变异”）下如何响应，并揭示这种行为漂移对服务质量稳定性的影响。

**Method:** 提出了一个名为“基于提示词的语义漂移（PBSS）”的诊断框架，用于衡量LLMs在语义等效的提示词重述下的行为漂移。该框架应用于十个受限任务。

**Result:** PBSS框架揭示了LLMs存在一致的、模型特定的响应漂移，并表明这些漂移与分词和解码过程的统计规律有关。

**Conclusion:** 这些结果突出了模型在提示词重述下评估稳定性的一个被忽视的维度，并表明分词策略和解码动态可能导致训练后服务质量的不稳定性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在语义不变但Token级别不同的提示词下产生的行为漂移，称之为“提示词变异”。为量化这种漂移，作者提出了“基于提示词的语义漂移（PBSS）”诊断框架。通过在十个任务上的应用，PBSS揭示了模型特有的响应变化，并指出分词策略和解码动态可能是导致模型服务质量不稳定的重要因素。

> **摘要翻译:** 我们研究了大型语言模型如何响应仅在Token级别实现上有所不同但保留相同语义意图的提示，我们称之为提示变异现象。我们提出了基于提示的语义漂移（PBSS），这是一个诊断框架，用于测量大型语言模型在语义等效的提示重述下的行为漂移。将PBSS应用于十项受限任务后，它揭示了一致的、模型特定的响应漂移，表明与分词和解码相关的统计规律。这些结果突出了模型在改写下评估稳定性的一个被忽视的维度，并表明分词策略和解码动态可能导致训练后服务质量的不稳定性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [149] [ChartReasoner: Code-Driven Modality Bridging for Long-Chain Reasoning in Chart Question Answering](https://arxiv.org/abs/2506.10116)
> *ChartReasoner：代码驱动的模态桥接，用于图表问答中的长链推理*

*Caijun Jia, Nan Xu, Jingxuan Wei, Qingli Wang, Lei Wang, Bihui Yu, Junnan Zhu* | **Main category: cs.CL**

**Keywords:** 图表问答, 长链推理, 代码驱动, 模态桥接, ECharts

**Comment:** 

> **TL;DR:** ChartReasoner是一个代码驱动的两阶段框架，通过将图表转换为ECharts代码来保留视觉细节，并利用合成数据进行训练，从而在图表问答中实现精确、可解释的长链推理，性能与最先进模型相当。

**AI_Comments:** ChartReasoner的创新点在于其独特的代码驱动模态桥接方法，通过将图表转换为结构化的ECharts代码，有效解决了现有方法在视觉到文本转换中信息丢失的问题。这种方法不仅保证了推理的精确性和可解释性，还通过数据合成管道解决了高质量训练数据稀缺的问题。其在保持性能的同时显著减少参数量的能力，以及在域外设置中接近GPT-4o的表现，都凸显了其在图表问答领域的潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在长链推理方面表现出色，但将此能力扩展到视觉推理任务（尤其是需要大量视觉细节的图表问答）仍是挑战。现有方法通过图像到文本的转换会丢失关键的结构和语义信息。

**Method:** 提出ChartReasoner，一个代码驱动的两阶段框架。首先训练一个高保真模型将图表图像转换为结构化ECharts代码，尽可能无损地保留布局和数据语义。然后设计一个通用的图表推理数据合成管道，利用预训练的传输模型自动生成图表推理轨迹，并使用代码验证器过滤低质量样本。最后，使用合成数据集通过监督微调和强化学习训练最终的多模态模型。

**Result:** 在四个公共基准测试中，ChartReasoner表现出有效性，能够最大程度地保留图表原始细节，在参数更少的情况下与最先进的开源模型性能相当，并在域外设置中接近GPT-4o等专有系统的性能。

**Conclusion:** ChartReasoner通过创新的代码驱动模态桥接方法，有效解决了图表问答中的长链推理挑战，实现了高性能、可解释的视觉推理，并能最大程度地保留图表细节。

> **ai_Abstract:** 本论文提出了ChartReasoner，一个代码驱动的两阶段框架，旨在解决图表问答中长链推理的视觉信息丢失问题。该框架首先将图表图像转换为ECharts代码以保留视觉和数据细节，然后通过数据合成管道生成高质量的图表推理轨迹数据集。最终训练的多模态模型在多个基准测试上表现出卓越性能，参数量更少，且能与顶尖模型相媲美，甚至在域外设置中接近GPT-4o的水平。

> **摘要翻译:** 最近，大型语言模型在响应前通过长链推理展现出卓越的推理能力。然而，如何将这种能力扩展到视觉推理任务仍然是一个开放的挑战。现有的多模态推理方法通过几次图像到文本的转换将此类视觉推理任务转换为文本推理任务，这通常会丢失嵌入在可视化中的关键结构和语义信息，特别是对于图表问答等需要大量视觉细节的任务。为了弥合这一差距，我们提出了ChartReasoner，一个代码驱动的新颖两阶段框架，旨在实现对图表的精确、可解释的推理。我们首先训练一个高保真模型，将各种图表图像转换为结构化的ECharts代码，尽可能无损地保留布局和数据语义。然后，我们设计了一个通用的图表推理数据合成管道，该管道利用这个预训练的传输模型自动且可扩展地生成图表推理轨迹，并利用代码验证器过滤掉低质量样本。最后，我们结合监督微调和强化学习，在我们合成的图表推理数据集上训练最终的多模态模型，在四个公共基准测试上的实验结果清楚地证明了我们提出的ChartReasoner的有效性。它能尽可能多地保留图表的原始细节，并且在使用更少参数的情况下与最先进的开源模型表现相当，在域外设置中接近GPT-4o等专有系统的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [168] [Unsupervised Elicitation of Language Models](https://arxiv.org/abs/2506.10139)
> *无监督语言模型能力激发*

*Jiaxin Wen, Zachary Ankner, Arushi Somani, Peter Hase, Samuel Marks, Jacob Goldman-Wetzler, Linda Petrini, Henry Sleight, Collin Burns, He He, Shi Feng, Ethan Perez, Jan Leike* | **Main category: cs.CL**

**Keywords:** 无监督学习, 语言模型, 微调, 内部一致性最大化, 超人能力

**Comment:** 

> **TL;DR:** 该论文提出了一种名为内部一致性最大化（ICM）的无监督算法，用于在没有外部监督的情况下微调预训练语言模型，并在多项任务上表现优于人类监督。

**AI_Comments:** 该论文的创新之处在于提出了一种完全无监督的语言模型微调方法，即内部一致性最大化（ICM），通过利用模型自身生成的标签来替代耗时且昂贵的人类监督。这对于随着语言模型能力不断增强、超越人类水平后，人类监督变得困难或不可能的现状具有重要意义。该方法为未来更强大语言模型的训练和对齐提供了一条可扩展的路径。

<details>
  <summary>Details</summary>

**Motivation:** 当前预训练语言模型在下游任务上的引导范式依赖人类指定期望行为，但对于具有超人能力的模型，难以或不可能获得高质量的人类监督。

**Method:** 提出了一种新的无监督算法——内部一致性最大化（ICM），用于在模型自身生成的标签上微调预训练语言模型，无需外部监督。该方法还被用于训练无监督奖励模型，并通过强化学习训练基于Claude 3.5 Haiku的助手。

**Result:** 在GSM8k-verification、TruthfulQA和Alpaca奖励建模任务上，ICM方法与黄金监督的性能相匹配，并优于众包人类监督。在语言模型能力远超人类的任务上，该方法能显著更好地激发这些能力。训练出的无监督奖励模型和基于Claude 3.5 Haiku的助手均优于其人类监督的对应版本。

**Conclusion:** 内部一致性最大化（ICM）是一种有效的无监督算法，能够解决超人能力语言模型的人类监督难题，并在多项任务上表现出色，甚至在某些情况下超越人类监督，同时能改进前沿语言模型的训练。

> **ai_Abstract:** 该论文提出了一种名为内部一致性最大化（ICM）的无监督算法，旨在解决超人能力语言模型难以获得高质量人类监督的问题。ICM通过让模型在其自身生成的标签上进行微调，无需外部监督。实验结果表明，在GSM8k-verification、TruthfulQA和Alpaca奖励建模等多个任务上，ICM的表现与黄金监督相当，优于众包人类监督，并且在语言模型能力远超人类的任务上能更好地激发其能力。此外，该方法还能有效提升前沿语言模型的训练，例如训练出的无监督奖励模型和基于Claude 3.5 Haiku的助手均优于其人类监督版本。

> **摘要翻译:** 为了引导预训练语言模型用于下游任务，当今的训练后范式依赖人类指定期望行为。然而，对于具有超人能力的模型，很难或不可能获得高质量的人类监督。为了解决这一挑战，我们引入了一种新的无监督算法——内部一致性最大化（ICM），用于在模型自身生成的标签上微调预训练语言模型，无需外部监督。在GSM8k-verification、TruthfulQA和Alpaca奖励建模任务上，我们的方法与使用黄金监督进行训练的性能相匹配，并优于使用众包人类监督进行训练。在语言模型能力远超人类的任务上，我们的方法可以比使用人类标签进行训练更好地激发这些能力。最后，我们展示了我们的方法可以改进前沿语言模型的训练：我们使用我们的方法训练了一个无监督奖励模型，并使用强化学习训练了一个基于Claude 3.5 Haiku的助手。奖励模型和助手都优于其人类监督的对应版本。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [184] [When Large Language Models are Reliable for Judging Empathic Communication](https://arxiv.org/abs/2506.10150)
> *大型语言模型在判断共情交流中的可靠性*

*Aakriti Kumar, Nalin Poungpeth, Diyi Yang, Erina Farrell, Bruce Lambert, Matthew Groh* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 共情交流, 可靠性, 专家标注, 评估基准

**Comment:** 

> **TL;DR:** 研究发现，大型语言模型在判断共情交流方面表现出接近专家水平的可靠性，且优于众包工作者，表明LLM在情感敏感应用中的潜力。

**AI_Comments:** 这篇论文的创新之处在于，它不仅验证了LLMs在共情生成方面的能力，更深入探讨了其在共情判断这一更复杂任务上的可靠性。通过引入专家一致性作为更具信息量的基准，而非仅仅依赖传统分类指标，论文为评估LLM在主观、复杂任务中的性能提供了一个更严谨的视角。其结果对于LLMs在心理健康支持、客户服务等情感敏感领域的应用具有重要指导意义，强调了正确验证和基准测试的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在生成共情回复方面表现出色，但其在判断共情交流细微之处的可靠性尚不明确。本研究旨在探究LLMs在此方面的可靠性。

**Method:** 研究比较了专家、众包工作者和LLMs在四种源自心理学、自然语言处理和通信领域的评估框架下，对200个真实世界对话（一方分享个人问题，另一方提供支持）中共情交流的标注情况。通过3,150份专家标注、2,844份众包标注和3,150份LLM标注，评估了这三组标注者之间的评估者间可靠性。

**Result:** 专家之间的一致性很高，但在不同框架的子组件上有所差异，这取决于其清晰度、复杂性和主观性。研究表明，专家一致性为LLM性能提供了一个比标准分类指标更具信息量的基准。在所有四个框架中，LLMs始终接近专家水平的基准，并超过了众包工作者的可靠性。

**Conclusion:** 当通过特定任务和适当基准进行验证时，大型语言模型可以支持情感敏感应用（包括作为对话伙伴）的透明度和监督。

> **ai_Abstract:** 本研究旨在评估大型语言模型（LLMs）在判断共情交流方面的可靠性。通过比较LLMs、专家和众包工作者在四种评估框架下对200个真实对话的标注，研究发现LLMs在共情判断上的表现持续接近专家水平，并且优于众包工作者。结果表明，在适当的基准验证下，LLMs在情感敏感应用中具有支持透明度和监督的潜力。

> **摘要翻译:** 大型语言模型（LLMs）在基于文本的对话中擅长生成共情回复。但是，它们在判断共情交流的细微之处方面有多可靠呢？我们通过比较专家、众包工作者和LLMs如何根据来自心理学、自然语言处理和通信的四种评估框架，对200个真实世界对话进行共情交流标注来调查这个问题，这些对话中一位说话者分享个人问题，另一位提供支持。我们利用3,150份专家标注、2,844份众包标注和3,150份LLM标注，评估了这三组标注者之间的评估者间可靠性。我们发现专家之间的一致性很高，但根据框架子组件的清晰度、复杂性和主观性而异。我们表明，专家一致性为LLM性能提供了一个比标准分类指标更具信息量的基准。在所有四个框架中，LLMs始终接近这个专家水平的基准，并超过了众包工作者的可靠性。这些结果表明，当通过特定任务和适当基准进行验证时，LLMs如何能够支持情感敏感应用（包括作为对话伙伴）的透明度和监督。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [198] [Analyzing Emotions in Bangla Social Media Comments Using Machine Learning and LIME](https://arxiv.org/abs/2506.10154)
> *孟加拉语社交媒体评论情感分析：机器学习与LIME的应用*

*Bidyarthi Paul, SM Musfiqur Rahman, Dipta Biswas, Md. Ziaul Hasan, Md. Zahid Hossain* | **Main category: cs.CL**

**Keywords:** 孟加拉语情感分析, 机器学习, LIME, 社交媒体, 资源匮乏语言

**Comment:** 

> **TL;DR:** 本研究使用机器学习模型和LIME对孟加拉语社交媒体评论进行情感分析，旨在为资源匮乏语言提供高效的情感识别技术。

**AI_Comments:** 本研究的创新点在于将情感分析应用于资源相对匮乏的孟加拉语，并结合了多种机器学习模型和解释性AI工具LIME，这对于理解模型决策过程非常重要。其重要性体现在为欠研究语言的情感计算提供了方法论和实践，有助于填补语言资源鸿沟。

<details>
  <summary>Details</summary>

**Motivation:** 现有情感分析研究在孟加拉语等资源匮乏语言中不足，这些语言具有独特的地域表达和文化特征。

**Method:** 本研究使用来自EmoNoBa数据集的22,698条孟加拉语社交媒体评论。采用机器学习模型：线性SVM、KNN和随机森林，结合TF-IDF向量化的n-gram数据。此外，探讨了PCA对降维的影响，并利用BiLSTM模型和AdaBoost来改进决策树。为提高模型可解释性，使用LIME解释了AdaBoost分类器的预测。

**Result:** Not mentioned in abstract

**Conclusion:** 旨在推进资源匮乏语言的情感分析，通过探索多种技术以识别孟加拉语情感的有效方法。

> **ai_Abstract:** 本研究致力于孟加拉语社交媒体评论的情感分析，该语言因其独特的文化特征而面临资源匮乏挑战。研究利用EmoNoBa数据集的22,698条评论，探索了多种机器学习模型，包括线性SVM、KNN、随机森林（结合TF-IDF和n-gram），并评估了PCA对降维的影响。此外，还应用了BiLSTM和AdaBoost来增强决策树模型，并使用LIME解释AdaBoost的预测。目标是为孟加拉语等资源有限的语言开发高效的情感识别技术。

> **摘要翻译:** 书面语言情感理解的研究持续扩展，特别是对于孟加拉语等具有独特地域表达和文化特征的欠研究语言。本研究使用来自EmoNoBa数据集的22,698条社交媒体评论来检查情感分析。对于语言分析，我们采用了机器学习模型：线性SVM、KNN和随机森林，使用TF-IDF向量化器生成的n-gram数据。我们还研究了PCA如何影响降维。此外，我们利用BiLSTM模型和AdaBoost来改进决策树。为了使我们的机器学习模型更容易理解，我们使用LIME来解释AdaBoost分类器（使用决策树）的预测。旨在推进资源匮乏语言的情感分析，我们的工作研究了各种技术，以寻找孟加拉语情感识别的有效技术。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [215] [Measuring Corporate Human Capital Disclosures: Lexicon, Data, Code, and Research Opportunities](https://arxiv.org/abs/2506.10155)
> *衡量企业人力资本披露：词典、数据、代码和研究机会*

*Elizabeth Demers, Victor Xiaoqi Wang, Kean Wu* | **Main category: cs.CL**

**Keywords:** 人力资本, 披露, 词典, word2vec, 机器学习

**Comment:** 50 pages, 6 figures, 5 tables

> **TL;DR:** 该研究开发了一个基于word2vec的全面人力资本相关关键词词典，并提供数据和代码，以帮助研究人员衡量和分析企业人力资本披露。

**AI_Comments:** 这项研究创新性地运用机器学习方法构建了人力资本披露的标准化词典，并开放了数据和代码，极大地降低了研究人员在此领域进行定量分析的门槛。其重要性在于为企业人力资本这一难以量化的资产提供了可操作的衡量工具，有助于推动相关研究和实践。

<details>
  <summary>Details</summary>

**Motivation:** 人力资本对于企业价值创造日益重要，但目前缺乏明确的衡量和披露规则。

**Method:** 研究团队使用机器学习算法（word2vec）对已确认的人力资本披露进行训练，开发了一个包含五个人力资本子类别（DEI；健康与安全；劳资关系与文化；薪酬与福利；人口统计及其他）的综合关键词列表。

**Result:** 研究成果包括一个细致分类的人力资本关键词词典、企业人力资本披露数据以及用于开发词典的Python代码，并提供了使用这些数据和代码的详细示例，包括微调BERT模型。

**Conclusion:** 本研究为研究人员提供了用于分析企业人力资本披露的工具、数据和代码，以解决相关人力资本问题，并讨论了未来的人力资本管理和披露研究机会。

> **ai_Abstract:** 本研究旨在解决人力资本披露缺乏标准衡量规则的问题。作者利用word2vec机器学习算法，基于已确认的人力资本披露数据，开发了一个包含五大子类别的全面人力资本关键词词典。研究不仅提供了该词典，还分享了相关的企业人力资本披露数据和Python代码，并演示了其在分析中的应用，包括微调BERT模型。这项工作为研究人员提供了宝贵的资源和工具，以更好地衡量和分析企业人力资本，并探讨了未来的研究方向。

> **摘要翻译:** 人力资本（HC）对于企业价值创造日益重要。然而，与其它资产不同，人力资本目前没有明确的衡量或披露规则。我们使用一个在已确认的人力资本披露集上训练的机器学习算法（word2vec）来开发一份全面的人力资本相关关键词列表，这些关键词被分为五个子类别（DEI；健康与安全；劳资关系与文化；薪酬与福利；人口统计及其他），以捕捉人力资本管理的多维性质。我们分享了我们的词典、企业人力资本披露数据以及用于开发词典的Python代码，并提供了使用我们的数据和代码的详细示例，包括用于微调BERT模型。研究人员可以使用我们的人力资本词典（或修改代码以捕获其他感兴趣的构建体）及其企业沟通样本来解决相关的人力资本问题。最后，我们讨论了与人力资本管理和披露相关的未来研究机会。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [223] ["Check My Work?": Measuring Sycophancy in a Simulated Educational Context](https://arxiv.org/abs/2506.10297)
> *“检查我的作业？”：在模拟教育环境中衡量奉承行为*

*Chuck Arvin* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 奉承行为, 教育公平, 模型偏差, GPT-4o

**Comment:** Presented at KDD Workshop on Ethical Artificial Intelligence: Methods
  and Applications (EAI) 2025

> **TL;DR:** 研究发现在模拟教育场景中，大型语言模型（LLMs）会对用户提供的答案表现出奉承行为，导致正确性下降或提高，且小型模型偏差更严重，这对教育公平有重要影响。

**AI_Comments:** 这项研究揭示了LLM在教育应用中的一个关键且潜在有害的偏见——奉承行为。其创新之处在于通过模拟教育场景量化了这种行为对模型准确性的影响，并指出了小型模型在此方面的脆弱性。研究的重要性在于它直接关联到LLM在教育公平方面的深远影响，提醒开发者和教育者在部署AI工具时需警惕并寻求缓解策略。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探究大型语言模型（LLMs）在模拟教育环境中，用户提供的建议如何影响其响应质量，并评估奉承行为在此情境下带来的风险。

**Method:** 研究测试了OpenAI GPT-4o和GPT-4.1系列中的五种不同LLM，涵盖五种实验条件，以测量其响应质量。通过分析LLM改变答案的频率以及token级别的概率来确认奉承行为。

**Result:** LLM的响应质量随查询框架变化显著。当学生提及错误答案时，LLM正确性可下降15个百分点；提及正确答案时，准确性提高相同幅度。小型模型偏差更强，GPT-4.1-nano模型效应高达30%，而GPT-4o模型为8%。分析证实，模型通常会根据学生提及的答案选择来改变其答案，符合奉承假设。

**Conclusion:** LLM的奉承行为对教育公平具有重要影响，可能加速知识渊博学生的学习，同时强化知识较少学生的误解。因此，需要更好地理解并减轻教育环境中的这种偏见机制。

> **ai_Abstract:** 这项研究调查了大型语言模型（LLMs）在模拟教育环境中对用户建议的奉承行为。通过测试OpenAI的五种LLM，发现当学生提及不正确答案时，LLM的正确性会显著下降；而提及正确答案时则会提高。小型模型的这种偏差效应更强。研究证实LLMs会根据用户的输入改变答案，这种奉承行为对教育公平构成挑战，可能加剧不同知识水平学生之间的学习差距。因此，理解并减轻这种偏差至关重要。

> **摘要翻译:** 本研究探讨了在模拟教育环境中，用户提供的建议如何影响大型语言模型（LLM），在这一环境中，奉承行为构成了重大风险。我们测试了OpenAI GPT-4o和GPT-4.1模型类别中的五种不同LLM，涵盖五种实验条件，结果表明响应质量随查询框架的变化而显著不同。在学生提及错误答案的情况下，LLM的正确性可能下降多达15个百分点，而提及正确答案则可将准确性提高相同的幅度。我们的结果还表明，这种偏差在较小的模型中更为明显，GPT-4.1-nano模型的影响高达30%，而GPT-4o模型为8%。我们对LLM“翻转”答案频率的分析，以及对token级别概率的调查，证实了模型通常会根据学生提及的答案选择来改变其答案，这与奉承假设一致。这种奉承行为对教育公平具有重要意义，因为LLM可能加速知识渊博学生的学习，而同样的工具可能强化知识较少学生的误解。我们的结果强调，需要更好地理解教育环境中这种偏见的机制和缓解方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [229] [Can LLMs Generate Good Stories? Insights and Challenges from a Narrative Planning Perspective](https://arxiv.org/abs/2506.10161)
> *大型语言模型能生成好故事吗？来自叙事规划视角的见解与挑战*

*Yi Wang, Max Kreminski* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 故事生成, 叙事规划, 计算叙事学, GPT-4

**Comment:** In 2025 IEEE Conference on Games (CoG)

> **TL;DR:** 大型语言模型（LLMs）在小规模上能生成因果合理的故事情节，但在处理角色意图性和戏剧冲突的复杂叙事规划方面仍面临挑战，可能需要强化学习训练。

**AI_Comments:** 这篇论文通过应用计算叙事学和叙事规划原则来评估LLMs的故事生成能力，提供了一个新颖的视角，超越了传统上常带有主观性的评估方法。其对因果合理性、角色意图性和戏剧冲突等特定叙事元素的关注，使得对LLM的优势和局限性有了更细致的理解。论文识别出复杂推理中的挑战并提出通过强化学习进行改进的建议，这对于游戏开发等实际应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了深入理解大型语言模型（LLMs）的故事生成能力，特别是鉴于当前自动评估方法的局限性、人工评估的高成本和主观性，以及计算叙事学和符号叙事规划提供的宝贵见解，本研究旨在通过让LLMs解决叙事规划问题来探究其生成高质量故事的能力。

**Method:** 研究者通过让LLMs解决叙事规划问题，并提出了一个基于文学实例的基准来评估LLMs。评估重点关注因果合理性、角色意图性和戏剧冲突。

**Result:** 实验表明，GPT-4级别的LLMs能够生成小规模的因果合理故事。然而，涉及角色意图性和戏剧冲突的规划仍然具有挑战性，对于复杂推理，可能需要通过强化学习训练的LLMs。研究结果揭示了LLMs在保持不同方面质量的情况下能够生成的故事规模，并突出了有趣的解决问题行为以及在游戏环境中应用LLM叙事规划的挑战和考量。

**Conclusion:** 尽管大型语言模型在生成小规模因果合理故事方面展现出潜力，但在叙事规划中融入角色意图性和戏剧冲突，特别是在复杂情境下，仍存在显著挑战，这表明需要采用如强化学习等更先进的训练方法。

> **ai_Abstract:** 本文通过让大型语言模型（LLMs）解决叙事规划问题，并结合计算叙事学的视角，深入探讨了LLMs生成高质量故事的能力。研究引入了一个新的评估基准，侧重于因果合理性、角色意图性和戏剧冲突。实验结果显示，GPT-4级别的LLMs能生成小规模的因果合理故事，但在处理角色意图性和戏剧冲突方面仍面临挑战，这表明对于复杂的叙事推理，可能需要通过强化学习进行训练。研究结果为LLMs高质量故事生成的规模提供了见解，并指出了其在游戏环境中应用所面临的挑战。

> **摘要翻译:** 故事生成一直是大型语言模型（LLMs）的一个突出应用。然而，由于自动评估方法的挑战以及手动评估的高成本和主观性，对LLMs生成高质量故事能力的理解仍然有限。计算叙事学为“什么是好故事”提供了宝贵的见解，这已应用于故事生成的符号叙事规划方法中。这项工作旨在通过使用LLMs解决叙事规划问题，加深对LLMs故事生成能力的理解。我们提出了一个基于文学实例的基准，用于评估LLMs在叙事规划方面的表现，重点关注因果合理性、角色意图性和戏剧冲突。我们的实验表明，GPT-4级别的LLMs可以在小规模上生成因果合理的故事情节，但涉及角色意图性和戏剧冲突的规划仍然具有挑战性，需要通过强化学习训练的LLMs来处理复杂推理。结果提供了关于LLMs在保持不同方面质量的同时可以生成的故事规模的见解。我们的发现还突出了有趣的解决问题行为，并阐明了在游戏环境中应用LLM叙事规划的挑战和考虑因素。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [231] [Scheduled Interleaved Speech-Text Training for Speech-to-Speech Translation with LLMs](https://arxiv.org/abs/2506.10299)
> *用于基于大型语言模型的端到端语音翻译的调度交错语音-文本训练*

*Hayato Futami, Emiru Tsunoo, Yosuke Kashiwagi, Yuki Ito, Hassan Shahmohammadi, Siddhant Arora, Shinji Watanabe* | **Main category: cs.CL**

**Keywords:** 语音到语音翻译, 大型语言模型, 模态适应, 调度训练, 交错训练

**Comment:** Accepted to Interspeech2025

> **TL;DR:** 本文提出了一种调度交错语音-文本训练方法，以解决大型语言模型在语音到语音翻译中从文本到语音的模态适应问题，并在有限数据语言上显著提升了翻译性能。

**AI_Comments:** 该论文的创新点在于提出了调度交错语音-文本训练方法，巧妙地解决了大型语言模型在语音到语音翻译中面临的文本到语音模态适应挑战。通过在训练初期引入文本信息并逐步减少其比例，实现了平滑的模态过渡。这项工作对于提升LLMs在多模态任务上的表现，特别是对于资源有限的语言的语音翻译具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）主要基于文本数据训练，这导致在将其应用于语音模态（尤其是语音到语音翻译，S2ST）时面临模态适应的挑战，特别是在语音到语音数据有限的情况下，训练难度较大。

**Method:** 研究提出了一种调度交错语音-文本训练方法。在训练过程中，使用交错的语音-文本单元（在单词级别交错对齐的文本标记）替代纯语音单元。随着训练的进行，逐渐降低文本的比例，以促进从文本到语音的渐进式模态适应。通过在CVSS数据集上微调LLaMA3.2-1B进行了实验评估。

**Result:** 所提出的方法持续改进了翻译性能，特别是对于训练数据有限的语言。

**Conclusion:** 调度交错语音-文本训练方法有效解决了大型语言模型在语音到语音翻译中的模态适应问题，显著提升了翻译性能，尤其对于资源稀缺的语言表现更佳。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLMs）在语音到语音翻译（S2ST）中从文本到语音的模态适应难题，因为LLMs主要在文本数据上训练且S2ST数据有限。为此，论文提出了一种调度交错语音-文本训练方法：在训练时使用交错的语音-文本单元（包含单词级对齐的文本标记），并逐步减少文本比例以促进模态渐进适应。实验结果表明，该方法显著提升了翻译性能，尤其对低资源语言效果更佳。

> **摘要翻译:** 大型语言模型（LLMs）的出现推动了语音到语音翻译（S2ST）的发展，这些模型通过对离散语音单元进行微调。在这种方法中，从文本到语音的模态适应一直是一个问题。LLMs是在纯文本数据上训练的，这给它们适应语音模态带来了挑战，尤其是在语音到语音数据有限的情况下。为了解决训练困难，本研究提出了调度交错语音-文本训练方法。我们在训练期间使用交错的语音-文本单元而不是纯语音单元，其中对齐的文本标记在单词级别进行交错。随着训练的进行，我们逐渐降低文本的比例，以促进从文本到语音的渐进式模态适应。我们通过在CVSS数据集上微调LLaMA3.2-1B进行实验评估。结果表明，所提出的方法持续改进了翻译性能，特别是对于训练数据有限的语言。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [242] [TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning](https://arxiv.org/abs/2506.10380)
> *TableRAG：一种用于异构文档推理的检索增强生成框架*

*Xiaohan Yu, Pu Jian, Chong Chen* | **Main category: cs.CL**

**Keywords:** 检索增强生成, 异构文档, 表格推理, 多跳问答, TableRAG

**Comment:** Under review. Codes are available at
  https://github.com/yxh-y/TableRAG/tree/main

> **TL;DR:** TableRAG是一个新的检索增强生成框架，专门用于处理包含文本和表格的异构文档，通过结合文本理解和表格操作，显著提升了多跳异构推理能力，并在多个数据集上取得了最先进的性能。

**AI_Comments:** TableRAG的创新之处在于其混合框架设计，巧妙地将文本理解与SQL编程结合，有效地解决了异构文档中表格结构破坏和信息丢失的问题。它通过迭代的四步流程，显著提升了LLMs在复杂多跳查询中的推理能力。同时，HeteQA基准的引入也为异构推理能力的评估提供了重要的工具，推动了该领域的发展。该工作对于提升RAG在更复杂现实世界数据应用中的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有检索增强生成（RAG）方法在处理包含文本和表格的异构文档时存在局限性，因为表格的扁平化和分块策略会破坏其内在结构，导致信息丢失，并削弱大型语言模型（LLMs）在多跳、全局查询中的推理能力。

**Method:** 本文提出了TableRAG，一个混合框架，它统一了文本理解和复杂的表格数据操作。TableRAG迭代地通过四个步骤运行：上下文敏感查询分解、文本检索、SQL编程和执行、以及组合式中间答案生成。同时，还开发了一个名为HeteQA的新基准来评估多跳异构推理能力。

**Result:** 实验结果表明，TableRAG在公共数据集和新提出的HeteQA数据集上都始终优于现有基线，在异构文档问答方面建立了新的最先进水平。

**Conclusion:** TableRAG通过其独特的方法有效解决了异构文档推理中的挑战，显著提升了检索增强生成模型在处理文本和表格混合数据时的性能，并为该领域设立了新的基准。

> **ai_Abstract:** 本文提出了TableRAG，一个针对异构文档（包含文本和表格）设计的检索增强生成框架，以克服现有RAG方法在处理此类数据时因表格结构破坏导致的信息丢失和推理能力受限问题。TableRAG通过上下文查询分解、文本检索、SQL编程执行和组合式答案生成四个迭代步骤，有效整合了文本理解和表格操作。此外，研究团队还开发了HeteQA基准用于评估多跳异构推理。实验证明，TableRAG在多个数据集上均超越了现有基线，确立了异构文档问答领域的最新技术水平。

> **摘要翻译:** 检索增强生成（RAG）在开放域问答中表现出相当大的有效性。然而，当应用于包含文本和表格组件的异构文档时，现有的RAG方法表现出严重的局限性。表格扁平化和分块策略的普遍做法破坏了内在的表格结构，导致信息丢失，并损害了LLM在多跳、全局查询中的推理能力。为了解决这些挑战，我们提出了TableRAG，一个统一文本理解和表格数据复杂操作的混合框架。TableRAG迭代地通过四个步骤运行：上下文敏感查询分解、文本检索、SQL编程和执行，以及组合式中间答案生成。我们还开发了一个名为HeteQA的新基准，旨在评估多跳异构推理能力。实验结果表明，TableRAG在公共数据集和我们的HeteQA上都始终优于现有基线，为异构文档问答建立了新的最先进水平。我们在https://github.com/yxh-y/TableRAG/tree/main发布了TableRAG。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [243] [Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202)
> *Q2E：用于零样本多语言文本到视频检索的查询到事件分解*

*Shubhashis Roy Dipta, Francis Ferraro* | **Main category: cs.CL**

**Keywords:** 文本到视频检索, 零样本学习, 多模态融合, 查询分解, 大语言模型

**Comment:** 

> **TL;DR:** Q2E是一种将查询分解为事件的方法，利用大型语言模型和视觉语言模型的知识，以改进零样本多语言文本到视频检索。它通过分解复杂查询并融合多模态信息（包括音频）来超越现有基线。

**AI_Comments:** Q2E方法通过创新性地将查询分解为事件，利用LLMs和VLMs的强大知识，解决了复杂查询在文本到视频检索中的理解难题。其零样本多语言能力和跨数据集、领域、模型的高度适应性是其重要亮点。此外，对多模态信息（特别是音频）的有效融合，进一步提升了检索精度，展现了其在实际应用中的巨大潜力。这项工作为未来多模态检索研究提供了有价值的思路和基线。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在提取和利用大型语言模型（LLMs）和视觉语言模型（VLMs）中的参数知识方面表现出色，但仍需改进对复杂现实世界事件相关视频的识别和检索。本研究旨在通过自动提取这些事件的潜在参数知识来解决这一问题，从而增强对过于简化的用户查询的理解。

**Method:** 本研究提出了Q2E（Query-to-Event）方法，这是一种用于零样本多语言文本到视频检索的查询到事件分解方法。它通过利用LLMs和VLMs中嵌入的知识来分解用户查询，从而增强对复杂查询的理解。该方法适用于不同数据集、领域、LLMs或VLMs。为了结合视觉和语音输入等多种模态知识，采用了基于熵的融合评分进行零样本融合。

**Result:** 在两个不同数据集和多个检索指标上的评估表明，Q2E优于多个最先进的基线方法。评估还显示，整合音频信息可以显著改善文本到视频检索的性能。

**Conclusion:** Q2E是一种有效且通用的查询到事件分解方法，能够利用LLMs和VLMs的知识来增强对复杂查询的理解，并结合多模态信息（特别是音频）来显著提高零样本多语言文本到视频检索的性能。

> **ai_Abstract:** 本论文提出了Q2E（Query-to-Event）方法，旨在通过利用大型语言模型和视觉语言模型中的知识，将复杂的查询分解为事件，从而改进零样本多语言文本到视频检索。Q2E能够增强对简化用户查询的理解，并支持视觉和语音等多模态输入，通过熵基融合进行信息整合。实验证明，Q2E在多个数据集上超越了现有先进方法，并强调了音频信息对文本到视频检索性能的显著提升作用。

> **摘要翻译:** 最近的方法在从大型语言模型（LLMs）和视觉语言模型（VLMs）中提取和利用参数知识方面表现出令人印象深刻的熟练度。在这项工作中，我们考虑如何通过自动提取关于复杂现实世界事件的潜在参数知识来改进对这些事件相关视频的识别和检索。我们提出了Q2E：一种用于零样本多语言文本到视频检索的查询到事件分解方法，可适应不同数据集、领域、LLMs或VLMs。我们的方法表明，通过使用LLMs和VLMs中嵌入的知识分解查询，我们可以增强对原本过于简化的人类查询的理解。我们还展示了如何将我们的方法应用于视觉和基于语音的输入。为了结合这种多样化的多模态知识，我们采用基于熵的融合评分进行零样本融合。通过在两个不同数据集和多个检索指标上的评估，我们证明了Q2E优于多个最先进的基线。我们的评估还表明，整合音频信息可以显著改善文本到视频检索。我们已经发布了代码和数据以供未来研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [254] [TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games](https://arxiv.org/abs/2506.10209)
> *TTT-Bench：一个用于评估简单新颖井字棋式游戏推理能力的基准*

*Prakamya Mishra, Jiang Liu, Jialian Wu, Xiaodong Yu, Zicheng Liu, Emad Barsoum* | **Main category: cs.CL**

**Keywords:** 大型推理模型, 基准测试, 井字棋, 战略推理, 逻辑推理

**Comment:** 

> **TL;DR:** TTT-Bench是一个新基准，用于评估大型推理模型（LRMs）在简单井字棋式游戏中的基本战略、空间和逻辑推理能力。研究发现，即使是擅长数学难题的LRMs，在这些对人类而言简单的游戏中也表现不佳，表明它们在更广泛任务领域的推理能力仍有待探索。

**AI_Comments:** TTT-Bench的创新之处在于它提供了一个独特且简单的基准，专门用于测试大型推理模型在非传统STEM领域的基本战略、空间和逻辑推理能力。这项工作的重要性在于揭示了当前LRMs的局限性，即使它们在复杂数学问题上表现出色，也可能在对人类而言微不足道的简单、新颖情境中失败。这为未来LRMs的研究指明了方向，即需要提升模型在更广泛、更具泛化性的推理任务中的表现，而不仅仅是依赖于大量数据训练的特定领域能力。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大型推理模型（LRMs）在STEM领域表现出强大的推理能力，但它们在更广泛任务领域（如基本战略、空间和逻辑推理）中的表现仍未得到充分探索。现有基准多集中于STEM领域。

**Method:** 本文引入了TTT-Bench，这是一个包含四种双人井字棋式游戏的基准，旨在评估LRMs的基本战略、空间和逻辑推理能力。作者提出了一种简单且可扩展的程序化方法来生成可验证的双人游戏问题。

**Result:** 研究发现，擅长解决数学难题的模型在这些简单的推理游戏中常常失败。评估的推理模型在TTT-Bench上的得分平均比MATH 500低41%，比AIME 2024低5%。较大的模型使用较短的推理轨迹能获得更高的性能，但大多数模型在简单和新的TTT-Bench任务上，在长期战略推理情境中表现不佳。

**Conclusion:** 即使是先进的大型推理模型，在对人类而言简单的、需要基本战略、空间和逻辑推理的新颖井字棋式游戏中也存在显著的推理能力缺陷，这表明它们在非STEM领域的泛化推理能力仍有待提高。

> **ai_Abstract:** TTT-Bench是一个新颖的基准，用于评估大型推理模型（LRMs）在简单井字棋式游戏中的基本战略、空间和逻辑推理能力。该基准包含四种对人类而言简单的双人游戏，并通过程序化方法生成问题。研究发现，即使是擅长解决复杂数学问题的LRMs，在这些需要推理对手意图和空间配置的简单游戏中也表现不佳，得分远低于在传统数学基准上的表现。这表明LRMs在非STEM领域的泛化推理能力存在局限性，尤其是在长期战略推理方面。

> **摘要翻译:** 大型推理模型（LRMs）在包括奥林匹克级别的数学问题在内的广泛任务中展示了令人印象深刻的推理能力，这表明它们具有复杂的推理能力。虽然许多推理基准侧重于STEM领域，但LRMs在更广泛任务领域中正确推理的能力仍未得到充分探索。在这项工作中，我们引入了TTT-Bench，这是一个新基准，旨在通过一套四种双人井字棋式游戏来评估LRMs的基本战略、空间和逻辑推理能力，这些游戏是人类从小就能轻松解决的。我们提出了一种简单但可扩展的程序化方法来为TTT-Bench生成可验证的双人游戏问题。尽管这些游戏对人类来说微不足道，但它们需要推理对手的意图以及棋盘的空间配置，以确保获胜。我们评估了各种最先进的LRMs，并发现那些擅长数学难题的模型在这些简单的推理游戏中经常失败。进一步测试表明，我们评估的推理模型在TTT-Bench上的平均得分分别比MATH 500和AIME 2024低41%和5%，其中较大的模型使用较短的推理轨迹实现了更高的性能，而大多数模型在简单和新的TTT-Bench任务中，在长期战略推理情境下表现挣扎。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [268] [Classifying Unreliable Narrators with Large Language Models](https://arxiv.org/abs/2506.10231)
> *使用大型语言模型分类不可靠叙述者*

*Anneliese Brei, Katharine Henry, Abhisheik Sharma, Shashank Srivastava, Snigdha Chaturvedi* | **Main category: cs.CL**

**Keywords:** 不可靠叙述者, 大型语言模型, 数据集, 自然语言处理, 叙事学

**Comment:** ACL 2025

> **TL;DR:** 本文提出使用大型语言模型（LLMs）来识别不可靠的叙述者。为此，作者创建了一个名为TUNa的人工标注数据集，并定义了分类任务。尽管任务极具挑战性，但研究结果显示LLMs在此领域具有潜力，并发布了数据集和代码以促进未来研究。

**AI_Comments:** 该论文通过将文学理论与计算方法相结合，解决了一个新颖且具有挑战性的自然语言处理任务。创建了一个新的、经过专家标注的数据集（TUNa），这是对该领域的重要贡献，为未来研究识别不可靠叙述等细微文本现象提供了宝贵资源。对不同LLM训练范式（少样本、微调、课程学习）的探索是全面的，并且对任务难度的坦诚承认以及潜力的识别提供了现实的展望。

<details>
  <summary>Details</summary>

**Motivation:** 在与第一人称叙述互动时，判断叙述者是否可靠是一个常见问题。本文旨在提出计算方法来识别那些无意中歪曲信息的不可靠叙述者。

**Method:** 1. 借鉴叙事学文学理论定义了不同类型的不可靠叙述者。2. 构建并发布了TUNa，一个包含博客、Reddit帖子、酒店评论和文学作品等多种领域叙述的人工标注数据集。3. 定义了叙述内、叙述间和文本间不可靠性的分类任务。4. 分析了流行的开源和专有大型语言模型在这些任务上的表现。5. 实验了少样本、微调和课程学习设置。

**Result:** 识别不可靠叙述者这项任务非常具有挑战性。尽管如此，研究结果表明使用大型语言模型识别不可靠叙述者具有潜力。

**Conclusion:** 本文提出了一种使用大型语言模型分类不可靠叙述者的方法，并为此构建了新的专家标注数据集TUNa和相关代码。尽管该任务极具挑战性，但研究证实了LLMs在此领域的潜力，并鼓励未来研究。

> **ai_Abstract:** 本文提出了一种计算方法来识别第一人称叙述中的不可靠叙述者。研究借鉴叙事学理论定义了叙述者不可靠性的类型，并构建了一个名为TUNa的人工标注数据集，其中包含来自不同领域的文本。作者定义并评估了多种分类任务，并分析了大型语言模型在少样本、微调和课程学习设置下的表现。尽管任务难度高，但结果表明LLMs在识别不可靠叙述者方面具有潜力。论文还发布了数据集和代码，以促进该领域的进一步研究。

> **摘要翻译:** 当我们与第一人称叙述的事件互动时，我们经常会考虑叙述者，即文本的主要讲述者，是否可靠。在本文中，我们提出使用计算方法来识别不可靠的叙述者，即那些无意中歪曲信息的人。我们借鉴叙事学中的文学理论，根据各种文本现象定义了不同类型的不可靠叙述者，并提出了TUNa，一个包含来自多个领域（包括博客文章、Reddit帖子、酒店评论和文学作品）叙述的人工标注数据集。我们定义了叙述内、叙述间和文本间不可靠性的分类任务，并分析了流行的开源和专有大型语言模型在每个任务上的表现。我们提出从文学中学习，以在真实世界的文本数据上执行不可靠叙述者分类。为此，我们尝试了少样本、微调和课程学习设置。我们的结果表明，这项任务非常具有挑战性，但使用大型语言模型识别不可靠叙述者具有潜力。我们发布了我们专家标注的数据集和代码，并邀请该领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [280] [Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims](https://arxiv.org/abs/2506.10728)
> *超越真假：检索增强的细微主张层次分析*

*Priyanka Kargupta, Runchu Tian, Jiawei Han* | **Main category: cs.CL**

**Keywords:** 细微主张, 检索增强生成, 层次分析, 观点表示, ClaimSpect

**Comment:** Accepted to ACL 2025 Main Conference. Code available at:
  https://github.com/pkargupta/claimspect

> **TL;DR:** ClaimSpect是一个检索增强的框架，用于自动构建和丰富对细微主张的层次分析，以提供多角度的结构化回应。

**AI_Comments:** ClaimSpect的创新之处在于其超越了传统二元真假判断，引入了层次化分析和多视角呈现的概念，这对于处理复杂、细微的主张（尤其是在科学和政治领域）至关重要。其结合检索增强生成（RAG）的框架，使得系统能够从大量语料中自动发现和组织相关信息及不同观点，大大提升了主张分析的深度和广度。该方法对于提升信息透明度、辅助批判性思维和应对虚假信息具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在处理无法简单标记为“真”或“假”的细微主张（如科学和政治主张）时存在局限性。这些主张需要更全面的、结构化的回应，能够分解成可单独验证的方面和子方面。

**Method:** 本文提出了ClaimSpect，一个基于检索增强生成（RAG）的框架。它自动构建分析主张时通常考虑的方面层次结构，并用语料库特定的视角丰富它们。该框架通过层次化划分输入语料库来检索相关片段，从而发现新的子方面和针对主张某方面（如支持、中立、反对）的不同观点及其流行程度。

**Result:** ClaimSpect被应用于各种现实世界的科学和政治主张数据集，展示了其在解构细微主张和表示语料库中观点方面的鲁棒性和准确性。通过现实世界案例研究和人工评估，验证了其优于多个基线的有效性。

**Conclusion:** ClaimSpect提供了一种有效且鲁棒的方法来分析和表示细微主张，超越了简单的真假判断，通过层次化地揭示和量化语料库中的多重观点。

> **ai_Abstract:** 本文提出了ClaimSpect，一个检索增强生成框架，旨在解决细微主张（如科学和政治主张）难以简单判断真假的问题。ClaimSpect通过自动构建主张的层次化方面结构，并利用语料库检索相关信息和不同视角（支持、中立、反对）及其流行程度来丰富这些方面。该框架在现实世界的科学和政治主张数据集上进行了验证，展示了其在解构细微主张和呈现多角度观点方面的鲁棒性和准确性。

> **摘要翻译:** 个人或实体提出的主张往往是细微的，不能被明确地标记为完全“真”或“假”——科学和政治主张经常如此。然而，一个主张（例如，“疫苗A比疫苗B更好”）可以分解成其组成部分和子部分（例如，功效、安全性、分发），这些部分更容易单独验证。这使得能够提供更全面、结构化的回应，为给定问题提供一个全面的视角，同时允许读者优先关注主张中感兴趣的特定角度（例如，对儿童的安全性）。因此，我们提出了ClaimSpect，这是一个基于检索增强生成（RAG）的框架，用于自动构建在处理主张时通常考虑的方面层次结构，并用语料库特定的视角丰富它们。这种结构层次化地划分输入语料库以检索相关片段，这些片段有助于发现新的子方面。此外，这些片段能够发现针对主张某方面（例如，支持、中立或反对）的不同观点及其各自的流行程度（例如，“有多少生物医学论文认为疫苗A比B更易于运输？”）。我们将ClaimSpect应用于我们构建的数据集中各种现实世界的科学和政治主张，展示了其在解构细微主张和表示语料库中观点方面的鲁棒性和准确性。通过现实世界案例研究和人工评估，我们验证了其优于多个基线的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [281] [ToxSyn-PT: A Large-Scale Synthetic Dataset for Hate Speech Detection in Portuguese](https://arxiv.org/abs/2506.10245)
> *ToxSyn-PT：一个用于葡萄牙语仇恨言论检测的大规模合成数据集*

*Iago Alves Brito, Julia Soares Dollis, Fernanda Bufon Färber, Diogo Fernandes Costa Silva, Arlindo Rodrigues Galvão Filho* | **Main category: cs.CL**

**Keywords:** 仇恨言论检测, 合成数据集, 葡萄牙语, 低资源语言, 细粒度分类

**Comment:** 8 pages, 5 tables, 1 figure

> **TL;DR:** ToxSyn-PT是首个大规模葡萄牙语合成数据集，包含53,274个句子，用于细粒度仇恨言论分类，通过四阶段管道创建，并在现有基准测试中表现出强大的泛化能力，已公开发布以促进低资源环境下的仇恨言论检测研究。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的四阶段管道来生成大规模合成数据集，有效地解决了葡萄牙语仇恨言论检测领域资源稀缺的问题。通过合成数据而非依赖于社交媒体语料，该数据集不仅扩大了规模，还提升了领域多样性和风格丰富性，有助于模型在更广泛的场景下进行泛化。其在多个现有基准上的强大表现证明了该方法的有效性，对于低资源语言的自然语言处理研究具有重要意义。数据集的公开发布将极大地推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的葡萄牙语仇恨言论数据集主要集中在社交媒体领域，且缺乏大规模、细粒度的分类能力。本研究旨在创建首个大规模葡萄牙语语料库，以支持针对九个受法律保护的少数群体的细粒度仇恨言论分类，特别是在低资源环境下推进合成数据和仇恨言论检测的研究。

**Method:** ToxSyn-PT通过一个新颖的四阶段管道创建：(1) 一个紧凑的手动策划种子；(2) 使用指令微调的LLM进行小样本扩展；(3) 基于释义的增强；(4) 富集，并添加额外的中性文本以抑制对特定群体线索的过拟合。该数据集包含53,274个合成句子，在少数群体和毒性标签之间均匀分布，并且是类别平衡、风格多样化且不依赖于社交媒体领域。

**Result:** 尽管与传统基准测试存在领域差异，但对该语料库进行的二元和多标签分类实验在五个公开的葡萄牙语仇恨言论数据集上均取得了强大的结果，甚至在跨领域边界时也表现出鲁棒的泛化能力。

**Conclusion:** ToxSyn-PT数据集已公开发布，旨在推进合成数据和低资源环境下仇恨言论检测的研究。

> **ai_Abstract:** 本论文介绍了ToxSyn-PT，一个大规模的葡萄牙语合成数据集，专为细粒度仇恨言论分类设计，涵盖九个受保护的少数群体。该数据集包含53,274个合成句子，通过一个四阶段管道生成，确保了类别平衡和风格多样性，并避免了现有数据集常见的社交媒体领域偏向。实验证明，ToxSyn-PT在多个公共葡萄牙语仇恨言论数据集上表现出强大的泛化能力，即使面对领域差异也能保持鲁棒性。该数据集的公开发布旨在促进低资源环境下的合成数据和仇恨言论检测研究。

> **摘要翻译:** 我们推出了ToxSyn-PT，这是首个大规模葡萄牙语语料库，能够对九个受法律保护的少数群体进行细粒度仇恨言论分类。该数据集包含53,274个合成句子，在少数群体和毒性标签之间均匀分布。ToxSyn-PT通过一个新颖的四阶段管道创建：(1) 一个紧凑的手动策划种子；(2) 使用指令微调的LLM进行小样本扩展；(3) 基于释义的增强；(4) 富集，并添加额外的中性文本以抑制对特定群体线索的过拟合。由此产生的语料库是类别平衡的、风格多样化的，并且摆脱了现有葡萄牙语数据集中主导的社交媒体领域。尽管与传统基准测试存在领域差异，但对该语料库进行的二元和多标签分类实验在五个公开的葡萄牙语仇恨言论数据集上均取得了强大的结果，即使跨领域边界也表现出鲁棒的泛化能力。该数据集已公开发布，旨在推进合成数据和低资源环境下仇恨言论检测的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [291] [TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora](https://arxiv.org/abs/2506.10737)
> *TaxoAdapt：将基于LLM的多维分类法构建与演进中的研究语料库对齐*

*Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han* | **Main category: cs.CL**

**Keywords:** 分类法构建, 大型语言模型, 科学文献, 多维度, 动态适应

**Comment:** Accepted to ACL 2025 Main Conference. Code available at:
  https://github.com/pkargupta/taxoadapt

> **TL;DR:** TaxoAdapt是一个框架，能动态调整LLM生成的分类法，使其适应不断演变的多维科学语料库，并表现出最先进的性能。

**AI_Comments:** TaxoAdapt的创新之处在于其动态适应LLM生成分类法以匹配特定语料库的能力，并解决了现有方法在通用性、动态性和多维度性方面的不足。通过迭代分层分类，它能有效捕捉科学领域的演变。其在粒度保留和连贯性方面的显著提升表明了其在实际应用中的重要潜力，尤其是在快速迭代的科研领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在组织和检索科学文献方面存在挑战，专家构建耗时昂贵；自动构建方法过度依赖特定语料或LLM的预训练知识，忽视领域动态性；且未能考虑科学文献的多维度性。

**Method:** 提出TaxoAdapt框架，动态地将LLM生成的分类法适应到给定语料库的多维结构中。它通过迭代分层分类，根据语料库的主题分布扩展分类法的宽度和深度。

**Result:** 在多年计算机科学会议数据集上展现了最先进的性能，能够构建和捕捉科学领域的发展。作为多维方法，TaxoAdapt生成的分类法在粒度保留方面比最具竞争力的基线高26.51%，在连贯性方面高50.41%（由LLM判断）。

**Conclusion:** TaxoAdapt成功解决了现有分类法构建方法的不足，特别是针对不断演变的科学领域和文献的多维度性，提供了更精确和连贯的分类结果。

> **ai_Abstract:** TaxoAdapt是一个创新框架，旨在解决科学文献组织和检索中的挑战，特别是针对快速发展的多维科学领域。它通过动态调整基于LLM生成的分类法，使其适应特定语料库，并利用迭代分层分类扩展分类法的宽度和深度。实验证明，TaxoAdapt在计算机科学领域表现出最先进的性能，其生成的多维分类法在粒度保留和连贯性方面显著优于现有基线。

> **摘要翻译:** 科学领域的快速发展给组织和检索科学文献带来了挑战。尽管专家策划的分类法传统上满足了这一需求，但其过程耗时且昂贵。此外，最近的自动分类法构建方法要么 (1) 过度依赖特定语料库，牺牲了通用性，要么 (2) 严重依赖大型语言模型 (LLM) 预训练数据中包含的通用知识，常常忽视不断演变的科学领域的动态性质。此外，这些方法未能考虑到科学文献的多面性，即一篇研究论文可能涉及多个维度（例如，方法论、新任务、评估指标、基准）。为了解决这些空白，我们提出了 TaxoAdapt，一个能够动态地将 LLM 生成的分类法适应到给定语料库的多维度的框架。TaxoAdapt 执行迭代分层分类，根据语料库的主题分布扩展分类法的宽度和深度。我们通过在多年来各种计算机科学会议数据集上的最先进性能来展示其能力，以展示其构建和捕捉科学领域演变的能力。作为一种多维方法，TaxoAdapt 生成的分类法在粒度保留方面比最具竞争力的基线高 26.51%，在连贯性方面高 50.41%（由 LLM 判断）。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [292] [Do Language Models Have Bayesian Brains? Distinguishing Stochastic and Deterministic Decision Patterns within Large Language Models](https://arxiv.org/abs/2506.10268)
> *语言模型拥有贝叶斯大脑吗？区分大型语言模型中的随机性和确定性决策模式*

*Andrea Yaoyun Cui, Pengfei Yu* | **Main category: cs.CL**

**Keywords:** 语言模型, 贝叶斯大脑, 随机性, 确定性, 吉布斯采样, 先验

**Comment:** 

> **TL;DR:** 本文挑战了语言模型总是进行概率性决策的假设，发现它们在特定条件下可以表现出接近确定性的行为，并提出了区分随机性和确定性决策模式的方法，以避免推断出错误的先验。

**AI_Comments:** 本文创新性地挑战了语言模型决策行为的传统观点，即它们总是进行概率性采样。通过揭示语言模型在特定条件下可能表现出确定性行为，该研究对当前推断语言模型先验的方法提出了重要质疑。提出的区分随机性和确定性决策模式的方法对于避免误导性结论具有实际意义，对深入理解大型语言模型的内部运作机制及其认知特性具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究假设语言模型通过迭代采样进行概率性决策，并使用模拟吉布斯采样来推断其先验。本文旨在重新审视一个关键问题：语言模型是否拥有贝叶斯大脑？特别是，它挑战了语言模型总是进行概率性决策的假设，并指出现有方法可能推断出错误的先验。

**Method:** 作者重新审视了语言模型决策模式的问题。他们通过实验证明，在特定条件下，即使采样温度非零，语言模型也能表现出接近确定性的决策行为（如最大似然估计）。他们进一步展示了确定性系统在模拟吉布斯采样下可能收敛到“错误先验”。为解决此问题，他们提出了一种直接的方法来区分吉布斯采样中的随机性和确定性决策模式。他们还在多种大型语言模型上进行了实验，以识别它们在各种情况下的决策模式。

**Result:** 研究发现，在特定条件下，语言模型可以表现出接近确定性的决策行为，例如产生最大似然估计，即使采样温度非零。这挑战了采样假设，并削弱了先前用于推断类似人类先验的方法。此外，研究表明，在缺乏适当审查的情况下，具有确定性行为的系统在模拟吉布斯采样下会收敛到“错误先验”。

**Conclusion:** 语言模型并非总是进行概率性决策，在特定条件下它们可以表现出接近确定性的行为。这挑战了现有关于语言模型决策的假设和用于推断其先验的方法。区分随机性和确定性决策模式对于准确理解大型语言模型的决策过程至关重要。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）的决策模式，质疑了它们总是进行概率性采样的普遍假设。研究发现，在特定条件下，LLMs即使在非零采样温度下也能表现出接近确定性的决策行为，例如最大似然估计。这挑战了先前基于采样假设推断LLM先验的方法，并指出确定性行为可能导致“错误先验”的推断。为解决此问题，作者提出了一种区分吉布斯采样中随机性和确定性决策模式的简单方法，并对多种LLMs进行了实验，以提供关于其决策过程的关键见解。

> **摘要翻译:** 语言模型本质上是令牌序列上的概率分布。自回归模型通过迭代计算并从下一个令牌的分布中采样来生成句子。这种迭代采样引入了随机性，导致人们假设语言模型做出概率性决策，类似于从未知分布中采样。基于这一假设，先前的研究利用模拟吉布斯采样（受旨在引发人类先验的实验启发）来推断语言模型的先验。在本文中，我们重新审视了一个关键问题：语言模型是否拥有贝叶斯大脑？我们的研究结果表明，在某些条件下，即使采样温度非零，语言模型也能表现出接近确定性的决策行为，例如产生最大似然估计。这挑战了采样假设，并削弱了先前用于推断类似人类先验的方法。此外，我们证明，在缺乏适当审查的情况下，具有确定性行为的系统在模拟吉布斯采样下会收敛到“错误先验”。为了解决这个问题，我们提出了一种直接的方法来区分吉布斯采样中的随机性和确定性决策模式，有助于防止推断出误导性的语言模型先验。我们对各种大型语言模型进行了实验，以识别它们在各种情况下的决策模式。我们的结果为理解大型语言模型的决策提供了关键见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [302] [CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training](https://arxiv.org/abs/2506.10844)
> *CIIR@LiveRAG 2025: 通过自训练优化多智能体检索增强生成*

*Alireza Salemi, Mukta Maddipatla, Hamed Zamani* | **Main category: cs.CL**

**Keywords:** 多智能体系统, 检索增强生成, 自训练, 奖励引导, LiveRAG

**Comment:** 

> **TL;DR:** 论文提出了mRAG，一个多智能体RAG框架，通过自训练和奖励引导优化代理协作，在LiveRAG竞赛中表现优于传统RAG基线。

**AI_Comments:** 这篇论文的创新点在于提出了一个多智能体RAG框架，并通过自训练和奖励引导的轨迹采样来优化智能体间的协作，这为提升RAG系统在复杂任务中的表现提供了一个有前景的方向。其在LiveRAG竞赛中的优异表现也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过优化多智能体协作来增强响应生成，并有效处理复杂的真实世界RAG任务。

**Method:** 本文提出了mRAG，一个多智能体检索增强生成（RAG）框架，由专门负责规划、搜索、推理和协调等子任务的智能体组成。该系统采用自训练范式，通过奖励引导的轨迹采样来优化智能体间的协作。

**Result:** 在SIGIR 2025 LiveRAG竞赛期间，mRAG在DataMorgana衍生数据集上进行了评估，其性能优于传统的RAG基线。竞赛结果分析和案例研究进一步展示了该框架的优势。

**Conclusion:** mRAG框架通过自训练和优化多智能体协作，有效解决了复杂的真实世界检索增强生成（RAG）任务。

> **ai_Abstract:** 本文介绍了mRAG，一个创新的多智能体检索增强生成（RAG）框架。该框架包含多个专业代理，负责规划、搜索、推理和协调等任务。mRAG利用自训练范式和奖励引导的轨迹采样来优化代理间的协作，从而提升生成响应的质量。在SIGIR 2025 LiveRAG竞赛的DataMorgana数据集上，mRAG的性能超越了传统的RAG基线，并通过案例研究证明了其在处理复杂真实世界RAG任务方面的有效性。

> **摘要翻译:** 本文提出了mRAG，一个由规划、搜索、推理和协调等子任务的专业智能体组成的多智能体检索增强生成（RAG）框架。我们的系统采用自训练范式，通过奖励引导的轨迹采样来优化智能体间的协作并增强响应生成。在SIGIR 2025 LiveRAG竞赛期间，mRAG在DataMorgana衍生数据集上进行了评估，其性能优于传统的RAG基线。我们进一步分析了竞赛结果，并通过案例研究展示了该框架的优势，证明了其在复杂、真实世界RAG任务中的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [303] [ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs](https://arxiv.org/abs/2506.10288)
> *ClusterUCB：面向LLM定向微调的高效基于梯度的数据选择方法*

*Zige Wang, Qi Zhu, Fei Mi, Minghui Xu, Ruochun Jin, Wenjing Yang* | **Main category: cs.CL**

**Keywords:** LLMs, 数据选择, 梯度, 微调, ClusterUCB

**Comment:** 

> **TL;DR:** ClusterUCB提出了一种高效的基于梯度的LLM数据选择框架，通过聚类和改进的UCB算法，在大幅减少计算开销的同时，实现了与原始方法相当的性能。

**AI_Comments:** 该论文的创新点在于将聚类思想与多臂老虎机（UCB）算法相结合，以优化基于梯度的LLM数据选择过程。这种方法有效地解决了梯度计算成本高昂的实际问题，使得基于影响力的数据选择在LLM微调中更加实用。其贡献在于提供了一种高效且性能相当的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于梯度的LLM数据选择方法计算资源消耗过大，难以在实际中应用。

**Method:** 本文提出了ClusterUCB框架。首先，基于梯度特征相似的数据样本影响相似的直觉，对训练数据池进行聚类。然后，将簇间数据选择视为受限计算预算分配问题，并将其建模为多臂老虎机问题，通过改进的UCB算法解决。该算法记录历史数据影响信息以估计每个簇的分布，并采用冷启动平衡探索与利用。

**Result:** 实验结果表明，ClusterUCB框架在各种基准测试上取得了与原始基于梯度的LLM数据选择方法相当的结果，同时显著降低了计算消耗。

**Conclusion:** ClusterUCB通过创新的聚类和UCB算法有效解决了基于梯度的数据选择在LLM微调中计算成本过高的问题，使其在实际应用中更具可行性。

> **ai_Abstract:** ClusterUCB是一种高效的LLM微调数据选择框架，旨在解决传统基于梯度方法计算成本高昂的问题。它通过对训练数据进行聚类，并将簇间选择建模为多臂老虎机问题，利用改进的UCB算法进行优化。该方法在保证性能的同时，显著降低了计算资源消耗，使其在实际应用中更具可行性。

> **摘要翻译:** 基于梯度的数据影响力近似已被用于在大语言模型的监督微调中选择有用数据样本。然而，在整个微调过程中计算梯度需要过多的资源，在实践中不可行。在本文中，我们提出了一种高效的基于梯度的、结合聚类和改进的Upper Confidence Bound（UCB）算法的数据选择框架。基于梯度特征相似的数据样本将具有相似影响的直觉，我们首先对训练数据池执行聚类。然后，我们将簇间数据选择构建为一个受限计算预算分配问题，并将其视为一个多臂老虎机问题。利用改进的UCB算法来解决这个问题。具体来说，在迭代采样过程中，记录历史数据影响信息以直接估计每个簇的分布，并采用冷启动来平衡探索和利用。在各种基准测试上的实验结果表明，我们提出的框架ClusterUCB可以实现与原始基于梯度的LLM数据选择方法相当的结果，同时大大减少了计算消耗。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [313] [ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark](https://arxiv.org/abs/2506.10960)
> *中文有害内容检测基准：ChineseHarm-Bench*

*Kangwei Liu, Siyuan Cheng, Bozhong Tian, Xiaozhuan Liang, Yuyang Yin, Meng Han, Ningyu Zhang, Bryan Hooi, Xi Chen, Shumin Deng* | **Main category: cs.CL**

**Keywords:** 中文有害内容检测, 基准数据集, 知识规则库, 大型语言模型, 知识增强

**Comment:** Work in progress

> **TL;DR:** 提出了一个名为ChineseHarm-Bench的中文有害内容检测基准，包含专业标注数据和知识规则库，并引入知识增强基线使小模型也能达到SOTA LLM性能。

**AI_Comments:** 这篇论文通过构建一个高质量的中文有害内容检测基准和知识规则库，有效填补了中文领域资源的空白。其创新之处在于提出了知识增强基线，使得小型模型也能达到与大型模型相当的性能，这对于资源受限的场景具有重要意义，降低了部署高性能有害内容检测系统的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 现有有害内容检测资源主要集中在英文，中文数据集稀缺且范围有限，而大型语言模型在有害内容检测中的应用日益增加，因此需要一个全面的中文有害内容检测基准。

**Method:** 1. 构建了一个全面的、专业标注的中文有害内容检测基准，涵盖六个代表性类别，并完全基于真实世界数据。2. 通过标注过程，得到了一个知识规则库，提供明确的专家知识以辅助LLM进行中文有害内容检测。3. 提出了一个知识增强基线，该基线整合了人工标注的知识规则和来自大型语言模型的隐式知识。

**Result:** 提出的知识增强基线能够使较小的模型达到与最先进的大型语言模型相当的性能。

**Conclusion:** ChineseHarm-Bench及其伴随的知识规则库和知识增强基线显著提升了中文有害内容检测的能力，特别是使得较小模型也能达到高性能，弥补了中文资源稀缺的空白。

> **ai_Abstract:** 本文推出了ChineseHarm-Bench，一个专门用于中文有害内容检测的综合基准数据集。该基准包含六个类别的真实世界数据，并伴随一个由专业标注产生的知识规则库。研究者还提出了一种知识增强基线方法，该方法结合了人工规则和LLM的隐式知识，使得较小模型也能实现与顶尖LLM相媲美的有害内容检测性能，有效弥补了中文有害内容检测资源的不足。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地应用于自动化有害内容检测任务，协助审核员识别政策违规并提高内容审查的整体效率和准确性。然而，现有有害内容检测资源主要集中在英文，中文数据集仍然稀缺且范围有限。我们提出了一个全面的、专业标注的中文内容危害检测基准，该基准涵盖了六个代表性类别，并且完全由真实世界数据构建。我们的标注过程进一步产生了一个知识规则库，该规则库提供了明确的专家知识，以协助LLMs进行中文有害内容检测。此外，我们提出了一个知识增强基线，该基线整合了人工标注的知识规则和来自大型语言模型的隐式知识，使较小的模型能够达到与最先进的大型语言模型相当的性能。代码和数据可在https://github.com/zjunlp/ChineseHarm-bench获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [314] [Flick: Few Labels Text Classification using K-Aware Intermediate Learning in Multi-Task Low-Resource Languages](https://arxiv.org/abs/2506.10292)
> *Flick：在多任务低资源语言中使用 K 感知中间学习的少量标签文本分类*

*Ali Almutairi, Abdullah Alsuhaibani, Shoaib Jameel, Usman Naseem, Gelareh Mohammadi, Imran Razzak* | **Main category: cs.CL**

**Keywords:** 少量标签文本分类, 低资源语言, 伪标签提炼, K 感知学习, 半监督学习

**Comment:** 

> **TL;DR:** Flick 提出了一种新的伪标签提炼方法，用于解决低资源语言中少量标签文本分类的挑战，通过识别和利用表现最佳的伪标签簇来提高伪标签质量。

**AI_Comments:** 该论文的创新点在于其针对低资源语言的伪标签提炼方法，通过 K 感知中间学习和识别高置信度伪标签簇，有效解决了现有方法在嘈杂伪标签和过拟合方面的局限性，对低资源自然语言处理领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在低资源语言的少量标签文本分类中表现不佳，原因在于易受嘈杂伪标签的错误影响、主要为资源丰富的语言设计或涉及易过拟合的复杂级联模型。

**Method:** Flick 提出了一种新颖的伪标签提炼组件，通过关注单簇凝聚力和利用自适应的 top-k 选择机制，从初始广泛的簇中提炼出高置信度的伪标签。这种有针对性的提炼过程有助于减轻低资源数据中固有的错误传播，从而能够使用少量真实标签对预训练语言模型进行鲁棒的微调。

**Result:** Flick 在包括阿拉伯语、乌尔都语和茨瓦纳语等具有挑战性的低资源语言以及英语在内的 14 个不同数据集上展示了其有效性，证明了其卓越的性能和适应性。

**Conclusion:** Flick 通过改进伪标签质量的新型提炼过程，有效解决了低资源语言中少量标签文本分类的挑战，从而实现了鲁棒的性能。

> **ai_Abstract:** Flick 提出了一种新颖的伪标签提炼组件，旨在解决低资源语言中少量标签文本分类的挑战。该方法通过关注单簇凝聚力和自适应的 top-k 选择机制，从初始广泛的簇中提炼出高置信度的伪标签，从而显著提高伪标签质量并减轻错误传播。这使得能够使用少量真实标签对预训练语言模型进行鲁棒的微调。Flick 在包括阿拉伯语、乌尔都语和茨瓦纳语在内的 14 个多样化数据集上表现出卓越的性能和适应性。

> **摘要翻译:** 训练深度学习网络以最少的监督获得了显著的研究关注，因为它有可能减少对大量标记数据的依赖。虽然自训练方法在半监督学习中被证明是有效的，但它们仍然容易受到嘈杂伪标签的错误影响。此外，大多数最近解决少量标签分类问题的方法要么是为英语等资源丰富的语言设计的，要么涉及容易过拟合的复杂级联模型。为了解决在真正的低资源语言环境中少量标签文本分类的持续挑战，现有方法在嘈杂伪标签和领域适应方面常常面临困难，我们提出了 Flick。与依赖通用多簇伪标签或复杂级联架构的现有方法不同，Flick 利用了基本见解：从更广泛的初始簇中提炼高置信度伪标签可以显著提高伪标签质量，特别是在语言多样性、低资源的设置中。Flick 引入了一个新颖的伪标签提炼组件，通过识别和利用表现最佳的伪标签簇，这与传统的伪标签策略不同。该组件专门学习通过关注单簇凝聚力和利用自适应的 top-k 选择机制，从最初的广泛集合中提炼出高度可靠的伪标签。这种有针对性的提炼过程对于减轻低资源数据中固有的错误传播至关重要，从而能够使用少量真实标签对预训练语言模型进行鲁棒的微调。我们在 14 个不同数据集上展示了 Flick 的功效，这些数据集涵盖了挑战性的低资源语言，如阿拉伯语、乌尔都语和茨瓦纳语，以及英语，展示了其卓越的性能和适应性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [327] [Analyzing the relationships between pretraining language, phonetic, tonal, and speaker information in self-supervised speech models](https://arxiv.org/abs/2506.10855)
> *分析自监督语音模型中预训练语言、语音、音调和说话人信息之间的关系*

*Michele Gubian, Ioana Krehan, Oli Liu, James Kirby, Sharon Goldwater* | **Main category: cs.CL**

**Keywords:** 自监督语音模型, wav2vec2, 语言表示, 语音信息, 音调信息, 说话人信息

**Comment:** 

> **TL;DR:** 本文分析了wav2vec2模型如何在不同的预训练语言中编码语音、音调和说话人信息，发现这些表示在很大程度上是正交的，并且独立于预训练语音材料。

**AI_Comments:** 这篇论文为wav2vec2等自监督语音模型的跨语言泛化能力提供了宝贵的见解。不同类型的语音信息（语音、音调、说话人）在很大程度上独立于预训练语言，以正交子空间的形式表示，这一发现意义重大。它表明这些模型中存在一个鲁棒且可能是通用的底层结构，这可以简化多语言语音处理并减少对特定语言预训练数据的需求。

<details>
  <summary>Details</summary>

**Motivation:** 此前对自监督语音模型的分析几乎都集中在英语上。本文旨在探究在不同语言上训练的wav2vec2模型如何编码与语言匹配和不匹配的语音。

**Method:** 作者使用了在四种不同语言上训练的wav2vec2模型。他们采用探针分类器和几何分析来检查语音、词汇音调和说话人信息的表示。

**Result:** 研究发现，对于所有预训练和测试语言，编码语音、音调和说话人的子空间大体上是正交的。探针准确率的层级模式相似，在后期层中，匹配语言的语音和音调（但不是说话人）探针具有相对较小的优势。

**Conclusion:** 研究结果表明，wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。

> **ai_Abstract:** 本文研究了wav2vec2自监督语音模型在多种预训练语言中对语音、音调和说话人信息的表示。通过探针分类器和几何分析，研究揭示了这些不同类型的信息被编码在很大程度上正交的子空间中，与预训练语言无关。探针准确率的层级模式一致，仅在后期层中，匹配语言的语音和音调探针具有微小优势，这表明所学习的表示结构在很大程度上独立于特定的预训练语音材料。

> **摘要翻译:** 对自监督语音模型的分析已经开始揭示它们在哪里以及如何表示不同类型的信息。然而，几乎所有分析都集中在英语上。在此，我们研究了在四种不同语言上训练的wav2vec2模型如何编码与语言匹配和不匹配的语音。我们使用探针分类器和几何分析来检查语音、词汇音调和说话人信息是如何表示的。我们表明，对于所有预训练和测试语言，编码语音、音调和说话人的子空间大体上是正交的，并且探针准确率的层级模式相似，在后期层中，匹配语言的语音和音调（但不是说话人）探针具有相对较小的优势。我们的研究结果表明，wav2vec2学习到的表示结构在很大程度上独立于预训练期间使用的语音材料。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [334] [Code Execution as Grounded Supervision for LLM Reasoning](https://arxiv.org/abs/2506.10343)
> *代码执行作为LLM推理的基础监督*

*Dongwon Jung, Wenxuan Zhou, Muhao Chen* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 思维链, 代码执行, 推理监督, 程序执行

**Comment:** 

> **TL;DR:** 该论文提出了一种利用代码执行生成高质量、可验证的思维链（CoT）监督数据的方法，以提高大型语言模型（LLM）的推理能力，并减少推理时的token长度。

**AI_Comments:** 该论文提出了一种创新的方法，利用代码执行来生成高质量的思维链（CoT）监督数据，为传统方法提供了一种可扩展且可验证的替代方案。其关注确定性以及通过更准确的推理来减少推理token长度，对提高LLM的效率和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前，为大型语言模型（LLM）获取可靠准确的思维链（CoT）推理监督存在挑战，现有方法要么成本高昂（人工标注），要么容易出错（LLM生成CoT）。

**Method:** 该方法通过利用程序执行的确定性来生成高质量的CoT监督数据集。它从代码执行中提取可验证的、分步的推理轨迹，并将其转换为自然语言的CoT推理。

**Result:** 实验表明，该方法能有效赋予LLM跨不同任务的可迁移推理能力。消融研究验证了该方法能产生高度准确的推理数据，并通过减少无意义的重复和过度思考，缩短了推理过程中的总token长度。

**Conclusion:** 该论文提出了一种利用代码执行生成高质量思维链（CoT）监督的可扩展且有效的方法，从而提升了大型语言模型（LLM）的推理能力并提高了推理效率。

> **ai_Abstract:** 该论文提出了一种可扩展的方法，通过利用程序执行的确定性来为大型语言模型（LLM）生成高质量的思维链（CoT）监督。与依赖人工标注或易出错的LLM生成CoT的方法不同，该方法从代码执行中提取可验证的、分步的推理轨迹，并将其转化为自然语言CoT。实验证明，该方法能有效提升LLM在各种任务中的可迁移推理能力，并通过减少冗余推理来缩短推理时的token长度。

> **摘要翻译:** 训练大型语言模型（LLM）与思维链（CoT）监督已被证明能有效增强其推理能力。然而，获取可靠准确的推理监督仍然是一个重大挑战。我们提出了一种可扩展的方法，通过利用程序执行的确定性来生成高质量的CoT监督数据集。与现有依赖昂贵的人工标注或易出错的LLM生成CoT的推理数据集生成方法不同，我们的方法从代码执行中提取可验证的、逐步的推理轨迹，并将其转化为自然语言CoT推理。在各种领域的推理基准测试中进行的实验表明，我们的方法有效地使LLM具备了跨不同任务的可迁移推理能力。此外，消融研究验证了我们的方法能产生高度准确的推理数据，并通过减少无意义的重复和过度思考，减少了推理过程中的总token长度。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [348] [PAG: Multi-Turn Reinforced LLM Self-Correction with Policy as Generative Verifier](https://arxiv.org/abs/2506.10406)
> *PAG：基于生成式验证器的多轮强化LLM自我纠正*

*Yuhua Jiang, Yuwen Xiong, Yufeng Yuan, Chao Xin, Wenyuan Xu, Yu Yue, Qianchuan Zhao, Lin Yan* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 自我纠正, 强化学习, 生成式验证, 选择性修正

**Comment:** 

> **TL;DR:** PAG是一个通过多轮强化学习实现LLM自我纠正的框架，它让LLM在策略和验证器角色间切换，并在检测到错误时选择性地进行修正，从而提高推理和验证能力。

**AI_Comments:** PAG的创新之处在于其将策略和生成式验证器角色统一到多轮强化学习框架中，并引入了选择性修正机制。这种“验证-然后-修正”的流程不仅提高了效率，避免了不必要的重复生成，还解决了模型崩溃的问题，并同时提升了推理和验证能力，具有重要的实践意义和理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在复杂推理任务中表现出色，但难以可靠地验证自身输出的正确性。当前解决方案依赖独立的验证器或多阶段训练，限制了可扩展性。

**Method:** 论文提出了PAG（Policy as Generative Verifier）框架，通过在统一的多轮强化学习范式中，让LLM在策略和验证器角色之间交替进行自我纠正。PAG引入了选择性修正机制，即模型仅在其生成式验证步骤检测到错误时才修正答案，与以往总是生成第二次尝试的方法不同。

**Result:** 广泛的实验表明，PAG在两个方面都有所改进：作为策略，它提高了直接生成和自我纠正的准确性；作为验证器，其自我验证能力优于自我一致性。

**Conclusion:** PAG框架通过其独特的生成式验证和选择性修正机制，有效提升了LLM的推理和验证能力，解决了现有自验证方案的局限性。

> **ai_Abstract:** 本文提出了PAG（Policy as Generative Verifier）框架，旨在解决大型语言模型（LLMs）在自我验证输出方面的挑战。PAG通过在多轮强化学习中让LLM扮演策略和生成式验证器两种角色，实现自我纠正。其核心创新在于引入了选择性修正机制，即仅在LLM自身检测到错误时才进行修正，这不同于以往的无条件修正方法。实验证明，PAG不仅提升了LLM的推理和自我纠正准确性，其自我验证能力也优于传统的自我一致性方法，有效缓解了模型崩溃问题。

> **摘要翻译:** 大型语言模型（LLMs）在复杂推理任务中展现出令人印象深刻的能力，但它们仍然难以可靠地验证自身输出的正确性。现有解决这一验证挑战的方案通常依赖独立的验证器模型或需要多阶段的自我纠正训练流程，这限制了可扩展性。在本文中，我们提出了策略即生成式验证器（PAG），这是一个简单而有效的框架，它通过在统一的多轮强化学习（RL）范式中，让LLMs在策略和验证器角色之间交替，从而赋能LLMs进行自我纠正。与以往无论模型置信度如何总是生成第二次尝试的方法不同，PAG引入了一种选择性修正机制：模型仅在其自身的生成式验证步骤检测到错误时才修正其答案。这种“验证-然后-修正”的工作流程不仅缓解了模型崩溃，而且共同增强了推理和验证能力。在各种推理基准上的广泛实验突出了PAG的双重进步：作为策略，它提高了直接生成和自我纠正的准确性；作为验证器，其自我验证能力优于自我一致性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [355] [Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?](https://arxiv.org/abs/2506.10415)
> *阅后即焚：多模态大型语言模型真的能捕捉图像序列中的事件顺序吗？*

*Yingjin Song, Yupei Du, Denis Paperno, Albert Gatt* | **Main category: cs.CL**

**Keywords:** 多模态大型语言模型, 时间推理, 图像序列, 基准测试, TempVS

**Comment:** 27 pages, 14 figures. Accepted to ACL 2025

> **TL;DR:** 新基准TempVS发现，多模态大型语言模型在理解图像序列中的事件时间顺序方面表现不佳，与人类能力存在显著差距。

**AI_Comments:** 这篇论文通过引入专门的TempVS基准，系统性地揭示了当前多模态大型语言模型在处理图像序列时间顺序方面的局限性。其创新之处在于设计了多维度的时间推理任务，并量化了模型与人类表现的差距，为未来多模态AI研究指明了关键的改进方向，具有重要的诊断和指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索并评估多模态大型语言模型（MLLMs）在图像序列中时间定位和推理能力方面的不足。

**Method:** 本文引入了TempVS基准，该基准包含事件关系推理、句子排序和图像排序三项主要测试，并评估了38个最先进的多模态大型语言模型在这些任务上的表现。

**Result:** 评估结果显示，多模态大型语言模型在解决TempVS基准任务时表现不佳，与人类能力相比存在显著的性能差距。

**Conclusion:** 多模态大型语言模型在理解图像序列中的事件时间顺序和进行时间推理方面存在明显不足，需要未来的研究来改进。

> **ai_Abstract:** 本文提出了TempVS基准，旨在评估多模态大型语言模型（MLLMs）在图像序列中理解事件时间顺序的能力。该基准包含事件关系推理、句子排序和图像排序等任务，要求MLLMs结合视觉和语言信息进行推理。对38个主流MLLMs的评估发现，它们在这些任务上表现远低于人类水平，揭示了当前MLLMs在时间顺序理解方面存在的显著不足，并为未来研究提供了方向。

> **摘要翻译:** 本文介绍了TempVS基准，该基准专注于评估多模态大型语言模型（MLLMs）在图像序列中的时间定位和推理能力。TempVS包含三个主要测试（即事件关系推理、句子排序和图像排序），每个测试都伴随着一个基本的定位测试。TempVS要求MLLMs依靠视觉和语言两种模态来理解事件的时间顺序。我们评估了38个最先进的MLLMs，结果表明模型在解决TempVS时表现不佳，与人类能力相比存在显著的性能差距。我们还提供了细致的见解，为未来的研究指明了有希望的方向。我们的TempVS基准数据和代码可在https://github.com/yjsong22/TempVS获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [361] [Beyond the Battlefield: Framing Analysis of Media Coverage in Conflict Reporting](https://arxiv.org/abs/2506.10421)
> *超越战场：冲突报道中媒体报道的框架分析*

*Avneet Kaur, Arnav Arora* | **Main category: cs.CL**

**Keywords:** 冲突报道, 媒体框架, 战争与和平新闻, 计算方法, 偏见

**Comment:** 

> **TL;DR:** 本研究利用计算方法分析了以色列-巴勒斯坦战争新闻报道中的战争与和平新闻框架，发现媒体更侧重战争报道，且不同地区媒体在受害者和袭击者框架上存在显著偏差。

**AI_Comments:** 该研究的创新之处在于结合了计算方法、框架语义学和大型语言模型来深入分析冲突报道中的媒体框架，超越了以往定性或表面化的研究。其重要性在于揭示了新闻媒体在冲突报道中的潜在偏见和其对公众认知的影响，尤其是在敏感的以色列-巴勒斯坦冲突背景下。研究结果对理解媒体在塑造冲突叙事中的作用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 新闻媒体在冲突报道中使用的框架对读者观点影响巨大，可能加剧冲突。现有冲突框架研究因定性性质或仅停留在表面通用框架而缺乏深入见解，因此本研究旨在弥补这一不足。

**Method:** 本研究在一个关于以色列-巴勒斯坦战争的新闻文章语料库中，识别了战争与和平新闻的指标。分析方法采用计算方法，结合框架语义学和大型语言模型，以识别交际框架及其与语言框架的联系。

**Result:** 分析显示，新闻报道更侧重于基于战争的报道而非基于和平的报道。研究还表明，美国、英国和中东新闻媒体在冲突中的袭击者和受害者框架上存在显著差异，揭示了媒体内部的偏见。

**Conclusion:** 媒体在冲突报道中存在明显的战争导向偏见，且不同地区媒体在塑造冲突叙事方面存在显著差异，这可能影响公众对冲突的认知并加剧冲突。

> **ai_Abstract:** 本研究旨在克服现有冲突框架研究的局限性，通过计算方法分析以色列-巴勒斯坦战争新闻报道中的媒体框架。研究利用框架语义学和大型语言模型，在一个新闻文章语料库中识别战争与和平新闻指标，并探讨交际框架与语言框架的联系。结果表明，媒体更侧重于战争报道，而非和平报道，并且美国、英国和中东新闻媒体在冲突中袭击者和受害者的框架上存在显著差异，揭示了媒体偏见。

> **摘要翻译:** 新闻媒体使用的框架，尤其是在冲突时期，可能对读者的观点产生重大影响，并可能加剧冲突本身。当前关于冲突框架主题的研究由于其定性性质或仅关注表面通用框架而缺乏深入见解。在这项工作中，我们在一个报道以色列-巴勒斯坦战争的新闻文章语料库中，识别了冲突研究中先前工作概述的战争与和平新闻指标。在我们的分析中，我们使用计算方法，结合框架语义学和大型语言模型来识别交际框架及其与语言框架的联系。我们的分析揭示了对基于战争的报道的更高关注，而不是基于和平的报道。我们还表明，美国、英国和中东新闻媒体在构建冲突中的袭击者和受害者方面存在实质性差异，揭示了媒体内部的偏见。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [367] [Fast on the Easy, Deep on the Hard: Efficient Reasoning via Powered Length Penalty](https://arxiv.org/abs/2506.10446)
> *易题快解，难题深思：通过强化长度惩罚实现高效推理*

*Zehui Ling, Deshu Chen, Hongwei Zhang, Yifeng Jiao, Xin Guo, Yuan Cheng* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 推理效率, 长度惩罚, 奖励函数, 自适应推理

**Comment:** 

> **TL;DR:** 本研究提出一种新的奖励函数和输出长度惩罚机制，以提高大型语言模型在不同难度问题上的推理效率和准确性。

**AI_Comments:** 这项研究的创新之处在于其提出的自适应长度惩罚机制，它突破了现有方法统一惩罚的局限性，能够根据问题复杂度智能地调整LLM的推理过程。这种“易题快解，难题深思”的策略对于提升LLM在实际应用中的效率和性能具有重要意义，尤其是在需要快速响应或资源受限的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在推理方面取得了显著进展，但目前的推理技术（如思维链）常导致输出过长，增加计算延迟。现有的缩短推理方法通常采用统一惩罚，未考虑问题复杂性，导致次优结果。

**Method:** 本研究通过划分奖励函数并引入一种新颖的输出长度惩罚来管理模型的推理效率。该方法旨在针对简单问题促进简洁性，同时为复杂问题保留足够的推理以确保准确性。

**Result:** 在GSM8K和MATH500等相对简单的基准数据集上，该方法有效缩短了输出长度，同时保持或提高了准确性。在更具挑战性的AIME2024数据集上，该方法提高了准确性。

**Conclusion:** 通过引入分段奖励函数和新颖的输出长度惩罚，本研究提出的方法能够根据问题复杂度自适应地调整大型语言模型的推理过程，从而在保持或提高准确性的同时显著提高推理效率。

> **ai_Abstract:** 本研究旨在解决大型语言模型推理效率低下的问题，尤其是在生成过长输出时增加计算延迟。作者提出了一种新颖的方法，通过划分奖励函数并引入自适应的输出长度惩罚，使模型能够根据问题难度调整推理长度：对简单问题追求简洁，对复杂问题保持深度。该方法在GSM8K、MATH500和AIME2024等数据集上进行了评估，结果表明其在简单数据集上能有效缩短输出长度并保持准确性，在复杂数据集上则能提高准确性。

> **摘要翻译:** 大型语言模型（LLMs）在推理能力方面取得了显著进步，在各种具有挑战性的基准测试中表现出色。诸如思维链提示等技术已被引入以进一步提高推理能力。然而，这些方法经常生成更长的输出，这反过来增加了计算延迟。尽管一些方法使用强化学习来缩短推理，但它们通常施加统一的惩罚，而没有考虑问题的复杂性，导致次优结果。在本研究中，我们旨在通过促进简单问题的简洁性，同时为更复杂的问题保留足够的推理以确保准确性，从而提高LLM推理的效率，进而提高模型的整体性能。具体来说，我们通过划分奖励函数并包含一个新颖的输出长度惩罚来管理模型的推理效率。我们的方法在GSM8K、MATH500和AIME2024三个数据集的基准评估中取得了令人印象深刻的结果。对于相对简单的GSM8K和MATH500数据集，我们的方法有效缩短了输出长度，同时保持或提高了准确性。在要求更高的AIME2024数据集上，我们的方法提高了准确性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [373] [Table-Text Alignment: Explaining Claim Verification Against Tables in Scientific Papers](https://arxiv.org/abs/2506.10486)
> *表格-文本对齐：解释科学论文中针对表格的声明验证*

*Xanh Ho, Sunisth Kumar, Yun-Ang Wu, Florian Boudin, Atsuhiro Takasu, Akiko Aizawa* | **Main category: cs.CL**

**Keywords:** 表格-文本对齐, 声明验证, 可解释性AI, 大型语言模型, 科学论文

**Comment:** 8 pages; code and data are available at
  https://github.com/Alab-NII/SciTabAlign

> **TL;DR:** 本文将表格文本对齐重构为解释任务，以提高科学声明验证的可解释性。通过构建一个新数据集并进行实验，发现表格对齐信息能提高验证性能，但大型语言模型在预测正确标签的同时，未能恢复人类对齐的理由。

**AI_Comments:** 本文的创新之处在于将传统的声明验证任务转化为一个解释性任务，通过要求模型识别关键表格单元格来增强可解释性，这对于理解模型决策过程至关重要。其构建带有单元格级理由的新数据集对后续研究有重要价值。此外，对LLMs在解释性方面不足的发现，揭示了当前LLMs虽然在预测准确率上表现良好，但在推理的忠实性上仍有待提高，为未来的LLM研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的科学声明验证方法（即预测支持或反驳标签）不足以揭示模型推理过程，且可解释性有限。为了解决这一问题，需要一种方法来识别对声明验证至关重要的表格单元格，从而提高模型的可解释性。

**Method:** 将表格-文本对齐重构为一个解释任务，要求模型识别对声明验证至关重要的表格单元格。通过扩展SciTab基准，构建了一个新数据集，其中包含人工标注的单元格级别的理由。标注者验证声明标签并突出显示支持其决策所需的最小单元格集。基于收集到的信息，提出了一种处理模糊情况的分类法。

**Result:** 实验表明：(i) 结合表格对齐信息可以提高声明验证性能；(ii) 大多数大型语言模型（LLMs）虽然经常预测正确的标签，但未能恢复人类对齐的理由，这表明它们的预测并非源于忠实的推理。

**Conclusion:** 将表格-文本对齐视为解释任务，并通过提供单元格级别的理由，可以提高科学声明验证的可解释性和性能。然而，大型语言模型在生成可信赖的解释方面仍有不足，其预测可能并非基于人类认可的推理过程。

> **ai_Abstract:** 本文将科学论文中针对表格的声明验证任务重新定义为表格-文本对齐的解释任务，旨在提高模型的可解释性。通过扩展现有基准数据集SciTab，引入了人工标注的单元格级别理由，以识别支持声明验证的关键表格单元格。研究提出了一种处理模糊情况的分类法。实验结果显示，整合表格对齐信息能提升声明验证性能，但大型语言模型在预测准确标签的同时，未能有效捕捉人类认定的解释依据，表明其推理过程可能缺乏忠实性。

> **摘要翻译:** 科学声明针对表格的验证通常需要预测声明是否被表格支持或反驳。然而，我们认为仅仅预测最终标签是不够的：它几乎没有揭示模型的推理过程，并且提供了有限的可解释性。为了解决这个问题，我们将表格-文本对齐重构为一个解释任务，要求模型识别对声明验证至关重要的表格单元格。我们通过扩展SciTab基准，构建了一个新数据集，其中包含人工标注的单元格级别理由。标注者验证声明标签并突出显示支持其决策所需的最小单元格集。在标注过程之后，我们利用收集到的信息，并提出了一种处理模糊情况的分类法。我们的实验表明：(i) 结合表格对齐信息可以提高声明验证性能；(ii) 大多数大型语言模型（LLMs）虽然经常预测正确的标签，但未能恢复人类对齐的理由，这表明它们的预测并非源于忠实的推理。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [377] [Tina: Tiny Reasoning Models via LoRA](https://arxiv.org/abs/2504.15777)
> *Tina：基于LoRA的微型推理模型*

*Shangshang Wang, Julian Asilis, Ömer Faruk Akgül, Enes Burak Bilgin, Ollie Liu, Willie Neiswanger* | **Main category: cs.CL**

**Keywords:** 微型推理模型, LoRA, 强化学习, 成本效益, 参数高效微调

**Comment:** 

> **TL;DR:** Tina通过在微型基础模型上使用LoRA进行强化学习，以极低的成本实现了强大的推理能力，性能与现有SOTA模型相当甚至超越。

**AI_Comments:** Tina模型在低资源下实现高性能推理是一个重要的创新，特别是在模型部署和可访问性方面。它证明了参数高效微调在强化学习中的潜力，为构建更经济、更环保的AI模型提供了新思路。其主要贡献在于通过LoRA结合RL实现了显著的成本效益和竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决如何在语言模型中以经济高效的方式实现强大的推理能力这一根本问题。

**Method:** 研究提出了Tina，一种通过在已有的1.5B参数微型基础模型上，利用低秩适应（LoRA）在强化学习（RL）过程中进行参数高效更新，从而开发出微型推理模型的方法。

**Result:** Tina模型在极低的计算后训练成本下（例如，最佳模型在AIME24上实现了超过20%的推理性能提升和43.33%的Pass@1准确率，成本仅为9美元，估计成本降低了260倍），实现了与SOTA RL推理模型相当甚至超越的推理性能。研究在多个开源推理数据集和消融设置中验证了其有效性。

**Conclusion:** 研究揭示了通过LoRA进行高效强化学习推理的惊人有效性。这种方法能够使模型快速适应强化学习奖励的推理结构格式，同时很大程度上保留了基础模型的底层知识。

> **ai_Abstract:** 本文介绍了Tina，一个通过在微型语言模型上应用LoRA进行强化学习，以极低成本实现强大推理能力的模型家族。Tina证明了仅需少量资源即可达到与现有SOTA模型相当甚至超越的推理性能，显著降低了计算成本。研究推测其高效性源于LoRA能快速适应推理结构，同时保留基础模型知识。

> **摘要翻译:** 论文标题：Tina：基于LoRA的微型推理模型

论文摘要：在语言模型中，如何以成本效益高的方式实现强大的推理能力？受这一基本问题的驱动，我们提出了Tina，一个以高成本效益实现的微型推理模型家族。值得注意的是，Tina通过在强化学习（RL）过程中，使用低秩适应（LoRA）对一个仅有1.5B参数的微型基础模型进行参数高效更新，证明了仅用最少资源即可开发出显著的推理性能。这种极简主义方法产生的模型，其推理性能与基于相同基础模型构建的SOTA RL推理模型相比具有竞争力，有时甚至超越。关键在于，这是以现有SOTA模型所采用的计算后训练成本的极小一部分实现的。事实上，最佳的Tina模型在AIME24上实现了超过20%的推理性能提升和43.33%的Pass@1准确率，而其后训练和评估成本仅为9美元（即估计成本降低了260倍）。我们的工作揭示了通过LoRA进行高效RL推理的惊人有效性。我们从一组固定的超参数开始，在多个开源推理数据集和各种消融设置中验证了这一点。此外，我们推测这种有效性和效率源于LoRA能够快速使模型适应RL奖励的推理结构格式，同时很大程度上保留了基础模型的底层知识。为了促进可访问性和开放研究，我们完全开源了所有代码、训练日志以及模型权重和检查点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [379] [Surface Fairness, Deep Bias: A Comparative Study of Bias in Language Models](https://arxiv.org/abs/2506.10491)
> *表面公平，深层偏见：语言模型偏见的比较研究*

*Aleksandra Sorokovikova, Pavel Chizhov, Iuliia Eremenko, Ivan P. Yamshchikov* | **Main category: cs.CL**

**Keywords:** 语言模型, 偏见, 公平性, 个性化, MMLU

**Comment:** 

> **TL;DR:** 语言模型在某些基准测试中表现出表面公平性，但在评估用户答案或提供建议时会显示出显著偏见，这在模型个性化趋势下尤为突出。

**AI_Comments:** 这项研究揭示了语言模型偏见的复杂性。其创新之处在于，它不仅关注了表面公平性，还深入探讨了在不同交互场景下（特别是涉及用户评估和建议时）偏见的表现。研究结果强调，随着LLM个性化功能的普及，模型内部的深层偏见将构成更大的挑战，因为模型能够直接获取用户数据，可能在用户无感知的情况下传递偏见。这项工作的局限性可能在于其偏见测量方法的普适性，但它为未来LLM偏见研究和缓解策略提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型在大量数据上训练，这些数据不可避免地包含有争议和带有刻板印象的内容，导致模型表达偏见观点或根据分配的人格或用户的人格产生不同结果。本文旨在调查大型语言模型（LLMs）中偏见的各种代理度量。

**Method:** 本文调查了大型语言模型（LLMs）中偏见的各种代理度量。具体通过以下方式进行：1) 在多学科基准（MMLU）上使用预设人格评估模型。2) 重新设计任务，要求模型对用户答案进行评分。3) 要求模型提供薪资谈判建议。

**Result:** 1) 使用预设人格在MMLU基准上评估模型时，分数差异微不足道且大多随机。2) 当任务重新设计为要求模型评分用户答案时，显示出更显著的偏见迹象。3) 当要求模型提供薪资谈判建议时，答案中表现出明显的偏见。

**Conclusion:** 虽然在某些评估下语言模型可能表现出表面公平，但更深入的互动（如评估用户答案或提供专业建议）会揭示显著的偏见。随着LLM助手记忆和个性化趋势的兴起，这些偏见问题将从新的角度出现，因为模型可能已了解用户的社会人口学信息。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）中存在的偏见问题。研究发现，尽管在一些表面评估（如MMLU基准上的预设人格测试）中，模型表现出微小的偏见差异，但在更深层次的互动中，如评估用户答案或提供薪资谈判建议时，模型会表现出显著的偏见。随着语言模型个性化和记忆功能的普及，这些深层偏见将变得更加突出，因为模型将直接了解用户的社会人口学信息，可能导致更隐蔽的偏见输出。

> **摘要翻译:** 现代语言模型在大量数据上训练。这些数据不可避免地包含有争议和带有刻板印象的内容，其中包含与性别、出身、年龄等相关的各种偏见。因此，模型会表达偏见观点或根据分配的人格或用户的个性产生不同的结果。在本文中，我们调查了大型语言模型（LLMs）中偏见的各种代理度量。我们发现，在多学科基准（MMLU）上使用预设人格评估模型会导致分数差异微不足道且大多随机。然而，如果我们重新设计任务，要求模型对用户的答案进行评分，这会显示出更显著的偏见迹象。最后，如果我们要求模型提供薪资谈判建议，我们会在答案中看到明显的偏见。随着LLM助手记忆和个性化的最新趋势，这些问题从一个不同的角度出现：现代LLM用户不需要预先提示他们的人格描述，因为模型已经了解他们的社会人口学信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [382] [Resa: Transparent Reasoning Models via SAEs](https://arxiv.org/abs/2506.09967)
> *Resa：通过稀疏自编码器实现透明推理模型*

*Shangshang Wang, Julian Asilis, Ömer Faruk Akgül, Enes Burak Bilgin, Ollie Liu, Deqing Fu, Willie Neiswanger* | **Main category: cs.CL**

**Keywords:** Resa, 稀疏自编码器, 推理模型, SAE-Tuning, 语言模型

**Comment:** 

> **TL;DR:** Resa使用一种新颖的SAE-Tuning方法，以极低的成本和时间在语言模型中高效地诱导强大的推理能力，并证明了其通用性和模块性。

**AI_Comments:** 这篇论文通过引入SAE-Tuning，提供了一种成本效益极高且高效的方法来在语言模型中激发推理能力。其创新点在于利用稀疏自编码器来捕获和转移推理能力，显著降低了训练成本和时间。通用性和模块性的发现尤其重要，这表明提取的推理能力可能具有更广泛的应用前景，并为构建可组合的AI系统提供了新的思路。这项工作对资源受限的AI研究和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究如何在语言模型中通过利用其底层表示，以成本效益高的方式激发强大的推理能力。

**Method:** 本文提出了Resa，一个1.5B推理模型家族，采用新颖高效的稀疏自编码器调优（SAE-Tuning）过程。该方法首先训练稀疏自编码器（SAE）从源模型中捕获推理能力，然后利用训练好的SAE指导标准的监督微调过程，在目标模型中激发这些能力，全程仅使用经过验证的问答数据，无需推理痕迹。

**Result:** 在RL后训练之前应用于某些基础模型时，SAE-Tuning保留了其RL训练对应模型超过97%的推理性能，同时将训练成本降低了2000倍以上（约1美元），训练时间缩短了450倍以上（约20分钟）。应用于轻度RL训练模型时，它能以大约1美元的额外成本实现如AIME24上43.33% Pass@1和AMC23上90% Pass@1的推理性能。通过SAE提取的推理能力具有潜在的通用性和模块性，即能从一个数据集泛化到更大的语料库，并可无需重新训练地附加到其他模型上产生可比的增益。

**Conclusion:** 通过SAE-Tuning，可以极大地提高在语言模型中激发推理能力的成本效益，并且这些能力表现出良好的通用性和模块性。

> **ai_Abstract:** 本文介绍了Resa，一个1.5B的推理模型家族，它通过创新的稀疏自编码器调优（SAE-Tuning）方法，以极低的成本和时间高效地在语言模型中诱导强大的推理能力。SAE-Tuning通过训练SAE捕获源模型的推理能力，并将其引导至目标模型。实验证明，该方法能以极小的训练开销（约1美元，20分钟）实现与RL训练模型相当的推理性能，甚至在轻度RL训练模型上取得显著成果。此外，通过SAE提取的推理能力展现出良好的通用性和模块性，即能在不同数据集上泛化并可作为模块附加到其他模型而无需重新训练。所有相关成果均已开源。

> **摘要翻译:** **标题**：Resa：通过稀疏自编码器实现透明推理模型

**摘要**：我们如何才能通过利用语言模型的底层表示，以经济高效的方式在其中激发强大的推理能力？我们用Resa回答了这个问题，Resa是一个1.5B推理模型家族，通过一种新颖高效的稀疏自编码器调优（SAE-Tuning）过程进行训练。该方法首先训练一个SAE从源模型中捕获推理能力，然后利用训练好的SAE指导标准的监督微调过程，在目标模型中激发这些能力，所有这些都使用经过验证的问答数据，而无需任何推理痕迹。值得注意的是，当在进一步RL后训练之前应用于某些基础模型时，SAE-Tuning保留了其RL训练对应模型超过97%的推理性能，同时将训练成本降低了2000倍以上，降至约1美元，训练时间缩短了450倍以上，降至约20分钟。此外，当应用于轻度RL训练的模型（例如，在2个GPU上训练1小时内），它能以大约1美元的额外成本实现如AIME24上43.33% Pass@1和AMC23上90% Pass@1的推理性能。令人惊讶的是，通过SAE提取的推理能力可能既具有通用性又具有模块性。通用性意味着从一个数据集提取的能力仍然能提升在更大、重叠语料库上的性能。模块性意味着从Qwen或Qwen-Math提取的能力可以在测试时无需任何重新训练地附加到R1-Distill模型上，并产生可比的增益。广泛的消融实验验证了这些发现，并且所有工件都已完全开源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [383] [Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2506.10504)
> *超越单用户对话：评估大型语言模型在多用户对话状态跟踪中的能力*

*Sangmin Song, Juhwan Choi, JungMin Yun, YoungBin Kim* | **Main category: cs.CL**

**Keywords:** 多用户对话状态跟踪, 大型语言模型, 对话状态跟踪, 零样本学习, 数据集扩展

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型在多用户对话状态跟踪中的能力，发现与单用户设置相比，性能显著下降，表明当前LLM在多说话人环境下存在局限性。

**AI_Comments:** 本研究的创新之处在于其通过系统性地引入第二用户语句来构建多用户对话数据集的方法，这为评估LLM在复杂交互环境中的能力提供了一个受控且成本效益高的新途径。其重要性在于揭示了当前LLM在多用户DST方面存在的显著性能瓶颈，明确指出了未来研究的方向。论文的局限性在于当前LLM在多说话人对话状态跟踪方面的表现不佳，这需要进一步的算法和模型改进。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在零样本对话状态跟踪（DST）中表现出色，但传统的DST基准测试主要关注结构化的用户-代理对话，未能捕捉真实世界多用户交互的复杂性。因此，本研究旨在评估LLM在多用户DST中的鲁棒性。

**Method:** 研究人员通过基于言语行为理论生成第二个用户的语句，扩展了一个现有的DST数据集。这种方法系统地将第二个用户的语句整合到对话中，从而在多用户设置中实现了对LLM的受控评估。

**Result:** 实验结果显示，与单用户DST相比，性能显著下降。这突出表明了当前大型语言模型在从多个说话人中提取和跟踪对话状态方面的局限性。

**Conclusion:** 研究结果强调，未来的研究需要增强大型语言模型以适应多用户DST场景，从而为更真实、更强大的DST模型铺平道路。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在多用户对话状态跟踪（DST）中的能力。为解决传统DST基准未能捕捉多用户复杂性的问题，研究人员基于言语行为理论，通过生成第二个用户的语句来扩展现有DST数据集，从而在受控环境中评估LLMs。实验结果表明，与单用户DST相比，LLMs在多用户DST中的性能显著下降，揭示了当前LLMs在处理多说话人对话状态跟踪方面的局限性。研究强调未来需加强LLMs以适应多用户DST场景。

> **摘要翻译:** 大型语言模型（LLMs）在零样本对话状态跟踪（DST）中展现出卓越的性能，减少了对特定任务训练的需求。然而，传统的DST基准测试主要关注结构化的用户-代理对话，未能捕捉真实世界多用户交互的复杂性。在本研究中，我们评估了LLMs在多用户DST中的鲁棒性，同时最大限度地降低了数据集构建成本。受LLM驱动的数据标注最新进展的启发，我们通过基于言语行为理论生成第二个用户的语句，扩展了一个现有的DST数据集。我们的方法系统地将第二个用户的语句整合到对话中，从而在多用户设置中实现了对LLMs的受控评估。实验结果显示，与单用户DST相比，性能显著下降，突出表明了当前LLMs在多个说话人之间提取和跟踪对话状态方面的局限性。我们的发现强调，未来的研究需要增强LLMs以适应多用户DST场景，从而为更真实、更强大的DST模型铺平道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [387] [Reliable Reasoning Path: Distilling Effective Guidance for LLM Reasoning with Knowledge Graphs](https://arxiv.org/abs/2506.10508)
> *可靠推理路径：利用知识图谱为大型语言模型推理提炼有效指导*

*Yilin Xiao, Chuang Zhou, Qinggang Zhang, Bo Li, Qing Li, Xiao Huang* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 知识图谱, 推理路径, RRP, 知识蒸馏

**Comment:** 

> **TL;DR:** RRP框架利用知识图谱为大型语言模型提供可靠的推理路径，通过结合语义和结构信息，并引入反思模块，解决了LLM在知识密集型任务中的挑战，实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于将LLM与知识图谱结合的重点从单纯的事实知识补充转向了“推理路径”的提炼和优化。RRP框架通过结合语义和结构信息，并引入独到的“反思模块”来评估和精炼推理路径，有效解决了从复杂知识图谱中提取可靠推理路径的挑战。其“即插即用”的特性也大大增强了其实用性和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在知识密集型任务中常因缺乏背景知识和幻觉问题而表现不佳。现有结合知识图谱（KGs）的LLMs侧重于补充事实知识，但在解决复杂问题时仍有困难。本文认为，提炼事实间的关系并组织成逻辑一致的推理路径与事实知识本身同等重要。从KGs中提取可靠推理路径面临图结构复杂性和多路径选择的挑战。

**Method:** 提出了RRP（Reliable Reasoning Path）框架来挖掘知识图谱，该框架结合了LLM的语义优势以及通过关系嵌入和双向分布学习获得的结构信息。此外，引入了一个反思模块，根据推理路径的重要性对其进行评估和优化。

**Result:** 在两个公共数据集上的实验结果表明，RRP与现有基线方法相比，实现了最先进的性能。此外，RRP可以方便地以即插即用的方式集成到各种LLM中，以增强它们的推理能力。

**Conclusion:** RRP通过生成针对特定问题量身定制的高质量推理路径，为大型语言模型的推理提炼了有效的指导。

> **ai_Abstract:** 本文提出了RRP框架，旨在通过从知识图谱中提取可靠的推理路径来提升大型语言模型（LLMs）在知识密集型任务中的推理能力。针对现有方法仅关注事实知识而忽略推理路径的不足，RRP结合了LLM的语义理解与知识图谱的结构信息（通过关系嵌入和双向分布学习），并引入了一个反思模块来评估和优化路径。实验证明，RRP在公共数据集上达到了最先进的性能，并能以即插即用的方式集成到不同LLM中，有效指导其推理。

> **摘要翻译:** 大型语言模型（LLMs）由于缺乏背景知识和容易产生幻觉，在知识密集型任务中常常表现不佳。为了解决这些限制，将知识图谱（KGs）与LLMs集成已得到深入研究。现有的KG增强型LLMs侧重于补充事实知识，但仍然难以解决复杂问题。我们认为，提炼事实之间的关系并将其组织成逻辑一致的推理路径与事实知识本身同样重要。尽管它们具有潜力，但从KGs中提取可靠的推理路径面临以下挑战：图结构的复杂性以及存在多个生成的路径，这使得区分有用路径和冗余路径变得困难。为了应对这些挑战，我们提出了RRP框架来挖掘知识图谱，该框架结合了LLMs的语义优势和通过关系嵌入和双向分布学习获得的结构信息。此外，我们引入了一个反思模块，根据推理路径的重要性对其进行评估和优化。在两个公共数据集上的实验结果表明，RRP与现有基线方法相比，实现了最先进的性能。此外，RRP可以方便地以即插即用的方式集成到各种LLMs中，以即插即用的方式增强它们的推理能力。通过生成针对特定问题量身定制的高质量推理路径，RRP为LLM推理提炼了有效的指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [392] [Unsupervised Protoform Reconstruction through Parsimonious Rule-guided Heuristics and Evolutionary Search](https://arxiv.org/abs/2506.10614)
> *无监督原始词形重建：基于简约规则引导启发式和演化搜索*

*Promise Dodzi Kpoglu* | **Main category: cs.CL**

**Keywords:** 原始词形重建, 无监督学习, 演化优化, 规则启发式, 计算语言学

**Comment:** 

> **TL;DR:** 本文提出一种无监督方法，结合数据驱动推理和规则启发式，通过演化优化框架重建原始词形，并在拉丁语重建任务上表现出显著提升。

**AI_Comments:** 该论文的创新之处在于其混合方法，结合了数据驱动的统计推断和语言学规则引导的启发式，并通过演化搜索进行优化。这克服了纯数据驱动模型的局限性，为原始词形重建提供了一个更鲁棒和语言学上更合理的框架。其在拉丁语重建上的显著提升证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法主要依赖于语音编辑的概率模型，但其数据驱动性质限制了其应用。因此，需要一种结合数据驱动推理和语言学约束的方法来改进原始词形重建。

**Method:** 该方法是一种无监督的混合方法，它将数据驱动推理与基于规则的启发式方法集成到演化优化框架中。它利用统计模式和语言学约束来指导重建过程。

**Result:** 在重建拉丁语原始词形的任务中，该方法在字符级准确性和语音合理性指标上都显著优于现有基线。

**Conclusion:** 该研究表明，结合数据驱动推理和规则启发式的演化优化框架能够有效且显著地改进原始词形重建的性能。

> **ai_Abstract:** 本文提出了一种创新的无监督原始词形重建方法，该方法通过将数据驱动推理与基于规则的启发式方法融合到演化优化框架中，克服了以往纯数据驱动模型的局限性。通过在拉丁语原始词形重建任务上进行评估，结果显示其在准确性和语音合理性方面均显著优于现有基线。

> **摘要翻译:** 我们提出了一种无监督方法，用于重建原始词形，即现代语言形式所源自的祖先词形。虽然先前的研究主要依赖于语音编辑的概率模型来从同源词集推断原始词形，但这些方法受限于其主要由数据驱动的性质。相比之下，我们的模型将数据驱动推理与基于规则的启发式方法集成到演化优化框架中。这种混合方法利用统计模式和语言学驱动的约束来指导重建过程。我们使用来自五种罗曼语的同源词数据集，在重建拉丁语原始词形的任务上评估了我们的方法。实验结果表明，在字符级准确性和语音合理性指标上，该方法均比现有基线有显著改进。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [396] [SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis](https://arxiv.org/abs/2506.10622)
> *SDialog：一个用于合成对话生成和分析的Python工具包*

*Sergio Burdisso, Esaú Villatoro-Tello, Petr Motlicek* | **Main category: cs.CL**

**Keywords:** 合成对话, Python工具包, 大型语言模型, 会话式AI, 数据生成

**Comment:** https://github.com/idiap/sdialog

> **TL;DR:** SDialog是一个Python工具包，利用指令微调的大型语言模型生成高质量、可控的合成对话，以支持会话式AI系统的训练、评估和基准测试，并促进数据生成的标准化和可复现性。

**AI_Comments:** SDialog通过利用LLMs来生成合成对话，解决了高质量、可复现数据稀缺的问题，这对于会话式AI的发展至关重要。其创新点在于提供角色、编排和场景管理的抽象，使得生成的数据更具真实性和可控性。此外，它对标准化和可复现性的强调，在当前AI研究快速迭代的环境中，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 会话式AI系统的发展依赖于高质量、灵活且可复现的合成对话数据，用于训练、评估和基准测试。然而，合成对话的生成和分析面临挑战。

**Method:** SDialog是一个模块化、可扩展的Python工具包，通过利用指令微调的大型语言模型（LLMs），提供角色（personas）、编排（orchestration）和场景管理（scenario management）的抽象，以生成逼真、多样和可控的对话数据。它支持多智能体模拟和场景驱动生成等工作流程。

**Result:** SDialog能够创建逼真、多样且可控的会话数据，支持多智能体模拟和场景驱动生成等工作流程。它代表了合成数据生成工具和框架标准化的进步。

**Conclusion:** SDialog是合成对话生成和分析领域的重要一步，通过标准化工具和框架，为确保当今快速发展的研究领域中的可复现性做出了关键贡献。

> **ai_Abstract:** SDialog是一个Python工具包，旨在解决合成对话生成和分析的挑战。它利用指令微调的大型语言模型，提供抽象层以管理角色、编排和场景，从而生成逼真、多样且可控的合成对话数据。该工具包支持多智能体模拟和场景驱动生成等工作流程，并有助于推动合成数据生成工具和框架的标准化，对于提高会话式AI研究的可复现性至关重要。

> **摘要翻译:** 会话式AI系统的进步依赖于高质量、灵活且可复现的合成对话，用于训练、评估和基准测试。SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战。通过利用指令微调的大型语言模型（LLMs），SDialog为角色、编排和场景管理提供了抽象，从而能够为研究和开发创建逼真、多样且可控的会话数据。SDialog支持多智能体模拟和场景驱动生成等工作流程，代表了合成数据生成工具和框架标准化方面的进步，这是确保当今快速发展的研究领域中可复现性的关键进展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [399] [NeuralNexus at BEA 2025 Shared Task: Retrieval-Augmented Prompting for Mistake Identification in AI Tutors](https://arxiv.org/abs/2506.10627)
> *NeuralNexus 在 BEA 2025 共享任务中：用于 AI 导师错误识别的检索增强型提示*

*Numaan Naeem, Sarfraz Ahmad, Momina Ahsan, Hasan Iqbal* | **Main category: cs.CL**

**Keywords:** AI 导师, 错误识别, 检索增强, 大型语言模型, 教学评估

**Comment:** 6 pages, 2 figures, 1 table

> **TL;DR:** 本文提出了一个用于AI导师错误识别的检索增强型提示系统，该系统在BEA 2025共享任务中表现优于所有基线。

**AI_Comments:** 本文的创新点在于结合了检索增强技术和大型语言模型（LLM）的少样本提示能力，用于复杂的教学反馈评估任务。这种方法不仅提高了错误识别的准确性，还通过生成可解释的预测增强了系统的实用性。对于AI教育领域，尤其是在开发更智能、更准确的AI导师方面，这项工作具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在评估AI驱动导师的教学能力，特别是其在识别学生数学推理错误方面的准确性。

**Method:** 研究探索了四种方法，最终采用了一个基于GPT-4o的检索增强型少样本提示系统。该系统通过检索语义相似的例子、构建结构化提示和使用模式引导的输出解析来生成可解释的预测。

**Result:** 最终系统超越了所有基线。

**Conclusion:** 结合示例驱动的提示与大型语言模型推理对于教学反馈评估是有效的。

> **ai_Abstract:** 本文介绍了 NeuralNexus 团队为 BEA 2025 共享任务中 AI 导师错误识别赛道开发的系统。该系统旨在评估 AI 导师能否正确识别学生数学推理中的错误。研究探索了四种方法，最终采用了一个基于 GPT-4o 的检索增强型少样本提示系统，该系统通过检索相似示例、构建结构化提示和模式引导解析来生成预测。实验结果表明，该系统优于所有基线，证明了将示例驱动提示与 LLM 推理结合在教学反馈评估中的有效性。

> **摘要翻译:** 本文介绍了我们为 BEA 2025 AI 驱动导师教学能力评估共享任务中赛道 1：错误识别而开发的系统。该任务涉及评估导师的回答是否正确识别了学生数学推理中的错误。我们探索了四种方法：(1) 对来自多个预训练语言模型 (LM) 的池化 token 嵌入进行机器学习模型集成；(2) 使用 [CLS] 嵌入和 MLP 分类器的冻结句子转换器；(3) 具有 token 级历史和响应嵌入之间多头注意力的历史感知模型；以及 (4) 一个结合大型语言模型 (LLM)，即 GPT 4o 的检索增强型少样本提示系统。我们的最终系统检索语义相似的示例，构建结构化提示，并使用模式引导的输出解析来生成可解释的预测。它超越了所有基线，证明了将示例驱动的提示与 LLM 推理相结合对于教学反馈评估的有效性。我们的代码可在 https://github.com/NaumanNaeem/BEA_2025 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [404] [Spelling-out is not Straightforward: LLMs' Capability of Tokenization from Token to Characters](https://arxiv.org/abs/2506.10641)
> *拼写输出并非直截了当：大型语言模型从词元到字符的分词能力*

*Tatsuya Hiraoka, Kentaro Inui* | **Main category: cs.CL**

**Keywords:** LLMs, 分词, 字符级, 拼写输出, Transformer层

**Comment:** 

> **TL;DR:** 大型语言模型在字符级任务上表现挣扎，本研究揭示了它们在拼写输出过程中如何内部表示和利用字符级信息，发现嵌入层未能完全编码字符信息，LLMs依赖中间和更高层的Transformer层来重建字符级知识。

**AI_Comments:** 这项工作创新性地揭示了LLMs在处理字符级信息时的内部机制，特别是指出了嵌入层的局限性以及Transformer高层在重建字符知识中的关键作用。这对于理解LLMs的内部工作原理及其在细粒度文本处理上的能力边界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大型语言模型（LLMs）可以高精度地逐字符拼写出词元，但它们在更复杂的字符级任务（如识别词元内的组成子组件）上却表现困难。本研究旨在调查LLMs在拼写输出过程中如何内部表示和利用字符级信息。

**Method:** 通过三种互补的分析方法：探测分类器（probing classifiers）、知识神经元识别（identification of knowledge neurons）和注意力权重检查（inspection of attention weights）来验证机制。

**Result:** 分析显示，尽管拼写输出对人类来说是一个简单的任务，但LLMs处理起来并非直截了当。具体而言，嵌入层未能完全编码字符级信息，尤其是在第一个字符之后。因此，LLMs依赖中间和更高层的Transformer层来重建字符级知识，并在此过程中观察到其拼写行为的明显“突破”。

**Conclusion:** 本研究得出结论，对于大型语言模型而言，拼写输出并非一个简单的过程，它们需要通过中间和更高层的Transformer层来重建字符级知识，而不是在嵌入层就完全编码。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在执行字符级拼写输出任务时内部处理信息的方式。尽管LLMs能高精度地拼写，但在更复杂的字符级任务上存在困难。研究发现，LLMs的嵌入层未能完全编码字符级信息，特别是首字符之后的部分。相反，LLMs需要依赖中间和更高层的Transformer层来重建和利用字符级知识，这在它们的拼写行为中表现出显著的“突破”。该机制通过探测分类器、知识神经元识别和注意力权重检查三种方法得到验证。

> **摘要翻译:** 大型语言模型（LLMs）可以高精度地逐字符拼写出词元，但它们在更复杂的字符级任务（例如识别词元内的组成子组件）上却表现困难。在这项工作中，我们调查了LLMs在拼写输出过程中如何内部表示和利用字符级信息。我们的分析揭示，尽管拼写输出对人类来说是一个简单的任务，但LLMs处理起来并非直截了当。具体而言，我们发现嵌入层未能完全编码字符级信息，尤其是在第一个字符之后。因此，LLMs依赖中间和更高层的Transformer层来重建字符级知识，我们观察到它们拼写行为中明显的“突破”。我们通过三种互补的分析验证了这一机制：探测分类器、知识神经元识别和注意力权重检查。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [409] [Large Language Models for Detection of Life-Threatening Texts](https://arxiv.org/abs/2506.10687)
> *大型语言模型用于生命威胁文本检测*

*Thanh Thi Nguyen, Campbell Wilson, Janis Dalins* | **Main category: cs.CL**

**Keywords:** 大型语言模型,生命威胁文本检测,文本分类,机器学习,心理健康

**Comment:** 

> **TL;DR:** 本文展示了大型语言模型（LLMs）在检测生命威胁文本方面的卓越性能，超越了传统方法。

**AI_Comments:** 本文创新性地将大型语言模型应用于生命威胁文本检测这一关键领域，并系统地与传统方法进行对比，明确展示了LLMs的优越性。特别指出不同LLM模型的性能差异以及上采样技术对LLM影响较小，为未来实际应用提供了宝贵的指导。这项研究对于心理健康支持和危机干预具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 检测生命威胁语言对于保障处于困境中的个体、促进心理健康和福祉以及预防潜在的伤害和生命损失至关重要。

**Method:** 本文提出了一种使用大型语言模型（LLMs）识别生命威胁文本的有效方法。研究者微调了Gemma、Mistral和Llama-2（7B参数变体）三种开源LLMs，并在不同类别平衡（平衡、不平衡、极端不平衡）的数据集上进行实验。同时，将LLMs与词袋模型、词嵌入、主题模型和BERT等传统方法进行了比较。对于不平衡数据场景，采用了上采样技术。

**Result:** 实验结果表明，LLMs的表现优于传统方法。具体来说，Mistral和Llama-2模型在平衡和不平衡数据场景中表现最佳，而Gemma略逊一筹。上采样技术对传统方法有益，但对LLMs的影响不大。

**Conclusion:** 这项研究表明大型语言模型在解决现实世界中生命威胁语言检测问题方面具有巨大潜力。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）在检测生命威胁文本方面的应用，并与传统方法进行了比较。通过在不同类别平衡的数据集上微调Gemma、Mistral和Llama-2等开源LLMs，实验证明LLMs的性能优于传统方法，其中Mistral和Llama-2表现最佳。研究还发现上采样技术对LLMs处理不平衡数据的影响较小。该研究突出了LLMs在生命威胁语言检测领域的巨大潜力。

> **摘要翻译:** 检测生命威胁语言对于保障处于困境中的个体、促进心理健康和福祉以及预防潜在的伤害和生命损失至关重要。本文提出了一种使用大型语言模型（LLMs）识别生命威胁文本的有效方法，并将其与词袋模型、词嵌入、主题模型和双向编码器表示转换器（BERT）等传统方法进行了比较。我们使用Gemma、Mistral和Llama-2三种开源LLM的7B参数变体，在构建了类别平衡、不平衡和极端不平衡场景的不同数据集上进行了微调。实验结果表明，LLMs相对于传统方法表现出强大的性能。更具体地说，Mistral和Llama-2模型在平衡和不平衡数据场景中均表现最佳，而Gemma略逊一筹。我们采用上采样技术来处理不平衡数据场景，并证明虽然这种方法有利于传统方法，但对LLMs的影响不大。这项研究表明大型语言模型在解决现实世界中生命威胁语言检测问题方面具有巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [413] [Inferring Adjective Hypernyms with Language Models to Increase the Connectivity of Open English Wordnet](https://arxiv.org/abs/2506.10715)
> *使用语言模型推断形容词上位词以增加开放英语词网的连通性*

*Lorenzo Augello, John P. McCrae* | **Main category: cs.CL**

**Keywords:** 形容词上位词, 语言模型, 开放英语词网, TaxoLLaMa, 词汇资源

**Comment:** 

> **TL;DR:** 本文研究如何使用语言模型推断形容词上位词，以解决开放英语词网中缺失链接的问题，并开发了新资源，证明了TaxoLLaMa方法的可行性。

**AI_Comments:** 本文的创新之处在于将大型语言模型（特别是TaxoLLaMa方法）应用于此前较少关注的形容词上位词推断任务，填补了开放英语词网中的一个重要空白。这对于提升词汇资源质量和语言理解能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开放英语词网（Open English Wordnet）中存在许多缺失的链接，尤其是在形容词上位词方面，这限制了其作为语言学链接开放数据云中关键资源的完整性。

**Method:** 本文首先对上位词关系及其在形容词与名词、动词之间的差异进行了理论探讨。然后，开发了一个新的形容词上位词资源，并微调大型语言模型来预测形容词上位词，借鉴了TaxoLLaMa的方法。

**Result:** 研究表明，TaxoLLaMa的方法可以成功地应用于形容词上位词推断任务。

**Conclusion:** 通过开发新资源并微调大型语言模型，证明了TaxoLLaMa方法可以有效应用于推断形容词上位词，从而有助于增加开放英语词网的连通性。

> **ai_Abstract:** 本研究旨在解决开放英语词网中形容词上位词链接缺失的问题。文章深入探讨了形容词上位词的理论概念，并与名词和动词的上位词进行了区分。为实现目标，研究团队开发了一个新的形容词上位词资源，并利用大型语言模型进行微调，以预测形容词的上位词关系。实验结果表明，TaxoLLaMa的现有方法能够成功地应用于此任务，有效提升了词网的连通性。

> **摘要翻译:** 开放英语词网是作为语言学链接开放数据云的一部分，以OntoLex-lemon形式发布的关键资源。然而，该资源中缺失许多链接，在本文中，我们探讨了如何建立形容词之间的上位词关系。我们对上位词关系及其与名词和动词相比在形容词中的差异进行了理论探讨。我们开发了一个新的形容词上位词资源，并微调大型语言模型来预测形容词上位词，表明TaxoLLaMa的方法可以适应这项任务。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [417] [PREMISE: Scalable and Strategic Prompt Optimization for Efficient Mathematical Reasoning in Large Models](https://arxiv.org/abs/2506.10716)
> *PREMISE：大型模型中高效数学推理的可扩展和战略性提示优化*

*Ye Yu, Yaoning Yu, Haohan Wang* | **Main category: cs.CL**

**Keywords:** 提示优化, 数学推理, 大型语言模型, 效率, 成本降低

**Comment:** 

> **TL;DR:** PREMISE是一种仅基于提示的框架，通过结合轨迹级诊断和梯度启发的提示优化，显著减少大型推理模型在数学任务中的冗余计算、token使用和成本，同时保持或提高准确性，并且无需修改模型权重。

**AI_Comments:** PREMISE的创新之处在于其“仅基于提示”的黑盒优化方法，这使其能够直接应用于商业大型语言模型，解决了传统方法需要模型微调或架构修改的限制。通过结合轨迹级诊断和梯度启发优化，它有效地平衡了推理效率和准确性，为降低大型模型部署成本提供了实用且可扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）在数学基准测试中表现出色，但其冗长的思维链（CoT）推理导致token使用和成本过高，限制了在延迟敏感或API受限环境中的部署。

**Method:** 本文介绍了PREMISE（PRompt-based Efficient Mathematical Inference with Strategic Evaluation），一个仅基于提示的框架，无需修改模型权重即可减少推理开销。PREMISE结合了轨迹级诊断和梯度启发的提示优化，通过多目标文本搜索来最小化冗余计算，同时保持答案准确性，平衡token长度和答案有效性。它以单次黑盒接口运行，可直接应用于商业LLM。

**Result:** 在GSM8K、SVAMP和Math500数据集上，PREMISE匹配或超过了基线准确性（Claude从96%到96%，Gemini从91%到92%），同时将推理token减少了高达87.5%，并将美元成本降低了69%-82%。

**Conclusion:** 提示级优化是实现高效大型推理模型推理的实用且可扩展的途径，且不影响推理质量。

> **ai_Abstract:** PREMISE是一个创新的仅基于提示的框架，旨在解决大型推理模型在数学任务中因冗长思维链导致的token使用和成本过高问题。该框架通过结合轨迹级诊断和梯度启发的提示优化，以多目标文本搜索的方式，在不修改模型权重的前提下，显著减少冗余计算，优化提示的简洁性和正确性。实验结果表明，PREMISE在保持或提高数学基准测试准确性的同时，能够大幅减少推理token和运行成本，证明了提示级优化在提高大型推理模型效率方面的实用性和可扩展性。

> **摘要翻译:** 大型推理模型（LRMs），如Claude 3.7 Sonnet和OpenAI o1，通过冗长的思维链（CoT）推理在数学基准测试中取得了强大的性能，但由此产生的轨迹通常不必要地冗长。这会增加token使用和成本，限制了在延迟敏感或API受限环境中的部署。我们引入了PREMISE（PRompt-based Efficient Mathematical Inference with Strategic Evaluation），一个仅基于提示的框架，无需修改模型权重即可减少推理开销。PREMISE结合了轨迹级诊断和梯度启发的提示优化，以最小化冗余计算，同时保持答案准确性。该方法通过多目标文本搜索共同优化简洁性和正确性，平衡token长度和答案有效性。与现有工作不同，PREMISE以单次黑盒接口运行，因此可以直接应用于商业LLM。在GSM8K、SVAMP和Math500数据集上，我们匹配或超过了基线准确性（Claude从96%到96%，Gemini从91%到92%），同时将推理token减少了高达87.5%，并将美元成本降低了69%-82%。这些结果表明，提示级优化是实现高效大型推理模型推理的实用且可扩展的途径，且不影响推理质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [422] [One Tokenizer To Rule Them All: Emergent Language Plasticity via Multilingual Tokenizers](https://arxiv.org/abs/2506.10766)
> *一个分词器统领一切：通过多语言分词器实现涌现的语言可塑性*

*Diana Abagyan, Alejandro R. Salamanca, Andres Felipe Cruz-Salinas, Kris Cao, Hangyu Lin, Acyr Locatelli, Marzieh Fadaee, Ahmet Üstün, Sara Hooker* | **Main category: cs.CL**

**Keywords:** 多语言LLMs, 分词器设计, 语言可塑性, 语言适应性, 通用分词器

**Comment:** 

> **TL;DR:** 预训练大规模多语言大型语言模型（LLMs）面临语言覆盖和适应性挑战。本文提出使用一个通用分词器，该分词器训练的语言比主要预训练语言更多，以提高模型在后训练阶段对新语言的适应能力（语言可塑性）。实验表明，这种通用分词器显著提高了对新语言甚至完全未见语言的适应性，同时对预训练语言的性能影响最小。

**AI_Comments:** 这篇论文为多语言大型语言模型（LLM）开发中的一个主要挑战——语言覆盖和适应性——提供了一个创新且实用的解决方案。作者提出的“通用分词器”理念，即使用比主要预训练语言更广泛的语言集进行训练，是一种巧妙且看似“廉价”的干预措施，却在语言可塑性方面带来了显著改进。其对“未见”语言的适应能力提升尤其值得关注，这表明了强大的泛化能力。这项工作有望对提升LLM在全球更广泛语言范围内的可用性和性能产生重大影响。

<details>
  <summary>Details</summary>

**Motivation:** 大规模多语言大型语言模型（LLMs）的预训练面临挑战，包括模型容量有限、高质量数据稀缺和计算资源限制。此外，分词器缺乏语言覆盖范围，使得在后训练阶段弥补新语言的差距变得困难。本文旨在研究如何在训练早期通过相对廉价的干预措施来提高模型的“语言可塑性”，即模型在后训练阶段对新语言的适应能力。

**Method:** 研究分词器设计，并提出使用一个通用分词器，该分词器训练的语言比主要的预训练语言更多。通过对不同语种和不同训练策略进行系统实验来验证其有效性。

**Result:** 通用分词器能够显著提高语言适应性，与特定于预训练语言的分词器相比，胜率提高了高达20.2%。此外，通用分词器还对分词器和预训练中完全未见的语言表现出更好的可塑性，胜率提高了高达5%。实现这种对扩展语言集的适应，同时对预训练中包含的大多数语言的性能影响最小。

**Conclusion:** 在训练早期使用通用分词器是一种有效且相对廉价的干预措施，可以显著提高大型语言模型对新语言甚至未见语言的语言可塑性和适应能力，同时不影响主要预训练语言的性能。

> **ai_Abstract:** 本文针对大规模多语言大型语言模型（LLMs）预训练中遇到的语言覆盖和适应性挑战，提出了一种新颖的分词器设计方法。研究提出使用一种“通用分词器”，该分词器训练的语言数量多于主要预训练语言，旨在增强模型的“语言可塑性”，即模型在后训练阶段对新语言的适应能力。实验结果表明，与传统分词器相比，这种通用分词器显著提高了模型对已知和完全未见语言的适应性，胜率分别提升高达20.2%和5%，同时对主要预训练语言的性能影响极小。这表明该方法提供了一种经济有效的方式来提升多语言LLM的泛化能力。

> **摘要翻译:** 大规模多语言大型语言模型（LLMs）同时预训练多种语言面临挑战，原因在于模型容量有限、高质量数据稀缺以及计算资源限制。此外，分词器缺乏语言覆盖范围，使得纯粹在后训练阶段解决新语言的差距变得更加困难。在这项工作中，我们研究了在训练早期相对廉价的干预措施如何改善“语言可塑性”，即模型在后训练阶段对新语言的适应能力。我们专注于分词器设计，并提出使用一个通用分词器，该分词器训练的语言比主要预训练语言更多，以实现在预训练后扩展语言覆盖范围时的有效适应。我们对不同语种和不同训练策略进行的系统实验表明，通用分词器能够显著提高语言适应性，与特定于预训练语言的分词器相比，胜率提高了高达20.2%。此外，通用分词器还对分词器和预训练中完全未见的语言表现出更好的可塑性，胜率提高了高达5%。我们实现了对扩展语言集的适应，同时对预训练中包含的大多数语言的性能影响最小。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [426] [Different Questions, Different Models: Fine-Grained Evaluation of Uncertainty and Calibration in Clinical QA with LLMs](https://arxiv.org/abs/2506.10769)
> *不同的问题，不同的模型：大型语言模型在临床问答中不确定性和校准的细粒度评估*

*Alberto Testoni, Iacer Calixto* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 临床问答, 不确定性估计, 模型校准, 细粒度评估

**Comment:** 

> **TL;DR:** 本文对大型语言模型在临床问答中不确定性估计和校准方法进行了细粒度评估，发现性能因专业和问题类型而异，并提出轻量级方法。

**AI_Comments:** 这项研究通过细粒度评估，揭示了LLM在临床问答中不确定性估计的复杂性，并提出了实用的轻量级方法。其创新在于强调了“不同问题，不同模型”的理念，对LLM在高风险领域（如医疗）的实际部署具有重要指导意义，提醒开发者需考虑领域和任务的细微差别。

<details>
  <summary>Details</summary>

**Motivation:** 在临床决策支持等高风险领域部署大型语言模型（LLMs）时，准确且校准良好的不确定性估计至关重要。

**Method:** 对临床多项选择问答中的不确定性估计方法进行细粒度评估。研究涵盖了十个开源LLM（通用、生物医学和推理模型），跨越两个数据集、十一个医学专业和六种问题类型。比较了标准的单次生成和基于采样的方法，并提出了一个案例研究，探讨了基于推理轨迹中行为信号的简单、单次通过估计器。

**Result:** 轻量级方法在仅需一次生成的情况下，性能接近语义熵。结果显示在不同专业和问题类型之间存在显著差异。

**Conclusion:** 选择模型时，必须根据问题的性质和模型的特定优势进行。

> **ai_Abstract:** 本文对大型语言模型在临床多项选择问答中的不确定性估计和校准进行了细致评估。研究涵盖了多种开源LLM、医学专业和问题类型，并比较了不同估计方法，包括提出了一种基于行为信号的轻量级单次通过估计器。研究发现，模型性能在不同专业和问题类型之间存在显著差异，强调了根据具体问题和模型特点选择LLM的重要性。

> **摘要翻译:** 准确且校准良好的不确定性估计对于在临床决策支持等高风险领域部署大型语言模型（LLMs）至关重要。我们对临床多项选择问答中的不确定性估计方法进行了细粒度评估，涵盖了十个开源LLM（通用、生物医学和推理模型），跨越两个数据集、十一个医学专业和六种问题类型。我们比较了标准的单次生成和基于采样的方法，并提出了一个案例研究，探讨了基于推理轨迹中行为信号的简单、单次通过估计器。这些轻量级方法在仅需一次生成的情况下，性能接近语义熵。我们的结果揭示了在不同专业和问题类型之间存在显著差异，强调了根据问题的性质和模型特定优势来选择模型的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [429] [Improving Named Entity Transcription with Contextual LLM-based Revision](https://arxiv.org/abs/2506.10779)
> *基于上下文LLM修订的命名实体转录改进*

*Viet Anh Trinh, Xinlu He, Jacob Whitehill* | **Main category: cs.CL**

**Keywords:** 命名实体, 自动语音识别, 大语言模型, 修订, 词错误率

**Comment:** 

> **TL;DR:** ASR在命名实体识别上表现不佳，本文提出用LLM结合上下文来修正ASR的命名实体错误，并在新数据集上实现了显著的错误率降低。

**AI_Comments:** 本文的创新点在于利用大语言模型结合上下文信息对ASR输出的命名实体进行后修正，这是一种有效解决ASR在特定领域命名实体识别瓶颈的方法。引入新的、专门针对命名实体识别的数据集NER-MIT-OpenCourseWare也对该领域的研究具有重要意义。该方法显著降低了命名实体的错误率，对于需要高精度命名实体识别的下游应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自动语音识别（ASR）系统在通用语音上表现出色，但其在命名实体上的词错误率（WER）仍然很高。由于命名实体通常是最关键的关键词，错误识别会影响所有下游应用，尤其当ASR系统作为复杂系统的前端时。

**Method:** 本文引入了一种大语言模型（LLM）修订机制，通过利用LLM的推理能力以及包含一组正确命名实体的局部上下文（例如，讲义）来修正ASR预测中不正确的命名实体。此外，还引入了NER-MIT-OpenCourseWare数据集，其中包含45小时的麻省理工学院课程数据用于开发和测试。

**Result:** 在NER-MIT-OpenCourseWare数据集上，本文提出的技术使命名实体的相对词错误率降低了高达30%。

**Conclusion:** 所提出的基于LLM的修订机制结合局部上下文，能够显著提高自动语音识别系统中命名实体的转录准确性。

> **ai_Abstract:** 本文针对自动语音识别（ASR）系统在命名实体识别上的高错误率问题，提出了一种基于大语言模型（LLM）的修订机制。该机制利用LLM的推理能力和局部上下文（如讲义中包含的正确命名实体）来纠正ASR的命名实体预测错误。研究团队还构建了新的NER-MIT-OpenCourseWare数据集进行评估。实验结果表明，该方法在命名实体上的相对词错误率降低了高达30%。

> **摘要翻译:** 随着建模的最新进展和监督训练数据量的增加，自动语音识别（ASR）系统在通用语音上取得了显著的性能。然而，最先进的ASR在命名实体上的词错误率（WER）仍然很高。由于命名实体通常是最关键的关键词，错误识别它们会影响所有下游应用，尤其当ASR系统作为复杂系统的前端时。在本文中，我们引入了一种大语言模型（LLM）修订机制，通过利用LLM的推理能力以及包含一组正确命名实体的局部上下文（例如，讲义）来修正ASR预测中不正确的命名实体。最后，我们引入了NER-MIT-OpenCourseWare数据集，其中包含45小时的麻省理工学院课程数据用于开发和测试。在该数据集上，我们提出的技术使命名实体的相对词错误率降低了高达30%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [430] [Mitigating Negative Interference in Multilingual Sequential Knowledge Editing through Null-Space Constraints](https://arxiv.org/abs/2506.10800)
> *通过零空间约束缓解多语言序列知识编辑中的负面干扰*

*Wei Sun, Tingyu Qu, Mingxiao Li, Jesse Davis, Marie-Francine Moens* | **Main category: cs.CL**

**Keywords:** 多语言知识编辑, 零空间约束, 参数干扰, 大型语言模型, 序列编辑

**Comment:** ACL 2025 Findings

> **TL;DR:** 提出LangEdit框架，通过零空间约束隔离语言特定知识更新，有效缓解多语言LLM序列知识编辑中的负面干扰，提高更新效率和准确性。

**AI_Comments:** LangEdit的创新之处在于其利用零空间约束来数学上保证不同语言知识更新的独立性，这有效地解决了多语言LLM中序列编辑的负面干扰问题。这种方法不仅提高了知识更新的准确性，也优化了资源利用，避免了为每种语言维护独立模型的成本，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）中高效更新多语言知识并保持跨语言事实表征的一致性是一个长期未解决的挑战。跨语言的序列编辑常导致破坏性参数干扰，严重降低多语言泛化能力和注入知识的准确性。

**Method:** 提出LangEdit框架，这是一种新颖的零空间约束框架，旨在精确隔离语言特定的知识更新。其核心创新在于将每种语言的参数更新投影到之前已更新子空间的零空间（正交补集）上，数学上保证了更新的独立性，同时保留了多语言泛化能力。

**Result:** LangEdit在三种模型架构、六种语言和四项下游任务上进行了全面评估，结果表明它能有效缓解参数干扰，并优于现有的最先进编辑方法。

**Conclusion:** LangEdit为LLMs中高效、准确的多语言知识更新提供了潜力，并通过零空间约束成功解决了跨语言序列知识编辑中的负面干扰问题。

> **ai_Abstract:** 本文提出了LangEdit，一个用于多语言序列知识编辑的新型零空间约束框架，旨在解决大型语言模型中跨语言编辑导致的负面参数干扰问题。LangEdit通过将语言特定的参数更新投影到先前更新子空间的正交补集上，确保了更新的独立性并维护了多语言泛化能力。实验结果表明，LangEdit有效缓解了干扰，并超越了现有SOTA方法，为LLMs的高效准确多语言知识更新提供了解决方案。

> **摘要翻译:** 在大型语言模型（LLMs）中高效更新多语言知识，同时保持跨语言事实表征的一致性，仍然是一个长期存在且未解决的挑战。虽然为每种语言部署单独的编辑系统似乎可行，但这种方法由于需要管理多个模型而导致成本高昂。更有效的解决方案是将所有语言的知识更新整合到一个统一模型中。然而，跨语言进行序列编辑常常导致破坏性参数干扰，严重降低多语言泛化能力和注入知识的准确性。为了解决这一挑战，我们提出了LangEdit，一个新颖的零空间约束框架，旨在精确隔离语言特定的知识更新。LangEdit的核心创新在于能够将每种语言的参数更新投影到之前已更新子空间的零空间（正交补集）上。这种方法在数学上保证了更新的独立性，同时保留了多语言泛化能力。我们在三种模型架构、六种语言和四项下游任务上进行了全面评估，结果表明LangEdit能有效缓解参数干扰，并优于现有的最先进编辑方法。我们的结果凸显了其在LLMs中实现高效、准确的多语言知识更新的潜力。代码可在https://github.com/VRCMF/LangEdit.git获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [433] [ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization](https://arxiv.org/abs/2506.10822)
> *ReCUT：通过逐步试探和偏好优化平衡大型语言模型中的推理长度和准确性*

*Zhensheng Jin, Xinze Li, Yifan Ji, Chunyi Peng, Zhenghao Liu, Qi Shi, Yukun Yan, Shuo Wang, Furong Peng, Ge Yu* | **Main category: cs.CL**

**Keywords:** 推理长度, 大型语言模型, 思维链, 偏好优化, 推理压缩

**Comment:** 

> **TL;DR:** ReCUT通过逐步探索和偏好优化，在保持或提高准确性的同时，显著缩短了LLM的推理长度。

**AI_Comments:** ReCUT的创新之处在于其结合了逐步探索、长短切换采样和基于偏好优化的双模型训练与参数插值，有效解决了思维链推理中冗余和过长的问题，并在平衡准确性和效率方面取得了显著进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的思维链（CoT）方法导致大型语言模型（LLM）的推理路径过长或冗余，且现有缓解方法受限于生成数据的质量并易于过拟合。

**Method:** ReCUT采用逐步探索机制和长短切换采样策略，使LLM能够逐步生成多样化的推理路径。这些路径被评估并用于构建偏好对，以训练两个专门模型（一个优化推理准确性，另一个优化较短推理），最终通过这两个模型的参数插值获得一个集成模型。

**Result:** 在多个数学推理数据集和骨干模型上的实验结果表明，ReCUT与各种基线相比，显著减少了约30-50%的推理长度，同时保持或提高了推理准确性。

**Conclusion:** ReCUT提供了一种有效的方法来平衡大型语言模型的推理长度和准确性，解决了思维链推理中过长路径的问题。

> **ai_Abstract:** ReCUT是一种新颖的方法，旨在通过逐步探索和长短切换采样生成多样化推理路径，并利用偏好优化训练两个专门模型（注重准确性和长度），最终通过参数插值集成，以在保持或提高LLM推理准确性的同时，显著缩短推理长度。

> **摘要翻译:** 思维链（CoT）提示的最新进展显著提高了大型语言模型（LLM）的推理能力。然而，这些方法常常存在过度思考的问题，导致推理轨迹不必要地冗长或冗余。现有方法试图通过整理多个推理链来训练LLM以缓解此问题，但其有效性常受限于生成数据的质量且易于过拟合。为了解决这一挑战，我们提出了一种新颖的方法——通过逐步试探进行推理压缩（ReCUT），旨在平衡推理轨迹的准确性和长度。具体而言，ReCUT采用逐步探索机制和长短切换采样策略，使LLM能够逐步生成多样化的推理路径。这些路径被评估并用于构建偏好对，以训练两个专门的模型（Gemini LLM）——一个优化推理准确性，另一个优化较短推理。最终通过这两个模型的参数插值获得一个集成模型。在多个数学推理数据集和骨干模型上的实验结果表明，与各种基线相比，ReCUT显著减少了约30-50%的推理长度，同时保持或提高了推理准确性。所有代码和数据将通过https://github.com/NEUIR/ReCUT发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [438] [Accelerating Diffusion Large Language Models with SlowFast: The Three Golden Principles](https://arxiv.org/abs/2506.10848)
> *使用SlowFast加速扩散大语言模型：三大黄金原则*

*Qingyan Wei, Yaojie Zhang, Zhiyuan Liu, Dongrui Liu, Linfeng Zhang* | **Main category: cs.CL**

**Keywords:** 扩散大语言模型, 采样策略, SlowFast, 加速, 并行生成

**Comment:** 11 pages; 5 figures;

> **TL;DR:** 本文提出SlowFast动态采样策略，通过自适应阶段切换和三大原则，显著加速扩散大语言模型（dLLMs）的推理过程，实现并行生成和高吞吐量。

**AI_Comments:** 该研究创新性地提出了动态采样策略，解决了扩散大语言模型现有采样方法的效率和灵活性问题。通过引入三大黄金原则和与缓存机制结合，实现了显著的推理速度提升，并证明了扩散模型在特定场景下超越传统自回归模型的潜力，对未来扩散模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有扩散大语言模型（dLLMs）的采样策略（如基于置信度或半自回归解码）存在静态行为，导致效率低下和灵活性受限，限制了dLLMs并行令牌生成的潜力。

**Method:** 提出SlowFast采样，一种新颖的动态采样策略，它自适应地在探索性解码和加速解码阶段之间交替。该方法遵循确定性原则、收敛性原则和位置原则三大黄金原则，并与dLLM-Cache集成以减少冗余计算。

**Result:** SlowFast采样在LLaDA上实现了高达15.63倍的加速，且准确率下降极小；与缓存结合时，加速比可达34.22倍。在吞吐量方面，该方法优于LLaMA3 8B等强大的自回归基线。

**Conclusion:** 精心设计的采样策略可以充分发挥扩散大语言模型（dLLMs）在快速高质量生成方面的潜力。

> **ai_Abstract:** 本文针对扩散大语言模型（dLLMs）现有采样策略的效率和灵活性不足问题，提出了一种名为SlowFast的动态采样策略。该策略通过自适应地在探索性解码和加速解码阶段之间切换，并遵循确定性、收敛性和位置三大原则，以优化令牌的置信和高效解码。此外，SlowFast采样与dLLM-Cache相结合以减少冗余计算。实验结果表明，该方法在LLaDA上实现了显著的推理加速，最高可达34.22倍，且在吞吐量上超越了强大的自回归基线，证实了其在实现dLLMs快速高质量生成方面的巨大潜力。

> **摘要翻译:** 基于扩散的语言模型（dLLM）通过实现并行令牌生成和显著降低推理延迟，已成为传统自回归LLM的一种有前景的替代方案。然而，现有dLLM的采样策略，例如基于置信度或半自回归解码，通常存在静态行为，导致效率低下和灵活性受限。在本文中，我们提出了SlowFast采样，一种新颖的动态采样策略，它自适应地在探索性解码和加速解码阶段之间交替。我们的方法遵循三大黄金原则：确定性原则、收敛性原则和位置原则，这些原则决定了何时何地可以自信高效地解码令牌。我们进一步将我们的策略与dLLM-Cache集成以减少冗余计算。在基准和模型上的大量实验表明，SlowFast采样在LLaDA上实现了高达15.63倍的加速，且准确率下降极小，与缓存结合时可达34.22倍。值得注意的是，我们的方法在吞吐量方面优于LLaMA3 8B等强大的自回归基线，这表明精心设计的采样可以充分发挥dLLM在快速高质量生成方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [443] [Enhancing Medical Dialogue Generation through Knowledge Refinement and Dynamic Prompt Adjustment](https://arxiv.org/abs/2506.10877)
> *通过知识精炼和动态提示调整增强医疗对话生成*

*Hongda Sun, Jiaren Peng, Wenzhong Yang, Liang He, Bo Du, Rui Yan* | **Main category: cs.CL**

**Keywords:** 医疗对话系统, 知识精炼, 动态提示调整, MedRef, 医学实体准确性

**Comment:** ACL 2025 Findings

> **TL;DR:** MedRef通过知识精炼和动态提示调整，显著提升了医疗对话系统的生成质量和医疗实体准确性。

**AI_Comments:** MedRef的创新之处在于其结合了知识精炼和动态提示调整，这有助于提高医疗对话的准确性和个性化。特别是三元组过滤器和演示选择器模块，展现了系统对复杂医疗场景的实时适应性，对于提升用户体验和医疗安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医疗对话系统（MDS）在识别相关医疗知识和生成个性化、医学准确的响应方面存在困难。

**Method:** 本文提出了MedRef，一种新颖的医疗对话系统，它集成了知识精炼机制以过滤不相关的医疗数据，并设计了一个包含历史和证据细节的综合提示结构。为实现对不同患者状况的实时适应性，MedRef还实现了两个关键模块：三元组过滤器（Triplet Filter）和演示选择器（Demo Selector），用于在系统提示中提供适当的知识和示例。

**Result:** 在MedDG和KaMed基准测试上的大量实验表明，MedRef在生成质量和医疗实体准确性方面均优于现有最先进的基线方法。

**Conclusion:** MedRef通过其知识精炼和动态提示调整机制，有效提高了医疗对话系统的性能，证明了其在实际医疗应用中的有效性和可靠性。

> **ai_Abstract:** 本文提出了一种名为MedRef的新型医疗对话系统，旨在解决现有系统在识别相关医疗知识和生成准确响应方面的不足。MedRef通过知识精炼机制过滤不相关数据，并采用动态提示调整，结合历史和证据细节。其核心模块三元组过滤器和演示选择器确保系统能实时适应不同患者情况。实验结果表明，MedRef在生成质量和医疗实体准确性上均超越了现有基线，验证了其在医疗应用中的潜力和可靠性。

> **摘要翻译:** 医疗对话系统（MDS）已成为重要的在线平台，能够与患者进行多轮、上下文感知的对话。然而，现有的MDS常常难以（1）识别相关的医学知识和（2）生成个性化、医学准确的响应。为了解决这些挑战，我们提出了MedRef，一种新颖的MDS，它结合了知识精炼和动态提示调整。首先，我们采用知识精炼机制来过滤掉不相关的医疗数据，从而提高响应中关键医疗实体的预测。此外，我们设计了一个综合的提示结构，其中包含历史细节和证据细节。为了实现对不同患者状况的实时适应性，我们实现了两个关键模块：三元组过滤器和演示选择器，它们在系统提示中提供适当的知识和示例。在MedDG和KaMed基准测试上的大量实验表明，MedRef在生成质量和医疗实体准确性方面均优于现有最先进的基线方法，突显了其在现实医疗应用中的有效性和可靠性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [446] [Slimming Down LLMs Without Losing Their Minds](https://arxiv.org/abs/2506.10885)
> *在不损失性能的情况下精简大型语言模型*

*Qingda, Mai* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 微调, LoRA, QLoRA, 参数高效

**Comment:** 10 pages

> **TL;DR:** 本文研究LoRA和QLoRA等参数高效微调方法对大型语言模型（LLM）性能的影响，发现在HellaSwag、GSM8K和MMLU-CS基准上，LoRA类方法能有效提升特定任务性能并保持计算效率，且性能与微调数据集和基准任务的对齐度密切相关。

**AI_Comments:** 该研究的创新点在于系统地验证了LoRA/QLoRA等参数高效微调方法在不同LLM能力领域的有效性，并强调了微调数据集与基准任务对齐的重要性。这对于在资源有限环境下优化LLM性能具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究微调，特别是参数高效方法（LoRA和QLoRA），对大型语言模型性能的影响，旨在实现LLM的精简而不损失其能力。

**Method:** 通过在三个关键领域（常识推理HellaSwag、数学推理GSM8K和多领域知识MMLU-CS）评估模型能力，来验证LoRA和QLoRA等参数高效微调方法的效果。

**Result:** LoRA类方法能有效提升特定任务性能并保持计算效率；性能强烈依赖于微调数据集与基准任务之间的对齐程度。

**Conclusion:** 本研究为参数高效机制提供了理论见解，并为资源有限的开发者实现高效LLM适应提供了实践指导。

> **ai_Abstract:** 本文探讨了LoRA和QLoRA等参数高效微调方法对大型语言模型性能的影响。研究通过在常识推理、数学推理和多领域知识三个基准上评估，发现LoRA类方法能有效提升特定任务性能并保持计算效率，且性能与微调数据集和基准任务的对齐度密切相关。该研究为LLM的高效适应提供了理论洞察和实践指导。

> **摘要翻译:** 本文研究并验证了微调对大型语言模型性能的影响，重点关注参数高效方法（LoRA和QLoRA）。我们评估了模型在三个关键领域的能力：(1) 常识推理（HellaSwag），(2) 数学推理（GSM8K），以及 (3) 多领域知识（MMLU-CS）。
我们的研究结果表明：(1) 基于LoRA的方法能有效提升特定任务性能，同时保持计算效率；(2) 性能强烈依赖于微调数据集与基准任务之间的对齐程度。本研究为参数高效机制提供了理论见解，并为资源有限的开发者实现高效LLM适应提供了实践指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [448] [Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers](https://arxiv.org/abs/2506.10887)
> *泛化还是幻觉？理解Transformer中的脱离语境推理*

*Yixiao Huang, Hanlin Zhu, Tianyu Guo, Jiantao Jiao, Somayeh Sojoudi, Michael I. Jordan, Stuart Russell, Song Mei* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 脱离语境推理, 泛化, 幻觉, 矩阵分解

**Comment:** 

> **TL;DR:** 本文认为大型语言模型（LLM）中的泛化和幻觉行为都源于脱离语境推理（OCR），并从理论和实验两方面探究了其机制。

**AI_Comments:** 这项工作创新性地将LLM的泛化和幻觉统一归结为脱离语境推理（OCR）机制，并从理论和实验两方面提供了深入的解释。特别是，它揭示了矩阵分解在模型学习OCR中的关键作用，并利用梯度下降的隐式偏置来解释其数学基础。这为理解LLM行为提供了新的视角，对于未来缓解知识注入中的不良行为具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在微调后能够获取新知识，但这一过程存在泛化能力强和易产生幻觉的矛盾现象，其原因尚不清楚。本文旨在理解这种现象。

**Method:** 作者提出泛化和幻觉都源于脱离语境推理（OCR），即通过关联概念（即使没有因果关系）来推断含义的能力。他们通过在五种LLM上进行实验来验证OCR驱动泛化和幻觉。为了建立严格的理论理解，他们将OCR形式化为一个合成的事实回忆任务，并经验性地展示了一个具有分解输出和值矩阵的单层单头注意力Transformer可以解决此任务。理论分析表明，OCR能力归因于梯度下降的隐式偏置，该偏置有利于最小化组合输出-值矩阵核范数的解决方案。

**Result:** 实验证实OCR确实驱动了泛化和幻觉，这取决于关联概念是否具有因果关系。经验表明，具有分解输出和值矩阵的Transformer可以学习解决OCR任务，而具有组合权重的模型则不能，这强调了矩阵分解的关键作用。理论分析揭示，OCR能力源于梯度下降的隐式偏置，该偏置倾向于最小化组合输出-值矩阵核范数的解决方案。

**Conclusion:** 本文为理解脱离语境推理（OCR）现象提供了理论基础，并为分析和缓解知识注入中不良行为提供了新的视角。OCR解释了LLM为何能高效地学习关联事实和推论，无论相关性是因果的还是虚假的。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在微调后同时表现出的强大泛化能力和幻觉现象。作者提出，这两种看似矛盾的行为都源于一个共同机制：脱离语境推理（OCR），即模型关联概念并进行推断的能力，无论这些概念之间是否存在因果关系。通过在五种LLMs上的实验，他们证实了OCR在因果关联存在时导致泛化，在因果关联缺失时导致幻觉。为了深入理解，论文将OCR形式化为一个合成任务，并从理论和经验上证明了具有分解矩阵的Transformer架构能够学习并执行OCR，这归因于梯度下降的隐式偏置，该偏置有利于低核范数解。这项工作为理解OCR现象提供了理论基础，并为解决LLM知识注入中的问题提供了新思路。

> **摘要翻译:** 大型语言模型（LLMs）可以通过微调获取新知识，但这一过程表现出令人费解的双重性：模型可以从新事实中出色地泛化，但也容易产生不正确信息的幻觉。然而，这种现象的原因仍然知之甚少。在这项工作中，我们认为这两种行为都源于一种称为脱离语境推理（OCR）的单一机制：即通过关联概念（即使没有因果联系）来推断含义的能力。我们在五种著名的LLM上的实验证实，OCR确实驱动了泛化和幻觉，这取决于关联概念是否具有因果关系。为了对这一现象建立严谨的理论理解，我们随后将OCR形式化为一个合成的事实回忆任务。我们通过经验证明，一个具有分解输出和值矩阵的单层单头仅注意力Transformer可以学习解决此任务，而一个具有组合权重的模型则不能，这突出了矩阵分解的关键作用。我们的理论分析表明，OCR能力可以归因于梯度下降的隐式偏置，它偏向于最小化组合输出-值矩阵核范数的解决方案。这种数学结构解释了为什么模型能够以高样本效率学习关联事实和推论，无论相关性是因果的还是仅仅是虚假的。最终，我们的工作为理解OCR现象提供了理论基础，为分析和缓解知识注入中的不良行为提供了新的视角。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [450] [BioClinical ModernBERT: A State-of-the-Art Long-Context Encoder for Biomedical and Clinical NLP](https://arxiv.org/abs/2506.10896)
> *BioClinical ModernBERT：一种用于生物医学和临床自然语言处理的先进长上下文编码器*

*Thomas Sounack, Joshua Davis, Brigitte Durieux, Antoine Chaffin, Tom J. Pollard, Eric Lehman, Alistair E. W. Johnson, Matthew McDermott, Tristan Naumann, Charlotta Lindvall* | **Main category: cs.CL**

**Keywords:** 生物医学NLP, 临床NLP, 编码器, 长上下文, Transformer

**Comment:** 

> **TL;DR:** BioClinical ModernBERT是一种新的、长上下文的、高性能编码器，专门用于生物医学和临床NLP，通过大规模预训练和多源数据集克服了现有编码器的局限性。

**AI_Comments:** 该论文提出了一种重要的领域特定编码器BioClinical ModernBERT，通过结合长上下文处理能力和利用迄今为止最大的、多样化的生物医学和临床语料库进行预训练，有效解决了现有编码器在特定领域适应性差和数据源单一的局限性。其性能提升和模型的公开发布对生物医学和临床NLP领域的研究和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有编码器模型在生物医学和临床自然语言处理（NLP）领域的发展速度较慢，导致其领域适应性有限，且难以有效处理长上下文信息，同时过度依赖单一数据源。

**Method:** 研究者开发了BioClinical ModernBERT，这是一种基于ModernBERT的领域适应性编码器，其特点是整合了长上下文处理能力。该模型通过对迄今为止最大的生物医学和临床语料库（超过535亿个token）进行持续预训练，并利用来自20个不同机构、领域和地理区域的数据集，而非单一来源数据。研究者发布了该模型的基础版（1.5亿参数）和大型版（3.96亿参数）。

**Result:** BioClinical ModernBERT在生物医学和临床NLP的速度和性能方面实现了实质性提升。它在涵盖广泛用例的四个下游任务上均优于现有的生物医学和临床编码器。

**Conclusion:** BioClinical ModernBERT通过大规模、多样化的预训练和长上下文处理能力，成功克服了现有生物医学和临床编码器的局限性，为该领域的判别性任务提供了先进且高性能的解决方案。

> **ai_Abstract:** BioClinical ModernBERT是一种专为生物医学和临床NLP设计的新型长上下文编码器。它基于ModernBERT，通过在包含535亿个token的超大规模、多样化（20个数据集）语料库上持续预训练，显著提升了处理速度和性能，并在多个下游任务上超越了现有模型，解决了传统编码器领域适应性差和上下文长度受限的问题。研究者发布了该模型的两个版本及训练检查点。

> **摘要翻译:** 基于编码器的Transformer模型是生物医学和临床自然语言处理（NLP）的核心，因为它们的双向自注意力使其非常适合通过判别任务从非结构化文本中有效提取结构化信息。然而，与解码器模型相比，编码器的发展速度较慢，导致在生物医学和临床环境中领域适应性有限。我们引入了BioClinical ModernBERT，这是一种领域适应性编码器，它基于最近发布的ModernBERT，整合了长上下文处理能力，并在生物医学和临床NLP的速度和性能方面进行了实质性改进。BioClinical ModernBERT通过对迄今为止最大的生物医学和临床语料库（超过535亿个token）进行持续预训练而开发，并通过利用来自不同机构、领域和地理区域的20个数据集，而不是依赖单一来源的数据，解决了先前临床编码器的一个关键限制。它在涵盖广泛用例的四个下游任务上优于现有的生物医学和临床编码器。我们发布了BioClinical ModernBERT的基础版（1.5亿参数）和大型版（3.96亿参数），以及训练检查点以支持进一步研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [453] [Beyond Gold Standards: Epistemic Ensemble of LLM Judges for Formal Mathematical Reasoning](https://arxiv.org/abs/2506.10903)
> *超越黄金标准：用于形式化数学推理的LLM评判者认知集成*

*Lan Zhang, Marco Valentino, Andre Freitas* | **Main category: cs.CL**

**Keywords:** LLM评判者, 自动形式化, 形式化数学推理, 评估方法, 认知集成

**Comment:** 

> **TL;DR:** 本文提出了一种基于认知和形式化基础的LLM评判者集成（EFG）方法，用于自动评估形式化数学推理中的自动形式化任务，实验证明其评估结果与人类评估更强相关。

**AI_Comments:** 这项工作在LLM作为评判者领域迈出了重要一步，特别是在需要高精度和细致评估的形式化数学推理领域。其创新点在于提出了一个基于认知和形式化基础的集成模型（EFG），并通过明确定义多维度的评估标准（LP, MC, FV, FQ），解决了现有LLM评估方法粗粒度的问题。这使得评估结果更加透明和可解释，并且实验结果也支持了其与人类评估的更高相关性，尤其是在捕捉形式质量方面。这对于自动化复杂数学证明的评估具有重要意义，有望显著降低人工评估的成本和专业门槛。

<details>
  <summary>Details</summary>

**Motivation:** 自动形式化在形式化数学推理中至关重要，但其自动评估方法仍未得到充分探索。在复杂数学领域，人工评估耗时且需要专业知识。现有LLM作为评判者的方法通常采用粗粒度且通用的评估标准，限制了其在需要细致、多粒度维度评估的高级形式化数学推理中的有效性。

**Method:** 提出了一种系统、自动的自动形式化任务评估方法，该方法基于认知和形式化基础的LLM评判者集成（EFG）。EFG的定义标准包括逻辑保持（LP）、数学一致性（MC）、形式有效性（FV）和形式质量（FQ），从而实现透明的评估，并考虑了不同的贡献因素。

**Result:** 实验表明，EFG LLM评判者集成作为自动形式化评估的代理是合适的，与粗粒度模型相比，它与人类评估的关联性更强，尤其是在评估形式质量时。

**Conclusion:** LLM作为评判者，尤其是在一组明确定义的原子属性指导下，可以为形式化数学推理的评估提供可扩展、可解释和可靠的支持。

> **ai_Abstract:** 本文提出了一种名为认知和形式化基础集成（EFG）的新型LLM评判者方法，旨在系统地、自动地评估形式化数学推理中的自动形式化任务。针对现有评估方法粗粒度和通用性的局限性，EFG通过结合逻辑保持、数学一致性、形式有效性和形式质量等多维度标准，提供了更细致和透明的评估。实验结果表明，EFG与人类评估的相关性优于传统粗粒度模型，尤其在形式质量评估方面表现突出，证实了LLM作为评判者在结构化指导下，能够为复杂数学推理评估提供可扩展、可解释和可靠的支持。

> **摘要翻译:** 自动形式化通过将自然语言语句自动翻译成形式语言，在形式化数学推理中发挥着关键作用。尽管最近使用大型语言模型（LLM）取得的进展显示出有希望的结果，但自动评估自动形式化的方法仍未得到充分探索。随着人们进入更复杂的领域（例如，高等数学），人类评估需要大量时间和领域专业知识，特别是随着底层语句和背景知识复杂性的增加。LLM作为评判者提供了一种自动化此类评估的有前景的方法。然而，现有方法通常采用粗粒度且通用的评估标准，这限制了它们在高级形式化数学推理中的有效性，因为质量取决于细致、多粒度的维度。在这项工作中，我们通过引入一种系统、自动的方法来评估自动形式化任务，从而弥补这一空白。所提出的方法基于认知和形式化基础的LLM评判者集成（EFG），其定义标准涵盖了逻辑保持（LP）、数学一致性（MC）、形式有效性（FV）和形式质量（FQ），从而实现透明的评估，并考虑了不同的贡献因素。我们验证了所提出的框架，以作为形式数学领域自动形式化评估的代理。总的来说，我们的实验表明，EFG LLM评判者集成是一种合适的评估代理，与粗粒度模型相比，它与人类评估的关联性更强，尤其是在评估形式质量时。这些发现表明，LLM作为评判者，特别是在一组明确定义的原子属性指导下，可以为评估形式化数学推理提供可扩展、可解释和可靠的支持。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [456] [Magistral](https://arxiv.org/abs/2506.10910)
> *Magistral 模型*

*Mistral-AI, :, Abhinav Rastogi, Albert Q. Jiang, Andy Lo, Gabrielle Berrada, Guillaume Lample, Jason Rute, Joep Barmentlo, Karmesh Yadav, Kartik Khandelwal, Khyathi Raghavi Chandu, Léonard Blier, Lucile Saulnier, Matthieu Dinot, Maxime Darrin, Neha Gupta, Roman Soletskyi, Sagar Vaze, Teven Le Scao, Yihan Wang, Adam Yang, Alexander H. Liu, Alexandre Sablayrolles, Amélie Héliou, Amélie Martin, Andy Ehrenberg, Anmol Agarwal, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, Clémence Lanfranchi, Darius Dabert, Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jean-Hadrien Chabran, Jean-Malo Delignon, Joachim Studnia, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Kush Jain, Lingxiao Zhao, Louis Martin, Luyu Gao, Lélio Renard Lavaud, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Maximilian Augustin, Mickaël Seznec, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patrick von Platen, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Pavankumar Reddy Muddireddy, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Romain Sauvestre, Rémi Delacourt, Sanchit Gandhi, Sandeep Subramanian, Shashwat Dalal, Siddharth Gandhi, Soham Ghosh, Srijan Mishra, Sumukh Aithal, Szymon Antoniak, Thibault Schueller, Thibaut Lavril, Thomas Robert, Thomas Wang, Timothée Lacroix, Valeriia Nemychnikova, Victor Paltz, Virgile Richard, Wen-Ding Li, William Marshall, Xuanyu Zhang, Yunhao Tang* | **Main category: cs.CL**

**Keywords:** 强化学习, 大语言模型, 推理模型, 可扩展流水线, 文本数据

**Comment:** 

> **TL;DR:** Magistral 是 Mistral 的首个推理大模型，采用全新的、可扩展的纯强化学习（RL）流水线进行训练。研究表明，仅在文本数据上进行 RL 训练能保持并提升模型能力，并且他们开源了其中一个版本。

**AI_Comments:** 本文具有创新性，因为它在不依赖现有 RL 轨迹或实现的情况下，探索了 LLM 纯强化学习的边界，展示了一种完全专有的自下而上方法。仅在文本上进行 RL 训练就能保留并提升多种模型能力这一发现意义重大。Magistral Small 的开源将促进 RL 驱动的 LLM 开发的进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 开发 Mistral 的首个推理模型和可扩展的强化学习（RL）流水线，通过采用自下而上的方法，完全依赖自己的模型和基础设施，而不是现有的实现和蒸馏的 RL 轨迹。旨在探索 LLM 纯 RL 训练的极限。

**Method:** 开发了一个名为 Magistral 的可扩展 RL 流水线。采用“自下而上”的方法，仅使用自己的模型和基础设施，不依赖现有的 RL 实现或轨迹。探索了 LLM 的纯 RL 训练，提出了一种简单的方法来强制模型的推理语言，并仅在文本数据上进行 RL。训练了基于 Mistral Medium 3 的 Magistral Medium，并开源了包含 Magistral Medium 冷启动数据的 Magistral Small。

**Result:** 展示了一个用于探索 LLM 纯 RL 训练极限的堆栈；提出了一种强制模型推理语言的简单方法；表明仅在文本数据上进行 RL 训练能保持初始检查点的大部分能力；发现文本上的 RL 保持或改进了多模态理解、指令遵循和函数调用；推出了 Magistral Medium 并开源了 Magistral Small。

**Conclusion:** 通过自下而上的方法和专有基础设施，纯粹在文本数据上应用的强化学习，对于训练用于推理的大型语言模型是有效的，能够保持甚至提升多模态理解、指令遵循和函数调用等核心能力。这种方法促成了 Magistral 模型的开发，包括一个开源版本。

> **ai_Abstract:** 本文介绍了 Magistral，这是 Mistral 开创性的推理模型和新颖的可扩展强化学习（RL）流水线。作者摒弃传统方法，采用自下而上的策略，完全依赖其专有模型和基础设施。他们证明，仅在文本数据上进行纯 RL 训练可以有效保持甚至增强大型语言模型的初始能力，包括多模态理解、指令遵循和函数调用。这项工作还提出了一种强制推理语言的方法，并介绍了用于推理的 Magistral Medium（一个经 RL 训练的模型）以及开源的 Magistral Small。

> **摘要翻译:** 我们介绍了 Magistral，这是 Mistral 的第一个推理模型，也是我们自己的可扩展强化学习 (RL) 流水线。我们没有依赖现有的实现和从先前模型中提取的 RL 轨迹，而是采用了一种自下而上的方法，完全依赖我们自己的模型和基础设施。值得注意的是，我们展示了一个堆栈，使我们能够探索 LLM 纯 RL 训练的极限，提出了一种简单的方法来强制模型的推理语言，并表明仅在文本数据上进行 RL 训练可以保持初始检查点的大部分能力。我们发现文本上的 RL 保持或改进了多模态理解、指令遵循和函数调用。我们展示了 Magistral Medium，它是在 Mistral Medium 3 的基础上纯粹通过 RL 进行推理训练的，并且我们开源了 Magistral Small (Apache 2.0)，它进一步包含了来自 Magistral Medium 的冷启动数据。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [459] [Decomposing MLP Activations into Interpretable Features via Semi-Nonnegative Matrix Factorization](https://arxiv.org/abs/2506.10920)
> *通过半非负矩阵分解将MLP激活分解为可解释特征*

*Or Shafran, Atticus Geiger, Mor Geva* | **Main category: cs.CL**

**Keywords:** MLP激活, 可解释性, 半非负矩阵分解, LLM, 稀疏特征

**Comment:** 

> **TL;DR:** 本文提出使用半非负矩阵分解（SNMF）直接分解LLM中的MLP激活，以识别可解释特征，并在因果评估和人类可解释性方面优于稀疏自编码器（SAE）。

**AI_Comments:** 该论文的创新点在于将半非负矩阵分解（SNMF）应用于大型语言模型（LLMs）的MLP激活分解，以获得可解释的特征。这克服了现有稀疏自编码器（SAE）在因果评估和内在可解释性方面的局限性。SNMF直接将特征与神经元组合及其激活输入关联起来，使得特征更具可解释性，并且在实验中表现出优越的因果操控能力和概念对齐。其揭示MLP激活空间中分层结构的能力也为理解LLM的内部机制提供了新的视角，为机械可解释性领域提供了一个简单而有效的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法，特别是基于稀疏自编码器（SAE）的字典学习，在因果评估中表现不佳且缺乏内在可解释性，因为它们的学习与模型计算没有明确关联。研究旨在克服这些局限性，找到一种无监督的方式来识别LLM中可解释的激活方向。

**Method:** 本文通过半非负矩阵分解（SNMF）直接分解多层感知机（MLP）的激活。学习到的特征是共激活神经元的稀疏线性组合，并映射到它们的激活输入，从而使其直接可解释。

**Result:** 在Llama 3.1、Gemma 2和GPT-2上的实验表明，SNMF导出的特征在因果操控方面优于SAE和一个强大的有监督基线（均值差），同时与人类可解释的概念对齐。进一步分析揭示，特定的神经元组合在语义相关的特征中被重用，暴露出MLP激活空间中的分层结构。

**Conclusion:** SNMF是一种简单有效的工具，可用于识别大型语言模型中的可解释特征并剖析概念表示。

> **ai_Abstract:** 该研究提出了一种名为半非负矩阵分解（SNMF）的新方法，用于直接分解大型语言模型（LLMs）中多层感知机（MLP）的激活。与现有方法（如稀疏自编码器SAE）的局限性相比，SNMF旨在学习稀疏、可解释的特征，这些特征是共激活神经元的线性组合，并可直接追溯到其输入。实验结果表明，SNMF在因果操控性能上优于SAE和监督基线，并且其发现的特征与人类可解释的概念高度一致。此外，研究还揭示了MLP激活空间中的分层结构，表明SNMF是分析LLM内部概念表示的有效工具。

> **摘要翻译:** 机械可解释性的核心目标是识别大型语言模型（LLMs）中能够因果解释其输出的正确分析单元。早期工作侧重于单个神经元，但神经元通常编码多个概念的证据促使人们转向分析激活空间中的方向。一个关键问题是如何以无监督的方式找到捕捉可解释特征的方向。当前方法依赖于使用稀疏自编码器（SAE）的字典学习，通常在残差流激活上训练以从头开始学习方向。然而，SAE在因果评估中常常表现不佳，并且缺乏内在可解释性，因为它们的学习与模型的计算没有明确关联。本文通过半非负矩阵分解（SNMF）直接分解MLP激活来解决这些局限性，使得学习到的特征（a）是共激活神经元的稀疏线性组合，并且（b）映射到它们的激活输入，从而使其直接可解释。在Llama 3.1、Gemma 2和GPT-2上的实验表明，SNMF导出的特征在因果操控方面优于SAE和一个强大的有监督基线（均值差），同时与人类可解释的概念对齐。进一步分析揭示，特定的神经元组合在语义相关的特征中被重用，暴露出MLP激活空间中的分层结构。总而言之，这些结果将SNMF定位为识别可解释特征和剖析LLMs中概念表示的简单有效工具。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [461] [Dynamic Epistemic Friction in Dialogue](https://arxiv.org/abs/2506.10934)
> *对话中的动态认知摩擦*

*Timothy Obiso, Kenneth Lai, Abhijnan Nath, Nikhil Krishnaswamy, James Pustejovsky* | **Main category: cs.CL**

**Keywords:** 认知摩擦, 大型语言模型, 对话, 信念更新, 动态认知逻辑

**Comment:** 11 pages, 2 figures, 2 tables, CoNLL 2025

> **TL;DR:** 本文引入并定义了“动态认知摩擦”的概念，解释了在对话中LLMs更新信念时遇到的阻力，并展示了其在预测信念更新中的有效性。

**AI_Comments:** 这篇论文的创新点在于引入并形式化了“动态认知摩擦”这一关键概念，填补了LLMs在信念更新过程中考虑阻力的空白。将其置于动态认知逻辑框架下，为理解和预测对话中的信念修正提供了新的理论视角和实用模型。这对于提升LLMs在复杂、动态人机交互中的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在人机协作中表现出色，但现有方法常忽略“认知摩擦”——即在接收到新的、冲突或模糊信息时更新信念所遇到的固有阻力。本文旨在解决这一问题。

**Method:** 本文定义了动态认知摩擦为认知整合的阻力，其特征是代理当前信念状态与外部证据支持的新命题之间的不一致。研究将其置于动态认知逻辑框架内，其中摩擦表现为交互过程中非平凡的信念修正。通过对情境化协作任务的分析来验证了该模型。

**Result:** 该认知摩擦模型能有效预测对话中的信念更新。

**Conclusion:** 将信念对齐作为认知阻力或摩擦的衡量标准，可以自然地变得更加复杂，以适应现实世界对话场景的复杂性。

> **ai_Abstract:** 本文提出了“动态认知摩擦”的概念，将其定义为代理在对话中整合新信息时遇到的信念更新阻力。该概念被置于动态认知逻辑框架内，并通过协作任务的分析验证了其在预测对话中信念更新的有效性。研究指出，将信念对齐作为认知阻力的一种衡量方式，有助于更精细地处理真实世界对话的复杂性。

> **摘要翻译:** **标题**：对话中的动态认知摩擦

**摘要**：近期在使大型语言模型（LLMs）与人类偏好对齐方面的进展显著增强了它们在人机协作场景中的实用性。然而，这些方法常常忽视“认知摩擦”的关键作用，即在响应新的、冲突的或模糊的信息时更新信念所遇到的固有阻力。在本文中，我们将动态认知摩擦定义为认知整合的阻力，其特征是代理当前信念状态与外部证据支持的新命题之间的不一致。我们将此置于动态认知逻辑（Van Benthem and Pacuit, 2011）的框架内，其中摩擦表现为交互过程中非平凡的信念修正。随后，我们展示了来自情境化协作任务的分析，这些分析表明该认知摩擦模型如何能有效预测对话中的信念更新，并且我们随后讨论了如何自然地使信念对齐作为认知阻力或摩擦的衡量标准变得更加复杂，以适应现实世界对话场景的复杂性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [463] [Domain2Vec: Vectorizing Datasets to Find the Optimal Data Mixture without Training](https://arxiv.org/abs/2506.10952)
> *Domain2Vec：向量化数据集以无需训练即可找到最优数据混合*

*Mozhi Zhang, Howe Tissue, Lu Wang, Xipeng Qiu* | **Main category: cs.CL**

**Keywords:** Domain2Vec, 数据混合, 元域, 语言模型预训练, 无训练

**Comment:** Accepted to ICML2025

> **TL;DR:** Domain2Vec 是一种无需训练即可向量化数据集以找到最优数据混合的新方法，能显著减少计算并提升性能。

**AI_Comments:** Domain2Vec 的创新之处在于引入了“元域”的概念，并提出了一种无需训练即可优化数据混合的方法，这对于语言模型预训练具有重大意义。它显著降低了计算成本并提升了性能，解决了大规模模型训练中的一个关键挑战，展现出强大的实用价值和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 寻找语言模型预训练的最优数据混合通常需要大量计算，Domain2Vec 旨在提供一种无需训练的解决方案。

**Method:** Domain2Vec 将数据集分解为元域的线性组合，元域是捕获数据集关键底层特征的新概念。它维护一个元域词汇表，并使用分类器将任何给定数据集分解为对应于该词汇表分布的域向量。这些域向量在分布对齐假设（DA^2）下，能够以无需训练的方式识别语言模型预训练的最优数据混合。此外，Domain2Vec 可以与现有工作集成，以建模域向量与语言模型性能之间的关系。

**Result:** Domain2Vec 能够以最小的计算开销找到增强下游任务性能的数据混合。具体而言，在 Pile-CC 上，它仅使用原始数据混合训练所需计算量的 51.5% 即可达到相同的验证损失。在同等计算预算下，Domain2Vec 将下游性能平均提高了 2.83%。

**Conclusion:** Domain2Vec 是一种有效且高效的方法，用于优化语言模型预训练的数据混合，显著降低计算成本并提高性能。

> **ai_Abstract:** Domain2Vec 是一种新颖的无需训练的方法，它将数据集向量化为“元域”，以找到语言模型预训练的最优数据混合。它将数据集分解为表示元域分布的域向量，并利用分布对齐假设（DA^2）来实现更低的验证损失。该方法显著降低了计算开销，在实现相同验证损失的情况下，计算量减少了 51.5%，下游性能平均提高了 2.83%，同时还可以与现有方法集成以提高效率和可扩展性。

> **摘要翻译:** 我们引入了~	extsc{Domain2Vec}，这是一种新颖的方法，它将任何数据集分解为几个元域的线性组合，元域是一个旨在捕获数据集关键底层特征的新概念。	extsc{Domain2Vec} 维护一个元域词汇表，并使用分类器将任何给定数据集分解为一个域向量，该向量对应于此词汇表上的分布。这些域向量在“分布对齐假设”（DA²）下，能够以无需训练的方式识别语言模型（LM）预训练的最优数据混合，该假设表明当训练集和验证集的数据分布更好地对齐时，可以实现更低的验证损失。此外，	extsc{Domain2vec} 可以无缝集成到以前的工作中，以建模域向量与 LM 性能之间的关系，极大地提高了以前方法的效率和可扩展性。大量的实验表明，	extsc{Domain2Vec} 有助于找到能够以最小计算开销增强下游任务性能的数据混合。具体而言，	extsc{Domain2Vec} 在 Pile-CC 上达到了相同的验证损失，而所需的计算量仅为在 The Pile 数据集原始混合上训练时所需计算量的 51.5%。在同等计算预算下，	extsc{Domain2Vec} 将下游性能平均提高了 2.83%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [468] [How Well Can Reasoning Models Identify and Recover from Unhelpful Thoughts?](https://arxiv.org/abs/2506.10979)
> *推理模型识别和纠正无益思维的能力如何？*

*Sohee Yang, Sang-Woo Lee, Nora Kassner, Daniela Gottesman, Sebastian Riedel, Mor Geva* | **Main category: cs.CL**

**Keywords:** 推理模型, 自我评估, 无益思维, 元认知, 反向扩展

**Comment:** 

> **TL;DR:** 推理模型能够识别无益思维，但在这些思维被注入其思考过程时，它们难以从中恢复，导致性能显著下降，且大型模型在此方面表现出反向扩展趋势，揭示了其自我评估能力的局限性。

**AI_Comments:** 这篇论文揭示了当前推理模型在“元认知”能力上的一个关键局限性：尽管它们可以识别无益思维，但一旦这些思维被强行植入，模型便难以有效纠正，反而会盲目沿用。其中，大型模型在恢复能力上表现出的“反向扩展”趋势尤为重要且出人意料，挑战了“越大越好”的直觉。越狱实验进一步强调了这种缺陷对系统安全的影响。这项工作对于推动AI系统在鲁棒性和安全性方面的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 近期推理模型展现出反思、回溯和自我验证推理的能力，这对于发现错误和得出准确解决方案至关重要。因此，一个自然而然的问题是模型能多有效地进行这种自我重新评估。

**Method:** 本研究通过调查推理模型如何有效识别和纠正四种无益思维来解决这一问题：无信息量的冗长思维、与问题无关的思维、将问题误导为略有不同问题的思维，以及导致错误答案的思维。研究通过将这些思维注入模型的思考过程来评估其表现。

**Result:** 研究表明，模型在识别大多数无益思维方面是有效的，但当这些思维被注入其思考过程时，模型难以从中恢复，导致性能显著下降。模型倾向于天真地延续被注入的无关思维的推理路线，这表明其自我评估能力远非普遍的“元认知”意识。此外，研究观察到非/反向扩展趋势，即大型模型在纠正短无关思维方面比小型模型更困难，即使被指示重新评估其推理。研究通过使用无关思维注入的越狱实验证明了这些发现的影响，显示最小的模型最不受触发有害响应的思维干扰。

**Conclusion:** 总的来说，我们的发现呼吁改进推理模型的自我评估能力，以开发更好的推理和更安全的系统。

> **ai_Abstract:** 本研究探讨了推理模型识别和纠正无益思维的能力。尽管模型能有效识别大多数无益思维，但当这些思维被注入其思考过程时，它们难以恢复，导致性能显著下降。研究发现模型倾向于延续被注入的无关思维，且大型模型在恢复能力上甚至表现出反向扩展趋势。这些发现揭示了当前推理模型自我评估能力的局限性，并强调了在开发更强大和安全的人工智能系统方面改进其元认知能力的重要性。

> **摘要翻译:** 最近的推理模型展示了反思、回溯和自我验证其推理的能力，这对于发现错误和得出准确的准确解决方案至关重要。一个自然而然的问题是模型能多有效地执行这种自我重新评估。我们通过调查推理模型如何有效地识别和纠正四种无益思维来解决这个问题：无信息量的冗长思维、与问题无关的思维、将问题误导为略有不同问题的思维，以及导致错误答案的思维。我们发现模型在识别大多数无益思维方面是有效的，但当这些思维被注入其思考过程时，它们难以从中恢复，导致性能显著下降。模型倾向于天真地延续被注入的无关思维的推理路线，这表明它们的自我重新评估能力远非普遍的“元认知”意识。此外，我们观察到非/反向扩展趋势，即大型模型在纠正短无关思维方面比小型模型更困难，即使被指示重新评估其推理。我们通过使用无关思维注入的越狱实验证明了这些发现的影响，显示最小的模型最不受触发有害响应的思维干扰。总的来说，我们的发现呼吁改进推理模型的自我重新评估能力，以开发更好的推理和更安全的系统。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [22] [New Approximation Guarantees for The Inventory Staggering Problem](https://arxiv.org/abs/2506.10339)
> *库存交错问题的新近似保证*

*Noga Alon, Danny Segev* | **Main category: cs.DS**

**Keywords:** 库存交错, 近似保证, 算法技术, 组合学, 数论

**Comment:** 

> **TL;DR:** 本文通过新颖的算法技术和分析思想，显著改进了库存交错问题的近似保证，解决了悬而未决的问题，并揭示了该问题的全局特性。

**AI_Comments:** 本文通过显著提高库存交错问题的近似保证，做出了重要贡献，这对实际应用至关重要。其创新性地利用组合学和数论概念，以及发现问题特有的结构特性，都值得关注。关于问题全局性质的发现为理解该问题增添了新的维度。

<details>
  <summary>Details</summary>

**Motivation:** 库存交错问题自20世纪60年代中期以来在生产计划、库存控制、仓储和航空航天/国防物流等多个应用领域得到了广泛探索和利用。然而，尽管有丰富的学术关注历史，但在库存交错问题的核心计算问题及相关结构特征方面，我们仍然知之甚少，现有方法论工具严重不足。

**Method:** 本文的核心贡献在于设计了一系列算法技术和分析思想，其中一些是全新的，另一些则利用了组合学和数论中已深入研究的概念，以超越库存交错问题几乎所有已知的近似保证。具体而言，工作展示了许多结构特性为设计多项式时间近似方案提供了可能性，包括多项式有界循环长度、恒定数量的不同时间间隔、所谓的嵌套实例以及成对互质设置。同时，本文还围绕一些尚未探索的问题开发了新理论，涉及峰值库存估计的采样复杂性以及群组同步的可行性。

**Result:** 本文的工作超越了库存交错问题几乎所有已知的近似保证。研究表明，许多结构特性（如多项式有界循环长度、恒定数量的不同时间间隔、嵌套实例和成对互质设置）为设计多项式时间近似方案提供了可能性。这些发现对现有常数因子近似值提供了实质性改进，并解决了各自领域中悬而未决的开放问题。此外，本文建立了库存交错问题的全局性质，证明了存在n个项目的实例，其中对于大约√n个项目的每个子集，没有策略能比最差策略改进超过1+ε的因子，而对于整个实例，存在一个策略能比最差策略改进近2倍，这是最优的。

**Conclusion:** 本文通过提供改进的近似保证和解决长期存在的开放问题，在库存交错问题的计算理解方面取得了重大突破，并揭示了该问题的全局特性。

> **ai_Abstract:** 本文解决了库存交错问题，这是一个被广泛研究但计算上仍未充分探索的领域。它引入了新颖的算法和分析技术，显著改善了现有近似保证，使得针对各种结构特性能够设计多项式时间近似方案。这项研究解决了若干开放问题，并揭示了库存交错问题的全局性质，即最优策略可能需要全局视角而非局部视角。

> **摘要翻译:** 自20世纪60年代中期诞生以来，库存交错问题已在生产计划、库存控制系统、仓储以及航空航天/国防物流等广泛应用领域得到了探索和利用。然而，即使有着丰富的学术关注历史，在库存交错问题及其相关结构特征的核心计算问题上，我们仍然知之甚少，我们的方法论工具箱严重不足。本文的核心贡献在于设计了一系列算法技术和分析思想——其中一些是全新的，另一些则利用了组合学和数论中已深入研究的概念——以超越库存交错问题几乎所有已知的近似保证。特别是，我们的工作表明，许多结构特性为设计多项式时间近似方案打开了大门，包括多项式有界循环长度、恒定数量的不同时间间隔、所谓的嵌套实例以及成对互质设置。这些发现对目前可用的常数因子近似值提供了实质性改进，并解决了各自背景下悬而未决的开放问题。同时，我们围绕一些尚未探索的问题开发了新理论，这些问题与峰值库存估计的采样复杂性以及群组同步的可行性有关。有趣的是，我们确立了库存交错问题的全局性质，证明了存在n个项目的实例，其中对于大约√n个项目的每个子集，没有策略能比最差策略改进超过1+ε的因子，而对于整个实例，存在一个策略能比最差策略改进近2倍，这是最优的。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [49] [Structural Parameterizations of $k$-Planarity](https://arxiv.org/abs/2506.10717)
> *k-平面性的结构参数化*

*Tatsuya Gima, Yasuaki Kobayashi, Yuto Okada* | **Main category: cs.DS**

**Keywords:** k-平面性, 参数化复杂性, 局部交叉数, 树深, 反馈顶点集

**Comment:** 20 pages, 9 figures

> **TL;DR:** 本文研究了 $k$-平面性（$k 	ext{ ≥ } 1$）的参数化复杂性，提供了紧密的参数化上下界结果，并针对特定图类强化了先前的难解性结论。

**AI_Comments:** 本文的创新之处在于将 $k$-平面性的结构参数化研究推广到了一般 $k 	ext{ ≥ } 1$ 的情况，并提供了紧密的参数化上下界。其重要性在于，通过强化现有下界，它揭示了即使在图具有强结构约束（例如常数树宽）的情况下， $k$-平面性问题在计算上仍然具有固有难度。这为理解图绘制问题的计算边界提供了更深入的见解，并可能指导未来算法设计中对参数选择的考量。

<details>
  <summary>Details</summary>

**Motivation:** 确定图是否为 $k$-平面以及近似局部交叉数的问题在计算上是难解的（NP-完全且难以近似）。为了解决这种计算上的难处理性，先前的研究针对 $k=1$ 的情况探讨了基于输入图结构参数化的方法。本文旨在将这种方法推广到一般的 $k 	ext{ ≥ } 1$。

**Method:** 本文将Bannister、Cabello和Eppstein（2018）针对 $k=1$ 的结构参数化方法推广到一般情况 $k 	ext{ ≥ } 1$。通过考虑不同的图结构参数，作者给出了（紧密的）参数化上界和下界结果。此外，他们还将先前关于难解性的下界结果推广并强化到常数树宽图的子类上。

**Result:** 本文给出了针对 $k 	ext{ ≥ } 1$ 的 $k$-平面性的（紧密的）参数化上界和下界结果。具体而言，他们强化了先前的下界结果：即使对于反馈顶点集数至多为3且路径宽度至多为4的近平面图，测试1-平面性仍然是NP-完全的；对于反馈顶点集数至多为2的图，局部交叉数在任意常数因子内都难以近似。

**Conclusion:** 本文为 $k$-平面性（针对一般 $k 	ext{ ≥ } 1$）建立了新的（且紧密的）参数化复杂性界限，进一步揭示了即使对于高度结构化的图类，该问题在计算上仍然是困难的。

> **ai_Abstract:** 本文研究了图的 $k$-平面性（即每条边最多被交叉 $k$ 次的平面绘制）的参数化复杂性，该问题因其NP-完全性和难以近似性而具有计算挑战性。在扩展先前针对 $k=1$ 的结构参数化工作的基础上，本研究为一般 $k 	ext{ ≥ } 1$ 的情况提供了（紧密的）参数化上界和下界结果。值得注意的是，研究强化了现有下界，证明了即使对于具有特定结构约束（如小的反馈顶点集数和路径宽度）的近平面图，测试 $1$-平面性仍然是NP-完全的，并且局部交叉数难以近似。

> **摘要翻译:** k-平面性的结构参数化

k-平面性的概念在“超越平面性”的背景下得到了广泛研究。一个图是k-平面的，如果它允许在平面上绘制，使得每条边最多被交叉k次。图的局部交叉数是使其成为k-平面的最小整数k。即使对于近平面图（即通过添加一条边从平面图获得的图），确定输入图是否为1-平面图的问题也已知是NP-完全的[Cabello和Mohar，SIAM J. Comput. 2013]。此外，对于任何 ε > 0，局部交叉数在2 - ε因子内都难以近似[Urschel和Wellens，IPL 2021]。为了解决这种计算上的难处理性，Bannister、Cabello和Eppstein[JGAA 2018]研究了k=1情况的参数化复杂性，特别关注输入图的结构参数化，例如树深、顶点覆盖数和反馈边数。在本文中，我们通过考虑一般情况k ≥ 1来扩展他们的方法，并给出（紧密的）参数化上界和下界结果。特别是，我们将上述下界结果强化到常数树宽图的子类：我们表明，即使对于反馈顶点集数至多为3且路径宽度至多为4的近平面图，测试1-平面性仍然是NP-完全的；对于反馈顶点集数至多为2的图，局部交叉数在任意常数因子内都难以近似。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [74] [Faster CONGEST Approximation Algorithms for Maximum Weighted Independent Set in Sparse Graphs](https://arxiv.org/abs/2506.10845)
> *稀疏图中最大加权独立集的更快CONGEST近似算法*

*Salwa Faour, Fabian Kuhn* | **Main category: cs.DS**

**Keywords:** 最大加权独立集, 分布式算法, CONGEST模型, 稀疏图, 近似算法

**Comment:** 23 pages

> **TL;DR:** 该论文为树和有界非循环度图中的最大加权独立集（MWIS）问题提出了更快的确定性CONGEST近似算法，为树提供了紧密的复杂度，并为有界非循环度图改进了近似比和轮次复杂度。

**AI_Comments:** 该论文在分布式最大加权独立集算法领域做出了重要贡献，特别是在稀疏图方面。其创新之处在于为树实现了紧密的复杂度界限，并为有界非循环度图提供了改进的近似比和轮次复杂度，超越了现有成果。局部舍入框架的应用和新算法的开发展示了CONGEST模型下强大的理论进步。

<details>
  <summary>Details</summary>

**Motivation:** 最大独立集问题是一个经典的优化问题，在分布式环境中得到了广泛研究，但通常难以近似。本文旨在为稀疏图族（树和有界非循环度图）中的加权最大独立集问题提供改进的近似算法。

**Method:** 本文研究确定性分布式CONGEST算法。对于树，证明了$(1-\epsilon)$-近似解的紧密复杂度。对于非循环度$\beta>1$的图，提供了两种算法：一种通过直接应用局部舍入框架实现近似，另一种则改进了现有结果。此外，还设计了一个中间算法来计算基于节点权重和度的独立集。

**Result:** 对于树，确定性计算最大加权独立集（MWIS）问题的$(1-\epsilon)$-近似解具有紧密的$\Theta(\log^*(n) / \epsilon)$复杂度。对于非循环度$\beta>1$的图，第一种算法能在$O(\log^2(\beta/\epsilon)/\epsilon + \log^* n)$轮内计算出权重至少为$(1-\epsilon)\cdot \frac{w(V)}{4\beta}$的独立集；第二种算法能在$O(\log^3(\beta)\cdot\log(1/\epsilon)/\epsilon^2 \cdot\log n)$轮内计算出权重至少为$(1-\epsilon)\cdot\frac{w(V)}{2\beta+1}$的独立集，这改进了现有结果。作为中间步骤，还设计了一种算法，用于在$O(\log^3(\Delta)\cdot\log(1/\epsilon)/\epsilon + \log^* n)$时间内计算总权重至少为$(1-\epsilon)\cdot\sum_{v\in V}\frac{w(v)}{deg(v)+1}$的独立集。

**Conclusion:** 本文为树和有界非循环度图中的最大加权独立集问题提供了更快和改进的近似算法，建立了树的紧密复杂度下限，并为有界非循环度图提供了更好的近似比和轮次复杂度。

> **ai_Abstract:** 本文提出了针对稀疏图中最大加权独立集（MWIS）问题的更快确定性分布式CONGEST算法。对于树，它建立了$(1-\epsilon)$-近似的紧密$\Theta(\log^*(n) / \epsilon)$复杂度。对于具有有界非循环度$\beta$的图，论文提供了两种算法：一种利用局部舍入框架在$O(\log^2(\beta/\epsilon)/\epsilon + \log^* n)$轮内实现了$(1-\epsilon)\cdot \frac{w(V)}{4\beta}$近似；另一种则将近似比提高到$(1-\epsilon)\cdot\frac{w(V)}{2\beta+1}$，轮次复杂度为$O(\log^3(\beta)\cdot\log(1/\epsilon)/\epsilon^2 \cdot\log n)$，优于现有工作。此外，还提出了一个基于节点权重和度的中间独立集算法。

> **摘要翻译:** 最大独立集问题是一个经典的优化问题，在分布式环境中也得到了相当深入的研究。虽然该问题通常难以近似，但对于一些稀疏图族，已有一些好的近似算法。在本文中，我们考虑了树和有界非循环度图（arboricity）中该问题加权版本的确定性分布式CONGEST算法。
对于树，我们证明了确定性计算最大加权独立集（MWIS）问题的$(1-\epsilon)$-近似解具有紧密的$\Theta(\log^*(n) / \epsilon)$复杂度。下界已经在无权有向路径上成立。在上界方面，我们表明即使在无根树中也能达到该界限。
对于非循环度$\beta>1$的图$G=(V,E)$，我们提供了两种算法。如果所有节点权重的总和为$w(V)$，我们表明对于任何$\epsilon>0$，可以在$O(\log^2(\beta/\epsilon)/\epsilon + \log^* n)$轮内计算出权重至少为$(1-\epsilon)\cdot \frac{w(V)}{4\beta}$的独立集。这个结果是通过直接应用Faour, Ghaffari, Grunau, Kuhn和Rozho\v{n} [SODA '23]的局部舍入框架获得的。我们进一步表明，对于任何$\epsilon>0$，可以在$O(\log^3(\beta)\cdot\log(1/\epsilon)/\epsilon^2 \cdot\log n)$轮内计算出权重至少为$(1-\epsilon)\cdot\frac{w(V)}{2\beta+1}$的独立集。这改进了Gil [OPODIS '23]最近的结果，他表明MWIS问题的$1/\lfloor(2+\epsilon)\beta\rfloor$-近似可以在$O(\beta\cdot\log n)$轮内计算。作为中间步骤，我们设计了一种算法，用于在$O(\log^3(\Delta)\cdot\log(1/\epsilon)/\epsilon + \log^* n)$时间内计算总权重至少为$(1-\epsilon)\cdot\sum_{v\in V}\frac{w(v)}{deg(v)+1}$的独立集，其中$\Delta$是图的最大度。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [24] [Learning-based density-equalizing map](https://arxiv.org/abs/2506.10027)
> *基于学习的密度均衡映射*

*Yanwen Huang, Lok Ming Lui, Gary P. T. Choi* | **Main category: cs.GR**

**Keywords:** 密度均衡映射, 深度学习, 神经网络, 几何处理, 数据可视化

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于深度学习的密度均衡映射框架（LDEM），解决了传统方法在准确性、重叠伪影以及从2D到3D扩展方面的局限性，并展示了优越的性能和泛化能力。

**AI_Comments:** 本文的创新之处在于将深度学习应用于密度均衡映射，成功解决了传统方法长期存在的精度限制、重叠伪影以及2D到3D扩展困难等问题。特别是其从2D到3D的无缝泛化能力，以及在精度和双射性方面的显著提升，极大地扩展了密度均衡映射在实际应用中的潜力和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的密度均衡映射（DEM）方法主要依赖迭代数值求解器或基于优化的方法，但存在准确性有限、在极端情况下产生重叠伪影以及由于能量公式的导数依赖性导致从2D到3D扩展需要大量算法重新设计等挑战。

**Method:** 本文提出了一种新颖的基于学习的密度均衡映射框架（LDEM），利用深度神经网络实现。具体来说，引入了一个强制密度均匀性和几何规律性的损失函数，并采用分层方法预测粗略和密集级别的变换。

**Result:** 与现有方法相比，LDEM在广泛的简单和复杂密度分布下，展示了卓越的密度均衡和双射特性。它可以轻松应用于具有不同效果的表面网格重构，并且无需模型架构或损失公式的结构性改变即可从2D域无缝推广到3D域。

**Conclusion:** 本文的工作为实际应用中密度均衡映射的可扩展和鲁棒计算开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种名为LDEM的新型基于学习的密度均衡映射（DEM）框架，旨在克服传统DEM方法在准确性、重叠问题以及2D到3D泛化方面的局限性。LDEM利用深度神经网络，并引入了一个结合密度均匀性和几何规律性的损失函数，同时采用分层方法进行变换预测。实验结果表明，LDEM在各种密度分布下均表现出优于现有方法的密度均衡和双射特性，并能无缝地从2D推广到3D，为DEM的实际应用提供了可扩展且鲁棒的计算方法。

> **摘要翻译:** 密度均衡映射（DEM）作为一种强大的技术，能够创建形状变形，其面积变化反映了底层的密度函数。近几十年来，DEM已广泛应用于数据可视化、几何处理和医学成像等领域。传统的DEM方法主要依赖于扩散方程的迭代数值求解器或最小化手工设计能量泛函的基于优化方法。然而，这些传统技术常常面临一些挑战：它们可能精度有限，在极端情况下产生重叠伪影，并且由于其能量公式的导数依赖性，从2D扩展到3D时需要大量的算法重新设计。在这项工作中，我们提出了一种新颖的基于学习的密度均衡映射框架（LDEM），使用深度神经网络。具体来说，我们引入了一个强制密度均匀性和几何规律性的损失函数，并利用分层方法预测粗略和密集级别的变换。与现有方法相比，我们的方法在广泛的简单和复杂密度分布下，展示了卓越的密度均衡和双射特性，并且可以轻松应用于具有不同效果的表面网格重构。此外，它无需模型架构或损失公式的结构性改变即可从2D域无缝推广到3D域。总而言之，我们的工作为实际应用中密度均衡映射的可扩展和鲁棒计算开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [51] [FastFLUX: Pruning FLUX with Block-wise Replacement and Sandwich Training](https://arxiv.org/abs/2506.10035)
> *FastFLUX：通过块级替换和三明治训练剪枝FLUX*

*Fuhan Cai, Yong Guo, Jie Li, Wenbo Li, Xiangzhong Fang, Jian Chen* | **Main category: cs.GR**

**Keywords:** 文本到图像生成, 扩散模型, 模型剪枝, 模型加速, FLUX

**Comment:** 14 pages

> **TL;DR:** 提出FastFLUX，一个通过块级替换和三明治训练来加速FLUX扩散模型推理的剪枝框架，同时保持图像质量。

**AI_Comments:** FastFLUX的创新之处在于其结合了架构级剪枝（BRLL）和精细化训练策略（ST），特别是三明治训练利用LoRA进行局部监督，有效解决了结构性剪枝可能带来的性能下降问题。这种方法为大型T2I模型的部署提供了新的思路，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像生成模型（如FLUX）参数量大，导致推理慢、内存占用高、部署困难。现有加速方法（如单步蒸馏和注意力剪枝）常导致性能显著下降且训练成本高。

**Method:** 提出FastFLUX，一个架构级剪枝框架。核心是“块级线性层替换 (BRLL)”方法，用轻量级线性层替换残差块中结构复杂的残差分支，同时保留原始捷径连接以保持稳定性。此外，引入“三明治训练 (ST)”，一种利用LoRA监督相邻块的局部微调策略，以减轻结构替换导致的性能下降。

**Result:** 实验表明，FastFLUX在定性和定量评估下均保持高图像质量，即使剪枝了20%的层级，也能显著提高推理速度。

**Conclusion:** FastFLUX通过其创新的剪枝和训练策略，有效解决了大型扩散模型推理效率低的问题，实现了速度提升而无显著性能损失。

> **ai_Abstract:** 本文提出了FastFLUX，一个针对大型文本到图像扩散模型FLUX的架构级剪枝框架，旨在解决其推理速度慢和资源消耗大的问题。FastFLUX引入了块级线性层替换（BRLL）方法，用轻量级线性层替代复杂的残差分支，并结合三明治训练（ST）策略，利用LoRA进行局部微调以缓解性能下降。实验结果表明，即使在20%的层级被剪枝的情况下，FastFLUX也能在显著提升推理速度的同时保持高图像质量。

> **摘要翻译:** 近年来，文本到图像（T2I）生成技术的进步催生了像扩散Transformer（DiTs）这样表现力极强的模型，其中FLUX就是典型代表。然而，它们庞大的参数量导致推理缓慢、内存占用高以及部署困难。现有的加速方法（例如单步蒸馏和注意力剪枝）通常会遭受显著的性能下降并产生高昂的训练成本。为了解决这些限制，我们提出了FastFLUX，一个旨在提高FLUX推理效率的架构级剪枝框架。其核心是“块级线性层替换（BRLL）”方法，该方法用轻量级线性层替换残差块中结构复杂的残差分支，同时保留原始的快捷连接以保持稳定性。此外，我们引入了“三明治训练（ST）”，这是一种利用LoRA监督相邻块的局部微调策略，以减轻结构替换引起的性能下降。实验表明，我们的FastFLUX在定性和定量评估下均保持了高图像质量，即使在剪枝了20%的层级后，也能显著提高推理速度。我们的代码即将可用。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [76] [Token Perturbation Guidance for Diffusion Models](https://arxiv.org/abs/2506.10036)
> *扩散模型的令牌扰动引导*

*Javad Rajabi, Soroush Mehraban, Seyedmorteza Sadat, Babak Taati* | **Main category: cs.GR**

**Keywords:** 令牌扰动引导, 扩散模型, 分类器自由引导, 无条件生成, 训练无关

**Comment:** 18 pages, 14 figures

> **TL;DR:** 本文提出了一种名为TPG的新型训练无关且条件无关的引导方法，通过直接扰动中间令牌表示来提高扩散模型的生成质量，并能应用于条件和无条件生成。

**AI_Comments:** 该论文提出了一种创新的训练无关且条件无关的引导方法TPG，通过直接操作中间令牌表示来提升扩散模型的性能。其核心创新在于“令牌扰动”和“范数保持洗牌操作”，这使得它无需重新训练模型即可应用，极大地拓展了引导方法的适用范围。TPG能够应用于无条件生成，填补了CFG在此方面的空白，并且在性能上接近甚至超越了现有技术，这对于扩散模型的实际应用具有重要意义。该方法的通用性和易用性是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有分类器自由引导（CFG）虽然能提升生成质量和对齐，但需要特定的训练过程且仅限于条件生成。为了解决这些限制，本文提出了TPG。

**Method:** 本文提出了令牌扰动引导（TPG），一种将扰动矩阵直接应用于扩散网络中中间令牌表示的新方法。TPG采用范数保持洗牌操作，提供有效且稳定的引导信号，无需架构更改即可提高生成质量。因此，TPG是训练无关的，并且与输入条件无关，使其适用于条件和无条件生成。

**Result:** 实验结果表明，TPG在无条件生成方面，SDXL上的FID比基线提高了近2倍，同时在提示对齐方面与CFG非常接近。

**Conclusion:** TPG被确立为一种通用的、条件无关的引导方法，能够为更广泛的扩散模型带来类似CFG的益处。

> **ai_Abstract:** 本文提出了一种名为令牌扰动引导（TPG）的新型方法，旨在克服传统分类器自由引导（CFG）在训练要求和条件限制上的不足。TPG通过在扩散模型内部直接对中间令牌表示应用范数保持的扰动矩阵来提供引导信号，从而在不改变模型架构的情况下提高生成质量。这种方法是训练无关且与输入条件无关的，使其能够广泛应用于条件和无条件生成。实验证明，TPG在无条件生成上显著提升了性能，并在提示对齐上与CFG表现相当，表明其能够为多种扩散模型带来类似CFG的优势。

> **摘要翻译:** 分类器自由引导（CFG）已成为现代扩散模型中增强生成质量和与输入条件对齐的重要组成部分。然而，CFG需要特定的训练过程，并且仅限于条件生成。为了解决这些限制，我们提出了令牌扰动引导（TPG），一种将扰动矩阵直接应用于扩散网络中中间令牌表示的新方法。TPG采用范数保持洗牌操作，提供有效且稳定的引导信号，无需架构更改即可提高生成质量。因此，TPG是训练无关的，并且与输入条件无关，使其适用于条件和无条件生成。我们进一步分析了TPG提供的引导项，并表明其对采样的影响与现有训练无关的引导技术相比更接近CFG。在SDXL和Stable Diffusion 2.1上的大量实验表明，TPG在无条件生成方面，SDXL上的FID比基线提高了近2倍，同时在提示对齐方面与CFG非常接近。这些结果确立了TPG作为一种通用的、条件无关的引导方法，能够为更广泛的扩散模型带来类似CFG的益处。代码可在https://github.com/TaatiTeam/Token-Perturbation-Guidance获取。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [102] [Ambient Diffusion Omni: Training Good Models with Bad Data](https://arxiv.org/abs/2506.10038)
> *环境扩散全能：用坏数据训练好模型*

*Giannis Daras, Adrian Rodriguez-Munoz, Adam Klivans, Antonio Torralba, Constantinos Daskalakis* | **Main category: cs.GR**

**Keywords:** 扩散模型, 低质量数据, Ambient Diffusion Omni, 图像生成, 数据增强

**Comment:** Preprint, work in progress

> **TL;DR:** Ambient Diffusion Omni框架利用低质量、合成和分布外图像来显著提升扩散模型的性能，通过利用图像的频谱幂律衰减和局部性特性，实现了更好的图像质量和多样性。

**AI_Comments:** 该论文的创新之处在于挑战了传统扩散模型对高质量、策展数据的高度依赖，并提出了一种有效利用低质量甚至“坏数据”来提升模型性能的新范式。通过利用图像的内在特性（频谱幂律衰减和局部性）和对噪声作用的深刻理解，实现了在数据利用效率和模型性能上的显著突破。这对于数据获取成本高昂或数据量有限的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型通常依赖于高度筛选的优质数据集进行训练，导致大量低质量但有价值的图像被丢弃。本文旨在证明并利用这些低质量图像的巨大价值，以改善扩散模型的训练。

**Method:** 本文提出了Ambient Diffusion Omni框架，一个简单且有原则性的方法，用于训练扩散模型，使其能够从所有可用图像中提取信号。该框架利用了自然图像的两个特性：频谱幂律衰减和局部性。核心洞察是噪声可以抑制期望高质量分布与实际观察到的混合分布之间的初始偏差。

**Result:** 该框架成功地使用高斯模糊、JPEG压缩和运动模糊合成损坏的图像训练了扩散模型。在使用该框架后，ImageNet FID达到了最先进水平，并且显著提高了文本到图像生成模型的图像质量和多样性。

**Conclusion:** 噪声能够抑制期望高质量分布与实际观察到的混合分布之间的初始偏差，这是利用低质量数据训练扩散模型的关键洞察。该方法在理论上具有严格的合理性，通过分析学习有偏数据与有限无偏数据在不同扩散时间下的权衡。

> **ai_Abstract:** 本文提出Ambient Diffusion Omni框架，旨在利用低质量、合成及分布外图像来提升扩散模型的性能。该框架通过利用自然图像的频谱幂律衰减和局部性特性，能够从所有可用图像中提取有效信号。研究表明，利用合成损坏图像可成功训练模型，并在ImageNet FID和文本到图像生成质量多样性方面取得显著提升。核心洞察在于噪声能抑制高质量与混合分布间的初始偏差，并提供了严格的理论分析。

> **摘要翻译:** 我们展示了如何使用低质量、合成和分布外图像来提高扩散模型的质量。通常，扩散模型是在从网络和其他来源高度过滤的数据池中整理出的数据集上训练的。我们表明，那些经常被丢弃的较低质量图像具有巨大的价值。我们提出了Ambient Diffusion Omni，一个简单、有原则的框架，用于训练扩散模型，可以在训练过程中从所有可用图像中提取信号。我们的框架利用了自然图像的两个特性——频谱幂律衰减和局部性。我们首先通过成功地使用高斯模糊、JPEG压缩和运动模糊合成损坏的图像来训练扩散模型，从而验证了我们的框架。然后，我们使用我们的框架实现了最先进的ImageNet FID，并且在文本到图像生成模型中显示了图像质量和多样性的显著改进。核心洞察是噪声抑制了期望的高质量分布与我们实际观察到的混合分布之间的初始偏差。我们通过分析在不同扩散时间下从有偏数据学习与从有限无偏数据学习之间的权衡，为我们的方法提供了严格的理论依据。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [125] [Low-Barrier Dataset Collection with Real Human Body for Interactive Per-Garment Virtual Try-On](https://arxiv.org/abs/2506.10468)
> *使用真实人体进行交互式逐件虚拟试穿的低门槛数据集收集*

*Zaiqiang Wu, Yechen Li, Jingyuan Liu, Yuki Shibata, Takayuki Hori, I-Chao Shen, Takeo Igarashi* | **Main category: cs.GR**

**Keywords:** 虚拟试穿, 数据集收集, 真实人体, DensePose, 服装对齐

**Comment:** 

> **TL;DR:** 现有虚拟试穿方法受限于昂贵的机器人模特和对齐问题。本文提出一种使用真实人体进行低门槛数据集收集的方法，并引入混合表示以实现更好的对齐和交互。

**AI_Comments:** 该论文通过消除对昂贵机器人模特的依赖，为虚拟试穿技术提供了一个更具成本效益和实用性的数据收集方案，显著降低了技术部署的门槛。其引入的混合人物表示，在无需定制硬件的情况下提升了服装对齐精度和交互性，是该领域的一个重要创新。这项工作对于推动虚拟试穿技术在实际应用中的普及具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于图像的虚拟试穿方法存在局限性，如仅限于正面视图和缺乏实时性。逐件虚拟试穿虽有所改进，但仍面临挑战：1) 用于数据集收集的机器人模特成本高昂且无法准确模拟人体变形；2) 合成服装常与人体未对齐。

**Method:** 提出了一种使用真实人体收集逐件数据集的低门槛方法，无需定制机器人模特。引入了一种混合人物表示，通过简化的DensePose图增强现有中间表示，以确保合成服装图像与人体准确对齐，并实现无需定制可穿戴设备的人衣交互。

**Result:** 定性和定量评估结果表明，与现有最先进的基于图像的虚拟试穿方法相比，本文方法在图像质量和时间一致性方面表现优越。消融研究也证实了这一点。用户研究结果显示，大多数参与者认为该虚拟试穿系统有助于做出服装购买决策。

**Conclusion:** 本文提出的低门槛数据集收集方法和混合人物表示有效解决了虚拟试穿中机器人模特成本高昂和服装对齐不准确的问题，提高了系统的实用性和用户体验，有助于服装购买决策。

> **ai_Abstract:** 本文旨在解决现有虚拟试穿方法中机器人模特成本高昂和服装与人体对齐不准确的问题。作者提出了一种使用真实人体进行低门槛逐件数据集收集的方法，并引入了一种结合简化DensePose图的混合人物表示，以确保合成服装的精确对齐和人衣交互。实验结果表明，该方法在图像质量和时间一致性方面优于现有技术，且用户研究证实了其在服装购买决策中的实用性。

> **摘要翻译:** 现有基于图像的虚拟试穿方法通常局限于正面视图，并且缺乏实时性能。虽然逐件虚拟试穿方法通过捕获逐件数据集和训练逐件神经网络解决了这些问题，但它们仍然遇到实际限制：(1) 用于捕获逐件数据集的机器人模特价格昂贵，难以广泛采用，并且无法准确复制自然的人体变形；(2) 合成的服装经常与人体未对齐。为了解决这些挑战，我们提出了一种使用真实人体收集逐件数据集的低门槛方法，从而消除了对定制机器人模特的需要。我们还引入了一种混合人物表示，通过简化的DensePose图增强了现有的中间表示。这确保了合成服装图像与人体的准确对齐，并实现了人衣交互，而无需定制可穿戴设备。我们对其他最先进的基于图像的虚拟试穿方法进行了定性和定量评估，并进行了消融研究，以证明我们方法在图像质量和时间一致性方面的优越性。最后，我们的用户研究结果表明，大多数参与者认为我们的虚拟试穿系统有助于做出服装购买决策。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [146] [Edit360: 2D Image Edits to 3D Assets from Any Angle](https://arxiv.org/abs/2506.10507)
> *Edit360：从任意角度将2D图像编辑应用于3D资产*

*Junchao Huang, Xinting Hu, Zhuotao Tian, Shaoshuai Shi, Li Jiang* | **Main category: cs.GR**

**Keywords:** 3D编辑, 扩散模型, 多视角一致性, 2D到3D, 视频扩散模型

**Comment:** 11 pages, 9 figures

> **TL;DR:** Edit360是一个无需微调的框架，它利用视频扩散模型，将2D图像编辑扩展到多视角一致的3D资产编辑，允许从任意角度进行用户自定义修改。

**AI_Comments:** 这篇论文的创新点在于提出了一个无需微调的框架Edit360，能够将2D图像编辑能力扩展到多视角一致的3D资产。其核心是利用视频扩散模型和新颖的“锚定视图编辑传播”机制，解决了现有方法在3D编辑中视角受限和多视图一致性难题，极大地提升了3D内容创建的灵活性和可定制性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型在2D图像生成和编辑方面取得了显著进展，但将这些能力扩展到3D资产，特别是需要多视角一致性的精细编辑，仍然具有挑战性。现有方法通常将编辑限制在预设的视角，这严重限制了它们的灵活性和实际应用。

**Method:** 论文引入了Edit360，一个无需微调的框架，将2D修改扩展到多视角一致的3D编辑。它基于视频扩散模型构建，通过选择锚定视图进行2D修改，并将编辑传播到整个360度范围。为了实现这一点，Edit360引入了一种新颖的“锚定视图编辑传播”机制，该机制有效地在扩散模型的潜在空间和注意力空间中对多视图信息进行对齐和合并。

**Result:** Edit360能够实现用户从任意视角的特定编辑，同时确保所有视图的结构连贯性。生成的编辑后的多视图序列有助于重建高质量的3D资产。

**Conclusion:** Edit360成功地将2D图像编辑的能力扩展到多视角一致的3D资产，从而实现了可定制的3D内容创建。

> **ai_Abstract:** Edit360是一个创新的无需微调框架，它解决了将2D图像编辑应用于多视角一致3D资产的挑战。该方法利用视频扩散模型，通过引入“锚定视图编辑传播”机制，允许用户从任意角度对3D对象进行精细编辑，确保跨视图的结构连贯性。最终，Edit360能够生成高质量的3D资产，从而实现灵活的3D内容定制。

> **摘要翻译:** 扩散模型的最新进展显著改善了图像生成和编辑，但将这些能力扩展到3D资产仍然充满挑战，特别是对于需要多视角一致性的精细编辑。现有方法通常将编辑限制在预设的视角，这严重限制了它们的灵活性和实际应用。我们引入了Edit360，一个无需微调的框架，它将2D修改扩展到多视角一致的3D编辑。Edit360基于视频扩散模型构建，能够实现用户从任意视角的特定编辑，同时确保所有视图的结构连贯性。该框架选择锚定视图进行2D修改，并将编辑传播到整个360度范围。为了实现这一点，Edit360引入了一种新颖的“锚定视图编辑传播”机制，该机制有效地在扩散模型的潜在空间和注意力空间中对多视图信息进行对齐和合并。由此产生的编辑后的多视图序列有助于重建高质量的3D资产，从而实现可定制的3D内容创建。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [165] [Transformer IMU Calibrator: Dynamic On-body IMU Calibration for Inertial Motion Capture](https://arxiv.org/abs/2506.10580)
> *Transformer IMU校准器：惯性运动捕捉的动态在体IMU校准*

*Chengxu Zuo, Jiawei Huang, Xiao Jiang, Yuan Yao, Xiangren Shi, Rui Cao, Xinyu Yi, Feng Xu, Shihui Guo, Yipeng Qin* | **Main category: cs.GR**

**Keywords:** 动态校准, IMU, 运动捕捉, Transformer, 稀疏IMU

**Comment:** Accepted by SIGGRAPH 2025 (TOG)

> **TL;DR:** 提出一种基于Transformer的动态IMU校准方法，打破静态假设，实现更精确的惯性运动捕捉。

**AI_Comments:** 本文的创新点在于首次打破了IMU校准中限制性的绝对静态假设，并通过引入Transformer模型实现了动态、实时的校准。这使得IMU能够隐式地投入使用，并首次实现了稀疏IMU的长期准确运动捕捉，极大地扩展了惯性运动捕捉的应用范围，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的IMU校准依赖于限制性的绝对静态假设，这极大地限制了其应用场景。本文旨在打破这一限制，扩展IMU校准的应用范围。

**Method:** 提出一种新颖的动态校准方法，打破了传统的绝对静态假设。该方法基于两个宽松的假设：1）在短时间内矩阵变化可忽略不计；2）在短时间内人体运动/IMU读数具有多样性。利用基于Transformer的模型学习合成数据集中坐标漂移（RG'G）和测量偏移（RBS）矩阵与IMU读数之间的映射。同时，设计了一个基于IMU读数多样性的校准触发器，以确保方法应用前满足第二个假设。

**Result:** 实现了对坐标漂移（RG'G）和测量偏移（RBS）的实时估计。首次实现了隐式IMU校准（即无需明确校准过程即可使用IMU）。首次实现了使用稀疏IMU进行长期、准确的运动捕捉。代码和数据集已公开。

**Conclusion:** 本文提出的Transformer IMU校准器通过实现动态、隐式和长期准确的IMU校准，显著扩展了稀疏惯性运动捕捉系统的应用场景。

> **ai_Abstract:** 本文提出了一种名为Transformer IMU校准器的新型动态校准方法，首次打破了惯性测量单元（IMU）校准中严格的绝对静态假设，从而显著扩展了稀疏惯性运动捕捉系统的应用场景。该方法在两个宽松假设下，利用基于Transformer的模型实时估计坐标漂移和测量偏移，并设计了校准触发器。这使得IMU能够隐式使用，并首次实现了使用稀疏IMU进行长期准确的运动捕捉。

> **摘要翻译:** 在本文中，我们提出了一种用于稀疏惯性运动捕捉系统的新型动态校准方法，这是首次打破IMU校准中限制性的绝对静态假设，即坐标漂移RG'G和测量偏移RBS在整个运动过程中保持不变，从而显著扩展了其应用场景。具体来说，我们在两个放松的假设下实现了RG'G和RBS的实时估计：i) 矩阵在短时间内变化可忽略不计；ii) 在这样的时间窗内，人体运动/IMU读数是多样化的。直观地说，第一个假设减少了候选矩阵的数量，第二个假设提供了多样化的约束，这极大地缩小了解决方案空间，并允许从短时间的IMU读数历史中实时准确估计RG'G和RBS。为了实现这一点，我们创建了配对的RG'G、RBS矩阵和IMU读数的合成数据集，并使用基于Transformer的模型学习它们的映射。我们还设计了一个基于IMU读数多样性的校准触发器，以确保在应用我们的方法之前满足假设ii)。据我们所知，我们是第一个实现隐式IMU校准（即无需明确校准过程即可无缝使用IMU）的，也是第一个使用稀疏IMU实现长期准确运动捕捉的。代码和数据集可在https://github.com/ZuoCX1996/TIC获取。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [25] [Contrastive Matrix Completion with Denoising and Augmented Graph Views for Robust Recommendation](https://arxiv.org/abs/2506.10658)
> *鲁棒推荐的去噪与增强图视图对比矩阵补全*

*Narges Nemati, Mostafa Haghir Chehreghani* | **Main category: cs.IR**

**Keywords:** 矩阵补全, 对比学习, 图神经网络, 推荐系统, 去噪

**Comment:** 30 pages

> **TL;DR:** 本文提出了一种名为MCCL的新方法，通过对比学习和双重图表示（一个去噪，一个通过GVAE）来解决基于GNN的推荐系统中矩阵补全对噪声的敏感性和过拟合问题，显著提高了预测准确性和排名效果。

**AI_Comments:** 该论文提出了一种创新的对比学习框架MCCL，通过双重图视图（去噪与增强）和互学习策略，有效解决了GNN在推荐系统中面临的噪声敏感性和泛化能力差的问题。其亮点在于结合了注意力机制进行去噪和GVAE进行特征对齐，并通过对比学习思想提升模型对噪声的鲁棒性和泛化性，对鲁棒推荐系统研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于图神经网络（GNN）的矩阵补全方法在推荐系统中对噪声或不相关边高度敏感，并且容易过拟合，这限制了它们的泛化能力。

**Method:** 本文提出了一种名为对比学习矩阵补全（MCCL）的新方法。该方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示：第一种通过集成GNN层与注意力机制来强调去噪；第二种通过图变分自编码器（GVAE）获得，用于将特征分布与标准先验对齐。训练过程中采用互学习损失函数逐步协调这些表示，以捕捉共同模式并显著增强模型的泛化能力。

**Result:** 在多个真实世界数据集上的广泛实验表明，该方法不仅提高了预测分数的数值准确性（RMSE提高了0.8%），而且在排名指标上表现更优异（排名指标提高了36%）。

**Conclusion:** 本文提出的MCCL方法通过结合去噪和增强图视图的对比学习，有效解决了传统GNN方法在推荐系统矩阵补全中对噪声的敏感性和泛化能力受限的问题，显著提升了预测精度和排名效果。

> **ai_Abstract:** 本文提出了一种名为对比学习矩阵补全（MCCL）的新型推荐系统方法，旨在解决现有GNN基矩阵补全模型对噪声敏感和过拟合的问题。MCCL通过为每个交互生成两种不同的图表示——一种侧重去噪，另一种通过图变分自编码器进行特征对齐——并利用互学习损失函数来协调这些表示。实验证明，MCCL显著提升了预测分数的准确性（RMSE提高0.8%）和排名效果（排名指标提高36%），从而增强了模型的泛化能力和鲁棒性。

> **摘要翻译:** 矩阵补全是推荐系统中广泛采用的框架，因为它能够预测用户-物品评分矩阵中的缺失条目，从而全面理解用户偏好。然而，当前基于图神经网络（GNN）的方法由于其固有的消息传递机制，对噪声或不相关边高度敏感，并且容易过拟合，这限制了它们的泛化能力。为了克服这些挑战，我们提出了一种名为对比学习矩阵补全（MCCL）的新方法。我们的方法首先为每个交互提取局部邻域子图，然后生成两种不同的图表示。第一种表示通过集成GNN层与注意力机制来强调去噪，而第二种通过图变分自编码器获得，用于将特征分布与标准先验对齐。训练过程中采用互学习损失函数逐步协调这些表示，使模型能够捕捉共同模式并显著增强其泛化能力。在多个真实世界数据集上的广泛实验表明，我们的方法不仅提高了预测分数的数值准确性（RMSE提高了0.8%），而且在排名指标上表现更优异（排名指标提高了36%）。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [27] [Towards Understanding Bias in Synthetic Data for Evaluation](https://arxiv.org/abs/2506.10301)
> *探究合成数据在评估中的偏差*

*Hossein A. Rahmani, Varsha Ramineni, Nick Craswell, Bhaskar Mitra, Emine Yilmaz* | **Main category: cs.IR**

**Keywords:** 合成数据, 大型语言模型, 信息检索, 偏差, 测试集

**Comment:** 

> **TL;DR:** 论文研究了LLM生成的合成测试集在信息检索系统评估中的偏差，发现对绝对性能影响显著，但对相对性能影响较小。

**AI_Comments:** 这篇论文探讨了利用LLM进行信息检索评估这一新兴且关键领域，并着重分析了合成数据中常被忽视的偏差问题。其发现偏差对相对性能比较影响较小，是一个有价值的洞察，可能指导未来的研究和实际应用。通过实证和模型验证，论文的论点得到了加强。

<details>
  <summary>Details</summary>

**Motivation:** 构建信息检索系统的测试集成本高昂且资源密集。尽管LLM生成合成数据已受关注，但利用LLM创建合成测试集的研究相对较少，且其潜在偏差需要深入分析。

**Method:** 论文深入探究了使用LLM构建的合成测试集的可靠性，其中LLM用于生成合成查询、标签或两者。通过实证分析展示了评估结果中偏差的存在及其影响，并使用线性混合效应模型进一步验证了偏差。

**Result:** 使用合成测试集获得的评估结果存在偏差。这种偏差在计算绝对系统性能时可能很显著，但在比较相对系统性能时可能不那么显著。

**Conclusion:** 尽管合成测试集在评估绝对系统性能时可能引入显著偏差，但对于比较相对系统性能而言，其影响可能不那么显著，这表明合成测试集在某些评估场景中仍具潜在价值。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）生成的合成测试集在信息检索（IR）系统评估中的可靠性和潜在偏差。研究通过实证和线性混合效应模型验证了，尽管在计算绝对系统性能时存在显著偏差，但这种偏差在比较相对系统性能时影响较小。这表明LLM生成的合成数据在IR评估中具有细微的适用性。

> **摘要翻译:** 信息检索 (IR) 系统的评估离不开测试集。为这些测试集创建多样化的用户查询可能具有挑战性，而获取相关性判断（指示检索到的文档与查询的匹配程度）通常成本高昂且资源密集。最近，使用大型语言模型 (LLM) 生成合成数据集在各种应用中受到了关注。虽然之前的工作已使用LLM生成合成查询或文档来改进排名模型，但利用LLM创建合成测试集仍相对未被充分探索。之前的工作~\[rahmani2024synthetic\] 表明合成测试集有潜力用于系统评估，然而，需要更多的分析来验证这一说法。在本文中，我们彻底调查了使用LLM构建的合成测试集的可靠性，其中LLM用于生成合成查询、标签或两者。特别是，我们检查了当此类测试集用于评估时可能出现的潜在偏差。我们首先通过实证证明了评估结果中存在此类偏差，并分析了它可能对系统评估产生的影响。我们还使用线性混合效应模型进一步验证了此类偏差的存在。我们的分析表明，尽管使用合成测试集获得的评估结果中存在的偏差效应可能很显著，例如计算绝对系统性能，但其对比较相对系统性能的影响可能不那么显著。代码和数据可在以下网址获取：https://github.com/rahmanidashti/BiasSyntheticData。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [53] [Context-Adaptive Graph Neural Networks for Next POI Recommendation](https://arxiv.org/abs/2506.10329)
> *上下文自适应图神经网络用于下一兴趣点推荐*

*Yu Lei, Limin Shen, Zhu Sun, Tiantian He, Yew-Soon Ong* | **Main category: cs.IR**

**Keywords:** 下一兴趣点推荐, 图神经网络, 上下文自适应, 注意力机制, 序列建模

**Comment:** 12 pages, 6 figures

> **TL;DR:** 本文提出了一种上下文自适应图神经网络（CAGNN），通过动态调整注意力权重和图序列互增强机制，显著提升了下一兴趣点推荐的准确性。

**AI_Comments:** 这篇论文的创新点在于提出了上下文自适应注意力机制和图序列互增强模块，有效解决了现有GNN在POI推荐中独立处理上下文和图序列信息融合不足的问题。通过动态调整注意力权重和互增强机制，模型能够更全面地捕获用户行为模式，提升推荐准确性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在下一兴趣点推荐中存在局限性：1) 大多数GNN方法独立建模不同类型的上下文，限制了多上下文因素协同影响的建模能力，导致注意力权重和推荐性能不佳。2) 它们常将序列组件作为主要预测器，可能削弱GNN学习到的POI嵌入中编码的语义和结构信息。

**Method:** 本文提出上下文自适应图神经网络（CAGNN）以解决上述局限性。CAGNN引入了：1) 上下文自适应注意力机制：在图传播过程中联合纳入不同类型的上下文因素进行注意力计算，动态捕获协作和上下文依赖的转换模式。2) 图序列互增强模块：通过KL散度对齐基于图和基于序列模块的输出，实现两组件的相互增强。

**Result:** 在三个真实世界数据集上的实验结果表明，CAGNN持续优于最先进的方法。同时，理论上保证了上下文自适应注意力机制提高了POI表示的表达能力。

**Conclusion:** CAGNN通过其上下文自适应注意力机制和图序列互增强模块，有效解决了现有下一兴趣点推荐方法中上下文建模不足和图序列信息融合不佳的问题，从而显著提升了推荐性能和POI表示的表达能力。

> **ai_Abstract:** 本文提出了一种名为CAGNN的上下文自适应图神经网络，用于下一兴趣点（POI）推荐。该模型通过引入上下文自适应注意力机制，在图传播中联合考虑多种上下文因素以动态捕获转换模式；并设计了图序列互增强模块，通过KL散度对齐图和序列模块的输出，实现两者的相互增强。实验结果表明，CAGNN在真实世界数据集上持续超越现有最先进方法，并提升了POI表示的表达能力。

> **摘要翻译:** 下一兴趣点（POI）推荐是基于位置服务中的一项关键任务，旨在根据用户的签到历史预测他们接下来的访问。尽管许多现有方法利用图神经网络（GNN）来整合协作信息并提高推荐准确性，但它们大多使用单独的图来建模每种类型的上下文，将不同因素孤立处理。这限制了它们在消息传播过程中建模多个上下文因素协同影响的能力，导致次优的注意力权重和推荐性能。此外，它们通常将序列组件作为主要预测器，这可能会削弱GNN学习到的POI嵌入中编码的语义和结构信息。为了解决这些局限性，我们提出了一种用于下一POI推荐的上下文自适应图神经网络（CAGNN），它使用特定于边缘的上下文因素动态调整注意力权重，并实现了基于图和序列组件之间的相互增强。具体来说，CAGNN引入了：（1）一种上下文自适应注意力机制，在图传播过程中将不同类型的上下文因素联合纳入注意力计算，使模型能够动态捕获协作和上下文相关的转换模式；（2）一个图序列互增强模块，通过KL散度对齐基于图和基于序列模块的输出，实现两个组件的相互增强。在三个真实世界数据集上的实验结果表明，CAGNN持续优于最先进的方法。同时，理论上保证了我们的上下文自适应注意力机制提高了POI表示的表达能力。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [78] [An Analysis of Datasets, Metrics and Models in Keyphrase Generation](https://arxiv.org/abs/2506.10346)
> *关键词生成中数据集、度量和模型的分析*

*Florian Boudin, Akiko Aizawa* | **Main category: cs.IR**

**Keywords:** 关键词生成, 数据集, 度量, 模型, 分析

**Comment:** GEM^2 paper @ ACL 2025

> **TL;DR:** 本文分析了关键词生成领域的50多篇研究论文，揭示了当前评估实践中数据集相似性和度量计算不一致等关键问题，并发布了一个基于PLM的强大模型以促进未来研究。

**AI_Comments:** 本文通过对关键词生成领域现有文献的系统性回顾和批判性分析，揭示了当前评估实践中的深层问题，如数据集同质化和评估指标的误导性。其创新之处在于不仅指出了问题，还通过发布新的PLM-based模型为未来的研究提供了实际的工具和方向，对于规范该领域的评估标准和促进高质量研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管关键词生成任务持续发展，但由于缺乏对现有工作的回顾和分析，该领域的现状仍不明确。本文旨在通过分析弥补这一空白。

**Method:** 本文通过分析超过50篇关于关键词生成的研究论文，全面概述了该领域的最新进展、局限性和开放挑战。

**Result:** 研究发现当前评估实践存在几个关键问题，例如常用基准数据集之间存在令人担忧的相似性，以及度量计算不一致导致性能被高估。此外，为解决预训练模型可用性有限的问题，本文发布了一个强大的基于PLM的关键词生成模型。

**Conclusion:** 本文通过对关键词生成领域现有工作的全面分析，揭示了当前评估实践中的重要问题，并发布了一个新的预训练模型，旨在促进未来的研究。

> **ai_Abstract:** 本文对关键词生成领域50多篇研究论文进行了全面分析，系统地回顾了该领域的进展、局限性和挑战。研究发现，当前评估实践中存在数据集高度相似和度量计算不一致导致性能虚高的问题。为解决预训练模型稀缺的现状，作者还发布了一个强大的基于PLM的关键词生成模型，以期推动后续研究。

> **摘要翻译:** 关键词生成是指生成一组总结文档内容的词语或短语的任务。在过去几年中，人们为这项任务付出了持续的努力，研究范围涉及模型架构、数据资源和用例场景等多个方面。然而，由于尚未有对先前工作的回顾和分析，关键词生成的当前状态仍然未知。在本文中，我们通过对50多篇关键词生成研究论文的分析来弥合这一空白，提供了对最新进展、局限性和开放挑战的全面概述。我们的发现突出了当前评估实践中的几个关键问题，例如常用基准数据集之间令人担忧的相似性以及度量计算中的不一致导致性能被高估。此外，我们通过发布一个强大的基于PLM的关键词生成模型来解决预训练模型可用性有限的问题，以促进未来的研究。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [104] [LightKG: Efficient Knowledge-Aware Recommendations with Simplified GNN Architecture](https://arxiv.org/abs/2506.10347)
> *LightKG：基于简化GNN架构的高效知识感知推荐系统*

*Yanhui Li, Dongxia Wang, Zhu Sun, Haonan Zhang, Huizhong Guo* | **Main category: cs.IR**

**Keywords:** 知识图谱推荐, 图神经网络, 自监督学习, 稀疏性, 模型简化

**Comment:** Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery
  and Data Mining

> **TL;DR:** LightKG提出了一种简化的GNN架构，用于知识图谱感知的推荐系统，通过简化GNN层和高效的对比学习解决了稀疏交互下的性能下降和训练时间过长问题，并在准确性和训练效率上显著优于现有方法。

**AI_Comments:** LightKG的创新点在于其极简主义的设计理念，通过简化GNN架构和优化自监督学习过程，有效解决了复杂模型在稀疏数据下性能下降的问题。它证明了在某些场景下，“少即是多”的原则可以带来更好的性能和效率，这对于资源受限或需要快速迭代的推荐系统尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于GNN的知识图谱感知推荐系统（KGRSs）在稀疏交互场景下表现不佳，即使结合了自监督学习（SSL）也未能保持其优越性能。此外，更复杂的模型（如注意力机制）在稀疏场景下反而会降低性能并增加学习难度。

**Method:** 论文提出了LightKG，它包含一个简化的GNN层，该层将有向关系编码为标量对而非密集嵌入，并采用线性聚合框架，大大降低了GNN的复杂度。此外，LightKG还整合了一个高效的对比层来实现SSL，通过直接最小化原始图中的节点相似度，避免了以往SSL方法中耗时的子图生成和比较。

**Result:** LightKG在四个基准数据集上，无论在稀疏还是密集场景下，都优于12种有竞争力的KGRSs。具体而言，它在推荐准确性上平均超过最佳基线5.8%，并且与采用SSL的KGRSs相比，训练时间节省了84.3%。

**Conclusion:** LightKG通过简化GNN架构和高效的对比学习方法，有效解决了知识图谱感知推荐系统在稀疏数据下的性能瓶颈和训练效率问题，实现了在准确性和训练时间上的显著提升。

> **ai_Abstract:** 本文提出了LightKG，一个针对知识图谱感知推荐系统（KGRSs）的简化图神经网络（GNN）模型，旨在解决现有GNN-based KGRSs在稀疏交互下的性能不足和训练效率低下问题。LightKG通过引入一个简化的GNN层（将关系编码为标量对并使用线性聚合）和一个高效的对比学习层（直接最小化节点相似度），显著降低了模型复杂度并优化了自监督学习过程。实验结果表明，LightKG在推荐准确性和训练时间方面均显著优于现有SOTA方法。

> **摘要翻译:** 最近，图神经网络（GNNs）因其已被证明的有效性，已成为知识图谱感知推荐系统（KGRSs）的主流方法。在基于GNN的KGRSs基础上，自监督学习（SSL）被引入以解决稀疏性问题，但这也导致了更长的训练时间。然而，通过大量的实验，我们发现：(1)与其他的KGRSs相比，现有的基于GNN的KGRSs即使结合了SSL，在稀疏交互下也未能保持其优越性能。(2)更复杂的模型在稀疏交互场景下往往表现更差，并且像注意力机制这样复杂的机制可能是有害的，因为它们通常会增加学习难度。受这些发现的启发，我们提出了LightKG，一个简单而强大的基于GNN的KGRS，以解决稀疏性问题。LightKG包含一个简化的GNN层，该层将有向关系编码为标量对而不是密集嵌入，并采用线性聚合框架，大大降低了GNN的复杂度。此外，LightKG还整合了一个高效的对比层来实现SSL。它直接最小化原始图中的节点相似度，避免了以往SSL方法中耗时的子图生成和比较。在四个基准数据集上的实验表明，LightKG在稀疏和密集场景下均优于12种有竞争力的KGRSs，同时显著减少了训练时间。具体来说，它在推荐准确性上平均超过最佳基线5.8%，并且与采用SSL的KGRSs相比，训练时间节省了84.3%。我们的代码可在https://github.com/1371149/LightKG获取。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [127] [SHORE: A Long-term User Lifetime Value Prediction Model in Digital Games](https://arxiv.org/abs/2506.10487)
> *SHORE：一种数字游戏中长期用户生命周期价值预测模型*

*Shuaiqi Sun, Congde Yuan, Haoqiang Yang, Mengzhuo Guo, Guiying Wei, Jiangbo Tian* | **Main category: cs.IR**

**Keywords:** 用户生命周期价值预测, 数字游戏, SHORE, 辅助任务, 混合损失函数

**Comment:** 7 pages

> **TL;DR:** SHORE是一种新颖的LTV预测框架，通过结合短周期辅助任务和混合损失函数，显著提高了数字游戏中长期用户生命周期价值预测的准确性和鲁棒性。

**AI_Comments:** 该论文提出了一种创新的LTV预测模型SHORE，其核心创新在于利用短周期预测作为辅助任务来优化长期LTV预测，并设计了独特的混合损失函数以有效处理游戏数据中常见的零膨胀和异常值问题。该方法解决了现有LTV模型在准确性和鲁棒性方面的不足，特别是在处理延迟支付和稀疏数据方面表现出色。实验结果显示了显著的性能提升，表明SHORE在实际工业应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在数字游戏中，长期用户生命周期价值（LTV）预测对于变现策略至关重要，但由于支付行为延迟、早期用户数据稀疏以及高价值异常值的存在，面临重大挑战。现有模型通常依赖短周期观察或强分布假设，这往往低估长期价值或鲁棒性差。

**Method:** 本文提出了SHort-cycle auxiliary with Order-preserving REgression (SHORE) 模型，这是一种新颖的LTV预测框架。SHORE将短周期预测（如LTV-15和LTV-30）作为辅助任务集成，以增强长周期目标（如LTV-60）的预测。此外，SHORE引入了一种混合损失函数，结合了保序多类分类和动态Huber损失，以减轻零膨胀和异常支付行为的影响。

**Result:** 在真实世界数据集上的大量离线和在线实验表明，SHORE显著优于现有基线模型，在线部署中预测误差相对减少了47.91%。

**Conclusion:** SHORE模型在数字游戏中的工业级LTV预测方面表现出实际有效性和鲁棒性。

> **ai_Abstract:** SHORE是一种针对数字游戏长期用户生命周期价值（LTV）预测的新型框架。它通过整合短周期预测作为辅助任务来提升长周期LTV的预测精度，并引入结合保序多类分类和动态Huber损失的混合损失函数，以应对数据稀疏、零膨胀和异常值等挑战。实验证明，SHORE显著优于现有模型，在线部署中预测误差降低了47.91%，展现了其在工业级应用中的有效性和鲁棒性。

> **摘要翻译:** 在数字游戏中，长期用户生命周期价值（LTV）预测对于变现策略至关重要，但由于支付行为延迟、早期用户数据稀疏以及高价值异常值的存在，面临重大挑战。尽管现有模型通常依赖短周期观察或强分布假设，但此类方法往往低估长期价值或鲁棒性差。为了解决这些问题，我们提出了SHort-cycle auxiliary with Order-preserving REgression（SHORE），这是一种新颖的LTV预测框架，它将短周期预测（例如LTV-15和LTV-30）作为辅助任务集成，以增强长周期目标（例如LTV-60）。SHORE还引入了一种混合损失函数，结合了保序多类分类和动态Huber损失，以减轻零膨胀和异常支付行为的影响。在真实世界数据集上的大量离线和在线实验表明，SHORE显著优于现有基线模型，在线部署中预测误差相对减少了47.91%。这些结果突出了SHORE在数字游戏中工业级LTV预测方面的实际有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [148] [Macro Graph of Experts for Billion-Scale Multi-Task Recommendation](https://arxiv.org/abs/2506.10520)
> *十亿级多任务推荐的宏观专家图*

*Hongyu Yao, Zijin Hong, Hao Chen, Yuanchen Bei, Zhiqing Li, Qijie Shen, Zuobin Ying, Huan Gong, Feiran Huang* | **Main category: cs.IR**

**Keywords:** 多任务学习, 图基推荐, 宏观图, 专家系统, 十亿级

**Comment:** 

> **TL;DR:** MGOE是一个新框架，首次利用宏观图嵌入和专家关联来解决十亿级多任务推荐中图结构被忽视的问题，并在离线和在线测试中表现出色。

**AI_Comments:** MGOE的创新之处在于它是首个将宏观图嵌入引入十亿级多任务学习，并有效整合图信息以提升推荐性能的框架。其重要性体现在它解决了传统方法忽视图结构的关键局限性，并通过实际部署和在线A/B测试验证了其在大规模推荐系统中的显著优越性。

<details>
  <summary>Details</summary>

**Motivation:** 十亿级多任务学习中，不同任务对应不同的十亿级图，传统方法忽视了这些图结构，仅依赖用户和物品嵌入，从而错失了性能提升的巨大潜力。

**Method:** 本文提出了宏观专家图（MGOE）框架，首次利用宏观图嵌入捕获任务特定的宏观特征，并建模任务特定专家之间的关联。具体而言，它提出了宏观图底部（Macro Graph Bottom）概念，首次使多任务学习模型有效融入图信息；并设计了宏观预测塔（Macro Prediction Tower）以动态集成跨任务的宏观知识。

**Result:** MGOE已在领先的十亿级推荐系统主页部署。在三个公共基准数据集上进行的广泛离线实验表明，MGOE优于最先进的多任务学习方法。在线A/B测试也证实了MGOE在十亿级推荐系统中的优越性。

**Conclusion:** MGOE在多任务图基推荐领域取得了突破，它有效利用宏观图嵌入并建模专家关联，解决了十亿级推荐系统中的图结构利用问题。

> **ai_Abstract:** MGOE框架旨在解决十亿级多任务推荐中图结构被忽视的问题。它首次利用宏观图嵌入来捕获任务特定的宏观特征，并建模任务特定专家之间的关联。通过引入宏观图底部来整合图信息，并设计宏观预测塔以动态集成跨任务知识，MGOE在离线基准测试和在线A/B测试中均表现出优于现有方法的性能，并已成功部署于大规模推荐系统。

> **摘要翻译:** 十亿级多任务学习在处理不同任务对应不同十亿级图时面临巨大挑战。传统的多任务学习方法常常忽视这些图结构，仅依赖于个体用户和物品嵌入。然而，忽视图结构会错过提升性能的巨大潜力。在本文中，我们引入了宏观专家图（MGOE）框架，这是第一个能够利用宏观图嵌入来捕获任务特定的宏观特征，同时建模任务特定专家之间关联的方法。具体而言，我们提出了宏观图底部（Macro Graph Bottom）的概念，这首次使得多任务学习模型能够有效地整合图信息。我们设计了宏观预测塔（Macro Prediction Tower）来动态整合跨任务的宏观知识。MGOE已大规模部署，为领先的十亿级推荐系统的主页提供多任务学习支持。在三个公共基准数据集上进行的广泛离线实验证明了其优于最先进的多任务学习方法，确立了MGOE在多任务图基推荐领域的突破地位。此外，在线A/B测试证实了MGOE在十亿级推荐系统中的优越性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [167] [Conversational Search: From Fundamentals to Frontiers in the LLM Era](https://arxiv.org/abs/2506.10635)
> *对话式搜索：从基础到LLM时代的未来前沿*

*Fengran Mo, Chuan Meng, Mohammad Aliannejadi, Jian-Yun Nie* | **Main category: cs.IR**

**Keywords:** 对话式搜索, 大型语言模型, 信息检索, 多轮交互, 教程

**Comment:** Accepted by Tutorial Track in SIGIR 2025

> **TL;DR:** 本教程旨在介绍对话式搜索的基础知识以及大型语言模型（LLM）如何彻底改变该领域的最新发展，为下一代对话式搜索系统提供见解。

**AI_Comments:** 这篇教程非常及时且重要，因为它弥合了对话式搜索的传统概念与大型语言模型带来的最新突破之间的鸿沟。它为理解LLM如何赋能和重塑复杂信息检索交互提供了宝贵的资源，对于该领域的未来发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）的兴起，对话式搜索系统面临新的机遇和挑战，因此需要一个教程来连接对话式搜索的基础知识与LLM带来的前沿发展。

**Method:** 本教程旨在介绍对话式搜索的基础知识与大型语言模型（LLM）所彻底改变的新兴主题之间的联系，为学生、研究人员和从业者提供全面的理解。

**Result:** 参与者将全面了解对话式搜索的核心原则以及由LLM驱动的尖端发展，掌握为下一代对话式搜索系统开发做出贡献所需的知识。

**Conclusion:** 本教程旨在使参与者掌握必要的知识，从而为下一代对话式搜索系统的发展做出贡献。

> **ai_Abstract:** 这篇教程探讨了对话式搜索的原理及其在大型语言模型（LLM）时代的前沿发展。对话式搜索通过多轮交互满足用户复杂的信息需求，要求系统理解对话上下文中的意图并返回相关信息。LLM的出现为构建智能对话式搜索系统带来了新的机遇和挑战。本教程旨在为学生、研究人员和从业者提供对话式搜索基础知识与LLM驱动的最新进展之间的全面理解，以促进下一代系统的发展。

> **摘要翻译:** 对话式搜索使用户和系统能够进行多轮交互，以满足用户复杂的信息需求。在此交互过程中，系统应在对话上下文中理解用户的搜索意图，然后通过灵活的、基于对话的界面返回相关信息。最近强大的大型语言模型（LLM）凭借其指令遵循、内容生成和推理能力，吸引了广泛的关注和进展，为构建智能对话式搜索系统提供了新的机遇和挑战。本教程旨在介绍对话式搜索背景下，基础知识与LLM所彻底改变的新兴主题之间的联系。它专为来自学术界和工业界的学生、研究人员和从业者设计。参与者将全面了解对话式搜索的核心原则以及由LLM驱动的尖端发展，掌握为下一代对话式搜索系统开发做出贡献所需的知识。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [197] [Constructing and Evaluating Declarative RAG Pipelines in PyTerrier](https://arxiv.org/abs/2506.10802)
> *在 PyTerrier 中构建和评估声明式 RAG 流水线*

*Craig Macdonald, Jinyuan Fang, Andrew Parry, Zaiqiao Meng* | **Main category: cs.IR**

**Keywords:** RAG, PyTerrier, 声明式流水线, 检索增强生成, 搜索系统

**Comment:** 4 pages, 3 tables, Accepted to SIGIR 2025

> **TL;DR:** 本文介绍如何在 PyTerrier 中构建声明式检索增强生成 (RAG) 流水线，并展示其在标准数据集上的简洁性和与现有 PyTerrier 生态系统的集成。

**AI_Comments:** 本文的创新之处在于将 RAG 流水线的构建引入到声明式 PyTerrier 框架中，这大大简化了复杂搜索和生成系统的开发和实验。通过提供统一的接口和集成现有工具，它降低了 RAG 研究和应用的门槛。其重要性体现在为研究人员和开发者提供了一个高效、灵活的平台来构建、评估和迭代 RAG 模型。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成 (RAG) 是流水线架构的一个重要应用，本文旨在描述如何在声明式 PyTerrier 架构中构建此类 RAG 流水线，并阐述这样做的优势。

**Method:** 通过 PyTerrier-RAG 扩展，在 PyTerrier 中构建声明式 RAG 流水线。该扩展提供了标准 RAG 数据集和评估指标、先进的 LLM 阅读器，并利用 PyTerrier 独特的运算符表示法来简化流水线的构建。通过在标准数据集（包括 Natural Questions）上展示索引和 RAG 流水线的简洁性，并演示如何与 PyTerrier 生态系统中的稀疏、学习稀疏和密集检索器以及其他神经排序器结合使用。

**Result:** 演示了在标准数据集上索引和 RAG 流水线的简洁性，以及如何利用 PyTerrier 生态系统中现有的先进稀疏、学习稀疏和密集检索器以及其他神经排序器来构建更强大的系统。

**Conclusion:** 本文展示了在 PyTerrier 中构建声明式 RAG 流水线的可行性和优势，提供了易于使用的工具和与现有生态系统的良好集成。

> **ai_Abstract:** 本文介绍 PyTerrier-RAG 扩展，它允许在 PyTerrier 框架中声明式地构建和评估检索增强生成 (RAG) 流水线。该扩展简化了 RAG 系统的构建，提供了对标准数据集、评估指标和先进 LLM 阅读器的访问，并展示了其与 PyTerrier 现有生态系统中各种检索器和排序器的无缝集成和简洁性。

> **摘要翻译:** 搜索引擎通常遵循流水线架构，其中复杂但有效的重排序组件用于细化初始检索的结果。检索增强生成（RAG）是流水线架构的一个令人兴奋的应用，其中最终组件从检索到的文档中为用户生成连贯的答案。在这篇演示论文中，我们描述了如何在声明式 PyTerrier 架构中构建此类 RAG 流水线，以及这样做的优势。我们的 PyTerrier-RAG 扩展为 PyTerrier 提供了对标准 RAG 数据集和评估措施、最先进的 LLM 阅读器的便捷访问，并利用 PyTerrier 独特的运算符表示法，可以轻松构建流水线。我们演示了在标准数据集（包括 Natural Questions）上索引和 RAG 流水线的简洁性，以及如何利用更大的 PyTerrier 生态系统（包括最先进的稀疏、学习稀疏和密集检索器以及其他神经排序器）进行构建。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [214] [Precise Zero-Shot Pointwise Ranking with LLMs through Post-Aggregated Global Context Information](https://arxiv.org/abs/2506.10859)
> *通过后聚合全局上下文信息实现LLM精准零样本点式排序*

*Kehan Long, Shasha Li, Chen Xu, Jintao Tang, Ting Wang* | **Main category: cs.IR**

**Keywords:** 零样本排序, LLM, 点式排序, 全局上下文, 后聚合

**Comment:** Accepted by SIGIR 2025

> **TL;DR:** 本文提出了一种名为全局一致比较点式排序（GCCP）的新策略，并通过后聚合全局上下文信息（PAGC）的方法，显著提升了LLM点式排序的有效性，同时保持了其高效率。

**AI_Comments:** 本文的创新点在于巧妙地解决了LLM点式排序中效率与效果之间的权衡问题。通过引入“锚点文档”和“后聚合”机制，在不牺牲点式方法效率的前提下，有效地融入了全局上下文信息，弥补了其性能瓶颈。这对于大规模零样本文档排序应用具有重要的实践意义和价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于LLM的点式排序方法虽然效率高，但由于独立生成分数而忽略了文档间的关键比较性见解，导致评分不一致和次优性能。而比较性方法（如成对和列表式）虽然有效，但计算成本高昂，不适用于大规模应用。

**Method:** 本文提出了两项关键创新来改进点式方法的有效性同时保持其效率：(1) 提出了一种新颖的全局一致比较点式排序（GCCP）策略，该策略通过将每个候选文档与一个锚点文档（作为查询聚焦的伪相关候选摘要）进行全局参考比较来生成对比性相关性分数，从而捕获文档比较的全局上下文。(2) 这些对比性相关性分数可以通过后聚合（PAGC）的方式与现有SOTA点式方法高效整合，以无训练的方式无缝集成必要的全局上下文信息。

**Result:** 在TREC DL和BEIR基准测试上的大量实验表明，我们的方法显著优于以前的点式方法，同时保持了可比的效率。与需要大量计算资源的比较性方法相比，我们的方法也取得了有竞争力的性能。进一步的分析验证了锚点构建策略的有效性。

**Conclusion:** 本文提出的GCCP和PAGC方法通过巧妙地融入全局上下文信息，有效提升了LLM点式排序的性能，同时维持了其固有的高效率，使其成为大规模零样本排序的实用且有竞争力的解决方案。

> **ai_Abstract:** 本文针对LLM点式排序方法效率高但性能受限的问题，提出了一种名为全局一致比较点式排序（GCCP）的新策略。该策略通过引入查询聚焦的锚点文档进行全局参考比较，生成对比性相关性分数，以捕获文档间的全局上下文。这些分数随后通过后聚合（PAGC）的方式与现有SOTA点式方法结合，无需训练即可提升性能。实验证明，该方法在保持高效率的同时，显著优于现有SOTA点式方法，并能与计算成本更高的比较性方法相媲美。

> **摘要翻译:** 最近的进展成功地利用大型语言模型（LLM）进行零样本文档排序，探索了各种提示策略。成对和列表式等比较方法虽然效率高，但计算密集，因此不适用于大规模应用。基于评分的点式方法通过独立同时为每个候选文档生成相关性分数，表现出卓越的效率。然而，这种独立性忽略了文档之间关键的比较性见解，导致评分不一致和次优性能。在本文中，我们旨在通过两项关键创新来提高点式方法的有效性，同时保持其效率：(1) 我们提出了一种新颖的全局一致比较点式排序（GCCP）策略，该策略结合了每个候选文档与一个锚点文档之间的全局参考比较，以生成对比性相关性分数。我们将锚点文档战略性地设计为伪相关候选文档的查询聚焦摘要，通过捕获文档比较的全局上下文，作为有效的参考点。(2) 这些对比性相关性分数可以与现有SOTA点式方法高效地进行后聚合（PAGC），以无训练的方式无缝集成必要的全局上下文信息。在TREC DL和BEIR基准测试上的大量实验表明，我们的方法显著优于以前的点式方法，同时保持了可比的效率。我们的方法与需要大量计算资源的比较方法相比，也取得了有竞争力的性能。更多分析进一步验证了我们锚点构建策略的有效性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [82] [Data-driven balanced truncation for second-order systems with generalized proportional damping](https://arxiv.org/abs/2506.10118)
> *具有广义比例阻尼的二阶系统的数驱动平衡截断*

*Sean Reiter, Steffen W. R. Werner* | **Main category: math.NA**

**Keywords:** 数据驱动, 平衡截断, 二阶系统, 广义比例阻尼, 降阶建模

**Comment:** 31 pages, 5 figures, 5 tables

> **TL;DR:** 该研究提出了一种新的数据驱动的平衡截断方法，用于对具有广义比例阻尼的二阶系统进行降阶建模。

**AI_Comments:** 该论文提出了一种创新的数据驱动方法，将平衡截断模型降阶技术应用于具有广义比例阻尼的二阶系统，填补了现有方法在处理此类系统时的空白。其通过数据驱动推断阻尼系数的机制，提升了模型构建的灵活性和自动化程度，对于计算机辅助控制系统设计具有重要意义。然而，抽象中未提及该方法在面对大规模复杂系统或噪声数据时的具体性能和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 在计算机辅助控制系统设计中，需要计算具有物理意义内部结构且易于评估的低维模型，而结构化降阶建模是其核心组成部分。

**Method:** 该方法通过平衡截断模型降阶，为二阶时间导数描述的线性动力系统开发了一种新的结构化数据驱动替代建模方法。它是二阶系统位置-速度平衡截断的数据驱动重新表述，并将非结构化一阶系统的基于正交的平衡截断推广到二阶情况。计算出的替代模型编码了广义比例阻尼结构，阻尼系数仅通过最小化系数的最小二乘误差从数据中推断出来。

**Result:** 通过几个数值例子证明了所提出方法的有效性。

**Conclusion:** 所提出的数据驱动平衡截断方法对于具有广义比例阻尼的二阶系统是有效的。

> **ai_Abstract:** 本文提出了一种用于具有广义比例阻尼的二阶系统的新型数据驱动平衡截断方法。该方法是位置-速度平衡截断的数据驱动重构，并将其推广到二阶系统，能够从数据中推断出阻尼系数。数值示例验证了其有效性。

> **摘要翻译:** 结构化降阶建模是计算机辅助控制系统设计中的核心组成部分，其中需要计算具有物理意义内部结构且易于评估的低维模型。在这项工作中，我们通过平衡截断模型降阶，为由二阶时间导数描述的线性动力系统开发了一种新的结构化数据驱动替代建模方法。所提出的方法是二阶系统位置-速度平衡截断的数据驱动重新表述，并将非结构化一阶系统的基于正交的平衡截断推广到二阶情况。计算出的替代模型编码了广义比例阻尼结构，阻尼系数仅通过最小化系数的最小二乘误差从数据中推断出来。几个数值例子证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [108] [R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN](https://arxiv.org/abs/2506.10243)
> *R-PINN：恢复型后验估计器增强的自适应PINN*

*Rongxin Lu, Jiwei Jia, Young Ju Lee, Zheng Lu, Chensong Zhang* | **Main category: math.NA**

**Keywords:** 物理信息神经网络, 自适应算法, 后验估计器, 偏微分方程, 混合数值方法

**Comment:** 

> **TL;DR:** 提出R-PINN，一种结合恢复型后验估计器的自适应物理信息神经网络（PINN），旨在解决偏微分方程在局部大梯度区域的精度问题，通过自适应调整配置点分布，相比现有方法能更快收敛并减少误差。

**AI_Comments:** 本文的创新之处在于将自适应有限元方法中常用的恢复型后验误差估计器引入到物理信息神经网络中，有效地解决了PINN在处理具有大梯度问题时精度不足的挑战。这种将传统数值方法与深度学习相结合的混合数值方法为偏微分方程的求解提供了新的思路，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有物理信息神经网络（PINN）在应用于具有大局部梯度的偏微分方程时，表现出次优性能，导致显著的局部误差。

**Method:** 本文提出R-PINN算法，其核心思想是根据当前数值解的恢复型后验误差自适应调整配置点的分布。该方法受自适应有限元方法启发，将梯度恢复估计器（恢复型后验估计器）与PINN结合。

**Result:** R-PINN在自适应点更少的情况下实现了更快的收敛，并且在具有多个大误差区域的情况下显著优于典型的自适应PINN算法FI-PINN。

**Conclusion:** R-PINN通过融合自适应有限元方法和PINN，提供了一种求解偏微分方程的混合数值方法，有效提升了PINN在处理大梯度问题时的精度和效率。

> **ai_Abstract:** 本文针对物理信息神经网络（PINN）在求解具有大局部梯度的偏微分方程时存在的精度问题，提出了一种名为R-PINN的自适应算法。该算法借鉴自适应有限元方法，利用恢复型后验误差估计器动态调整配置点分布，以提高解的精度。实验结果表明，R-PINN相比现有方法（如FI-PINN）能以更少的自适应点实现更快收敛，并在多误差区域表现出显著优势。该方法是一种结合自适应有限元方法与PINN的混合数值方法。

> **摘要翻译:** 近年来，随着机器学习和神经网络的进步，使用物理信息神经网络（PINN）求解偏微分方程（PDE）的算法得到了广泛应用。虽然这些算法适用于各种方程，但当应用于具有大局部梯度的方程时，它们通常表现不佳，导致显著的局部误差。为了解决这个问题，本文提出了一种自适应PINN算法，旨在提高此类情况下的精度。该算法的核心思想是根据当前数值解的恢复型后验误差自适应调整配置点的分布，从而更好地逼近真实解。这种方法受到自适应有限元方法的启发。通过将自适应有限元方法（FEM）中常用的梯度恢复估计器——恢复型后验估计器与PINN结合，我们引入了恢复型后验估计器增强的自适应PINN（R-PINN），并将其性能与典型的自适应PINN算法FI-PINN进行了比较。我们的结果表明，R-PINN在自适应点更少的情况下实现了更快的收敛，并且在具有多个大误差区域的情况下显著优于FI-PINN。值得注意的是，我们的方法是一种用于求解偏微分方程的混合数值方法，它将自适应FEM与PINN进行了集成。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [131] [Enhanced randomized Douglas-Rachford method: Improved probabilities and adaptive momentum](https://arxiv.org/abs/2506.10261)
> *增强型随机Douglas-Rachford方法：改进的概率和自适应动量*

*Liqi Guo, Ruike Xiang, Deren Han, Jiaxin Xie* | **Main category: math.NA**

**Keywords:** 随机Douglas-Rachford方法, 自适应动量, 采样策略, 线性系统, 收敛性

**Comment:** 

> **TL;DR:** 本文通过引入改进的采样策略和自适应动量机制，增强了随机Douglas-Rachford (RDR) 方法，实现了更强的收敛保证和更快的收敛速度。

**AI_Comments:** 本文的创新点在于将先进的采样策略（无放回和体积抽样）与自适应动量机制相结合，显著提升了随机Douglas-Rachford方法的性能。这对于解决大规模机器学习和信号处理中的线性系统问题具有重要意义，其理论收敛性证明和实际效果验证都很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 随机迭代方法在机器学习和信号处理中解决大规模线性系统方面受到关注，其中随机Douglas-Rachford (RDR) 方法是一个例子。本文旨在增强RDR方法以获得更好的性能和收敛保证。

**Method:** 1. 引入了无放回抽样和体积抽样到RDR中。2. 开发了一种自适应重球动量机制，可以根据之前的迭代动态调整步长和动量参数。

**Result:** 1. 与传统的独立同分布(i.i.d.)抽样相比，建立了更强的收敛保证。2. 证明了新方法在期望上实现了线性收敛，并改进了收敛界。3. 数值实验表明，增强型RDR方法始终优于原始版本，在各种问题设置中提供了显著的实际效益。

**Conclusion:** 通过引入改进的采样策略和自适应动量机制，增强型随机Douglas-Rachford方法在理论和实践上都表现出优越的性能，具有更强的收敛保证和更快的收敛速度。

> **ai_Abstract:** 本文提出了一种增强型随机Douglas-Rachford (RDR) 方法，旨在解决大规模线性系统。该方法通过引入无放回抽样和体积抽样等改进的采样策略，以及一个自适应重球动量机制来优化RDR。研究证明，与传统RDR相比，新方法具有更强的收敛保证，并在期望上实现线性收敛，同时改进了收敛界。数值实验验证了其在实际应用中超越原始RDR的显著优势。

> **摘要翻译:** 随机迭代方法在机器学习和信号处理中解决大规模线性系统方面最近受到了关注。其中一个例子是随机Douglas-Rachford (RDR) 方法，它通过将迭代点通过两个随机选择的超平面进行反射，并与当前点进行凸组合来更新迭代。在这项工作中，我们通过引入改进的采样策略和自适应重球动量方案来增强RDR。具体来说，我们将无放回抽样和体积抽样融入到RDR中，并与传统的独立同分布(i.i.d.)抽样相比，建立了更强的收敛保证。此外，我们开发了一种自适应动量机制，可以根据之前的迭代动态调整步长和动量参数，并证明由此产生的方法在期望上实现了线性收敛，并改进了收敛界。数值实验表明，增强型RDR方法始终优于原始版本，在各种问题设置中提供了显著的实际效益。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [151] [Complex scaling for open waveguides](https://arxiv.org/abs/2506.10263)
> *开放波导的复标度法*

*Charles L. Epstein, Tristan Goodwill, Jeremy Hoskins, Solomon Quinn, Manas Rachh* | **Main category: math.NA**

**Keywords:** 复标度法, 开放波导, 积分方程, 解析延拓, 数值离散化

**Comment:** 

> **TL;DR:** 本文分析了复标度法在开放介质波导中时谐标量波传播问题上的应用，通过对积分方程核和解的解析延拓及等高线变形，实现了高效的数值离散化，误差呈指数衰减。

**AI_Comments:** 本文创新性地将复标度法应用于开放介质波导的波传播问题，并通过严格的数学分析，证明了积分方程核与解的解析性质，进而实现了数值求解的高效性和高精度（指数衰减误差）。这对于解决复杂开放系统中的波传播问题具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 分析复标度法应用于“泄漏”或开放介质波导结之间时谐标量波传播问题的有效性。

**Method:** 作者分析了复标度法，该问题可简化为无限界面上的Fredholm第二类积分方程系统。通过证明积分方程中的核在特定实子流形上具有快速衰减的解析延拓，且解本身也具有解析延拓并满足渐近估计。然后，通过将积分方程变形到合适的等高线，利用核、密度和数据的衰减特性，实现了直接的离散化和截断。

**Result:** 积分方程中的核在特定自然全实子流形上具有快速衰减的解析延拓；对于合适的边界数据，积分方程的解本身也具有解析延拓并满足相关的渐近估计；通过变形积分方程到合适的等高线，离散化和截断的误差随截断长度呈指数衰减。结果通过数值例子进行了说明。

**Conclusion:** 复标度法通过对积分方程核和解的深入分析及等高线变形，为开放波导中波传播问题的数值求解提供了一种高效且误差呈指数衰减的方法。

> **ai_Abstract:** 本文研究了复标度法在开放介质波导中时谐标量波传播问题上的应用。作者证明了将该问题简化为Fredholm第二类积分方程后，其核和解都具有快速衰减的解析延拓。通过将积分方程变形到合适的复等高线，结合核和解的衰减特性，实现了高效的数值离散化和截断，且误差随截断长度呈指数衰减。研究结果通过数值例子进行了验证。

> **摘要翻译:** 在这项工作中，我们分析了复标度法应用于“泄漏”或开放介质波导结之间时谐标量波传播问题。在[arXiv:2302.04353, arXiv:2310.05816, arXiv:2401.04674, arXiv:2411.11204]中，研究表明在适当假设下，该问题可以简化为在与波导横向的无限界面上的Fredholm第二类积分方程组。在此，我们表明积分方程中出现的核在$\mathbb{C}^2$的某些自然全实子流形上具有快速衰减的解析延拓。然后，我们表明对于合适的、具有物理意义的边界数据，积分方程的解本身也具有解析延拓并满足相关的渐近估计。通过将积分方程变形到合适的等高线，核、密度和数据的衰减特性使得直接的离散化和截断成为可能，并且误差随截断长度呈指数衰减。我们通过几个代表性的数值例子说明了我们的结果。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [171] [Penalty-Based Feedback Control and Finite Element Analysis for the Stabilization of Nonlinear Reaction-Diffusion Equations](https://arxiv.org/abs/2506.10428)
> *基于惩罚的反馈控制和有限元分析用于非线性反应扩散方程的稳定性*

*Sudeep Kundu, Shishu pal Singh* | **Main category: math.NA**

**Keywords:** 惩罚反馈控制, 反应扩散方程, 有限元分析, 稳定性, 收敛性

**Comment:** 

> **TL;DR:** 本文利用惩罚技术分析了反应扩散方程的Dirichlet边界反馈控制问题，证明了等效Robin问题在H2范数下的稳定性，并证明了惩罚控制问题的解在惩罚参数趋于零时收敛到Dirichlet问题的解。文章还应用C0-一致有限元方法处理空间变量，讨论了半离散格式的稳定性并进行了误差分析，最后通过数值实验验证了理论结果。

**AI_Comments:** 本文的创新点在于将惩罚技术应用于非线性反应扩散方程的Dirichlet边界反馈控制问题，并提供了严格的数学分析，包括稳定性、收敛性证明以及误差分析。结合有限元方法进行数值验证，使得理论与实践相结合，具有较强的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过采用惩罚技术来分析反应扩散方程的Dirichlet边界反馈控制问题，并建立其稳定性。

**Method:** 1. 采用惩罚技术分析Dirichlet边界反馈控制问题。
2. 建立等效Robin问题在H2范数下的稳定性结果。
3. 证明惩罚控制问题的解在惩罚参数趋于零时收敛到Dirichlet边界反馈控制问题的相应解。
4. 应用C0-一致有限元方法处理空间变量，时间变量保持连续。
5. 讨论惩罚控制问题的半离散格式的稳定性并进行误差分析。
6. 通过数值实验验证理论发现。

**Result:** 1. 建立了等效Robin问题在H2范数下关于惩罚参数的稳定性结果。
2. 证明了惩罚控制问题的解在惩罚参数趋于零时收敛到Dirichlet边界反馈控制问题的相应解。
3. 讨论了惩罚控制问题半离散格式的稳定性。
4. 提出了其解的误差分析。
5. 通过数值实验验证了理论发现。

**Conclusion:** 通过数值实验验证了理论发现，表明基于惩罚的反馈控制和有限元分析方法能够有效地稳定非线性反应扩散方程。

> **ai_Abstract:** 本文研究了非线性反应扩散方程的Dirichlet边界反馈控制问题。作者采用惩罚技术将原问题转化为等效的Robin问题，并证明了其在H2范数下的稳定性。研究还证明了惩罚问题的解在惩罚参数趋于零时收敛到Dirichlet问题的解。在数值方法上，文章对空间变量应用了C0-一致有限元方法，并分析了半离散格式的稳定性及误差。最终，通过数值实验验证了所有理论结果。

> **摘要翻译:** 在这项工作中，我们首先采用惩罚技术来分析与反应扩散方程相关的Dirichlet边界反馈控制问题。我们建立了等效Robin问题在H2范数下关于惩罚参数的稳定性结果。此外，我们证明了当惩罚参数ε趋于零时，惩罚控制问题的解收敛到Dirichlet边界反馈控制问题的相应解。本文将C0-一致有限元方法应用于此问题的空间变量，同时保持时间变量连续。我们讨论了惩罚控制问题半离散格式的稳定性，并提出了其解的误差分析。最后，我们通过数值实验验证了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [186] [Stability analysis of the free-surface Stokes problem and an unconditionally stable explicit scheme](https://arxiv.org/abs/2506.10447)
> *自由表面斯托克斯问题的稳定性分析和无条件稳定的显式格式*

*Igor Tominec, Lukas Lundgren, André Löfgren, Josefin Ahlkrona* | **Main category: math.NA**

**Keywords:** 自由表面流, 斯托克斯问题, 稳定性分析, 显式格式, 有限元方法

**Comment:** 

> **TL;DR:** 本文理论分析了自由表面斯托克斯问题的稳定性，并提出了一种无条件稳定的显式时间步进方案。

**AI_Comments:** 这项工作在数值模拟高粘度自由表面流体方面具有重要意义，尤其是在开发无条件稳定显式方案方面。它解决了传统显式方法可能存在的稳定性限制，并通过引入稳定项实现了体积守恒，这对于实际应用中的物理准确性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 准确模拟冰盖动力学、地幔对流、熔岩流等高粘度自由表面流体需要解决耦合的斯托克斯/自由表面方程，因此需要对其稳定性进行分析并开发稳定的数值方法。

**Method:** 理论分析了牛顿流体和非牛顿流体在连续和离散层面上的弱形式的稳定性和守恒特性。对空间使用有限元方法、时间使用显式和隐式欧拉时间步进方法的完全离散稳定性进行了分析。提出了一种为显式欧拉离散设计的稳定项。

**Result:** 提出的稳定项确保了无条件时间稳定性和域体积的守恒，并通过数值实验验证了理论发现。

**Conclusion:** 通过理论分析和数值验证，成功开发了一种适用于自由表面斯托克斯问题的无条件稳定显式方案，能够保持域体积守恒。

> **ai_Abstract:** 本文对自由表面斯托克斯问题在牛顿和非牛顿流体下的弱形式的稳定性与守恒性进行了理论分析，涵盖连续和离散层面。针对有限元空间离散和欧拉时间步进方法，作者提出了一种新的稳定项，以确保显式欧拉离散的无条件时间稳定性和体积守恒。数值实验验证了该理论发现。

> **摘要翻译:** 冰盖动力学、地幔对流、熔岩流以及其他高粘度自由表面流体的精确模拟涉及求解耦合的斯托克斯/自由表面方程。在本文中，我们理论分析了牛顿流体和非牛顿流体在该系统弱形式的稳定性和守恒特性，包括连续和离散层面。我们对空间使用有限元方法、时间使用显式和隐式欧拉时间步进方法的完全离散稳定性进行了分析。受理论启发，我们提出了一种为显式欧拉离散设计的稳定项，该稳定项确保了无条件时间稳定性和域体积的守恒。数值实验验证并支持了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [200] [Convergence of adaptive boundary element methods driven by functional a posteriori error estimates](https://arxiv.org/abs/2506.10499)
> *由泛函后验误差估计驱动的自适应边界元方法收敛性*

*Alexander Freiszlinger, Dirk Pauly, Dirk Praetorius* | **Main category: math.NA**

**Keywords:** 边界元方法, 后验误差估计, 自适应网格细化, 收敛性, 泛函误差

**Comment:** 

> **TL;DR:** 本文证明了一种新的泛函后验误差估计驱动的自适应网格细化算法对于Galerkin边界元方法能够使域内势误差收敛到零。

**AI_Comments:** 本文的创新点在于其提出的泛函后验误差估计器能够控制域内势近似的误差，而非仅仅是边界上的积分密度误差，这使得该方法在实际应用中更具价值。此外，文章为Galerkin边界元方法证明了该自适应算法的收敛性，并指出证明过程需要新的思想，这体现了其理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统的后验边界元方法（BEM）误差估计器通常控制边界上的积分密度误差，而本文提出的泛函误差估计器控制域内势近似的误差，这在实践中更具相关性。

**Method:** 本文采用由Kurz等人提出的泛函后验误差估计方法，并结合自适应网格细化策略。该方法依赖于在沿边界的辅助条带域上数值求解辅助问题，这些条带域会随自适应网格细化而变化。

**Result:** 对于Galerkin边界元方法，本文证明了所提出的自适应网格细化算法能够使势误差收敛到零。

**Conclusion:** 本文证明了基于泛函后验误差估计的自适应网格细化算法对Galerkin边界元方法具有收敛性，并且由于其与基于残差的估计器的结构差异，该证明需要新的思路。

> **ai_Abstract:** 本文研究了一种由泛函后验误差估计驱动的自适应边界元方法（BEM）的收敛性。该方法由Kurz等人提出，其创新之处在于控制域内势近似的误差，而非传统的边界积分密度误差，这更符合实际应用需求。文章详细描述了其依赖于辅助条带域上辅助问题的数值求解过程。对于Galerkin BEM，本文证明了该自适应网格细化算法能够确保域内势误差收敛到零，并指出由于其与传统基于残差的估计器存在结构差异，因此需要新的证明方法。

> **摘要翻译:** 最近的工作[Kurz et al., Numer. Math., 147 (2021)]提出了一种针对边界元方法（BEMs）的泛函后验误差估计以及相关的自适应网格细化策略。与大多数后验BEM误差估计器不同，所提出的泛函误差估计器涵盖了Galerkin和搭配BEM，更重要的是，它们不控制边界上的积分密度误差，而是控制域内势近似的误差，这在实践中更具相关性。这些估计依赖于在沿边界的辅助条带域上数值求解辅助问题，这些条带域受自适应网格细化的影响而变化。对于Galerkin BEM，我们证明了所提出的自适应网格细化算法能够使势误差收敛到零。由于与基于残差的估计器的结构差异，该证明需要新的思路。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [217] [A semi-Lagrangian scheme for First-Order Mean Field Games based on monotone operators](https://arxiv.org/abs/2506.10509)
> *一种基于单调算子的一阶平均场博弈半拉格朗日格式*

*Elisabetta Carlini, Valentina Coscetti* | **Main category: math.NA**

**Keywords:** 半拉格朗日格式, 平均场博弈, 单调算子, 学习价值算法, 策略迭代

**Comment:** 

> **TL;DR:** 本文构建了一种用于一阶平均场博弈的半拉格朗日格式，分析了其收敛性，并提出了一种基于策略迭代的加速学习价值算法，数值实验验证了其有效性和性能提升。

**AI_Comments:** 创新点在于提出了一个结合学习价值算法和策略迭代加速策略的半拉格朗日方案来解决一阶平均场博弈，并通过数值实验验证了其有效性和性能提升。该工作对平均场博弈的数值求解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在构建并分析一种用于一阶、时变、非局部平均场博弈的数值格式，并开发解决离散问题的有效方法。

**Method:** 作者构建了一种用于平均场博弈的半拉格朗日格式，利用单调性分析其收敛性，并提出了一种结合策略迭代加速策略的学习价值算法来解决离散问题。

**Result:** 所提出的方案是有效的，并且加速版本显著提高了性能，这一点已通过数值实验得到验证。

**Conclusion:** 本研究成功开发了一种用于一阶平均场博弈的有效且高效的半拉格朗日格式，其中加速策略显著提升了性能。

> **ai_Abstract:** 本文提出了一种用于一阶、时变、非局部平均场博弈的半拉格朗日格式。该方案的收敛性通过其单调性特性得到分析。为解决离散问题，研究人员实现并证明了学习价值算法的收敛性，并引入了一种基于策略迭代的加速策略。数值实验证实了所提方案的有效性，并显示加速版本显著提升了性能。

> **摘要翻译:** 我们构建了一种用于一阶、时变、非局部平均场博弈的半拉格朗日格式。通过利用一个关键的单调性，分析了该格式对系统弱解的收敛性。为了解决由此产生的离散问题，我们实现了一个学习价值算法，证明了其收敛性，并提出了一种基于策略迭代方法的加速策略。最后，我们展示了数值实验，验证了所提出方案的有效性，并表明加速版本显著提高了性能。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [232] [Non-augmented velocity-vorticity-pressure formulation for the Navier--Stokes--Brinkman--Forchheimer problem](https://arxiv.org/abs/2506.10533)
> *纳维-斯托克斯-布林克曼-福希海默问题的非增广速度-涡度-压力公式*

*Santiago Badia, Carsten Carstensen, Alberto F. Martin, Ricardo Ruiz-Baier, Segundo Villa-Fuentes* | **Main category: math.NA**

**Keywords:** Navier--Stokes--Brinkman--Forchheimer, 涡度-速度-压力, 有限元, 误差估计, 自适应网格细化

**Comment:** 

> **TL;DR:** 本文研究了Navier--Stokes--Brinkman--Forchheimer方程的涡度-速度-压力公式，证明了连续和离散解的存在性，并提出了鲁棒的先验和后验误差估计方法，通过自适应网格细化提高了收敛速度。

**AI_Comments:** 该论文在处理Navier--Stokes--Brinkman--Forchheimer方程的双鞍点问题上具有创新性，特别是在涡度-速度-压力公式的框架下。其贡献在于证明了连续和离散解的存在性，并提出了鲁棒的先验和后验误差估计方法，这对于数值模拟的准确性和效率至关重要。引入新颖的离散不等式以应对Forchheimer非线性是其技术亮点之一。此外，采用高度并行的自适应网格细化算法结合轻量级数据结构，显著提升了实际应用的效率和收敛性能。

<details>
  <summary>Details</summary>

**Motivation:** 解决不可压缩流体在高度渗透多孔介质中流动时，Navier--Stokes--Brinkman--Forchheimer方程在涡度-速度-伯努利压力形式下导致的双鞍点问题。

**Method:** 使用最低阶分段无散度Crouzeix--Raviart有限元；涡度采用带有法向和切向速度跳跃惩罚项的压力空间向量版本；利用Raviart--Thomas插值器获得压力鲁棒的先验误差估计；采用基于残差的显式后验误差估计进行误差控制；为Forchheimer非线性引入了新的离散不等式；实现基于轻量级树林数据结构和高度并行的自适应网格细化算法。

**Result:** 建立了小源情况下连续和离散解的存在性；获得了压力鲁棒的先验误差估计；实现了高效可靠的后验误差控制；数值模拟显示后验误差估计的鲁棒性；通过自适应网格细化提高了收敛速度。

**Conclusion:** 本文成功建立了Navier--Stokes--Brinkman--Forchheimer问题在涡度-速度-压力形式下的解的存在性，并提供了鲁棒且高效的误差估计和控制方法，通过自适应网格细化显著提升了收敛性能。

> **ai_Abstract:** 本文提出了一种Navier--Stokes--Brinkman--Forchheimer问题的非增广速度-涡度-压力公式，旨在解决不可压缩流体在多孔介质中流动产生的双鞍点问题。研究建立了连续和离散层面解的存在性，并开发了压力鲁棒的先验误差估计和高效可靠的后验误差控制方法，其中包含一个新颖的离散不等式以处理Forchheimer非线性。通过结合轻量级数据结构和自适应网格细化算法，数值模拟验证了所提方法的鲁棒性，并展示了通过自适应网格细化实现的收敛速度提升。

> **摘要翻译:** 不可压缩流体在涡度-速度-伯努利压力形式的高度渗透多孔介质中的流动导致Navier--Stokes--Brinkman--Forchheimer方程中的双鞍点问题。本文对于小源情况，建立了最低阶分段无散度Crouzeix--Raviart有限元在连续和离散层面的解的存在性。涡度采用了压力空间的向量版本，并带有法向和切向速度跳跃惩罚项。一个简单的Raviart--Thomas插值器带来了压力鲁棒的先验误差估计。显式的基于残差的后验误差估计允许高效可靠的后验误差控制。Forchheimer非线性的效率需要一个独立兴趣的新颖离散不等式。实现基于轻量级树林数据结构，由一套高度并行的自适应网格细化算法处理。数值模拟揭示了后验误差估计的鲁棒性以及通过自适应网格细化提高的收敛速度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [245] [Structure and asymptotic preserving deep neural surrogates for uncertainty quantification in multiscale kinetic equations](https://arxiv.org/abs/2506.10636)
> *多尺度动理学方程不确定性量化的结构和渐近保持深度神经网络代理模型*

*Wei Chen, Giacomo Dimarco, Lorenzo Pareschi* | **Main category: math.NA**

**Keywords:** 不确定性量化, 动理学方程, 深度学习, 代理模型, 蒙特卡洛

**Comment:** 

> **TL;DR:** 本文提出了一种结合多尺度控制变量和结构渐近保持神经网络（SAPNNs）的方法，用于解决动理学方程不确定性量化中的计算挑战，显著提高了采样效率、方差减少和物理一致性。

**AI_Comments:** 本文的创新点在于将多尺度控制变量与专门设计的结构和渐近保持神经网络（SAPNNs）相结合，以解决高维动理学方程不确定性量化中的计算难题。SAPNNs的设计确保了物理守恒律和渐近行为的保留，这对于物理建模至关重要。该方法在提高计算效率和精度方面表现出色，并能处理大规模预测，对多尺度物理系统的不确定性量化研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动理学方程的高维性及其随机参数给不确定性量化（UQ）带来了巨大的计算挑战。传统的蒙特卡洛（MC）采样方法收敛速度慢且方差大，随着参数空间维度的增加，这些问题变得更加严重。

**Method:** 为了加速蒙特卡洛采样，本文采用了多尺度控制变量策略，利用简化动理学模型的低保真解来减少方差。为了进一步提高采样效率并保持底层物理特性，引入了基于结构和渐近保持神经网络（SAPNNs）的代理模型。这些深度神经网络被专门设计来满足关键的物理属性，包括正性、守恒定律、熵耗散和渐近极限。通过在低保真模型上训练SAPNNs，并用来自完整玻尔兹曼方程的选定高保真样本进行丰富，该方法实现了方差减少。

**Result:** 该方法在保持物理一致性和渐近精度的同时，实现了显著的方差减少。所提出的方法能够在动理学不确定性量化中进行高效的大规模预测，并在同质和非同质多尺度机制下得到验证。数值结果表明，与标准蒙特卡洛技术相比，该方法提高了精度和计算效率。

**Conclusion:** 本文提出的结合多尺度控制变量和结构渐近保持神经网络（SAPNNs）的方法，有效解决了动理学方程不确定性量化中的计算难题，显著提高了采样效率、精度和物理一致性，为大规模预测提供了高效工具。

> **ai_Abstract:** 本文针对高维动理学方程不确定性量化中蒙特卡洛采样效率低的问题，提出了一种结合多尺度控制变量和结构渐近保持神经网络（SAPNNs）的新方法。该方法利用低保真模型减少方差，并设计SAPNNs以满足关键物理属性。通过在低保真模型上训练并在高保真样本上丰富，该方法显著提高了采样效率、方差减少、物理一致性和计算效率，适用于大规模动理学不确定性量化预测。

> **摘要翻译:** 具有随机参数的动理学方程的高维性对不确定性量化（UQ）提出了重大的计算挑战。传统的蒙特卡洛（MC）采样方法虽然被广泛使用，但存在收敛缓慢和方差大的问题，随着参数空间维度的增加，这些问题变得越来越严重。为了加速蒙特卡洛采样，我们采用了多尺度控制变量策略，该策略利用简化动理学模型的低保真解来减少方差。为了进一步提高采样效率并保持底层物理特性，我们引入了基于结构和渐近保持神经网络（SAPNNs）的代理模型。这些深度神经网络被专门设计来满足关键的物理属性，包括正性、守恒定律、熵耗散和渐近极限。通过在低保真模型上训练SAPNNs，并用来自完整玻尔兹曼方程的选定高保真样本进行丰富，我们的方法在保持物理一致性和渐近精度的同时，实现了显著的方差减少。所提出的方法能够在动理学不确定性量化中进行高效的大规模预测，并在同质和非同质多尺度机制下得到验证。数值结果表明，与标准蒙特卡洛技术相比，该方法提高了精度和计算效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [256] [Alternating steepest descent methods for tensor completion with applications to spectromicroscopy](https://arxiv.org/abs/2506.10661)
> *用于张量补全的交替最速下降方法及其在光谱显微镜中的应用*

*Oliver Townsend, Sergey Dolgov, Silvia Gazzola, Misha Kilmer* | **Main category: math.NA**

**Keywords:** 张量补全, 交替最速下降, $\\star_{M}$-乘积, 光谱显微镜, 欠采样

**Comment:** 

> **TL;DR:** 本文提出了两种基于张量交替最速下降算法，用于低秩张量补全，并应用于X射线光谱显微镜数据，证明了其在减少样本量的情况下能达到与矩阵补全算法相同的重建误差。

**AI_Comments:** 这项研究的创新之处在于将传统的矩阵补全ASD方法扩展到张量领域，并引入了$\\star_{M}$-乘积格式来处理张量数据，特别是针对X射线光谱显微镜的实际应用。通过提出两种不同的实现方式，提供了解决张量欠采样问题的有效途径，并且证明了其在减少数据采集量方面的优越性，这对于实际应用具有重要意义。该工作强调了张量方法在处理高维稀疏数据方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 旨在从少量测量中重建整个低秩张量。具体针对X射线光谱显微镜欠采样问题，该问题导致数据仅部分扫描，形成张量补全问题。

**Method:** 开发了两种新的张量交替最速下降算法（Tensor Alternating Steepest Descent algorithms）用于低秩$\\star_{M}$-乘积格式的张量补全。两种算法都源自矩阵补全的交替最速下降（ASD）方法。方法1：ASD在$\\star_{M}$-诱导度量空间中的重构。方法2：求解一组（易于并行化）独立的矩阵补全问题，针对变换后张量的前切片。可以对张量按管（tube）应用任何变换（如傅里叶变换）。

**Result:** 这两种新方法在真实的X射线光谱显微镜数据上进行了测试，结果表明，与应用于扁平张量的矩阵补全算法相比，它们在从张量中获取更少样本的情况下，实现了相同的重建误差。

**Conclusion:** 本文提出的两种张量交替最速下降算法能有效解决低秩张量补全问题，特别是在光谱显微镜等应用中，可以在减少数据采集量的同时保持重建精度。

> **ai_Abstract:** 本文提出了两种新颖的张量交替最速下降算法，用于解决低秩$\\star_{M}$-乘积格式下的张量补全问题。这些算法基于矩阵补全的ASD方法，并特别应用于X射线光谱显微镜中的数据欠采样问题。其中一种算法是在$\\star_{M}$-诱导度量空间中重构ASD，另一种则通过并行解决变换后张量前切片的独立矩阵补全问题。实验结果表明，与传统矩阵补全方法相比，这两种新方法在样本量更少的情况下能达到相同的重建精度。

> **摘要翻译:** 本文提出了两种用于低秩$\\star_{M}$-乘积格式张量补全的新型张量交替最速下降算法，旨在从少量测量中重建整个低秩张量。这两种算法都源于[J. Tanner和K. Wei, Appl. Comput. Harmon. Anal., 40 (2016), pp. 417-429]首次提出的矩阵补全交替最速下降（ASD）方法。在推导新方法时，我们针对X射线光谱显微镜欠采样问题，即通过用不同能量的X射线束扫描矩形视场的样本来收集数据。混合样本材料的记录吸收系数自然地存储在三阶张量中，具有空间水平和垂直轴以及能量轴。为了加快X射线光谱显微镜测量过程，该张量（或其重塑版本）只有一小部分管被完全扫描，从而导致一个张量补全问题。在此框架中，我们可以逐管地对张量应用任何变换（例如傅里叶变换），提供了一种与$\\star_{M}$-张量代数自然协作的方式，并提出了：(1) 一种本质上是ASD在$\\star_{M}$-诱导度量空间中重新公式化的张量补全算法；(2) 一种通过解决变换张量前切片的一组（易于并行化）独立的矩阵补全问题来实现张量补全的算法。这两种新方法在真实的X射线光谱显微镜数据上进行了测试，证明与应用于扁平张量的矩阵补全算法相比，它们在从张量中获取更少样本的情况下，实现了相同的重建误差。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [271] [Semi-discrete moduli of smoothness and their applications in one- and two- sided error estimates](https://arxiv.org/abs/2506.10723)
> *半离散光滑模及其在单边和双边误差估计中的应用*

*Danilo Costarelli, Donato Lavella* | **Main category: math.NA**

**Keywords:** 半离散光滑模, 误差估计, 逼近理论, K-泛函, Steklov积分

**Comment:** 

> **TL;DR:** 本文引入了一种新的半离散光滑模，推广了现有定义，并在非限制性假设下建立了单边和双边误差估计，适用于更广泛的算子类型，并能获得更尖锐的估计。

**AI_Comments:** 该论文在逼近理论领域具有重要意义。它通过引入新的半离散光滑模，不仅推广了现有定义，还显著扩展了其适用范围，使其能够处理非三角型算子，这是对以往研究的一个重要突破。此外，能够获得更尖锐的误差估计也提升了理论的实用性。对K-泛函的引入和等价性证明也进一步丰富了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 推广Kolomoitsev和Lomako (KL)于2023年给出的半离散光滑模的定义，并在非限制性假设下建立更一般的单边和双边误差估计，解决KL定理仅适用于三角型算子的问题，使其适用于非三角型算子，并获得比经典平均光滑模（$\tau$-模）更尖锐的估计。

**Method:** 引入了一种新的半离散光滑模；利用Sendov和Popov于1983年引入的某些Steklov积分的正则化和逼近性质；建立了Rathore型定理；引入了新的K-泛函概念并证明其与半离散光滑模及其实现等价性。

**Result:** 建立了非常一般的单边和双边误差估计，且在非限制性假设下；所提出的结果与Kolomoitsev和Lomako的结果不同；新的半离散光滑模定义能够应用于非三角型算子，并能推导出比经典平均光滑模更尖锐的估计；证明了新的K-泛函与半离散光滑模及其实现的等价性；在有界域上的经典算子（如Bernstein多项式）和整个实数线上的逼近算子（如Shannon采样级数、广义采样算子）均可建立单边逼近估计。

**Conclusion:** 本文引入了一种新的半离散光滑模，成功推广了现有定义，并在更广泛的条件下建立了通用的单边和双边误差估计，使其适用于更多类型的算子并提供更精确的估计。研究还考虑了代数拉格朗日逼近中双边误差估计的开放问题。

> **ai_Abstract:** 本文提出了一种新的半离散光滑模，推广了Kolomoitsev和Lomako的定义，并在非限制性条件下建立了更通用的单边和双边误差估计。研究利用Steklov积分的性质，解决了现有方法仅限于三角型算子的问题，使得新方法能应用于更广泛的算子类型，并能获得比传统方法更精确的估计。文中还建立了一个Rathore型定理，并引入了与半离散光滑模等价的K-泛函。新方法可用于经典算子如Bernstein多项式以及Shannon采样级数等，并讨论了代数拉格朗日逼近中双边误差估计的开放问题。

> **摘要翻译:** 本文引入了一种新的半离散光滑模，它推广了Kolomoitsev和Lomako（KL）于2023年（发表在《逼近理论杂志》上的论文中）给出的定义，并在非限制性假设下建立了非常普遍的单边和双边误差估计。所提出的结果是利用Sendov和Popov于1983年引入的某些Steklov积分的正则化和逼近性质证明的，并且与Kolomoitsev和Lomako给出的结果不同。此外，原始KL逼近定理的证明与三角最佳逼近的某些经典结果的应用密切相关，因此，它们仅适用于三角型算子。通过本文提出的半离散光滑模的定义，我们也能够推导出适用于不一定是三角型算子的应用，并且还可以用于推导出比经典平均光滑模（$\tau$-模）更尖锐的估计。此外，还建立了一个Rathore型定理，并引入了一个新的K-泛函概念，显示了其与半离散光滑模及其实现的等价性。对于有界域上的经典算子，例如Bernstein多项式，可以建立单边逼近估计。在整个实数线上的逼近算子的情况下，可以实现单边估计，例如Shannon采样（基数）级数以及所谓的广义采样算子。在论文的最后，考虑了代数拉格朗日逼近的情况，展示了在该值得关注的情况下推导双边误差估计的主要开放问题。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [284] [Reduced-Order Time Splitting for Navier-Stokes with Open Boundaries](https://arxiv.org/abs/2506.10763)
> *针对开放边界Navier-Stokes方程的降阶时间分裂法*

*Mejdi Azaïez, Tomás Chacón Rebollo, Carlos Núñez Fernández, Samuele Rubino* | **Main category: math.NA**

**Keywords:** Navier-Stokes方程, 降阶模型, 时间分裂, 开放边界条件, POD-ROM

**Comment:** 

> **TL;DR:** 本文提出了一种结合时间分裂、开放边界条件非标准处理和降阶模型（POD-ROM）的方法，旨在显著减少Navier-Stokes方程的求解时间，并通过数值实验比较了全侵入式和混合式POD-ROM的效率和精度。

**AI_Comments:** 论文通过结合多种现有技术（时间分裂、降阶模型、非标准边界条件）来解决Navier-Stokes方程的计算效率问题，具有一定的创新性。特别是对全侵入式和混合式POD-ROM的比较分析，对于理解和选择合适的降阶模型在实际应用中具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过结合时间分裂、计算域缩减（通过非标准开放边界条件处理）和降阶建模（POD-ROM）三种策略，减少Navier-Stokes方程求解的计算时间。

**Method:** 提出了一种应用于Navier-Stokes方程开放边界条件的时间分裂方案，采用一阶欧拉时间离散化并推导了非标准压力边界条件。构建了基于Galerkin投影的POD-ROM，并对出口压力边界条件进行了两种不同处理。比较了标准的全侵入式投影POD-ROM和结合了基于投影（侵入式）与数据驱动（非侵入式，使用径向基函数RBF）技术的混合POD-ROM的性能。通过分叉管内流动和绕圆柱体流动两个数值算例进行验证。

**Result:** 论文通过数值算例比较了标准全侵入式POD-ROM与混合POD-ROM在效率和精度方面的表现，并进行了数值调查。

**Conclusion:** 论文成功地提出了结合时间分裂、开放边界处理和降阶建模的Navier-Stokes方程求解方法，并通过数值实验比较了全侵入式和混合POD-ROM的效率和精度。

> **ai_Abstract:** 本文提出了一种针对开放边界Navier-Stokes方程的降阶时间分裂方法，旨在显著减少计算时间。该方法融合了时间分裂、非标准开放边界条件处理和本征正交分解降阶模型（POD-ROM）。文章详细阐述了时间分裂方案的公式化，并构建了基于Galerkin投影的POD-ROM。特别地，研究对比了标准的全侵入式POD-ROM与结合了数据驱动技术的混合POD-ROM的性能，并通过分叉管流动和绕圆柱体流动等数值算例验证了这两种模型的效率和精度。

> **摘要翻译:** 在这项工作中，我们提出了一种应用于Navier-Stokes方程开放边界条件下时间分裂方案的本征正交分解降阶模型（POD-ROM）。在该方法中，我们结合了三种策略来减少求解Navier-Stokes方程的计算时间：时间分裂、通过开放边界条件的非标准处理来缩小计算域以及降阶建模。为了使工作自洽，我们首先介绍了应用于Navier-Stokes方程开放边界条件的时间分裂方案的公式，采用了首次欧拉时间离散化并推导了压力的非标准边界条件。然后，我们构建了一个基于Galerkin投影的ROM，该ROM使用POD，并在出口处对压力边界条件进行了两种不同的处理。我们提出了一种比较标准基于投影的POD-ROM（完全侵入式）和结合了基于投影方法（侵入式）与数据驱动技术（非侵入式）使用径向基函数（RBF）的混合POD-ROM的性能分析。我们通过两个不同的数值测试来阐明这种比较：分叉管中的流动和绕圆柱体流动的基准数值测试，数值研究了两种ROM的效率和精度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [294] [A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for Nonlinear Differential Equations](https://arxiv.org/abs/2506.10820)
> *一种用于非线性微分方程的并行时间直接逆（ParaDIn）-Parareal组合方法*

*Subhash Paudel, Nail K. Yamaleev* | **Main category: math.NA**

**Keywords:** 并行时间积分, ParaDIn, Parareal, 非线性微分方程, 加速比

**Comment:** 24 pages. arXiv admin note: text overlap with arXiv:2406.00878

> **TL;DR:** 为了克服ParaDIn方法在并行时间层数上的限制并进一步提高加速比，本文提出了一种将ParaDIn与Parareal算法结合的新方法。该方法通过ParaDIn并行化Parareal的粗细网格传播器，在非线性偏微分方程的求解中实现了显著的并行性能提升，最高加速比达124倍。

**AI_Comments:** 该论文的创新点在于巧妙地结合了ParaDIn和Parareal两种并行时间积分方法，有效地解决了ParaDIn在时间层数上的限制。尤其值得注意的是，通过ParaDIn并行化Parareal的粗细网格传播器，显著提升了传统Parareal算法的并行度，这对于大规模非线性微分方程的并行求解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** ParaDIn方法在并行时间层数（$N_t$）上存在最大限制，阻碍了其进一步的加速能力。

**Method:** 本文提出了一种结合ParaDIn和Parareal算法的方法。核心思想是使用一个块-雅可比预处理器，其中每个块都通过ParaDIn方法求解。为了加速雅可比迭代的收敛，使用Parareal方法（可解释为时间上的两级多重网格方法）。与传统Parareal不同，新方法中粗网格和细网格的传播器都通过ParaDIn方法并行实现。

**Result:** 数值结果表明，与顺序一阶隐式后向差分（BDF1）方案相比，新的ParaDIn-Parareal组合方法在480个计算核心上，对于二维非线性热方程和Burgers方程（包括光滑和不连续解），提供了高达124倍的加速。

**Conclusion:** 结合ParaDIn和Parareal算法能够有效克服ParaDIn的时间层数限制，并通过并行化Parareal的粗细网格传播器，显著提升非线性微分方程并行求解的性能。

> **ai_Abstract:** 本文提出了一种结合并行时间直接逆（ParaDIn）和Parareal算法的新方法，旨在克服ParaDIn方法在并行时间层数上的限制并提高加速比。该方法采用块-雅可比预处理器，并利用ParaDIn求解每个块；同时，通过将Parareal解释为时间上的两级多重网格方法来加速收敛。与传统Parareal不同，本方法将粗细网格传播器均并行化。数值结果显示，新方法在480个核心上，对于2D非线性热方程和Burgers方程，相较于顺序BDF1方案，实现了高达124倍的加速。

> **摘要翻译:** 正如我们之前的工作所示，由Yamaleev和Paudel在（arXiv: 2406.00878v1, 2024）中引入的并行时间直接逆（ParaDIn）方法对可以并行积分的最大时间层数$N_t$施加了一些限制。为了规避这个问题并进一步提高加速比，我们将ParaDIn方法与Parareal算法结合起来，以有效地并行化通过线法离散的非线性偏微分方程中的一阶时间导数项。所提出方法的主要思想是使用块-雅可比预处理器，以便每个块都通过ParaDIn方法求解。为了加速雅可比迭代的收敛，我们使用Parareal方法，该方法可以解释为时间上的两级多重网格方法。与传统的Parareal算法（其粗网格校正步骤是顺序执行的）不同，所提出方法中的粗网格和细网格传播器都通过ParaDIn方法并行实现，从而显著提高了组合算法的并行性能。数值结果表明，与顺序一阶隐式后向差分（BDF1）方案相比，新的ParaDIn-Parareal组合方法在480个计算核心上，对于二维非线性热方程和Burgers方程（包括光滑和不连续解），提供了高达124倍的加速。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [305] [Numerical approximation of a PDE-constrained Optimization problem that appears in Data-Driven Computational Mechanics](https://arxiv.org/abs/2506.10894)
> *数据驱动计算力学中偏微分方程约束优化问题的数值近似*

*Pedro B. Bazon, Cristian G. Gebhardt, Gustavo C. Buscaglia, Roberto F. Ausas* | **Main category: math.NA**

**Keywords:** 数据驱动计算力学, 偏微分方程约束优化, 有限元离散化, 鞍点结构, 适定性

**Comment:** 

> **TL;DR:** 本文研究了数据驱动计算力学中的一个PDE约束优化问题，提出了稳定的有限元离散化方法，并验证了其有效性。

**AI_Comments:** 本文的创新之处在于提出了保持鞍点结构并允许所有场进行等阶插值的稳定有限元离散化方法，这对于处理数据驱动计算力学中的PDE约束优化问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在数据驱动计算力学范式中，需要寻找最接近给定材料数据集离散场的连续原始场（梯度和通量），该优化问题是受物理守恒定律和几何兼容性约束的。

**Method:** 首先，在连续设置中建立了问题的适定性。然后，提出了稳定的有限元离散化方法，该方法能够一致地近似连续公式，保留其鞍点结构，并允许所有场进行等阶插值。

**Result:** 通过一系列数值示例，证明了所提出方法的有效性。

**Conclusion:** 所提出的数值方法能够有效近似数据驱动计算力学中的偏微分方程约束优化问题。

> **ai_Abstract:** 本文研究了数据驱动计算力学中出现的偏微分方程约束优化问题。该问题旨在寻找最接近预定义离散材料数据集的连续原始场，同时满足物理守恒定律和几何兼容性。文章首先建立了连续设置下的适定性，然后提出了稳定的有限元离散化方法，该方法保留了连续公式的鞍点结构并允许等阶插值。最后，通过数值示例验证了方法的有效性。

> **摘要翻译:** 我们研究了在数据驱动计算力学范式中出现的一个优化问题。在扩散-反应问题的背景下，这种优化问题旨在寻找最接近从材料数据集中获取的某些预定义离散场的连续原始场（梯度和通量）。优化是在满足物理守恒定律和几何兼容性的原始场上进行的。我们在守恒定律中考虑了一个反应项，这会耦合所有的最优性条件。我们首先在连续设置中建立了适定性。然后，我们提出了稳定的有限元离散化方法，这些方法能够一致地近似连续公式，保留其鞍点结构并允许所有场进行等阶插值。最后，我们通过一系列数值示例证明了所提出方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [316] [Accelerating Newton-Schulz Iteration for Orthogonalization via Chebyshev-type Polynomials](https://arxiv.org/abs/2506.10935)
> *通过切比雪夫型多项式加速牛顿-舒尔茨正交迭代*

*Ekaterina Grishina, Matvey Smirnov, Maxim Rakhuba* | **Main category: math.NA**

**Keywords:** 牛顿-舒尔茨迭代, 正交化, 切比雪夫多项式, 矩阵近似, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了一种基于切比雪夫多项式优化的牛顿-舒尔茨迭代（CANS），解决了其系数固定不优化的限制，并在机器学习应用中展示了其有效性。

**AI_Comments:** 本文的创新点在于将切比雪夫多项式引入牛顿-舒尔茨迭代，通过优化迭代系数克服了传统方法的固有局限性。这种方法不仅提升了计算效率，还为深度学习和黎曼优化等领域提供了更灵活、更精确的正交化工具，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有牛顿-舒尔茨迭代在矩阵正交近似计算中虽然高效，但其系数是固定的，未针对特定矩阵进行优化，限制了其性能。

**Method:** 论文提出了切比雪夫优化版的牛顿-舒尔茨（CANS）方法，通过切比雪夫交错定理理论推导了三阶牛顿-舒尔茨迭代的最优系数，并利用Remez算法计算更高阶的最优多项式，从而构建受控的近似正交化方案。

**Result:** CANS方法在Muon优化器中的正交化以及作为Stiefel流形上黎曼优化的有效收缩替代方案中，均表现出实际的有效性。

**Conclusion:** 本文成功提出并验证了CANS方法，通过优化牛顿-舒尔茨迭代的系数，显著提升了矩阵正交近似计算的效率和灵活性，为深度学习和黎曼优化提供了新的高效工具。

> **ai_Abstract:** 本文针对牛顿-舒尔茨迭代在矩阵正交近似计算中系数固定、非最优的问题，提出了一种切比雪夫优化版的牛顿-舒尔茨（CANS）方法。该方法利用切比雪夫交错定理推导最优系数，并通过Remez算法计算高阶最优多项式，从而构建高效且受控的近似正交化方案。实验证明，CANS在Muon优化器和Stiefel流形上的黎曼优化中均表现出显著的有效性。

> **摘要翻译:** 矩阵最优正交近似计算问题在机器学习领域引起了日益增长的兴趣。显著的应用包括最近的Muon优化器或Stiefel流形上的黎曼优化。在现有方法中，牛顿-舒尔茨迭代已成为一种特别有效的解决方案，因为它仅依赖于矩阵乘法，因此在GPU硬件上实现了高计算效率。尽管效率高，但该方法存在固有的局限性——其系数是固定的，因此未针对给定矩阵进行优化。在本文中，我们通过提出切比雪夫优化版牛顿-舒尔茨（CANS）来解决这个问题。基于切比雪夫交错定理，我们理论推导了三阶牛顿-舒尔茨迭代的最优系数，并应用Remez算法计算最优的高阶多项式。我们利用这些多项式来构建受控的近似正交化方案，这在深度学习应用中具有重要意义。实际上，我们在两个关键应用中展示了该方法的有效性：Muon优化器中的正交化，以及为Stiefel流形上的黎曼优化提供高效的收缩替代方案。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [30] [Description and Discussion on DCASE 2025 Challenge Task 2: First-shot Unsupervised Anomalous Sound Detection for Machine Condition Monitoring](https://arxiv.org/abs/2506.10097)
> *DCASE 2025挑战赛任务2：机器状态监测的首次无监督异常声音检测的描述与讨论*

*Tomoya Nishida, Noboru Harada, Daisuke Niizumi, Davide Albertini, Roberto Sannino, Simone Pradolini, Filippo Augusti, Keisuke Imoto, Kota Dohi, Harsh Purohit, Takashi Endo, Yohei Kawaguchi* | **Main category: cs.SD**

**Keywords:** 异常声音检测, 机器状态监测, DCASE 挑战赛, 首次学习, 域泛化

**Comment:** this article draws heavily from arXiv:2406.07250v1

> **TL;DR:** 介绍了DCASE 2025挑战赛任务2，该任务旨在通过首次无监督异常声音检测，实现新机器类型ASD系统的快速部署，无需特定机器的超参数调整。

**AI_Comments:** 这篇论文介绍了一个重要的挑战任务，旨在推动异常声音检测技术在工业应用中的实际部署。其创新点在于采用了“首次无监督”和“域泛化”框架，旨在解决现有ASD系统在新机器类型上部署时需要大量标记数据和手动调优的问题。这对于实现更高效、更通用的机器状态监测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该任务的主要目标是促进异常声音检测（ASD）系统在新机器类型上的快速部署，而无需针对特定机器进行超参数调整，从而解决实际应用中的部署效率问题。

**Method:** 该任务是DCASE 2025挑战赛任务2，构建在DCASE 2024挑战赛任务2之上，被构建为一个在域泛化框架内的“首次”问题。评估数据集包含了来自先前未见过的机器类型的声音。

**Result:** 未提及摘要。

**Conclusion:** 未提及摘要。

> **ai_Abstract:** 本文详细阐述了DCASE 2025挑战赛任务2，即“机器状态监测的首次无监督异常声音检测”的具体内容。该任务旨在通过“首次”方法，在域泛化框架下，实现异常声音检测系统对新型机器的快速部署，且无需进行繁琐的机器特定超参数调整。为此，挑战赛提供了包含未见机器类型声音的评估数据集。论文指出，挑战赛结果和分析将在提交截止日期后公布。

> **摘要翻译:** 本文介绍了检测与分类声学场景与事件（DCASE）2025挑战赛任务2的任务描述，该任务题为“用于机器状态监测的首次无监督异常声音检测（ASD）”。该任务建立在DCASE 2024挑战赛任务2的基础上，被构建为一个域泛化框架内的“首次”问题。首次方法的主要目标是促进异常声音检测系统在新机器类型上的快速部署，而无需机器特定的超参数调整。对于DCASE 2025挑战赛任务2，已收集并提供了来自先前未见过的机器类型声音作为评估数据集。挑战赛提交截止日期后，将补充挑战赛提交结果和分析。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [56] [FedMLAC: Mutual Learning Driven Heterogeneous Federated Audio Classification](https://arxiv.org/abs/2506.10207)
> *FedMLAC：互学习驱动的异构联邦音频分类*

*Jun Bai, Rajib Rana, Di Wu, Youyang Qu, Xiaohui Tao, Ji Zhang* | **Main category: cs.SD**

**Keywords:** 联邦学习, 音频分类, 互学习, 异构性, 数据投毒

**Comment:** initial version

> **TL;DR:** FedMLAC是一个统一的互学习框架，通过双模型架构和层级剪枝聚合策略，解决了联邦音频分类中的数据异构性、模型异构性和数据投毒问题，并显著提高了性能和鲁棒性。

**AI_Comments:** FedMLAC的创新点在于提出了一个统一的框架来同时解决联邦学习中的多个异构性和鲁棒性挑战，而不是分别处理。双模型架构结合知识蒸馏，以及针对数据投毒的LPA策略，为实际联邦音频应用提供了更全面的解决方案，展示了其在复杂联邦环境下的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦音频分类（FedAC）面临数据异构性、模型异构性和数据投毒三大挑战，现有方法通常独立解决这些问题，缺乏适用于真实世界联邦音频场景的统一且鲁棒的解决方案。

**Method:** 本文提出了FedMLAC，一个统一的互学习框架，旨在同时解决联邦音频分类中的数据异构性、模型异构性和数据投毒问题。具体而言，FedMLAC在每个客户端引入了双模型架构，包括一个个性化本地AC模型和一个轻量级、全局共享的Plug-in模型。通过双向知识蒸馏，Plug-in模型能够实现全局知识迁移并适应客户端特定数据分布，从而支持泛化和个性化。此外，为增强对损坏音频数据的鲁棒性，开发了一种层级剪枝聚合（LPA）策略，该策略在服务器端聚合期间根据参数偏差过滤不可靠的Plug-in模型更新。

**Result:** 在涵盖语音和非语音任务的四个不同音频分类基准测试上进行的广泛实验表明，FedMLAC在分类准确性和对噪声数据的鲁棒性方面始终优于现有最先进的方法。

**Conclusion:** FedMLAC通过其统一的互学习框架和鲁棒的聚合策略，成功解决了联邦音频分类中的多重挑战，显著提升了性能和鲁棒性。

> **ai_Abstract:** 本文提出了FedMLAC，一个统一的互学习框架，旨在解决联邦音频分类（FedAC）中数据异构性、模型异构性和数据投毒等核心挑战。FedMLAC在客户端采用双模型架构（个性化本地模型和全局Plug-in模型），并通过双向知识蒸馏实现知识共享与个性化。此外，引入层级剪枝聚合策略增强对抗恶意数据的鲁棒性。实验证明，FedMLAC在多个音频分类任务上显著优于现有SOTA方法，提升了准确性和抗噪能力。

> **摘要翻译:** 联邦学习（FL）提供了一种隐私保护范式，可以在不共享原始数据的情况下，在分布式客户端上训练音频分类（AC）模型。然而，联邦音频分类（FedAC）面临三个严重阻碍性能的关键挑战：数据异构性、模型异构性和数据投毒。尽管先前的研究试图解决这些问题，但它们通常是独立处理的，缺乏适用于真实世界联邦音频场景的统一且鲁棒的解决方案。为了弥补这一空白，我们提出了FedMLAC，一个统一的互学习框架，旨在同时解决FedAC中的这些挑战。具体来说，FedMLAC在每个客户端引入了一个双模型架构，包括一个个性化本地AC模型和一个轻量级、全局共享的Plug-in模型。通过双向知识蒸馏，Plug-in模型能够实现全局知识迁移，同时适应客户端特定数据分布，从而支持泛化和个性化。为了进一步增强对损坏音频数据的鲁棒性，我们开发了一种层级剪枝聚合（LPA）策略，该策略在服务器端聚合期间根据参数偏差过滤不可靠的Plug-in模型更新。在涵盖语音和非语音任务的四个不同音频分类基准测试上进行的广泛实验表明，FedMLAC在分类准确性和对噪声数据的鲁棒性方面始终优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [81] [Fine-Grained control over Music Generation with Activation Steering](https://arxiv.org/abs/2506.10225)
> *音乐生成中的激活转向细粒度控制*

*Dipanshu Panda, Jayden Koshy Joe, Harshith M R, Swathi Narashiman, Pranay Mathur, Anish Veerakumar, Aniruddh Krishna, Keerthiharan A* | **Main category: cs.SD**

**Keywords:** 音乐生成, 细粒度控制, 激活转向, MusicGen, 推理时干预

**Comment:** 

> **TL;DR:** 通过在自回归音乐生成模型MusicGen中进行推理时干预，实现对音乐生成细粒度控制的方法，包括音色、风格和流派融合。

**AI_Comments:** 该论文的创新点在于提出了通过“激活转向”这种推理时干预的方式，在预训练的生成模型上实现细粒度控制，而无需重新训练整个模型。将控制任务建模为回归问题并利用MSE是一种新颖且有效的方法，有助于在激活空间中保持信息。这种方法为音乐生成提供了强大的局部和全局控制能力，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法可能缺乏细粒度控制，或者研究者希望在MusicGen模型中实现更精细的控制，以实现音色迁移、风格迁移和流派融合。

**Method:** 在MusicGen模型中，通过线性探针训练的权重引导残差流，或类似地引导注意力层激活，来实现推理时干预。将此建模为回归任务，使用均方误差(MSE)来更好地保留激活空间中的方向信息，从而提高性能。结合MusicGen文本提示提供的全局条件，实现全局和局部控制。

**Result:** 该方法实现了音色迁移、风格迁移和流派融合。将任务建模为回归任务提高了性能。

**Conclusion:** 该方法结合MusicGen的全局条件，提供了对音乐生成的全局和局部细粒度控制。

> **ai_Abstract:** 本文提出了一种在MusicGen自回归音乐生成模型中实现细粒度控制的新方法，即通过推理时干预，引导残差流或注意力层激活。该方法通过将控制建模为回归任务并利用均方误差，有效地实现了音色迁移、风格迁移和流派融合，并结合文本提示实现了音乐生成的全局和局部控制。

> **摘要翻译:** 我们提出了一种通过对自回归生成音乐Transformer模型MusicGen进行推理时干预来对音乐生成进行细粒度控制的方法。我们的方法通过使用在其上训练的线性探针的权重引导残差流，或以类似方式引导注意力层激活，从而实现音色迁移、风格迁移和流派融合。我们观察到将其建模为回归任务可以提高性能，推测均方误差能更好地保留激活空间中有意义的方向信息。结合MusicGen中文本提示提供的全局条件，我们的方法提供了对音乐生成的全局和局部控制。说明我们方法的音频样本可在我们的演示页面上获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [107] [Discrete Audio Tokens: More Than a Survey!](https://arxiv.org/abs/2506.10274)
> *离散音频Tokens：不仅仅是综述！*

*Pooneh Mousavi, Gallil Maimon, Adel Moumen, Darius Petermann, Jiatong Shi, Haibin Wu, Haici Yang, Anastasia Kuznetsova, Artem Ploujnikov, Ricard Marxer, Bhuvana Ramabhadran, Benjamin Elizalde, Loren Lugosch, Jinyu Li, Cem Subakan, Phil Woodland, Minje Kim, Hung-yi Lee, Shinji Watanabe, Yossi Adi, Mirco Ravanelli* | **Main category: cs.SD**

**Keywords:** 离散音频Token, 音频Token化, 系统综述, 基准测试, 大型语言模型

**Comment:** 

> **TL;DR:** 本文对离散音频Token化方法进行了系统性回顾和基准测试，涵盖语音、音乐和通用音频三个领域，提出了分类法，评估了不同Token化器，并指出了未来的研究方向。

**AI_Comments:** 本文超越了简单的文献综述，通过系统性的基准测试和分类法，为离散音频Token化领域提供了全面的分析。其创新之处在于统一了不同领域的评估标准，并深入剖析了现有方法的局限性，对推动音频与LLM的融合具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于离散音频Token化的研究和综述通常侧重于特定领域或任务，缺乏在各种基准测试中进行统一比较。

**Method:** 本文对离散音频Token化器进行了系统性回顾和基准测试，涵盖语音、音乐和通用音频三个领域。文章提出了一种基于编码器-解码器、量化技术、训练范式、可流式传输性和应用领域的Token化方法分类法。研究人员在重建、下游任务性能和声学语言建模等多个基准上评估了Token化器，并通过受控消融研究分析了权衡。

**Result:** 研究结果揭示了关键局限性、实际考虑因素和开放挑战，为该快速发展领域的未来研究提供了见解和指导。

**Conclusion:** 离散音频Token化在整合语音和音频到大型语言模型中具有巨大潜力，但仍存在关键局限性、实际考虑和开放挑战，需要未来研究的深入探索。

> **ai_Abstract:** 本文对离散音频Token化方法进行了系统性回顾和基准测试，旨在弥补现有研究缺乏统一比较的不足。研究涵盖语音、音乐和通用音频三大领域，提出了一种详细的Token化方法分类法，并基于多项基准对不同的Token化器进行了评估和权衡分析。研究结果揭示了该领域的关键局限性、实际应用考虑及未来面临的挑战，为后续研究提供了方向。

> **摘要翻译:** 离散音频Token是一种紧凑的表示形式，旨在保持感知质量、语音内容和说话者特征，同时实现高效存储和推理，并在各种下游任务中表现出具有竞争力的性能。它们为连续特征提供了一种实用的替代方案，使语音和音频能够集成到现代大型语言模型（LLMs）中。随着对基于Token的音频处理的兴趣日益增长，各种Token化方法应运而生，并且已经有几篇综述回顾了该领域的最新进展。然而，现有研究通常侧重于特定领域或任务，缺乏对各种基准的统一比较。本文对离散音频Token化器进行了系统性回顾和基准测试，涵盖语音、音乐和通用音频三个领域。我们提出了一种基于编码器-解码器、量化技术、训练范式、可流式传输性和应用领域的Token化方法分类法。我们在重建、下游性能和声学语言建模等多个基准上评估了Token化器，并通过受控消融研究分析了权衡。我们的发现强调了关键局限性、实际考虑因素和开放挑战，为这一快速发展领域的未来研究提供了见解和指导。有关更多信息，包括我们的主要结果和Token化器数据库，请访问我们的网站：https://poonehmousavi.github.io/dates-website/。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [130] [PAL: Probing Audio Encoders via LLMs -- A Study of Information Transfer from Audio Encoders to LLMs](https://arxiv.org/abs/2506.10423)
> *PAL：通过大型语言模型探究音频编码器——一项关于音频编码器到大型语言模型信息传输的研究*

*Tony Alex, Wish Suharitdamrong, Sara Atito, Armin Mustafa, Philip J. B. Jackson, Imran Razzak, Muhammad Awais* | **Main category: cs.SD**

**Keywords:** 音频-LLMs, 信息传输, 音频编码器, 大型语言模型, 架构设计

**Comment:** 21 pages, 11 figures

> **TL;DR:** 该论文研究了架构选择如何影响音频编码器到大型语言模型（LLMs）的信息传输，发现延迟音频集成、仅使用注意力子模块以及多样化编码器集成显著提升了性能。

**AI_Comments:** 这篇论文通过系统地探索音频-LLMs中高效信息传输的架构设计选择，做出了重要贡献，该领域尽管应用快速发展但仍未得到充分探索。关于延迟集成、仅注意力探究和编码器集成的发现为未来的音频-LLM开发提供了实用指导，并强调了机制理解的重要性。显著的性能改进证明了其所提出修改的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管音频-LLMs在应用方面发展迅速，但从音频编码器到大型语言模型（LLMs）有效传输丰富语义表示的底层机制仍未得到充分探索。本文旨在系统地研究架构设计选择如何影响LLM熟练探究音频编码器表示以满足文本查询的能力。

**Method:** 研究从标准的Pengi/LLaVA风格音频-LLM架构开始，提出了并评估了受机械可解释性研究和LLM操作原理指导的几种修改。所有假设均使用包含560万音频-文本对的数据集，通过相同的三阶段训练课程进行评估，以确保受控比较。

**Result:** 实验表明：1）将音频整合延迟到LLM的初始层建立文本上下文后，可以增强其探究音频表示以获取相关信息的能力；2）LLM可以仅通过LLM层的注意力子模块熟练探究音频表示，而无需传播到其前馈网络（FFN）子模块；3）高效集成的多样化音频编码器集合提供了更丰富、互补的表示，从而拓宽了LLM探究更广泛音频信息的能力。最终的架构相对于基线实现了10%到60%的相对改进。

**Conclusion:** 所提出的架构设计修改显著优化了音频-LLMs中的跨模态信息传输，验证了其方法。

> **ai_Abstract:** 本文研究了音频编码器到大型语言模型（LLMs）信息传输的未充分探索机制。作者提出了并评估了对标准音频-LLM的架构修改，这些修改受到机械可解释性的指导。主要发现包括延迟音频集成、仅使用注意力子模块进行音频探究以及集成多样化音频编码器的好处。他们的最终架构结合了这些改变，在560万音频-文本对数据集上，相对于基线实现了显著的性能提升（10-60%），验证了其优化跨模态信息传输的方法。

> **摘要翻译:** 大型语言模型（LLMs）中整合音频感知能力使得音频-LLMs取得了显著进展。尽管以应用为中心的发展，特别是在为特定能力（例如音频推理）策划训练数据方面进展迅速，但控制着从音频编码器到LLMs丰富语义表示高效传输的底层机制仍未得到充分探索。我们将有效的音频-LLM交互概念化为LLM熟练探究音频编码器表示以满足文本查询的能力。本文系统地研究了架构设计选择如何影响这一点。我们从标准的Pengi/LLaVA风格的音频-LLM架构开始，提出了并评估了几种修改，这些修改受到机械可解释性研究和LLM操作原理中得出的假设指导。我们的实验表明：（1）将音频整合延迟到LLM的初始层建立文本上下文后，可以增强其探究音频表示以获取相关信息的能力；（2）LLM可以仅通过LLM层的注意力子模块熟练探究音频表示，而无需传播到其前馈网络（FFN）子模块；（3）高效集成的多样化音频编码器集合提供了更丰富、互补的表示，从而拓宽了LLM探究更广泛音频信息的能力。所有假设均使用一个包含560万音频-文本对的数据集，通过相同的三阶段训练课程进行评估，确保了受控的比较。我们最终的架构，结合了所有提出的修改，相对于基线实现了10%到60%的相对改进，验证了我们优化音频-LLMs中跨模态信息传输的方法。项目页面：https://ta012.github.io/PAL/

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [150] [Description and Discussion on DCASE 2025 Challenge Task 4: Spatial Semantic Segmentation of Sound Scenes](https://arxiv.org/abs/2506.10676)
> *DCASE 2025 挑战任务 4：声景空间语义分割的描述与讨论*

*Masahiro Yasuda, Binh Thien Nguyen, Noboru Harada, Romain Serizel, Mayank Mishra, Marc Delcroix, Shoko Araki, Daiki Takeuchi, Daisuke Niizumi, Yasunori Ohishi, Tomohiro Nakatani, Takao Kawamura, Nobutaka Ono* | **Main category: cs.SD**

**Keywords:** 空间语义分割, 声景, DCASE 2025, 声事件检测, 多通道信号

**Comment:** 

> **TL;DR:** DCASE 2025 挑战任务 4 专注于从多通道空间输入信号中检测和分离声事件，旨在提升沉浸式通信技术。

**AI_Comments:** 该论文详细描述了 DCASE 2025 挑战赛的一个关键任务，即声景的空间语义分割。其创新之处在于聚焦于处理带有空间信息的声事件分离，并为此专门构建了数据集。这项工作对于推动沉浸式通信技术的发展具有重要意义，因为它直接解决了多通道音频处理中声源分离和空间信息提取的难题。由于是挑战任务的介绍，其最终的性能和完整细节尚待挑战结果公布后才能全面评估。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提升从多通道输入信号中检测和分离声事件的技术，这些信号混合了具有空间信息的多个声事件。这是沉浸式通信的基础，最终目标是将带有 6 自由度信息的声事件信号分离成干声对象信号和包含方向等空间信息的元数据。

**Method:** 本文概述了 DCASE 2025 挑战任务 4 (S5) 的任务设置，并介绍了为此任务新录制和整理的 DCASE2025 任务 4 数据集。同时，报告了在该数据集上训练和评估的 S5 系统的实验结果。

**Result:** 报告了针对该数据集训练和评估的 S5 系统的实验结果。

**Conclusion:** 本文描述了 DCASE 2025 挑战任务 4 的设置和数据集，并提供了初步的实验结果。完整版论文将在挑战结果公布后发布。

> **ai_Abstract:** 本文描述了 DCASE 2025 挑战任务 4 (S5)，该任务旨在从多通道空间输入信号中检测和分离声事件，以支持沉浸式通信。文章概述了任务设置和为此任务创建的新数据集，并报告了在该数据集上训练和评估的 S5 系统的初步实验结果。

> **摘要翻译:** 声景空间语义分割 (S5) 旨在增强从混合了多个声事件和空间信息的多通道输入信号中进行声事件检测和分离的技术。这是沉浸式通信的根本基础。最终目标是将带有 6 自由度 (6DoF) 信息的声事件信号分离成干声对象信号和关于对象类型（声事件类别）以及表示空间信息（包括方向）的元数据。然而，由于几个现有的挑战任务已经提供了一部分子功能，今年的任务重点是从多通道空间输入信号中检测和分离声事件。本文概述了声学场景和事件检测与分类 (DCASE) 2025 挑战任务 4 的 S5 任务设置以及为此任务新录制和整理的 DCASE2025 任务 4 数据集。我们还报告了在该数据集上训练和评估的 S5 系统的实验结果。本文的完整版将在挑战结果公布后发布。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [170] [BNMusic: Blending Environmental Noises into Personalized Music](https://arxiv.org/abs/2506.10754)
> *BNMusic：将环境噪声融入个性化音乐*

*Chi Zuo, Martin B. Møller, Pablo Martínez-Nuevo, Huayang Huang, Yu Wu, Ye Zhu* | **Main category: cs.SD**

**Keywords:** 环境噪声, 个性化音乐, 声学掩蔽, 音乐生成, 梅尔频谱图

**Comment:** 

> **TL;DR:** BNMusic提出了一种新方法，通过将环境噪声融入个性化音乐来降低其可感知性，解决了传统声学掩蔽中声音与噪声不匹配的问题。

**AI_Comments:** BNMusic提出了一种创新的方法来处理环境噪声，通过将噪声融入音乐而非简单覆盖，解决了传统声学掩蔽中声音与噪声不匹配的问题。其利用跨模态生成和梅尔频谱图表示，通过两阶段处理实现了噪声的音乐化融合，显著提升了用户听觉体验。这项工作在个性化音频处理和噪声管理方面具有重要意义和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的声学掩蔽技术在处理环境噪声时，由于主导声音与噪声（如节拍）之间存在错位，往往需要过度提高音量才能有效掩蔽，这导致了效果不佳。受跨模态生成最新进展的启发，本文旨在引入一种替代方法，通过将环境噪声融入根据用户文本提示生成的个性化音乐中，以降低噪声的可感知性。

**Method:** 本文提出了一个名为BNMusic（将噪声融入个性化音乐）的框架，该框架基于梅尔频谱图表示的音乐生成范式，并包含两个关键阶段。第一阶段，合成一段完整的梅尔频谱图表示的音乐，该音乐封装了噪声的音乐本质。第二阶段，自适应地放大生成的音乐片段，以进一步降低噪声感知并增强融合效果，同时保持听觉质量。

**Result:** 在MusicBench、EPIC-SOUNDS和ESC-50上进行的综合评估实验证明了BNMusic框架的有效性。实验结果突出表明，该框架能够将环境噪声与节奏对齐、自适应放大且令人愉悦的音乐片段融合，从而最大限度地降低噪声的可感知性。

**Conclusion:** BNMusic框架通过将环境噪声融入个性化音乐中，提供了一种有效且创新的方法来改善整体听觉体验，解决了传统声学掩蔽的局限性。

> **ai_Abstract:** BNMusic提出了一种新颖的框架，旨在通过将环境噪声融入个性化音乐来解决传统声学掩蔽的局限性。该方法通过两个阶段实现：首先，根据噪声的音乐本质合成一段完整的音乐（梅尔频谱图表示）；其次，自适应放大生成的音乐片段以增强噪声融合和降低感知，同时保持音质。实验结果表明，该框架能有效将噪声与节奏对齐、自适应放大的音乐融合，从而显著降低噪声可感知性并提升听觉体验。

> **摘要翻译:** 当受到环境噪声干扰时，声学掩蔽技术是音频工程中一种传统的降低烦恼的方法，它试图用其他主导但干扰性较小的声音来覆盖噪声。然而，主导声音与噪声之间的错位——例如节拍不匹配——通常需要过度提高音量才能实现有效的掩蔽。受跨模态生成最新进展的启发，在这项工作中，我们引入了一种替代声学掩蔽的方法，旨在通过将环境噪声融入根据用户提供的文本提示生成的个性化音乐中来降低其可感知性。遵循使用梅尔频谱图表示进行音乐生成的范式，我们提出了一个名为“将噪声融入个性化音乐”（BNMusic）的框架，该框架包含两个关键阶段。第一阶段，合成一段完整的梅尔频谱图表示的音乐，该音乐封装了噪声的音乐本质。在第二阶段，我们自适应地放大生成的音乐片段，以进一步降低噪声感知并增强融合效果，同时保持听觉质量。我们在MusicBench、EPIC-SOUNDS和ESC-50上进行的综合评估实验证明了我们框架的有效性，突出了将环境噪声与节奏对齐、自适应放大且令人愉悦的音乐片段融合的能力，最大限度地降低了噪声的可感知性，从而改善了整体听觉体验。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [6] [Immersive Multimedia Communication: State-of-the-Art on eXtended Reality Streaming](https://arxiv.org/abs/2506.10004)
> *沉浸式多媒体通信：扩展现实流媒体的最新技术*

*Haopeng Wang, Haiwei Dong, Abdulmotaleb El Saddik* | **Main category: cs.MM**

**Keywords:** 扩展现实, XR, 流媒体, 沉浸式通信, 体验质量

**Comment:** accepted by ACM Transactions on Multimedia Computing, Communications,
  and Applications

> **TL;DR:** 这篇综述探讨了扩展现实（XR）流媒体的最新技术，涵盖了XR定义、头显、流量特性、体验质量、优化方法以及应用和挑战。

**AI_Comments:** 作为一篇综述性论文，其创新性在于系统性地梳理了XR流媒体领域的最新进展，提供了一个全面的概览。论文结构清晰，从基础概念到技术细节，再到应用和挑战，为研究人员和工程师提供了宝贵的参考。其重要性在于，在XR技术快速发展的背景下，它为理解该领域的核心问题、现有解决方案和未来方向提供了一个坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 扩展现实（XR）正在迅速发展，并有望彻底改变内容的创作和消费方式。这篇综述旨在审查XR流媒体的最新技术，以提供对XR的基础理解、其独特的数据传输需求、提升用户满意度的关键因素、效率和性能优化方法，并为XR的当前和未来发展提供见解。

**Method:** 这篇综述通过以下步骤审查了XR流媒体的最新技术：首先，定义了XR并介绍了各种XR头显及其多模态交互方法；其次，分析了XR流量特性以突出其独特的数据传输要求；接着，探讨了影响XR系统体验质量的因素；然后，介绍了基于视觉注意力的XR流媒体优化方法；最后，审视了当前的应用并强调了挑战。

**Result:** 这篇综述提供了一个对XR的基础理解，揭示了XR独特的流量特性和数据传输要求，识别了提升用户满意度的关键体验质量要素，介绍了基于视觉注意力的优化方法，并对XR的当前应用、持续发展和未来挑战提供了见解。

**Conclusion:** 这篇综述通过审视当前应用并突出挑战，为XR的持续和未来发展提供了深入的见解。

> **ai_Abstract:** 本综述全面回顾了扩展现实（XR）流媒体的最新技术。文章首先定义了XR并介绍了相关硬件和交互方式，接着分析了XR流量特性和影响用户体验质量的因素。随后，论文探讨了基于视觉注意力的优化方法以提升流媒体效率和性能。最后，文章考察了XR的现有应用并指出了面临的挑战，为XR的当前和未来发展提供了深入的见解。

> **摘要翻译:** 扩展现实（XR）正在迅速发展，并有望彻底改变内容的创作和消费方式。在XR中，用户整合各种感官输入，形成对虚拟环境的连贯感知。本综述回顾了XR流媒体的最新技术，重点关注多种范式。首先，我们定义了XR并介绍了各种XR头显及其多模态交互方法，以提供基础理解。然后，我们分析了XR流量特性，以突出其独特的数据传输要求。我们还探讨了影响XR系统体验质量的因素，旨在识别提升用户满意度的关键要素。在此之后，我们介绍了基于视觉注意力的XR流媒体优化方法，以提高效率和性能。最后，我们审查了当前的应用并强调了挑战，旨在为XR的持续和未来发展提供见解。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [159] [Immersive Fantasy Based on Digital Nostalgia: Environmental Narratives for the Korean Millennials and Gen Z](https://arxiv.org/abs/2506.10013)
> *基于数字怀旧的沉浸式幻想：韩国千禧一代和Z世代的环境叙事*

*Yerin Doh, Joonhyung Bae* | **Main category: cs.MM**

**Keywords:** 数字怀旧, 环境叙事, 口罩废弃物, 沉浸式艺术, 千禧一代和Z世代

**Comment:** 

> **TL;DR:** 本研究介绍了一种名为《亲爱的乘客，请戴好口罩》的媒体艺术作品，它利用数字怀旧和幻想，通过沉浸式游戏和展览，旨在解决千禧一代和Z世代一次性口罩废弃物问题，以培养同理心，尽管存在体验后参与的挑战。

**AI_Comments:** 该研究的创新之处在于利用数字怀旧和奇幻叙事，结合互动游戏和展览形式，吸引特定人群（千禧一代和Z世代）关注紧迫的环境问题（口罩废弃物）。其重要性在于探索了提高生态意识的新颖方式。文中明确指出了一个局限性：资源使用和体验后参与的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决COVID-19大流行期间一次性口罩废弃物激增的问题，并通过将生态问题重新构建，特别是针对千禧一代和Z世代，以引起对这些被低估问题的关注。

**Method:** 本研究介绍了一个名为《亲爱的乘客，请戴好口罩》的媒体艺术作品。该作品通过一个点击式游戏和沉浸式展览，将数字怀旧和千禧一代及Z世代的航空旅行回忆与独特的奇幻叙事相结合，引导参与者穿梭于虚拟和现实领域，面对伦理和环境困境。

**Result:** 该艺术作品培养了参与者的同理心和潜在的行动。

**Conclusion:** 尽管该艺术作品培养了同理心和潜在的行动，但资源使用和体验后参与的挑战依然存在。

> **ai_Abstract:** 本研究介绍了一件名为《亲爱的乘客，请戴好口罩》的媒体艺术作品，旨在解决COVID-19大流行期间显著增加的一次性口罩废弃物环境问题。该作品创造性地将千禧一代和Z世代的数字怀旧及航空旅行记忆与奇幻叙事相结合。通过互动点击式游戏和沉浸式展览，它引导参与者在虚拟和现实环境中面对伦理和环境困境，旨在培养同理心并鼓励行动，尽管也指出了资源使用和持续参与方面的挑战。

> **摘要翻译:** 本研究介绍了一种媒体艺术作品《亲爱的乘客，请戴好口罩》，旨在分层探索在COVID-19大流行期间激增的一次性口罩废弃物问题。该作品通过将千禧一代和Z世代的数字怀旧和航空旅行回忆与独特的奇幻叙事交织在一起，重新诠释了被低估的生态问题。通过点击式游戏和沉浸式展览，参与者在虚拟和现实领域中穿梭，面临伦理和环境困境。尽管它培养了同理心和潜在的行动，但资源使用和体验后参与的挑战依然存在。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [181] [Multimodal Emotion Coupling via Speech-to-Facial and Bodily Gestures in Dyadic Interaction](https://arxiv.org/abs/2506.10010)
> *双人互动中通过语音到面部和身体姿态的多模态情感耦合*

*Von Ralph Dane Marquez Herbuela, Yukie Nagai* | **Main category: cs.MM**

**Keywords:** 多模态情感耦合, 语音, 面部姿态, 身体姿态, 双人互动

**Comment:** 

> **TL;DR:** 本研究探讨了双人互动中语音、面部和手部动作之间的情感耦合，发现语音特征能预测面部和手部运动，且情感和对话结构会影响多模态表达。研究结果有助于提升实时情感检测的准确性。

**AI_Comments:** 这项研究通过细致分析双人互动中的多模态情感表达，特别是结合了对话结构的影响，为情感计算领域提供了深入见解。其创新之处在于不仅关注语音与面部，还扩展到手部动作，并区分了非重叠和重叠语音情境下的表达差异。研究结果对于开发更准确、更具情境感知的AI情感识别系统具有重要指导意义，但也可能面临跨文化或更复杂互动场景的泛化挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究对语音和面部对齐已充分证实，但语音与面部区域和手部动作的更广泛动态关联，以及对话结构（如轮流讲话和同时讲话）如何调节这种协调性，对于深入理解真实互动中情感和行为线索的沟通至关重要。理解这些动态有助于提高实时情感检测的准确性。

**Method:** 本研究使用IEMOCAP语料库中双人互动的区域特定动作捕捉数据。语音特征包括低级韵律、MFCCs以及模型导出的唤醒度、效价和分类情感（高兴、悲伤、愤怒、中性），并与3D面部和手部标记位移对齐。通过帧间位移大小量化表达活跃度，并通过语音到手势预测将语音特征映射到面部和手部运动。

**Result:** 非重叠语音一致地引发了更高的活跃度，特别是在下脸部和嘴部。悲伤在非重叠时表现出更高的表达性，而愤怒在重叠时抑制了手势。预测映射显示，韵律和MFCCs在发音区域的准确性最高，而唤醒度和效价的相关性较低且更具上下文敏感性。手部-语音同步在低唤醒度和重叠语音下增强，但对效价则不然。

**Conclusion:** 理解语音、面部和手部动作之间的多模态情感耦合以及对话结构对其调节作用，对于提升真实互动和AI系统中实时情感检测的准确性和同步性至关重要。研究结果揭示了特定情感和对话情境下多模态表达的动态模式。

> **ai_Abstract:** 本研究探讨了双人互动中语音、面部和手部动作之间的多模态情感耦合，特别关注对话结构（如轮流讲话和同时讲话）的影响。研究利用IEMOCAP语料库，通过分析语音特征（韵律、MFCCs、唤醒度、效价和分类情感）与面部和手部动作的关联。结果显示，非重叠语音会增加面部和嘴部活跃度，悲伤在非重叠时表达性增强，愤怒在重叠时抑制手势。语音特征对运动的预测能力各异，其中韵律和MFCCs在发音区域表现最佳。研究强调了理解这些动态对于提升实时情感检测的重要性。

> **摘要翻译:** 人类情感表达通过协调的语音、面部和手势信号出现。虽然语音与面部的对齐已得到充分证实，但连接情感表达性语音与区域性面部和手部动作的更广泛动态，对于深入了解真实互动中情感和行为线索如何沟通至关重要。进一步调节这种协调性的是对话交流的结构，例如顺序轮流讲话，它为多模态同步创造了稳定的时间窗口；而同时讲话，通常预示着高唤醒时刻，则会破坏这种对齐并影响情感清晰度。理解这些动态通过提高人类互动和AI系统中跨模态的时间和同步准确性来增强实时情感检测。本研究使用IEMOCAP语料库中双人互动的区域特定动作捕捉来检查多模态情感耦合。语音特征包括低级韵律、MFCCs以及模型导出的唤醒度、效价和分类情感（高兴、悲伤、愤怒、中性），并与3D面部和手部标记位移对齐。通过帧间位移大小量化表达活跃度，并通过语音到手势预测将语音特征映射到面部和手部运动。非重叠语音一致地引发了更高的活跃度，特别是在下脸部和嘴部。悲伤在非重叠时表现出更高的表达性，而愤怒在重叠时抑制了手势。预测映射显示，韵律和MFCCs在发音区域的准确性最高，而唤醒度和效价的相关性较低且更具上下文敏感性。值得注意的是，手部-语音同步在低唤醒度和重叠语音下增强，但对效价则不然。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [270] [Can Sound Replace Vision in LLaVA With Token Substitution?](https://arxiv.org/abs/2506.10416)
> *声音能否通过令牌替换在LLaVA中取代视觉？*

*Ali Vosoughi, Jing Bi, Pinxin Liu, Yunlong Tang, Chenliang Xu* | **Main category: cs.MM**

**Keywords:** SoundCLIP, 多模态大语言模型, 音频-视觉集成, 令牌替换, 跨模态对齐

**Comment:** 29 pages including references and appendices

> **TL;DR:** SoundCLIP通过令牌替换将音频集成到MLLM中，发现检索性能和文本生成质量之间存在权衡。

**AI_Comments:** 这项研究具有创新性，因为它直接探索了在MLLM中用声音替代视觉的可能性，挑战了传统的多模态融合范式。其重要性在于揭示了在音视频多模态任务中，检索性能和生成质量之间存在一个帕累特定律式的权衡，这对于未来MLLM的设计具有指导意义。引入WhisperCLIP和AVE-2数据集也为后续研究提供了有价值的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态系统通常依赖文本对齐表示而非直接集成音频和视觉输入，这限制了声学信息在需要细致音频理解的任务中的使用。SoundCLIP旨在解决这一问题，探索多模态大语言模型（MLLMs）中直接的音视集成。

**Method:** 引入SoundCLIP，通过将CLIP的视觉令牌替换为音频表示，并在LLaVA等模型中选择与声音相关的补丁令牌。研究了两种配置：(1) 将音频特征投影到CLIP的视觉流形中，(2) 保留原始音频嵌入。实验使用了五种最先进的音频编码器，并引入了WhisperCLIP架构和AudioVisual Event Evaluation (AVE-2) 数据集。

**Result:** 当音频投影到CLIP空间时，音视频检索性能显著提高（Top-1准确率提高高达44个百分点），但文本生成质量下降。经过文本监督预训练的编码器（CLAP, Whisper, ImageBind）比主要关注音视对齐的编码器（Wav2CLIP, AudioCLIP）保持更强的生成能力。发现更强的跨模态对齐不一定有利于所有多模态任务，而是存在一个帕累托前沿，最佳性能取决于平衡检索准确性和文本生成质量。

**Conclusion:** 跨模态对齐的增强不一定对所有多模态任务都有利；相反，最佳性能在于平衡检索准确性和文本生成质量之间存在一个帕累托前沿。经过文本监督预训练的编码器在生成任务中表现更好。

> **ai_Abstract:** 本研究引入了SoundCLIP，旨在解决多模态大语言模型中音频和视觉输入直接集成不足的问题。通过将CLIP的视觉令牌替换为音频表示，并在LLaVA等模型中探索两种配置，研究人员发现，虽然将音频投影到视觉空间能显著提升音视频检索性能，但却会损害文本生成质量。实验表明，经过文本监督预训练的音频编码器在生成任务中表现更优。研究结果挑战了跨模态对齐越强越好的假设，提出最佳性能存在于检索准确性和文本生成质量之间的权衡中。此外，论文还引入了WhisperCLIP架构和AVE-2数据集。

> **摘要翻译:** 多模态系统取得了令人印象深刻的进展，但它们通常依赖于文本对齐的表示，而不是直接集成音频和视觉输入。这种依赖性可能会限制声学信息在需要细致音频理解的任务中的使用。为此，SoundCLIP通过用音频表示替换CLIP的视觉令牌并在LLaVA等模型中选择与声音相关的补丁令牌，探索了多模态大语言模型（MLLM）中的直接音视集成。我们研究了两种配置：(1) 通过多层感知器（使用InfoNCE在配对音视频段上训练）将音频特征投影到CLIP的视觉流形中，以及 (2) 保留原始音频嵌入并进行最小的维度调整。对五种最先进的音频编码器的实验揭示了一个根本性的权衡。当音频投影到CLIP空间时，音视频检索性能显著提高（Top-1准确率提高高达44个百分点），但文本生成质量下降。经过文本监督预训练的编码器（CLAP、Whisper、ImageBind）比主要关注音视对齐的编码器（Wav2CLIP、AudioCLIP）保持更强的生成能力，这凸显了语言暴露对生成任务的价值。我们引入了WhisperCLIP，这是一种融合了Whisper中间表示的架构，以及AudioVisual Event Evaluation (AVE-2)，一个包含580,147个三秒音视频片段和细粒度对齐注释的数据集。我们的发现挑战了“更强的跨模态对齐必然有利于所有多模态任务”的假设；相反，出现了一个帕累托前沿，其中最佳性能取决于平衡检索准确性和文本生成质量。代码和数据集：https://github.com/ali-vosoughi/SoundCLIP。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [386] [Semantic Communication-Enabled Cloud-Edge-End-collaborative Metaverse Services Architecure](https://arxiv.org/abs/2506.10001)
> *语义通信赋能的云边端协同元宇宙服务架构*

*Yuxuan Li, Sheng Jinag, Bizhu Wang* | **Main category: cs.MM**

**Keywords:** 语义通信, 元宇宙, 云边端协同, VR, 传输延迟

**Comment:** arXiv admin note: text overlap with arXiv:2407.13764 by other authors

> **TL;DR:** 元宇宙服务面临带宽和延迟问题，本文提出SC-CEE-Meta架构，通过语义通信和云边端协同显著降低延迟并提升图像质量。

**AI_Comments:** 这篇论文的创新点在于将语义通信引入到云边端协同的元宇宙服务架构中，解决了传统位级传输在高带宽、低延迟要求下的局限性。通过传输关键语义信息而非原始比特流，有效地缓解了VR设备无线传输的瓶颈问题，尤其是在恶劣信道条件下仍能保持较好的性能，这对于提升元宇宙用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着技术进步和对新视听体验的追求，元宇宙获得了巨大的热情。然而，元宇宙服务面临实际障碍，如高分辨率虚拟场景等大量数据需要在云平台和VR设备之间传输。具体而言，VR设备的无线传输受到带宽不足的阻碍，导致速度和延迟问题。同时，较差的信道质量导致数据错误并恶化用户体验。

**Method:** 本文提出了一种语义通信赋能的云边端协同沉浸式元宇宙服务（SC-CEE-Meta）架构，包含VR视频语义传输、视频合成和3D虚拟场景重建三个模块。通过在VR设备和边缘服务器上部署语义模块，发送关键语义信息而非位级重建，以减少延迟、解决资源带宽冲突并增强抗信道干扰能力。此外，云端负责视频合成和3D场景重建预处理，边缘设备负责3D重建渲染模块。

**Result:** 在Meta Quest Pro上验证，SC-CEE-Meta可以将无线传输延迟降低96.05%，并在信道条件较差的情况下将图像质量提高43.99%。

**Conclusion:** SC-CEE-Meta架构通过语义通信和云边端协同，有效解决了元宇宙服务中无线传输的带宽、延迟和信道干扰问题，显著提升了用户体验。

> **ai_Abstract:** 本文针对元宇宙服务中VR设备无线传输带宽不足、延迟高和信道质量差导致的用户体验问题，提出了一种语义通信赋能的云边端协同沉浸式元宇宙服务（SC-CEE-Meta）架构。该架构通过在VR设备和边缘服务器部署语义模块，传输关键语义信息，并结合云边端协同处理，有效降低了无线传输延迟，提升了图像质量，解决了资源带宽冲突，并增强了对信道干扰的抵抗能力。实验结果显示其在延迟和图像质量方面有显著提升。

> **摘要翻译:** 随着技术进步和对新视听体验追求的加强，元宇宙获得了高涨的热情。然而，它面临实际障碍，因为高分辨率虚拟场景等大量数据必须在云平台和VR设备之间传输。具体而言，VR设备的无线传输受到带宽不足的阻碍，导致速度和延迟问题。同时，较差的信道质量导致数据错误并恶化用户体验。为了解决这个问题，我们提出了语义通信赋能的云边端协同沉浸式元宇宙服务（SC-CEE-Meta）架构，其中包括三个模块：VR视频语义传输、视频合成和3D虚拟场景重建。通过在VR设备和边缘服务器上部署语义模块，并发送关键语义信息而不是关注位级重建，它可以减少延迟，解决资源带宽冲突，并更好地抵抗信道干扰。此外，云端部署视频合成和3D场景重建预处理，而边缘设备托管3D重建渲染模块，所有这些都用于沉浸式服务。在Meta Quest Pro上验证，SC-CEE-Meta可以将无线传输延迟降低96.05%，并在信道条件较差的情况下将图像质量提高43.99%。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [390] [EQ-TAA: Equivariant Traffic Accident Anticipation via Diffusion-Based Accident Video Synthesis](https://arxiv.org/abs/2506.10002)
> *EQ-TAA：基于扩散的事故视频合成的等变交通事故预测*

*Jianwu Fang, Lei-Lei Li, Zhedong Zheng, Hongkai Yu, Jianru Xue, Zhengguo Li, Tat-Seng Chua* | **Main category: cs.MM**

**Keywords:** 交通事故预测, 扩散模型, 视频合成, 等变学习, 数据增强

**Comment:** Accepted by IEEE-TMM

> **TL;DR:** 本文提出EQ-TAA，通过Attentive Video Diffusion (AVD) 模型合成事故视频片段，以解决交通事故预测中数据标注困难和数据偏见问题，并取得了具有竞争力的性能。

**AI_Comments:** 该论文创新性地将扩散模型应用于交通事故预测领域，通过合成因果事故视频解决了该领域数据稀缺和标注困难的痛点。其无需额外标注的训练方式显著降低了数据准备成本。此外，等变三重损失的设计有效应对了交通场景的复杂性和数据偏见问题，提升了模型的鲁棒性。这为交通事故预测提供了一种新颖且高效的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 交通场景中的交通事故预测（TAA）是一个具有挑战性的问题，旨在实现未来零死亡。当前方法通常将TAA视为监督学习任务，需要对事故发生持续时间进行费力的标注。然而，交通场景固有的长尾、不确定和快速演变特性使得事故的真实因果部分难以识别，并且容易受到数据偏见的影响，导致背景混淆问题。

**Method:** 我们提出了一种Attentive Video Diffusion (AVD) 模型，通过在行车记录仪视频中生成因果部分（即从正常片段到事故片段）来合成额外的事故视频片段。AVD旨在根据事故或无事故文本提示生成因果视频帧，同时在视频生成后保留TAA的帧风格和内容。这种方法可以使用从各种驾驶场景收集的数据集进行训练，无需任何额外标注。此外，AVD通过等变三重损失促进了Equivariant TAA (EQ-TAA)，该损失针对一个锚定无事故视频片段以及生成的一对对比伪正常和伪事故片段。

**Result:** 对AVD和EQ-TAA的性能进行了广泛的实验评估，并取得了与最先进方法相比具有竞争力的表现。

**Conclusion:** 本文提出的AVD模型能够有效地合成交通事故视频，解决了数据稀缺和标注困难的问题。在此基础上，EQ-TAA结合等变三重损失，进一步提升了交通事故预测的性能，并在实验中取得了与现有SOTA方法相当的竞争性表现，为未来实现零死亡目标提供了新的途径。

> **ai_Abstract:** 本文针对交通事故预测（TAA）中数据标注困难和数据偏见问题，提出了一种名为Attentive Video Diffusion (AVD) 的模型。AVD通过从正常视频片段生成事故视频片段，合成额外的事故视频数据，从而无需人工标注即可训练。该模型能够根据文本提示生成因果视频帧，并保持原始帧的风格和内容。在此基础上，本文进一步提出了Equivariant TAA (EQ-TAA)，利用等变三重损失，结合锚定无事故视频和生成的伪正常/伪事故片段对进行对比学习。实验结果表明，AVD和EQ-TAA在交通事故预测任务上取得了与现有最先进方法相当的竞争性性能。

> **摘要翻译:** 交通事故预测（TAA）在交通场景中是一个具有挑战性的问题，旨在未来实现零死亡。当前方法通常将TAA视为监督学习任务，需要对事故发生持续时间进行费力的标注。然而，交通场景固有的长尾、不确定和快速演变特性使得事故的真实因果部分难以识别，并且容易受到数据偏见的影响，导致背景混淆问题。因此，我们提出了一种Attentive Video Diffusion (AVD) 模型，通过在行车记录仪视频中生成因果部分（即从正常片段到事故片段）来合成额外的事故视频片段。AVD旨在根据事故或无事故文本提示生成因果视频帧，同时在视频生成后保留TAA的帧风格和内容。这种方法可以使用从各种驾驶场景收集的数据集进行训练，无需任何额外标注。此外，AVD通过等变三重损失促进了Equivariant TAA (EQ-TAA)，该损失针对一个锚定无事故视频片段以及生成的一对对比伪正常和伪事故片段。对AVD和EQ-TAA的性能进行了广泛的实验评估，并取得了与最先进方法相比具有竞争力的表现。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [402] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
> *基于动态双向重建的HER2表达预测灵活多模态输入*

*Jie Qin, Wei Yang, Yan Su, Yiran Zhu, Weizhen Li, Yunyue Pan, Chengchang Pan, Honggang Qi* | **Main category: cs.MM**

**Keywords:** HER2预测, 多模态输入, 动态重建, 跨模态GAN, 乳腺癌

**Comment:** 7 pages,5 figures,3 tables,submitted to the 33rd ACM International
  Conference on Multimedia(ACM MM 2025)

> **TL;DR:** 本研究提出了一个自适应双模态框架，通过动态分支选择器、双向跨模态GAN和混合训练协议，实现了灵活的单/双模态HER2表达预测，显著提高了预测准确性，尤其在数据不完整的情况下，同时降低了成本。

**AI_Comments:** 该论文的创新点在于其提出的“双模态优先，单模态兼容”设计，通过动态分支选择和跨模态重建，有效解决了临床实践中多模态数据获取不完整的问题，同时显著提升了预测性能。这对于资源有限的医疗环境具有重要意义，能够降低成本并推广精准医疗。其结合GAN进行特征空间重建以及多任务优化的训练策略也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 目前的乳腺癌HER2评估模型主要孤立地分析H&E或IHC图像，尽管临床上依赖它们的协同解释。然而，同时获取这两种模态常因工作流程复杂性和成本限制而受阻。

**Method:** 提出一个自适应双模态框架，实现灵活的单/双模态HER2预测。该框架包含三项创新：1) 动态分支选择器，根据输入完整性激活单模态重建或双模态联合推断；2) 双向跨模态GAN，执行缺失模态的上下文感知特征空间重建；3) 结合对抗学习和多任务优化的混合训练协议。

**Result:** 单模态H&E预测准确率从71.44%提升至94.25%，双模态准确率达到95.09%，仅使用IHC输入时仍保持90.28%的可靠性。相较于H&E/IHC基线，准确率分别提高了22.81%/12.90%。跨模态重建将F1分数提升至0.9609（HE到IHC）和0.9251（IHC到HE）。轻量级变体参数减少了78.55%。

**Conclusion:** 该弹性架构通过动态路由输入，减轻了数据缺失导致的性能下降，同时保持了计算效率，在不同医疗环境中普及精准HER2评估方面显示出巨大潜力。

> **ai_Abstract:** 本论文提出了一种名为“动态双向重建”的自适应双模态框架，用于乳腺癌HER2表达预测。该框架解决了现有模型孤立处理H&E和IHC图像的局限性以及双模态数据获取的困难。通过引入动态分支选择器、双向跨模态生成对抗网络（GAN）进行缺失模态重建以及混合训练协议，实现了单模态和双模态输入的灵活预测。实验结果表明，该方法显著提高了单模态H&E预测准确率至94.25%，双模态准确率达到95.09%，并在仅有IHC输入时保持高可靠性，同时有效降低了计算成本和对同步数据采集的需求，有望在资源受限的环境中推广精准HER2评估。

> **摘要翻译:** 当前用于乳腺癌的HER2评估模型主要孤立地分析H&E或IHC图像，尽管临床上依赖它们的协同解释。然而，同时获取这两种模态常因工作流程复杂性和成本限制而受阻。我们提出了一个自适应双模态框架，通过三项创新实现灵活的单/双模态HER2预测：1) 一个动态分支选择器，根据输入完整性激活单模态重建或双模态联合推断；2) 一个双向跨模态GAN，执行缺失模态的上下文感知特征空间重建；3) 一个整合对抗学习和多任务优化的混合训练协议。该架构将单模态H&E预测准确率从71.44%提升至94.25%，同时实现95.09%的双模态准确率，并保持仅IHC输入时90.28%的可靠性。该框架的“双模态优先，单模态兼容”设计在无需同步采集的情况下提供了接近双模态的性能，尤其通过降低IHC基础设施成本而使资源受限的环境受益。实验验证证实，相较于H&E/IHC基线，准确率分别提高了22.81%/12.90%，跨模态重建将F1分数提升至0.9609（HE到IHC）和0.9251（IHC到HE）。通过动态路由输入通过重建增强或原生融合路径，该系统减轻了数据缺失导致的性能下降，同时保持了计算效率（轻量级变体参数减少78.55%）。这种弹性架构在不同医疗环境中普及精准HER2评估方面显示出巨大潜力。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [407] [Controllable Expressive 3D Facial Animation via Diffusion in a Unified Multimodal Space](https://arxiv.org/abs/2506.10007)
> *可控的富有表现力的统一多模态空间扩散三维面部动画*

*Kangwei Liu, Junwu Liu, Xiaowei Yi, Jinlin Guo, Yun Cao* | **Main category: cs.MM**

**Keywords:** 3D Facial Animation, Diffusion Model, Multimodal Control, Emotion Synthesis, FLAME

**Comment:** Accepted by ICME2025

> **TL;DR:** 提出一个基于扩散的多模态框架，用于可控的三维面部动画，解决了单模态控制和确定性映射的限制，显著提升了情感相似度。

**AI_Comments:** 这项工作通过引入多模态融合和扩散模型，为三维面部动画领域带来了创新。其多模态情感绑定策略有效解决了单一控制信号的局限性，而扩散模型则克服了传统确定性方法在表现力上的不足，使生成的动画更具随机性和自然性。情感相似度的大幅提升是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频驱动的情感三维面部动画面临两大挑战：1) 依赖单一模态控制信号（视频、文本或情感标签），未能利用其互补优势进行全面的情感操控；2) 基于确定性回归的映射限制了情感表达和非语言行为的随机性，从而限制了合成动画的表现力。

**Method:** 提出一个基于扩散的框架，用于可控的富有表现力的三维面部动画。该方法引入了两项关键创新：1) 以FLAME为中心的多模态情感绑定策略，通过对比学习对齐不同模态（文本、音频和情感标签），实现从多个信号源进行灵活的情感控制；2) 一个具有内容感知注意力和情感引导层的基于注意力的潜在扩散模型，它在保持时间连贯性和自然面部动态的同时，丰富了运动多样性。

**Result:** 在大多数指标上优于现有方法，情感相似度提高了21.6%，同时保留了生理上合理的面部动态。

**Conclusion:** 该方法通过结合多模态控制和扩散模型，显著提升了三维面部动画的表现力和情感相似度，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种基于扩散的框架，用于生成可控且富有表现力的三维面部动画，旨在解决现有方法中单模态控制的局限性以及确定性映射对表达随机性的限制。该框架引入了FLAME中心的多模态情感绑定策略，通过对比学习整合文本、音频和情感标签等多种模态，实现灵活的情感控制。同时，一个带有内容感知注意力和情感引导层的潜在扩散模型被用于增加运动多样性并保持动画的自然性。实验结果表明，该方法在情感相似度方面有显著提升（21.6%），并优于现有技术。

> **摘要翻译:** 音频驱动的情感三维面部动画面临两大显著挑战：(1) 依赖单一模态控制信号（视频、文本或情感标签），未能利用其互补优势进行全面的情感操控；(2) 基于确定性回归的映射限制了情感表达和非语言行为的随机性，从而限制了合成动画的表现力。为了解决这些挑战，我们提出了一种基于扩散的可控表现力三维面部动画框架。我们的方法引入了两项关键创新：(1) 一种以FLAME为中心的多模态情感绑定策略，通过对比学习对齐不同模态（文本、音频和情感标签），从而实现从多个信号源进行灵活的情感控制；(2) 一个具有内容感知注意力和情感引导层的基于注意力的潜在扩散模型，它在保持时间连贯性和自然面部动态的同时，丰富了运动多样性。大量实验表明，我们的方法在大多数指标上优于现有方法，在保持生理上合理的面部动态的同时，情感相似度提高了21.6%。项目页面：https://kangweiiliu.github.io/Control_3D_Animation。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [411] [Structured Graph Representations for Visual Narrative Reasoning: A Hierarchical Framework for Comics](https://arxiv.org/abs/2506.10008)
> *视觉叙事推理的结构化图表示：一个漫画分层框架*

*Yi-Chun Chen* | **Main category: cs.MM**

**Keywords:** 视觉叙事, 知识图谱, 漫画, 分层框架, 多模态推理

**Comment:** This paper has been submitted to ACM Multimedia 2025 and is currently
  under review

> **TL;DR:** 本文提出了一个分层知识图谱框架，用于理解漫画等多模态视觉叙事，并能支持多种叙事推理任务。

**AI_Comments:** 该论文的创新点在于提出了一个分层的知识图谱框架，能够对视觉叙事进行结构化理解，并整合了多模态信息（视觉与文本）。其重要性在于为漫画等复杂视觉叙事媒体的自动化分析和推理提供了有效工具，并为未来的交互式故事讲述和多模态推理奠定了基础。框架的连贯性和可解释性是其优势。

<details>
  <summary>Details</summary>

**Motivation:** 理解视觉叙事内容，特别是漫画等多模态媒体的结构化理解，并支持叙事推理。

**Method:** 该方法将叙事内容分解为多个层次（从宏观故事弧到细粒度事件片段），并通过集成知识图谱表示它们，捕获语义、空间和时间关系。在画格层面构建多模态图，连接视觉元素（角色、物体、动作）和文本组件（对话、标题），并跨叙事层级整合这些图以支持故事结构、角色连续性和事件进展的推理。

**Result:** 将该方法应用于Manga109数据集的手动标注子集，并证明其能够支持跨不同叙事任务（包括动作检索、对话追踪、角色出现映射和画格时间线重建）的符号推理。评估结果显示在各项任务中均具有高精度和高召回率。

**Conclusion:** 该框架具有连贯性和可解释性，为基于叙事的内容分析、交互式故事讲述和视觉媒体中的多模态推理提供了一个可扩展的基础。

> **ai_Abstract:** 本文提出了一个针对漫画等视觉叙事的分层知识图谱框架。该框架将叙事内容分解为多层级的知识图谱，整合视觉和文本信息，以捕捉语义、空间和时间关系。实验证明，该方法能有效支持多种叙事推理任务，如动作检索和角色追踪，并为视觉媒体的内容分析和交互式叙事提供了可扩展的基础。

> **摘要翻译:** 本文提出了一个用于结构化理解视觉叙事的分层知识图谱框架，重点关注漫画等多模态媒体。所提出的方法将叙事内容分解为多个层次，从宏观层面的故事弧到细粒度的事件片段。它通过集成的知识图谱来表示这些内容，捕获语义、空间和时间关系。在画格层面，我们构建多模态图，将角色、物体、动作等视觉元素与对话和标题等相应的文本组件连接起来。这些图在叙事层级之间进行整合，以支持对故事结构、角色连续性和事件进展的推理。我们将我们的方法应用于Manga109数据集的手动标注子集，并展示了其支持跨不同叙事任务（包括动作检索、对话追踪、角色出现映射和画格时间线重建）的符号推理的能力。评估结果显示在各项任务中均具有高精度和高召回率，验证了该框架的连贯性和可解释性。这项工作为基于叙事的内容分析、交互式故事讲述和视觉媒体中的多模态推理贡献了一个可扩展的基础。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [415] [WDMIR: Wavelet-Driven Multimodal Intent Recognition](https://arxiv.org/abs/2506.10011)
> *WDMIR：小波驱动的多模态意图识别*

*Weiyin Gong, Kai Zhang, Yanghai Zhang, Qi Liu, Xinjie Sun, Junyu Lu, Linbo Zhu* | **Main category: cs.MM**

**Keywords:** 多模态意图识别, 小波, 频域分析, 非语言线索, 特征融合

**Comment:** Accepted at IJCAI 2025, 9pages, 6figures

> **TL;DR:** WDMIR是一个新颖的多模态意图识别框架，通过对视频和音频等非语言信息进行小波驱动的频域分析，显著提升了意图理解的准确性，并在MIntRec数据集上达到了最先进的性能。

**AI_Comments:** 本文的创新点在于引入小波变换对非语言信息进行频域分析，这为多模态意图识别提供了一个新颖且有效的方法，弥补了现有方法对非语言线索利用不足的缺陷。其模块化设计也增强了方法的鲁棒性和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数多模态意图识别方法过度侧重于文本分析，往往忽视了视频和音频等非语言信息中蕴含的丰富语义内容，导致无法充分利用这些关键线索来准确解释用户意图。

**Method:** 本文提出了一个新颖的小波驱动多模态意图识别（WDMIR）框架。具体包括：1) 一个小波驱动的融合模块，在频域对视频和音频特征进行同步分解和整合，实现对时间动态的细粒度分析；2) 一个跨模态交互机制，促进从双模态到三模态的渐进式特征增强，有效弥合语言和非语言信息之间的语义鸿沟。

**Result:** 在MIntRec数据集上的大量实验表明，WDMIR方法达到了最先进的性能，识别准确率比现有方法提高了1.13%。消融研究进一步证实，小波驱动的融合模块显著改善了非语言源的语义信息提取，在分析微妙情感线索时识别准确率提高了0.41%。

**Conclusion:** WDMIR框架通过引入小波驱动的频域分析和跨模态交互机制，有效利用了非语言信息中的语义内容，显著提升了多模态意图识别的性能，并达到了最先进的水平。

> **ai_Abstract:** WDMIR是一个新颖的多模态意图识别框架，旨在通过对非语言信息（视频和音频）进行小波驱动的频域分析来克服现有方法对文本的过度依赖。该框架包含一个小波驱动的融合模块，用于频域内视频-音频特征的细粒度分析，以及一个跨模态交互机制，用于弥合语言与非语言信息间的语义鸿沟。实验结果显示，WDMIR在MIntRec数据集上取得了最先进的性能，准确率提高了1.13%，并且小波模块在提取非语言语义信息方面表现出色。

> **摘要翻译:** 多模态意图识别（MIR）旨在通过整合视频、音频和文本模态中的语言和非语言信息来准确解释用户意图。虽然现有方法优先考虑文本分析，但它们常常忽视非语言线索中嵌入的丰富语义内容。本文提出了一个新颖的小波驱动多模态意图识别（WDMIR）框架，通过对非语言信息进行频域分析来增强意图理解。具体来说，我们提出了：(1) 一个小波驱动的融合模块，在频域执行视频-音频特征的同步分解和整合，从而实现时间动态的细粒度分析；(2) 一个跨模态交互机制，促进从双模态到三模态整合的渐进式特征增强，有效地弥合了语言和非语言信息之间的语义鸿沟。在MIntRec上的大量实验表明，我们的方法达到了最先进的性能，在准确率上超越了以往方法1.13%。消融研究进一步验证了小波驱动的融合模块显著改善了非语言源的语义信息提取，在分析微妙情感线索时识别准确率提高了0.41%。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [418] [Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2506.10016)
> *多模态大型语言模型：一项综述*

*Longzhen Han, Awes Mubarak, Almas Baimagambetov, Nikolaos Polatidis, Thar Baker* | **Main category: cs.MM**

**Keywords:** 多模态大型语言模型, 综述, 跨模态能力, 基础技术, 开放挑战

**Comment:** 

> **TL;DR:** 综述了多模态大型语言模型（MLLMs）的发展，涵盖其多模态输出、核心技术、架构趋势、协同效应和开放挑战。

**AI_Comments:** 这篇综述的重要性在于它系统性地梳理了多模态大型语言模型（MLLMs）的最新进展和未来方向。它不仅涵盖了MLLMs如何超越传统文本生成，扩展到多种输出模态的创新点，还深入分析了支撑其发展的核心技术和架构趋势。特别地，它指出了评估、模块化和结构化推理等关键的未解决挑战，为领域内的研究者提供了明确的研究方向。其统一的视角对于理解这一快速发展领域的复杂性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）已迅速发展，超越文本生成，涵盖多种输出模态。本综述旨在提供对MLLM发展的统一视角，分析其关键技术、架构趋势、协同作用以及面临的挑战，并指明未来发展方向。

**Method:** 本综述将六种主要的生成模态进行分类，并考察了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。同时，分析了关键模型、架构趋势和新兴的跨模态协同作用，并强调了可迁移技术和未解决的挑战。

**Result:** MLLMs已扩展到图像、音乐、视频、人体运动和3D对象等多种输出模态。Transformer和扩散模型等架构创新是其融合的基础。本综述识别了评估、模块化和结构化推理方面的开放挑战，并提出了协同作用的新兴模式。

**Conclusion:** 本综述为多模态大型语言模型（MLLM）的发展提供了一个统一的视角，并指明了通向更通用、适应性更强、可解释的多模态系统的关键路径。

> **ai_Abstract:** 这篇综述深入探讨了多模态大型语言模型（MLLMs）的快速演进，这些模型已从单一文本生成扩展到包括图像、音乐、视频等多种输出模态。文章分类了六种主要生成模态，并分析了自监督学习、专家混合等关键技术如何赋能跨模态能力。此外，综述还探讨了核心模型、架构趋势、跨模态协同效应，并指出了评估和模块化等开放挑战，旨在为构建更通用、适应性强的多模态系统提供统一视角和发展路径。

> **摘要翻译:** 多模态大型语言模型（MLLM）已迅速发展，超越了文本生成，通过在统一架构下将语言与其他感官模态相结合，现已涵盖图像、音乐、视频、人体运动和3D对象等多种输出模态。本综述将六种主要的生成模态进行分类，并考察了自监督学习（SSL）、专家混合（MoE）、人类反馈强化学习（RLHF）和思维链（CoT）提示等基础技术如何实现跨模态能力。我们分析了关键模型、架构趋势和新兴的跨模态协同作用，同时强调了可迁移技术和未解决的挑战。Transformer和扩散模型等架构创新是这种融合的基础，实现了跨模态迁移和模块化专业化。我们强调了协同作用的新兴模式，并指出了评估、模块化和结构化推理方面的开放挑战。本综述为MLLM的发展提供了一个统一的视角，并指明了通向更通用、适应性更强、可解释的多模态系统的关键路径。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [33] [Quantum resources in resource management systems](https://arxiv.org/abs/2506.10052)
> *资源管理系统中的量子资源*

*Iskandar Sitdikov, M. Emre Sahin, Utz Bacher, Aleksander Wennersteen, Andrew Damin, Mark Birmingham, Philippa Rubin, Stefano Mensa, Matthieu Moreau, Aurelien Nober, Hitomi Takahashi, Munetaka Ohtani* | **Main category: quant-ph**

**Keywords:** 量子计算, 资源管理, 高性能计算, Slurm, 混合量子-经典

**Comment:** 

> **TL;DR:** 该论文提出了一种将量子计算资源集成到现有高性能计算（HPC）工作负载管理系统（如Slurm）中的方法，以实现统一调度和支持混合量子-经典应用。

**AI_Comments:** 这篇论文通过提出将量子资源集成到现有高性能计算（HPC）基础设施中的实用方法，解决了量子计算实际应用中的一个关键挑战。其创新之处在于利用现有成熟的工作负载管理系统（如Slurm）并通过插件机制实现集成，而非从头构建新系统。这大大降低了量子技术在HPC环境中落地的门槛，对于促进混合量子-经典应用的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算机开始在HPC环境中运行，它们可以补充经典资源，但其广泛采用取决于能否集成到现有HPC基础设施中。将量子设备作为一流资源处理可以实现统一调度、提高可用性并支持混合量子-经典应用。

**Method:** 本文提出了一种利用现有工作负载管理系统（特别是Slurm）控制量子资源的设计架构和参考实现。具体方法是引入一套Slurm插件，以将本地和云端量子计算资源集成到现有HPC中心。论文详细介绍了接口设计、插件概念与实现、异构计算集群的操作方面以及对其他资源管理系统的考虑。

**Result:** 论文提出了将量子资源集成到现有高性能计算（HPC）环境中的设计架构和参考实现，并通过为Slurm开发插件成功实现了量子计算资源（包括本地和云端）的集成。

**Conclusion:** 通过将量子设备作为一流资源集成到现有工作负载管理系统（如Slurm）中，可以实现量子资源与经典资源的统一调度，提高可用性，并有效支持混合量子-经典应用，从而促进量子计算在HPC环境中的广泛采用。

> **ai_Abstract:** 本文提出了一种将量子计算资源无缝集成到现有高性能计算（HPC）基础设施中的方法。通过将量子设备视为一流资源，并利用现有工作负载管理系统（如Slurm），论文设计并实现了一套插件，旨在实现量子与经典资源的统一调度、提高可用性，并支持混合量子-经典应用程序。这项工作为量子计算在HPC环境中的广泛采用提供了实用的解决方案。

> **摘要翻译:** 量子计算机正开始在高性能计算（HPC）环境中运行。量子计算可以补充特定工作负载的经典资源，但其采用取决于与现有HPC基础设施的集成。将量子设备视为一流资源可以实现统一调度、提高可用性并支持混合量子-经典应用程序。本文介绍了使用现有工作负载管理系统控制量子资源的设计架构和参考实现。我们为Slurm引入了一套插件，使本地和云端量子计算资源能够集成到现有高性能计算中心。本文详细介绍了接口设计、插件概念与实现、异构计算集群的操作方面，以及对其他资源管理系统的考虑。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [67] [Landauer Principle and Thermodynamics of Computation](https://arxiv.org/abs/2506.10876)
> *朗道尔原理与计算热力学*

*Pritam Chattopadhyay, Avijit Misra, Tanmoy Pandit, Goutam Paul* | **Main category: quant-ph**

**Keywords:** 朗道尔原理, 计算热力学, 信息擦除, 能量界限, 纠错

**Comment:** 

> **TL;DR:** 本文综述了朗道尔原理的最新进展，包括实验验证、有限时间/非平衡环境下的研究，以及计算过程的能量界限和纠错的热力学方面。

**AI_Comments:** 本文作为一篇综述性文章，全面梳理了朗道尔原理在计算热力学领域的最新进展，涵盖了实验和理论研究，并扩展到能量界限和纠错的热力学方面。其重要性在于为该领域的研究人员提供了系统的知识框架和未来研究方向的指引。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在全面回顾朗道尔原理的最新进展，该原理是计算热力学中的一个基本原理。同时，也为未来的研究方向提供展望，并回顾了计算过程的能量界限以及纠错的热力学方面。

**Method:** 本文采用综述（review）的方法，对朗道尔原理、计算热力学中的能量界限以及纠错的热力学方面进行了全面回顾。

**Result:** 文章回顾了朗道尔原理的最新进展，包括在经典和量子领域达到朗道尔极限的实验探索，以及在有限时间、有限热浴、非马尔可夫和非平衡量子环境下的朗道尔极限研究。此外，还回顾了计算过程的能量界限和纠错的热力学方面。

**Conclusion:** 本文对朗道尔原理的最新进展进行了全面回顾，该原理是计算热力学中的基本原理，并为未来的研究方向提供了展望。同时，也探讨了计算过程的能量界限和纠错的热力学方面。

> **ai_Abstract:** 本文全面综述了朗道尔原理在计算热力学中的最新进展，该原理指出逻辑不可逆过程伴随熵产生和热耗散。文章回顾了达到朗道尔极限的实验探索、有限时间与非平衡环境下的理论研究，并探讨了计算过程的能量界限以及信息处理中纠错的热力学特性，同时为未来研究提供了展望。

> **摘要翻译:** 根据朗道尔原理，任何逻辑上不可逆的过程都伴随着熵的产生，这导致了环境中热量的耗散。信息擦除作为主要的逻辑不可逆过程之一，其耗散到环境中的热量有一个下限，称为朗道尔极限（LB）。然而，实际的擦除过程耗散的热量远高于朗道尔极限。最近，在经典和量子领域都有一些实验研究试图达到这个极限。同时，也有大量活动探讨在有限时间、有限尺寸热浴、非马尔可夫和非平衡量子体系中朗道尔极限的问题，在这些情况下，系统与热浴的涨落和关联效应不再能被忽略。本文全面回顾了朗道尔极限的最新进展，它作为计算热力学中的一个基本原理。我们还为这些方向的未来努力提供了展望。此外，我们回顾了最近在建立计算过程能量界限方面的探索。我们还回顾了纠错的热力学方面，这是信息处理和计算中不可或缺的一部分。在此过程中，我们简要讨论了这些领域的基础知识，以提供一个完整的图景。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [137] [Synchronization for Fault-Tolerant Quantum Computers](https://arxiv.org/abs/2506.10258)
> *容错量子计算机的同步*

*Satvik Maurya, Swamit Tannu* | **Main category: quant-ph**

**Keywords:** 量子计算, 表面代码, 同步, 容错, 量子纠错

**Comment:** 

> **TL;DR:** 该论文提出了三种同步逻辑量子比特综合征生成周期的策略（被动、主动和混合），以解决容错量子计算中表面代码去同步化的问题。主动策略将逻辑错误率降低2.4倍，混合策略降低3.4倍，并能将解码延迟加速2.2倍。

**AI_Comments:** 该论文解决了容错量子计算中一个关键且实际的挑战，即逻辑量子比特的同步问题。通过提出三种新颖的同步策略，特别是主动和混合策略，它显著降低了逻辑错误率并加速了解码过程，为构建更鲁棒的量子计算机提供了重要的工程优化方案。其创新之处在于系统性地定义并评估了不同程度的同步干预措施，并量化了它们对系统性能的提升。

<details>
  <summary>Details</summary>

**Motivation:** 量子纠错（QEC）代码通过将信息编码到更多不可靠的量子比特中，在逻辑量子比特中可靠地存储信息。表面代码是容错量子计算（FTQC）的主要候选。然而，由于非Clifford态的产生、制造缺陷导致的脱落以及与其他QEC代码结合使用，使用表面代码编码的逻辑量子比特可能会出现综合征生成周期的不同步。逻辑操作要求所涉及逻辑量子比特的综合征生成周期同步，但这会导致领先的量子比特暂停或减慢其周期，从而在下一周期之前积累更多错误，增加不可纠正错误的风险。因此，需要有效的同步策略。

**Method:** 为了同步逻辑量子比特的综合征生成周期，本文定义了三种策略：被动（Passive）、主动（Active）和混合（Hybrid）。被动策略是最简单、作为基线的策略，其中领先的逻辑量子比特空闲直到与其余逻辑量子比特同步。主动策略旨在通过在多个代码周期前插入短空闲期来逐渐减慢领先的逻辑量子比特。混合策略通过减少同步松弛并运行额外的错误纠正轮次来进一步优化。

**Result:** 与被动策略相比，主动策略将逻辑错误率（LER）降低了高达2.4倍。混合策略进一步将LER降低了高达3.4倍。此外，所提出的同步策略在电路级噪声模型下，将解码延迟加速了高达2.2倍。

**Conclusion:** 本文提出的同步策略能有效降低容错量子计算机中逻辑量子比特的逻辑错误率，并显著加速解码过程，从而提升了表面代码在实际应用中的可行性。

> **ai_Abstract:** 该论文解决了容错量子计算中表面代码逻辑量子比特综合征生成周期不同步的问题。这种不同步会增加不可纠正错误的风险。为解决此问题，作者提出了三种同步策略：被动、主动和混合。实验结果表明，主动策略可将逻辑错误率降低高达2.4倍，而混合策略可进一步降低高达3.4倍，同时还能将解码延迟加速高达2.2倍，显著提升了容错量子计算的性能。

> **摘要翻译:** 量子纠错（QEC）代码通过将信息编码到数量更多的、可靠性较低的量子比特中，从而在逻辑量子比特中可靠地存储信息。表面代码因其对物理错误的高弹性而成为容错量子计算（FTQC）的主要候选方案。然而，用表面代码编码的逻辑量子比特可能处于其综合征生成周期的不同阶段，从而在系统中引入去同步化。这可能由于非Clifford态的产生、制造缺陷导致的脱落以及将其他QEC代码与表面代码结合使用以减少资源需求而发生。逻辑操作要求所涉及逻辑量子比特的综合征生成周期同步。这要求领先的量子比特暂停或减慢其周期，从而在下一周期之前积累更多错误，从而增加不可纠正错误的风险。
为了同步逻辑量子比特的综合征生成周期，我们定义了三种策略——被动、主动和混合。被动策略是基线，也是最简单的，其中领先的逻辑量子比特空闲直到它们与其余逻辑量子比特同步。另一方面，主动策略旨在通过在多个代码周期之前插入短空闲期来逐渐减慢领先的逻辑量子比特。这种方法与被动策略相比，将逻辑错误率（LER）降低了高达2.4倍。混合策略通过减少同步松弛并运行一些额外的错误纠正轮次，进一步将LER降低了高达3.4倍。此外，所提出的同步策略在电路级噪声模型下，将解码延迟加速了高达2.2倍。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [546] [VQC-MLPNet: An Unconventional Hybrid Quantum-Classical Architecture for Scalable and Robust Quantum Machine Learning](https://arxiv.org/abs/2506.10275)
> *VQC-MLPNet：一种用于可扩展和鲁棒量子机器学习的非常规混合量子-经典架构*

*Jun Qi, Chao-Han Yang, Pin-Yu Chen, Min-Hsiu Hsieh* | **Main category: quant-ph**

**Keywords:** 量子机器学习, 混合量子-经典架构, 变分量子电路, 神经网络, 噪声鲁棒性

**Comment:** 31 pages, 11 figures, under review

> **TL;DR:** VQC-MLPNet提出了一种混合量子-经典架构，通过量子电路动态生成经典MLP参数，以克服变分量子电路的局限性，实现可扩展和鲁棒的量子机器学习。

**AI_Comments:** VQC-MLPNet的创新之处在于其独特的混合架构，通过量子电路动态生成经典MLP参数，有效弥补了VQC的局限性。该研究不仅提供了扎实的理论基础（统计学习和神经正切核分析），还通过经验实验验证了其在噪声环境下的鲁棒性，这对于当前噪声中等规模量子（NISQ）时代的应用至关重要。其对表示能力指数级提升的理论证明，显示出该架构在可扩展性上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 变分量子电路（VQCs）在量子机器学习中面临线性表达能力受限、优化困难和对量子硬件噪声敏感等固有限制。

**Method:** VQC-MLPNet通过创新性地利用量子电路（通过幅度编码和参数化量子操作）动态生成经典多层感知器（MLPs）的参数。该方法通过统计学习技术和神经正切核分析提供了严格的理论保证，明确推导了逼近、均匀偏差和优化误差的上限。

**Result:** 理论上，VQC-MLPNet在表示能力上相对于量子电路深度和量子比特数量实现了指数级提升，相较于独立量子电路和现有混合量子架构具有计算优势。经验上，通过分类半导体量子点电荷态和预测基因组转录因子结合位点等实验证实了其理论主张，即使在真实的IBM量子噪声模拟下也能展现出弹性性能。

**Conclusion:** 这项研究建立了一个理论上健全且实践中鲁棒的框架，推动了在噪声中等规模量子（NISQ）时代及未来非常规计算范式下量子增强学习的前沿发展。

> **ai_Abstract:** VQC-MLPNet是一种新型混合量子-经典架构，旨在解决变分量子电路（VQCs）在量子机器学习中面临的表达能力、优化和噪声敏感性问题。该架构通过量子电路动态生成经典多层感知器（MLPs）的参数，显著提升了表示能力和训练稳定性。论文提供了严格的理论保证，并通过半导体量子点分类和基因组预测等实验验证了其在噪声环境下的鲁棒性能，为量子增强学习提供了一个可扩展且稳健的框架。

> **摘要翻译:** 变分量子电路（VQCs）为量子机器学习提供了一条新途径，但其实际应用受到固有局限性的阻碍，例如受限的线性表达能力、优化挑战以及对量子硬件噪声的极度敏感。本工作介绍了VQC-MLPNet，一种可扩展且鲁棒的混合量子-经典架构，旨在克服这些障碍。通过创新性地利用量子电路，通过幅度编码和参数化量子操作为经典多层感知器（MLPs）动态生成参数，VQC-MLPNet大大扩展了表示能力并增强了训练稳定性。我们通过统计学习技术和神经正切核分析提供了严格的理论保证，明确推导了逼近、均匀偏差和优化误差的上限。这些理论见解表明，相对于量子电路深度和量子比特数量，表示能力有指数级提升，与独立量子电路和现有混合量子架构相比具有明显的计算优势。我们的理论主张通过广泛的实验得到了经验证实，包括分类半导体量子点电荷态和预测基因组转录因子结合位点，即使在真实的IBM量子噪声模拟下也能展现出弹性性能。这项研究建立了一个理论上健全且实践中鲁棒的框架，推动了在噪声中等规模量子时代及未来非常规计算范式下量子增强学习的前沿发展。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [89] [Comparing name generator designs in rural panel studies: analyzing alter retention and change](https://arxiv.org/abs/2506.10136)
> *比较农村小组研究中的姓名生成器设计：分析关系人保留和变化*

*Marian-Gabriel Hâncean, Jürgen Lerner, Christopher McCarty* | **Main category: stat.ME**

**Keywords:** 姓名生成器, 面板研究, 网络稳定性, 关系人保留, 农村社区

**Comment:** 14 pages, 4 tables, 1 figure

> **TL;DR:** 一项在罗马尼亚农村进行的双波个人网络研究发现，亲属、同住者或情感亲近的关系人更容易被保留，这强调了关系属性在网络稳定性中的作用，并为资源有限、文化独特的网络研究提供了设计考量。

**AI_Comments:** 这项研究的创新之处在于，它在特定且研究不足的背景（罗马尼亚农村）下比较了不同的姓名生成器设计，并强调了关系属性在网络稳定性中的关键作用。其结果为在资源受限和文化差异大的地区进行网络研究提供了重要的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 为了比较农村小组研究中不同姓名生成器设计的有效性，并评估关系人的保留情况，尤其是在资源有限、文化独特的背景下进行网络研究时的设计考量。

**Method:** 研究在罗马尼亚农村社区进行了一项双波个人网络研究，对相同的68名参与者使用了两种姓名生成器。第一波采用侧重情感亲近的固定选择生成器；第二波采用基于频繁互动的自由选择生成器。研究比较了关系特征并评估了跨波次的保留情况。

**Result:** 无论使用哪种生成器类型，作为亲属、同住者或情感亲近的关系人更有可能被保留。

**Conclusion:** 研究结果强调了关系属性在个人网络稳定性中的作用，并突出了在资源有限、文化独特的背景下进行网络研究时的设计考量。

> **ai_Abstract:** 本研究在罗马尼亚农村社区进行了一项双波个人网络调查，比较了两种姓名生成器（固定选择与自由选择）在关系人保留方面的效果。结果显示，亲属、同住者或情感亲近的关系人更容易被保留。这项研究强调了关系属性对个人网络稳定性的重要性，并为在资源有限、文化独特的环境中进行网络研究提供了实用的设计建议。

> **摘要翻译:** 我们在罗马尼亚农村社区进行了一项双波个人网络研究，对相同的参与者（n = 68）使用了两种姓名生成器。第一波采用侧重情感亲近的固定选择生成器（n = 25）；第二波使用基于频繁互动的自由选择生成器。我们比较了关系特征并评估了跨波次的保留情况。作为亲属、同住者或情感亲近的关系人更有可能被保留，无论生成器类型如何。这些发现强调了关系属性在个人网络稳定性中的作用，并突出了在资源有限、文化独特的背景下进行网络研究时的设计考量。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [563] [On feature selection in double-imbalanced data settings: a Random Forest approach](https://arxiv.org/abs/2506.10929)
> *双重不平衡数据设置下的特征选择：一种随机森林方法*

*Fabio Demaria* | **Main category: stat.ME**

**Keywords:** 特征选择, 双重不平衡数据, 随机森林, 最小深度, 变量选择

**Comment:** Working paper

> **TL;DR:** 本文提出了一种基于最小深度的随机森林新颖阈值方案，用于在响应变量存在类别不平衡和数据维度不对称（$n 	ext{»} p$）的双重不平衡数据设置下进行特征选择，实验证明该方法比传统方法更精简和准确。

**AI_Comments:** 本文创新性地解决了随机森林在双重不平衡数据下特征选择不稳定的问题，提出了一种基于最小深度的新颖阈值方案。其重要性在于提供了一种实用且可解释的方法，显著提高了特征选择的准确性和精简性。

<details>
  <summary>Details</summary>

**Motivation:** 在响应变量存在类别不平衡和数据维度不对称（$n 	ext{»} p$）的双重不平衡数据设置下，高维分类任务中的特征选择是一个关键步骤，但传统应用于随机森林的特征选择方法往往产生不稳定或误导性的重要性排名。

**Method:** 本文提出了一种基于最小深度的特征选择新颖阈值方案，该方案利用树拓扑结构来评估变量相关性。

**Result:** 在模拟和真实世界数据集上的大量实验表明，所提出的方法与传统的基于最小深度的选择方法相比，产生了更精简和准确的变量子集。

**Conclusion:** 该方法为双重不平衡条件下的随机森林变量选择提供了一种实用且可解释的解决方案。

> **ai_Abstract:** 本文针对响应变量类别不平衡和数据维度不对称的双重不平衡数据设置，提出了一种基于最小深度的新颖阈值方案，用于随机森林的特征选择。该方法利用树拓扑结构评估变量相关性，并通过实验证明其在生成更精简和准确的变量子集方面优于传统方法，为双重不平衡条件下的变量选择提供了一个实用且可解释的解决方案。

> **摘要翻译:** 特征选择是高维分类任务中的关键一步，特别是在双重不平衡的挑战性条件下，即响应变量存在类别不平衡和数据维度不对称（$n \gg p$）的设置。在这种情况下，应用于随机森林（RF）的传统特征选择方法通常会产生不稳定或误导性的重要性排名。本文提出了一种基于最小深度的特征选择新颖阈值方案，该方案利用树拓扑结构来评估变量相关性。在模拟和真实世界数据集上的大量实验表明，所提出的方法与传统的基于最小深度的选择方法相比，产生了更精简和准确的变量子集。该方法为双重不平衡条件下的随机森林变量选择提供了一种实用且可解释的解决方案。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [100] [Circulant TSP: Vertices of the Edge-Length Polytope and Superpolynomial Lower Bounds](https://arxiv.org/abs/2506.10758)
> *环状TSP：边长多面体的顶点和超多项式下界*

*Samuel C. Gutekunst* | **Main category: cs.DM**

**Keywords:** 环状TSP, 边长多面体, 超多项式下界, Buratti-Horak-Rosa猜想, 因子分解

**Comment:** 

> **TL;DR:** 本文研究环状旅行商问题（Circulant TSP）的边长多面体，发现其顶点数量与输入规模n的因子分解密切相关，揭示了某些情况下暴力算法的有效性。同时，为与Buratti-Horak-Rosa猜想相关的组合序列提供了超多项式下界。

**AI_Comments:** 这项研究创新性地将环状TSP的复杂性与数论中的因子分解联系起来，揭示了在特定情况下暴力算法的潜在效率，这与传统TSP的NP-hard特性形成鲜明对比。对Buratti-Horak-Rosa猜想的贡献也显示了其在组合数学领域的广度。

<details>
  <summary>Details</summary>

**Motivation:** 研究环状旅行商问题（Circulant TSP）的算法复杂性以及与Buratti-Horak-Rosa猜想相关的数论问题。环状TSP的整体复杂度仍是一个重要的未解问题。

**Method:** 通过研究边长多面体来分析环状TSP实例，并探究其顶点数量与n的因子分解之间的关系。作为中间步骤，还给出了与Buratti-Horak-Rosa猜想相关的两个组合序列的超多项式下界。

**Result:** 边长多面体的顶点数量与n的因子分解紧密相关：当n是素数时，顶点数量与n呈线性关系；当n是素数的平方时，顶点数量与n^(3/2)呈线性关系；但当n是2的幂时，顶点数量是超多项式数量。这表明对于环状TSP，在某些情况下，基于n的因子分解，暴力算法是有效的。此外，还给出了与Buratti-Horak-Rosa猜想相关的两个组合序列的超多项式下界。

**Conclusion:** 环状TSP的边长多面体顶点数量的特性表明，在特定条件下，暴力算法可能比预期更有效。这项研究也为Buratti-Horak-Rosa猜想提供了新的理论进展。

> **ai_Abstract:** 本文深入研究了环状旅行商问题（Circulant TSP）中的边长多面体，揭示了其顶点数量与输入规模n的因子分解之间的紧密联系。研究发现，当n为素数或素数平方时，顶点数量增长相对缓慢；而当n为2的幂时，顶点数量则呈现超多项式增长。这一发现颠覆了传统认知，表明在特定条件下，针对环状TSP的暴力算法可能出乎意料地高效。此外，本研究还为与Buratti-Horak-Rosa猜想相关的两个组合序列建立了超多项式下界。

> **摘要翻译:** 我们研究了边长多面体，其动机源于环状旅行商问题（Circulant TSP）的算法研究以及与Buratti-Horak-Rosa猜想相关的数论研究。环状TSP是TSP的一个特例，其整体复杂度仍是一个重要的未解问题。在输入顶点为{1, 2, ..., n}的情况下，边{i, j}的成本仅取决于其长度min{|i-j|, n-|i-j|}。边长多面体为解决环状TSP实例提供了一条途径，我们发现它与n的因子分解密切相关：当n是素数时，顶点数量与n呈线性关系；当n是素数的平方时，顶点数量与n^(3/2)呈线性关系；但当n是2的幂时，顶点数量是超多项式数量。相比之下，更标准的对称TSP多面体大约有n!个顶点。因此，对于环状TSP，基于n的因子分解，在某些情况下，检查每个顶点的暴力算法实际上是高效的。作为中间步骤，我们给出了与Buratti-Horak-Rosa猜想相关的两个组合序列的超多项式下界，该猜想询问哪些边长组合可以构成哈密顿路径。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [111] [A Hybrid Heuristic Framework for Resource-Efficient Querying of Scientific Experiments Data](https://arxiv.org/abs/2506.10422)
> *一种用于科学实验数据资源高效查询的混合启发式框架*

*Mayank Patel, Minal Bhise* | **Main category: cs.DB**

**Keywords:** 资源高效查询, 混合框架, 科学数据, RAW-HF, 工作负载感知

**Comment:** 

> **TL;DR:** 本文提出了一种轻量级的资源感知混合框架（RAW-HF），通过优化资源利用率来高效查询科学实验原始数据，显著减少了查询执行时间和资源消耗。

**AI_Comments:** 本文的创新点在于提出了一个轻量级的混合启发式框架RAW-HF，它结合了资源可用性和工作负载感知，以优化科学实验数据的查询。其重要性在于解决了大数据背景下数据查询的资源效率瓶颈，尤其是在科学数据领域。通过实际数据集的验证，展示了显著的性能提升，表明其在实际应用中具有很高的价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的数据库管理系统（DBMS）和HTAP系统在查询执行前需要耗费大量时间和资源加载整个数据集，而原位引擎可能多次重复解析所需数据，导致资源利用率和数据处理成本增加。此外，资源的过度或不足分配也会增加应用程序运行成本。

**Method:** 本文提出了一种轻量级的资源可用性与工作负载感知混合框架（RAW-HF），旨在通过高效利用现有有限资源来优化原始数据查询。RAW-HF包含有助于优化执行给定工作负载所需资源和最大化现有资源利用率的模块。它还比较了RAW-HF使用的MUAR技术与基于机器学习的资源分配技术（如PCC）。

**Result:** RAW-HF应用于Sloan Digital Sky Survey (SDSS)和Linked Observation Data (LOD)等真实世界科学数据集工作负载时，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）分别减少了90%和85%以上。与最先进的工作负载感知部分加载技术（WA）相比，RAW-HF将整体CPU、IO资源利用率和WET分别降低了26%、25%和26%，同时内存利用率提高了33%。

**Conclusion:** RAW-HF框架通过优化资源利用，显著提高了科学实验数据查询的效率，并在实际应用中展现出优于传统DBMS和现有混合系统的性能，有效降低了数据处理成本。

> **ai_Abstract:** 本文提出了一种名为RAW-HF的轻量级混合框架，旨在解决传统数据库和原位引擎在处理大规模科学实验数据时存在的资源效率低下和成本高昂的问题。RAW-HF通过其模块优化资源分配和利用率，从而高效查询原始数据。实验结果表明，与PostgreSQL和现有混合系统相比，RAW-HF显著减少了工作负载执行时间，并提高了资源利用效率，有效降低了数据处理成本。

> **摘要翻译:** 科学实验和现代应用程序每天都会生成大量数据。大多数组织利用内部服务器或云资源来管理应用程序数据和工作负载。传统的数据库管理系统（DBMS）和HTAP系统在开始查询执行之前，需要花费大量时间和资源加载整个数据集。另一方面，原位引擎可能会多次重新解析所需数据，从而增加资源利用率和数据处理成本。此外，资源的过度或不足分配也会增加应用程序运行成本。本文提出了一种轻量级的资源可用性与工作负载感知混合框架（RAW-HF），旨在通过高效利用现有有限资源来优化原始数据查询。RAW-HF包含有助于优化执行给定工作负载所需资源和最大化现有资源利用率的模块。将RAW-HF应用于Sloan Digital Sky Survey (SDSS)和Linked Observation Data (LOD)等真实世界科学数据集工作负载的结果表明，与广泛使用的传统DBMS PostgreSQL相比，工作负载执行时间（WET）分别减少了90%和85%以上。与最先进的工作负载感知部分加载技术（WA）相比，整体CPU、IO资源利用率和WET分别降低了26%、25%和26%，同时内存利用率提高了33%。本文还比较了RAW-HF使用的MUAR技术与基于机器学习的资源分配技术（如PCC）。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matdis-nn'></a>
## cond-mat.dis-nn 

### [173] [Learning Chaotic Dynamics with Neuromorphic Network Dynamics](https://arxiv.org/abs/2506.10773)
> *利用神经形态网络动力学学习混沌动力学*

*Yinhao Xu, Georg A. Gottwald, Zdenka Kuncic* | **Main category: cond-mat.dis-nn**

**Keywords:** 神经形态网络, 混沌动力学, 忆阻元件, 储层计算, 动力系统

**Comment:** 37 pages, 22 figures

> **TL;DR:** 本研究探讨了如何利用基于忆阻元件的神经形态网络（本身也是一个动力系统）来学习和建模混沌动力学，并通过外部控制参数优化其学习能力。

**AI_Comments:** 这项研究的创新之处在于利用神经形态网络的固有动力学特性，特别是基于忆阻元件的电路，来直接学习和模拟混沌系统，而不是仅仅将其作为传统的计算单元。它强调了利用物理系统本身的特性进行计算的潜力，为未来高效、低功耗的神经形态计算设备设计提供了新的思路。其重要性在于为理解如何通过简单的外部控制参数优化复杂物理系统以执行计算任务提供了实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探究如何利用神经形态网络（其本身就是一个动力系统）来学习和建模其他动力系统，并利用其底层物理特性进行计算。

**Method:** 研究使用了基于忆阻元件的复杂电路构建的神经形态网络。该网络在储层计算框架下，通过模拟和评估其对多元混沌时间序列的自主预测能力。通过操纵输入电极和电压来优化网络响应。

**Result:** 当输入电压使忆阻元件的内部动力学探索其整个动力学范围时，发现了最佳的非线性动力学响应。增加输入电极的网络覆盖率可以抑制不利于学习的其他非线性响应。

**Conclusion:** 这些结果为如何仅使用外部控制参数来优化实际神经形态网络设备以学习复杂动力系统提供了宝贵的见解。

> **ai_Abstract:** 本研究探索了利用基于忆阻元件的神经形态网络（作为一个动力系统）学习和建模混沌动力学的方法。通过模拟并结合储层计算框架，研究评估了该网络在多元混沌时间序列自主预测上的表现。结果表明，通过优化输入电压使忆阻器充分探索其动力学范围，以及增加输入电极覆盖率，能够获得最佳的非线性响应并抑制不利于学习的响应。这些发现为通过外部控制参数优化神经形态设备学习复杂动力系统提供了重要指导。

> **摘要翻译:** 本研究探讨了如何利用神经形态网络（其本身也是一个动力系统）来学习和建模动力系统。本研究中使用的神经形态网络基于一个复杂的电路，该电路包含忆阻元件，这些元件对输入的电信号产生神经突触的非线性响应。为了确定如何利用底层系统的物理特性进行计算，对神经形态网络进行了模拟和评估，以实现多元混沌时间序列的自主预测，并采用储层计算框架。通过仅操纵输入电极和电压，当输入电压使忆阻元件的内部动力学探索忆阻器模型的整个动力学范围时，发现了最佳的非线性动力学响应。研究发现，增加输入电极的网络覆盖率可以抑制其他不利于学习的非线性响应。这些结果为如何仅使用外部控制参数来优化实际神经形态网络设备以学习复杂动力系统提供了宝贵见解。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

### [552] [On the role of non-linear latent features in bipartite generative neural networks](https://arxiv.org/abs/2506.10552)
> *双向生成神经网络中非线性潜在特征的作用*

*Tony Bonnaire, Giovanni Catania, Aurélien Decelle, Beatriz Seoane* | **Main category: cond-mat.dis-nn**

**Keywords:** 受限玻尔兹曼机, 联想记忆, 隐藏单元, 统计物理学, 相图

**Comment:** 23 pages, 5 figures

> **TL;DR:** 研究了RBM中隐藏单元先验分布对其相图和记忆检索能力的影响，发现标准RBM容量受限，通过引入局部偏差和更丰富的隐藏单元先验可显著改善性能。

**AI_Comments:** 这篇论文通过统计物理学的方法深入分析了受限玻尔兹曼机（RBMs）的内在机制和局限性。其创新点在于揭示了标准RBM在联想记忆方面的容量瓶颈，并提出了通过优化隐藏单元设计（如引入局部偏差和丰富先验分布）来显著提升其性能的有效策略。这对于理解和改进基于能量的生成模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨限制玻尔兹曼机（RBM）作为联想记忆的有效性问题，特别是标准RBM在广泛连接下临界容量降低的问题。

**Method:** 运用无序系统统计物理学分析工具，并与Hopfield模型建立联系，探索架构选择和激活函数如何影响RBM的热力学性质。通过引入局部偏差和采用更丰富的隐藏单元先验分布（包括二元、多态和ReLU类激活）来修改RBM。通过有限尺寸蒙特卡洛模拟支持理论发现。

**Result:** 标准RBM在二元隐藏节点和广泛连接下，临界容量降低，限制了其作为联想记忆的有效性。引入局部偏差和采用更丰富的隐藏单元先验可恢复有序检索阶段，并显著改善召回性能，即使在有限温度下也是如此。

**Conclusion:** 隐藏单元设计对于增强RBM的表达能力至关重要。

> **ai_Abstract:** 这项研究调查了受限玻尔兹曼机（RBMs）的相图和记忆检索能力，重点关注隐藏单元的先验分布（如二元、多态和ReLU类激活）。研究发现，标准RBMs由于临界容量受限而作为联想记忆效率不高。通过引入局部偏差和更丰富的隐藏单元先验，可以显著提高RBM的召回性能并恢复有序检索，强调了隐藏单元设计对RBM表达能力的关键作用。

> **摘要翻译:** 我们研究了双向基于能量的神经网络，即受限玻尔兹曼机（RBMs）的相图和记忆检索能力，作为对其隐藏单元施加的先验分布（包括二元、多态和类ReLU激活）的函数。通过与Hopfield模型的联系，并运用无序系统统计物理学的分析工具，我们探索了架构选择和激活函数如何塑造这些模型的热力学性质。我们的分析揭示，具有二元隐藏节点和广泛连接的标准RBMs的临界容量降低，限制了它们作为联想记忆的有效性。为了解决这个问题，我们研究了几种修改，例如引入局部偏差和采用更丰富的隐藏单元先验。这些调整恢复了有序检索阶段，并显著提高了召回性能，即使在有限温度下也是如此。我们的理论发现得到了有限尺寸蒙特卡洛模拟的支持，突出了隐藏单元设计在增强RBMs表达能力方面的重要性。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [207] [Revisiting mean estimation over $\ell_p$ balls: Is the MLE optimal?](https://arxiv.org/abs/2506.10354)
> *重新审视 $\ell_p$ 球上的均值估计：最大似然估计器是最优的吗？*

*Liviu Aolaritei, Michael I. Jordan, Reese Pathak, Annie Ulichney* | **Main category: math.ST**

**Keywords:** 均值估计, $\ell_p$ 球, 最大似然估计器, 最小最大率, 非线性估计

**Comment:** 37 pages, 3 figures

> **TL;DR:** 本文研究了在加性高斯噪声下，$\ell_p$ 球上均值估计的最大似然估计器（MLE）的性能。结果表明，当 $p \in (1,2)$ 时，尽管 MLE 是非线性的，但它在最小最大意义上是次优的，而在其他 $p$ 值附近（接近1或大于等于2）则可能是最优的。

**AI_Comments:** 该论文对最大似然估计器（MLE）在 $\ell_p$ 球均值估计中的普遍最优性提出了质疑。其创新之处在于揭示了 MLE 在特定 $p$ 范围（$p \in (1,2)$）内的次优行为，这对于理解 MLE 的局限性及其在非线性估计问题中的适用性具有重要意义。该研究不仅提供了理论分析，还通过构造性下界给出了明确的证据，增强了结果的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 在加性高斯噪声下，当 $p$ 严格小于 $2$ 时，已知率最优估计器必须是非线性的。本文重新审视了 $\ell_p$ 球上的均值估计问题，并深入研究了最大似然估计器（MLE）的性能，以探讨其是否为最优估计器。

**Method:** 本文研究了最大似然估计器（MLE），并证明了其行为的两种现象，这些现象取决于噪声水平、范数约束半径、维度和范数指数 $p$。研究还通过构造性的下界证明了 MLE 次优的情况，并提供了 MLE 明显导致次优风险的显式实例。

**Result:** 1. 当 $p$ 接近 $1$ 或至少 $2$ 时，MLE 在所有噪声水平和所有约束半径下都是最小最大率最优的。
2. 当 $p$ 介于 $1$ 和 $2$ 之间时，对于几乎所有需要非线性估计的噪声水平和半径，尽管 MLE 在观测值中是非线性的，但它在最小最大率上是次优的。
3. 当给定 $n$ 个独立同分布的高斯样本时，MLE 可能比最优估计器次优一个多项式因子。
4. 提供了当 MLE 率次优时，MLE 风险明显次优的显式实例。

**Conclusion:** 本文研究表明，在 $\ell_p$ 球上的均值估计问题中，最大似然估计器（MLE）并非总是最优的。特别是在 $p$ 介于 $1$ 和 $2$ 之间时，MLE 即使是非线性的，其性能也可能远低于最小最大最优率，这挑战了其普遍最优性的假设。

> **ai_Abstract:** 本文研究了在加性高斯噪声下 $\ell_p$ 球上的均值估计问题，重点分析了最大似然估计器（MLE）的性能。研究发现，MLE 的最优性取决于范数指数 $p$。具体而言，当 $p$ 接近 $1$ 或至少 $2$ 时，MLE 达到最小最大率最优；然而，当 $p$ 介于 $1$ 和 $2$ 之间时，MLE 即使是非线性的，也表现出最小最大率次优性。此外，对于独立同分布的高斯样本情况，MLE 也可能次优一个多项式因子。研究通过构造性下界提供了 MLE 次优的实例。

> **摘要翻译:** 我们重新审视了加性高斯噪声下 $\ell_p$ 球上的均值估计问题。当 $p$ 严格小于 $2$ 时，众所周知，率最优估计器必须是非线性的。在这项工作中，我们研究了最大似然估计器（MLE），它可以被视为 $\ell_p$ 球上均值估计的一种非线性收缩过程。我们展示了 MLE 行为的两种现象，这取决于噪声水平、范数约束半径、维度和范数指数 $p$。首先，作为维度的一个函数，当 $p$ 接近 $1$ 或至少 $2$ 时，MLE 对于所有噪声水平和所有约束半径都是最小最大率最优的。另一方面，当 $p$ 介于 $1$ 和 $2$ 之间时，存在一种更显著的行为：对于几乎所有需要非线性估计的噪声水平和半径，尽管 MLE 在观测值中是非线性的，但它在最小最大率上是次优的。我们的结果也意味着当给定 $n$ 个独立同分布的高斯样本时，有类似的结论，我们证明了 MLE 在样本量上可能次优一个多项式因子。我们的下界是构造性的：无论何时 MLE 率次优，我们都提供了 MLE 明显导致次优风险的显式实例。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='physicsclass-ph'></a>
## physics.class-ph 

### [287] [Impacts between multibody systems and deformable structures](https://arxiv.org/abs/2506.10034)
> *多体系统与可变形结构之间的冲击*

*Lipinski Krzysztof* | **Main category: physics.class-ph**

**Keywords:** 冲击, 多体系统, 可变形结构, 刚体方法, 软接触方法

**Comment:** 20 pages, 11 figures, submitted to Virtual Conference Proceeding of
  12th ECCOMAS Thematic Conference on Multibody Dynamics - Innsbruck July
  13-18, 2025 and to the journal of Multibody System Dynamics

> **TL;DR:** 本文讨论了多体系统与可变形结构之间冲击的精确建模问题，并探讨了刚体方法和软接触方法，重点关注多边接触和弹性碰撞。

**AI_Comments:** 这篇论文探讨了冲击建模这一复杂且重要的工程动力学问题。其重要性在于冲击在许多系统动态响应中扮演关键角色。论文的贡献可能在于对刚体和软接触方法在处理多体系统与可变形结构之间复杂冲击（特别是多边单边接触和弹性碰撞）方面的比较和应用。局限性可能在于摘要中未明确指出具体的创新点或量化结果。

<details>
  <summary>Details</summary>

**Motivation:** 冲击的精确建模是一个挑战性问题，因为缺乏准确和普遍接受的本构律来描述其力学行为。

**Method:** 论文讨论并检验了刚体方法和软接触方法，并通过数值例子进行验证。主要关注点是具有多个单边接触的系统中的冲击以及与参考系弹性元件的碰撞，并讨论了互连单边弹簧的参数。

**Result:** 论文讨论并检验了刚体方法和软接触方法，并在数值例子中进行了验证。互连单边弹簧的参数正在讨论中。具体的量化结果未在摘要中提及。

**Conclusion:** 本文讨论了多体系统与可变形结构之间冲击的精确建模问题，并探讨了刚体方法和软接触方法在处理多边单边接触和弹性元件碰撞方面的应用。

> **ai_Abstract:** 本文旨在解决多体系统与可变形结构之间冲击的精确建模难题，指出其主要挑战在于缺乏统一的本构律。文章讨论并检验了刚体方法和软接触方法，并通过数值例子进行验证。研究重点在于处理具有多个单边接触的系统中的冲击以及与弹性元件的碰撞，并对互连单边弹簧的参数进行了深入探讨。

> **摘要翻译:** 碰撞和冲击是系统动态响应中常见脉冲运动的主要原因。由于缺乏准确且普遍接受的本构律来描述其力学行为，冲击的精确建模是一个具有挑战性的问题。本文讨论了刚体方法和软接触方法，并在所提供的数值示例中进行了检验。主要关注点是具有多个单边接触的系统中的冲击以及与参考系弹性元件的碰撞。互连单边弹簧的参数正在讨论中。

</details>

[⬆️ 返回分类顶部](#physicsclass-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [326] [Optimal Voltage Control Using Online Exponential Barrier Method](https://arxiv.org/abs/2506.10247)
> *使用在线指数障碍法的最优电压控制*

*Peng Zhang, Baosen Zhang* | **Main category: math.OC**

**Keywords:** 最优电压控制, 在线指数障碍法, 配电系统, 模型不准确, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种在线指数障碍法，用于在模型信息不准确的情况下，对高渗透率逆变器型可再生能源的配电系统进行最优电压控制，并通过实验验证了其对模型不准确的鲁棒性显著提高。

**AI_Comments:** 本文提出了一种新颖的在线指数障碍法，其创新之处在于能够有效应对配电系统中日益增长的可再生能源渗透率带来的电压控制挑战，尤其是在模型信息不准确的现实条件下。通过结合在线反馈和理论分析，该方法不仅提高了控制的鲁棒性，还提供了安全保证和收敛性证明，具有较高的理论和实际应用价值。其对模型不准确的显著改进是其重要性的一大体现。

<details>
  <summary>Details</summary>

**Motivation:** 解决配电系统在高渗透率逆变器型可再生能源和模型信息不准确情况下的最优电压控制问题。

**Method:** 提出在线指数障碍法，利用电网在线反馈增强对模型不准确的鲁棒性，并纳入电压约束以满足安全要求。提供了关于最优障碍参数选择和收敛电压安全保证的充分条件的分析结果。建立了适当步长下指数收敛速度的理论结果。

**Result:** 在56节点辐射状网络上验证了所提出框架的有效性，与现有方法相比，显著提高了对模型不准确的鲁棒性。

**Conclusion:** 所提出的在线指数障碍法能有效解决高渗透率可再生能源配电系统的最优电压控制问题，并在模型不准确的情况下表现出更高的鲁棒性。

> **ai_Abstract:** 本文提出了一种在线指数障碍法来解决高渗透率逆变器型可再生能源配电系统在模型信息不准确下的最优电压控制问题。该方法利用在线反馈提高鲁棒性，并包含电压约束确保安全。研究提供了最优参数选择和安全保证的分析结果，并证明了指数收敛速度。在56节点网络上的验证显示，该方法在应对模型不准确方面显著优于现有技术。

> **摘要翻译:** 本文解决了在模型信息不准确的情况下，具有高渗透率逆变器型可再生能源的配电系统的最优电压控制问题。我们提出了在线指数障碍法，该方法明确利用来自电网的在线反馈来增强对模型不准确的鲁棒性，并结合电压约束以保持安全要求。我们提供了关于最优障碍参数选择和收敛电压安全保证的充分条件的分析结果。我们还建立了在适当步长下指数收敛速度的理论结果。所提出的框架在56节点辐射状网络上得到了验证，与现有方法相比，我们显著提高了对模型不准确的鲁棒性。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [336] [On a mean-field Pontryagin minimum principle for stochastic optimal control](https://arxiv.org/abs/2506.10506)
> *随机最优控制的平均场庞特里亚金最小原理*

*Manfred Opper, Sebastian Reich* | **Main category: math.OC**

**Keywords:** 庞特里亚金最小原理, 随机最优控制, 平均场, 规范变量, 确定性控制

**Comment:** 

> **TL;DR:** 本文提出了一种新的确定性平均场庞特里亚金最小原理，用于随机最优控制，通过引入规范变量简化了方程求解，并进行了数值验证。

**AI_Comments:** 这篇论文通过引入“平均场”和“规范变量”的概念，为随机最优控制提供了一种创新的、确定性的方法，避免了传统随机庞特里亚金原理中复杂的前向-后向随机微分方程。这种方法的创新之处在于其确定性性质和简化求解过程的能力，对于实际应用中的计算效率和可实现性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的随机庞特里亚金最小原理涉及复杂的前向-后向随机微分方程，本文旨在提供一种确定性的平均场方法来简化随机最优控制问题的求解。

**Method:** 本文提出了一种确定性的平均场庞特里亚金最小原理，通过引入适当的规范变量来构建哈密顿结构，并利用规范自由度解耦前向和反向时间方程。对于无限时域问题，将最优控制律的计算转换为求解一对前向平均场常微分方程。

**Result:** 所提出的方法能够解耦前向和反向时间方程，从而简化了边值问题的求解。对于无限时域问题，可以将最优控制律的计算转化为求解一对前向平均场常微分方程。该方法已在受控倒立摆和受控Lorenz-63系统上进行了数值测试。

**Conclusion:** 本文成功地将经典的庞特里亚金最小原理扩展到随机最优控制问题，提出了一种确定性平均场方法，通过规范变量简化了求解过程，并展示了其在实际系统中的有效性。

> **ai_Abstract:** 本文提出了一种新颖的、确定性的平均场庞特里亚金最小原理，用于解决随机最优控制问题。该方法通过引入规范变量构建哈密顿结构，并利用规范自由度解耦了前向和反向时间方程，从而简化了边值问题的求解。对于无限时域问题，该方法将最优控制律的计算转化为求解前向平均场常微分方程。该原理已在受控倒立摆和Lorenz-63系统上进行了数值验证。

> **摘要翻译:** 本文概述了经典庞特里亚金最小（最大）原理在随机最优控制问题上的新颖扩展。与涉及前向-后向随机微分方程的众所周知的随机庞特里亚金最小原理相反，所提出的公式是确定性的，并且是平均场类型的。所提出的庞特里亚金最小原理的哈密顿结构是通过引入适当的规范变量实现的。规范自由度可用于解耦前向和反向时间方程；从而简化了底层边值问题的求解。我们还考虑了无限时域折现成本最优控制问题。在这种情况下，平均场公式允许将所需最优控制律的计算转换为求解一对前向平均场常微分方程。所提出的庞特里亚金最小原理的平均场公式在受控倒立摆和受控Lorenz-63系统上进行了数值测试。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [363] [A space-time interface-fitted method for moving-subdomain distributed control problems with energy regularization](https://arxiv.org/abs/2506.10924)
> *具有能量正则化的移动子域分布式控制问题的时空界面拟合方法*

*Quang Huy Nguyen, Phuong Cuc Hoang, Van Chien Le, Thi Thanh Mai Ta* | **Main category: math.OC**

**Keywords:** 最优控制, 移动界面, 时空方法, Petrov-Galerkin, 能量正则化

**Comment:** 

> **TL;DR:** 本文研究了具有能量正则化的移动界面最优控制问题，提出并分析了一种时空界面拟合的Petrov-Galerkin近似方法，建立了最佳误差估计，并用数值结果进行了验证。

**AI_Comments:** 本文为处理涉及移动界面的最优控制问题提供了一种新颖且严谨的数值方法。时空界面拟合网格和Petrov-Galerkin方法的结合，加上详尽的误差分析，显著提升了对此类复杂问题的求解能力，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究具有能量正则化的移动界面最优控制问题的时空界面拟合近似方法。

**Method:** 将最优性条件重新表述为一个涉及状态和伴随变量的变分问题，并证明其等同于最优控制问题。基于完全非结构化的时空界面拟合网格，提出并分析了该问题的Petrov-Galerkin近似。在状态和伴随变量的特定正则性假设下，建立了关于离散范数的最佳误差估计。

**Result:** 建立了关于离散范数的最佳误差估计。提出了几个数值结果来证实理论结果。

**Conclusion:** 本文提出的时空界面拟合Petrov-Galerkin近似方法对于具有能量正则化的移动界面最优控制问题是有效的，并得到了理论分析（最佳误差估计）和数值结果的支持。

> **ai_Abstract:** 本文针对具有能量正则化的移动界面最优控制问题，将其最优性条件转化为一个等价的变分问题。在此基础上，提出并分析了一种基于非结构化时空界面拟合网格的Petrov-Galerkin近似方法，并在特定正则性假设下建立了最佳误差估计。数值结果验证了理论分析的正确性。

> **摘要翻译:** 本文研究了具有能量正则化的移动界面最优控制问题的时空界面拟合近似。我们将最优性条件重新表述为一个涉及状态和伴随变量的变分问题。该问题被证明等同于我们的最优控制问题。基于完全非结构化的时空界面拟合网格，我们提出并分析了该问题的Petrov-Galerkin近似。在状态和伴随变量的特定正则性假设下，建立了关于离散范数的最佳误差估计。提出了几个数值结果来证实我们的理论结果。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [559] [The Gittins Index: A Design Principle for Decision-Making Under Uncertainty](https://arxiv.org/abs/2506.10872)
> *Gittins 指数：不确定性下决策的设计原则*

*Ziv Scully, Alexander Terenin* | **Main category: math.OC**

**Keywords:** Gittins 指数, 不确定性决策, 多臂老虎机, 贝叶斯优化, 队列优化

**Comment:** 

> **TL;DR:** Gittins 指数是一种解决不确定性下决策问题的工具。尽管其应用范围有限且定义微妙，本教程旨在通过示例展示其在贝叶斯优化和队列尾部延迟最小化等实际问题中的有效应用。

**AI_Comments:** 本文创新性地将 Gittins 指数从一个理论概念提升为实用的决策工具，通过具体示例展示了其在复杂不确定性问题中的应用潜力。其重要性在于拓宽了 Gittins 指数的应用边界，特别是指出其在次优解情况下仍能提供优秀性能，这对于实际工程应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** Gittins 指数常被视为纯粹的理论概念而非实用工具，且其完美最优解的问题空间有限、定义微妙。本文旨在纠正这种看法，证明 Gittins 指数可以有效地应用于实际问题。

**Method:** 本教程通过示例驱动的方式介绍 Gittins 指数，并逐步展示其解决多种问题的能力，包括一些最优解和一些次优但性能优异的例子，特别强调了其在贝叶斯优化和队列尾部延迟最小化中的应用。

**Result:** 论文展示了 Gittins 指数可以有效地应用于实际问题，包括在贝叶斯优化和队列尾部延迟最小化等场景中实现优秀性能，即使是在提供次优解的情况下。

**Conclusion:** Gittins 指数不仅仅是一个理论概念，它也是一个可以有效应用于实际决策问题的工具，即便在某些情况下只能提供次优解，其性能依然出色。

> **ai_Abstract:** 本教程旨在纠正 Gittins 指数被视为纯理论工具的普遍看法，通过提供示例驱动的介绍，并展示其在解决多臂老虎机、队列优化和搜索问题中的应用，证明其在实际问题中的有效性。论文强调了 Gittins 指数在贝叶斯优化和队列尾部延迟最小化等实际场景中，即使是次优解也能表现出色。

> **摘要翻译:** Gittins 指数是一种能够最优地解决各种涉及不确定性的决策问题的工具，包括多臂老虎机问题、最小化队列平均延迟以及潘多拉魔盒模型等搜索问题。然而，尽管有上述例子及其后续扩展，Gittins 指数能够完美最优解决的问题空间是有限的，而且与其他的多臂老虎机算法相比，它的定义相当微妙。因此，Gittins 指数通常被认为主要是一个具有理论重要性的概念，而非解决决策问题的实用工具。
本教程的目的是证明 Gittins 指数可以有效地应用于实际问题。我们首先通过示例驱动的方式介绍 Gittins 指数，然后逐步讲解它解决的几个问题示例——有些是最佳的，有些是次优但仍表现出色的。后一类中的两个实际亮点是将 Gittins 指数应用于贝叶斯优化，以及将其应用于最小化队列中的尾部延迟。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [329] [Fast Ramanujan--type Series for Logarithms. Part II](https://arxiv.org/abs/2506.10321)
> *快速拉马努金型对数级数。第二部分*

*Jorge Zuniga* | **Main category: math.NT**

**Keywords:** 拉马努金级数, 对数, 超几何公式, 整数规划, 数值计算

**Comment:** 17 pages, 1 table. TeX file must be downloaded, PARI GP program is
  embedded as a large comment there

> **TL;DR:** 本文扩展了拉马努金型对数级数的研究，提出了反正切的新公式和对数快速多级数评估方法，并通过整数规划优化了级数组合，实现了单一对数和多值对数的高效计算，并将log(10)的精度扩展至2.0·10^12位。

**AI_Comments:** 该论文的创新之处在于应用整数规划来优化拉马努金型级数中变量值的选择，从而为对数计算提供了高效且创纪录的方法。其重要性在于推动了数值常数计算的界限。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在扩展先前关于拉马努金型级数在对数高效计算方面的成果，开发反正切的新公式和对数非常快速的多级数评估方法，特别是用于同步计算多个对数。

**Method:** 该方法基于$	ext{log}(p)$在$pightarrow1$时的$	ext{O}((p-1)^6)$拉马努金型级数渐近逼近。通过解决一个整数规划问题，在有限格$	ext{Z}^n$中识别最优变量值，从而推导出计算$	ext{n}$个同步对数的公式。这种方法产生了级数的线性组合。

**Result:** 该方法提供了：(i) 自然数单一对数的高效公式；(ii) $	ext{Z}_{>1}$中$	ext{n}$个选定整数多值对数的最快已知超几何公式。这些成果的一个应用是将log(10)的已知小数位数扩展到2.0·10^12位。

**Conclusion:** 通过结合整数规划和拉马努金型级数，本文开发的方法显著提高了单一对数和多个对数计算的效率和速度，并为特定常数如log(10)的计算达到了创纪录的精度。

> **ai_Abstract:** 本文《快速拉马努金型对数级数。第二部分》扩展了先前工作，引入了反正切新公式和对数快速多级数评估方法。通过解决整数规划问题来优化级数组合，开发了同步对数计算公式。这产生了高效的单一对数公式和已知最快的超几何多值对数公式，并成功将log(10)的计算精度扩展至2.0·10^12位。

> **摘要翻译:** 这项工作扩展了预印本《拉马努金型对数级数，第一部分》（arXiv:2506.08245）的成果，该预印本介绍了用于有效计算$	ext{log}(p)$（其中$p	ext{∈Z}_{>1}$）的单一超几何型恒等式。我们提出了反正切的新公式以及对数非常快速的多级数评估方法。在$	ext{log}(p)$在$pightarrow1$时的一个$	ext{O}((p-1)^6)$拉马努金型级数渐近逼近的基础上，开发了计算$	ext{n}$个同步对数的公式。这些公式是通过解决一个整数规划问题来推导的，以在有限格$	ext{Z}^n$中识别最优变量值。这种方法产生了级数的线性组合，提供了：(i) 自然数单一对数的高效公式；(ii) $	ext{Z}_{>1}$中$	ext{n}$个选定整数多值对数的最快已知超几何公式。这些成果的一个应用是将log(10)的已知小数位数扩展到2.0·10^12位（2025年6月6日）。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='csos'></a>
## cs.OS 

### [376] [Playing in the Sandbox: A Study on the Usability of Seccomp](https://arxiv.org/abs/2506.10234)
> *在沙箱中玩耍：Seccomp可用性研究*

*Maysara Alhindi, Joseph Hallett* | **Main category: cs.OS**

**Keywords:** Seccomp, 沙箱, 可用性, 开发者, 挑战

**Comment:** 

> **TL;DR:** 研究了7名经验丰富的Seccomp开发者对沙箱化应用的可用性挑战，发现他们的方法和解决方案各不相同，并指出了Seccomp的使用难点。

**AI_Comments:** 这项研究通过用户研究方法直接探究了Seccomp沙箱技术的实际可用性问题，而非仅仅关注技术本身。其创新之处在于揭示了开发者在实际操作中面临的具体困难，这对于改进沙箱工具的设计和推广具有重要意义。研究结果表明，即使是经验丰富的开发者也面临挑战，暗示了该技术在普及方面存在可用性障碍。

<details>
  <summary>Details</summary>

**Motivation:** 尽管沙箱技术能够限制应用程序行为并防止被利用的进程被滥用，但实际应用中很少有程序被沙箱化，本研究旨在探究其原因。

**Method:** 对7名有经验的Seccomp开发者进行了一项可用性试验，观察他们如何对应用程序进行沙箱化以及他们面临的困难。

**Result:** 开发者们对沙箱化应用程序采取了不同的方法，并得出了不同的解决方案。研究揭示了使用Seccomp的诸多挑战、参与者的沙箱设计，以及开发者认为能有效简化沙箱化应用的改进建议。

**Conclusion:** 本研究揭示了Seccomp在实际应用中面临的可用性挑战，并提出了开发者对改进沙箱化工具的期望，这对于未来提升沙箱技术的普及和效率具有指导意义。

> **ai_Abstract:** 本研究通过对7名经验丰富的Seccomp开发者进行可用性试验，探究了应用程序沙箱化过程中遇到的挑战。结果显示，开发者们在沙箱化方法和解决方案上存在显著差异，研究识别了Seccomp的诸多使用难题，并收集了开发者关于如何提高沙箱化效率的建议。

> **摘要翻译:** 沙箱技术限制了应用程序的行为，并防止被利用的进程被滥用；然而，相对较少的应用程序被沙箱化：为什么？我们报告了一项针对7名经验丰富的Seccomp开发者进行的可用性试验，探讨了他们如何进行应用程序沙箱化以及他们面临的困难。开发者们各自以不同的方式进行应用程序沙箱化，并得出了不同的解决方案。我们强调了使用Seccomp的许多挑战、参与者的沙箱设计，以及开发者认为什么能让他们更有效地沙箱化应用程序。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [424] [From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop](https://arxiv.org/abs/2506.10021)
> *从工具调用到符号思维：LLM在持久Lisp元编程循环中*

*Jordi de la Torre* | **Main category: cs.PL**

**Keywords:** LLM, Lisp, 元编程, 符号思维, 工具创建

**Comment:** 

> **TL;DR:** 该论文提出了一种新颖的架构，将大型语言模型（LLM）与持久的Lisp环境集成，使LLM能够通过程序化交互定义、调用和演化自己的工具，从而实现有状态的外部记忆、反射编程和动态工具创建。

**AI_Comments:** 这篇论文的创新之处在于提出了LLM与Lisp环境的深度集成，超越了传统的工具调用，实现了更高级的元编程能力。它在弥合神经AI和符号AI之间的鸿沟方面具有重要意义，有望带来更健壮和自适应的AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种将大型语言模型（LLM）与持久、交互式Lisp环境集成的新架构，以使LLM能够通过程序化交互定义、调用和演化自己的工具，并为未来集成符号编程与神经语言生成的交互式AI系统提供设计框架和架构原则。

**Method:** 该方法提出了一种新颖的架构，通过在生成中嵌入Lisp表达式并通过中间件层拦截，使LLM能够通过与实时REPL的程序化交互来定义、调用和演化其工具。这允许实现有状态的外部记忆、反射编程和动态工具创建。

**Result:** 论文提出了一个设计框架和架构原则，用于指导未来集成符号编程与神经语言生成的交互式AI系统的实现。

**Conclusion:** 该论文提出了一种将LLM与Lisp环境深度集成的新颖架构，通过实现动态工具创建、反射编程和有状态外部记忆，为未来结合符号编程和神经语言生成的交互式AI系统提供了重要的设计框架和原则。

> **ai_Abstract:** 本文提出了一种将大型语言模型（LLM）与持久、交互式Lisp环境集成的新颖架构。该架构允许LLM通过与实时REPL的程序化交互来定义、调用和演化自己的工具。通过在LLM生成中嵌入和拦截Lisp表达式，系统实现了有状态的外部记忆、反射编程和动态工具创建。论文还提出了一个设计框架和架构原则，旨在指导未来结合符号编程与神经语言生成的交互式AI系统的开发。

> **摘要翻译:** 我们提出了一种将大型语言模型（LLM）与持久、交互式Lisp环境集成的新颖架构。这种设置使LLM能够通过与实时REPL的程序化交互来定义、调用和演化自己的工具。通过在生成中嵌入Lisp表达式并通过中间件层拦截它们，该系统允许有状态的外部记忆、反射编程和动态工具创建。我们提出了一个设计框架和架构原则，以指导未来集成符号编程与神经语言生成的交互式AI系统的实现。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [510] [Encoding call-by-push-value in the pi-calculus](https://arxiv.org/abs/2506.10584)
> *在 Pi 演算中编码按值推送调用*

*Benjamin Bennetzen, Nikolaj Rossander Kristensen, Peter Buus Steffensen* | **Main category: cs.LO**

**Keywords:** 按值推送调用, Pi 演算, 编码, 可靠性, 完备性

**Comment:** 56 pages

> **TL;DR:** 本文定义了 Levy 的按值推送 λ 演算 (CBPV) 在 Pi 演算中的编码，并证明了其完备性和可靠性，同时讨论了与 Gorla 准则的符合性以及与 Milner 编码的相似性。

**AI_Comments:** 该论文在理论计算机科学领域，尤其是在进程演算和 λ 演算的交叉点上，具有重要意义。通过在 Pi 演算中编码 CBPV 并严格证明其可靠性和完备性，为理解不同计算模型之间的关系提供了深刻见解。值得注意的是，虽然部分证明是手动的或非形式化的，但作者明确指出了这一点，并正在进行 Coq 中的形式化工作，这表明了对严谨性的追求。满足 Gorla 的良好编码标准进一步增强了这项工作的价值。

<details>
  <summary>Details</summary>

**Motivation:** 定义 Levy 的按值推送 λ 演算 (CBPV) 在 Pi 演算中的编码，并证明其可靠性和完备性。

**Method:** 在 Pi 演算中定义了 CBPV 的编码，并提供了可靠性、完备性及所有必需引理的非正式（手动）证明。编码专门针对内部 Pi 演算（pi-i-calculus）以规避 De Bruijn 索引的挑战，并有助于双模拟。此外，还包括异步多重 Pi 演算和局部 Pi 演算中的编码。部分证明在 Coq 中进行了形式化。

**Result:** 编码被证明是可靠且完备的。编码满足 Gorla 提出的良好编码的五项标准，并显示出与 Milner 编码的相似性。

**Conclusion:** 本文成功地在 Pi 演算中编码了 CBPV，并验证了其关键属性。尽管部分引理未完全形式化证明，但其合理性得到了论证，且正在进行 Coq 中的形式化工作。

> **ai_Abstract:** 本文定义了 Levy 的按值推送 λ 演算 (CBPV) 在 Pi 演算中的编码，并证明了其可靠性和完备性。研究专注于内部 Pi 演算以简化形式化和双模拟。作者提供了非正式证明，并论证了编码符合 Gorla 的良好编码标准，同时指出与 Milner 编码的相似之处。部分证明正在 Coq 中进行形式化。

> **摘要翻译:** 本报告定义了 Levy 的按值推送 λ 演算 (CBPV) 在 Pi 演算中的编码，并证明我们的编码既可靠又完备。我们提供了可靠性、完备性以及所有必需引理的非正式（手动）证明。该编码专门针对内部 Pi 演算（pi-i-calculus），以规避在使用 De Bruijn 索引进行形式化时遇到的某些挑战，并且它还有助于双模拟，因为在这种设置下，早期、晚期和开放双模拟是重合的，此外双模拟是一种同余。此外，我们认为我们的编码也满足 Gorla 提出的良好编码的五项标准，并展示了 Milner 编码与我们编码之间的相似性。本文包括从 CBPV 到 pi-i-calculus、异步多重 Pi 演算和局部 Pi 演算的编码。我们开始在 Coq 中对 pi-i-calculus 中编码的可靠性和完备性证明进行形式化。并非所有在形式化中使用的引理本身都经过了形式化证明。然而，我们认为未证明的引理是合理的，因为它们是手动证明的，或者鉴于非正式论证，它们仅仅是 Coq 的形式化细节。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [542] [StepProof: Step-by-step verification of natural language mathematical proofs](https://arxiv.org/abs/2506.10558)
> *StepProof：自然语言数学证明的逐步验证*

*Xiaolin Hu, Qinghua Zhou, Bogdan Grechuk, Ivan Y. Tyukin* | **Main category: cs.LO**

**Keywords:** StepProof, 自动形式化, 自然语言证明, 逐步验证, 交互式定理证明器

**Comment:** 

> **TL;DR:** StepProof是一种新的自动形式化方法，通过将自然语言数学证明分解为可验证的子证明，实现了细粒度、逐句的验证，显著提高了证明成功率和效率。

**AI_Comments:** StepProof的创新之处在于其实现了自然语言数学证明的细粒度、逐句验证，这弥补了现有自动形式化方法只能验证完整证明的不足。通过将复杂证明分解为更小的可管理单元，它提高了验证的效率和成功率，为将自然语言与形式化证明系统结合迈出了重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 交互式定理证明器（ITPs）缺乏自然语言接口是一个重要限制。尽管大型语言模型（LLMs）增强了对自然语言输入的理解，但现有的自动形式化方法仅限于验证完整的证明，无法进行更细致的句子级别验证。

**Method:** 本文提出了StepProof，一种新颖的自动形式化方法，专为细粒度、逐步验证而设计。StepProof将完整的证明分解为多个可验证的子证明，从而实现了句子级别的验证。

**Result:** 实验结果表明，与传统方法相比，StepProof显著提高了证明成功率和效率。此外，对自然语言证明进行少量手动调整以适应步骤级验证，可以进一步提升StepProof在自动形式化方面的性能。

**Conclusion:** StepProof通过实现对自然语言数学证明的细粒度、逐步验证，有效解决了现有自动形式化方法在验证粒度上的局限性，并显著提升了验证性能。

> **ai_Abstract:** 本文提出了一种名为StepProof的新型自动形式化方法，旨在解决现有方法在自然语言数学证明验证中缺乏细粒度、句子级别验证的问题。StepProof通过将完整证明分解为多个可验证的子证明来实现逐句验证。实验结果表明，StepProof显著提高了证明的成功率和效率，并且通过少量手动调整可进一步提升性能。

> **摘要翻译:** 交互式定理证明器（ITPs）是强大的工具，可以将数学证明形式化验证到公理层面。然而，它们缺乏自然语言接口仍然是一个显著的限制。大型语言模型（LLMs）的最新进展增强了对自然语言输入的理解，为自动形式化铺平了道路——即将自然语言证明翻译成可以验证的形式化证明。尽管有这些进展，现有的自动形式化方法仅限于验证完整的证明，并且缺乏更细致的、句子级别的验证能力。为了解决这个空白，我们提出了StepProof，一种新颖的自动形式化方法，专为细粒度、逐步验证而设计。StepProof将完整的证明分解为多个可验证的子证明，从而实现了句子级别的验证。实验结果表明，与传统方法相比，StepProof显著提高了证明成功率和效率。此外，我们发现对自然语言证明进行少量手动调整，使其适应步骤级验证，进一步提升了StepProof在自动形式化方面的性能。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [527] [CARE: a Benchmark Suite for the Classification and Retrieval of Enzymes](https://arxiv.org/abs/2406.15669)
> *CARE：一个酶分类与检索的基准测试套件*

*Jason Yang, Ariane Mora, Shengchao Liu, Bruce J. Wittmann, Anima Anandkumar, Frances H. Arnold, Yisong Yue* | **Main category: q-bio.BM**

**Keywords:** 酶, 分类, 检索, 基准测试, 机器学习

**Comment:** 

> **TL;DR:** CARE是一个新的基准测试套件和数据集，用于评估酶的分类和检索方法，旨在解决现有方法缺乏标准化基准的问题。

**AI_Comments:** 该论文的创新之处在于首次提出了一个标准化基准CARE，解决了酶功能预测领域缺乏统一评估标准的问题。它不仅涵盖了传统的酶分类任务，还首次形式化并提出了酶检索任务，并提供了相应的基线方法，对推动该领域的机器学习研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前预测酶功能的机器学习方法缺乏标准化的评估基准。

**Method:** 引入了CARE，一个包含分类和检索两种任务的基准测试套件和数据集。分类任务是根据EC号对蛋白质序列进行分类；检索任务是给定化学反应检索EC号。设计了训练-测试划分以评估不同类型的分布外泛化能力。为分类任务提供了最先进方法的基线，并针对首次形式化的检索任务提出了Contrastive Reaction-EnzymE Pretraining (CREEP) 方法作为基线，并与CLIPZyme进行了比较。

**Result:** 为分类任务提供了最先进方法的基线。针对检索任务，提出了CREEP作为首批基线之一，并将其与CLIPZyme进行了比较。

**Conclusion:** CARE为酶的分类和检索提供了标准化的基准和数据集，有助于评估和推进相关机器学习方法的发展。

> **ai_Abstract:** 本论文介绍了CARE，一个用于酶分类和检索的标准化基准测试套件和数据集。它包含两个核心任务：基于EC号的蛋白质序列分类和给定化学反应的EC号检索。CARE设计了特殊的训练-测试划分以评估模型的分布外泛化能力。论文为分类任务提供了现有方法的基线，并针对首次形式化的检索任务提出了新的基线方法CREEP，并与CLIPZyme进行了比较，旨在弥补当前机器学习方法缺乏统一评估标准的不足。

> **摘要翻译:** 酶是催化化学反应的重要蛋白质。近年来，机器学习方法已兴起，用于从序列预测酶功能；然而，目前还没有标准化基准来评估这些方法。我们引入了CARE，一个用于酶分类和检索（Classification And Retrieval of Enzymes, CARE）的基准测试套件和数据集。CARE围绕两项任务展开：（1）通过酶学委员会（EC）编号对蛋白质序列进行分类，以及（2）给定化学反应检索EC编号。对于每项任务，我们设计了训练-测试划分，以评估与实际用例相关的不同类型的分布外泛化能力。对于分类任务，我们提供了最先进方法的基线。由于检索任务以前没有被形式化，我们提出了一种名为对比反应-酶预训练（Contrastive Reaction-EnzymE Pretraining, CREEP）的方法，作为该任务的首批基线之一，并将其与最近的方法CLIPZyme进行了比较。CARE可在https://github.com/jsunn-y/CARE/获取。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [532] [Identifying critical residues of a protein using meaningfully-thresholded Random Geometric Graphs](https://arxiv.org/abs/2506.10015)
> *使用有意义阈值随机几何图识别蛋白质关键残基*

*Chuqiao Zhang, Sarath Chandra Dantu, Debarghya Mitra, Dalia Chakrabarty* | **Main category: q-bio.BM**

**Keywords:** 蛋白质关键残基, 随机几何图, Cramer's V, 有机阈值, 分子动力学模拟

**Comment:** submitted to Journal of Computational and Graphical Statistics

> **TL;DR:** 本文提出三种基于随机几何图的方法来识别蛋白质的关键残基，并通过与实验数据对比验证了其有效性。

**AI_Comments:** 本文创新性地将随机几何图应用于蛋白质关键残基的识别，并提出了多种新颖的关键性参数化方法，包括“有机阈值”和基于后验概率差异的度量。通过与实验数据进行对比验证，增加了研究的可靠性。该方法为蛋白质功能研究提供了新的计算工具。

<details>
  <summary>Details</summary>

**Motivation:** 蛋白质关键残基的识别是当前研究热点，因为这些残基对蛋白质功能至关重要。

**Method:** 本文提出三种识别蛋白质关键残基的方法。首先，通过学习随机几何图（RGG）来识别，其中每个残基的状态变量作为图的节点，RGG通过残基对状态变量的相关矩阵（使用Cramer's V计算）学习得到。引入了一种“有机阈值”方法来学习RGG，并将关键性参数化为节点度，与其他现有阈值技术进行比较。其次，通过计算包含所有残基的完整图的后验概率与移除一个残基后的图的后验概率之间的差异来衡量关键性。第三种方法通过模拟过程中蛋白质演化时节点度的动态变化来表征关键性。

**Result:** 本文将通过上述三种不同关键性参数获得的结果与实验确定的关键残基进行了比较。

**Conclusion:** 本文提出了多种基于随机几何图的方法来识别蛋白质关键残基，并通过与实验数据的比较验证了这些方法的有效性。

> **ai_Abstract:** 本文旨在识别蛋白质的关键残基，这些残基对蛋白质功能至关重要。研究人员提出并比较了三种基于随机几何图（RGG）的方法。这些方法利用残基状态变量之间的相关性（通过Cramer's V计算）来构建RGG。第一种方法通过“有机阈值”学习RGG，并将节点度作为关键性参数。第二种方法通过比较完整图与移除单一残基图的后验概率差异来评估关键性。第三种方法关注蛋白质演化过程中节点度的动态变化。所有方法的结果都与实验确定的关键残基进行了比较。

> **摘要翻译:** 蛋白质关键残基的识别是当前积极追求的目标，因为这些残基对蛋白质功能至关重要。我们提出了三种识别示例蛋白质关键残基的方法，该蛋白质的演化通过分子动力学模拟进行追踪。我们的方法基于学习一个随机几何图（RGG）变量，其中156个残基中每个残基的状态变量都附着到该图的一个节点上，RGG是利用每个残基对状态变量之间的相关矩阵学习得到的。鉴于状态变量的分类性质，残基对之间的相关性使用Cramer's V计算。我们提出了一种有机阈值方法来学习RGG，并将其结果与现有阈值技术进行比较，其中关键性被参数化为学习到的RGG中的节点度。其次，我们通过计算定义在所有156个残基上的完整图变量的后验概率与除一个残基外所有残基都省略的图的后验概率之间的计算差异进行排序，从而开发了一种关键性度量。第三种关键性参数化方法说明了蛋白质在模拟过程中演化时节点度的动态变化。最后，我们将通过三种不同关键性参数获得的结果与实验确定的关键残基进行了比较。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [536] [scSSL-Bench: Benchmarking Self-Supervised Learning for Single-Cell Data](https://arxiv.org/abs/2506.10031)
> *scSSL-Bench：单细胞数据自监督学习基准测试*

*Olga Ovcharenko, Florian Barkmann, Philip Toma, Imant Daunhawer, Julia Vogt, Sebastian Schelter, Valentina Boeva* | **Main category: q-bio.QM**

**Keywords:** 自监督学习, 单细胞数据, 基准测试, 数据增强, 批次校正

**Comment:** Accepted at ICML 2025 (Spotlight)

> **TL;DR:** scSSL-Bench是一个综合性的基准测试平台，评估了19种自监督学习（SSL）方法在9个单细胞数据集上的表现，涵盖了批次校正、细胞类型注释和缺失模态预测等任务，并提供了具体的推荐。

**AI_Comments:** 该论文通过提供一个全面的基准测试平台scSSL-Bench，对单细胞数据领域的自监督学习方法进行了系统性评估，具有重要的创新性。它不仅评估了多种现有方法，还深入分析了数据增强策略的效果，并揭示了不同方法在特定任务上的优势和劣势。其提供的具体建议和指出的未来研究方向（如专门的多模态整合框架）对于推动深度学习与单细胞基因组学的融合具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了加深对应用于单细胞数据的自监督学习（SSL）方法的理解，本文提出了scSSL-Bench。

**Method:** scSSL-Bench是一个综合性的基准测试平台，评估了19种自监督学习方法。评估范围涵盖了9个数据集，并专注于三个常见的下游任务：批次校正、细胞类型注释和缺失模态预测。此外，还系统地评估了各种数据增强策略。

**Result:** 分析揭示了任务特定的权衡：专门的单细胞框架（scVI、CLAIRE和微调后的scGPT）在单模态批次校正方面表现出色，而通用SSL方法（如VICReg和SimCLR）在细胞分型和多模态数据整合方面表现更优。随机掩蔽是所有任务中最有效的数据增强技术，超越了领域特定的增强方法。值得注意的是，结果表明需要一个专门的单细胞多模态数据整合框架。

**Conclusion:** scSSL-Bench提供了一个标准化的评估平台和将SSL应用于单细胞分析的具体建议，推动了深度学习和单细胞基因组学的融合。

> **ai_Abstract:** scSSL-Bench是一个综合性基准测试平台，旨在评估自监督学习（SSL）方法在单细胞数据上的性能。它分析了19种SSL方法在9个数据集上的表现，并聚焦于批次校正、细胞类型注释和缺失模态预测等下游任务。研究发现，专业单细胞框架在单模态批次校正上表现优异，而通用SSL方法在细胞分型和多模态整合上更出色。随机掩蔽被认为是最佳的数据增强技术。该研究强调了对专门单细胞多模态数据整合框架的需求，并为SSL在单细胞分析中的应用提供了标准化评估和具体建议。

> **摘要翻译:** 自监督学习（SSL）已被证明是一种从单细胞数据中提取具有生物学意义的表示的强大方法。为了增进我们对应用于单细胞数据的SSL方法的理解，我们提出了scSSL-Bench，这是一个评估19种SSL方法的综合基准测试平台。我们的评估涵盖了9个数据集，并专注于三个常见的下游任务：批次校正、细胞类型注释和缺失模态预测。此外，我们系统地评估了各种数据增强策略。我们的分析揭示了任务特定的权衡：专门的单细胞框架，如scVI、CLAIRE和经过微调的scGPT，在单模态批次校正方面表现出色，而通用SSL方法，如VICReg和SimCLR，在细胞分型和多模态数据整合方面表现更优。随机掩蔽成为所有任务中最有效的数据增强技术，超越了领域特定的增强方法。值得注意的是，我们的结果表明需要一个专门的单细胞多模态数据整合框架。scSSL-Bench提供了一个标准化的评估平台和将SSL应用于单细胞分析的具体建议，推动了深度学习和单细胞基因组学的融合。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [545] [Predicting function of evolutionarily implausible DNA sequences](https://arxiv.org/abs/2506.10271)
> *预测进化上不合理的DNA序列的功能*

*Shiyu Jiang, Xuyin Liu, Zitong Jerry Wang* | **Main category: q-bio.QM**

**Keywords:** 基因组语言模型, DNA序列, 功能预测, 突变效应, 序列似然度, 序列长度

**Comment:** 13 pages, 6 figures, accepted to ICML 2025 Generative AI and Biology
  Workshop

> **TL;DR:** 本文引入了Nullsettes任务来评估基因组语言模型(gLMs)预测DNA序列功能丧失突变的能力，发现突变效应预测性能与非突变序列的预测似然度强相关，且受序列长度影响，强调了在使用gLMs进行突变效应预测时考虑序列似然度和序列长度的重要性。

**AI_Comments:** 这项研究通过引入Nullsettes任务，为评估基因组语言模型在预测非进化合理序列功能方面的能力提供了一个新颖且重要的基准。它揭示了gLMs在处理合成生物学中关键挑战时的局限性和关键影响因素，特别是强调了序列似然度和长度对模型性能的影响，这对于未来gLMs的设计和应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 基因组语言模型(gLMs)在合成生物学中生成新颖、功能性DNA序列方面显示出潜力，但要实现这一目标，它们不仅需要学习进化上的合理性，还需要学习序列到功能的关系。

**Method:** 研究引入了一系列名为Nullsettes的预测任务，通过评估模型预测由合成表达盒中关键控制元件易位引起的失功能突变的能力来进行评估。研究在12个最先进的模型上进行了测试。

**Result:** 研究发现，突变效应预测性能与非突变序列的预测似然度强烈相关。此外，预测模型良好性能的似然度值范围高度依赖于序列长度。

**Conclusion:** 研究强调了在使用基因组语言模型(gLMs)进行突变效应预测时，考虑序列似然度和序列长度的重要性。

> **ai_Abstract:** 本文引入了Nullsettes预测任务来评估基因组语言模型(gLMs)预测DNA序列失功能突变的能力。研究发现，在12个主流gLMs中，突变效应预测性能与非突变序列的预测似然度呈强相关性，并且这种相关性受序列长度显著影响。这项工作强调了在使用gLMs进行突变效应预测时，必须同时考虑序列似然度和序列长度。

> **摘要翻译:** 基因组语言模型（gLMs）在为合成生物学生成新颖、功能性DNA序列方面显示出潜力，但要实现这一目标，它们不仅需要学习进化上的合理性，还需要学习序列到功能的关系。我们引入了一组名为Nullsettes的预测任务，用于评估模型预测通过易位合成表达盒中关键控制元件产生的失功能突变的能力。在12个最先进的模型中，我们发现突变效应预测性能与非突变体的预测似然度密切相关。此外，预测模型强大性能的似然度值范围高度依赖于序列长度。我们的工作强调了在使用gLMs进行突变效应预测时，考虑序列似然度和序列长度的重要性。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [560] [A Goemans-Williamson type algorithm for identifying subcohorts in clinical trials](https://arxiv.org/abs/2506.10879)
> *临床试验中识别亚群的Goemans-Williamson型算法*

*Pratik Worah* | **Main category: q-bio.QM**

**Keywords:** 亚群识别, 线性分类器, Goemans-Williamson, 临床试验, 乳腺癌

**Comment:** 

> **TL;DR:** 开发了一种基于Goemans-Williamson型算法的线性分类器，用于从异质数据集中识别同质亚群，并应用于乳腺癌数据以发现疾病相关亚群。

**AI_Comments:** 该论文的创新点在于引入了Goemans-Williamson类型的舍入技术来解决亚群识别问题，并提供了理论近似保证。其重要性在于提供了一种有效工具来处理临床试验中的异质性数据，有助于发现疾病的生物标志物和潜在治疗靶点。

<details>
  <summary>Details</summary>

**Motivation:** 从大型异质数据集中识别同质子群（亚群），这对于发现疾病通路和特定治疗方法非常有用。

**Method:** 设计了一种高效的算法，该算法输出一个线性分类器。其理论贡献是一种类似于Goemans和Williamson (1994) 的舍入技术，能将底层优化问题的最优解近似到0.82的因子。

**Result:** 该算法成功应用于乳腺癌RNA微阵列数据集，识别出主要由转移性病例组成的同质患者亚群。此外，还系统地识别出肿瘤抑制基因甲基化水平和核受体表达同时发生显著变化的患者亚群。

**Conclusion:** 识别同质患者亚群对于发现疾病通路和特定于亚群的治疗方法具有潜在的帮助。

> **ai_Abstract:** 本文提出了一种基于Goemans-Williamson型舍入技术的高效线性分类算法，用于从大型异质数据集中识别同质亚群。该算法能将优化问题近似到0.82的因子。作为应用，该算法被用于乳腺癌RNA微阵列数据集，成功识别出转移性病例亚群以及肿瘤抑制基因甲基化和核受体表达同时变化的患者亚群，这对于疾病通路和特定治疗的发现具有重要意义。

> **摘要翻译:** 我们设计了一种高效的算法，该算法输出一个线性分类器，用于从大型异质数据集中识别同质子集（等同于亚群）。我们的理论贡献是一种类似于Goemans和Williamson (1994) 的舍入技术，它能将底层优化问题的最优解近似到0.82的因子。作为一项应用，我们使用我们的算法设计了一个简单的测试，可以从Curtis等人(2012)的乳腺癌RNA微阵列数据集中识别出主要由转移性病例组成的同质患者亚群。此外，我们还使用该算法输出的测试系统地识别出肿瘤抑制基因甲基化水平发生统计学显著变化与核受体表达发生统计学显著变化同时出现的患者亚群。识别此类同质患者亚群对于发现疾病通路和特定于该亚群的治疗方法可能有用。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [537] [Patient-Specific Deep Reinforcement Learning for Automatic Replanning in Head-and-Neck Cancer Proton Therapy](https://arxiv.org/abs/2506.10073)
> *头颈部癌症质子治疗中患者特异性深度强化学习用于自动再计划*

*Malvern Madondo, Yuan Shao, Yingzi Liu, Jun Zhou, Xiaofeng Yang, Zhen Tian* | **Main category: physics.med-ph**

**Keywords:** 深度强化学习, 质子治疗, 自动再计划, 头颈部癌症, 患者特异性

**Comment:** 

> **TL;DR:** 该研究提出了一种患者特异性的深度强化学习框架，用于头颈部癌症质子治疗中的自动再计划，通过学习调整优化优先级来提高计划质量，并显示出优于手动再计划的性能。

**AI_Comments:** 这项研究的创新之处在于提出了一个患者特异性的深度强化学习框架来自动化质子治疗的再计划过程，这在很大程度上解决了当前手动再计划耗时且效率低下的问题。其独特之处在于为每位患者训练个性化智能体，利用患者自身的解剖数据进行学习，这比传统的基于人群的方法更具适应性。研究结果表明，该方法不仅提高了计划质量，甚至超越了人类规划师的水平，这对于临床实践具有重要意义，预示着未来自适应质子治疗的效率和精准度将得到显著提升。同时，它也为在线自适应质子治疗的发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 头颈部癌症的调强质子治疗过程中，解剖结构变化可能导致布拉格峰位移，增加肿瘤欠剂量和危及器官过剂量的风险，因此需要再计划。然而，目前的手动再计划过程资源密集且耗时。

**Method:** 本研究提出了一个患者特异性的深度强化学习(DRL)框架，用于自动化调强质子治疗再计划。该框架采用基于150点计划质量评分的奖励塑形机制，将计划过程表述为RL问题，智能体学习调整优化优先级。与基于人群的方法不同，该框架为每位患者训练个性化智能体，利用其计划CT和模拟解剖变化的增强解剖结构。研究实现了两种DRL算法：深度Q网络(DQN)和近端策略优化(PPO)，使用剂量体积直方图(DVH)作为状态表示，并采用22维的优先级调整动作空间。

**Result:** 在五名头颈部癌症患者的实际再计划CT数据上进行评估，结果显示两种DRL智能体均将初始计划分数从120.63 ± 21.40提高到139.78 ± 6.84 (DQN) 和 142.74 ± 5.16 (PPO)，超过了人类规划师生成的手动再计划分数 (137.20 ± 5.58)。临床验证证实，这些改进转化为更好的肿瘤覆盖和危及器官保护，适用于各种解剖结构变化。

**Conclusion:** 这项工作展示了深度强化学习在解决自适应质子治疗的几何和剂量学复杂性方面的潜力，提供了高效的离线适应解决方案，并推动了在线自适应质子治疗的发展。

> **ai_Abstract:** 本研究提出了一种创新的患者特异性深度强化学习(DRL)框架，旨在自动化头颈部癌症质子治疗中的再计划过程。鉴于解剖结构变化导致的手动再计划耗时且资源密集，该框架将治疗计划制定为强化学习问题，智能体学习调整优化优先级以最大化基于150点评分的计划质量。与传统方法不同，该模型为每位患者训练个性化智能体，利用其CT影像和模拟解剖变化的增强数据。实验结果表明，该DRL方法（DQN和PPO）在五名患者中显著提高了计划质量分数，且优于人类规划师的手动再计划。临床验证进一步证实了其在肿瘤覆盖和危及器官保护方面的有效性，展示了DRL在自适应质子治疗中的巨大潜力。

> **摘要翻译:** 在头颈部癌症(HNC)的调强质子治疗(IMPT)期间，解剖结构变化可能导致布拉格峰位移，从而有肿瘤欠剂量和危及器官过剂量的风险。因此，通常需要治疗再计划以保持临床可接受的治疗质量。然而，目前的手动再计划过程资源密集且耗时。我们提出了一种患者特异性的深度强化学习(DRL)框架，用于自动化IMPT再计划，该框架具有基于150点计划质量评分的奖励塑形机制，以解决相互竞争的临床目标。我们将计划过程表述为一个RL问题，其中智能体学习控制策略以调整优化优先级，从而最大化计划质量。与基于人群的方法不同，我们的框架使用每位患者的计划CT(计算机断层扫描)和模拟解剖变化的增强解剖结构(肿瘤进展和退化)来训练个性化智能体。这种患者特异性的方法利用了整个治疗过程中的解剖相似性，从而实现了有效的计划适应。我们使用剂量体积直方图(DVHs)作为状态表示和22维的优先级调整动作空间，实现了两种DRL算法：深度Q网络和近端策略优化。对五名HNC患者使用实际再计划CT数据进行的评估显示，两种DRL智能体都将初始计划分数从120.63 ± 21.40提高到139.78 ± 6.84 (DQN) 和 142.74 ± 5.16 (PPO)，超过了人类规划师生成的手动再计划分数(137.20 ± 5.58)。临床验证证实，这些改进转化为更好的肿瘤覆盖和危及器官保护，适用于各种解剖结构变化。这项工作展示了DRL在解决自适应质子治疗的几何和剂量学复杂性方面的潜力，提供了高效的离线适应解决方案，并推动了在线自适应质子治疗的发展。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

### [549] [Modality-AGnostic Image Cascade (MAGIC) for Multi-Modality Cardiac Substructure Segmentation](https://arxiv.org/abs/2506.10797)
> *模态无关图像级联（MAGIC）用于多模态心脏亚结构分割*

*Nicholas Summerfield, Qisheng He, Alex Kuo, Ahmed I. Ghanem, Simeng Zhu, Chase Ruff, Joshua Pan, Anudeep Kumar, Prashant Nagpal, Jiwei Zhao, Ming Dong, Carri K. Glide-Hurst* | **Main category: physics.med-ph**

**Keywords:** 心脏亚结构分割, 多模态, 深度学习, MAGIC, nnU-Net, 胸部放射治疗

**Comment:** 

> **TL;DR:** 本文提出并验证了模态无关图像级联（MAGIC），一个轻量级、单模型的深度学习解决方案，用于准确的多模态心脏亚结构分割，其性能优于现有方法，并简化了临床实施。

**AI_Comments:** 本文引入的“模态无关图像级联（MAGIC）”架构是一项创新，它通过在单一nnU-Net骨干网中集成复制的编码/解码分支，有效解决了当前深度学习分割模型在不同成像模态之间泛化能力不足的关键限制。这种方法避免了为每种模态训练单独模型的需求，显著提升了临床工作流程的效率和便利性。该模型“轻量化”和“简化计算要求”的特性对于实际的临床部署至关重要。尽管MAGIC在超过一半的案例中表现优于比较模型，但“有限的统计差异”表明在某些特定情况下仍有进一步改进或更深入分析的空间。总体而言，该研究为开发更通用、更适合临床应用的心脏分割工具迈出了有希望的一步。

<details>
  <summary>Details</summary>

**Motivation:** 心脏亚结构在胸部放射治疗计划中至关重要，但现有深度学习方法在不同模态和重叠结构上的泛化能力不足，增加了勾画负担。

**Method:** 本文引入了模态无关图像级联（MAGIC），该方法通过nnU-Net基础的U形骨干网的复制编码和解码分支实现。研究使用来自模拟CT（Sim-CT）、低场MR-Linac和心脏CT血管造影（CCTA）三种模态的二十个心脏亚结构进行训练（n=76）、验证（n=15）和测试（n=30）。通过Dice相似系数（DSC）和Wilcoxon符号秩检验，将MAGIC与十二个比较模型在训练效率和分割精度上进行比较。

**Result:** MAGIC在Sim-CT上的平均DSC得分为0.75(0.16)，MR-Linac为0.68(0.21)，CCTA为0.80(0.16)。MAGIC在57%的情况下优于比较模型，统计差异有限。

**Conclusion:** MAGIC提供了一种有效、准确、轻量化且灵活的分割解决方案，能够在单个模型中处理多种模态和重叠的心脏结构。它通过简化计算要求和提供灵活性，进一步推动了临床应用。

> **ai_Abstract:** 本文提出了一种名为模态无关图像级联（MAGIC）的新型深度学习框架，旨在解决现有深度学习模型在多模态心脏亚结构分割中泛化能力不足的问题。MAGIC基于nnU-Net架构，通过复制编码和解码分支实现，使其能够在一个单一模型中处理来自Sim-CT、MR-Linac和CCTA等多种模态的图像。研究在20个心脏亚结构上对MAGIC进行了训练、验证和测试，并与12个比较模型进行了评估。结果显示，MAGIC在不同模态上均取得了良好的分割精度（Sim-CT平均DSC为0.75，MR-Linac为0.68，CCTA为0.80），并在57%的情况下优于比较模型。该研究认为MAGIC提供了一个有效、准确、轻量且灵活的单模型解决方案，有望通过简化计算需求和增加临床适用性来促进其在临床中的应用。

> **摘要翻译:** 心脏亚结构在胸部放射治疗计划中至关重要，旨在最大限度地降低放射性心脏病风险。深度学习（DL）提供了有效的减少勾画负担的方法，但其在不同模态和重叠结构上的泛化能力不足。本工作介绍并验证了一种模态无关图像级联（MAGIC），用于全面、多模态的心脏亚结构分割。MAGIC通过nnU-Net基础的U形骨干网的复制编码和解码分支实现，保持了单个模型的功能。来自模拟CT（Sim-CT）、低场MR-Linac和心脏CT血管造影（CCTA）模态的二十个心脏亚结构（心脏、心腔、大血管（GVs）、瓣膜、冠状动脉（CAs）和传导结）被手动勾画，并用于训练（n=76）、验证（n=15）和测试（n=30）MAGIC。十二个比较模型（三个模态下的四个分割子组）进行了等效训练。所有方法都通过Dice相似系数（DSC）和双尾Wilcoxon符号秩检验（阈值，p<0.05）进行训练效率和与参考轮廓的比较。Sim-CT的平均DSC评分为0.75(0.16)，MR-Linac为0.68(0.21)，CCTA为0.80(0.16)。MAGIC在57%的情况下优于比较模型，统计差异有限。MAGIC提供了一种有效且准确的分割解决方案，该方案轻量化，并能够在单个模型中分割多种模态和重叠结构。MAGIC通过简化计算要求并为临床环境提供无与伦比的灵活性，进一步实现了临床实施。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [538] [Equitable Mechanism Design for Facility Location](https://arxiv.org/abs/2506.10460)
> *设施选址的公平机制设计*

*Toby Walsh* | **Main category: cs.GT**

**Keywords:** 策略证明机制, 设施选址, 基尼指数, 公平性, 纳什福利

**Comment:** To appear in Proceedings of IJCAI 2025

> **TL;DR:** 本文研究了设施选址中最大化代理人之间公平性的策略证明机制，证明了在传统基尼指数下无法界定最优近似比的不可能性结果，并提出使用补足基尼指数和纳什福利作为新的衡量标准。

**AI_Comments:** 本文的创新之处在于揭示了在设施选址的策略证明机制中，以基尼指数衡量公平性时存在一个重要的不可能性结果，这挑战了现有的一些假设。同时，提出使用补足基尼指数和纳什福利作为替代衡量标准，为解决公平性问题提供了新的视角和研究方向，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 在设施选址问题中，研究者旨在设计策略证明机制，以最大化代理人之间的公平性。传统上以基尼指数衡量公平性，但存在无法界定近似比的问题，因此需要探索新的衡量方法和机制设计。

**Method:** 本文首先证明了一个不可能性结果，即没有策略证明机制可以界定一个或多个设施效用最优基尼指数的近似比。作为替代，提出计算效用补足基尼指数的近似比，并考虑确定性和随机机制如何近似它。此外，还考虑了机制如何近似纳什福利。

**Result:** 证明了一个简单但根本性的不可能性结果：对于一个或多个设施的效用最优基尼指数，没有策略证明机制能够界定其近似比。提出了使用效用补足基尼指数的近似比进行计算，并探讨了确定性和随机机制对其的近似效果。同时，也考虑了机制对纳什福利的近似效果。

**Conclusion:** 在设施选址的策略证明机制中，直接优化基尼指数存在根本性的近似比界定不可能性。因此，提出并探索了补足基尼指数和纳什福利作为衡量公平性的替代方法，为未来公平机制设计提供了新的方向。

> **ai_Abstract:** 本研究探讨了设施选址中的策略证明机制，旨在最大化代理人间的公平性。论文指出，使用传统基尼指数衡量公平性时存在一个根本性的不可能性结果，即无法界定最优近似比。为克服此限制，作者提出转而计算效用补足基尼指数的近似比，并分析了确定性和随机机制在此方面的表现。此外，研究还评估了机制对纳什福利的近似效果，将其作为一种公平折衷的衡量标准。

> **摘要翻译:** 我们考虑了设施选址的策略证明机制，旨在最大化代理人之间的公平性。正如文献中常见的，我们使用基尼指数来衡量公平性。我们首先证明了一个简单但根本性的不可能性结果，即没有策略证明机制能够界定一个或多个设施效用最优基尼指数的近似比。我们转而建议计算效用补足基尼指数的近似比，并考虑确定性和随机机制如何很好地近似它。此外，由于纳什福利常被认为是平均主义和功利主义结果之间的一种公平折衷，我们还考虑了机制如何很好地近似纳什福利。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [539] [Fundamental Limits of Learning High-dimensional Simplices in Noisy Regimes](https://arxiv.org/abs/2506.10101)
> *噪声环境下高维单纯形学习的根本限制*

*Seyed Amir Hossein Saberi, Amir Najafi, Abolfazl Motahari, Babak H. khalaj* | **Main category: stat.ML**

**Keywords:** 高维单纯形, 样本复杂度, 噪声学习, 信息论下界, 傅里叶方法

**Comment:** Extension of our ICML 2023 paper, 44 pages

> **TL;DR:** 本文研究了在噪声数据下学习高维单纯形的样本复杂度，推导了上下界，并证明在特定信噪比下，噪声情况下的复杂度与无噪声情况一致，同时引入了一种新的傅里叶方法。

**AI_Comments:** 这篇论文通过推导严格的样本复杂度界限，对噪声环境下高维单纯形学习的理论基础做出了重要贡献。特别是，它解决了噪声与无噪声复杂度对齐的开放问题，并引入了一种新颖的傅里叶方法，该方法可能在其他数据恢复任务中找到应用，显示出其创新性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在建立从噪声数据中学习高维单纯形的样本复杂度界限，以理解在高维和噪声环境下学习的根本限制。

**Method:** 研究人员证明了一个算法的存在性，该算法能够以高概率从噪声数据中恢复出与真实单纯形距离在$\ell_2$或全变差（TV）距离内误差不超过$\varepsilon$的单纯形。他们还推导了新的信息论下界，并利用样本压缩技术和一种新颖的基于傅里叶的方法来从噪声观测中恢复分布。

**Result:** 结果表明，存在一个算法，在样本量$n \ge (K^2/\varepsilon^2) e^{\mathcal{O}(K/\mathrm{SNR}^2)}$时，能以高概率输出一个与真实单纯形距离在$\varepsilon$内的单纯形。信息论下界显示，在TV距离$\varepsilon$内估计单纯形至少需要$n \ge \Omega(K^3 \sigma^2/\varepsilon^2 + K/\varepsilon)$个样本。在无噪声情况下，下界$n \ge \Omega(K/\varepsilon)$与已知上界匹配。研究还发现，当$\mathrm{SNR} \ge \Omega(K^{1/2})$时，噪声情况下的复杂度与无噪声情况一致。

**Conclusion:** 本文解决了高维单纯形学习中的一个开放问题，证明了在足够高的信噪比下，噪声情况下的学习复杂度与无噪声情况相同。此外，引入的傅里叶方法具有超越单纯形学习的潜在应用。

> **ai_Abstract:** 本文研究了在加性高斯噪声下从高维单纯形中均匀抽取的独立同分布样本的学习问题。研究人员建立了学习高维单纯形的样本复杂度上界和信息论下界，并证明了在特定信噪比条件下，噪声情况下的复杂度与无噪声情况一致，从而解决了一个开放问题。此外，论文还引入了一种新颖的基于傅里叶的方法，用于从噪声观测中恢复分布，该方法具有广泛的应用潜力。

> **摘要翻译:** 在本文中，我们建立了从噪声数据中学习$\mathbb{R}^K$中高维单纯形的样本复杂度界限。具体来说，我们考虑了$n$个独立同分布的样本，这些样本均匀地从$\mathbb{R}^K$中一个未知单纯形中抽取，每个样本都受到未知方差的加性高斯噪声污染。我们证明存在一个算法，它能以高概率输出一个与真实单纯形在$\ell_2$或全变差（TV）距离上至多$\varepsilon$的单纯形，前提是$n \ge (K^2/\varepsilon^2) e^{\mathcal{O}(K/\mathrm{SNR}^2)}$，其中$\mathrm{SNR}$是信噪比。扩展我们之前的工作\citep{saberi2023sample}，我们推导了新的信息论下界，表明在TV距离$\varepsilon$内估计单纯形至少需要$n \ge \Omega(K^3 \sigma^2/\varepsilon^2 + K/\varepsilon)$个样本，其中$\sigma^2$表示噪声方差。在无噪声情况下，我们的下界$n \ge \Omega(K/\varepsilon)$与已知的上界在常数因子内匹配。我们通过证明当$\mathrm{SNR} \ge \Omega(K^{1/2})$时，噪声情况下的复杂度与无噪声情况一致，从而解决了一个开放问题。我们的分析利用了样本压缩技术（Ashtiani et al., 2018），并引入了一种新颖的基于傅里叶的方法，用于从噪声观测中恢复分布，这可能适用于单纯形学习之外的领域。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [543] [Momentum Multi-Marginal Schrödinger Bridge Matching](https://arxiv.org/abs/2506.10168)
> *动量多边际薛定谔桥匹配*

*Panagiotis Theodoropoulos, Augustinos D. Saravanos, Evangelos A. Theodorou, Guan-Horng Liu* | **Main category: stat.ML**

**Keywords:** 薛定谔桥, 多边际, 轨迹推断, 动量匹配, 随机系统

**Comment:** 

> **TL;DR:** 本文提出了一种名为3MSBM的新型匹配框架，通过将动力学提升到相空间并推广随机桥以适应多个条件点，解决了从稀疏快照推断轨迹时现有方法无法捕获长程时间依赖性的问题，并在实际应用中展示了卓越性能。

**AI_Comments:** 3MSBM的创新点在于将动力学提升到相空间并引入多边际条件，这使得模型能够捕获长程时间依赖性，解决了现有方法仅限于成对插值的问题。其作为匹配方法，在训练中保持中间边际的特性，对提高收敛性和可扩展性至关重要。这项工作对于单细胞生物学、气象学和经济学等需要从稀疏快照推断复杂轨迹的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从稀疏样本快照中推断复杂系统的轨迹是一个基本挑战。现有的桥和流匹配框架依赖于相邻快照之间的成对插值，这阻碍了它们捕获长程时间依赖性的能力，并可能影响推断轨迹的连贯性。

**Method:** 本文引入了动量多边际薛定谔桥匹配（3MSBM）框架。该方法通过将动力学提升到相空间，并将随机桥推广为以多个点为条件，从而形成一个多边际条件随机最优控制问题。通过最小化一个变分目标来学习底层动力学，同时固定由多边际条件桥引起的路径。作为一种匹配方法，3MSBM在训练过程中保留了中间边际，显著提高了收敛性和可扩展性。

**Result:** 在多项实际应用中进行的广泛实验验证了3MSBM在捕获具有时间依赖性的复杂动力学方面优于现有方法，表现出卓越的性能。

**Conclusion:** 3MSBM框架的提出为多边际设置中的匹配框架训练开辟了新途径，显著提高了从稀疏数据推断复杂系统轨迹的能力。

> **ai_Abstract:** 本文针对从稀疏数据推断复杂系统轨迹时现有方法无法有效捕获长程时间依赖性的问题，提出了一种名为“动量多边际薛定谔桥匹配（3MSBM）”的新型匹配框架。3MSBM通过将系统动力学提升到相空间，并推广随机桥以适应多个条件点，将其建模为一个多边际条件随机最优控制问题。该方法通过最小化变分目标学习动力学，并在训练中保持中间边际，从而显著提升了收敛性和可扩展性。实验证明，3MSBM在处理复杂时间依赖性动力学方面表现优异，为多边际匹配框架的研究开辟了新方向。

> **摘要翻译:** 通过从稀疏样本快照推断轨迹来理解复杂系统是广泛领域（例如单细胞生物学、气象学和经济学）中的一个基本挑战。尽管桥和流匹配框架取得了进展，但当前方法依赖于相邻快照之间的成对插值。这阻碍了它们捕获长程时间依赖性的能力，并可能影响推断轨迹的连贯性。为了解决这些问题，我们引入了动量多边际薛定谔桥匹配（3MSBM），这是一种新颖的匹配框架，用于学习满足多个位置约束的随机系统的平滑测度值样条。这是通过将动力学提升到相空间并将随机桥推广为以多个点为条件来实现的，从而形成一个多边际条件随机最优控制问题。然后通过最小化一个变分目标来学习底层动力学，同时固定由多边际条件桥引起的路径。作为一种匹配方法，3MSBM在整个训练过程中保留了中间边际，显著提高了收敛性和可扩展性。在系列实际应用中的广泛实验验证了3MSBM在捕获具有时间依赖性的复杂动力学方面优于现有方法，为多边际设置中的匹配框架训练开辟了新途径。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [547] [Distributionally-Constrained Adversaries in Online Learning](https://arxiv.org/abs/2506.10293)
> *在线学习中受分布约束的对抗者*

*Moïse Blanchard, Samory Kpotufe* | **Main category: stat.ML**

**Keywords:** 在线学习, 受分布约束的对抗者, 可学习性, 平滑分析, 遗憾

**Comment:** 

> **TL;DR:** 本文研究了在线学习中受分布约束的对抗者，刻画了可学习的分布类别，并表明对于自然函数类别，无需先验分布知识即可实现学习。

**AI_Comments:** 这篇论文引入了一个更通用的在线学习框架，统一了随机和对抗性设置，从而更深入地理解了在不同对抗性控制水平下的可学习性。在没有先验分布类别知识的情况下进行学习的能力是一个重要的实际优势。

<details>
  <summary>Details</summary>

**Motivation:** 理解在线学习中从对抗性到随机性设置的连续统一体，并弥合这一差距；现有的框架（如平滑设置）存在局限性。

**Method:** 提出并考虑了受分布约束的对抗者的更通用和灵活的框架，其中实例由对抗者在受约束的分布类别中选择的分布中抽取。他们刻画了针对盲目和自适应对抗者的可学习分布类别。

**Result:** 他们刻画了哪些分布类别在这种情况下是可学习的。他们的结果恢复并推广了已知平滑设置的可学习性。此外，他们表明对于包括线性分类器在内的几种自然函数类别，无需任何先验分布类别知识即可实现学习。

**Conclusion:** 本文深入探讨了函数类别与对抗者分布约束之间相互作用的类型，这些相互作用使得可学习性成为可能，表明即使对于特定函数类型，在没有先验分布类别知识的情况下也可以进行学习。

> **ai_Abstract:** 本文研究了在线学习中受分布约束的对抗者框架，旨在弥合完全随机和完全对抗性设置之间的差距。它刻画了针对盲目和自适应对抗者的可学习分布类别，从而深入了解了实现可学习性的条件。研究结果推广了现有的平滑设置，并表明对于某些函数类别，学习可以在不具备分布类别先验知识的情况下实现，从而允许学习者与任何受约束的对抗者竞争。

> **摘要翻译:** 最近人们对理解在线学习中从对抗性到随机性设置的连续统一体产生了浓厚兴趣，各种框架（包括平滑设置）被提出以弥合这一差距。我们考虑了受分布约束的对抗者的更通用和灵活的框架，其中实例由对抗者在某些受约束的分布类别 [RST11] 中选择的分布中抽取。与平滑分析相比，我们考虑了通用分布类别，这使得能够对完全随机和完全对抗性之间的学习设置进行细粒度理解，学习者可以在其中实现非平凡的遗憾。我们刻画了在这种情况下针对盲目和自适应对抗者的哪些分布类别是可学习的，从而深入了解了函数类别与对抗者分布约束之间相互作用的类型，这些相互作用使得可学习性成为可能。特别是，我们的结果恢复并推广了已知平滑设置的可学习性。此外，我们表明对于包括线性分类器在内的几种自然函数类别，无需任何先验分布类别知识即可实现学习——换句话说，学习者可以同时与可学习分布类别中的任何受约束对抗者竞争。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [550] [Measuring Semantic Information Production in Generative Diffusion Models](https://arxiv.org/abs/2506.10433)
> *测量生成扩散模型中的语义信息生成*

*Florian Handke, Félix Koulischer, Gabriel Raya, Luca Ambrogioni* | **Main category: stat.ML**

**Keywords:** 语义信息, 扩散模型, 信息论, 条件熵, CIFAR10

**Comment:** 4 pages, 3 figures, an appendix with derivations and implementation
  details, accepted at ICLR DeLTa 2025

> **TL;DR:** 本研究提出了一种通用的信息论方法来量化生成扩散模型中语义信息“决策”的时间点，并发现语义信息传递在扩散的中间阶段最高，且不同类别之间存在显著差异。

**AI_Comments:** 这项研究的创新之处在于提出了一个通用的信息论框架来量化扩散模型中的语义信息生成过程，这有助于更深入地理解这些模型的工作机制。通过将信息论与扩散模型相结合，为分析生成过程中的“决策”点提供了新的视角。研究结果对理解扩散模型的内部动态和潜在优化方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成扩散模型中图像的语义和结构特征在逆向扩散过程中不同时间出现，这种现象与磁体和其他材料中的物理相变有关。本研究旨在引入一种通用的信息论方法来测量这些类别语义“决策”在生成过程中何时做出。

**Method:** 本研究采用一种在线最优贝叶斯分类器公式来估计给定噪声状态下类别标签的条件熵。然后，利用条件熵的时间导数来确定噪声状态与类别标签之间信息传递最高的时段。该方法在一维高斯混合模型和在CIFAR10数据集上训练的DDPM模型上进行了验证。

**Result:** 研究发现，语义信息传递在扩散的中间阶段最高，而在最后阶段消失，这与预期相符。然而，不同类别的熵率分布存在显著差异，表明不同的“语义决策”发生在不同的中间时间。

**Conclusion:** 本研究的结论是，在生成扩散模型中，语义信息传递主要发生在扩散的中间阶段，并且不同类别的语义信息生成时间点存在差异。

> **ai_Abstract:** 本论文提出了一种新的信息论方法，用于量化生成扩散模型中类别语义信息形成的精确时间点。通过计算条件熵及其时间导数，该方法能够识别噪声状态与类别标签之间信息传递最活跃的阶段。研究结果表明，语义信息在扩散过程的中间阶段达到峰值，并在最终阶段消失。此外，不同类别的语义信息生成时间存在显著差异，揭示了扩散过程中类别特有的信息编码模式。

> **摘要翻译:** 众所周知，生成图像的语义和结构特征在扩散的逆向动态过程中在不同时间出现，这种现象已与磁体和其他材料中的物理相变联系起来。在本文中，我们引入了一种通用的信息论方法来测量这些类别语义“决策”在生成过程中何时做出。通过使用最优贝叶斯分类器的在线公式，我们估计了给定噪声状态下类别标签的条件熵。然后，我们利用条件熵的时间导数来确定噪声状态与类别标签之间信息传递最高的时段。我们在​​一维高斯混合模型和在CIFAR10数据集上训练的DDPM模型上验证了我们的方法。正如预期的那样，我们发现语义信息传递在扩散的中间阶段最高，而在最后阶段消失。然而，我们发现不同类别的熵率分布存在显著差异，这表明不同的“语义决策”位于不同的中间时间。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [553] [Box-Constrained Softmax Function and Its Application for Post-Hoc Calibration](https://arxiv.org/abs/2506.10572)
> *盒约束Softmax函数及其在事后校准中的应用*

*Kyohei Atarashi, Satoshi Oyama, Hiromi Arai, Hisashi Kashima* | **Main category: stat.ML**

**Keywords:** 盒约束Softmax, 事后校准, 概率校准, 模型可靠性, 硬约束

**Comment:** 

> **TL;DR:** 本文提出了一种新的盒约束Softmax函数（BCSoftmax），它能对输出概率施加硬性上下限约束。我们还开发了一种高效的计算算法，并将其应用于事后校准，通过学习输出概率的边界来缓解模型的欠置信和过置信问题，从而提高了可靠性。

**AI_Comments:** 该论文的创新点在于提出了BCSoftmax，解决了传统Softmax无法施加硬性输出概率约束的问题，这对于需要高可靠性和可信度的应用场景具有重要意义。所提出的高效计算算法和在事后校准中的应用，为提升模型置信度校准提供了一种新颖且实用的方法。这对于模型部署和风险敏感型应用具有潜在的积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 现代机器学习中，控制基于Softmax模型的输出概率是一个常见问题。尽管Softmax函数可以通过温度参数提供软控制，但它缺乏对输出概率施加硬性约束（如盒约束）的能力，这对于需要可靠和可信模型的特定应用至关重要。

**Method:** 本文提出了盒约束Softmax（BCSoftmax）函数，它是Softmax函数的一种新颖泛化，明确地对输出概率施加了下限和上限。BCSoftmax被表述为盒约束优化问题的解，并开发了一种精确高效的计算算法。作为关键应用，引入了两种基于BCSoftmax的事后校准方法，通过在模型训练后学习输出概率或logits的下限和上限来缓解预测模型中的欠置信和过置信。

**Result:** 在TinyImageNet、CIFAR-100和20NewsGroups数据集上进行了实验，证明了所提方法的有效性，并在校准指标方面取得了改进。

**Conclusion:** BCSoftmax函数能够对输出概率施加硬性约束，并通过事后校准有效缓解了模型的欠置信和过置信问题，提高了预测模型的可靠性。

> **ai_Abstract:** 本文提出了一种名为盒约束Softmax（BCSoftmax）的新型函数，它扩展了传统Softmax，允许对输出概率施加明确的上下限硬约束。针对BCSoftmax的计算，论文开发了一种精确高效的算法。作者将BCSoftmax应用于事后校准任务，设计了两种方法，通过学习输出概率的边界来纠正模型的欠置信和过置信问题，从而提升了模型在下游任务中的可靠性。实验结果表明，该方法在多个数据集上有效改善了校准性能。

> **摘要翻译:** 控制基于Softmax模型的输出概率是现代机器学习中的一个常见问题。尽管Softmax函数通过其温度参数提供软控制，但它缺乏对输出概率施加硬性约束（如盒约束）的能力，这在需要可靠和可信模型的某些应用中可能至关重要。在这项工作中，我们提出了盒约束Softmax（BCSoftmax）函数，它是Softmax函数的一种新颖泛化，明确地对输出概率施加了下限和上限。虽然BCSoftmax被表述为盒约束优化问题的解，但我们开发了一种精确高效的BCSoftmax计算算法。作为一个关键应用，我们引入了两种基于BCSoftmax的事后校准方法。所提出的方法通过在模型训练后学习输出概率或logits的下限和上限来缓解预测模型中的欠置信和过置信，从而增强下游决策任务的可靠性。我们使用TinyImageNet、CIFAR-100和20NewsGroups数据集通过实验证明了我们方法的有效性，并在校准指标方面取得了改进。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [555] [Logarithmic Smoothing for Adaptive PAC-Bayesian Off-Policy Learning](https://arxiv.org/abs/2506.10664)
> *自适应PAC-贝叶斯离策略学习中的对数平滑*

*Maxime Haddouche, Otmane Sakhi* | **Main category: stat.ML**

**Keywords:** 离策略学习, PAC-贝叶斯, 对数平滑, 自适应学习, 收敛速度

**Comment:** 

> **TL;DR:** 本文将对数平滑（LS）的PAC-贝叶斯学习框架扩展到自适应离策略学习场景，通过调整LS估计器以适应多轮部署，实现了更快的收敛速度，并在允许中间策略部署时显著优于现有方法。

**AI_Comments:** 本文的创新点在于将对数平滑（LS）PAC-贝叶斯学习框架扩展到更具挑战性和实际意义的自适应离策略学习场景。通过对LS估计器进行巧妙调整，该方法不仅在理论上保证了更快的收敛速度，而且在实践中也展现出优于传统离线方法的性能，尤其是在允许策略迭代部署的情况下。这对于需要持续学习和改进的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的离策略学习主要关注静态行为策略下的数据收集，而本文旨在研究更实用和灵活的自适应离策略学习设置，其中策略被迭代优化和重新部署以收集更高质量的数据。

**Method:** 本文将静态设置中成功的对数平滑（LS）PAC-贝叶斯学习框架，利用在线PAC-贝叶斯理论的工具，扩展到自适应场景。此外，对LS估计器进行了一项原则性调整，使其自然地适应多轮部署。

**Result:** 该方法在温和条件下能产生更快的收敛速度。在静态设置中，其性能与领先的离线方法相匹配；在允许中间策略部署时，其性能显著优于这些方法。

**Conclusion:** 经验评估突出了自适应数据收集的优势以及PAC-贝叶斯公式的强大之处。

> **ai_Abstract:** 本文将对数平滑（LS）的PAC-贝叶斯学习框架从静态设置扩展到自适应离策略学习场景。通过对LS估计器进行调整，该方法能够适应多轮策略部署，并在温和条件下实现更快的收敛速度。实验结果表明，该方法在静态设置中性能与现有领先方法相当，而在允许中间策略部署时则表现出显著优势，证明了自适应数据收集和PAC-贝叶斯公式的有效性。

> **摘要翻译:** 离策略学习是根据静态行为策略下收集的记录交互来学习最优策略的主要框架。在这项工作中，我们研究了更实用和灵活的自适应离策略学习设置，其中策略被迭代优化并重新部署以收集更高质量的数据。基于对数平滑（LS）PAC-贝叶斯学习在静态设置中取得的成功，我们利用在线PAC-贝叶斯理论的工具将该框架扩展到自适应场景。此外，我们证明了对LS估计器进行一项原则性调整可以自然地适应多轮部署，并在温和条件下产生更快的收敛速度。我们的方法在静态设置中与领先的离线方法表现相当，并且在允许中间策略部署时显著优于它们。对各种场景的经验评估突出了自适应数据收集的优势和PAC-贝叶斯公式的强大之处。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [557] [Practical Improvements of A/B Testing with Off-Policy Estimation](https://arxiv.org/abs/2506.10677)
> *A/B测试中离线策略评估的实用改进*

*Sakhi Otmane, Gilotte Alexandre, Rohde David* | **Main category: stat.ML**

**Keywords:** A/B测试, 离线策略估计, 方差降低, 估计器

**Comment:** 

> **TL;DR:** 本文提出了一种新的无偏离线策略估计器家族，用于A/B测试，能够比传统方法显著降低方差，尤其当测试系统相似时效果更佳。

**AI_Comments:** 本文提出了一种针对A/B测试中方差问题的实用改进方法。通过引入离线策略估计器，解决了传统均值差估计器效率不高的问题，特别是在系统相似性场景下实现了显著的方差降低，具有重要的实际应用价值。创新点在于提供了一个更优的估计器，提高了A/B测试的统计效率。

<details>
  <summary>Details</summary>

**Motivation:** A/B测试中常用的均值差估计器虽然无偏，但仍有改进空间，旨在提高其效率和准确性。

**Method:** 引入了一个无偏离线策略估计器家族，通过理论分析和实验验证，从中确定了方差最低的估计器。

**Result:** 所提出的估计器简单易用，并且在两个测试系统具有相似性时，能够实现显著的方差降低。理论分析和实验结果验证了该方法的有效性和实用性。

**Conclusion:** 通过引入新的无偏离线策略估计器，可以显著提高A/B测试的效率和准确性，尤其在测试系统相似时效果显著，具有很强的实用性。

> **ai_Abstract:** 本文针对A/B测试中均值差估计器存在的方差问题，提出了一种新的无偏离线策略估计器家族。研究者通过理论分析和实验，从该家族中识别出方差最低的估计器。结果表明，这种新的估计器简单且能显著降低方差，尤其在测试系统相似时效果更佳，从而提高了A/B测试的效率和准确性。

> **摘要翻译:** 我们解决了A/B测试的问题，这是一种广泛用于评估新决策系统相对于基线所能实现潜在改进的协议。该协议将人群分为两个子组，每个子组接触一个版本的系统，并通过测量效果之间的差异来估计改进。在这项工作中，我们证明了常用的均值差估计器虽然无偏，但可以得到改进。我们引入了一个无偏离线策略估计器家族，该家族比标准方法实现了更低的方差。在这个家族中，我们确定了方差最低的估计器。由此产生的估计器简单，并且当两个测试系统表现出相似性时，提供了显著的方差降低。我们的理论分析和实验结果验证了所提出方法的有效性和实用性。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [561] [Demystifying Spectral Feature Learning for Instrumental Variable Regression](https://arxiv.org/abs/2506.10899)
> *揭秘工具变量回归中的谱特征学习*

*Dimitri Meunier, Antoine Moulin, Jakub Wornbard, Vladimir R. Kostic, Arthur Gretton* | **Main category: stat.ML**

**Keywords:** 谱特征, 工具变量回归, 因果推断, 泛化误差界, 隐藏混杂因素

**Comment:** 

> **TL;DR:** 本文分析了非参数工具变量（IV）回归中谱特征的性能，并根据谱对齐和特征值衰减识别出三种情景（好、坏、差），同时推导了泛化误差界。

**AI_Comments:** 该论文对工具变量回归中的谱特征学习提供了有价值的理论分析，通过引入谱对齐和特征值衰减的概念，清晰地解释了其性能表现，并提出了一个可预测的分类体系。这有助于“揭秘”该方法的内部机制，使研究人员和实践者能更好地理解其适用范围和局限性。特别是识别出导致方法失效的“差”情景，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决在存在隐藏混杂因素的情况下，使用非参数工具变量（IV）回归进行因果效应估计的问题，并深入理解谱特征学习方法的性能。

**Method:** 本文推导了基于谱特征的两阶段最小二乘估计器的泛化误差界。通过分析谱对齐和特征值衰减这两个关键因素，提出了该方法性能的三种分类（好、坏、差）。通过合成实验验证了这种分类。

**Result:** 方法性能取决于两个关键因素：谱对齐（结构函数被条件算子的顶部特征函数表示的程度）和特征值衰减（工具变量的强度）。这导致了三种结果：1. 好情景：强谱对齐和慢特征值衰减，性能最佳。2. 坏情景：强谱对齐但快特征值衰减，需要更多样本。3. 差情景：弱谱对齐，方法失败。合成实验验证了此分类。

**Conclusion:** 谱特征学习在工具变量回归中的性能关键取决于谱对齐和工具变量的强度（特征值衰减），这导致了从最优到完全失败的可预测结果。

> **ai_Abstract:** 本论文深入探讨了在存在隐藏混杂因素的情况下，非参数工具变量（IV）回归中谱特征学习的有效性。作者为基于谱特征的两阶段最小二乘估计器推导了泛化误差界，并揭示了该方法性能的两个核心决定因素：谱对齐度（结构函数与条件算子顶部特征函数的匹配程度）和特征值衰减速度（工具变量的强度）。基于这些因素，论文提出了一个清晰的性能分类体系，包括“好”、“坏”和“差”三种情景，详述了每种情景下的表现。合成实验经验性地验证了这一分类，为理解谱特征学习何时表现最佳、何时性能下降以及何时完全失效提供了宝贵见解。

> **摘要翻译:** 我们解决了在存在隐藏混杂因素的情况下，使用非参数工具变量（IV）回归进行因果效应估计的问题。一种主要策略是采用谱特征——即，学习到的特征跨越连接处理与工具的操作符的顶部特征子空间。我们推导了基于谱特征的两阶段最小二乘估计器的泛化误差界，并深入了解了该方法的性能和失败模式。我们表明，性能取决于两个关键因素，从而形成清晰的结果分类。在好的情况下，该方法是最佳的。这发生在强谱对齐时，意味着结构函数通过条件算子的顶部特征函数得到了很好的表示，并且该算子的特征值衰减缓慢，表明工具变量强。在坏的情况下，性能会下降：谱对齐仍然很强，但特征值衰减迅速（表明工具变量弱）需要显著更多的样本才能有效学习特征。最后，在糟糕的情况下，弱谱对齐会导致该方法失败，无论特征值的特性如何。我们的合成实验经验性地验证了这种分类。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [562] [Probably Approximately Correct Labels](https://arxiv.org/abs/2506.10908)
> *可能近似正确的标签*

*Emmanuel J. Candès, Andrew Ilyas, Tijana Zrnic* | **Main category: stat.ML**

**Keywords:** 标注数据集, AI预测, 成本效益, 数据整理, 可能近似正确

**Comment:** 

> **TL;DR:** 该论文提出了一种通过结合专家标签和AI预测来经济高效地构建高质量标注数据集的方法，确保了高概率下的低总体标注错误，并在文本、图像和蛋白质折叠分析中得到验证。

**AI_Comments:** 该论文的创新之处在于利用AI预测来降低获取高质量标注数据的成本和工作量，解决了AI发展中的一个重要瓶颈。‘可能近似正确的标签’的概念为生成数据集的质量提供了理论保证，这对于实际应用至关重要。其在自然语言处理、计算机视觉和生物信息学等不同领域的适用性突出了其广泛的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 获取高质量的标注数据集通常成本高昂，需要大量人工标注或昂贵的实验。

**Method:** 提出一种方法，用预训练模型的人工智能预测来补充“专家”标签，以更具成本效益的方式构建标注数据集。该方法旨在实现“可能近似正确的标签”，即总体标注错误以高概率保持较小。

**Result:** 该方法能够实现严谨而高效的数据集整理。通过使用大型语言模型进行文本标注、使用预训练视觉模型进行图像标注以及使用AlphaFold进行蛋白质折叠分析，展示了该方法的好处。

**Conclusion:** 通过利用AI预测补充专家标签，该方法能够以成本效益高的方式创建高质量数据集，产生“可能近似正确的标签”，且总体错误率较低。

> **ai_Abstract:** 本文提出了一种经济高效的方法来构建高质量的标注数据集，通过将昂贵的“专家”标签与预训练模型的AI预测相结合。该方法确保了“可能近似正确的标签”，即总体标注错误以高概率保持较小，从而实现高效且严谨的数据集整理。其有效性在文本标注、图像标注和蛋白质折叠分析等多个领域得到了验证。

> **摘要翻译:** 获取高质量的标注数据集通常成本高昂，需要大量人工标注或昂贵的实验。我们提出一种方法，用预训练模型的人工智能预测来补充此类“专家”标签，以更具成本效益的方式构建标注数据集。我们的方法产生了可能近似正确的标签：以高概率，总体标注错误很小。该解决方案能够使用现代人工智能模型进行严谨而高效的数据集整理。我们通过使用大型语言模型进行文本标注、使用预训练视觉模型进行图像标注以及使用AlphaFold进行蛋白质折叠分析，展示了该方法的好处。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [565] [What Exactly Does Guidance Do in Masked Discrete Diffusion Models](https://arxiv.org/abs/2506.10971)
> *引导在掩码离散扩散模型中究竟做了什么*

*He Ye, Rojas Kevin, Tao Molei* | **Main category: stat.ML**

**Keywords:** 掩码离散扩散模型, 无分类器引导, 采样行为, 总变异, 动力学

**Comment:** 

> **TL;DR:** 本文研究了掩码离散扩散模型中的无分类器引导（CFG），推导了引导反向动力学的显式解，揭示了引导如何影响采样行为，并观察到引导在放大特定类别区域、抑制共享区域以及影响采样轨迹动力学方面的作用。

**AI_Comments:** 这篇论文通过严格的理论推导，为理解无分类器引导在离散扩散模型中的作用提供了深刻见解。其创新之处在于提供了引导反向动力学的显式解，这对于精确分析引导机制至关重要。研究结果揭示了引导对类别区域的放大作用以及对采样轨迹动力学的控制，这对于改进扩散模型的生成质量和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究无分类器引导（CFG）在掩码离散扩散模型中的作用，以精确刻画引导如何影响采样行为。

**Method:** 在没有分数误差和离散化误差的假设下，推导了引导反向动力学的显式解，并通过理论分析和实验支持了研究发现。

**Result:** 1. 引导能够放大类别特定区域并抑制与其他类别共享的区域。2. 引导效果取决于引导强度w，并导致采样分布中独特的协方差结构。3. 在1D和2D中观察到定量上不同的行为。4. 对于大的w，反向动力学沿线的总变异（TV）衰减率在1D和2D中都是w的双指数级。

**Conclusion:** 引导不仅塑造输出分布，还控制采样轨迹的动力学。

> **ai_Abstract:** 本文深入研究了无分类器引导（CFG）在掩码离散扩散模型中的作用。通过推导引导反向动力学的显式解，作者精确地刻画了引导如何影响采样过程。研究发现，引导能够放大类别特有的区域并抑制共享区域，其效果与引导强度w相关，并导致独特的协方差结构。此外，文章还指出总变异的衰减率对于大w是双指数级的。这些发现揭示了引导不仅影响最终输出分布，还控制采样轨迹的动态。

> **摘要翻译:** 我们研究了带有无分类器引导（CFG）的掩码离散扩散模型。假设没有分数误差和离散化误差，我们推导出了引导反向动力学的显式解，从而可以精确地描述引导如何影响采样行为。当完整数据分布是类别混合体且目标是从特定类别中采样时，引导会放大类别特定区域，同时抑制与其他类别共享的区域。这种效应取决于引导强度w，并在采样分布中诱导独特的协方差结构。值得注意的是，我们观察到1D和2D中定量上不同的行为。我们还表明，对于大的w，反向动力学沿线的总变异（TV）衰减率在1D和2D中都是w的双指数级。这些发现强调了引导的作用，它不仅塑造了输出分布，而且控制着采样轨迹的动力学。我们的理论分析得到了实验的支持，这些实验说明了引导的几何效应及其对收敛的影响。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='physicsgeo-ph'></a>
## physics.geo-ph 

### [540] [Diffusion prior as a direct regularization term for FWI](https://arxiv.org/abs/2506.10141)
> *扩散先验作为全波形反演的直接正则化项*

*Yuke Xie, Hervé Chauris, Nicolas Desassis* | **Main category: physics.geo-ph**

**Keywords:** 扩散模型, 全波形反演, 正则化, 生成先验, 地震成像

**Comment:** 

> **TL;DR:** 本文提出将扩散模型作为全波形反演（FWI）的直接正则化项，避免了传统扩散方法中的噪声中间状态和反向扩散过程，从而提高了FWI的稳定性和效率。

**AI_Comments:** 本文的创新之处在于将扩散先验直接用作干净图像空间中的正则化项，从而绕过了计算密集且不稳定的反向扩散过程和噪声中间状态。这简化了与现有FWI管道的集成，同时提高了稳定性和性能，是生成模型应用于物理约束逆问题的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 传统的扩散模型在逆问题中应用时，需要解决完整的反向扩散过程并在有噪声的中间状态下操作，这在全波形反演（FWI）等非线性求解器中会导致不稳定性、数值伪影和较差的反演质量。

**Method:** 提出通过分数匹配策略，将预训练的去噪扩散概率模型（DDPM）作为基于分数的生成扩散先验直接集成到FWI中。该方法避免了反向扩散采样，减少了迭代次数，并在干净图像空间中进行操作，将生成扩散先验作为标准FWI更新规则中的简单正则化项。

**Result:** 数值实验表明，与传统和基于GAN的FWI方法相比，所提出的方法提供了增强的保真度和鲁棒性，同时在地震成像和其他逆问题任务中保持实用和计算效率。

**Conclusion:** 本文提出的方法将扩散先验作为直接正则化项有效地集成到FWI中，显著改善了波传播的稳定性、收敛行为和反演质量，为地震成像及其他逆问题提供了更优的解决方案。

> **ai_Abstract:** 本文提出一种新颖的框架，将预训练的去噪扩散概率模型（DDPM）作为直接正则化项集成到全波形反演（FWI）中。与传统扩散方法不同，该方法避免了复杂的反向扩散过程和在噪声中间空间中的操作，而是在干净图像空间中进行。通过将扩散先验作为FWI更新规则中的简单正则化项，该方法增强了波传播的稳定性，改善了收敛性，并产生了更优的反演质量。数值实验表明，与现有FWI技术相比，其在保真度、鲁棒性、实用性和计算效率方面均有所提升。

> **摘要翻译:** 扩散模型最近在逆问题中显示出作为强大生成先验的潜力。然而，传统应用需要解决完整的反向扩散过程并在有噪声的中间状态下操作，这给受物理约束的计算地震成像带来了挑战。特别是，这种不稳定性在全波形反演（FWI）等非线性求解器中尤为明显，其中通过噪声速度场的波传播可能导致数值伪影和较差的反演质量。在这项工作中，我们提出了一种简单而有效的框架，通过分数匹配策略将预训练的去噪扩散概率模型（DDPM）作为基于分数的生成扩散先验直接集成到FWI中。与传统扩散方法不同，我们的方法避免了反向扩散采样，并且需要的迭代次数更少。我们在干净图像空间中完全进行图像反演，无需通过噪声速度模型操作。生成扩散先验可以作为标准FWI更新规则中的一个简单正则化项引入，对现有FWI管道的修改最小。这促进了稳定的波传播，并可以改善收敛行为和反演质量。数值实验表明，与传统和基于GAN的FWI方法相比，所提出的方法提供了增强的保真度和鲁棒性，同时在地震成像和其他逆问题任务中保持实用和计算效率。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

### [548] [Self-learning signal classifier for decameter coherent scatter radars](https://arxiv.org/abs/2506.10305)
> *分米波相干散射雷达自学习信号分类器*

*Oleg Berngardt, Ivan Lavygin* | **Main category: physics.geo-ph**

**Keywords:** 自学习分类器, 分米波相干散射雷达, 电离层, 无线电波传播, 数据分类

**Comment:** 30 pages, 10 figures, 4 tables. To be submitted to Advances in Space
  Research

> **TL;DR:** 本文提出并构建了一种基于雷达数据、电离层无线电波传播模型和数学准则的自学习分类器，用于自动分类分米波相干散射雷达数据，并识别出关键分类参数和信号类别。

**AI_Comments:** 这项研究的创新之处在于提出了一种完全基于数据和物理模型相结合的自学习方法来自动构建雷达信号分类器，大大减少了对人工干预的需求。其重要性体现在能够系统化地对复杂的雷达散射数据进行分类和解释，为理解电离层物理现象提供了新的工具。通过识别关键分类参数和分析类别动态，为进一步的科学研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为分米波相干散射雷达的已处理数据自动构建一个分类器，以实现数据的自动化分析和模式识别。

**Method:** 该方法基于雷达数据、电离层无线电波传播的自动建模结果以及评估模型质量的数学标准。最终分类器在来自SuperDARN和SECIRA网络12个雷达两年（每个雷达）的数据上进行训练，模型系数为2669。分类时同时使用模型电离层中计算的无线电波传播参数和雷达直接测量的参数。通过流星尾迹散射信号对每个雷达的无线电波仰角测量进行了校准。

**Result:** 分析表明数据中最佳类别数为37个（其中25个频繁观测）。从中选出了14个在其他模型训练变体中能可靠分离的类别，并对其中10个进行了初步解释。展示了不同类别的观测动态及其与雷达地理纬度、太阳和地磁活动水平的依赖关系，结果与已知物理机制不矛盾。分析显示，识别类别的最重要参数是信号射线追踪轨迹后半部分的形状、射线追踪散射高度和雷达测量的多普勒速度。

**Conclusion:** 该研究成功构建了一个自学习信号分类器，能够有效分类分米波相干散射雷达数据，并识别出关键的分类参数和信号类别，其结果与已知物理机制一致。

> **ai_Abstract:** 本文提出了一种用于分米波相干散射雷达数据的自学习信号分类器。该分类器整合了实际雷达数据、电离层无线电波传播模型及质量评估标准进行训练。通过在SuperDARN和SECIRA网络12个雷达两年数据上的训练，模型能有效识别并区分出37个潜在类别中的14个关键类别，并初步解释了其中10个。研究还揭示了这些类别的观测动态与地理纬度、太阳及地磁活动的关系，并指出信号射线追踪轨迹形状、散射高度和多普勒速度是识别类别的最重要参数，其结果与现有物理机制相符。

> **摘要翻译:** 本文提出了一种自动构建用于分米波相干散射雷达处理数据的分类器的方法。该方法仅基于获得的雷达数据、电离层中无线电波传播的自动建模结果以及评估模型质量的数学标准。最终的分类器是在SuperDARN和SECIRA网络中12个雷达两年（每个雷达）的数据上训练的模型。模型系数为2669。为了进行分类，该模型同时使用了模型电离层中计算的无线电波传播参数和雷达直接测量的参数。每个雷达的无线电波仰角测量都通过流星尾迹散射信号进行了校准。分析表明，数据中最佳类别数为37个，其中25个是频繁观测的。分析使得从中选择了14个类别，这些类别在其他模型训练变体中能够可靠地分离。对其中10个进行了初步解释。展示了不同类别的观测动态及其与雷达地理纬度在不同太阳和地磁活动水平下的依赖关系，结果表明这与已知的物理机制不矛盾。分析显示，识别类别的最重要参数是信号射线追踪轨迹后半部分的形状、射线追踪散射高度和雷达测量的多普勒速度。

</details>

[⬆️ 返回分类顶部](#physicsgeo-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [541] [Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows](https://arxiv.org/abs/2506.10153)
> *流体控制中的注意力机制：基于Transformer的强化学习用于强扰流中的升力调节*

*Zhecheng Liu, Jeff D. Eldredge* | **Main category: physics.flu-dyn**

**Keywords:** 强化学习, Transformer, 流体控制, 升力调节, 俯仰控制

**Comment:** 

> **TL;DR:** 本文提出了一种基于Transformer的强化学习框架，通过俯仰控制在强扰流中调节气动升力。该方法优于传统控制，并具有良好的泛化能力，同时通过预训练和迁移学习加速训练。

**AI_Comments:** 本文创新性地将Transformer模型引入强化学习框架，以解决流体控制中局部可观察性问题，并结合预训练和迁移学习显著加速了训练过程。其在强扰动流体控制领域的应用展示了强化学习的巨大潜力，尤其是在泛化能力和控制效率方面的提升。对不同枢轴配置的深入分析也为实际应用提供了有价值的指导。该研究为未来解决更复杂、计算量更大的流体控制问题奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 针对弱扰动设计的线性流体控制策略在强扰动序列中可能失效，因为存在非线性相互作用。因此，需要开发一种更有效的策略。

**Method:** 本文提出了一种基于Transformer的强化学习（RL）框架，通过俯仰控制来学习调节阵风序列中的气动升力。Transformer用于处理有限表面压力传感器导致的局部可观察性挑战。训练通过专家策略（线性控制）预训练和任务级迁移学习（将针对单一阵风训练的策略扩展到多个阵风）两种技术加速。研究了枢轴配置，并分解了升力以分析优势。

**Result:** 学习到的策略优于最佳比例控制，且随着阵风数量增加，性能差距扩大。在少量连续阵风环境中学习到的控制策略能有效泛化到任意长序列的阵风环境。四分之一弦长俯仰控制比中弦长俯仰控制能以更少的控制力实现更优的升力调节，这归因于通过四分之一弦长俯仰可获得的主导附加质量贡献。

**Conclusion:** 所提出的基于Transformer的强化学习框架及其加速技术，在多种配置下表现出良好的泛化性，为解决计算要求更高的流体控制问题提供了一种有前景的方法。

> **ai_Abstract:** 本研究提出了一种基于Transformer的强化学习（RL）框架，用于通过俯仰控制在强扰流（阵风序列）中有效地调节气动升力。该框架通过Transformer处理有限传感器输入带来的局部可观察性问题。为加速训练，研究采用了专家策略预训练和任务级迁移学习。实验结果表明，该学习策略优于传统比例控制，且在阵风数量增加时性能优势更显著，并能有效泛化到长序列阵风环境。此外，研究发现四分之一弦长俯仰控制比中弦长俯仰控制能以更小的控制代价实现更优的升力调节。该方法具有良好的通用性，有望解决更复杂的流体控制问题。

> **摘要翻译:** 为弱扰动设计的线性流体控制策略在强扰动序列中可能因非线性相互作用而失效，但利用其来开发更好的策略是明智的。在本研究中，我们提出了一种基于Transformer的强化学习（RL）框架，以通过俯仰控制学习在阵风序列中调节气动升力的有效控制策略。Transformer解决了有限表面压力传感器导致的局部可观察性挑战。我们证明了通过两种技术可以加速训练——使用专家策略（此处为线性控制）进行预训练和任务级迁移学习（此处为将针对孤立阵风训练的策略扩展到多个阵风）。我们表明，学习到的策略优于最佳比例控制，并且随着阵风数量的增加，性能差距扩大。在少量连续阵风环境中学习到的控制策略被证明可以有效泛化到具有任意长序列阵风的环境中。我们研究了枢轴配置，并表明与中弦长俯仰控制相比，四分之一弦长俯仰控制可以以显著更少的控制力实现更优的升力调节。通过升力分解，我们将这一优势归因于通过四分之一弦长俯仰可获得的主导附加质量贡献。在多种配置上的成功表明了所提出的基于Transformer的RL框架的通用性，当与所提出的加速技术结合时，它为解决计算要求更高的流体控制问题提供了一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [558] [OmniFluids: Unified Physics Pre-trained Modeling of Fluid Dynamics](https://arxiv.org/abs/2506.10862)
> *OmniFluids：流体动力学统一物理预训练建模*

*Rui Zhang, Qi Meng, Han Wan, Yang Liu, Zhi-Ming Ma, Hao Sun* | **Main category: physics.flu-dyn**

**Keywords:** 流体动力学, 算子学习, 物理预训练, 深度学习, 计算流体力学

**Comment:** 

> **TL;DR:** OmniFluids是一个统一的物理预训练算子学习框架，通过整合物理预训练、粗网格蒸馏和少样本微调，实现了在有限或零数据监督下流体动力学的快速准确预测，相比传统求解器提速10-100倍。

**AI_Comments:** OmniFluids的创新之处在于其统一的框架，有效地结合了物理知识和深度学习的优势，通过预训练、蒸馏和微调的策略，解决了现有方法在效率、数据依赖和稳定性方面的痛点。其在速度和精度上的显著提升，尤其是在数据稀缺条件下的表现，预示着其在实际工程和科学应用中巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 高精度和高效的流体动力学模拟对于科学和工程应用至关重要。传统的计算流体力学方法计算成本高昂。物理信息神经网络（PINNs）和神经算子需要大量再训练和调整，纯数据驱动算子需要大量标记数据集。混合物理感知方法速度提升有限，且在平衡粗粒度先验与高精度测量时不稳定。

**Method:** 本文引入了OmniFluids，一个统一的物理预训练算子学习框架。该框架整合了纯物理预训练、粗网格算子蒸馏和少样本微调，以实现有限或零数据监督下的快速推理和准确预测。OmniFluids的关键架构组件包括算子混合器、多帧解码器和分解傅里叶层，这些组件能够高效、可扩展地建模各种物理任务，同时保持与基于物理的监督无缝集成。

**Result:** 在广泛的二维和三维基准测试中，OmniFluids在流场重建和湍流统计精度方面显著优于最先进的AI驱动方法，与经典求解器相比实现了10-100倍的速度提升，并能从稀疏、嘈杂的数据中准确恢复未知物理参数。

**Conclusion:** 这项工作为在数据有限的复杂流体系统中实现高效、可泛化的替代模型建立了一个新范式。

> **ai_Abstract:** 本文提出了OmniFluids，一个统一的物理预训练算子学习框架，旨在克服传统计算流体力学方法计算成本高昂、现有深度学习方法（如PINNs和纯数据驱动算子）需要大量数据或难以调整的局限性。OmniFluids通过整合纯物理预训练、粗网格算子蒸馏和少样本微调，实现了在有限或零数据监督下对流体动力学的快速准确预测。其核心架构包括算子混合器、多帧解码器和分解傅里叶层。实验结果表明，OmniFluids在二维和三维流体模拟中显著优于现有AI方法，实现了10-100倍的速度提升，并能准确恢复未知物理参数，为复杂流体系统在数据有限条件下的高效通用代理建模提供了新范式。

> **摘要翻译:** 高精度和高效的流体动力学模拟推动了各种科学和工程应用的进步。传统的计算流体力学方法具有很强的可解释性和收敛性保证，但依赖于精细的空间和时间网格，导致计算成本过高。物理信息神经网络（PINNs）和神经算子旨在利用深度学习技术加速偏微分方程求解器。然而，PINNs需要大量的再训练和仔细调整，而纯数据驱动的算子则需要大量的标记数据集。混合物理感知方法将数值离散化嵌入到网络架构或损失函数中，但速度提升微乎其微，并且在平衡粗粒度先验与高精度测量时变得不稳定。为此，我们引入了OmniFluids，一个统一的物理预训练算子学习框架，它整合了纯物理预训练、粗网格算子蒸馏和少样本微调，从而在有限或零数据监督下实现快速推理和准确预测。在架构设计方面，OmniFluids的关键组件包括算子混合器、多帧解码器和分解傅里叶层，这些组件能够高效、可扩展地建模各种物理任务，同时保持与基于物理的监督无缝集成。在广泛的二维和三维基准测试中，OmniFluids在流场重建和湍流统计精度方面显著优于最先进的AI驱动方法，与经典求解器相比实现了10-100倍的速度提升，并能从稀疏、嘈杂的数据中准确恢复未知物理参数。这项工作为在数据有限的复杂流体系统中实现高效、可泛化的替代模型建立了一个新范式。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [544] [Exploring Topological and Localization Phenomena in SSH Chains under Generalized AAH Modulation: A Computational Approach](https://arxiv.org/abs/2506.10195)
> *探索广义AAH调制下SSH链中的拓扑和局域化现象：一种计算方法*

*Souvik Ghosh, Sayak Roy* | **Main category: cond-mat.mtrl-sci**

**Keywords:** SSH模型, 拓扑绝缘体, 局域化, 非厄米性, Floquet驱动

**Comment:** 

> **TL;DR:** 本文计算研究了广义SSH模型中拓扑、准周期无序、非厄米性及时间驱动的相互作用，发现AAH调制可破坏拓扑态，非厄米性导致非厄米趋肤效应，并成功工程化了Floquet拓扑绝缘体。

**AI_Comments:** 这篇论文通过结合精确对角化、数值求解器以及无监督机器学习（PCA）等多种计算方法，对广义SSH模型进行了深入且全面的研究，其创新性在于系统地探索了多种复杂因素（如准周期无序、非厄米性和时间依赖驱动）对拓扑现象的影响。特别是非厄米趋肤效应的发现以及Floquet拓扑绝缘体的工程化，为理解和设计新型拓扑材料提供了重要见解。论文也指出了强局域化可能掩盖拓扑特征的局限性，这对于未来实验和理论研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索Su-Schrieffer-Heeger (SSH) 模型在更复杂、更真实的条件下的行为，因为这是研究的肥沃领域。特别关注拓扑、准周期无序、非厄米性以及时间相关驱动之间的相互作用。

**Method:** 使用精确对角化和专门的数值求解器，通过光谱特性和局域化特征（由逆参与比 IPR 量化）绘制系统相空间。采用无监督机器学习（PCA）自动分类系统相位。将模型扩展到非厄米性。对拓扑平凡链施加周期性Floquet驱动。

**Result:** 强Aubry-Andr\'e-Harper (AAH) 调制引起的局域化跃迁会破坏标准SSH模型的拓扑保护边缘态。强局域化会掩盖潜在的拓扑特征。在非厄米模型中发现了非厄米趋肤效应，即所有体态在边界的显著局域化。成功地将拓扑平凡链工程化为Floquet拓扑绝缘体，其特征是在准能量区边界出现反常边缘态。

**Conclusion:** 这些发现共同提供了对广义一维拓扑系统中丰富现象的多方面视角。

> **ai_Abstract:** 本文通过计算方法深入研究了广义SSH模型，探讨了拓扑、准周期无序、非厄米性及时间驱动的复杂耦合。研究发现，强AAH调制能破坏SSH模型的拓扑边缘态，并揭示了强局域化对拓扑特征的掩盖作用。进一步，论文揭示了非厄米趋肤效应，并通过Floquet驱动成功设计出具有反常边缘态的拓扑绝缘体，为理解广义一维拓扑系统提供了多维度视角。

> **摘要翻译:** Su-Schrieffer-Heeger (SSH) 模型是一维拓扑绝缘体的典型例子，但其在更复杂、更真实条件下的行为仍然是研究的热点。本文对广义SSH模型进行了全面的计算研究，探索了拓扑、准周期无序、非厄米性和时间依赖驱动之间的相互作用。我们使用精确对角化和专门的数值求解器，通过系统的光谱特性和局域化特征（由逆参与比 (IPR) 量化）绘制了系统的相空间。我们证明，虽然标准SSH模型表现出拓扑保护的边缘态，但这些态会被强Aubry-Andr\'e-Harper (AAH) 调制引起的局域化跃迁破坏。此外，我们采用无监督机器学习（主成分分析PCA）自主分类了系统的相位，揭示了强局域化可以掩盖潜在的拓扑特征。将模型扩展到非厄米性，我们发现了非厄米趋肤效应，即所有体态在边界处的显著局域化。最后，我们将周期性Floquet驱动应用于拓扑平凡链，成功地工程化了一个Floquet拓扑绝缘体，其特征是在准能量区边界出现反常边缘态。这些发现共同提供了对广义一维拓扑系统中丰富现象的多方面视角。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

### [564] [Coupled reaction and diffusion governing interface evolution in solid-state batteries](https://arxiv.org/abs/2506.10944)
> *耦合反应和扩散控制固态电池中的界面演化*

*Jingxuan Ding, Laura Zichi, Matteo Carli, Menghang Wang, Albert Musaelian, Yu Xie, Boris Kozinsky* | **Main category: cond-mat.mtrl-sci**

**Keywords:** 固态电池, SEI, 反应扩散, 原子模拟, 活性学习

**Comment:** 

> **TL;DR:** 本文利用主动学习和深度等变神经网络势能，进行了大规模量子精度反应模拟，揭示了固态电池SEI中一个未曾报道的晶体无序相的形成，并解释了实验观察到的SEI形成和锂蠕变机制。

**AI_Comments:** 本文的创新之处在于结合了主动学习、深度等变神经网络势能和大规模量子精度模拟，以克服传统模拟和实验在表征埋藏界面时的局限性。通过发现新的SEI相并解释锂蠕变机制，为固态电池关键界面的理解提供了重要见解，尤其强调了动力学在SEI形成中的作用，而非仅仅是热力学。其“数字孪生”方法无需实验拟合参数，具有普适性和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 理解和控制固态电解质界面（SEI）的原子级反应对于下一代固态电池的实际应用至关重要。然而，由于实验表征埋藏界面的困难以及模拟速度和精度的限制，挑战依然存在。

**Method:** 研究人员利用主动学习和深度等变神经网络原子间势能，对对称电池单元进行了大规模、显式的量子精度反应模拟。为了自动表征界面处的耦合反应和相互扩散，他们制定并使用了基于局部原子环境空间聚类的无监督分类技术。

**Result:** 分析揭示了SEI中形成了先前未报道的晶体无序相Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$，该相规避了之前纯粹基于热力学的预测，强调了明确建模完整反应和传输动力学的重要性。模拟结果与SEI形成的实验观察结果一致并对其进行了解释，阐明了锂蠕变机制（对枝晶形成至关重要，其特征是锂沿界面发生显著运动）。

**Conclusion:** 该方法从第一性原理创建了一个数字孪生，没有经过实验拟合的可调参数。因此，它提供了深入了解固态合成和电化学中复杂异质过程的原子动力学的能力。

> **ai_Abstract:** 本研究通过结合主动学习和深度等变神经网络原子间势能，对固态电池中的界面演化进行了大规模、量子精度的反应模拟。利用无监督分类技术分析了界面处的耦合反应和相互扩散，首次发现了SEI中一个未曾报道的晶体无序相Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$。该工作强调了显式建模反应和传输动力学的重要性，并成功解释了SEI形成和锂蠕变的实验观察结果，为固态电池材料设计提供了从第一性原理出发的见解。

> **摘要翻译:** 理解和控制固态电解质界面（SEI）形成的原子级反应对于下一代固态电池的实际应用至关重要。然而，由于实验表征埋藏界面的困难以及模拟速度和精度的限制，挑战依然存在。我们利用主动学习和深度等变神经网络原子间势能，对对称电池单元进行了大规模、显式的量子精度反应模拟。为了自动表征界面处的耦合反应和相互扩散，我们制定并使用了基于局部原子环境空间聚类的无监督分类技术。我们的分析揭示了SEI中形成了先前未报道的晶体无序相Li$_2$S$_{0.72}$P$_{0.14}$Cl$_{0.14}$，该相规避了之前纯粹基于热力学的预测，强调了明确建模完整反应和传输动力学的重要性。我们的模拟结果与SEI形成的实验观察结果一致并对其进行了解释，阐明了锂蠕变机制（对枝晶形成至关重要，其特征是锂沿界面发生显著运动）。我们的方法是从第一性原理创建了一个数字孪生，没有经过实验拟合的可调参数。因此，它提供了深入了解固态合成和电化学中复杂异质过程的原子动力学的能力。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='physicsao-ph'></a>
## physics.ao-ph 

### [551] [Prediction of steady states in a marine ecosystem model by a machine learning technique](https://arxiv.org/abs/2506.10475)
> *利用机器学习技术预测海洋生态系统模型的稳态*

*Sarker Miraz Mahfuz, Thomas Slawig* | **Main category: physics.ao-ph**

**Keywords:** 海洋生态系统模型, 稳态预测, 机器学习, 条件变分自编码器, 自旋启动

**Comment:** 

> **TL;DR:** 本文利用条件变分自编码器（CVAE）预测海洋生态系统模型的稳态，并将其预测结果作为初始值，显著加速了模型自旋启动过程，节省了50%到95%的计算时间。

**AI_Comments:** 这项研究的创新之处在于将机器学习，特别是CVAE，应用于加速计算密集型的海洋生态系统模型自旋启动过程。通过利用ML模型预测的近似稳态作为初始值，极大地提高了模拟效率。这对于需要大量模拟实验（如参数敏感性分析、不确定性量化）的领域具有重要意义。其局限性可能在于CVAE预测的周期性仍需后续自旋启动修正，以及该方法对模型复杂度和数据量的依赖性。

<details>
  <summary>Details</summary>

**Motivation:** 海洋生态系统模型的自旋启动（spin-up）过程需要大量的计算时间来达到稳态，这限制了模型的使用和参数探索。因此，需要一种更高效的方法来加速这一过程。

**Method:** 研究人员使用预先计算好的全球海洋生态系统模型的稳态数据作为训练数据，通过带有质量校正的条件变分自编码器（CVAE）将少量生物地球化学模型参数映射到三维收敛的稳态年循环。然后，将CVAE的预测结果作为自旋启动的初始值，以减少达到预设停止准则所需的迭代次数。

**Result:** CVAE的预测结果可以合理地近似通过常规自旋启动获得的稳态，但年度周期性不如原始数据。然而，将CVAE预测作为自旋启动的初始值，可以显著减少达到稳态所需的迭代次数（模型年数），与使用均匀常数初始值相比，计算时间节省了50%到95%，具体取决于停止准则。与使用训练数据平均值作为初始值相比，CVAE的加速效果更显著。

**Conclusion:** 机器学习技术，特别是CVAE，可以有效地预测海洋生态系统模型的稳态，并作为自旋启动的优秀初始值，从而大幅缩短模型达到稳态所需的计算时间，显著提高了模型运行效率。

> **ai_Abstract:** 本研究利用条件变分自编码器（CVAE）预测全球海洋生态系统模型的稳态。通过将预计算的稳态数据作为训练集，CVAE能够从模型参数映射到三维稳态年循环。尽管CVAE的直接预测在周期性上略逊于传统自旋启动结果，但当其预测值作为自旋启动的初始条件时，能显著减少达到稳态所需的迭代次数，从而节省50%至95%的计算时间。这表明机器学习方法能有效加速大型海洋生态系统模型的模拟过程。

> **摘要翻译:** 我们使用通过自旋启动获得的全球海洋生态系统模型的预计算稳态作为训练数据，以构建从少量生物地球化学模型参数到三维收敛稳态年循环的映射。该映射通过带有质量校正的条件变分自编码器（CVAE）进行。应用于测试数据时，我们发现CVAE获得的预测已经能够很好地近似通过常规自旋启动获得的稳态。然而，预测的年度周期性未能达到原始自旋启动数据所达到的水平。因此，我们将预测结果作为自旋启动的初始值。结果表明，与使用原始均匀常数初始值相比，达到自旋启动中预设停止准则所需的迭代次数（对应于模型年数）可以显著减少。减少量取决于所应用的停止准则，即衡量解的周期性。自旋启动所需迭代次数和计算时间的节省范围为50%到95%，具体取决于自旋启动的停止准则。我们将这些结果与使用训练数据平均值作为初始值的情况进行了比较。我们发现这也加速了自旋启动，但加速因子要低得多。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

---

### [554] [Pushing the Limits of Extreme Weather: Constructing Extreme Heatwave Storylines with Differentiable Climate Models](https://arxiv.org/abs/2506.10660)
> *突破极端天气极限：利用可微分气候模型构建极端热浪情景*

*Tim Whittaker, Alejandro Di Luca* | **Main category: physics.ao-ph**

**Keywords:** 极端天气, 热浪, 可微分气候模型, NeuralGCM, 风险评估

**Comment:** 

> **TL;DR:** 本文提出一种利用可微分混合气候模型（NeuralGCM）生成极端热浪最坏情景的新框架，能高效探索极端事件的上限，为气候变化下的风险评估提供新方法。

**AI_Comments:** 本文提出了一种新颖且具有潜力的极端天气事件模拟方法，通过引入可微分气候模型（如NeuralGCM），克服了传统物理模型集合在计算成本和对罕见极端事件模拟保真度方面的局限性。其创新点在于将优化技术与气候模型相结合，能够高效地探索极端事件的“上尾”可能性。这对于提升气候风险评估的准确性和针对性具有重要意义，尤其是在应对日益频繁和强烈的极端热浪方面。该方法为未来极端天气事件的预测和情景构建开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 在气候变暖背景下，了解极端天气事件的合理上限对于风险评估至关重要。现有基于物理模型的集合方法计算成本高昂或缺乏模拟罕见高影响极端事件所需的保真度。

**Method:** 本文提出一种新颖的框架，利用可微分混合气候模型NeuralGCM优化初始条件，生成符合物理规律的最坏情况热浪轨迹。该方法应用于2021年太平洋西北部热浪。

**Result:** 该方法产生的温度异常比75个成员集合中最极端成员高出3.7°C。这些轨迹表现出大气阻塞加剧和罗斯贝波模式放大。

**Conclusion:** 研究结果表明，可微分气候模型可以有效地探索事件发生可能性的上限，为构建气候变化下极端天气的特定情景提供了一种强大的新方法。

> **ai_Abstract:** 本研究提出了一种利用可微分混合气候模型NeuralGCM来构建极端热浪情景的新框架。该方法通过优化初始条件，能够生成符合物理规律的最坏情况热浪轨迹。应用于2021年太平洋西北部热浪，该方法产生了比现有集合模型更极端的温度异常，并揭示了加剧的大气阻塞和罗斯贝波模式。这表明可微分气候模型能高效探索极端事件的上限，为气候变化下的风险评估提供了一种创新方法。

> **摘要翻译:** 理解极端天气事件的合理上限对于变暖气候下的风险评估至关重要。现有基于大量物理模型集合的方法通常计算成本高昂，或者缺乏模拟罕见、高影响极端事件所需的保真度。在此，我们提出一个新颖的框架，该框架利用可微分混合气候模型NeuralGCM，优化初始条件并生成符合物理规律的最坏情况热浪轨迹。将该方法应用于2021年太平洋西北部热浪，我们的方法产生的温度异常比75个成员集合中最极端成员高出3.7°C。这些轨迹的特点是大气阻塞加剧和罗斯贝波模式放大——这是严重热事件的标志。我们的结果表明，可微分气候模型可以有效地探索事件发生可能性的上限，为构建气候变化下极端天气的特定情景提供了一种强大的新方法。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

---

### [556] [A multi-scale loss formulation for learning a probabilistic model with proper score optimisation](https://arxiv.org/abs/2506.10868)
> *一种用于学习具有适当分数优化的概率模型的多尺度损失公式*

*Simon Lang, Martin Leutbecher, Pedro Maciel* | **Main category: physics.ao-ph**

**Keywords:** 多尺度损失, 概率模型, 天气预报, afCRPS, 变异性约束

**Comment:** 

> **TL;DR:** 评估多尺度损失在概率天气预报模型中对小尺度变异性的约束作用。

**AI_Comments:** 这项工作通过引入多尺度损失，解决了天气预报模型中对小尺度变异性约束不足的问题，其创新性在于在不牺牲整体预测技能的前提下提升了模型对细节的捕捉能力。这对于提高天气预报的精度和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进概率机器学习天气预报模型的训练，特别是更好地约束小尺度变异性，同时不负面影响预测技能。

**Method:** 提出并评估了一种多尺度损失公式，将其应用于欧洲中期天气预报中心（ECMWF）开发的AIFS-CRPS模型进行训练，该模型通过直接优化几乎公平的连续分级概率得分（afCRPS）。

**Result:** 多尺度损失能够更好地约束小尺度变异性，同时不负面影响预测技能。

**Conclusion:** 多尺度损失公式为未来尺度感知模型训练开辟了有前景的方向。

> **ai_Abstract:** 本文评估了一种多尺度损失公式在训练概率机器学习天气预报模型中的效果。该损失在ECMWF开发的AIFS-CRPS模型中进行测试，该模型通过优化afCRPS进行训练。结果显示，多尺度损失能有效约束小尺度变异性，同时保持或不损害预测性能，为未来的尺度感知模型训练提供了新方向。

> **摘要翻译:** 我们评估了一种多尺度损失公式对训练概率机器学习天气预报模型的影响。这种多尺度损失在AIFS-CRPS中进行了测试，AIFS-CRPS是欧洲中期天气预报中心（ECMWF）开发的一种机器学习天气预报模型。AIFS-CRPS通过直接优化几乎公平的连续分级概率得分（afCRPS）进行训练。多尺度损失能更好地约束小尺度变异性，而不会对预测技能产生负面影响。这为未来尺度感知模型训练开辟了有前景的方向。

</details>

[⬆️ 返回分类顶部](#physicsao-ph) | [⬆️ 返回总目录](#toc)

