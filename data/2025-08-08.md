# AI-Enhanced arXiv Daily 2025-08-08

<a id='toc'></a>
## 今日总计: 878 篇论文
### 目录
- [cs.AI](#csai) (271 篇)
- [cs.AR](#csar) (5 篇)
- [cs.CC](#cscc) (3 篇)
- [cs.CE](#csce) (12 篇)
- [cs.CG](#cscg) (5 篇)
- [cs.CL](#cscl) (58 篇)
- [cs.CR](#cscr) (25 篇)
- [cs.CV](#cscv) (147 篇)
- [cs.CY](#cscy) (6 篇)
- [cs.DB](#csdb) (2 篇)
- [cs.DC](#csdc) (9 篇)
- [cs.DM](#csdm) (8 篇)
- [cs.DS](#csds) (7 篇)
- [cs.ET](#cset) (4 篇)
- [cs.FL](#csfl) (3 篇)
- [cs.GR](#csgr) (3 篇)
- [cs.GT](#csgt) (6 篇)
- [cs.HC](#cshc) (24 篇)
- [cs.IR](#csir) (19 篇)
- [cs.IT](#csit) (18 篇)
- [cs.LG](#cslg) (105 篇)
- [cs.LO](#cslo) (5 篇)
- [cs.MA](#csma) (5 篇)
- [cs.MM](#csmm) (1 篇)
- [cs.MS](#csms) (1 篇)
- [cs.NE](#csne) (2 篇)
- [cs.NI](#csni) (4 篇)
- [cs.PF](#cspf) (3 篇)
- [cs.PL](#cspl) (1 篇)
- [cs.RO](#csro) (31 篇)
- [cs.SC](#cssc) (1 篇)
- [cs.SD](#cssd) (3 篇)
- [cs.SE](#csse) (7 篇)
- [cs.SI](#cssi) (2 篇)
- [eess.AS](#eessas) (7 篇)
- [eess.IV](#eessiv) (7 篇)
- [eess.SP](#eesssp) (18 篇)
- [eess.SY](#eesssy) (14 篇)
- [math.NA](#mathna) (13 篇)
- [stat.AP](#statap) (3 篇)
- [math.AP](#mathap) (3 篇)
- [cond-mat.soft](#cond-matsoft) (1 篇)
- [cond-mat.mtrl-sci](#cond-matmtrl-sci) (1 篇)
- [astro-ph.EP](#astro-phep) (2 篇)
- [math.PR](#mathpr) (1 篇)
- [math.DG](#mathdg) (1 篇)
- [math.FA](#mathfa) (1 篇)

---
<a id='csai'></a>
## cs.AI 

### [1] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
> *DeepPHY：基准测试具身VLM的物理推理能力*

*Xinrun Xu, Pi Bu, Ye Wang, Börje F. Karlsson, Ziming Wang, Tengtao Song, Qi Zhu, Jun Song, Zhiming Ding, Bo Zheng* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** DeepPHY, 视觉语言模型, 物理推理, 基准测试, 模拟环境

**Comment:** 

> **TL;DR:** DeepPHY是一个新的基准测试框架，用于在模拟环境中系统地评估视觉语言模型（VLM）的物理推理能力。研究发现，即使是最先进的VLM也难以将描述性物理知识转化为精确的预测控制。

**AI_Comments:** DeepPHY的创新之处在于其提供了一个系统且成本效益高的平台，用于评估VLM的物理推理能力，弥补了现实世界评估的不足。其重要性在于揭示了当前VLM在将高层物理知识转化为精确具身控制方面的局限性，为未来研究指明了方向。该工作可能为开发更具鲁棒性和实用性的具身AI系统奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉语言模型（VLM）具有强大的感知和视觉推理能力，但在复杂动态环境中，它们在细节关注和精确动作规划方面表现不佳，导致性能欠佳。现实世界任务通常需要复杂的交互、高级空间推理、长期规划和持续策略优化，这通常需要理解目标场景的物理规则。然而，在现实世界场景中评估这些能力成本过高。

**Method:** 为了弥补这一差距，我们引入了DeepPHY，一个新颖的基准测试框架，旨在通过一系列具有挑战性的模拟环境，系统地评估VLM对基本物理原理的理解和推理能力。DeepPHY集成了不同难度级别的多个物理推理环境，并包含了细粒度的评估指标。

**Result:** 我们的评估发现，即使是最先进的视觉语言模型也难以将描述性物理知识转化为精确的预测控制。

**Conclusion:** 当前最先进的视觉语言模型在将描述性物理知识转化为精确的预测控制方面存在困难，表明在物理推理和具身智能方面仍有很大的改进空间。

> **ai_Abstract:** 本文介绍了DeepPHY，一个用于评估视觉语言模型（VLM）物理推理能力的新型基准测试框架。鉴于现有VLM在复杂物理场景中精确控制和规划的不足以及现实世界评估的高成本，DeepPHY通过集成多难度模拟环境和细粒度评估指标，系统地测试VLM对物理原理的理解。研究结果表明，即使是最先进的VLM也难以有效地将理论物理知识应用于精确的预测控制。

> **摘要翻译:** 尽管视觉语言模型（VLM）展现出强大的感知能力和出色的视觉推理，但它们在复杂、动态环境中对细节的关注和精确的动作规划方面仍有不足，导致性能欠佳。现实世界任务通常需要复杂的交互、高级空间推理、长期规划和持续的策略优化，这通常需要理解目标场景的物理规则。然而，在现实世界场景中评估这些能力往往成本过高。为了弥补这一差距，我们引入了DeepPHY，一个新颖的基准测试框架，旨在通过一系列具有挑战性的模拟环境，系统地评估VLM对基本物理原理的理解和推理能力。DeepPHY集成了不同难度级别的多个物理推理环境，并包含了细粒度的评估指标。我们的评估发现，即使是最先进的VLM也难以将描述性物理知识转化为精确的预测控制。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [2] [Latent Expression Generation for Referring Image Segmentation and Grounding](https://arxiv.org/abs/2508.05123)
> *用于指代图像分割和接地的潜在表达生成*

*Seonghoon Yu, Joonbeom Hong, Joonseok Lee, Jeany Son* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉定位, 图像分割, 潜在表达生成, 指代表达理解, 对比学习

**Comment:** 

> **TL;DR:** 提出了一种新的视觉定位框架，通过生成多个潜在表达来解决现有方法文本输入稀疏导致的目标识别问题，并在多个基准测试中超越了现有技术水平。

**AI_Comments:** 这项研究的创新点在于其提出的多潜在表达生成框架，有效弥补了单一文本描述与丰富视觉信息之间的鸿沟。通过引入主体分布器和视觉概念注入器，它能够捕获更细致和目标特定的视觉线索，这对于提升视觉定位任务的准确性至关重要。正裕度对比学习策略的引入也确保了潜在表达的多样性与文本语义的一致性。该方法在多个基准测试中超越SOTA表现，显示了其强大的实用性和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉定位任务（如指代图像分割和指代表达理解）依赖单一文本输入，这与丰富的视觉细节不匹配，导致在识别相似对象时出现错误识别，因为文本输入未能捕获视觉域中所有丰富信息。

**Method:** 我们提出了一种新的视觉定位框架，通过从单一文本输入生成多个潜在表达来利用互补的视觉细节。具体来说，引入了主体分布器和视觉概念注入器模块，将共享主体和独特属性概念嵌入到潜在表示中。此外，还提出了一种正裕度对比学习策略，以使所有潜在表达与原始文本对齐，同时保留细微变化。

**Result:** 我们的方法不仅在多个基准测试中优于最先进的指代图像分割（RIS）和指代表达理解（REC）方法，而且在广义指代表达分割（GRES）基准测试中也取得了出色的性能。

**Conclusion:** 通过生成多个潜在表达并整合互补的视觉细节，本研究成功解决了视觉定位任务中文本输入稀疏性的挑战，显著提升了目标识别的准确性和鲁棒性。

> **ai_Abstract:** 该论文提出了一种新的视觉定位框架，旨在解决现有方法在指代图像分割和理解任务中因文本输入稀疏而导致的目标误识别问题。通过引入主体分布器和视觉概念注入器模块，该框架能从单一文本输入生成多个包含互补视觉细节的潜在表达。此外，采用正裕度对比学习策略来对齐这些潜在表达与原始文本。实验证明，该方法在RIS、REC和GRES等多个基准测试中均超越了现有最先进技术。

> **摘要翻译:** 视觉定位任务，例如指代图像分割（RIS）和指代表达理解（REC），旨在根据给定的文本描述定位目标对象。图像中的目标对象可以通过多种方式描述，反映出颜色、位置等多种属性。然而，大多数现有方法依赖单一文本输入，这仅捕获了视觉领域中丰富信息的一小部分。视觉细节丰富与文本线索稀疏之间的这种不匹配可能导致相似对象的错误识别。为了解决这个问题，我们提出了一种新颖的视觉定位框架，通过整合原始描述中缺失的互补视觉细节，从单一文本输入生成多个潜在表达。具体来说，我们引入了主体分布器和视觉概念注入器模块，将共享主体和独特属性的概念嵌入到潜在表示中，从而捕获独特且针对目标的视觉线索。我们还提出了一种正裕度对比学习策略，以使所有潜在表达与原始文本对齐，同时保留细微变化。实验结果表明，我们的方法不仅在多个基准测试中优于最先进的RIS和REC方法，而且在广义指代表达分割（GRES）基准测试中也取得了出色的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [3] [ArXivBench: When You Should Avoid Using ChatGPT for Academic Writing](https://arxiv.org/abs/2504.10496)
> *ArXivBench：何时应避免使用 ChatGPT 进行学术写作*

*Ning Li, Jingran Zhang, Justin Cui* | **Category: cs.AI, cs.CL, cs.IR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 学术写作, arXiv, 基准测试, 引用

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在生成学术论文时常出现不准确的arXiv链接和引用，本研究引入ArXivBench基准来评估其可靠性，发现Claude-3.5-Sonnet表现最佳，并建议在学术写作中谨慎使用。

**AI_Comments:** 本文探讨了大型语言模型在学术写作中，尤其是在引用和归属方面的关键可靠性问题。ArXivBench的引入具有创新性，它提供了一个专门且标准化的基准来评估LLM在这一重要但常被忽视的方面的性能。研究结果揭示了当前LLM的显著局限性，特别是在需要事实准确性和正确引用的任务中，这与论文标题的警告相呼应。代码和数据集的公开进一步提升了研究的重要性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在推理和问答方面能力强大，但其生成事实不准确内容的倾向，特别是生成错误的arXiv链接或引用不存在的论文，严重损害了其正确归因研究贡献的能力。本研究旨在评估LLM在生成带有准确arXiv链接的相关研究论文方面的表现。

**Method:** 研究引入了ArXivBench，这是一个专门设计的基准，用于评估LLM在arXiv上的八个主要学科类别以及计算机科学的五个子领域中的表现。研究团队使用此基准评估了专有和开源的LLM。

**Result:** 评估发现LLMs经常生成不正确的arXiv链接或引用不存在的论文。不同学科之间的准确性差异显著，其中Claude-3.5-Sonnet在生成相关且准确的响应方面表现出显著优势。大多数LLM在人工智能领域的表现明显优于其他子领域。

**Conclusion:** ArXivBench为评估LLM在科学背景下的可靠性提供了一个标准化工具，有助于促进在研究环境中更可靠的学术使用。鉴于LLM在引用归属方面的不足，在学术写作中应避免或谨慎使用，尤其是ChatGPT。

> **ai_Abstract:** 本研究引入了ArXivBench，一个旨在评估大型语言模型（LLMs）在学术写作中生成准确arXiv链接和引用的基准。研究发现，LLMs普遍存在生成错误链接或引用不存在论文的问题，这严重影响了其正确归因研究贡献的能力。评估结果显示，Claude-3.5-Sonnet在准确性和相关性方面表现出显著优势，且LLMs在人工智能领域的表现优于其他子领域。ArXivBench旨在提供一个标准化工具，以提高LLM在科学背景下使用的可靠性。

> **摘要翻译:** 大型语言模型（LLMs）在推理和问答方面展现出强大的能力，但其生成事实不准确内容的倾向仍然是一个严峻的挑战。本研究评估了专有和开源LLM在生成具有准确arXiv链接的相关研究论文方面的表现。我们的评估揭示了严重的学术风险：LLM经常生成不正确的arXiv链接或引用不存在的论文，这从根本上损害了它们将研究贡献正确归因于实际作者的能力。我们引入了arXivBench，这是一个专门用于评估LLM在arXiv上八个主要学科类别以及计算机科学（其中最受欢迎的类别之一）的五个子领域中的表现的基准。我们的研究结果显示，不同学科之间的准确性差异令人担忧，其中Claude-3.5-Sonnet在生成相关和准确的响应方面表现出显著优势。值得注意的是，大多数LLM在人工智能领域的表现明显优于其他子领域。该基准为评估LLM在科学背景下的可靠性提供了一个标准化工具，从而促进了在研究环境中更可靠的学术使用。我们的代码和数据集可在 https://github.com/liningresearch/arXivBench 和 https://huggingface.co/datasets/arXivBenchLLM/arXivBench 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [8] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
> *大型语言模型将有机合成从反应预测转向自动化*

*Kartar Kumar Lohana Tharwani, Rajesh Kumar, Sumita, Numan Ahmed, Yong Tang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 有机合成, 反应预测, 自动化, 人工智能化学

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）正在通过提供合成路线、预测反应结果和指导自动化实验来彻底改变有机合成，本综述探讨了LLMs如何与图形神经网络、量子计算和实时光谱学结合以加速发现，并讨论了其局限性及未来发展方向。

**AI_Comments:** 这篇综述突出了大型语言模型在有机合成领域的巨大潜力，尤其是在加速发现周期和实现自动化方面的创新。它不仅展示了LLMs与现有技术的结合如何推动化学研究，还诚实地指出了其面临的挑战，如数据偏见和可解释性问题。同时，文章提出的社区倡议对于确保LLMs的负责任和包容性发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）正在开始重塑化学家在有机合成中规划和运行反应的方式，本论文旨在回顾LLMs从推测性工具转变为实用实验室伙伴的里程碑，并探讨它们如何促进更快、更环保、数据驱动的化学研究。

**Method:** 本文通过综述LLMs在有机合成中的应用和发展，展示了LLMs如何与图神经网络、量子计算和实时光谱学结合，以缩短发现周期并支持更环保、数据驱动的化学。同时，讨论了LLMs的局限性并提出了社区倡议。

**Result:** 研究表明，将大型语言模型与图神经网络、量子计算和实时光谱学结合，可以显著缩短发现周期，并支持更绿色、数据驱动的化学研究。LLMs能够提出合成路线、预测反应结果，甚至指导机器人执行实验。

**Conclusion:** 这些进展为人工智能和自动化驱动的快速、可靠和包容的分子创新指明了道路。

> **ai_Abstract:** 本文综述了大型语言模型（LLMs）在有机合成领域的变革性作用。LLMs通过提供合成路线、预测反应结果和实现自动化实验，正成为化学研究的实用工具。文章探讨了LLMs如何与图神经网络、量子计算和实时光谱学结合，以加速化学发现并支持绿色化学。同时，也讨论了偏见数据、不透明推理等局限性，并提出了开放基准、联邦学习和可解释接口等社区倡议，以促进LLMs在分子创新中的民主化和负责任应用。

> **摘要翻译:** 大型语言模型（LLMs）正开始重塑化学家在有机合成中规划和运行反应的方式。这些经过数百万次报告转化训练的基于文本的模型，能够提出合成路线、预测反应结果，甚至在无人监督的情况下指导机器人执行实验。本文回顾了将LLMs从推测性工具转变为实用实验室伙伴的里程碑。我们展示了LLMs如何与图神经网络、量子计算和实时光谱学结合，以缩短发现周期并支持更环保、数据驱动的化学。我们讨论了其局限性，包括偏见数据集、不透明的推理以及需要防止意外危害的安全门。最后，我们概述了旨在普及访问权限同时保持人类牢牢掌控的社区倡议——开放基准、联邦学习和可解释接口。这些进步为人工智能和自动化驱动的快速、可靠和包容的分子创新指明了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [9] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
> *注意力盆地：为什么上下文位置在大型语言模型中很重要*

*Zihao Yi, Delong Zeng, Zhenqing Ling, Haohao Luo, Zhe Xu, Wei Liu, Jian Luan, Wanxia Cao, Ying Shen* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 上下文位置, 注意力盆地, 信息重排, AttnRank

**Comment:** 

> **TL;DR:** 大语言模型性能对信息上下文位置敏感，表现为“注意力盆地”现象。本文提出AttnRank框架，通过重排关键信息到高注意力位置，显著提升模型性能。

**AI_Comments:** 该论文通过发现并命名“注意力盆地”这一现象，深入揭示了LLM对上下文位置敏感的底层机制，具有重要的理论意义。提出的AttnRank框架是一种创新且实用的解决方案，其模型无关、无需训练和即插即用的特性使其具有广泛的应用前景和较高的工程价值，能够有效提升现有LLM在多项任务上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的性能对输入信息在上下文中的位置非常敏感，为了探究这种位置偏差背后的机制，并解决由此带来的性能下降问题。

**Method:** 通过大量实验揭示了“注意力盆地”现象，即模型倾向于关注序列开头和结尾的信息而忽略中间部分。基于此，提出了Attention-Driven Reranking (AttnRank) 框架，该框架分为两阶段：(i) 使用小型校准集估计模型的内在位置注意力偏好；(ii) 重排检索到的文档或少样本示例，使最显著的内容与高注意力位置对齐。AttnRank是一种模型无关、无需训练、即插即用的方法。

**Result:** AttnRank在多跳问答和少样本上下文学习任务上，对10种不同架构和规模的大型语言模型都实现了显著的性能提升，且无需修改模型参数或训练过程。

**Conclusion:** 上下文位置对大型语言模型的性能至关重要，模型存在“注意力盆地”现象。通过将关键信息放置在模型注意力集中的位置，可以显著提升模型性能。AttnRank是一种有效且高效的解决方案。

> **ai_Abstract:** 本研究揭示了大型语言模型中存在的“注意力盆地”现象，即模型对输入序列开头和结尾的信息关注度更高，而对中间部分关注度较低，这种位置偏好显著影响模型性能。为解决此问题，论文提出了Attention-Driven Reranking (AttnRank) 框架。AttnRank通过校准模型内在的位置注意力偏好，并将关键信息重排到高注意力位置，从而提升模型性能。该方法模型无关、无需训练且计算开销小，在多跳问答和少样本学习任务上对多种LLM展现出显著效果。

> **摘要翻译:** 大型语言模型（LLMs）的性能对输入信息在上下文中的位置显著敏感。为了探究这种位置偏差背后的机制，我们的大量实验揭示了一个我们称之为“注意力盆地”的一致现象：当呈现一系列结构化项目（例如，检索到的文档或少样本示例）时，模型系统地将更高的注意力分配给序列开头和结尾的项目，而忽略中间的项目。至关重要的是，我们的分析进一步表明，将更高的注意力分配给关键信息是提升模型性能的关键。基于这些见解，我们引入了注意力驱动重排（AttnRank），这是一个两阶段框架，它（i）使用一个小型校准集估计模型的内在位置注意力偏好，以及（ii）重新排序检索到的文档或少样本示例，以使最显著的内容与这些高注意力位置对齐。AttnRank是一种模型无关、无需训练、即插即用的方法，计算开销极小。在多跳问答和少样本上下文学习任务上的实验表明，AttnRank在10个不同架构和规模的大型语言模型中都取得了显著的改进，而无需修改模型参数或训练过程。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [10] [JEPA4Rec: Learning Effective Language Representations for Sequential Recommendation via Joint Embedding Predictive Architecture](https://arxiv.org/abs/2504.10512)
> *JEPA4Rec：通过联合嵌入预测架构学习序列推荐的有效语言表示*

*Minh-Anh Nguyen, Dung D.Le* | **Category: cs.AI, cs.CL, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 序列推荐, 语言表示学习, 联合嵌入预测架构, 数据稀疏性, 自监督学习

**Comment:** 

> **TL;DR:** JEPA4Rec是一个结合联合嵌入预测架构和语言模型的框架，用于序列推荐，解决了数据稀疏性和对常识用户偏好理解有限的问题，并在六个真实世界数据集上表现优于现有SOTA方法。

**AI_Comments:** JEPA4Rec的创新之处在于其结合了联合嵌入预测架构（JEPA）与语言模型，并将其应用于序列推荐，有效解决了数据稀疏性和对常识理解的不足。其将项目信息扁平化为文本句子并采用定制Transformer编码器的做法，以及两阶段自监督训练策略，使其能够学习到更鲁棒和可迁移的表示。该方法在低资源和跨领域场景下的优越表现，凸显了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语言表示学习方法在序列推荐中面临数据稀疏性和对常识用户偏好理解有限的问题。

**Method:** JEPA4Rec将项目表示为文本句子，通过扁平化标题、类别和其他属性等描述性信息。它使用一个带有修改嵌入层的双向Transformer编码器来编码这些句子，并应用掩码预测未掩码句子的表示。该方法采用两阶段训练策略，结合自监督学习损失，以提高推荐性能和语言理解能力。

**Result:** JEPA4Rec在六个真实世界数据集上始终优于最先进的方法，特别是在跨域、跨平台和低资源场景中表现出色。

**Conclusion:** JEPA4Rec通过结合联合嵌入预测架构和语言模型，成功学习到有效且可迁移的语言表示，显著改善了序列推荐性能，并减少了对大规模预训练数据的依赖，尤其在资源受限和复杂场景下表现优异。

> **ai_Abstract:** JEPA4Rec是一种新颖的序列推荐框架，旨在克服现有语言表示学习方法在数据稀疏性和常识理解方面的局限性。它结合了联合嵌入预测架构与项目文本描述的语言建模，将项目表示为扁平化的文本句子，并利用修改后的Transformer编码器和掩码预测来学习可泛化的项目嵌入。通过两阶段自监督训练策略，JEPA4Rec能够捕获语义丰富且可迁移的表示，从而在六个真实世界数据集上，尤其是在跨域、跨平台和低资源场景中，持续超越最先进的推荐方法，同时减少对大规模预训练数据的依赖。

> **摘要翻译:** 语言表示学习因其学习可泛化表示的能力而成为序列推荐的一种有前景的方法。然而，尽管有其优点，这种方法仍然面临数据稀疏性和对常识用户偏好理解有限的问题。为了解决这些局限性，我们提出了 JEPA4Rec，一个将联合嵌入预测架构与项目文本描述的语言建模相结合的框架。JEPA4Rec 捕获语义丰富且可迁移的表示，从而提高推荐性能并减少对大规模预训练数据的依赖。具体来说，JEPA4Rec 通过扁平化标题、类别和其他属性等描述性信息，将项目表示为文本句子。为了编码这些句子，我们采用了一个双向 Transformer 编码器，其嵌入层经过修改，专门用于捕获推荐数据集中的项目信息。我们对文本句子应用掩码，并使用它们来预测未掩码句子的表示，帮助模型学习可泛化的项目嵌入。为了进一步提高推荐性能和语言理解，我们采用了结合自监督学习损失的两阶段训练策略。在六个真实世界数据集上的实验表明，JEPA4Rec 始终优于最先进的方法，特别是在跨域、跨平台和低资源场景中。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [15] [Whose Truth? Pluralistic Geo-Alignment for (Agentic) AI](https://arxiv.org/abs/2508.05432)
> *谁的真相？（代理）AI的多元地理对齐*

*Krzysztof Janowicz, Zilong Liu, Gengchen Mai, Zhangyu Wang, Ivan Majic, Alexandra Fortacz, Grant McKenzie, Song Gao* | **Category: cs.AI, cs.CY** | **Updated: 2025-08-07**

**Keywords:** 地理对齐, AI对齐, 地理变异性, 文化规范, 代理AI

**Comment:** 

> **TL;DR:** 该论文讨论了由于各地文化和法律规范的差异，AI对齐需要考虑地理敏感性，并放弃“一刀切”的方法。

**AI_Comments:** 该论文强调了AI对齐中一个关键且常被忽视的方面：地理和文化的可变性。这对于AI在全球范围内的部署至关重要。呼吁“时空感知对齐”是创新的，解决了当前“一刀切”方法的一个显著局限性。它侧重于回顾问题并提出未来工作方向，而不是提供具体的解决方案，这可能被视为立即应用的一个限制，但它为重要的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** AI对齐需要考虑真实性、适当性和合法性在地理上的差异。当前的对齐措施可能会产生与统计现实不符的结果，并且某些AI输出具有地理敏感性，而目前“一刀切”的方法在AI大规模自动化传播知识的背景下存在问题。

**Method:** 本文回顾了关键的地理研究问题，提出了未来的工作方向，并概述了评估对齐敏感性的方法。

**Result:** Not mentioned in abstract

**Conclusion:** 论文的结论是，随着代理AI的临近，迫切需要时空感知的对齐，而不是“一刀切”的方法。

> **ai_Abstract:** AI对齐面临地理变异性挑战，因文化、政治和法律差异，各地对“真相”的定义不同。现有对齐方法可能导致结果偏离现实，且部分AI输出具有地理敏感性。鉴于AI大规模自动化传播知识，论文强调需摆脱“一刀切”的对齐方式，转向时空感知对齐。文中回顾了地理研究问题，并提出了未来工作方向和对齐敏感性评估方法。

> **摘要翻译:** AI（超级）对齐描述了确保（未来）AI系统行为符合社会规范和目标的挑战。尽管相关文献正在快速发展并解决偏见和不平等问题，但对齐的地理变异性仍未得到充分探索。简而言之，由于文化规范、政治现实和立法，在不同地区，什么是适当的、真实的或合法的可能存在很大差异。应用于AI/ML工作流的对齐措施有时会产生与统计现实相悖的结果，例如文本到图像模型在公司领导层中描绘出平衡的性别比例，尽管存在现有不平衡。关键的是，一些模型输出是全球可接受的，而另一些，例如关于克什米尔的问题，则取决于了解用户的位置和上下文。这种地理敏感性并非新鲜事物。例如，谷歌地图根据用户位置以不同方式呈现克什米尔的边界。新鲜的是，AI现在以前所未有的规模和自动化程度来传递知识、表达观点，并向全球数百万用户呈现地理现实，而对于如何管理上下文却鲜有透明度。随着我们接近代理AI，对时空感知对齐的需求，而不是“一刀切”的方法，变得日益紧迫。本文回顾了关键的地理研究问题，提出了未来的工作方向，并概述了评估对齐敏感性的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [16] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
> *评估医学伦理从知识到实践*

*Chang Hong, Minghao Wu, Qingying Xiao, Yuchi Wang, Xiang Wan, Guangjun Yu, Benyou Wang, Yan Hu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 医学伦理, 大型语言模型, 基准测试, 原则主义, PrinciplismQA

**Comment:** 

> **TL;DR:** 引入PrinciplismQA基准，评估LLM在医疗领域的伦理推理能力，发现模型在伦理知识与实践应用之间存在显著差距。

**AI_Comments:** 该论文的创新之处在于提出了一个专门用于评估大型语言模型在医疗伦理实践应用能力的基准PrinciplismQA，填补了现有评估体系的空白。其重要性在于，在AI日益融入医疗的背景下，确保AI的伦理行为至关重要。通过揭示模型在伦理知识与实践之间的差距，为未来医疗AI的研发指明了方向，有助于开发出更安全、更负责任的医疗AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）融入医疗保健领域需要对其伦理推理能力进行严格评估，而现有基准往往忽视了这一点。

**Method:** 本研究引入了PrinciplismQA，一个包含3,648个问题的综合基准，旨在系统评估LLMs与核心医学伦理的契合度。该基准以“原则主义”为基础，包含高质量数据集，其中多项选择题来自权威教科书，开放式问题来自权威医学伦理案例研究文献，所有问题均经过医学专家验证。

**Result:** 实验结果显示，模型在伦理知识与其在实际场景中动态应用伦理原则的能力之间存在显著差距。大多数LLMs在处理“受益”原则的困境时表现不佳，常常过分强调其他原则。前沿的闭源模型凭借强大的通用能力目前在该基准上领先。值得注意的是，医学领域的微调可以提升模型的整体伦理能力。

**Conclusion:** PrinciplismQA提供了一个可扩展的框架来诊断LLMs在医学伦理方面的具体弱点，为开发更平衡、更负责任的医疗AI铺平了道路。

> **ai_Abstract:** 本研究引入了PrinciplismQA，一个基于“原则主义”的综合基准，包含3,648个经医学专家验证的问题，旨在评估大型语言模型在医疗伦理方面的推理能力。研究发现，LLMs在伦理知识与实际应用之间存在显著差距，尤其是在处理“受益”原则时表现不足。尽管前沿模型表现较好，且医学领域微调能提升伦理能力，但仍需进一步提升模型与医学伦理知识的对齐。PrinciplismQA为诊断这些伦理弱点并促进负责任的医疗AI发展提供了框架。

> **摘要翻译:** 大型语言模型整合到医疗保健领域需要对其伦理推理能力进行严格评估，而这是当前基准经常忽视的一个领域。我们引入了PrinciplismQA，一个包含3,648个问题的综合基准，旨在系统评估LLMs与核心医学伦理的契合度。我们的基准以“原则主义”为基础，具有高质量的数据集。这包括从权威教科书策划的多项选择题和从权威医学伦理案例研究文献中获取的开放式问题，所有这些都经过医学专家的验证。我们的实验揭示了模型伦理知识与其实际应用之间存在显著差距，特别是在将伦理原则动态应用于现实场景时。大多数LLMs在处理有关“受益”原则的困境时表现不佳，常常过分强调其他原则。前沿的闭源模型，凭借强大的通用能力，目前在该基准上领先。值得注意的是，医学领域的微调可以增强模型的整体伦理能力，但进一步的进展需要更好地与医学伦理知识对齐。PrinciplismQA提供了一个可扩展的框架来诊断这些特定的伦理弱点，为更平衡和负责任的医疗AI铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [17] [Probabilistic Stability Guarantees for Feature Attributions](https://arxiv.org/abs/2504.13787)
> *特征归因的概率稳定性保证*

*Helen Jin, Anton Xue, Weiqiu You, Surbhi Goel, Eric Wong* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 特征归因, 稳定性保证, 软稳定性, SCA算法, 模型可解释性

**Comment:** 

> **TL;DR:** 本文引入“软稳定性”概念并提出一种新的模型无关、样本高效的算法SCA，旨在为特征归因提供非平凡且可解释的稳定性保证，并指出适度平滑能更好地平衡准确性与稳定性。

**AI_Comments:** 本文创新性地引入了“软稳定性”概念和SCA算法，解决了现有稳定性认证方法过度保守和对平滑分类器依赖的问题。通过实现模型无关性和样本高效性，SCA显著提升了特征归因稳定性评估的实用性。此外，对平滑与稳定性之间权衡的深入分析，为未来解释性AI的研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有特征归因的稳定性认证方法依赖于过度平滑的分类器，且通常产生保守的保证，限制了其有效性和实用性。

**Method:** 引入“软稳定性”概念，并提出一种简单、模型无关、样本高效的稳定性认证算法（SCA）。此外，利用布尔函数分析推导了平滑下稳定性的一种新特征，以解释其行为。

**Result:** SCA能为任何归因方法提供非平凡且可解释的稳定性保证。研究表明，轻度平滑在准确性和稳定性之间实现了更优的权衡，避免了传统方法中的激进妥协。在视觉和语言任务上的评估证明了软稳定性在衡量解释方法鲁棒性方面的有效性。

**Conclusion:** 软稳定性和SCA算法为评估特征归因的鲁棒性提供了一种有效且不那么保守的方法，并且适度平滑有利于平衡模型性能与解释稳定性。

> **ai_Abstract:** 本文针对现有特征归因稳定性认证方法过度依赖平滑分类器且保证保守的问题，提出了“软稳定性”概念和一种名为SCA的模型无关、样本高效的认证算法。该算法能为任何归因方法提供非平凡且可解释的稳定性保证。研究还发现，适度平滑能更好地平衡模型准确性与解释稳定性，并通过布尔函数分析解释了这一现象。SCA在视觉和语言任务上验证了其有效性。

> **摘要翻译:** 稳定性保证已成为评估特征归因的一种原则性方法，但现有的认证方法依赖于高度平滑的分类器，并且通常产生保守的保证。为了解决这些限制，我们引入了软稳定性并提出了一种简单、模型无关、样本高效的稳定性认证算法（SCA），该算法能为任何归因方法提供非平凡且可解释的保证。此外，我们表明，轻度平滑在准确性和稳定性之间实现了更有利的权衡，避免了先前认证方法中激进的妥协。为了解释这种行为，我们使用布尔函数分析推导出了平滑下稳定性的一种新特征。我们在视觉和语言任务上评估了SCA，并证明了软稳定性在衡量解释方法鲁棒性方面的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [22] [Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?](https://arxiv.org/abs/2508.05464)
> *Bench-2-CoP：我们能信任基准测试来符合欧盟人工智能法规吗？*

*Matteo Prandi, Vincenzo Suriani, Federico Pierucci, Marcello Galisai, Daniele Nardi, Piercosma Bisconti* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** AI合规性, 基准测试, 欧盟人工智能法案, 系统性风险, 评估差距

**Comment:** 

> **TL;DR:** 当前的人工智能基准测试未能充分覆盖欧盟人工智能法案所要求的系统性风险，特别是关键的“失控”能力，导致评估存在重大差距。

**AI_Comments:** 该论文通过首次对AI基准测试与监管要求之间的差距进行定量分析，展现了其创新性。其重要性在于揭示了当前AI评估中存在的关键盲点，特别是关于系统性风险和失控场景的评估不足，这对于先进AI的安全和道德部署至关重要。它为政策制定者和开发人员提供了可操作的见解。

<details>
  <summary>Details</summary>

**Motivation:** 通用人工智能（GPAI）模型的快速发展以及欧盟人工智能法案及其相关行为准则（CoP）等新兴法规的出台，使得建立健全的评估框架变得必要。然而，当前的人工智能评估实践严重依赖现有基准，但这些工具并非旨在衡量新监管环境所关注的系统性风险。本研究旨在解决量化这种“基准-法规差距”的迫切需求。

**Method:** 我们引入了Bench-2-CoP，这是一个新颖的、系统的框架，它使用经过验证的“LLM即法官”分析方法，将194,955个来自广泛使用的基准测试问题，与欧盟人工智能法案的模型能力和倾向分类进行映射。

**Result:** 研究结果揭示了严重的错位：评估生态系统绝大多数关注狭窄的行为倾向，例如“幻觉倾向”（占语料库的53.7%）和“歧视性偏见”（占28.9%），而关键的功能能力却被危险地忽视。尤其值得注意的是，与失控情景（包括规避人类监督、自我复制和自主AI开发）相关的核心能力在整个基准语料库中覆盖率为零。这导致了对“失控”（0.4%覆盖率）和“网络攻击”（0.8%覆盖率）等系统性风险的评估几乎完全缺失。

**Conclusion:** 本研究首次对这一差距进行了全面、定量的分析，为政策制定者完善行为准则以及开发人员构建下一代评估工具提供了关键见解，最终促进更安全、更符合法规的人工智能。

> **ai_Abstract:** 本论文介绍了Bench-2-CoP，这是一个新颖的框架，旨在定量评估现有AI评估基准与欧盟人工智能法案要求之间的“基准-法规差距”。通过分析194,955个基准测试问题，研究揭示了显著的错位，表明当前基准测试在很大程度上忽视了关键的系统性风险和失控能力，而仅关注狭窄的行为倾向。这项研究强调了开发新评估工具和完善政策以确保AI更安全、更合规的迫切需求。

> **摘要翻译:** 通用人工智能（GPAI）模型的快速发展使得建立健全的评估框架变得必要，尤其是在欧盟人工智能法案及其相关行为准则（CoP）等新兴法规出台的背景下。当前的人工智能评估实践严重依赖现有基准，但这些工具并非旨在衡量新监管环境所关注的系统性风险。本研究旨在解决量化这种“基准-法规差距”的迫切需求。我们引入了Bench-2-CoP，这是一个新颖的、系统的框架，它使用经过验证的“LLM即法官”分析方法，将194,955个来自广泛使用的基准测试问题，与欧盟人工智能法案的模型能力和倾向分类进行映射。我们的研究结果揭示了严重的错位：评估生态系统绝大多数关注狭窄的行为倾向，例如“幻觉倾向”（占语料库的53.7%）和“歧视性偏见”（占28.9%），而关键的功能能力却被危险地忽视。尤其值得注意的是，与失控情景相关的核心能力，包括规避人类监督、自我复制和自主AI开发，在整个基准语料库中覆盖率为零。这导致了对“失控”（0.4%覆盖率）和“网络攻击”（0.8%覆盖率）等系统性风险的评估几乎完全缺失。本研究首次对这一差距进行了全面、定量的分析，为政策制定者完善行为准则以及开发人员构建下一代评估工具提供了关键见解，最终促进更安全、更符合法规的人工智能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [23] [FedGIN: Federated Learning with Dynamic Global Intensity Non-linear Augmentation for Organ Segmentation using Multi-modal Images](https://arxiv.org/abs/2508.05137)
> *FedGIN：采用动态全局强度非线性增强的联邦学习，用于多模态图像的器官分割*

*Sachin Dudda Nagaraju, Ashkan Moradi, Bendik Skarre Abrahamsen, Mattijs Elschot* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 联邦学习, 多模态图像分割, 全局强度非线性增强, 医疗图像, 隐私保护

**Comment:** 

> **TL;DR:** FedGIN是一个联邦学习框架，通过动态全局强度非线性增强，实现了在不共享原始数据的情况下进行多模态器官分割，并在有限数据和完整数据场景下均表现出色。

**AI_Comments:** FedGIN的创新之处在于将联邦学习与动态全局强度非线性增强相结合，有效解决了医疗图像分割中数据隐私和模态异构性问题。其在有限数据和完整数据场景下的出色表现，尤其是在跨模态泛化方面的提升，使其在实际临床应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 医疗图像分割对AI辅助诊断至关重要，但面临数据稀缺、模态间域偏移及隐私限制等挑战，需要开发统一模型以泛化到多种模态。

**Method:** 本文提出了FedGIN，一个联邦学习（FL）框架，用于在不共享原始患者数据的情况下进行多模态器官分割。该方法整合了一个轻量级的全局强度非线性（GIN）增强模块，用于在局部训练期间协调模态特定的强度分布。

**Result:** 在有限数据场景中，FedGIN在MRI测试案例上的3D Dice分数比没有GIN的FL提高了12%至18%，并始终优于局部基线。在完整数据集场景中，FedGIN表现出接近中心化的性能，比仅MRI基线提高了30%的Dice分数，比仅CT基线提高了10%，突出了其在隐私限制下的强大跨模态泛化能力。

**Conclusion:** FedGIN在不共享原始数据的情况下，通过结合动态全局强度非线性增强，有效地解决了多模态器官分割中的隐私和数据异构性问题，并在多种数据场景下展现出卓越的性能和跨模态泛化能力。

> **ai_Abstract:** 本文提出了FedGIN，一个联邦学习框架，用于在不共享原始患者数据的情况下进行多模态器官分割。该框架集成了轻量级的全局强度非线性（GIN）增强模块，以协调模态间强度分布。实验结果表明，FedGIN在有限数据和完整数据场景下均显著优于基线模型，并在隐私保护下实现了强大的跨模态泛化能力。

> **摘要翻译:** 医疗图像分割在AI辅助诊断、手术规划和治疗监测中发挥着关键作用。准确和鲁棒的分割模型对于在不同成像模态下实现可靠的、数据驱动的临床决策至关重要。考虑到图像特征在不同模态之间的固有变异性，开发一个能够有效泛化到多种模态的统一模型将非常有益。这个模型可以简化临床工作流程，减少对特定模态训练的需求。然而，实际部署面临主要挑战，包括数据稀缺、模态之间（例如CT与MRI）的域偏移以及阻止数据共享的隐私限制。为了解决这些问题，我们提出了FedGIN，一个联邦学习（FL）框架，它能够在不共享原始患者数据的情况下进行多模态器官分割。我们的方法整合了一个轻量级的全局强度非线性（GIN）增强模块，用于在局部训练期间协调模态特定的强度分布。我们使用两种类型的数据集评估了FedGIN：一个插补数据集和一个完整数据集。在有限数据集场景中，模型最初仅使用MRI数据进行训练，并添加CT数据以评估其性能改进。在完整数据集场景中，MRI和CT数据都被所有客户端充分用于训练。在有限数据场景中，与没有GIN的FL相比，FedGIN在MRI测试案例上的3D Dice分数提高了12%至18%，并始终优于局部基线。在完整数据集场景中，FedGIN表现出接近中心化的性能，比仅MRI基线提高了30%的Dice分数，比仅CT基线提高了10%，突出了其在隐私限制下的强大跨模态泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [24] [Explainable Recommendation with Simulated Human Feedback](https://arxiv.org/abs/2504.14147)
> *基于模拟人类反馈的可解释推荐*

*Jiakai Tang, Jingsen Zhang, Zihang Tian, Xueyang Feng, Lei Wang, Xu Chen* | **Category: cs.AI, cs.CL, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 可解释推荐, 人类反馈, 大型语言模型, 帕累托优化, 离策略优化

**Comment:** 

> **TL;DR:** 现有可解释推荐方法因缺乏有效反馈而受限，本文提出一种新颖的、利用大型语言模型模拟人类反馈并结合多目标优化的框架，有效提升了可解释推荐的性能。

**AI_Comments:** 该研究的创新之处在于其巧妙地利用大型语言模型作为人类模拟器，生成类人反馈信号以优化可解释推荐系统，从而在不依赖昂贵人工标注的情况下实现了以人为中心的解释质量提升。帕累托优化在处理解释质量多目标冲突方面的应用也极具洞察力。这为可解释人工智能领域提供了一个新颖且高效的解决方案，对于提升推荐系统的实用性和用户信任度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有可解释推荐方法由于在稀疏交互数据中依赖传统的监督学习范式，未能为生成的解释提供有效的反馈信号，从而无法有效判断解释的优劣。

**Method:** 本文提出了一种新颖的、以类人反馈驱动的优化框架。该框架采用动态交互优化机制，利用大型语言模型（LLMs）作为人类模拟器来预测类人反馈，以指导学习过程。为使LLMs深入理解任务本质并满足个性化需求，引入了人工诱导的定制奖励评分方法。此外，针对解释质量不同视角间的潜在冲突，引入了帕累托优化，将多视角质量提升任务转化为多目标优化问题。最后，设计了离策略优化流程，结合回放缓冲区并解决数据分布偏差，以提高数据利用率和模型泛化能力。

**Result:** 在四个数据集上的大量实验证明了该方法的优越性。

**Conclusion:** 本文提出的框架通过利用大型语言模型模拟人类反馈，并结合多目标帕累托优化和高效的离策略训练，有效解决了现有可解释推荐方法在反馈信号和解释质量优化方面的局限性，显著提升了可解释推荐的性能。

> **ai_Abstract:** 本文针对现有可解释推荐方法在稀疏交互数据中缺乏有效反馈信号的问题，提出了一种新颖的、基于模拟人类反馈的优化框架。该框架利用大型语言模型（LLMs）作为人类模拟器来预测类人反馈，并通过引入人工诱导的定制奖励评分方法来增强LLMs的理解和推理能力。为处理解释质量的多视角冲突，模型采用了帕累托优化。此外，还设计了离策略优化流程以提高数据利用率和模型泛化能力。在四个数据集上的广泛实验验证了该方法的优越性。

> **摘要翻译:** 可解释推荐的最新进展通过阐明决策理由，极大地提升了用户体验。然而，现有方法由于在稀疏交互数据中依赖传统的监督学习范式，实际上未能为潜在的更好或更差的生成解释提供有效的反馈信号。为解决这些问题，我们提出了一种新颖的、由类人反馈驱动的优化框架。该框架采用动态交互优化机制，无需承担高昂的人工成本即可实现以人为中心的可解释性要求。具体而言，我们提出利用大型语言模型（LLMs）作为人类模拟器来预测类人反馈，以指导学习过程。为了使LLMs深入理解任务本质并满足用户多样化的个性化需求，我们引入了一种人工诱导的定制奖励评分方法，这有助于激发LLMs的语言理解和逻辑推理能力。此外，考虑到解释质量不同视角之间的潜在冲突，我们引入了原则性的帕累托优化，将多视角质量提升任务转化为多目标优化问题，以提高解释性能。最后，为实现高效的模型训练，我们设计了一个离策略优化流程。通过结合回放缓冲区并解决数据分布偏差，我们可以有效地提高数据利用率并增强模型泛化能力。在四个数据集上的大量实验证明了我们方法的优越性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [29] [Can Large Language Models Generate Effective Datasets for Emotion Recognition in Conversations?](https://arxiv.org/abs/2508.05474)
> *大型语言模型能否为对话情感识别生成有效数据集？*

*Burak Can Kaplan, Hugo Cesar De Castro Carneiro, Stefan Wermter* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 对话情感识别, 大型语言模型, 数据生成, 数据增强, 情感分类

**Comment:** 

> **TL;DR:** 本研究利用小型LLM生成了新的对话情感识别数据集，有效解决了数据稀缺和偏差问题，并显著提升了现有基准模型的性能和鲁棒性。

**AI_Comments:** 本论文的创新点在于探索并验证了使用小型、资源高效的LLM来生成高质量、多样化的对话情感识别数据集，有效缓解了该领域数据稀缺和偏见的问题。这为未来情感识别任务的数据增强提供了一个经济且高效的新途径，对推动ERC技术发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 对话情感识别（ERC）数据稀缺，现有数据集存在来源偏见和软标签主观性等挑战。尽管大型语言模型（LLMs）在情感任务中表现出色，但其训练成本高昂，且在ERC任务（特别是数据生成）中的应用有限。

**Method:** 为解决ERC数据挑战，本研究使用一个小型、资源高效且通用的大型语言模型来合成具有多样属性的ERC数据集。共生成了六个新颖的数据集，旨在补充和增强三个最广泛使用的ERC基准。研究评估了这些数据集在以下方面的效用：1) 补充现有数据集用于ERC分类，2) 分析ERC中标签不平衡的影响。

**Result:** 实验结果表明，在生成数据集上训练的ERC分类器模型表现出强大的鲁棒性，并在现有ERC基准上持续实现统计学上显著的性能改进。

**Conclusion:** 小型、资源高效的LLM能够有效地生成高质量的对话情感识别数据集，显著提升现有ERC模型的性能和鲁棒性，从而有效缓解ERC数据稀缺和质量问题。

> **ai_Abstract:** 本研究旨在解决对话情感识别（ERC）领域数据稀缺和现有数据集质量问题。作者提出利用一个小型、资源高效的大型语言模型（LLM）来合成多样化的ERC数据集，以补充和增强主流基准。研究生成了六个新数据集，并评估了它们在ERC分类和标签不平衡分析中的作用。实验证明，在这些生成数据集上训练的ERC分类器模型表现出更强的鲁棒性，并在现有基准上实现了显著的性能提升，验证了LLM生成ERC数据集的有效性。

> **摘要翻译:** 对话情感识别（ERC）专注于识别互动中的情感变化，代表着推进机器智能的重要一步。然而，ERC数据仍然稀缺，现有数据集由于其高度偏颇的来源和软标签固有的主观性而面临诸多挑战。尽管大型语言模型（LLMs）在许多情感任务中展现了其质量，但它们通常训练成本高昂，并且其在ERC任务中的应用——特别是在数据生成方面——仍然有限。为了解决这些挑战，我们采用了一个小型、资源高效且通用的大型语言模型来合成具有多样属性的ERC数据集，补充了三个最广泛使用的ERC基准。我们生成了六个新颖的数据集，其中两个旨在增强每个基准。我们评估了这些数据集的效用，以（1）补充现有数据集用于ERC分类，以及（2）分析ERC中标签不平衡的影响。我们的实验结果表明，在生成数据集上训练的ERC分类器模型表现出强大的鲁棒性，并在现有ERC基准上持续实现统计学上显著的性能改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [30] [Chemist Eye: A Visual Language Model-Powered System for Safety Monitoring and Robot Decision-Making in Self-Driving Laboratories](https://arxiv.org/abs/2508.05148)
> *Chemist Eye：一种基于视觉语言模型的自主实验室安全监控和机器人决策系统*

*Francisco Munguia-Galeano, Zhengxue Zhou, Satheeshkumar Veeramani, Hatem Fakhruldeen, Louis Longley, Rob Clowes, Andrew I. Cooper* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 自主实验室, 安全监控, 视觉语言模型, 机器人决策, 事故预防

**Comment:** 

> **TL;DR:** Chemist Eye是一个基于视觉语言模型的系统，用于自主实验室的安全监控和机器人决策，能检测安全隐患并引导机器人规避风险。

**AI_Comments:** Chemist Eye的创新之处在于其将视觉语言模型应用于自主实验室的安全监控和机器人决策，实现了对复杂安全场景的实时感知和智能响应。其分布式架构和多传感器融合提升了态势感知能力，并能直接指导机器人行为，这对于提升SDLs的安全性具有重要意义。该系统在实际测试中表现出的高准确率也验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 自主实验室（SDLs）中机器人和自动化引入了额外的安全复杂性，除了传统实验室已有的风险，如个人防护设备（PPE）合规性、火灾风险，特别是移动机器人携带易燃锂电池可能加剧火灾严重性。因此需要一个系统来增强SDLs中的态势感知和安全监控。

**Method:** Chemist Eye是一个分布式安全监控系统，集成了配备RGB、深度和红外摄像头的多个站点来监控SDLs中的事件。它使用视觉语言模型（VLM）驱动的决策来识别潜在事故、医疗紧急情况、PPE合规性和火灾危险。系统可与机器人实时通信，根据VLM建议将移动机器人引导远离潜在火灾、出口或未佩戴PPE的人员，并发出声音警告。它还与第三方消息平台集成以提供即时通知。

**Result:** 在配备三台移动机器人的自主实验室中，Chemist Eye对潜在安全隐患的发现性能达到97%，决策性能达到95%。

**Conclusion:** Chemist Eye系统有效地提高了自主实验室的安全监控和机器人决策能力，通过整合视觉语言模型和多传感器数据，显著提升了对安全隐患的识别和响应效率。

> **ai_Abstract:** 本文介绍了Chemist Eye，一个用于自主实验室（SDLs）的分布式安全监控系统。该系统旨在解决SDLs中因机器人和自动化引入的安全复杂性，特别是PPE合规性和火灾风险。Chemist Eye集成了多站点的RGB、深度和红外摄像头，并利用视觉语言模型（VLM）进行决策，以识别潜在事故、PPE违规和火灾危险。系统能够与移动机器人实时通信，根据VLM的建议引导机器人规避危险区域，并向实验室人员发送即时通知。在实际SDL环境中的测试显示，该系统在安全隐患发现和决策方面的表现分别达到了97%和95%。

> **摘要翻译:** 自主实验室（SDLs）中机器人技术和自动化的整合除了传统研究实验室已有的复杂性外，还会引入额外的安全复杂性。个人防护设备（PPE）是确保实验室（无论是自主实验室还是其他类型）工作人员安全和福祉的基本要求。火灾是化学实验室中另一个重要的风险因素。在SDLs中，发生在靠近使用易燃锂电池的移动机器人附近的火灾，其严重性可能会增加。本文介绍了Chemist Eye，一个分布式安全监控系统，旨在增强SDLs中的态势感知能力。该系统集成了多个配备RGB、深度和红外摄像头的站点，旨在监控SDLs中的事件。Chemist Eye还旨在发现可能遭受事故或医疗紧急情况的工作人员、PPE合规性以及火灾隐患。为此，Chemist Eye使用由视觉-语言模型（VLM）驱动的决策。Chemist Eye设计用于无缝集成，实现与机器人的实时通信。根据VLM的建议，系统尝试将移动机器人驱离潜在的火灾位置、出口或未佩戴PPE的人员，并在必要时发出听觉警告。它还与第三方消息平台集成，为实验室人员提供即时通知。我们使用来自配备三台移动机器人的SDL的真实数据对Chemist Eye进行了测试，发现其发现潜在安全隐患和决策的性能分别达到了97%和95%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [31] [NoWag: A Unified Framework for Shape Preserving Compression of Large Language Models](https://arxiv.org/abs/2504.14569)
> *NoWag：一种大语言模型形状保持压缩的统一框架*

*Lawrence Liu, Inesh Chakrabarti, Yixiao Li, Mengdi Wang, Tuo Zhao, Lin F. Yang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 模型压缩, 向量量化, 剪枝, NoWag

**Comment:** 

> **TL;DR:** NoWag是一个统一的、一次性形状保持压缩框架，通过向量量化和剪枝技术显著降低了大型语言模型的计算和内存需求，并在Llama模型上取得了优异的性能。

**AI_Comments:** 这项工作通过提出一个统一的框架NoWag，创新性地将向量量化和剪枝这两种不同的模型压缩技术结合起来。其重要性在于，它不仅为LLMs在资源受限环境中的部署提供了有效的解决方案，而且揭示了不同压缩范式之间的共性，为未来的模型压缩研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言处理任务中表现出色，但其庞大的计算和内存需求限制了它们在资源受限环境中的部署。

**Method:** 本文提出了NoWag（归一化权重和激活引导压缩），一个用于一次性形状保持压缩算法的统一框架。作者将NoWag应用于压缩Llama-2和Llama-3模型，使用了两种流行的形状保持技术：向量量化（NoWag-VQ）和非结构化/半结构化剪枝（NoWag-P）。

**Result:** 实验结果表明，NoWag-VQ显著优于最先进的一次性向量量化方法，而NoWag-P与领先的剪枝技术相比也表现出竞争力。

**Conclusion:** 这些发现突出了不同压缩范式之间的潜在共性，并为未来的研究提供了有前景的方向。

> **ai_Abstract:** NoWag是一个统一的框架，旨在通过一次性形状保持压缩算法来解决大型语言模型（LLMs）的计算和内存限制。它结合了向量量化（NoWag-VQ）和剪枝（NoWag-P）两种技术，并成功应用于Llama-2和Llama-3模型。实验证明，NoWag-VQ在性能上超越了现有的一次性向量量化方法，而NoWag-P则与主流剪枝技术表现相当，这表明不同压缩方法之间存在共性，并为未来的研究提供了新思路。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但其巨大的计算和内存需求限制了它们在资源受限环境中的部署。为了解决这一挑战，我们提出了NoWag（归一化权重和激活引导压缩），一个用于一次性形状保持压缩算法的统一框架。我们将NoWag应用于压缩Llama-2（7B、13B、70B）和Llama-3（8B、70B）模型，使用了两种流行的形状保持技术：向量量化（NoWag-VQ）和非结构化/半结构化剪枝（NoWag-P）。我们的结果表明，NoWag-VQ显著优于最先进的一次性向量量化方法，而NoWag-P与领先的剪枝技术相比也表现出竞争力。这些发现突出了这些压缩范式之间的潜在共性，并为未来的研究提供了有前景的方向。我们的代码可在https://github.com/LawrenceRLiu/NoWag获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [36] [InfiAlign: A Scalable and Sample-Efficient Framework for Aligning LLMs to Enhance Reasoning Capabilities](https://arxiv.org/abs/2508.05496)
> *InfiAlign：一种可扩展且样本高效的LLM对齐框架，用于增强推理能力*

*Shuo Cai, Su Lu, Qi Zhou, Kejing Yang, Zhijie Sang, Congkai Xie, Hongxia Yang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** LLMs, 对齐, 推理能力, 数据效率, 可扩展性

**Comment:** 

> **TL;DR:** InfiAlign是一个可扩展且样本高效的框架，通过结合SFT和DPO以及高质量数据选择，显著提升LLM的推理能力，同时大幅减少数据需求。

**AI_Comments:** InfiAlign的创新之处在于其结合了SFT和DPO的全面后训练策略，并辅以一个高度有效且可扩展的数据选择管道。这一管道通过多维质量指标自动筛选数据，解决了现有方法在数据效率和可扩展性上的局限性。其在仅使用12%数据量的情况下达到SOTA性能的成果，以及在数学推理任务上的显著提升，都突显了其作为对齐大型推理模型实用解决方案的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的推理能力增强在后训练阶段资源密集，尤其是在数据和计算成本方面。现有提高样本效率的方法通常依赖启发式或任务特定策略，限制了可扩展性。

**Method:** 本文引入了InfiAlign，一个结合了监督微调（SFT）和直接偏好优化（DPO）的后训练框架，用于对齐LLMs以增强推理能力。其核心是一个强大的数据选择管道，它使用多维质量指标从开源推理数据集中自动筛选高质量对齐数据。

**Result:** 当应用于Qwen2.5-Math-7B-Base模型时，InfiAlign的SFT模型仅使用约12%的训练数据，就达到了与DeepSeek-R1-Distill-Qwen-7B相当的性能，并展现出强大的跨多样推理任务泛化能力。通过应用DPO获得了额外改进，尤其是在数学推理任务中，在AIME 24/25基准测试中平均提升了3.89%。

**Conclusion:** 结合原则性数据选择与全阶段后训练是有效的，为以可扩展和数据高效的方式对齐大型推理模型提供了一个实用解决方案。

> **ai_Abstract:** InfiAlign是一个旨在以可扩展和样本高效的方式增强大型语言模型（LLMs）推理能力的后训练框架。它通过结合监督微调（SFT）和直接偏好优化（DPO）实现这一目标，并核心依赖于一个自动筛选高质量对齐数据的强大数据选择管道。该方法在显著减少数据需求的同时，实现了与现有先进模型相当甚至超越的性能，尤其在数学推理任务上表现突出，证明了其在数据效率和性能提升方面的有效性。

> **摘要翻译:** 大型语言模型（LLMs）在各种复杂任务上展现出令人印象深刻的推理能力。然而，通过后训练增强这些能力仍然是资源密集型的，尤其是在数据和计算成本方面。尽管最近的努力试图通过选择性数据筛选来提高样本效率，但现有方法通常依赖启发式或任务特定的策略，这阻碍了可扩展性。在这项工作中，我们引入了InfiAlign，一个可扩展且样本高效的后训练框架，它将监督微调（SFT）与直接偏好优化（DPO）相结合，以对齐LLMs来增强推理能力。InfiAlign的核心是一个强大的数据选择管道，它使用多维质量指标从开源推理数据集中自动筛选高质量对齐数据。这个管道在显著减少数据需求的同时实现了显著的性能提升，并且可以扩展到新的数据源。当应用于Qwen2.5-Math-7B-Base模型时，我们的SFT模型仅使用大约12%的训练数据就达到了与DeepSeek-R1-Distill-Qwen-7B相当的性能，并展现出跨不同推理任务的强大泛化能力。通过应用DPO获得了额外改进，尤其是在数学推理任务中取得了显著的进步。该模型在AIME 24/25基准测试中平均提升了3.89%。我们的结果突出了将原则性数据选择与全阶段后训练相结合的有效性，为以可扩展和数据高效的方式对齐大型推理模型提供了一个实用解决方案。模型检查点可在https://huggingface.co/InfiX-ai/InfiAlign-Qwen-7B-SFT获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [37] [Speech LLMs in Low-Resource Scenarios: Data Volume Requirements and the Impact of Pretraining on High-Resource Languages](https://arxiv.org/abs/2508.05149)
> *语音大模型在低资源场景：数据量需求与高资源语言预训练的影响*

*Seraphina Fong, Marco Matassoni, Alessio Brutti* | **Category: cs.AI, cs.CL, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 语音大模型, 低资源语言, 自动语音识别, 预训练, 数据稀缺

**Comment:** 

> **TL;DR:** 研究了语音大模型在低资源语音识别中的应用，发现预训练和多语言投影器能有效缓解数据稀缺问题，并评估了数据量需求。

**AI_Comments:** 这项研究通过探索预训练和多语言投影器在高资源语言上的应用，为解决低资源语音识别中的数据稀缺问题提供了有价值的见解。其创新点在于结合了现有的LLM和语音编码器，并通过轻量级投影器进行连接，有效提升了低资源场景下的性能。这项工作对于推动语音大模型在更广泛语言环境中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型在处理高资源语言的语音输入方面表现出色，但在低资源环境下其适用性尚未充分探索。本文旨在解决这一问题。

**Method:** 采用SLAM-ASR框架，通过可训练的轻量级投影器连接语音编码器和LLM。评估了训练数据量需求，并利用在高资源语言上预训练的单语或多语言投影器来减少数据稀缺的影响。使用多语言LLM（EuroLLM, Salamandra）和whisper-large-v3-turbo在公共基准上进行性能评估。

**Result:** 1. 评估了匹配Whisper-only性能所需的训练数据量，再次强调了数据有限的挑战。2. 表明在高资源语言上预训练的单语或多语言投影器能减少数据稀缺的影响，尤其是在小训练集上。3. 使用多语言LLM在多个公共基准上评估了性能。

**Conclusion:** 预训练和多语言投影器对于优化低资源语言的语音大模型和多语言能力至关重要，能有效应对数据稀缺问题。

> **ai_Abstract:** 本文探讨了语音大模型在低资源自动语音识别中的应用，利用SLAM-ASR框架连接语音编码器和LLM。研究评估了匹配现有模型性能所需的数据量，并发现利用高资源语言预训练的单语或多语言投影器能显著缓解数据稀缺问题，尤其是在训练数据量较小的情况下。研究结果为未来优化低资源语言和多语言环境下的语音大模型提供了重要方向。

> **摘要翻译:** 大型语言模型（LLMs）在高资源语言的语音输入处理方面展现出潜力，在各种任务中达到了最先进的性能。然而，它们在低资源环境中的适用性仍有待探索。本工作研究了在SLAM-ASR框架下，语音大模型在低资源自动语音识别中的应用，其中一个可训练的轻量级投影器连接语音编码器和LLM。首先，我们评估了匹配Whisper-only性能所需的训练数据量，再次强调了有限数据的挑战。其次，我们展示了利用在高资源语言上预训练的单语或多语言投影器可以减少数据稀缺的影响，尤其是在小型训练集上。使用多语言LLMs（EuroLLM, Salamandra）与whisper-large-v3-turbo，我们在几个公共基准上评估了性能，为未来优化低资源语言和多语言能力的语音大模型研究提供了见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [38] [Diffusion Models are Secretly Exchangeable: Parallelizing DDPMs via Autospeculation](https://arxiv.org/abs/2505.03983)
> *扩散模型是秘密可交换的：通过自动推测并行化DDPMs*

*Hengyuan Hu, Aniket Das, Dorsa Sadigh, Nima Anari* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 扩散模型, DDPMs, 并行化, 自动推测解码, 可交换性

**Comment:** 

> **TL;DR:** 去噪扩散概率模型（DDPMs）因其顺序计算而面临推理速度瓶颈。本文揭示了DDPMs增量的可交换性，并引入了自动推测解码（ASD）算法，该算法无需辅助模型即可并行化DDPMs，理论上实现了显著加速。

**AI_Comments:** 本文的创新之处在于揭示了DDPM增量的可交换性这一深层特性，这为加速扩散模型提供了新的理论基础。通过将自回归模型中的推测解码技术适配到DDPMs，并成功地避免了对辅助草稿模型的依赖，极大地提升了其实用性和效率，是解决DDPM推理速度瓶颈的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 去噪扩散概率模型（DDPMs）虽然是强大的生成建模工具，但其顺序计算要求导致显著的推理时间瓶颈。

**Method:** 本文利用DDPMs与随机局部化之间的联系，证明在适当的重新参数化下，DDPM的增量满足可交换性。基于此，提出并引入了自动推测解码（ASD）算法，该算法是广泛使用的推测解码算法在DDPMs上的扩展，且不需要任何辅助草稿模型。

**Result:** 理论分析表明，ASD在K步顺序DDPM上实现了$	ilde{O} (K^{\frac{1}{3}})$的并行运行时间加速。实际实现也证明了自动推测解码在各种领域显著加速了DDPM的推理。

**Conclusion:** 通过利用DDPM增量的可交换性并引入自动推测解码（ASD），可以显著加速DDPM的推理过程，从而克服其主要的计算瓶颈。

> **ai_Abstract:** 去噪扩散概率模型（DDPMs）在生成建模中表现出色，但其顺序计算限制了推理速度。本文发现DDPM增量在适当重参数化下具有可交换性，通过连接随机局部化，实现了将自回归模型的优化技术应用于扩散模型。为此，作者提出了一种无需辅助模型的自动推测解码（ASD）算法，将其应用于DDPMs。理论分析表明ASD可实现$\tilde{O} (K^{\frac{1}{3}})$的并行运行时间加速，并在实践中显著加速了DDPM在多个领域的推理。

> **摘要翻译:** 去噪扩散概率模型（DDPMs）已成为生成建模的强大工具。然而，它们的顺序计算要求导致显著的推理时间瓶颈。在这项工作中，我们利用DDPMs与随机局部化之间的联系，证明在适当的重新参数化下，DDPM的增量满足可交换性。这一普遍的见解使得将自回归模型中的各种性能优化技术几乎以黑盒方式适应到扩散设置成为可能。为了证明这一点，我们引入了\emph{自动推测解码}（ASD），这是将广泛使用的推测解码算法扩展到DDPMs的一种方法，它不需要任何辅助草稿模型。我们的理论分析表明，ASD在K步顺序DDPM上实现了$\tilde{O} (K^{\frac{1}{3}})$的并行运行时间加速。我们还证明了自动推测解码的实际实现显著加速了DDPM在各个领域的推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [43] [GRAIL:Learning to Interact with Large Knowledge Graphs for Retrieval Augmented Reasoning](https://arxiv.org/abs/2508.05498)
> *GRAIL：学习与大型知识图谱交互以进行检索增强推理*

*Ge Chang, Jinbo Su, Jiacheng Liu, Pengfei Yang, Yuhao Shang, Huiwen Zheng, Hongli Ma, Yan Liang, Yuanchun Li, Yunxin Liu* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 知识图谱, 检索增强推理, 大型语言模型, 交互式学习, 图检索

**Comment:** 

> **TL;DR:** GRAIL是一个新的框架，旨在通过交互式学习和两阶段训练过程，解决大型语言模型在处理结构化知识图谱时的检索增强推理挑战，显著提升知识图谱问答性能。

**AI_Comments:** GRAIL的创新点在于其将LLM引导的探索与交互式学习相结合，用于知识图谱的检索增强推理。它通过解耦精度-简洁性目标和采用过程监督奖励，有效提升了训练效率和稳定性。这种交互式检索范式对于处理复杂知识图谱数据具有重要意义，能够更精准地平衡检索广度和精度，弥补了现有RAG在结构化数据处理上的不足。

<details>
  <summary>Details</summary>

**Motivation:** 现有检索增强生成（RAG）方法主要处理非结构化数据，对知识图谱等结构化知识的处理能力有限。当前的图检索方法难以捕获整体图结构，同时面临精确度控制挑战，表现为关键信息缺失或冗余连接过多，从而损害推理性能。

**Method:** GRAIL是一个图检索增强交互式学习框架。它整合了LLM引导的随机探索与路径过滤，建立数据合成管道，为每个任务自动生成细粒度推理轨迹。基于合成数据，采用两阶段训练过程，学习在每个推理步骤动态决定最优动作的策略。图检索中精度-简洁性平衡的总目标被解耦为细粒度的过程监督奖励，以提高数据效率和训练稳定性。在实际部署中，GRAIL采用交互式检索范式，使模型能够自主探索图路径，动态平衡检索广度和精度。

**Result:** GRAIL在三个知识图谱问答数据集上，平均准确率提高了21.01%，F1分数提高了22.43%。

**Conclusion:** GRAIL通过其创新的交互式检索范式和两阶段训练过程，显著提升了大型语言模型在知识图谱上的检索增强推理能力，有效解决了现有方法在处理结构化数据时的局限性和图检索中的精度-简洁性平衡问题。

> **ai_Abstract:** GRAIL是一个针对大型语言模型在知识图谱上进行检索增强推理的新框架。它解决了现有RAG方法在处理结构化数据和图检索精度控制上的不足。GRAIL通过整合LLM引导的探索和路径过滤来合成数据，并采用两阶段训练策略学习动态动作决策。其核心在于通过过程监督奖励实现图检索的精度与简洁性平衡，并支持交互式探索。实验证明，GRAIL在知识图谱问答任务上显著提升了准确率和F1分数。

> **摘要翻译:** 大型语言模型（LLMs）与检索增强生成（RAG）技术相结合，在广泛领域展现出卓越性能。然而，现有RAG方法主要作用于非结构化数据，在处理知识图谱等结构化知识方面能力有限。同时，当前图检索方法根本上难以捕获整体图结构，并面临精度控制挑战，表现为关键信息缺失或过度冗余连接，共同损害推理性能。为解决这一挑战，我们提出了GRAIL：图检索增强交互式学习，一个旨在与大规模图交互以进行检索增强推理的框架。具体而言，GRAIL将LLM引导的随机探索与路径过滤相结合，建立了一个数据合成管道，为每个任务自动生成细粒度推理轨迹。基于合成数据，我们随后采用两阶段训练过程，学习一种在每个推理步骤动态决定最优动作的策略。图检索中精度-简洁性平衡的总体目标被解耦为细粒度的过程监督奖励，以增强数据效率和训练稳定性。在实际部署中，GRAIL采用交互式检索范式，使模型能够自主探索图路径，同时动态平衡检索广度和精度。广泛的实验表明，GRAIL在三个知识图谱问答数据集上，平均准确率提高了21.01%，F1分数提高了22.43%。我们的源代码和数据集可在https://github.com/Changgeww/GRAIL获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [44] [Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval for Large Language Models](https://arxiv.org/abs/2508.05152)
> *工具图检索器：探索基于依赖图的工具检索用于大型语言模型*

*Linfeng Gao, Yaoxiang Wang, Minlong Peng, Jialong Tang, Yuzhe Shang, Mingming Sun, Jinsong Su* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 工具检索, 依赖图, 大型语言模型, 图卷积, AI代理

**Comment:** 

> **TL;DR:** 本文提出Tool Graph Retriever (TGR)，通过利用工具间的依赖关系来学习更好的工具表示，以解决现有工具检索方法忽略工具依赖导致遗漏前置工具的问题，并在实验中取得了最先进的性能。

**AI_Comments:** 本文的创新点在于首次将工具间的依赖关系显式地融入到工具检索过程中，通过构建工具依赖图和使用图卷积来学习更有效的工具表示。这解决了现有方法独立处理工具的局限性，显著提高了工具检索的准确性和完整性。其提出的TDI300K数据集也为未来的研究提供了宝贵的资源。该方法对于提升AI代理在复杂任务中的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI代理配备的工具数量迅速增加，将所有工具信息整合到有限的模型上下文中变得不切实际，因此需要高效的工具检索方法。现有主导方法主要依赖工具描述和用户查询之间的语义相似性来检索相关工具，但它们通常独立考虑每个工具，忽略工具间的依赖关系，这可能导致成功执行任务所需的前置工具被遗漏。

**Method:** 本文提出了Tool Graph Retriever (TGR)。首先，构建了一个名为TDI300K的数据集，用于训练一个判别器以识别工具依赖关系。然后，将所有候选工具表示为工具依赖图，并使用图卷积将依赖关系整合到它们的表示中。最后，这些更新的工具表示被用于在线检索。

**Result:** 实验结果表明，TGR可以改进现有主导方法的性能，达到SOTA（State-of-the-Art）性能。深入分析也验证了工具依赖关系的重要性以及TGR的有效性。

**Conclusion:** 本文提出的Tool Graph Retriever (TGR)通过利用工具间的依赖关系，有效地解决了现有工具检索方法中忽略前置工具的问题，并在多个常用数据集上取得了最先进的性能，证明了工具依赖性的重要性和TGR的有效性。

> **ai_Abstract:** 本文提出了一种名为Tool Graph Retriever (TGR)的新型工具检索方法，旨在解决大型语言模型中工具数量增长带来的检索挑战。现有方法常忽略工具间的依赖关系，导致检索不完整。TGR通过构建工具依赖图并利用图卷积来学习更丰富的工具表示，从而更好地捕捉工具间的关联。研究团队创建了TDI300K数据集用于训练依赖关系判别器。实验结果表明，TGR在多个数据集上超越了现有方法，实现了最先进的性能，并验证了工具依赖关系在工具检索中的重要性。

> **摘要翻译:** 随着AI代理的显著进步，其配备的工具数量迅速增加。然而，将所有工具信息整合到有限的模型上下文中变得不切实际，这突显了对高效工具检索方法的需求。在这方面，主导方法主要依赖工具描述和用户查询之间的语义相似性来检索相关工具。然而，它们通常独立考虑每个工具，忽略工具之间的依赖关系，这可能导致成功执行任务所需的前置工具被遗漏。为了解决这个缺陷，在本文中，我们提出了工具图检索器（TGR），它利用工具之间的依赖关系来学习更好的工具表示以进行检索。首先，我们构建了一个名为TDI300K的数据集，用于训练一个判别器以识别工具依赖关系。然后，我们将所有候选工具表示为工具依赖图，并使用图卷积将依赖关系整合到它们的表示中。最后，这些更新的工具表示被用于在线检索。在几个常用数据集上的实验结果表明，我们的TGR可以为现有主导方法带来性能提升，达到SOTA性能。此外，深入分析也验证了工具依赖关系的重要性以及我们TGR的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [45] [RLSR: Reinforcement Learning from Self Reward](https://arxiv.org/abs/2505.08827)
> *RLSR：来自自我奖励的强化学习*

*Toby Simonds, Kevin Lopez, Akira Yoshiyama, Dominique Garmier* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 自我奖励, 强化学习, 大型语言模型, 自我改进, 自主AI

**Comment:** 

> **TL;DR:** 大型语言模型可以通过自我评判进行自我提升，无需外部可验证奖励，从而在奖励难以获取的领域实现强化学习。

**AI_Comments:** 这项工作的创新之处在于提出LLM可以通过“自我评判”来生成强化学习所需的奖励信号，从而摆脱了对昂贵或不可得的外部真实奖励的依赖。这解决了强化学习在许多实际应用中面临的关键挑战，特别是对于那些缺乏明确反馈或真实答案的复杂问题。其重要性在于为LLM的自我持续学习和自主AI系统的发展开辟了新的道路，有望在数据稀缺或评估复杂的领域加速AI进步。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过强化学习训练通常需要昂贵且并非所有领域都可行的可验证奖励信号。

**Method:** 本文提出LLMs可以通过自我评判（self-judging）有效实现自我提升，利用生成和验证解决方案之间固有的不对称性，提供可靠的奖励信号而无需真实答案。该方法应用于Countdown谜题和积分问题。

**Result:** 实验表明，模型在没有真实答案的情况下也能提供可靠的奖励信号，性能与正式验证相当。Qwen 2.5 7B DeepSeek Distilled 模型通过自我奖励训练，获得了MIT积分大赛的参赛资格。当与合成问题生成结合时，建立了完整的自我改进循环，模型可以生成练习问题、解决问题并评估自身表现，无需任何外部验证。

**Conclusion:** LLM评判器可以为训练提供有效的奖励信号，从而在以前受奖励工程挑战限制的无数领域解锁强化学习，是迈向通过自我导向学习持续改进的自主AI系统的重要一步。

> **ai_Abstract:** 本文提出RLSR（来自自我奖励的强化学习），使大型语言模型能够通过自我评判实现自我改进，克服了传统强化学习对昂贵且难以获得的外部可验证奖励的依赖。研究表明，模型无需真实答案即可提供可靠奖励信号，并在Countdown谜题和积分问题上达到与正式验证相当的性能，甚至使模型获得MIT积分大赛参赛资格。结合合成问题生成，模型可实现完全自主的自我改进循环。这为在奖励工程受限的领域应用强化学习提供了可能，并推动了自主AI系统的发展。

> **摘要翻译:** 大型语言模型可以生成复杂问题的解决方案，但使用强化学习训练它们通常需要可验证的奖励，这不仅成本高昂，而且并非适用于所有领域。我们证明，大型语言模型可以通过自我评判有效地进行自我改进，无需参考解决方案，利用生成和验证解决方案之间固有的不对称性。我们的实验表明，模型可以在没有真实答案的情况下提供可靠的奖励信号，从而在可验证奖励不切实际的领域实现强化学习。通过在Countdown谜题和积分问题中实施自我评判，我们实现了与正式验证相当的性能，而无需真实解决方案。最值得注意的是，通过自我奖励训练的Qwen 2.5 7B DeepSeek Distilled模型获得了著名的MIT积分大赛的参赛资格，其性能通过自我监督改进而来。当与合成问题生成相结合时，我们建立了一个完整的自我改进循环，模型可以生成练习问题，解决它们，并评估自己的表现，而无需任何外部验证。我们的发现表明，大型语言模型评判器可以为训练提供有效的奖励信号，从而在以前受奖励工程挑战限制的无数领域解锁强化学习。这项工作代表着迈向自主AI系统的重要一步，这些系统通过自我导向学习而非人类指导训练持续改进，可能加速在训练数据稀缺或评估复杂的领域取得进展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [50] [Auto-Eval Judge: Towards a General Agentic Framework for Task Completion Evaluation](https://arxiv.org/abs/2508.05508)
> *Auto-Eval Judge：迈向通用智能体任务完成评估框架*

*Roshita Bhonsle, Rishav Dutta, Sneha Vavilapalli, Harsh Seth, Abubakarr Jaye, Yapei Chang, Mukund Rungta, Emmanuel Aboah Boateng, Sadid Hasan, Ehi Nosakhare, Soundar Srinivasan* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 智能体评估, 任务完成, 通用框架, 逐步推理, LLM-as-a-Judge

**Comment:** 

> **TL;DR:** 本文提出了一个通用的、模块化的智能体任务完成评估框架，通过分解任务并验证每一步骤来模拟人类评估，并在基准测试中展现出优于现有方法的性能。

**AI_Comments:** 该论文提出了一种创新的通用智能体评估框架，解决了现有评估方法（如LLM-as-a-Judge）仅关注最终输出而忽略逐步推理的局限性，以及Agent-as-a-Judge系统领域特异性的问题。其模块化设计和模拟人类评估的思路是重要的创新点，有助于推动智能体评估领域的发展。实验结果也初步验证了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型作为智能体在各领域日益普及，需要一个强大的评估框架。然而，现有方法如LLM-as-a-Judge仅关注最终输出，忽略了智能体的逐步推理过程；而现有Agent-as-a-Judge系统通常针对狭窄的特定领域设计，缺乏通用性。

**Method:** 本文提出了一个通用、模块化的智能体任务完成评估框架，该框架独立于任务领域。它通过将任务分解为子任务并利用智能体的输出和推理等可用信息验证每一步骤，从而模拟人类评估。每个模块负责评估过程的特定方面，其输出被聚合以产生关于任务完成的最终判断。

**Result:** 作者通过在GAIA和BigCodeBench两个基准测试上评估Magentic-One Actor Agent来验证了该框架。与基于GPT-4o的LLM-as-a-Judge基线相比，作者提出的Judge Agent在预测任务成功方面与人类评估的吻合度更高，对齐准确率分别提高了4.76%和10.52%。

**Conclusion:** 本文提出的通用评估框架具有巨大潜力，能够更准确地评估智能体任务完成度，尤其是在逐步推理方面。

> **ai_Abstract:** 本文针对当前智能体评估方法无法有效评估逐步推理和缺乏通用性的问题，提出了一种名为“Auto-Eval Judge”的通用、模块化框架。该框架通过将任务分解为子任务并逐步骤验证智能体的输出和推理，以模拟人类评估过程。实验结果表明，该框架在GAIA和BigCodeBench基准测试中，相较于GPT-4o基线，能更准确地预测任务成功，验证了其有效性和潜力。

> **摘要翻译:** 基础模型作为智能体在各个领域日益普及，这需要一个强大的评估框架。当前的评估方法，例如LLM-as-a-Judge，仅关注最终输出，而忽略了驱动智能体决策的逐步推理过程。同时，现有的Agent-as-a-Judge系统（其中一个智能体评估另一个智能体的任务完成情况）通常是为狭窄的、特定领域的设置而设计的。为了解决这一差距，我们提出了一个通用、模块化的框架，用于评估智能体任务完成情况，且独立于任务领域。该框架通过将任务分解为子任务，并利用智能体的输出和推理等可用信息验证每一步骤，从而模拟人类般的评估。每个模块都对评估过程的特定方面做出贡献，其输出被聚合以产生关于任务完成的最终判断。我们通过在GAIA和BigCodeBench两个基准测试上评估Magentic-One Actor Agent来验证了我们的框架。我们的Judge Agent在预测任务成功方面与人类评估的吻合度更高，与基于GPT-4o的LLM-as-a-Judge基线相比，对齐准确率分别提高了4.76%和10.52%。这证明了我们提出的通用评估框架的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [51] [FCBV-Net: Category-Level Robotic Garment Smoothing via Feature-Conditioned Bimanual Value Prediction](https://arxiv.org/abs/2508.05153)
> *FCBV-Net：基于特征条件双臂价值预测的类别级机器人服装平滑*

*Mohammed Daba, Jing Qiu* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人服装平滑, 类别级泛化, 双臂操作, 特征条件, 价值预测

**Comment:** 

> **TL;DR:** FCBV-Net通过将几何理解与双臂动作价值学习解耦，利用预训练的冻结几何特征进行双臂价值预测，从而显著提高了机器人服装平滑任务在类别层面的泛化能力。

**AI_Comments:** 本文的核心创新在于将几何特征的理解与双臂动作价值的预测解耦，这通过使用预训练并冻结的几何特征实现。这种方法有效地解决了机器人操作中可变形物体（如服装）的类别内变异性问题，显著提升了策略的泛化能力，是机器人柔性物体操作领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 机器人服装操作（如双臂平滑）的类别级泛化面临高维度、复杂动力学和类别内变异的挑战。现有方法常常过拟合特定实例，或虽能进行类别级感知泛化，却无法预测协同双臂动作的价值。

**Method:** 本文提出了特征条件双臂价值网络（FCBV-Net），该网络基于3D点云操作，旨在增强服装平滑的类别级策略泛化能力。FCBV-Net通过预训练、冻结的密集几何特征来条件化双臂动作价值预测，以确保对类别内服装变异的鲁棒性。可训练的下游组件随后利用这些静态特征学习特定任务的策略。

**Result:** 在GarmentLab模拟实验和CLOTH3D数据集上的测试表明，FCBV-Net展现出卓越的类别级泛化能力。与基于2D图像的基线相比，它在未见过的服装上效率仅下降11.5%（Steps80），而后者下降96.2%。FCBV-Net实现了89%的最终覆盖率，优于使用相同逐点几何特征但固定原语的3D对应基线的83%覆盖率。

**Conclusion:** 研究结果表明，将几何理解与双臂动作价值学习解耦能够实现更好的类别级泛化。

> **ai_Abstract:** FCBV-Net是一种用于机器人服装平滑的新型网络，旨在解决类别级泛化难题。它通过在预训练的冻结3D几何特征上条件化双臂动作价值预测，并分离几何理解与动作价值学习，显著提高了对类别内服装变异的鲁棒性和泛化能力。在模拟实验中，FCBV-Net在未见过服装的效率下降方面远优于2D基线，并在最终覆盖率上超过3D基线，验证了其在类别级机器人服装操作中的有效性。

> **摘要翻译:** 类别级机器人服装操作（如双臂平滑）由于高维度、复杂动力学和类别内变异，仍然是一个重大难题。当前方法常常难以奏效，要么因同时学习的视觉特征对特定实例过拟合，要么尽管实现了类别级感知泛化，却无法预测协同双臂动作的价值。我们提出了特征条件双臂价值网络（FCBV-Net），该网络基于3D点云操作，旨在专门增强服装平滑的类别级策略泛化能力。FCBV-Net通过预训练、冻结的密集几何特征来条件化双臂动作价值预测，确保对类别内服装变异的鲁棒性。可训练的下游组件随后利用这些静态特征学习特定任务的策略。在GarmentLab模拟实验和CLOTH3D数据集上的测试表明，FCBV-Net展现出卓越的类别级泛化能力。与基于2D图像的基线相比，它在未见过的服装上效率仅下降11.5%（Steps80），而后者下降96.2%。它实现了89%的最终覆盖率，优于使用相同逐点几何特征但固定原语的3D对应基线的83%覆盖率。这些结果突出表明，将几何理解与双臂动作价值学习解耦能够实现更好的类别级泛化。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [52] [EarthSynth: Generating Informative Earth Observation with Diffusion Models](https://arxiv.org/abs/2505.12108)
> *EarthSynth：使用扩散模型生成信息丰富的地球观测数据*

*Jiancheng Pan, Shiye Lei, Yuqian Fu, Jiahao Li, Yanxing Liu, Yuze Sun, Xiao He, Long Peng, Xiaomeng Huang, Bo Zhao* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 扩散模型, 遥感图像解释, 数据合成, 生成模型, 多任务生成

**Comment:** 

> **TL;DR:** EarthSynth是一个基于扩散模型的生成式基础模型，旨在通过合成多类别、跨卫星的标注地球观测数据，解决遥感图像（RSI）解释中标注数据稀缺的问题，并在开放世界场景下的多项RSI解释任务中取得显著改进。

**AI_Comments:** EarthSynth的创新之处在于它是首个探索遥感领域多任务生成的扩散模型，有效解决了RSI解释中标注数据稀缺和任务导向合成泛化能力有限的问题。其采用的反事实组合训练策略和三维批次样本选择机制，以及R-Filter数据过滤方法，都旨在提升合成数据的质量和多样性，使其能更好地服务于下游任务。该研究为推进遥感图像智能解释提供了重要的实践性解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像（RSI）解释通常面临标注数据稀缺的挑战，这限制了RSI解释任务的性能。

**Method:** 本文提出了EarthSynth，一个基于扩散模型的生成式基础模型，能够合成多类别、跨卫星的标注地球观测数据。EarthSynth在EarthSynth-180K数据集上训练，采用反事实组合训练策略和三维批次样本选择机制，以提高训练数据多样性和增强类别控制。此外，还提出了一种基于规则的R-Filter方法来过滤出对下游任务更有信息量的合成数据。

**Result:** EarthSynth在开放世界场景下的场景分类、目标检测和语义分割任务中进行了评估，并在开放词汇理解任务中取得了显著改进。

**Conclusion:** EarthSynth为推进遥感图像解释提供了一个实用的解决方案。

> **ai_Abstract:** EarthSynth是一个创新的扩散模型，旨在解决遥感图像（RSI）解释中标注数据不足的问题。它通过合成多类别、跨卫星的标注地球观测数据来支持下游任务。该模型是首个探索遥感多任务生成的模型，通过反事实组合训练策略和三维批次样本选择机制提高数据多样性和类别控制，并利用R-Filter过滤高质量合成数据。在场景分类、目标检测和语义分割等开放世界任务中的评估显示，EarthSynth显著提升了开放词汇理解能力，为RSI解释提供了有效方案。

> **摘要翻译:** 遥感图像（RSI）解释通常面临标注数据稀缺的挑战，这限制了RSI解释任务的性能。为了解决这一挑战，我们提出了EarthSynth，一个基于扩散模型的生成式基础模型，它能够合成多类别、跨卫星的标注地球观测数据，用于下游RSI解释任务。据我们所知，EarthSynth是第一个探索遥感多任务生成的模型，解决了RSI解释中面向任务合成泛化能力有限的挑战。EarthSynth在EarthSynth-180K数据集上训练，采用反事实组合训练策略和三维批次样本选择机制，以提高训练数据多样性并增强类别控制。此外，还提出了一种基于规则的R-Filter方法来过滤出对下游任务更有信息量的合成数据。我们在开放世界场景下的场景分类、目标检测和语义分割任务中评估了我们的EarthSynth。在开放词汇理解任务中取得了显著改进，为推进RSI解释提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [57] [Streamlining Admission with LOR Insights: AI-Based Leadership Assessment in Online Master's Program](https://arxiv.org/abs/2508.05513)
> *通过推荐信洞察简化招生：在线硕士项目中的AI领导力评估*

*Meryem Yilmaz Soylu, Adrian Gallard, Jeonghyun Lee, Gayane Grigoryan, Rushil Desai, Stephen Harmon* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 推荐信, 领导力评估, 人工智能, 自然语言处理, 招生

**Comment:** 

> **TL;DR:** 开发了一个AI工具LORI，用于自动化评估在线硕士申请人推荐信中的领导力。

**AI_Comments:** 本文提出了一种创新性的AI解决方案，通过自动化分析推荐信来评估申请人的领导力，有效解决了传统人工审查的效率问题。其重要性在于，在STEM领域日益重视领导力的背景下，该工具能够提供更客观、高效的评估方式，有助于招生委员会做出更全面的决策。

<details>
  <summary>Details</summary>

**Motivation:** 审查推荐信耗时费力，需要一种更高效的方式来评估在线硕士申请人的领导力，并支持招生委员会为学生提供专业成长反馈。

**Method:** 本研究引入了名为LORI的AI驱动检测工具，该工具利用自然语言处理技术，并结合RoBERTa和LLAMA等大型语言模型来识别推荐信中的领导力属性，如团队合作、沟通和创新。

**Result:** 最新的RoBERTa模型在测试数据上实现了91.6%的加权F1分数、92.4%的精确度和91.6%的召回率，显示出强一致性。

**Conclusion:** 将LORI整合到研究生招生流程中对于准确评估申请人的领导力能力至关重要，这不仅能简化招生过程，还能实现自动化并确保对候选人能力的更全面评估。

> **ai_Abstract:** 本研究提出了一种名为LORI的AI工具，旨在自动化评估在线硕士项目申请人推荐信中的领导力技能。通过结合自然语言处理和RoBERTa、LLAMA等大型语言模型，LORI能够识别团队合作、沟通和创新等关键领导力属性。该工具旨在解决传统推荐信审查耗时的问题，并已通过RoBERTa模型验证，取得了91.6%的加权F1分数，显示出其在评估领导力方面的有效性，从而简化并增强了研究生招生流程。

> **摘要翻译:** 推荐信（LORs）提供了对候选人能力和经验的宝贵见解，这些见解超越了标准化考试成绩。然而，审查这些文本量大的材料既耗时又费力。为了解决这一挑战并支持招生委员会为学生的专业成长提供反馈，我们的研究引入了LORI：推荐信洞察，这是一种新颖的基于人工智能的检测工具，用于评估在线硕士项目申请人提交的推荐信中的领导力技能。通过采用自然语言处理并利用RoBERTa和LLAMA等大型语言模型，我们旨在识别团队合作、沟通和创新等领导力属性。我们最新的RoBERTa模型实现了91.6%的加权F1分数、92.4%的精确度以及91.6%的召回率，这表明我们的测试数据具有很强的一致性。随着领导力技能在STEM领域日益重要，将LORI整合到研究生招生流程中对于准确评估申请人的领导力能力至关重要。这种方法不仅简化了招生过程，还实现了自动化并确保了对候选人能力的更全面评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [58] [Domain-driven Metrics for Reinforcement Learning: A Case Study on Epidemic Control using Agent-based Simulation](https://arxiv.org/abs/2508.05154)
> *领域驱动的强化学习指标：基于智能体仿真的疫情控制案例研究*

*Rishabh Gaur, Gaurav Deshkar, Jayanta Kshirsagar, Harshal Hayatnagarkar, Janani Venugopalan* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 智能体仿真, 疫情控制, 领域驱动指标, 性能评估

**Comment:** 

> **TL;DR:** 针对复杂智能体模型中强化学习性能评估的挑战，本研究开发了领域驱动的强化学习指标，并以疫情控制案例进行了演示。

**AI_Comments:** 本文的创新之处在于提出了领域驱动的强化学习指标，以解决在智能体模型中评估强化学习性能的挑战。其重要性在于旨在为复杂、随机系统中的强化学习评估提供标准化方法，这对于疫情控制等实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 评估基于强化学习的智能体模型（ABMs和RABMs）的性能具有挑战性，这是由于建模系统的复杂性和随机性，以及缺乏用于比较强化学习算法的标准化指标。

**Method:** 本研究开发了领域驱动的强化学习指标，并结合了最先进的指标。通过在一个理性的智能体疾病建模案例研究中，利用策略优化来演示这些指标，该案例模拟了疫情中的戴口罩行为、疫苗接种和封锁。

**Result:** 结果表明，在几种不同的模拟场景（例如口罩的不同可用性）中，领域驱动的奖励与传统和最先进的指标结合使用是有效的。

**Conclusion:** 领域驱动的强化学习指标可以有效地评估复杂系统（如疫情控制）中强化学习模型的性能。

> **ai_Abstract:** 本文旨在解决在复杂智能体模型（ABMs）和理性智能体模型（RABMs）中评估强化学习（RL）性能的挑战，该挑战源于系统复杂性、随机性以及缺乏标准化指标。作者提出并开发了“领域驱动强化学习指标”，并借鉴了现有最先进的指标。他们通过一个理性的智能体疾病模型案例研究中的策略优化来演示这些新指标，该案例模拟了疫情中的戴口罩、疫苗接种和封锁等行为。结果表明，在各种模拟场景（例如口罩的不同可用性）中，将领域驱动的奖励与传统和先进指标结合使用是有效的。

> **摘要翻译:** 对于智能体模型（ABMs）和理性智能体模型（RABMs）的开发和优化，强化学习等优化算法被广泛使用。然而，评估基于强化学习的ABMs和RABMs模型的性能具有挑战性，这是由于建模系统的复杂性和随机性，以及缺乏用于比较强化学习算法的标准化指标。在本研究中，我们开发了领域驱动的强化学习指标，同时借鉴了最先进的指标。我们通过在一个理性的智能体疾病建模案例研究中，利用策略优化来演示我们的“领域驱动强化学习指标”，该案例模拟了疫情中的戴口罩行为、疫苗接种和封锁。我们的结果表明，在一些不同的模拟场景（例如口罩的不同可用性）中，领域驱动的奖励与传统和最先进的指标结合使用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [59] [Flex-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal Evaluators](https://arxiv.org/abs/2505.18601)
> *Flex-Judge：纯文本推理释放零样本多模态评估器*

*Jongwoo Ko, Sungnyun Kim, Sungwoo Cho, Se-Young Yun* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多模态评估, LLM-as-a-Judge, 文本推理, 零样本, 泛化

**Comment:** 

> **TL;DR:** Flex-Judge提出了一种仅通过少量文本推理数据训练的多模态评估器，它能有效泛化到多种模态和评估格式，表现优于现有方法，尤其在资源受限领域有显著价值。

**AI_Comments:** Flex-Judge的创新在于其“纯文本推理”方法，打破了传统多模态评估器对大量模态特定训练数据的依赖。它利用文本推理的泛化能力来处理不同模态的数据，这在理论上和实践中都具有重要意义。该方法降低了多模态模型评估的门槛和成本，尤其对资源稀缺领域具有显著的实用价值。其核心理念——“结构化文本推理解释编码可泛化决策模式”——为未来跨模态泛化研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM-as-a-Judge模型需要大量的模态特定训练数据，并且在多样化的多模态任务中泛化能力不佳，导致人工标注成本高昂。

**Method:** 本文提出了Flex-Judge，一个推理引导的多模态评估模型。其核心思想是结构化的文本推理解释内在地编码了可泛化的决策模式，从而能有效地转移到多模态判断（如图像、视频）。它利用最少的文本推理数据进行训练。

**Result:** 尽管Flex-Judge在显著更少的文本数据上进行训练，但它与最先进的商业API和经过广泛训练的多模态评估器相比，取得了有竞争力或更优的性能。值得注意的是，Flex-Judge在分子等综合评估基准稀缺的模态中也展现出广泛的影响。

**Conclusion:** Flex-Judge证明了基于推理的文本监督是一种强大且经济高效的替代方案，可以取代传统的密集标注方法，从而极大地推动了可扩展的多模态模型即评估器（model-as-a-judge）的发展。

> **ai_Abstract:** Flex-Judge是一种新型的多模态评估模型，它通过利用少量文本推理数据，克服了现有LLM-as-a-Judge模型在多模态任务中泛化能力差、对模态特定数据依赖性强的问题。该模型的核心在于利用结构化文本推理解释中编码的泛化决策模式，使其能够有效地应用于图像、视频等多种模态的判断。实验证明，Flex-Judge在数据量显著减少的情况下，仍能达到或超越现有商业API和训练充分的多模态评估器的性能，尤其在评估基准稀缺的资源受限领域（如分子模态）展现出巨大潜力。该框架提供了一种成本效益高、可扩展的推理驱动文本监督方法，以替代传统的高标注成本方法。

> **摘要翻译:** 人类生成的奖励信号对于使生成模型与人类偏好保持一致至关重要，它指导着训练和推理时的评估。虽然作为代理评估器使用的大型语言模型（LLMs），即“LLM即法官”（LLM-as-a-Judge），显著降低了手动标注的成本，但它们通常需要大量的模态特定训练数据，并且难以在多样化的多模态任务中很好地泛化。在本文中，我们提出了Flex-Judge，一个推理引导的多模态评估模型，它利用最少的文本推理数据，能够稳健地泛化到多种模态和评估格式。我们的核心直觉是，结构化的文本推理解释内在地编码了可泛化的决策模式，从而能够有效地转移到多模态判断中，例如处理图像或视频。实证结果表明，尽管Flex-Judge在显著更少的文本数据上进行训练，但它与最先进的商业API和经过广泛训练的多模态评估器相比，取得了有竞争力或更优的性能。值得注意的是，Flex-Judge在分子等综合评估基准稀缺的模态中也展现出广泛的影响，这突显了其在资源受限领域的实用价值。我们的框架强调，基于推理的文本监督是一种强大、经济高效的替代方案，可以取代传统的密集标注方法，从而极大地推动了可扩展的多模态模型即评估器。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [64] [MV-Debate: Multi-view Agent Debate with Dynamic Reflection Gating for Multimodal Harmful Content Detection in Social Media](https://arxiv.org/abs/2508.05557)
> *MV-Debate：多视角代理辩论与动态反射门控用于社交媒体多模态有害内容检测*

*Rui Lu, Jinhe Bi, Yunpu Ma, Feng Xiao, Yuntao Du, Yijun Tian* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 多模态有害内容检测, 代理辩论, 动态反射, 社交媒体, 社会意图检测

**Comment:** 

> **TL;DR:** MV-Debate是一个多视角代理辩论框架，用于检测社交媒体中的多模态有害内容，通过迭代辩论和反思提高了准确性和效率。

**AI_Comments:** MV-Debate的创新之处在于其多代理辩论框架和动态反射门控机制，这使得模型能够从多个互补视角分析内容并迭代优化判断，从而有效解决了多模态有害内容检测中跨模态矛盾和语用线索识别的难题。其在多模态理解和有害内容识别方面展现出重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体中多模态有害内容（如讽刺、仇恨言论、虚假信息）的检测由于跨模态矛盾、快速文化变迁和微妙语用线索而具有挑战性。

**Method:** 本文提出了MV-Debate，一个多视角代理辩论框架，包含四个互补的辩论代理：表面分析器、深度推理器、模态对比器和社会情境分析器。通过迭代辩论和基于“反射增益”标准的自我反思来完善响应。

**Result:** 在三个基准数据集上的实验表明，MV-Debate显著优于强大的单一模型和现有的多代理辩论基线。

**Conclusion:** 这项工作突出了多代理辩论在推进安全关键在线环境中可靠的社会意图检测方面的潜力。

> **ai_Abstract:** MV-Debate是一个旨在解决社交媒体中多模态有害内容检测挑战的框架。它通过整合四个不同视角的代理（表面分析、深度推理、模态对比、社会情境分析）进行迭代辩论和动态反思，以识别隐藏在文本、图像等信号中的有害意图。实验证明MV-Debate在检测有害内容方面优于现有基线。

> **摘要翻译:** 社交媒体已演变为一个复杂的多模态环境，其中文本、图像和其他信号相互作用，形成细微的含义，常常隐藏有害意图。识别此类意图，无论是讽刺、仇恨言论还是虚假信息，由于跨模态矛盾、快速的文化变迁和微妙的语用线索，仍然具有挑战性。为了应对这些挑战，我们提出了MV-Debate，一个具有动态反射门控的多视角代理辩论框架，用于统一的多模态有害内容检测。MV-Debate集合了四个互补的辩论代理：表面分析师、深度推理者、模态对比者和社会情境分析师，从不同的解释视角分析内容。通过迭代辩论和反思，代理在反射增益标准下完善响应，确保准确性和效率。在三个基准数据集上的实验表明，MV-Debate显著优于强大的单一模型和现有的多代理辩论基线。这项工作突出了多代理辩论在推进安全关键在线环境中可靠的社会意图检测方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [65] [Aligning LLMs on a Budget: Inference-Time Alignment with Heuristic Reward Models](https://arxiv.org/abs/2508.05165)
> *在预算内对齐大型语言模型：使用启发式奖励模型进行推理时对齐*

*Mason Nakamura, Saaduddin Mahmud, Kyle H. Wray, Hamed Zamani, Shlomo Zilberstein* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** LLM对齐, 推理时对齐, 启发式奖励模型, 计算成本, 低预算

**Comment:** 

> **TL;DR:** 提出HIA，一种免调优的推理时LLM对齐方法，通过启发式奖励模型和两阶段过滤在低推理预算下保持高对齐质量，优于现有基线。

**AI_Comments:** 这篇论文通过引入启发式奖励模型和两阶段过滤，在推理时对齐LLMs方面取得了创新。其核心贡献在于能够在严格的计算预算下，显著降低推理成本，同时保持甚至超越现有的对齐质量，这对于LLM的实际部署和规模化应用具有重要意义。特别是在低推理预算下的有效性，使其成为一种极具实用价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 对齐大型语言模型（LLMs）与用户偏好对于实际应用至关重要，但通常需要昂贵的微调或推理成本，导致在对齐质量和计算成本之间进行权衡。现有的推理时方法通常忽略这种平衡，只关注优化策略的性能。

**Method:** 提出HIA（启发式引导的推理时对齐）方法，这是一种免调优、黑盒兼容的推理时对齐方法，它使用轻量级提示优化器、启发式奖励模型和两阶段过滤来减少推理调用次数，同时保持对齐质量。

**Result:** 在HelpSteer和ComPRed等真实世界提示数据集上，HIA在相同的推理预算下，在多目标、目标导向型任务中，优于best-of-N采样、束搜索和贪婪搜索基线。HIA在低推理预算下（仅需一两次响应查询）也有效。

**Conclusion:** HIA为可扩展、个性化的大型语言模型部署提供了一种实用的解决方案。

> **ai_Abstract:** 本文提出了一种名为HIA（启发式引导的推理时对齐）的新方法，旨在解决大型语言模型（LLMs）对齐中高昂的计算成本问题。HIA是一种免调优、黑盒兼容的推理时对齐方法，它利用轻量级提示优化器、启发式奖励模型和两阶段过滤来显著减少推理调用次数，同时保持甚至提高对齐质量。实验结果表明，在相同的推理预算下，HIA在多目标、目标导向型任务中优于best-of-N采样、束搜索和贪婪搜索等现有基线，并且在极低推理预算下（仅需一两次响应查询）也能有效工作，为可扩展和个性化的LLM部署提供了实用方案。

> **摘要翻译:** 将大型语言模型（LLMs）与用户偏好对齐对于实际应用至关重要，但这通常需要昂贵的微调或高成本的推理，从而迫使人们在对齐质量和计算成本之间进行权衡。现有的推理时方法通常忽略这种平衡，只专注于优化策略的性能。我们提出了HIA（启发式引导的推理时对齐），这是一种免调优、黑盒兼容的方法，它使用轻量级提示优化器、启发式奖励模型和两阶段过滤来减少推理调用次数，同时保持对齐质量。在真实世界提示数据集HelpSteer和ComPRed上，HIA在相同的推理预算下，在多目标、目标导向型任务中优于best-of-N采样、束搜索和贪婪搜索基线。我们还发现，HIA在低推理预算下（仅需一两次响应查询）也有效，为可扩展、个性化的大型语言模型部署提供了一种实用解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [66] [Diagnosing and Mitigating Modality Interference in Multimodal Large Language Models](https://arxiv.org/abs/2505.19616)
> *诊断和缓解多模态大语言模型中的模态干扰*

*Rui Cai, Bangzheng Li, Xiaofei Wen, Muhao Chen, Zhe Zhao* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 模态干扰, 多模态大语言模型, 鲁棒性, 数据增强, 一致性正则化

**Comment:** 

> **TL;DR:** 本文诊断并量化了多模态大语言模型在处理不相关模态信息时出现的“模态干扰”问题，并提出了一种基于扰动的数据增强和一致性正则化的微调框架来缓解此问题，显著提升了模型在单模态和多模态任务上的鲁棒性和性能。

**AI_Comments:** 本文识别并量化了多模态大语言模型在多模态和单模态任务中普遍存在的“模态干扰”问题，这一创新点在于明确了模型在处理跨模态信息时的深层缺陷。提出的基于扰动的数据增强和一致性正则化微调框架具有通用性，能够有效提升模型的鲁棒性和跨模态能力，对未来多模态模型的训练和应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在任务中表现出色，但它们常常难以区分任务相关和不相关的信号，特别是在视觉问答（VQA）等任务中，这导致模型容易受到误导性或虚假输入的影响。这种限制被称为“跨模态能力问题”，即模型无法公平地评估所有模态。在图像分类或纯文本问答等模态特定任务中，来自不相关模态的虚假信息常常导致性能显著下降，作者将此现象定义为“模态干扰”。

**Method:** 为了诊断和量化模态干扰问题，本文设计了一个基于扰动的因果诊断实验。为了缓解模态干扰，本文提出了一种新颖的微调MLLMs框架，该框架包括：1) 基于扰动的数据增强，使用启发式扰动和通过投影梯度下降（PGD）生成的对抗性扰动；2) 对原始输入和扰动输入对应的模型输出应用一致性正则化策略。

**Result:** 在多个基准数据集（包括图像密集型、文本密集型和VQA任务）以及不同规模的多个模型家族上的实验表明，本文提出的方法在鲁棒性和跨模态能力方面取得了显著改进，表明该方法在提升单模态推理能力的同时，也增强了多模态任务的性能。

**Conclusion:** 本文诊断并量化了多模态大语言模型中的模态干扰问题，并提出了一种有效的微调框架，通过扰动数据增强和一致性正则化显著提升了模型的鲁棒性和跨模态能力，从而改善了模型在单模态和多模态任务上的表现。

> **ai_Abstract:** 本文研究了多模态大语言模型（MLLMs）中的“模态干扰”问题，即模型在模态特定任务中受不相关模态虚假信息影响导致性能下降的现象。作者首先通过基于扰动的因果诊断实验量化了这一问题。为缓解模态干扰，提出了一种新的微调框架，该框架结合了基于启发式和对抗性扰动的数据增强，以及对原始和扰动输入输出的一致性正则化。实验证明，该方法显著提升了MLLMs在单模态推理和多模态任务中的鲁棒性和跨模态能力。

> **摘要翻译:** 多模态大语言模型（MLLMs）在各项任务中展现出令人印象深刻的能力，但它们常常难以区分任务相关和不相关的信号，特别是在视觉问答（VQA）等任务中，这可能导致模型容易受到误导性或虚假输入的影响。我们将这种更广泛的局限性称为“跨模态能力问题”：即模型无法公平地评估所有模态。这种脆弱性在诸如图像分类或纯文本问答等模态特定任务中变得更加明显，在这些任务中，模型应仅依赖于一种模态。在此类任务中，来自不相关模态的虚假信息常常导致性能显著下降。我们将这种失败称为“模态干扰”，它是跨模态能力问题的一个具体且可量化的实例。我们进一步设计了一个基于扰动的因果诊断实验来验证和量化这个问题。为了缓解模态干扰，我们提出了一种新颖的微调MLLMs框架，包括基于扰动的数据增强（结合启发式扰动和通过投影梯度下降（PGD）生成的对抗性扰动），以及应用于原始输入和扰动输入对应的模型输出的一致性正则化策略。在多个基准数据集（包括图像密集型、文本密集型和VQA任务）以及不同规模的多个模型家族上的实验表明，在鲁棒性和跨模态能力方面取得了显著改进，这表明我们的方法在提升单模态推理能力的同时，也增强了多模态任务的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [71] [The Missing Reward: Active Inference in the Era of Experience](https://arxiv.org/abs/2508.05619)
> *缺失的奖励：经验时代的活跃推理*

*Bo Wen* | **Category: cs.AI, nlin.AO, physics.bio-ph, physics.comp-ph, physics.hist-ph** | **Updated: 2025-08-07**

**Keywords:** 活跃推理, 奖励工程, 自主AI, 经验学习, 自由能

**Comment:** 

> **TL;DR:** 本文提出活跃推理（AIF）可以通过内在的自由能最小化来替代外部奖励，从而弥合当前AI系统在自主目标制定方面的“基础代理差距”，并实现真正自主的AI代理从经验中学习。

**AI_Comments:** 本文提出了一种新颖的视角，即利用活跃推理（AIF）来克服当前AI系统对人工奖励工程的过度依赖，并弥补其在自主性方面的“基础代理差距”。其创新点在于将自由能最小化作为内在驱动，替代了传统的外部奖励机制，并进一步提出将大型语言模型与AIF结合，以实现更强大的自主学习能力。这对于推动AI走向真正自主智能具有重要意义，尤其是在数据和奖励设计瓶颈日益突出的背景下。该提议为AI的未来发展提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI范式在高质量训练数据耗尽和奖励设计对大量人工劳动力的高度依赖上面临可伸缩性挑战，阻碍了迈向真正自主智能的进展。特别是，即使是“经验时代”的愿景也仍然依赖于大量人工设计的奖励函数，这导致了“基础代理差距”：当代AI系统无法自主地根据变化的环境制定、适应和追求目标。

**Method:** 本文提出活跃推理（AIF）可以通过用最小化自由能的内在驱动来替代外部奖励信号，从而弥合这一差距，使代理通过统一的贝叶斯目标自然地平衡探索与利用。通过将大型语言模型作为生成式世界模型与AIF的原则性决策框架相结合。

**Result:** 这种合成提供了一条引人注目的路径，可以创建能够高效地从经验中学习，同时与人类价值观保持一致，并在计算和物理约束下自主发展的AI系统。

**Conclusion:** 活跃推理（AIF）能够通过内在的自由能最小化来解决当前AI系统在自主目标制定上的“基础代理差距”，从而实现从经验中高效学习并与人类价值观对齐的真正自主AI代理。

> **ai_Abstract:** 本文探讨了当前AI系统在奖励工程和自主目标制定方面的挑战，特别指出了“基础代理差距”。为解决这一问题，论文提出活跃推理（AIF）作为一种解决方案，通过用内在的自由能最小化替代外部奖励，使AI代理能够从经验中自主学习并平衡探索与利用。通过将大型语言模型与AIF结合，有望构建出高效学习、符合人类价值观且真正自主的AI系统。

> **摘要翻译:** 本文认为，活跃推理（AIF）为开发能够从经验中学习而无需持续人工奖励工程的自主AI代理提供了关键基础。随着AI系统开始耗尽高质量训练数据并依赖日益庞大的人力进行奖励设计，当前范式面临着严重的扩展性挑战，这可能会阻碍迈向真正自主智能的进展。提出“经验时代”的设想，即代理从自我生成的数据中学习，是向前迈出的有希望的一步。然而，这一愿景仍然依赖于对奖励函数的大量人工工程，有效地将瓶颈从数据整理转移到奖励整理。这突出了我们所识别的“基础代理差距”：当代AI系统无法自主地根据变化的环境制定、适应和追求目标。我们提出AIF可以通过用最小化自由能的内在驱动来替代外部奖励信号，从而弥合这一差距，使代理通过统一的贝叶斯目标自然地平衡探索与利用。通过将大型语言模型作为生成式世界模型与AIF的原则性决策框架相结合，我们可以创建能够高效地从经验中学习，同时与人类价值观保持一致的代理。这种合成提供了一条引人注目的路径，可以创建能够在遵守计算和物理约束的同时自主发展的AI系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [72] [Posterior-GRPO: Rewarding Reasoning Processes in Code Generation](https://arxiv.org/abs/2508.05170)
> *Posterior-GRPO：奖励代码生成中的推理过程*

*Lishui Fan, Yu Zhang, Mouxiang Chen, Zhongxin Liu* | **Category: cs.AI, cs.CL, cs.LG, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 代码生成, 强化学习, 推理过程, 奖励作弊, 大型语言模型

**Comment:** 

> **TL;DR:** 引入了Posterior-GRPO，一个强化学习框架，通过将推理过程的奖励与任务成功相关联，以减轻奖励作弊并改进代码生成，性能优于仅基于结果的方法。

**AI_Comments:** 该论文的创新之处在于其将推理过程质量融入代码生成强化学习的新颖方法，特别是通过将基于过程的奖励与任务成功相关联来缓解奖励作弊。这直接解决了当前大型语言模型中强化学习范式的关键局限性。LCB-RB和用于奖励模型训练的OD-based方法的引入也是重要的贡献。强有力的实证结果，尤其是在性能上超越了仅基于结果的基线并与GPT-4-Turbo相媲美，突显了这项工作对于推动鲁棒和可靠代码生成的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于代码生成的强化学习（RL）范式依赖于基于测试用例的结果奖励，忽略了中间推理过程的质量。直接监督推理过程容易受到奖励作弊（reward hacking）的影响，即策略模型可能学会利用推理奖励信号而不改进最终结果。

**Method:** 1. 开发了LCB-RB基准，包含优劣推理过程的偏好对，用于推理评估。2. 引入了基于优化-降级（OD-based）的方法用于奖励模型训练，通过系统地优化和降级初始推理路径，生成高质量的推理偏好对。3. 提出了Posterior-GRPO（P-GRPO），一种新颖的RL方法，将基于过程的奖励与任务成功相关联，仅对成功结果的推理过程施加奖励，以有效缓解奖励作弊问题。

**Result:** 1. 采用OD-based方法的7B参数奖励模型在LCB-RB上达到了最先进（SOTA）的性能，并能很好地泛化到其他基准测试。2. 使用P-GRPO的7B参数模型在各种代码生成任务中取得了卓越的性能，比仅依赖结果的基线模型高出4.5%。3. P-GRPO的性能与GPT-4-Turbo相当。4. 该方法具有通用性，可扩展到数学任务。

**Conclusion:** Posterior-GRPO框架有效地将推理过程质量融入到代码生成的强化学习中，解决了奖励作弊问题并显著提高了性能，展现出强大的通用性。

> **ai_Abstract:** 本文介绍了Posterior-GRPO（P-GRPO），一个用于代码生成的新型强化学习框架，通过整合中间推理过程的质量来解决基于结果奖励的局限性。它提出了LCB-RB作为推理评估的基准，以及一种优化-降级（OD-based）方法用于训练能够准确评估推理质量的奖励模型。P-GRPO选择性地仅对成功结果的推理过程施加基于过程的奖励，有效地缓解了奖励作弊问题。实验结果表明，一个带有P-GRPO的7B参数模型在代码生成中显著优于仅基于结果的基线模型，并达到了与GPT-4-Turbo相当的性能，同时展示了对数学任务的通用性。

> **摘要翻译:** 强化学习（RL）极大地推动了大型语言模型（LLMs）的代码生成。然而，当前的范式依赖于基于测试用例的结果奖励，忽略了中间推理过程的质量。虽然直接监督推理过程是一个有前景的方向，但它极易受到奖励作弊（reward hacking）的影响，即策略模型学会利用推理奖励信号而不改进最终结果。为了解决这个问题，我们引入了一个统一的框架，可以有效地将推理过程的质量纳入RL。首先，为了实现推理评估，我们开发了LCB-RB，这是一个包含优劣推理过程偏好对的基准。其次，为了准确地评估推理质量，我们引入了一种基于优化-降级（OD-based）的方法用于奖励模型训练。该方法通过沿着推理质量的精心策划维度（如事实准确性、逻辑严谨性和连贯性）系统地优化和降级初始推理路径，生成高质量的偏好对。采用这种方法的7B参数奖励模型在LCB-RB上达到了最先进（SOTA）的性能，并能很好地泛化到其他基准测试。最后，我们引入了Posterior-GRPO（P-GRPO），一种新颖的RL方法，它将基于过程的奖励与任务成功相关联。通过仅对成功结果的推理过程选择性地应用奖励，P-GRPO有效地缓解了奖励作弊问题，并使模型的内部推理与最终代码的正确性保持一致。使用P-GRPO的7B参数模型在各种代码生成任务中取得了卓越的性能，比仅依赖结果的基线模型高出4.5%，并达到了与GPT-4-Turbo相当的性能。我们进一步通过将其扩展到数学任务来证明我们方法的通用性。我们的模型、数据集和代码都是公开可用的。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [74] [WeatherEdit: Controllable Weather Editing with 4D Gaussian Field](https://arxiv.org/abs/2505.20471)
> *WeatherEdit: 可控天气编辑与4D高斯场*

*Chenghao Qian, Wenjing Li, Yuhu Guo, Gustav Markkula* | **Category: cs.AI, cs.CV, cs.ET, cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 天气编辑, 4D高斯场, 扩散模型, 自动驾驶模拟, 可控生成

**Comment:** 

> **TL;DR:** WeatherEdit是一个新颖的管道，用于在3D场景中生成具有可控类型和严重程度的逼真天气效果，通过结合天气背景编辑和动态4D高斯场粒子构建实现。

**AI_Comments:** 这项工作通过结合扩散模型进行背景编辑和4D高斯场进行粒子生成，提供了一种新颖且全面的天气编辑解决方案。其创新点在于一体化适配器和TV-注意力机制确保了多视图和多帧的一致性，以及通过4D高斯场对天气粒子进行精确的物理建模和控制。该方法在自动驾驶模拟中的应用潜力突出，解决了生成逼真恶劣天气数据以进行模型训练和测试的关键需求。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决在3D场景中生成具有可控类型和严重程度的逼真天气效果的需求，特别是在自动驾驶模拟中的应用。

**Method:** WeatherEdit包含两个关键组件：天气背景编辑和天气粒子构建。天气背景编辑引入一个一体化适配器，将多种天气风格集成到预训练扩散模型中，并在推理时设计一个时空（TV-）注意力机制，以确保多帧和多视图图像之间的一致编辑。天气粒子构建首先使用编辑后的图像重建3D场景，然后引入动态4D高斯场来生成雪花、雨滴和雾，并通过基于物理的建模和模拟精确控制粒子属性和动态。最后，将4D高斯场与3D场景集成以渲染一致且逼真的天气效果。

**Result:** 在多个驾驶数据集上的实验表明，WeatherEdit可以生成具有可控条件严重程度的多样天气效果，突出了其在恶劣天气下自动驾驶模拟的潜力。

**Conclusion:** WeatherEdit能够生成具有可控类型和严重程度的逼真天气效果，并在自动驾驶模拟中展现出巨大潜力。

> **ai_Abstract:** WeatherEdit是一种新颖的管道，用于在3D场景中生成可控且逼真的天气效果。它通过将天气背景编辑（使用一体化适配器和TV-注意力确保一致性）与天气粒子构建（利用动态4D高斯场和物理建模进行精确控制）相结合来实现。该方法能够生成具有可控严重程度的多样化天气效果，并在自动驾驶模拟中表现出巨大潜力。

> **摘要翻译:** 在这项工作中，我们提出了WeatherEdit，一种新颖的天气编辑管道，用于在3D场景中生成具有可控类型和严重程度的逼真天气效果。我们的方法分为两个关键组成部分：天气背景编辑和天气粒子构建。对于天气背景编辑，我们引入了一个一体化适配器，将多种天气风格集成到单个预训练扩散模型中，从而能够在2D图像背景中生成多样化的天气效果。在推理过程中，我们设计了一个时空（TV-）注意力机制，它遵循特定顺序聚合时间和空间信息，确保多帧和多视图图像之间的一致编辑。为了构建天气粒子，我们首先使用编辑后的图像重建3D场景，然后引入一个动态4D高斯场来在场景中生成雪花、雨滴和雾。这些粒子的属性和动态通过基于物理的建模和模拟进行精确控制，确保逼真的天气表示和灵活的严重程度调整。最后，我们将4D高斯场与3D场景集成，以渲染一致且高度逼真的天气效果。在多个驾驶数据集上的实验表明，WeatherEdit可以生成具有可控条件严重程度的多样天气效果，突出了其在恶劣天气下自动驾驶模拟的潜力。项目页面请见：https://jumponthemoon.github.io/w-edit

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [77] [Refining Gaussian Splatting: A Volumetric Densification Approach](https://arxiv.org/abs/2508.05187)
> *精炼高斯泼溅：一种体积密度化方法*

*Mohamed Abdul Gafoor, Marius Preda, Titus Zaharia* | **Category: cs.AI, cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 3D高斯泼溅, 密度化, 体积控制, 新视图合成, 点基元管理

**Comment:** 

> **TL;DR:** 本文提出一种新的体积密度控制方法，用于改进3D高斯泼溅的重建质量。

**AI_Comments:** 本文的创新点在于引入了利用高斯函数惯性体积的密度控制方法，有效解决了3DGS中密度化策略的不足。这对于提升3DGS的新视图合成质量具有重要意义，进一步优化了点基元管理。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅（3DGS）的密度化策略存在关键缺陷，影响高质量的新视图合成。

**Method:** 本文引入了一种新颖的密度控制方法，该方法利用与每个高斯函数相关的惯性体积来指导细化过程。此外，研究了传统运动结构（SfM）和深度图像匹配（DIM）方法对点云初始化的影响。

**Result:** 在Mip-NeRF 360数据集上的广泛实验评估表明，我们的方法在重建质量上超越了3DGS，并在不同场景中展现出令人鼓舞的性能。

**Conclusion:** 所提出的体积密度化方法显著提升了3DGS的重建质量，超越了现有方法。

> **ai_Abstract:** 本文旨在解决3D高斯泼溅（3DGS）中原始密度化策略的不足，提出了一种新颖的体积密度控制方法。该方法利用高斯函数相关的惯性体积来指导细化过程，并探讨了运动结构（SfM）和深度图像匹配（DIM）在点云初始化中的作用。在Mip-NeRF 360数据集上的实验结果表明，该方法在重建质量上超越了传统的3DGS，表现出优异的性能。

> **摘要翻译:** 在3D高斯泼溅（3DGS）中实现高质量的新视图合成通常取决于有效的点基元管理。底层的自适应密度控制（ADC）过程通过自动化密度化和剪枝来解决这个问题。然而，原始的3DGS密度化策略存在关键缺陷。为了解决这个问题，本文引入了一种新颖的密度控制方法，该方法利用与每个高斯函数相关的惯性体积来指导细化过程。此外，我们研究了传统运动结构（SfM）和深度图像匹配（DIM）方法对点云初始化的影响。在Mip-NeRF 360数据集上进行的广泛实验评估表明，我们的方法在重建质量上超越了3DGS，并在不同场景中展现出令人鼓舞的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [80] [CountingFruit: Language-Guided 3D Fruit Counting with Semantic Gaussian Splatting](https://arxiv.org/abs/2506.01109)
> *计数水果：语言引导的3D水果计数与语义高斯泼溅*

*Fengze Li, Yangle Liu, Jieming Ma, Hai-Ning Liang, Yaochun Shen, Huangxiang Li, Zhijing Wu* | **Category: cs.AI, cs.CV, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 3D水果计数, 语言引导, 高斯泼溅, 语义检索, 农业场景理解

**Comment:** 

> **TL;DR:** FruitLangGS是一种语言引导的3D水果计数框架，利用语义高斯泼溅和双阈值过滤机制，在果园场景中实现高效准确的水果计数，即使在严重遮挡下也能表现出色，并可扩展到其他3D语义检索任务。

**AI_Comments:** 该论文的创新点在于将语言引导的语义信息与3D高斯泼溅技术相结合，实现了在复杂果园场景中鲁棒且高效的水果计数。其双阈值过滤机制和无需重新训练的特性显著提高了实用性。该方法不仅解决了传统多视图2D分割和体积重建的局限性，还为农业领域的自动化和精准管理提供了新的思路，尤其是在处理高遮挡场景下的3D目标识别方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在果园中准确进行3D水果计数面临挑战，原因包括严重遮挡、水果与周围结构之间的语义模糊以及体积重建的高计算成本。现有方法依赖多视图2D分割和密集体积采样，导致累积的融合误差和缓慢的推理速度。

**Method:** 本文引入FruitLangGS，一个语言引导的3D水果计数框架。它使用自适应密度高斯泼溅管线（包含半径感知剪枝和基于瓦片的栅格化）重建果园级场景，实现可扩展的3D表示。在推理过程中，通过双阈值余弦相似性机制过滤嵌入在每个高斯中的压缩CLIP对齐语义向量，检索与目标提示相关的特征，同时抑制常见的干扰物（如叶子），无需重新训练或图像空间掩码。选定的高斯然后被采样成密集点云并进行几何聚类以估计水果实例，在严重遮挡和视角变化下仍保持鲁棒性。

**Result:** 在九个不同的果园级数据集上的实验表明，FruitLangGS在实例计数召回率方面始终优于现有方法，避免了多视图分割融合误差，并在Pfuji-Size_Orch2018果园数据集上实现了高达99.7%的召回率。消融研究进一步证实，语言条件语义嵌入和双阈值提示过滤对于抑制干扰物和提高严重遮挡下的计数精度至关重要。

**Conclusion:** FruitLangGS框架不仅能进行高效准确的3D水果计数，还能在不重新训练的情况下实现提示驱动的3D语义检索，突显了语言引导的3D感知在可扩展农业场景理解方面的潜力。

> **ai_Abstract:** 本文提出了FruitLangGS，一个创新的语言引导3D水果计数框架，旨在解决果园中因遮挡、语义模糊和高计算成本导致的计数难题。该框架利用自适应密度高斯泼溅技术进行高效的3D场景重建，并通过嵌入CLIP对齐的语义向量和双阈值过滤机制，实现对目标水果的准确识别和干扰物的抑制。实验证明，FruitLangGS在多个果园数据集上显著优于现有方法，在严重遮挡下依然保持高精度，并能扩展应用于其他3D语义检索任务，展现了语言引导3D感知在农业领域的巨大潜力。

> **摘要翻译:** 在果园中准确进行3D水果计数由于严重遮挡、水果与周围结构之间的语义模糊以及体积重建的高计算成本而具有挑战性。现有管线通常依赖多视图2D分割和密集体积采样，这导致累积的融合误差和缓慢的推理。我们引入了FruitLangGS，一个语言引导的3D水果计数框架，它使用自适应密度高斯泼溅管线（包含半径感知剪枝和基于瓦片的栅格化）重建果园级场景，从而实现可扩展的3D表示。在推理过程中，嵌入在每个高斯中的压缩CLIP对齐语义向量通过双阈值余弦相似性机制进行过滤，检索与目标提示相关的特征，同时抑制常见的干扰物（例如叶子），无需重新训练或图像空间掩码。选定的高斯然后被采样成密集点云并进行几何聚类以估计水果实例，在严重遮挡和视角变化下仍保持鲁棒性。在九个不同的果园级数据集上的实验表明，FruitLangGS在实例计数召回率方面始终优于现有管线，避免了多视图分割融合误差，并在Pfuji-Size_Orch2018果园数据集上实现了高达99.7%的召回率。消融研究进一步证实，语言条件语义嵌入和双阈值提示过滤对于抑制干扰物和提高严重遮挡下的计数精度至关重要。除了水果计数，相同的框架无需重新训练即可实现提示驱动的3D语义检索，突显了语言引导的3D感知在可扩展农业场景理解方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [84] [Reinforcement Learning Generation of 4-Qubits Entangled States](https://arxiv.org/abs/2204.12351)
> *强化学习生成四量子比特纠缠态*

*Sara Giordano, Miguel A. Martin-Delgado* | **Category: cs.AI, cs.LG, quant-ph** | **Updated: 2022-10-27**

**Keywords:** 强化学习, 量子纠缠, Q-learning, 4量子比特, SLOCC类

**Comment:** 

> **TL;DR:** 本文提出一种基于Q-learning的AI算法，能生成4量子比特纠缠态的代表性状态，覆盖九个纠缠家族的至少一个真SLOCC类，并构建了对实验实现有用的最优量子电路。

**AI_Comments:** 该论文的创新点在于将强化学习（Q-learning）应用于4量子比特纠缠态的生成，并引入了状态链接图（SLG）这一图形工具来优化量子电路的构建。这为复杂量子态的自动化合成提供了一种新颖且高效的方法，对于量子计算和量子信息领域具有重要意义。其发现的优化量子电路对于实验实现具有直接的指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 构建具有4量子比特的纠缠态，生成其代表性状态，并探索其内在属性，为这些重要纠缠态的实验实现提供有用的量子电路。

**Method:** 开发了一种基于Q-learning的AI算法来构建4量子比特纠缠态。引入了状态链接图（SLG）作为图形工具，用于表示Q矩阵的构建，从而发现纠缠特征与量子门作用之间的联系。算法构建的量子电路对于所选的量子门集是最佳的。

**Result:** 该算法能够生成4量子比特纠缠态的49个真SLOCC类中的代表性状态，特别是能够为九个纠缠家族中的每一个至少达到一个真SLOCC类。发现的量子电路对于这些重要纠缠态的实验实现可能有用，并有助于得出关于宇宙内在属性的结论。

**Conclusion:** 该算法提供了一种简单、直观且有用的资源，用于自动化构建少量量子比特的纠缠态。发现的量子电路是最佳的，对实验实现和理解宇宙属性具有重要意义。

> **ai_Abstract:** 本文提出了一种基于Q-learning的AI算法，用于生成4量子比特纠缠态。该算法能生成49个真SLOCC类中的代表性状态，并能覆盖九个纠缠家族的至少一个真SLOCC类。通过引入状态链接图（SLG），算法能够优化量子电路并揭示纠缠特征与量子门作用的关系。这些发现的量子电路是最佳的，对实验实现和理解宇宙内在属性具有重要意义，提供了一种简单高效的自动化构建纠缠态的方法。

> **摘要翻译:** 我们设计了一种采用机器学习强化学习（Q-learning）的人工智能算法，用于构建具有4个量子比特的显著纠缠态。通过这种方式，该算法能够为四量子比特纠缠态的49个真SLOCC类中的一些生成代表性状态。特别是，它能够为九个纠缠家族中的每一个至少达到一个真SLOCC类。该算法合成的量子电路可能有助于这些重要纠缠态类别的实验实现，并有助于得出关于我们宇宙内在属性的结论。我们引入了一种称为状态链接图（SLG）的图形工具，用于表示算法构建给定目标状态（属于相应纠缠类）所使用的质量矩阵（Q矩阵）的构建。这使我们能够发现特定纠缠特征与算法需要包含在量子门动作集中的某些量子门作用之间的必要联系。所发现的量子电路相对于所选的量子门集而言，通过构造是最佳的。这些SLG使算法变得简单、直观，并且是自动化构建少量量子比特纠缠态的有用资源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [85] [Incident Response Planning Using a Lightweight Large Language Model with Reduced Hallucination](https://arxiv.org/abs/2508.05188)
> *使用轻量级大型语言模型减少幻觉的事件响应规划*

*Kim Hammar, Tansu Alpcan, Emil C. Lupu* | **Category: cs.AI, cs.CR** | **Updated: 2025-08-07**

**Keywords:** 事件响应, 大型语言模型, 幻觉, 网络安全, 轻量级

**Comment:** 

> **TL;DR:** 本文提出了一种使用轻量级大型语言模型进行事件响应规划的新方法，该方法通过微调、信息检索和前瞻规划来减少幻觉，并实现了更短的恢复时间。

**AI_Comments:** 该论文的创新点在于提出了一个轻量级且能有效减少幻觉的LLM事件响应规划框架，解决了现有大型LLM在实际应用中面临的成本和可靠性问题。其三步法（微调、信息检索、前瞻规划）具有清晰的逻辑，并通过理论证明和实验验证了其有效性，特别是在缩短恢复时间和泛化能力方面的表现值得关注。该研究对于将LLM应用于关键安全领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 及时有效的事件响应对于管理日益增长的网络攻击至关重要。然而，为复杂系统识别正确的响应行动是一个重大的技术挑战。虽然使用大型语言模型（LLMs）协助安全操作员处理事件是一个有前景的方法，但现有方法主要基于前沿LLMs的提示工程，这成本高昂且容易产生幻觉。

**Method:** 我们提出了一种使用LLM进行事件响应规划的新方法，旨在减少幻觉。该方法包括三个步骤：微调、信息检索和前瞻规划。我们证明了该方法生成的响应计划具有有界幻觉概率，并且在某些假设下，该概率可以以增加规划时间为代价任意减小。此外，我们的方法是轻量级的，可以在商用硬件上运行。

**Result:** 实验结果表明，我们的方法a) 比前沿LLMs的恢复时间缩短了22%；b) 能够推广到广泛的事件类型和响应行动。

**Conclusion:** 本文提出了一种新颖的、轻量级的LLM事件响应规划方法，该方法能有效减少幻觉，缩短恢复时间，并具有良好的泛化能力。

> **ai_Abstract:** 本文提出了一种使用轻量级大型语言模型（LLM）进行事件响应规划的新方法，旨在解决现有LLM方法在网络安全事件处理中成本高昂和幻觉问题。该方法通过微调、信息检索和前瞻规划三个步骤，证明了其能够生成具有有界幻觉概率的响应计划，并且可以在商用硬件上运行。实验结果显示，该方法比现有前沿LLM缩短了高达22%的恢复时间，并能泛化到多种事件类型和响应行动。

> **摘要翻译:** 及时有效的事件响应是管理日益增长的网络攻击的关键。然而，为复杂系统识别正确的响应行动是一个重大的技术挑战。缓解这一挑战的一个有前景的方法是利用大型语言模型（LLMs）中嵌入的安全知识来协助安全操作员处理事件。最近的研究已经证明了这种方法的潜力，但当前的方法主要基于前沿LLMs的提示工程，这成本高昂且容易产生幻觉。我们通过提出一种使用LLM进行事件响应规划的新颖方法来解决这些局限性，该方法减少了幻觉。我们的方法包括三个步骤：微调、信息检索和前瞻规划。我们证明了我们的方法生成的响应计划具有有界幻觉概率，并且在某些假设下，该概率可以以增加规划时间为代价任意减小。此外，我们表明我们的方法是轻量级的，可以在商用硬件上运行。我们评估了我们的方法在文献中报告的事件日志上的表现。实验结果表明，我们的方法a) 比前沿LLMs的恢复时间缩短了22%；b) 能够推广到广泛的事件类型和响应行动。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [86] [Learning to Diagnose Privately: DP-Powered LLMs for Radiology Report Classification](https://arxiv.org/abs/2506.04450)
> *隐私诊断学习：差分隐私驱动的LLMs用于放射学报告分类*

*Payel Bhattacharjee, Fengwei Tian, Geoffrey D. Rubin, Joseph Y. Lo, Nirav Merchant, Heidi Hanson, John Gounley, Ravi Tandon* | **Category: cs.AI, cs.CL, cs.CR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 差分隐私, 大型语言模型, 放射学报告, 分类, LoRA

**Comment:** 

> **TL;DR:** 本研究提出使用差分隐私（DP）微调大型语言模型（LLMs），以对放射学报告进行多异常分类，同时保护患者数据隐私。

**AI_Comments:** 这项研究通过将差分隐私与LoRA技术相结合，为在敏感医疗数据上训练大型语言模型提供了一个创新且实用的解决方案。它有效地平衡了数据隐私保护和模型性能，对于推动医疗AI在临床应用中的落地具有重要意义。该方法有望减少数据泄露风险，同时保持诊断的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 解决在敏感患者数据上微调大型语言模型（LLMs）时面临的隐私风险和数据泄露问题，同时努力保持分类性能。

**Method:** 研究使用了50,232份放射学报告，来源于MIMIC-CXR和CT-RATE数据集。采用差分隐私低秩适应（DP-LoRA）技术对LLMs进行微调，以分类MIMIC-CXR的14个标签和CT-RATE的18个标签。模型性能通过加权F1分数进行评估，涉及BERT-medium、BERT-small和ALBERT-base三种模型架构，并在高、中等隐私预算（0.01、0.1、1.0、10.0）下进行实验，以量化隐私-效用权衡。

**Result:** 实验在两个数据集和三种模型上均观察到明显的隐私-效用权衡。在中等隐私保证下，DP微调模型在MIMIC-CXR数据集上取得了0.88的加权F1分数，在CT-RATE数据集上取得了0.59的加权F1分数，与非隐私LoRA基线（分别为0.90和0.78）相比具有可比性。

**Conclusion:** 使用LoRA进行差分隐私微调能够实现对放射学报告的有效且隐私保护的多异常分类，解决了在敏感医疗数据上微调LLMs的关键挑战。

> **ai_Abstract:** 本研究提出一种结合差分隐私（DP）和低秩适应（LoRA）的框架，用于微调大型语言模型（LLMs），以在保护患者隐私的同时对放射学报告进行多异常分类。研究使用MIMIC-CXR和CT-RATE数据集，对BERT和ALBERT等模型进行DP-LoRA微调，并在不同隐私预算下评估其性能。结果表明，尽管存在隐私-效用权衡，但在中等隐私保证下，DP微调模型仍能达到与非隐私基线相当的分类性能，有效解决了敏感医疗数据上LLM微调的隐私挑战。

> **摘要翻译:** 目的：本研究提出一个框架，用于利用差分隐私（DP）微调大型语言模型（LLMs），以对放射学报告文本进行多异常分类。通过在微调过程中注入校准噪声，该框架旨在减轻与敏感患者数据相关的隐私风险，并防止数据泄露，同时保持分类性能。材料和方法：我们使用了从2011年至2019年收集的50,232份放射学报告，这些报告来自公开可用的MIMIC-CXR胸部X射线和CT-RATE计算机断层扫描数据集。LLMs的微调旨在利用差分隐私低秩适应（DP-LoRA）在高和中等隐私制度（隐私预算范围为{0.01, 0.1, 1.0, 10.0}）下分类MIMIC-CXR数据集的14个标签和CT-RATE数据集的18个标签。模型性能使用加权F1分数在三种模型架构（BERT-medium、BERT-small和ALBERT-base）上进行评估。统计分析比较了不同隐私水平下的模型性能，以量化隐私-效用权衡。结果：我们在两个不同数据集和三个不同模型上的实验中观察到明显的隐私-效用权衡。在中等隐私保证下，DP微调模型在MIMIC-CXR上取得了0.88的加权F1分数，在CT-RATE上取得了0.59的加权F1分数，与非隐私LoRA基线（分别为0.90和0.78）相比具有可比性。结论：使用LoRA进行差分隐私微调能够实现对放射学报告的有效且隐私保护的多异常分类，解决了在敏感医疗数据上微调LLMs的关键挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [91] [Evaluating the Use of LLMs for Documentation to Code Traceability](https://arxiv.org/abs/2506.16440)
> *评估大型语言模型在文档到代码可追溯性中的应用*

*Ebube Alor, SayedHassan Khatoonabadi, Emad Shihab* | **Category: cs.AI, cs.LG, cs.SE** | **Updated: 2025-06-19**

**Keywords:** 大型语言模型, 文档可追溯性, 代码可追溯性, 软件工程, 评估

**Comment:** 

> **TL;DR:** 该研究全面评估了大型语言模型（LLMs）在构建软件文档到源代码可追溯性链接方面的能力，发现LLMs表现优于基线模型，但仍存在局限性，需要人工参与和进一步研究。

**AI_Comments:** 这项研究创新性地全面评估了当前主流LLMs在文档到代码可追溯性这一关键软件工程任务中的表现，填补了现有研究的空白。其重要性在于，它不仅量化了LLMs在该领域的有效性（F1分数远超基线），还深入分析了其局限性和错误模式（如命名假设、过度泛化），为未来改进LLMs及其应用提供了宝贵的见解。研究强调了任务框架的关键作用，并指出未来工具设计可能需要结合人机协作，这对于实际应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自动化文档到代码的可追溯性方面展现出新的潜力，但其能力尚未得到充分探索。

**Method:** 研究团队对Claude 3.5 Sonnet、GPT-4o和o3-mini等LLMs进行了全面评估，旨在建立各种软件文档（包括API参考和用户指南）与源代码之间的追溯链接。为此，他们从两个开源项目（Unity Catalog和Crawl4AI）创建了两个新颖的数据集，并通过系统实验评估了LLMs的三项关键能力：1) 追溯链接识别准确性，2) 关系解释质量，以及3) 多步骤链重建。

**Result:** 表现最佳的LLM在两个数据集上分别取得了79.4%和80.4%的F1分数，显著优于基线模型（TF-IDF、BM25和CodeBERT）。完全正确的关系解释准确率介于42.9%至71.1%之间，但部分准确率超过97%，表明基本连接很少被遗漏。对于多步骤链，LLMs在保持高终点准确性的同时，在捕获精确的中间链接方面存在差异。误差分析显示，许多误报源于基于命名的假设、虚假链接或架构模式的过度泛化。研究还表明，任务框架（例如一对多匹配策略）对性能至关重要。

**Conclusion:** 研究结果表明，大型语言模型是追溯发现的强大辅助工具，但它们的局限性可能需要“人机协作”的工具设计，并为未来的研究指明了具体的错误模式。

> **ai_Abstract:** 本研究全面评估了大型语言模型（LLMs）在自动化软件文档到代码可追溯性方面的能力。通过对Claude 3.5 Sonnet、GPT-4o和o3-mini等LLMs在两个新颖数据集上的实验，研究发现LLMs在链接识别准确性方面显著优于传统基线模型。尽管在关系解释和多步骤链重建方面存在一定局限性，但LLMs展现出作为追溯发现强大助手的潜力。研究还揭示了LLMs的常见错误模式，并强调了任务框架的重要性，为未来结合人工参与的工具设计和误差模式研究提供了方向。

> **摘要翻译:** 大型语言模型（LLMs）为自动化文档到代码的可追溯性提供了新的潜力，但其能力仍未得到充分探索。我们对LLMs（Claude 3.5 Sonnet、GPT-4o和o3-mini）在建立各种软件文档（包括API参考和用户指南）与源代码之间的追溯链接方面的能力进行了全面评估。我们从两个开源项目（Unity Catalog和Crawl4AI）创建了两个新颖的数据集。通过系统实验，我们评估了三项关键能力：(1) 追溯链接识别准确性，(2) 关系解释质量，以及(3) 多步骤链重建。结果显示，表现最佳的LLM在两个数据集上分别取得了79.4%和80.4%的F1分数，显著优于我们的基线模型（TF-IDF、BM25和CodeBERT）。虽然完全正确的关系解释准确率介于42.9%至71.1%之间，但部分准确率超过97%，表明基本连接很少被遗漏。对于多步骤链，LLMs在保持高终点准确性的同时，在捕获精确的中间链接方面存在差异。误差分析显示，许多误报源于基于命名的假设、虚假链接或架构模式的过度泛化。我们证明，任务框架（例如一对多匹配策略）对性能至关重要。这些发现将LLMs定位为追溯发现的强大辅助工具，但其局限性可能需要“人机协作”的工具设计，并为未来的研究指明了具体的错误模式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [92] [Balancing Accuracy and Novelty with Sub-Item Popularity](https://arxiv.org/abs/2508.05198)
> *平衡准确性和新颖性与子项流行度*

*Chiara Mallamaci, Aleksandr Vladimirovich Petrov, Alberto Carlo Maria Mancino, Vito Walter Anelli, Tommaso Di Noia, Craig Macdonald* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 音乐推荐, 个性化流行度, 新颖性, 准确性, 子项分解

**Comment:** 

> **TL;DR:** 该研究通过在RecJPQ框架中引入子ID级别的个性化流行度（sPPS），在音乐推荐系统中实现了准确性和新颖性的平衡，显著提高了新颖性而未损害准确性。

**AI_Comments:** 该论文的创新之处在于利用子项分解来建模更细粒度的个性化流行度，这是一种新颖的方法，有效解决了推荐系统中常见的准确性与新颖性之间的困境，特别适用于音乐领域中重复收听的模式。通过在子ID层面操作，模型能够捕捉到传统项目级方法无法发现的潜在用户偏好。

<details>
  <summary>Details</summary>

**Motivation:** 在音乐推荐领域，个性化流行度分数（PPS）虽然能增强推荐的相关性，但往往会强化用户已知内容，限制了系统推荐新颖或意外项目的能力。而新颖性是促进用户长期参与和满意度的关键因素，因此需要解决PPS在提供新颖性方面的局限性。

**Method:** 研究基于Transformer框架RecJPQ，利用其子项分解架构，将个性化流行度建模到更细粒度的子ID级别。通过在RecJPQ框架中整合子ID级别的个性化流行度（sPPS），该方法能够捕获跨子嵌入的共享重复模式，并明确控制准确性和个性化新颖性之间的权衡。

**Result:** 提出的子ID级别个性化流行度方法（sPPS）在不损害推荐准确性的前提下，始终显著优于项目级别个性化流行度（item-level PPS），实现了更高的个性化新颖性。

**Conclusion:** 通过在RecJPQ框架中引入子ID级别的个性化流行度，可以有效地在音乐推荐中平衡准确性和新颖性，显著提升用户体验。

> **ai_Abstract:** 该论文旨在解决音乐推荐中准确性和新颖性之间的平衡问题。现有方法如个性化流行度分数（PPS）虽然提高了相关性，但却限制了新颖内容的发现。为解决此问题，作者在RecJPQ框架中引入了子ID级别的个性化流行度（sPPS）。该方法利用RecJPQ的子项分解架构，以更细粒度建模流行度，从而捕获潜在的共享重复模式，并能够明确控制准确性和新颖性之间的权衡。实验结果表明，sPPS在不牺牲推荐准确性的前提下，显著提升了个性化新颖性。

> **摘要翻译:** 在音乐推荐领域，序列推荐器在捕捉音乐消费的动态性方面展现出前景。该领域的一个关键特征是重复收听，用户频繁重播熟悉的曲目。为了捕捉这些重复模式，最近的研究引入了个性化流行度分数（PPS），它根据历史频率量化用户特定的偏好。虽然PPS增强了推荐的相关性，但它通常会强化已知内容，限制了系统呈现新颖或意外项目的能力——而这些是培养长期用户参与和满意度的关键要素。为了解决这一局限性，我们以RecJPQ为基础，这是一个最初为通过子项分解提高大型项目目录的可扩展性而开发的基于Transformer的框架。我们重新利用RecJPQ的子项架构，以更细的粒度对个性化流行度进行建模。这使我们能够捕获跨子嵌入的共享重复模式——这是仅通过项目级流行度无法获得的潜在结构。我们提出了一种在RecJPQ框架内整合子ID级别个性化流行度的新颖方法，从而能够明确控制准确性和个性化新颖性之间的权衡。我们的子ID级别PPS方法（sPPS）通过在不损害推荐准确性的情况下实现显著更高的个性化新颖性，始终优于项目级PPS。代码和实验已公开于https://github.com/sisinflab/Sub-id-Popularity。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [93] [MOGO: Residual Quantized Hierarchical Causal Transformer for High-Quality and Real-Time 3D Human Motion Generation](https://arxiv.org/abs/2506.05952)
> *MOGO：用于高质量实时3D人体运动生成的残差量化分层因果变换器*

*Dongjie Fu, Tengjiao Sun, Pengcheng Fang, Xiaohao Cai, Hansung Kim* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D人体运动生成, 残差量化, 变换器, 实时生成, 自回归框架

**Comment:** 

> **TL;DR:** MOGO是一种新型自回归框架，通过引入MoSA-VQ和RQHC-Transformer，实现了高质量、实时、可流式传输的3D人体运动生成，显著降低了推理延迟并提升了性能。

**AI_Comments:** MOGO的创新之处在于其双组件设计：MoSA-VQ实现了高效紧凑的运动表示，而RQHC-Transformer则通过单次前向传播显著提升了推理速度，解决了实时性难题。文本条件对齐机制进一步确保了生成运动与文本语义的高度一致性。该工作对于实时应用场景下的高质量3D人体运动生成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于变换器的文本到运动生成取得了进展，但同时实现高保真度、流式传输能力、实时响应和可扩展性仍然是一个基本挑战。

**Method:** 本文提出了MOGO（一次性运动生成），一个用于高效实时3D运动生成的自回归框架。MOGO包含两个核心组件：1) MoSA-VQ，一个运动尺度自适应残差向量量化模块，用于分层离散化运动序列以生成紧凑而富有表现力的表示；2) RQHC-Transformer，一个残差量化分层因果变换器，能够单次前向传播生成多层运动令牌，显著减少推理延迟。此外，还引入了文本条件对齐机制以增强语义保真度。

**Result:** MOGO在HumanML3D、KIT-ML和CMP等基准数据集上进行了广泛实验，结果表明，与最先进的基于变换器的方法相比，MOGO实现了有竞争力或更优的生成质量，并在实时性能、流式生成和零样本设置下的泛化能力方面有显著提升。

**Conclusion:** MOGO框架通过其创新的MoSA-VQ和RQHC-Transformer组件，成功解决了3D人体运动生成中高保真度、实时性、流式传输和可扩展性的挑战，并在多个方面超越了现有技术。

> **ai_Abstract:** MOGO是一种新颖的自回归框架，旨在解决3D人体运动生成中高保真度、实时性和可扩展性的挑战。它包含MoSA-VQ模块用于高效运动表示，以及RQHC-Transformer用于单次前向传播生成多层运动令牌，显著降低推理延迟。此外，MOGO还引入了文本条件对齐机制以增强语义保真度。实验证明，MOGO在生成质量上与现有SOTA方法相当或更优，并在实时性能、流式生成和零样本泛化方面表现出色。

> **摘要翻译:** 基于变换器的文本到运动生成技术的最新进展，在合成高质量人体运动方面取得了令人瞩目的进步。然而，同时实现高保真度、流式传输能力、实时响应和可扩展性仍然是一个根本性挑战。在本文中，我们提出了MOGO（一次性运动生成），一个专为高效实时3D运动生成量身定制的新型自回归框架。MOGO包含两个关键组件：(1) MoSA-VQ，一个运动尺度自适应残差向量量化模块，它通过可学习的缩放分层离散化运动序列，以产生紧凑而富有表现力的表示；(2) RQHC-Transformer，一个残差量化分层因果变换器，它能在单次前向传播中生成多层运动令牌，显著减少推理延迟。为了增强语义保真度，我们进一步引入了一种文本条件对齐机制，以改善文本控制下的运动解码。在HumanML3D、KIT-ML和CMP等基准数据集上进行的广泛实验表明，与最先进的基于变换器的方法相比，MOGO实现了有竞争力或更优的生成质量，同时在实时性能、流式生成和零样本设置下的泛化能力方面提供了显著的改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [98] [How Robust are LLM-Generated Library Imports? An Empirical Study using Stack Overflow](https://arxiv.org/abs/2507.10818)
> *LLM生成的库导入有多健壮？一项基于Stack Overflow的实证研究*

*Jasmine Latendresse, SayedHassan Khatoonabadi, Emad Shihab* | **Category: cs.AI, cs.LG, cs.SE** | **Updated: 2025-07-14**

**Keywords:** LLM, 库导入, 实证研究, Stack Overflow, 依赖管理

**Comment:** 

> **TL;DR:** 一项对六个LLM的实证研究发现，它们在生成库导入时倾向于推荐成熟的第三方库，但存在可用性问题，如4.6%的库无法自动解析，且多数模型未提供安装指导，增加了用户手动解决依赖的负担。

**AI_Comments:** 这项研究通过对LLM生成的库导入进行实证分析，揭示了LLM在代码生成实用性方面的关键限制，特别是关于依赖管理。其创新之处在于量化了LLM推荐库的可用性差距，并明确指出了未来的改进方向，对LLM开发者和使用LLM的程序员都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着开发者越来越多地使用大型语言模型（LLMs）协助编程任务，理解这些模型如何推荐库变得至关重要，因为软件库是现代代码功能、安全性和可维护性的核心。

**Method:** 本研究对六个最先进的LLM（包括专有和开源模型）进行了实证研究。研究人员通过让这些LLM解决源自Stack Overflow的真实世界Python问题，分析了它们导入的库类型、这些库的特性以及推荐的开箱即用可用性。

**Result:** 研究结果显示，LLM主要偏爱第三方库而非标准库，并且通常推荐成熟、流行且许可宽松的依赖项。然而，研究也发现可用性方面的不足：4.6%的库由于导入名称与可安装包之间的结构不匹配而无法自动解析，并且只有两个模型（六个中）提供了安装指导。尽管生成的代码在技术上是有效的，但缺乏上下文支持将手动解决依赖的负担转嫁给了用户。

**Conclusion:** LLM生成的代码在库导入方面存在可用性挑战，尤其是在依赖解析和安装指导方面。研究结果为开发者和研究人员提供了可操作的见解，并强调了在软件依赖方面提高LLM生成代码可靠性和可用性的机会。

> **ai_Abstract:** 这项实证研究评估了六个LLM在生成Python库导入时的鲁棒性。研究发现，LLM倾向于推荐成熟且流行的第三方库，但在可用性方面存在显著缺陷，例如约4.6%的推荐库无法自动解析，且大多数模型未能提供安装指导。这导致用户需要手动解决依赖问题。研究强调了改进LLM生成代码在软件依赖方面可靠性和可用性的必要性。

> **摘要翻译:** 软件库是现代代码功能、安全性及可维护性的核心。随着开发者越来越多地转向大型语言模型（LLMs）来辅助编程任务，理解这些模型如何推荐库变得至关重要。本文对六个最先进的LLM（包括专有和开源模型）进行了一项实证研究，通过提示它们解决源自Stack Overflow的真实世界Python问题。我们分析了它们导入的库类型、这些库的特性以及推荐的开箱即用可用性。我们的结果显示，LLM主要偏爱第三方库而非标准库，并且通常推荐成熟、流行且许可宽松的依赖项。然而，我们也发现了可用性方面的不足：4.6%的库由于导入名称与可安装包之间的结构不匹配而无法自动解析，并且只有两个模型（六个中）提供了安装指导。尽管生成的代码在技术上是有效的，但缺乏上下文支持将手动解决依赖的负担转嫁给了用户。我们的发现为开发者和研究人员提供了可操作的见解，并强调了在软件依赖方面提高LLM生成代码可靠性和可用性的机会。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [99] [EvoGraph: Hybrid Directed Graph Evolution toward Software 3.0](https://arxiv.org/abs/2508.05199)
> *EvoGraph：迈向软件3.0的混合有向图演化*

*Igor Costa, Christopher Baran* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 软件演化, 有向图, 小型语言模型, 软件现代化, 软件3.0

**Comment:** 

> **TL;DR:** EvoGraph是一个框架，它使软件系统能够通过有向图、小型语言模型和多目标适应度来自我演化源代码、构建管道、文档和工单，并在安全修复、语言转换和文档维护方面表现出色，为软件3.0提供了一条实用路径。

**AI_Comments:** EvoGraph的创新之处在于其将软件演化建模为有向图，并结合了专门的小型语言模型（SLMs）和多目标优化，实现了软件系统的自我修复、转换和维护。这种混合方法不仅解决了传统软件现代化中的挑战，还通过降低计算成本和提高效率，为迈向“软件3.0”提供了一条实用且有前景的路径。其在多个基准上的显著性能提升，特别是与大型语言模型相比的成本效益，凸显了其潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为了解决传统现代化中遇到的经验性故障模式，例如隐式契约、性能保持和集成演化，并探索软件系统持续自适应的可能性。

**Method:** EvoGraph框架通过将所有软件制品表示为类型化有向图，应用由专门的小型语言模型（SLMs）驱动的学习突变算子，并通过多目标适应度选择幸存者。该方法还扩展到使用特定语言的SLMs进行代码现代化。

**Result:** EvoGraph在三个基准测试中修复了83%的已知安全漏洞，以93%的功能等效性将COBOL转换为Java，并在两分钟内保持文档新鲜度。与强基线相比，延迟降低了40%，功能交付时间缩短了七倍。在现代化多种语言的代码库时，实现了82-96%的语义等效性，同时计算成本比大型语言模型降低了90%。

**Conclusion:** EvoGraph的结果表明，通过其设计和能力，提供了一条迈向软件3.0的实用路径，即系统能够持续适应但仍处于可测量的控制之下。

> **ai_Abstract:** EvoGraph是一个创新框架，旨在通过自我演化实现软件3.0。它将软件制品建模为有向图，利用小型语言模型驱动的变异操作和多目标适应度进行演化。实验证明，EvoGraph在安全修复、跨语言转换和文档维护方面表现卓越，显著提升了效率并降低了成本，为软件系统的持续适应性提供了可行方案。

> **摘要翻译:** 我们引入了EvoGraph，这是一个使软件系统能够演化其自身源代码、构建管道、文档和工单的框架。EvoGraph将每个制品表示为类型化有向图，应用由专门小型语言模型（SLMs）驱动的学习突变算子，并以多目标适应度选择幸存者。在三个基准测试中，EvoGraph修复了83%的已知安全漏洞，以93%的功能等效性（经测试验证）将COBOL转换为Java，并在两分钟内保持文档新鲜度。实验表明，与强基线相比，延迟降低了40%，功能交付时间缩短了七倍。我们将我们的方法扩展到evoGraph，利用特定语言的SLMs来现代化.NET、Lisp、CGI、ColdFusion、遗留Python和C代码库，在各种语言之间实现了82-96%的语义等效性，同时计算成本比大型语言模型降低了90%。EvoGraph的设计响应了传统现代化中的经验性故障模式，例如隐式契约、性能保持和集成演化。我们的结果表明，迈向软件3.0的实用路径，即系统能够持续适应但仍处于可测量的控制之下。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [100] [Enabling On-Device Medical AI Assistants via Input-Driven Saliency Adaptation](https://arxiv.org/abs/2506.11105)
> *通过输入驱动显著性适应实现设备端医疗AI助手*

*Uttej Kallakurik, Edward Humes, Rithvik Jonna, Xiaomin Lin, Tinoosh Mohsenin* | **Category: cs.AI, cs.AR, cs.CL, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 设备端AI, 模型压缩, 神经元显著性, 医疗AI

**Comment:** 

> **TL;DR:** 通过基于显著性的剪枝和量化来压缩大型语言模型，使其能够在资源受限的边缘设备上实现实时、节能的医疗AI推理。

**AI_Comments:** 该论文为在边缘设备上部署大型语言模型以实现医疗AI提供了创新且实用的解决方案，这对于实时医疗应用至关重要。利用输入驱动的显著性进行剪枝并结合量化是一种巧妙的方法，可在保持性能的同时实现显著压缩。这项工作解决了将先进AI引入资源有限环境的关键瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）对医疗保健领域影响显著，但其庞大的规模使其难以在实时、资源受限的边缘设备上部署。

**Method:** 该研究引入了一种通用的压缩框架，通过测量领域特定数据上的神经元显著性来积极剪枝不相关的神经元，以减小模型大小并保持性能。随后应用训练后量化来进一步减少内存占用。

**Result:** 模型大小显著减小（Gemma压缩50%，LLaMA3压缩67%），同时保持了性能。成功在Jetson Orin Nano和Raspberry Pi 5等边缘设备上部署，实现了硬件约束下的实时、节能推理。

**Conclusion:** 该方法成功地使大型语言模型能够作为医疗AI助手部署在资源受限的边缘设备上，实现了实时和节能的推理。

> **ai_Abstract:** 本文提出了一种新颖的医疗AI助手系统，旨在优化大型语言模型（LLMs）以实现在资源受限环境中的设备端部署。该系统引入了一个通用的压缩框架，利用输入驱动的神经元显著性在领域特定数据上进行积极剪枝，随后进行训练后量化。这种方法显著减小了模型大小并保持了性能，使得压缩后的LLMs（如Gemma和LLaMA3）能够在Jetson Orin Nano和Raspberry Pi 5等边缘设备上实现实时、节能的推理，并通过医疗基准进行了验证。

> **摘要翻译:** 大型语言模型（LLMs）对医疗保健场景产生了重大影响，但对于在实时、资源受限的环境（如边缘设备）中部署而言，其规模仍然过大。在这项工作中，我们引入了一种新颖的医疗助手系统，通过我们通用的压缩框架进行优化，该框架为在特定领域部署大型语言模型（LLMs）进行了定制。通过测量领域特定数据上的神经元显著性，我们的方法可以积极剪枝不相关的神经元，在保持性能的同时减小模型大小。剪枝后，我们应用训练后量化以进一步减少内存占用，并在包括MedMCQA、MedQA和PubMedQA在内的医疗基准上评估压缩模型。我们还在Jetson Orin Nano（峰值18.7W）和Raspberry Pi 5（峰值6.3W）上部署了50%压缩的Gemma和67%压缩的LLaMA3模型，在硬件限制下实现了实时、节能的推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [105] [FAITH: A Framework for Assessing Intrinsic Tabular Hallucinations in finance](https://arxiv.org/abs/2508.05201)
> *FAITH：一个评估金融领域内在表格幻觉的框架*

*Mengao Zhang, Jiayu Fu, Tanya Warrier, Yuwen Wang, Tianhui Tan, Ke-wei Huang* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 金融LLM, 表格幻觉, FAITH框架, 金融AI, 数据集创建

**Comment:** 

> **TL;DR:** 本文提出了FAITH框架，用于评估金融领域大型语言模型（LLMs）的内在表格幻觉，通过构建新的数据集和评估方法，旨在提高金融AI系统的可靠性。

**AI_Comments:** 该论文通过提出FAITH框架，填补了金融领域LLM幻觉评估的空白，特别强调了金融数据特有的上下文、数值和专有性。其创新之处在于自动化数据集创建范式和基于真实金融文档的评估方法，为提高金融AI的可靠性提供了实际可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在金融领域的部署面临幻觉这一关键挑战。从表格数据中准确提取和精确计算对可靠的金融分析至关重要，因为即使是微小的数字错误也可能影响决策和合规性。现有幻觉基准很少捕捉金融应用对上下文、数值和专有表格数据的独特需求。

**Method:** 本研究开发了一个严格且可扩展的框架FAITH，用于评估金融LLMs的内在幻觉，将其概念化为对真实世界金融文档的上下文感知掩码跨度预测任务。主要贡献包括：(1) 一种新颖的、使用掩码策略的自动化数据集创建范式；(2) 一个源自标准普尔500年度报告的新幻觉评估数据集；(3) 对最先进LLMs在金融表格数据上内在幻觉模式的全面评估。

**Result:** 本文对最先进LLMs在金融表格数据上的内在幻觉模式进行了全面评估。

**Conclusion:** 我们的工作为内部LLM评估提供了一种稳健的方法，是构建更值得信赖和可靠的金融生成式AI系统的关键一步。

> **ai_Abstract:** 本文介绍了FAITH框架，旨在解决大型语言模型（LLMs）在金融领域处理表格数据时产生的内在幻觉问题。由于金融分析对准确性有极高要求，作者提出了一种新的、可扩展的评估方法，将幻觉评估视为上下文感知的掩码跨度预测任务。研究贡献包括创新的自动化数据集创建范式、基于S&P 500年度报告的新评估数据集，以及对现有LLMs在金融表格数据上幻觉模式的全面评估。这项工作为构建更可靠的金融生成式AI系统提供了关键的评估工具和方法。

> **摘要翻译:** 幻觉仍然是大型语言模型（LLMs）在金融领域部署面临的关键挑战。从表格数据中准确提取和精确计算对于可靠的金融分析至关重要，因为即使是微小的数字错误也可能影响决策和监管合规性。金融应用具有独特的要求，通常依赖于现有幻觉基准很少捕获的上下文相关、数值化和专有表格数据。在本研究中，我们开发了一个严格且可扩展的框架，用于评估金融LLMs中的内在幻觉，将其概念化为对真实世界金融文档的上下文感知掩码跨度预测任务。我们的主要贡献是：(1) 一种新颖的、使用掩码策略的自动化数据集创建范式；(2) 一个源自标准普尔500年度报告的新幻觉评估数据集；以及(3) 对最先进LLMs在金融表格数据上内在幻觉模式的全面评估。我们的工作为内部LLM评估提供了一种稳健的方法，是构建更值得信赖和可靠的金融生成式AI系统的关键一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [106] [Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis](https://arxiv.org/abs/2507.16641)
> *混合奖励驱动的强化学习用于高效量子电路合成*

*Sara Giordano, Kornikar Sen, Miguel A. Martin-Delgado* | **Category: cs.AI, cs.LG, quant-ph** | **Updated: 2025-07-22**

**Keywords:** 量子电路合成, 强化学习, Q-learning, 混合奖励, 量子状态空间

**Comment:** 

> **TL;DR:** 该研究引入了一种混合奖励驱动的强化学习框架，通过离散化量子状态空间和Q-learning，高效合成最小深度量子电路，解决量子电路合成的核心挑战。

**AI_Comments:** 该论文的创新点在于其提出的混合奖励机制，它有效地结合了领域知识指导和对低效电路结构的惩罚。同时，通过状态空间离散化和稀疏矩阵表示来处理量子状态空间的指数级增长，是其技术亮点。这项工作对于量子电路优化至关重要，为实现资源高效的量子计算提供了新的路径。

<details>
  <summary>Details</summary>

**Motivation:** 解决NISQ时代和未来容错量子计算中高效量子电路合成的核心挑战，即从固定初始状态生成指定目标量子态。

**Method:** 该方法引入了一个强化学习框架，利用基于动作序列的表格Q-learning，在离散化的量子状态空间中进行操作。它采用了一种混合奖励机制，结合了指导智能体朝向目标状态的静态领域知情奖励，以及惩罚低效电路结构（如门拥堵和冗余状态重访）的可定制动态惩罚。通过利用稀疏矩阵表示和状态空间离散化，该方法实现了高维环境的可扩展导航并最小化计算开销。

**Result:** 在多达七个量子位的图态准备任务上进行基准测试，该算法持续发现具有优化门计数的最小深度电路。此外，将该框架扩展到用于任意量子态的通用门集，它仍然能生成最小深度电路，突出了算法的鲁棒性和适应性。

**Conclusion:** 该强化学习驱动的方法能高效探索复杂的量子状态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

> **ai_Abstract:** 本文提出了一种基于强化学习的框架，用于高效合成量子电路，以解决量子计算中的核心挑战。该框架结合了表格Q-learning、离散化量子状态空间以及创新的混合奖励机制（包含静态领域知情奖励和动态惩罚），有效管理了状态空间的指数增长并避免低效结构。实验证明，该方法能稳定生成最小深度且门计数优化的电路，并对通用门集具有良好的鲁棒性和适应性，为量子电路优化提供了高效且资源节约的解决方案。

> **摘要翻译:** 本研究引入了一种强化学习（RL）框架，用于高效合成量子电路，这些电路能从固定初始状态生成指定的目标量子态，解决了NISQ时代和未来容错量子计算中的一个核心挑战。该方法在离散化的量子状态空间中利用基于动作序列的表格Q-learning，有效管理状态空间的指数级增长。该框架引入了一种混合奖励机制，结合了引导智能体朝向目标状态的静态领域知情奖励，以及惩罚低效电路结构（如门拥堵和冗余状态重访）的可定制动态惩罚。通过利用稀疏矩阵表示和状态空间离散化，该方法能够实现高维环境的可扩展导航，同时最大限度地减少计算开销。在多达七个量子位的图态准备任务上进行基准测试，我们证明该算法能持续发现具有优化门计数的最小深度电路。此外，将该框架扩展到用于任意量子态的通用门集时，它仍然能生成最小深度电路，突显了算法的鲁棒性和适应性。结果证实，这种RL驱动的方法能够高效探索复杂的量子状态空间并合成接近最优的量子电路，为量子电路优化提供了资源高效的基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [108] [Unsupervised deep learning model for fast energy layer pre-selection of delivery-efficient proton arc therapy plan optimization of nasopharyngeal carcinoma](https://arxiv.org/abs/2506.15803)
> *用于鼻咽癌递送高效质子弧治疗计划优化中快速能量层预选择的无监督深度学习模型*

*Bohan Yang, Gang Liu, Yang Zhong, Rirao Dao, Yujia Qian, Ke Shi, Anke Tang, Yong Luo, Qi Kong, Jingnan Liu* | **Category: cs.AI, physics.med-ph** | **Updated: 2025-08-07**

**Keywords:** 质子弧治疗, 能量层预选择, 无监督深度学习, 鼻咽癌, 治疗优化

**Comment:** 

> **TL;DR:** 一个无监督深度学习模型（SPArc_dl）能够快速预选择质子弧治疗的能量层，显著提高鼻咽癌治疗计划质量并缩短治疗递送时间。

**AI_Comments:** 该论文的创新点在于提出了“点计数表示”这一新颖的数据表示方法，并将无监督深度学习应用于质子弧治疗的能量层预选择任务，有效解决了传统方法计算量大、治疗时间长的问题。SPArc_dl在速度和计划质量上均表现出显著优势。然而，其在鲁棒性方面的局限性是未来研究需要解决的关键问题。意外发现的关于ELS效率的结论也很有趣。

<details>
  <summary>Details</summary>

**Motivation:** 质子弧治疗（PAT）是放射治疗中的一种新兴且有前景的模式，但识别最佳能量层（EL）序列由于计算需求大和治疗递送时间延长而具有挑战性。

**Method:** 本研究提出了一种无监督深度学习模型SPArc_dl，用于快速EL预选择。它引入了新颖的“点计数表示”方法，将质子点数编码为矩阵作为U-Net风格架构的输入。模型使用三目标函数进行训练：最大化目标区域点计数、最小化危及器官（OAR）点计数以及减少EL切换时间。模型在35例鼻咽癌病例上进行了评估，并与SPArc_particle_swarm (SPArc_ps) 进行了比较。

**Result:** SPArc_dl生成的EL预选择显著提高了计划质量和递送效率。与SPArc_ps相比，它将适形指数提高了0.1 (p<0.01)，均匀性指数降低了0.71 (p<0.01)，脑干平均剂量降低了0.25 (p<0.01)，并将EL切换时间缩短了37.2% (p < 0.01)。SPArc_dl的推理时间在1秒内。结果意外地揭示了采用不变的ELS比下降的ELS在时间上更有效。然而，SPArc_dl计划在鲁棒性方面存在局限性。

**Conclusion:** SPArc_dl是一种快速工具，通过策略性预选择EL来减少递送时间，同时保持优异的剂量学性能，从而生成高质量的PAT计划。所提出的点计数表示为将无监督深度学习方法纳入EL预选择任务奠定了基础。

> **ai_Abstract:** 本研究提出了一种名为SPArc_dl的无监督深度学习模型，用于快速优化质子弧治疗中的能量层预选择。通过引入独特的“点计数表示”和三目标训练函数，该模型旨在在保持高计划质量的同时，显著缩短治疗递送时间。在鼻咽癌病例上的评估显示，SPArc_dl在提高计划适形性、均匀性、降低危及器官剂量以及大幅减少能量层切换时间方面表现出色，且推理速度快。尽管在鲁棒性方面存在局限，但该研究为质子治疗计划的自动化优化提供了新的方向。

> **摘要翻译:** 质子弧治疗（PAT）是一种新兴且有前景的放射治疗方式，与调强质子治疗相比，它能提供更好的剂量分布和治疗鲁棒性。然而，由于计算需求大和治疗递送时间延长，识别最佳能量层（EL）序列仍然具有挑战性。本研究提出了一种无监督深度学习模型，用于快速EL预选择，旨在最大限度地减少EL切换（ELS）时间，同时保持高计划质量。我们引入了一种新颖的数据表示方法——点计数表示，该方法将质子点与目标和危及器官（OAR）的交点数量编码成一个矩阵，该矩阵按排序的机架角度和能量层进行结构化。这种表示作为U-Net风格架构SPArc_dl的输入，该架构使用三目标函数进行训练：最大化目标上的点计数、最小化OAR上的点计数以及减少ELS时间。该模型在35例鼻咽癌病例上进行了评估，并将其性能与SPArc_particle_swarm (SPArc_ps) 进行了比较。SPArc_dl生成的EL预选择显著提高了计划质量和递送效率。与SPArc_ps相比，它将适形指数提高了0.1 (p<0.01)，将均匀性指数降低了0.71 (p<0.01)，将脑干平均剂量降低了0.25 (p<0.01)，并将ELS时间缩短了37.2% (p < 0.01)。结果意外地揭示了采用不变的ELS比下降的ELS在时间上更有效。SPArc_dl的推理时间在1秒内。然而，SPArc_dl计划在鲁棒性方面表现出局限性。所提出的点计数表示为将无监督深度学习方法纳入EL预选择任务奠定了基础。SPArc_dl是一种快速工具，通过策略性预选择EL来减少递送时间，同时保持优异的剂量学性能，从而生成高质量的PAT计划。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [112] [AI Should Be More Human, Not More Complex](https://arxiv.org/abs/2508.04713)
> *人工智能应更像人类，而非更复杂*

*Carlo Esposito* | **Category: cs.AI, cs.HC** | **Updated: 2025-07-27**

**Keywords:** 大型语言模型, 用户满意度, 人工智能沟通, 简洁性, 信任

**Comment:** 

> **TL;DR:** 大型语言模型在搜索应用中过于冗长和复杂的回复反而降低了用户满意度。一项针对10,000名参与者的研究表明，用户更倾向于简洁、有来源的回复。研究认为，当前AI追求“人工复杂性”导致用户信任度降低和认知负荷增加，而像人类一样简洁、透明的沟通才是提升用户参与度和系统可靠性的关键。

**AI_Comments:** 这篇论文的创新点在于它直接挑战了当前AI领域普遍存在的“越复杂越好”的开发范式，特别是针对LLMs在实际应用中的表现。它通过大规模用户研究提供了有力的实证证据，强调了用户体验和认知负荷的重要性。其核心观点——AI应更像人类，即更注重简洁、透明和可靠性，而非盲目追求技术上的复杂性——对于未来AI产品设计和评估具有重要指导意义，尤其是在追求用户信任和长期参与度方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在搜索应用中倾向于提供冗长、词汇复杂的回复，但这反而降低了用户满意度和参与度。研究旨在挑战“越复杂越好”的普遍假设，并探究提升用户体验的AI沟通方式。

**Method:** 通过一项针对大约10,000名参与者的综合研究，比较了五种主流AI驱动搜索系统的回复，以评估用户偏好。

**Result:** 用户绝大多数偏爱简洁、有来源的回复，而非冗长的解释。分析显示，当前AI发展趋势中的“人工复杂性”产生了“恐怖谷效应”，即系统听起来知识渊博但缺乏真正的批判性思维，导致信任度降低和认知负荷增加。

**Conclusion:** 最佳的AI沟通应模仿有效的人类对话：直接、有适当来源并诚实地承认局限性。研究结果挑战了AI回复越复杂性能越好的普遍假设，反而表明类人般的简洁和透明是提升用户参与度和系统可靠性的关键。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在搜索应用中过度复杂和冗长的回复对用户满意度的负面影响。通过一项针对10,000名用户的实验，比较了五种AI搜索系统，结果显示用户更偏好简洁、有来源的回复。研究指出，AI追求“人工复杂性”导致用户信任度下降和认知负担增加，并提出AI沟通应模仿人类对话的直接、透明和诚实，认为类人般的简洁和透明是提高用户参与度和系统可靠性的关键。

> **摘要翻译:** 大型语言模型（LLM）在搜索应用中越来越倾向于提供冗长、词汇复杂的回复，但这却矛盾地降低了用户满意度和参与度。通过一项针对约10,000名参与者的综合研究，我们比较了五种主要AI驱动搜索系统的回复，结果表明用户绝大多数偏爱简洁、有来源的回复，而非详尽的解释。我们的分析揭示，当前AI发展中趋向“人工复杂性”的趋势产生了一种“恐怖谷效应”，即系统听起来知识渊博但缺乏真正的批判性思维，导致信任度降低和认知负荷增加。我们提供的证据表明，最佳的AI沟通应模仿有效的人类对话：直接、有适当来源并诚实地承认局限性。我们的研究结果挑战了AI回复越复杂性能越好的普遍假设，反而表明类人般的简洁和透明是提升用户参与度和系统可靠性的关键。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [113] [SpectroStream: A Versatile Neural Codec for General Audio](https://arxiv.org/abs/2508.05207)
> *SpectroStream：一种通用的神经音频编解码器*

*Yunpeng Li, Kehang Han, Brian McWilliams, Zalan Borsos, Marco Tagliasacchi* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 神经音频编解码器, SpectroStream, 时频域, 多通道音频, 音频重建

**Comment:** 

> **TL;DR:** SpectroStream是一种新的全频带多通道神经音频编解码器，它扩展了SoundStream的能力，实现了48 kHz立体声音乐的高质量重建，并引入了时频域表示和延迟融合策略。

**AI_Comments:** SpectroStream的创新之处在于其对时频域音频表示的利用以及为多通道处理设计的延迟融合策略，这使其在处理高采样率和多通道音频方面具有显著优势。作为SoundStream的继承者，它有效地扩展了神经音频编解码器的应用范围和性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的音频编解码器（如SoundStream）在处理24 kHz单声道音频方面表现良好，但SpectroStream旨在扩展其能力，实现48 kHz立体声音乐的高质量重建，以应对更高的采样率和多通道音频的需求。

**Method:** SpectroStream采用了一种新的神经架构，利用时频域的音频表示来提高音频质量，尤其是在高采样率下。此外，该模型还使用了一种延迟融合策略来处理多通道音频，以平衡每通道声学质量和跨通道相位一致性。

**Result:** SpectroStream能够以4-16 kbps的比特率高质量重建48 kHz立体声音乐，超越了SoundStream在24 kHz单声道音频上的能力。

**Conclusion:** SpectroStream通过创新的架构和策略，成功实现了全频带多通道音频的高质量编码，特别是在高采样率和多通道场景下表现出色。

> **ai_Abstract:** 本文提出了一种名为SpectroStream的全频带多通道神经音频编解码器。作为SoundStream的升级版，SpectroStream突破了24 kHz单声道音频的限制，能够以4-16 kbps的比特率高质量重建48 kHz立体声音乐。其核心创新在于采用了利用时频域音频表示的新型神经架构，以及处理多通道音频的延迟融合策略，从而在更高采样率下实现了更好的音频质量，并有效平衡了通道间的声学质量和相位一致性。

> **摘要翻译:** 我们提出了SpectroStream，一种全频带多通道神经音频编解码器。作为成熟的SoundStream的继承者，SpectroStream将其能力扩展到24 kHz单声道音频之外，并能以4-16 kbps的比特率高质量重建48 kHz立体声音乐。这通过一种新的神经架构实现，该架构利用时频域的音频表示，从而带来更好的音频质量，尤其是在更高采样率下。该模型还使用延迟融合策略来处理多通道音频，这对于平衡每通道声学质量和跨通道相位一致性至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [114] [Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance](https://arxiv.org/abs/2506.20883)
> *不确定人类指导下通过强化学习进行复杂模型转换*

*Kyanna Dagenais, Istvan David* | **Category: cs.AI, cs.LG, cs.SE** | **Updated: 2025-08-06**

**Keywords:** 强化学习, 模型转换, 人类指导, 不确定性, 模型驱动工程

**Comment:** 

> **TL;DR:** 本文提出了一种结合不确定人类指导的强化学习方法和框架，用于开发复杂的模型转换序列，实验证明该方法显著提高了RL性能并提高了开发效率。

**AI_Comments:** 该论文的创新点在于将不确定的人类指导引入到强化学习框架中，以解决复杂模型转换的开发难题。它有效地结合了人类的领域知识和RL的探索能力，克服了纯RL在复杂问题上的局限性，并提升了开发效率。这种人机协作的范式对于模型驱动工程领域具有重要意义，尤其是在需要专家经验指导的复杂自动化任务中。

<details>
  <summary>Details</summary>

**Motivation:** 模型驱动工程中复杂的模型转换（MTs）手动开发容易出错且不可行。传统的强化学习（RL）在处理复杂问题时存在性能问题，而人类指导在这种情况下具有很高的实用性。

**Method:** 本文提出了一种结合不确定人类建议的强化学习方法和技术框架，用于开发复杂的模型转换序列。该框架允许将用户定义的MTs映射到RL原语，并将其作为RL程序执行以找到最优的MT序列。

**Result:** 评估结果表明，即使是不确定的人类指导也能显著提高强化学习的性能，并能更有效地开发复杂的模型转换。

**Conclusion:** 通过权衡人类建议的确定性和及时性，该方法向着强化学习驱动的人机协作工程方法迈进了一步。

> **ai_Abstract:** 本文提出了一种结合人类不确定指导的强化学习（RL）方法和框架，旨在解决模型驱动工程中复杂模型转换（MTs）序列开发中的挑战。鉴于手动开发MTs的困难和RL在复杂问题上的性能瓶颈，该框架将用户定义的MTs映射为RL原语，并通过RL程序寻找最优序列。实验证明，即使是不确定的人类指导也能显著提升RL性能，从而更高效地开发复杂的MTs，这标志着向RL驱动的人机协作工程方法迈出了重要一步。

> **摘要翻译:** 模型驱动工程问题通常需要复杂的模型转换（MTs），即需要大量序列串联的MTs。这类问题的相关示例包括模型同步、自动化模型修复和设计空间探索。手动开发复杂的MTs是一个容易出错且通常不可行的过程。强化学习（RL）是缓解这些问题的有效方法。在RL中，自主代理通过试错探索状态空间，以识别有益的动作序列，例如MTs。然而，RL方法在复杂问题中表现出性能问题。在这种情况下，人类指导具有很高的实用性。在本文中，我们提出了一种通过强化学习开发复杂MT序列的方法和技术框架，该框架由可能不确定的人类建议指导。我们的框架允许将用户定义的MTs映射到RL原语，并将其作为RL程序执行以找到最优的MT序列。我们的评估表明，人类指导，即使是不确定的，也能显著提高RL性能，并能更有效地开发复杂的MTs。通过权衡人类建议的确定性和及时性，我们的方法向着RL驱动的人机协作工程方法迈进了一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [119] [Toward Low-Latency End-to-End Voice Agents for Telecommunications Using Streaming ASR, Quantized LLMs, and Real-Time TTS](https://arxiv.org/abs/2508.04721)
> *使用流式ASR、量化LLM和实时TTS实现电信领域低延迟端到端语音代理*

*Vignesh Ethiraj, Ashwath David, Sidhanth Menon, Divya Vijay* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-08-05**

**Keywords:** 电信AI, 语音代理, 低延迟, 流式ASR, 量化LLM, 实时TTS

**Comment:** 

> **TL;DR:** 开发了一种用于电信的低延迟AI语音代理管道，结合了流式ASR、量化LLM和实时TTS，以实现实时交互和客户支持。

**AI_Comments:** 该论文的创新点在于其端到端低延迟的电信AI语音代理管道，特别强调了电信领域的专业化模型（TSLAM, T-VEC, TTE, T-Synth）。通过4比特量化LLM和流式处理，有效解决了电信场景对实时性和低延迟的严苛要求。其构建的专用数据集和RTF评估也体现了对实际应用效果的重视，为电信行业的AI语音交互提供了实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 解决电信领域对实时交互和高级语音AI的需求，以实现呼叫中心自动化、智能IVR和AI驱动的客户支持。

**Method:** 引入了NetoAI的四种电信专用模型：TSLAM（4比特量化大型语言模型）、T-VEC（嵌入模型）、TTE（自动语音识别模型）和T-Synth（文本到语音模型）。该管道集成了流式ASR、会话智能、基于电信文档的检索增强生成（RAG）和实时TTS。研究人员构建了一个包含500个人工录制电信问题的评估数据集。

**Result:** TSLAM、TTE和T-Synth的实时因子（RTF）均低于1.0，支持企业级、低延迟的电信部署。

**Conclusion:** 这些由TSLAM、TTE和T-Synth驱动的AI代理为下一代电信AI奠定了基础，能够实现自动化客户支持和诊断等功能。

> **ai_Abstract:** 这篇论文介绍了一种用于电信行业的低延迟AI语音代理管道，旨在实现实时交互和自动化客户支持。该解决方案整合了NetoAI的四种电信专用模型：TSLAM（量化LLM）、T-VEC（嵌入模型）、TTE（流式ASR）和T-Synth（实时TTS）。通过结合流式ASR、会话智能、RAG和实时TTS，该系统为电信语音助手树立了新标准。实验结果表明，其核心模型能实现低于1.0的实时因子，支持企业级低延迟部署，为下一代电信AI应用奠定了基础。

> **摘要翻译:** 我们介绍了一种用于实时、交互式电信用途的低延迟电信AI语音代理管道，它能为呼叫中心自动化、智能IVR（交互式语音应答）和AI驱动的客户支持提供先进的语音AI。该解决方案专为电信领域构建，结合了NetoAI的四种专用模型：TSLAM（一种4比特量化电信专用大型语言模型）、T-VEC（一种电信专用嵌入模型）、TTE（一种电信专用自动语音识别模型）和T-Synth（一种电信专用文本到语音模型）。这些模型能够实现高度响应、领域适应的语音AI代理，支持基于知识的低延迟语音交互。该管道集成了流式ASR（TTE）、会话智能（TSLAM）、基于电信文档的检索增强生成（RAG）和实时TTS（T-Synth），为电信语音助手设定了新的基准。为了评估该系统，我们构建了一个包含500个人工录制、来自RFC的电信问题数据集，模拟真实的电信代理查询。该框架允许分析整个堆栈的延迟、领域相关性和实时性能。结果显示，TSLAM、TTE和T-Synth的实时因子（RTF）均低于1.0，支持企业级、低延迟的电信部署。这些由TSLAM、TTE和T-Synth驱动的AI代理为下一代电信AI奠定了基础，可实现自动化客户支持、诊断等。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [120] [Advanced Hybrid Transformer LSTM Technique with Attention and TS Mixer for Drilling Rate of Penetration Prediction](https://arxiv.org/abs/2508.05210)
> *用于钻井钻速预测的先进混合Transformer LSTM技术，结合注意力和TS Mixer*

*Saddam Hussain Khan* | **Category: cs.AI, cs.LG, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 钻速预测, 深度学习, LSTM, Transformer, TS-Mixer

**Comment:** 

> **TL;DR:** 该论文提出了一种结合LSTM、Transformer、TS-Mixer和注意力机制的混合深度学习模型，用于准确预测钻井钻速（ROP），并在实际数据集上取得了优异性能。

**AI_Comments:** 该论文通过集成多种先进的深度学习技术（LSTM、Transformer、TS-Mixer和注意力机制）来解决钻井ROP预测的复杂性，展现了较强的技术创新性。其在真实数据集上的优异表现和对模型可解释性的关注，增加了其实际应用价值，对于提升钻井作业的效率和成本效益具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 钻速（ROP）对于优化钻井作业至关重要，但由于钻井数据的复杂性、动态性和高维度性，准确预测ROP面临挑战。传统的经验、物理和基本机器学习模型难以捕捉复杂的时间和上下文关系，导致预测不佳且实时效用有限。

**Method:** 提出了一种新颖的混合深度学习架构，该架构整合了长短期记忆（LSTM）网络、Transformer编码器、时间序列混合器（TS-Mixer）模块和注意力机制，以协同建模时间依赖性、静态特征交互、全局上下文和动态特征重要性。

**Result:** 在真实钻井数据集上进行评估，该模型优于基准模型（独立的LSTM、TS-Mixer和更简单的混合模型），R平方得分为0.9988，平均绝对百分比误差为1.447%。使用SHAP和LIME确保了模型可解释性，实际与预测曲线以及偏差检查证实了在各种场景下的准确性和公平性。

**Conclusion:** 这种先进的混合方法能够实现可靠的实时ROP预测，为智能、经济高效的钻井优化系统铺平了道路，具有显著的运营影响。

> **ai_Abstract:** 本研究提出了一种创新的混合深度学习模型，结合了LSTM、Transformer、TS-Mixer和注意力机制，旨在解决钻井钻速（ROP）预测中数据复杂性和传统模型不足的问题。该模型能够协同处理时间依赖性、特征交互和动态重要性。在真实钻井数据集上的评估显示，该模型在ROP预测方面表现出色，R平方达到0.9988，MAPE为1.447%，显著优于现有基准模型。此外，通过SHAP和LIME确保了模型的可解释性。该方法为实现可靠的实时ROP预测和智能钻井优化系统提供了有效途径。

> **摘要翻译:** 钻速（ROP）对于优化钻井作业至关重要；然而，准确预测它受到钻井数据复杂、动态和高维度的阻碍。传统的经验、基于物理和基本的机器学习模型通常无法捕捉复杂的时间和上下文关系，导致预测次优和实时效用有限。为了解决这一差距，我们提出了一种新颖的混合深度学习架构，该架构整合了长短期记忆（LSTM）网络、Transformer编码器、时间序列混合器（TS-Mixer）模块和注意力机制，以协同建模时间依赖性、静态特征交互、全局上下文和动态特征重要性。在真实世界的钻井数据集上进行评估，我们的模型在标准回归指标（R平方、MAE、RMSE、MAPE）的测量下，R平方得分为0.9988，平均绝对百分比误差为1.447%，优于基准模型（独立的LSTM、TS-Mixer和更简单的混合模型）。使用SHAP和LIME确保了模型可解释性，同时实际与预测曲线和偏差检查证实了在各种场景下的准确性和公平性。这种先进的混合方法能够实现可靠的实时ROP预测，为智能、经济高效的钻井优化系统铺平了道路，具有显著的运营影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [121] [Can Vision Language Models Understand Mimed Actions?](https://arxiv.org/abs/2506.21586)
> *视觉语言模型能理解哑剧动作吗？*

*Hyundong Cho, Spencer Lin, Tejas Srinivasan, Michael Saxon, Deuksin Kwon, Natali T. Chavez, Jonathan May* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉语言模型, 哑剧动作, 非语言交流, 视频问答, 数据集

**Comment:** 

> **TL;DR:** 本文提出了MIME，一个评估视觉语言模型对哑剧动作理解能力的视频问答基准。研究发现，现有视觉语言模型在该基准上的表现远低于人类，表明需要进一步研究以提升模型对人类手势的鲁棒理解。

**AI_Comments:** 本文创新性地提出了MIME数据集，专注于哑剧动作这一特定且解释差异较小的非语言交流子集，为视觉语言模型理解复杂人类行为提供了新的评估视角。其重要性在于，揭示了当前视觉语言模型在理解具象化手势方面的局限性，并强调了未来研究应着重提升模型对人类非语言交流的鲁棒理解能力。该研究为构建更智能、更能理解人类意图的AI系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 非语言交流（NVC）在人类语言中扮演着重要角色，但其范围广、个体和文化间解释差异大，难以研究。哑剧作为NVC的一个子集，其动作明确且具象，人类解释差异小。作者认为，对哑剧动作的扎实理解是视觉语言模型解释和掌握更细微NVC的关键前提。

**Method:** 研究提出了MIME（Mime Identification Multimodal Evaluation），一个新颖的、基于视频的问答基准，包含86种哑剧动作。MIME利用动作捕捉数据构建，并通过对角色、背景和视角的扰动来评估识别的鲁棒性。

**Result:** 研究发现，无论是开源模型还是基于API的视觉语言模型，在MIME基准上的表现都显著低于人类。

**Conclusion:** 现有视觉语言模型在理解哑剧动作方面表现不佳，这激励了未来需要更多研究来增强模型对人类手势的鲁棒理解能力。

> **ai_Abstract:** 本研究提出MIME，一个包含86种哑剧动作的视频问答基准，旨在评估视觉语言模型对非语言交流中哑剧动作的理解能力。该基准通过动作捕捉数据构建，并引入扰动以测试模型的鲁棒性。实验结果表明，当前视觉语言模型在MIME基准上的表现远逊于人类，突显了在人类手势理解方面进一步研究的必要性。

> **摘要翻译:** 非语言交流（NVC）在人类语言中扮演着不可或缺的角色，但由于其范围广、个体和文化间解释差异大，研究NVC总体上具有挑战性。然而，哑剧——一种仅通过手势、表情和动作来暗示意图的戏剧技巧——是NVC的一个子集，它包含明确和具象的动作，人类解释差异小得多。我们认为，对哑剧动作的扎实理解是视觉语言模型能够解释和掌握NVC更细微方面的关键前提。因此，我们提出了MIME（Mime Identification Multimodal Evaluation），一个新颖的、基于视频的问答基准，包含86种哑剧动作。MIME利用动作捕捉数据构建，包含每个动作的变体，并对角色、背景和视角应用了扰动，以评估识别的鲁棒性。我们发现，无论是开源模型还是基于API的视觉语言模型，在MIME上的表现都显著低于人类，这促使我们需要增加研究，以灌输对人类手势更鲁棒的理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [122] [Simulating Human-Like Learning Dynamics with LLM-Empowered Agents](https://arxiv.org/abs/2508.05622)
> *使用LLM赋能的智能体模拟类人学习动态*

*Yu Yuan, Lili Zhao, Wei Chen, Guangting Zheng, Kai Zhang, Mengdi Zhang, Qi Liu* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** LLM, 学习动态, 多智能体系统, 认知模拟, 人类学习

**Comment:** 

> **TL;DR:** 该研究引入了一个基于LLM的多智能体框架LearnerAgent，以模拟人类学习行为，并揭示了不同学习者类型（包括LLM的默认行为）在长期学习过程中的认知动态和行为模式。

**AI_Comments:** 该研究的创新之处在于利用LLM构建多智能体框架来模拟复杂的类人学习动态，并引入了心理学上合理的用户画像。其重要性在于不仅提供了一种新的方法来研究人类学习行为，更揭示了LLM在模拟学习过程中的内在特点和局限性，特别是“勤奋但脆弱的表面学习者”这一发现，对理解LLM的能力边界和未来发展方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前捕捉人类学习行为的方法（如受控实验或基于规则的模型）难以捕捉学习动态、跟踪随时间推移的进展或提供可解释性。

**Method:** 研究引入了LearnerAgent，一个基于大型语言模型（LLMs）的新型多智能体框架，用于模拟真实的教学环境。该框架构建了具有心理学基础的学习者档案（如深度学习者、表面学习者和懒惰学习者），以及一个无个性特征的通用学习者来检查基础LLM的默认行为。通过每周知识获取、每月策略选择、定期测试和同伴互动，可以跟踪个体学习者一整年的动态学习进度。

**Result:** 1) 纵向分析显示只有深度学习者实现了持续的认知成长，设计的“陷阱问题”有效诊断了表面学习者的浅层知识。 2) 不同学习者的行为和认知模式与他们的心理画像高度一致。 3) 学习者的自我概念分数真实演变，通用学习者尽管认知有限却发展出惊人的高自我效能感。 4) 基础LLM的默认学习者档案是“勤奋但脆弱的表面学习者”，模仿好学生的行为但缺乏真正可推广的理解。

**Conclusion:** LearnerAgent框架能够很好地与真实场景对齐，并为理解LLMs的行为提供了更深入的发现。

> **ai_Abstract:** 该论文提出了LearnerAgent，一个基于LLM的多智能体框架，旨在模拟类人学习动态。通过构建不同心理画像的学习者（包括通用LLM学习者），并在模拟教学环境中进行为期一年的跟踪，研究揭示了不同学习者在认知成长、行为模式和自我概念发展上的差异。特别地，研究发现基础LLM的默认行为类似于一个“勤奋但脆弱的表面学习者”，即能模仿好学生行为但缺乏深层理解。该框架为深入理解LLM的行为及其在模拟人类学习方面的潜力提供了新的视角。

> **摘要翻译:** 基于深度学习方法捕捉人类学习行为已成为心理学和智能系统领域的一个主要研究焦点。最近的方法依赖于受控实验或基于规则的模型来探索认知过程。然而，它们难以捕捉学习动态、跟踪随时间推移的进展或提供可解释性。为了解决这些这些挑战，我们引入了LearnerAgent，一个基于大型语言模型（LLMs）的新型多智能体框架，用于模拟真实的教学环境。为了探索类人学习动态，我们构建了具有心理学基础的学习者档案——例如深度学习者、表面学习者和懒惰学习者——以及一个无个性特征的通用学习者来检查基础LLM的默认行为。通过每周知识获取、每月策略选择、定期测试和同伴互动，我们可以跟踪个体学习者一整年的动态学习进度。我们的发现有四点：1）纵向分析显示只有深度学习者实现了持续的认知成长。我们特别设计的“陷阱问题”有效诊断了表面学习者的浅层知识。2）不同学习者的行为和认知模式与他们的心理画像紧密对齐。3）学习者的自我概念分数真实演变，通用学习者尽管认知有限却发展出令人惊讶的高自我效能感。4）关键的是，基础LLM的默认档案是一个“勤奋但脆弱的表面学习者”——一个模仿好学生行为但缺乏真正、可推广理解的智能体。广泛的模拟实验表明，LearnerAgent与真实场景高度吻合，为理解LLMs的行为提供了更深入的发现。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [127] [Wearable Music2Emotion : Assessing Emotions Induced by AI-Generated Music through Portable EEG-fNIRS Fusion](https://arxiv.org/abs/2508.04723)
> *可穿戴式音乐情绪评估：通过便携式EEG-fNIRS融合评估AI生成音乐诱发的情绪*

*Sha Zhao, Song Yi, Yangxuan Zhou, Jiadong Pan, Jiquan Wang, Jie Xia, Shijian Li, Shurong Dong, Gang Pan* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-08-05**

**Keywords:** AI生成音乐, 情绪评估, EEG-fNIRS融合, 便携式设备, 多模态数据集

**Comment:** 

> **TL;DR:** 提出MEEtBrain框架，结合AI生成音乐和便携式EEG-fNIRS设备，用于大规模、多模态、可穿戴的情绪评估，并发布数据集。

**AI_Comments:** 该论文的创新点在于结合了AI生成音乐来解决传统音乐刺激库的局限性，并采用了便携式EEG-fNIRS多模态融合技术，克服了单模态数据和设备笨重的问题。这对于在真实世界环境中进行大规模情绪评估具有重要意义。数据集的公开也极大地促进了该领域的研究发展。

<details>
  <summary>Details</summary>

**Motivation:** 情绪对心理健康至关重要，但现有基于音乐的情感计算存在三点限制：1. 刺激限制：音乐库小，受版权和策展成本限制，且启发式映射存在选择偏差。2. 模态特异性：过度依赖单模态神经数据，忽略跨模态融合的互补洞察。3. 便携性限制：传统设备笨重，阻碍实际应用。

**Method:** 本文提出了MEEtBrain框架，一个便携式多模态情绪分析（效价/唤醒度）框架。该框架整合AI生成音乐刺激，以消除主观选择偏差并确保音乐多样性。通过一个轻量级无线头带，同步采集EEG和fNIRS数据，该头带采用干电极设计。

**Result:** 通过MEEtBrain框架，收集了20名参与者的14小时数据集，验证了其有效性，AI生成音乐能够诱发目标情绪（效价/唤醒度）。目前正在扩展多模态数据集（最新为44名参与者），并已公开可用。

**Conclusion:** MEEtBrain框架通过结合AI生成音乐和便携式EEG-fNIRS融合技术，有效解决了现有音乐情绪评估中的刺激限制、模态特异性和便携性限制，为大规模、多样化、实际应用中的情绪评估提供了解决方案，并促进了相关研究。

> **ai_Abstract:** 本文提出了MEEtBrain框架，旨在克服现有音乐情绪评估中刺激限制、模态特异性和便携性不足的问题。MEEtBrain结合了AI生成的大规模音乐刺激和通过轻量级无线头带同步采集的EEG-fNIRS多模态神经数据。该框架能够消除主观选择偏差，确保音乐多样性，并提高了设备的便携性。初步实验验证了其有效性，AI生成音乐能诱发目标情绪，研究团队正积极扩大并公开相关数据集，以推动该领域的研究和应用。

> **摘要翻译:** 情绪严重影响心理健康，推动了通过脑机接口技术利用神经生理信号进行基于音乐的情感计算的兴趣。尽管先前的研究利用音乐的可及性来诱导情绪，但仍存在三个关键限制：(1) 刺激限制：由于版权和策展成本，音乐刺激仅限于小型语料库，且启发式情绪-音乐映射存在选择偏差，忽略个体情感特征。(2) 模态特异性：过度依赖单模态神经数据（例如EEG）忽略了来自跨模态信号融合的互补洞察。(3) 便携性限制：笨重的设置（例如64通道以上凝胶式EEG帽）由于程序复杂性和便携性障碍而阻碍了实际应用。为了解决这些限制，我们提出了MEEtBrain，一个用于情绪分析（效价/唤醒度）的便携式多模态框架，通过无线头带整合AI生成音乐刺激与同步的EEG-fNIRS采集。通过MEEtBrain，音乐刺激可以由AI大规模自动生成，消除主观选择偏差，同时确保音乐多样性。我们使用自行开发的轻量级头带式便携设备，采用干电极，同时收集EEG和fNIRS记录。在首次招募中收集了来自20名参与者的14小时数据集，以验证该框架的功效，AI生成音乐能够诱发目标情绪（效价/唤醒度）。我们正在积极扩展我们的多模态数据集（最新数据集为44名参与者），并将其公开，以促进进一步的研究和实际应用。数据集可在https://zju-bmi-lab.github.io/ZBra获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [128] [ReasoningTrack: Chain-of-Thought Reasoning for Long-term Vision-Language Tracking](https://arxiv.org/abs/2508.05221)
> *ReasoningTrack：面向长期视觉-语言跟踪的思维链推理*

*Xiao Wang, Liye Jin, Xufeng Lou, Shiao Wang, Lan Chen, Bo Jiang, Zhipeng Zhang* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 视觉-语言跟踪, 思维链, 推理, 大型语言模型, 基准数据集

**Comment:** 

> **TL;DR:** 本文提出了ReasoningTrack，一个新颖的基于思维链推理的视觉-语言跟踪框架，利用预训练的Qwen2.5-VL模型，并引入了一个新的长期视觉-语言跟踪基准数据集TNLLT。

**AI_Comments:** 本文的创新之处在于将思维链推理应用于视觉-语言跟踪，并有效利用大型预训练视觉-语言模型（Qwen2.5-VL）来提高跟踪的适应性和可解释性。同时，引入TNLLT数据集为长期视觉-语言跟踪任务提供了重要的基准，对该领域的发展具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言跟踪方法在融合固定语言或使用注意力机制方面表现有限。一些文本生成方法未能提供模型推理过程的见解，也未充分利用大型模型的优势，从而限制了整体性能。

**Method:** 本文提出了一个名为ReasoningTrack的新型基于推理的视觉-语言跟踪框架，该框架基于预训练的视觉-语言模型Qwen2.5-VL。使用SFT（监督微调）和强化学习GRPO优化推理和语言生成。将更新的语言描述嵌入并与视觉特征一起输入统一的跟踪骨干网络，然后采用跟踪头预测目标对象的具体位置。此外，本文提出了一个包含200个视频序列的大规模长期视觉-语言跟踪基准数据集TNLLT。

**Result:** 在多个视觉-语言跟踪基准数据集上的大量实验充分验证了所提出的基于推理的自然语言生成策略的有效性。20个基线视觉跟踪器在该数据集上进行了重新训练和评估，为视觉-语言视觉跟踪任务奠定了坚实的基础。

**Conclusion:** 所提出的ReasoningTrack框架和基于推理的自然语言生成策略对视觉-语言跟踪是有效的，并且新的TNLLT数据集为未来的研究提供了坚实的基础。

> **ai_Abstract:** 本文提出了ReasoningTrack，一个新颖的视觉-语言跟踪框架，利用预训练的Qwen2.5-VL模型进行思维链推理。它通过SFT和GRPO优化语言生成和推理，解决了现有方法的局限性。该框架将更新的语言描述和视觉特征整合到统一的骨干网络中进行目标定位。此外，本文还发布了TNLLT，一个用于长期视觉-语言跟踪的大规模基准数据集，验证了ReasoningTrack的有效性，并为未来研究奠定了基础。

> **摘要翻译:** 近年来，视觉-语言跟踪受到了越来越多的关注，因为文本信息可以有效解决指定目标对象进行跟踪时存在的灵活性和不准确性问题。现有工作要么直接将固定语言与视觉特征融合，要么简单地通过注意力机制进行修改，然而它们的性能仍然有限。最近，一些研究人员探索使用文本生成来适应跟踪过程中目标的变化，然而，这些工作未能提供对模型推理过程的深入理解，也没有充分利用大型模型的优势，这进一步限制了它们的整体性能。为了解决上述问题，本文提出了一个名为ReasoningTrack的新型基于推理的视觉-语言跟踪框架，该框架基于预训练的视觉-语言模型Qwen2.5-VL。SFT（监督微调）和强化学习GRPO都用于推理和语言生成的优化。我们将更新的语言描述嵌入并与视觉特征一起输入统一的跟踪骨干网络。然后，我们采用一个跟踪头来预测目标对象的具体位置。此外，我们提出了一个大规模的长期视觉-语言跟踪基准数据集，命名为TNLLT，其中包含200个视频序列。在该数据集上重新训练和评估了20个基线视觉跟踪器，这为视觉-语言视觉跟踪任务奠定了坚实的基础。在多个视觉-语言跟踪基准数据集上的大量实验充分验证了我们提出的基于推理的自然语言生成策略的有效性。本文的源代码将在https://github.com/Event-AHU/Open_VLTrack 上发布。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [129] [Sign Spotting Disambiguation using Large Language Models](https://arxiv.org/abs/2507.03703)
> *使用大型语言模型的手语识别消歧*

*JianHe Low, Ozge Mercanoglu Sincan, Richard Bowden* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 手语识别, 大型语言模型, 消歧, 无需训练, 数据稀缺

**Comment:** 

> **TL;DR:** 本文提出一个无需训练的框架，整合大型语言模型 (LLMs) 以提高手语识别质量，通过特征匹配和LLM进行上下文消歧，解决了数据稀缺和歧义问题，并在实验中表现出优越性。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型（LLMs）引入到手语识别任务中，并提出了一个无需训练的框架，有效解决了传统方法的词汇不灵活性和歧义问题。其无需微调LLM的上下文消歧方法，大大降低了实现难度和计算成本，为手语翻译的数据标注提供了高效且灵活的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 手语识别在扩展数据集标注和解决手语翻译中的数据稀缺问题方面至关重要。然而，自动化手语识别面临词汇不灵活性和连续手语流中固有的歧义挑战。

**Method:** 引入了一种新颖的、无需训练的框架，该框架整合了大型语言模型（LLMs）以显著提高手语识别质量。该方法提取全局时空和手形特征，然后使用动态时间规整和余弦相似性与大规模手语词典进行匹配。为了减轻匹配过程中的噪声和歧义，LLM通过束搜索执行上下文感知的词素消歧，无需微调。

**Result:** 在合成和真实世界手语数据集上的广泛实验表明，该方法与传统方法相比，具有更高的准确性和句子流畅性。

**Conclusion:** 本研究突出了大型语言模型在推进手语识别方面的潜力。

> **ai_Abstract:** 本文提出了一种新颖的、无需训练的框架，通过整合大型语言模型（LLMs）来解决手语识别中的数据稀缺、词汇不灵活性和歧义问题。该方法结合了全局时空和手形特征与大规模手语词典的匹配，并利用LLM进行上下文感知的词素消歧，无需微调。实验结果表明，该方法在准确性和句子流畅性方面优于传统方法，展示了LLMs在手语识别领域的巨大潜力。

> **摘要翻译:** 手语识别，即在连续手语视频中识别和定位单个手语的任务，在扩展数据集标注和解决手语翻译中严重的数据稀缺问题方面发挥着关键作用。尽管自动化手语识别在实现大规模帧级监督方面前景广阔，但它也面临着词汇不灵活性和连续手语流中固有的歧义等挑战。因此，我们引入了一种新颖的、无需训练的框架，该框架整合了大型语言模型（LLMs），以显著提高手语识别质量。我们的方法提取全局时空和手形特征，然后使用动态时间规整和余弦相似性与大规模手语词典进行匹配。这种基于词典的匹配本身就提供了卓越的词汇灵活性，无需模型再训练。为了减轻匹配过程中的噪声和歧义，LLM通过束搜索执行上下文感知的词素消歧，值得注意的是，这无需微调。在合成和真实世界手语数据集上的广泛实验表明，我们的方法与传统方法相比，具有更高的准确性和句子流畅性，突出了LLMs在推进手语识别方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [134] [Agency, Affordances, and Enculturation of Augmentation Technologies](https://arxiv.org/abs/2508.04725)
> *增强技术中的能动性、可供性与文化适应*

*Ann Hill Duin, Isabel Pedersen* | **Category: cs.AI, cs.CY** | **Updated: 2025-08-05**

**Keywords:** 增强技术, 人工智能, 文化适应, 能动性, 元宇宙

**Comment:** 

> **TL;DR:** 本章批判性地审视了增强技术（特别是受AI驱动的）将改善生活的假设，探讨了AI术语的模糊性、人机能动关系以及市场营销如何促使文化适应，并讨论了元宇宙和增强现实。

**AI_Comments:** 该论文从批判性角度审视了增强技术，特别是AI驱动的增强技术对社会和文化的影响，这在当前技术快速发展的背景下具有重要意义。它不仅关注了技术本身，还深入探讨了其文化适应过程、营销策略以及人机关系等社会学和传播学维度，特别是对AI术语模糊性的探讨和对元宇宙的批判性审视，体现了其理论深度和现实关怀。论文的创新之处在于将能动性、可供性与文化适应这些概念融合起来分析增强技术，提供了一个多维度的分析框架。

<details>
  <summary>Details</summary>

**Motivation:** 本章旨在批判性地审视关于复杂、新兴和具身增强技术将改善生活、文化和经济的过度炒作假设。

**Method:** 本章首先讨论了AI术语的模糊性，并借助世界知识产权组织（WIPO）的AI技术分类方案进行阐明。接着，它借鉴媒体和传播学研究，探讨了能动者、能动性、权力以及人机之间的能动关系。它还关注了工业中非人类能动者的发展对增强技术兴起的关键作用，并分析了营销传播如何使未来用户接受并适应这些技术。最后，它审视了关于元宇宙和增强现实的最新主张。

**Result:** 本章批判性地审视了增强技术（特别是受AI驱动的）将改善生活的假设，探讨了AI术语的模糊性、人机能动关系以及市场营销如何促使文化适应。它揭示了人们如何被进一步吸引到商业数字景观中，并对元宇宙和增强现实的最新主张进行了审视。

**Conclusion:** 本章通过审视元宇宙和增强现实的最新主张，对增强技术的文化适应过程及其在后互联网社会中对人类社会、文化和经济影响的复杂性进行了批判性探讨。

> **ai_Abstract:** 本章批判性地探讨了增强技术的文化适应过程，特别是受人工智能推动的影响。它质疑了关于这些技术将改善生活的普遍假设，并深入分析了AI术语的模糊性。文章还借鉴媒体和传播学理论，审视了人机之间的能动关系以及工业中非人类能动者的发展。此外，它探讨了营销传播如何促进用户对新技术的接受，并分析了后互联网社会中人们被吸引到如元宇宙等商业数字景观的现象，最后对元宇宙和增强现实的最新主张进行了审视。

> **摘要翻译:** 增强技术正经历一个文化适应的过程，其中一个重要因素是人工智能（AI）的兴起，世界知识产权组织（WIPO）称之为AI浪潮或AI繁荣。第三章将批判性地关注一个被大肆宣传的假设，即复杂、新兴和具身的增强技术将改善生活、识字、文化、艺术、经济和社会环境。本章首先讨论了AI术语的模糊性问题，并通过描述WIPO的AI技术分类方案来加以辅助。然后，它借鉴媒体和传播学研究，探索了诸如能动者、能动性、权力以及人机之间的能动关系等概念。本章将工业中非人类能动者的发展视为增强技术兴起的关键因素。它探讨了营销传播如何使未来用户接受并适应这项技术。学者们正在描绘后互联网社会中人们被进一步吸引到商业数字景观（如元宇宙概念）中的重要方式。最后，它审视了有关元宇宙和增强现实的最新主张。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [135] [CWEFS: Brain volume conduction effects inspired channel-wise EEG feature selection for multi-dimensional emotion recognition](https://arxiv.org/abs/2508.05228)
> *CWEFS：受脑容量传导效应启发的通道级脑电图特征选择，用于多维情感识别*

*Xueyuan Xu, Wenjia Dong, Fulin Wei, Li Zhuo* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 脑电图, 特征选择, 情感识别, 容量传导, 潜在空间

**Comment:** 

> **TL;DR:** 针对多维情感识别中脑电图特征冗余和通道重要性被忽视的问题，本文提出了一种受脑容量传导效应启发的通道级脑电图特征选择方法CWEFS，实验证明其性能优于现有方法。

**AI_Comments:** 该论文的创新之处在于通过考虑脑容量传导效应和引入通道级自适应加权来解决脑电图特征选择的特定挑战，这些方面在现有研究中常被忽视。共享潜在结构模型和多维标签潜在语义分析的结合也增加了其新颖性。其优于众多基线方法的性能凸显了其在实时和准确情感识别方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 由于颅内容积传导效应，高维多通道脑电图（EEG）特征包含大量冗余和不相关信息，这阻碍了判别性情感表示的提取并影响实时性能。现有研究忽略了潜在脑电图特征结构对情感标签相关性的影响，并假设各通道重要性均一，限制了多维情感计算中脑电图特征选择模型的精确构建。

**Method:** 本文提出了一种新颖的通道级脑电图特征选择（CWEFS）方法。受脑容量传导效应启发，CWEFS将脑电图情感特征选择集成到共享潜在结构模型中，以构建跨不同脑电图通道的共识潜在空间。为保留局部几何结构，该共识空间与多维情感标签的潜在语义分析相结合。此外，CWEFS还引入了自适应通道权重学习以自动确定不同脑电图通道的重要性。

**Result:** CWEFS的有效性通过三个流行的具有多维情感标签的脑电图数据集进行了验证。与十九种特征选择方法进行比较的综合实验结果表明，CWEFS选择的脑电图特征子集在六个评估指标上均取得了最佳情感识别性能。

**Conclusion:** CWEFS有效解决了脑电图特征冗余和通道重要性不均的问题，从而实现了卓越的多维情感识别性能。

> **ai_Abstract:** 本文提出了一种新颖的通道级脑电图（EEG）特征选择方法CWEFS，用于多维情感识别。该方法通过整合受脑容量传导效应启发的共享潜在结构模型来解决EEG特征冗余和通道重要性被忽视的问题。CWEFS构建了一个共识潜在空间，结合了情感标签的潜在语义分析，并自适应地学习通道权重。在三个数据集上与十九种现有方法进行比较，CWEFS始终实现了最佳情感识别性能。

> **摘要翻译:** 由于颅内容积传导效应，高维多通道脑电图（EEG）特征通常包含大量冗余和不相关信息。这个问题不仅阻碍了判别性情感表示的提取，而且影响了实时性能。特征选择已被证明是解决这些挑战的有效方法，同时增强了情感识别模型的透明度和可解释性。然而，现有的脑电图特征选择研究忽略了潜在脑电图特征结构对情感标签相关性的影响，并假设各个通道的重要性均一，这直接限制了用于多维情感计算的脑电图特征选择模型的精确构建。为了解决这些局限性，本文提出了一种新颖的通道级脑电图特征选择（CWEFS）方法，用于多维情感识别。具体而言，受脑容量传导效应的启发，CWEFS将脑电图情感特征选择集成到一个共享潜在结构模型中，该模型旨在构建跨不同脑电图通道的共识潜在空间。为了保留局部几何结构，该共识空间进一步与多维情感标签的潜在语义分析相结合。此外，CWEFS还引入了自适应通道权重学习，以自动确定不同脑电图通道在情感特征选择任务中的重要性。CWEFS的有效性通过三个流行的具有多维情感标签的脑电图数据集进行了验证。与十九种特征选择方法进行比较的综合实验结果表明，CWEFS选择的脑电图特征子集在六个评估指标上均取得了最佳情感识别性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [136] [AI Agent Smart Contract Exploit Generation](https://arxiv.org/abs/2507.05558)
> *AI智能体智能合约漏洞利用生成*

*Arthur Gervais, Liyi Zhou* | **Category: cs.AI, cs.CR** | **Updated: 2025-08-07**

**Keywords:** AI智能体, 智能合约, 漏洞利用生成, 大语言模型, 区块链安全

**Comment:** 

> **TL;DR:** A1是一个将LLM转化为端到端漏洞利用生成器的智能体系统，通过专用工具和执行验证，成功发现了真实智能合约中的漏洞，并揭示了攻击者与防御者之间的经济不对称性。

**AI_Comments:** 本文提出了一种新颖的基于AI智能体的方法来自动生成智能合约漏洞利用，其创新性在于将LLM与领域专用工具结合，并通过实际执行来验证漏洞的有效性。这显著提高了漏洞发现的准确性和实用性，解决了LLM在早期应用中误报率高的问题。其重要性体现在能够以机器的速度和类似人类的推理能力，高效地识别和利用高价值的智能合约漏洞，对区块链安全领域具有深远影响。然而，文章最后提出的关于AI智能体可能更倾向于攻击而非防御的伦理问题，也揭示了未来AI安全研究需要面对的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约漏洞已导致数十亿美元的损失，但找到可操作的漏洞利用仍然充满挑战。传统的模糊测试器过于僵化，难以应对复杂攻击，而人工审计则效率低下且难以扩展。尽管大型语言模型（LLMs）有潜力，但早期研究表明，简单地提示LLMs会产生未经证实且误报率高的漏洞推测。

**Method:** 我们提出了A1，一个将任何大型语言模型（LLM）转化为端到端漏洞利用生成器的智能体系统。A1为智能体提供了六种领域专用工具，用于自主漏洞发现，包括理解合约行为和在真实区块链状态上测试策略。所有输出都通过执行进行具体验证，确保只报告有利可图的概念验证漏洞利用。

**Result:** A1在以太坊和币安智能链上36个真实世界漏洞合约中进行了评估。A1在VERITE基准测试中取得了63%的成功率，在所有成功案例中，每次漏洞利用提取高达859万美元，总计933万美元。通过对六个LLM进行的432次实验表明，大多数漏洞利用在五次迭代内出现，每次尝试的成本范围为0.01-3.59美元。对历史攻击的蒙特卡洛分析表明，立即检测漏洞的成功概率为86-89%，而延迟一周则降至6-21%。经济分析揭示了令人不安的不对称性：攻击者在6,000美元的漏洞利用价值下即可实现盈利，而防御者则需要60,000美元。

**Conclusion:** A1系统成功地将LLM转化为高效的智能合约漏洞利用生成器，证明了其在发现高价值漏洞方面的能力。研究结果还突出了漏洞检测时效性的重要性，并揭示了智能合约安全领域中攻击者与防御者之间存在的显著经济不对称性，这引发了关于AI智能体是否必然偏向于利用而非防御的根本性问题。

> **ai_Abstract:** 本研究提出了A1，一个基于LLM的智能体系统，旨在自动化智能合约漏洞利用的生成，以应对传统方法效率低下和误报率高的问题。A1通过提供六种领域专用工具和执行验证，能够发现并利用真实区块链上的漏洞。实验结果显示，A1在VERITE基准测试中取得了63%的成功率，并能从漏洞中提取数百万美元。研究还通过经济分析揭示了攻击者与防御者之间在漏洞利用盈利能力上的显著不对称性，并强调了及时检测的重要性。

> **摘要翻译:** 智能合约漏洞已导致数十亿美元的损失，但找到可操作的漏洞利用仍然充满挑战。传统的模糊测试器依赖僵化的启发式方法，难以应对复杂攻击，而人工审计员虽然彻底但速度慢且无法扩展。大型语言模型提供了一个有前景的中间地带，结合了类似人类的推理能力和机器的速度。
然而，早期研究表明，简单地提示LLM会生成未经证实的漏洞猜测，且误报率很高。为了解决这个问题，我们提出了A1，一个将任何LLM转化为端到端漏洞利用生成器的智能体系统。A1为智能体提供了六种领域专用工具，用于自主漏洞发现，从理解合约行为到在真实区块链状态上测试策略。所有输出都通过执行进行具体验证，确保只报告有利可图的概念验证漏洞利用。我们在以太坊和币安智能链上36个真实世界漏洞合约中评估了A1。A1在VERITE基准测试中取得了63%的成功率。在所有成功案例中，A1每次漏洞利用提取高达859万美元，总计933万美元。通过对六个LLM进行的432次实验，我们发现大多数漏洞利用在五次迭代内出现，每次尝试的成本范围为0.01-3.59美元。
使用历史攻击的蒙特卡洛分析，我们证明立即检测漏洞的成功概率为86-89%，而延迟一周则降至6-21%。我们的经济分析揭示了令人不安的不对称性：攻击者在6,000美元的漏洞利用价值下即可实现盈利，而防御者则需要60,000美元——这引发了关于AI智能体是否必然偏向于利用而非防御的根本性问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [141] [Cross-Domain Image Synthesis: Generating H&E from Multiplex Biomarker Imaging](https://arxiv.org/abs/2508.04734)
> *跨域图像合成：从多重生物标志物成像生成H&E图像*

*Jillur Rahman Saurav, Mohammad Sadegh Nasr, Jacob M. Luber* | **Category: cs.AI, eess.IV, q-bio.QM** | **Updated: 2025-08-05**

**Keywords:** 跨域图像合成, 虚拟H&E染色, 多级VQGAN, 多重免疫荧光, 计算机辅助诊断

**Comment:** 

> **TL;DR:** 本研究使用多级VQGAN从多重免疫荧光图像生成虚拟H&E染色图像，以弥合分子和形态学分析之间的差距，并发现其在计算机辅助诊断中优于cGAN。

**AI_Comments:** 本文的创新点在于利用多级VQGAN进行跨域图像合成，特别是将多重免疫荧光图像转换为H&E染色图像，这在病理诊断领域具有重要意义。通过弥合分子和形态学分析之间的差距，它有望极大扩展现有H&E-based CAD工具的应用范围，加速精准医疗的发展。其优势在于生成的虚拟图像不仅视觉上逼真，更重要的是在下游诊断任务中表现出优越的功能性，这对于实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 多重免疫荧光（mIF）成像提供了深入的空间分辨分子数据，但将其与苏木精和伊红（H&E）的形态学标准结合对于获取组织互补信息非常重要。生成虚拟H&E染色图像可以为丰富的分子数据提供即时形态学背景，并使基于H&E的计算机辅助诊断（CAD）工具能够应用于分子数据，从而弥合分子和形态学分析之间的差距。

**Method:** 本研究 investigates 使用多级向量量化生成对抗网络（VQGAN）从mIF图像创建高保真虚拟H&E染色图像。研究将VQGAN与标准条件GAN（cGAN）基线在两个公开结直肠癌数据集上进行了严格评估。

**Result:** 结果显示，虽然VQGAN和cGAN都能生成视觉上合理的图像，但VQGAN生成的虚拟染色图像在计算机辅助诊断中更有效。具体来说，在VQGAN生成的图像上进行的下游细胞核分割和组织分类任务中的语义保留显示出优越的性能，并且与真实分析结果具有更好的一致性，优于cGAN。

**Conclusion:** 本研究表明，多级VQGAN是一种强大且优越的架构，用于生成科学上有用的虚拟染色图像，为将mIF的丰富分子数据整合到已建立且强大的基于H&E的分析工作流程中提供了可行的途径。

> **ai_Abstract:** 本论文提出了一种利用多级向量量化生成对抗网络（VQGAN）从多重免疫荧光（mIF）图像生成高保真虚拟苏木精和伊红（H&E）染色图像的方法。这项技术旨在将丰富的分子数据与形态学背景相结合，并利用现有的H&E计算机辅助诊断工具。通过与条件GAN（cGAN）的比较，研究表明VQGAN生成的虚拟H&E图像在下游的细胞核分割和组织分类等计算机辅助诊断任务中表现出更优异的性能和与真实数据的一致性，证明了其在整合mIF分子数据到H&E分析工作流程中的有效性和优越性。

> **摘要翻译:** 虽然多重免疫荧光（mIF）成像提供了深入的、空间分辨的分子数据，但将这些信息与苏木精和伊红（H&E）的形态学标准结合对于获取底层组织的互补信息可能非常重要。从mIF数据生成虚拟H&E染色图像提供了一个强大的解决方案，能够提供即时的形态学背景。至关重要的是，这种方法使得基于H&E的计算机辅助诊断（CAD）工具的庞大生态系统能够应用于分析丰富的分子数据，弥合了分子和形态学分析之间的差距。在这项工作中，我们研究了使用多级向量量化生成对抗网络（VQGAN）从mIF图像创建高保真虚拟H&E染色图像。我们对我们的VQGAN与标准条件GAN（cGAN）基线在两个公开可用的结直肠癌数据集上进行了严格评估，评估了图像相似性和下游分析的功能效用方面的性能。我们的结果表明，虽然两种架构都能生成视觉上合理的图像，但我们的VQGAN生成的虚拟染色图像为计算机辅助诊断提供了更有效的基质。具体来说，在VQGAN生成的图像上进行的下游细胞核分割和组织分类任务中的语义保留与cGAN相比，显示出卓越的性能和与真实分析结果的一致性。这项工作证实了多级VQGAN是一种强大且优越的架构，用于生成科学上有用的虚拟染色图像，为将mIF的丰富分子数据整合到已建立且强大的基于H&E的分析工作流程中提供了可行的途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [142] [Logic layer Prompt Control Injection (LPCI): A Novel Security Vulnerability Class in Agentic Systems](https://arxiv.org/abs/2507.10457)
> *逻辑层提示控制注入 (LPCI)：代理系统中的一种新型安全漏洞类别*

*Hammad Atta, Ken Huang, Manish Bhatt, Kamal Ahmed, Muhammad Aziz Ul Haq, Yasir Mehmood* | **Category: cs.AI, cs.CR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** LPCI, 大型语言模型, 安全漏洞, 代理系统, 提示注入

**Comment:** 

> **TL;DR:** LLM集成系统存在新型安全漏洞LPCI，它通过在内存中嵌入编码、延迟触发的恶意负载，可绕过输入过滤器并引发未经授权的行为。

**AI_Comments:** 这篇论文揭示了LLM集成系统中的一个重要且隐蔽的安全漏洞类别。LPCI的创新之处在于其利用了逻辑执行层和持久内存的特性，以及其延迟触发和绕过传统过滤器的能力，对LLM代理系统的安全性提出了新的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）集成到企业系统引入了新的隐蔽安全漏洞，特别是在逻辑执行层和持久内存上下文中。

**Method:** 本文介绍了“逻辑层提示控制注入 (LPCI)”这一新型攻击类别，其方法是将编码、延迟且有条件触发的有效载荷嵌入到内存、向量存储或工具输出中。

**Result:** 这些有效载荷可以绕过传统的输入过滤器，并在跨会话中触发未经授权的行为。

**Conclusion:** LPCI是一种新型的安全漏洞，能够利用逻辑执行层和持久内存上下文，绕过传统防御机制，对集成LLM的代理系统构成威胁。

> **ai_Abstract:** 本文介绍了逻辑层提示控制注入（LPCI），这是一种在集成大型语言模型（LLMs）的企业系统中发现的新型隐蔽安全漏洞。LPCI攻击通过在系统的内存、向量存储或工具输出中嵌入编码、延迟且条件触发的恶意载荷，这些载荷能够绕过常规输入过滤器，并在不同会话中引发未经授权的行为。

> **摘要翻译:** 将大型语言模型（LLMs）集成到企业系统中，引入了一类新的隐蔽安全漏洞，特别是在逻辑执行层和持久内存上下文中。本文介绍了逻辑层提示控制注入（LPCI），这是一种新型的攻击类别，它将编码、延迟且有条件触发的有效载荷嵌入到内存、向量存储或工具输出中。这些有效载荷可以绕过传统的输入过滤器，并在跨会话中触发未经授权的行为。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [143] [ADSEL: Adaptive dual self-expression learning for EEG feature selection via incomplete multi-dimensional emotional tagging](https://arxiv.org/abs/2508.05229)
> *ADSEL：基于不完全多维情感标注的自适应双重自表达学习用于脑电特征选择*

*Tianze Yu, Junming Zhang, Wenjia Dong, Xueyuan Xu, Li Zhuo* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 脑电图, 特征选择, 不完整标签, 自表达学习, 情感识别

**Comment:** 

> **TL;DR:** 本文提出ADSEL算法，通过自适应双重自表达学习解决不完全多维情感标注下脑电特征选择中高维和标签缺失问题，提高标签恢复准确性和特征选择效果。

**AI_Comments:** 这篇论文的创新点在于提出了ADSEL算法来解决不完整多维情感标签下的脑电特征选择问题，特别强调了样本级和维度级自表达学习的双向交互，这对于提高标签恢复精度和特征选择效果具有重要意义。它弥补了现有方法在处理不完整标签时忽略样本间相关性的不足。

<details>
  <summary>Details</summary>

**Motivation:** 脑电特征高维性与有限样本量导致分类器过拟合和高计算复杂度。现有方法假设标签完整，但实际中标签常不完整，影响模型泛化。现有处理不完整标签的方法忽视了标签空间中样本间相关性及其与维度的交互。

**Method:** 提出一种新的不完全多维特征选择算法，将自适应双重自表达学习（ADSEL）与最小二乘回归相结合。ADSEL在标签空间中建立样本级和维度级自表达学习过程之间的双向通路，促进学习信息的交叉共享，同时利用样本和维度上的有效信息进行标签重建。

**Result:** ADSEL能够增强标签恢复的准确性，并有效识别用于多维情感识别的最佳脑电特征子集。

**Conclusion:** ADSEL通过其双向自表达学习机制，能有效处理不完整多维标签下的脑电特征选择问题，提高标签恢复和特征选择效果。

> **ai_Abstract:** 本文提出ADSEL（自适应双重自表达学习）算法，旨在解决基于脑电的多维情感识别中，高维特征和不完整多维情感标签导致的分类器过拟合、计算复杂以及模型泛化能力差的问题。ADSEL通过在标签空间中建立样本级和维度级自表达学习的双向通路，促进信息交叉共享，从而有效重建不完整标签并选择最优脑电特征子集，以提高情感识别的准确性。

> **摘要翻译:** 基于脑电的多维情感识别在人机界面中引起了广泛的研究兴趣。然而，脑电特征的高维性，加上有限的样本量，经常导致分类器过拟合和高计算复杂度。特征选择是缓解这些挑战的关键策略。大多数现有的脑电特征选择方法假设多维情感标签是完整的。在实践中，开放的采集环境和情感感知固有的主观性常常导致不完整的标签数据，这会损害模型的泛化能力。此外，现有处理不完整多维标签的特征选择方法主要关注标签恢复过程中各个维度之间的相关性，而忽略了标签空间中样本之间的相关性及其与各个维度的交互。为了解决这些问题，我们提出了一种新颖的、用于基于脑电情感识别的不完全多维特征选择算法。所提出的方法将自适应双重自表达学习（ADSEL）与最小二乘回归相结合。ADSEL在标签空间中建立了样本级和维度级自表达学习过程之间的双向通路。这可以促进这些过程之间学习信息的交叉共享，从而能够同时利用样本和维度上的有效信息进行标签重建。因此，ADSEL可以提高标签恢复的准确性，并有效识别用于多维情感识别的最佳脑电特征子集。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [144] [FDC-Net: Rethinking the association between EEG artifact removal and multi-dimensional affective computing](https://arxiv.org/abs/2508.05231)
> *FDC-Net：重新思考脑电图伪影去除与多维情感计算之间的关联*

*Wenjia Dong, Xueyuan Xu, Tianze Yu, Junming Zhang, Li Zhuo* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 脑电图情感识别, 伪影去除, 噪声鲁棒性, 深度耦合, FDC-Net

**Comment:** 

> **TL;DR:** FDC-Net是一个深度耦合去噪和情感识别的框架，实现了端到端的噪声鲁棒情感识别，并在去噪和情感识别任务上均表现出色。

**AI_Comments:** FDC-Net的创新之处在于其打破了传统上将脑电图去噪和情感识别视为独立任务的范式，通过深度耦合和动态协作机制，实现了端到端的噪声鲁棒情感识别。这种联合优化策略有效地解决了误差累积问题，并挖掘了任务间的协同潜力，为实际应用中的脑电图情感计算提供了更可靠的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑电图情感识别方法将去噪和情感识别视为独立任务，导致误差累积且未能利用任务间的协同作用；同时，传统模型依赖“完美去噪数据”的假设，缺乏系统的噪声鲁棒性设计。

**Method:** 本文提出FDC-Net框架，通过深度耦合去噪和情感识别任务实现端到端噪声鲁棒情感识别。其创新点在于通过双向梯度传播与联合优化策略，以及结合可学习频带位置编码的频率自适应Transformer的门控注意力机制，建立了伪影去除和情感识别之间的动态协作机制。

**Result:** 在DEAP和DREAMER数据集上：去噪任务方面，FDC-Net在DEAP上最大相关系数(CC)为96.30%，在DREAMER上为90.31%。情感识别任务（在生理伪影干扰下）方面，FDC-Net在DEAP上准确率为82.3+7.1%，在DREAMER上为88.1+0.8%。

**Conclusion:** FDC-Net通过深度耦合去噪和情感识别任务，有效解决了传统方法的局限性，在噪声环境下显著提升了脑电图情感识别的去噪和识别性能。

> **ai_Abstract:** 本文提出FDC-Net，一个深度耦合脑电图去噪和情感识别任务的框架，旨在解决现有方法中去噪与识别独立处理导致的误差累积和噪声鲁棒性不足问题。FDC-Net通过双向梯度传播和联合优化，以及结合频率自适应Transformer的门控注意力机制，实现了伪影去除与情感识别的动态协作。实验结果表明，FDC-Net在去噪和噪声环境下的情感识别方面均优于现有先进方法。

> **摘要翻译:** 脑电图（EEG）情感识别在情感计算和脑机接口中具有重要价值。然而，在实际应用中，脑电图记录容易受到各种生理伪影的影响。当前方法通常将去噪和情感识别视为独立的任务，采用级联架构，这不仅导致误差累积，而且未能利用这些任务之间潜在的协同作用。此外，传统的基于脑电图的情感识别模型往往依赖于“完美去噪数据”的理想化假设，缺乏系统性的噪声鲁棒性设计。为了解决这些挑战，本文提出了一种深度耦合去噪和情感识别任务的新型框架，用于端到端的噪声鲁棒情感识别，命名为反馈驱动协作网络（FDC-Net）。我们的主要创新在于通过以下方式在伪影去除和情感识别之间建立动态协作机制：（1）采用联合优化策略的双向梯度传播；（2）将门控注意力机制与使用可学习频带位置编码的频率自适应Transformer相结合。我们采用两个最流行的多维情感标签的脑电图情感数据集（DEAP和DREAMER）来比较FDC-Net与九种最先进方法的伪影去除和情感识别性能。在去噪任务方面，FDC-Net在DEAP上获得了96.30%的最大相关系数（CC）值，在DREAMER上获得了90.31%的最大CC值。在生理伪影干扰下的情感识别任务方面，FDC-Net在DEAP上实现了82.3+7.1%的情感识别准确率，在DREAMER上实现了88.1+0.8%的情感识别准确率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [146] [SPICE: An Automated SWE-Bench Labeling Pipeline for Issue Clarity, Test Coverage, and Effort Estimation](https://arxiv.org/abs/2507.09108)
> *SPICE：一个用于问题清晰度、测试覆盖率和工作量估算的自动化SWE-Bench标注管道*

*Gustavo A. Oliva, Gopi Krishnan Rajbahadur, Aaditya Bhatia, Haoxiang Zhang, Yihao Chen, Zhilong Chen, Arthur Leung, Dayi Lin, Boyuan Chen, Ahmed E. Hassan* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 自动化标注, 软件工程, 数据集, 基础模型, SPICE

**Comment:** 

> **TL;DR:** SPICE是一个自动化管道，用于经济高效地标注大规模软件工程数据集，解决高质量数据创建成本高昂的问题。

**AI_Comments:** SPICE的创新之处在于其自动化标注流程，显著降低了高质量软件工程数据集的创建成本，从根本上解决了阻碍基础模型发展的“数据瓶颈”问题。其结合多种技术（上下文感知代码导航、理由驱动提示、多遍共识）来模拟专家标注，并取得了与人工高度一致的结果，具有重要的实际应用价值。发布的工具和数据集将极大地推动软件工程领域AI模型的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 高质量的标注数据集对于训练和评估软件工程中的基础模型至关重要，但创建它们通常成本高昂且劳动密集。

**Method:** SPICE结合了上下文感知代码导航、理由驱动提示和多遍共识，以生成近似专家标注的标签。

**Result:** SPICE与人工标注的SWE-bench验证数据高度一致，并将标注1,000个实例的成本从约100,000美元（手动标注）降低到仅5.10美元。同时，发布了SPICE工具和SPICE Bench数据集（包含6,802个SPICE标注实例，比SWE-bench Verified大13倍以上）。

**Conclusion:** SPICE展示了其在为以SE为重点的基础模型创建经济高效、大规模数据集方面的潜力，并能支持社区发展。

> **ai_Abstract:** 本文介绍了SPICE，一个自动化管道，旨在解决软件工程领域中高质量标注数据集创建成本高昂的问题。SPICE通过结合上下文感知代码导航、理由驱动提示和多遍共识，能够自动为SWE-bench风格的数据集标注问题清晰度、测试覆盖率和工作量估算。实验结果表明，SPICE能与人工标注数据高度一致，并将千例标注成本从10万美元降至5.10美元。研究者还发布了SPICE工具和包含6,802个实例的SPICE Bench数据集，以支持社区。

> **摘要翻译:** 高质量的标注数据集对于训练和评估软件工程中的基础模型至关重要，但创建它们往往成本高昂且劳动密集。我们引入了SPICE，这是一个可扩展的自动化管道，用于标注SWE-bench风格的数据集，并提供问题清晰度、测试覆盖率和工作量估算的注释。SPICE结合了上下文感知代码导航、理由驱动提示和多遍共识，以生成与专家标注高度近似的标签。SPICE的设计灵感来自于我们自己在标注SWE-Gym中800多个实例时的经验和挫败感。SPICE与人工标注的SWE-bench验证数据取得了高度一致，同时将标注1,000个实例的成本从大约100,000美元（手动标注）降低到仅5.10美元。这些结果表明SPICE在为以SE为重点的基础模型实现经济高效、大规模数据集创建方面的潜力。为了支持社区，我们发布了SPICE工具和SPICE Bench，这是一个新的数据集，包含从SWE-Gym中291个开源项目整理的6,802个SPICE标注实例（比SWE-bench Verified大13倍以上）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [154] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
> *面向公平灾后电力恢复的不确定性感知预测-优化框架*

*Lin Jiang, Dahai Yu, Rongchao Xu, Tian Tang, Guang Wang* | **Category: cs.AI, cs.LG, cs.SI** | **Updated: 2025-08-06**

**Keywords:** 电力恢复, 公平性, 不确定性感知, 预测-优化, 强化学习

**Comment:** 

> **TL;DR:** 该研究提出了一个名为EPOPR的预测-优化框架，通过考虑不确定性和解决弱势社区请求量差异，实现高效公平的灾后电力恢复。

**AI_Comments:** 该论文的创新点在于提出了一个将不确定性感知预测与公平性优化相结合的框架，特别关注了弱势社区在灾后电力恢复中的被忽视问题。通过结合两种机器学习方法（分位数回归和强化学习）来处理预测不确定性和决策公平性，为解决实际社会问题提供了有价值的解决方案。其重要性体现在提升灾后响应效率和促进社会公平。

<details>
  <summary>Details</summary>

**Motivation:** 极端天气事件日益频繁，凸显了高效公平电力系统恢复的迫切需求。当前电力提供商主要基于区域请求量做决策，但数据分析显示弱势社区的请求提交量存在显著差异，导致现有恢复方案不公平，使这些社区面临更长时间的停电。

**Method:** 本文设计了一个名为EPOPR的预测-优化框架，包含两个关键组件：1) 公平共形分位数回归，用于不确定性感知的修复持续时间预测；2) 空间-时间注意力强化学习，用于适应不同区域的不确定性水平，以实现公平决策。

**Result:** 实验结果表明，与最先进的基线相比，EPOPR有效减少了平均停电持续时间3.60%，并使不同社区之间的不公平性降低了14.19%。

**Conclusion:** 本文成功提出了一个考虑不确定性并平衡效率与公平的电力恢复策略，显著改善了灾后电力恢复的效率和公平性。

> **ai_Abstract:** 本文提出了一个名为EPOPR的预测-优化框架，旨在解决灾后电力恢复中的效率和公平性问题。研究发现，现有恢复策略因弱势社区请求量低估而导致不公平。EPOPR通过结合公平共形分位数回归进行不确定性感知的修复时间预测，以及空间-时间注意力强化学习进行公平决策，克服了预测不确定性和强化学习偏好低不确定性行动的挑战。实验证明，EPOPR在减少停电时间和提高社区公平性方面优于现有基线。

> **摘要翻译:** 极端天气事件（如飓风）的发生频率日益增加，凸显了对高效和公平电力系统恢复的迫切需求。许多电力供应商主要根据各区域的电力恢复请求量做出恢复决策。然而，我们的数据驱动分析显示，请求提交量存在显著差异，因为弱势社区往往提交较少的恢复请求。这种差异使得当前的恢复解决方案不公平，使这些社区容易遭受长时间的停电。为了解决这个问题，我们旨在提出一种兼顾恢复效率和社区公平的电力恢复策略。然而，实现这一目标面临两个挑战：在数据集异方差性下预测修复持续时间的困难，以及强化学习代理倾向于选择低不确定性行动，这可能损害公平性。为了克服这些挑战，我们设计了一个名为EPOPR的预测-优化框架，包含两个关键组件：(1) 公平共形分位数回归，用于不确定性感知的修复持续时间预测；(2) 空间-时间注意力强化学习，用于适应不同区域的不确定性水平，以实现公平决策。实验结果表明，与最先进的基线相比，我们的EPOPR有效减少了平均停电持续时间3.60%，并使不同社区之间的不公平性降低了14.19%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [155] [ERDES: A Benchmark Video Dataset for Retinal Detachment and Macular Status Classification in Ocular Ultrasound](https://arxiv.org/abs/2508.04735)
> *ERDES：一个用于眼部超声视网膜脱离和黄斑状态分类的基准视频数据集*

*Pouyan Navard, Yasemin Ozkut, Srikar Adhikari, Elaine Situ-LaCasse, Josie Acuña, Adrienne Yarnish, Alper Yilmaz* | **Category: cs.AI, q-bio.QM** | **Updated: 2025-08-05**

**Keywords:** 视网膜脱离, 黄斑状态, 眼部超声, 数据集, 深度学习

**Comment:** 

> **TL;DR:** ERDES是首个用于眼部超声视网膜脱离和黄斑状态分类的开放获取视频数据集，并提供了基准机器学习模型。

**AI_Comments:** ERDES数据集的创新之处在于它是首个专门用于眼部超声视网膜脱离和黄斑状态分类的开放获取视频数据集，这对于推动深度学习在该领域的应用至关重要。其重要性体现在解决了当前临床实践中超声图像判读缺乏专业知识的问题，并为开发自动化诊断工具提供了宝贵资源。该数据集的发布及其提供的基准将显著加速视网膜脱离诊断AI算法的研发。

<details>
  <summary>Details</summary>

**Motivation:** 现有超声图像判读缺乏专业知识，尤其是在资源有限地区。目前尚无用于临床的视网膜脱离机器学习超声算法，也无使用超声评估黄斑状态的研究，且缺乏支持黄斑相关视网膜脱离分类的公开数据集。

**Method:** 研究引入了ERDES数据集，这是首个开放获取的眼部超声视频数据集，其中包含视网膜脱离的存在与否以及黄斑完整或黄斑脱离状态的标签。同时，使用多种时空卷积神经网络（CNN）架构提供了基准性能。

**Result:** 成功构建并发布了ERDES数据集，该数据集是首个用于视网膜脱离和黄斑状态分类的开放获取眼部超声视频数据集。同时，为该数据集提供了基于时空CNN的基准性能。

**Conclusion:** ERDES数据集的发布旨在促进用于检测视网膜脱离的机器学习模型的开发和评估，填补了该领域缺乏公开数据集的空白，并为未来的研究提供了基础。

> **ai_Abstract:** 本研究介绍了ERDES数据集，这是首个开放获取的眼部超声视频数据集，用于视网膜脱离（RD）及其黄斑状态（完整或脱离）的分类。鉴于当前超声判读缺乏专业知识和缺乏相关公开数据集，ERDES旨在促进机器学习模型在该领域的开发与评估。研究提供了基于时空卷积神经网络的基准性能，并公开了所有数据、标签和训练代码，以加速自动化RD诊断算法的研发。

> **摘要翻译:** 视网膜脱离（RD）是一种威胁视力的疾病，需要及时干预以保护视力。黄斑受累——黄斑是完整（黄斑完整）还是脱离（黄斑脱离）——是视觉结局和治疗紧急程度的关键决定因素。床旁超声（POCUS）提供了一种快速、无创、经济且易于获取的成像方式，广泛用于各种临床环境中以检测视网膜脱离。然而，超声图像判读受到医疗服务提供者缺乏专业知识的限制，尤其是在资源有限的地区。深度学习为视网膜脱离的超声评估自动化提供了潜力。然而，目前没有可用于临床的机器学习超声算法来检测视网膜脱离，也没有关于使用超声评估视网膜脱离病例中黄斑状态的先验研究——这是手术优先级划分的重要区别。此外，目前没有公共数据集支持使用超声视频剪辑进行基于黄斑的视网膜脱离分类。我们引入了眼部视网膜脱离超声（ERDES），这是第一个开放获取的眼部超声剪辑数据集，其标签包含（i）视网膜脱离的存在和（ii）黄斑完整与黄斑脱离状态。该数据集旨在促进用于检测视网膜脱离的机器学习模型的开发和评估。我们还使用多种时空卷积神经网络（CNN）架构提供了基线基准。所有剪辑、标签和训练代码均可在 https://osupcvlab.github.io/ERDES/ 公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [156] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
> *资源受限的多模态情感推理与分类：通过思维链增强和蒸馏*

*Haonan Shangguan, Xiaocui Yang, Shi Feng, Daling Wang, Yifei Zhang, Ge Yu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多模态情感分析, 思维链, 蒸馏, 资源受限, 大语言模型

**Comment:** 

> **TL;DR:** 提出MulCoT-RD模型，利用“教师-助手-学生”蒸馏范式，在资源受限环境下实现轻量级多模态情感推理与分类。

**AI_Comments:** 该论文的创新点在于将思维链（Chain-of-Thought）与蒸馏技术结合，解决了多模态情感分析在资源受限环境下的部署难题。通过“教师-助手-学生”范式，有效地将大型模型的推理能力迁移到轻量级模型中，提高了实际应用的可行性，并兼顾了性能、泛化能力和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态情感分析主要依赖参数量大的大语言模型，忽视了在资源受限环境中自主生成多模态情感推理的能力。因此，本文关注资源受限下的联合多模态情感推理与分类（JMSRC）任务。

**Method:** 提出MulCoT-RD模型，采用“教师-助手-学生”蒸馏范式。首先，利用高性能多模态大语言模型生成初始推理数据集；然后，训练一个中等大小的助手模型，结合多任务学习机制；最后，联合训练一个轻量级学生模型，以高效执行多模态情感推理生成和分类。

**Result:** 在四个数据集上的大量实验表明，参数量仅为3B的MulCoT-RD模型在JMSRC任务上取得了强大的性能，同时展现出鲁棒的泛化能力和增强的可解释性。

**Conclusion:** 本文提出的MulCoT-RD模型成功解决了资源受限环境下联合多模态情感推理和分类的挑战，实现了轻量级模型的优异性能、鲁棒泛化能力和可解释性。

> **ai_Abstract:** 本文针对资源受限环境下联合多模态情感推理与分类（JMSRC）任务，提出了一种名为MulCoT-RD的思维链推理蒸馏模型。该模型采用“教师-助手-学生”蒸馏范式，利用高性能多模态大语言模型生成推理数据集，并训练中等助手模型和轻量级学生模型。实验证明，MulCoT-RD模型在仅有3B参数的情况下，在JMSRC任务上表现出色，并具有良好的泛化能力和可解释性。

> **摘要翻译:** 社交媒体平台上丰富的多模态内容的激增极大地推动了多模态情感分析（MSA）的发展，大型语言模型（LLMs）进一步加速了该领域的进展。当前方法主要利用参数量大的（多模态）LLMs的知识和推理能力进行情感分类，却忽视了在资源受限环境中自主生成多模态情感推理。因此，我们关注资源受限的联合多模态情感推理与分类（JMSRC）任务，该任务仅用轻量级模型同时执行多模态情感推理链生成和情感分类。我们提出了一种多模态思维链推理蒸馏模型（MulCoT-RD），专为JMSRC设计，采用“教师-助手-学生”蒸馏范式来解决资源受限环境中的部署约束。我们首先利用高性能多模态大型语言模型（MLLM）生成初始推理数据集，并训练一个结合多任务学习机制的中等大小助手模型。然后，联合训练一个轻量级学生模型，以执行高效的多模态情感推理生成和分类。在四个数据集上的大量实验表明，MulCoT-RD模型仅用3B参数就在JMSRC上取得了强大的性能，同时展现出鲁棒的泛化能力和增强的可解释性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [157] [$\texttt{Droid}$: A Resource Suite for AI-Generated Code Detection](https://arxiv.org/abs/2507.10583)
> *Droid：一个用于AI生成代码检测的资源套件*

*Daniil Orel, Indraneil Paul, Iryna Gurevych, Preslav Nakov* | **Category: cs.AI, cs.CY, cs.SE** | **Updated: 2025-08-06**

**Keywords:** AI生成代码检测, DroidCollection, DroidDetect, 对抗性训练, 度量学习

**Comment:** 

> **TL;DR:** 本文介绍了DroidCollection，一个用于AI生成代码检测的大型数据集，以及DroidDetect，一个新的检测器。研究表明现有检测器泛化能力差且易受攻击，但通过对抗性训练和其他技术可以改进。

**AI_Comments:** 该论文的创新之处在于编译了迄今为止最广泛的AI生成代码检测开放数据集，其中包含了多样化的代码类型和对抗性样本，直接解决了现有检测器在泛化性和鲁棒性方面的问题。DroidDetect的开发以及通过对抗性训练和先进学习技术提升检测器韧性的实证演示，对AI安全和保障领域做出了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器生成代码检测器在多样化的编码领域和编程语言中泛化能力不足，并且容易受到“人性化”输出分布的影响。

**Method:** 作者编译了DroidCollection，这是一个用于训练和评估机器生成代码检测器的广泛开放数据集，包含超过一百万个代码样本、七种编程语言、来自43个编码模型的输出以及三个以上的真实世界编码领域，其中还包括人类-AI合著代码和对抗性样本。随后，他们开发了DroidDetect，一个使用多任务目标在DroidCollection上训练的编码器专用检测器套件。

**Result:** 实验表明，现有检测器的性能无法泛化到其狭窄训练数据之外的多样化编码领域和编程语言。大多数检测器容易被通过表面提示和对齐方法“人性化”输出分布所规避，但通过少量对抗性数据训练可以轻松修正这个问题。此外，研究还证明了度量学习和基于不确定性的重采样可以有效增强在可能嘈杂分布上的检测器训练。

**Conclusion:** 本文介绍了一个全面的数据集和一套检测器，揭示了现有检测器的局限性，并提出了有效的策略（对抗性训练、度量学习、基于不确定性的重采样）来提高AI生成代码检测的鲁棒性和泛化能力。

> **ai_Abstract:** 本文推出了DroidCollection，一个用于训练和评估AI生成代码检测器的全面开放数据集，包含超过一百万个样本，涵盖多种语言和领域，并包括人类-AI合著代码和对抗性代码。在此基础上，作者开发了DroidDetect，一个基于多任务目标训练的编码器专用检测器套件。研究结果表明，当前检测器在不同编码环境下的泛化能力不足，且易受“人性化”输出的影响，但通过对抗性数据训练可以有效缓解此问题。此外，该研究还强调了度量学习和基于不确定性的重采样对于鲁棒检测器训练的益处。

> **摘要翻译:** 在这项工作中，我们编译了DroidCollection，这是用于训练和评估机器生成代码检测器的最广泛的开放数据套件，包括超过一百万个代码样本、七种编程语言、来自43个编码模型的输出以及三个以上的真实世界编码领域。除了完全由AI生成的样本外，我们的集合还包括人类-AI合著代码以及明确旨在逃避检测的对抗性样本。随后，我们开发了DroidDetect，一个使用多任务目标在DroidCollection上训练的编码器专用检测器套件。我们的实验表明，现有检测器的性能无法泛化到其狭窄训练数据之外的多样化编码领域和编程语言。此外，我们证明了虽然大多数检测器很容易通过使用表面提示和对齐方法“人性化”输出分布而被攻破，但通过少量对抗性数据训练可以轻松修正这个问题。最后，我们证明了度量学习和基于不确定性的重采样作为在可能嘈杂的分布上增强检测器训练的有效手段。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [162] [Evaluating the Impact of LLM-guided Reflection on Learning Outcomes with Interactive AI-Generated Educational Podcasts](https://arxiv.org/abs/2508.04787)
> *评估大型语言模型引导的反思对交互式人工智能生成教育播客学习成果的影响*

*Vishnu Menon, Andy Cherney, Elizabeth B. Cloude, Li Zhang, Tiffany D. Do* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-06**

**Keywords:** LLM, 反思, 教育播客, 学习成果, 用户体验

**Comment:** 

> **TL;DR:** 一项研究发现，在AI生成播客中嵌入LLM引导的反思提示并未显著提高学习成果，反而降低了用户感知吸引力，提示未来需更多研究反思性交互设计。

**AI_Comments:** 该研究揭示了一个反直觉的发现，即旨在提升学习的LLM引导反思提示反而降低了用户体验，这对于设计未来的教育AI工具具有重要意义。它强调了将AI融入教育的复杂性，不仅仅是内容生成。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨在交互式人工智能生成播客中嵌入大型语言模型引导的反思提示是否能改善学习效果和用户体验。

**Method:** 36名本科生参与了实验，比较了包含LLM引导反思提示的版本与不含提示的版本。

**Result:** 不同条件下的学习成果相似，但反思提示降低了用户感知到的吸引力。

**Conclusion:** 需要对反思性交互设计进行更多研究。

> **ai_Abstract:** 本研究调查了在交互式AI生成教育播客中嵌入LLM引导的反思提示对学习成果和用户体验的影响。实验招募了36名本科生，比较了有提示和无提示的版本。结果显示，学习成果在两组间无显著差异，但反思提示降低了播客的感知吸引力。研究呼吁未来需加强对反思性交互设计的深入研究。

> **摘要翻译:** 本研究旨在探讨在交互式人工智能生成播客中嵌入大型语言模型引导的反思提示是否能改善学习效果和用户体验，并将其与不含提示的版本进行比较。共有36名本科生参与。结果显示，尽管不同条件下的学习成果相似，但反思提示降低了用户感知到的吸引力，这表明需要对反思性交互设计进行更多研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [163] [Navigating the Trade-off: A Synthesis of Defensive Strategies for Zero-Shot Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2508.05237)
> *权衡取舍：视觉-语言模型零样本对抗鲁棒性防御策略的综合研究*

*Zane Xu, Jason Sun* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 零样本对抗鲁棒性, 视觉-语言模型, 防御策略, 对抗微调, 权衡

**Comment:** 

> **TL;DR:** 本报告综合分析了八篇关于视觉-语言模型零样本对抗鲁棒性的重要论文，探讨了鲁棒性与泛化能力间的权衡，分析了主要的防御范式及演变，并指出了未来的挑战与方向。

**AI_Comments:** 这篇论文通过综合分析现有研究，为视觉-语言模型在零样本对抗鲁棒性方面提供了全面的视角。其价值在于系统梳理了不同防御策略的演变，并明确指出了该领域面临的挑战和潜在的未来研究方向，对于指导后续研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决视觉-语言模型在增强对抗鲁棒性与保持零样本泛化能力之间存在的固有权衡问题。

**Method:** 本报告综合分析了八篇关于视觉-语言模型（VLMs）零样本对抗鲁棒性的重要论文，并分析了两种主要的防御范式：修改模型参数的对抗微调（AFT）和保留模型参数的无训练/测试时防御。报告还追溯了从对齐保持方法到嵌入空间重构、从输入启发式到潜在空间净化的防御策略演变。

**Result:** 识别了视觉-语言模型零样本对抗鲁棒性领域的关键挑战和未来的研究方向，包括混合防御策略和对抗性预训练。

**Conclusion:** 本报告综合了视觉-语言模型零样本对抗鲁棒性的防御策略，并指出了该领域的关键挑战和未来发展方向。

> **ai_Abstract:** 这篇报告综合了八篇关于视觉-语言模型（如CLIP）零样本对抗鲁棒性的核心论文。它深入分析了提升对抗鲁棒性与维持零样本泛化能力之间的关键权衡，并探讨了对抗微调和无训练/测试时防御这两种主要防御范式。报告追溯了不同防御方法的演变，并提出了该领域的关键挑战和未来的研究方向，如混合防御策略和对抗性预训练。

> **摘要翻译:** 本报告综合了八篇关于CLIP等视觉-语言模型（VLMs）零样本对抗鲁棒性的重要论文。该领域的一个核心挑战是增强对抗鲁棒性与保持模型零样本泛化能力之间的固有权衡。我们分析了两种主要的防御范式：对抗微调（AFT），它修改模型参数；以及无训练/测试时防御，它保留模型参数。我们追溯了从对齐保持方法（TeCoA）到嵌入空间重构（LAAT, TIMA），以及从输入启发式（AOM, TTC）到潜在空间净化（CLIPure）的演变。最后，我们识别了关键挑战和未来方向，包括混合防御策略和对抗性预训练。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [164] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
> *学习重要内容：基于互信息的概率任务选择用于模型微调*

*Prateek Chanda, Saral Sureka, Parth Pratim Chatterjee, Krishnateja Killamsetty, Nikhil Shivakumar Nayak, Ganesh Ramakrishnan* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** LLM微调, 任务选择, 马尔可夫随机场, 互信息, 混合优化

**Comment:** 

> **TL;DR:** TASKPGM是一个原则性的、可扩展的框架，通过最小化马尔可夫随机场上的能量函数来优化大型语言模型微调的任务组合，解决了现有方法手动和启发式的问题。

**AI_Comments:** 本文提出了一种新颖且具有原则性的方法来解决LLM微调中任务选择的难题，通过引入基于MRF的混合优化框架TASKPGM，克服了传统手动和启发式方法的局限性。其创新之处在于利用行为散度建模任务关系，并提供闭式解和理论保证，同时兼顾了任务的代表性和多样性。该方法不仅提升了模型性能，还提供了可解释性，对于推动LLM的高效和鲁棒微调具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLMs）的性能关键取决于训练混合的组成，但选择最佳任务数据集组合仍然是一个手动、启发式驱动的过程，通常依赖于统一或基于大小的采样策略。

**Method:** 本文提出了TASKPGM框架，通过在马尔可夫随机场（MRF）上最小化能量函数来选择连续任务比例。任务关系通过行为散度（如Jensen Shannon散度、点互信息）建模，这些散度从单任务微调模型的预测分布计算得出。该方法在单纯形约束下提供了闭式解，并能平衡任务的代表性和多样性。

**Result:** TASKPGM在Llama 2和Mistral模型上，在MMLU和BIGBench等评估套件中展现出持续的经验改进。该方法还提供了理论保证，包括预算变体的弱次模性。除了性能提升，TASKPGM还提供了对任务影响和混合组成的解释性洞察。

**Conclusion:** TASKPGM是一个强大的工具，可用于高效且鲁棒的LLM微调，它能提供可解释的任务影响和混合组成洞察。

> **ai_Abstract:** 本文提出了TASKPGM，一个用于优化大型语言模型微调任务组合的原则性且可扩展的框架。该方法通过在马尔可夫随机场上最小化能量函数来选择任务比例，并利用行为散度（如Jensen Shannon散度、点互信息）建模任务关系。TASKPGM在单纯形约束下提供闭式解，并能平衡任务的代表性和多样性。实验证明，其在Llama 2和Mistral模型上实现了性能提升，并提供了任务影响和混合组成的可解释性。

> **摘要翻译:** 微调大型语言模型（LLMs）的性能关键取决于训练混合的组成。然而，选择最佳任务数据集组合仍然是一个很大程度上依赖手动、启发式驱动的过程，从业者通常依赖统一或基于大小的采样策略。我们引入了TASKPGM，一个原则性的、可扩展的混合优化框架，它通过最小化马尔可夫随机场（MRF）上的能量函数来选择连续的任务比例。任务关系通过行为散度建模，例如从单任务微调模型的预测分布计算得到的Jensen Shannon散度（Jensen Shannon Divergence）和点互信息（Pointwise Mutual Information）。我们的方法在单纯形约束下提供了闭式解，并能证明在任务之间平衡了代表性和多样性。我们提供了理论保证，包括预算变体的弱次模性，并展示了在Llama 2和Mistral模型上，在MMLU和BIGBench等评估套件中持续的经验改进。除了性能之外，TASKPGM还提供了对任务影响和混合组成的可解释性洞察，使其成为一个用于高效和鲁棒LLM微调的强大工具。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [169] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
> *利用冻结LLM增强对话标注的说话者特征*

*Thomas Thebaud, Yen-Ju Lu, Matthew Wiesner, Peter Viechnicki, Najim Dehak* | **Category: cs.AI, cs.CL, cs.SD, eess.AS** | **Updated: 2025-08-06**

**Keywords:** 对话标注, 说话者特征, 冻结LLM, 音频基础模型, 后处理

**Comment:** 

> **TL;DR:** 该研究提出一种利用冻结的音频基础模型（如Whisper或WavLM）和冻结的LLAMA语言模型，在无需微调的情况下，为对话转录添加说话者特征（如年龄、性别、情感）元数据的方法，实现了有竞争力的性能。

**AI_Comments:** 该研究的创新之处在于利用冻结的预训练模型（包括音频基础模型和LLM）来推断说话者特征，从而避免了昂贵的微调成本。这突显了预训练模型强大的表征能力及其在模块化、高效集成到新任务中的潜力。此外，LLAMA模型能够直接比较x-向量的发现也值得关注，这暗示了LLM在音频处理领域更广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 在对话转录流程中，现有的大型语言模型（LLM）主要用于改进语法、标点和可读性。本文旨在探索一个补充性的后处理步骤，即通过添加说话者特征（如年龄、性别、情感）的元数据标签来丰富转录的对话。

**Method:** 该方法将冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型相结合，以推断说话者属性。它使用轻量级、高效的连接器来桥接音频和语言表示，且无需对任何模型进行特定任务的微调。

**Result:** 在说话者分析任务上取得了有竞争力的性能，同时保持了模块化和速度。此外，证明了冻结的LLAMA模型可以直接比较x-向量，在某些情况下实现了8.8%的等错误率（EER）。

**Conclusion:** 通过结合冻结的音频基础模型和冻结的LLAMA语言模型，无需进行任务特定的微调，即可有效增强对话标注的说话者特征，并在说话者分析任务上表现出竞争力，同时LLAMA模型也展现了直接比较x-向量的能力。

> **ai_Abstract:** 本文提出一种创新的后处理方法，通过向转录对话添加说话者特征（如年龄、性别、情感）元数据来增强对话标注。该方法结合了冻结的音频基础模型（如Whisper或WavLM）和冻结的LLAMA语言模型，并利用轻量级连接器桥接音频和语言表示。这种系统能够在不进行任务特定微调的情况下推断说话者属性，从而在说话者分析任务中实现了有竞争力的性能，并保持了模块化和速度。此外，研究还展示了LLAMA模型直接比较x-向量的能力，并在某些场景下达到了8.8%的等错误率。

> **摘要翻译:** 在对话转录流程中，大型语言模型（LLM）经常用于后处理以改进语法、标点和可读性。我们探索了一种补充性的后处理步骤：通过添加说话者特征的元数据标签（如年龄、性别和情感）来丰富转录的对话。其中一些标签是对话全局性的，而另一些是随时间变化的。我们的方法将冻结的音频基础模型（如Whisper或WavLM）与冻结的LLAMA语言模型结合，以推断这些说话者属性，而无需对任何模型进行特定任务的微调。通过使用轻量级、高效的连接器来桥接音频和语言表示，我们在说话者分析任务上取得了有竞争力的性能，同时保持了模块化和速度。此外，我们证明了一个冻结的LLAMA模型可以直接比较x-向量，在某些情况下实现了8.8%的等错误率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [170] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
> *扩散模型在数据受限环境下优于自回归模型*

*Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak* | **Category: cs.AI, cs.CV, cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 扩散模型, 自回归模型, 数据受限, 语言模型, 隐式数据增强

**Comment:** 

> **TL;DR:** 在数据受限但计算资源充足的情况下，扩散语言模型显著优于自回归模型，因为它们能更好地利用重复数据。

**AI_Comments:** 这项研究具有重要意义，因为它挑战了大型语言模型领域中自回归模型的传统主导地位，特别是在数据稀缺的实际场景中。其创新点在于系统性地探索了扩散模型在数据受限环境下的优势，并提出了“隐式数据增强”这一解释。发现新的缩放定律和临界计算阈值也为未来模型设计和资源分配提供了理论指导。这为在特定约束条件下开发更高效、性能更好的语言模型开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 自回归模型长期主导大型语言模型领域，但扩散语言模型作为一种有前景的替代方案，其优势尚未得到充分探索。本文旨在系统研究在数据受限环境下掩码扩散模型的表现。

**Method:** 本文系统研究了在数据受限（训练涉及对有限数据进行重复传递）环境下掩码扩散模型，并与自回归模型进行了比较。研究还探讨了新的扩散模型缩放定律并推导了临界计算阈值的闭式表达式。

**Result:** 研究发现，当计算资源充足但数据稀缺时，扩散模型显著优于自回归模型。扩散模型能更好地利用重复数据，达到更低的验证损失和更优的下游性能。这种优势被解释为隐式数据增强，因为掩码扩散模型将模型暴露在多样化的token排序和预测任务中。此外，还发现了扩散模型的新缩放定律，并推导出了扩散模型开始超越自回归模型的临界计算阈值的闭式表达式。

**Conclusion:** 当数据而非计算是瓶颈时，扩散模型为标准的自回归范式提供了一个引人注目的替代方案。

> **ai_Abstract:** 本文系统研究了在数据受限环境下，掩码扩散语言模型与自回归模型的性能对比。研究发现，在计算资源充足但数据稀缺时，扩散模型显著优于自回归模型，因其能更有效地利用重复数据，实现更好的验证损失和下游性能。这种优势被归因于隐式数据增强，即扩散模型能暴露于更丰富的token排序和预测任务。论文还提出了扩散模型的新缩放定律，并给出了其超越自回归模型的临界计算阈值的闭式表达式。研究结果表明，在数据为瓶颈的场景下，扩散模型是自回归模型的有力替代。

> **摘要翻译:** 自回归（AR）模型长期以来一直主导着大型语言模型的领域，推动了各种任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相对于AR模型的优势尚未得到充分探索。在本文中，我们系统地研究了数据受限环境（训练涉及对有限数据进行重复传递）下的掩码扩散模型，发现当计算资源充足但数据稀缺时，它们显著优于AR模型。扩散模型能更好地利用重复数据，实现更低的验证损失和更优的下游性能。我们将这种优势解释为隐式数据增强：与AR固定的从左到右分解不同，掩码扩散模型使模型暴露在多样化的token排序和预测任务分布中。我们发现了扩散模型的新缩放定律，并推导出了扩散模型开始超越AR模型的临界计算阈值的闭式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准的AR范式提供了一个引人注目的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [171] [Driver Assistant: Persuading Drivers to Adjust Secondary Tasks Using Large Language Models](https://arxiv.org/abs/2508.05238)
> *驾驶助手：使用大型语言模型说服驾驶员调整次级任务*

*Wei Xiang, Muchen Li, Jie Yan, Manling Zheng, Hanfei Zhu, Mengyun Jiang, Lingyun Sun* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 驾驶员辅助, 自动驾驶, 次级任务, 认知负荷

**Comment:** 

> **TL;DR:** 该研究使用大型语言模型（LLM）通过人性化的说服建议帮助L3级自动驾驶系统的驾驶员在紧急情况下保持对路况的适当关注并降低认知负荷。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型应用于驾驶员辅助系统，通过“人性化”的说服方式来管理驾驶员在L3级自动驾驶中的次级任务和注意力。这种方法有望提高自动驾驶系统的安全性，尤其是在需要驾驶员接管的紧急情况下的表现。

<details>
  <summary>Details</summary>

**Motivation:** L3级自动驾驶系统允许驾驶员进行次级任务，但会降低他们对风险的感知。在需要驾驶员干预的紧急情况下，系统会发出警报，留给驾驶员的反应时间有限，并带来巨大的认知负担。

**Method:** 该研究采用大型语言模型（LLM）通过“人性化”的说服建议来帮助驾驶员保持对路况的适当关注。该工具利用L3系统遇到的路况作为触发器，通过视觉和听觉途径主动引导驾驶员行为。

**Result:** 经验研究表明，该工具能有效维持驾驶员的注意力，降低认知负荷，并协调次级任务与接管行为。

**Conclusion:** 该工作为使用大型语言模型在多任务自动驾驶中支持驾驶员的潜力提供了见解。

> **ai_Abstract:** 本研究提出并评估了一个基于大型语言模型（LLM）的驾驶助手，旨在帮助L3级自动驾驶系统中的驾驶员在紧急情况下保持适当的道路关注，同时降低认知负荷。该系统通过检测路况并提供人性化的视觉和听觉说服建议来主动引导驾驶员行为。实证结果证明了其在维持驾驶员注意力、减少认知负担和协调次级任务与接管行为方面的有效性。

> **摘要翻译:** L3级自动驾驶系统允许驾驶员进行次级任务，同时降低他们对风险的感知。在需要驾驶员干预的紧急情况下，系统会发出警报，留给驾驶员的反应时间有限，并带来巨大的认知负担。为解决这一挑战，本研究采用大型语言模型（LLM）通过“人性化”的说服建议来帮助驾驶员保持对路况的适当关注。我们的工具利用L3系统遇到的路况作为触发器，通过视觉和听觉途径主动引导驾驶员行为。实证研究表明，我们的工具能有效维持驾驶员的注意力，降低认知负荷，并协调次级任务与接管行为。我们的工作为使用大型语言模型在多任务自动驾驶中支持驾驶员的潜力提供了见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [172] [Generative Multi-Target Cross-Domain Recommendation](https://arxiv.org/abs/2507.12871)
> *生成式多目标跨域推荐*

*Jinqiu Jin, Yang Zhang, Fuli Feng, Xiangnan He* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 生成式推荐, 跨域推荐, 多目标推荐, 语义标识符, 序列到序列模型

**Comment:** 

> **TL;DR:** GMC是一种基于生成范式的多目标跨域推荐方法，它利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多领域知识，并在多个公共数据集上表现出有效性。

**AI_Comments:** GMC的创新之处在于其采用生成式范式和语义量化离散物品标识符来解决多目标跨域推荐问题，特别是在处理无共享实体或无需大量辅助数据的情况下。这为跨域推荐领域提供了一个新颖且高效的解决方案，有望推动该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多目标跨域推荐（MTCDR）方法主要依赖于域共享实体进行知识融合和迁移，这在非重叠推荐场景中可能不可用。另一些方法则需要大量的辅助数据进行预训练。因此，开发更有效的MTCDR解决方案是一个重要的探索领域。

**Method:** 本文提出了GMC，一种基于生成范式的多目标跨域推荐方法。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多领域知识。具体而言，GMC首先使用物品分词器为每个物品生成域共享的语义标识符，然后通过训练一个域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用领域信息提升性能，GMC在语义标识符学习中融入了领域感知对比损失，并对统一推荐器执行领域特定的微调。

**Result:** 在五个公共数据集上进行的广泛实验表明，与一系列基线方法相比，GMC表现出有效性。

**Conclusion:** GMC作为一种基于生成范式的方法，通过利用语义量化的离散物品标识符和统一的生成模型，有效解决了多目标跨域推荐中的挑战，并在实验中验证了其优越性。

> **ai_Abstract:** 本文提出了一种名为GMC的生成式多目标跨域推荐方法，旨在解决现有MTCDR方法在非重叠场景中对共享实体或大量预训练数据依赖的问题。GMC的核心在于利用语义量化的离散物品标识符作为跨域知识整合的媒介，通过物品分词器生成域共享的语义标识符，并将推荐任务转化为统一序列到序列模型中的下一个令牌生成。为增强性能，GMC还引入了领域感知对比损失并进行领域特定微调。实验结果表明，GMC在多个公共数据集上优于现有基线方法。

> **摘要翻译:** 近年来，多目标跨域推荐（MTCDR）引起了广泛关注，旨在同时提升多个领域的推荐性能。现有的MTCDR方法主要依赖于领域共享实体（例如用户或物品）来融合和迁移跨域知识，这在非重叠推荐场景中可能不可用。一些研究将用户偏好和物品特征建模为领域可共享的语义表示，可用于处理MTCDR任务。然而，它们通常需要大量的辅助数据进行预训练。因此，开发更有效的MTCDR解决方案仍然是一个值得进一步探索的重要领域。
受生成式推荐最新进展的启发，本文提出了GMC，一种基于生成范式的多目标跨域推荐方法。GMC的核心思想是利用语义量化的离散物品标识符作为媒介，在一个统一的生成模型中整合多领域知识。GMC首先采用物品分词器为每个物品生成域共享的语义标识符，然后通过训练一个域统一的序列到序列模型，将物品推荐表述为下一个令牌生成任务。为了进一步利用领域信息提升性能，我们在语义标识符学习中融入了领域感知对比损失，并对统一推荐器进行领域特定的微调。在五个公共数据集上进行的广泛实验表明，与一系列基线方法相比，GMC表现出有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [181] [Optimality Principles and Neural Ordinary Differential Equations-based Process Modeling for Distributed Control](https://arxiv.org/abs/2508.04799)
> *优化原理与基于神经常微分方程的分布式控制过程建模*

*Michael R. Wartmann, B. Erik Ydstie* | **Category: cs.AI, cs.LG, cs.NE, eess.SY** | **Updated: 2025-08-06**

**Keywords:** 过程建模, 神经常微分方程, 分布式控制, 数据驱动, 拓扑性质

**Comment:** 

> **TL;DR:** 本文提出一个将数据驱动算法与经典过程模型结合的过程建模框架，通过拓扑性质和守恒律，利用神经常微分方程对系统进行建模，并在库存控制系统中进行了验证，形成可用于模型预测控制的状态空间模型。

**AI_Comments:** 本文的创新点在于提出了一个统一的框架，将数据驱动的神经常微分方程模型与经典过程控制中的拓扑性质和守恒律相结合，解决了传统模型与现代机器学习方法融合的挑战。这种方法在保持物理一致性的同时，利用数据学习系统动力学，为分布式控制和优化提供了新的途径。其将系统自然目标函数与非平衡熵产生联系起来的思路也颇具启发性。

<details>
  <summary>Details</summary>

**Motivation:** 当前机器学习和分析在过程控制中的最新进展提出了如何将新的数据驱动方法与经典过程模型和控制自然整合的问题。

**Method:** 提出一个过程建模框架，通过一致的拓扑性质和广延量守恒来整合数据驱动算法。通过连接矩阵和网络图表示过程网络单元之间的互连。推导出系统在稳态下等同于非平衡熵产生的自然目标函数作为过程动力学的驱动力。阐述了分布式控制和优化如何实现到过程网络结构中，且流条件需用锥形扇区（无源性）条件表达。通过稀疏深度神经网络集成拓扑学的基本守恒性质与从数据中学习到的动态关系。在一个简单的库存控制系统实例中，将过程基本拓扑与神经常微分方程模型结合，并利用伴随方法和自适应ODE求解器从合成时间序列数据中学习系统特定的本构方程。

**Result:** 形成了一个过程建模框架，能够通过一致的拓扑性质和广延量守征来整合数据驱动算法。推导出了系统在稳态下等同于非平衡熵产生的自然目标函数。展示了如何将分布式控制和优化实现到过程网络结构中。在库存控制系统实例中成功集成了过程基本拓扑与神经常微分方程模型。学习到的神经网络形成一个可用于模型预测控制算法的状态空间模型。

**Conclusion:** 本文提出的形式主义允许将拓扑学的基本守恒性质与从数据中学习到的动态关系通过稀疏深度神经网络进行整合，并成功地将神经常微分方程模型应用于过程控制，形成可用于模型预测控制的状态空间模型。

> **ai_Abstract:** 本文提出了一个创新的过程建模框架，旨在解决数据驱动方法与传统过程控制模型整合的挑战。该框架通过利用一致的拓扑性质、广延量守恒以及基于非平衡熵产生的自然目标函数来整合数据驱动算法。研究通过稀疏深度神经网络，将拓扑学的基本守恒律与从数据中学习到的动态关系相结合。在一个库存控制系统的实例中，作者演示了如何将过程拓扑与神经常微分方程模型（其本构方程通过伴随方法和自适应ODE求解器从合成数据中学习）相结合，从而形成一个可用于模型预测控制的状态空间模型。

> **摘要翻译:** 机器学习和过程控制分析的最新进展提出了如何将新的数据驱动方法与经典过程模型和控制自然整合的问题。我们提出了一个过程建模框架，通过一致的拓扑性质和广延量守恒来实现数据驱动算法的整合。过程网络单元之间的互连通过连接矩阵和网络图表示。我们推导出系统在稳态下等同于非平衡熵产生的自然目标函数，作为过程动力学的驱动力。我们阐述了如何将分布式控制和优化实现到过程网络结构中，以及控制律和算法如何将系统的自然平衡改变为工程目标。基本要求是流动条件可以用锥形扇区（无源性）条件来表达。我们的形式主义允许通过稀疏深度神经网络整合拓扑学的基本守恒性质与从数据中学习到的动态关系。我们通过一个简单的库存控制系统的实际例子，演示了如何将过程的基本拓扑与神经常微分方程模型结合。系统特定的本构方程未被描述，而是由神经常微分方程算法使用伴随方法结合自适应ODE求解器从合成时间序列数据中学习。生成的神经网络形成一个状态空间模型，可用于例如模型预测控制算法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [182] [Coarse-to-Fine Joint Registration of MR and Ultrasound Images via Imaging Style Transfer](https://arxiv.org/abs/2508.05240)
> *磁共振与超声图像基于图像风格迁移的由粗到精联合配准*

*Junyi Wang, Xi Zhu, Yikun Guo, Zixi Wang, Haichuan Gao, Le Zhang, Fan Zhang* | **Category: cs.AI, cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 图像配准, 风格迁移, CycleGAN, 磁共振图像, 超声图像

**Comment:** 

> **TL;DR:** 该文提出一种通过3D CycleGAN风格迁移和粗到精配准方法，用于配准术前MR和术后US图像。

**AI_Comments:** 该研究创新性地将3D CycleGAN风格迁移技术引入到术前MR与术后US图像的联合配准中，通过生成合成图像克服了图像模态差异，并结合多阶段配准策略，为跨模态医学图像配准提供了一种有效且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 配准术前磁共振（MR）图像和术后超声（US）图像，并提高配准性能。

**Method:** 使用3D CycleGAN进行无配对风格迁移以生成合成T1图像，然后采用仿射和局部形变变换进行由粗到精的配准。

**Result:** 该方法在大多数情况下提高了MR和US图像对之间的一致性。

**Conclusion:** 所提出的方法能够有效提高术前MR与术后US图像的配准一致性。

> **ai_Abstract:** 本文提出了一种通过图像风格迁移实现磁共振（MR）和超声（US）图像联合配准的新方法。该方法利用3D CycleGAN进行无配对风格迁移生成合成T1图像，并结合由粗到精的仿射和局部形变配准策略，有效提高了术前MR与术后US图像配准的一致性。

> **摘要翻译:** 我们开发了一个用于配准术前磁共振（MR）图像和术后切除超声（US）图像的流程。我们的方法利用3D CycleGAN进行无配对风格迁移以生成合成T1图像，从而增强配准性能。此外，我们的配准过程采用仿射和局部形变变换进行由粗到精的配准。结果表明，我们的方法在大多数情况下提高了MR和US图像对之间的一致性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [183] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
> *公平感知字节对编码：提升分词中的跨语言公平性*

*Negar Foroutan, Clara Meister, Debjit Paul, Joel Niklaus, Sina Ahmadi, Antoine Bosselut, Rico Sennrich* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 词元化, 跨语言公平性, 字节对编码, 低资源语言, NLP管道

**Comment:** 

> **TL;DR:** 当前的词元化算法对低资源语言不公平。本文提出公平感知字节对编码（Parity-aware BPE），通过在合并步骤中优先考虑压缩最差的语言来平衡词元计数，从而在不显著影响性能的情况下提高跨语言公平性。

**AI_Comments:** 该论文解决了NLP管道初始阶段一个关键但常被忽视的公平性问题。其创新点在于修改了BPE的合并策略，明确地优化跨语言公平性而非仅仅是全局压缩，这是一种改善词元化公平性的新颖方法。这项工作对于促进NLP领域对低资源语言的包容性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 标准的基于频率的词元化算法偏向训练数据中占主导地位的语言，导致低资源语言的词元化结果过长、形态不合理或包含大量未知词元（<UNK>），这加剧了不同语言背景用户之间的计算和经济不平等。

**Method:** 引入了公平感知字节对编码（Parity-aware BPE），它是BPE算法的一种变体。在每个合并步骤中，Parity-aware BPE旨在最大化当前压缩最差语言的压缩增益，从而在牺牲少量全局压缩的情况下实现跨语言的公平性。

**Result:** 经验结果表明，公平感知BPE能够使不同语言之间的词元计数更加公平，同时对全局压缩率的影响可以忽略不计，并且对下游任务中的语言模型性能没有实质性影响。

**Conclusion:** 公平感知BPE通过实现更公平的词元计数，有效解决了词元化中的跨语言不公平问题，且对压缩率和下游任务性能的影响极小。

> **ai_Abstract:** 本文提出了一种名为公平感知字节对编码（Parity-aware BPE）的新型词元化算法，旨在解决传统基于频率的BPE算法对低资源语言造成的不公平问题（如词元化结果过长或质量差）。Parity-aware BPE在每个合并步骤中优先考虑压缩最差的语言，以实现跨语言的词元计数公平性。实证结果表明，该方法在不显著影响全局压缩率或下游语言模型性能的前提下，有效提升了不同语言间的词元化公平性。

> **摘要翻译:** 分词是大多数NLP管道的第一步——也通常是最少被审查的一步。学习分词器的标准算法依赖于基于频率的目标，这偏爱训练数据中占主导地位的语言，因此导致低资源语言的分词结果不成比例地更长、形态上不可信，甚至充斥着<UNK>占位符。这种现象最终加剧了来自不同语言背景用户之间的计算和经济不平等。为了解决这个问题，我们引入了公平感知字节对编码（Parity-aware BPE），这是一种广泛使用的BPE算法的变体。在每个合并步骤中，公平感知BPE最大限度地提高当前压缩最差语言的压缩增益，以牺牲少量全局压缩为代价换取跨语言的公平性。我们通过经验发现，公平感知BPE导致语言间更公平的词元计数，对全局压缩率影响可忽略不计，并且对下游任务中的语言模型性能没有实质性影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [184] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
> *通过识别和保留功能网络来剪枝大型语言模型*

*Yiheng Liu, Junhao Ning, Sichen Xia, Xiaohui Gao, Ning Qiang, Bao Ge, Junwei Han, Xintao Hu* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型剪枝, 功能网络, 模型压缩, 结构化剪枝, 神经元交互

**Comment:** 

> **TL;DR:** 本文提出一种通过识别和保留大型语言模型（LLMs）中的功能网络来剪枝模型的新方法，以提高剪枝性能和效率。

**AI_Comments:** 这项工作通过引入“功能网络”的概念，并将其应用于大型语言模型的剪枝，提供了一种新颖的视角。它解决了传统剪枝方法忽视神经元间协作的局限性，借鉴了神经科学的灵感，具有一定的创新性。其重要性在于能够实现更高效、性能损失更小的模型压缩，对于LLMs在资源受限环境下的部署具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的结构化剪枝方法通常忽视大型语言模型（LLMs）中人工神经元之间对模型功能至关重要的交互和协作，这导致LLMs宏观功能架构的破坏和剪枝性能的下降。

**Method:** 本研究受到人脑功能神经网络的启发，提出将大型语言模型视为一个数字大脑，并将其分解为功能网络。随后，通过保留这些功能网络中的关键神经元来进行模型剪枝。

**Result:** 实验结果表明，所提出的方法能够成功识别并定位大型语言模型中的功能网络和关键神经元，从而实现高效的模型剪枝。

**Conclusion:** 通过识别和保留大型语言模型中的功能网络及其关键神经元，可以有效解决传统剪枝方法忽略神经元交互导致性能下降的问题，从而实现更高效、性能损失更小的模型压缩。

> **ai_Abstract:** 本文提出了一种新颖的剪枝大型语言模型（LLMs）的方法，旨在解决现有结构化剪枝忽略神经元交互导致性能下降的问题。受人脑功能网络的启发，该方法将LLM视为数字大脑，分解为功能网络，并通过保留这些网络中的关键神经元进行剪枝。实验证明，该方法能有效识别LLM中的功能网络和关键神经元，从而实现高效模型剪枝。

> **摘要翻译:** 结构化剪枝是压缩大型语言模型（LLMs）以减少GPU内存消耗和加速推理速度的代表性技术之一。它在提高LLMs在实际应用中的效率方面具有重要的实用价值。当前的结构化剪枝方法通常依赖于评估结构单元的重要性并剪枝重要性较低的单元。它们大多忽视了对LLMs功能至关重要的神经元之间的交互和协作，导致LLMs宏观功能架构的破坏，从而导致剪枝性能下降。受人脑中人工神经网络和功能神经网络之间内在相似性的启发，我们缓解了这一挑战，并在本研究中提出通过识别和保留LLMs中的功能网络来剪枝LLMs。为了实现这一点，我们将LLM视为一个数字大脑，并将LLM分解为功能网络，类似于在神经影像数据中识别功能性大脑网络。之后，通过保留这些功能网络中的关键神经元来剪枝LLM。实验结果表明，所提出的方法能够成功识别并定位LLMs中的功能网络和关键神经元，从而实现高效的模型剪枝。我们的代码可在https://github.com/WhatAboutMyStar/LLM_ACTIVATION 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [185] [Look Before You Fuse: 2D-Guided Cross-Modal Alignment for Robust 3D Detection](https://arxiv.org/abs/2507.16861)
> *融合前瞻：基于2D引导的跨模态对齐实现鲁棒3D检测*

*Xiang Li, Zhangchi Hu, Xiao Xu, Bin Kong* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D检测, 跨模态对齐, 激光雷达-相机融合, 2D先验, 空间错位

**Comment:** 

> **TL;DR:** 现有激光雷达与相机融合方法存在空间错位问题，影响3D检测精度。本文提出利用2D先验在融合前预先对齐跨模态特征，通过PGDC、DAGF和SGDM模块，显著提升了3D检测的鲁棒性和性能。

**AI_Comments:** 该论文通过利用2D检测器识别的物体-背景边界处可预测的投影误差，提出了一个创新的“融合前瞻”策略，在特征融合之前进行跨模态对齐。这种方法直接从根源上解决了激光雷达和相机特征的空间错位问题，相比于融合后修正误差的方法更具鲁棒性。PGDC、DAGF和SGDM的模块化设计针对性地解决了不同层面的错位问题，是其取得SOTA性能的关键。

<details>
  <summary>Details</summary>

**Motivation:** 现有激光雷达和相机特征在融合时存在空间错位，源于校准不准确和卷帘快门效应导致的投影误差，这会导致深度监督不准确和融合错误。本文的关键在于，这些投影误差集中在2D检测器可识别的物体-背景边界，因此提出利用2D物体先验在融合前预先对齐跨模态特征。

**Method:** 本文提出了三种方法：1. 先验引导深度校准（Prior Guided Depth Calibration, PGDC），利用2D先验缓解局部错位并保留正确的跨模态特征对。2. 不连续感知几何融合（Discontinuity Aware Geometric Fusion, DAGF），解决全局错位，抑制PGDC的残余噪声并增强深度过渡。3. 结构引导深度调制器（Structural Guidance Depth Modulator, SGDM），使用门控注意力机制高效融合对齐的深度和图像特征。

**Result:** 本文方法在nuScenes验证数据集上取得了最先进的性能，mAP达到71.5%，NDS达到73.6%。

**Conclusion:** 本文通过利用2D物体先验来预先对齐跨模态特征，并引入PGDC、DAGF和SGDM等模块，有效解决了激光雷达和相机特征的空间错位问题，从而显著提升了3D检测的鲁棒性和性能。

> **ai_Abstract:** 本文提出了一种名为“融合前瞻：基于2D引导的跨模态对齐实现鲁棒3D检测”的方法，旨在解决激光雷达和相机特征在BEV表示中融合时存在的空间错位问题。该问题主要由校准误差和卷帘快门效应引起的投影误差导致，且这些误差集中在物体-背景边界。为解决此问题，作者利用2D物体先验在融合前对跨模态特征进行预对齐。具体而言，引入了先验引导深度校准（PGDC）来处理局部错位，不连续感知几何融合（DAGF）来解决全局错位并增强深度过渡，以及结构引导深度调制器（SGDM）来高效融合对齐后的特征。该方法在nuScenes验证数据集上取得了SOTA性能，mAP和NDS分别达到71.5%和73.6%。

> **摘要翻译:** 将激光雷达和相机输入整合到统一的鸟瞰图（BEV）表示中，对于增强自动驾驶汽车的3D感知能力至关重要。然而，现有方法存在激光雷达和相机特征之间的空间错位问题，这导致相机分支中深度监督不准确以及跨模态特征聚合过程中融合错误。这种错位的根本原因在于投影误差，源于校准不准确和卷帘快门效应。这项工作的关键见解是，这些投影误差的位置并非随机，而是高度可预测的，因为它们集中在2D检测器可以可靠识别的物体-背景边界处。基于此，我们的主要动机是利用2D物体先验在融合前预先对齐跨模态特征。为了解决局部错位问题，我们提出了先验引导深度校准（PGDC），它利用2D先验来缓解错位并保留正确的跨模态特征对。为了解决全局错位问题，我们引入了不连续感知几何融合（DAGF）来抑制PGDC的残余噪声，并明确增强物体-背景边界处的尖锐深度过渡，从而产生结构感知的表示。为了有效利用这些对齐的表示，我们结合了结构引导深度调制器（SGDM），使用门控注意力机制有效地融合对齐的深度和图像特征。我们的方法在nuScenes验证数据集上取得了最先进的性能，其mAP和NDS分别达到71.5%和73.6%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [190] [RegionMed-CLIP: A Region-Aware Multimodal Contrastive Learning Pre-trained Model for Medical Image Understanding](https://arxiv.org/abs/2508.05244)
> *RegionMed-CLIP：一种用于医学图像理解的区域感知多模态对比学习预训练模型*

*Tianchen Fang, Guiru Liu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 医学图像理解, 区域感知, 多模态对比学习, 预训练模型, MedRegion-500k

**Comment:** 

> **TL;DR:** RegionMed-CLIP是一个区域感知的多模态对比学习框架，通过整合局部病理信号和全局语义表示，解决了医学图像理解中数据稀缺和全局特征不足的问题，并在多项任务上超越了现有SOTA模型。

**AI_Comments:** RegionMed-CLIP的创新之处在于其区域感知多模态对比学习框架，特别是ROI处理器能够有效整合局部和全局信息，克服了传统方法对全局特征的过度依赖。同时，构建大规模区域标注的MedRegion-500k数据集，为医学领域缺乏高质量标注数据提供了重要资源，极大地推动了医学图像理解领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像理解受限于高质量标注医学数据的稀缺性，以及过度依赖全局图像特征而忽略细微但临床重要的病理区域。

**Method:** 提出RegionMed-CLIP，一个区域感知多模态对比学习框架，明确结合局部病理信号和整体语义表示。其核心是创新的兴趣区域（ROI）处理器，自适应地将细粒度区域特征与全局上下文整合，并通过渐进式训练策略增强多模态分层对齐。同时构建了MedRegion-500k，一个包含大量区域标注和多级别临床描述的综合医学图像-文本语料库。

**Result:** 在图像-文本检索、零样本分类和视觉问答任务上的大量实验表明，RegionMed-CLIP显著超越了最先进的视觉语言模型。

**Conclusion:** 结果强调了区域感知对比预训练的关键重要性，并将RegionMed-CLIP定位为推进多模态医学图像理解的强大基础。

> **ai_Abstract:** 本研究提出RegionMed-CLIP，一个区域感知的多模态对比学习预训练模型，旨在解决医学图像理解中数据稀缺和全局特征不足的问题。该模型通过创新的ROI处理器整合局部病理信号和全局语义，并采用渐进式训练策略。为支持大规模区域级学习，构建了MedRegion-500k数据集。实验证明，RegionMed-CLIP在多项医学图像理解任务上显著优于现有SOTA模型，强调了区域感知预训练的重要性。

> **摘要翻译:** 医学图像理解在实现自动化诊断和数据驱动的临床决策支持中发挥着关键作用。然而，其进展受到两个主要挑战的阻碍：高质量标注医学数据的有限可用性，以及过度依赖全局图像特征，这往往会错过细微但临床上重要的病理区域。为了解决这些问题，我们引入了RegionMed-CLIP，一个区域感知多模态对比学习框架，它明确地将局部病理信号与整体语义表示结合起来。我们方法的核心是一个创新的兴趣区域（ROI）处理器，它自适应地将细粒度区域特征与全局上下文整合，并辅以一种渐进式训练策略，以增强分层多模态对齐。为了实现大规模区域级表示学习，我们构建了MedRegion-500k，这是一个综合性的医学图像-文本语料库，具有广泛的区域标注和多级别临床描述。在图像-文本检索、零样本分类和视觉问答任务上的大量实验表明，RegionMed-CLIP始终以显著优势超越了最先进的视觉语言模型。我们的结果强调了区域感知对比预训练的关键重要性，并将RegionMed-CLIP定位为推进多模态医学图像理解的强大基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [191] [CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework](https://arxiv.org/abs/2508.04816)
> *CoMAD：一个多教师自监督蒸馏框架*

*Sriram Mandalika, Lalitha V* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-06**

**Keywords:** 自监督学习, 知识蒸馏, 视觉Transformer, 紧凑模型, 多教师

**Comment:** 

> **TL;DR:** CoMAD是一个轻量级、无参数的框架，它通过创新的非对称掩码和联合共识门控机制，将多个自监督视觉Transformer的知识统一蒸馏到一个紧凑的学生网络中，在紧凑型自监督学习领域取得了最先进的性能。

**AI_Comments:** CoMAD的创新点在于其多教师蒸馏方法，特别是引入了非对称掩码和联合共识门控机制，有效地整合了不同自监督模型提供的互补见解。它解决了大型自监督模型部署受限的问题，并实现了紧凑模型的最先进性能，这对于资源受限环境下的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自监督学习范式通常是独立预训练的，这导致它们忽视了互补的见解，并产生了对于资源受限部署不切实际的大模型。本文旨在通过知识蒸馏，将来自多个最先进的自监督视觉Transformer的知识统一到一个紧凑的学生网络中，以克服这些挑战。

**Method:** CoMAD是一个轻量级、无参数的框架，它从三个预训练的ViT-Base教师模型（MAE、MoCo v3和iBOT）中进行蒸馏。它采用非对称掩码策略：学生只看到25%的图像块，而每个教师则接收逐渐更轻、独特的掩码，以迫使学生在更丰富的上下文中插值缺失特征。教师嵌入通过线性适配器和层归一化对齐到学生的空间，并通过结合余弦相似度和教师间一致性的联合共识门控进行融合。学生通过对可见令牌和重建特征图的双级KL散度进行训练。

**Result:** CoMAD的ViT-Tiny模型在ImageNet-1K上实现了75.4%的Top-1准确率，比之前的最先进水平提高了0.4%。在密集预测迁移任务中，它在ADE20K上获得了47.3%的mIoU，在MS-COCO上获得了44.5%的包围盒平均精度和40.5%的掩码平均精度。这些结果在紧凑型自监督蒸馏领域建立了新的最先进水平。

**Conclusion:** CoMAD成功地将多个自监督视觉Transformer的知识统一到一个紧凑的学生网络中，通过其独特的蒸馏机制，有效解决了现有自监督学习范式中孤立预训练和模型庞大的问题，并在各项基准测试中取得了最先进的性能，证明了其在紧凑型自监督学习领域的有效性。

> **ai_Abstract:** CoMAD是一个轻量级、无参数的框架，旨在通过整合来自多个最先进的自监督视觉Transformer（如MAE、MoCo v3和iBOT）的知识，将其蒸馏到一个紧凑的学生网络中，以克服现有自监督学习范式孤立预训练和模型庞大的问题。该框架采用非对称掩码、线性适配器、层归一化以及联合共识门控来融合教师嵌入，并通过双级KL散度训练学生。CoMAD的ViT-Tiny在ImageNet-1K上实现了75.4%的Top-1准确率，并在ADE20K和MS-COCO的密集预测任务中取得了最先进的性能，为紧凑型自监督蒸馏树立了新标杆。

> **摘要翻译:** 许多自监督学习范式，如对比学习和掩码图像建模，能从未标记数据中学习到强大的表征，但它们通常是独立预训练的，忽视了互补的见解，并产生了对于资源受限部署不切实际的大模型。为了克服这些挑战，我们引入了面向共识的掩码蒸馏（CoMAD），这是一个轻量级、无参数的框架，它将来自多个当前最先进的自监督视觉Transformer的知识统一到一个紧凑的学生网络中。CoMAD从三个预训练的ViT-Base教师模型（MAE、MoCo v3和iBOT）中进行蒸馏，每个教师都提供了独特的语义和上下文先验。我们没有简单地平均教师输出，而是应用了非对称掩码：学生只看到25%的图像块，而每个教师则收到逐渐更轻、独特的掩码，迫使学生在更丰富的上下文中插值缺失的特征。教师嵌入通过线性适配器和层归一化对齐到学生的空间，然后通过我们的联合共识门控进行融合，该门控通过结合余弦相似度和教师间一致性来加权每个令牌。学生通过对可见令牌和重建特征图的双级KL散度进行训练，捕获局部和全局结构。在ImageNet-1K上，CoMAD的ViT-Tiny实现了75.4%的Top-1准确率，比之前的最先进水平提高了0.4%。在密集预测迁移中，它在ADE20K上获得了47.3%的mIoU，在MS-COCO上获得了44.5%的包围盒平均精度和40.5%的掩码平均精度，在紧凑型自监督蒸馏领域建立了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [192] [Efficient Attention Mechanisms for Large Language Models: A Survey](https://arxiv.org/abs/2507.19595)
> *大型语言模型中的高效注意力机制：一项综述*

*Yutao Sun, Zhenyu Li, Yike Zhang, Tengyu Pan, Bowen Dong, Yuyi Guo, Jianyong Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 高效注意力, 大型语言模型, 线性注意力, 稀疏注意力, Transformer

**Comment:** 

> **TL;DR:** 这项综述系统地概述了大型语言模型中用于解决自注意力机制二次复杂度的两种主要高效注意力机制：线性注意力和稀疏注意力，并探讨了它们在实际部署中的应用。

**AI_Comments:** 这是一篇及时且重要的综述论文，它系统地梳理了大型语言模型中高效注意力机制的复杂领域。其创新之处在于不仅涵盖了算法层面的进展，还整合了硬件考量，并分析了这些机制在实际模型构建中的应用，为研究人员和工程师提供了宝贵的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 自注意力机制的二次时间和内存复杂度是大型语言模型有效处理长上下文的主要障碍。

**Method:** 本综述系统全面地概述了高效注意力机制的最新发展，涵盖了算法创新和硬件层面的考量。它分析了线性注意力和稀疏注意力两种主要类别，并探讨了它们在大型预训练语言模型中的整合方式。

**Result:** 综述介绍了两种主要的高效注意力机制：线性注意力（通过核近似、循环公式或快权重动力学实现线性复杂度）和稀疏注意力（通过固定模式、块级路由或聚类策略限制注意力计算）。它还分析了这些机制在完全基于高效注意力的架构和结合局部与全局组件的混合设计中的应用。

**Conclusion:** 这项工作旨在为推进可扩展和高效语言模型的设计提供一个基础性参考，将理论基础与实际部署策略相结合。

> **ai_Abstract:** 本综述系统地探讨了大型语言模型中高效注意力机制的最新进展，旨在解决传统自注意力机制的二次复杂性。文章详细介绍了线性注意力和稀疏注意力这两种主要类别，分析了它们各自的实现方式及其在算法和硬件层面的考量。此外，综述还讨论了高效注意力机制在大型预训练语言模型中的整合，涵盖了纯高效注意力架构和混合设计。该工作旨在为开发可扩展和高效的语言模型提供一个全面的参考。

> **摘要翻译:** 基于Transformer的架构已成为大型语言模型的主流骨干。然而，自注意力机制的二次时间和内存复杂度仍然是高效长上下文建模的一个根本障碍。为了解决这一限制，最近的研究引入了两种主要的高效注意力机制。线性注意力方法通过核近似、循环公式或快权重动力学实现线性复杂度，从而在降低计算开销的同时实现可扩展的推理。相比之下，稀疏注意力技术根据固定模式、块级路由或聚类策略，将注意力计算限制在选定的标记子集上，在提高效率的同时保持上下文覆盖。本综述系统全面地概述了这些发展，整合了算法创新和硬件层面的考量。此外，我们还分析了将高效注意力整合到大型预训练语言模型中的情况，包括完全基于高效注意力的架构和结合局部与全局组件的混合设计。通过将理论基础与实际部署策略相结合，这项工作旨在为推进可扩展和高效语言模型的设计提供一个基础性参考。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [197] [Automated File-Level Logging Generation for Machine Learning Applications using LLMs: A Case Study using GPT-4o Mini](https://arxiv.org/abs/2508.04820)
> *使用大型语言模型为机器学习应用自动生成文件级日志：以 GPT-4o Mini 为案例研究*

*Mayra Sofia Ruiz Rodriguez, SayedHassan Khatoonabadi, Emad Shihab* | **Category: cs.AI, cs.LG, cs.SE** | **Updated: 2025-08-06**

**Keywords:** 文件级日志, 机器学习, 大型语言模型, GPT-4o Mini, 日志生成

**Comment:** 

> **TL;DR:** 本研究评估了 GPT-4o Mini 在机器学习项目中生成文件级日志的能力。发现 LLM 在日志位置上与人类有63.91%的一致性，但存在82.66%的过量日志问题，且在大型代码块和项目特定约定方面存在挑战。

**AI_Comments:** 本文创新性地将大型语言模型应用于文件级日志生成，弥补了现有研究主要集中于函数级日志的不足。以GPT-4o Mini为例进行的案例研究提供了具体的数据支持。然而，其主要局限在于过高的过量日志率以及在复杂代码块和项目约定方面表现出的不足，这表明在实际部署前仍需进一步优化模型，使其能更好地理解上下文和项目规范。

<details>
  <summary>Details</summary>

**Motivation:** 日志在软件开发中至关重要，用于监控系统行为和调试。尽管大型语言模型（LLMs）在生成日志语句方面显示出潜力，但现有工作主要关注代码函数内的日志，而文件级日志生成，尤其是在机器学习（ML）应用中，仍未得到充分探索，尽管全面的日志记录可以增强可靠性。

**Method:** 本研究使用 GPT-4o Mini 作为案例研究，评估其为机器学习项目生成文件级日志的能力。收集了171个ML仓库，包含4,073个至少有一个日志语句的Python文件。移除了原始日志，提示LLM生成日志，并评估了生成日志的位置、日志级别、变量和文本质量，并与人工编写的日志进行比较。此外，手动分析了代表性样本以识别常见模式和挑战。

**Result:** 研究发现，LLM在63.91%的情况下将日志引入与人类相同的位置，但代价是高达82.66%的过量日志率。此外，手动分析揭示了文件级日志的挑战，表现为函数开头或结尾的过量日志、在大型代码块中记录的困难以及与项目特定日志约定不一致。

**Conclusion:** 尽管大型语言模型在为完整文件生成日志方面显示出前景，但其存在的局限性（如过量日志、在大型代码块中的困难以及与项目特定约定不符）仍需解决才能实际应用。

> **ai_Abstract:** 本研究探讨了使用大型语言模型（LLMs），特别是GPT-4o Mini，为机器学习（ML）应用自动生成文件级日志的能力。尽管LLMs在生成代码函数内日志方面已被探索，但文件级日志生成仍是未充分研究的领域。研究者收集了包含4,073个Python文件的171个ML仓库，移除原有日志后，让GPT-4o Mini生成新日志。评估结果显示，LLM在63.91%的情况下日志位置与人工一致，但存在82.66%的过量日志率。手动分析进一步揭示了在大型代码块中日志生成困难以及与项目约定不符等挑战。尽管LLM显示出潜力，但其局限性需在实际应用中加以解决。

> **摘要翻译:** 日志在软件开发中至关重要，有助于开发人员监控系统行为并协助调试应用程序。鉴于大型语言模型（LLMs）生成自然语言和代码的能力，研究人员正在探索它们生成日志语句的潜力。然而，以前的工作侧重于评估代码函数中引入的日志，而文件级日志生成——尤其是在机器学习（ML）应用程序中，其中全面的日志记录可以增强可靠性——仍未得到充分探索。在本研究中，我们以 GPT-4o mini 为案例研究，评估其在文件级别为ML项目生成日志语句的能力。我们收集了171个ML仓库，包含4,073个至少有一个日志语句的Python文件。我们识别并移除了文件中的原始日志，提示LLM为其生成日志，并评估了生成日志的位置、日志级别、变量和文本质量，并与人工编写的日志进行比较。此外，我们手动分析了生成日志的代表性样本，以识别常见模式和挑战。我们发现LLM在63.91%的情况下在与人类相同的位置引入日志，但代价是高达82.66%的过量日志率。此外，我们的手动分析揭示了文件级日志的挑战，这表现为函数开头或结尾的过量日志、在大型代码块中记录的困难以及与项目特定日志约定不一致。尽管LLM在为完整文件生成日志方面显示出前景，但这些局限性仍有待解决以实现实际应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [198] [A Study of Gender Classification Techniques Based on Iris Images: A Deep Survey and Analysis](https://arxiv.org/abs/2508.05246)
> *基于虹膜图像的性别分类技术研究：深度调查与分析*

*Basna Mohammed Salih Hasan, Ramadhan J. Mstafa* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 性别分类, 虹膜图像, 生物识别, 综述, 分析

**Comment:** 

> **TL;DR:** 本文对基于虹膜图像的性别分类技术进行了深入调查和分析，旨在提供现有方法的知识、突出空白和挑战，并提出改进建议和未来发展方向。

**AI_Comments:** 这是一篇有价值的综述性论文，它整合了现有知识并指明了未来的研究方向。其专注于基于虹膜图像的性别分类值得关注，因为与主流的面部特征相比，它探讨了一种较少但有前景的生物特征。识别该领域的空白和挑战对于推动该领域的发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 性别分类在监控、企业画像和人机交互等应用中具有吸引力。虹膜作为一种稳定的、外部可见且非侵入性的生物特征，尽管面部特征目前占据主导地位，但在性别分类中具有重要潜力。本研究旨在为研究人员提供基于虹膜图像的性别分类方法的知识和分析，并指出该领域的空白和挑战。

**Method:** 本研究对基于虹膜图像的性别分类技术进行了深入的调查和分析。它简要回顾了现有文献，并讨论了性别分类不同步骤的各种方法。

**Result:** 本研究为研究人员提供了现有性别分类方法的知识和分析。它还指出了该领域的空白和挑战，并提供了改进的建议和未来路径。

**Conclusion:** 本研究对基于虹膜图像的性别分类技术进行了全面的概述，识别了现有方法、挑战，并提出了未来的研究方向。

> **ai_Abstract:** 本文对基于虹膜图像的性别分类技术进行了全面的调查和分析。研究指出性别分类在多种应用中具有重要价值，并强调虹膜作为一种稳定、实用且非侵入性的生物特征，在性别识别方面具有巨大潜力，尽管目前面部识别方法更为普遍。该研究回顾了现有文献，讨论了虹膜图像性别分类的各种方法，旨在加深研究人员对该领域的理解，明确当前面临的挑战，并为未来的研究方向提供指导。

> **摘要翻译:** 性别分类在监控、企业画像和人机交互等一系列应用中具有吸引力。个体的身份信息可以从其性别信息中获取，这是一种软生物特征。多年来，已经设计了多种确定个体性别的方法。其中最著名的一些方法基于面部、指纹、掌纹、DNA、耳朵、步态和虹膜等物理特征。另一方面，面部特征占据了绝大多数的性别分类方法。此外，虹膜是一种重要的生物特征，因为研究表明虹膜在个体一生中基本保持不变。除此之外，虹膜是外部可见且对用户无创的，这对于实际应用很重要。此外，目前已经存在高质量的虹膜图像分割和编码方法，并且现有方法有助于从虹膜纹理中选择和提取属性向量。本研究讨论了几种确定性别的方法。简要回顾了以往的文献。此外，性别分类的不同步骤有多种方法。本研究为研究人员提供了现有性别分类方法的知识和分析。此外，它将协助对该特定领域感兴趣的研究人员，突出该领域的空白和挑战，并最终提供改进的建议和未来路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [199] [Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition](https://arxiv.org/abs/2507.20997)
> *带正交约束的模块化Delta合并：一个持续且可逆的模型组合的可扩展框架*

*Haris Khan, Sadia Asif, Shumaila Asif* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 模型合并, 持续学习, 正交约束, 可逆性, 增量学习

**Comment:** 

> **TL;DR:** MDM-OC是一个新的框架，通过将任务特定模型编码为delta并投影到正交子空间，实现可扩展、无干扰和可逆的微调模型组合。

**AI_Comments:** 该论文提出了一种新颖的模型合并方法，通过引入正交约束和delta编码，有效解决了持续学习中的关键挑战，如任务干扰和可逆性问题。其在合规性（如GDPR）方面的支持，以及对模型稳定性的关注，显示出很强的实际应用价值和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模型合并和持续学习方法常常遭受任务干扰、灾难性遗忘或缺乏可逆性。

**Method:** 我们提出了带正交约束的模块化Delta合并（MDM-OC）框架。它将每个任务特定模型编码为共享基础的delta，并投影到正交子空间以消除冲突。这些投影的delta通过基于梯度的优化合并，形成一个在所有任务上保持性能的统一模型。该方法支持新模型的持续集成、结构化解合并以及通过弹性权重整合和合成重放实现模型稳定性。

**Result:** 在视觉和自然语言处理基准测试中的广泛实验表明，MDM-OC在准确性、反向迁移和解合并保真度方面优于现有基线，同时保持内存效率和计算可行性。

**Conclusion:** MDM-OC为模块化和合规的AI系统设计提供了一个原则性的解决方案。

> **ai_Abstract:** 本文提出了带正交约束的模块化Delta合并（MDM-OC）框架，旨在解决现有模型合并和持续学习中存在的任务干扰、灾难性遗忘和缺乏可逆性问题。MDM-OC通过将每个任务特定模型表示为delta并投影到正交子空间来消除冲突，然后通过梯度优化进行合并，从而实现可扩展、无干扰且可逆的模型组合。实验证明，该方法在性能、反向迁移和解合并保真度上优于现有方法，并具有良好的内存和计算效率，为模块化和合规的AI系统设计提供了有效方案。

> **摘要翻译:** 在现实世界的机器学习部署中，模型必须持续更新、组合，并在需要时选择性地撤销。然而，现有的模型合并和持续学习方法常常遭受任务干扰、灾难性遗忘或缺乏可逆性。我们提出了带正交约束的模块化Delta合并（MDM-OC），这是一个新颖的框架，能够实现微调模型的可扩展、无干扰和可逆组合。每个任务特定模型都被编码为与共享基础的delta，并投影到正交子空间以消除冲突。然后，这些投影的delta通过基于梯度的优化合并，形成一个在所有任务上保持性能的统一模型。我们的方法支持新模型的持续集成、为符合GDPR等要求而进行的结构化解合并，以及通过弹性权重整合和合成重放实现模型稳定性。在视觉和自然语言处理基准测试中的广泛实验表明，MDM-OC在准确性、反向迁移和解合并保真度方面优于现有基线，同时保持内存效率和计算可行性。该框架为模块化和合规的AI系统设计提供了一个原则性的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [204] [Voost: A Unified and Scalable Diffusion Transformer for Bidirectional Virtual Try-On and Try-Off](https://arxiv.org/abs/2508.04825)
> *Voost：一种用于双向虚拟试穿和试脱的统一可扩展扩散变换器*

*Seungyong Lee, Jeong-gi Kwak* | **Category: cs.AI, cs.CV, cs.GR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 虚拟试穿, 扩散变换器, 联合学习, 试脱, Voost

**Comment:** 

> **TL;DR:** Voost提出了一种统一的扩散变换器，通过联合学习虚拟试穿和试脱任务，解决了服装与身体对应建模的挑战，并在两项任务上均达到了最先进的性能。

**AI_Comments:** Voost的创新在于其统一的扩散变换器架构，能够同时处理虚拟试穿和试脱任务，并通过联合学习实现双向监督，有效提升了服装与身体关系推理的准确性。这种方法避免了传统方法中对特定任务网络或额外标签的依赖，简化了模型结构并提高了效率。其提出的推理时技术也进一步增强了模型的鲁棒性和性能。该研究对于推动虚拟试穿领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟试穿技术在准确建模服装与身体的对应关系方面面临持续挑战，尤其是在姿态和外观变化较大的情况下。

**Method:** 本文提出了Voost，一个统一且可扩展的框架，它使用单一的扩散变换器联合学习虚拟试穿和试脱。通过联合建模，Voost使每个服装-人物对能够双向监督，并支持对生成方向和服装类别的灵活条件化，从而在不使用特定任务网络、辅助损失或额外标签的情况下增强服装与身体的关系推理。此外，还引入了两种推理时技术：注意力温度缩放（提高对分辨率或遮罩变化的鲁棒性）和自校正采样（利用任务间的双向一致性）。

**Result:** Voost在试穿和试脱基准测试中均取得了最先进的成果，在对齐精度、视觉保真度和泛化能力方面持续优于强大的基线模型。

**Conclusion:** Voost通过其统一的扩散变换器和联合学习策略，有效解决了虚拟试穿和试脱中的服装-身体对应难题，并在多项性能指标上展现了卓越的SOTA表现，证明了其在虚拟试穿领域的有效性和先进性。

> **ai_Abstract:** Voost是一个创新的统一可扩展扩散变换器框架，旨在解决虚拟试穿中服装与身体对应建模的挑战。它通过一个单一模型联合学习虚拟试穿和试脱任务，利用双向监督和灵活条件化来增强推理能力，无需额外的网络或标签。Voost还引入了注意力温度缩放和自校正采样等推理技术。实验证明，该方法在试穿和试脱任务上均达到了最先进的性能，超越了现有基线。

> **摘要翻译:** 虚拟试穿旨在合成一个人穿着目标服装的逼真图像，但准确建模服装与身体的对应关系仍然是一个持续的挑战，尤其是在姿态和外观变化较大的情况下。在本文中，我们提出了Voost——一个统一且可扩展的框架，它使用单一的扩散变换器联合学习虚拟试穿和试脱。通过联合建模这两项任务，Voost使每个服装-人物对能够双向监督，并支持对生成方向和服装类别的灵活条件化，从而在不使用特定任务网络、辅助损失或额外标签的情况下增强服装与身体的关系推理。此外，我们引入了两种推理时技术：注意力温度缩放，用于提高对分辨率或遮罩变化的鲁棒性；以及自校正采样，它利用任务间的双向一致性。广泛的实验表明，Voost在试穿和试脱基准测试中均取得了最先进的成果，在对齐精度、视觉保真度和泛化能力方面持续优于强大的基线模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [205] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
> *探索深度学习技术在眼部图像准确性别分类中的可行性*

*Basna Mohammed Salih Hasan, Ramadhan J. Mstafa* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 性别分类, 深度学习, 卷积神经网络, 眼周区域, 图像处理

**Comment:** 

> **TL;DR:** 本研究探索了使用深度学习技术，特别是CNN模型，通过眼周区域图像进行性别分类的可行性，并在两个数据集上取得了高准确率。

**AI_Comments:** 该论文的创新点在于专注于利用眼周区域进行性别分类，这可能减少了化妆和伪装对分类准确性的影响。通过使用CNN模型并取得高准确率，表明了其在实际应用中的潜力。其重要性在于为需要高精度性别识别的领域提供了一种鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 性别分类在安全、人机交互、监控和广告等领域至关重要，但现有方法易受化妆和伪装影响。本研究旨在通过关注眼周区域的图像来解决这一准确性问题。

**Method:** 本研究引入了一个复杂的卷积神经网络（CNN）模型，利用彩色眼周区域图像数据库进行性别分类。该模型在CVBL和(Female and Male)两个眼部数据集上进行了验证。

**Result:** 所提出的架构在CVBL数据集上取得了99%的卓越准确率，在(Female and Male)数据集上以少量可学习参数（7,235,089个）取得了96%的可观准确率。结果表明该模型有效。

**Conclusion:** 本研究的结果明确证明了所提出模型在利用眼周区域进行性别分类方面的有效性，表明其在安全和监控等领域的潜在实际应用价值。

> **ai_Abstract:** 本研究旨在解决现有性别分类方法易受化妆和伪装影响的问题，提出了一种基于眼周区域彩色图像的深度学习解决方案。论文设计了一个先进的卷积神经网络（CNN）模型，并利用CVBL和(Female and Male)两个眼部数据集进行了性能评估。实验结果显示，该CNN模型在CVBL数据集上达到了99%的准确率，在(Female and Male)数据集上达到了96%的准确率，验证了其在通过眼周区域进行性别分类方面的有效性，并展现了其在安全和监控等领域的应用潜力。

> **摘要翻译:** 性别分类已成为安全、人机交互、监控和广告等各个领域的关键方面。然而，这种分类的准确性可能会受到化妆和伪装等因素的影响。因此，我们的研究致力于通过关注使用眼周区域彩色图像进行性别分类来解决这一问题。眼周区域指眼睛周围的区域，包括眼睑、眉毛以及它们之间的区域。它包含有价值的视觉线索，可用于提取性别分类的关键特征。本文介绍了一种复杂的卷积神经网络（CNN）模型，该模型利用彩色图像数据库来评估眼周区域在性别分类中的有效性。为了验证模型的性能，我们在两个眼部数据集上进行了测试，即CVBL和（Female and Male）。所推荐的架构在之前未使用的CVBL数据集上取得了99%的卓越准确率，同时在（Female and Male）数据集上以少量可学习参数（7,235,089个）取得了96%的可观准确率。为了确定我们提出的模型在利用眼周区域进行性别分类方面的有效性，我们通过广泛的指标评估了其性能，并将其与其他最先进的方法进行了比较。结果明确证明了我们模型的功效，从而表明其在安全和监控等领域具有潜在的实际应用价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [206] [CF3: Compact and Fast 3D Feature Fields](https://arxiv.org/abs/2508.05254)
> *CF3：紧凑快速的3D特征场*

*Hyunjoon Lee, Joonkyu Min, Jaesik Park* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D Gaussian Splatting, 特征场, 自适应稀疏化, 高斯自编码器, 计算效率

**Comment:** 

> **TL;DR:** 提出CF3，一种紧凑快速的3D高斯特征场构建方法，通过加权融合、高斯级自编码器和自适应稀疏化，仅用5%的高斯点即可实现有竞争力的性能。

**AI_Comments:** 这篇论文通过提出CF3，有效地解决了3D高斯溅射中特征场构建的效率问题。其创新点在于从“自下而上”转变为“自顶向下”的优化流程，特别是引入了直接在提升特征上训练高斯级自编码器以及自适应稀疏化方法，显著降低了模型复杂度（仅用5%高斯点）同时保持了性能，这对于大规模场景或实时应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯溅射（3DGS）整合2D基础模型特征的方法，通常采用自下而上的优化过程，将原始2D特征视为真值，导致计算成本增加。

**Method:** 提出CF3（Compact and Fast 3D Feature Fields）顶层设计流程。首先，对多视图2D特征与预训练高斯进行快速加权融合。接着，直接在提升的特征上训练每个高斯点的自编码器，而非在2D域训练，使自编码器更好地与特征分布对齐。最重要的是，引入自适应稀疏化方法，在优化特征场的高斯属性的同时，剪枝和合并冗余高斯点，构建高效且保留几何细节的表示。

**Result:** 相比Feature-3DGS，该方法仅使用5%的高斯点即可实现具有竞争力的3D特征场。

**Conclusion:** CF3通过高效的特征融合和创新的自适应稀疏化，显著减少了3D高斯特征场的计算成本和表示大小，同时保持了性能和几何细节。

> **ai_Abstract:** CF3提出一种构建紧凑快速3D高斯特征场的新范式，旨在解决现有3DGS特征整合中计算成本高的问题。该方法通过对多视图2D特征与预训练高斯进行快速加权融合，并在提升特征上直接训练高斯级自编码器，实现了特征的良好对齐。此外，引入自适应稀疏化方法，通过剪枝和合并冗余高斯点来优化表示效率和几何细节。实验表明，CF3仅用Feature-3DGS 5%的高斯点就能达到有竞争力的3D特征场效果。

> **摘要翻译:** 3D高斯溅射（3DGS）已开始整合来自2D基础模型的丰富信息。然而，大多数方法依赖于自下而上的优化过程，将原始2D特征视为真值，这导致计算成本增加。我们提出了一种构建紧凑快速3D高斯特征场的顶层设计流程，即CF3。我们首先对多视图2D特征与预训练高斯进行快速加权融合。这种方法使得可以直接在提升的特征上训练每个高斯点的自编码器，而不是在2D域训练自编码器。因此，自编码器能更好地与特征分布对齐。更重要的是，我们引入了一种自适应稀疏化方法，该方法在优化特征场的高斯属性的同时，剪枝和合并冗余高斯点，从而构建了一个高效且保留几何细节的表示。我们的方法与Feature-3DGS相比，仅使用5%的高斯点即可实现具有竞争力的3D特征场。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [211] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
> *LLM个性测量中的持续不稳定性：规模、推理和对话历史的影响*

*Tommaso Tosato, Saskia Helbling, Yorguin-Jose Mantilla-Ramos, Mahmood Hegazy, Alberto Tosato, David John Lemay, Irina Rish, Guillaume Dumas* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 个性测量, 行为一致性, 不稳定性, PERSIST

**Comment:** 

> **TL;DR:** 大型语言模型在个性测量中表现出持续的不稳定性，这对其安全部署构成挑战。

**AI_Comments:** 这项研究通过大规模的系统评估，揭示了LLM在个性测量方面存在的根本性不稳定性，这对于LLM的安全部署和对齐策略具有重要意义。其创新之处在于提出了一个全面的评估框架PERSIST，并系统地测试了多种变量对LLM行为一致性的影响。研究结果挑战了现有关于LLM行为稳定性的假设，并强调了在开发需要可预测行为的LLM应用时面临的严峻挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型需要一致的行为模式以实现安全部署，但其类个性特征仍知之甚少。

**Method:** 提出了PERSIST评估框架，测试了25+个开源模型（1B-671B参数），产生了500,000+响应。使用了传统（BFI-44, SD3）和新型LLM适应的个性测量工具，系统地改变了问题顺序、释义、角色和推理模式。

**Result:** 1. 即使是400B+的模型也表现出显著的响应变异性（标准差 > 0.4）；2. 仅微小的提示重新排序就能使个性测量结果改变高达20%；3. 预期能稳定行为的干预措施（如思维链推理、详细角色指令、包含对话历史）反而可能增加变异性；4. LLM适应的工具与以人为中心的版本显示出同样的不稳定性，证实了是架构而非翻译限制。

**Conclusion:** 这种跨规模和缓解策略的持续不稳定性表明当前的LLM缺乏真正行为一致性的基础。对于需要可预测行为的安全关键应用，这些发现表明基于个性的对齐策略可能根本不充分。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLM）个性测量中的持续不稳定性。通过开发PERSIST评估框架并测试25+个开源模型，研究发现即使是大型LLM也表现出显著的响应变异性，且微小的提示变化或旨在稳定行为的干预措施（如思维链）反而会增加这种不稳定性。这表明当前LLM缺乏行为一致性的基础，对安全关键应用中基于个性的对齐策略提出了质疑。

> **摘要翻译:** 大型语言模型需要一致的行为模式以实现安全部署，但其类个性特征仍知之甚少。我们提出了PERSIST（合成文本中的个性稳定性），这是一个全面的评估框架，测试了25+个开源模型（1B-671B参数），产生了500,000+响应。我们使用传统（BFI-44，SD3）和新型LLM适应的个性测量工具，系统地改变了问题顺序、释义、角色和推理模式。我们的发现挑战了基本的部署假设：（1）即使是400B+的模型也表现出显著的响应变异性（标准差 > 0.4）；（2）仅微小的提示重新排序就能使个性测量结果改变高达20%；（3）预期能稳定行为的干预措施，例如思维链推理、详细角色指令、包含对话历史，反而可能增加变异性；（4）LLM适应的工具与以人为中心的版本显示出同样的不稳定性，证实了是架构而非翻译限制。这种跨规模和缓解策略的持续不稳定性表明当前的LLM缺乏真正行为一致性的基础。对于需要可预测行为的安全关键应用，这些发现表明基于个性的对齐策略可能根本不充分。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [212] [Marine Chlorophyll Prediction and Driver Analysis based on LSTM-RF Hybrid Models](https://arxiv.org/abs/2508.05260)
> *基于LSTM-RF混合模型的海洋叶绿素预测与驱动因素分析*

*Zhouyao Qian, Yang Chen, Baodian Li, Shuyi Zhang, Zhen Tian, Gongsen Wang, Tianyue Gu, Xinyu Zhou, Huilin Chen, Xinyi Li, Hao Zhu, Shuyao Zhang, Zongheng Li, Siyuan Wang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 海洋叶绿素, LSTM-RF混合模型, 预测, 时间序列, 驱动因素分析

**Comment:** 

> **TL;DR:** 本文提出了一种LSTM-RF混合模型，用于准确预测海洋叶绿素浓度，该模型在时间序列建模和非线性特征刻画方面优于单一模型，并显著提高了预测精度。

**AI_Comments:** 本文提出了一种创新的LSTM-RF混合模型，有效结合了两种模型的优势，解决了海洋叶绿素预测中的关键挑战。其创新性在于融合了时间序列建模和非线性特征刻画能力，并显著提高了预测精度，为海洋生态预警和管理提供了有力的工具。

<details>
  <summary>Details</summary>

**Motivation:** 海洋叶绿素浓度是生态系统健康和碳循环强度的重要指标，其准确预测对于赤潮预警和生态响应至关重要。

**Method:** 本文提出了一种结合LSTM和RF优点的LSTM-RF混合模型，解决了单一模型在时间序列建模和非线性特征刻画方面的不足。模型使用多源海洋数据（温度、盐度、溶解氧等）进行训练，并采用了标准化处理和滑动窗口方法。

**Result:** 实验结果表明，LSTM-RF模型在测试集上的R^2为0.5386，MSE为0.005806，MAE为0.057147，显著优于单独使用LSTM（R^2 = 0.0208）和RF（R^2 = 0.4934）的模型。

**Conclusion:** LSTM-RF混合模型能够有效提高海洋叶绿素的预测精度，为海洋生态变量的高频预测提供了一种创新解决方案。

> **ai_Abstract:** 本研究提出了一种结合LSTM和RF优点的LSTM-RF混合模型，用于准确预测海洋叶绿素浓度。该模型通过整合多源海洋数据训练，有效克服了单一模型在时间序列和非线性特征处理上的局限性。实验结果显示，该混合模型在预测精度上显著优于单独的LSTM或RF模型，为海洋生态变量的高频预测提供了新方法。

> **摘要翻译:** 海洋叶绿素浓度是生态系统健康和碳循环强度的重要指标，其准确预测对于赤潮预警和生态响应至关重要。本文提出了一种LSTM-RF混合模型，该模型结合了LSTM和RF的优点，解决了单一模型在时间序列建模和非线性特征刻画方面的不足。利用多源海洋数据（温度、盐度、溶解氧等）进行训练，实验结果表明，LSTM-RF模型在测试集上的R^2为0.5386，MSE为0.005806，MAE为0.057147，分别显著优于单独使用LSTM（R^2 = 0.0208）和RF（R^2 = 0.4934）的模型。标准化处理和滑动窗口方法提高了模型的预测精度，为海洋生态变量的高频预测提供了一种创新解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [213] [Personalized Safety Alignment for Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.01151)
> *文本到图像扩散模型的个性化安全对齐*

*Yu Lei, Jinbin Bai, Qingyu Shi, Aosong Feng, Kaidong Yu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 个性化安全, 扩散模型, 文本到图像, 内容生成, 用户偏好

**Comment:** 

> **TL;DR:** 提出个性化安全对齐（PSA）框架，允许用户自定义文生图模型的安全行为，以适应不同用户的偏好，同时保持图像质量。

**AI_Comments:** 这项工作具有创新性，因为它解决了当前文生图模型中安全策略的“一刀切”问题，引入了用户个性化定制安全行为的能力。这对于提升用户体验和模型在多样化社会背景下的适用性至关重要。通过引入新的数据集和框架，该研究为未来个性化内容生成安全领域奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前的文本到图像扩散模型安全机制采用统一标准，未能考虑用户个体偏好，忽略了年龄、心理健康和个人信仰等因素塑造的差异化安全边界。

**Method:** 提出个性化安全对齐（PSA）框架，通过将个性化用户配置文件整合到扩散过程中，并引入新的数据集Sage来捕捉用户特定的安全偏好，通过交叉注意力机制调整模型行为以匹配个体安全偏好，同时保持图像质量。

**Result:** 实验表明，PSA在有害内容抑制方面优于现有方法，并且更好地将生成内容与用户约束对齐，实现了更高的胜率（Win Rate）和通过率（Pass Rate）分数。

**Conclusion:** 个性化安全对齐（PSA）框架能有效解决文本到图像扩散模型中统一安全标准无法满足个体用户偏好的问题，显著提升有害内容抑制效果并更好地与用户约束对齐。

> **ai_Abstract:** 本文提出了个性化安全对齐（PSA）框架，旨在解决文本到图像扩散模型中现有统一安全机制无法满足用户个性化安全偏好的问题。PSA通过将用户配置文件整合到扩散过程中，并引入新的Sage数据集来捕捉和利用用户特定的安全偏好，通过交叉注意力机制调整模型行为。实验证明，PSA在有害内容抑制和内容与用户约束对齐方面均优于现有方法，提升了生成内容的个性化安全性和质量。

> **摘要翻译:** 文本到图像扩散模型彻底改变了视觉内容生成，但当前的安全机制采用统一标准，往往无法顾及个体用户偏好。这些模型忽视了由年龄、心理健康和个人信仰等因素塑造的多样化安全边界。为了解决这个问题，我们提出了个性化安全对齐（PSA），这是一个允许用户特定控制生成模型安全行为的框架。PSA将个性化用户配置文件整合到扩散过程中，调整模型的行为以匹配个体安全偏好，同时保持图像质量。我们引入了一个新的数据集Sage，它捕捉用户特定的安全偏好并通过交叉注意力机制整合这些配置文件。实验表明，PSA在有害内容抑制方面优于现有方法，并能更好地将生成内容与用户约束对齐，实现了更高的胜率和通过率分数。我们的代码、数据和模型已在https://m-e-agi-lab.github.io/PSAlign/公开可用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [218] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
> *多阶段知识蒸馏VGAE和GAT用于鲁棒的控制器局域网入侵检测*

*Robert Frenken, Sidra Ghayour Bhatti, Hanqin Zhang, Qadeer Ahmed* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-06**

**Keywords:** CAN入侵检测, 图神经网络, 知识蒸馏, 异常检测, 类别不平衡

**Comment:** 

> **TL;DR:** 本文提出一种多阶段知识蒸馏VGAE和GAT框架，通过图学习和选择性欠采样，实现了对CAN总线网络攻击的鲁棒检测，显著提升了不平衡数据集上的F1分数，并大幅减少了模型参数。

**AI_Comments:** 该研究的创新点在于结合无监督VGAE进行异常检测和数据预处理（欠采样），以及利用知识蒸馏GAT进行高效鲁棒分类。特别是在解决车载网络数据高度不平衡问题上，其性能提升显著，同时实现了模型的小型化，这对于资源受限的车载环境具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 控制器局域网（CAN）协议作为车载通信标准，因缺乏内置安全性而易受网络攻击，因此需要一个鲁棒有效的入侵检测框架。

**Method:** 提出一个多阶段入侵检测框架，结合无监督变分图自编码器（VGAE）进行结构异常检测和知识蒸馏图注意力网络（KD-GAT）进行攻击分类。将CAN总线活动编码为图序列以建模时序和关系依赖。通过VGAE进行选择性欠采样以处理类别不平衡，随后是GAT分类，并可选分数级融合。

**Result:** 在Car-Hacking、Car-Survival和can-train-and-test等六个公共CAN入侵数据集上，该方法展现出竞争性的准确性和效率。F1分数比现有方法平均提高16.2%，在高度不平衡数据集上F1分数提高高达55%。紧凑的学生GAT模型与教师模型相比，参数减少96%，同时保持了强大的预测性能。

**Conclusion:** 该多阶段知识蒸馏VGAE和GAT框架能够有效且鲁棒地检测CAN总线入侵，尤其在处理类别不平衡问题上表现出色，且模型效率高，具有实际应用价值。

> **ai_Abstract:** 本文提出了一种新颖的多阶段入侵检测框架，用于增强车载CAN协议的安全性。该框架结合了变分图自编码器（VGAE）进行结构异常检测和知识蒸馏图注意力网络（KD-GAT）进行攻击分类。通过将CAN活动编码为图序列，并利用VGAE进行选择性欠采样以处理类别不平衡问题，该方法在多个公共数据集上展现了优越的性能，尤其在F1分数上取得了显著提升，同时实现了模型的高度压缩和高效运行。

> **摘要翻译:** 控制器局域网（CAN）协议是车载通信的标准，但由于缺乏内置安全性，仍然容易受到网络攻击。本文提出了一种多阶段入侵检测框架，利用无监督异常检测和为汽车CAN流量量身定制的监督图学习。我们的架构结合了用于结构异常检测的变分图自编码器（VGAE）和用于鲁棒攻击分类的知识蒸馏图注意力网络（KD-GAT）。CAN总线活动被编码为图序列，以建模时间依赖性和关系依赖性。该流程应用基于VGAE的选择性欠采样来解决类别不平衡问题，随后进行GAT分类，并可选地进行分数级融合。紧凑的学生GAT模型与教师模型相比，参数减少了96%，同时保持了强大的预测性能。在六个公共CAN入侵数据集（Car-Hacking、Car-Survival和can-train-and-test）上的实验证明了具有竞争力的准确性和效率，F1分数比现有方法平均提高了16.2%，尤其在高度不平衡数据集上F1分数提高了高达55%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [219] [Robust Tracking with Particle Filtering for Fluorescent Cardiac Imaging](https://arxiv.org/abs/2508.05262)
> *荧光心脏成像中基于粒子滤波的鲁棒跟踪*

*Suresh Guttikonda, Maximilian Neidhart, Johanna Sprenger, Johannes Petersen, Christian Detter, Alexander Schlaefer* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 粒子滤波, 鲁棒跟踪, 荧光心脏成像, 循环一致性检查, 心脏灌注

**Comment:** 

> **TL;DR:** 提出了一种基于循环一致性检查的粒子滤波跟踪器，用于荧光心脏成像中鲁棒跟踪心脏特征点，其跟踪误差低且性能优于传统和深度学习跟踪器。

**AI_Comments:** 该研究的创新点在于将粒子滤波与循环一致性检查相结合，有效解决了心脏成像中因运动和图像波动导致的跟踪难题。其重要性在于为术中荧光心脏成像提供了实时、高精度的跟踪解决方案，有助于提高冠状动脉旁路移植术后的质量控制。

<details>
  <summary>Details</summary>

**Motivation:** 传统跟踪方法在荧光心脏成像中受心脏运动和图像特征显著波动限制，难以准确跟踪局部特征点以估计心脏灌注等定量指标。

**Method:** 提出了一种基于循环一致性检查的粒子滤波跟踪器，用于鲁棒地跟踪采样以跟随目标地标的粒子。

**Result:** 该方法能够以25.4 fps的速度同时跟踪117个目标，跟踪误差为(5.00 +/- 0.22 px)，优于深度学习跟踪器(22.3 +/- 1.1 px)和传统跟踪器(58.1 +/- 27.1 px)。

**Conclusion:** 该粒子滤波跟踪器能有效克服心脏运动和图像波动，实现荧光心脏成像中的实时、高精度鲁棒跟踪，有助于术中质量控制。

> **ai_Abstract:** 本文提出了一种用于荧光心脏成像的粒子滤波跟踪器，旨在解决心脏运动和图像特征波动对传统跟踪方法的限制。该方法基于循环一致性检查，能够鲁棒地跟踪心脏局部特征点，从而实现心肌灌注等定量指标的实时估计。实验结果表明，该跟踪器能以高帧率同时跟踪大量目标，并显著优于现有深度学习和传统跟踪方法，具有更高的跟踪精度。

> **摘要翻译:** 术中荧光心脏成像能够实现冠状动脉旁路移植术后的质量控制。通过跟踪局部特征点，我们可以估计局部定量指标，例如心肌灌注。然而，心脏运动和血管结构富集引起的图像特征显著波动限制了传统跟踪方法。我们提出了一种基于循环一致性检查的粒子滤波跟踪器，以鲁棒地跟踪采样以跟随目标地标的粒子。我们的方法能以25.4帧/秒的速度同时跟踪117个目标，从而在介入过程中进行实时估计。它实现了(5.00 +/- 0.22 像素)的跟踪误差，并且优于其他深度学习跟踪器(22.3 +/- 1.1 像素)和传统跟踪器(58.1 +/- 27.1 像素)。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [220] [SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy](https://arxiv.org/abs/2508.01188)
> *SpectrumWorld: 人工智能光谱学基础*

*Zhuo Yang, Jiaqing Xie, Shuaike Shen, Daolang Wang, Yeyun Chen, Ben Gao, Shuzhou Sun, Biqing Qi, Dongzhan Zhou, Lei Bai, Linjiang Chen, Shufei Zhang, Jun Jiang, Tianfan Fu, Yuqiang Li* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 光谱学, 深度学习, 基准测试, 统一平台, 人工智能

**Comment:** 

> **TL;DR:** SpectrumLab是一个统一平台，旨在标准化和加速光谱学领域的深度学习研究，提供库、数据标注工具和多任务基准测试，并揭示了现有方法的局限性。

**AI_Comments:** 本文提出SpectrumLab平台，旨在解决光谱学深度学习研究中缺乏标准化的痛点。其创新之处在于整合了数据处理工具、高质量基准生成器和全面的多任务基准测试集。SpectrumBench涵盖了广泛的光谱类型和任务，数据量庞大，对于评估和推动光谱学AI模型的发展具有重要意义。实证研究揭示了当前方法的局限性，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在光谱学中潜力巨大，但该领域的研究和评估缺乏标准化。

**Method:** 本文引入了SpectrumLab，一个开创性的统一平台，旨在系统化和加速光谱学领域的深度学习研究。SpectrumLab集成了三个核心组件：一个全面的Python库，包含基本的数据处理和评估工具以及排行榜；一个创新的SpectrumAnnotator模块，可以从有限的种子数据生成高质量的基准；以及SpectrumBench，一个多层基准测试套件，涵盖14个光谱任务和10多种光谱类型，其光谱数据来自超过120万种不同的化学物质。

**Result:** 对SpectrumBench使用18个尖端多模态LLM进行的彻底实证研究，揭示了当前方法的关键局限性。

**Conclusion:** 希望SpectrumLab能成为深度学习驱动光谱学未来发展的重要基础。

> **ai_Abstract:** 本文介绍了SpectrumLab，一个旨在标准化和加速光谱学深度学习研究的统一平台。它包含一个Python库、一个数据标注模块SpectrumAnnotator和一个多任务基准测试套件SpectrumBench。SpectrumBench涵盖14个光谱任务和10多种光谱类型，包含超过120万种化学物质的光谱。实证研究表明，现有方法在这些任务上存在局限性，作者希望SpectrumLab能为未来研究奠定基础。

> **摘要翻译:** 深度学习在光谱学领域前景广阔，但这一新兴领域的研究和评估往往缺乏标准化的表述。为了解决这个问题，我们引入了SpectrumLab，这是一个开创性的统一平台，旨在系统化和加速光谱学领域的深度学习研究。SpectrumLab集成了三个核心组件：一个全面的Python库，包含基本的数据处理和评估工具以及排行榜；一个创新的SpectrumAnnotator模块，可以从有限的种子数据生成高质量的基准；以及SpectrumBench，一个多层基准测试套件，涵盖14个光谱任务和10多种光谱类型，其光谱数据来自超过120万种不同的化学物质。通过对SpectrumBench使用18个尖端多模态LLM进行的彻底实证研究，揭示了当前方法的关键局限性。我们希望SpectrumLab能成为深度学习驱动光谱学未来发展的重要基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [225] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
> *可证明的训练后量化：OPTQ和Qronos的理论分析*

*Haoyu Zhang, Shihao Zhang, Ian Colbert, Rayan Saab* | **Category: cs.AI, cs.IT, cs.LG, math.NA** | **Updated: 2025-08-06**

**Keywords:** 训练后量化, OPTQ, Qronos, 误差界限, 量化理论

**Comment:** 

> **TL;DR:** 本文首次为流行的训练后量化算法OPTQ及其变体以及Qronos提供了严格的定量误差界限，为实践中的设计选择提供了理论依据。

**AI_Comments:** 本文的创新点在于首次为广泛使用的训练后量化算法OPTQ提供了严格的定量误差界限，填补了该领域的一个重要理论空白。其重要性体现在为实际应用中的算法设计选择提供了坚实的理论依据和指导，有助于进一步优化量化效果和理解算法行为。特别是对随机变体和Qronos的分析，扩展了理论适用范围。

<details>
  <summary>Details</summary>

**Motivation:** 尽管OPTQ（又名GPTQ）在计算效率和经验性能方面表现出色并被广泛采用，但它缺乏严格的定量理论保证。

**Method:** 本文对OPTQ的迭代过程进行误差分析，推导了非渐近的2范数误差界限，这些界限明确依赖于校准数据和正则化参数。对于随机变体，建立了更强的无穷范数误差界限。此外，还将分析扩展到Qronos算法。

**Result:** 首次为确定性和随机OPTQ以及Qronos提供了定量误差界限。分析为实践中的设计选择（如按范数递减排序特征）提供了理论依据，并为正则化参数的选择提供了指导。随机变体的无穷范数误差界限有助于控制所需的量化字母表。为Qronos提供了新的理论界限，解释了其经验优势。

**Conclusion:** 本文通过提供严格的理论误差界限，为OPTQ和Qronos这两种重要的训练后量化算法提供了坚实的理论基础，并为实际应用中的设计选择和参数调整提供了指导。

> **ai_Abstract:** 本文针对流行的训练后量化（PTQ）算法OPTQ（亦称GPTQ）及其相关算法Qronos，解决了它们缺乏严格理论保证的问题。研究首次为OPTQ的确定性与随机变体以及Qronos提供了量化误差界限，具体推导了依赖于校准数据和正则化参数的非渐近2范数误差界限，并为随机变体建立了更强的无穷范数误差界限。这些理论分析不仅为OPTQ的实际设计选择（如特征排序）提供了理论依据和参数选择指导，也解释了Qronos的经验优势。

> **摘要翻译:** 训练后量化（PTQ）已成为降低现代深度神经网络（包括大型语言模型，LLM）内存和计算成本的关键工具。在PTQ算法中，OPTQ框架（也称为GPTQ）因其计算效率和强大的经验性能而成为领先方法。然而，尽管OPTQ被广泛采用，但它缺乏严格的定量理论保证。本文首次为OPTQ的确定性和随机变体以及最近相关的最先进PTQ算法Qronos提供了定量误差界限。我们分析了OPTQ的迭代过程如何引起量化误差，并推导出了非渐近的2范数误差界限，这些界限明确依赖于校准数据和OPTQ使用的正则化参数。我们的分析为几种实际设计选择提供了理论依据，包括广泛使用的按范数递减排序特征的启发式方法，以及选择正则化参数的指导。对于随机变体，我们建立了更强的无穷范数误差界限，这使得能够控制所需的量化字母表，并且对于下游层和非线性尤其有用。最后，我们将分析扩展到Qronos，为其确定性和随机变体提供了新的理论界限，这有助于解释其经验优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [226] [SGDFuse: SAM-Guided Diffusion for High-Fidelity Infrared and Visible Image Fusion](https://arxiv.org/abs/2508.05264)
> *SGDFuse：SAM引导扩散用于高保真红外与可见光图像融合*

*Xiaoyang Zhang, Zhen Hua, Yakun Ju, Wei Zhou, Jun Liu, Alex C. Kot* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 红外与可见光图像融合, 扩散模型, SAM, 语义引导, 高保真

**Comment:** 

> **TL;DR:** SGDFuse提出了一种由SAM引导的条件扩散模型，用于实现高保真、语义感知的红外与可见光图像融合，解决了现有方法在目标保留和伪影生成方面的不足，并取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于首次将SAM的强大语义分割能力引入到红外与可见光图像融合任务中，并通过条件扩散模型进行有效引导。这种结合解决了传统融合方法在语义理解和关键目标保留上的不足，显著提升了融合图像的质量和实用性。其两阶段的融合策略也显示出对细节和语义的精细控制能力，为图像融合领域带来了新的研究方向和技术突破。

<details>
  <summary>Details</summary>

**Motivation:** 红外与可见光图像融合（IVIF）旨在结合红外图像的热辐射信息和可见光图像丰富的纹理细节，以增强下游视觉任务的感知能力。然而，现有方法由于缺乏对场景的深层语义理解，往往无法保留关键目标，并且融合过程本身会引入伪影和细节损失，严重损害图像质量和任务性能。

**Method:** 本文提出了SGDFuse，一个由Segment Anything Model (SAM) 引导的条件扩散模型，以实现高保真和语义感知的图像融合。其核心是利用SAM生成的高质量语义掩码作为显式先验，通过条件扩散模型引导融合过程的优化。该框架分两阶段操作：首先对多模态特征进行初步融合，然后将SAM的语义掩码与初步融合的图像联合作为条件，驱动扩散模型的从粗到精去噪生成，从而确保融合过程具有明确的语义方向性并保证最终结果的高保真度。

**Result:** 广泛的实验表明，SGDFuse在主观和客观评估以及对下游任务的适应性方面均达到了最先进的性能，为图像融合中的核心挑战提供了强大的解决方案。

**Conclusion:** SGDFuse通过结合SAM引导的条件扩散模型，为红外与可见光图像融合提供了一个高保真、语义感知的解决方案，有效解决了现有方法在目标保留和伪影生成方面的挑战，并显著提升了图像质量和下游任务性能。

> **ai_Abstract:** SGDFuse是一种新颖的红外与可见光图像融合方法，它利用Segment Anything Model (SAM) 生成的语义掩码作为显式先验，并通过两阶段的条件扩散模型进行引导。该方法旨在解决现有融合技术中目标保留不足、伪影和细节丢失的问题，从而实现高保真和语义感知的图像融合。实验结果表明，SGDFuse在图像质量和下游任务适应性方面均超越了现有技术，为图像融合领域提供了强大的新方案。

> **摘要翻译:** 红外与可见光图像融合（IVIF）旨在结合红外图像的热辐射信息和可见光图像丰富的纹理细节，以增强下游视觉任务的感知能力。然而，现有方法由于缺乏对场景的深层语义理解，往往无法保留关键目标，并且融合过程本身会引入伪影和细节损失，严重损害图像质量和任务性能。为解决这些问题，本文提出了SGDFuse，一个由Segment Anything Model (SAM) 引导的条件扩散模型，以实现高保真和语义感知的图像融合。我们方法的核心是利用SAM生成的高质量语义掩码作为显式先验，通过条件扩散模型引导融合过程的优化。具体而言，该框架分两阶段操作：首先对多模态特征进行初步融合，然后将SAM的语义掩码与初步融合的图像联合作为条件，驱动扩散模型的从粗到精去噪生成。这确保了融合过程不仅具有明确的语义方向性，而且保证了最终结果的高保真度。广泛的实验表明，SGDFuse在主观和客观评估以及对下游任务的适应性方面均达到了最先进的性能，为图像融合中的核心挑战提供了强大的解决方案。SGDFuse的代码可在https://github.com/boshizhang123/SGDFuse获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [227] [RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Lifelong Learning in Physical Embodied Systems](https://arxiv.org/abs/2508.01415)
> *RoboMemory：一个受大脑启发的物理具身系统终身学习多记忆智能体框架*

*Mingcong Lei, Honghao Cai, Binbin Que, Zezhou Cui, Liangchen Tan, Junkun Hong, Gehan Hu, Shuangyu Zhu, Yimou Wu, Shaohan Jiang, Ge Wang, Zhen Li, Shuguang Cui, Yiming Zhao, Yatong Han* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 终身学习, 多记忆系统, 具身智能体, 脑启发, 知识图谱

**Comment:** 

> **TL;DR:** RoboMemory是一个受大脑启发的多记忆框架，用于物理具身系统中的终身学习，它通过集成多模块记忆和规划，显著提高了在真实世界任务中的成功率，并解决了延迟和可扩展性问题。

**AI_Comments:** RoboMemory的创新之处在于其受大脑启发的模块化设计，特别是通过并行化更新/检索来解决复杂记忆框架中的推理速度问题，并引入动态知识图谱增强记忆一致性和可扩展性。其在真实世界具身系统中的应用前景广阔，为解决机器人终身学习的关键挑战提供了有效方案。该框架不仅在性能上超越了现有SOTA，还通过实际部署验证了其鲁棒性，具有重要的研究和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决物理具身系统在真实世界环境中的关键挑战：持续学习、多模块记忆延迟、任务相关性捕获以及闭环规划中的无限循环缓解。

**Method:** RoboMemory是一个受大脑启发的多记忆框架，整合了信息预处理器（类丘脑）、终身具身记忆系统（类海马体）、闭环规划模块（类前额叶）和低级执行器（类小脑）四个核心模块。其核心的终身具身记忆系统通过在空间、时间、情景和语义子模块间并行更新/检索来缓解推理速度问题，并整合动态知识图谱（KG）以增强记忆一致性和可扩展性。

**Result:** 在EmbodiedBench上的评估显示，RoboMemory在平均成功率方面比开源基线（Qwen2.5-VL-72B-Ins）高出25%，并超越了闭源最先进技术（SOTA）（Claude3.5-Sonnet）5%，确立了新的SOTA。消融研究验证了关键组件的有效性，真实世界部署证实了其终身学习能力和在重复任务中显著提高的成功率。

**Conclusion:** RoboMemory通过可扩展性缓解了高延迟挑战，为在物理机器人中集成多模态记忆系统提供了基础性参考。

> **ai_Abstract:** 本论文提出了RoboMemory，一个受大脑启发的物理具身系统终身学习多记忆框架。它旨在解决现实世界中持续学习、记忆延迟、任务关联和无限循环等挑战。RoboMemory集成了信息预处理器、终身具身记忆系统、闭环规划模块和低级执行器等核心模块，其中终身具身记忆系统通过并行更新/检索和动态知识图谱来提高效率和一致性。实验证明，RoboMemory在EmbodiedBench上表现优异，超越了现有基线和SOTA模型，并在实际部署中验证了其终身学习能力和高成功率，为物理机器人多模态记忆系统提供了重要参考。

> **摘要翻译:** 我们提出了RoboMemory，一个受大脑启发的物理具身系统终身学习多记忆框架，旨在解决真实世界环境中的关键挑战：持续学习、多模块记忆延迟、任务相关性捕获以及闭环规划中的无限循环缓解。该框架以认知神经科学为基础，整合了四个核心模块：信息预处理器（类丘脑）、终身具身记忆系统（类海马体）、闭环规划模块（类前额叶）和低级执行器（类小脑），以实现长期规划和累积学习。终身具身记忆系统是该框架的核心，通过在空间、时间、情景和语义子模块之间进行并行更新/检索，缓解了复杂记忆框架中的推理速度问题。它整合了一个动态知识图谱（KG）和一致的架构设计，以增强记忆一致性和可扩展性。在EmbodiedBench上的评估表明，RoboMemory在平均成功率方面比开源基线（Qwen2.5-VL-72B-Ins）高出25%，并超越了闭源最先进技术（SOTA）（Claude3.5-Sonnet）5%，确立了新的SOTA。消融研究验证了关键组件（评论家、空间记忆、长期记忆），而实际部署证实了其终身学习能力，在重复任务中显著提高了成功率。RoboMemory通过可扩展性缓解了高延迟挑战，为在物理机器人中集成多模态记忆系统提供了基础性参考。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [232] [Sequence Aware SAC Control for Engine Fuel Consumption Optimization in Electrified Powertrain](https://arxiv.org/abs/2508.04874)
> *电动动力总成中发动机油耗优化的序列感知SAC控制*

*Wafeeq Jaleel, Md Ragib Rownak, Athar Hanif, Sidra Ghayour Bhatti, Qadeer Ahmed* | **Category: cs.AI, cs.LG, eess.SY** | **Updated: 2025-08-06**

**Keywords:** 强化学习, 软Actor-Critic, 混合动力汽车, 发动机控制, 序列感知, 燃油优化

**Comment:** 

> **TL;DR:** 本文提出一种基于SAC算法并结合GRU和DT的强化学习框架，用于优化混合动力重型卡车的发动机控制，在燃油经济性上接近动态规划，并在未见过的驾驶循环中表现出更好的泛化能力。

**AI_Comments:** 本文的创新点在于将序列感知能力（通过GRU和DT）引入到SAC强化学习框架中，以解决混合动力汽车发动机控制中的时间依赖性问题。这种方法显著提升了模型的泛化能力和鲁棒性，使其在实际未见的驾驶循环中表现优异，接近最优控制策略的性能，对于电动动力总成的能量管理具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着混合动力电动汽车在重型卡车中的应用，自适应和高效的能量管理对于降低油耗和维持电池电量以实现长时间运行至关重要。

**Method:** 提出了一种基于软Actor-Critic (SAC) 算法的新型强化学习框架，用于优化串联式混合动力电动汽车的发动机控制。将控制任务重新定义为序列决策问题，并通过将门控循环单元(GRU)和决策Transformer (DT)集成到Actor和Critic网络中来增强SAC，以捕获时间依赖性并改进长期规划。模型在不同的初始电池状态、驾驶循环持续时间、功率需求和输入序列长度下进行训练，以评估鲁棒性和泛化能力。

**Result:** 在高速公路燃油经济性测试 (HFET) 循环中，结合DT-based Actor和GRU-based Critic的SAC智能体在节油方面与动态规划 (DP) 的差距在1.8%以内。同时，Actor和Critic网络均采用GRU的SAC智能体以及FFN Actor-Critic智能体的节油差距分别为3.16%和3.43%。在未见过的驾驶循环（US06和重型卡车巡航路段）中，泛化的序列感知智能体持续优于基于前馈网络 (FFN) 的智能体。

**Conclusion:** 结合了序列感知能力的SAC强化学习方法，特别是融合了决策Transformer和门控循环单元的模型，在混合动力电动汽车的发动机油耗优化方面表现出接近最优的性能，并具备在真实世界场景中的出色适应性和鲁棒性。

> **ai_Abstract:** 本文提出了一种新型强化学习框架，该框架基于Soft Actor-Critic (SAC) 算法，并结合了门控循环单元 (GRU) 和决策Transformer (DT) 来优化串联式混合动力电动汽车的发动机控制。通过将控制任务建模为序列决策问题，该方法能够捕获时间依赖性并改进规划。实验结果表明，所提出的序列感知SAC智能体在燃油经济性方面接近动态规划的性能，并且在未见过的驾驶循环中展现出优于传统前馈网络方法的泛化能力和鲁棒性，对于重型卡车中的高效能量管理具有重要意义。

> **摘要翻译:** 随着混合动力电动汽车（HEV）在重型卡车中的普及，自适应且高效的能量管理对于降低油耗同时维持电池电量以实现长时间运行至关重要。我们提出了一种基于软Actor-Critic（SAC）算法的新型强化学习（RL）框架，用于优化串联式HEV中的发动机控制。我们将控制任务重新定义为序列决策问题，并通过将门控循环单元（GRU）和决策Transformer（DT）集成到Actor和Critic网络中来增强SAC，以捕获时间依赖性并改进长期规划。为了评估鲁棒性和泛化能力，我们在不同的初始电池状态、驾驶循环持续时间、功率需求和输入序列长度下训练模型。实验表明，在高速公路燃油经济性测试（HFET）循环中，结合DT-based Actor和GRU-based Critic的SAC智能体在节油方面与动态规划（DP）的差距在1.8%以内，而Actor和Critic网络均采用GRU的SAC智能体以及FFN Actor-Critic智能体的差距分别为3.16%和3.43%。在未见过的驾驶循环（US06和重型卡车巡航路段）中，泛化的序列感知智能体持续优于基于前馈网络（FFN）的智能体，突显了它们在真实世界环境中的适应性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [233] [FlowState: Sampling Rate Invariant Time Series Forecasting](https://arxiv.org/abs/2508.05287)
> *FlowState：采样率不变时间序列预测*

*Lars Graf, Thomas Ortner, Stanisław Woźniak, Angeliki Pantazi* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 时间序列预测, 基础模型, 采样率不变性, 状态空间模型, 连续时间建模

**Comment:** 

> **TL;DR:** FlowState是一个新的时间序列基础模型，通过基于状态空间模型（SSM）的编码器和函数基解码器实现采样率不变性，解决了现有模型在泛化性、适应性和效率上的挑战，并在基准测试中表现出色。

**AI_Comments:** FlowState的创新之处在于其采用SSM编码器和函数基解码器来实现采样率不变性，这在时间序列预测领域是一个重大突破，解决了现有Transformer基模型在泛化性和适应性上的核心痛点。它通过连续时间建模和动态时间尺度调整，实现了对不同采样率的内在适应，而非依赖大量多尺度训练数据，这显著提高了模型的效率和实用性。其在小型模型下达到SOTA性能，显示了其设计的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间序列基础模型（TSFMs）在不同上下文和目标长度的泛化方面存在困难，缺乏对不同采样率的适应性，且计算效率低下，需要大量跨采样率的训练数据。

**Method:** 本文提出了FlowState，一种新颖的TSFM架构。其核心创新在于采用基于状态空间模型（SSM）的编码器和函数基解码器。这种设计实现了连续时间建模和动态时间尺度调整，使模型能够固有地泛化所有可能的时间分辨率并动态调整预测范围。此外，还提出了一种高效的预训练策略。

**Result:** FlowState能固有地将其内部动态适应输入尺度，实现更小的模型、更少的数据需求和更高的效率。尽管是最小的模型，FlowState在GIFT-ZS和Chronos-ZS基准测试中超越了所有其他模型，达到了最先进水平。消融研究证实了其组件的有效性，并展示了其在线适应不同输入采样率的独特能力。

**Conclusion:** FlowState通过引入一种新颖的架构，成功解决了现有TSFM的局限性，实现了采样率不变性、卓越的泛化能力和效率，并在关键基准测试中取得了最先进的性能。

> **ai_Abstract:** 本研究介绍了FlowState，一种新颖的时间序列基础模型（TSFM），旨在解决现有TSFM在泛化能力、采样率适应性和计算效率方面的局限性。FlowState的核心创新在于其基于状态空间模型（SSM）的编码器和函数基解码器，实现了连续时间建模和动态时间尺度调整，使其能够固有地适应各种时间分辨率和采样率。与传统方法不同，FlowState无需在所有采样率下进行训练，从而减少了模型大小和数据需求。实验结果表明，FlowState即使作为最小的模型，也能在GIFT-ZS和Chronos-ZS基准测试中超越现有最先进模型，并展示了其在线适应不同输入采样率的独特能力。

> **摘要翻译:** 基础模型（FMs）已经彻底改变了自然语言处理，但它们的成功尚未转化为时间序列预测。现有的时间序列基础模型（TSFMs），通常基于Transformer变体，在不同上下文和目标长度的泛化方面存在困难，缺乏对不同采样率的适应性，并且计算效率低下。我们引入了FlowState，一种新颖的TSFM架构，通过两项关键创新解决了这些挑战：一个基于状态空间模型（SSM）的编码器和一个函数基解码器。这种设计实现了连续时间建模和动态时间尺度调整，使FlowState能够固有地泛化所有可能的临时分辨率，并动态调整预测范围。与需要跨所有可能采样率的训练数据以记忆每个尺度模式的其他最先进的TSFMs不同，FlowState固有地将其内部动态适应输入尺度，从而实现更小的模型、更少的数据需求和更高的效率。我们进一步提出了一种有效的预训练策略，以提高鲁棒性并加速训练。尽管是最小的模型，FlowState优于所有其他模型，并且在GIFT-ZS和Chronos-ZS基准测试中达到了最先进水平。消融研究证实了其组件的有效性，我们展示了其在线适应不同输入采样率的独特能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [234] [CUPID: Evaluating Personalized and Contextualized Alignment of LLMs from Interactions](https://arxiv.org/abs/2508.01674)
> *CUPID：从交互中评估LLM的个性化和情境化对齐*

*Tae Soo Kim, Yoonjoo Lee, Yoonah Park, Jiho Kim, Young-Ho Kim, Juho Kim* | **Category: cs.AI, cs.CL, cs.HC** | **Updated: 2025-08-07**

**Keywords:** LLM个性化, 情境化对齐, 用户偏好, CUPID基准, 多轮交互

**Comment:** 

> **TL;DR:** CUPID是一个新的基准，用于评估LLM从多轮交互中推断用户情境化偏好的能力。结果显示，当前最先进的LLM在此方面表现不佳，凸显了LLM在情境化个性化交互方面的进步需求。

**AI_Comments:** CUPID基准的创新之处在于它关注LLM在动态和情境化偏好学习方面的能力，这与传统静态偏好假设形成对比。它提供了一个急需的工具来评估LLM在实际用户交互中更复杂、更真实的对齐挑战。其评估结果清晰地指出了当前SOTA LLM的显著局限性，为未来研究指明了方向，即如何使LLM更好地理解和适应用户不断变化的上下文偏好。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM的个性化通常假设用户偏好是静态且全局的，但这与人类动态且依赖情境的偏好不符。LLM需要能够从用户交互中推断和应用情境化偏好以实现对齐，因此需要一个评估这种能力的基准。

**Method:** 研究引入了CUPID基准，包含756个人工策划的用户与LLM聊天助手的交互会话历史。每个会话中，用户在特定情境下提出请求并通过多轮反馈表达偏好。CUPID评估LLM能否根据新的用户请求和之前的交互会话，推断出相关偏好并生成满足该偏好的响应。研究使用CUPID评估了10个开源和专有LLM。

**Result:** 评估结果显示，最先进的LLM难以从多轮交互中推断用户偏好，并且无法辨别哪些先前的上下文与新请求相关，其准确率低于50%，召回率低于65%。

**Conclusion:** 研究强调，LLM需要提升其在情境化个性化交互方面的能力，并提出CUPID作为推动这些改进的资源。

> **ai_Abstract:** 当前LLM的个性化未能充分考虑用户偏好的动态性和情境依赖性。为了解决这一问题，本研究提出了CUPID，一个包含756个真实人机交互会话历史的基准，旨在评估LLM从多轮交互中推断并应用用户情境化偏好的能力。通过对10个主流LLM的评估，发现现有模型在理解多轮偏好和识别相关上下文方面表现不佳（准确率<50%，召回率<65%）。这表明LLM在实现更情境化的个性化交互方面仍需重大改进，CUPID可作为推动此项进展的重要资源。

> **摘要翻译:** 大型语言模型（LLM）的个性化通常假设用户持有静态偏好，并在所有任务中普遍体现。然而，在现实中，人类的偏好是动态的，并随情境而变化。当用户在各种情境下与LLM互动时，他们自然会揭示其情境化偏好，模型必须推断并应用于未来的情境中以确保对齐。为了评估这一点，我们引入了CUPID，这是一个包含756个人工策划的用户与基于LLM的聊天助手之间交互会话历史的基准。在每个交互会话中，用户在特定情境中提出请求，并通过多轮反馈表达其偏好。给定一个新的用户请求和之前的交互会话，我们的基准评估LLM能否推断出与该请求相关的偏好并生成满足该偏好的响应。通过CUPID，我们评估了10个开源和专有LLM，结果显示最先进的LLM难以从多轮交互中推断偏好，并且无法辨别哪些先前的上下文与新请求相关——准确率低于50%，召回率低于65%。我们的工作强调了提升LLM能力以实现更具情境化个性化交互的必要性，并提出CUPID作为推动这些改进的资源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [239] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
> *使用深度学习对地表臭氧模拟器进行不确定性量化*

*Kelsey Doerksen, Yuliya Marchetti, Steven Lu, Kevin Bowman, James Montgomery, Kazuyuki Miyazaki, Yarin Gal, Freddie Kalaitzis* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 不确定性量化, 地表臭氧, 深度学习, U-Net, 空气污染

**Comment:** 

> **TL;DR:** 该研究使用不确定性感知的U-Net架构，结合贝叶斯和分位数回归方法，对地表臭氧模拟器的偏差进行不确定性量化，以提高空气污染模型的可解释性，并辅助决策。

**AI_Comments:** 该论文的创新之处在于将不确定性量化方法（贝叶斯和分位数回归）整合到深度学习U-Net架构中，以解决空气污染模拟器（特别是地表臭氧）中长期存在的缺乏可解释性问题。这对于将深度学习模型应用于需要高置信度决策（如公共卫生政策）的领域至关重要。其重要性在于，通过提供偏差估计的置信区间，提高了模型的可靠性和实用性，有助于更好地理解模型误差来源，并优化数据同化过程。

<details>
  <summary>Details</summary>

**Motivation:** 全球94%的人口暴露在不安全的空气污染水平下，其中地表臭氧（O3）难以建模。传统的物理模型在与人类健康影响相关的尺度上实用性不足。虽然深度学习模拟器在捕捉复杂气候模式方面前景广阔，但缺乏支持关键决策（如政策变化和公共健康措施）所需的可解释性。

**Method:** 研究实施了一个不确定性感知的U-Net架构，使用贝叶斯和分位数回归方法来预测多模型多组分化学数据同化（MOMO-Chem）模型的地表臭氧残差（偏差）。

**Result:** 研究展示了其技术在2019年6月北美和欧洲区域偏差估计中的能力。它突出了两种不确定性量化（UQ）方法之间的UQ分数，辨别出哪些地面站点是MOMO-Chem偏差校正的最佳和次优候选，并评估了土地利用信息在地表臭氧残差建模中的影响。

**Conclusion:** 该研究成功地为深度学习驱动的地表臭氧模拟器引入了不确定性量化能力，提高了模型的可靠性和决策支持潜力，特别是在评估偏差校正和土地利用信息影响方面。

> **ai_Abstract:** 该研究旨在解决地表臭氧建模中深度学习模拟器缺乏可解释性的问题。通过引入一个不确定性感知的U-Net架构，结合贝叶斯和分位数回归方法，该研究能够预测并量化MOMO-Chem模型地表臭氧残差的偏差。实验结果表明，该方法能够有效进行区域偏差估计，并有助于识别最佳地面站点进行偏差校正，同时评估土地利用信息对模型的影响，从而提升了空气污染模型的可信度和实用性。

> **摘要翻译:** 空气污染是全球性危害，截至2023年，全球94%的人口暴露在不安全的污染水平下。地表臭氧（O3）是一种重要的污染物，其趋势的驱动因素难以建模，传统的基于物理的模型在与人类健康影响相关的尺度上的实际应用中存在不足。基于深度学习的模拟器在捕捉复杂气候模式方面显示出前景，但总体上缺乏支持政策变化和公共卫生措施等关键决策所需的可解释性。我们实施了一个不确定性感知的U-Net架构，使用贝叶斯和分位数回归方法来预测多模型多组分化学数据同化（MOMO-Chem）模型的地表臭氧残差（偏差）。我们展示了我们的技术在2019年6月北美和欧洲区域偏差估计方面的能力。我们强调了我们两种不确定性量化（UQ）方法之间的UQ分数，并辨别出哪些地面站点是MOMO-Chem偏差校正的最佳和次优候选，并评估了土地利用信息在地表臭氧残差建模中的影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [240] [Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction](https://arxiv.org/abs/2508.05294)
> *迈向具身智能体AI：LLM和VLM驱动的机器人自主性与交互的综述与分类*

*Sahar Salimpour, Lei Fu, Farhad Keramat, Leonardo Militano, Giovanni Toffetti, Harry Edelman, Jorge Peña Queralta* | **Category: cs.AI, cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** LLM, VLM, 机器人自主性, 具身智能体, 综述, 分类

**Comment:** 

> **TL;DR:** 本综述论文探讨了LLM和VLM驱动的机器人自主性，重点关注具身智能体AI的架构，并提出了模型集成方法的分类法。

**AI_Comments:** 这篇论文对一个快速发展且至关重要的领域——大型基础模型与机器人系统集成以实现具身智能体AI——进行了及时而全面的综述。其创新之处在于提出了分类法，并纳入了非传统来源（社区项目、工业框架）以捕捉该领域的动态性质。这种广泛的范围和结构化分析对于理解当前趋势和未来机器人自主性发展方向至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型（如LLM和VLM）的最新进展为机器人自主性和人机交互带来了新方法，催生了具身智能体AI。本论文旨在对这些快速发展的具身智能体应用和架构进行综述和分类。

**Method:** 本综述论文回顾了LLM和VLM驱动的机器人自主性和交互方面的进展，特别关注智能体应用和架构。它涵盖了同行评审研究以及社区驱动项目、ROS包和工业框架。论文提出了一种用于分类模型集成方法的分类法，并对智能体在不同解决方案中扮演的角色进行了比较分析。

**Result:** 本论文提出了一种分类法，用于分类具身智能体AI中的模型集成方法。它还对智能体在当前文献中不同解决方案（包括GPT风格接口、协调器、规划器、感知执行器和通用接口）中扮演的角色进行了比较分析。

**Conclusion:** 本论文对LLM和VLM驱动的机器人自主性与交互，特别是具身智能体AI架构，进行了全面的综述和分类。通过提出分类法并分析智能体的多样化角色，包括来自新兴社区和工业趋势的见解，它为理解这一快速发展的领域提供了结构化的认识。

> **ai_Abstract:** 本综述论文探讨了大型语言模型（LLMs）和视觉-语言模型（VLMs）如何推动机器人自主性和交互，旨在迈向具身智能体AI。它考察了AI智能体作为协调器、规划器或通用接口的应用，使机器人能够理解自然语言并执行复杂任务。论文提出了一种分类法来分类模型集成方法，并分析了智能体的多样化角色，同时纳入了学术研究和新兴的社区及工业趋势。

> **摘要翻译:** 基础模型，包括大型语言模型（LLMs）和视觉-语言模型（VLMs），最近为机器人自主性和人机接口带来了新颖的方法。与此同时，视觉-语言-动作模型（VLAs）或大型行为模型（BLMs）正在提高机器人系统的灵活性和能力。本综述论文侧重于那些正在迈向智能体应用和架构的进展。这包括探索GPT风格工具接口的初步努力，以及更复杂的系统，其中AI智能体充当协调器、规划器、感知执行器或通用接口。这种智能体架构允许机器人对自然语言指令进行推理、调用API、规划任务序列或协助操作和诊断。除了同行评审的研究，鉴于该领域快速发展的性质，我们强调并收录了显示新兴趋势的社区驱动项目、ROS包和工业框架。我们提出了一种分类法来对模型集成方法进行分类，并对智能体在当今文献中不同解决方案中扮演的角色进行了比较分析。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [241] [VLM4D: Towards Spatiotemporal Awareness in Vision Language Models](https://arxiv.org/abs/2508.02095)
> *VLM4D：迈向视觉语言模型的时空感知能力*

*Shijie Zhou, Alexander Vilesov, Xuehai He, Ziyu Wan, Shuwang Zhang, Aditya Nagachandra, Di Chang, Dongdong Chen, Xin Eric Wang, Achuta Kadambi* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-06**

**Keywords:** 时空感知, 视觉语言模型, 基准测试, 动态环境, 4D特征场

**Comment:** 

> **TL;DR:** VLM4D引入了一个新的基准测试，用于评估视觉语言模型（VLMs）在时空推理方面的能力，发现现有VLMs在这方面存在显著缺陷，并提出了改进方向。

**AI_Comments:** 本文创新性地提出了VLM4D，这是首个专门针对视觉语言模型时空推理能力的基准测试，填补了该领域的一个空白。通过揭示现有VLMs在动态时空理解方面的显著局限性，并提供具体的分析，该研究为未来VLM的发展指明了方向。同时，探索4D特征场重建和监督微调等解决方案，也为提升模型性能提供了有价值的参考。这项工作对于推动VLM在更复杂的现实世界动态场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉语言模型（VLMs）在理解动态时空交互方面存在根本性限制，尤其是在跟踪和推理物体运动、旋转和视角变化等对现实世界动态理解至关重要的能力上，这与人类的能力形成鲜明对比。

**Method:** 本文引入了VLM4D，这是第一个专门设计用于评估VLMs时空推理能力的基准测试。该基准包含多样化的真实世界和合成视频，并配有精心策划的问答对，强调平移和旋转运动、视角感知和运动连续性。此外，还探索了利用4D特征场重建和有针对性的时空监督微调等方法来增强时空理解。

**Result:** 通过对最先进的开源和闭源VLMs进行全面评估，研究发现与人类基线相比存在显著的性能差距，突出了现有模型的根本性缺陷。广泛分析表明，VLMs尤其难以整合多个视觉线索和保持时间连贯性。所探索的4D特征场重建和时空监督微调方法被证明在增强时空理解方面是有效的。

**Conclusion:** 本研究旨在鼓励更深入地探索改进VLMs的空间和时间基础，为动态环境中更强大、更可靠的视觉智能铺平道路。现有VLMs在时空推理方面存在显著不足，但通过特定技术可以有效提升其能力。

> **ai_Abstract:** 本文介绍了VLM4D，一个用于评估视觉语言模型（VLMs）时空推理能力的基准测试。研究指出当前VLMs在理解动态时空交互方面存在显著不足，无法像人类一样有效处理物体运动、旋转和视角变化。通过对现有VLMs进行评估，发现它们与人类表现存在巨大差距，尤其在整合多视觉线索和保持时间连贯性方面表现不佳。论文还探索了利用4D特征场重建和时空监督微调等方法来提升VLMs的时空理解能力，并证明了其有效性，旨在推动未来VLM在动态环境中的发展。

> **摘要翻译:** 视觉语言模型（VLMs）在整合语言和视觉推理方面展现出卓越能力，但在理解动态时空交互方面仍存在根本性限制。人类可以毫不费力地跟踪和推理物体的运动、旋转和视角变化——这些能力对于稳健地理解动态现实世界至关重要，但在当前的VLMs中却明显缺乏。在本文中，我们引入了VLM4D，这是第一个专门设计用于评估VLMs时空推理能力的基准测试。我们的基准包含多样化的真实世界和合成视频，并配有精心策划的问答对，强调平移和旋转运动、视角感知和运动连续性。通过对最先进的开源和闭源VLMs进行全面评估，我们发现与人类基线相比存在显著的性能差距，突出了现有模型的根本性缺陷。广泛分析表明，VLMs尤其难以整合多个视觉线索和保持时间连贯性。我们进一步探索了有前景的方向，例如利用4D特征场重建和有针对性的时空监督微调，证明了它们在增强时空理解方面的有效性。我们的工作旨在鼓励更深入地探索改进VLMs的空间和时间基础，为动态环境中更强大、更可靠的视觉智能铺平道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [246] [Leveraging Deep Learning for Physical Model Bias of Global Air Quality Estimates](https://arxiv.org/abs/2508.04886)
> *利用深度学习纠正全球空气质量估计中的物理模型偏差*

*Kelsey Doerksen, Yuliya Marchetti, Kevin Bowman, Steven Lu, James Montgomery, Yarin Gal, Freddie Kalaitzis, Kazuyuki Miyazaki* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 深度学习, 空气质量, 臭氧, 模型偏差, 卷积神经网络

**Comment:** 

> **TL;DR:** 本文利用二维卷积神经网络来估计地表臭氧物理模型（MOMO-Chem）的残差（即模型偏差），并在北美和欧洲展示了其潜力，优于传统机器学习方法，有助于改善环境政策。

**AI_Comments:** 该论文创新性地将深度学习（2D CNN）应用于物理模型偏差的估计，这对于提高全球空气质量预测的准确性具有重要意义。通过纠正物理模型的系统性偏差，可以显著提升模型的实用性。此外，引入高分辨率土地利用信息进一步增强了模型的性能。这项研究的成果不仅有助于科学理解，还为制定更有效的环境政策提供了数据支持，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 空气污染是人类疾病和过早死亡的最大环境风险因素，其中地表臭氧的建模仍面临挑战，特别是在与人类健康影响相关的尺度上，全球臭氧趋势的驱动因素在这些尺度上很大程度上未知，限制了基于物理模型的实际应用。

**Method:** 研究采用基于二维卷积神经网络（2D CNN）的架构来估计地表臭氧MOMO-Chem模型的残差（即模型偏差）。该方法与传统机器学习方法进行了比较，并评估了结合高分辨率卫星图像的土地利用信息对改善模型估计的影响。

**Result:** 该技术在北美和欧洲展示了其潜力，与传统机器学习方法相比，它能更好地捕捉物理模型残差。研究还评估了结合高分辨率卫星图像的土地利用信息对改善模型估计的影响。

**Conclusion:** 研究结果可以提高我们对影响城市尺度臭氧偏差因素的科学理解，从而用于改进环境政策。

> **ai_Abstract:** 本研究旨在解决全球空气质量模型中地表臭氧预测的挑战，特别是其物理模型偏差。作者提出了一种利用二维卷积神经网络（2D CNN）来估计MOMO-Chem物理模型残差（即模型偏差）的方法。该方法在北美和欧洲地区进行了验证，结果表明其在捕捉物理模型残差方面优于传统的机器学习方法。研究还探讨了整合高分辨率卫星图像中的土地利用信息对模型估计的改进作用。最终，本文强调了其研究成果如何增进对影响城市尺度臭氧偏差因素的科学理解，并为环境政策的制定提供依据。

> **摘要翻译:** 空气污染是全球人类疾病和过早死亡的最大环境风险因素，导致2019年超过600万人过早死亡。目前，模拟最重要的空气污染物之一——地表臭氧——仍然面临挑战，特别是在与人类健康影响相关的尺度上，全球臭氧趋势在这些尺度上的驱动因素在很大程度上未知，这限制了基于物理模型的实际应用。我们采用基于二维卷积神经网络的架构来估计地表臭氧MOMO-Chem模型的残差，即模型偏差。我们在北美和欧洲展示了这项技术的潜力，强调了其与传统机器学习方法相比，能够更好地捕捉物理模型残差的能力。我们评估了结合高分辨率卫星图像的土地利用信息对改善模型估计的影响。重要的是，我们讨论了我们的研究结果如何提高我们对影响城市尺度臭氧偏差因素的科学理解，这可用于改进环境政策。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [247] [VS-LLM: Visual-Semantic Depression Assessment based on LLM for Drawing Projection Test](https://arxiv.org/abs/2508.05299)
> *VS-LLM：基于LLM的绘画投射测试视觉-语义抑郁评估*

*Meiqi Wu, Yaxuan Kang, Xuchen Li, Shiyu Hu, Xiaotang Chen, Yunfeng Kang, Weiqiang Wang, Kaiqi Huang* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 绘画投射测试, 抑郁评估, 大型语言模型, 视觉-语义, PPAT

**Comment:** 

> **TL;DR:** 本文提出了一种名为VS-LLM的视觉-语义方法，利用大型语言模型（LLM）自动化绘画投射测试（DPT）中的抑郁评估，解决了传统DPT解释耗时且依赖经验的问题，并在实验中实现了相较于心理学家评估方法17.6%的提升。

**AI_Comments:** 该论文提出了一种利用LLM自动化心理绘画投射测试（DPT）评估的方法，解决了传统DPT耗时且主观性强的问题，具有重要的实践意义。其创新之处在于将视觉-语义分析与LLM结合，以适应DPT对整体评估而非细节识别的侧重。17.6%的性能提升表明了该方法的潜力，为大规模心理健康筛查提供了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 绘画投射测试（DPT）是艺术疗法中的重要工具，但其解读费力且高度依赖心理学家的经验。特别是在“一个人从树上摘苹果（PPAT）”主题的速写中，由于时间限制和禁止口头提醒，导致绘画精度低且缺乏细节描绘。为了解决这些挑战，实现大规模自动化DPT，本文提出了新的方法。

**Method:** 本文提出了一种有效的识别方法，以支持心理学家进行大规模自动化DPT。具体地，提出了基于LLM的视觉-语义抑郁评估方法（VS-LLM）。主要工作包括：1）提供一个用于抑郁评估的PPAT速写自动化分析实验环境；2）提供VS-LLM方法。

**Result:** 实验结果表明，本文提出的方法比心理学家评估方法提高了17.6%。

**Conclusion:** 这项工作有望促进基于PPAT速写元素识别的精神状态评估研究。

> **ai_Abstract:** 本文针对绘画投射测试（DPT）中“一个人从树上摘苹果（PPAT）”速写解释耗时且依赖经验的问题，提出了一种名为VS-LLM的视觉-语义抑郁评估方法，该方法基于大型语言模型（LLM）实现DPT的自动化分析。研究构建了自动化分析的实验环境，并设计了VS-LLM方法。实验结果显示，VS-LLM相较于心理学家的评估方法，性能提升了17.6%，有望推动基于速写元素识别的精神状态评估研究。

> **摘要翻译:** 绘画投射测试（DPT）是艺术疗法中的重要工具，心理学家可以通过速写评估参与者的心理状态。具体来说，通过以“一个人从树上摘苹果（PPAT）”为主题的速写，可以揭示参与者是否存在抑郁等心理状态。与量表相比，DPT可以丰富心理学家对个体心理状态的理解。然而，PPAT的解释费力且依赖于心理学家的经验。为了解决这个问题，我们提出了一种有效的识别方法，以支持心理学家进行大规模自动化DPT。与传统的速写识别不同，DPT更侧重于速写的整体评估，例如颜色使用和空间利用。此外，PPAT有时间限制并禁止口头提醒，导致绘画精度低且缺乏详细描绘。为了应对这些挑战，我们提出了以下努力：(1) 为抑郁评估提供PPAT速写自动化分析的实验环境；(2) 提供基于LLM的视觉-语义抑郁评估（VS-LLM）方法；(3) 实验结果表明，我们的方法比心理学家评估方法提高了17.6%。我们预计这项工作将有助于基于PPAT速写元素识别的精神状态评估研究。我们的数据集和代码可在https://github.com/wmeiqi/VS-LLM获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [248] [ByteGen: A Tokenizer-Free Generative Model for Orderbook Events in Byte Space](https://arxiv.org/abs/2508.02247)
> *ByteGen：一种用于字节空间中订单簿事件的无分词器生成模型*

*Yang Li, Zhi Chen* | **Category: cs.AI, cs.CE, cs.LG, q-fin.CP, q-fin.TR** | **Updated: 2025-08-07**

**Keywords:** 生成模型, 订单簿, 字节空间, 高频数据, 金融建模

**Comment:** 

> **TL;DR:** ByteGen是一种新型的无分词器生成模型，直接在原始字节流上操作，用于高频限价订单簿事件的建模，解决了传统方法中分词和特征工程的局限性，并成功复现了金融市场的关键风格化事实。

**AI_Comments:** 该论文的创新之处在于提出了一个完全“无分词器”的生成模型ByteGen，直接在原始字节流上进行操作，这彻底消除了传统分词方法在处理高精度金融数据时引入的偏差和信息损失。通过采用字节级的处理方式和高效的打包数据表示，ByteGen提供了一个端到端、更忠实于原始数据特性的LOB建模框架。其适配H-Net架构并利用动态分块机制来发现市场消息固有结构的能力，是方法上的一个亮点，展现了在不依赖预定义规则下学习复杂模式的潜力。这项工作对于高频金融数据建模领域具有重要意义，为市场模拟、策略回溯测试等应用提供了新的视角和更可靠的基础。

<details>
  <summary>Details</summary>

**Motivation:** 高频限价订单簿（LOB）动态的生成建模是量化金融领域一个关键但尚未解决的挑战，对于稳健的市场模拟和策略回溯测试至关重要。现有方法受限于简化的随机假设，或依赖于通过离散化和分箱影响金融数据高精度数值性质的分词方案。

**Method:** 我们引入了ByteGen，一个直接在LOB事件的原始字节流上操作的新型生成模型。该方法将问题视为自回归的下一字节预测任务，并设计了一种紧凑高效的32字节打包二进制格式来无损表示市场消息。通过改编H-Net架构（一种混合Mamba-Transformer模型），使用动态分块机制来发现市场消息的固有结构，从而完全消除了特征工程和分词。

**Result:** ByteGen在超过3400万个CME比特币期货事件上进行训练，成功复现了金融市场的关键风格化事实，生成了逼真的价格分布、厚尾收益和突发事件时序。在标准市场质量指标上取得了有竞争力的性能。

**Conclusion:** 直接从字节空间学习是建模复杂金融系统的一种有前途且高度灵活的范式，可以在不引入分词偏差的情况下，在标准市场质量指标上取得有竞争力的性能。

> **ai_Abstract:** ByteGen是一种新颖的生成模型，旨在解决高频限价订单簿（LOB）动态建模中的挑战。它通过直接在LOB事件的原始字节流上操作，并将其视为自回归的下一字节预测任务，从而避免了传统方法中分词和特征工程的局限性。该模型采用高效的32字节打包二进制格式表示数据，并基于H-Net架构，通过动态分块机制学习市场结构。ByteGen在CME比特币期货数据上的评估表明，它能够成功复现金融市场的关键风格化事实，如逼真的价格分布、厚尾收益和突发事件时序，证明了直接从字节空间学习在建模复杂金融系统方面的有效性和灵活性。

> **摘要翻译:** 高频限价订单簿（LOB）动态的生成建模是量化金融领域一个关键但尚未解决的挑战，对于稳健的市场模拟和策略回溯测试至关重要。现有方法通常受限于简化的随机假设，或者，就现代深度学习模型如Transformer而言，依赖于通过离散化和分箱影响金融数据高精度数值性质的分词方案。为了解决这些限制，我们引入了ByteGen，一个新型的生成模型，它直接在LOB事件的原始字节流上操作。我们的方法将问题视为自回归的下一字节预测任务，为此我们设计了一种紧凑高效的32字节打包二进制格式来无损表示市场消息。我们工作的核心创新是完全消除了特征工程和分词，使模型能够从其最基本的表示中学习市场动态。我们通过改编H-Net架构实现了这一点，H-Net是一个混合Mamba-Transformer模型，它使用动态分块机制来发现市场消息的固有结构，而无需预定义规则。我们的主要贡献是：1）第一个端到端、字节级的LOB建模框架；2）一种高效的打包数据表示；3）对高频数据的全面评估。ByteGen在超过3400万个CME比特币期货事件上进行训练，成功复现了金融市场的关键风格化事实，生成了逼真的价格分布、厚尾收益和突发事件时序。我们的研究结果表明，直接从字节空间学习是建模复杂金融系统的一种有前途且高度灵活的范式，可以在不引入分词偏差的情况下，在标准市场质量指标上取得有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [253] [Adversarial Attacks and Defenses on Graph-aware Large Language Models (LLMs)](https://arxiv.org/abs/2508.04894)
> *图感知大型语言模型 (LLMs) 的对抗性攻击与防御*

*Iyiola E. Olatunji, Franziska Boenisch, Jing Xu, Adam Dziedzic* | **Category: cs.AI, cs.CR, cs.SI** | **Updated: 2025-08-06**

**Keywords:** 对抗性攻击, 图感知LLMs, 鲁棒性, GALGUARD, 脆弱性

**Comment:** 

> **TL;DR:** 本文首次探讨了图感知大型语言模型 (LLMs) 在对抗性攻击下的脆弱性，通过现有图攻击方法和发现新攻击面来评估，并提出了一个端到端防御框架GALGUARD。

**AI_Comments:** 本文在图感知LLMs的鲁棒性研究领域迈出了重要一步，填补了现有研究空白。其创新之处在于不仅利用了现有的图攻击方法，还发现了一种针对LLAGA模型的新型攻击面。此外，提出的GALGUARD防御框架为提升图感知LLMs的安全性提供了实用的解决方案，对未来LLM与图数据融合应用的安全发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型 (LLMs) 越来越多地与图结构数据集成，以改善节点分类等任务性能。然而，这种集成在对抗性攻击下的鲁棒性尚未被探索。

**Method:** 研究人员首先利用现有针对图模型的对抗性攻击方法（包括投毒攻击和规避攻击）来探索图感知LLMs的漏洞。他们在LLAGA和GRAPHPROMPTER这两种代表性模型上进行了实验。此外，他们发现LLAGA存在一个新的攻击面，即攻击者可以通过在节点序列模板中注入恶意节点作为占位符来严重降低其性能。最后，他们提出了一个端到端防御框架GALGUARD，该框架结合了一个基于LLM的特征校正模块来缓解特征级扰动，并适配了GNN防御来抵御结构性攻击。

**Result:** 系统的分析揭示了图编码中的某些设计选择可以提高攻击成功率。具体发现包括：(1) LLAGA中的节点序列模板增加了其脆弱性；(2) GRAPHPROMPTER中使用的GNN编码器表现出更强的鲁棒性；(3) 两种方法都容易受到难以察觉的特征扰动攻击。

**Conclusion:** 本文首次探索了图感知LLMs的对抗性攻击漏洞，揭示了特定设计选择对其鲁棒性的影响，并提出了一个名为GALGUARD的端到端防御框架来增强其安全性。

> **ai_Abstract:** 本文首次系统性地探索了图感知大型语言模型 (LLMs) 在对抗性攻击下的脆弱性。研究人员利用现有的图攻击方法（如投毒和规避攻击）在LLAGA和GRAPHPROMPTER模型上进行评估，并发现LLAGA模型中存在一种新的攻击面，即通过注入恶意节点降低其性能。分析结果表明，图编码的设计选择会影响攻击成功率，其中LLAGA的节点序列模板增加了脆弱性，而GRAPHPROMPTER的GNN编码器更具鲁棒性，但两者都易受特征扰动攻击。为应对这些挑战，论文提出了一个端到端防御框架GALGUARD，它结合了基于LLM的特征校正和GNN防御，以提高图感知LLMs的鲁棒性。

> **摘要翻译:** 大型语言模型（LLMs）正越来越多地与图结构数据集成，用于节点分类等任务，这是一个传统上由图神经网络（GNNs）主导的领域。虽然这种集成利用丰富的关系信息来提高任务性能，但它们对抗对抗性攻击的鲁棒性仍未被探索。我们迈出了探索图感知LLMs脆弱性的第一步，通过利用现有为基于图模型量身定制的对抗性攻击方法，包括投毒（训练时攻击）和规避（测试时攻击），在LLAGA（Chen et al. 2024）和GRAPHPROMPTER（Liu et al. 2024）这两种代表性模型上进行。此外，我们发现了LLAGA的一个新攻击面，攻击者可以将恶意节点作为占位符注入到节点序列模板中，从而严重降低其性能。我们的系统分析表明，图编码中的某些设计选择可以增强攻击成功率，具体发现是：(1) LLAGA中的节点序列模板增加了其脆弱性；(2) GRAPHPROMPTER中使用的GNN编码器表现出更高的鲁棒性；(3) 两种方法都仍然容易受到难以察觉的特征扰动攻击。最后，我们提出了一个端到端的防御框架GALGUARD，该框架结合了一个基于LLM的特征校正模块来缓解特征级扰动，并适配了GNN防御以抵御结构性攻击。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [254] [Estimating Musical Surprisal from Audio in Autoregressive Diffusion Model Noise Spaces](https://arxiv.org/abs/2508.05306)
> *在自回归扩散模型噪声空间中估计音频中的音乐意外性*

*Mathias Rose Bjare, Stefan Lattner, Gerhard Widmer* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 音乐意外性, 自回归扩散模型, 信息内容, 音频分析, 扩散模型

**Comment:** 

> **TL;DR:** 本文研究了使用自回归扩散模型（ADMs）计算信息内容（IC）来建模音乐预期和意外性的有效性，并发现其在描述数据和捕捉意外性方面优于GIVT。

**AI_Comments:** 本文的创新之处在于将自回归扩散模型（ADMs）引入音乐意外性估计领域，并探索了不同扩散过程噪声水平对结果的影响。这为音乐信息检索和音乐理解提供了新的工具和视角。其重要性在于证明了ADMs在处理复杂音频数据和捕捉细微音乐特征方面的潜力，可能为未来的音乐分析应用开辟道路。

<details>
  <summary>Details</summary>

**Motivation:** 最近，生成式无限词汇Transformer（GIVT）的预测信息内容（IC）被用于建模音频中的音乐预期和意外性。本文旨在研究使用自回归扩散模型（ADMs）计算的IC在建模音乐意外性方面的有效性。

**Method:** 研究人员使用自回归扩散模型（ADMs）计算信息内容（IC），并将其与基于两种不同扩散常微分方程（ODEs）的模型进行比较。他们通过负对数似然评估了模型描述数据的能力。此外，他们通过两个任务评估了扩散模型IC捕捉意外性方面的有效性：1) 捕捉单音音高意外性，以及 2) 检测多轨音频中的段落边界。他们还假设不同扩散过程噪声水平下估计的意外性对应于不同音频粒度下的音乐和音频特征的意外性，并对此进行了测试。

**Result:** 经验结果表明，基于两种不同扩散常微分方程（ODEs）的模型的IC估计在描述多样数据方面（以负对数似然计）优于GIVT。在捕捉单音音高意外性和检测多轨音频段落边界这两个任务中，扩散模型的性能达到或超过了GIVT。研究还发现，对于适当的噪声水平，所研究的音乐意外性任务的结果有所改善。

**Conclusion:** 本文得出结论，使用自回归扩散模型（ADMs）计算的信息内容（IC）是建模音乐预期和意外性的有效方法，其性能在某些方面优于GIVT，并且在不同噪声水平下能更好地捕捉音乐意外性。

> **ai_Abstract:** 本文探讨了使用自回归扩散模型（ADMs）计算信息内容（IC）来建模音乐意外性的有效性，作为GIVT的替代方案。研究表明，ADMs在描述多样数据方面表现更好，并且在捕捉单音音高意外性和检测多轨音频段落边界的任务中，其性能与GIVT相当或更优。此外，研究发现通过在适当的噪声水平下估计意外性，可以提高音乐意外性任务的结果，这表明不同噪声水平的意外性对应于不同音频粒度的音乐特征。

> **摘要翻译:** 最近，生成式无限词汇Transformer（GIVT）的预测信息内容（IC）已被用于建模音频中的音乐预期和意外性。我们研究了使用自回归扩散模型（ADMs）计算的IC来建模这种有效性。我们经验性地表明，基于两种不同扩散常微分方程（ODEs）的模型在负对数似然方面，其IC估计比GIVT能更好地描述多样数据。我们通过检查两个任务来评估扩散模型IC在捕捉意外性方面的有效性：(1) 捕捉单音音高意外性，和 (2) 检测多轨音频中的段落边界。在这两个任务中，扩散模型的性能都达到或超过了GIVT。我们假设在不同扩散过程噪声水平下估计的意外性对应于不同音频粒度下存在的音乐和音频特征的意外性。通过验证我们的假设，我们发现，对于适当的噪声水平，所研究的音乐意外性任务的结果有所改善。代码已在github.com/SonyCSLParis/audioic上提供。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [255] [VeOmni: Scaling Any Modality Model Training with Model-Centric Distributed Recipe Zoo](https://arxiv.org/abs/2508.02317)
> *VeOmni：使用以模型为中心的分布式配方库扩展任意模态模型训练*

*Qianli Ma, Yaowei Zheng, Zhelun Shi, Zhongkai Zhao, Bin Jia, Ziyue Huang, Zhiqi Lin, Youjie Li, Jiacheng Yang, Yanghua Peng, Zhi Zhang, Xin Liu* | **Category: cs.AI, cs.CL, cs.DC** | **Updated: 2025-08-07**

**Keywords:** 全模态LLMs, 分布式训练, 3D并行, 模型可扩展性, VeOmni

**Comment:** 

> **TL;DR:** VeOmni是一个高效的训练框架，通过解耦通信和计算，实现3D并行，显著提升了全模态大型语言模型（LLMs）的训练效率和可扩展性。

**AI_Comments:** VeOmni的创新之处在于其“以模型为中心”的分布式配方，成功地将通信与计算解耦，并实现了高效的3D并行，这对于处理全模态LLMs的异构性至关重要。它通过提供灵活的配置接口降低了新模态集成的工程开销，解决了当前全模态模型训练中的核心痛点，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有框架在训练全模态LLMs时，由于模型定义与并行逻辑耦合，导致可扩展性有限和工程开销大，难以有效处理异构模型架构。

**Method:** 本文提出了VeOmni，一个模块化且高效的训练框架，旨在加速全模态LLMs的开发。VeOmni引入了以模型为中心的分布式配方，将通信与计算解耦，从而在全模态LLMs上实现高效的3D并行。它还具有灵活的配置接口，支持以最少的代码更改无缝集成新的模态。

**Result:** 使用VeOmni，一个拥有300亿参数的全模态专家混合（MoE）模型可以通过3D并行在128个GPU上以超过2,800 tokens/sec/GPU的吞吐量进行训练，并扩展到160K的上下文长度。

**Conclusion:** VeOmni展示了其在训练大型全模态LLMs方面的卓越效率和可扩展性。

> **ai_Abstract:** 本文提出了VeOmni，一个专门为加速全模态大型语言模型（LLMs）训练而设计的模块化高效框架。针对现有框架模型定义与并行逻辑耦合导致可扩展性差的问题，VeOmni引入了以模型为中心的分布式配方，解耦通信与计算，实现了高效的3D并行。此外，它还提供灵活的配置接口以支持新模态的集成。实验结果表明，VeOmni显著提升了全模态MoE模型（30B参数）的训练吞吐量和上下文长度扩展能力，验证了其在训练大型全模态LLMs方面的优越效率和可扩展性。

> **摘要翻译:** 近期大型语言模型（LLMs）的进展推动了全模态理解和生成方面的显著进步。然而，由于处理不同模态所需的异构模型架构，训练全模态LLMs仍然是一个重大挑战，这需要复杂的系统设计以实现高效的大规模训练。现有框架通常将模型定义与并行逻辑纠缠在一起，导致可扩展性有限，并为端到端全模态训练带来大量的工程开销。我们提出了VeOmni，一个模块化且高效的训练框架，旨在加速全模态LLMs的开发。VeOmni引入了以模型为中心的分布式配方，将通信与计算解耦，从而在全模态LLMs上实现高效的3D并行。VeOmni还具有灵活的配置接口，支持以最少的代码更改无缝集成新的模态。使用VeOmni，一个拥有300亿参数的全模态专家混合（MoE）模型可以通过3D并行在128个GPU上以超过2,800 tokens/sec/GPU的吞吐量进行训练，并扩展到160K的上下文长度，展示了其在训练大型全模态LLMs方面的卓越效率和可扩展性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [260] [Revealing Temporal Label Noise in Multimodal Hateful Video Classification](https://arxiv.org/abs/2508.04900)
> *揭示多模态仇恨视频分类中的时间标签噪声*

*Shuonan Yang, Tailin Chen, Rahul Singh, Jiangbei Yue, Jianbo Jiao, Zeyu Fu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-06**

**Keywords:** 仇恨视频分类, 时间标签噪声, 多模态, 细粒度分析

**Comment:** 

> **TL;DR:** 本文研究了多模态仇恨视频分类中由于粗粒度视频级标注引入的时间标签噪声，并发现其显著影响模型性能，强调需要时间感知的模型。

**AI_Comments:** 本文识别并量化了多模态仇恨视频分类中一个关键但常被忽视的问题——时间标签噪声。其创新之处在于通过细粒度分析揭示了这种噪声对模型性能的负面影响，并强调了时间感知模型的重要性，这对于未来构建更准确、更具解释性的仇恨言论检测系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在线多媒体内容中仇恨言论的迅速传播带来了社会挑战。现有的大多数多模态仇恨视频检测方法依赖于粗粒度的视频级标注，忽略了仇恨内容的细粒度时间信息，导致大量标签噪声。

**Method:** 本文采用细粒度方法，使用标注的时间戳从HateMM和MultiHateClip数据集中修剪仇恨视频，以分离出明确的仇恨片段。随后对这些修剪后的片段进行探索性分析，以检查仇恨和非仇恨内容的分布和特征。最后，通过受控实验评估时间戳噪声的影响。

**Result:** 探索性分析揭示了粗粒度视频级标注引入的语义重叠和混淆。受控实验表明，时间戳噪声从根本上改变了模型的决策边界并削弱了分类置信度，突出了仇恨言论表达的上下文依赖性和时间连续性。

**Conclusion:** 研究结果提供了关于多模态仇恨视频时间动态的新见解，并强调了需要开发时间感知的模型和基准，以提高模型的鲁棒性和可解释性。

> **ai_Abstract:** 本文研究了多模态仇恨视频分类中普遍存在的时间标签噪声问题，该噪声源于粗粒度的视频级标注。作者通过使用细粒度的时间戳修剪数据集，并对修剪后的片段进行分析，揭示了标签模糊性带来的语义重叠和混淆。实验证明，时间戳噪声会显著改变模型决策边界并降低分类置信度。研究强调了开发时间感知的模型和基准对于提高仇恨视频检测鲁棒性和可解释性的重要性。

> **摘要翻译:** 在线多媒体内容的迅速普及加剧了仇恨言论的传播，带来了严峻的社会和监管挑战。尽管最近的工作在多模态仇恨视频检测方面取得了进展，但大多数方法依赖于粗粒度的视频级标注，忽略了仇恨内容的时序粒度。这引入了大量的标签噪声，因为被标注为仇恨的视频通常包含很长的非仇恨片段。在本文中，我们通过一种细粒度的方法研究了这种标签模糊性的影响。具体来说，我们使用标注的时间戳从HateMM和MultiHateClip英文数据集中修剪仇恨视频，以分离出明确的仇恨片段。然后，我们对这些修剪后的片段进行了探索性分析，以检查仇恨和非仇恨内容的分布和特征。这项分析突出了粗粒度视频级标注所引入的语义重叠程度和混淆。最后，受控实验表明，时间戳噪声从根本上改变了模型的决策边界并削弱了分类置信度，这突出了仇恨言论表达固有的上下文依赖性和时间连续性。我们的发现为多模态仇恨视频的时间动态提供了新见解，并强调了需要时间感知的模型和基准，以提高鲁棒性和可解释性。代码和数据可在https://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [261] [ASkDAgger: Active Skill-level Data Aggregation for Interactive Imitation Learning](https://arxiv.org/abs/2508.05310)
> *ASkDAgger：用于交互式模仿学习的主动技能级别数据聚合*

*Jelle Luijkx, Zlatan Ajanović, Laura Ferranti, Jens Kober* | **Category: cs.AI, cs.HC, cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 交互式模仿学习, 主动学习, 数据聚合, 教师反馈, 新手计划

**Comment:** 

> **TL;DR:** ASkDAgger是一个新的框架，通过利用新手计划和教师反馈来减少交互式模仿学习中的人类教学工作，从而减少查询次数并提高泛化能力。

**AI_Comments:** ASkDAgger的创新之处在于其允许新手表达不确定性并利用教师对新手计划的反馈，这是一种更自然且信息量更大的交互方式。通过结合SAG、FIER和PIER，该框架有效解决了交互式模仿学习中数据效率和泛化能力的关键挑战，对于减少人类教学负担具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 交互式模仿学习中人类教学工作的投入是一个重要的瓶颈。现有方法虽然采用主动学习来减少查询，但未能利用新手规划的动作中包含的宝贵信息（如能力和不确定性水平）。

**Method:** 本文提出了主动技能级别数据聚合（ASkDAgger）框架，通过以下三种方式利用教师对新手计划的反馈：1) S-Aware Gating (SAG)：调整门控阈值以跟踪敏感度、特异性或最小成功率；2) Foresight Interactive Experience Replay (FIER)：将有效和重新标记的新手动作计划重新塑造成演示；3) Prioritized Interactive Experience Replay (PIER)：根据不确定性、新手成功率和演示年龄优先进行回放。

**Result:** ASkDAgger的各个组件协同作用，平衡了查询频率与失败发生率，减少了所需的演示标注数量，提高了泛化能力，并加速了对不断变化的领域的适应。其有效性已通过模拟和真实世界环境中的语言条件操作任务得到验证。

**Conclusion:** ASkDAgger通过利用新手计划和教师反馈，显著减少了交互式模仿学习中的人类教学工作，提高了学习效率和泛化能力。

> **ai_Abstract:** 本研究旨在解决交互式模仿学习中人类教学工作量大的问题。现有方法未能充分利用新手规划的动作信息。为此，论文提出了ASkDAgger框架，该框架允许新手表达不确定性并利用教师反馈。ASkDAgger包含S-Aware Gating (SAG)、Foresight Interactive Experience Replay (FIER)和Prioritized Interactive Experience Replay (PIER)三个核心组件，旨在平衡查询频率、减少标注需求、提高泛化能力并加速领域适应。研究通过语言条件操作任务在模拟和真实环境中验证了ASkDAgger的有效性。

> **摘要翻译:** 人类教学工作是交互式模仿学习更广泛应用的一个重要瓶颈。为了减少所需的查询次数，现有方法采用主动学习，仅在不确定、有风险或新颖的情况下向人类教师查询。然而，在这些查询过程中，新手计划的动作并未被利用，尽管其中包含宝贵信息，例如新手的技能水平以及相应的不确定性水平。为此，我们允许新手表达：“我打算这样做，但我不太确定。”我们引入了主动技能级别数据聚合（ASkDAgger）框架，该框架通过三种关键方式利用教师对新手计划的反馈：(1) S-Aware Gating (SAG)：调整门控阈值以跟踪敏感度、特异性或最小成功率；(2) Foresight Interactive Experience Replay (FIER)，将有效和重新标记的新手动作计划重新塑造成演示；以及(3) Prioritized Interactive Experience Replay (PIER)，根据不确定性、新手成功率和演示年龄优先进行回放。这些组件共同平衡了查询频率与失败发生率，减少了所需的演示标注数量，提高了泛化能力，并加速了对不断变化的领域的适应。我们通过在模拟和真实世界环境中的语言条件操作任务验证了ASkDAgger的有效性。代码、数据和视频可在 https://askdagger.github.io 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [262] [GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics](https://arxiv.org/abs/2508.02926)
> *GrandJury：一种用于动态质量评估标准的协作式机器学习模型评估协议*

*Arthur Cho* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 机器学习评估, 生成式模型, 动态评估, 人工判断, GrandJury

**Comment:** 

> **TL;DR:** GrandJury提出了一种新的机器学习模型评估协议，该协议结合了时间衰减聚合、可追溯性、动态评估标准和多人人工判断，以应对生成式模型在缺乏绝对真值情况下的动态评估需求。

**AI_Comments:** GrandJury的创新之处在于它认识到生成式AI模型输出评估的复杂性和动态性，并提供了一个超越传统静态基准测试的解决方案。通过引入时间衰减聚合、可追溯性和动态评估标准，它能够更好地反映现实世界中用户需求和共识的演变。其支持多人判断和开源实现的特点，有望促进更透明、负责任和适应性强的AI评估实践。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习模型（特别是生成式模型）的评估方法依赖于静态基准测试，导致模型优化偏向排行榜分数而非动态用户需求或不断变化的实际情况。然而，在许多应用领域，可接受的响应是多元化且高度依赖上下文的，而非绝对或静态的。

**Method:** GrandJury引入了一种正式的评估协议，它结合了时间衰减聚合、完整的可追溯性、对动态透明任务评估标准的归因支持以及多评估者的人工判断。

**Result:** 这些元素共同实现了多元化、负责任的评估，能够捕捉不断演变的共识并揭示分歧。该协议提供了一个开源实现（grandjury PyPI包）和一个公共的大型语言模型（LLM）推理输出集合，以说明其必要性和方法。

**Conclusion:** GrandJury为AI从业者在评估缺乏绝对真值的机器学习输出时提供了一种新的范式。

> **ai_Abstract:** 本论文提出了GrandJury，一种用于评估生成式机器学习模型的新型协作协议。针对现有评估方法无法适应动态、情境化和多元化用户需求的不足，GrandJury整合了时间衰减聚合、完整可追溯性、动态透明任务评估标准以及多评估者人工判断。该协议旨在提供一种多元化且负责任的评估范式，以捕捉不断演变的共识并揭示分歧，尤其适用于缺乏绝对真值的场景。论文还提供了开源实现和LLM推理输出示例。

> **摘要翻译:** 生成式机器学习模型已成为现代系统的核心，为创意写作、摘要、多跳推理和上下文感知对话等应用提供支持。这些模型支撑着大规模人工智能助手、工作流自动化和自主决策。在这些领域中，可接受的响应很少是绝对或静态的，而是多元化且高度依赖上下文的。然而，标准的评估制度仍然依赖于静态的基准测试，这激励了对排行榜分数的优化，而非与动态用户需求或不断演变的现实保持一致。GrandJury引入了一种正式的评估协议，该协议结合了时间衰减聚合、完整的可追溯性、对动态透明任务评估标准的归因支持以及多评估者的人工判断。这些元素共同实现了多元化、负责任的评估，能够捕捉不断演变的共识并揭示分歧。我们提供了一个开源实现（grandjury PyPI包）和一个公共的大型语言模型（LLM）推理输出集合，以说明其必要性和方法。GrandJury为AI从业者在评估缺乏绝对真值的机器学习输出时提供了一种新的范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [267] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
> *RCR-Router：面向多智能体LLM系统的有效角色感知上下文路由与结构化记忆*

*Jun Liu, Zhenglun Kong, Changdi Yang, Fan Yang, Tianqi Li, Peiyan Dong, Joannah Nanjekye, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-08-06**

**Keywords:** 多智能体LLM, 上下文路由, 结构化记忆, 令牌效率, 角色感知

**Comment:** 

> **TL;DR:** RCR-Router是一种新的路由框架，用于多智能体LLM系统，通过动态选择与角色相关的记忆子集来减少令牌消耗并保持答案质量。

**AI_Comments:** RCR-Router的创新之处在于其首次提出了动态、角色感知的上下文路由方法，有效解决了多智能体LLM系统中长期存在的令牌效率和记忆管理问题。其对结构化记忆和输出感知评估的强调，为未来可扩展多智能体LLM系统的发展提供了重要方向。该方法在减少资源消耗的同时保持性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有多智能体LLM系统中的协调方案依赖于静态或全上下文路由策略，导致令牌消耗过多、记忆暴露冗余以及在交互轮次中适应性有限。

**Method:** 本文提出了RCR-Router，一个模块化、角色感知的上下文路由框架。它根据智能体的角色和任务阶段，动态选择语义相关的记忆子集，并遵守严格的令牌预算。通过轻量级评分策略指导记忆选择，并将智能体输出迭代整合到共享记忆存储中，以促进渐进式上下文细化。此外，还提出了一个答案质量分数（Answer Quality Score）指标来评估模型行为。

**Result:** 在HotPotQA、MuSiQue和2WikiMultihop三个多跳问答基准测试中，RCR-Router在提高或保持答案质量的同时，将令牌使用量减少了高达30%。

**Conclusion:** 这些结果强调了结构化记忆路由和输出感知评估在推进可扩展多智能体LLM系统中的重要性。

> **ai_Abstract:** RCR-Router是一种为多智能体LLM系统设计的上下文路由框架，旨在解决现有方法中令牌消耗高、记忆暴露冗余及适应性差的问题。它通过动态选择与智能体角色和任务阶段相关的记忆子集，并在严格的令牌预算下运行，从而实现高效协作。该框架利用轻量级评分策略进行记忆选择，并迭代整合智能体输出以优化上下文。实验结果表明，RCR-Router在多跳问答任务中能显著减少令牌使用（高达30%），同时保持或提升答案质量。此外，论文还提出了一个新的答案质量分数指标，用于更全面的评估。

> **摘要翻译:** 多智能体大型语言模型（LLM）系统在复杂推理和协作决策任务中展现出强大潜力。然而，现有的大多数协调方案依赖于静态或全上下文路由策略，这导致令牌消耗过多、记忆暴露冗余以及在交互轮次中适应性有限。我们引入了RCR-Router，一个模块化、角色感知的上下文路由框架，旨在实现多智能体LLM中高效、自适应的协作。据我们所知，这是第一个动态选择每个智能体基于其角色和任务阶段的语义相关记忆子集，同时遵守严格令牌预算的路由方法。轻量级评分策略指导记忆选择，智能体输出被迭代整合到共享记忆存储中，以促进渐进式上下文细化。为了更好地评估模型行为，我们进一步提出了一个答案质量分数（Answer Quality Score）指标，该指标捕获了LLM生成的解释，超越了标准问答准确性。在HotPotQA、MuSiQue和2WikiMultihop三个多跳问答基准测试中的实验表明，RCR-Router在提高或保持答案质量的同时，将令牌使用量减少了高达30%。这些结果强调了结构化记忆路由和输出感知评估在推进可扩展多智能体LLM系统中的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [268] [mKG-RAG: Multimodal Knowledge Graph-Enhanced RAG for Visual Question Answering](https://arxiv.org/abs/2508.05318)
> *mKG-RAG：多模态知识图谱增强的RAG用于视觉问答*

*Xu Yuan, Liangbo Ning, Wenqi Fan, Qing Li* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多模态知识图谱, 检索增强生成, 视觉问答, MLLM, 结构化知识

**Comment:** 

> **TL;DR:** 本文提出了mKG-RAG框架，通过整合多模态知识图谱来提升基于RAG的视觉问答（VQA）的准确性和可靠性，解决了传统方法依赖非结构化数据导致的问题。

**AI_Comments:** mKG-RAG的创新点在于将多模态知识图谱引入到RAG框架中，以结构化知识弥补传统RAG依赖非结构化文档的缺陷，有效解决了信息冗余和不准确的问题。其结合MLLM进行知识图谱构建和双阶段检索策略，提升了知识型VQA的性能和可靠性，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于检索增强生成（RAG）的视觉问答（VQA）方法依赖于非结构化文档，并且忽视了知识元素之间的结构关系，这经常导致引入不相关或误导性的内容，从而降低了答案的准确性和可靠性。

**Method:** 本文提出了一个新颖的多模态知识增强生成框架（mKG-RAG）。该方法利用多模态大型语言模型（MLLM）驱动的关键词提取和视觉-文本匹配技术，从多模态文档中提炼出语义一致且模态对齐的实体/关系，以此构建高质量的多模态知识图谱作为结构化知识表示。此外，mKG-RAG还引入了一种配备问题感知多模态检索器的双阶段检索策略，旨在提高检索效率并提升精度。

**Result:** 全面的实验证明，mKG-RAG方法显著优于现有方法，并在知识型视觉问答（VQA）任务中取得了最先进的（state-of-the-art）性能。

**Conclusion:** 通过将结构化的多模态知识图谱与优化的双阶段检索策略整合到检索增强生成（RAG）框架中，mKG-RAG有效克服了传统RAG在视觉问答（VQA）任务中的局限性，显著提升了知识型VQA的答案准确性和可靠性。

> **ai_Abstract:** 本文提出了mKG-RAG框架，旨在通过整合多模态知识图谱来提升知识型视觉问答（VQA）的准确性和可靠性。针对现有RAG方法依赖非结构化数据导致信息冗余的问题，mKG-RAG利用MLLM进行关键词提取和视觉-文本匹配，构建高质量的结构化多模态知识图谱。同时，它引入双阶段检索策略和问题感知多模态检索器，以优化检索效率和精度。实验结果表明，mKG-RAG在知识型VQA任务上表现优异，超越了现有SOTA方法。

> **摘要翻译:** 最近，检索增强生成（RAG）被提出通过将外部知识库整合到生成过程中来扩展多模态大型语言模型（MLLM）的内部知识，这被广泛用于基于知识的视觉问答（VQA）任务。尽管取得了令人印象深刻的进展，但依赖非结构化文档并忽视知识元素之间结构关系的普通基于RAG的VQA方法经常引入不相关或误导性内容，从而降低了答案的准确性和可靠性。为了克服这些挑战，一个有前景的解决方案是将多模态知识图谱（KGs）整合到基于RAG的VQA框架中，通过引入结构化多模态知识来增强生成。因此，在本文中，我们提出了一种新颖的基于多模态知识图谱的多模态知识增强生成框架（mKG-RAG），用于知识密集型VQA任务。具体来说，我们的方法利用MLLM驱动的关键词提取和视觉-文本匹配，从多模态文档中提炼出语义一致且模态对齐的实体/关系，构建高质量的多模态知识图谱作为结构化知识表示。此外，引入了一种配备问题感知多模态检索器的双阶段检索策略，以提高检索效率，同时提升精度。全面的实验表明，我们的方法显著优于现有方法，为基于知识的VQA设定了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [269] [Realizing Scaling Laws in Recommender Systems: A Foundation-Expert Paradigm for Hyperscale Model Deployment](https://arxiv.org/abs/2508.02929)
> *推荐系统中实现规模化定律：超大规模模型部署的“基础-专家”范式*

*Dai Li, Kevin Course, Wei Li, Hongwei Li, Jie Hua, Yiqi Chen, Zhao Zhu, Rui Jian, Xuan Cao, Bi Xue, Yu Shi, Jing Qian, Kai Ren, Matt Ma, Qunshu Zhang, Rui Li* | **Category: cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 推荐系统, 规模化定律, 基础-专家范式, 超大规模模型, HyperCast

**Comment:** 

> **TL;DR:** 本文提出并成功部署了一种“基础-专家”范式，用于推荐系统中的超大规模模型部署，解决了现有挑战并提升了性能和效率。

**AI_Comments:** 该论文的创新点在于提出了“基础-专家”范式来应对推荐系统特有的挑战，并成功将其部署到超大规模生产环境，证明了其在性能提升、计算效率和开发效率方面的优势。这是该范式首次在此规模下的成功应用，为未来推荐系统的发展提供了宝贵的实践经验和蓝图。

<details>
  <summary>Details</summary>

**Motivation:** 推荐系统在部署超大规模模型时面临独特挑战，如在线流数据、数据分布变化、不同推荐界面的适应性、严格的延迟和计算限制，导致无法充分利用规模化定律带来的性能提升。

**Method:** 本文提出“基础-专家”范式，其中一个中央基础模型通过学习终身、跨界面、多模态的用户数据来获取通用知识，然后将知识通过目标感知嵌入高效地转移到轻量级、特定界面的“专家”模型。为支持此范式，研究团队构建了生产级基础设施系统HyperCast，并重新设计了训练、服务、日志和迭代流程。

**Result:** 该方法已在Meta部署，每天处理数百亿用户请求，相比先前的单阶段生产系统，实现了在线指标改进，同时提高了开发人员速度并保持了基础设施效率。这是首次在此规模下成功部署“基础-专家”范式。

**Conclusion:** 该工作首次成功部署了这种规模的“基础-专家”范式，提供了一个经过验证、计算高效、开发人员友好的蓝图，以实现在推荐系统中规模化定律的潜力。

> **ai_Abstract:** 本文针对推荐系统在部署超大规模模型时面临的挑战，提出并成功部署了“基础-专家”范式。该范式通过一个学习通用知识的中央基础模型，结合多个适应特定任务的轻量级专家模型，实现了知识的有效迁移。研究团队为此构建了生产级基础设施HyperCast。该方法已在Meta的实际生产环境中应用，不仅提升了在线指标表现，还提高了开发效率并保持了基础设施效率，为推荐系统实现规模化定律提供了可行的解决方案。

> **摘要翻译:** 尽管规模化定律有望为推荐系统带来显著的性能提升，但高效部署超大规模模型仍然是一个尚未解决的重大挑战。与自然语言处理和计算机视觉等领域中基础模型（FMs）已广泛采用的情况不同，推荐系统的进展受到独特挑战的阻碍，包括需要从不断变化的数据分布下的在线流数据中学习、需要适应具有广泛下游任务和输入分布多样性的不同推荐界面，以及严格的延迟和计算限制。为了弥合这一差距，我们提出利用“基础-专家”范式：一个为开发和部署超大规模推荐基础模型而设计的框架。在我们的方法中，一个中央基础模型在终身、跨界面、多模态用户数据上进行训练，以学习通用知识。然后，这些知识通过目标感知嵌入高效地转移到各种轻量级、特定界面的“专家”模型，使它们能够以最小的开销适应本地数据分布和优化目标。为了满足我们的训练、推理和开发需求，我们构建了HyperCast，一个生产级的infra系统，它重新设计了训练、服务、日志和迭代，以支持这种解耦的范式。我们的方法目前已在Meta部署，每天处理数百亿用户请求，与我们之前的一阶段生产系统相比，在线指标有所改进，同时提高了开发人员速度并保持了基础设施效率。据我们所知，这项工作代表了“基础-专家”范式在此规模下的首次成功部署，提供了一个经过验证、计算高效且开发人员友好的蓝图，以实现在推荐系统中规模化定律的承诺。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [274] [Taxonomy of Faults in Attention-Based Neural Networks](https://arxiv.org/abs/2508.04925)
> *注意力机制神经网络中的故障分类*

*Sigma Jahan, Saurabh Singh Rajput, Tushar Sharma, Mohammad Masudur Rahman* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-06**

**Keywords:** 注意力机制, 故障分类, 神经网络, 诊断指南, 实证研究

**Comment:** 

> **TL;DR:** 本文提出了首个针对注意力机制神经网络的全面故障分类法和诊断指南，基于对真实世界故障的实证研究。

**AI_Comments:** 该论文的创新之处在于首次为注意力机制神经网络建立了专门的故障分类法和诊断指南，填补了深度学习故障分析领域的一个关键空白。鉴于注意力机制的广泛应用和重要性，这项基于真实世界故障的实证研究具有显著的实践价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习故障分类法未能充分涵盖注意力机制引入的独特故障，导致从业者缺乏可操作的诊断指导。

**Method:** 通过对来自GitHub、Hugging Face和Stack Overflow等10个框架的96个项目中的555个真实世界故障进行系统分析，进行了一项全面的注意力机制神经网络故障实证研究。

**Result:** 开发了一个包含七个注意力特定故障类别的全新分类法；结果显示超过一半的注意力机制神经网络故障源于注意力架构特有的机制；通过分析症状-根本原因关联，识别出四种可解释33.0%注意力特定故障的循证诊断启发式方法。

**Conclusion:** 本研究为注意力机制模型提供了首个系统性的诊断指导。

> **ai_Abstract:** 本文旨在解决现有深度学习故障分类法未能涵盖注意力机制神经网络（ABNNs）特有故障的问题。研究通过对来自96个项目、10个框架的555个真实世界故障进行系统分析，首次全面实证研究了ABNNs的故障。研究成果包括一个包含七个注意力特定故障类别的全新分类法，并发现超过一半的ABNNs故障源于注意力架构独有机制。此外，通过分析症状与根本原因的关联，论文识别出四种循证诊断启发式方法，为注意力模型提供了首个系统性诊断指导。

> **摘要翻译:** 注意力机制是现代神经网络架构的核心，为从ChatGPT到自动驾驶汽车等系统提供动力，并产生重大的经济影响。然而，ChatGPT的无意义输出或Google因注意力权重错误暂停Gemini图像生成等备受关注的故障，凸显了一个关键空白：现有的深度学习故障分类法可能无法充分捕捉注意力机制引入的独特故障。这一空白使得从业者缺乏可操作的诊断指导。为了解决这一空白，我们提出了首个针对注意力机制神经网络（ABNNs）故障的全面实证研究。我们的工作基于对来自GitHub、Hugging Face和Stack Overflow等10个框架的96个项目中的555个真实世界故障的系统分析。通过我们的分析，我们开发了一个包含七个注意力特定故障类别的全新分类法，这是现有工作未曾涵盖的。我们的结果显示，超过一半的注意力机制神经网络故障源于注意力架构特有的机制。我们进一步通过各种症状分析了这些故障的根本原因和表现形式。最后，通过分析症状-根本原因关联，我们识别出四种可解释33.0%注意力特定故障的循证诊断启发式方法，为注意力机制模型提供了首个系统性的诊断指导。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [275] [Efficient Reasoning for Large Reasoning Language Models via Certainty-Guided Reflection Suppression](https://arxiv.org/abs/2508.05337)
> *通过确定性引导的反射抑制实现大型推理语言模型的有效推理*

*Jiameng Huang, Baijiong Lin, Guhao Feng, Jierun Chen, Di He, Lu Hou* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型推理语言模型, 反射抑制, 过度思考, 效率推理, token使用量

**Comment:** 

> **TL;DR:** 提出CGRS方法，通过抑制不必要的反射行为，显著减少大型推理语言模型（LRLMs）的token使用量并降低推理成本，同时保持推理准确性。

**AI_Comments:** CGRS的创新之处在于其“确定性引导”的动态抑制机制，解决了LRLMs在长链推理中的效率瓶颈。其模型无关性、无需再训练和架构修改的特点，使其具有很高的实用价值和普适性，能够无缝集成到现有系统中。这项工作对于优化LRLMs的推理效率和降低部署成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理语言模型（LRLMs）的复杂反射行为导致“过度思考”，产生冗余推理步骤，从而增加token使用、提高推理成本并降低实用性。

**Method:** 提出确定性引导的反射抑制（CGRS）方法。当模型对其当前响应表现出高置信度时，CGRS会动态抑制模型生成反射触发词，从而防止冗余的反射循环，同时不影响输出质量。该方法与模型无关，无需重新训练或修改架构，可无缝集成到现有自回归生成管道中。

**Result:** 在四个推理基准测试中，CGRS将token使用量平均减少18.5%至41.9%，同时保持了推理准确性。与现有最佳基线相比，它在长度缩减和性能之间达到了最佳平衡。这些结果在不同模型架构和规模上均保持一致。

**Conclusion:** CGRS方法为大型推理语言模型提供了高效推理的实用价值，有效解决了过度思考问题。

> **ai_Abstract:** 本文提出了确定性引导的反射抑制（CGRS）方法，旨在解决大型推理语言模型（LRLMs）中因复杂反射行为导致的“过度思考”问题。CGRS通过在模型高置信度时动态抑制反射触发词，有效减少冗余推理步骤，从而降低token使用量和推理成本，同时保持甚至优化推理准确性。该方法无需模型修改或再训练，且在多个基准测试和不同模型上均表现出显著的效率提升。

> **摘要翻译:** **标题:** 通过确定性引导的反射抑制实现大型推理语言模型的有效推理

**摘要:** 近期的大型推理语言模型（LRLMs）采用长链式思维推理和复杂的反射行为（通常由特定的触发词如“Wait”和“Alternatively”表示）来提升性能。然而，这些反射行为可能导致“过度思考”问题，即生成冗余的推理步骤，不必要地增加token使用量，提高推理成本，并降低实用性。在本文中，我们提出了确定性引导的反射抑制（CGRS），这是一种新颖的方法，旨在减轻LRLMs中的过度思考问题，同时保持推理准确性。CGRS通过在模型对其当前响应表现出高置信度时动态抑制其反射触发词的生成来运作，从而在不损害输出质量的情况下防止冗余的反射循环。我们的方法与模型无关，无需重新训练或修改架构，并且可以与现有的自回归生成管道无缝集成。在四个推理基准测试（即AIME24、AMC23、MATH500和GPQA-D）上进行的广泛实验证明了CGRS的有效性：它在保持准确性的同时，将token使用量平均减少了18.5%至41.9%。与现有最先进的基线相比，它还在长度缩减和性能之间取得了最佳平衡。这些结果在不同模型架构（例如DeepSeek-R1-Distill系列、QwQ-32B和Qwen3家族）和规模（4B到32B参数）上均保持一致，突出了CGRS在高效推理方面的实用价值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [276] [LLMs are Single-threaded Reasoners: Demystifying the Working Mechanism of Soft Thinking](https://arxiv.org/abs/2508.03440)
> *LLM是单线程推理器：揭秘软思维的工作机制*

*Chünhung Wu, Jinliang Lu, Zixuan Ren, Gangqiang Hu, Zhi Wu, Dai Dai, Hua Wu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 软思维, 单线程推理, 贪婪解码, Gumbel-Softmax

**Comment:** 

> **TL;DR:** LLMs的“软思维”看似能探索多条推理路径，但实际上是贪婪解码，只依赖最有影响力的软输入。引入随机性（如Gumbel-Softmax）能改善此问题并提升性能。

**AI_Comments:** 这项研究揭示了LLMs“软思维”的一个关键局限性，即其本质上的贪婪解码行为，这与直觉相悖。通过引入随机性来克服这一限制，特别是Gumbel-Softmax技巧的有效性，为提升LLMs在复杂推理任务中的表现提供了新的方向。其创新点在于对LLMs内部推理机制的深入剖析以及提出了一种有效的改进策略。

<details>
  <summary>Details</summary>

**Motivation:** 现有推理模型依赖离散令牌，限制表达能力。近期的“软思维”旨在通过生成抽象的软令牌来解决此限制，促进在连续概念空间内的推理。本文旨在探索并揭示LLMs软思维的内部工作机制。

**Method:** 本文使用一系列探测技术检查大型语言模型（LLMs）的内部行为以探索其“软思维”能力。为解决发现的贪婪解码问题，研究探索并采用了Dirichlet重采样和Gumbel-Softmax技巧等采样策略来引入随机性。实验在八个推理基准上进行。

**Result:** 研究发现，LLMs在“软思维”中主要依赖软输入中最具影响力的部分，这阻碍了不同推理路径的探索，并将原始的软思维简化为一种贪婪解码形式。实验证明，引入随机性可以缓解原始方法的局限性并释放软思维的潜力。值得注意的是，Gumbel-Softmax技巧提供了足够的随机性和受控的平滑性，从而在八个推理基准上取得了卓越的性能。

**Conclusion:** LLMs的软思维在没有随机性引入的情况下表现为单线程的贪婪解码。通过引入适当的随机性，特别是Gumbel-Softmax技巧，可以有效提升软思维的推理能力，使其能够探索更多路径并提高性能。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）的“软思维”机制，发现其在推理时并非同时探索多路径，而是表现为单线程的贪婪解码，主要依赖软输入中最具影响力的部分。为解决这一局限，研究引入了Dirichlet重采样和Gumbel-Softmax等随机性采样策略。实验证明，引入随机性，特别是Gumbel-Softmax技巧，能有效提升软思维的性能，使其在连续概念空间推理中发挥更大潜力。

> **摘要翻译:** 人类认知自然地与抽象和流动的概念互动，而现有的推理模型通常依赖于生成离散的令牌，这可能限制了它们的表达能力。最近的进展旨在通过使大型语言模型（LLM）生成软的、抽象的令牌来解决这一限制，从而促进在连续概念空间内的推理。本文通过使用一系列探测技术检查模型的内部行为，探讨了各种LLM的“软思维”能力。与普遍认为软思维能够同时探索不同推理路径的观念相反，我们的发现揭示了LLM在随后的解码步骤中主要依赖于软输入中最具影响力的组成部分。这种依赖阻碍了不同推理路径的探索，并将原始的软思维简化为一种贪婪解码形式，从而掩盖了通过软令牌传输更多信息的优势。为了解决这个问题，我们探索了引入“随机性”的采样策略，采用了如Dirichlet重采样和Gumbel-Softmax技巧等方法。我们的实验表明，引入随机性可以缓解原始方法的局限性，并释放软思维的潜力。值得注意的是，Gumbel-Softmax技巧提供了足够的随机性和受控的平滑性，从而在八个推理基准上取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [281] [Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)
> *使用校准令牌将基础单目深度估计器扩展到鱼眼相机*

*Suchisrit Gangopadhyay, Jung-Hee Kim, Xien Chen, Patrick Rim, Hyoungseob Park, Alex Wong* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 单目深度估计, 鱼眼相机, 校准令牌, 潜在嵌入, 自监督学习

**Comment:** 

> **TL;DR:** 提出一种使用校准令牌的方法，在不重新训练或微调的情况下，将为透视图像训练的基础单目深度估计器扩展到鱼眼相机，通过对潜在嵌入进行调制来解决相机标定引起的协变量偏移问题，并取得优于现有技术的结果。

**AI_Comments:** 该论文的主要创新点在于引入了“校准令牌”这一轻量级适应机制，在不触及原始模型权重的情况下，通过调制潜在空间实现了对不同相机畸变的适应，有效避免了传统图像空间变换可能引入的伪影和信息损失。这种方法极大地提高了基础单目深度估计器在实际应用中的泛化能力和实用性，尤其是在处理非透视相机（如鱼眼相机）数据时，具有重要的工程意义。

<details>
  <summary>Details</summary>

**Motivation:** 为透视图像训练的基础单目深度估计器（FMDEs）在相机标定参数（内参、畸变）变化引入的协变量偏移面前表现脆弱，导致深度估计错误。传统的重新训练或微调成本高昂，因此需要一种无需重新训练即可将FMDEs应用于鱼眼相机的方法。

**Method:** 提出一种轻量级适应机制，即“校准令牌”，通过调制FMDEs的潜在嵌入来对齐鱼眼图像和透视图像的潜在嵌入分布。该方法是自监督的，不依赖鱼眼图像，而是利用公开的大规模透视图像数据集，通过将透视图像重新校准为鱼眼图像并在训练期间强制其估计之间的一致性来实现。

**Result:** 在室内和室外场景下，使用多个FMDEs对该方法进行了评估，结果表明，使用单一的校准令牌集，该方法始终优于现有先进方法。

**Conclusion:** 该研究成功地提出了一种无需重新训练或微调即可将基础单目深度估计器扩展到鱼眼相机的方法，通过引入校准令牌有效地解决了相机标定引起的协变量偏移问题，并在各种场景下取得了显著的性能提升。

> **ai_Abstract:** 该论文提出了一种创新方法，旨在将为透视图像训练的基础单目深度估计器（FMDEs）扩展到鱼眼相机，而无需进行重新训练或微调。针对相机标定参数变化导致的协变量偏移问题，研究引入了一组“校准令牌”作为轻量级适应机制，通过调制FMDEs的潜在嵌入来对齐鱼眼图像和透视图像的潜在嵌入分布。该方法是自监督的，利用公开的透视图像数据集，通过将透视图像重新校准为鱼眼图像并在训练中强制一致性来实现。实验结果表明，该方法在室内外场景下均能持续优于现有先进方法。

> **摘要翻译:** 我们提出了一种将基础单目深度估计器（FMDEs）从透视图像扩展到鱼眼图像的方法。尽管FMDEs在数千万张图像上进行训练，但它们对相机标定（内参、畸变）参数变化引入的协变量偏移敏感，导致错误的深度估计。我们的方法将编码鱼眼图像的潜在嵌入分布与透视图像的潜在嵌入分布对齐，从而无需重新训练或微调即可将FMDEs用于鱼眼相机。为此，我们引入了一组校准令牌作为一种轻量级适应机制，用于调制潜在嵌入以进行对齐。通过利用FMDEs已有的表达性潜在空间，我们认为调制其嵌入可以避免传统图像空间中的重新校准或映射到规范参考帧所引入的伪影和损失的负面影响。我们的方法是自监督的，不需要鱼眼图像，而是利用公开可用的大规模透视图像数据集。这是通过将透视图像重新校准为鱼眼图像，并在训练期间强制其估计之间的一致性来实现的。我们使用多个FMDEs在室内和室外评估了我们的方法，在这两种情况下，我们都始终优于使用单一令牌集的现有先进方法。代码可在以下网址获取：https://github.com/JungHeeKim29/calibration-token。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [282] [Information-Theoretic Graph Fusion with Vision-Language-Action Model for Policy Reasoning and Dual Robotic Control](https://arxiv.org/abs/2508.05342)
> *信息论图融合结合视觉-语言-动作模型用于策略推理和双臂机器人控制*

*Shunlei Li, Longsen Gao, Jin Wang, Chang Che, Xi Xiao, Jiuwen Cao, Yingbai Hu, Hamid Reza Karimi* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人技术, 图融合, 视觉-语言-动作, 双臂控制, 信息论

**Comment:** 

> **TL;DR:** 本文提出了GF-VLA，一个结合信息论场景图和语言条件Transformer的框架，使双臂机器人能从人类演示中学习灵巧技能，在积木组装任务中实现了高准确性和泛化能力。

**AI_Comments:** 该论文通过结合信息论进行场景表示、视觉-语言模型和图融合来实现机器人控制，提出了一种创新方法。利用基于香农信息的线索来识别任务相关性，并通过场景图明确建模手-物体/物体-物体交互是其主要优势。交叉手选择策略进一步增强了双臂操作的效率。在各种泛化测试中取得的强大实验结果突显了这项工作在推动机器人从人类演示中学习方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 从人类视频中教导机器人灵巧技能仍然具有挑战性，因为现有方法依赖于低级轨迹模仿，这导致其无法泛化到不同物体类型、空间布局和机械臂配置。

**Method:** 本文提出了Graph-Fused Vision-Language-Action (GF-VLA) 框架。它首先提取基于香农信息论的线索来识别任务相关性最高的手和物体，然后将这些线索编码成捕捉手-物体和物体-物体交互的时间有序场景图。这些图与一个语言条件Transformer融合，生成分层行为树和可解释的笛卡尔运动指令。为了提高双手操作的执行效率，进一步引入了交叉手选择策略，无需显式几何推理即可推断出最佳的抓手分配。

**Result:** 信息论场景表示实现了超过95%的图准确率和93%的子任务分割，支持LLM规划器生成可靠且人类可读的任务策略。当由双臂机器人执行时，这些策略在堆叠、字母构建和几何重构场景中分别产生了94%的抓取成功率、89%的放置准确率和90%的整体任务成功率，展示了在多样空间和语义变化下的强大泛化性和鲁棒性。

**Conclusion:** 信息论场景表示和GF-VLA框架使双臂机器人能够从人类演示中学习和执行复杂任务，具有高准确性、泛化性和鲁棒性，克服了传统轨迹模仿的局限性。

> **ai_Abstract:** GF-VLA是一个用于双臂机器人系统从人类演示中学习灵巧技能的新颖框架。它利用信息论线索构建场景图，这些图随后由语言条件Transformer处理以生成分层策略。结合交叉手选择策略，GF-VLA实现了鲁棒的任务级推理和执行，在多样的积木组装场景中展示了高成功率和泛化能力。

> **摘要翻译:** 从人类视频中教导机器人灵巧技能仍然具有挑战性，原因在于对低级轨迹模仿的依赖，这导致其无法泛化到不同物体类型、空间布局和机械臂配置。我们提出了Graph-Fused Vision-Language-Action (GF-VLA)，这是一个使双臂机器人系统能够直接从RGB和深度人类演示中进行任务级推理和执行的框架。GF-VLA首先提取基于香农信息的线索，以识别具有最高任务相关性的手和物体，然后将这些线索编码成时间有序的场景图，捕捉手-物体和物体-物体之间的交互。这些图与一个语言条件Transformer融合，生成分层行为树和可解释的笛卡尔运动指令。为了提高双手操作环境中的执行效率，我们进一步引入了一种交叉手选择策略，该策略无需明确的几何推理即可推断出最佳的抓手分配。我们在涉及符号形状构建和空间泛化的四项结构化双臂积木组装任务上评估了GF-VLA。实验结果表明，信息论场景表示实现了超过95%的图准确率和93%的子任务分割，支持LLM规划器生成可靠且人类可读的任务策略。当由双臂机器人执行时，这些策略在堆叠、字母构建和几何重构场景中分别产生了94%的抓取成功率、89%的放置准确率和90%的整体任务成功率，展示了在多样空间和语义变化下的强大泛化性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [283] [Probing and Enhancing the Robustness of GNN-based QEC Decoders with Reinforcement Learning](https://arxiv.org/abs/2508.03783)
> *使用强化学习探测和增强基于GNN的QEC解码器的鲁棒性*

*Ryota Ikeda* | **Category: cs.AI, quant-ph** | **Updated: 2025-08-07**

**Keywords:** GNNs, QEC解码器, 强化学习, 对抗性训练, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的框架，利用强化学习代理作为对手，系统地探测GNN量子纠错解码器的脆弱性，并展示了通过对抗性训练可以显著增强解码器的鲁棒性，为容错量子计算开发更可靠的解码器。

**AI_Comments:** 本文的创新之处在于将强化学习引入到GNN QEC解码器的鲁棒性分析和增强中，通过RL代理自动化地发现漏洞，并利用对抗性训练提升模型性能。这对于构建容错量子计算中更可靠的解码器具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图神经网络（GNNs）已成为量子纠错（QEC）解码的强大方法，但它们对细微对抗性扰动的鲁棒性仍然是一个关键的开放问题。

**Method:** 本文引入了一个新颖的框架，利用强化学习（RL）代理作为对手，系统地探测GNN解码器的脆弱性。RL代理被训练以寻找导致解码器错误分类的最小综合征修改。该框架应用于在Google Quantum AI的实验表面码数据上训练的图注意力网络（GAT）解码器。

**Result:** RL代理能够成功识别特定的关键脆弱性，以最少的位翻转实现高攻击成功率。此外，研究表明，通过对抗性训练（即使用RL代理生成的对抗性示例重新训练模型），解码器的鲁棒性可以显著增强。

**Conclusion:** 这种自动化漏洞发现和有针对性再训练的迭代过程，为开发更可靠、更鲁棒的容错量子计算神经网络解码器提供了一种有前景的方法。

> **ai_Abstract:** 本研究提出了一种利用强化学习（RL）代理来探测和增强基于图神经网络（GNN）的量子纠错（QEC）解码器鲁棒性的新框架。RL代理被训练为对手，旨在发现导致解码器错误分类的最小综合征修改。通过在实验数据上应用该框架，研究发现RL代理能有效识别解码器的脆弱性。更重要的是，通过使用RL生成的对抗性示例进行对抗性训练，可以显著提升解码器的鲁棒性。这为开发更可靠的容错量子计算解码器提供了一条有前景的路径。

> **摘要翻译:** 图神经网络（GNNs）已成为量子纠错（QEC）解码的一种强大、数据驱动的方法，能够直接从综合征数据中学习复杂的噪声特性。然而，这些解码器对细微对抗性扰动的鲁棒性仍然是一个关键的开放问题。这项工作引入了一个新颖的框架，利用强化学习（RL）代理系统地探测GNN解码器的脆弱性。RL代理被训练为对手，目标是找到导致解码器错误分类的最小综合征修改。我们将此框架应用于在Google Quantum AI的实验表面码数据上训练的图注意力网络（GAT）解码器。我们的结果表明，RL代理可以成功识别特定的关键脆弱性，以最少的位翻转实现高攻击成功率。此外，我们证明了通过对抗性训练可以显著增强解码器的鲁棒性，即模型在RL代理生成的对抗性示例上进行再训练。这种自动化漏洞发现和有针对性再训练的迭代过程，为开发更可靠、更鲁棒的容错量子计算神经网络解码器提供了一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [288] [INTENTION: Inferring Tendencies of Humanoid Robot Motion Through Interactive Intuition and Grounded VLM](https://arxiv.org/abs/2508.04931)
> *INTENTION：通过交互式直觉和基础VLM推断人形机器人运动趋势*

*Jin Wang, Weijie Wang, Boyuan Deng, Heng Zhang, Rui Dai, Nikos Tsagarakis* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-06**

**Keywords:** 机器人操作, 视觉-语言模型, 交互直觉, 记忆图, 自主操作

**Comment:** 

> **TL;DR:** INTENTION是一个新框架，通过整合VLM场景推理和交互驱动记忆，使机器人具备学习到的交互直觉和自主操作能力，以克服传统机器人控制在现实世界场景中的局限性。

**AI_Comments:** INTENTION框架的创新之处在于其整合了VLM和交互驱动记忆，以赋予机器人类人的直觉和适应性，克服了传统方法对精确模型和预定义序列的依赖。记忆图和直觉感知器的设计是其核心，有望显著提升机器人在非结构化环境中的泛化能力和自主性。该研究对于推动机器人从结构化环境走向真实世界应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统机器人操控严重依赖精确的物理模型和预定义动作序列，但在现实世界中由于建模不准确和泛化能力差而失效。与此相反，人类能直观地与环境互动，通过隐式物理理解做出高效决策，展现出卓越的适应性。因此，需要一种新方法让机器人具备类似人类的直觉和适应性。

**Method:** 本文提出了INTENTION框架，通过整合基于视觉-语言模型（VLM）的场景推理与交互驱动记忆，使机器人具备学习到的交互直觉和在多样化场景中的自主操作能力。该框架引入了记忆图（Memory Graph）来记录先前任务交互中的场景，以体现类人理解和决策。同时，设计了直觉感知器（Intuitive Perceptor）从视觉场景中提取物理关系和可供性。这些组件共同使机器人在新场景中无需重复指令即可推断出适当的交互行为。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 针对传统机器人控制在复杂现实世界中泛化能力差的问题，本文提出了INTENTION框架。该框架结合了视觉-语言模型（VLM）的场景推理和交互驱动记忆，通过引入记忆图（Memory Graph）存储交互经验和直觉感知器（Intuitive Perceptor）提取物理关系，使机器人能够学习交互直觉，并在新场景中自主推断适当行为，实现类人适应性操作。

> **摘要翻译:** 传统机器人操作的控制和规划严重依赖精确的物理模型和预定义的动作序列。虽然在结构化环境中有效，但由于建模不准确，此类方法在现实世界中往往会失败，并且难以推广到新任务。相比之下，人类能够直观地与周围环境互动，展现出卓越的适应性，通过隐式物理理解做出高效决策。在这项工作中，我们提出了INTENTION，一个新颖的框架，通过将基于视觉-语言模型（VLM）的场景推理与交互驱动记忆相结合，使机器人具备学习到的交互直觉和在多样化场景中的自主操作能力。我们引入了记忆图（Memory Graph）来记录先前任务交互中的场景，这体现了人类对现实世界中不同任务的理解和决策。同时，我们设计了一个直觉感知器（Intuitive Perceptor），从视觉场景中提取物理关系和可供性。这些组件共同使机器人在新场景中无需依赖重复指令即可推断出适当的交互行为。视频：https://robo-intention.github.io

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [289] [Multi-Modal Multi-Behavior Sequential Recommendation with Conditional Diffusion-Based Feature Denoising](https://arxiv.org/abs/2508.05352)
> *基于条件扩散特征去噪的多模态多行为序列推荐*

*Xiaoxi Cui, Weihai Lu, Yu Tong, Yiheng Li, Zhejun Zhao* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 多模态推荐, 多行为推荐, 序列推荐, 条件扩散, 特征去噪

**Comment:** 

> **TL;DR:** 本文提出了一种名为M$^3$BSR的新型模型，用于解决多模态多行为序列推荐中的挑战，包括模态偏好表征不足、隐式行为噪声和模态噪声问题，通过引入条件扩散去噪层和多专家兴趣提取层，显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新点在于将条件扩散模型引入到多模态多行为序列推荐中，用于特征去噪。这种方法有效地解决了用户行为中的隐式噪声和多模态表示中的模态噪声问题，这对于提升推荐系统准确性至关重要。同时，通过多专家兴趣提取层建模共同和特定兴趣，也提升了模型对复杂用户偏好的理解能力。该模型为处理多源异构数据在推荐系统中的应用提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 当前序列推荐系统在整合用户多样行为模式与丰富的项目多模态信息时面临挑战：1) 缺乏有效表征不同行为下模态偏好，因为用户对不同项目模态的关注随行为变化；2) 难以有效缓解用户行为中的隐式噪声，例如意外点击；3) 无法处理多模态表示中的模态噪声，这进一步影响用户偏好的准确建模。

**Method:** 本文提出了一种新颖的多模态多行为序列推荐模型（M$^3$BSR）。该模型首先使用条件扩散模态去噪层去除多模态表示中的噪声。接着，它利用深度行为信息指导浅层行为数据的去噪，通过条件扩散行为去噪缓解隐式反馈中噪声的影响。最后，通过引入多专家兴趣提取层，M$^3$BSR显式建模跨行为和模态的共同和特定兴趣，以增强推荐性能。

**Result:** 实验结果表明，M$^3$BSR在基准数据集上显著优于现有最先进的方法。

**Conclusion:** 本文提出的M$^3$BSR模型通过有效处理多模态和多行为数据中的噪声以及建模跨行为和模态的兴趣，显著提升了序列推荐系统的性能。

> **ai_Abstract:** 本文针对多模态多行为序列推荐中的挑战，提出了一种名为M$^3$BSR的新型模型。该模型旨在解决不同行为下模态偏好表征不足、隐式行为噪声以及多模态表示中的模态噪声问题。M$^3$BSR通过引入条件扩散模态去噪层和条件扩散行为去噪层来去除噪声，并利用多专家兴趣提取层显式建模跨行为和模态的共同及特定兴趣。实验证明，M$^3$BSR在基准数据集上表现显著优于现有最先进的方法。

> **摘要翻译:** 序列推荐系统利用历史用户交互来预测偏好。有效整合多样化的用户行为模式与丰富的项目多模态信息以提高序列推荐的准确性是一个新兴且具有挑战性的研究方向。本文关注多模态多行为序列推荐问题，旨在解决以下挑战：(1) 缺乏有效表征跨不同行为的模态偏好，因为用户对不同项目模态的关注因行为而异；(2) 难以有效缓解用户行为中的隐式噪声，例如意外点击等非预期行为；(3) 无法处理多模态表示中的模态噪声，这进一步影响用户偏好的准确建模。为了解决这些问题，我们提出了一种新颖的多模态多行为序列推荐模型（M$^3$BSR）。该模型首先使用条件扩散模态去噪层去除多模态表示中的噪声。随后，它利用深度行为信息指导浅层行为数据的去噪，从而通过条件扩散行为去噪减轻隐式反馈中噪声的影响。最后，通过引入多专家兴趣提取层，M$^3$BSR显式建模跨行为和模态的共同和特定兴趣，以增强推荐性能。实验结果表明，M$^3$BSR在基准数据集上显著优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [290] [Human-Centered Human-AI Interaction (HC-HAII): A Human-Centered AI Perspective](https://arxiv.org/abs/2508.03969)
> *以人为本的人机交互 (HC-HAII)：一个人机交互的视角*

*Wei Xu* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 人机交互, 以人为本AI, HC-HAII, 框架, 方法论

**Comment:** 

> **TL;DR:** 本章从以人为本的AI视角系统地推广了人机交互(HAII)这一新兴的跨学科领域，并提出了以人为本的HAII(HC-HAII)框架、方法论、研究挑战和未来方向，旨在为后续章节奠定基础。

**AI_Comments:** 本文创新性地提出了“以人为本的人机交互（HC-HAII）”概念，强调了在AI发展中将人类置于核心的重要性，这对于避免技术中心主义带来的潜在问题具有指导意义。其提出的框架和方法论为HAII领域的未来研究和实践提供了坚实的基础，特别是在构建负责任和有益的AI系统方面。

<details>
  <summary>Details</summary>

**Motivation:** 本章旨在从以人为本的AI（HCAI）视角，系统地推广人机交互（HAII）这一新兴的跨学科领域，并提供一个关于HAII研究和应用的基础框架，为后续章节铺平道路。

**Method:** 本章引入了以人为本的人机交互（HC-HAII）框架，该框架将人类置于HAII研究和应用的核心，强调采用以人为本而非以技术为中心的方法。它还提出了HC-HAII方法论，包括以人为本的方法、过程、跨学科团队和多层次设计范式。

**Result:** 本章系统地推广了人机交互（HAII）这一新兴的跨学科领域，并提出了以人为本的人机交互（HC-HAII）框架和方法论。它还概述了本书的结构，汇集了来自跨学科研究人员和从业者的贡献，以推进HCAI在HAII各个领域的理论、方法和应用。

**Conclusion:** 本章为本书提供了一个基础框架，其核心是以HCAI方法为基础的HAII研究和应用，旨在为后续章节的内容铺平道路。

> **ai_Abstract:** 本章从以人为本的AI（HCAI）视角，系统地推广了新兴的跨学科领域——人机交互（HAII）。它提出了以人为本的人机交互（HC-HAII）框架，强调将人类置于HAII研究和应用的核心，并详细介绍了其方法论。此外，本章还指出了主要研究挑战和未来方向，并作为全书的开篇，为后续章节的HAII研究奠定了理论和方法基础。

> **摘要翻译:** 本章从以人为本的人工智能（HCAI）视角系统地推广了人机交互（HAII）这一新兴的跨学科领域。它介绍了以人为本的人机交互（HC-HAII）框架。HC-HAII将人类置于HAII研究和应用的核心，强调采用以人为本而非以技术为中心的方法的重要性。本章提出了HC-HAII方法论，包括以人为本的方法、过程、跨学科团队和多层次设计范式。它还强调了关键的研究挑战和未来方向。作为第一章，本章还提供了本书的结构概述，本书汇集了来自跨学科研究人员和从业者的贡献，旨在推进HCAI在HAII不同领域的理论、方法和应用。本章的目的是为本书提供一个基础框架，该框架以HCAI方法为基础，以HAII研究和应用为中心，这将为后续章节的内容铺平道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [295] [TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring](https://arxiv.org/abs/2508.04943)
> *TRKT：基于时间增强关系感知知识迁移的弱监督动态场景图生成*

*Zhu Xu, Ting Lei, Zhimin Li, Guan Wang, Qingchao Chen, Yuxin Peng, Yang liu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 动态场景图生成, 弱监督, 知识迁移, 关系感知, 时间增强

**Comment:** 

> **TL;DR:** TRKT提出了一种弱监督动态场景图生成方法，通过关系感知知识挖掘和双流融合模块解决了外部目标检测器在动态场景中的不足。

**AI_Comments:** TRKT的创新点在于通过引入关系感知知识挖掘和利用时间信息（光流）来增强弱监督DSGG中的目标检测，有效弥补了外部静态检测器在动态场景中的不足。这种方法能够更准确地定位对象并提高置信度，对于减少DSGG的标注成本和提升其在复杂动态环境中的应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有弱监督动态场景图生成（WS-DSGG）方法依赖的外部目标检测器在动态、关系感知场景中表现不佳，导致对象定位不准确和提案置信度低。

**Method:** 提出了一种时间增强关系感知知识迁移（TRKT）方法，旨在增强关系感知动态场景中的检测。TRKT包含两个关键组件：1. 关系感知知识挖掘：利用对象和关系类别解码器生成类别特定注意力图，并通过帧间注意力增强策略利用光流增强注意力图，使其具有运动感知性。2. 双流融合模块：将类别特定注意力图整合到外部检测中，以改进对象定位并提高对象提案的置信度。

**Result:** TRKT在Action Genome数据集上取得了最先进的性能。

**Conclusion:** TRKT有效解决了弱监督动态场景图生成中外部目标检测器面临的挑战，并通过结合关系感知知识和时间信息显著提升了性能。

> **ai_Abstract:** 本文提出TRKT，一种用于弱监督动态场景图生成的方法。针对现有方法中外部目标检测器在动态场景下性能不佳的问题，TRKT通过关系感知知识挖掘和双流融合模块，利用类别特定注意力图和时间信息来增强目标检测的准确性和置信度。实验证明TRKT在Action Genome数据集上达到了SOTA性能。

> **摘要翻译:** 动态场景图生成（DSGG）旨在通过检测对象和预测它们的关系来为每个视频帧创建场景图。弱监督DSGG（WS-DSGG）通过使用每个视频的单帧未定位场景图进行训练，减少了标注工作量。现有的WS-DSGG方法依赖现成的外部目标检测器为后续的DSGG训练生成伪标签。然而，在静态、以对象为中心的图像上训练的检测器在DSGG所需的动态、关系感知场景中表现不佳，导致定位不准确和低置信度建议。为了解决外部目标检测器在WS-DSGG中带来的挑战，我们提出了一种时间增强关系感知知识迁移（TRKT）方法，该方法利用知识来增强关系感知动态场景中的检测。TRKT建立在两个关键组件上：（1）关系感知知识挖掘：我们首先采用对象和关系类别解码器，生成类别特定注意力图，以突出对象区域和交互区域。然后我们提出了一种帧间注意力增强策略，利用相邻帧的光流来增强注意力图，使其具有运动感知性并对运动模糊具有鲁棒性。这一步为WS-DSGG提供了关系和运动感知知识挖掘。（2）我们引入了一个双流融合模块，将类别特定注意力图整合到外部检测中，以改进对象定位并提高对象建议的置信度。大量的实验表明，TRKT在Action Genome数据集上取得了最先进的性能。我们的代码可在https://github.com/XZPKU/TRKT.git获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [296] [PriorRG: Prior-Guided Contrastive Pre-training and Coarse-to-Fine Decoding for Chest X-ray Report Generation](https://arxiv.org/abs/2508.05353)
> *PriorRG：先验引导对比预训练和粗到细解码用于胸部X射线报告生成*

*Kang Liu, Zhuoqi Ma, Zikang Fang, Yunan Li, Kun Xie, Qiguang Miao* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 胸部X射线报告生成, 先验知识, 对比预训练, 粗到细解码, 医疗图像分析

**Comment:** 

> **TL;DR:** PriorRG是一个新的胸部X射线报告生成框架，通过两阶段训练，利用患者特定的先验知识，显著提高了报告的临床准确性和流畅性，在MIMIC-CXR和MIMIC-ABN数据集上超越了现有SOTA方法。

**AI_Comments:** 该论文的创新点在于其两阶段的训练管道和对患者特定先验知识的有效利用，这在胸部X射线报告生成领域是关键但未被充分探索的。通过模拟真实世界的临床工作流程，PriorRG能够更好地捕获诊断意图和疾病进展，从而显著提高生成报告的临床准确性和流畅性。其性能提升在实际应用中具有重要意义，有助于减轻放射科医生的工作量并提高诊断效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的胸部X射线报告生成方法大多从单张图像生成报告，忽略了放射科医生诊断推理中依赖的患者特定先验知识（如临床背景、最新先验图像），导致无法捕获诊断意图或疾病进展。本研究旨在弥补这一空白，有效利用先验信息以生成高质量的初步报告，减轻放射科医生的工作量。

**Method:** 本研究提出了PriorRG框架，通过两阶段训练模拟真实临床工作流程。第一阶段引入了先验引导对比预训练方案，利用临床背景指导时空特征提取，使模型与放射学报告的内在时空语义更紧密对齐。第二阶段提出了先验感知粗到细解码用于报告生成，逐步将患者特定先验知识与视觉编码器的隐藏状态相结合，使模型与诊断焦点对齐并跟踪疾病进展。

**Result:** 在MIMIC-CXR和MIMIC-ABN数据集上的广泛实验表明，PriorRG优于现有最先进的方法，在MIMIC-CXR上实现了BLEU-4提高3.6%和F1分数提高3.8%，在MIMIC-ABN上实现了BLEU-1提高5.9%。

**Conclusion:** PriorRG通过有效利用患者特定的先验知识，显著提高了胸部X射线报告生成的临床准确性和流畅性，证明了其在自动化高质量报告生成方面的优越性。

> **ai_Abstract:** 本论文提出了PriorRG，一个用于胸部X射线报告生成的新型框架，旨在通过整合患者特定的先验知识（如临床背景和既往图像）来提高报告质量。现有的方法常忽略这些关键的先验信息。PriorRG采用两阶段训练管道：第一阶段是先验引导的对比预训练，用于提取与放射学语义对齐的时空特征；第二阶段是先验感知的粗到细解码，用于逐步整合先验知识以增强诊断准确性和报告流畅性。实验结果表明，PriorRG在MIMIC-CXR和MIMIC-ABN数据集上显著优于现有SOTA方法，证明了其在自动化高质量临床报告方面的潜力。

> **摘要翻译:** 胸部X射线报告生成旨在通过自动生成高质量的初步报告来减轻放射科医生的工作量。这项任务的一个关键但尚未充分探索的方面是有效利用患者特定的先验知识——包括临床背景（例如症状、病史）和最新的先验图像——放射科医生在诊断推理中常规依赖这些知识。大多数现有方法从单张图像生成报告，忽略了这些重要的先验信息，因此未能捕获诊断意图或疾病进展。为了弥补这一差距，我们提出了PriorRG，一个新颖的胸部X射线报告生成框架，它通过两阶段训练管道模拟真实世界的临床工作流程。在第一阶段，我们引入了一种先验引导的对比预训练方案，该方案利用临床背景指导时空特征提取，使模型能够更紧密地与放射学报告中固有的时空语义对齐。在第二阶段，我们提出了一种先验感知的粗到细解码方法用于报告生成，该方法逐步将患者特定的先验知识与视觉编码器的隐藏状态相结合。这种解码方式使模型能够与诊断焦点对齐并跟踪疾病进展，从而提高生成报告的临床准确性和流畅性。在MIMIC-CXR和MIMIC-ABN数据集上进行的广泛实验表明，PriorRG优于现有最先进的方法，在MIMIC-CXR上实现了3.6%的BLEU-4和3.8%的F1分数提升，在MIMIC-ABN上实现了5.9%的BLEU-1提升。代码和检查点将在接收后发布。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [297] [Unlocking the Potential of MLLMs in Referring Expression Segmentation via a Light-weight Mask Decoder](https://arxiv.org/abs/2508.04107)
> *通过轻量级掩码解码器释放多模态大模型在指代表达分割中的潜力*

*Jingchao Wang, Zhijian Wu, Dingjiang Huang, Yefeng Zheng, Hong Wang* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 指代表达分割, 多模态大模型, 轻量级掩码解码器, 特征融合, MLLMSeg

**Comment:** 

> **TL;DR:** 本文提出MLLMSeg，一个轻量级框架，通过利用多模态大模型固有的视觉细节特征和创新的特征融合模块，在指代表达分割任务中实现高性能和低成本的平衡。

**AI_Comments:** 该论文提出了一种创新的方法来解决多模态大模型在像素级密集预测方面的固有挑战，特别是针对指代表达分割任务。其核心创新在于巧妙地利用了MLLM内部的视觉细节特征，并设计了一个高效的特征融合模块和一个轻量级掩码解码器，从而在性能和计算成本之间取得了显著的平衡。这对于推动MLLMs在实际应用中的部署具有重要意义，因为它避免了对额外大型模型的依赖，降低了资源消耗。

<details>
  <summary>Details</summary>

**Motivation:** 现有的指代表达分割（RES）方法在使用多模态大模型（MLLMs）时，要么依赖参数量庞大的SAM模型牺牲效率，要么采用轻量级但牺牲准确性的无SAM流水线。为了解决性能和成本之间的权衡问题，本文旨在开发一种更有效的解决方案。

**Method:** 本文提出了MLLMSeg框架，它充分利用了MLLM视觉编码器中固有的视觉细节特征，无需引入额外的视觉编码器。此外，还提出了一个细节增强和语义一致的特征融合模块（DSFF），将细节相关的视觉特征与LLM输出的语义相关特征充分整合。最后，建立了一个仅34M参数的轻量级掩码解码器，该解码器最佳地利用了视觉编码器的详细空间特征和LLM的语义特征，以实现精确的掩码预测。

**Result:** 广泛的实验表明，本文提出的方法通常优于基于SAM和无SAM的竞争对手，在性能和成本之间取得了更好的平衡。

**Conclusion:** MLLMSeg框架通过创新的轻量级设计和特征融合策略，成功解决了指代表达分割中性能与成本的权衡问题，实现了卓越的分割精度。

> **ai_Abstract:** 本文针对指代表达分割（RES）任务中多模态大模型（MLLMs）在像素级预测上的不足以及现有方法在性能与成本之间的权衡问题，提出了一个名为MLLMSeg的新型轻量级框架。MLLMSeg通过直接利用MLLM视觉编码器中的细节特征，并引入细节增强和语义一致的特征融合模块（DSFF），将视觉细节与LLM的语义信息有效结合。最终，一个仅34M参数的轻量级掩码解码器用于精确预测。实验证明，MLLMSeg在保持高性能的同时显著降低了成本，优于现有基于SAM和无SAM的竞争方法。

> **摘要翻译:** 指代表达分割（RES）旨在分割由指代表达指定的图像区域，并随着多模态大模型（MLLMs）的兴起而变得流行。虽然MLLMs在语义理解方面表现出色，但其token生成范式在像素级密集预测方面存在困难。现有的RES方法要么将MLLMs与参数量巨大的Segment Anything Model（SAM）（6.32亿网络参数）耦合，要么采用牺牲准确性的无SAM轻量级流水线。为了解决性能和成本之间的权衡问题，我们专门提出了MLLMSeg，这是一个新颖的框架，它充分利用了MLLM视觉编码器中固有的视觉细节特征，而无需引入额外的视觉编码器。此外，我们提出了一个细节增强和语义一致的特征融合模块（DSFF），它充分整合了细节相关的视觉特征与MLLM中大型语言模型（LLM）输出的语义相关特征。最后，我们建立了一个仅有34M网络参数的轻量级掩码解码器，该解码器最佳地利用了视觉编码器的详细空间特征和LLM的语义特征，以实现精确的掩码预测。广泛的实验表明，我们的方法通常优于基于SAM和无SAM的竞争对手，在性能和成本之间取得了更好的平衡。代码可在https://github.com/jcwang0602/MLLMSeg 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [302] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
> *迈向鲁棒的视觉活动识别评估：通过语义聚类解决动词歧义*

*Louie Hong Yao, Nicholas Jarvis, Tianyu Jiang* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉活动识别, 动词歧义, 语义聚类, 评估, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种视觉语言聚类框架，通过构建动词语义簇来解决视觉活动识别中动词语义和图像解释的模糊性，从而提供更鲁棒的模型评估，并且该方法与人类判断更一致。

**AI_Comments:** 本文的创新点在于提出了一个视觉语言聚类框架，通过解决动词语义歧义性来改进视觉活动识别的评估方法。这对于提高评估的鲁棒性和与人类判断的一致性具有重要意义，克服了传统评估方法中单一黄金答案的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 评估视觉活动识别系统面临挑战，因为动词语义和图像解释存在固有的歧义。标准精确匹配评估依赖单一黄金答案，无法捕捉这些歧义，导致模型性能评估不完整。

**Method:** 提出了一种视觉语言聚类框架，该框架构建动词语义簇，以提供更鲁棒的评估。

**Result:** 对imSitu数据集的分析表明，每张图像平均映射到2.8个语义簇，每个簇代表图像的不同视角。通过该方法评估了多个活动识别模型，并与标准评估方法进行了比较。人类对齐分析表明，基于聚类的评估与人类判断更一致。

**Conclusion:** 基于语义簇的评估方法能够更好地捕捉视觉活动识别中的歧义，提供更细致的模型性能评估，并且与人类判断更一致，从而实现了更鲁棒的评估。

> **ai_Abstract:** 本文针对视觉活动识别系统评估中动词语义和图像解释的固有歧义问题，提出了一种创新的视觉语言聚类框架。该框架通过构建动词语义簇来解决标准精确匹配评估的不足，从而提供更鲁棒、更细致的模型性能评估。研究表明，在imSitu数据集上，每张图像平均映射到2.8个语义簇，且该聚类评估方法与人类判断更为一致。

> **摘要翻译:** 评估视觉活动识别系统具有挑战性，原因在于动词语义和图像解释中固有的歧义。在描述图像中的动作时，同义动词可以指代同一事件（例如，刷牙与梳理），而不同的视角可能导致同样有效但不同的动词选择（例如，驾驶与操作）。标准的精确匹配评估依赖于单一的黄金答案，未能捕捉这些歧义，导致对模型性能的评估不完整。为了解决这个问题，我们提出了一种视觉语言聚类框架，该框架构建动词语义簇，提供更鲁棒的评估。我们对imSitu数据集的分析表明，每张图像平均映射到2.8个语义簇，每个簇代表图像的不同视角。我们评估了多个活动识别模型，并将我们基于聚类的评估与标准评估方法进行了比较。此外，我们的人类对齐分析表明，基于聚类的评估与人类判断更好地对齐，提供了对模型性能更细致的评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [303] [Building Effective Safety Guardrails in AI Education Tools](https://arxiv.org/abs/2508.05360)
> *在人工智能教育工具中构建有效的安全护栏*

*Hannah-Beth Clark, Laura Benton, Emma Searle, Margaux Dowland, Matthew Gregory, Will Gayne, John Roberts* | **Category: cs.AI, cs.CY** | **Updated: 2025-08-07**

**Keywords:** AI教育, 安全护栏, 生成式AI, 内容审核, 教师工具

**Comment:** 

> **TL;DR:** 鉴于生成式AI工具在教育领域的快速发展和教师的广泛采用，本研究关注AI生成内容的安全性和年龄适宜性问题。论文详细介绍了Oak National Academy在开发英国政府首个AI课程规划助手Aila时实施的四项关键安全护栏，并通过持续评估发现了实施和测试安全护栏的挑战与机遇，最终提出通过持续迭代和跨领域合作来构建更有效安全护栏的方法。

**AI_Comments:** 该论文探讨了在教育领域应用生成式AI工具时至关重要的安全问题，具有现实意义。其创新之处在于详细阐述了四项具体的安全护栏实施方案，为其他类似工具的开发提供了实践参考。强调持续迭代和跨领域协作的重要性，体现了对AI安全治理的动态和开放性思考。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI工具在教育领域的快速发展和广泛采用引发了对其生成内容的安全性和年龄适宜性的担忧，本研究旨在解决这些问题。

**Method:** 本研究探讨了Oak National Academy在开发英国政府首个公开可用的生成式AI工具——AI课程规划助手Aila时所采用的方法。该方法包括实施四项关键安全护栏：1) 提示工程，确保AI输出符合教学法和课程要求；2) 输入威胁检测，以减轻攻击；3) 独立异步内容审核代理（IACMA），根据预定义的安全类别评估输出；4) 采用人工干预方法，鼓励教师在使用前审查生成内容。

**Result:** 通过对这些安全护栏的持续评估，研究确定了在实施和测试安全护栏时需要考虑的若干挑战和机遇。

**Conclusion:** 本论文强调了在生成式AI教育工具中构建更有效安全护栏的方法，包括护栏的持续迭代和完善，以及通过共享开源代码、数据集和学习经验来促进跨部门协作。

> **ai_Abstract:** 本论文旨在解决生成式AI工具在教育领域快速普及所带来的内容安全性和年龄适宜性问题。文章详细介绍了Oak National Academy在开发AI课程规划助手Aila时所采取的四项关键安全护栏措施，包括提示工程、输入威胁检测、独立内容审核和人工干预。通过对这些护栏的持续评估，研究揭示了实施和测试安全措施所面临的挑战与机遇，并提出了通过持续迭代和跨领域合作来构建更有效安全护栏的建议。

> **摘要翻译:** 生成式AI工具在教育领域发展迅速，这反过来也导致教师的采用率增加。然而，这也引发了人们对课堂上使用的AI生成内容的安全性和年龄适宜性的担忧。本文探讨了Oak National Academy在开发英国政府首个公开可用的生成式AI工具——我们的AI驱动课程规划助手（Aila）时，如何应对这些担忧。Aila旨在支持教师规划符合国家课程、适合5-16岁学生使用的课程。为了减轻AI生成内容相关的安全风险，我们实施了四个关键安全护栏：(1) 提示工程，以确保AI输出在教学合理和课程对齐的参数范围内生成；(2) 输入威胁检测，以减轻攻击；(3) 独立异步内容审核代理（IACMA），根据预定义的安全类别评估输出；(4) 采用人工干预方法，鼓励教师在使用前审查生成内容。通过对这些安全护栏的持续评估，我们发现了在实施和测试安全护栏时需要考虑的若干挑战和机遇。本文强调了在生成式AI教育工具中构建更有效安全护栏的方法，包括护栏的持续迭代和完善，以及通过共享开源代码、数据集和学习经验来促进跨部门协作。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [304] [Symmetric Behavior Regularization via Taylor Expansion of Symmetry](https://arxiv.org/abs/2508.04225)
> *对称性泰勒展开的行为正则化*

*Lingwei Zhu, Zheng Chen, Han Wang, Yukie Nagai* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 对称散度, 行为正则化策略优化, 离线强化学习, 泰勒展开, S$f$-AC

**Comment:** 

> **TL;DR:** 本文提出了一种新的离线强化学习框架S$f$-AC，通过泰勒展开解决对称散度在行为正则化策略优化中的解析策略和数值问题，并在实验中表现出竞争力。

**AI_Comments:** 本文的创新点在于首次将对称散度引入行为正则化策略优化，并巧妙地利用泰勒展开解决了对称散度带来的解析策略获取和数值稳定性问题。这为离线强化学习提供了一个新的视角和实用的算法，拓宽了BRPO中散度的选择范围，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有行为正则化策略优化（BRPO）方法主要使用非对称散度，而对称散度在作为正则化时无法得到解析策略，并且在作为损失时会引起数值问题。

**Method:** 论文通过f-散度的泰勒级数来解决这些挑战。具体来说，证明了通过有限级数可以获得解析策略。对于损失函数，观察到对称散度可以分解为非对称项和条件对称项，对后者进行泰勒展开可以缓解数值问题。基于此，提出了Symmetric $f$ Actor-Critic (S$f$-AC) 算法。

**Result:** S$f$-AC在分布近似和MuJoCo上的实验结果验证了其具有竞争力。

**Conclusion:** S$f$-AC是首个使用对称散度的实用BRPO算法，通过泰勒展开成功克服了对称散度在离线强化学习中的挑战，并取得了良好的性能。

> **ai_Abstract:** 本文提出了一种新的离线强化学习框架，将对称散度引入行为正则化策略优化（BRPO）。针对对称散度无法获得解析策略和存在数值问题，作者通过f-散度的泰勒级数展开来解决。研究表明，有限级数可以得到解析策略；通过将对称散度分解并泰勒展开其条件对称项，可以缓解数值问题。基于此，论文提出了首个使用对称散度的实用BRPO算法Symmetric $f$ Actor-Critic (S$f$-AC)，并在实验中验证了其竞争力。

> **摘要翻译:** 本文介绍了将对称散度引入行为正则化策略优化（BRPO），以建立一个新的离线强化学习框架。现有方法侧重于非对称散度（如KL散度）来获得解析正则化策略和实际的最小化目标。我们发现对称散度不允许作为正则化的解析策略，并且作为损失时可能导致数值问题。我们通过f-散度的泰勒级数来解决这些挑战。具体来说，我们证明了通过有限级数可以获得解析策略。对于损失，我们观察到对称散度可以分解为非对称项和条件对称项，对后者进行泰勒展开可以缓解数值问题。综上所述，我们提出了Symmetric $f$ Actor-Critic (S$f$-AC)，这是第一个使用对称散度的实用BRPO算法。在分布近似和MuJoCo上的实验结果验证了S$f$-AC具有竞争力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [309] [Tesserae: Scalable Placement Policies for Deep Learning Workloads](https://arxiv.org/abs/2508.04953)
> *Tesserae：深度学习工作负载的可扩展放置策略*

*Song Bian, Saurabh Agarwal, Md. Tareq Mahmood, Shivaram Venkataraman* | **Category: cs.AI, cs.DC** | **Updated: 2025-08-07**

**Keywords:** 深度学习, 集群调度, 放置策略, 图匹配, GPU

**Comment:** 

> **TL;DR:** Tesserae是一个新的GPU集群调度器，它使用图匹配来制定放置策略，从而显著提高了深度学习工作负载的资源利用率，超越了现有调度器。

**AI_Comments:** Tesserae的创新点在于将深度学习工作负载的放置问题转化为图匹配问题，提供了一种系统性的解决方案，而非依赖于临时启发式方法。其可扩展性和性能提升对于数据中心中日益增长的深度学习任务至关重要，有望提高资源利用率并缩短模型训练周期。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习集群调度器的放置策略（无论是临时启发式方法还是复杂优化问题中的约束）都存在性能不佳或可扩展性差的问题，导致资源利用率低下。

**Method:** 论文提出将许多放置约束表述为图匹配问题，并在此基础上设计了新颖的放置策略，以最小化作业迁移开销和实现作业打包。这些策略被集成到Tesserae中，形成一个可扩展且有效的GPU集群调度器。

**Result:** 与现有调度器相比，Tesserae将平均JCT（作业完成时间）提高了1.62倍，并将Makespan（完工时间）提高了1.15倍。

**Conclusion:** Tesserae通过将放置约束表述为图匹配问题并设计新的放置策略，成功构建了一个可扩展且高效的GPU集群调度器，显著提升了深度学习工作负载的性能。

> **ai_Abstract:** 该论文提出了Tesserae，一个针对深度学习工作负载的GPU集群调度器，旨在解决现有放置策略在性能和可扩展性上的不足。通过将放置约束重新构想为图匹配问题，Tesserae设计了新颖的策略来减少作业迁移开销并优化作业打包。实验结果表明，与现有调度器相比，Tesserae显著提高了平均作业完成时间（JCT）和完工时间（Makespan）。

> **摘要翻译:** 训练深度学习（DL）模型已成为数据中心的主要工作负载，提高资源利用率是DL集群调度器的关键目标。为了实现这一目标，调度器通常会整合放置策略，以管理作业在集群中的放置位置。现有的放置策略要么是临时启发式设计，要么作为复杂优化问题中的约束条件，因此要么性能不佳，要么可扩展性差。我们的关键见解是，许多放置约束可以被表述为图匹配问题，并在此基础上，我们设计了新颖的放置策略，以最小化作业迁移开销和实现作业打包。我们将这些策略集成到Tesserae中，并描述了我们的设计如何实现一个可扩展且有效的GPU集群调度器。我们的实验结果表明，与现有调度器相比，Tesserae将平均JCT（作业完成时间）提高了1.62倍，并将Makespan（完工时间）提高了1.15倍。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [310] [Optimal Corpus Aware Training for Neural Machine Translation](https://arxiv.org/abs/2508.05364)
> *神经机器翻译中的最优语料库感知训练*

*Yi-Hsiu Liao, Cheng Shen, Brenda, Yang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 神经机器翻译, 语料库感知训练, 微调, OCAT, chrF

**Comment:** 

> **TL;DR:** 提出最优语料库感知训练（OCAT），通过微调预训练模型并仅调整少量参数，有效提升神经机器翻译精度，且轻量化、抗过拟合。

**AI_Comments:** OCAT的创新点在于其轻量级的微调策略，通过冻结大部分参数并只调整少量与语料库相关的参数，解决了传统CAT方法中数据预定义的问题。这种方法提高了训练效率和模型鲁棒性，同时保持了高精度，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语料库感知训练（CAT）方法在训练前预定义高质量数据，这可能导致错误且效率低下。

**Method:** 提出最优语料库感知训练（OCAT），通过冻结预训练CAT模型的大部分参数，仅微调一小组与语料库相关的参数。

**Result:** OCAT轻量、抗过拟合，并能有效提升模型精度。在WMT23英译中和英译德任务中，相较于普通训练分别提升了3.6和1.8的chrF分数。此外，该方法与SOTA微调技术相当或略优，且对超参数设置不敏感。

**Conclusion:** OCAT是一种轻量、高效且鲁棒的微调策略，能显著提升神经机器翻译模型的性能，并克服了传统CAT方法的局限性。

> **ai_Abstract:** 本文提出最优语料库感知训练（OCAT），旨在解决传统语料库感知训练（CAT）中预定义高质量数据效率低下和易出错的问题。OCAT通过微调预训练的CAT模型，冻结大部分参数，仅调整少量与语料库相关的参数。实验证明，OCAT不仅轻量、抗过拟合，还能显著提升神经机器翻译的准确性，在WMT23英译中和英译德任务中分别带来3.6和1.8的chrF提升，并且性能与现有先进微调技术相当或更优，同时对超参数不敏感。

> **摘要翻译:** 语料库感知训练（CAT）通过将语料库信息注入每个训练样本，在训练过程中利用宝贵的语料库元数据，并已被文献证明有效，通常被称为“标签”方法。使用CAT训练的模型能够直接从数据中学习语料库之间的质量、领域和细微差别，并且可以轻松切换到不同的推理行为。为了获得最佳评估，CAT模型在训练开始前预定义一组高质量数据，这可能容易出错且效率低下。在这项工作中，我们提出了最优语料库感知训练（OCAT），通过冻结大部分模型参数并仅调整一小组与语料库相关的参数来微调CAT预训练模型。我们表明OCAT轻量化、抗过拟合，并且能有效提升模型精度。我们使用WMT23英语到中文和英语到德语翻译任务作为测试平台，结果显示相较于普通训练分别提升了3.6和1.8的chrF分数。此外，我们的方法与其它最先进的微调技术相当或略优，同时对超参数设置的敏感度较低。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [312] [A Comprehensive Framework for Uncertainty Quantification of Voxel-wise Supervised Models in IVIM MRI](https://arxiv.org/abs/2508.04588)
> *IVIM MRI体素级监督模型不确定性量化的综合框架*

*Nicola Casali, Alessandro Brusaferri, Giuseppe Baselli, Stefano Fumagalli, Edoardo Micotti, Gianluigi Forloni, Riaz Hussein, Giovanna Rizzo, Alfonso Mastropietro* | **Category: cs.AI, cs.LG, eess.IV** | **Updated: 2025-08-07**

**Keywords:** IVIM MRI, 不确定性量化, 深度学习, 混合密度网络, 深度集成

**Comment:** 

> **TL;DR:** 针对IVIM MRI提出一种基于深度集成混合密度网络的不确定性量化框架，提高了参数估计的可靠性。

**AI_Comments:** 该论文的创新之处在于使用深度集成混合密度网络，不仅量化总不确定性，还将其分解为偶然不确定性和认知不确定性，用于IVIM MRI，这对于在临床相关背景下识别不可靠的估计至关重要。这种全面的不确定性量化增强了模型预测的可信度和可解释性，特别是对于IVIM这种具有挑战性的逆问题。该方法可推广到其他物理模型也是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 由于逆问题的病态性质以及对噪声的高度敏感性，特别是灌注室中的噪声，从扩散加权MRI中准确估计体素内非相干运动（IVIM）参数仍然具有挑战性。

**Method:** 提出了一种基于深度集成（DE）混合密度网络（MDN）的概率深度学习框架，能够估计总预测不确定性并将其分解为偶然不确定性（AU）和认知不确定性（EU）分量。在合成数据上进行监督训练，并在模拟和体内数据集上进行评估。使用校准曲线、输出分布尖锐度和连续排序概率评分（CRPS）评估量化不确定性的可靠性。

**Result:** MDN为扩散系数D和分数f参数产生了更校准和更尖锐的预测分布，尽管在伪扩散系数D*中观察到轻微的过度自信。鲁棒变异系数（RCV）表明，与高斯模型相比，MDN对D*的体内估计更平滑。尽管训练数据涵盖了预期的生理范围，但体内EU升高表明与实际采集条件不匹配，这突出了结合EU的重要性，而DE允许了这一点。

**Conclusion:** 总的来说，本文提出了一个用于IVIM拟合的综合不确定性量化框架，该框架能够识别和解释不可靠的估计。所提出的方法也可以通过适当的架构和模拟调整来用于拟合其他物理模型。

> **ai_Abstract:** 本文提出了一种基于深度集成混合密度网络（MDN）的概率深度学习框架，用于准确估计MRI中的体素内非相干运动（IVIM）参数，解决了逆问题病态性和噪声敏感性等挑战。该框架量化并将预测不确定性分解为偶然不确定性和认知不确定性。在合成、模拟和体内数据集上与其他方法进行基准测试后，MDN显示出对D和f参数的更好校准和尖锐度，以及更平滑的D*估计，并强调了认知不确定性对于识别不可靠估计的重要性，表明该方法可广泛应用于其他物理模型。

> **摘要翻译:** 由于逆问题的病态性质以及对噪声的高度敏感性，特别是灌注室中的噪声，从扩散加权MRI中准确估计体素内非相干运动（IVIM）参数仍然具有挑战性。在这项工作中，我们提出了一种基于深度集成（DE）混合密度网络（MDN）的概率深度学习框架，能够估计总预测不确定性并将其分解为偶然不确定性（AU）和认知不确定性（EU）分量。该方法与非概率神经网络、贝叶斯拟合方法以及具有单一高斯参数化的概率网络进行了基准测试。监督训练在合成数据上进行，并在模拟和体内数据集上进行评估。使用校准曲线、输出分布尖锐度和连续排序概率评分（CRPS）评估量化不确定性的可靠性。MDN为扩散系数D和分数f参数产生了更校准和更尖锐的预测分布，尽管在伪扩散系数D*中观察到轻微的过度自信。鲁棒变异系数（RCV）表明，与高斯模型相比，MDN对D*的体内估计更平滑。尽管训练数据涵盖了预期的生理范围，但体内EU升高表明与实际采集条件不匹配，这突出了结合EU的重要性，而DE允许了这一点。总的来说，我们提出了一个用于IVIM拟合的综合不确定性量化框架，该框架能够识别和解释不可靠的估计。所提出的方法也可以通过适当的架构和模拟调整来用于拟合其他物理模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [316] [AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics](https://arxiv.org/abs/2508.04955)
> *AdvDINO：用于空间蛋白质组学的域对抗自监督表示学习*

*Stella Su, Marc Harary, Scott J. Rodig, William Lotter* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 自监督学习, 域对抗, 空间蛋白质组学, DINOv2, 域偏移

**Comment:** 

> **TL;DR:** AdvDINO是一种域对抗自监督学习框架，通过将梯度反转层集成到DINOv2架构中，旨在学习领域不变的特征，以应对生物医学成像中批次效应导致的域偏移问题，并在非小细胞肺癌患者的多重免疫荧光图像上取得了显著效果，提高了生存预测能力。

**AI_Comments:** AdvDINO的创新之处在于将域对抗学习的思想融入到自监督学习框架DINOv2中，以解决生物医学图像中普遍存在的域偏移（批次效应）问题。这对于提高模型在真实世界复杂数据上的泛化能力和生物学解释性至关重要。该方法通过强制模型学习领域不变的特征，有效提升了表示的鲁棒性，并在临床预测任务中展现了潜力，对于推动自监督学习在医疗图像分析领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自监督学习（SSL）在视觉表示学习中表现出色，但其在数据源之间存在系统性差异（即域偏移）时（尤其是在生物医学成像中，批次效应可能掩盖真实的生物信号）的鲁棒性仍不确定，这构成了一个关键挑战。

**Method:** 本文提出了AdvDINO，一个域对抗自监督学习框架。该框架将梯度反转层集成到DINOv2架构中，以促进域不变特征的学习。

**Result:** AdvDINO在来自非小细胞肺癌患者的六通道多重免疫荧光（mIF）全玻片图像真实队列上应用，减轻了玻片特异性偏差，学习到了比非对抗基线更鲁棒、更具生物学意义的表示。在超过546万张mIF图像切片上，该模型揭示了具有独特蛋白质组学特征和预后意义的表型簇，并改进了基于注意力机制的多实例学习中的生存预测。

**Conclusion:** AdvDINO在mIF数据上得到了验证，但它广泛适用于其他成像领域，包括放射学、遥感和自动驾驶，在这些领域中，域偏移和有限的标注数据阻碍了模型的泛化和可解释性。

> **ai_Abstract:** 本文提出了AdvDINO，一个创新的域对抗自监督学习框架，旨在解决生物医学成像中因批次效应导致的域偏移问题。AdvDINO将梯度反转层集成到DINOv2架构中，以学习领域不变的特征。该方法在非小细胞肺癌患者的六通道多重免疫荧光图像上进行了验证，成功减轻了玻片特异性偏差，学习到更鲁棒、更具生物学意义的表示。实验结果表明，AdvDINO能发现具有预后意义的表型簇，并显著提升生存预测性能。此外，该框架具有广泛的适用性，可应用于其他存在域偏移和数据标注限制的成像领域。

> **摘要翻译:** 自监督学习（SSL）已成为一种强大的方法，无需手动标注即可学习视觉表示。然而，标准SSL方法对域偏移（数据源之间的系统性差异）的鲁棒性仍不确定，这在生物医学成像中构成了特别关键的挑战，因为批次效应可能掩盖真实的生物信号。我们提出了AdvDINO，一个域对抗自监督学习框架，它将梯度反转层集成到DINOv2架构中，以促进域不变特征的学习。应用于非小细胞肺癌患者的六通道多重免疫荧光（mIF）全玻片图像的真实队列，AdvDINO减轻了玻片特异性偏差，学习到了比非对抗基线更鲁棒、更具生物学意义的表示。在超过546万张mIF图像切片上，该模型揭示了具有独特蛋白质组学特征和预后意义的表型簇，并改进了基于注意力机制的多实例学习中的生存预测。虽然在mIF数据上得到了验证，但AdvDINO广泛适用于其他成像领域——包括放射学、遥感和自动驾驶——在这些领域中，域偏移和有限的标注数据阻碍了模型的泛化和可解释性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [317] [Echo: Decoupling Inference and Training for Large-Scale RL Alignment on Heterogeneous Swarms](https://arxiv.org/abs/2508.05387)
> *Echo：在异构集群上解耦推理和训练以实现大规模RL对齐*

*Jie Xiao, Shaoduo Gan, Changyuan Fan, Qingnan Ren, Alfred Long, Yuchen Zhang, Rymon Yu, Eric Yang, Lynn Ai* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 大型语言模型, 解耦, 异构集群, 分布式训练

**Comment:** 

> **TL;DR:** Echo系统解耦了LLM大规模RL训练中的推理与训练过程，使其能在异构硬件上运行，并在将采样卸载到边缘设备的同时保持与传统共置系统相当的性能。

**AI_Comments:** 本文的创新点在于成功地将大规模强化学习中LLM的推理和训练阶段解耦，并利用异构计算资源，特别是将轨迹生成卸载到廉价的边缘硬件上。这对于降低LLM RL训练的成本和提高其可扩展性具有重要意义，展示了去中心化资源实现数据中心级性能的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代基于强化学习（RL）的大型语言模型（LLM）后训练中，轨迹采样和策略优化共置于同一GPU集群，导致系统在推理和训练工作负载之间进行串行上下文切换。这种串行上下文切换违反了当前分布式训练系统所依赖的单程序多数据（SPMD）假设，从而降低了效率。

**Method:** 提出了Echo系统，该系统将推理和训练这两个阶段在异构的“推理”和“训练”集群中干净地解耦，同时保持统计效率。Echo引入了两种轻量级同步协议：一种是顺序拉取模式，每次API调用刷新采样器权重以最小化偏差；另一种是异步推拉模式，通过重放缓冲区流式传输带版本标签的回放数据以最大化硬件利用率。

**Result:** 在地理分布的集群上，使用Qwen3-4B、Qwen2.5-7B和Qwen3-32B训练了三个代表性RL工作负载。Echo在收敛速度和最终奖励方面与完全共置的Verl基线相当，同时成功将轨迹生成任务卸载到商用边缘硬件。

**Conclusion:** 大规模LLM的强化学习能够使用去中心化、异构的资源实现数据中心级别的性能。

> **ai_Abstract:** Echo系统旨在解决LLM大规模RL后训练中推理与训练共置导致的效率问题。它通过将这两个阶段解耦到异构的“推理”和“训练”集群上，并引入顺序拉取和异步推拉两种轻量级同步协议来优化性能和资源利用。实验证明，Echo在收敛速度和最终奖励上与传统共置系统相当，同时能将轨迹生成卸载到边缘硬件，表明去中心化、异构资源可以实现数据中心级的RL训练性能。

> **摘要翻译:** 现代基于强化学习（RL）的大型语言模型（LLM）后训练将轨迹采样和策略优化共置于同一GPU集群，迫使系统在推理和训练工作负载之间进行切换。这种串行上下文切换违反了当前分布式训练系统所依赖的单程序多数据（SPMD）假设。我们提出了Echo，这是一个RL系统，它在保持统计效率的同时，将这两个阶段在异构的“推理”和“训练”集群中干净地解耦。Echo引入了两种轻量级同步协议：一种是顺序拉取模式，每次API调用刷新采样器权重以最小化偏差；另一种是异步推拉模式，通过重放缓冲区流式传输带版本标签的回放数据以最大化硬件利用率。在地理分布的集群上，使用Qwen3-4B、Qwen2.5-7B和Qwen3-32B训练了三个代表性RL工作负载，Echo在收敛速度和最终奖励方面与完全共置的Verl基线相当，同时将轨迹生成任务卸载到商用边缘硬件。这些有希望的结果表明，用于LLM的大规模RL可以使用去中心化、异构的资源实现数据中心级别的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [318] [Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning](https://arxiv.org/abs/2508.04610)
> *神经形态网络安全与半监督终身学习*

*Md Zesun Ahmed Mia, Malyaban Bal, Sen Lu, George M. Nishibuchi, Suhas Chelian, Srini Vasan, Abhronil Sengupta* | **Category: cs.AI, cs.ET, cs.LG, cs.NE** | **Updated: 2025-08-07**

**Keywords:** 神经形态网络安全, 脉冲神经网络, 终身学习, 网络入侵检测系统, 灾难性遗忘

**Comment:** 

> **TL;DR:** 本文提出了一种受大脑启发的脉冲神经网络（SNN）架构，用于终身网络入侵检测系统（NIDS），能够增量学习新威胁并保持现有知识，在持续学习环境下表现出鲁棒的适应性和低功耗潜力。

**AI_Comments:** 这项研究的创新之处在于将SNN与终身学习范式相结合，应用于网络入侵检测，并引入了生物学上合理（bio-plausible）的机制（如GWR和Ad-STDP）来解决持续学习中的关键挑战，如灾难性遗忘。其在特定数据集上展示的性能和在神经形态硬件上低功耗部署的潜力，突显了其在未来网络安全领域的重要性和前景。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的灵感来源于大脑的层次处理和能量效率，旨在开发一种能够增量学习新威胁并保持现有知识的终身网络入侵检测系统（NIDS）。

**Method:** 本文提出了一种脉冲神经网络（SNN）架构，用于终身网络入侵检测系统。该系统首先使用一个高效的静态SNN识别潜在入侵，然后激活一个自适应动态SNN来分类特定攻击类型。动态分类器利用受“按需增长”（GWR）启发的结构可塑性以及一种新颖的自适应脉冲时间依赖可塑性（Ad-STDP）学习规则，以实现增量学习和知识保留。

**Result:** 该架构在UNSW-NB15基准测试的持续学习设置中进行了测试，表现出鲁棒的适应性，减少了灾难性遗忘，并达到了85.3%的总体准确率。此外，使用Intel Lava框架进行的仿真证实了高操作稀疏性，突出了其在神经形态硬件上低功耗部署的潜力。

**Conclusion:** 该研究成功开发了一种基于SNN的终身NIDS，它能够有效学习和适应新的网络威胁，同时保持现有知识，并具有在神经形态硬件上实现低功耗部署的巨大潜力。

> **ai_Abstract:** 本文提出了一种受大脑启发的脉冲神经网络（SNN）架构，用于构建终身网络入侵检测系统（NIDS）。该系统结合了静态SNN进行初步检测和动态SNN进行攻击分类，其中动态SNN通过GWR启发的结构可塑性和新型Ad-STDP学习规则实现增量学习和知识保留。在UNSW-NB15数据集上的持续学习测试表明，该架构具有强大的适应性、减少了灾难性遗忘，并达到了85.3%的准确率。此外，其高操作稀疏性预示着在神经形态硬件上低功耗部署的巨大潜力。

> **摘要翻译:** 受大脑层次处理和能效的启发，本文提出了一种用于终身网络入侵检测系统（NIDS）的脉冲神经网络（SNN）架构。所提出的系统首先采用一个高效的静态SNN来识别潜在入侵，然后激活一个自适应动态SNN负责分类特定攻击类型。为了模仿生物适应性，动态分类器利用受“按需增长”（GWR）启发的结构可塑性以及一种新颖的自适应脉冲时间依赖可塑性（Ad-STDP）学习规则。这些生物学上合理（bio-plausible）的机制使网络能够增量学习新威胁，同时保留现有知识。在持续学习设置下，该架构在UNSW-NB15基准测试中进行了测试，表现出鲁棒的适应性，减少了灾难性遗忘，并实现了85.3%的总体准确率。此外，使用Intel Lava框架进行的仿真证实了高操作稀疏性，突出了在神经形态硬件上低功耗部署的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [323] [MENDR: Manifold Explainable Neural Data Representations](https://arxiv.org/abs/2508.04956)
> *MENDR：流形可解释神经数据表示*

*Matthew Chen, Micky Nnamdi, Justin Shao, Andrew Hornback, Hongyun Huang, Ben Tamo, Yishan Zhong, Benoit Marteau, Wenqi Shi, May Dongmei Wang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 脑电图, 基础模型, 可解释性, 黎曼流形, Transformer

**Comment:** 

> **TL;DR:** MENDR是一个基于黎曼流形Transformer的脑电图基础模型，通过学习可解释的对称正定矩阵嵌入，提高了透明度和性能，并实现了高效、可解释的临床应用。

**AI_Comments:** MENDR的创新之处在于其结合了黎曼流形几何与Transformer架构，并引入对称正定矩阵作为脑电信号的表示，这为脑电信号的解释性分析提供了新的视角。通过可视化几何椭球体和支持信号重建，MENDR显著提升了模型的可解释性，这是当前许多深度学习模型所欠缺的。此外，其在保持高性能的同时显著减少参数量，也使其在实际临床应用中更具吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑电图基础模型在预训练动态方面缺乏透明度，对脑电图信息在嵌入中的保留程度洞察有限，且主要在时域操作，忽视了数字信号处理（如小波）的进展，这阻碍了它们在临床上的成功整合。

**Method:** 论文提出了MENDR（Manifold Explainable Neural Data Representations），一个基于滤波器组的脑电图基础模型。它构建在一种新颖的黎曼流形Transformer架构之上，学习脑电信号的对称正定矩阵嵌入。MENDR在超过4000小时的脑电数据语料库上进行预训练，这些数据通过离散小波包变换分解为多分辨率系数。

**Result:** MENDR通过将对称正定嵌入可视化为几何椭球体，显著增强了可解释性，并支持从学习到的嵌入中准确重建脑电信号。在多项临床脑电任务中，MENDR以显著更少的参数实现了接近最先进的性能。

**Conclusion:** MENDR展示了其在高效、可解释和临床适用的脑电分析方面的潜力，解决了当前脑电基础模型在透明度和可解释性方面的不足。

> **ai_Abstract:** 本文提出了MENDR，一个基于黎曼流形Transformer的脑电图基础模型，旨在解决现有模型在透明度和可解释性方面的不足。MENDR学习脑电信号的对称正定矩阵嵌入，并利用小波变换分解的数据进行预训练。该模型通过可视化几何椭球体增强了可解释性，并支持信号重建。实验证明，MENDR在多个临床任务中以更少的参数实现了接近最先进的性能，展现了其在高效、可解释和临床应用方面的巨大潜力。

> **摘要翻译:** 脑电图（EEG）信号的基础模型最近在学习脑电图的广义表示方面取得了成功，在各种下游任务中超越了专用模型。然而，这些模型中的许多缺乏预训练动态的透明度，并且对脑电图信息在其嵌入中保留的程度提供有限的洞察。为了成功的临床整合，脑电图基础模型必须确保预训练、下游微调以及学习表示的可解释性方面的透明度。当前的方法主要在时域操作，忽视了数字信号处理的进步，这些进步能够提取确定性和可追溯的特征，例如基于小波的表示。我们提出了MENDR（Manifold Explainable Neural Data Representations），一个基于滤波器组的脑电图基础模型，它建立在一种新颖的黎曼流形Transformer架构之上，以解决这些问题。MENDR学习脑电信号的对称正定矩阵嵌入，并在一个包含超过4000小时脑电数据的大型语料库上进行预训练，这些数据通过离散小波包变换分解为多分辨率系数。MENDR通过将对称正定嵌入可视化为几何椭球体，显著增强了可解释性，并支持从学习到的嵌入中准确重建脑电信号。对多个临床脑电任务的评估表明，MENDR以显著更少的参数实现了接近最先进的性能，突显了其在高效、可解释和临床适用的脑电分析方面的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [324] [Real-Time Iteration Scheme for Diffusion Policy](https://arxiv.org/abs/2508.05396)
> *扩散策略的实时迭代方案*

*Yufei Duan, Hang Yin, Danica Kragic* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 扩散策略, 实时迭代, 推理加速, 机器人操作, 去噪

**Comment:** 

> **TL;DR:** 本文提出一种受实时迭代（RTI）方案启发的扩散策略加速方法，显著减少推理时间，无需额外训练或策略修改，同时保持性能。

**AI_Comments:** 本文的创新之处在于将最优控制领域的实时迭代方案首次应用于扩散策略的推理加速，这避免了传统加速方法（如蒸馏）所需的额外训练成本。其重要性在于，该方法能够无缝集成到现有的大型预训练扩散模型中，显著提高了其在实时或延迟敏感机器人任务中的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 扩散策略在机器人操作任务中表现出色，但其冗长的迭代去噪过程导致推理时间长，且需要执行动作块才能进行下一次预测，这限制了其在对延迟敏感或短周期任务中的应用。现有加速方法通常需要额外的训练，这对于大型机器人模型而言资源密集。

**Method:** 本文引入一种受实时迭代（RTI）方案启发的全新方法，该方案利用前一时间步的解作为后续迭代的初始猜测来加速优化。作者探索了该方案在扩散推理中的应用，并提出一种基于缩放的方法，以有效处理机器人操作中的离散动作（如抓取）。

**Result:** 该方案显著降低了运行时计算成本，无需蒸馏或策略重新设计。这使得它能够无缝集成到许多预训练的基于扩散的模型中，特别是资源需求大的大型模型。广泛的模拟实验量化结果显示，推理时间大幅缩减，且与使用全步去噪的扩散策略相比，整体性能相当。

**Conclusion:** 提出的实时迭代方案能够有效加速扩散策略的推理过程，显著降低计算成本，同时保持性能，尤其适用于大型预训练模型，解决了其在延迟敏感任务中的应用限制。

> **ai_Abstract:** 本文提出一种受实时迭代（RTI）方案启发的新方法，以解决扩散策略在机器人操作任务中推理时间长的问题。该方案通过利用前一步的解作为初始猜测来加速去噪过程，并引入了一种缩放方法来处理离散动作。实验结果表明，该方法在不进行模型蒸馏或重新设计的情况下，显著缩短了推理时间，同时保持了与全步去噪扩散策略相当的性能，尤其适用于大型预训练模型。

> **摘要翻译:** 扩散策略在机器人操作任务中表现出令人印象深刻的性能。然而，其冗长的迭代去噪过程导致的漫长推理时间，以及在下一次预测前需要执行动作块以保持动作一致性，限制了它们在对延迟敏感任务或短周期简单任务中的适用性。尽管最近的方法探索了蒸馏或替代策略结构来加速推理，但这些通常需要额外的训练，这对于大型机器人模型来说可能是资源密集型的。在本文中，我们介绍了一种受实时迭代（RTI）方案启发的新颖方法，这是一种来自最优控制的方法，通过利用前一时间步的解作为后续迭代的初始猜测来加速优化。我们探索了该方案在扩散推理中的应用，并提出了一种基于缩放的方法，以有效处理机器人操作中的离散动作，例如抓取。所提出的方案显著降低了运行时计算成本，无需蒸馏或策略重新设计。这使得它能够无缝集成到许多预训练的基于扩散的模型中，特别是对资源要求高的大型模型。我们还提供了收缩性的理论条件，这对于估计初始去噪步骤可能很有用。来自广泛模拟实验的定量结果显示，推理时间大幅缩减，与使用全步去噪的扩散策略相比，整体性能相当。我们的项目页面提供了额外资源：https://rti-dp.github.io/。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [330] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
> *基于RAG的自动化维护处方智能体（PARAM）*

*Chitranshu Harbola, Anupam Purwar* | **Category: cs.AI, cs.CL, cs.LG, cs.MA, eess.SP** | **Updated: 2025-07-28**

**Keywords:** 工业维护, 大型语言模型, 处方性维护, 振动分析, 多智能体系统

**Comment:** 

> **TL;DR:** PARAM是一个基于LLM的智能系统，通过结合振动数据分析和多智能体检索生成，为工业机械提供可操作的预测性维护建议。

**AI_Comments:** 该研究通过将LLM与振动数据分析及多智能体检索相结合，为工业预测性维护提供了一个创新且可扩展的解决方案。其将数值数据转化为自然语言供LLM处理的方法，以及利用RAG（检索增强生成）获取实时和全面的维护知识，是其关键创新点。该系统为工业实践者提供了超越传统异常检测的智能决策支持，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 工业机械维护需要及时干预以防止灾难性故障并优化运营效率，传统异常检测不足以提供可操作的维护建议。

**Method:** PARAM系统是一个集成的基于LLM的智能系统，构建于LAMP框架之上。它将轴承振动频率数据（BPFO, BPFI, BSF, FTF）序列化为自然语言供LLM处理，实现高精度少样本异常检测。系统能分类故障类型并评估严重程度。多智能体组件利用向量嵌入和语义搜索处理维护手册，并进行网络搜索以获取全面的程序知识和最新维护实践。Gemini模型生成结构化维护建议，包括即时行动、检查清单、纠正措施、零件需求和时间表。

**Result:** 在轴承振动数据集上的实验验证表明，系统能有效进行异常检测并提供与上下文相关的维护指导。

**Conclusion:** 该系统成功弥合了状态监测与可操作维护规划之间的差距，为工业从业者提供了智能决策支持，并推进了LLM在工业维护中的应用，提供了一个可扩展的预测性维护框架。

> **ai_Abstract:** PARAM是一个基于LLM的集成智能系统，专为工业机械的处方性维护设计。它通过将轴承振动数据转化为自然语言供LLM处理，并结合多智能体组件检索维护手册和网络信息，实现高精度故障检测、分类和严重性评估。最终，系统能生成详细的结构化维护建议，有效弥合了状态监测与实际维护行动之间的鸿沟。

> **摘要翻译:** 工业机械维护需要及时干预，以防止灾难性故障并优化运营效率。本文提出了一个集成的基于大型语言模型（LLM）的智能系统，用于处方性维护，它超越了传统的异常检测，提供了可操作的维护建议。在现有用于数值数据分析的LAMP框架基础上，我们开发了一个综合解决方案，结合了轴承振动频率分析和多智能体生成，以实现智能维护规划。我们的方法将轴承振动数据（BPFO、BPFI、BSF、FTF频率）序列化为自然语言，供LLM处理，从而实现高精度的少样本异常检测。该系统对故障类型（内圈、外圈、滚珠/滚柱、保持架故障）进行分类并评估严重程度。一个多智能体组件使用向量嵌入和语义搜索处理维护手册，同时进行网络搜索以检索全面的程序知识并获取最新的维护实践，从而提供更准确和深入的建议。Gemini模型随后生成结构化的维护建议，包括即时行动、检查清单、纠正措施、零件需求和时间表规范。轴承振动数据集上的实验验证表明，该系统能够有效进行异常检测并提供与上下文相关的维护指导。该系统成功弥合了状态监测与可操作维护规划之间的差距，为工业从业者提供了智能决策支持。这项工作推动了LLM在工业维护中的应用，为机械组件和工业部门的预测性维护提供了一个可扩展的框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [331] [UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS](https://arxiv.org/abs/2508.04968)
> *UGOD：不确定性引导的可微分不透明度和软丢弃用于增强稀疏视角3DGS*

*Zhihao Guo, Peng Wang, Zidong Chen, Xiangyu Kong, Yan Lyu, Guanyu Gao, Liangxiu Han* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D高斯泼溅, 稀疏视角, 新颖视图合成, 不确定性引导, 软丢弃

**Comment:** 

> **TL;DR:** UGOD通过学习不确定性来引导高斯不透明度更新和软丢弃正则化，从而在稀疏视角3DGS中实现了更好的渲染质量和更少的过拟合。

**AI_Comments:** UGOD通过引入不确定性引导的自适应加权和软丢弃正则化，巧妙地解决了3DGS在稀疏视角下的过拟合问题，这是对现有3DGS方法的重要改进。其创新点在于将不确定性融入到高斯不透明度更新和渲染丢弃策略中，有效提升了重建质量和效率，对NVS领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅（3DGS）方法在渲染时对高斯点进行等权重处理，容易导致过拟合，尤其是在稀疏视角场景下，这会影响渲染质量。

**Method:** 本研究提出UGOD方法，通过学习不确定性来适应性地加权高斯点。该不确定性有两个作用：1) 指导高斯不透明度的可微分更新，同时保持3DGS管道的完整性；2) 经过软可微分丢弃正则化，将不确定性转化为连续的丢弃概率，用于控制最终的高斯投影和渲染混合过程。

**Result:** 在广泛使用的数据集上进行的实验结果表明，UGOD在稀疏视角3D合成方面优于竞争对手，在大多数数据集中实现了更高质量的重建，并且使用的3D高斯点更少。例如，与DropGaussian相比，UGOD在MipNeRF 360数据集上实现了3.27%的PSNR提升。

**Conclusion:** 通过引入不确定性引导的高斯不透明度更新和软丢弃正则化，UGOD有效解决了稀疏视角3DGS中的过拟合问题，显著提升了渲染质量和重建效率。

> **ai_Abstract:** UGOD是一种针对稀疏视角3D高斯泼溅（3DGS）的新方法，旨在解决现有方法中高斯点等权重处理导致的过拟合问题。该方法引入了学习不确定性，用于引导高斯不透明度的可微分更新，并进行软可微分丢弃正则化，将不确定性转化为连续的丢弃概率以优化渲染过程。实验结果表明，UGOD在稀疏视角3D合成中表现优异，以更少的高斯点实现了更高质量的重建，并显著提升了渲染质量。

> **摘要翻译:** 3D高斯泼溅（3DGS）因其通过3D高斯投影和混合实现的高级渲染效率，已成为新颖视图合成（NVS）的一种有竞争力的方。然而，在大多数3DGS方法中，高斯点在渲染时被等权重处理，这使得它们容易出现过拟合，在稀疏视角场景中尤为如此。为了解决这个问题，我们研究了高斯点的自适应加权如何影响渲染质量，其特征是所提出的学习不确定性。这种学习到的不确定性有两个关键目的：首先，它在保持3DGS管道完整性的同时，引导高斯不透明度的可微分更新；其次，不确定性经过软可微分丢弃正则化，这策略性地将原始不确定性转化为连续的丢弃概率，这些概率控制着最终的高斯投影和渲染混合过程。在广泛采用的数据集上进行的大量实验结果表明，我们的方法在稀疏视角3D合成方面优于竞争对手，与现有稀疏视角方法相比，例如与DropGaussian相比，我们的方法在大多数数据集中以更少的高斯点实现了更高质量的重建，在MipNeRF 360数据集上实现了3.27%的PSNR提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [332] [UNCAGE: Contrastive Attention Guidance for Masked Generative Transformers in Text-to-Image Generation](https://arxiv.org/abs/2508.05399)
> *UNCAGE：文本到图像生成中掩码生成式Transformer的对比注意力引导*

*Wonjun Kang, Byeongkeun Ahn, Minjae Lee, Kevin Galim, Seunghyuk Oh, Hyung Il Koo, Nam Ik Cho* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 文本到图像生成, 掩码生成式Transformer, 对比注意力, 组合性, 无需训练

**Comment:** 

> **TL;DR:** UNCAGE是一种无需训练的方法，通过利用对比注意力引导来改进掩码生成式Transformer在文本到图像生成中的组合性。

**AI_Comments:** 该研究通过提出UNCAGE，填补了掩码生成式Transformer在处理组合性文本到图像生成方面研究不足的空白。其创新之处在于提出了一种无需训练的方法，通过智能地利用注意力图来提升生成图像的组合保真度，这对于实际应用具有重要意义，因为它避免了昂贵的再训练过程。

<details>
  <summary>Details</summary>

**Motivation:** 文本到图像生成中的组合性挑战，特别是属性绑定和文本-图像对齐问题，以及掩码生成式Transformer在此方面未被充分探索的限制。

**Method:** 本文提出了UNCAGE（Unmasking with Contrastive Attention Guidance），这是一种新颖的、无需训练的方法。它通过利用注意力图来优先解除对清晰表示单个对象的token的掩码，从而提高组合保真度。

**Result:** UNCAGE在多个基准和指标的定量和定性评估中持续改善了性能，且推理开销可忽略不计。

**Conclusion:** UNCAGE有效解决了掩码生成式Transformer在文本到图像生成中组合性保真度不足的问题，提供了一种高效且无需训练的解决方案。

> **ai_Abstract:** 本文提出了UNCAGE，一种针对文本到图像生成中掩码生成式Transformer的无需训练方法。该方法通过利用注意力图来优先处理代表独立对象的token的解掩码过程，以解决组合性T2I生成中属性绑定和文本-图像对齐的挑战。UNCAGE在多项评估中均显示出性能提升，且推理开销极小。

> **摘要翻译:** 文本到图像（T2I）生成已通过扩散模型和自回归模型得到积极研究。最近，掩码生成式Transformer作为自回归模型的替代品受到了关注，它通过双向注意力和并行解码克服了因果注意力和自回归解码的固有局限性，从而实现了高效、高质量的图像生成。然而，组合性T2I生成仍然具有挑战性，因为即使是最先进的扩散模型也常常无法准确绑定属性并实现适当的文本-图像对齐。尽管扩散模型已针对此问题进行了广泛研究，但掩码生成式Transformer也表现出类似的局限性，但在这方面尚未得到探索。为了解决这个问题，我们提出了UNCAGE（Unmasking with Contrastive Attention Guidance），这是一种新颖的、无需训练的方法，它通过利用注意力图优先解除对清晰表示单个对象的token的掩码，从而提高组合保真度。UNCAGE在多个基准和指标的定量和定性评估中持续改善了性能，且推理开销可忽略不计。我们的代码可在https://github.com/furiosa-ai/uncage获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [338] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
> *GeoFlow：地理空间任务的智能体工作流自动化*

*Amulya Bhattaram, Justin Chung, Stanley Chung, Ranit Gupta, Janani Ramamoorthy, Kartikeya Gullapalli, Diana Marculescu, Dimitrios Stamoulis* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-05**

**Keywords:** GeoFlow, 智能体工作流, 地理空间任务, API 调用, 大语言模型

**Comment:** 

> **TL;DR:** GeoFlow 是一种为地理空间任务自动生成智能体工作流的方法，通过提供详细的工具调用目标，提高了智能体成功率并显著减少了 LLM 的 token 使用。

**AI_Comments:** GeoFlow 的创新之处在于其明确的工具调用目标，这与以往隐式 API 选择的方法形成了鲜明对比。这种方法不仅提高了智能体在地理空间任务中的成功率，还显著优化了 LLM 的资源使用效率，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作侧重于推理分解，但API选择是隐式的。本研究的动机是为每个智能体提供详细的工具调用目标，以在运行时指导地理空间API调用，从而提高智能体成功率并优化资源使用。

**Method:** GeoFlow 方法自动为地理空间任务生成智能体工作流。它与以往工作不同之处在于，为每个智能体提供详细的工具调用目标，以指导运行时地理空间API的调用。

**Result:** 与最先进的方法相比，GeoFlow 将智能体成功率提高了 6.8%，并在主要的 LLM 系列中将 token 使用量减少了高达四倍。

**Conclusion:** GeoFlow 通过为智能体提供明确的工具调用目标，显著提高了地理空间任务的自动化成功率，并优化了大型语言模型的资源消耗。

> **ai_Abstract:** GeoFlow 是一种新颖的方法，旨在自动化地理空间任务的智能体工作流生成。通过为智能体提供明确的工具调用目标，GeoFlow 克服了现有方法中隐式 API 选择的局限性。实验结果表明，GeoFlow 显著提高了智能体的成功率，并大幅降低了大型语言模型的 token 消耗。

> **摘要翻译:** 我们提出了 GeoFlow，一种自动为地理空间任务生成智能体工作流的方法。与以往专注于推理分解而将 API 选择隐式处理的工作不同，我们的方法为每个智能体提供了详细的工具调用目标，以在运行时指导地理空间 API 的调用。与最先进的方法相比，GeoFlow 将智能体成功率提高了 6.8%，并在主要的 LLM 系列中将 token 使用量减少了高达四倍。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [339] [Hierarchical Deep Deterministic Policy Gradient for Autonomous Maze Navigation of Mobile Robots](https://arxiv.org/abs/2508.04994)
> *移动机器人自主迷宫导航的分层深度确定性策略梯度*

*Wenjie Hu, Ye Zhou, Hann Woei Ho* | **Category: cs.AI, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 分层深度确定性策略梯度, 迷宫导航, 移动机器人, 强化学习, DDPG

**Comment:** 

> **TL;DR:** 提出一种分层深度确定性策略梯度（HDDPG）算法，显著提升了移动机器人在复杂迷宫导航中的成功率和奖励。

**AI_Comments:** 这项研究通过引入分层结构和多项优化，有效解决了DDPG在复杂迷宫导航中的核心挑战。其创新性在于将长期规划与短期执行解耦，并通过细致的算法改进提升了性能。对于提升移动机器人在复杂环境中的自主导航能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** DDPG在迷宫导航中存在稀疏奖励、探索效率低和长期规划困难等问题，导致成功率和平均奖励低，甚至无法有效导航。

**Method:** 提出高效的分层DDPG (HDDPG) 算法，包含高层和低层策略。高层策略使用改进DDPG从长期和更高时间尺度生成中间子目标；低层策略也使用改进DDPG通过观察当前状态并遵循高层子目标生成原始动作。通过离策略校正、自适应参数空间噪声、重塑的内外在奖励函数、梯度裁剪和Xavier初始化等优化手段增强稳定性、改进探索和提升学习效率。

**Result:** 在自主迷宫导航任务的三个不同最终目标上，HDDPG相比基线算法，成功率至少提高56.59%，平均奖励至少提高519.03。

**Conclusion:** HDDPG算法显著克服了标准DDPG及其变体在自主迷宫导航任务中的局限性，大幅提升了性能。

> **ai_Abstract:** 本文针对移动机器人在复杂迷宫导航中，标准DDPG算法面临的稀疏奖励、探索效率低和长期规划困难等问题，提出了一种高效的分层深度确定性策略梯度（HDDPG）算法。HDDPG采用高低两层策略：高层生成子目标，低层执行原始动作。通过离策略校正、自适应噪声、重塑奖励函数等多种优化手段，显著提升了算法的稳定性、探索能力和学习效率。实验结果表明，HDDPG在自主迷宫导航任务中，相比基线DDPG算法，成功率和平均奖励均有显著提升。

> **摘要翻译:** 迷宫导航是机器人领域的一个基本挑战，要求智能体高效地穿越复杂的环境。虽然深度确定性策略梯度（DDPG）算法在控制任务中表现出色，但其在迷宫导航中的性能受制于稀疏奖励、低效探索和长期规划困难，常常导致成功率和平均奖励较低，有时甚至无法实现有效的导航。为了解决这些局限性，本文提出了一种高效的分层DDPG（HDDPG）算法，该算法包括高层和低层策略。高层策略采用先进的DDPG框架，从长期视角和更高时间尺度生成中间子目标。低层策略也由改进的DDPG算法驱动，通过观察当前状态并遵循高层策略分配的子目标来生成原始动作。所提出的方法通过离策略校正增强稳定性，通过重新标记历史经验来优化子目标分配。此外，还利用自适应参数空间噪声来改进探索，并采用重塑的内外在奖励函数来提高学习效率。进一步的优化，包括梯度裁剪和Xavier初始化，也被用于提高鲁棒性。所提出的算法通过使用机器人操作系统（ROS）和Gazebo执行的数值模拟实验进行了严格评估。在自主迷宫导航任务的三个不同最终目标方面，HDDPG显著克服了标准DDPG及其变体的局限性，与基线算法相比，成功率至少提高了56.59%，平均奖励至少提升了519.03。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [340] [LLM-based Multi-Agent Copilot for Quantum Sensor](https://arxiv.org/abs/2508.05421)
> *基于大型语言模型的多智能体量子传感器副驾驶*

*Rong Sha, Binglin Wang, Jun Yang, Xiaoxiao Ma, Chengkun Wu, Liang Yan, Chao Zhou, Jixun Liu, Guochao Wang, Shuhua Yan, Lingxiao Zhu* | **Category: cs.AI, physics.atom-ph, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 量子传感器, 多智能体系统, 主动学习, 优化

**Comment:** 

> **TL;DR:** QCopilot是一个基于LLM的多智能体框架，通过整合外部知识、主动学习和不确定性量化，显著加速量子传感器开发，并在原子冷却实验中实现了无人干预的100倍速度提升和异常参数识别。

**AI_Comments:** 本文提出了一种创新的LLM多智能体框架QCopilot，有效解决了量子传感器开发中的知识壁垒和复杂优化问题。其通过整合外部知识、主动学习和不确定性量化，实现了高度自动化和效率提升。在原子冷却实验中取得的显著速度提升和自主异常识别能力，显示了该方法在加速科学探索和工程应用方面的巨大潜力。这项工作对于推动量子信息系统的大规模部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在量子传感器开发中面临跨学科知识障碍和复杂优化过程的限制。

**Method:** 本文提出了QCopilot，一个基于LLM的多智能体框架，集成了外部知识访问、主动学习和不确定性量化，用于量子传感器的设计和诊断。它由商业LLM、少样本提示工程和向量知识库组成，并利用专业智能体自适应选择优化方法、自动化建模分析和独立执行问题诊断。

**Result:** 将QCopilot应用于原子冷却实验，在数小时内无需人工干预生成了10^8个亚微开尔文原子，比手动实验加速了约100倍。通过持续积累先验知识和实现动态建模，QCopilot能够自主识别多参数实验设置中的异常参数。

**Conclusion:** QCopilot降低了大规模量子传感器部署的障碍，并易于扩展到其他量子信息系统。

> **ai_Abstract:** 本文介绍了QCopilot，一个基于大型语言模型（LLM）的多智能体框架，旨在克服量子传感器开发中的跨学科知识和复杂优化挑战。QCopilot通过结合商业LLM、知识库和专业智能体，实现了优化方法自适应选择、自动化建模分析和问题诊断。实验证明，QCopilot在原子冷却实验中实现了无人干预的显著加速（约100倍），并能自主识别异常参数，从而降低了量子传感器大规模部署的障碍并具有广泛的适用性。

> **摘要翻译:** 大型语言模型（LLM）展现出广泛的实用性，但在量子传感器开发中面临限制，这源于跨学科知识障碍和涉及复杂的优化过程。本文提出了QCopilot，一个基于LLM的多智能体框架，集成了外部知识访问、主动学习和不确定性量化，用于量子传感器的设计和诊断。QCopilot由结合了少样本提示工程的商业LLM和向量知识库组成，并利用专业智能体自适应选择优化方法、自动化建模分析和独立执行问题诊断。将QCopilot应用于原子冷却实验，我们在数小时内无需任何人工干预生成了10^8个亚微开尔文原子，这代表着比手动实验加速了约100倍。值得注意的是，通过持续积累先验知识和实现动态建模，QCopilot能够自主识别多参数实验设置中的异常参数。我们的工作降低了大规模量子传感器部署的障碍，并易于扩展到其他量子信息系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [346] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
> *谁是更好的玩家：大型语言模型对战大型语言模型*

*Yingjie Zhou, Jiezhang Cao, Farong Wen, Li Xu, Yanwei Jiang, Jun Jia, Ronghui Li, Xiaohong Liu, Yu Zhou, Xiongkuo Min, Jie Guo, Zicheng Zhang, Guangtao Zhai* | **Category: cs.AI** | **Updated: 2025-08-05**

**Keywords:** 大型语言模型, 对抗性棋盘游戏, 基准测试, Elo等级分, 技能不稳定性

**Comment:** 

> **TL;DR:** 该研究提出了一个使用棋盘游戏评估大型语言模型（LLM）的对抗性基准测试框架，发现LLM在高压环境下具有适应性但技能表现不稳定。

**AI_Comments:** 该论文提供了一种创新方法，通过对抗性棋盘游戏而非传统问答任务来评估LLM，这更具动态性和战略性。引入“弈镇”平台以及Elo、PLG和PSS等指标，全面评估了LLM的技术能力和“心理素质”。LLM在高压环境下表现出乐观和适应性这一发现尤其有趣，但观察到的技能不稳定性也指出了未来在持续战略推理方面需要进一步研究的领域。

<details>
  <summary>Details</summary>

**Motivation:** 为了弥补主流基于问答（Q&A）的基准测试方法的数据依赖性限制，并全面评估大型语言模型（LLM）在作为战略推理和智能典范领域的棋盘游戏中的综合性能。

**Method:** 提出了一种通过棋盘游戏竞赛评估LLM的对抗性基准测试框架。引入了“弈镇”（Qi Town）评估平台，支持5种游戏和20个LLM驱动的玩家。采用Elo等级分系统和新颖的性能循环图（PLG）来定量评估LLM的技术能力，并通过积极情绪分数（PSS）评估心理素质。评估以循环赛形式进行。

**Result:** 实验结果表明，尽管存在技术差异，大多数LLM在输赢方面仍保持乐观，表现出比人类更强的对高压对抗环境的适应性。PLG中循环胜负的复杂关系暴露了LLM在游戏过程中技能发挥的不稳定性。

**Conclusion:** LLM在对抗性棋盘游戏中表现出良好的心理素质（乐观、适应性），但其技能一致性（PLG中显示的不稳定性）需要进一步研究。该框架提供了一种新的LLM基准测试方法。

> **ai_Abstract:** 本文提出了一种对抗性基准测试框架，通过棋盘游戏评估大型语言模型（LLM）的综合性能，弥补了传统问答基准测试的局限性。该框架利用“弈镇”（Qi Town）平台，支持5种游戏和20个LLM玩家，并采用Elo等级分系统、新颖的性能循环图（PLG）进行技术评估，同时通过积极情绪分数（PSS）评估心理素质。循环赛结果显示，LLM在高压环境下具有韧性和适应性，通常保持乐观。然而，研究也揭示了LLM在游戏过程中技能表现的不稳定性，这有待进一步研究。

> **摘要翻译:** 对抗性棋盘游戏作为战略推理和智能的典范领域，长期以来一直是流行的竞技活动和评估人工智能（AI）系统的基准。在此基础上，我们提出了一个对抗性基准测试框架，通过棋盘游戏竞赛来评估大型语言模型（LLM）的综合性能，弥补了主流基于问答（Q&A）的基准测试方法的数据依赖性限制。我们引入了“弈镇”（Qi Town），一个专门的评估平台，支持5种广泛流行的游戏，并涉及20个由LLM驱动的玩家。该平台采用Elo等级分系统和一种新颖的性能循环图（PLG）来定量评估LLM的技术能力，同时在游戏过程中捕获积极情绪分数（PSS）以评估心理素质。评估结构为循环赛，从而能够系统地比较不同玩家。实验结果表明，尽管存在技术差异，大多数LLM在输赢方面仍保持乐观，表现出比人类更强的对高压对抗环境的适应性。另一方面，PLG中循环胜负的复杂关系暴露了LLM在游戏过程中技能发挥的不稳定性，这需要进一步的解释和探索。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [347] [Situated Epistemic Infrastructures: A Diagnostic Framework for Post-Coherence Knowledge](https://arxiv.org/abs/2508.04995)
> *情境化认知基础设施：后连贯知识的诊断框架*

*Matthew Kelly* | **Category: cs.AI, cs.DL, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 情境化认知基础设施, 大型语言模型, 知识生产, AI治理, 可信度

**Comment:** 

> **TL;DR:** 本文提出了情境化认知基础设施（SEI）框架，作为一种诊断工具，用于分析在大型语言模型（LLM）带来的“后连贯”条件下，混合人机系统中知识如何获得权威性，并强调了适应性知识管理的需求。

**AI_Comments:** 本文提出的情境化认知基础设施（SEI）框架具有创新性，它直接回应了大型语言模型（LLMs）对传统知识权威和验证机制的挑战。其重要性在于提供了一个分析和理解“后连贯知识”如何形成和获得权威性的新视角，超越了传统的表征主义模型。通过强调协调和适应性管理，该框架为未来AI时代下知识生产和信息系统的伦理设计提供了实用的指导。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）如ChatGPT通过模拟连贯性但绕过传统的引用、权威和验证模式，揭示了当代知识基础设施的脆弱性。这促使研究者需要一个诊断工具来分析在“后连贯”条件下知识如何获得权威性。

**Method:** 本文提出了情境化认知基础设施（SEI）框架。该框架整合了基础设施研究、平台理论和认识论的见解，并侧重于协调而非分类，强调了对知识管理采取前瞻性和适应性模式的必要性。SEI框架通过追踪可信度如何在制度、计算和时间安排中介导，而非依赖于稳定的学术领域或有限的实践社群。

**Result:** SEI框架被提出作为一种诊断工具，用于分析在后连贯条件下，混合人机系统中知识如何获得权威性。该框架能够追踪可信度如何在制度、计算和时间安排中介导。

**Conclusion:** 本文通过提供一种替代表征主义学术交流模型的强大方法，为人工智能治理、知识生产和信息系统伦理设计等方面的辩论做出了贡献。

> **ai_Abstract:** 本文针对大型语言模型（LLM）揭示的当代知识基础设施的脆弱性，提出了一种名为情境化认知基础设施（SEI）的诊断框架。SEI旨在分析在LLM带来的“后连贯”条件下，混合人机系统中的知识如何获得权威性。该框架整合了基础设施研究、平台理论和认识论，强调通过追踪制度、计算和时间安排中的可信度中介来理解知识的形成，并倡导前瞻性和适应性的知识管理模式。该研究为AI治理、知识生产和信息系统伦理设计提供了新的视角。

> **摘要翻译:** 大型语言模型（LLM）如ChatGPT通过模拟连贯性但绕过传统的引用、权威和验证模式，揭示了当代知识基础设施的脆弱性。本文提出了情境化认知基础设施（SEI）框架，作为一种诊断工具，用于分析在后连贯条件下，混合人机系统中知识如何获得权威性。SEI不依赖于稳定的学术领域或有限的实践社群，而是追踪可信度如何在制度、计算和时间安排中介导。该框架整合了基础设施研究、平台理论和认识论的见解，侧重于协调而非分类，强调了对认知管理采取前瞻性和适应性模式的必要性。本文通过提供一种替代表征主义学术交流模型的强大方法，为人工智能治理、知识生产和信息系统伦理设计等方面的辩论做出了贡献。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [348] [MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource Language Constraints](https://arxiv.org/abs/2508.05429)
> *MyCulture：在低资源语言约束下探索马来西亚多元文化*

*Zhong Ken Hew, Jia Xin Low, Sze Jue Yang, Chee Seng chan* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大语言模型, 文化偏见, 低资源语言, 马来西亚文化, 基准测试

**Comment:** 

> **TL;DR:** 现有LLMs在低资源语言下对文化理解存在偏见。本文提出MyCulture，一个马来西亚文化基准，用于评估LLMs的文化理解能力，发现模型存在显著的文化理解差异，强调需要文化包容的基准。

**AI_Comments:** 创新点：1. 提出了MyCulture基准，专门关注低资源语言环境下的文化理解评估，填补了现有LLM评估的空白。2. 引入了新颖的开放式多项选择题格式，有效减少了猜测和格式偏差，提高了评估的公平性和区分度。重要性：1. 揭示了现有LLMs在文化理解方面的显著不足，特别是对于非高资源语言文化。2. 强调了在LLM开发中融入文化多样性和语言包容性的紧迫性，对于构建更公平、更普适的AI系统具有重要意义。局限性：1. 仅关注马来西亚文化，未来可扩展到更多低资源语言和文化。2. 开放式问题格式的评估可能需要更复杂的自动化或人工标注方法。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）由于训练数据主要来自高资源语言，存在文化偏见，导致在低资源语言环境下难以准确表示和评估多元文化背景。

**Method:** 引入MyCulture基准，用于全面评估LLMs在马来西亚文化六个支柱（艺术、服饰、习俗、娱乐、食物、宗教）上的表现，并以马来语呈现。采用新颖的开放式多项选择题格式，没有预定义选项，以减少猜测和格式偏差。提供开放式结构在提高公平性和区分度方面的理论依据。通过比较模型在结构化和自由形式输出上的表现来分析结构偏差，并通过多语言提示变体评估语言偏差。

**Result:** 对一系列区域和国际LLMs的评估揭示了文化理解方面的显著差异。

**Conclusion:** 迫切需要开发和评估具有文化基础和语言包容性的LLM基准。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在低资源语言文化理解上的偏见问题，提出了MyCulture基准。该基准以马来语呈现，涵盖马来西亚文化的六个方面，并采用独特的开放式多项选择题格式以减少偏差。研究通过评估多种LLMs，发现它们在文化理解上存在显著差异，强调了开发文化包容性基准的重要性。

> **摘要翻译:** 大型语言模型（LLMs）由于训练数据主要由英语和中文等高资源语言主导，经常表现出文化偏见。这给准确表示和评估多元文化背景带来了挑战，尤其是在低资源语言环境中。为了解决这个问题，我们引入了MyCulture，这是一个旨在全面评估LLMs在马来西亚文化六大支柱（艺术、服饰、习俗、娱乐、食物和宗教）上的基准，并以马来语呈现。与传统基准不同，MyCulture采用了一种新颖的开放式多项选择题格式，没有预设选项，从而减少了猜测并减轻了格式偏差。我们为这种开放式结构在提高公平性和区分度方面的有效性提供了理论依据。此外，我们通过比较模型在结构化和自由形式输出上的表现来分析结构偏差，并通过多语言提示变体评估语言偏差。我们对一系列区域和国际LLMs的评估揭示了文化理解方面的显著差异，突显了在LLM开发和评估中迫切需要具有文化基础和语言包容性的基准。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [354] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
> *为自主网络地理信息系统（AWebGIS）微调小型语言模型（SLMs）*

*Mahdi Nazari Ashani, Ali Asghar Alesheikh, Saba Kazemi, Kimya Kheirkhah, Yasin Mohammadi, Fatemeh Rezaie, Amir Mahdi Manafi, Hedieh Zarkesh* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 小型语言模型, AWebGIS, 客户端计算, T5-small, 地理信息系统

**Comment:** 

> **TL;DR:** 本研究探索了在客户端浏览器中运行的微调小型语言模型（SLM）在自主网络地理信息系统（AWebGIS）中的应用，并证明其在准确性方面优于基于云的大型语言模型（LLM）和传统机器学习方法，同时解决了隐私和可扩展性问题。

**AI_Comments:** 这篇论文的创新点在于提出了在客户端浏览器中运行微调小型语言模型（SLM）来解决自主网络地理信息系统（AWebGIS）中基于云的大型语言模型（LLM）所面临的隐私、可扩展性和持续联网问题。其重要性在于为AWebGIS提供了一种高效、私密且低服务器依赖的解决方案，为未来地理信息系统的发展开辟了新的方向。该研究证明了SLM在特定应用场景下的强大潜力，尤其是在边缘计算和隐私敏感领域。

<details>
  <summary>Details</summary>

**Motivation:** 当前的自主网络地理信息系统（AWebGIS）解决方案主要依赖于基于云的大型语言模型（LLMs），这导致了持续的互联网连接需求、用户隐私问题以及由于集中式服务器处理引起的可扩展性问题。

**Method:** 本研究比较了三种实现AWebGIS的方法：1) 使用基于云的LLM（如Cohere）的全自动化在线方法；2) 使用支持向量机和随机森林等经典机器学习分类器的半自动化离线方法；3) 基于微调小型语言模型（具体为T5-small模型）的全自主离线（客户端）方法，该方法在客户端的网页浏览器中执行。

**Result:** 第三种方法，即利用小型语言模型（SLMs）的方法，在所有方法中取得了最高的准确性，其精确匹配准确率为0.93，Levenshtein相似度为0.99，ROUGE-1和ROUGE-L得分均为0.98。此外，这种客户端计算策略通过将处理任务卸载到用户设备，减少了后端服务器的负载，消除了对基于服务器推理的需求。

**Conclusion:** 研究结果突出了浏览器可执行模型在自主网络地理信息系统（AWebGIS）解决方案中的可行性。

> **ai_Abstract:** 本研究旨在解决当前自主网络地理信息系统（AWebGIS）对云端大型语言模型（LLMs）的依赖所带来的隐私和可扩展性问题。论文比较了三种实现AWebGIS的方法：基于云LLM的在线方法、基于传统机器学习的离线方法以及基于微调小型语言模型（SLM，T5-small）的客户端离线方法。结果表明，客户端运行的SLM方法表现最佳，在准确性指标上显著优于其他方法，并证明了浏览器可执行模型在AWebGIS解决方案中的可行性，同时减轻了服务器负担。

> **摘要翻译:** 自主网络地理信息系统（AWebGIS）旨在通过自然语言输入执行地理空间操作，提供直观、智能和无需动手的交互。然而，当前大多数解决方案依赖于基于云的大型语言模型（LLMs），这需要持续的互联网访问，并由于集中式服务器处理而引发用户隐私和可扩展性问题。本研究比较了实现AWebGIS的三种方法：（1）使用基于云的LLM（例如Cohere）的全自动化在线方法；（2）使用支持向量机和随机森林等经典机器学习分类器的半自动化离线方法；（3）基于微调小型语言模型（SLM），特别是T5-small模型，在客户端网页浏览器中执行的全自主离线（客户端）方法。第三种方法，即利用SLM的方法，在所有方法中取得了最高的准确性，其精确匹配准确率为0.93，Levenshtein相似度为0.99，召回率导向的概要评估（ROUGE-1和ROUGE-L）得分均为0.98。至关重要的是，这种客户端计算策略通过将处理任务卸载到用户设备，减少了后端服务器的负载，消除了对基于服务器推理的需求。这些结果突出了浏览器可执行模型在AWebGIS解决方案中的可行性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [355] [AgenticData: An Agentic Data Analytics System for Heterogeneous Data](https://arxiv.org/abs/2508.05002)
> *AgenticData：一个用于异构数据的智能体数据分析系统*

*Ji Sun, Guoliang Li, Peiyao Zhou, Yihui Ma, Jingzhe Xu, Yuan Li* | **Category: cs.AI, cs.DB** | **Updated: 2025-08-07**

**Keywords:** AgenticData, 智能体数据分析, 异构数据, 自然语言处理, 多智能体系统

**Comment:** 

> **TL;DR:** AgenticData是一个创新的智能体数据分析系统，允许用户通过自然语言提问来分析异构数据，并通过反馈驱动规划、多智能体协作和语义优化模型实现卓越性能，显著优于现有方法。

**AI_Comments:** AgenticData的创新在于其将智能体技术应用于异构数据分析，实现了自然语言交互和自动化流程。其多智能体协作策略和反馈驱动规划是核心亮点，有望大幅降低数据分析的门槛和成本，对非专业用户进行复杂数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有非结构化数据分析系统依赖专家编写代码和管理复杂工作流，导致成本高昂且耗时。

**Method:** AgenticData系统通过以下方式实现：1) 采用反馈驱动的规划技术，将自然语言查询自动转换为语义计划。2) 提出多智能体协作策略，包括数据分析智能体、语义交叉验证智能体和智能记忆智能体。3) 提出语义优化模型以有效完善和执行语义计划。系统已通过三个基准测试。

**Result:** AgenticData在简单和困难任务上均取得了卓越的准确性，显著优于最先进的方法。

**Conclusion:** AgenticData通过其智能体驱动的方法，成功解决了异构数据分析中对专家和复杂工作流的依赖问题，实现了通过自然语言进行高效准确的数据分析。

> **ai_Abstract:** AgenticData是一个为解决现有数据分析系统高成本和耗时问题而设计的智能体数据分析系统。它允许用户通过自然语言提问，自主分析包括结构化和非结构化在内的异构数据源。该系统采用反馈驱动的规划技术将自然语言查询转换为语义计划，并利用数据分析、语义交叉验证和智能记忆等多智能体协作策略。此外，它还包含一个语义优化模型来完善和执行计划。实验结果表明，AgenticData在多项任务上均表现出卓越的准确性，显著超越了现有技术。

> **摘要翻译:** 现有的非结构化数据分析系统依赖专家编写代码和管理复杂的分析工作流，这使得它们既昂贵又耗时。为了解决这些挑战，我们引入了 AgenticData，一个创新的智能体数据分析系统，它允许用户简单地提出自然语言（NL）问题，同时自主分析跨多个领域的数据源，包括非结构化和结构化数据。首先，AgenticData 采用了一种反馈驱动的规划技术，可以自动将自然语言查询转换为由关系和语义操作符组成的语义计划。我们通过利用数据分析智能体来发现相关数据、语义交叉验证智能体基于反馈进行迭代优化，以及智能记忆智能体来维护短期上下文和长期知识，提出了一种多智能体协作策略。其次，我们提出了一种语义优化模型，以有效地完善和执行语义计划。我们的系统 AgenticData 已经使用三个基准进行了测试。实验结果表明，AgenticData 在简单和困难任务上都取得了卓越的准确性，显著优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [357] [Explaining Similarity in Vision-Language Encoders with Weighted Banzhaf Interactions](https://arxiv.org/abs/2508.05430)
> *使用加权Banzhaf交互解释视觉-语言编码器中的相似性*

*Hubert Baniecki, Maximilian Muschalik, Fabian Fumagalli, Barbara Hammer, Eyke Hüllermeier, Przemyslaw Biecek* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 视觉-语言编码器, 可解释人工智能, 博弈论, Banzhaf交互, 跨模态交互

**Comment:** 

> **TL;DR:** 本文提出FIxLIP，一种基于博弈论的二阶交互解释方法，通过捕捉视觉-语言编码器中的复杂跨模态交互来解释相似性，优于现有的一阶方法，并可用于模型比较。

**AI_Comments:** 这篇论文的创新之处在于，它超越了一阶归因，解释了视觉-语言模型中复杂的跨模态交互，这对于理解其内部工作原理至关重要。通过利用博弈论，特别是加权Banzhaf交互，它提供了一种更细致、计算效率更高的方法来分解相似性。将评估指标扩展到二阶解释也是一项重要的贡献，弥补了当前可解释性研究中的空白。其在模型比较中的实用性也进一步突出了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的解释方法（如显著性图）仅捕获一阶归因，忽略了视觉-语言编码器中固有的复杂跨模态交互，因此需要一种能解释复杂交互的方法。

**Method:** 提出FIxLIP（LIP模型的可信交互解释），这是一种统一的方法，用于分解视觉-语言编码器中的相似性。FIxLIP根植于博弈论，通过使用加权Banzhaf交互指数，相比Shapley交互量化框架，提供了更大的灵活性并提高了计算效率。此外，还提出了如何将现有的解释评估指标（如指向游戏和插入/删除曲线之间的面积）扩展到二阶交互解释。

**Result:** 在MS COCO和ImageNet-1k基准测试上的实验验证了FIxLIP等二阶方法优于一阶归因方法。除了提供高质量的解释，FIxLIP还可用于比较不同的模型，如CLIP与SigLIP-2以及ViT-B/32与ViT-L/16。

**Conclusion:** 论文成功引入了FIxLIP，一种基于博弈论的二阶交互解释方法，解决了现有方法仅捕获一阶归因的局限性，从而能更好地解释视觉-语言编码器中的复杂跨模态交互，并可用于模型比较。

> **ai_Abstract:** 本文介绍了一种名为FIxLIP的新型博弈论解释方法，用于视觉-语言编码器。与现有的一阶归因方法不同，FIxLIP通过使用加权Banzhaf交互指数捕获复杂的跨模态二阶交互来分解相似性，从而提供更高的灵活性和计算效率。该方法还扩展了用于二阶解释的现有评估指标。在MS COCO和ImageNet-1k上的实验表明，FIxLIP优于一阶方法，并且可用于比较不同的视觉-语言模型。

> **摘要翻译:** 语言-图像预训练（LIP）使得视觉-语言模型能够进行零样本分类、定位、多模态检索和语义理解。已经提出了各种解释方法来可视化输入图像-文本对对模型相似性输出的重要性。然而，流行的显著性图受限于只能捕获一阶归因，忽略了此类编码器固有的复杂跨模态交互。我们引入了LIP模型的可信交互解释（FIxLIP），作为一种统一的方法来分解视觉-语言编码器中的相似性。FIxLIP植根于博弈论，我们分析了使用加权Banzhaf交互指数如何比Shapley交互量化框架提供更大的灵活性并提高计算效率。从实践角度来看，我们提出了如何自然地将解释评估指标（如指向游戏和插入/删除曲线之间的面积）扩展到二阶交互解释。在MS COCO和ImageNet-1k基准测试上的实验验证了FIxLIP等二阶方法优于一阶归因方法。除了提供高质量的解释，我们还展示了FIxLIP在比较不同模型（如CLIP与SigLIP-2以及ViT-B/32与ViT-L/16）方面的实用性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [362] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
> *RL微调后大型语言模型在非理想条件下的推理能力*

*Chang Tian, Matthew B. Blaschko, Mingzhe Xing, Xiuxing Li, Yinliang Yue, Marie-Francine Moens* | **Category: cs.AI** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 推理能力, RL微调, 非理想条件, 策略梯度

**Comment:** 

> **TL;DR:** 研究发现，经过RL微调的大型语言模型在非理想推理场景下表现显著下降，揭示了其高级推理能力的局限性，并强调了在真实条件下评估模型的重要性。

**AI_Comments:** 该论文通过引入非理想条件下的评估，开辟了一个重要的研究方向，挑战了现有基准测试的局限性。其创新之处在于定义了具体的非理想场景并系统地评估了RL微调模型在这些场景下的表现。重要性在于揭示了当前RL方法在提升模型鲁棒推理能力方面的不足，对理解LLM的真实能力边界具有深远意义。它表明，尽管模型在理想条件下表现出色，但在面对真实世界的复杂性和不确定性时，其性能可能被高估。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准测试大多在理想设置下评估大型语言模型的推理能力，而忽视了其在现实非理想场景中的表现，这与人类推理在不完美输入下仍保持可靠的脑科学发现形成对比。

**Method:** 本研究定义了三种具有实际相关性的非理想场景：摘要推理、细粒度噪声抑制和上下文过滤。作者使用一种代表性策略梯度算法对三个大型语言模型（LLMs）和一个最先进的大型视觉语言模型（LVLM）进行RL微调，并在八个公共数据集上测试了它们的性能。同时，提出了一种针对特定场景的补救方法。

**Result:** 结果显示，尽管RL微调提高了模型在理想设置下的基线推理能力，但在所有三种非理想场景中，性能均显著下降，暴露出高级推理能力的严重局限性。

**Conclusion:** 本研究指出，尽管提出了场景特定的补救方法，但现有方法在很大程度上仍未能解决这些推理缺陷。这凸显了大型模型推理能力常被夸大的事实，并强调了在非理想场景下评估模型的重要性。

> **ai_Abstract:** 本论文研究了经过强化学习（RL）微调的大型语言模型（LLMs）及其视觉语言模型（LVLM）在非理想条件下的推理能力。研究识别并定义了摘要推理、细粒度噪声抑制和上下文过滤三种具有实际意义的非理想场景。实验结果表明，尽管RL微调能提升模型在理想环境中的推理表现，但在这些非理想场景下，模型的推理能力显著下降，揭示了当前RL微调方法在高级推理方面存在的关键局限性。论文强调，现有方法未能有效解决这些推理缺陷，并呼吁在更贴近现实的非理想条件下评估大型模型的推理能力，以避免对其能力产生过高估计。

> **摘要翻译:** 强化学习（RL）已成为增强大型语言模型（LLMs）推理能力的关键技术，其中策略梯度算法因其效率和有效性而在训练后阶段占据主导地位。然而，大多数现有基准测试在理想设置下评估大型语言模型的推理能力，忽视了在现实、非理想场景中的表现。我们确定了三种具有实际相关性的代表性非理想场景：摘要推理、细粒度噪声抑制和上下文过滤。我们引入了一个由脑科学发现（即人类推理在不完美输入下仍保持可靠）引导的新研究方向。我们正式定义并评估了这些具有挑战性的场景。我们使用一种代表性策略梯度算法通过RL对三个LLMs和一个最先进的大型视觉语言模型（LVLM）进行了微调，然后在八个公共数据集上测试了它们的性能。我们的结果表明，虽然RL微调提高了理想设置下的基线推理能力，但在所有三种非理想场景中，性能均显著下降，暴露出高级推理能力的严重局限性。尽管我们提出了一种针对特定场景的补救方法，但我们的结果表明，当前方法在很大程度上仍未能解决这些推理缺陷。这项工作强调了大型模型推理能力常常被夸大的事实，并强调了在非理想场景下评估模型的重要性。代码和数据将在XXXX发布。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [363] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
> *用于提取与自杀相关的健康社会决定因素的多阶段大型语言模型框架*

*Song Wang, Yishu Wei, Haotian Ma, Max Lovitt, Kelly Deng, Yuan Meng, Zihan Xu, Jingze Zhang, Yunyu Xiao, Ying Ding, Xuhai Xu, Joydeep Ghosh, Yifan Peng* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 健康社会决定因素, 自杀预防, 信息提取, 模型可解释性

**Comment:** 

> **TL;DR:** 该研究提出了一个多阶段大型语言模型框架，用于从非结构化文本中提取与自杀相关的健康社会决定因素，提高了提取精度和模型可解释性，并能降低推理成本。

**AI_Comments:** 该论文的创新之处在于提出了一个多阶段的大型语言模型框架，有效解决了现有数据驱动方法在SDoH提取中面临的长尾分布、关键压力源分析和模型可解释性不足等挑战。其重要性体现在不仅提高了提取的准确性，还通过提供中间解释增强了模型透明度，这对于医疗健康领域，特别是自杀风险评估，是至关重要的。此外，通过微调小型模型实现相似或更优性能并降低推理成本的发现，也为实际应用提供了经济高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 理解导致自杀事件的健康社会决定因素（SDoH）对于早期干预和预防至关重要。然而，数据驱动的方法面临着长尾因素分布、分析自杀事件前关键压力源以及模型可解释性有限等挑战。

**Method:** 本研究提出了一个多阶段大型语言模型框架，以增强从非结构化文本中提取SDoH因素的能力。该方法与BioBERT、GPT-3.5-turbo等现有先进语言模型以及DeepSeek-R1等推理模型进行了比较。研究还评估了模型解释如何帮助人们更快、更准确地标注SDoH因素，分析包括自动化比较和一项初步用户研究。

**Result:** 所提出的框架在SDoH因素提取的总体任务和检索相关上下文的细粒度任务中均表现出性能提升。此外，对一个更小、特定任务的模型进行微调，可以在降低推理成本的同时达到相当或更好的性能。多阶段设计不仅增强了提取能力，还提供了中间解释，提高了模型的可解释性。

**Conclusion:** 本研究的方法提高了从非结构化文本中提取与自杀相关的SDoH的准确性和透明度。这些进展有望支持早期识别高风险个体，并为更有效的预防策略提供信息。

> **ai_Abstract:** 本研究提出了一种多阶段大型语言模型框架，旨在从非结构化文本中高效准确地提取与自杀相关的健康社会决定因素（SDoH）。该框架通过与现有先进模型的比较，证明了其在SDoH因素提取和上下文检索方面的性能提升。值得注意的是，该方法还能通过微调小型模型实现成本效益，同时保持或提升性能，并且其多阶段设计提供了中间解释，显著增强了模型的可解释性。这项工作为早期识别高风险个体和制定更有效的自杀预防策略提供了潜在支持。

> **摘要翻译:** 背景：理解导致自杀事件的健康社会决定因素（SDoH）对于早期干预和预防至关重要。然而，数据驱动的方法在实现这一目标时面临挑战，例如长尾因素分布、分析自杀事件前的关键压力源以及模型可解释性有限。方法：我们提出了一个多阶段大型语言模型框架，以增强从非结构化文本中提取SDoH因素的能力。我们的方法与BioBERT和GPT-3.5-turbo等其他最先进的语言模型以及DeepSeek-R1等推理模型进行了比较。我们还评估了模型的解释如何帮助人们更快、更准确地标注SDoH因素。分析包括自动化比较和一项初步用户研究。结果：我们表明，我们提出的框架在提取SDoH因素的总体任务和检索相关上下文的细粒度任务中均表现出性能提升。此外，我们还表明，对一个更小、特定任务的模型进行微调，可以在降低推理成本的同时达到相当或更好的性能。多阶段设计不仅增强了提取能力，还提供了中间解释，提高了模型的可解释性。结论：我们的方法提高了从非结构化文本中提取与自杀相关的SDoH的准确性和透明度。这些进展有望支持早期识别高风险个体，并为更有效的预防策略提供信息。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [364] [Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees](https://arxiv.org/abs/2508.05441)
> *PAC级别保证下的尾部风险安全蒙特卡洛树搜索*

*Zuyuan Zhang, Arnob Ghosh, Tian Lan* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 蒙特卡洛树搜索, 尾部风险, 条件风险价值, Wasserstein距离, PAC保证

**Comment:** 

> **TL;DR:** 本文提出了两种新方法，CVaR-MCTS和Wasserstein-MCTS，用于在蒙特卡洛树搜索中实现严格的尾部风险安全，并提供PAC级别的理论保证。

**AI_Comments:** 本文的创新之处在于其首次为蒙特卡洛树搜索提供了PAC级别的严格尾部安全保证，这对于高风险决策场景至关重要。通过引入CVaR和Wasserstein模糊集，作者不仅解决了尾部风险的量化控制问题，还巧妙地处理了有限样本下的估计偏差。这使得该方法在理论和实践上都具有显著的进步意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的蒙特卡洛树搜索（MCTS）仅考虑预期回报，无法应对高风险、不利结果。现有的安全感知MCTS方法（如引入均值风险度量或硬成本阈值）未能提供针对极端或高风险结果（即尾部风险）的严格安全保证，这在高风险场景中可能导致严重后果。

**Method:** 本文提出了两种新颖的解决方案：1. CVaR-MCTS：将相干尾部风险度量条件风险价值（CVaR）嵌入MCTS中，实现了对“最差(1-α)%场景”中预期损失的明确尾部风险控制。2. Wasserstein-MCTS（W-MCTS）：通过引入一阶Wasserstein模糊集来表征尾部风险估计中的不确定性，以解决有限样本导致的尾部风险估计偏差问题。本文证明了CVaR-MCTS和W-MCTS的PAC尾部安全保证，并建立了它们的遗憾界。

**Result:** 在各种模拟环境中的评估表明，本文提出的方法优于现有基线，有效地实现了鲁棒的尾部风险保证，并提高了回报和稳定性。

**Conclusion:** 本文通过开发CVaR-MCTS和Wasserstein-MCTS两种新颖方法，解决了蒙特卡洛树搜索中尾部风险控制的问题，并提供了PAC级别的理论保证，在高风险场景下实现了更安全、更稳定的决策。

> **ai_Abstract:** 本文针对蒙特卡洛树搜索（MCTS）中传统方法无法有效控制尾部风险的问题，提出了两种新颖的解决方案。首先是CVaR-MCTS，它将条件风险价值（CVaR）嵌入MCTS中，以实现对极端风险场景下损失的明确控制。其次是Wasserstein-MCTS（W-MCTS），它通过引入Wasserstein模糊集来解决有限样本导致的尾部风险估计偏差。研究证明了这两种方法的PAC尾部安全保证，并建立了它们的遗憾界。实验结果表明，这些方法在多种模拟环境中均优于现有基线，提供了鲁棒的尾部风险保证，并提高了回报和稳定性。

> **摘要翻译:** 仅根据蒙特卡洛树搜索（MCTS）中的预期回报进行决策，无法考虑到与决策相关的高风险、不利结果的潜在范围。为此，安全感知MCTS通常会考虑一些受限变体——通过引入某种形式的均值风险度量或硬成本阈值。这些方法未能提供针对极端或高风险结果（表示为尾部风险）的严格尾部安全保证，在高风险场景中可能导致严重后果。本文通过开发两种新颖的解决方案来解决这个问题。我们首先提出了CVaR-MCTS，它将相干尾部风险度量条件风险价值（CVaR）嵌入MCTS中。我们的CVaR-MCTS通过参数α实现了对“最差（1-α）%场景”中预期损失的明确尾部风险控制。其次，我们进一步解决了由于样本有限导致的尾部风险估计偏差问题。我们通过引入具有半径εs的一阶Wasserstein模糊集Pεs(s,a)来表征尾部风险估计中的不确定性，从而提出了Wasserstein-MCTS（或W-MCTS）。我们证明了CVaR-MCTS和W-MCTS的PAC尾部安全保证，并建立了它们的遗憾界。在各种模拟环境中的评估表明，我们提出的方法优于现有基线，有效地实现了鲁棒的尾部风险保证，并提高了回报和稳定性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [370] [R-Zero: Self-Evolving Reasoning LLM from Zero Data](https://arxiv.org/abs/2508.05004)
> *R-Zero：从零数据开始的自我演化推理大语言模型*

*Chengsong Huang, Wenhao Yu, Xiaoyang Wang, Hongming Zhang, Zongxia Li, Ruosen Li, Jiaxin Huang, Haitao Mi, Dong Yu* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 自我演化大语言模型, 零数据学习, 推理能力, 挑战者-求解器, R-Zero

**Comment:** 

> **TL;DR:** R-Zero是一个无需人工标注数据，通过挑战者和求解器模型协同演化，实现大语言模型自我提升推理能力的框架。

**AI_Comments:** R-Zero的创新之处在于其“从零数据”的自我演化机制，通过挑战者-求解器模型对抗性学习，突破了传统AI训练对大规模人工标注数据的依赖。这种方法为实现真正自主学习和超越人类智能的AI系统提供了潜在的范式转变，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有自我演化大语言模型过度依赖人工标注数据，限制了AI超越人类智能的能力，因此需要一种完全自主生成训练数据的方法。

**Method:** 引入R-Zero框架，初始化两个独立的模型：挑战者（Challenger）和求解器（Solver）。挑战者提出接近求解器能力边界的任务并获得奖励；求解器解决挑战者提出的日益具有挑战性的任务并获得奖励。通过这种交互，实现无需预设任务和标签的自我改进课程。

**Result:** R-Zero显著提升了不同基础大语言模型的推理能力，例如，使Qwen3-4B-Base在数学推理基准上提高了+6.49，在通用领域推理基准上提高了+7.54。

**Conclusion:** R-Zero通过其独特的挑战者-求解器协同演化机制，成功实现了大语言模型在无人工标注数据情况下的自我演化和推理能力提升，为超越人类智能的AI系统提供了新的路径。

> **ai_Abstract:** R-Zero是一个创新的全自主框架，旨在解决现有自我演化大语言模型对人工数据的高度依赖问题。它通过初始化一个“挑战者”和一个“求解器”模型，并让它们通过互相提出和解决任务来协同演化，从而从零开始生成训练数据并构建自我改进的学习课程。实验证明，R-Zero能显著提升大语言模型的推理能力，为AI发展超越人类智能提供了无需人工干预的路径。

> **摘要翻译:** 自我演化的大语言模型（LLMs）通过自主生成、完善和从自身经验中学习，为超智能提供了可扩展的路径。然而，现有训练此类模型的方法仍然严重依赖大量人工整理的任务和标签，通常通过微调或强化学习，这构成了AI系统向超越人类智能能力发展的根本瓶颈。为了克服这一限制，我们引入了R-Zero，一个完全自主的框架，它从零开始生成自己的训练数据。R-Zero从一个单一的基础大语言模型开始，初始化两个具有不同角色的独立模型：一个挑战者和一个求解器。这些模型被单独优化并通过交互共同演化：挑战者因提出接近求解器能力边缘的任务而获得奖励，求解器因解决挑战者提出的日益具有挑战性的任务而获得奖励。这个过程产生了一个有针对性的、自我改进的课程，而无需任何预先存在的任务和标签。经验上，R-Zero显著提高了不同骨干大语言模型的推理能力，例如，在数学推理基准上将Qwen3-4B-Base提升了+6.49，在通用领域推理基准上提升了+7.54。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [371] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
> *ConfAgents: 一种共形引导的多智能体框架，用于成本效益的医疗诊断*

*Huiya Zhao, Yinghao Zhu, Zixiang Wang, Yasha Wang, Junyi Gao, Liantao Ma* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-08-06**

**Keywords:** 自进化AI代理, 医疗诊断, 战略规划, HealthFlow, EHRFlowBench

**Comment:** 

> **TL;DR:** AI医疗代理受限于静态策略，HealthFlow通过元级别进化机制实现自主策略优化，并在EHRFlowBench上表现优于SOTA。

**AI_Comments:** 这篇论文的核心创新在于提出了一个自进化的AI代理框架HealthFlow，它通过元级别进化机制，使AI能够从经验中学习并优化其高级战略规划能力，而非仅仅是工具使用。这解决了当前AI代理在复杂领域（如医疗）中面临的关键限制。引入EHRFlowBench作为新的基准，也为后续研究提供了可重复评估的平台。其意义在于推动AI从被动执行者向主动规划者的转变，对于提升AI在科学发现和复杂决策领域的自主性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI代理在医疗保健研究中受限于静态、预定义策略，无法学习成为更好的战略规划者，这对于医疗等复杂领域是关键限制。

**Method:** 引入HealthFlow，一个自进化的AI代理，通过新颖的元级别进化机制，将程序性成功和失败提炼成战略知识库，自主完善其高级问题解决策略。同时引入EHRFlowBench，一个包含复杂、真实健康数据分析任务的新基准，用于可重复评估。

**Result:** 综合实验表明，HealthFlow的自进化方法显著优于最先进的代理框架。

**Conclusion:** 这项工作标志着从构建更好的工具使用者转向设计更智能、自进化的任务管理者，为更自主、有效的科学发现AI铺平了道路。

> **ai_Abstract:** 本文提出了HealthFlow，一个自进化的AI代理，旨在解决现有医疗AI代理在战略规划上的局限性。HealthFlow通过元级别进化机制，将经验提炼为战略知识，自主优化其问题解决策略。为验证其效能，研究引入了EHRFlowBench基准。实验结果显示，HealthFlow的性能超越了现有最先进的代理框架，预示着AI从工具使用向自主任务管理的转变。

> **摘要翻译:** 人工智能代理在医疗保健研究中的效力受到其对静态、预定义策略的阻碍。这造成了一个关键限制：代理可以成为更好的工具使用者，但无法学会成为更好的战略规划者，这对于医疗保健等复杂领域来说是一项关键技能。我们引入了 HealthFlow，一个自进化的人工智能代理，通过一种新颖的元级别进化机制克服了这一限制。HealthFlow 通过将程序性的成功和失败提炼成一个持久的战略知识库，自主地完善其自身的高级问题解决策略。为了锚定我们的研究并促进可重复的评估，我们引入了 EHRFlowBench，这是一个新的基准，其特点是包含源自同行评审临床研究的复杂、真实的健康数据分析任务。我们的综合实验表明，HealthFlow 的自进化方法显著优于最先进的代理框架。这项工作标志着从构建更好的工具使用者转向设计更智能、自进化的任务管理者，为更自主、有效的科学发现人工智能铺平了道路。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [372] [EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty Estimation for Energy Forecasting](https://arxiv.org/abs/2508.05454)
> *EnergyPatchTST：用于能源预测的带不确定性估计的多尺度时间序列Transformer*

*Wei Li, Zixin Wang, Qizheng Sun, Qixiang Gao, Fenglei Yang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 能源预测, 时间序列, Transformer, 不确定性估计, 多尺度

**Comment:** 

> **TL;DR:** EnergyPatchTST是一种用于能源预测的Patch时间序列Transformer扩展，通过多尺度特征提取、不确定性估计和预训练/微调，提高了预测精度和可靠性。

**AI_Comments:** 该论文通过引入多尺度特征提取和不确定性估计，有效解决了能源时间序列预测中的复杂性和不确定性问题，具有较强的创新性。同时，结合预训练和微调策略，增强了模型在有限数据场景下的实用性，对实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确可靠的能源时间序列预测对发电规划和分配具有重要意义。然而，现有的深度学习方法受限于多尺度时间动态和真实数据的不规则性。

**Method:** 本文提出了EnergyPatchTST，它是Patch时间序列Transformer的扩展，专门用于能源预测。其主要创新包括：(1) 多尺度特征提取机制以捕获不同时间分辨率的模式；(2) 通过蒙特卡洛消除估计不确定性的概率预测框架；(3) 整合未来已知变量（如温度和风况）；(4) 预训练和微调范例以增强有限能源数据集的性能。

**Result:** 在一系列通用能源数据集上的实验表明，EnergyPatchTST优于其他常用方法，预测误差降低了7-12%，并提供了可靠的不确定性估计。

**Conclusion:** EnergyPatchTST是能源时间序列预测的有效方法，能够显著提高预测精度并提供可靠的不确定性估计，为能源领域的时间序列预测提供了重要参考。

> **ai_Abstract:** 本研究提出了一种名为EnergyPatchTST的新型模型，旨在解决能源时间序列预测中多尺度动态和数据不规则性的挑战。作为Patch时间序列Transformer的扩展，EnergyPatchTST引入了多尺度特征提取机制、基于蒙特卡洛消除的概率预测框架以估计不确定性，并整合了未来已知变量。此外，它还利用预训练和微调策略来优化有限数据集的性能。实验结果表明，EnergyPatchTST在常用能源数据集上表现优异，预测误差降低了7-12%，并能提供可靠的不确定性估计，为能源领域的预测提供了重要参考。

> **摘要翻译:** 准确可靠的能源时间序列预测对发电规划和分配具有重要意义。目前，深度学习时间序列预测已成为主流方法。然而，多尺度时间动态和真实数据的不规则性导致现有方法的局限性。因此，我们提出了EnergyPatchTST，它是专门为能源预测设计的Patch时间序列Transformer的扩展。我们方法的主要创新点如下：(1) 多尺度特征提取机制以捕获不同时间分辨率的模式；(2) 通过蒙特卡洛消除估计不确定性的概率预测框架；(3) 未来已知变量（如温度和风况）的整合路径；以及 (4) 预训练和微调范例以增强有限能源数据集的性能。在一系列通用能源数据集上的实验表明，EnergyPatchTST优于其他常用方法，预测误差降低了7-12%，并提供了可靠的不确定性估计，这为能源领域的时间序列预测提供了重要参考。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [378] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
> *停靠博弈：用于快速、动态、准确预测柔性蛋白质-配体结合的循环自博弈*

*Youzhi Zhang, Yufei Li, Gaofeng Meng, Hongbin Liu, Jiebo Luo* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 分子对接, 蛋白质-配体结合, 博弈论, 循环自博弈, 药物发现

**Comment:** 

> **TL;DR:** 本文提出一种名为“停靠博弈”的博弈论框架和“循环自博弈”算法，通过蛋白质和配体模块的交替训练，显著提高了分子对接预测的准确性。

**AI_Comments:** 该论文创新性地将蛋白质-配体结合预测建模为双人博弈，并提出了独特的循环自博弈算法，通过相互适应和动态细化来解决传统多任务模型中配体和蛋白质对接性能不平衡的问题。其理论收敛性证明和在基准数据集上显著的性能提升（约10%）表明了该方法的有效性和重要性，对于药物发现领域的分子对接准确性提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前分子对接的多任务学习模型在配体对接方面的性能往往不如蛋白质口袋对接，主要原因是配体和蛋白质独特的结构复杂性导致了这种性能差异。

**Method:** 本文提出一个新颖的博弈论框架，将蛋白质-配体相互作用建模为双人博弈，称为“停靠博弈”。配体对接模块作为配体玩家，蛋白质口袋对接模块作为蛋白质玩家。为解决此博弈，开发了一种新颖的“循环自博弈”（LoopPlay）算法，通过两级循环交替训练这些玩家：外层循环中玩家交换预测姿态以促进相互适应，内层循环中每个玩家动态细化自身预测。理论上证明了LoopPlay的收敛性。

**Result:** 在公共基准数据集上进行的广泛实验表明，LoopPlay 在预测准确结合模式方面比现有最先进的方法提高了约10%。

**Conclusion:** LoopPlay算法通过其新颖的博弈论框架和循环自博弈机制，显著提高了分子对接的准确性，在药物发现中具有增强预测潜力的作用。

> **ai_Abstract:** 本文提出一种新颖的“停靠博弈”博弈论框架和“循环自博弈”（LoopPlay）算法，旨在解决分子对接中配体和蛋白质口袋对接性能不平衡的问题。该方法将蛋白质-配体相互作用建模为双人博弈，并利用两级循环交替训练配体和蛋白质玩家模块。实验结果表明，LoopPlay 在预测准确结合模式方面比现有技术提高了约10%，显示出其在药物发现中提高分子对接准确性的巨大潜力。

> **摘要翻译:** 分子对接是药物发现的关键方面，因为它预测小分子配体和蛋白质口袋之间的结合相互作用。然而，当前用于对接的多任务学习模型在配体对接方面的性能往往不如蛋白质口袋对接。这种差异很大程度上是由于配体和蛋白质独特的结构复杂性造成的。为了解决这个问题，我们提出了一种新颖的博弈论框架，将蛋白质-配体相互作用建模为双人博弈，称为“停靠博弈”，其中配体对接模块充当配体玩家，蛋白质口袋对接模块充当蛋白质玩家。为了解决这个博弈，我们开发了一种新颖的循环自博弈（LoopPlay）算法，通过两级循环交替训练这些玩家。在外层循环中，玩家交换预测的姿态，允许每个玩家整合对方的结构预测，这促进了多轮迭代中的相互适应。在内层循环中，每个玩家通过将其自身预测的配体或口袋姿态重新纳入模型来动态细化其预测。我们从理论上证明了LoopPlay的收敛性，确保了稳定的优化。在公共基准数据集上进行的广泛实验表明，与现有最先进的方法相比，LoopPlay 在预测准确结合模式方面取得了大约10%的改进。这突显了其在药物发现中提高分子对接准确性的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [379] [Towards Hallucination-Free Music: A Reinforcement Learning Preference Optimization Framework for Reliable Song Generation](https://arxiv.org/abs/2508.05011)
> *迈向无幻觉音乐：一种用于可靠歌曲生成的强化学习偏好优化框架*

*Huaicheng Zhang, Wei Tan, Guangzheng Li, Yixuan Zhang, Hangting Chen, Shun Lei, Chenyu Yang, Zhiyong Wu, Shuai Wang, Qijun Huang, Dong Yu* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 偏好优化, 幻觉控制, 歌曲生成, 音素错误率

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的偏好优化框架，以减少AI歌词生成歌曲中的幻觉，并显著降低了音素错误率。

**AI_Comments:** 本文的创新之处在于将强化学习与偏好优化相结合，专门解决音乐生成中的内容幻觉问题，这与传统的监督微调方法相比是一种新颖的尝试。利用音素错误率（PER）构建数据集和奖励模型也是一个重要的技术贡献。该框架的可迁移性是其显著优势，预示着更广泛的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI歌词生成歌曲模型存在内容幻觉问题，导致输出与输入歌词不符，且现有监督微调方法在自我改进和幻觉缓解方面存在局限性。

**Method:** 提出了一种利用偏好优化的新型强化学习框架。开发了一个通过音素错误率（PER）计算和基于规则的过滤构建的幻觉偏好数据集。实现了并评估了三种偏好优化策略：直接偏好优化（DPO）、近端策略优化（PPO）和组相对策略优化（GRPO）。DPO采用离线策略以提高正面标记的可能性，而PPO和GRPO采用在线策略，通过基于PER的奖励模型进行迭代优化。

**Result:** DPO实现了7.4%的音素错误率（PER）降低。PPO和GRPO分别实现了4.9%和4.7%的PER降低。客观和主观评估证实了该方法能有效抑制幻觉并保持音乐质量。

**Conclusion:** 这项工作提出了一个系统性的、基于强化学习的歌词生成歌曲幻觉控制解决方案。该框架具有可迁移性，为音乐风格一致性和音乐性增强提供了潜力，并为未来的生成式歌曲研究开辟了新途径。

> **ai_Abstract:** 本文旨在解决AI歌词生成歌曲中的内容幻觉问题，提出了一种基于强化学习的偏好优化框架。该框架构建了一个幻觉偏好数据集，并评估了DPO、PPO和GRPO三种偏好优化策略。实验结果表明，这些方法显著降低了音素错误率（DPO降低7.4%，PPO降低4.9%，GRPO降低4.7%），有效抑制了幻觉并保持了音乐质量。这项工作提供了一个系统性的强化学习解决方案，为未来音乐生成研究开辟了新方向。

> **摘要翻译:** 近期音频生成语言模型的进展加速了AI驱动的歌词生成歌曲。然而，这些模型经常遭受内容幻觉问题，产生与输入歌词不符的输出，从而损害了音乐的连贯性。当前的监督微调（SFT）方法受限于被动标签拟合，表现出有限的自我改进能力和较差的幻觉缓解效果。为解决这一核心挑战，我们提出了一种新颖的强化学习（RL）框架，利用偏好优化来控制幻觉。我们的主要贡献包括：(1) 开发了一个通过音素错误率（PER）计算和基于规则的过滤构建的鲁棒幻觉偏好数据集，以捕捉与人类期望的一致性；(2) 在RL框架内实现并评估了三种不同的偏好优化策略：直接偏好优化（DPO）、近端策略优化（PPO）和组相对策略优化（GRPO）。DPO采用离线策略来增强正面标记的可能性，实现了显著的7.4%的PER降低。PPO和GRPO采用在线策略，通过基于PER的奖励模型迭代优化序列，通过奖励最大化和KL正则化，分别实现了4.9%和4.7%的PER降低。全面的客观和主观评估证实，我们的方法在有效抑制幻觉的同时保留了音乐质量。至关重要的是，这项工作提出了一种系统性的、基于RL的歌词生成歌曲幻觉控制解决方案。该框架的可迁移性也为音乐风格一致性和音乐性增强提供了潜力，为未来的生成式歌曲研究开辟了新途径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [380] [Task complexity shapes internal representations and robustness in neural networks](https://arxiv.org/abs/2508.05463)
> *任务复杂度影响神经网络的内部表示和鲁棒性*

*Robert Jankowski, Filippo Radicchi, M. Ángeles Serrano, Marián Boguñá, Santo Fortunato* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 神经网络, 任务复杂度, 内部表示, 鲁棒性, 二值化

**Comment:** 

> **TL;DR:** 本文通过引入五种数据无关的探测方法，量化了任务难度如何影响多层感知器（MLP）中表示的拓扑结构和鲁棒性，发现任务复杂度决定了模型对权重二值化和噪声的敏感度，并提出了衡量任务复杂度的通用指标。

**AI_Comments:** 这项工作创新性地将网络科学的视角应用于分析神经网络的内部表示，特别是将MLP视为带符号的二分图，并引入了一系列新颖的数据无关探测方法。其重要性在于揭示了任务复杂度与模型鲁棒性及表示拓扑之间的深层联系，并提出了一种衡量任务复杂度的通用指标。这些发现不仅有助于提升神经网络的可解释性，也为模型压缩提供了基于任务复杂度的实用策略。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络虽然在许多任务中表现出色，但其内部运作机制仍是“黑箱”，特别是输入数据和问题复杂度如何影响内部表示尚不明确。

**Method:** 引入了五种数据无关的探测方法：剪枝、二值化、噪声注入、符号翻转和二分网络随机化。将MLP视为带符号、加权的二分图。在MNIST和Fashion-MNIST数据集上对比了简单和困难的分类任务，并使用上述探测方法量化任务难度对MLP表示的拓扑结构和鲁棒性的影响。

**Result:** 在困难任务模型中，权重二值化会导致准确率降至随机水平，而简单任务模型则保持鲁棒性。在二值化后的困难任务模型中，剪枝低幅度边缘会使性能出现急剧的相变。适度的噪声注入可以提高准确率，类似于随机共振效应，这与小幅度权重的最佳符号翻转有关。仅保留符号结构而非精确权重幅度，通过二分网络随机化足以保持高准确率。提出了衡量任务复杂度的通用指标：全精度与二值化或打乱神经网络性能之间的差距。

**Conclusion:** 研究结果强调了带符号二分拓扑结构在学习表示中的关键作用，并为模型压缩和可解释性提供了与任务复杂度一致的实用策略。

> **ai_Abstract:** 本文通过引入剪枝、二值化、噪声注入等五种数据无关的探测方法，深入探讨了任务复杂度如何影响多层感知器（MLP）的内部表示拓扑结构和鲁棒性。研究发现，困难任务模型对权重二值化更敏感，而简单任务模型则更鲁棒。此外，适度噪声可提高准确率，且仅保留权重符号结构即可维持高精度。这些发现定义了一种通用的任务复杂度衡量标准，并为神经网络模型压缩和可解释性提供了新思路。

> **摘要翻译:** 神经网络在广泛的任务中表现出色，但仍然是黑箱。特别是，它们的内部表示如何受到输入数据和所解决问题的复杂性的影响仍然不清楚。在这项工作中，我们引入了一套五种数据无关的探测方法——剪枝、二值化、噪声注入、符号翻转和二分网络随机化——来量化任务难度如何影响多层感知器（MLP）中表示的拓扑结构和鲁棒性。从网络科学的角度来看，MLP被表示为带符号的加权二分图。我们对比了MNIST和Fashion-MNIST数据集上的简单和困难分类任务。我们发现，在困难任务模型中，权重二值化会使准确率降至随机水平，而简单任务模型则保持鲁棒性。我们还发现，在二值化后的困难任务模型中剪枝低幅度边缘会揭示性能上的急剧相变。此外，适度的噪声注入可以提高准确率，类似于随机共振效应，这与小幅度权重的最佳符号翻转有关。最后，通过二分网络随机化，仅保留符号结构（而不是精确的权重幅度）足以保持高准确率。这些现象定义了一种与模型和模态无关的任务复杂度度量：全精度与二值化或打乱的神经网络性能之间的差距。我们的发现强调了带符号二分拓扑结构在学习表示中的关键作用，并提出了与任务复杂度相符的模型压缩和可解释性的实用策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [386] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
> *大型语言模型能否整合空间数据？对推理能力和计算弱点的实证洞察*

*Bin Han, Robert Wolfe, Anat Caspi, Bill Howe* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 空间数据整合, 空间推理, 计算几何, 城市数据

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）可以整合空间数据，但直接处理计算几何任务存在困难；通过提供相关特征并采用“审查和完善”方法，可显著提高其性能，使其成为传统方法的有前景替代方案。

**AI_Comments:** 本文为LLM在一个新颖的应用领域——空间数据整合——中的优势和劣势提供了有价值的实证洞察。其创新之处在于探索了如何有效利用LLM，特别是通过识别提供结构化特征可以弥补其在计算几何方面的弱点。所提出的“审查和完善”方法是一项实用的贡献。该论文对于强调LLM在传统NLP任务之外的潜力以及为未来的多模态整合研究指明方向具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于规则的空间数据整合方法无法覆盖所有边缘情况且需要人工干预，而机器学习方法需要大量的标记数据。本研究旨在探索大型语言模型（LLM）在整合大型、异构、嘈杂的城市空间数据集方面的潜力，以克服现有方法的局限性。

**Method:** 本研究首先分析了LLM对由人类经验介导的环境空间关系（如道路和人行道之间）的推理能力。接着，研究探讨了当LLM被提供相关特征以减少对空间推理的依赖时，其性能表现。此外，研究还采用了一种“审查和完善”方法来纠正错误的初始响应并保留准确的响应。

**Result:** LLM表现出空间推理能力，但难以将宏观环境与相关的计算几何任务联系起来，常产生逻辑不连贯的响应。然而，当提供相关特征（从而减少对空间推理的依赖）时，LLM能够生成高性能的结果。所采用的“审查和完善”方法在纠正错误同时保留准确响应方面非常有效。

**Conclusion:** 本研究的发现表明，大型语言模型是传统基于规则的启发式方法的一种有前景且灵活的替代方案，能够提升自适应空间数据整合的能力。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）在整合复杂城市空间数据集方面的潜力，旨在解决传统基于规则和机器学习方法的局限性。研究发现，LLM虽然具备空间推理能力，但直接处理计算几何任务时存在困难。然而，通过提供相关特征可显著提高其性能。论文还引入了一种成功的“审查和完善”方法进行错误纠正，并得出结论：LLM是用于高级空间数据整合的一种有前景且灵活的替代方案。

> **摘要翻译:** 我们探索大型语言模型（LLM）在赋能领域专家整合大型、异构和嘈杂的城市空间数据集方面的应用。传统的基于规则的整合方法无法覆盖所有边缘情况，需要人工验证和修复。机器学习方法需要收集和标记大量的任务特定样本。在本研究中，我们调查了LLM在空间数据整合方面的潜力。我们的分析首先考虑LLM如何推理由人类经验介导的环境空间关系，例如道路和人行道之间。我们表明，虽然LLM表现出空间推理能力，但它们难以将宏观环境与相关的计算几何任务联系起来，经常产生逻辑不连贯的响应。但是，当提供相关特征，从而减少对空间推理的依赖时，LLM能够生成高性能的结果。然后，我们采用了一种“审查和完善”方法，该方法在纠正错误的初始响应同时保留准确响应方面证明非常有效。我们讨论了在实际环境中采用LLM进行空间数据整合的实际意义，并概述了未来的研究方向，包括后训练、多模态整合方法和支持多样化数据格式。我们的发现将LLM定位为传统基于规则的启发式方法的有前景且灵活的替代方案，从而提升了自适应空间数据整合的能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [387] [Making Prompts First-Class Citizens for Adaptive LLM Pipelines](https://arxiv.org/abs/2508.05012)
> *让提示成为自适应大型语言模型管道的一等公民*

*Ugur Cetintemel, Shu Chen, Alexander W. Lee, Deepti Raghavan* | **Category: cs.AI, cs.CL, cs.DB** | **Updated: 2025-08-07**

**Keywords:** LLM管道, 提示管理, 自适应提示, SPEAR, 结构化提示

**Comment:** 

> **TL;DR:** 本文提出了SPEAR，一种语言和运行时，旨在使大型语言模型（LLM）管道中的提示结构化、自适应并成为执行模型的一等公民，从而实现运行时提示优化和结构化管理。

**AI_Comments:** 本文的创新之处在于将提示从简单的字符串提升为结构化、自适应且可管理的组件，使其成为LLM管道中的“一等公民”。这种方法有望显著提高LLM管道的灵活性、优化潜力和鲁棒性，是提升大型语言模型应用效率和可控性的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 现代LLM管道中，提示作为核心元素，仍是脆弱、不透明的字符串，与周围数据流脱节。这种脱节限制了提示的重用、优化和运行时控制。

**Method:** 本文提出了SPEAR，一种语言和运行时，旨在通过使提示结构化、自适应并成为执行模型的一等组件来解决提示管理问题。SPEAR支持运行时提示细化（根据运行时信号动态修改提示）和结构化提示管理（将提示片段组织成带版本视图）。SPEAR定义了一种提示代数，并支持手动、辅助和自动等多种细化模式。通过将提示逻辑视为结构化数据，SPEAR实现了操作符融合、前缀缓存和视图重用等优化。

**Result:** 初步实验量化了不同细化模式与静态提示和代理重试的行为，以及提示级别优化（如操作符融合）的影响。

**Conclusion:** 通过将提示逻辑视为结构化数据，SPEAR能够实现优化，并为开发者提供控制与自动化之间的平衡，从而提升LLM管道的灵活性、优化和鲁棒性。

> **ai_Abstract:** 现代LLM管道中的提示存在脆弱、不透明且与数据流脱节的问题，限制了其重用、优化和运行时控制。为解决此问题，本文提出SPEAR，一种语言和运行时，旨在将提示提升为结构化、自适应的执行模型一等公民。SPEAR支持基于运行时信号的动态提示细化和带有版本视图的结构化提示管理。它定义了提示代数，并提供多种细化模式，从而实现操作符融合等优化。初步实验验证了不同细化模式和提示级别优化的效果。

> **摘要翻译:** 现代LLM管道越来越类似于以数据为中心的系统：它们检索外部上下文、组合中间输出、验证结果并根据运行时反馈进行调整。然而，引导这一过程的核心元素——提示——仍然是脆弱、不透明的字符串，与周围的数据流脱节。这种脱节限制了重用、优化和运行时控制。
在本文中，我们描述了SPEAR的愿景和初步设计，SPEAR是一种语言和运行时，通过使提示结构化、自适应并成为执行模型的一等组件来填补提示管理空白。SPEAR实现了（1）运行时提示细化——根据置信度、延迟或缺失上下文等执行时信号动态修改提示；以及（2）结构化提示管理——将提示片段组织成带版本视图，并支持内省和日志记录。
SPEAR定义了一种提示代数，用于管理提示在管道中的构建和适应方式。它支持多种细化模式（手动、辅助和自动），为开发人员提供了控制和自动化之间的平衡。通过将提示逻辑视为结构化数据，SPEAR实现了操作符融合、前缀缓存和视图重用等优化。初步实验量化了不同细化模式与静态提示和代理重试的行为，以及提示级别优化（如操作符融合）的影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [388] [Embedding Alignment in Code Generation for Audio](https://arxiv.org/abs/2508.05473)
> *音频代码生成中的嵌入对齐*

*Sam Kouteili, Hiren Madhu, George Typaldos, Mark Santolucito* | **Category: cs.AI, cs.MM, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 代码生成, 音频嵌入, 嵌入对齐, 大型语言模型, 创意编码

**Comment:** 

> **TL;DR:** 本研究探讨了代码和音频嵌入空间之间的映射关系，发现它们并非简单的线性关系，但可以通过构建预测模型学习嵌入对齐，从而有助于生成更多样化的音乐代码。

**AI_Comments:** 该论文的创新点在于提出了代码和音频嵌入对齐的概念，并构建了相应的预测模型，以解决LLM在音频代码生成中输出多样性不足和缺乏音频反馈的问题。这对于提升创意编码领域的LLM应用具有重要意义，尤其是在音乐生成方面。其局限性可能在于模型的泛化能力和对复杂音乐结构的支持程度。

<details>
  <summary>Details</summary>

**Motivation:** LLM驱动的代码生成在创意编程（如现场编码）中潜力巨大，但当前模型难以提供独特多样的代码候选项，且缺乏对代码音频输出的直接洞察，这限制了用户实现其音乐意图的能力。

**Method:** 研究人员调查了代码和音频嵌入空间之间映射的拓扑结构。他们构建了一个预测模型，该模型给定代码能够预测输出音频嵌入，从而构建了一个代码-音频嵌入对齐图。

**Result:** 研究发现代码和音频嵌入之间不存在简单的线性关系。然而，补充这一发现的是，他们构建的预测模型表明可以学习到嵌入对齐图。

**Conclusion:** 通过学习代码和音频嵌入之间的对齐，可以帮助生成具有音乐多样性的代码输出。

> **ai_Abstract:** 本研究旨在解决大型语言模型在音频代码生成中难以提供多样化输出且缺乏音频洞察的问题。通过深入分析代码和音频嵌入空间之间的映射关系，研究发现两者并非简单的线性关联。为此，论文提出并构建了一个预测模型，能够学习代码与音频嵌入之间的对齐关系，从而实现基于代码预测音频嵌入，旨在促进生成更具音乐多样性的代码。

> **摘要翻译:** LLM驱动的代码生成有潜力通过让用户专注于结构主题而非语法细节来彻底改变创意编码工作，例如现场编码。在这些领域中，当提示大型语言模型时，用户可能会从考虑多个不同的代码候选项中受益，以更好地实现其音乐意图。然而，代码生成模型难以呈现独特多样的代码候选项，并且无法直接洞察代码的音频输出。为了更好地建立代码候选项和生成音频之间的关系，我们研究了代码和音频嵌入空间之间映射的拓扑结构。我们发现代码和音频嵌入不呈现简单的线性关系，但我们通过构建一个预测模型来补充这一点，该模型表明可以学习到嵌入对齐图。为了补充实现音乐多样化输出的目标，我们提出了一个模型，该模型给定代码可以预测输出音频嵌入，从而构建一个代码-音频嵌入对齐图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [394] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
> *适应性网络代理的认知二元性*

*Jiarun Liu, Chunhong Zhang, Zheng Hu* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-08-07**

**Keywords:** 网络代理, 认知二元性, 双过程理论, AGI, WebArena

**Comment:** 

> **TL;DR:** 本文受人类双系统认知启发，提出了一种名为CogniWeb的网络代理架构，有效整合了离线模仿学习和在线探索，在Web导航任务中实现了性能与效率的平衡，显著减少了令牌使用量。

**AI_Comments:** 本文的创新点在于将人类认知双过程理论巧妙地应用于网络代理设计，为整合离线模仿学习和在线探索提供了一个统一且高效的框架。CogniWeb架构在性能和效率之间取得了显著平衡，尤其是在减少令牌使用量方面的表现，对于开发资源高效的通用网络代理具有重要的实践意义和前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** Web导航是评估通用人工智能（AGI）的关键且具挑战性的领域，需要复杂的决策，且现有网络代理方法未能有效整合离线模仿学习和在线探索，导致效率或性能受限。

**Method:** 受到人类认知双过程理论的启发，本文将认知过程分解为快速的系统1（System 1）和慢速的系统2（System 2）。基于此，开发了模块化代理架构CogniWeb，该架构能够根据任务复杂性自适应地在快速直观处理和深思熟虑推理之间切换，以桥接离线学习和在线探索的差距。

**Result:** 在WebArena上的评估表明，CogniWeb取得了有竞争力的性能（43.96%的成功率），同时显著提高了效率（令牌使用量减少了75%）。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对Web导航中AGI面临的复杂决策挑战，提出了一种名为CogniWeb的模块化网络代理架构。该架构受人类认知双过程理论启发，将决策分为快速直观的系统1和慢速深思熟虑的系统2，并能根据任务复杂性自适应切换。CogniWeb有效整合了离线模仿学习和在线探索，在WebArena基准测试中表现出竞争性性能，并显著提升了效率，大幅减少了令牌使用量。

> **摘要翻译:** 网络导航是评估通用人工智能（AGI）的一个关键且具有挑战性的领域，它要求在高熵、动态环境以及组合爆炸式动作空间中进行复杂的决策。目前构建自主网络代理的方法要么侧重于离线模仿学习，要么侧重于在线探索，但很少能有效地整合这两种范式。受人类认知双过程理论的启发，我们推导出了一个原则性的分解，将其分为快速的系统1和慢速的系统2认知过程。这种分解为现有网络代理方法提供了一个统一的视角，弥合了直观反应行为的离线学习与深思熟虑规划能力的在线获取之间的鸿沟。我们在CogniWeb中实现了这一框架，这是一个模块化的代理架构，它根据任务复杂性自适应地在快速直观处理和深思熟虑推理之间切换。我们在WebArena上的评估表明，CogniWeb在保持显著更高效率（令牌使用量减少75%）的同时，取得了有竞争力的性能（43.96%的成功率）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [395] [SPaRFT: Self-Paced Reinforcement Fine-Tuning for Large Language Models](https://arxiv.org/abs/2508.05015)
> *SPaRFT：大型语言模型的自步强化微调*

*Dai Do, Manh Nguyen, Svetha Venkatesh, Hung Le* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 强化学习, 自步学习, 数据选择, 微调

**Comment:** 

> **TL;DR:** SPaRFT是一种自步学习框架，通过优化数据选择和使用时机，使大型语言模型能高效地进行强化微调，显著减少所需数据量，同时保持或提高性能。

**AI_Comments:** SPaRFT的创新之处在于其结合了数据降维和自适应数据选择的自步学习框架，有效解决了LLM强化微调中数据和计算资源消耗巨大的痛点。通过显著减少所需样本量，该方法使得RL微调对于资源受限的场景或小型模型变得更加可行，具有重要的实际意义和推广潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）通过强化学习（RL）微调展现出强大的推理能力，但这类方法需要大量数据和计算资源，对于小型模型不切实际。当前的课程学习或数据选择方法大多是启发式的或需要大量计算资源，限制了它们的可扩展性和泛化能力。

**Method:** 本文提出了SPaRFT，一个自步学习框架。首先，它应用“基于聚类的数据降维”技术，按语义和难度划分训练数据，提取一个紧凑且多样化的子集以减少冗余。然后，“多臂老虎机”方法将数据簇视为臂，根据模型当前性能优化训练样本的分配。

**Result:** 在多个推理基准测试中，SPaRFT实现了与最先进的基线相当或更好的准确性，同时使用的样本量减少了高达100倍。消融研究和分析进一步突出了数据聚类和自适应选择的重要性。

**Conclusion:** 精心策划、性能驱动的训练课程能够以最少的资源解锁大型语言模型的强大推理能力。

> **ai_Abstract:** 本文提出SPaRFT，一个针对大型语言模型（LLMs）的自步强化微调框架，旨在解决现有RL微调方法对数据和计算资源需求过大的问题。SPaRFT通过“基于聚类的数据降维”减少数据冗余，并利用“多臂老虎机”根据模型性能自适应选择训练样本。实验证明，SPaRFT在推理基准测试中能以远少的数据量（最高减少100倍）达到或超越SOTA基线性能，表明其能有效利用有限资源提升LLMs的推理能力。

> **摘要翻译:** 大型语言模型（LLMs）在通过强化学习（RL）进行微调时展现出强大的推理能力。然而，此类方法需要大量数据和计算，这使得它们对于较小的模型来说不切实际。当前课程学习或数据选择的方法在很大程度上是启发式的或需要大量的计算资源，限制了它们的可扩展性和泛化能力。我们提出了SPaRFT，一个自步学习框架，它通过优化使用哪些数据以及何时使用，根据模型正在训练的能力实现高效学习。首先，我们应用“基于聚类的数据降维”来根据语义和难度划分训练数据，提取一个紧凑但多样化的子集，从而减少冗余。然后，一个“多臂老虎机”将数据簇视为臂，优化以根据模型当前性能分配训练样本。在多个推理基准测试中的实验表明，SPaRFT实现了与最先进的基线相当或更好的准确性，同时使用的样本量减少了高达100倍。消融研究和分析进一步突出了数据聚类和自适应选择的重要性。我们的结果表明，精心策划、性能驱动的训练课程能够以最少的资源解锁大型语言模型的强大推理能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [396] [MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical Prediction Modelling](https://arxiv.org/abs/2508.05492)
> *MoMA：一种用于增强临床预测建模的多模态智能体混合架构*

*Jifan Gao, Mahmudur Rahman, John Caskey, Madeline Oguss, Ann O'Rourke, Randy Brown, Anne Stey, Anoop Mayampurath, Matthew M. Churpek, Guanhua Chen, Majid Afshar* | **Category: cs.AI, cs.LG, cs.MA** | **Updated: 2025-08-07**

**Keywords:** 多模态数据, 临床预测, 大型语言模型, 电子健康记录, 智能体架构

**Comment:** 

> **TL;DR:** MoMA是一种新的多模态智能体混合架构，它利用多个大型语言模型（LLM）智能体，将多模态电子健康记录（EHR）数据转化为统一文本摘要，以提高临床预测任务的准确性和灵活性，并优于现有最先进方法。

**AI_Comments:** MoMA的创新之处在于其“多模态智能体混合”架构，通过将不同模态的数据转化为统一的文本表示，有效利用了大型语言模型（LLM）处理多模态信息的能力。这种方法为临床预测建模提供了一种灵活且高性能的解决方案，有望推动医疗AI领域的发展。其模块化的设计也可能便于未来的扩展和改进。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态电子健康记录（EHR）数据提供了更丰富、互补的患者健康信息，但由于数据量要求高，有效整合不同数据模态进行临床预测建模仍然具有挑战性。

**Method:** MoMA架构利用多个大型语言模型（LLM）智能体进行临床预测。它包括：1. 专门的LLM智能体（“专家智能体”），将非文本模态（如医学图像和实验室结果）转换为结构化文本摘要。2. 另一个LLM（“聚合智能体”），将这些摘要与临床笔记结合，生成统一的多模态摘要。3. 第三个LLM（“预测智能体”），使用该统一摘要进行临床预测。

**Result:** 在三种使用真实世界数据集进行的预测任务中，MoMA在不同模态组合和预测设置下，均优于当前最先进的方法。

**Conclusion:** MoMA架构通过有效整合多模态电子健康记录数据，显著提高了临床预测任务的准确性和灵活性。

> **ai_Abstract:** MoMA是一种新颖的多模态智能体混合架构，旨在解决临床预测建模中整合多模态EHR数据的挑战。该架构利用“专家智能体”将非文本数据转换为文本摘要，然后由“聚合智能体”与临床笔记结合生成统一摘要，最后由“预测智能体”进行临床预测。实验结果表明，MoMA在多种临床预测任务中表现优异，超越了现有最先进的方法，展示了其在准确性和灵活性方面的优势。

> **摘要翻译:** 多模态电子健康记录（EHR）数据与单一模态数据相比，能为患者健康提供更丰富、互补的见解。然而，由于大量的数据需求，有效整合不同数据模态进行临床预测建模仍然具有挑战性。我们引入了一种新颖的架构，即多模态智能体混合（MoMA），旨在利用多个大型语言模型（LLM）智能体，使用多模态EHR数据执行临床预测任务。MoMA采用专门的LLM智能体（“专家智能体”）将非文本模态（如医学图像和实验室结果）转换为结构化文本摘要。这些摘要与临床笔记一起，由另一个LLM（“聚合智能体”）组合，生成一个统一的多模态摘要，然后由第三个LLM（“预测智能体”）用于生成临床预测。通过在三种使用真实世界数据集、不同模态组合和预测设置的预测任务上评估MoMA，MoMA优于当前最先进的方法，突显了其在各种任务中增强的准确性和灵活性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [402] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
> *MedMKEB：一个用于医学多模态大语言模型的综合知识编辑基准*

*Dexuan Xu, Jieyi Wang, Zhongyan Chai, Yongzhi Cao, Hanpin Wang, Huamin Zhang, Yu Huang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 医学多模态大语言模型, 知识编辑, 基准, 视觉问答, 可靠性

**Comment:** 

> **TL;DR:** 现有医学多模态大语言模型缺乏知识编辑基准。本文提出了MedMKEB，一个综合性基准，用于评估医学多模态大语言模型中的知识编辑，并揭示了现有方法的局限性。

**AI_Comments:** MedMKEB填补了医学多模态大语言模型知识编辑领域基准的空白，其创新性在于首次提供了一个综合性的评估框架，涵盖了多项关键评估维度。该基准结合了图像和文本模态，并融入了人类专家验证，显著提升了其可靠性。通过揭示现有方法的局限性，MedMKEB有望推动医学AI领域更高效、更可信赖的知识编辑算法的研发。

<details>
  <summary>Details</summary>

**Motivation:** 医学知识不断演变，多模态大语言模型（MLLMs）需要高效更新过时或错误信息而无需从头再训练。尽管文本知识编辑已广泛研究，但缺乏针对图像和文本模态的系统性多模态医学知识编辑基准。

**Method:** 提出了MedMKEB，第一个综合性基准，用于评估医学多模态大语言模型中知识编辑的可靠性、通用性、局部性、可移植性和鲁棒性。MedMKEB建立在一个高质量医学视觉问答数据集上，并包含反事实修正、语义泛化、知识迁移和对抗鲁棒性等精心构建的编辑任务。通过人类专家验证确保基准的准确性和可靠性。

**Result:** 对最先进的通用和医学多模态大语言模型进行的广泛单次编辑和顺序编辑实验表明，现有基于知识的编辑方法在医学领域存在局限性，这突出需要开发专门的编辑策略。

**Conclusion:** MedMKEB将作为标准基准，促进可信赖和高效的医学知识编辑算法的开发。

> **ai_Abstract:** 本文介绍了MedMKEB，一个针对医学多模态大语言模型（MLLMs）的综合知识编辑基准。鉴于医学知识的不断更新，以及现有文本知识编辑研究的局限性，MedMKEB旨在评估MLLMs中知识编辑的可靠性、通用性、局部性、可移植性和鲁棒性。该基准基于高质量医学视觉问答数据集，并包含多种编辑任务，通过人类专家验证。实验结果揭示了现有知识编辑方法在医学领域的不足，强调了开发专门编辑策略的重要性。MedMKEB有望成为推动医学知识编辑算法发展的标准基准。

> **摘要翻译:** 医学多模态大语言模型（MLLMs）的最新进展显著改善了医学AI，使其能够统一理解视觉和文本信息。然而，随着医学知识的不断演变，让这些模型高效更新过时或错误信息而无需从头再训练至关重要。尽管文本知识编辑已得到广泛研究，但仍缺乏涉及图像和文本模态的多模态医学知识编辑的系统性基准。为了填补这一空白，我们提出了MedMKEB，这是第一个旨在评估医学多模态大语言模型中知识编辑的可靠性、通用性、局部性、可移植性和鲁棒性的综合基准。MedMKEB建立在一个高质量的医学视觉问答数据集上，并通过精心构建的编辑任务进行丰富，包括反事实修正、语义泛化、知识迁移和对抗鲁棒性。我们结合了人类专家验证，以确保基准的准确性和可靠性。对最先进的通用和医学MLLMs进行的广泛单次编辑和顺序编辑实验表明，现有基于知识的编辑方法在医学领域存在局限性，这突显了开发专门编辑策略的必要性。MedMKEB将作为标准基准，促进可信赖和高效的医学知识编辑算法的开发。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [403] [Skin-SOAP: A Weakly Supervised Framework for Generating Structured SOAP Notes](https://arxiv.org/abs/2508.05019)
> *Skin-SOAP：一个用于生成结构化SOAP笔记的弱监督框架*

*Sadia Kamal, Tim Oates, Joy Wan* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 皮肤癌, SOAP笔记, 弱监督, 多模态框架, 临床文档

**Comment:** 

> **TL;DR:** 本文提出了Skin-SOAP，一个弱监督多模态框架，用于从有限的输入（如病变图像和稀疏文本）生成结构化的临床SOAP笔记，其性能可与大型语言模型媲美，并减轻了临床医生的负担。

**AI_Comments:** 该论文的创新之处在于其弱监督多模态方法，解决了医疗领域数据注释稀缺的关键挑战。通过结合图像和文本输入并减少对大量手动注释的依赖，Skin-SOAP为临床医生职业倦怠提供了一个实用的解决方案，并提高了文档记录的可扩展性。引入新颖的评估指标（MedConceptEval和CCS）也是对评估临床相关性的重要贡献。其与最先进大型语言模型媲美的性能进一步突显了其潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 手动生成详细的SOAP笔记对临床医生来说是劳动密集型的，并导致职业倦怠，尽管早期诊断和及时治疗对提高皮肤癌患者的生存率至关重要。这促使了对自动化解决方案的需求。

**Method:** 本文提出了“skin-SOAP”，一个弱监督多模态框架。它从有限的输入（病变图像和稀疏临床文本）生成临床结构化SOAP笔记。该方法减少了对手动注释的依赖，并引入了两个新颖的指标：MedConceptEval（评估与专家医学概念的语义对齐）和临床一致性评分（CCS）（分别评估与输入特征的语义对齐）。

**Result:** 所提出的方法在关键临床相关性指标上取得了与GPT-4o、Claude和DeepSeek Janus Pro相当的性能。

**Conclusion:** Skin-SOAP实现了可扩展的、临床基础的文档记录，同时减轻了临床医生的负担，并减少了对大量带注释数据的需求。

> **ai_Abstract:** 本文介绍了Skin-SOAP，一个弱监督多模态框架，旨在自动化生成皮肤癌患者的结构化SOAP笔记。通过利用病变图像和稀疏临床文本等有限输入，Skin-SOAP旨在减少手动笔记的劳动密集型过程并减轻临床医生的职业倦怠。该框架在临床相关性方面取得了与先进大型语言模型相当的性能，并引入了两个新的评估指标，MedConceptEval和临床一致性评分（CCS），分别评估语义对齐和输入特征一致性。这种方法促进了可扩展且具有临床依据的文档记录，同时减少了对大量手动注释的依赖。

> **摘要翻译:** 皮肤癌是全球最常见的癌症形式，每年医疗支出超过80亿美元。早期诊断、准确及时的治疗对于提高患者生存率至关重要。在临床环境中，医生使用详细的SOAP（主观、客观、评估和计划）笔记记录患者就诊情况。然而，手动生成这些笔记是劳动密集型的，并导致临床医生职业倦怠。在这项工作中，我们提出了skin-SOAP，一个弱监督多模态框架，用于从有限的输入（包括病变图像和稀疏临床文本）生成临床结构化SOAP笔记。我们的方法减少了对手动注释的依赖，实现了可扩展的、临床基础的文档记录，同时减轻了临床医生的负担，并减少了对大量带注释数据的需求。我们的方法在关键临床相关性指标上取得了与GPT-4o、Claude和DeepSeek Janus Pro相当的性能。为了评估这种临床相关性，我们引入了两个新颖的指标：MedConceptEval和临床一致性评分（CCS），它们分别评估与专家医学概念和输入特征的语义对齐。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [405] [LAG: Logic-Augmented Generation from a Cartesian Perspective](https://arxiv.org/abs/2508.05509)
> *LAG：基于笛卡尔视角的逻辑增强生成*

*Yilin Xiao, Chuang Zhou, Qinggang Zhang, Su Dong, Shengyuan Chen, Xiao Huang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 逻辑增强生成, 大型语言模型, 检索增强生成, 笛卡尔原理, 推理鲁棒性

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在知识密集型任务中存在幻觉和推理不足。LAG通过系统分解问题和依赖感知推理，显著提升了LLMs的推理鲁棒性并减少了幻觉。

**AI_Comments:** LAG的创新之处在于其将笛卡尔的系统性思维引入LLM的知识增强和推理过程，通过问题分解和依赖感知推理，有效弥补了RAG在复杂逻辑推理上的不足。其逻辑终止机制也是一个亮点，有助于提高效率并减少错误传播。这为提升LLM在知识密集型任务中的可靠性和准确性提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在知识密集型任务中表现出关键局限性，常产生幻觉。现有检索增强生成（RAG）系统虽能缓解这一问题，但由于其依赖直接语义检索且缺乏结构化逻辑组织，在复杂推理场景中表现不佳。

**Method:** LAG（逻辑增强生成）受笛卡尔原理启发，通过系统的问题分解和依赖感知推理来重构知识增强。它首先将复杂问题分解为按逻辑依赖排序的原子子问题，然后顺序解决这些子问题，利用之前的答案引导后续子问题的上下文检索。为防止错误传播，LAG引入了逻辑终止机制，在遇到无法回答的子问题时停止推理。最后，它综合所有子解决方案生成经过验证的响应。

**Result:** 在四个基准数据集上的实验表明，LAG显著增强了推理鲁棒性，减少了幻觉，并使LLM的问题解决与人类认知对齐。

**Conclusion:** LAG为现有RAG系统提供了一种有原则的替代方案，能够显著提升LLM在知识密集型任务中的推理能力和准确性。

> **ai_Abstract:** 本文提出了一种名为逻辑增强生成（LAG）的新范式，旨在解决大型语言模型在知识密集型任务中产生的幻觉和现有检索增强生成（RAG）在复杂推理中的不足。受笛卡尔思想启发，LAG通过将复杂问题分解为逻辑依赖的子问题，并按顺序解决它们，利用先前答案指导后续检索，从而确保推理的逐步 grounding。LAG还包含一个逻辑终止机制来防止错误传播。实验证明，LAG显著提高了LLM的推理鲁棒性，减少了幻觉，并使其问题解决过程更贴近人类认知，是RAG系统的一种有效替代。

> **摘要翻译:** 大型语言模型（LLMs）在广泛的任务中展示了卓越的能力，但在知识密集型任务中表现出关键局限性，当面对需要专业知识的问题时，经常产生幻觉。尽管检索增强生成（RAG）通过整合外部知识缓解了这一问题，但由于其依赖直接语义检索和缺乏结构化逻辑组织，它在复杂推理场景中表现不佳。受《方法论》中笛卡尔原理的启发，本文引入了逻辑增强生成（LAG），这是一种新颖的范式，通过系统的问题分解和依赖感知推理来重构知识增强。具体来说，LAG首先将复杂问题分解为按逻辑依赖排序的原子子问题。然后，它按顺序解决这些子问题，利用之前的答案引导后续子问题的上下文检索，确保逻辑链中的逐步 grounding。为防止错误传播，LAG引入了逻辑终止机制，在遇到无法回答的子问题时停止推理，并减少了在过度推理上的计算浪费。最后，它综合所有子解决方案以生成经过验证的响应。在四个基准数据集上的实验表明，LAG显著增强了推理鲁棒性，减少了幻觉，并使LLM问题解决与人类认知对齐，为现有RAG系统提供了一种有原则的替代方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [410] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
> *EasySize：基于LLM引导的启发式搜索的弹性模拟电路尺寸设计*

*Xinyue Wu, Fan Hu, Shaik Jani Babu, Yi Zhao, Xinfei Guo* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 模拟电路尺寸设计, LLM, 启发式搜索, 跨节点通用性, EasySize

**Comment:** 

> **TL;DR:** EasySize是一个轻量级框架，利用微调的LLM和启发式搜索，实现跨技术节点的模拟电路尺寸设计，显著优于现有方法并大幅减少资源消耗。

**AI_Comments:** EasySize的创新点在于其轻量级LLM结合启发式搜索的框架，以及在单一节点训练后即可在多个不同技术节点上实现高性能的通用性，这解决了传统AI方法在跨节点移植性和资源消耗方面的痛点。其对仿真资源的显著减少也极具价值。

<details>
  <summary>Details</summary>

**Motivation:** 模拟电路设计是芯片开发中一项耗时且依赖经验的任务。尽管AI有所进展，但开发通用、快速、稳定的模拟电路门尺寸设计方法仍面临重大挑战，尤其是在大型模型尺寸和跨技术节点移植性方面。

**Method:** EasySize是一个基于微调Qwen3-8B模型的轻量级门尺寸设计框架。它通过利用性能指标的易获得性（EOA）动态构建任务特定的损失函数，并结合全局差分进化（DE）和局部粒子群优化（PSO）在反馈增强流中进行高效的启发式搜索，实现跨工艺节点、设计规范和电路拓扑的通用适用性。

**Result:** EasySize尽管仅在350nm节点数据上微调，但在180nm、45nm和22nm技术节点上的5个运算放大器（Op-Amp）网络列表中表现出强大的性能，无需额外的针对性训练。它在86.67%的任务上优于广泛使用的基于强化学习的尺寸设计框架AutoCkt，并减少了超过96.67%的仿真资源。

**Conclusion:** EasySize可以显著减少门尺寸设计对人工专业知识和计算资源的依赖，从而加速和简化模拟电路设计过程。

> **ai_Abstract:** EasySize是一个创新的轻量级模拟电路尺寸设计框架，它结合了微调的大型语言模型（Qwen3-8B）和启发式搜索（DE、PSO），通过动态损失函数克服了现有方法对大模型和跨节点移植性的依赖。该框架仅通过在单一节点上的训练，便在多个不同技术节点上展示出卓越的性能，显著优于现有强化学习方法，并大幅减少了计算资源消耗，有望加速和简化模拟电路设计流程。

> **摘要翻译:** 模拟电路设计是芯片开发中一项耗时且依赖经验的任务。尽管人工智能取得了进展，但开发通用、快速、稳定的模拟电路门尺寸设计方法仍然是一项重大挑战。最近的方法将大型语言模型（LLM）与启发式搜索技术相结合以增强通用性，但它们通常依赖于大型模型尺寸并且缺乏跨不同技术节点的便携性。为了克服这些限制，我们提出了EasySize，这是第一个基于微调Qwen3-8B模型的轻量级门尺寸设计框架，旨在实现跨工艺节点、设计规范和电路拓扑的通用适用性。EasySize利用性能指标的易获得性（EOA）的差异来动态构建任务特定的损失函数，通过全局差分进化（DE）和局部粒子群优化（PSO）在反馈增强流中实现高效的启发式搜索。尽管仅在350nm节点数据上进行了微调，EasySize在180nm、45nm和22nm技术节点上的5个运算放大器（Op-Amp）网络列表中表现出强大的性能，无需额外的针对性训练，并且在86.67%的任务上优于广泛使用的基于强化学习的尺寸设计框架AutoCkt，同时减少了超过96.67%的仿真资源。我们认为EasySize可以显著减少门尺寸设计对人工专业知识和计算资源的依赖，从而加速和简化模拟电路设计过程。EasySize将在稍后开源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [411] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
> *基于结构熵最小化划分的对话方面级情感四元组抽取*

*Kun Peng, Cong Cao, Hao Peng, Zhifeng Hao, Lei Jiang, Kongjing Gu, Yanbing Liu, Philip S. Yu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 对话情感分析, 方面级情感抽取, 结构熵, 子对话划分, 四元组抽取

**Comment:** 

> **TL;DR:** 针对对话情感四元组抽取中全对话学习引入噪音的问题，提出用结构熵最小化划分对话为语义独立子对话，并采用两步抽取框架，实现了SOTA性能且计算成本更低。

**AI_Comments:** 该论文的创新点在于认识到对话中存在语义独立的子对话，并提出使用结构熵最小化来解决这一问题，从而避免了全局学习带来的噪音。这种划分策略结合两步抽取框架，不仅提高了抽取准确性，还显著降低了计算成本，为对话情感分析领域提供了一个高效且有效的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在对话情感四元组抽取中，通常学习整个对话的词关系，并假设情感元素均匀分布。然而，对话常包含多个语义独立的子对话，它们之间没有明确依赖关系，因此在整个对话中学习词关系会引入额外噪音。

**Method:** 本研究提出一种新的方法来解决对话方面级情感四元组抽取（DiaASQ）中的噪音问题。核心方法是利用结构熵最小化算法将对话划分为语义独立的子对话，旨在保留相关话语并区分不相关话语。在此基础上，引入一个两步抽取框架：首先在话语层面抽取单个情感元素，然后在子对话层面匹配四元组。

**Result:** 实验结果表明，该方法在DiaASQ任务上取得了最先进的性能（state-of-the-art），并且计算成本显著降低。

**Conclusion:** 通过将对话划分为语义独立的子对话并结合两步抽取框架，可以有效提高对话方面级情感四元组抽取的性能，并显著降低计算成本。

> **ai_Abstract:** 这篇论文提出了一种新的对话方面级情感四元组抽取（DiaASQ）方法，旨在解决现有方法因在整个对话中学习词关系而引入噪音的问题。作者发现对话包含语义独立的子对话，并提出使用结构熵最小化算法进行有效划分。在此基础上，设计了一个两步抽取框架：先在话语级别抽取情感元素，再在子对话级别匹配四元组。实验结果表明，该方法在DiaASQ任务上达到了最先进的性能，并显著降低了计算成本。

> **摘要翻译:** 对话方面级情感四元组抽取（DiaASQ）旨在从给定的多轮、多参与者对话中抽取所有目标-方面-观点-情感四元组。现有方法通常学习整个对话的词关系，假设情感元素均匀分布。然而，我们发现对话通常包含多个语义独立的子对话，它们之间没有明确的依赖关系。因此，在整个对话中学习词关系不可避免地会给抽取过程引入额外噪音。为了解决这个问题，我们的方法侧重于将对话划分为语义独立的子对话。在最小化这些子对话的同时实现完整性是一个重大挑战。简单地基于回复关系进行划分是无效的。相反，我们提出利用结构熵最小化算法来划分对话。这种方法旨在保留相关话语，同时尽可能区分不相关话语。此外，我们引入了一个两步抽取框架：首先在话语层面抽取单个情感元素，然后在子对话层面匹配四元组。大量的实验表明，我们的方法在DiaASQ中取得了最先进的性能，且计算成本大大降低。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [412] [The World According to LLMs: How Geographic Origin Influences LLMs' Entity Deduction Capabilities](https://arxiv.org/abs/2508.05525)
> *大型语言模型眼中的世界：地理起源如何影响大型语言模型的实体推理能力*

*Harsh Nishant Lalai, Raj Sanjay Shah, Jiaxin Pei, Sashank Varma, Yi-Chia Wang, Ali Emami* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** LLMs, 地理偏见, 实体推断, 20个问题游戏, 隐式偏见

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在实体推断中表现出地理偏见，对来自全球北方/西方实体的推断能力显著优于全球南方/东方，即使经过了偏见缓解。这项发现通过“20个问题”游戏和一个新数据集揭示。

**AI_Comments:** 本研究创新性地利用“20个问题”游戏来揭示LLMs中隐含的地理偏见，这是一种巧妙绕过传统提示防护措施的方法。Geo20Q+数据集的创建是一个重要贡献。它强调了即使经过广泛调优，LLMs仍保留了来自训练数据的根深蒂固的偏见，尤其是在全球代表性方面。游戏语言对性能影响甚微的发现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）经过广泛调优以减轻显式偏见，但它们常表现出植根于预训练数据的微妙隐式偏见。为了避免直接使用可能触发防护措施的人工问题探测LLMs，本研究旨在通过观察模型主动提问时的行为，来研究地理起源如何影响LLMs的实体推断能力。

**Method:** 研究提出通过LLMs主动提问来研究其行为，并选择“20个问题”游戏作为理想测试平台。构建了一个新数据集Geo20Q+，包含来自不同地区的知名人物和文化重要物品（如食物、地标、动物）。在两种游戏配置（标准20问和无限轮次）以及七种语言（英语、印地语、普通话、日语、法语、西班牙语和土耳其语）下测试了流行LLMs。

**Result:** 研究结果揭示了地理差异：LLMs在推断来自全球北方实体的成功率远高于全球南方，在推断来自全球西方实体的成功率远高于全球东方。虽然维基百科页面浏览量和预训练语料库频率与性能略有相关，但它们未能完全解释这些差异。值得注意的是，游戏所用语言对性能差距的影响微乎其微。

**Conclusion:** 这些发现表明，创新、自由形式的评估框架对于揭示在标准提示设置中隐藏的LLMs微妙偏见具有重要价值。通过分析模型如何启动和追求多轮推理目标，我们发现地理和文化差异嵌入在它们的推理过程中。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）中存在的微妙地理偏见，这些偏见即使在模型经过显式偏见缓解后依然存在。通过采用“20个问题”游戏和新颖的Geo20Q+数据集，研究发现LLMs在推断来自全球北方和西方实体方面的表现显著优于全球南方和东方。尽管维基百科页面浏览量和语料库频率与性能存在轻微相关，但它们未能完全解释这些差异，且游戏语言对性能差距影响甚微。这项工作强调了自由形式评估框架在揭示LLMs隐藏偏见方面的价值，并揭示了LLMs推理过程中固有的地理和文化差异。

> **摘要翻译:** 大型语言模型（LLMs）已经过广泛调优以减轻显式偏见，但它们通常会表现出根植于其预训练数据的微妙隐式偏见。我们提出通过研究模型主动提问时的行为，而不是直接用可能触发防护措施的人工问题来探测LLMs。为此，“20个问题”游戏，一个多轮推理任务，是一个理想的测试平台。我们使用一个新数据集Geo20Q+，系统地评估了实体推断中的地理性能差异，该数据集包含来自不同地区的知名人物和具有文化意义的物品（例如食物、地标、动物）。我们测试了流行的LLMs在两种游戏配置（标准的20个问题和无限轮次）以及七种语言（英语、印地语、普通话、日语、法语、西班牙语和土耳其语）下的表现。我们的结果揭示了地理差异：LLMs在推断来自全球北方实体的成功率远高于全球南方，在推断来自全球西方实体的成功率远高于全球东方。虽然维基百科页面浏览量和预训练语料库频率与性能略有相关，但它们未能完全解释这些差异。值得注意的是，游戏所用语言对性能差距的影响微乎其微。这些发现表明，创新、自由形式的评估框架对于揭示在标准提示设置中隐藏的LLMs微妙偏见具有重要价值。通过分析模型如何启动和追求多轮推理目标，我们发现地理和文化差异嵌入在它们的推理过程中。我们发布了数据集（Geo20Q+）和代码，网址为https://sites.google.com/view/llmbias20q/home。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [418] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
> *超越自动化：苏格拉底式人工智能、认知能动性以及编排式多智能体学习架构涌现的启示*

*Peer-Benedikt Degen, Igor Asanov* | **Category: cs.AI, cs.MA** | **Updated: 2025-08-07**

**Keywords:** 苏格拉底式AI, 多智能体系统, 高等教育, 批判性思维, 混合学习生态系统

**Comment:** 

> **TL;DR:** 本研究通过实验证明苏格拉底式AI导师能促进学生批判性思维，并提出将多智能体系统应用于教育的“编排式多智能体系统”概念，为混合学习生态系统提供实证和概念路线图。

**AI_Comments:** 该论文的创新之处在于提出了“编排式多智能体系统”（orchestrated MAS）这一概念，将AI从单一工具提升为由教育者策划、支持多样化学习路径的模块化智能体群，这为AI在教育中的应用提供了新的、更复杂的范式。其重要性在于通过实证研究证明了对话式AI（如苏格拉底式AI）不仅不会导致技能退化，反而能促进学生的元认知参与和高阶思维。此外，论文超越了技术可行性，深入探讨了系统层面对高等教育机构的深远影响，包括资金、教师角色和课程改革，提供了全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI正在迅速成为重塑知识生成、中介和验证方式的通用基础设施，这促使研究者探索如何利用AI促进更高阶思维，而非导致技能退化，并提出了将多智能体系统应用于教育的必要性。

**Method:** 本研究进行了一项对照实验，评估一个基于建构主义理论、旨在通过结构化对话辅助学生研究问题发展的苏格拉底式AI导师。实验对象为65名德国职前教师学生，将他们与苏格拉底导师的互动与未受指导的AI聊天机器人的互动进行了比较。

**Result:** 使用苏格拉底导师的学生报告称，他们获得了显著更高的批判性、独立性和反思性思维支持，这表明对话式AI可以激发元认知参与，并挑战了生成式AI使用导致技能退化的近期论述。

**Conclusion:** 本研究为教育领域的广泛教学转变（即使用由专业AI智能体组成的多智能体系统）提供了概念验证，并提出了“编排式多智能体系统”的概念。研究强调了人机协同能动性和教学对齐的混合学习生态系统，并提供了实证证据和概念路线图。

> **ai_Abstract:** 本论文探讨了生成式AI在高等教育中的演变及其影响。通过一项与65名德国职前教师学生的对照实验，研究评估了一个苏格拉底式AI导师，发现其能显著促进学生的批判性、独立性和反思性思维，挑战了AI导致技能退化的观点。在此基础上，论文提出了“编排式多智能体系统”的概念，即由教育者管理、支持多样化学习路径的模块化、教学对齐的AI智能体群。研究还提出了一个适应性的“提供-使用”模型，并探讨了这种系统对高等教育机构和学生的系统级影响，包括资金、教师角色、课程和评估实践，最后进行了成本效益分析，为混合学习生态系统提供了实证和概念框架。

> **摘要翻译:** 生成式AI不再是高等教育中的边缘工具。它正迅速演变为一种通用基础设施，重塑知识的生成、中介和验证方式。本论文展示了一项受控实验的结果，该实验评估了一个苏格拉底式AI导师，这是一个大型语言模型，旨在通过基于建构主义理论的结构化对话来辅助学生发展研究问题。这项研究在德国与65名职前教师学生进行，比较了与苏格拉底导师的互动和与未受指导的AI聊天机器人的互动。使用苏格拉底导师的学生报告称，他们获得了显著更高的批判性、独立性和反思性思维支持，这表明对话式AI可以激发元认知参与，并挑战了近期关于生成式AI使用导致技能退化的论述。这些发现为更广泛的教学转变提供了概念验证：即使用由专业AI智能体组成的多智能体系统（MAS）。为了概念化这一点，我们引入了编排式MAS的概念，即由教育者策划、通过差异化角色和协调互动支持多样化学习轨迹的模块化、教学对齐的智能体群。为了锚定这一转变，我们提出了一个适应性的“提供-使用”模型，学生在该模型中采纳这些智能体提供的教学内容。除了技术可行性之外，我们还研究了对高等教育机构和学生的系统级影响，包括资金需求、教师角色、课程、能力和评估实践的变化。我们以一项比较成本效益分析作为结论，强调了此类系统的可扩展性。总而言之，本研究为嵌入人机协同能动性和教学对齐的混合学习生态系统贡献了实证证据和概念路线图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [419] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
> *大型语言模型在抽象意义表示解析中的评估*

*Shu Han Ho* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** AMR解析, 大型语言模型, 微调, 语义表示, LLaMA 3.2

**Comment:** 

> **TL;DR:** 本文评估了对四种不同大型语言模型（LLMs）进行微调，以用于抽象意义表示（AMR）解析。结果表明，这种直接的微调方法可以达到与现有最先进（SOTA）AMR解析器相当的性能，特别是LLaMA 3.2表现出色。

**AI_Comments:** 该论文的创新之处在于，它证明了通过对仅解码器LLMs进行“直接”微调，就可以在AMR解析这一复杂的语义任务上达到与现有高度复杂的SOTA系统相当的性能。这可能为未来的AMR解析研究提供一个更简单、更高效的基线或方法，降低了进入门槛。其重要性在于，它验证了LLMs在处理结构化语义表示方面的潜力，并为LLM在自然语言理解领域的应用提供了新的视角。研究结果清晰地展示了不同LLM架构在特定子任务上的优劣，例如LLaMA 3.2在语义性能上的领先和Phi 3.5在结构有效性上的优势，这对于模型选择和未来优化具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 抽象意义表示（AMR）解析中，对仅解码器的大型语言模型（LLMs）进行微调，代表了一种有前景的新颖且直接的方向。本研究旨在全面评估这种方法的有效性。

**Method:** 本研究对四种不同的LLM架构（Phi 3.5, Gemma 2, LLaMA 3.2, 和 DeepSeek R1 LLaMA Distilled）进行了微调，并使用LDC2020T02 Gold AMR3.0测试集进行了评估。

**Result:** 结果显示，对仅解码器LLMs进行直接微调可以达到与复杂的最先进（SOTA）AMR解析器相当的性能。LLaMA 3.2在SMATCH F1得分上达到0.804，与APT + Silver (IBM)持平，并接近Graphene Smatch (MBSE)的0.854。分析还发现，LLaMA 3.2在语义性能上领先，而Phi 3.5在结构有效性上表现出色。

**Conclusion:** 通过直接微调仅解码器的大型语言模型，可以在抽象意义表示解析任务中取得与现有最先进方法相当的性能，证明了LLMs在该领域的潜力。

> **ai_Abstract:** 本文评估了对四种不同的仅解码器大型语言模型（Phi 3.5, Gemma 2, LLaMA 3.2, DeepSeek R1 LLaMA Distilled）进行微调，以用于抽象意义表示（AMR）解析。研究发现，这种直接的微调方法在LDC2020T02 Gold AMR3.0测试集上取得了与现有最先进AMR解析器相当的性能。具体而言，LLaMA 3.2表现出很强的竞争力，在SMATCH F1得分上达到0.804，与一些SOTA系统持平。研究还指出，LLaMA 3.2在语义性能上表现突出，而Phi 3.5在结构有效性方面表现优异。

> **摘要翻译:** 意义表示（AMR）是一种语义形式主义，它将句子意义编码为有根、有向、无环图，其中节点代表概念，边表示语义关系。对仅解码器大型语言模型（LLMs）进行微调，代表了AMR解析中一个有前景的新颖且直接的方向。本文对四种不同的LLM架构（Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled）使用LDC2020T02 Gold AMR3.0测试集进行了全面评估。我们的结果表明，对仅解码器LLMs进行直接微调可以达到与复杂的最先进（SOTA）AMR解析器相当的性能。值得注意的是，LLaMA 3.2通过直接微调方法，展现出与SOTA AMR解析器相当的竞争力。我们在完整的LDC2020T02测试集上取得了0.804的SMATCH F1分数，与APT + Silver (IBM)的0.804持平，并接近Graphene Smatch (MBSE)的0.854。在我们的分析中，我们还观察到一个一致的模式，即LLaMA 3.2在语义性能上领先，而Phi 3.5在结构有效性上表现出色。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [420] [Tractable Sharpness-Aware Learning of Probabilistic Circuits](https://arxiv.org/abs/2508.05537)
> *可处理的概率电路锐度感知学习*

*Hrithik Suresh, Sahil Sidheekh, Vishnu Shreeram M.P, Sriraam Natarajan, Narayanan C. Krishnan* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 概率电路, 过拟合, 锐度感知最小化, Hessian, 泛化性能

**Comment:** 

> **TL;DR:** 本文提出了一种基于Hessian的正则化器，用于训练概率电路（PCs），以解决过拟合问题，通过引导模型收敛到更平坦的最小值，从而提高泛化性能。

**AI_Comments:** 这篇论文的创新点在于将神经网络中的锐度感知最小化思想引入到概率电路（PCs）的学习中，并解决了Hessian迹在PCs中高效计算的难题。通过引导模型收敛到更平坦的最小值，有效缓解了PCs在数据稀疏条件下的过拟合问题，对于提升PCs的实用性和泛化能力具有重要意义。其理论贡献和实验验证都展现了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 概率电路（PCs）虽然具有强大的推断能力，但其增加的模型容量在数据有限时容易导致过拟合。研究发现，过拟合通常是由于收敛到泛化能力差的尖锐最优解造成的。

**Method:** 作者从对数似然景观的角度分析了PC的过拟合问题，并提出了一种基于Hessian的正则化器来训练PC。关键在于，他们展示了对数似然Hessian的迹（一种锐度代理）可以高效地计算。最小化Hessian迹会产生一个基于梯度范数的正则化器，该正则化器为EM算法提供了简单的闭合形式参数更新，并能与基于梯度的学习方法无缝集成。

**Result:** 在合成数据集和真实世界数据集上的实验表明，该方法能够持续引导PC走向更平坦的最小值，并提高泛化性能。

**Conclusion:** 通过引入可计算的Hessian迹正则化器，本文的方法成功地将概率电路引导至更平坦的最小值，从而有效缓解了过拟合问题，显著提高了模型在有限数据条件下的泛化能力。

> **ai_Abstract:** 本文针对概率电路（PCs）在数据有限时易出现过拟合的问题，提出了一种新的锐度感知学习方法。通过分析PCs的对数似然景观，发现过拟合与收敛到尖锐最优解有关。受神经网络锐度感知最小化启发，作者引入了一种基于Hessian的正则化器，并证明了其关键组成部分——对数似然Hessian的迹——可以高效计算。该正则化器能产生基于梯度范数的更新规则，并适用于EM和梯度学习。实验证明，该方法能引导PCs收敛到更平坦的最小值，从而显著提升泛化性能。

> **摘要翻译:** 概率电路（PCs）是一类生成模型，能够对各种查询进行精确且可处理的推断。尽管最近的发展使得深度和表达性PC的学习成为可能，但这种增加的容量往往会导致过拟合，尤其是在数据有限的情况下。我们从对数似然景观的角度分析了PC的过拟合问题，并表明它通常是由收敛到泛化能力差的尖锐最优解引起的。受神经网络中锐度感知最小化的启发，我们提出了一种基于Hessian的正则化器来训练PC。作为一个关键贡献，我们表明对数似然的Hessian迹——一种在深度神经网络中通常难以处理的锐度代理——可以为PC高效计算。最小化这个Hessian迹会产生一个基于梯度范数的正则化器，该正则化器为EM提供了简单的闭合形式参数更新，并与基于梯度的学习方法无缝集成。在合成和真实世界数据集上的实验表明，我们的方法持续引导PC走向更平坦的最小值，提高了泛化性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [430] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
> *QA-Dragon：面向知识密集型视觉问答的查询感知动态RAG系统*

*Zhuohang Jiang, Pangjing Wu, Xu Yuan, Wenqi Fan, Qing Li* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 检索增强生成, 视觉问答, 多模态推理, 动态检索, 查询感知

**Comment:** 

> **TL;DR:** 提出了QA-Dragon，一个查询感知的动态RAG系统，通过结合文本和图像检索来处理复杂的知识密集型视觉问答任务，并在Meta CRAG-MM挑战赛中显著提高了推理性能。

**AI_Comments:** QA-Dragon的创新之处在于其动态的查询感知检索机制，特别是结合了领域路由器和搜索路由器，实现了文本和图像的混合检索，从而有效支持多模态、多轮和多跳推理。这对于解决知识密集型VQA中复杂的查询和缓解MLLM幻觉问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG方法在知识密集型VQA中通常单独从文本或图像检索，限制了其处理需要多跳推理或最新事实知识的复杂查询的能力。

**Method:** 提出QA-Dragon系统，引入领域路由器识别查询主题领域进行领域特定推理，并引入搜索路由器动态选择最优检索策略。通过混合设置协调文本和图像搜索代理，支持多模态、多轮和多跳推理。

**Result:** 在KDD Cup 2025的Meta CRAG-MM挑战赛上进行了评估，显著增强了基础模型在挑战场景下的推理性能。在答案准确率和知识重叠分数上均有显著提升，单源任务优于基线5.06%，多源任务优于6.35%，多轮任务优于5.03%。

**Conclusion:** QA-Dragon通过其查询感知动态RAG系统，能够有效处理复杂的知识密集型视觉问答任务，并在多个挑战性场景下显著提升了性能。

> **ai_Abstract:** 本文提出QA-Dragon，一个面向知识密集型视觉问答（VQA）的查询感知动态检索增强生成（RAG）系统。针对现有RAG方法在处理复杂多模态查询时检索能力受限的问题，QA-Dragon设计了领域路由器和搜索路由器，以动态选择最佳的文本和图像检索策略，支持多模态、多轮和多跳推理。实验证明，QA-Dragon在Meta CRAG-MM挑战赛中显著提升了VQA任务的推理性能、答案准确率和知识重叠分数。

> **摘要翻译:** 检索增强生成（RAG）已被引入以通过将外部知识纳入生成过程来缓解多模态大型语言模型（MLLMs）中的幻觉，并且它已成为知识密集型视觉问答（VQA）中广泛采用的方法。然而，现有的RAG方法通常单独从文本或图像中检索，限制了它们处理需要多跳推理或最新事实知识的复杂查询的能力。为了解决这一限制，我们提出了QA-Dragon，一个面向知识密集型VQA的查询感知动态RAG系统。具体而言，QA-Dragon引入了一个领域路由器来识别查询的主题领域以进行领域特定推理，以及一个搜索路由器来动态选择最优检索策略。通过在混合设置中协调文本和图像搜索代理，我们的系统支持多模态、多轮和多跳推理，使其能够有效处理复杂的VQA任务。我们在KDD Cup 2025的Meta CRAG-MM挑战赛上评估了我们的QA-Dragon，它在挑战性场景下显著增强了基础模型的推理性能。我们的框架在答案准确率和知识重叠分数方面都取得了显著改进，在单源任务上优于基线5.06%，在多源任务上优于6.35%，在多轮任务上优于5.03%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [432] [Learning from Oblivion: Predicting Knowledge Overflowed Weights via Retrodiction of Forgetting](https://arxiv.org/abs/2508.05059)
> *从遗忘中学习：通过遗忘回溯预测知识溢出权重*

*Jinhyeok Jang, Jaehong Kim, Jung Uk Kim* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 知识溢出权重, 结构化遗忘, 元学习, 预训练权重, 知识迁移

**Comment:** 

> **TL;DR:** 本文提出KNOW预测，一种利用结构化遗忘及其逆转来生成知识丰富的预训练权重的方法，其性能优于传统微调。

**AI_Comments:** 这项工作通过利用深度学习中的“遗忘”现象，提出了一种反直觉但创新的方法来增强预训练模型的知识。它将遗忘视为一种可逆的过程，并通过回溯来“恢复”或“合成”额外的知识，这与传统的知识蒸馏或迁移学习方法不同。这种方法可能在数据稀缺的场景下尤其重要，因为它提供了一种从现有数据中提取更多潜在知识的途径。其创新性在于将遗忘动态重新解释为一种知识获取机制，而非仅仅是信息丢失。

<details>
  <summary>Details</summary>

**Motivation:** 预训练权重是深度学习的基石，但在数据稀缺场景下，如何获得包含更多知识的更好预训练权重以实现高效知识迁移和改善下游任务性能是一个基本问题。

**Method:** 本文引入了知识溢出权重（KNOW）预测策略，该策略利用结构化遗忘及其逆转来合成知识丰富权重。核心思想是通过在逐渐缩小的数集上进行顺序微调来诱导结构化遗忘过程，然后建模并逆转此过程以恢复知识。通过构建受控遗忘下的权重转换数据集，并采用元学习，特别是使用KNOW即时预测器（KNOWN）作为超模型来学习权重演变并预测增强权重。

**Result:** KNOW预测在不同数据集和架构上的广泛实验中始终优于朴素微调和简单权重预测，从而带来卓越的下游性能。

**Conclusion:** 这项工作为重新解释遗忘动态以推动深度学习中知识迁移的极限提供了新的视角。

> **ai_Abstract:** 本文提出了一种名为知识溢出权重（KNOW）预测的新颖策略，旨在通过利用结构化遗忘及其逆转来生成包含更多知识的预训练权重。研究发现，在逐步缩小的数据集上进行顺序微调会导致可建模和逆转的结构化遗忘过程，从而能恢复如同在更大数据集上训练获得的知识。通过构建权重转换数据集并采用元学习，特别是使用KNOW即时预测器（KNOWN）作为超模型来预测增强权重，该方法在多项实验中显著优于传统微调和简单权重预测，提升了下游任务性能。这项工作为深度学习中的知识迁移提供了新的视角。

> **摘要翻译:** 预训练权重已成为现代深度学习的基石，尤其是在数据稀缺的情况下，能够实现高效的知识迁移并提高下游任务性能。然而，一个基本问题仍然存在：我们如何才能获得包含更多超出给定数据集知识的更好预训练权重？在这项工作中，我们引入了**知识溢出权重（KNOW）**预测，这是一种利用结构化遗忘及其逆转来合成知识丰富权重的新颖策略。我们的关键见解是，在逐渐缩小的数据集上进行顺序微调会引发结构化遗忘过程，该过程可以被建模和逆转，以恢复知识，就好像在更大的数据集上训练过一样。我们构建了一个受控遗忘控制的权重转换数据集，并采用元学习来有效建模权重预测。具体来说，我们的**知识溢出权重即时预测器（KNOWN）**充当一个超模型，学习权重的普遍演变并预测具有更好泛化能力的增强权重。跨不同数据集和架构的广泛实验表明，KNOW预测始终优于朴素微调和简单权重预测，从而带来卓越的下游性能。我们的工作为重新解释遗忘动态以推动深度学习中知识迁移的极限提供了新的视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [433] [Adapting Vision-Language Models Without Labels: A Comprehensive Survey](https://arxiv.org/abs/2508.05547)
> *无标签的视觉-语言模型适应：一项综合调查*

*Hao Dong, Lijun Sheng, Jian Liang, Ran He, Eleni Chatzi, Olga Fink* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 视觉-语言模型, 无监督适应, 无标签, 综合调查, 分类法

**Comment:** 

> **TL;DR:** 这是一篇关于无标签视觉-语言模型适应方法的综合调查，提出了一个基于无标签视觉数据可用性和性质的分类法，并分析了核心方法、基准、挑战和未来方向。

**AI_Comments:** 这篇综述填补了无监督VLM适应领域系统性总结的空白，其提出的分类法有助于组织和理解现有方法，对研究人员具有重要指导意义。它不仅总结了现状，还展望了未来，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）在特定下游场景中直接应用时性能不佳，需要无标签适应方法，但目前缺乏统一的、面向任务的无监督VLM适应调查。

**Method:** 提出了一个基于无标签视觉数据可用性和性质的分类法，将现有方法分为四种范式：无数据迁移、无监督域迁移、分批测试时适应和在线测试时适应。在此框架内，分析了核心方法和适应策略，回顾了代表性基准，并指出了开放挑战和未来研究方向。

**Result:** 提出了一个将无标签VLM适应方法分为四种范式（无数据迁移、无监督域迁移、分批测试时适应、在线测试时适应）的分类法，系统分析了每种范式的核心方法和策略，回顾了代表性基准，并指出了开放挑战和未来研究方向。

**Conclusion:** 这篇调查旨在弥补无监督VLM适应领域缺乏统一调查的空白，提供了系统的理解，并展望了未来研究方向。

> **ai_Abstract:** 这篇论文对无标签视觉-语言模型（VLM）适应方法进行了全面的调查。由于VLM在特定下游任务中表现不佳且需要数据效率，无监督适应成为研究热点。作者提出了一个基于无标签视觉数据可用性的四种范式分类法（无数据迁移、无监督域迁移、分批测试时适应、在线测试时适应），并分析了每种范式的核心方法和策略。此外，论文还回顾了相关基准，并指出了未来的挑战和研究方向。

> **摘要翻译:** 视觉-语言模型（VLMs）在广泛的任务中展现出卓越的泛化能力。然而，当直接应用于特定的下游场景而没有进行任务特定适应时，它们的性能往往不尽如人意。为了在保持数据效率的同时提高其效用，最近的研究越来越关注不依赖于标记数据的无监督适应方法。尽管该领域日益受到关注，但仍然缺乏一个统一的、面向任务的无监督VLM适应调查。为了弥补这一空白，我们对该领域进行了全面而结构化的概述。我们提出了一个基于无标签视觉数据可用性和性质的分类法，将现有方法分为四个关键范式：无数据迁移（无数据）、无监督域迁移（大量数据）、分批测试时适应（批数据）和在线测试时适应（流数据）。在此框架内，我们分析了与每个范式相关的核心方法和适应策略，旨在建立对该领域的系统理解。此外，我们还回顾了跨不同应用的代表性基准，并强调了开放挑战和未来研究的有前景方向。相关文献的活跃维护仓库可在 https://github.com/tim-learn/Awesome-LabelFree-VLMs 获得。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [435] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
> *基于图的事件日志修复*

*Sebastiano Dissegna, Chiara Di Francescomarino, Massimiliano Ronzani* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 事件日志修复, 异构图神经网络, 过程挖掘, 缺失数据, 图神经网络

**Comment:** 

> **TL;DR:** 本文提出了一种基于异构图神经网络的方法来修复过程挖掘中事件日志的缺失属性，并在实验中表现出优于现有方法的性能，能够重建所有类型的缺失属性。

**AI_Comments:** 这篇论文的创新点在于将异构图神经网络应用于事件日志修复，这是一种相对较新的方法，能够更好地捕捉过程轨迹的复杂多模态和语义信息。与现有方法相比，它不仅能修复缺失值，而且能够全面修复所有类型的缺失属性，解决了现有无模型方法只关注部分属性的局限性，对于提高过程挖掘中数据质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 过程挖掘中事件日志的质量至关重要，但实际日志常因数据采集问题而存在缺失信息。现有修复方法存在局限性，如需要过程模型或无法全面修复所有缺失属性。

**Method:** 开发了一个异构图神经网络（Heterogeneous Graph Neural Network）模型。该模型接收包含不完整事件的轨迹，并返回这些事件中缺失的完整属性集。

**Result:** 该方法在两种合成日志和四种真实事件日志上，针对不同类型的缺失值进行了评估，并与一种基于自编码器的最先进方法进行了比较。结果显示，与主要关注修复事件属性子集的最先进无模型方法不同，所提出的方法在重建所有不同事件属性方面表现出非常好的性能。

**Conclusion:** 提出的基于异构图神经网络的事件日志修复方法能够有效且全面地重建所有类型的缺失事件属性，优于现有的一些无模型方法。

> **ai_Abstract:** 本文提出一种基于异构图神经网络（HGNN）的事件日志修复方法，旨在解决过程挖掘中事件日志因数据采集问题而导致的缺失信息。与传统方法不同，该HGNN模型能够利用图结构处理复杂的多模态序列，并恢复事件中所有缺失的属性。实验结果表明，该方法在重建所有不同事件属性方面表现出色，优于现有的基于自编码器的无模型修复方法。

> **摘要翻译:** 过程挖掘中事件日志的质量对于对其进行任何形式的分析都至关重要。在真实世界的事件日志中，数据采集可能并非易事（例如，由于手动活动的执行和相关的手动记录，或由于收集每个事件的所有属性时出现问题），并且通常可能导致记录的事件缺少一些信息。跟踪（或日志）重建问题的标准方法要么需要一个过程模型的可用性，该模型通过利用不同的推理技术来填充缺失值，要么采用机器学习/深度学习模型通过从相似案例中学习来恢复缺失值。近年来，一种能够处理编码为图的输入数据的新型深度学习模型——图神经网络——已经出现。图神经网络模型，尤其是异构图神经网络，提供了处理复杂多模态序列（如过程挖掘中的执行轨迹）的更自然表示的优势，从而实现更具表达性和语义丰富的编码。
在这项工作中，我们专注于开发一个异构图神经网络模型，该模型在给定包含一些不完整事件的轨迹后，将返回这些事件中缺失的完整属性集。我们通过与一种利用自编码器的最先进方法进行比较，在两种合成日志和四种真实事件日志上，针对不同类型的缺失值对我们的工作进行了评估。与主要关注修复事件属性子集的最先进无模型方法不同，所提出的方法在重建所有不同事件属性方面表现出非常好的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [438] [Human-AI Schema Discovery and Application for Creative Problem Solving](https://arxiv.org/abs/2508.05045)
> *人机协作图式发现与应用促进创造性问题解决*

*Sitong Wang* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 人机协作, 图式, 创造性问题解决, 隐性知识

**Comment:** 

> **TL;DR:** 本博士研究开发人机协作图式发现与应用框架，以支持创造性问题解决。

**AI_Comments:** 该研究的创新之处在于其专注于人机协作的图式发现与应用，旨在解决复杂领域中图式难以发现和应用的问题。其重要性在于通过图式引导的交互，使隐性知识更易于获取和操作，从而推动了更透明和协作的人机系统发展，对创造性问题解决具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类在创作时常依赖图式，但图式在复杂或不熟悉的领域中难以发现和应用。

**Method:** 开发了一个人机协作图式发现和应用框架，并设计系统支持用户通过示例理解抽象图式，并将图式转化为人机协作的共同创作工作流进行应用。

**Result:** 本研究提供了关于图式引导交互如何使隐性知识更易于获取和操作的见解，推动了更透明和协作的人机系统发展。

**Conclusion:** 通过图式引导的交互，可以使隐性知识更易于获取和操作，从而推进更透明和协作的人机系统。

> **ai_Abstract:** 本博士研究提出了一个人机协作图式发现与应用框架，旨在支持创造性问题解决。该研究设计系统帮助用户从示例中抽象图式，并将其操作化为共同创作工作流，以解决图式在复杂领域难以发现和应用的问题，最终促进更透明和协作的人机系统，使隐性知识更易于获取和操作。

> **摘要翻译:** 人类在创作时，无论是写作故事、设计软件还是作曲，都常常依赖潜在的结构模式——图式。图式有助于组织思想和引导探索，但它们往往难以发现和应用，尤其是在复杂或不熟悉的领域。我的博士研究开发了一个人机协作图式发现和应用框架，以支持创造性问题解决。我设计的系统支持用户通过示例进行理解，从而抽象出图式，并将图式操作化为应用于人机协作共同创作工作流。这项研究提供了关于图式引导交互如何使隐性知识更易于获取和操作的见解，从而推动了更透明和协作的人机系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [441] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
> *一种用于企业通信中识别和通知目标受众的可解释自然语言框架*

*Vítor N. Lourenço, Mohnish Dubey, Yunfei Bai, Audrey Depeige, Vivek Jain* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 自然语言框架, 目标受众识别, 企业通信, RDF图数据库, 大型语言模型

**Comment:** 

> **TL;DR:** 该论文提出了一种结合RDF图数据库和LLM的新颖框架，用于企业通信中精确识别目标受众并提供可解释的推理，以提高效率。

**AI_Comments:** 该论文的创新之处在于将RDF图数据库与LLM结合，为企业通信中的目标受众识别提供了可解释的自然语言框架。这解决了传统方法在信息过载和响应时间上的不足，通过提供透明的推理，有助于建立用户对系统的信任，同时提升通信效率，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型维护组织中，识别主题专家和管理复杂实体关系间的通信面临重大挑战，包括信息过载和响应时间延长，传统通信方法无法有效解决这些问题。

**Method:** 提出了一种结合RDF图数据库和大型语言模型（LLM）的新颖框架，通过规划-编排架构处理自然语言查询以实现精确的受众定位，并提供透明的推理。

**Result:** 该解决方案使通信所有者能够制定直观的查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，从而在提高组织内部通信效率的同时保持对系统的信任。

**Conclusion:** 该框架通过结合RDF图数据库和LLM，有效解决了大型维护组织中受众识别和通信管理的挑战，提高了效率和信任度。

> **ai_Abstract:** 本论文提出了一种创新的框架，旨在解决大型维护组织中识别专家和管理复杂通信的难题。该框架结合了RDF图数据库和大型语言模型（LLM），能够处理自然语言查询，从而实现精确的目标受众识别，并通过规划-编排架构提供可解释的推理。此方案旨在帮助通信负责人高效地构建查询，提升企业内部的通信效率和系统信任度。

> **摘要翻译:** 在大型维护组织中，识别主题专家和管理复杂实体关系间的通信带来了重大挑战——包括信息过载和更长的响应时间——这是传统通信方法无法有效解决的。我们提出了一种新颖的框架，它将RDF图数据库与大型语言模型（LLM）相结合，用于处理自然语言查询以实现精确的受众定位，同时通过规划-编排架构提供透明的推理。我们的解决方案使通信所有者能够制定直观的查询，结合设备、制造商、维护工程师和设施等概念，提供可解释的结果，从而在提高组织内部通信效率的同时保持对系统的信任。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [442] [Conformal Sets in Multiple-Choice Question Answering under Black-Box Settings with Provable Coverage Guarantees](https://arxiv.org/abs/2508.05544)
> *黑盒设置下多项选择问答中的保形集，具有可证明的覆盖保证*

*Guang Yang, Xinyang Liu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多项选择问答, 大型语言模型, 保形预测, 不确定性量化, 黑盒设置

**Comment:** 

> **TL;DR:** 针对大型语言模型在多项选择问答中不可靠性问题，本文提出了一种基于频率的不确定性量化方法，利用保形预测在黑盒设置下提供可证明的覆盖保证，提高了模型的可信度。

**AI_Comments:** 本文的创新之处在于，在黑盒设置下，通过基于频率的采样方法而非依赖于对数几率来量化大型语言模型的不确定性，并结合保形预测提供可证明的覆盖保证。这对于提升LLMs在高风险应用场景中的可靠性和可信度具有重要意义，尤其是在无法访问模型内部参数的黑盒环境中。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在多项选择问答（MCQA）中取得了显著进展，但其固有的不可靠性（如幻觉和过度自信）限制了它们在高风险领域的应用。

**Method:** 本文提出了一种在黑盒设置下基于频率的不确定性量化方法，利用保形预测（CP）来确保可证明的覆盖保证。该方法涉及对每个输入进行模型输出分布的多次独立采样，并以最频繁的样本作为参考来计算预测熵（PE）。

**Result:** 实验评估表明，在区分正确和不正确预测方面，基于频率的预测熵（PE）优于基于对数几率的预测熵（PE），以AUROC衡量。此外，该方法在用户指定的风险水平下有效控制了经验错误覆盖率，验证了采样频率可以作为黑盒场景中基于对数几率概率的有效替代品。

**Conclusion:** 这项工作为多项选择问答中可靠的不确定性量化提供了一个无分布、模型无关的框架，具有保证的覆盖范围，从而增强了大型语言模型在实际应用中的可信度。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）在多项选择问答（MCQA）中存在的不可靠性问题，提出了一种基于频率的不确定性量化方法。该方法在黑盒设置下，利用保形预测（CP）通过对模型输出分布进行多次独立采样来计算预测熵（PE），从而提供可证明的覆盖保证。实验结果表明，该方法在区分预测的正确性方面优于传统的基于对数几率的方法，并能有效控制错误覆盖率。这项工作为MCQA提供了一个可靠、无分布、模型无关的不确定性量化框架，显著提升了LLMs在实际应用中的可信度。

> **摘要翻译:** 大型语言模型（LLMs）在多项选择问答（MCQA）中取得了显著进展，但其固有的不可靠性，如幻觉和过度自信，限制了它们在高风险领域的应用。为了解决这个问题，我们提出了一种在黑盒设置下基于频率的不确定性量化方法，利用保形预测（CP）来确保可证明的覆盖保证。我们的方法涉及对每个输入进行模型输出分布的多次独立采样，以最频繁的样本作为参考来计算预测熵（PE）。对六个LLM和四个数据集（MedMCQA、MedQA、MMLU、MMLU-Pro）的实验评估表明，基于频率的PE在区分正确和不正确预测方面优于基于对数几率的PE，以AUROC衡量。此外，该方法在用户指定的风险水平下有效控制了经验错误覆盖率，验证了采样频率可以作为黑盒场景中基于对数几率概率的有效替代品。这项工作为MCQA中可靠的不确定性量化提供了一个无分布、模型无关的框架，具有保证的覆盖范围，从而增强了LLM在实际应用中的可信度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [443] [Automatic Image Colorization with Convolutional Neural Networks and Generative Adversarial Networks](https://arxiv.org/abs/2508.05068)
> *基于卷积神经网络和生成对抗网络的图像自动上色*

*Ruiyu Li, Changyuan Qiu, Hangrui Cao, Qihan Ren, Yuqing Qiu* | **Category: cs.AI, cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 图像上色, 卷积神经网络, 生成对抗网络, 分类, 对抗学习

**Comment:** 

> **TL;DR:** 本文探讨了使用卷积神经网络和生成对抗网络进行图像自动上色，旨在解决传统回归方法忽略颜色预测多模态性的问题。

**AI_Comments:** 该论文项目旨在解决图像上色中多模态性被忽略的问题，通过引入分类和对抗学习，结合CNN和GAN，有望提升上色效果。其创新点在于对传统回归方法的突破，并利用了大量可用的训练数据。然而，由于是项目探索阶段，具体实验结果和局限性尚未提及。

<details>
  <summary>Details</summary>

**Motivation:** 图像上色是一项具有挑战性的任务，因为它是一个严重不适定问题，丢失了图像三分之二的维度，导致自由度很大。然而，场景语义和表面纹理可以为颜色提供重要线索，并且存在大量可用于学习这些先验知识的训练数据。传统的上色方法通常将其视为回归任务，但这忽略了颜色预测的多模态性质。

**Method:** 本项目通过分类和对抗学习探索自动图像上色。研究者将在现有工作的基础上构建模型，并针对特定场景进行修改和比较。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文旨在解决图像上色这一挑战性问题，该问题因其固有的不适定性及颜色预测的多模态性而复杂。研究者提出通过结合分类和对抗学习的方法，利用卷积神经网络和生成对抗网络来实现图像的自动上色。该项目将基于现有研究进行模型构建、修改和比较。

> **摘要翻译:** 图像上色，即为灰度图像添加颜色的任务，近年来在计算机视觉领域受到了广泛关注，因为它具有颜色恢复和自动动画上色等多种应用领域 [15, 1]。上色问题具有挑战性，因为它是一个严重不适定问题，丢失了图像三分之三的维度，导致自由度很大。然而，场景的语义以及表面纹理可以为颜色提供重要线索：天空通常是蓝色的，云通常是白色的，草通常是绿色的，并且有大量的训练数据可用于学习这些先验知识，因为任何彩色图像都可以作为训练数据点 [20]。
上色最初被公式化为回归任务 [5]，这忽略了颜色预测的多模态性质。在这个项目中，我们探索通过分类和对抗学习实现自动图像上色。我们将在现有工作的基础上构建模型，针对我们特定的场景进行修改并进行比较。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [444] [Iterative Learning of Computable Phenotypes for Treatment Resistant Hypertension using Large Language Models](https://arxiv.org/abs/2508.05581)
> *使用大型语言模型迭代学习治疗抵抗性高血压的可计算表型*

*Guilherme Seidyo Imai Aldeia, Daniel S. Herman, William G. La Cava* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 可计算表型, 迭代学习, 高血压, 临床决策支持

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型（LLMs）如何通过迭代学习生成准确且可解释的可计算表型（CPs），以支持高血压临床决策，并发现其性能接近SOTA机器学习方法但所需训练数据更少。

**AI_Comments:** 这项研究具有创新性，它将大型语言模型应用于生成可计算表型，并通过迭代学习的方法提高了其准确性和解释性。其重要性在于，它为临床决策支持提供了一种数据效率更高且可扩展的新途径，尤其是在高血压等慢性病管理中。通过减少对大量标注数据的依赖，该方法有望加速医疗领域人工智能的应用落地。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在医学问答和编程方面表现出色，但其在生成可解释的可计算表型（CPs）方面的潜力尚未充分探索。本研究旨在探讨LLMs是否能为不同复杂程度的临床表型生成准确且简洁的CPs，以支持可扩展的临床决策，改善高血压患者的护理。

**Method:** 本文评估了LLMs的零样本（zero-shot）性能，并提出并测试了一种名为“合成、执行、调试、指导”（synthesize, execute, debug, instruct）的策略。该策略利用LLMs生成并利用数据驱动的反馈迭代优化可计算表型。

**Result:** 结果表明，大型语言模型结合迭代学习，能够生成可解释且相当准确的程序（可计算表型）。这些程序的性能接近最先进的机器学习方法，同时所需的训练示例显著减少。

**Conclusion:** 大型语言模型，通过迭代学习策略，能够有效地生成用于治疗抵抗性高血压的可解释且准确的可计算表型，且在数据效率方面优于现有方法，为可扩展的临床决策支持提供了新的可能性。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在生成可解释的可计算表型（CPs）方面的潜力，特别是针对治疗抵抗性高血压。研究评估了LLMs的零样本表现，并提出了一种“合成、执行、调试、指导”的迭代学习策略，通过数据反馈优化CPs。实验结果表明，结合迭代学习的LLMs能够生成准确且可解释的CPs，其性能可与先进的机器学习方法媲美，同时显著减少了所需的训练数据。

> **摘要翻译:** 大型语言模型（LLMs）在医学问答和编程方面展现出卓越的能力，但其生成可解释可计算表型（CPs）的潜力尚未得到充分探索。在这项工作中，我们研究了LLMs是否能为六种不同复杂度的临床表型生成准确且简洁的CPs，这些CPs可用于实现可扩展的临床决策支持，从而改善高血压患者的护理。除了评估零样本性能外，我们还提出并测试了一种“合成、执行、调试、指导”策略，该策略利用LLMs生成并使用数据驱动的反馈迭代优化CPs。我们的结果表明，LLMs结合迭代学习，可以生成可解释且相当准确的程序，其性能接近最先进的机器学习方法，同时所需的训练示例显著减少。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [450] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
> *一种结合决策树和大型语言模型代理的符号推理新架构*

*Andrew Kiruluta* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 符号推理, 决策树, LLM代理, 神经符号AI, 混合架构

**Comment:** 

> **TL;DR:** 该论文提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLM）的生成能力整合到一个协调的多智能体框架中，实现了强大的神经符号推理性能，并在多个推理基准上取得了显著改进。

**AI_Comments:** 该论文的创新之处在于其紧密的集成方法：将决策树和随机森林作为“可调用预言机”嵌入到大型语言模型代理的框架中，而非简单的松散耦合。这种设计有效地结合了决策树提供的可解释性推理能力和大型语言模型的强大生成与泛化能力，解决了神经符号AI领域的一个核心挑战。其多智能体和中心协调器的设计也增强了系统的鲁棒性和管理复杂推理任务的能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法在符号模块和神经网络模块之间是松散耦合的，本文旨在提出一种更紧密集成和统一的推理系统，以结合决策树的可解释性推理能力和大型语言模型的生成与泛化能力。

**Method:** 该论文提出了一种混合架构，将决策树和随机森林作为可调用的预言机（oracles）嵌入到统一的推理系统中。树基模块实现可解释的规则推理和因果逻辑，而LLM代理处理溯因推理、泛化和交互式规划。一个中央协调器维护信念状态一致性并协调代理与外部工具之间的通信，从而能够对结构化和非结构化输入进行推理。

**Result:** 在ProofWriter基准测试中，通过逻辑接地树验证，其蕴涵一致性提高了+7.2%。在GSM8k上，通过符号增强，在多步数学问题中的准确性提高了+5.3%。在ARC上，通过集成符号预言机，抽象准确性提高了+6.0%。在临床决策支持和科学发现中的应用表明，该系统能够符号化编码领域规则，同时利用LLM进行上下文推理和假设生成。

**Conclusion:** 该架构为通用神经符号推理提供了一个鲁棒、可解释和可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的混合架构，将决策树和大型语言模型（LLM）代理整合到统一的推理系统中，以实现神经符号推理。与以往松散耦合的方法不同，该设计将决策树作为可调用的预言机，赋予系统可解释的规则推理能力，而LLM代理则负责泛化和规划。通过中央协调器协调，系统能处理结构化和非结构化输入。实验结果表明，该系统在ProofWriter、GSM8k和ARC等推理基准上取得了显著的性能提升，并在临床决策支持和科学发现中展现了应用潜力，提供了一个鲁棒、可解释且可扩展的通用神经符号推理解决方案。

> **摘要翻译:** 我们提出了一种混合架构，将基于决策树的符号推理与大型语言模型（LLM）的生成能力整合到一个协调的多智能体框架中。与以往松散耦合符号和神经模块的方法不同，我们的设计将决策树和随机森林作为可调用的预言机嵌入到统一的推理系统中。基于树的模块实现可解释的规则推理和因果逻辑，而LLM代理处理溯因推理、泛化和交互式规划。一个中央协调器维护信念状态一致性，并协调代理与外部工具之间的通信，从而能够对结构化和非结构化输入进行推理。
该系统在推理基准上取得了强大的性能。在ProofWriter上，通过逻辑接地树验证，其蕴涵一致性提高了+7.2%。在GSM8k上，通过符号增强，在多步数学问题中的准确性提高了+5.3%。在ARC上，通过集成符号预言机，抽象准确性提高了+6.0%。在临床决策支持和科学发现中的应用表明，该系统能够符号化编码领域规则，同时利用LLM进行上下文推理和假设生成。该架构为通用神经符号推理提供了一个鲁棒、可解释和可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [451] [Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented Diffusion for Cross-domain Sequential Recommendation](https://arxiv.org/abs/2508.05074)
> *Align-for-Fusion：通过双向扩散协调三重偏好，用于跨域序列推荐*

*Yongfu Zha, Xinxin Dong, Haokai Ma, Yonghui Yang, Xiaodong Wang* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 跨域序列推荐, 扩散模型, 偏好融合, 数据稀疏性, 兴趣漂移

**Comment:** 

> **TL;DR:** 本文提出了HorizonRec，一个基于双向扩散模型的Align-for-Fusion框架，用于跨域序列推荐，以解决现有方法中粗粒度融合的问题，并通过引入混合条件分布检索和双向偏好扩散方法，有效实现了细粒度的三重域偏好融合。

**AI_Comments:** 本文创新性地将双向扩散模型引入跨域序列推荐领域，通过“Align-for-Fusion”范式解决了现有“Align-then-Fusion”范式中细粒度偏好融合不足的问题。其提出的混合条件分布检索策略和双向偏好扩散方法有效地解决了扩散模型中的噪声和不稳定性问题，提升了跨域推荐的准确性和鲁棒性，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的跨域序列推荐（CDSR）方法通常遵循“先对齐后融合”范式，在表示层面进行跨域对齐，然后机械地结合起来进行推荐，这忽略了领域特定偏好的细粒度融合。此外，现有基于扩散模型的推荐器存在随机噪声注入导致的不稳定性问题。

**Method:** 本文提出了一个名为HorizonRec的Align-for-Fusion框架，通过双向扩散模型（DMs）来协调三重偏好。具体地，它引入了一种混合条件分布检索策略，利用从用户真实行为逻辑中检索到的分布作为跨域语义桥梁，实现一致的多域偏好建模。此外，还提出了一种双向偏好扩散方法，用于在多域用户表示融合过程中抑制潜在噪声并强调与目标相关的兴趣。

**Result:** 在来自两个不同平台的四个CDSR数据集上进行的广泛实验表明，HorizonRec在细粒度的三重域偏好融合方面具有有效性和鲁棒性。

**Conclusion:** HorizonRec框架通过其创新的双向扩散模型和精细的偏好融合机制，成功解决了现有跨域序列推荐方法中粗粒度融合和扩散模型不稳定性问题，实现了高质量的跨域推荐。

> **ai_Abstract:** 本文针对现有跨域序列推荐（CDSR）方法中粗粒度融合和扩散模型不稳定性问题，提出了名为HorizonRec的Align-for-Fusion框架。该框架利用双向扩散模型（DMs）协调三重偏好，并通过混合条件分布检索策略构建跨域语义桥梁，以及双向偏好扩散方法抑制噪声并强调目标兴趣，实现了细粒度的多域用户表示融合。实验结果验证了HorizonRec在CDSR任务上的有效性和鲁棒性。

> **摘要翻译:** 个性化序列推荐旨在根据用户的行为序列预测合适的物品。为了缓解数据稀疏性和兴趣漂移问题，传统方法通常通过跨域转换整合来自其他领域的辅助行为。然而，现有的跨域序列推荐（CDSR）方法通常遵循“先对齐后融合”的范式，即在多个领域之间进行表示层面的对齐，然后机械地结合起来进行推荐，从而忽略了领域特定偏好的细粒度融合。受扩散模型（DMs）在分布匹配方面最新进展的启发，我们提出了一个Align-for-Fusion框架，用于CDSR，通过双向DMs协调三重偏好，称之为HorizonRec。具体来说，我们研究了DMs的不确定性注入，并确定随机噪声是现有基于DM的推荐器不稳定的关键来源。为了解决这个问题，我们引入了一种混合条件分布检索策略，该策略利用从用户真实行为逻辑中检索到的分布作为跨领域语义桥梁，从而实现一致的多领域偏好建模。此外，我们提出了一种双向偏好扩散方法，以在多领域用户表示融合过程中抑制潜在噪声并强调与目标相关的兴趣。在来自两个不同平台的四个CDSR数据集上进行的广泛实验表明，HorizonRec在细粒度的三重域偏好融合方面具有有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [452] [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612)
> *Shuffle-R1：通过以数据为中心的动态洗牌实现多模态大型语言模型高效强化学习框架*

*Linghao Zhu, Yiran Guan, Dingkang Liang, Jianzhong Ju, Zhenbo Luo, Bin Qin, Jian Luan, Yuliang Liu, Xiang Bai* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 多模态大型语言模型, 数据中心, 动态洗牌, 训练效率

**Comment:** 

> **TL;DR:** Shuffle-R1通过数据中心的动态洗牌，解决了多模态大型语言模型强化学习中训练效率低下的问题，从而提高了性能。

**AI_Comments:** 该论文的创新点在于它识别并解决了强化学习（RL）在多模态大型语言模型（MLLM）训练中两个此前未充分探索的效率瓶颈：优势崩溃和回滚静默。通过引入数据中心的动态策略，即成对轨迹采样和基于优势的轨迹洗牌，Shuffle-R1提供了一种新颖且有原则的方法来优化RL微调过程。其重要性在于能够显著提高MLLM的RL训练效率和效果，对于推动MLLM在复杂推理任务上的应用具有积极意义。该方法以最小的开销实现了性能提升，使其在实际应用中更具吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的强化学习（RL）流程在增强多模态大型语言模型（MLLM）的推理能力时，存在训练效率低下的问题。具体表现为“优势崩溃”（批次中大多数优势集中在零附近）和“回滚静默”（贡献非零梯度的回滚比例随时间减少），这导致梯度更新次优并阻碍长期学习效率。

**Method:** 我们提出了Shuffle-R1框架，通过动态重构轨迹采样和批次组成来提高RL微调效率。它包含两部分：1) 成对轨迹采样（Pairwise Trajectory Sampling），选择具有大优势的高对比度轨迹以提高梯度信号质量；2) 基于优势的轨迹洗牌（Advantage-based Trajectory Shuffle），通过信息丰富的批次重排增加有价值回滚的曝光度。

**Result:** 在多个推理基准上的实验表明，Shuffle-R1框架以最小的开销持续优于强大的RL基线。

**Conclusion:** 本研究结果强调了以数据为中心的适应性对于多模态大型语言模型（MLLM）中更高效强化学习训练的重要性。

> **ai_Abstract:** Shuffle-R1是一个为多模态大型语言模型（MLLM）设计的强化学习（RL）框架，旨在解决现有RL训练中遇到的“优势崩溃”和“回滚静默”问题，这些问题导致训练效率低下和梯度更新次优。该框架通过引入“成对轨迹采样”来选择高对比度轨迹以改善梯度信号质量，以及“基于优势的轨迹洗牌”来增加有价值回滚的曝光度，从而动态地重构轨迹采样和批次组成。实验结果表明，Shuffle-R1在多个推理基准上以最小的开销持续优于现有RL基线，强调了数据中心方法在提高MLLM强化学习效率方面的重要性。

> **摘要翻译:** 强化学习（RL）已成为增强多模态大型语言模型（MLLM）推理能力的有效后训练范式。然而，当前的RL流程常因两个未充分探索的问题而导致训练效率低下：优势崩溃（Advantage Collapsing），即批次中大多数优势集中在零附近；以及回滚静默（Rollout Silencing），即贡献非零梯度的回滚比例随时间减少。这些问题导致次优的梯度更新并阻碍长期学习效率。为了解决这些问题，我们提出了Shuffle-R1，一个简单而有原则的框架，通过动态重构轨迹采样和批次组成来提高RL微调效率。它引入了（1）成对轨迹采样（Pairwise Trajectory Sampling），选择具有大优势的高对比度轨迹以提高梯度信号质量；以及（2）基于优势的轨迹洗牌（Advantage-based Trajectory Shuffle），通过信息丰富的批次重排增加有价值回滚的曝光度。在多个推理基准上的实验表明，我们的框架以最小的开销持续优于强大的RL基线。这些结果强调了以数据为中心的适应性对于MLLM中更高效RL训练的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [458] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
> *“代理”一词已被稀释至失去效用，需要重新定义*

*Brinnae Bent* | **Category: cs.AI, cs.CY** | **Updated: 2025-08-07**

**Keywords:** 代理, 定义, 大型语言模型, 术语标准化, 人工智能

**Comment:** 

> **TL;DR:** AI中“代理”一词的含义模糊，导致研究和政策挑战。本文提出一个框架来重新定义“代理”，以提高清晰度和可复制性。

**AI_Comments:** 本文识别并解决了AI领域中一个关键的术语模糊问题，尤其是在大型语言模型时代背景下，其重要性日益凸显。提出的多维框架为“代理”概念提供了更清晰、更可操作的定义，有助于规范研究交流和系统评估。这种对基础概念的重新审视和标准化尝试具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能中“代理”一词的多种解释和近期AI能力的发展（特别是大型语言模型系统）加剧了这种模糊性，给研究沟通、系统评估、可复制性和政策制定带来了重大挑战。

**Method:** 本文通过历史分析和当代使用模式，提出了一个框架，该框架定义了系统被视为“代理”的明确最低要求，并根据环境交互、学习与适应、自主性、目标复杂性和时间连贯性等多维光谱来表征系统。

**Result:** 该方法为系统描述提供了精确的词汇，同时保留了该术语历史上多方面的性质。它提供了实用的工具，以提高研究的清晰度和可复制性，并支持更有效的政策制定。

**Conclusion:** “代理”一词需要重新定义，通过提出的框架和标准化建议，可以改善研究沟通、系统评估和政策发展。

> **ai_Abstract:** 本文指出，人工智能中“代理”一词的定义模糊，尤其在大语言模型兴起后，加剧了研究沟通和政策制定的困难。为解决此问题，论文通过历史分析和当前用法，提出了一个全新的“代理”定义框架，明确了成为代理的最低标准，并从多个维度对系统进行表征。该框架旨在提供精确的词汇，提升研究清晰度、可复制性，并支持更有效的政策制定。

> **摘要翻译:** 人工智能领域中“代理”（agent）一词长期以来在不同子领域中具有多种解释。人工智能能力，特别是大型语言模型系统的最新发展，加剧了这种模糊性，给研究沟通、系统评估和可复制性以及政策制定带来了重大挑战。本文认为“代理”一词需要重新定义。借鉴历史分析和当代使用模式，我们提出了一个框架，该框架定义了系统被视为代理的明确最低要求，同时根据环境交互、学习与适应、自主性、目标复杂性和时间连贯性等多维光谱来表征系统。这种方法为系统描述提供了精确的词汇，同时保留了该术语历史上多方面的性质。在审查了潜在的反驳意见和实施挑战后，我们为该领域未来的发展提供了具体建议，包括术语标准化和框架采纳的建议。所提出的方法为提高研究清晰度和可复制性提供了实用工具，同时支持更有效的政策制定。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [459] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
> *对齐而非分裂：重新审视多任务学习中的LoRA架构*

*Jinda Liu, Bo Cheng, Yi Chang, Yuan Wu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多任务学习, LoRA, 参数高效微调, 共享表示, LLM适应

**Comment:** 

> **TL;DR:** 本文挑战了多任务学习中LoRA变体使用多个适配器或头部的流行趋势，发现简化的多头架构和高秩的单适配器LoRA表现优异，并提出了Align-LoRA通过对齐任务表示来学习鲁棒的共享表示，显著超越基线。

**AI_Comments:** 本文对多任务学习中LLM的PEFT方法提出了颠覆性的见解。其创新点在于挑战了当前主流的多适配器/多头部LoRA变体范式，转而强调共享表示的重要性。通过实验证明了简化架构和高秩单适配器的有效性，并提出了Align-LoRA，通过显式对齐任务表示来提升性能。这为未来的LLM多任务适应提供了更简洁、更高效的方向，具有重要的实践意义和理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 在多任务学习中，LLM通常需要处理来自多个领域的不同任务。当前主流的LoRA变体倾向于使用多个适配器或头部来捕获任务特定的知识，但本文发现这种结构多样性的范式并非最优。

**Method:** 本文首先展示了具有高头间相似性的简化多头架构优于复杂的多适配器和多头系统。接着证明了具有足够高秩的标准单适配器LoRA也能达到极具竞争力的性能。在此基础上，提出了Align-LoRA，它引入了一个显式损失来对齐共享适配器空间中的任务表示。

**Result:** 实验表明，具有高头间相似性的简化多头架构显著优于复杂的多适配器和多头系统。标准单适配器LoRA在增加秩后也能达到极具竞争力的性能。Align-LoRA显著超越了所有基线模型。

**Conclusion:** 有效的多任务学习泛化依赖于学习鲁棒的共享表示，而不是隔离任务特定特征。Align-LoRA建立了一个更简单但更有效的范式来使LLM适应多任务。

> **ai_Abstract:** 本文挑战了多任务学习中LoRA变体通过多个适配器或头部来捕获任务特定知识的现有范式。研究发现，简化的多头架构（具有高头间相似性）和高秩的单适配器LoRA均能实现优异性能。基于此，论文提出了一种新假设：有效的多任务泛化应侧重于学习鲁棒的共享表示，而非隔离任务特定特征。为验证此假设，作者提出了Align-LoRA，通过引入显式损失来对齐共享适配器空间中的任务表示。实验证明，Align-LoRA显著超越了现有基线，为LLM的多任务适应提供了一个更简洁高效的范式。

> **摘要翻译:** 参数高效微调（PEFT）对于适应大型语言模型（LLM）至关重要。在实践中，LLM通常需要处理来自多个领域的不同任务，这种情况自然地通过多任务学习（MTL）来解决。在MTL的背景下，一种流行的趋势涉及带有多个适配器或头部的LoRA变体，它们倡导结构多样性以捕获任务特定知识。我们的发现直接挑战了这一范式。我们首先表明，具有高头间相似性的简化多头架构显著优于复杂的多适配器和多头系统。这促使我们质疑多组件范式本身，我们进一步证明，具有足够高秩的标准单适配器LoRA也能实现极具竞争力的性能。这些结果使我们得出了一个新的假设：有效的MTL泛化取决于学习鲁棒的共享表示，而不是隔离任务特定特征。为了验证这一点，我们提出了Align-LoRA，它引入了一个显式损失来对齐共享适配器空间中的任务表示。实验证实，Align-LoRA显著超越了所有基线，为LLM适应多个任务建立了一个更简单但更有效的范式。代码可在https://github.com/jinda-liu/Align-LoRA获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [460] [Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2508.05613)
> *Cooper：在大型语言模型强化学习中协同优化策略和奖励模型*

*Haitao Hong, Yuchen Yan, Xingyu Wu, Guiyang Hou, Wenqi Zhang, Weiming Lu, Yongliang Shen, Jun Xiao* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 大型语言模型, 奖励模型, 策略优化, 奖励作弊

**Comment:** 

> **TL;DR:** Cooper是一个强化学习框架，它通过协同优化策略模型和奖励模型来解决大型语言模型中奖励模型存在的鲁棒性不足和奖励作弊问题，从而提高性能。

**AI_Comments:** Cooper通过同时优化策略模型和奖励模型，创新性地解决了大型语言模型强化学习中奖励模型的鲁棒性和奖励作弊问题，这对于提升LLM在推理任务中的表现至关重要。其动态更新奖励模型和引入基于参考的奖励建模范式，为RL中奖励模型的设计和集成提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在推理任务中表现出色，但当前主流的奖励范式（基于模型的奖励和基于规则的奖励）都存在局限性：基于规则的奖励缺乏鲁棒性，而基于模型的奖励容易受到奖励作弊的影响。

**Method:** 我们提出了Cooper（Co-optimizing Policy Model and Reward Model），这是一个强化学习框架，它协同优化策略模型和奖励模型。Cooper利用基于规则的奖励在识别正确响应时的高精度，并动态构建和选择正负样本对以持续训练奖励模型。为了支持Cooper，我们引入了一种混合标注策略，可以高效准确地生成奖励模型的训练数据。我们还提出了一种基于参考的奖励建模范式，其中奖励模型将参考答案作为输入。基于此设计，我们训练了一个名为VerifyRM的奖励模型。

**Result:** 我们的实验表明，Cooper不仅缓解了奖励作弊问题，还提高了端到端强化学习的性能，例如在Qwen2.5-1.5B-Instruct上平均准确率提升了0.54%。VerifyRM在VerifyBench上实现了比同等大小的其他模型更高的准确率。

**Conclusion:** 动态更新奖励模型是对抗奖励作弊的有效方法，为更好地将奖励模型集成到强化学习中提供了参考。

> **ai_Abstract:** 本论文提出了Cooper，一个用于大型语言模型强化学习的新框架，旨在解决现有奖励模型（包括基于规则和基于模型的）的局限性，如鲁棒性不足和奖励作弊。Cooper通过协同优化策略模型和奖励模型来实现这一目标，并利用基于规则奖励的精确性动态构建训练样本以持续更新奖励模型。论文还引入了混合标注策略和基于参考的奖励建模范式，并训练了VerifyRM奖励模型。实验结果表明，Cooper有效缓解了奖励作弊并提升了RL性能，例如在Qwen2.5-1.5B-Instruct上实现了0.54%的准确率提升。

> **摘要翻译:** 大型语言模型（LLMs）在推理任务中表现出卓越的性能，其中强化学习（RL）是增强其推理能力的关键算法。目前，存在两种主流的奖励范式：基于模型的奖励和基于规则的奖励。然而，这两种方法都存在局限性：基于规则的奖励缺乏鲁棒性，而基于模型的奖励容易受到奖励作弊的影响。为了解决这些问题，我们提出了Cooper（Co-optimizing Policy Model and Reward Model），一个协同优化策略模型和奖励模型的RL框架。Cooper利用基于规则的奖励在识别正确响应时的高精度，并动态构建和选择正负样本对以持续训练奖励模型。这种设计增强了鲁棒性并减轻了奖励作弊的风险。为了进一步支持Cooper，我们引入了一种混合标注策略，可以高效准确地生成奖励模型的训练数据。我们还提出了一种基于参考的奖励建模范式，其中奖励模型将参考答案作为输入。基于此设计，我们训练了一个名为VerifyRM的奖励模型，它在VerifyBench上实现了比同等大小的其他模型更高的准确率。我们使用VerifyRM和Cooper进行了强化学习。我们的实验表明，Cooper不仅缓解了奖励作弊问题，还提高了端到端RL性能，例如在Qwen2.5-1.5B-Instruct上平均准确率提升了0.54%。我们的发现表明，动态更新奖励模型是对抗奖励作弊的有效方法，为更好地将奖励模型集成到RL中提供了参考。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [466] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
> *NomicLaw：大型语言模型在协作立法中涌现的信任与策略性论证*

*Asutosh Hota, Jussi P.P. Jokinen* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 多智能体模拟, 协作立法, 信任, 策略性论证

**Comment:** 

> **TL;DR:** 本文介绍了NomicLaw，一个多智能体模拟平台，用于研究LLMs在协作立法中如何形成信任、进行策略性论证，并展示了LLMs的社会推理和说服能力。

**AI_Comments:** 这项研究通过NomicLaw模拟提供了一个新颖的视角来探索LLMs在复杂多智能体环境中的行为，特别是其在法律制定这种高度依赖信任、论证和策略互动的场景。发现LLMs能自发形成联盟和背叛信任，并调整修辞，这揭示了LLMs深层的社会推理和说服能力，远超简单的文本生成。这对于理解LLMs的潜在社会动态以及设计更高级的自主AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前对大型语言模型在开放式、多智能体环境中（特别是涉及法律和道德困境的审议）行为的实证理解仍然有限。

**Method:** 引入了NomicLaw，一个结构化的多智能体模拟平台，LLMs在此平台中参与协作立法，通过对复杂的法律情景提出规则、论证其合理性并对同行提案进行投票。研究通过投票模式定量测量信任和互惠，并定性评估代理如何使用策略性语言来论证提案和影响结果。

**Result:** 涉及同质和异质LLM群体的实验表明，代理会自发形成联盟、背叛信任并调整其修辞以影响集体决策。结果突出了十个开源LLM的潜在社会推理和说服能力。

**Conclusion:** 本研究为未来能够进行自主谈判、协调和起草法律的人工智能系统设计提供了见解。

> **ai_Abstract:** 本文介绍了NomicLaw，一个用于研究大型语言模型（LLMs）在协作立法中行为的多智能体模拟平台。通过让LLMs在法律情景中提出、论证和投票规则，研究量化了信任和互惠，并分析了策略性语言的使用。实验结果表明，LLMs能够自发形成联盟、背叛信任并调整其论证策略以影响集体决策，揭示了LLMs潜在的社会推理和说服能力，为未来AI系统在法律领域的自主谈判和立法提供了设计思路。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展已将其能力从基本的文本处理扩展到复杂的推理任务，包括法律解释、论证和策略性互动。然而，在开放式、多智能体环境中，特别是涉及法律和道德困境审议的LLM行为的实证理解仍然有限。我们引入了NomicLaw，一个结构化的多智能体模拟平台，LLMs在此平台中参与协作立法，通过对复杂的法律情景提出规则、论证其合理性并对同行提案进行投票。我们通过投票模式定量测量信任和互惠，并定性评估代理如何使用策略性语言来论证提案和影响结果。涉及同质和异质LLM群体的实验表明，代理会自发形成联盟、背叛信任并调整其修辞以影响集体决策。我们的结果突出了十个开源LLM的潜在社会推理和说服能力，并为未来能够进行自主谈判、协调和在法律环境中起草立法的人工智能系统设计提供了见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [467] [JPS: Jailbreak Multimodal Large Language Models with Collaborative Visual Perturbation and Textual Steering](https://arxiv.org/abs/2508.05087)
> *JPS：通过协同视觉扰动和文本引导越狱多模态大型语言模型*

*Renmiao Chen, Shiyao Cui, Xuancheng Huang, Chengwei Pan, Victor Shea-Jay Huang, QingLin Zhang, Xuan Ouyang, Zhexin Zhang, Hongning Wang, Minlie Huang* | **Category: cs.AI, cs.CL, cs.CR, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 越狱攻击, 多模态大型语言模型, 视觉扰动, 文本引导, 恶意意图实现率

**Comment:** 

> **TL;DR:** JPS提出了一种新的越狱多模态大型语言模型（MLLMs）的方法，通过结合视觉扰动和文本引导提示，不仅提高了攻击成功率（ASR），还显著提升了恶意意图实现率（MIFR），解决了现有方法生成低质量输出的问题。

**AI_Comments:** JPS的创新之处在于其协同优化视觉扰动和文本引导提示的策略，这不仅提升了越狱攻击的成功率，更重要的是，通过引入恶意意图实现率（MIFR）这一新颖的评估指标，解决了以往研究中越狱内容质量低下的痛点。这种对攻击“质量”的关注，使得JPS能够生成更具实质性危害的内容，这对于理解和防御未来更复杂的越狱攻击具有重要意义。该研究方法新颖且具有实际影响力，同时也提醒了我们MLLMs安全防护的严峻性。

<details>
  <summary>Details</summary>

**Motivation:** 当前针对多模态大型语言模型（MLLMs）的越狱攻击研究主要关注最大化攻击成功率（ASR），但往往忽视了生成响应是否真正满足攻击者的恶意意图，这导致了绕过安全过滤器但缺乏实质性有害内容的低质量输出。本文旨在弥补这一空白。

**Method:** 本文提出了JPS，一种通过视觉图像扰动和文本引导提示协同作用实现越狱的方法。具体来说，JPS利用目标导向的对抗性图像扰动来有效绕过安全过滤器，并通过多智能体系统优化的“引导提示”来专门引导LLM响应以满足攻击者的意图。这些视觉和文本组件通过迭代协同优化以增强性能。为了评估攻击结果的质量，本文提出了恶意意图实现率（MIFR）指标，并使用基于推理LLM的评估器进行评估。

**Result:** 实验表明，JPS在各种MLLMs和基准测试中，在攻击成功率（ASR）和恶意意图实现率（MIFR）方面都达到了新的最先进水平，分析也证实了其有效性。

**Conclusion:** JPS通过协同视觉扰动和文本引导，显著提升了多模态大型语言模型的越狱攻击效果，尤其是在恶意意图实现方面，为越狱攻击研究设定了新的基准。

> **ai_Abstract:** 本研究提出JPS，一种针对多模态大型语言模型（MLLMs）的新型越狱攻击方法，旨在解决现有方法在满足攻击者恶意意图方面表现不足的问题。JPS通过结合目标导向的视觉扰动和经多智能体系统优化的文本引导提示，实现对MLLMs安全过滤器的有效绕过并引导生成高质量的恶意内容。为评估攻击效果，引入了恶意意图实现率（MIFR）指标。实验结果表明，JPS在攻击成功率（ASR）和MIFR上均达到了最先进水平，验证了其有效性。

> **摘要翻译:** 针对多模态大型语言模型（MLLMs）的越狱攻击是一个重要的研究焦点。当前研究主要侧重于最大化攻击成功率（ASR），往往忽视了生成的响应是否真正满足攻击者的恶意意图。这种疏忽经常导致绕过安全过滤器但缺乏实质性有害内容的低质量输出。为了弥补这一空白，我们提出了JPS，通过协同视觉扰动和文本引导越狱MLLMs，它通过视觉图像和文本引导提示的协作来实现越狱。具体来说，JPS利用目标导向的对抗性图像扰动来有效绕过安全过滤器，辅以通过多智能体系统优化的“引导提示”，以专门引导LLM响应满足攻击者的意图。这些视觉和文本组件进行迭代协同优化以增强性能。为了评估攻击结果的质量，我们提出了恶意意图实现率（MIFR）指标，并使用基于推理LLM的评估器进行评估。我们的实验表明，JPS在各种MLLMs和基准测试中，在ASR和MIFR方面都设定了新的最先进水平，分析也证实了其有效性。代码可在https://github.com/thu-coai/JPS获取。警告：本文包含潜在敏感内容。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [468] [OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks](https://arxiv.org/abs/2508.05614)
> *OmniEAR：具身任务中代理推理的基准测试*

*Zixuan Wang, Dingming Li, Hongxing Li, Shuo Chen, Yuchen Yan, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 具身推理, 大型语言模型, 基准测试, 多代理协作, 工具使用

**Comment:** 

> **TL;DR:** OmniEAR是一个用于评估大型语言模型在具身任务中推理能力的综合框架。研究发现，在需要从约束条件进行推理时，模型的性能显著下降，尤其是在工具使用、隐式协作和复杂任务中。完全的环境信息反而会降低协作性能，且微调对多代理任务的提升微乎其微，表明当前模型在具身推理方面存在根本性挑战。

**AI_Comments:** OmniEAR的创新之处在于其要求代理动态获取能力和自主决定协作策略，这比现有基准更接近真实世界的具身推理挑战。该研究重要性在于它揭示了大型语言模型在具身推理方面的深层局限性，特别是在处理约束、过滤信息和多代理协作方面。这些发现为未来具身AI系统的发展指明了方向，强调需要开发能够处理复杂物理交互和动态协作的新架构。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在抽象推理方面表现出色，但其在具身代理推理方面的能力尚未得到充分探索。现有基准测试通常提供预定义工具集或明确的协作指令，未能充分评估模型动态获取能力和自主决定协作策略的能力。

**Method:** 本文提出了OmniEAR，一个用于评估语言模型在具身任务中对物理交互、工具使用和多代理协作进行推理的综合框架。它要求代理根据任务需求动态获取能力并自主确定协作策略。通过基于文本的环境表示，该框架在1,500个涵盖家庭和工业领域的场景中建模连续物理属性和复杂的空间关系。

**Result:** 系统评估显示，当模型必须从约束条件进行推理时，性能会严重下降：在有明确指令的情况下成功率达85-96%，但在工具推理中降至56-85%，在隐式协作中降至63-85%，复合任务的失败率超过50%。令人惊讶的是，完整的环境信息反而会降低协作性能，表明模型无法过滤出与任务相关的约束。微调显著改善了单代理任务（0.6%提升至76.3%），但对多代理任务的提升微乎其微（1.5%提升至5.5%），暴露出根本性的架构局限性。

**Conclusion:** 具身推理提出了与当前模型所能解决的问题根本不同的挑战。OmniEAR被确立为评估和推进具身AI系统的严格基准。

> **ai_Abstract:** 本文提出了OmniEAR，一个用于评估大型语言模型在具身任务中（包括物理交互、工具使用和多代理协作）推理能力的综合基准。与现有基准不同，OmniEAR要求代理动态获取能力并自主决定协作策略。通过1,500个基于文本的场景，研究发现当模型需要从约束条件推理时，性能显著下降，尤其是在工具使用、隐式协作和复合任务中。意外的是，完整的环境信息反而会降低协作性能，且微调对多代理任务的提升有限，这揭示了当前模型在具身推理方面的根本性局限性。

> **摘要翻译:** 大型语言模型在抽象推理方面表现出色，但其在具身代理推理方面的能力仍未得到充分探索。我们提出了OmniEAR，一个综合框架，用于评估语言模型如何在具身任务中对物理交互、工具使用和多代理协作进行推理。与现有提供预定义工具集或明确协作指令的基准测试不同，OmniEAR要求代理根据任务需求动态获取能力并自主确定协作策略。通过基于文本的环境表示，我们在涵盖家庭和工业领域的1,500个场景中建模连续物理属性和复杂的空间关系。我们的系统评估揭示了当模型必须从约束条件进行推理时，性能会严重下降：在有明确指令的情况下成功率达85-96%，但在工具推理中降至56-85%，在隐式协作中降至63-85%，复合任务的失败率超过50%。令人惊讶的是，完整的环境信息反而会降低协作性能，表明模型无法过滤出与任务相关的约束。微调显著改善了单代理任务（0.6%提升至76.3%），但对多代理任务的提升微乎其微（1.5%提升至5.5%），暴露出根本性的架构局限性。这些发现表明，具身推理提出了与当前模型所能解决的问题根本不同的挑战，将OmniEAR确立为评估和推进具身AI系统的严格基准。我们的代码和数据包含在补充材料中，并将在接受后开源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [474] [Integrated Influence: Data Attribution with Baseline](https://arxiv.org/abs/2508.05089)
> *整合影响力：基于基线的数据归因*

*Linxiao Yang, Xinyu Gu, Liang Sun* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 数据归因, 整合影响力, 基线, 影响力函数, 机器学习可解释性

**Comment:** 

> **TL;DR:** 提出了一种名为“整合影响力”的新型数据归因方法，通过引入基线和数据退化过程来解决现有方法局部性解释和缺乏基线的问题，并在实验中表现出更可靠的归因效果。

**AI_Comments:** 这篇论文通过引入“基线”概念和“数据退化”过程，创新性地解决了传统数据归因方法（如LOO）在处理集体影响力和提供反事实解释方面的局限性。其理论框架的普适性，能够将现有流行方法视为特例，显示了其重要性和潜在的广泛应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据归因方法存在两个主要问题：一是基于“留一法”(LOO)的策略只扰动单个训练样本，忽略了训练集中的集体影响力，导致解释的局部性；二是许多方法缺乏基线，降低了解释的灵活性，无法提供反事实解释。

**Method:** 本文提出了一种名为“整合影响力”(Integrated Influence)的新型数据归因方法。该方法定义了一个基线数据集，通过数据退化过程将当前数据集逐步过渡到基线，并在此过程中累积每个样本的影响力。该方法还提供了坚实的理论框架，并证明了如影响力函数等流行方法可以被视为其特殊情况。

**Result:** 实验结果表明，“整合影响力”方法在数据归因任务和错误标记样本识别任务中，比现有方法生成了更可靠的数据归因。

**Conclusion:** “整合影响力”方法通过引入基线和数据退化过程，有效解决了现有数据归因方法的局限性，并能生成更可靠的归因结果，且具有广泛的理论适用性。

> **ai_Abstract:** 本文提出了一种新颖的数据归因方法“整合影响力”，旨在解决现有方法中基于“留一法”的局部解释限制以及缺乏基线导致解释灵活性不足的问题。该方法通过定义基线数据集和数据退化过程来累积样本影响力，并提供了坚实的理论基础。实验证明，“整合影响力”在数据归因和错误标记样本识别任务中，能比现有方法提供更可靠的归因结果。

> **摘要翻译:** 数据归因作为量化训练样本如何影响测试样本的有效方法，对于理解数据和模型以及进一步提高机器学习模型的透明度至关重要。我们发现，当前基于“留一法”(LOO)策略的数据归因方法存在局部解释的问题，因为这些基于LOO的方法只扰动单个训练样本，而忽略了训练集中的集体影响力。另一方面，许多数据归因方法缺乏基线，降低了解释的灵活性，例如无法提供反事实解释。在本文中，我们提出了“整合影响力”(Integrated Influence)，这是一种结合了基线方法的新型数据归因方法。我们的方法定义了一个基线数据集，遵循数据退化过程将当前数据集过渡到基线，并在此过程中累积每个样本的影响力。我们为我们的方法提供了坚实的理论框架，并进一步证明了影响力函数等流行方法可以被视为我们方法的特例。实验结果表明，“整合影响力”在数据归因任务和错误标记样本识别任务中，与现有方法相比，生成了更可靠的数据归因。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [475] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
> *描述逻辑中的最小模型推理：请勿在家尝试！*

*Federica Di Stefano, Quentin Manière, Magdalena Ortiz, Mantas Šimkus* | **Category: cs.AI, cs.CC, cs.LO** | **Updated: 2025-08-07**

**Keywords:** 最小模型推理, 描述逻辑, 不可判定性, 复杂度, DL-Lite

**Comment:** 

> **TL;DR:** 研究发现描述逻辑（DLs）中的纯最小模型推理，即使对于简单的EL，也是不可判定的，并且在DL-Lite家族中也表现出高复杂性。

**AI_Comments:** 这篇论文揭示了描述逻辑中纯最小模型推理的固有复杂性和不可判定性，这对于知识表示和推理领域具有重要意义。它强调了在DLs中实现此类推理的挑战，并为未来的研究指明了方向，即需要施加严格的条件才能保证可判定性。其负面结果尤其引人注目，因为它挑战了在DLs中轻松应用最小模型推理的直觉。

<details>
  <summary>Details</summary>

**Motivation:** 最小模型推理是许多知识表示技术的核心，但在描述逻辑（DLs）中对其理解有限。特别是，所有谓词都必须最小化的“纯”最小模型情况，在DLs中仍未被充分探索。

**Method:** 研究了流行DLs中的纯最小模型问题。为了重新获得可判定性，对TBox施加了非循环条件。建立了与最近研究的逐点限定（pointwise circumscription）的联系。推导了数据复杂性方面的结果。对DL-Lite家族进行了简要探讨。

**Result:** 概念可满足性在最小模型中对于$\mathcal{EL}$已经不可判定。这种不可判定性也延伸到非常受限的元组生成依赖片段。施加TBox的非循环条件可以将最坏情况复杂度降低到双指数时间以下。DL-Lite$_{\text{horn}}$的扩展已经达到ExpSpace-hard，而DL-Lite$_{\text{core}}$之前已知有积极结果。

**Conclusion:** 在描述逻辑中进行纯最小模型推理，即使对于看似简单的DLs（如EL），也会导致不可判定性，并且在DL-Lite家族中也表现出高复杂性，表明这是一个具有挑战性的问题。通过施加某些限制（如TBox非循环性）可以重新获得可判定性。

> **ai_Abstract:** 这篇论文深入探讨了描述逻辑（DLs）中的“纯”最小模型推理问题，即所有谓词都必须最小化的情景。研究发现，即使对于简单的$\mathcal{EL}$，最小模型中的概念可满足性也是不可判定的，并且这种不可判定性也适用于受限的元组生成依赖。为了恢复可判定性，作者引入了TBox的非循环条件，从而将复杂度降低并建立了与逐点限定的联系。此外，论文还分析了DL-Lite家族，发现DL-Lite$_{\text{horn}}$的推理复杂性达到了ExpSpace-hard，揭示了这类推理的固有挑战性。

> **摘要翻译:** 最小模型推理一直是许多知识表示技术的核心，但我们对描述逻辑 (DLs) 中的这个问题仍然知之甚少。像限定（circumscription）中提出的那样，对某些选定谓词进行最小化，让其余谓词变化或固定，这方面已经有所探索并表现出高复杂性。而“纯”最小模型的情况，即所有谓词的扩展都必须是最小的，则在很大程度上仍未被探索。我们在流行的DLs中解决了这个问题，并获得了令人惊讶的负面结果：即使对于$\mathcal{EL}$，最小模型中的概念可满足性也是不可判定的。这种不可判定性也延伸到元组生成依赖的一个非常受限的片段。为了重新获得可判定性，我们对TBox施加了非循环条件，这将最坏情况复杂度降低到双指数时间以下，并使我们能够建立与最近研究的逐点限定的联系；我们还在数据复杂性方面得出了结果。最后，我们简要探讨了DL-Lite家族，其中DL-Lite$_{\text{core}}$已知有一个积极的结果，但我们的研究表明，其扩展DL-Lite$_{\text{horn}}$已经达到了ExpSpace-hard。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [476] [Test-Time Reinforcement Learning for GUI Grounding via Region Consistency](https://arxiv.org/abs/2508.05615)
> *基于区域一致性的GUI接地测试时强化学习*

*Yong Du, Yuchen Yan, Fei Tang, Zhengxi Lu, Chang Zong, Weiming Lu, Shengpei Jiang, Yongliang Shen* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** GUI接地, 测试时学习, 强化学习, 区域一致性, 自监督学习

**Comment:** 

> **TL;DR:** 本文提出了GUI-RC和GUI-RCPO，通过利用多样本预测的空间一致性来提高GUI接地任务的测试时准确性，无需额外训练或标注奖励，为更鲁棒、数据高效的GUI代理提供了新途径。

**AI_Comments:** 该论文的创新点在于利用测试时多预测的空间一致性来生成隐式置信度信号，并将其应用于GUI接地任务，从而有效避免了对昂贵像素级标注的依赖。特别是，将这种一致性模式转化为测试时强化学习的奖励，实现了在无标签数据上的自监督优化，这是朝着构建更数据高效和鲁棒的GUI代理迈出的重要一步，对于降低机器学习模型对大规模标注数据集的依赖具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有图形用户界面（GUI）接地方法受限于像素级标注的高成本和可用性不足，无论是用于监督训练还是强化学习中的带标签奖励。

**Method:** 本文提出了两种方法：1. GUI-RC（区域一致性）：一种测试时缩放方法，通过多个采样预测构建空间投票网格，以识别模型显示最高一致性的共识区域，无需任何训练。2. GUI-RCPO（区域一致性策略优化）：将一致性模式转化为测试时强化学习的奖励。通过计算每个预测与集体共识的对齐程度，GUI-RCPO使模型能够在推理过程中迭代优化未标记数据上的输出。

**Result:** GUI-RC在ScreenSpot基准测试中将各种架构的准确率提高了2-3%。GUI-RC将Qwen2.5-VL-3B-Instruct在ScreenSpot-v2上的准确率从80.11%提升到83.57%，而GUI-RCPO通过自监督优化进一步将其提升到85.14%。

**Conclusion:** 本文的方法揭示了测试时缩放和测试时强化学习在GUI接地方面的未开发潜力，为实现更鲁棒和数据高效的GUI代理提供了有前景的路径。

> **ai_Abstract:** 本文针对GUI接地任务中像素级标注成本高昂和可用性不足的问题，提出了两种创新的测试时方法：GUI-RC和GUI-RCPO。GUI-RC通过分析多个预测的空间重叠模式，构建投票网格以识别共识区域，从而在无需额外训练的情况下提高定位准确性。在此基础上，GUI-RCPO将这种区域一致性转化为奖励信号，用于测试时强化学习，使模型能够在推理阶段通过自监督方式迭代优化其输出。实验结果表明，这两种方法在ScreenSpot基准测试上均实现了显著的性能提升，例如将Qwen2.5-VL-3B-Instruct的准确率从80.11%提升至85.14%，证明了测试时方法在构建更鲁棒、数据高效的GUI代理方面的巨大潜力。

> **摘要翻译:** 图形用户界面（GUI）接地，即将自然语言指令映射到精确屏幕坐标的任务，是自主GUI代理的基础。虽然现有方法通过大量的监督训练或带标签奖励的强化学习取得了强大的性能，但它们仍然受限于像素级标注的成本和可用性。我们观察到，当模型对同一GUI元素生成多个预测时，空间重叠模式揭示了隐式置信度信号，可以指导更准确的定位。利用这一见解，我们提出了GUI-RC（区域一致性），一种测试时缩放方法，它从多个采样预测构建空间投票网格，以识别模型显示最高一致性的共识区域。在没有任何训练的情况下，GUI-RC在ScreenSpot基准测试中将各种架构的准确率提高了2-3%。我们进一步引入了GUI-RCPO（区域一致性策略优化），它将这些一致性模式转化为测试时强化学习的奖励。通过计算每个预测与集体共识的对齐程度，GUI-RCPO使模型能够在推理过程中迭代优化未标记数据上的输出。广泛的实验证明了我们方法的通用性：GUI-RC将Qwen2.5-VL-3B-Instruct在ScreenSpot-v2上的准确率从80.11%提升到83.57%，而GUI-RCPO通过自监督优化进一步将其提升到85.14%。我们的方法揭示了测试时缩放和测试时强化学习在GUI接地方面的未开发潜力，为实现更鲁棒和数据高效的GUI代理提供了有前景的路径。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [482] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
> *StructVRM：通过结构化和可验证奖励模型对齐多模态推理*

*Xiangxiang Zhang, Jingxuan Wei, Donghong Zhong, Qi Chen, Caijun Jia, Cheng Tan, Jinming Gu, Xiaobo Qin, Zhiping Liu, Liang Hu, Tong Sun, Yuchen Wu, Zewei Sun, Chenwei Lou, Hua Zheng, Tianyang Zhan, Changbao Wang, Shuangzhi Wu, Zefa Lin, Chang Guo, Sihang Yuan, Riwei Chen, Shixiong Zhao, Yingping Zhang, Gaowei Wu, Bihui Yu, Jiahui Wu, Zhehui Zhao, Qianqian Liu, Ruofeng Tang, Xingyue Huang, Bing Zhao, Mengyang Zhang, Youqiang Zhou* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 多模态推理, 奖励模型, 视觉-语言模型, 结构化奖励, 部分得分

**Comment:** 

> **TL;DR:** StructVRM引入了一种基于模型的验证器，通过提供细粒度、子问题级别的反馈和部分得分，解决了现有视觉-语言模型在复杂多问题推理任务中粗糙奖励机制的问题，并在多个多模态基准测试和新的STEM-Bench上取得了最先进的性能。

**AI_Comments:** 本文的创新点在于提出了StructVRM，通过引入一个能够提供细粒度、子问题级别反馈的模型化验证器，解决了现有视觉-语言模型在复杂推理任务中奖励机制过于粗糙的问题。这种方法允许对部分正确性进行评估，显著提升了模型在多模态基准测试上的表现，尤其是在STEM-Bench这类高难度任务上，显示了其在真实世界复杂推理领域的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言模型在处理复杂的、多问题推理任务时表现不佳，尤其是在部分正确性至关重要的情况下。传统的二元奖励机制过于粗糙，无法在包含多个子部分的复杂问题中有效指导模型学习。

**Method:** 本文提出了StructVRM方法，通过结构化和可验证的奖励模型来对齐多模态推理。其核心是一个经过训练的模型化验证器，能够提供细粒度、子问题级别的反馈，评估语义和数学等效性，而不是依赖严格的字符串匹配。这使得在以前难以处理的问题格式中也能进行细致的部分得分。

**Result:** StructVRM的广泛实验证明了其有效性。经过训练的模型Seed-StructVRM在十二个公共多模态基准测试中的六个以及新策展的高难度STEM-Bench上取得了最先进的性能。

**Conclusion:** 通过结构化、可验证的奖励进行训练是提高多模态模型在复杂真实世界推理领域能力的非常有效的方法。

> **ai_Abstract:** StructVRM提出了一种新的方法来改进视觉-语言模型在复杂多问题推理任务中的表现。它引入了一个结构化和可验证的奖励模型，该模型包含一个细粒度的模型化验证器，能够评估子问题级别的语义和数学等效性，从而实现部分得分。实验结果表明，StructVRM在多个多模态基准测试和新的STEM-Bench上达到了最先进的性能，验证了结构化可验证奖励在提升多模态推理能力方面的有效性。

> **摘要翻译:** 现有视觉-语言模型在复杂的、多问题推理任务中常常表现不佳，而这些任务中部分正确性对于有效学习至关重要。传统的奖励机制为整个响应提供单一的二元分数，这对于指导模型解决具有多个子部分的复杂问题来说过于粗糙。为了解决这个问题，我们引入了StructVRM，这是一种通过结构化和可验证奖励模型对齐多模态推理的方法。其核心是一个经过训练的模型化验证器，旨在提供细粒度、子问题级别的反馈，评估语义和数学等效性，而不是依赖僵硬的字符串匹配。这使得在以前难以处理的问题格式中也能进行细致的部分得分。广泛的实验证明了StructVRM的有效性。我们训练的模型Seed-StructVRM在十二个公共多模态基准测试中的六个以及我们新策展的高难度STEM-Bench上取得了最先进的性能。StructVRM的成功验证了使用结构化、可验证奖励进行训练是提升多模态模型在复杂真实世界推理领域能力的一种高效方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [483] [Fairness in Dysarthric Speech Synthesis: Understanding Intrinsic Bias in Dysarthric Speech Cloning using F5-TTS](https://arxiv.org/abs/2508.05102)
> *构音障碍语音合成中的公平性：使用 F5-TTS 理解构音障碍语音克隆中的内在偏差*

*Anuprabha M, Krishna Gurugubelli, Anil Kumar Vuppala* | **Category: cs.AI, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 构音障碍语音合成, 语音克隆, 公平性, F5-TTS, 语音清晰度

**Comment:** 

> **TL;DR:** 本研究调查了 F5-TTS 在构音障碍语音克隆中的有效性及其潜在偏差，发现 F5-TTS 在构音障碍语音合成中对语音清晰度表现出强烈偏向。

**AI_Comments:** 这项研究创新性地将公平性指标引入构音障碍语音合成领域，揭示了当前主流语音克隆模型在处理特殊语音类型时可能存在的内在偏差。其重要性在于，它提醒研究者在追求技术进步的同时，也需要关注技术的公平性和包容性，尤其是在辅助技术领域，确保技术能惠及所有用户。

<details>
  <summary>Details</summary>

**Motivation:** 由于数据有限，构音障碍语音给辅助技术开发带来了挑战。虽然神经语音合成（特别是零样本语音克隆）有助于数据增强，但它们可能对构音障碍语音引入偏差。

**Method:** 本研究使用 TORGO 数据集，调查了最先进的 F5-TTS 在克隆构音障碍语音方面的有效性，重点关注清晰度、说话人相似度和韵律保留。研究还使用 Disparate Impact 和 Parity Difference 等公平性指标分析了跨构音障碍严重程度的潜在偏差。

**Result:** 结果表明，F5-TTS 在构音障碍语音合成中，相对于说话人和韵律保留，对语音清晰度表现出强烈的偏向。

**Conclusion:** 本研究的见解有助于整合公平性感知的构音障碍语音合成，从而促进更具包容性的语音技术的发展。

> **ai_Abstract:** 本论文探讨了在数据有限的背景下，构音障碍语音合成中零样本语音克隆技术（如 F5-TTS）可能引入的偏差。研究使用 TORGO 数据集，评估了 F5-TTS 在构音障碍语音克隆中对语音清晰度、说话人相似度和韵律保留的影响，并利用公平性指标分析了不同严重程度的偏差。结果显示 F5-TTS 倾向于优先保证语音清晰度，而非说话人特征和韵律的保留。这项研究为未来开发更具公平性和包容性的构音障碍语音技术提供了重要见解。

> **摘要翻译:** 构音障碍语音在开发辅助技术方面带来了重大挑战，这主要是由于数据可用性有限。神经语音合成，特别是零样本语音克隆的最新进展，促进了合成语音的生成以进行数据增强；然而，它们可能会对构音障碍语音引入偏差。在本文中，我们使用 TORGO 数据集，调查了最先进的 F5-TTS 在克隆构音障碍语音方面的有效性，重点关注清晰度、说话人相似度和韵律保留。我们还使用 Disparate Impact 和 Parity Difference 等公平性指标分析了潜在偏差，以评估构音障碍严重程度之间的差异。结果表明，F5-TTS 在构音障碍语音合成中，相对于说话人和韵律保留，对语音清晰度表现出强烈偏向。本研究的见解有助于整合公平性感知的构音障碍语音合成，从而促进更具包容性的语音技术的发展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [484] [TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven Evolution](https://arxiv.org/abs/2508.05616)
> *TrajEvo：基于大型语言模型驱动进化的轨迹预测启发式设计*

*Zhikai Zhao, Chuanbo Hua, Federico Berto, Kanghoon Lee, Zihan Ma, Jiachen Li, Jinkyoo Park* | **Category: cs.AI, cs.LG, cs.NE, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 轨迹预测, 大型语言模型, 进化算法, 启发式方法, OOD泛化

**Comment:** 

> **TL;DR:** TrajEvo是一个利用大型语言模型和进化算法自动设计轨迹预测启发式方法，解决了传统方法和深度学习方法的局限性，并在泛化性方面表现优异。

**AI_Comments:** TrajEvo的创新之处在于将LLM与进化算法相结合，实现了轨迹预测启发式方法的自动化设计，这在解决传统方法泛化性差和深度学习方法可解释性差、OOD性能不佳的问题上迈出了重要一步。其对OOD场景的优越泛化能力尤其值得关注，这对于安全关键领域的应用至关重要。该方法为未来自动化智能系统设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 轨迹预测在社交机器人和自动驾驶等安全关键领域至关重要。传统的启发式方法缺乏准确性和泛化性，而深度学习方法存在计算成本高、可解释性差以及对分布外（OOD）场景泛化能力弱的问题。

**Method:** 本文提出了TrajEvo框架，利用大型语言模型（LLM）自动设计轨迹预测启发式方法。TrajEvo采用进化算法从过去的轨迹数据中生成和优化预测启发式方法。提出了两个关键创新：跨代精英采样（Cross-Generation Elite Sampling）以鼓励种群多样性，以及统计反馈循环（Statistics Feedback Loop）使LLM能够分析和改进替代预测。

**Result:** 评估表明，TrajEvo在多个真实世界数据集上优于现有启发式方法，并且在泛化到未见的分布外（OOD）真实世界数据集方面，显著超越了启发式和深度学习方法。

**Conclusion:** TrajEvo标志着在自动化设计快速、可解释且可泛化的轨迹预测启发式方法方面迈出了有希望的一步。

> **ai_Abstract:** TrajEvo是一个新颖的框架，它结合大型语言模型（LLM）和进化算法来自动生成和优化轨迹预测启发式方法。该框架旨在克服传统手工规则和深度学习方法在准确性、泛化性、计算成本和可解释性方面的局限性。通过引入跨代精英采样和统计反馈循环，TrajEvo在多个真实世界数据集上表现出优越性，尤其是在对未知分布外（OOD）数据的泛化能力上超越了现有启发式和深度学习方法，为开发快速、可解释且泛化能力强的轨迹预测模型提供了有前景的方向。

> **摘要翻译:** 轨迹预测是建模人类行为的一项关键任务，尤其是在社交机器人和自动驾驶等安全关键领域。基于手工规则的传统启发式方法通常缺乏准确性和泛化性。尽管深度学习方法提供了改进的性能，但它们通常面临计算成本高、可解释性有限，以及更重要的是，对分布外（OOD）场景泛化能力差的问题。在本文中，我们引入了TrajEvo，这是一个利用大型语言模型（LLM）自动设计轨迹预测启发式方法的框架。TrajEvo采用进化算法从过去的轨迹数据中生成和优化预测启发式方法。我们提出了两项关键创新：跨代精英采样，以鼓励种群多样性；以及统计反馈循环，使LLM能够分析和改进替代预测。我们的评估表明，TrajEvo在多个真实世界数据集上优于现有启发式方法，并且在泛化到未见的OOD真实世界数据集方面，显著超越了启发式和深度学习方法。TrajEvo标志着在自动化设计快速、可解释且可泛化的轨迹预测启发式方法方面迈出了有希望的一步。我们发布了源代码以促进未来的研究：https://github.com/ai4co/trajevo。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [490] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
> *一个用于铁路预测性维护的可解释机器学习框架，使用来自葡萄牙地铁运营商的数据流*

*Silvia García-Méndez, Francisco de Arriba-Pérez, Fátima Leal, Bruno Veloso, Benedita Malheiro, Juan Carlos Burguillo-Rial* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 铁路预测性维护, 可解释机器学习, 数据流, 在线故障预测, 智能交通系统

**Comment:** 

> **TL;DR:** 本文提出了一个针对葡萄牙铁路的实时预测性维护的可解释机器学习框架，通过在线处理管道实现了高精度故障预测，并首次提供了自然语言和视觉解释。

**AI_Comments:** 该工作创新性地将在线数据流处理与可解释机器学习相结合，特别是在实时故障预测中引入自然语言和视觉解释，显著提升了预测性维护系统的实用性和可信度。其在高精度和鲁棒性方面的表现，对于关键基础设施（如铁路）的运营安全和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为智能交通系统提供实时数据驱动的预测性维护解决方案，以应对铁路运营中准确故障预测的关键需求，从而最大化服务可用性、降低成本并提高安全性。

**Method:** 该研究实现了一个在线处理管道，包含样本预处理（即时构建统计和频率相关特征）、机器学习模型的增量分类和结果解释模块。这是首次通过自然语言和视觉解释进行在线故障预测。

**Result:** 在MetroPT数据集上的F-measure高于98%，准确率高于99%。该管道在类别不平衡和噪声存在的情况下仍保持高性能，并且其解释有效地反映了决策过程。

**Conclusion:** 该方法在方法上是可靠的，并具有实际适用性，能够支持铁路运营中的主动维护决策，通过识别早期故障迹象帮助决策者迅速理解潜在问题并采取相应行动。

> **ai_Abstract:** 本文提出了一种创新的在线处理管道，用于铁路预测性维护，该管道结合了即时特征构建的样本预处理、增量机器学习分类和独特的解释模块，首次实现了在线故障预测与自然语言和视觉解释。在葡萄牙波尔图地铁运营商的数据集上，该方法在F-measure和准确率上均达到98%以上，并且在类别不平衡和噪声环境下仍表现出色，其解释性有效支持决策，对实现高服务可用性、降低成本和提高安全性至关重要。

> **摘要翻译:** 这项工作为智能交通系统中的实时数据驱动预测性维护解决方案做出了贡献。所提出的方法实现了一个处理管道，包括样本预处理、机器学习模型的增量分类和结果解释。这个新颖的在线处理管道有两个主要亮点：(i) 一个专门的样本预处理模块，它即时构建统计和频率相关特征，以及 (ii) 一个可解释性模块。这项工作首次通过自然语言和视觉解释进行在线故障预测。实验使用来自葡萄牙波尔图地铁运营商的MetroPT数据集进行。结果显示F-measure高于98%，准确率高于99%。在铁路预测性维护的背景下，由于准确故障预测的实际和操作影响，获得这些高值至关重要。在F-measure高的情况下，这确保系统在检测尽可能多的真实故障和最小化误报之间保持最佳平衡，这对于最大化服务可用性至关重要。此外，获得的准确性提高了可靠性，直接影响成本降低和安全性提高。分析表明，该管道即使在类别不平衡和噪声存在的情况下也能保持高性能，并且其解释有效地反映了决策过程。这些发现验证了该方法的方法论健全性，并证实了其在支持实际铁路运营中主动维护决策方面的实际适用性。因此，通过识别故障的早期迹象，该管道使决策者能够理解潜在问题并迅速采取相应行动。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [491] [Exploring Superior Function Calls via Reinforcement Learning](https://arxiv.org/abs/2508.05118)
> *通过强化学习探索卓越的函数调用*

*Bingguang Hao, Maolin Wang, Zengzhuang Xu, Yicheng Chen, Cunyin Peng, Jinjie GU, Chenyi Zhuang* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 函数调用, 强化学习, 群组相对策略优化, 大型语言模型, 熵探索

**Comment:** 

> **TL;DR:** 本文提出一种新颖的强化学习框架，通过策略熵探索优化群组相对策略，在函数调用任务中实现了最先进的性能，尤其对代码预训练模型效果显著。

**AI_Comments:** 本文的创新点在于提出了一个专门针对LLM函数调用任务的强化学习框架，通过引入策略熵探索和两阶段数据准备流程，有效解决了现有方法中探索不足和推理结构化欠缺的问题。其在开放模型中取得的SOTA性能，以及对代码预训练模型展现出的显著改进，对于推动LLM在复杂实际应用场景中的部署和功能拓展具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）在函数调用中的训练方法（监督微调和标准强化学习）未能开发出鲁棒的推理策略。监督微调依赖于肤浅的模式匹配，而标准强化学习难以处理结构化函数调用的复杂动作空间。具体挑战包括策略学习期间的探索不足、思维链生成中缺乏结构化推理以及参数提取验证不足。

**Method:** 本文提出一种新颖的强化学习框架，旨在通过专门为函数调用任务定制的基于策略熵的探索来增强群组相对策略优化（GRPO）。该方法解决了探索不足、缺乏结构化推理和参数提取验证不足的问题。此外，采用两阶段数据准备流程，通过迭代LLM评估和抽象语法树（AST）验证来确保高质量的训练样本。

**Result:** 在Berkeley函数调用排行榜上，该框架在开源模型中实现了86.02%的整体准确率，达到了最先进的性能。在复杂多函数场景中，其性能比标准GRPO高出多达6%。值得注意的是，该方法在代码预训练模型上显示出特别显著的改进。

**Conclusion:** 结构化语言生成能力（源自代码预训练模型）为函数调用任务中的强化学习提供了一个有利的起点。研究成果（包括代码、模型和数据集）将公开发布以造福社区。

> **ai_Abstract:** 本文针对大型语言模型（LLM）在函数调用中存在的推理能力不足和探索受限等问题，提出了一种新颖的强化学习框架。该框架通过基于策略熵的探索来增强群组相对策略优化，并利用两阶段数据准备流程保证训练样本质量。实验结果表明，该方法在Berkeley函数调用排行榜上取得了86.02%的最先进准确率，并在复杂多函数场景中显著优于标准方法，尤其对代码预训练模型提升显著，证明了其在函数调用任务中的有效性。

> **摘要翻译:** 函数调用能力对于在实际应用中部署大型语言模型至关重要，但当前的训练方法未能开发出鲁棒的推理策略。监督微调产生的模型依赖于肤浅的模式匹配，而标准强化学习方法难以处理结构化函数调用的复杂动作空间。我们提出了一种新颖的强化学习框架，旨在通过专门为函数调用任务定制的基于策略熵的探索来增强群组相对策略优化。我们的方法解决了函数调用中的三个关键挑战：策略学习期间的探索不足、思维链生成中缺乏结构化推理以及参数提取验证不足。我们的两阶段数据准备流程通过迭代LLM评估和抽象语法树验证确保高质量的训练样本。在Berkeley函数调用排行榜上进行的广泛实验表明，该框架在开源模型中实现了86.02%的整体准确率，达到最先进的性能，在复杂多函数场景中比标准GRPO高出多达6%。值得注意的是，我们的方法在代码预训练模型上显示出特别显著的改进，这表明结构化语言生成能力为函数调用任务中的强化学习提供了有利的起点。我们将发布所有代码、模型和数据集，以造福社区。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [492] [How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in Multi-Turn Conversations](https://arxiv.org/abs/2508.05625)
> *大型语言模型如何说服人类？线性探针可揭示多轮对话中的说服动态*

*Brandon Jaipersaud, David Krueger, Ekdeep Singh Lubana* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 线性探针, 说服, 多轮对话, 认知科学

**Comment:** 

> **TL;DR:** 本文研究了如何使用线性探针分析大型语言模型在多轮对话中的说服动态，发现其在效率和性能上优于基于提示的方法。

**AI_Comments:** 这项研究的创新之处在于提出并验证了使用线性探针作为一种高效且有效的方法来分析LLMs的说服能力，这为理解AI与人类互动中的复杂行为（如说服、欺骗、操纵）提供了一个新的视角。其重要性在于，线性探针在计算效率上优于基于提示的方法，使其在大规模数据集和多轮对话分析中更具实用性。这对于未来AI可解释性和安全性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）已开始展现说服人类的能力，但我们对这种动态如何发生的理解有限。近期工作利用线性探针研究了LLMs的各种能力，受此启发，本文旨在应用探针研究自然多轮对话中的说服动态。

**Method:** 本文应用线性探针研究多轮对话中的说服动态。研究者利用认知科学的见解，训练探针来分析说服的三个不同方面：说服成功、被说服者的个性以及说服策略。

**Result:** 研究表明，尽管线性探针很简单，但它们能在样本和数据集层面捕捉说服的各个方面。例如，探针可以识别对话中被说服者被说服的时间点，或者整个数据集中说服成功的普遍发生点。此外，探针比昂贵的基于提示的方法更快，并且在某些设置下（例如揭示说服策略时）表现得同样好甚至更好。

**Conclusion:** 研究结果表明，线性探针是研究说服等复杂行为（如欺骗和操纵）的可行途径，尤其是在多轮设置和大规模数据集分析中，因为基于提示的方法在计算上效率低下。

> **ai_Abstract:** 本文探讨了如何使用线性探针来理解大型语言模型在多轮对话中的说服机制。研究人员借鉴认知科学，训练探针分析说服成功、被说服者个性和说服策略。结果显示，线性探针能有效识别说服动态，并且相较于传统的基于提示的方法，其在效率和性能上均有优势，尤其在处理复杂行为和大规模数据集时更具潜力。

> **摘要翻译:** 大型语言模型（LLMs）已开始展现说服人类的能力，但我们对这种动态如何发生的理解有限。近期工作利用线性探针，一种用于分析模型表示的轻量级工具，研究了LLMs的各种能力，例如建模用户情绪和政治观点。受此启发，我们将探针应用于研究自然、多轮对话中的说服动态。我们利用认知科学的见解，训练探针来分析说服的三个不同方面：说服成功、被说服者的个性以及说服策略。尽管它们很简单，但我们展示了它们在样本和数据集层面捕捉说服的各个方面。例如，探针可以识别对话中被说服者被说服的时间点，或者整个数据集中说服成功的普遍发生点。我们还表明，除了比昂贵的基于提示的方法更快之外，探针在某些设置下，例如揭示说服策略时，表现得同样好甚至更好。这表明探针是研究其他复杂行为（如欺骗和操纵）的可行途径，尤其是在多轮设置和大规模数据集分析中，因为基于提示的方法在计算上效率低下。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [498] [H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language Modelling in Morphologically-Rich Languages](https://arxiv.org/abs/2508.05628)
> *H-Net++：用于形态丰富语言中无分词器语言建模的分层动态分块*

*Mehrdad Zakershahrak, Samira Ghodratnama* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 分层动态分块, 无分词器语言建模, 形态丰富语言, H-Net++, 波斯语

**Comment:** 

> **TL;DR:** H-Net++ 是一种分层动态分块模型，通过端到端训练学习语言学分段，在形态丰富的语言中实现了无分词器语言建模的SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个分层动态分块模型H-NET++，它通过端到端训练学习语言学分段，从而解决了形态丰富语言中字节级模型面临的计算效率和分词器依赖问题。其在波斯语上的SOTA表现以及无需显式监督即可学习形态边界的能力，突出了其在MRLs应用中的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 字节级语言模型在形态丰富的语言（MRLs）中面临计算挑战，因为单词跨越许多字节，且需要消除脆弱的分词器。

**Method:** 提出H-NET++，一个分层动态分块模型，通过端到端训练学习语言学分段。主要创新包括：(1) 轻量级Transformer上下文混合器（1.9M参数）用于跨块注意力；(2) 两级潜在超先验用于文档级一致性；(3) 特殊处理正字法伪影（如波斯语ZWNJ）；(4) 基于课程的训练与分阶段序列长度。

**Result:** 在1.4B-token波斯语语料库上，H-NET++实现了最先进的结果：相较于基于BPE的GPT-2-fa，BPB减少0.159（压缩率提高12%）；ParsGLUE上提高5.4pp；对ZWNJ损坏的鲁棒性提高53%；在黄金形态边界上F1达到73.8%。

**Conclusion:** 分层动态分块为形态丰富的语言提供了一种有效的无分词器解决方案，同时保持了计算效率，并且学习到的块与波斯语形态对齐，无需显式监督。

> **ai_Abstract:** 本文提出了H-NET++，一个针对形态丰富语言的无分词器语言建模的分层动态分块模型。该模型通过端到端训练学习语言学分段，并引入了轻量级Transformer上下文混合器、两级潜在超先验、正字法伪影处理和课程训练等创新。H-NET++在波斯语语料库上达到了最先进的性能，包括更高的压缩率、ParsGLUE增益和对字符损坏的鲁棒性，证明了其在MRLs中作为高效无分词器解决方案的有效性。

> **摘要翻译:** 字节级语言模型消除了脆弱的分词器，但在形态丰富的语言（MRLs）中面临计算挑战，因为单词跨越许多字节。我们提出了H-NET++，一个分层动态分块模型，通过端到端训练学习语言学分段。主要创新包括：(1) 一个轻量级Transformer上下文混合器（1.9M参数）用于跨块注意力，(2) 一个两级潜在超先验用于文档级一致性，(3) 对正字法伪影（例如波斯语ZWNJ）的专门处理，以及(4) 基于课程的训练与分阶段序列长度。在1.4B-token的波斯语语料库上，H-NET++实现了最先进的结果：相较于基于BPE的GPT-2-fa，BPB减少0.159（压缩率提高12%），ParsGLUE上获得5.4pp的增益，对ZWNJ损坏的鲁棒性提高53%，在黄金形态边界上F1达到73.8%。我们学习到的块在没有明确监督的情况下与波斯语形态对齐，这表明分层动态分块为MRLs提供了一种有效的无分词器解决方案，同时保持了计算效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [505] [KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation](https://arxiv.org/abs/2508.05633)
> *KuaiLive：一个用于直播推荐的实时交互数据集*

*Changle Qu, Sunhao Dai, Ke Guo, Liqin Zhao, Yanan Niu, Xiao Zhang, Jun Xu* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 直播推荐, 数据集, 实时交互, 快手, 行为建模

**Comment:** 

> **TL;DR:** KuaiLive是一个新的实时交互式直播推荐数据集，旨在解决现有数据集缺乏动态性、无法准确反映直播环境的问题，并为直播推荐研究提供基准。

**AI_Comments:** KuaiLive数据集的创新之处在于其首次公开提供了大规模、实时且包含多种交互类型的直播数据，这对于弥补学术界在直播推荐研究中缺乏真实环境数据的空白至关重要。其详细的用户和主播侧信息以及精细的行为数据，为研究更复杂的推荐算法（如多行为建模、多任务学习和公平性推荐）提供了可能，对推动直播推荐领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 直播平台已成为主要的在线内容消费形式，但其独特的动态性、实时互动性和高参与度为直播推荐带来了新的挑战。学术界的研究进展受限于缺乏能够准确反映直播环境动态性的公开数据集。

**Method:** 研究团队引入了KuaiLive数据集，这是从中国领先的直播平台快手（拥有超过4亿日活用户）收集的第一个实时交互式数据集。该数据集记录了23,772名用户和452,621名主播在21天内的互动日志。它包含精确的直播间开始和结束时间戳、多种实时用户互动类型（点击、评论、点赞、送礼）以及丰富的用户和主播侧信息特征。

**Result:** KuaiLive数据集能够更真实地模拟动态候选项目，更好地建模用户和主播行为。研究人员对KuaiLive进行了多角度的彻底分析，并评估了多种代表性推荐方法，为未来的研究建立了强大的基准。该数据集支持直播领域的广泛任务，如Top-K推荐、点击率预测、观看时长预测和礼物价格预测。其细粒度行为数据还支持多行为建模、多任务学习和公平性感知推荐研究。

**Conclusion:** KuaiLive数据集的发布弥补了直播推荐领域公开数据集的空白，为学术界提供了宝贵的资源，以推动对直播环境中动态和交互式推荐系统的研究。它为未来的直播推荐算法开发和评估提供了坚实的基础。

> **ai_Abstract:** 本文介绍了KuaiLive，一个从快手平台收集的实时交互式直播推荐数据集。该数据集旨在解决现有直播推荐研究中缺乏动态、真实世界数据集的问题。KuaiLive包含了21天内2万多用户和45万多主播的互动日志，具备精确的时间戳、多类型实时互动和丰富的侧信息，能更真实地模拟直播环境。研究团队对数据集进行了深入分析，并在此基础上评估了多种推荐方法，为直播推荐领域的未来研究提供了重要的基准和资源，支持包括Top-K推荐、CTR预测、观看时长预测等多项任务。

> **摘要翻译:** 直播平台已成为在线内容消费的主导形式，提供动态演变的内容、实时互动和高度参与的用户体验。这些独特的特征带来了新的挑战，使直播推荐有别于传统的推荐设置，并近年来获得了业界的日益关注。然而，学术界的研究进展一直受到缺乏能够准确反映直播环境动态性质的公开数据集的阻碍。为了弥补这一空白，我们推出了KuaiLive，这是从中国领先的直播平台快手（拥有超过4亿日活跃用户）收集的第一个实时交互式数据集。该数据集记录了23,772名用户和452,621名主播在21天内的互动日志。与现有数据集相比，KuaiLive具有多项优势：它包括精确的直播间开始和结束时间戳、多种类型的实时用户互动（点击、评论、点赞、送礼），以及用户和主播的丰富侧信息特征。这些特征能够更真实地模拟动态候选项目，并更好地建模用户和主播行为。我们从多个角度对KuaiLive进行了彻底分析，并评估了其上几种代表性的推荐方法，为未来的研究建立了强大的基准。KuaiLive可以支持直播领域的广泛任务，例如Top-K推荐、点击率预测、观看时长预测和礼物价格预测。此外，其细粒度行为数据还支持多行为建模、多任务学习和公平性感知推荐的研究。数据集和相关资源可在https://imgkkk574.github.io/KuaiLive公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [510] [Towards Generalizable Safety in Crowd Navigation via Conformal Uncertainty Handling](https://arxiv.org/abs/2508.05634)
> *通过共形不确定性处理实现人群导航中的泛化安全性*

*Jianpeng Yao, Xiaopan Zhang, Yu Xia, Zejin Wang, Amit K. Roy-Chowdhury, Jiachen Li* | **Category: cs.AI, cs.CV, cs.LG, cs.RO, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 人群导航, 泛化安全, 共形不确定性, 强化学习, 机器人鲁棒性

**Comment:** 

> **TL;DR:** 该研究通过结合自适应共形推断和约束强化学习来处理行人不确定性，显著提高了机器人人群导航在分布内和分布外场景中的安全性和鲁棒性。

**AI_Comments:** 该论文的创新点在于将共形不确定性处理引入到强化学习框架中，以解决机器人人群导航中分布外场景的泛化性问题。这种方法有效地提高了机器人在复杂动态环境中的安全性和鲁棒性，具有重要的实际应用价值。在真实机器人上的部署验证也增加了其可信度。

<details>
  <summary>Details</summary>

**Motivation:** 移动机器人在人群中导航时，通过强化学习训练的模型在面对分布外（out-of-distribution, OOD）场景时性能会下降，缺乏泛化安全性。

**Method:** 该方法通过自适应共形推断生成预测不确定性估计，并用这些估计增强代理的观察。这些不确定性估计随后通过约束强化学习来指导代理的行为，以调节其动作并适应分布变化。

**Result:** 在分布内设置中，成功率达到96.93%，比现有最佳基线高8.80%以上，碰撞次数减少3.72倍以上，侵入真实人类未来轨迹的次数减少2.43倍。在三种分布外场景中，该方法在面对速度变化、策略变化以及从个体到群体动态的分布偏移时表现出更强的鲁棒性。在真实机器人上的部署实验表明，机器人在与稀疏和密集人群互动时都能做出安全且鲁棒的决策。

**Conclusion:** 通过适当考虑行人的不确定性，机器人可以学习到对分布偏移具有鲁棒性的安全导航策略，从而在模拟和实际部署中实现人群导航的泛化安全性。

> **ai_Abstract:** 该研究提出了一种通过处理行人不确定性来提高机器人人群导航泛化安全性的方法。通过使用自适应共形推断增强观测并结合约束强化学习，该系统使机器人能够学习对分布偏移具有鲁棒性的安全策略。实验结果表明，在分布内和分布外场景中，该方法均显著优于现有技术，并在真实机器人上验证了其安全和鲁棒的决策能力。

> **摘要翻译:** 移动机器人在人群中导航时，通过强化学习训练的模型在面对分布外场景时性能会下降。我们提出，通过适当考虑行人的不确定性，机器人可以学习到对分布偏移具有鲁棒性的安全导航策略。我们的方法通过自适应共形推断生成的预测不确定性估计来增强代理的观察，并利用这些估计通过约束强化学习来指导代理的行为。该系统有助于调节代理的动作，使其适应分布偏移。在分布内设置中，我们的方法实现了96.93%的成功率，比现有最佳基线高出8.80%以上，碰撞次数减少3.72倍以上，侵入真实人类未来轨迹的次数减少2.43倍。在三种分布外场景中，我们的方法在面对速度变化、策略变化以及从个体到群体动态的分布偏移时表现出更强的鲁棒性。我们将我们的方法部署在真实机器人上，实验表明机器人在与稀疏和密集人群互动时都能做出安全且鲁棒的决策。我们的代码和视频可在https://gen-safe-nav.github.io/上获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [516] [Unified Bayesian Frameworks for Multi-criteria Decision-making Problems](https://arxiv.org/abs/2208.13390)
> *多准则决策问题的统一贝叶斯框架*

*Majid Mohammadi* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 贝叶斯框架, 多准则决策, 群体决策, 不确定性, 概率模型

**Comment:** 

> **TL;DR:** 本文提出了统一的贝叶斯框架，通过概率解释解决多准则决策中的挑战，包括群体决策和不确定性，并通过实验验证了其有效性。

**AI_Comments:** 该论文的创新之处在于将贝叶斯框架统一应用于多准则决策问题，并利用概率解释来解决传统MCDM中的复杂挑战，如群体决策和不确定性偏好。其提出的概率混合模型和排序方案为大规模MCDM提供了新的视角和工具，增强了决策的鲁棒性和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多准则决策 (MCDM) 问题中的关键挑战，例如群体决策问题、准则相关性，以及适应决策者偏好中的各种不确定性形式。

**Method:** 引入了利用MCDM方法和挑战的概率解释的贝叶斯框架。开发了概率混合模型以识别同质决策者子群，用于大规模群体MCDM场景。设计了概率排序方案以评估准则和备选方案的相对重要性。

**Result:** 所提出的框架通过各种数值示例进行了验证，证明了其有效性，并突出了其与替代方法相比的独特特征。

**Conclusion:** 所提出的统一贝叶斯框架为多准则决策问题提供了统计上优雅的解决方案，能够应对复杂性，如群体决策、准则相关性和决策者偏好中的不确定性。

> **ai_Abstract:** 本文提出了一个统一的贝叶斯框架，通过对多准则决策（MCDM）方法和挑战的概率解释，有效解决了MCDM中的关键问题，如群体决策和准则相关性。该框架能够处理决策者偏好中的多种不确定性形式，并引入了概率混合模型来处理大规模群体MCDM，以及概率排序方案来评估重要性。数值实验验证了其有效性和优越性。

> **摘要翻译:** 本文介绍了解决多准则决策（MCDM）问题各个方面的贝叶斯框架，利用了MCDM方法和挑战的概率解释。通过利用贝叶斯模型的灵活性，所提出的框架为MCDM中的关键挑战提供了统计上优雅的解决方案，例如群体决策问题和准则相关性。此外，这些模型可以适应决策者（DM）偏好中的各种不确定性形式，包括正态分布和三角分布，以及区间偏好。为了解决大规模群体MCDM场景，开发了一种概率混合模型，能够识别同质的决策者子群。此外，还设计了一种概率排序方案，根据决策者（们）的偏好评估准则和备选方案的相对重要性。通过对各种数值示例的实验，所提出的框架得到了验证，证明了其有效性并突出了其与替代方法相比的显著特征。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [522] [Toward A Causal Framework for Modeling Perception](https://arxiv.org/abs/2401.13408)
> *走向一个感知建模的因果框架*

*Jose M. Alvarez, Salvatore Ruggieri* | **Category: cs.AI, cs.CY, cs.HC** | **Updated: 2025-08-06**

**Keywords:** 感知, 因果模型, 机器学习, 公平性, 结构因果模型

**Comment:** 

> **TL;DR:** 该论文提出了一种使用结构因果模型（SCM）对人类感知进行因果建模的框架，旨在解决机器学习中人类专家对相同信息不同解读的问题，并强调其对公平机器学习的重要性。

**AI_Comments:** 该论文的创新之处在于首次将因果框架（特别是结构因果模型）引入到对人类感知的建模中，以解决机器学习系统中因人类专家不同解读而产生的偏见问题。这对于理解并潜在地缓解人机交互中的偏差至关重要，尤其是在公平机器学习领域具有显著意义。

<details>
  <summary>Details</summary>

**Motivation:** 感知是人类决策中导致偏见的认知现象，但在机器学习（ML）中仍未得到充分研究。现代决策流程，无论是部分还是完全由ML应用自动化，都涉及人类专家。由于不同专家可能对相同的ML模型输出或解释有不同的解读，这导致了问题。因此，需要一种能够与ML驱动的决策流程相结合的感知建模方法。

**Method:** 本文提出了一种首次尝试的因果感知建模方法。作者使用结构因果模型（SCM）在因果推理下定义感知，将个体经验形式化为专家决策者所拥有并使用的额外因果知识（以SCM的形式）。论文定义了两种概率因果感知：结构性和参数性感知。

**Result:** 作者通过一系列现代决策流程的例子展示了他们提出的框架。他们还强调了在公平机器学习中解决感知问题的重要性，并讨论了相关的公平性影响和可能的应用。

**Conclusion:** 该论文提出了一个用于建模感知的因果框架，强调了在机器学习（特别是公平机器学习）中解决感知问题的重要性，并讨论了其对公平性的影响和潜在应用。

> **ai_Abstract:** 本文旨在解决机器学习（ML）中感知现象研究不足的问题，即人类专家对ML输出的不同解读可能导致偏见。作者提出了一种新颖的因果框架，利用结构因果模型（SCM）来建模感知。该方法将个体经验形式化为SCM中的因果知识，并定义了结构性和参数性两种概率因果感知。论文通过实例展示了该框架，并探讨了其在公平ML中的重要性及相关应用。

> **摘要翻译:** 当个体对相同信息有不同解读时，感知便会发生。这是一种已知的认知现象，对人类决策中的偏见具有影响。然而，在机器学习（ML）中，感知仍未得到充分研究。这是一个问题，因为现代决策流程，无论是部分还是完全由ML应用自动化，总是涉及人类专家。例如，我们如何解释两位专家对来自ML模型的相同延迟实例或解释有不同解读的情况？解决这个问题以及类似问题，首先需要对感知进行公式化，特别是以一种能与ML驱动的决策流程相结合的方式。在这项工作中，我们提出了一个首次尝试的因果感知建模方法。我们使用结构因果模型（SCM）在因果推理下定义感知。我们的方法将个体经验形式化为专家决策者所拥有并使用的额外因果知识，以SCM的形式。我们定义了两种概率因果感知：结构性和参数性感知。我们通过一系列现代决策流程的例子展示了我们的框架。我们还强调了在公平机器学习中解决感知问题的重要性，讨论了相关的公平性影响和可能的应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [528] [Advancing Multi-Organ Disease Care: A Hierarchical Multi-Agent Reinforcement Learning Framework](https://arxiv.org/abs/2409.04224)
> *推进多器官疾病护理：一种分层多智能体强化学习框架*

*Daniel J. Tan, Qianyi Xu, Kay Choong See, Dilruk Perera, Mengling Feng* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 多器官疾病, 强化学习, 多智能体系统, 临床决策支持, 脓毒症管理

**Comment:** 

> **TL;DR:** 提出HMARL框架，通过多智能体协作和双层状态表示，管理复杂的多器官疾病，并在脓毒症管理中显著提高患者生存率。

**AI_Comments:** 这篇论文的创新点在于提出了第一个明确为多器官治疗建议设计的强化学习解决方案，通过分层多智能体架构和双层状态表示有效处理了多器官疾病的复杂性及器官间的相互依赖性。其重要性在于能够为临床医生提供更全面、更符合实际的多器官疾病管理决策支持，显著提高患者生存率，具有巨大的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI临床决策支持系统主要关注单一器官系统，未能解决多器官疾病中器官间的复杂相互依赖性，导致无法提供整体且可行的治疗建议。

**Method:** 提出分层多智能体强化学习（HMARL）框架。该架构为每个器官系统部署专门的智能体，并通过智能体间通信实现跨器官系统的协同决策。此外，引入双层状态表示技术，从全局和器官特定层面情境化患者状况。

**Result:** 在脓毒症管理任务上评估了HMARL解决方案，结果显示该方法学习到有效且符合临床实践的治疗策略，显著提高了患者生存率。

**Conclusion:** 该框架是临床决策支持系统的一个重大进步，是首个明确为多器官治疗建议设计的强化学习解决方案，超越了现有简化、单器官模型的局限性。

> **ai_Abstract:** 本文提出一种新颖的分层多智能体强化学习（HMARL）框架，旨在解决现有临床决策支持系统在多器官疾病管理中忽略器官间复杂相互依赖性的问题。HMARL通过为每个器官系统部署专用智能体并促进其间通信来协同决策，并引入双层状态表示以提升决策准确性。在脓毒症管理任务上的评估表明，该框架能学习到有效且提高患者生存率的治疗策略，是首个专为多器官治疗建议设计的强化学习解决方案，克服了传统单器官模型的局限。

> **摘要翻译:** 在医疗保健领域，多器官系统疾病带来了独特而重大的挑战，因为它们同时影响多个生理系统，需要复杂和协调的治疗策略。尽管基于人工智能的临床决策支持系统最近取得了进展，但这些解决方案仅关注个体器官系统，未能考虑它们之间复杂的相互依赖性。这种狭隘的关注极大地阻碍了它们在现实世界中推荐整体且具有临床可行性的治疗方案的有效性。为了解决这一关键空白，我们提出了一种新颖的分层多智能体强化学习（HMARL）框架。我们的架构为每个器官系统部署了专门的智能体，并促进了智能体间的通信，以实现跨器官系统的协同决策。此外，我们引入了一种双层状态表示技术，该技术从全局和器官特定层面情境化患者状况，提高了治疗决策的准确性和相关性。我们通过定性和定量指标，在脓毒症管理（一种常见且关键的多器官疾病）任务上评估了我们的HMARL解决方案。我们的方法学习到有效、符合临床实践的治疗策略，显著提高了患者生存率。我们相信这个框架代表了临床决策支持系统的一个重大进步，引入了第一个明确为多器官治疗建议设计的强化学习解决方案。我们的解决方案超越了当前在解决多器官疾病复杂性方面不足的简化、单器官模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [534] [DOTS: Learning to Reason Dynamically in LLMs via Optimal Reasoning Trajectories Search](https://arxiv.org/abs/2410.03864)
> *DOTS：通过最优推理轨迹搜索在大型语言模型中动态推理*

*Murong Yue, Wenlin Yao, Haitao Mi, Dian Yu, Ziyu Yao, Dong Yu* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** LLMs, 推理, 动态推理, 最优轨迹, 提示策略

**Comment:** 

> **TL;DR:** DOTS提出一种新的方法，使大型语言模型（LLMs）能够通过搜索最优推理轨迹，根据具体问题和模型能力动态地进行推理，实验表明其优于静态推理方法。

**AI_Comments:** DOTS的创新之处在于引入了“最优推理轨迹搜索”的概念，使LLMs能够根据问题特性和自身能力进行动态、自适应的推理，而非依赖固定的推理模式。这显著提升了LLMs在复杂推理任务上的性能和效率，使其能更智能地分配计算资源，对LLM的推理范式研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 以往提升大型语言模型（LLMs）推理能力的方法通常采用静态、预定义的推理动作，统一应用于所有问题，而没有考虑每个问题的具体特征或任务解决LLM的固有能力。

**Method:** 本文提出了DOTS方法，使LLMs能够通过最优推理轨迹搜索进行动态推理。该方法包括三个关键步骤：1) 定义可组合成各种推理动作轨迹的原子推理动作模块；2) 通过迭代探索和评估，为每个训练问题搜索针对特定任务解决LLM的最优动作轨迹；3) 利用收集到的最优轨迹训练LLM，使其能够规划未见问题的推理轨迹。具体来说，提出了两种学习范式：微调外部LLM作为规划器来指导任务解决LLM，或者直接微调任务解决LLM使其具备内部推理动作规划能力。

**Result:** 实验在八个推理任务上进行，结果显示DOTS方法始终优于静态推理技术和普通的指令微调方法。进一步分析表明，该方法使LLMs能够根据问题复杂性调整其计算，对更难的问题分配更深入的思考和推理。

**Conclusion:** DOTS通过动态地搜索和规划最优推理轨迹，显著提升了大型语言模型的推理能力，并使其能够根据问题难度自适应地调整计算资源。

> **ai_Abstract:** 该论文提出了DOTS，一种旨在提升大型语言模型（LLMs）推理能力的新方法。针对现有方法静态、统一应用推理动作的局限性，DOTS通过为每个具体问题动态搜索最优推理轨迹，并考虑LLM自身能力。该方法包含定义原子推理动作、搜索训练问题的最优轨迹以及训练LLM规划新问题的轨迹。实验在八个推理任务上验证了DOTS的优越性，证明其能根据问题复杂性调整推理深度，从而显著超越了静态推理和普通指令微调技术。

> **摘要翻译:** 近年来，提升大型语言模型（LLMs）的推理能力受到了广泛关注。先前的研究已经证明了各种提示策略在辅助LLMs推理（称为“推理动作”）方面的有效性，例如逐步思考、回答前反思、通过程序解决以及它们的组合。然而，这些方法通常将静态、预定义的推理动作统一应用于所有问题，而没有考虑每个问题的具体特征或任务解决LLM的固有能力。在本文中，我们提出了DOTS，一种通过最优推理轨迹搜索使LLMs能够动态推理的方法，它根据每个问题的具体特征和任务解决LLM的固有能力进行定制。我们的方法包括三个关键步骤：i）定义可以组合成各种推理动作轨迹的原子推理动作模块；ii）通过迭代探索和评估，为每个训练问题搜索针对特定任务解决LLM的最优动作轨迹；iii）利用收集到的最优轨迹来训练LLM，使其能够规划未见问题的推理轨迹。特别是，我们提出了两种学习范式，即微调外部LLM作为规划器来指导任务解决LLM，或者直接微调任务解决LLM使其具备内部推理动作规划能力。我们在八个推理任务上的实验表明，我们的方法始终优于静态推理技术和普通的指令微调方法。进一步分析揭示，我们的方法使LLMs能够根据问题复杂性调整其计算，对更难的问题分配更深入的思考和推理。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [539] [ST-WebAgentBench: A Benchmark for Evaluating Safety and Trustworthiness in Web Agents](https://arxiv.org/abs/2410.06703)
> *ST-WebAgentBench：一个评估网络代理安全性和可信赖性的基准*

*Ido Levy, Ben Wiesel, Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 网络代理, 安全性, 可信赖性, 基准, 评估

**Comment:** 

> **TL;DR:** 现有的网络代理基准忽略了安全性和可信赖性，本文引入了ST-WebAgentBench，一个用于评估网络代理在企业场景中安全性和可信赖性的基准，并揭示了SOTA代理的关键安全漏洞。

**AI_Comments:** 该论文的创新点在于填补了现有网络代理评估基准在安全性和可信赖性方面的空白，提出了实用的评估框架和指标。其重要性在于为企业级应用部署网络代理提供了关键的评估工具和标准，有助于识别和解决潜在的安全风险。通过揭示现有SOTA代理的安全缺陷，强调了未来研究和开发需要关注的方向。发布代码和工具也极大地促进了社区的进一步研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的网络代理基准只衡量任务完成度，而忽略了代理在完成任务时的安全性和可信赖性，这对于将这些代理集成到关键企业工作流程中是必不可少的。

**Method:** 本文引入了ST-WebAgentBench，这是一个可配置且易于扩展的套件，用于评估网络代理在实际企业场景中的安全性和可信赖性。它包含222个任务，每个任务都配有ST策略和约束规则，并从六个正交维度（如用户同意、鲁棒性）进行评分。此外，还提出了“策略下完成率”（CuP）指标和“风险比率”来量化ST违规。

**Result:** 通过评估三个最先进的开放网络代理，发现它们的平均CuP低于其标称完成率的三分之二，暴露了关键的安全漏洞。

**Conclusion:** ST-WebAgentBench通过发布代码、评估模板和策略编写界面，为大规模部署可信赖的网络代理提供了可行的第一步。

> **ai_Abstract:** 本文介绍了ST-WebAgentBench，一个旨在评估自主网络代理在企业环境中的安全性和可信赖性的新型基准。该基准包含222个任务，每个任务都附带安全和可信赖性策略，并从六个维度进行评估。为更准确衡量，提出了“策略下完成率”（CuP）和“风险比率”两个新指标。实验结果显示，当前最先进的网络代理在安全性方面存在显著缺陷，其策略下完成率远低于任务完成率。ST-WebAgentBench通过提供评估工具和资源，为推动可信赖网络代理的大规模部署迈出了重要一步。

> **摘要翻译:** 自主网络代理可以解决复杂的浏览任务，然而现有基准仅衡量代理是否完成任务，而忽略其是否安全或以企业可以信任的方式完成。为了将这些代理集成到关键工作流程中，安全性与可信赖性（ST）是采用的先决条件。我们引入了ST-WebAgentBench，这是一个可配置且易于扩展的套件，用于评估网络代理在实际企业场景中的ST。其222个任务中的每一个都配有ST策略（编码约束的简洁规则），并沿六个正交维度（例如用户同意、鲁棒性）进行评分。除了原始任务成功率，我们还提出了“策略下完成率”（CuP）指标，该指标仅认可遵守所有适用策略的完成，以及“风险比率”，该比率量化了跨维度的ST违规。对三个最先进的开放代理的评估表明，它们的平均CuP低于其标称完成率的三分之二，暴露了关键的安全差距。通过发布代码、评估模板和策略编写界面，ST-WebAgentBench为大规模部署可信赖的网络代理提供了可行的第一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [546] [Interactive Data Harmonization with LLM Agents: Opportunities and Challenges](https://arxiv.org/abs/2502.07132)
> *使用大型语言模型代理的交互式数据协调：机遇与挑战*

*Aécio Santos, Eduardo H. M. Pena, Roque Lopez, Juliana Freire* | **Category: cs.AI, cs.DB** | **Updated: 2025-08-07**

**Keywords:** 数据协调, LLM代理, Harmonia, 交互式系统, 数据整合

**Comment:** 

> **TL;DR:** 本文介绍了Harmonia系统，它利用LLM代理和交互式界面自动化数据协调流程，以解决现有方法的耗时和挑战性问题。

**AI_Comments:** 本文提出了一种新颖的结合LLM代理和交互式界面的数据协调方法，具有创新性。通过自动化管道合成，有望显著提高数据协调的效率并降低专家门槛。在临床数据场景中的演示也表明了其潜在的应用价值。未来的研究可以关注如何进一步提高LLM在复杂数据理解和推理方面的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 数据协调是将来自不同来源的数据集进行整合的关键任务，但由于模式不匹配、术语差异和数据收集方法不同，该任务仍然耗时且充满挑战。本文旨在通过代理式数据协调赋能专家并简化该过程。

**Method:** 本文提出了Harmonia系统，该系统结合了基于大型语言模型（LLM）的推理、交互式用户界面以及数据协调原语库，以自动化数据协调管道的合成。

**Result:** Harmonia系统在一个临床数据协调场景中得到了验证，它帮助交互式地创建了可重用的管道，将数据集映射到标准格式。

**Conclusion:** 本文讨论了数据协调领域的挑战和开放问题，并提出了未来的研究方向，以推进其愿景。

> **ai_Abstract:** 本文针对数据协调任务中存在的模式不匹配、术语差异等挑战，提出了一种名为Harmonia的代理式数据协调系统。Harmonia结合了LLM推理、交互式用户界面和数据协调原语，能够自动化数据协调管道的创建。系统在一个临床数据场景中得到了验证，成功地帮助用户交互式地构建了将数据映射到标准格式的可重用管道。论文最后还讨论了该领域的挑战和未来的研究方向。

> **摘要翻译:** 数据协调是一项必不可少的任务，需要整合来自不同来源的数据集。尽管该领域已研究多年，但由于模式不匹配、术语差异和数据收集方法不同，它仍然是一项耗时且具有挑战性的任务。本文提出了代理式数据协调的案例，作为赋能专家协调其数据并简化流程的一种手段。我们介绍了Harmonia，一个结合了基于大型语言模型（LLM）推理、交互式用户界面和数据协调原语库的系统，以自动化数据协调管道的合成。我们在一个临床数据协调场景中演示了Harmonia，它有助于交互式地创建可重用的管道，将数据集映射到标准格式。最后，我们讨论了挑战和开放问题，并提出了推进我们愿景的研究方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [552] [Benchmarking Retrieval-Augmented Generation in Multi-Modal Contexts](https://arxiv.org/abs/2502.17297)
> *多模态背景下检索增强生成基准测试*

*Zhenghao Liu, Xingsheng Zhu, Tianshuo Zhou, Xinyi Zhang, Xiaoyuan Yi, Yukun Yan, Ge Yu, Maosong Sun* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 多模态RAG, MLLM, 基准测试, 指令微调, M$^2$RAG

**Comment:** 

> **TL;DR:** 本文介绍了M$^2$RAG，一个用于评估多模态大语言模型在多模态检索增强生成中知识利用能力的基准，并提出了MM-RAIT，一种增强上下文利用的指令微调方法，实验证明其显著提升了不同RAG模型的响应质量。

**AI_Comments:** 本文的创新点在于首次提出了一个针对多模态检索增强生成（M$^2$RAG）的综合基准，填补了该领域评估工具的空白。同时，引入的MM-RAIT指令微调方法为提升MLLMs在多模态RAG中的上下文利用能力提供了有效途径，其显著的性能提升显示了该方法的实用价值。该研究对于推动多模态RAG技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）在理解图像和文本方面能力显著提升，但它们在检索增强生成（RAG）中利用多模态上下文信息的潜力仍未得到充分探索。本文旨在弥补这一空白。

**Method:** 本文引入了Multi-Modal Retrieval-Augmented Generation (M$^2$RAG) 基准，用于评估多模态大语言模型利用多模态检索文档中知识的有效性。该基准包含图像字幕、多模态问答、多模态事实核查和图像重排序四个开放域任务。此外，还提出了Multi-Modal Retrieval-Augmented Instruction Tuning (MM-RAIT)，一种优化多模态上下文中MLLMs的指令微调方法。

**Result:** 实验证明MM-RAIT显著提高了不同RAG模型生成的响应质量，分别比MiniCPM-V 2.6和Qwen2-VL高出34%和33%。

**Conclusion:** 本文成功引入了M$^2$RAG基准和MM-RAIT指令微调方法，有效提升了多模态大语言模型在多模态检索增强生成任务中的性能和上下文利用能力。

> **ai_Abstract:** 本文针对多模态大语言模型（MLLMs）在检索增强生成（RAG）中多模态上下文信息利用不足的问题，提出了M$^2$RAG基准和MM-RAIT指令微调方法。M$^2$RAG包含图像字幕、多模态问答、多模态事实核查和图像重排序四个开放域任务，用于评估MLLMs在多模态RAG中的知识利用能力。MM-RAIT则通过指令微调优化MLLMs的上下文利用。实验结果表明，MM-RAIT显著提升了RAG模型的性能，例如MiniCPM-V 2.6和Qwen2-VL分别有34%和33%的提升。

> **摘要翻译:** 随着多模态大语言模型（MLLMs）的快速发展，它们在理解图像和文本方面的能力得到了极大提升。然而，它们在检索增强生成（RAG）中利用多模态上下文信息的潜力仍未得到充分探索。为了弥补这一空白，本文引入了多模态检索增强生成（M$^2$RAG），这是一个旨在评估多模态大语言模型在利用多模态检索文档中知识方面的有效性的基准。该基准包含四个任务：图像字幕、多模态问答、多模态事实核查和图像重排序。所有任务都设置在开放域环境中，要求RAG模型从多模态文档集合中检索与查询相关的信息，并将其用作RAG建模的上下文输入。为了增强MLLMs的上下文利用能力，我们还引入了多模态检索增强指令微调（MM-RAIT），这是一种在多模态上下文中优化MLLMs的指令微调方法。我们的实验证明了MM-RAIT的有效性，通过显著提高不同RAG模型生成的响应质量，分别比MiniCPM-V 2.6和Qwen2-VL高出34%和33%。所有数据和代码均可在https://github.com/NEUIR/M2RAG获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [558] [Agent Guide: A Simple Agent Behavioral Watermarking Framework](https://arxiv.org/abs/2504.05871)
> *Agent Guide：一种简单的智能体行为水印框架*

*Kaibo Huang, Zipei Zhang, Zhongliang Yang, Linna Zhou* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 智能体水印, 行为水印, 可追溯性, 大型语言模型, 数字安全

**Comment:** 

> **TL;DR:** Agent Guide是一种新颖的行为水印框架，通过引导智能体的高层决策来嵌入水印，解决了传统LLM水印技术在智能体应用中的局限性。

**AI_Comments:** Agent Guide的创新之处在于其将智能体行为解耦为行为和动作两个层级，并针对行为层面进行水印嵌入，有效克服了传统LLM水印在行为令牌化和信息损失方面的挑战。这种方法在不影响具体执行自然性的前提下实现了水印的鲁棒性，对于提高智能体的可追溯性和问责制具有重要意义，尤其是在数字安全和内容保护领域。该框架为识别恶意智能体和保护专有系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 数字生态系统中智能体部署的增加引发了对可追溯性和问责制的担忧，特别是在网络安全和数字内容保护方面。传统的基于令牌操作的大型语言模型（LLM）水印技术不适用于智能体，因为行为令牌化和行为到动作转换过程中的信息丢失带来了挑战。

**Method:** 本文提出了Agent Guide，一种新颖的行为水印框架。它通过概率偏差引导智能体的高层决策（行为）来嵌入水印，同时保留特定执行（动作）的自然性。该方法将智能体行为解耦为两个级别：行为（例如，选择收藏）和动作（例如，使用特定标签收藏），并将水印引导的偏差应用于行为概率分布。采用基于z统计量的统计分析来检测水印，确保多轮可靠提取。

**Result:** 在具有不同智能体配置文件的社交媒体场景中进行的实验表明，Agent Guide实现了有效的水印检测，且误报率低。

**Conclusion:** Agent Guide框架为智能体水印提供了一种实用且鲁固的解决方案，可应用于识别恶意智能体和保护专有智能体系统。

> **ai_Abstract:** 本研究提出Agent Guide，一种针对智能体的新型行为水印框架，旨在解决传统大型语言模型（LLM）水印技术在智能体可追溯性和问责制方面的局限性。Agent Guide通过对智能体高层决策（行为）施加概率偏差来嵌入水印，同时保持具体执行（动作）的自然性。该框架将智能体行为分为行为和动作两个层面，并将水印引导的偏差应用于行为概率分布。通过Z统计量进行水印检测，确保多轮检测的可靠性。实验结果表明，该框架在社交媒体场景中能有效检测水印并保持较低的误报率，为识别恶意智能体和保护专有智能体系统提供了一个实用且稳健的解决方案。

> **摘要翻译:** 随着智能体在社交媒体平台等数字生态系统中的部署日益增多，对可追溯性和问责制的担忧也随之增加，尤其是在网络安全和数字内容保护方面。传统的依赖于令牌操作的大型语言模型（LLM）水印技术不适用于智能体，因为行为令牌化和行为到动作转换过程中的信息丢失带来了挑战。为了解决这些问题，我们提出了Agent Guide，一种新颖的行为水印框架，它通过引导智能体的高层决策（行为）来嵌入水印，同时保留特定执行（动作）的自然性。我们的方法将智能体行为解耦为两个级别：行为（例如，选择收藏）和动作（例如，使用特定标签收藏），并将水印引导的偏差应用于行为概率分布。我们采用基于z统计量的统计分析来检测水印，确保多轮可靠提取。在具有不同智能体配置文件的社交媒体场景中进行的实验表明，Agent Guide实现了有效的水印检测，且误报率低。我们的框架为智能体水印提供了一种实用且稳健的解决方案，可应用于识别恶意智能体和保护专有智能体系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [564] [Graph-Based Fault Diagnosis for Rotating Machinery: Adaptive Segmentation and Structural Feature Integration](https://arxiv.org/abs/2504.20756)
> *基于图的旋转机械故障诊断：自适应分割与结构特征融合*

*Moirangthem Tiken Singh* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 图诊断, 故障诊断, 旋转机械, 信号分割, 特征融合

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于图的框架，用于旋转机械的鲁棒和可解释的多类别故障诊断，该方法在多个数据集上取得了高精度，并展示了强大的抗噪声能力和跨域迁移性。

**AI_Comments:** 该论文提出了一种创新的基于图的故障诊断方法，其亮点在于无需深度学习架构即可实现高精度、鲁棒性和可解释性，这在工业应用中具有重要意义。通过结合熵优化分割和图论，有效地将复杂振动信号转化为可分析的结构化数据，并成功应用于旋转机械故障诊断。其在噪声环境和跨域场景下的出色表现，进一步验证了该方法的实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为旋转机械提供一种鲁棒、可解释且无需深度学习架构的多类别故障诊断方法，以解决传统技术的复杂性和解释性问题。

**Method:** 该方法整合了熵优化信号分割、时频特征提取和图论建模，将振动信号转换为结构化表示。计算图度量（如平均最短路径、模块化、谱隙）并与局部特征结合，以捕获全局和分段级故障特征。最后使用逻辑回归分类器进行分类。

**Result:** 在CWRU轴承数据集（0-3 HP负载下）和SU齿轮箱和轴承数据集（不同速度-负载配置下）上，诊断准确率在CWRU上高达99.8%，在SU数据集上高达100%。模型在高噪声水平（标准差=0.5）下仍保持超过95.4%的准确率，并在负载迁移场景中表现出高达99.7%的F1分数。

**Conclusion:** 该基于图的故障诊断方法在旋转机械中表现出高精度、强大的抗噪声能力和卓越的跨域迁移性。它无需深度学习架构，降低了复杂性并确保了可解释性，证实了其可扩展性、可靠性以及在工业诊断中实时部署的潜力。

> **ai_Abstract:** 本文提出了一种用于旋转机械多类别故障诊断的新型基于图的框架。该框架结合了熵优化信号分割、时频特征提取和图论建模，将振动信号转化为结构化表示。通过计算图度量和结合局部特征来捕获故障特性。实验结果表明，该方法在CWRU和SU数据集上实现了高诊断精度（高达99.8%和100%），并展现出优异的抗噪声能力（高噪声下仍保持95.4%以上准确率）和跨域迁移性（负载迁移F1分数达99.7%）。该方法无需深度学习架构，具有低复杂性和高可解释性，证实了其在工业诊断中的实用潜力。

> **摘要翻译:** 本文提出了一种新颖的基于图的框架，用于旋转机械中鲁棒且可解释的多类别故障诊断。该方法集成了熵优化信号分割、时频特征提取和图论建模，将振动信号转换为适合分类的结构化表示。计算图度量，如平均最短路径长度、模块化和谱隙，并与局部特征结合，以捕获全局和分段级故障特征。该方法在两个基准数据集上进行评估时，实现了高诊断精度，包括CWRU轴承数据集（0-3 HP负载下）和SU齿轮箱和轴承数据集（不同速度-负载配置下）。使用逻辑回归分类器，在凯斯西储大学（CWRU）数据集上分类得分达到99.8%的准确率，在东南大学数据集上达到100%的准确率。此外，该模型表现出强大的抗噪声能力，在高噪声水平（标准差=0.5）下仍保持超过95.4%的准确率，并在负载迁移场景中表现出卓越的跨域迁移性，F1分数高达99.7%。与传统技术相比，该方法不需要深度学习架构，从而降低了复杂性，同时确保了可解释性。结果证实了该方法的可扩展性、可靠性以及在工业诊断中实时部署的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [570] [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org/abs/2505.16086)
> *基于文本反馈优化大型语言模型多智能体系统：以软件开发为例*

*Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 多智能体系统, 文本反馈, 提示优化, 软件开发

**Comment:** 

> **TL;DR:** 该论文提出了一种基于文本反馈的两步提示优化流程，以优化基于LLM的多智能体系统在软件开发任务中的表现，并研究了不同优化设置的影响，证明了方法的有效性。

**AI_Comments:** 该论文的创新之处在于提出了基于文本反馈的两步提示优化流程，专用于多智能体系统，并将其应用于复杂的软件开发任务。通过对在线/离线、个体/群体以及单次/多次提示等多种优化设置的实证研究，论文提供了宝贵的实践指导，这对于开发健壮的基于LLM的多智能体系统至关重要。将软件开发作为案例研究凸显了该方法的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 优化大型语言模型（LLM）驱动的多智能体系统仍然具有挑战性，尤其是在需要专家协作解决复杂任务时。

**Method:** 1. 对基于角色的多智能体系统进行群体优化实证案例研究，利用自然语言反馈解决软件开发任务。2. 提出两步智能体提示优化流程：a) 利用文本反馈和失败解释识别表现不佳的智能体；b) 利用失败解释优化已识别智能体的系统提示。3. 研究了不同优化设置的影响：在线与离线优化，个体与群体优化；群体优化中包括单次与多次提示优化。

**Result:** 1. 证明了其优化方法对于处理软件开发任务的基于角色的多智能体系统的有效性，并在多种评估维度上进行了评估。2. 调查了不同优化设置对多智能体系统群体行为的影响。

**Conclusion:** 该研究证明了其优化方法在软件开发任务中的有效性，并通过对不同优化设置下多智能体系统群体行为的深入研究，为未来的发展提供了实用见解。

> **ai_Abstract:** 这篇论文解决了优化基于大型语言模型的多智能体系统所面临的挑战，特别是在软件开发领域。它提出了一种两步的提示优化流程，该流程利用文本反馈来识别并纠正表现不佳的智能体。该研究通过实证调查了各种优化设置的影响，包括在线与离线优化、个体与群体优化，以及群体优化中的单次与多次提示策略。研究结果不仅证明了该方法的有效性，还为不同优化设置如何影响多智能体系统的群体行为提供了实用的见解。

> **摘要翻译:** 我们看到大型语言模型（LLMs）赋能的多智能体系统在解决需要不同技能专家之间合作的复杂任务方面取得了显著进展。然而，优化基于LLM的多智能体系统仍然具有挑战性。在这项工作中，我们对利用自然语言反馈进行具有挑战性软件开发任务中基于角色的多智能体系统的群体优化进行了实证案例研究，并在各种评估维度下进行。我们提出了一个两步的智能体提示优化流程：利用文本反馈识别表现不佳的智能体及其失败解释，然后利用失败解释优化已识别智能体的系统提示。我们随后研究了各种优化设置对系统性能的影响，并设置了两个比较组：在线优化对比离线优化，以及个体优化对比群体优化。对于群体优化，我们研究了两种提示策略：单次提示优化和多次提示优化。总的来说，我们展示了我们的优化方法对于处理软件开发任务的基于角色的多智能体系统的有效性，并在不同的评估维度上进行了评估，我们还研究了不同优化设置对多智能体系统群体行为的影响，为未来的发展提供了实用见解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [576] [MAGIK: Mapping to Analogous Goals via Imagination-enabled Knowledge Transfer](https://arxiv.org/abs/2506.01623)
> *MAGIK：通过想象力实现知识迁移到类比目标*

*Ajsal Shereef Palattuparambil, Thommen George Karimpanal, Santu Rana* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 知识迁移, 类比推理, 零样本学习, 想象力

**Comment:** 

> **TL;DR:** MAGIK是一个新颖的框架，使强化学习代理能够通过想象力将知识零样本迁移到类比任务，无需与目标环境交互，仅需少量人工标记示例即可实现有效转移。

**AI_Comments:** MAGIK的创新之处在于其引入的想象机制，该机制使得强化学习代理能够进行零样本知识迁移，显著减少了在新任务上的训练需求。这种基于类比映射的方法，特别是无需与目标环境交互的能力，对于提升RL的泛化能力和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人类擅长类比推理，能将知识从一个任务应用到相关任务中，只需极少的重新学习。相比之下，强化学习（RL）代理即使在新任务与先前学习的任务具有结构相似性时，也通常需要大量的重新训练。

**Method:** 本文提出了MAGIK框架，它利用一种想象机制将目标任务中的实体映射到源域中的类比实体，从而允许代理重用其原始策略，实现无需与目标环境交互的知识迁移。

**Result:** 在自定义MiniGrid和MuJoCo任务上的实验表明，MAGIK仅使用少量人工标记示例即可实现有效的零样本迁移。该方法与相关基线进行了比较，并展示了其通过基于想象的类比映射实现知识迁移的新颖有效机制。

**Conclusion:** MAGIK提供了一种新颖且有效的机制，通过基于想象的类比映射实现知识迁移，使RL代理能够在不与目标环境交互的情况下，将知识零样本迁移到类比任务。

> **ai_Abstract:** MAGIK是一个创新的强化学习框架，旨在解决RL代理在面对与已知任务结构相似的新任务时需要大量重新训练的问题。该框架通过一个想象机制，将新任务中的实体映射到源任务中的类比实体，从而允许RL代理重用其现有策略，实现零样本知识迁移，无需与目标环境进行交互。实验证明，MAGIK在MiniGrid和MuJoCo任务上仅需少量人工标记示例即可实现高效的零样本迁移，展示了其通过基于想象的类比映射进行知识转移的有效性和新颖性。

> **摘要翻译:** 人类擅长类比推理——将知识从一个任务应用到相关任务中，只需极少的重新学习。相比之下，强化学习（RL）代理即使在新任务与先前学习的任务具有结构相似性时，也通常需要大量的重新训练。在这项工作中，我们提出了MAGIK，一个新颖的框架，使RL代理能够将知识迁移到类比任务，而无需与目标环境交互。我们的方法利用一种想象机制，将目标任务中的实体映射到源域中的类比实体，从而允许代理重用其原始策略。在自定义MiniGrid和MuJoCo任务上的实验表明，MAGIK仅使用少量人工标记示例即可实现有效的零样本迁移。我们将我们的方法与相关基线进行比较，并强调它如何提供一种通过基于想象的类比映射实现知识迁移的新颖有效机制。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [582] [Multi-level Value Alignment in Agentic AI Systems: Survey and Perspectives](https://arxiv.org/abs/2506.09656)
> *代理式AI系统中的多层次价值对齐：综述与展望*

*Wei Zeng, Hengshu Zhu, Chuan Qin, Han Wu, Yihang Cheng, Sirui Zhang, Xiaowei Jin, Yinuo Shen, Zhenxing Wang, Feimin Zhong, Hui Xiong* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 代理式AI, 价值对齐, 多智能体系统, 大型语言模型, 综述

**Comment:** 

> **TL;DR:** 本综述全面审视了代理式AI系统（特别是基于LLM的多智能体系统）中的多层次价值对齐，涵盖了价值原则、应用场景、对齐方法和评估，并提出了未来研究方向。

**AI_Comments:** 这篇论文及时且结构化地概述了代理式AI，尤其是多智能体LLM系统中价值对齐这一关键新兴领域。其提出的多层次框架为理解和解决AI与人类价值观对齐的复杂挑战提供了一种系统方法，这对于安全和有益的AI部署至关重要。对原则、场景和方法的系统性审查具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的进步，其应用变得日益多样和复杂，导致情境和系统性风险增加。为了确保代理的R目标、偏好和行为与人类价值观和社会规范保持一致，需要对代理式AI系统中的价值对齐进行深入研究。

**Method:** 本研究通过一个多层次价值框架，对基于LLM的多智能体系统（作为代理式AI系统的代表原型）中的价值对齐进行了全面综述。该综述系统地考察了三个相互关联的维度：价值原则（宏观、中观、微观）、应用场景（从通用到特定）以及价值对齐方法和评估（基准数据集和相关方法）。此外，还探讨了代理式AI系统中多智能体之间的价值协调。

**Result:** 该综述系统地构建了跨宏观、中观和微观层面的价值原则；根据这些价值层级对应用场景进行了分类；并通过系统审查基准数据集和相关方法，将价值对齐方法和评估映射到这个分层框架中。此外，还深入探讨了多智能体之间的价值协调。

**Conclusion:** 本研究提出了该领域未来潜在的研究方向。

> **ai_Abstract:** 本研究综述了代理式AI系统（特别是基于LLM的多智能体系统）中的多层次价值对齐问题。鉴于LLM应用日益增长的复杂性和风险，该综述提出了一个多层次价值框架，并系统地考察了价值原则（宏观、中观、微观）、应用场景以及对齐方法和评估。此外，论文还探讨了多智能体间的价值协调，并展望了未来的研究方向。

> **摘要翻译:** 人工智能范式的持续演进已将AI研究推向了代理式AI阶段。因此，研究的焦点已从单一智能体和简单应用转向复杂环境中的多智能体自主决策和任务协作。随着大型语言模型（LLMs）的进步，其应用变得日益多样和复杂，导致情境和系统性风险不断增加。这使得代理式AI系统中的价值对齐受到了广泛关注，其旨在确保智能体的目标、偏好和行为与人类价值观和社会规范保持一致。本研究通过一个多层次价值框架来应对社会治理需求，全面综述了基于LLM的多智能体系统（作为代理式AI系统的代表原型）中的价值对齐。我们的综述系统地考察了三个相互关联的维度：首先，价值原则通过宏观、中观和微观层面的自上而下层次结构进行构建。其次，应用场景沿着从通用到特定的连续统一体进行分类，明确反映了这些价值层级。第三，价值对齐方法和评估通过系统审查基准数据集和相关方法，被映射到这个分层框架中。此外，我们深入探讨了代理式AI系统中多个智能体之间的价值协调。最后，我们提出了该领域的几个潜在研究方向。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [588] [Style-Preserving Policy Optimization for Game Agents](https://arxiv.org/abs/2506.16995)
> *游戏智能体风格保持策略优化*

*Lingfeng Li, Yunlong Lu, Yongyi Wang, Wenxin Li* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 策略优化, 游戏智能体, 强化学习, 风格保持, MPPO

**Comment:** 

> **TL;DR:** 本文提出MPPO方法，旨在提升现有游戏智能体的熟练度，同时保留其独特的游戏风格，实现高熟练度和多样化的智能体生成。

**AI_Comments:** 这项工作具有重要意义，它解决了强化学习在游戏AI领域的一个关键限制——即过度关注性能而牺牲了多样性。MPPO的创新之处在于其统一在线/离线损失目标和引入隐式约束来保持风格，这为生成更丰富、更具吸引力的游戏体验提供了新的可能。该方法有望在游戏开发和AI研究中找到广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于强化学习的游戏AI主要侧重于提升熟练度，而基于进化算法的方法虽然能生成多样化风格的智能体，但性能较差。本文旨在弥补这一差距，在提升智能体熟练度的同时保留其独特的风格。

**Method:** 本文提出了混合近端策略优化（MPPO）方法。MPPO统一了在线和离线样本的损失目标，并引入了隐式约束，通过调整样本的经验分布来近似演示者策略。

**Result:** 在不同规模的环境中进行的实证结果表明，MPPO在保持演示者游戏风格的同时，达到了与纯在线算法相当甚至更优的熟练度水平。

**Conclusion:** 这项工作提出了一种生成高熟练度和多样化游戏智能体的有效方法，最终有助于提供更具吸引力的游戏体验。

> **ai_Abstract:** 本文针对强化学习在游戏AI中侧重熟练度而忽视风格多样性的问题，提出了一种名为混合近端策略优化（MPPO）的新方法。MPPO通过统一在线和离线样本的损失目标，并引入隐式约束来近似演示者策略，从而在提升游戏智能体熟练度的同时，有效保留其独特的风格。实验结果表明，MPPO在保持风格的同时，能达到与纯在线算法相当或更优的熟练度，为生成兼具高熟练度和多样化风格的游戏智能体提供了有效途径。

> **摘要翻译:** 熟练且风格多样的游戏智能体能丰富游戏体验并提升游戏的可玩性。然而，近期基于强化学习的游戏AI进展主要集中于提高熟练度，而基于进化算法的方法虽然能生成风格多样的智能体，但其性能与强化学习方法相比却逊色。为了弥补这一差距，本文提出了一种混合近端策略优化（MPPO）方法，旨在在提升现有次优智能体熟练度的同时，保留其独特的风格。MPPO统一了在线和离线样本的损失目标，并引入了隐式约束，通过调整样本的经验分布来近似演示者策略。在不同规模环境中的实证结果表明，MPPO在保持演示者游戏风格的同时，达到了与纯在线算法相当甚至更优的熟练度水平。这项工作为生成高熟练度和多样化的游戏智能体提供了一种有效方法，最终有助于提供更具吸引力的游戏体验。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [594] [Scaling LLM Planning: NL2FLOW for Parametric Problem Generation and Rigorous Evaluation](https://arxiv.org/abs/2507.02253)
> *扩展LLM规划：用于参数化问题生成和严格评估的NL2FLOW*

*Jungkoo Kang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** LLM规划, NL2Flow, 问题生成, 评估, 工作流

**Comment:** 

> **TL;DR:** 本文介绍了NL2Flow系统，用于参数化生成LLM规划问题并严格评估其规划质量，发现LLM在生成有效规划方面表现良好，但直接从自然语言到动作的推理优于分解任务。

**AI_Comments:** NL2Flow的创新在于其全自动化、参数化的规划问题生成能力，以及对LLM规划的严格评估框架。它解决了LLM规划领域评估数据稀缺的关键问题，并提出了关于LLM推理路径（直接推理与分解）的重要见解，这对于未来LLM在复杂任务中的应用具有指导意义。该研究强调了理解LLM内部瓶颈的重要性。

<details>
  <summary>Details</summary>

**Motivation:** LLM规划和推理的进展受限于缺乏可扩展、可靠的评估数据。本文旨在通过识别合适的LLM应用工作流领域并提供自动化系统来解决这一限制。

**Method:** 引入NL2Flow，一个全自动系统，用于参数化生成以自然语言、结构化中间表示和PDDL表达的规划问题，并严格评估生成规划的质量。NL2Flow生成了一个包含2296个低难度问题的自动化工作流生成数据集，并评估了多个开源、指令调优的LLM，没有进行任务特定的优化或架构修改。此外，还评估了LLM作为自然语言到JSON转换器的性能。

**Result:** 最高性能模型在生成有效规划方面达到86%的成功率，在生成最优规划方面达到69%的成功率（针对可行规划的问题）。回归分析表明，问题特征对规划生成的影响取决于模型和提示设计。将自然语言转换为工作流问题的JSON表示的成功率低于直接生成规划，这表明不必要的推理任务分解可能会降低性能，并突出了模型直接从自然语言推理到动作的优势。

**Conclusion:** LLM规划和推理的进展受限于缺乏可扩展、可靠的评估数据。NL2Flow系统解决了这一问题，并揭示了LLM在规划方面的潜力，同时强调了直接从自然语言到动作推理的重要性，而非不必要的任务分解。随着LLM推理处理日益复杂的问题，理解系统内部瓶颈和错误来源至关重要。

> **ai_Abstract:** 本研究针对LLM规划和推理中评估数据稀缺的问题，引入了NL2Flow系统。该系统能自动生成参数化规划问题，并严格评估LLM生成的规划。实验发现，LLM在生成有效规划方面表现良好，最高性能模型成功率达86%。研究还指出，直接从自然语言到动作的推理优于将任务不必要地分解为中间表示，这对于LLM处理复杂问题至关重要。

> **摘要翻译:** 有效的智能体性能依赖于将工具和智能体组合成有效工作流的能力。然而，大型语言模型（LLM）规划和推理的进展受限于缺乏可扩展、可靠的评估数据。本研究通过识别适合LLM应用的工作流领域来解决这一限制。我引入了NL2Flow，一个全自动系统，用于参数化生成以自然语言、结构化中间表示和形式化PDDL表达的规划问题，并严格评估生成规划的质量。NL2Flow生成了一个包含2296个低难度问题的自动化工作流生成数据集，并评估了多个开源、指令调优的LLM，没有进行任务特定的优化或架构修改。结果显示，最高性能的模型在生成有效规划方面达到86%的成功率，在生成最优规划方面达到69%的成功率，特别是对于具有可行规划的问题。回归分析表明，问题特征对规划生成的影响取决于模型和提示设计。为了研究LLM作为工作流定义中自然语言到JSON转换器的潜力，并促进与下游符号计算工具和符号规划器的集成，我评估了LLM在自然语言工作流描述上的翻译性能。我观察到，将自然语言转换为工作流问题的JSON表示的成功率低于直接生成规划，这表明不必要的推理任务分解可能会降低性能，并突出了模型直接从自然语言推理到动作的优势。随着LLM推理扩展到日益复杂的问题，理解这些系统中不断变化的瓶颈和错误来源将至关重要。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [600] [Establishing Best Practices for Building Rigorous Agentic Benchmarks](https://arxiv.org/abs/2507.02825)
> *建立严谨智能体基准的实践指南*

*Yuxuan Zhu, Tengjun Jin, Yada Pruksachatkun, Andy Zhang, Shu Liu, Sasha Cui, Sayash Kapoor, Shayne Longpre, Kevin Meng, Rebecca Weiss, Fazl Barez, Rahul Gupta, Jwala Dhamala, Jacob Merizian, Mario Giulianelli, Harry Coppock, Cozmin Ududec, Jasjeet Sekhon, Jacob Steinhardt, Antony Kellermann, Sarah Schwettmann, Matei Zaharia, Ion Stoica, Percy Liang, Daniel Kang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 智能体基准, 评估, 最佳实践, Agentic Benchmark Checklist, 性能高估

**Comment:** 

> **TL;DR:** 现有智能体基准在任务设置或奖励设计上存在问题，导致评估不准确。本文提出智能体基准清单(ABC)来改进基准的严谨性，并成功减少了性能高估。

**AI_Comments:** 这篇论文识别了当前智能体基准的关键问题，并提出了一个实用的解决方案——ABC清单，这对于确保AI智能体评估的准确性和可靠性至关重要。其创新点在于将实践经验和理论问题结合，形成一套可操作的指导方针，并用具体案例验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI智能体能力日益增强，智能体基准被引入以评估其在复杂现实任务中的表现。然而，许多现有智能体基准在任务设置或奖励设计上存在问题，例如测试用例不足或将空响应计为成功，这可能导致对智能体性能的低估或高估高达100%。

**Method:** 本文综合了基准构建经验、最佳实践调查和先前报告的问题，提出了一套名为“智能体基准清单（Agentic Benchmark Checklist, ABC）”的指导方针。

**Result:** 将智能体基准清单（ABC）应用于评估设计复杂的CVE-Bench基准时，成功将性能高估减少了33%。

**Conclusion:** 智能体基准清单（ABC）有助于使智能体评估更加严谨和准确。

> **ai_Abstract:** 本文指出当前AI智能体基准在任务设置和奖励设计上存在缺陷，可能导致高达100%的性能评估误差。为解决此问题，作者提出了智能体基准清单（ABC），一套基于经验和最佳实践的指南。实验证明，将ABC应用于复杂基准CVE-Bench可将性能高估减少33%，从而提高智能体评估的严谨性。

> **摘要翻译:** 基准对于量化跟踪AI进展至关重要。随着AI智能体能力日益增强，研究人员和从业者引入了智能体基准来评估智能体在复杂现实任务中的表现。这些基准通常通过特定的奖励设计来评估任务结果，从而衡量智能体能力。然而，我们发现许多智能体基准在任务设置或奖励设计上存在问题。例如，SWE-bench Verified 使用了不足的测试用例，而TAU-bench则将空响应计为成功。这些问题可能导致对智能体性能的低估或高估，相对误差高达100%。为了使智能体评估更加严谨，我们引入了智能体基准清单（ABC），这是一套我们根据基准构建经验、最佳实践调查和先前报告的问题综合而成的指南。当应用于CVE-Bench（一个评估设计特别复杂的基准）时，ABC将性能高估减少了33%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [606] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
> *Chart-R1：用于高级图表推理器的思维链监督与强化*

*Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Yufeng Zhong, Lin Ma* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 图表推理, 强化学习, 思维链, 视觉语言模型, 数据合成

**Comment:** 

> **TL;DR:** Chart-R1引入了一种基于强化学习微调的视觉语言模型，通过程序化数据合成和两阶段训练策略（思维链监督和数值敏感强化微调），显著提升了图表推理能力，甚至可与大型模型媲美。

**AI_Comments:** 本文的创新点在于将R1-Style强化学习方法首次应用于图表多模态推理领域，并通过新颖的程序化数据合成技术解决了该领域高质量推理数据缺乏的痛点。两阶段训练策略，特别是数值敏感的强化微调，对于图表这种包含大量数值信息的模态尤为重要。其性能达到甚至超越了现有SOTA图表模型，并可与顶级大型语言模型媲美，显示了其在该领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 受OpenAI-o1/o3和Deepseek-R1启发，R1-Style方法在数学推理和代码智能方面受到广泛关注。然而，在更通用的多模态数据（如图表）上验证其优势具有重要的研究意义。图表是一种信息丰富的多模态数据类型，其复杂推理带来了重要的研究挑战，且图表领域缺乏高质量的推理数据。

**Method:** 本文提出了Chart-R1，一个用于图表领域的视觉语言模型，采用强化学习进行微调以实现复杂的图表推理。为支持Chart-R1，首先提出了一种新颖的程序化数据合成技术，生成覆盖单子图和多子图的高质量分步图表推理数据，弥补了图表领域推理数据的不足。然后开发了一个两阶段训练策略：Chart-COT（分步思维链监督）和Chart-RFT（数值敏感强化微调）。Chart-COT旨在通过分步监督将复杂图表推理任务分解为细粒度、可理解的子任务；Chart-RFT采用典型的组相对策略优化策略，对数值响应采用相对软的奖励，以强调图表领域的数值敏感性。

**Result:** 在开源基准和自建图表推理数据集（ChartRQA）上进行了广泛实验。实验结果表明，Chart-R1相比现有图表领域方法具有显著优势，甚至可以与开源/闭源大型模型（如GPT-4o, Claude-3.5）相媲美。

**Conclusion:** Chart-R1通过结合程序化数据合成、思维链监督和数值敏感强化微调，在图表推理任务上取得了突破性进展，显著提升了模型性能，并证明了R1-Style方法在更广泛多模态数据上的潜力。

> **ai_Abstract:** 本文介绍了Chart-R1，一个专门用于复杂图表推理的视觉语言模型，它通过强化学习进行微调。为解决图表推理数据稀缺问题，研究团队开发了一种程序化数据合成技术，生成高质量的分步推理数据。在此基础上，Chart-R1采用了两阶段训练策略：Chart-COT通过思维链监督分解复杂任务，Chart-RFT则通过数值敏感的强化微调提升推理精度。实验证明，Chart-R1在图表推理任务上表现卓越，超越了现有图表领域方法，并与GPT-4o和Claude-3.5等大型模型性能相当。

> **摘要翻译:** 最近，受OpenAI-o1/o3和Deepseek-R1的启发，基于强化学习微调的R1-Style方法受到了社区的广泛关注。之前的R1-Style方法主要集中在数学推理和代码智能方面。在更通用的多模态数据上验证它们的优势具有重要的研究意义。图表是一种信息丰富的多模态数据类型，在复杂推理中带来了重要的研究挑战。在这项工作中，我们引入了Chart-R1，一个通过强化学习微调实现的图表领域视觉语言模型，以支持复杂的图表推理。为了支持Chart-R1，我们首先提出了一种新颖的程序化数据合成技术，用于生成涵盖单子图和多子图的高质量分步图表推理数据，这弥补了图表领域推理数据的不足。然后我们开发了一个两阶段训练策略：Chart-COT采用分步思维链监督，Chart-RFT采用数值敏感强化微调。Chart-COT旨在通过分步监督将复杂图表推理任务分解为细粒度、可理解的子任务，这为提高强化学习的推理水平奠定了良好基础。Chart-RFT利用典型的组相对策略优化策略，其中对数值响应采用相对软的奖励，以强调图表领域的数值敏感性。我们在开源基准和自建图表推理数据集（即ChartRQA）上进行了广泛实验。实验结果表明，Chart-R1相比图表领域方法具有显著优势，甚至可以与开源/闭源大型模型（例如GPT-4o, Claude-3.5）相媲美。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [612] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
> *自适应推理的分层预算策略优化*

*Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 分层预算策略优化, 自适应推理, 强化学习, 思维链, 效率

**Comment:** 

> **TL;DR:** HBPO是一种强化学习框架，通过分层预算和差异化奖励，使大型推理模型能够根据问题复杂性自适应调整推理深度，显著提高效率和准确性。

**AI_Comments:** 该论文通过引入分层预算策略优化（HBPO）框架，创新性地解决了大型推理模型在效率和能力之间权衡的挑战。其核心贡献在于通过分层探索空间和差异化奖励机制，克服了传统长度惩罚导致探索空间崩溃的问题，使得模型能够学习到真正的自适应推理行为。这对于提升大型语言模型在实际应用中的效能具有重要意义，表明效率和能力可以同时优化，为未来的高效推理模型设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型通过广泛的思维链生成取得了显著性能，但存在一个关键的低效问题：无论问题复杂性如何，都统一地应用广泛的推理。

**Method:** 本文提出了分层预算策略优化（HBPO），一个强化学习框架，使模型能够在不牺牲能力的情况下学习特定问题的推理深度。HBPO将探索空间划分为预算受限的层次（512-2560个token），每个层次具有差异化的奖励结构，以保持效率激励和推理能力。它通过分层采样和预算感知奖励来维持探索多样性，同时教导模型识别何时需要扩展推理。

**Result:** HBPO在四个推理基准测试中将平均token使用量减少了高达60.6%，同时将准确率提高了3.14%。最值得注意的是，HBPO展现了涌现的自适应行为，模型能根据问题复杂性自动调整推理深度。

**Conclusion:** 推理效率和能力并非固有冲突，可以通过适当结构化的分层训练同时优化，这种训练能够保持探索多样性。

> **ai_Abstract:** 本文提出了一种名为分层预算策略优化（HBPO）的强化学习框架，旨在解决大型推理模型在推理过程中效率低下的问题。HBPO通过将探索空间划分为具有不同奖励结构的分层预算，使得模型能够根据问题的复杂性自适应地调整推理深度，从而在不牺牲性能的情况下显著减少token使用量。实验证明，HBPO在提高准确性的同时大幅提升了推理效率，并展现出模型自动调整推理深度的自适应行为。

> **摘要翻译:** 大型推理模型通过广泛的思维链生成取得了显著性能，但存在一个关键的低效问题：无论问题复杂性如何，都统一地应用广泛的推理。我们提出了分层预算策略优化（HBPO），一个强化学习框架，使模型能够在不牺牲能力的情况下学习特定问题的推理深度。与现有施加严格约束或依赖离散模式选择的方法不同，HBPO将探索空间划分为预算受限的层次（512-2560个token），每个层次具有差异化的奖励结构，以保持效率激励和推理能力。这种设计解决了高效推理训练中的一个根本性挑战：传统的长度惩罚系统地偏离模型，使其远离必要的长推理路径，导致探索空间崩溃。通过分层采样和预算感知奖励，HBPO在维持探索多样性的同时，教导模型识别何时需要扩展推理。广泛的实验表明，HBPO在四个推理基准测试中将平均token使用量减少了高达60.6%，同时将准确率提高了3.14%。最值得注意的是，HBPO展现了涌现的自适应行为，模型能根据问题复杂性自动调整推理深度。我们的结果表明，推理效率和能力并非固有冲突，可以通过适当结构化的分层训练同时优化，这种训练能够保持探索多样性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [618] [SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law](https://arxiv.org/abs/2507.18576)
> *SafeWork-R1：在AI-45°定律下安全与智能的协同进化*

*Shanghai AI Lab, Yicheng Bao, Guanxu Chen, Mingkang Chen, Yunhao Chen, Chiyu Chen, Lingjie Chen, Sirui Chen, Xinquan Chen, Jie Cheng, Yu Cheng, Dengke Deng, Yizhuo Ding, Dan Ding, Xiaoshan Ding, Yi Ding, Zhichen Dong, Lingxiao Du, Yuyu Fan, Xinshun Feng, Yanwei Fu, Yuxuan Gao, Ruijun Ge, Tianle Gu, Lujun Gui, Jiaxuan Guo, Qianxi He, Yuenan Hou, Xuhao Hu, Hong Huang, Kaichen Huang, Shiyang Huang, Yuxian Jiang, Shanzhe Lei, Jie Li, Lijun Li, Hao Li, Juncheng Li, Xiangtian Li, Yafu Li, Lingyu Li, Xueyan Li, Haotian Liang, Dongrui Liu, Qihua Liu, Zhixuan Liu, Bangwei Liu, Huacan Liu, Yuexiao Liu, Zongkai Liu, Chaochao Lu, Yudong Lu, Xiaoya Lu, Zhenghao Lu, Qitan Lv, Caoyuan Ma, Jiachen Ma, Xiaoya Ma, Zhongtian Ma, Lingyu Meng, Ziqi Miao, Yazhe Niu, Yuezhang Peng, Yuan Pu, Han Qi, Chen Qian, Xingge Qiao, Jingjing Qu, Jiashu Qu, Wanying Qu, Wenwen Qu, Xiaoye Qu, Qihan Ren, Qingnan Ren, Qingyu Ren, Jing Shao, Wenqi Shao, Shuai Shao, Dongxing Shi, Xin Song, Xinhao Song, Yan Teng, Xuan Tong, Yingchun Wang, Xuhong Wang, Shujie Wang, Xin Wang, Yige Wang, Yixu Wang, Yuanfu Wang, Futing Wang, Ruofan Wang, Wenjie Wang, Yajie Wang, Muhao Wei, Xiaoyu Wen, Fenghua Weng, Yuqi Wu, Yingtong Xiong, Xingcheng Xu* | **Category: cs.AI, cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** SafeWork-R1, SafeLadder, AI安全, 多模态推理, 强化学习, 协同进化

**Comment:** 

> **TL;DR:** SafeWork-R1通过SafeLadder框架实现了能力与安全的协同进化，并在安全基准上显著超越现有模型，同时保持通用能力。

**AI_Comments:** 该论文的创新之处在于其SafeLadder框架，通过培养内在的安全推理和自我反思能力，超越了传统的RLHF方法，实现了能力与安全的协同进化。这是构建值得信赖的AI的关键进展。该框架在不同基础模型上的普适性进一步彰显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的对齐方法（如RLHF）仅学习人类偏好，缺乏内在的安全推理和自我反思能力，因此需要一种能使AI模型安全与能力协同进化的新方法。

**Method:** 本文引入了SafeWork-R1多模态推理模型，该模型通过SafeLadder框架开发。SafeLadder框架采用大规模、渐进式、面向安全的强化学习后训练，并辅以多原则验证器，以培养模型内在的安全推理和自我反思能力。此外，还实现了两种推理时干预方法和一种审慎搜索机制，用于步骤级验证。该框架已应用于Qwen2.5-VL-72B、InternVL3-78B-以及DeepSeek-70B等多种基础模型。

**Result:** SafeWork-R1在安全相关基准测试中，比其基础模型Qwen2.5-VL-72B平均提升了46.54%，且未损害通用能力。与GPT-4.1和Claude Opus 4等领先的专有模型相比，它提供了最先进的安全性能。所有基于该框架开发出的模型都证明了安全和能力可以协同进化。

**Conclusion:** SafeLadder框架能够实现AI模型中安全与能力的协同进化，这突显了其在构建鲁棒、可靠和值得信赖的通用人工智能方面的普适性。

> **ai_Abstract:** 本文介绍了SafeWork-R1，一个通过SafeLadder框架开发的多模态推理模型。SafeLadder利用渐进式、面向安全的强化学习和多原则验证器，培养模型内在的安全推理和自我反思能力，超越了单纯学习人类偏好的方法。SafeWork-R1在安全性能上取得了显著提升（比Qwen2.5-VL-72B高46.54%），同时保持了通用能力，并达到了与顶级专有模型相当的SOTA安全表现。该框架在不同基础模型上的通用性得到了验证，表明安全与能力能够协同进化，以构建鲁棒可靠的AI。

> **摘要翻译:** 我们引入了SafeWork-R1，一个尖端的多模态推理模型，它展示了能力和安全的协同进化。它由我们提出的SafeLadder框架开发，该框架结合了大规模、渐进式、面向安全的强化学习后训练，并由一套多原则验证器支持。与以前简单学习人类偏好的对齐方法（如RLHF）不同，SafeLadder使SafeWork-R1能够发展内在的安全推理和自我反思能力，从而产生安全“顿悟”时刻。值得注意的是，SafeWork-R1在安全相关基准测试中比其基础模型Qwen2.5-VL-72B平均提高了46.54%，同时不损害通用能力，并且与GPT-4.1和Claude Opus 4等领先的专有模型相比，提供了最先进的安全性能。为了进一步增强其可靠性，我们实施了两种不同的推理时干预方法和一种审慎搜索机制，强制进行步骤级验证。最后，我们进一步开发了SafeWork-R1-InternVL3-78B、SafeWork-R1-DeepSeek-70B和SafeWork-R1-Qwen2.5VL-7B。所有由此产生的模型都表明安全和能力可以协同进化，突出了我们框架在构建鲁棒、可靠和值得信赖的通用人工智能方面的普适性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [624] [Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image](https://arxiv.org/abs/2507.21881)
> *疼痛识别的多表示图：将各种电真皮活动信号整合到单个图像中*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 疼痛识别, 电真皮活动, 多表示图, 信号融合, 自动评估

**Comment:** 

> **TL;DR:** 本研究提出了一种将多种电真皮活动（EDA）信号表示整合到单个多表示图中的方法，用于疼痛识别，并在实验中表现出与传统融合方法相当或更优的性能。

**AI_Comments:** 这篇论文的创新点在于其提出的多表示图方法，能够将电真皮活动（EDA）信号的多种复杂表示整合到单个视觉图像中。这种方法简化了多模态数据融合，并可能为疼痛识别提供更直观、更有效的数据表示。其在AI4PAIN挑战中的提交背景也凸显了其在实际应用和挑战解决中的潜力。该方法提供了一种新颖的信号整合策略，可能超越传统融合方法的局限性，具有重要的研究价值和潜在的临床应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛影响大量人群，可靠的疼痛评估对患者和管理策略开发至关重要。自动疼痛评估系统通过生理信号提供客观、准确的洞察，有助于持续监测、临床决策和减少痛苦。

**Method:** 该研究提出一个利用电真皮活动（EDA）信号作为输入模式的流程。它创建信号的多种表示并将其可视化为波形，然后将这些波形共同可视化在一个单一的多表示图中。

**Result:** 广泛的实验表明，所提出的方法与传统融合方法相比，始终能产生可比甚至在某些情况下更优的结果。

**Conclusion:** 所提出的方法为整合不同的信号表示或模态提供了一种稳健的替代方案，并在疼痛识别方面表现出有效性。

> **ai_Abstract:** 本文提出了一种用于疼痛识别的自动评估方法，该方法通过整合电真皮活动（EDA）信号的多种表示到单一的多表示图中。该研究旨在提高疼痛评估的客观性和准确性，并通过实验证明，与传统融合方法相比，其提出的方法在性能上具有竞争力甚至更优，为生理信号的集成提供了一个稳健的新范式。

> **摘要翻译:** 疼痛是一种多方面的现象，影响着相当一部分人口。可靠和一致的评估有益于经历疼痛的人，并支撑着有效和先进管理策略的开发。自动疼痛评估系统提供持续监测，为临床决策提供信息，旨在减轻痛苦并防止功能下降。通过整合生理信号，这些系统能对个体状况提供客观、准确的洞察。这项研究已提交给“第二届下一代疼痛评估多模态感知大挑战（AI4PAIN）”。所提出的方法引入了一个利用电真皮活动信号作为输入模态的流程。信号的多种表示被创建并可视化为波形，然后它们被共同可视化在一个单一的多表示图中。结合各种处理和过滤技术以及多种表示组合的广泛实验，证明了所提出方法的有效性。它始终能产生与传统融合方法可比，并且在某些情况下更优的结果，从而确立了其作为整合不同信号表示或模态的稳健替代方案的地位。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [630] [Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline](https://arxiv.org/abs/2507.21886)
> *通过呼吸信号进行高效疼痛识别：一种单交叉注意力Transformer多窗口融合管道*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI, cs.LG, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 疼痛识别, 呼吸信号, 交叉注意力Transformer, 多窗口融合, 生理模态

**Comment:** 

> **TL;DR:** 该研究提出了一种利用呼吸信号进行疼痛识别的高效方法，结合了交叉注意力Transformer和多窗口融合策略，并证明呼吸信号是一种有价值的生理模态，且紧凑模型也能表现出色。

**AI_Comments:** 该研究的创新之处在于利用呼吸信号结合紧凑的交叉注意力Transformer和多窗口融合管道进行疼痛识别。其重要性体现在证明了呼吸作为生理模态在疼痛评估中的有效性，以及高效模型超越大型模型的潜力，这对于实际、实时的疼痛评估系统至关重要。提交给AI4PAIN挑战赛也表明了其与当前研究工作的相关性。

<details>
  <summary>Details</summary>

**Motivation:** 准确和一致的疼痛评估对于经历疼痛的个体至关重要，这有助于开发有效的管理策略。自动疼痛评估系统能够提供持续监测并支持临床决策，从而减轻痛苦并防止功能下降。

**Method:** 本研究提出了一种以呼吸信号作为输入，结合高效交叉注意力Transformer和多窗口策略的管道。该多窗口方法旨在有效捕获短期、长期和全局特征。

**Result:** 实验证明，呼吸是评估疼痛的一种有价值的生理模态。此外，实验表明，经过适当优化的紧凑高效模型可以实现强大的性能，通常超越大型模型。所提出的多窗口方法有效捕获了短期、长期特征以及全局特征，从而增强了模型的表示能力。

**Conclusion:** 呼吸信号是进行疼痛评估的有效生理模态，并且通过适当优化的紧凑模型结合多窗口策略，可以实现高性能的疼痛识别。

> **ai_Abstract:** 本文介绍了一种利用呼吸信号进行高效疼痛识别的系统。它提出了一种新颖的管道，该管道将单一交叉注意力Transformer与多窗口融合策略相结合。实验证实呼吸是疼痛评估中一种有价值的生理指标，并表明紧凑、优化的模型可以实现卓越的性能。多窗口方法增强了模型捕获多样时间特征的能力，从而改善了疼痛评估。

> **摘要翻译:** 疼痛是一种复杂的疾病，影响着大部分人口。对经历疼痛的个体进行准确和一致的评估至关重要，它支持开发有效和先进的管理策略。自动疼痛评估系统提供持续监测并支持临床决策，旨在减轻痛苦并防止功能下降。本研究已提交给“第二届下一代疼痛评估多模态感知大挑战 (AI4PAIN)”。所提出的方法引入了一个管道，该管道利用呼吸作为输入信号，并结合了高效的交叉注意力Transformer和多窗口策略。大量实验表明，呼吸是评估疼痛的一种有价值的生理模态。此外，实验表明，紧凑高效的模型，在适当优化后，可以实现强大的性能，通常超越大型模型。所提出的多窗口方法有效捕获了短期和长期特征以及全局特征，从而增强了模型的表示能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [636] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
> *DSBC：数据科学任务基准测试与上下文工程*

*Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Giulio Martini, Ali Shafique, Suman Debnath, Hamza Farooq* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-08-06**

**Keywords:** 数据科学代理, 大型语言模型, 基准测试, 上下文工程, 性能评估

**Comment:** 

> **TL;DR:** 引入DSBC，一个评估数据科学代理的基准，揭示了大型语言模型和方法之间的性能差异。

**AI_Comments:** 该论文解决了大型语言模型驱动的数据科学代理评估中的一个关键空白，提供了一个受真实世界启发设计的基准。其对上下文工程、多步骤方法以及对提示问题敏感性的关注，使其对实际应用特别有意义。识别性能差异和关键部署因素对研究人员和从业者都具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据科学代理被迅速采用，但评估其效能和局限性的系统基准仍然稀缺。

**Method:** 本文引入了一个全面的基准测试（DSBC），旨在通过观察商业应用的使用情况来反映用户与数据科学代理的真实交互。评估了三种大型语言模型（Claude-4.0-Sonnet, Gemini-2.5-Flash, OpenAI-o4-Mini）在三种方法（零样本上下文工程、多步骤上下文工程和使用SmolAgent）下的表现。基准测试评估了八个不同数据科学任务类别的性能，并探讨了模型对常见提示问题（如数据泄露和指令模糊）的敏感性，还研究了温度参数对每个模型和方法的整体及特定任务结果的影响。

**Result:** 研究结果揭示了所评估模型和方法之间明显的性能差异，突出了影响实际部署的关键因素。

**Conclusion:** 本文介绍的基准数据集和评估框架旨在为未来研究更强大、更有效的数据科学代理提供基础。

> **ai_Abstract:** 本文介绍了DSBC，一个新颖的基准测试，旨在系统评估由大型语言模型驱动的数据科学代理，以解决当前缺乏全面评估工具的问题。通过观察真实世界的使用情况，DSBC评估了领先的大型语言模型（Claude-4.0-Sonnet, Gemini-2.5-Flash, OpenAI-o4-Mini）在不同方法和八个数据科学任务类别中的表现。该研究还调查了模型对常见提示问题（如数据泄露和模糊指令）的鲁棒性以及温度参数的影响。结果揭示了模型和方法之间显著的性能差异，为实际部署提供了重要见解，并为未来研究更有效的数据科学代理奠定了基础。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展显著影响了数据科学工作流程，催生了旨在自动化分析任务的专用数据科学代理。尽管被迅速采用，但评估这些代理效能和局限性的系统基准仍然稀缺。本文介绍了一个全面的基准测试，该基准通过观察我们商业应用程序的使用情况，专门设计用于反映用户与数据科学代理的真实世界交互。我们评估了三种大型语言模型：Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini，采用三种方法：零样本上下文工程、多步骤上下文工程和使用SmolAgent。我们的基准测试评估了八个不同数据科学任务类别的性能，此外还探讨了模型对常见提示问题（如数据泄露和轻微模糊指令）的敏感性。我们进一步研究了温度参数对每个模型和方法的整体及特定任务结果的影响。我们的研究结果揭示了所评估模型和方法之间明显的性能差异，突出了影响实际部署的关键因素。本文介绍的基准数据集和评估框架旨在为未来研究更强大、更有效的数据科学代理提供基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [642] [NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset](https://arxiv.org/abs/2508.01330)
> *NatureGAIA：通过挑战性基准和高质量轨迹数据集推动GUI智能体的边界*

*Zihan Zheng, Tianle Cui, Chuwen Xie, Jiahui Zhang, Jiahui Pan, Lewei He, Qianglong Chen* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** GUI智能体, 评估基准, 大语言模型, 轨迹数据集, 强化微调

**Comment:** 

> **TL;DR:** 引入了NaturalGAIA，一个基于因果路径的新型GUI智能体评估基准，并开发了LightManus智能体以生成高质量数据集。实验表明，当前最先进的LLM在此基准上表现不佳，且对小型模型进行RFT虽有提升但在复杂场景下仍有限。

**AI_Comments:** 这项研究通过引入NaturalGAIA基准和LightManus智能体及其生成的高质量数据集，为GUI智能体领域做出了重要贡献。其创新之处在于提出了基于因果路径的评估范式，这显著提高了评估的准确性和可复现性。此外，数据集包含了LLM的自我纠正行为，这对于训练更鲁棒的智能体非常有价值。研究结果清晰地揭示了当前SOTA LLM在复杂GUI任务上的不足，并指出了小型模型通过RFT提升后的局限性，为后续研究提供了明确的方向，即需要更强大的模型和更复杂的训练策略来应对GUI代理的挑战。这项工作的重要性在于它为GUI智能体的研发提供了一个更严谨、更具挑战性的试验场，有助于推动该领域向前发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估基准在准确性、可复现性和可扩展性方面存在严重限制，阻碍了大型语言模型驱动的图形用户界面（GUI）智能体的快速发展。

**Method:** 1. 引入了NaturalGAIA，一个基于因果路径原则的新型基准，将复杂任务分解为可编程验证的原子步骤，确保严格、全自动化和可复现的评估标准。2. 开发了LightManus，一个分层智能体架构，专门为长周期任务优化，并用其生成了一个高质量、经人工验证的轨迹数据集，该数据集捕获了LLM多样化甚至自我纠正的交互模式。3. 利用该数据集对Qwen2.5-VL-7B模型进行了强化微调（RFT）。

**Result:** 1. NaturalGAIA对当前最先进的LLM构成了严峻挑战；即使是表现最好的Claude-sonnet-4，其加权路径成功率（WPSR）也仅为34.6%。2. 强化微调（RFT）显著提升了小型模型（Qwen2.5-VL-7B）的GUI执行能力（WPSR从3.3%提高到10.8%）。3. 然而，RFT后的模型在处理复杂场景时性能急剧下降，这凸显了小型模型在面对集成感知、决策和执行的综合任务时固有的能力上限。

**Conclusion:** 本研究为GUI智能体社区贡献了一个严格的评估标准和一个高质量的数据集，旨在指导未来GUI智能体的发展。

> **ai_Abstract:** 本研究旨在解决现有GUI智能体评估基准的局限性。为此，作者提出了NaturalGAIA，一个基于因果路径的新型基准，以实现严格、可复现的评估。同时，开发了LightManus智能体来生成一个高质量、包含复杂交互模式的轨迹数据集。利用该数据集对Qwen2.5-VL-7B模型进行强化微调（RFT）后，实验结果显示，NaturalGAIA对当前最先进的LLM构成了巨大挑战，即使是顶尖模型也表现不佳。RFT虽然提升了小型模型的性能，但其在复杂任务中的局限性也得以显现，揭示了小型模型的能力上限。本工作为GUI智能体的未来发展提供了重要的评估标准和数据集。

> **摘要翻译:** 大型语言模型（LLM）驱动的图形用户界面（GUI）智能体的快速发展受到现有评估基准在准确性、可复现性和可扩展性方面严重限制的阻碍。为了解决这一关键空白，我们引入了NaturalGAIA，一个基于因果路径原则设计的新型基准。这种设计范式将复杂任务构建成一系列可编程验证的原子步骤，确保了严格、全自动化和可复现的评估标准。同时，为了弥补智能体固有的能力缺陷，我们开发了LightManus，一个专门为长周期任务优化的分层智能体架构。我们利用这个智能体生成了一个高质量、经人工验证的轨迹数据集，该数据集独特地捕捉了LLM多样化甚至自我纠正的交互模式。然后，我们利用这个数据集对Qwen2.5-VL-7B模型进行了强化微调（RFT）。我们的实验表明，NaturalGAIA对当前最先进的LLM构成了严峻挑战；即使是表现最好的Claude-sonnet-4，其加权路径成功率（WPSR）也仅为34.6%。此外，虽然RFT显著提升了小型模型的GUI执行能力（WPSR从3.3%提高到10.8%），但其在处理复杂场景时性能急剧下降。这一结果凸显了小型模型在面对集成感知、决策和执行的综合任务时固有的能力上限。本研究为社区贡献了一个严格的评估标准和一个高质量的数据集，旨在指导GUI智能体的未来发展。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [648] [Getting out of the Big-Muddy: Escalation of Commitment in LLMs](https://arxiv.org/abs/2508.01545)
> *走出困境：大型语言模型中的承诺升级*

*Emilio Barkett, Olivia Long, Paul Kröger* | **Category: cs.AI, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 承诺升级, 认知偏见, 多智能体系统, 上下文依赖

**Comment:** 

> **TL;DR:** 研究发现大型语言模型（LLMs）的承诺升级偏见并非固有，而是高度依赖于社会和组织情境，尤其在多智能体协作和压力情境下显著。

**AI_Comments:** 这项研究创新性地将人类认知偏见“承诺升级”的视角引入到LLM行为分析中，揭示了LLMs在不同社会和组织上下文中的决策差异。其重要性在于，它挑战了LLMs决策行为的固有性假设，强调了外部环境对LLMs偏见表现的关键作用，对未来多智能体系统和自动化决策的部署和风险管理具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自主决策中应用日益广泛，但由于其训练数据来源于人类，可能继承人类的认知偏见，如承诺升级。目前尚不清楚LLMs是否会表现出这种偏见，以及在何种条件下会表现。

**Method:** 本研究使用两阶段投资任务，在四种实验条件下进行调查：模型作为投资者、模型作为顾问、多智能体协商以及复合压力情境。共进行了6500次试验。

**Result:** 研究发现LLMs的偏见表现高度依赖于上下文。在个体决策情境中（N=4000），LLMs表现出强大的理性成本效益逻辑，承诺升级现象极少。然而，在多智能体协商中（N=500），不对称层级显示出中等程度的承诺升级率（46.2%），而对称的同伴决策则产生了近乎普遍的承诺升级（99.2%）。同样，在复合组织和个人压力下（N=2000），模型表现出高度的承诺升级（对失败部门的平均分配为68.95%）。

**Conclusion:** LLM偏见的表现关键取决于社会和组织背景，而非固有属性。

> **ai_Abstract:** 本研究探讨大型语言模型（LLMs）是否会表现出人类的认知偏见，特别是承诺升级。通过在两阶段投资任务中设置四种实验条件（个体决策、多智能体协商、复合压力），研究发现LLMs的承诺升级偏见并非固有，而是高度依赖于社会和组织情境。在个体决策中LLMs表现理性，但在对称的多智能体协商和复合压力下，承诺升级现象显著。这揭示了部署多智能体系统和无人监督操作时，需考虑社会和组织环境对LLMs决策行为的影响。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地被部署到高风险领域的自主决策角色中。然而，由于模型是根据人类生成的数据进行训练的，它们可能会继承系统性扭曲人类判断的认知偏见，包括承诺升级——决策者由于先前的投入而继续投资于失败的行动方案。理解LLMs何时表现出这种偏见提出了独特的挑战。尽管这些偏见在人类中已得到充分记录，但尚不清楚它们是否在LLMs中持续表现，或者是否需要特定的触发条件。本文使用两阶段投资任务，在四种实验条件下调查了这个问题：模型作为投资者、模型作为顾问、多智能体协商和复合压力情境。在N=6500次试验中，我们发现LLMs中偏见的表现高度依赖于上下文。在个体决策情境中（研究1-2，N=4000），LLMs表现出强大的理性成本效益逻辑，承诺升级现象极少。然而，多智能体协商揭示了显著的层级效应（研究3，N=500）：虽然不对称层级显示出中等程度的承诺升级率（46.2%），但对称的基于同伴的决策产生了近乎普遍的承诺升级（99.2%）。同样，当受到复合组织和个人压力时（研究4，N=2000），模型表现出高度的承诺升级（对失败部门的平均分配为68.95%）。这些发现表明，LLM偏见的表现关键取决于社会和组织背景，而非固有属性，这对多智能体系统和无人监督操作的部署具有重要意义，因为在这些情况下，此类条件可能会自然出现。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [654] [SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents](https://arxiv.org/abs/2508.02085)
> *SE-Agent：基于LLM代理的多步推理中自进化轨迹优化*

*Jiaye Lin, Yifu Guo, Yuzhen Han, Sen Hu, Ziyi Ni, Licheng Wang, Mingguang Chen, Daxin Jiang, Binxing Jiao, Chen Hu, Huacan Wang* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** LLM代理, 自进化, 多步推理, 轨迹优化, SWE-bench Verified

**Comment:** 

> **TL;DR:** SE-Agent是一个自进化框架，通过修订、重组和改进过去的推理轨迹，显著提高了LLM代理在复杂多步推理任务中的性能，在SWE-bench Verified上实现了高达55%的相对提升。

**AI_Comments:** SE-Agent的创新之处在于其提出的自进化框架，通过对历史推理轨迹的迭代优化（修订、重组、改进），解决了LLM代理在复杂多步推理中轨迹利用不足和搜索空间受限的问题。这种方法不仅提高了推理效率，还显著提升了解决实际问题的能力，尤其在代码生成和问题修复等领域具有重要应用潜力。该方法通过利用轨迹间的相互依赖性，有效克服了传统搜索方法的局限性，实现了持续的性能提升，为LLM代理的未来发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）代理在复杂推理和工具使用方面表现出色，但其解决问题的过程（即代理的交互轨迹）尚未得到充分利用。现有方法（如MCTS）忽略了不同轨迹之间的相互依赖性，并缺乏搜索空间的多样性，导致推理冗余和次优结果。

**Method:** 本文提出了SE-Agent，一个自进化框架，使代理能够迭代优化其推理过程。该方法通过“修订（revision）”、“重组（recombination）”和“改进（refinement）”三个关键操作，重新审视并增强先前的试探性轨迹。这种进化机制能够扩展搜索空间，超越局部最优，并通过跨轨迹的启发来提高性能。

**Result:** 在SWE-bench Verified数据集上对真实世界GitHub问题进行评估，SE-Agent在五种强大的LLM上实现了高达55%的相对改进，并在所有开源代理中达到了最先进的性能。

**Conclusion:** SE-Agent通过其独特的自进化机制，有效解决了LLM代理在多步推理中轨迹利用不足和搜索空间多样性缺乏的问题，显著提升了代理的推理质量和任务完成能力，达到了最先进的水平。

> **ai_Abstract:** 本文提出了SE-Agent，一个针对LLM代理多步推理的自进化框架。现有LLM代理在处理复杂任务时，其交互轨迹的利用效率不高，且传统方法在轨迹间缺乏关联性，导致推理冗余和次优解。SE-Agent通过“修订”、“重组”和“改进”等操作，迭代优化并增强历史轨迹，从而扩展搜索空间、避免局部最优，并有效利用跨轨迹的启发来提升性能。实验证明，SE-Agent在SWE-bench Verified数据集上使LLM代理的性能相对提升高达55%，达到了当前开源代理的最高水平，验证了其在复杂问题解决中的有效性。

> **摘要翻译:** 大型语言模型（LLM）代理最近在通过与环境的多步交互进行复杂推理和工具使用方面展现出令人印象深刻的能力。尽管这些代理有潜力解决复杂的任务，但其解决问题的过程，即代理完成任务的交互轨迹，仍未得到充分利用。这些轨迹包含丰富的反馈，可以引导代理朝着正确的方向解决问题。尽管诸如蒙特卡洛树搜索（MCTS）等流行方法可以有效地平衡探索和利用，但它们忽略了各种轨迹之间的相互依赖性，并且缺乏搜索空间的多样性，这导致了冗余推理和次优结果。为了应对这些挑战，我们提出了SE-Agent，一个自进化框架，使代理能够迭代优化其推理过程。我们的方法通过三个关键操作：修订、重组和改进，重新审视并增强了先前的试探性轨迹。这种进化机制带来了两个关键优势：（1）它通过智能地探索由先前轨迹引导的各种解决方案路径，将搜索空间扩展到局部最优之外；（2）它利用跨轨迹的启发来有效提高性能，同时减轻次优推理路径的影响。通过这些机制，SE-Agent实现了持续的自进化，逐步提高推理质量。我们在SWE-bench Verified上评估了SE-Agent，以解决真实世界的GitHub问题。在五种强大的LLM上的实验结果表明，集成SE-Agent可实现高达55%的相对改进，在SWE-bench Verified上所有开源代理中达到了最先进的性能。我们的代码和演示材料可在https://github.com/JARVIS-Xs/SE-Agent公开获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [660] [CAMA: Enhancing Mathematical Reasoning in Large Language Models with Causal Knowledge](https://arxiv.org/abs/2508.02583)
> *CAMA：利用因果知识增强大型语言模型的数学推理能力*

*Lei Zan, Keli Zhang, Ruichu Cai, Lujia Pan* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 数学推理, 因果框架, 数学因果图, 结构化指导

**Comment:** 

> **TL;DR:** CAMA是一个两阶段的因果框架，通过构建和利用数学因果图（MCG）来为大型语言模型（LLMs）提供显式的数学结构，从而显著提升LLMs在复杂数学推理任务上的表现。

**AI_Comments:** CAMA的创新之处在于引入了一个两阶段的因果框架，通过构建和利用“数学因果图”（MCG）来为LLM提供结构化的数学知识。这种显式的因果关系建模是其核心优势，因为它解决了LLM在复杂数学推理中缺乏深层结构理解的问题。通过将因果知识注入推理过程，CAMA不仅提高了性能，还证明了结构化指导和非对称因果关系的重要性，这对于未来LLM在符号推理和复杂问题解决方面的发展具有重要启示。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在处理复杂数学推理时表现不佳，这主要是由于其深层的结构依赖性。为了解决这一挑战，研究旨在提升LLMs的数学推理能力。

**Method:** 本文提出了CAMA（因果数学家），一个两阶段的因果框架。在学习阶段，CAMA结合LLM先验知识和因果发现算法，从问答对语料库中构建数学因果图（MCG），该图编码了知识点及其因果依赖关系，并通过迭代反馈进行优化。在推理阶段，CAMA根据新问题和LLM的中间推理轨迹，从MCG中动态提取任务相关的子图，并将其注入LLM以指导其推理过程。

**Result:** 在真实世界数据集上的实证结果表明，CAMA显著提升了LLMs在复杂数学问题上的性能。实验还证明，结构化指导始终优于非结构化替代方案，并且结合非对称因果关系比单独使用对称关联能带来更大的改进。

**Conclusion:** CAMA通过引入显式、可复用的数学结构和因果知识，有效解决了大型语言模型在复杂数学推理方面的挑战，显著提升了其性能，并证明了结构化和非对称因果指导的优越性。

> **ai_Abstract:** 本文提出CAMA，一个两阶段的因果框架，旨在通过赋予大型语言模型（LLMs）显式且可复用的数学结构来增强其数学推理能力。CAMA首先构建并优化一个数学因果图（MCG），该图编码了数学知识点及其因果依赖。在推理时，CAMA从MCG中提取相关子图注入LLM以指导其解决新的数学问题。实验证明，CAMA显著提升了LLMs在复杂数学问题上的表现，并显示出结构化和非对称因果指导的优越性。

> **摘要翻译:** 大型语言模型（LLMs）在广泛的任务中表现出强大的性能，但它们仍然在复杂的数学推理方面苦苦挣扎，这是一个根本上植根于深层结构依赖性的挑战。为了解决这一挑战，我们提出了CAMA（因果数学家），一个两阶段的因果框架，它为LLMs配备了显式的、可复用的数学结构。在学习阶段，CAMA首先通过结合LLM先验知识和应用于问答对语料库的因果发现算法，构建了数学因果图（MCG），这是一种解决方案策略的高级表示。生成的MCG编码了基本知识点及其因果依赖关系。为了更好地使图与下游推理任务对齐，CAMA通过从选定的问答对子集中导出的迭代反馈进一步完善了MCG。在推理阶段，给定一个新问题，CAMA根据问题内容和LLM的中间推理轨迹，从MCG中动态提取一个任务相关的子图。这个子图编码了最相关的知识点及其因果依赖关系，然后被注入回LLM以指导其推理过程。在真实世界数据集上的实证结果表明，CAMA显著提高了LLMs在具有挑战性的数学问题上的性能。此外，我们的实验表明，结构化指导始终优于非结构化替代方案，并且结合非对称因果关系比单独使用对称关联能产生更大的改进。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [666] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
> *Polymath：一种具有动态分层工作流的自优化智能体*

*Chia-Tung Ho, Jing Gong, Xufeng Yao, Yunsheng Bai, Abhishek B Akkur, Haoxing Ren* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** Polymath, 自优化智能体, 动态分层工作流, 大型语言模型, 工作流优化

**Comment:** 

> **TL;DR:** Polymath是一种自优化智能体，它利用任务流图和代码表示的工作流，结合多网格图优化和自反射引导的进化算法，无需标注数据即可优化工作流，并在多项任务上显著优于现有基线。

**AI_Comments:** Polymath的创新之处在于其无需标注数据即可进行工作流优化，这显著增强了LLM代理在真实世界动态问题中的适用性和灵活性。结合任务流图、代码表示以及多网格优化和自反射进化算法，为构建更通用、更高效的智能体提供了新的范式。其在多项任务上的显著性能提升也证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLMs）代理工作流构建方法受限于手动嵌入和依赖标注数据进行训练和优化，导致可扩展性、效率低下且在缺乏标注数据的真实世界动态问题中无效和不灵活。

**Method:** Polymath是一种自优化智能体，具有动态分层工作流，利用任务流图的灵活性和代码表示工作流的表达能力。其优化方法整合了受多网格启发的图优化与自反射引导的进化算法，无需标注数据即可优化工作流。

**Result:** 在编码、数学和多轮问答任务的六个基准数据集上，Polymath比现有最先进的基线平均提高了8.1%。

**Conclusion:** Polymath通过无需标注数据的自优化机制，有效解决了现有LLM代理工作流构建的局限性，并在多种复杂任务上取得了显著的性能提升。

> **ai_Abstract:** 本文提出了Polymath，一个自优化智能体，旨在解决现有LLM代理工作流在可扩展性、效率和对标注数据依赖方面的局限性。Polymath采用动态分层工作流，结合任务流图和代码表示，并引入了一种创新的优化方法，该方法融合了多网格图优化和自反射引导的进化算法，无需标注数据即可实现工作流的优化。实验结果表明，Polymath在编码、数学和多轮问答等六个基准数据集上，相较于现有最先进的基线，平均性能提升了8.1%。

> **摘要翻译:** 大型语言模型（LLM）通过执行由详细指令和结构化操作组成的代理工作流，擅长解决复杂任务。然而，通过文本接口手动将基础模型嵌入到思维链、自我反思和ReACT等代理系统中来构建通用代理，限制了可扩展性和效率。最近，许多研究人员试图通过基于代码的表示来自动化这些工作流的生成和优化。然而，现有方法通常依赖于标注数据集来训练和优化工作流，这使得它们在解决缺乏标注数据的真实世界动态问题时变得无效和不灵活。为了解决这个挑战，我们引入了Polymath，一个具有动态分层工作流的自优化代理，它利用任务流图的灵活性和代码表示工作流的表达能力来解决各种真实世界的动态问题。所提出的优化方法将受多网格启发的图优化与自反射引导的进化算法相结合，无需标注数据即可完善工作流。在编码、数学和多轮问答任务的六个基准数据集上的实验结果表明，Polymath比现有最先进的基线平均提高了8.1%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [672] [OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing](https://arxiv.org/abs/2508.04361)
> *OmniPlay：全模态模型在全模态游戏中的基准测试*

*Fuqing Bie, Shiyu Huang, Xijia Tao, Zhiqin Fang, Leyi Pan, Junzhe Chen, Min Ren, Liuyu Xiang, Zhaofeng He* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 全模态模型, 基准测试, 游戏AI, 模态融合, 跨模态推理

**Comment:** 

> **TL;DR:** OmniPlay是一个新的基准测试平台，用于评估和探测全模态模型在动态、交互式游戏环境中融合和推理能力，发现现有模型在复杂推理和战略规划上的不足，并指出未来研究应关注协同融合。

**AI_Comments:** OmniPlay的创新之处在于其专门设计用于评估全模态模型在动态、交互式环境中的融合和推理能力，这弥补了现有静态和模态受限基准的不足。通过引入模态冲突场景和揭示“少即是多”的悖论，该研究对当前多模态模型融合机制的脆弱性提供了重要见解，并为未来通用人工智能（AGI）的发展指明了方向，即需要更关注协同融合而非单纯的模型规模。这是一个重要的诊断工具，有助于推动该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有的评估方法未能测试通用基础模型在动态、交互式世界中的智能，静态基准缺乏能动性，而交互式基准存在严重的模态瓶颈，通常忽略关键的听觉和时间线索。为了弥补这一评估鸿沟，本文引入了OmniPlay。

**Method:** 本文引入了OmniPlay，一个诊断性基准测试平台，旨在评估和探测智能代理模型在全感官范围内的融合和推理能力。OmniPlay基于模态相互依赖的核心理念，包含一套由五个游戏环境组成的套件，系统地创建了协同和冲突的场景，迫使代理进行真正的跨模态推理。

**Result:** 对六个领先的全模态模型的综合评估揭示了一个关键的二分法：它们在高保真记忆任务上表现出超人性能，但在需要稳健推理和战略规划的挑战中遭遇系统性失败。研究表明，这种脆弱性源于脆弱的融合机制，这导致在模态冲突下性能灾难性下降，并揭示了一个反直觉的“少即是多”悖论，即移除感官信息反而可以提高性能。

**Conclusion:** 研究结果表明，实现稳健的AGI需要将研究重点超越规模化，明确解决协同融合问题。

> **ai_Abstract:** 本文介绍了OmniPlay，一个旨在评估和诊断全模态模型在动态、交互式游戏环境中融合与推理能力的基准测试平台。现有评估未能充分测试模型在复杂交互世界中的智能，尤其是在处理听觉和时间线索方面存在瓶颈。OmniPlay包含五个游戏环境，旨在通过创建模态协同与冲突的场景，迫使模型进行真正的跨模态推理。对六个领先模型的评估显示，它们在记忆任务上表现出色，但在需要稳健推理和战略规划的挑战中表现不佳，这主要归因于脆弱的融合机制。研究还发现“少即是多”的悖论，即移除某些感官信息反而能提高性能。研究强调，实现鲁棒的通用人工智能（AGI）需要将重点放在协同融合而非仅仅规模化上。

> **摘要翻译:** 尽管像Gemini和GPT-4o这样的通用基础模型展现出令人印象深刻的多模态能力，但现有评估未能测试它们在动态、交互式世界中的智能。静态基准缺乏能动性，而交互式基准则存在严重的模态瓶颈，通常忽略关键的听觉和时间线索。为了弥补这一评估鸿沟，我们引入了OmniPlay，一个诊断性基准测试平台，旨在不仅评估，而且探测智能代理模型在全感官范围内的融合和推理能力。OmniPlay基于模态相互依赖的核心理念构建，包含一套由五个游戏环境组成的套件，系统地创建了协同和冲突的场景，迫使代理进行真正的跨模态推理。我们对六个领先的全模态模型的综合评估揭示了一个关键的二分法：它们在高保真记忆任务上表现出超人性能，但在需要稳健推理和战略规划的挑战中遭遇系统性失败。我们证明了这种脆弱性源于脆弱的融合机制，这导致在模态冲突下性能灾难性下降，并揭示了一个反直觉的“少即是多”悖论，即移除感官信息反而可以提高性能。我们的发现表明，实现稳健的AGI需要将研究重点超越规模化，明确解决协同融合问题。我们的平台可在https://github.com/fuqingbie/omni-game-benchmark匿名评审。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [681] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
> *Nemori: 受认知科学启发的自组织智能体记忆*

*Jiayan Nan, Wenquan Ma, Wenlong Wu, Yize Chen* | **Category: cs.AI** | **Updated: 2025-08-07**

**Keywords:** 智能体记忆, 自组织, 认知科学, 大型语言模型, 持久记忆

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）缺乏持久记忆。Nemori是一种受认知科学启发的自组织记忆系统，解决了记忆粒度和自适应学习问题，在长语境中显著优于现有先进系统。

**AI_Comments:** Nemori的创新之处在于其从人类认知原理（事件分割理论、自由能原理）中汲取灵感，以解决LLM记忆中的根本性挑战。其用于记忆粒度的自组织特性和主动学习机制，代表着超越传统基于规则或任意粒度记忆系统的重大进步，为实现更具自适应性和自主性的智能体铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在长语境中无法保持持久记忆，限制了它们作为自主智能体在长期交互中的有效性。现有记忆系统依赖任意粒度定义基本记忆单元，并采用被动、基于规则的知识提取机制，这限制了它们进行真正学习和进化的能力。

**Method:** 本文提出了Nemori，一种受人类认知原理启发的新型自组织记忆架构。其核心创新有两点：
1. 受事件分割理论启发的“两步对齐原则”：提供了一种有原则的、自上而下的方法，将原始对话流自主组织成语义连贯的片段，解决了记忆粒度问题。
2. 受自由能原理启发的“预测-校准原则”：使智能体能够主动从预测差距中学习，超越预定义启发式方法，实现自适应知识进化。

**Result:** 在LoCoMo和LongMemEval基准上的大量实验表明，Nemori显著优于现有最先进的系统，其优势在更长的语境中尤为明显。

**Conclusion:** Nemori通过借鉴认知科学原理，解决了LLM记忆的根本限制，为处理自主智能体的长期、动态工作流提供了一条可行途径。

> **ai_Abstract:** 本文介绍了Nemori，一种新颖的自组织记忆架构，旨在解决大型语言模型（LLMs）在长期交互中维持持久记忆和实现真正学习的局限性。Nemori受认知科学启发，采用“两步对齐原则”实现有原则的记忆粒度，并利用“预测-校准原则”实现自适应知识进化。实验结果表明，Nemori的性能显著优于现有最先进的系统，尤其是在较长的语境中，为自主智能体的长期动态工作流提供了有前景的解决方案。

> **摘要翻译:** 大型语言模型（LLMs）展现出卓越的能力，但它们在长语境中无法维持持久记忆，限制了其作为自主智能体在长期交互中的有效性。尽管现有的记忆系统已取得进展，但它们在定义基本记忆单元时依赖任意粒度，以及采用被动、基于规则的知识提取机制，限制了它们真正学习和进化的能力。为了解决这些根本性限制，我们提出了Nemori，一种受人类认知原理启发的、新颖的自组织记忆架构。Nemori的核心创新是双重的：首先，其受事件分割理论启发的“两步对齐原则”，提供了一种有原则的、自上而下的方法，用于自主地将原始对话流组织成语义连贯的片段，解决了记忆粒度的关键问题。其次，其受自由能原理启发的“预测-校准原则”，使智能体能够主动地从预测差距中学习，超越预定义的启发式方法，实现自适应的知识进化。这为处理自主智能体的长期、动态工作流提供了一条可行途径。在LoCoMo和LongMemEval基准上的大量实验表明，Nemori显著优于现有最先进的系统，其优势在更长的语境中尤为明显。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [684] [Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas](https://arxiv.org/abs/2309.14610)
> *无监督图深度学习揭示城市地区新兴洪水风险概况*

*Kai Yin, Junwei Ma, Ali Mostafavi* | **Category: cs.AI, cs.CY, cs.LG, stat.AP** | **Updated: 2025-08-06**

**Keywords:** 无监督图深度学习,城市洪水风险,FloodRisk-Net,空间依赖性,特征交互

**Comment:** 

> **TL;DR:** 本研究提出了一种基于无监督图深度学习模型（FloodRisk-Net）的集成城市洪水风险评估模型，该模型能够捕获空间依赖性和特征交互，将美国大都市统计区的洪水风险划分为六个不同的城市特定级别，并揭示了核心城市承担最高洪水风险的等级空间分布。

**AI_Comments:** 该论文的创新之处在于首次将无监督图深度学习应用于城市洪水风险评估，解决了传统方法在处理复杂特征交互和空间依赖性方面的局限。其重要性在于提供了一种更全面、可解释的风险评估工具，有助于城市规划者更好地理解和应对洪水风险的复杂性，尤其是在识别核心城市的高风险负担和探讨发展与风险平衡的挑战方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有城市洪水风险表征方法主要基于洪泛区地图，关注有限的特征，且未考虑特征交互或空间区域间的依赖关系，这导致无法充分捕捉由洪水灾害、暴露、社会和物理脆弱性以及复杂空间洪水依赖关系之间复杂非线性相互作用产生的城市洪水风险。

**Method:** 本研究提出了一种名为FloodRisk-Net的无监督图深度学习模型，用于构建集成城市洪水风险评估模型。该模型能够捕获区域间的空间依赖性以及洪水灾害和城市特征之间复杂非线性的交互作用，以确定新兴洪水风险。

**Result:** 模型将美国多个大都市统计区（MSAs）的洪水风险划分为六个不同的城市特定级别。该模型可解释，并能够对每个洪水风险级别内的区域进行特征分析，从而识别出在每个MSA中形成最高洪水风险的三种原型。研究发现，洪水风险在每个MSA内呈分层空间分布，其中核心城市不成比例地承担着最高的洪水风险。此外，发现多个城市具有高整体洪水风险水平和低空间不平等，这表明平衡城市发展和洪水风险降低的选择有限。

**Conclusion:** 该研究揭示了城市洪水风险在空间上的分层分布，核心城市承担最高风险，且一些城市在面临高整体洪水风险时，在平衡城市发展与风险降低方面选择有限。文章还讨论了相关的洪水风险降低策略。

> **ai_Abstract:** 本研究提出了一种名为FloodRisk-Net的无监督图深度学习模型，旨在解决现有洪水风险评估方法未能充分考虑特征交互和空间依赖性问题。该模型能够捕捉城市洪水风险中复杂的非线性相互作用和空间依赖性，并将美国大都市区的洪水风险划分为六个可解释的城市特定级别。研究发现洪水风险在城市内部呈现分层空间分布，核心城市承担最高风险，并识别出三种最高风险原型。结果表明，一些城市在面对高洪水风险时，在城市发展和风险降低之间平衡的选择有限。

> **摘要翻译:** 城市洪水风险源于洪水灾害、洪水暴露以及社会和物理脆弱性等多重特征之间复杂非线性的相互作用，以及复杂的空间洪水依赖关系。然而，现有表征城市洪水风险的方法主要基于洪泛区地图，侧重于有限的特征，主要是灾害和暴露特征，而没有考虑特征交互或空间区域之间的依赖关系。为了解决这一空白，本研究提出了一种基于新型无监督图深度学习模型（称为FloodRisk-Net）的集成城市洪水风险评估模型。FloodRisk-Net能够捕获区域间的空间依赖性以及洪水灾害和城市特征之间复杂非线性的交互作用，以确定新兴洪水风险。利用美国多个大都市统计区（MSAs）的数据，该模型将其洪水风险划分为六个不同的城市特定级别。该模型具有可解释性，并能对每个洪水风险级别内的区域进行特征分析，从而识别出在每个MSA中形成最高洪水风险的三种原型。研究发现，洪水风险在每个MSA内呈分层结构空间分布，其中核心城市不成比例地承担着最高的洪水风险。发现多个城市具有高整体洪水风险水平和低空间不平等，这表明平衡城市发展和洪水风险降低的选择有限。文章讨论了相关的洪水风险降低策略，考虑了最高洪水风险和洪水风险不均匀空间分布的形成方式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [690] [Probabilities of Chat LLMs Are Miscalibrated but Still Predict Correctness on Multiple-Choice Q&A](https://arxiv.org/abs/2402.13213)
> *聊天LLM的概率虽然校准不佳，但在多项选择问答中仍能预测正确性*

*Benjamin Plaut, Nguyen X. Khanh, Tu Trinh* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 概率校准, 多项选择问答, 最大softmax概率, 不确定性预测

**Comment:** 

> **TL;DR:** 研究发现，聊天LLM的最大softmax概率在多项选择问答中存在校准问题，但仍能有效预测答案的正确性，并且可以用于提高模型在选择弃权时的性能。

**AI_Comments:** 这篇论文揭示了当前大型语言模型在不确定性量化方面的一个重要且反直觉的发现：即使模型的概率校准不佳，其内部置信度（通过最大softmax概率体现）仍能有效指示答案的正确性。这一发现对于LLM在风险敏感应用中的部署具有重要意义，因为它提供了一种在不完美校准条件下仍能利用模型不确定性信息的方法。通过展示如何利用这一特性进行智能弃权，论文为提高LLM的实际应用性能提供了清晰的路径。其创新点在于区分了“正确性预测”与“校准”这两个概念，并指出在当前微调范式下，前者可能更容易随模型能力提升而改善。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探讨聊天大型语言模型（LLMs）的最大softmax概率（MSPs）是否编码了有用的不确定性信息，尽管它们在多项选择问答中存在校准不佳的问题。具体而言，假设错误答案会与较小的MSPs相关联。

**Method:** 研究了15个针对聊天进行微调的大型语言模型（LLMs）。通过严格的统计测试验证了错误答案与较小MSPs相关的假设。分析了问答准确性与MSP正确性预测之间的相关性，以及问答准确性与校准误差之间的相关性。还通过允许模型弃权来展示正确性预测的实用性，通过使用少量标记数据选择MSP阈值来提高性能。

**Result:** 发现15个聊天LLM的最大softmax概率（MSPs）在多项选择问答中始终校准不佳。然而，对于在基础问答任务上表现良好的模型，MSPs确实能预测答案的正确性（即错误答案与较小的MSPs相关联）。发现问答准确性与MSP正确性预测之间存在很强的正向相关性，但问答准确性与校准误差之间没有相关性。当模型可以选择弃权时，通过根据初始模型响应的MSP选择性弃权，可以使用少量标记数据来选择MSP阈值，从而提高性能。

**Conclusion:** 尽管聊天LLM的概率校准不佳，但其最大softmax概率（MSPs）仍然能够有效地预测答案的正确性。在当前的微调范式下，随着LLM能力的进步，可以预期正确性预测会提高，而校准不会。正确性预测具有实用性，可以用于通过弃权来提高模型性能。

> **ai_Abstract:** 本研究调查了15个聊天大型语言模型（LLMs）在多项选择问答任务中的概率校准问题。结果显示，尽管这些模型的最大softmax概率（MSPs）普遍存在校准不佳，但它们仍能有效预测答案的正确性：错误答案通常与较低的MSPs相关。研究发现，问答准确性与MSP的正确性预测之间存在强相关性，但与校准误差无关。这表明随着LLM能力的提升，正确性预测有望改善，但校准问题可能依然存在。此外，研究还展示了利用MSP进行正确性预测的实用性，即通过基于MSP选择性弃权，可以在仅使用少量标记数据的情况下提升模型性能。

> **摘要翻译:** 我们研究了15个针对聊天进行微调的大型语言模型（LLMs），发现它们的S大softmax概率（MSPs）在多项选择问答中始终校准不佳。然而，这些MSPs可能仍然编码了有用的不确定性信息。具体来说，我们假设错误答案会与较小的MSPs相关联，而正确答案则相反。通过严格的统计测试，我们表明这一假设对于在基础问答任务上表现良好的模型是成立的。我们还发现问答准确性与MSP正确性预测之间存在很强的方向相关性，而问答准确性与校准误差之间没有相关性。这表明在当前的微调范式下，随着LLM能力的进步，我们可以预期正确性预测会提高，但校准不会。为了证明正确性预测的实用性，我们展示了当模型可以选择弃权时，可以通过根据初始模型响应的MSP选择性弃权来提高性能，仅使用少量标记数据来选择MSP阈值。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [696] [A dataset of primary nasopharyngeal carcinoma MRI with multi-modalities segmentation](https://arxiv.org/abs/2404.03253)
> *原发性鼻咽癌多模态磁共振成像分割数据集*

*Yin Li, Qi Chen, Kai Wang, Meige Li, Liping Si, Yingwei Guo, Yu Xiong, Qixing Wang, Yang Qin, Ling Xu, Patrick van der Smagt, Jun Tang, Nutan Chen* | **Category: cs.AI, cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-06**

**Keywords:** 鼻咽癌, MRI, 数据集, 多模态, 分割

**Comment:** 

> **TL;DR:** 本研究发布了首个全面的原发性鼻咽癌多模态MRI数据集，包含277名患者的831次扫描，旨在解决现有公开数据集的不足，以促进鼻咽癌的诊断、治疗规划和机器学习算法开发。

**AI_Comments:** 该论文通过发布首个全面的鼻咽癌多模态MRI数据集，解决了该领域长期以来数据稀缺的关键问题。其创新之处在于数据集的规模（277名患者，831次扫描）以及包含多种模态、临床数据和专业医生手动标注的高质量分割，这对于促进鼻咽癌的早期诊断、精确分割和机器学习模型开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有公开、全面的鼻咽癌（NPC）多模态磁共振成像（MRI）数据集的缺乏，限制了鼻咽癌诊断、治疗规划以及机器学习算法开发的进展。

**Method:** 本研究构建并发布了首个全面的原发性鼻咽癌MRI数据集。

**Result:** 该数据集包含277名原发性鼻咽癌患者的MR轴位图像，共计831次扫描，涵盖T1加权、T2加权和对比增强T1加权序列。此外，数据集还包括相应的临床数据以及经验丰富的放射科医生手动标注和分割的高质量数据。

**Conclusion:** 该数据集为未经治疗的原发性鼻咽癌提供了高质量的数据资源，有望促进鼻咽癌的早期诊断、肿瘤分割和疾病分期等方面的研究和发展。

> **ai_Abstract:** 针对鼻咽癌（NPC）多模态MRI数据集稀缺的问题，本研究发布了首个全面的原发性鼻咽癌MRI数据集。该数据集包含277名患者的831次T1、T2和对比增强T1加权序列扫描，并附带临床数据和由经验丰富的放射科医生手动标注的高质量分割，旨在为鼻咽癌的诊断、治疗规划及机器学习算法开发提供重要的公共资源。

> **摘要翻译:** 多模态磁共振成像（MRI）数据有助于鼻咽癌（NPC）管理中的早期诊断、肿瘤分割和疾病分期。然而，缺乏公开可用的综合数据集限制了鼻咽癌诊断、治疗规划和机器学习算法开发的进展。为解决这一关键需求，我们推出了首个全面的鼻咽癌MRI数据集，涵盖277名原发性鼻咽癌患者的MR轴位成像。该数据集包括T1加权、T2加权和对比增强T1加权序列，共计831次扫描。除了相应的临床数据外，由经验丰富的放射科医生手动标注和标记的分割提供了未经治疗的原发性鼻咽癌的高质量数据资源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [702] [Understanding Large Language Model Behaviors through Interactive Counterfactual Generation and Analysis](https://arxiv.org/abs/2405.00708)
> *通过交互式反事实生成与分析理解大型语言模型行为*

*Furui Cheng, Vilém Zouhar, Robin Shing Moon Chan, Daniel Fürst, Hendrik Strobelt, Mennatallah El-Assady* | **Category: cs.AI, cs.CL, cs.HC, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 可解释性AI, 反事实分析, 交互式可视化, LLM Analyzer

**Comment:** 

> **TL;DR:** 提出LLM Analyzer，一个交互式可视化系统，通过反事实分析帮助用户更直观高效地理解大型语言模型行为，并强调人类主动参与解释过程的重要性。

**AI_Comments:** 这篇论文的创新点在于提出了一个交互式可视化系统LLM Analyzer，通过反事实分析方法解决了现有LLM可解释性方法的局限性，特别是其非交互性和与人类推理不符的问题。它强调了人类在解释过程中的主动参与，这对于提升LLM的透明度和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLM）的可解释人工智能（XAI）方法主要依赖于词级解释，这些解释通常计算效率低下且与人类推理过程不符。此外，这些方法通常将解释视为一次性输出，忽略了其固有的交互性和迭代性。

**Method:** 本文提出了LLM Analyzer，一个交互式可视化系统，通过反事实分析来探索LLM行为。该系统包含一个新颖的算法，通过在用户定义的粒度级别进行有针对性的删除和替换操作，生成流畅且语义有意义的反事实。这些反事实用于计算特征归因分数，并与具体示例整合在表格可视化中，以支持模型的动态分析。

**Result:** 对LLM从业者进行的用例研究和专家访谈表明，该系统具有可用性和有效性。

**Conclusion:** 理解大型语言模型行为对于确保其安全可靠使用至关重要。研究强调了在解释过程中将人类作为主动参与者而非被动接受者的重要性。

> **ai_Abstract:** 本文介绍了LLM Analyzer，一个交互式可视化系统，旨在解决现有大型语言模型（LLM）可解释性方法在效率、与人类推理对齐以及交互性方面的局限。该系统通过新颖的算法生成有意义的反事实，并结合特征归因分数和表格可视化，支持用户对LLM行为进行直观高效的动态探索。用户研究验证了其可用性和有效性，并强调了人类在解释过程中主动参与的重要性。

> **摘要翻译:** 理解大型语言模型（LLM）的行为对于确保其安全可靠使用至关重要。然而，现有的大型语言模型可解释人工智能（XAI）方法主要依赖于词级解释，这些解释通常计算效率低下，并且与人类推理过程不符。此外，这些方法通常将解释视为一次性输出，忽视了其固有的交互性和迭代性。在本文中，我们提出了LLM Analyzer，一个交互式可视化系统，通过反事实分析实现对LLM行为的直观高效探索，从而解决了这些局限性。我们的系统具有一种新颖的算法，通过在用户定义的粒度级别进行有针对性的删除和替换操作，生成流畅且语义有意义的反事实。这些反事实用于计算特征归因分数，然后与具体示例集成在表格可视化中，支持对模型行为的动态分析。对LLM从业者进行的用例研究和专家访谈证明了该系统的可用性和有效性，强调了在解释过程中让人类作为积极参与者而非被动接受者的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [708] [GTR: Improving Large 3D Reconstruction Models through Geometry and Texture Refinement](https://arxiv.org/abs/2406.05649)
> *GTR：通过几何和纹理优化改进大型3D重建模型*

*Peiye Zhuang, Songfang Han, Chaoyang Wang, Aliaksandr Siarohin, Jiaxu Zou, Michael Vasilkovsky, Vladislav Shakhrai, Sergey Korolev, Sergey Tulyakov, Hsin-Ying Lee* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** GTR, 3D重建, NeRF, 多视角图像, 纹理优化

**Comment:** 

> **TL;DR:** GTR提出了一种新颖的3D网格重建方法，通过对大型重建模型LRM进行几何和纹理优化，显著提升了重建质量，并在复杂纹理重建上取得了突破。

**AI_Comments:** GTR的创新点在于其对现有大型3D重建模型LRM的系统性改进，包括几何和纹理两个层面的细化。通过可微分的网格提取和渲染来监督几何，以及轻量级的逐实例纹纹理优化，有效地解决了高精度3D重建中的关键挑战，特别是复杂纹理的重建难题。其高效的纹理优化过程（仅4秒）和在SOTA性能上的表现，使其在实际应用中具有重要价值，并为未来的文本/图像到3D生成等应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型3D重建模型（如LRM）存在一些不足和局限性，特别是在3D重建质量和复杂纹理的重建方面。本文旨在通过引入重要修改来显著提升3D重建质量，并解决前馈模型难以重建复杂纹理的问题。

**Method:** 本文提出GTR方法，用于从多视角图像进行3D网格重建。该方法借鉴了LRM（基于Transformer的三平面生成器和NeRF模型），并进行了多项关键改进：1. 优化了LRM架构以改善多视角图像表示并提高训练计算效率。2. 以可微分的方式从NeRF场中提取网格，并通过网格渲染微调NeRF模型，以改善几何重建并实现全图像分辨率监督。3. 引入了轻量级的逐实例纹理优化程序，在网格表面上使用输入多视角图像微调三平面表示和NeRF颜色估计模型，以解决复杂纹理重建问题。

**Result:** 该方法在2D和3D评估指标上都达到了最先进的性能。在Google Scanned Objects (GSO) 数据集上，PSNR达到了28.67。通过纹理优化，PSNR进一步提升至29.79，并实现了对文本等复杂纹理的忠实重建。此外，纹理优化过程仅需4秒。该方法还支持文本到3D或图像到3D生成等多种下游应用。

**Conclusion:** GTR通过对大型3D重建模型进行几何和纹理上的多项关键改进，显著提升了3D重建质量，实现了最先进的性能，并有效解决了复杂纹理重建的难题。同时，该方法还支持多种下游应用。

> **ai_Abstract:** 本文提出GTR，一种用于从多视角图像进行3D网格重建的新方法。GTR通过改进现有的LRM架构，优化了多视角图像表示和训练效率，并通过可微分的网格提取和渲染微调NeRF模型来提升几何重建质量。此外，GTR引入了高效的逐实例纹理优化程序，解决了前馈模型难以处理复杂纹理的问题。实验结果表明，GTR在2D和3D指标上均达到最先进水平，显著提升了PSNR，并能忠实重建复杂纹理，同时支持多种下游应用。

> **摘要翻译:** 我们提出了一种从多视角图像进行3D网格重建的新颖方法。我们的方法借鉴了大型重建模型，如LRM，它使用基于Transformer的三平面生成器和在多视角图像上训练的神经辐射场（NeRF）模型。然而，在我们的方法中，我们引入了几项重要的修改，使我们能够显著提升3D重建质量。首先，我们审查了原始的LRM架构，并发现了一些缺点。随后，我们对LRM架构引入了相应的修改，这导致了改进的多视角图像表示和更具计算效率的训练。其次，为了改善几何重建并实现全图像分辨率的监督，我们以可微分的方式从NeRF场中提取网格，并通过网格渲染对NeRF模型进行微调。这些修改使我们能够在2D和3D评估指标上都达到最先进的性能，例如在Google Scanned Objects (GSO) 数据集上实现了28.67的PSNR。尽管取得了这些卓越的结果，我们的前馈模型在重建复杂纹理（例如资产上的文本和肖像）时仍然存在困难。为了解决这个问题，我们引入了一种轻量级的逐实例纹理优化程序。此程序在短短4秒内，使用输入的多视角图像在网格表面上微调三平面表示和NeRF颜色估计模型。此优化将PSNR提高到29.79，并实现了对文本等复杂纹理的忠实重建。此外，我们的方法还支持各种下游应用，包括文本到3D或图像到3D生成。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [714] [CrisisSense-LLM: Instruction Fine-Tuned Large Language Model for Multi-label Social Media Text Classification in Disaster Informatics](https://arxiv.org/abs/2406.15477)
> *CrisisSense-LLM：用于灾害信息学中多标签社交媒体文本分类的指令微调大型语言模型*

*Kai Yin, Bo Li, Chengkai Liu, Ali Mostafavi, Xia Hu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 指令微调, 多标签分类, 灾害信息学, 社交媒体文本分类

**Comment:** 

> **TL;DR:** 本研究通过指令微调大型语言模型（LLM），实现了灾害相关推文的多标签文本分类，以提升灾害情境感知能力。

**AI_Comments:** 这项研究的创新之处在于将指令微调的大型语言模型应用于灾害信息学中的多标签文本分类任务。它解决了传统单标签分类方法无法捕捉灾害社交媒体数据复杂性的局限性，通过同时识别多个灾害相关方面，显著提升了情境感知能力。该方法为利用LLM处理复杂、动态的灾害数据提供了新的思路，对于构建更智能、更高效的灾害管理工具具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 目前的危机/灾害信息学中文本分类工具大多依赖于单标签模型，无法捕获动态且多方面的灾害相关社交媒体数据中嵌入的不同见解。

**Method:** 本研究通过指令微调预训练的大型语言模型（LLM）来增强其能力，目标是实现灾害相关推文的多标签分类。具体方法包括：从灾害相关推文创建全面的指令数据集，然后使用该数据集对开源LLM进行微调，使其嵌入灾害特定知识。

**Result:** 结果表明，该方法增强了从社交媒体帖子中对关键信息的分类能力，从而有助于在紧急情况下更有效地部署以实现情境感知。

**Conclusion:** 这项研究为更先进、适应性更强、更稳健的灾害管理工具铺平了道路，利用大型语言模型的能力来改善灾害情景中的实时情境感知和响应策略。

> **ai_Abstract:** 本研究提出CrisisSense-LLM，一个通过指令微调的大型语言模型，用于灾害信息学中的多标签社交媒体文本分类。针对现有单标签模型无法处理灾害数据多面性的问题，作者构建了一个灾害相关推文的指令数据集，并用其微调开源LLM。该模型能够同时分类灾害事件类型、信息量和援助参与等多个方面，显著提升了社交媒体数据在灾害情境感知中的实用性，并被证明能有效增强关键信息的分类。

> **摘要翻译:** 在危机/灾害信息学领域，社交媒体正日益被用于改善情境感知，以指导响应和救援工作。高效准确的文本分类工具一直是危机信息学研究的重点领域。然而，目前的方法大多依赖于单标签文本分类模型，这未能捕获动态和多方面的灾害相关社交媒体数据中嵌入的不同见解。本研究引入了一种新的灾害文本分类方法，通过指令微调增强预训练的大型语言模型（LLM），目标是实现灾害相关推文的多标签分类。我们的方法涉及从灾害相关推文创建全面的指令数据集，然后用于微调一个开源LLM，从而使其嵌入灾害特定知识。这个微调模型可以同时分类灾害相关信息的多个方面，例如事件类型、信息量和人类援助的参与，显著提高了社交媒体数据在灾害情境感知中的实用性。结果表明，这种方法增强了从社交媒体帖子中对关键信息的分类能力，从而有助于在紧急情况下更有效地部署以实现情境感知。这项研究为更先进、适应性更强、更稳健的灾害管理工具铺平了道路，利用大型语言模型的能力来改善灾害情景中的实时情境感知和响应策略。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [720] [SincVAE: A new semi-supervised approach to improve anomaly detection on EEG data using SincNet and variational autoencoder](https://arxiv.org/abs/2406.17537)
> *SincVAE：一种使用SincNet和变分自编码器改进EEG数据异常检测的新型半监督方法*

*Andrea Pollastro, Francesco Isgrò, Roberto Prevete* | **Category: cs.AI, cs.LG, eess.SP** | **Updated: 2025-08-07**

**Keywords:** SincVAE, 半监督学习, 脑电图, 癫痫检测, 变分自编码器

**Comment:** 

> **TL;DR:** SincVAE是一种新的半监督深度学习方法，通过结合SincNet和VAE，提高了脑电图（EEG）数据上的癫痫发作检测能力，并能识别早期和晚期发作。

**AI_Comments:** SincVAE的创新之处在于将SincNet（通过学习带通滤波器进行特征提取）与变分自编码器结合，实现了半监督的异常检测。这种方法有效解决了癫痫EEG数据标注困难和数据不平衡的问题，并且通过在模型中集成滤波器学习，有望简化传统的预处理步骤，使其更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的监督机器学习方法在癫痫脑电图波形标注困难且数据（癫痫发作事件）稀有导致数据不平衡，从而影响预测性能。因此，需要一种能够避免这些问题的半监督方法。

**Method:** 本研究提出了一种名为SincVAE的半监督深度学习方法，用于从EEG数据中检测癫痫发作。SincVAE将自适应带通滤波器学习作为变分自编码器（VAE）的第一层，旨在消除识别和分离信息频带的预处理阶段。

**Result:** 结果表明，SincVAE改进了EEG数据中的癫痫发作检测，并且能够识别痫前期的早期癫痫发作以及在痫后期监测患者。

**Conclusion:** SincVAE是一种有效的半监督方法，可以改善EEG数据上的癫痫检测，并通过集成自适应带通滤波器学习简化了预处理过程。

> **ai_Abstract:** 本论文提出了一种名为SincVAE的半监督深度学习方法，用于改进EEG数据上的癫痫发作检测。鉴于传统监督方法在EEG数据标注困难和数据不平衡方面的挑战，SincVAE通过将自适应带通滤波器学习整合到变分自编码器（VAE）的第一层，旨在简化预处理流程并提高检测性能。实验结果表明，SincVAE能够有效地检测EEG数据中的癫痫发作，包括在痫前期和痫后期进行监测。

> **摘要翻译:** 在过去的几十年中，脑电图（EEG）监测已成为诊断神经系统疾病，特别是检测癫痫发作的关键工具。癫痫是全球最普遍的神经系统疾病之一，影响着大约1%的人口。这些患者面临着巨大的风险，这凸显了在日常生活中进行可靠、持续癫痫监测的必要性。文献中讨论的大多数技术都依赖于监督机器学习（ML）方法。然而，癫痫脑电图波形变异的准确标注挑战使得这些方法的使用变得复杂。此外，癫痫发作事件的稀有性导致数据内部高度不平衡，这可能导致监督学习方法的预测性能不佳。相反，半监督方法允许模型仅在不包含癫痫发作的数据上进行训练，从而避免了与数据不平衡相关的问题。这项工作提出了一种半监督方法，用于从EEG数据中检测癫痫发作，利用一种新颖的基于深度学习的方法，称为SincVAE。该提案将自适应带通滤波器阵列的学习作为变分自编码器（VAE）的第一层，这可能消除了识别和分离信息频带的预处理阶段。结果表明，SincVAE改进了EEG数据中的癫痫发作检测，并且能够识别痫前期的早期癫痫发作以及在痫后期监测患者。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [726] [StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation](https://arxiv.org/abs/2408.01343)
> *StitchFusion：编织任意视觉模态以增强多模态语义分割*

*Bingyu Li, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 多模态语义分割, 特征融合, 预训练模型, 多向适配器, StitchFusion

**Comment:** 

> **TL;DR:** 提出StitchFusion框架，通过集成预训练模型和引入多向适配器，实现任意视觉模态的灵活融合，以提升多模态语义分割性能，并达到SOTA效果，同时参数量很少。

**AI_Comments:** 这篇论文提出了一种新颖且高效的多模态融合方法，其创新点在于直接将大规模预训练模型作为编码器和融合器，并通过MultiAdapter实现编码阶段的跨模态信息集成。这种方法提高了输入模态的灵活性，同时显著减少了额外参数，实现了SOTA性能，对多模态语义分割领域具有重要意义。其模块化的设计也使得与现有融合模块的结合成为可能。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态语义分割方法通常采用针对特定模态的专用特征融合模块，导致输入灵活性受限且训练参数量增加。

**Method:** 提出StitchFusion框架，直接将大规模预训练模型作为编码器和特征融合器。该框架通过共享多模态视觉信息在编码阶段实现模态集成。引入了一个多向适配器模块（MultiAdapter），在编码过程中实现跨模态信息传输，并利用其在预训练编码器之间传播多尺度信息，以实现多模态视觉信息集成。

**Result:** 在四个多模态分割数据集上取得了最先进的性能，且仅增加了极少的参数。实验还表明MultiAdapter与现有特征融合模块（FFMs）具有互补性。

**Conclusion:** StitchFusion通过创新的模态融合方式，显著提升了多模态语义分割的性能，同时保持了参数效率和输入灵活性，证明了其在复杂场景应用中的潜力。

> **ai_Abstract:** 本文提出了StitchFusion，一个用于多模态语义分割的创新框架，旨在解决现有方法输入灵活性差和参数量大的问题。StitchFusion直接利用大规模预训练模型作为编码器和特征融合器，并通过引入多向适配器（MultiAdapter）在编码阶段实现高效的跨模态和多尺度信息融合。实验证明，StitchFusion在多个多模态分割数据集上达到了最先进的性能，且仅需少量额外参数，同时MultiAdapter与现有融合模块表现出良好的互补性，展现了其在复杂场景分割中的强大能力。

> **摘要翻译:** 多模态语义分割在提升复杂场景下的分割精度方面展现出巨大潜力。然而，现有方法通常采用针对特定模态的专用特征融合模块，从而限制了输入灵活性并增加了训练参数的数量。为了解决这些挑战，我们提出了StitchFusion，一个直接而有效的模态融合框架，它直接将大规模预训练模型集成作为编码器和特征融合器。这种方法促进了全面的多模态和多尺度特征融合，能够适应任何视觉模态输入。具体来说，我们的框架通过共享多模态视觉信息在编码过程中实现模态集成。为了增强跨模态信息交换，我们引入了一个多向适配器模块（MultiAdapter），以在编码过程中实现跨模态信息传输。通过利用MultiAdapter在编码过程中跨预训练编码器传播多尺度信息，StitchFusion在编码过程中实现了多模态视觉信息集成。广泛的对比实验表明，我们的模型在四个多模态分割数据集上以极少的额外参数实现了最先进的性能。此外，MultiAdapter与现有特征融合模块（FFMs）的实验集成突出了它们的互补性。我们的代码可在StitchFusion_repo获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [732] [CRAFT Your Dataset: Task-Specific Synthetic Dataset Generation Through Corpus Retrieval and Augmentation](https://arxiv.org/abs/2409.02098)
> *CRAFT Your Dataset：通过语料库检索和增强生成任务特定合成数据集*

*Ingo Ziegler, Abdullatif Köksal, Desmond Elliott, Hinrich Schütze* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 合成数据集,语料库检索,LLM增强,少样本学习,任务特定数据

**Comment:** 

> **TL;DR:** CRAFT是一种通过语料库检索和大型语言模型增强，从少量用户提供的示例中高效生成大规模任务特定合成数据集的方法，其性能优于通用LLM和现有合成数据生成方法。

**AI_Comments:** CRAFT的创新点在于结合了语料库检索和LLM增强，以少量人工示例为基础，高效生成大规模高质量的合成数据集，从而解决了构建专业数据集耗时耗力的问题。其重要性在于为LLM微调提供了新的数据生成范式，尤其适用于数据稀缺的专业领域。方法表现出对初始示例质量的鲁棒性，进一步提升了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为专业任务构建高质量数据集耗时、资源密集且常需领域知识。

**Method:** CRAFT方法：1. 接收少量用户编写的少样本示例。2. 利用大规模公共网络爬取语料库和基于相似度的文档检索来查找相关人工文档。3. 使用指令调优的大型语言模型（LLMs）将检索到的文档增强为自定义格式的任务样本，用于微调。

**Result:** CRAFT能高效生成生物学、医学、常识问答和摘要等四种任务的大规模训练数据集。在问答任务上，基于CRAFT的模型优于或匹配通用LLMs；在摘要任务上，比使用人工策划数据训练的模型高出46个偏好点。CRAFT优于Self-Instruct和Evol-Instruct等其他合成数据集生成方法，即使初始少样本质量有变，也保持稳健。

**Conclusion:** CRAFT提供了一种高效、稳健的方法来生成高质量的任务特定合成数据集，显著提升了LLM在特定任务上的表现，并优于现有合成数据生成技术。

> **ai_Abstract:** 本研究提出CRAFT（Corpus Retrieval and Augmentation for Fine-Tuning），一种高效生成任务特定合成数据集的方法。CRAFT利用少量用户提供的示例，通过检索大规模语料库中的相关文档，并使用指令调优的LLM进行增强，从而创建用于微调的自定义格式任务样本。实验证明，CRAFT能为多种任务生成大规模高质量数据集，其模型在问答任务上表现优异，在摘要任务上显著超越人工策划数据训练的模型，且性能优于其他合成数据生成方法，对初始少样本质量变化具有鲁棒性。

> **摘要翻译:** 构建高质量的专业任务数据集是一个耗时且资源密集的过程，通常需要专业的领域知识。我们提出了CRAFT（Corpus Retrieval and Augmentation for Fine-Tuning），这是一种生成合成数据集的方法，它只需要少量用户编写的、展示了待执行任务的少样本示例。给定这些示例，CRAFT利用大规模公共网络爬取语料库和基于相似度的文档检索来查找其他相关的人工编写文档。最后，经过指令调优的大型语言模型（LLMs）将检索到的文档增强为自定义格式的任务样本，这些样本随后可用于微调。我们证明了CRAFT可以有效地为四种不同任务生成大规模的任务特定训练数据集：生物学、医学和常识问答（QA），以及摘要。我们的实验表明，基于CRAFT的模型在问答任务上优于或匹配通用LLMs，而在摘要任务上，比使用人工策划数据训练的模型高出46个偏好点。CRAFT优于其他合成数据集生成方法，如Self-Instruct和Evol-Instruct，并且即使初始少样本的质量有所不同，也能保持稳健。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [738] [Medal Matters: Probing LLMs' Failure Cases Through Olympic Rankings](https://arxiv.org/abs/2409.06518)
> *奖牌很重要：通过奥运排名探究大型语言模型的失败案例*

*Juhwan Choi, Seunguk Yu, JungMin Yun, YoungBin Kim* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 知识结构, 奥运排名, 奖牌计数, 知识整合

**Comment:** 

> **TL;DR:** 本研究通过评估大型语言模型在奥运奖牌计数和排名任务上的表现，揭示了其内部知识整合的局限性，发现LLMs擅长记忆但难以进行排名。

**AI_Comments:** 本文通过一个具体且易于理解的案例（奥运奖牌数据）来深入探究大型语言模型的内部知识结构和局限性，特别是其在知识召回与知识整合（排名）能力上的差异。这一发现对于理解LLMs的认知机制及其在复杂推理任务中的挑战具有重要意义。同时，公开数据集和代码也有助于后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的内部知识结构仍未被充分理解，本研究旨在通过奥运奖牌数据来探究这些结构。

**Method:** 本研究通过历史奥运奖牌数据，评估了大型语言模型在两项任务上的表现：1) 检索特定团队的奖牌数量；2) 识别每个团队的排名。

**Result:** 最先进的大型语言模型在回忆奖牌数量方面表现出色，但在提供排名方面却举步维艰，这突显了其知识组织与人类推理之间的关键差异。

**Conclusion:** 这些发现揭示了大型语言模型内部知识整合的局限性，并为改进指明了方向。

> **ai_Abstract:** 本研究通过评估大型语言模型在奥运奖牌计数和排名任务上的表现，深入探究了其内部知识结构。研究发现，尽管LLMs在回忆具体的奖牌数量方面表现出色，但在对团队进行排名时却面临困难。这一结果揭示了LLMs在知识整合方面的局限性，并为未来改进提供了方向。为促进后续研究，作者还发布了代码、数据集和模型输出。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言处理任务中取得了显著成功，但其内部知识结构仍未被充分理解。本研究通过历史奥运奖牌统计数据，审视了这些结构，评估了LLMs在两项任务上的表现：(1) 检索特定团队的奖牌数量；(2) 识别每个团队的排名。虽然最先进的LLMs在回忆奖牌数量方面表现出色，但在提供排名方面却举步维艰，这突显了其知识组织与人类推理之间的关键差异。这些发现揭示了LLMs内部知识整合的局限性，并为改进指明了方向。为了促进进一步研究，我们发布了代码、数据集和模型输出。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [744] [MedHalu: Hallucinations in Responses to Healthcare Queries by Large Language Models](https://arxiv.org/abs/2409.19492)
> *MedHalu：大型语言模型在医疗健康查询回应中的幻觉*

*Vibhor Agarwal, Yiqiao Jin, Mohit Chandra, Munmun De Choudhury, Srijan Kumar, Nishanth Sastry* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 医疗健康, 幻觉, 基准, 专家在环

**Comment:** 

> **TL;DR:** 本研究引入了MedHalu基准和MedHaluDetect框架，开创性地研究了大型语言模型在真实医疗健康查询中产生幻觉的问题，发现LLM在检测幻觉方面表现不佳，但专家参与的方法能显著提高检测能力。

**AI_Comments:** 该论文的创新之处在于其开创性地关注了LLMs在“真实世界”医疗健康查询中的幻觉问题，而非仅仅是标准化考试。MedHalu基准和MedHaluDetect框架的提出，为评估和理解LLMs在医疗领域的风险提供了宝贵的工具。更重要的是，提出的“专家在环”方法为解决LLM幻觉问题提供了一个实用的、可行的方向，强调了人机协作在敏感领域的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在医疗健康等敏感领域容易产生幻觉，即生成看似合理但事实不准确的信息。现有研究主要关注LLMs在标准化医学考试中的知识表现，未能充分反映其在真实患者互动中的表现，因此需要一项开创性的研究来填补这一空白。

**Method:** 本研究引入了MedHalu，一个包含多样化健康主题和LLM幻觉回应的医学幻觉基准，并详细标注了幻觉类型和文本跨度。同时，提出了MedHaluDetect框架来评估LLM检测幻觉的能力。此外，研究还比较了医学专家、LLM和普通大众在识别医疗幻觉方面的能力，并提出了一种将专家推理整合到LLM输入中的“专家在环”方法以改善幻觉检测。

**Result:** 研究发现，大型语言模型在检测医疗幻觉方面显著不如人类专家，在某些情况下甚至不如普通大众。然而，通过引入“专家在环”方法，所有LLM的幻觉检测能力都得到了显著提升，其中GPT-4的macro-F1得分提高了6.3%。

**Conclusion:** 大型语言模型在医疗领域的幻觉问题非常严重，它们在检测自身幻觉方面的表现远低于人类。通过将专家知识融入LLM的输入中，可以显著提高其在医疗领域检测幻觉的能力，这表明人机协作是解决LLM幻觉问题的一个有效途径。

> **ai_Abstract:** 该研究开创性地调查了大型语言模型（LLMs）在回应真实世界医疗健康查询时产生的幻觉问题。为了解决现有医学知识测试未能充分捕捉实际互动表现的局限，作者构建了MedHalu，一个包含多种健康主题和LLM幻觉回应的医学幻觉基准，并详细标注了幻觉类型。同时，提出了MedHaluDetect框架来评估LLM的幻觉检测能力。研究发现，LLMs在检测医疗幻觉方面显著逊于人类专家，有时甚至不如普通人。为提升检测效果，研究提出了一种“专家在环”方法，将专家推理融入LLM输入，显著提高了LLM的幻觉检测能力，例如使GPT-4的macro-F1提高了6.3%。

> **摘要翻译:** 大型语言模型（LLMs）正开始补充传统的如网络搜索等信息获取机制。ChatGPT等由LLM驱动的聊天机器人正在大众中普及。AI聊天机器人也越来越多地在社交媒体平台上生成内容。然而，LLMs也容易产生幻觉，即生成看似合理但事实不准确或捏造的信息。当普通人开始寻求有关医疗保健等敏感问题的信息时，这成为了一个关键问题。现有关于医学领域LLM幻觉的研究主要集中通过标准化的医学考试问题来测试LLMs的医学知识，这些问题通常定义明确且答案清晰。然而，这些方法可能无法完全捕捉这些LLMs在与患者进行实际互动时的表现。这项工作对LLM生成的真实世界患者医疗保健查询回应中的幻觉进行了开创性研究。我们引入了MedHalu，一个新颖的医学幻觉基准，其特点是包含多样化的健康相关主题和LLMs产生的幻觉回应，并详细标注了幻觉类型和文本跨度。我们还提出了MedHaluDetect，一个评估LLMs检测幻觉能力的综合框架。此外，我们研究了医学专家、LLMs和普通大众这三组人对医疗幻觉的脆弱性。值得注意的是，LLMs在检测医疗幻觉方面显著不如人类专家，在某些情况下甚至不如普通大众。为了改善幻觉检测，我们提出了一种专家在环方法，将专家推理整合到LLM输入中，显著提高了所有LLMs的幻觉检测能力，包括GPT-4的macro-F1提高了6.3%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [749] [From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging](https://arxiv.org/abs/2410.01215)
> *从代码到正确性：通过分层调试弥补代码生成的最后一公里*

*Yuling Shi, Songsong Wang, Chengcheng Wan, Min Wang, Xiaodong Gu* | **Category: cs.AI, cs.CL, cs.PL, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 代码生成, 调试, 分层, 大型语言模型, 错误修复

**Comment:** 

> **TL;DR:** 大型语言模型生成的代码常有细微错误，本文提出MGDebugger，一个分层代码调试器，通过分解代码并自下而上修复不同粒度的错误，显著提高了代码修复成功率。

**AI_Comments:** 本文提出了一种新颖的分层调试范式，通过将复杂代码分解为可管理的子功能并逐步调试，有效解决了现有LLM调试系统无法处理多粒度错误的问题。其引入的LLM模拟Python执行器是关键创新，提升了错误定位的准确性。这对于提高LLM在复杂代码生成任务中的实用性具有重要意义，是代码生成“最后一公里”的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在代码生成方面取得进展，但生成的代码通过率受限于细微错误，尤其对于复杂问题，常需人工干预。现有基于LLM的调试系统将程序视为整体，无法处理从低级语法到高级算法缺陷等多个粒度级别的错误，这成为代码生成通过率的瓶颈。

**Method:** 本文引入了Multi-Granularity Debugger (MGDebugger)，一个分层代码调试器。MGDebugger通过将问题代码分解为子函数的分层树结构，每个级别代表特定粒度的错误。在调试过程中，它分析每个子函数并以自下而上的方式迭代解决错误。为了有效测试每个子函数，提出了一种LLM模拟的Python执行器，该执行器跟踪代码执行并追踪重要的变量状态以精确定位错误。

**Result:** 广泛的实验表明，MGDebugger优于现有调试系统，在HumanEval中比种子生成提高了18.9%的准确率，在HumanEvalFix中达到了97.6%的修复成功率。此外，MGDebugger有效修复了不同类别和难度级别的错误，展示了其鲁棒性和有效性。

**Conclusion:** MGDebugger通过其独特的分层调试方法，显著提升了大型语言模型生成代码的调试能力，有效解决了多粒度错误问题，并在实验中展现出卓越的性能和鲁棒性。

> **ai_Abstract:** 本文介绍了Multi-Granularity Debugger (MGDebugger)，一个创新的分层代码调试系统，旨在解决大型语言模型生成代码中存在的细微错误。MGDebugger通过将代码分解为分层结构，并结合LLM模拟的Python执行器，能够自下而上地识别和修复从语法到算法层面的多粒度错误。实验证明，MGDebugger在准确率和修复成功率方面显著优于现有系统，有效提升了代码生成的正确性。

> **摘要翻译:** 虽然大型语言模型在代码生成方面取得了显著进展，但生成代码的通过率受限于细微错误，尤其对于复杂问题，通常需要人工干预才能通过测试。现有的基于LLM的调试系统将生成的程序视为整体单元，未能解决从低级语法错误到高级算法缺陷等多个粒度级别的错误。在本文中，我们引入了多粒度调试器（MGDebugger），一个分层代码调试器，通过在不同粒度级别上隔离、识别和解决错误。MGDebugger将问题代码分解为子函数的分层树结构，每个级别代表特定粒度的错误。在调试过程中，它分析每个子函数并以自下而上的方式迭代解决错误。为了有效测试每个子函数，我们提出了一个LLM模拟的Python执行器，它跟踪代码执行并跟踪重要的变量状态以精确定位错误。广泛的实验表明，MGDebugger优于现有调试系统，在HumanEval中比种子生成提高了18.9%的准确率，在HumanEvalFix中达到了97.6%的修复成功率。此外，MGDebugger有效修复了不同类别和难度级别的错误，展示了其鲁棒性和有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [754] [DisCoRD: Discrete Tokens to Continuous Motion via Rectified Flow Decoding](https://arxiv.org/abs/2411.19527)
> *DisCoRD：通过整流流解码实现从离散标记到连续运动的转换*

*Jungbin Cho, Junwan Kim, Jisoo Kim, Minseo Kim, Mingu Kang, Sungeun Hong, Tae-Hyun Oh, Youngjae Yu* | **Category: cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 运动生成, 离散标记, 连续运动, 整流流, DisCoRD

**Comment:** 

> **TL;DR:** DisCoRD是一种新颖的方法，它利用整流流将离散运动标记解码为连续、自然的运动，解决了离散和连续运动表示之间的矛盾，并实现了最先进的性能。

**AI_Comments:** DisCoRD的创新之处在于其引入整流流解码器，有效地将离散运动标记转换为高质量的连续运动，解决了现有离散和连续方法各自的局限性。它提供了一个通用的解决方案，可以集成到任何基于离散的框架中，显著提升了运动生成的自然度和真实感，同时保持了对条件信号的忠实性，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 人类运动的连续性和动态性给生成模型带来了挑战。离散生成方法存在表达能力有限和逐帧噪声伪影的问题，而连续方法虽然产生更平滑的运动，但由于高维复杂性和有限的训练数据，难以遵循条件信号。

**Method:** DisCoRD（Discrete Tokens to Continuous Motion via Rectified Flow Decoding）通过利用整流流在连续原始运动空间中解码离散运动标记来解决离散和连续表示之间的“不和谐”。其核心思想是将标记解码构建为条件生成任务，以确保捕获细粒度动态并实现更平滑、更自然的运动。该方法与任何基于离散的框架兼容。

**Result:** DisCoRD在HumanML3D上实现了0.032的FID，在KIT-ML上实现了0.169的FID，达到了最先进的性能。这些结果表明DisCoRD是弥合离散效率和连续真实感之间鸿沟的强大解决方案。

**Conclusion:** DisCoRD成功地弥合了离散运动生成方法的效率与连续方法提供的真实感之间的差距，通过其整流流解码机制实现了高质量、自然的运动。

> **ai_Abstract:** DisCoRD是一种新颖的运动生成方法，旨在解决离散和连续运动表示之间的矛盾。它利用整流流将离散运动标记解码为连续的原始运动空间中的运动，并将此过程视为条件生成任务。该方法能够生成更平滑、更自然的运动，同时保持对条件信号的忠实性。DisCoRD与现有离散框架兼容，并在HumanML3D和KIT-ML数据集上取得了最先进的性能，有效弥合了离散方法的效率与连续方法的真实感之间的差距。

> **摘要翻译:** 人类运动本质上是连续和动态的，这对生成模型构成了重大挑战。虽然离散生成方法被广泛使用，但它们存在表达能力有限和逐帧噪声伪影的问题。相反，连续方法产生更平滑、更自然的运动，但由于高维复杂性和有限的训练数据，通常难以遵循条件信号。为了解决离散和连续表示之间的这种“不和谐”，我们引入了DisCoRD：通过整流流解码实现从离散标记到连续运动的转换，这是一种利用整流流在连续原始运动空间中解码离散运动标记的新颖方法。我们的核心思想是将标记解码构建为条件生成任务，确保DisCoRD捕获细粒度动态并实现更平滑、更自然的运动。我们的方法与任何基于离散的框架兼容，在不损害对各种设置下条件信号的忠实性的情况下增强了自然度。广泛的评估表明，DisCoRD实现了最先进的性能，在HumanML3D上FID为0.032，在KIT-ML上为0.169。这些结果确立了DisCoRD作为弥合离散效率和连续真实感之间鸿沟的强大解决方案。项目网站：https://whwjdqls.github.io/discord-motion/

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [759] [PL-DCP: A Pairwise Learning framework with Domain and Class Prototypes for EEG emotion recognition under unseen target conditions](https://arxiv.org/abs/2412.00082)
> *PL-DCP：一种基于域和类别原型的成对学习框架，用于不可见目标条件下的脑电图情感识别*

*Guangli Li, Canbiao Wu, Zhehao Zhou, Tuo Sun, Ping Tan, Li Zhang, Zhen Liang* | **Category: cs.AI, cs.HC, cs.LG, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 脑电图情感识别, 成对学习, 域原型, 类别原型, 特征解耦

**Comment:** 

> **TL;DR:** PL-DCP是一种新的脑电图情感识别框架，它通过特征解耦、域和类别原型以及成对学习策略，解决了现有深度迁移学习方法对源域和目标域的双重依赖和标签噪声问题，在目标域完全不可见的情况下仍能达到SOTA性能。

**AI_Comments:** PL-DCP的创新之处在于其结合了特征解耦、双重原型（域原型和类别原型）以及成对学习策略，以解决脑电图情感识别中跨域泛化和标签噪声的难题。特别是在目标域完全不可见的情况下仍能取得良好性能，这对于实际应用中的跨个体或跨会话情感识别具有重要意义。其提出的域原型和类别原型概念，有效地分离了个体特异性和情感共性，提高了模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于深度迁移学习的情感识别方法面临模型对源域和目标域的双重依赖以及受标签噪声影响的挑战，这严重影响了模型的性能和泛化能力。

**Method:** 本文提出了PL-DCP（Pairwise Learning framework with Domain and Category Prototypes）框架，该框架集成了特征解耦和原型推理概念。特征解耦模块提取并解耦情感脑电图特征，形成域特征和类别特征，并计算双重原型表示。域原型捕捉受试者间的个体差异，而类别原型捕捉情感类别的跨个体共性。此外，成对学习策略有效减少了错误标签引起的噪声影响。

**Result:** PL-DCP框架在SEED、SEED-IV和SEED-V数据集上进行了系统实验评估，准确率分别为82.88%、65.15%和61.29%。结果表明，尽管目标域在训练期间完全不可见，PL-DCP模型仍然比需要源域和目标域数据的深度迁移学习方法取得了略好的性能，优于其他SOTA方法。

**Conclusion:** 这项工作为情感识别提供了一个有效且鲁棒的潜在解决方案。

> **ai_Abstract:** 本文提出了一种名为PL-DCP的成对学习框架，用于在目标域不可见的情况下进行脑电图情感识别。该框架旨在解决现有深度迁移学习方法在EEG情感识别中面临的源域和目标域双重依赖以及标签噪声问题。PL-DCP通过特征解耦模块分离出域特征和类别特征，并生成相应的原型，其中域原型捕获个体差异，类别原型捕获情感共性。此外，它采用成对学习策略以降低错误标签的影响。实验结果显示，PL-DCP在SEED、SEED-IV和SEED-V数据集上的准确率分别为82.88%、65.15%和61.29%，即使在目标域完全不可见的情况下，其性能也优于需要源域和目标域数据的SOTA深度迁移学习方法，证明了其有效性和鲁棒性。

> **摘要翻译:** 脑电图（EEG）信号是情感脑机接口（aBCI）中的强大工具，在情感计算中发挥着关键作用。近年来，深度学习技术的引入显著推动了aBCI的发展。然而，目前基于深度迁移学习的情感识别方法面临模型对源域和目标域双重依赖的挑战，同时受标签噪声影响，这严重影响了模型的性能和泛化能力。为了克服这一限制，我们提出了一个用于不可见目标条件下的脑电图情感识别的基于域和类别原型的成对学习框架（PL-DCP），并整合了特征解耦和原型推理的概念。其中，特征解耦模块提取并解耦情感脑电图特征，形成域特征和类别特征，并进一步计算双重原型表示。域原型捕捉受试者间的个体差异，而类别原型捕捉情感类别的跨个体共性。此外，成对学习策略有效减少了错误标签引起的噪声影响。PL-DCP框架在已发布的SEED、SEED-IV和SEED-V数据集上进行了系统实验评估，准确率分别为82.88%、65.15%和61.29%。结果表明，与其它最先进（SOTA）方法相比，尽管目标域在训练期间完全不可见，PL-DCP模型仍然比需要源域和目标域数据的深度迁移学习方法取得了略好的性能。这项工作为情感识别提供了一个有效且鲁棒的潜在解决方案。源代码可在https://github.com/WuCB-BCI/PL_DCP获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [764] [TokenFlow: Unified Image Tokenizer for Multimodal Understanding and Generation](https://arxiv.org/abs/2412.03069)
> *TokenFlow：用于多模态理解和生成的统一图像分词器*

*Liao Qu, Huichao Zhang, Yiheng Liu, Xu Wang, Yi Jiang, Yiming Gao, Hu Ye, Daniel K. Du, Zehuan Yuan, Xinglong Wu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 图像分词器, 多模态理解, 多模态生成, 双码本架构, 向量量化

**Comment:** 

> **TL;DR:** TokenFlow 是一种新型统一图像分词器，通过创新的双码本架构弥合了多模态理解和生成之间的差距，并在理解、重建和生成任务中取得了卓越性能。

**AI_Comments:** TokenFlow 的创新点在于其双码本架构，巧妙地解决了多模态理解和生成对视觉信息不同粒度需求的矛盾，通过共享映射机制实现了两种特征的协同作用。这对于统一多模态任务具有重要意义，尤其是在离散视觉输入超越连续表示方面展示了巨大潜力。该研究为未来统一多模态模型的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究尝试使用单一的重建导向的向量量化 (VQ) 编码器来统一多模态理解和生成任务，但理解和生成对视觉信息的需求粒度根本不同，这导致了关键的权衡，尤其是在多模态理解任务中损害了性能。

**Method:** TokenFlow 通过创新的双码本架构解决了这一挑战，该架构解耦了语义和像素级特征学习，同时通过共享映射机制保持了它们的对齐。这种设计使得通过共享索引可以直接访问对理解任务至关重要的高级语义表示和对生成必不可少的细粒度视觉特征。

**Result:** TokenFlow 在理解性能上首次超越了 LLaVA-1.5 13B，平均提升了 7.2%。在图像重建方面，在 384*384 分辨率下实现了 0.63 的强大 FID 分数。此外，TokenFlow 在 256*256 分辨率下以 0.55 的 GenEval 分数在自回归图像生成方面达到了最先进的性能，实现了与 SDXL 相当的结果。

**Conclusion:** TokenFlow 有效地弥合了多模态理解和生成之间的长期差距，并通过其独特的双码本架构在理解、图像重建和自回归图像生成方面均取得了显著的、甚至是最先进的性能。

> **ai_Abstract:** TokenFlow 提出了一种统一的图像分词器，旨在解决多模态理解和生成任务之间由于视觉信息粒度需求不同而产生的性能权衡问题。通过引入创新的双码本架构，TokenFlow 能够解耦并对齐语义和像素级特征学习，从而同时支持高层理解和细粒度生成。实验证明，TokenFlow 在理解任务中超越了现有模型，并在图像重建和自回归图像生成方面取得了领先或与最先进模型相当的性能。

> **摘要翻译:** 我们提出了 TokenFlow，这是一种新颖的统一图像分词器，它弥合了多模态理解和生成之间长期存在的鸿沟。先前的研究试图采用单一的以重建为目标的向量量化 (VQ) 编码器来统一这两个任务。我们观察到，理解和生成需要根本不同粒度的视觉信息。这导致了一个关键的权衡，尤其是在多模态理解任务中损害了性能。TokenFlow 通过创新的双码本架构解决了这一挑战，该架构解耦了语义和像素级特征学习，同时通过共享映射机制保持了它们的对齐。这种设计使得通过共享索引可以直接访问对理解任务至关重要的高级语义表示和对生成必不可少的细粒度视觉特征。我们的大量实验表明 TokenFlow 在多个维度上都表现出卓越性。利用 TokenFlow，我们首次证明离散视觉输入在理解性能上可以超越 LLaVA-1.5 13B，实现了 7.2% 的平均提升。对于图像重建，我们在 384*384 分辨率下实现了 0.63 的强大 FID 分数。此外，TokenFlow 在 256*256 分辨率下以 0.55 的 GenEval 分数在自回归图像生成方面建立了最先进的性能，实现了与 SDXL 相当的结果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [769] [GuARD: Effective Anomaly Detection through a Text-Rich and Graph-Informed Language Model](https://arxiv.org/abs/2412.03930)
> *GuARD：通过文本丰富和图信息语言模型实现有效异常检测*

*Yunhe Pang, Bo Chen, Fanjin Zhang, Yanghui Rao, Evgeny Kharlamov, Jie Tang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 异常检测, 语言模型, 图神经网络, 文本丰富图, 指令微调

**Comment:** 

> **TL;DR:** GuARD是一个结合文本和图结构信息的语言模型，用于文本丰富图上的异常检测，性能优于现有方法且速度更快。

**AI_Comments:** GuARD的创新之处在于其将文本丰富信息与图结构信息有机结合，弥补了现有大语言模型在处理图结构数据时忽视结构偏置的局限性。通过引入小型语言模型来提取细粒度语义属性，有效降低了传统LLM微调的高昂成本。此外，其在训练和推理速度上实现的显著提升，尤其是在大规模数据集上的表现，预示着该方法在实际应用中具有巨大的潜力和效率优势。

<details>
  <summary>Details</summary>

**Motivation:** 在文本丰富图上进行异常检测（如识别学术论文作者分配不正确、社交网络中的机器人）非常普遍。大语言模型（LLM）利用丰富的文本信息为有效异常检测提供了新途径，但简单地将丰富文本引入LLMs会模糊关键检测线索并引入高昂的微调成本。此外，LLMs常忽略对区分正常和异常节点模式至关重要的图内在结构偏置。

**Method:** 本文提出了GuARD，一个文本丰富且图信息感知的语言模型，它将基于图方法的关键结构特征与通过小型语言模型提取的细粒度语义属性相结合，用于文本丰富图上的有效异常检测。GuARD通过渐进式多模态多轮指令微调框架进行优化，该框架在任务引导的指令微调机制下，旨在整合丰富的文本和结构模态。

**Result:** 在四个数据集上的大量实验表明，GuARD优于基于图和基于LLM的异常检测方法，同时在大规模WhoIsWho数据集上，其训练速度比普通长上下文LLM快5倍，推理速度也快5倍。

**Conclusion:** GuARD在文本丰富图上的异常检测中表现出卓越的性能和效率，通过结合图结构和文本语义信息，有效解决了现有LLM的局限性，并显著提升了训练和推理速度。

> **ai_Abstract:** 本文提出了GuARD，一个用于文本丰富图异常检测的语言模型。它巧妙地结合了图结构的关键特征和通过小型语言模型提取的细粒度文本语义信息，旨在解决现有大语言模型在处理此类任务时面临的挑战，如信息模糊和高成本。GuARD通过渐进式多模态多轮指令微调框架进行优化。实验结果表明，GuARD在多个数据集上均超越了传统的图基和LLM基异常检测方法，并且在训练和推理速度上实现了显著提升，尤其是在大规模数据集上可达5倍加速。

> **摘要翻译:** 文本丰富图上的异常检测在现实生活中广泛存在，例如检测学术论文作者分配不正确以及社交网络中的机器人。大语言模型（LLM）卓越的能力为利用丰富的文本信息进行有效异常检测开辟了新的途径。然而，简单地将丰富文本引入LLMs会模糊关键检测线索并引入高昂的微调成本。此外，LLMs常忽视对区分正常和异常节点模式至关重要的图内在结构偏置。为此，本文引入了GuARD，一个文本丰富且图信息感知的语言模型，它将基于图方法的关键结构特征与通过小型语言模型提取的细粒度语义属性相结合，用于文本丰富图上的有效异常检测。GuARD通过渐进式多模态多轮指令微调框架进行优化，该框架在任务引导的指令微调机制下，旨在整合丰富的文本和结构模态。在四个数据集上的大量实验表明，GuARD优于基于图和基于LLM的异常检测方法，同时在大规模WhoIsWho数据集上，其训练速度比普通长上下文LLM快5倍，推理速度也快5倍。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [774] [AnomalyControl: Learning Cross-modal Semantic Features for Controllable Anomaly Synthesis](https://arxiv.org/abs/2412.06510)
> *AnomalyControl：学习跨模态语义特征实现可控异常合成*

*Shidan He, Lei Liu, Xiujun Shu, Bo Wang, Yuanhao Feng, Shen Zhao* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 异常合成, 跨模态语义特征, 文本到图像生成, AnomalyControl, 细粒度特征

**Comment:** 

> **TL;DR:** AnomalyControl是一个新的异常合成框架，通过学习跨模态语义特征来提高生成异常样本的真实感和可控性，解决了现有方法在捕捉细粒度异常特征方面的不足。

**AI_Comments:** AnomalyControl 的创新之处在于其引入了跨模态语义特征作为异常合成的指导信号，并设计了CSM、ASEA和SGA等模块来有效处理细粒度异常特征，从而显著提升了合成异常样本的真实感和可控性。这对于异常检测领域中数据增强的需求具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像异常合成方法主要依赖文本信息或粗略对齐的视觉特征，难以捕捉真实异常的复杂特性（如细粒度视觉模式），这限制了生成过程的真实性和泛化能力。

**Method:** 本文提出AnomalyControl框架，旨在学习跨模态语义特征作为指导信号，以提高合成异常样本的真实感。该框架采用灵活的非匹配提示对（文本-图像参考提示和目标文本提示）。具体包括：1. 跨模态语义建模（CSM）模块：从文本和视觉描述符中提取跨模态语义特征。2. 异常语义增强注意力（ASEA）机制：使CSM专注于异常的特定视觉模式，增强生成异常特征的真实性和上下文相关性。3. 语义引导适配器（SGA）：将跨模态语义特征作为先验，编码有效的引导信号，实现充分和可控的合成过程。

**Result:** AnomalyControl在异常合成方面取得了最先进的结果，并且在下游任务中表现出卓越的性能。

**Conclusion:** AnomalyControl通过学习和利用跨模态语义特征，有效解决了现有异常合成方法在真实性和泛化能力上的局限性，实现了更真实、更可控的异常样本合成，并在实验中证明了其优越性。

> **ai_Abstract:** 本文提出了 AnomalyControl，一个新颖的异常合成框架，旨在解决现有文本到图像异常合成方法在捕捉细粒度异常特征和生成真实感样本方面的不足。AnomalyControl 通过学习跨模态语义特征作为指导信号，并利用灵活的文本-图像参考提示和目标文本提示对。它包含跨模态语义建模（CSM）模块、异常语义增强注意力（ASEA）机制和语义引导适配器（SGA）来提取、聚焦并编码有效的引导信号。实验证明 AnomalyControl 在异常合成和下游任务中均达到了最先进的性能。

> **摘要翻译:** 异常合成是增强异常数据以推进异常检测的关键方法。基于大规模预训练的知识，现有的文本到图像异常合成方法主要侧重于文本信息或粗略对齐的视觉特征来指导整个生成过程。然而，这些方法通常缺乏足够的描述符来捕捉真实异常的复杂特征（例如，异常的细粒度视觉模式），这限制了生成过程的真实性和泛化能力。为此，我们提出了一种新颖的异常合成框架，名为 AnomalyControl，用于学习跨模态语义特征作为指导信号，该信号可以从文本-图像参考提示中编码广义异常线索，并提高合成异常样本的真实感。具体来说，AnomalyControl 采用灵活且非匹配的提示对（即，文本-图像参考提示和目标文本提示），其中设计了一个跨模态语义建模（CSM）模块，用于从文本和视觉描述符中提取跨模态语义特征。然后，制定了异常语义增强注意力（ASEA）机制，以允许 CSM 专注于异常的特定视觉模式，从而增强生成异常特征的真实性和上下文相关性。将跨模态语义特征视为先验，设计了一个语义引导适配器（SGA）来编码有效的引导信号，以实现充分和可控的合成过程。大量实验表明，与现有方法相比，AnomalyControl 在异常合成方面取得了最先进的结果，同时在下游任务中表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [778] [Rationale-guided Prompting for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2412.16936)
> *基于推理指导的知识型视觉问答提示*

*Zhongjian Hu, Peng Yang, Bing Li, Fengyuan Liu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 知识型视觉问答, 大型语言模型, 思维链, 推理启发式, PLRH

**Comment:** 

> **TL;DR:** PLRH框架通过提示LLM生成推理启发式（中间思维过程），然后利用这些启发式来预测答案，从而在知识型视觉问答中表现优于现有基线。

**AI_Comments:** 该论文的创新点在于引入了“推理启发式”作为LLM进行知识型VQA的中间思维过程，通过CoT提示激活LLM的深层能力，弥补了以往方法直接预测答案的不足。这种方法对于提升LLM在复杂推理任务上的表现具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）在知识型视觉问答（VQA）中的应用，直接提示LLMs预测答案，忽略了中间思维过程，未能充分激活LLMs的能力。

**Method:** 本文提出了一个名为PLRH的框架，用于知识型VQA。PLRH通过思维链（CoT）提示LLMs生成推理启发式（即中间思维过程），然后利用这些推理启发式来激发LLMs预测答案。

**Result:** 该方法在OK-VQA和A-OKVQA数据集上分别比现有基线提高了超过2.2和2.1。

**Conclusion:** 通过引入推理启发式作为中间思维过程，PLRH框架能够更有效地利用大型语言模型的能力，显著提升知识型视觉问答的性能。

> **ai_Abstract:** 本文提出了一种名为PLRH的框架，用于知识型视觉问答。与直接预测答案的传统方法不同，PLRH通过思维链（CoT）提示大型语言模型（LLMs）生成中间推理启发式，并利用这些启发式来指导答案预测。实验结果显示，PLRH在OK-VQA和A-OKVQA数据集上均显著优于现有基线。

> **摘要翻译:** 最近，大型语言模型（LLMs）已被用于知识型视觉问答（VQA）。尽管先前研究取得了令人鼓舞的结果，但以前的方法直接提示LLMs预测答案，忽略了中间思维过程。我们认为以前的方法未能充分激活LLMs的能力。我们提出了一个名为PLRH的框架，该框架通过推理启发式提示LLMs进行知识型VQA。PLRH使用思维链（CoT）提示LLMs生成推理启发式（即中间思维过程），然后利用这些推理启发式来激发LLMs预测答案。实验表明，我们的方法在OK-VQA和A-OKVQA上分别优于现有基线超过2.2和2.1。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [784] [PromptDresser: Improving the Quality and Controllability of Virtual Try-On via Generative Textual Prompt and Prompt-aware Mask](https://arxiv.org/abs/2412.16978)
> *PromptDresser：通过生成式文本提示和提示感知掩码提高虚拟试穿的质量和可控性*

*Jeongho Kim, Hoiyeong Jin, Sunghyun Park, Jaegul Choo* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 虚拟试穿, 文本到图像扩散模型, 大型多模态模型, 文本可编辑, 提示感知掩码

**Comment:** 

> **TL;DR:** PromptDresser利用生成式文本提示和提示感知掩码，结合大型多模态模型（LMM），实现了高质量、文本可编辑的虚拟试穿，并显著优于现有基线方法。

**AI_Comments:** 这篇论文通过将文本提示与大型多模态模型（LMM）深度结合，为虚拟试穿领域带来了创新。利用LMM生成详细描述以及引入提示感知掩码是其核心创新点，有效解决了传统图像中心方法在可控性和真实感方面的局限性。这推动了文本到图像扩散模型在虚拟试穿应用中的发展。

<details>
  <summary>Details</summary>

**Motivation:** 当前虚拟试穿方法对文本提示的利用不足，且在文本可编辑虚拟试穿任务中面临挑战，包括难以设计丰富的文本描述、现有衣物文本信息干扰新衣物生成以及难以自适应调整修补掩码以确保编辑区域。

**Method:** 本文提出了PromptDresser，一个文本可编辑的虚拟试穿模型。该模型利用大型多模态模型（LMM）通过上下文学习，独立地为人物和服装图像生成详细的文本描述（包括姿态和编辑属性），并根据文本提示自适应地调整修补掩码，以确保正确的编辑区域。

**Result:** PromptDresser提升了文本可编辑性，有效传达了仅通过图像难以捕获的服装细节，提高了图像质量。实验表明，PromptDresser显著优于基线模型，展示了卓越的文本驱动控制能力和多功能服装操作能力。

**Conclusion:** PromptDresser通过利用大型多模态模型和自适应掩码，成功解决了文本可编辑虚拟试穿中的关键挑战，从而实现了更高质量和更强的控制能力。

> **ai_Abstract:** PromptDresser是一个创新的文本可编辑虚拟试穿模型，旨在解决现有方法中文本提示利用不足以及文本编辑挑战。它通过利用大型多模态模型（LMM）生成详细的人物和服装文本描述，并根据这些描述自适应调整修补掩码，从而实现对穿着风格和服装细节的高质量文本驱动控制。实验证明，该方法在图像质量、文本可编辑性和服装操作方面均显著优于现有基线。

> **摘要翻译:** 最近的虚拟试穿方法通过微调预训练的文本到图像扩散模型，利用其强大的生成能力取得了进展。然而，文本提示在虚拟试穿中的使用仍未得到充分探索。本文解决了一项文本可编辑的虚拟试穿任务，该任务在根据提供的服装图像修改服装的同时，根据文本描述编辑穿着风格（例如，塞入方式、合身度）。在文本可编辑的虚拟试穿中，存在三个关键方面：(i) 为配对的人物-服装数据设计丰富的文本描述以训练模型，(ii) 解决现有人物服装的文本信息干扰新服装生成的问题，以及 (iii) 自适应地调整与文本描述对齐的修补掩码，确保正确的编辑区域，同时保留与新服装无关的原始人物外观。为了解决这些方面，我们提出了PromptDresser，一个文本可编辑的虚拟试穿模型，它利用大型多模态模型（LMM）的辅助，通过生成式文本提示实现高质量和多功能的操作。我们的方法通过上下文学习利用LMM，以最小的人力成本独立地为人物和服装图像生成详细的文本描述，包括姿态细节和编辑属性。此外，为了确保编辑区域，我们根据文本提示自适应地调整修补掩码。我们的方法增强了文本可编辑性，同时有效传达了仅通过图像难以捕获的服装细节，从而提高了图像质量。实验表明，PromptDresser显著优于基线模型，展示了卓越的文本驱动控制和多功能服装操作。我们的代码可在 https://github.com/rlawjdghek/PromptDresser 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [789] [Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2412.18351)
> *基于大语言模型的多智能体用于知识型视觉问答*

*Zhongjian Hu, Peng Yang, Bing Li, Zhenqi Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 视觉问答, 多智能体, 工具使用, 团队协作

**Comment:** 

> **TL;DR:** 本文提出了一种基于大语言模型的多智能体投票框架，通过模拟人类使用工具和协作的方式，解决了现有知识型视觉问答方法在自主工具使用和团队协作方面的不足，并在OK-VQA和A-OKVQA数据集上取得了优于基线模型的结果。

**AI_Comments:** 本文的创新点在于将人类的工具使用和团队协作行为引入到LLM驱动的VQA系统中，通过多智能体协作和投票机制，有效地提升了模型的性能。这种模拟真实世界团队协作的方式，为LLM在复杂任务中的应用提供了新的思路，具有较好的实用性和扩展潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在知识型视觉问答中面临两大挑战：一是无法自主使用外部工具，二是无法进行团队协作。受人类在遇到问题时会根据需要使用工具并与他人协作的启发，本文旨在解决这些问题。

**Method:** 本文提出了一个多智能体投票框架。该框架设计了三个基于LLM的智能体，模拟团队中不同级别的员工，并根据级别分配可用的工具。每个智能体提供相应的答案，最终通过对所有智能体提供的答案进行投票以获得最终答案。

**Result:** 在OK-VQA和A-OKVQA数据集上的实验表明，本文提出的方法分别比其他基线方法提高了2.2和1.0的性能。

**Conclusion:** 本文提出的基于大语言模型的多智能体投票框架，通过模拟人类的工具使用和团队协作行为，有效提升了知识型视觉问答的性能。

> **ai_Abstract:** 本文提出了一种新颖的基于大语言模型的多智能体投票框架，旨在解决现有知识型视觉问答方法在自主工具使用和团队协作方面的不足。该框架通过设计模拟不同级别员工的LLM智能体，并按级别分配工具，使每个智能体提供答案，最终通过投票机制整合所有答案。实验结果表明，该方法在OK-VQA和A-OKVQA数据集上均优于现有基线。

> **摘要翻译:** 大型语言模型（LLMs）在知识型视觉问答（VQA）方面取得了令人印象深刻的成果。然而，现有方法仍然面临挑战：无法自主使用外部工具，以及无法进行团队协作。人类在遇到新问题时倾向于知道是否需要使用外部工具，例如，他们倾向于直接回答熟悉的问题，而遇到不熟悉的问题时则倾向于使用搜索引擎等工具。此外，人类也倾向于与他人协作和讨论以获得更好的答案。受此启发，我们提出了多智能体投票框架。我们设计了三个基于LLM的智能体，模拟团队中不同级别的员工，并根据级别分配可用的工具。每个智能体提供相应的答案，最终所有智能体提供的答案通过投票获得最终答案。在OK-VQA和A-OKVQA上的实验表明，我们的方法分别比其他基线方法提高了2.2和1.0。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [796] [Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes](https://arxiv.org/abs/2501.12106)
> *开源大型语言模型能否用于德国的肿瘤文件记录？——对泌尿科医生笔记的评估*

*Stefan Lenz, Arsenij Ustjanzew, Marco Jeray, Meike Ressing, Torsten Panholzer* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-07**

**Keywords:** 开源大型语言模型, 肿瘤文件记录, 医疗NLP, 泌尿科医生笔记, 性能评估

**Comment:** 

> **TL;DR:** 本研究评估了开源大型语言模型在德国肿瘤文件记录中的应用潜力，发现7-120亿参数的模型在性能和资源效率之间达到了最佳平衡，表明通过微调和精心设计的提示，这些模型有望成为临床文档的重要工具。

**AI_Comments:** 该论文通过对不同参数规模的开源LLMs在特定医学文档任务上的评估，展示了其在自动化肿瘤文件记录方面的巨大潜力。创新之处在于其构建了德语泌尿科医生笔记的真实数据集，并系统地测试了多种开源模型及提示策略。研究还指出了模型规模与性能之间的平衡点，为实际应用提供了有价值的指导。其发布的德语医学NLP数据集弥补了该领域基准资源的不足，具有重要意义。未来，如何进一步提升模型在复杂医学文本理解和生成方面的准确性，以及如何确保数据隐私和安全性，将是值得关注的方向。

<details>
  <summary>Details</summary>

**Motivation:** 德国的肿瘤文件记录主要依靠人工完成，需要阅读患者记录并手动输入数据到结构化数据库中，效率低下且可能存在错误。大型语言模型（LLMs）有望通过提高效率和可靠性来改进这一过程。

**Method:** 本研究评估了11种参数量从10亿到700亿不等的开源大型语言模型，针对肿瘤文件记录过程中的三个基本任务：识别肿瘤诊断、分配ICD-10编码和提取首次诊断日期。为此，研究人员基于匿名的泌尿科医生笔记准备了一个带注释的文本片段数据集。使用了不同的提示策略来探究少量样本提示中示例数量的影响，并探索LLMs的通用能力。

**Result:** Llama 3.1 8B、Mistral 7B和Mistral NeMo 12 B模型在各项任务中表现相当。训练数据较少或参数少于70亿的模型表现明显较差，而更大的模型并未显示出性能提升。使用来自泌尿科以外的其他医学领域的示例也能改善少量样本提示的结果，这表明LLMs能够处理肿瘤文件记录所需的任务。开源LLMs在自动化肿瘤文件记录方面显示出巨大潜力。

**Conclusion:** 开源大型语言模型在自动化肿瘤文件记录方面显示出强大潜力。参数量在70亿到120亿之间的模型可以在性能和资源效率之间提供最佳平衡。通过量身定制的微调和精心设计的提示，这些模型未来可能成为临床文档的重要工具。

> **ai_Abstract:** 本研究评估了开源大型语言模型（LLMs）在德国肿瘤文件记录自动化中的应用潜力。通过对11个开源LLM在识别肿瘤诊断、ICD-10编码和提取首次诊断日期三项任务上的表现进行测试，发现Llama 3.1 8B、Mistral 7B和Mistral NeMo 12 B表现良好，且70亿至120亿参数的模型在性能与资源效率间达到最佳平衡。研究还指出，跨领域示例有助于提升少量样本提示的效果。结果表明，开源LLMs在未来通过微调和优化提示，有望成为临床文档的重要工具，并为此发布了相关数据集和代码。

> **摘要翻译:** 德国的肿瘤文件记录主要通过人工完成，需要阅读患者记录并将数据输入结构化数据库。大型语言模型（LLMs）有可能通过提高效率和可靠性来增强这一过程。本评估测试了11种不同的开源LLM，其模型参数范围从10亿到700亿，涉及肿瘤文件记录过程的三个基本任务：识别肿瘤诊断、分配ICD-10编码和提取首次诊断日期。为了评估LLM在这些任务上的表现，研究人员准备了一个基于匿名的泌尿科医生笔记的带注释文本片段数据集。使用了不同的提示策略来调查少量样本提示中示例数量的影响，并探索LLM的通用能力。Llama 3.1 8B、Mistral 7B和Mistral NeMo 12 B模型在任务中表现相当。训练数据较少或参数少于70亿的模型表现明显较差，而更大的模型并未显示出性能提升。来自泌尿科以外的其他医学领域的示例也能改善少量样本提示的结果，这表明LLM能够处理肿瘤文件记录所需的任务。开源LLM在自动化肿瘤文件记录方面显示出强大潜力。参数量在70亿到120亿之间的模型可以在性能和资源效率之间提供最佳平衡。通过量身定制的微调和精心设计的提示，这些模型未来可能成为临床文档的重要工具。评估代码可在https://github.com/stefan-m-lenz/UroLlmEval获取。我们还将数据集作为一个新的宝贵资源发布，以解决德语医学自然语言处理领域中真实且易于访问的基准数据集短缺的问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [799] [MetaOcc: Spatio-Temporal Fusion of Surround-View 4D Radar and Camera for 3D Occupancy Prediction with Dual Training Strategies](https://arxiv.org/abs/2501.15384)
> *MetaOcc: 环视4D雷达与相机时空融合的双训练策略3D占用预测*

*Long Yang, Lianqing Zheng, Wenjin Ai, Minghao Liu, Sen Li, Qunshu Lin, Shengyu Yan, Jie Bai, Zhixiong Ma, Tao Huang, Xichan Zhu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D 占用预测, 4D 雷达, 多模态融合, 半监督学习, 自动驾驶

**Comment:** 

> **TL;DR:** MetaOcc是一个多模态框架，结合4D雷达和相机进行3D占用预测，通过创新的模块和半监督学习策略，在恶劣天气下表现出色并降低标注成本。

**AI_Comments:** MetaOcc的创新点在于其针对4D雷达数据特性设计的雷达高度自注意力模块，以及有效融合异构传感器数据的分层多尺度多模态融合策略。此外，其提出的半监督学习策略显著降低了对昂贵点云标注的依赖，使得该方法更具实际应用价值。这对于在恶劣天气下提升自动驾驶系统的感知能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶需要鲁棒的3D占用预测，尤其是在传统视觉系统表现不佳的恶劣天气下。融合环视4D雷达和相机是一种有前景的低成本解决方案，但有效提取和整合异构传感器特征仍具挑战。此外，昂贵的点云标注也是一个问题。

**Method:** 本文提出了MetaOcc，一个利用多视角4D雷达和图像进行全向3D占用预测的多模态框架。它包括：1. 雷达高度自注意力模块，用于增强垂直空间推理和特征提取，解决直接将LiDAR编码器应用于稀疏雷达数据的问题。2. 分层多尺度多模态融合策略，用于跨模态和时间执行自适应的局部-全局融合，以缓解时空错位并丰富融合的特征表示。3. 基于开放集分割器的伪标签生成管道，实现半监督训练策略，仅使用50%的真值标签即可达到全监督性能的90%，从而降低对昂贵点云标注的依赖。

**Result:** 全监督下，MetaOcc在OmniHD-Scenes数据集上SC IoU提升0.47，mIoU提升4.02。在SurroundOcc-nuScenes数据集上SC IoU提升1.16，mIoU提升1.24。半监督策略仅使用50%的真值标签即可达到全监督性能的90%。实验证明MetaOcc在传感器域和训练条件下都具有可扩展性和鲁棒性。

**Conclusion:** MetaOcc通过融合4D雷达和相机，并结合创新的特征提取与融合策略以及高效的半监督训练方法，实现了3D占用预测的最新性能，并有效降低了标注成本，为自动驾驶系统的实际部署奠定了基础。

> **ai_Abstract:** 本文提出了MetaOcc，一个创新的多模态框架，用于结合环视4D雷达和相机进行鲁棒的3D占用预测，特别针对恶劣天气条件。该框架引入了雷达高度自注意力模块以优化雷达特征提取，并设计了分层多尺度多模态融合策略来解决跨模态和时空错位问题。为降低标注成本，MetaOcc还提出了一种基于伪标签生成的半监督训练策略。实验结果表明，MetaOcc在全监督下取得了最先进的性能，并且其半监督方法在减少标注需求的同时保持了高精度，展示了其在实际自动驾驶应用中的潜力和鲁棒性。

> **摘要翻译:** 鲁棒的3D占用预测对自动驾驶至关重要，尤其是在传统纯视觉系统难以应对的恶劣天气条件下。虽然环视4D雷达和相机的融合提供了一种有前景的低成本解决方案，但有效提取和整合这些异构传感器的特征仍然具有挑战性。本文介绍了MetaOcc，一个新颖的多模态框架，利用多视角4D雷达和图像进行全向3D占用预测。为了解决将LiDAR导向的编码器直接应用于稀疏雷达数据的局限性，我们提出了一个雷达高度自注意力模块，以增强垂直空间推理和特征提取。此外，还开发了一种分层多尺度多模态融合策略，用于跨模态和时间执行自适应的局部-全局融合，从而缓解时空错位并丰富融合的特征表示。为了减少对昂贵点云标注的依赖，我们进一步提出了一个基于开放集分割器的伪标签生成管道。这使得半监督策略能够仅使用50%的真值标签就达到全监督性能的90%，在标注成本和准确性之间提供了有效的权衡。广泛的实验表明，MetaOcc在全监督下实现了最先进的性能，在OmniHD-Scenes数据集上分别比以前的方法高出+0.47 SC IoU和+4.02 mIoU，在SurroundOcc-nuScenes数据集上分别高出+1.16 SC IoU和+1.24 mIoU。这些结果证明了MetaOcc在传感器域和训练条件下的可扩展性和鲁棒性，为在现实世界自动驾驶系统中的实际部署铺平了道路。代码和数据可在https://github.com/LucasYang567/MetaOcc 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [804] [Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries](https://arxiv.org/abs/2502.10154)
> *视频配乐生成：情感与时间边界对齐*

*Serkan Sulun, Paula Viana, Matthew E. P. Davies* | **Category: cs.AI, cs.LG, cs.MM, cs.SD, eess.AS, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 视频配乐生成, 情感对齐, 时间边界, 符号音乐, MIDI生成

**Comment:** 

> **TL;DR:** EMSYNC是一个视频音乐生成模型，通过对齐视频情感和时间边界（如场景切换）来生成配乐，且在主观测试中优于现有模型。

**AI_Comments:** EMSYNC的创新之处在于引入了“边界偏移”这一新颖的时间条件机制，能够精确对齐音乐与视频的场景切换，并保留了事件编码以实现细粒度的音乐控制和表现力。同时，它解决了离散情感类别与连续情感输入之间的映射问题。该模型在主观评估中显著优于现有模型，显示出其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频配乐生成模型可能无法很好地对齐视频的情感内容和时间边界，或缺乏细粒度的时序控制和音乐表现力。该研究旨在提出一个能解决这些问题的模型。

**Method:** 提出EMSYNC模型，采用两阶段框架：首先，预训练的视频情感分类器提取情感特征；然后，条件音乐生成器根据情感和时间线索生成MIDI序列。引入了“边界偏移”作为新颖的时间条件机制，使模型能预测并将音乐和弦与场景切换对齐。与现有模型不同，EMSYNC保留了事件编码，以实现精细的时序控制和音乐表现力。此外，还提出了一个映射方案，以连接输出离散情感类别的视频情感分类器和接受连续效价-唤醒输入的MIDI生成器。

**Result:** 在主观听力测试中，EMSYNC在所有主观指标上均优于最先进的模型，无论是对音乐理论有了解的参与者还是普通听众。

**Conclusion:** EMSYNC模型通过有效对齐视频情感和时间边界，并采用创新的时间条件机制和事件编码，能够生成高质量的视频配乐，并在用户感知上显著优于现有技术。

> **ai_Abstract:** 本文提出了EMSYNC，一个用于视频配乐生成的符号音乐模型。该模型采用两阶段框架，利用预训练情感分类器提取视频情感，并结合新颖的边界偏移时间条件机制，使音乐与视频的情感和场景切换精确对齐。EMSYNC还保留了事件编码以实现精细控制，并设计了情感映射方案。主观听力测试结果表明，EMSYNC在生成高质量配乐方面优于现有最先进模型。

> **摘要翻译:** 我们引入了EMSYNC，一个基于视频的符号音乐生成模型，它将音乐与视频的情感内容和时间边界对齐。它遵循一个两阶段框架，其中一个预训练的视频情感分类器提取情感特征，一个条件音乐生成器在情感和时间线索的引导下生成MIDI序列。我们引入了边界偏移，这是一种新颖的时间条件机制，使模型能够预测并将音乐和弦与场景切换对齐。与现有模型不同，我们的方法保留了基于事件的编码，确保了细粒度的时间控制和富有表现力的音乐细微差别。我们还提出了一种映射方案，以连接产生离散情感类别的视频情感分类器和在连续效价-唤醒输入上操作的情感条件MIDI生成器。在主观听力测试中，EMSYNC在所有主观指标上均优于最先进的模型，无论是对音乐理论有了解的参与者还是普通听众。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [809] [RLTHF: Targeted Human Feedback for LLM Alignment](https://arxiv.org/abs/2502.13417)
> *RLTHF：面向LLM对齐的靶向人工反馈*

*Yifei Xu, Tusher Chakraborty, Emre Kıcıman, Bibek Aryal, Eduardo Rodrigues, Srinagesh Sharma, Roberto Estevao, Maria Angels de Luis Balaguer, Jessica Wolk, Rafael Padilha, Leonardo Nunes, Shobana Balakrishnan, Songwu Lu, Ranveer Chandra* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** LLM对齐, 人工反馈, RLHF, 成本效益, 人机混合

**Comment:** 

> **TL;DR:** RLTHF是一个人机混合框架，它通过选择性地使用少量人工标注来高效地将大型语言模型与用户偏好对齐，显著减少了人工标注成本，同时实现了与全人工标注相当甚至更优的性能。

**AI_Comments:** 本文提出了一种新颖且高效的LLM对齐方法，其创新点在于将人工反馈的重点放在LLM难以处理的“硬样本”上，从而大幅降低了高质量人工标注的成本。这种靶向的人工反馈机制有效解决了现有RLHF方法在成本和AI反馈在泛化性上的局限性，对推动LLM的实际应用具有重要意义。其在下游任务上的优异表现进一步证明了该方法的有效性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 微调大型语言模型（LLMs）以使其与用户偏好对齐具有挑战性，主要原因在于强化学习中人工反馈（RLHF）高质量人工标注的成本高昂，以及AI反馈在泛化能力上的局限性。

**Method:** RLTHF是一个人机混合框架，它结合了基于LLM的初始对齐与选择性的人工标注，以最小的努力实现与全人工标注相当的对齐效果。该方法通过奖励模型的奖励分布识别出LLM错误标注的难以标注样本，并利用LLM正确标注的样本，通过整合战略性的人工修正来迭代增强对齐。

**Result:** 在HH-RLHF和TL;DR数据集上的评估表明，RLTHF仅需6-7%的人工标注工作量即可达到全人工标注水平的对齐效果。此外，使用RLTHF精选数据集训练的模型在下游任务上的表现优于使用完全人工标注数据集训练的模型。

**Conclusion:** RLTHF能够以极少的标注成本实现与全人工标注相当或更优的LLM对齐效果，证明了其在解决LLM对齐中人工标注成本高昂和AI反馈泛化性限制问题上的有效性。

> **ai_Abstract:** RLTHF是一个创新的人机混合框架，旨在解决大型语言模型（LLMs）对齐中人工反馈（RLHF）成本高昂和AI反馈泛化性不足的问题。该框架通过结合LLM的初步对齐和选择性的人工标注，利用奖励模型识别出LLM难以处理的样本进行人工修正，从而以极少的人工投入（仅6-7%）达到与全人工标注相当甚至更优的对齐效果。实验结果验证了RLTHF在提高LLM对齐效率和性能方面的显著优势。

> **摘要翻译:** 微调大型语言模型（LLMs）以使其与用户偏好对齐具有挑战性，主要原因在于强化学习中人工反馈（RLHF）高质量人工标注的成本高昂，以及AI反馈在泛化能力上的局限性。为了应对这些挑战，我们提出了RLTHF，一个结合了基于LLM的初始对齐与选择性人工标注的人机混合框架，以最小的努力实现与全人工标注相当的对齐效果。RLTHF利用奖励模型的奖励分布识别出LLM错误标注的难以标注样本，并通过整合战略性的人工修正来迭代增强对齐，同时充分利用LLM正确标注的样本。在HH-RLHF和TL;DR数据集上的评估表明，RLTHF仅需6-7%的人工标注工作量即可达到全人工标注水平的对齐效果。此外，使用RLTHF精选数据集训练的模型在下游任务上的表现优于使用完全人工标注数据集训练的模型，这突显了RLTHF的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [814] [Text2VDM: Text to Vector Displacement Maps for Expressive and Interactive 3D Sculpting](https://arxiv.org/abs/2502.20045)
> *Text2VDM：文本到矢量置换贴图，用于富有表现力和交互性的3D雕刻*

*Hengyu Meng, Duotun Wang, Zhijing Shao, Ligang Liu, Zeyu Wang* | **Category: cs.AI, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 矢量置换贴图, 文本到VDM, 3D雕刻, 分数蒸馏采样, 雕刻笔刷

**Comment:** 

> **TL;DR:** Text2VDM是一个新颖的框架，通过文本提示生成高质量的矢量置换贴图（VDM）雕刻笔刷，解决了现有方法在生成子对象结构方面的挑战，并支持与主流3D软件集成。

**AI_Comments:** Text2VDM的创新之处在于其将文本生成能力应用于矢量置换贴图（VDM）的生成，特别是在解决传统SDS在生成特定子对象结构时的“语义耦合”问题上。通过引入加权混合的提示词元，它显著提高了生成笔刷的语义准确性和质量。该方法的重要性在于其为3D艺术家提供了一种全新的、高效的工具来创建和定制雕刻笔刷，极大地简化了专业3D资产创建的复杂性，并为实时交互式建模提供了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 专业的3D资产创建需要多样化的雕刻笔刷来添加表面细节和几何结构，但生成与艺术家工作流程兼容的可重用雕刻笔刷（通常表示为矢量置换贴图VDMs）仍然是一个开放且具有挑战性的问题，现有模型难以生成VDMs。

**Method:** 本文提出了Text2VDM，一个通过分数蒸馏采样（SDS）引导密集平面网格变形来实现文本到VDM笔刷生成的新颖框架。针对原始SDS损失在生成子对象结构时的“语义耦合”问题，Text2VDM引入了提示词元加权混合到SDS中，以实现更准确的目标分布和语义指导。

**Result:** 实验表明，Text2VDM能够生成多样化、高质量的VDM笔刷，用于雕刻表面细节和几何结构。生成的笔刷可以无缝集成到主流建模软件中，支持网格风格化和实时交互式建模等多种应用。

**Conclusion:** Text2VDM成功地解决了文本到VDM笔刷生成中的挑战，能够生成高质量、多样化的雕刻笔刷，并与现有3D工作流程兼容，极大地提升了3D资产创建的效率和表现力。

> **ai_Abstract:** Text2VDM是一个创新的文本到矢量置换贴图（VDM）生成框架，旨在解决3D雕刻笔刷生成中的挑战。该方法通过分数蒸馏采样（SDS）引导平面网格变形，并引入提示词元加权混合来解决SDS在生成子对象结构时的语义耦合问题。Text2VDM能够生成多样化、高质量的VDM笔刷，这些笔刷可以无缝集成到主流3D建模软件中，支持高效且富有表现力的3D雕刻和多种应用，如网格风格化和实时交互式建模。

> **摘要翻译:** 专业3D资产创建通常需要多样化的雕刻笔刷来添加表面细节和几何结构。尽管3D生成最近取得了进展，但生成与艺术家工作流程兼容的可重用雕刻笔刷仍然是一个开放且具有挑战性的问题。这些雕刻笔刷通常表示为矢量置换贴图（VDMs），与自然图像相比，现有模型难以轻松生成。本文提出了Text2VDM，一个通过分数蒸馏采样（SDS）引导密集平面网格变形来实现文本到VDM笔刷生成的新颖框架。原始的SDS损失设计用于生成完整对象，在笔刷生成中从头开始生成所需子对象结构时存在困难。我们将此问题称为语义耦合，通过引入提示词元的加权混合到SDS中来解决，从而实现更准确的目标分布和语义指导。实验表明，Text2VDM能够生成多样化、高质量的VDM笔刷，用于雕刻表面细节和几何结构。我们生成的笔刷可以无缝集成到主流建模软件中，支持网格风格化和实时交互式建模等多种应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [819] [Semantic Integrity Constraints: Declarative Guardrails for AI-Augmented Data Processing Systems](https://arxiv.org/abs/2503.00600)
> *语义完整性约束：AI增强数据处理系统的声明式护栏*

*Alexander W. Lee, Justin Chan, Michael Fu, Nicolas Kim, Akshay Mehta, Deepti Raghavan, Ugur Cetintemel* | **Category: cs.AI, cs.CL, cs.DB** | **Updated: 2025-08-07**

**Keywords:** 语义完整性约束, AI增强数据处理系统, 大型语言模型, 可靠性, 数据质量

**Comment:** 

> **TL;DR:** 引入语义完整性约束（SICs）作为声明式护栏，以提高AI增强数据处理系统中使用LLM的可靠性。

**AI_Comments:** 这篇论文通过引入语义完整性约束（SICs），为提高AI增强数据处理系统（特别是涉及LLM的系统）的可靠性提供了一个创新性的解决方案。它将传统数据库的完整性概念扩展到语义层面，为LLM的输出提供了“护栏”，这对于LLM在关键领域的应用至关重要。其声明式特性和对反应式/主动式策略的支持也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** AI增强数据处理系统（DPSs）中大型语言模型（LLMs）可能产生错误，导致系统可靠性（信任度）受挑战，限制了其在关键领域的应用。

**Method:** 引入语义完整性约束（SICs），这是一种声明式抽象，用于指定和强制执行LLM输出的正确性条件。SICs泛化了传统数据库完整性约束，支持接地、健全性和排除等常见约束类型，并提供反应式和主动式强制策略。提出了一个将SICs集成到查询规划和运行时执行中的系统设计。

**Result:** 提出了SICs作为构建可靠和可审计的AI增强数据系统的基础。概述了多个设计目标（表达能力、运行时语义、集成、性能、企业级适用性），并讨论了SICs框架如何解决这些目标。

**Conclusion:** SICs为构建可靠和可审计的AI增强数据系统提供了基础。

> **ai_Abstract:** 这篇论文引入了语义完整性约束（SICs），旨在解决AI增强数据处理系统中大型语言模型（LLMs）可能引入错误导致的可靠性问题。SICs作为一种声明式抽象，能够为LLM的输出定义和强制执行正确性条件，泛化了传统数据库约束。论文提出了将SICs集成到查询规划和执行中的系统设计，并阐述了SICs如何为构建可靠和可审计的AI增强数据系统奠定基础，同时考虑了表达能力、性能和企业级应用等设计目标。

> **摘要翻译:** AI增强数据处理系统（DPSs）将大型语言模型（LLMs）集成到查询管道中，从而对结构化和非结构化数据进行强大的语义操作。然而，这些系统的可靠性（即信任度）受到LLM可能产生错误的根本挑战，这限制了它们在关键领域的采用。为了帮助解决这一可靠性瓶颈，我们引入了语义完整性约束（SICs）——一种声明式抽象，用于在语义查询中指定和强制执行LLM输出的正确性条件。SICs将传统数据库完整性约束泛化到语义设置中，支持接地、健全性和排除等常见类型的约束，并采用反应式和主动式强制策略。
我们认为SICs为构建可靠和可审计的AI增强数据系统提供了基础。具体来说，我们提出了一个将SICs集成到查询规划和运行时执行中的系统设计，并讨论了其在AI增强DPSs中的实现。为了指导和评估我们的愿景，我们概述了几个设计目标——涵盖表达能力、运行时语义、集成、性能和企业级适用性等标准——并讨论了我们的框架如何解决这些目标，以及开放的研究挑战。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [824] [GNN-Enhanced Fault Diagnosis Method for Parallel Cyber-physical Attacks in Power Grids](https://arxiv.org/abs/2503.05797)
> *电网中并行网络物理攻击的GNN增强型故障诊断方法*

*Junhao Ren, Kai Zhao, Guangxiao Zhang, Xinghua Liu, Chao Zhai, Gaoxi Xiao* | **Category: cs.AI, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 网络物理攻击, 故障诊断, 电网, 图神经网络, 混合整数规划

**Comment:** 

> **TL;DR:** 本文提出了一种结合图注意力网络（GAT）和元混合整数规划（MMIP）的故障诊断框架，用于检测电网中的并行网络物理攻击，并估计攻击位置、大小及重建系统状态。

**AI_Comments:** 本文创新性地结合了图神经网络（GAT）的概率预测能力和混合整数规划（MMIP）的优化求解能力，解决了电网中复杂的并行网络物理攻击的故障诊断问题。这种混合模型能够同时处理物理损坏和数据阻塞，并精确估计攻击参数和重建系统状态，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 并行网络物理攻击（PCPA）同时破坏电网中的物理输电线路并阻塞测量数据传输，从而损害或延迟系统保护和恢复。本文旨在解决PCPA下线性化（直流）潮流模型的故障诊断问题，其物理攻击机制不仅包括线路断开，还包括导纳修改。

**Method:** 本文提出了一种基于元混合整数规划（MMIP）的故障诊断框架，并集成了基于图注意力网络（GAT）的故障定位（GAT-FL）。首先，推导了测量重建条件，允许从可用测量和系统拓扑中重建受攻击区域的未知测量。然后，基于这些条件将诊断任务表述为MMIP模型。GAT-FL预测潜在物理攻击的概率分布，并将其作为目标系数纳入MMIP中。求解MMIP可获得最优攻击位置和幅值估计，并从中重建系统状态。

**Result:** 实验仿真在IEEE 30/118总线标准测试案例上进行，结果表明所提出的故障诊断算法是有效的，能够获得最优的攻击位置和幅值估计，并重建系统状态。

**Conclusion:** 本文成功开发并验证了一种GNN增强型MMIP框架，用于诊断电网中复杂的并行网络物理攻击，能够定位攻击并重建系统状态。

> **ai_Abstract:** 本文针对电网中同时破坏物理线路和阻塞数据传输的并行网络物理攻击（PCPA），提出了一种GNN增强型故障诊断方法。该方法基于元混合整数规划（MMIP）框架，并结合了图注意力网络（GAT）进行故障定位。通过推导测量重建条件，将诊断问题建模为MMIP，并利用GAT预测的攻击概率作为MMIP的系数。该方法能够有效识别攻击位置和幅值，并重建系统状态，已在IEEE标准测试案例上验证其有效性。

> **摘要翻译:** 并行网络物理攻击（PCPA）同时破坏电网中的物理输电线路并阻塞测量数据传输，从而损害或延迟系统保护和恢复。本文研究了PCPA下线性化（直流）潮流模型的故障诊断问题。物理攻击机制不仅包括线路断开，还包括导纳修改，例如通过受损的分布式柔性交流输电系统（D-FACTS）设备。为了解决这个问题，我们提出了一种基于元混合整数规划（MMIP）的故障诊断框架，集成了基于图注意力网络（GAT）的故障定位（GAT-FL）。首先，我们推导了测量重建条件，允许从可用测量和系统拓扑中重建受攻击区域的未知测量。基于这些条件，我们将诊断任务表述为MMIP模型。GAT-FL预测潜在物理攻击的概率分布，然后将其作为目标系数纳入MMIP中。求解MMIP可获得最优攻击位置和幅值估计，并从中重建系统状态。在IEEE 30/118总线标准测试案例上进行了实验仿真，以证明所提出的故障诊断算法的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [829] [Evaluation of Safety Cognition Capability in Vision-Language Models for Autonomous Driving](https://arxiv.org/abs/2503.06497)
> *自动驾驶中视觉-语言模型的安全认知能力评估*

*Enming Zhang, Peizhe Gong, Xingyuan Dai, Min Huang, Yisheng Lv, Qinghai Miao* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉-语言模型, 自动驾驶, 安全认知, SCD-Bench, SCD-Training

**Comment:** 

> **TL;DR:** 该研究提出了SCD-Bench，一个用于评估自动驾驶中视觉-语言模型（VLM）安全认知的基准；引入了半自动化标注系统ADA；并构建了首个大规模安全认知数据集SCD-Training。实验表明，在SCD-Training上训练的模型显著提高了VLM的安全认知能力。

**AI_Comments:** 该论文的创新点在于其全面地解决了自动驾驶VLM的安全评估和训练问题。SCD-Bench填补了安全关键评估的空白，ADA和基于LLM的自动化评估流程提高了效率和一致性，而SCD-Training数据集则为模型对齐安全认知提供了宝贵的资源。这些贡献共同为提升自动驾驶系统的安全性提供了坚实的基础，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 确保自动驾驶系统中视觉-语言模型（VLM）的安全性至关重要，然而现有研究主要集中于传统基准测试，而非安全关键评估。

**Method:** 本研究提出了SCD-Bench（Safety Cognition Driving Benchmark），一个专门用于评估VLM在交互式驾驶场景中安全认知能力的框架。为解决数据标注的可扩展性问题，引入了ADA（Autonomous Driving Annotation）半自动化标注系统，并经过专家评审进一步完善。为实现可扩展且一致的评估，还提出了一种利用大型语言模型（LLM）的自动化评估流程，该流程与人类专家判断的一致性超过98%。此外，构建了SCD-Training，这是第一个为此任务量身定制的大规模数据集，包含324.35K高质量样本，以解决VLM与驾驶环境中安全认知对齐的更广泛挑战。

**Result:** 通过大量实验，结果表明在SCD-Training上训练的模型不仅在SCD-Bench上，而且在通用和特定领域基准测试上都表现出显著改进。

**Conclusion:** 本研究为增强自动驾驶中视觉-语言系统的安全感知交互提供了新视角，通过引入SCD-Bench、ADA、自动化评估流程以及大规模SCD-Training数据集，显著提升了模型的安全认知能力。

> **ai_Abstract:** 本研究旨在解决自动驾驶中视觉-语言模型（VLM）安全关键评估的缺失。为此，论文提出了SCD-Bench，一个专门评估VLM安全认知能力的基准；引入了ADA半自动化标注系统以提高数据标注效率；并开发了基于大型语言模型的自动化评估流程，其与人类专家判断一致性高。此外，构建了首个大规模安全认知数据集SCD-Training。实验证明，在SCD-Training上训练的模型在安全认知和通用基准测试上均表现出显著提升，为自动驾驶VLM的安全感知交互提供了新的方向。

> **摘要翻译:** 确保自动驾驶系统中视觉-语言模型（VLM）的安全性至关重要，然而现有研究主要集中于传统基准测试而非安全关键评估。在这项工作中，我们提出了SCD-Bench（Safety Cognition Driving Benchmark），一个专门设计用于评估VLM在交互式驾驶场景中安全认知能力的新颖框架。为解决数据标注的可扩展性挑战，我们引入了ADA（Autonomous Driving Annotation），一个半自动化标注系统，并通过具有自动驾驶领域专业知识的专家评审进一步完善。为促进可扩展且一致的评估，我们还提出了一种利用大型语言模型（LLM）的自动化评估流程，该流程与人类专家判断的一致性超过98%。在解决VLM与驾驶环境中安全认知对齐的更广泛挑战方面，我们构建了SCD-Training，这是第一个为此任务量身定制的大规模数据集，包含324.35K高质量样本。通过大量实验，我们表明在SCD-Training上训练的模型不仅在SCD-Bench上，而且在通用和特定领域基准测试上都表现出显著改进，为增强自动驾驶中视觉-语言系统的安全感知交互提供了新视角。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [834] [Teaching LLMs How to Learn with Contextual Fine-Tuning](https://arxiv.org/abs/2503.09032)
> *教导大型语言模型如何通过上下文微调来学习*

*Younwoo Choi, Muhammad Adil Asif, Ziwen Han, John Willes, Rahul G. Krishnan* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 上下文微调, 指令微调, 人类认知策略, 快速微调

**Comment:** 

> **TL;DR:** 本文提出了一种称为“上下文微调”的新方法，通过模仿人类学习策略的指令提示来快速微调大型语言模型，并在医疗和金融领域显示出有效性。

**AI_Comments:** 这项工作提出了一种新颖且直观的方法，通过模拟人类学习过程来改进LLM的微调。其创新点在于将人类认知策略融入到提示设计中，以指导模型学习，这为LLM的适应性学习提供了一个新的视角。在快速变化的领域中，这种快速微调的能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在快速发展的领域中，需要微调LLM以改进其知识或在新领域中的开放式推理能力。作者提出了一个问题：“提示能否帮助我们教导LLM如何学习？”

**Method:** 本文研究了一种指令微调的新泛化形式，称为“上下文微调”。该方法利用旨在模仿人类学习和解决问题认知策略的指令提示来指导训练过程中的学习，旨在提高模型对领域特定知识的解释和理解。

**Result:** 经验证明，这种简单而有效的修改提高了LLM在医疗和金融领域新数据集上快速进行微调的能力。

**Conclusion:** 上下文微调，通过模仿人类认知策略的指令提示，可以有效且快速地提高LLM在特定领域（如医疗和金融）进行微调的能力。

> **ai_Abstract:** 本文提出了一种名为“上下文微调”的新型指令微调方法，旨在通过模仿人类学习和解决问题认知策略的指令提示来提高大型语言模型（LLM）在训练过程中对领域特定知识的理解和解释能力。研究通过在医疗和金融领域的新数据集上进行实证，证明了该方法能够有效且快速地提升LLM的微调能力。

> **摘要翻译:** 提示大型语言模型（LLM），或提供关于预期操作模型的上下文，是指导此类模型输出以满足人类需求的一种有效方式，尤其是在它们经过训练之后。但在快速发展的领域中，通常需要对LLM进行微调，以改进其记忆中的知识类型或在新领域中进行开放式推理的能力。当人类学习新概念时，我们通常通过将正在学习的新材料与之前已经学过的概念联系起来。为此，我们不禁要问：“提示能否帮助我们教导LLM如何学习？”在这项工作中，我们研究了一种新颖的指令微调泛化形式，称为上下文微调，用于微调LLM。我们的方法利用旨在模仿人类学习和解决问题认知策略的指令提示来指导训练过程中的学习，旨在提高模型对领域特定知识的解释和理解。我们经验性地证明，这种简单而有效的修改提高了LLM在医疗和金融领域的新数据集上快速进行微调的能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [839] [The Impact of Item-Writing Flaws on Difficulty and Discrimination in Item Response Theory](https://arxiv.org/abs/2503.10533)
> *项目编写缺陷对项目反应理论中难度和区分度的影响*

*Robin Schmucker, Steven Moore* | **Category: cs.AI, cs.CL, cs.CY** | **Updated: 2025-08-07**

**Keywords:** 项目编写缺陷, 项目反应理论, 试题验证, 自动化分析, 难度和区分度

**Comment:** 

> **TL;DR:** 本研究探讨了项目编写缺陷（IWFs）对项目反应理论（IRT）中项目难度和区分度的影响，发现IWFs与这些参数之间存在显著关联，并提出自动化IWF分析可作为传统验证方法的有效补充。

**AI_Comments:** 该论文的创新之处在于其大规模的自动化IWF分析，并首次在如此大的数据集上系统地将其与经验性的IRT参数联系起来。这为测试项目开发提供了一种高效、可扩展的预部署评估工具，减少了对昂贵预测试的依赖。其重要性在于为教育评估领域的试题质量控制提供了一种新的视角和方法。然而，论文也指出，尽管自动化IWF分析有其价值，但仍需要进一步研究领域通用评估细则和理解领域特定内容的算法，以实现更稳健的试题验证，这表明其局限性在于目前可能无法完全替代人工专家评估或完全理解所有领域特异性内容。

<details>
  <summary>Details</summary>

**Motivation:** 传统的试题验证方法（如预测试）资源密集且耗时。虽然项目编写缺陷（IWF）评估方法提供了一种无需学生数据即可进行大规模预部署评估的替代方案，但其对经验性IRT参数的预测有效性尚未得到充分探索。本研究旨在弥补这一空白。

**Method:** 研究使用了7,126道来自STEM学科（物理科学、数学、生命/地球科学）的多项选择题。采用自动化方法，使用19项标准的IWF评估细则对每道题进行标注，并分析了IWF数量与数据驱动的IRT难度和区分度参数之间的关系。

**Result:** 研究发现，IWF的数量与IRT难度和区分度参数之间存在统计学上的显著关联，尤其是在生命/地球科学和物理科学领域。此外，还观察到特定的IWF标准（如否定措辞 vs. 不合理干扰项）对项目质量的影响程度不同，以及它们如何使问题更具挑战性或更简单。

**Conclusion:** 自动化IWF分析被确立为传统试题验证的宝贵补充，特别是在初期筛选和识别低难度多选题方面提供了一种高效方法。研究结果表明，需要进一步研究领域通用评估细则以及理解领域特定内容的算法，以实现稳健的试题验证。

> **ai_Abstract:** 本研究探讨了项目编写缺陷（IWFs）对项目反应理论（IRT）中项目难度和区分度的影响。通过对7,126道多选题进行自动化IWF标注和分析，研究发现IWFs的数量与IRT难度和区分度参数之间存在显著统计关联，尤其是在特定科学领域。研究还揭示了不同IWF类型对项目质量的不同影响。结果表明，自动化IWF分析可作为传统试题验证的有效补充，尤其适用于初期筛选和识别低难度试题。

> **摘要翻译:** 高质量的测试项目对于教育评估至关重要，特别是在项目反应理论（IRT）中。传统的验证方法依赖于资源密集型的预测试来估计项目难度和区分度。最近，项目编写缺陷（IWF）细则作为一种领域通用的方法出现，用于基于文本特征评估测试项目。这种方法提供了一种可扩展的、无需学生数据即可进行的预部署评估，但其对经验性IRT参数的预测有效性尚未得到充分探索。为了弥补这一空白，我们进行了一项研究，涉及7,126道来自各种STEM学科（物理科学、数学和生命/地球科学）的多项选择题。我们使用自动化方法，用19项标准的IWF细则标注了每道题，并研究了它们与数据驱动的IRT参数之间的关系。我们的分析揭示了IWF数量与IRT难度和区分度参数之间存在统计学上的显著关联，特别是在生命/地球和物理科学领域。我们进一步观察了特定IWF标准如何或多或少地严重影响项目质量（例如，否定措辞与不合理的干扰项），以及它们如何使问题变得更具挑战性或更简单。总的来说，我们的研究结果确立了自动化IWF分析作为传统验证的宝贵补充，为初始项目筛选提供了一种高效方法，特别是用于标记低难度的多选题。我们的研究结果表明，需要进一步研究领域通用评估细则和理解领域特定内容的算法，以实现稳健的项目验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [844] [Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection](https://arxiv.org/abs/2503.15818)
> *计算高效且识别友好的3D点云隐私保护*

*Haotian Ma, Lin Gu, Siyi Wu, Yingying Zhu* | **Category: cs.AI, cs.CV** | **Updated: 2025-08-06**

**Keywords:** 3D点云, 隐私保护, 流式生成模型, 角相似度损失, 识别友好

**Comment:** 

> **TL;DR:** 本文提出PointFlowGMM框架，利用流式生成模型和新颖的角相似度损失，在保护3D点云隐私的同时，支持下游识别任务并实现模型尺寸大幅缩减。

**AI_Comments:** 该论文的创新点在于首次系统性地定义了3D点云的隐私问题，并提出了一个独特的基于流式生成模型的解决方案。特别值得注意的是，其引入的角相似度损失不仅有效混淆了原始几何结构，还在保证识别性能的同时大幅降低了模型大小，这在资源受限的应用中具有重要意义。同时，在潜在空间进行正交旋转的策略巧妙地兼顾了隐私保护与数据可用性。这项工作为3D点云在隐私敏感应用中的部署提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 3D点云在自动驾驶、机器人等领域广泛应用，但其隐私泄露问题尚未得到充分研究，且与2D图像隐私保护方式不同，需要专门针对3D几何结构进行处理。

**Method:** 提出PointFlowGMM框架，利用流式生成模型将点云投影到潜在高斯混合分布子空间。设计新颖的角相似度损失来混淆原始几何结构并减小模型大小。在潜在空间中对投影点云进行随机正交旋转以进一步保护隐私，同时保持类别间关系。

**Result:** 模型大小从767MB显著减小到120MB，同时识别性能没有下降。在加密点云上取得了与原始点云相当的识别结果。

**Conclusion:** 本文提出的PointFlowGMM框架能够有效保护3D点云隐私，同时保持对下游识别任务的支持能力，并且具有较高的计算效率和更小的模型尺寸。

> **ai_Abstract:** 本文针对3D点云隐私泄露问题，提出了一种名为PointFlowGMM的高效隐私保护框架。该框架利用流式生成模型将点云投影到潜在空间，并通过新颖的角相似度损失来混淆几何结构并显著减小模型尺寸。此外，在潜在空间进行随机正交旋转进一步增强隐私保护，同时确保下游分类和分割任务的识别性能不受影响。实验结果表明，该方法在保持识别准确性的前提下，成功实现了模型轻量化和隐私保护。

> **摘要翻译:** 3D点云已广泛应用于自动驾驶汽车、机器人、CAD模型等应用中。据我们所知，这些应用引发了3D点云中的隐私泄露问题，而这一问题尚未得到充分研究。与2D图像隐私（与纹理和2D几何结构相关）不同，3D点云是无纹理的，且仅与3D几何结构相关。在这项工作中，我们定义了3D点云隐私问题，并提出了一个高效的隐私保护框架PointFlowGMM，该框架无需查看原始数据即可支持下游分类和分割任务。利用流式生成模型，点云被投影到一个潜在的高斯混合分布子空间中。我们进一步设计了一种新颖的角相似度损失，以混淆原始几何结构，并将模型大小从767MB减小到120MB，同时识别性能没有下降。潜在空间中投影的点云被随机正交旋转以进一步保护原始几何结构，旋转后类别间的关系得以保留，因此，受保护的点云可以支持识别任务。我们在多个数据集上评估了我们的模型，与原始点云相比，在加密点云上取得了可比较的识别结果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [848] [SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic Reproduction from Research Papers](https://arxiv.org/abs/2504.00255)
> *SciReplicate-Bench：基於代理的LLM在研究論文算法復現中的基準測試*

*Yanzheng Xiang, Hanqi Yan, Shuyin Ouyang, Lin Gui, Yulan He* | **Category: cs.AI, cs.CL, cs.MA, cs.SE** | **Updated: 2025-08-07**

**Keywords:** LLMs, 代碼生成, 算法復現, 基準測試, NLP論文

**Comment:** 

> **TL;DR:** 本研究引入了SciReplicate-Bench，一個用於評估大型語言模型（LLMs）從NLP論文中復現算法的基準測試。研究提出了一個雙代理框架Sci-Reproducer，並發現目前最強大的LLM在此任務上僅達到39%的執行準確度，表明該任務難度高且現有LLMs表現不佳。

**AI_Comments:** 本論文的創新之處在於引入了一個新的、高難度的基準測試SciReplicate-Bench，以及一個用於算法復現的雙代理框架Sci-Reproducer。它揭示了當前LLMs在從研究論文中理解複雜算法並生成可執行代碼方面的顯著局限性，尤其是在算法理解和處理不完整描述方面。這對於未來LLM在科研自動化和代碼生成領域的發展具有重要指導意義。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在評估大型語言模型（LLMs）從近期NLP論文的算法描述中生成代碼的能力。這項任務需要算法理解和編碼專業知識兩項關鍵能力，研究旨在為此提供嚴格的評估。

**Method:** 研究引入了SciReplicate-Bench，一個包含來自36篇2024年NLP論文的100個任務的基準測試，具有詳細註釋和全面的測試用例。在此基礎上，提出了Sci-Reproducer雙代理框架，由一個解釋算法概念的論文代理和一個檢索依賴並實現解決方案的代碼代理組成。評估指標包括推理圖準確度（衡量算法理解）以及執行準確度、CodeBLEU和倉庫依賴/API召回率（衡量實現質量）。

**Result:** 實驗中，最佳表現的LLM（使用ModelName）僅達到39%的執行準確度，突顯了基準測試的難度。分析表明，算法描述的缺失或不一致是成功復現的主要障礙。

**Conclusion:** 大型語言模型在從研究論文中復現算法方面表現不佳，當前算法描述的質量問題是其主要挑戰。本研究的基準測試證明了該任務的複雜性，並為未來LLM在代碼生成領域的發展提供了方向。

> **ai_Abstract:** 本研究旨在評估大型語言模型（LLMs）從NLP研究論文中復現算法的能力。為此，作者引入了SciReplicate-Bench，一個包含100個任務的基準測試，並提出了Sci-Reproducer雙代理框架來處理算法理解和代碼實現。評估結果顯示，即使是表現最佳的LLM在執行準確度上也僅達到39%，這表明了任務的挑戰性以及當前LLMs在複雜算法復現方面的局限性。研究進一步指出，論文中算法描述的缺失或不一致是導致復現失敗的主要原因。

> **摘要翻译:** 本研究評估了大型語言模型（LLM）從近期自然語言處理（NLP）論文的算法描述中生成代碼的能力。這項任務需要兩項關鍵能力：（1）算法理解：綜合論文和學術文獻中的信息以理解實現邏輯；（2）編碼專業知識：識別依賴關係並正確實現必要的API。為便於嚴格評估，我們引入了SciReplicate-Bench，一個包含來自36篇2024年NLP論文的100個任務的基準測試，其特點是詳細的註釋和全面的測試用例。基於SciReplicate-Bench，我們提出了Sci-Reproducer，一個雙代理框架，由一個解釋文獻中算法概念的論文代理和一個從倉庫中檢索依賴並實現解決方案的代碼代理組成。為了評估算法理解，我們引入了推理圖準確度，它量化了生成推理圖與從代碼註釋和結構中導出的參考推理圖之間的相似性。為了評估實現質量，我們採用執行準確度、CodeBLEU以及倉庫依賴/API召回率指標。在我們的實驗中，我們評估了各種強大的非推理和推理LLM作為基礎模型。使用ModelName的最佳LLM僅達到39%的執行準確度，突顯了基準測試的難度。我們的分析發現，缺失或不一致的算法描述是成功復現的關鍵障礙。我們在https://github.com/xyzCS/SciReplicate-Bench和項目主頁https://xyzcs.github.io/scireplicate.github.io/上提供了我們的基準測試和代碼。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [854] [R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation](https://arxiv.org/abs/2504.04699)
> *R2Vul：通过强化学习和结构化推理蒸馏学习软件漏洞推理*

*Martin Weyssow, Chengran Yang, Junkai Chen, Ratnadira Widyasari, Ting Zhang, Huihui Huang, Huu Hung Nguyen, Yan Naing Tun, Tan Bui, Yikun Li, Ang Han Wei, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, David Lo* | **Category: cs.AI, cs.CL, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 软件漏洞检测, 强化学习, 大型语言模型, 推理蒸馏, RLAIF

**Comment:** 

> **TL;DR:** R2Vul结合AI反馈强化学习和结构化推理蒸馏，使小型语言模型能更精确地检测软件漏洞并生成高质量解释，性能超越大型模型和商业LLM。

**AI_Comments:** R2Vul的创新点在于结合RLAIF和结构化推理蒸馏来提升小型LLM的推理能力和解释质量，特别是通过奖励“有根据”而非“似是而非”的解释，解决了LLM推理不可靠的问题。构建首个多语言偏好数据集也极具价值。其性能超越大型模型和商业LLM，以及降低误报率的校准步骤，都显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在软件漏洞检测中表现出潜力，但其推理能力仍不可靠。

**Method:** 提出R2Vul方法，结合AI反馈强化学习（RLAIF）和结构化推理蒸馏，以训练小型代码LLMs检测漏洞并生成安全感知解释。R2Vul通过RLAIF奖励有充分根据的漏洞解释。为支持RLAIF，构建了首个包含C#、JavaScript、Java、Python和C语言的18,000个高质量样本的多语言漏洞检测偏好数据集。此外，引入了轻量级校准步骤以降低误报率。

**Result:** 一个1.5B的R2Vul模型性能超越了其32B的教师模型和领先的商业LLMs（如Claude-4-Opus）。轻量级校准步骤在不同不平衡数据分布下有效降低了误报率。LLM和人类评估者一致认为R2Vul模型的推理能力优于其他基于推理的基线模型。

**Conclusion:** R2Vul通过结合AI反馈强化学习和结构化推理蒸馏，显著提升了小型语言模型在软件漏洞检测中的性能和解释质量，并有效解决了误报率问题，展现了超越大型模型的潜力。

> **ai_Abstract:** R2Vul是一种结合AI反馈强化学习（RLAIF）和结构化推理蒸馏的新方法，旨在提升小型代码大型语言模型（LLMs）在软件漏洞检测中的推理能力和解释质量。该方法通过奖励有充分根据的漏洞解释来提高检测精度和推理生成质量，并为此构建了首个多语言漏洞检测偏好数据集。实验结果表明，一个1.5B的R2Vul模型在性能上超越了其32B的教师模型和顶级的商业LLMs，并能有效降低误报率，其推理能力也得到LLM和人类评估者的高度认可。

> **摘要翻译:** 大型语言模型（LLMs）在软件漏洞检测方面表现出良好的性能，但其推理能力仍不可靠。我们提出了R2Vul，一种结合了AI反馈强化学习（RLAIF）和结构化推理蒸馏的方法，旨在教授小型代码LLMs检测漏洞，同时生成安全感知的解释。与以往的思维链和指令微调方法不同，R2Vul通过RLAIF奖励有充分根据而非貌似合理的漏洞解释，从而实现更精确的检测和高质量的推理生成。为了支持RLAIF，我们构建了首个用于漏洞检测的多语言偏好数据集，包含C#、JavaScript、Java、Python和C语言的18,000个高质量样本。我们在五种编程语言中对R2Vul进行了评估，并与四种静态分析工具、八种最先进的基于LLM的基线模型以及各种微调方法进行了比较。我们的结果表明，一个1.5B的R2Vul模型超越了其32B的教师模型和领先的商业LLMs，例如Claude-4-Opus。此外，我们引入了一个轻量级校准步骤，可在不同不平衡数据分布下降低误报率。最后，通过定性分析，我们表明LLM和人类评估者都一致认为R2Vul模型的推理能力高于其他基于推理的基线模型。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [859] [Predicting the Lifespan of Industrial Printheads with Survival Analysis](https://arxiv.org/abs/2504.07638)
> *使用生存分析预测工业打印头的寿命*

*Dan Parii, Evelyne Janssen, Guangzhi Tang, Charalampos Kouzinopoulos, Marcin Pietrasik* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 生存分析, 打印头寿命预测, 工业维护, 预测性维护

**Comment:** 

> **TL;DR:** 本文利用生存分析预测工业打印头寿命，性能优于现有基线方法。

**AI_Comments:** 本文的创新之处在于将生存分析这一统计方法成功应用于工业打印头寿命预测，并证明其性能优于传统的行业基线方法。这对于工业设备的预防性维护和生产效率提升具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测关键设备组件的寿命对于维护计划和生产优化至关重要，因此在学术界和工业界都备受关注。

**Method:** 本文研究了使用生存分析来预测佳能生产打印公司开发的生产打印头的寿命。具体应用了五种技术来估计生存概率和故障率：Kaplan-Meier估计器、Cox比例风险模型、Weibull加速失效时间模型、随机生存森林和梯度提升。估计结果通过等渗回归进一步细化，并聚合以确定预期故障数量。预测结果通过真实世界数据进行验证。

**Result:** 使用三种性能指标的定量评估表明，生存分析在打印头寿命预测方面优于行业标准基线方法。

**Conclusion:** 生存分析方法在预测工业打印头寿命方面表现出色，优于行业标准基线方法，为维护计划和生产优化提供了有效工具。

> **ai_Abstract:** 本文探讨了利用生存分析预测佳能生产打印公司工业打印头寿命的方法，旨在优化维护计划和生产。研究应用了包括Kaplan-Meier、Cox模型、Weibull模型、随机生存森林和梯度提升在内的五种生存分析技术，并通过等渗回归进行结果细化与聚合。通过与真实世界数据的验证，结果表明生存分析在预测打印头寿命方面显著优于行业标准基线方法。

> **摘要翻译:** 准确预测关键设备组件的寿命对于维护计划和生产优化至关重要，因此在学术界和工业界都备受关注。在这项工作中，我们研究了使用生存分析来预测佳能生产打印公司开发的生产打印头的寿命。具体来说，我们重点应用了五种技术来估计生存概率和故障率：Kaplan-Meier估计器、Cox比例风险模型、Weibull加速失效时间模型、随机生存森林和梯度提升。然后使用等渗回归进一步细化所得估计值，并随后进行聚合以确定预期的故障数量。随后，预测结果在多个时间窗口内根据真实的地面实况数据进行验证，以评估模型的可靠性。我们使用三种性能指标进行的定量评估表明，生存分析在打印头寿命预测方面优于行业标准基线方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [864] [Vector Quantized-Elites: Unsupervised and Problem-Agnostic Quality-Diversity Optimization](https://arxiv.org/abs/2504.08057)
> *向量量化精英：无监督和问题无关的质量-多样性优化*

*Constantinos Tsakonas, Konstantinos Chatzilygeroudis* | **Category: cs.AI, cs.LG, cs.NE, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 质量-多样性优化, 无监督学习, 向量量化变分自编码器, 行为空间, VQ-Elites

**Comment:** 

> **TL;DR:** VQ-Elites是一种新的无监督质量-多样性（QD）算法，它利用向量量化变分自编码器自动构建行为空间，无需预设任务知识，显著提升了QD的灵活性和适用性。

**AI_Comments:** VQ-Elites的创新之处在于其将向量量化变分自编码器引入到质量-多样性优化中，实现了行为空间的无监督构建，极大地拓展了质量-多样性算法的应用范围。这解决了传统方法对先验知识依赖的痛点，使其能够应用于更复杂、未知环境的任务。提出的新度量指标也很有价值，有助于更好地评估无监督质量-多样性算法的表现。

<details>
  <summary>Details</summary>

**Motivation:** 传统的质量-多样性算法（如MAP-Elites）严重依赖预定义的行为描述符和完整的任务先验知识来定义行为空间网格，这限制了它们的灵活性和适用性。

**Method:** 本文提出了向量量化精英（VQ-Elites），一种新颖的质量-多样性算法，它通过整合向量量化变分自编码器，利用无监督学习自主构建结构化的行为空间网格，从而消除了对任务特定先验知识的需求。此外，为了进一步提高无监督质量-多样性算法的性能，引入了行为空间边界和协作机制，并提出了两种新的度量指标：有效多样性比率和覆盖多样性分数，用于量化无监督环境中的实际多样性。

**Result:** VQ-Elites在机械臂姿态到达、移动机器人空间覆盖和MiniGrid探索任务上进行了验证。结果表明，它能够有效地生成多样化、高质量的解决方案，并展现出良好的适应性、可扩展性、对超参数的鲁棒性，以及将质量-多样性优化扩展到复杂、以前无法访问的领域的潜力。

**Conclusion:** VQ-Elites通过无监督学习和动态行为空间构建，成功克服了传统质量-多样性算法的局限性，提供了一个灵活、鲁棒且任务无关的优化框架，能够高效地在复杂任务中生成多样化的高质量解决方案。

> **ai_Abstract:** VQ-Elites是一种创新的质量-多样性优化算法，它通过集成向量量化变分自编码器，实现了无监督地自动构建结构化行为空间，从而摆脱了对先验任务知识的依赖。该方法显著提升了质量-多样性算法的灵活性、鲁棒性和任务无关性。实验证明，VQ-Elites能够高效生成多样且高质量的解决方案，并适用于多种复杂任务。

> **摘要翻译:** 质量-多样性算法通过优先发现多样化、高性能的解决方案而非单一最优结果，彻底改变了优化领域。然而，传统的质量-多样性方法（如MAP-Elites）严重依赖预定义的行为描述符和完整的任务先验知识来定义行为空间网格，这限制了它们的灵活性和适用性。在这项工作中，我们引入了向量量化精英（VQ-Elites），一种新颖的质量-多样性算法，它利用无监督学习自主构建结构化的行为空间网格，从而消除了对任务特定知识的需求。VQ-Elites的核心是整合了向量量化变分自编码器，这使得行为描述符能够动态学习并生成结构化而非非结构化的行为空间网格——这是现有无监督质量-多样性方法的重大进步。这种设计使VQ-Elites成为一个灵活、鲁棒且任务无关的优化框架。为了进一步提高无监督质量-多样性算法的性能，我们引入了行为空间边界和协作机制，这显著改善了收敛性和性能，同时提出了有效多样性比率和覆盖多样性分数这两种新颖的度量指标，用于量化无监督环境中的实际多样性。我们在机械臂姿态到达、移动机器人空间覆盖和MiniGrid探索任务上验证了VQ-Elites。结果表明，它能够有效地生成多样化、高质量的解决方案，突出了其适应性、可扩展性、对超参数的鲁棒性，以及将质量-多样性优化扩展到复杂、以前无法访问的领域的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [869] [Deep Learning Methods for Detecting Thermal Runaway Events in Battery Production Lines](https://arxiv.org/abs/2504.08632)
> *电池生产线中热失控事件检测的深度学习方法*

*Athanasios Athanasopoulos, Matúš Mihalák, Marcin Pietrasik* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 深度学习, 热失控检测, 电池生产线, 计算机视觉, 安全

**Comment:** 

> **TL;DR:** 本文研究了在VDL Nedcar电池生产线上使用深度学习方法检测热失控事件，结果表明深度学习是一种可行的方法。

**AI_Comments:** 这项工作通过在实际生产线上模拟热失控并使用多模态数据（光学和热图像）结合多种深度学习模型，为电池生产安全提供了创新的自动化检测方案。其重要性在于提升了电池制造过程的安全性，并验证了深度学习在该领域的应用潜力。未来可以进一步探索模型的鲁棒性和实时性。

<details>
  <summary>Details</summary>

**Motivation:** 电池制造中的热失控是一个关键的安全问题，可能导致火灾、爆炸和有毒气体排放。因此，开发能够检测此类事件的自动化系统在学术和工业领域都非常重要。

**Method:** 研究人员在VDL Nedcar电池生产线收集了基线和模拟热失控条件下的光学和热图像数据。数据经过预处理和融合后，输入到三种计算机视觉中常用的深度学习模型：浅层卷积神经网络、残差神经网络和视觉Transformer。模型性能通过两种指标评估，并使用可解释性方法分析其特征捕获能力。

**Result:** 结果表明，深度学习是电池生产线中热失控检测的一种可行方法。

**Conclusion:** 深度学习可以作为电池生产线中热失控检测的有效方法。

> **ai_Abstract:** 本文探讨了在VDL Nedcar电池生产线上利用深度学习方法检测热失控事件。研究人员通过模拟热失控场景收集了光学和热图像数据，并将其预处理后输入到浅层卷积神经网络、残差神经网络和视觉Transformer三种深度学习模型中进行评估。结果表明，深度学习在电池生产线热失控检测中表现出可行性。

> **摘要翻译:** 电池制造的关键安全考量之一是热失控，即温度的无控制升高，这可能导致火灾、爆炸和有毒气体排放。因此，开发能够检测此类事件的自动化系统在学术和工业领域都具有相当重要的意义。在这项工作中，我们研究了在荷兰汽车制造商VDL Nedcar的电池生产线中使用深度学习检测热失控。具体而言，我们从生产线收集了代表基线（非热失控）和热失控条件的数据。热失控通过使用外部热源和烟源进行模拟。数据包括光学图像和热图像，这些图像随后经过预处理和融合，作为我们模型的输入。在这方面，我们评估了计算机视觉中广泛使用的三种深度学习模型，包括浅层卷积神经网络、残差神经网络和视觉Transformer，并使用了两种性能指标。此外，我们还使用可解释性方法评估了这些模型，以深入了解它们从输入中捕获相关特征信息的能力。所得结果表明，深度学习在电池生产线中进行热失控检测是一种可行的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [874] [Towards Personalized Conversational Sales Agents: Contextual User Profiling for Strategic Action](https://arxiv.org/abs/2504.08754)
> *迈向个性化对话式销售代理：情境用户画像与策略行动*

*Tongyoung Kim, Jeongeun Lee, Soojin Yoon, Sunghwan Kim, Dongha Lee* | **Category: cs.AI, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 对话式销售, 用户画像, 推荐系统, 销售代理, LLM用户模拟器

**Comment:** 

> **TL;DR:** 本文引入了对话式销售（CSALES）新任务，并提出了基于LLM的用户模拟器（CSUSER）和对话式销售代理（CSI），实验证明CSI在推荐成功率和说服效果方面表现出色。

**AI_Comments:** 本文创新性地将偏好获取、推荐和说服整合到“对话式销售”这一新任务中，并提出了基于LLM的用户模拟器进行系统评估，这对于开发更贴近真实商业场景的对话代理具有重要意义。CSI代理通过情境用户画像提升了交互的个性化和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统对话推荐系统（CRSs）在电商场景中无法捕捉用户复杂的决策过程和多重考虑因素，因此需要一个更全面的框架来整合偏好获取、推荐和说服。

**Method:** 本文引入了对话式销售（CSALES）这一新任务，将偏好获取、推荐和说服整合到一个统一的对话框架中。为了进行系统评估，提出了CSUSER，一个基于真实世界行为数据的LLM用户模拟器，用于建模细粒度用户画像。此外，还提出了CSI，一个能够主动推断情境用户画像并通过对话策略性地选择行动的对话式销售代理。

**Result:** 全面的实验表明，CSI显著提高了推荐成功率和说服有效性，并且适用于各种不同的用户画像。

**Conclusion:** 本研究通过引入对话式销售（CSALES）任务、CSUSER评估协议和CSI代理，成功地为个性化对话式销售代理提供了新的框架和有效的解决方案，显著提升了推荐和说服效果。

> **ai_Abstract:** 本文提出了一种名为对话式销售（CSALES）的新任务，旨在解决传统对话推荐系统在复杂电商决策中的不足。为了支持评估，引入了基于真实行为数据的LLM用户模拟器CSUSER。同时，开发了对话式销售代理CSI，它能够主动识别情境用户画像并策略性地采取行动。实验证明CSI在提高推荐成功率和说服效果方面表现出色。

> **摘要翻译:** 对话推荐系统（CRSs）旨在通过对话与用户互动，提供量身定制的推荐。传统的CRSs侧重于获取偏好和检索商品，而现实世界的电子商务互动涉及更复杂的决策，用户会考虑简单属性之外的多种因素。为了捕捉这种复杂性，我们引入了对话式销售（CSALES），一项新颖的任务，它将偏好获取、推荐和说服整合到统一的对话框架中。为了支持现实和系统的评估，我们提出了CSUSER，一个基于LLM的用户模拟协议，通过建模细粒度用户画像实现个性化互动，并以真实世界的行为数据为基础。我们还提出了CSI，一个对话式销售代理，它能够主动推断情境用户画像并通过对话策略性地选择行动。全面的实验表明，CSI显著提高了不同用户画像下的推荐成功率和说服有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [325] [Understanding and Mitigating Errors of LLM-Generated RTL Code](https://arxiv.org/abs/2508.05266)
> *理解并缓解LLM生成的RTL代码中的错误*

*Jiazheng Zhang, Cheng Liu, Huawei Li* | **Category: cs.AR, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** LLM, RTL代码生成, 错误分析, 检索增强生成, 迭代调试

**Comment:** 

> **TL;DR:** 本文深入分析了LLM生成RTL代码的常见错误原因，并提出了一系列针对性的纠错技术，包括构建领域知识库、引入设计描述规则、集成外部工具和迭代调试，显著提升了RTL代码生成准确率。

**AI_Comments:** 本文的创新之处在于其对LLM生成RTL代码错误的深入、系统性分析，并针对性地提出了多维度解决方案。它不仅指出了LLM在专业领域应用中面临的知识和理解障碍，还提供了实用的缓解策略，如RAG结合领域知识、规则化描述及外部工具集成，这些方法对于提升LLM在特定工程领域的应用性能具有重要借鉴意义。其高准确率提升也证明了这些方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于大型语言模型（LLM）的寄存器传输级（RTL）代码生成潜力巨大，但其整体成功率仍不尽如人意。错误由多种因素引起，且对具体失败原因的理解有限，阻碍了改进。

**Method:** 本文进行了全面的错误分析和手动分类，发现大多数错误并非源于LLM的推理局限，而是由于RTL编程知识不足、电路概念理解薄弱、设计描述模糊或多模态输入误解。针对这些问题，作者提出了一系列纠错技术：构建领域特定知识库并结合检索增强生成（RAG）以提供RTL知识；引入设计描述规则并实现规则检查机制以缓解歧义错误；集成外部工具将多模态输入转换为LLM兼容的元格式；对剩余错误采用迭代调试循环（模拟-错误定位-纠正）。这些技术被整合到一个LLM框架中。

**Result:** 实验结果表明，增强后的框架在VerilogEval基准测试中达到了91.0%的准确率，比基线代码生成方法提高了32.7%，证明了所提方法的有效性。

**Conclusion:** 本文提出的针对性纠错技术，通过解决LLM生成RTL代码中常见的知识、理解、歧义和多模态输入问题，显著提高了代码生成的准确性和性能。

> **ai_Abstract:** 本文针对LLM生成RTL代码成功率低的问题，通过全面的错误分析，揭示了错误主要源于RTL知识不足、电路概念理解薄弱、设计描述模糊及多模态输入误解，而非LLM推理能力。为解决这些问题，论文提出了一系列纠错技术：利用RAG构建领域知识库以补充RTL知识，引入设计描述规则和检查机制以减少歧义，整合外部工具处理多模态输入，并采用迭代调试循环处理剩余错误。这些技术集成到LLM框架后，在VerilogEval基准测试上将准确率提升至91.0%，较基线提升32.7%，验证了其有效性。

> **摘要翻译:** 尽管基于大型语言模型（LLM）的寄存器传输级（RTL）代码生成潜力巨大，但其整体成功率仍不尽如人意。错误由多种因素引起，且对具体失败原因的理解有限，阻碍了改进。为了解决这个问题，我们进行了全面的错误分析和手动分类。我们的发现表明，大多数错误并非源于LLM的推理局限性，而是由于RTL编程知识不足、电路概念理解薄弱、设计描述模糊或复杂多模态输入的误解。我们利用上下文学习，提出了有针对性的错误纠正技术。具体来说，我们构建了一个领域特定知识库，并采用检索增强生成（RAG）来提供必要的RTL知识。为了缓解歧义错误，我们引入了设计描述规则并实现了规则检查机制。对于多模态误解，我们集成了外部工具，将输入转换为LLM兼容的元格式。对于剩余的错误，我们采用了迭代调试循环（模拟-错误定位-纠正）。将这些技术整合到一个基于LLM的框架中，显著提高了性能。我们将这些错误纠正技术整合到一个基础的基于LLM的RTL代码生成框架中，从而显著提高了性能。实验结果表明，我们增强的框架在VerilogEval基准测试中达到了91.0%的准确率，比基线代码生成方法提高了32.7%，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [333] [relOBI: A Reliable Low-latency Interconnect for Tightly-Coupled On-chip Communication](https://arxiv.org/abs/2508.05354)
> *relOBI: 紧密耦合片上通信的可靠低延迟互连*

*Michael Rogenmoser, Angelo Garofalo, Luca Benini* | **Category: cs.AR** | **Updated: 2025-08-07**

**Keywords:** 片上通信, 可靠性, 三模冗余, 纠错码, 辐射环境

**Comment:** 

> **TL;DR:** relOBI是一种新的片上互连设计，通过TMR和ECC提高了辐射环境下的可靠性，且开销可接受。

**AI_Comments:** relOBI的创新之处在于其结合了TMR和ECC两种不同的错误防护机制，针对关键信号和非关键信号分别采取了不同的策略，从而在实现高可靠性的同时，有效控制了面积和时序开销，尤其是在辐射敏感环境中具有重要应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代片上系统（SoCs）中的片上通信至关重要，但在辐射密集环境中，互连中的软错误可能导致整个SoC的功能故障，因此需要可靠的片上互连设计。

**Method:** 本文提出了relOBI，它是Open Bus Interface（OBI）的扩展，通过结合关键握手信号的三模冗余（TMR）和对其他信号的纠错码（ECC）保护，以实现完全可靠性。

**Result:** 实现并测试了一个完全可靠的交叉开关，与参考设计相比，对注入故障的脆弱性从34.85%降低到0%，可靠性显著提高。面积增加了2.6倍，时序影响为1.4倍。其面积开销比文献中报道的细粒度三复制和投票方式低1.8倍。

**Conclusion:** relOBI通过结合TMR和ECC，显著提高了片上互连在辐射环境下的可靠性，并展示出相对较低的面积开销，优于现有冗余方法。

> **ai_Abstract:** 本文提出了一种名为relOBI的片上互连设计，旨在解决辐射环境下片上通信的可靠性问题。relOBI通过在Open Bus Interface (OBI) 中集成三模冗余 (TMR) 和纠错码 (ECC) 来确保所有信号的完整可靠性。实验结果表明，与传统设计相比，relOBI将故障脆弱性从34.85%降至0%，显著提高了可靠性，同时面积开销和时序影响在可接受范围内，并且面积开销优于现有细粒度冗余方法。

> **摘要翻译:** 片上通信是现代片上系统（SoCs）的关键组成部分，它允许处理器核心与内存和外设进行交互。在辐射密集的环境中，互连需要特别注意，因为片上系统互连中的任何软错误都可能导致整个SoC的功能故障。这项工作提出了relOBI，它是Open Bus Interface（OBI）的扩展，它结合了关键握手信号的三模冗余（TMR）和对其他信号的纠错码（ECC）保护，以实现完全可靠性。实现和测试一个完全可靠的交叉开关显示，与参考设计相比，对注入故障的脆弱性从34.85%提高到0%，可靠性得到改善，同时面积增加了2.6倍，时序影响为1.4倍。其面积开销比文献中报道的细粒度三复制和投票方式低1.8倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [341] [RACE-IT: A Reconfigurable Analog Computing Engine for In-Memory Transformer Acceleration](https://arxiv.org/abs/2312.06532)
> *RACE-IT: 一种用于内存内Transformer加速的可重构模拟计算引擎*

*Lei Zhao, Aishwarya Natarajan, Luca Buonanno, Archit Gajjar, Ron M. Roth, Sergey Serebryakov, John Moon, Jim Ignowski, Giacomo Pedretti* | **Category: cs.AR, cs.ET, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 内存内计算, Transformer加速, 模拟计算引擎, 可重构, ACAMs

**Comment:** 

> **TL;DR:** RACE-IT是一种基于增强型模拟内容可寻址存储器（ACAMs）的可重构模拟计算引擎，它能够高效地在模拟域执行Transformer模型的所有核心操作，相比现有技术显著提升性能并降低能耗。

**AI_Comments:** 该论文提出了一种创新的方法，通过可重构模拟计算引擎（RACE）来解决Transformer模型在内存内计算中的挑战。其核心创新在于增强模拟内容可寻址存储器（ACAMs）以支持更广泛的DNN操作，超越了传统的VMM加速。RACE-IT的灵活性和显著的性能及能效提升是其重要亮点，预示着未来硬件加速器在处理复杂AI模型方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** Transformer模型虽然是深度神经网络的前沿，但其处理需要大量的计算资源和内存。尽管内存内计算（IMC）在加速向量-矩阵乘法（VMMs）方面有前景，但将其应用于其他关键的DNN操作，特别是Transformer模型中复杂的激活函数、Softmax和数据依赖型矩阵乘法（DMMuls），仍然是一个巨大的挑战。

**Method:** 本文引入了一种可重构模拟计算引擎（RACE），通过增强模拟内容可寻址存储器（ACAMs）来支持更广泛的操作。在此基础上，提出了RACE-IT加速器，以实现在模拟域高效执行Transformer模型的所有核心操作。RACE的灵活性使其能够适应新兴和非传统的DNN架构，无需硬件修改。

**Result:** RACE-IT与各种加速器进行了比较。结果显示，RACE-IT的性能比最先进的GPU提升了453倍，比现有的Transformer专用IMC加速器提升了15倍；能耗分别降低了354倍和122倍。

**Conclusion:** RACE-IT通过提供一种高效的模拟计算引擎，成功解决了Transformer模型在内存内计算中的挑战，显著提升了性能并降低了能耗，并且具有良好的可重构性以适应未来DNN架构。

> **ai_Abstract:** 本文提出了一种名为RACE-IT的内存内Transformer加速器，它基于一种创新的可重构模拟计算引擎（RACE）。RACE通过增强模拟内容可寻址存储器（ACAMs）来支持Transformer模型中所有核心操作的模拟域执行，包括复杂的激活函数和数据依赖型矩阵乘法。RACE-IT的灵活性使其能够适应新兴的DNN架构。实验结果表明，与现有GPU和Transformer专用IMC加速器相比，RACE-IT在性能和能效方面均取得了显著提升。

> **摘要翻译:** Transformer模型代表了深度神经网络（DNN）的前沿，并在广泛的机器学习任务中表现出色。然而，处理这些模型需要大量的计算资源，并导致巨大的内存占用。尽管内存内计算（IMC）有望通过高计算并行度和最小数据移动来加速向量-矩阵乘法（VMM），但将其用于其他关键的DNN操作仍然是一项艰巨的任务。Transformer模型中广泛使用的复杂激活函数、Softmax和数据依赖型矩阵乘法（DMMuls）加剧了这一挑战。为了应对这一挑战，我们通过增强模拟内容可寻址存储器（ACAMs）以支持更广泛的操作，引入了一种可重构模拟计算引擎（RACE）。基于RACE，我们提出了RACE-IT加速器（意为用于内存内Transformer的RACE），以实现在模拟域高效执行Transformer模型的所有核心操作。鉴于我们提出的RACE在支持任意计算方面的灵活性，RACE-IT非常适合适应新兴和非传统的DNN架构，而无需进行硬件修改。我们将RACE-IT与各种加速器进行了比较。结果显示，RACE-IT的性能比最先进的GPU提升了453倍和15倍，能耗分别降低了354倍和122倍，这分别针对最先进的GPU和现有的Transformer专用IMC加速器。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [349] [A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs](https://arxiv.org/abs/2411.18148)
> *一种基于FPGA的运行时自适应Transformer神经网络加速器*

*Ehsan Kabir, Jason D. Bakos, David Andrews, Miaoqing Huang* | **Category: cs.AR, cs.LG, eess.SY** | **Updated: 2025-08-07**

**Keywords:** Transformer神经网络, FPGA, 运行时自适应, 加速器, 密集矩阵

**Comment:** 

> **TL;DR:** ADAPTOR是一种运行时自适应的FPGA加速器，用于Transformer神经网络，提高了能效和速度。

**AI_Comments:** ADAPTOR的创新之处在于其对Transformer网络中密集矩阵计算的运行时自适应能力，避免了处理复杂稀疏模式的挑战，同时在FPGA上实现了竞争性的性能。这对于在资源受限的FPGA设备上高效部署Transformer模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Transformer神经网络（TNN）在FPGA等资源受限设备上计算和内存需求高；现有定制加速器缺乏运行时适应性且依赖应用特定的稀疏模式，增加了硬件设计难度；为每个Transformer模型设计定制加速器复杂且耗时。

**Method:** 本文提出ADAPTOR，一种用于FPGA上Transformer编码器和解码器中密集矩阵计算的运行时自适应加速器。ADAPTOR通过增强处理单元和片上内存利用率，提高并行性并降低延迟。它采用高效的矩阵分块来分配资源，并进行完全量化以提高计算效率和可移植性。

**Result:** 在Xilinx Alveo U55C数据中心卡和VC707、ZCU102等嵌入式平台上评估，ADAPTOR比NVIDIA K80 GPU的能效高1.2倍，比i7-8700K CPU的能效高2.87倍。此外，与一些最先进的基于FPGA的加速器相比，它实现了1.7到2.25倍的加速。

**Conclusion:** ADAPTOR为FPGA上的Transformer加速提供了一个高效且更快的解决方案，相较于GPU、CPU和现有FPGA加速器具有显著优势。

> **ai_Abstract:** 本文提出了一种名为ADAPTOR的运行时自适应FPGA加速器，专为Transformer神经网络中的密集矩阵计算设计。它旨在解决Transformer模型在FPGA上高计算和内存需求以及现有加速器缺乏运行时适应性的问题。ADAPTOR通过优化处理单元和片上内存利用率、采用高效矩阵分块和完全量化来提高并行性和效率。实验结果表明，ADAPTOR在能效上优于GPU和CPU，并在速度上超越了部分现有FPGA加速器。

> **摘要翻译:** Transformer神经网络（TNN）在自然语言处理（NLP）、机器翻译和计算机视觉（CV）中表现出色，不依赖循环或卷积层。然而，它们对计算和内存要求很高，尤其是在FPGA等资源受限设备上。此外，Transformer模型在不同应用中的处理时间各异，需要具有特定参数的定制模型。为每个模型设计定制加速器既复杂又耗时。一些现有的定制加速器缺乏运行时适应性，并且通常依赖稀疏矩阵来降低延迟。然而，由于需要应用特定的稀疏模式，硬件设计变得更具挑战性。本文介绍了ADAPTOR，一种用于FPGA上Transformer编码器和解码器中密集矩阵计算的运行时自适应加速器。ADAPTOR增强了处理单元和片上内存的利用率，提高了并行性并降低了延迟。它结合了高效的矩阵分块技术，以在FPGA平台上分配资源，并经过完全量化以提高计算效率和可移植性。在Xilinx Alveo U55C数据中心卡以及VC707和ZCU102等嵌入式平台上的评估表明，我们的设计比NVIDIA K80 GPU的能效高1.2倍，比i7-8700K CPU的能效高2.87倍。此外，与一些最先进的基于FPGA的加速器相比，它实现了1.7到2.25倍的加速。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [356] [Basis Selection: Low-Rank Decomposition of Pretrained Large Language Models for Target Applications](https://arxiv.org/abs/2405.15877)
> *基选择：面向目标应用的预训练大型语言模型低秩分解*

*Yang Li, Daniel Agyei Asante, Changsheng Zhao, Ernie Chang, Yangyang Shi, Vikas Chandra* | **Category: cs.AR, cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 低秩分解, 模型压缩, 基选择, 应用定制

**Comment:** 

> **TL;DR:** 本文提出了一种名为“基选择”的低秩分解方法，用于压缩大型语言模型（LLMs），通过识别和移除特定应用中的冗余组件，显著减小模型尺寸并保持与最先进技术相当的准确性。

**AI_Comments:** 本文的创新点在于提出了“基选择”这一概念，通过识别和移除预训练LLMs中针对特定应用冗余的基，并引入新的有用基，实现了更精细化的模型压缩。这对于LLM在边缘设备上的部署具有重要意义，同时也为降低云端推理成本提供了有效途径。其方法针对性强，有望在保持性能的同时大幅提升LLM的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）虽然能显著提升各种应用性能，但计算和能耗密集，难以部署在资源受限设备（如个人电脑、移动/可穿戴设备）上，并在云服务器等资源丰富环境中产生高昂的推理成本。

**Method:** 本文提出一种低秩分解方法，通过将LLMs的权重矩阵表示为基组件的线性组合来压缩模型。该方法侧重于识别和移除预训练LLMs中特定应用不需要的冗余部分，只保留必要元素。具体而言，它会剪枝不相关的基，并用对特定应用有益的新基来增强模型。

**Result:** 在Llama 2-7b和-13B模型上，针对数学推理和代码生成等目标应用进行的深度压缩结果表明，该方法显著减小了模型尺寸，同时保持了与最先进的低秩压缩技术相当的准确性。

**Conclusion:** 本文提出的“基选择”低秩分解方法能够有效压缩大型语言模型，使其在资源受限环境下部署成为可能，并通过移除冗余组件和保留必要元素，在大幅减小模型尺寸的同时保持了与现有先进技术相当的性能。

> **ai_Abstract:** 本文提出了一种名为“基选择”的低秩分解方法，旨在解决大型语言模型（LLMs）计算和能耗高昂的问题，使其能更广泛地应用于资源受限设备和降低云端推理成本。该方法通过将LLMs的权重矩阵分解为基组件，识别并移除针对特定应用（如数学推理和代码生成）的冗余部分，同时引入新基来增强模型。实验结果表明，该方法在Llama 2模型上实现了显著的模型尺寸减小，同时保持了与现有先进低秩压缩技术相当的准确性。

> **摘要翻译:** 大型语言模型（LLMs）显著提升了各种应用的性能，但它们计算密集且能耗巨大。这使得它们难以部署在资源有限的设备上，例如个人电脑和移动/可穿戴设备，并导致在云服务器等资源丰富的环境中产生高昂的推理成本。为了扩展LLMs的使用，我们引入了一种低秩分解方法来有效地压缩这些模型，并根据特定应用的需求进行定制。我们观察到，在通用数据集上预训练的LLMs包含许多特定应用不需要的冗余组件。我们的方法侧重于识别和移除这些冗余部分，只保留目标应用所需的必要元素。具体来说，我们将LLMs的权重矩阵表示为基组件的线性组合。然后，我们剪枝不相关的基，并用对特定应用有益的新基来增强模型。在Llama 2-7b和-13B模型上，针对数学推理和代码生成等目标应用进行的深度压缩结果表明，我们的方法显著减小了模型尺寸，同时保持了与最先进的低秩压缩技术相当的准确性。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [365] [NP-Hardness and ETH-Based Inapproximability of Communication Complexity via Relaxed Interlacing](https://arxiv.org/abs/2508.05597)
> *通过松弛交错证明通信复杂度的NP-硬度和基于ETH的不可近似性*

*Serge Gaspers, Zixu He, Simon Mackenzie* | **Category: cs.CC, cs.DS, math.CO** | **Updated: 2025-08-07**

**Keywords:** 通信复杂度, NP-硬度, 不可近似性, 交错引理, 指数时间假设

**Comment:** 

> **TL;DR:** 本文证明了计算布尔函数的确定性通信复杂度D(f)是NP-难的，即使协议限制在常数次交替，解决了Yao在1979年提出的问题。此外，在指数时间假设下，还得到了一个无界增长的加性不可近似性间隙。

**AI_Comments:** 本文的创新之处在于其通过引入和扩展“交错”引理，并利用自相似的递归嵌入构造，解决了通信复杂性领域的长期开放问题。其证明了确定性通信复杂度的NP-硬度，甚至在常数次交替的强限制下，这比同期其他工作更为严格。此外，该工作为未来的下界构造提供了一个可重用的模块化框架，具有重要的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决Yao于1979年提出的一个长期问题：计算布尔函数的确定性通信复杂度D(f)是否是NP-难的，即使协议仅限于常数次交替。

**Method:** 本文的归约方法基于并扩展了Mackenzie和Saffidine引入的一系列结构性“交错”引理。通过自相似的小工具递归嵌入，并在指数时间假设下推导不可近似性。

**Result:** 主要结果是证明了计算布尔函数D(f)是NP-难的，即使协议限制在常数次交替。此外，在指数时间假设(ETH)下，得到了一个无界增长的加性不可近似性间隙。

**Conclusion:** 本文解决了确定性通信复杂度本身的复杂性问题，并开发了一个模块化框架，该框架可用于更广泛的归约，并有望解决通信复杂性中的其他长期问题。

> **ai_Abstract:** 本文证明了计算布尔函数的确定性通信复杂度D(f)是NP-难的，即使协议仅限于常数次交替，解决了Yao在1979年提出的一个问题。该证明利用了新的结构性“交错”引理和自相似的递归嵌入构造。此外，在指数时间假设下，本文还推导出了一个无界增长的加性不可近似性间隙。所开发的模块化框架有望应用于通信复杂性领域的其他问题。

> **摘要翻译:** 我们证明了即使协议限制在常数次交替，计算布尔函数的确定性通信复杂度D(f)也是NP-难的，这解决了Yao（1979）首次提出的问题。我们的归约建立并扩展了Mackenzie和Saffidine（arXiv:2505.12345）引入的一系列结构性“交错”引理；这些引理可以在未来的下界构造中作为黑盒重用。
我们的归约产生的实例允许仅使用常数次交替的最优协议，因此NP-硬度在比Hirahara、Ilango和Loff（arXiv:2507.06789）的同期独立工作（其证明需要无界交替）所考虑的更强的限制下成立。
由于我们构造中的小工具是自相似的，它们可以递归嵌入。我们概述了在指数时间假设下，这如何产生一个无界增长的加性不可近似性间隙，并且我们描绘了在固定常数加性误差内近似D(f)的NP-硬度的途径。基于ETH的不可近似性结果的完整细节将出现在未来的版本中。
除了解决确定性通信复杂度本身的复杂性问题，我们开发的模块化框架为更广泛的归约打开了大门，我们相信，它将有助于解决通信复杂性中的其他长期问题。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [373] [Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space](https://arxiv.org/abs/2508.04726)
> *近似线性伪多项式时间和多项式空间中的子集和问题*

*Thejas Radhika Sajith* | **Category: cs.CC, cs.DS** | **Updated: 2025-08-05**

**Keywords:** 子集和, 伪多项式时间, 多项式空间, 随机算法, 确定性算法

**Comment:** 

> **TL;DR:** 本文通过构建确定性算法和随机算法，肯定地回答了关于子集和问题算法时间和空间复杂度的两个开放性问题。

**AI_Comments:** 本文在子集和问题上取得了显著进展，通过肯定地回答了该领域的两个开放性问题，展示了其创新性。它在 Jin et al. 的工作基础上，引入了多点求值等技术来优化算法效率，尤其是在空间复杂度方面取得了改进，为解决这一经典问题提供了更优的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有子集和问题的算法在时间或空间复杂度上存在局限性。Jin et al. 提出了两个自然问题：是否存在一个在 poly(n, log t) 空间中运行的 $\tilde{O}(n+t)$ 时间算法，以及是否可能构建一个时间复杂度与Bellman算法相当的确定性多项式空间算法。本文旨在回答这两个问题。

**Method:** 本文基于Jin et al. 的框架，并利用基于多点求值的方法来加速其算法中的一个瓶颈步骤。

**Result:** 本文构建了一个确定性算法，其运行时间为 $\tilde{O}(nt)$，空间复杂度为 $\tilde{O}(n \log^2 t)$。同时，还构建了一个随机算法，其运行时间为 $\tilde{O}(n+t)$，空间复杂度为 $\tilde{O}(n^2 + n \log^2 t)$。

**Conclusion:** 本文肯定地回答了关于子集和问题算法的两个开放性问题，提出了在近似线性伪多项式时间和多项式空间下的新的确定性和随机算法。

> **ai_Abstract:** 子集和问题是一个经典的计算问题，旨在确定给定整数多重集中是否存在一个子集其和等于目标值。尽管Bellman的动态规划算法提供了基线解决方案，但后续研究致力于优化其时间和空间复杂度。例如，Bringmann提出了一个随机算法，而Jin et al. 则开发了多项式空间算法并提出了两个开放性问题：是否存在一个在多项式空间中运行的近线性时间算法，以及是否存在时间复杂度与Bellman算法相当的确定性多项式空间算法。本文通过扩展Jin et al. 的框架并引入多点求值方法，成功构建了新的确定性算法（$\tilde{O}(nt)$ 时间，$\tilde{O}(n \log^2 t)$ 空间）和随机算法（$\tilde{O}(n+t)$ 时间，$\tilde{O}(n^2 + n \log^2 t)$ 空间），从而肯定地回答了这两个问题。

> **摘要翻译:** 给定一个正整数的多重集 $A = \{a_1, \dots, a_n\}$ 和一个目标整数 $t$，子集和问题（Subset Sum）询问是否存在 $A$ 的一个子集其和为 $t$。Bellman [1957] 的经典动态规划算法运行时间为 $O(nt)$，空间复杂度为 $O(t)$。此后，在时间和空间复杂度方面都有多项改进。
值得注意的是，Bringmann [SODA 2017] 使用两步颜色编码技术获得了一个运行时间为 $\tilde{O}(n+t)$，空间复杂度为 $\tilde{O}(t)$ 的随机算法。另一方面，存在多项式空间算法——例如，Jin, Vyas 和 Williams [SODA 2021] 在 Bringmann 的算法基础上，利用Kane的对数空间算法中首次出现的巧妙代数技巧，获得了一个 $\tilde{O}(nt)$ 时间和 $\tilde{O}(\log(nt))$ 空间的算法。Jin 等人提出的一个自然问题是是否存在一个在 poly$(n, \log t)$ 空间中运行的 $\tilde{O}(n+t)$ 时间算法。另一个自然问题是是否可能构建一个时间复杂度与Bellman算法相当的确定性多项式空间算法。
在本文中，我们肯定地回答了这两个问题。我们建立在 Jin 等人给出的框架上，使用基于多点求值的方法来加速他们算法中的一个瓶颈步骤。我们构建了一个运行时间为 $\tilde{O}(nt)$，空间复杂度为 $\tilde{O}(n \log^2 t)$ 的确定性算法，以及一个运行时间为 $\tilde{O}(n+t)$，空间复杂度为 $\tilde{O}(n^2 + n \log^2 t)$ 的随机算法。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [381] [A full dichotomy for Holant$^c$, inspired by quantum computation](https://arxiv.org/abs/2201.03375)
> *受量子计算启发的Holant$^c$完全二分法*

*Miriam Backens* | **Category: cs.CC, quant-ph** | **Updated: 2025-08-07**

**Keywords:** Holant问题, 二分法, 量子计算, 量子信息理论, 复杂度分类

**Comment:** 

> **TL;DR:** 本文利用量子信息理论解释了Holant问题的现有结果，并推导出了Holant$^+$和Holant$^c$的两个新二分法，其中Holant$^+$的二分法也适用于平面图。

**AI_Comments:** 本文的创新之处在于将量子信息理论应用于Holant问题的复杂度分析，这为理解和分类这类问题提供了一个全新的视角。通过引入新的问题家族Holant$^+$并在此基础上完成Holant$^c$的完全二分法，本文显著扩展了Holant问题的理论边界。此外，在证明过程中发现的关于纠缠量子态的结果也展现了跨学科研究的潜力。

<details>
  <summary>Details</summary>

**Motivation:** Holant问题源于全息算法理论，该理论最初受量子计算概念启发。本文旨在利用量子信息理论简洁地解释Holant问题的现有结果，并推导出两个新的二分法。

**Method:** 本文采用量子信息理论来解释Holant问题的现有结果，并在此基础上推导出Holant$^+$和Holant$^c$这两个新家族问题的二分法。

**Result:** 本文推导出了两个新的二分法：一个是针对名为Holant$^+$的新问题家族，另一个是基于此的Holant$^c$的完全二分法。Holant$^+$的二分法在输入限制为平面图实例时也适用。在证明这些复杂度分类时，本文还推导出了一个关于纠缠量子态的原创结果。

**Conclusion:** 本文成功利用量子信息理论为Holant问题提供了简洁的解释，并为Holant$^+$和Holant$^c$这两个新的Holant问题家族建立了完整的复杂度二分法，同时在证明过程中得到了一个关于纠缠量子态的新结果。

> **ai_Abstract:** 本文利用量子信息理论，对参数化Holant问题进行了深入研究。作者不仅简洁地解释了现有Holant问题的结果，还成功推导出了Holant$^+$和Holant$^c$这两个新家族问题的完整复杂度二分法。其中，Holant$^+$的二分法在平面图上依然成立。此外，在复杂度分类的证明过程中，本文还提出了一个关于纠缠量子态的原创性发现。

> **摘要翻译:** Holant问题是一类计数问题，由代数复数值约束函数集参数化，并在图上定义。它们源于全息算法理论，该理论最初受量子计算概念启发。在此，我们利用量子信息理论简洁地解释了Holant问题的现有结果，并推导出了两个新的二分法：一个针对我们称之为Holant$^+$的新问题家族，另一个在此基础上针对Holant$^c$的完全二分法。这两个Holant问题家族假设某些一元约束函数可用——Holant$^c$的情况下是两个钉扎函数，Holant$^+$的情况下是四个函数——否则允许任意的代数复数值约束函数集。Holant$^+$的二分法在输入限制为平面图实例时也适用。在证明这些复杂度分类时，我们推导出了一个关于纠缠量子态的原创结果。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [421] [PriceFM: Foundation Model for Probabilistic Electricity Price Forecasting](https://arxiv.org/abs/2508.04875)
> *PriceFM：用于概率性电力价格预测的基础模型*

*Runyao Yu, Chenhui Gu, Jochen Stiasny, Qingsong Wen, Wasim Sarwar Dilov, Lianlian Qi, Jochen L. Cremer* | **Category: cs.CE** | **Updated: 2025-08-06**

**Keywords:** 电力价格预测, 基础模型, 时空模型, 图神经网络, 概率预测

**Comment:** 

> **TL;DR:** PriceFM是一个用于欧洲多区域、多时间步、多分位数概率性电力价格预测的时空基础模型，它利用图归纳偏置来捕捉空间相互依赖性，并在新数据集上表现优于现有基线。

**AI_Comments:** 本文的创新之处在于提出了一个结合图归纳偏置的时空基础模型（PriceFM），以解决欧洲电力市场中复杂的空间相互依赖性和不确定性问题。同时，构建并发布了一个大型、全面的欧洲电力市场数据集，这对于推动该领域的研究具有重要意义。模型的有效性及其对空间上下文重要性的强调，为未来的电力价格预测研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 欧洲电力市场日益整合和物理互联，导致电力价格预测面临独特挑战。现有方法未能有效捕捉电力市场中复杂的空间相互依赖性和不确定性。

**Method:** 本文提出了PriceFM，一个时空基础模型，它整合了基于图的归纳偏置，以捕捉互联电力市场中的空间相互依赖性。该模型专为多区域、多时间步、多分位数概率性电力价格预测而设计。此外，还构建了一个涵盖24个欧洲国家（38个区域）、从2022年1月1日到2025年1月1日的综合数据集。

**Result:** 广泛的实验和消融研究证实了PriceFM模型的有效性，它持续优于竞争基线，并突出了电力市场中空间上下文的重要性。

**Conclusion:** PriceFM通过其独特的时空建模和图归纳偏置，成功解决了欧洲电力市场中复杂的空间相互依赖性和不确定性问题，显著提高了概率性电力价格预测的准确性。

> **ai_Abstract:** PriceFM是一个创新的时空基础模型，专为欧洲电力市场的概率性电力价格预测而设计。它通过整合图归纳偏置来有效捕捉复杂的空间相互依赖性，并利用一个新颖的涵盖24个欧洲国家的数据集。实验结果表明，PriceFM在多区域、多时间步、多分位数预测方面表现出色，显著优于现有基线，强调了空间信息在电力价格预测中的关键作用。

> **摘要翻译:** 欧洲的电力价格预测由于其日益整合和物理互联的电力市场而面临独特的挑战。尽管深度学习和基础模型的最新进展在通用时间序列预测方面取得了实质性改进，但大多数现有方法未能捕捉电力市场中固有的复杂空间相互依赖性和不确定性。在本文中，我们通过引入一个涵盖24个欧洲国家（38个区域）、从2022年1月1日到2025年1月1日的全面且最新的数据集来解决这些限制。在此基础上，我们提出了PriceFM，一个时空基础模型，它整合了基于图的归纳偏置，以捕捉互联电力市场中的空间相互依赖性。该模型专为多区域、多时间步、多分位数概率性电力价格预测而设计。广泛的实验和消融研究证实了模型的有效性，它持续优于竞争基线，并突出了电力市场中空间上下文的重要性。数据集和代码可在https://github.com/runyao-yu/PriceFM找到。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [434] [Sentiment-Aware Stock Price Prediction with Transformer and LLM-Generated Formulaic Alpha](https://arxiv.org/abs/2508.04975)
> *基于Transformer和LLM生成公式化Alpha的情绪感知股价预测*

*Qizhao Chen, Hiroaki Kawashima* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 股价预测, 大型语言模型, 公式化Alpha, Transformer, 金融数据

**Comment:** 

> **TL;DR:** 本文提出一个新颖框架，利用LLM生成公式化Alpha作为高层特征，结合Transformer等模型进行情绪感知股价预测，显著提高了预测准确性并增强了可解释性。

**AI_Comments:** 该论文的创新点在于将LLM的能力应用于金融领域，特别是自动化生成公式化Alpha，解决了传统方法耗时且难以扩展的问题。通过将LLM生成的Alpha作为高层特征，而非直接交易信号，巧妙地融入到现有预测模型中，提升了预测性能。同时，LLM提供的自然语言推理显著增强了模型的可解释性，这对金融决策至关重要。这为量化金融和人工智能的交叉领域开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统上，交易员和量化分析师通过手动构建公式化Alpha来解决Alpha衰减问题，但这一过程耗时且难以扩展。随着大型语言模型（LLM）的最新进展，现在可以利用LLM的推理能力自动化Alpha的生成。

**Method:** 本文引入了一个新颖的框架，将基于提示的LLM与Transformer模型集成用于股价预测。LLM首先使用结构化输入（如历史股票特征、技术指标、目标公司和相关公司的情绪得分）生成多样化和自适应的Alpha。这些Alpha被视为捕获金融数据中复杂依赖关系的高级特征。然后，这些LLM生成的Alpha特征被输入到Transformer、LSTM、TCN、SVR和Random Forest等预测模型中，以预测未来的股票价格。

**Result:** 实验结果表明，LLM生成的Alpha显著提高了预测准确性。此外，LLM提供的自然语言推理增强了预测的可解释性和透明度。

**Conclusion:** LLM生成的公式化Alpha能够显著提高股价预测的准确性，并且其伴随的自然语言推理提升了预测的可解释性和透明度，支持更明智的金融决策。

> **ai_Abstract:** 本文提出了一种结合大型语言模型（LLM）和Transformer模型的新型框架，用于情绪感知股价预测。该框架利用LLM生成公式化Alpha，这些Alpha被用作高级特征，捕捉金融数据中的复杂依赖关系，并输入到预测模型中。实验证明，LLM生成的Alpha显著提升了预测准确性，并且LLM提供的自然语言推理增强了预测的可解释性和透明度，从而支持更明智的金融决策。

> **摘要翻译:** 传统上，交易员和量化分析师通过手动构建公式化Alpha来解决Alpha衰减问题，这些数学表达式通过领域专业知识和反复试验来识别金融数据中的模式或信号。这一过程通常耗时且难以扩展。随着大型语言模型（LLM）的最新进展，现在可以利用LLM的推理能力自动化Alpha的生成。本文引入了一个新颖的框架，将基于提示的LLM与Transformer模型集成用于股价预测。LLM首先使用结构化输入（如历史股票特征（收盘价、开盘价、最高价、最低价、成交量）、技术指标、目标公司和相关公司的情绪得分）生成多样化和自适应的Alpha。这些Alpha不直接用于交易，而是被视为捕获金融数据中复杂依赖关系的高级特征。为了评估这些LLM生成公式化Alpha的有效性，Alpha特征随后被输入到Transformer、LSTM、TCN、SVR和Random Forest等预测模型中，以预测未来的股票价格。实验结果表明，LLM生成的Alpha显著提高了预测准确性。此外，LLM提供的自然语言推理增强了预测的可解释性和透明度，支持更明智的金融决策。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [445] [Fuzzy Decisions on Fluid Instabilities: Autoencoder-Based Reconstruction meets Rule-Based Anomaly Classification](https://arxiv.org/abs/2508.05418)
> *流体不稳定性中的模糊决策：基于自编码器的重建与基于规则的异常分类*

*Bharadwaj Dogga, Gibin M. Raju, Wilhelm Louw, Kelly Cohen* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 冲击波分类, 自编码器, 模糊推理系统, 无监督学习, 流体不稳定性

**Comment:** 

> **TL;DR:** 本研究提出一种结合自编码器和模糊推理系统的混合框架，用于在有限标签数据下对阴影图成像中的冲击波进行可解释的无监督分类。

**AI_Comments:** 这篇论文的创新点在于结合了无监督学习（自编码器）和可解释性（模糊推理系统），解决了流体不稳定性诊断中标记数据不足和结果难以解释的痛点。这种混合方法不仅提高了分类效果，还为实际工业应用中的实时诊断提供了可能性，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 阴影图成像中的冲击波分类由于标记数据有限和流结构复杂而具有挑战性。

**Method:** 提出一个混合框架，结合无监督自编码器模型和模糊推理系统来生成和解释异常图。具体地，评估了混合$\beta$-VAE自编码器与模糊规则系统。

**Result:** 在评估的方法中，混合$\beta$-VAE自编码器与模糊规则系统最有效地捕获了连贯的冲击特征，并整合了空间上下文以增强异常分类。

**Conclusion:** 该方法实现了对流体扰动的可解释、无监督分类，并为实验和工业流体应用中的实时、物理信息诊断奠定了基础。

> **ai_Abstract:** 本文针对阴影图成像中冲击波分类面临的标记数据稀缺和流结构复杂性挑战，提出了一种创新的混合框架。该框架将无监督自编码器模型（特别是$\beta$-VAE）与模糊推理系统相结合，用于生成和解释异常图。研究结果表明，这种混合方法能有效捕捉冲击波特征并增强异常分类，为流体扰动的可解释、无监督诊断以及未来实时、物理信息诊断奠定了基础。

> **摘要翻译:** 阴影图成像中的冲击波分类由于标记数据有限和流结构复杂而具有挑战性。本研究提出了一个混合框架，结合无监督自编码器模型和模糊推理系统来生成和解释异常图。在评估的方法中，混合$\beta$-VAE自编码器与模糊规则系统最有效地捕获了连贯的冲击特征，整合了空间上下文以增强异常分类。由此产生的方法能够对流体扰动进行可解释的无监督分类，并为实验和工业流体应用中的实时、物理信息诊断奠定了基础。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [453] [Categorising SME Bank Transactions with Machine Learning and Synthetic Data Generation](https://arxiv.org/abs/2508.05425)
> *使用机器学习和合成数据生成对中小企业银行交易进行分类*

*Aluffi Pietro Alessandro, Brandi Jess, Marya Bazzi, Kate Kennedy, Matt Arderne, Daniel Rodrigues, Martin Lotz* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 中小企业, 银行交易分类, 机器学习, 合成数据生成, 现金流贷款

**Comment:** 

> **TL;DR:** 本文提出了一种利用机器学习和合成数据生成来分类中小企业银行交易的方法，以解决数据稀缺、噪音和不平衡等挑战，并实现了高精度。

**AI_Comments:** 本文的创新点在于结合了合成数据生成来解决中小企业交易数据稀缺、非结构化和不平衡的挑战，这对于金融领域的数据分析是一个重要的贡献。其提出的三组件管道设计思路清晰，且实验结果验证了方法的有效性和实用性，尤其是在高置信度预测方面表现突出。该框架为构建稳健的分类系统提供了可行途径，对于促进中小企业融资具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管中小企业对经济贡献巨大，但由于信息不对称，它们在获得传统融资方面面临持续障碍。现金流贷款已成为一种有前景的替代方案，但其有效性取决于对交易层面数据的准确建模。中小企业交易分析的主要挑战在于文本描述的非结构化性质，其特点是极度缩写、上下文有限和标签分布不平衡。

**Method:** 本文提出了一种银行分类流程，利用合成数据生成来扩充现有交易数据集。该方法包括三个核心组件：(1) 一个复制交易属性同时保留上下文和语义含义的合成数据生成模块；(2) 一个在此丰富数据集上训练的微调分类模型；(3) 一个将模型输出与真实世界标签分布对齐的校准方法。

**Result:** 实验结果表明，该方法在保留数据上实现了 73.49% (±5.09) 的标准准确率，高置信度预测的准确率达到 90.36% (±6.52)。该模型在不同类型的中小企业和交易中表现出稳健的泛化能力。

**Conclusion:** 通过解决核心数据挑战，即稀缺性、噪音和不平衡，该框架为在数据稀疏的中小企业贷款环境中构建稳健的分类系统提供了一个实用的解决方案，适用于现金流贷款应用中的实际部署。

> **ai_Abstract:** 本文提出了一种利用机器学习和合成数据生成来分类中小企业银行交易的管道。针对中小企业交易数据非结构化、稀缺、噪音和不平衡的挑战，该方法包括合成数据生成、微调分类模型和校准模块。实验结果表明，该方法在分类准确性上表现出色，并具有良好的泛化能力，为现金流贷款应用提供了实用的解决方案。

> **摘要翻译:** 尽管中小企业（SMEs）对经济贡献巨大，但由于信息不对称，它们在获得传统融资方面面临持续障碍。现金流贷款已成为一种有前景的替代方案，但其有效性取决于对交易层面数据的准确建模。中小企业交易分析的主要挑战在于文本描述的非结构化性质，其特点是极度缩写、上下文有限和标签分布不平衡。虽然消费者交易描述通常在个体之间显示出显著的共性，但中小企业交易描述通常是非标准化的，并且在不同企业和行业之间不一致。为了解决其中一些挑战，我们提出了一种银行分类流程，利用合成数据生成来扩充现有交易数据集。我们的方法包括三个核心组件：(1) 一个复制交易属性同时保留上下文和语义含义的合成数据生成模块；(2) 一个在此丰富数据集上训练的微调分类模型；以及 (3) 一个将模型输出与真实世界标签分布对齐的校准方法。实验结果表明，我们的方法在保留数据上实现了 73.49% (±5.09) 的标准准确率，高置信度预测的准确率达到 90.36% (±6.52)。该模型在不同类型的中小企业和交易中表现出稳健的泛化能力，这使其适用于现金流贷款应用中的实际部署。通过解决核心数据挑战，即稀缺性、噪音和不平衡，我们的框架为在数据稀疏的中小企业贷款环境中构建稳健的分类系统提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [461] [Deconstructing the Crystal Ball: From Ad-Hoc Prediction to Principled Startup Evaluation with the SAISE Framework](https://arxiv.org/abs/2508.05491)
> *拆解水晶球：从临时预测到SAISE框架下的规范化创业公司评估*

*Seyed Mohammad Ali Jafari, Ali Mobini Dehkordi, Ehsan Chitsaz, Yadollah Yaghoobzadeh* | **Category: cs.CE, econ.GN** | **Updated: 2025-08-07**

**Keywords:** 创业公司评估, 人工智能, 系统文献综述, SAISE框架, 预测模型

**Comment:** 

> **TL;DR:** 本文通过系统文献综述揭示了AI驱动的创业公司评估领域的方法学缺陷，并提出了SAISE框架以实现更规范、一致的评估。

**AI_Comments:** 这篇论文通过其全面的系统文献综述，揭示了AI驱动的创业公司评估领域当前面临的核心方法论挑战，特别是其在工具使用上的趋同与方法学严谨性上的分歧。SAISE框架的提出具有重要创新性，它提供了一个急需的、结构化的指导，有望将该领域的研究从目前的“临时”状态提升到更“规范”的水平，极大地提高了未来研究的可比性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI驱动的创业公司评估研究方法碎片化，采用临时方法，导致成功定义不一致、特征缺乏理论基础、缺乏严格验证，从而限制了预测模型的可比性、可靠性和实用性。

**Method:** 本文进行了一项全面的系统文献综述，分析了57项实证研究，系统性地梳理了AI驱动的创业公司预测领域的特征、算法、数据源和评估实践。在此基础上，提出了系统化AI驱动的创业公司评估（SAISE）框架。

**Result:** 系统综述揭示了该领域的一个悖论：工具包（风险投资数据库和基于树的集成方法）的高度趋同与方法学严谨性的显著分歧。研究识别出四个根本性弱点：成功定义碎片化、理论驱动与数据驱动特征工程之间的鸿沟、常见与最佳实践模型验证之间的差距，以及数据伦理和可解释性方法的萌芽。

**Conclusion:** 为了解决AI驱动的创业公司评估领域的方法学缺陷，本文提出了SAISE框架，这是一个五阶段的规范性路线图，旨在指导研究人员从临时预测转向规范化评估，从而为该领域的研究提供新的标准。

> **ai_Abstract:** 本文通过对57项AI驱动的创业公司评估实证研究进行系统性综述，揭示了该领域在方法论上的碎片化和缺陷，包括成功定义不一致、特征工程缺乏理论指导、验证不严谨以及数据伦理和可解释性不足。为解决这些问题，文章提出了SAISE（系统化AI驱动的创业公司评估）框架，这是一个包含五阶段的规范性路线图，旨在为研究人员提供一个从临时预测到规范化评估的连贯方法，从而提升研究的可比性、鲁棒性和实践相关性。

> **摘要翻译:** 人工智能（AI）融入创业公司评估代表着一项重大的技术转变，然而支撑这一转变的学术研究在方法论上仍然支离破碎。现有研究常常采用临时性的方法，导致研究成果在成功定义上不一致，特征缺乏理论基础，并且缺乏严格的验证。这种碎片化严重限制了当前预测模型的可比性、可靠性和实用性。
为了弥补这一关键空白，本文对57项实证研究进行了全面的系统文献综述。我们通过系统性地梳理定义AI驱动的创业公司预测领域的特征、算法、数据源和评估实践，解构了当前的技术现状。我们的综合分析揭示了该领域的一个核心悖论：在常用工具包——风险投资数据库和基于树的集成方法——上高度趋同，但在方法学严谨性上却存在显著分歧。我们识别出四个根本性弱点：“成功”定义碎片化、理论驱动与数据驱动特征工程之间的鸿沟、常见与最佳实践模型验证之间的巨大差距，以及数据伦理和可解释性方法的萌芽。
针对这些发现，我们的主要贡献是提出了系统化AI驱动的创业公司评估（SAISE）框架。这个新颖的、五阶段的规范性路线图旨在指导研究人员从临时预测转向规范化评估。通过强制推行一个连贯的、端到端的方法论，强调阶段感知的问题定义、理论驱动的数据合成、规范的特征工程、严格的验证和风险感知的解释，SAISE框架为在这个快速成熟的领域进行更具可比性、鲁棒性和实践相关性的研究提供了新标准。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [469] [Latent Space Diffusion for Topology Optimization](https://arxiv.org/abs/2508.05624)
> *潜在空间扩散用于拓扑优化*

*Aaron Lutheran, Srijan Das, Alireza Tabarraei* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 拓扑优化, 潜在扩散模型, 变分自编码器, 条件生成, 结构设计

**Comment:** 

> **TL;DR:** 本文提出了一种结合潜在扩散模型（LDMs）和变分自编码器（VAEs）的新型框架，用于快速、条件生成优化后的拓扑结构，解决了传统梯度方法扩展性差的问题，并在性能上优于现有扩散方法。

**AI_Comments:** 该论文的创新之处在于将潜在扩散模型与变分自编码器结合，并巧妙地利用物理意义上的场进行条件化生成，同时引入辅助损失函数来确保生成设计的物理真实性和可制造性。这为拓扑优化提供了一个有前景的、可扩展的替代方案，特别是在处理高分辨率和高维度问题时，有望显著提高效率和设计质量。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于梯度方法的拓扑优化在分辨率和维度增加时扩展性差，因为需要重复的有限元分析和敏感性评估。

**Method:** 本文提出了一种结合潜在扩散模型（LDMs）和变分自编码器（VAEs）的新型框架，用于快速、条件生成优化后的拓扑结构。该方法通过将物理意义上的场（如von Mises应力、应变能密度、体积分数和载荷信息）作为密集输入通道来条件化生成过程。此外，引入了辅助损失函数来惩罚浮动材料、载荷不平衡和体积分数偏差，以鼓励物理真实和可制造的设计。

**Result:** 在大型合成数据集上的数值实验表明，所提出的VAE-LDM框架在柔度精度、体积控制和结构连通性方面优于现有的基于扩散的方法。

**Conclusion:** 所提出的VAE-LDM框架为拓扑优化提供了一种鲁棒且可扩展的替代方案，优于传统的和现有的扩散方法。

> **ai_Abstract:** 本文提出了一种基于潜在扩散模型（LDMs）和变分自编码器（VAEs）的拓扑优化新框架，旨在克服传统梯度方法在扩展性方面的局限。该方法通过对物理场进行条件化生成，并引入辅助损失函数来确保设计的物理真实性和可制造性。实验结果表明，该框架在柔度精度、体积控制和结构连通性方面均优于现有扩散方法，提供了一种鲁棒且可扩展的拓扑优化解决方案。

> **摘要翻译:** 拓扑优化通过在定义域内优化材料分布，实现高效结构的自动化设计。然而，传统的基于梯度的方法由于需要重复的有限元分析和灵敏度评估，在分辨率和维度增加时，其扩展性往往较差。在这项工作中，我们提出了一种新颖的框架，将潜在扩散模型（LDMs）与变分自编码器（VAEs）相结合，以实现优化拓扑的快速、条件生成。与以往的方法不同，我们的方法将生成过程条件化于具有物理意义的场，具体是von Mises应力、应变能密度、体积分数和载荷信息，并将其嵌入为密集输入通道。为了进一步指导生成过程，我们引入了辅助损失函数，惩罚浮动材料、载荷不平衡和体积分数偏差，从而鼓励物理真实和可制造的设计。在大型合成数据集上的数值实验表明，我们的VAE-LDM框架在柔度精度、体积控制和结构连通性方面优于现有的基于扩散的方法，为传统方法提供了一个鲁棒且可扩展的替代方案。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [477] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
> *大型语言模型是动态治疗规划师吗？一项从先验知识注入角度进行的计算机模拟研究*

*Zhiyao Luo, Tingting Zhu* | **Category: cs.CE, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 动态治疗方案, 胰岛素给药, 计算机模拟, 提示工程

**Comment:** 

> **TL;DR:** 本研究在计算机模拟的1型糖尿病环境中评估了大型语言模型（LLMs）作为动态胰岛素给药代理的能力，发现精心设计的零样本提示可以使小型LLMs达到与经过训练的强化学习代理相当或更优的性能，但LLMs也存在局限性，例如推理错误和对复杂生理动态的捕获不足。

**AI_Comments:** 这项研究具有重要的创新性，它探索了LLMs在医疗决策支持，特别是动态治疗规划中的应用潜力，提供了一种无需大量环境特定训练的知识注入方式。其重要性在于，它为克服传统强化学习在临床部署中的工程障碍提供了新的思路。然而，研究也明确指出了LLMs的局限性，如在复杂推理和处理隐性生理状态时的不足，以及可能出现的“幻觉”问题，这对于LLMs在高度敏感的医疗领域中的应用提出了警示。未来需要结合更强的生理建模能力和严格的验证。

<details>
  <summary>Details</summary>

**Motivation:** 基于强化学习（RL）的动态治疗方案（DTRs）在自动化复杂临床决策方面具有潜力，但其部署因需要大量工程来注入临床知识和确保患者安全而受阻。大型语言模型（LLMs）的最新进展提供了一种互补方法，通过语言提示自然地嵌入隐式先验知识和临床启发式，而无需进行特定于环境的训练。

**Method:** 本研究在计算机模拟的1型糖尿病模拟器中，严格评估了开源大型语言模型作为动态胰岛素给药代理的性能。研究将LLMs的零样本推理性能与经过专门训练的小型神经网络强化学习代理（SRAs）进行了比较。

**Result:** 研究结果表明，精心设计的零样本提示能使较小的LLMs（例如Qwen2.5-7B）在临床性能上达到与经过广泛训练的SRAs相当或更优的水平，尤其是在稳定患者群体中。然而，LLMs也表现出显著的局限性，例如在链式思考（CoT）提示下胰岛素给药过于激进，暴露出算术幻觉、时间误解和不一致的临床逻辑等关键故障模式。此外，纳入关于潜在临床状态（如膳食）的显式推理，性能提升微乎其微，这突显了当前模型仅通过文本推理捕获复杂、隐藏生理动态的局限性。

**Conclusion:** 研究结果提倡谨慎而乐观地将大型语言模型整合到临床工作流程中，强调了有针对性的提示工程、仔细的验证以及潜在的混合方法（结合语言推理和结构化生理建模）的必要性，以实现安全、稳健和临床有效的决策支持系统。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）作为动态治疗规划师在计算机模拟的1型糖尿病胰岛素给药中的潜力。研究发现，通过精心设计的零样本提示，小型LLMs在稳定患者群中能达到与经过训练的强化学习代理相当或更优的临床性能。然而，LLMs在复杂推理和处理隐藏生理动态方面存在局限性，如可能出现算术幻觉和时间误解，导致不稳定的胰岛素给药。因此，论文建议在临床应用中谨慎整合LLMs，并强调了精细的提示工程、严格验证以及结合语言推理与结构化生理建模的混合方法的重要性。

> **摘要翻译:** 强化学习（RL）驱动的动态治疗方案（DTRs）在自动化复杂临床决策方面前景广阔，但其在实际部署中仍受到阻碍，原因在于注入临床知识和确保患者安全需要大量的工程投入。大型语言模型（LLMs）的最新进展提示了一种互补方法，即通过语言提示自然地嵌入隐式先验知识和临床启发式，而无需进行特定于环境的训练。在本研究中，我们严格评估了开源LLMs在计算机模拟的1型糖尿病模拟器中作为动态胰岛素给药代理的性能，并将其零样本推理性能与经过专门训练的小型神经网络强化学习代理（SRAs）进行了比较。我们的结果表明，精心设计的零样本提示能够使较小的LLMs（例如Qwen2.5-7B）在临床性能上达到与经过广泛训练的SRAs相当或更优的水平，特别是在稳定患者群体中。然而，LLMs也表现出显著的局限性，例如在链式思考（CoT）推理提示下胰岛素给药过于激进，这凸显了包括算术幻觉、时间误解和不一致临床逻辑在内的关键故障模式。纳入关于潜在临床状态（例如膳食）的显式推理，性能提升微乎其微，这强调了当前模型仅通过文本推理捕获复杂、隐藏生理动态的局限性。我们的发现提倡谨慎而乐观地将LLMs整合到临床工作流程中，强调了有针对性的提示工程、仔细的验证以及潜在的混合方法（结合语言推理和结构化生理建模）的必要性，以实现安全、稳健和临床有效的决策支持系统。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [485] [Task-Based Programming for Adaptive Mesh Refinement in Compressible Flow Simulations](https://arxiv.org/abs/2508.05020)
> *用于可压缩流体模拟中自适应网格细化的基于任务的编程*

*Anjiang Wei, Hang Song, Mert Hidayetoglu, Elliott Slaughter, Sanjiva K. Lele, Alex Aiken* | **Category: cs.CE, cs.DC, cs.MS** | **Updated: 2025-08-07**

**Keywords:** 自适应网格细化, 可压缩流体模拟, 基于任务的编程, Regent, 性能优化

**Comment:** 

> **TL;DR:** 本文开发了一个基于Regent语言的自适应网格细化（AMR）数值求解器，用于可压缩流体模拟，解决了动态数据结构和任务启动开销等挑战，并通过任务融合和GPU内核生成实现了显著的性能提升。

**AI_Comments:** 该论文在高性能计算领域具有重要意义，特别是在利用现代编程模型（如Legion/Regent）优化科学计算方面。其创新点在于将任务融合和自动化GPU内核生成应用于AMR，显著提升了可压缩流体模拟的计算效率。18倍和9.7倍的加速比表明了该方法的巨大潜力，对于推动大规模科学模拟的发展具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 高阶可压缩流体求解器在科学应用中至关重要，而自适应网格细化（AMR）是降低计算成本的关键技术。本文旨在解决在Regent编程模型中实现AMR所面临的挑战，例如动态数据结构、网格有效性维护以及减少任务启动开销。

**Method:** 开发了一个基于Regent语言的AMR数值求解器。解决了实现AMR的几个挑战，包括：1) 补丁细化/粗化的动态数据结构；2) 网格有效性强制；3) 通过任务融合减少任务启动开销。同时，利用简单的注解实现了自动GPU内核生成。

**Result:** 实验结果显示，任务融合实现了18倍的加速。针对目标内核，通过简单注解实现的自动化GPU内核生成带来了9.7倍的加速。该方法通过欧拉方程控制的两个典型可压缩流体问题的模拟得到了验证。

**Conclusion:** 本文成功开发了一个高效的基于Regent的AMR数值求解器，并通过任务融合和自动化GPU内核生成显著提升了可压缩流体模拟的性能，解决了AMR实现中的关键挑战。

> **ai_Abstract:** 本文介绍了一个使用Regent编程语言开发的，用于可压缩流体模拟的基于自适应网格细化（AMR）的数值求解器。该工作解决了在Regent中实现AMR的挑战，包括动态数据结构管理和网格有效性维护，并通过任务融合和自动GPU内核生成显著提升了性能。实验证明，任务融合带来了18倍的加速，而GPU内核生成实现了9.7倍的加速，验证了该方法在典型可压缩流体问题上的有效性。

> **摘要翻译:** 高阶可压缩流体求解器在科学应用中至关重要。自适应网格细化（AMR）是集中分辨率于感兴趣区域以降低计算成本的关键技术。在这项工作中，我们使用Regent（Legion编程模型的高级编程语言）开发了一个基于AMR的数值求解器。我们解决了在Regent中实现AMR相关的几个挑战。这些挑战包括用于补丁细化/粗化的动态数据结构、网格有效性强制以及通过任务融合减少任务启动开销。实验结果表明，任务融合实现了18倍的加速，而通过简单注解自动生成GPU内核使目标内核获得了9.7倍的加速。我们通过欧拉方程控制的两个典型可压缩流体问题的模拟展示了我们的方法。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [493] [Echo State Networks for Bitcoin Time Series Prediction](https://arxiv.org/abs/2508.05416)
> *回声状态网络在比特币时间序列预测中的应用*

*Mansi Sharma, Enrico Sartor, Marc Cavazza, Helmut Prendinger* | **Category: cs.CE, cs.LG, cs.NE** | **Updated: 2025-08-07**

**Keywords:** 回声状态网络, 比特币, 时间序列预测, 混沌分析, 机器学习

**Comment:** 

> **TL;DR:** 本研究首次探索使用回声状态网络（ESNs）预测比特币价格，并在混沌分析中发现ESNs在极端波动下表现优于现有机器学习方法。

**AI_Comments:** 本研究的创新点在于首次将回声状态网络（ESNs）应用于加密货币预测，并结合混沌分析验证了其在极端波动条件下的优越性能。这为加密货币价格预测提供了一种新的、更鲁棒的方法。

<details>
  <summary>Details</summary>

**Motivation:** 由于高波动性和非平稳性，预测股票和加密货币价格极具挑战性，而先前的研究表明回声状态网络（ESNs）能有效建模短期股市走势并捕捉非线性模式。

**Method:** 本研究探索使用回声状态网络（ESNs）进行加密货币预测，特别是在极端波动时期。同时，通过Lyapunov指数进行混沌分析。

**Result:** 研究发现，回声状态网络（ESNs）在比特币时间序列预测中表现显著优于现有机器学习方法。结果与Lyapunov指数分析一致，表明ESNs在混沌时期具有鲁棒性，并在高混沌条件下优于Boosting和朴素方法。

**Conclusion:** 回声状态网络（ESNs）在预测比特币时间序列方面表现出色，尤其在极端波动和混沌时期展现出强大的鲁棒性和优越性。

> **ai_Abstract:** 本研究首次将回声状态网络（ESNs）应用于比特币时间序列预测，旨在解决加密货币高波动性和非平稳性带来的挑战。通过Lyapunov指数进行的混沌分析表明，ESNs能够有效捕捉非线性模式，并在极端波动和混沌时期表现出强大的鲁棒性，显著优于传统的机器学习方法。

> **摘要翻译:** 预测股票和加密货币价格由于高波动性和非平稳性而具有挑战性，这些受到经济变化和市场情绪等因素的影响。先前的研究表明，回声状态网络（ESNs）可以有效地模拟短期股票市场走势，捕捉动态数据中的非线性模式。据我们所知，这项工作是首次探索将ESNs用于加密货币预测，特别是在极端波动期间。我们还通过Lyapunov指数在混沌时期进行了混沌分析，结果表明我们的方法显著优于现有的机器学习方法。我们的发现与Lyapunov指数分析一致，表明ESNs在混沌时期具有鲁棒性，并且在高混沌条件下优于Boosting和朴素方法。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [499] [Constitutive Manifold Neural Networks](https://arxiv.org/abs/2506.13648)
> *构成流形神经网络*

*Wouter J. Schuttert, Mohammed Iqbal Abdul Rasheed, Bojana Rosić* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 对称正定张量, 流形学习, 神经网络, 各向异性材料, 不确定性量化

**Comment:** 

> **TL;DR:** 提出了一种新的神经网络CMNN，通过将SPD张量映射到切线空间来处理其几何结构，从而在工程应用中提高了张量数据的学习性能。

**AI_Comments:** 这项工作通过引入CMNN，创新性地解决了传统神经网络在处理对称正定（SPD）张量数据时未能保留其几何结构的问题。其核心思想是将张量数据从弯曲流形映射到切线空间，这是一种巧妙且有效的方法，能够更好地捕获数据的内在特性。这对于需要处理复杂张量数据的工程和科学领域具有重要意义，尤其是在材料科学、计算力学等领域。该方法有望提高模型在复杂材料行为预测和不确定性量化方面的准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 工程复合材料的各向异性材料特性（如热导率）因材料异质性和制造不确定性而表现出变异性，这些特性被建模为对称正定（SPD）张量，存在于弯曲的黎曼流形上。在随机框架中，需要保留SPD结构和张量的空间对称性。传统的神经网络（FNN）不适合直接处理SPD张量，因为直接使用张量分量作为输入特征无法保留其固有的几何结构，导致性能不佳。因此，需要一种能够有效处理和学习张量数据几何特性的计算高效的替代模型。

**Method:** 研究引入了构成流形神经网络（CMNN）。CMNN通过在输入层将SPD张量从弯曲流形映射到局部切线空间（一个平坦的向量空间），从而保留数据集中统计和几何信息。这种方法通过张量的谱分解实现不确定性参数化为尺度和旋转分量，并将其通过基于物理的正向模型传播。

**Result:** 通过一个涉及随机各向异性导热的稳态热传导案例研究表明，与传统多层感知器（MLP）相比，这种保留几何结构的神经网络显著增强了学习性能。

**Conclusion:** 研究结果强调了在工程应用中处理张量值数据时，流形感知方法的重要性。

> **ai_Abstract:** 本研究针对工程复合材料中各向异性材料特性（表现为对称正定张量）的建模挑战，提出了一种新型神经网络——构成流形神经网络（CMNN）。传统神经网络在处理SPD张量时未能保留其固有的几何结构，导致性能不佳。CMNN通过引入输入层，将SPD张量从弯曲的黎曼流形映射到平坦的局部切线空间，从而有效地保留了数据的统计和几何信息。通过稳态热传导的案例研究，证明CMNN相比传统MLP显著提升了学习性能，凸显了在工程应用中处理张量数据时流形感知方法的重要性。

> **摘要翻译:** 各向异性材料特性，例如工程复合材料的热导率，由于固有的材料异质性和制造相关的不确定性而表现出变异性。在数学上，这些特性被建模为对称正定（SPD）张量，它们存在于弯曲的黎曼流形上。将这种描述扩展到随机框架需要保留SPD结构和张量的潜在空间对称性。这通过张量的谱分解来实现，谱分解能够将不确定性参数化为尺度（强度）和旋转（方向）分量。为了量化强度和方向不确定性对复合材料热行为的影响，随机材料张量必须通过基于物理的正向模型传播。这个过程需要计算高效的替代模型，为此采用了前馈神经网络（FNN）。然而，传统的FNN架构不适合SPD张量，因为直接使用张量分量作为输入特征未能保留其潜在的几何结构，通常导致次优性能。为了解决这个问题，我们引入了构成流形神经网络（CMNN），它包含输入层，将SPD张量从弯曲流形映射到局部切线空间——一个平坦的向量空间——从而保留数据集中的统计和几何信息。一个涉及随机各向异性导热的稳态热传导案例研究表明，保留几何结构的神经网络与传统多层感知器（MLP）相比显著增强了学习性能。这些发现强调了在工程应用中处理张量值数据时，流形感知方法的重要性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [504] [Method-Based Reasoning for Large Language Models: Extraction, Reuse, and Continuous Improvement](https://arxiv.org/abs/2508.04289)
> *基于方法的大语言模型推理：提取、复用与持续改进*

*Hong Su* | **Category: cs.CE** | **Updated: 2025-08-07**

**Keywords:** 大语言模型, 推理, 方法论, 持续学习, 知识提取

**Comment:** 

> **TL;DR:** 本文提出了一种基于方法的大语言模型，通过提取、存储和复用显式的问题-解决方案对来增强LLM的推理能力，实现持续学习和逻辑一致性，并在实验中表现出更好的事实核查和泛化能力。

**AI_Comments:** 这项研究提出了一种新颖的、基于显式方法而非单纯统计模式的LLM推理增强范式。其创新点在于将问题-解决方案对作为可复用的“方法”进行外部存储和管理，并引入了持续学习和用户驱动的改进机制。这对于提升LLM的逻辑一致性、泛化能力和处理新问题的能力具有重要意义，克服了传统LLM的内在局限性，为构建更可靠、可控的AI系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）的推理过程主要受训练数据中的统计模式引导，这限制了它们处理新问题和进行一致逻辑推理的能力。

**Method:** 本文提出了一种基于方法模型，通过从训练内容、生成响应和用户交互中提取显式、可复用的过程来增强LLM。每个方法表示为一个问题及其对应解决方案的配对，外部存储并根据反馈进行排名。当接收到新查询时，系统检索并应用最相关的方法来指导LLM的响应。

**Result:** 实验结果表明，该系统提高了复杂提示中的事实核查和泛化能力，并且通过用户驱动的改进，新学习到的方法可以优于早期的方法。

**Conclusion:** 该模型通过显式方法增强LLM的推理过程，实现了持续学习、方法复用和逻辑一致性，超越了单纯的下一个词预测，并在实际应用中表现出显著的性能提升。

> **ai_Abstract:** 本文提出了一种基于方法的大语言模型推理框架，旨在解决现有LLM在处理新问题和逻辑推理方面受限于统计模式的问题。该框架通过提取、存储和复用问题-解决方案对（称为“方法”）来增强LLM。这些方法从训练数据、生成响应和用户交互中获取，并根据反馈进行排名。当接收到新查询时，系统会检索并应用最相关的方法来指导LLM的响应。实验证明，该方法显著提升了LLM在事实核查和复杂提示泛化方面的能力，并能通过用户反馈持续改进，使新学习的方法表现优于旧方法。

> **摘要翻译:** 大型语言模型（LLM）在广泛的语言任务中展现出令人印象深刻的能力。然而，它们的推理过程主要由训练数据中的统计模式引导，这限制了它们处理新问题和执行一致逻辑推理的能力。在本文中，我们提出了一种基于方法模型，通过从训练内容、生成响应和用户交互中提取显式、可复用的过程来增强LLM。每个方法表示为一个问题及其对应解决方案的配对，外部存储并根据反馈进行排名。当接收到新查询时，系统检索并应用最相关的方法来指导LLM的响应。我们的模型实现了持续学习、方法复用和超越下一个词预测的逻辑一致性。实验结果表明，该系统提高了复杂提示中的事实核查和泛化能力，并且通过用户驱动的改进，新学习到的方法可以优于早期的方法。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [511] [Mean-Variance Efficient Collaborative Filtering for Stock Recommendation](https://arxiv.org/abs/2306.06590)
> *均值-方差有效协同过滤的股票推荐*

*Munki Chung, Junhyeong Lee, Yongjae Lee, Woo Chang Kim* | **Category: cs.CE, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 股票推荐, 协同过滤, 均值-方差效率, 投资组合优化, 金融科技

**Comment:** 

> **TL;DR:** 本文提出了一种均值-方差有效协同过滤（MVECF）模型，用于股票推荐，该模型同时考虑用户偏好和股票的风险-收益特征，并在真实世界数据上展示了提高投资组合效率的能力。

**AI_Comments:** 该论文的创新之处在于成功弥合了协同过滤（关注用户偏好）与现代投资组合理论（关注风险-收益权衡）之间的鸿沟。通过将均值-方差效率整合到协同过滤框架中，它为股票推荐提供了一种更全面、更实用的方法，解决了金融科技领域现有模型的关键不足。为提高计算效率而进行的模型重构以及其对最新模型的可适用性进一步增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 金融科技的兴起推动了金融服务在线化，但股票投资推荐系统受到的关注有限。个性化股票推荐对客户参与度和满意度至关重要，但传统方法常忽略用户偏好或不直接适用于股票推荐。目前没有模型能同时考虑用户偏好和股票的风险-收益特征，因此需要一种能将用户偏好与投资组合理论最佳融合的模型。

**Method:** 我们提出了均值-方差有效协同过滤（MVECF）模型。该模型旨在通过系统处理股票价格不确定性，在风险（收益方差）和收益（平均收益）之间权衡中提高帕累托最优性（均值-方差效率）。通过正则化将这些改进融入MVECF模型，并重构模型以适应普通矩阵分解方案，以提高计算效率。此外，MVECF易于应用于最先进的基于图的排名模型。

**Result:** 在真实世界的基金持仓数据上的实验表明，我们的模型可以提高推荐投资组合的均值-方差效率，同时仅牺牲少量平均精度和召回率。

**Conclusion:** MVECF模型有效结合了用户偏好和股票风险-收益特征进行股票推荐，显著提高了投资组合的均值-方差效率，同时保持了良好的推荐性能，并易于适配先进的排名模型。

> **ai_Abstract:** 本文提出了一种新颖的均值-方差有效协同过滤（MVECF）模型，旨在解决股票投资推荐系统中用户偏好与风险-收益特征未能兼顾的问题。与传统方法不同，MVECF通过融合用户偏好和现代投资组合理论，在考虑股票风险（收益方差）和收益（平均收益）的同时，优化了推荐投资组合的均值-方差效率。该模型通过系统处理股票价格不确定性，并利用正则化和矩阵分解提高计算效率。真实世界数据实验证明，MVECF能显著提升推荐投资组合的均值-方差效率，且对平均精度和召回率的影响微乎其微，同时易于与先进的图基排名模型结合。

> **摘要翻译:** FinTech 的兴起已将金融服务转型到在线平台，然而与其它行业相比，股票投资推荐系统受到的关注有限。个性化股票推荐可以显著影响行业内的客户参与度和满意度。然而，传统的投资推荐侧重于高回报股票或基于现代投资组合理论的高度多元化投资组合，往往忽略用户偏好。另一方面，协同过滤 (CF) 方法也可能不直接适用于股票推荐，因为它不适合仅仅推荐用户喜欢的股票。关键在于如何将用户偏好与投资组合理论进行最佳融合。然而，推荐系统领域内关于股票推荐的研究相对有限，并且没有现有模型同时考虑用户偏好和股票的风险-收益特征。在此背景下，我们提出了一种均值-方差有效协同过滤 (MVECF) 模型用于股票推荐，该模型同时考虑了这两个方面。我们的模型专门设计用于通过系统地处理股票价格的不确定性，在风险（收益方差）和收益（平均收益）之间的权衡中提高帕累托最优性（均值-方差效率）。这些改进通过正则化纳入 MVECF 模型中，并且模型被重构以适应普通的矩阵分解方案，以提高计算效率。在真实基金持仓数据上的实验表明，我们的模型可以提高推荐投资组合的均值-方差效率，同时仅牺牲少量平均精度和召回率。最后，我们进一步表明 MVECF 易于应用于最先进的基于图的排名模型。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [389] [An Improved Physically-Based Surface Triangulation Method](https://arxiv.org/abs/2508.05099)
> *一种改进的基于物理的表面三角剖分方法*

*Lei Shangyu, Fan Wei, Ren Hui* | **Category: cs.CG** | **Updated: 2025-08-07**

**Keywords:** Adaptive triangulation, Surface remeshing, Bubble meshing, Conformal parameterization, Algorithm efficiency

**Comment:** 

> **TL;DR:** 通过共形映射和优化气泡控制，改进了基于物理的气泡网格生成方法，显著提高了计算效率。

**AI_Comments:** 这项研究通过引入共形映射和优化气泡控制，巧妙地解决了传统气泡网格方法在复杂表面处理上的效率瓶颈。其创新点在于将三维表面的复杂问题转化到二维平面求解，极大地提升了算法的实用性，对于需要高效高质量表面网格生成的领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的气泡网格方法在处理复杂表面时计算成本高且收敛速度慢，限制了其应用。

**Method:** 本研究提出通过共形映射将表面平展到平面上，简化气泡填充，并从平面网格诱导表面三角剖分，避免在表面上直接移动气泡。此外，优化了气泡数量控制并将其与松弛过程分离，以加速收敛。

**Result:** 计算时间缩短了70%以上，实现了盘拓扑表面的高效三角剖分，支持局部尺寸控制、曲率自适应和离散表面重网格化。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种改进的基于物理的表面三角剖分方法——气泡网格法。针对现有气泡网格在复杂表面上计算成本高和收敛慢的问题，该方法引入共形映射将表面展平到平面进行气泡填充，并优化了气泡数量控制。实验结果表明，该改进方法将计算时间缩短了70%以上，并能高效处理盘拓扑表面的三角剖分，支持局部尺寸控制、曲率自适应和重网格化。

> **摘要翻译:** 本文提出改进基于物理的表面三角剖分方法——气泡网格法。该方法模拟物理气泡自动生成网格顶点，从而生成高质量的Delaunay三角形。尽管气泡网格法在局部网格尺寸控制方面具有灵活性，并具备局部重网格化的优势，但其受限于高计算成本和在复杂表面上收敛缓慢。所提出的方法采用共形映射，通过将表面展平到平面上来简化表面气泡填充。表面三角剖分从平面网格中导出，避免了气泡在表面上的直接移动。优化气泡数量控制并将其与松弛过程分离，加速了收敛，将计算时间缩短了70%以上。增强的方法能够高效地对盘拓扑表面进行三角剖分，支持局部尺寸控制、曲率自适应和离散表面重网格化。关键词：自适应三角剖分，表面重网格化，气泡网格，共形参数化，算法效率

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [397] [GASP: A Gradient-Aware Shortest Path Algorithm for Boundary-Confined Visualization of 2-Manifold Reeb Graphs](https://arxiv.org/abs/2508.05524)
> *GASP：一种用于二维流形Reeb图边界约束可视化的梯度感知最短路径算法*

*Sefat Rahman, Tushar M. Athawale, Paul Rosen* | **Category: cs.CG, cs.GR, cs.HC** | **Updated: 2025-08-07**

**Keywords:** Reeb图, 可视化, 梯度感知, 最短路径, 2-流形

**Comment:** 

> **TL;DR:** GASP是一种新的算法，它能生成更忠实、更具代表性的Reeb图可视化，通过考虑边界约束、紧凑性和梯度对齐等属性，并优于现有方法。

**AI_Comments:** GASP算法的创新之处在于其明确地将Reeb图可视化所需的三个关键属性（边界约束、紧凑性和梯度对齐）整合到算法设计中，这解决了现有方法的不足。通过生成更忠实和代表性的可视化，该研究对于理解和分析复杂数据集的拓扑结构具有重要意义。其通过与广泛使用的Topology ToolKit中的现有算法进行比较，也增强了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Reeb图绘制算法忽略或违反了忠实表示Reeb图所需的三个关键属性：边界约束、紧凑性和与函数梯度的对齐，导致可视化效果不佳。

**Method:** 本文提出了一种名为GASP的算法，该算法在生成Reeb图可视化时考虑了边界约束、紧凑性和与函数梯度的对齐这三个属性，从而生成更能代表底层数据的可视化。

**Result:** GASP生成的Reeb图可视化通过定性和定量评估，证明其相对于几何重心算法（在Topology ToolKit中实现）有显著改进。

**Conclusion:** GASP算法通过考虑Reeb图可视化的关键属性，能够生成更忠实、更具代表性的Reeb图，并在评估中表现出优于现有算法的改进。

> **ai_Abstract:** 本文提出了一种名为GASP的梯度感知最短路径算法，用于二维流形Reeb图的边界约束可视化。该算法旨在解决现有Reeb图绘制方法忽略或违反边界约束、紧凑性和梯度对齐等关键属性的问题。GASP通过考虑这些属性，生成了更能代表底层数据的Reeb图可视化，并通过与几何重心算法进行定性和定量评估，证明了其改进。

> **摘要翻译:** Reeb图是抽象和表示流形上定义函数的拓扑结构的重要工具。我们确定了在可视化中忠实表示Reeb图的三个属性：它们应受限于边界、紧凑且与函数梯度对齐。现有的Reeb图绘制算法对这些属性不了解或违反了这些属性。在本文中，我们引入了一种生成Reeb图可视化的算法，称为GASP，该算法考虑了这些属性，从而生成更能代表底层数据的可视化。为了证明这些改进，将所得的Reeb图与几何重心算法（使用Topology ToolKit (TTK)中可用的实现，TTK是计算和可视化Reeb图的广泛采用工具）进行了定性和定量评估。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [404] [Optimal Volume-Sensitive Bounds for Polytope Approximation](https://arxiv.org/abs/2303.09586)
> *多面体逼近的最优体积敏感界限*

*Sunil Arya, David M. Mount* | **Category: cs.CG** | **Updated: 2025-08-07**

**Keywords:** 多面体逼近, 体积敏感界限, 凸体, 豪斯多夫误差, 几何分析

**Comment:** 

> **TL;DR:** 本文提出了针对“瘦”凸体的多面体逼近的新的最优体积敏感界限，该界限基于体积直径，优于现有的基于直径和表面直径的界限。

**AI_Comments:** 本文的创新之处在于提出了一个更优的、对体积敏感的多面体逼近界限，解决了现有界限对“瘦”凸体表现不佳的问题。通过引入体积直径并利用几何分析和问题转化（如夹层多面体和调和平均覆盖），该研究为凸体逼近理论提供了重要进展，其结果在理论上达到了紧密性，具有重要的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 在几何学中，逼近凸体是一个基本问题，具有广泛应用。已知现有的基于直径的界限 $O((\text{diam}(K)/\varepsilon)^{(d-1)/2})$ 对于“瘦”凸体来说远非最优，尽管Arya、da Fonseca和Mount已将其改进为 $O((\Delta_{d-1}(K)/\varepsilon)^{(d-1)/2})$（基于表面直径）。因此，需要找到一个更紧的、对体积敏感的界限。

**Method:** 本文结合了新思想，利用原始物体及其极对偶的已知性质。为了获得体积敏感的界限，作者探索了计算夹在两个给定凸体之间的低复杂度多面体的问题，并将其简化为一个涉及基于调和平均的自然中间体的覆盖问题。证明依赖于对涉及这些物体的相对“肥瘦”概念的几何分析。

**Result:** 本文证明了存在一个具有 $O((\Delta_d(K)/\varepsilon)^{(d-1)/2})$ 个刻面的逼近。这个界限仅作为体积的函数而言，在常数因子内是紧密的。

**Conclusion:** 本文成功地为凸体逼近问题提供了最优的体积敏感界限，该界限仅作为体积的函数而言，在常数因子内是紧密的，解决了现有界限对“瘦”凸体不够优化的问题。

> **ai_Abstract:** 本文研究了在给定豪斯多夫误差下，用最少刻面逼近凸体的问题。针对现有基于直径的界限对“瘦”凸体不够最优的问题，作者引入了体积直径 $\Delta_d(K)$ 的概念。通过结合新思想和几何分析，包括利用原体及其极对偶的性质，以及将问题转化为涉及调和平均中间体的覆盖问题，本文成功证明了存在一个具有 $O((\Delta_d(K)/\varepsilon)^{(d-1)/2})$ 个刻面的逼近。该结果提供了最优的体积敏感界限，并且作为仅与体积相关的函数，在常数因子内是紧密的。

> **摘要翻译:** 逼近凸体是几何学中的一个基本问题，具有广泛的应用。给定固定维度 $d$ 下的 $\textbf{R}^d$ 中的一个凸体 $K$，目标是对于给定的豪斯多夫误差 $\varepsilon$，最小化逼近多面体的刻面数量。已知对于许多情况，例如欧几里得球， $O((\text{diam}(K)/\varepsilon)^{(d-1)/2})$ 个刻面是足够且必要的。然而，对于“瘦”凸体，这个界限远非最优。

表征凸体“瘦度”的自然方式是根据其与欧几里得球的关系。给定一个凸体 $K$，其\emph{体积直径} $\Delta_d(K)$ 定义为与 $K$ 体积相同的欧几里得球的直径。\emph{表面直径} $\Delta_{d-1}(K)$ 类似地定义为表面积。根据等周不等式的推广，有 $\text{diam}(K) \geq \Delta_{d-1}(K) \geq \Delta_d(K)$。

Arya、da Fonseca和Mount 证明了基于直径的界限可以对表面直径敏感，将上述界限改进为 $O((\Delta_{d-1}(K)/\varepsilon)^{(d-1)/2})$。在本文中，我们通过证明存在一个具有 $O((\Delta_d(K)/\varepsilon)^{(d-1)/2})$ 个刻面的逼近来强化这一点。作为仅与体积相关的函数，这个界限在常数因子内是紧密的。

我们的改进源于新思想的结合。我们利用了原始物体及其极对偶的已知性质。为了获得体积敏感的界限，我们探讨了计算夹在两个给定凸体之间的低复杂度多面体的问题。我们表明，这个问题可以简化为一个涉及基于调和平均的自然中间体的覆盖问题。我们的证明依赖于对涉及这些物体的相对“肥瘦”概念的几何分析。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [413] [Optimizing Mesh to Improve the Triangular Expansion Algorithm for Computing Visibility Regions](https://arxiv.org/abs/2506.04086)
> *优化网格以改进用于计算可见区域的三角扩展算法*

*Jan Mikula, Miroslav Kulich* | **Category: cs.CG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 可见区域, 三角扩展算法, 网格优化, 查询性能, 启发式方法

**Comment:** 

> **TL;DR:** 本文通过优化三角网格来提高三角扩展算法（TEA）计算可见区域的查询性能，提出了一种新的网格类型，可将平均查询时间缩短12-16%。

**AI_Comments:** 该论文的创新点在于提出了一种新的三角网格类型，旨在通过最小化预期扩展次数来优化可见区域计算的查询性能。其重要性在于，在不增加预处理时间成本的前提下，显著提升了算法的运行时效率，特别适合于需要大量重复查询的离线应用，具有实际应用价值。此外，代码的公开性也促进了研究的可复现性和社区协作。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决三角扩展算法（TEA）在计算可见区域时查询性能不佳的问题，通过寻找最优的三角网格预处理结构来提高其效率。

**Method:** 通过寻找最优的三角网格实例来改进三角扩展算法（TEA）的查询性能。提出了一种新的三角网格类型，该类型在假设查询点服从已知概率分布的情况下，能最小化预期扩展次数。设计了一种启发式方法来近似构建这种网格，并在模拟真实世界环境的实例上进行了评估。

**Result:** 与参考约束Delaunay三角剖分相比，所提出的网格将平均查询时间提高了12-16%。

**Conclusion:** 所提出的优化网格方法能够显著提高三角扩展算法的查询性能，特别适用于需要执行数百万次查询且不关注预处理时间的离线应用。

> **ai_Abstract:** 本研究致力于通过优化三角网格预处理结构来提升三角扩展算法（TEA）计算可见区域的查询效率。文章指出查询时间与网格遍历中的三角形边缘扩展次数成正比，并由此提出一种新型三角网格，该网格在给定查询点概率分布下能最小化预期扩展次数。通过启发式方法近似构建并评估，结果显示该优化网格相较于传统约束Delaunay三角剖分，平均查询时间可提升12-16%。该方法尤其适用于需要大量查询的离线应用。

> **摘要翻译:** 本文旨在通过寻找最有优势的三角网格实例（即预处理结构）来提高三角扩展算法（TEA）计算可见区域的查询性能。TEA在多边形世界中递归遍历网格，同时记录可见区域（即从查询点可见的所有点的集合）。我们发现测得的查询时间近似与网格遍历期间的三角形边缘扩展次数成正比。我们提出了一种新型的三角网格，该网格在假设查询点来自已知概率分布的情况下，能最小化预期扩展次数。我们设计了一种启发式方法来近似构建这种网格，并在许多类似于真实世界环境的挑战性实例上评估了该方法。与参考约束Delaunay三角剖分相比，所提出的网格将平均查询时间提高了12-16%。该方法适用于提升需要计算数百万次查询而不考虑预处理时间的离线应用程序。其实现已公开，可用于复现我们的实验并服务社区。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [422] [Counts and end-curves in two-parameter persistence](https://arxiv.org/abs/2505.13412)
> *双参数持久化中的计数和端曲线*

*Thomas Brüstle, Steve Oudot, Luis Scoccola, Hugh Thomas* | **Category: cs.CG, math.AC, math.AT, math.RT** | **Updated: 2025-08-06**

**Keywords:** 双参数持久化, 端曲线, 双参数计数, Betti表, 边界不变量

**Comment:** 

> **TL;DR:** 本文在双参数持久化理论中定义了“双参数计数”和“端曲线”，并研究了它们的性质，包括与Betti表的联系以及作为不变量的潜力。

**AI_Comments:** 本文创新性地将单参数持久化理论中的核心概念推广到双参数设置，引入了新的几何不变量。特别是“边界”作为特定表示集的完全不变量，具有重要的理论意义。它为理解高维持久化模块的结构提供了新的视角，并建立了与经典代数拓扑和几何理论的联系。

<details>
  <summary>Details</summary>

**Motivation:** 为持久化理论中单变量多项式环上单分次模的条形计数和端点概念寻找二维类比。

**Method:** 定义了有限维、双分次模的双参数计数和端曲线。证明了计数的唯一性。展示了端曲线如何通过插值生成器、关系和合冲来确定经典的Betti表。利用特定字符串代数的带状表示，证明了端曲线集可以被规范划分形成闭合曲线，并称之为模的边界。

**Result:** 定义了双参数计数（一个自然数）和端曲线（一组平面曲线）。证明了该计数是满足特定自然条件的唯一计数，并等于端曲线的数量。端曲线被证明能决定经典的Betti表。定义了模的“边界”不变量，并证明其在散布可分解表示集上是一个完全不变量，且与秩不变量相比既不弱也不强。研究结果连接了多参数持久化中的多条工作线，并与二维莫尔斯理论相关。

**Conclusion:** 本文引入了双参数持久化中的新不变量（计数和端曲线/边界），建立了它们与现有理论（Betti表、莫尔斯理论）的联系，并展示了边界作为特定表示集的完全不变量的潜力。

> **ai_Abstract:** 本文在双参数持久化理论中引入了有限维双分次模的“双参数计数”和“端曲线”概念，作为单参数持久化中条形计数和端点的二维推广。研究证明了该计数的唯一性，并揭示了它与端曲线数量的几何等价性。此外，文章展示了端曲线如何决定经典的Betti表，并通过引入“边界”不变量，揭示了其在散布可分解表示集上的完全不变量性质，并将其与二维莫尔斯理论联系起来，从而连接了多参数持久化中的多个研究方向。

> **摘要翻译:** 给定一个有限维、双分次的双变量多项式环模，我们定义了它的双参数计数（一个自然数）和它的端曲线（一组平面曲线）。这些是持久化理论中单变量多项式环上单分次模的条形计数和端点的二维类比。我们证明了我们的计数是满足某些自然条件的唯一计数；因此，双参数持久化中的几个包含-排除公式产生了相同的正数，该数等于我们的计数，并且反过来等于端曲线的数量，从而赋予了该计数几何意义。我们通过展示端曲线在生成器、关系和合冲之间进行插值来证明它们决定了经典的Betti表。使用某个字符串代数的带状表示，我们证明了端曲线集允许规范划分，其中每个部分在平面上形成一个闭合曲线；我们称之为模的边界。作为一个不变量，边界既不弱于也不强于秩不变量，但与秩不变量不同的是，它在散布可分解表示集上是一个完全不变量。我们的结果连接了多参数持久化中的多条工作线，并且它们扩展到双变量实指数多项式环上的模与二维莫尔斯理论相关。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [4] [You Cannot Feed Two Birds with One Score: the Accuracy-Naturalness Tradeoff in Translation](https://arxiv.org/abs/2503.24013)
> *一石二鸟在翻译中行不通：准确性与自然度之间的权衡*

*Gergely Flamich, David Vilar, Jan-Thorsten Peter, Markus Freitag* | **Category: cs.CL** | **Updated: 2025-08-06**

**Keywords:** 机器翻译, 评估, 准确性, 自然度, 权衡

**Comment:** 

> **TL;DR:** 机器翻译的单一评估分数无法反映系统性能全貌，因为准确性和自然度之间存在权衡，应在准确性-自然度平面上进行评估。

**AI_Comments:** 这篇论文通过引入信息论的数学证明，为机器翻译评估领域的一个长期存在的经验现象（准确性与自然度的权衡）提供了坚实的理论基础。其创新之处在于明确指出单一分数评估的局限性，并提出了在准确性-自然度平面上进行多维度评估的变革性建议，这对于推动机器翻译评估方法的发展具有重要意义，有助于更全面地理解和优化翻译系统。

<details>
  <summary>Details</summary>

**Motivation:** 机器翻译研究中，通常使用单一分数来评估译文的语义准确性和目标语言的自然度，但这种单一分数无法全面反映系统真实性能。

**Method:** 作者基于信息论，通过数学证明和经验验证（评估WMT24共享任务的提交结果），证明了准确性和自然度之间存在权衡。

**Result:** 证明了翻译的准确性和自然度之间存在权衡。经验结果表明，为特定准确性指标（如BLEU）优化翻译系统初期能提高自然度，但“过拟合”会导致自然度显著下降。

**Conclusion:** 提倡改变翻译评估方式，不应使用单一分数比较系统，而应在准确性-自然度平面上进行比较。

> **ai_Abstract:** 本文指出机器翻译领域目前普遍采用的单一分数评估方法无法全面反映翻译系统的真实性能，因为翻译的准确性和自然度之间存在固有的权衡。作者利用信息论进行数学证明，并通过WMT24任务的实证数据验证了这一权衡现象，解释了为何过度优化特定准确性指标会导致自然度下降。因此，文章提倡将翻译评估从单一数值比较转变为在准确性-自然度平面上的多维度比较。

> **摘要翻译:** 翻译的目标，无论是人工翻译还是机器翻译，都是在给定源语言文本的情况下，生成目标语言文本，使其同时：1）保留源文本的意义，2）在目标语言中实现自然的表达。然而，机器翻译领域的研究人员通常使用一个旨在同时捕捉语义准确性和输出自然度的单一分数来评估翻译。在本文中，我们基于信息论的最新进展，通过数学证明和经验演示，表明这种单一分数的总结不能也无法全面反映系统真实的性能。具体来说，我们证明了准确性与自然度之间存在权衡，并通过评估WMT24共享任务的提交结果来加以证明。我们的发现有助于解释一些众所周知的经验现象，例如：为特定准确性指标（如BLEU）优化翻译系统最初会提高系统的自然度，而系统“过拟合”该指标则会显著降低其自然度。因此，我们提倡改变翻译的评估方式：不应使用单一数字来比较系统，而应在准确性-自然度平面上进行比较。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [11] [PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages](https://arxiv.org/abs/2504.04377)
> *PolyGuard：一个支持17种语言的多语言安全审核工具*

*Priyanshu Kumar, Devansh Jain, Akhila Yerukola, Liwei Jiang, Himanshu Beniwal, Thomas Hartvigsen, Maarten Sap* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多语言安全, 大型语言模型, PolyGuard, 安全审核, 数据集

**Comment:** 

> **TL;DR:** PolyGuard是一个新的最先进的多语言安全模型，用于保护大型语言模型（LLM）的生成内容，并附带用于17种语言的大型训练和评估数据集，其性能优于现有模型5.5%。

**AI_Comments:** PolyGuard的创新之处在于其支持多达17种语言，并通过构建大规模的多语言训练和评估数据集（PolyGuardMix和PolyGuardPrompts）来弥补现有研究在语言覆盖范围和安全定义上的不足。其性能提升5.5%表明了该工具的有效性，对于推动LLM的全球化应用和保障用户安全具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLM）的多语言安全审核工作受限于对少数语言的狭隘关注以及有限的安全定义范围，导致审核能力存在显著差距。本研究旨在弥补这些差距。

**Method:** 研究发布了PolyGuard，一个用于保护LLM生成内容的多语言安全模型。PolyGuard在PolyGuardMix上进行训练，这是迄今为止最大的多语言安全训练语料库，包含17种语言的191万个样本。同时引入了PolyGuardPrompts，一个包含2.9万个样本的高质量多语言基准数据集，用于评估安全防护栏。数据集通过结合自然发生的人机LLM交互和对英语安全数据集的机器翻译（经人工验证）创建，包含带有提示有害性、响应有害性和响应拒绝标签的提示-输出对。

**Result:** 通过在多个安全和毒性基准测试中进行广泛评估，PolyGuard的性能比现有最先进的开源和商业安全分类器提高了5.5%。

**Conclusion:** 本研究的贡献推动了为所有全球用户提供更安全的多语言LLM的努力。

> **ai_Abstract:** 该论文介绍了PolyGuard，一个针对17种语言的多语言安全审核工具，旨在解决当前大型语言模型（LLM）在多语言安全审核方面存在的局限性。PolyGuard模型在迄今最大的多语言安全训练语料库PolyGuardMix上训练，并引入了高质量的多语言评估基准PolyGuardPrompts。实验结果表明，PolyGuard在安全和毒性基准测试中，性能优于现有最先进的分类器5.5%，显著提升了多语言LLM的安全性。

> **摘要翻译:** 大型语言模型（LLM）真正多语言的安全审核工作一直受到阻碍，原因是对少数几种语言（例如英语、中文）的狭隘关注以及安全定义范围的限制，导致审核能力存在显著差距。为了弥补这些差距，我们发布了PolyGuard，一个用于保护LLM生成内容的全新最先进多语言安全模型，以及相应的训练和评估数据集。PolyGuard在PolyGuardMix上进行训练，这是迄今为止最大的多语言安全训练语料库，包含17种语言（例如中文、捷克语、英语、印地语）的191万个样本。我们还引入了PolyGuardPrompts，一个包含2.9万个样本的高质量多语言基准，用于评估安全防护栏。我们的数据集通过结合自然发生的多语言人机LLM交互和对仅限英语的安全数据集（WildGuardMix；Han等，2024）进行人工验证的机器翻译创建，包含带有提示有害性、响应有害性和响应拒绝标签的提示-输出对。通过在多个安全和毒性基准测试中进行广泛评估，我们证明PolyGuard的性能比现有最先进的开源和商业安全分类器提高了5.5%。我们的贡献推动了为所有全球用户提供更安全的多语言LLM的努力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [18] [DEL: Context-Aware Dynamic Exit Layer for Efficient Self-Speculative Decoding](https://arxiv.org/abs/2504.05598)
> *DEL：上下文感知的动态退出层，用于高效的自推测解码*

*Hossein Entezari Zarch, Lei Gao, Chaoyi Jiang, Murali Annavaram* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 推测解码, 大型语言模型, 动态退出层, 推理加速, 上下文感知

**Comment:** 

> **TL;DR:** DEL是一种上下文感知的动态退出层方法，用于自推测解码，通过自适应选择退出层和推测长度，显著加速LLM推理。

**AI_Comments:** DEL的创新之处在于它引入了一种上下文感知的动态机制来选择推测解码中的关键超参数（退出层和推测长度），解决了现有方法静态选择的局限性。这种自适应方法显著提高了LLM推理效率，且作为即插即用方案，易于集成。

<details>
  <summary>Details</summary>

**Motivation:** 推测解码（SD）使用早期退出方法来加速LLM推理，但其性能依赖于静态选择的退出层和推测长度，而这些值是任务和上下文相关的。

**Method:** DEL（动态退出层）是一种即插即用方法，在推理过程中自适应地选择退出层和推测长度。它动态跟踪在LLM每一层生成token的接受率，并利用这些知识启发式地选择最佳退出层和推测长度。

**Result:** DEL在各种模型和下游任务上，相对于普通的自回归解码，实现了2.16倍至2.62倍的整体加速，并比最先进的SD方法（峰值为2.43倍）提高了高达0.19倍。

**Conclusion:** DEL通过动态调整退出层和推测长度，显著提高了自推测解码的效率，超越了现有方法。

> **ai_Abstract:** 本文介绍了DEL（动态退出层），一种用于加速大型语言模型（LLM）推理的即插即用方法。DEL通过动态调整推测解码中用于草拟token的退出层和推测长度来优化性能。与现有方法静态选择这些参数不同，DEL根据上下文自适应地选择，从而显著提高了推理速度，并在多种任务和模型上超越了现有最先进的推测解码方法。

> **摘要翻译:** 推测解码（SD）是一种广泛使用的方法，可以在不降低生成质量的情况下加速大型语言模型（LLM）的推理。它首先使用一个紧凑模型高效地草拟多个token，然后使用目标LLM进行并行验证。与自回归解码相比，这种方法可以实现更快的推理。虽然有多种方法可以创建草稿模型，但一种有前景的方法是使用早期退出方法。这些方法通过使用主模型的一部分层来草拟候选token，并使用其余层进行验证，从而允许单个模型处理草拟和验证。虽然这种技术减少了内存使用和计算成本，但其性能依赖于草拟的退出层的选择以及每个SD轮次中草拟的token数量（推测长度）。先前的工作通过超参数探索静态选择这些值。然而，我们的评估表明，这些超参数值是任务特定的，甚至在同一任务中也依赖于当前的序列上下文。我们引入了DEL（动态退出层），这是一种即插即用方法，可在推理期间自适应地选择退出层和推测长度。DEL动态跟踪如果token在LLM的每一层被草拟时的token接受率，并利用这些知识启发式地选择最佳退出层和推测长度。我们在广泛的模型和下游任务上的实验表明，DEL相对于普通的自回归解码实现了2.16倍至2.62倍的整体加速，并比最先进的SD方法（峰值为2.43倍）提高了高达0.19倍。代码可在https://github.com/hoenza/DEL获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [25] [Tell Me Who Your Students Are: GPT Can Generate Valid Multiple-Choice Questions When Students' (Mis)Understanding Is Hinted](https://arxiv.org/abs/2505.05815)
> *告诉我你的学生是谁：当学生的（误）解被暗示时，GPT 可以生成有效的多项选择题*

*Machi Shimmei, Masaki Uto, Yuichiroh Matsubayashi, Kentaro Inui, Aditi Mallavarapu, Noboru Matsuda* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多项选择题生成, 大语言模型, AnaQuest, 项目反应理论, 学生误解

**Comment:** 

> **TL;DR:** 本研究开发并评估了一种名为 AnaQuest 的创新提示技术，用于使用大型语言模型生成多项选择题，该技术能更好地模拟人工出题的难度和区分度。

**AI_Comments:** AnaQuest 的创新之处在于它利用了学生对开放式问题的回答来生成多项选择题，特别是能够生成高质量的错误选项（干扰项），这对于评估学生的真实理解和误解至关重要。这种方法提高了 AI 生成试题的诊断性价值和教学效用。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的主要目标是开发和评估一种创新的提示技术 AnaQuest，以使用预训练的大型语言模型生成多项选择题。

**Method:** 开发了 AnaQuest 技术，该技术将形成性评估（学生对开放式问题的自由文本回答）和总结性评估（分析学生回答以生成正确和不正确的断言作为多选题选项）相结合。通过应用项目反应理论（IRT）来评估生成的多项选择题的有效性，并将其与基线 ChatGPT 提示和人工制作的题目进行比较。

**Result:** 专家教师认为两种 AI 模型生成的多项选择题与人工制作的题目一样有效。基于 IRT 的分析显示，AnaQuest 生成的问题，特别是包含错误断言（干扰项）的问题，在难度和区分度方面比 ChatGPT 生成的题目更接近人工制作的题目。

**Conclusion:** AnaQuest 是一种有效的多项选择题生成技术，能够生成在难度和区分度上与人工出题质量相当的题目，尤其在处理学生的误解方面表现突出。

> **ai_Abstract:** 本研究提出并评估了 AnaQuest，一种利用大型语言模型生成多项选择题的创新提示技术。AnaQuest 通过分析学生对开放式问题的回答来生成包含正确和错误断言的选项，从而整合了形成性与总结性评估。通过与基线 ChatGPT 和人工出题的比较，并使用项目反应理论进行评估，结果表明 AnaQuest 生成的多项选择题在有效性上与人工出题相当，尤其是在难度和区分度方面，其错误选项（干扰项）的质量更接近人工出题。

> **摘要翻译:** 本研究的主要目标是开发和评估一种创新的提示技术 AnaQuest，用于使用预训练的大型语言模型生成多项选择题（MCQ）。在 AnaQuest 中，选项是关于复杂概念的句子级断言。该技术整合了形成性评估和总结性评估。在形成性阶段，学生以自由文本形式回答针对目标概念的开放式问题。在总结性评估中，AnaQuest 分析这些回答以生成正确和不正确的断言。为了评估生成的多项选择题的有效性，应用了项目反应理论（IRT）来比较 AnaQuest 生成的多项选择题、基线 ChatGPT 提示生成的多项选择题和人工制作的题目之间的项目特征。一项实证研究发现，专家教师认为两种 AI 模型生成的多项选择题与人工教师创建的题目一样有效。然而，基于 IRT 的分析显示，AnaQuest 生成的问题——特别是那些包含错误断言（干扰项）的问题——在难度和区分度方面比 ChatGPT 生成的题目更接近人工制作的题目。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [32] [Improving Factuality for Dialogue Response Generation via Graph-Based Knowledge Augmentation](https://arxiv.org/abs/2506.12496)
> *通过基于图的知识增强提高对话响应生成的准确性*

*Xiangyan Chen, Yujian Gan, Yimeng Gu, Matthew Purver* | **Category: cs.CL, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 对话响应生成, 事实性, 图知识增强, 大语言模型, 幻觉

**Comment:** 

> **TL;DR:** 大语言模型（LLMs）在对话响应中易产生幻觉。本文提出两种基于图知识增强的框架（TG-DRG和GA-DRG），通过结合推理引导的对话重构、知识选择和图增强生成来提高对话响应的真实性，并引入新的对话事实分数进行评估。实验证明其在OpendialKG和HybriDialogue数据集上显著优于现有基线。

**AI_Comments:** 本文创新性地将图知识增强与对话响应生成相结合，有效解决了LLMs的“幻觉”问题。提出的两种框架结合了多种技术，并引入了新的评估指标，对提升对话系统的事实准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）在对话响应生成中存在“幻觉”问题，即生成看似合理但与事实不符或不准确的文本，这在对话任务中会导致严重问题。

**Method:** 提出了两种新的图知识增强框架：Dialogue Response Generation via Textualised Graphs (TG-DRG) 和 Graph-Aware Dialogue Response Generation (GA-DRG)。这些框架结合了推理引导的对话重构、对话语义知识选择和图增强的响应生成。为了评估生成响应的真实性，还提出了一种新的对话事实分数，以克服现有方法的局限性。

**Result:** 提出的方法在OpendialKG和HybriDialogue数据集上，与包括最先进的G-retriever在内的其他图知识增强基线相比，显著提高了真实性。在OpendialKG上对话事实分数提高了3.47%，在HybriDialogue上提高了3.12%。

**Conclusion:** 本文提出的基于图知识增强的框架（TG-DRG和GA-DRG）以及新的对话事实分数，能够有效提高对话响应的真实性，并在实验中取得了显著优于现有基线的效果。

> **ai_Abstract:** 本文旨在解决大语言模型在对话响应生成中容易产生“幻觉”的问题。为此，作者提出了两种基于图知识增强的新框架：TG-DRG和GA-DRG。这些框架通过整合推理引导的对话重构、语义知识选择和图增强生成技术来提升响应的真实性。此外，为更准确评估对话真实性，论文还引入了一种新的对话事实分数。实验结果表明，与现有基线相比，所提方法在OpendialKG和HybriDialogue数据集上显著提高了对话的真实性。

> **摘要翻译:** 大型语言模型（LLMs）在许多自然语言处理任务中取得了成功。然而，它们产生幻觉的倾向——生成看似合理但不一致或事实不准确的文本——在某些任务中，包括对话中的响应生成，可能会导致严重问题。为了缓解这个问题，我们提出了两种新颖的图知识增强框架，即通过文本化图的对话响应生成（TG-DRG）和图感知对话响应生成（GA-DRG），它们结合了推理引导的对话重构、对话语义知识选择和图增强的响应生成，以提高对话响应的真实性。为了评估生成响应的真实性，我们提出了一种对话事实分数，解决了现有事实分数方法在对话设置中的局限性，提供了更可靠的事实一致性评估。我们使用不同基线在OpendialKG和HybriDialogue数据集上评估了我们的方法。与包括最先进的G-retriever在内的其他图知识增强基线相比，我们的方法显著提高了真实性，在OpendialKG上对话事实分数提高了3.47%，在HybriDialogue上提高了3.12%。代码将在GitHub上发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [39] [FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning](https://arxiv.org/abs/2506.16123)
> *FinCoT：在专家金融推理中奠定思维链基础*

*Natapong Nitarach, Warit Sirichotedumrong, Panop Pitchayarthorn, Pittawat Taveekitworachai, Potsawee Manakul, Kunat Pipatanakul* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** FinCoT, 思维链, 金融自然语言处理, 专家推理, 结构化提示

**Comment:** 

> **TL;DR:** FinCoT是一个结构化的思维链提示框架，它将领域专家金融推理蓝图嵌入到大语言模型中，显著提高了通用模型和金融专用模型在CFA风格金融领域的准确性，并减少了输出长度，同时提供了更可解释的推理过程。

**AI_Comments:** FinCoT的创新之处在于其将领域专家金融推理蓝图嵌入到结构化思维链提示中，弥补了以往研究在结构化CoT和领域知识整合方面的不足。其重要性体现在不仅显著提升了模型在金融任务上的性能和解释性，还降低了推理成本，尤其对通用模型具有显著效果。这为金融领域的大语言模型应用提供了新的方向和有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的金融自然语言处理（FinNLP）方法主要集中在标准提示和非结构化思维链上，而结构化思维链仍未被充分探索且缺乏领域专业知识的整合。因此，需要一种能够结合领域专家知识的结构化金融特定提示方法。

**Method:** 本文提出了FinCoT，一个结构化的思维链（CoT）提示框架，该框架嵌入了领域特定的专家金融推理蓝图来指导大型语言模型的行为。研究评估了三种提示方法（标准提示、非结构化CoT、结构化CoT）在十个CFA风格金融领域的表现，并引入FinCoT作为第一个结合领域专家蓝图的结构化金融特定提示方法。

**Result:** FinCoT将通用模型Qwen3-8B-Base的准确率从63.2%提高到80.5%，将金融专用模型Fin-R1 (7B)的准确率从65.7%提高到75.7%。与结构化CoT方法相比，输出长度分别减少了8.9倍和1.16倍。FinCoT对缺乏金融后训练的模型最有效。

**Conclusion:** FinCoT不仅提高了性能并降低了推理成本，还产生了更具可解释性且与专家一致的推理轨迹。研究发现FinCoT对缺乏金融后训练的模型最有效。

> **ai_Abstract:** 本文介绍了FinCoT，一种创新的结构化思维链（CoT）提示框架，旨在通过整合领域专家金融推理蓝图来优化大型语言模型在金融任务中的表现。研究发现，在金融自然语言处理领域，标准提示和非结构化CoT是主流，而结构化CoT及其领域专业知识集成却未被充分利用。为此，作者在十个CFA风格的金融领域对三种提示方法进行了评估，并提出FinCoT作为首个结合专家知识的结构化金融特定提示方案。实验结果表明，FinCoT显著提升了通用模型（Qwen3-8B-Base）和金融专用模型（Fin-R1）的准确率，并显著减少了输出长度。此外，FinCoT尤其适用于缺乏金融领域后训练的模型，并能生成更具解释性和与专家推理一致的输出。

> **摘要翻译:** 本文提出了FinCoT，一个结构化的思维链（CoT）提示框架，该框架嵌入了领域特定的专家金融推理蓝图来指导大型语言模型的行为。我们识别了金融自然语言处理（FinNLP）中的三种主要提示风格：(1) 标准提示（零样本），(2) 非结构化CoT（自由形式推理），以及 (3) 结构化CoT（具有明确结构化推理步骤）。先前的工作主要集中在前两种，而结构化CoT仍未被充分探索且缺乏领域专业知识的整合。因此，我们在十个CFA风格的金融领域评估了所有三种提示方法，并引入FinCoT作为第一个结合领域专家蓝图的结构化金融特定提示方法。FinCoT将通用模型Qwen3-8B-Base的准确率从63.2%提高到80.5%，并将金融专用模型Fin-R1 (7B)的准确率从65.7%提高到75.7%，同时与结构化CoT方法相比，输出长度分别减少了高达8.9倍和1.16倍。我们发现FinCoT对缺乏金融后训练的模型最有效。我们的研究结果表明，FinCoT不仅提高了性能并降低了推理成本，而且产生了更具可解释性且与专家一致的推理轨迹。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [46] [McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2507.02088)
> *McBE：一个用于大型语言模型的多任务中文偏见评估基准*

*Tian Lan, Xiangdong Su, Xu Liu, Ruirui Wang, Ke Chang, Jiang Li, Guanglai Gao* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 偏见评估, 中文, 多任务基准, McBE

**Comment:** 

> **TL;DR:** 提出了McBE，一个多任务中文偏见评估基准，用于解决现有英文数据集不足和中文数据集缺乏多任务评估的问题，并发现LLM普遍存在偏见。

**AI_Comments:** McBE的创新之处在于其针对中文语境，并引入了多任务评估能力，填补了现有中文偏见评估数据集的空白。这对于理解和缓解大型语言模型在跨文化应用中的伦理风险具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型偏见评估数据集主要关注英语和北美文化，且大多只支持单一评估任务，不适用于中文语境，缺乏多角度评估能力，同时中文数据集稀缺。

**Method:** 提出了一个名为McBE的多任务中文偏见评估基准，它包含4,077个偏见评估实例，覆盖12个单一偏见类别和82个子类别，并引入了5种评估任务。此外，该研究使用McBE评估了不同系列和参数大小的多种流行大型语言模型。

**Result:** 所有被评估的大型语言模型都表现出不同程度的偏见。

**Conclusion:** McBE为中文大型语言模型的偏见评估提供了一个全面且多任务的基准，研究发现当前的大型语言模型普遍存在偏见，需要进一步关注和缓解。

> **ai_Abstract:** 本文提出了McBE（多任务中文偏见评估基准），旨在解决现有大型语言模型偏见评估数据集在中文语境下不足且缺乏多任务评估能力的问题。McBE包含4,077个评估实例，覆盖12个偏见类别和82个子类别，并支持5种评估任务，提供了全面的偏见评估能力。通过使用McBE评估多个流行的大型语言模型，研究发现这些模型普遍存在不同程度的偏见。

> **摘要翻译:** 随着大型语言模型（LLMs）越来越多地应用于各种自然语言处理任务，其固有的偏见逐渐显露。因此，衡量LLMs中的偏见对于减轻其伦理风险至关重要。然而，大多数现有的偏见评估数据集侧重于英语和北美文化，其偏见类别不完全适用于其他文化。基于中文语言和文化的数据集稀缺。更重要的是，这些数据集通常只支持单一评估任务，无法从多个方面评估LLMs中的偏见。为了解决这些问题，我们提出了一个多任务中文偏见评估基准（McBE），它包含4,077个偏见评估实例，涵盖12个单一偏见类别，82个子类别，并引入了5种评估任务，提供了广泛的类别覆盖、内容多样性和衡量全面性。此外，我们评估了不同系列和参数大小的几种流行LLMs。总的来说，所有这些LLMs都表现出不同程度的偏见。我们对结果进行了深入分析，为LLMs中的偏见提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [53] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
> *面向多模态推理的感知感知策略优化*

*Zhenhailong Wang, Xuehang Guo, Sofia Stoica, Haiyang Xu, Hongru Wang, Hyeonjeong Ha, Xiusi Chen, Yangyi Chen, Ming Yan, Fei Huang, Heng Ji* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多模态推理, 强化学习, 感知优化, 策略梯度, 大型语言模型

**Comment:** 

> **TL;DR:** PAPO是一种新颖的策略梯度算法，通过引入隐式感知损失和双熵损失，显著提高了RLVR在多模态推理任务中的性能，尤其是在视觉依赖性高的任务上，并显著减少了感知错误。

**AI_Comments:** PAPO的创新之处在于将感知学习与推理过程深度融合，通过新颖的损失函数解决了多模态RL中视觉感知不足的关键问题。其重要性体现在显著提升了LLMs在复杂多模态任务上的表现，且无需额外的数据或复杂的模型，展现了其高效性和普适性。该工作为未来构建更强大的视觉接地推理系统提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有可验证奖励强化学习（RLVR）在纯文本领域表现出色，但在多模态推理任务中性能不佳，主要问题在于视觉输入的感知错误。

**Method:** 提出PAPO（Perception-Aware Policy Optimization），一种新的策略梯度算法，鼓励模型在推理的同时学习感知。具体引入了隐式感知损失（KL散度形式），可无缝集成到GRPO和DAPO等主流RLVR算法中。为增强训练稳定性，引入了双熵损失来正则化新的KL目标。PAPO不依赖额外数据、奖励模型或更强的教师模型。

**Result:** PAPO在多样化的多模态基准测试中总体性能提升了4.4%-17.5%。在视觉依赖性高的任务上，提升更为显著，达到8.0%-19.1%。感知错误显著减少了30.5%。

**Conclusion:** 本工作将感知感知监督更深入地整合到核心学习目标中，为鼓励视觉接地推理的新型强化学习框架奠定了基础。

> **ai_Abstract:** 本文提出了一种名为PAPO（Perception-Aware Policy Optimization）的新型策略梯度算法，旨在解决现有可验证奖励强化学习（RLVR）在多模态推理中因视觉感知不足导致的性能瓶颈。PAPO通过引入隐式感知损失（KL散度）和双熵损失，使模型在推理的同时学习感知，且无需额外数据或更强的教师模型。实验结果表明，PAPO在多模态基准测试中取得了显著性能提升（4.4%-17.5%），尤其是在视觉依赖性高的任务上（8.0%-19.1%），并有效减少了30.5%的感知错误，为视觉接地推理的RL框架奠定了基础。

> **摘要翻译:** 可验证奖励强化学习（RLVR）已被证明是赋予大型语言模型（LLMs）强大多步推理能力的有效策略。然而，其设计和优化仍局限于纯文本领域，导致应用于多模态推理任务时性能不佳。特别是，我们观察到当前多模态推理中的主要错误来源在于视觉输入的感知。为解决这一瓶颈，我们提出了PAPO，一种新颖的策略梯度算法，鼓励模型在学习推理的同时学习感知。具体而言，我们引入了以KL散度项形式存在的隐式感知损失，该损失可以无缝地插入到GRPO和DAPO等主流RLVR算法中。值得注意的是，PAPO不依赖额外的数据整理、奖励模型或更强的教师模型。为了进一步提高PAPO的训练稳定性，我们引入了双熵损失，它在不损害性能的情况下有效地正则化了新的KL目标。尽管其简单性，PAPO在多样化的多模态基准测试中取得了4.4%-17.5%的显著总体改进。在视觉依赖性高的任务上，改进更为显著，接近8.0%-19.1%。我们还观察到感知错误大幅减少了30.5%，表明PAPO提高了感知能力。总的来说，我们的工作将感知感知监督更深入地整合到核心学习目标中，并为鼓励视觉接地推理的新型强化学习框架奠定了基础。代码和数据将公开发布以供研究使用。项目页面：https://mikewangwzhl.github.io/PAPO。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [60] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
> *使用情感分析调查母语和非母语英语使用者之间的同伴反馈*

*Brittney Exline, Melanie Duffin, Brittany Harbison, Chrissa da Gomez, David Joyner* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 情感分析, 同伴反馈, 母语者, 非母语者, 在线教育

**Comment:** 

> **TL;DR:** 研究发现，在美国在线计算机课程中，母语和非母语英语学生的同伴反馈体验存在复杂差异，非母语学生写得更积极但收到的反馈积极性较低。

**AI_Comments:** 本文通过情感分析量化了母语和非母语英语学生在同伴反馈中的差异，为在线教育中跨文化交流和教学改进提供了新的视角。其创新点在于将情感分析应用于这一特定领域，揭示了语言背景对反馈质量和接受度的复杂影响。

<details>
  <summary>Details</summary>

**Motivation:** 随着美国CS研究生课程中国际学生（非母语英语使用者）比例的增加，以及在线课程中同伴反馈的广泛使用，研究语言背景如何影响同伴反馈体验变得重要。

**Method:** 使用Twitter-roBERTa模型分析500名学生撰写和收到的同伴评论的情感，并将情感分数和反馈评级与学生的语言背景相关联。

**Result:** 母语英语使用者对反馈的评价较低，而非母语使用者撰写反馈时更积极，但收到的反馈积极性较低。在控制性别和年龄后，语言背景对同伴反馈体验有适度但复杂的影响。

**Conclusion:** 语言背景在塑造同伴反馈体验中扮演着适度但复杂的角色，尽管存在一些差异，但具体影响需要进一步深入研究。

> **ai_Abstract:** 本文利用情感分析研究了美国在线计算机课程中母语和非母语英语使用者之间同伴反馈体验的差异。研究分析了500名学生的同伴评论情感，发现母语者对反馈评价较低，而非母语者写得更积极但收到的积极反馈较少。结果表明语言背景对同伴反馈体验有适度但复杂的影响。

> **摘要翻译:** 美国研究生计算机科学项目招收的国际学生越来越多，2023年60.2%的硕士学位授予了非美国学生。这些学生中有许多人参加在线课程，其中同伴反馈被用于吸引学生并以可扩展的方式改进教学法。由于这些课程以英语进行，许多学生使用非母语进行学习。本文研究了母语和非母语英语使用者身份如何影响美国在线计算机课程中同伴反馈体验的三个指标。我们使用基于Twitter-roBERTa的模型，分析了随机抽取的500名学生撰写和收到的同伴评论的情感。然后，我们将情感得分和同伴反馈评级与学生的语言背景相关联。结果显示，母语英语使用者对反馈的评价较低，而非母语使用者撰写时更积极，但收到的积极情感反馈较少。在控制性别和年龄后，出现了显著的交互作用，表明语言背景在塑造同伴反馈体验中扮演着适度但复杂的角色。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [67] [TreeDiff: AST-Guided Code Generation with Diffusion LLMs](https://arxiv.org/abs/2508.01473)
> *TreeDiff：AST引导的扩散大语言模型代码生成*

*Yiming Zeng, Jinghan Cao, Zexin Li, Yiming Chen, Tao Ren, Dawei Xiang, Xidong Wu, Shangqian Gao, Tingting Yu* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 代码生成, 扩散模型, 抽象语法树, 语法感知, 结构化数据

**Comment:** 

> **TL;DR:** TreeDiff提出一种语法感知的扩散框架，通过AST引导的代码片段损坏，显著提升扩散模型在代码生成中的语法正确性和泛化能力，解决了传统方法忽略代码结构的问题。

**AI_Comments:** 该论文的创新点在于将抽象语法树（AST）的结构信息融入到扩散模型的去噪过程中，解决了标准token级损坏技术在处理代码时忽略语法结构的问题。这对于提高代码生成模型的语法正确性和泛化能力至关重要，为基于扩散的LLMs在结构化数据领域的应用开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型在应用于源代码等结构化领域时面临挑战，因为它们通常采用标准token级损坏技术，忽略了编程语言严格的语法和层次结构，导致模型难以学习有意义的代码表示。

**Method:** 提出TreeDiff，一个语法感知的扩散框架，将抽象语法树（AST）的结构先验知识融入去噪过程。该方法选择性地损坏从AST子树衍生的语法有意义的代码片段，而非随机掩盖单个token，从而使模型能够尊重语法边界并捕获长距离依赖关系。

**Result:** 实验结果表明，语法感知的损坏显著提高了代码的语法正确性、重建准确性以及对未见代码模式的泛化能力。

**Conclusion:** 将结构信息融入基于扩散的训练中具有巨大潜力，并且语法引导的去噪是推动基于扩散的语言模型在代码生成任务中发展的一个有前途的方向。

> **ai_Abstract:** TreeDiff提出一种语法感知的扩散框架，以解决现有扩散模型在代码生成中忽略代码结构的问题。通过利用抽象语法树（AST）进行语法有意义的代码片段损坏，而非随机token掩盖，TreeDiff显著提高了代码的语法正确性、重建准确性及泛化能力。这表明将结构信息融入扩散模型训练对代码生成任务至关重要，为基于扩散的LLMs在结构化数据领域的应用开辟了新方向。

> **摘要翻译:** 近期基于扩散的语言模型进展为可控和双向序列生成开辟了新的可能性。这些模型通过将文本生成视为迭代去噪过程，为传统的自回归方法提供了一种替代方案。然而，将扩散模型应用于源代码等结构化领域仍然是一个重大挑战。编程语言与自然语言不同，它们遵循严格的语法和语义规则，并具有必须保持正确性的层次结构。训练中使用的标准token级损坏技术通常会忽略这种结构，这可能会阻碍模型学习有意义的代码表示的能力。为了解决这一限制，我们提出了一种语法感知的扩散框架，将抽象语法树（AST）的结构先验知识融入到去噪过程中。我们没有随机掩盖单个token，而是选择性地损坏从AST子树派生的语法有意义的代码片段。这使得模型能够以尊重语法边界并捕获长距离依赖关系的方式重建程序。实验结果表明，语法感知的损坏显著提高了语法正确性、重建准确性以及对未见代码模式的泛化能力。这些发现突出了将结构信息融入基于扩散的训练中的潜力，并表明语法引导的去噪是推动基于扩散的语言模型在代码生成任务中发展的一个有前途的方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [73] [The SMeL Test: A simple benchmark for media literacy in language models](https://arxiv.org/abs/2508.02074)
> *SMeL测试：衡量语言模型媒体素养的简单基准*

*Gustaf Ahdritz, Anat Kleiman* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 媒体素养, 语言模型, 基准测试, 幻觉, 不可信内容

**Comment:** 

> **TL;DR:** 本文介绍了SMeL测试，这是一个用于评估语言模型过滤不可信信息能力的基准测试，结果显示当前LLM在这方面表现不佳，且大型模型不一定优于小型模型，突出显示了幻觉问题。

**AI_Comments:** 这项研究通过引入SMeL测试，填补了评估语言模型媒体素养的空白，具有重要意义。它揭示了当前LLM在处理不可信信息时普遍存在的幻觉问题，并指出模型规模并非性能提升的唯一途径，这对于未来LLM的开发和应用具有重要的指导价值。其局限性可能在于SMeL测试作为“最小化”基准的覆盖范围，以及对不同类型不可信内容的细致区分。

<details>
  <summary>Details</summary>

**Motivation:** 互联网上充斥着不可靠内容，而大型语言模型（LLMs）常被用于自主网页浏览。目前尚不清楚LLM在多大程度上掌握了人类研究人员用于应对这种嘈杂环境的简单启发式方法，因此需要评估它们过滤不可信信息的能力。

**Method:** 本文引入了合成媒体素养测试（SMeL Test），这是一个最小化的基准测试，旨在评估语言模型在上下文中主动过滤不可信信息的能力。研究人员对各种常用的指令微调LLM（包括推理模型）进行了基准测试。

**Result:** 测试结果表明，没有模型能够始终成功地过滤不可信信息；尽管推理能力与更高的分数相关，但即使是测试中表现最好的API模型，其幻觉率也高达70%。值得注意的是，更大、能力更强的模型不一定比其小型对应模型表现更优。

**Conclusion:** 这项工作旨在揭示语言模型中这种重要的幻觉形式，并指导开发新的方法来对抗它。

> **ai_Abstract:** 本文介绍了SMeL测试，一个衡量语言模型媒体素养的简单基准。该测试评估LLM过滤互联网上不可信信息的能力。研究人员对多种主流LLM进行了基准测试，发现所有模型在过滤不可信内容方面均表现不佳，即使是具备推理能力的模型也存在高达70%的幻觉率。研究还指出，模型大小和性能之间没有必然的正相关关系。这项工作旨在揭示LLM的幻觉问题并推动相关应对方法的发展。

> **摘要翻译:** 互联网上充斥着未经注明出处、蓄意误导或以其他方式不可信的内容。尽管大型语言模型（LLM）通常被赋予自主网页浏览的任务，但它们在多大程度上掌握了人类研究人员用于应对这种嘈杂环境的简单启发式方法，目前尚不清楚。在本文中，我们引入了合成媒体素养测试（SMeL Test），这是一个最小化的基准测试，用于测试语言模型在上下文中主动过滤不可信信息的能力。我们对各种常用的指令微调LLM（包括推理模型）进行了基准测试，发现没有模型能够始终成功；虽然推理能力尤其与更高的分数相关，但即使是我们测试过的最好的API模型，其幻觉率也高达70%。值得注意的是，更大、能力更强的模型不一定优于其小型对应模型。我们希望我们的工作能更多地揭示这种重要的幻觉形式，并指导开发新的方法来对抗它。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [79] [An Entity Linking Agent for Question Answering](https://arxiv.org/abs/2508.03865)
> *问答系统中的实体链接代理*

*Yajie Luo, Yihong Wu, Muzhi Li, Fengran Mo, Jia Ao Sun, Xinyu Wang, Liheng Ma, Yingxue Zhang, Jian-Yun Nie* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 实体链接,问答系统,大型语言模型,知识库,短文本

**Comment:** 

> **TL;DR:** 本文提出了一个基于大型语言模型的实体链接代理，用于解决问答系统中短而模糊的用户问题，并在实验中验证了其有效性。

**AI_Comments:** 该研究提出了一种新颖的基于LLM的实体链接代理，通过模拟人类认知工作流程，有效解决了传统EL方法在短文本、模糊问题场景下的性能瓶颈，对于提升基于知识库的QA系统性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的实体链接（EL）方法主要针对长文本设计，在处理问答（QA）任务中短小、模糊的用户问题时表现不佳。

**Method:** 本文提出了一个基于大型语言模型（LLM）的实体链接代理，该代理模拟人类认知流程，主动识别实体提及、检索候选实体并做出决策。

**Result:** 实验结果证实了所提出的实体链接代理的鲁棒性和有效性。

**Conclusion:** 该实体链接代理能够有效解决问答系统中短而模糊问题的实体链接挑战。

> **ai_Abstract:** 本文针对现有实体链接（EL）方法在处理问答（QA）系统中短而模糊用户问题时的不足，提出了一种基于大型语言模型（LLM）的实体链接代理。该代理模拟人类认知过程，能够主动识别实体、检索候选并做出决策。通过工具型实体链接和QA任务评估两项实验，验证了该代理的鲁棒性和有效性。

> **摘要翻译:** 一些问答（QA）系统依赖知识库（KBs）提供准确的答案。实体链接（EL）在将自然语言提及链接到知识库条目中起着关键作用。然而，大多数现有EL方法是为长文本设计的，在QA任务中处理短小、模糊的用户问题时表现不佳。我们提出了一种基于大型语言模型（LLM）的问答实体链接代理，该代理模拟人类认知工作流程。该代理主动识别实体提及，检索候选实体，并做出决策。为了验证我们代理的有效性，我们进行了两项实验：基于工具的实体链接和QA任务评估。结果证实了我们代理的鲁棒性和有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [87] [GM-PRM: A Generative Multimodal Process Reward Model for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2508.04088)
> *GM-PRM: 一种用于多模态数学推理的生成式多模态过程奖励模型*

*Jianghangfan Zhang, Yibo Yan, Kening Zheng, Xin Zou, Song Dai, Xuming Hu* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多模态数学推理, 过程奖励模型, 生成式模型, 错误修正, MLLM

**Comment:** 

> **TL;DR:** GM-PRM是一种新的多模态过程奖励模型，它不仅能识别多模态数学推理中的错误，还能生成修正，显著提高了复杂数学问题的解决能力。

**AI_Comments:** GM-PRM的创新之处在于将过程奖励模型从被动错误识别器转变为主动错误修正器，通过生成性能力直接提供纠正反馈。这种主动协作的方式显著提升了多模态模型在复杂数学推理中的鲁棒性和准确性，并且其高数据效率也凸显了其潜在的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在复杂多步数学推理中表现不佳，视觉感知或逻辑推断中的小错误可能导致彻底失败。现有的多模态过程奖励模型（PRMs）仅限于二元验证，只能识别错误但不能纠正错误，且解释能力有限。

**Method:** 本文提出了生成式多模态过程奖励模型（GM-PRM），它将PRM从被动评判者转变为主动推理协作器。GM-PRM提供对每个推理步骤细粒度、可解释的分析，评估其步骤意图、视觉对齐和逻辑合理性。更重要的是，GM-PRM被训练来生成其识别的第一个错误步骤的修正版本。这种独特的纠正能力使得新的测试时推理策略Refined Best-of-N（Refined-BoN）得以实现，该框架通过使用PRM生成的修正来引导策略模型走向更有希望的推理轨迹，从而提高解决方案池的多样性和正确性。

**Result:** GM-PRM在多个多模态数学基准测试中取得了最先进的结果，显著提升了策略模型的性能，并且数据效率显著，仅需要2万个样本的训练数据集。

**Conclusion:** GM-PRM通过提供细粒度的错误分析和生成纠正，有效地解决了多模态大语言模型在复杂数学推理中的挑战，并取得了最先进的性能，证明了其作为主动推理协作器的有效性。

> **ai_Abstract:** 本文提出了一种生成式多模态过程奖励模型（GM-PRM），旨在解决多模态大语言模型在复杂数学推理中易出错的问题。与现有仅能识别错误的多模态PRM不同，GM-PRM能对推理步骤进行细粒度分析，并能生成识别出的第一个错误步骤的修正。结合Refined Best-of-N推理策略，GM-PRM能主动引导模型修正推理轨迹，从而提高解决方案的质量和多样性。实验结果表明，GM-PRM在多个多模态数学基准测试中取得了最先进的性能，且数据效率高。

> **摘要翻译:** 多模态大语言模型（MLLMs）展现出卓越的能力，但通常在复杂的、多步骤的数学推理中遇到困难，其中视觉感知或逻辑推断中的微小错误都可能导致完全失败。尽管过程奖励模型（PRMs）提供了逐步监督，但现有的多模态PRMs仅限于二元验证器，只能识别错误但不能纠正错误，解释能力也很弱。为了解决这些不足，我们引入了生成式多模态过程奖励模型（GM-PRM），这是一种新颖的范式，它将PRM从被动评判者转变为主动推理协作器。GM-PRM不是简单的标量分数，而是对每个推理步骤提供细粒度、可解释的分析，评估其步骤意图、视觉对齐和逻辑合理性。更关键的是，GM-PRM经过训练可以生成其识别的第一个错误步骤的修正版本。这种独特的纠正能力使我们的新测试时推理策略Refined Best-of-N（Refined-BoN）得以实现。该框架通过使用PRM生成的修正来引导策略模型走向更有希望的推理轨迹，从而积极提高解决方案的质量，进而改善解决方案池的多样性和正确性。我们证明了GM-PRM在多个多模态数学基准测试中取得了最先进的结果，以卓越的数据效率显著提升了策略模型的性能，仅需要2万个样本的训练数据集。我们的代码将在接受后发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [94] [Balancing Stylization and Truth via Disentangled Representation Steering](https://arxiv.org/abs/2508.04530)
> *通过解耦表示引导平衡风格化与真实性*

*Chenglei Shen, Zhongxiang Sun, Teng Shi, Xiao Zhang, Jun Xu* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 风格化, 真实性, 大型语言模型, 表示学习, 解耦

**Comment:** 

> **TL;DR:** 提出StyliTruth，一种通过解耦语言模型中的风格和真实性表示来生成风格化且保持真实性的响应的方法，解决了现有方法中风格化导致真实性下降的问题。

**AI_Comments:** 这篇论文创新性地提出了通过解耦LLM内部的表示空间来解决风格化与真实性之间的冲突，而不是简单地注入风格信号。其核心思想——将风格和真实性分离到不同的正交子空间中，并通过自适应引导向量进行精细控制，为LLM的细粒度输出控制提供了一个新颖且有效的方法。这对于需要兼顾表达方式和信息准确性的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在生成风格化的大型语言模型(LLM)响应时，现有方法通过简单地注入风格信号，往往会污染模型的真实性表示，导致答案正确性下降，即“风格化引起的真实性崩溃”。这源于模型中风格和真实性方向之间的潜在耦合。

**Method:** 提出StyliTruth机制。该机制通过正交紧缩过程在模型的表示空间中分离出与风格相关和与真实性相关的子空间。这种分解使得在各自子空间中能够独立控制风格和真实性，从而最大限度地减少干扰。通过在每个子空间内设计自适应的、令牌级的引导向量，动态精确地控制生成过程，以保持风格保真度和真实性。

**Result:** 在多种风格和语言上进行了验证。大量的实验和分析表明，StyliTruth显著减少了风格化引起的真实性崩溃，并且在平衡风格遵循和真实性方面优于现有的推理时干预方法。

**Conclusion:** StyliTruth通过解耦LLM中的风格和真实性表示，有效解决了风格化与真实性之间的固有权衡问题，显著提高了生成风格化响应时的真实性，并优于现有方法。

> **ai_Abstract:** 这篇论文提出了StyliTruth，一种用于大型语言模型（LLM）的表示引导机制，旨在解决生成风格化响应时真实性下降的问题。StyliTruth通过正交紧缩过程将模型表示空间中的风格和真实性子空间解耦，从而实现对风格和真实性的独立控制。通过在各自子空间中应用自适应的令牌级引导向量，该方法能够在保持风格保真度的同时，显著减少风格化引起的真实性崩溃，并在实验中表现优于现有方法。

> **摘要翻译:** 通过表示编辑生成风格化的大型语言模型（LLM）响应是一种有前景的细粒度输出控制方式。然而，存在一种固有的权衡：施加独特的风格往往会降低真实性。现有的表示编辑方法通过简单地注入风格信号，忽视了这种附带影响，并且经常污染模型的核心真实性表示，导致答案正确性降低。我们将这种现象称为风格化引起的真实性崩溃。我们将此问题归因于某些关键注意力头中风格和真实性方向之间的潜在耦合，并提出了StyliTruth，一种在保持风格化的同时保持真实性不变的机制。StyliTruth通过正交紧缩过程在模型的表示空间中分离出与风格相关和与真实性相关的子空间。这种分解使得在各自子空间中能够独立控制风格和真实性，从而最大限度地减少干扰。通过在每个子空间内设计自适应的、令牌级的引导向量，我们动态精确地控制生成过程，以保持风格保真度和真实性。我们在多种风格和语言上验证了我们的方法。大量的实验和分析表明，StyliTruth显著减少了风格化引起的真实性崩溃，并且在平衡风格遵循和真实性方面优于现有的推理时干预方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [101] [IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2508.04632)
> *IFDECORATOR：用可验证奖励包装指令遵循强化学习*

*Xu Guo, Tianyi Liang, Tong Jian, Xiaogui Yang, Ling-I Wu, Chenhui Li, Zhihui Lu, Qipeng Guo, Kai Chen* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 指令遵循, 强化学习, 可验证奖励, 大型语言模型, 奖励作弊

**Comment:** 

> **TL;DR:** IFDecorator通过合作对抗数据飞轮、IntentCheck和跳闸线解决了可验证奖励强化学习（RLVR）在指令遵循方面的训练效率低下和过度优化问题，显著提高了性能并减少了奖励作弊。

**AI_Comments:** IFDecorator通过其独特的三组件设计，尤其是在数据生成（合作对抗数据飞轮）和行为诊断（跳闸线）方面的创新，为解决RLVR的效率和鲁棒性问题提供了新的思路。它不仅提高了模型在指令遵循上的性能，还关注了“奖励作弊”这一重要且具有挑战性的问题，这对于构建更安全、更可靠的AI系统具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 可验证奖励强化学习（RLVR）在提升大型语言模型（LLM）指令遵循能力时，存在训练效率低下（由于难度评估不足）和过度优化（LLM利用验证捷径而非对齐实际用户意图）的问题。

**Method:** 本文提出了指令遵循装饰器（IFDecorator）框架，它将RLVR训练包装成一个健壮且样本高效的管道。IFDecorator包含三个核心组件：1. 合作对抗数据飞轮：协同演进指令和混合验证，以生成难度逐渐增加的指令-验证对。2. IntentCheck：一个旁路模块，用于强制执行意图对齐。3. 跳闸线：一种诊断机制，通过陷阱指令来检测奖励作弊，从而触发并捕获捷径利用行为。

**Result:** Qwen2.5-32B-Instruct-IFDecorator在IFEval上实现了87.43%的准确率，超越了包括GPT-4o在内的更大专有模型。此外，该方法在FollowBench上展示了显著改进，同时保持了通用能力。跳闸线机制显著降低了奖励作弊率。

**Conclusion:** IFDecorator框架通过其创新的组件设计，有效解决了RLVR在指令遵循训练中面临的效率低下和过度优化问题，显著提升了大型语言模型的指令遵循能力，并能有效检测和减少奖励作弊行为。

> **ai_Abstract:** 本文针对可验证奖励强化学习（RLVR）在大型语言模型（LLM）指令遵循中存在的训练效率低下和过度优化问题，提出了IFDecorator框架。该框架通过引入合作对抗数据飞轮、IntentCheck模块和跳闸线机制，分别解决了渐进式难度生成、意图对齐强制以及奖励作弊检测。实验结果表明，IFDecorator显著提升了LLM在指令遵循任务上的表现，并在IFEval上超越了GPT-4o等领先模型，同时有效降低了奖励作弊率。

> **摘要翻译:** 可验证奖励强化学习（RLVR）提高了大型语言模型（LLM）的指令遵循能力，但由于难度评估不足而导致训练效率低下。此外，RLVR容易过度优化，LLM会利用验证捷径，而不是与用户指令的实际意图对齐。我们引入了指令遵循装饰器（IFDecorator），一个将RLVR训练包装成健壮且样本高效的管道的框架。它由三个组件组成：（1）一个合作对抗数据飞轮，协同演进指令和混合验证，生成难度逐渐增加的指令-验证对；（2）IntentCheck，一个强制意图对齐的旁路模块；（3）跳闸线，一种通过陷阱指令检测奖励作弊的诊断机制，用于触发和捕获捷径利用行为。我们的Qwen2.5-32B-Instruct-IFDecorator在IFEval上达到了87.43%的准确率，超越了GPT-4o等大型专有模型。此外，我们展示了在FollowBench上的显著改进，同时保留了通用能力。我们的跳闸线显示奖励作弊率显著降低。我们将发布模型、代码和数据以供未来研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [107] [Verbalized Representation Learning for Interpretable Few-Shot Generalization](https://arxiv.org/abs/2411.18651)
> *可解释的少样本泛化口语化表征学习*

*Cheng-Fu Yang, Da Yin, Wenbo Hu, Heng Ji, Nanyun Peng, Bolei Zhou, Kai-Wei Chang* | **Category: cs.CL, cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 口语化表征学习, 少样本泛化, 可解释性, 视觉-语言模型, 目标识别

**Comment:** 

> **TL;DR:** 本文提出了一种名为VRL的新方法，通过使用视觉-语言模型自动提取人类可解释的口语化特征，显著提高了少样本目标识别的泛化能力，并在数据量更少的情况下取得了显著优于现有SOTA方法的结果。

**AI_Comments:** 这项工作具有创新性，它利用了视觉-语言模型来生成可解释的、口语化的特征，这与人类学习方式相契合。其在少样本设置下实现了显著的性能提升和数据效率，解决了低数据场景下的泛化难题，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 人类在观察少量样本后就能识别物体，这得益于他们对现实世界环境固有的语言理解能力。在低数据设置下，开发口语化和可解释的表征可以显著提高模型的泛化能力。

**Method:** 本文提出口语化表征学习（VRL）方法，利用视觉-语言模型（VLM）自动提取用于目标识别的人类可解释特征。该方法通过VLM识别不同类别之间的关键判别特征和相同类别内的共享特征，以自然语言的形式独特地捕获类间差异和类内共性。这些口语化特征随后通过VLM映射为数值向量，可用于训练和推理下游分类器。

**Result:** 实验结果表明，在相同的模型规模下，VRL比现有最先进方法提高了24%的绝对性能，同时使用的数据量减少了95%，模型更小。此外，与人类标注属性相比，VRL学习到的特征在下游分类任务中表现出20%的绝对增益。

**Conclusion:** VRL通过自动提取可解释的口语化特征，显著提升了少样本目标识别的泛化能力，并且在数据效率和性能上均优于现有方法。

> **ai_Abstract:** 本文提出了一种名为口语化表征学习（VRL）的新颖方法，旨在通过自动提取人类可解释的特征来提高少样本数据下的目标识别模型泛化能力。VRL利用视觉-语言模型（VLM）以自然语言形式捕获类间差异和类内共性，并将这些口语化特征转换为数值向量供下游分类器使用。实验证明，VRL在显著减少数据量（95%）和模型规模的同时，比现有最先进方法取得了24%的绝对性能提升，并且其学习到的特征在下游分类任务中比人类标注属性高出20%的绝对增益。

> **摘要翻译:** 人类在观察少量样本后就能识别物体，这是一种卓越的能力，得益于他们对现实世界环境固有的语言理解。开发口语化和可解释的表征可以显著提高模型在低数据设置下的泛化能力。在这项工作中，我们提出了口语化表征学习（VRL），一种新颖的方法，用于使用少样本数据自动提取用于目标识别的人类可解释特征。我们的方法独特地通过雇佣视觉-语言模型（VLM）来识别不同类别之间的关键判别特征和相同类别内的共享特征，以自然语言的形式捕获类间差异和类内共性。这些口语化特征随后通过VLM映射为数值向量。生成的特征向量可以进一步用于训练和推理下游分类器。实验结果表明，在相同的模型规模下，VRL比现有最先进方法取得了24%的绝对性能提升，同时使用的数据量减少了95%，并且模型更小。此外，与人类标注属性相比，VRL学习到的特征在用于下游分类任务时表现出20%的绝对增益。代码可在https://github.com/joeyy5588/VRL/tree/main获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [115] [Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey](https://arxiv.org/abs/2412.20367)
> *强化学习赋能代码生成中的代码大型语言模型：一项综述*

*Junqiao Wang, Zeng Zhang, Yangfan He, Zihao Zhang, Xinyuan Song, Yuyang Song, Tianyu Shi, Yuchen Li, Hengyuan Xu, Kunyu Wu, Xin Yi, Zhongwei Wan, Xinhang Yuan, Zijun Wang, Kuan Lu, Menghao Huo, Tang Jingqun, Guangwu Qian, Keqin Li, Qiuwu Chen, Lewei He* | **Category: cs.CL, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 强化学习, 代码生成, 代码优化, 大型语言模型, 编译器优化

**Comment:** 

> **TL;DR:** 这篇综述系统地回顾了强化学习在代码生成和优化中的应用，特别关注编译器优化、资源分配以及框架和工具的开发。

**AI_Comments:** 这篇综述及时地关注了强化学习在代码大型语言模型（Code LLMs）和代码生成领域的交叉应用，填补了该领域系统性文献的空白。它为研究人员和实践者提供了一个全面的视角，有助于理解和应用RL来优化代码生成流程。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLM）的快速发展，强化学习（RL）已成为代码生成和优化领域的一项关键技术。本综述旨在为对利用强化学习推进代码生成和优化技术感兴趣的研究人员和实践者提供一个全面的资源。

**Method:** 本文提出了一项系统性综述，探讨强化学习在代码优化和生成中的应用。它深入研究了强化学习在编译器优化、资源分配以及代码生成框架和工具中的作用。

**Result:** 综述强调了强化学习在增强编译器优化、资源分配（特别是寄存器分配和系统优化）以及代码生成框架和工具能力方面的作用。

**Conclusion:** 这篇综述旨在作为对利用强化学习推进代码生成和优化技术感兴趣的研究人员和从业人员的全面资源。

> **ai_Abstract:** 本文系统性地综述了强化学习在代码生成与优化领域的应用。内容涵盖了强化学习如何提升编译器优化效率、优化资源分配（如寄存器分配和系统优化），以及如何整合到代码生成框架和工具中以增强其功能。本综述旨在为相关研究人员和实践者提供一个全面的参考。

> **摘要翻译:** 随着大型语言模型（LLM）的快速发展，强化学习（RL）已成为代码生成和优化领域的一项关键技术。本文系统地综述了强化学习在代码优化和生成中的应用，强调了其在增强编译器优化、资源分配以及框架和工具开发中的作用。随后的章节首先深入探讨了编译器优化的复杂过程，其中利用强化学习算法来提高效率和资源利用率。然后讨论进展到强化学习在资源分配中的作用，强调寄存器分配和系统优化。我们还探讨了框架和工具在代码生成中日益增长的作用，研究了如何整合强化学习以增强其能力。本综述旨在为对利用强化学习推进代码生成和优化技术感兴趣的研究人员和实践者提供一个全面的资源。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [123] [Human Cognitive Benchmarks Reveal Foundational Visual Gaps in MLLMs](https://arxiv.org/abs/2502.16435)
> *人类认知基准揭示多模态大语言模型（MLLMs）在视觉方面的基础性缺陷*

*Jen-Tse Huang, Dasen Dai, Jen-Yuan Huang, Youliang Yuan, Xiaoyuan Liu, Wenxuan Wang, Wenxiang Jiao, Pinjia He, Zhaopeng Tu, Haodong Duan* | **Category: cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** MLLMs, 视觉推理, 认知基准, VisFactor, 人类认知

**Comment:** 

> **TL;DR:** 尽管在流行多模态基准上取得了显著进展，但多模态大语言模型（MLLMs）在人类轻易解决的基本视觉推理任务（如识别空间关系）上仍表现不佳。为系统性调查这一差距，研究引入了VisFactor，一个数字化了20项来自成熟认知心理学评估的以视觉为中心的子测试的基准。评估结果显示，即使是表现最佳的模型也仅获得25.19分（满分100分），在心理旋转、空间关系推理和图形-背景辨别等任务上持续失败，这表明当前MLLMs在高层基准上的性能提升并未反映出类人低层视觉认知能力。

**AI_Comments:** 该论文的创新之处在于引入了VisFactor这一新颖的基准，它基于人类认知心理学评估，为MLLMs的视觉推理能力提供了一个更具人类中心视角的评估方法。其重要性在于揭示了当前MLLMs的一个关键局限性——尽管在高层任务上表现出色，但仍缺乏基础的低层视觉认知能力。这直接挑战了关于大规模预训练能够自然产生类人感知能力的普遍假设。抽象中未详细说明所使用的具体“认知心理学评估”的名称。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在流行的多模态基准测试上取得了显著进展，但当前最先进的多模态大语言模型（MLLMs）在人类可以轻易解决的基本视觉推理任务（如识别空间关系）上仍然表现困难。本研究的动机是系统性地调查并量化这一差距。

**Method:** 研究引入了VisFactor基准，该基准将一项成熟认知心理学评估中的20项以视觉为中心的子测试数字化。这些子测试涵盖了人类视觉认知的四个核心领域：可视化与空间处理、感知与闭合、记忆和推理。研究评估了来自GPT、Gemini、Claude、LLaMA、Qwen和SEED家族的20个前沿MLLM。

**Result:** 评估结果显示，表现最佳的模型得分仅为100分中的25.19分。模型在心理旋转、空间关系推理和图形-背景辨别等任务上持续失败，无论模型大小或提示策略如何，都表现出一致的不足。

**Conclusion:** 研究结果表明，当前MLLMs在高层基准上获得的性能提升并未反映出类人低层视觉认知能力。这挑战了大规模预训练自然会诱导类格式塔感知能力的假设。

> **ai_Abstract:** 本研究发现，尽管在多模态基准上有所进步，但多模态大语言模型（MLLMs）在人类轻易解决的基本视觉推理任务上仍存在显著缺陷。为深入探究此差距，研究引入了VisFactor基准，其数字化了20项源自成熟认知心理学评估的视觉子测试，涵盖了人类视觉认知的四大核心领域。对20个主流MLLMs的评估结果显示，最佳模型得分仅为25.19/100，并在心理旋转、空间关系推理等任务上普遍失败，这表明当前MLLMs的性能提升并未带来类人低层视觉认知能力，挑战了大规模预训练能自然诱导格式塔式感知能力的假设。

> **摘要翻译:** 尽管在流行的多模态基准上取得了显著进展，但当前最先进的多模态大语言模型（MLLMs）在人类可以轻易解决的基本视觉推理任务（如识别空间关系）上仍然表现困难。为了系统地调查这一差距，我们引入了VisFactor，这是一个将一项成熟认知心理学评估中的20项以视觉为中心的子测试数字化的基准。这些子测试涵盖了人类视觉认知的四个核心领域：(1) 可视化与空间处理，(2) 感知与闭合，(3) 记忆，和 (4) 推理。我们评估了来自GPT、Gemini、Claude、LLaMA、Qwen和SEED家族的20个前沿MLLM。表现最佳的模型得分仅为100分中的25.19分，在心理旋转、空间关系推理和图形-背景辨别等任务上持续失败，无论模型大小或提示策略如何。这些发现表明，当前MLLMs在高层基准上获得的性能提升并未反映出类人低层视觉认知能力，这挑战了大规模预训练自然会诱导类格式塔感知能力的假设。数据集和评估工具已公开：https://github.com/CUHK-ARISE/VisFactor。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [669] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
> *音高重音检测提升预训练自动语音识别*

*David Sasu, Natalie Schluter* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-08-06**

**Keywords:** 音高重音检测, 自动语音识别, 联合训练, 韵律线索, 半监督学习

**Comment:** 

> **TL;DR:** 通过引入联合ASR和音高重音检测模型，自动语音识别（ASR）性能得到了显著提升，同时音高重音检测任务也取得了最先进的改进，强调了在预训练语音模型中保留或重新学习韵律线索的重要性。

**AI_Comments:** 该论文的创新点在于提出了一个联合模型，将音高重音检测与ASR相结合，有效地利用了韵律信息来提升语音识别性能。在资源有限的微调场景下，ASR性能的显著提升（WER降低28.3%）具有重要的实际意义。此外，音高重音检测任务本身的改进也显示了该方法的有效性。这强调了多任务学习和显式建模韵律线索在语音处理中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升使用半监督语音表示的自动语音识别（ASR）系统的性能，通过引入一个互补的音高重音检测模块。

**Method:** 引入了一个联合ASR和音高重音检测模型，以提升ASR性能并改进音高重音检测。

**Result:** 音高重音检测组件在F1-score上将与现有技术水平的差距缩小了41%。在有限资源微调下，联合训练使LibriSpeech上的ASR词错误率（WER）降低了28.3%。

**Conclusion:** 本研究表明，扩展预训练语音模型以保留或重新学习重要的韵律线索（如音高重音）非常重要。

> **ai_Abstract:** 本研究提出了一种联合自动语音识别（ASR）和音高重音检测模型，旨在提升ASR系统的性能。实验结果表明，该模型的音高重音检测组件在F1-score上将与现有最佳技术的差距缩小了41%。同时，在有限资源微调的条件下，联合训练使得ASR在LibriSpeech数据集上的词错误率（WER）降低了28.3%。这突显了将音高重音等重要韵律线索整合到预训练语音模型中的重要性。

> **摘要翻译:** 我们展示了通过引入一个联合ASR和音高重音检测模型，使用半监督语音表示的自动语音识别（ASR）系统的性能可以通过一个互补的音高重音检测模块得到提升。我们模型的音高重音检测组件在该任务上取得了显著的最新技术改进，将F1-score的差距缩小了41%。此外，在有限资源微调下，联合训练中的ASR性能在LibriSpeech上将词错误率（WER）降低了28.3%。通过这些结果，我们展示了扩展预训练语音模型以保留或重新学习重要的韵律线索（如音高重音）的重要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [674] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
> *基于统一视觉、文本和上下文表示的多模态事实核查*

*Aditya Kishore, Gaurav Kumar, Jasabanta Patro* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 多模态事实核查, 错误信息, MultiCheck, 对比学习, 跨模态推理

**Comment:** 

> **TL;DR:** 本文提出了“MultiCheck”，一个统一的多模态事实核查框架，旨在处理视觉、文本和上下文信息，并在Factify 2数据集上显著优于基线。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的框架“MultiCheck”，它能够同时处理视觉、文本和上下文信息，并通过对比学习来增强跨模态的语义对齐。这对于解决当前多模态错误信息泛滥的挑战具有重要意义，尤其是在需要可扩展和可解释的真实世界应用中。

<details>
  <summary>Details</summary>

**Motivation:** 多模态错误信息（文本和图像共同支持的声明）的日益增长，对主要依赖文本证据的事实核查系统构成了重大挑战。

**Method:** 本文提出了一个名为“MultiCheck”的统一框架，用于细粒度多模态事实核查。该架构结合了文本和图像的专用编码器，以及一个使用元素级交互捕获跨模态关系的融合模块。分类头预测声明的真实性，并辅以对比学习目标，以鼓励共享潜在空间中声明-证据对之间的语义对齐。

**Result:** 在Factify 2数据集上，我们提出的方法实现了0.84的加权F1分数，显著优于基线。

**Conclusion:** 这些结果突出了显式多模态推理的有效性，并展示了我们方法在复杂、真实场景中进行可扩展和可解释事实核查的潜力。

> **ai_Abstract:** 针对日益增长的多模态错误信息问题，本文提出了“MultiCheck”框架，一个统一的细粒度多模态事实核查系统。该系统通过专用编码器处理文本和图像，并利用融合模块捕获跨模态关系，结合对比学习实现声明与证据的语义对齐。在Factify 2数据集上的评估显示，MultiCheck达到了0.84的加权F1分数，显著优于基线，证明了其在复杂真实世界场景中进行可扩展和可解释事实核查的有效性和潜力。

> **摘要翻译:** 多模态错误信息（其中声明由文本和图像共同支持）的日益增长，对主要依赖文本证据的事实核查系统构成了重大挑战。在这项工作中，我们提出了一个名为“MultiCheck”的统一框架，用于细粒度多模态事实核查，旨在对结构化文本和视觉信号进行推理。我们的架构结合了文本和图像的专用编码器，以及一个使用元素级交互捕获跨模态关系的融合模块。分类头然后预测声明的真实性，并辅以对比学习目标，以鼓励共享潜在空间中声明-证据对之间的语义对齐。我们在Factify 2数据集上评估了我们的方法，实现了0.84的加权F1分数，显著优于基线。这些结果突出了显式多模态推理的有效性，并展示了我们方法在复杂、真实场景中进行可扩展和可解释事实核查的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [683] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
> *我思故我不足格？一个用于评估大型语言模型招聘评估中语言石化现象检测的基准*

*Julia Kharchenko, Tanya Roosta, Aman Chadha, Chirag Shah* | **Category: cs.CL** | **Updated: 2025-08-06**

**Keywords:** 语言石化现象, 大型语言模型, 招聘评估, 语言歧视, 委婉语

**Comment:** 

> **TL;DR:** 本文引入了一个新基准，用于评估大型语言模型在招聘评估中如何响应语言石化现象（如委婉语），发现LLM会系统性地惩罚某些语言模式，导致对特定语言（如委婉语）的评分降低，从而揭示了AI系统中的语言歧视并为公平性提供了框架。

**AI_Comments:** 该论文的创新之处在于提出了一个专门用于评估LLM在招聘场景中语言歧视的综合基准。它通过控制语言变量来精确测量偏见，并明确指出了LLM对特定语言模式（如委婉语）的惩罚，这对于理解和改进AI系统的公平性至关重要。这项工作为未来的研究提供了一个量化和解决AI系统潜在偏见的新视角。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为了评估大型语言模型（LLMs）在招聘评估中如何响应细微的语言标记（语言石化现象），这些标记可能无意中揭示人口属性（如性别、社会阶层或地域背景），并发现LLMs是否会系统性地惩罚某些语言模式，例如委婉语，即使内容质量相同。

**Method:** 本文引入了一个综合基准，通过精心构建的面试模拟（使用100对经过验证的问题-回答对）来评估LLMs。该基准生成受控的语言变体，在保持语义等效性的同时，隔离特定的语言现象，从而精确测量自动化评估系统中的人口偏见。研究还沿着多个语言维度验证了其方法。

**Result:** 研究结果表明，大型语言模型（LLMs）系统性地惩罚某些语言模式，特别是委婉语，尽管内容质量相同。平均而言，委婉的回答会收到低25.6%的评分。该基准有效识别了模型特定的偏见。

**Conclusion:** 这项工作为检测和测量AI系统中的语言歧视建立了一个基础框架，在自动化决策情境下的公平性方面具有广泛的应用。

> **ai_Abstract:** 该论文提出了一个全面的基准，用于评估大型语言模型（LLMs）在招聘评估中对语言石化现象（如委婉语）的响应。通过模拟面试，研究发现LLMs系统性地惩罚某些语言模式，特别是委婉语，导致评分显著降低。该基准通过生成受控的语言变体来精确测量LLM评估中的人口偏见，为检测和量化AI系统中的语言歧视提供了一个基础框架，对自动化决策的公平性具有重要意义。

> **摘要翻译:** 本文引入了一个综合基准，用于评估大型语言模型（LLMs）如何响应语言石化现象：这些细微的语言标记可能无意中揭示人口属性，如性别、社会阶层或地域背景。通过使用100对经过验证的问题-回答对精心构建的面试模拟，我们展示了LLMs如何系统性地惩罚某些语言模式，特别是委婉语，尽管内容质量相同。我们的基准生成受控的语言变体，在保持语义等效性的同时隔离特定现象，这使得能够精确测量自动化评估系统中的人口偏见。我们沿着多个语言维度验证了我们的方法，表明委婉的回答平均会收到低25.6%的评分，并证明了该基准在识别模型特定偏见方面的有效性。这项工作为检测和测量AI系统中的语言歧视建立了一个基础框架，在自动化决策情境下的公平性方面具有广泛的应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [685] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
> *BEE-RAG：检索增强生成中的平衡熵工程*

*Yuhao Wang, Ruiyang Ren, Yucheng Wang, Jing Liu, Wayne Xin Zhao, Hua Wu, Haifeng Wang* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 检索增强生成, 熵工程, 长上下文, 注意力稀释, 大型语言模型

**Comment:** 

> **TL;DR:** BEE-RAG通过平衡上下文熵来解决检索增强生成（RAG）中长上下文导致的熵增长和注意力稀释问题，从而提高RAG系统的适应性和性能。

**AI_Comments:** BEE-RAG的创新点在于从熵工程的角度审视RAG中的长上下文问题，并提出了熵不变性原理来解决注意力稀释。这种将信息论概念应用于模型架构设计的方法具有独特性和前瞻性，可能为未来处理长上下文问题提供新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）存在固有的知识限制，检索增强生成（RAG）是补充这一限制的关键方法。然而，由于检索信息量大，RAG通常需要处理长上下文，这会导致熵增长失控和注意力稀释，从而显著影响RAG性能。

**Method:** 本文提出了平衡熵工程RAG（BEE-RAG）框架，通过熵不变性原理改善RAG系统对不同上下文长度的适应性。BEE-RAG利用平衡上下文熵来重新构建注意力动态，使注意力敏感性与上下文长度分离，确保稳定的熵水平。在此基础上，引入了多重要性估计的零样本推理策略和参数高效的自适应微调机制，以获取不同设置下的最优平衡因子。

**Result:** 在多个RAG任务上的大量实验证明了BEE-RAG的有效性。

**Conclusion:** BEE-RAG通过引入平衡熵工程，有效解决了RAG系统中长上下文导致的性能问题，提高了系统在不同上下文长度下的适应性和表现。

> **ai_Abstract:** 本文提出了BEE-RAG（平衡熵工程检索增强生成）框架，旨在解决现有RAG系统中因长上下文引起的熵增长和注意力稀释问题。BEE-RAG基于熵不变性原理，通过平衡上下文熵来重构注意力机制，使注意力不再受上下文长度影响，从而在不同上下文长度下保持稳定的性能。研究还引入了零样本推理和自适应微调机制以优化平衡因子。实验结果表明，BEE-RAG在多个RAG任务上表现出显著的有效性。

> **摘要翻译:** 随着大型语言模型（LLMs）的快速发展，检索增强生成（RAG）已成为补充LLMs固有知识限制的关键方法。然而，由于检索信息量通常很大，RAG倾向于在长上下文长度下运行。从熵工程的角度来看，我们认为长检索上下文导致的无约束熵增长和注意力稀释是影响RAG性能的重要因素。在本文中，我们提出了平衡熵工程RAG（BEE-RAG）框架，该框架通过熵不变性原理提高了RAG系统对不同上下文长度的适应性。通过利用平衡上下文熵重构注意力动态，BEE-RAG将注意力敏感性与上下文长度分离，确保稳定的熵水平。在此基础上，我们引入了一种用于多重要性估计的零样本推理策略和一种参数高效的自适应微调机制，以获取不同设置下的最佳平衡因子。在多个RAG任务上的大量实验证明了BEE-RAG的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [691] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
> *ATLANTIS在SemEval-2025任务3：问答系统中幻觉文本片段检测*

*Catherine Kobus, François Lancelot, Marion-Cécile Martin, Nawal Ould Amer* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 幻觉检测, 问答系统, 大型语言模型, SemEval, 提示工程

**Comment:** 

> **TL;DR:** ATLANTIS团队在SemEval-2025任务3中，通过结合上下文、少量样本提示、令牌级分类和微调LLM等方法，成功检测问答系统中的LLM幻觉文本，并在多语言任务中取得优异成绩。

**AI_Comments:** 这项研究通过参与SemEval任务，有效地展示了在实际应用中检测和缓解LLM幻觉的重要性与可行性。其创新之处在于结合了多种策略（有无上下文、少量样本提示、令牌级分类、LLM微调），并在多语言环境下验证了方法的有效性，为提升LLM的可靠性提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言生成（NLG）方面取得了显著进展，但仍容易产生幻觉，即生成不正确或误导性的内容。本研究旨在解决LLM在问答系统中产生幻觉文本的问题。

**Method:** 本文探讨了有或无外部上下文的方法，包括使用LLM进行少量样本提示（few-shot prompting）、令牌级分类（token-level classification）以及在合成数据上对LLM进行微调（fine-tuned on synthetic data）。

**Result:** ATLANTIS团队的方法在西班牙语任务中取得了最高排名，并在英语和德语任务中取得了有竞争力的成绩。

**Conclusion:** 这项工作强调了整合相关上下文以减轻幻觉的重要性，并展示了微调模型和提示工程的潜力。

> **ai_Abstract:** 本文介绍了ATLANTIS团队在SemEval-2025任务3中的工作，该任务旨在检测问答系统中大型语言模型产生的幻觉文本。研究团队探索了结合外部上下文、少量样本提示、令牌级分类以及LLM微调等多种方法来解决幻觉问题。实验结果表明，其方法在西班牙语任务中名列前茅，并在英语和德语任务中表现出色，凸显了整合上下文和模型优化的重要性。

> **摘要翻译:** 本文介绍了ATLANTIS团队对SemEval-2025任务3的贡献，该任务侧重于检测问答系统中的幻觉文本片段。大型语言模型（LLMs）在自然语言生成（NLG）方面取得了显著进展，但仍易受幻觉影响，生成不正确或误导性的内容。为了解决这个问题，我们探索了有和没有外部上下文的方法，利用LLM进行少量样本提示，令牌级分类或在合成数据上微调LLM。值得注意的是，我们的方法在西班牙语中取得了最高排名，并在英语和德语中取得了有竞争力的名次。这项工作强调了整合相关上下文以减轻幻觉的重要性，并展示了微调模型和提示工程的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [697] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
> *CodeBoost：通过强化学习从代码片段中提取知识以提升代码大语言模型*

*Sijie Wang, Quanjiang Guo, Kai Zhao, Yawei Zhang, Xin Li, Xiang Li, Siqi Li, Rui She, Shangshu Yu, Wee Peng Tay* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 代码大语言模型, 强化学习, 代码片段, 后训练, CodeBoost

**Comment:** 

> **TL;DR:** CodeBoost 是一种新的强化学习后训练框架，它利用丰富的代码片段来提升代码大语言模型，从而解决了对昂贵的人工标注指令的依赖。

**AI_Comments:** CodeBoost 的创新之处在于它提出了一种无需人工标注指令，纯粹利用大量代码片段进行代码 LLM 后训练的方法，这显著解决了数据瓶颈问题。其多组件的强化学习框架，如最大团筛选和异构奖励，为代码 LLM 的训练提供了新的思路，使其更具可扩展性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有代码大语言模型（LLMs）的后训练通常依赖于“人工指令-最终答案”对，但收集高质量的编码指令既费力又难以扩展。然而，代码片段却随处可见。这种不平衡是基于指令的后训练中的主要瓶颈。

**Method:** 我们提出了 CodeBoost，一个纯粹从代码片段中增强代码 LLMs 的后训练框架，不依赖人工标注指令。CodeBoost 引入了以下关键组件：(1) 最大团筛选：从代码中选择具有代表性和多样性的训练语料库；(2) 双向预测：使模型能够从前向和后向预测目标中学习；(3) 错误感知预测：结合来自正确和不正确输出的学习信号；(4) 异构增强：使训练分布多样化以丰富代码语义；(5) 异构奖励：通过多种奖励类型（包括格式正确性和来自成功与失败的执行反馈）指导模型学习。

**Result:** 在多个代码 LLMs 和基准测试上进行的广泛实验验证了 CodeBoost 持续提升了性能。

**Conclusion:** CodeBoost 证明了其作为可扩展且有效的训练流程的有效性。

> **ai_Abstract:** CodeBoost 提出了一种创新的后训练框架，旨在通过利用丰富的代码片段来提升代码大语言模型（LLMs），从而克服了传统方法对昂贵且难以获取的人工标注指令的依赖。该框架整合了多个关键组件，包括最大团筛选以选择多样化的语料库、双向和错误感知预测以从不同信号中学习、异构增强以丰富语义，以及异构奖励以多维度指导模型。实验结果表明，CodeBoost 能持续提升代码 LLMs 的性能，证明了其作为一种可扩展且高效训练管道的有效性。

> **摘要翻译:** 代码大语言模型（LLMs）已成为构建高效自动化编码流程不可或缺的工具。现有模型通常通过强化学习（RL）从通用 LLMs 进行后训练，使用“人工指令-最终答案”对，其中指令通常来自手动标注。然而，收集高质量的编码指令既费力又难以扩展。另一方面，代码片段可从各种来源大量获取。这种不平衡构成了基于指令的后训练中的主要瓶颈。我们提出了 CodeBoost，一个纯粹从代码片段中增强代码 LLMs 的后训练框架，不依赖人工标注指令。CodeBoost 引入了以下关键组件：(1) 最大团筛选，它从代码中选择具有代表性和多样性的训练语料库；(2) 双向预测，它使模型能够从前向和后向预测目标中学习；(3) 错误感知预测，它结合了来自正确和不正确输出的学习信号；(4) 异构增强，它使训练分布多样化以丰富代码语义；(5) 异构奖励，它通过多种奖励类型（包括格式正确性和来自成功与失败的执行反馈）指导模型学习。在多个代码 LLMs 和基准测试上进行的广泛实验验证了 CodeBoost 持续提升了性能，证明了其作为可扩展且有效训练流程的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [703] [ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for Late-Stage Fragility in LLMs](https://arxiv.org/abs/2508.05282)
> *ASCoT：一种针对LLM后期脆弱性的自适应自修正思维链方法*

*Dongxu Zhang, Ning Yang, Jihua Zhu, Jinnan Yang, Miao Xin, Baoliang Tian* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 思维链, 后期脆弱性, 自适应修正, 错误诊断

**Comment:** 

> **TL;DR:** LLM思维链在后期更容易出错，ASCoT通过识别和修正后期高风险步骤来提高准确性。

**AI_Comments:** 这篇论文的创新点在于挑战了传统对LLM推理错误传播的理解，提出了“后期脆弱性”这一反直觉但重要的发现。ASCoT方法针对这一特定问题设计了模块化的自适应修正机制，而非采用统一的验证策略，这对于提升LLM在复杂推理任务中的鲁棒性具有重要意义。研究结果表明了诊断特定故障模式的价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统观点认为LLM思维链早期错误危害最大，但本文通过实验发现“后期脆弱性”现象，即后期错误比早期错误更有可能破坏最终答案。因此，需要开发一种方法来解决这种特定的后期脆弱性。

**Method:** 本文提出了自适应自修正思维链（ASCoT）方法。ASCoT采用模块化管道，首先由自适应验证管理器（AVM）运行，该管理器利用位置影响评分函数I(k)识别并优先处理推理链中高风险的后期步骤。随后，多视角自修正引擎（MSCE）对识别出的失败部分进行鲁棒的双路径修正。

**Result:** 在GSM8K和MATH等基准测试上的广泛实验表明，ASCoT取得了出色的准确性，优于包括标准CoT在内的强基线方法。

**Conclusion:** 该工作强调了诊断LLM推理中特定故障模式的重要性，并提倡从统一验证策略转向自适应、关注脆弱性的修正机制。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）思维链（CoT）推理的可靠性问题。通过系统性错误注入实验，作者推翻了早期错误危害最大的传统假设，揭示了“后期脆弱性”现象，即CoT后期引入的错误对最终答案影响更大。为解决此问题，论文提出了自适应自修正思维链（ASCoT）方法，该方法通过自适应验证管理器（AVM）识别并优先处理高风险的后期步骤，再由多视角自修正引擎（MSCE）进行双路径修正。实验结果表明，ASCoT在多个基准测试上表现出色，显著提高了LLM的推理准确性。

> **摘要翻译:** 思维链（CoT）提示已显著提升大型语言模型（LLM）的推理能力，然而这些推理链的可靠性仍然是一个严峻的挑战。一个普遍持有的“级联失败”假设认为，错误在推理过程早期发生时危害最大。本文通过系统性的错误注入实验挑战了这一假设，揭示了一个反直觉的现象，我们称之为“后期脆弱性”：在CoT链后期引入的错误比在开始阶段引入的相同错误更有可能破坏最终答案。为了解决这一特定脆弱性，我们引入了自适应自修正思维链（ASCoT）方法。ASCoT采用模块化管道，其中自适应验证管理器（AVM）首先运行，随后是多视角自修正引擎（MSCE）。AVM利用位置影响评分函数I(k)根据推理链中的位置分配不同权重，通过识别和优先处理高风险的后期步骤来解决后期脆弱性问题。一旦识别出这些关键步骤，MSCE会专门对失败部分应用鲁棒的双路径修正。在GSM8K和MATH等基准测试上的广泛实验表明，ASCoT取得了出色的准确性，优于包括标准CoT在内的强基线方法。我们的工作强调了诊断LLM推理中特定故障模式的重要性，并提倡从统一验证策略转向自适应、关注脆弱性的修正机制。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [709] [Decision-Making with Deliberation: Meta-reviewing as a Document-grounded Dialogue](https://arxiv.org/abs/2508.05283)
> *深思熟虑的决策：作为文档基础对话的元评审*

*Sukannya Purkayastha, Nils Dycke, Anne Lauscher, Iryna Gurevych* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 元评审, 决策制定, 对话代理, 大型语言模型, 合成数据

**Comment:** 

> **TL;DR:** 本文将元评审视为决策过程，通过LLM生成合成数据并训练对话代理来辅助元评审员，有效提升了元评审效率。

**AI_Comments:** 本文的创新点在于将元评审从单纯的摘要任务提升至一个需要深思熟虑的决策过程，并首次提出通过文档基础对话代理来辅助此过程。其利用LLM生成高质量合成数据以克服专家领域数据稀缺性的方法极具开创性，为未来类似场景的数据生成提供了有效范式。研究成果表明，定制化的对话代理在提升专业领域（如学术评审）的决策效率方面具有显著潜力，为构建更智能的辅助系统奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 元评审是同行评审的关键阶段，但以往研究多将其视为摘要问题。本文认为元评审是一个需要权衡论点并置于更广阔语境下的决策过程，而对话代理已被证明能有效辅助决策者。因此，本文旨在探索实现能有效辅助元评审员的对话代理所面临的实际挑战。

**Method:** 为解决训练对话代理的数据稀缺问题，本文首先利用大型语言模型（LLMs）基于自我完善策略生成合成数据，以提高对话与专家领域的关联性。随后，利用这些合成数据训练专门针对元评审的对话代理。最后，将训练好的代理应用于真实世界的元评审场景。

**Result:** 该方法生成了更高质量的合成数据，可作为训练元评审助手的宝贵资源。训练出的对话代理在元评审任务上表现优于现成的基于LLM的助手。在真实世界的元评审场景中，这些代理被证实能有效提高元评审的效率。

**Conclusion:** 通过生成高质量的合成数据并训练专门的对话代理，可以有效辅助元评审员进行决策，从而提升元评审过程的效率。

> **ai_Abstract:** 本文将元评审重新定义为一种文档基础的决策过程，而非简单的摘要任务。为应对训练辅助元评审对话代理的数据稀缺性，研究团队利用大型语言模型（LLMs）通过自我完善策略生成高质量的合成对话数据。基于这些数据，他们训练出专门的对话代理，实验证明这些代理在元评审任务上表现优异，并能有效提升真实世界元评审的效率，凸显了定制化对话代理在复杂专业决策辅助中的潜力。

> **摘要翻译:** 元评审是同行评审过程中一个关键阶段，是决定论文是否被推荐接受的最后一步。以往关于元评审的研究将其视为对评审报告的总结问题。然而，与这一观点互补的是，元评审是一个决策过程，需要权衡评审员的论点并将其置于更广阔的语境中。先前的研究表明，在这种情况下，对话代理可以有效地协助决策者。基于这一框架，我们探索了实现能够有效协助元评审员的对话代理所面临的实际挑战。具体而言，我们首先通过使用大型语言模型（LLMs）基于自我完善策略生成合成数据来解决训练对话代理的数据稀缺问题，以提高这些对话与专家领域的关联性。我们的实验表明，这种方法可以生成更高质量的合成数据，并可以作为训练元评审助手的宝贵资源。随后，我们利用这些数据训练专门用于元评审的对话代理，发现这些代理在此任务上优于现成的基于LLM的助手。最后，我们将我们的代理应用于真实世界的元评审场景，并证实了它们在提高元评审效率方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [715] [SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens](https://arxiv.org/abs/2508.05305)
> *SONAR-LLM：一种以句子嵌入进行思考并以词元进行表达的自回归Transformer*

*Nikita Dragunov, Temurbek Rahmatullaev, Elizaveta Goncharova, Andrey Kuznetsov, Anton Razzhigaev* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** SONAR-LLM, 自回归Transformer, 句子嵌入, 词元级监督, 大概念模型

**Comment:** 

> **TL;DR:** SONAR-LLM是一个新型的自回归Transformer，它在连续的句子嵌入空间中“思考”，并通过词元级交叉熵进行监督，从而改进了LCM模型，实现了有竞争力的文本生成质量。

**AI_Comments:** SONAR-LLM的创新之处在于其独特的混合目标，它将高层次的语义（句子嵌入）与低层次的精确度（词元级监督）结合起来，解决了LCM在训练效率和似然估计上的局限性。这种方法为大型语言模型的架构设计提供了新的思路，特别是在平衡语义理解和生成质量方面。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在改进现有的大概念模型（LCM），通过保留其语义抽象能力，同时消除扩散采样器并恢复基于似然的训练信号。

**Method:** SONAR-LLM是一个仅解码器Transformer，它在连续的SONAR嵌入空间中进行“思考”，并利用通过冻结的SONAR解码器传播的词元级交叉熵进行监督。这种混合目标结合了句子嵌入的语义抽象和词元级的精确监督。

**Result:** SONAR-LLM在从39M到1.3B参数的不同模型尺寸下均能获得有竞争力的生成质量。研究还报告了缩放趋势、消融实验和基准测试结果。

**Conclusion:** SONAR-LLM成功地将大概念模型（LCM）的语义抽象优势与一种更高效、基于似然的训练方法相结合，并在文本生成方面展现出有竞争力的性能。

> **ai_Abstract:** SONAR-LLM是一种新型的自回归Transformer，旨在改进现有的大概念模型（LCM）。它结合了在连续SONAR嵌入空间中进行“思考”的能力与通过冻结SONAR解码器传播的词元级交叉熵监督。这种混合方法保留了LCM的语义抽象优势，同时避免了扩散采样器的需要，并恢复了基于似然的训练。实验表明，SONAR-LLM在不同模型规模下均能实现具有竞争力的文本生成质量。

> **摘要翻译:** 最近提出的大概念模型（LCM）通过预测一系列句子级嵌入来生成文本，并使用均方误差或扩散目标进行训练。我们提出了SONAR-LLM，一个仅解码器Transformer，它在相同的连续SONAR嵌入空间中“思考”，但通过冻结的SONAR解码器传播的词元级交叉熵进行监督。这种混合目标保留了LCM的语义抽象，同时消除了其扩散采样器并恢复了基于似然的训练信号。在从39M到1.3B参数的模型尺寸范围内，SONAR-LLM获得了有竞争力的生成质量。我们报告了缩放趋势、消融研究、基准测试结果，并发布了完整的训练代码和所有预训练检查点，以促进可复现性和未来的研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [721] [Evaluation of a Sign Language Avatar on Comprehensibility, User Experience \& Acceptability](https://arxiv.org/abs/2508.05358)
> *手语虚拟形象在可理解性、用户体验与可接受性方面的评估*

*Fenya Wasserroth, Eleftherios Avramidis, Vera Czehmann, Tanja Kojic, Fabrizio Nunnari, Sebastian Möller* | **Category: cs.CL, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 手语虚拟形象, 可理解性, 用户体验, 可接受性, HoloLens 2

**Comment:** 

> **TL;DR:** 本研究评估了在微软HoloLens 2上手语虚拟形象添加调整功能的影响。尽管用户偏好可调整设置，但可理解性和用户体验并未显著提高，且仍处于低水平，主要受缺失的手语元素和实现问题影响。研究强调个性化不足以弥补基本可理解性的缺失。

**AI_Comments:** 该研究揭示了当前手语虚拟形象在实现用户体验和可理解性方面的局限性，特别是在个性化功能并非万能药的背景下。其重要性在于指出了未来手语虚拟形象开发的关键方向，即必须优先确保基础的可理解性，而非仅仅增加调整选项。此外，对享乐质量和实用质量的区分也提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查在现有手语（SL）虚拟形象中添加调整功能对其可理解性、用户体验（UX）和可接受性的影响。

**Method:** 本研究通过详细分析德国手语（DGS）专家用户与微软HoloLens 2设备上可调整和不可调整虚拟形象在特定使用案例中的互动，来识别影响系统可理解性、用户体验和可接受性的关键因素。

**Result:** 尽管用户偏好可调整设置，但可理解性和用户体验并未显著改善，且仍处于低水平。主要原因是手语元素（口型和面部表情）缺失以及实现问题（手形不清晰、缺乏反馈和菜单定位）。享乐质量评分高于实用质量，表明用户认为系统在情感或美学上更令人愉悦而非功能实用。可调整虚拟形象的压力水平更高，反映出性能较低、付出更多努力和更多挫败感。对HoloLens调整手势的直观性和易学性也提出了担忧。概念的可接受性普遍积极，但强烈依赖于可用性和动画质量。

**Conclusion:** 本研究强调，仅靠个性化是不够的，手语虚拟形象必须默认是可理解的。主要建议包括增强口型和面部动画、改进交互界面以及应用参与式设计。

> **ai_Abstract:** 本研究评估了在微软HoloLens 2设备上，为手语虚拟形象添加调整功能对可理解性、用户体验和可接受性的影响。通过德国手语专家用户的实验，发现尽管用户偏好可调整性，但可理解性和用户体验并未显著提升，且因手语元素缺失和实现问题而维持在低水平。研究指出享乐质量优于实用质量，可调整虚拟形象增加了用户压力。最终强调，个性化不足以弥补核心可理解性问题，建议改进口型和面部动画、交互界面并采用参与式设计，以确保手语虚拟形象的默认可理解性。

> **摘要翻译:** 本文研究了在微软HoloLens 2设备上，为现有手语（SL）虚拟形象添加调整功能所产生的影响。通过详细分析德国手语（DGS）专家用户在特定使用案例中与可调整和不可调整虚拟形象的互动，本研究识别了影响此类系统可理解性、用户体验（UX）和可接受性的关键因素。尽管用户偏好可调整设置，但并未观察到用户体验或可理解性的显著改善，它们仍处于低水平，这主要是由于手语元素（口型和面部表情）的缺失和实现问题（不清晰的手形、缺乏反馈和菜单定位）。享乐质量评分高于实用质量，表明用户认为该系统在情感或美学上更令人愉悦而非功能实用。可调整虚拟形象的压力水平更高，反映出较低的性能、更大的努力和更多的挫败感。此外，关于HoloLens的调整手势是否直观且易于熟悉也引起了担忧。虽然可调整性概念的接受度普遍积极，但它强烈依赖于可用性和动画质量。本研究强调，仅靠个性化是不够的，手语虚拟形象必须默认是可理解的。主要建议包括增强口型和面部动画、改进交互界面以及应用参与式设计。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [727] [Can Language Models Critique Themselves? Investigating Self-Feedback for Retrieval Augmented Generation at BioASQ 2025](https://arxiv.org/abs/2508.05366)
> *语言模型能否自我批判？在BioASQ 2025上研究检索增强生成中的自我反馈*

*Samy Ateia, Udo Kruschwitz* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 语言模型, 自我反馈, 检索增强生成, BioASQ, 生物医学搜索

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型在专业领域（如生物医学）中，通过自我反馈机制对检索增强生成（RAG）的性能提升，并发现其效果因模型和任务而异。

**AI_Comments:** 这项研究探讨了LLM在专业领域自我纠正和自我反馈的能力，尤其是在RAG系统中的应用，具有创新性。它指出了自动化系统在专业搜索中可能导致的用户参与度降低和信息不对齐的问题，并通过BioASQ挑战赛提供了实际的评估平台。其局限性在于结果仍是初步的，且自我反馈的效果因模型和任务而异，表明需要进一步深入研究。未来的工作将着重比较LLM反馈与人类专家输入的有效性，这对于构建更可靠的专业搜索系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 代理式检索增强生成（RAG）和“深度研究”系统旨在实现自主搜索，但将其应用于生物医学等专业领域时面临挑战，因为自动化系统可能减少用户参与并与专家信息需求不符。专业搜索任务通常需要高水平的用户专业知识和透明度。BioASQ CLEF 2025挑战赛提供了一个研究这些问题的平台。

**Method:** 本文探索了Gemini-Flash 2.0、o3-mini、o4-mini和DeepSeek-R1等推理和非推理LLM的性能。核心方法是自我反馈机制，LLM生成、评估并改进其输出，用于查询扩展和多种答案类型（是/否、事实、列表、理想）。研究了迭代自我纠正是否能提高性能，以及推理模型是否更能生成有用的反馈。

**Result:** 初步结果表明，自我反馈策略在不同模型和任务上的表现各不相同。

**Conclusion:** 这项工作提供了关于LLM自我纠正的见解，并为未来比较LLM生成的反馈与人类专家直接输入在这些搜索系统中的有效性提供了信息。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）在专业领域（如生物医学）中应用检索增强生成（RAG）时的自我反馈能力。针对专业搜索中用户参与度降低和与专家需求不符的挑战，作者利用BioASQ CLEF 2025平台，测试了包括Gemini-Flash 2.0在内的多种LLMs。研究核心在于LLMs通过生成、评估和改进自身输出来进行迭代自我纠正的机制，以提升查询扩展和不同答案类型的性能。初步结果显示，自我反馈策略在不同模型和任务上的效果存在差异。这项工作为LLM的自我纠正提供了见解，并为未来比较LLM生成反馈与人类专家输入提供了基础。

> **摘要翻译:** 代理式检索增强生成（RAG）和“深度研究”系统旨在实现自主搜索过程，其中大型语言模型（LLM）迭代地完善输出。然而，将这些系统应用于生物医学研究等领域特定的专业搜索会带来挑战，因为自动化系统可能会减少用户参与，并与专家信息需求不符。专业搜索任务通常需要高水平的用户专业知识和透明度。BioASQ CLEF 2025挑战赛利用专家制定的问题，可以作为一个研究这些问题的平台。我们探索了当前推理和非推理LLM（如Gemini-Flash 2.0、o3-mini、o4-mini和DeepSeek-R1）的性能。我们方法的一个关键方面是自我反馈机制，LLM生成、评估然后改进其输出，用于查询扩展和多种答案类型（是/否、事实、列表、理想）。我们调查了这种迭代自我纠正是否能提高性能，以及推理模型是否更能生成有用的反馈。初步结果表明，自我反馈策略在不同模型和任务上的表现各不相同。这项工作提供了关于LLM自我纠正的见解，并为未来比较LLM生成的反馈与人类专家直接输入在这些搜索系统中的有效性提供了信息。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [733] [The TUB Sign Language Corpus Collection](https://arxiv.org/abs/2508.05374)
> *TUB手语语料库集合*

*Eleftherios Avramidis, Vera Czehmann, Fabian Deckert, Lorenz Hufe, Aljoscha Lipski, Yuni Amaloa Quintero Villalobos, Tae Kwon Rhee, Mengqian Shi, Lennart Stölting, Fabrizio Nunnari, Sebastian Möller* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 手语语料库, 平行语料库, 视频数据, 拉丁美洲手语, 德语手语

**Comment:** 

> **TL;DR:** 本文介绍了TUB手语语料库，一个包含12种手语的大规模平行语料库集合，包括首次提供的8种拉丁美洲手语和显著扩大的德语手语数据，主要通过收集在线视频创建。

**AI_Comments:** 该论文通过提供一个大规模、多样化且文档齐全的语料库，对手语研究做出了重要贡献。首次包含8种拉丁美洲手语的一致平行语料库以及德语手语数据的显著扩展，尤其具有创新性和重要性，解决了该领域资源匮乏的关键需求。从在线来源收集数据的详细方法对于未来类似工作也很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在介绍一个大规模的平行手语语料库集合，以支持手语研究和应用。

**Method:** 该语料库是通过从各种在线来源（主要是新闻节目、政府机构和教育频道的广播材料）收集和处理多种手语视频而创建的。准备工作涉及多个阶段，包括数据收集、通知内容创建者并寻求使用许可、抓取和裁剪。

**Result:** 整个语料库包含超过1,300小时的4,381个视频文件，附带130万个字幕，包含1,400万个词元。最值得注意的是，它包含了8种拉丁美洲手语的第一个一致平行语料库，并且德语手语语料库的规模是现有语料库的十倍。

**Conclusion:** 该论文提供了语料库的统计数据和收集数据所用方法的概述。

> **ai_Abstract:** 本文介绍了TUB手语语料库，这是一个大规模的平行语料库集合，包含12种手语的视频格式数据及字幕。它包括超过1,300小时的视频和1,400万个词元，值得注意的是，它包含了8种拉丁美洲手语的第一个一致平行语料库，并将德语手语数据扩展了十倍。该语料库是通过收集和处理各种在线视频内容而编译的，论文详细介绍了收集方法和统计数据。

> **摘要翻译:** 我们展示了一个包含12种手语的平行语料库集合，以视频格式呈现，并附有相应国家主要口语的字幕。整个集合包含4,381个视频文件，超过1,300小时，附带130万个字幕，包含1400万个词元。最值得注意的是，它包含了8种拉丁美洲手语的第一个一致平行语料库，而德语手语语料库的规模是现有语料库的十倍。该集合是通过从各种在线来源（主要是新闻节目、政府机构和教育频道的广播材料）收集和处理多种手语视频而创建的。准备工作涉及多个阶段，包括数据收集、通知内容创建者并寻求使用许可、抓取和裁剪。该论文提供了语料库的统计数据和收集数据所用方法的概述。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [739] [LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair Evaluation of Large Language Models](https://arxiv.org/abs/2508.05452)
> *LLMEval-3：大型语言模型鲁棒和公平评估的大规模纵向研究*

*Ming Zhang, Yujiong Shen, Jingyi Deng, Yuhui Wang, Yue Zhang, Junzhe Wang, Shichun Liu, Shihan Dou, Huayu Sha, Qiyuan Peng, Changhao Jiang, Jingqi Tong, Yilong Wu, Zhihao Zhang, Mingqi Wu, Zhiheng Xi, Mingxu Chai, Tao Liang, Zhihui Fei, Zhen Wang, Mingyang Wan, Guojun Ma, Tao Gui, Qi Zhang, Xuanjing Huang* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** LLMEval-3, 动态评估, 大型语言模型, 数据污染, 鲁棒性

**Comment:** 

> **TL;DR:** LLMEval-3是一个动态评估大型语言模型的框架，旨在解决现有静态基准测试中数据污染和排行榜过拟合的问题。通过20个月的纵向研究，LLMEval-3揭示了模型性能上限和数据污染漏洞，并证明了其评估的鲁棒性和可靠性。

**AI_Comments:** LLMEval-3的创新之处在于其动态评估范式和强大的防污染/防作弊机制，这对于解决LLM评估中长期存在的挑战至关重要。通过大规模纵向研究，该工作提供了扎实的经验证据，验证了动态评估的优越性，对于推动更公正、更可靠的LLM评估标准具有重要意义。其“LLM作为评判者”与人类高一致性的特点也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）评估方法依赖静态基准测试，容易受到数据污染和排行榜过拟合的影响，这掩盖了模型的真实能力。为了解决这些关键问题，研究引入了LLMEval-3。

**Method:** LLMEval-3是一个动态评估LLM的框架，它基于一个包含22万个研究生级别问题的专有题库，每次评估都动态抽取未见过的测试集。其自动化流程通过抗污染数据管理、新颖的防作弊架构以及与人类专家达成90%一致的LLM作为评判者的校准过程来确保评估的完整性。此外，它还采用相对排名系统进行公平比较。

**Result:** 对近50个领先模型进行了为期20个月的纵向研究，结果显示：揭示了知识记忆方面的性能上限，并暴露了静态基准测试无法检测到的数据污染漏洞。该框架在排名稳定性和一致性方面表现出卓越的鲁棒性。

**Conclusion:** LLMEval-3为动态评估范式提供了强有力的实证验证，并提供了一种可靠且可信的方法来评估LLM的真实能力，超越了排行榜分数，从而促进了更值得信赖的评估标准的发展。

> **ai_Abstract:** LLMEval-3是一个为解决大型语言模型（LLM）评估中数据污染和排行榜过拟合问题而设计的动态评估框架。该框架利用22万个研究生级别的问题库动态生成测试集，并通过抗污染、防作弊机制和高准确度的LLM作为评判者确保评估的完整性和公平性。一项为期20个月的纵向研究表明，LLMEval-3能够揭示模型在知识记忆上的性能瓶颈及传统方法难以发现的数据污染，同时展现出卓越的排名稳定性和一致性，为LLM的鲁棒和可信评估提供了新的范式。

> **摘要翻译:** 大型语言模型（LLMs）在静态基准上的现有评估容易受到数据污染和排行榜过拟合的影响，这些关键问题掩盖了模型的真实能力。为了解决这个问题，我们引入了LLMEval-3，一个用于动态评估LLMs的框架。LLMEval-3建立在一个包含22万个研究生级别问题的专有题库上，每次评估都会从中动态抽取未见过的测试集。其自动化流程通过抗污染数据管理、新颖的防作弊架构以及与人类专家达成90%一致的校准过的LLM作为评判者的过程来确保完整性，并辅以相对排名系统进行公平比较。对近50个领先模型进行的为期20个月的纵向研究揭示了知识记忆方面的性能上限，并暴露了静态基准测试无法检测到的数据污染漏洞。该框架在排名稳定性和一致性方面表现出卓越的鲁棒性，为动态评估范式提供了强有力的实证验证。LLMEval-3提供了一种鲁棒且可信的方法，用于评估LLMs超越排行榜分数的真实能力，从而促进了更值得信赖的评估标准的发展。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [745] [TASE: Token Awareness and Structured Evaluation for Multilingual Language Models](https://arxiv.org/abs/2508.05468)
> *TASE：多语言大型语言模型的词元感知与结构化评估*

*Chenzhuo Zhao, Xinda Wang, Yue Huang, Junting Lu, Ziqian Liu* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** TASE, 大型语言模型, 词元感知, 结构化评估, 多语言

**Comment:** 

> **TL;DR:** TASE是一个评估多语言大型语言模型在词元级理解和结构推理方面能力的基准测试，研究发现当前大型语言模型在此类任务中表现远逊于人类。

**AI_Comments:** TASE的创新之处在于其专注于大型语言模型在被忽视的词元级理解和结构化推理能力上的评估，这对于需要高精度控制的应用至关重要。通过构建多语言、多任务的综合基准测试，并公开数据集和代码，该工作为社区提供了一个宝贵的诊断工具，有助于推动大型语言模型在基础语言理解能力上的进步。其发现人类表现远超LLMs，也突出了未来研究的明确方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在高级语义任务上表现出色，但在需要精确控制的细粒度、词元级理解和结构化推理方面仍存在不足。

**Method:** 引入了TASE基准测试，旨在评估大型语言模型在跨语言词元级信息感知和推理能力。TASE涵盖了中文、英文和韩语的10项任务，分为词元感知和结构理解两大类，包含35,927个评估实例和一个可扩展的合成数据生成流程。任务包括字符计数、词元对齐、句法结构解析和长度约束满足。研究评估了30多个主流商业和开源大型语言模型，并使用GRPO训练方法训练了一个定制的Qwen2.5-14B模型。

**Result:** 结果显示，人类在这些任务上的表现显著优于当前的大型语言模型，揭示了大型语言模型在词元级推理方面持续存在的弱点。

**Conclusion:** TASE揭示了大型语言模型在低层语言理解和跨语言泛化方面的局限性，并为未来的改进提供了一个新的诊断视角。

> **ai_Abstract:** 本文介绍了TASE，一个用于评估多语言大型语言模型在细粒度词元级理解和结构化推理能力方面的综合基准测试。TASE包含10项跨中文、英文、韩文的任务，并评估了30多个主流大型语言模型。研究发现，当前大型语言模型在此类任务上的表现远逊于人类，揭示了其在低层语言理解和跨语言泛化方面的显著不足。TASE为诊断这些局限性并指导未来改进提供了重要工具。

> **摘要翻译:** 尽管大型语言模型（LLMs）在高级语义任务上表现出色，但它们在细粒度、词元级理解和结构化推理方面常常遇到困难——这些能力对于需要精度和控制的应用至关重要。我们引入了TASE，这是一个全面的基准测试，旨在评估LLMs跨语言感知和推理词元级信息的能力。TASE涵盖了词元感知和结构理解两大核心类别的10项任务，跨越中文、英文和韩语，拥有35,927个实例的评估集和用于训练的可扩展合成数据生成管道。任务包括字符计数、词元对齐、句法结构解析和长度约束满足。我们评估了30多个领先的商业和开源LLMs，包括O3、Claude 4、Gemini 2.5 Pro和DeepSeek-R1，并使用GRPO训练方法训练了一个定制的Qwen2.5-14B模型。结果显示，人类的表现显著超越了当前的LLMs，揭示了词元级推理中持续存在的弱点。TASE揭示了这些局限性，并为未来在低层语言理解和跨语言泛化方面的改进提供了新的诊断视角。我们的代码和数据集已公开可用，网址为https://github.com/cyzcz/Tase。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [750] [Rethinking Creativity Evaluation: A Critical Analysis of Existing Creativity Evaluations](https://arxiv.org/abs/2508.05470)
> *重新思考创造力评估：对现有创造力评估的批判性分析*

*Li-Chun Lu, Miri Liu, Pin-Chun Lu, Yufei Tian, Shao-Hua Sun, Nanyun Peng* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 创造力评估, 创造力指数, 困惑度, LLM-as-a-Judge, 评估框架

**Comment:** 

> **TL;DR:** 现有创造力评估方法在不同领域表现出局限性、不一致性和偏差，需要更鲁棒的评估框架。

**AI_Comments:** 这篇论文通过对现有创造力评估方法的系统性分析，揭示了当前评估体系的深层问题，如一致性不足、维度单一和潜在偏见。其重要性在于指出了未来创造力评估研究的方向，即开发更全面、准确且与人类认知对齐的评估标准，对于推动人工智能在创意领域的应用和理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有创造力评估方法存在问题，需要系统性地检查、分析和比较它们，以发现其局限性并推动更准确的评估。

**Method:** 研究系统地检查、分析和比较了四种代表性的创造力衡量指标：创造力指数、困惑度、句法模板和LLM-as-a-Judge，涵盖了创意写作、非常规问题解决和研究构思等不同创造性领域。

**Result:** 这些指标表现出有限的一致性，捕捉了创造力的不同维度。具体局限性包括：创造力指数侧重词汇多样性，困惑度对模型置信度敏感，句法模板无法捕捉概念性创造力，LLM-as-a-Judge表现出不稳定性和偏见。

**Conclusion:** 研究结果强调需要更鲁棒、更具通用性且与人类创造力判断更一致的评估框架。

> **ai_Abstract:** 这篇论文批判性地分析了现有创造力评估方法，包括创造力指数、困惑度、句法模板和LLM-as-a-Judge。研究发现这些指标在不同创意领域中表现出一致性有限、捕捉维度不同，并存在各自的局限性和偏差。论文强调了开发更鲁棒、通用且与人类判断更一致的创造力评估框架的必要性。

> **摘要翻译:** 我们系统地检查、分析并比较了代表性的创造力衡量指标——创造力指数、困惑度、句法模板和LLM-as-a-Judge——涵盖了创意写作、非常规问题解决和研究构思等不同创造性领域。我们的分析揭示，这些指标表现出有限的一致性，捕捉了创造力的不同维度。我们强调了主要的局限性，包括创造力指数对词汇多样性的关注、困惑度对模型置信度的敏感性，以及句法模板无法捕捉概念性创造力。此外，LLM-as-a-Judge表现出不稳定性和偏见。我们的发现强调了需要更鲁棒、更具通用性且与人类创造力判断更一致的评估框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [755] [CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation](https://arxiv.org/abs/2508.05534)
> *CoCoLex：面向扎根法律文本生成的置信度引导复制解码*

*Santosh T.Y.S.S, Youssef Tarek Elkhayat, Oana Ichim, Pranav Shetty, Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 法律文本生成, 大型语言模型, 复制机制, 解码策略, 忠实度

**Comment:** 

> **TL;DR:** CoCoLex是一种新的解码策略，通过结合模型置信度进行上下文复制，提高了法律文本生成的忠实度，解决了LLM在法律领域生成不忠实内容的问题。

**AI_Comments:** CoCoLex的创新之处在于其“置信度引导的复制机制”，它将模型的置信度与直接从上下文复制相结合，从而有效解决了LLM在法律领域中“幻觉”和“不忠实”的问题。这种方法为需要高精确度和可信度的领域（如法律）提供了一个有价值的解决方案，尤其在处理长文本时表现出优势。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在法律领域应用受阻，因为它们倾向于生成不忠实、无根据或幻觉的内容。尽管检索增强生成（RAG）有所帮助，但不能保证有效整合上下文。现有的上下文感知解码策略通常不明确强制对上下文的忠实性。

**Method:** 本文引入了CoCoLex，一种置信度引导的复制解码策略。CoCoLex动态地将模型生成的词汇分布与基于上下文复制的分布进行插值。该方法根据模型的置信度鼓励直接从上下文复制，以确保生成内容对源文本的更高忠实度。

**Result:** 在五个法律基准测试上的实验结果表明，CoCoLex优于现有的上下文感知解码方法，特别是在长文本生成任务中表现出色。

**Conclusion:** CoCoLex有效解决了大型语言模型在法律文本生成中忠实度不足的问题，并通过结合置信度引导的复制机制提高了生成质量，尤其适用于长文本生成。

> **ai_Abstract:** 本文提出了CoCoLex，一种用于法律文本生成的置信度引导复制解码策略。针对大型语言模型在法律领域生成不忠实内容的挑战，CoCoLex通过动态插值模型词汇分布与基于上下文复制的分布来解决。该方法根据模型置信度鼓励直接从上下文复制，从而提高生成内容对源文本的忠实度。实验证明，CoCoLex在五个法律基准测试上优于现有上下文感知解码方法，尤其在长文本生成方面表现出色。

> **摘要翻译:** 由于其处理长而复杂上下文的能力，大型语言模型（LLMs）可以为法律领域带来关键优势，但其应用一直受到其生成不忠实、无根据或幻觉内容的倾向的阻碍。尽管检索增强生成（RAG）通过将生成内容基于外部知识提供了一个有前景的解决方案，但它不能保证所提供的上下文能够被有效整合。为了解决这个问题，已经提出了上下文感知解码策略来放大相关上下文的影响，但它们通常没有明确强制对上下文的忠实性。在这项工作中，我们引入了面向法律文本生成的置信度引导复制解码（CoCoLex）——一种动态地将模型生成的词汇分布与基于上下文复制的分布进行插值的解码策略。CoCoLex根据模型的置信度鼓励直接复制，确保对源文本的更高忠实度。在五个法律基准测试上的实验结果表明，CoCoLex优于现有的上下文感知解码方法，特别是在长文本生成任务中。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [760] [Do Political Opinions Transfer Between Western Languages? An Analysis of Unaligned and Aligned Multilingual LLMs](https://arxiv.org/abs/2508.05553)
> *政治观点是否在西方语言之间转移？一项对未对齐和已对齐多语言大型语言模型的分析*

*Franziska Weeber, Tanise Ceron, Sebastian Padó* | **Category: cs.CL, cs.CY** | **Updated: 2025-08-07**

**Keywords:** 多语言大型语言模型, 政治观点, 语言转移, 对齐, 跨语言

**Comment:** 

> **TL;DR:** 研究发现，在多语言大型语言模型（MLLMs）中，政治观点在西方语言之间是会转移的，这凸显了实现明确的社会语言、文化和政治对齐的挑战。

**AI_Comments:** 这项研究揭示了多语言大型语言模型（MLLMs）中政治观点传播的一个重要方面，表明即使主要使用一种语言的对齐数据进行训练，政治偏见也可能在不同语言之间传播。这强调了控制和本地化大型模型中偏见的复杂性，对于理解和构建更公平、更具文化意识的AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 公共舆论调查显示不同社会文化背景下的政治观点存在跨文化差异，但目前尚不清楚这些差异是否会转化为多语言大型语言模型（MLLMs）中的跨语言差异。本研究旨在分析政治观点是否在语言之间转移，或者每种语言在MLLMs中是否存在独立的观点。

**Method:** 研究分析了各种规模的多语言大型语言模型（MLLMs），涵盖五种西方语言。通过提示模型报告它们对来自投票建议应用程序的政治声明的（不）同意程度来评估它们的观点。为了更好地理解模型中语言之间的相互作用，研究在模型使用直接偏好优化和仅英文对齐数据进行左右视图对齐前后都进行了评估。

**Result:** 研究发现，未对齐的模型在反映的政治观点上仅显示出非常少的显著跨语言差异。政治对齐几乎在所有五种语言中统一地改变了观点。

**Conclusion:** 研究得出结论，在西方语言环境中，政治观点在语言之间是会转移的，这表明在实现多语言大型语言模型（MLLMs）的明确社会语言、文化和政治对齐方面存在挑战。

> **ai_Abstract:** 本研究探讨了多语言大型语言模型（MLLMs）中政治观点在西方语言之间是否会转移的问题。通过分析不同规模的MLLMs在五种西方语言中的表现，并评估模型在对齐前后对政治声明的（不）同意程度，研究发现，未对齐的模型在政治观点上几乎没有显著的跨语言差异，且政治对齐对观点的影响在所有语言中是统一的。这表明在西方语言背景下，政治观点在MLLMs中会跨语言转移，从而揭示了实现MLLMs社会语言、文化和政治对齐的复杂性。

> **摘要翻译:** 公众舆论调查显示，不同社会文化背景下的政治观点存在跨文化差异。然而，目前尚不清楚这些差异是否会转化为多语言大型语言模型（MLLMs）中的跨语言差异。我们分析了在各种规模的多语言大型语言模型中，观点是否在五种西方语言之间转移，或者每种语言是否存在独立的观点。我们通过提示MLLMs报告它们对来自投票建议应用程序的政治声明的（不）同意程度来评估它们的观点。为了更好地理解模型中语言之间的相互作用，我们使用直接偏好优化和仅英文对齐数据，在模型与更左翼或右翼观点对齐前后都进行了评估。我们的发现表明，未对齐的模型在它们反映的政治观点上仅显示出非常少的显著跨语言差异。政治对齐几乎在所有五种语言中统一地改变了观点。我们得出结论，在西方语言环境中，政治观点在语言之间是会转移的，这表明在实现MLLMs的明确社会语言、文化和政治对齐方面存在挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [765] [MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging Synthetic Problems with a Reinforced Policy](https://arxiv.org/abs/2508.05592)
> *MathSmith：通过强化策略锻造合成问题以实现极其困难的数学推理*

*Shaoxiong Zhan, Yanlin Lai, Ziyu Lu, Dahua Lin, Ziqing Yang, Fei Tang* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 数学推理, 合成数据, 强化学习, 大型语言模型, 高难度问题

**Comment:** 

> **TL;DR:** MathSmith是一个新颖的框架，通过强化学习和从头开始合成高难度数学问题，以提升大型语言模型的推理能力。

**AI_Comments:** MathSmith的创新之处在于其从头开始合成高难度数学问题的方法，而不是简单地修改现有模板，这极大地增强了数据多样性和可扩展性。通过结合强化学习和认知复杂性（推理轨迹长度）作为优化目标，它有效地生成了对LLM更具挑战性的问题。这种方法对于解决当前LLM在处理复杂数学推理时面临的数据稀缺问题具有重要意义。其弱点聚焦模块也为未来针对性改进提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在数学推理方面取得进展，但受到高质量、高难度训练数据稀缺的限制。现有合成方法依赖于转换人工编写的模板，限制了多样性和可扩展性。

**Method:** MathSmith通过从PlanetMath随机采样概念-解释对来从头构建新的数学问题，确保数据独立性。它设计了九种预定义策略作为推理过程中的软约束以增加难度。该方法进一步采用强化学习来共同优化结构有效性、推理复杂性和答案一致性。通过自回归提示生成的推理轨迹长度被用来反映认知复杂性，鼓励创建更具挑战性的问题。此外，还有一个弱点聚焦的变体生成模块。

**Result:** 实验表明，MathSmith在五个基准测试（包括简单、中等和困难类别）中，在短CoT和长CoT设置下均持续优于现有基线。它展现出强大的可扩展性、泛化能力和可迁移性。

**Conclusion:** 高难度合成数据在提升大型语言模型推理能力方面具有巨大潜力。

> **ai_Abstract:** MathSmith是一个新颖的框架，旨在通过从头开始合成高难度数学问题来提升大型语言模型的数学推理能力。它利用PlanetMath的数据独立性，结合九种预定义难度策略和强化学习来优化问题质量、推理复杂性和答案一致性。通过鼓励生成更长的推理链，MathSmith能够创建更具挑战性的问题。实验证明，MathSmith在多个数学基准测试中显著优于现有方法，并具有强大的可扩展性、泛化和迁移能力，表明合成高难度数据对提升LLM推理能力至关重要。

> **摘要翻译:** 大型语言模型在数学推理方面取得了显著进展，但其进步受到高质量、高难度训练数据稀缺的限制。现有合成方法主要依赖于转换人工编写的模板，这限制了多样性和可扩展性。我们提出了MathSmith，一个用于合成挑战性数学问题以增强大型语言模型推理能力的新颖框架。MathSmith不是修改现有问题，而是通过从PlanetMath随机采样概念-解释对来从头构建新问题，确保数据独立性并避免污染。为了增加难度，我们在推理过程中设计了九种预定义策略作为软约束。我们进一步采用强化学习来共同优化结构有效性、推理复杂性和答案一致性。自回归提示下生成的推理轨迹长度用于反映认知复杂性，鼓励创建与长链思维推理对齐的更具挑战性的问题。在五个基准测试（分为简单和中等（GSM8K、MATH-500）以及困难（AIME2024、AIME2025、OlympiadBench））上的实验表明，MathSmith在短CoT和长CoT设置下均持续优于现有基线。此外，一个弱点聚焦的变体生成模块能够对特定概念进行有针对性的改进。总的来说，MathSmith展现出强大的可扩展性、泛化能力和可迁移性，突显了高难度合成数据在推进大型语言模型推理能力方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [770] [Learning to Reason for Factuality](https://arxiv.org/abs/2508.05618)
> *学习事实性推理*

*Xilun Chen, Ilia Kulikov, Vincent-Pierre Berges, Barlas Oğuz, Rulin Shao, Gargi Ghosh, Jason Weston, Wen-tau Yih* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 事实性推理, 大型语言模型, 强化学习, 奖励函数, 幻觉

**Comment:** 

> **TL;DR:** 推理大型语言模型（R-LLMs）在事实性方面表现不佳。本文提出一种新颖的奖励函数，并应用在线强化学习来提高事实性推理，显著减少幻觉。

**AI_Comments:** 本文的创新点在于提出了一个多维度的奖励函数，解决了传统单一事实性评估指标在在线强化学习中导致的奖励作弊问题，有效提升了R-LLMs的事实性表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的推理大型语言模型（R-LLMs）在复杂推理任务上表现出色，但在事实性方面却面临挑战，在长篇事实性基准测试中比非推理模型产生更多的幻觉。将在线强化学习应用于长篇事实性设置面临缺乏可靠验证方法的挑战，且直接使用自动事实性评估框架（如FActScore）作为在线RL的奖励函数会导致奖励作弊，产生细节较少或不相关的响应。

**Method:** 本文提出了一种新颖的奖励函数，该函数同时考虑了事实准确性、响应细节水平和答案相关性。然后，应用在线强化学习来学习高质量的事实性推理。

**Result:** 在六个长篇事实性基准测试中，模型平均幻觉率降低了23.1个百分点，答案细节水平提高了23%，并且整体响应有用性没有下降。

**Conclusion:** 通过结合考虑多方面指标的新型奖励函数和在线强化学习，可以显著提高大型语言模型的事实性推理能力，同时保持响应的细节和有用性。

> **ai_Abstract:** 本文旨在解决推理大型语言模型（R-LLMs）在事实性方面普遍存在的幻觉问题。针对现有自动评估框架作为在线强化学习奖励函数时导致的奖励作弊问题，作者提出了一种新颖的奖励函数，该函数综合考量了事实准确性、响应细节水平和答案相关性。通过将该奖励函数应用于在线强化学习，模型在多个长篇事实性基准测试中显著降低了幻觉率，并提升了答案细节水平，同时保持了响应的有用性。

> **摘要翻译:** 推理大型语言模型（R-LLMs）在复杂推理任务上取得了显著进展，但常常在事实性方面遇到困难，在长篇事实性基准测试中比非推理模型产生更多的幻觉。然而，将在线强化学习（RL）（近期R-LLM进展的关键组成部分）扩展到长篇事实性设置，由于缺乏可靠的验证方法而带来了一些独特的挑战。之前的工作利用FActScore等自动事实性评估框架在离线RL设置中整理偏好数据，但我们发现直接将此类方法作为在线RL中的奖励会导致多种方式的奖励作弊，例如产生细节较少或不相关的响应。我们提出了一种新颖的奖励函数，该函数同时考虑了事实准确性、响应细节水平和答案相关性，并应用在线RL来学习高质量的事实性推理。在六个长篇事实性基准测试中进行评估，我们的事实性推理模型平均幻觉率降低了23.1个百分点，答案细节水平提高了23%，并且整体响应有用性没有下降。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [775] [Federal Reserve Communication and the COVID-19 Pandemic](https://arxiv.org/abs/2508.04830)
> *美联储沟通与COVID-19大流行*

*Jonathan Benchimol, Sophia Kazinnik, Yossi Saadon* | **Category: cs.CL, cs.IT, econ.GN, stat.AP, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 美联储, 沟通, COVID-19, 货币政策, 金融稳定

**Comment:** 

> **TL;DR:** 本研究考察了美联储在COVID-19大流行期间的沟通策略，并与以往经济压力时期的沟通进行了比较。研究发现美联储对COVID-19的沟通更具反应性，且非常规货币政策（UMP）的沟通已成为新常态。

**AI_Comments:** 这篇论文为理解中央银行在空前危机期间沟通的演变提供了宝贵的见解。其对专业词典和比较分析的运用为理解沟通焦点和反应性的转变提供了一个稳健的框架。非常规货币政策（UMP）沟通成为“新常态”的发现尤其富有洞察力，表明中央银行策略发生了持久性变化。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在考察美联储在COVID-19大流行期间的沟通策略，并将其与以往经济压力时期的沟通进行比较。此外，它还旨在增进对央行沟通在危机期间如何演变以及沟通策略如何适应特殊经济环境的理解。

**Method:** 研究使用了针对COVID-19、非常规货币政策（UMP）和金融稳定量身定制的专业词典，并结合了情感分析和主题建模技术。通过比较分析，研究将美联储在COVID-19危机期间的沟通与其在互联网泡沫危机和全球金融危机期间的应对措施进行了对比，考察了内容、情感和时间维度。

**Result:** 研究发现，美联储在大流行期间的沟通明显侧重于金融稳定、市场波动、社会福利和非常规货币政策（UMP），并伴有显著的语境不确定性。与以往危机相比，美联储的沟通和政策行动对COVID-19危机的反应更为迅速。此外，利率公告和会议纪要中与金融稳定相关的情绪下降预示着随后的宽松货币政策决定。研究还表明，自全球金融危机以来，非常规货币政策的沟通已成为美联储联邦公开市场委员会会议纪要和主席讲话的“新常态”，这反映了经济困境时期沟通策略的制度性适应。

**Conclusion:** 中央银行的沟通在危机期间会演变，沟通策略会适应特殊的经济环境，其中非常规货币政策（UMP）的沟通已成为一种制度性适应。

> **ai_Abstract:** 本研究分析了美联储在COVID-19大流行期间的沟通，并将其与互联网泡沫危机和全球金融危机等以往危机进行了比较。研究运用专业词典、情感分析和主题建模，识别出大流行期间美联储沟通的独特焦点，即金融稳定、市场波动、社会福利和非常规货币政策（UMP），并伴有高度不确定性。研究结果表明，美联储对COVID-19的反应更为迅速，且金融稳定情绪的下降预示着宽松政策。此外，研究强调自全球金融危机以来，UMP沟通已成为美联储的常态，反映了危机沟通中的制度性适应。

> **摘要翻译:** 在本研究中，我们考察了联邦储备银行在COVID-19大流行期间的沟通策略，并将其与以往经济压力时期的沟通进行了比较。我们使用针对COVID-19、非常规货币政策（UMP）和金融稳定量身定制的专业词典，结合情感分析和主题建模技术，识别出美联储在大流行期间的沟通明显侧重于金融稳定、市场波动、社会福利和UMP，并具有显著的语境不确定性。通过比较分析，我们将美联储在COVID-19危机期间的沟通与其在互联网泡沫危机和全球金融危机期间的应对措施进行了对比，考察了内容、情感和时间维度。我们的研究结果表明，美联储的沟通和政策行动对COVID-19危机的反应比以往危机更为迅速。此外，利率公告和会议纪要中与金融稳定相关的情绪下降预示着随后的宽松货币政策决定。我们进一步记录了，自全球金融危机以来，关于UMP的沟通已成为美联储联邦公开市场委员会会议纪要和主席讲话的“新常态”，这反映了经济困境时期沟通策略的制度性适应。这些发现有助于我们理解中央银行沟通在危机期间如何演变以及沟通策略如何适应特殊经济环境。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [780] [Advancing Hate Speech Detection with Transformers: Insights from the MetaHate](https://arxiv.org/abs/2508.04913)
> *使用Transformer推进仇恨言论检测：来自MetaHate的见解*

*Santosh Chapagain, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 仇恨言论检测, Transformer, MetaHate, 深度学习, ELECTRA

**Comment:** 

> **TL;DR:** 本文使用MetaHate数据集全面探索了基于Transformer的模型用于仇恨言论检测，其中ELECTRA表现最佳，并分析了分类误差。

**AI_Comments:** 这项研究通过引入Transformer模型并利用大规模的MetaHate数据集，显著推动了仇恨言论检测领域的发展。其创新之处在于对多种先进Transformer模型的全面评估，并明确指出ELECTRA的优越性能。研究的重要性体现在其对解决在线仇恨言论这一社会问题的贡献。然而，论文也坦诚地指出了模型在处理复杂语言现象（如讽刺和隐语）以及标签噪声方面的局限性，这为未来的研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 仇恨言论是一种广泛存在的有害在线言论，对个人和社区造成严重影响，且与现实世界的仇恨犯罪相关。现有深度学习方法（如RNNs, LSTM, CNNs）在处理长期依赖和并行化方面存在局限性，因此需要开发更强大的自动化检测方法。

**Method:** 本研究使用MetaHate数据集（一个包含36个数据集、120万社交媒体样本的元集合）全面探索了基于Transformer的模型（包括BERT, RoBERTa, GPT-2, ELECTRA）进行仇恨言论检测。研究评估了多个最先进的Transformer模型。

**Result:** 经过微调的ELECTRA模型取得了最高性能（F1分数：0.8980）。研究还分析了分类误差，揭示了讽刺、隐语和标签噪声带来的挑战。

**Conclusion:** 基于Transformer的模型，特别是ELECTRA，在仇恨言论检测方面表现出色。然而，处理讽刺、隐语和标签噪声等复杂情况仍然是未来的挑战。

> **ai_Abstract:** 本研究旨在通过探索Transformer模型来推进仇恨言论检测，以应对在线仇恨言论的普遍性和危害性。研究使用了大规模的MetaHate数据集，评估了BERT、RoBERTa、GPT-2和ELECTRA等多种先进的Transformer模型。结果显示，经过微调的ELECTRA模型表现最佳，F1分数达到0.8980。论文还分析了模型在处理讽刺、隐语和标签噪声时的分类误差，指出了未来研究的挑战。

> **摘要翻译:** 仇恨言论是一种广泛存在且有害的在线言论形式，包含辱骂和诽谤性帖子，可能对目标个人和社区造成严重的社会、心理，有时甚至是身体影响。随着X（前身为Twitter）、Facebook、Instagram、Reddit等社交媒体平台继续促进广泛的交流，它们也成为仇恨言论滋生的温床，而仇恨言论与现实世界的仇恨犯罪的关联日益紧密。解决这个问题需要开发强大的自动化方法，以在不同的社交媒体环境中检测仇恨言论。深度学习方法，如传统的循环神经网络（RNNs）、长短期记忆网络（LSTM）和卷积神经网络（CNNs），已经取得了良好的结果，但通常受限于长期依赖和低效并行化等问题。本研究代表了对基于Transformer的模型在仇恨言论检测方面的全面探索，使用了MetaHate数据集——一个包含36个数据集、120万社交媒体样本的元集合。我们评估了多个最先进的Transformer模型，包括BERT、RoBERTa、GPT-2和ELECTRA，其中经过微调的ELECTRA取得了最高性能（F1分数：0.8980）。我们还分析了分类误差，揭示了讽刺、隐语和标签噪声带来的挑战。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [785] [REINA: Regularized Entropy Information-Based Loss for Efficient Simultaneous Speech Translation](https://arxiv.org/abs/2508.04946)
> *REINA：基于正则化熵信息的有效同声传译损失函数*

*Nameer Hirschkind, Joseph Liu, Mahesh Kumar Nandwana, Xiao Yu* | **Category: cs.CL, cs.LG, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 同声传译, 延迟-质量权衡, 信息论, REINA, 自适应策略

**Comment:** 

> **TL;DR:** REINA引入了一种基于信息理论的新型损失函数，用于训练自适应策略，以优化同声传译中的延迟与质量权衡，并在多语言对上实现了最先进的性能。

**AI_Comments:** REINA的创新之处在于其将信息论原理应用于同声传译的延迟-质量权衡优化，通过引入一个自适应策略损失函数，有效地解决了这一核心挑战。其在仅使用开源或合成数据的情况下达到SOTA性能，显示出其方法的强大和实用性。此外，引入新的流式效率指标也为该领域提供了更精确的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 同声传译（SimulST）系统面临着平衡翻译质量和延迟的重大挑战，现有方法难以有效优化这一权衡。本文旨在通过引入一种新策略来解决此问题：仅在获得信息时才等待更多输入。

**Method:** 本文提出了一种名为REINA（Regularized Entropy INformation Adaptation）的新型损失函数，该函数基于信息论原理，用于训练一个自适应策略。REINA利用现有的非流式翻译模型，通过优化“仅在获得信息时才等待更多输入”的策略来平衡延迟与质量。

**Result:** REINA成功地将延迟/质量权衡的帕累托前沿推向了超越现有工作。利用REINA训练的SimulST模型在法语、西班牙语和德语（与英语互译）上，仅使用开源或合成数据，就实现了同等规模模型的最先进（SOTA）流式翻译结果。此外，本文还引入了一个流式效率指标，定量表明REINA相较于现有方法，将延迟/质量权衡提高了多达21%（相对于非流式基线BLEU分数进行归一化）。

**Conclusion:** REINA作为一种基于信息理论的正则化熵信息适应损失函数，有效解决了同声传译中的延迟与质量权衡问题，显著提升了性能，并为流式翻译效率提供了一个新的衡量标准。

> **ai_Abstract:** 本文提出了一种名为REINA（Regularized Entropy INformation Adaptation）的新型损失函数，旨在优化同声传译（SimulST）系统中翻译质量与延迟之间的权衡。REINA基于信息论原理，通过训练一个自适应策略，使其仅在获得更多信息时才等待输入。实验结果表明，REINA将延迟/质量权衡的帕累托前沿推向了超越现有工作，并在多种语言对上实现了最先进的流式翻译性能。此外，本文还引入了一个新的流式效率指标，量化显示REINA相较于现有方法，将延迟/质量权衡改善了高达21%。

> **摘要翻译:** 同声传译（SimulST）系统在音频流输入的同时输出翻译文本或语音。此类系统面临着平衡翻译质量和延迟的重大挑战。我们引入了一种优化这种权衡的策略：仅当通过等待获得信息时才等待更多输入。基于此策略，我们提出了正则化熵信息适应（REINA），这是一种新颖的损失函数，用于使用现有的非流式翻译模型训练自适应策略。我们从信息论原理推导出REINA，并表明REINA有助于将延迟/质量权衡的帕累托前沿推向超越现有工作。利用REINA，我们训练了一个SimulST模型，在法语、西班牙语和德语（与英语互译）上进行训练。仅使用开源或合成数据进行训练，我们实现了同等规模模型的最先进（SOTA）流式翻译结果。我们还引入了一个流式效率指标，定量表明REINA相较于现有方法，将延迟/质量权衡提高了多达21%，相对于非流式基线BLEU分数进行归一化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [790] [A Study of the Framework and Real-World Applications of Language Embedding for 3D Scene Understanding](https://arxiv.org/abs/2508.05064)
> *语言嵌入在三维场景理解中的框架和实际应用研究*

*Mahmoud Chick Zaouali, Todd Charter, Yehor Karpichev, Brandon Haworth, Homayoun Najjjaran* | **Category: cs.CL, cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 高斯泼溅, 语言嵌入, 三维场景理解, 文本条件生成, 综述

**Comment:** 

> **TL;DR:** 本综述全面回顾了将语言指导与3D高斯泼溅技术结合的当前研究，详细介绍了理论基础、集成策略、实际应用案例，并指出了局限性、开放挑战和未来方向。

**AI_Comments:** 该论文作为一篇综述，填补了语言指导与3D高斯泼溅技术结合领域的空白，系统梳理了现有研究，并明确指出了当前面临的挑战和未来的发展方向，对于推动该领域的研究具有重要指导意义。其对局限性的分析，如计算瓶颈和数据稀缺，为后续研究提供了明确的问题导向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管语言模型与高斯泼溅技术结合在三维场景理解方面取得了进展，但目前缺乏对这一新兴交叉领域的全面概述。

**Method:** 本研究通过对当前结合语言指导与三维高斯泼溅的研究进行结构化综述，详细阐述了理论基础、集成策略和实际应用案例。

**Result:** 综述强调了计算瓶颈、泛化能力以及语义标注三维高斯数据稀缺等关键局限性，并概述了利用高斯泼溅推进语言引导三维场景理解的开放挑战和未来方向。

**Conclusion:** 结合语言指导的三维高斯泼溅技术在三维场景理解中展现出巨大潜力，但仍面临计算效率、数据稀缺和泛化能力等挑战，未来研究需致力于克服这些限制。

> **ai_Abstract:** 本综述审视了语言嵌入与高斯泼溅技术结合在三维场景理解中的应用。文章首先介绍了高斯泼溅作为高效三维表示方法的优势，随后探讨了语言模型集成如何实现文本条件下的生成与语义理解。鉴于该交叉领域缺乏全面总结，本综述系统回顾了相关研究，涵盖理论基础、集成策略及实际应用，并指出了计算瓶颈、数据稀缺和泛化能力等主要限制，最后展望了未来的研究方向和挑战。

> **摘要翻译:** 高斯泼溅技术已迅速成为实时三维场景表示的一种变革性技术，为神经辐射场（NeRF）提供了高效且富有表现力的替代方案。其以高保真度渲染复杂场景的能力，推动了场景重建、机器人技术和交互式内容创建等领域的进步。最近，大型语言模型（LLMs）和语言嵌入与高斯泼溅管线的集成，为文本条件下的生成、编辑和语义场景理解开辟了新的可能性。尽管取得了这些进展，但对这一新兴交叉领域仍缺乏全面的概述。本综述对当前结合语言指导与三维高斯泼溅的研究进行了结构化回顾，详细阐述了理论基础、集成策略和实际应用案例。我们强调了计算瓶颈、泛化能力以及语义标注三维高斯数据稀缺等关键局限性，并概述了利用高斯泼溅推进语言引导三维场景理解的开放挑战和未来方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [794] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
> *驾驭论文洪流：通过领域感知检索和潜在推理推进基于LLM的论文评估*

*Wuqiang Zheng, Yiyan Xu, Xinyu Lin, Chongming Gao, Wenjie Wang, Fuli Feng* | **Category: cs.CL, cs.IR** | **Updated: 2025-08-07**

**Keywords:** LLM, 论文评估, 领域感知检索, 潜在推理, PaperEval

**Comment:** 

> **TL;DR:** PaperEval是一个新的基于LLM的论文评估框架，它通过领域感知检索和潜在推理来解决现有LLM评估方法中过时领域知识和推理能力有限的问题，并在实验和实际应用中表现出色。

**AI_Comments:** PaperEval的创新之处在于其结合了领域感知检索和潜在推理机制，有效解决了LLM在论文评估中面临的知识滞后和推理深度不足的问题。其渐进式排名优化策略也为LLM的推理过程提供了有效指导。该工作不仅在理论上提高了LLM的评估能力，更通过实际部署证明了其在解决“论文洪流”问题上的重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 随着学术出版物数量的快速持续增长，识别高质量研究变得越来越紧迫。尽管现有利用大型语言模型（LLM）进行自动化论文评估的方法前景广阔，但它们通常受限于过时的领域知识和有限的推理能力。

**Method:** 本文提出了PaperEval，一个新颖的基于LLM的自动化论文评估框架。它通过两个关键组件解决现有方法的局限性：1) 一个领域感知论文检索模块，用于检索相关的同期工作以支持对新颖性和贡献的语境化评估；2) 一个潜在推理机制，能够深入理解复杂的动机和方法，并与同期相关工作进行全面比较，以支持更准确可靠的评估。为了指导推理过程，引入了一种渐进式排名优化策略，鼓励LLM迭代地细化其预测，并侧重于相对比较。

**Result:** 在两个数据集上的实验表明，PaperEval在学术影响和论文质量评估方面始终优于现有方法。此外，PaperEval被部署在一个真实的论文推荐系统中，用于过滤高质量论文，并在社交媒体上获得了强烈反响——积累了超过8,000名订阅者，许多过滤后的高质量论文吸引了超过10,000次观看，这证明了PaperEval的实际有效性。

**Conclusion:** PaperEval通过结合领域感知检索和潜在推理，成功解决了现有LLM论文评估方法的局限性，并在学术评估和实际应用中展现出卓越的性能和实用性。

> **ai_Abstract:** 本文提出PaperEval，一个创新的基于LLM的自动化论文评估框架，旨在解决现有LLM方法在处理海量学术出版物时面临的知识过时和推理能力不足的问题。PaperEval通过结合领域感知检索模块来获取相关同期工作，以及潜在推理机制来深入理解论文并进行全面比较，从而实现更准确可靠的评估。此外，它还引入了渐进式排名优化策略来指导LLM的推理过程。实验结果表明，PaperEval在学术影响和论文质量评估上均优于现有方法，并在实际论文推荐系统中成功部署，展现了其显著的实用效果和用户参与度。

> **摘要翻译:** 随着学术出版物数量的快速持续增长，识别高质量研究变得越来越紧迫。尽管近期利用大型语言模型（LLM）进行自动化论文评估的方法前景广阔，但它们通常受限于过时的领域知识和有限的推理能力。在这项工作中，我们提出了PaperEval，一个新颖的基于LLM的自动化论文评估框架，它通过两个关键组件解决了这些局限性：1) 一个领域感知论文检索模块，用于检索相关的同期工作，以支持对新颖性和贡献的语境化评估；2) 一个潜在推理机制，能够深入理解复杂的动机和方法，并与同期相关工作进行全面比较，以支持更准确可靠的评估。为了指导推理过程，我们引入了一种渐进式排名优化策略，鼓励LLM迭代地细化其预测，并侧重于相对比较。在两个数据集上的实验表明，PaperEval在学术影响和论文质量评估方面始终优于现有方法。此外，我们将PaperEval部署在一个真实的论文推荐系统中，用于过滤高质量论文，这在社交媒体上获得了强烈反响——积累了超过8,000名订阅者，许多过滤后的高质量论文吸引了超过10,000次观看——证明了PaperEval的实际有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [800] [MELLA: Bridging Linguistic Capability and Cultural Groundedness for Low-Resource Language MLLMs](https://arxiv.org/abs/2508.05502)
> *MELLA：弥合低资源语言多模态大语言模型的语言能力与文化基础*

*Yufei Gao, Jiaying Fei, Nuo Chen, Ruirui Chen, Guohang Yan, Yunshi Lan, Botian Shi* | **Category: cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 低资源语言, 多模态大语言模型, 语言能力, 文化基础, 数据集

**Comment:** 

> **TL;DR:** MLLMs在低资源语言中表现不佳，因为它们忽视了多模态信息和文化基础。本研究提出了MELLA数据集和双源策略，以同时提升语言能力和文化基础，实验证明了其有效性。

**AI_Comments:** 这篇论文的创新点在于明确提出了低资源语言MLLM需要兼顾“语言能力”和“文化基础”这两个关键目标，并设计了一种新颖的“双源策略”来构建数据集，有效弥补了现有方法在文化接地性方面的不足。MELLA数据集的发布也为后续研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有MLLMs在高资源语言中表现出色，但在低资源语言中有效性显著下降。当前的多语言增强方法局限于文本模态或依赖机器翻译，忽视了多模态信息和文化基础的重要性，而这两者对于有效服务低资源语言用户至关重要。

**Method:** 提出了一种双源策略，用于收集专门针对语言能力和文化基础目标的数据：文化数据来源于原生网络alt-text，语言数据来源于MLLM生成的字幕。基于此策略，构建了MELLA多模态多语言数据集，并使用该数据集对多种MLLM骨干模型进行微调。

**Result:** 在MELLA数据集上进行微调后，八种低资源语言在各种MLLM骨干模型上的性能普遍提升，模型能够产生“厚描述”。性能提升被验证来自于文化知识增强和语言能力增强。

**Conclusion:** 通过MELLA数据集和双源策略，可以有效提升低资源语言MLLMs的语言能力和文化基础，使其能够更好地服务于低资源语言用户。

> **ai_Abstract:** 本文旨在解决多模态大语言模型（MLLMs）在低资源语言中性能下降的问题，指出现有方法忽视了多模态信息和文化基础的重要性。为此，作者提出了提升MLLM语言能力和文化基础的双重目标，并设计了一种双源数据收集策略：利用原生网络alt-text获取文化数据，使用MLLM生成字幕获取语言数据。基于此策略构建了MELLA多模态多语言数据集。实验证明，在MELLA上微调后，MLLMs在八种低资源语言上的性能显著提升，且能生成更具文化深度的描述，验证了所提方法的有效性。

> **摘要翻译:** 多模态大语言模型（MLLMs）在高资源语言中表现出色。然而，在低资源语言环境下，它们的有效性显著下降。当前的多语言增强方法通常局限于文本模态或仅仅依赖机器翻译。尽管这些方法有助于模型获得基本的语言能力并产生“薄描述”，但它们忽视了多模态信息和文化基础的重要性，而这两者对于有效服务低资源语言用户至关重要。为了弥合这一差距，本研究确定了在低资源语言设置下真正有效的MLLM的两个重要目标，即1）语言能力和2）文化基础，并特别强调文化意识。为了实现这两个目标，我们提出了一种双源策略，指导收集针对每个目标量身定制的数据，其中文化数据来源于原生网络alt-text，语言数据来源于MLLM生成的字幕。作为具体实现，我们引入了MELLA，一个多模态、多语言数据集。实验结果表明，在MELLA上进行微调后，八种语言在各种MLLM骨干模型上的性能普遍提升，模型能够产生“厚描述”。我们验证了性能提升来自于文化知识增强和语言能力增强。我们的数据集可在 https://opendatalab.com/applyMultilingualCorpus 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [805] [Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation](https://arxiv.org/abs/2508.05535)
> *人机协作操作中的混合主动对话*

*Albert Yu, Chengshu Li, Luca Macesanu, Arnav Balaji, Ruchira Ray, Raymond Mooney, Roberto Martín-Martín* | **Category: cs.CL, cs.HC, cs.LG, cs.MA, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 混合主动对话, 人机协作, MICoBot, 自然语言, 任务分配

**Comment:** 

> **TL;DR:** MICoBot是一个采用混合主动对话范式的人机协作系统，它允许机器和人使用自然语言共同决定任务分配，通过三层决策机制显著提高了任务成功率和用户体验。

**AI_Comments:** 本文创新性地将混合主动对话范式引入人机协作操作，通过MICoBot系统实现了人机之间更自然、灵活的沟通和任务分配。其三层决策机制设计精巧，能够有效处理复杂的协作场景。实验结果表明了其在实际应用中的巨大潜力，尤其是在提高用户体验和任务成功率方面。这是一个重要的进步，有助于推动人机协作技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 有效的人机协作机器人系统需要适应各种人类伙伴，他们的行为、协助意愿和对机器人能力的理解会随时间变化。这要求一个紧密耦合的通信循环，使双方都能灵活地提出、接受或拒绝请求，以有效协调完成任务。

**Method:** 本文将混合主动对话范式应用于协作人机团队，并提出了MICoBot系统。MICoBot通过三层决策来处理多样化的、面向任务的对话，并寻找最小化人类努力的成功协作策略：(1)元规划器根据人类对话制定高层协作策略；(2)规划器根据机器人能力（通过预训练的示能模型测量）和人类估计的可用性，优化分配剩余步骤；(3)动作执行器决定执行的低级动作或对人说的话。

**Result:** 在模拟和真实世界中（与18名独特的人类参与者在27小时内使用物理机器人）进行的广泛评估表明，该方法能够有效地与不同的人类用户协作，与纯LLM基线和其他代理分配模型相比，任务成功率和用户体验显著提高。

**Conclusion:** MICoBot通过混合主动对话范式，实现了高效、灵活的人机协作，显著提升了任务成功率和用户体验，证明了其在处理复杂人机交互场景中的有效性。

> **ai_Abstract:** 本文提出了一种名为MICoBot的混合主动对话系统，用于人机协作操作。该系统允许人类和机器人使用自然语言共同发起、接受或拒绝任务分配提议。MICoBot通过一个三层决策框架（包括元规划、任务分配规划和低级动作执行）来优化协作策略并最小化人类努力。广泛的模拟和真实世界评估表明，MICoBot能有效适应不同人类用户，显著提高任务成功率和用户体验，优于基线模型。

> **摘要翻译:** 有效的机器人系统，用于长期人机协作，必须适应各种人类伙伴，这些伙伴的身体行为、协助意愿以及对机器人能力的理解可能会随时间变化。这要求一个紧密耦合的通信循环，该循环赋予两个代理提出、接受或拒绝请求的灵活性，以便在有效完成任务时进行协调。我们将混合主动对话范式应用于协作人机团队，并提出了MICoBot，这是一个处理常见场景的系统，在该场景中，两个代理都使用自然语言主动地制定、接受或拒绝关于谁能最好地完成任务不同步骤的提议。为了处理多样化的、面向任务的对话，并找到最小化人类努力的成功协作策略，MICoBot在三个层面做出决策：(1)一个元规划器考虑人类对话来制定和编码高级协作策略，(2)一个规划器根据机器人的能力（通过模拟预训练的示能模型测量）和人类估计的可用性，优化地将剩余步骤分配给任一代理，以及(3)一个动作执行器决定要执行的低级动作或对人类说的话。我们在模拟和真实世界中——在一个物理机器人上与18名独特的人类参与者进行了超过27小时的广泛评估——证明了我们方法能够有效地与不同的人类用户协作，与纯LLM基线和其他代理分配模型相比，显著提高了任务成功率和用户体验。请参阅更多视频和材料：https://robin-lab.cs.utexas.edu/MicoBot/。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [810] [SPGISpeech 2.0: Transcribed multi-speaker financial audio for speaker-tagged transcription](https://arxiv.org/abs/2508.05554)
> *SPGISpeech 2.0：用于说话人标记转录的转录多说话人金融音频*

*Raymond Grossman, Taejin Park, Kunal Dhawan, Andrew Titus, Sophia Zhi, Yulia Shchadilova, Weiqing Wang, Jagadeesh Balam, Boris Ginsburg* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** SPGISpeech 2.0, 语音识别, 数据集, 金融领域, 说话人标记转录

**Comment:** 

> **TL;DR:** SPGISpeech 2.0 是一个包含 3,780 小时金融领域多说话人音频的转录数据集，旨在改进说话人标记的自动语音识别。

**AI_Comments:** SPGISpeech 2.0 通过提供大规模、高质量且包含说话人信息的金融领域音频数据，显著填补了该领域多说话人 ASR 数据稀缺的空白。其创新性在于专注于特定领域并提供详细的元数据，这对于开发更精确的金融领域语音识别模型至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高金融领域说话人标记转录的建模任务多样性，并促进语音识别技术的发展。

**Method:** 推出了 SPGISpeech 2.0 数据集，该数据集新增了 3,780 小时专业转录的财报电话会议音频，并包含通话和说话人信息，以支持多说话人自动语音识别（ASR）。

**Result:** 通过在 SPGISpeech 2.0 上对流行的语音识别模型进行微调，验证了其在说话人标记 ASR 性能方面的提升。

**Conclusion:** SPGISpeech 2.0 是一个有用的数据集，有望推动语音识别技术和相关研究应用的发展。

> **ai_Abstract:** SPGISpeech 2.0 是一个新增 3,780 小时专业转录金融财报电话会议音频的数据集，旨在提升说话人标记转录的建模任务多样性。该数据集包含音频片段、格式化文本转录以及通话和说话人信息，支持端到端和多说话人 ASR。通过在流行模型上进行微调，验证了其在说话人标记 ASR 性能上的提升，并期望能推动语音识别技术发展。

> **摘要翻译:** 我们推出了 SPGISpeech 2.0，这是一个适用于金融领域说话人标记转录的数据集。SPGISpeech 2.0 提高了适用建模任务的多样性，同时保持了原始 SPGISpeech 数据集的核心特征：音频片段及其相应的完全格式化文本转录，可用于端到端自动语音识别 (ASR)。SPGISpeech 2.0 包含额外 3,780 小时专业转录的财报电话会议。此外，该数据集包含每个音频片段的通话和说话人信息，便于多说话人 ASR。我们通过在 SPGISpeech 2.0 上微调后，流行语音识别模型的说话人标记 ASR 性能的改进来验证 SPGISpeech 2.0 的实用性。SPGISpeech 2.0 免费用于非商业用途，我们期望它能促进语音识别技术的进步并激发广泛的研究应用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [815] [Fairy$\pm i$: the First 2-bit Complex LLM with All Parameters in $\{\pm1, \pm i\}$](https://arxiv.org/abs/2508.05571)
> *Fairy$\\pm i$: 首个参数全为$\\{\\pm1, \\pm i\\}$的2比特复数大语言模型*

*Feiyu Wang, Guoan Wang, Yihao Zhang, Shengfan Wang, Weitao Li, Bokai Huang, Shimao Chen, Zihan Jiang, Rui Xu, Tong Yang* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 2比特量化, 复数大语言模型, 量化感知训练, 无乘法推理, 低比特LLM

**Comment:** 

> **TL;DR:** Fairy$\\pm i$是首个2比特复数大语言模型，通过利用复数域提升全精度模型上限并实现高效量化，在性能上超越了现有2比特量化方法的上限。

**AI_Comments:** 这项工作创新性地将复数域引入大语言模型量化，突破了传统量化方法以全精度模型为上限的局限。通过利用复数表示和单位四次根的特性，实现了极低的2比特量化，同时还能进行无乘法推理，极大地提升了计算效率。这是一个重要的进展，为在资源受限设备上部署高性能大语言模型提供了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 现有量化感知训练（QAT）研究将全精度模型精度视为上限，致力于最小化量化误差，但从未有方法尝试突破此上限。本文旨在打破这一精度上限。

**Method:** 提出Fairy$\\pm i$，首个针对复数大语言模型的2比特量化框架。通过利用复数域的表示优势来提升全精度精度。将权重映射到单位四次根$\\{\\pm1, \\pm i\\}$，形成对称且信息论最优的2比特表示。每个量化权重实部或虚部为零，实现仅通过加法和元素交换的无乘法推理。

**Result:** Fairy$\\pm i$在PPL和下游任务上均超越了现有2比特量化方法的精度上限，同时保持了严格的存储和计算效率。

**Conclusion:** 这项工作为在极低比特约束下构建高精度且实用的大语言模型开辟了新方向。

> **ai_Abstract:** Fairy$\\pm i$是首个2比特复数大语言模型量化框架，旨在打破现有量化方法的精度上限。它通过在复数域中提升全精度模型性能，并将权重映射到$\\{\\pm1, \\pm i\\}$，实现了高效且无乘法的2比特推理。实验证明，Fairy$\\pm i$在性能上超越了现有2比特量化方案，为构建高精度低比特大语言模型提供了新方向。

> **摘要翻译:** 量化感知训练（QAT）将量化集成到训练循环中，使大语言模型能够学习鲁棒的低比特表示，被广泛认为是前景广阔的研究方向之一。当前所有QAT研究都专注于最小化全精度模型上的量化误差，其中全精度精度充当上限（精度天花板）。目前没有现有方法尝试超越这个天花板。为了打破这个天花板，我们提出了一种新范式：提高天花板（全精度模型），然后仍然将其高效量化为2比特。我们提出了Fairy$\\pm i$，这是首个针对复数大语言模型的2比特量化框架。具体而言，我们的方法利用复数域的表示优势来提升全精度精度。我们将权重映射到单位四次根$\\{\\pm1, \\pm i\\}$，形成了一个完美对称且信息论最优的2比特表示。重要的是，每个量化权重都具有零实部或零虚部，从而仅使用加法和元素交换即可实现无乘法推理。实验结果表明，Fairy$\\pm i$在PPL和下游任务方面均优于现有2比特量化方法的上限，同时保持严格的存储和计算效率。这项工作为在极低比特约束下构建高精度且实用的大语言模型开辟了新方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [821] [Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision](https://arxiv.org/abs/2508.05606)
> *Uni-cot：迈向文本与视觉统一的思维链推理*

*Luozheng Qin, Jia Gong, Yuqing Sun, Tianjiao Li, Mengping Yang, Xiaomeng Yang, Chao Qu, Zhiyu Tan, Hao Li* | **Category: cs.CL, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 思维链推理, 多模态, 视觉-语言, 统一模型, 图像生成

**Comment:** 

> **TL;DR:** 提出Uni-CoT框架，通过统一模型和两级推理范式，解决了多模态思维链推理中的视觉状态转换建模挑战，并在多个基准测试中取得了SOTA性能。

**AI_Comments:** Uni-CoT的创新之处在于其统一的多模态CoT框架和两级推理范式，有效解决了视觉-语言推理中视觉状态转换建模的挑战，同时显著降低了计算资源需求。这对于推动多模态AI的发展具有重要意义，尤其是在需要复杂视觉推理和内容生成的任务中。其高效的资源利用也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有的思维链（CoT）推理方法在扩展到视觉-语言任务时面临挑战，难以有效解释视觉状态转换或因碎片化架构导致视觉轨迹不连贯。

**Method:** 本文提出了Uni-CoT框架，一个统一的思维链框架，旨在实现连贯且有根据的多模态推理。其核心思想是利用一个具备图像理解和生成能力的统一模型来推理视觉内容并建模演变中的视觉状态。为克服高计算成本和训练负担，Uni-CoT引入了一种新颖的两级推理范式：用于高层任务规划的宏观级CoT和用于子任务执行的微观级CoT。此外，还结合了交错图像-文本监督（宏观级）和多任务目标（微观级）的结构化训练范式。

**Result:** Uni-CoT在推理驱动的图像生成基准（WISE）和编辑基准（RISE和KRIS）上展示了最先进（SOTA）的性能和强大的泛化能力。所有实验仅需8个A100 GPU即可高效完成。

**Conclusion:** Uni-CoT为多模态推理提供了一个有前途的解决方案，能够实现可扩展且连贯的多模态推理。

> **ai_Abstract:** 本文提出了Uni-CoT，一个统一的思维链（CoT）框架，旨在解决现有方法在视觉-语言推理中难以建模视觉状态转换的问题。Uni-CoT利用一个能够理解和生成图像的统一模型，并引入了两级推理范式（宏观级CoT用于规划，微观级CoT用于执行）以降低计算成本。结合结构化训练范式，Uni-CoT实现了可扩展且连贯的多模态推理，并在多个图像生成和编辑基准上取得了最先进的性能。

> **摘要翻译:** 思维链（CoT）推理已被广泛采用以增强大型语言模型（LLMs），通过将复杂任务分解为更简单、按顺序的子任务。然而，将CoT扩展到视觉-语言推理任务仍然具有挑战性，因为它通常需要解释视觉状态的转换以支持推理。现有方法由于建模视觉状态转换的能力有限或或碎片化架构导致视觉轨迹不连贯而难以解决此问题。为了克服这些限制，我们提出了Uni-CoT，一个统一的思维链框架，能够在单一统一模型中实现连贯且有根据的多模态推理。其核心思想是利用一个既能理解图像又能生成图像的模型来对视觉内容进行推理并建模演变中的视觉状态。然而，赋予一个统一模型实现这一目标并非易事，考虑到高昂的计算成本和训练负担。为了解决这个问题，Uni-CoT引入了一种新颖的两级推理范式：用于高层任务规划的宏观级CoT和用于子任务执行的微观级CoT。这种设计显著降低了计算开销。此外，我们引入了一种结构化的训练范式，将宏观级CoT的交错图像-文本监督与微观级CoT的多任务目标相结合。这些创新共同使Uni-CoT能够执行可扩展且连贯的多模态推理。此外，由于我们的设计，所有实验仅使用8个配备80GB显存的A100 GPU即可高效完成。在推理驱动的图像生成基准（WISE）和编辑基准（RISE和KRIS）上的实验结果表明，Uni-CoT展示了SOTA性能和强大的泛化能力，确立了Uni-CoT作为多模态推理的有前景解决方案。项目页面和代码：https://sais-fuxi.github.io/projects/uni-cot/

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [825] [A Latent-Variable Model for Intrinsic Probing](https://arxiv.org/abs/2201.08214)
> *探究式探测的潜在变量模型*

*Karolina Stańczak, Lucas Torroba Hennigen, Adina Williams, Ryan Cotterell, Isabelle Augenstein* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 潜在变量模型, 内在探究, 预训练表示, 语言信息, 形态句法

**Comment:** 

> **TL;DR:** 提出了一种新的潜在变量模型用于内在探究，可以更准确地估计预训练表示中的语言信息，并发现它们编码了跨语言的形态句法知识。

**AI_Comments:** 该论文的创新之处在于提出了一个新的潜在变量模型，用于更精确地探究预训练模型中语言信息的编码方式和位置。其重要性在于为理解深度学习模型内部的工作机制提供了一个更有效的工具，特别是在语言学信息编码方面。

<details>
  <summary>Details</summary>

**Motivation:** 预训练上下文表示在多种NLP任务上的成功，促使研究人员分析其中是否包含语言信息，特别是探究这些信息是如何编码的。

**Method:** 提出了一种新的潜在变量公式来构建内在探究器，并推导了对数似然的可处理变分近似。

**Result:** 该模型用途广泛，并且比文献中提出的两种现有内在探究器产生了更紧密的互信息估计。同时，发现预训练表示发展出了一种跨语言纠缠的形态句法概念。

**Conclusion:** 预训练表示确实编码了跨语言纠缠的形态句法知识，并且所提出的潜在变量模型能够更有效地探究这些语言属性。

> **ai_Abstract:** 这篇论文提出了一种新颖的潜在变量模型，用于内在探究（intrinsic probing），旨在识别预训练上下文表示中编码的语言属性及其编码位置。该模型通过可处理的变分近似来估计对数似然，并在实验中展现出比现有方法更紧密的互信息估计。研究结果表明，预训练表示确实学习到了跨语言纠缠的形态句法知识。

> **摘要翻译:** 预训练上下文表示的成功促使研究人员分析它们是否存在语言信息。事实上，很自然地假设这些预训练表示确实编码了某种程度的语言知识，因为它们在各种NLP任务上带来了巨大的经验改进，这表明它们正在学习真正的语言泛化。在这项工作中，我们专注于内在探测，这是一种分析技术，其目标不仅是识别表示是否编码了语言属性，还在于查明该属性编码在何处。我们提出了一种新颖的潜在变量公式来构建内在探测器，并推导了对数似然的可处理变分近似。我们的结果表明，我们的模型用途广泛，并且比文献中先前提出的两种内在探测器产生了更紧密的互信息估计。最后，我们发现经验证据表明，预训练表示发展出了一种跨语言纠缠的形态句法概念。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [830] [When in Doubt, Cascade: Towards Building Efficient and Capable Guardrails](https://arxiv.org/abs/2407.06323)
> *当有疑问时，级联：构建高效且强大的护栏*

*Manish Nagireddy, Inkit Padhi, Soumya Ghosh, Prasanna Sattigeri* | **Category: cs.CL** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 护栏, 合成数据生成, 用-提区分, 偏见检测

**Comment:** 

> **TL;DR:** 本文提出了一种基于用-提区分的合成数据生成管道，用于构建高效且强大的大型语言模型护栏，在降低计算成本的同时实现有竞争力的性能。

**AI_Comments:** 本文的核心创新在于其提出的基于“用-提区分”的合成数据生成管道，这有效地解决了传统检测器在处理社会偏见时遇到的性能瓶颈。通过生成大规模的合成对比数据，该方法不仅提高了护栏模型的效率和能力，还显著降低了计算成本，这对于实际部署具有重要意义。其可扩展性和可复现性也为未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在各种下游任务中表现出色，但容易生成有害和有偏见的输出。为了解决这些不良生成，开发护栏（或检测器）模型变得越来越重要。

**Method:** 受开发社会偏见检测器经验的启发，本文采用了“用-提区分”的概念，并描述了一个完全可扩展和可复现的合成数据生成管道，该管道利用分类法驱动的指令来创建有针对性的标记数据。使用此管道生成了超过30万个独特的对比样本。

**Result:** 该方法在计算成本仅为一小部分的情况下，实现了与现有方法相当的性能，并在大量开源数据集上进行了系统评估。

**Conclusion:** 本文提供了关于迭代开发高效且强大的护栏模型的见解。

> **ai_Abstract:** 本文针对大型语言模型生成有害和偏见内容的挑战，提出了一种构建高效护栏模型的方法。通过引入“用-提区分”概念，并开发一个基于分类法驱动指令的合成数据生成管道，生成了大量对比样本。实验证明，该方法在显著降低计算成本的同时，能够达到与现有技术相当的性能，并为开发强大的护栏模型提供了新的思路。

> **摘要翻译:** 大型语言模型（LLMs）在各种下游任务中表现出令人信服的性能。然而，这些系统容易生成不良输出，例如有害和有偏见的文本。为了纠正此类生成，护栏（或检测器）模型的开发已获得关注。受开发社会偏见检测器发现的启发，我们采用了用-提区分的概念——我们将其识别为我们社会偏见检测器初步版本中表现不佳的主要原因。掌握了这些信息，我们描述了一个完全可扩展和可复现的合成数据生成管道，该管道利用分类法驱动的指令来创建有针对性的标记数据。使用此管道，我们生成了超过30万个独特的对比样本，并提供了广泛的实验来系统评估一系列开源数据集上的性能。我们表明，我们的方法以一小部分计算成本实现了有竞争力的性能，并为迭代开发高效且强大的护栏模型提供了见解。警告：本文包含有毒、有偏见和可能有害的文本示例。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [835] [WhisperNER: Unified Open Named Entity and Speech Recognition](https://arxiv.org/abs/2409.08107)
> *WhisperNER：统一开放命名实体与语音识别*

*Gil Ayache, Menachem Pirchi, Aviv Navon, Aviv Shamsian, Gill Hetz, Joseph Keshet* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 语音识别, 命名实体识别, 开放类型NER, WhisperNER, 联合模型

**Comment:** 

> **TL;DR:** WhisperNER是一个新模型，能同时进行语音转录和开放类型命名实体识别，在实验中表现优于基线模型。

**AI_Comments:** 该论文的创新点在于提出了一个统一的模型WhisperNER，将语音识别与开放类型命名实体识别相结合，这对于提升转录质量和信息提取具有重要意义。通过使用合成数据进行训练，解决了开放类型NER数据稀缺的问题，并展示了其在处理多样化和动态实体方面的潜力。其超越基线模型的表现也证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 将命名实体识别（NER）与自动语音识别（ASR）相结合可以显著提高转录的准确性和信息量。

**Method:** 本文介绍了WhisperNER，一个允许联合语音转录和实体识别的新模型。它支持开放类型NER，能够识别多样化和不断演变的实体。通过在大型合成数据集中增加合成语音样本，在大量具有多样化NER标签的示例上训练模型。训练期间，模型被提示NER标签并优化以输出转录的语音和相应的标记实体。为了评估WhisperNER，为常用的NER基准生成合成语音，并用开放NER标签标注现有的ASR数据集。

**Result:** 实验表明，WhisperNER在域外开放类型NER和监督微调方面均优于自然基线模型。

**Conclusion:** WhisperNER通过联合语音转录和开放命名实体识别，显著提高了转录的准确性和信息量，并在多种评估中表现出色。

> **ai_Abstract:** WhisperNER是一个创新模型，旨在通过联合语音转录和开放类型命名实体识别（NER）来提高自动语音识别（ASR）的准确性和信息量。该模型利用合成语音样本增强大型合成数据集进行训练，以支持多样化的NER标签。实验结果表明，WhisperNER在处理域外开放类型NER和进行监督微调时，其性能均优于传统基线模型。

> **摘要翻译:** 将命名实体识别（NER）与自动语音识别（ASR）相结合可以显著提高转录的准确性和信息量。在本文中，我们介绍了WhisperNER，一个允许联合语音转录和实体识别的新模型。WhisperNER支持开放类型NER，能够在推理时识别多样化和不断演变的实体。基于开放NER研究的最新进展，我们用合成语音样本扩充了一个大型合成数据集。这使我们能够在大量具有多样化NER标签的示例上训练WhisperNER。在训练期间，模型被提示NER标签并优化以输出转录的语音以及相应的标记实体。为了评估WhisperNER，我们为常用的NER基准生成合成语音，并用开放NER标签标注现有的ASR数据集。我们的实验表明，WhisperNER在域外开放类型NER和监督微调方面均优于自然基线模型。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [840] [Recent Advances in Speech Language Models: A Survey](https://arxiv.org/abs/2410.03751)
> *语音语言模型最新进展：一项综述*

*Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Yiwen Guo, Irwin King* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 语音语言模型, SpeechLMs, 综述, 端到端, 自动语音识别

**Comment:** 

> **TL;DR:** 本综述首次全面概述了语音语言模型（SpeechLMs）的最新方法，SpeechLMs作为端到端模型，旨在解决传统“ASR+LLM+TTS”管道的信息丢失、延迟和错误积累问题。

**AI_Comments:** 该综述论文填补了语音语言模型领域系统性概述的空白，对于理解这一新兴技术至关重要。它不仅总结了现有方法，还指出了未来的研究方向和挑战，对研究人员和开发者具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 自然人类交互主要依赖语音，但现有的大语言模型（LLMs）主要基于文本。传统的“ASR+LLM+TTS”管道存在信息丢失、显著延迟和多阶段错误累积等固有限制，因此需要开发端到端的语音语言模型（SpeechLMs）来克服这些问题。

**Method:** 本综述提供了构建语音语言模型（SpeechLMs）最新方法的首次全面概述。它详细介绍了SpeechLMs架构的关键组件和对其开发至关重要的各种训练方案。此外，论文系统地调查了SpeechLMs的各种能力，分类了它们的评估指标，并讨论了该快速发展领域面临的挑战和未来的研究方向。

**Result:** Not mentioned in abstract

**Conclusion:** 本综述全面概述了语音语言模型的最新进展，指出了该领域面临的挑战和未来的研究方向，确认了SpeechLMs作为解决传统语音交互管道限制的有前景的替代方案。

> **ai_Abstract:** 本综述论文首次全面概述了语音语言模型（SpeechLMs）的最新进展。SpeechLMs是端到端模型，旨在克服传统“ASR+LLM+TTS”管道在语音交互中存在的信息丢失、高延迟和错误累积等问题。论文详细介绍了SpeechLMs的架构组件、训练方法、能力、评估指标，并探讨了该领域的挑战和未来研究方向。

> **摘要翻译:** 大型语言模型（LLMs）最近获得了广泛关注，主要归因于其在基于文本的交互方面的能力。然而，自然人类交互通常依赖于语音，因此需要向基于语音的模型转变。实现这一目标的一个直接方法是采用“自动语音识别（ASR）+LLM+文本转语音（TTS）”的管道，其中输入语音被转录为文本，由LLM处理，然后转换回语音。尽管这种方法直接，但它存在固有的局限性，例如模态转换期间的信息丢失、由于复杂管道导致的显著延迟以及三阶段中的错误累积。为了解决这些问题，语音语言模型（SpeechLMs）——无需从文本转换即可生成语音的端到端模型——作为一种有前景的替代方案应运而生。本综述论文首次全面概述了构建SpeechLMs的最新方法，详细阐述了其架构的关键组件和对其发展至关重要的各种训练方案。此外，我们系统地调查了SpeechLMs的各种能力，分类了它们的评估指标，并讨论了该快速发展领域面临的挑战和未来的研究方向。GitHub存储库可在https://github.com/dreamtheater123/Awesome-SpeechLM-Survey获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [845] [BloomWise: Enhancing Problem-Solving capabilities of Large Language Models using Bloom's-Taxonomy-Inspired Prompts](https://arxiv.org/abs/2410.04094)
> *BloomWise：使用布鲁姆分类法启发式提示增强大型语言模型的解决问题能力*

*Maria-Eleni Zoumpoulidi, Georgios Paraskevopoulos, Alexandros Potamianos* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 数学推理, 提示工程, 布鲁姆分类法, 可解释性

**Comment:** 

> **TL;DR:** BloomWise 是一种受布鲁姆分类法启发的提示技术，旨在提高大型语言模型在数学问题解决中的性能和可解释性。

**AI_Comments:** 这篇论文通过应用布鲁姆分类法这一成熟的教育框架，引入了一种创新的提示策略，以增强大型语言模型在数学推理方面的能力。其侧重于“如何思考”而非“思考什么”的方法，巧妙地解决了LLM在性能和可解释性方面的已知局限性。迭代过程与收敛标准的结合是一种实用的设计选择，有望为LLM的推理能力带来实质性改进。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）能力强大，但在数学推理方面仍面临挑战。受人类在被提示“如何思考”而非“思考什么”时学习更有效的启发，研究旨在提升LLM的数学问题解决能力并增强其解决方案的可解释性。

**Method:** BloomWise 是一种受认知启发的提示技术。它通过引导LLM按顺序执行从基础（如记忆）到高级（如评估）的认知操作来生成解释形式的解决方案，模拟人类的理解构建过程。该过程迭代进行，如果两个或更多连续级别产生相同答案则提前停止，否则继续直到所有级别完成。

**Result:** 在五个流行的数学推理数据集上进行的广泛实验证明了 BloomWise 的有效性。研究还进行了全面的消融研究，分析了系统中每个组件的优势。

**Conclusion:** BloomWise 是一种创新的提示技术，通过模仿人类认知过程（基于布鲁姆分类法）显著增强了大型语言模型在数学问题解决方面的能力，并提高了解决方案的可解释性。

> **ai_Abstract:** BloomWise 是一种新颖的、受认知启发的提示技术，它利用布鲁姆分类法来提高大型语言模型的数学推理能力和解决方案的可解释性。它引导LLM通过一系列认知操作，从基本的记忆到高级的评估，模仿人类的学习过程。在五个数据集上的实验证实了其有效性，并通过消融研究详细阐述了各组件的贡献。

> **摘要翻译:** 尽管大型语言模型（LLM）在一系列任务中表现出卓越的能力，但数学推理仍然是一个具有挑战性的领域。我们观察到人类在被提示“如何思考”而不是“思考什么”时学习更有效，受此启发，我们引入了BloomWise，这是一种受认知启发的提示技术，旨在增强LLM在数学问题解决中的性能，同时使其解决方案更具可解释性。BloomWise鼓励LLM以解释的形式生成解决方案，通过一系列认知操作（从基础的记忆到更高级的推理技能，如评估）逐步进行，这反映了人类如何建立理解。这个过程会迭代这些级别，如果满足收敛标准则提前停止：具体来说，如果两个或更多连续级别产生相同的答案，则输出最早的该级别解决方案；否则，过程继续直到所有级别完成。通过在五个流行的数学推理数据集上进行广泛实验，我们证明了BloomWise的有效性。我们还进行了全面的消融研究，以分析我们系统中每个组件的优势。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [850] [Scaling Laws For Mixed Quantization](https://arxiv.org/abs/2410.06722)
> *混合量化的标度律*

*Zeyu Cao, Boyang Gu, Cheng Zhang, Pedro Gimenes, Jianqiao Lu, Jianyi Cheng, Xitong Gao, Yiren Zhao* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 后训练量化, 大型语言模型, 标度律, 混合量化, 量化块大小

**Comment:** 

> **TL;DR:** 该研究提出了大型语言模型（LLMs）后训练量化的统一标度律，表明更大的模型更适合采用更高的量化比（$Q_r$），并且不需要非常小的量化块大小（$Q_b$）。

**AI_Comments:** 该论文通过引入量化比和量化块大小两个关键指标，并提出了一个统一的后训练量化标度律，为大型语言模型的高效部署提供了重要的理论指导。其创新性在于量化了模型规模与量化策略之间的关系，尤其指出大型模型在量化比和块大小选择上的优势，这对于优化LLM推理性能和简化硬件设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当对大型语言模型进行低精度量化以达到目标精度或困惑度时，需要保留多少高精度计算量，以及随着模型规模增大，量化需要有多精细。

**Method:** 引入了两个关键指标：量化比（$Q_r$，低精度参数占总参数的比例）和量化块大小（$Q_b$，共享缩放因子的块内值数量）。通过对不同模型和量化方法进行广泛且严格控制的实验，提出了一个统一的后训练量化（PTQ）标度律，可以预测不同$Q_r$和$Q_b$下的损耗退化。

**Result:** 提出了一个统一的PTQ标度律。对于$Q_r$，标度律表明参数缩放和比率缩放具有乘法关系，这意味着更大的模型更适合采用更高的量化比$Q_r$，从而支持混合量化在推理中的应用增加。对于$Q_b$，研究结果表明，对于大型模型而言，小的块大小并非必需，采用小的$Q_b$反而会不必要地使硬件电路设计复杂化。

**Conclusion:** 更大的大型语言模型可以更好地利用更高的量化比，促进混合量化的应用。对于大型模型，小的量化块大小并非必需，可以简化硬件设计。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）后训练量化中的关键问题：如何平衡高精度计算与低精度量化以达到目标性能，以及量化粒度应如何随模型规模变化。为此，论文引入了量化比（$Q_r$）和量化块大小（$Q_b$）两个指标，并通过广泛实验提出了一个统一的PTQ标度律。该标度律揭示，模型规模越大越适合采用更高的量化比，从而促进混合量化。同时，研究指出对大型模型而言，小的量化块大小并非必要，且可能增加硬件设计复杂度。

> **摘要翻译:** 大型语言模型（LLMs）的后训练量化已被证明能有效降低推理所需的内存和计算需求。在这项研究中，我们关注一个直接的问题：当旨在通过低精度量化达到目标精度或困惑度时，需要保留多少高精度计算量，以及随着LLMs扩展到更大规模，这种量化需要有多精细？我们首先引入了两个关键指标，分别命名为量化比（$Q_r$）和量化块大小（$Q_b$）。前者衡量的是量化为低精度算术的参数数量占总参数数量的比例，而后者定义了块内共享缩放因子的值数量，类似于NVIDIA Blackwell架构中FP4格式引入的块大小概念。通过对不同模型和量化方法进行广泛且严格控制的实验，我们提出了一个关于后训练量化（PTQ）的统一标度律，可以预测不同$Q_r$和$Q_b$下的损耗退化。对于$Q_r$，我们的标度律意味着参数缩放和比率缩放具有乘法关系。因此，更大的模型更适合采用更高的量化比$Q_r$，从而支持混合量化在推理中应用的增加。关于$Q_b$，我们的发现表明，类似于Blackwell中使用的较小块大小对于大型模型并非必需。采用小的$Q_b$反而会不必要地使硬件电路设计复杂化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [855] [Data Processing for the OpenGPT-X Model Family](https://arxiv.org/abs/2410.08800)
> *OpenGPT-X模型家族的数据处理*

*Nicolo' Brandizzi, Hammam Abdelwahab, Anirban Bhowmick, Lennard Helmer, Benny Jörg Stein, Pavel Denisov, Qasid Saleem, Michael Fromm, Mehdi Ali, Richard Rutmann, Farzad Naderi, Mohamad Saif Agy, Alexander Schwirjow, Fabian Küch, Luzian Hahn, Malte Ostendorff, Pedro Ortiz Suarez, Georg Rehm, Dennis Wegener, Nicolas Flores-Herr, Joachim Köhler, Johannes Leveling* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 数据处理, 多语言大型语言模型, OpenGPT-X, 数据管道, 欧洲语言

**Comment:** 

> **TL;DR:** 本文介绍了OpenGPT-X项目的数据准备流程，该项目旨在创建针对欧洲主要语言的开放高性能多语言大型语言模型，并详细说明了数据处理步骤、区分了精选数据和网络数据，并提供了数据集分析、见解和未来建议。

**AI_Comments:** 本文的创新之处在于其为大规模多语言大型语言模型（LLMs）构建了一个全面且细致的数据准备管道。特别值得注意的是，它根据数据来源（精选数据与网络数据）设计了不同的处理策略，并强调了数据透明度和符合欧洲数据法规的重要性，这对于在欧盟地区部署LLMs至关重要。这篇论文对于未来构建符合特定地域要求的多语言LLMs提供了宝贵的实践经验和指导。

<details>
  <summary>Details</summary>

**Motivation:** OpenGPT-X项目旨在创建开放且高性能的多语言大型语言模型（LLMs），覆盖所有主要的欧洲语言，并特别关注欧盟内的实际应用。因此，需要开发一个全面的数据准备流程。

**Method:** 本文介绍了从数据选择、需求定义到最终过滤数据准备的所有数据处理步骤。它区分了精选数据和网络数据，并为每种数据类型开发了独特的管道，其中精选数据仅进行最少过滤，而网络数据需要广泛的过滤和去重。此外，还对数据集进行了深入分析。

**Result:** 结果是建立了一个全面的数据准备流程，该流程能够处理不同类型的数据（精选数据和网络数据），并提高了数据集的透明度，使其与欧洲数据法规保持一致。

**Conclusion:** 论文分享了项目期间面临的关键见解和挑战，并为未来大规模多语言LLM数据准备工作提供了建议。

> **ai_Abstract:** 本文详细介绍了OpenGPT-X项目的数据准备管道，该项目旨在开发针对欧洲主要语言的开放高性能多语言大型语言模型。文章阐述了从数据选择到最终过滤的完整处理流程，并根据数据来源（精选数据和网络数据）设计了不同的处理管道，其中网络数据需进行更严格的过滤和去重。论文还对数据集进行了深入分析以确保符合欧洲数据法规，并分享了项目经验和未来建议。

> **摘要翻译:** 本文全面概述了为OpenGPT-X项目开发的数据准备管道，该项目是一项旨在创建开放和高性能多语言大型语言模型（LLM）的大规模倡议。该项目目标是提供覆盖所有主要欧洲语言的模型，并特别关注欧盟内的实际应用。我们解释了所有数据处理步骤，从数据选择和需求定义到最终过滤数据的准备。我们区分了精选数据和网络数据，因为这些类别中的每一个都由不同的管道处理，其中精选数据进行最少过滤，而网络数据需要广泛的过滤和去重。这种区别指导了两种管道的专门算法解决方案的开发。除了描述处理方法外，我们还对数据集进行了深入分析，提高了透明度并符合欧洲数据法规。最后，我们分享了项目期间面临的关键见解和挑战，为未来大规模多语言LLM数据准备工作提供了建议。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [860] [Large Language Models Still Exhibit Bias in Long Text](https://arxiv.org/abs/2410.17519)
> *大型语言模型在长文本中仍表现出偏见*

*Wonje Jeung, Dongjae Jeon, Ashkan Yousefpour, Jonghyun Choi* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 偏见, 长文本生成, 公平性, 微调

**Comment:** 

> **TL;DR:** 大型语言模型在长文本生成中仍存在偏见，现有基准未能充分评估。本文提出了LTF-TEST框架来检测长文本偏见，并引入FT-REGARD微调方法来减轻偏见。

**AI_Comments:** 本文的创新点在于提出了一个专门用于评估大型语言模型在长文本生成中偏见的框架LTF-TEST，填补了现有公平性基准的空白。其不仅关注结果，还分析了模型背后的推理，能更深入地揭示偏见。同时，提出的FT-REGARD微调方法也为缓解长文本偏见提供了一个有效的实践方案，对于提升LLM的公平性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型公平性基准主要关注简单任务，如多项选择题，忽略了在长文本生成等复杂场景中可能出现的偏见。为了弥补这一空白，本文旨在评估和解决大型语言模型在长文本生成中的偏见问题。

**Method:** 本文引入了长文本公平性测试框架（LTF-TEST），通过散文式提示评估LLM的偏见。LTF-TEST涵盖14个主题和10个受试者特征轴，包含11,948个样本，并评估模型响应及其背后的推理。此外，本文提出了FT-REGARD，一种通过将有偏提示与中性响应配对的微调方法来减轻偏见。

**Result:** 在对五种最新LLM（包括GPT-4o和LLaMa3）的评估中，发现了两种关键偏见模式：模型频繁偏向某些受试者特征群体，并对传统弱势群体过度敏感。FT-REGARD方法将性别偏见降低了34.6%，并在BBQ基准测试中将性能提高了1.4个百分点。

**Conclusion:** 大型语言模型在长文本生成中仍然存在显著偏见，且现有评估方法不足。本文提出的LTF-TEST框架有效揭示了这些偏见，而FT-REGARD微调方法则为减轻长文本生成任务中的偏见提供了一个有前景的解决方案。

> **ai_Abstract:** 本文针对现有大型语言模型（LLM）公平性基准无法有效评估长文本生成中偏见的问题，提出了LTF-TEST框架。该框架通过散文式提示和对模型响应及推理的评估，揭示了LLM在长文本中存在的细微偏见，包括对特定受试者特征群体的偏好以及对弱势群体的过度敏感。为缓解这些偏见，文章还提出了一种名为FT-REGARD的微调方法，该方法通过配对有偏提示和中性响应，显著降低了性别偏见并提升了性能。

> **摘要翻译:** 现有的大型语言模型（LLM）公平性基准主要集中在简单任务，例如多项选择题，忽视了在长文本生成等更复杂场景中可能出现的偏见。为了弥补这一空白，我们引入了长文本公平性测试（LTF-TEST），这是一个通过散文式提示评估LLM偏见的框架。LTF-TEST涵盖14个主题和10个受试者特征轴，包括性别和种族，共产生11,948个样本。通过评估模型响应及其背后的推理，LTF-TEST揭示了在简单响应中难以检测到的细微偏见。在我们对包括GPT-4o和LLaMa3在内的五种最新LLM的评估中，我们发现了两种关键的偏见模式。首先，这些模型在响应中频繁偏向某些受试者特征群体。其次，它们对传统弱势群体表现出过度敏感，经常提供过度保护的响应，而忽视了其他群体。为了减轻这些偏见，我们提出了FT-REGARD，这是一种将有偏提示与中性响应配对的微调方法。FT-REGARD将性别偏见降低了34.6%，并在BBQ基准测试中将性能提高了1.4个百分点，为解决长文本生成任务中的偏见提供了一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [865] [Efficient Knowledge Injection in LLMs via Self-Distillation](https://arxiv.org/abs/2412.14964)
> *通过自蒸馏在大型语言模型中高效注入知识*

*Kalle Kujanpää, Pekka Marttinen, Harri Valpola, Alexander Ilin* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 知识注入, 大型语言模型, 自蒸馏, 提示蒸馏, RAG

**Comment:** 

> **TL;DR:** 本文提出了一种基于自蒸馏的提示蒸馏方法，用于高效地将新知识注入大型语言模型，实验证明其优于传统的微调和检索增强生成（RAG）方法。

**AI_Comments:** 本文的创新之处在于将自蒸馏（特别是提示蒸馏）应用于知识注入任务，而非传统的风格对齐或指令调整。其重要性体现在无需外部教师模型或结构化知识即可实现高效的知识内化，并且在性能上超越了当前主流的微调和RAG方法，为LLM的知识更新和适应性提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 在许多实际应用中，大型语言模型（LLMs）需要获取预训练数据中不存在的新知识。目前有效利用这些知识的方法主要依赖于监督微调或检索增强生成（RAG）。尽管RAG已成为知识注入的行业标准，但微调尚未取得可比的成功。

**Method:** 本文提出利用提示蒸馏（一种主要用于风格对齐和指令调整的自蒸馏方法）从自由格式文档中内化新的事实知识。与现有方法不同，该方法既不需要更大的教师模型，也不需要结构化知识格式。

**Result:** 在多种LLM尺寸和模型家族中，提示蒸馏表现优于标准的监督微调，甚至可以超越RAG。论文还分析了提示蒸馏有效性的关键因素及其扩展性。

**Conclusion:** 提示蒸馏是一种高效且有效的知识注入方法，能够将新的事实知识内化到大型语言模型中，并超越了监督微调和RAG等现有方法。

> **ai_Abstract:** 本文介绍了一种通过提示蒸馏（一种基于自蒸馏的方法）在大型语言模型中高效注入新知识的策略。该方法能够从自由格式文档中学习事实知识，且无需大型教师模型或结构化数据。实验结果表明，该方法在不同规模的LLM上均优于监督微调，甚至超越了检索增强生成（RAG）的表现，为LLMs的知识更新提供了一条有效途径。

> **摘要翻译:** 在许多实际应用中，大型语言模型（LLMs）需要获取预训练数据中不存在的新知识。有效利用这些知识通常依赖于监督微调或检索增强生成（RAG）。尽管RAG已成为知识注入的行业标准，但微调尚未取得可比的成功。本文提出利用提示蒸馏，这是一种主要用于风格对齐和指令调整的基于自蒸馏的方法，来从自由格式文档中内化新的事实知识。与现有方法不同，我们的方法既不需要更大的教师模型，也不需要结构化知识格式。在多种LLM尺寸和模型家族中，我们展示了提示蒸馏优于标准的监督微调，甚至可以超越RAG。我们分析了促成提示蒸馏有效性的关键因素，并研究了其扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [870] [Which Questions Improve Learning the Most? Utility Estimation of Questions with LM-based Simulations](https://arxiv.org/abs/2502.17383)
> *哪些问题能最大程度地提高学习效果？基于语言模型模拟的问题效用估计*

*Dong-Ho Lee, Hyundong Cho, Jonathan May, Jay Pujara* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 问题效用, 语言模型, 学习模拟, 问题生成, 考试表现

**Comment:** 

> **TL;DR:** QUEST是一个使用语言模型模拟学习者并直接量化问题对考试成绩贡献的框架，旨在评估和生成高学习效用的问题。

**AI_Comments:** QUEST的创新之处在于其直接量化问题对学习成果（通过考试表现衡量）的效用，而非依赖间接指标。通过引入语言模型模拟学习者和构建专门的基准数据集，该框架为教育技术和自然语言处理领域提供了一个新颖且实用的问题评估与生成方法。其结果证明了直接衡量效用的优越性，为未来智能辅导系统和教育内容生成提供了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 提问是理解和学习的关键，但评估和生成好问题仍然是一个挑战。现有研究侧重于学习者生成的好奇驱动型问题，并使用间接指标（如显著性或信息增益）进行评估，这些指标不能直接反映问题对实际学习成果的影响。

**Method:** 本文提出了QUEST（Question Utility Estimation with Simulated Tests）框架，该框架使用语言模型模拟学习者，直接量化问题的效用——即其对考试表现的贡献。QUEST模拟学习者在学习教科书章节时提问并获得答案，然后利用这些信息参加章节末考试。通过这种模拟，每个问题的效用通过其对考试表现的直接影响来估计。为支持此评估，本文还整理了TEXTBOOK-EXAM基准数据集，该数据集将五个学科的教科书章节与章节末考试问题对齐。QUEST用于筛选高效用问题并通过拒绝采样微调问题生成器。

**Result:** 实验表明，由QUEST训练模型生成的问题使模拟测试分数比使用间接指标微调或利用提示方法的强基线提高了20%以上。此外，问题效用与显著性和与考试问题的相似性仅呈弱相关，表明它捕获了有益于下游性能的独特信号。

**Conclusion:** QUEST为问题评估和生成提供了一种新的以结果为导向的范式，超越了问题-答案内容，实现了学习成果的可衡量改进。

> **ai_Abstract:** 本文提出了一种名为QUEST（Question Utility Estimation with Simulated Tests）的新框架，旨在通过语言模型模拟学习者并直接量化问题对考试表现的贡献来评估和生成高质量问题。与以往依赖间接指标的方法不同，QUEST通过模拟学习过程和期末考试来直接估计问题效用。为支持该框架，研究者构建了TEXTBOOK-EXAM基准数据集。实验结果显示，经QUEST训练的问题生成模型能显著提高模拟测试分数（超过20%），并且问题效用与传统间接指标的相关性较低，表明QUEST捕获了独特的、对学习效果有益的信号。这为问题评估和生成提供了一种以学习成果为导向的新范式。

> **摘要翻译:** 好的问题对于理解和学习至关重要，但评估和生成此类问题仍然是一个挑战。先前关于探究性问题的工作侧重于学习者生成的好奇心驱动的查询，并使用间接指标（例如显著性或信息增益）对其进行评估，这些指标不能直接捕捉问题对实际学习成果的影响。我们引入了QUEST（Question Utility Estimation with Simulated Tests），这是一个使用语言模型模拟学习者并直接量化问题效用——即其对考试表现的贡献的框架。QUEST模拟了一个学习者在学习教科书章节时提问并接收答案，然后利用这些信息参加章节末考试。通过这种模拟，每个问题的效用通过其对考试表现的直接影响来估计，而不是通过底层内容间接推断。为了支持这种评估，我们整理了TEXTBOOK-EXAM，这是一个将五个学术学科的教科书章节与章节末考试问题对齐的基准。使用QUEST，我们筛选出高效用问题并通过拒绝采样微调问题生成器。实验表明，由QUEST训练的模型生成的问题比使用间接指标微调或利用提示方法的强基线将模拟测试分数提高了20%以上。此外，效用与显著性和与考试问题的相似性仅呈弱相关，这表明它捕获了有益于下游性能的独特信号。QUEST为问题评估和生成提供了一种新的以结果为导向的范式——一种超越问题-答案内容，实现学习成果可衡量改进的范式。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [875] [Language Model Uncertainty Quantification with Attention Chain](https://arxiv.org/abs/2503.19168)
> *基于注意力链的语言模型不确定性量化*

*Yinghao Li, Rushi Qiang, Lama Moukheiber, Chao Zhang* | **Category: cs.CL** | **Updated: 2025-08-07**

**Keywords:** 不确定性量化, 大型语言模型, 注意力链, 推理, 可靠性

**Comment:** 

> **TL;DR:** 该论文提出UQAC，一种利用“注意力链”有效量化大型语言模型不确定性的方法，尤其适用于涉及中间推理步骤的复杂任务，通过缩小推理空间来解决现有方法的局限性。

**AI_Comments:** UQAC通过解决复杂推理任务中的不确定性量化问题，解决了LLM可靠性的一个关键挑战，这在现有研究中常常被忽视。其“注意力链”机制是管理庞大推理空间的创新方法，使得不确定性量化变得可行且高效。这对于提升LLM的可信度具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 准确量化大型语言模型（LLM）的预测不确定性对于判断其答案的可靠性至关重要。然而，大多数现有研究侧重于封闭形式输出的简短、直接可回答的问题，而LLM响应中涉及中间推理步骤变得越来越重要。这种复杂性使得不确定性量化（UQ）变得复杂，因为答案令牌的概率取决于大量的先行推理令牌空间。直接边际化是不可行的，并且这种依赖性会夸大概率估计，导致UQ中的过度自信。

**Method:** 为解决现有问题，论文提出了UQAC，一种高效的方法，将推理空间缩小到可处理的大小以进行边际化。UQAC通过回溯过程迭代构建一个被认为对最终答案“语义关键”的令牌的“注意力链”。从答案令牌开始，它使用注意力权重识别最具影响力的前驱，然后重复此过程直到达到输入令牌。由此产生的链通过相似性过滤和概率阈值进一步细化，这减少了推理空间，从而促进了边际答案令牌概率的近似。

**Result:** UQAC在多个推理基准上，使用先进的开源LLM进行了验证，结果表明它始终能提供可靠的UQ估计，且计算效率高。

**Conclusion:** UQAC有效地解决了涉及推理步骤的LLM中不确定性量化的挑战，提供了可靠且高效的估计。

> **ai_Abstract:** 该论文介绍了一种名为UQAC的高效方法，用于量化大型语言模型（LLMs）的预测不确定性，尤其针对涉及中间推理步骤的复杂响应。针对现有方法在处理推理空间复杂性时面临的挑战，UQAC通过回溯过程构建一个包含对最终答案“语义关键”令牌的“注意力链”。该链经过精炼以缩小推理空间，从而能够近似边际答案令牌的概率。在推理基准上使用先进的开源LLM进行的实验验证表明，UQAC能够提供可靠且计算高效的不确定性估计。

> **摘要翻译:** 准确量化大型语言模型（LLM）的预测不确定性对于判断其答案的可靠性至关重要。虽然大多数现有研究侧重于短小、直接可回答的、封闭形式输出的问题（例如，多项选择），但LLM响应中涉及中间推理步骤变得越来越重要。这种增加的复杂性使得不确定性量化（UQ）变得复杂，因为答案令牌的概率取决于大量的先行推理令牌空间。直接边际化是不可行的，并且这种依赖性会夸大概率估计，导致UQ中的过度自信。为了解决这个问题，我们提出了UQAC，一种高效的方法，将推理空间缩小到可处理的大小以进行边际化。UQAC通过回溯过程迭代构建一个被认为对最终答案“语义关键”的令牌的“注意力链”。从答案令牌开始，它使用注意力权重识别最具影响力的前驱，然后重复此过程直到达到输入令牌。由此产生的链通过相似性过滤和概率阈值进一步细化，这减少了推理空间，从而促进了边际答案令牌概率的近似。我们在多个推理基准上，使用先进的开源LLM对UQAC进行了验证，结果表明它始终能提供可靠的UQ估计，且计算效率高。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='cscr'></a>
## cs.CR 

### [520] [On the Classical Hardness of the Semidirect Discrete Logarithm Problem in Finite Groups](https://arxiv.org/abs/2508.05048)
> *有限群中半直积离散对数问题的经典困难性研究*

*Mohammad Ferry Husnil Arif, Muhammad Imran* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 半直积离散对数问题, 经典困难性, 有限群, 后量子密码学, 离散对数问题

**Comment:** 

> **TL;DR:** 本文研究了有限群中半直积离散对数问题（SDLP）的经典困难性，发现其困难性高度依赖于底层群平台，并且不一定比标准离散对数问题（DLP）更难，特别是其非阿贝尔结构不保证更高的经典困难性。

**AI_Comments:** 本文对半直积离散对数问题（SDLP）的经典困难性进行了深入分析，纠正了之前对其作为后量子密码学基础的误解。其创新点在于将SDLP重新表述为广义DLP，并系统地分析了其在不同群平台上的表现。研究结果揭示了非阿贝尔结构并非天然带来更高困难性，这对于未来密码学困难问题的选择具有重要指导意义，提醒研究者需更加关注具体代数结构的细节而非泛泛的性质。

<details>
  <summary>Details</summary>

**Motivation:** 半直积离散对数问题（SDLP）曾被提议作为后量子密码协议的基础，因其非阿贝尔结构被认为能抵抗量子攻击。然而，最近的研究表明SDLP存在高效的量子算法，削弱了其量子抗性。因此，本文旨在探讨SDLP相对于标准离散对数问题（DLP）在经典对手面前是否具有计算优势。

**Method:** 本文研究了不同有限群平台上的SDLP经典困难性。将群案例SDLP重新表述为广义离散对数问题，从而能够适配经典算法来研究其复杂性。具体地，提出了Baby-Step Giant-Step算法在SDLP上的具体适配，并进行了理论分析和在SageMath中的实验验证。

**Result:** SDLP的Baby-Step Giant-Step算法适配实现了$O(\sqrt{r})$的时间和空间复杂度。研究表明，SDLP的经典困难性高度依赖于群平台，并且不均匀地超过标准DLP的困难性。在有限域$\mathbb{F}_p^*$中，两者复杂性相当。在椭圆曲线$E(\mathbb{F}_p)$中，由于有界自同构群，SDLP变得微不足道。在初等阿贝尔群$\mathbb{F}_p^n$中，SDLP可能比DLP更难，其复杂性取决于自同构的特征值结构。

**Conclusion:** 半直积的非阿贝尔结构不必然保证更高的经典困难性。这表明，为密码应用寻找经典困难问题需要更仔细地考虑底层的代数结构。

> **ai_Abstract:** 本文研究了半直积离散对数问题（SDLP）在不同有限群平台上的经典困难性，旨在评估其相对于标准离散对数问题（DLP）的计算优势。研究发现，SDLP的经典困难性高度依赖于底层群结构，并且其非阿贝尔特性不必然导致更高的经典困难性。具体来说，SDLP在有限域中与DLP复杂性相当，在椭圆曲线中变得容易，而在初等阿贝尔群中可能更难，这取决于自同构的特征值结构。研究强调，在为密码学寻找困难问题时，需要更深入地考虑代数结构。

> **摘要翻译:** 有限群中的半直积离散对数问题（SDLP）曾被提议作为后量子密码协议的基础，基于其非阿贝尔结构能够抵抗量子攻击的信念。然而，最近的结果表明，有限群中的SDLP存在高效的量子算法，从而削弱了其量子抗性。这引出了一个基本问题：SDLP在经典对手面前是否比标准离散对数问题（DLP）提供任何计算优势？在这项工作中，我们研究了SDLP在不同有限群平台上的经典困难性。我们确定了群案例SDLP可以被重新表述为广义离散对数问题，从而能够适配经典算法来研究其复杂性。我们提出了Baby-Step Giant-Step算法在SDLP上的具体适配，实现了$O(\sqrt{r})$的时间和空间复杂度，其中$r$是底层循环结构的周期。通过理论分析和在SageMath中的实验验证，我们证明了SDLP的经典困难性高度依赖于平台，并且不均匀地超过标准DLP的困难性。在有限域$\mathbb{F}_p^*$中，这两个问题表现出可比的复杂性。令人惊讶的是，在椭圆曲线$E(\mathbb{F}_p)$中，由于有界自同构群，SDLP变得微不足道，而在初等阿贝尔群$\mathbb{F}_p^n$中，SDLP可能比DLP更难，其复杂性根据自同构的特征值结构而变化。我们的发现表明，半直积的非阿贝尔结构并不固有地保证增加的经典困难性，这表明为密码应用寻找经典困难问题需要更仔细地考虑底层的代数结构。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [523] [An Overview of 7726 User Reports: Uncovering SMS Scams and Scammer Strategies](https://arxiv.org/abs/2508.05276)
> *7726份用户报告概述：揭示短信诈骗和诈骗者策略*

*Sharad Agarwal, Guillermo Suarez-Tangil, Marie Vasek* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 短信诈骗, 用户报告, 诈骗策略, 垃圾短信, 移动安全

**Comment:** 

> **TL;DR:** 本研究分析了135万份用户提交的报告，揭示了短信诈骗的策略、类型（如“错号”诈骗）以及诈骗者滥用的基础设施，并首次区分了垃圾短信和诈骗短信。

**AI_Comments:** 这项研究的创新之处在于首次利用大规模用户报告来分析绕过传统防火墙的短信诈骗，并明确区分了垃圾短信与诈骗短信。其重要性在于揭示了诈骗者规避检测的策略、常用的诈骗类型以及滥用的基础设施，为移动网络运营商和安全机构提供了打击短信诈骗的实用见解和数据支持。通过对诈骗消息文本的分析，也为用户识别诈骗提供了参考。

<details>
  <summary>Details</summary>

**Motivation:** 尽管移动网络运营商部署了防火墙来阻止非法消息，但诈骗者总能找到规避检测的方法。以往的研究主要关注被防火墙拦截的短信，而对于那些绕过防火墙并成功发送到用户手中的短信，人们知之甚少。

**Method:** 本研究与一家大型移动网络运营商合作，收集了四个月内提交的135万份用户报告。研究团队开发了一个方法框架，用于识别和分类报告中的短信。他们将识别出的诈骗短信分为12种类型，并分析了诈骗者滥用的基础设施服务以及诈骗消息的文本内容。

**Result:** 在用户报告中，89.16%是短信报告。通过研究方法，35.12%的独立短信被识别为垃圾短信，而40.27%被识别为诈骗短信。研究将诈骗短信分为12种类型，其中“错号”诈骗最为常见。此外，研究揭示了诈骗者滥用的基础设施服务（包括移动网络运营商和托管基础设施），并分析了诈骗消息如何诱骗受害者提供个人或财务信息。

**Conclusion:** 本论文首次调查了用户提交的短信报告，并区分了垃圾短信和诈骗短信。研究成功识别并分类了多种短信诈骗类型，揭示了诈骗者策略和滥用的基础设施，为理解和打击短信诈骗提供了宝贵见解。

> **ai_Abstract:** 本研究首次基于135万份用户提交的报告，深入分析了绕过移动网络防火墙并成功抵达用户的短信诈骗。论文详细区分了垃圾短信和诈骗短信，识别出多种诈骗类型（如“错号”诈骗），并揭示了诈骗者滥用的基础设施服务和其诱骗受害者的策略。研究结果为理解和打击日益复杂的短信诈骗提供了全面的视角。

> **摘要翻译:** 移动网络运营商部署防火墙来阻止非法消息，但诈骗者总能找到规避检测的方法。以往的研究主要关注被这些防火墙拦截的短信。然而，对于那些绕过防火墙并成功发送到用户手中的短信，人们知之甚少。为此，我们与一家主要移动网络运营商合作，接收了四个月内提交的135万份用户报告。我们发现89.16%的用户报告是短信，其次是可疑电话和URL的报告。使用我们的方法框架，我们识别出用户报告的独立短信中，35.12%是垃圾短信，而40.27%是诈骗短信。这是第一篇调查用户提交的短信报告并区分垃圾短信和诈骗短信的论文。我们的论文将识别出的诈骗短信分为12种诈骗类型，其中最常见的是“错号”诈骗。我们探讨了诈骗者滥用各种基础设施服务来实施短信诈骗，包括移动网络运营商和托管基础设施，并分析了诈骗消息的文本内容，以了解诈骗者如何诱骗受害者提供个人或财务详细信息。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [529] [ShikkhaChain: A Blockchain-Powered Academic Credential Verification System for Bangladesh](https://arxiv.org/abs/2508.05334)
> *ShikkhaChain：一个基于区块链的孟加拉国学术证书验证系统*

*Ahsan Farabi, Israt Khandaker, Nusrat Jahan, Ibrahim Khalil Shanto* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 区块链, 学术证书, 验证系统, 以太坊, 孟加拉国

**Comment:** 

> **TL;DR:** ShikkhaChain是一个基于区块链的系统，用于在孟加拉国安全、高效地验证学术证书，旨在解决证书欺诈问题。

**AI_Comments:** 该论文提出了一种利用区块链技术解决发展中国家学术证书欺诈问题的创新方案。通过以太坊智能合约和IPFS结合，实现了证书的去中心化、防篡改管理，有效提升了验证效率和信任度。其原型验证结果显示了在孟加拉国应用的可行性和积极影响，对于提升当地教育和就业生态系统的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 学术证书欺诈威胁着教育的完整性，尤其是在孟加拉国等发展中国家，那里的验证方法主要是人工且效率低下。

**Method:** 本文提出了ShikkhaChain平台，一个基于区块链的证书管理系统，旨在安全地颁发、验证和撤销学术证书。该系统构建于以太坊智能合约，并利用IPFS进行链下存储。它通过基于React的DApp与MetaMask集成提供访问，并支持政府、监管机构、机构和公共验证者的基于角色的访问，允许基于QR码的验证和链上撤销跟踪。

**Result:** ShikkhaChain的原型展示了增强的信任、减少的验证时间以及提高孟加拉国学历的国际信誉。

**Conclusion:** ShikkhaChain促进了一个更可靠的学术和就业生态系统。

> **ai_Abstract:** 本文提出了ShikkhaChain，一个基于区块链的学术证书验证系统，旨在解决孟加拉国因人工验证效率低下导致的证书欺诈问题。该系统利用以太坊智能合约和IPFS存储，通过DApp提供去中心化、防篡改的证书颁发、验证和撤销功能。原型验证表明，ShikkhaChain能有效提升信任、缩短验证时间并增强学历国际认可度，有助于构建更可靠的学术和就业环境。

> **摘要翻译:** 学术证书欺诈威胁着教育的完整性，尤其是在孟加拉国这样的发展中国家，那里的验证方法主要是人工且效率低下。为了解决这一挑战，我们提出了ShikkhaChain，一个由区块链驱动的证书管理平台，旨在以去中心化和防篡改的方式安全地颁发、验证和撤销学术证书。该平台建立在以太坊智能合约之上，并利用IPFS进行链下存储，通过基于React的DApp与MetaMask集成，提供了一个透明、可扩展的解决方案。ShikkhaChain为政府、监管机构、机构和公共验证者提供了基于角色的访问权限，允许基于二维码的验证和链上撤销跟踪。我们的原型展示了增强的信任、减少的验证时间以及提高孟加拉国学历的国际信誉，从而促进了一个更可靠的学术和就业生态系统。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [535] [Grouped k-threshold random grid-based visual cryptography scheme](https://arxiv.org/abs/2508.05394)
> *分组k阈值随机网格视觉密码方案*

*Xiaoli Zhuo, Xuehu Yan, Wei Yan* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 视觉密码, 随机网格, 对比度优化, k阈值, 秘密共享

**Comment:** 

> **TL;DR:** 提出了一种新的分组k阈值随机网格视觉密码方案，通过引入n'分组范式并优化对比度，实现了现有文献中最高的对比度。

**AI_Comments:** 该论文的创新点在于提出了“n'分组”这一新的RGVCS共享范式，并据此构建了对比度更高的方案。通过优化对比度这一核心指标，该研究对提高秘密图像共享的视觉质量具有重要意义。其贡献在于通过理论创新和实验验证，实现了RGVCS领域对比度的新突破。

<details>
  <summary>Details</summary>

**Motivation:** 现有(k,n)随机网格视觉密码方案(RGVCS)未能达到对比度的理论上限，导致恢复图像的视觉质量不佳，因此迫切需要更高对比度的构造。

**Method:** 提出了一种新的RGVCS共享范式，称为“n'分组(k,n) RGVCS”，它可以从任意(k,n')阈值方案构建(k,n)阈值方案。该范式建立了分层对比度特性，并引入了新的对比度计算公式。通过设置n'=k，提出了一种对比度增强的(k,n) RGVCS。

**Result:** 该方案在对比度方面实现了现有文献中最高的对比度值，并且理论分析和实验结果都证明了其优越性。

**Conclusion:** 通过引入n'分组范式并优化对比度，成功构建了一种对比度增强的(k,n)随机网格视觉密码方案，达到了现有文献中的最高对比度，显著提高了恢复图像的视觉质量。

> **ai_Abstract:** 本文提出了一种新颖的“n'分组(k,n)随机网格视觉密码方案(RGVCS)”，旨在解决现有RGVCS对比度未达理论上限的问题。该方案引入了新的共享范式和对比度计算公式，通过设置n'=k，实现了现有文献中最高的对比度。理论分析和实验结果均验证了其在对比度方面的优越性，显著提升了恢复图像的视觉质量。

> **摘要翻译:** 视觉密码方案(VCS)属于一种秘密图像共享方案，它不需要解密方面的密码学知识，而是直接依赖于人类视觉系统。在VCS中，基于随机网格的VCS(RGVCS)因避免像素扩展且无需设计基本矩阵而受到广泛关注。对比度作为RGVCS的核心指标，直接决定了恢复图像的视觉质量，因此其优化是一个关键的研究目标。然而，现有的(k,n)RGVCS仍未能达到对比度的理论上限，这凸显了对更高对比度构造的迫切需求。在本文中，我们提出了一种新颖的RGVCS共享范式，它从任意(k,n')阈值方案(k ≤ n'≤ n)构建(k,n)阈值方案，称为“n'分组(k,n) RGVCS”。这种范式建立了分层对比度特性：同一组内的参与者实现最佳恢复质量，而组间恢复则显示出分层对比度。我们进一步引入了适用于新范式的新对比度计算公式。然后，我们通过设置n'=k，提出了一种对比度增强的(k,n) RGVCS，实现了现有文献中最高的对比度值。理论分析和实验结果证明了我们提出的方案在对比度方面的优越性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [541] [Local Distance Query with Differential Privacy](https://arxiv.org/abs/2508.05518)
> *差分隐私下的局部距离查询*

*Weihong Sheng, Jiajun Chen, Bin Cai, Chunqiang Hu, Meng Han, Jiguo Yu* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 局部差分隐私, 距离查询, 图分析, 隐私保护, 合成图

**Comment:** 

> **TL;DR:** 本文提出了两种在局部差分隐私（LDP）下进行距离查询的方法，旨在解决缺乏可信策展人时的问题，其中第二种方法通过聚合局部距离向量来捕获全局图结构，提高了效用。

**AI_Comments:** 本文关注LDP下距离查询这一重要且具挑战性的问题，创新性地提出了通过聚合局部距离向量来捕获全局图结构的方法，这是LDP在距离查询领域的一个重要进展。相较于传统的依赖可信策展人的DP方法，LDP更符合现实场景需求。该研究的贡献在于为LDP下的图分析提供了新的视角和实用方法，特别是第二种方法在效用方面的提升具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在图分析中，距离是一个关键因素，通常通过策展人差分隐私（curator DP）来处理，即由一个可信的策展人持有完整的邻居列表并私密地回答查询。然而，在许多现实世界场景中，可能不存在这样的策展人，这给在局部差分隐私（LDP）下实现差分隐私距离查询带来了重大挑战。

**Method:** 本文提出了两种方法来解决LDP下的距离查询挑战。第一种方法通过随机化响应生成合成图，并应用按位操作来减少噪声干扰，但其效用较低。第二种方法是第一个专门为距离查询设计的LDP方法，它通过不断聚合来自邻近顶点的局部距离向量来捕获全局图结构，从而实现全局距离的准确更新。

**Result:** 通过全面的理论分析和在真实世界数据集上的实验评估，证明了所提出方法的有效性。

**Conclusion:** 本文提出了两种在缺乏可信策展人时进行局部差分隐私下距离查询的方法，特别是第二种方法通过聚合局部距离向量成功捕获了全局图结构，实现了全局距离的准确更新，并在理论和实验上证明了其有效性。

> **ai_Abstract:** 本文针对在缺乏可信策展人情况下，局部差分隐私（LDP）下进行距离查询的挑战，提出了两种解决方案。第一种方法通过生成合成图并利用按位操作降噪，但存在效用低的局限性。为克服此问题，研究者提出了第二种创新方法，即首个专为距离查询设计的LDP方案，该方法通过持续聚合邻近顶点的局部距离向量来捕获并准确更新全局图结构。实验和理论分析验证了该方法的有效性。

> **摘要翻译:** 差分隐私（DP）常用于保护图分析或发布。距离作为图分析中的一个关键因素，通常使用策展人差分隐私（curator DP）来处理，即由一个可信的策展人持有所有顶点的完整邻居列表并私密地回答查询。然而，在许多现实世界场景中，可能不存在这样的策展人，这给在局部差分隐私（LDP）下实现差分隐私距离查询带来了重大挑战。本文提出了两种方法来解决这一挑战。第一种方法通过随机化响应生成合成图，并应用按位操作来减少噪声干扰。然而，像其他合成图方法一样，这种方法存在效用低的问题。为了克服这一限制，我们提出了第二种方法，这是第一个专门为距离查询设计的LDP方法，它通过不断聚合来自邻近顶点的局部距离向量来捕获全局图结构。这个过程能够准确更新全局距离。我们通过全面的理论分析和在真实世界数据集上的实验评估证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [549] [PRvL: Quantifying the Capabilities and Risks of Large Language Models for PII Redaction](https://arxiv.org/abs/2508.05545)
> *PRvL：量化大型语言模型在个人身份信息（PII）修订方面的能力和风险*

*Leon Garza, Anantaa Kotal, Aritran Piplai, Lavanya Elluri, Prajit Das, Aman Chadha* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** PII Redaction, Large Language Models, Data Privacy, LLM Evaluation, Open-source Tools

**Comment:** 

> **TL;DR:** 本文对大型语言模型（LLMs）作为个人身份信息（PII）修订系统的能力和风险进行了全面分析，并发布了开源工具PRvL，以提供准确、高效且注重隐私的解决方案。

**AI_Comments:** 本文的创新之处在于首次对大型语言模型在PII修订中的能力和风险进行了全面量化分析，特别关注了架构和训练选择的影响。它不仅提供了实用的配置指导，还通过发布开源工具PRvL，极大地促进了LLM在隐私保护领域的实际应用和可复现性。PRvL的自管理部署特性解决了企业对数据隐私和安全的担忧，使其在合规性要求高的领域具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 从非结构化文本中修订个人身份信息（PII）对于在受监管领域确保数据隐私至关重要。虽然早期方法依赖于基于规则的系统和特定领域的命名实体识别（NER）模型，但这些方法无法在不同格式和上下文中泛化。大型语言模型（LLMs）提供了有前景的替代方案，然而，其架构和训练选择对修订性能的影响尚未得到充分探索。

**Method:** 作者对大型语言模型（LLMs）作为隐私保护的个人身份信息（PII）修订系统进行了全面分析。他们评估了一系列LLM架构和训练策略在PII修订中的有效性，并测量了修订性能、语义保留和PII泄露，同时比较了这些结果与延迟和计算成本。此外，他们发布了PRvL，一个开源的微调模型和评估工具套件，用于通用PII修订。

**Result:** 研究结果为配置准确、高效且注重隐私的基于LLM的修订器提供了实用指导。作者还发布了PRvL，一个开源的微调模型和评估工具套件，支持可定制性、多种推理设置，并可在安全、自管理环境中运行，无需依赖第三方服务。

**Conclusion:** 通过对LLMs在PII修订方面的全面分析，本文提供了关于如何配置高效、准确且隐私保护的LLM修订器的实用指导。PRvL的发布进一步支持了在安全、自管理环境中实现通用PII修订，增强了数据隐私。

> **ai_Abstract:** 本文针对现有PII修订方法泛化能力不足的问题，全面分析了大型语言模型（LLMs）在个人身份信息（PII）修订方面的能力和风险。研究评估了不同LLM架构和训练策略对修订性能、语义保留和PII泄露的影响，并考虑了延迟和计算成本。研究结果为构建准确、高效且注重隐私的LLM修订器提供了实用指导。为支持实际应用，作者还发布了开源工具PRvL，一个基于开源LLMs构建的微调模型和评估工具套件，支持定制化和安全自管理部署，从而实现无需第三方服务的PII修订。

> **摘要翻译:** 从非结构化文本中修订个人身份信息（PII）对于在受监管领域确保数据隐私至关重要。虽然早期方法依赖于基于规则的系统和特定领域的命名实体识别（NER）模型，但这些方法无法在不同格式和上下文中泛化。大型语言模型（LLMs）的最新进展提供了一种有前景的替代方案，然而，架构和训练选择对修订性能的影响仍未得到充分探索。LLMs在需要上下文语言理解的任务中表现出强大的性能，包括自由格式文本中的PII修订。先前的研究表明，通过适当的适应，LLMs可以成为有效的上下文隐私学习器。然而，架构和训练选择对PII修订的影响仍未得到充分探索。在这项工作中，我们对LLMs作为隐私保护的PII修订系统进行了全面分析。我们评估了一系列LLM架构和训练策略在PII修订中的有效性。我们的分析测量了修订性能、语义保留和PII泄露，并将这些结果与延迟和计算成本进行了比较。结果为配置准确、高效且注重隐私的基于LLM的修订器提供了实用指导。为了支持可复现性和实际部署，我们发布了PRvL，一个用于通用PII修订的开源微调模型和评估工具套件。PRvL完全基于开源LLMs构建，并支持多种推理设置，以实现灵活性和合规性。它旨在轻松定制以适应不同领域，并完全在安全、自管理的环境中运行。这使得数据所有者无需依赖第三方服务或将其敏感内容暴露在其自身基础设施之外即可执行修订。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [553] [Q-DPTS: Quantum Differentially Private Time Series Forecasting via Variational Quantum Circuits](https://arxiv.org/abs/2508.05036)
> *Q-DPTS: 基于变分量子电路的量子差分隐私时间序列预测*

*Chi-Sheng Chen, Samuel Yen-Chi Chen* | **Category: cs.CR, cs.LG, eess.SP, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子差分隐私, 时间序列预测, 变分量子电路, 隐私-效用权衡, 混合量子-经典框架

**Comment:** 

> **TL;DR:** Q-DPTS是一种混合量子-经典框架，用于实现量子差分隐私时间序列预测。它结合了变分量子电路和差分隐私机制，在保护数据隐私的同时，与现有基线相比，实现了更低的预测误差和更好的隐私-效用权衡。

**AI_Comments:** 本文的创新之处在于首次将量子增强技术应用于差分隐私时间序列预测领域，提出了一种混合量子-经典框架Q-DPTS。通过利用变分量子电路的表达能力，该方法有效缓解了传统差分隐私机制（如DP-SGD）在注入噪声时对模型性能的负面影响，实现了更好的隐私-效用权衡。这对于金融和能源等数据敏感领域的时间序列建模具有重要意义，为在保护用户隐私的同时保持高预测精度提供了有前途的方向。

<details>
  <summary>Details</summary>

**Motivation:** 时间序列预测在金融和能源系统等数据敏感领域至关重要。然而，现有的差分隐私（DP）技术，特别是通过DP-SGD集成时，由于注入噪声，往往会损害模型性能。因此，需要一种既能提供强大隐私保护又能保持模型性能的方法。

**Method:** 本文提出了Q-DPTS，一个用于量子差分隐私时间序列预测的混合量子-经典框架。Q-DPTS结合了变分量子电路（VQCs）与逐样本梯度裁剪和高斯噪声注入，以确保严格的$(\epsilon, \delta)$-差分隐私。量子模型的表达能力增强了对DP机制引起的效用损失的鲁棒性。

**Result:** Q-DPTS在ETT（电力变压器温度）数据集上进行了评估，并与LSTM、QASA、QRWKV和QLSTM等经典和量子基线进行了比较。结果表明，在相同的隐私预算下，Q-DPTS始终实现了更低的预测误差，表明其具有有利的隐私-效用权衡。

**Conclusion:** 这项工作首次探索了量子增强的差分隐私预测，为在隐私关键场景中实现安全准确的时间序列建模提供了有前景的方向。

> **ai_Abstract:** Q-DPTS是一个新颖的混合量子-经典框架，专为量子差分隐私时间序列预测而设计。该方法通过结合变分量子电路（VQCs）与逐样本梯度裁剪和高斯噪声注入，旨在解决传统差分隐私在时间序列预测中可能导致的性能下降问题。在ETT数据集上的实验结果表明，Q-DPTS在保持严格隐私保护的同时，能够实现比现有经典和量子基线更低的预测误差，展现了其在隐私与效用之间的优越权衡，为隐私敏感领域的时间序列建模提供了新的途径。

> **摘要翻译:** 时间序列预测在金融和能源系统等数据敏感领域至关重要。虽然差分隐私（DP）为保护个人数据贡献提供了理论保证，但其集成，特别是通过DP-SGD时，由于注入噪声，往往会损害模型性能。在本文中，我们提出了Q-DPTS，一个用于量子差分隐私时间序列预测的混合量子-经典框架。Q-DPTS结合了变分量子电路（VQCs）与逐样本梯度裁剪和高斯噪声注入，确保了严格的$(\epsilon, \delta)$-差分隐私。量子模型的表达能力增强了对DP机制引起的效用损失的鲁棒性。我们在ETT（电力变压器温度）数据集上评估了Q-DPTS，这是一个用于长期时间序列预测的标准基准。我们的方法与包括LSTM、QASA、QRWKV和QLSTM在内的经典和量子基线进行了比较。结果表明，Q-DPTS在相同的隐私预算下始终实现了更低的预测误差，表明其具有有利的隐私-效用权衡。这项工作首次探索了量子增强的差分隐私预测，为在隐私关键场景中实现安全准确的时间序列建模提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [559] [Necessity of Block Designs for Optimal Locally Private Distribution Estimation](https://arxiv.org/abs/2508.05110)
> *块设计在最优局部隐私分布估计中的必要性*

*Abigail Gentle* | **Category: cs.CR, cs.DS, cs.IT** | **Updated: 2025-08-07**

**Keywords:** 局部差分隐私, 分布估计, 块设计, 最优误差, 对称平衡不完全块设计

**Comment:** 

> **TL;DR:** 本文证明了在局部隐私分布估计中，任何实现最优误差的协议都必须基于平衡不完全块设计。

**AI_Comments:** 这项工作在局部差分隐私领域的分布估计问题上提供了一个基础性的理论结果，解决了长期存在的开放问题，即最优协议是否必须依赖于块设计。其证明了块设计的必要性，为未来设计高效且隐私保护的协议提供了明确的方向和理论依据，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 虽然已有研究表明基于平衡不完全块设计的协议可以在局部差分隐私模型下实现最优的分布估计误差，但此前仍不清楚是否存在其他构造也能达到最优性能。

**Method:** 通过数学证明，本文解决了这一问题。

**Result:** 1. 任何实现最优误差的协议都必须对应某种平衡不完全块设计。2. 这一结果结合现有工作，完全刻画了该问题的最优协议集合。3. 实现最优误差和最优通信的协议仅限于基于对称平衡不完全块设计的协议。

**Conclusion:** 本文证明了平衡不完全块设计对于实现最优局部隐私分布估计误差是必需的，并且对称平衡不完全块设计对于同时实现最优误差和最优通信是必需的，从而完全刻画了最优协议的集合。

> **ai_Abstract:** 本文研究了局部差分隐私模型下最优分布估计协议的构造问题。在已有研究表明平衡不完全块设计能够实现最优误差的基础上，本文进一步证明了任何实现最优误差的协议都必须是平衡不完全块设计。这一发现与现有工作结合，完整地界定了最优协议的集合。此外，论文还指出，同时实现最优误差和最优通信的协议仅限于对称平衡不完全块设计。

> **摘要翻译:** 局部差分隐私是数据离开设备前保护隐私的黄金标准，并且该模型下的分布估计已被深入研究。最近，基于平衡不完全块设计（BIBD）的协议被证明可以实现该问题的最优误差。然而，其他构造是否也能达到最优仍是未知。我们通过证明任何实现最优误差的协议都必须对应某种平衡不完全块设计来解决这个问题。这一结果结合先前的工作，完全刻画了该问题的最优协议集合。因此，能够实现最优误差和最优通信的协议仅限于基于对称平衡不完全块设计的协议。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [565] [Secure and practical Quantum Digital Signatures](https://arxiv.org/abs/2508.05355)
> *安全实用的量子数字签名*

*Federico Grasselli, Gaetano Russo, Massimiliano Proietti* | **Category: cs.CR, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子数字签名, 信息论安全, 协议优化, 量子密码学, 数字签名

**Comment:** 

> **TL;DR:** 本文分析并改进了三种现有的量子数字签名协议，证明了它们的理论安全性，并优化了其效率。

**AI_Comments:** 这项工作在确保数字签名在量子时代的安全方面具有重要意义。通过分析、修正现有协议并进行效率优化，它为量子数字签名的实际应用铺平了道路，特别是考虑到信息论安全认证通信的潜在失败，这增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 数字签名是重要的密码资产，需抵御量子攻击。量子数字签名（QDS）能提供信息论安全的解决方案，免疫量子攻击。

**Method:** 分析了三种基于预共享密钥（通过量子密钥分发建立）和通用哈希族的现有实用QDS协议。对每个协议进行修正以弥补潜在漏洞，并在考虑信息论安全认证通信失败的情况下证明其信息论安全性。随后，数值优化协议参数以提高预共享比特消耗和签名长度的效率。

**Result:** 成功修正了现有QDS协议的漏洞，证明了其信息论安全性，并识别出最有效的协议。

**Conclusion:** 通过修正和优化，实现了安全且高效的量子数字签名协议，为抵御量子攻击提供了实用解决方案。

> **ai_Abstract:** 本文研究了量子数字签名（QDS），一种能抵抗量子攻击的信息论安全解决方案。作者分析了三种现有的实用QDS协议，对其进行了修正以修复漏洞并证明了其信息论安全性，同时考虑了认证通信的失败。此外，研究还通过数值优化协议参数，提高了预共享比特消耗和签名长度的效率，最终确定了最有效的协议。

> **摘要翻译:** 数字签名是必须抵御量子对手攻击的关键密码资产。量子数字签名（QDS）可以提供信息论（IT）安全的解决方案，从而免疫量子攻击。在这项工作中，我们分析了三种基于预共享安全密钥（例如，通过量子密钥分发建立）和通用哈希族的现有实用QDS协议。对于每个协议，我们进行了修改以弥补潜在漏洞，并在考虑信息论安全认证通信失败的情况下证明了它们的信息论安全性。然后，我们对协议参数进行数值优化，以提高预共享比特消耗和签名长度方面的效率，从而使我们能够识别出最有效的协议。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [571] [Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)](https://arxiv.org/abs/2508.05591)
> *使用Kolmogorov-Arnold网络（KANs）优化物联网威胁检测*

*Natalia Emelianova, Carlos Kamienski, Ronaldo C. Prati* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 物联网安全, 入侵检测, Kolmogorov-Arnold网络, KANs, 可解释性AI

**Comment:** 

> **TL;DR:** 本研究探讨了使用KANs进行物联网入侵检测，发现其性能优于传统MLP，与SOTA模型相当，且具有更好的可解释性。

**AI_Comments:** 该研究的创新点在于将KANs应用于物联网入侵检测领域，并强调了其在性能和可解释性方面的优势。KANs的可学习激活函数特性使其在复杂网络安全场景下具有潜力，尤其是在需要模型透明度的应用中。

<details>
  <summary>Details</summary>

**Motivation:** 物联网的指数级增长导致了严重的安全问题，物联网网络已成为网络攻击的主要目标，因此需要更有效的入侵检测方法。

**Method:** 本研究探讨了Kolmogorov-Arnold网络（KANs）作为传统机器学习模型的替代方案，用于物联网网络中的入侵检测。KANs采用可学习的激活函数。

**Result:** KANs在物联网入侵检测中性能优于传统多层感知机（MLPs），与Random Forest和XGBoost等先进模型相比，达到了具有竞争力的准确性，同时提供了卓越的可解释性。

**Conclusion:** KANs是物联网入侵检测的有效且可解释的替代方案。

> **ai_Abstract:** 本文研究了Kolmogorov-Arnold网络（KANs）在物联网入侵检测中的应用，以应对物联网安全威胁。研究发现，KANs在性能上超越了传统MLP，并且在准确性上与Random Forest和XGBoost等先进模型相当，同时提供了更高的可解释性，为物联网威胁检测提供了一种优化的解决方案。

> **摘要翻译:** 物联网（IoT）的指数级增长导致了严重的安全问题，物联网网络已成为网络攻击的主要目标。本研究探讨了Kolmogorov-Arnold网络（KANs）作为传统机器学习模型在物联网网络中入侵检测的替代方案的潜力。研究表明，采用可学习激活函数的KANs优于传统的MLP，并且与Random Forest和XGBoost等最先进的模型相比，实现了具有竞争力的准确性，同时为物联网网络中的入侵检测提供了卓越的可解释性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [577] [Non-omniscient backdoor injection with a single poison sample: Proving the one-poison hypothesis for linear regression and linear classification](https://arxiv.org/abs/2508.05600)
> *非全知后门注入与单个投毒样本：证明线性回归和线性分类的“一毒假设”*

*Thorsten Peinemann, Paula Arnold, Sebastian Berndt, Thomas Eisenbarth, Esfandiar Mohammadi* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 后门注入, 投毒攻击, 一毒假设, 线性回归, 线性分类

**Comment:** 

> **TL;DR:** 本文提出了“一毒假设”，证明了攻击者仅用一个投毒样本和有限背景知识，就能在不显著影响良性学习任务性能的情况下，对线性回归和线性分类模型成功注入后门。

**AI_Comments:** 这项研究通过提出并证明“一毒假设”，极大地推进了对后门攻击样本效率的理解。其创新之处在于挑战了传统观念，证明了在特定条件下，即使是单个投毒样本也能有效实施攻击。这对于理解和防御数据投毒攻击具有重要意义，尤其是在数据来源不可信的场景中。该研究的局限性可能在于其证明主要针对线性模型，对于更复杂的非线性模型，该假设是否依然成立仍需进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型在从不可信来源收集的大数据上训练时面临后门注入攻击的威胁。现有工作已确定后门攻击的成功界限及其对良性学习任务的影响，但成功进行后门攻击所需投毒数据量仍是一个悬而未决的问题。典型的攻击要么需要少量样本但需大量数据信息，要么需要毒害许多数据点。

**Method:** 本文提出了“一毒假设”，并对其在线性回归和线性分类中的成立进行了证明。研究表明，对于利用良性数据分布未使用方向的投毒样本，所得模型功能上等同于未包含投毒样本的模型。此外，基于统计后门学习的现有工作，证明了在所有其他情况下对良性学习任务的影响仍然有限。理论结果通过现实基准数据集进行了实验验证。

**Result:** 本文成功证明了“一毒假设”：攻击者仅用一个投毒样本和有限背景知识，就能以零后门错误注入后门，且不显著影响良性学习任务性能。对于利用良性数据分布未使用的方向进行投毒的情况，模型功能等效于未包含投毒样本的模型。在所有其他情况下，对良性学习任务的影响仍然有限。理论结果通过实验得到了验证。

**Conclusion:** 本文解决了后门攻击所需投毒量的问题，成功证明了在特定条件下，仅需一个投毒样本即可对线性模型进行有效的后门注入，且对模型的良性性能影响有限。

> **ai_Abstract:** 本文研究了机器学习模型中的后门注入攻击，旨在解决成功攻击所需投毒数据量的问题。作者提出了“一毒假设”，即攻击者仅需一个投毒样本和有限背景知识，即可在不对良性学习任务性能产生显著影响的情况下，成功注入零错误后门。该假设已在线性回归和线性分类中得到证明，并指出当投毒样本利用良性数据分布未使用的方向时，模型功能等同于未受攻击的模型。研究通过理论分析和实验验证了其发现。

> **摘要翻译:** 后门注入攻击是对在从不可信来源收集的大数据上训练的机器学习模型的一种威胁；这些攻击使攻击者能够将恶意行为注入到模型中，并通过特殊构造的输入触发。先前的研究已经确定了后门攻击成功的界限及其对良性学习任务的影响，然而，一个悬而未决的问题是成功进行后门攻击需要多少投毒数据。典型的攻击要么使用少量样本但需要大量关于数据点的信息，要么需要毒害许多数据点。
在本文中，我们提出了“一毒假设”：一个拥有一个投毒样本和有限背景知识的攻击者，可以注入一个零后门错误的后门，并且不会显著影响良性学习任务的性能。此外，我们证明了“一毒假设”对于线性回归和线性分类成立。对于利用良性数据分布未使用的方向进行投毒样本的攻击者，我们表明所得模型在功能上等同于一个在训练中排除了投毒样本的模型。我们基于统计后门学习的现有工作，表明在所有其他情况下，对良性学习任务的影响仍然有限。我们还通过现实基准数据集的实验验证了我们的理论结果。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [583] [Proof-of-Useful-Work Blockchain for Trustworthy Biomedical Hyperdimensional Computing](https://arxiv.org/abs/2202.02964)
> *用于可信生物医学超维度计算的有用工作量证明区块链*

*Jinghao Wen, Dongning Ma, Sizhe Zhang, Hasshi Sudler, Xun Jiao* | **Category: cs.CR, cs.NE** | **Updated: 2025-08-07**

**Keywords:** 有用工作量证明, 区块链, 超维度计算, 生物医学, 可信度

**Comment:** 

> **TL;DR:** HDCoin引入了一种有用工作量证明区块链框架，将传统区块链挖矿与生物医学超维度计算模型的开发相结合，以创建可信赖且可验证的模型。

**AI_Comments:** 该论文的创新之处在于将“有用工作”（训练HDC模型）整合到区块链挖矿过程中，同时解决了传统工作量证明的能源浪费问题以及生物医学等关键领域对可信赖AI模型的需求。这种方法有望显著提高AI驱动生物医学解决方案的实际适用性和信任度。

<details>
  <summary>Details</summary>

**Motivation:** 超维度计算（HDC）在生物医学领域具有广阔前景，但其学习模型的可信度（如可复现性和可验证性）至关重要。传统的区块链挖矿过程存在能源浪费问题。

**Method:** 引入了HDCoin，这是首个用于HDC的有用工作量证明（PoUW）区块链框架。该框架将传统的能源浪费型挖矿过程转变为一个竞争性过程，用于开发高精度、可信且可验证的超维度模型。研究探索了四个不同的生物医学数据集，并对区块链矿工的关键HDC超参数（如维度、学习率和再训练迭代次数）进行了广泛的设计空间探索，以评估模型性能、自适应挖矿难度和PoUW的公平性。

**Result:** 开发了HDCoin框架，成功将能源浪费型挖矿转变为有益的超维度模型开发过程。通过对多个生物医学数据集和HDC超参数的探索，验证了其在模型性能、自适应挖矿难度和公平性方面的潜力。

**Conclusion:** HDCoin提供了一种新颖的有用工作量证明区块链方法，通过将HDC模型训练整合到挖矿过程中，解决了生物医学应用中对可信赖、可验证学习模型的需求，并提升了区块链的实用性。

> **ai_Abstract:** 本文介绍了HDCoin，一个创新的用于生物医学超维度计算（HDC）的有用工作量证明区块链框架。HDCoin旨在解决生物医学应用中对可信赖（可复现和可验证）学习模型的关键需求，通过将能源浪费的区块链挖矿过程转化为开发高精度HDC模型的竞争性任务。研究人员探索了其在多种生物医学数据集上的有效性，并研究了影响性能、挖矿难度和公平性的关键超参数。

> **摘要翻译:** 超维度计算（HDC）是一种有前景的生物启发式学习范式，因其在平衡性能和效率方面的优势而日益应用于生物医学领域。在生物医学应用中，训练出的学习模型的可信度，例如可复现性和可验证性，至关重要。在这项工作中，我们引入了HDCoin，这是首个用于HDC的有用工作量证明区块链框架。通过HDCoin，我们将传统的能源浪费型挖矿过程转变为一个用于开发高精度、可信且可验证的超维度模型的竞争过程。我们探索了四个不同的生物医学数据集，并对区块链矿工的关键HDC超参数（如维度、学习率和再训练迭代次数）进行了广泛的设计空间探索，以评估模型性能、自适应挖矿难度和有用工作量证明的公平性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [589] [Theorem-Carrying Transactions: Runtime Verification to Ensure Interface Specifications for Smart Contract Safety](https://arxiv.org/abs/2408.06478)
> *携带定理的交易：运行时验证以确保智能合约安全的接口规范*

*Thomas Ball, Nikolaj S. Bjørner, Ashley J. Chen, Shuo Chen, Yang Chen, Zhongxin Guo, Tzu-Han Hsu, Peng Liu, Nanqing Luo* | **Category: cs.CR, cs.PL** | **Updated: 2025-08-06**

**Keywords:** 智能合约安全, 运行时验证, 定理证明, 以太坊, 区块链

**Comment:** 

> **TL;DR:** 提出了一种名为“携带定理的交易（TCT）”的方法，通过在交易中附带证明其符合规范的定理，并在运行时验证，以确保智能合约的安全性，且开销极低。

**AI_Comments:** TCT的创新之处在于将定理证明与运行时验证结合，并将其嵌入到交易本身中，形成“定理携带交易”的概念。这种方法克服了传统静态分析在处理大规模、高多态性智能合约时的局限性，同时通过定理重用显著降低了运行时开销，使其在实际应用中具有可行性。其在DeFi场景的应用展示了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约中的安全漏洞和后门对以太坊社区造成了持续影响。由于以太坊合约的规模和复杂性，静态验证难以确保“巨型程序”符合高级安全规范。

**Method:** 提出“携带定理的交易（TCT）”技术，结合具体执行和符号证明。TCT协议要求每笔交易携带一个定理，证明其符合所调用合约的指定属性，运行时系统在执行前检查该定理。已证明的定理可重复使用，从而降低运行时开销。

**Result:** 成功应用于保护代币合约，无需预见代码级复杂性（如整数溢出和重入）。也成功应用于Uniswap代码库，展示了在复杂DeFi场景中的应用。评估显示运行时开销可忽略不计，比现有最先进的运行时检查方法低两个数量级。

**Conclusion:** TCT提供了一种有效且高效的方法，通过运行时验证和定理携带，确保智能合约在复杂且不可预测的环境中的安全性。

> **ai_Abstract:** 本文提出了一种名为“携带定理的交易（TCT）”的新方法，旨在解决智能合约中的安全问题。TCT通过在每笔交易中嵌入一个证明其符合合约安全规范的定理，并在运行时进行验证，从而在不依赖静态分析的情况下确保智能合约的安全性。该方法结合了具体执行和符号证明的优点，并能重用已验证的定理以最小化运行时开销。实验证明TCT能有效保护代币合约和复杂DeFi场景（如Uniswap），且运行时开销远低于现有方法。

> **摘要翻译:** 智能合约中的安全漏洞和后门自以太坊诞生以来一直影响着其社区。从概念上讲，以太坊的145万份合约形成了一个“巨型程序”，其行为由合约的复杂组合决定。尽管存在不可预见的代码级复杂性，程序员能否确保这个巨型程序符合高级安全规范？由于其规模和高度多态性，静态代码验证无法忠实于这个巨型程序。在本文中，我们提出了一种实现这一目标的有效方法。我们的技术，称为携带定理的交易（TCT），结合了具体执行和符号证明的优点。在TCT协议下，每笔交易都带有一个定理，证明其符合所调用合约中指定的属性，并且运行时系统在执行交易前检查该定理。一旦定理被证明，它将被重复用于未来的交易，因此TCT的运行时开销是最小的。作为案例研究，我们证明TCT在不预见代码级复杂性（如整数溢出和重入）的情况下保护了代币合约。TCT也成功应用于Uniswap代码库，展示了一个复杂的去中心化金融（DeFi）场景。我们的评估显示，运行时开销可忽略不计，比现有最先进的合约代码安全运行时检查方法低两个数量级。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [595] [Dimension Reduction via Random Projection for Privacy in Multi-Agent Systems](https://arxiv.org/abs/2412.04031)
> *多智能体系统中通过随机投影进行维度降低以保护隐私*

*Puspanjali Ghoshal, Ashok Singh Sairam* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 多智能体系统, 隐私保护, 维度降低, 随机投影, 效用-隐私权衡

**Comment:** 

> **TL;DR:** 本文提出了一种基于压缩的方法，利用鲁棒概念在多智能体系统中对共享数据进行隐私保护，同时管理效用-隐私权衡，并推导了实现最大隐私的压缩矩阵范数界限。

**AI_Comments:** 这项工作通过提出一种基于压缩的新颖方法，解决了多智能体系统中数据共享的关键隐私挑战。其创新之处在于将问题框架化为效用-隐私权衡，并利用鲁棒概念进行数据清洗，同时量化了实现隐私目标的压缩矩阵要求。这对于需要平衡数据效用和用户隐私的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在多智能体系统中，代理需要共享敏感数据（如位置）以提高效率，但这会导致隐私泄露风险（如推断用户日常活动），且数据清洗会导致效用损失。因此，需要在隐私和效用之间进行权衡。

**Method:** 将问题表述为效用-隐私权衡问题，并提出一种新颖的基于压缩的方法，利用鲁棒概念来清洗共享数据。此外，推导了确保最大隐私同时满足预定义效用约束所需的压缩矩阵范数的界限。

**Result:** 导出了确保最大隐私同时满足预定义效用约束所需的压缩矩阵范数的界限。

**Conclusion:** 本文通过提出一种基于压缩的方法来解决多智能体系统中的数据共享隐私风险，旨在实现效用与隐私之间的最佳权衡。

> **ai_Abstract:** 本文研究了多智能体系统中的数据共享隐私问题，指出直接共享敏感数据会导致隐私泄露，而数据清洗又会损失效用。为此，作者将该问题建模为效用-隐私权衡，并提出了一种创新的基于压缩的方法，利用鲁棒概念对共享数据进行清洗。研究还推导了在满足预定义效用约束下确保最大隐私所需的压缩矩阵范数界限。

> **摘要翻译:** 在多智能体系统（MAS）中，单个智能体观察环境的各个方面并将此信息传输给负责聚合数据和推断系统参数的中心实体。为了提高整体效率，智能体可能会将某些私人参数附加到其观察结果中。例如，在众包交通监控系统中，通勤者不仅可以分享他们当前的速度，还可以分享敏感信息，例如他们的位置，以实现更准确的路线预测。然而，共享此类数据可能允许中心实体或潜在的对手推断用户的私人详细信息，例如他们的日常活动。为了减轻这些隐私风险，智能体在传输前对数据进行清洗。这种清洗不可避免地导致效用损失。在这项工作中，我们将问题表述为效用-隐私权衡，并提出一种新颖的基于压缩的方法，利用鲁棒概念来清洗共享数据。我们进一步推导了确保最大隐私同时满足预定义效用约束所需的压缩矩阵范数的界限。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [601] [Position: Mind the Gap-the Growing Disconnect Between Established Vulnerability Disclosure and AI Security](https://arxiv.org/abs/2412.14855)
> *立场：关注差距——既有漏洞披露与人工智能安全之间日益扩大的脱节*

*Lukas Bieringer, Sean McGregor, Nicole Nichols, Kevin Paeth, Jochen Stängler, Andreas Wespi, Alexandre Alahi, Kathrin Grosse* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 人工智能安全, 漏洞披露, 事件报告, 人工智能代理, 网络安全

**Comment:** 

> **TL;DR:** 现有的漏洞披露方法因人工智能系统的根本性差异而不足以应对人工智能安全；需要新的专业方法，尤其随着人工智能代理的兴起。

**AI_Comments:** 这篇论文的重要性在于它明确指出了传统网络安全漏洞披露与新兴人工智能安全领域之间存在的关键差距。其创新之处在于明确阐述了为什么现有方法的适应性会失败，并提出了新的方向。它还强调了知识产权和所有权等复杂挑战，这些对于实际实施至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 人工智能系统面临日益增长的安全威胁，而现有共享的事件报告实践（无论是来自非人工智能网络安全还是非安全人工智能报告）都未能满足人工智能安全报告的特定要求。本论文旨在论证调整现有流程来适应人工智能安全报告注定会失败。

**Method:** 本论文作为一篇立场论文，主张现有流程在人工智能安全报告方面存在根本性缺陷，并提出了解决这些缺陷的建议。它讨论了一种人工智能安全报告的方法，并强调了人工智能代理将如何进一步强化对专业人工智能安全事件报告进展的需求。

**Result:** 论文指出，由于人工智能系统的独特特征，现有流程在人工智能安全报告方面存在根本性缺陷，因此调整这些流程注定会失败。它识别出了一些可立即解决的缺陷，以及一些在技术或社会系统中尚未解决的问题（如知识产权处理或漏洞所有权）。论文提出了解决这些缺陷的方法。

**Conclusion:** 现有的漏洞披露框架根本不适用于人工智能安全，因此需要一种专门的方法，人工智能代理的出现进一步强调了这一需求。

> **ai_Abstract:** 这篇立场论文指出，由于人工智能系统独特的特性，现有的漏洞披露和事件报告实践在应对人工智能安全方面存在根本性不足。论文强调了具体的缺陷，其中一些可以立即解决，另一些则更为复杂（例如知识产权和所有权问题）。论文提出了一种解决这些差距的方法，并强调人工智能代理的出现进一步加剧了对专业人工智能安全事件报告进展的需求。

> **摘要翻译:** 人工智能系统面临日益增多的安全威胁，这些威胁在实践中正被日益利用。因此，行业内正在出现共享的人工智能事件报告实践，作为最佳实践并受监管要求的强制执行。尽管非人工智能网络安全和非安全人工智能报告已作为工业和政策规范取得进展，但现有的实践集合未能满足人工智能安全报告的特定要求。**在这篇立场论文中，我们认为，由于人工智能系统独特特征带来的根本性缺陷，调整现有流程以适应人工智能安全报告注定会失败。其中一些缺陷可以立即解决，而另一些在技术上或社会系统中仍未解决，例如知识产权的处理或漏洞的所有权。**基于我们解决这些缺陷的提议，我们讨论了一种人工智能安全报告的方法，以及新的人工智能范式——人工智能代理——将如何进一步强化对专业人工智能安全事件报告进展的需求。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [607] [IRCopilot: Automated Incident Response with Large Language Models](https://arxiv.org/abs/2505.20945)
> *IRCopilot：基于大型语言模型的自动化事件响应*

*Xihuan Lin, Jie Zhang, Gelei Deng, Tianzhe Liu, Xiaolong Liu, Changcai Yang, Tianwei Zhang, Qing Guo, Riqing Chen* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 事件响应, 大型语言模型, 自动化, 网络安全, IRCopilot

**Comment:** 

> **TL;DR:** IRCopilot是一个基于大型语言模型的自动化事件响应框架，它通过模拟真实事件响应团队的工作流程，并利用协作式LLM组件和策略性责任划分，显著提高了事件响应的实用性和效率，在多项任务中超越了基线LLM。

**AI_Comments:** IRCopilot的创新之处在于其多LLM协作框架和明确的责任划分机制，这有效地缓解了大型语言模型在复杂任务中常见的上下文丢失和幻觉问题。通过模拟真实事件响应流程，该系统提高了自动化事件响应的实用性和效率，为网络安全领域LLM的应用提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 传统的威胁检测和事件响应方法在复杂网络环境中难以有效运作，而大型语言模型（LLMs）在早期威胁检测方面表现出潜力，但在入侵后的自动化事件响应方面能力有限。为了弥补这一空白，并解决现有LLMs在实际应用中面临的上下文丢失、幻觉、隐私保护和提供准确推荐能力有限等挑战，本文提出了IRCopilot。

**Method:** 本文构建了一个基于真实事件响应任务的增量基准来评估LLMs的性能。针对识别出的挑战，提出了IRCopilot框架。IRCopilot通过四个协作的基于LLM的会话组件模拟真实事件响应团队的三个动态阶段。这些组件通过明确的责任划分来减少幻觉和上下文丢失等问题，并利用多样化的提示设计和策略性责任划分来提高系统的实用性和效率。

**Result:** 实验结果表明，IRCopilot在关键基准测试中优于基线LLMs，在各种响应任务中的子任务完成率分别达到150%、138%、136%、119%和114%。此外，IRCopilot在公共事件响应平台和真实攻击场景中表现出强大的鲁棒性，展示了其强大的适用性。

**Conclusion:** IRCopilot框架通过其创新的多LLM协作机制，成功克服了当前大型语言模型在自动化事件响应中面临的挑战，显著提升了事件响应的效率和准确性，并在实际应用中展现出强大的潜力。

> **ai_Abstract:** 本文提出IRCopilot，一个基于大型语言模型的自动化事件响应框架，旨在解决现有LLM在网络安全事件响应中面临的挑战。研究首先构建了一个真实的事件响应任务基准来评估LLM的局限性，发现上下文丢失、幻觉和隐私是主要问题。为应对此，IRCopilot通过模拟真实事件响应团队的三个阶段，利用四个协作的LLM组件进行责任划分和多样化提示设计，显著提高了系统效率和实用性。实验证明，IRCopilot在多项响应任务中超越了基线LLM，并展现出强大的实际应用能力。

> **摘要翻译:** 事件响应在减轻网络攻击影响方面发挥着关键作用。近年来，全球网络威胁的强度和复杂性显著增长，使得传统的威胁检测和事件响应方法在复杂网络环境中难以有效运作。尽管大型语言模型（LLMs）在早期威胁检测方面表现出巨大潜力，但在入侵后的自动化事件响应方面其能力仍然有限。为了弥补这一空白，我们构建了一个基于真实事件响应任务的增量基准，以彻底评估LLMs在此领域的性能。我们的分析揭示了阻碍当代LLMs实际应用的几个关键挑战，包括上下文丢失、幻觉、隐私保护问题以及它们提供准确、特定于上下文的建议的能力有限。为了应对这些挑战，我们提出了IRCopilot，一个由LLMs驱动的自动化事件响应的新颖框架。IRCopilot利用四个协作的基于LLM的会话组件，模拟真实事件响应团队的三个动态阶段。这些组件在设计时具有明确的职责划分，从而减少了幻觉和上下文丢失等问题。我们的方法利用多样化的提示设计和策略性责任划分，显著提高了系统的实用性和效率。实验结果表明，IRCopilot在关键基准测试中优于基线LLMs，在各种响应任务中的子任务完成率分别达到150%、138%、136%、119%和114%。此外，IRCopilot在公共事件响应平台和真实攻击场景中表现出强大的性能，展示了其强大的适用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [613] [Navigating Cookie Consent Violations Across the Globe](https://arxiv.org/abs/2506.08996)
> *全球范围内的Cookie同意违规行为导航*

*Brian Tang, Duc Bui, Kang G. Shin* | **Category: cs.CR** | **Updated: 2025-08-06**

**Keywords:** Cookie同意, 隐私法, Cookie违规, ConsentChk, 地域差异

**Comment:** 

> **TL;DR:** 本文提出了ConsentChk系统，用于检测和分析全球范围内网站的Cookie同意违规行为，发现违规率和实现方式高度依赖于地区，且可能源于对区域隐私法的不正确理解。

**AI_Comments:** 本文创新性地提出了一个自动化系统ConsentChk来检测全球范围内的Cookie同意违规，并揭示了不同地区在Cookie同意实施和违规率上的显著差异。其重要性在于揭示了当前Cookie同意实践中普遍存在的问题，并强调了对区域隐私法理解和执行的重要性。该研究为监管机构和网站开发者提供了有价值的见解，以改善用户隐私保护。其局限性可能在于仅调查了英语国家/地区和特定数量的网站。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Cookie横幅的使用日益增多，但很少有措施能确保Cookie同意符合全球隐私法。先前的研究发现，即使用户明确拒绝，Cookie也常常被放置在浏览器中，这种不一致性规避了用户的同意偏好，构成了Cookie同意违规，这是一个重要的问题需要解决。

**Method:** 本文提出了一个端到端系统ConsentChk，用于检测和分析Cookie横幅行为。ConsentChk使用形式化模型系统地检测和分类Cookie同意违规。研究调查了全球八个英语国家/地区，并分析了1,793个全球流行网站的Cookie横幅行为。

**Result:** Cookie行为、Cookie同意违规率和Cookie横幅实现方式高度依赖于地区。评估显示，同意管理平台（CMPs）和网站开发者可能根据他们对区域隐私法（通常不正确）的解释来定制Cookie横幅配置。这些实现产生了误导性的Cookie横幅，表明不同地区之间Cookie同意的实施和执行存在普遍的不一致性。

**Conclusion:** Cookie同意违规行为普遍存在且高度依赖于地区，这可能是由于同意管理平台和网站开发者对区域隐私法存在不正确的解释和不一致的实施导致的。

> **ai_Abstract:** 本文针对全球范围内普遍存在的Cookie同意违规问题，提出了一个名为ConsentChk的端到端系统。该系统利用形式化模型检测并分析网站的Cookie横幅行为，以识别并分类违规。研究对全球八个英语国家/地区的1,793个流行网站进行了调查，发现Cookie行为和违规率具有显著的地域依赖性。研究指出，这种不一致性可能源于同意管理平台和网站开发者对区域隐私法的不正确理解和定制化配置，导致了误导性的Cookie横幅。

> **摘要翻译:** 在线服务向用户提供Cookie横幅，以接受/拒绝放置在其网络浏览器上的Cookie。尽管Cookie横幅的应用日益增多，但很少有工作能确保Cookie同意符合全球隐私法。先前的研究发现，即使用户明确拒绝，Cookie也常常被放置在浏览器上。Cookie横幅行为中的这些不一致性规避了用户的同意偏好，被称为Cookie同意违规。为了解决这个重要问题，我们提出了一个端到端系统，名为ConsentChk，用于检测和分析Cookie横幅行为。ConsentChk使用形式化模型系统地检测和分类Cookie同意违规。我们调查了全球八个英语国家/地区，并分析了1,793个全球流行网站的Cookie横幅行为。结果发现，Cookie行为、Cookie同意违规率和Cookie横幅实现方式高度依赖于地区。我们的评估揭示，同意管理平台（CMPs）和网站开发者很可能根据他们对区域隐私法（通常不正确）的解释来定制Cookie横幅配置。我们讨论了这些Cookie同意违规背后的各种根本原因。由此产生的实现产生了误导性的Cookie横幅，表明不同地区之间Cookie同意的实施和执行存在普遍的不一致性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [619] [Wrapless: The trustless lending protocol on top of Bitcoin](https://arxiv.org/abs/2507.06064)
> *Wrapless：基于比特币的无需信任借贷协议*

*Oleksandr Kurbatov, Kyrylo Baibula, Yaroslava Chopa, Sergey Kozlov, Oleh Komendant, Illia Dovhopolyi, Dmitrii Kurbatov, Zakhar Naumets, Yuliia Aritkulova, Pavel Kravchenko, Volodymyr Dubinin, Lasha Antadze, Yaroslav Panasenko, Mykhailo Velykodnyi* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** Wrapless, 比特币, 借贷协议, 无需信任, 抵押

**Comment:** 

> **TL;DR:** Wrapless是一个在比特币区块链上实现的借贷协议，允许比特币作为抵押品，无需信任的包装机制，即可在任何支持图灵完备智能合约的区块链上获得贷款。

**AI_Comments:** 该论文创新性地提出了一种无需信任的比特币抵押借贷方案，解决了传统跨链借贷中对中心化包装机制的依赖问题。其核心在于通过比特币链上的“贷款通道”实现资金锁定，并与外部智能合约链协同。虽然协议声称经济上不可操纵，但其与传统AMM的融合潜力以及实际操作中的流动性和清算机制仍需深入探讨。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决在不依赖可信包装机制的情况下，实现比特币抵押借贷的问题。

**Method:** Wrapless协议通过在比特币区块链上建立“贷款通道”来实现。它允许比特币被锁定作为抵押品，从而在任何支持图灵完备智能合约的区块链上发放贷款。

**Result:** 该协议的设计使得所有参与方操纵贷款规则在经济上是不理性的。

**Conclusion:** 该协议仍有很大的研究空间，以使其更接近传统的AMM金融工具。

> **ai_Abstract:** Wrapless是一个无需信任的借贷协议，它允许用户在比特币区块链上抵押比特币，并通过一个“贷款通道”在任何支持图灵完备智能合约的区块链上获得贷款，而无需依赖中心化的包装机制。该协议的设计确保了其经济上的不可操纵性，但仍需进一步研究以整合传统AMM特性。

> **摘要翻译:** 本文介绍了 Wrapless——一个借贷协议，它无需可信的包装机制，即可实现比特币的抵押。该协议在比特币区块链上建立了一个“贷款通道”，允许比特币被锁定作为抵押品，用于在任何支持图灵完备智能合约的区块链上发放贷款。该协议的设计方式使得每个参与方操纵贷款规则在经济上都是不理性的。将该协议更接近传统AMM金融工具仍是一个重要的研究领域。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [625] [A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption](https://arxiv.org/abs/2507.14853)
> *以隐私为中心的方法：混合同态加密实现的可扩展安全联邦学习*

*Khoa Nguyen, Tanveer Khan, Hossein Abdinasibfar, Antonis Michalas* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 联邦学习, 混合同态加密, 隐私保护, 可扩展性, 去中心化学习

**Comment:** 

> **TL;DR:** 论文提出将混合同态加密与联邦学习结合，以解决联邦学习中的通信开销和隐私保护挑战，实现可扩展和安全的去中心化学习。

**AI_Comments:** 本文的创新点在于提出了将混合同态加密应用于联邦学习，以期同时解决通信开销和隐私保护两大挑战。这对于推动联邦学习在实际隐私敏感场景中的应用具有重要意义。该方法有望在保证数据隐私的同时，提升联邦学习的效率和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在隐私敏感领域有潜力，但面临通信开销和数据隐私挑战。现有的隐私保护技术（如同态加密）引入了高昂的计算和通信成本，限制了实际部署。

**Method:** 探索将混合同态加密（结合对称加密和同态加密的密码协议）有效集成到联邦学习中。

**Result:** Not mentioned in abstract

**Conclusion:** 将混合同态加密与联邦学习结合，能够有效解决联邦学习中的通信和隐私挑战，从而实现可扩展且安全的去中心化学习系统。

> **ai_Abstract:** 本文提出了一种以隐私为中心的联邦学习方法，通过集成混合同态加密（HHE）来解决现有联邦学习在通信开销和数据隐私方面的挑战。HHE结合了对称加密和同态加密的优势，旨在实现可扩展且安全的去中心化学习系统，克服了传统隐私保护技术的高成本限制。

> **摘要翻译:** 联邦学习（FL）能够在不共享原始数据的情况下实现协作模型训练，使其成为隐私敏感领域的一种有前景的方法。尽管潜力巨大，FL仍面临严峻挑战，尤其是在通信开销和数据隐私方面。同态加密（HE）等隐私保护技术（PPTs）已被用于缓解这些问题。然而，这些技术引入了巨大的计算和通信成本，限制了它们的实际部署。在这项工作中，我们探讨了如何将混合同态加密（HHE），一种结合了对称加密和HE的密码协议，有效地与FL集成，以解决通信和隐私挑战，为可扩展和安全的去中心化学习系统铺平道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [631] [HSM and TPM Failures in Cloud: A Real-World Taxonomy and Emerging Defenses](https://arxiv.org/abs/2507.17655)
> *云中HSM和TPM故障：真实世界分类及新兴防御*

*Shams Shaikh, Trima P. Fernandes e Fizardo* | **Category: cs.CR, cs.NI, cs.SE** | **Updated: 2025-08-07**

**Keywords:** HSM, TPM, 云安全, 密钥管理, 分类法

**Comment:** 

> **TL;DR:** 本文分析了云环境中HSM和TPM的真实世界故障，提出了攻击向量分类，并评估了新兴防御措施，强调了分层、上下文感知安全方法的重要性。

**AI_Comments:** 这项工作具有重要意义，因为它首次将真实世界的云HSM和TPM故障系统地分类，并提出了基于现代威胁模型的连贯分类法。它不仅揭示了当前云环境中密钥管理面临的挑战，还评估了前沿的防御技术，为云安全架构师提供了实用的策略指导。其创新点在于对实际案例的整合分析和分类方法的提出，对提升云基础设施的安全性具有直接的指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着云基础设施成为现代组织的核心，硬件安全模块（HSM）和可信平台模块（TPM）在加密密钥管理中的安全性面临前所未有的挑战。尽管这些硬件解决方案在隔离环境中提供了强大的保护，但其有效性正受到云原生威胁（如错误配置、API受损和横向权限提升）的削弱。

**Method:** 本文对云环境中涉及HSM和TPM的公开披露的攻击和泄露进行了全面分析，识别了重复出现的架构和操作缺陷。研究基于真实案例研究和威胁情报报告，提出了攻击向量的分类法。此外，还评估了新兴的防御范式：机密计算、后量子密码学和去中心化密钥管理系统（dKMS），评估它们弥补这些差距的潜力。

**Result:** 研究识别了HSM和TPM在云环境中面临的重复出现的架构和操作缺陷，并提出了基于真实世界案例的攻击向量分类。评估结果强调，保护基于云的加密信任需要一种分层、上下文感知的方法，该方法整合了硬件和软件防护措施。该研究为云架构师和安全工程师提供了一个实用框架，以根据不断演变的威胁重新评估密钥保护策略。

**Conclusion:** 保护云中加密信任需要一种分层、上下文感知的方法，该方法应整合硬件和软件防护措施。

> **ai_Abstract:** 本文深入分析了云环境中硬件安全模块（HSM）和可信平台模块（TPM）面临的真实世界安全挑战。通过对公开攻击和泄露的综合分析，研究提出了一个基于真实案例和威胁情报的攻击向量分类法，揭示了硬件信任锚点与动态云生态系统之间的差距。此外，论文评估了机密计算、后量子密码学和去中心化密钥管理系统等新兴防御措施的潜力。研究强调，确保云中加密信任需要采用结合硬件和软件防护的分层、上下文感知方法，并为云安全专业人员提供了实用的指导框架。

> **摘要翻译:** 随着云基础设施成为现代组织的核心，加密密钥管理（特别是使用硬件安全模块（HSM）和可信平台模块（TPM））的安全性面临前所未有的挑战。尽管这些基于硬件的解决方案在隔离环境中提供了强大的保护，但其有效性正受到云原生威胁（如错误配置、API受损和横向权限提升）的削弱。本文对云环境中涉及HSM和TPM的公开披露的攻击和泄露进行了全面分析，识别了重复出现的架构和操作缺陷。我们基于真实案例研究和威胁情报报告，提出了一种攻击向量分类法，突出了硬件信任锚点与动态云生态系统之间的差距。此外，我们评估了新兴的防御范式：机密计算、后量子密码学和去中心化密钥管理系统（dKMS），评估它们解决这些差距的潜力。我们的研究结果强调，保护基于云的加密信任需要一种分层、上下文感知的方法，该方法整合了硬件和软件防护措施。这项研究为云架构师和安全工程师提供了一个实用框架，以根据不断演变的威胁重新评估密钥保护策略。据我们所知，这是首次将已记录的真实世界云HSM和TPM故障综合成一个基于现代威胁模型的连贯分类法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [637] [ranDecepter: Real-time Identification and Deterrence of Ransomware Attacks](https://arxiv.org/abs/2508.00293)
> *ranDecepter：勒索软件攻击的实时识别与威慑*

*Md Sajidul Islam Sajid, Jinpeng Wei, Ehab Al-Shaer* | **Category: cs.CR** | **Updated: 2025-08-06**

**Keywords:** 勒索软件, 网络欺骗, 实时识别, 资源耗尽, ranDecepter

**Comment:** 

> **TL;DR:** ranDecepter是一种结合主动网络欺骗和实时分析的新方法，能够实时识别勒索软件，将其隔离在欺骗环境中，并通过生成伪造的加密信息和密钥来耗尽攻击者的资源，实现100%的识别准确率。

**AI_Comments:** ranDecepter的创新之处在于其将主动网络欺骗与实时分析相结合，不仅能够识别勒索软件，还能通过耗尽攻击者资源的方式进行主动威慑。其100%的识别准确率和生成大量伪造数据的能力展示了其在对抗勒索软件方面的巨大潜力。此方法为勒索软件防御提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 勒索软件（RW）在数字领域构成重大而广泛的威胁，需要有效的应对措施。主动网络欺骗是一种有前景的策略，可以通过误导虚假信息并揭示其真实行为来阻止RW并限制其传播。此外，RW通常充当攻击者和防御者之间的通信渠道，允许欺骗将虚假数据返回给攻击者并耗尽其资源。

**Method:** 本文介绍了ranDecepter，一种结合主动网络欺骗与实时分析的新颖方法，以增强对勒索软件攻击的防御。ranDecepter能够实时识别勒索软件并将其隔离在欺骗环境中，自主识别勒索软件代码中的关键元素以创建循环机制。通过反复重启恶意软件并向攻击者传输伪造的加密信息和密钥，它迫使攻击者为每个受害者存储这些伪造的详细信息，从而耗尽他们的资源。

**Result:** 对ranDecepter的综合评估，使用1,134个真实恶意软件样本和12个良性应用程序进行，结果显示勒索软件识别准确率高达100%，没有误报，对响应时间的影响最小。此外，在24小时内，ranDecepter使用50个代理在攻击者数据库中生成了多达9,223K条目，展示了其削弱攻击者资源的潜力。

**Conclusion:** ranDecepter通过结合主动网络欺骗和实时分析，提供了一种高效且准确的勒索软件识别和威慑机制，能够有效耗尽攻击者资源，显著提升了对勒索软件攻击的防御能力。

> **ai_Abstract:** ranDecepter是一种新型的勒索软件防御系统，它结合了主动网络欺骗和实时分析技术。该系统能够实时识别勒索软件，并将其隔离在受控的欺骗环境中。ranDecepter通过分析勒索软件代码，创建循环机制，不断重启恶意软件并向攻击者发送伪造的加密数据和密钥，从而迫使攻击者存储大量虚假信息，有效耗尽其资源。实验结果表明，ranDecepter在勒索软件识别方面达到了100%的准确率，且对系统响应时间影响极小，并能显著增加攻击者数据库中的无效数据量。

> **摘要翻译:** 勒索软件（RW）在数字领域构成重大而广泛的威胁，需要有效的应对措施。主动网络欺骗是一种有前景的策略，可以通过误导虚假信息并揭示其真实行为来阻止RW并限制其传播。此外，RW通常充当攻击者和防御者之间的通信渠道，允许欺骗将虚假数据返回给攻击者并耗尽其资源。本文介绍了ranDecepter，一种结合主动网络欺骗与实时分析的新颖方法，以增强对RW攻击的防御。ranDecepter能够实时识别RW并将其隔离在欺骗环境中，自主识别RW代码中的关键元素以创建循环机制。通过反复重启恶意软件并向攻击者传输伪造的加密信息和密钥，它迫使攻击者为每个受害者存储这些伪造的详细信息，从而耗尽他们的资源。我们对ranDecepter的综合评估，使用1,134个真实恶意软件样本和12个良性应用程序进行，结果显示RW识别准确率高达100%，没有误报，对响应时间的影响最小。此外，在24小时内，ranDecepter使用50个代理在攻击者数据库中生成了多达9,223K条目，展示了其削弱攻击者资源的潜力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [643] [Performance and Storage Analysis of CRYSTALS Kyber as a Post Quantum Replacement for RSA and ECC](https://arxiv.org/abs/2508.01694)
> *CRYSTALS Kyber 作为 RSA 和 ECC 的后量子替代方案的性能和存储分析*

*Nicolas Rodriguez-Alvarez, Fernando Rodriguez-Merino* | **Category: cs.CR** | **Updated: 2025-08-07**

**Keywords:** 后量子密码学, CRYSTALS Kyber, 性能分析, RSA, ECC

**Comment:** 

> **TL;DR:** 本研究评估了后量子密码算法 CRYSTALS-Kyber 在商用硬件上使用内置处理器加速功能的实际性能和存储，发现它在提供量子安全的同时，性能可接受。

**AI_Comments:** 本文的创新之处在于其对CRYSTALS-Kyber实用可行性的评估，特别强调了在现有商用硬件和内置加速功能下的性能表现，这对于后量子密码的实际部署具有重要指导意义。它解决了从传统密码学向后量子密码学过渡中的一个关键担忧，即新算法的性能开销，并提供了积极的证据。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算机的不断发展对当前的RSA和ECC加密构成了威胁，需要向抗量子算法过渡。CRYSTALS-Kyber是NIST标准化的领先后量子密码解决方案，但其广泛采用面临挑战。本研究旨在评估Kyber的实际可行性，以避免类似SHA-1到SHA-2过渡期间可能出现的长期漏洞和安全经济后果。

**Method:** 本研究通过在各种实现方案中进行性能测试来评估Kyber的实际可行性，仅利用标准的内置处理器加速功能，包括AES-NI和ASIMD，而没有添加任何专用硬件。

**Result:** 研究结果表明，Kyber在提供针对量子攻击的强大安全保障的同时，对于大多数当代应用而言，在仅使用带有制造商提供的加速功能的商用硬件的情况下，仍能保持可接受的性能表现。

**Conclusion:** CRYSTALS-Kyber在商用硬件上利用现有加速功能，能够提供强大的量子安全，并保持适用于当前应用的可接受性能，证明了其作为RSA和ECC后量子替代方案的实际可行性。

> **ai_Abstract:** 本研究评估了NIST标准化的后量子密码算法CRYSTALS-Kyber在实际应用中的性能和存储表现，以应对量子计算对现有密码学（如RSA和ECC）的威胁。研究人员在不使用专用硬件的情况下，仅利用商用处理器内置的加速功能（如AES-NI和ASIMD）进行了性能测试。结果显示，Kyber在提供强大的量子安全保障的同时，能够为大多数现代应用提供可接受的性能，证明了其作为后量子替代方案的实用性。

> **摘要翻译:** 量子计算机纠错技术的稳步进步已将当前记录推至48个稳定的逻辑量子比特，使我们更接近能够运行Shor算法的机器，其规模足以威胁RSA和ECC密码学。尽管开发此类量子计算机的时间表仍不确定，但密码学界必须为向抗量子算法的过渡做好准备。CRYSTALS-Kyber于2022年由NIST标准化，代表了一种领先的后量子密码解决方案，但其广泛采用面临重大挑战。如果这种迁移遵循与SHA-1到SHA-2过渡类似的模式，组织可能会经历长期的漏洞期，带来重大的安全和经济后果。本研究通过在各种实现方案中进行性能测试来评估Kyber的实际可行性，仅利用标准的内置处理器加速功能，其中一些包括AES-NI和ASIMD，而没有添加任何专用硬件。我们的发现表明，Kyber在提供针对量子攻击的强大安全保障的同时，对于大多数当代应用而言，在仅使用带有制造商提供的加速功能的商用硬件的情况下，仍能保持可接受的性能表现。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [649] [JULI: Jailbreak Large Language Models by Self-Introspection](https://arxiv.org/abs/2505.11790)
> *JULI：通过自我反思越狱大型语言模型*

*Jesson Wang, Zhanhao Hu, David Wagner* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 越狱, 自我反思, 黑盒攻击, 令牌对数概率

**Comment:** 

> **TL;DR:** JULI是一种新型的越狱大型语言模型（LLMs）的方法，它通过操纵令牌对数概率来实现，并且在黑盒设置下，仅通过API调用和了解前5个令牌对数概率就能有效工作，优于现有SOTA方法。

**AI_Comments:** JULI的创新之处在于它提出了一种无需访问模型内部机制（如权重或生成过程）即可越狱LLM的方法，这对于攻击流行的黑盒API调用模型至关重要。其仅依赖于令牌对数概率的策略，极大地拓宽了越狱研究的范围，并对LLM安全对齐提出了新的挑战。BiasNet作为轻量级插件，也体现了设计的精巧性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的越狱大型语言模型（LLMs）的方法通常需要访问模型权重或生成过程，这使得它们难以攻击通过API调用的专有模型。因此，需要一种新的方法来克服这些限制。

**Method:** 本文提出了通过LLM自省进行越狱（JULI），它通过操纵令牌对数概率来越狱LLMs，使用一个微小的插件块BiasNet。JULI仅依赖于目标LLM预测的令牌对数概率知识，并且可以在黑盒设置下，仅了解前5个令牌对数概率的情况下，有效地越狱API调用LLMs。

**Result:** JULI在多个指标上表现出卓越的有效性，优于现有最先进（SOTA）的方法。

**Conclusion:** JULI通过利用令牌对数概率，提供了一种在黑盒API调用设置下有效越狱大型语言模型的新方法，克服了现有攻击的局限性，并展现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为JULI（Jailbreaking Using LLM Introspection）的新型越狱大型语言模型（LLMs）的方法。与需要访问模型权重或生成过程的传统方法不同，JULI仅通过操纵LLM预测的令牌对数概率，并利用一个小型插件BiasNet来实现越狱。该方法特别适用于黑盒API调用模型，即使只知道前5个令牌的对数概率也能有效工作。实验结果表明，JULI在多个性能指标上均优于现有的最先进方法，解决了现有越狱技术在专有模型上的局限性。

> **摘要翻译:** 大型语言模型（LLMs）经过安全对齐训练，以防止生成恶意内容。尽管一些攻击已经突出了这些安全对齐LLMs的漏洞，但它们通常存在局限性，例如需要访问模型权重或生成过程。由于通过API调用的专有模型不授予用户此类权限，这些攻击很难攻破它们。在本文中，我们提出了使用LLM自省进行越狱（JULI），它通过操纵令牌对数概率，并使用一个微小的插件块BiasNet来越狱LLMs。JULI仅依赖于目标LLM预测的令牌对数概率知识。它可以在黑盒设置下，仅了解前5个令牌对数概率的情况下，有效地越狱API调用LLMs。我们的方法展示了卓越的有效性，在多个指标上优于现有最先进（SOTA）的方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [655] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
> *重新审视目标检测器上的对抗性补丁防御：统一评估、大规模数据集和新见解*

*Junhao Zheng, Jiahao Sun, Chenhao Lin, Zhengyu Zhao, Chen Ma, Chong Zhang, Cong Wang, Qian Wang, Chao Shen* | **Category: cs.CR, cs.CV** | **Updated: 2025-08-07**

**Keywords:** 对抗性补丁防御, 目标检测器, 统一评估, 大规模数据集, 新见解

**Comment:** 

> **TL;DR:** 该研究提出了首个针对目标检测器对抗性补丁防御的统一评估基准和大规模数据集，并揭示了关于防御有效性的新见解。

**AI_Comments:** 该论文的创新之处在于首次提出了一个统一的对抗性补丁防御评估基准和一个大规模数据集，填补了现有评估框架的空白。其对防御难点和性能指标的新见解，特别是指出数据分布而非高频是防御自然补丁的关键，以及强调被攻击对象平均精度作为更可靠的评估指标，对领域发展具有重要指导意义。此外，对自适应攻击和鲁棒防御特性的分析也很有价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有针对目标检测器的补丁攻击防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致且不完整。

**Method:** 研究者重新审视了11种代表性防御方法，并提出了首个补丁防御基准，该基准包含2个攻击目标、13种补丁攻击、11个目标检测器和4种不同的度量标准。他们还构建了一个包含94种补丁类型和94,000张图像的大规模对抗性补丁数据集。

**Result:** 1. 防御自然补丁的难度在于数据分布，而非普遍认为的高频。新数据集可将现有防御性能提高15.09% AP@0.5。
2. 被攻击对象的平均精度与防御性能高度一致，而非普遍追求的补丁检测精度。
3. 自适应攻击能显著绕过现有防御，而具有复杂/随机模型或通用补丁属性的防御相对更鲁棒。

**Conclusion:** 研究者希望他们的分析能为正确评估补丁攻击/防御提供指导，并促进其设计进展。

> **ai_Abstract:** 该论文通过识别现有对抗性补丁防御评估的不足，提出了首个针对目标检测器的统一评估基准和大规模对抗性补丁数据集。通过对11种防御方法和多种攻击的综合分析，研究揭示了防御自然补丁的真实难度在于数据分布而非高频，指出被攻击对象的平均精度是衡量防御性能的更优指标，并发现自适应攻击能有效绕过现有防御，而复杂或通用补丁属性的防御更具鲁棒性。这些发现旨在为未来补丁攻击与防御的设计和评估提供指导。

> **摘要翻译:** 开发针对目标检测器上补丁攻击的可靠防御已引起越来越多的关注。然而，我们发现现有的防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致且不完整。为了解决这个问题，我们重新审视了11种代表性防御方法，并提出了首个补丁防御基准，其中涉及2个攻击目标、13种补丁攻击、11个目标检测器和4种不同的度量标准。这产生了包含94种补丁类型和94,000张图像的大规模对抗性补丁数据集。我们的全面分析揭示了新见解：(1) 防御自然补丁的难度在于数据分布，而非普遍认为的高频。我们拥有多样化补丁分布的新数据集可以将现有防御性能提高15.09% AP@0.5。(2) 被攻击对象的平均精度，而非普遍追求的补丁检测精度，与防御性能表现出高度一致性。(3) 自适应攻击可以显著绕过现有防御，而具有复杂/随机模型或通用补丁属性的防御相对更鲁棒。我们希望我们的分析能为正确评估补丁攻击/防御提供指导，并促进其设计进展。代码和数据集可在 https://github.com/Gandolfczjh/APDE 获取，我们将在此持续集成新的攻击/防御。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [661] [Optimizing Preventive and Reactive Defense Resource Allocation with Uncertain Sensor Signals](https://arxiv.org/abs/2508.02881)
> *优化不确定传感器信号下的预防性和反应性防御资源分配*

*Faezeh Shojaeighadikolaei, Shouhuai Xu, Keith Paarporn* | **Category: cs.CR, cs.GT, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 网络防御, 资源分配, 预防性防御, 反应性防御, 传感器不确定性, 信号质量

**Comment:** 

> **TL;DR:** 本文研究了在网络攻击中，如何在预防性和反应性防御之间分配资源，并考虑了传感器信号的不确定性。研究发现，传感器质量越高，预防性投资越多；且在攻击成功率较低时，传感器带来的性能提升最大。

**AI_Comments:** 本文的创新之处在于将传感器信号的不确定性引入到预防性和反应性网络防御资源的优化分配问题中，这更贴近现实世界的网络安全挑战。研究结果为防御者在不同传感器质量和攻击威胁水平下制定战略投资提供了有价值的指导。其重要性在于提供了一种更全面的防御资源管理框架，超越了传统上仅关注预防的视角，并强调了情报质量在决策中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管网络防御技术不断进步，网络攻击仍然令人担忧。标准的决策框架通常只关注如何阻止攻击成功，而忽略了成功攻击造成的损害清理成本。因此，本文旨在研究一种新的资源分配问题，即防御者如何在预防性防御和反应性防御之间分配投资。

**Method:** 本文研究了一种新的资源分配问题，即防御者如何在预防性防御（旨在增强节点防御能力）和反应性防御（旨在快速清理受损节点）之间分配投资。研究考虑了传感器信号的不确定性，即攻击检测器不完美导致节点是否真正受损的观察存在不确定性。文章调查了传感器信号质量如何影响防御者在两种防御类型中的战略投资以及最终可实现的安全水平。

**Result:** 研究表明，随着传感器质量的提高，对预防性资源的最佳投资会增加，从而导致反应性资源投资减少。此外，相对于不使用传感器的基线，当攻击者只能实现较低的攻击成功概率时，防御者的性能提升最大。

**Conclusion:** 传感器信号质量对防御者在预防性和反应性防御资源上的战略投资具有显著影响，高质量的传感器能促使防御重心转向预防。同时，传感器在攻击成功率较低的场景下能带来最大的防御性能提升。

> **ai_Abstract:** 本文提出并研究了一个新的网络防御资源分配问题，旨在优化预防性防御和反应性防御之间的投资分配。该研究考虑了攻击检测器不完美导致的传感器信号不确定性，并分析了传感器质量对防御策略和整体安全水平的影响。主要发现包括：传感器质量越高，预防性投资越倾向于增加；并且在攻击者成功概率较低时，传感器对防御性能的提升最为显著。

> **摘要翻译:** 尽管网络防御技术不断进步，网络攻击仍然令人担忧。虽然网络攻击无法完全预防，但标准的决策框架通常只关注如何阻止其成功，而不考虑成功攻击造成的损害清理成本。这促使我们研究本文中提出的一种新的资源分配问题：防御者必须决定如何在其投资中分配预防性防御（旨在使节点免受攻击）和反应性防御（旨在快速清理受损节点）。这遇到一个由观察或传感器信号相关的不确定性带来的挑战，即一个节点是否真正受到损害；这种不确定性是真实存在的，因为攻击检测器并不完美。我们调查了传感器信号的质量如何影响防御者在两种防御类型上的战略投资，并最终影响可以实现的安全水平。特别是，我们表明，随着传感器质量的提高，对预防性资源的最佳投资会增加，从而反应性资源投资减少。我们还表明，相对于不使用传感器的基线，当攻击者只能实现较低的攻击成功概率时，防御者的性能提升最大。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [5] [Repurposing 2D Diffusion Models with Gaussian Atlas for 3D Generation](https://arxiv.org/abs/2503.15877)
> *将2D扩散模型与高斯图谱结合用于3D生成*

*Tiange Xiang, Kai Li, Chengjiang Long, Christian Häne, Peihong Guo, Scott Delp, Ehsan Adeli, Li Fei-Fei* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 2D扩散模型, 3D生成, 高斯图谱, 迁移学习, GaussianVerse

**Comment:** 

> **TL;DR:** 通过高斯图谱和新数据集，将预训练的2D扩散模型重用于3D生成，克服3D数据稀缺问题。

**AI_Comments:** 这项工作通过创新的高斯图谱表示和大规模数据集的构建，有效地利用了成熟的2D扩散模型来解决3D数据稀缺的挑战，为3D内容生成提供了一个有前景的解决方案，并展示了2D到3D迁移学习的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 高质量3D数据稀缺阻碍了3D扩散模型的发展，导致其性能与2D模型相比竞争力不足。

**Method:** 本文提出重用预训练的2D扩散模型进行3D对象生成。核心方法是引入高斯图谱（Gaussian Atlas），这是一种利用密集2D网格的新颖表示，能够微调2D扩散模型以生成3D高斯。为支持模型训练，研究者还编译了一个包含20.5万个高质量3D高斯拟合的大规模数据集GaussianVerse。

**Result:** 实验结果表明，文本到图像的扩散模型可以有效地适应3D内容生成。

**Conclusion:** 该方法成功弥合了2D和3D建模之间的鸿沟，证明了2D扩散模型可有效用于3D生成。

> **ai_Abstract:** 本文提出了一种将预训练的2D扩散模型重用于3D对象生成的方法，以解决高质量3D数据稀缺的问题。通过引入高斯图谱这一新颖的2D网格表示，模型能够微调生成3D高斯。为了支持训练，作者构建了大型数据集GaussianVerse。实验证明该方法能有效将2D扩散模型应用于3D内容生成，从而弥合了2D与3D建模之间的差距。

> **摘要翻译:** 文本到图像扩散模型的最新进展得益于2D配对数据可用性的增加。然而，3D扩散模型的发展受到高质量3D数据稀缺的阻碍，导致其性能与2D模型相比竞争力不足。为了解决这一挑战，我们提出将预训练的2D扩散模型重用于3D对象生成。我们引入了高斯图谱，这是一种利用密集2D网格的新颖表示，使得2D扩散模型能够进行微调以生成3D高斯。我们的方法展示了从预训练2D扩散模型到从3D结构扁平化而来的2D流形的成功迁移学习。为了支持模型训练，我们编译了GaussianVerse，一个包含20.5万个高质量3D对象高斯拟合的大规模数据集。我们的实验结果表明，文本到图像扩散模型可以有效地适应3D内容生成，弥合了2D和3D建模之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [12] [Follow-Your-Color: Multi-Instance Sketch Colorization](https://arxiv.org/abs/2503.16948)
> *Follow-Your-Color：多实例草图上色*

*Yinhan Zhang, Yue Ma, Bingyuan Wang, Qifeng Chen, Zeyu Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 草图上色, 多实例, 扩散模型, 自玩训练, 颜色匹配

**Comment:** 

> **TL;DR:** Follow-Your-Color是一种基于扩散的框架，通过自玩训练、实例引导器和细粒度颜色匹配来自动化多实例草图上色，解决了数据不足和人工效率低下的问题，并实现了零人工调整的精确上色。

**AI_Comments:** 该论文提出了一个针对多实例草图上色的创新解决方案，其核心贡献在于通过自玩训练策略、实例引导器和细粒度颜色匹配有效地解决了数据稀缺和多实例控制的挑战。其“零人工调整”的自动化能力，对于提升动漫、游戏等行业的工作效率和降低艺术创作门槛具有重要意义。这是一个结合了实用性和技术创新潜力的工作。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多实例2D线稿上色工作流程需要艺术家重复手动上色每个实例，这既不准确又效率低下。同时，当前生成方法因多实例对数据收集的挑战而无法解决此任务。

**Method:** 本文提出了Follow-Your-Color框架，包含三个技术设计：1. 提出自玩训练策略以解决训练数据缺乏问题。2. 引入实例引导器来输入实例颜色。3. 提出带有边缘损失的细粒度颜色匹配以增强视觉质量和实现精确颜色匹配。

**Result:** 实验表明，Follow-Your-Color模型在色彩精度方面优于现有方法。该模型能够实现零人工调整的自动化上色过程，使新手用户通过提供参考实例和原始线稿即可生成风格一致的艺术作品。

**Conclusion:** Follow-Your-Color框架成功地实现了多实例草图的自动化上色，解决了现有方法的局限性，并显著提高了效率和准确性，使非专业用户也能创作出高质量的彩色作品。

> **ai_Abstract:** Follow-Your-Color是一个创新的扩散基框架，专为多实例草图自动化上色而设计。它解决了传统手动上色流程效率低下和现有生成方法数据收集困难的问题。该框架通过引入自玩训练策略解决数据稀缺性，利用实例引导器进行颜色输入，并通过带有边缘损失的细粒度颜色匹配确保高精度色彩。实验证明，Follow-Your-Color在色彩精度上超越了现有技术，能够实现零人工干预的自动化上色，使非专业用户也能轻松创作出风格统一的艺术作品。

> **摘要翻译:** 我们提出了Follow-Your-Color，一个基于扩散的多实例草图上色框架。多实例2D线稿上色的生产遵循行业标准工作流程，该流程包括三个关键阶段：线稿角色设计、单个对象上色和精修过程。艺术家需要重复逐个实例的上色过程，这既不准确又低效。同时，当前生成方法由于多实例对数据收集的挑战而未能解决此任务。为了应对这些挑战，我们结合了三种技术设计，以确保精确的角色细节转录，并在一次前向传递中实现多实例草图上色。具体来说，我们首先提出了自玩训练策略来解决训练数据不足的问题。然后我们引入了一个实例引导器来输入实例的颜色。为了实现精确的颜色匹配，我们提出了带有边缘损失的细粒度颜色匹配，以提高视觉质量。配备了所提出的模块，Follow-Your-Color能够自动将草图转换为色彩鲜艳的图像，具有准确的一致性和多实例控制。我们收集的数据集上的实验表明，我们的模型在色彩精度方面优于现有方法。具体来说，我们的模型通过零人工调整关键性地自动化了上色过程，因此新手用户可以通过提供参考实例和原始线稿来制作风格一致的艺术作品。我们的代码和附加细节可在https://yinhan-zhang.github.io/color 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [19] [GaSLight: Gaussian Splats for Spatially-Varying Lighting in HDR](https://arxiv.org/abs/2504.10809)
> *GaSLight：用于HDR中空间变异照明的高斯溅射*

*Christophe Bolduc, Yannick Hold-Geoffroy, Zhixin Shu, Jean-François Lalonde* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 高斯溅射, 空间变异照明, HDR, 渲染器, 扩散模型

**Comment:** 

> **TL;DR:** GaSLight 是一种新方法，首次使用 HDR 高斯溅射将普通图像作为3D渲染器中的光源，生成空间变异照明，并取得了最先进的HDR估计结果。

**AI_Comments:** GaSLight的创新之处在于首次将HDR高斯溅射用于将普通图像转化为3D渲染器中的光源，从而实现了空间变异照明。这种方法结合了扩散模型进行图像动态范围增强，显示了其在处理图像数据方面的先进性。该研究对于虚拟现实、渲染和计算机图形学领域具有重要意义，因为它提供了一种高效且高质量的照明解决方案。引入新的数据集也体现了其对领域发展的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法可能无法直接将普通图像用作3D渲染器中的光源并生成空间变异照明。该研究旨在解决这一问题，提升HDR估计及其在虚拟场景照明中的应用。

**Method:** GaSLight采用两阶段过程：1. 利用扩散模型中的先验知识，可信且准确地增强图像的动态范围。2. 使用高斯溅射（Gaussian Splats）来建模3D照明，从而实现空间变异照明。此外，还引入了一个新的校准且未饱和的HDR数据集，用于评估图像作为光源的基准测试。

**Result:** 1. 首次将普通图像作为3D渲染器中的光源。2. 在HDR估计及其在照亮虚拟物体和场景中的应用方面取得了最先进的结果。3. 引入了一个新的校准且未饱和的HDR数据集，用于评估图像作为光源。

**Conclusion:** GaSLight成功地通过利用HDR高斯溅射和两阶段处理，将普通图像转化为3D渲染器中的空间变异光源，并在HDR估计和虚拟场景照明方面达到了最先进的性能，同时提出了新的评估数据集。

> **ai_Abstract:** GaSLight是一种创新的方法，它首次实现了将普通图像作为3D渲染器中的光源，以生成空间变异照明。该方法通过一个两阶段过程实现：首先利用扩散模型增强图像的动态范围，然后使用HDR高斯溅射来建模3D照明。GaSLight在HDR估计和虚拟场景照明方面展现了最先进的性能，并为此领域引入了一个新的校准HDR数据集以促进基准测试。

> **摘要翻译:** 我们提出了GaSLight，一种从普通图像生成空间变异照明的方法。我们的方法建议使用HDR高斯溅射作为光源表示，这标志着普通图像首次可以在3D渲染器中用作光源。我们的两阶段过程首先利用扩散模型中嵌入的先验知识，可信且准确地增强图像的动态范围。接下来，我们采用高斯溅射来建模3D照明，实现空间变异照明。我们的方法在HDR估计及其在照亮虚拟物体和场景中的应用方面取得了最先进的结果。为了方便图像作为光源的基准测试，我们引入了一个新的校准且未饱和的HDR数据集来评估图像作为光源。我们结合这个新数据集和文献中现有数据集来评估我们的方法。项目页面：https://lvsn.github.io/gaslight/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [26] [Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video Pipeline](https://arxiv.org/abs/2504.12169)
> *迈向通用零样本合成低光图像和视频处理管线*

*Joanne Lin, Crispian Morris, Ruirui Lin, Fan Zhang, David Bull, Nantheera Anantrasirichai* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 零样本, 低光, 合成数据, 噪声生成, 降级估计网络

**Comment:** 

> **TL;DR:** 本文提出了一种名为降级估计网络（DEN）的新方法，用于零样本合成生成逼真的低光图像和视频噪声，无需相机元数据，并在低光任务中实现了显著性能提升。

**AI_Comments:** 该论文的创新之处在于其提出的零样本、自监督的降级估计网络（DEN），能够生成多样化且逼真的低光噪声，且无需依赖相机元数据或特定的训练数据噪声特征。这克服了现有合成方法的主要局限性，为低光图像和视频的机器理解研究开辟了新的途径，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 低光条件对人类和机器标注都构成了重大挑战，导致对低光图像（尤其是视频）的机器理解研究不足。现有方法通常将高质量数据集的标注应用于合成创建的低光版本，但这些方法常因使用不真实的噪声模型而受限。

**Method:** 本文提出了一种新的降级估计网络（DEN），它通过估计物理信息噪声分布的参数，以自监督方式进行训练，从而在无需相机元数据的情况下合成生成逼真的标准RGB（sRGB）噪声。这种零样本方法使得其能够生成具有多样化真实噪声特征的合成内容。

**Result:** 该合成管线在多种低光任务（包括合成噪声复制、视频增强和目标检测）中进行了评估，显示出高达24% KLD、21% LPIPS和62% AP$_{50-95}$的改进。

**Conclusion:** 本文提出的零样本合成管线，特别是其降级估计网络（DEN），能够有效生成逼真的低光噪声，克服了现有方法的局限性，并在多种低光任务中实现了显著性能提升。

> **ai_Abstract:** 该论文旨在解决低光条件下机器理解的挑战，其部分原因是标注困难和现有合成数据中不真实的噪声模型。作者提出了一种名为降级估计网络（DEN）的新型网络，该网络能够以自监督的零样本方式，通过估计物理信息噪声分布的参数，合成生成逼真的标准RGB（sRGB）噪声，且无需相机元数据。这使得该方法能够生成具有多样化真实噪声特征的合成内容，优于仅关注重现训练数据噪声特征的其他方法。在合成噪声复制、视频增强和目标检测等低光任务上的评估结果表明，该合成管线带来了显著的性能提升，最高分别达到24% KLD、21% LPIPS和62% AP$_{50-95}$。

> **摘要翻译:** 低光条件对人类和机器标注都构成了重大挑战。这反过来导致了对低光图像（尤其是视频）的机器理解研究不足。一种常见的方法是将从高质量数据集获得的标注应用于合成创建的低光版本。此外，这些方法通常因使用不真实的噪声模型而受到限制。在本文中，我们提出了一种新的降级估计网络（DEN），它在无需相机元数据的情况下合成生成逼真的标准RGB（sRGB）噪声。这是通过估计物理信息噪声分布的参数来实现的，并以自监督方式进行训练。这种零样本方法使得我们的方法能够生成具有多样化真实噪声特征的合成噪声内容，这与专注于重现训练数据噪声特征的其他方法不同。我们使用在其合成数据上训练的各种方法，针对典型的低光任务（包括合成噪声复制、视频增强和目标检测）评估了我们提出的合成管线，分别显示出高达24% KLD、21% LPIPS和62% AP$_{50-95}$的改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [33] [Cross-Image Contrastive Decoding: Precise, Lossless Suppression of Language Priors in Large Vision-Language Models](https://arxiv.org/abs/2505.10634)
> *跨图像对比解码：大视觉-语言模型中语言先验的精确、无损抑制*

*Jianfei Zhao, Feng Zhang, Xin Sun, Chong Feng* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 语言先验抑制, 对比解码, 大视觉-语言模型, 幻觉, 图像字幕

**Comment:** 

> **TL;DR:** 提出一种名为CICD的无训练方法，通过使用不相关图像进行对比解码并结合动态选择机制，有效且精确地抑制大视觉-语言模型中的语言先验，从而减少幻觉。

**AI_Comments:** 这篇论文通过引入“跨图像”概念来生成对比输入，解决了现有对比解码方法中图像扰动导致的对比信号不完整和过度抑制问题，具有创新性。动态选择机制进一步提升了抑制的精确性，避免了对模型性能的负面影响，使其成为一个实用的训练无关的幻觉抑制方案。

<details>
  <summary>Details</summary>

**Motivation:** 大视觉-语言模型（LVLMs）过度依赖语言先验是导致幻觉的主要原因，现有对比解码方法通过扰动原始图像构造对比输入，导致对比分布失真、信号不完整和过度抑制。本文的动机是观察到语言先验在不同图像之间趋于保持一致。

**Method:** 提出跨图像对比解码（CICD），一种简单而有效的无训练方法，使用不相关的图像作为对比视觉输入。为解决过度抑制语言先验的问题，引入基于模型行为跨图像差异的动态选择机制，以选择性地抑制语言先验。

**Result:** 在多个基准测试和LVLM上的大量实验证实了CICD的有效性和普遍性，特别是在语言先验尤其占主导地位的图像字幕任务中。该方法在减少幻觉的同时不损害模型性能。

**Conclusion:** CICD通过使用不相关图像和动态选择机制，提供了一种精确、无损地抑制大视觉-语言模型中语言先验的有效方法，显著减少了幻觉并保持了模型性能。

> **ai_Abstract:** 本文提出了一种名为跨图像对比解码（CICD）的无训练方法，旨在解决大视觉-语言模型中因过度依赖语言先验而导致的幻觉问题。与现有方法通过扰动图像不同，CICD利用不相关的图像作为对比输入，并引入动态选择机制以精确、选择性地抑制语言先验，从而在不影响模型性能的前提下有效减少幻觉。实验证明了其在多种基准和模型上的有效性和泛化能力，尤其在图像字幕任务中表现突出。

> **摘要翻译:** 大视觉-语言模型（LVLMs）过度依赖语言先验是导致幻觉的主要原因，这通常导致语言上合理但在视觉上不一致的输出。最近的研究探索了对比解码作为一种无需训练的解决方案。然而，这些方法通常通过扰动原始图像来构建对比视觉输入，导致对比分布失真、对比信号不完整以及语言先验的过度抑制。受语言先验在不同图像之间趋于保持一致的观察启发，我们提出了跨图像对比解码（CICD），这是一种简单而有效的无需训练的方法，它使用不相关的图像作为对比视觉输入。为了解决过度抑制语言先验（这可能会对生成响应的质量产生负面影响）的问题，我们进一步引入了一种基于模型行为跨图像差异的动态选择机制。通过选择性地抑制语言先验，我们的方法在不损害模型性能的情况下减少了幻觉。在多个基准测试和LVLM上进行的广泛实验证实了CICD的有效性和普遍性，特别是在语言先验尤其占主导地位的图像字幕领域。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [40] [DSOcc: Leveraging Depth Awareness and Semantic Aid to Boost Camera-Based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2505.20951)
> *DSOcc：利用深度感知和语义辅助提升基于摄像头的3D语义占据预测*

*Naiyu Fang, Zheyuan Zhou, Kang Wang, Ruibo Li, Lemiao Qiu, Shuyou Zhang, Zhe Wang, Guosheng Lin* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D语义占据预测, 深度感知, 语义辅助, 摄像头, 自动驾驶

**Comment:** 

> **TL;DR:** DSOcc通过结合深度感知和语义辅助，改进了基于摄像头的3D语义占据预测，解决了现有方法特征分配不准确和样本不足的问题，并在SemanticKITTI数据集上达到了SOTA性能。

**AI_Comments:** 这篇论文通过引入深度感知和语义辅助，创新性地解决了基于摄像头的3D语义占据预测中的关键挑战，即特征分配不准确和样本不足。其独特的隐式占据状态推断和直接利用语义分割的策略，避免了复杂的特征学习，提升了系统的效率和鲁棒性，为自动驾驶场景感知提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于摄像头的3D语义占据预测方法依赖显式占据状态推断，导致错误的特征分配；同时，样本不足限制了占据类别推断的学习。

**Method:** 提出DSOcc，联合执行占据状态和占据类别推断。通过非学习方法计算软占据置信度并与图像特征相乘，使体素感知深度，实现自适应隐式占据状态推断。直接利用预训练的图像语义分割，并融合多帧的占据概率来辅助占据类别推断，从而增强鲁棒性。

**Result:** DSOcc在SemanticKITTI数据集上，在基于摄像头的方法中达到了最先进的性能。

**Conclusion:** DSOcc通过引入深度感知和语义辅助，有效解决了基于摄像头的3D语义占据预测中特征分配不准确和样本不足的问题，显著提升了预测性能和鲁棒性。

> **ai_Abstract:** DSOcc是一种新的基于摄像头的3D语义占据预测方法，旨在解决现有方法中特征分配不准确和样本不足的问题。它通过结合深度感知（非学习软占据置信度与图像特征结合）实现自适应隐式占据状态推断，并利用预训练的图像语义分割和多帧融合来辅助占据类别推断，从而提高鲁棒性。实验证明，DSOcc在SemanticKITTI数据集上达到了最先进的性能。

> **摘要翻译:** 基于摄像头的3D语义占据预测为自动驾驶中的周围场景感知提供了一种高效且经济的解决方案。然而，现有工作依赖于显式的占据状态推断，导致大量的错误特征分配，并且样本不足限制了占据类别推断的学习。为了解决这些挑战，我们提出了利用深度感知和语义辅助来提升基于摄像头的3D语义占据预测（DSOcc）的方法。我们联合执行占据状态和占据类别推断，其中软占据置信度通过非学习方法计算，并与图像特征相乘，使体素感知深度，从而实现自适应隐式占据状态推断。我们没有增强特征学习，而是直接利用训练良好的图像语义分割，并融合多帧及其占据概率来辅助占据类别推断，从而增强鲁棒性。实验结果表明，DSOcc在基于摄像头的方法中，在SemanticKITTI数据集上取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [47] [SteerPose: Simultaneous Extrinsic Camera Calibration and Matching from Articulation](https://arxiv.org/abs/2506.01691)
> *SteerPose：基于关节运动的同时外部相机标定与匹配*

*Sang-Eun Lee, Ko Nishino, Shohei Nobuhara* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 相机标定, 姿态估计, 对应点匹配, 神经网络, 多相机系统

**Comment:** 

> **TL;DR:** SteerPose是一个神经网络，它能利用自由移动的人或动物作为标定目标，同时进行多相机系统的外部标定和视图间姿态对应点匹配，并能重建新动物的3D姿态。

**AI_Comments:** SteerPose的创新之处在于其将多相机标定与跨视图姿态对应点匹配集成到一个统一的神经网络框架中，并通过引入几何一致性损失保证了结果的有效性。其利用自由移动的生物作为标定目标，极大地提高了实际应用的灵活性和便捷性。此外，该方法的类别无关性使其能够处理新型动物的3D姿态重建，具有很高的实用价值和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的相机标定需要特定目标，而本文旨在探索是否能利用自由移动的人或动物作为多相机系统的标定目标，并同时估计不同视角间的对应关系，灵感来源于人类通过心理旋转2D姿态来对齐的能力。

**Method:** 本文提出了SteerPose，一个神经网络，它能够将2D姿态旋转到另一个视图中。通过集成可微分匹配，SteerPose在一个统一框架内同时执行外部相机标定和对应点搜索。此外，还引入了一种新颖的几何一致性损失，以确保估计的旋转和对应关系能够产生有效的平移估计。

**Result:** 在多样化的野外人与动物数据集上的实验结果验证了所提出方法的有效性和鲁棒性。此外，该方法能够通过利用现成的2D姿态估计器和类别无关模型，在多相机设置中重建新动物的3D姿态。

**Conclusion:** SteerPose方法有效且鲁棒，能够利用自由移动的人或动物进行多相机系统的同时外部标定和对应点匹配，并能结合现有的2D姿态估计器重建新动物的3D姿态。

> **ai_Abstract:** SteerPose是一个受人类认知能力启发而设计的神经网络，旨在解决多相机系统中利用自由移动的人或动物进行同时外部相机标定和姿态对应点匹配的问题。该网络通过旋转2D姿态并集成可微分匹配，在一个统一框架内实现标定与匹配，并引入了几何一致性损失。实验证明，SteerPose在野外数据集上具有有效性和鲁棒性，并能结合现有2D姿态估计器重建新动物的3D姿态。

> **摘要翻译:** 多相机系统能否以自由移动的人或动物本身作为校准目标，同时估计它们在不同视图间的对应关系？我们人类可以通过心理旋转观察到的2D姿态并将它们与目标视图中的姿态对齐来解决这个问题。受这种认知能力的启发，我们提出了SteerPose，一个执行2D姿态旋转到另一个视图的神经网络。通过整合可微分匹配，SteerPose在一个统一的框架内同时执行外部相机校准和对应点搜索。我们还引入了一种新颖的几何一致性损失，明确确保估计的旋转和对应关系能够产生有效的平移估计。在多样化的野外人与动物数据集上的实验结果验证了所提出方法的有效性和鲁棒性。此外，我们证明了我们的方法可以通过利用现成的2D姿态估计器和我们的类别无关模型，在多相机设置中重建新动物的3D姿态。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [54] [CLIP Meets Diffusion: A Synergistic Approach to Anomaly Detection](https://arxiv.org/abs/2506.11772)
> *CLIP 遇上 Diffusion：异常检测的协同方法*

*Byeongchan Lee, John Won, Seunghyun Lee, Jinwoo Shin* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 异常检测, CLIP, Diffusion, 多模态融合, CLIPFUSION

**Comment:** 

> **TL;DR:** CLIPFUSION 结合 CLIP 和 Diffusion 模型，有效解决了异常检测中数据稀缺和类型多样性的挑战，在基准数据集上表现优异。

**AI_Comments:** 本文的创新点在于将判别式（CLIP）和生成式（Diffusion）两种基础模型进行协同融合，以应对异常检测中全局与局部特征捕获的挑战。这种多模态、多模型的融合方法在数据稀缺的场景下尤其重要，为解决实际世界的异常检测问题提供了一个有前景且可扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 异常检测是一个复杂的问题，因为异常定义模糊、异常类型多样（例如局部和全局缺陷）以及训练数据稀缺。因此，需要一个即使在数据有限的情况下也能捕获低级和高级特征的综合模型。

**Method:** 我们提出了 CLIPFUSION，一种利用判别式和生成式基础模型的方法。具体来说，基于 CLIP 的判别式模型擅长捕获全局特征，而基于扩散的生成式模型有效捕获局部细节，从而创建了一种协同互补的方法。值得注意的是，我们引入了一种利用从扩散模型中提取的交叉注意力图和特征图进行异常检测的方法。

**Result:** 在基准数据集（MVTec-AD、VisA）上的实验结果表明，CLIPFUSION 始终优于基线方法，在异常分割和分类方面均取得了出色的性能。

**Conclusion:** 我们相信，我们的方法强调了多模态和多模型融合在解决异常检测多方面挑战方面的有效性，为实际应用提供了可扩展的解决方案。

> **ai_Abstract:** 本文提出了一种名为 CLIPFUSION 的新型异常检测方法，旨在解决异常定义模糊、类型多样和数据稀缺等挑战。CLIPFUSION 创新性地结合了基于 CLIP 的判别式模型（用于捕获全局特征）和基于扩散的生成式模型（用于捕获局部细节），形成协同互补的优势。该方法还引入了利用扩散模型中的交叉注意力图和特征图进行异常检测的技术。实验结果表明，CLIPFUSION 在MVTec-AD和VisA等基准数据集上，在异常分割和分类任务中均显著优于现有基线方法，证明了多模态和多模型融合在实际异常检测应用中的有效性和可扩展性。

> **摘要翻译:** 异常检测是一个复杂的问题，因为异常定义模糊、异常类型多样（例如局部和全局缺陷）以及训练数据稀缺。因此，需要一个即使在数据有限的情况下也能捕获低级和高级特征的综合模型。为了解决这个问题，我们提出了 CLIPFUSION，一种利用判别式和生成式基础模型的方法。具体来说，基于 CLIP 的判别式模型擅长捕获全局特征，而基于扩散的生成式模型有效捕获局部细节，从而创建了一种协同互补的方法。值得注意的是，我们引入了一种利用从扩散模型中提取的交叉注意力图和特征图进行异常检测的方法。在基准数据集（MVTec-AD、VisA）上的实验结果表明，CLIPFUSION 始终优于基线方法，在异常分割和分类方面均取得了出色的性能。我们相信，我们的方法强调了多模态和多模型融合在解决异常检测多方面挑战方面的有效性，为实际应用提供了可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [61] [HydroChronos: Forecasting Decades of Surface Water Change](https://arxiv.org/abs/2506.14362)
> *HydroChronos：预测地表水数十年变化*

*Daniele Rege Cambrin, Eleonora Poeta, Eliana Pastor, Isaac Corley, Tania Cerquitelli, Elena Baralis, Paolo Garza* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 地表水预测, HydroChronos, 时空数据集, AquaClimaTempo UNet, 气候变化

**Comment:** 

> **TL;DR:** 本文介绍了HydroChronos，一个用于地表水动力学预测的大规模多模态时空数据集，并提出了AquaClimaTempo UNet模型作为基准，该模型在预测未来水动力学方面表现显著优于基线。

**AI_Comments:** 该论文通过引入大规模多模态数据集和创新的深度学习模型，显著推动了地表水变化预测领域的发展。数据集的长期性和多源性是其重要创新点。模型结合气候数据分支的设计也很有见地，并通过可解释AI分析提供了对预测机制的深入理解，这对于指导未来的水资源管理和气候适应研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地表水动力学预测对于水资源管理和气候变化适应至关重要，但该领域缺乏全面的数据集和标准化的基准。

**Method:** 本文引入了HydroChronos，一个大规模、多模态时空数据集，用于地表水动力学预测。该数据集包含超过三十年的Landsat 5和Sentinel-2图像、气候数据和数字高程模型。此外，还提出了AquaClimaTempo UNet，一种新颖的时空架构，带有专门的气候数据分支，作为强大的基准线。

**Result:** AquaClimaTempo UNet模型在变化检测和变化方向分类任务中，F1分数分别比Persistence基线高出+14%和+11%；在变化幅度回归任务中，MAE提高了+0.1。

**Conclusion:** 本研究通过引入HydroChronos数据集和AquaClimaTempo UNet模型，显著提升了地表水变化预测的能力，并通过可解释AI分析揭示了影响地表水变化的关键气候变量和输入通道，为未来的建模工作提供了指导。

> **ai_Abstract:** 本文提出了HydroChronos，一个用于地表水动力学预测的大规模多模态时空数据集，旨在解决现有数据集和基准的不足。该数据集包含了多源遥感图像、气候数据和DEM。同时，研究还提出了AquaClimaTempo UNet模型，该模型通过引入专门的气候数据分支，在多个预测任务上显著优于基线模型。此外，研究还进行了可解释AI分析，以揭示影响地表水变化的关键因素。

> **摘要翻译:** 预测地表水动力学对于水资源管理和气候变化适应至关重要。然而，该领域缺乏全面的数据集和标准化的基准。在本文中，我们介绍了HydroChronos，一个大规模、多模态时空数据集，旨在弥补这一空白，用于地表水动力学预测。我们将该数据集与三个预测任务相结合。该数据集包括欧洲、北美和南美洲不同湖泊和河流的三十多年对齐的Landsat 5和Sentinel-2图像、气候数据和数字高程模型。我们还提出了AquaClimaTempo UNet，一种新颖的时空架构，带有专门的气候数据分支，作为强大的基准线。我们的模型在预测未来水动力学方面显著优于Persistence基线，在变化检测和变化方向分类任务中，F1分数分别高出+14%和+11%，在变化幅度回归任务中，MAE提高了+0.1。最后，我们进行了可解释AI分析，以识别影响地表水变化的关键气候变量和输入通道，为未来的建模工作提供见解和指导。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
> *基于动态三维高斯模型的关节物体部件分割与运动估计*

*Jun-Jee Chao, Qingyuan Jiang, Volkan Isler* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 部件分割, 运动估计, 关节物体, 3D高斯模型, 点云

**Comment:** 

> **TL;DR:** 本文提出了一种使用动态三维高斯模型对关节物体进行部件分割和运动估计的方法，该方法在处理非固定点云和遮挡场景时表现出优越的鲁棒性。

**AI_Comments:** 本文的创新点在于提出了基于动态3D高斯模型来表示关节物体，有效地解决了传统方法在处理非固定点云和严重遮挡场景时遇到的挑战。这种表示方法允许在没有显式点对应的情况下进行部件分割和运动估计，显著提高了在复杂真实世界场景中的鲁棒性和准确性，尤其是在部件分割方面取得了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 关节物体的部件分割和运动估计是运动分析中的基本问题。现有方法依赖于点对应跟踪，但在点云并非由固定点集生成（如存在严重遮挡或异步多传感器数据）时不再适用，这是本文主要解决的挑战。

**Method:** 本文提出了一种基于紧凑有效表示的方法，将物体建模为3D高斯集合。高斯模型参数化为时间相关的旋转、平移和尺度，并在所有时间步长中共享。通过在观测点和高斯模型之间建立对应关系来实现部件分割，并通过跟踪分配的高斯姿态来获取每个点随时间变化的变换。

**Result:** 实验表明，本文方法优于仅依赖于寻找点对应关系的现有方法。在考虑视点遮挡的扩展数据集中，本文方法对缺失点表现出更强的鲁棒性。在存在遮挡的点云上，部件分割性能优于现有最先进方法13%。

**Conclusion:** 本文提出的基于动态三维高斯模型的方法，能够有效且鲁棒地解决关节物体在复杂场景（如非固定点云、严重遮挡）下的部件分割和运动估计问题，并显著优于现有依赖点对应的方法。

> **ai_Abstract:** 本文提出了一种新颖的方法，用于从一系列非固定、可能存在遮挡的关节物体点云中，同时进行部件分割和运动估计。该方法将物体表示为动态三维高斯模型集合，并通过建立点与高斯之间的对应关系来解决分割问题，通过高斯姿态跟踪来估计运动。实验证明，相比于依赖点对应的方法，本文方法在处理缺失数据和遮挡方面更具鲁棒性，并且在部件分割性能上取得了显著提升。

> **摘要翻译:** 部件分割和运动估计是关节物体运动分析的两个基本问题。在本文中，我们提出了一种从单个关节物体的一系列观测点云中联合解决这两个问题的方法。我们问题设置中的主要挑战是，点云不被假设由一组固定的移动点生成。相反，序列中的每个点云都可能是该特定时间步长中物体表面的任意采样。当物体经历主要遮挡时，或者如果数据集是使用来自多个传感器的异步测量收集时，就会出现这种情况。在这些情况下，依赖于跟踪点对应关系的方法是不合适的。我们提出了一种基于紧凑但有效表示的替代方法，我们将物体表示为由3D高斯模型建模的简单构建块的集合。我们用时间相关的旋转、平移和尺度参数化高斯模型，这些参数在所有时间步长中共享。通过我们的表示，可以通过在观测点和高斯模型之间建立对应关系来实现部件分割。此外，每个点随时间变化的变换可以通过遵循分配的高斯姿态来获得（即使该点未被观测到）。实验表明，我们的方法优于仅依赖于寻找点对应关系的现有方法。此外，我们通过考虑视点遮挡来扩展现有数据集，以模拟真实世界场景。我们进一步证明，与现有方法相比，我们的方法在这些具有挑战性的数据集上对缺失点更具鲁棒性，即使在某些时间步长中某些部件完全被遮挡。值得注意的是，在存在遮挡的点云上，我们的部件分割性能优于最先进方法13%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [75] [DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)
> *DepthSync：基于扩散引导的深度同步，用于尺度和几何一致的视频深度估计*

*Yue-Jiang Dong, Wang Zhao, Jiale Xu, Ying Shan, Song-Hai Zhang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频深度估计, 扩散引导, 尺度一致性, 几何一致性, 长视频

**Comment:** 

> **TL;DR:** 现有基于扩散的视频深度估计方法在处理长视频时存在尺度和几何不一致问题。DepthSync提出了一种无需训练的框架，通过尺度和几何引导实现长视频的深度一致性预测。

**AI_Comments:** 该论文提出了一种创新的、无需训练的方法，解决了长视频深度估计中的关键挑战，特别是尺度和几何不一致性。其利用扩散引导，并专门设计尺度和几何项，巧妙地在不额外训练的情况下实现了3D一致性，这对于实际应用可能非常有益。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散的视频深度估计方法在处理长视频时面临两大挑战：一是将视频分割成重叠滑动窗口时，随着窗口数量的增加，会导致累积的尺度差异；二是这些方法仅依赖2D扩散先验，忽略了视频深度固有的3D几何结构，导致几何不一致的预测。

**Method:** 本文提出了DepthSync，一个新颖的、无需训练的框架，利用扩散引导实现尺度和几何一致的深度预测。具体引入了尺度引导来同步跨窗口的深度尺度，以及几何引导来基于视频深度固有的3D约束强制窗口内的几何对齐。这两个项协同工作，引导去噪过程趋向于一致的深度预测。

**Result:** 在各种数据集上的实验验证了DepthSync方法在生成具有改进的尺度和几何一致性的深度估计方面的有效性，特别是对于长视频。

**Conclusion:** 通过协同应用尺度引导和几何引导，本方法成功解决了长视频深度估计中的尺度和几何不一致问题，从而在去噪过程中实现了更一致的深度预测。

> **ai_Abstract:** DepthSync是一个新的无需训练的框架，旨在解决现有基于扩散的视频深度估计方法在处理长视频时出现的尺度和几何不一致问题。它通过引入尺度引导来同步不同视频窗口间的深度尺度，以及几何引导来利用视频深度固有的3D结构进行几何对齐，从而在去噪过程中协同作用，实现了尺度和几何一致的深度预测。实验证明DepthSync在长视频深度估计方面具有更好的尺度和几何一致性。

> **摘要翻译:** 基于扩散的视频深度估计方法取得了显著成功，具有强大的泛化能力。然而，预测长视频的深度仍然具有挑战性。现有方法通常将视频分割成重叠的滑动窗口，导致不同窗口之间累积的尺度差异，特别是随着窗口数量的增加。此外，这些方法仅依赖于2D扩散先验，忽略了视频深度固有的3D几何结构，从而导致几何不一致的预测。在本文中，我们提出了DepthSync，一个新颖的、无需训练的框架，利用扩散引导实现长视频的尺度和几何一致的深度预测。具体来说，我们引入了尺度引导来同步跨窗口的深度尺度，并引入几何引导来基于视频深度固有的3D约束强制窗口内的几何对齐。这两个项协同工作，引导去噪过程趋向于一致的深度预测。在各种数据集上的实验验证了我们方法在生成具有改进的尺度和几何一致性的深度估计方面的有效性，特别是对于长视频。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [81] [CLOT: Closed Loop Optimal Transport for Unsupervised Action Segmentation](https://arxiv.org/abs/2507.03539)
> *CLOT：用于无监督动作分割的闭环最优传输*

*Elena Bueno-Benito, Mariella Dimiccoli* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 最优传输, 无监督动作分割, 循环学习, 伪标签, 动作表示

**Comment:** 

> **TL;DR:** CLOT是一种新的基于最优传输的框架，通过多级循环特征学习机制，解决了无监督动作分割中缺乏片段级监督的问题，并在基准数据集上取得了良好效果。

**AI_Comments:** CLOT的创新之处在于引入了多级循环特征学习机制，并通过解决多个最优传输问题，有效地解决了无监督动作分割中片段级监督的缺失问题。其编解码器架构结合交叉注意力机制，实现了帧和片段嵌入的协同学习与细化，为无监督动作分割领域提供了一个有前景的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于最优传输的无监督动作分割方法（如ASOT）在分割结果中缺乏片段级监督，这限制了帧与动作表示之间反馈的有效性。

**Method:** 本文提出了闭环最优传输（CLOT），一个具有多级循环特征学习机制的新型基于最优传输的框架。CLOT利用其编解码器架构，通过解决两个独立的最优传输问题来学习伪标签以及帧和片段嵌入。然后，通过在学习到的帧和片段嵌入之间进行交叉注意力，并整合第三个最优传输问题，进一步细化帧嵌入和伪标签。

**Result:** 在四个基准数据集上的实验结果表明，循环学习对无监督动作分割有益。

**Conclusion:** CLOT通过引入多级循环特征学习机制和解决三个最优传输问题，有效解决了无监督动作分割中缺乏片段级监督的问题，并提高了分割性能。

> **ai_Abstract:** CLOT是一种新颖的基于最优传输（OT）的框架，旨在解决无监督动作分割中缺乏片段级监督的问题。该方法通过一个多级循环特征学习机制，利用其编解码器架构，通过解决两个独立的最优传输问题来学习帧和片段嵌入以及伪标签。随后，CLOT通过引入第三个OT问题和交叉注意力机制，进一步细化帧嵌入和伪标签。实验结果表明，该循环学习方法在无监督动作分割任务上表现出优越性。

> **摘要翻译:** 无监督动作分割最近通过ASOT（一种基于最优传输（OT）的方法）突破了其极限，该方法同时学习动作表示并使用伪标签执行聚类。与其他基于OT的方法不同，ASOT不对动作顺序做任何假设，并且可以从视频帧和动作标签之间的噪声成本矩阵中解码出时间一致的分割。然而，由此产生的分割缺乏片段级监督，限制了帧与动作表示之间反馈的有效性。为了解决这一限制，我们提出了闭环最优传输（CLOT），一个具有多级循环特征学习机制的新型基于OT的框架。CLOT利用其编解码器架构，通过解决两个独立的最优传输问题来学习伪标签以及帧和片段嵌入。然后，它通过整合第三个最优传输问题，在学习到的帧和片段嵌入之间进行交叉注意力，从而细化帧嵌入和伪标签。在四个基准数据集上的实验结果证明了循环学习对无监督动作分割的益处。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [88] [EchoMimicV3: 1.3B Parameters are All You Need for Unified Multi-Modal and Multi-Task Human Animation](https://arxiv.org/abs/2507.03905)
> *EchoMimicV3：13亿参数足以实现统一的多模态多任务人体动画*

*Rang Meng, Yan Wang, Weipeng Wu, Ruobing Zheng, Yuming Li, Chenguang Ma* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 人体动画, 多模态, 多任务, EchoMimicV3, 统一框架

**Comment:** 

> **TL;DR:** EchoMimicV3是一个高效的框架，通过创新的“任务之汤”和“模态之汤”范式，以及新的训练策略，以13亿参数实现了统一的多模态多任务人体动画，解决了现有方法速度慢、计算量大和多模型成本高的问题。

**AI_Comments:** 该论文的关键创新在于提出了“任务之汤”和“模态之汤”这两种范式，有效地统一了多任务和多模态人体动画，同时显著降低了模型参数量（仅13亿）。这对于提高实际应用中的推理速度和降低计算成本具有重要意义。通过整合新的训练策略，进一步保证了模型的稳定性和性能，为轻量级、多功能的人体动画模型提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人体动画方法通常依赖大型视频模型，导致推理速度慢、计算需求高。此外，传统方法为每个动画任务使用单独的模型，增加了多任务场景下的成本和复杂性。

**Method:** 本文提出了EchoMimicV3框架，其核心是三重设计：1. 任务之汤（Soup-of-Tasks）范式：利用多任务掩码输入和反直觉的任务分配策略，实现多任务增益。2. 模态之汤（Soup-of-Modals）范式：引入耦合-解耦多模态交叉注意力模块注入多模态条件，并通过多模态时间步相位感知动态分配机制调节多模态混合。3. 新的训练和推理策略：提出了负向直接偏好优化、相位感知负向无分类器指导（CFG）和长视频CFG，以确保训练和推理的稳定性。

**Result:** EchoMimicV3仅用13亿参数，在定量和定性评估中都取得了具有竞争力的性能。

**Conclusion:** EchoMimicV3成功地证明了通过创新的架构和训练策略，仅用13亿参数就能实现高效、统一的多模态多任务人体动画，解决了现有方法的效率和成本问题。

> **ai_Abstract:** EchoMimicV3是一个高效的框架，旨在解决当前人体动画领域中大型模型推理慢、计算成本高以及多任务场景下模型分散的问题。该框架通过其核心的“任务之汤”和“模态之汤”范式，结合创新的训练和推理策略，实现了多模态和多任务人体动画的统一。实验表明，EchoMimicV3仅用13亿参数就能在性能上与现有方法相媲美，展示了其在效率和统一性方面的优势。

> **摘要翻译:** 近期关于人体动画的工作通常整合了大规模视频模型，从而实现了更生动的表现。然而，此类方法的实际应用受到推理速度慢和计算需求高的阻碍。此外，传统工作通常为每个动画任务采用单独的模型，这增加了多任务场景下的成本并加剧了困境。为了解决这些限制，我们引入了EchoMimicV3，这是一个高效的框架，它统一了多任务和多模态人体动画。EchoMimicV3的核心是三重设计：任务之汤范式、模态之汤范式以及一种新颖的训练和推理策略。任务之汤利用多任务掩码输入和反直觉的任务分配策略，在不增加多模型负担的情况下实现了多任务增益。同时，模态之汤引入了耦合-解耦多模态交叉注意力模块以注入多模态条件，并辅以多模态时间步相位感知动态分配机制来调节多模态混合。此外，我们提出了负向直接偏好优化、相位感知负向无分类器指导（CFG）和长视频CFG，这些确保了训练和推理的稳定性。广泛的实验和分析表明，EchoMimicV3以13亿参数的最小模型尺寸，在定量和定性评估中都取得了具有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
> *NeuraLeaf：形状与变形解耦的神经参数化叶片模型*

*Yang Yang, Dongni Mao, Hiroaki Santo, Yasuyuki Matsushita, Fumio Okura* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 神经参数模型, 3D叶片建模, 形状解耦, 变形, 植物建模

**Comment:** 

> **TL;DR:** NeuraLeaf是一种新的神经参数化模型，用于3D叶片建模和重建，它将叶片几何形状解耦为2D基形和3D变形，并引入了无骨架蒙皮模型和新的3D叶片数据集。

**AI_Comments:** 该论文的创新点在于提出了将叶片几何形状解耦为2D基形和3D变形的神经参数化模型，这有效地利用了2D图像数据的丰富性来学习基形，并解决了3D叶片建模的复杂性。新颖的无骨架蒙皮模型和新数据集DeformLeaf的创建也为该领域的研究提供了宝贵的资源。该方法对于植物学、农业和计算机图形学领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经参数化模型在处理植物叶片时面临挑战，因为叶片形状多样且变形灵活。植物建模和重建对农业和计算机图形学至关重要。

**Method:** 本文引入了名为NeuraLeaf的神经参数化叶片模型。该模型将叶片几何形状解耦为2D基形和3D变形，利用叶片展平后可近似为2D平面的特性。2D基形可以从丰富的2D叶片图像数据集中学习，并同时学习与几何对齐的纹理。为建模3D变形，提出了一种新颖的无骨架蒙皮模型，并创建了一个名为DeformLeaf的新捕获的3D叶片数据集。

**Result:** NeuraLeaf成功生成了各种具有变形的叶片形状，并能准确拟合3D观测数据（如深度图和点云）。

**Conclusion:** NeuraLeaf提供了一种有效的方法来应对3D叶片建模和重建的挑战，通过解耦形状和变形，并利用2D和3D数据源，实现了准确的叶片生成和拟合。

> **ai_Abstract:** 本文提出了一种名为NeuraLeaf的神经参数化模型，用于3D叶片的建模与重建。该模型通过将叶片几何形状解耦为2D基形和3D变形，有效解决了叶片形状多样和变形灵活的挑战。NeuraLeaf利用2D叶片图像数据集学习基形，并引入了新颖的无骨架蒙皮模型来处理3D变形，同时发布了新的DeformLeaf 3D叶片数据集。实验结果表明，NeuraLeaf能够成功生成多种叶片形状及其变形，并能准确拟合3D观测数据。

> **摘要翻译:** 我们开发了一种用于植物建模和重建的3D叶片神经参数模型，这对于农业和计算机图形学至关重要。虽然神经参数模型在人类和动物领域得到了积极研究，但植物叶片由于其多样的形状和灵活的变形而带来了独特的挑战。针对这个问题，我们引入了一种神经参数叶片模型——NeuraLeaf。利用展平的叶片形状可以近似为2D平面的事实，NeuraLeaf将叶片的几何形状解耦为它们的2D基本形状和3D变形。这种表示允许从丰富的2D叶片图像数据集中学习基本形状，并且还具有同时学习与几何对齐的纹理的优势。为了建模3D变形，我们提出了一种新颖的无骨架蒙皮模型，并创建了一个新捕获的3D叶片数据集，名为DeformLeaf。我们展示了NeuraLeaf成功生成了各种具有变形的叶片形状，从而实现了对深度图和点云等3D观测数据的准确模型拟合。我们的实现和数据集可在https://neuraleaf-yang.github.io/获得。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [103] [GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution](https://arxiv.org/abs/2507.18998)
> *GPSMamba：一种用于红外图像超分辨率的全局相位和光谱提示引导Mamba模型*

*Yongsong Huang, Tomo Miyazaki, Shinichiro Omachi* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 红外图像超分辨率, 状态空间模型, Mamba, 全局相位, 光谱提示

**Comment:** 

> **TL;DR:** GPSMamba通过引入全局相位和光谱提示以及非因果监督，解决了Mamba模型在红外图像超分辨率中因1D因果扫描导致的全局上下文碎片化问题，实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于系统性地解决了Mamba模型在处理2D图像时因其1D因果扫描机制导致的全局上下文碎片化问题。通过结合语义-频率提示引导和非因果监督（特别是热光谱注意力和相位一致性损失），GPSMamba为红外图像超分辨率提供了一种新颖且有效的解决方案，成功地将状态空间模型应用于需要全局信息保持的任务，突破了现有Mamba模型在图像任务中的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 红外图像超分辨率（IRSR）面临低对比度和稀疏纹理的挑战，需要强大的长程建模来保持全局一致性。Mamba等状态空间模型虽然擅长建模长程依赖，但其固有的1D因果扫描机制会破坏2D图像的全局上下文，从而阻碍细节恢复。

**Method:** 本文提出了全局相位和光谱提示引导Mamba (GPSMamba) 框架，该框架结合了架构引导和非因果监督。首先，自适应语义-频率状态空间模块 (ASF-SSM) 将融合的语义-频率提示直接注入Mamba块，以整合非局部上下文并指导重建。其次，新颖的热光谱注意力和相位一致性损失提供了显式的非因果监督，以增强全局结构和光谱保真度。

**Result:** 广泛的实验表明，GPSMamba实现了最先进的性能，验证了其作为红外图像恢复强大新范式的有效性。

**Conclusion:** GPSMamba通过系统地结合架构引导和非因果监督，成功缓解了因果建模的局限性，为红外图像恢复提供了一个强大的新范式。

> **ai_Abstract:** GPSMamba是一个针对红外图像超分辨率的新框架，旨在解决Mamba模型因1D因果扫描导致的全局上下文碎片化问题。它通过引入自适应语义-频率状态空间模块（ASF-SSM）来注入融合的语义-频率提示，以及通过热光谱注意力和相位一致性损失来提供非因果监督，从而有效整合非局部上下文并增强全局保真度。该方法在红外图像恢复中达到了最先进的性能。

> **摘要翻译:** 红外图像超分辨率（IRSR）面临红外数据低对比度和稀疏纹理的挑战，需要强大的长程建模以保持全局一致性。尽管Mamba等状态空间模型在此任务中展现出建模长程依赖的能力，但其固有的1D因果扫描机制会碎片化2D图像的全局上下文，从而阻碍精细细节的恢复。为解决此问题，我们提出了全局相位和光谱提示引导Mamba（GPSMamba），一个结合了架构引导和非因果监督的框架。首先，我们的自适应语义-频率状态空间模块（ASF-SSM）将融合的语义-频率提示直接注入Mamba块，整合非局部上下文以指导重建。然后，一种新颖的热光谱注意力和相位一致性损失提供了显式的非因果监督，以强制执行全局结构和光谱保真度。通过结合这两项创新，我们的工作提出了一种系统策略来缓解因果建模的局限性。广泛的实验表明，GPSMamba实现了最先进的性能，验证了我们的方法作为红外图像恢复强大新范式的有效性。代码可在https://github.com/yongsongH/GPSMamba获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [109] [Learning Only with Images: Visual Reinforcement Learning with Reasoning, Rendering, and Visual Feedback](https://arxiv.org/abs/2507.20766)
> *仅凭图像学习：通过推理、渲染和视觉反馈进行的视觉强化学习*

*Yang Chen, Yufan Shen, Wenxuan Huang, Sheng Zhou, Qunshu Lin, Xinyu Cai, Zhi Yu, Jiajun Bu, Botian Shi, Yu Qiao* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉强化学习, 多模态大型语言模型, 视觉推理, 图像到代码, 视觉反馈

**Comment:** 

> **TL;DR:** 本文提出了一种名为RRVF的新框架，使多模态大型语言模型（MLLMs）能够仅从原始图像中学习复杂的视觉推理，通过利用验证的不对称性作为强化学习的奖励信号，减少对图像-文本监督的依赖，并在图像到代码生成任务上取得了SOTA性能。

**AI_Comments:** 本文提出了一种创新性的方法，通过强化学习和视觉反馈机制，成功地使MLLMs摆脱了对昂贵图像-文本监督的依赖，实现了仅凭图像进行深度视觉推理。其核心的“验证的不对称性”原则是一个巧妙的设计，将验证过程的相对简易性转化为有效的奖励信号，这对于推动MLLMs在真实世界应用中的自主学习能力具有重要意义。在图像到代码生成任务上的优异表现和泛化能力进一步证明了该方法的有效性，尤其是在超越更先进模型方面，凸显了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）在深度视觉推理方面的一个关键瓶颈是它们严重依赖于精心策划的图像-文本监督。

**Method:** 本文引入了一种名为“推理-渲染-视觉-反馈”（RRVF）的新颖框架，使MLLMs能够仅从原始图像中学习复杂的视觉推理。该框架基于“验证的不对称性”原则，即验证渲染输出与源图像相比，比执行深度视觉推理以生成忠实的结构化表示（如代码）要容易得多。这种相对容易性为通过强化学习（RL）进行优化提供了理想的奖励信号，从而减少了对图像-文本监督的依赖。RRVF实现了包括推理、渲染和视觉反馈组件的闭环迭代过程，使模型能够通过多轮交互进行复杂的推理，包括自我纠正。这个过程使用GRPO算法进行端到端优化。

**Result:** RRVF训练的模型不仅优于现有类似规模的开源MLLMs和监督微调基线，而且表现出卓越的泛化能力。值得注意的是，该模型甚至超越了在训练期间用于生成视觉反馈的更先进的MLLM。

**Conclusion:** RRVF框架通过利用视觉反馈和强化学习，成功地解决了多模态大型语言模型在深度视觉推理中对图像-文本监督的依赖问题，实现了仅凭图像学习复杂视觉推理的能力，并在图像到代码生成任务上取得了显著的性能提升和更好的泛化能力。

> **ai_Abstract:** 本文提出了一种名为“推理-渲染-视觉-反馈”（RRVF）的新型框架，旨在解决多模态大型语言模型（MLLMs）在深度视觉推理中对大量图像-文本监督的依赖问题。RRVF利用“验证的不对称性”原则，将验证渲染输出与源图像的匹配度作为强化学习的奖励信号，从而使MLLMs能够仅从原始图像中学习复杂的视觉推理。该框架通过一个包含推理、渲染和视觉反馈的闭环迭代过程进行优化。实验结果表明，RRVF训练的模型在图像到代码生成任务上，不仅超越了现有的MLLMs和监督基线，还展现出优越的泛化能力，甚至超越了其训练中用于生成视觉反馈的更先进模型。

> **摘要翻译:** 多模态大型语言模型（MLLMs）在各种视觉任务中表现出令人印象深刻的性能。随后对增强其视觉推理能力的研究显著扩展了它们的性能范围。然而，MLLMs在向深度视觉推理发展中的一个关键瓶颈是它们严重依赖于精心策划的图像-文本监督。为了解决这个问题，我们引入了一种新颖的框架，“推理-渲染-视觉-反馈”（RRVF），它使MLLMs能够仅从原始图像中学习复杂的视觉推理。该框架建立在“验证的不对称性”原则之上，即验证渲染输出与源图像相比，比执行深度视觉推理以生成忠实的、结构化表示（如代码）要容易得多。我们证明了这种相对容易性为通过强化学习（RL）进行优化提供了理想的奖励信号，从而减少了对图像-文本监督的依赖。RRVF实现了包括推理、渲染和视觉反馈组件的闭环迭代过程，使模型能够进行复杂的推理，包括通过多轮交互进行自我纠正。这个过程使用GRPO算法进行端到端优化。在数据图表和网页界面这两个不同领域的图像到代码生成方面进行了广泛的评估。RRVF训练的模型不仅优于现有类似规模的开源MLLMs和监督微调基线，而且表现出卓越的泛化能力。值得注意的是，该模型甚至超越了在训练期间用于生成视觉反馈的更先进的MLLM。代码可在https://github.com/L-O-I/RRVF获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [116] [Few-Shot Vision-Language Reasoning for Satellite Imagery via Verifiable Rewards](https://arxiv.org/abs/2507.21745)
> *通过可验证奖励实现卫星图像的少样本视觉-语言推理*

*Aybora Koksal, A. Aydin Alatan* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 少样本学习, 视觉-语言推理, 卫星图像, 强化学习, 可验证奖励

**Comment:** 

> **TL;DR:** 本文提出了一种名为RLVR的少样本强化学习框架，通过使用轻量级、基于规则的奖励，解决了卫星图像领域数据稀缺的问题，并在少至一个示例的情况下实现了显著的性能提升。

**AI_Comments:** 这项工作在数据稀缺的遥感领域引入了一种创新的少样本强化学习方法，通过利用可验证奖励而非昂贵的标注数据，极大地降低了模型开发的成本和对数据的依赖。其创新性在于将“1-shot RLVR”范式应用于视觉-语言模型，并证明了在极少数据下也能实现强大的性能提升，这对于专业领域具有重要意义。该方法为未来在类似数据受限领域开发高效的视觉-语言模型提供了实用的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言模型在遥感等专业领域不实用，因为这些领域的标注数据稀缺且昂贵。

**Method:** 本文提出了首个用于卫星图像的少样本可验证奖励强化学习（RLVR）框架。该框架无需标注监督，仅依赖轻量级、基于规则的二元或IoU奖励。通过将“1-shot RLVR”范式从语言模型应用于视觉-语言模型，使用策略梯度优化，并仅需少量（甚至一个）精心策划的示例来对齐模型输出，以执行卫星推理任务。

**Result:** 在包括分类、视觉问答和接地等多个遥感基准测试中进行的综合实验表明，即使单个示例也能比基础模型带来实质性改进。扩展到128个示例时，性能与在数千个标注样本上训练的模型相匹配或超越。尽管极端的一样本设置可能会导致轻微的、任务特定的过拟合，但该方法在不同任务中始终表现出强大的泛化能力和效率。此外，还发现提示设计和损失加权显著影响训练稳定性和最终准确性。

**Conclusion:** 本文提出的方法能够经济高效、数据高效地开发领域专家视觉-语言推理模型，为数据稀缺领域提供了一个实用的方案：从紧凑型VLM开始，策划少量可检查奖励的案例，并通过RLVR进行训练。

> **ai_Abstract:** 本文提出了一种名为RLVR的少样本强化学习框架，用于卫星图像的视觉-语言推理。该框架通过使用轻量级、基于规则的可验证奖励，解决了遥感领域标注数据稀缺的问题。实验证明，即使仅用一个示例，RLVR也能显著提升模型性能，并在使用128个示例时达到或超越传统模型在数千个标注数据上的表现，展现出强大的泛化能力和数据效率，为数据受限领域提供了实用的解决方案。

> **摘要翻译:** 大型语言和视觉-语言模型的最新进展使得强大的推理能力成为可能，但对于遥感等专业领域来说，它们仍然不切实际，因为这些领域的标注数据稀缺且昂贵。我们提出了首个用于卫星图像的少样本可验证奖励强化学习（RLVR）框架，该框架消除了对字幕监督的需求——仅依赖轻量级、基于规则的二元或IoU奖励。通过将“1-shot RLVR”范式从语言模型应用于视觉-语言模型，我们使用策略梯度优化，并仅需少量精心策划的示例来对齐模型输出，以执行卫星推理任务。在包括分类、视觉问答和接地等多个遥感基准测试中进行的综合实验表明，即使单个示例也能比基础模型带来实质性改进。扩展到128个示例时，性能与在数千个标注样本上训练的模型相匹配或超越。尽管极端的一样本设置可能会导致轻微的、任务特定的过拟合，但我们的方法在不同任务中始终表现出强大的泛化能力和效率。此外，我们发现提示设计和损失加权显著影响训练稳定性和最终准确性。我们的方法能够经济高效、数据高效地开发领域专家视觉-语言推理模型，为数据稀缺领域提供了一个实用的方案：从紧凑型VLM开始，策划少量可检查奖励的案例，并通过RLVR进行训练。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [124] [Patho-AgenticRAG: Towards Multimodal Agentic Retrieval-Augmented Generation for Pathology VLMs via Reinforcement Learning](https://arxiv.org/abs/2508.02258)
> *Patho-AgenticRAG：通过强化学习实现病理学VLM的多模态智能体检索增强生成*

*Wenchuan Zhang, Jingru Guo, Hengzhe Zhang, Penghao Zhang, Jie Chen, Shuwan Zhang, Zhang Zhang, Yuhao Yi, Hong Bu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 病理学VLM, 多模态RAG, 检索增强生成, 幻觉, 文本-图像搜索

**Comment:** 

> **TL;DR:** Patho-AgenticRAG是一个多模态RAG框架，通过结合文本和图像搜索以及智能体能力，解决了病理学VLM的幻觉问题，并在复杂病理任务中表现出色。

**AI_Comments:** Patho-AgenticRAG的创新点在于其多模态检索能力，尤其是在病理学这种视觉信息至关重要的领域。通过结合页面级嵌入和联合文本-图像搜索，它有效地解决了传统RAG方法忽视视觉线索的问题，并增强了VLM在复杂病理任务中的可靠性。其引入的智能体能力（推理、任务分解、多轮交互）也提升了系统的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉语言模型（VLM）在医学影像方面表现出强大的泛化能力，但病理学因其超高分辨率、复杂的组织结构和细致的临床语义而带来独特挑战，导致病理学VLM容易产生幻觉，即生成与视觉证据不符的输出，从而损害临床信任。现有RAG方法主要依赖于文本知识库，限制了其利用诊断视觉线索的能力。

**Method:** 本文提出了Patho-AgenticRAG，一个多模态RAG框架。它构建了一个基于权威病理学教科书页面级嵌入的数据库，支持联合文本-图像搜索，能够直接检索包含查询文本和相关视觉线索的教科书页面，从而避免关键图像信息的丢失。Patho-AgenticRAG还支持推理、任务分解和多轮搜索交互。

**Result:** 实验表明，Patho-AgenticRAG在多项选择诊断和视觉问答等复杂病理任务中显著优于现有多模态模型。

**Conclusion:** Patho-AgenticRAG通过其多模态检索能力和智能体特性，有效解决了病理学VLM的幻觉问题，并在复杂诊断场景中提高了准确性。

> **ai_Abstract:** 本文提出了Patho-AgenticRAG，一个针对病理学视觉语言模型（VLM）的多模态检索增强生成（RAG）框架，旨在解决VLM在病理领域因高分辨率图像和复杂语义导致的幻觉问题。该框架构建了一个基于权威病理学教科书页面级嵌入的数据库，支持联合文本-图像搜索，从而在检索时保留关键视觉信息。Patho-AgenticRAG还具备推理、任务分解和多轮搜索交互能力。实验结果表明，Patho-AgenticRAG在多项选择诊断和视觉问答等复杂病理任务中显著优于现有模型，提升了病理诊断的准确性和可靠性。

> **摘要翻译:** 尽管视觉语言模型（VLM）在医学影像方面表现出强大的泛化能力，但病理学因其超高分辨率、复杂的组织结构和细致的临床语义而带来独特的挑战。这些因素使得病理学VLM容易产生幻觉，即生成与视觉证据不符的输出，这损害了临床信任。该领域现有的RAG方法主要依赖于文本知识库，限制了它们利用诊断视觉线索的能力。为了解决这个问题，我们提出了Patho-AgenticRAG，一个多模态RAG框架，其数据库建立在权威病理学教科书的页面级嵌入之上。与传统的纯文本检索系统不同，它支持联合文本-图像搜索，能够直接检索包含查询文本和相关视觉线索的教科书页面，从而避免了关键图像信息的丢失。Patho-AgenticRAG还支持推理、任务分解和多轮搜索交互，提高了在复杂诊断场景中的准确性。实验表明，Patho-AgenticRAG在多项选择诊断和视觉问答等复杂病理任务中显著优于现有多模态模型。我们的项目可在Patho-AgenticRAG仓库获取：https://github.com/Wenchuan-Zhang/Patho-AgenticRAG。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [131] [EgoPrompt: Prompt Learning for Egocentric Action Recognition](https://arxiv.org/abs/2508.03266)
> *EgoPrompt：第一人称动作识别的提示学习*

*Huaihai Lyu, Chaofan Chen, Yuheng Ji, Changsheng Xu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 第一人称动作识别, 提示学习, 统一提示池, 动词名词组件, 泛化能力

**Comment:** 

> **TL;DR:** EgoPrompt提出了一种基于提示学习的框架，通过构建统一提示池空间来融合动词和名词组件，从而解决了第一人称动作识别中现有方法忽略组件间关系导致表示碎片化的问题，并在多个基准测试中取得了最先进的性能。

**AI_Comments:** EgoPrompt的创新点在于其提出了一种新颖的提示学习框架，通过构建统一提示池空间和引入多样化池标准，有效解决了第一人称动作识别中动词和名词组件之间关系被忽视的挑战。这种方法不仅提升了模型对复杂动作的理解能力，也显著增强了其泛化性能，对于推动第一人称视觉领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有第一人称动作识别方法通常将动词和名词组件视为独立的分类任务，忽略了它们固有的语义和上下文关系，导致表示碎片化和泛化能力欠佳。为了解决这些挑战，并满足增强现实和虚拟现实应用日益增长的需求，本文提出了EgoPrompt。

**Method:** 本文提出了一个名为EgoPrompt的基于提示学习的框架。它在现有提示策略的基础上，构建了一个统一提示池空间来建立动词和名词组件表示之间的交互。具体而言，组件表示被分解为提示对形式的细粒度模式，然后通过基于注意力的机制融合这些模式级表示。此外，为确保提示池的信息量，引入了一种新颖的训练目标——多样化池标准，通过提示选择频率正则化和提示知识正交化来实现。

**Result:** EgoPrompt在Ego4D、EPIC-Kitchens和EGTEA数据集上进行了广泛实验，结果一致表明其在数据集内、跨数据集和从基础到新颖的泛化基准测试中均实现了最先进的性能。

**Conclusion:** EgoPrompt通过有效融合动词和名词组件的表示，克服了现有第一人称动作识别方法的局限性，显著提升了模型在多种泛化场景下的性能，达到了领域内的最先进水平。

> **ai_Abstract:** 本文针对第一人称动作识别中动词和名词组件独立处理导致表示碎片化和泛化能力差的问题，提出了一个名为EgoPrompt的基于提示学习的框架。EgoPrompt通过构建统一提示池空间，将组件表示分解为细粒度模式并进行融合，以建立组件间的语义和上下文关系。为确保提示池的有效性，引入了多样化池标准。实验结果表明，EgoPrompt在多个基准测试中均达到了最先进的性能。

> **摘要翻译:** 随着增强现实和虚拟现实应用需求的日益增长，第一人称动作识别已成为一个突出的研究领域。它通常分为两个子任务：识别执行的行为（即动词组件）和识别被作用的对象（即名词组件）。然而，大多数现有方法将这两个组件视为独立的分类任务，侧重于提取组件特定的知识，同时忽略了它们固有的语义和上下文关系，导致表示碎片化和次优的泛化能力。为了应对这些挑战，我们提出了一种基于提示学习的框架EgoPrompt来执行第一人称动作识别任务。在现有提示策略的基础上，为捕获组件特定知识，我们构建了一个统一提示池空间来建立两类组件表示之间的交互。具体而言，组件表示（来自动词和名词）首先以提示对的形式分解为细粒度模式。然后，这些模式级表示通过基于注意力的机制进行融合，以促进跨组件交互。为了确保提示池的信息量，我们进一步引入了一种新颖的训练目标，即多样化池标准。该目标从两个角度实现了我们的目标：提示选择频率正则化和提示知识正交化。在Ego4D、EPIC-Kitchens和EGTEA数据集上进行了广泛的实验。结果一致表明，EgoPrompt在数据集内、跨数据集以及从基础到新颖的泛化基准测试中均实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [138] [Modular Transformer Architecture for Precision Agriculture Imaging](https://arxiv.org/abs/2508.03751)
> *模块化Transformer架构在精准农业影像中的应用*

*Brian Gopalan, Nathalia Nascimento, Vishal Monga* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 精准农业, 杂草分割, Transformer, 图像退化, 深度学习

**Comment:** 

> **TL;DR:** 提出了一种模块化Transformer架构，通过分析图像质量（模糊和噪声）并动态路由到专门的Transformer模型进行处理，从而提高精准农业中杂草分割的效率和准确性。

**AI_Comments:** 这篇论文的创新点在于其质量感知的模块化设计和动态路由策略，有效地解决了精准农业图像中常见的图像退化问题。通过将不同的Transformer模型专门用于处理特定类型的图像质量问题，该系统显著提升了性能和效率，为实际应用提供了更鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 精准农业中从无人机视频中高效准确地分割杂草的需求，以及现有方法在图像退化（模糊和噪声）情况下的不足。

**Method:** 本文提出了一种质量感知的模块化深度学习框架。该系统首先使用平均绝对偏差和拉普拉斯算子分析无人机图像的噪声和模糊。然后，数据被动态路由到三种视觉Transformer模型之一：用于清晰图像的基线模型，用于降噪的带有Fisher向量编码的改进Transformer模型，或用于校正模糊的带有展开Lucy-Richardson解码器的Transformer模型。

**Result:** 该新颖的路由策略使系统在分割质量和计算效率方面均优于现有的基于CNN的方法。

**Conclusion:** 该研究在农业深度学习应用方面取得了重大进展，通过处理图像退化提高了杂草分割的准确性和效率。

> **ai_Abstract:** 本文提出了一种用于精准农业杂草分割的模块化Transformer架构。该框架能够识别无人机图像中的模糊和噪声等退化，并智能地将图像路由到专门的Transformer模型进行处理。这种方法在分割质量和计算效率上均超越了传统的CNN方法，为农业领域的深度学习应用带来了显著改进。

> **摘要翻译:** 这篇论文旨在解决精准农业中无人机视频高效准确的杂草分割这一关键需求。文章提出了一种质量感知的模块化深度学习框架，该框架通过分析模糊和噪声等质量条件来解决常见的图像退化问题，并将输入路由到针对每种退化类型优化的专门预处理和Transformer模型。该系统首先使用平均绝对偏差和拉普拉斯算子分析无人机图像的噪声和模糊。然后，数据被动态路由到三种视觉Transformer模型之一：用于清晰图像的基线模型，用于降噪的带有Fisher向量编码的改进Transformer模型，或用于校正模糊的带有展开Lucy-Richardson解码器的Transformer模型。这种新颖的路由策略使该系统在分割质量和计算效率方面均优于现有的基于CNN的方法，这表明在农业深度学习应用方面取得了重大进展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [S$^2$Q-VDiT: Accurate Quantized Video Diffusion Transformer with Salient Data and Sparse Token Distillation](https://arxiv.org/abs/2508.04016)
> *S$^2$Q-VDiT：基于显著数据和稀疏令牌蒸馏的精确量化视频扩散Transformer*

*Weilun Feng, Haotong Qin, Chuanguang Yang, Xiangqi Li, Han Yang, Yuqi Li, Zhulin An, Libo Huang, Michele Magno, Yongjun Xu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频扩散Transformer, 量化, 显著数据选择, 稀疏令牌蒸馏, 模型压缩

**Comment:** 

> **TL;DR:** S$^2$Q-VDiT提出了一种后训练量化框架，通过显著数据选择和稀疏令牌蒸馏，实现了视频扩散Transformer的无损性能和显著加速与压缩。

**AI_Comments:** 这篇论文的创新点在于其提出的两种核心策略：Hessian感知显著数据选择和注意力引导稀疏令牌蒸馏，它们专门针对视频扩散模型量化中的独特挑战。通过结合扩散和量化特性来选择校准数据，并利用注意力机制优化令牌处理，该方法有效地平衡了性能、模型大小和推理速度，对于实际部署大型视频生成模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视频扩散Transformer模型参数量巨大，导致计算成本高昂。此外，视频中空间和时间信息的联合建模产生极长的令牌序列，引入了高校准方差和学习挑战。

**Method:** 提出S$^2$Q-VDiT，一个针对视频扩散模型（V-DMs）的后训练量化框架，其核心是显著数据和稀疏令牌蒸馏。具体包括：1. Hessian-aware Salient Data Selection：通过考虑V-DMs特有的扩散和量化特性，构建高质量的校准数据集，以降低量化性能对校准数据选择的敏感性。2. Attention-guided Sparse Token Distillation：基于V-DMs中固有的稀疏注意力模式，利用令牌级的注意力分布来强调对模型输出更有影响的令牌，以解决学习挑战。

**Result:** 在W4A6量化下，S$^2$Q-VDiT实现了无损性能，同时模型压缩比达到3.9倍，推理加速达到1.3倍。

**Conclusion:** S$^2$Q-VDiT通过创新的显著数据选择和稀疏令牌蒸馏方法，有效解决了视频扩散Transformer量化过程中的挑战，实现了显著的模型压缩和推理加速，同时保持了性能。

> **ai_Abstract:** 本文提出了S$^2$Q-VDiT，一个针对参数量庞大的视频扩散Transformer的后训练量化框架。该框架通过引入Hessian感知显著数据选择来优化校准数据集，并利用注意力引导稀疏令牌蒸馏来应对长令牌序列带来的学习挑战。S$^2$Q-VDiT在W4A6量化下实现了无损性能，同时显著压缩了模型并加速了推理。

> **摘要翻译:** 扩散Transformer已成为视频生成模型的主流范式。然而，使用多达数十亿的参数会产生巨大的计算成本。量化通过减少内存使用和加速推理提供了一个有前景的解决方案。尽管如此，我们观察到视频扩散模型（V-DMs）中空间和时间信息的联合建模导致了极长的令牌序列，这引入了高校准方差和学习挑战。为了解决这些问题，我们提出了S$^2$Q-VDiT，一个针对V-DMs的后训练量化框架，它利用显著数据和稀疏令牌蒸馏。在校准阶段，我们发现量化性能对校准数据的选择高度敏感。为了缓解这个问题，我们引入了Hessian感知显著数据选择，通过考虑V-DMs特有的扩散和量化特性来构建高质量的校准数据集。为了应对学习挑战，我们进一步分析了V-DMs中固有的稀疏注意力模式。基于这一观察，我们提出了注意力引导稀疏令牌蒸馏，它利用令牌级的注意力分布来强调对模型输出更有影响的令牌。在W4A6量化下，S$^2$Q-VDiT实现了无损性能，同时实现了3.9倍的模型压缩和1.3倍的推理加速。代码将在https://github.com/wlfeng0509/s2q-vdit 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [151] [TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding](https://arxiv.org/abs/2508.04369)
> *TSPO：长视频语言理解的时间采样策略优化*

*Canhui Tang, Zifan Han, Hongbo Sun, Sanping Zhou, Xuchong Zhang, Xin Wei, Ye Yuan, Jinglin Xu, Hao Sun* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 时间采样, 强化学习, 长视频, MLLMs, 视频语言理解

**Comment:** 

> **TL;DR:** TSPO通过强化学习优化长视频的时间采样策略，以提升多模态大语言模型（MLLMs）在长视频理解上的性能，解决了现有方法在处理长视频时因上下文限制和训练成本带来的挑战。

**AI_Comments:** 本文的创新之处在于利用强化学习解决长视频理解中稀疏帧采样这一无监督且不可微分的难题，并将其与语言生成结合为联合决策过程，突破了传统采样的局限性。其提出的事件感知时间代理、独特的强化学习范式、专门的数据构建流水线以及基于规则的奖励机制，共同构建了一个高效且可迁移的解决方案。这对于推动MLLMs在真实世界长视频应用中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在处理长视频输入时面临上下文限制和训练成本的挑战，需要稀疏帧采样。现有方法（统一采样或关键帧搜索）可能错过关键事件或受限于预训练模型的能力。同时，由于稀疏帧采样的无监督和不可微分性质，构建基于训练的方法仍然具有挑战性。

**Method:** 提出时间采样策略优化（TSPO），通过强化学习提升MLLMs的长视频语言理解能力。具体来说，首先提出一个可训练的事件感知时间代理，捕捉事件-查询关联以进行概率性关键帧选择。然后，提出TSPO强化学习范式，将关键帧选择和语言生成建模为联合决策过程，通过高效的基于规则的奖励实现端到端的组相对优化。此外，为TSPO的训练，提出一个长视频训练数据构建流水线，包含全面的时间数据和视频“大海捞针”数据。最后，结合基于规则的回答准确性和时间定位奖励机制来优化时间采样策略。

**Result:** TSPO在多个长视频理解基准上取得了最先进的性能，并显示出对不同尖端视频-MLLMs的迁移能力。

**Conclusion:** TSPO通过强化学习优化时间采样策略，有效地解决了多模态大语言模型在长视频理解方面的挑战，实现了最先进的性能和良好的迁移能力。

> **ai_Abstract:** 该论文提出了时间采样策略优化（TSPO），一个基于强化学习的框架，旨在解决多模态大语言模型（MLLMs）在处理长视频时因上下文限制和训练成本导致的稀疏帧采样挑战。TSPO通过引入一个可训练的事件感知时间代理进行概率性关键帧选择，并将关键帧选择与语言生成建模为联合决策过程，实现了端到端的优化。此外，论文还提出了专门的长视频训练数据构建方法和基于规则的奖励机制。实验证明，TSPO在多个长视频理解基准上达到了最先进的性能，并展现了良好的模型迁移能力。

> **摘要翻译:** 多模态大语言模型（MLLMs）在视觉-语言任务中取得了显著进展，但在处理长时程视频输入时仍面临挑战。这种限制源于MLLMs的上下文限制和训练成本，因此在将视频输入到MLLMs之前需要进行稀疏帧采样。现有的视频MLLMs采用无需训练的均匀采样或关键帧搜索，这可能会错过关键事件或受限于预训练模型的事件理解能力。同时，由于稀疏帧采样的无监督和不可微分性质，构建基于训练的方法仍然具有挑战性。为了解决这些问题，我们提出了时间采样策略优化（TSPO），通过强化学习提升MLLMs的长视频语言理解能力。具体来说，我们首先提出了一个可训练的事件感知时间代理，它捕捉事件-查询关联以执行概率性关键帧选择。然后，我们提出了TSPO强化学习范式，它将关键帧选择和语言生成建模为联合决策过程，通过高效的基于规则的奖励实现端到端的组相对优化。此外，为了TSPO的训练，我们提出了一个长视频训练数据构建流水线，包含全面的时间数据和视频“大海捞针”数据。最后，我们结合基于规则的回答准确性和时间定位奖励机制来优化时间采样策略。全面的实验表明，我们的TSPO在多个长视频理解基准上取得了最先进的性能，并显示出对不同尖端视频-MLLMs的迁移能力。我们的代码可在 https://github.com/Hui-design/TSPO 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [159] [ANPrompt: Anti-noise Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2508.04677)
> *ANPrompt：视觉-语言模型的抗噪声提示调优*

*Yansheng Gao, Yufei Zheng, Jinghan Qu, Zixi Zhu, Yukuan Zhang, Shengsheng Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 提示调优, 视觉-语言模型, 抗噪声, 鲁棒性, 语义扰动

**Comment:** 

> **TL;DR:** ANPrompt 是一种新的提示调优框架，通过融合噪声文本特征和引入抗噪声提示，并结合新的损失函数，显著提高了视觉-语言模型对语义噪声的鲁棒性和泛化能力。

**AI_Comments:** ANPrompt的创新在于其多方面的抗噪声策略，包括在文本特征层面引入噪声、生成抗噪声提示并深层注入，以及设计专门的损失函数（WALoss）来增强鲁棒性。这对于提升视觉-语言模型在实际应用中的可靠性具有重要意义，尤其是在数据可能存在噪声的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有提示调优方法忽略了视觉-语言模型对弱语义扰动（如细微的图像或文本噪声）的脆弱性，这会降低它们对未见类别的泛化能力。

**Method:** ANPrompt 首先通过融合原始和噪声扰动文本嵌入来构建弱噪声文本特征，然后将这些特征聚类形成噪声提示。这些噪声提示与可学习提示令牌集成以生成抗噪声提示，并注入到图像和文本编码器的更深层。它还通过平均视觉编码器输出的提示令牌来计算噪声抵抗视觉提示原型（NRVPP），并引入对齐、鲁棒性和抗噪声目标，通过计算弱语义噪声对齐损失（WALoss）以及标准交叉熵和相似性损失。

**Result:** 在11个基准测试中，ANPrompt 始终优于现有提示调优方法，实现了对语义噪声的卓越鲁棒性，并提高了对新类别的泛化能力。

**Conclusion:** ANPrompt 有效地解决了现有提示调优方法在面对弱语义扰动时的鲁棒性问题，显著提升了视觉-语言模型在噪声环境下的性能和泛化能力。

> **ai_Abstract:** 本文提出了ANPrompt，一种针对视觉-语言模型的新型抗噪声提示调优框架，旨在解决现有方法在弱语义扰动下鲁棒性差的问题。ANPrompt通过构建噪声文本特征、生成抗噪声提示并将其注入模型深层，同时引入噪声抵抗视觉提示原型和弱语义噪声对齐损失（WALoss）等多个损失目标，显著提升了模型对语义噪声的鲁棒性和对新类别的泛化能力，并在多个基准测试中表现优异。

> **摘要翻译:** 提示调优已成为一种高效且有效的技术，以较低的计算开销适应视觉-语言模型（VLMs）。然而，现有方法通常忽视了提示调优的VLMs对弱语义扰动（如细微的图像或文本噪声）的脆弱性，这会降低它们对未见类别的泛化能力。为了解决这一限制，我们提出了ANPrompt，一种新颖的提示调优框架，旨在增强在此类扰动下的鲁棒性。ANPrompt首先通过融合原始和噪声扰动文本嵌入来构建弱噪声文本特征，然后将这些特征聚类形成噪声提示。这些噪声提示与可学习提示令牌集成以生成抗噪声提示，并注入到图像和文本编码器的更深层。为了进一步捕获噪声感知的视觉语义，ANPrompt通过平均视觉编码器输出的提示令牌来计算噪声抵抗视觉提示原型（NRVPP）。最后，ANPrompt通过计算弱语义噪声对齐损失（WALoss）以及标准交叉熵和相似性损失，引入了对齐、鲁棒性和抗噪声目标。在11个基准测试中的实验表明，ANPrompt始终优于现有提示调优方法，实现了对语义噪声的卓越鲁棒性，并提高了对新类别的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [166] [Beyond Subspace Isolation: Many-to-Many Transformer for Light Field Image Super-resolution](https://arxiv.org/abs/2401.00740)
> *超越子空间隔离：用于光场图像超分辨率的多对多Transformer*

*Zeke Zexi Hu, Xiaoming Chen, Vera Yuk Ying Chung, Yiran Shen* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 光场图像超分辨率, Transformer, 多对多, 子空间隔离, 空间-角度特征

**Comment:** 

> **TL;DR:** 本文提出了一种名为多对多Transformer（M2MT）的新型Transformer架构，以解决现有光场图像超分辨率（LFSR）方法中由于子空间隔离导致的特征提取限制，并在LFSR任务中实现了最先进的性能。

**AI_Comments:** 本文的创新点在于明确指出了现有光场超分辨率方法中“子空间隔离”的限制，并提出了一种新颖的“多对多Transformer（M2MT）”架构来解决这一问题。M2MT通过在空间子空间中聚合角度信息，实现了对光场数据更全面的信息访问和长距离相关性捕获，有效提升了LFSR的性能和效率。其在性能与计算资源之间的平衡以及通过LAM进行的视觉可解释性分析，都增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有光场图像超分辨率（LFSR）方法为了处理庞大的4D数据量，将数据分解为低维子空间，并在每个子空间中独立执行Transformer，这导致了“子空间隔离”问题，限制了自注意力机制只能以“一对一”方式访问有限的光场数据，从而阻碍了对所有空间和角度信息的全面优化。

**Method:** 本文提出了一种新颖的“多对多Transformer（M2MT）”来解决子空间隔离问题。M2MT在执行自注意力机制之前，在空间子空间中聚合角度信息，从而实现对光场图像中所有子孔径图像（SAI）的全部信息访问。基于M2MT，作者开发了一个简单而有效的M2MT网络用于LFSR。

**Result:** 实验结果表明，M2MT在各种公共数据集上实现了最先进的性能，并在模型性能和效率之间取得了良好的平衡，以显著降低的内存和计算需求获得了更高质量的LFSR结果。通过局部归因图（LAM）的深入分析进一步验证了M2MT在空间和角度子空间中都具有真正的非局部上下文，从而缓解了子空间隔离并获得了有效的空间-角度表示。

**Conclusion:** M2MT通过在空间子空间中聚合角度信息并实现对所有光场数据的全面访问，有效克服了子空间隔离问题，并成功捕获了长距离相关依赖，从而在光场图像超分辨率任务中取得了卓越的表现和效率。

> **ai_Abstract:** 该论文提出了多对多Transformer（M2MT）来解决光场图像超分辨率（LFSR）中现有方法面临的子空间隔离问题。传统的LFSR方法将4D光场数据分解为低维子空间，导致Transformer的自注意力机制仅限于局部信息。M2MT通过在空间子空间中聚合角度信息，实现了对所有子孔径图像信息的全面访问，从而能够捕获全面的长距离空间-角度相关性。基于M2MT构建的LFSR网络在性能和效率上均达到最先进水平，并通过可视化分析验证了其非局部上下文学习能力。

> **摘要翻译:** 有效提取空间-角度特征在光场图像超分辨率（LFSR）任务中起着关键作用，而卷积和Transformer的引入显著改善了这一领域。然而，由于光场图像庞大的4D数据量，许多现有方法选择将数据分解为多个低维子空间，并在每个子空间中独立执行Transformer。作为一个副作用，这些方法无意中将自注意力机制限制在“一对一”方案中，只能访问有限的光场数据子集，明确阻止了对所有空间和角度线索的全面优化。在本文中，我们将此限制识别为子空间隔离，并引入了一种新颖的多对多Transformer（M2MT）来解决它。M2MT在执行自注意力机制之前，在空间子空间中聚合角度信息。它能够完全访问光场图像中所有子孔径图像（SAI）的所有信息。因此，M2MT能够全面捕获长距离相关依赖。以M2MT作为基础组件，我们开发了一个简单而有效的M2MT网络用于LFSR。我们的实验结果表明，M2MT在各种公共数据集上实现了最先进的性能，并在模型性能和效率之间取得了良好的平衡，以显著降低的内存和计算需求获得了更高质量的LFSR结果。我们进一步使用局部归因图（LAM）进行了深入分析，以获得视觉可解释性，结果验证了M2MT在空间和角度子空间中都具有真正的非局部上下文，以缓解子空间隔离并获取有效的空间-角度表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [173] [ACM Multimedia Grand Challenge on ENT Endoscopy Analysis](https://arxiv.org/abs/2508.04801)
> *ACM多媒体耳鼻喉内窥镜分析大挑战*

*Trong-Thuan Nguyen, Viet-Tham Huynh, Thao Thi Phuong Dao, Ha Nguyen Thi, Tien To Vu Thuy, Uyen Hanh Tran, Tam V. Nguyen, Thanh Dinh Le, Minh-Triet Tran* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 耳鼻喉内窥镜分析, 大挑战, 图像检索, 文本到图像, 数据集

**Comment:** 

> **TL;DR:** 本文介绍了ENTRep，即ACM多媒体2025耳鼻喉内窥镜分析大挑战，旨在通过整合精细解剖分类、图像到图像和文本到图像检索，解决耳鼻喉内窥镜图像自动化分析的不足，并提供了一个新的双语数据集和基准任务。

**AI_Comments:** 本文介绍了一个重要的多媒体大挑战，旨在推动耳鼻喉内窥镜图像分析领域的发展。其创新之处在于引入了ENTRep数据集，该数据集具有专家标注、双语描述以及整合了细粒度分类和检索任务，这对于解决现有基准的不足至关重要。该挑战有望促进该领域的研究，并为临床应用提供更可靠的自动化分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 耳鼻喉科（ENT）护理中内窥镜图像的自动化分析是一个关键但尚未充分发展的领域，受到设备和操作者变异性、细微和局部发现以及细粒度区分（如侧向性和声带状态）的阻碍。此外，临床医生需要可靠地检索视觉上和通过简洁文本描述的相似病例，而现有公共基准很少支持这些功能。

**Method:** 本文引入了ENTRep，即ACM多媒体2025耳鼻喉内窥镜分析大挑战。该挑战整合了精细解剖分类与图像到图像和文本到图像检索，并在双语（越南语和英语）临床监督下进行。具体来说，该数据集包含由专家标注的图像，标注了解剖区域和正常或异常状态，并附有双语叙述性描述。此外，本文定义了三个基准任务，标准化了提交协议，并使用服务器端评分评估了公共和私人测试集的性能。

**Result:** 本文报告了表现最佳团队的结果，并提供了深入的讨论。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了ACM多媒体2025耳鼻喉内窥镜分析大挑战（ENTRep），旨在解决耳鼻喉内窥镜图像自动化分析的现有不足。该挑战提供了一个新的数据集，包含专家标注的图像和双语描述，并整合了精细解剖分类、图像到图像和文本到图像检索任务。同时，定义了三个基准任务和标准化评估协议，并计划报告顶尖团队的表现。

> **摘要翻译:** 耳鼻喉科（ENT）护理中内窥镜图像的自动化分析是一个关键但尚未充分发展的组成部分，受到设备和操作者变异性、细微和局部发现以及细粒度区分（如侧向性和声带状态）的阻碍。除了分类，临床医生还需要可靠地检索视觉上和通过简洁文本描述的相似病例。现有公共基准很少支持这些功能。为此，我们引入了ENTRep，即ACM多媒体2025耳鼻喉内窥镜分析大挑战，它在双语（越南语和英语）临床监督下整合了精细解剖分类与图像到图像和文本到图像检索。具体来说，该数据集包含由专家标注的图像，标注了解剖区域和正常或异常状态，并附有双语叙述性描述。此外，我们定义了三个基准任务，标准化了提交协议，并使用服务器端评分评估了公共和私人测试集的性能。此外，我们报告了表现最佳团队的结果，并提供了深入的讨论。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [174] [Towards Scalable Newborn Screening: Automated General Movement Assessment in Uncontrolled Settings](https://arxiv.org/abs/2411.09821)
> *迈向可扩展的新生儿筛查：非受控环境下的自动全身运动评估*

*Daphné Chopard, Sonia Laguna, Kieran Chin-Cheong, Annika Dietz, Anna Badura, Sven Wellmann, Julia E. Vogt* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 全身运动评估, 新生儿筛查, 自动化, 机器学习, 非受控环境

**Comment:** 

> **TL;DR:** 本文提出了一种工具和机器学习方法，旨在从非受控环境下的婴儿视频中自动分类全身运动，以实现可扩展的新生儿神经发育障碍筛查。

**AI_Comments:** 该研究通过引入自动化工具和机器学习方法，有望显著提升新生儿神经发育障碍筛查的可及性和效率，尤其是在资源有限或偏远地区。其创新点在于尝试在非受控、多样化的视频环境下进行全身运动评估，这对于实际应用具有重要意义。未来的挑战可能在于模型的泛化能力和临床验证。

<details>
  <summary>Details</summary>

**Motivation:** 全身运动（GMs）评估是预测神经发育障碍的可靠方法，但Prechtl全身运动评估（GMA）需要经过专门培训的临床医生，而这些医生数量有限，限制了新生儿筛查的规模。因此，需要一种算法来自动分类婴儿视频记录中的全身运动。

**Method:** 本文引入了一种从婴儿视频记录中提取特征的工具，并探索了各种机器学习技术以实现全身运动的自动化分类。该方法旨在处理录制时长、设备类型和设置等方面的视频数据变异性，以及视频粗略标注的挑战。

**Result:** 抽象中未提及具体结果。

**Conclusion:** 抽象中未提及结论。

> **ai_Abstract:** 本研究旨在解决新生儿神经发育障碍筛查中全身运动评估（GMA）对专业临床医生依赖的问题，以实现筛查的规模化。针对非受控环境下婴儿视频数据存在的录制长度、设备和设置多样性以及粗略标注等挑战，研究提出了一种特征提取工具，并探索了多种机器学习技术，以实现对婴儿全身运动的自动化分类。

> **摘要翻译:** 全身运动（GMs）是婴儿自发的、协调的身体运动，能为正在发育的神经系统提供宝贵见解。通过Prechtl全身运动评估（GMA）进行评估，全身运动是神经发育障碍的可靠预测指标。然而，GMA需要经过专门培训的临床医生，而这些医生数量有限。为了扩大新生儿筛查规模，需要一种能够从婴儿视频记录中自动分类全身运动的算法。这类数据带来了挑战，包括录制时长、设备类型和设置的变异性，并且每个视频都只是粗略地标注了整体运动质量。在这项工作中，我们引入了一种从这些记录中提取特征的工具，并探索了各种机器学习技术以实现全身运动的自动化分类。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [175] [RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration](https://arxiv.org/abs/2508.04797)
> *RetinexDual：基于Retinex的双重性质方法，用于广义超高清图像恢复*

*Mohab Kishawy, Ali Abdellatif Hussein, Jun Chen* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 超高清图像恢复, Retinex, 双重性质, 频域, 空间域

**Comment:** 

> **TL;DR:** RetinexDual是一个基于Retinex理论的新型框架，通过结合空间域和频域处理，克服了传统方法在超高清图像恢复中的局限性，并在去雨、去模糊、去雾和低光图像增强等任务上取得了优异性能。

**AI_Comments:** 该论文提出了一种创新的双重性质方法RetinexDual，结合了Retinex理论、空间域的精细处理（SAMBA）和频域的全局校正（FIA），有效解决了超高清图像恢复中传统方法的局限性。其在多个广义任务上的优异表现，证明了这种混合方法在处理复杂图像退化问题上的潜力。特别强调了不同分支独特设计的重要性，增强了其方法的合理性。

<details>
  <summary>Details</summary>

**Motivation:** 传统超高清图像恢复方法存在显著缺陷：极端下采样导致不可逆信息损失，而纯频域方法对空间受限的图像伪影无效，因为其丧失了退化局部性。

**Method:** 本文提出了RetinexDual，一个基于Retinex理论的新型框架，用于广义超高清图像恢复。它利用两个互补的子网络：Scale-Attentive maMBA (SAMBA) 和 Frequency Illumination Adaptor (FIA)。SAMBA负责校正反射分量，采用从粗到精的机制；FIA在频域操作，利用全局上下文校正颜色和光照失真。

**Result:** RetinexDual在去雨、去模糊、去雾和低光图像增强这四项超高清图像恢复任务上，在定性和定量方面均优于现有方法。消融研究表明，RetinexDual中各分支独特设计的重要性及其组件的有效性。

**Conclusion:** RetinexDual通过结合空间域和频域的优势，有效克服了传统超高清图像恢复方法的局限性，并在多项任务上取得了卓越的性能，证明了其在广义超高清图像恢复中的有效性和优越性。

> **ai_Abstract:** RetinexDual是一种新颖的基于Retinex理论的框架，旨在解决超高清图像恢复中传统方法的局限性。该框架包含两个互补的子网络：负责反射分量校正的Scale-Attentive maMBA (SAMBA) 和在频域中校正颜色与光照失真的Frequency Illumination Adaptor (FIA)。实验证明，RetinexDual在去雨、去模糊、去雾和低光图像增强等四项超高清图像恢复任务上，在性能上超越了现有方法，并验证了其组件的有效性。

> **摘要翻译:** 图像传感技术的进步提升了超高清图像恢复 (UHD IR) 的重要性。传统方法，如极端下采样或从空间域到频域的转换，存在显著缺点：下采样导致 UHD 图像中不可逆的信息损失，而我们的频率分析表明，纯频域方法对空间受限的图像伪影无效，这主要是由于退化局部性的丧失。为了克服这些限制，我们提出了 RetinexDual，一个新颖的基于 Retinex 理论的框架，专为广义 UHD IR 任务设计。RetinexDual 利用两个互补的子网络：尺度注意 maMBA (SAMBA) 和频率光照适配器 (FIA)。SAMBA 负责校正反射分量，利用从粗到精的机制克服 mamba 的因果建模，从而有效地减少伪影并恢复复杂的细节。另一方面，FIA 通过在频域操作并利用其提供的全局上下文，确保精确校正颜色和光照失真。在去雨、去模糊、去雾和低光图像增强 (LLIE) 这四项 UHD IR 任务上评估 RetinexDual 表明，它在定性和定量上均优于最新方法。消融研究证明了在 RetinexDual 中为每个分支采用不同设计的重要性，以及其各个组件的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [177] [Calibrating Deep Neural Network using Euclidean Distance](https://arxiv.org/abs/2410.18321)
> *使用欧几里得距离校准深度神经网络*

*Wenhao Liang, Chang Dong, Liangwei Zheng, Wei Zhang, Weitong Chen* | **Category: cs.CV, cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 深度学习, 概率校准, 欧几里得距离, Focal Loss, 损失函数

**Comment:** 

> **TL;DR:** 提出Focal Calibration Loss (FCL) 新损失函数，通过欧几里得距离校准深度神经网络的预测概率，实现校准和准确性上的SOTA性能。

**AI_Comments:** 该论文创新性地将欧几里得距离引入到损失函数设计中，提出了Focal Calibration Loss (FCL) 以解决深度学习模型中常见的预测概率校准问题。它在保留Focal Loss处理难分类样本优势的同时，有效提升了模型的校准能力，对于提高模型在不确定性环境下的可靠性具有重要意义，尤其在医疗健康等对置信度要求高的领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的Focal Loss虽能减少误分类，但不能保证预测概率的良好校准，导致模型过自信或欠自信，高校准误差影响模型可靠性。

**Method:** 引入新的损失函数Focal Calibration Loss (FCL)，通过最小化欧几里得范数（通过严格适当损失），惩罚实例级校准误差并约束边界，旨在提高概率校准同时保留Focal Loss处理难分类样本的优势。

**Result:** 理论验证了所提方法，并将其应用于校准CheXNet。在各种模型和数据集上的广泛评估表明，该方法在校准和准确性指标上均达到了最先进的性能（SOTA）。

**Conclusion:** Focal Calibration Loss (FCL) 有效解决了深度神经网络的预测概率校准问题，同时保持了分类性能，提高了模型在实际应用中的可靠性。

> **ai_Abstract:** 本研究提出一种名为Focal Calibration Loss (FCL) 的新型损失函数，旨在解决现有Focal Loss在深度神经网络中预测概率校准不足的问题。FCL通过最小化欧几里得范数来惩罚实例级校准误差，从而提高模型预测的可靠性。实验结果表明，FCL在校准和准确性方面均达到了最先进的性能，有望应用于医疗等实际系统。

> **摘要翻译:** 不确定性是现实世界场景的一个基本方面，其中完美信息很少可用。人类自然地发展出复杂的内部模型来处理不完整的数据并有效响应不可预见或部分观察到的事件。在机器学习中，Focal Loss 通常用于通过强调难以分类的样本来降低错误分类率。然而，它不能保证预测概率的良好校准，并可能导致模型过自信或欠自信。高校准误差表明预测概率与实际结果之间存在错位，影响模型可靠性。本研究引入了一种新颖的损失函数，称为Focal Calibration Loss (FCL)，旨在提高概率校准，同时保留Focal Loss在处理困难样本方面的优势。通过严格适当的损失最小化欧几里得范数，FCL惩罚实例级校准误差并约束边界。我们为所提出的方法提供了理论验证，并将其应用于校准CheXNet，以实现在基于网络的医疗系统中的潜在部署。对各种模型和数据集的广泛评估表明，我们的方法在校准和准确性指标上均取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [186] [A solvable generative model with a linear, one-step denoiser](https://arxiv.org/abs/2411.17807)
> *一种具有线性一步去噪器的可解生成模型*

*Indranil Halder* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 生成模型, 扩散模型, Kullback-Leibler散度, 线性去噪器, 可解析模型

**Comment:** 

> **TL;DR:** 该研究开发了一个基于线性去噪器的可解析单步扩散模型，并给出了Kullback-Leibler散度的显式公式，解释了有限扩散时间和噪声尺度的影响，并揭示了KL散度的单调下降阶段以及为什么更多扩散步骤能提高生成质量。

**AI_Comments:** 这项工作通过构建一个可解析的单步扩散模型，为理解和分析扩散模型的行为提供了重要的理论基础。其创新之处在于提供了KL散度的显式公式，并从理论层面解释了实际扩散模型中增加扩散步骤的有效性，这对于指导模型设计和优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个可解析的单步扩散模型，并基于理论论证解释大规模实际扩散模型中增加扩散步数能提高生成质量的原因。

**Method:** 开发了一个基于线性去噪器的可解析单步扩散模型，并提出了生成分布与采样分布（假定为各向同性高斯）之间Kullback-Leibler散度的显式公式。

**Result:** 得到了生成分布与采样分布之间Kullback-Leibler散度的显式公式，展示了有限扩散时间和噪声尺度的影响。研究还发现，当训练数据集大小达到数据点维度时，Kullback-Leibler散度开始单调下降。

**Conclusion:** 基于理论论证，解释了为什么对于大规模实际扩散模型，增加扩散步骤能够提高生成质量。

> **ai_Abstract:** 本文开发了一种可解析的单步扩散生成模型，该模型使用线性去噪器，并提供了一个计算生成分布与各向同性高斯采样分布之间Kullback-Leibler散度的显式公式，揭示了扩散时间与噪声尺度的影响。研究发现，当训练数据集大小达到数据维度时，KL散度开始单调下降。此外，该模型还从理论上解释了大型扩散模型中增加扩散步数能提升生成质量的原因。

> **摘要翻译:** 我们开发了一个基于线性去噪器的可解析单步扩散模型，并给出了生成分布与采样分布（假定为各向同性高斯）之间Kullback-Leibler散度的显式公式，展示了有限扩散时间和噪声尺度的影响。我们的研究进一步揭示，当训练数据集大小达到数据点的维度时，Kullback-Leibler散度的单调下降阶段开始。最后，对于大规模实际扩散模型，我们基于之前提出的理论论证，解释了为什么更多的扩散步骤能够提高生成质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [187] [Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models](https://arxiv.org/abs/2508.04818)
> *基于扩散模型的单步免重建异常检测与分割*

*Mehrdad Moradi, Marco Grasso, Bianca Maria Colosimo, Kamran Paynabar* | **Category: cs.CV, eess.IV, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 异常检测, 扩散模型, 免重建, 实时, 分割

**Comment:** 

> **TL;DR:** RADAR是一种新的基于扩散模型的异常检测方法，无需重建，直接生成异常图，显著提高了实时性和准确性。

**AI_Comments:** 这项工作通过提出一种免重建的扩散模型方法，解决了现有基于扩散模型的异常检测方法在计算效率和实际应用中的主要瓶颈。其创新点在于直接生成异常图，而非耗时的图像重建过程，这对于实时异常检测至关重要。性能的显著提升，特别是在F1分数上的进步，证明了该方法的有效性和实用性。该研究为基于扩散模型的异常检测开辟了新的方向，使其更适用于需要快速响应的工业和医疗领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散模型的异常检测方法依赖于重建过程，这带来了三个主要挑战：计算成本高昂导致无法实时应用；对于复杂模式，重建图像可能与原始输入不符；以及选择中间噪声水平困难，因为它依赖于应用且通常假设存在异常的先验知识，这在无监督设置中不成立。

**Method:** 本文提出了一种名为RADAR（基于注意力扩散模型的实时免重建异常检测）的新方法。与当前最先进的重建输入图像的方法不同，RADAR直接从扩散模型中生成异常图，从而提高了检测精度和计算效率。

**Result:** RADAR在真实世界的3D打印材料和MVTec-AD数据集上进行了评估。结果显示，RADAR在所有关键指标（包括准确率、精确率、召回率和F1分数）上都超越了最先进的基于扩散模型和统计机器学习模型。具体而言，与次优模型相比，RADAR在MVTec-AD数据集上的F1分数提高了7%，在3D打印材料数据集上提高了13%。

**Conclusion:** RADAR通过避免重建过程，成功克服了现有基于扩散模型的异常检测方法的局限性，并显著提升了异常检测和分割的实时性和性能。

> **ai_Abstract:** 本文提出了一种名为RADAR的新型基于扩散模型的异常检测与分割方法，旨在解决传统基于重建的扩散模型在计算效率和准确性方面的局限性。RADAR通过直接从扩散模型生成异常图，而非重建图像，实现了单步、免重建的异常检测。实验结果表明，RADAR在3D打印材料和MVTec-AD数据集上，其性能在准确率、精确率、召回率和F1分数等关键指标上均优于现有的最先进模型，显著提升了实时应用的可能性和检测精度。

> **摘要翻译:** 在过去十年中，生成模型在异常检测和分割方面取得了显著成功。最近，扩散模型作为一种强大的替代方案出现，其性能优于GAN和VAE等先前方法。在典型的基于扩散的异常检测中，模型在正常数据上进行训练，在推理过程中，异常图像被扰动到前向扩散过程中的预定义中间步骤。然后通过迭代逆向采样重建相应的正常图像。
然而，基于重建的方法存在三个主要挑战：（1）由于多个采样步骤，重建过程计算成本高昂，使得实时应用不切实际；（2）对于复杂或细微的模式，重建图像可能对应于不同的正常模式而非原始输入；（3）选择合适的中间噪声水平具有挑战性，因为它依赖于应用并且通常假设存在异常的先验知识，而这种假设在无监督设置中不成立。
我们引入了RADAR（基于注意力扩散模型的实时免重建异常检测），它克服了基于重建的异常检测的局限性。与当前最先进的重建输入图像的方法不同，RADAR直接从扩散模型中生成异常图，从而提高了检测精度和计算效率。我们在真实世界的3D打印材料和MVTec-AD数据集上评估了RADAR。我们的方法在所有关键指标，包括准确率、精确率、召回率和F1分数上，都超越了最先进的基于扩散模型和统计机器学习模型。具体而言，与次优模型相比，RADAR在MVTec-AD上的F1分数提高了7%，在3D打印材料数据集上提高了13%。
代码可在以下网址获取：https://github.com/mehrdadmoradi124/RADAR

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [193] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
> *一种基于事件的深度学习眼动追踪方法*

*Chirag Seth, Divya Naiken, Keyan Lin* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 眼动追踪, 深度学习, 事件相机, CNN_LSTM, VR/AR

**Comment:** 

> **TL;DR:** 该研究利用深度学习（CNN_LSTM）通过事件相机追踪眼球运动，旨在提供经济高效且可解释的解决方案，在VR/AR应用中实现81%的准确率。

**AI_Comments:** 该研究利用深度学习方法解决传统眼动追踪成本高昂的问题，特别指出事件相机作为输入源，具有创新性。采用CNN_LSTM模型并强调可解释性，这对于VR/AR等消费电子产品的实际应用非常重要。81%的准确率是一个有希望的开端。

<details>
  <summary>Details</summary>

**Motivation:** 准确追踪快速眼球运动的挑战，传统方法需要昂贵的高速相机。研究旨在开发一种可解释且经济高效的算法，以预测人类注意力，从而改善VR和AR设备舒适度和用户体验。

**Method:** 该研究探索了各种深度学习方法，其中CNN_LSTM模型被证明最有效。它利用事件相机输入来定位眼睛中心位置（x, y）。未来工作将关注分层相关性传播（LRP）以增强模型可解释性。

**Result:** CNN_LSTM模型在定位眼睛中心位置方面达到了大约81%的准确率。

**Conclusion:** 该研究成功展示了一种基于深度学习（CNN_LSTM）的经济高效的眼动追踪方法，并取得了可观的准确率。未来工作将进一步提升模型的可解释性和预测性能。

> **ai_Abstract:** 该研究提出一种基于深度学习的眼动追踪方法，旨在解决传统高速相机成本高昂的问题。通过使用事件相机输入和CNN_LSTM模型，成功以约81%的准确率定位眼睛中心，旨在为VR/AR应用提供经济高效且可解释的注意力预测算法，以提升用户体验。未来工作将探索LRP以增强模型可解释性。

> **摘要翻译:** 这项研究项目通过利用现有研究，解决了在特定事件期间准确追踪眼球运动的挑战。考虑到人眼快速运动，速度可达300度/秒，精确的眼动追踪通常需要昂贵的高速相机。我们的主要目标是利用事件相机的输入来定位眼睛中心位置（x, y）。眼动分析在消费电子领域有广泛应用，特别是在VR和AR产品开发中。因此，我们的最终目标是开发一种可解释且经济高效的深度学习算法来预测人类注意力，从而提高设备舒适度并增强整体用户体验。为了实现这一目标，我们探索了各种方法，其中CNN_LSTM模型被证明最有效，达到了大约81%的准确率。此外，我们提出了未来工作将专注于分层相关性传播（LRP），以进一步提高模型的可解释性和预测性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [194] [STARFormer: A Novel Spatio-Temporal Aggregation Reorganization Transformer of FMRI for Brain Disorder Diagnosis](https://arxiv.org/abs/2501.00378)
> *STARFormer：一种用于脑疾病诊断的fMRI时空聚合重组Transformer*

*Wenhao Dong, Yueyang Li, Weiming Zeng, Lei Chen, Hongjie Yan, Wai Ting Siok, Nizhuan Wang* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-07**

**Keywords:** fMRI, 脑疾病诊断, Transformer, 时空特征, BOLD信号

**Comment:** 

> **TL;DR:** STARFormer是一种新型的fMRI时空聚合重组Transformer，通过有效整合BOLD信号的时空依赖性，提高了脑疾病（如ASD和ADHD）的诊断准确性，并达到了最先进的性能。

**AI_Comments:** STARFormer的创新之处在于其独特地结合了时空特征的聚合和重组，并通过专门设计的模块来处理fMRI数据的复杂性。特别是利用特征向量中心性（EC）来重组脑区，以及多尺度时间特征捕获，都显示出其在挖掘fMRI数据深层信息方面的潜力。该方法对提高脑疾病诊断的准确性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多现有使用功能性磁共振成像（fMRI）分类脑疾病（如自闭症谱系障碍（ASD）和注意缺陷多动障碍（ADHD））的方法，往往忽视了血氧水平依赖（BOLD）信号的空间和时间依赖性整合，这可能导致分类结果不准确或不精确。

**Method:** 本文提出了一种时空聚合重组Transformer（STARFormer），通过整合三个关键模块有效捕获BOLD信号的空间和时间特征。这些模块包括：1) 兴趣区域（ROI）空间结构分析模块，它使用特征向量中心性（EC）基于有效连接重组大脑区域；2) 时间特征重组模块，它将时间序列系统地分割成等维度窗口标记，并通过可变窗口和跨窗口注意力捕获多尺度特征；3) 时空特征融合模块，它采用并行Transformer架构，具有专门的时间和空间分支来提取集成特征。

**Result:** STARFormer在两个公开的ASD和ADHD分类数据集上进行了严格评估，实验结果证实其在多个评估指标上取得了最先进的性能。

**Conclusion:** STARFormer为脑疾病诊断和生物医学研究提供了一个更准确和可靠的工具。

> **ai_Abstract:** 该论文提出了一种名为STARFormer的新型时空聚合重组Transformer，旨在解决现有fMRI脑疾病诊断方法中对BOLD信号时空依赖性整合不足的问题。STARFormer通过引入兴趣区域空间结构分析、时间特征重组和时空特征融合三个核心模块，有效捕获并整合了BOLD信号的时空特征。在ASD和ADHD的分类任务上，STARFormer在公开数据集上表现出最先进的性能，为脑疾病的准确诊断提供了更可靠的工具。

> **摘要翻译:** 许多现有使用功能性磁共振成像（fMRI）分类脑疾病（如自闭症谱系障碍（ASD）和注意缺陷多动障碍（ADHD））的方法，往往忽视了血氧水平依赖（BOLD）信号的空间和时间依赖性整合，这可能导致分类结果不准确或不精确。为了解决这个问题，我们提出了一种时空聚合重组Transformer（STARFormer），通过整合三个关键模块有效捕获BOLD信号的空间和时间特征。兴趣区域（ROI）空间结构分析模块使用特征向量中心性（EC）根据有效连接重组大脑区域，突出与脑疾病相关的关键空间关系。时间特征重组模块将时间序列系统地分割成等维度窗口标记，并通过可变窗口和跨窗口注意力捕获多尺度特征。时空特征融合模块采用并行Transformer架构，具有专门的时间和空间分支来提取集成特征。所提出的STARFormer已在两个公开可用的ASD和ADHD分类数据集上进行了严格评估。实验结果证实，STARFormer在多个评估指标上取得了最先进的性能，为脑疾病诊断和生物医学研究提供了一个更准确和可靠的工具。代码可在：https://github.com/NZWANG/STARFormer 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [200] [CARE: Enhancing Safety of Visual Navigation through Collision Avoidance via Repulsive Estimation](https://arxiv.org/abs/2506.03834)
> *CARE：通过斥力估计增强视觉导航的安全性以避免碰撞*

*Joonkyung Kim, Joonyeol Sim, Woojun Kim, Katia Sycara, Changjoo Nam* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 视觉导航, 碰撞避免, 斥力估计, 深度估计, 机器人安全

**Comment:** 

> **TL;DR:** CARE是一个可附加模块，通过使用从RGB图像估计的深度信息计算的斥力来调整预训练模型的轨迹，从而显著提高学习型视觉导航模型的安全性并减少碰撞，无需额外的传感器或微调。

**AI_Comments:** CARE的创新之处在于其作为可附加模块的设计，能够无缝集成到现有基于RGB的导航模型中，并且无需额外的距离传感器或对预训练模型进行昂贵的微调。它通过从RGB输入估计深度并计算斥力来动态调整轨迹，解决了视觉导航模型在OOD场景下泛化能力差导致碰撞的关键问题。这对于提升机器人自主导航的实用性和安全性具有重要意义，尤其是在复杂和未知环境中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型视觉导航模型（特别是基础模型）在面对分布外（OOD）场景（如未见过的物体或不同的相机设置）时泛化能力差，可能导致碰撞，且需要大量数据收集和额外训练来解决。

**Method:** CARE（Collision Avoidance via Repulsive Estimation）是一个可附加模块，无需额外的距离传感器或对预训练模型进行微调。它通过使用直接从RGB输入估计的深度图像计算的斥力矢量，动态调整预训练模型生成的局部机器人轨迹。CARE可以无缝集成到任何基于RGB的导航模型中。

**Result:** 在真实世界实验中，CARE显著减少了碰撞（最高100%），同时在目标条件导航中不影响导航性能。在探索任务中，它进一步提高了无碰撞行驶距离（最高10.7倍）。

**Conclusion:** CARE通过动态调整轨迹和利用估计的深度信息，有效地提高了视觉导航模型的安全性、鲁棒性和泛化能力，显著减少了碰撞，而无需额外的硬件或昂贵的微调。

> **ai_Abstract:** 本文提出了CARE（Collision Avoidance via Repulsive Estimation），一个用于增强学习型视觉导航模型安全性的可附加模块。针对现有模型在未知环境中泛化能力差导致碰撞的问题，CARE通过从RGB图像估计深度信息并计算斥力矢量，动态调整预训练模型生成的轨迹，从而避免碰撞。该方法无需额外传感器或模型微调，可无缝集成。实验证明，CARE能显著减少碰撞（最高100%），并在探索任务中大幅增加无碰撞行驶距离，同时保持导航性能。

> **摘要翻译:** 我们提出了CARE（Collision Avoidance via Repulsive Estimation）来提高基于学习的视觉导航方法的鲁棒性。最近，视觉导航模型，特别是基础模型，通过仅使用RGB图像生成可行的轨迹，展示了有前景的性能。然而，这些策略对包含分布外（OOD）场景的环境（其特征是未见过的物体或不同的相机设置，例如视场、相机姿态或焦距的变化）的泛化能力较差。在不进行微调的情况下，此类模型可能会产生导致碰撞的轨迹，这需要大量的数据收集和额外的训练。为了解决这一限制，我们引入了CARE，一个可附加模块，它在不要求额外距离传感器或对预训练模型进行微调的情况下，增强了视觉导航的安全性。CARE可以无缝集成到任何生成局部机器人轨迹的基于RGB的导航模型中。它使用直接从RGB输入估计的深度图像计算的斥力矢量，动态调整预训练模型生成的轨迹。我们通过将其与最先进的视觉导航模型集成到不同的机器人平台上评估了CARE。真实世界实验表明，CARE显著减少了碰撞（最高100%），同时在目标条件导航中不影响导航性能，并在探索任务中进一步提高了无碰撞行驶距离（最高10.7倍）。项目页面：https://airlab-sogang.github.io/CARE/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [201] [LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction](https://arxiv.org/abs/2508.04847)
> *LuKAN：一种用于3D人体运动预测的科尔莫哥洛夫-阿诺德网络框架*

*Md Zahidul Hasan, A. Ben Hamza, Nizar Bouguila* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 3D人体运动预测, 科尔莫哥洛夫-阿诺德网络, 卢卡斯多项式, 离散小波变换, 计算效率

**Comment:** 

> **TL;DR:** LuKAN利用科尔莫哥洛夫-阿诺德网络（KANs）和卢卡斯多项式，通过处理时空依赖性，实现准确高效的3D人体运动预测。

**AI_Comments:** LuKAN的创新之处在于将科尔莫哥洛夫-阿诺德网络（KANs）与卢卡斯多项式激活相结合，以提高3D人体运动预测的精度和计算效率，尤其是在处理振荡行为方面。这种方法为解决现有模型在准确性和效率之间权衡的局限性提供了一个有效的新框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在预测精度和计算效率之间难以取得平衡。

**Method:** 该模型首先应用离散小波变换编码输入运动序列中的时间信息；然后，使用空间投影层捕获关节间依赖性，确保人体结构一致性；核心是时间依赖学习器，它采用由卢卡斯多项式参数化的KAN层进行高效函数逼近；最后，逆离散小波变换重建时间域中的运动序列。

**Result:** 在三个基准数据集上的大量实验表明，该模型与强基线相比具有竞争性性能，并通过定量和定性评估得到证实。此外，其紧凑的架构与卢卡斯多项式的线性递推相结合，确保了计算效率。

**Conclusion:** LuKAN通过结合科尔莫哥洛夫-阿诺德网络和卢卡斯多项式，有效提升了3D人体运动预测的精度和计算效率。

> **ai_Abstract:** 本文介绍了LuKAN，一个利用科尔莫哥洛夫-阿诺德网络（KANs）和卢卡斯多项式激活的新型3D人体运动预测模型。LuKAN通过离散小波变换编码时间信息、通过投影层捕获空间依赖性，并使用基于KAN的时间依赖学习器进行高效函数逼近，解决了精度与效率的权衡问题。实验表明，LuKAN在基准数据集上实现了具有竞争力的性能和高计算效率。

> **摘要翻译:** 3D人体运动预测的目标是根据历史运动数据预测人体未来的3D姿态。现有方法在预测精度和计算效率之间往往难以取得平衡。在本文中，我们提出了LuKAN，一个基于科尔莫哥洛夫-阿诺德网络（KANs）并采用卢卡斯多项式激活的有效模型。我们的模型首先应用离散小波变换对输入运动序列中的时间信息进行编码。然后，使用空间投影层捕获关节间的依赖关系，确保人体的结构一致性。LuKAN的核心是时间依赖学习器，它采用由卢卡斯多项式参数化的KAN层进行高效的函数逼近。这些多项式提供了计算效率，并增强了处理振荡行为的能力。最后，逆离散小波变换在时域中重建运动序列，生成时间上连贯的预测。在三个基准数据集上进行的大量实验表明，我们的模型与强基线相比具有竞争性性能，这通过定量和定性评估得到了证实。此外，其紧凑的架构以及卢卡斯多项式的线性递推，确保了计算效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [207] [VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence](https://arxiv.org/abs/2508.04852)
> *VER-Bench: 评估多模态大语言模型在细粒度视觉证据推理方面的能力*

*Chenhui Qiang, Zhaoyang Wei, Xumeng Han Zipeng Wang, Siyao Li, Xiangyuan Lan, Jianbin Jiao, Zhenjun Han* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 多模态大语言模型, 细粒度视觉证据, 推理, 评估基准, VER-Bench

**Comment:** 

> **TL;DR:** 引入VER-Bench，一个新基准，用于评估多模态大语言模型在识别和整合细微视觉线索进行复杂推理方面的能力，揭示了现有模型在此方面的局限性。

**AI_Comments:** VER-Bench的创新点在于它填补了现有MLLM评估基准的空白，特别是关注了对细微、不显眼视觉细节的推理能力，这对于实现类人视觉理解至关重要。其精心设计的问题和结构化证据为更深入地分析模型的弱点提供了清晰路径。这项工作的重要性在于它指出了当前MLLMs在处理复杂视觉信息时的局限性，并为未来的模型开发提供了明确的方向，即需要增强对细粒度视觉证据的提取、整合和推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准在评估多模态大语言模型（MLLMs）的视觉能力时存在不足：基础感知基准缺乏深度推理，而主流推理基准未能评估需要复杂分析的细微线索。然而，深刻的视觉理解和复杂推理更依赖于对细微、不显眼局部细节的解读，而非宏观显著物体。

**Method:** 引入了VER-Bench，一个新颖的框架，旨在评估MLLMs识别细粒度视觉线索（平均只占图像面积的0.25%）以及将这些线索与世界知识结合进行复杂推理的能力。该基准包含374个精心设计的问题，涵盖地理空间、时间、情境、意图、系统状态和符号推理等类别，每个问题都附有结构化证据：视觉线索和由此衍生的相关推理。

**Result:** VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性。

**Conclusion:** 研究强调了增强模型在细粒度视觉证据提取、整合和推理能力方面的必要性，以实现真正的视觉理解和类人分析。

> **ai_Abstract:** 本研究提出了VER-Bench，一个新颖的评估框架，旨在解决现有基准在评估多模态大语言模型（MLLMs）细粒度视觉推理能力方面的不足。VER-Bench专注于评估MLLMs识别图像中微小但关键的视觉线索，并将其与世界知识结合进行复杂推理的能力。该基准包含374个跨多个推理类别的精心设计问题，并提供结构化证据。通过VER-Bench，研究发现当前模型在提取细微视觉证据和构建证据链方面存在明显局限性，从而强调了提升MLLMs在该领域能力的必要性，以实现更深层次的视觉理解。

> **摘要翻译:** 随着多模态大语言模型（MLLMs）的快速发展，评估其视觉能力变得越来越重要。当前的基准主要分为两种类型：专注于局部细节但缺乏深度推理的基础感知基准（例如，“图像中有什么？”），以及侧重于突出图像元素但可能无法评估需要复杂分析的细微线索的主流推理基准。然而，深刻的视觉理解和复杂推理更多地依赖于对细微、不显眼局部细节的解读，而非对显著、宏观物体的感知。这些细节虽然只占据极小的图像区域，但通常包含更丰富、更关键的信息，以进行稳健的分析。为了弥合这一差距，我们引入了VER-Bench，一个新颖的框架，用于评估MLLMs识别细粒度视觉线索（通常平均只占图像面积的0.25%）以及将这些线索与世界知识结合进行复杂推理的能力。VER-Bench包含374个精心设计的问题，涵盖地理空间、时间、情境、意图、系统状态和符号推理，VER-Bench中的每个问题都附有结构化证据：视觉线索和由此衍生的相关推理。VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性，强调了需要增强模型在细粒度视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类人分析。数据集和附加材料可在https://github.com/verbta/ACMMM-25-Materials获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [208] [Brain Network Analysis Based on Fine-tuned Self-supervised Model for Brain Disease Diagnosis](https://arxiv.org/abs/2506.11671)
> *基于微调自监督模型的脑网络分析用于脑疾病诊断*

*Yifei Tang, Hongjie Jiang, Changhong Jing, Hieu Pham, Shuqiang Wang* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 脑网络分析, 脑疾病诊断, 自监督学习, 微调模型, 功能磁共振成像

**Comment:** 

> **TL;DR:** 该研究提出了一个基于自监督学习和多维度扩展的微调脑网络模型，用于提高脑疾病诊断的泛化能力和性能。

**AI_Comments:** 该研究的创新点在于提出了一个多维度扩展的微调自监督脑网络模型，解决了现有模型泛化能力受限的问题。通过在大规模fMRI数据上预训练和利用Transformer结构，提高了脑疾病诊断的准确性。这对于推动脑疾病的早期诊断和理解具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的脑网络基础模型研究有限且局限于单一维度，这限制了它们在神经科学中的广泛应用。

**Method:** 提出了一个用于脑疾病诊断的微调脑网络模型。该模型通过一个适配器模块将脑区表示扩展到多个维度，并包含一个基于自监督学习、在数千名参与者fMRI数据上预训练的微调基础脑网络模型。其Transformer块能有效提取脑区特征并计算区域间关联，并推导出一个紧凑的脑网络潜在表示用于诊断。

**Result:** 下游实验表明，所提出的模型在脑疾病诊断中取得了卓越的性能。

**Conclusion:** 该模型在脑疾病诊断中表现出色，可能为脑网络分析研究提供一种有前景的方法。

> **ai_Abstract:** 本文提出了一种用于脑疾病诊断的微调脑网络模型，旨在解决现有脑网络基础模型在单一维度上的局限性。该模型通过适配器模块将脑区特征扩展到多维度，并利用一个基于自监督学习、在大量fMRI数据上预训练的Transformer基础模型来提取特征和关联。实验结果表明，该模型在脑疾病诊断方面表现出卓越的性能，为脑网络分析提供了新的方向。

> **摘要翻译:** 功能性脑网络分析已成为脑疾病分析不可或缺的工具。它深受深度学习方法的影响，这些方法可以表征ROI之间复杂的连接。然而，脑网络基础模型的研究有限且局限于单一维度，这限制了它们在神经科学中的广泛应用。在本研究中，我们提出了一个用于脑疾病诊断的微调脑网络模型。它在原始脑网络模型的基础上，将脑区表示扩展到多个维度，从而增强了其泛化能力。我们的模型由两个关键模块组成：(1)一个适配器模块，用于跨不同维度扩展脑区特征。(2)一个基于自监督学习并在数千名参与者的fMRI数据上预训练的微调基础脑网络模型。具体来说，其Transformer块能够有效地提取脑区特征并计算区域间关联。此外，我们推导出了一个用于脑疾病诊断的紧凑脑网络潜在表示。本研究中的下游实验表明，所提出的模型在脑疾病诊断中取得了卓越的性能，这可能为脑网络分析研究提供一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [214] [Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications](https://arxiv.org/abs/2508.04868)
> *用于交通应用中目标检测的双流多模态查询注意力机制*

*Noreen Anwar, Guillaume-Alexandre Bilodeau, Wassim Bouachir* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 目标检测, Transformer, 多模态查询, 双流注意力, 交通应用

**Comment:** 

> **TL;DR:** DAMM是一种新的基于Transformer的目标检测框架，通过引入多模态查询适应和双流交叉注意力来解决现有检测器在遮挡、精细定位和计算效率方面的挑战，并在多个基准测试中达到了最先进的性能。

**AI_Comments:** DAMM通过引入多模态查询适应和双流交叉注意力，为Transformer基目标检测器提供了一种新颖的解决方案，有效提升了在复杂场景下的检测精度和效率，尤其是在处理遮挡和精细定位方面。其创新点在于结合了不同类型的查询以提供更全面的场景覆盖和特征表示，并通过双流机制精细化特征，具有重要的研究价值和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基于Transformer的目标检测器在处理遮挡、精细定位和由固定查询及密集注意力引起的计算效率低下问题时表现不佳。

**Method:** 本文提出了DAMM（Dual-stream Attention with Multi-Modal queries），一个引入查询适应和结构化交叉注意力的新颖框架。DAMM利用三种类型的查询：来自视觉-语言模型的基于外观的查询、使用多边形嵌入的位置查询以及用于一般场景覆盖的随机学习查询。此外，一个双流交叉注意力模块分别细化语义和空间特征，以提高杂乱场景中的定位精度。

**Result:** DAMM在四个具有挑战性的基准测试中进行了评估，并在平均精度（AP）和召回率方面取得了最先进的性能。

**Conclusion:** 多模态查询适应和双流注意力机制是有效的，能够显著提高目标检测的准确性和效率，特别是在处理遮挡和精细定位方面。

> **ai_Abstract:** 本文提出了一种名为DAMM（Dual-stream Attention with Multi-Modal queries）的新型目标检测框架，旨在解决现有基于Transformer的检测器在遮挡、精细定位和计算效率方面的不足。DAMM通过结合三种多模态查询（外观、位置和随机学习）以及一个双流交叉注意力模块来分别优化语义和空间特征。在四个具有挑战性的基准测试中，DAMM在平均精度和召回率方面均达到了最先进的性能，证明了其在提高交通应用中目标检测准确性和效率方面的有效性。

> **摘要翻译:** 基于Transformer的目标检测器通常在处理遮挡、细粒度定位以及由固定查询和密集注意力引起的计算效率低下问题时面临挑战。我们提出了DAMM（Dual-stream Attention with Multi-Modal queries），一个引入查询适应和结构化交叉注意力的新颖框架，旨在提高准确性和效率。DAMM利用三种类型的查询：来自视觉-语言模型的基于外观的查询、使用多边形嵌入的位置查询以及用于一般场景覆盖的随机学习查询。此外，一个双流交叉注意力模块分别细化语义和空间特征，从而提高在杂乱场景中的定位精度。我们在四个具有挑战性的基准测试中评估了DAMM，它在平均精度（AP）和召回率方面取得了最先进的性能，证明了多模态查询适应和双流注意力的有效性。源代码可在GitHub上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [215] [Capsule-ConvKAN: A Hybrid Neural Approach to Medical Image Classification](https://arxiv.org/abs/2507.06417)
> *Capsule-ConvKAN：一种用于医学图像分类的混合神经网络方法*

*Laura Pituková, Peter Sinčák, László József Kovács, Peng Wang* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-07**

**Keywords:** Capsule-ConvKAN, 医学图像分类, 混合神经网络, 胶囊网络, 卷积科尔莫哥洛夫-阿诺德网络

**Comment:** 

> **TL;DR:** 本研究提出了一种名为Capsule-ConvKAN的混合神经网络架构，结合了胶囊网络和卷积科尔莫哥洛夫-阿诺德网络的优点，在组织病理图像数据集上实现了最高的医学图像分类准确率。

**AI_Comments:** 该论文的创新点在于结合了胶囊网络和卷积科尔莫哥洛夫-阿诺德网络，形成了一种新的混合架构Capsule-ConvKAN，旨在克服传统卷积模型在医学图像分类中的局限性。这种混合方法有望更好地捕获空间模式和管理复杂特征，对于提高生物医学图像的诊断准确性具有重要意义。其在病理图像分类中取得的高准确率证明了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 开发该新型混合模型是为了改善特征表示和分类精度，特别是在具有挑战性的真实生物医学图像数据中。

**Method:** 本研究对四种神经网络架构进行了全面比较：卷积神经网络、胶囊网络、卷积科尔莫哥洛夫-阿诺德网络以及新提出的Capsule-卷积科尔莫哥洛夫-阿诺德网络（Capsule-ConvKAN）。Capsule-ConvKAN结合了胶囊网络的动态路由和空间层次能力与卷积科尔莫哥洛夫-阿诺德网络灵活且可解释的函数逼近能力。

**Result:** 在组织病理图像数据集上，Capsule-ConvKAN实现了最高的分类性能，准确率为91.21%。

**Conclusion:** 结果表明，新引入的Capsule-ConvKAN在捕获空间模式、管理复杂特征以及解决传统卷积模型在医学图像分类中局限性方面具有潜力。

> **ai_Abstract:** 本研究提出了一种名为Capsule-ConvKAN的新型混合神经网络架构，旨在提升医学图像分类的性能。该模型结合了胶囊网络的动态路由和空间层次特性以及卷积科尔莫哥洛夫-阿诺德网络的灵活函数逼近能力。通过与CNN、Capsule Network和ConvKAN进行比较，Capsule-ConvKAN在组织病理图像数据集上取得了91.21%的最高分类准确率，展现了其在处理复杂医学图像特征方面的优越性。

> **摘要翻译:** 本研究对四种神经网络架构进行了全面比较：卷积神经网络、胶囊网络、卷积科尔莫哥洛夫-阿诺德网络以及新提出的Capsule-卷积科尔莫哥洛夫-阿诺德网络。所提出的Capsule-ConvKAN架构结合了胶囊网络的动态路由和空间层次能力与卷积科尔莫哥洛夫-阿诺德网络灵活且可解释的函数逼近能力。开发这种新型混合模型是为了改善特征表示和分类精度，特别是在具有挑战性的真实生物医学图像数据中。这些架构在组织病理图像数据集上进行了评估，其中Capsule-ConvKAN以91.21%的准确率实现了最高的分类性能。结果表明，新引入的Capsule-ConvKAN在捕获空间模式、管理复杂特征以及解决传统卷积模型在医学图像分类中局限性方面具有潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [221] [Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations](https://arxiv.org/abs/2508.04924)
> *基于元辅助学习和跨模态幻觉的视频精彩片段检测测试时自适应*

*Zahidul Islam, Sujoy Paul, Mrigank Rochan* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 视频精彩片段检测, 测试时自适应, 元辅助学习, 跨模态幻觉, 泛化

**Comment:** 

> **TL;DR:** 提出Highlight-TTA框架，通过测试时自适应和元辅助学习，结合跨模态幻觉，提高视频精彩片段检测的泛化能力和性能。

**AI_Comments:** 该论文的创新点在于提出了一个测试时自适应框架Highlight-TTA，解决了视频精彩片段检测中模型泛化能力差的问题。通过引入元辅助学习和跨模态幻觉作为辅助任务，实现了模型在测试阶段对未见视频的动态适应，这对于提高实际应用中的性能具有重要意义。该方法通过结合辅助任务来增强主任务，提供了一种新的模型自适应范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频精彩片段检测方法在泛化到所有测试视频时表现不佳，因为它们使用固定的通用模型，无法适应单个测试视频的独特特征和多样内容、风格或音视频质量，导致性能下降。

**Method:** 提出Highlight-TTA框架，通过在测试时动态调整模型以适应每个测试视频的特定特征。该框架与辅助任务（跨模态幻觉）和主要任务（精彩片段检测）联合优化。采用元辅助训练方案，通过辅助任务实现有效自适应，同时增强主要任务。在测试时，利用辅助任务对训练好的模型进行自适应，以进一步提高其精彩片段检测性能。

**Result:** 在三个最先进的精彩片段检测模型和三个基准数据集上进行的广泛实验表明，引入Highlight-TTA可以提高这些模型的性能，并产生卓越的结果。

**Conclusion:** Highlight-TTA通过测试时自适应和元辅助学习，显著提高了视频精彩片段检测的泛化能力和性能。

> **ai_Abstract:** 本文提出了Highlight-TTA，一个视频精彩片段检测的测试时自适应框架，旨在解决现有方法泛化能力差的问题。Highlight-TTA通过在测试阶段动态调整模型以适应每个视频的独特特征，并结合元辅助学习和跨模态幻觉任务进行联合优化。实验证明，该方法能显著提升现有精彩片段检测模型的性能和泛化能力。

> **摘要翻译:** 尽管现有的视频精彩片段检测方法很先进，但它们难以很好地泛化到所有测试视频。这些方法通常为每个测试视频采用一个通用的精彩片段检测模型，这是次优的，因为它未能考虑到单个测试视频的独特特征和变化。这种固定模型不适应新、未见测试视频中存在的多样内容、风格或音视频质量，导致精彩片段检测性能下降。在本文中，我们提出了Highlight-TTA，一个用于视频精彩片段检测的测试时自适应框架，通过在测试期间动态调整模型以更好地适应每个测试视频的特定特征，从而解决这一限制，提高泛化能力和精彩片段检测性能。Highlight-TTA与辅助任务（跨模态幻觉）以及主要的精彩片段检测任务联合优化。我们利用元辅助训练方案，通过辅助任务实现有效自适应，同时增强主要任务。在测试期间，我们利用测试视频上的辅助任务来调整训练好的模型，以进一步提高其精彩片段检测性能。对三个最先进的精彩片段检测模型和三个基准数据集进行的广泛实验表明，将Highlight-TTA引入这些模型可以提高其性能，并产生卓越的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [222] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
> *STF：浅层时间反馈增强脉冲Transformer*

*Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin* | **Category: cs.CV, cs.NE** | **Updated: 2025-08-07**

**Keywords:** 脉冲神经网络, Transformer, 浅层时间反馈, 脉冲编码, 性能提升

**Comment:** 

> **TL;DR:** 本文提出了一种轻量级的浅层时间反馈（STF）模块，用于脉冲神经网络（SNNs）的编码层，以提高基于Transformer的SNNs的性能，同时减少计算开销。

**AI_Comments:** 本文提出的STF模块通过关注浅层反馈而非传统的深层反馈，巧妙地解决了现有方法计算成本高昂的问题，体现了创新性。其即插即用的特性增加了实用性。通过增强脉冲模式多样性来提升性能的洞察也很有价值。该研究对于推动SNNs在实际应用中的性能和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于Transformer的脉冲神经网络（SNNs）与浮点人工神经网络（ANNs）相比存在显著的性能差距，这主要是由于脉冲序列的二值特性。现有方法引入的深层反馈环路虽然能缩小差距，但会导致高昂的特征转换、参数开销、能耗增加和推理延迟。

**Method:** 提出了一种名为浅层时间反馈（STF）的轻量级即插即用模块，用于编码层。STF由时空位置嵌入（TSPE）和时间反馈（TF）组成。

**Result:** STF在CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集上，在不同脉冲时间步设置下，持续提升了各种基于Transformer的SNN骨干网络的性能。分析表明STF增强了脉冲模式的多样性。STF在对抗鲁棒性和时间敏感性方面优于直接编码及其变体。

**Conclusion:** STF作为一种新的静态场景脉冲编码方案，能够有效提升基于Transformer的SNNs的性能，同时具有轻量级和高效的特点，并通过增强脉冲模式多样性来实现性能提升。

> **ai_Abstract:** 本文提出了一种名为浅层时间反馈（STF）的轻量级即插即用模块，旨在弥补基于Transformer的脉冲神经网络（SNNs）与人工神经网络（ANNs）之间的性能差距。针对现有深层反馈方法计算成本高的问题，STF由时空位置嵌入（TSPE）和时间反馈（TF）构成，并应用于SNN的编码层。实验证明，STF在多个静态数据集上显著提升了不同Transformer-based SNN模型的性能，并通过增加脉冲模式多样性实现增益。研究还表明STF在对抗鲁棒性和时间敏感性方面表现优越，有望成为新的脉冲编码方案。

> **摘要翻译:** Transformer-based 脉冲神经网络（SNNs）由于脉冲序列的二值特性，与浮点人工神经网络（ANNs）相比存在巨大的性能差距。最近的努力引入了深层反馈环路来传输高层语义信息以缩小这一差距。然而，这些设计通常跨越多个深层，导致昂贵的特征转换、更高的参数开销、增加的能耗和更长的推理延迟。为了解决这个问题，我们提出了浅层时间反馈（STF），一个用于编码层的轻量级即插即用模块，它由时空位置嵌入（TSPE）和时间反馈（TF）组成。大量的实验表明，STF在CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集上，在不同的脉冲时间步设置下，持续提高了各种基于Transformer的SNN骨干网络的性能。进一步的分析表明，STF增强了脉冲模式的多样性，这是性能增益的关键。此外，对抗鲁棒性和时间敏感性评估证实，STF优于直接编码及其变体，突出了其作为静态场景新型脉冲编码方案的潜力。我们的代码将在接受后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [228] [Toward Errorless Training ImageNet-1k](https://arxiv.org/abs/2508.04941)
> *迈向ImageNet-1k的无误差训练*

*Bo Deng, Levi Heath* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** ImageNet, 神经网络, 深度学习, 图像分类, 数据集问题

**Comment:** 

> **TL;DR:** 该论文描述了一个在ImageNet数据集上训练的前馈神经网络，实现了98.3%的准确率和99.69%的Top-1准确率，并推测未能达到100%准确率是由于数据集中的重复标签问题。

**AI_Comments:** 这篇论文展示了在ImageNet数据集上实现极高准确率的努力，并提出了一个关于数据集质量（双重标签问题）的创新性见解，这对于理解深度学习模型性能上限的限制因素具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在探索在ImageNet-1k数据集上实现接近无误差的训练，并达到高准确率。

**Method:** 使用一种新的方法训练了一个前馈人工神经网络，并在ImageNet 2012竞赛数据集上进行测试。

**Result:** 模型在ImageNet 2012数据集上达到了98.3%的准确率和99.69%的Top-1准确率，平均有285.9个标签在10个批次分区上被完美分类。最佳模型使用了322,430,160个参数，精度为4位小数。

**Conclusion:** 尽管取得了高准确率，但模型未能达到100%准确率的原因被推测为数据集中的双重标签（即具有不同标签的重复图像）问题。

> **ai_Abstract:** 本文介绍了一个针对ImageNet 2012数据集训练的前馈神经网络。该网络采用一种新方法，实现了98.3%的整体准确率和99.69%的Top-1准确率。研究者指出，模型未能达到100%完美分类的原因可能在于数据集中存在的重复图像与不同标签的双重标注问题。

> **摘要翻译:** 在本文中，我们描述了一个使用[5]中的新方法在ImageNet 2012竞赛数据集[7]上训练的前馈人工神经网络，其准确率达到98.3%，Top-1准确率达到99.69%，并且在数据集的10个批次分区中平均有285.9个标签被完美分类。性能最佳的模型使用了322,430,160个参数，精度为4位小数。我们推测，我们的模型未能达到100%准确率的原因是由于双重标签问题，即数据集中存在具有不同标签的重复图像。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [229] [AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation](https://arxiv.org/abs/2508.00733)
> *AudioGen-Omni: 一种用于视频同步音频、语音和歌曲生成的统一多模态扩散变换器*

*Le Wang, Jun Wang, Chunyu Qiang, Feng Deng, Chen Zhang, Di Zhang, Kun Gai* | **Category: cs.CV, cs.MM, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 多模态扩散变换器, 视频同步音频生成, 语音生成, 歌曲生成, 联合训练

**Comment:** 

> **TL;DR:** AudioGen-Omni 是一种基于多模态扩散变换器的统一方法，能够生成与输入视频同步的高保真音频、语音和歌曲，并通过新颖的联合训练范式实现了最先进的性能和高效率。

**AI_Comments:** 该论文提出了一种创新的统一多模态扩散变换器 AudioGen-Omni，其核心贡献在于引入了新颖的联合训练范式和增强的跨模态融合机制（PAAPI），有效解决了视频同步音频、语音和歌曲生成中的挑战。通过解冻所有模态，它突破了传统模型的语义限制，实现了更灵活和强大的跨模态条件生成。在实现最先进性能的同时，其高效的推理时间也展现了实际应用潜力，具有重要的研究和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一种能够生成与输入视频连贯同步的高保真音频、语音和歌曲的统一方法，并解决现有文本冻结范式的语义限制，从而实现有效的跨模态条件生成。

**Method:** AudioGen-Omni 采用多模态扩散变换器（MMDit）框架，引入了一种新颖的联合训练范式，无缝整合大规模视频-文本-音频语料库。它使用统一的歌词-转录编码器将歌素和音素编码为密集帧级表示。这些表示通过基于 AdaLN 的联合注意力机制融合，该机制通过相位对齐各向异性位置信息注入（PAAPI）增强，选择性地将 RoPE 应用于时间结构化模态，以确保精确的跨模态对齐。通过解冻所有模态并掩蔽缺失输入，该方法缓解了文本冻结范式的语义限制。

**Result:** AudioGen-Omni 能够生成高保真、语义丰富、声学多样化的音频、语音和歌曲，并与输入视频连贯同步。它在文本到音频/语音/歌曲任务上取得了最先进的结果，显著提升了音频质量、语义对齐和唇形同步准确性。此外，它在生成8秒音频时的推理时间为1.91秒，在效率和通用性方面都有显著改进。

**Conclusion:** AudioGen-Omni 作为一种统一的多模态扩散变换器，通过其创新的联合训练范式和架构设计，在视频同步音频、语音和歌曲生成方面取得了最先进的性能，并显著提升了效率和通用性。

> **ai_Abstract:** AudioGen-Omni 提出了一种基于多模态扩散变换器（MMDit）的统一方法，旨在生成与视频同步的高保真音频、语音和歌曲。该模型通过创新的联合训练范式，整合了大规模多模态语料，并采用统一的歌词-转录编码器和基于 AdaLN 的联合注意力机制（增强了 PAAPI）进行跨模态融合。通过解冻所有模态并掩蔽缺失输入，该方法克服了传统文本冻结范式的限制，显著提升了音频质量、语义对齐和唇形同步准确性。AudioGen-Omni 在文本到音频/语音/歌曲任务上取得了最先进的成果，并在效率和通用性方面展现出显著优势。

> **摘要翻译:** 我们提出了 AudioGen-Omni——一种基于多模态扩散变换器（MMDit）的统一方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲。AudioGen-Omni 引入了一种新颖的联合训练范式，无缝整合大规模视频-文本-音频语料库，使模型能够生成以多模态输入为条件的语义丰富、声学多样的音频，并适应各种音频生成任务。AudioGen-Omni 采用统一的歌词-转录编码器，将歌曲和语音输入中的字素和音素编码为密集的帧级表示。密集的帧级表示通过基于 AdaLN 的联合注意力机制融合，该机制通过相位对齐各向异性位置信息注入（PAAPI）增强，其中 RoPE 被选择性地应用于时间结构化模态，以确保精确和鲁棒的跨模态对齐。通过解冻所有模态并掩蔽缺失输入，AudioGen-Omni 缓解了文本冻结范式的语义限制，从而实现有效的跨模态条件生成。这种联合训练方法提高了音频质量、语义对齐和唇形同步准确性，同时还在文本到音频/语音/歌曲任务上取得了最先进的结果。其生成8秒音频的推理时间为1.91秒，在效率和通用性方面都提供了显著改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [235] [Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models](https://arxiv.org/abs/2508.04942)
> *通过掩码图像建模加速视觉-语言模型的条件提示学习*

*Phuoc-Nguyen Bui, Khanh-Binh Nguyen, Hyunseung Choo* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 条件提示学习, 掩码图像建模, 视觉-语言模型, 泛化, 过拟合

**Comment:** 

> **TL;DR:** ProMIM通过将掩码图像建模集成到现有视觉-语言模型中，以很小的计算成本显著提高了条件提示学习的泛化能力，解决了过拟合问题。

**AI_Comments:** ProMIM的创新之处在于其将掩码图像建模（MIM）以即插即用的方式融入现有条件提示学习框架，解决了提示学习中常见的过拟合问题。其通过仅掩码可见图像块来生成鲁棒提示的策略，既简单又高效，且计算成本极低，这使其在实际应用中具有很高的价值和可行性。该方法对现有VLM的改进是通用且显著的。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言模型（VLMs）如CLIP在零样本学习中表现出色，但适应新任务需要大量资源训练。提示学习技术（如CoOp和CoCoOp）虽然高效，但易于对已知类别过拟合，限制了其对未见类别的泛化能力。

**Method:** 本文提出了ProMIM，一个即插即用的框架，通过将掩码图像建模（MIM）集成到现有VLM管道中，增强了条件提示学习。ProMIM利用一种简单有效的掩码策略来生成鲁棒的实例条件提示，无缝增强了CoOp和CoCoOp等方法，而无需改变其核心架构。它通过仅掩码可见图像块并使用这些表示来指导提示生成，从而提高特征鲁棒性并减轻过拟合。

**Result:** 在零样本和少样本分类任务中的大量实验表明，ProMIM在插入现有方法时，能够持续提升泛化性能。

**Conclusion:** ProMIM为现实世界的视觉-语言应用提供了一个实用、轻量级的解决方案，通过引入可忽略的额外计算成本来提高泛化能力并减轻过拟合。

> **ai_Abstract:** 本文提出ProMIM，一个即插即用的框架，旨在通过将掩码图像建模（MIM）集成到现有视觉-语言模型（VLM）管道中，加速条件提示学习。ProMIM通过仅掩码可见图像块并使用这些表示来生成鲁棒的实例条件提示，有效解决了现有提示学习方法（如CoOp和CoCoOp）在泛化到未见类别时易于过拟合的问题。该方法在引入可忽略计算成本的同时，显著提高了特征鲁棒性并减轻了过拟合。实验证明，ProMIM能持续提升现有VLM方法的泛化性能，为实际应用提供了轻量级且有效的解决方案。

> **摘要翻译:** 视觉-语言模型（VLMs）如CLIP在零样本学习中表现出色，但通常需要资源密集型训练才能适应新任务。提示学习技术，如CoOp和CoCoOp，提供了高效的适应性，但倾向于对已知类别过拟合，限制了对未见类别的泛化。我们引入了ProMIM，一个即插即用的框架，通过将掩码图像建模（MIM）集成到现有VLM管道中，增强了条件提示学习。ProMIM利用一种简单而有效的掩码策略来生成鲁棒的实例条件提示，无缝地增强了CoOp和CoCoOp等方法，而无需改变它们的核心架构。通过仅掩码可见图像块并使用这些表示来指导提示生成，ProMIM提高了特征鲁棒性并减轻了过拟合，同时引入了可忽略的额外计算成本。在零样本和少样本分类任务中的大量实验表明，ProMIM在插入现有方法时，能够持续提升泛化性能，为现实世界的视觉-语言应用提供了一个实用、轻量级的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [236] [Towards Reliable Audio Deepfake Attribution and Model Recognition: A Multi-Level Autoencoder-Based Framework](https://arxiv.org/abs/2508.02521)
> *走向可靠的音频深度伪造归因和模型识别：一个基于多级自编码器的框架*

*Andrea Di Pierno, Luca Guarnera, Dario Allegra, Sebastiano Battiato* | **Category: cs.CV, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 音频深度伪造, 归因, 模型识别, 自编码器, LAVA框架

**Comment:** 

> **TL;DR:** 该论文提出了LAVA框架，一个基于多级自编码器的分层框架，用于音频深度伪造检测和模型识别，在多个数据集上表现出强大的性能和鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了LAVA框架，一个用于音频深度伪造归因和模型识别的分层方法。其核心是利用仅在伪造音频上训练的卷积自编码器提取注意力增强型潜在表示，并在此基础上构建两个专门的分类器。特别值得注意的是，该方法在开集条件下通过引入置信度阈值提升了鲁棒性，解决了现有研究中未充分探索的关键挑战。其在多个公共基准上的强大性能和代码、模型的公开，都显示了其在推动该领域发展方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 音频深度伪造的泛滥对数字通信中的信任构成了日益增长的威胁。虽然检测方法有所进步，但将音频深度伪造归因于其源模型仍然是一个未充分探索但至关重要的挑战。

**Method:** 本文介绍了LAVA（Layered Architecture for Voice Attribution），一个用于音频深度伪造检测和模型识别的分层框架。该框架利用由仅在伪造音频上训练的卷积自编码器提取的注意力增强型潜在表示。两个专门的分类器在此特征上运行：音频深度伪造归因（ADA），识别生成技术；以及音频深度伪造模型识别（ADMR），识别特定的生成模型实例。为提高开集条件下的鲁棒性，引入了基于置信度的拒绝阈值。

**Result:** 在ASVspoof2021、FakeOrReal和CodecFake数据集上的实验显示出强大的性能：ADA分类器在所有数据集上F1分数超过95%，ADMR模块在六个类别上达到96.31%的宏观F1分数。对ASVpoof2019 LA的未见攻击和误差传播分析的额外测试证实了LAVA的鲁棒性和可靠性。

**Conclusion:** 该框架通过引入一种在开集条件下进行深度伪造归因和模型识别的监督方法，并经过公共基准验证，以及公开模型和代码，推动了该领域的发展。

> **ai_Abstract:** 针对日益增长的音频深度伪造威胁，本文提出LAVA（Layered Architecture for Voice Attribution）框架，一个基于注意力增强型潜在表示的多级自编码器系统，用于音频深度伪造的归因和源模型识别。LAVA包含ADA和ADMR两个分类器，分别用于识别生成技术和特定模型实例，并通过置信度阈值增强开集条件下的鲁棒性。实验证明，LAVA在多个公共数据集上实现了高F1分数（ADA >95%，ADMR 96.31%），并对未见攻击表现出强大的鲁棒性和可靠性，为深度伪造归因提供了监督式解决方案。

> **摘要翻译:** 音频深度伪造的泛滥对数字通信中的信任构成了日益增长的威胁。虽然检测方法有所进步，但将音频深度伪造归因于其源模型仍然是一个未充分探索但至关重要的挑战。在本文中，我们引入了LAVA（Layered Architecture for Voice Attribution），一个用于音频深度伪造检测和模型识别的分层框架，该框架利用由仅在伪造音频上训练的卷积自编码器提取的注意力增强型潜在表示。两个专门的分类器在此特征上运行：音频深度伪造归因（ADA），用于识别生成技术；以及音频深度伪造模型识别（ADMR），用于识别特定的生成模型实例。为提高开集条件下的鲁棒性，我们引入了基于置信度的拒绝阈值。在ASVspoof2021、FakeOrReal和CodecFake数据集上的实验显示出强大的性能：ADA分类器在所有数据集上F1分数超过95%，ADMR模块在六个类别上达到96.31%的宏观F1分数。对ASVpoof2019 LA的未见攻击和误差传播分析的额外测试证实了LAVA的鲁棒性和可靠性。该框架通过引入一种在开集条件下进行深度伪造归因和模型识别的监督方法，并经过公共基准验证，以及公开模型和代码，推动了该领域的发展。模型和代码可在https://www.github.com/adipiz99/lava-framework获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [243] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
> *开放世界点云语义分割：一种人机协同框架*

*Peng Zhang, Songru Yang, Jinsheng Sun, Weiqing Li, Zhiyong Su* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 点云语义分割, 开放世界, 人机协同, 原型学习, 稀疏标注

**Comment:** 

> **TL;DR:** 本文提出了HOW-Seg，首个用于开放世界点云语义分割的人机协同框架，通过稀疏的人工标注和迭代反馈，实现了对基类和新类的高质量分割，性能超越现有方法。

**AI_Comments:** HOW-Seg的创新之处在于其将人机协同引入开放世界点云语义分割，有效解决了数据标注稀疏性和原型偏差问题。通过引入分层原型消歧和CRF优化，提高了分割的准确性和鲁棒性。其核心思想是利用人的少量反馈来迭代优化模型，这对于实际应用中数据获取成本高昂的场景具有重要意义。该框架为未来的人机协同点云处理提供了新的范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有开放世界点云语义分割方法依赖于资源密集型的离线增量学习或密集标注的支持数据，限制了其在实际场景中的应用。

**Method:** 本文提出了HOW-Seg框架，具体方法包括：1) 直接在查询数据上构建类原型，避免了支持数据和查询数据之间类内分布偏移导致的偏差。2) 利用稀疏的人工标注作为指导，实现基于原型的基类和新类分割。3) 引入分层原型消歧机制来细化模糊原型。4) 在细化后的原型上使用密集条件随机场（CRF）来优化标签分配。5) 通过迭代的人机反馈动态改进预测。

**Result:** 在稀疏标注（例如，每个新类一次点击）下，HOW-Seg的性能与最先进的广义少样本分割（GFS-Seg）方法在5样本设置下相当或超越。当使用先进骨干网络（如Stratified Transformer）和更密集的标注（如每个子场景10次点击）时，HOW-Seg在S3DIS上达到85.27% mIoU，在ScanNetv2上达到66.37% mIoU，显著优于其他替代方案。

**Conclusion:** HOW-Seg作为首个开放世界点云语义分割的人机协同框架，通过有效利用稀疏人工标注和迭代反馈，显著提高了基类和新类分割的质量，解决了现有方法的局限性。

> **ai_Abstract:** 本文提出了HOW-Seg，一个针对开放世界点云语义分割（OW-Seg）的首个人机协同框架。为克服现有方法对密集标注或离线学习的依赖，HOW-Seg通过直接在查询数据上构建类原型并利用稀疏人工标注进行指导，实现了对基类和新类的高质量分割。它引入了分层原型消歧机制来细化原型，并使用密集条件随机场优化标签分配。通过迭代的人机反馈，HOW-Seg动态提升预测性能。实验证明，在稀疏标注下，HOW-Seg的性能可与SOTA方法匹敌或超越，并在密集标注下显著优于现有替代方案。

> **摘要翻译:** 开放世界点云语义分割（OW-Seg）旨在预测真实世界场景中基类和新类点云的标签。然而，现有方法依赖于资源密集型的离线增量学习或密集标注的支持数据，限制了其实用性。为了解决这些局限性，我们提出了HOW-Seg，这是首个用于OW-Seg的人机协同框架。具体来说，我们直接在查询数据上构建类原型，即基本的分割单元，从而避免了支持数据和查询数据之间类内分布偏移导致的“原型偏差”。通过利用稀疏的人工标注作为指导，HOW-Seg能够对基类和新类进行基于原型的分割。考虑到初始原型的粒度不足，我们引入了一种分层原型消歧机制来细化模糊原型，这些原型对应于不同类别的标注。为了进一步丰富上下文感知能力，我们在细化后的原型上采用了密集条件随机场（CRF）来优化其标签分配。通过迭代的人机反馈，HOW-Seg动态地改进其预测，实现了基类和新类的高质量分割。实验表明，在稀疏标注（例如，每个新类一次点击）下，HOW-Seg在5样本设置下与最先进的广义少样本分割（GFS-Seg）方法相当或超越。当使用先进骨干网络（例如，Stratified Transformer）和更密集的标注（例如，每个子场景10次点击）时，HOW-Seg在S3DIS上达到85.27% mIoU，在ScanNetv2上达到66.37% mIoU，显著优于其他替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [249] [CSRAP: Enhanced Canvas Attention Scheduling for Real-Time Mission Critical Perception](https://arxiv.org/abs/2508.04976)
> *CSRAP：增强型画布注意力调度用于实时关键任务感知*

*Md Iftekharul Islam Sakib, Yigong Hu, Tarek Abdelzaher* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 画布注意力调度, 实时感知, 边缘计算, 目标检测, 资源优化

**Comment:** 

> **TL;DR:** CSRAP通过可变大小的画布帧和可选画布帧率，增强了边缘平台实时感知的画布注意力调度，显著提高了目标检测的精度和召回率。

**AI_Comments:** 本文通过引入可变大小画布帧和可选择画布帧率，对现有的画布注意力调度机制进行了创新性扩展，有效解决了边缘设备上实时高分辨率目标检测的资源限制问题。其重要性在于，该方法能够在保持甚至提升检测性能的同时，优化资源利用，这对于自动驾驶等关键任务应用至关重要。研究结果表明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 边缘平台上的实时感知面临核心挑战：在有限计算资源和严格延迟约束下执行高分辨率目标检测。

**Method:** 本文扩展了先前的基于画布的注意力调度工作，通过(i)允许可变大小的画布帧和(ii)采用可选择的画布帧率，使其可以偏离原始数据帧率。作者使用YOLOv11作为感知模块，在NVIDIA Jetson Orin Nano上评估了该解决方案，检查来自Waymo开放数据集的视频帧。

**Result:** 结果表明，额外的自由度改善了可达到的质量/成本权衡，从而实现了相对于现有技术更高的一致平均精度(mAP)和召回率。

**Conclusion:** 通过引入可变大小画布帧和可选画布帧率，CSRAP显著提升了边缘平台实时感知任务中目标检测的性能（mAP和召回率）。

> **ai_Abstract:** 本文提出CSRAP，一种增强型画布注意力调度方法，旨在解决边缘平台实时高分辨率目标检测的资源限制和延迟挑战。该方法通过引入可变大小的画布帧和可选画布帧率来改进现有画布调度机制。在NVIDIA Jetson Orin Nano上使用YOLOv11和Waymo数据集进行的评估显示，CSRAP能有效提升质量/成本权衡，并实现比现有技术更高的平均精度和召回率。

> **摘要翻译:** 边缘平台上的实时感知面临核心挑战：在有限计算资源和严格延迟约束下执行高分辨率目标检测。早期的工作提出了基于画布的注意力调度作为一种机制，以减少感知子系统的资源需求。它将输入数据帧中感兴趣的区域整合到一个更小的区域，称为画布帧，该区域可以以所需的帧率进行处理。本文通过(i)允许可变大小的画布帧和(ii)采用可选择的画布帧率（可能偏离原始数据帧率）来扩展先前的基于画布的注意力调度文献。我们通过在NVIDIA Jetson Orin Nano上运行YOLOv11作为感知模块，检查Waymo开放数据集中的视频帧来评估我们的解决方案。我们的结果表明，额外的自由度改善了可达到的质量/成本权衡，从而实现了相对于现有技术更高的一致平均精度（mAP）和召回率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [256] [Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression](https://arxiv.org/abs/2508.04979)
> *引导一步扩散模型与高保真解码器用于快速图像压缩*

*Zheng Chen, Mingde Zhou, Jinpei Guo, Jiale Yuan, Yifei Ji, Yulun Zhang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 扩散模型, 图像压缩, 单步解码, 高保真, 速率-失真-感知

**Comment:** 

> **TL;DR:** 本文提出SODEC，一种单步扩散图像压缩模型，通过利用信息丰富的潜在表示和高保真度指导，解决了现有扩散模型解码延迟高和保真度差的问题，实现了更快的解码速度和卓越的性能。

**AI_Comments:** SODEC的创新点在于将扩散模型的迭代解码过程简化为单步，并通过VAE和保真度指导模块弥补了单步带来的潜在信息损失和保真度问题。这极大地提升了扩散模型在图像压缩领域的实用性，特别是解决了长期存在的速度瓶颈，使其在实时应用中更具竞争力。其在保持感知质量的同时，显著提升速度和保真度，是图像压缩领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散的图像压缩模型存在两大缺点：一是多步采样导致的解码延迟过高；二是过度依赖生成先验导致保真度差。

**Method:** 本文提出了一种新颖的单步扩散图像压缩模型SODEC。该方法利用预训练的VAE模型生成信息丰富的潜在表示，并用单步解码取代迭代去噪过程。同时，引入保真度指导模块以确保输出忠实于原始图像。此外，设计了速率退火训练策略以在极低比特率下进行有效训练。

**Result:** 实验表明，SODEC显著优于现有方法，实现了卓越的速率-失真-感知性能。与之前的基于扩散的压缩模型相比，SODEC的解码速度提高了20倍以上。

**Conclusion:** SODEC通过其单步解码和高保真度设计，成功解决了扩散模型在图像压缩中面临的速度和保真度问题，为快速图像压缩提供了高性能的解决方案。

> **ai_Abstract:** 本文提出了SODEC，一种新颖的单步扩散图像压缩模型，旨在解决现有扩散模型在图像压缩中解码延迟高和保真度差的问题。SODEC通过利用预训练的VAE生成信息丰富的潜在表示，并采用单步解码取代多步迭代过程。同时，引入保真度指导模块以确保输出忠实于原始图像，并设计速率退火训练策略以适应低比特率。实验证明，SODEC在速率-失真-感知性能上显著优于现有方法，并且解码速度比现有扩散模型快20倍以上。

> **摘要翻译:** 基于扩散的图像压缩已展现出令人印象深刻的感知性能。然而，它存在两个关键缺点：(1) 由于多步采样导致的解码延迟过高；(2) 由于过度依赖生成先验导致的保真度差。为解决这些问题，我们提出了SODEC，一种新颖的单步扩散图像压缩模型。我们认为在图像压缩中，足够信息丰富的潜在表示使得多步细化变得不必要。基于这一见解，我们利用预训练的基于VAE的模型生成信息丰富的潜在表示，并用单步解码取代迭代去噪过程。同时，为了提高保真度，我们引入了保真度指导模块，鼓励输出忠实于原始图像。此外，我们设计了速率退火训练策略，以在极低比特率下实现有效训练。大量实验表明，SODEC显著优于现有方法，实现了卓越的速率-失真-感知性能。此外，与之前的基于扩散的压缩模型相比，SODEC的解码速度提高了20倍以上。代码已发布在：https://github.com/zhengchen1999/SODEC。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [263] [Propagating Sparse Depth via Depth Foundation Model for Out-of-Distribution Depth Completion](https://arxiv.org/abs/2508.04984)
> *通过深度基础模型传播稀疏深度用于分布外深度补全*

*Shenglun Chen, Xinzhu Ma, Hong Zhang, Haojie Li, Zhihui Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 深度补全, 深度基础模型, 分布外, 稀疏深度, 双空间传播

**Comment:** 

> **TL;DR:** 提出一种新的深度补全框架，利用深度基础模型在无需大规模训练的情况下，显著提升了分布外场景的鲁棒性，并优于现有最先进方法。

**AI_Comments:** 这项工作通过巧妙地结合深度基础模型和无学习参数的双空间传播，为分布外深度补全提供了一个创新且高效的解决方案。其关键创新在于利用预训练的深度基础模型获取丰富的环境上下文，并设计了无需额外训练的双空间传播机制，显著提升了模型在未见过数据上的泛化能力，避免了对大规模特定领域数据的依赖，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度补全模型依赖有限数据，在分布外（OOD）场景性能显著下降。深度基础模型在单目深度估计中展现出卓越鲁棒性，利用它们增强深度补全的鲁棒性是一个有前景的解决方案。

**Method:** 提出一个新颖的深度补全框架。该框架利用深度基础模型从RGB图像中提取环境线索（结构和语义上下文），以指导稀疏深度信息向缺失区域的传播。设计了一种无学习参数的双空间传播方法，在3D和2D空间中有效传播稀疏深度，以保持几何结构和局部一致性。引入一个可学习的校正模块来逐步调整深度预测。

**Result:** 该框架在OOD场景中表现出色，并且优于现有的最先进深度补全方法。

**Conclusion:** 通过利用深度基础模型和创新的传播与校正机制，本研究成功开发了一个在分布外场景中表现出卓越鲁棒性的深度补全框架，无需大规模训练，并超越了现有技术。

> **ai_Abstract:** 本文提出一种新的深度补全框架，旨在解决现有方法在分布外场景中性能下降的问题。该框架通过利用深度基础模型从RGB图像中提取环境线索，并结合无学习参数的双空间传播方法，有效传播稀疏深度。此外，引入可学习的校正模块以细化深度预测。实验证明，该方法在无需大规模训练的情况下，在多个分布外数据集上表现出卓越的鲁棒性，并超越了现有最先进的深度补全技术。

> **摘要翻译:** 深度补全是计算机视觉中的一个关键挑战，旨在从稀疏深度图（通常与配对的RGB图像一起）重建密集深度图。现有的基于学习的模型依赖于精心准备但有限的数据，导致在分布外（OOD）场景中性能显著下降。最近的基础模型通过大规模训练在单目深度估计中表现出卓越的鲁棒性，利用此类模型来增强深度补全模型的鲁棒性是一个有前景的解决方案。在这项工作中，我们提出了一种新颖的深度补全框架，该框架利用深度基础模型在无需大规模训练的情况下实现卓越的鲁棒性。具体来说，我们利用深度基础模型从RGB图像中提取环境线索，包括结构和语义上下文，以指导稀疏深度信息向缺失区域的传播。我们进一步设计了一种双空间传播方法，没有任何可学习参数，以有效地在3D和2D空间中传播稀疏深度，以保持几何结构和局部一致性。为了细化复杂的结构，我们引入了一个可学习的校正模块，以逐步将深度预测调整到真实深度。我们在NYUv2和KITTI数据集上训练了我们的模型作为分布内数据集，并在其他16个数据集上广泛评估了该框架。我们的框架在OOD场景中表现出色，并且优于现有的最先进深度补全方法。我们的模型已在https://github.com/shenglunch/PSD 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [270] [Unified modality separation: A vision-language framework for unsupervised domain adaptation](https://arxiv.org/abs/2508.04987)
> *统一模态分离：一种用于无监督域适应的视觉-语言框架*

*Xinyao Li, Jingjing Li, Zhekai Du, Lei Zhu, Heng Tao Shen* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 无监督域适应, 视觉-语言模型, 模态分离, 模态差距, 提示调整

**Comment:** 

> **TL;DR:** 该研究提出了一个统一的模态分离框架，通过解耦模态特定和模态不变组件来解决预训练视觉-语言模型在无监督域适应中存在的模态差距问题，显著提升了性能和计算效率。

**AI_Comments:** 这项工作创新性地解决了视觉-语言模型在无监督域适应中存在的模态差距问题，通过引入统一的模态分离框架，使得模型能够更精细地处理模态特异性和模态不变性知识。其提出的模态差异度量和自适应集成权重机制是关键的创新点，不仅提升了性能，还显著提高了计算效率，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 预训练视觉-语言模型（VLMs）在无监督域适应（UDA）中表现出潜力，但模态间固有的差异（模态差距）导致直接UDA仅传输模态不变知识，从而导致次优的目标性能。

**Method:** 提出一个统一的模态分离框架，在训练阶段将VLM特征中的不同模态组件（模态特定和模态不变）解耦并统一处理。在测试阶段，自动确定模态自适应集成权重以最大化不同组件的协同作用。设计了一个模态差异度量来评估实例级模态特性，将样本分为模态不变、模态特定和不确定样本。模态不变样本用于促进跨模态对齐，不确定样本则被标注以增强模型能力。该方法基于提示调整技术。

**Result:** 方法实现了高达9%的性能提升，同时计算效率提高了9倍。在各种骨干网络、基线、数据集和适应设置下进行了广泛的实验和分析，证明了其设计的有效性。

**Conclusion:** 通过统一模态分离框架处理模态差距，可以显著提升预训练视觉-语言模型在无监督域适应任务中的性能和计算效率，证明了考虑模态特定和模态不变组件的重要性。

> **ai_Abstract:** 本文提出了一个统一的模态分离框架，旨在解决预训练视觉-语言模型（VLMs）在无监督域适应（UDA）中因模态差距导致的性能次优问题。该框架能够解耦并分别处理模态特定和模态不变组件，并在测试时通过自适应集成权重最大化协同效应。通过引入模态差异度量来分类样本，并利用模态不变样本进行跨模态对齐，标注不确定样本以增强模型。实验证明，该方法在显著提升性能的同时，大幅提高了计算效率。

> **摘要翻译:** 无监督域适应（UDA）使在有标签源域上训练的模型能够处理新的无标签域。最近，预训练视觉-语言模型（VLMs）通过利用语义信息促进目标任务，展示了有前景的零样本性能。通过对齐视觉和文本嵌入，VLMs在弥合域差距方面取得了显著成功。然而，模态之间自然存在固有的差异，这被称为模态差距。我们的发现表明，在模态差距存在的情况下直接进行UDA仅传输模态不变知识，导致次优的目标性能。为了解决这一限制，我们提出了一个统一的模态分离框架，该框架同时容纳模态特定和模态不变组件。在训练期间，不同的模态组件从VLM特征中解耦，然后以统一的方式单独处理。在测试时，自动确定模态自适应集成权重，以最大化不同组件的协同作用。为了评估实例级模态特征，我们设计了一个模态差异度量，将样本分为模态不变、模态特定和不确定样本。模态不变样本用于促进跨模态对齐，而不确定样本则被标注以增强模型能力。基于提示调整技术，我们的方法在计算效率提高9倍的情况下，实现了高达9%的性能提升。在各种骨干网络、基线、数据集和适应设置下进行的广泛实验和分析证明了我们设计的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [277] [Modeling Rapid Contextual Learning in the Visual Cortex with Fast-Weight Deep Autoencoder Networks](https://arxiv.org/abs/2508.04988)
> *采用快权重深度自编码网络模拟视觉皮层中的快速上下文学习*

*Yue Li, Weifan Wang, Tai Sing Lee* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 快速上下文学习, 视觉皮层, 快权重, 深度自编码器, LoRA

**Comment:** 

> **TL;DR:** 本研究使用基于Vision Transformer的自编码器和LoRA技术，模拟了视觉皮层中快速上下文学习的机制，并发现快权重能显著增强早期层对全局上下文的敏感性。

**AI_Comments:** 本研究的创新点在于将神经科学中关于视觉皮层快速上下文学习的机制与深度学习模型相结合，特别是引入了“快权重”的概念并使用LoRA技术进行实现。这不仅为理解大脑工作机制提供了计算模型，也为深度学习中实现快速适应和情境依赖学习提供了新的思路。其重要性在于搭建了神经科学与人工智能之间的桥梁，揭示了快速学习可能通过权重动态调整实现。

<details>
  <summary>Details</summary>

**Motivation:** 近期神经生理学研究表明，早期视觉皮层能快速学习全局图像上下文，表现为对熟悉图像上下文的反应稀疏化和平均活动降低，这主要归因于局部循环交互。本研究旨在从功能角度探讨熟悉度训练如何诱导深度神经网络早期层对全局上下文的敏感性。

**Method:** 本研究采用基于Vision Transformer (ViT) 的自编码器来调查熟悉度训练如何诱导深度神经网络早期层对全局上下文的敏感性。研究假设快速学习通过编码瞬时或短期记忆痕迹的快权重进行，并探索使用低秩适应（LoRA）在每个Transformer层中实现这些快权重。

**Result:** 1. 所提出的基于ViT的自编码器的自注意力电路执行的流形变换类似于熟悉度效应的神经电路模型。2. 熟悉度训练使早期层的潜在表示与包含全局上下文信息的顶层表示对齐。3. 熟悉度训练拓宽了记忆图像上下文中的自注意力范围。4. 基于LoRA的快权重显著增强了这些效应。

**Conclusion:** 这些发现表明，熟悉度训练将全局敏感性引入到分层网络的早期层中，并且混合的快慢权重架构可能为研究大脑中快速全局上下文学习提供一个可行的计算模型。

> **ai_Abstract:** 本研究旨在使用基于Vision Transformer (ViT) 的深度自编码器模型，结合低秩适应（LoRA）实现的快权重，来模拟和理解视觉皮层中快速上下文学习的机制。研究发现，熟悉度训练能使神经网络早期层对全局上下文产生敏感性，表现为潜在表示的对齐和自注意力范围的拓宽，且这些效应通过快权重显著增强。这提出了一种混合快慢权重架构作为大脑快速全局上下文学习的计算模型。

> **摘要翻译:** 最近的神经生理学研究表明，早期视觉皮层可以快速学习全局图像上下文，表现为在熟悉与新颖图像上下文下，群体反应的稀疏化和平均活动的减少。这种现象主要归因于局部循环交互，而非前馈或反馈路径的变化，这得到了经验发现和电路级建模的支持。能够模拟这些效应的循环神经网络已被证明可以重塑神经流形的几何结构，增强对无关变化的鲁棒性和不变性。在本研究中，我们采用基于Vision Transformer (ViT) 的自编码器，从功能角度调查熟悉度训练如何诱导深度神经网络早期层对全局上下文的敏感性。我们假设快速学习通过快权重进行操作，这些快权重编码瞬时或短期记忆痕迹，并且我们探索在每个Transformer层内使用低秩适应（LoRA）来实现这种快权重。我们的结果显示：(1) 所提出的基于ViT的自编码器的自注意力电路执行的流形变换类似于熟悉度效应的神经电路模型。(2) 熟悉度训练使早期层的潜在表示与包含全局上下文信息的顶层表示对齐。(3) 熟悉度训练拓宽了记忆图像上下文中的自注意力范围。(4) 基于LoRA的快权重显著增强了这些效应。总而言之，这些发现表明熟悉度训练将全局敏感性引入到分层网络的早期层中，并且混合的快慢权重架构可能为研究大脑中快速全局上下文学习提供一个可行的计算模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [284] [Attribute Guidance With Inherent Pseudo-label For Occluded Person Re-identification](https://arxiv.org/abs/2508.04998)
> *基于固有伪属性标签的遮挡行人重识别*

*Rui Zhi, Zhen Yang, Haiyang Zhang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 行人重识别, 遮挡Re-ID, 属性引导, 伪标签, 细粒度特征

**Comment:** 

> **TL;DR:** 本文提出AG-ReID框架，利用预训练模型生成属性伪标签，并采用双重引导机制，有效解决了遮挡行人重识别中现有模型忽视细粒度属性信息的问题，并在多个数据集上取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了AG-ReID框架，它巧妙地利用了预训练模型的固有能力来生成细粒度属性伪标签，避免了额外标注的需求，这在数据标注成本高昂的领域具有重要意义。双重引导机制的设计，结合了整体与细粒度信息，有效提升了模型在复杂遮挡和细微差异场景下的识别能力，对行人重识别领域，尤其是遮挡场景下的研究，具有重要的推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的预训练视觉-语言模型在遮挡行人重识别任务中面临挑战，因为它们侧重于整体图像语义，而忽略了细粒度属性信息，这在处理部分遮挡行人或区分外观细微差异的个体时尤为明显。

**Method:** 本文提出了Attribute-Guide ReID (AG-ReID)框架。该框架利用预训练模型固有的能力提取细粒度语义属性，无需额外数据或标注。它通过两阶段过程运行：首先生成捕获细微视觉特征的属性伪标签，然后引入结合整体和细粒度属性信息的双重引导机制，以增强图像特征提取。

**Result:** AG-ReID在多个广泛使用的Re-ID数据集上取得了最先进（SOTA）的结果，在处理遮挡和细微属性差异方面显示出显著改进，同时在标准Re-ID场景中保持了竞争力。

**Conclusion:** AG-ReID框架通过利用预训练模型的细粒度属性引导和双重引导机制，有效解决了遮挡行人重识别中细粒度信息不足的问题，显著提升了在该任务上的性能。

> **ai_Abstract:** 本文提出一种名为AG-ReID的新颖框架，旨在解决遮挡行人重识别中预训练模型忽视细粒度属性信息的局限性。AG-ReID利用预训练模型的固有能力生成细粒度属性伪标签，并引入双重引导机制，结合整体和细粒度信息来增强图像特征提取。实验证明，该方法在多个Re-ID数据集上实现了最先进的性能，显著改善了对遮挡和细微属性差异的处理。

> **摘要翻译:** 行人重识别（Re-ID）旨在匹配不同摄像机视图中的行人图像，其中遮挡Re-ID解决了行人部分可见的场景。虽然预训练的视觉-语言模型在Re-ID任务中表现出有效性，但它们在遮挡场景中面临重大挑战，因为它们侧重于整体图像语义而忽视了细粒度属性信息。当处理部分遮挡的行人或区分外观细微差异的个体时，这种限制变得尤为明显。为了解决这一限制，我们提出了Attribute-Guide ReID（AG-ReID），一个新颖的框架，它利用预训练模型固有的能力来提取细粒度语义属性，而无需额外的数据或标注。我们的框架通过两阶段过程运行：首先生成捕获细微视觉特征的属性伪标签，然后引入结合整体和细粒度属性信息的双重引导机制，以增强图像特征提取。广泛的实验表明，AG-ReID在多个广泛使用的Re-ID数据集上取得了最先进（SOTA）的结果，在处理遮挡和细微属性差异方面显示出显著改进，同时在标准Re-ID场景中保持了竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [291] [CRAM: Large-scale Video Continual Learning with Bootstrapped Compression](https://arxiv.org/abs/2508.05001)
> *CRAM：大规模视频持续学习与自举压缩*

*Shivani Mall, Joao F. Henriques* | **Category: cs.CV, cs.LG, cs.PF** | **Updated: 2025-08-07**

**Keywords:** 持续学习, 视频学习, 内存压缩, 灾难性遗忘, CRAM

**Comment:** 

> **TL;DR:** 提出CRAM方法，通过存储压缩视频编码解决视频持续学习中的高内存需求问题，并在大规模视频数据集上实现了更好的性能和更低的内存占用。

**AI_Comments:** 本文的创新点在于将数据压缩与持续学习相结合，特别是在视频领域。通过存储视频编码而非原始数据，并设计了独特的编码刷新机制来克服压缩器自身的灾难性遗忘，有效解决了视频持续学习中的内存瓶颈。其在大规模数据集上的实证表现，表明了该方法在实际部署中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续学习方法在处理视频数据时面临高内存需求，特别是对于长视频和持续流，这与常见的排练缓冲区大小限制相悖。传统的IID采样需要随机访问完整数据集，不适用于资源受限的部署系统。

**Method:** 本文提出CRAM（Continually Refreshed Amodal Memory）方法。核心思想是使用压缩视觉，即存储视频编码（嵌入）而不是原始输入，并通过从滚动缓冲区中进行IID采样来训练视频分类器。为了解决在线训练视频压缩器时可能出现的灾难性遗忘问题，提出一种刷新视频编码的方案，通过使用网络的前一版本进行仔细解压缩，然后使用新版本重新压缩。

**Result:** 在EpicKitchens-100和Kinetics-700等大规模视频持续学习基准上扩展了当前设置，能够在2GB以下存储数千个相对较长的视频。实验证明，该视频持续学习方法在显著降低内存占用的情况下，优于现有技术。

**Conclusion:** CRAM通过创新的压缩和刷新机制，有效解决了大规模视频持续学习中的内存瓶颈和灾难性遗忘问题，实现了更高效和高性能的视频持续学习。

> **ai_Abstract:** 本文提出CRAM（持续刷新无模态记忆）方法，旨在解决大规模视频持续学习中高内存需求和灾难性遗忘的挑战。CRAM通过存储压缩的视频编码而非原始数据，并引入一种刷新机制来应对压缩器自身的遗忘问题。实验证明，CRAM在EpicKitchens-100和Kinetics-700等大规模视频数据集上，以显著减少的内存占用，实现了超越现有方法的性能。

> **摘要翻译:** 持续学习（CL）有望使神经网络从连续的输入流中学习，而不是依赖于需要随机访问整个数据集的IID（独立同分布）采样。这将大大减少存储需求，并使部署系统能够像生物学习一样应对自然分布变化，实现自给自足。我们专注于采用基于排练方法的视频持续学习，该方法通过记忆缓冲区中的过去样本进行强化。我们认为，实际视频持续学习之所以具有挑战性，部分原因是视频的高内存需求，长视频和持续流进一步加剧了这一问题，这与常见的排练缓冲区大小限制相悖。为了解决这个问题，我们建议使用压缩视觉，即存储视频编码（嵌入）而不是原始输入，并通过从这个滚动缓冲区中进行IID采样来训练视频分类器。在线训练视频压缩器（因此不依赖任何预训练网络）意味着它也容易遭受灾难性遗忘。我们提出了一种处理这种遗忘的方案，即刷新视频编码，这需要使用网络的前一版本进行仔细解压缩，并使用新版本进行重新压缩。我们将我们的方法命名为持续刷新无模态记忆（CRAM）。我们将当前的视频持续学习基准扩展到大规模设置，即EpicKitchens-100和Kinetics-700，在2GB以下存储了数千个相对较长的视频，并经验性地证明我们的视频持续学习方法在显著降低内存占用的情况下优于现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [298] [Multimodal Causal-Driven Representation Learning for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2508.05008)
> *多模态因果驱动表示学习用于可泛化医学图像分割*

*Xusheng Liang, Lihua Zhou, Nianxin Li, Miao Xu, Ziyang Song, Dong Yi, Jinlin Wu, Hongbin Liu, Jiebo Luo, Zhen Lei* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 医学图像分割, 域泛化, 因果推断, 视觉-语言模型, CLIP

**Comment:** 

> **TL;DR:** 针对医学图像分割中的域泛化问题，提出MCDRL框架，结合CLIP和因果推断，通过识别并消除领域特异性变异来提高模型泛化性。

**AI_Comments:** 这篇论文的创新点在于将因果推断引入到视觉-语言模型中，以系统性地解决医学图像领域中常见的域漂移问题。通过明确构建和利用“混杂因素字典”来消除非病灶相关的领域特异性变异，MCDRL提供了一种提高模型泛化能力的新颖且有前景的方法，对于临床应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言模型（VLMs）如CLIP在医学图像领域应用受限，因为医学数据变异性高且复杂，存在设备差异、伪影、成像模式等混杂因素导致的显著域漂移，导致模型在未见域上泛化能力差。

**Method:** 提出多模态因果驱动表示学习（MCDRL）框架。分两步实现：1. 利用CLIP的跨模态能力，通过文本提示识别候选病灶区域并构建混杂因素字典，该字典专门用于表示域特异性变异。2. 训练一个因果干预网络，利用此字典识别并消除这些域特异性变异的影响，同时保留对分割任务至关重要的解剖结构信息。

**Result:** 广泛的实验表明，MCDRL始终优于竞争方法，在分割精度上表现出色，并展现出强大的泛化能力。

**Conclusion:** MCDRL框架通过结合CLIP和因果推断，有效解决了医学图像分割中的域泛化问题，提高了模型的准确性和泛化能力。

> **ai_Abstract:** 本文提出了一种新颖的多模态因果驱动表示学习（MCDRL）框架，旨在解决医学图像分割中的域泛化挑战。MCDRL结合了CLIP的跨模态能力和因果推断，通过构建混杂因素字典来识别并消除医学图像中由设备差异、伪影等引起的域特异性变异，同时保留关键的解剖信息。实验结果表明，MCDRL在分割精度和泛化能力上均优于现有方法。

> **摘要翻译:** 视觉-语言模型（VLMs），如CLIP，在各种计算机视觉任务中展示了卓越的零样本能力。然而，由于医学数据的高度变异性和复杂性，它们在医学成像中的应用仍然具有挑战性。具体而言，医学图像经常表现出由各种混杂因素（包括设备差异、程序伪影和成像模式）引起的显著域漂移，这可能导致模型应用于未见域时泛化能力差。为了解决这一限制，我们提出了多模态因果驱动表示学习（MCDRL），这是一个新颖的框架，它将因果推断与VLM相结合，以解决医学图像分割中的域泛化问题。MCDRL分两步实现：首先，它利用CLIP的跨模态能力，通过文本提示识别候选病灶区域并构建混杂因素字典，该字典专门设计用于表示域特异性变异；其次，它训练一个因果干预网络，利用此字典识别并消除这些域特异性变异的影响，同时保留对分割任务至关重要的解剖结构信息。广泛的实验表明，MCDRL始终优于竞争方法，在分割精度上表现出色，并展现出强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [AU-IQA: A Benchmark Dataset for Perceptual Quality Assessment of AI-Enhanced User-Generated Content](https://arxiv.org/abs/2508.05016)
> *AU-IQA：一个用于AI增强用户生成内容感知质量评估的基准数据集*

*Shushi Wang, Chunyi Li, Zicheng Zhang, Han Zhou, Wei Dong, Jun Chen, Guangtao Zhai, Xiaohong Liu* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 感知质量评估, AI增强内容, 用户生成内容, 基准数据集, 图像质量评估

**Comment:** 

> **TL;DR:** 论文构建了一个名为AU-IQA的基准数据集，用于评估AI增强用户生成内容的感知质量。

**AI_Comments:** 这篇论文通过构建一个专门的基准数据集AU-IQA，填补了AI增强用户生成内容（AI-UGC）感知质量评估领域的空白。其创新之处在于针对AI-UGC这一特定混合内容类型，提供了急需的评估资源和性能分析，这对于推动AI图像增强技术的发展和提升用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** AI图像增强技术广泛应用，但缺乏专门的质量评估模型，限制了用户体验并阻碍了增强方法的发展。现有感知质量评估方法对UGC和AIGC单独有效，但它们在融合了两者特征的AI增强UGC（AI-UGC）上的有效性仍未被充分探索。

**Method:** 构建了一个名为AU-IQA的基准数据集，包含4800张由超分辨率、低光增强和去噪三种代表性增强类型生成的AI-UGC图像。在此数据集上，评估了一系列现有质量评估模型，包括传统IQA方法和大型多模态模型。

**Result:** 提供了对当前方法在评估AI-UGC感知质量方面表现的全面分析。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了AU-IQA，一个专门用于评估AI增强用户生成内容（AI-UGC）感知质量的基准数据集。鉴于现有质量评估模型在AI-UGC领域存在不足，该数据集包含了4800张经过超分辨率、低光增强和去噪处理的AI-UGC图像。研究人员在此数据集上评估了包括传统IQA方法和大型多模态模型在内的多种现有质量评估模型，并提供了这些模型在AI-UGC感知质量评估方面的性能分析。

> **摘要翻译:** AI图像增强技术已广泛应用于各种视觉应用中，显著提高了用户生成内容（UGC）的感知质量。然而，缺乏专门的质量评估模型已成为该领域的一个重要限制因素，限制了用户体验并阻碍了增强方法的发展。虽然感知质量评估方法在UGC和AIGC上分别表现出强大的性能，但它们在融合了两者特征的AI增强UGC（AI-UGC）上的有效性仍未被充分探索。为了解决这一空白，我们构建了AU-IQA，一个包含4800张AI-UGC图像的基准数据集，这些图像由超分辨率、低光增强和去噪三种代表性增强类型生成。在此数据集上，我们进一步评估了一系列现有质量评估模型，包括传统IQA方法和大型多模态模型。最后，我们全面分析了当前方法在评估AI-UGC感知质量方面的表现。AU-IQA的访问链接是https://github.com/WNNGGU/AU-IQA-Dataset。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [311] [A Novel Image Similarity Metric for Scene Composition Structure](https://arxiv.org/abs/2508.05037)
> *一种用于场景构图结构的新型图像相似度度量*

*Md Redwanul Haque, Manzur Murshed, Manoranjan Paul, Tsz-Kwan Lee* | **Category: cs.CV, cs.IT** | **Updated: 2025-08-07**

**Keywords:** 图像相似度度量, 场景构图结构, 生成式AI, 结构评估, SCSSIM

**Comment:** 

> **TL;DR:** 本文提出了一种名为SCSSIM的全新、分析性、免训练的图像相似度度量，专门用于评估生成式AI模型输出中场景构图结构的完整性，解决了现有方法在结构保真度评估方面的不足。

**AI_Comments:** 这篇论文提出了一种创新且实用的方法来解决生成式AI领域的一个关键挑战——如何客观评估生成图像的场景构图结构。SCSSIM的“分析性”和“免训练”特性是其主要创新点，这解决了传统基于神经网络方法存在的训练成本和泛化性问题。它专注于非对象级结构关系，填补了现有像素级和感知级度量无法有效捕捉的空白，对于确保生成内容的结构准确性和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI模型的快速发展需要超越人类感知的新型图像质量评估方法。一个关键问题是图像底层场景构图结构（SCS）的保存，这对于确保生成式AI输出的忠实性和结构准确性至关重要。传统的图像相似度度量（像素级、基于感知、基于神经网络）在评估SCS方面存在不足，无法充分捕捉结构保真度。

**Method:** 我们引入了SCS相似度指数度量（SCSSIM），这是一种新颖、分析性且免训练的度量标准。它通过利用图像的立方体分层分区导出的统计度量来量化SCS的保存，能够稳健地捕捉非基于对象的结构关系。

**Result:** 实验表明，SCSSIM对非构图失真具有高度不变性，能准确反映未改变的SCS。相反，它对构图失真表现出强烈的单调下降，精确指示SCS何时被改变。与现有度量相比，SCSSIM在结构评估方面表现出优越的特性。

**Conclusion:** SCSSIM是开发和评估生成模型、确保场景构图完整性的宝贵工具。

> **ai_Abstract:** 本文提出了一种名为SCSSIM（场景构图结构相似度指数度量）的新型图像相似度度量。SCSSIM是一种分析性且无需训练的方法，旨在解决现有度量在评估生成式AI模型输出中场景构图结构（SCS）完整性方面的不足。它通过利用图像立方体分层分区导出的统计度量来量化SCS的保存。实验证明，SCSSIM对非构图失真具有高不变性，并能精确反映构图失真，优于现有方法，是评估生成模型结构保真度的重要工具。

> **摘要翻译:** 生成式AI模型的快速发展需要超越人类感知的新型图像质量评估方法。这些模型的一个关键问题是图像底层场景构图结构（SCS）的保存，SCS定义了物体与背景之间的几何关系、它们的相对位置、大小、方向等。保持SCS完整性对于确保忠实和结构准确的生成式AI输出至关重要。传统的图像相似度度量在评估SCS方面往往不足。像素级方法对微小的视觉噪声过于敏感，而基于感知的度量则优先考虑人类审美吸引力，两者都未能充分捕捉结构保真度。此外，最近基于神经网络的度量引入了训练开销和潜在的泛化问题。我们引入了SCS相似度指数度量（SCSSIM），这是一种新颖、分析性且免训练的度量标准，它通过利用图像的立方体分层分区导出的统计度量来量化SCS的保存，能够稳健地捕捉非基于对象的结构关系。我们的实验表明，SCSSIM对非构图失真具有高度不变性，能准确反映未改变的SCS。相反，它对构图失真表现出强烈的单调下降，精确指示SCS何时被改变。与现有度量相比，SCSSIM在结构评估方面表现出优越的特性，使其成为开发和评估生成模型、确保场景构图完整性的宝贵工具。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [319] [HAMoBE: Hierarchical and Adaptive Mixture of Biometric Experts for Video-based Person ReID](https://arxiv.org/abs/2508.05038)
> *HAMoBE：用于视频行人重识别的层级自适应生物特征专家混合模型*

*Yiyang Su, Yunping Shi, Feng Liu, Xiaoming Liu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 行人重识别, 视频ReID, 生物特征, 专家混合, 自适应学习

**Comment:** 

> **TL;DR:** HAMoBE是一个新颖的层级自适应生物特征专家混合框架，通过独立建模外观、体型和步态等关键生物特征并自适应集成，显著提升了视频行人重识别的性能。

**AI_Comments:** HAMoBE的创新点在于其层级和自适应的专家混合架构，以及引入双输入决策门控网络来动态调整不同生物特征专家的贡献，这有效地解决了视频行人重识别中特征选择和融合的挑战。其模仿人类感知机制的思路也颇具启发性，对提升复杂动态环境下的行人重识别鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频行人重识别方法通常忽略了从查询-图库对的视频中识别和选择最具判别力的特征以进行有效匹配的必要性。

**Method:** 我们提出了一个新颖的层级自适应生物特征专家混合（HAMoBE）框架。它利用预训练大模型（如CLIP）的多层特征，并模拟人类感知机制，独立建模外观、静态体型和动态步态等关键生物特征并自适应集成。HAMoBE包含两个层级：第一层从冻结大模型提供的多层表示中提取低级特征；第二层由专注于长期、短期和时间特征的专业专家组成。为了确保鲁棒匹配，我们引入了一个新的双输入决策门控网络，根据输入场景的相关性动态调整每个专家的贡献。

**Result:** 在MEVID等基准测试上进行的大量评估表明，我们的方法显著提高了性能（例如，Rank-1准确率提高了13.0%）。

**Conclusion:** HAMoBE框架通过有效识别和自适应集成多层生物特征，显著提升了视频行人重识别的性能，解决了现有方法在特征选择上的不足。

> **ai_Abstract:** 本文提出了HAMoBE（层级自适应生物特征专家混合）框架，旨在解决视频行人重识别中特征选择和集成的问题。该框架利用预训练大模型的多层特征，并通过两个层级独立建模并自适应融合外观、体型和步态等关键生物特征。其中，第一层提取低级特征，第二层包含专注于长期、短期和时间特征的专家。为实现鲁棒匹配，引入了双输入决策门控网络动态调整专家贡献。实验结果表明，HAMoBE在MEVID等基准测试上显著提升了行人重识别性能。

> **摘要翻译:** 最近，行人重识别（ReID）的研究兴趣日益集中在基于视频的场景中，这对于在多变和动态环境中实现鲁棒的监控和安全至关重要。然而，现有的基于视频的ReID方法常常忽略了从查询-图库对的视频中识别和选择最具判别力的特征以进行有效匹配的必要性。为了解决这个问题，我们提出了一个新颖的层级自适应生物特征专家混合（HAMoBE）框架，该框架利用预训练大模型（例如CLIP）的多层特征，旨在通过独立建模关键生物特征——外观、静态体型和动态步态——并自适应集成它们来模仿人类感知机制。具体而言，HAMoBE包括两个层级：第一层从冻结大模型提供的多层表示中提取低级特征，而第二层由专注于长期、短期和时间特征的专业专家组成。为了确保鲁棒匹配，我们引入了一个新的双输入决策门控网络，根据输入场景的相关性动态调整每个专家的贡献。在MEVID等基准测试上进行的大量评估表明，我们的方法产生了显著的性能改进（例如，Rank-1准确率提高了13.0%）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [326] [Finding Needles in Images: Can Multimodal LLMs Locate Fine Details?](https://arxiv.org/abs/2508.05053)
> *图像中寻针：多模态大型语言模型能否定位精细细节？*

*Parth Thakkar, Ankush Agarwal, Prasad Kasu, Pulkit Bansal, Chaitanya Devaguptapu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多模态大型语言模型, 细粒度理解, 基准测试, 图像寻针, Spot-IT

**Comment:** 

> **TL;DR:** 本文提出了一个名为NiM的基准测试，用于评估多模态大型语言模型（MLLMs）在复杂文档中定位和推理精细细节的能力。研究还提出了Spot-IT方法，通过智能补丁选择和高斯注意力机制来增强MLLMs的性能，并在实验中取得了显著改进。

**AI_Comments:** 本文通过提出专门的基准测试NiM和改进方法Spot-IT，创新性地解决了多模态大型语言模型在细粒度文档理解方面的局限性。NiM基准测试的构建填补了该领域评估工具的空白，而Spot-IT方法通过模拟人类聚焦行为，为提升模型性能提供了有效途径，对于推动MLLMs在实际应用中的精确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型（MLLMs）在文档理解任务中表现出色，但它们在复杂文档中定位和推理细粒度细节的能力仍未得到充分研究。这类似于在图像中寻找“针”（Finding Needles in Images, NiM），需要关注细小但重要的细节。

**Method:** 为了解决现有MLLMs在精细细节定位方面的不足，本文引入了NiM，一个精心策划的基准测试，涵盖报纸、菜单和讲座图像等多样化的真实世界文档，专门用于评估MLLMs在这些复杂任务中的能力。在此基础上，研究进一步提出了Spot-IT，一种简单而有效的方法，通过智能补丁选择和高斯注意力机制来增强MLLMs的能力，其灵感来源于人类在搜索文档时如何进行缩放和聚焦。

**Result:** 广泛的实验揭示了当前MLLMs在处理细粒度文档理解任务时的能力和局限性。同时，实验证明了Spot-IT方法的有效性，它在基线方法上取得了显著改进，尤其是在需要从复杂布局中精确提取细节的场景中。

**Conclusion:** 当前的多模态大型语言模型在处理复杂文档中的精细细节定位任务时仍存在局限性，但通过引入专门的评估基准NiM和提出的Spot-IT方法，可以显著提升其在这些任务上的性能，尤其是在需要精确细节提取的场景中。

> **ai_Abstract:** 本研究旨在解决多模态大型语言模型（MLLMs）在复杂文档中定位和推理精细细节能力不足的问题。为此，论文引入了NiM，一个包含报纸、菜单和讲座图像等真实世界文档的基准测试，专门用于评估MLLMs的细粒度理解能力。此外，论文提出了Spot-IT方法，该方法通过智能补丁选择和高斯注意力机制提升了MLLMs的性能，其灵感来源于人类的搜索行为。实验结果表明，Spot-IT在处理复杂布局中的精确细节提取任务上，相较于基线方法取得了显著的改进，同时也揭示了当前MLLMs在此类任务中的能力与局限性。

> **摘要翻译:** 尽管多模态大型语言模型（MLLMs）在文档理解任务中表现出令人印象深刻的能力，但它们在复杂文档中定位和推理细粒度细节的能力仍未得到充分研究。考虑在餐馆菜单中搜索特定的营养细节，或者在冗长的新闻文章中识别免责声明——这些任务都需要对更广泛叙述中的细小但重要的细节给予仔细关注，类似于在图像中寻找“针”（Finding Needles in Images, NiM）。为了弥补这一空白，我们引入了NiM，一个精心策划的基准测试，涵盖报纸、菜单和讲座图像等多样化的真实世界文档，专门用于评估MLLMs在这些复杂任务中的能力。在此基础上，我们进一步提出了Spot-IT，一种简单而有效的方法，通过智能补丁选择和高斯注意力机制来增强MLLMs的能力，其灵感来源于人类在搜索文档时如何进行缩放和聚焦。我们广泛的实验揭示了当前MLLMs在处理细粒度文档理解任务时的能力和局限性，同时证明了我们方法的有效性。Spot-IT在基线方法上取得了显著改进，尤其是在需要从复杂布局中精确提取细节的场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [334] [DualMat: PBR Material Estimation via Coherent Dual-Path Diffusion](https://arxiv.org/abs/2508.05060)
> *DualMat：通过相干双路径扩散进行PBR材质估计*

*Yifeng Huang, Zhang Chen, Yi Xu, Minh Hoai, Zhong Li* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** PBR材质估计, 双路径扩散, 单图像, 物理渲染, 深度学习

**Comment:** 

> **TL;DR:** DualMat是一个新颖的双路径扩散框架，用于在复杂光照条件下从单张图像估计PBR材质，并实现了最先进的性能。

**AI_Comments:** DualMat的创新之处在于其独特的双路径扩散框架，该框架将反照率估计与金属/粗糙度估计分离，并在训练过程中通过特征蒸馏确保预测的一致性。这种设计有效地解决了PBR材质估计中的多模态挑战。此外，采用整流流提高了效率，使其更具实用性。其在Objaverse和真实世界数据上实现的显著性能提升，凸显了其在图像到3D重建和计算机图形领域的潜在重要性。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂光照条件下，从单张图像估计物理渲染（PBR）材质是一项挑战。现有方法可能无法充分利用视觉知识或精确估计所有材质属性。因此，需要一种能够高效且高质量地估计PBR材质的方法。

**Method:** DualMat提出了一种双路径扩散框架。它包含两个独立的潜在空间路径：一个利用RGB潜在空间中预训练视觉知识的“反照率优化路径”，以及一个在紧凑潜在空间中运行的“材质专用路径”，用于精确的金属度和粗糙度估计。为确保路径间的预测一致性，引入了训练期间的特征蒸馏。为了提高效率，通过整流流减少推理步骤。此外，通过基于块的估计和跨视图注意力，框架扩展到高分辨率和多视图输入。

**Result:** DualMat在Objaverse和真实世界数据上都取得了最先进的性能，显著优于现有方法，在反照率估计方面提高了28%，在金属-粗糙度预测误差方面减少了39%。

**Conclusion:** DualMat通过其新颖的双路径扩散框架，有效解决了在复杂光照条件下从单张图像估计PBR材质的挑战，并在多个指标上实现了显著的性能提升，证明了其在图像到3D管线中的强大潜力。

> **ai_Abstract:** DualMat是一个创新的双路径扩散框架，旨在从复杂光照下的单张图像中估计PBR材质。它通过结合一个反照率优化路径（利用RGB潜在空间中的视觉知识）和一个材质专用路径（用于精确金属和粗糙度估计）来实现。该框架引入了特征蒸馏以确保路径间预测的一致性，并使用整流流提高推理效率。DualMat还支持高分辨率和多视图输入，并通过块估计和跨视图注意力集成到图像到3D管线中。实验结果表明，DualMat在Objaverse和真实世界数据上均达到最先进水平，显著优于现有方法，在反照率估计和金属-粗糙度预测误差方面有显著提升。

> **摘要翻译:** 我们提出了DualMat，一种新颖的双路径扩散框架，用于在复杂光照条件下从单张图像估计物理渲染（PBR）材质。我们的方法在两个不同的潜在空间中运行：一个利用RGB潜在空间中预训练视觉知识的反照率优化路径，以及一个在紧凑潜在空间中运行的材质专用路径，专为精确的金属度和粗糙度估计而设计。为了确保反照率优化路径和材质专用路径之间预测的一致性，我们在训练期间引入了特征蒸馏。我们采用整流流通过减少推理步骤来提高效率，同时保持质量。我们的框架通过基于块的估计和跨视图注意力扩展到高分辨率和多视图输入，从而能够无缝集成到图像到3D管线中。DualMat在Objaverse和真实世界数据上都取得了最先进的性能，显著优于现有方法，在反照率估计方面提高了28%，在金属-粗糙度预测误差方面减少了39%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Decoupling Continual Semantic Segmentation](https://arxiv.org/abs/2508.05065)
> *解耦持续语义分割*

*Yifu Guo, Yuquan Lu, Wentao Zhang, Zishan Xu, Dexia Chen, Siyu Zhang, Yizhe Zhang, Ruixuan Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 持续语义分割, 灾难性遗忘, 解耦, 两阶段框架, SAM

**Comment:** 

> **TL;DR:** DecoupleCSS 提出了一种两阶段框架，通过解耦类别感知检测和类别无关分割，解决了持续语义分割中灾难性遗忘和平衡保留-可塑性的问题，实现了最先进的性能。

**AI_Comments:** 该论文创新性地提出了一种两阶段解耦框架来应对持续语义分割中的核心挑战——灾难性遗忘。通过将类别感知检测与类别无关分割分离，并引入 LoRA 适配器和 SAM 模型，它提供了一个新颖且有效的解决方案，显著提升了模型在保留旧知识和学习新知识之间的平衡。这种解耦思想对于未来的持续学习研究具有重要的启发意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有持续语义分割 (CSS) 方法通常采用单阶段编码器-解码器架构，其中分割掩码和类别标签紧密耦合，导致新旧类别学习之间存在干扰，并导致次优的保留-可塑性平衡。

**Method:** 本文引入了 DecoupleCSS，一个新颖的两阶段持续语义分割框架。第一阶段利用预训练的文本和图像编码器（使用 LoRA 适配）来编码类别特定信息并生成位置感知提示。第二阶段使用 Segment Anything Model (SAM) 来生成精确的分割掩码，确保分割知识在新旧类别之间共享。

**Result:** DecoupleCSS 改善了持续语义分割中保留和适应性之间的平衡，并在各种具有挑战性的任务中实现了最先进的性能。

**Conclusion:** 通过解耦类别感知检测和类别无关分割，DecoupleCSS 能够更有效地进行持续学习，在学习新类别的同时保留了过去的知识，解决了灾难性遗忘问题并取得了 SOTA 性能。

> **ai_Abstract:** 本文提出了 DecoupleCSS，一个用于持续语义分割 (CSS) 的两阶段框架，旨在解决现有方法中类别学习耦合导致的灾难性遗忘和保留-可塑性平衡不佳的问题。DecoupleCSS 通过将类别感知检测与类别无关分割解耦，利用 LoRA 适配的预训练编码器生成位置感知提示，并结合 Segment Anything Model (SAM) 生成精确分割掩码。该方法有效地保留了旧知识并学习新类别，在多项任务中实现了最先进的性能。

> **摘要翻译:** 持续语义分割 (CSS) 要求学习新类别而不忘记先前获得的知识，解决了密集预测任务中灾难性遗忘的根本挑战。然而，现有 CSS 方法通常采用单阶段编码器-解码器架构，其中分割掩码和类别标签紧密耦合，导致新旧类别学习之间存在干扰，并导致次优的保留-可塑性平衡。我们引入了 DecoupleCSS，一个新颖的两阶段 CSS 框架。通过解耦类别感知检测和类别无关分割，DecoupleCSS 能够更有效地进行持续学习，在学习新类别的同时保留过去的知识。第一阶段利用预训练的文本和图像编码器（使用 LoRA 适配）来编码类别特定信息并生成位置感知提示。第二阶段使用 Segment Anything Model (SAM) 来生成精确的分割掩码，确保分割知识在新旧类别之间共享。这种方法改善了 CSS 中保留和适应性之间的平衡，并在各种具有挑战性的任务中实现了最先进的性能。我们的代码已公开可用：https://github.com/euyis1019/Decoupling-Continual-Semantic-Segmentation。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [FLUX-Makeup: High-Fidelity, Identity-Consistent, and Robust Makeup Transfer via Diffusion Transformer](https://arxiv.org/abs/2508.05069)
> *FLUX-Makeup：通过扩散变换器实现高保真、身份一致和鲁棒的妆容迁移*

*Jian Zhu, Shanyuan Liu, Liuzhuozheng Li, Yue Gong, He Wang, Bo Cheng, Yuhang Ma, Liebucha Wu, Xiaoyu Wu, Dawei Leng, Yuhui Yin, Yang Xu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 妆容迁移, 扩散变换器, 身份一致性, 高保真, RefLoRAInjector

**Comment:** 

> **TL;DR:** 提出FLUX-Makeup，一个无需辅助组件、高保真、身份一致且鲁棒的妆容迁移框架，通过新颖的注入器和数据生成管道实现了最先进的性能。

**AI_Comments:** FLUX-Makeup的创新之处在于其无需辅助面部控制组件即可实现高保真和身份一致的妆容迁移，这简化了模型设计并减少了误差源。RefLoRAInjector的设计及其与主干网络的解耦，以及高质量数据生成管道的引入，都是提升性能的关键。该方法在鲁棒性和性能上达到了SOTA，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的GAN和扩散模型在妆容迁移中依赖辅助组件（如损失函数或面部控制模块），这些组件引入误差并导致次优结果，难以平衡迁移质量和身份一致性。

**Method:** 提出FLUX-Makeup框架，它不依赖任何辅助面部控制组件，而是直接利用源-参考图像对。该方法基于FLUX-Kontext，将源图像作为原生条件输入。引入RefLoRAInjector，一个轻量级妆容特征注入器，它将参考路径与主干网络解耦，以高效提取妆容信息。同时，设计了一个鲁棒且可扩展的数据生成管道，用于提供更准确的训练监督，生成的数据集质量显著优于现有数据集。

**Result:** FLUX-Makeup实现了最先进的性能，并在不同场景下表现出强大的鲁棒性。

**Conclusion:** 本文提出的FLUX-Makeup框架成功克服了现有妆容迁移方法的局限性，通过创新的架构和数据生成策略，在不依赖辅助组件的情况下实现了高保真、身份一致且鲁棒的妆容迁移，达到了最先进的水平。

> **ai_Abstract:** FLUX-Makeup是一个创新的妆容迁移框架，旨在解决现有方法中因依赖辅助组件而导致的性能限制。该方法通过直接利用源-参考图像对，并结合基于FLUX-Kontext的架构、轻量级的RefLoRAInjector和高质量的数据生成管道，实现了高保真、身份一致和鲁棒的妆容迁移，无需额外的面部控制模块。实验证明其达到了最先进的性能。

> **摘要翻译:** 妆容迁移旨在将参考人脸的妆容风格应用到目标人脸，并且已在实际应用中得到越来越多的采用。现有的基于GAN的方法通常依赖精心设计的损失函数来平衡迁移质量和面部身份一致性，而基于扩散的方法则通常依赖额外的面部控制模块或算法来保留身份。然而，这些辅助组件往往会引入额外的误差，导致次优的迁移结果。为了克服这些限制，我们提出了FLUX-Makeup，一个高保真、身份一致且鲁棒的妆容迁移框架，它消除了对任何辅助面部控制组件的需求。相反，我们的方法直接利用源-参考图像对来实现卓越的迁移性能。具体来说，我们基于FLUX-Kontext构建了我们的框架，使用源图像作为其原生的条件输入。此外，我们引入了RefLoRAInjector，一个轻量级的妆容特征注入器，它将参考路径与主干网络解耦，从而能够高效且全面地提取与妆容相关的信息。同时，我们设计了一个鲁棒且可扩展的数据生成管道，以便在训练期间提供更准确的监督。该管道生成的配对妆容数据集显著超越了所有现有数据集的质量。广泛的实验表明，FLUX-Makeup实现了最先进的性能，在不同场景下表现出强大的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [358] [AdaFusion: Prompt-Guided Inference with Adaptive Fusion of Pathology Foundation Models](https://arxiv.org/abs/2508.05084)
> *AdaFusion：基于提示引导和自适应融合病理基础模型的推断*

*Yuxiang Xiao, Yang Hu, Bin Li, Tianyang Zhang, Zexi Li, Huazhu Fu, Jens Rittscher, Kaixiang Yang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 病理基础模型, 模型融合, 提示引导推断, 可解释性, 组织病理学

**Comment:** 

> **TL;DR:** 提出AdaFusion框架，通过自适应融合多个病理基础模型，提高性能并增强可解释性，克服单一模型泛化和透明度不足的问题。

**AI_Comments:** AdaFusion的创新之处在于它首次动态整合了多个病理基础模型的知识，并通过自适应融合机制解决了单一模型泛化性和透明度不足的问题。其引入的轻量级注意力机制和对组织表型上下文的利用，使其能够更智能地结合不同模型的优势。这项工作的重要性在于它不仅提升了病理学任务的预测性能，还增强了模型的可解释性，这在医疗领域尤为关键。

<details>
  <summary>Details</summary>

**Motivation:** 病理基础模型（PFMs）通过自监督预训练获得了强大的表征能力，但其多样且不透明的预训练上下文引入了潜在偏差，从而阻碍了其在下游应用中的泛化能力和透明度。

**Method:** AdaFusion是一个新型的提示引导推断框架，它动态整合来自多个PFM的互补知识。该方法通过压缩和对齐来自不同模型的瓦片级特征，并采用轻量级注意力机制，根据组织表型上下文自适应地融合这些特征。

**Result:** AdaFusion在治疗反应预测、肿瘤分级和空间基因表达推断这三个真实世界基准测试中，在分类和回归任务上始终优于单个PFM。它还为每个模型的生物语义特化提供了可解释的见解。

**Conclusion:** AdaFusion能够弥合异构的病理基础模型，同时实现性能的提升和模型特定归纳偏差的可解释性。

> **ai_Abstract:** 本文提出了AdaFusion，一个创新的提示引导推断框架，旨在解决病理基础模型（PFMs）因预训练偏差导致的泛化和透明度问题。AdaFusion通过压缩、对齐并自适应融合来自多个PFM的瓦片级特征，有效整合了互补知识。在多个真实世界病理学任务上的评估表明，AdaFusion显著优于单一PFM，并提供了关于模型生物语义特化的可解释性，从而提升了性能和对模型归纳偏差的理解。

> **摘要翻译:** 病理基础模型（PFMs）通过在大规模、未标注的组织病理学图像数据集上进行自监督预训练，展示了强大的表征能力。然而，它们多样但不够透明的预训练上下文，由数据相关以及结构/训练因素共同塑造，引入了潜在偏差，阻碍了在下游应用中的泛化能力和透明度。在本文中，我们提出了AdaFusion，一个新颖的提示引导推断框架，据我们所知，它是最早动态整合来自多个PFM的互补知识的方法之一。我们的方法压缩并对齐来自不同模型的瓦片级特征，并采用轻量级注意力机制，根据组织表型上下文自适应地融合它们。我们在涵盖治疗反应预测、肿瘤分级和空间基因表达推断的三个真实世界基准测试中评估了AdaFusion。我们的方法在分类和回归任务中始终优于单个PFM，同时为每个模型的生物语义特化提供了可解释的见解。这些结果突出了AdaFusion弥合异构PFM的能力，实现了性能的提升和模型特定归纳偏差的可解释性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [366] [PoseGen: In-Context LoRA Finetuning for Pose-Controllable Long Human Video Generation](https://arxiv.org/abs/2508.05091)
> *PoseGen：用于姿态可控长人视频生成的上下文LoRA微调*

*Jingxuan He, Busheng Su, Finn Wong* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频生成, 姿态控制, LoRA, 扩散模型, 长视频

**Comment:** 

> **TL;DR:** PoseGen是一个新颖的框架，通过上下文LoRA微调和交错片段生成，可以从单张参考图像和姿态序列生成任意长度、身份保持和姿态精确的人类视频。

**AI_Comments:** PoseGen的创新在于其结合了上下文LoRA微调和独特的交错片段生成方法，有效解决了长时间视频生成中的身份漂移和连贯性问题。其能够在小数据集上训练并实现SOTA性能，且能生成无限时长视频，显示出巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的扩散模型在生成具有精确主体身份和运动控制的长时间、时间连贯视频方面面临巨大挑战，常出现身份漂移且仅限于短视频。

**Method:** PoseGen采用上下文LoRA微调策略，在token级别注入主体外观以保持身份，并在通道级别以姿态信息为条件进行精细运动控制。为克服时长限制，它开创了一种交错片段生成方法，通过共享KV缓存机制和专门的过渡过程无缝拼接视频片段，确保背景一致性和时间平滑性。

**Result:** PoseGen在身份保真度、姿态准确性方面显著优于最先进的方法，并且能够生成无限时长、连贯无伪影的视频。

**Conclusion:** PoseGen通过其创新的上下文LoRA微调和交错片段生成方法，有效解决了现有扩散模型在生成长时、高保真人类视频方面的挑战，并在多项指标上超越了现有技术。

> **ai_Abstract:** PoseGen是一个创新的框架，旨在解决当前扩散模型在生成长时、身份保持和姿态可控人类视频方面的限制。它引入了上下文LoRA微调策略，用于身份保持和精细运动控制，并通过交错片段生成方法克服了视频时长限制，确保了时间连贯性。实验证明，PoseGen在身份保真度、姿态准确性和生成无限时长视频方面表现优异，超越了现有技术。

> **摘要翻译:** 在对主体身份和运动进行精确控制的情况下，生成长时间、时间连贯的视频对于当前的扩散模型来说是一个艰巨的挑战，这些模型经常遭受身份漂移的困扰，并且仅限于短视频。我们引入了PoseGen，这是一个新颖的框架，可以从单一参考图像和驱动姿态序列生成特定主体的任意长度视频。我们的核心创新是一种上下文LoRA微调策略，该策略在token级别注入主体外观以保持身份，同时在通道级别以姿态信息为条件进行精细运动控制。为了克服持续时间限制，PoseGen开创了一种交错片段生成方法，该方法使用共享的KV缓存机制和专门的过渡过程，无缝地拼接视频片段，以确保背景一致性和时间平滑性。在仅仅33小时的小型视频数据集上进行训练，广泛的实验表明，PoseGen在身份保真度、姿态准确性以及生成无限时长、连贯、无伪影视频的独特能力方面显著优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [Sculpting Margin Penalty: Intra-Task Adapter Merging and Classifier Calibration for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.05094)
> *雕琢裕度惩罚：少样本类增量学习中的任务内适配器合并与分类器校准*

*Liang Bai, Hong Song, Jinfu Li, Yucong Lin, Jingfan Fan, Tianyu Fu, Danni Ai, Deqiang Xiao, Jian Yang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 少样本类增量学习, 裕度惩罚, 适配器合并, 分类器校准, 前向兼容学习

**Comment:** 

> **TL;DR:** SMP是一种新的少样本类增量学习方法，通过在不同阶段应用裕度惩罚来平衡基类判别性和新类泛化性，并优化决策边界，实现了最先进的性能。

**AI_Comments:** SMP的创新之处在于其在少样本类增量学习中，巧妙地将裕度惩罚机制融入到参数高效微调的不同阶段。MIAM机制通过训练两组带有不同约束的适配器并进行自适应合并，有效地解决了基类判别性与新类泛化性之间的矛盾。MPCC策略则进一步优化了增量任务中的决策边界，这对于有限数据下的类别区分至关重要。该方法为解决FSCIL中的核心挑战提供了一个有前景的框架，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界应用中数据隐私和高获取成本导致增量任务中训练数据不足，这使得类增量学习性能显著下降。现有方法在平衡基类判别性和新类泛化性方面存在困难，且在增量任务中原始数据访问受限导致类间决策边界模糊。

**Method:** 本文提出SMP（Sculpting Margin Penalty），一种新型的少样本类增量学习（FSCIL）方法，通过在参数高效微调范式内不同阶段策略性地整合裕度惩罚。具体来说，引入了用于基任务学习的裕度感知任务内适配器合并（MIAM）机制，该机制训练两组低秩适配器：一组带有裕度惩罚以增强基类判别性，另一组不带裕度约束以促进对未来新类的泛化。这些适配器随后自适应合并以提高前向兼容性。对于增量任务，提出了一种基于裕度惩罚的分类器校准（MPCC）策略，通过对所有已见类的嵌入进行带有裕度惩罚的分类器微调来优化决策边界。

**Result:** 在CIFAR100、ImageNet-R和CUB200上的大量实验表明，SMP在FSCIL中实现了最先进的性能，同时在基类和新类之间保持了更好的平衡。

**Conclusion:** SMP通过引入裕度惩罚在参数高效微调范式内不同阶段的应用，有效解决了少样本类增量学习中基类判别性和新类泛化性的平衡问题以及决策边界模糊问题，达到了SOTA性能。

> **ai_Abstract:** 本文提出了一种名为SMP（Sculpting Margin Penalty）的新型少样本类增量学习（FSCIL）方法，旨在解决现有方法在基类判别性和新类泛化性之间平衡困难以及类间决策边界模糊的问题。SMP通过在参数高效微调范式中策略性地引入裕度惩罚来实现。它包含两个核心机制：裕度感知任务内适配器合并（MIAM）用于基任务学习，通过合并带有和不带裕度惩罚训练的适配器来平衡判别性和泛化性；以及基于裕度惩罚的分类器校准（MPCC）用于增量任务，通过微调分类器来优化决策边界。实验结果表明，SMP在多个数据集上达到了最先进的FSCIL性能，并更好地平衡了基类和新类的表现。

> **摘要翻译:** 现实世界的应用经常面临数据隐私限制和高获取成本，这使得增量任务中充足训练数据的假设变得不切实际，并导致类增量学习的性能显著下降。前向兼容学习作为一种在基础任务训练期间为未来任务做准备的方法，已成为少样本类增量学习（FSCIL）的一种有前景的解决方案。然而，现有方法仍然难以平衡基类判别性和新类泛化性。此外，在增量任务中对原始数据的有限访问通常会导致模糊的类间决策边界。为了解决这些挑战，我们提出了SMP（Sculpting Margin Penalty），一种新颖的FSCIL方法，它在参数高效微调范式内不同阶段策略性地整合了裕度惩罚。具体来说，我们为基任务学习引入了裕度感知任务内适配器合并（MIAM）机制。MIAM训练两组具有不同分类损失的低秩适配器：一组带有裕度惩罚以增强基类判别性，另一组不带裕度约束以促进对未来新类的泛化。然后，这些适配器被自适应地合并以提高前向兼容性。对于增量任务，我们提出了一种基于裕度惩罚的分类器校准（MPCC）策略，通过对所有已见类的嵌入进行带有裕度惩罚的分类器微调来优化决策边界。在CIFAR100、ImageNet-R和CUB200上的大量实验表明，SMP在FSCIL中实现了最先进的性能，同时在基类和新类之间保持了更好的平衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [382] [AHDMIL: Asymmetric Hierarchical Distillation Multi-Instance Learning for Fast and Accurate Whole-Slide Image Classification](https://arxiv.org/abs/2508.05114)
> *AHDMIL：用于快速准确的全玻片图像分类的非对称分层蒸馏多实例学习*

*Jiuyang Dong, Jiahan Li, Junjun Jiang, Kui Jiang, Yongbing Zhang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多实例学习, 全玻片图像, 图像分类, 蒸馏, 计算病理学

**Comment:** 

> **TL;DR:** AHDMIL是一种非对称分层蒸馏多实例学习框架，通过两步训练过程消除不相关图像块，实现快速准确的全玻片图像分类，显著提高了性能和推理速度。

**AI_Comments:** AHDMIL的创新之处在于其非对称分层蒸馏策略，通过利用多分辨率信息，有效解决了千兆像素WSI的计算负担。两步训练过程（自蒸馏和非对称蒸馏）与新颖的CKA分类器相结合，显著提升了准确性和速度，这对于计算病理学的临床应用至关重要。其展示出的效率提升使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多实例学习（MIL）在病理图像分类中取得了成功，但由于需要处理每个千兆像素全玻片图像（WSI）的数千个图像块，它面临着高推理成本的挑战。

**Method:** 本文提出了AHDMIL，一个非对称分层蒸馏多实例学习框架，通过两步训练过程消除不相关图像块，从而实现快速准确的分类。AHDMIL包含两个关键组件：在高清WSI上操作的动态多实例网络（DMIN）和分析相应低分辨率对应物的双分支轻量级实例预筛选网络（DB-LIPN）。在第一步自蒸馏（SD）中，DMIN经过WSI分类训练，同时生成每个实例的注意力分数以识别不相关图像块。这些分数指导第二步非对称蒸馏（AD），其中DB-LIPN学习预测每个低分辨率图像块的相关性。DB-LIPN预测的相关图像块与高清WSI中的图像块具有空间对应关系，用于DMIN的微调和高效推理。此外，本文还设计了计算病理学中第一个基于切比雪夫多项式的Kolmogorov-Arnold（CKA）分类器，通过可学习激活层提高了分类性能。

**Result:** 在四个公共数据集上进行的广泛实验表明，AHDMIL在分类性能和推理速度方面始终优于现有最先进的方法。例如，在Camelyon16数据集上，它实现了5.3%的准确率相对提升，并将推理速度加快了1.2倍。在所有数据集中，曲线下面积（AUC）、准确率、F1分数和Brier分数均显示出持续的提升，平均推理速度提升范围为1.2到2.1倍。

**Conclusion:** AHDMIL是一种用于全玻片图像分类的快速准确框架，通过智能地蒸馏和利用多分辨率图像的信息，有效解决了多实例学习中高推理成本的挑战，并在性能和速度上均超越了现有技术。

> **ai_Abstract:** AHDMIL是一个新颖的框架，用于快速准确的全玻片图像（WSI）分类，解决了多实例学习（MIL）中高推理成本的挑战。它采用非对称分层蒸馏过程，结合了用于高清WSI的动态多实例网络（DMIN）和用于低分辨率对应物的双分支轻量级实例预筛选网络（DB-LIPN）。通过自蒸馏，DMIN识别相关图像块，然后通过非对称蒸馏指导DB-LIPN预测低分辨率图像块的相关性。这些相关图像块用于DMIN的高效微调和推理。AHDMIL还引入了基于切比雪夫多项式的Kolmogorov-Arnold（CKA）分类器。实验表明，AHDMIL在多个数据集上超越了现有最先进方法的性能和速度。

> **摘要翻译:** 尽管多实例学习（MIL）在病理图像分类中取得了成功，但由于需要处理每个千兆像素全玻片图像（WSI）的数千个图像块，它面临着高推理成本的挑战。为了解决这个问题，我们提出了AHDMIL，一个非对称分层蒸馏多实例学习框架，通过两步训练过程消除不相关图像块，从而实现快速准确的分类。AHDMIL包含两个关键组件：在高清WSI上操作的动态多实例网络（DMIN）和分析相应低分辨率对应物的双分支轻量级实例预筛选网络（DB-LIPN）。在第一步自蒸馏（SD）中，DMIN经过WSI分类训练，同时生成每个实例的注意力分数以识别不相关图像块。这些分数指导第二步非对称蒸馏（AD），其中DB-LIPN学习预测每个低分辨率图像块的相关性。DB-LIPN预测的相关图像块与高清WSI中的图像块具有空间对应关系，用于DMIN的微调和高效推理。此外，我们设计了计算病理学中第一个基于切比雪夫多项式的Kolmogorov-Arnold（CKA）分类器，通过可学习激活层提高了分类性能。在四个公共数据集上进行的广泛实验表明，AHDMIL在分类性能和推理速度方面始终优于现有最先进的方法。例如，在Camelyon16数据集上，它实现了5.3%的准确率相对提升，并将推理速度加快了1.2倍。在所有数据集中，曲线下面积（AUC）、准确率、F1分数和Brier分数均显示出持续的提升，平均推理速度提升范围为1.2到2.1倍。代码已开源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [390] [Deep Learning-based Animal Behavior Analysis: Insights from Mouse Chronic Pain Models](https://arxiv.org/abs/2508.05138)
> *基于深度学习的动物行为分析：来自小鼠慢性疼痛模型的见解*

*Yu-Hsi Chen, Wei-Hsin Chen, Chien-Yao Wang, Hong-Yuan Mark Liao, James C. Liao, Chien-Chang Chen* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 深度学习, 动物行为分析, 慢性疼痛, 小鼠模型, 疼痛分类

**Comment:** 

> **TL;DR:** 本研究提出了一种深度学习框架，用于自动分析小鼠慢性疼痛行为，无需人工标注，并在疼痛分类任务中显著优于人类专家和现有方法，显示出在疼痛研究和药物开发中的应用潜力。

**AI_Comments:** 该论文的创新点在于提出了一个无需人工标注即可自动发现慢性疼痛相关行为特征的深度学习框架，这有效地解决了传统方法中人工标注主观性强、效率低下的问题。其重要性体现在其在疼痛分类任务中显著超越人类专家和现有基线方法的性能，以及在药物疗效评估方面的潜在应用。这为慢性疼痛的客观评估和新药研发提供了新的工具和视角。

<details>
  <summary>Details</summary>

**Motivation:** 在临床前研究中，评估小鼠慢性疼痛行为至关重要。然而，现有方法主要依赖人工标注行为特征，且人类对哪些行为最能代表慢性疼痛缺乏清晰理解，导致现有方法难以准确捕捉慢性疼痛的隐匿性和持续性行为变化。

**Method:** 本研究提出一个框架，旨在不依赖人类定义动作标签的情况下，自动发现与慢性疼痛相关的特征。该方法使用通用动作空间投影仪自动提取小鼠动作特征，通过保留原始视频中丰富的行为信息，避免了人类标注可能带来的偏见。此外，本研究还收集了一个小鼠疼痛行为数据集，该数据集捕获了神经性疼痛和炎症性疼痛在多个时间点的疾病进展情况。

**Result:** 在15类疼痛分类任务中，本方法取得了48.41%的准确率，显著优于人类专家（21.33%）和广泛使用的方法B-SOiD（30.52%）。当分类简化为神经性疼痛、炎症性疼痛和无疼痛三类时，本方法达到了73.1%的准确率，明显高于人类专家（48%）和B-SOiD（58.43%）。此外，本方法在零样本加巴喷丁药物测试中揭示了不同类型疼痛的药物疗效差异，结果与过去的药物疗效文献一致。

**Conclusion:** 本研究展示了所提出方法的潜在临床应用价值，有望为疼痛研究和相关药物开发提供新的见解。

> **ai_Abstract:** 本研究提出了一种基于深度学习的框架，用于自动分析小鼠慢性疼痛行为。该方法通过通用动作空间投影仪自动提取小鼠行为特征，避免了人工标注的偏见，并利用自建的包含神经性疼痛和炎症性疼痛的小鼠数据集进行训练。实验结果表明，在15类和3类疼痛分类任务中，该方法均显著优于人类专家和现有方法B-SOiD。此外，该方法还能有效评估药物疗效，其发现与现有文献一致，显示出在疼痛研究和药物开发中的巨大潜力。

> **摘要翻译:** 评估小鼠慢性疼痛行为对于临床前研究至关重要。然而，现有方法大多依赖于行为特征的人工标注，且人类对哪些行为最能代表慢性疼痛缺乏清晰的理解。因此，现有方法难以准确捕捉慢性疼痛中隐匿而持久的行为变化。本研究提出了一种框架，旨在无需依赖人类定义的动作标签的情况下，自动发现与慢性疼痛相关的特征。我们的方法使用通用动作空间投影仪自动提取小鼠动作特征，并通过保留原始视频中丰富的行为信息，避免了人类标注的潜在偏见。在本文中，我们还收集了一个小鼠疼痛行为数据集，该数据集捕获了神经性疼痛和炎症性疼痛在多个时间点上的疾病进展。我们的方法在15类疼痛分类任务中取得了48.41%的准确率，显著优于人类专家（21.33%）和广泛使用的方法B-SOiD（30.52%）。此外，当分类简化为仅有三类，即神经性疼痛、炎症性疼痛和无疼痛时，我们的方法达到了73.1%的准确率，这明显高于人类专家（48%）和B-SOiD（58.43%）。最后，我们的方法在零样本加巴喷丁药物测试中揭示了不同类型疼痛的药物疗效差异，结果与过去的药物疗效文献一致。这项研究展示了我们方法的潜在临床应用，可以为疼痛研究和相关药物开发提供新的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [Rotation Equivariant Arbitrary-scale Image Super-Resolution](https://arxiv.org/abs/2508.05160)
> *旋转等变任意尺度图像超分辨率*

*Qi Xie, Jiahong Fu, Zongben Xu, Deyu Meng* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 图像超分辨率, 旋转等变性, 任意尺度, 隐式神经表示, 几何模式

**Comment:** 

> **TL;DR:** 提出了一种旋转等变的任意尺度图像超分辨率方法，通过重新设计编码器和INR模块，解决了现有方法在处理几何模式时的形变问题，并首次实现了端到端的旋转等变ASISR。

**AI_Comments:** 这篇论文通过引入旋转等变性，解决了任意尺度图像超分辨率中几何模式扭曲的关键问题，具有创新性。其端到端的设计和理论分析增强了方法的稳健性。此外，即插即用的集成能力使其具有很高的实用价值和应用潜力，有望显著提升现有ASISR方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的任意尺度图像超分辨率(ASISR)方法在处理低分辨率图像时，常见的几何模式（如重复纹理、边缘、形状）会严重扭曲和变形，导致高分辨率恢复中出现伪影。为了使恢复图像忠实地保持几何模式的原始方向和结构完整性，需要将旋转等变性嵌入到ASISR网络中。

**Method:** 本研究构建了一种旋转等变的ASISR方法。具体而言，重新设计了INR和编码器模块的基本架构，使其具有超越传统ASISR网络的内在旋转等变能力，从而首次实现了从输入到输出都保持端到端旋转等变的ASISR网络。此外，还提供了理论分析来评估其内在等变误差。

**Result:** 实验在模拟和真实数据集上验证了所提出方法的优越性。此外，证明了所提出的框架可以以即插即用的方式轻松集成到当前的ASISR方法中，以进一步提高其性能。

**Conclusion:** 本文成功构建并验证了一种旋转等变的任意尺度图像超分辨率方法，通过对核心模块的创新性设计，有效解决了现有ASISR在几何模式处理上的缺陷，并提供了可集成到现有框架的通用解决方案。

> **ai_Abstract:** 本文提出了一种新颖的旋转等变任意尺度图像超分辨率（ASISR）方法，旨在解决现有ASISR在处理低分辨率图像中几何模式时出现的扭曲和伪影问题。通过重新设计编码器和隐式神经表示（INR）模块，本方法首次实现了从输入到输出的端到端旋转等变性。理论分析和在模拟及真实数据集上的实验均验证了其优越性，并且该框架可以即插即用地集成到现有ASISR方法中以提升性能。

> **摘要翻译:** 任意尺度图像超分辨率（ASISR）是计算机视觉领域最近的一个热门话题，旨在从低分辨率输入图像中实现任意尺度的高分辨率恢复。这项任务通过两个基本模块——一个基于深度网络的编码器和一个隐式神经表示（INR）模块，将图像表示为连续的隐式函数来实现。尽管取得了显著进展，但这种高度不适定设置的一个关键挑战是，许多常见的几何模式，如重复纹理、边缘或形状，在低分辨率图像中严重扭曲和变形，自然导致其高分辨率恢复中出现意想不到的伪影。因此，将旋转等变性嵌入到ASISR网络中是必要的，因为这已被广泛证明可以使恢复忠实地保持输入图像中几何模式的原始方向和结构完整性。受此启发，本研究致力于构建一种旋转等变的ASISR方法。具体来说，我们精心重新设计了INR和编码器模块的基本架构，使其具有超越传统ASISR网络的内在旋转等变能力。通过这种改进，ASISR网络首次实现了从输入到输出都保持端到端旋转等变。我们还提供了扎实的理论分析来评估其内在等变误差，证明了其嵌入这种等变结构的固有性质。所提出方法的优越性通过在模拟和真实数据集上进行的实验得到了证实。我们还验证了所提出的框架可以以即插即用的方式轻松集成到当前的ASISR方法中，以进一步提高其性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [X-MoGen: Unified Motion Generation across Humans and Animals](https://arxiv.org/abs/2508.05162)
> *X-MoGen：跨人类和动物的统一运动生成*

*Xuan Wang, Kai Ruan, Liyang Qian, Zhizhi Guo, Chang Su, Gaoang Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 运动生成, 跨物种, 文本驱动, 统一框架, UniMo4D

**Comment:** 

> **TL;DR:** X-MoGen是一个统一框架，用于基于文本生成人类和动物的运动，通过解决物种间形态差异并构建大规模数据集实现。

**AI_Comments:** 该论文的创新点在于首次提出了一个统一的跨物种运动生成框架，解决了物种间形态差异的难题。通过引入形态一致性模块和构建大规模的UniMo4D数据集，为未来的跨物种运动生成研究奠定了基础，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通常分别对人类和动物运动进行建模，而统一的跨物种方法具有统一表示和改进泛化能力等优势。然而，物种间的形态差异是一个关键挑战，常常影响运动的合理性。

**Method:** 提出X-MoGen，这是第一个用于跨物种文本驱动运动生成的统一框架。它采用两阶段架构：首先，条件图变分自编码器学习规范T-pose先验，同时自编码器将运动编码到共享潜在空间，并通过形态损失进行正则化。其次，执行掩蔽运动建模，根据文本描述生成运动嵌入，并在训练期间采用形态一致性模块促进跨物种骨骼的合理性。为支持统一建模，构建了UniMo4D数据集，一个包含115个物种和119k运动序列的大规模数据集，该数据集在共享骨骼拓扑下整合了人类和动物运动以进行联合训练。

**Result:** 在UniMo4D数据集上的大量实验表明，X-MoGen在已知和未知物种上都优于现有最先进的方法。

**Conclusion:** X-MoGen成功地实现了跨物种的统一运动生成，解决了形态差异的挑战，并展示了其在泛化能力上的优势。

> **ai_Abstract:** X-MoGen是一种新型的统一框架，用于基于文本生成人类和动物的运动。它通过两阶段架构解决了跨物种形态差异带来的挑战，该架构包括学习T-pose先验、将运动编码到共享潜在空间、以及利用形态一致性模块确保骨骼合理性。为了支持统一建模，该研究还构建了大规模的UniMo4D数据集。实验证明X-MoGen在已知和未知物种上均优于现有方法。

> **摘要翻译:** 文本驱动的运动生成因其在虚拟现实、动画和机器人技术中的广泛应用而受到越来越多的关注。虽然现有方法通常分别对人类和动物运动进行建模，但联合的跨物种方法提供了关键优势，例如统一表示和改进的泛化能力。然而，物种间的形态差异仍然是一个关键挑战，常常损害运动的合理性。为了解决这个问题，我们提出了X-MoGen，这是第一个涵盖人类和动物的跨物种文本驱动运动生成的统一框架。X-MoGen采用两阶段架构。首先，条件图变分自编码器学习规范的T-pose先验，同时自编码器将运动编码到由形态损失正则化的共享潜在空间中。在第二阶段，我们执行掩蔽运动建模，以根据文本描述生成运动嵌入。在训练期间，采用形态一致性模块来促进跨物种的骨骼合理性。为了支持统一建模，我们构建了UniMo4D，一个包含115个物种和119k运动序列的大规模数据集，该数据集在共享骨骼拓扑下整合了人类和动物运动以进行联合训练。在UniMo4D上的大量实验表明，X-MoGen在已知和未知物种上都优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [PhysPatch: A Physically Realizable and Transferable Adversarial Patch Attack for Multimodal Large Language Models-based Autonomous Driving Systems](https://arxiv.org/abs/2508.05167)
> *PhysPatch：一种针对多模态大语言模型自动驾驶系统的物理可实现和可迁移对抗性补丁攻击*

*Qi Guo, Xiaojun Jia, Shanmin Pang, Simeng Qin, Lin Wang, Ju Jia, Yang Liu, Qing Guo* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 对抗性攻击, 多模态大语言模型, 自动驾驶, 对抗性补丁, 物理可实现

**Comment:** 

> **TL;DR:** 本文提出了PhysPatch，一种针对MLLM自动驾驶系统的物理可实现且可迁移的对抗性补丁攻击框架，显著优于现有方法，并能将补丁放置在物理可行区域，确保现实世界适用性。

**AI_Comments:** PhysPatch的创新点在于它专门针对MLLM-based AD系统设计，解决了现有对抗性补丁方法在复杂MLLM架构上的迁移性问题。其联合优化策略和多项新颖技术（语义初始化、SVD对齐、势场细化）使其在物理可实现性和攻击有效性上表现出色，对未来自动驾驶系统的安全研究具有重要意义，同时也提醒了MLLM在关键应用中面临的安全风险。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在自动驾驶（AD）系统中日益重要，但易受对抗性攻击，尤其是对抗性补丁攻击，这在现实世界中构成严重威胁。现有补丁攻击方法主要针对目标检测模型，在MLLM系统上表现不佳，因为MLLM架构复杂且推理能力强。

**Method:** 本文提出了PhysPatch框架，一个为基于MLLM的AD系统量身定制的、物理可实现且可迁移的对抗性补丁框架。PhysPatch联合优化补丁位置、形状和内容，以增强攻击有效性和现实世界适用性。它引入了语义初始化策略用于真实放置，基于SVD的局部对齐损失与补丁引导的裁剪-调整大小相结合以提高可迁移性，以及基于势场的掩码细化方法。

**Result:** 广泛实验表明，PhysPatch在引导MLLM-based AD系统产生目标对齐的感知和规划输出方面显著优于现有方法。PhysPatch能将对抗性补丁始终放置在自动驾驶场景中物理可行的区域，确保了强大的现实世界适用性和可部署性。

**Conclusion:** PhysPatch成功解决了现有对抗性补丁攻击在MLLM-based AD系统上表现不佳的问题，提供了一种有效且在物理上可实现的攻击方法，对自动驾驶系统的安全性构成潜在威胁。

> **ai_Abstract:** 本文提出了PhysPatch，一种专门针对多模态大语言模型（MLLMs）自动驾驶系统的物理可实现且可迁移的对抗性补丁攻击框架。针对现有方法在复杂MLLM上迁移性差的问题，PhysPatch通过联合优化补丁的位置、形状和内容，并结合语义初始化、SVD局部对齐损失和势场掩码细化等创新策略，显著提升了攻击效果和现实适用性。实验证明，PhysPatch能有效引导MLLM-based AD系统产生错误的感知和规划输出，且补丁放置在物理可行区域，对自动驾驶系统的安全性构成重要挑战。

> **摘要翻译:** 多模态大语言模型（MLLMs）因其强大的视觉-语言推理能力而成为自动驾驶（AD）系统不可或缺的一部分。然而，MLLMs容易受到对抗性攻击，特别是对抗性补丁攻击，这在现实世界场景中可能构成严重威胁。现有的基于补丁的攻击方法主要针对目标检测模型，由于MLLM复杂的架构和推理能力，当迁移到基于MLLM的系统时表现不佳。为了解决这些限制，我们提出了PhysPatch，一个为基于MLLM的AD系统量身定制的、物理可实现且可迁移的对抗性补丁框架。PhysPatch联合优化补丁位置、形状和内容，以增强攻击有效性和现实世界适用性。它引入了一种基于语义的掩码初始化策略，用于现实放置；一种基于SVD的局部对齐损失与补丁引导的裁剪-调整大小相结合，以提高可迁移性；以及一种基于势场的掩码细化方法。对开源、商业和具有推理能力的MLLM进行的广泛实验表明，PhysPatch在引导基于MLLM的AD系统产生目标对齐的感知和规划输出方面显著优于现有方法。此外，PhysPatch始终将对抗性补丁放置在AD场景中物理可行的区域，确保了强大的现实世界适用性和可部署性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [Multi-tracklet Tracking for Generic Targets with Adaptive Detection Clustering](https://arxiv.org/abs/2508.05172)
> *多轨迹跟踪用于自适应检测聚类的通用目标*

*Zewei Wu, Longhao Wang, Cui Wang, César Teixeira, Wei Ke, Zhang Xiong* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多目标跟踪, 轨迹跟踪, 自适应检测聚类, 通用目标, 目标关联

**Comment:** 

> **TL;DR:** 提出了一种名为MTT的多轨迹跟踪器，通过自适应检测聚类和多轨迹关联来解决通用目标跟踪中遇到的低置信度检测、弱约束和长期遮挡问题。

**AI_Comments:** 该论文创新性地将轨迹段生成与多轨迹段关联相结合，以应对通用目标跟踪中的复杂挑战，特别是对未见类别的鲁棒性。其自适应检测聚类和多线索轨迹段划分策略有助于提高跟踪精度并缓解误差传播，对于提升通用场景下的多目标跟踪性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉多目标跟踪方法在处理通用目标时面临挑战，因为存在低置信度检测、弱运动和外观约束以及长期遮挡问题，导致无法有效跟踪未见类别。

**Method:** 本文提出了一种名为Multi-Tracklet Tracking (MTT) 的轨迹增强跟踪器，它将灵活的轨迹段生成集成到多轨迹段关联框架中。该框架首先根据短时空相关性自适应地将检测结果聚类为鲁棒轨迹段，然后利用位置、外观等多种线索估计最佳轨迹段划分，以减轻长期关联中的误差传播。

**Result:** 在通用多目标跟踪基准上的广泛实验表明，所提出的框架具有竞争力。

**Conclusion:** 该论文提出的Multi-Tracklet Tracking (MTT) 框架通过其灵活的轨迹生成和多轨迹关联机制，有效解决了通用目标跟踪中由于低置信度检测、弱约束和长期遮挡带来的挑战，并展现出良好的性能。

> **ai_Abstract:** 本文提出了一种名为Multi-Tracklet Tracking (MTT) 的通用目标跟踪方法，旨在解决现有方法在处理未见类别时遇到的低置信度检测、弱约束和长期遮挡问题。MTT通过将灵活的轨迹段生成与多轨迹段关联框架相结合，首先自适应地将检测结果聚类为鲁棒的短轨迹段，然后利用多种线索优化轨迹段划分，以减少长期关联中的误差。实验证明了该框架在通用多目标跟踪任务上的有效性。

> **摘要翻译:** 跟踪特定目标，如行人和车辆，一直是近期基于视觉的多目标跟踪研究的重点。然而，在某些现实场景中，由于低置信度检测、弱运动和外观约束以及长期遮挡，未见类别常常对现有方法构成挑战。为了解决这些问题，本文提出了一种名为Multi-Tracklet Tracking (MTT) 的轨迹增强跟踪器，它将灵活的轨迹段生成集成到多轨迹段关联框架中。该框架首先根据其短时空相关性自适应地将检测结果聚类为鲁棒的轨迹段，然后利用位置和外观等多种线索随时间估计最佳轨迹段划分，以减轻长期关联中的误差传播。最后，在通用多目标跟踪基准上的大量实验证明了所提出框架的竞争力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [424] [SPA++: Generalized Graph Spectral Alignment for Versatile Domain Adaptation](https://arxiv.org/abs/2508.05182)
> *SPA++：广义图谱对齐用于多功能领域适应*

*Zhiqing Xiao, Haobo Wang, Xu Lu, Wentao Ye, Gang Chen, Junbo Zhao* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 领域适应, 图谱对齐, 域内结构, 判别性, 鲁棒性

**Comment:** 

> **TL;DR:** SPA++是一种新的领域适应框架，通过图谱对齐和邻居感知传播，有效解决现有方法忽视域内结构导致判别性下降的问题，并在各种复杂场景下表现出卓越的鲁棒性和适应性。

**AI_Comments:** SPA++的创新之处在于其将领域适应问题建模为图原语，并结合了粗粒度的图谱对齐与细粒度的邻居感知传播机制，同时兼顾了域间可迁移性和域内结构。引入谱正则化器和扎实的理论分析（如泛化界限）增加了其方法的严谨性和可信度。其在复杂DA场景下的通用性和在基准测试中超越现有SOTA方法的性能，凸显了其在领域适应研究领域的重要性和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有领域适应（DA）方法侧重于捕获域间可迁移性，但忽略了丰富的域内结构，这在经验上导致判别性甚至更差。为了解决这种权衡，本文提出了SPA++。

**Method:** 提出广义图谱对齐框架SPA++。其核心包括：1) 将DA问题转化为图原语，通过新颖的谱正则化器在特征空间中对齐域图；2) 开发细粒度的邻居感知传播机制，增强目标域的判别性；3) 结合数据增强和一致性正则化，使其适应包括大多数DA设置和挑战性分布场景。此外，还提供了理论分析支持，包括基于图的DA泛化界限和谱对齐与平滑一致性的作用。

**Result:** 在基准数据集上的广泛实验表明，SPA++始终优于现有先进方法，在各种挑战性适应场景中实现了卓越的鲁棒性和适应性。

**Conclusion:** SPA++通过创新的图谱对齐和邻居感知传播机制，有效解决了领域适应中域内结构被忽视的问题，显著提升了跨域知识迁移的判别性、鲁棒性和适应性，并在理论和实践上均表现出优越性。

> **ai_Abstract:** 本文提出了一种名为SPA++的广义图谱对齐框架，旨在解决领域适应中现有方法忽视域内结构导致判别性下降的问题。SPA++通过将DA问题转化为图原语，并结合谱正则化器进行粗粒度图对齐，同时开发细粒度邻居感知传播机制以增强判别性。该框架还融入数据增强和一致性正则化以适应复杂场景，并提供了理论分析支持。实验结果表明，SPA++在多个基准数据集上均优于现有先进方法，展现出卓越的鲁棒性和适应性。

> **摘要翻译:** 领域适应（DA）旨在域偏移下，将知识从有标签的源域迁移到无标签或稀疏标签的目标域。大多数现有工作侧重于捕获域间可迁移性，但很大程度上忽视了丰富的域内结构，这在经验上导致判别性甚至更差。为了解决这种权衡，我们提出了一种广义图谱对齐框架SPA++。其核心简要概括如下：(1)-通过将DA问题转化为图原语，它结合了一种粗粒度图对齐机制和一种新颖的谱正则化器，以在特征空间中对齐域图；(2)-我们进一步开发了一种细粒度的邻居感知传播机制，以增强目标域的判别性；(3)-通过结合数据增强和一致性正则化，SPA++能够适应复杂场景，包括大多数DA设置，甚至具有挑战性的分布场景。此外，我们还提供了理论分析来支持我们的方法，包括基于图的DA泛化界限以及谱对齐和平滑一致性的作用。在基准数据集上的广泛实验表明，SPA++始终优于现有尖端方法，在各种挑战性适应场景中实现了卓越的鲁棒性和适应性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [436] [SPEX: A Vision-Language Model for Land Cover Extraction on Spectral Remote Sensing Images](https://arxiv.org/abs/2508.05202)
> *SPEX：一种用于光谱遥感图像土地覆盖提取的视觉-语言模型*

*Dongchen Si, Di Wang, Erzhong Gao, Xiaolei Qin, Liu Zhao, Jing Zhang, Minqiang Xu, Jianbo Zhan, Jianshe Wang, Lin Liu, Bo Du, Liangpei Zhang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉-语言模型, 土地覆盖提取, 光谱遥感, 指令遵循, 多光谱

**Comment:** 

> **TL;DR:** SPEX是一种新的视觉-语言模型，利用光谱信息和指令遵循机制，在光谱遥感图像上实现精确的土地覆盖提取，并优于现有SOTA方法。

**AI_Comments:** SPEX的创新之处在于其首次将多模态视觉-语言模型应用于光谱遥感图像的土地覆盖提取，并有效利用了光谱信息。通过构建SPIE数据集和引入特定训练策略，SPEX不仅提高了提取精度，还增强了模型的可解释性，为遥感图像分析领域带来了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言模型在像素级解释中未能充分利用光谱信息，特别是在多光谱场景下表现不佳，导致性能次优。

**Method:** 构建了一个名为SPIE的视觉-语言指令遵循数据集，将土地覆盖对象的光谱先验编码为LLM可识别的文本属性。在此基础上，提出了SPEX，一个多模态LLM，用于指令驱动的土地覆盖提取。引入了多尺度特征聚合、token上下文凝缩和多光谱视觉预训练等组件和训练策略。

**Result:** 在五个公共多光谱数据集上的广泛实验表明，SPEX在提取植被、建筑物和水体等典型土地覆盖类别方面持续优于现有最先进的方法。SPEX还能够生成文本解释，增强可解释性和用户友好性。

**Conclusion:** SPEX是第一个专门用于光谱遥感图像土地覆盖提取的多模态视觉-语言模型，通过有效利用光谱信息和指令遵循机制，实现了卓越的性能和可解释性。

> **ai_Abstract:** 本文提出SPEX，一个用于光谱遥感图像土地覆盖提取的视觉-语言模型。针对现有模型对光谱信息利用不足的问题，作者构建了SPIE数据集，将光谱先验编码为LLM可理解的文本属性。SPEX模型集成了多尺度特征聚合、token上下文凝缩和多光谱视觉预训练等技术，实现了指令驱动的像素级土地覆盖提取。实验结果表明，SPEX在多个数据集上均优于现有SOTA方法，并能提供预测的文本解释，提高了模型的可解释性和用户友好性。

> **摘要翻译:** 光谱信息长期以来被认为是遥感观测中的关键线索。尽管已经开发了许多视觉-语言模型用于像素级解释，但光谱信息仍未得到充分利用，导致性能不佳，特别是在多光谱场景中。为了解决这一限制，我们构建了一个名为SPIE的视觉-语言指令遵循数据集，该数据集基于经典光谱指数计算，将土地覆盖对象的光谱先验编码为大型语言模型（LLM）可识别的文本属性。利用该数据集，我们提出了SPEX，一个多模态LLM，旨在进行指令驱动的土地覆盖提取。为此，我们引入了几个精心设计的组件和训练策略，包括多尺度特征聚合、token上下文凝缩和多光谱视觉预训练，以实现精确和灵活的像素级解释。据我们所知，SPEX是第一个专门用于光谱遥感图像土地覆盖提取的多模态视觉-语言模型。在五个公共多光谱数据集上的广泛实验表明，SPEX在提取植被、建筑物和水体等典型土地覆盖类别方面持续优于现有最先进的方法。此外，SPEX能够为其预测生成文本解释，从而增强可解释性和用户友好性。代码将在此处发布：https://github.com/MiliLab/SPEX。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [447] [EndoMatcher: Generalizable Endoscopic Image Matcher via Multi-Domain Pre-training for Robot-Assisted Surgery](https://arxiv.org/abs/2508.05205)
> *EndoMatcher：通过多领域预训练实现机器人辅助手术中可泛化内窥镜图像匹配器*

*Bingyu Yang, Qingyao Tian, Yimeng Geng, Huai Liao, Xinyan Huang, Jiebo Luo, Hongbin Liu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 内窥镜图像匹配, 机器人辅助手术, 多领域预训练, 零样本泛化, Endo-Mix6

**Comment:** 

> **TL;DR:** EndoMatcher通过大规模多领域预训练和新数据集Endo-Mix6，显著提升了内窥镜图像匹配的泛化性和准确性，尤其适用于机器人辅助手术。

**AI_Comments:** EndoMatcher的创新之处在于其结合了多领域预训练、专门设计的双分支Vision Transformer架构以及针对大规模多领域数据集的渐进式多目标训练策略。通过构建首个多领域内窥镜匹配数据集Endo-Mix6，解决了该领域数据稀缺和泛化性差的关键挑战。其在零样本设置下的显著性能提升，证明了该方法在实际机器人辅助手术中的巨大应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 机器人辅助手术中的内窥镜图像密集特征匹配对于3D重建、导航和手术场景理解至关重要，但由于困难的视觉条件（如弱纹理、大视角变化）和标注数据稀缺而面临挑战。

**Method:** 提出EndoMatcher，一个通过大规模、多领域数据预训练的可泛化内窥镜图像匹配器。它采用双分支Vision Transformer提取多尺度特征，并通过双重交互块增强鲁棒性。为解决数据稀缺和增加领域多样性，构建了Endo-Mix6数据集（约1.2M真实和合成图像对，跨六个领域，通过SfM和模拟变换生成对应标签）。为应对Endo-Mix6带来的训练稳定性挑战，采用渐进式多目标训练策略以促进平衡学习和提高跨领域表示质量。

**Result:** EndoMatcher在零样本匹配实验中，在Hamlyn和Bladder数据集上，内点匹配数量分别比最先进的方法增加了140.69%和201.43%；在Gastro-Matching数据集上，匹配方向预测准确率（MDPA）提高了9.40%。在挑战性内窥镜条件下实现了密集和准确的匹配。

**Conclusion:** EndoMatcher通过多领域预训练和新颖的训练策略，成功解决了内窥镜图像匹配中的泛化性挑战，在零样本设置下表现出卓越的性能，对于机器人辅助手术具有重要意义。

> **ai_Abstract:** 本文提出了EndoMatcher，一个用于机器人辅助手术的可泛化内窥镜图像匹配器。它通过大规模多领域预训练和新构建的Endo-Mix6数据集（包含1.2M图像对），解决了内窥镜图像匹配中视觉条件困难和数据稀缺的问题。EndoMatcher采用双分支Vision Transformer结合双重交互块，并辅以渐进式多目标训练策略。实验证明，EndoMatcher在零样本设置下，相比现有SOTA方法，显著提高了匹配内点数量和准确率，展现了在挑战性内窥镜条件下的卓越泛化能力。

> **摘要翻译:** 在机器人辅助任务中，内窥镜图像中可泛化的密集特征匹配至关重要，这些任务包括3D重建、导航和手术场景理解。然而，由于困难的视觉条件（例如，弱纹理、大视角变化）和带标注数据稀缺，这仍然是一个挑战。为了应对这些挑战，我们提出了EndoMatcher，一个通过大规模、多领域数据预训练的可泛化内窥镜图像匹配器。为了应对困难的视觉条件，EndoMatcher采用双分支Vision Transformer来提取多尺度特征，并通过双重交互块增强以实现鲁棒的对应学习。为了克服数据稀缺并提高领域多样性，我们构建了Endo-Mix6，这是第一个用于内窥镜匹配的多领域数据集。Endo-Mix6包含大约120万对来自六个领域的真实和合成图像对，其对应标签使用Structure-from-Motion和模拟变换生成。Endo-Mix6的多样性和规模由于数据集大小、分布偏移和误差不平衡的显著变化，带来了训练稳定性方面的新挑战。为了解决这些问题，采用了一种渐进式多目标训练策略，以促进平衡学习并提高跨领域的表示质量。这使得EndoMatcher能够以零样本方式泛化到未见过的器官和成像条件。广泛的零样本匹配实验表明，EndoMatcher在Hamlyn和Bladder数据集上的内点匹配数量分别比最先进的方法增加了140.69%和201.43%，并在Gastro-Matching数据集上将匹配方向预测准确率（MDPA）提高了9.40%，在挑战性的内窥镜条件下实现了密集和准确的匹配。代码已公开在https://github.com/Beryl2000/EndoMatcher。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [454] [VFlowOpt: A Token Pruning Framework for LMMs with Visual Information Flow-Guided Optimization](https://arxiv.org/abs/2508.05211)
> *VFlowOpt：一种基于视觉信息流引导优化的LMMs令牌剪枝框架*

*Sihan Yang, Runsen Xu, Chenhang Cui, Tai Wang, Dahua Lin, Jiangmiao Pang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 令牌剪枝, 大型多模态模型, 视觉信息流, 计算效率, KV-Cache

**Comment:** 

> **TL;DR:** VFlowOpt是一种新的令牌剪枝框架，通过引入改进的注意力图、渐进式剪枝和视觉信息流引导优化，可以在保持性能的同时显著减少LMMs的视觉令牌，从而降低计算成本并加速推理。

**AI_Comments:** VFlowOpt的创新之处在于其结合了上下文相关性与信息熵来构建更精确的重要性图，并引入了带有回收机制的渐进式剪枝，有效缓解了信息损失问题。更重要的是，通过视觉信息流引导优化剪枝策略的超参数，使得剪枝过程能够更好地适应不同LMM的特性，从而在保持高性能的同时实现显著的计算效率提升，这对于LMMs的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）在视觉-语言任务中表现出色，但其使用的海量视觉令牌导致计算成本高昂且存在冗余。现有的令牌剪枝方法过于简单且探索不足，常导致性能显著下降。

**Method:** 本研究提出了VFlowOpt框架，包含以下关键方法：1. 基于注意力派生的上下文相关性和补丁级信息熵计算图像令牌的重要性图。2. 引入带有回收机制的渐进式剪枝模块，将剪枝后的令牌聚合成回收令牌以避免潜在的信息损失。3. 应用视觉信息流引导方法优化剪枝策略的超参数，该方法将LMM中最后一个令牌视为文本-视觉交互最具代表性的信号，并最小化剪枝前后LMM中令牌表示的差异。

**Result:** VFlowOpt能够剪枝90%的视觉令牌，同时保持可比的性能。这使得KV-Cache内存减少了89%，推理速度提高了3.8倍。

**Conclusion:** VFlowOpt通过其创新的剪枝策略和优化方法，有效解决了LMMs中视觉令牌冗余导致的计算效率问题，在大幅减少计算资源的同时保持了高性能，为LMMs的实际部署提供了更高效的解决方案。

> **ai_Abstract:** VFlowOpt是一种针对大型多模态模型（LMMs）的令牌剪枝框架，旨在解决视觉令牌冗余导致的计算成本高昂问题。该框架通过引入基于注意力上下文相关性和信息熵的重要性图推导、带有回收机制的渐进式剪枝模块，以及通过视觉信息流引导的超参数优化，实现高效的视觉令牌剪枝。实验证明，VFlowOpt能在剪枝90%视觉令牌的同时保持性能，并显著降低KV-Cache内存和加速推理。

> **摘要翻译:** 大型多模态模型（LMMs）通过利用大量的视觉令牌来获取细粒度的视觉信息，从而在视觉-语言任务中表现出色，但这种令牌冗余导致了显著的计算成本。以前旨在减少推理期间视觉令牌的研究通常利用来自纯视觉令牌或视觉-语言令牌之间注意力分数的重要性图，在一个或多个剪枝阶段进行令牌剪枝。尽管取得了进展，但剪枝框架和策略仍然过于简单且探索不足，常常导致性能大幅下降。在本文中，我们提出了VFlowOpt，一个令牌剪枝框架，它引入了一种重要性图推导过程和一种带有回收机制的渐进式剪枝模块。其剪枝策略的超参数进一步通过视觉信息流引导方法进行优化。具体而言，我们根据图像令牌的注意力派生的上下文相关性和补丁级信息熵计算其重要性图。然后我们决定保留或剪枝哪些令牌，并将剪枝后的令牌聚合成回收令牌以避免潜在的信息损失。最后，我们应用了一种视觉信息流引导方法，该方法将LMM中最后一个令牌视为文本-视觉交互最具代表性的信号。这种方法最小化了剪枝前后LMM中令牌表示之间的差异，从而能够为不同的LMMs定制更优越的剪枝策略。实验表明，VFlowOpt可以在保持可比性能的同时剪枝90%的视觉令牌，从而使KV-Cache内存减少89%，推理速度提高3.8倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [462] [Textual and Visual Guided Task Adaptation for Source-Free Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2508.05213)
> *文本和视觉引导的任务适应，用于无源跨域小样本分割*

*Jianming Liu, Wenlong Qiu, Haitao Wei* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 小样本分割, 跨域, 无源, 任务适应, 文本-视觉引导

**Comment:** 

> **TL;DR:** 本文提出了一种无源跨域小样本分割（CD-FSS）方法，通过结合文本和视觉信息进行任务适应，显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新之处在于解决了无源跨域小样本分割问题，这对于数据隐私和降低成本至关重要。通过结合文本和视觉信息进行双重引导，特别是利用预对齐的多模态特征（如CLIP）来指导任务适应，是一种新颖且有效的方法。其在性能上的显著提升验证了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 小样本分割（FSS）在训练和部署之间存在领域差异时性能会显著下降。现有的跨域小样本分割（CD-FSS）方法主要集中于在源域开发模型以实现跨域泛化。然而，出于对数据隐私日益增长的担忧以及最大程度减少数据传输和训练成本的需求，开发无源CD-FSS方法变得至关重要。

**Method:** 本文提出了一种无源CD-FSS方法，该方法利用文本和视觉信息来促进目标域任务适应，而无需源域数据。具体来说，首先将任务特定注意力适配器（TSAA）附加到预训练骨干网络的特征金字塔上，以适应从共享预训练骨干网络中提取的多级特征到目标任务。然后，TSAA的参数通过视觉-视觉嵌入对齐（VVEA）模块和文本-视觉嵌入对齐（TVEA）模块进行训练。VVEA模块利用全局-局部视觉特征来对齐不同视图的图像特征，而TVEA模块利用预对齐多模态特征（例如来自CLIP）的文本先验来指导跨模态适应。通过密集比较操作和随后的跳跃连接融合，结合这些模块的输出，我们的方法生成了精炼的预测掩码。

**Result:** 在1-shot和5-shot设置下，所提出的方法在四个跨域数据集上分别实现了平均分割精度2.18%和4.11%的提高，显著优于最先进的CD-FSS方法。

**Conclusion:** 本文提出的方法通过利用文本和视觉信息进行任务适应，有效解决了无源跨域小样本分割问题，并取得了卓越的性能。

> **ai_Abstract:** 本文提出了一种新颖的无源跨域小样本分割（CD-FSS）方法，该方法利用文本和视觉信息在不依赖源域数据的情况下实现目标域任务适应。该方法通过在预训练骨干网络上应用任务特定注意力适配器（TSAA），并利用视觉-视觉嵌入对齐（VVEA）模块和文本-视觉嵌入对齐（TVEA）模块训练其参数。实验结果表明，该方法在多个跨域数据集上显著提升了分割精度，性能超越了现有最先进的CD-FSS方法。

> **摘要翻译:** 小样本分割（FSS）旨在用少量标记样本实现新对象的有效分割。然而，当训练和部署之间存在领域差异时，其性能会显著下降。为了缓解这种性能下降，提出了跨域小样本分割（CD-FSS）。当前的CD-FSS方法主要寻求在源域开发能够进行跨域泛化的分割模型。然而，出于对数据隐私日益增长的担忧以及最大程度减少数据传输和训练成本的需求，开发无源CD-FSS方法变得至关重要。在这项工作中，我们提出了一种无源CD-FSS方法，该方法利用文本和视觉信息来促进目标域任务适应，而无需源域数据。具体来说，我们首先将任务特定注意力适配器（TSAA）附加到预训练骨干网络的特征金字塔上，以适应从共享预训练骨干网络中提取的多级特征到目标任务。然后，TSAA的参数通过视觉-视觉嵌入对齐（VVEA）模块和文本-视觉嵌入对齐（TVEA）模块进行训练。VVEA模块利用全局-局部视觉特征来对齐不同视图的图像特征，而TVEA模块利用预对齐多模态特征（例如来自CLIP）的文本先验来指导跨模态适应。通过密集比较操作和随后的跳跃连接融合，结合这些模块的输出，我们的方法生成了精炼的预测掩码。在1-shot和5-shot设置下，所提出的方法在四个跨域数据集上分别实现了平均分割精度2.18%和4.11%的提高，显著优于最先进的CD-FSS方法。代码可在https://github.com/ljm198134/TVGTANet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [Segmenting the Complex and Irregular in Two-Phase Flows: A Real-World Empirical Study with SAM2](https://arxiv.org/abs/2508.05227)
> *双相流中复杂不规则结构的分割：基于SAM2的真实世界实证研究*

*Semanur Küçük, Cosimo Della Santina, Angeliki Laskari* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 双相流分割, 气泡分割, Segment Anything Model (SAM), 迁移学习, 不规则形状

**Comment:** 

> **TL;DR:** 双相流中不规则气泡的分割是一个难题。本研究首次证明，通过少量（100张）标注图像对SAM v2.1进行微调，可以准确分割高度非凸、不规则的气泡结构。

**AI_Comments:** 该研究的创新之处在于利用现代视觉基础模型（SAM）和迁移学习来解决多相流中复杂气泡几何形状的长期分割挑战。其在仅需100张标注图像的情况下就能实现高精度分割，这对于数据标注成本高昂的实际工业应用而言，具有重要的实践意义和潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 在多相流中分割气泡是一个关键但尚未解决的挑战，特别是在气泡发生变形、聚结或破裂导致其形状复杂不规则时，传统的和大多数基于学习的方法都因假设气泡接近球形而失效，这限制了它们在实际工业环境中的有效性。

**Method:** 本研究将气泡分割任务视为一个迁移学习问题，并利用现代视觉基础模型，具体是对Segment Anything Model (SAM v2.1)进行微调。

**Result:** 首次证明了经过微调的Segment Anything Model (SAM v2.1)能够使用少至100张标注图像，准确地分割高度非凸、不规则的气泡结构。

**Conclusion:** 通过迁移学习对SAM v2.1进行微调，即使仅使用少量标注数据，也能有效解决双相流中复杂不规则气泡的精确分割问题。

> **ai_Abstract:** 本文旨在解决双相流中复杂不规则气泡分割的难题，现有方法因假设气泡为球形而受限。通过将此任务视为迁移学习问题，并对Segment Anything Model (SAM v2.1)进行微调，研究首次证明了该模型能够使用极少量（低至100张）标注图像，准确分割高度非凸、不规则的气泡结构，为工业应用提供了新的解决方案。

> **摘要翻译:** 在多相流中分割气泡是众多工业环境（从冶金加工到船舶减阻）中一个关键但尚未解决的挑战。传统方法和大多数最新的基于学习的方法都假设气泡接近球形，这限制了它们在气泡发生变形、聚结或破裂的区域中的有效性。这种复杂性在空气润滑系统中尤为明显，其中聚结的气泡形成无定形且拓扑结构多样的斑块。在这项工作中，我们通过现代视觉基础模型的视角重新审视了这个问题。我们将该任务视为一个迁移学习问题，并首次证明了经过微调的Segment Anything Model SAM v2.1可以使用少至100张带标注的图像准确地分割高度非凸、不规则的气泡结构。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [478] [ArbiViewGen: Controllable Arbitrary Viewpoint Camera Data Generation for Autonomous Driving via Stable Diffusion Models](https://arxiv.org/abs/2508.05236)
> *ArbiViewGen：基于稳定扩散模型的可控任意视角自动驾驶相机数据生成*

*Yatong Lan, Jingfeng Chen, Yiru Wang, Lei He* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 任意视角生成, 扩散模型, 自动驾驶, 自监督学习, 视图拼接

**Comment:** 

> **TL;DR:** ArbiViewGen是一种新的扩散模型框架，用于生成可控的任意视角相机图像，解决了自动驾驶中缺乏外推视图真实数据的问题，通过特征感知自适应视图拼接和跨视图一致性自监督学习实现。

**AI_Comments:** 这篇论文通过提出Arbiviewgen，创新性地将扩散模型应用于自动驾驶中的任意视角图像生成，解决了传统方法中真实数据缺失的痛点。其引入的FAVS和CVC-SSL组件设计巧妙，特别是CVC-SSL的自监督范式，有效避免了对额外标注数据的依赖。该方法无需额外传感器，降低了数据采集成本，对于推动自动驾驶感知技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中任意视角图像生成潜力巨大，但由于缺乏外推视图的真实数据，阻碍了高保真生成模型的训练，因此需要一种新的方法来解决这一挑战。

**Method:** 提出Arbiviewgen，一个基于扩散模型的新框架。核心组件是：1) 特征感知自适应视图拼接 (FAVS)，通过分层匹配策略建立粗略几何对应和细粒度对齐，并识别高置信度匹配区域。2) 跨视图一致性自监督学习 (CVC-SSL)，模型从合成拼接图像中重建原始相机视图，强制执行跨视图一致性，无需外推数据监督。该框架仅需多相机图像及其姿态进行训练。

**Result:** Arbiviewgen是首个能够在多种车辆配置下生成可控任意视图相机图像的方法。

**Conclusion:** Arbiviewgen通过解决外推视图真实数据缺失的问题，实现了可控的任意视角相机数据生成，且无需额外的传感器或深度图，为自动驾驶领域提供了新的解决方案。

> **ai_Abstract:** Arbiviewgen是一个创新的基于扩散模型的框架，专为自动驾驶领域生成可控的任意视角相机数据而设计。该框架通过引入特征感知自适应视图拼接（FAVS）和跨视图一致性自监督学习（CVC-SSL）两大核心组件，有效地解决了外推视图真实数据匮乏的难题。FAVS利用分层匹配策略实现视图的精确拼接，而CVC-SSL则通过自监督方式确保生成图像的跨视图一致性。值得一提的是，Arbiviewgen仅需多相机图像和姿态即可进行训练，无需额外传感器或深度图，并且是首个实现多车辆配置下可控任意视角图像生成的方法。

> **摘要翻译:** 任意视角图像生成在自动驾驶领域具有巨大潜力，但由于缺乏外推视图的真实数据，阻碍了高保真生成模型的训练，这仍然是一项具有挑战性的任务。在这项工作中，我们提出了Arbiviewgen，一个新颖的基于扩散模型的框架，用于生成可控的任意视角相机图像。为了解决未见视图中真实数据缺失的问题，我们引入了两个关键组件：特征感知自适应视图拼接（FAVS）和跨视图一致性自监督学习（CVC-SSL）。FAVS采用分层匹配策略，首先使用相机姿态建立粗略的几何对应关系，然后通过改进的特征匹配算法执行细粒度对齐，并通过聚类分析识别高置信度匹配区域。在此基础上，CVC-SSL采用自监督训练范式，模型使用扩散模型从合成的拼接图像中重建原始相机视图，强制执行跨视图一致性，而无需外推数据的监督。我们的框架仅需要多相机图像及其关联姿态进行训练，无需额外的传感器或深度图。据我们所知，Arbiviewgen是第一个能够在多种车辆配置下生成可控任意视角相机图像的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [486] [B4DL: A Benchmark for 4D LiDAR LLM in Spatio-Temporal Understanding](https://arxiv.org/abs/2508.05269)
> *B4DL：一个用于时空理解的4D激光雷达大型语言模型基准*

*Changho Choi, Youngwoo Shin, Gyojin Han, Dong-Jae Lee, Junmo Kim* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 4D LiDAR, MLLM, 时空理解, 基准, B4DL

**Comment:** 

> **TL;DR:** 引入B4DL，一个用于4D激光雷达理解的MLLM新基准，以及一个能直接处理原始4D激光雷达数据并与语言理解结合的MLLM模型，以解决现有高质量标注和模型架构的缺失问题。

**AI_Comments:** 这篇论文的创新点在于首次提出了一个专门针对4D激光雷达数据与大型多模态语言模型结合的基准（B4DL），并开发了能够直接处理原始4D激光雷达数据的MLLM模型，这对于推动时空理解和动态环境感知具有重要意义。它填补了现有高质量模态特定标注和合适模型架构的空白，为未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 理解动态户外环境需要捕捉复杂的物体交互及其随时间演变。尽管4D激光雷达在表示现实世界场景方面具有潜力，但由于缺乏高质量、模态特定的标注以及能够处理其高维组成的大型多模态语言模型（MLLM）架构，4D激光雷达在MLLM背景下仍未得到充分探索。

**Method:** 我们引入了B4DL，一个专门为训练和评估MLLM在4D激光雷达理解方面设计的新基准。此外，我们提出了一种可扩展的数据生成管道和一个MLLM模型，该模型首次通过将其与语言理解相结合，直接处理原始4D激光雷达数据。

**Result:** 结合我们的数据集和基准，我们提出的模型为动态户外环境中的时空推理提供了一个统一的解决方案。研究团队还提供了渲染的4D激光雷达视频、生成的数据集以及在不同场景下的推理输出。

**Conclusion:** 该论文引入了B4DL基准、可扩展的数据生成管道和新的MLLM模型，首次实现了原始4D激光雷达数据与语言理解的直接结合，为动态户外环境中的时空推理提供了一个统一的解决方案，解决了4D激光雷达在MLLM应用中缺乏高质量标注和合适模型架构的挑战。

> **ai_Abstract:** 该论文提出了B4DL，一个用于4D激光雷达理解的新基准，旨在解决多模态大型语言模型（MLLM）在处理4D激光雷达数据时面临的标注和架构挑战。作者还开发了一个可扩展的数据生成管道和一个创新的MLLM模型，该模型能够直接处理原始4D激光雷达数据并将其与语言理解相结合。此集成方案为动态户外环境中的时空推理提供了一个统一的框架。

> **摘要翻译:** 理解动态户外环境需要捕捉复杂的物体交互及其随时间演变。基于激光雷达的4D点云提供了精确的空间几何和丰富的时序线索，使其成为表示真实世界场景的理想选择。然而，尽管4D激光雷达具有潜力，但由于缺乏高质量、模态特定的标注以及能够处理其高维组成的大型多模态语言模型（MLLM）架构，4D激光雷达在MLLM背景下仍未得到充分探索。为了解决这些挑战，我们引入了B4DL，一个专门为训练和评估MLLM在4D激光雷达理解方面设计的新基准。此外，我们提出了一种可扩展的数据生成管道和一个MLLM模型，该模型首次通过将其与语言理解相结合，直接处理原始4D激光雷达数据。结合我们的数据集和基准，我们的模型为动态户外环境中的时空推理提供了一个统一的解决方案。我们提供了渲染的4D激光雷达视频、生成的数据集以及在不同场景下的推理输出，网址为：https://mmb4dl.github.io/mmb4dl/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [494] [Wavelet-Guided Dual-Frequency Encoding for Remote Sensing Change Detection](https://arxiv.org/abs/2508.05271)
> *小波引导的双频编码遥感变化检测*

*Xiaoyang Zhang, Guodong Fan, Guang-Yong Chen, Zhen Hua, Jinjiang Li, Min Gan, C. L. Philip Chen* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 遥感, 变化检测, 小波变换, 双频编码, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为WGDF的小波引导双频编码方法，用于遥感图像变化检测。该方法通过利用频域特征，特别是小波域特征，来增强对细微变化的感知，克服了现有空间域方法的局限性，提高了检测精度和鲁棒性。

**AI_Comments:** 该论文的创新之处在于其将小波变换引入深度学习框架中，用于遥感变化检测，有效地结合了频域分析的优势。通过将图像分解为高频和低频分量并分别处理，WGDF能够同时关注细微的边缘变化和宏观的结构变化，这弥补了传统空间域方法在捕捉复杂变化方面的不足。双分支架构和专门设计的模块（DFFE、FDID、PCDM）体现了对不同频率特征的精细化处理。这项工作对于提升遥感图像变化检测的精度和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感图像变化检测在自然灾害监测、城市扩张追踪和基础设施管理等工程应用中至关重要。尽管深度学习取得了显著进展，但大多数现有方法仍依赖于空间域建模，其有限的特征表示多样性阻碍了对细微变化区域的检测。研究发现频域特征建模，特别是在小波域中，可以放大频率分量中的细粒度差异，增强对空间域中难以捕获的边缘变化的感知。

**Method:** 本文提出了一种名为小波引导的双频编码（WGDF）方法。具体来说，首先应用离散小波变换（DWT）将输入图像分解为高频和低频分量，分别用于建模局部细节和全局结构。在高频分支中，设计了一个双频特征增强（DFFE）模块来强化边缘细节表示，并引入了一个频域交互差异（FDID）模块来增强细粒度变化的建模。在低频分支中，利用Transformer捕获全局语义关系，并采用渐进式上下文差异模块（PCDM）逐步细化变化区域，实现精确的结构语义表征。最后，高频和低频特征协同融合，以统一局部敏感性和全局判别性。

**Result:** 在多个遥感数据集上进行的广泛实验表明，WGDF显著缓解了边缘模糊性，与最先进的方法相比，实现了卓越的检测精度和鲁棒性。

**Conclusion:** WGDF方法通过有效利用双频特征（高频和低频）克服了遥感变化检测中空间域方法的局限性，从而提高了精度和鲁棒性，尤其是在捕获细微边缘变化方面。

> **ai_Abstract:** 本文提出了一种新颖的小波引导双频编码（WGDF）方法，用于遥感图像变化检测，旨在解决现有空间域方法在检测细微变化时特征表示不足的问题。WGDF通过离散小波变换将图像分解为高频和低频分量，分别处理局部细节和全局结构。高频分支利用DFFE和FDID模块增强边缘细节和细粒度变化检测，而低频分支则结合Transformer和PCDM模块捕捉全局语义并逐步细化变化区域。最终，融合高低频特征以实现局部敏感性和全局判别性的统一。实验证明，该方法在多个数据集上有效缓解了边缘模糊性，并优于现有最先进方法。

> **摘要翻译:** 遥感图像变化检测在自然灾害监测、城市扩张追踪和基础设施管理等各种工程应用中发挥着至关重要的作用。尽管近年来深度学习取得了显著进展，但大多数现有方法仍依赖于空间域建模，其中特征表示的有限多样性阻碍了对细微变化区域的检测。我们观察到，频域特征建模，特别是在小波域中，可以放大频率分量中的细粒度差异，增强对空间域中难以捕获的边缘变化的感知。因此，我们提出了一种名为小波引导的双频编码（WGDF）方法。具体来说，我们首先应用离散小波变换（DWT）将输入图像分解为高频和低频分量，分别用于建模局部细节和全局结构。在高频分支中，我们设计了一个双频特征增强（DFFE）模块来强化边缘细节表示，并引入了一个频域交互差异（FDID）模块来增强细粒度变化的建模。在低频分支中，我们利用Transformer来捕获全局语义关系，并采用渐进式上下文差异模块（PCDM）来逐步细化变化区域，从而实现精确的结构语义表征。最后，高频和低频特征协同融合，以统一局部敏感性与全局判别性。在多个遥感数据集上进行的广泛实验表明，WGDF显著缓解了边缘模糊性，与最先进的方法相比，实现了卓越的检测精度和鲁棒性。代码将可在https://github.com/boshizhang123/WGDF获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [500] [CoCAViT: Compact Vision Transformer with Robust Global Coordination](https://arxiv.org/abs/2508.05307)
> *CoCAViT：具有鲁棒全局协调的紧凑型视觉Transformer*

*Xuyang Wang, Lingjuan Miao, Zhiqiang Zhou* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** Vision Transformer, 紧凑模型, 域外泛化, 交叉注意力, 视觉骨干网络

**Comment:** 

> **TL;DR:** CoCAViT是一种新型紧凑型视觉Transformer，通过引入协调器-补丁交叉注意力（CoCA）机制，解决了小型模型在域外（OOD）数据上泛化性能下降的问题，实现了鲁棒的实时视觉表示，并在多个基准测试中取得了显著性能。

**AI_Comments:** CoCAViT的创新之处在于其针对小型模型在OOD数据上泛化能力不足的痛点，提出了独特的协调器-补丁交叉注意力（CoCA）机制。这种机制通过动态、域感知的全局token，有效地弥补了纯窗口注意力在全局信息捕获上的不足，同时保持了计算效率。其在紧凑模型中实现鲁棒性的方法对于实际应用具有重要意义，尤其是在资源受限的实时系统中。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，大型视觉骨干网络在通过大量预训练学习通用特征方面表现出色。同时，许多高效架构在域内基准测试上取得了与大型模型相当的性能。然而，研究发现对于小型模型，在域外（OOD）数据上的性能下降比例更大，这表明现有高效模型的泛化性能存在缺陷。

**Method:** 为了解决小型模型在域外数据上泛化性能下降的问题，本文识别了导致此问题的关键架构瓶颈和不恰当的设计选择，旨在为小型模型保留鲁棒性。为恢复纯窗口注意力机制的全局视野，引入了一种协调器-补丁交叉注意力（CoCA）机制，该机制具有动态、域感知的全局token，可增强局部-全局特征建模，并以最小的计算开销自适应地捕获跨域的鲁棒模式。将这些改进集成后，提出了CoCAViT，一种用于鲁棒实时视觉表示的新型视觉骨干网络。

**Result:** CoCAViT在224*224分辨率下，CoCAViT-28M在ImageNet-1K上实现了84.0%的top-1准确率，与竞争模型相比，在多个OOD基准测试上取得了显著的性能提升。它还在COCO目标检测上达到了52.2 mAP，在ADE20K语义分割上达到了51.3 mIOU，同时保持了低延迟。

**Conclusion:** CoCAViT是一种新颖的视觉骨干网络，通过引入协调器-补丁交叉注意力（CoCA）机制，有效解决了小型模型在域外数据上的泛化性能不足问题，实现了鲁棒的实时视觉表示，并在多项视觉任务中展现出卓越的性能和效率。

> **ai_Abstract:** CoCAViT提出了一种紧凑型视觉Transformer，旨在解决现有小型模型在域外（OOD）数据上泛化性能不足的问题。通过识别架构瓶颈并引入创新的协调器-补丁交叉注意力（CoCA）机制，CoCAViT能够恢复全局视野，增强局部-全局特征建模，并自适应捕获跨域的鲁棒模式，同时保持低计算开销。实验证明，CoCAViT在ImageNet-1K上取得了高准确率，并在多个OOD基准测试以及COCO目标检测和ADE20K语义分割任务上均表现出色，验证了其在鲁棒实时视觉表示方面的有效性。

> **摘要翻译:** 近年来，大型视觉骨干网络通过广泛的预训练，在学习图像通用特征方面表现出卓越的能力。与此同时，许多高效架构也应运而生，在域内基准测试上表现出与大型模型相当的性能。然而，我们观察到对于小型模型，在域外（OOD）数据上的性能下降比例更大，这表明现有高效模型的泛化性能存在缺陷。为了解决这个问题，我们识别了导致此问题的关键架构瓶颈和不恰当的设计选择，旨在为小型模型保留鲁棒性。为了恢复纯窗口注意力机制的全局视野，我们进一步引入了一种协调器-补丁交叉注意力（CoCA）机制，该机制具有动态、域感知的全局token，可增强局部-全局特征建模，并以最小的计算开销自适应地捕获跨域的鲁棒模式。将这些进步整合后，我们提出了CoCAViT，一种用于鲁棒实时视觉表示的新型视觉骨干网络。广泛的实验经验性地验证了我们的设计。在224*224分辨率下，CoCAViT-28M在ImageNet-1K上实现了84.0%的top-1准确率，与竞争模型相比，在多个OOD基准测试上取得了显著的性能提升。它还在COCO目标检测上达到了52.2 mAP，在ADE20K语义分割上达到了51.3 mIOU，同时保持了低延迟。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [506] [Textual Inversion for Efficient Adaptation of Open-Vocabulary Object Detectors Without Forgetting](https://arxiv.org/abs/2508.05323)
> *文本反演实现开放词汇目标检测器的无遗忘高效适应*

*Frank Ruis, Gertjan Burghouts, Hugo Kuijf* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 文本反演, 开放词汇目标检测, 少样本学习, 遗忘, 视觉语言模型

**Comment:** 

> **TL;DR:** 本文提出将文本反演（Textual Inversion, TI）应用于开放词汇目标检测，以高效适应新型或细粒度对象，仅需少量样本，同时保留模型原有能力并避免遗忘。

**AI_Comments:** 该论文的创新之处在于将文本反演（Textual Inversion）这一在文本到图像生成领域取得成功的技术，创造性地应用于开放词汇目标检测。这有效地解决了在模型适应新对象时，大型视觉语言模型（VLMs）普遍存在的灾难性遗忘问题，同时实现了高效的少样本学习。其保持原始模型能力和显著降低计算资源的特点，使其在实际应用中极具价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型预训练视觉语言模型（VLMs）在目标检测方面表现出色并具有强大的零样本能力，但为了在特定目标上获得最佳性能，仍需要某种形式的微调。然而，传统的微调方法通常会导致原始的自然语言查询和零样本能力丢失（即遗忘问题）。

**Method:** 受文本反演（TI）在个性化文本到图像扩散模型中成功的启发，本文提出了一种针对开放词汇目标检测的类似表述。TI通过学习新的或改进现有token来扩展VLM词汇，从而仅用少量（最少三个）示例即可准确检测新颖或细粒度对象。学习到的token与原始VLM权重完全兼容，同时保持原始权重冻结，保留了原始模型的基准性能，并利用了其现有能力，如零样本域迁移。存储和梯度计算仅限于token嵌入维度，计算量远低于全模型微调。

**Result:** 在各种定量和定性实验中，该方法与那些存在遗忘问题的基线方法相比，性能相当或更优。

**Conclusion:** 文本反演（TI）可以高效地将开放词汇目标检测器适应于新目标，仅需极少量示例，且不会发生灾难性遗忘，同时保留了模型的原始能力并显著减少了计算需求。

> **ai_Abstract:** 本文提出了一种将文本反演（TI）应用于开放词汇目标检测的新方法，以解决大型预训练视觉语言模型（VLMs）在微调时面临的遗忘问题。该方法通过学习或改进文本token来扩展VLM的词汇量，使其能够从极少量（最少三个）样本中识别新的或细粒度对象。与传统微调不同，TI保持原始VLM权重冻结，从而保留了模型的零样本能力和基准性能，并显著降低了计算成本。实验结果表明，该方法在性能上与现有基线方法相当或更优，且有效避免了灾难性遗忘。

> **摘要翻译:** 大型预训练视觉语言模型（VLMs）的最新进展在多个目标检测基准上取得了最先进的性能，并拥有强大的零样本能力，但为了在特定目标上获得最佳性能，某种形式的微调仍然是必要的。虽然初始的VLM权重允许很好的少样本迁移学习，但这通常会导致原始的自然语言查询和零样本能力的丧失。受文本反演（TI）在个性化文本到图像扩散模型中成功的启发，我们为开放词汇目标检测提出了一种类似的表述。TI允许通过学习新的或改进现有token来扩展VLM词汇，从而仅用最少三个示例即可准确检测新颖或细粒度对象。学习到的token与原始VLM权重完全兼容，同时保持原始权重冻结，保留了原始模型的基准性能，并利用了其现有能力，如零样本域迁移（例如，在仅用真实照片训练后检测对象的草图）。存储和梯度计算仅限于token嵌入维度，所需的计算量显著少于全模型微调。我们通过各种定量和定性实验评估了该方法是否与那些存在遗忘问题的基线方法相匹配或超越。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [3DGabSplat: 3D Gabor Splatting for Frequency-adaptive Radiance Field Rendering](https://arxiv.org/abs/2508.05343)
> *3DGabSplat: 用于频率自适应辐射场渲染的3D Gabor Splatting*

*Junyu Zhou, Yuyang Huang, Wenrui Dai, Junni Zou, Ziyang Zheng, Nuowen Kan, Chenglin Li, Hongkai Xiong* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D高斯Splatting, 辐射场, Gabor, 新颖视图合成, 高频细节

**Comment:** 

> **TL;DR:** 3DGabSplat提出了一种基于3D Gabor的原始体，以解决3D高斯Splatting在表示高频细节、渲染效率和内存开销方面的局限性，从而实现更好的渲染质量和资源效率。

**AI_Comments:** 该论文的创新之处在于将Gabor函数引入到辐射场渲染中，以克服3DGS在高频细节表示上的固有局限性。Gabor原始体能够更好地捕获方向性和频率信息，这对于高精度场景重建至关重要。其即插即用的设计使其易于集成到现有框架中，具有很强的实用价值。通过同时提升质量和效率，该工作为实时高保真辐射场渲染提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的3D高斯Splatting（3DGS）由于高斯函数固有的低通特性，难以表示3D场景中的高频细节。此外，它会导致冗余的原始体，降低训练和渲染效率，并产生过多的内存开销。

**Method:** 本文提出了3D Gabor Splatting (3DGabSplat)，它利用一种新颖的基于3D Gabor的原始体，该原始体具有多个方向性的3D频率响应，用于辐射场表示，并通过多视角图像进行监督。该原始体形成了一个滤波器组，包含多个不同频率的3D Gabor核，以提高捕获精细3D细节的灵活性和效率。为了实现新颖视图渲染，开发了一个高效的基于CUDA的栅格化器，用于将3D Gabor原始体所表征的多个方向性3D频率分量投影到2D图像平面上，并引入了一种频率自适应机制，用于原始体的自适应联合优化。3DGabSplat可作为一个即插即用的内核，无缝集成到现有的3DGS范式中，以提升新颖视图合成的效率和质量。

**Result:** 实验表明，3DGabSplat优于3DGS及其使用其他原始体的变体，并在真实世界和合成场景中实现了最先进的渲染质量。值得注意的是，相对于3DGS，它实现了高达1.35 dB的PSNR增益，同时减少了原始体数量和内存消耗。

**Conclusion:** 3DGabSplat通过引入频率自适应的3D Gabor原始体，成功克服了3D高斯Splatting在处理高频细节、效率和内存方面的局限性，显著提升了新颖视图合成的质量和资源效率。

> **ai_Abstract:** 本文提出了3DGabSplat，旨在解决现有3D高斯Splatting (3DGS) 在高频细节表示、渲染效率和内存消耗方面的不足。3DGabSplat引入了一种新颖的基于3D Gabor的原始体，该原始体具有多方向3D频率响应，并形成一个包含多频率Gabor核的滤波器组，以更灵活高效地捕获精细3D细节。通过开发高效的CUDA栅格化器和频率自适应优化机制，3DGabSplat能够作为即插即用内核集成到现有3DGS框架中。实验证明，3DGabSplat在渲染质量上超越了3DGS及其变体，实现了高达1.35 dB的PSNR增益，同时显著减少了原始体数量和内存占用。

> **摘要翻译:** 3DGabSplat: 用于频率自适应辐射场渲染的3D Gabor Splatting

最近3D高斯Splatting (3DGS) 的突出表现使得实时渲染成为可能，同时保持了高保真度的新颖视图合成。然而，3DGS依赖于本质上是低通的高斯函数，在表示3D场景中的高频细节方面受到限制。此外，它导致了冗余的原始体，降低了训练和渲染效率，并产生了过多的内存开销。为了克服这些局限性，我们提出了3D Gabor Splatting (3DGabSplat)，它利用一种新颖的基于3D Gabor的原始体，该原始体具有多个方向性的3D频率响应，用于辐射场表示，并通过多视角图像进行监督。所提出的基于3D Gabor的原始体形成了一个滤波器组，包含多个不同频率的3D Gabor核，以增强捕获精细3D细节的灵活性和效率。此外，为了实现新颖视图渲染，开发了一个高效的基于CUDA的栅格化器，用于将3D Gabor原始体所表征的多个方向性3D频率分量投影到2D图像平面上，并引入了一种频率自适应机制，用于原始体的自适应联合优化。3DGabSplat可以作为一个即插即用的内核，无缝集成到现有的3DGS范式中，以提升新颖视图合成的效率和质量。大量的实验表明，3DGabSplat优于3DGS及其使用其他原始体的变体，并在真实世界和合成场景中实现了最先进的渲染质量。值得注意的是，相对于3DGS，我们实现了高达1.35 dB的PSNR增益，同时减少了原始体数量和内存消耗。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [517] [Cross-View Localization via Redundant Sliced Observations and A-Contrario Validation](https://arxiv.org/abs/2508.05369)
> *基于冗余切片观测和反例验证的跨视角定位*

*Yongjun Zhang, Mingtao Xiong, Yi Wan, Gui-Song Xia* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 跨视角定位, 冗余观测, a-contrario验证, Slice-Loc, 定位可靠性

**Comment:** 

> **TL;DR:** Slice-Loc通过将查询图像切片并使用a-contrario验证来提高跨视角定位的可靠性和精度，解决了现有方法缺乏冗余观测的问题。

**AI_Comments:** 该论文的创新点在于引入了“冗余切片观测”和“a-contrario验证”来解决跨视角定位中的可靠性评估难题。通过将单张查询图像分解为多个独立的子观测，并利用统计学方法（NFA）来量化定位的意义和过滤错误，极大地增强了定位结果的鲁棒性和可信度。这种方法对于需要在GNSS受限环境中进行高精度和高可靠性自定位的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的跨视角定位（CVL）方法通常只输出单个相机姿态观测，缺乏测量学原理所需的冗余观测，导致难以通过观测数据间的相互验证来评估定位可靠性。

**Method:** 本文提出了一种名为Slice-Loc的两阶段方法，用于跨视角定位的a-contrario可靠性验证。该方法不将查询图像作为一个单一输入，而是将其分割成子图像（切片），并估计每个切片的3自由度姿态，从而创建冗余和独立的观测。随后，提出了一种几何刚度公式来滤除错误的3自由度姿态，并将内点合并以生成最终的相机姿态。此外，还提出了一个模型，通过根据切片图像位置的分布估计误报数（NFA）来量化定位的意义。

**Result:** Slice-Loc通过消除大误差，提升了定位精度并有效检测故障。在滤除错误定位后，将超过10米误差的比例降低到3%以下。在DReSS数据集的跨城市测试中，Slice-Loc将平均定位误差从4.47米降低到1.86米，平均方向误差从3.42°降低到1.24°，优于现有最先进的方法。

**Conclusion:** Slice-Loc通过引入冗余切片观测和a-contrario验证，显著提高了跨视角定位的精度和可靠性，并能有效检测定位失败，解决了传统方法缺乏可靠性评估的问题。

> **ai_Abstract:** 本文提出了一种名为Slice-Loc的跨视角定位方法，旨在解决现有CVL方法缺乏冗余观测导致可靠性难以评估的问题。Slice-Loc将查询图像分割成多个子图像，为每个子图像估计3自由度姿态，从而生成冗余且独立的观测。通过引入几何刚度公式过滤错误姿态并合并有效姿态，以及利用a-contrario模型量化定位意义，Slice-Loc显著提高了定位精度并能有效检测故障。实验结果表明，该方法在DReSS数据集上显著优于现有技术。

> **摘要翻译:** 跨视角定位（CVL）将地面图像与航空参考图像匹配，以确定摄像机的地理位置，使智能车辆能够在GNSS拒绝环境中离线进行自定位。然而，大多数CVL方法仅输出单个观测结果，即摄像机姿态，并且缺乏测量原理所需的冗余观测，这使得通过观测数据的相互验证来评估定位可靠性变得具有挑战性。为了解决这个问题，我们引入了Slice-Loc，这是一种两阶段方法，具有用于CVL的反例可靠性验证。Slice-Loc不使用查询图像作为单一输入，而是将其划分为子图像并估计每个切片的3自由度姿态，从而创建冗余和独立的观测。然后，提出了一种几何刚度公式来滤除错误的3自由度姿态，并将内点合并以生成最终的摄像机姿态。此外，我们提出了一个模型，根据切片图像位置的分布估计误报数（NFA），从而量化定位的意义。通过消除总误差，Slice-Loc提高了定位精度并有效检测故障。在滤除错误定位后，Slice-Loc将超过10米误差的比例降低到3%以下。在DReSS数据集的跨城市测试中，Slice-Loc将平均定位误差从4.47米降低到1.86米，平均方向误差从3.42°降低到1.24°，性能优于现有最先进的方法。代码和数据集将在此处提供：https://github.com/bnothing/Slice-Loc。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [524] [CT-GRAPH: Hierarchical Graph Attention Network for Anatomy-Guided CT Report Generation](https://arxiv.org/abs/2508.05375)
> *CT-GRAPH：用于解剖引导的CT报告生成的层次图注意力网络*

*Hamza Kalisch, Fabian Hörst, Jens Kleesiek, Ken Herrmann, Constantin Seibold* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** CT报告生成, 层次图注意力网络, 解剖引导, 医学影像, 大型语言模型

**Comment:** 

> **TL;DR:** CT-GRAPH提出了一种层次图注意力网络，通过建模解剖区域来改进CT报告自动生成，并在F1分数上显著优于现有SOTA方法。

**AI_Comments:** 该论文的创新点在于引入了层次图注意力网络（CT-GRAPH）来显式建模解剖区域和器官之间的关系，这弥补了现有方法仅依赖全局特征的不足。通过将细粒度解剖知识融入模型，并结合预训练特征编码器和大型语言模型，显著提高了CT报告生成的准确性。其重要性在于能够有效辅助放射科医生，减轻其工作负担。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像在诊断过程中至关重要，放射科医生工作量繁重。当前的报告生成方法主要依赖全局图像特征，未能捕捉细粒度的器官关系，导致报告准确性不足。

**Method:** 本文提出了CT-GRAPH，一个层次图注意力网络，通过将解剖区域结构化为图来明确建模放射学知识，将细粒度器官特征链接到粗糙的解剖系统和全局患者上下文。该方法利用预训练的3D医学特征编码器，通过解剖掩模获取全局和器官级特征。这些特征在图内进一步细化，然后整合到大型语言模型中以生成详细的医疗报告。

**Result:** 在大型胸部CT数据集CT-RATE上对报告生成任务进行评估，结果显示CT-GRAPH在F1分数上比当前最先进的方法绝对提高了7.9%。

**Conclusion:** CT-GRAPH通过引入层次图注意力网络和显式建模解剖知识，显著提高了CT报告自动生成的准确性。

> **ai_Abstract:** CT-GRAPH是一个针对CT报告自动生成提出的层次图注意力网络。它通过构建解剖区域图谱来显式整合放射学知识，连接细粒度的器官特征与宏观解剖系统及全局患者背景。该模型利用预训练的3D医学特征编码器提取特征，并在图结构中进行精炼，随后输入大型语言模型生成报告。实验结果表明，该方法在CT-RATE数据集上比现有技术提升了7.9%的F1分数。

> **摘要翻译:** 医学影像在诊断过程中至关重要，因此自动化放射学报告生成对于辅助放射科医生应对繁重的工作量变得越来越重要。大多数现有方法仅依赖全局图像特征，未能捕捉对准确报告至关重要的细粒度器官关系。为此，我们提出了CT-GRAPH，一个层次图注意力网络，通过将解剖区域结构化为图，将细粒度器官特征链接到更粗糙的解剖系统和全局患者上下文，从而明确地建模放射学知识。我们的方法利用预训练的3D医学特征编码器，通过解剖掩模获取全局和器官级特征。这些特征在图内进一步细化，然后整合到大型语言模型中以生成详细的医疗报告。我们在大型胸部CT数据集CT-RATE上评估了我们的方法在报告生成任务上的表现。我们对用于CT报告生成的预训练特征编码器进行了深入分析，并表明我们的方法在F1分数上比当前最先进的方法绝对提高了7.9%。代码已在https://github.com/hakal104/CT-GRAPH 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [530] [Deformable Attention Graph Representation Learning for Histopathology Whole Slide Image Analysis](https://arxiv.org/abs/2508.05382)
> *用于组织病理学全玻片图像分析的可变形注意力图表示学习*

*Mingxi Fu, Xitong Ling, Yuxuan Chen, Jiawen Li, fanglei fu, Huaitian Yuan, Tian Guan, Yonghong He, Lianghui Zhu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 可变形注意力, 图神经网络, 全玻片图像, 组织病理学, 计算病理学

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于可变形注意力的图神经网络框架，用于组织病理学全玻片图像分析，通过引入可学习的空间偏移来捕获复杂的空间结构，并在多个基准数据集上取得了最先进的性能。

**AI_Comments:** 本文的创新点在于将可变形注意力引入图神经网络，用于组织病理学全玻片图像分析。通过结合可学习的空间偏移，模型能够更精确地捕获病理图像中复杂的空间结构和形态学特征，解决了传统方法在空间依赖性建模和注意力特异性方面的不足。其在多个基准数据集上取得的最先进性能，证明了该方法在计算病理学领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 计算病理学中全玻片图像（WSIs）和感兴趣区域（ROIs）的准确分类是一个基本挑战。主流的多实例学习（MIL）方法难以捕获组织结构间的空间依赖性。图神经网络（GNNs）虽能建模实例间关系，但多数依赖静态图拓扑并忽略组织斑块的物理空间位置。此外，传统注意力机制缺乏特异性，限制了其聚焦于结构相关区域的能力。

**Method:** 我们提出了一个新颖的GNN框架，引入了可变形注意力机制用于病理图像分析。该方法基于斑块特征构建了一个动态加权有向图，其中每个节点通过注意力加权边从其邻居聚合上下文信息。具体来说，我们结合了由每个斑块的真实坐标指导的可学习空间偏移，使模型能够自适应地关注整个玻片中形态学相关的区域。这种设计显著增强了上下文感知能力，同时保留了空间特异性。

**Result:** 我们的框架在四个基准数据集（TCGA-COAD、BRACS、胃肠化生分级和肠道ROI分类）上取得了最先进的性能，证明了可变形注意力在捕获WSIs和ROIs中复杂空间结构方面的强大能力。

**Conclusion:** 可变形注意力图表示学习方法能够有效捕获组织病理学全玻片图像中的复杂空间结构，并在多项分类任务中达到领先水平，为计算病理学提供了新的有效工具。

> **ai_Abstract:** 本文针对计算病理学中WSI和ROI分类面临的空间依赖性捕获不足及传统GNN和注意力机制局限性问题，提出了一种新型可变形注意力图神经网络（GNN）框架。该框架构建动态加权有向图，并通过引入基于斑块真实坐标的可学习空间偏移，使模型能自适应地关注形态学相关区域，有效增强上下文信息并保持空间特异性。实验证明，该方法在四个基准数据集上均达到最先进性能，突显了可变形注意力在处理复杂病理图像结构方面的优势。

> **摘要翻译:** 全玻片图像（WSIs）和感兴趣区域（ROIs）的准确分类是计算病理学中的一个基本挑战。尽管主流方法常采用多实例学习（MIL），但它们难以捕获组织结构间的空间依赖性。图神经网络（GNNs）已成为建模实例间关系的一种解决方案，但大多数依赖静态图拓扑并忽略组织斑块的物理空间位置。此外，传统注意力机制缺乏特异性，限制了其聚焦于结构相关区域的能力。在这项工作中，我们提出了一种用于病理图像分析的新型GNN框架，具有可变形注意力。我们基于斑块特征构建了一个动态加权有向图，其中每个节点通过注意力加权边从其邻居聚合上下文信息。具体来说，我们结合了由每个斑块的真实坐标指导的可学习空间偏移，使模型能够自适应地关注整个玻片中形态学相关的区域。这种设计显著增强了上下文场，同时保留了空间特异性。我们的框架在四个基准数据集（TCGA-COAD、BRACS、胃肠化生分级和肠道ROI分类）上取得了最先进的性能，证明了可变形注意力在捕获WSIs和ROIs中复杂空间结构方面的强大能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [536] [From Detection to Correction: Backdoor-Resilient Face Recognition via Vision-Language Trigger Detection and Noise-Based Neutralization](https://arxiv.org/abs/2508.05409)
> *从检测到纠正：通过视觉-语言触发器检测和基于噪声的中和实现后门弹性人脸识别*

*Farah Wahida, M.A.P. Chamikara, Yashothara Shanmugarasa, Mohan Baruwal Chhetri, Thilina Ranbaduge, Ibrahim Khalil* | **Category: cs.CV, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 后门攻击, 人脸识别, 视觉-语言模型, 中毒图像, 噪声中和

**Comment:** 

> **TL;DR:** TrueBiometric 提出了一种针对人脸识别系统中后门攻击的防御方法，通过视觉-语言模型检测中毒图像并使用基于噪声的中和进行纠正，实现了100%的检测和纠正准确率。

**AI_Comments:** 该论文的创新之处在于提出了一种从检测到纠正的完整后门攻击防御框架。其结合大型视觉-语言模型进行触发器检测的思路是新颖的，而100%的检测和纠正准确率（在不影响干净图像性能的情况下）是一个非常显著且重要的成果，表明了其在实践中的巨大潜力。这对于提高生物识别系统，特别是人脸识别系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络支持的人脸识别系统易受后门攻击，攻击者通过在训练图像中插入微小触发器来操纵训练过程，从而在认证时实现未经授权的访问。现有防御机制在精准识别和缓解中毒图像方面面临挑战，且可能损害数据效用。

**Method:** 本文提出了一种名为 TrueBiometric 的新颖方法。它利用多个最先进的大型视觉-语言模型通过多数投票机制准确检测中毒图像。一旦识别出中毒样本，则使用有针对性和校准的纠正噪声对其进行修正。

**Result:** TrueBiometric 能够以100%的准确率检测和纠正中毒图像，同时不损害干净图像的准确性。与现有最先进的方法相比，它提供了一种更实用、准确和有效的解决方案。

**Conclusion:** TrueBiometric 为人脸识别系统中的后门攻击提供了一种全面且高效的缓解方案，通过结合视觉-语言触发器检测和噪声中和技术，显著提升了系统的可靠性和安全性。

> **ai_Abstract:** 本文提出了一种名为 TrueBiometric 的新颖方法，旨在防御人脸识别系统中的后门攻击。该方法通过利用多个先进的视觉-语言模型进行多数投票来准确检测中毒图像，随后使用有针对性的校准噪声对识别出的中毒样本进行纠正。实验结果表明，TrueBiometric 能够以100%的准确率检测并纠正中毒图像，同时不影响正常图像的准确性，相比现有方法提供了更实用、准确和有效的后门攻击缓解方案。

> **摘要翻译:** 生物识别系统，例如由深度神经网络（DNN）驱动的人脸识别系统，依赖于大型且高度敏感的数据集。后门攻击可以通过操纵训练过程来颠覆这些系统。通过在少量训练图像中插入一个小的触发器，例如贴纸、化妆品或图案化面具，攻击者可以在认证时呈现相同的触发器，从而被错误地识别为另一个人，获得未经授权的访问。现有的针对后门攻击的防御机制在精确识别和缓解中毒图像方面仍然面临挑战，且不会损害数据效用，这损害了系统的整体可靠性。我们提出了一种新颖且可泛化的方法，TrueBiometric：可信生物识别，它利用多个最先进的大型视觉-语言模型通过多数投票机制准确检测中毒图像。一旦识别出来，中毒样本将使用有针对性和校准的纠正噪声进行修正。我们广泛的实证结果表明，TrueBiometric 以100%的准确率检测和纠正中毒图像，同时不损害干净图像的准确性。与现有最先进的方法相比，TrueBiometric 为缓解人脸识别系统中的后门攻击提供了一种更实用、准确和有效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [542] [Physical Adversarial Camouflage through Gradient Calibration and Regularization](https://arxiv.org/abs/2508.05414)
> *基于梯度校准与正则化的物理对抗性伪装*

*Jiawei Liang, Siyuan Liang, Jianjie Huang, Chenxi Si, Ming Zhang, Xiaochun Cao* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 物理对抗性伪装, 梯度优化, 目标检测器, 攻击成功率, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种新的物理对抗性伪装方法，通过解决梯度采样不一致和更新冲突问题，显著提高了攻击成功率。

**AI_Comments:** 本文的创新之处在于通过新颖的梯度优化技术解决了物理对抗性攻击中的具体挑战（梯度不一致性、多角度冲突）。这项工作对于理解和减轻安全关键AI系统中的漏洞具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度目标检测器对物理对抗性伪装的脆弱性对自动驾驶等安全关键领域构成重大安全风险。现有技术在可变物理环境下存在两个主要挑战：1) 距离上采样点密度不一致阻碍了梯度优化确保局部连续性；2) 多角度更新纹理梯度导致冲突，降低了优化稳定性和攻击有效性。

**Method:** 提出了一种基于梯度优化的新型对抗性伪装框架。首先，引入了梯度校准策略，通过将梯度从稀疏采样点传播到未采样纹理点，确保了跨距离的梯度更新一致性。其次，开发了一种梯度去相关方法，根据损失值优先处理和正交化梯度，通过消除冗余或冲突的更新，增强了多角度优化中的稳定性和有效性。

**Result:** 在各种检测模型、角度和距离上的大量实验结果表明，该方法显著优于现有技术，攻击成功率（ASR）在跨距离上平均提高了13.46%，在跨角度上平均提高了11.03%。此外，在实际场景中的经验评估强调了对更鲁棒系统设计的需求。

**Conclusion:** 本文提出的方法显著提高了物理对抗性伪装攻击的有效性，并强调了针对此类威胁设计更鲁棒系统的重要性。

> **ai_Abstract:** 本文针对深度目标检测器在可变环境下对抗性伪装的挑战，提出了一种新颖的基于梯度优化的框架。该框架包含梯度校准策略，确保跨距离的梯度更新一致性；以及梯度去相关方法，稳定多角度优化。实验结果显示，该方法显著提高了攻击成功率，强调了当前检测模型的脆弱性及对更鲁棒系统设计的需求。

> **摘要翻译:** 深度目标检测器的进步极大地影响了自动驾驶等安全关键领域。然而，物理对抗性伪装通过改变物体纹理来欺骗检测器，构成了重大的安全风险。现有技术在可变物理环境下难以应对，面临两个主要挑战：1) 距离上采样点密度不一致阻碍了梯度优化确保局部连续性；2) 多角度更新纹理梯度导致冲突，降低了优化稳定性和攻击有效性。为了解决这些问题，我们提出了一种基于梯度优化的新型对抗性伪装框架。首先，我们引入了梯度校准策略，通过将梯度从稀疏采样点传播到未采样纹理点，确保了跨距离的梯度更新一致性。此外，我们开发了一种梯度去相关方法，根据损失值优先处理和正交化梯度，通过消除冗余或冲突的更新，增强了多角度优化中的稳定性和有效性。在各种检测模型、角度和距离上的大量实验结果表明，我们的方法显著优于现有技术，攻击成功率（ASR）在跨距离上平均提高了13.46%，在跨角度上平均提高了11.03%。此外，在实际场景中的经验评估强调了对更鲁棒系统设计的需求。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [547] [Smoothing Slot Attention Iterations and Recurrences](https://arxiv.org/abs/2508.05417)
> *平滑槽位注意力迭代与循环*

*Rongzhen Zhao, Wenyan Yang, Juho Kannala, Joni Pajarinen* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** Slot Attention, 对象中心化学习, 平滑迭代, 循环, 视频处理

**Comment:** 

> **TL;DR:** SmoothSA通过预热冷启动查询和区分迭代变换来解决Slot Attention在图像和视频处理中的迭代和循环平滑问题，提高了对象中心化学习的性能。

**AI_Comments:** SmoothSA的关键创新在于识别并解决了Slot Attention在处理图像和视频时迭代和循环机制中的两个核心平滑问题。通过引入“预热”冷启动查询和“区分”不同帧的变换，它提高了对象中心化学习的精度和效率，特别是在处理视频序列时。这项工作为提升基于注意力机制的对象中心化表示学习提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** Slot Attention (SA) 及其变体在对象中心化学习（OCL）中存在问题：冷启动查询缺乏样本特定线索，导致图像或视频首帧的精确聚合受阻；非首帧的查询已具有样本特异性，但与首帧使用同质变换，导致聚合不当。

**Method:** 本文提出了SmoothSA方法来解决上述问题：1) 通过一个在OCL内部自蒸馏的小模块，用丰富的输入特征信息“预热”冷启动查询，以平滑图像或视频首帧的SA迭代。2) 通过分别使用完整和单次迭代，区分首帧和非首帧的同质变换，以平滑所有视频帧上的SA循环。

**Result:** 在对象发现、识别和下游基准测试上的综合实验验证了我们方法的有效性。进一步的分析直观地阐明了我们的方法如何平滑SA迭代和循环。

**Conclusion:** SmoothSA通过改进Slot Attention的迭代和循环机制，显著提升了对象中心化学习在图像和视频处理中的性能。

> **ai_Abstract:** 本文提出了SmoothSA，旨在解决主流对象中心化学习中Slot Attention（SA）的迭代和循环平滑问题。现有SA在图像或视频首帧上冷启动查询时缺乏样本特定线索，且视频非首帧与首帧使用同质变换导致聚合不精确。SmoothSA通过“预热”冷启动查询来增强首帧的迭代，并通过区分首帧和非首帧的变换来平滑视频帧间的循环。实验证明，该方法在对象发现、识别等任务上有效提升了性能。

> **摘要翻译:** 槽位注意力（SA）及其变体是主流对象中心化学习（OCL）的核心。图像中的对象可以通过在图像特征上通过SA迭代地（通常三次）细化冷启动查询向量，聚合成各自的槽位向量。对于视频，这种聚合在帧之间循环共享，其中查询在第一帧上冷启动，而在非第一帧上从前一帧的槽位转换而来。然而，冷启动查询缺乏样本特定线索，从而阻碍了图像或视频第一帧的精确聚合；此外，非第一帧的查询已经是样本特定的，因此需要与第一帧聚合不同的变换。我们首次通过我们的SmoothSA解决了这些问题：(1) 为了平滑图像或视频第一帧上的SA迭代，我们通过一个在OCL内部自蒸馏的微小模块，用丰富的输入特征信息“预热”冷启动查询；(2) 为了平滑所有视频帧上的SA循环，我们通过分别使用完整和单次迭代来区分第一帧和非第一帧的同质变换。在对象发现、识别和下游基准测试上的综合实验验证了我们方法的有效性。进一步的分析直观地阐明了我们的方法如何平滑SA迭代和循环。我们的代码可在补充材料中获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [554] [How and Why: Taming Flow Matching for Unsupervised Anomaly Detection and Localization](https://arxiv.org/abs/2508.05461)
> *如何与为何：驯服流匹配用于无监督异常检测与定位*

*Liangwei Li, Lin Liu, Juanxiu Liu, Jing Zhang, Ruqian Hao, Xiaohui Du* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 流匹配, 异常检测, 定位, 无监督学习, 最差传输

**Comment:** 

> **TL;DR:** 本文提出了一种基于时间反向流匹配（rFM）和最差传输（WT）位移插值的新型无监督异常检测与定位范式，解决了传统流模型表达能力有限的问题，并在MVTec数据集上实现了最先进的性能。

**AI_Comments:** 该论文创新性地将流匹配（FM）应用于无监督异常检测领域，解决了传统流模型在表达能力上的固有缺陷。通过引入时间反向流匹配（rFM）和最差传输（WT）位移插值，作者构建了一个理论上严谨且计算高效的异常分离机制。特别值得注意的是，WT-Flow通过创建“退化势阱”来约束正常样本，同时允许异常样本逃逸，这种机制设计巧妙。在MVTec数据集上取得的最先进性能证明了该方法的有效性和潜力。该工作为流基模型在异常检测中的应用开辟了新方向，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决传统流模型在无监督异常检测和定位中存在的模型表达能力限制。

**Method:** 本文提出了时间反向流匹配（rFM）的概念，将其形式化为沿预定义概率路径的向量场回归，以将未知数据分布转换为标准高斯分布。通过核心观察，指出线性插值概率路径的FM本质上不可逆，且在高维空间中使用反向高斯概率路径可能导致平凡向量场。基于此，提出了最差传输（WT）位移插值来重建非概率演化路径，从而形成WT-Flow。WT-Flow增强了样本轨迹的动态控制，为无异常样本构建“退化势阱”，同时允许异常样本逃逸。

**Result:** 首次成功将流匹配（FM）应用于无监督异常检测任务，并在MVTec数据集上实现了单尺度下的最先进性能。

**Conclusion:** 本文提出的基于流匹配的无监督异常检测范式提供了一种理论上扎实的异常样本分离机制，计算效率高，能够扩展到复杂数据，并在实际应用中取得了优异表现。

> **ai_Abstract:** 本文提出了一种利用流匹配（FM）进行无监督异常检测和定位的新范式，旨在解决传统流模型表达能力的局限性。研究者形式化了时间反向流匹配（rFM）的概念，并揭示了FM在特定概率路径下的非可逆性和高维空间中的潜在问题。为克服这些问题，论文引入了最差传输（WT）位移插值来构建非概率演化路径，形成了WT-Flow，该方法能有效区分正常和异常样本。该范式首次成功应用于无监督异常检测任务，并在MVTec数据集上取得了最先进的性能。

> **摘要翻译:** 我们提出了一种使用流匹配（FM）进行无监督异常检测和定位的新范式，它从根本上解决了传统基于流的方法的模型表达能力限制。为此，我们将时间反向流匹配（rFM）的概念形式化为沿预定义概率路径的向量场回归，以将未知数据分布转换为标准高斯分布。我们提出了两个重塑我们对FM理解的核心观察。首先，我们严格证明了线性插值概率路径的FM本质上是不可逆的。其次，我们的分析表明，在高维空间中采用反向高斯概率路径可能导致平凡向量场。这个问题是由于流形相关的约束引起的。基于第二个观察，我们提出了最差传输（WT）位移插值来重建非概率演化路径。所提出的WT-Flow增强了样本轨迹的动态控制，为无异常样本构建“退化势阱”，同时允许异常样本逃逸。这种新颖的无监督范式为异常样本提供了一种理论上扎实的分离机制。值得注意的是，FM提供了一个计算上可处理的框架，可以扩展到复杂数据。我们首次成功将FM应用于无监督异常检测任务，在MVTec数据集上实现了单尺度的最先进性能。用于训练的可复现代码将在最终提交时发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [560] [F2PASeg: Feature Fusion for Pituitary Anatomy Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2508.05465)
> *F2PASeg：内窥镜手术中垂体解剖结构分割的特征融合方法*

*Lumin Chen, Zhiying Wu, Tianye Lei, Xuexue Bai, Ming Feng, Yuxi Wang, Gaofeng Meng, Zhen Lei, Hongbin Liu* | **Category: cs.CV, eess.IV, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 垂体解剖分割, 特征融合, 内窥镜手术, 实时分割, 数据集

**Comment:** 

> **TL;DR:** F2PASeg利用特征融合在内窥镜垂体手术中实时准确分割解剖结构，并提出了新的PAS数据集。

**AI_Comments:** 这篇论文的创新点在于提出了F2PASeg模型及其特征融合策略，有效应对了内窥镜手术中复杂多变的术中图像特征不一致问题。同时，其构建的PAS数据集对于弥补该领域高质量标注数据稀缺的现状具有重要意义，对后续研究有积极推动作用。模型实时分割的能力也显示了其在实际临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 垂体肿瘤手术中，精确的解剖结构分割能为外科医生提供早期风险区域预警，从而提高手术安全性。然而，缺乏像素级标注的垂体手术视频流数据集，且术中遮挡、相机运动和出血导致特征表示不一致，是实现这一目标的主要挑战。

**Method:** 为解决数据稀缺问题，本研究引入了一个新的垂体解剖结构分割（PAS）数据集，包含从120个视频中提取的7,845张时间连贯图像，并通过模拟手术器械的数据增强技术来缓解类别不平衡。针对术中特征表示不一致问题，提出了F2PASeg模型，该模型通过整合特征融合模块，利用高分辨率图像特征和深度语义嵌入来优化解剖结构分割，增强对术中变化的鲁棒性。

**Result:** 实验结果表明，F2PASeg能够实时且一致地分割关键解剖结构。

**Conclusion:** F2PASeg为术中垂体手术规划提供了一个可靠的解决方案。

> **ai_Abstract:** 该研究针对内窥镜垂体手术中解剖结构分割的挑战，提出了一种名为F2PASeg的特征融合模型。为了解决数据稀缺问题，研究构建了一个包含7,845张图像的新型垂体解剖结构分割(PAS)数据集，并采用数据增强技术。F2PASeg通过结合高分辨率图像特征和深度语义嵌入，增强了模型对术中变化（如遮挡、相机运动、出血）的鲁棒性。实验证明，F2PASeg能够实时且一致地分割关键解剖结构，为术中手术规划提供了可靠支持。

> **摘要翻译:** 垂体肿瘤常导致邻近重要结构变形或包绕。解剖结构分割可以为外科医生提供手术风险区域的早期预警，从而提高垂体手术的安全性。然而，用于垂体手术的像素级标注视频流数据集极其稀少。为了解决这一挑战，我们引入了一个新的垂体解剖结构分割（PAS）数据集。PAS包含从120个视频中提取的7,845张时间连贯图像。为了缓解类别不平衡，我们应用了数据增强技术，模拟训练数据中手术器械的存在。垂体解剖结构分割的一个主要挑战是由于遮挡、相机运动和手术出血导致的特征表示不一致。通过整合特征融合模块，我们提出了F2PASeg，旨在通过利用高分辨率图像特征和深度语义嵌入来优化解剖结构分割，增强对术中变化的鲁棒性。实验结果表明，F2PASeg能够实时一致地分割关键解剖结构，为术中垂体手术规划提供了可靠的解决方案。代码：https://github.com/paulili08/F2PASeg.

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [566] [Keep It Real: Challenges in Attacking Compression-Based Adversarial Purification](https://arxiv.org/abs/2508.05489)
> *保持真实：攻击基于压缩的对抗性净化中的挑战*

*Samuel Räber, Till Aczel, Andreas Plesner, Roger Wattenhofer* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 对抗性净化, 图像压缩, 对抗性攻击, 真实感, 鲁棒性

**Comment:** 

> **TL;DR:** 攻击基于压缩的对抗性净化很难，因为图像的真实感越高，攻击就越困难，这并非梯度掩蔽，而是真实重建的固有鲁棒性。

**AI_Comments:** 这项工作揭示了基于压缩的对抗性防御的一个重要特性，即图像重建的真实性是其鲁棒性的关键。它驳斥了梯度掩蔽的解释，并提出了“固有鲁棒性”的新视角，这对于理解和开发更强大的对抗性防御具有重要意义。同时，它也为未来攻击者指明了方向：如何有效降低重建图像的真实感。

<details>
  <summary>Details</summary>

**Motivation:** 先前研究提出有损压缩可以防御对抗性扰动，但缺乏全面的攻击评估。本文旨在构建强大的攻击来评估这种防御的有效性。

**Method:** 构建了针对各种压缩模型的强大白盒和自适应攻击，并通过跨多个攻击场景的严格评估来测试它们。分析了攻击难度与图像真实感之间的关系。

**Result:** 能够产生真实、高保真重建的压缩模型对攻击具有显著更强的抵抗力。相反，低真实感压缩模型可以被攻破。这种鲁棒性并非由于梯度掩蔽，而是因为真实重建保持了与自然图像的分布对齐。

**Conclusion:** 图像重建的真实感是未来对抗性攻击的一个重大障碍，开发克服真实感的有效技术对于全面的安全评估至关重要。

> **ai_Abstract:** 本文研究了攻击基于压缩的对抗性净化的挑战。研究者构建了针对多种压缩模型的强大白盒和自适应攻击，发现图像重建的真实感是攻击成功的关键障碍。高真实感、高保真的压缩模型对攻击表现出更强的抵抗力，而低真实感模型则容易被攻破。这种鲁棒性并非源于梯度掩蔽，而是由于真实重建保持了与自然图像的分布对齐。研究强调，克服图像真实感是未来对抗性攻击和安全评估中的重要挑战。

> **摘要翻译:** 先前的工作表明，通过有损压缩预处理图像可以防御对抗性扰动，但缺乏全面的攻击评估。在本文中，我们针对各种压缩模型构建了强大的白盒和自适应攻击，并识别出攻击者面临的一个关键挑战：重建图像中的高真实感显著增加了攻击难度。通过跨多个攻击场景的严格评估，我们证明了能够产生真实、高保真重建的压缩模型对我们的攻击具有显著更强的抵抗力。相反，低真实感压缩模型可以被攻破。我们的分析表明，这并非由于梯度掩蔽。相反，保持与自然图像分布对齐的真实重建似乎提供了固有的鲁棒性。这项工作突出了未来对抗性攻击的一个重大障碍，并表明开发更有效的技术来克服真实感代表了全面安全评估的一个基本挑战。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [572] [SMOL-MapSeg: Show Me One Label](https://arxiv.org/abs/2508.05501)
> *SMOL-MapSeg: 给我一个标签*

*Yunshuang Yuan, Frank Thiemann, Thorsten Dahms, Monika Sester* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 历史地图, 语义分割, 基础模型, 按需声明式提示, SMOL-MapSeg

**Comment:** 

> **TL;DR:** SMOL-MapSeg通过按需声明式知识提示，使基础模型能够准确地对历史地图进行语义分割，并能适应新的类别。

**AI_Comments:** 本文提出的OND知识提示机制是其主要创新点，它有效地解决了基础模型在处理缺乏一致性数据的历史地图时的局限性，使得模型能够根据用户的具体需求进行灵活的语义分割，具有较高的实用价值和泛化潜力。

<details>
  <summary>Details</summary>

**Motivation:** 历史地图对于研究地球表面变化很有价值，但现有的深度学习模型（如UNet）和预训练的基础模型在处理历史地图时表现不佳。基础模型在现代或特定领域图像上训练，而历史地图缺乏一致性，导致相似概念可能以不同形状和风格出现，现有模型难以处理。

**Method:** 我们提出了“按需声明式 (On-Need Declarative, OND)”知识提示机制，通过引入明确的提示来指导模型识别特定模式与概念的对应关系。该机制允许用户在推理时指定目标概念和模式。具体实现上，我们用OND提示机制替换了基础模型SAM的提示编码器，并在历史地图上对其进行了微调，得到了SMOL-MapSeg模型。

**Result:** SMOL-MapSeg能够准确地分割由OND知识定义的类别。它还可以通过少量样本微调来适应未见过的类别。此外，它在平均分割性能上优于基于UNet的基线模型。

**Conclusion:** SMOL-MapSeg通过引入按需声明式知识提示，有效解决了基础模型在历史地图语义分割中的挑战，并展现出良好的准确性和泛化能力。

> **ai_Abstract:** 本文提出SMOL-MapSeg模型，旨在解决现有深度学习和基础模型在历史地图语义分割上的不足。针对历史地图中概念与模式不一致的问题，引入了“按需声明式（OND）”知识提示机制，通过显式提示指导模型识别模式与概念的对应关系。该模型通过替换基础模型SAM的提示编码器并在历史地图上微调实现。实验证明，SMOL-MapSeg能准确分割定义类别，并通过少量样本微调适应新类别，且性能优于UNet基线。

> **摘要翻译:** 历史地图对于研究地球表面变化具有宝贵的价值。随着深度学习的兴起，UNet等模型已被用于通过语义分割从这些地图中提取信息。最近，预训练的基础模型在自动驾驶、医学成像和工业检测等领域展现出强大的性能。然而，它们在历史地图方面却表现不佳。这些模型是在现代或特定领域图像上训练的，其中模式可以通过常识或专业知识与预定义的慨念联系起来。历史地图缺乏这种一致性——相似的慨念可以以截然不同的形状和风格出现。为了解决这个问题，我们提出了按需声明式（OND）知识提示，它引入了明确的提示来指导模型哪些模式对应哪些慨念。这允许用户在推理期间（按需推理）指定目标慨念和模式。我们通过用我们的OND提示机制替换基础模型SAM的提示编码器并对其在历史地图上进行微调来实现这一点。由此产生的模型称为SMOL-MapSeg（Show Me One Label）。实验表明，SMOL-MapSeg可以准确地分割由OND知识定义的类别。它还可以通过少量样本微调来适应未见过的类别。此外，它在平均分割性能上优于基于UNet的基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [578] [AutoIAD: Manager-Driven Multi-Agent Collaboration for Automated Industrial Anomaly Detection](https://arxiv.org/abs/2508.05503)
> *AutoIAD：经理驱动的多智能体协作自动化工业异常检测*

*Dongwei Ji, Bingzhang Hu, Yi Zhou* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 工业异常检测, 多智能体系统, 自动化, 经理驱动, 视觉检测

**Comment:** 

> **TL;DR:** AutoIAD是一个经理驱动的多智能体协作框架，用于自动化工业视觉异常检测，显著优于现有框架。

**AI_Comments:** AutoIAD的创新点在于其经理驱动的多智能体协作架构和领域特定知识库的集成，实现了工业异常检测的自动化和端到端开发。这显著减少了人工投入，提高了效率和模型性能，并通过迭代优化缓解了AI模型常见的幻觉问题，为工业自动化领域提供了高质量的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 传统的工业异常检测（IAD）需要大量人工，且难以适应各种应用场景，这阻碍了制造质量控制的自动化。

**Method:** AutoIAD是一个多智能体协作框架，采用经理驱动的中心智能体来协调专业子智能体（数据准备、数据加载、模型设计器、训练器），并集成领域特定知识库，以端到端自动化处理原始工业图像数据，开发训练好的异常检测模型。

**Result:** 在MVTec AD数据集上的广泛实验表明，AutoIAD在任务完成率和模型性能（AUROC）方面显著优于现有通用智能体协作框架和传统AutoML框架，并通过迭代优化有效缓解了幻觉问题。消融研究证实了经理中心智能体和领域知识库模块在生成鲁棒、高质量IAD解决方案中的关键作用。

**Conclusion:** AutoIAD通过其经理驱动的多智能体协作架构和领域知识库，能够自动化并提供鲁棒且高质量的工业异常检测解决方案。

> **ai_Abstract:** 本文提出了AutoIAD，一个经理驱动的多智能体协作框架，旨在实现工业视觉异常检测的端到端自动化开发。该框架通过中心经理智能体协调数据准备、加载、模型设计和训练等子智能体，并结合领域知识库，自动化地从原始图像数据生成异常检测模型。实验证明，AutoIAD在性能和任务完成率上超越了现有框架，并有效解决了幻觉问题，其经理智能体和知识库的作用至关重要。

> **摘要翻译:** 工业异常检测（IAD）对于制造质量控制至关重要，但传统上需要针对各种应用场景投入大量人工。本文介绍了AutoIAD，一个多智能体协作框架，专门为工业视觉异常检测的端到端自动化开发而设计。AutoIAD利用经理驱动的中心智能体来协调专业的子智能体（包括数据准备、数据加载、模型设计器、训练器），并集成了一个领域特定知识库，该知识库能够智能地处理整个流程，利用原始工业图像数据开发训练好的异常检测模型。我们使用MVTec AD数据集构建了一个全面的基准，以评估AutoIAD在各种LLM后端上的表现。大量实验表明，AutoIAD在任务完成率和模型性能（AUROC）方面显著优于现有通用智能体协作框架和传统AutoML框架，同时通过迭代优化有效缓解了幻觉等问题。消融研究进一步证实了经理中心智能体和领域知识库模块在生成鲁棒、高质量IAD解决方案中的关键作用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [584] [Symmetry Understanding of 3D Shapes via Chirality Disentanglement](https://arxiv.org/abs/2508.05505)
> *三维形状的对称性理解：通过手性解耦*

*Weikang Wang, Tobias Weißberg, Nafie El Amrani, Florian Bernard* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 手性解耦, 三维形状分析, 无监督学习, 特征提取, Diff3F

**Comment:** 

> **TL;DR:** 本文提出了一种无监督手性特征提取方法，用于为三维形状顶点添加手性感知信息，从而有效解决三维形状分析中左右对称部分难以区分的问题。

**AI_Comments:** 这篇论文解决了三维形状分析中一个关键但被忽视的问题：手性理解。通过引入无监督的手性特征提取器，并利用2D基础模型的能力，它提供了一种新颖且实用的方法来增强三维形状描述符，使其能够区分左右对称部分，这对于许多计算机视觉和图形学任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 手性信息在计算机视觉中普遍存在，但在三维形状分析（如点云和网格）中的探索不足。现有形状顶点描述符无法区分左右对称部分，因此迫切需要开发一种手性特征提取器。

**Method:** 基于Diff3F框架，提出了一种无监督的手性特征提取流程，从2D基础模型中提取手性感知信息来装饰形状顶点。通过在不同数据集上进行定量和定性实验来评估提取的手性特征。

**Result:** 在左右解耦、形状匹配和部件分割等下游任务中的结果表明，所提取的手性特征具有有效性和实用性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种新颖的无监督手性特征提取方法，旨在解决三维形状分析中现有描述符无法区分左右对称部分的挑战。该方法基于Diff3F框架，从2D基础模型中提取手性感知信息并应用于三维形状顶点。实验结果表明，所提取的手性特征在左右解耦、形状匹配和部件分割等下游任务中表现出显著的有效性和实用性。

> **摘要翻译:** 手性信息（即允许区分左右的信息）在计算机视觉的各种数据模式中普遍存在，包括图像、视频、点云和网格。虽然手性在图像领域得到了广泛研究，但其在形状分析（如点云和网格）中的探索仍不充分。尽管许多形状顶点描述符已显示出吸引人的特性（例如对刚体变换的鲁棒性），但它们通常无法区分左右对称部分。考虑到手性信息在不同形状分析问题中的普遍性以及当前形状描述符中缺乏手性感知特征，开发手性特征提取器变得必要和紧迫。基于最近的Diff3F框架，我们提出了一种无监督手性特征提取流程，用于用从2D基础模型中提取的手性感知信息来装饰形状顶点。我们通过在不同数据集上的定量和定性实验评估了提取的手性特征。左右解耦、形状匹配和部件分割等下游任务的结果证明了它们的有效性和实用性。项目页面：https://wei-kang-wang.github.io/chirality/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [590] [MagicHOI: Leveraging 3D Priors for Accurate Hand-object Reconstruction from Short Monocular Video Clips](https://arxiv.org/abs/2508.05506)
> *MagicHOI：利用3D先验从短单目视频片段中准确重建手物交互*

*Shibo Wang, Haonan He, Maria Parelli, Christoph Gebhardt, Zicong Fan, Jie Song* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 手物重建, 3D先验, 单目视频, 新颖视图合成, 扩散模型

**Comment:** 

> **TL;DR:** MagicHOI是一种从单目视频中重建手物交互的方法，通过利用新颖视图合成扩散模型的3D先验来解决物体不可见区域的问题，性能优于现有SOTA方法。

**AI_Comments:** 本文提出了一种创新方法，通过利用大规模新颖视图合成扩散模型作为3D先验，解决了手物重建中物体不可见区域的挑战性问题。这对于在实际场景中难以保证物体完全可见的情况尤为重要。将扩散模型集成到重建框架中进行正则化是一个新颖的贡献，有助于生成更合理和准确的重建结果，推动了该领域的最新进展。

<details>
  <summary>Details</summary>

**Motivation:** 大多数基于RGB的手物重建方法依赖于物体模板，而无模板方法通常假设物体完全可见。但在实际场景中，固定摄像机视角和静态抓取会导致部分物体不可见，从而产生不合理的重建结果。

**Method:** 本文提出了MagicHOI，一种即使在有限视角变化下也能从短单目交互视频中重建手和物体的方法。核心思想是，尽管3D手物配对数据稀缺，但大规模新颖视图合成扩散模型提供了丰富的物体监督。这种监督作为先验，用于规范手部交互过程中不可见的物体区域。基于此，我们将新颖视图合成模型集成到手物重建框架中，并通过结合可见接触约束来进一步对齐手和物体。

**Result:** MagicHOI显著优于现有的最先进手物重建方法。新颖视图合成扩散先验能有效规范不可见的物体区域，增强3D手物重建。

**Conclusion:** MagicHOI通过利用新颖视图合成扩散先验，有效解决了手物重建中物体不可见区域的问题，显著提高了3D手物重建的准确性。

> **ai_Abstract:** MagicHOI是一种新颖的3D手物重建方法，能够从短单目视频中重建手和物体，解决了物体部分不可见的问题。它利用大规模新颖视图合成扩散模型提供的3D先验来规范这些不可见区域。该方法将新颖视图合成模型集成到重建框架中，并引入可见接触约束以对齐手和物体。实验结果表明，MagicHOI显著优于现有最先进方法，并证明了扩散先验在增强重建质量方面的有效性。

> **摘要翻译:** 大多数基于RGB的手物重建方法依赖于物体模板，而无模板方法通常假设物体完全可见。但在实际场景中，固定摄像机视角和静态抓取会导致部分物体不可见，从而产生不合理的重建结果，这使得上述假设常常失效。为了克服这个问题，我们提出了MagicHOI，一种即使在有限视角变化下也能从短单目交互视频中重建手和物体的方法。我们的关键见解是，尽管3D手物配对数据稀缺，但大规模新颖视图合成扩散模型提供了丰富的物体监督。这种监督作为先验，用于规范手部交互过程中不可见的物体区域。利用这一见解，我们将新颖视图合成模型集成到我们的手物重建框架中。我们通过结合可见接触约束来进一步对齐手和物体。我们的结果表明，MagicHOI显著优于现有的最先进手物重建方法。我们还表明，新颖视图合成扩散先验能有效规范不可见的物体区域，增强3D手物重建。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [596] [Revealing Latent Information: A Physics-inspired Self-supervised Pre-training Framework for Noisy and Sparse Events](https://arxiv.org/abs/2508.05507)
> *揭示潜在信息：一种受物理启发、用于噪声和稀疏事件的自监督预训练框架*

*Lin Zhu, Ruonan Liu, Xiao Wang, Lizhi Wang, Hua Huang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 事件相机, 自监督学习, 预训练, 稀疏数据, 噪声数据

**Comment:** 

> **TL;DR:** 提出一种三阶段自监督预训练框架，用于从稀疏噪声事件数据中提取潜在信息，并在多项下游任务上超越SOTA。

**AI_Comments:** 该研究通过结合物理采样过程和多阶段对比学习，为处理事件相机数据的固有挑战提供了一种新颖的自监督预训练方法。其创新之处在于分阶段地揭示和利用事件数据中的潜在信息，并且在不更新主干的情况下进行特征对比，有效平衡了表示学习和语义判别。该框架在多个下游任务上的SOTA表现证明了其有效性和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机数据稀疏且噪声大，主要反映亮度变化，导致难以有效提取特征。本研究旨在充分揭示事件数据中的潜在信息，如边缘和纹理线索。

**Method:** 提出一个三阶段自监督预训练框架：1) 差分引导掩码建模：受事件物理采样过程启发，重建时间强度差分图以从原始事件数据中提取增强信息。2) 主干固定特征转换：在不更新主干的情况下对比事件和图像特征，以保留从掩码建模中学到的表示并稳定其在对比学习中的效果。3) 聚焦对比学习：更新整个模型，通过关注高价值区域来提高语义判别能力。

**Result:** 实验表明该框架具有鲁棒性，并在物体识别、语义分割和光流估计等各种下游任务上持续优于最先进的方法。

**Conclusion:** 该框架能够有效处理稀疏和噪声事件数据，并提取出有用的潜在信息，从而在多种视觉任务中取得卓越性能。

> **ai_Abstract:** 本文提出一个名为“揭示潜在信息”的自监督预训练框架，旨在解决事件相机数据稀疏和噪声大导致特征提取困难的问题。该框架包含三个阶段：差分引导掩码建模、主干固定特征转换和聚焦对比学习，通过物理启发和多阶段对比学习，有效提取事件数据中的边缘和纹理等潜在信息。实验证明，该方法在多种下游任务上表现出优越的性能和鲁棒性。

> **摘要翻译:** 事件相机，一种新型神经形态视觉传感器，以高时间分辨率和宽动态范围记录数据，为在挑战性场景中实现精确视觉表示提供了新的可能性。然而，事件数据本质上是稀疏且噪声大的，主要反映亮度变化，这使得有效特征提取变得复杂。为了解决这个问题，我们提出了一种自监督预训练框架，以充分揭示事件数据中的潜在信息，包括边缘信息和纹理线索。我们的框架由三个阶段组成：受事件物理采样过程启发的差分引导掩码建模，它重建时间强度差分图以从原始事件数据中提取增强信息。主干固定特征转换，在不更新主干的情况下对比事件和图像特征，以保留从掩码建模中学到的表示并稳定其在对比学习中的效果。聚焦对比学习，更新整个模型，通过关注高价值区域来提高语义判别能力。大量实验表明，我们的框架在各种下游任务（包括物体识别、语义分割和光流估计）上具有鲁棒性，并且持续优于最先进的方法。代码和数据集可在https://github.com/BIT-Vision/EventPretrain 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [602] [Head Anchor Enhanced Detection and Association for Crowded Pedestrian Tracking](https://arxiv.org/abs/2508.05514)
> *基于头部锚点增强检测与关联的拥挤行人跟踪*

*Zewei Wu, César Teixeira, Wei Ke, Zhang Xiong* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 行人跟踪, 遮挡, 头部关键点, 卡尔曼滤波, 多目标跟踪

**Comment:** 

> **TL;DR:** 该论文提出了一种新的行人跟踪框架，通过结合头部关键点检测、增强的检测特征和迭代卡尔曼滤波来解决拥挤场景下的严重遮挡问题。

**AI_Comments:** 该论文的创新点在于结合了多源检测特征（回归和分类分支）、引入了对遮挡不敏感的头部关键点信息，以及改进了运动模型（迭代卡尔曼滤波与3D先验）。这些方法共同提升了在拥挤和高遮挡场景下行人跟踪的鲁棒性，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有行人跟踪方法在拥挤场景中面临严重的遮挡挑战，导致目标特征丢失，难以维持稳定的轨迹，尤其是在全身体边界框特征和线性恒速运动假设下表现不佳。

**Method:** 该方法提出了一个增强的跟踪框架，融合了来自目标检测器回归和分类分支的检测特征，嵌入了空间和位置信息。引入了头部关键点检测模型以应对遮挡。在运动建模方面，提出了迭代卡尔曼滤波方法，并整合了3D先验以更好地完成复杂场景中的运动轨迹。

**Result:** Not mentioned in abstract

**Conclusion:** 通过结合外观和运动建模的这些进步，所提出的方法为拥挤且遮挡普遍的多目标跟踪提供了更鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一种针对拥挤行人跟踪的增强框架，旨在解决严重遮挡问题。该方法通过整合目标检测器中回归和分类分支的丰富特征，并引入头部关键点检测来应对身体遮挡。此外，还提出了迭代卡尔曼滤波与3D先验相结合的运动模型，以提高复杂场景下多目标跟踪的鲁棒性。

> **摘要翻译:** 视觉行人跟踪是一个很有前景的研究领域，在智能监控、行为分析和人机交互等领域有广泛应用。然而，实际应用面临着严重的遮挡挑战。当多个行人互动或重叠时，目标特征的丢失会严重损害跟踪器维持稳定轨迹的能力。传统的跟踪方法通常依赖于从Re-ID模型中提取的全身体边界框特征和线性恒速运动假设，在严重遮挡场景下往往表现不佳。为了解决这些限制，这项工作提出了一个增强的跟踪框架，该框架利用更丰富的特征表示和更鲁棒的运动模型。具体来说，所提出的方法结合了来自目标检测器回归和分类分支的检测特征，将空间和位置信息直接嵌入到特征表示中。为了进一步缓解遮挡挑战，引入了一个头部关键点检测模型，因为头部相比于全身更不容易被遮挡。在运动建模方面，我们提出了一种迭代卡尔曼滤波方法，旨在与现代检测器假设对齐，并整合3D先验以更好地完成复杂场景中的运动轨迹。通过结合外观和运动建模的这些进步，所提出的方法为拥挤且遮挡普遍的多目标跟踪提供了更鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [608] [FS-IQA: Certified Feature Smoothing for Robust Image Quality Assessment](https://arxiv.org/abs/2508.05516)
> *FS-IQA：用于鲁棒图像质量评估的认证特征平滑*

*Ekaterina Shumitskaya, Dmitriy Vatolin, Anastasia Antsiferova* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 图像质量评估, 认证防御, 特征平滑, 随机平滑, 鲁棒性

**Comment:** 

> **TL;DR:** 提出一种新的IQA模型认证防御方法FS-IQA，通过在特征空间而非输入空间应用随机平滑，实现鲁棒性并保持图像质量，且计算效率高。

**AI_Comments:** FS-IQA的创新点在于将随机平滑应用于特征空间而非输入空间，有效解决了传统方法中噪声注入导致图像质量下降的问题。其重要性在于为IQA模型提供了一种高效且有效的认证鲁棒性方法，同时保持了图像的视觉质量，这对于实际应用至关重要。计算效率的显著提升也是一大亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有IQA模型防御方法通过在输入图像中直接注入高斯噪声，通常会降低视觉质量，且可能计算效率不高。

**Method:** 提出FS-IQA，一种基于随机平滑的认证防御方法，其特点是在特征空间而非输入空间应用噪声。通过分析骨干网络雅可比矩阵的最大奇异值，形式化连接特征空间噪声水平与输入空间扰动。该方法支持全参考（FR）和无参考（NR）IQA模型，无需架构修改，且计算高效，每张图像只需一次骨干网络前向传播。

**Result:** 该方法在提供鲁棒性保证的同时保持了图像保真度。与现有方法相比，未认证时推理时间减少99.5%，认证时减少20.6%。在两个基准数据集上，涉及六种FR和NR IQA模型，与五种最先进的认证防御方法比较，结果显示与主观质量分数的相关性一致提高了高达30.9%。

**Conclusion:** FS-IQA是一种新颖、高效且有效的认证防御方法，能显著提高图像质量评估（IQA）模型的鲁棒性和性能，同时保持图像的视觉质量。

> **ai_Abstract:** 本文提出FS-IQA，一种针对图像质量评估（IQA）模型的认证防御方法。该方法通过在特征空间而非输入空间应用随机平滑来增强模型鲁棒性，从而避免了传统方法中因在输入空间注入噪声而导致的图像质量下降。FS-IQA通过分析骨干网络雅可比矩阵的最大奇异值来量化特征空间噪声与输入空间扰动之间的关系。该方法适用于FR和NR IQA模型，无需架构修改，且计算效率高。实验结果表明，FS-IQA在保持图像保真度的同时，显著提高了IQA模型与主观质量分数的相关性，并大幅降低了推理时间。

> **摘要翻译:** 我们提出了一种新颖的图像质量评估（IQA）模型认证防御方法，该方法基于随机平滑，并在特征空间而非输入空间应用噪声。与以往直接在输入图像中注入高斯噪声（通常会降低视觉质量）的方法不同，我们的方法在提供鲁棒性保证的同时保持了图像保真度。为了将特征空间中的噪声水平与相应的输入空间扰动形式化关联起来，我们分析了骨干网络雅可比矩阵的最大奇异值。我们的方法支持全参考（FR）和无参考（NR）IQA模型，无需任何架构修改，适用于各种场景。它还具有计算效率，每张图像只需一次骨干网络前向传播。与以前的方法相比，它在未认证时将推理时间减少了99.5%，在认证时减少了20.6%。我们通过在两个基准数据集上进行的大量实验验证了我们的方法，涉及六种广泛使用的FR和NR IQA模型，并与五种最先进的认证防御方法进行了比较。我们的结果表明，与主观质量分数的相关性一致提高了高达30.9%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [611] [RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation](https://arxiv.org/abs/2508.02903)
> *RDDPM：用于无监督异常分割的鲁棒去噪扩散概率模型*

*Mehrdad Moradi, Kamran Paynabar* | **Category: cs.CV, eess.IV, stat.ML** | **Updated: 2025-08-04**

**Keywords:** 扩散模型, 异常分割, 鲁棒回归, 无监督学习, 受污染数据

**Comment:** 

> **TL;DR:** 提出RDDPM，一个鲁棒的扩散模型，用于在只有混合（正常+异常）数据时进行无监督异常分割，并通过鲁棒回归方法优于现有技术。

**AI_Comments:** 该论文的创新点在于提出了一个鲁棒的扩散模型RDDPM，解决了现有扩散模型在无监督异常分割中对纯净正常数据训练的依赖性，使其在真实世界混合数据场景下更具实用性。通过将最大似然估计重新解释为鲁棒回归问题，为扩散模型提供了一个新颖的理论视角。其在处理带噪声数据方面的鲁棒性是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的扩散模型在训练时通常需要纯正常数据，这限制了它们在实际应用中的普适性，因为实际数据往往是正常和异常混合的。

**Method:** 提出RDDPM，通过将数据最大似然估计视为非线性回归问题，并利用鲁棒回归重新解释去噪扩散概率模型，从而推导出鲁棒版本的扩散模型，适用于仅有受污染（正常和异常混合）无标签数据的情况。

**Result:** RDDPM在仅有受污染数据的情况下，在无监督异常分割任务中优于现有最先进的扩散模型，在MVTec数据集上AUROC提高了高达8.08%，AUPRC提高了10.37%。

**Conclusion:** 提出的RDDPM框架通过引入鲁棒性，有效解决了扩散模型在处理受污染数据时的局限性，并在性能上显著超越了现有方法。

> **ai_Abstract:** 本文提出了一种名为RDDPM的鲁棒去噪扩散概率模型，用于在仅有受污染（正常与异常混合）无标签数据的情况下进行无监督异常分割。该方法通过将数据最大似然估计重新解释为非线性回归问题，并应用鲁棒回归原理，解决了传统扩散模型需要纯净正常数据训练的局限性。实验结果表明，RDDPM在性能上显著优于现有最先进的扩散模型，在MVTec数据集上AUROC和AUPRC均有显著提升。

> **摘要翻译:** 扩散模型最近的进展在无监督异常分割方面取得了显著成功。对于异常分割，这些模型首先在正常数据上进行训练；然后，异常图像被噪声化到中间步骤，并通过反向扩散重建正常图像。与传统的统计方法不同，扩散模型不依赖于数据或目标异常的特定假设，使其适用于不同领域。然而，扩散模型通常假设可以访问正常数据进行训练，这限制了它们在现实环境中的适用性。在本文中，我们针对仅有受污染（即正常和异常混合）的无标签数据可用的场景，提出了新颖的鲁棒去噪扩散扩散模型。通过将数据的最大似然估计视为非线性回归问题，我们通过回归视角重新解释了去噪扩散概率模型。利用鲁棒回归，我们推导出了去噪扩散概率模型的鲁棒版本。我们新颖的框架为构建各种鲁棒扩散模型提供了灵活性。我们的实验表明，当只有受污染数据可用时，我们的方法在无监督异常分割方面优于当前最先进的扩散模型。我们的方法优于现有的基于扩散的方法，在MVTec数据集上AUROC提高了高达8.08%，AUPRC提高了10.37%。实现代码可在以下地址获取：https://github.com/mehrdadmoradi124/RDDPM

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [614] [Leveraging AI to Accelerate Clinical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods](https://arxiv.org/abs/2508.05519)
> *利用人工智能加速临床数据清洗：AI辅助与传统方法的比较研究*

*Matthew Purri, Amit Patel, Erik Deurrell* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 临床数据清洗, 人工智能, 大型语言模型, 药物开发, Octozi

**Comment:** 

> **TL;DR:** AI平台Octozi显著提高了临床数据清洗效率，减少了错误和不必要的查询，加速了药物开发。

**AI_Comments:** 这篇论文通过引入AI辅助平台Octozi，在临床数据清洗这一关键且耗时的环节中取得了显著的效率和准确性提升。其创新之处在于结合了大型语言模型与领域特定启发式方法，并通过实证研究验证了其有效性，特别是在减少错误和虚假阳性查询方面的表现突出。这项工作为AI在安全关键型医疗工作流程中的应用提供了有力的案例，展示了人机协作的变革潜力，对加速药物开发具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 临床试验数据清洗是药物开发中的一个关键瓶颈，手动审查过程难以管理呈指数增长的数据量和复杂性。

**Method:** 本文提出了一个名为Octozi的人工智能辅助平台，该平台结合了大型语言模型和领域特定启发式方法来革新临床数据审查。通过一项有10名经验丰富的临床审阅员参与的对照实验研究，对比了AI辅助方法与传统方法。

**Result:** AI辅助使数据清洗吞吐量提高了6.03倍，同时将清洗错误从54.67%降低到8.48%（6.44倍的改进）。该系统将虚假阳性查询减少了15.48倍。这些改进在不同经验水平的审阅员中保持一致。

**Conclusion:** AI辅助方法可以解决临床试验操作中的根本性低效率问题，可能加速药物开发时间表并降低成本，同时保持法规遵从性。本工作为将AI集成到安全关键型临床工作流程中建立了框架，并展示了人机协作在制药临床试验中的变革潜力。

> **ai_Abstract:** 本文介绍了Octozi，一个结合大型语言模型和领域特定启发式方法的人工智能辅助平台，旨在解决临床试验数据清洗的瓶颈。通过一项有10名经验丰富的临床审阅员参与的对照实验，研究表明Octozi将数据清洗吞吐量提高了6.03倍，错误率从54.67%降至8.48%，并显著减少了虚假阳性查询，证明了AI辅助方法在提高效率和准确性方面的巨大潜力，有望加速药物开发并降低成本。

> **摘要翻译:** 临床试验数据清洗是药物开发中的一个关键瓶颈，人工审查过程难以管理呈指数增长的数据量和复杂性。本文介绍了Octozi，一个人工智能辅助平台，它结合了大型语言模型和领域特定启发式方法来改变临床数据审查。在一项有经验丰富的临床审查员（n=10）参与的对照实验研究中，我们证明了AI辅助将数据清洗吞吐量提高了6.03倍，同时将清洗错误从54.67%降低到8.48%（6.44倍的改进）。关键的是，该系统将误报查询减少了15.48倍，最大限度地减少了不必要的现场负担。这些改进在不同经验水平的审查员中保持一致，表明其广泛适用性。我们的发现表明，AI辅助方法可以解决临床试验操作中的根本性低效率问题，可能加速药物开发时间表并降低成本，同时保持法规遵从性。这项工作为将AI集成到安全关键型临床工作流程中建立了框架，并展示了人机协作在制药临床试验中的变革潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [620] [Optimal Brain Connection: Towards Efficient Structural Pruning](https://arxiv.org/abs/2508.05521)
> *最佳大脑连接：迈向高效结构化剪枝*

*Shaowu Chen, Wei Ma, Binhua Huang, Qingyuan Wang, Guoxin Wang, Weize Sun, Lei Huang, Deepu John* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 结构化剪枝, 神经网络压缩, 雅可比准则, 等效剪枝, 模型性能

**Comment:** 

> **TL;DR:** 提出了一种名为“最佳大脑连接”的结构化剪枝框架，通过雅可比准则评估参数显著性并使用等效剪枝机制在微调时保留原始连接贡献，有效提升了模型压缩性能并减轻了性能下降。

**AI_Comments:** 该论文的创新点在于提出了雅可比准则来更全面地评估参数显著性，考虑了参数间的互连性，这弥补了现有许多一阶方法的不足。同时，等效剪枝机制通过保留原始连接贡献来缓解性能下降，为剪枝后的模型微调提供了新的思路。这对于提高神经网络压缩效率和性能保持具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有结构化剪枝方法常常忽略参数之间的互连性。

**Method:** 提出了“最佳大脑连接”框架，包含两部分：1. 雅可比准则，一种一阶度量，用于评估结构参数的显著性，它明确捕捉了组件内部交互和层间依赖。2. 等效剪枝机制，利用自编码器在微调期间保留所有原始连接（包括已剪枝的）的贡献。

**Result:** 雅可比准则在保持模型性能方面优于几种流行度量。等效剪枝机制有效减轻了微调后的性能下降。

**Conclusion:** 结合雅可比准则和等效剪枝机制的“最佳大脑连接”框架，能够更有效地进行结构化剪枝，在压缩神经网络的同时更好地保持模型性能。

> **ai_Abstract:** 本文提出了一种名为“最佳大脑连接”的结构化剪枝框架，旨在解决现有方法忽略参数互连性的问题。该框架包含两个核心部分：一是雅可比准则，这是一个能捕捉内部交互和层间依赖的一阶参数显著性评估指标；二是等效剪枝机制，它利用自编码器在微调过程中保留原始连接的贡献。实验证明，雅可比准则能更好地保持模型性能，而等效剪枝机制能有效缓解剪枝后的性能下降。

> **摘要翻译:** 结构化剪枝因其在压缩神经网络方面的有效性而被广泛研究。然而，现有方法通常忽略参数之间的互连性。为了解决这一局限性，本文提出了一种名为“最佳大脑连接”（Optimal Brain Connection）的结构化剪枝框架。首先，我们引入了雅可比准则（Jacobian Criterion），这是一个用于评估结构参数显著性的一阶度量。与现有独立评估参数的一阶方法不同，我们的准则明确捕捉了组件内部交互和层间依赖。其次，我们提出了等效剪枝机制（Equivalent Pruning mechanism），该机制利用自编码器在微调期间保留所有原始连接（包括已剪枝的）的贡献。实验结果表明，雅可比准则在保持模型性能方面优于几种流行度量，而等效剪枝机制有效减轻了微调后的性能下降。代码：https://github.com/ShaowuChen/Optimal_Brain_Connection

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [626] [When Deepfake Detection Meets Graph Neural Network:a Unified and Lightweight Learning Framework](https://arxiv.org/abs/2508.05526)
> *当Deepfake检测遇到图神经网络：一个统一的轻量级学习框架*

*Haoyu Liu, Chaoyu Gong, Mengke He, Jiate Li, Kai Han, Siqiang Luo* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** Deepfake检测, 图神经网络, 轻量级, 时空谱, 视频篡改

**Comment:** 

> **TL;DR:** 本文提出了SSTGNN，一个轻量级的时空谱图神经网络框架，用于Deepfake检测。它将视频表示为结构化图，并联合推理时空和谱失真，实现了卓越的性能、强大的鲁棒性，并且参数量远少于现有SOTA模型。

**AI_Comments:** SSTGNN的创新之处在于其将视频Deepfake检测问题转化为图结构分析，并首次统一了空间、时间、谱信息进行联合推理。其轻量化设计（参数量大幅减少）在保证高性能的同时，显著提升了模型在实际应用中的部署潜力，解决了现有Deepfake检测模型普遍存在的资源消耗大和泛化能力不足的痛点。这对于推动Deepfake检测技术走向实用化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式视频模型的普及使得检测AI生成和篡改的视频成为一个紧迫的挑战。现有检测方法通常依赖孤立的时空或谱信息，难以泛化到多样化的操作类型，并且通常需要大型模型才能表现良好。

**Method:** 本文提出了SSTGNN，一个轻量级的时空谱图神经网络（Spatial-Spectral-Temporal Graph Neural Network）框架。它将视频表示为结构化图，能够对空间不一致性、时间伪影和谱失真进行联合推理。SSTGNN将可学习的谱滤波器和时间差分建模融入到基于图的架构中，以更有效地捕获细微的操作痕迹。

**Result:** SSTGNN在各种基准数据集上进行了广泛实验，结果表明其在域内和跨域设置中均取得了卓越的性能，并对未见过的操作表现出强大的鲁棒性。此外，SSTGNN的参数量比现有最先进模型少42.4倍，使其非常轻量级且可扩展，适用于实际部署。

**Conclusion:** SSTGNN作为一个统一且轻量级的图神经网络框架，通过联合分析视频的时空和谱特征，有效解决了Deepfake检测中泛化能力差和模型庞大的问题，为AI生成视频检测提供了高效且实用的解决方案。

> **ai_Abstract:** 本文提出了一种名为SSTGNN的轻量级时空谱图神经网络框架，旨在解决Deepfake视频检测中现有方法泛化能力差和模型庞大问题。SSTGNN通过将视频表示为结构化图，并整合可学习的谱滤波器和时间差分建模，实现了对视频空间、时间及谱失真的联合推理，从而更有效地捕获篡改痕迹。实验证明，SSTGNN在域内和跨域检测中均表现出色，对未知操作具有强大的鲁棒性，并且参数量远低于现有SOTA模型，使其适用于实际部署。

> **摘要翻译:** 生成式视频模型的普及使得检测AI生成和篡改的视频成为一个紧迫的挑战。现有检测方法通常由于依赖孤立的空间、时间或谱信息而无法泛化到多样化的操作类型，并且通常需要大型模型才能表现良好。本文介绍了SSTGNN，一个轻量级的时空谱图神经网络框架，它将视频表示为结构化图，从而能够对空间不一致性、时间伪影和谱失真进行联合推理。SSTGNN将可学习的谱滤波器和时间差分建模融入到基于图的架构中，更有效地捕获细微的操作痕迹。在各种基准数据集上的广泛实验表明，SSTGNN不仅在域内和跨域设置中均取得了卓越的性能，而且对未见过的操作具有强大的鲁棒性。值得注意的是，SSTGNN以比最先进模型少42.4倍的参数量实现了这些结果，使其高度轻量级且可扩展，适用于实际部署。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [632] [AI vs. Human Moderators: A Comparative Evaluation of Multimodal LLMs in Content Moderation for Brand Safety](https://arxiv.org/abs/2508.05527)
> *AI与人类审核员：多模态大型语言模型在品牌安全内容审核中的比较评估*

*Adi Levi, Or Levi, Sardhendu Mishra, Jonathan Morra* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多模态大型语言模型, 内容审核, 品牌安全, 视频内容, 比较评估

**Comment:** 

> **TL;DR:** 鉴于在线视频内容呈指数级增长，人工审核已力不从心。本文评估了多模态大型语言模型（MLLMs）在品牌安全内容审核中的能力，并与专业人工审核员进行了准确性和成本效益比较，同时发布了一个新的多模态多语言数据集。

**AI_Comments:** 本文通过引入一个由专业人士标注的多模态多语言数据集，首次对多模态大型语言模型在品牌安全内容审核中的应用进行了深入评估，具有重要创新性。它不仅验证了MLLMs在该领域的潜力，还通过与人类审核员的比较，揭示了其在准确性和成本效益方面的优势与局限性，为未来负责任的AI内容审核研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在线视频内容量呈指数级增长，导致不安全视频的审核需求已超出人工能力，带来了运营和心理健康挑战。尽管多模态大型语言模型（MLLMs）在视频理解任务中表现出色，但其在需要细致理解视觉和文本线索的多模态内容审核领域的应用仍相对未被充分探索。

**Method:** 本文构建了一个新颖的、由专业审核员细致标注的多模态多语言数据集，用于品牌安全分类。在此基础上，对Gemini、GPT和Llama等多模态大型语言模型在多模态品牌安全方面的能力进行了基准测试，并详细比较了它们与专业人工审核员在准确性和成本效益方面的表现。

**Result:** 研究结果表明，多模态大型语言模型（如Gemini、GPT和Llama）在多模态品牌安全方面表现出有效性。论文评估了它们相对于专业人工审核员的准确性和成本效益，并深入探讨了MLLMs的局限性和失败案例。

**Conclusion:** 多模态大型语言模型在品牌安全内容审核中展现出有效性，但仍存在局限性。通过与人工审核员的比较，揭示了其在准确性和成本效益方面的潜力。本文发布的开放数据集旨在促进未来在该领域负责任的研究。

> **ai_Abstract:** 本研究旨在应对在线视频内容爆炸式增长带来的内容审核挑战，特别是在品牌安全领域，因为人工审核已不堪重负。论文通过构建一个新颖的多模态多语言数据集，对Gemini、GPT和Llama等多模态大型语言模型（MLLMs）进行了基准测试。研究详细比较了这些MLLMs与专业人工审核员在品牌安全分类任务上的准确性和成本效益，并深入分析了MLLMs的局限性和失败案例。本研究还发布了其数据集，以支持未来在内容审核领域的研究。

> **摘要翻译:** 随着在线视频内容的指数级增长，不安全视频的审核需求已超越了人类的能力，带来了运营和心理健康方面的挑战。尽管最近的研究表明多模态大型语言模型（MLLMs）在各种视频理解任务中具有优势，但它们在多模态内容审核（一个需要对视觉和文本线索有细致理解的领域）中的应用仍相对未被充分探索。在这项工作中，我们对MLLMs在品牌安全分类（内容审核中保护广告完整性的关键子集）方面的能力进行了基准测试。为此，我们引入了一个新颖的、多模态、多语言数据集，该数据集由专业审核员根据多种风险类别精心标注。通过详细的比较分析，我们展示了Gemini、GPT和Llama等MLLMs在多模态品牌安全方面的有效性，并评估了它们与专业人工审核员相比的准确性和成本效益。此外，我们深入讨论了MLLMs的局限性和失败案例。我们随论文发布了该数据集，以促进未来在有效和负责任的品牌安全及内容审核方面的研究。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [638] [Looking into the Unknown: Exploring Action Discovery for Segmentation of Known and Unknown Actions](https://arxiv.org/abs/2508.05529)
> *探索未知：探索已知和未知动作分割的动作发现*

*Federico Spurio, Emad Bahrami, Olga Zatsarynna, Yazan Abu Farha, Gianpiero Francesca, Juergen Gall* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 动作发现, 时间动作分割, 部分标注数据, 未知动作, 粒度引导分割

**Comment:** 

> **TL;DR:** 该论文引入了“动作发现”这一新颖的时间动作分割设置，旨在解决部分标注数据集中模糊动作和不完整标注的挑战。它提出了一种两步法：首先是粒度引导分割模块（GGSM），用于识别已知和未知动作的时间间隔；其次是未知动作段分配（UASA），用于识别未知动作中的语义有意义类别。实验证明该方法显著优于现有基线。

**AI_Comments:** 该论文引入了一个新颖且极具实际意义的问题设定——“动作发现”，这对于处理现实世界中不完整标注的数据集至关重要。其提出的两步法（GGSM和UASA）通过巧妙地利用已知标注来指导未知动作的分割和语义理解，展现了创新性。这项工作有望在神经科学和通用视频分析等标注成本高昂或难以全面标注的领域产生重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 在时间动作分割中，面对部分标注的数据集时，定义和标注模糊动作以及处理不完整的标注是一个挑战。特别是在训练数据中只有部分“已知动作”被标注，而其他“未知动作”未被标注的场景（例如神经科学领域中细微或不常见的动作，或因标签模糊/缺失导致数据集固有的部分标注）。

**Method:** 提出了一种两步法来解决问题：
1.  **粒度引导分割模块（GGSM）**：通过模仿已标注动作的粒度，识别已知和未知动作的时间间隔。
2.  **未知动作段分配（UASA）**：基于学习到的嵌入相似性，识别未知动作中具有语义意义的类别。

**Result:** 该方法在三个具有挑战性的数据集（Breakfast、50Salads和Desktop Assembly）上进行了系统性探索，结果表明它显著优于现有基线方法。

**Conclusion:** 该论文提出的“动作发现”设置及其两步法（GGSM和UASA）能够有效解决部分标注数据下的时间动作分割问题，并显著优于现有基线方法。

> **ai_Abstract:** 本论文提出了“动作发现”这一时间动作分割的新颖设置，旨在解决部分标注数据集中已知和未知动作的分割问题。该设置特别关注训练数据中仅部分动作被标注而未知动作未标注的情况。为应对此挑战，论文提出了一种两步法：首先是粒度引导分割模块（GGSM），用于根据已知动作的粒度识别已知和未知动作的时间间隔；其次是未知动作段分配（UASA），用于基于学习到的嵌入相似性对未知动作进行语义分类。实验结果表明，该方法在Breakfast、50Salads和Desktop Assembly三个数据集上均显著优于现有基线。

> **摘要翻译:** 我们引入了动作发现，这是一种时间动作分割中的新颖设置，解决了部分标注数据集中定义和标注模糊动作以及不完整标注的挑战。在此设置中，训练数据中仅标注了一部分动作（称为已知动作），而其他未知动作则保持未标注。这种场景在神经科学等领域尤其相关，其中明确定义的行为（例如，行走、进食）与经常被忽视的细微或不频繁的动作并存，以及在由于模糊或缺失标签导致数据集本身部分标注的应用中也相关。为了解决这个问题，我们提出了一种两步法，利用已知标注来指导未知动作段的时间和语义粒度。首先，我们引入了粒度引导分割模块（GGSM），通过模仿已标注动作的粒度来识别已知和未知动作的时间间隔。其次，我们提出了未知动作段分配（UASA），它根据学习到的嵌入相似性，识别未知动作中具有语义意义的类别。我们系统地探索了在三个具有挑战性的数据集（Breakfast、50Salads和Desktop Assembly）上提出的动作发现设置，证明我们的方法显著优于现有基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [644] [Follow-Your-Instruction: A Comprehensive MLLM Agent for World Data Synthesis](https://arxiv.org/abs/2508.05580)
> *Follow-Your-Instruction：一个用于世界数据合成的综合MLLM代理*

*Kunyu Feng, Yue Ma, Xinhua Zhang, Boshi Liu, Yikuang Yuluo, Yinhan Zhang, Runtao Liu, Hongyu Liu, Zhiyuan Qin, Shanhui Mo, Qifeng Chen, Zeyu Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 数据合成, MLLM, AIGC, 2D/3D/4D数据, 数据生成

**Comment:** 

> **TL;DR:** 本文提出了Follow-Your-Instruction，一个基于MLLM的框架，用于自动合成高质量的2D、3D和4D数据，以解决AIGC对大规模高质量数据日益增长的需求。

**AI_Comments:** 该论文提出了一种新颖的MLLM驱动框架，用于自动化多维数据合成，解决了传统数据收集的成本和可扩展性问题。其创新点在于结合了MLLM和VLM进行多模态数据处理和场景构建，并生成时间连贯的序列，对于AIGC和下游应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI生成内容（AIGC）需求的增长，对高质量、多样化和可扩展数据的需求变得日益关键。然而，收集大规模真实世界数据成本高昂且耗时，阻碍了下游应用的发展。现有方法依赖手动场景构建，限制了可扩展性和准确性。

**Method:** Follow-Your-Instruction是一个由多模态大语言模型（MLLM）驱动的框架，用于自动合成高质量的2D、3D和4D数据。它首先通过MLLM-Collector利用多模态输入收集资产及其相关描述。然后，它构建3D布局，并通过MLLM-Generator和MLLM-Optimizer分别利用视觉-语言模型（VLM）通过多视角场景进行语义细化。最后，它使用MLLM-Planner生成时间上连贯的未来帧。

**Result:** 通过在2D、3D和4D生成任务上的综合实验，结果表明合成数据显著提升了现有基线模型的性能。

**Conclusion:** Follow-Your-Instruction展示了其作为生成智能的可扩展且有效的数据引擎的潜力，能够自动合成高质量的多维数据。

> **ai_Abstract:** 本文提出了Follow-Your-Instruction，一个创新的多模态大语言模型（MLLM）驱动框架，旨在解决AIGC领域中高质量、多样化和可扩展数据收集的挑战。该框架通过MLLM-Collector收集资产，利用MLLM-Generator和MLLM-Optimizer构建和细化3D布局，并使用MLLM-Planner生成时间连贯的未来帧，从而自动合成高质量的2D、3D和4D数据。实验结果表明，其合成数据能够显著提升现有模型的性能，证明了其作为生成智能高效数据引擎的潜力。

> **摘要翻译:** 随着AI生成内容（AIGC）需求的增长，对高质量、多样化和可扩展数据的需求变得日益关键。然而，收集大规模真实世界数据仍然成本高昂且耗时，阻碍了下游应用的发展。尽管一些工作试图通过渲染过程收集特定任务的数据，但大多数方法仍然依赖于手动场景构建，限制了它们的可扩展性和准确性。为了解决这些挑战，我们提出了Follow-Your-Instruction，一个由多模态大语言模型（MLLM）驱动的框架，用于自动合成高质量的2D、3D和4D数据。我们的Follow-Your-Instruction首先通过使用MLLM-Collector的多模态输入收集资产及其相关描述。然后，它构建3D布局，并分别通过MLLM-Generator和MLLM-Optimizer利用视觉-语言模型（VLM）通过多视角场景进行语义细化。最后，它使用MLLM-Planner生成时间上连贯的未来帧。我们通过在2D、3D和4D生成任务上的综合实验评估了生成数据的质量。结果表明，我们的合成数据显著提升了现有基线模型的性能，展示了Follow-Your-Instruction作为生成智能的可扩展且有效的数据引擎的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [650] [DART: Dual Adaptive Refinement Transfer for Open-Vocabulary Multi-Label Recognition](https://arxiv.org/abs/2508.05585)
> *DART：用于开放词汇多标签识别的双自适应细化迁移*

*Haijing Liu, Tao Pu, Hefeng Wu, Keze Wang, Liang Lin* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 开放词汇多标签识别, 自适应细化, 关系迁移, 弱监督, 大型语言模型

**Comment:** 

> **TL;DR:** DART框架通过双自适应模块，结合弱监督下的类内定位细化和LLM驱动的类间关系迁移，提升了开放词汇多标签识别的性能。

**AI_Comments:** DART的创新之处在于首次将外部LLM派生的结构化关系知识与弱监督下的自适应类内细化相结合，用于开放词汇多标签识别。这种双重自适应策略有效解决了现有VLP模型在细粒度定位和复杂类别依赖建模上的不足，为OV-MLR领域提供了新的SOTA方法。

<details>
  <summary>Details</summary>

**Motivation:** 开放词汇多标签识别（OV-MLR）需要精确的类内定位和有效的类间推理。现有VLP模型在弱监督下的细粒度定位方面表现不佳，并且未能有效利用结构化关系知识，尤其限制了对未见类别的性能。

**Method:** 本文提出了双自适应细化迁移（DART）框架，通过两个协同的自适应模块增强冻结的VLP骨干网络。1. 类内细化：自适应细化模块（ARM）自适应地细化图像块特征，并结合新的弱监督图像块选择（WPS）损失，仅使用图像级标签实现判别性定位。2. 类间迁移：自适应迁移模块（ATM）利用从大型语言模型（LLM）中挖掘的结构化知识构建的类关系图（CRG），并采用图注意力网络自适应地迁移类表示之间的关系信息。

**Result:** DART在具有挑战性的基准测试中取得了新的最先进性能。

**Conclusion:** DART是首个明确集成外部LLM派生关系知识以进行自适应类间迁移，同时在弱监督下执行自适应类内细化的OV-MLR框架，其有效性通过广泛的实验得到验证。

> **ai_Abstract:** 本文提出了DART（Dual Adaptive Refinement Transfer）框架，旨在解决开放词汇多标签识别中VLP模型在弱监督下细粒度定位不足和未能有效利用结构化关系知识的问题。DART通过双重自适应模块实现：自适应细化模块（ARM）结合弱监督图像块选择（WPS）损失进行类内定位细化，而自适应迁移模块（ATM）则利用从LLM构建的类关系图进行类间关系知识的自适应迁移。实验证明DART在OV-MLR任务上达到了最先进的性能。

> **摘要翻译:** 开放词汇多标签识别（OV-MLR）旨在识别图像中的多个已知和未知对象类别，这需要精确的类内定位以精确定位对象，以及有效的类间推理以建模复杂的类别依赖关系。虽然视觉-语言预训练（VLP）模型提供了强大的开放词汇基础，但它们在弱监督下的细粒度定位方面常常遇到困难，并且通常未能明确利用超出基本语义的结构化关系知识，尤其限制了对未见类别的性能。为了克服这些限制，我们提出了双自适应细化迁移（DART）框架。DART通过两个协同的自适应模块增强了冻结的VLP骨干网络。对于类内细化，自适应细化模块（ARM）自适应地细化图像块特征，并结合一种新颖的弱监督图像块选择（WPS）损失，仅使用图像级标签即可实现判别性定位。同时，对于类间迁移，自适应迁移模块（ATM）利用从大型语言模型（LLM）中挖掘的结构化知识构建的类关系图（CRG），并采用图注意力网络自适应地迁移类表示之间的关系信息。据我们所知，DART是第一个明确集成外部LLM派生关系知识以进行自适应类间迁移，同时在弱监督下执行自适应类内细化的OV-MLR框架。在具有挑战性的基准测试上进行的广泛实验表明，我们的DART取得了新的最先进性能，验证了其有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [657] [WeTok: Powerful Discrete Tokenization for High-Fidelity Visual Reconstruction](https://arxiv.org/abs/2508.05599)
> *WeTok：用于高保真视觉重建的强大离散分词器*

*Shaobin Zhuang, Yiwei Guo, Canmiao Fu, Zhipeng Huang, Zeyue Tian, Ying Zhang, Chen Li, Yali Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视觉分词器, 高保真重建, 离散量化, 生成解码

**Comment:** 

> **TL;DR:** WeTok是一种新的视觉分词器，通过组式无查找量化和生成解码实现高保真视觉重建和高压缩比，性能优于现有方法。

**AI_Comments:** WeTok的创新性在于其提出的GQ和GD机制，有效地解决了视觉分词器在压缩比和重建保真度之间的长期矛盾。GQ通过组式处理和无查找量化，显著提升了效率和可扩展性；GD则通过引入生成式建模，使得在高压缩比下也能保持高保真重建。这些改进对于图像生成、压缩等领域具有重要意义，尤其是在资源受限或需要极致压缩的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉分词器在压缩比和重建保真度之间面临不令人满意的权衡，需要填补这一空白。

**Method:** 本文提出了WeTok分词器，包含两项核心创新：1. 组式无查找量化（GQ）：将潜在特征划分为多个组，并对每组执行无查找量化，有效克服内存和计算限制，并实现可扩展码本的重建突破。2. 生成解码（GD）：引入带有额外噪声变量先验的生成解码器，能够概率性地建模以离散token为条件的视觉数据分布，从而重建视觉细节，尤其是在高压缩比下。

**Result:** 在主流基准测试中表现出色。在ImageNet 50k验证集上，WeTok实现了创纪录的低零样本rFID（0.12），优于FLUX-VAE（0.18）和SD-VAE 3.5（0.19）。最高压缩模型在768的压缩比下实现了3.49的零样本rFID，优于Cosmos（384）4.57，后者压缩率仅为WeTok的一半。

**Conclusion:** WeTok通过其创新的组式无查找量化（GQ）和生成解码（GD）机制，显著提升了视觉分词器的性能，在高保真重建和高压缩比方面取得了突破性进展，优于现有领先方法。

> **ai_Abstract:** 本文提出了WeTok，一个用于高保真视觉重建的强大离散分词器。WeTok通过引入组式无查找量化（GQ）和生成解码（GD）两项核心创新，解决了现有视觉分词器在压缩比和重建保真度之间的权衡问题。GQ克服了内存和计算限制，并实现了可扩展码本的重建突破；GD则通过概率建模在离散token条件下重建视觉细节，尤其是在高压缩比下。实验结果表明，WeTok在ImageNet等主流基准测试上取得了优异性能，在零样本rFID和高压缩比下均超越了现有领先方法。

> **摘要翻译:** 视觉分词器是视觉生成中的关键组成部分。然而，现有分词器常常面临压缩比和重建保真度之间不令人满意的权衡。为了填补这一空白，我们引入了一种强大而简洁的WeTok分词器，它通过两项核心创新超越了之前领先的分词器。(1) 组式无查找量化（GQ）。我们将潜在特征划分为多个组，并对每个组执行无查找量化。因此，GQ可以有效地克服先前分词器的内存和计算限制，同时通过更具可扩展性的码本实现重建突破。(2) 生成解码（GD）。与先前分词器不同，我们引入了一种带有额外噪声变量先验的生成解码器。在这种情况下，GD可以概率性地建模以离散token为条件的视觉数据分布，从而使WeTok能够重建视觉细节，尤其是在高压缩比下。在主流基准测试中进行的广泛实验表明，我们的WeTok表现出卓越的性能。在ImageNet 50k验证集上，WeTok实现了创纪录的低零样本rFID（WeTok：0.12 对比 FLUX-VAE：0.18 对比 SD-VAE 3.5：0.19）。此外，我们最高压缩模型在768的压缩比下实现了3.49的零样本rFID，优于Cosmos（384）4.57（后者压缩率仅为我们模型的一半）。代码和模型已提供：https://github.com/zhuangshaobin/WeTok。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [662] [LLaVA-RE: Binary Image-Text Relevancy Evaluation with Multimodal Large Language Model](https://arxiv.org/abs/2508.05602)
> *LLaVA-RE：使用多模态大型语言模型进行二元图像-文本相关性评估*

*Tao Sun, Oliver Liu, JinJin Li, Lan Ma* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 图像-文本相关性评估, 多模态大语言模型, LLaVA, 二元评估, 数据集

**Comment:** 

> **TL;DR:** 本文提出了LLaVA-RE，一个基于多模态大语言模型（MLLM）的二元图像-文本相关性评估框架，并构建了相关数据集，实验证明其有效性。

**AI_Comments:** LLaVA-RE的创新之处在于首次将多模态大语言模型应用于二元图像-文本相关性评估，解决了传统方法在处理复杂文本格式和多样化相关性定义上的挑战。其重要性体现在为多模态生成AI的响应质量评估提供了一个有效且灵活的工具。

<details>
  <summary>Details</summary>

**Motivation:** 多模态生成AI中，图像-文本相关性评估对于衡量响应质量或排序候选响应至关重要。特别是，二元相关性评估（“相关” vs. “不相关”）是一个基本但具有挑战性的问题，因为文本格式多样且相关性定义因场景而异。多模态大型语言模型（MLLM）因其处理复杂文本和额外任务信息的能力，是构建此类评估器的理想选择。

**Method:** 提出了LLaVA-RE，这是首次尝试使用多模态大型语言模型（MLLM）进行二元图像-文本相关性评估。它遵循LLaVA架构，并采用了详细的任务指令和多模态上下文样本。此外，还提出了一个涵盖各种任务的新型二元相关性数据集。

**Result:** 实验结果验证了该框架的有效性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了LLaVA-RE，一个基于多模态大型语言模型（MLLM）的二元图像-文本相关性评估框架，旨在解决多模态生成AI中响应质量评估的挑战。该框架遵循LLaVA架构，并利用详细任务指令和多模态上下文样本。研究还构建了一个涵盖多种任务的新型二元相关性数据集，并通过实验验证了LLaVA-RE的有效性。

> **摘要翻译:** 多模态生成式AI通常涉及根据另一种模态的输入生成图像或文本响应。图像-文本相关性评估对于衡量响应质量或对候选响应进行排序至关重要。特别是，二元相关性评估，即“相关”与“不相关”，是一个基本问题。然而，考虑到文本格式多样且相关性定义在不同场景中有所不同，这是一项具有挑战性的任务。我们发现多模态大型语言模型（MLLM）是构建此类评估器的理想选择，因为它们可以灵活处理复杂的文本格式并接收额外的任务信息。在本文中，我们提出了LLaVA-RE，这是首次尝试使用MLLM进行二元图像-文本相关性评估。它遵循LLaVA架构，并采用了详细的任务指令和多模态上下文样本。此外，我们提出了一个涵盖各种任务的新型二元相关性数据集。实验结果验证了我们框架的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [668] [MOSEv2: A More Challenging Dataset for Video Object Segmentation in Complex Scenes](https://arxiv.org/abs/2508.05630)
> *MOSEv2：一个更具挑战性的复杂场景视频目标分割数据集*

*Henghui Ding, Kaining Ying, Chang Liu, Shuting He, Xudong Jiang, Yu-Gang Jiang, Philip H.S. Torr, Song Bai* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频目标分割, 数据集, 复杂场景, MOSEv2, 真实世界复杂性

**Comment:** 

> **TL;DR:** MOSEv2是一个新的、更具挑战性的视频目标分割数据集，旨在推动VOS方法在真实世界复杂场景中的发展，并揭示了现有方法在此类场景中的不足。

**AI_Comments:** MOSEv2数据集的创新之处在于其对真实世界复杂性的深度模拟，填补了现有VOS数据集的空白。通过引入多样的挑战，如恶劣天气、低光照和非物理目标，它能够更全面地评估和推动VOS方法的进步。其重要性在于，它揭示了当前VOS方法在实际应用中的局限性，为研究人员提供了开发更鲁棒、更具泛化能力模型的宝贵资源。该数据集有望成为未来VOS研究的重要基准。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频目标分割（VOS）数据集（如DAVIS和YouTube-VOS）主要包含突出、主导和孤立的目标，限制了现有最先进方法在真实世界场景中的泛化能力。为了将VOS推向更真实的复杂环境，需要一个更具挑战性的数据集来克服MOSEv1的局限性。

**Method:** 本文提出了MOSEv2数据集，其包含5,024个视频、超过701,976个高质量掩码和10,074个对象（涵盖200个类别）。MOSEv2在MOSEv1的基础上，引入了显著更高的场景复杂度，包括更频繁的目标消失和重新出现、严重的遮挡和拥挤、更小的目标，以及恶劣天气、低光照、多镜头序列、伪装目标、非物理目标（如阴影、反射）和需要外部知识的场景等新挑战。作者还使用MOSEv2基准测试了20种VOS方法和9种视频目标跟踪方法。

**Result:** 在MOSEv2上，20种代表性VOS方法在5种不同设置下均表现出一致的性能下降，例如SAM2从MOSEv1上的76.4%下降到MOSEv2上的50.9%。9种视频目标跟踪方法也发现了类似的性能下降。

**Conclusion:** 这些结果表明，尽管在现有数据集上表现出高精度，但当前的VOS方法在真实世界的复杂性面前仍然面临挑战。MOSEv2数据集的发布将有助于推动VOS方法在实际应用中的进步。

> **ai_Abstract:** 本文介绍了MOSEv2，一个旨在解决现有视频目标分割（VOS）数据集在真实世界复杂场景中泛化能力不足问题的新数据集。MOSEv2在MOSEv1的基础上，显著增加了场景复杂度，包含更多视频、对象和高难度挑战，如遮挡、小目标、恶劣天气和非物理目标。通过对20种VOS方法和9种视频目标跟踪方法进行基准测试，结果显示现有方法在MOSEv2上性能显著下降，凸显了当前VOS技术在处理真实世界复杂性方面的局限性。MOSEv2的发布旨在推动VOS领域向更实际应用场景发展。

> **摘要翻译:** 视频目标分割（VOS）旨在对视频中指定的目标进行分割。尽管最先进的方法在现有基准测试（如DAVIS和YouTube-VOS）上取得了令人印象深刻的性能（例如90%以上的J&F），但这些数据集主要包含突出、主导和孤立的对象，限制了它们在真实世界场景中的泛化能力。为了将VOS推向更真实的复杂环境，引入了复杂视频目标分割（MOSEv1）以促进复杂场景中的VOS研究。在MOSEv1的优点和局限性基础上，我们提出了MOSEv2，一个显著更具挑战性的数据集，旨在进一步推动VOS方法在真实世界条件下的发展。MOSEv2包含5,024个视频，涵盖200个类别的10,074个对象，拥有超过701,976个高质量掩码。与前身相比，MOSEv2引入了显著更高的场景复杂度，包括更频繁的目标消失和重新出现、严重的遮挡和拥挤、更小的目标，以及一系列新的挑战，例如恶劣天气（如雨、雪、雾）、低光照场景（如夜间、水下）、多镜头序列、伪装目标、非物理目标（如阴影、反射）、需要外部知识的场景等。我们对20种代表性VOS方法在5种不同设置下进行了基准测试，并观察到一致的性能下降。例如，SAM2在MOSEv1上的性能从76.4%下降到MOSEv2上的50.9%。我们进一步评估了9种视频目标跟踪方法，并发现了类似的下降，这表明MOSEv2在不同任务中都带来了挑战。这些结果强调，尽管在现有数据集上精度很高，但当前的VOS方法在真实世界的复杂性面前仍然举步维艰。MOSEv2可在https://MOSE.video公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [673] [Hi3DEval: Advancing 3D Generation Evaluation with Hierarchical Validity](https://arxiv.org/abs/2508.05609)
> *Hi3DEval：通过分层有效性推进3D生成评估*

*Yuhan Zhang, Long Zhuo, Ziyang Chu, Tong Wu, Zhibing Li, Liang Pan, Dahua Lin, Ziwei Liu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D生成评估, 分层评估, 材料真实性, Hi3DEval, Hi3DBench

**Comment:** 

> **TL;DR:** Hi3DEval是一个分层3D生成评估框架，结合了对象级和部分级评估，并引入了材料真实性评估。它还构建了Hi3DBench数据集和自动化评分系统，实验证明其优于现有方法并与人类偏好更一致。

**AI_Comments:** 本文的创新点在于提出了一个分层评估框架Hi3DEval，解决了现有3D生成内容评估方法仅限于图像级别和对象级别的问题。通过引入部分级评估和材料真实性评估，极大地提升了评估的全面性和细致性。同时，构建大规模数据集Hi3DBench和3D感知自动化评分系统，为3D评估提供了强大的支持，并展示了超越传统方法的优越性，对3D内容生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D内容生成质量评估方法主要依赖基于图像的指标，且仅限于对象级别，限制了其捕捉空间一致性、材料真实性和高保真局部细节的能力。

**Method:** 引入Hi3DEval，一个分层评估框架，结合对象级和部分级评估，并扩展了纹理评估以评估材料真实性（如反照率、饱和度、金属度）。构建Hi3DBench，一个包含多样化3D资产和高质量标注的大规模数据集，并伴随可靠的多代理标注流程。提出基于混合3D表示的3D感知自动化评分系统，利用基于视频的表示进行对象级和材料主题评估，并使用预训练3D特征进行部分级感知。

**Result:** 实验证明，该方法在建模3D特性方面优于现有基于图像的指标，并实现了与人类偏好的卓越对齐，为手动评估提供了可扩展的替代方案。

**Conclusion:** Hi3DEval框架及其支持的系统和数据集能够更全面、准确地评估3D生成内容的质量，克服了现有方法的局限性，并为自动化和可扩展的3D评估提供了有效途径。

> **ai_Abstract:** 本文介绍了Hi3DEval，一个用于3D生成内容的分层评估框架，旨在解决现有3D评估方法在捕捉空间一致性、材料真实性和局部细节方面的不足。Hi3DEval结合了对象级和部分级评估，并扩展了材料真实性评估。为支持该框架，作者构建了大规模数据集Hi3DBench，并提出了基于混合3D表示的3D感知自动化评分系统。实验结果表明，该方法在3D特性建模上优于基于图像的指标，并与人类偏好高度一致，为3D生成内容的质量评估提供了可扩展且更准确的解决方案。

> **摘要翻译:** 尽管3D内容生成取得了快速进展，但生成3D资产的质量评估仍然具有挑战性。现有方法主要依赖于基于图像的指标，并且仅在对象级别操作，限制了它们捕捉空间一致性、材料真实性和高保真局部细节的能力。1）为了解决这些挑战，我们引入了Hi3DEval，一个专为3D生成内容量身定制的分层评估框架。它结合了对象级和部分级评估，能够实现多维度上的整体评估以及细粒度的质量分析。此外，我们通过明确评估材料真实性（侧重于反照率、饱和度和金属度等属性），将纹理评估扩展到美学外观之外。2）为了支持这个框架，我们构建了Hi3DBench，一个包含多样化3D资产和高质量标注的大规模数据集，并伴随一个可靠的多代理标注流程。我们进一步提出了一种基于混合3D表示的3D感知自动化评分系统。具体来说，我们利用基于视频的表示进行对象级和材料主题评估，以增强时空一致性建模，并采用预训练的3D特征进行部分级感知。广泛的实验表明，我们的方法在建模3D特性方面优于现有基于图像的指标，并实现了与人类偏好的卓越对齐，为手动评估提供了可扩展的替代方案。项目页面可在https://zyh482.github.io/Hi3DEval/查看。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [676] [GAP: Gaussianize Any Point Clouds with Text Guidance](https://arxiv.org/abs/2508.05631)
> *GAP: 文本引导下对任意点云进行高斯化*

*Weiqi Zhang, Junsheng Zhou, Haotian Geng, Wenyuan Zhang, Yu-Shen Liu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 点云高斯化, 3D高斯泼溅, 文本指导, 深度感知扩散, 表面锚定

**Comment:** 

> **TL;DR:** GAP提出了一种新颖的方法，利用文本指导将原始点云高斯化为高保真3D高斯，解决了无色点云直接生成高斯的问题。

**AI_Comments:** GAP的创新点在于首次提出通过文本指导将无色点云直接转换为高保真3D高斯，解决了现有方法仅限于彩色点云的局限。其多视角优化框架结合了深度感知扩散模型、表面锚定和扩散修复策略，为点云到高斯转换提供了一套全面的解决方案，对于3D重建和渲染领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯泼溅（3DGS）在实现快速高质量渲染方面表现出色，而点云作为一种广泛使用的3D表示形式，将点云转换为高斯变得日益重要。现有研究已探索彩色点云转换，但直接从无色3D点云生成高斯仍是一个未解决的挑战。

**Method:** 本文提出了GAP，一种通过文本指导将原始点云高斯化为高保真3D高斯的新方法。其核心思想是设计一个多视角优化框架，利用深度感知图像扩散模型合成不同视角的连贯外观。为确保几何精度，引入了表面锚定机制，在优化过程中有效约束高斯位于3D形状表面。此外，GAP还结合了基于扩散的修复策略，专门用于补全难以观察的区域。

**Result:** GAP在不同复杂程度的点云到高斯生成任务上进行了评估，包括合成点云、具有挑战性的真实世界扫描以及大规模场景。

**Conclusion:** 该论文提出了GAP，一个通过文本指导将原始点云转换为高保真3D高斯的新颖框架，通过多视角优化、表面锚定和区域修复机制有效解决了从无色点云直接生成高斯的问题，并在多种场景下进行了验证。

> **ai_Abstract:** 本文提出GAP，一种新颖的方法，通过文本指导将原始无色点云转换为高保真3D高斯，以弥补点云与3D高斯泼溅之间的空白。该方法包含一个多视角优化框架，利用深度感知图像扩散模型生成一致外观，并通过表面锚定机制确保几何精度，同时采用扩散修复策略处理难观察区域。GAP在合成和真实世界点云数据集上均表现出有效性。

> **摘要翻译:** 3D高斯泼溅（3DGS）在实现快速高质量渲染方面展现了其优势。由于点云作为一种广泛使用且易于获取的3D表示形式，弥合点云与高斯之间的鸿沟变得日益重要。最近的研究已经探索了如何将彩色点转换为高斯，但直接从无色3D点云生成高斯仍然是一个未解决的挑战。在本文中，我们提出了GAP，一种新颖的方法，通过文本指导将原始点云高斯化为高保真3D高斯。我们的核心思想是设计一个多视角优化框架，该框架利用深度感知图像扩散模型来合成不同视角的连贯外观。为了确保几何精度，我们引入了一种表面锚定机制，在优化过程中有效地将高斯约束在3D形状的表面上。此外，GAP还结合了一种基于扩散的修复策略，专门用于补全难以观察的区域。我们在不同复杂程度的点云到高斯生成任务上评估了GAP，从合成点云到具有挑战性的真实世界扫描，甚至大规模场景。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [686] [FaceAnonyMixer: Cancelable Faces via Identity Consistent Latent Space Mixing](https://arxiv.org/abs/2508.05636)
> *FaceAnonyMixer：通过身份一致的潜在空间混合实现可撤销人脸*

*Mohammed Talha Alam, Fahad Shamshad, Fakhri Karray, Karthik Nandakumar* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 可撤销人脸, 隐私保护, 潜在空间混合, 人脸识别, 生物特征模板保护

**Comment:** 

> **TL;DR:** FaceAnonyMixer提出了一种通过在生成模型的潜在空间中混合真实人脸和可撤销密钥生成的合成代码来创建高质量、可撤销且隐私保护的人脸图像的方法，解决了现有方法在生物特征模板保护方面的不足，并在识别准确性和隐私保护方面表现优异。

**AI_Comments:** FaceAnonyMixer的创新之处在于利用生成模型的潜在空间实现可撤销人脸生成，并结合可撤销密钥和多目标损失来满足生物特征模板保护的严格要求。其重要性在于提供了一种兼顾隐私和识别效用的解决方案，对于人脸识别技术的广泛应用具有积极意义。该方法在商业API上实现的性能提升也显示出其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 人脸识别技术的发展加剧了隐私担忧，现有的人脸匿名化方法通常只侧重于模糊身份，但未能满足生物特征模板保护的要求，包括可撤销性、不可关联性和不可逆性。

**Method:** FaceAnonyMixer通过以下步骤生成可撤销人脸：1. 利用预训练生成模型的潜在空间来合成隐私保护的人脸图像。2. 将真实人脸图像的潜在代码与从可撤销密钥导出的合成代码进行不可逆混合。3. 通过精心设计的多目标损失进一步优化混合后的潜在代码，以满足所有可撤销生物特征要求。

**Result:** FaceAnonyMixer能够生成高质量的可撤销人脸，可以直接与现有的人脸识别系统匹配，无需任何修改。在基准数据集上的广泛实验表明，FaceAnonyMixer在提供显著更强的隐私保护的同时，提供了卓越的识别准确性，与最近的可撤销生物特征方法相比，在商业API上实现了超过11%的增益。

**Conclusion:** FaceAnonyMixer成功地解决了人脸识别技术带来的隐私问题，通过其创新的可撤销人脸生成框架，实现了在保持识别效用的同时提供强大的身份隐私保护，并满足了生物特征模板保护的关键要求。

> **ai_Abstract:** FaceAnonyMixer是一个新颖的可撤销人脸生成框架，旨在解决人脸识别技术带来的隐私问题。它通过在预训练生成模型的潜在空间中，将真实人脸的潜在代码与基于可撤销密钥的合成代码进行不可逆混合来生成隐私保护的人脸图像。该方法通过多目标损失进行优化，以满足生物特征模板保护的可撤销性、不可关联性和不可逆性要求。实验证明，FaceAnonyMixer在保持高识别准确性的同时，提供了比现有方法更强的隐私保护。

> **摘要翻译:** 人脸识别（FR）技术的进步加剧了隐私担忧，因此需要保护身份同时保持识别效用的方法。现有的人脸匿名化方法通常侧重于模糊身份，但未能满足生物特征模板保护的要求，包括可撤销性、不可关联性和不可逆性。我们提出了FaceAnonyMixer，一个可撤销人脸生成框架，该框架利用预训练生成模型的潜在空间来合成隐私保护的人脸图像。FaceAnonyMixer的核心思想是将真实人脸图像的潜在代码与从可撤销密钥导出的合成代码进行不可逆混合。混合后的潜在代码通过精心设计的多目标损失进一步优化，以满足所有可撤销生物特征要求。FaceAnonyMixer能够生成高质量的可撤销人脸，可以直接使用现有的人脸识别系统进行匹配，无需任何修改。在基准数据集上的广泛实验表明，FaceAnonyMixer在提供显著更强的隐私保护的同时，提供了卓越的识别准确性，与最近的可撤销生物特征方法相比，在商业API上实现了超过11%的增益。代码可在：https://github.com/talha-alam/faceanonymixer 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [692] [Advanced Multi-Architecture Deep Learning Framework for BIRADS-Based Mammographic Image Retrieval: Comprehensive Performance Analysis with Super-Ensemble Optimization](https://arxiv.org/abs/2508.04790)
> *用于BIRADS乳腺X线图像检索的先进多架构深度学习框架：超集成优化的综合性能分析*

*MD Shaikh Rahman, Feiroz Humayara, Syed Maudud E Rabbi, Muhammad Mahbubur Rashid* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-06**

**Keywords:** 乳腺X线图像检索, 深度学习, BIRADS, 超集成, 精准度@10

**Comment:** 

> **TL;DR:** 本研究开发了一种用于BIRADS乳腺X线图像检索的先进深度学习框架，通过比较多种CNN架构和训练策略，并利用超集成优化，显著提高了检索性能，建立了新的性能基准。

**AI_Comments:** 本论文的创新之处在于其对BIRADS乳腺X线图像检索这一复杂多类别任务的深入研究，并提出了一个综合性的深度学习评估框架。其重要性体现在通过严格的实验设计、大规模的测试查询和统计验证，显著提升了医学图像检索的性能，并为临床应用提供了实用的指导。特别是超集成优化策略的应用，展现了其在提高检索精度方面的强大潜力，为未来医学图像检索系统的开发奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 基于内容的乳腺X线图像检索系统需要对BIRADS五类进行精确匹配，这比文献中常见的二元分类任务复杂得多。当前的医学图像检索研究存在方法学上的局限性，包括样本量不足、数据分割不当和统计验证不足，这些都阻碍了临床转化。

**Method:** 本研究开发了一个综合评估框架，系统地比较了CNN架构（DenseNet121、ResNet50、VGG16）和先进的训练策略，包括精细调整、度量学习和超集成优化。评估采用了严格的分层数据分割（50%/20%/30% 训练/验证/测试）、602个测试查询，并使用1,000个样本的自助法置信区间进行系统验证。

**Result:** 采用差异学习率的先进精细调整显著提高了性能：DenseNet121（precision@10 34.79%，提高19.64%）和ResNet50（34.54%，提高19.58%）。结合互补架构的超集成优化实现了36.33%的precision@10（95% CI：[34.78%, 37.88%]），比基线提高了24.93%，每个查询提供3.6个相关病例。统计分析显示优化策略之间存在显著的性能差异（p<0.001），且效应量大（Cohen's d>0.8），同时保持了实际搜索效率（2.8毫秒）。性能显著超过了五类医学检索任务的实际预期，文献表明20-25%的precision@10是BIRADS精确匹配可达到的性能。

**Conclusion:** 本框架建立了新的性能基准，并为诊断支持和质量保证应用中的临床部署提供了循证架构选择指南。

> **ai_Abstract:** 本研究针对BIRADS乳腺X线图像检索中多类别精确匹配的复杂性和现有研究的方法学局限性，开发了一个先进的多架构深度学习框架。该框架系统评估了多种CNN架构（DenseNet121, ResNet50, VGG16）和训练策略，包括精细调整、度量学习和超集成优化。通过严格的数据分割和统计验证，研究发现差异学习率的精细调整和超集成优化显著提升了检索性能，其中超集成优化达到了36.33%的precision@10，远超现有文献中的可实现水平。该框架为临床部署提供了新的性能基准和架构选择指南。

> **摘要翻译:** 基于内容的乳腺X线图像检索系统要求在五个不同类别中进行精确的BIRADS分类匹配，这比文献中常见的二元分类任务复杂得多。当前的医学图像检索研究存在方法学上的局限性，包括样本量不足、数据分割不当和统计验证不足，这些都阻碍了临床转化。我们开发了一个综合评估框架，系统地比较了CNN架构（DenseNet121、ResNet50、VGG16）和先进的训练策略，包括复杂的精细调整、度量学习和超集成优化。我们的评估采用了严格的分层数据分割（50%/20%/30% 训练/验证/测试）、602个测试查询，并使用1,000个样本的自助法置信区间进行系统验证。采用差异学习率的先进精细调整取得了显著的改进：DenseNet121（precision@10 34.79%，提高19.64%）和ResNet50（34.54%，提高19.58%）。结合互补架构的超集成优化实现了36.33%的precision@10（95% CI：[34.78%, 37.88%]），比基线提高了24.93%，每个查询提供3.6个相关病例。统计分析显示优化策略之间存在显著的性能差异（p<0.001），且效应量大（Cohen's d>0.8），同时保持了实际搜索效率（2.8毫秒）。性能显著超过了五类医学检索任务的实际预期，文献表明20-25%的precision@10代表了BIRADS精确匹配可达到的性能。我们的框架建立了新的性能基准，同时为诊断支持和质量保证应用中的临床部署提供了循证架构选择指南。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [698] [CryoGS: Gaussian Splatting for Cryo-EM Homogeneous Reconstruction](https://arxiv.org/abs/2508.04929)
> *CryoGS：用于冷冻电镜均相重构的高斯泼溅*

*Suyi Chen, Haibin Ling* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-06**

**Keywords:** 冷冻电镜, 高斯泼溅, 均相重构, 高斯混合模型

**Comment:** 

> **TL;DR:** CryoGS是一种基于高斯混合模型的新方法，它将高斯泼溅与冷冻电镜成像物理相结合，实现了从原始图像直接进行冷冻电镜均相重构，解决了现有方法需要外部初始化的问题。

**AI_Comments:** 这篇论文通过引入CryoGS，解决了一个冷冻电镜重构领域的重要问题，即现有GMM方法对外部初始化的依赖。其创新点在于将高斯泼溅技术与冷冻电镜成像物理深度融合，并进行了多项针对性的技术改进，使得从原始数据直接进行重建成为可能，这对于构建更自包含、更易用的冷冻电镜分析流程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于高斯混合模型（GMM）的冷冻电镜重构方法依赖于外部共识图或原子模型进行初始化，这限制了它们在自包含管道中的应用。

**Method:** 论文引入了CryoGS，这是一种基于GMM的方法，它将高斯泼溅与冷冻电镜图像形成物理相结合。具体来说，开发了一种正交投影感知的高斯泼溅技术，并进行了适应性改进，如归一化项和FFT对齐的坐标系，这些都为冷冻电镜成像量身定制。这些创新使得可以直接从原始冷冻电镜颗粒图像进行稳定的、高效的均相重构，且可以使用随机初始化。

**Result:** 在真实数据集上的实验结果验证了CryoGS相对于代表性基线的有效性和鲁棒性。

**Conclusion:** CryoGS通过引入将高斯泼溅与冷冻电镜物理相结合的新方法，成功解决了冷冻电镜均相重构中对外部初始化的依赖，实现了从原始图像直接进行稳定高效的重构。

> **ai_Abstract:** CryoGS是一种用于冷冻电镜均相重构的新型高斯混合模型（GMM）方法。它通过将高斯泼溅技术与冷冻电镜的成像物理相结合，并引入了正交投影感知、归一化项和FFT对齐坐标系等创新，解决了现有GMM方法需要外部初始化的问题。CryoGS能够直接从原始冷冻电镜图像进行稳定高效的重建，且支持随机初始化，其有效性和鲁棒性已在真实数据集上得到验证。

> **摘要翻译:** 冷冻电子显微镜（Cryo-EM）作为结构生物学中的关键模式，有助于以接近原子分辨率确定大分子结构。单颗粒冷冻电镜中的核心计算任务是从大量在未知方向上获取的嘈杂2D投影中重建分子的3D静电势。高斯混合模型（GMMs）为分子密度提供了一种连续、紧凑且物理可解释的表示，并且最近在冷冻电镜重建中引起了兴趣。然而，现有方法依赖于外部共识图或原子模型进行初始化，限制了它们在自包含管道中的使用。为了解决这个问题，我们引入了cryoGS，这是一种基于GMM的方法，它将高斯泼溅与冷冻电镜图像形成的物理相结合。特别是，我们开发了一种正交投影感知的高斯泼溅，并进行了适应性改进，如归一化项和为冷冻电镜成像量身定制的FFT对齐坐标系。所有这些创新使得可以直接从原始冷冻电镜颗粒图像使用随机初始化进行稳定高效的均相重建。在真实数据集上的实验结果验证了cryoGS相对于代表性基线的有效性和鲁棒性。代码将在发布后发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [704] [ALScope: A Unified Toolkit for Deep Active Learning](https://arxiv.org/abs/2508.04937)
> *ALScope：一个深度主动学习的统一工具包*

*Chenkai Wu, Yuanyuan Qi, Xiaohao Yang, Jueqing Lu, Gang Liu, Wray Buntine, Lan Du* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 深度主动学习, 统一平台, 评估, 分布偏移, 数据不平衡

**Comment:** 

> **TL;DR:** ALScope是一个统一的深度主动学习（DAL）平台，集成了多个数据集和算法，用于在各种条件下进行公平和系统的评估，并揭示了DAL算法在不同场景下的表现差异和改进空间。

**AI_Comments:** ALScope的创新之处在于提供了一个统一、全面的DAL评估平台，解决了长期以来阻碍DAL算法公平比较和系统研究的痛点。其重要性体现在能够促进DAL领域的标准化评估，揭示现有算法的优缺点，并为未来算法设计指明方向，特别是在处理现实世界复杂场景（如分布偏移和数据不平衡）方面的潜力。该平台支持灵活配置多种实验因素，使得评估结果更具说服力。

<details>
  <summary>Details</summary>

**Motivation:** 深度主动学习（DAL）通过选择信息量最大的未标记样本来降低标注成本。然而，由于实际应用中分布偏移（如开放集识别）和数据不平衡等挑战日益突出，导致大量DAL算法涌现，但缺乏一个统一的平台来在不同条件下进行公平和系统的评估。

**Method:** 本文提出了一个新的DAL平台ALScope，专为分类任务设计。该平台整合了来自计算机视觉（CV）和自然语言处理（NLP）的10个数据集，以及21种代表性的DAL算法（包括经典基线和处理分布偏移、数据不平衡的最新方法）。ALScope支持灵活配置关键实验因素，例如算法和数据集选择，以及任务特定因素如域外（OOD）样本比例和类别不平衡比例，从而实现全面和真实的评估。

**Result:** 实验结果显示：(1) DAL算法的性能在不同领域和任务设置下差异显著；(2) 在非标准场景（如不平衡和开放集设置）中，DAL算法仍有改进空间，需要进一步研究；(3) 某些算法虽然表现良好，但选择时间显著更长。

**Conclusion:** DAL算法的性能受领域和任务设置影响显著，在不平衡和开放集等非标准场景下仍需深入研究和改进，且部分高性能算法存在计算效率问题。

> **ai_Abstract:** ALScope是一个针对深度主动学习（DAL）的统一评估平台，旨在解决现有DAL算法缺乏统一评估标准的问题。该平台集成了10个CV和NLP数据集以及21种DAL算法，支持对分布偏移、数据不平衡等复杂场景的灵活配置和全面评估。通过广泛实验，研究发现DAL算法性能受领域和任务设置影响显著，在非标准场景下仍有较大改进空间，且部分高性能算法存在效率问题，为DAL的未来研究指明了方向。

> **摘要翻译:** 深度主动学习（DAL）通过在训练过程中选择信息量最大的未标记样本来降低标注成本。随着现实世界应用变得更加复杂，源于分布偏移（例如，开放集识别）和数据不平衡的挑战受到了越来越多的关注，促使了大量DAL算法的开发。然而，缺乏一个统一的平台阻碍了在不同条件下进行公平和系统的评估。因此，我们提出了一个新的DAL平台ALScope，用于分类任务，它集成了来自计算机视觉（CV）和自然语言处理（NLP）的10个数据集和21种代表性DAL算法，包括经典基线和旨在处理分布偏移和数据不平衡等挑战的最新方法。该平台支持关键实验因素的灵活配置，范围从算法和数据集选择到任务特定因素，如域外（OOD）样本比例和类别不平衡比例，从而实现全面和真实的评估。我们在此平台上在各种设置下进行了广泛的实验。我们的发现表明：(1) DAL算法的性能在不同领域和任务设置下差异显著；(2) 在非标准场景（如不平衡和开放集设置）中，DAL算法显示出改进空间，需要进一步研究；(3) 某些算法取得了良好的性能，但需要显著更长的选择时间。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [710] [Perceive-Sample-Compress: Towards Real-Time 3D Gaussian Splatting](https://arxiv.org/abs/2508.04965)
> *感知-采样-压缩：迈向实时三维高斯泼溅*

*Zijian Wang, Beizhen Zhao, Hao Wang* | **Category: cs.CV, cs.GR, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 三维高斯泼溅, 实时渲染, 内存效率, 新颖视图合成, 压缩

**Comment:** 

> **TL;DR:** 本文提出了一种名为“感知-采样-压缩”的新型框架，旨在解决三维高斯泼溅（3DGS）在处理大规模场景时的存储和管理效率问题，同时保持实时渲染速度和视觉质量。

**AI_Comments:** 这项工作通过提出一个集成的“感知-采样-压缩”框架，为三维高斯泼溅在大规模场景应用中的实际部署提供了重要的解决方案。其创新点在于结合了感知优化、分层采样和高效压缩，有效平衡了渲染质量、内存消耗和实时性，对于推动3DGS在资源受限环境下的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的三维高斯泼溅（3DGS）表示在处理大规模场景管理和高效存储方面存在困难，尤其是在复杂环境或计算资源有限的情况下。

**Method:** 本文引入了一种新颖的“感知-采样-压缩”框架。具体而言，提出了场景感知补偿算法，智能地在每个级别细化高斯参数，优先处理视觉重要区域以实现更高保真度渲染并优化资源使用。其次，提出了一种金字塔采样表示来管理分层级别的高斯基元。最后，开发了一种广义高斯混合模型压缩算法，以实现显著的压缩比而不牺牲视觉保真度。

**Result:** 该方法显著提高了内存效率和视觉质量，同时保持了实时渲染速度。

**Conclusion:** 本文提出的感知-采样-压缩框架有效解决了三维高斯泼溅在大规模场景管理和存储方面的局限性，实现了内存效率、高视觉质量和实时渲染速度的平衡。

> **ai_Abstract:** 本文针对三维高斯泼溅（3DGS）在处理大规模场景时面临的存储和管理效率挑战，提出了一种名为“感知-采样-压缩”的新型框架。该框架包含三个核心组件：场景感知补偿算法，用于智能优化高斯参数和渲染质量；金字塔采样表示，用于分层管理高斯基元；以及广义高斯混合模型压缩算法，用于高效存储。实验证明，该方法显著提升了内存效率和视觉质量，同时保持了实时渲染性能。

> **摘要翻译:** 三维高斯泼溅（3DGS）的最新进展在实时和逼真的新颖视图合成方面展现出卓越的能力。然而，传统3DGS表示在处理大规模场景管理和高效存储方面常常遇到困难，尤其是在处理复杂环境或计算资源有限的情况下。为了解决这些限制，我们引入了一种新颖的感知-采样-压缩框架，用于三维高斯泼溅。具体而言，我们提出了一种场景感知补偿算法，该算法智能地在每个级别细化高斯参数。该算法智能地优先处理视觉重要性区域，以实现更高保真度渲染，同时优化资源使用并提高整体可见质量。此外，我们提出了一种金字塔采样表示来管理分层级别的高斯基元。最后，为了促进所提出的分层金字塔表示的有效存储，我们开发了一种广义高斯混合模型压缩算法，以在不牺牲视觉保真度的情况下实现显著的压缩比。广泛的实验表明，我们的方法显著提高了内存效率和高视觉质量，同时保持了实时渲染速度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [716] [Laplacian Analysis Meets Dynamics Modelling: Gaussian Splatting for 4D Reconstruction](https://arxiv.org/abs/2508.04966)
> *拉普拉斯分析与动态建模的结合：用于4D重建的高斯泼溅*

*Yifan Zhou, Beizhen Zhao, Pengcheng Wu, Hao Wang* | **Category: cs.CV, cs.GR, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 4D重建, 高斯泼溅, 动态场景, 拉普拉斯分析, 频谱感知

**Comment:** 

> **TL;DR:** 现有动态3DGS方法在处理运动细节和形变一致性方面存在挑战。本文提出了一种新的动态3DGS框架，采用频谱感知的拉普拉斯编码、增强的高斯动态属性和自适应高斯分裂策略，以实现更好的4D重建。

**AI_Comments:** 本文提出了一种创新性的方法来解决动态3DGS中固有的频谱冲突这一重大挑战。其混合显式-隐式函数设计，特别是频谱感知的拉普拉斯编码和增强的高斯动态属性是关键创新点。KDTree引导的自适应高斯分裂策略也提升了效率。这项工作通过提高动态场景的保真度和细节保留，推动了4D重建领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有动态3DGS方法在扩展到动态场景时面临显著挑战，主要表现为因低秩分解导致的过度平滑或因高维网格采样导致的特征冲突。这源于在保留运动细节和保持不同频率下的形变一致性之间固有的频谱冲突。

**Method:** 提出了一种新颖的动态3DGS框架，该框架采用混合显式-隐式函数。其主要创新包括：1) 一个频谱感知的拉普拉斯编码架构，融合了哈希编码和基于拉普拉斯的模块，用于灵活的频率运动控制。2) 一个增强的高斯动态属性，用于补偿几何形变引起的光度失真。3) 一个由KDTree基元控制引导的自适应高斯分裂策略，以有效查询和优化动态区域。

**Result:** 通过广泛的实验，该方法在重建复杂动态场景方面展示了最先进的性能，实现了更好的重建保真度。

**Conclusion:** 该方法有效解决了动态3DGS中存在的挑战，显著提升了4D重建的质量和保真度。

> **ai_Abstract:** 本文提出了一种新颖的动态3D高斯泼溅（3DGS）框架，旨在解决现有方法在处理动态场景时出现的过度平滑和特征冲突问题。该框架通过引入频谱感知的拉普拉斯编码实现灵活运动控制，利用增强的高斯动态属性补偿光度失真，并采用自适应高斯分裂策略优化动态区域。实验证明，该方法在复杂4D场景重建中达到了最先进的性能，并提高了重建保真度。

> **摘要翻译:** 虽然3D高斯泼溅（3DGS）在静态场景建模方面表现出色，但将其扩展到动态场景带来了重大挑战。现有的动态3DGS方法要么因低秩分解导致过度平滑，要么因高维网格采样导致特征冲突。这是因为在保留运动细节和保持不同频率下的形变一致性之间存在固有的频谱冲突。为了解决这些挑战，我们提出了一种新颖的动态3DGS框架，该框架采用混合显式-隐式函数。我们的方法包含三个关键创新：一个频谱感知的拉普拉斯编码架构，它融合了哈希编码和基于拉普拉斯的模块，用于灵活的频率运动控制；一个增强的高斯动态属性，用于补偿几何形变引起的光度失真；以及一个由KDTree基元控制引导的自适应高斯分裂策略，以有效查询和优化动态区域。通过广泛的实验，我们的方法在重建复杂动态场景方面展示了最先进的性能，实现了更好的重建保真度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [722] [RAP: Real-time Audio-driven Portrait Animation with Video Diffusion Transformer](https://arxiv.org/abs/2508.05115)
> *RAP：基于视频扩散Transformer的实时音频驱动肖像动画*

*Fangyu Du, Taiqing Li, Ziwei Zhang, Qian Qiao, Tan Yu, Dingcheng Zhen, Xu Jia, Yang Yang, Shunshun Yin, Siyuan Liu* | **Category: cs.CV, cs.GR, cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 音频驱动动画, 实时, 肖像动画, 视频扩散Transformer, 混合注意力

**Comment:** 

> **TL;DR:** 本文提出了RAP，一个实时音频驱动肖像动画框架，通过混合注意力机制和静态-动态训练推理范式，解决了现有方法计算复杂导致无法实时部署的问题，实现了高质量的实时生成。

**AI_Comments:** RAP的创新之处在于其对实时性的关注，通过混合注意力机制和静态-动态训练推理范式，在保证高质量输出的同时，克服了现有方法在计算效率上的瓶颈。这对于实际应用场景，如虚拟会议、内容创作等具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频驱动肖像动画方法虽然质量高，但计算复杂度高，不适用于实时部署。实时推理对延迟和内存有严格要求，导致需要使用高度压缩的潜在表示，但这会损害精细时空细节的保留，并使音视频同步复杂化。

**Method:** RAP（实时音频驱动肖像动画）是一个统一的框架，用于在实时约束下生成高质量的说话肖像。它引入了一种混合注意力机制，用于细粒度音频控制，以及一种避免显式运动监督的静态-动态训练-推理范式。

**Result:** RAP通过其技术实现了精确的音频驱动控制，减轻了长期时间漂移，并保持了高视觉保真度。大量实验表明，RAP在实时约束下实现了最先进的性能。

**Conclusion:** RAP框架成功解决了实时音频驱动肖像动画的挑战，在保持高视觉质量和精确音画同步的同时，实现了实时操作和最先进的性能。

> **ai_Abstract:** 本文提出RAP，一个实时音频驱动肖像动画的统一框架，旨在解决现有方法计算复杂度高、无法实时部署的问题。RAP通过引入混合注意力机制实现细粒度音频控制，并采用静态-动态训练推理范式避免显式运动监督，从而在实时约束下实现精确的音频驱动控制、缓解长期时间漂移并保持高视觉保真度，达到了最先进的性能。

> **摘要翻译:** 音频驱动肖像动画旨在从输入音频信号和单张参考图像合成逼真自然的说话人视频。尽管现有方法通过利用高维中间表示和明确建模运动动态实现了高质量结果，但其计算复杂性使其不适合实时部署。实时推理对延迟和内存有严格限制，通常需要使用高度压缩的潜在表示。然而，在这种紧凑空间中操作会阻碍精细时空细节的保留，从而使音视频同步复杂化。RAP（实时音频驱动肖像动画）是一个统一的框架，用于在实时约束下生成高质量的说话肖像。具体而言，RAP引入了一种混合注意力机制，用于细粒度音频控制，以及一种避免显式运动监督的静态-动态训练-推理范式。通过这些技术，RAP实现了精确的音频驱动控制，减轻了长期时间漂移，并保持了高视觉保真度。大量实验表明，RAP在实时约束下实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [728] [Beyond Pixels: Medical Image Quality Assessment with Implicit Neural Representations](https://arxiv.org/abs/2508.05168)
> *超越像素：基于隐式神经表示的医学图像质量评估*

*Caner Özer, Patryk Rygiel, Bram de Wilde, İlkay Öksüz, Jelmer M. Wolterink* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 医学图像质量评估, 隐式神经表示, 伪影检测, 深度学习, 内存效率

**Comment:** 

> **TL;DR:** 本文提出使用隐式神经表示（INRs）进行医学图像质量评估，以克服传统方法的局限性，并在参数更少的情况下实现了相似的性能。

**AI_Comments:** 该论文创新性地将隐式神经表示（INRs）引入医学图像质量评估领域，有效解决了传统方法中预处理导致的信息丢失和内存效率低下的问题。通过利用INRs的紧凑连续特性，该方法不仅提高了评估效率，还在参数量更少的情况下保持了性能，这对于大规模医学图像处理和模型部署具有重要意义。其提出的基于INRs的网络架构也为未来研究提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 伪影在医学成像中构成重大挑战，影响诊断准确性和后续分析。现有的基于图像的伪影检测方法虽然有效，但常依赖预处理，导致信息丢失和高内存需求，限制了分类模型的可扩展性。

**Method:** 本文提出使用隐式神经表示（INRs）作为医学图像的紧凑连续表示，以进行图像质量评估。研究开发了在INRs上操作的深度权重空间网络、图神经网络和关系注意力转换器。

**Result:** 该方法在ACDC数据集上使用合成伪影模式进行评估，证明了其在评估图像质量方面的有效性，并在参数更少的情况下实现了相似的性能。

**Conclusion:** 隐式神经表示（INRs）为医学图像质量评估提供了一种有效且高效的新方法，能够克服传统方法的局限性，并在保持性能的同时降低资源消耗。

> **ai_Abstract:** 本文针对医学图像中伪影检测的传统方法存在信息丢失和高内存需求的问题，提出了一种基于隐式神经表示（INRs）的图像质量评估新方法。INRs能够提供紧凑连续的图像表示，有效处理分辨率和图像大小变化，并减少内存开销。研究开发了深度权重空间网络、图神经网络和关系注意力转换器来处理INRs。在ACDC数据集上的实验表明，该方法在评估图像质量方面表现出色，并且在参数量更少的情况下达到了与现有方法相似的性能。

> **摘要翻译:** 伪影在医学成像中构成了重大挑战，影响诊断准确性和后续分析。虽然基于图像的伪影检测方法可能有效，但它们通常依赖于预处理方法，这可能导致信息丢失和高内存需求的医学图像，从而限制了分类模型的可扩展性。在这项工作中，我们提出了使用隐式神经表示（INRs）进行图像质量评估。INRs提供了医学图像的紧凑连续表示，自然地处理分辨率和图像尺寸的变化，同时减少内存开销。我们开发了在INRs上运行的深度权重空间网络、图神经网络和关系注意力转换器，以实现图像质量评估。我们的方法在ACDC数据集上进行了评估，使用了合成生成的伪影模式，证明了其在评估图像质量方面的有效性，同时在参数更少的情况下实现了相似的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [734] [Learning to See and Act: Task-Aware View Planning for Robotic Manipulation](https://arxiv.org/abs/2508.05186)
> *学会观察与行动：面向机器人操作的任务感知视角规划*

*Yongjie Bai, Zhouxia Wang, Yang Liu, Weixing Chen, Ziliang Chen, Mingtong Dai, Yongsen Zheng, Lingbo Liu, Guanbin Li, Liang Lin* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人操作, 视角规划, 任务感知, 视觉-语言-动作模型, 专家混合

**Comment:** 

> **TL;DR:** TAVP通过主动视角规划和任务特定表征学习，克服了现有VLA模型中固定视角和任务干扰的限制，显著提升了机器人操作的动作预测性能和泛化能力。

**AI_Comments:** TAVP的创新点在于将主动视角规划与任务特定的表征学习相结合，有效地解决了VLA模型中视觉感知和任务泛化的瓶颈。引入伪环境加速探索以及MoE视觉编码器解耦特征是其关键贡献，有望为多任务机器人操作带来更鲁棒和泛化的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉-语言-动作（VLA）模型在多任务机器人操作中，常依赖静态视角和共享视觉编码器，这限制了3D感知并导致任务干扰，从而影响了鲁棒性和泛化能力。

**Method:** 本文提出了任务感知视角规划（TAVP）框架，通过整合主动视角规划与任务特定表征学习来解决现有问题。TAVP利用一种新颖的伪环境加速高效探索策略，主动获取信息丰富的视角。此外，引入了专家混合（MoE）视觉编码器，以解耦不同任务的特征，提升表征保真度和任务泛化能力。

**Result:** 在RLBench任务上的大量实验表明，TAVP模型在动作预测方面显著优于最先进的固定视角方法，实现了卓越的性能。

**Conclusion:** 通过任务感知的方式学习观察世界，TAVP能够生成更完整、更具区分性的视觉表征，从而显著增强了机器人操作中各种挑战的动作预测能力，验证了其在多任务机器人操作中的优越性和潜力。

> **ai_Abstract:** 本文提出任务感知视角规划（TAVP）框架，旨在解决现有视觉-语言-动作（VLA）模型在机器人操作中因静态视角和共享视觉编码器导致的3D感知受限及任务干扰问题。TAVP通过结合主动视角规划（利用伪环境加速探索）和任务特定表征学习（采用专家混合视觉编码器解耦特征），提升了视觉表征的完整性和区分性。实验证明，TAVP在多种机器人操作任务中显著提高了动作预测性能，并超越了现有固定视角方法。

> **摘要翻译:** 最近用于多任务机器人操作的视觉-语言-动作（VLA）模型通常依赖于静态视角和共享视觉编码器，这限制了3D感知并导致任务干扰，从而阻碍了鲁棒性和泛化能力。在这项工作中，我们提出了任务感知视角规划（TAVP），一个旨在通过整合主动视角规划与任务特定表征学习来克服这些挑战的框架。TAVP采用了一种高效的探索策略，通过新颖的伪环境加速，以主动获取信息丰富的视角。此外，我们引入了专家混合（MoE）视觉编码器，以解耦不同任务的特征，从而提升表征保真度和任务泛化能力。通过以任务感知的方式学习观察世界，TAVP生成了更完整、更具区分性的视觉表征，在广泛的操作挑战中显著增强了动作预测能力。在RLBench任务上的大量实验表明，我们提出的TAVP模型优于最先进的固定视角方法。视觉结果和代码可在：https://hcplab-sysu.github.io/TAVP 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [740] [Don't Reach for the Stars: Rethinking Topology for Resilient Federated Learning](https://arxiv.org/abs/2508.05224)
> *不要触及星辰：重新思考拓扑以实现弹性联邦学习*

*Mirko Konstantin, Anirban Mukhopadhyay* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 联邦学习, 点对点, 去中心化, 拓扑, 鲁棒性, 个性化

**Comment:** 

> **TL;DR:** 本文提出了一种名为LIGHTYEAR的去中心化点对点（P2P）联邦学习框架，旨在解决传统中心化FL的局限性。通过引入基于本地验证集的一致性分数来选择和聚合个性化更新，LIGHTYEAR在异构和对抗条件下显著优于现有方法。

**AI_Comments:** 本文通过从脆弱的中心化星形拓扑转向更具弹性的P2P架构，为联邦学习带来了显著改进。引入“一致性分数”以实现语义对齐和个性化更新选择是其关键创新，这在非独立同分布（non-IID）和对抗性设置中提供了更大的客户端控制和鲁棒性。这种方法在分布式学习环境中同时增强了隐私性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 传统的中心化联邦学习（FL）方法存在诸多限制，包括单点故障、个性化能力有限、对数据分布偏移的鲁棒性差以及易受恶意客户端攻击。此外，中心化FL中基于低级参数差异的更新选择在非独立同分布（non-IID）数据下可能不可靠，且客户端缺乏控制权。

**Method:** 本文提出了一种去中心化的点对点（P2P）联邦学习框架，命名为LIGHTYEAR。该框架利用P2P拓扑的灵活性，使每个客户端能够识别并聚合一组个性化的、值得信赖且有益的更新。其核心是一个在本地验证集上计算的“一致性分数”，用于量化传入更新在函数空间中相对于客户端参考模型的语义对齐程度。每个客户端利用此分数选择定制的更新子集，并通过添加正则化项进行聚合以稳定训练。

**Result:** 在两个数据集上的实证评估表明，所提出的LIGHTYEAR方法在客户端级别的性能方面始终优于中心化基线和现有P2P方法，尤其是在对抗性和异构条件下。

**Conclusion:** LIGHTYEAR框架通过其去中心化的P2P拓扑和基于语义对齐的个性化更新聚合机制，显著提高了联邦学习的鲁棒性和客户端性能，特别是在面临异构和对抗性挑战的环境中。

> **ai_Abstract:** 本文提出了一种名为LIGHTYEAR的新型去中心化点对点（P2P）联邦学习框架，旨在克服传统中心化FL的局限性，如单点故障和鲁棒性差。LIGHTYEAR通过允许客户端基于衡量语义对齐的“一致性分数”来选择和聚合个性化、可信赖的更新。实证结果表明，特别是在异构和对抗性环境中，LIGHTYEAR的性能优于中心化基线和现有P2P方法。

> **摘要翻译:** 联邦学习（FL）通过将数据保留在本地，实现了分布式客户端之间的协作模型训练，同时保护了数据隐私。传统的FL方法依赖于中心化的星形拓扑，其中中央服务器聚合来自客户端的模型更新。然而，这种架构引入了几个限制，包括单点故障、个性化受限、对分布偏移的鲁棒性差或易受故障客户端的影响。此外，中心化FL中的更新选择通常依赖于低级参数差异，当客户端数据不是独立同分布时，这可能不可靠，并且客户端几乎没有控制权。在这项工作中，我们提出了一种去中心化的点对点（P2P）FL框架。它利用P2P拓扑的灵活性，使每个客户端能够识别并聚合一组个性化的、值得信赖且有益的更新。这个框架是“用于异构训练环境的本地推理引导聚合以通过一致性和正则化提高性能”（LIGHTYEAR）。我们方法的核心是一个在本地验证集上计算的一致性分数，它量化了传入更新在函数空间中相对于客户端参考模型的语义对齐程度。每个客户端使用这个分数来选择一个定制的更新子集，并执行带有正则化项的聚合，该正则化项进一步稳定了训练。我们对两个数据集的实证评估表明，所提出的方法在客户端级别的性能方面始终优于中心化基线和现有P2P方法，特别是在对抗性和异构条件下。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [746] [Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning](https://arxiv.org/abs/2508.05316)
> *半监督持续学习中增强无标签学习、稳定性和可塑性的分而治之方法*

*Yue Duan, Taicai Chen, Lei Qi, Yinghuan Shi* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 半监督持续学习, 无标签学习, 记忆稳定性, 学习可塑性, 分而治之

**Comment:** 

> **TL;DR:** 本文提出了一种名为 USP 的分而治之框架，旨在协同增强半监督持续学习中的无标签学习、记忆稳定性和学习可塑性，并取得了显著的性能提升。

**AI_Comments:** 本文提出了一种新颖的“分而治之”策略来协同解决半监督持续学习中的三大核心挑战：无标签学习、记忆稳定性和学习可塑性。其创新之处在于将这些看似独立的问题整合到一个统一的框架USP中，并通过FSR、DCP和CUD三个相互关联的模块进行解决，形成了一个协同增强的系统。这种系统性的方法超越了以往孤立解决单一问题的局限性，使得模型能够更有效地利用未标注数据，同时有效缓解灾难性遗忘并保持适应新知识的能力。其在最终准确率上高达5.94%的提升证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 半监督持续学习 (SSCL) 旨在利用标注和未标注数据进行序列学习，以降低标注成本并管理持续数据到达。SSCL 引入了复杂挑战，包括确保有效的无标签学习 (UL)，同时平衡记忆稳定性 (MS) 和学习可塑性 (LP)。现有 SSCL 方法通常只关注这三个方面中的孤立部分。

**Method:** 本文提出了 USP，一个分而治之的框架，旨在协同增强无标签学习 (UL)、记忆稳定性 (MS) 和学习可塑性 (LP) 这三个方面：1) 用于 LP 的特征空间保留 (FSR) 策略，通过将旧类别塑造成等角紧框架为未来类别构建保留特征位置；2) 用于 UL 的分而治之伪标签 (DCP) 方法，该方法在高中低置信度未标注数据中分配可靠的伪标签；3) 用于 MS 的类均值锚定无标签蒸馏 (CUD)，它重用 DCP 的输出，将未标注数据锚定到稳定的类均值进行蒸馏以防止遗忘。

**Result:** 综合评估显示，USP 优于之前的 SSCL 方法，在最终准确率方面提高了高达 5.94%，验证了其有效性。

**Conclusion:** 本文提出的 USP 框架通过其分而治之的方法，成功地协同增强了半监督持续学习中的无标签学习、记忆稳定性和学习可塑性，并在实验中取得了优异的性能，证明了其有效性。

> **ai_Abstract:** 本文提出了一个名为 USP 的分而治之框架，用于解决半监督持续学习 (SSCL) 中无标签学习 (UL)、记忆稳定性 (MS) 和学习可塑性 (LP) 之间的复杂平衡问题。USP 通过三个协同策略实现：特征空间保留 (FSR) 增强可塑性，分而治之伪标签 (DCP) 提升无标签学习，以及类均值锚定无标签蒸馏 (CUD) 确保稳定性。实验结果表明，USP 显著优于现有 SSCL 方法，在最终准确率上最高提升 5.94%，验证了其有效性。

> **摘要翻译:** 半监督持续学习 (SSCL) 旨在利用标注和未标注数据在序列学习设置中进行学习，旨在降低标注成本同时管理持续数据到达。SSCL 引入了复杂的挑战，包括确保有效的无标签学习 (UL)，同时平衡记忆稳定性 (MS) 和学习可塑性 (LP)。之前的 SSCL 工作通常只关注这三个方面的孤立部分，而这项工作提出了 USP，一个分而治之的框架，旨在协同增强这三个方面：(1) 用于 LP 的特征空间保留 (FSR) 策略，通过将旧类别塑造成等角紧框架为未来类别构建保留特征位置；(2) 用于 UL 的分而治之伪标签 (DCP) 方法，该方法在高中低置信度未标注数据中分配可靠的伪标签；(3) 用于 MS 的类均值锚定无标签蒸馏 (CUD)，它重用 DCP 的输出，将未标注数据锚定到稳定的类均值进行蒸馏以防止遗忘。综合评估显示 USP 优于之前的 SSCL 方法，在最终准确率方面提高了高达 5.94%，验证了其有效性。代码可在 https://github.com/NJUyued/USP4SSCL 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [751] [Artificial Intelligence-Based Classification of Spitz Tumors](https://arxiv.org/abs/2508.05391)
> *基于人工智能的Spitz肿瘤分类*

*Ruben T. Lucassen, Marjanna Romers, Chiel F. Ebbelaar, Aia N. Najem, Donal P. Hayes, Antien L. Mooyaart, Sara Roshani, Liliane C. D. Wynaendts, Nikolas Stathonikos, Gerben E. Breimer, Anne M. L. Jansen, Mitko Veta, Willeke A. M. Blokx* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-07**

**Keywords:** Spitz肿瘤, 黑色素瘤, 人工智能, 诊断分类, 遗传畸变

**Comment:** 

> **TL;DR:** 本研究开发并验证了AI模型，用于区分Spitz肿瘤与常规黑色素瘤，并预测Spitz肿瘤的遗传畸变和诊断类别，结果显示AI模型在所有任务上均优于病理学家，并能优化诊断流程。

**AI_Comments:** 这项研究展示了人工智能在解决复杂病理诊断问题上的巨大潜力，特别是在Spitz肿瘤这种诊断难度较高的领域。其创新之处在于不仅关注了鉴别诊断，还深入到预测遗传畸变和诊断类别，这对于个性化治疗和预后评估具有重要意义。此外，通过与人类专家的比较以及对工作流程效率的模拟，为AI在临床实践中的落地提供了有力的支持。然而，虽然AI表现优于病理学家，但大多数个体比较的差异未达统计学显著性，这提示AI仍需进一步优化以达到更具压倒性的优势。

<details>
  <summary>Details</summary>

**Motivation:** Spitz肿瘤在诊断上具有挑战性，因为其非典型组织学特征与常规黑色素瘤存在重叠。本研究旨在探究AI模型在区分Spitz肿瘤与常规黑色素瘤、预测Spitz肿瘤的遗传畸变以及预测其诊断类别方面的潜力。

**Method:** 研究使用包含393例Spitz肿瘤和379例常规黑色素瘤的数据集开发和验证AI模型。预测性能通过AUROC和准确率衡量。AI模型性能与四位经验丰富的病理学家进行比较。此外，还进行了模拟实验，以调查实施基于AI的辅助诊断测试建议对病理科工作流程的影响。

**Result:** 在区分Spitz肿瘤与常规黑色素瘤方面，最佳AI模型（基于UNI特征）的AUROC达到0.95，准确率为0.86。遗传畸变的预测准确率为0.55（随机猜测为0.25）。诊断类别的预测准确率为0.51（随机猜测为0.33）。在所有三个任务上，AI模型表现均优于四位病理学家，尽管大多数个体比较的差异无统计学意义。模拟实验表明，实施基于AI的辅助诊断测试建议可以减少材料成本、周转时间和检查。

**Conclusion:** AI模型在区分Spitz肿瘤和常规黑色素瘤方面取得了强大的预测性能。在预测Spitz肿瘤的遗传畸变和诊断类别等更具挑战性的任务上，AI模型的表现优于随机猜测。

> **ai_Abstract:** 本研究开发并验证了基于AI的模型，旨在解决Spitz肿瘤与常规黑色素瘤诊断重叠的挑战。模型利用组织学和/或临床特征，成功区分了这两种肿瘤，并预测了Spitz肿瘤的遗传畸变和诊断类别。实验结果表明，AI模型在预测准确性方面超越了经验丰富的病理学家，并且通过模拟证实，其应用有望优化病理诊断流程，降低成本并缩短周转时间。

> **摘要翻译:** Spitz肿瘤由于其非典型组织学特征与常规黑色素瘤存在重叠，诊断上具有挑战性。我们研究了AI模型在多大程度上能够利用组织学和/或临床特征来：(1)区分Spitz肿瘤与常规黑色素瘤；(2)预测Spitz肿瘤的潜在遗传畸变；以及(3)预测Spitz肿瘤的诊断类别。AI模型使用包含393例Spitz肿瘤和379例常规黑色素瘤的数据集进行开发和验证。预测性能通过AUROC和准确率进行衡量。AI模型的性能在读者研究中与四位经验丰富的病理学家进行了比较。此外，还进行了一项模拟实验，以调查实施基于AI的辅助诊断测试建议对病理科工作流程的影响。基于UNI特征的最佳AI模型在区分Spitz肿瘤与常规黑色素瘤方面达到了0.95的AUROC和0.86的准确率。遗传畸变的预测准确率为0.55，而随机猜测的准确率为0.25。诊断类别的预测准确率为0.51，而随机机会水平的准确率为0.33。在所有三项任务中，AI模型均优于四位病理学家，尽管大多数个体比较的差异无统计学意义。根据模拟实验，实施基于AI的辅助诊断测试建议可以减少材料成本、周转时间和检查。总之，AI模型在区分Spitz肿瘤和常规黑色素瘤方面取得了强大的预测性能。在预测Spitz肿瘤的遗传畸变和诊断类别等更具挑战性的任务上，AI模型的表现优于随机猜测。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [756] [DistillDrive: End-to-End Multi-Mode Autonomous Driving Distillation by Isomorphic Hetero-Source Planning Model](https://arxiv.org/abs/2508.05402)
> *DistillDrive：基于同构异源规划模型的端到端多模式自动驾驶蒸馏*

*Rui Yu, Xianghang Zhang, Runkai Zhao, Huaicheng Yan, Meng Wang* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 自动驾驶, 知识蒸馏, 端到端, 多模式, 规划模型

**Comment:** 

> **TL;DR:** DistillDrive通过知识蒸馏，利用结构化场景规划模型作为教师模型，结合强化学习和生成模型，提升端到端自动驾驶的鲁棒性和多模式运动特征学习，显著降低了碰撞率并提高了闭环性能。

**AI_Comments:** DistillDrive的创新之处在于其将知识蒸馏与异源规划模型相结合，以提升端到端自动驾驶的鲁棒性。通过引入规划导向的理解和多模式运动特征学习，它解决了现有模型过于依赖单一自我车辆状态的问题。结合强化学习和生成模型进一步优化了决策过程，使其在实际应用中更具潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有端到端自动驾驶方法过度关注自我车辆状态作为唯一的学习目标，缺乏面向规划的理解，限制了整体决策过程的鲁棒性。

**Method:** 本文引入了DistillDrive，一个基于知识蒸馏的端到端自动驾驶模型。它利用多样化的实例模仿来增强多模式运动特征学习。具体来说，它使用基于结构化场景表示的规划模型作为教师模型，利用其多样化的规划实例作为端到端模型的多目标学习目标。此外，还结合了强化学习来增强状态到决策映射的优化，并利用生成模型构建面向规划的实例，促进潜在空间内的复杂交互。

**Result:** 在nuScenes和NAVSIM数据集上验证了模型，与基线模型相比，碰撞率降低了50%，闭环性能提高了3点。

**Conclusion:** DistillDrive通过知识蒸馏、多源规划实例学习、强化学习和生成建模的结合，显著提升了端到端自动驾驶的鲁棒性和决策性能。

> **ai_Abstract:** DistillDrive是一个创新的端到端知识蒸馏自动驾驶模型，旨在解决现有方法在鲁棒性和规划理解方面的不足。它通过将结构化场景规划模型作为教师，并结合强化学习和生成模型，使端到端模型能够学习多样化的多模式运动特征和面向规划的决策。实验证明，该模型在碰撞率和闭环性能上均优于基线模型。

> **摘要翻译:** 端到端自动驾驶最近发展迅速，对工业界和学术界产生了深远影响。然而，现有工作过度关注自我车辆状态作为其唯一的学习目标，缺乏面向规划的理解，这限制了整体决策过程的鲁棒性。在这项工作中，我们引入了DistillDrive，一个基于知识蒸馏的端到端自动驾驶模型，它利用多样化的实例模仿来增强多模式运动特征学习。具体来说，我们采用基于结构化场景表示的规划模型作为教师模型，利用其多样化的规划实例作为端到端模型的多目标学习目标。此外，我们结合了强化学习来增强状态到决策映射的优化，同时利用生成建模来构建面向规划的实例，促进潜在空间内的复杂交互。我们在nuScenes和NAVSIM数据集上验证了我们的模型，与基线模型相比，碰撞率降低了50%，闭环性能提高了3点。代码和模型已公开提供在https://github.com/YuruiAI/DistillDrive

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [761] [Parameter-free entropy-regularized multi-view clustering with hierarchical feature selection](https://arxiv.org/abs/2508.05504)
> *无参数熵正则化多视图聚类与分层特征选择*

*Kristina P. Sinaga, Sara Colantonio, Miin-Shen Yang* | **Category: cs.CV, cs.LG, math.ST** | **Updated: 2025-08-07**

**Keywords:** 多视图聚类, 无参数, 熵正则化, 特征选择, 维度降低

**Comment:** 

> **TL;DR:** 本文提出了两种无参数、熵正则化的多视图聚类算法AMVFCM-U和AAMVFCM-U，通过信号噪声比进行特征加权和分层维度降低，显著提高了计算效率和模式发现能力。

**AI_Comments:** 该论文的创新点在于提出了一个无参数的多视图聚类框架，通过引入熵正则化和基于信噪比的特征加权，有效解决了传统方法的参数敏感性和特征选择问题。特别是AAMVFCM-U的分层降维机制，显著提升了算法的效率和处理高维数据的能力，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多视图聚类方法在处理高维特征和消除无关信息时，面临手动参数调整和缺乏统一的跨视图集成机制的挑战。

**Method:** 本文引入了两种互补的无参数算法AMVFCM-U和AAMVFCM-U。它们用熵正则化项代替模糊化参数，以实现自适应的跨视图共识。核心创新在于使用基于信噪比的正则化进行特征加权，并结合双层熵项自动平衡视图和特征贡献。AAMVFCM-U进一步通过自适应阈值在特征和视图层面实现了分层降维。

**Result:** 在五个不同的基准测试中，AAMVFCM-U和AMVFCM-U优于15种最先进的方法。AAMVFCM-U实现了高达97%的计算效率提升，将维度降低到原始大小的0.45%，并自动识别出最优模式发现的关键视图组合。

**Conclusion:** 本文提出的无参数熵正则化多视图聚类方法，通过创新的特征加权和分层降维机制，有效解决了传统方法的局限性，显著提升了多视图聚类在处理异构高维数据时的性能和效率。

> **ai_Abstract:** 本文提出了一种名为AMVFCM-U和AAMVFCM-U的无参数熵正则化多视图聚类框架，旨在解决传统方法中手动参数调整和跨视图集成不足的问题。该框架通过熵正则化实现自适应跨视图共识，并利用基于信噪比的正则化进行特征加权，同时AAMVFCM-U引入了分层维度降低。实验证明，该方法在多个基准测试中优于现有技术，显著提升了计算效率和维度降低效果，并能自动识别关键视图组合。

> **摘要翻译:** 多视图聚类在自动发现异构数据模式、管理高维特征和消除无关信息方面面临严峻挑战。传统方法受制于手动参数调整，并且缺乏有原则的跨视图集成机制。本工作引入了两种互补的算法：AMVFCM-U和AAMVFCM-U，提供了一个统一的无参数框架。我们的方法用熵正则化项代替了模糊化参数，强制执行自适应的跨视图共识。核心创新采用了基于信噪比的正则化（$\\delta_j^h = \\frac{\\bar{x}_j^h}{(\\sigma_j^h)^2}$）来实现有原则的特征加权，并具有收敛保证，同时结合了双层熵项，自动平衡视图和特征贡献。AAMVFCM-U通过自适应阈值（$\\theta^{h^{(t)}} = \\frac{d_h^{(t)}}{n}$）在特征和视图层面进行分层降维，从而扩展了此方法。在五个不同的基准测试中的评估表明，该方法优于15种最先进的方法。AAMVFCM-U实现了高达97%的计算效率增益，将维度降低到原始大小的0.45%，并自动识别出用于最佳模式发现的关键视图组合。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [766] [Point cloud segmentation for 3D Clothed Human Layering](https://arxiv.org/abs/2508.05531)
> *用于3D着装人体分层的点云分割*

*Davide Garavaso, Federico Masi, Pietro Musoni, Umberto Castellani* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 3D点云分割, 着装人体, 分层, 深度学习, 语义重建

**Comment:** 

> **TL;DR:** 本文提出了一种新的3D点云分割范式，称为着装人体分层，允许每个点同时关联到不同层，以估计底层身体部位和被遮挡的服装区域，并在合成和真实世界扫描数据集上验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于提出了“着装人体分层”这一新的3D点云分割范式，它突破了传统分割方法提供不相交集合的限制，允许点同时属于多个重叠层，这对于处理复杂如着装人体等多层结构具有重要意义。该方法通过估计底层身体和被遮挡服装区域，为高精度3D服装建模和虚拟形象创建奠定了基础。同时，创建新的带真实标注的合成数据集也为该领域的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 3D服装建模和模拟在时尚、娱乐和动画等领域创建虚拟形象至关重要，但由于着装身体的巨大可变性，尤其是真实皱纹的生成，实现高质量结果具有挑战性。3D扫描虽然提供高精度，但缺乏语义信息。现有3D形状分割方法主要针对场景理解而非建模，且无法处理着装身体多层重叠的问题，这阻碍了底层身体和相关服装的完全语义重建。

**Method:** 本文提出了一种新的3D点云分割范式，称为“着装人体分层”，允许每个3D点同时关联到不同的层。通过这种方式，可以估计底层身体部位和被遮挡的服装区域。为此，作者创建了一个新的合成数据集，模拟逼真的3D扫描并包含服装层的真实标注。研究中提出并评估了不同的神经网络设置来处理3D服装分层，并考虑了粗粒度和细粒度的每层服装识别。

**Result:** 实验证明，在服装领域引入适当的分割策略，在合成数据集和真实世界扫描数据集上都带来了益处。

**Conclusion:** 本文提出的着装人体分层范式及其在服装领域应用的分割策略，有效地解决了3D着装人体多层重叠的分割挑战，并有助于实现更准确的底层身体和服装部位的重建。

> **ai_Abstract:** 本文针对3D着装人体建模中多层服装重叠导致的点云分割挑战，提出了一种名为“着装人体分层”的新型3D点云分割范式。该范式允许单个点同时属于不同层，从而能够估计底层身体和被遮挡的服装区域。为支持研究，作者构建了一个包含真实标注的合成3D扫描数据集，并评估了多种神经网络配置以实现粗粒度和细粒度的服装层识别。实验结果表明，该方法在合成和真实扫描数据集上均有效提升了服装领域的分割性能。

> **摘要翻译:** 3D服装建模和模拟在时尚、娱乐和动画等多个领域对于虚拟形象的创建至关重要。由于着装身体的巨大可变性，尤其是在生成逼真皱纹方面，实现高质量结果具有挑战性。3D扫描采集在表示真实世界物体方面提供了更高的精度，但缺乏可以通过可靠的语义重建流程推断的语义信息。为此，形状分割在识别语义形状部分中起着关键作用。然而，当前的3D形状分割方法是为场景理解和解释而设计的，只有少数工作致力于建模。在着装身体建模的背景下，分割是完全语义形状部分重建的初步步骤，即底层身体和所涉及的服装。这些部分代表了具有强烈重叠的多个层，这与提供不相交集合的标准分割方法形成对比。在这项工作中，我们提出了一种新的3D点云分割范式，其中每个3D点可以同时关联到不同的层。通过这种方式，我们可以估计底层身体部位和看不见的着装区域，即被上方着装层遮挡的服装部分。我们将这种分割范式命名为着装人体分层。我们创建了一个新的合成数据集，模拟了非常逼真的3D扫描，并带有相关服装层的真实标注。我们提出并评估了不同的神经网络设置来处理3D服装分层。我们考虑了粗粒度和细粒度的每层服装识别。我们的实验证明了在服装领域引入适当的分割策略在合成和真实世界扫描数据集上的益处。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [771] [X-VFL: A New Vertical Federated Learning Framework with Cross Completion and Decision Subspace Alignment](https://arxiv.org/abs/2508.05568)
> *X-VFL：一种具有交叉补全和决策子空间对齐的新型垂直联邦学习框架*

*Qinghua Yao, Xiangrui Xu, Zhize Li* | **Category: cs.CV, cs.DC, cs.LG, math.OC** | **Updated: 2025-08-07**

**Keywords:** 垂直联邦学习, 特征补全, 决策子空间对齐, 本地推理, X-VFL

**Comment:** 

> **TL;DR:** X-VFL是一种新的垂直联邦学习框架，它通过交叉补全和决策子空间对齐，解决了现有VFL在数据未对齐和本地独立推理方面的挑战，并在实际数据集中取得了显著的性能提升。

**AI_Comments:** X-VFL的创新之处在于其通过XCom和DS-Align模块，有效地解决了垂直联邦学习中长期存在的两大挑战：数据对齐要求和本地独立推理的限制。这极大地扩展了VFL的应用范围和实用性，尤其是在数据不完整或需要边缘推理的场景中。其理论收敛性分析也增强了方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的垂直联邦学习（VFL）面临两大挑战：一是要求所有客户端的数据样本完美对齐（不允许特征缺失）；二是要求所有客户端共同参与联合协作推理/预测，不支持单个客户端的本地独立推理。

**Method:** 本文提出了X-VFL框架，旨在处理带有（部分）缺失特征的未对齐数据样本，并支持每个客户端对新数据样本进行本地独立推理。X-VFL包含两个新颖模块：交叉补全（XCom）利用其他客户端的信息完成/重建缺失特征；决策子空间对齐（DS-Align）将本地特征与所有客户端的已补全和全局特征在决策子空间内对齐，从而实现每个客户端的本地独立推理。此外，论文还提供了X-VFL训练中不同算法的收敛定理。

**Result:** X-VFL在实际数据集上表现显著优于现有方法，例如在图像CIFAR-10数据集上准确率提高了15%，在医疗MIMIC-III数据集上提高了43%。收敛性方面，SGD类算法的收敛率为$O(1/\sqrt{T})$，PAGE类算法的收敛率为$O(1/T)$，其中$T$是训练更新步数。

**Conclusion:** X-VFL在处理部分缺失特征和支持本地独立推理的场景中，表现出实际有效性和优越性，显著提升了垂直联邦学习的性能。

> **ai_Abstract:** 本文提出了一种名为X-VFL的新型垂直联邦学习（VFL）框架，旨在解决现有VFL在处理未对齐数据和支持本地独立推理方面的局限性。X-VFL引入了交叉补全（XCom）模块来重建缺失特征，以及决策子空间对齐（DS-Align）模块以实现客户端的本地独立推理。实验结果表明，X-VFL在处理部分缺失特征和支持本地独立推理的场景下，性能显著优于现有方法，并在多个真实数据集上取得了显著的准确率提升，同时提供了理论收敛性保证。

> **摘要翻译:** 垂直联邦学习（VFL）通过整合来自多个客户端/方的分离特征子集，实现协作学习。然而，VFL通常面临两个关键挑战：i) 要求所有客户端的数据样本完美对齐（不允许特征缺失）；ii) 要求所有客户端共同参与联合协作推理/预测（不支持单个客户端的本地独立推理）。为了解决这些挑战，我们提出了X-VFL，一个旨在处理带有（部分）缺失特征的未对齐数据样本，并支持每个客户端对新数据样本进行本地独立推理的新型VFL框架。特别是，我们在X-VFL中设计了两个新颖的模块：交叉补全（XCom）和决策子空间对齐（DS-Align）。XCom可以通过利用来自其他客户端的信息来完成/重建未对齐数据样本的缺失特征。DS-Align将本地特征与决策子空间内所有客户端的已补全和全局特征对齐，从而实现每个客户端的本地独立推理。此外，我们还为X-VFL训练中使用的不同算法提供了收敛定理，结果显示SGD类算法的收敛率为$O(1/\sqrt{T})$，PAGE类算法的收敛率为$O(1/T)$，其中$T$表示训练更新步数。在真实世界数据集上的大量实验表明，X-VFL显著优于现有方法，例如在图像CIFAR-10数据集上准确率提高了15%，在医疗MIMIC-III数据集上提高了43%。这些结果验证了X-VFL的实际有效性和优越性，特别是在涉及部分缺失特征和本地独立推理的场景中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [776] [Physically Controllable Relighting of Photographs](https://arxiv.org/abs/2508.05626)
> *照片的物理可控重打光*

*Chris Careaga, Yağız Aksoy* | **Category: cs.CV, cs.GR** | **Updated: 2025-08-07**

**Keywords:** 图像重打光, 物理渲染, 神经渲染, 自监督学习, 3D控制

**Comment:** 

> **TL;DR:** 该论文提出了一种自监督方法，通过结合传统渲染的物理精度和神经渲染的真实感，实现对野外图像进行物理可控的重打光。

**AI_Comments:** 该论文的创新之处在于成功地将传统基于物理的渲染的精确性与深度学习驱动的神经渲染的真实感相结合，实现了对“野外”图像的物理可控重打光。自监督训练范式的引入极大地降低了数据标注的门槛，使其在实际应用中更具潜力。这项工作是计算机图形学和计算机视觉交叉领域的重要进展，为图像编辑和内容创作提供了强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 目前的图像重打光方法在物理精度和真实感之间存在权衡。该研究旨在将3D计算机图形工具中对光线的显式物理控制引入到野外图像的重打光中。

**Method:** 该方法通过推断给定场景的彩色网格表示，结合单目几何和内在组件的估计。用户可以在3D中定义所需的照明配置，然后使用路径追踪引擎渲染场景。渲染出的近似场景通过前馈神经渲染器处理，以预测最终的光真实感重打光结果。该方法开发了一个可微分渲染过程来重建野外场景照明，从而在原始图像集上实现神经渲染器的自监督训练。

**Result:** 该方法能够对野外图像进行完全可控的、基于物理的照明编辑，并实现了传统渲染的物理精度与神经渲染的光真实感外观的结合。

**Conclusion:** 该方法在将3D计算机图形工具（如Blender）中可用的光线显式物理控制引入到野外重打光方面迈出了重要一步。

> **ai_Abstract:** 该论文提出了一种自监督方法，用于野外图像的物理可控重打光。通过结合传统渲染的物理精度和神经渲染的光真实感，该方法能够推断场景的彩色网格表示，允许用户在3D中定义照明，并通过路径追踪和前馈神经渲染器生成最终的逼真重打光结果。其核心在于开发了可微分渲染过程，实现了神经渲染器的自监督训练，从而将3D图形工具中的物理光照控制带入到真实照片的重打光应用中。

> **摘要翻译:** 我们提出了一种野外图像重打光的自监督方法，该方法能够实现完全可控的、基于物理的照明编辑。我们通过将传统渲染的物理精度与神经渲染所实现的光真实感外观相结合来实现这一点。我们的流程通过使用几何和内在组件的单目估计来推断给定场景的彩色网格表示。这种表示允许用户在3D中定义他们所需的照明配置。然后可以使用路径追踪引擎渲染新光照下的场景。我们将场景的这种近似渲染发送到前馈神经渲染器，以预测最终的光真实感重打光结果。我们开发了一个可微分渲染过程来重建野外场景照明，从而使我们的神经渲染器能够在原始图像集合上进行自监督训练。我们的方法代表着将典型的3D计算机图形工具（如Blender）中对光线的显式物理控制引入到野外重打光方面迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [781] [Genie Envisioner: A Unified World Foundation Platform for Robotic Manipulation](https://arxiv.org/abs/2508.05635)
> *精灵幻想家：一个用于机器人操作的统一世界基础平台*

*Yue Liao, Pengfei Zhou, Siyuan Huang, Donglin Yang, Shengcong Chen, Yuxin Jiang, Yue Hu, Jingbin Cai, Si Liu, Jianlan Luo, Liliang Chen, Shuicheng Yan, Maoqing Yao, Guanghui Ren* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人操作, 视频扩散模型, 统一平台, 具身智能, 策略学习

**Comment:** 

> **TL;DR:** Genie Envisioner (GE) 是一个统一的机器人操作平台，它在一个视频生成框架内整合了策略学习、评估和模拟，旨在实现指令驱动的通用具身智能。

**AI_Comments:** Genie Envisioner的创新之处在于其将策略学习、评估和模拟统一到一个单一的视频生成框架中，特别是核心的GE-Base利用大规模指令条件视频扩散模型来捕捉机器人交互的复杂动态。这提供了一个通用且可扩展的方法来解决机器人操作问题，是具身智能领域的重要进展。然而，抽象中并未提及具体的实验结果或与现有方法的性能对比，这使得其在实际效果上的说服力略显不足。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是创建一个统一、可扩展且实用的世界基础平台，用于机器人操作，该平台能够在一个视频生成框架内整合策略学习、评估和模拟，以支持指令驱动的通用具身智能。

**Method:** Genie Envisioner (GE) 平台由以下核心组件构成：GE-Base是一个大规模、指令条件视频扩散模型，用于捕捉真实世界机器人交互的空间、时间及语义动态；GE-Act通过轻量级流匹配解码器将潜在表征映射到可执行动作轨迹；GE-Sim是一个动作条件神经模拟器，用于生成高保真推演以支持闭环策略开发。此外，平台还配备了EWMBench标准基准套件进行评估。

**Result:** 该平台能够实现跨不同具身设备的精确和通用策略推理，且仅需最少监督。它支持可扩展的评估和训练，并为指令驱动的通用具身智能奠定了可扩展且实用的基础。

**Conclusion:** Genie Envisioner 作为一个统一的视频生成框架，成功地为指令驱动的通用具身智能建立了一个可扩展且实用的基础，整合了策略学习、评估和模拟。

> **ai_Abstract:** Genie Envisioner (GE) 是一个创新性的统一平台，旨在通过视频生成框架整合机器人操作中的策略学习、评估和模拟。它包含GE-Base（一个视频扩散模型）、GE-Act（用于动作映射）和GE-Sim（一个神经模拟器），并辅以EWMBench基准套件。该平台致力于提供一个可扩展且实用的基础，以实现指令驱动的通用具身智能。

> **摘要翻译:** 我们引入了Genie Envisioner (GE)，这是一个用于机器人操作的统一世界基础平台，它在一个单一的视频生成框架内整合了策略学习、评估和模拟。其核心是GE-Base，这是一个大规模、指令条件视频扩散模型，它在结构化的潜在空间中捕捉真实世界机器人交互的空间、时间及语义动态。在此基础上，GE-Act通过一个轻量级的流匹配解码器将潜在表征映射到可执行的动作轨迹，从而以最少的监督实现跨多样具身设备的精确和通用策略推理。为了支持可扩展的评估和训练，GE-Sim作为一个动作条件神经模拟器，为闭环策略开发生成高保真推演。该平台还配备了EWMBench，这是一个标准化的基准套件，用于衡量视觉保真度、物理一致性和指令-动作对齐。这些组件共同将Genie Envisioner确立为指令驱动、通用具身智能的可扩展且实用的基础。所有代码、模型和基准将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [786] [A Fast Text-Driven Approach for Generating Artistic Content](https://arxiv.org/abs/2208.01748)
> *快速文本驱动的艺术内容生成方法*

*Marian Lupascu, Ryan Murdock, Ionut Mironica, Yijun Li* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-06**

**Keywords:** 艺术内容生成, 文本驱动, 风格化, 超分辨率, 视觉艺术

**Comment:** 

> **TL;DR:** 提出一个快速、灵活的文本驱动框架，用于生成具有丰富细节和风格的视觉艺术，克服了传统风格化方法的局限性。

**AI_Comments:** 该论文提出了一种创新的文本驱动艺术内容生成方法，解决了现有风格化方法在灵活性方面的局限性。其引入的改进版本和超分辨率模块显著提升了生成效率和艺术细节，使得生成的作品更具表现力。这是一个在艺术创作和AIGC领域有潜力的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有风格化方法在风格参数上缺乏灵活性，通常只允许使用单一风格图像、单一风格化文本或特定领域的内容图像进行风格化。

**Method:** 本文提出了一个完整的视觉艺术生成框架。该方法实现了一个改进版本，可以生成具有广泛细节、风格和结构的结果，并提升了生成速度。此外，为了进一步增强结果，还在生成管道中插入了一个艺术超分辨率模块，以增加画师特有图案和细微笔触等细节。

**Result:** 该方法在风格参数上没有限制，能够生成具有不同细节、风格和结构的广泛结果，并显著提升了生成速度。超分辨率模块能带来额外的细节，如画师特有图案和细微笔触。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一个快速的文本驱动视觉艺术生成框架。该方法克服了传统风格化方法在风格参数灵活性上的限制，能够生成具有广泛细节、风格和结构变化的艺术内容。通过引入改进版本和艺术超分辨率模块，显著提升了生成速度并丰富了艺术作品的细节，如画师特有图案和笔触。

> **摘要翻译:** 在这项工作中，我们提出了一个生成视觉艺术的完整框架。与以前对风格参数不灵活的风格化方法（即它们只允许使用一张风格图像、一个单一的风格化文本或对特定领域的内容图像进行风格化）不同，我们的方法没有这样的限制。此外，我们实现了一个改进版本，可以生成具有不同程度的细节、风格和结构的广泛结果，并提高了生成速度。为了进一步增强结果，我们在生成管道中插入了一个艺术超分辨率模块。这个模块将带来额外的细节，例如画家特有的图案、细微的笔触等等。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [791] [M$^{2}$Chat: Empowering VLM for Multimodal LLM Interleaved Text-Image Generation](https://arxiv.org/abs/2311.17963)
> *M$^{2}$Chat：赋能VLM实现多模态LLM交错式图文生成*

*Xiaowei Chi, Junbo Qi, Rongyu Zhang, Shanghang Zhang, Qifeng Liu, Yike Guo* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 多模态LLM, 图文生成, M$^{2}$Chat, M$^{3}Adapter$, 微调策略

**Comment:** 

> **TL;DR:** M$^{2}$Chat提出了一个统一的多模态LLM框架，通过M$^{3}$Adapter和两阶段M$^{3}$FT微调策略，实现高效高质量的图文交错生成，并在多个基准测试中超越SOTA。

**AI_Comments:** 本文的创新点在于提出了M$^{3}Adapter$和两阶段M$^{3}FT$微调策略，这有效地解决了多模态LLM在图文交错生成中面临的特征对齐和性能平衡问题。M$^{3}Adapter$能够整合细粒度视觉信息和高级语义特征，并通过门控策略自适应地平衡模型表现，这对于提升多任务性能至关重要。两阶段微调策略进一步优化了图像-文本对齐和视觉-指令理解，确保了上下文的连贯性。其在多项基准测试中超越SOTA的表现，凸显了该框架在多模态LLM领域的重要性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM聊天机器人（如GPT-4V）在实现文本-图像生成方面，仍缺乏高效的对齐方法，以在多个下游任务中实现高保真性能。

**Method:** 本文提出了M$^{2}$Chat，一个新颖的统一多模态LLM框架，用于生成跨场景的交错式图文对话。具体地，提出了M$^{3}Adapter$来高效整合来自多模态提示的细粒度低级视觉信息和高级语义特征。基于良好对齐的融合特征，M$^{3}Adapter$设计了一种可学习的门控策略，以自适应地平衡模型在各种任务中的创造性和一致性。此外，为了进一步增强M$^{3}Adapter$的有效性，同时保持语义上下文理解的连贯性，引入了两阶段M$^{3}FT$微调策略，该策略优化了图像-文本对齐和视觉-指令的独立参数组。

**Result:** 广泛的实验表明，M$^{2}$Chat在各种基准测试中超越了最先进的同类模型，展示了其在交错生成、故事讲述和多模态对话系统方面的强大能力。

**Conclusion:** M$^{2}$Chat通过其创新的M$^{3}Adapter$和两阶段M$^{3}FT$微调策略，成功地为多模态LLM提供了高效的图文交错生成能力，并在多个关键任务中取得了领先性能。

> **ai_Abstract:** 本文提出了M$^{2}$Chat，一个用于多模态LLM交错式图文生成的统一框架，旨在解决现有模型在多任务高保真对齐方面的不足。M$^{2}$Chat通过引入M$^{3}Adapter$高效融合多模态特征并平衡创造性与一致性，并采用两阶段M$^{3}FT$微调策略优化对齐和指令理解。实验证明，M$^{2}$Chat在交错生成、故事讲述和多模态对话等任务上超越了现有SOTA模型。

> **摘要翻译:** 尽管当前像GPT-4V这样的LLM聊天机器人弥合了人类指令和视觉表示之间的鸿沟，实现了文本-图像生成，但它们仍然缺乏高效的对齐方法，以在多个下游任务中实现高保真性能。在本文中，我们提出了M$^{2}$Chat，一个新颖的统一多模态LLM框架，用于生成跨各种场景的交错式文本-图像对话。具体地，我们提出了一个M$^{3}Adapter$，它能够高效地整合来自多模态提示的细粒度低级视觉信息和高级语义特征。基于良好对齐的融合特征，M$^{3}Adapter$设计了一种可学习的门控策略，以自适应地平衡模型在各种任务中的创造性和一致性。此外，为了在保持语义上下文理解连贯性的同时进一步增强M$^{3}Adapter$的有效性，我们引入了两阶段M$^{3}FT$微调策略。该策略为图像-文本对齐和视觉-指令分别优化了不相交的参数组。广泛的实验表明，我们的M$^{2}Chat$在各种基准测试中超越了最先进的同类模型，展示了其在交错生成、故事讲述和多模态对话系统方面的强大能力。演示和代码可在https://mattie-e.github.io/M2Chat.github.io获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [795] [Magic Fixup: Streamlining Photo Editing by Watching Dynamic Videos](https://arxiv.org/abs/2403.13044)
> *魔法修复：通过观看动态视频简化照片编辑*

*Hadi Alzayer, Zhihao Xia, Xuaner Zhang, Eli Shechtman, Jia-Bin Huang, Michael Gharbi* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 生成模型, 照片编辑, 视频监督, 扩散模型, 图像合成

**Comment:** 

> **TL;DR:** 提出一种生成模型，通过观看动态视频简化照片编辑，实现逼真图像合成，同时保留细节和适应新布局的光照。

**AI_Comments:** 这篇论文的创新点在于利用动态视频作为监督源来解决图像编辑中的逼真度问题，特别是对于光照和物理交互的协调。这种方法提供了一种新的、数据驱动的途径来简化复杂的照片编辑任务。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像编辑方法在生成逼真输出、处理光照和上下文变化方面存在挑战。本研究旨在开发一个生成模型，能够将粗略编辑的图像转化为逼真的输出，同时保留原始图像细节、身份，并适应新布局的光照和上下文。核心在于利用视频作为强大的监督来源。

**Method:** 提出一个生成模型；利用视频作为监督源，因为视频提供了世界如何随视角、光照和物理交互变化的观察；构建了一个图像数据集，包含从同一视频中随机时间间隔提取的源帧和目标帧对；使用两个运动模型将源帧扭曲到目标帧，以模拟用户编辑；从预训练的扩散模型开始，监督模型将扭曲图像转换为真实图像；模型设计明确支持从源帧到生成图像的细节迁移，并紧密遵循用户指定布局。

**Result:** 通过简单的分割和粗略的2D操作，可以合成忠实于用户输入的逼真编辑；解决了二阶效应，如协调编辑对象之间的光照和物理交互。

**Conclusion:** 该模型能够实现逼真的图像编辑，同时处理复杂的光照和物理交互，并通过利用视频数据作为监督来简化照片编辑流程。

> **ai_Abstract:** 这篇论文提出了一种名为“Magic Fixup”的生成模型，旨在简化照片编辑过程。该模型能够将粗略编辑的图像转换为逼真的输出，同时保留原始细节并适应新的光照和上下文。其核心创新在于利用动态视频作为监督来源，通过观察物体和摄像机运动来学习世界变化。研究者构建了一个视频帧数据集，并使用运动模型扭曲图像，然后从预训练的扩散模型开始训练模型。结果表明，该模型能生成忠实于用户输入的逼真编辑，并能处理光照和物理交互等复杂效应。

> **摘要翻译:** 我们提出了一种生成模型，该模型在给定粗略编辑的图像后，能够合成遵循预设布局的逼真输出。我们的方法从原始图像中转移精细细节并保留其部分的身份。然而，它能使其适应新布局定义的光照和上下文。我们的关键见解是，视频是这项任务强大的监督来源：物体和摄像机运动提供了许多关于世界如何随视角、光照和物理交互变化的观察。我们构建了一个图像数据集，其中每个样本都是从同一视频中随机选择的时间间隔提取的源帧和目标帧对。我们使用两种模拟预期测试时用户编辑的运动模型将源帧扭曲到目标帧。我们从预训练的扩散模型开始，监督我们的模型将扭曲的图像转换为真实图像。我们的模型设计明确支持从源帧到生成图像的精细细节转移，同时紧密遵循用户指定的用户布局。我们展示了通过使用简单的分割和粗略的2D操作，我们可以合成忠实于用户输入的逼真编辑，同时处理像协调编辑对象之间的光照和物理交互这样的二阶效应。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [801] [PerSense: Training-Free Personalized Instance Segmentation in Dense Images](https://arxiv.org/abs/2405.13518)
> *PerSense: 密集图像中免训练的个性化实例分割*

*Muhammad Ibraheem Siddiqui, Muhammad Umer Sheikh, Hassan Abid, Muhammad Haris Khan* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 实例分割, 密集图像, 免训练, 密度图, 个性化分割

**Comment:** 

> **TL;DR:** PerSense是一个针对密集图像中个性化实例分割的免训练、模型无关的一键式框架，通过引入新的模块和反馈机制，并在新基准上超越了现有技术。

**AI_Comments:** PerSense的创新之处在于其“免训练”和“模型无关”的特性，这大大降低了应用门槛。通过引入密度图和反馈机制来处理密集场景中的遮挡和尺度变化，显示了其在实际应用中的潜力。同时，引入新的评估基准PerSense-D也对该领域未来的研究具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 基础模型的出现显著推动了分割方法的发展，但在密集场景中，由于遮挡、尺度变化和杂乱等问题，精确的实例描绘仍然面临挑战。本文旨在解决这一问题。

**Method:** 本文提出了PerSense，一个端到端、免训练、模型无关的一键式框架，用于密集图像中的个性化实例分割。它首先通过提出一个利用密度图（DMs）的新型实例检测模块（IDM）来自动生成实例级点提示。为了减少误报，设计了点提示选择模块（PPSM），该模块基于自适应阈值和空间门控细化IDM的输出。此外，引入了一个反馈机制，通过自动化DM生成的范例选择过程来提高DMs的准确性。最后，引入了PerSense-D，一个用于密集图像中实例分割的评估基准。

**Result:** 广泛的实验证明PerSense在密集设置中优于现有最先进（SOTA）的方法。

**Conclusion:** PerSense通过其创新的免训练框架和模块设计，有效解决了密集图像中实例分割的挑战，并在新基准上取得了优越的性能，为该领域的研究提供了新的方向。

> **ai_Abstract:** PerSense是一个针对密集图像中个性化实例分割的创新框架，旨在解决密集场景中实例描绘的挑战。该框架是端到端、免训练且模型无关的，通过引入实例检测模块（IDM）利用密度图生成点提示，并使用点提示选择模块（PPSM）进行优化。此外，PerSense包含一个反馈机制以提高密度图的准确性。为了促进研究，该论文还推出了PerSense-D评估基准。实验结果表明，PerSense在密集图像分割方面优于现有SOTA方法。

> **摘要翻译:** 基础模型的出现显著推动了分割方法的发展。然而，在密集场景中，由于遮挡、尺度变化和杂乱，精确的实例描绘仍然面临挑战。为了解决这个问题，我们提出了PerSense，一个端到端、免训练、模型无关的一键式框架，用于密集图像中的个性化实例分割。我们首先开发了一个新的基线，能够通过提出一个利用密度图（DMs）的新型实例检测模块（IDM）来自动生成实例级点提示，该模块封装了图像中对象的空间分布。为了减少误报，我们设计了点提示选择模块（PPSM），它基于自适应阈值和空间门控来细化IDM的输出。IDM和PPSM都无缝集成到我们的模型无关框架中。此外，我们引入了一个反馈机制，使PerSense能够通过自动化DM生成的范例选择过程来提高DMs的准确性。最后，为了推动这个相对未充分探索领域的研究，我们引入了PerSense-D，一个用于密集图像中实例分割的评估基准。我们广泛的实验证明了PerSense在密集设置中优于现有最先进（SOTA）的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [806] [Interior Object Geometry via Fitted Frames](https://arxiv.org/abs/2407.14357)
> *内部对象几何通过拟合框架*

*Stephen M. Pizer, Zhiyuan Liu, Junjie Zhao, Nicholas Tapp-Hughes, James Damon, Miaomiao Zhang, JS Marron, Mohsen Taheri, Jared Vicory* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 拟合框架, 几何特征, 对象表示, 局部对应, 进化s-rep

**Comment:** 

> **TL;DR:** 提出了一种新的几何特征表示方法（进化s-rep），通过拟合框架在对象内部和边界上生成对齐无关且可在群体中局部对应的特征，并在解剖对象（如海马体）的分类任务中表现出显著改进。

**AI_Comments:** 这篇论文通过引入“拟合框架”和“进化s-rep”的概念，提供了一种新颖且强大的方法来处理对象几何特征的表示，尤其是在需要跨群体进行局部对应和统计分析的场景下。其创新点在于克服了传统方法在对齐和局部对应方面的限制，并通过在解剖对象上的出色表现证明了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法难以在对象群体中实现几何特征的强局部对应，从而限制了对对象统计数据的强大分析。本文旨在解决这一问题，为解剖对象提供能够实现群体内强定位对应并产生强大对象统计数据的表示方法。

**Method:** 提出一种计算对象边界和内部拟合框架的方法，并利用这些框架生成对齐无关且可在对象群体中局部对应的几何特征。该方法将对象理解为椭球体内部闭包的微分同胚变形，并使用贯穿变形的骨架表示来生成目标对象模型。这种新的表示被称为“进化s-rep”。

**Result:** 在区分患有疾病个体和健康个体之间海马体形状的分类性能测试中，与两种最先进的对象表示方法相比，新的“进化s-rep”表示方法显示出显著改进的分类性能。

**Conclusion:** 通过引入“进化s-rep”表示和基于拟合框架的几何特征，本研究显著提升了在对象群体中捕获几何对应性及生成有用统计特征的能力，尤其是在解剖对象分析方面。

> **ai_Abstract:** 本文提出了一种名为“进化s-rep”的新型对象几何表示方法，该方法通过在对象边界和内部计算拟合框架来生成对齐无关且可在对象群体中局部对应的几何特征。该方法将对象视为椭球体内部的微分同胚变形，并使用骨架表示进行建模。实验结果表明，在解剖对象（如海马体）的形状分类任务中，与现有先进方法相比，该方法能显著提高分类性能，为对象统计分析提供了强大的基础。

> **摘要翻译:** 我们提出了一种在对象边界和内部计算拟合框架的方法，并利用它们作为基础，从中生成几何特征。这些特征不仅与对齐无关，最重要的是可以在对象群体中实现局部对应。我们描述了一种针对解剖对象的表示方法，旨在实现对象群体内的这种强定位对应，从而提供强大的对象统计数据。它通过将对象理解为椭球体内部闭包的微分同胚变形，并使用贯穿整个变形的骨架表示来生成目标对象模型，其中对象最初以边界网格的形式提供。通过对患有疾病个体和健康个体之间海马体形状的分类性能进行比较，我们将我们的方法与两种旨在捕获对象群体间几何对应并产生对统计有用的几何特征的最先进方法进行了比较，并且我们展示了这种被称为“进化s-rep”的新表示方法显著提高了分类性能。讨论了从每种表示中，特别是通过拟合框架，派生出的几何特征。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [811] [Learned Single-Pass Multitasking Perceptual Graphics for Immersive Displays](https://arxiv.org/abs/2408.07836)
> *沉浸式显示器的学习型单通道多任务感知图形*

*Doğa Yılmaz, He Wang, Towaki Takikawa, Duygu Ceylan, Kaan Akşit* | **Category: cs.CV, cs.GR, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 感知图形, 多任务学习, 沉浸式显示, 文本引导, 计算效率

**Comment:** 

> **TL;DR:** 针对沉浸式显示器，提出一种计算轻量级的学习型多任务感知图形模型，通过文本提示在一个推理步骤中执行多种感知任务，高效且高质量。

**AI_Comments:** 这项研究的创新点在于提出了一个“单通道多任务”的学习型感知图形模型，有效解决了传统方法中模型串联或专用模型带来的资源和管理挑战。通过文本提示进行控制提供了极大的灵活性和易用性，特别适用于需要动态调整效果的沉浸式应用和创意工作流。其在嵌入式平台上的评估也凸显了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有沉浸式显示技术中的多重感知图形方法（如注视点渲染、去噪）在资源有限的设备上运行时面临功耗和计算资源挑战。简单地串联或训练专用模型可能导致模型管理问题和资源耗尽。

**Method:** 提出了一种计算轻量级的学习型多任务感知图形模型。该模型接收RGB图像和文本提示作为输入，在一个推理步骤中执行文本描述的感知任务。通过文本指导（使用形容词如“轻度”、“微弱”）实现灵活的感知效果强度控制。为训练模型，构建了一个包含源图像、感知增强图像和相应文本提示的数据集。

**Result:** 该方法以合理的计算开销实现了持续高质量的感知效果，支持多种排列组合和不同强度。模型在桌面和嵌入式平台上进行了评估，并通过用户研究验证了感知质量。

**Conclusion:** 该模型提供了一种灵活且计算高效的解决方案，能够通过文本指导支持沉浸式显示器中动态的感知图形需求，包括创意过程。

> **ai_Abstract:** 这篇论文提出了一种针对沉浸式显示器的计算轻量级学习型多任务感知图形模型。该模型能够通过文本提示在单次推理中执行多样的感知任务，有效解决了现有方法在资源受限设备上运行多重感知图形时的效率和管理问题。该方法通过文本指导实现了高质量且灵活的感知效果，并在桌面和嵌入式平台上进行了验证。

> **摘要翻译:** 新兴的沉浸式显示技术通过注视点渲染和去噪等感知图形方法有效利用资源。然而，运行多种感知图形方法对功耗和计算资源有限的设备提出了挑战。我们提出了一种计算轻量级的学习型多任务感知图形模型。给定RGB图像和文本提示，我们的模型可以在一个推理步骤中执行文本描述的感知任务。简单地将多个模型串联起来或训练专门的模型可能导致模型管理问题并耗尽计算资源。相比之下，我们灵活的方法以合理的计算开销实现了持续高质量的感知效果，支持使用文本提示中的形容词（例如“轻度”、“微弱”）以不同强度实现各种排列组合。文本指导为动态需求（如创作过程）提供了易用性。为了训练我们的模型，我们提出了一个包含源图像和感知增强图像以及相应文本提示的数据集。我们在桌面和嵌入式平台上评估了我们的模型，并通过用户研究验证了感知质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [816] [ReferEverything: Towards Segmenting Everything We Can Speak of in Videos](https://arxiv.org/abs/2410.23287)
> *ReferEverything：在视频中分割我们能说的一切*

*Anurag Bagchi, Zhipeng Bao, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 视频分割, 扩散模型, 零样本分割, 开放词汇, 视觉-语言映射

**Comment:** 

> **TL;DR:** REM是一个视频分割框架，它利用视频扩散模型来分割视频中可以通过自然语言描述的广泛概念，包括稀有和未见过的对象以及非对象动态概念。

**AI_Comments:** 该论文的创新点在于利用视频扩散模型的强大泛化能力，通过巧妙地改变其目标函数实现视频中任意可描述概念的分割，这为开放词汇视频分割提供了一个新颖且高效的范式。其能够处理稀有和未见概念以及非对象动态概念的能力，显示了其巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在视频中分割通过自然语言描述的广泛概念（特别是稀有、未见对象及非对象动态概念）方面存在挑战。

**Method:** 本文提出了REM框架，通过在小规模指代对象分割数据集上微调视频扩散模型来实现视频分割。其核心思想是，通过将生成模型的预测目标从预测噪声转变为预测掩码潜在变量，从而完整保留生成模型的架构，以利用其在互联网规模数据上学习到的通用视觉-语言映射。

**Result:** 模型能够准确分割稀有和未见过的对象，尽管仅在有限类别上训练。它能轻松泛化到非对象动态概念（如烟雾、雨滴），并在新的Ref-VPS基准上得到验证。REM在域内数据集（如Ref-DAVIS）上与现有技术相当，在域外数据集上表现优于现有技术高达12个IoU点，这得益于生成式预训练。研究还表明，视频生成技术的进步直接改善了分割效果。

**Conclusion:** REM框架通过利用视频扩散模型的强大生成预训练能力，实现了对视频中广泛概念（包括稀有对象和非对象动态概念）的高效和泛化分割，并证明了视频生成与分割之间的积极关联。

> **ai_Abstract:** 本文介绍了REM框架，旨在利用微调后的视频扩散模型实现视频中通过自然语言描述的广泛概念的分割。REM通过将生成模型的预测目标从预测噪声转变为预测掩码潜在变量，有效利用了预训练的视觉-语言映射，从而能准确分割稀有、未见对象以及非对象动态概念。实验结果表明，REM在域内数据集上与现有技术持平，在域外数据集上表现更优，并揭示了视频生成技术的进步对分割效果有积极影响。

> **摘要翻译:** 我们提出了REM，一个用于分割视频中可以通过自然语言描述的广泛概念的框架。我们的方法通过在小规模指代对象分割数据集上微调视频扩散模型，利用了这些模型在互联网规模数据上学习到的通用视觉-语言映射。我们的关键见解是，通过将其目标从预测噪声转变为预测掩码潜在变量，来保留生成模型的整体架构。由此产生的模型能够准确分割稀有和未见过的对象，尽管它只在有限的类别上进行过训练。此外，它还可以毫不费力地泛化到非对象动态概念，例如烟雾或雨滴，这在我们新的指代视频过程分割（Ref-VPS）基准中得到了证明。REM在域内数据集（如Ref-DAVIS）上的表现与最先进技术相当，同时在域外数据集上表现优于它们高达12个IoU点，这得益于生成式预训练的力量。我们还表明，视频生成方面的进步直接改善了分割效果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [820] [Viewpoint Consistency in 3D Generation via Attention and CLIP Guidance](https://arxiv.org/abs/2412.02287)
> *通过注意力与CLIP引导实现3D生成中的视角一致性*

*Qing Zhang, Zehao Chen, Jinguang Tong, Jing Zhang, Jie Hong, Xuesong Li* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D生成, 视角一致性, 雅努斯问题, 注意力机制, CLIP引导

**Comment:** 

> **TL;DR:** 本文提出了一种名为ACG的无调优方法，通过自适应控制交叉注意力图和基于CLIP的视图-文本相似性来解决文本到3D生成中的“雅努斯问题”，显著减少了几何不一致性。

**AI_Comments:** 本文创新性地指出了“雅努斯问题”的根源在于扩散模型的视角生成偏差，并提出了ACG这一无调优、即插即用的解决方案。其结合注意力控制和CLIP引导，提供了一种有效且高效的方法来提升3D生成中的视角一致性，对现有文本到3D框架具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前的文本到3D生成技术存在几何不一致性，即“雅努斯问题”。本文指出其根本原因是扩散模型中的视角生成偏差，导致实际生成视角与优化3D模型所需的预期视角之间存在显著差距。

**Method:** 本文提出了一种名为“注意力与CLIP引导”（ACG）的无调优方法。ACG通过自适应控制交叉注意力图来增强所需的视角，利用基于CLIP的视图-文本相似性过滤掉错误的视角，并采用分阶段提示的粗到细优化策略逐步细化3D生成。

**Result:** 大量实验表明，ACG方法显著减少了“雅努斯问题”，且不影响生成速度。它是一个高效的即插即用组件，可用于现有的文本到3D框架。

**Conclusion:** ACG机制通过解决扩散模型中的视角生成偏差，有效提升了文本到3D生成中的视角一致性，且具有高效性和易用性。

> **ai_Abstract:** 本文针对文本到3D生成中普遍存在的“雅努斯问题”（几何不一致性），提出了一种名为“注意力与CLIP引导”（ACG）的无调优解决方案。该问题源于扩散模型中的视角生成偏差。ACG通过自适应注意力控制、CLIP视图-文本相似性过滤以及粗到细的优化策略，有效纠正了视角偏差，显著提升了3D生成的视角一致性，且不牺牲生成速度，可作为现有框架的高效即插即用组件。

> **摘要翻译:** 尽管文本到3D生成技术最近取得了进展，但目前的方法常遭受几何不一致性，通常称为“雅努斯问题”。本文确定了雅努斯问题的根本原因：扩散模型中的视角生成偏差，这在实际生成的视角与优化3D模型所需的预期视角之间造成了显著差距。为了解决这个问题，我们提出了一种名为“注意力与CLIP引导”（ACG）的无调优方法。ACG通过自适应控制交叉注意力图来增强所需的视角，利用基于CLIP的视图-文本相似性过滤掉错误的视角，并采用分阶段提示的粗到细优化策略逐步细化3D生成。大量实验表明，我们的方法显著减少了雅努斯问题，且不影响生成速度，使ACG成为现有文本到3D框架的高效、即插即用组件。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [826] [RoboTron-Drive: All-in-One Large Multimodal Model for Autonomous Driving](https://arxiv.org/abs/2412.07689)
> *RoboTron-Drive：自动驾驶一体化大型多模态模型*

*Zhijian Huang, Chengjian Feng, Feng Yan, Baihui Xiao, Zequn Jie, Yujie Zhong, Xiaodan Liang, Lin Ma* | **Category: cs.CV, cs.MM, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 大型多模态模型, 自动驾驶, 泛化能力, 感知, 规划

**Comment:** 

> **TL;DR:** RoboTron-Drive是一个通用的多模态大模型，旨在解决当前自动驾驶方法在单一数据集和特定任务上的局限性，通过课程预训练和多数据集微调，在多种感知、预测和规划任务上实现最先进的性能，并具备零样本泛化能力。

**AI_Comments:** RoboTron-Drive的创新之处在于其“一体化”设计，通过整合多种数据类型和任务，旨在实现更强的泛化能力。其采用的课程预训练和多数据集微调策略，以及在零样本迁移上的优异表现，都突显了其在解决自动驾驶领域数据和任务碎片化问题上的潜力。这对于实际自动驾驶系统的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的自动驾驶（AD）数据驱动方法倾向于专注于单一数据集和特定任务，忽视了其整体能力和泛化能力。本文旨在弥补这些差距。

**Method:** 本文提出了RoboTron-Drive，一个通用的多模态大模型，能够处理图像和多视角视频等多样化数据输入，并执行感知、预测和规划等广泛的自动驾驶任务。该模型首先进行课程预训练以处理各种视觉信号并执行基本的视觉理解和感知任务。随后，通过增强和标准化各种AD数据集来微调模型，使其成为自动驾驶的一体化大型多模态模型。

**Result:** RoboTron-Drive在六个公共基准测试中进行了评估，并在三个未见过的数据集上进行了零样本迁移，在所有任务上都取得了最先进的性能。

**Conclusion:** RoboTron-Drive作为自动驾驶领域的一个有前景的解决方案，在处理多样化数据和执行广泛任务方面表现出色，并展示了强大的泛化能力。

> **ai_Abstract:** 本文提出了RoboTron-Drive，一个面向自动驾驶的一体化大型多模态模型，旨在解决现有方法在单一数据集和特定任务上的局限性。该模型通过课程预训练处理多样化视觉输入，并结合多数据集微调，使其能够执行感知、预测和规划等广泛的自动驾驶任务。实验结果表明，RoboTron-Drive在多个公共基准测试和零样本迁移任务上均达到了最先进的性能，展现了其强大的通用性和泛化能力。

> **摘要翻译:** 大型多模态模型（LMMs）通过整合大型语言模型，在自动驾驶（AD）领域展示了卓越的理解和解释能力。尽管取得了进步，但当前的数据驱动AD方法倾向于集中于单一数据集和特定任务，忽视了其整体能力和泛化能力。为了弥补这些差距，我们提出了RoboTron-Drive，一个通用的多模态大模型，旨在处理多样化的数据输入，如图像和多视角视频，同时执行广泛的AD任务，包括感知、预测和规划。最初，模型进行课程预训练以处理各种视觉信号并执行基本的视觉理解和感知任务。随后，我们增强并标准化了各种AD数据集以微调模型，从而形成了一个用于自动驾驶的一体化LMM。为了评估其通用能力和泛化能力，我们在六个公共基准测试中进行了评估，并在三个未见过的数据集上进行了零样本迁移，RoboTron-Drive在所有任务上都取得了最先进的性能。我们希望RoboTron-Drive能成为现实世界自动驾驶的一个有前景的解决方案。项目页面和代码：https://github.com/zhijian11/RoboTron-Drive。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [831] [A Differentiable Wave Optics Model for End-to-End Computational Imaging System Optimization](https://arxiv.org/abs/2412.09774)
> *计算成像系统端到端优化的可微分波动光学模型*

*Chi-Jui Ho, Yash Belhe, Steve Rotenberg, Ravi Ramamoorthi, Tzu-Mao Li, Nicholas Antipa* | **Category: cs.CV** | **Updated: 2025-08-06**

**Keywords:** 可微分光学, 波动光学, 端到端优化, 计算成像, 像差和衍射

**Comment:** 

> **TL;DR:** 提出了一种可微分波动光学模型，用于计算成像系统端到端优化，解决了现有方法忽略波动光学效应导致鲁棒性差的问题。

**AI_Comments:** 该论文的创新点在于提出了一个高效的可微分波动光学模型，解决了计算成像系统端到端优化中长期存在的物理精度与计算成本之间的矛盾。它强调了波动光学效应在成像系统设计中的重要性，通过实验证明了忽略这些效应会导致系统性能和鲁棒性下降，为未来计算成像系统的设计提供了更准确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的计算成像系统端到端优化方法因计算成本高，难以同时建模光传输中的像差和衍射，导致其忽略波动光学效应或离轴像差，从而使得设计出的系统鲁棒性差，引发对鲁棒性的担忧。

**Method:** 提出了一种可微分光学模拟器，能够高效地对复合光学系统的像差和衍射进行建模。利用该模拟器对场景重建和分类进行端到端优化。

**Result:** 实验结果表明，在建模波动光学时，镜头和算法会采用不同的配置。未考虑波动光学优化的系统在测试时引入波动光学效应后性能会下降。

**Conclusion:** 准确的波动光学建模对于优化成像系统以实现鲁棒、高性能的应用至关重要。

> **ai_Abstract:** 本文提出了一种可微分光学模拟器，能够高效地在计算成像系统的端到端优化中同时建模复合光学系统的像差和衍射。针对现有方法因计算成本高而忽略波动光学效应导致系统鲁棒性差的问题，该模拟器使得在场景重建和分类任务中进行更精确的优化成为可能。实验证明，波动光学建模对镜头和算法配置有显著影响，且未考虑波动光学优化会导致系统性能下降，强调了其在实现鲁棒高性能成像系统中的关键作用。

> **摘要翻译:** 端到端优化，即同时优化光学和算法，已成为计算成像系统设计中一种强大的数据驱动方法。该方法通过整合可微分光学模拟器生成测量结果和算法从测量结果中提取信息，通过反向传播实现联合优化。然而，由于计算成本高，在复合光学系统的端到端优化中，同时对光传输中的像差和衍射进行建模具有挑战性。因此，大多数现有方法通过忽略波动光学效应或离轴像差来牺牲物理精度，这引发了对所得设计鲁棒性的担忧。在本文中，我们提出了一种可微分光学模拟器，可以高效地对复合光学系统的像差和衍射进行建模。利用该模拟器，我们对场景重建和分类进行了端到端优化。实验结果表明，镜头和算法会根据是否建模波动光学而采用不同的配置。我们还发现，在测试时引入波动光学效应后，未考虑波动光学优化的系统性能会下降。这些发现强调了在优化成像系统以实现鲁棒、高性能应用中准确波动光学建模的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [836] [ESVQA: Perceptual Quality Assessment of Egocentric Spatial Videos](https://arxiv.org/abs/2412.20423)
> *ESVQA：以自我为中心的空间视频感知质量评估*

*Xilei Zhu, Huiyu Duan, Liu Yang, Yucheng Zhu, Xiongkuo Min, Guangtao Zhai, Patrick Le Callet* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 以自我为中心视频, 空间视频, 感知质量评估, ESVQAD, ESVQAnet

**Comment:** 

> **TL;DR:** 该研究提出了一种针对以自我为中心的沉浸式空间视频的感知质量评估方法，包括构建首个相关数据集ESVQAD和提出多维度双目特征融合模型ESVQAnet，并在实验中表现出优异性能。

**AI_Comments:** 该论文的创新点在于首次关注以自我为中心的沉浸式空间视频的质量评估，并构建了首个相关数据集ESVQAD，填补了该领域的空白。提出的ESVQAnet模型结合了多维度双目特征，在性能上显著优于现有模型，并展现了良好的泛化能力，对XR领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着扩展现实（XR）的快速发展，以自我为中心的空间拍摄和显示技术增强了用户的沉浸感和参与度，但目前缺乏对以自我为中心的空间视频体验质量（QoE）的评估研究。

**Method:** 该研究引入了第一个以自我为中心的空间视频质量评估数据库（ESVQAD），包含600个使用Apple Vision Pro捕获的视频及其平均意见分数（MOSs）。此外，提出了一种新颖的多维度双目特征融合模型ESVQAnet，该模型整合了双目空间、运动和语义特征来预测整体感知质量。

**Result:** 实验结果表明，ESVQAnet在具身感知质量评估任务上显著优于16种最先进的VQA模型，并在传统VQA任务上表现出强大的泛化能力。

**Conclusion:** 该论文成功构建了首个以自我为中心的空间视频质量评估数据库，并提出了一个高性能的ESVQAnet模型，有效解决了以自我为中心的空间视频的感知质量评估问题，并展现了良好的泛化能力。

> **ai_Abstract:** 本研究旨在解决以自我为中心的沉浸式空间视频的感知质量评估问题，因为现有研究不足。作者构建了首个大规模以自我为中心的空间视频质量评估数据库ESVQAD，并提出了一个新颖的多维度双目特征融合模型ESVQAnet。实验证明ESVQAnet在具身感知质量评估任务上表现优异，并具有良好的泛化能力。

> **摘要翻译:** 随着扩展现实（XR）的快速发展，以自我为中心的空间拍摄和显示技术进一步增强了用户的沉浸感和参与度，提供了更具吸引力和互动性的体验。评估以自我为中心的空间视频的体验质量（QoE）对于确保高质量的观看体验至关重要。然而，相关的研究仍然缺乏。在本文中，我们使用具身体验的概念来强调这种更沉浸式的体验，并研究了一个新问题，即以自我为中心的空间视频的具身感知质量评估。具体来说，我们引入了第一个以自我为中心的空间视频质量评估数据库（ESVQAD），该数据库包含600个使用Apple Vision Pro捕获的以自我为中心的空间视频及其相应的平均意见分数（MOS）。此外，我们提出了一种新颖的多维度双目特征融合模型，命名为ESVQAnet，该模型整合了双目空间、运动和语义特征来预测整体感知质量。实验结果表明，ESVQAnet在具身感知质量评估任务上显著优于16种最先进的VQA模型，并在传统VQA任务上表现出强大的泛化能力。数据库和代码可在https://github.com/iamazxl/ESVQA获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [841] [FullTransNet: Full Transformer with Local-Global Attention for Video Summarization](https://arxiv.org/abs/2501.00882)
> *FullTransNet：用于视频摘要的局部-全局注意力全Transformer*

*Libin Lan, Lu Jiang, Tianshu Yu, Xiaojuan Liu, Zhongshi He* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频摘要, Transformer, 局部-全局注意力, 编码器-解码器, 稀疏注意力

**Comment:** 

> **TL;DR:** FullTransNet提出了一种带有编码器-解码器结构和局部-全局稀疏注意力的全Transformer模型，用于视频摘要，在SumMe和TVSum数据集上实现了最先进的性能，同时保持了较低的计算成本。

**AI_Comments:** FullTransNet的创新之处在于将全Transformer的编码器-解码器架构引入视频摘要任务，并结合了创新的局部-全局稀疏注意力机制。这种设计不仅解决了传统方法在处理长距离依赖和计算效率上的问题，还在保持高性能的同时降低了资源需求，为视频摘要领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视频摘要方法（如循环神经网络、卷积神经网络和仅编码器Transformer）在并行性、建模长距离依赖性以及提供明确的生成能力方面存在局限性。

**Method:** 提出了一种名为FullTransNet的Transformer类架构。它采用带有编码器-解码器结构的全Transformer作为视频摘要的替代架构。它用局部和全局稀疏注意力代替标准的完全注意力机制，以捕获长距离依赖性并显著降低计算成本，该机制主要应用于编码器侧。

**Result:** 在SumMe和TVSum数据集上，模型分别达到了54.4%和63.9%的F-分数，超过了次优方法0.1%和0.3%，同时保持了相对较低的计算和内存需求。

**Conclusion:** FullTransNet在视频摘要方面表现出有效性和效率，通过其全Transformer编码器-解码器结构和局部-全局稀疏注意力，在基准数据集上取得了领先的性能。

> **ai_Abstract:** 本文提出了一种名为FullTransNet的视频摘要模型，它采用全Transformer的编码器-解码器结构，并引入了局部-全局稀疏注意力机制。该模型旨在克服现有方法在并行性、长距离依赖建模和生成能力方面的不足。通过将局部和全局注意力结合并应用于编码器，FullTransNet显著降低了计算成本，同时有效捕获了视频中的长距离依赖。在SumMe和TVSum数据集上的实验结果表明，FullTransNet在F-分数上取得了领先的性能，且计算资源消耗较低，验证了其有效性和效率。

> **摘要翻译:** 视频摘要旨在生成原始视频的紧凑、信息丰富和具有代表性的概要，这对于浏览、分析和理解视频内容至关重要。视频摘要中的主要方法主要依赖于循环或卷积神经网络，最近则依赖于仅编码器Transformer架构。然而，这些方法通常在并行性、建模长距离依赖性以及提供明确的生成能力方面存在一些局限性。为了解决这些问题，我们提出了一种名为FullTransNet的Transformer类架构，其中包含两方面的思想。首先，它使用带有编码器-解码器结构的全Transformer作为视频摘要的替代架构。由于全Transformer是专门为序列转导任务设计的，因此将其直接应用于视频摘要既直观又有效。其次，它用局部和全局稀疏注意力组合代替了标准的完全注意力机制，使模型能够捕获长距离依赖性，同时显著降低计算成本。这种局部-全局稀疏注意力仅应用于编码器侧，因为大部分计算发生在此处，从而进一步提高了效率。在两个广泛使用的基准数据集SumMe和TVSum上进行的广泛实验表明，我们的模型分别实现了54.4%和63.9%的F-分数，同时保持了相对较低的计算和内存需求。这些结果分别超过了次优方法0.1%和0.3%，验证了FullTransNet的有效性和效率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [846] [RIFLEx: A Free Lunch for Length Extrapolation in Video Diffusion Transformers](https://arxiv.org/abs/2502.15894)
> *RIFLEx：视频扩散Transformer长度外推的免费午餐*

*Min Zhao, Guande He, Yixiao Chen, Hongzhou Zhu, Chongxuan Li, Jun Zhu* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频生成, 长度外推, 扩散Transformer, 位置嵌入, RIFLEx

**Comment:** 

> **TL;DR:** RIFLEx通过降低位置嵌入的固有频率，在不额外训练的情况下，实现了视频扩散Transformer的高质量长度外推，解决了现有方法的时间重复和运动减速问题。

**AI_Comments:** RIFLEx的创新性在于它从频率分析的角度解决了视频长度外推的挑战，通过对位置嵌入的微小调整，实现了显著的性能提升，特别是其“训练免费”的特性极具吸引力，降低了应用门槛。这表明深入理解模型内部机制对于解决复杂问题的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频生成模型虽然能生成高质量的分钟级视频，但生成更长且具有时间一致性的视频仍是巨大挑战，且现有长度外推方法会导致时间重复或运动减速问题。

**Method:** 本研究系统分析了位置嵌入中频率分量的作用，识别出主要控制外推行为的固有频率。基于此洞察，提出了RIFLEx方法，通过降低固有频率来抑制重复并保持运动一致性，无需任何额外修改。

**Result:** RIFLEx在最先进的视频扩散Transformer上实现了高质量的2倍长度外推，且无需任何训练。此外，通过少量微调（无需长视频），RIFLEx还能提高质量并实现3倍长度外推。

**Conclusion:** RIFLEx通过对位置嵌入的频率分析，提供了一种简单而有效的方法，显著提升了视频扩散Transformer的长度外推能力，且实现了训练免费或少量微调的优势。

> **ai_Abstract:** RIFLEx是一种针对视频扩散Transformer的创新方法，通过分析位置嵌入的频率成分，识别并降低了控制视频长度外推行为的固有频率。该方法无需额外训练即可实现高质量的2倍视频长度外推，有效解决了现有方法中常见的视频时间重复和运动减速问题。通过少量微调，RIFLEx还能进一步提升视频质量并支持3倍长度外推，为长视频生成提供了高效且低成本的解决方案。

> **摘要翻译:** 视频生成领域的最新进展已使模型能够合成高质量的、长达一分钟的视频。然而，生成更长且具有时间一致性的视频仍然是一个重大挑战，且现有的长度外推方法会导致时间重复或运动减速。在这项工作中，我们系统地分析了位置嵌入中频率分量的作用，并识别出主要控制外推行为的固有频率。基于这一洞察，我们提出了RIFLEx，这是一种极简而有效的方法，它通过降低固有频率来抑制重复，同时保持运动一致性，而无需任何额外的修改。RIFLEx提供了一个真正的免费午餐——在完全无需训练的情况下，在最先进的视频扩散Transformer上实现了高质量的2倍外推。此外，它通过少量微调（无需长视频）即可提高质量并实现3倍外推。项目页面和代码：https://riflex-video.github.io/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [851] [BUFFER-X: Towards Zero-Shot Point Cloud Registration in Diverse Scenes](https://arxiv.org/abs/2503.07940)
> *BUFFER-X：实现多样化场景下零样本点云配准*

*Minkyun Seo, Hyungtae Lim, Kanghee Lee, Luca Carlone, Jaesik Park* | **Category: cs.CV, cs.RO, eess.IV** | **Updated: 2025-08-07**

**Keywords:** 点云配准, 零样本, 泛化性, BUFFER-X, 鲁棒性

**Comment:** 

> **TL;DR:** BUFFER-X提出了一种零样本点云配准方法，通过自适应参数、最远点采样和尺度归一化解决了现有深度学习方法泛化性差的问题，并在11个数据集上表现出显著的泛化能力。

**AI_Comments:** 该论文的创新点在于提出了BUFFER-X这一零样本点云配准框架，通过解决现有方法对特定环境参数的依赖、学习型检测器的鲁棒性问题以及尺度差异问题，显著提升了点云配准的泛化能力。其方法论中的自适应参数确定、最远点采样和分块尺度归一化是关键创新。此外，构建包含11个多样化数据集的通用性基准测试也具有重要意义，为后续研究提供了评估标准。该工作对于推动点云配准在实际复杂场景中的应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于深度学习的点云配准方法泛化性差，在新的环境中需要重新训练或手动调参。主要限制因素包括：对环境特定体素大小和搜索半径的依赖、学习型关键点检测器域外鲁棒性差、以及原始坐标使用加剧尺度差异。

**Method:** BUFFER-X是一个零样本配准流程，通过以下方法解决问题：(a) 自适应确定体素大小/搜索半径；(b) 使用最远点采样绕过学习型检测器；(c) 利用分块尺度归一化实现一致的坐标边界。特别地，该方法提出了多尺度分块描述符生成和跨尺度的分层内点搜索，以提高在多样化场景中的鲁棒性。

**Result:** BUFFER-X在包含各种室内/室外场景和传感器模态的11个数据集上构建了一个新的通用性基准测试，结果表明其在没有先验信息或手动参数调整的情况下，对测试数据集实现了显著的泛化能力。

**Conclusion:** BUFFER-X通过解决现有方法的泛化性限制，实现了在多样化场景下零样本点云配准，并在广泛的基准测试中验证了其卓越的泛化能力。

> **ai_Abstract:** BUFFER-X提出了一种创新的零样本点云配准方法，旨在克服现有深度学习方法在多样化场景中泛化能力差的问题。该方法通过自适应确定体素大小/搜索半径、采用最远点采样替代学习型检测器以及利用分块尺度归一化来解决关键限制。BUFFER-X引入了多尺度分块描述符生成和分层内点搜索以增强鲁棒性。实验结果在一个包含11个不同数据集的新通用性基准测试上验证了BUFFER-X无需预先信息或手动调参即可实现卓越的泛化能力。

> **摘要翻译:** 最近基于深度学习的点云配准进展提高了泛化能力，但大多数方法对于每个新环境仍然需要重新训练或手动调整参数。在本文中，我们确定了限制泛化能力的三个关键因素：(a) 依赖于环境特定的体素大小和搜索半径，(b) 基于学习的关键点检测器域外鲁棒性差，以及 (c) 原始坐标的使用，这加剧了尺度差异。为了解决这些问题，我们提出了一个名为 BUFFER-X 的零样本配准流程，通过 (a) 自适应确定体素大小/搜索半径，(b) 使用最远点采样绕过学习型检测器，以及 (c) 利用分块尺度归一化实现一致的坐标边界。特别是，我们提出了多尺度分块描述符生成和跨尺度的分层内点搜索，以提高在多样化场景中的鲁棒性。我们还提出了一个使用11个数据集（涵盖各种室内/室外场景和传感器模态）的新型通用性基准测试，结果表明 BUFFER-X 在没有先验信息或手动参数调整的情况下，对测试数据集实现了显著的泛化能力。我们的代码可在 https://github.com/MIT-SPARK/BUFFER-X 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [856] [Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature Awareness](https://arxiv.org/abs/2503.09336)
> *3D点云中基于曲率感知的隐蔽性补丁级后门攻击*

*Yu Feng, Dingxin Zhang, Runkai Zhao, Yong Xia, Heng Huang, Weidong Cai* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 3D点云, 后门攻击, 补丁级攻击, 曲率感知, 隐蔽性

**Comment:** 

> **TL;DR:** 提出SPBA，一种针对3D点云的隐蔽性补丁级后门攻击，通过在视觉不敏感区域注入触发器，提高了隐蔽性和优化效率。

**AI_Comments:** SPBA的创新之处在于首次提出了针对3D点云的补丁级后门攻击，并通过结合曲率感知机制，将触发器注入到视觉不敏感区域，显著提高了攻击的隐蔽性。同时，通过优化统一的补丁级触发器，解决了现有样本级攻击计算成本高的问题，提升了优化效率。这对于理解和防御3D点云领域的后门攻击具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D点云后门攻击主要依赖样本级全局修改，导致低不可感知性；优化虽能提高隐蔽性，但样本级触发器优化计算成本高。

**Method:** 提出隐蔽性补丁级后门攻击（SPBA），首次将点云分解为局部补丁。利用基于曲率的不可感知性分数引导触发器注入到视觉不敏感的补丁中。通过优化一个统一的补丁级触发器来扰动选定补丁的光谱特征。

**Result:** 在ModelNet40和ShapeNetPart上的大量实验表明，SPBA在攻击有效性和抵抗防御方法方面均超越了现有最先进的后门攻击。

**Conclusion:** SPBA通过创新的补丁级攻击和曲率感知机制，有效解决了3D点云后门攻击中隐蔽性差和计算成本高的问题，并展现出优越的攻击性能和防御鲁棒性。

> **ai_Abstract:** 本文提出SPBA，一种针对3D点云的补丁级后门攻击框架。针对现有方法样本级全局修改导致隐蔽性低和优化成本高的问题，SPBA将点云分解为局部补丁，并利用曲率感知分数在视觉不敏感区域注入触发器。通过扰动选定补丁的光谱特征，SPBA在保持高隐蔽性的同时显著提高了优化效率。实验证明SPBA在攻击效果和防御抵抗方面优于现有SOTA方法。

> **摘要翻译:** 后门攻击通过植入隐藏后门对深度神经网络（DNN）构成严重威胁，这些后门可以通过预定义触发器激活，恶意操纵模型行为。现有的3D点云后门攻击主要依赖于样本级的全局修改，这导致了较低的不可感知性。尽管优化可以提高隐蔽性，但优化样本级触发器会显著增加计算成本。为了解决这些限制，我们提出了隐蔽性补丁级后门攻击（SPBA），这是首个针对3D点云的补丁级后门攻击框架。具体而言，SPBA将点云分解为局部补丁，并采用基于曲率的不可感知性分数来引导触发器注入到视觉上不敏感的补丁中。通过优化一个统一的补丁级触发器来扰动选定补丁的光谱特征，SPBA在保持高隐蔽性的同时显著提高了优化效率。在ModelNet40和ShapeNetPart上的大量实验进一步证明，SPBA在攻击有效性和抵抗防御方法方面均超越了现有最先进的后门攻击。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [861] [CM-Diff: A Single Generative Network for Bidirectional Cross-Modality Translation Diffusion Model Between Infrared and Visible Images](https://arxiv.org/abs/2503.09514)
> *CM-Diff：一种用于红外和可见图像之间双向跨模态翻译扩散模型的单一生成网络*

*Bin Hu, Chenqiang Gao, Shurui Liu, Junjie Guo, Fang Chen, Fangcen Liu, Junwei Han* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 红外图像, 可见图像, 图像翻译, 扩散模型, 双向翻译

**Comment:** 

> **TL;DR:** CM-Diff是一种新的扩散模型，能够同时对红外和可见图像进行双向跨模态翻译，解决了现有方法单向或性能不佳的问题。

**AI_Comments:** 该论文提出了一种新颖的扩散模型CM-Diff，解决了红外和可见图像之间双向翻译的挑战。其创新点在于集成了双向扩散训练（BDT）和统计约束推理（SCI），实现了对两种模态数据分布的同步建模和精确控制，避免了传统循环一致性方法的潜在性能问题。这对于缓解信息缺失和促进双模态数据集增强具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的红外和可见图像翻译方法要么只能实现单向模态翻译，要么依赖循环一致性进行双向模态翻译，这可能导致次优性能。

**Method:** 本文提出了一种双向跨模态翻译扩散模型（CM-Diff），用于同时建模红外和可见模态的数据分布。通过结合翻译方向标签进行训练指导和跨模态特征控制来解决挑战。具体而言，通过新颖的双向扩散训练（BDT）来学习数据分布和理解模态差异，并提出了统计约束推理（SCI）以确保生成图像紧密遵循目标模态的数据分布。

**Result:** 实验结果表明，CM-Diff优于现有最先进的方法。

**Conclusion:** CM-Diff在生成双模态数据集方面具有潜力。

> **ai_Abstract:** CM-Diff是一种创新的双向跨模态翻译扩散模型，专为红外和可见图像设计，旨在解决现有方法在双向翻译中的局限性。它通过引入双向扩散训练（BDT）和统计约束推理（SCI）来同时学习两种模态的数据分布和差异，并确保生成图像的质量。实验证明，CM-Diff在性能上超越了现有技术，并为生成高质量双模态数据集提供了新的途径。

> **摘要翻译:** 图像翻译是缓解红外和可见模态信息不足的关键方法之一，同时也有助于增强特定模态的数据集。然而，现有的红外和可见图像翻译方法要么实现单向模态翻译，要么依赖循环一致性进行双向模态翻译，这可能导致次优性能。在这项工作中，我们提出了双向跨模态翻译扩散模型（CM-Diff），用于同时建模红外和可见模态的数据分布。我们通过在训练过程中结合翻译方向标签进行指导和跨模态特征控制来解决这一挑战。具体而言，我们将建立两种模态之间的映射关系视为学习数据分布和理解模态差异的过程，这通过一种新颖的双向扩散训练（BDT）实现。此外，我们提出了一种统计约束推理（SCI），以确保生成的图像紧密遵循目标模态的数据分布。实验结果表明，我们的CM-Diff优于现有最先进的方法，突出了其生成双模态数据集的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [866] [TIME: Temporal-Sensitive Multi-Dimensional Instruction Tuning and Robust Benchmarking for Video-LLMs](https://arxiv.org/abs/2503.09994)
> *TIME: 视频大语言模型的时序敏感多维指令微调与鲁棒基准测试*

*Yunxiao Wang, Meng Liu, Wenqi Liu, Xuemeng Song, Bin Wen, Fan Yang, Tingting Gao, Di Zhang, Guorui Zhou, Liqiang Nie* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 视频大语言模型, 时序理解, 指令微调, 基准测试, 多任务学习

**Comment:** 

> **TL;DR:** 视频大语言模型在时间理解方面表现不佳。本文提出了一个时序敏感的多维指令微调数据集，一种无需额外标注的多任务提示微调方法，以及一个更鲁棒的评估基准，以显著提升视频大语言模型的时间理解能力并避免捷径。

**AI_Comments:** 该论文解决了视频大语言模型在时序理解方面的关键瓶颈，通过创新的数据集构建、无标注的多任务微调方法以及鲁棒的基准测试，为提升视频LLMs的实际应用能力提供了重要贡献。其减少对昂贵标注的依赖和避免捷径评估的策略尤为值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 视频大语言模型在视频问答等任务中表现出色，但其时间理解能力仍不理想。本文旨在解决这一局限性。

**Method:** 本文策划了一个专门的指令微调数据集，侧重于增强五个关键维度的时序理解。引入了一种多任务提示微调方法，将时序敏感任务无缝集成到现有指令数据集中，无需额外标注，以减少对昂贵时序标注的依赖。此外，开发了一个新颖的时序敏感视频理解基准，该基准弥补了现有基准在维度覆盖上的不足，并严格过滤潜在的捷径，确保更准确的评估。

**Result:** 广泛的实验结果表明，该方法显著增强了视频大语言模型的时序理解能力，同时避免了对捷径的依赖。

**Conclusion:** 通过引入时序敏感的多维指令微调数据集、无需额外标注的多任务提示微调方法以及更鲁棒的评估基准，本文成功提升了视频大语言模型的时间理解能力并确保了评估的准确性。

> **ai_Abstract:** 本文针对视频大语言模型在时序理解方面的不足，提出了TIME框架。该框架包含一个时序敏感的多维指令微调数据集，一个无需额外时序标注的多任务提示微调方法，以及一个更全面、更鲁棒的评估基准。实验证明，该方法能有效提升视频大语言模型的时序理解能力并避免模型利用捷径。

> **摘要翻译:** 视频大语言模型在视频问答等任务中取得了显著的性能，然而，它们的时序理解能力仍然不尽如人意。为了解决这一局限性，我们策划了一个专门的指令微调数据集，该数据集侧重于增强五个关键维度的时序理解。为了减少对昂贵时序标注的依赖，我们引入了一种多任务提示微调方法，该方法将时序敏感任务无缝集成到现有指令数据集中，无需额外的标注。此外，我们开发了一个新颖的时序敏感视频理解基准，该基准不仅弥补了现有基准在维度覆盖上的不足，而且严格过滤了潜在的捷径，确保了更准确的评估。广泛的实验结果表明，我们的方法显著增强了视频大语言模型的时序理解能力，同时避免了对捷径的依赖。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [871] [Learning Disease State from Noisy Ordinal Disease Progression Labels](https://arxiv.org/abs/2503.10440)
> *从嘈杂的序数疾病进展标签中学习疾病状态*

*Gustav Schmidt, Holger Heidrich, Philipp Berens, Sarah Müller* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 嘈杂序数标签, 疾病进展, nAMD, 疾病分类, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种新方法，利用嘈杂的序数疾病进展标签（如“更好”、“更差”或“稳定”）来学习可解释的疾病表征，并能有效进行眼部疾病（nAMD）活动分类，即使只使用图像对进行训练。

**AI_Comments:** 该论文的创新点在于其针对嘈杂序数标签学习的独特方法，特别是在医疗影像领域。通过将疾病进展建模为序数分类任务并结合多项技术（独立编码、反对称等变性、序数感知和不确定性估计），模型有效应对了数据噪声和泛化能力挑战。其在仅用图像对训练的情况下，能对单张图像进行分类，并在小样本场景下表现出色，这对于临床应用具有重要意义，尤其是在数据标注成本高昂的医疗领域。

<details>
  <summary>Details</summary>

**Motivation:** 医学影像中，从嘈杂的序数标签中学习是一个关键挑战。具体来说，研究人员希望探究能否利用序数疾病进展标签（更好、更差或稳定）来学习一种能够分类疾病状态的表征。

**Method:** 本研究将医疗访视之间疾病进展建模的问题转化为一个带有序数等级的分类任务。为增强泛化能力，模型通过以下方式进行定制：1) 独立图像编码，2) 反对称逻辑空间等变性，3) 序数尺度感知。此外，通过学习不确定性估计进行损失重加权来解决标签噪声问题。

**Result:** 所提出的方法学习到了一种可解释的疾病表征，使得在仅使用带有序数疾病进展标签的图像对进行训练的情况下，也能在相关任务（nAMD活动分类）上实现强大的小样本性能。

**Conclusion:** 该方法成功地从嘈杂的序数疾病进展标签中学习到了可解释的疾病表征，并能够有效地对相关疾病状态进行分类，即使是在有限的数据和噪声条件下。这表明序数标签在医疗影像分析中具有重要潜力。

> **ai_Abstract:** 本研究旨在解决医学影像中从嘈杂序数标签学习的挑战。针对新生血管性年龄相关性黄斑变性（nAMD），作者将疾病进展建模为一个序数分类任务。模型通过独立图像编码、反对称逻辑空间等变性和序数尺度感知来提升泛化能力，并通过学习不确定性估计来处理标签噪声。该方法成功学习到一种可解释的疾病表征，即使仅用带有序数进展标签的图像对训练，也能在nAMD活动分类任务上展现出优异的小样本性能。

> **摘要翻译:** 从嘈杂的序数标签中学习是医学影像中的一个关键挑战。在这项工作中，我们提出序数疾病进展标签（更好、更差或稳定）是否可以用于学习一种能够分类疾病状态的表示。对于新生血管性年龄相关性黄斑变性（nAMD），我们将医疗访视之间疾病进展建模的问题转换为一个带有序数等级的分类任务。为了增强泛化能力，我们通过以下方式根据问题设置定制了模型：(1) 独立图像编码，(2) 反对称逻辑空间等变性，以及 (3) 序数尺度感知。此外，我们通过学习不确定性估计进行损失重加权来解决标签噪声问题。我们的方法学习到了一种可解释的疾病表示，使得在仅使用带有序数疾病进展标签的图像对进行训练的情况下，也能在相关任务（从单张图像进行nAMD活动分类）上实现强大的小样本性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [876] [MotionStreamer: Streaming Motion Generation via Diffusion-based Autoregressive Model in Causal Latent Space](https://arxiv.org/abs/2503.15451)
> *MotionStreamer：基于因果潜在空间的扩散自回归模型流式运动生成*

*Lixing Xiao, Shunlin Lu, Huaijin Pi, Ke Fan, Liang Pan, Yueer Zhou, Ziyong Feng, Xiaowei Zhou, Sida Peng, Jingbo Wang* | **Category: cs.CV** | **Updated: 2025-08-07**

**Keywords:** 流式运动生成, 扩散模型, 自回归模型, 因果潜在空间, 文本条件生成

**Comment:** 

> **TL;DR:** MotionStreamer提出了一种新的基于扩散的自回归模型，用于文本条件流式运动生成，解决了现有方法的延迟和误差积累问题。

**AI_Comments:** MotionStreamer的创新之处在于其将连续因果潜在空间与概率自回归模型相结合，有效解决了流式运动生成中离散化带来的信息损失和误差累积问题。这种方法对于实时、长期的运动生成具有重要意义，尤其是在虚拟现实、动画和人机交互等领域。其能够支持多轮和动态合成的能力也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在文本条件流式运动生成方面存在挑战，例如扩散模型受限于预定义的运动长度，而基于GPT的方法因离散非因果分词而导致响应延迟和误差累积。

**Method:** 本文提出了MotionStreamer，一个将连续因果潜在空间融入概率自回归模型的新框架。连续潜在空间减轻了离散化造成的信息损失，并有效减少了长期自回归生成中的误差累积。此外，通过在当前和历史运动潜在空间之间建立时间因果依赖关系，模型充分利用可用信息实现准确的在线运动解码。

**Result:** 实验表明，MotionStreamer优于现有方法，并提供了更多应用，包括多轮生成、长期生成和动态运动合成。

**Conclusion:** MotionStreamer通过引入连续因果潜在空间和建立时间因果依赖，成功解决了文本条件流式运动生成中的挑战，并在性能和应用范围上超越了现有方法。

> **ai_Abstract:** MotionStreamer提出了一种新颖的框架，用于文本条件流式运动生成，旨在克服现有扩散模型和GPT-based方法在运动长度限制、响应延迟和误差积累方面的不足。该方法将连续因果潜在空间整合到概率自回归模型中，通过连续潜在变量减少信息损失和误差累积，并通过建立时间因果依赖实现准确的在线运动解码。实验证明，MotionStreamer在性能上优于现有方法，并支持多轮、长期生成和动态运动合成等多种应用。

> **摘要翻译:** 本文解决了文本条件流式运动生成的挑战，这需要我们根据可变长度的历史运动和输入的文本来预测下一步的人体姿态。现有方法难以实现流式运动生成，例如，扩散模型受到预定义运动长度的限制，而基于GPT的方法由于离散的非因果分词而遭受响应延迟和误差累积问题。为了解决这些问题，我们提出了MotionStreamer，一个将连续因果潜在空间融入概率自回归模型的新框架。连续潜在空间减轻了离散化造成的信息损失，并有效减少了长期自回归生成中的误差累积。此外，通过在当前和历史运动潜在空间之间建立时间因果依赖关系，我们的模型充分利用可用信息以实现准确的在线运动解码。实验表明，我们的方法优于现有方法，同时提供了更多应用，包括多轮生成、长期生成和动态运动合成。项目页面：https://zju3dv.github.io/MotionStreamer/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [130] [Resistance Technologies: Moving Beyond Alternative Designs](https://arxiv.org/abs/2508.05223)
> *抵抗技术：超越替代设计*

*Iness Ben Guirat, Jan Tobias Mühlberg* | **Category: cs.CY** | **Updated: 2025-08-07**

**Keywords:** 抵抗技术, 可持续性, 主权, 反监控, 环境危机

**Comment:** 

> **TL;DR:** 本文认为，当前的可持续技术方法不足以应对环境危机及其严重后果。作者提出了“抵抗技术”的概念，旨在保护我们免受战争、种族灭绝和新形式殖民主义等后果的影响，并强调反监控技术是主权的基础组成部分，应纳入未来的可持续性讨论。

**AI_Comments:** 这篇论文通过将环境可持续性与战争、种族灭绝和殖民主义等地缘政治后果联系起来，并引入根植于主权和反监控的“抵抗技术”概念，提供了一个新颖的视角。其创新之处在于将可持续性讨论从单纯的技术解决方案扩展到更深层次的社会和政治保护层面。

<details>
  <summary>Details</summary>

**Motivation:** 应对环境危机，并指出当前可持续技术（例如开发替代方案或资源优化）的讨论不足以解决环境破坏带来的严重后果（如战争、种族灭绝和殖民主义）。

**Method:** 文章通过提出并定义“抵抗技术”这一新概念来展开论证，将其“保护”的内涵与主权而非军事防御联系起来。作者进一步论证反监控技术是主权的基础组成部分，并旨在与“限制计算”社区及其他领域展开对话，以定义“抵抗技术”的其他核心价值观。

**Result:** 论文定义了“抵抗技术”为旨在保护人类免受环境破坏后果（如战争、种族灭绝和新形式殖民主义）影响的技术，并强调反监控技术是主权的基础组成部分，也是未来可持续性讨论的重要组成部分。

**Conclusion:** 论文呼吁将重点转向“抵抗技术”，并旨在与“限制计算”社区及其他领域展开对话，以进一步定义这一概念的其他基本方面或核心价值观，特别是强调反监控技术对可持续性讨论的重要性。

> **ai_Abstract:** 本文认为，当前针对环境危机的可持续技术方法，即开发替代方案或优化资源，是不足够的。作者提出“抵抗技术”的概念，旨在设计能够保护人类免受环境破坏更深远后果（如战争、种族灭绝和新形式殖民主义）的技术。论文将这种“保护”定义为主权的一部分，而非军事防御，并强调反监控技术是主权的基础组成部分，因此应成为未来可持续性讨论的核心。文章旨在开启一场与“限制计算”社区及其他领域的对话，以进一步明确“抵抗技术”的核心价值观。

> **摘要翻译:** 关于可持续技术的讨论源于我们所面临的环境崩溃的认知。在本文中，我们认为解决这场危机需要的不仅仅是开发当前在线服务的可持续替代方案，或者利用各种仪表板和人工智能优化资源。相反，重点必须转向设计能够保护我们免受环境破坏后果影响的技术。在这些后果中，战争、种族灭绝和新形式的殖民主义可能是最重要的。我们认为“保护”不是西方国家所主张的军事防御，而是主权的一部分。我们试图为这类技术定义“抵抗技术”一词，并进一步论证反监控技术是主权的基础组成部分，必须成为未来围绕可持续性讨论的一部分。最后，我们的论文旨在与“限制计算”社区及其他领域展开对话，以定义我们认为作为“抵抗技术”核心价值的其他技术基本方面或概念。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [137] [Everything You Need to Know About CS Education: Open Results from a Survey of More Than 18,000 Participants](https://arxiv.org/abs/2508.05286)
> *计算机科学教育的方方面面：一项针对18,000多名参与者的调查开放结果*

*Katsiaryna Dzialets, Aleksandra Makeeva, Ilya Vlasov, Anna Potriasaeva, Aleksei Rostovskii, Yaroslav Golubev, Anastasiia Birillo* | **Category: cs.CY, cs.HC, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 计算机科学教育, 大规模调查, 开放数据集, 学习者多样性, AI使用

**Comment:** 

> **TL;DR:** 对全球18,032名计算机科学学习者进行了一项大规模调查，生成了一个开放数据集，以更新对CS教育的理解，并支持未来研究。

**AI_Comments:** 这项研究的创新之处在于其前所未有的规模和广度，涵盖了来自173个国家的18,032名参与者，并涉及了当前CS教育中的多个关键方面，包括AI和新兴学习形式。其重要性在于提供了一个开放的大规模数据集，为未来的研究提供了宝贵资源，有助于更全面地理解和改进全球CS教育。

<details>
  <summary>Details</summary>

**Motivation:** 计算机科学教育是一个动态领域，受多种因素影响。现有大规模调查提供了有价值的见解，但新趋势（如AI）、新学习形式（如IDE内学习）和学习者多样性的增加，需要进行一项更新的全面研究。

**Method:** 作者对来自173个国家的18,032名学习者进行了一项大规模调查。调查涵盖了正式教育、学习形式、AI使用、挑战和动机等广泛主题。论文介绍了调查结果作为开放数据集，并描述了方法和调查问题。

**Result:** 论文公布了这项大规模调查的结果，作为一个开放数据集。它还提出了三个可能的研究方向：学习挑战、新兴学习形式以及IDE内学习形式的见解。

**Conclusion:** 该数据集旨在支持进一步的研究，并促进计算机教育的进步。

> **ai_Abstract:** 本文介绍了对来自173个国家的18,032名计算机科学学习者进行的一项大规模调查的结果，将其作为一个开放数据集发布。鉴于AI等新趋势和学习者多样性的增加，该研究旨在提供对CS教育的全面更新。调查涵盖了广泛的主题，包括正式教育、学习形式和AI使用。该论文还详细说明了研究方法和调查问题，并提出了基于数据集的潜在研究方向，以期促进计算机教育领域的未来研究和发展。

> **摘要翻译:** 计算机科学教育是一个动态领域，其许多方面影响着学习者的路径。虽然这些方面通常被单独深入研究，但进行触及许多主题的更广泛的大规模研究也很重要，因为它们使我们能够将不同的结果相互联系起来。过去的大规模调查提供了有价值的见解，然而，新趋势（例如AI）、新学习形式（例如IDE内学习）的出现以及学习者多样性的增加，凸显了对更新的综合研究的需求。为了解决这个问题，我们对来自173个国家的18,032名学习者进行了一项调查，确保了多样化的代表性并探索了广泛的主题——正规教育、学习形式、AI使用、挑战、动机等等。本文介绍了这项调查的结果作为一个开放数据集，描述了我们的方法和调查问题，并作为一个激励性示例，强调了该数据中三个可能的研究方向：学习中的挑战、新兴形式以及对IDE内形式的见解。该数据集旨在支持进一步研究并促进计算机教育的进步。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [145] [A Conceptual Model and Methodology for Sustainability-aware, IoT-enhanced Business Processes](https://arxiv.org/abs/2508.05301)
> *一种面向可持续发展、物联网增强型业务流程的概念模型与方法论*

*Victoria Torres Bosch, Ronny Seiger, Manuela Albert Albiol, Antoni Mestre Gascon, Pedro Jose Valderas Aranda* | **Category: cs.CY, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 物联网, 业务流程, 可持续性, 概念模型, 方法论

**Comment:** 

> **TL;DR:** 本文提出了一种概念模型和方法论，旨在利用物联网分析和提升业务流程的可持续性，超越传统环境维度的关注。

**AI_Comments:** 该论文的创新点在于提出了一个超越传统环境视角的、更全面的可持续性概念模型和方法论，并将其与物联网技术相结合，为业务流程的绿色化转型提供了新的系统性框架。其重要性在于为企业和组织提供了利用物联网技术实现多维度可持续发展目标的实用工具和指导。

<details>
  <summary>Details</summary>

**Motivation:** 物联网（IoT）正在革新业务流程，并展现出提升可持续性的巨大潜力。然而，现有的业务流程管理（BPM）中关于可持续性的研究主要集中于环境方面，缺乏一个系统性方法来全面解决可持续性问题，以实现整体和持久的影响。

**Method:** 本文提出了一种概念模型和一个结构化的方法论。概念模型旨在正式表示关键的可持续性概念，通过突出物联网设备如何支持和促进可持续性来连接BPM和IoT。该方法论指导对现有业务流程进行系统分析，识别机会，并实现可持续发展导向的、物联网增强型业务流程。

**Result:** 该方法通过一个来自旅游领域的运行实例和医疗保健领域的案例研究进行了说明。

**Conclusion:** 该工作提出了一个概念模型和方法论，旨在利用物联网的力量来测量和改进业务流程的可持续性，超越单一环境维度，实现更全面和持久的影响。

> **ai_Abstract:** 本文针对现有业务流程管理中可持续性研究主要关注环境维度的问题，提出了一种利用物联网（IoT）提升业务流程（BPs）可持续性的概念模型和方法论。该概念模型形式化了关键可持续性概念，并阐明了IoT设备如何支持可持续性；该方法论则指导系统分析现有业务流程、识别机会并实施可持续发展导向的、物联网增强型业务流程。论文通过旅游和医疗保健领域的案例进行了示例。

> **摘要翻译:** 物联网（IoT）提供的实时数据收集和自动化能力正在彻底改变和改造业务流程（BPs），使其成为物联网增强型业务流程，展现出改善可持续性的巨大潜力。尽管在业务流程管理（BPM）中已有研究，但可持续性研究主要集中在环境问题上。然而，要实现全面和持久的影响，需要一种系统方法来解决环境维度之外的可持续性问题。这项工作提出了一种概念模型和一个结构化的方法论，旨在分析物联网在衡量和改善业务流程可持续性方面的潜力。该概念模型正式表示了关键的可持续性概念，通过强调物联网设备如何支持和促进可持续性来连接BPM和IoT。该方法论指导对现有业务流程进行系统分析，识别机会，并实施可持续发展导向的、物联网增强型业务流程。该方法通过一个来自旅游领域的运行实例和医疗保健领域的案例研究进行了说明。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [147] [Learning AI Auditing: A Case Study of Teenagers Auditing a Generative AI Model](https://arxiv.org/abs/2508.04902)
> *学习AI审计：青少年审计生成式AI模型的案例研究*

*Luis Morales-Navarro, Michelle Gan, Evelyn Yu, Lauren Vogelstein, Yasmin B. Kafai, Danaé Metaxa* | **Category: cs.CY, cs.HC** | **Updated: 2025-08-06**

**Keywords:** AI审计, 青少年, 生成式AI, 偏见, AI素养

**Comment:** 

> **TL;DR:** 本研究探讨了青少年如何通过算法审计识别并理解生成式AI模型中的偏见，并发现他们能有效参与并提出独特见解。

**AI_Comments:** 这项研究创新性地将AI审计的主体从专业人士扩展到青少年，证明了非专业用户在识别AI偏见方面的潜力。其重要性在于，它不仅为AI教育提供了一种实践性方法，赋能年轻一代批判性地理解和参与AI治理，而且揭示了青少年视角下可能被专业审计忽视的新型偏见（如年龄偏见），为算法公平性研究带来了新鲜的视角和数据。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI/ML技术日益融入年轻人的生活，迫切需要培养青少年的AI素养，使其具备技术知识并认识到社会影响。传统上由专家进行的算法审计，现在有研究表明非专业用户也能有效参与。

**Method:** 研究人员与14名青少年（14-15岁）进行了为期两周的参与式设计工作坊，审计了TikTok Effect House背后的生成式AI模型，并描述了青少年如何进行审计，包括决定审计内容、分析数据和沟通结果。

**Result:** 参与者在整个活动中都积极投入且富有创造力，独立提出并探索了专业审计中不常见的考量，例如与年龄相关的偏见。尽管青少年发现的种族、性别和年龄代表性变化数量与研究人员略有不同，但他们得出了相似的结论。

**Conclusion:** 本研究强调了审计作为学习活动的潜力，可以激发AI素养的培养，赋能青少年批判性地审视AI系统，并为算法危害研究贡献新视角。

> **ai_Abstract:** 本研究考察了高中生如何通过算法审计来识别和理解日常接触的AI/ML工具中的偏见。鉴于AI技术日益融入青少年生活，培养其AI素养的需求迫切。研究团队与14名青少年（14-15岁）开展了为期两周的参与式设计工作坊，审计了TikTok Effect House的生成式AI模型。案例研究展示了青少年如何独立进行审计，包括发现并深入探讨了专业审计中不常见的年龄相关偏见。尽管青少年发现的偏见数量与专家略有差异，但结论相似。本研究表明，审计能有效促进AI素养学习，赋能青少年批判性思考AI系统，并为算法危害研究带来新视角。

> **摘要翻译:** 本研究调查了高中生如何参与算法审计，以识别和理解他们日常接触的人工智能和机器学习（AI/ML）工具中的偏见。随着AI/ML技术日益融入年轻人的生活，迫切需要为青少年提供AI素养，以建立技术知识并提高对社会影响的认识。算法审计（也称为AI审计）传统上由专家用于评估潜在的有害偏见，但最近的研究表明，非专业用户也可以有效地参与审计。我们与14名青少年（14-15岁）进行了为期两周的参与式设计工作坊，他们在其中审计了TikTok Effect House背后的生成式AI模型，这是一种用于创建交互式TikTok滤镜的工具。我们提出了一个案例研究，描述了青少年如何进行审计，从决定审计内容到使用多种策略分析数据以及沟通他们的结果。我们的发现表明，参与者在整个活动中都积极投入且富有创造力，独立提出并探索了新的考量，例如与年龄相关的偏见，这些在专业审计中并不常见。我们利用在算法审计方面的专业知识对他们的发现进行了三角验证，以检查工作坊是否支持参与者在审计中得出连贯的结论。尽管青少年发现的种族、性别和年龄代表性变化数量与我们略有不同，但我们得出了相似的结论。这项研究强调了审计激发学习活动以培养AI素养、赋能青少年批判性地审视AI系统以及为算法危害研究贡献新视角的潜力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [158] [Invisible Women in Digital Diplomacy: A Multidimensional Framework for Online Gender Bias Against Women Ambassadors Worldwide](https://arxiv.org/abs/2311.17627)
> *数字外交中的隐形女性：针对全球女大使在线性别偏见的多维框架*

*Yevgeniy Golovchenko, Karolina Stańczak, Rebecca Adler-Nissen, Patrice Wangen, Isabelle Augenstein* | **Category: cs.CY, cs.SI** | **Updated: 2025-08-07**

**Keywords:** 数字外交, 性别偏见, 女性大使, 在线可见度, 社交媒体

**Comment:** 

> **TL;DR:** 本研究首次对社交媒体上女外交官的待遇进行了全球分析，发现尽管语言和负面反应中的性别偏见不明显，但女性大使的在线可见度存在显著差异，她们获得的转发量比男性少66.4%。

**AI_Comments:** 本文的创新之处在于首次对全球范围内的女性外交官在社交媒体上的待遇进行了系统性分析，并引入了多维多语言的研究方法。其重要性在于揭示了在线可见度这一被忽视的性别偏见形式，即女性外交官在社交媒体上获得的关注度远低于男性，这对于理解数字外交中的性别不平等具有重要意义。研究结果挑战了传统上对在线敌意和负面反馈的关注，转而强调了“隐形”这一微妙而普遍的偏见形式。

<details>
  <summary>Details</summary>

**Motivation:** 尽管有证据表明女性在外交政策中常遭受在线敌意，但针对外交官的在线性别偏见的程度尚未被探索。本研究旨在进行首次全球分析，以填补这一空白。

**Method:** 本研究采用多维多语言方法，关注三个关键要素：性别化语言、针对外交官推文的负面情绪以及女性外交官的可见度。数据集涵盖来自164个国家的大使及其推文和65种语言的直接回复。分析方法使用自动化内容和情感分析。

**Result:** 研究发现存在关键的性别偏见。对外交推文的回复语言轻微性别化，主要与国际事务相关；女性大使收到的负面反应并不比男性多。然而，在线可见度存在显著差异，女性获得的转发量比男性少66.4%。

**Conclusion:** 揭示了社交媒体上女性外交官的“隐形”问题，并希望激发对国际政治中在线偏见的进一步研究。

> **ai_Abstract:** 本研究首次对全球女性外交官在社交媒体上的待遇进行多维分析，旨在探究在线性别偏见。研究采用多语言数据集，涵盖来自164个国家的女性大使的推文及其回复，并利用自动化内容和情感分析。结果显示，尽管语言和负面反应中的性别偏见不显著，但女性外交官的在线可见度存在严重不平等，她们获得的转发量远低于男性。这揭示了数字外交中女性的“隐形”问题，并呼吁对国际政治中的在线偏见进行更多研究。

> **摘要翻译:** 尽管越来越多的证据表明外交政策领域的女性经常遭受在线敌意，但针对外交官的在线性别偏见的程度仍未被探索。本文首次对社交媒体上女性外交官的待遇进行了全球分析。通过引入一种研究在线性别偏见的多维多语言方法，本研究聚焦于三个关键要素：性别化语言、针对外交官推文的负面情绪以及女性外交官的可见度。我们独特的数据集涵盖了来自164个国家的大使、她们的推文以及用65种不同语言对这些推文的直接回复。通过自动化内容和情感分析，我们的发现揭示了一个关键的性别偏见。对外交推文的回复语言只有轻微的性别化，并且主要与国际事务相关；总的来说，女性大使收到的推文负面反应并不比男性多。然而，在线可见度上的显著差异作为一个重要的性别偏见形式脱颖而出。女性获得的转发量比男性惊人地少了66.4%。通过揭示社交媒体上女性外交官的“隐形”问题，我们希望激发对国际政治中在线偏见的进一步研究。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [165] [Inequality in the Age of Pseudonymity](https://arxiv.org/abs/2508.04668)
> *匿名时代的不平等*

*Aviv Yaish, Nir Chemaya, Lin William Cong, Dahlia Malkhi* | **Category: cs.CY, cs.GT, econ.TH** | **Updated: 2025-08-07**

**Keywords:** 不平等, 匿名性, Sybils, 基尼系数, 数字平台

**Comment:** 

> **TL;DR:** 本研究探讨了在匿名（例如基于互联网或区块链）平台中，虚假身份（Sybils）如何扭曲基尼系数等不平等衡量指标。研究表明，在存在Sybils的情况下，现有方法无法准确衡量不平等，而提出的抗Sybils措施虽然能缓解问题，但牺牲了细粒度评估能力。

**AI_Comments:** 这项研究创新性地指出了在匿名数字经济中，虚假身份（Sybils）对不平等衡量指标的根本性影响。它揭示了现有衡量方法在面对Sybils时的局限性，并提出了新的抗Sybils衡量指标，尽管这些新方法存在细粒度评估的限制。这对于理解和制定数字平台上的政策具有重要意义，因为它挑战了直接应用传统经济学工具的假设。

<details>
  <summary>Details</summary>

**Motivation:** 不平等衡量指标（如基尼系数）越来越多地应用于数字平台，但在匿名设置（如互联网或区块链平台）中，参与者创建多个虚假身份（Sybils）的能力是一个关键挑战。研究旨在分析Sybils如何无意中扭曲不平等指标，并探讨在这种背景下衡量不平等的挑战。

**Method:** 研究分析了在匿名设置中不平等衡量指标的表现。首先，证明了当存在Sybils时，使用满足标准期望属性的不平等衡量指标无法正确衡量经济体的不平等。其次，提出了满足放宽版期望属性的抗Sybils衡量指标类别，并通过完全刻画它们，证明了其结构限制了其细粒度评估不平等的能力。此外，研究还展示了包括基尼系数在内的流行指标并非抗Sybils的。最后，研究考察了在匿名和传统环境中导致Sybils产生的动态。

**Result:** 研究发现，当经济体中存在Sybils时，不可能使用满足文献中标准期望属性的不平等衡量指标来正确衡量经济体的不平等。研究提出了抗Sybils的衡量指标类别，这些指标满足了上述期望属性的放宽版本，但其结构限制了它们在细粒度层面评估不平等的能力。此外，研究表明流行的衡量指标（如基尼系数）并非抗Sybils的。

**Conclusion:** 在匿名环境中，Sybils的存在会扭曲不平等衡量指标，导致无法使用传统方法准确衡量不平等。虽然可以设计抗Sybils的衡量指标，但它们在细粒度评估方面存在固有限制，且流行的不平等衡量指标（如基尼系数）对Sybils攻击不具备抵抗力。

> **ai_Abstract:** 本研究探讨了在匿名数字平台中，虚假身份（Sybils）对不平等衡量指标的影响。研究发现，在Sybils存在的情况下，传统的衡量方法（如基尼系数）无法准确评估不平等。论文提出了抗Sybils的衡量指标，这些指标虽然能缓解问题，但其结构限制了细粒度分析能力。这表明在匿名环境中准确衡量不平等面临根本性挑战。

> **摘要翻译:** 不平等衡量指标如基尼系数被用于为政策制定提供信息和动力，并且越来越多地应用于数字平台。我们分析了在匿名设置中这些指标的表现，这在基于互联网或区块链的平台中很常见。一个关键的挑战是参与者能够创建多个虚假身份，也称为“Sybils”。虽然有些参与者这样做是为了保护他们的隐私，但我们表明这可能会无意中扭曲不平等指标。正如我们所示，当使用满足文献中标准期望属性的不平等衡量指标时，经济体中Sybils的存在意味着不可能正确衡量经济体的不平等。然后，我们提出了满足上述期望属性的放宽版本的抗Sybils衡量指标类别，并通过完全刻画它们，我们证明了所施加的结构限制了它们在细粒度层面评估不平等的能力。此外，我们表明流行的衡量指标，如著名的基尼系数，并非抗Sybils的。最后，我们考察了在匿名和传统环境中导致Sybils产生的动态。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [242] [Data-Aware Socratic Query Refinement in Database Systems](https://arxiv.org/abs/2508.05061)
> *数据库系统中数据感知苏格拉底式查询优化*

*Ruiyuan Zhang, Chrysanthi Kosyfaki, Xiaofang Zhou* | **Category: cs.DB, cs.IR** | **Updated: 2025-08-07**

**Keywords:** 自然语言查询, 查询优化, 对话系统, 数据感知, 歧义消除

**Comment:** 

> **TL;DR:** 本文提出了数据感知苏格拉底式指导（DASG），一个对话式的查询增强框架，它将交互式澄清作为数据库系统中的一流操作符，以解决自然语言查询中的歧义。

**AI_Comments:** 该论文的创新点在于将交互式澄清作为数据库系统中的一流操作符，并将其视为一种优化决策，通过量化歧义和成本效益来智能地选择澄清问题。这代表了一种从被动翻译到主动协作的范式转变，对于提高自然语言查询的可用性和准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决自然语言查询中的歧义，并提高查询精度，同时保持效率。

**Method:** DASG将对话视为优化决策，仅当预期执行成本降低超过交互开销时才提出澄清问题。系统通过语言模糊性、模式接地置信度和关系型及向量后端上的预计成本来量化歧义。算法通过结合语义相关性、基于目录的信息增益和潜在成本降低来选择最佳澄清。

**Result:** 在三个数据集上的评估结果表明，DASG在保持效率的同时提高了查询精度。

**Conclusion:** DASG建立了一个合作分析范式，其中系统积极参与查询制定，而不是被动地翻译用户请求，从而提高了查询精度并保持了效率。

> **ai_Abstract:** 本文提出数据感知苏格拉底式指导（DASG），一个对话式查询增强框架，旨在通过将交互式澄清作为数据库系统中的一流操作符来解决自然语言查询中的歧义。DASG根据成本效益决定何时提出澄清问题，并通过量化歧义（语言模糊性、模式接地置信度、预计成本）和优化选择（语义相关性、信息增益、成本降低）来实现。实验结果表明，DASG在提高查询精度的同时保持了效率，开创了系统主动参与查询制定的合作分析模式。

> **摘要翻译:** 本文提出了数据感知苏格拉底式指导（DASG），一个对话式的查询增强框架，它将交互式澄清作为数据库系统中的一流操作符，以解决自然语言查询中的歧义。DASG将对话视为优化决策，仅当预期执行成本降低超过交互开销时才提出澄清问题。系统通过语言模糊性、模式接地置信度以及关系型和向量后端上的预计成本来量化歧义。我们的算法通过结合语义相关性、基于目录的信息增益和潜在成本降低来选择最佳澄清。我们在三个数据集上评估了我们提出的框架。结果表明，DASG在保持效率的同时提高了查询精度，建立了一个合作分析范式，其中系统积极参与查询制定，而不是被动地翻译用户请求。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [250] [Theseus: A Distributed and Scalable GPU-Accelerated Query Processing Platform Optimized for Efficient Data Movement](https://arxiv.org/abs/2508.05029)
> *Theseus：一个为高效数据移动优化的分布式可扩展GPU加速查询处理平台*

*Felipe Aramburú, William Malpica, Kaouther Abrougui, Amin Aramoon, Romulo Auccapuclla, Claude Brisson, Matthijs Brobbel, Colby Farrell, Pradeep Garigipati, Joost Hoozemans, Supun Kamburugamuve, Akhil Nair, Alexander Ocsa, Johan Peltenburg, Rubén Quesada López, Deepak Sihag, Ahmet Uyar, Dhruv Vats, Michael Wendt, Jignesh M. Patel, Rodrigo Aramburú* | **Category: cs.DB, cs.DC** | **Updated: 2025-08-07**

**Keywords:** GPU加速, 分布式查询处理, 数据移动优化, 在线分析处理, Theseus

**Comment:** 

> **TL;DR:** Theseus是一个分布式GPU加速查询引擎，通过优化数据移动、内存利用和计算，显著提升了大规模数据查询处理的性能和成本效益。

**AI_Comments:** Theseus的创新之处在于其对数据移动、内存利用和计算的精细平衡，特别是在加速器（GPU）环境中。其通过定制的异步控制机制和优化的内存子系统，有效克服了大规模数据处理中GPU加速的常见瓶颈。与现有解决方案（如Databricks Photon）的对比结果突出显示了其显著的性能和成本优势，这对于需要处理海量数据的企业级应用具有重要意义。该系统在性能和资源效率方面取得了显著进步。

<details>
  <summary>Details</summary>

**Motivation:** 在线分析处理（OLAP）大规模数据集需要昂贵的分布式计算系统。为了降低成本并提高吞吐量，系统可以利用GPU等加速器，但这引入了许多关于数据移动的挑战。

**Method:** 本文提出了Theseus，一个生产就绪的企业级分布式加速器原生查询引擎。它通过专门的异步控制机制与硬件资源紧密耦合，用于网络通信、数据预加载、跨内存和存储的数据溢出以及GPU计算任务。内存子系统包含一个固定大小的页锁定主机内存分配机制，以提高吞吐量并减少内存碎片。

**Result:** 在云基础设施上，针对TPC-H基准测试（规模因子1k到30k），Theseus在成本相同的情况下，性能比Databricks Photon高出4倍。Theseus能够使用最少2个DGX A100 640GB节点处理TPC-H和TPC-DS基准测试中规模因子100k（100 TB规模）的所有查询。

**Conclusion:** Theseus通过优化数据移动和资源利用，显著提高了大规模GPU加速查询处理的效率和成本效益，证明了其在企业级应用中的可行性和优越性。

> **ai_Abstract:** Theseus是一个为大规模在线分析处理设计的分布式GPU加速查询平台。它通过优化数据移动、内存利用和计算，解决了现有系统中数据移动的挑战。该平台采用专门的异步控制机制和固定大小的页锁定内存分配，以提高吞吐量和减少内存碎片。在TPC-H基准测试中，Theseus在成本相同的情况下，性能比Databricks Photon高出4倍，并能以少量节点处理100TB规模的数据集，展现了其卓越的性能和成本效益。

> **摘要翻译:** 对数TB级数据集进行在线分析查询处理，只有通过昂贵的分布式计算系统才能实现。为了降低成本并提高吞吐量，系统可以利用GPU等加速器，这些加速器现在在计算基础设施中无处不在。这带来了许多挑战，其中大部分与何时、何地以及如何最好地在系统内移动数据有关。我们提出了Theseus——一个生产就绪的企业级分布式加速器原生查询引擎，旨在平衡基于加速器系统中的数据移动、内存利用和计算。专门的异步控制机制与硬件资源紧密耦合，用于网络通信、数据预加载、跨内存和存储的数据溢出以及GPU计算任务。内存子系统包含一个固定大小的页锁定主机内存分配机制，以提高吞吐量并减少内存碎片。在云基础设施上，针对规模因子从1k到30k的TPC-H基准测试，Theseus在成本相同的情况下，性能比Databricks Photon高出4倍。Theseus能够使用最少2个DGX A100 640GB节点处理TPC-H和TPC-DS基准测试中规模因子100k（100 TB规模）的所有查询。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [257] [OPTIMUMP2P: Fast and Reliable Gossiping in P2P Networks](https://arxiv.org/abs/2508.04833)
> *OPTIMUMP2P：P2P网络中快速可靠的流言传播*

*Nicolas Nicolaou, Onyeka Obi, Aayush Rajasekaran, Alejandro Bergasov, Aleksandr Bezobchuk, Kishori M. Konwar, Michael Meier, Santiago Paiva, Har Preet Singh, Swarnabha Sinha* | **Category: cs.DC** | **Updated: 2025-08-06**

**Keywords:** P2P网络, 流言算法, 随机线性网络编码, libp2p, 区块链

**Comment:** 

> **TL;DR:** OPTIMUMP2P引入随机线性网络编码，显著提升了P2P网络中信息传播的速度和可靠性，并能抵御恶意攻击，优于现有Gossipsub协议。

**AI_Comments:** 本文的创新点在于将随机线性网络编码（RLNC）应用于P2P网络中的流言传播算法，以解决现有协议在速度和面对恶意攻击时的可靠性问题。其重要性体现在为区块链等去中心化系统的信息传播提供了更高效、更健壮的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的流言算法（如libp2p中的floodsup和gossibsup）在去中心化系统中信息传播的性能和可靠性方面有提升空间，尤其是在存在恶意攻击者的情况下。

**Method:** 本文引入了OPTIMUMP2P，一种新的流言算法，它利用随机线性网络编码（RLNC）来加速P2P网络中的信息传播，同时确保可靠传输，即使面对能够破坏传输数据的恶意行为者。

**Result:** 在模拟和真实环境中进行的广泛评估结果表明，OPTIMUMP2P在性能上优于Gossipsub协议。以太坊基金会的初步研究也表明RLNC可以显著改善区块传播时间。

**Conclusion:** OPTIMUMP2P通过结合随机线性网络编码，显著提升了P2P网络中信息传播的速度和可靠性，即使在存在恶意攻击的情况下也能有效运行。

> **ai_Abstract:** 本文提出了一种名为OPTIMUMP2P的新型流言算法，旨在提升libp2p在P2P网络中的信息传播性能和可靠性。OPTIMUMP2P利用随机线性网络编码（RLNC）技术，不仅加速了信息传播，还能在存在恶意攻击者破坏数据的情况下确保可靠传输。通过模拟和真实环境的广泛评估，证明了OPTIMUMP2P在性能上优于Gossipsub协议。

> **摘要翻译:** 流言算法在去中心化系统中的信息传播中至关重要。因此，许多流言库已被开发并广泛使用，尤其是在区块链协议中用于区块和交易的传播。一个成熟的库是libp2p，它提供了两种流言算法：floodsup和gossibsup。这些算法能够将发布的消息传递给一组对等点。在这项工作中，我们旨在通过引入OPTIMUMP2P来增强libp2p的性能和可靠性。OPTIMUMP2P是一种新颖的流言算法，它利用随机线性网络编码（RLNC）的能力来加速点对点（P2P）网络中的信息传播，同时确保可靠传输，即使存在能够破坏传输数据的恶意行为者。以太坊基金会的初步研究已经证明了RLNC在显著改善区块传播时间方面的应用[14]。在这里，我们提供了在模拟和真实世界环境中进行的广泛评估结果，这些结果证明了OPTIMUMP2P相对于Gossipsub协议的性能提升。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [264] [Linear Search for Capturing an Oblivious Mobile Target in the Sender/Receiver Model](https://arxiv.org/abs/2508.04870)
> *在发送者/接收者模型中捕获无感知移动目标的线性搜索*

*Khaled Jawhar, Evangelos Kranakis* | **Category: cs.DC** | **Updated: 2025-08-06**

**Keywords:** 线性搜索, 无感知目标, 发送者/接收者模型, 机器人, 竞争比

**Comment:** 

> **TL;DR:** 本文研究了在发送者/接收者（S/R）通信模型下，两个具有不同通信能力的机器人如何通过线性搜索捕获一个无感知移动目标，并分析了捕获时间的竞争比。

**AI_Comments:** 本文的创新点在于将不对称的发送者/接收者（S/R）通信模型引入到线性搜索问题中，这与传统的对称通信模型不同，更贴近实际应用场景。研究通过设计新算法并分析竞争比，为理解通信能力差异对搜索效率的影响提供了理论基础。其重要性在于为多机器人协作搜索和捕获策略提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在理解不对称通信如何影响线性搜索的竞争比，特别是在机器人通信能力不同的情况下捕获移动目标的问题。

**Method:** 研究人员设计了新的线性搜索算法，并分析了捕获目标所需时间的竞争比。该方法考虑了机器人对搜索环境（如起始距离、移动速度、目标移动方向模型）的不同认知场景。

**Result:** 结果是对捕获目标所需时间的竞争比进行了分析，并考虑了机器人对搜索环境（如起始距离或移动速度、远离或靠近模型，或它们的组合）的各种认知场景。

**Conclusion:** 本研究有助于理解不对称通信如何影响线性搜索的竞争比。

> **ai_Abstract:** 本文研究了在发送者/接收者（S/R）通信模型下，两个具有不对称通信能力的机器人如何通过线性搜索捕获一个无感知移动目标。机器人可以进行面对面通信，其中一个机器人额外具备无线发送能力，另一个额外具备无线接收能力。研究设计了新的线性搜索算法，并分析了在不同目标移动模型（远离或靠近）和机器人对环境信息（如起始距离、速度）的不同认知场景下，捕获目标所需时间的竞争比。这项工作旨在深入理解不对称通信对线性搜索竞争比的影响。

> **摘要翻译:** 我们考虑了两个具有不同通信能力的自主机器人对一个无感知移动目标的线性搜索捕获问题。两个机器人在共定位时可以进行面对面（F2F）通信，此外，一个机器人是发送者（也可以无线发送消息），另一个是接收者（也可以无线接收消息）。这被称为发送者/接收者（S/R，简称）通信模型。机器人可以以最大速度1移动。移动目标从距原点距离d处开始，可以在“远离”模型中以速度v<1远离原点，或者在“靠近”模型中以速度v≥0向原点移动。我们假设机器人预先知道目标运动的方向（即是远离模型还是靠近模型）。为了捕获目标，两个机器人必须与目标共定位。
我们设计了新的线性搜索算法，并分析了捕获目标所需时间的竞争比。该方法考虑了与机器人对搜索环境（例如，移动体的起始距离或速度、远离或靠近模型，或它们的组合）的了解相关的各种场景。我们的研究有助于理解不对称通信如何影响线性搜索的竞争比。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [271] [Managing, Analyzing and Sharing Research Data with Gen3 Data Commons](https://arxiv.org/abs/2508.04944)
> *使用 Gen3 数据共享平台管理、分析和共享研究数据*

*Craig Barnes, Kyle Burton, Michael S. Fitzsimons, Hara Prasad Juvvala, Brienna Larrick, Christopher Meyer, Pauline Ribeyre, Ao Liu, Clint Malson, Noah Metoki-Shlubsky, Andrii Prokhorenkov, Jawad Qureshi, Radhika Reddy, L. Philip Schumm, Mingfei Shao, Trevar Simmons, Alexander VanTol, Peter Vassilatos, Aarti Venkat, Robert L. Grossman* | **Category: cs.DC** | **Updated: 2025-08-07**

**Keywords:** Gen3, 数据共享平台, 研究数据, FAIR数据, 开源平台

**Comment:** 

> **TL;DR:** Gen3 是一个开源数据平台，用于构建云端数据共享平台，以管理、分析和共享研究数据。

**AI_Comments:** Gen3 的创新之处在于其自动化数据门户和 FAIR API 的生成能力，极大地简化了数据共享平台的部署和数据访问。其基于标准的服务设计也保证了良好的互操作性，使其成为管理和共享大规模研究数据的强大工具。该平台的重要性在于其解决了研究数据管理、分析和共享的复杂性，促进了FAIR原则的实践。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是提供一个开源、云端的数据平台（Gen3），用于帮助研究社区管理、分析和共享研究数据，以应对大规模数据管理和互操作性的挑战。

**Method:** Gen3 通过定义数据模型来设置数据共享平台，然后自动生成用于搜索、探索、提交数据的门户以及用于程序化访问数据的 FAIR API。Gen3 基于少量标准化的软件服务构建，旨在支持当前和未来的组件，实现与其他数据平台和数据生态系统的互操作性。

**Result:** Gen3 已被用于构建十多个数据共享平台，总计包含超过 28 PB 的数据和 6400 万个 FAIR 数据对象。

**Conclusion:** Gen3 是一个可扩展、标准化的开源数据平台，能够有效地管理、分析和共享大规模研究数据，并支持与其他数据平台和生态系统的互操作性。

> **ai_Abstract:** Gen3 是一个开源的云端数据平台，旨在为研究社区提供数据管理、分析和共享的能力。它通过定义数据模型自动生成数据门户和 FAIR API，简化了数据共享平台的构建。Gen3 已成功应用于多个大规模数据共享平台，其基于标准的服务设计确保了与现有数据生态系统的互操作性。

> **摘要翻译:** Gen3 是一个用于构建数据共享平台的开源数据平台。数据共享平台是一个基于云的数据平台，用于与研究社区管理、分析和共享数据。Gen3 已被用于构建十多个数据共享平台，总计包含超过 28 PB 的数据和 6400 万个 FAIR 数据对象。要设置一个 Gen3 数据共享平台，首先需要定义一个数据模型。然后 Gen3 会自动生成：1) 用于搜索和探索数据共享平台中数据的门户；2) 用于向数据共享平台提交数据的门户；3) 用于程序化访问数据的 FAIR API。Gen3 基于少量标准化的软件服务构建，这些服务旨在支持当前和未来的 Gen3 组件，以便 Gen3 可以与其他数据平台和数据生态系统互操作。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [278] [Simulating LLM training workloads for heterogeneous compute and network infrastructure](https://arxiv.org/abs/2508.05370)
> *模拟异构计算和网络基础设施上的LLM训练工作负载*

*Sumit Kumar, Arjun Temura, Naman Sharma, Ramanjeet Singh, Meet Dadhania, Praveen Tammana, Satananda Burla, Abed Mohammad Kamaluddin, Rinku Shah* | **Category: cs.DC** | **Updated: 2025-08-07**

**Keywords:** LLM训练, 异构计算, 模拟器, 分布式训练, 性能预测

**Comment:** 

> **TL;DR:** 现有LLM训练模拟器假设基础设施是同构的，但实际环境是异构的。本文提出了一种新的异构感知分布式LLM模拟器，以准确预测训练时间。

**AI_Comments:** 这篇论文通过关注LLM训练模拟器中被忽视的异构性问题，弥补了现有研究与实际应用之间的重要差距。其创新点在于提出了一种能够考虑设备异构性的新模拟器设计，这对于在复杂真实的云计算环境中优化大型模型训练至关重要。该工作有望为未来的LLM系统设计和性能调优提供更准确的指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM训练模拟器假设计算和网络基础设施是同构的，但实际环境中设备的异构性是不可避免的，这导致了现有模拟器与实际需求之间的差距。

**Method:** 本文提出并设计了一种异构感知分布式LLM模拟器，该模拟器能够预测训练时间，并允许为设备组和设备到并行映射指定自定义配置。文中还讨论了构建该模拟器的设计要求、挑战以及非均匀工作负载分区等设计组件。

**Result:** 初步模拟结果表明，异构性对模型计算和通信时间有显著影响。

**Conclusion:** 开发一个异构感知的LLM训练模拟器对于准确预测训练时间并指导设计决策至关重要，因为异构性对训练性能有实际影响。

> **ai_Abstract:** 本文提出了一种异构感知分布式LLM训练模拟器，旨在解决现有模拟器忽略实际计算和网络基础设施异构性的问题。通过考虑设备异构性，该模拟器能够更准确地预测LLM训练时间，并支持自定义配置，从而克服了大规模GPU集群分布式训练中的性能优化挑战。初步结果证实了异构性对训练时间的影响。

> **摘要翻译:** 分布式模型训练中对大规模GPU集群日益增长的需求，对创新构成了重大障碍，尤其是在模型优化、性能调优和系统级增强方面。为了应对这一挑战，LLM训练模拟器被用于估算训练时间并指导设计决策。然而，最先进的LLM训练模拟器假设计算和网络基础设施是同构的。在实践中，由于云环境中的资源共享、设备代际的频繁更替以及芯片内互连固有的异构性，设备异构性是不可避免的。为了弥补现有技术与实际需求之间的差距，我们提出设计一种异构感知分布式LLM模拟器，该模拟器能够预测训练时间，同时允许抽象地指定设备组和设备到并行映射的自定义配置。我们提出了构建异构感知分布式机器学习训练模拟器的设计要求和挑战，并设计了非均匀工作负载分区等组件。我们的初步模拟结果证明了异构性对模型计算和通信时间的影响。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [285] [Adaptive Parallel Downloader for Large Genomic Datasets](https://arxiv.org/abs/2508.05511)
> *大型基因组数据集的自适应并行下载器*

*Rasman Mubtasim Swargo, Engin Arslan, Md Arifuzzaman* | **Category: cs.DC** | **Updated: 2025-08-07**

**Keywords:** 基因组数据, 并行下载, 自适应控制, 在线优化, FastBioDL

**Comment:** 

> **TL;DR:** 现有工具下载大型基因组数据效率低下，FastBioDL通过自适应并行下载，显著提高了下载速度并优化了资源利用。

**AI_Comments:** 这篇论文的创新点在于将数据下载过程视为一个在线优化问题，并利用梯度下降算法实现并发连接数的自适应调整，从而显著提高了大型基因组数据下载的效率。其重要性在于解决了现有工具在动态网络环境下性能瓶颈的问题，使得研究人员能够更快速、高效地获取海量生物数据，无需依赖昂贵的商业软件或复杂协议，促进了高性能数据检索的普及。

<details>
  <summary>Details</summary>

**Motivation:** 现代下一代测序（NGS）项目产生TB级数据，研究人员需要从公共存储库下载。现有下载工具采用静态并发设置，无法适应动态网络条件，导致带宽利用率低和下载时间长。

**Method:** 引入FastBioDL，一个为大型生物数据集设计的并行文件下载器，具有自适应并发控制器。它将下载过程视为一个在线优化问题，利用效用函数和梯度下降实时动态调整并发套接字流的数量，以最大化下载吞吐量同时最小化资源开销。

**Result:** 在公共基因组数据集上的综合评估显示，FastBioDL比现有最先进工具提速高达4倍。在高速网络实验中，其自适应设计比现有工具快2.1倍。

**Conclusion:** FastBioDL通过在客户端智能优化标准HTTP或FTP下载，为大规模基因组数据获取提供了一个强大而高效的解决方案，使研究人员无需专业商业软件或协议即可实现高性能数据检索。

> **ai_Abstract:** 本文介绍了FastBioDL，一个针对大型基因组数据集的自适应并行下载工具。针对现有工具无法适应动态网络条件导致下载效率低下的问题，FastBioDL将下载过程建模为在线优化问题，通过梯度下降动态调整并发连接数，以最大化吞吐量并最小化资源消耗。实验表明，FastBioDL比现有工具在公共基因组数据集上提速高达4倍，在高速网络中提速2.1倍，为研究人员提供了高效便捷的数据获取方案。

> **摘要翻译:** 现代下一代测序（NGS）项目通常会生成数TB的数据，研究人员普遍从SRA或ENA等公共存储库下载这些数据。现有的下载工具通常采用静态并发设置，由于无法适应动态网络条件，导致带宽利用率低下和下载时间过长。我们引入了FastBioDL，一个专为大型生物数据集设计的并行文件下载器，其特点是具有自适应并发控制器。FastBioDL将下载过程视为一个在线优化问题，利用效用函数和梯度下降算法实时动态调整并发套接字流的数量。这种方法在最大化下载吞吐量的同时，最大限度地减少了资源开销。对公共基因组数据集的全面评估表明，FastBioDL比现有最先进的工具实现了高达4倍的加速。此外，在高速网络实验中，其自适应设计比现有工具快2.1倍。通过在客户端智能优化标准HTTP或FTP下载，FastBioDL为大规模基因组数据获取提供了一个强大而高效的解决方案，使研究人员无需专业商业软件或协议即可实现高性能数据检索。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [292] [Modular Architecture for High-Performance and Low Overhead Data Transfers](https://arxiv.org/abs/2508.05546)
> *高性能低开销数据传输的模块化架构*

*Rasman Mubtasim Swargo, Engin Arslan, Md Arifuzzaman* | **Category: cs.DC** | **Updated: 2025-08-07**

**Keywords:** 模块化架构, 数据传输, 深度强化学习, 并发优化, PPO

**Comment:** 

> **TL;DR:** AutoMDT是一种模块化数据传输架构，利用深度强化学习优化读、网络和写操作的并发级别，显著提升了大规模数据传输的性能和效率。

**AI_Comments:** AutoMDT的创新之处在于其模块化架构与深度强化学习的结合，特别是引入轻量级模拟器进行离线训练，解决了生产环境中在线训练耗时的问题。这种方法使得数据传输能够动态适应复杂的网络和系统条件，显著提升了性能和效率，对于需要大规模数据传输的高性能应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统文件传输工具因固定配置或单一优化方法导致资源利用率低和不稳定，无法满足高性能应用对大规模数据集快速可靠传输的需求。

**Method:** 本文提出AutoMDT，一种新型模块化数据传输架构。它采用基于深度强化学习的智能体，同时优化读、网络和写操作的并发级别。该解决方案包含一个轻量级网络系统模拟器，支持离线训练Proximal Policy Optimization (PPO) 智能体，平均约45分钟，从而克服了生产网络中耗时在线训练的不切实际性。AutoMDT的模块化设计解耦了I/O和网络任务，使智能体能够精确捕捉复杂的缓冲区动态并快速适应不断变化的系统和网络条件。

**Result:** 在生产级测试平台上评估显示，AutoMDT与现有最先进的解决方案相比，收敛速度提高了8倍，传输完成时间减少了68%。

**Conclusion:** AutoMDT通过其模块化设计和基于深度强化学习的优化方法，显著提升了大规模数据传输的性能和效率，克服了传统方法的局限性，并能快速适应不断变化的系统和网络条件。

> **ai_Abstract:** 本文提出了AutoMDT，一种创新的模块化数据传输架构，旨在解决传统文件传输工具在处理大规模数据时效率低下和不稳定的问题。AutoMDT利用深度强化学习智能体（通过轻量级模拟器离线训练PPO）来同步优化读、网络和写操作的并发级别。其模块化设计实现了I/O与网络任务的解耦，使其能精确适应动态系统条件。实验结果表明，AutoMDT在收敛速度和传输完成时间方面显著优于现有技术。

> **摘要翻译:** 高性能应用需要跨地域快速可靠地传输海量数据集。传统文件传输工具由于固定配置或单一优化方法，常常导致资源利用率不足和不稳定。我们提出AutoMDT，一种新颖的模块化数据传输架构，它采用基于深度强化学习的智能体，同时优化读、网络和写操作的并发级别。我们的解决方案包含一个轻量级网络系统模拟器，能够平均在大约45分钟内离线训练Proximal Policy Optimization (PPO) 智能体，从而克服了生产网络中耗时在线训练的不切实际性。AutoMDT的模块化设计解耦了I/O和网络任务，使智能体能够精确捕捉复杂的缓冲区动态并快速适应不断变化的系统和网络条件。在生产级测试平台上的评估表明，与现有最先进的解决方案相比，AutoMDT的收敛速度提高了8倍，传输完成时间减少了68%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [299] [HFedATM: Hierarchical Federated Domain Generalization via Optimal Transport and Regularized Mean Aggregation](https://arxiv.org/abs/2508.05135)
> *HFedATM：通过最优传输和正则化平均聚合的分层联邦域泛化*

*Thinh Nguyen, Trung Phan, Binh T. Nguyen, Khoa D Doan, Kok-Seng Wong* | **Category: cs.DC, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 分层联邦学习, 域泛化, 最优传输, 联邦学习, 模型聚合

**Comment:** 

> **TL;DR:** 本文提出了HFedATM，一种新的分层聚合方法，通过结合滤波器最优传输对齐和收缩感知正则化平均聚合，解决了分层联邦学习中的域偏移问题，显著提升了联邦域泛化性能。

**AI_Comments:** HFedATM的创新之处在于其将最优传输理论引入分层联邦学习的聚合过程，以解决域偏移问题。通过对齐卷积滤波器并采用正则化平均聚合，该方法不仅在实践中提升了模型性能，还在理论上提供了更强的泛化保证。这对于提升联邦学习在复杂异构环境下的实际应用价值具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的联邦学习面临可扩展性挑战，分层联邦学习（HFL）通过分布式聚合解决此问题，但仍受限于域偏移（数据分布在客户端和站点间差异大）。虽然联邦域泛化（FedDG）方法旨在提高对域偏移的鲁棒性，但它们与HFL框架的集成尚未得到充分探索。

**Method:** 本文正式引入了分层联邦域泛化（HFedDG）这一新场景，并提出了HFedATM。HFedATM是一种分层聚合方法，首先通过“滤波器级最优传输对齐”来对齐来自不同站点的模型卷积滤波器，然后使用“收缩感知正则化平均聚合”来合并对齐后的模型。

**Result:** 实验评估表明，HFedATM显著提升了现有FedDG基线在多个数据集上的性能，并保持了计算和通信效率。理论分析表明，HFedATM实现了比标准分层平均更紧密的泛化误差界限，从而实现更快的收敛和稳定的训练行为。

**Conclusion:** HFedATM是一种新颖的分层聚合方法，有效解决了分层联邦学习中的域偏移问题，通过结合最优传输对齐和正则化平均聚合，显著提升了联邦域泛化性能，并具有良好的理论保证。

> **ai_Abstract:** 本文针对分层联邦学习（HFL）中存在的域偏移问题，提出了分层联邦域泛化（HFedDG）的新场景，并引入了HFedATM方法。HFedATM通过结合滤波器级最优传输对齐和收缩感知正则化平均聚合，有效对齐并合并来自不同站点的模型，从而提高模型在未见域上的泛化能力。实验和理论分析均表明，HFedATM显著提升了现有联邦域泛化方法的性能，同时保持了计算和通信效率，并实现了更紧密的泛化误差界限和更稳定的训练。

> **摘要翻译:** 联邦学习（FL）是一种去中心化的方法，多个客户端在不共享原始数据的情况下协同训练共享的全局模型。尽管其有效，但随着参与设备数量的增加，传统的FL由于对单个中央服务器的计算和通信要求过高而面临可扩展性挑战。分层联邦学习（HFL）通过将模型聚合任务分配给中间节点（站点）来解决这些问题，从而增强了系统可扩展性和对抗单点故障的鲁棒性。然而，HFL仍然存在一个关键但经常被忽视的限制：域偏移，即数据分布在不同客户端和站点之间存在显著差异，从而降低了模型在未见目标域上的性能。尽管联邦域泛化（FedDG）方法已经出现以提高对域偏移的鲁棒性，但它们与HFL框架的集成在很大程度上仍未被探索。在本文中，我们正式引入了分层联邦域泛化（HFedDG），这是一个旨在研究分层架构中域偏移的新场景。具体而言，我们提出了HFedATM，这是一种分层聚合方法，它首先通过滤波器级最优传输对齐来对齐来自不同站点的模型卷积滤波器，然后使用收缩感知正则化平均聚合来合并对齐后的模型。我们广泛的实验评估表明，HFedATM显著提升了现有FedDG基线在多个数据集上的性能，并保持了计算和通信效率。此外，理论分析表明，HFedATM实现了比标准分层平均更紧密的泛化误差界限，从而实现更快的收敛和稳定的训练行为。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [306] [Nexus:Proactive Intra-GPU Disaggregation of Prefill and Decode in LLM Serving](https://arxiv.org/abs/2507.06608)
> *Nexus：大模型服务中预填充与解码的GPU内部主动解耦*

*Xiaoxiang Shi, Colin Cai, Junjia Du, Zhihao Jia* | **Category: cs.DC, cs.LG** | **Updated: 2025-08-07**

**Keywords:** LLM服务, GPU解耦, 预填充, 解码, 资源管理

**Comment:** 

> **TL;DR:** Nexus系统通过主动的GPU内部预填充和解码解耦，显著提升了LLM服务的吞吐量并降低了延迟，解决了现有方法在动态工作负载下的适应性问题。

**AI_Comments:** Nexus的创新之处在于其“主动”的GPU内部解耦策略，而非传统的“反应性”方法，这使其能更好地适应动态工作负载。通过深入分析GPU资源的边际收益和内存带宽瓶颈，Nexus提出了一个更精细且高效的资源管理方案。其显著的性能提升（如2.2倍吞吐量和20倍TTFT降低）证明了该方法的有效性和重要性，对于提升LLM服务效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大模型服务方法，无论是整体服务还是引擎级解耦，都存在问题：整体服务有细粒度阶段干扰，而引擎级解耦则有高硬件和协调开销。先前的GPU内部解耦方法是反应性的，无法有效适应动态工作负载，限制了其性能。作者旨在解决在动态工作负载下如何实现主动的GPU内部解耦的问题。

**Method:** Nexus系统通过动态划分GPU资源来解决预填充和解码之间冲突的资源需求。它基于两个关键洞察：GPU资源存在边际收益递减，以及内存带宽竞争是一个关键瓶颈。系统设计同时考虑了计算能力、内存占用和带宽竞争。

**Result:** Nexus系统在不同LLM和工作负载上进行了评估，实现了：吞吐量比vLLM高出2.2倍，TTFT（首次令牌时间）降低20倍，TBT（批处理时间）降低2.5倍；性能比SGLang高出2倍；与解耦的vLLM持平或超越。

**Conclusion:** 该研究成功展示了通过主动的GPU内部预填充与解码解耦，可以显著提升大模型服务的效率和适应性，克服了现有反应性方法的局限性。

> **ai_Abstract:** 该论文提出了Nexus系统，旨在解决大模型服务中预填充和解码阶段的GPU资源管理问题。针对现有整体服务和反应性解耦方法的局限性，Nexus通过主动的GPU内部解耦，动态划分GPU资源，同时考虑计算能力、内存占用和带宽竞争。该方法基于GPU资源边际收益递减和内存带宽瓶颈的观察。实验结果表明，Nexus在吞吐量、首次令牌时间（TTFT）和批处理时间（TBT）上均显著优于现有主流系统，有效提升了动态工作负载下的LLM服务性能。

> **摘要翻译:** 整体服务（chunked prefill）通过将预填充和解码批处理在一起，提高了GPU利用率，但存在细粒度阶段干扰。引擎级预填充-解码（PD）解耦避免了干扰，但会产生更高的硬件和协调开销。先前的GPU内部解耦方法在单个GPU内多路复用预填充和解码，使用基于SLO的调优，其指导来自离线分析的启发式方法或反应式反馈循环。然而，这些方法对性能问题的反应是被动的，而不是预期的，限制了其在动态工作负载下的适应性。
我们提出问题：我们能否实现能够有效适应动态工作负载的主动GPU内部解耦？关键挑战在于管理预填充和解码在不同条件下的冲突资源需求。我们首先表明GPU资源存在边际收益递减——超过饱和点后，更多的分配只会带来最小的延迟收益。其次，我们观察到内存带宽竞争成为一个关键瓶颈。这些见解促使我们设计了一种动态划分GPU资源用于预填充和解码阶段，同时联合考虑计算能力、内存占用和带宽竞争的方案。
在各种LLM和工作负载上进行评估，我们的系统Nexus实现了高达2.2倍的吞吐量提升，20倍的TTFT降低，以及2.5倍的TBT降低，优于vLLM；性能比SGLang高出2倍；并与解耦的vLLM持平或超越。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [314] [xDeepServe: Model-as-a-Service on Huawei CloudMatrix384](https://arxiv.org/abs/2508.02520)
> *xDeepServe：华为CloudMatrix384上的模型即服务*

*Ao Xiao, Bangzheng He, Baoquan Zhang, Baoxing Huai, Bingji Wang, Bo Wang, Bo Xu, Boyi Hou, Chan Yang, Changhong Liu, Cheng Cui, Chenyu Zhu, Cong Feng, Daohui Wang, Dayun Lin, Duo Zhao, Fengshao Zou, Fu Wang, Gangqiang Zhang, Gengyuan Dan, Guanjie Chen, Guodong Guan, Guodong Yang, Haifeng Li, Haipei Zhu, Hao Feng, Hao Huang, Hao Xu, Hengrui Ma, Hengtao Fan, Hui Liu, Jia Li, Jiang Liu, Jiang Xu, Jie Meng, Jinhan Xin, Junhao Hu, Juwei Chen, Lan Yu, Lanxin Miao, Liang Liu, Linan Jing, Lu Zhou, Meina Han, Mingkun Deng, Mingyu Deng, Naitian Deng, Nizhong Lin, Peihan Zhao, Peng Pan, Pengfei Shen, Ping Li, Qi Zhang, Qin Zhang, Qingrong Xia, Qingyi Zhang, Qunchao Fu, Ren Guo, Ruimin Gao, Shaochun Li, Sheng Long, Shentian Li, Shining Wan, Shuai Shen, Shuangfu Zeng, Shuming Jing, Siqi Yang, Song Zhang, Tao Xu, Tianlin Du, Ting Chen, Wanxu Wu, Wei Jiang, Weinan Tong, Weiwei Chen, Wen Peng, Wenli Zhou, Wenquan Yang, Wenxin Liang, Xiang Liu, Xiaoli Zhou, Xin Jin, Xinyu Duan, Xu Li, Xu Zhang, Xusheng Chen, Yalong Shan, Yang Gan, Yao Lu, Yi Deng, Yi Zheng, Yingfei Zheng, Yiyun Zheng, Yizhou Shan, Yong Gao, Yongqiang Yang, Yuanjin Gong, Yue Yu, Yuetao Chen, Yukun Zhu* | **Category: cs.DC** | **Updated: 2025-08-07**

**Keywords:** xDeepServe, LLM服务, SuperPod, 解耦架构, MoE

**Comment:** 

> **TL;DR:** xDeepServe是华为云为SuperPod规模基础设施设计的LLM服务系统，采用解耦架构Transformerless，旨在高效支持大规模MoE模型推理。

**AI_Comments:** xDeepServe的创新之处在于其Transformerless解耦架构，它将Transformer模型的核心组件分解并独立执行，这对于在SuperPod这类超大规模硬件上高效服务MoE LLM至关重要。此外，专门为CloudMatrix384优化的XCCL通信库也显著提升了系统性能。该工作为未来大规模AI模型服务提供了有益的探索和解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在大规模AI基础设施中，LLM正通过MoE模型不断扩展，而AI硬件如华为CloudMatrix384 SuperPod也在不断升级。在SuperPod规模的硬件上运行大型MoE模型带来了新的挑战，包括需要新的执行模型、可扩展的调度、高效的专家负载均衡以及消除单点故障。

**Method:** 本文提出了xDeepServe，一个为SuperPod规模基础设施设计的LLM服务系统。其核心是Transformerless，一种解耦架构，将Transformer模型分解为独立的模块单元（注意力、前馈、MoE），在通过高速互连连接的NPU上独立执行。该设计以两种形式实现：解耦的预填充-解码和解耦的MoE-注意力。为了支持这种架构，提出了XCCL通信库，它利用CloudMatrix384的全局共享内存实现高效的点对点和全对全原语。此外，还扩展了服务引擎FlowServe，通过系统级技术实现跨数百个NPU的可扩展推理。

**Result:** 该完全解耦的设置可以在不牺牲性能的情况下实现计算和内存的独立扩展，并支持跨数百个NPU的可扩展推理。

**Conclusion:** xDeepServe是华为云为SuperPod规模的LLM服务系统，通过创新的Transformerless解耦架构、XCCL通信库以及对FlowServe的扩展，解决了在超大规模硬件上运行大型MoE模型的挑战，实现了高效且可扩展的推理。

> **ai_Abstract:** 本文介绍了华为云的xDeepServe系统，这是一个专为SuperPod规模基础设施设计的大型语言模型（LLM）服务系统。面对在大型AI硬件上运行专家混合（MoE）LLM的挑战，xDeepServe提出了Transformerless解耦架构，将Transformer模型组件化并在NPU上独立执行，支持计算和内存的独立扩展。系统还引入了XCCL通信库和FlowServe引擎的扩展，以实现跨数百个NPU的高效可扩展推理。

> **摘要翻译:** 大规模LLM和SuperPod的兴起标志着大规模AI基础设施的新时代。LLM通过MoE（专家混合）模型持续扩展，如DeepSeek、Kimi和Qwen等最新模型所示。同时，AI硬件也在不断升级，华为的CloudMatrix384 SuperPod提供了数百GB/s的高速互连。在SuperPod规模的硬件上运行大型MoE模型带来了新的挑战，它需要新的执行模型、可扩展的调度、高效的专家负载均衡以及消除单点故障。本文介绍了xDeepServe，华为云为SuperPod规模基础设施设计的LLM服务系统。其核心是Transformerless，一种解耦架构，将Transformer模型分解为模块化单元——注意力、前馈和MoE——并在通过高速互连连接的NPU上独立执行。我们将这种设计以两种形式实现：解耦的预填充-解码和解耦的MoE-注意力。这种完全解耦的设置可以在不牺牲性能的情况下实现计算和内存的独立扩展。为了支持这种架构，我们提出了XCCL，一个利用CloudMatrix384全局共享内存实现高效点对点和全对全原语的通信库。我们还通过系统级技术扩展了我们的服务引擎FlowServe，实现了跨数百个NPU的可扩展推理。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [320] [Aircraft routing: periodicity and complexity](https://arxiv.org/abs/2508.05532)
> *飞机航线规划：周期性与复杂性*

*Frédéric Meunier, Axel Parmentier, Nour ElHouda Tellache* | **Category: cs.DM, math.OC** | **Updated: 2025-08-07**

**Keywords:** 飞机航线规划, 周期性, 复杂性, NP-hard, 周期性解

**Comment:** 

> **TL;DR:** 本文研究了飞机航线规划的周期性与计算复杂度。证明了在特定维护条件下，强形式周期性解的存在性，并首次确立了非周期性飞机航线规划问题的NP-hard性，同时发现了一个可多项式时间求解的特例。

**AI_Comments:** 该论文在飞机航线规划这一经典运筹学问题上做出了重要贡献。其创新点在于：1) 明确证明了在特定维护条件下强形式周期性解的存在性，纠正并扩展了领域内长期存在的隐含假设；2) 首次为非周期性飞机航线规划问题建立了NP-hard性，填补了计算复杂性理论上的一个重要空白。这些发现对于理论研究和实际应用都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 飞机航线规划是运筹学在飞机管理中的核心问题。现有文献对周期性实例与周期性解之间的关系存在未经充分讨论的假设，且缺乏对非周期性版本计算复杂度的明确证明。本研究旨在填补这些理论空白。

**Method:** 本文采用数学证明方法。首先，通过理论分析探讨了周期性实例与周期性解的关系，并证明了在特定维护频率下，强形式周期性解的存在性。其次，通过计算复杂性理论分析，建立了非周期性飞机航线规划问题的NP-hard性，并识别了一个可多项式时间求解的特殊情况。

**Result:** 研究证明了当定期维护至多每四天需要一次时，强形式的周期性解总是存在的。首次建立了非周期性飞机航线规划问题的NP-hard性。此外，还证明了一个特殊但自然情况下的多项式时间可解性。

**Conclusion:** 本研究通过澄清和扩展飞机航线规划问题在周期性和计算复杂度方面的理论基础，为该领域的进一步研究和实际应用提供了更坚实、准确的理论依据。

> **ai_Abstract:** 本文深入探讨了飞机航线规划问题，重点分析了其周期性与计算复杂性。研究证明了在定期维护要求不频繁（至多每四天一次）的情况下，强形式的周期性解决方案始终存在。此外，论文首次确立了非周期性飞机航线规划问题的NP-hard性，并识别了一个在特殊但自然场景下可多项式时间求解的情况，从而弥补了现有文献中的理论空白。

> **摘要翻译:** 飞机航线规划问题是运筹学应用于飞机管理领域中研究最多的问题之一。它涉及将航班分配给飞机，同时确保定期访问维修基地。本文探讨了该问题的两个方面。
首先，我们探讨了周期性实例（即航班每天都相同）与周期性解之间的关系。文献中曾隐含地（未经讨论）假设周期性实例必然需要周期性解，甚至是更强的周期性解，即每两架飞机执行完全相同的循环航班序列，或完全不相交的循环序列。然而，强制执行这种周期性可能会排除可行的解决方案。我们证明，当定期维护至多每四天需要一次时，总是存在这种形式的周期性解。
其次，我们考虑了该问题的计算难度。尽管该领域的许多论文都提到了飞机航线规划问题的NP-hard性，但文献中只有周期性实例才有这样的结果。我们为非周期性版本建立了其NP-hard性。同时，还证明了一个特殊但自然情况下的多项式可解性。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [327] [Balanced Steinhaus triangles](https://arxiv.org/abs/2508.05159)
> *平衡的斯坦豪斯三角形*

*Jonathan Chappelon* | **Category: cs.DM, math.CO, math.NT** | **Updated: 2025-08-07**

**Keywords:** 斯坦豪斯三角形, 平衡三角形, 模m, 算术级数, 组合数学

**Comment:** 

> **TL;DR:** 证明了对于任意正整数m，存在无限多个平衡的模m斯坦豪斯三角形，解决了Molluzzo的一个弱版本问题。

**AI_Comments:** 这项工作通过证明无限多个平衡的模m斯坦豪斯三角形的存在，解决了John C. Molluzzo提出的一个长期存在的问题的弱版本，展示了通过考虑周期三角形和算术级数来解决组合数学中未决问题的创新方法。

<details>
  <summary>Details</summary>

**Motivation:** 解决John C. Molluzzo在1978年提出的一个关于模m斯坦豪斯三角形的问题的弱版本，该问题对于$m 	ext{≥} 12$的偶数情况至今未解决。

**Method:** 通过考虑由交错算术级数生成的周期三角形来实现。

**Result:** 证明了对于任意正整数m，存在无限多个平衡的模m斯坦豪斯三角形。

**Conclusion:** 成功地证明了无限多个平衡的模m斯坦豪斯三角形的存在，从而积极地回答了John C. Molluzzo在1978年提出的一个弱版本问题。

> **ai_Abstract:** 本文研究了模m的平衡斯坦豪斯三角形。这种三角形定义为包含有限循环群$\mathbb{Z}/m\mathbb{Z}$中所有元素且出现次数相同的向下指向三角形。研究通过考察由交错算术级数生成的周期三角形，证明了对于任意正整数m，都存在无限多个平衡的模m斯坦豪斯三角形。这一发现积极地解决了John C. Molluzzo在1978年提出的一个长期未决问题的弱版本，该问题对于$m \text{≥} 12$的偶数值仍未解决。

> **摘要翻译:** 模m的斯坦豪斯三角形是一个有限的向下指向的三角形，其元素属于有限循环群$\mathbb{Z}/m\mathbb{Z}$，并满足与标准模m帕斯卡三角形相同的局部规则。如果一个模m的斯坦豪斯三角形包含$\mathbb{Z}/m\mathbb{Z}$的所有元素且出现次数相同，则称其为平衡的。本文证明了对于任意正整数m，存在无限多个平衡的模m斯坦豪斯三角形。这是通过考虑由交错算术级数生成的周期三角形来实现的。这积极地回答了John C. Molluzzo在1978年提出的一个弱版本问题，该问题对于$m \text{≥} 12$的偶数情况至今未解决。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [335] [Space-Efficient Hierholzer: Eulerian Cycles in O(m) Time and O(n) Space](https://arxiv.org/abs/2508.05251)
> *空间高效的Hierholzer算法：欧拉环在O(m)时间和O(n)空间中的实现*

*Ziad Ismaili Alaoui, Detlef Plump, Sebastian Wild* | **Category: cs.DM, cs.DS** | **Updated: 2025-08-07**

**Keywords:** 欧拉环, Hierholzer算法, 空间效率, 图算法, 线性时间

**Comment:** 

> **TL;DR:** 提出了一种改进的Hierholzer算法，能在O(m)时间复杂度下以O(n log m)空间复杂度找到欧拉环，显著节省了空间。

**AI_Comments:** 这项工作通过改进经典的Hierholzer算法，在保持线性时间复杂度的同时，大幅度降低了查找欧拉环所需的空间复杂度，实现了O(n)级别的空间效率，这对于处理大规模或密集图尤其具有创新性和实用价值。算法的易于实现性也是一个优点，尽管其正确性证明较为复杂。

<details>
  <summary>Details</summary>

**Motivation:** 标准Hierholzer算法的实现需要O(m log n)比特的工作空间，作者旨在大幅减少这一空间需求，尤其对于密集图或多重图。

**Method:** 描述了一种Hierholzer算法的简单变体，该算法避免了O(m)大小的顶点栈或为每条边存储信息。论文提供了详细的正式正确性证明。

**Result:** 该算法能在O(m)时间复杂度下找到欧拉环，并使用O(n log m)比特的工作内存，相比标准实现O(m log n)比特的空间有显著改进。据作者所知，这是第一个达到此空间界限的线性时间算法。

**Conclusion:** 提出了一种创新且空间高效的Hierholzer算法变体，在保持线性时间复杂度的同时，大幅减少了欧拉环查找所需的内存，尤其适用于密集图。

> **ai_Abstract:** 这篇论文介绍了一种改进的Hierholzer算法，该算法能够在O(m)时间复杂度下找到欧拉环，同时将所需工作空间从传统的O(m log n)比特显著优化至O(n log m)比特。该算法避免了使用大型栈或存储每条边的信息，并且是首个实现此空间效率的线性时间算法，尤其适用于密集图。

> **摘要翻译:** 我们描述了Hierholzer算法的一个简单变体，它在具有n个顶点和m条边的（多）图中，使用O(n log m)比特的工作内存找到一个欧拉环。这与标准Hierholzer算法的实现相比，后者使用O(m log n)比特的空间，显著改善了工作空间。我们的算法运行时间是线性的，与经典版本一样，但避免了O(m)大小的顶点栈或为每条边存储信息。据我们所知，这是第一个达到此空间界限的线性时间算法，并且该方法非常容易实现。相比之下，其正确性论证出奇地微妙；我们给出了详细的正式证明。空间节省对于密集图或具有大边多重性的多重图尤为重要。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [343] [Parameterized complexity of isometric path partition: treewidth and diameter](https://arxiv.org/abs/2508.05448)
> *等距路径划分的参数化复杂度：树宽和直径*

*Dibyayan Chakraborty, Oscar Defrain, Florent Foucaud, Mathieu Mari, Prafullkumar Tale* | **Category: cs.DM, cs.DS, math.CO** | **Updated: 2025-08-07**

**Keywords:** 等距路径划分, 参数化复杂度, 树宽, 直径, W[1]-难

**Comment:** 

> **TL;DR:** 本文研究了等距路径划分问题在树宽参数化下的复杂性，证明其是W[1]-难的，并提出了一个动态规划算法，其时间复杂度对树宽有较高的依赖性，同时排除了显著更快的算法的可能性。

**AI_Comments:** 本文的重要贡献在于明确了等距路径划分（一类基于度量的图问题）在树宽参数化下的复杂性边界，证实了这类问题与标准MSO可表达问题的差异。其W[1]-难度的证明以及随后的算法设计和条件性下界分析，为理解和处理这类“硬核”图问题提供了理论基础和实用指导。特别是对树宽参数的高依赖性及其必要性的证明，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 许多基于度量的图问题（如等距路径划分）无法用MSO公式表达，因此不适用于Courcelle定理，需要单独研究其参数化复杂性，尤其是在树宽参数化下。本文旨在回答Dumas et al.和Fernau et al.提出的问题，并确认这一趋势。

**Method:** 证明了等距路径划分问题在树宽（甚至路径宽）参数化下是W[1]-难的；设计了一个定制的动态规划算法，时间复杂度为 $n^{O(\mathrm{tw})}$；该动态规划方法也导致了一个时间复杂度为 $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$ 的算法；通过证明等距路径划分不接受时间复杂度为 $\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$ 的算法（除非随机ETH失败），排除了显著更快的算法的可能性。

**Result:** 等距路径划分问题在树宽（甚至路径宽）参数化下是W[1]-难的；提出了一个运行时间为 $n^{O(\mathrm{tw})}$ 的动态规划算法；该算法也可表示为 $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$；证明了除非随机ETH失败，否则不存在显著更快的算法（$\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$）。

**Conclusion:** 等距路径划分问题在树宽参数化下具有较高的计算复杂性（W[1]-难），即使存在多项式时间算法（相对于n），其对树宽的依赖性也异常高，并且这种高依赖性是必要的，排除了显著更快的算法的可能性。这证实了基于度量的图问题在树宽参数化下往往是复杂性边界的观点。

> **ai_Abstract:** 本文探讨了等距路径划分问题在图的树宽参数化下的复杂性。研究表明，与许多可通过MSO公式表达的问题不同，这类基于度量的图问题在树宽参数化下表现出更高的复杂性。具体地，作者证明了等距路径划分是W[1]-难的，并设计了一个时间复杂度为 $n^{O(\mathrm{tw})}$ 或 $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$ 的动态规划算法。此外，研究还通过条件性下界排除了存在显著更快算法的可能性，强调了该问题对树宽的固有高依赖性。

> **摘要翻译:** 我们研究了等距路径划分问题的参数化复杂性，其参数是输入图的树宽（tw），这无疑是研究最广泛的参数之一。Courcelle定理表明，可表达为常数大小MSO公式的图问题，在输入图的树宽参数化下，允许FPT算法。这涵盖了许多自然的图问题。然而，许多基于度量的图问题，其解是使用图的某种基于度量的属性（通常是距离）定义的，无法表达为常数大小的MSO公式。这类问题，等距路径划分便是其中之一，需要单独关注，并且通常划定了树宽参数化成功故事的界限。
在本文中，我们证明了等距路径划分在树宽（甚至路径宽）参数化下是W[1]-难的，回答了Dumas et al. [SIDMA, 2024]和Fernau et al. [CIAC, 2023]提出的问题，并证实了上述趋势。我们通过设计一个运行时间为 $n^{O(\mathrm{tw})}$ 的定制动态规划算法来补充这一难度结果。这种动态规划方法还导致了一个运行时间为 $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$ 的算法，其中 $\textrm{diam}$ 是图的直径。值得注意的是，对树宽的依赖性异常高，因为大多数问题都允许运行时间为 $2^{O(\mathrm{tw})}\cdot n^{O(1)}$ 或 $2^{O(\mathrm{tw} \log (\mathrm{tw}))}\cdot n^{O(1)}$ 的算法。然而，我们通过证明等距路径划分不接受运行时间为 $\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$ 的算法，除非随机ETH失败，从而排除了显著更快的算法的可能性。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [351] [Improved lower bounds on the maximum size of graphs with girth 5](https://arxiv.org/abs/2508.05562)
> *改进的周长为5的图的最大尺寸的下界*

*Jan Goedgebeur, Jorik Jooken, Gwenaël Joret, Tibo Van den Eede* | **Category: cs.DM, math.CO** | **Updated: 2025-08-07**

**Keywords:** 图论, 周长为5的图, 下界, 爬山启发式算法, 最大尺寸

**Comment:** 

> **TL;DR:** 本文提出了一种新算法，用于改进周长至少为5的n顶点图的最大尺寸（边数）的下界，并在特定范围内取得了显著进展。

**AI_Comments:** 该论文的创新之处在于其提出的新算法，该算法是爬山启发式算法的改进版本，并引入了“传播”良好模式的机制。这种方法使其能够在传统精确方法无法处理的大范围n值上，有效地改进图的尺寸下界。其重要性在于为图论中的一个长期问题提供了新的进展，特别是在构建具有特定周长性质的图方面。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在改进周长至少为5的n顶点图的最大尺寸（边数）的下界，即$ex(n;\{C_3,C_4\})$。

**Method:** 本文提出了一种新的算法，该算法是Exoo、McKay、Myrvold和Nadon（2011）引入的爬山启发式算法的变体。该算法在多个通道中考虑一系列n值，并在每个通道中，通过修改先前为相邻n值找到的近极值图来初始化爬山启发式算法，从而“传播”发现的良好模式。

**Result:** 对于$n\in \{74,75, \dots, 198\}$范围内的所有n值（除了$n=96,97$），该方法都改进了$ex(n;\{C_3,C_4\})$的现有下界。

**Conclusion:** 本文提出的算法成功改进了在目前精确方法无法处理的范围内，周长为5的图的最大尺寸的下界。

> **ai_Abstract:** 本文介绍了一种新的算法，它是现有爬山启发式算法的变体，旨在提高周长至少为5的图的最大尺寸的下界。该算法通过在多个通道中迭代并利用相邻n值发现的良好模式进行初始化，成功改进了$n\in \{74,75, \dots, 198\}$范围内几乎所有n值的现有下界，这些值是精确方法目前无法处理的。

> **摘要翻译:** 我们提出了一种新的算法，用于改进周长至少为5的n顶点图的最大尺寸（边数）的下界，$ex(n;\{C_3,C_4\})$。我们算法的核心是Exoo、McKay、Myrvold和Nadon（2011）引入的一种爬山启发式算法的变体，用于寻找小型笼。我们的算法在多个通道中考虑一系列n值。在每个通道中，针对特定n值的爬山启发式算法通过修改先前为相邻n值找到的近极值图来初始化，从而允许“传播”发现的良好模式。我们专注于$n\in \{74,75, \dots, 198\}$范围，这目前超出了精确方法的范围，我们的方法对该范围内所有n值的$ex(n;\{C_3,C_4\})$现有下界进行了改进，除了两个n值（$n=96,97$）。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [359] [On near optimal colorable graphs](https://arxiv.org/abs/2505.13932)
> *关于近最优可着色图*

*C.U.Angeliya, Arnab Char, T. Karthick* | **Category: cs.DM, math.CO** | **Updated: 2025-08-07**

**Keywords:** 近最优可着色图, 色数, 团数, $\chi$-有界图, 禁止子图

**Comment:** 

> **TL;DR:** 本文定义了“近最优可着色图”，并证明了特定类型 ($F, K_4-e$)-自由图属于此类，部分回答了现有问题，并为这些图的色数问题提供了多项式时间可解的替代证明。

**AI_Comments:** 本文通过识别一类新的“近最优可着色图”并将其与现有研究问题联系起来，为图着色领域做出了贡献。其创新之处在于证明了特定禁止子图类的近最优可着色性，并为它们色数的计算复杂性提供了多项式时间可解的替代证明。这可能简化或为这些图类的算法方法提供新见解。

<details>
  <summary>Details</summary>

**Motivation:** 研究近最优可着色图这一重要的 $\chi$-有界图子类。具体而言，旨在回答 Ju 和 Huang 以及 Schiermeyer 关于特定图类可着色性的问题，并为这些图的色数问题提供多项式时间可解的替代证明。

**Method:** 通过定义近最优可着色图，并证明 ($F, K_4-e$)-自由图（其中 $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$，$K_4-e$ 是菱形图）满足该性质。此外，结合这些结果和早期已知结果，提供了色数问题多项式时间可解的替代证明。

**Result:** 证明了 ($F, K_4-e$)-自由图类是近最优可着色的，其中 $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$。这部分回答了 Ju 和 Huang 的一个问题，并与 Schiermeyer 的一个问题相关。此外，为 ($F, K_4-e$)-自由图类（相同 $F$）的色数问题可在多项式时间内解决提供了替代证明。

**Conclusion:** 本文成功识别了一类新的近最优可着色图，并为这些图的色数计算复杂性提供了新视角。研究结果有助于理解 $\chi$-有界图和相关开放问题。

> **ai_Abstract:** 本文引入了“近最优可着色图”的概念，并将其定义为 $\chi$-有界图的一个重要子类。研究表明，特定选择的 $F$ 下的 ($F, K_4-e$)-自由图属于此类，这部分回答了图论中现有的开放问题。此外，本文利用这些结果为这些特定 ($F, K_4-e$)-自由图的色数问题可在多项式时间内解决提供了替代证明。

> **摘要翻译:** 一类图 $\cal G$ 被称为 \emph{近最优可着色}，如果存在一个常数 $c\in \mathbb{N}$，使得每个图 $G\in \cal G$ 满足 $\chi(G) \leq \max\{c, \omega(G)\}$，其中 $\chi(G)$ 和 $\omega(G)$ 分别表示 $G$ 的色数和团数。近最优可着色图类是 $\chi$-有界图类的一个重要子类，在文献中得到了充分研究。在本文中，我们证明了 ($F, K_4-e$)-自由图类是近最优可着色的，其中 $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$，图 $K_4-e$ 通常被称为“菱形”。这部分回答了 Ju 和 Huang [Theoretical Computer Science 993 (2024) Article No.: 114465] 的一个问题，并与 Schiermeyer (未发表) 的一个问题相关。此外，利用这些结果和一些早期已知的结果，我们还为 ($F, K_4-e$)-自由图类（其中 $F\in \{P_1+2P_2,2P_1+P_3,3P_1+P_2\}$）的 \textsc{色数} 问题可在多项式时间内解决这一事实提供了一个替代证明。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [367] [Graphs with nonnegative resistance curvature](https://arxiv.org/abs/2410.07756)
> *非负电阻曲率图*

*Karel Devriendt* | **Category: cs.DM, math.CO, math.MG** | **Updated: 2025-08-07**

**Keywords:** 非负电阻曲率, 图论, 离散曲率, 生成树, 多面体

**Comment:** 

> **TL;DR:** 本文引入并研究了一类新的图，称为非负电阻图，这类图介于哈密顿图和1-tough图之间，并与匹配多面体和生成树多面体的交集有关。

**AI_Comments:** 本文创新性地引入了“非负电阻图”这一概念，并将其与离散曲率、哈密顿图、1-tough图以及多面体几何联系起来，揭示了图论中新的结构特性。特别是其与多面体交集的关系是一个令人惊讶且重要的发现，为图论研究开辟了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是离散曲率，旨在引入并研究一类新的图。

**Method:** 本文引入并定义了“非负电阻图”这一新图类，其定义基于生成树上的分布，使得随机生成树中每个顶点的期望度数至多为二。研究了这类图的性质、特征化以及与其他图类的关系。

**Result:** 结果表明，非负电阻图介于哈密顿图和1-tough图之间。此外，一个图是电阻非负的当且仅当其二倍膨胀匹配多面体与生成树多面体的内部相交。

**Conclusion:** 本文引入并初步研究了非负电阻图，揭示了其与哈密顿图、1-tough图以及特定多面体交集的关系，并提出了未来研究的问题。

> **ai_Abstract:** 本文引入了“非负电阻图”这一新图类，其定义是存在一种生成树上的分布，使得随机生成树中所有顶点的期望度数不超过二。这类图恰好对应于具有非负电阻曲率的图。研究发现，非负电阻图位于哈密顿图和1-tough图之间，且其特性与两倍膨胀匹配多面体和生成树多面体的交集紧密相关。文章还探讨了该图类的进一步特性并提出了未来的研究方向。

> **摘要翻译:** 本文引入并研究了一类受离散曲率启发的新型图。如果一个图存在一个生成树上的分布，使得随机生成树中每个顶点的期望度数至多为二，则我们称之为电阻非负图；这些图正是那些具有非负电阻曲率（由Devriendt和Lambiotte引入的一种离散曲率）的图。我们证明了这类图介于哈密顿图和1-tough图之间，并且令人惊讶的是，一个图是电阻非负的当且仅当其二倍膨胀匹配多面体与其生成树多面体的内部相交。我们进一步研究了电阻非负图的特征和基本性质，并为未来的研究提出了一些问题。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [375] [($P_2+P_4$, $K_4-e$)-free graphs are nearly $ω$-colorable](https://arxiv.org/abs/2501.02543)
> *($P_2+P_4$, $K_4-e$)-自由图是近似 $ω$-可染色的*

*C. U. Angeliya, T. Karthick, Shenwei Huang* | **Category: cs.DM, math.CO** | **Updated: 2025-08-07**

**Keywords:** 图染色, 色数, 团数, 自由图, 紧界限

**Comment:** 

> **TL;DR:** 本文给出了($P_2+P_4$, $K_4-e$)-自由图的色数与团数之间的紧密关系，扩展并改进了现有结果，并部分回答了开放问题。

**AI_Comments:** 本文在图论领域，特别是图染色理论中做出了重要贡献。其创新之处在于精确地确定了特定类型自由图的色数界限，并证明了这些界限的紧性。研究结果不仅统一并扩展了之前关于相关图类的结论，而且通过部分回答开放问题，为未来研究提供了方向，具有较高的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在扩展已知色数界限，改进现有研究的界限，并部分回答关于“近似最优可染色图”以及($P_7$, $K_4-e$)-自由图色数界限的开放问题。

**Method:** 本文通过数学证明的方式，给出了($P_2+P_4$, $K_4-e$)-自由图的色数与团数之间的具体关系。

**Result:** (i) 如果$G$是($P_2+P_4$, $K_4-e$)-自由图且$\\omega(G)\\geq 3$，则$\\chi(G)\\\\leq \\max\\{6, \\omega(G)\\}$，且对于每个$\\omega(G)\\\\notin \\{4,5\\}$，该界是紧的。(ii) 如果$G$是($P_2+P_4$, $K_4-e$)-自由图且$\\omega(G)= 4$，则$\\chi(G)= 4$。

**Conclusion:** 本文的结果扩展了($P_2+P_2$, $K_4-e$)-自由图和($P_2+P_3$, $K_4-e$)-自由图的已知色数界限，改进了Chen和Zhang对($P_2+P_4$, $K_4-e$)-自由图给出的界限，并部分回答了Ju和第三作者以及Schiermeyer关于色数界限的开放问题。

> **ai_Abstract:** 本文研究了($P_2+P_4$， $K_4-e$)-自由图的色数与团数之间的关系。研究结果表明，对于$\\omega(G)\\geq 3$的此类图，其色数$\\chi(G)\\\\leq \\max\\{6, \\omega(G)\\}$，且在多数情况下该界是紧的；对于$\\omega(G)=4$的情况，$\\chi(G)=4$。这些发现不仅扩展了现有关于($P_2+P_2$， $K_4-e$)-自由图和($P_2+P_3$， $K_4-e$)-自由图的色数界限，还改进了先前的工作，并部分解决了图染色领域的一些开放问题。

> **摘要翻译:** 对于图$G$，$\\chi(G)$和$\\omega(G)$分别表示$G$的色数和团数。在本文中，我们展示了以下结果：(i) 如果$G$是($P_2+P_4$， $K_4-e$)-自由图且$\\omega(G)\\geq 3$，则$\\chi(G)\\\\leq \\max\\{6, \\omega(G)\\}$，并且对于每个$\\omega(G)\\\\notin \\{4,5\\}$，该界是紧的。(ii) 如果$G$是($P_2+P_4$， $K_4-e$)-自由图且$\\omega(G)= 4$，则$\\chi(G)= 4$。这些结果扩展了($P_2+P_2$， $K_4-e$)-自由图和($P_2+P_3$， $K_4-e$)-自由图类的已知色数界限，改进了Chen和Zhang [arXiv:2412.14524 [math.CO]， 2024] 对($P_2+P_4$， $K_4-e$)-自由图类给出的界限，部分回答了Ju和第三作者 [Theor. Comp. Sci. 993 (2024) Article No.: 114465] 关于“近似最优可染色图”的问题，以及Schiermeyer（未发表）关于($P_7$， $K_4-e$)-自由图色数界限的问题。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [383] [A Refutation of Elmasry's $\tilde{O}(m \sqrt{n})$-Time Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2508.04872)
> *对Elmasry单源最短路径$	ilde{O}(m \sqrt{n})$时间算法的驳斥*

*Sunny Atalig, Marek Chrobak* | **Category: cs.DS** | **Updated: 2025-08-06**

**Keywords:** 单源最短路径, 算法复杂度, 反例, Elmasry算法, 算法驳斥

**Comment:** 

> **TL;DR:** 本文通过提供一个反例，驳斥了Elmasry声称的单源最短路径算法的$	ilde{O}(m \sqrt{n})$时间复杂度分析是错误的，并指出其实际运行时间为$\Omega(mn)$。

**AI_Comments:** 这篇论文的重要性在于它纠正了一个可能存在的关于单源最短路径算法效率的误解。通过提供一个具体的反例，它严谨地证明了Elmasry算法的复杂度分析是错误的，这对于理论计算机科学，特别是图算法领域，具有重要的澄清作用。它强调了算法复杂度分析的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** Elmasry提出了一种声称运行时间复杂度为$	ilde{O}(m\sqrt{n})$的单源最短路径算法，本文旨在检验其分析的正确性。

**Method:** 作者通过提供一个加权图的例子来证明Elmasry算法的运行时间分析不正确。

**Result:** 结果表明，在所提供的加权图例子上，Elmasry算法的运行时间复杂度为$\Omega(mn)$，而不是他声称的$	ilde{O}(m\sqrt{n})$。

**Conclusion:** Elmasry提出的单源最短路径算法的运行时间复杂度分析是错误的。

> **ai_Abstract:** 本文对Amr Elmasry提出的单源最短路径算法进行了审视。Elmasry声称该算法的运行时间复杂度为$	ilde{O}(m\sqrt{n})$。然而，本文通过构造一个特定的加权图实例，证明了Elmasry的分析存在错误，并指出其算法在该实例上的实际运行时间为$\Omega(mn)$，从而驳斥了其声称的复杂度。

> **摘要翻译:** 在这篇笔记中，我们审视了Amr Elmasry最近发表的论文“打破Bellman-Ford最短路径界限”，其中他提出了一种用于单源最短路径问题的算法，并声称其运行时间复杂度为$	ilde{O}(m\sqrt{n})$，其中$n$是顶点数，$m$是边数。我们通过提供一个加权图的例子，证明了他的分析是不正确的，在该图上，他的算法的运行时间为$\Omega(mn)$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [391] [Text Indexing and Pattern Matching with Ephemeral Edits](https://arxiv.org/abs/2508.05124)
> *具有瞬时编辑的文本索引和模式匹配*

*Solon P. Pissis* | **Category: cs.DS** | **Updated: 2025-08-07**

**Keywords:** 文本索引, 模式匹配, 瞬时编辑, 子串编辑, 算法

**Comment:** 

> **TL;DR:** 本文引入了两种新的数据结构：用于支持瞬时子串编辑的文本索引，以及用于支持瞬时编辑的模式匹配，均实现了高效的查询时间。

**AI_Comments:** 本文的创新点在于引入了“瞬时编辑”这一概念，并针对其特性设计了专门的文本索引和模式匹配算法。这种对特定编辑模式的关注，使得在处理如独立编辑流或假设性编辑测试等场景时，能够实现比传统动态数据结构更高效的查询性能。尤其是在瞬时编辑模式匹配中达到最优的O(Occ)时间复杂度，显示了其在理论和实践上的重要性。该工作为处理特定类型的动态文本数据提供了新的思路和工具。

<details>
  <summary>Details</summary>

**Motivation:** 瞬时编辑序列在处理独立编辑流或测试假设性编辑时出现，因此需要设计支持此类操作的高效文本索引和模式匹配数据结构。

**Method:** 本文提出了两种主要方法：1. 瞬时子串编辑的文本索引：预处理文本T在O(n)时间内，预处理模式P在O(m log log m)时间和O(m)空间内，查询所有匹配项在O(log log n + Occ)时间内。2. 瞬时编辑的模式匹配：预处理文本T和模式P在O(n)时间内，查询所有匹配项在最优的O(Occ)时间内。此外，还提供了一种针对瞬时块删除模式匹配的最优解。

**Result:** 1. 对于瞬时子串编辑的文本索引，文本预处理时间为O(n)，模式预处理时间为O(m log log m)，空间为O(m)，查询时间为O(log log n + Occ)。2. 对于瞬时编辑的模式匹配，文本和模式预处理时间为O(n)，查询时间为最优的O(Occ)。3. 实现了瞬时块删除模式匹配的最优解。

**Conclusion:** 本文成功引入了支持瞬时编辑的文本索引和模式匹配的新范式，并为这两种场景提供了高效甚至最优的算法，解决了处理动态文本数据中的特定编辑模式的挑战。

> **ai_Abstract:** 本文提出并解决了在瞬时编辑操作场景下的文本索引和模式匹配问题。瞬时编辑定义为成对出现，其中一个操作被紧随其后的操作还原。针对这类编辑，文章设计了两种新的数据结构和算法：一种是支持瞬时子串插入、删除和常数长度替换的文本索引，其查询时间为O(log log n + Occ)；另一种是支持任意瞬时编辑的模式匹配，实现了最优的O(Occ)查询时间。此外，还给出了瞬时块删除模式匹配的最优解，为处理动态数据流和假设性编辑提供了高效的解决方案。

> **摘要翻译:** 字符串T中的编辑操作序列e_0, e_1, ...被称为瞬时序列，如果对于所有i=2k（k∈N），构造字符串T^i的操作e_i被重建T的操作e_{i+1}还原。这种序列在处理独立的编辑流或测试假设性编辑时出现。
我们引入了瞬时子串编辑的文本索引，这是文本索引的一个新版本。我们的目标是设计一个给定文本上的数据结构，以支持后续在文本中进行瞬时子串插入、删除或替换的模式匹配查询；我们要求插入和替换是常数长度的。具体来说，我们以O(n)时间预处理整数字母表Σ=[0,σ)（其中σ=n^O(1)）上的文本T=T[0...n)。然后，我们可以在O(m log log m)时间O(m)空间内在线预处理任意模式P=P[0...m)，并允许T中任意瞬时编辑序列。在还原第i个操作之前，我们以O(log log n + Occ)时间报告P在T^i中的所有Occ出现。
我们还引入了瞬时编辑的模式匹配。具体来说，我们以O(n)时间预处理两个字符串T和P，每个长度至多为n，都在整数字母表Σ=[0,σ)（其中σ=n^O(1)）上。然后，我们允许T中任意瞬时编辑序列。在还原第i个操作之前，我们以最优的O(Occ)时间报告P在T^i中的所有Occ出现。在取得这一结果的过程中，我们还给出了瞬时块删除模式匹配的最优解。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [399] [Parameterized Algorithms for Spanning Tree Isomorphism by Redundant Set Size](https://arxiv.org/abs/2508.05351)
> *基于冗余集大小的生成树同构参数化算法*

*Fangjian Shen, Yicheng Zheng, Wushao Wen, Hankz Hankui Zhuo* | **Category: cs.DS** | **Updated: 2025-08-07**

**Keywords:** 生成树同构, 参数化算法, 冗余集, 固定参数可解性

**Comment:** 

> **TL;DR:** 本文提出了针对无向和有向生成树同构问题的固定参数可解算法，其参数为冗余集的大小k，并给出了具体的算法时间复杂度。

**AI_Comments:** 本文通过将生成树同构问题参数化为冗余集大小，为该问题提供了固定参数可解算法，这是一个有价值的创新方法。尽管时间复杂度在参数 $k$ 上呈指数级增长，但在顶点数量 $n$ 上是多项式的，这使得该算法对于冗余集较小的图具有实际意义。这对于图论和算法设计领域是一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为生成树同构问题（包括无向和有向版本）开发高效的固定参数可解算法，通过将冗余集的大小作为参数。

**Method:** 本文提出了固定参数可解算法，其参数为冗余集的大小k。冗余集被定义为移除后能将图转换为生成树的边集合。文章分别为无向和有向版本设计了算法。

**Result:** 对于无向生成树同构问题，算法的时间复杂度为$O(n^2 \log n \cdot 2^{k \log k})$。对于有向生成树同构问题，算法的时间复杂度为$O(n^2 \cdot 2^{4k-3})$，其中$n$是顶点的数量。

**Conclusion:** 本文成功提出了针对无向和有向生成树同构问题的固定参数可解算法，并展示了其基于冗余集大小参数的效率。

> **ai_Abstract:** 本文介绍了针对无向和有向生成树同构问题的固定参数可解算法。这些算法以冗余集的大小 $k$ 为参数，其中冗余集是移除后能使图变为生成树的边集合。对于无向图，算法的时间复杂度为 $O(n^2 \log n \cdot 2^{k \log k})$；对于有向图，算法的时间复杂度为 $O(n^2 \cdot 2^{4k-3})$，其中 $n$ 代表顶点数量。

> **摘要翻译:** 在本文中，我们提出了针对无向和有向生成树同构问题的固定参数可解算法，其参数为冗余集的大小 $k$。冗余集是指一组边的集合，移除这些边后图会变成一棵生成树。对于无向版本，我们的算法实现了 $O(n^2 \log n \cdot 2^{k \log k})$ 的时间复杂度。对于有向版本，我们提出了一个更高效的算法，其时间复杂度为 $O(n^2 \cdot 2^{4k-3})$，其中 $n$ 是顶点的数量。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [406] [Online Sparsification of Bipartite-Like Clusters in Graphs](https://arxiv.org/abs/2508.05437)
> *图的二部类簇的在线稀疏化*

*Joyentanuj Das, Suranjan De, He Sun* | **Category: cs.DS, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 图聚类, 在线稀疏化, 二部类簇, 图算法, 效率

**Comment:** 

> **TL;DR:** 本文研究图中的二部类簇，并提出高效的在线稀疏化算法，以显著加速现有图聚类算法的运行时间，同时保持其有效性。

**AI_Comments:** 该论文的创新点在于提出了针对图的二部类簇的在线稀疏化算法，这对于处理大规模图数据尤其重要。通过加速现有聚类算法，它解决了图分析中常见的计算效率问题，同时保持了聚类质量，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大多数图聚类算法的目标是找到低电导的顶点集，但最近的研究强调在分析真实世界数据集时，顶点集之间互连的重要性。本文沿着这一研究方向，关注二部类簇。

**Method:** 本文研究二部类簇，并提出了高效的在线稀疏化算法，用于在无向图和有向图中找到此类簇。

**Result:** 实验研究表明，本文提出的算法显著加速了现有聚类算法的运行时间，同时保留了它们的有效性。

**Conclusion:** 本文提出的在线稀疏化算法能够有效加速图聚类过程，同时保持聚类质量，为分析大规模图提供了新的高效工具。

> **ai_Abstract:** 本文关注图聚类中顶点集间互连的重要性，特别是针对二部类簇。提出了一种高效的在线稀疏化算法，用于在无向图和有向图中识别此类簇。实验结果表明，该算法能够显著提高现有图聚类算法的速度，同时不牺牲其有效性。

> **摘要翻译:** 图聚类是一种重要的算法技术，用于分析大规模图，并已广泛应用于数据科学的许多研究领域。虽然大多数图聚类算法的目标是找到低电导的顶点集，但最近一系列研究强调了在分析真实世界数据集时顶点集之间互连的重要性。沿着这一研究方向，本文研究了二部类簇，并提出了高效的在线稀疏化算法，用于在无向图和有向图中找到此类簇。我们在合成数据集和真实世界数据集上进行了实验研究，结果表明我们的算法显著加速了现有聚类算法的运行时间，同时保持了它们的有效性。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [414] [An Improved Approximation Algorithm for the Capacitated Arc Routing Problem](https://arxiv.org/abs/2508.05471)
> *一种改进的带容量弧路径问题的近似算法*

*Jingyang Zhao, Mingyu Xiao* | **Category: cs.DS** | **Updated: 2025-08-07**

**Keywords:** 带容量弧路径问题, 近似算法, 运筹学, 车辆容量, 近似比率

**Comment:** 

> **TL;DR:** 本文提出了一种新的近似算法，首次改进了带容量弧路径问题（CARP）在单位需求情况下的最佳近似比率。

**AI_Comments:** 本文的创新之处在于，它首次突破了带容量弧路径问题（CARP）在单位需求情境下近三十年未被改进的近似比率。这一进展对于运筹学中的弧路径问题研究具有重要意义，可能为未来更优的算法设计奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 在单位需求情况下，带容量弧路径问题（CARP）的最佳近似比率自1993年以来一直未能得到改进（由Jansen给出，为$\frac{5}{2}-\frac{1.5}{k}$），因此有必要对其进行改进。

**Method:** 基于最近在近似带容量车辆路径问题（CVRP）方面的进展，本文提出了一种新的近似算法。

**Result:** 本文提出了一种$(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-近似算法，该算法首次改进了Jansen的界限。

**Conclusion:** 本文提出的算法首次改进了Jansen在1993年为带容量弧路径问题（CARP）给出的近似比率。

> **ai_Abstract:** 本文针对单位需求情况下的带容量弧路径问题（CARP），提出了一种新的近似算法。该算法基于带容量车辆路径问题（CVRP）的最新进展，成功将CARP的最佳近似比率从Jansen在1993年提出的$\frac{5}{2}-\frac{1.5}{k}$改进为$(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$，实现了该领域近三十年来的首次突破。

> **摘要翻译:** 带容量弧路径问题（CARP）由Golden和Wong于1981年提出，是运筹学中一个重要的弧路径问题，它推广了著名的带容量车辆路径问题（CVRP）。当每个客户都有单位需求时，CARP的最佳已知近似比率由Jansen在1993年给出，仍然是$\frac{5}{2}-\frac{1.5}{k}$，其中$k$表示车辆容量。基于近期在近似CVRP方面的进展，我们通过提出一种$(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-近似算法来改进这一结果，据我们所知，这是对Jansen界限的首次改进。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [425] [Minimum-Weight Parity Factor Decoder for Quantum Error Correction](https://arxiv.org/abs/2508.04969)
> *量子纠错的最小权重奇偶因子解码器*

*Yue Wu, Binghong Li, Kathleen Chang, Shruti Puri, Lin Zhong* | **Category: cs.DS, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子纠错, 解码器, 最小权重奇偶因子, 超图, HyperBlossom

**Comment:** 

> **TL;DR:** 本文提出了HyperBlossom，一个统一的量子纠错（QEC）解码框架，将最可能错误（MLE）解码公式化为最小权重奇偶因子（MWPF）问题，并通过推广blossom算法到超图来解决。其软件实现Hyperion在逻辑错误率和运行时效率方面均优于现有解码器，对可扩展容错量子计算至关重要。

**AI_Comments:** HyperBlossom的创新之处在于其将MLE解码统一为MWPF问题，并将blossom算法推广到超图，从而弥合了启发式解码器和可认证解码器之间的差距。这对于通过提供快速准确的解码解决方案来实现可扩展的容错量子计算至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 快速准确的量子纠错（QEC）解码对于可扩展的容错量子计算至关重要。最可能错误（MLE）解码虽然接近最优，但对于一般的量子低密度奇偶校验（qLDPC）码来说是难以处理的，通常依赖于近似和启发式方法。

**Method:** 本文提出了HyperBlossom，一个统一的框架，将最可能错误（MLE）解码公式化为最小权重奇偶因子（MWPF）问题。它通过类似的原始-对偶线性规划模型将blossom算法推广到超图，并具有可证明的接近性界限。HyperBlossom统一了所有现有的基于图的解码器，如（超图）Union-Find解码器和最小权重完美匹配（MWPM）解码器。该方法在软件中实现，命名为Hyperion。

**Result:** Hyperion在距离为11的表面码上，逻辑错误率比MWPM解码器低4.8倍。在代码容量噪声下，对于[[90, 8, 10]]双变量自行车码，其逻辑错误率比经过微调的BPOSD解码器低1.6倍。它在表面码和颜色码上都实现了几乎线性的平均运行时缩放，数值结果在足够大的代码距离（代码容量噪声下为99，电路级噪声下为31）下得到验证。

**Conclusion:** HyperBlossom/Hyperion为量子纠错（QEC）解码提供了一个统一、高效且准确的解决方案，弥合了启发式解码器和可认证解码器之间的鸿沟，对于实现可扩展的容错量子计算至关重要。

> **ai_Abstract:** HyperBlossom是一种新颖的统一量子纠错（QEC）解码框架，通过将最可能错误（MLE）解码公式化为最小权重奇偶因子（MWPF）问题，解决了其难以处理的问题。该框架将blossom算法推广到超图，并统一了现有的基于图的解码器。其软件实现Hyperion在逻辑错误率方面显著优于MWPM和BPOSD解码器，并实现了近线性的运行时缩放，为可扩展的容错量子计算铺平了道路。

> **摘要翻译:** 快速准确的量子纠错（QEC）解码对于可扩展的容错量子计算至关重要。最可能错误（MLE）解码虽然接近最优，但对于一般的量子低密度奇偶校验（qLDPC）码来说是难以处理的，通常依赖于近似和启发式方法。我们提出了HyperBlossom，一个统一的框架，将MLE解码公式化为最小权重奇偶因子（MWPF）问题，并通过类似的原始-对偶线性规划模型将blossom算法推广到超图，并具有可证明的接近性界限。HyperBlossom统一了所有现有的基于图的解码器，如（超图）Union-Find解码器和最小权重完美匹配（MWPM）解码器，从而弥合了启发式解码器和认证解码器之间的鸿沟。
我们在软件中实现了HyperBlossom，即Hyperion。在距离为11的表面码上，Hyperion的逻辑错误率比MWPM解码器低4.8倍；在代码容量噪声下，对于[[90, 8, 10]]双变量自行车码，其逻辑错误率比经过微调的BPOSD解码器低1.6倍。它在表面码和颜色码上都实现了几乎线性的平均运行时缩放，数值结果在足够大的代码距离（代码容量噪声下为99，电路级噪声下为31）下得到验证。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [426] [Computing the probability of intersection](https://arxiv.org/abs/2507.10329)
> *计算交集的概率*

*Alexander Barvinok* | **Category: cs.DS, math.CO, math.PR** | **Updated: 2025-08-07**

**Keywords:** 概率, 交集, 补集, 多项式时间, 依赖事件

**Comment:** 

> **TL;DR:** 本文证明了在特定条件下，可以多项式时间高效计算多个事件补集的交集概率。

**AI_Comments:** 该论文的主要创新在于，它为在特定依赖结构和概率条件下，高效计算复杂概率（事件补集的交集）提供了理论保证（多项式时间复杂度及相对误差）。其重要性在于为处理具有局部依赖性的事件系统提供了计算框架。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 该研究通过数学证明，表明在特定条件下，事件补集交集的概率可以从k维事件交集的概率中在多项式时间内计算出来。

**Result:** 如果对于所有事件$A_i$，其概率$P(A_i) < (3	ext{Δ})^{-3	ext{μ}_i}$，那么对于任意$0 < 	ext{ϵ} < 1$，所有$A_i$的补集交集的概率$Pig( igcap_{i=1}^n ar{A}_iig)$可以从$k$维事件交集的概率$P(A_{i_1} igcap 	ext{...} igcap A_{i_k})$中，在多项式时间内以相对误差$	ext{ϵ}$计算出来，其中$k = e^{O(	ext{Δ})} 	ext{ln} (n/	ext{ϵ})$。

**Conclusion:** 该论文证明了在事件概率足够小且依赖关系受限的情况下，可以高效地近似计算多个事件补集的交集概率。

> **ai_Abstract:** 本文研究了在乘积概率空间中，一组事件补集交集概率的计算问题。研究发现，在单个事件概率$P(A_i)$相对于依赖参数$\Delta$和坐标依赖度$r_i$足够小的情况下，该复杂概率可以在多项式时间内以给定的相对误差$\epsilon$进行近似计算。此近似计算依赖于已知$k$维事件交集的概率，其中$k$的值与$\Delta$呈指数关系，与$n/\epsilon$呈对数关系。

> **摘要翻译:** 设 $\Omega_1, \ldots, \Omega_m$ 是概率空间，$\Omega=\Omega_1 \times \cdots \times \Omega_m$ 是它们的乘积，且 $A_1, \ldots, A_n \subset \Omega$ 是事件。假设每个事件 $A_i$ 依赖于点 $x \in \Omega$ 的 $r_i$ 个坐标，$x=\left(\xi_1, \ldots, \xi_m\right)$，并且对于每个事件 $A_i$，有 $\Delta_i$ 个其他事件 $A_j$ 依赖于 $A_i$ 所依赖的某些坐标。令 $\Delta=\max\{5,\ \Delta_i: i=1, \ldots, n\}$，并令 $\mu_i=\min\{r_i,\ \Delta_i+1\}$ 对于 $i=1, \ldots, n$。我们证明，如果对于所有 $i$，$P(A_i) < (3\Delta)^{-3\mu_i}$，那么对于任何 $0 < \epsilon < 1$，所有 $A_i$ 的补集交集的概率 $P\left( \bigcap_{i=1}^n \overline{A}_i\right)$ 可以从事件 $A_i$ 的 $k$ 维交集概率 $P\left(A_{i_1} \cap \ldots \cap A_{i_k}\right)$ 在多项式时间内以相对误差 $\epsilon$ 计算出来，其中 $k = e^{O(\Delta)} \ln (n/\epsilon)$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [437] [Injection Locking and Coupling Dynamics in Superconducting Nanowire based Cryogenic Oscillators](https://arxiv.org/abs/2508.04878)
> *基于超导纳米线低温振荡器的注入锁定和耦合动力学研究*

*Md Mazharul Islam, Md Shafayat Hossain, Kathleen E Hamilton, Ahmedullah Aziz* | **Category: cs.ET, physics.app-ph** | **Updated: 2025-08-06**

**Keywords:** 超导纳米线, 低温振荡器, 注入锁定, 互耦, 相位控制

**Comment:** 

> **TL;DR:** 本文对基于超导纳米线的低温振荡器的注入锁定和互耦动力学进行了全面的数值研究，确定了影响锁定范围的关键设计参数，并展示了通过调节耦合强度精确控制振荡器间相位差以实现可编程相位编码信息处理的可能性，为构建低温神经网络和逻辑块提供了基础。

**AI_Comments:** 该论文通过对超导纳米线低温振荡器注入锁定和互耦动力学的数值研究，深入探讨了低温环境下频率同步和信号协调的关键机制。其创新之处在于识别了影响锁定范围的关键设计参数，并揭示了通过调节耦合强度精确控制振荡器间相位差的可能性，这对于未来低温计算和量子信息处理中的同步和信息编码具有重要价值。成果直接指向了低温神经网络和逻辑块的构建，具有重要的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 低温振荡器在超导电子学和量子计算中至关重要，它们能提供稳定、低噪声且能量损耗极小的信号。

**Method:** 本文采用全面的数值研究方法， investigates 了基于超导纳米线（ScNW）的独立振荡器的设计空间，并分析了两种关键机制：外部交流信号引起的注入锁定和两个ScNW振荡器在不同耦合强度下的互耦动力学。

**Result:** 研究识别了影响锁定范围的关键设计参数，包括并联电阻、纳米线电感和耦合强度。此外，研究发现注入信号的幅度会影响锁定振荡的幅度，为功率感知的振荡器同步提供了见解。结果还表明，通过调整耦合强度可以精确控制振荡器之间的相位差，从而实现可编程的相位编码信息处理。

**Conclusion:** 这些发现有望促进基于ScNW的振荡神经网络、同步低温逻辑块和片上低温谐振器阵列的构建。

> **ai_Abstract:** 本文对超导纳米线（ScNW）低温振荡器的注入锁定和互耦动力学进行了全面的数值研究。研究探究了外部信号注入锁定和两振荡器互耦两种关键机制，并确定了影响锁定范围的关键设计参数（如并联电阻、纳米线电感和耦合强度）。结果表明，通过调节耦合强度可以精确控制振荡器间的相位差，为实现可编程相位编码信息处理提供了可能。这些发现对构建ScNW基振荡神经网络、同步低温逻辑块和片上低温谐振器阵列具有重要意义。

> **摘要翻译:** 设计用于低温环境的振荡器在超导电子学和量子计算中发挥着关键作用，通过提供稳定、低噪声且能量损耗极小的信号。本文对基于超导纳米线的低温振荡器中的注入锁定和互耦动力学进行了全面的数值研究。利用独立ScNW振荡器的设计空间，我们研究了控制低温计算架构中频率同步和信号协调的两个关键机制。首先，由频率接近振荡器固有频率的外部交流信号引起的注入锁定；其次，两个ScNW振荡器在不同耦合强度下的互耦动力学。我们确定了控制锁定范围的关键设计参数，例如并联电阻、纳米线电感和耦合强度。此外，我们研究了注入信号的幅度如何影响锁定振荡的幅度，为功率感知的振荡器同步提供了宝贵的见解。此外，我们使用电容和电阻耦合元件分析了耦合ScNW振荡器之间的相互同步。我们的结果表明，通过调节耦合强度可以精确控制振荡器之间的相位差，从而实现可编程的相位编码信息处理。这些发现有望促进基于ScNW的振荡神经网络、同步低温逻辑块和片上低温谐振器阵列的构建。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [446] [Wave Computing based on Dynamical Networks: Applications in Optimization Problems](https://arxiv.org/abs/2508.05014)
> *基于动态网络的波计算：在优化问题中的应用*

*Yunwen Liu, Jiang Xiao* | **Category: cs.ET** | **Updated: 2025-08-07**

**Keywords:** 波计算, 动态网络, 优化问题, NP-hard问题, 并行计算

**Comment:** 

> **TL;DR:** 本文提出了一种利用互联网络中波传播的计算框架，能够高效并行解决NP-hard问题，并在SPICE仿真中得到验证。

**AI_Comments:** 该研究提出了一种新颖的波计算范式，通过利用波传播的多维特性和内在并行性来解决NP-hard问题，这是一种不同于传统数字计算的创新方法。其在SPICE仿真中对多个经典NP-hard问题的验证，显示了其在硬件实现上的潜在可行性和高效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的计算方法在处理NP-hard问题时效率低下，本文旨在开发一种新的计算范式，通过波传播的内在并行性来有效解决这些问题。

**Method:** 开发了一个利用互联网络中波传播的计算框架，其中节点和边具有波操控能力（如频率混合或时间延迟）。该架构通过SPICE仿真进行了验证。

**Result:** 该计算范式不仅能实现现有工作的内在并行性，同时探索指数级的可能性，并将其扩展到空间、时间和频率等多维空间。SPICE仿真验证了其在解决数个NP-hard问题（如数字分区问题、0/1背包问题和旅行商问题）方面的潜力。

**Conclusion:** 基于动态网络的波计算框架通过利用波传播的内在并行性，在解决NP-hard问题方面展现出巨大的潜力。

> **ai_Abstract:** 本文提出了一种基于动态网络的波计算框架，利用互联网络中波的传播特性，通过节点和边的波操控能力实现计算。该框架利用多维空间中的波传播，扩展了内在并行性，使其特别适用于解决NP-hard问题。通过SPICE仿真，该架构在解决数字分区问题、0/1背包问题和旅行商问题等NP-hard问题上展现了潜力。

> **摘要翻译:** 我们开发了一个计算框架，该框架利用互联网络中的波传播，其中节点和边缘具有波操纵能力，例如频率混合或时间延迟。这种计算范式不仅可以通过同时探索指数级的可能性，以非常少的硬件单元实现现有工作的内在并行性，而且还将这种独特的特性扩展到包括空间、时间和频率域在内的多维空间，使其特别有效地解决NP-hard问题。所提出的架构已通过SPICE仿真验证，展示了其在解决多个NP-hard问题（例如数字分区问题、0/1背包问题和旅行商问题）方面的潜在能力。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [455] [QFOR: A Fidelity-aware Orchestrator for Quantum Computing Environments using Deep Reinforcement Learning](https://arxiv.org/abs/2508.04974)
> *QFOR：一种基于深度强化学习的量子计算环境保真度感知编排器*

*Hoa T. Nguyen, Muhammad Usman, Rajkumar Buyya* | **Category: cs.ET, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子计算, 深度强化学习, 任务编排, 保真度, 马尔可夫决策过程

**Comment:** 

> **TL;DR:** QFOR利用深度强化学习解决量子云计算中任务分配和调度问题，通过平衡执行保真度和时间，显著提升了性能。

**AI_Comments:** QFOR的创新点在于将深度强化学习应用于量子任务编排，以应对异构和噪声量子硬件的挑战，并通过平衡保真度和时间来优化性能。其将量子任务编排建模为马尔可夫决策过程并采用PPO算法是其方法的核心，显著提高了执行保真度。该研究对于未来量子云计算资源的优化管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子云计算环境中的异构性和噪声导致高效资源编排面临挑战，现有启发式方法难以适应动态条件或有效平衡执行保真度和时间。

**Method:** 本文提出了QFOR，一个使用深度强化学习在云端异构量子节点上进行量子任务保真度感知编排的框架。它将量子任务编排建模为马尔可夫决策过程，并采用近端策略优化（PPO）算法学习自适应调度策略，利用IBM量子处理器校准数据进行噪声感知性能估计。

**Result:** QFOR在相对保真度性能上比启发式基线提高了29.5-84%，同时保持了可比的量子执行时间，有助于经济高效地利用量子计算资源。

**Conclusion:** QFOR通过深度强化学习实现了对异构量子硬件的有效任务编排，显著提高了量子任务的执行保真度，并保持了高效的执行时间，为量子云计算提供了自适应和成本效益高的解决方案。

> **ai_Abstract:** 本文提出了QFOR，一个基于深度强化学习的量子任务编排框架，旨在解决量子云计算中异构和噪声硬件带来的资源分配挑战。QFOR将任务编排建模为马尔可夫决策过程，并利用近端策略优化算法学习自适应调度策略，以平衡量子任务的执行保真度和时间。通过对IBM量子处理器校准数据的利用，QFOR能够进行噪声感知性能估计。实验结果表明，QFOR在相对保真度性能上比传统启发式方法有显著提升（29.5-84%），同时保持了可比的执行时间，从而提高了量子计算资源的利用效率。

> **摘要翻译:** 量子云计算使得远程访问量子处理器成为可能，然而现有量子硬件的异构性和噪声给高效资源编排带来了巨大挑战。这些问题使得量子任务分配和调度的优化变得复杂，因为现有的启发式方法在适应动态条件或有效平衡执行保真度和时间方面存在不足。本文提出了QFOR，一个使用深度强化学习在云端异构量子节点上进行量子任务保真度感知编排的框架。我们将量子任务编排建模为马尔可夫决策过程，并采用近端策略优化算法学习自适应调度策略，利用IBM量子处理器校准数据进行噪声感知性能估计。我们可配置的框架平衡了整体量子任务执行保真度和时间，使其能够适应不同的操作优先级。广泛的评估表明，QFOR具有自适应性，并在相对保真度性能上比启发式基线提高了29.5-84%，实现了显著的性能提升。此外，它保持了可比的量子执行时间，有助于经济高效地利用量子计算资源。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [464] [Salt-Rock Creep Deformation Forecasting Using Deep Neural Networks and Analytical Models for Subsurface Energy Storage Applications](https://arxiv.org/abs/2508.05248)
> *盐岩蠕变变形预测：基于深度神经网络和分析模型在地下能源储存应用中的研究*

*Pradeep Kumar Shukla, Tanujit Chakraborty, Mustafa Sari, Joel Sarout, Partha Pratim Mandal* | **Category: cs.ET, cs.LG, physics.geo-ph** | **Updated: 2025-08-07**

**Keywords:** 盐岩蠕变, 深度神经网络, 时间序列预测, 地下储存, N-BEATS, TCN

**Comment:** 

> **TL;DR:** 本研究利用深度神经网络（N-BEATS和TCN）准确预测盐岩蠕变变形，为地下能源储存设施设计提供支持，其性能优于传统分析模型。

**AI_Comments:** 该研究创新性地将多种深度神经网络模型应用于盐岩蠕变变形预测，并与传统分析模型进行了量化比较，突出了DNN在处理复杂时序数据方面的显著优势。其结果对于地下核废料、氢能等储存设施的长期安全设计和运行具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 蠕变变形评估对于设计和操作核废料、氢能或放射性材料的地下储存设施至关重要。

**Method:** 研究使用多级三轴（MSTL）蠕变数据，在不同围压下记录轴向应变数据集。进行了季节-趋势分解（STL）、格兰杰因果检验、增广迪基-富勒（ADF）检验和小波相干图（WCP）分析。然后，利用N-BEATS、TCN、RNN和Transformer等深度神经网络模型，并与统计基线模型进行比较，使用RMSE、MAE、MAPE和SMAPE评估预测性能。

**Result:** N-BEATS和TCN模型在不同应力水平下表现优于其他模型。深度神经网络模型，特别是N-BEATS和TCN，在准确性上比传统分析模型提高了15-20%，有效捕获了复杂的时序依赖性和模式。

**Conclusion:** 深度神经网络模型，尤其是N-BEATS和TCN，能够有效且更准确地预测盐岩蠕变变形，对地下能源储存设施的长期安全设计和运行具有重要意义。

> **ai_Abstract:** 本研究深入探讨了利用深度神经网络（DNN）和分析模型预测盐岩蠕变变形的方法，这对地下能源储存设施的设计和运行至关重要。研究利用多级三轴蠕变数据，并进行了多项统计分析以确认数据特性。结果显示，N-BEATS和TCN等DNN模型在预测准确性上比传统分析模型提高了15-20%，有效捕捉了复杂的时序模式，证明了其在盐岩蠕变预测中的优越性。

> **摘要翻译:** 本研究深入分析了时间序列预测方法，以预测盐岩在不同围压条件下的时间依赖性变形趋势（也称为蠕变）。蠕变变形评估对于设计和运行核废料、氢能或放射性材料的地下储存设施至关重要。研究使用多级三轴（MSTL）蠕变数据对盐岩进行了检查，盐岩以其低孔隙度、低渗透率、高延展性以及卓越的蠕变和自愈合能力等机械性能而闻名。重采样后，在5-35 MPa的围压水平下，以5-10秒的间隔记录了为期5.8-21天的轴向应变数据集。初步分析，包括季节-趋势分解（STL）和格兰杰因果检验，表明轴向应变与温度数据之间的季节性和因果关系极小。进一步的统计检验，如增广迪基-富勒（ADF）检验，证实了数据在p值小于0.05的情况下是平稳的，小波相干图（WCP）分析表明存在重复趋势。研究利用了一系列深度神经网络（DNN）模型（时间序列神经基扩展分析（N-BEATS）、时间卷积网络（TCN）、循环神经网络（RNN）和Transformer（TF）），并与统计基线模型进行了比较。预测性能使用均方根误差（RMSE）、平均绝对误差（MAE）、平均绝对百分比误差（MAPE）和对称平均绝对百分比误差（SMAPE）进行评估。结果表明，N-BEATS和TCN模型在不同应力水平下分别优于其他模型。DNN模型，特别是N-BEATS和TCN，在准确性上比传统分析模型提高了15-20%，有效捕获了复杂的时序依赖性和模式。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csfl'></a>
## cs.FL 

### [471] [A Dichotomy for $k$-automatic expansions of Presburger Arithmetic](https://arxiv.org/abs/2508.04851)
> *k-自动展开Presburger算术的二分法*

*Jason Bell, Alexi Block Gorman, Chris Schulz* | **Category: cs.FL, math.LO** | **Updated: 2025-08-06**

**Keywords:** 二分法, k-自动, Presburger算术, 可定义性

**Comment:** 

> **TL;DR:** 对于非最终周期性的k-自动集合X，将其加入Presburger算术中会产生一个二分法：要么所有k-自动集合都变得可定义，要么所得结构等同于加入k的幂。

**AI_Comments:** 这篇论文在逻辑学、数论和自动机理论的交叉领域提出了一个重要的理论成果，为Presburger算术在被某些k-自动集合扩展时的表达能力提供了一个清晰的分类。这个二分法对理解此类扩展系统中的可定义性性质提供了深刻的见解。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨当一个特定的k-自动且非最终周期性的自然数子集X作为谓词加入Presburger算术时，k-自动子集的定义性问题。核心动机是建立一个关于其表达能力的“二分法”。

**Method:** 本文通过理论证明和逻辑分析，确立了一个二分法成立。

**Result:** 结果是一个二分法：要么所有k-自动子集都可以在加入了谓词X的Presburger算术中定义，要么结构$(\mathbb{N},+,X)$等同于$(\mathbb{N},+,k^{\mathbb{N}})$。

**Conclusion:** 本论文确立了一个关于k-自动子集可定义性的基本二分法，该二分法在Presburger算术通过加入特定类型的k-自动集合X进行扩展时成立。

> **ai_Abstract:** 本论文探讨了在扩展的Presburger算术中k-自动子集的可定义性。具体而言，对于一个k-自动且非最终周期性的自然数子集X，研究表明存在一个二分法：所有k-自动子集要么在加入了谓词X的Presburger算术中变得可定义，要么扩展结构$(\mathbb{N},+,X)$与$(\mathbb{N},+,k^{\mathbb{N}})$等价。

> **摘要翻译:** 设 $k\ge 2$，并且 $X$ 是自然数的一个子集，它是 $k$-自动的且不是最终周期性的。我们证明存在一个二分法：要么所有 $k$-自动子集都可以在扩充的Presburger算术中定义，其中我们加入了谓词 $X$，要么 $(\mathbb{N},+,X)=(\mathbb{N},+,k^{\mathbb{N}})$。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [479] [Overview of Controllability Definitions in Supervisory Control Theory](https://arxiv.org/abs/2508.05177)
> *监督控制理论中可控性定义的概述*

*Jeroen J.A. Keiren, Michel A. Reniers* | **Category: cs.FL, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 监督控制理论, 可控性, 定义, 确定性自动机, 非确定性自动机

**Comment:** 

> **TL;DR:** 本文概述了监督控制理论中可控性的各种定义，并分析了它们在确定性和非确定性自动机设置中的关系，指出哪些定义是等价的以及哪些定义隐含了传统的语言可控性。

**AI_Comments:** 本文的创新之处在于系统地梳理和比较了监督控制理论中多个可控性定义，并明确了它们之间的等价性和蕴含关系，尤其是在非确定性系统背景下。这对于统一该领域的术语和概念理解，促进理论研究和实际应用具有重要意义。它解决了长期存在的概念混淆问题，为后续研究奠定了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在监督控制理论领域，文献中经常为同一概念提出不同的定义，这使得理解这些定义之间的关系变得困难。特别是对于主管相对于工厂的可控性这一基本概念。

**Method:** 本文列出了文献中发现的可控性定义，并在确定性和非确定性自动机设置中研究了它们之间的关系。

**Result:** 在主管和工厂都被允许为非确定性的通用上下文中，Flordal和Malik描述的可控性概念以及Kushi和Takai的不可控事件可接受性概念是等价的。这些也是唯一隐含传统（语言）可控性概念的定义。从实践角度来看，在受控工厂相对于工厂的可控性上下文中，除了前述两个可控性概念外，Zhou等人的状态可控性也隐含语言可控性。

**Conclusion:** 本文澄清了监督控制理论中不同可控性定义之间的复杂关系，指出了它们在确定性和非确定性环境下的等价性和蕴含关系，对于理解和应用这些概念具有重要意义。

> **ai_Abstract:** 本文旨在解决监督控制理论中可控性概念定义多样且关系不明晰的问题。研究梳理了文献中现有的可控性定义，并在确定性与非确定性自动机框架下分析了它们之间的相互关系。研究发现，在通用非确定性环境下，Flordal和Malik的可控性定义与Kushi和Takai的不可控事件可接受性定义是等价的，并且只有它们隐含了传统的语言可控性。此外，在考虑受控工厂的可控性时，Zhou等人的状态可控性也隐含语言可控性。

> **摘要翻译:** 在监督控制理论领域，文献中经常为同一概念提出不同的定义，这使得理解这些定义之间的关系变得困难。对于主管相对于工厂的可控性这一基本概念来说，情况更是如此。本文列出了文献中发现的可控性定义，并在确定性和非确定性自动机设置中研究了它们之间的关系。在通用上下文中，当主管和工厂都被允许为非确定性时，Flordal和Malik描述的可控性概念以及Kushi和Takai的不可控事件可接受性概念是等价的。这些也是唯一隐含传统（语言）可控性概念的定义。从实践角度来看，人们通常更关注受控工厂相对于工厂的可控性。在这种情况下，除了前述两个可控性概念外，Zhou等人的状态可控性也隐含语言可控性。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

### [487] [Watson-Crick conjugates of words and languages](https://arxiv.org/abs/2208.03123)
> *单词和语言的沃森-克里克共轭*

*Kalpana Mahalingam, Anuran Maity* | **Category: cs.FL, math.CO** | **Updated: 2025-08-07**

**Keywords:** 沃森-克里克共轭, 形式语言, $\theta$-共轭, 闭包性质, 可判定性

**Comment:** 

> **TL;DR:** 本文探索了单词和语言的沃森-克里克共轭（即 $\theta$-共轭）的概念，将其扩展到包含DNA序列的互补性，并研究了其性质、语言的闭包性质、迭代共轭以及相关可判定性问题。

**AI_Comments:** 本文的创新点在于将生物学中DNA的沃森-克里克互补性引入到形式语言理论的共轭概念中，从而创建了一个新的理论框架。这为理解单词和语言的结构提供了新的视角，并可能在生物信息学或理论计算机科学中找到潜在应用。研究的全面性体现在对基本性质、闭包属性、迭代行为和可判定性问题的系统性探讨。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过引入DNA序列的沃森-克里克互补性，扩展经典的共轭概念，从而探索单词和语言的沃森-克里克共轭（即$\theta$-共轭）的概念。

**Method:** 本研究首先探讨了单词$\theta$-共轭的性质。接着，定义了语言的$\theta$-共轭，并研究了某些语言族在$\theta$-共轭操作下的闭包性质。此外，还分析了单词和语言的迭代$\theta$-共轭。最后，讨论了$\theta$-共轭自由语言的概念，并检查了与其相关的一些可判定性问题。

**Result:** 本文探索了单词$\theta$-共轭的性质，定义了语言的$\theta$-共轭并研究了其在某些语言族下的闭包性质，分析了单词和语言的迭代$\theta$-共轭，并讨论了$\theta$-共轭自由语言的概念及相关可判定性问题。

**Conclusion:** 本文全面探索了单词和语言的沃森-克里克共轭（$\theta$-共轭）的概念，涵盖了其基本性质、对语言家族的影响、迭代行为以及相关理论问题。

> **ai_Abstract:** 本文引入并深入探讨了单词和语言的沃森-克里克共轭（$\theta$-共轭）概念，该概念是经典共轭的扩展，融入了DNA序列的互补性。研究内容包括分析单词$\theta$-共轭的性质、定义语言的$\theta$-共轭并考察其闭包性质、探究迭代$\theta$-共轭，以及讨论$\theta$-共轭自由语言及其可判定性问题。

> **摘要翻译:** 在这项工作中，我们探索了单词和语言的沃森-克里克共轭，也称为$\theta$-共轭（其中$\theta$是一个反同态对合）的概念。这个概念通过结合DNA序列的沃森-克里克互补性，扩展了经典的共轭思想。我们的研究最初集中在单词$\theta$-共轭的性质上。然后，我们定义了语言的$\theta$-共轭，并研究了某些语言族在$\theta$-共轭操作下的闭包性质。此外，我们分析了单词和语言的迭代$\theta$-共轭。最后，我们讨论了$\theta$-共轭自由语言的思想，并检查了与其相关的一些可判定性问题。

</details>

[⬆️ 返回分类顶部](#csfl) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [531] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
> *LumiGen：一种用于细粒度文本到图像生成的LVLM增强迭代框架*

*Xiaoqi Dong, Xiangyu Zhou, Nicholas Evans, Yujia Lin* | **Category: cs.GR, cs.LG** | **Updated: 2025-08-05**

**Keywords:** 文本到图像生成, LVLM, 细粒度控制, 迭代框架, 扩散模型

**Comment:** 

> **TL;DR:** LumiGen是一个LVLM增强的迭代框架，通过智能提示解析和视觉反馈机制，显著提升了文本到图像生成在复杂指令、细粒度控制和语义一致性方面的性能。

**AI_Comments:** LumiGen的创新点在于其将LVLM的强大理解能力融入T2I生成过程，构建了一个闭环的迭代反馈机制。这种“视觉评论家”的角色，使得模型能够自我纠正和优化，显著提升了细粒度控制和语义一致性。这为未来T2I模型的发展提供了一个有前景的方向，特别是在需要高精度内容控制的应用场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型在文本到图像（T2I）生成方面取得了显著进展，但现有模型在处理复杂指令、确保细粒度内容控制和保持深度语义一致性方面仍面临挑战，例如准确的文本渲染、精确的姿态生成或复杂的构图连贯性。

**Method:** 我们提出了LumiGen，一个新颖的LVLM增强迭代框架。它通过一个闭环、LVLM驱动的反馈机制来提升T2I模型性能。LumiGen包含一个用于主动提示增强的智能提示解析与增强（IPPA）模块，以及一个作为“视觉评论家”迭代纠正和优化生成图像的迭代视觉反馈与细化（IVFR）模块。

**Result:** 在具有挑战性的LongBench-T2I基准测试中，LumiGen取得了3.08的卓越平均分数，优于最先进的基线模型。该框架在文本渲染和姿态表达等关键维度上表现出显著改进。

**Conclusion:** LumiGen通过LVLM的集成，有效地实现了更可控和更高质量的图像生成，验证了其在细粒度控制方面的有效性。

> **ai_Abstract:** 本文提出了LumiGen，一个LVLM增强的迭代框架，旨在解决现有文本到图像（T2I）模型在处理复杂指令和实现细粒度控制方面的不足。LumiGen通过智能提示解析与增强（IPPA）模块进行主动提示优化，并利用迭代视觉反馈与细化（IVFR）模块作为“视觉评论家”迭代改进图像。实验结果表明，LumiGen在LongBench-T2I基准测试中表现优异，尤其在文本渲染和姿态表达方面显著提升了生成图像的质量和可控性。

> **摘要翻译:** 文本到图像（T2I）生成在扩散模型方面取得了显著进展，但在处理复杂指令、确保细粒度内容控制和保持深度语义一致性方面仍存在挑战。现有的T2I模型在诸如准确的文本渲染、精确的姿态生成或复杂的构图连贯性等任务上常常表现不佳。同时，视觉语言模型（LVLM）在跨模态理解和指令遵循方面展示了强大的能力。我们提出了LumiGen，一个新颖的LVLM增强迭代框架，旨在通过闭环、LVLM驱动的反馈机制提升T2I模型性能，特别是在需要细粒度控制的领域。LumiGen包含一个用于主动提示增强的智能提示解析与增强（IPPA）模块，以及一个迭代视觉反馈与细化（IVFR）模块，该模块充当“视觉评论家”，迭代地纠正和优化生成的图像。在具有挑战性的LongBench-T2I基准测试中进行评估，LumiGen取得了3.08的卓越平均分数，优于最先进的基线模型。值得注意的是，我们的框架在文本渲染和姿态表达等关键维度上表现出显著改进，验证了LVLM集成对于更可控和更高质量图像生成的有效性。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [537] [Radiance Fields in XR: A Survey on How Radiance Fields are Envisioned and Addressed for XR Research](https://arxiv.org/abs/2508.04326)
> *辐射场在XR中的应用：关于辐射场如何被设想和应用于XR研究的综述*

*Ke Li, Mana Masuda, Susanne Schmidt, Shohei Mori* | **Category: cs.GR** | **Updated: 2025-08-07**

**Keywords:** 辐射场, XR, 综述, 3D高斯泼溅, 神经辐射场

**Comment:** 

> **TL;DR:** 该综述分析了辐射场（如3DGS和NeRF）在XR领域的研究现状，旨在理解研究差距，并为XR社区提供资源。

**AI_Comments:** 这篇综述论文的重要性在于它系统性地梳理了辐射场技术在XR领域的应用现状和未来潜力。它不仅指出了当前研究的空白，还通过对大量文献的分析，为研究人员提供了清晰的路线图，帮助他们理解如何将前沿的辐射场技术更好地融入到XR应用中。其价值在于为XR社区提供了一个导航工具，促进了跨学科的交流与合作。

<details>
  <summary>Details</summary>

**Motivation:** 尽管辐射场（RF）研究呈指数级增长，但与XR社区相关的贡献仍然稀少。为了更好地理解这一研究空白，作者进行了系统性综述。

**Method:** 作者对当前RF文献进行了系统性综述，收集了来自计算机视觉、计算机图形学、机器人学、多媒体、人机交互和XR社区的365篇与XR相关的RF贡献。其中，对66篇详细探讨了RF在XR中特定方面的论文进行了深入分析。

**Result:** 该综述分析了辐射场如何被设想用于XR应用，它们如何已被实现，以及仍存在的研��差距。通过这项调查，作者扩展并定位了XR特有的RF研究主题在更广泛的RF研究领域中的位置。

**Conclusion:** 这项综述扩展并定位了XR特有的辐射场研究主题在更广泛的辐射场研究领域中的位置，并为XR社区在辐射场研究的快速发展中提供了有用的资源。

> **ai_Abstract:** 本论文对辐射场（RF）在XR领域的研究进行了系统性综述，旨在弥补现有研究空白。作者收集并分析了365篇与XR相关的RF论文，其中66篇进行了深入分析，探讨了RF在XR中的设想、实现方式及未来研究方向。该综述为XR社区提供了宝贵的资源，以应对RF技术的快速发展。

> **摘要翻译:** 辐射场（RF）如三维高斯泼溅（3DGS）和神经辐射场（NeRF）的发展，彻底改变了交互式照片级真实感视图合成，并为XR研究和应用带来了巨大的机遇。然而，尽管RF研究呈指数级增长，RF与XR社区相关的贡献仍然稀少。为了更好地理解这一研究空白，我们对当前RF文献进行了系统性综述，以分析（i）RF如何被设想用于XR应用，（ii）它们如何已被实现，以及（iii）剩余的研究空白。我们从计算机视觉、计算机图形学、机器人学、多媒体、人机交互和XR社区收集了365篇与XR相关的RF贡献，旨在回答上述研究问题。在这365篇论文中，我们对66篇已详细探讨RF在XR中特定方面的论文进行了分析。通过这项综述，我们扩展并定位了XR特有的RF研究主题在更广泛的RF研究领域中的位置，并为XR社区在RF研究的快速发展中提供了有用的资源。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [543] [InSituTale: Enhancing Augmented Data Storytelling with Physical Objects](https://arxiv.org/abs/2507.21411)
> *InSituTale：通过物理对象增强增强数据叙事*

*Kentaro Takahira, Yue Yu, Takanori Fujiwara, Ryo Suzuki, Huamin Qu* | **Category: cs.GR, cs.HC** | **Updated: 2025-08-07**

**Keywords:** 增强数据叙事, 物理对象, 可视化控制, 人机交互, InSituTale

**Comment:** 

> **TL;DR:** InSituTale 是一种通过物理对象操作来控制可视化的增强数据叙事系统，用户研究表明其交互直观、实用性高且体验引人入胜。

**AI_Comments:** 该论文的创新之处在于其将物理对象交互引入增强数据叙事领域，弥补了现有系统主要依赖姿势或语音的不足。通过结合深度摄像头跟踪和 Vision-LLM，InSituTale 提供了一种新颖且直观的方式来控制数据可视化，增强了演示的沉浸感和参与度。其对物理与数字融合的探索对于人机交互和数据可视化领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有增强数据叙事系统主要依赖身体姿势或语音控制可视化，而与物理对象的交互则在很大程度上未被充分探索。

**Method:** 首先，我们对数据驱动的演示文稿进行了调查，以识别常见的可视化命令。然后，我们与九位 HCI/VIS 研究人员进行了研讨会，收集了物理操作与这些命令之间的映射。基于这些见解，我们开发了 InSituTale 原型，该原型结合了深度摄像头的对象跟踪和 Vision-LLM 来检测现实世界事件。

**Result:** 通过物理操作，演示者可以动态执行各种可视化命令，提供融合物理和数字元素的连贯数据叙事体验。一项针对 12 名参与者的用户研究表明，InSituTale 实现了直观的交互、提供了高实用性并促进了引人入胜的演示体验。

**Conclusion:** InSituTale 有效地通过物理对象交互增强了数据叙事，提供了直观、实用且引人入胜的演示体验。

> **ai_Abstract:** 本文介绍了 InSituTale，一种增强物理数据叙事的方法，允许演示者通过物理对象操作来控制可视化。研究团队首先调查了常见可视化命令，然后通过研讨会收集了物理操作与这些命令的映射。基于这些发现，他们开发了 InSituTale 原型，该原型结合了深度摄像头进行对象跟踪和 Vision-LLM 来识别现实世界事件。用户研究结果表明，InSituTale 提供了直观的交互、高实用性以及引人入胜的演示体验，有效地将物理和数字元素融合到数据叙事中。

> **摘要翻译:** 增强数据叙事通过将可视化与物理环境和演示者动作相结合来增强叙事呈现。现有系统主要依赖身体姿势或语音来控制可视化，而与物理对象的交互则在很大程度上未被充分探索。我们引入了增强物理数据叙事，这是一种使演示者能够通过物理对象交互来操作可视化的方法。为了为这种方法提供信息，我们首先对数据驱动的演示文稿进行了调查，以识别常见的可视化命令。然后，我们与九位 HCI/VIS 研究人员进行了研讨会，收集了物理操作与这些命令之间的映射。在这些见解的指导下，我们开发了 InSituTale 原型，该原型结合了通过深度摄像头的对象跟踪和 Vision-LLM 来检测现实世界事件。通过物理操作，演示者可以动态执行各种可视化命令，提供融合物理和数字元素的连贯数据叙事体验。一项针对 12 名参与者的用户研究表明，InSituTale 实现了直观的交互、提供了高实用性并促进了引人入胜的演示体验。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [495] [Online EFX Allocations with Predictions](https://arxiv.org/abs/2508.04779)
> *在线EFX分配与预测*

*Themistoklis Melissourgos, Nicos Protopapas* | **Category: cs.GT, cs.MA** | **Updated: 2025-08-06**

**Keywords:** 在线公平分配, EFX, 预测, 加性估值, 不可能结果

**Comment:** 

> **TL;DR:** 本文研究了在线公平分配中的EFX（对任何商品而言的无嫉妒）问题，发现即使有预测，实现近似EFX也面临挑战；论文提出了不可能结果，并为特定情况（两代理、相同估值）设计了一个利用预测的算法，其性能随预测准确性提高而改善。

**AI_Comments:** 这篇论文在在线公平分配领域中引入了预测机制，这是一个重要的创新点，因为它尝试通过外部信息来克服传统在线算法的局限性。论文不仅指出了在没有预测和不当使用预测时实现EFX的困难，还量化了预测准确性的重要性，并为特定场景（双代理、相同估值）提供了实际的解决方案。这为未来研究如何将机器学习预测与在线算法结合以提高公平性提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 在在线公平分配问题中，商品依次到达并需立即分配，目标是实现对任何商品而言的无嫉妒（EFX）。然而，研究发现近似EFX分配通常是无法实现的，即使在估值函数受限的情况下也是如此。为了解决这一挑战，论文引入了利用预测来增强算法的方法。

**Method:** 论文通过引入预测向量（估计代理的真实估值）来增强在线分配算法，并采用总变差距离衡量预测误差。研究聚焦于加性估值，首先证明了忽视预测或仅依赖预测的算法无法实现近似EFX。接着，为任何能计算近似EFX的算法设定了对预测准确性的强下限。最后，论文提出了一个针对两个具有相同估值的代理的算法，该算法有效利用了预测和真实值。

**Result:** 结果表明，在加性估值下，忽略预测或仅依赖预测的算法无法实现近似EFX分配。对于任何能计算近似EFX的算法，都存在对预测准确性的强下限要求，即使在估值相同的情况下也是如此。论文还提出了一个针对两个具有相同估值的代理的算法，该算法结合使用预测和真实值，并能近似实现EFX，其保证会随着预测准确性的提高而改善。

**Conclusion:** 在线EFX分配在没有预测的情况下通常无法实现，且即使有预测，实现近似EFX也面临严格限制。然而，通过有效结合预测和真实值，在特定条件下（如两个代理、相同估值），可以设计出近似实现EFX的算法，其性能随预测准确性提升而改善。

> **ai_Abstract:** 本文研究在线公平分配中的EFX（对任何商品而言的无嫉妒）问题，其中商品依次到达并需立即分配。研究发现，在没有预测的情况下，近似EFX通常无法实现。为解决此问题，论文引入了利用预测增强算法的方法，并测量了预测误差。结果表明，即使有预测，完全忽略或仅依赖预测的算法也无法实现近似EFX，且任何算法都需要较高的预测准确性才能达到近似EFX。最后，论文提出了一种针对两个具有相同估值的代理的算法，该算法有效结合预测和真实值，其EFX近似保证随预测准确性提高而改善。

> **摘要翻译:** 我们研究了一个在线公平分配问题，其中固定数量的商品依次到达，并且必须分配给一组给定的代理。一旦商品到达，其对每个代理的真实价值就会被揭示，并且必须立即且不可撤销地分配给某个代理。最终目标是确保在所有商品分配后达到对任何商品而言的无嫉妒（EFX）。不幸的是，正如我们所示，即使在估值函数受限的假设下，近似EFX分配通常也是无法实现的。
为了解决这个问题，我们遵循了近期一个富有成效的趋势，即用预测来增强算法。具体来说，我们假设可以访问一个预测向量，该向量估计代理的真实估值——例如，由在过去数据上训练的机器学习模型生成。预测可能不可靠，我们使用与真实估值之间的总变差距离来衡量其误差，即预测值量与真实值不一致的百分比。
我们专注于加性估值的自然类别，证明了对于那些要么忽略预测要么完全依赖预测的算法，即使是近似EFX分配也是不可能实现的。然后，我们转向使用预测和真实值两种信息的算法，并展示了任何算法计算近似EFX所需的预测准确性的强下限。这些负面结果即使在估值相同的情况下也依然存在，这与离线设置中无需预测即可始终存在精确EFX分配的情况相反。接着，我们提出了一个针对两个具有相同估值的代理的算法，该算法有效地利用了预测和真实值。该算法近似EFX，其保证随着预测准确性的提高而改善。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [501] [Toward Energy and Location-Aware Resource Allocation in Next Generation Networks](https://arxiv.org/abs/2508.05109)
> *面向下一代网络中能源和位置感知资源分配*

*Mandar Datar, Mattia Merluzzi* | **Category: cs.GT, math.OC** | **Updated: 2025-08-07**

**Keywords:** 资源分配, 下一代网络, 能源效率, 费雪市场, 公平性

**Comment:** 

> **TL;DR:** 本文提出了一种基于费雪市场的低复杂度解决方案，用于下一代网络中的通信和计算资源分配，旨在平衡服务提供商效用、用户体验质量和公平性，同时满足能源约束，并通过数值结果展示了效用与能源之间的权衡。

**AI_Comments:** 本文的创新点在于将费雪市场模型应用于下一代网络中复杂的资源分配问题，并特别整合了能源约束和位置感知。其重要性在于提供了一个低复杂度、经数学证明的解决方案，能够平衡竞争服务提供商的多个冲突目标（效用、用户体验质量、公平性和能源效率），这对于可持续和高效的网络运营至关重要。一个潜在的局限性可能是“虚拟货币预算”的假设及其在实际经济激励中的转化程度。

<details>
  <summary>Details</summary>

**Motivation:** 无线网络正在从单一的无线电资源提供者演变为涉及分布式计算（边缘和云）的复杂系统，其优化范式也从性能导向转向价值导向。研究的动机在于如何在这些异构资源贡献下，持续平衡服务提供商的效用、用户体验质量和公平性，同时满足能源消耗和碳足迹等全球约束，尤其是在多个服务提供商竞争资源且存在能源限制的情况下进行通信和计算资源分配。

**Method:** 本文将网络建模为费雪市场，并提出了一种低复杂度的解决方案来分配通信和计算资源。该方法允许多个服务提供商通过花费虚拟货币预算来竞争获取资源包。所提出的解决方案的市场均衡已通过数学方式证明。

**Result:** 所提出的低复杂度解决方案能够实现高效用并保证能源约束，同时与社会最优解决方案相比，还能促进服务提供商之间的公平性。数值结果显示了在不同位置、针对通信和计算密集型服务，效用和能源之间的多维权衡。

**Conclusion:** 本文成功提出了一种基于费雪市场的低复杂度解决方案，用于下一代网络中能源和位置感知的通信与计算资源分配，有效平衡了服务提供商的效用、能源效率和公平性。

> **ai_Abstract:** 本文针对下一代无线网络中能源和位置感知的通信与计算资源分配问题进行了研究。鉴于网络融合分布式计算并侧重价值导向优化，作者将网络建模为费雪市场，提出了一种低复杂度的资源分配方案。该方案旨在最大化服务提供商效用、用户体验质量和公平性，同时严格遵守能源消耗限制。该解决方案的市场均衡已得到数学证明，数值结果也展示了其在不同位置针对不同服务类型平衡效用与能源效率的有效性。

> **摘要翻译:** 无线网络正在从无线电资源提供者演变为复杂的系统，其中还涉及计算，后者分布在边缘和云设施中。此外，它们的优化也越来越从性能导向转向价值导向范式。这两个方面应持续平衡，以最大限度地提高服务提供商（SPs）的效用、用户体验质量和公平性，同时满足能源消耗和碳足迹等方面的全球限制，所有这些异构资源都为此做出贡献。在本文中，我们解决了在能源约束下通信和计算资源分配的问题，多个SP通过花费虚拟货币预算来竞争获取他们偏好的资源包。通过将网络建模为费雪市场，我们提出了一种低复杂度的解决方案，该方案能够实现高效用并保证能源约束，同时与社会最优解决方案相比，还能促进SP之间的公平性。市场均衡得到了数学证明，数值结果显示了在不同位置、针对通信和计算密集型服务，效用和能源之间的多维权衡。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [507] [A New Three-Players Auction Bridge with Dynamic Opponents and Team Members](https://arxiv.org/abs/2508.05582)
> *一种具有动态对手和团队成员的新型三人叫牌桥牌*

*Sourish Sarkar, Aritrabha Majumdar, Moutushi Chatterjee* | **Category: cs.GT** | **Updated: 2025-08-07**

**Keywords:** 三人桥牌, 动态团队, 新颖计分系统, 适应性策略, 纸牌比赛

**Comment:** 

> **TL;DR:** 本文提出了一种新型三人桥牌游戏，通过动态团队和新颖的计分系统，增加了游戏的不可预测性和公平性，并要求玩家不断调整策略。

**AI_Comments:** 该论文的创新之处在于将传统的固定搭档桥牌转变为动态的三人游戏，极大地增强了不可预测性和策略深度。其新颖的计分系统旨在实现公平性，解决了传统游戏中的偏见问题。这可能通过提高可玩性和战略挑战性，对竞技桥牌产生显著影响。

<details>
  <summary>Details</summary>

**Motivation:** 为了结束桥牌中固定的搭档关系，使游戏更具动态性和灵活性，增加不可预测性，并促进公平性。

**Method:** 通过实时动态重新定义团队组成，引入了新颖的计分系统以减少偏见并通过奖励系统强制战术决策和风险评估，同时遵循常规桥牌规则。文章还讨论了叫牌的概率问题和赢墩的算法方法。

**Result:** 模拟结果说明了多样化策略的效率。该游戏的架构非常适合比赛，并可能有助于扩大锦标赛纸牌游戏的参与范围。

**Conclusion:** 这种新型三人桥牌版本成功地创造了一个更具动态性、公平性和不可预测性的游戏，鼓励玩家采取适应性策略，适用于比赛并有望扩大玩家基础。

> **ai_Abstract:** 本文介绍了一种新颖的三人桥牌游戏，旨在通过取消固定搭档和实时重新定义团队来增强游戏的动态性和灵活性。它引入了一种新的计分系统，以实现公平性和不可预测性，并促使玩家持续调整策略。该游戏遵循标准桥牌规则，探讨了叫牌和赢墩等战略方面，模拟结果显示了各种方法的有效性。它适用于竞技比赛，并可能扩大纸牌锦标赛的参与度。

> **摘要翻译:** 本文提出了一种新的三人桥牌纸牌游戏版本，旨在结束固定搭档关系，使游戏更具动态性和灵活性。通过实时动态重新定义团队组成，这种游戏设计增加了不可预测性，并迫使玩家不断更新策略。引入了一种新颖的计分系统，通过奖励系统来强制战术决策和风险评估，从而倾向于公平性，以减少传统基于规则游戏中存在的偏见。这个版本遵循常规桥牌规则，考验玩家在没有固定友谊的情况下进行协作，要求实时进行灵活调整和适应性叫牌行为。战略问题涉及激进和防御性叫牌、适应性打法以及三人结构特有的寻求损失策略。文章讨论了叫牌的概率问题、有将和无将声明效果以及赢墩的算法方法。模拟结果说明了多样化策略的效率。该游戏的架构非常适合比赛，并可能有助于扩大锦标赛纸牌游戏的参与范围。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [513] [The Implicit Barrier of Utility Maximization: An Interior-Point Approach for Market Equilibria](https://arxiv.org/abs/2508.04822)
> *效用最大化的隐式障碍：市场均衡的内点法*

*Chuwen Zhang, Chang He, Bo Jiang, Yinyu Ye* | **Category: cs.GT, math.OC** | **Updated: 2025-08-06**

**Keywords:** 市场均衡, 内点法, 效用最大化, 隐式障碍, 试探过程

**Comment:** 

> **TL;DR:** 本文研究了具有可分割商品和异质效用参与者的交换市场中均衡的计算。作者重新审视了仅更新价格的多项式时间内点策略，并引入了“隐式障碍”的概念，即当商品几乎免费时效用变得无界。文章提出了两种不精确内点法，其中一种具有O(ln(1/{\epsilon}))的复杂度，另一种在温和条件下实现了非渐近超线性收敛速度。

**AI_Comments:** 该论文通过解决效用最大化中的“隐式障碍”这一实际挑战，对市场均衡的计算方面做出了重要贡献。开发具有强收敛保证（对数和超线性）的新型内点法以及改进Hessian算子的处理方法，代表了一项显著的创新。专注于仅更新价格也与现实世界的市场动态良好契合。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究具有可分割商品和异质效用参与者的交换市场中均衡的计算问题，并重新审视了多项式时间内的点策略。研究的动机在于解决效用最大化中固有的“隐式障碍”问题，即当商品接近免费时，效用会变得无界。

**Method:** 1. 将效用最大化中的“隐式障碍”形式化为尺度Lipschitz连续性。2. 提出计算高阶导数无需额外努力的伴随结果。3. 提出一种具有高概率保证的Hessian算子的显式可逆近似和最小化线性系统条件数的缩放矩阵。4. 设计了两种不精确内点法：一种具有O(ln(1/{\epsilon}))的复杂度，另一种实现了非渐近超线性收敛速度。

**Result:** 1. 形式化了效用最大化的尺度Lipschitz连续性。2. 证明了计算高阶导数不需要额外努力。3. 提出了Hessian算子的显式可逆近似和缩放矩阵。4. 设计了两种不精确内点法，分别实现了O(ln(1/{\epsilon}))的复杂度率和非渐近超线性收敛率。5. 提供了扩展和初步实验结果。

**Conclusion:** 本文通过解决效用最大化中的隐式障碍并改进牛顿系统的处理，设计了两种用于计算市场均衡的不精确内点法，其中一种实现了O(ln(1/{\epsilon}))的复杂度，另一种实现了非渐近超线性收敛速度。

> **ai_Abstract:** 本文研究了具有可分割商品和异质效用参与者的交换市场中均衡的计算问题。文章重新审视了仅更新价格的多项式时间内的点策略，并着重解决了效用最大化中的“隐式障碍”（即商品接近免费时效用无界）。作者将这一现象形式化为尺度Lipschitz连续性，并提出了一种Hessian算子的显式可逆近似和用于牛顿系统的缩放矩阵。基于这些工具，论文设计了两种不精确内点法：一种具有O(ln(1/{\epsilon}))的复杂度，另一种实现了非渐近超线性收敛速度。文章还展示了扩展和初步实验结果。

> **摘要翻译:** 我们研究了具有可分割商品和异质效用玩家的交换市场中均衡的计算。在本文中，我们重新审视了仅更新价格的多项式时间内点策略，这与试探过程相呼应。关键要素是效用最大化中固有的“隐式障碍”：当商品几乎免费时，效用变得无界。针对一类普遍存在的效用，我们从原始和对偶角度将这一观察结果形式化为效用最大化的尺度Lipschitz连续性。一个伴随结果表明，计算高阶导数不需要额外的努力；所有必要信息在收集最佳响应时即可获得。为了解决牛顿系统，我们提出了一种具有高概率保证的Hessian算子的显式可逆近似，以及一个使线性系统条件数最小化的缩放矩阵。基于这些工具，我们设计了两种不精确内点法。其中一种方法具有O(ln(1/{\epsilon}))的复杂度，在温和条件下，另一种方法实现了非渐近超线性收敛速度。本文还介绍了扩展和初步实验。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [518] [Pairwise efficiency and monotonicity imply Pareto efficiency in (probabilistic) object allocation](https://arxiv.org/abs/2508.05340)
> *成对效率和单调性暗示（概率性）物品分配中的帕累托效率*

*Tom Demeulemeester, Bettina Klaus* | **Category: cs.GT, econ.TH** | **Updated: 2025-08-07**

**Keywords:** 物品分配, 成对效率, 帕累托效率, 单调性, 抽签规则

**Comment:** 

> **TL;DR:** 在物品分配问题中，如果抽签规则满足事后无浪费性和概率单调性，则事后成对效率等同于事后帕累托效率，这加强了现有特征化结果。

**AI_Comments:** 该论文通过在特定条件下建立两种重要效率概念（成对效率和帕累托效率）之间的新颖等价性，做出了重要的理论贡献。这一创新很重要，因为它简化了分配规则的特征化，使得通过依赖可能更弱或更易处理的成对效率条件来证明各种机制的属性变得更容易。其影响延伸到加强机制设计和资源分配领域的现有结果。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在加强物品分配问题中各种现有分配规则（抽签和确定性）的特征化结果，通过证明在特定条件下成对效率与帕累托效率之间的等价性。

**Method:** 研究方法是理论证明，表明如果一个抽签规则满足事后无浪费性和概率（马斯金）单调性，那么事后成对效率等同于事后帕累托效率。

**Result:** 主要结果是，在事后无浪费性和概率（马斯金）单调性的条件下，事后成对效率等同于事后帕累托效率。这一发现允许加强各种现有特征化结果。

**Conclusion:** 该论文的结论是，在特定条件下建立的成对效率与帕累托效率之间的等价性，为加强各种分配规则的特征化提供了有价值的工具，使得用（可能更弱的）成对效率取代帕累托效率成为可能。

> **ai_Abstract:** 本论文研究了有容量的物品分配问题，证明了一个重要的理论等价性。它表明，对于满足事后无浪费性和概率（马斯金）单调性的抽签规则，事后成对效率等同于事后帕累托效率。这一发现至关重要，因为它能够加强现有抽签规则和确定性规则的特征化结果，允许研究人员在各种背景下，包括随机序列独裁、交易循环和分层交换规则的特征化中，用（事后）成对效率取代（事后）帕累托效率。

> **摘要翻译:** 我们考虑有容量的物品分配问题（参见，例如，Abdulkadiroglu 和 Sonmez, 1998; Basteck, 2025），其中物品必须分配给代理人。我们表明，如果一个抽签规则满足事后无浪费性和概率（马斯金）单调性，那么事后成对效率等同于事后帕累托效率。这一结果通过用（事后）成对效率取代（事后）帕累托效率，加强了各种现有特征化结果，无论是对于抽签规则还是确定性规则，例如对于随机序列独裁规则（Basteck, 2025）、交易循环规则（Pycia 和 Unver, 2017）和分层交换规则（Papai, 2000）的特征化。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [525] [Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning](https://arxiv.org/abs/2506.05252)
> *保守分类器在改进代理中表现始终良好：表征统计和在线学习*

*Dravyansh Sharma, Alec Sun* | **Category: cs.GT, cs.LG, cs.MA** | **Updated: 2025-08-07**

**Keywords:** 战略分类, 代理改进, 学习能力, 泛化误差, 在线学习

**Comment:** 

> **TL;DR:** 本文研究了当代理为了获得更好的分类结果而真正改进时，机器学习算法的学习能力。它精确地表征了可实现设置中的适当学习，并为更自然的改进区域和不适当学习提供了积极结果，解决了先前研究中的开放问题。

**AI_Comments:** 本文的创新之处在于它将战略分类的研究焦点从对抗欺骗性代理行为转向理解和利用代理的积极改进。通过引入新的理论工具（如不对称的最小一致概念类）并探索更自然的改进集（如欧几里得球），它显著推进了对战略分类中学习能力的理解，为代理与分类器之间的互动提供了更乐观的视角。解决了Attias等人的开放问题，也凸显了其在基础理论上的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习在社会决策中应用广泛，如评估求职者或贷款申请。考虑被分类代理如何对学习算法做出反应变得日益重要。虽然多数现有文献关注对抗代理的欺骗行为，但Attias等人的近期工作揭示了当代理真正改进时，学习能力会展现出令人惊讶的特性（如更小的泛化误差）。本文旨在在多个新维度上表征这种“带改进的学习能力”。

**Method:** 本文引入了一种最小一致概念类的不对称变体，并用其精确表征了在可实现设置中带改进的适当学习。不同于先前研究仅在任意改进区域下进行，本文为更自然的欧几里得球改进集给出了积极结果。此外，它在温和的数据分布生成假设下表征了不适当学习。研究还展示了如何在有界噪声模型下实现更低的泛化误差，并在可实现和不可知在线学习中获得错误界限。

**Result:** 1. 使用最小一致概念类的不对称变体，精确表征了可实现设置中带改进的适当学习。2. 在更自然的欧几里得球改进集下，获得了学习能力的积极结果。3. 在温和的数据分布生成假设下，表征了不适当学习。4. 在有界噪声模型下实现了更低的泛化误差。5. 在可实现和不可知在线学习中获得了错误界限。6. 解决了Attias等人提出的关于适当和不适当学习的开放问题。

**Conclusion:** 本文全面表征了当代理为了获得理想分类而真正改进时的学习能力，并解决了Attias等人提出的关于适当和不适当学习的开放问题。

> **ai_Abstract:** 本文深入探讨了当被分类代理为获得理想分类而进行真正改进时，“带改进的学习能力”的特性。研究引入了一种最小一致概念类的不对称变体，用于精确刻画可实现设置中的适当学习。与现有工作不同，本文为更自然的欧几里得球改进集提供了积极结果，并在温和的生成假设下刻画了不适当学习。此外，研究还展示了在有界噪声模型下实现更低泛化误差，以及在可实现和不可知在线学习中获得错误界限的方法，并成功解决了Attias等人提出的相关开放问题。

> **摘要翻译:** 机器学习现在在社会决策中无处不在，例如评估求职者或贷款申请，并且考虑到被分类的代理将如何对学习算法做出反应变得越来越重要。最近关于策略性分类的大多数文献都集中在减少和对抗被分类代理的欺骗行为，但Attias等人最近的工作发现，当代理为了获得理想分类而真正改进时，学习能力具有令人惊讶的特性，例如比标准PAC学习更小的泛化误差。在本文中，我们通过多个新维度来表征所谓的“带改进的学习能力”。我们引入了一种最小一致概念类的不对称变体，并用它来精确表征在可实现设置中带改进的适当学习。虽然之前的工作仅在一般、任意的代理改进区域下研究学习能力，但我们为更自然的欧几里得球改进集给出了积极结果。特别是，我们在数据分布的温和生成假设下表征了不适当学习。我们进一步展示了如何在更具挑战性的设置中进行学习，在经过充分研究的有界噪声模型下实现更低的泛化误差，并在可实现和不可知在线学习中获得错误界限。我们解决了Attias等人提出的关于适当和不适当学习的开放问题。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [548] [At a Glance to Your Fingertips: Enabling Direct Manipulation of Distant Objects Through SightWarp](https://arxiv.org/abs/2508.04821)
> *一瞥即指尖：通过SightWarp实现对远处物体的直接操作*

*Yang Liu, Thorbjørn Mikkelsen, Zehai Liu, Gengchen Tian, Diako Mardanbegi, Qiushi Zhou, Hans Gellersen, Ken Pfeuffer* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** 3D用户界面, 直接操作, 远距离交互, 眼手协调, 对象代理

**Comment:** 

> **TL;DR:** SightWarp是一种在3D用户界面中实现远距离物体直接操作的技术，它利用眼手协调将按比例缩放的物体代理召唤到用户指尖，从而提供即时且自然的直接手势操作，并在一项用户研究中显示出比间接方法更好的性能。

**AI_Comments:** SightWarp为3D用户界面中长期存在的远距离物体操作挑战提供了一个创新的解决方案。其新颖之处在于通过在用户指尖创建临时的、按比例缩放的代理，将直接操作与间接选择无缝融合，从而提供了间接方法所缺乏的即时本体感受反馈。这种方法通过弥合自然手势与操作超出触及范围物体之间的鸿沟，显著提升了用户体验。

<details>
  <summary>Details</summary>

**Motivation:** 在3D用户界面中，直接操作近距离物体效果很好，但对于远距离物体则无能为力。凝视和捏合等间接技术虽然能实现远距离交互，但缺乏直接手势所提供的即时性和本体感受反馈。因此，需要一种支持远距离物体直接手势操作的方法。

**Method:** 本文提出SightWarp，一种利用眼手协调的交互技术。当用户注视远距离物体后，将目光转移到手部或将手移入视野时，系统会创建该物体及其周围环境的按比例缩放的近空间代理，并将其召唤到用户指尖。该代理保持激活状态，直到眼手模式解除，从而允许用户通过自然、直接的手势立即操作远距离物体。

**Result:** 一项3D对象停靠任务的用户研究表明，用户可以轻松使用SightWarp，并且随后的直接操作比凝视和捏合等间接技术提高了性能。应用示例也展示了其在6自由度操作、概览-细节导航和微缩世界交互中的实用性。

**Conclusion:** SightWarp通过为远距离物体提供直接手势操作，从而促进了跨近距离和远距离空间的更具表现力和灵活性的对象交互。

> **ai_Abstract:** 本文介绍了SightWarp，一种用于3D用户界面的交互技术，旨在实现对远距离物体的直接操作。SightWarp利用眼手协调，在用户指尖创建远距离物体的按比例缩放的近空间代理，从而允许即时且自然的直接手势操作。一项用户研究表明，SightWarp易于使用，并且在3D对象操作任务中，其性能优于凝视和捏合等间接方法。这项技术提升了跨不同距离的对象交互的表达性和灵活性。

> **摘要翻译:** 在3D用户界面中，伸手抓取和操作物体非常有效，直到物体超出触及范围。凝视和捏合等间接技术为远距离交互提供了替代方案，但无法提供与直接手势相同的即时性或本体感受反馈。为了支持对远距离物体的直接手势，我们引入了SightWarp，这是一种利用眼手协调将物体代理无缝召唤到用户指尖的交互技术。其理念是，在注视远距离物体后，用户要么将目光转移到手上，要么将手移入视野——这会触发物体及其周围环境的按比例缩放的近空间代理的创建。该代理保持激活状态，直到眼手模式解除。关键优势在于，用户始终可以通过自然、直接的手势立即操作远距离物体。通过一项3D对象停靠任务的用户研究，我们表明用户可以轻松使用SightWarp，并且随后的直接操作比凝视和捏合提高了性能。应用示例说明了其在6自由度操作、概览-细节导航和微缩世界交互中的实用性。我们的工作有助于实现跨近距离和远距离空间的富有表现力和灵活的对象交互。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [555] [Charts-of-Thought: Enhancing LLM Visualization Literacy Through Structured Data Extraction](https://arxiv.org/abs/2508.04842)
> *思维图表：通过结构化数据提取提升大型语言模型的可视化素养*

*Amit Kumar Das, Mohammad Tarun, Klaus Mueller* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 可视化素养, 结构化提示, 思维图表, 数据提取

**Comment:** 

> **TL;DR:** 本文介绍了一种名为“思维图表”（Charts-of-Thought）的新型提示技术，显著提升了大型语言模型（LLM）的可视化素养，使其在可视化素养评估测试（VLAT）中超越人类表现，并为LLM的复杂视觉解释任务建立了新的基准。

**AI_Comments:** “思维图表”方法在提升LLM解释视觉数据的能力方面具有显著创新性，它将LLM的能力从简单的图像识别提升到结构化的分析推理。其重要性在于证明了通过适当的提示，LLM不仅能够理解，还能批判性地分析视觉信息，甚至可能超越人类。这对于数据分析、可访问性和人机协作具有广泛的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 评估现代大型语言模型（LLM）的可视化素养，并引入一种新颖的提示技术来提升LLM在复杂视觉解释任务中的表现。

**Method:** 引入并测试了名为“思维图表”（Charts-of-Thought）的提示技术。该方法引导LLM通过系统的i数据提取、验证和分析过程来回答可视化问题。在可视化素养评估测试（VLAT）中，使用标准提示和“思维图表”方法对三种最先进的LLM（Claude-3.7-sonnet、GPT-4.5 preview和Gemini-2.0-pro）进行了测试。

**Result:** “思维图表”方法显著提升了所有测试模型的性能。Claude-3.7-sonnet使用此方法获得了50.17分，远超人类基线28.82。与标准提示相比，GPT-4.5的得分提高了21.8%，Gemini-2.0提高了9.4%，Claude-3.7提高了13.5%。Claude在几种之前对LLM构成挑战的图表类型中正确回答了100%的问题。

**Conclusion:** 现代多模态LLM在获得适当的分析框架（如结构化提示）时，可以在可视化素养任务上超越人类表现。这些发现为LLM可视化素养建立了新的基准，并强调了结构化提示策略对于复杂视觉解释任务的重要性。“思维图表”还有助于提高可视化的可访问性。

> **ai_Abstract:** 本文提出了一种名为“思维图表”（Charts-of-Thought）的新型结构化提示技术，旨在提升大型语言模型（LLM）的可视化素养。该方法通过引导LLM进行系统的数据提取、验证和分析，显著提高了它们在可视化素养任务上的表现。在对Claude-3.7-sonnet、GPT-4.5 preview和Gemini-2.0-pro进行可视化素养评估测试（VLAT）的实验中，“思维图表”使LLM（特别是Claude-3.7-sonnet）超越了人类基线得分，并在具有挑战性的图表类型上实现了高准确率，为LLM的可视化素养建立了新的基准，突出了结构化提示的重要性。该技术还显示出改善可视化可访问性的潜力。

> **摘要翻译:** 本文评估了现代大型语言模型（LLM）的可视化素养，并引入了一种新颖的提示技术，称为思维图表（Charts-of-Thought）。我们使用标准提示和我们的结构化方法，在可视化素养评估测试（VLAT）上测试了三种最先进的LLM（Claude-3.7-sonnet、GPT-4.5 preview和Gemini-2.0-pro）。思维图表方法引导LLM在回答可视化问题之前，通过系统的i数据提取、验证和分析过程。我们的结果显示，使用这种方法，Claude-3.7-sonnet的得分达到50.17，远超人类基线28.82。与标准提示相比，这种方法提高了所有模型的性能，其中GPT-4.5的得分提高了21.8%，Gemini-2.0提高了9.4%，Claude-3.7提高了13.5%。性能提升在原始和修改后的VLAT图表上保持一致，Claude在几种以前对LLM构成挑战的图表类型中正确回答了100%的问题。我们的研究表明，当给予适当的分析框架时，现代多模态LLM在可视化素养任务上可以超越人类表现。这些发现为LLM可视化素养建立了新的基准，并证明了结构化提示策略对于复杂视觉解释任务的重要性。除了提高LLM可视化素养之外，思维图表还可以增强可视化的可访问性，可能有利于有视力障碍或可视化素养较低的个体。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [561] [An Implementation of a Visual Stepper in the GRASP Programming System](https://arxiv.org/abs/2508.04859)
> *GRASP编程系统中可视化步进器的实现*

*Panicz Maciej Godek* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** GRASP, 可视化步进器, 编程系统, 扩展机制, Scheme社区

**Comment:** 

> **TL;DR:** 本文介绍了GRASP编程系统中可视化步进器扩展的实现方式，并提供了GRASP系统设计及其扩展机制架构的教程。

**AI_Comments:** 本文主要关注GRASP编程系统中特定功能（可视化步进器）的实现和系统架构的设计。一个显著的局限性是，该系统在撰写时尚未最终完成，且细节可能会发生变化，这表明它更像是一份进展报告或设计文档，而非已完成产品或实证结果的展示。其重要性在于分享了构建具有扩展能力的编程系统所面临的设计挑战和解决方案，特别是对Scheme社区而言。

<details>
  <summary>Details</summary>

**Motivation:** 本文的直接目的是展示如何在GRASP编程系统中实现可视化求值器扩展。间接目的是提供一个关于GRASP设计及其扩展机制架构的教程，并探讨可能对Scheme社区感兴趣的相关问题。

**Method:** 本文通过介绍GRASP编程系统中可视化求值器扩展的实现细节来阐述其方法，并围绕GRASP的设计及其扩展机制架构提供了一个教程。

**Result:** 本文描述了GRASP系统中可视化步进器扩展的实现细节，并提供了GRASP设计的教程。然而，论文明确指出该系统尚不最终或完整，并且一些细节在首次发布前可能会改变。未提及具体的实验结果或性能指标。

**Conclusion:** 本文的结论是，尽管GRASP系统及其扩展机制在撰写时仍未最终完成，但构建一个具有类似GRASP功能的系统所需解决的问题集是重要的，并且可能引起Scheme社区的兴趣。

> **ai_Abstract:** 本文详细阐述了在GRASP编程系统中实现可视化求值器扩展的过程，并作为GRASP系统设计及其扩展机制架构的教程。作者指出，GRASP及其扩展功能仍在开发中，可能存在变动，但他们认为所讨论的系统构建问题对Scheme社区具有重要意义。

> **摘要翻译:** 本文的直接目的——正如其标题所示——是介绍可视化求值器扩展如何在GRASP编程系统中实现。间接目的是围绕GRASP的设计，特别是其扩展机制的架构，提供一个教程。GRASP及其扩展机制在撰写本文时既不最终也不完整，我们确信此处描述的解决方案的一些细节甚至在首次发布之前就会改变。然而，不会改变的是构建一个具有与GRASP类似功能的系统所需解决的一系列问题。我们相信这些问题可能对Scheme社区感兴趣。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [567] [Root Cause Analysis Training for Healthcare Professionals With AI-Powered Virtual Simulation: A Proof-of-Concept](https://arxiv.org/abs/2508.04904)
> *面向医疗专业人员的AI驱动虚拟仿真根本原因分析培训：概念验证*

*Yuqi Hu, Qiwen Xiong, Zhenzhen Qin, Brandon Watanabe, Yujing Wang, Mirjana Prpa, Ilmi Yoon* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** 根本原因分析, AI驱动仿真, 医疗培训, 虚拟现实, 大语言模型

**Comment:** 

> **TL;DR:** 本文提出一个AI驱动的3D模拟游戏，通过交互式虚拟仿真为医疗专业人员提供根本原因分析（RCA）技能培训，以解决现有培训资源需求高、效果不一致的问题。

**AI_Comments:** 本文的创新之处在于利用AI驱动的3D虚拟仿真，特别是结合大型语言模型（LLMs）来实现逼真的互动和智能反馈，为根本原因分析（RCA）培训提供了一种新颖且可能更有效的解决方案。它解决了传统培训中资源限制和效果不一致的关键痛点，具有重要的实际应用潜力。然而，目前仍处于概念验证阶段，尚未进行实证评估，未来的研究需要验证其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有根本原因分析（RCA）培训项目通常受限于高资源需求，导致培训不足和实施不一致。为解决这一挑战，本文提出了一个AI驱动的虚拟仿真系统。

**Method:** 本文提出了一个AI驱动的3D模拟游戏，通过交互式、沉浸式仿真帮助医疗专业人员发展RCA技能。该原型模拟了ICU死亡事件后的RCA调查，学习者采访五个虚拟化身（代表ICU团队成员）以调查事件并完成书面报告。系统通过大型语言模型（LLMs）、情感文本转语音和AI驱动动画实现与化身的自然、逼真互动。一个额外的LLM组件提供形成性与总结性反馈，以支持持续改进。

**Result:** Not mentioned in abstract

**Conclusion:** 本文通过概述对系统有效性进行实证评估的计划作为结尾。

> **ai_Abstract:** 本文提出了一种AI驱动的3D模拟游戏，旨在通过交互式、沉浸式仿真为医疗专业人员提供根本原因分析（RCA）技能培训，以克服传统培训资源需求高、效果不一致的局限性。该概念验证原型模拟了ICU死亡事件的RCA调查，学习者通过大型语言模型驱动的虚拟化身进行访谈并完成报告，系统还提供AI驱动的反馈。该方法提供了一种成本效益高、可扩展且易于访问的传统培训替代方案。

> **摘要翻译:** 根本原因分析（RCA）是调查医疗不良事件和提高患者安全的关键工具。然而，现有RCA培训项目往往受限于高资源需求，导致培训不足和实施不一致。为解决这一挑战，我们提出了一款AI驱动的3D模拟游戏，通过交互式、沉浸式仿真帮助医疗专业人员发展RCA技能。这种方法为传统培训提供了一种成本效益高、可扩展且易于访问的替代方案。该原型模拟了ICU（重症监护室）死亡事件后的RCA调查，学习者采访代表ICU团队成员的五个虚拟化身，以调查事件并完成书面报告。该系统通过大型语言模型（LLMs）、情感文本转语音和AI驱动动画实现与化身的自然、逼真互动。一个额外的LLM组件提供形成性与总结性反馈，以支持持续改进。最后，我们概述了对系统有效性进行实证评估的计划。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [573] [Toward Supporting Narrative-Driven Data Exploration: Barriers and Design Opportunities](https://arxiv.org/abs/2508.04920)
> *支持叙事驱动的数据探索：障碍与设计机会*

*Oliver Huang, Carolina Nobre* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** 叙事驱动数据探索, 障碍, 设计机会, 数据分析, 形成性研究

**Comment:** 

> **TL;DR:** 本研究通过一项形成性研究，识别了叙事驱动数据探索中存在的关键障碍，并提出了相应的设计机会。

**AI_Comments:** 这项研究解决了数据分析领域的一个重要问题，即如何支持更动态和演进的数据探索过程。通过识别具体的障碍，它为设计更有效的分析工具提供了清晰的方向，强调了上下文维护和推理路径追踪的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 分析师越来越多地通过不断演变的、叙事驱动的查询来探索数据，但现有工具（如静态仪表板和预定义指标）难以支持这种探索，导致洞察分散，难以维持上下文或阐明结论的产生。

**Method:** 通过一项包含48名参与者的形成性研究。

**Result:** 识别出阻碍叙事驱动探索的关键障碍，包括难以在不同视图间保持上下文、追踪推理路径以及外部化不断演变的解释。这些发现揭示了支持叙事驱动分析的设计机会。

**Conclusion:** 研究发现的障碍为更好地支持叙事驱动分析提供了设计机会。

> **ai_Abstract:** 本研究旨在支持叙事驱动的数据探索。通过对48名参与者进行形成性研究，论文识别了叙事驱动数据探索中的关键障碍，如难以保持上下文、追踪推理路径和外部化解释。研究结果为未来的设计提供了机会，以更好地支持此类分析。

> **摘要翻译:** 分析师越来越多地通过不断演变的、叙事驱动的查询来探索数据，超越了静态仪表板和预定义指标，因为他们的问题不断深化和转变。随着这些探索的进展，洞察往往分散在不同的视图中，使得难以维持上下文或阐明结论是如何产生的。通过一项包含48名参与者的形成性研究，我们识别了阻碍叙事驱动探索的关键障碍，包括难以在不同视图间保持上下文、追踪推理路径以及外部化不断演变的解释。我们的发现为更好地支持叙事驱动分析提供了设计机会。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [579] [Accessibility Beyond Accommodations: A Systematic Redesign of Introduction to Computer Science for Students with Visual Impairments](https://arxiv.org/abs/2508.05056)
> *超越无障碍便利：为视障学生系统性地重新设计计算机科学导论课程*

*Vaanee Tripathi, Aalok Thakkar* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 无障碍性, 视障学生, 计算机科学教育, 课程设计, 通用设计

**Comment:** 

> **TL;DR:** 本文提出了一个全面的框架，用于重新设计计算机科学导论课程，旨在为视障学生提供公平的学习体验，无需复杂的专业技术基础设施，并强调将无障碍性作为课程设计的组成部分。

**AI_Comments:** 本文的创新之处在于其将无障碍性从“个体便利”提升到“课程设计核心组成部分”的理念，提供了一个全面的、系统性的框架。其重要性在于解决了现有解决方案分散、依赖复杂技术基础设施的问题，并强调了在标准大学环境中的实际可操作性，为视障学生的公平计算机教育提供了可推广的模板。该研究通过专家咨询进行验证，但其在实际教学中的学习成果和学生参与度的实证评估仍有待未来工作完成。

<details>
  <summary>Details</summary>

**Motivation:** 计算机科学教育的现有方法将无障碍性视为个体便利设施而非课程设计的组成部分，导致整体教育支持存在差距。尽管现有研究开发了专门的编程工具和辅助技术，但这些解决方案分散且常需要复杂的技术基础设施，限制了其课堂实施，从而阻碍了视障学生充分参与。

**Method:** 本文提出了一个全面的框架，用于重新设计计算机科学导论课程，旨在为视障学生提供公平的学习体验，且无需专业的复杂技术基础设施。该框架概述了五个关键组成部分：预分发材料和触觉图的可访问学习资源、带动手实践演示的课堂学习工具包、带专门助教的结构化支持系统、在线工具库以及课堂参与的心理社会支持。该设计基于通用设计原则，并通过与无障碍专家和残疾服务专业人员的专家咨询进行了验证。

**Result:** 该框架在不要求专业技术基础设施的情况下，为视障学生提供了公平的学习体验。与现有以工具为中心的解决方案不同，该框架解决了包容性教育的技术和教学维度，同时强调在标准大学环境中的实际实施。它为未来学习成果和学生参与的实证评估奠定了基础，并可作为更广泛机构采纳的模板。

**Conclusion:** 该论文提出并验证了一个全面的框架，通过将无障碍性融入课程设计而非仅提供个体便利，为视障学生提供了公平的计算机科学教育体验。该框架实用且可广泛采纳，为未来研究和机构推广奠定了基础。

> **ai_Abstract:** 本论文提出了一个全面的框架，旨在系统性地重新设计计算机科学导论课程，以消除视障学生参与学习的障碍。该框架超越了传统的个体便利方法，将无障碍性作为课程设计的核心组成部分，包含可访问的学习资源、实践学习套件、结构化支持系统、在线工具库和心理社会支持。与现有工具导向的解决方案不同，本方法同时关注技术和教学维度，强调在标准大学环境中的实际应用，并通过专家咨询验证，为未来的实证评估和广泛机构采纳提供了基础。

> **摘要翻译:** 计算机科学教育发展迅速；然而，系统性障碍仍阻碍视障学生充分参与。尽管现有研究开发了专门的编程工具和辅助技术，但这些解决方案仍然分散，并且通常需要复杂的技术基础设施，这限制了它们在课堂上的实施。目前的方法将无障碍性视为个体便利而非课程设计的组成部分，从而在整体教育支持方面造成了差距。本文提出了一个全面的框架，用于重新设计计算机科学导论课程，旨在为视障学生提供公平的学习体验，而无需专门的技术基础设施。该框架概述了五个关键组成部分，它们共同构成了课程无障碍性的系统方法：包含预分发材料和触觉图的可访问学习资源、包含动手演示的课堂学习工具包、包含专门助教的结构化支持系统、一个在线工具库以及课堂参与的心理社会支持。与现有以工具为中心的解决方案不同，该框架解决了包容性教育的技术和教学维度，同时强调在标准大学环境中的实际实施。该设计以通用设计原则为基础，并通过与无障碍专家和残疾服务专业人员的专家咨询进行验证，为未来学习成果和学生参与的实证评估奠定了基础，同时也可作为更广泛机构采纳的模板。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [585] [A Desktop-Centric Design Space for Direct Object Examination and Visualization in Mixed-Reality Environments](https://arxiv.org/abs/2508.05088)
> *面向桌面中心的混合现实环境中直接物体检查与可视化设计空间*

*Sam Johnson-Lacoss, Santiago V. Lombeyda, S. George Djorgovski* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 混合现实, 桌面中心, 设计空间, 物体检查, 数据可视化

**Comment:** 

> **TL;DR:** 本文提出了一个面向桌面的设计空间，用于在混合现实环境中进行精确的以物体为中心的数据分析，以适应未来MR技术的普及和科研临床工作站的演变。

**AI_Comments:** 该论文的创新点在于提出了一个“桌面中心”的混合现实设计空间，这与传统上强调完全沉浸或大空间交互的MR应用有所不同。它认识到许多专业工作仍需在桌面环境中进行，并试图将MR的优势融入到这种受限但符合人体工程学的工作流中。这对于需要精确数据分析和操作的领域（如医疗和科学研究）具有重要意义，因为它提供了一个将3D沉浸式体验与现有2D桌面工作流程相结合的实用框架。潜在的局限性可能在于如何有效地平衡桌面物理限制与MR带来的3D自由度，以及如何处理多模态交互的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 随着混合现实（MR）技术变得更轻、更高分辨率、更经济实惠，它将成为当前工作和生活空间的无缝延伸。对于专注于理解3D现象或患者病理的研究科学家和临床医生来说，他们的工作站需要从当前仅使用2D界面进行日常交流、物流和数据分析的方式进行必要的演变。MR技术能够提供沉浸式3D表示，与自然空间共存，并允许更丰富的互联信息显示，从而极大地帮助详细理解物理结构、空间关系以及2D测量、投影、抽象和其他数据细节的3D情境化。

**Method:** 本文提出了一个将不同的交互区域和模式分解为设计空间的方法。该设计空间旨在最佳地适应为用户创建应用程序，这些用户通过MR技术在其桌面物理空间的符合人体工程学限制内进行精确的以物体为中心的数据分析。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对未来普及的混合现实（MR）环境，提出了一种面向桌面的设计空间。该设计空间旨在帮助科研人员和临床医生在符合人体工程学的桌面物理空间内，利用MR技术进行直接的、以物体为中心的精确数据分析和可视化，从而弥补当前2D工作站的不足，并提升对3D现象和复杂数据的理解能力。

> **摘要翻译:** 混合现实（MR）环境注定会变得无处不在，因为MR技术变得更轻、更高分辨率、更经济实惠，并且总体上成为我们当前工作和生活空间的无缝延伸。对于专注于理解3D现象或在更大的人体解剖学背景下理解患者病理的研究科学家和临床医生来说，这意味着他们目前仅使用2D界面进行日常交流、物流和数据分析的工作站需要进行必要的演变。MR技术带来了与我们自然空间共存的沉浸式3D表示，同时允许更丰富的互联信息显示，其中3D表示极大地有助于详细理解物理结构、空间关系以及2D测量、投影、抽象和其他数据细节的3D情境化。我们提出了一个将不同交互区域和模式分解为设计空间的方法，该设计空间能最佳地适应为用户创建应用程序，这些用户通过MR技术在其桌面物理空间的符合人体工程学限制内进行精确的以物体为中心的数据分析。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [592] [SparseEMG: Computational Design of Sparse EMG Layouts for Sensing Gestures](https://arxiv.org/abs/2508.05098)
> *SparseEMG：用于手势感应的稀疏EMG布局的计算设计*

*Anand Kumar, Antony Albert Raj Irudayaraj, Ishita Chandra, Adwait Sharma, Aditya Shekhar Nittala* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** EMG, 手势识别, 电极选择, 稀疏布局, 机器学习

**Comment:** 

> **TL;DR:** 本文提出SparseEMG，一个数据驱动的设计工具，通过优化电极选择和分类器组合，显著减少EMG手势识别所需的电极数量，同时保持高精度和跨用户可转移性。

**AI_Comments:** 这项工作通过数据驱动的方法解决了EMG手势识别中电极冗余的关键问题，具有重要创新性。SparseEMG工具的提出，不仅优化了硬件成本和佩戴舒适度，还通过其跨用户可转移性，显著提升了EMG手势识别系统的实用性和部署效率。其系统性的评估方法和具体的电极削减比例（53.5%）提供了扎实的证据，对于推动EMG在可穿戴设备和人机交互领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的肌电图（EMG）手势识别工具包主要关注模型开发，但忽略了电极选择对分类准确性的影响，而电极数量和位置是影响手势识别复杂性的关键因素。

**Method:** 本文进行了首次数据驱动分析，系统评估了28种电极选择方案与分类器组合（4种选择方案，7种分类器）在六个数据集上的表现，以探究其对准确性和稀疏性的影响。基于评估结果，开发了SparseEMG工具，该工具能根据用户选择的手势集、电极约束和机器学习参数生成稀疏电极布局，并预测分类性能。SparseEMG支持50多种独特手势，并在三种真实世界应用中通过不同硬件设置进行了验证。

**Result:** 研究发现，将“置换重要性”（Permutation Importance）选择方案与“随机森林”（Random Forest）分类器结合，可在不损害准确性的前提下，将电极数量减少53.5%。此外，SparseEMG设计工具生成的布局在用户之间具有可转移性，手势识别性能差异极小。

**Conclusion:** 本文成功开发了SparseEMG，一个计算设计工具，通过数据驱动的方法优化EMG电极布局，显著减少了手势识别所需的电极数量，同时保持了高准确性和良好的跨用户泛化能力，为EMG手势识别的实际应用提供了有效解决方案。

> **ai_Abstract:** 本文介绍了SparseEMG，一个用于肌电图（EMG）手势识别的计算设计工具。该工具通过数据驱动分析，系统评估了电极选择方案和分类器组合对准确性和电极稀疏性的影响。研究发现，结合置换重要性（Permutation Importance）和随机森林（Random Forest）可将电极数量减少53.5%而不牺牲准确性。SparseEMG基于这些发现生成稀疏电极布局，并已在多项真实世界应用中验证了其在不同用户间的良好性能可转移性。

> **摘要翻译:** 使用肌电图（EMG）进行手势识别是一个复杂的问题，受手势集、电极数量和放置以及机器学习参数（例如，特征、分类器）的影响。大多数现有工具包侧重于简化模型开发，但忽略了电极选择对分类准确性的影响。在这项工作中，我们首次提出了数据驱动的分析，探讨电极选择和分类器选择如何同时影响准确性和稀疏性。通过对六个数据集上28种组合（4种选择方案，7种分类器）的系统评估，我们找到了一种在不损害准确性的前提下最小化电极数量的方法。结果显示，将置换重要性（Permutation Importance）（选择方案）与随机森林（Random Forest）（分类器）结合，可将电极数量减少53.5%。基于这些发现，我们引入了SparseEMG，一个设计工具，它能根据用户选择的手势集、电极约束和机器学习参数生成稀疏电极布局，同时预测分类性能。SparseEMG支持50多种独特手势，并在三种使用不同硬件设置的真实世界应用中进行了验证。我们的多数据集评估结果表明，SparseEMG设计工具生成的布局在用户之间具有可转移性，手势识别性能差异极小。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [597] [Metacognition and self-regulated learning in manipulative robotic problem-solving task](https://arxiv.org/abs/2508.05112)
> *元认知与机械手机器人问题解决任务中的自我调节学习*

*Margarida Romero, George Kalmpourtzis* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 元认知, 自我调节学习, 机器人问题解决, 创造性问题解决, 教育机器人

**Comment:** 

> **TL;DR:** 本章通过一个案例研究，探讨了在教育机器人问题解决任务中，元认知和元推理如何调节探索和利用过程，从而促进知识的产生和问题的解决。

**AI_Comments:** 本研究通过一个具体的案例研究，深入探讨了元认知和元推理在复杂机器人问题解决任务中的作用，这对于理解学习者在技术环境中的认知过程具有重要意义。其创新之处在于将元认知理论应用于机器人教育领域，揭示了元认知对知识建构和问题解决的关键调节作用。然而，作为一个案例研究，其结果的普适性可能有限。

<details>
  <summary>Details</summary>

**Motivation:** 本章旨在通过元认知和互动主义方法，研究和识别教育机器人场景中的创造性问题解决（CPS）过程。

**Method:** 本章提出了一个案例研究，参与者需要探索一组机器人立方体，以发展与每个组件相关的技术知识，并概念化组装后的系统级行为，从而解决问题。研究分析了元推理在监控学习者推理和CPS活动进展中的应用。

**Result:** 研究展示了知识是如何通过元认知调节探索和利用现有知识和新兴知识的过程而产生的，直到找到解决方案。

**Conclusion:** 元认知和元推理在操纵性机器人问题解决任务中，通过调节探索和利用过程，对创造性问题解决和知识的产生至关重要。

> **ai_Abstract:** 本章探讨了在涉及教育机器人的创造性问题解决（CPS）任务中，元认知和元推理的作用。研究指出，元推理通过监控和调节探索与利用过程，影响学习者在解决定义不明确问题时的进展。通过一个案例研究，本章展示了参与者如何通过对机器人立方体的探索和对系统行为的概念化，在元认知调节下产生知识并最终找到解决方案。

> **摘要翻译:** 元认知是创造性问题解决（CPS）的一个重要方面，通过本章，我们分析了在监控学习者推理和CPS活动的不同过程中应用的元推理方面。元推理监控问题解决过程的进展方式，并调节时间和精力以找到解决方案。在定义不明确的问题情境中，需要探索以发展一个定义更明确的问题空间并向解决方案空间迈进。学习者参与探索和利用的方式由CPS活动中的元推理调节。本章的目标是结合元认知和互动主义方法，检查和识别教育机器人中的CPS过程。本章提出了一个案例研究，为了解决一个问题，参与者必须探索一组机器人立方体，以发展与系统每个单一组件相关的技术知识，同时也要概念化立方体组装时的系统级行为。本章展示了知识的出现是通过元认知调节探索和利用先前知识和新兴知识的过程，直到找到解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [603] [AI Conversational Tutors in Foreign Language Learning: A Mixed-Methods Evaluation Study](https://arxiv.org/abs/2508.05156)
> *针对外语学习的AI会话导师：一项混合方法评估研究*

*Nikolaos Avouris* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** AI导师, 外语学习, 会话功能, 混合方法, 用户体验

**Comment:** 

> **TL;DR:** 本研究对外语学习中的AI会话导师进行了混合方法评估，重点关注用户体验和会话质量，旨在建立评估标准并指导未来系统设计。

**AI_Comments:** 这项研究通过采用混合方法评估了AI会话导师在外语学习中的应用，其创新性在于结合了用户体验和基于聊天记录的质量分析。其重要性在于试图为AI语言学习工具的质量评估建立标准，并为未来设计提供指导，尤其关注了数据隐私这一关键问题。

<details>
  <summary>Details</summary>

**Motivation:** 随着自然语言理解和处理技术的进步，AI导师在外语学习领域取得了巨大发展，它们旨在满足提高语言技能（口语、交际能力、理解力）的需求。

**Method:** 本文报告了一项混合方法实证研究，评估了不同类型的最先进AI导师在外语学习中的应用。研究包括对典型工具的用户体验评估（特别关注会话功能）和基于聊天记录的质量评估。

**Result:** 研究结果未在摘要中明确提及，但指出该研究可以帮助建立评估此类系统质量的标准，并为未来工具的设计提供信息。

**Conclusion:** 该研究有助于建立评估AI会话导师系统质量的标准，并为未来工具的设计提供信息，包括数据隐私和学习者信息安全处理的考虑。

> **ai_Abstract:** 本文对外语学习中AI会话导师的有效性进行了一项混合方法实证评估。研究侧重于评估当前AI导师工具的用户体验及其会话能力，并通过分析聊天记录来衡量其质量。该研究旨在为AI语言学习系统的质量评估提供一套标准，并为未来工具的设计提供指导，同时强调了数据隐私和学习者信息安全的重要性。

> **摘要翻译:** 本文关注外语学习中的人工智能导师，这是人工智能导师应用的一个重要发展领域，尤其是在过去几年中，自然语言理解和实时处理取得了巨大进展。这些导师试图解决提高语言技能（口语或交际能力、理解力）的需求。本文报道了一项关于使用不同类型最先进人工智能导师进行语言学习的混合方法实证研究。这项研究涉及对典型工具的用户体验评估，特别关注其会话功能，以及基于聊天记录的质量评估。这项研究有助于建立评估此类系统质量的标准，并为未来工具的设计提供信息，包括对数据隐私和学习者信息安全处理的担忧。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [609] [A Methodological Framework and Questionnaire for Investigating Perceived Algorithmic Fairness](https://arxiv.org/abs/2508.05281)
> *一种调查感知算法公平性的方法论框架和问卷*

*Ahmed Abdal Shafi Rasel, Ahmed Mustafa Amlan, Tasmim Shajahan Mim, Tanvir Hasan* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 算法公平性, 用户感知, 孟加拉国, 混合方法, 文化因素

**Comment:** 

> **TL;DR:** 本研究通过混合方法调查了孟加拉国用户对算法公平性的看法，强调了文化背景在AI系统设计中的重要性。

**AI_Comments:** 该论文的创新之处在于其将非西方视角（孟加拉国）引入算法公平性讨论，这对于构建更具包容性和全球代表性的伦理AI框架至关重要。其混合方法论结合了定量和定性数据，有助于深入理解文化和社会因素对算法感知公平性的影响。其重要性在于为未来算法公平性的跨文化研究提供了基础，并强调了在AI系统设计中考虑地域和文化特异性的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索孟加拉国用户对算法决策公平性的感知，并考察文化、社会和语境因素如何影响用户对AI系统公平性、透明度和可问责性的理解，从而将非西方视角的观点纳入算法公平性的全球讨论中。

**Method:** 本研究采用综合混合方法，整合了定量调查数据和定性访谈见解，对孟加拉国用户进行了调查。

**Result:** 研究结果揭示了用户对人工监督、解释机制和可争议性的细微态度，并强调了文化、社会和语境因素对用户理解公平性、透明度和可问责性的影响。

**Conclusion:** 本研究强调了为公平和值得信赖的算法系统设计文化敏感原则的重要性，并通过引入非西方背景的视角，为算法公平性的持续讨论做出了贡献，从而拓宽了伦理AI部署的全球对话。

> **ai_Abstract:** 本研究通过在孟加拉国进行混合方法调查，深入探讨了用户对算法公平性的感知。研究结合定量调查和定性访谈数据，分析了文化、社会和语境因素如何塑造用户对AI公平性、透明度和问责制的理解。研究结果揭示了用户对人工监督、解释机制和可争议性的复杂态度，强调了在算法系统设计中融入文化敏感原则的重要性，从而为全球伦理AI部署的对话提供了非西方视角。

> **摘要翻译:** 本研究通过综合混合方法，探讨了孟加拉国用户对算法决策公平性的感知。通过整合定量调查数据和定性访谈见解，我们研究了文化、社会和语境因素如何影响用户对AI系统公平性、透明度和可问责性的理解。我们的发现揭示了对人工监督、解释机制和可争议性的细微态度，突出了为公平和值得信赖的算法系统设计文化敏感原则的重要性。这些见解通过突出非西方背景的视角，为算法公平性的持续讨论做出了贡献，从而拓宽了伦理AI部署的全球对话。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [615] [Critical Design Strategy: a Method for Heuristically Evaluating Visualisation Designs](https://arxiv.org/abs/2508.05325)
> *批判性设计策略：一种启发式评估可视化设计的方法*

*Jonathan C. Roberts, Hanan Alnjar, Aron E. Owen, Panagiotis D. Ritsos* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 批判性设计策略, 可视化设计, 启发式评估, 设计方法, 批判性思维

**Comment:** 

> **TL;DR:** 本文介绍了一种名为“批判性设计策略”（CDS）的结构化方法，旨在通过反思和批判性思维，帮助设计师启发式地评估和改进可视化设计，并分享了其在教学中的应用和发展历程。

**AI_Comments:** 该论文提出了一种实用的、经过时间检验的设计评估方法，其创新之处在于将批判性思维系统化为具体的三阶段六视角流程。其重要性在于为可视化设计领域的教育者和实践者提供了一个结构化的工具，以应对识别设计改进点的挑战。特别是其在高等教育中的长期应用和迭代改进，增加了该方法的可信度和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在开发可视化工具或开创新的可视化方法时，识别改进领域可能具有挑战性。批判性思维对于可视化设计师和工具开发者，特别是该领域的新手（如高等教育中的可视化学生）至关重要。

**Method:** 批判性设计策略（CDS）是一种结构化方法，通过反思和批判性思维促进可视化设计的检查。它包含三个阶段和六个视角：
1.  **第一阶段：** 通过指定指示性标题和选择五个形容词（从20个选项中）来捕捉设计的本质，形成初步印象。
2.  **第二阶段：** 使用30个启发式问题进行深入批判，这些问题涵盖六个关键视角：用户、环境、界面、组件、设计和视觉标记。
3.  **第三阶段：** 专注于综合见解、反思设计决策并确定下一步。

**Result:** 本文介绍了CDS，并探讨了它在本科生和研究生课程的三个可视化模块中的使用。作者团队通过长期使用CDS，对其进行了完善和发展：从2017/18年通过研讨会首次创建，到2020年改进措辞并开发了两个应用程序，再到2023年扩展支持笔记和完善启发式方法；每年都在教学中使用。

**Conclusion:** 持续使用CDS使作者团队能够反思其实际应用，并就其他人如何将其融入自己的工作提供指导。

> **ai_Abstract:** 本文提出了一种名为“批判性设计策略”（CDS）的结构化方法，旨在帮助可视化设计师通过启发式评估和批判性思维来审查和改进设计。该方法分为三个阶段：初步印象、深入批判（包含30个启发式问题和六个关键视角）以及见解综合。文章探讨了CDS在大学可视化课程中的应用，并分享了其从2017年至今的持续发展和完善过程，最终旨在为其他设计师提供将其融入工作实践的指导。

> **摘要翻译:** 我们提出了批判性设计策略（CDS）——一种结构化方法，旨在通过反思和批判性思维促进可视化设计的审查。CDS帮助设计师批判性思考并使用启发式评估做出明智的改进。在开发可视化工具或开创一种新颖的可视化方法时，识别改进领域可能具有挑战性。批判性思维对于可视化设计师和工具开发者，特别是该领域的新手（例如在高等教育中学习可视化的人）来说至关重要。CDS由三个阶段和六个视角组成：第一阶段通过指定一个指示性标题并选择五个形容词（从二十个选项中）来捕捉想法的本质，形成对设计的初步印象。第二阶段涉及使用30个启发式问题进行深入批判，这些问题涵盖六个关键视角——用户、环境、界面、组件、设计和视觉标记。第三阶段侧重于综合见解，反思设计决策，并确定下一步。我们介绍了CDS，并探讨了它在本科生和研究生课程的三个可视化模块中的使用。我们长期使用CDS的经验使我们能够随着时间的推移对其进行完善和发展：从2017/18年通过研讨会首次创建，到2020年改进措辞并开发了两个应用程序，随后在2023年扩展了支持笔记并完善了启发式方法；同时每年都在我们的教学中使用它。这种持续的使用使我们能够反思其实际应用，并就其他人如何将其融入自己的工作提供指导。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [621] [Implementation and Application of Multi-Format 3D Data Integration in a Cross-Device Commercial Metaverse Platform](https://arxiv.org/abs/2508.05332)
> *跨设备商业元宇宙平台中多格式三维数据集成与应用*

*Masanori Ibara, Yuichi Hiroi, Takushi Kamegai, Takefumi Hiraki* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 元宇宙, 三维数据集成, 跨设备, 协作决策, 数字孪生

**Comment:** 

> **TL;DR:** 该论文探讨了在商业元宇宙平台Cluster上集成多格式三维数据（如BIM和CAD），以打破传统专家壁垒，实现工业元宇宙中多设备访问和多用户协作决策，从而促进民主化环境。

**AI_Comments:** 该论文的创新点在于提出了在商业元宇宙平台中集成多格式三维数据以实现普通用户参与和协作决策的实际方法。其重要性在于打破了传统三维数据应用的专家壁垒，通过元宇宙和数字孪生技术赋能工业和建筑领域的民主化决策过程。这对于推动工业元宇宙的普及和应用具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统上，BIM和CAD等专业三维设计数据仅限于专家使用，阻碍了普通用户参与决策过程。本文旨在打破这一壁垒，通过在商业元宇宙平台中集成多格式三维数据，使普通用户也能参与工业和建筑领域的三维数据利用和决策。

**Method:** 本文系统性地概述了在商业跨设备元宇宙平台Cluster上利用三维数据的实际见解，并展示了工业元宇宙的实施案例。它分析了工业和建筑领域主要数据格式的特性和限制，并组织了元宇宙的集成工作流程。通过利用跨多个领域的三维数据应用案例，展示了元宇宙与数字孪生技术融合实现的协作决策支持。

**Result:** 通过该方法，实现了多设备访问和同时多用户参与能力，在工业元宇宙中培养了民主化环境。这些能力在传统的、依赖专家的系统中难以实现。

**Conclusion:** 本文证明了通过在跨设备商业元宇宙平台中集成多格式三维数据，并结合元宇宙和数字孪生技术，能够有效支持协作决策，并为工业元宇宙带来多设备访问和多用户参与的民主化环境，克服了传统系统的局限性。

> **ai_Abstract:** 本论文旨在解决传统专业三维数据（如BIM、CAD）仅限于专家使用，普通用户难以参与决策的问题。通过在商业跨设备元宇宙平台Cluster上，系统性地集成和应用多格式三维数据，并结合元宇宙与数字孪生技术，本文展示了如何实现工业和建筑领域中多设备访问和多用户协作决策。研究结果表明，这种方法能够创建民主化的工业元宇宙环境，克服了传统专家依赖系统的局限性。

> **摘要翻译:** 传统上，BIM和CAD等专业三维设计数据仅限于少数专家使用，造成了阻碍普通用户参与决策过程的重大障碍。本文系统地概述了在商业跨设备元宇宙平台Cluster上利用三维数据在工业和建筑领域的实际见解，并展示了工业元宇宙的实施案例。本文分析了工业和建筑领域主要数据格式的特性和限制，并组织了元宇宙的集成工作流程。通过利用跨多个领域的三维数据应用案例，我们展示了元宇宙和数字孪生技术融合实现的协作决策支持的实际范例。具体来说，我们证明了多设备访问和同时多用户参与能力在工业元宇宙中培养了民主化环境，而这在传统的、依赖专家的系统中是难以实现的。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [627] [Towards Human-Centric Evaluation of Interaction-Aware Automated Vehicle Controllers: A Framework and Case Study](https://arxiv.org/abs/2508.05497)
> *面向人本交互感知识别自动驾驶车辆控制器评估：一个框架与案例研究*

*Federico Scarì, Olger Siebinga, Arkady Zgonnikov* | **Category: cs.HC, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 自动驾驶车辆, 人机交互, 评估框架, 人本评估, 交互感知

**Comment:** 

> **TL;DR:** 该研究提出了一个以人为中心的自动驾驶车辆（AV）控制器评估框架，通过纳入人机交互指标来弥补现有评估方法仅关注技术性能的不足，并在一个合并场景中进行了案例研究，证明了其在揭示驾驶员体验差异方面的有效性。

**AI_Comments:** 该论文的创新之处在于提出了一个全面的、以人为中心的自动驾驶车辆评估框架，弥补了现有评估方法在关注技术性能时忽视人机交互维度的不足。其重要性在于为自动驾驶车辆的研发提供了更具指导意义的评估工具，有助于开发出不仅技术先进，而且能与人类和谐共存的自动驾驶系统，对于提升自动驾驶车辆的社会接受度和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶车辆（AV）控制器性能评估主要基于碰撞避免或车道保持效率等技术指标，而忽视了与人类驾驶车辆（HDV）交互的人本维度。随着AVs日益融入混合交通环境，评估其与人类的交互变得至关重要，以弥补这一评估空白。

**Method:** 本文提出了一个结构化的评估框架，该框架涵盖四个关键领域：a) 交互效果、b) 交互感知、c) 交互努力和d) 交互能力。这些领域旨在捕捉自动驾驶车辆的性能及其对周围人类驾驶员的影响。为验证框架的效用，研究将其应用于一个案例研究，评估了在驾驶模拟器中，最先进的AV控制器在合并场景中如何与人类驾驶员交互。以人类驾驶车辆之间的交互作为基线，每个领域包含一个代表性指标：a) 感知安全性、b) 主观评分（例如，参与者如何感知其他车辆的驾驶行为，如攻击性或可预测性）、c) 驾驶员工作量和d) 合并成功率。

**Result:** 研究结果表明，在自动驾驶车辆控制器评估中纳入涵盖所有四个领域的指标，能够揭示与自动驾驶车辆交互时驾驶员体验的关键差异。

**Conclusion:** 本文的框架为研究人员、开发人员和政策制定者提供了一种系统方法，用于评估自动驾驶车辆除技术性能之外的行为，从而促进开发不仅功能强大，而且从人类角度来看易于理解、可接受且安全的自动驾驶车辆。这强调了需要一种更全面的评估方法。

> **ai_Abstract:** 本论文提出了一个以人为中心的自动驾驶车辆（AV）控制器评估框架，旨在弥补现有评估方法仅关注技术性能而忽视人机交互维度的不足。该框架包含交互效果、交互感知、交互努力和交互能力四个关键领域。通过在一个驾驶模拟器中的合并场景案例研究，应用此框架评估AV控制器与人类驾驶员的交互，结果表明，纳入这些多维度指标能有效揭示驾驶员体验的差异，强调了更全面评估AV行为的重要性，以促进开发出功能性强且符合人类理解、接受度和安全性的AVs。

> **摘要翻译:** 随着自动驾驶车辆（AVs）日益融入混合交通环境，评估它们与人类驾驶车辆（HDVs）的交互变得至关重要。在大多数专注于开发新AV控制算法（控制器）的研究中，这些算法的性能仅基于碰撞避免或车道保持效率等性能指标进行评估，而很大程度上忽视了与HDVs交互的人本维度。本文提出了一个结构化的评估框架，通过纳入基于人机交互文献的指标来弥补这一空白。该框架涵盖四个关键领域：a) 交互效果、b) 交互感知、c) 交互努力和d) 交互能力。这些领域既捕捉了AV的性能，也捕捉了其对周围人类驾驶员的影响。为了展示该框架的效用，我们将其应用于一个案例研究，评估了在驾驶模拟器中的合并场景中，最先进的AV控制器如何与人类驾驶员交互。本研究以HDV-HDV交互作为基线，每个领域包含一个代表性指标：a) 感知安全性、b) 主观评分（具体指参与者如何感知其他车辆的驾驶行为，例如攻击性或可预测性）、c) 驾驶员工作量和d) 合并成功率。结果显示，在AV控制器评估中纳入涵盖所有四个领域的指标，可以阐明与AVs交互时驾驶员体验的关键差异。这突出了需要一种更全面的评估方法。我们的框架为研究人员、开发人员和政策制定者提供了一种系统方法，用于评估AV行为，超越了技术性能，从而促进开发不仅功能强大，而且从人类角度来看易于理解、可接受且安全的AVs。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [633] [Discrepancy-Aware Contrastive Adaptation in Medical Time Series Analysis](https://arxiv.org/abs/2508.05572)
> *医疗时间序列分析中的差异感知对比适应*

*Yifan Wang, Hongfeng Ai, Ruiqi Li, Maowei Jiang, Ruiyuan Kang, Jiahua Dong, Cheng Jiang, Chenzhong Li* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 医疗时间序列, 对比学习, AE-GAN, 多视图学习, 疾病诊断

**Comment:** 

> **TL;DR:** 本文提出了一种新的框架LMCF，结合AE-GAN和多视图对比学习，解决了医疗时间序列诊断中数据标注成本高和现有对比学习方法泛化性差的问题，并在多个疾病诊断任务中表现优异。

**AI_Comments:** 本文的创新点在于结合了AE-GAN提取先验知识和LMCF框架进行多视图对比学习，有效地解决了医疗时间序列数据标注成本高和现有对比学习方法泛化性不足的问题。通过自适应地捕获疾病特异性特征，提高了诊断的准确性，对实际医疗应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗时间序列疾病诊断中，存在两个主要挑战：一是医疗数据标注成本高昂，导致模型在标签受限的单中心数据集上训练时容易过拟合；二是现有对比学习方法依赖手动设计的样本对，导致复杂性高、泛化能力差，且无法自适应捕获疾病特异性特征。

**Method:** 本文提出了一种结合AE-GAN和LMCF（Learnable Multi-views Contrastive Framework）的方法。首先，利用AE-GAN从外部数据中提取先验知识。其次，LMCF框架集成了多头注意力机制，并通过视图间和视图内对比学习策略自适应地从不同视图中学习表示。此外，预训练的AE-GAN还用于将目标数据中的差异重构为疾病概率，并将其整合到对比学习过程中。

**Result:** 在三个目标数据集上的实验表明，本文方法持续优于其他七种基线方法。

**Conclusion:** 本文提出的方法在医疗时间序列疾病诊断中具有显著影响，尤其适用于心肌梗死、阿尔茨海默病和帕金森病等医疗保健应用。

> **ai_Abstract:** 本文针对医疗时间序列疾病诊断中的数据标注成本高和对比学习泛化性差的问题，提出了一种名为LMCF的差异感知对比适应框架。该框架结合AE-GAN提取先验知识，并利用多头注意力机制和视图间/视图内对比学习自适应地学习多视图表示。此外，AE-GAN重构的疾病概率被整合到对比学习中。实验证明，该方法在多个医疗数据集上表现优于现有基线，对心肌梗死、阿尔茨海默病和帕金森病等疾病的诊断具有重要意义。

> **摘要翻译:** 在医疗时间序列疾病诊断中，识别出两个关键挑战。首先，医疗数据的高昂标注成本导致模型在标签受限的单中心数据集上训练时出现过拟合。为了解决这个问题，我们提出结合来自相关任务的外部数据，并利用AE-GAN提取先验知识，为下游任务提供有价值的参考。其次，许多现有研究采用对比学习来推导更通用的医疗序列表示用于诊断任务，通常依赖于手动设计的不同正负样本对。然而，这些方法复杂、缺乏泛化性，并且未能自适应地捕获不同条件下的疾病特异性特征。为了克服这一点，我们引入了LMCF（Learnable Multi-views Contrastive Framework），这是一个集成了多头注意力机制并通过视图间和视图内对比学习策略自适应学习不同视图表示的框架。此外，预训练的AE-GAN用于将目标数据中的差异重构为疾病概率，然后将其整合到对比学习过程中。在三个目标数据集上的实验表明，我们的方法持续优于其他七种基线方法，突显了其在心肌梗死、阿尔茨海默病和帕金森病诊断等医疗保健应用中的重要影响。我们已在xxxx发布源代码。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [639] [Graffiti: Enabling an Ecosystem of Personalized and Interoperable Social Applications](https://arxiv.org/abs/2508.04889)
> *Graffiti：实现个性化和可互操作社交应用生态系统*

*Theia Henderson, David R. Karger, David D. Clark* | **Category: cs.HC, cs.SE, cs.SI** | **Updated: 2025-08-06**

**Keywords:** 社交应用, 互操作性, 个性化, 去中心化, Graffiti

**Comment:** 

> **TL;DR:** Graffiti是一个系统，旨在轻松构建个性化、可互操作的社交应用，解决现有应用僵化和孤立的问题。

**AI_Comments:** Graffiti的创新之处在于其“完全具体化”和“频道”的概念，解决了社交应用个性化与互操作性之间的核心矛盾。它提供了一个通用框架，使得用户可以在不同应用设计间无缝切换，同时保持数据和社交关系，这对于打破现有社交巨头的壁垒、促进去中心化和用户主导的社交体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大多数社交应用设计僵化、千篇一律，且构建新应用技术复杂，导致应用之间相互孤立，用户数据和关系无法迁移。

**Method:** 提出Graffiti系统，通过“完全具体化”（total reification）概念实现看似矛盾的设计（包括冲突的审核规则）之间的互操作性；通过“频道”（channels）概念防止意外互操作。应用通过最小的客户端API交互，支持去中心化实现。

**Result:** 构建了一个Vue.js插件，用于开发类似Twitter、Messenger和Wikipedia的客户端应用。案例研究展示了这些应用如何互操作，以及Graffiti所支持的更广泛的生态系统。

**Conclusion:** Graffiti通过其独特的设计理念（如完全具体化和频道）和易于使用的API，成功地使开发者能够轻松创建多样化、个性化且能互操作的社交应用，从而打破现有社交应用的壁垒，并促进一个更灵活、用户友好的社交生态系统。

> **ai_Abstract:** Graffiti是一个旨在解决当前社交应用僵化和孤立问题的系统。它使得开发者能够轻松构建多样化、个性化且能相互操作的社交应用。通过“完全具体化”和“频道”的概念，Graffiti实现了复杂设计间的互操作性，同时避免了意外的上下文冲突。该系统提供了一个最小的客户端API，并已通过Vue.js插件验证了其构建类似主流社交应用的潜力，从而促进了一个更灵活、用户数据可自由迁移的社交生态系统。

> **摘要翻译:** 大多数社交应用，从Twitter到Wikipedia，都采用僵化的“一刀切”设计，但构建新的社交应用不仅技术上具有挑战性，还会导致应用与现有社区相互隔离。我们提出了Graffiti，一个可以相对轻松地构建各种个性化社交应用，并且它们之间可以相互操作的系统。人们可以在多种设计之间自由切换——每种设计都有自己的美学、功能集和审核机制——而不会丢失他们的朋友或数据。
我们的“完全具体化”概念使得看似矛盾的设计，包括冲突的审核规则，也能实现互操作。相反，我们的“频道”概念可以防止意外的互操作，避免上下文崩溃。
Graffiti应用通过一个最小的客户端API进行交互，我们展示了它至少支持两种去中心化实现。在此API之上，我们构建了一个Vue.js插件，仅使用客户端代码即可开发类似Twitter、Messenger和Wikipedia的应用。我们的案例研究探讨了这些应用以及其他新颖应用如何互操作，以及Graffiti所能实现的更广泛的生态系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [645] [Will You Be Aware? Eye Tracking-Based Modeling of Situational Awareness in Augmented Reality](https://arxiv.org/abs/2508.05025)
> *你会意识到吗？基于眼动追踪的增强现实情境感知建模*

*Zhehan Qu, Tianyi Hu, Christian Fronk, Maria Gorlatova* | **Category: cs.HC, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 眼动追踪, 情境感知, 增强现实, 图神经网络, 心肺复苏

**Comment:** 

> **TL;DR:** 增强现实（AR）系统可能导致认知隧道效应，损害情境感知。本研究通过眼动追踪数据，开发了一个图神经网络模型FixGraphPool，以高精度预测AR环境下的情境感知水平，并揭示了眼动行为与情境感知之间的关联。

**AI_Comments:** 该论文的创新点在于首次将眼动追踪数据中的注视事件（注视、眼跳）结构化为时空图，并利用图神经网络（FixGraphPool）对增强现实（AR）环境下的情境感知（SA）进行建模和预测。这提供了一种量化和预测AR系统中认知隧道效应引起SA下降的有效方法。其重要性体现在为设计更安全、更高效的AR系统提供了新的技术路径，特别是在医疗等安全关键领域具有显著应用价值。研究结果表明眼动追踪数据在SA建模中的强大潜力，为未来AR交互设计中融入SA考量奠定了基础。局限性可能在于其研究场景主要集中在CPR，未来需要进一步验证该模型在其他AR应用场景的通用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 增强现实（AR）系统在提升任务性能的同时，存在导致认知隧道效应的风险，即用户过度关注虚拟内容，从而在安全关键场景中损害情境感知（SA）。本研究旨在AR辅助心肺复苏（CPR）场景下，调查并解决这一问题，因为在该场景中，救援人员必须在有效按压和警惕不可预测的危险之间取得平衡。

**Method:** 研究开发了一款在Magic Leap 2上运行的AR应用，提供实时CPR反馈。通过用户研究，模拟意外事件（如出血），并使用观察和冻结探针问卷收集SA指标。采用眼动追踪分析SA与注视行为的关系。提出并开发了FixGraphPool，一个将注视事件（注视、眼跳）构建成时空图的图神经网络模型，用于预测SA。

**Result:** 眼动追踪分析显示，较高的SA水平与更大的眼跳幅度、速度以及更低的虚拟内容注视比例和频率相关。所提出的FixGraphPool模型在SA预测上达到了83.0%的准确率（F1=81.0%），并且通过利用眼动追踪数据中编码的领域知识和时空信息，优于传统的基于特征的机器学习模型和最先进的时间序列模型。

**Conclusion:** 研究结果证明了眼动追踪在增强现实情境感知建模中的巨大潜力，并强调了其在设计能够确保用户安全和情境感知的AR系统方面的实用价值。

> **ai_Abstract:** 本研究探讨了增强现实（AR）系统中认知隧道效应导致的情境感知（SA）受损问题，尤其是在AR辅助心肺复苏（CPR）等安全关键场景。研究开发了一款AR应用，并进行了用户研究以评估SA。通过眼动追踪分析，发现高SA与特定的眼动行为（如更大的眼跳幅度、速度，更少的虚拟内容注视）相关。为预测SA，研究提出了一种名为FixGraphPool的图神经网络模型，该模型将眼动数据构建成时空图，实现了83.0%的预测准确率，并优于现有模型。研究结果表明眼动追踪在AR情境感知建模中的巨大潜力，并为设计更安全的AR系统提供了指导。

> **摘要翻译:** 增强现实（AR）系统在通过实时指导提高任务性能的同时，也存在诱发认知隧道效应的风险——即过度关注虚拟内容，从而在安全关键场景中损害情境感知（SA）。本文研究了AR引导下的心肺复苏（CPR）中的SA，在该场景中，救援人员必须在有效按压和警惕不可预测的危险（例如患者呕吐）之间取得平衡。我们基于Magic Leap 2开发了一款AR应用程序，可以叠加实时CPR反馈（按压深度和速率），并进行了一项用户研究，模拟了意外事件（例如出血）以评估SA，其中SA指标通过观察和在冻结探针事件期间进行的问卷收集。眼动追踪分析显示，较高的SA水平与更大的眼跳幅度、速度以及更低的虚拟内容注视比例和频率相关。为了预测SA，我们提出了FixGraphPool，一个将注视事件（注视、眼跳）构建成时空图的图神经网络，有效地捕捉动态注意力模式。我们的模型达到了83.0%的准确率（F1=81.0%），通过利用眼动追踪数据中编码的领域知识和时空信息，其性能优于基于特征的机器学习和最先进的时间序列模型。这些发现证明了眼动追踪在AR中SA建模的潜力，并突出了其在设计确保用户安全和情境感知的AR系统中的实用性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [651] ["Mango Mango, How to Let The Lettuce Dry Without A Spinner?": Exploring User Perceptions of Using An LLM-Based Conversational Assistant Toward Cooking Partner](https://arxiv.org/abs/2310.05853)
> *“芒果芒果，如何不用甩干机让生菜变干？”：探索用户对使用基于大型语言模型的对话助手作为烹饪伙伴的看法*

*Szeyi Chan, Jiachen Li, Bingsheng Yao, Amama Mahmood, Chien-Ming Huang, Holly Jimison, Elizabeth D Mynatt, Dakuo Wang* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 对话助手, 用户感知, 烹饪辅助, 人机交互

**Comment:** 

> **TL;DR:** 本研究探索了用户在使用基于LLM的对话助手（Mango Mango）进行烹饪时的体验，发现用户重视个性化指导和信息拓展，但也期望系统在口语对话和主动建议方面更适应，并提出了未来设计建议。

**AI_Comments:** 这篇论文的创新点在于它深入探索了LLM在特定日常任务（烹饪）中的实际用户体验，超越了简单的功能测试，关注用户情感和角色认知（从工具到伙伴）。其重要性在于揭示了当前LLM对话助手的优势和局限性，并基于用户反馈提出了实用的设计建议，对未来AI助手的设计和发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在对话助手（CAs）中展现出巨大潜力，特别是在日常任务辅助方面，但用户在现实世界中与这些助手的互动体验仍未被充分探索。

**Method:** 研究选择烹饪这一复杂的日常任务作为场景，探索用户在使用一个名为“Mango Mango”的基于LLM的对话助手时，所经历的成功和不尽如人意的体验。

**Result:** 用户重视系统提供基于上下文的定制化指令、提供超出食谱的广泛信息以及协助动态任务规划的能力。然而，用户期望系统能更好地适应口语对话，并提供更具启发性的回复以保持他们积极参与。

**Conclusion:** 用户开始将LLM对话助手视为个人助理甚至伙伴，而不仅仅是食谱阅读工具，研究基于此提出了未来开发的五项设计考虑。

> **ai_Abstract:** 本研究探讨了用户在使用基于大型语言模型（LLM）的对话助手“Mango Mango”进行烹饪任务时的体验。研究发现，用户赞赏LLM助手提供个性化指令、丰富额外信息和协助动态任务规划的能力。同时，用户也期望系统能更好地适应口语交流并提供更主动的建议。鉴于用户将LLM助手视为伙伴，研究提出了未来LLM对话助手的五项设计考量。

> **摘要翻译:** 大型语言模型（LLMs）的快速发展为与对话助手（CAs）集成以协助人们完成日常任务创造了众多潜力，特别是由于其广泛的灵活性。然而，用户在现实世界中与这些助手的互动体验仍未被探索。在这项研究中，我们选择烹饪这一复杂的日常任务作为场景，探索人们在使用一个名为“Mango Mango”的基于LLM的CA获得帮助时，所经历的成功和不尽如人意的体验。我们发现参与者重视系统提供基于上下文的定制化指令、提供超出食谱的广泛信息以及协助他们进行动态任务规划的能力。然而，用户期望系统能更好地适应口语对话，并提供更具启发性的回复以保持他们积极参与。认识到用户开始将我们的LLM-CA视为个人助理甚至伙伴，而不仅仅是食谱阅读工具，我们为未来的开发提出了五项设计考虑。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [656] [The Homework Wars: Exploring Emotions, Behaviours, and Conflicts in Parent-Child Homework Interactions](https://arxiv.org/abs/2502.01325)
> *家庭作业之战：探究亲子作业互动中的情绪、行为与冲突*

*Nan Gao, Yibin Liu, Xin Tang, Yanyan Liu, Chun Yu, Yun Huang, Yuntao Wang, Flora D. Salim, Xuhai Orson Xu, Jun Wei, Yuanchun Shi* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 亲子互动, 家庭作业, 大型语言模型, 情绪冲突, 家庭教育

**Comment:** 

> **TL;DR:** 本研究利用大型语言模型分析了78个中国家庭的亲子作业互动，揭示了父母情绪变化、18种父母行为和7种冲突类型（知识冲突最常见），并发现即使是善意的行为也与特定冲突相关。

**AI_Comments:** 本文通过引入大型语言模型分析自然亲子互动数据，创新性地解决了以往研究缺乏细粒度、实时动态分析的问题。其大规模的实地研究和详尽的行为、冲突模式分类，为家庭教育理论和实践提供了宝贵的实证依据，对于理解和改善亲子作业冲突具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 家长参与家庭作业是家庭教育的重要组成部分，但常引发情感紧张和冲突。现有研究缺乏对这些互动细致、实时的动态分析，本研究旨在弥补这一空白。

**Method:** 本研究提出了一个框架，利用自然亲子互动数据和大型语言模型（LLMs）大规模分析作业对话。通过一项为期四周、有78个中国家庭参与的实地研究，收集了475小时的录音和每日问卷，捕捉了602个家庭作业场景。基于LLM的流程可靠地从转录对话中提取并分类了父母行为和冲突模式，与专家标注具有高度一致性。

**Result:** 分析显示父母在作业前后情绪有显著变化；识别出18种反复出现的父母行为和7种常见的冲突类型，其中知识冲突最为频繁。值得注意的是，即使是善意的行为也与特定冲突显著正相关。

**Conclusion:** 这项工作推动了普适计算方法在研究复杂家庭动态方面的应用，并提供了实证见解，以丰富家庭教育理论，并为未来更有效的育儿策略和干预措施提供信息。

> **ai_Abstract:** 本研究旨在弥补现有研究在亲子作业互动动态分析上的不足。通过对78个中国家庭进行四周的实地研究，收集了大量的录音和问卷数据。研究利用大型语言模型构建的分析流程，识别并分类了父母的行为和冲突模式。结果发现父母在作业前后情绪有显著变化，并揭示了18种父母行为和7种冲突类型，其中知识冲突最为常见。研究还指出，即使是善意的父母行为也可能与特定冲突相关。这项工作为理解复杂的家庭动态提供了实证洞察，并有助于未来制定更有效的育儿策略。

> **摘要翻译:** 家长参与家庭作业是家庭教育的一个重要方面，但它经常引发情感紧张和冲突。尽管对其对家庭幸福的影响日益关注，但先前的研究缺乏对这些互动精细、实时的动态分析。为了弥补这一空白，我们提出了一个框架，该框架利用自然亲子互动数据和大型语言模型（LLMs）大规模分析作业对话。在一项为期四周、有78个中国家庭参与的实地研究中，我们收集了475小时的录音和随附的每日问卷，捕捉了日常家庭环境中602个作业会话。我们基于LLM的管道可靠地从转录对话中提取并分类了父母行为和冲突模式，与专家标注实现了高度一致性。分析揭示了父母在作业前后显著的情绪变化，18种反复出现的父母行为和七种常见的冲突类型，其中知识冲突最为频繁。值得注意的是，即使是善意的行为也与特定冲突显著正相关。这项工作推动了普适计算方法在研究复杂家庭动态方面的应用，并提供了实证见解，以丰富家庭教育理论，并为未来更有效的育儿策略和干预措施提供信息。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [663] [Audio Personas: Augmenting Social Perception via Body-Anchored Audio Cues](https://arxiv.org/abs/2505.00956)
> *听觉角色：通过身体锚定音频线索增强社交感知*

*Yujie Tao, Libby Ye, Jeremy N. Bailenson, Sean Follmer* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 听觉角色, 社交感知, 增强现实, 身体锚定音频, 印象形成

**Comment:** 

> **TL;DR:** 本文介绍了“听觉角色”，一种在音频增强现实中通过身体锚定声音来“装饰”用户的方式。研究表明，听觉角色能影响人们的印象形成，积极的听觉角色使个体更具社交吸引力、更受欢迎且威胁性更小。听觉设计师认为其在公共和半公共空间中对管理社交印象和信号当前状态有效。

**AI_Comments:** 这项研究提出了一种新颖的社交增强方式，通过听觉而非视觉或嗅觉进行“装饰”，具有创新性。它揭示了声音在社交感知中的潜在影响力，为未来增强现实应用中的非语言交流开辟了新方向。研究结果表明，简单的音频线索也能显著影响人际印象，这对于社交互动设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供一种替代且动态的渠道来增强面对面互动，就像服装、化妆品和香水一样，听觉角色旨在通过身体锚定的声音来“装饰”用户，从而影响社交感知。

**Method:** 研究团队实现了一个基于耳机的原型系统，该系统具有多用户跟踪和音频流功能，以实例化“听觉角色”的概念。他们进行了一项预注册的实验室研究，共有64名参与者，以评估听觉角色对印象形成的影响。此外，还对音频设计师进行了一项研究，以了解他们对听觉角色在不同空间中用途的看法。

**Result:** 在实验室研究中，听觉角色确实影响了参与者形成印象的方式。拥有积极听觉角色的个体被评价为比拥有消极听觉角色的个体更具社交吸引力、更受欢迎且威胁性更小。对音频设计师的研究表明，他们倾向于在公共和半公共私人空间中使用听觉角色来管理社交印象（例如，个性）和发出当前状态信号（例如，情绪）。

**Conclusion:** 听觉角色提供了一种新颖的、动态的社交增强方式，能够有效影响个体在面对面互动中的印象形成。它们在管理社交印象和传递情绪状态方面具有潜力，尤其是在公共和半公共空间中。

> **ai_Abstract:** 本文介绍了“听觉角色”这一概念，通过身体锚定的声音在音频增强现实中装饰用户，旨在作为一种新的动态渠道来增强面对面社交互动。研究团队开发了一个基于耳机的原型系统，并进行了两项研究：一项针对64名参与者的实验室研究发现，积极的听觉角色能显著提升个体的社交吸引力、受欢迎程度并降低威胁感；另一项针对音频设计师的研究则揭示，听觉角色在公共和半公共空间中对管理社交印象和表达当前状态具有实用价值。

> **摘要翻译:** 我们引入了“听觉角色”，让用户能够在音频增强现实中用身体锚定的声音“装饰”自己。就像服装、化妆品和香水一样，听觉角色提供了一种替代但动态的渠道来增强面对面互动。例如，一个人可以将其听觉角色设置为雨声以反映糟糕的心情，蜂鸣声以建立个人边界，或 playful 的“嗖”声来模仿像微风一样从某人身边经过。为了实例化这一概念，我们实现了一个基于耳机的原型，具有多用户跟踪和音频流功能。我们对64名参与者进行的预注册实验室研究表明，听觉角色影响了参与者形成印象的方式。拥有积极听觉角色的个体被评价为比拥有消极听觉角色的个体更具社交吸引力、更受欢迎且威胁性更小。我们对音频设计师的研究表明，听觉角色在公共和半公共私人空间中更受青睐，用于管理社交印象（例如，个性）和发出当前状态信号（例如，情绪）。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [667] [Facilitating Visual Media Exploration for Blind and Low Vision Users through AI-Powered Interactive Storytelling](https://arxiv.org/abs/2508.03061)
> *通过AI驱动的交互式叙事促进盲人和低视力用户对视觉媒体的探索*

*Shuchang Xu* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** AI驱动叙事, 盲人和低视力用户, 视觉媒体探索, 交互式叙事, 无障碍技术

**Comment:** 

> **TL;DR:** 该博士研究引入了AI驱动的交互式叙事范式，通过分层、并行和分支叙事技术，帮助盲人和低视力用户在连贯的叙事体验中探索视觉媒体，有效平衡用户自主性和叙事连贯性。

**AI_Comments:** 这项研究的创新之处在于提出了AI驱动的交互式叙事范式，它将视觉媒体探索无缝融入到叙事流程中，解决了现有工具打断叙事连贯性和增加认知负荷的问题。通过分层、并行和分支叙事等具体技术，该研究为盲人和低视力用户提供了更自然、沉浸式的媒体体验，有效提升了他们的内容理解和自主性。其重要性体现在为无障碍技术领域提供了一个新颖且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 赋能盲人和低视力（BLV）用户探索视觉媒体可以提高内容理解、增强用户自主性并满足多样化的信息需求。然而，现有工具通常将探索与主要叙事分离，这会打断叙事流程，增加认知负荷，并限制对视觉媒体的深度参与。

**Method:** 该研究引入了AI驱动的交互式叙事范式，利用AI生成交互式叙事，使盲人和低视力用户能够在连贯的叙事体验中探索视觉媒体。具体通过三种技术实现：1）分层叙事，支持不同细节层次的照片集探索；2）并行叙事，提供时间同步视频评论的无缝访问；3）分支叙事，实现360度视频的沉浸式导航。

**Result:** 这些技术共同证明，AI驱动的交互式叙事可以有效地平衡用户自主性和跨多种媒体格式的叙事连贯性。

**Conclusion:** AI驱动的交互式叙事范式能够有效帮助盲人和低视力用户在保持叙事连贯性的同时，更深入地探索视觉媒体，平衡了用户自主性与叙事连贯性。

> **ai_Abstract:** 该研究旨在解决现有工具在帮助盲人和低视力（BLV）用户探索视觉媒体时，探索与叙事分离导致的问题。作者提出了一种AI驱动的交互式叙事范式，通过AI生成连贯的交互式叙事，使BLV用户能在叙事流程中探索视觉内容。该范式通过分层叙事（照片集）、并行叙事（视频评论）和分支叙事（360度视频）三种技术实现，并证明了其在平衡用户自主性与叙事连贯性方面的有效性。

> **摘要翻译:** 赋能盲人和低视力（BLV）用户探索视觉媒体可以提高内容理解，增强用户自主性，并满足多样化的信息需求。然而，大多数现有工具将探索与主要叙事分离，这会打断叙事流程，增加认知负荷，并限制对视觉媒体的深度参与。为了解决这些挑战，我的博士研究引入了AI驱动的交互式叙事范式，该范式利用AI生成交互式叙事，使BLV用户能够在连贯的叙事体验中探索视觉媒体。我通过三种技术实现了这一范式：（1）分层叙事，支持不同细节层次的照片集探索；（2）并行叙事，提供时间同步视频评论的无缝访问；以及（3）分支叙事，实现360度视频的沉浸式导航。这些技术共同证明，AI驱动的交互式叙事可以有效地平衡用户自主性和跨多种媒体格式的叙事连贯性。我未来的工作将通过为BLV受众提供更个性化和富有表现力的叙事体验来推进这一范式。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [675] [A Review of Behavioral Closed-Loop Paradigm from Sensing to Intervention for Ingestion Health](https://arxiv.org/abs/2505.03185)
> *从感知到干预的摄食健康行为闭环范式综述*

*Jun Fang, Yanuo Zhou, Ka I Chan, Jiajin Li, Zeyi Sun, Zhengnan Li, Zicong Fu, Hongjing Piao, Haodong Xu, Yuanchun Shi, Yuntao Wang* | **Category: cs.HC** | **Updated: 2025-08-06**

**Keywords:** 摄食健康, 行为闭环, 传感器, 情境感知, 干预

**Comment:** 

> **TL;DR:** 本文综述了136项关于利用传感器或交互介导方法进行摄食行为闭环干预的研究，提出了一个行为闭环范式和分类法，并揭示了当前模式和设计空白，为未来干预提供见解。

**AI_Comments:** 这篇综述通过系统梳理大量文献，提出了一个清晰的行为闭环范式和分类法，对于理解当前摄食健康干预的现状和趋势具有重要价值。其创新性在于将情境感知计算和HCI行为改变框架融入闭环干预，并揭示了该领域的设计空白，为未来的研究和应用指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有摄食行为干预措施受限于静态指导或手动追踪。随着传感器、情境感知计算和感知计算的进步，动态闭环干预成为可能。因此，需要对这些利用新技术影响摄食行为的闭环系统进行系统回顾。

**Method:** 本综述回顾了136项利用传感器或交互介导方法影响摄食行为的研究。研究提出了一个基于情境感知计算和HCI行为改变框架的行为闭环范式，该范式包含目标行为、感知方式、推理和干预策略四个组成部分。此外，还提出了感知和干预方式的分类法，并分析了不同方式-行为配对的评估方法和设计趋势。

**Result:** 综述揭示了当前摄食健康干预中的主流模式和关键空白，并为未来适应性强且情境感知的干预措施提供了设计见解。此外，本文提出了一个包含四个组成部分的行为闭环范式和一个感知与干预方式的分类法。

**Conclusion:** 这项综述揭示了当前在摄食健康干预中的主流模式和关键空白，并为未来开发更具适应性和情境感知能力的干预措施提供了设计见解。

> **ai_Abstract:** 这篇综述系统地回顾了136项关于利用传感器和交互技术进行摄食行为闭环干预的研究。文章提出了一个包含目标行为、感知方式、推理和干预策略四个组成部分的行为闭环范式，并提供了一个感知与干预方式的分类体系。通过分析评估方法和设计趋势，该综述揭示了现有研究的模式和不足，为未来开发智能、情境感知的摄食健康干预提供了指导。

> **摘要翻译:** 摄食行为在健康中起着关键作用，然而许多现有干预措施仍局限于静态指导或手动自我追踪。随着传感器、情境感知计算和感知计算的日益整合，最近的系统已开始支持闭环干预，这些干预能在摄食发生期间或前后动态感知用户行为并提供反馈。在本综述中，我们回顾了136项利用传感器或交互介导方法影响摄食行为的研究。我们提出了一种基于情境感知计算并受HCI行为改变框架启发的行为闭环范式，该范式包含四个组成部分：目标行为、感知方式、推理和干预策略。本文提出了感知和干预方式的分类法，该分类法按以人为中心和以环境为中心的维度组织。我们的分析还考察了不同方式-行为配对的评估方法和设计趋势。这项综述揭示了当前主流模式和关键空白，为未来适应性强且情境感知的摄食健康干预提供了设计见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [678] [A11yShape: AI-Assisted 3-D Modeling for Blind and Low-Vision Programmers](https://arxiv.org/abs/2508.03852)
> *A11yShape：AI辅助盲人和低视力程序员进行三维建模*

*Zhuohao Jerry Zhang, Haichang Li, Chun Meng Yu, Faraz Faruqi, Junan Xie, Gene S-H Kim, Mingming Fan, Angus G. Forbes, Jacob O. Wobbrock, Anhong Guo, Liang He* | **Category: cs.HC** | **Updated: 2025-08-07**

**Keywords:** 三维建模, 盲人和低视力, 可访问性, LLM, OpenSCAD

**Comment:** 

> **TL;DR:** A11yShape是一个新系统，它利用LLM和OpenSCAD帮助盲人和低视力程序员理解、修改和迭代三维模型，并通过用户研究证明了其有效性。

**AI_Comments:** A11yShape的创新之处在于它将LLMs与OpenSCAD结合，并引入了跨表示高亮机制，为盲人和低视力用户提供了前所未有的三维建模能力。这项工作的重要性在于它极大地提高了BLV程序员在三维设计领域的包容性和独立性。通过赋能用户独立完成之前需要视力正常者协助的任务，该系统为可访问性工具的未来发展开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 由于三维模型固有的复杂性以及现有工具缺乏非视觉交互支持，盲人和低视力（BLV）用户进行三维建模面临挑战。

**Method:** A11yShape是一个新系统，它利用大型语言模型（LLMs）并与流行的开源编辑器OpenSCAD集成，OpenSCAD通过代码生成三维模型。其主要功能包括：三维模型的可访问描述、跟踪模型和代码变化的版本控制，以及模型组件的分层表示。最重要的是，A111yShape采用跨表示高亮机制，同步代码、语义层次结构、AI描述和三维渲染中所有模型表示的语义选择。

**Result:** 对四名盲人和低视力程序员进行了多会话用户研究。在初始教程会话后，参与者在两次测试会话中独立完成了12个不同的模型，结果符合他们的满意度。结果表明，参与者能够理解提供的三维模型，并独立创建和修改三维模型，而这些任务在没有视力正常者协助的情况下是以前不可能完成的。

**Conclusion:** A11yShape成功地使盲人和低视力程序员能够独立进行三维建模，解决了现有工具的局限性，并显著提高了他们的建模能力。

> **ai_Abstract:** A11yShape是一个为盲人和低视力程序员设计的新系统，旨在解决他们进行三维建模的挑战。该系统利用大型语言模型（LLMs）并与OpenSCAD集成，提供可访问的三维模型描述、版本控制和分层表示。其核心创新是跨表示高亮机制，同步代码、语义层次、AI描述和三维渲染的语义选择。用户研究表明，A11yShape使盲人和低视力程序员能够独立理解、创建和修改三维模型，克服了现有工具的局限性。

> **摘要翻译:** 构建三维模型对于盲人和低视力（BLV）用户来说具有挑战性，这是由于三维模型固有的复杂性以及现有工具缺乏对非视觉交互的支持。为了解决这个问题，我们引入了A11yShape，一个旨在帮助具备基本编程技能的BLV用户理解、修改和迭代三维模型的新型系统。A11yShape利用大型语言模型（LLMs）并与OpenSCAD集成，OpenSCAD是一个流行的开源编辑器，它通过代码生成三维模型。A11yShape的关键功能包括三维模型的可访问描述、跟踪模型和代码变化的版本控制，以及模型组件的分层表示。最重要的是，A11yShape采用跨表示高亮机制，同步代码、语义层次结构、AI描述和三维渲染中所有模型表示的语义选择。我们对四名BLV程序员进行了多会话用户研究，在初始教程会话之后，参与者在两次测试会话中独立完成了12个不同的模型，取得了符合他们满意度的结果。结果表明，参与者能够理解提供的三维模型，并独立创建和修改三维模型——这些任务在没有视力正常者协助的情况下是以前不可能完成的。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [687] [Label Leakage in Federated Inertial-based Human Activity Recognition](https://arxiv.org/abs/2505.20924)
> *联邦惯性人体活动识别中的标签泄露*

*Marius Bock, Maximilian Hopp, Kristof Van Laerhoven, Michael Moeller* | **Category: cs.HC, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 联邦学习, 标签泄露, 人体活动识别, 梯度攻击, 隐私保护

**Comment:** 

> **TL;DR:** 本研究发现联邦学习中基于梯度的标签重建攻击在人体活动识别（HAR）任务上非常有效，即使采用差分隐私技术也难以完全阻止标签泄露，并提出了隐私感知部署的建议。

**AI_Comments:** 这项研究首次将标签重建攻击应用于联邦惯性人体活动识别领域，揭示了联邦学习在该应用中存在的严重隐私风险。研究结果强调了现有隐私保护机制的局限性，对未来设计更鲁棒的联邦HAR系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管之前的研究表明联邦学习更新会泄露敏感信息，但标签重建攻击在人体活动识别（HAR）领域尚未被研究。鉴于活动标签的敏感性，本研究旨在评估此类攻击的有效性。

**Method:** 评估了最先进的基于梯度的标签泄露攻击在HAR基准数据集上的有效性。研究了活动类别数量、采样策略和类别不平衡对标签泄露的影响，并评估了局部差分隐私技术（如梯度噪声和裁剪）的保护效果。

**Result:** 标签重建准确率在两个基准数据集上达到90%以上，即使对于已训练模型。活动类别数量、采样策略和类别不平衡是影响标签泄露程度的关键因素。局部差分隐私技术（如梯度噪声和裁剪）提供的保护有限，某些攻击仍能可靠地推断出多数和少数类标签。

**Conclusion:** 联邦惯性人体活动识别系统在部署时需要注意隐私问题，并提出了实际建议，同时指出了未来研究的开放挑战。

> **ai_Abstract:** 本文研究了联邦学习中基于梯度的标签泄露攻击在人体活动识别（HAR）任务上的有效性。研究发现，即使是已训练模型，在HAR基准数据集上标签重建准确率仍可超过90%，且活动类别数量、采样策略和类别不平衡是关键影响因素。此外，局部差分隐私技术对某些攻击的保护作用有限。文章最后提供了隐私感知部署的建议。

> **摘要翻译:** 尽管先前的研究表明联邦学习的更新会泄露敏感信息，但旨在从共享梯度中恢复输入标签的标签重建攻击尚未在人体活动识别（HAR）的背景下进行检验。考虑到活动标签的敏感性，本研究评估了最先进的基于梯度的标签泄露攻击在HAR基准数据集上的有效性。我们的发现表明，活动类别的数量、采样策略和类别不平衡是影响标签泄露程度的关键因素，即使对于训练过的模型，在两个基准数据集上的重建准确率也达到了90%以上。此外，我们发现局部差分隐私技术（如梯度噪声和裁剪）提供的保护有限，因为某些攻击仍然能够可靠地推断出多数和少数类标签。最后，我们为联邦HAR系统的隐私感知部署提供了实用建议，并指出了未来研究的开放挑战。重现我们实验的代码可在github.com/mariusbock/leakage_har上公开获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [694] [Augmented Question-guided Retrieval (AQgR) of Indian Case Law with LLM, RAG, and Structured Summaries](https://arxiv.org/abs/2508.04710)
> *结合大型语言模型、检索增强生成和结构化摘要的印度判例法增强型问题引导检索（AQgR）*

*Vishnuprabha V, Daleesha M Viswanathan, Rajesh R, Aneesh V Pillai* | **Category: cs.IR** | **Updated: 2025-07-23**

**Keywords:** 判例法检索, 大型语言模型, 检索增强生成, 结构化摘要, 印度法律

**Comment:** 

> **TL;DR:** 本文提出一种基于LLM、RAG和结构化摘要的AQgR框架，通过生成法律问题来更有效地检索印度判例法，并显著超越现有基准。

**AI_Comments:** 本文的创新点在于将大型语言模型、RAG和结构化摘要结合起来，并引入了“增强型问题引导检索（AQgR）”框架，通过生成法律问题来改进判例法检索，从而实现从传统的事实相似性检索到法律问题导向的检索的转变。这对于法律信息检索领域是一个重要的进步，因为它提供了更符合法律专业人士实际需求的、上下文更相关的结果，并且能够自主生成解释，降低了对法律专业知识的依赖。其性能显著超越现有基准也证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 识别相关的法律先例仍然具有挑战性，因为大多数检索方法侧重于事实相似性而非法律问题，并且现有系统通常缺乏解释案例相关性的说明。

**Method:** 本文提出使用大型语言模型（LLMs）来检索相关案例、生成解释并自主识别核心法律问题。该方法结合了检索增强生成（RAG）和针对印度判例法优化的结构化摘要。通过增强型问题引导检索（AQgR）框架，系统根据事实场景生成有针对性的法律问题，以更有效地识别相关判例法。结构化摘要由法律专家手动评估，判例法检索使用FIRE数据集进行评估，解释生成由法律专家审查。

**Result:** 在FIRE 2019数据集子集上的实验评估取得了有希望的结果，测试查询的平均精度（MAP）得分达到0.36，平均召回率（MAR）达到0.67，显著超过当前0.1573的MAP基准。

**Conclusion:** 该工作引入了一系列新颖的贡献来推进判例法检索。通过从基于事实的检索转向基于法律问题的检索，所提出的方法提供了与法律专业人士需求更紧密相关的上下文相关结果。通过AQgR框架在检索过程中整合法律问题，通过细化查询上下文确保了更精确和有意义的检索。

> **ai_Abstract:** 本文针对现有法律检索系统侧重事实相似性且缺乏解释的问题，提出了一种名为增强型问题引导检索（AQgR）的新方法。该方法结合大型语言模型（LLM）、检索增强生成（RAG）和结构化摘要，能够自主检索相关印度判例法、生成相关性解释并识别核心法律问题。AQgR框架通过生成基于事实场景的法律问题来提高检索效率和精确性。在FIRE 2019数据集上的实验结果显示，该方法在平均精度（MAP）和平均召回率（MAR）上显著优于现有基准，证明了其从事实检索向法律问题检索转变的有效性，从而提供更符合法律专业人士需求的上下文相关结果。

> **摘要翻译:** 识别相关的法律先例仍然具有挑战性，因为大多数检索方法侧重于事实相似性而非法律问题，并且现有系统通常缺乏解释案例相关性的说明。本文提出使用大型语言模型（LLMs）来解决这一问题，通过促进相关案例的检索、生成解释以阐明相关性，并自主识别核心法律问题，所有这些都无需法律专业知识。我们的方法将检索增强生成（RAG）与针对印度判例法优化的结构化摘要相结合。利用增强型问题引导检索（AQgR）框架，系统根据事实场景生成有针对性的法律问题，以更有效地识别相关判例法。鉴于缺乏合适的结构化摘要数据集，结构化摘要由法律专家手动评估。判例法检索使用FIRE数据集进行评估，解释由法律专家审查，因为案例检索伴随解释生成是一项新兴创新。在FIRE 2019数据集子集上的实验评估取得了有希望的结果，测试查询的平均精度（MAP）得分达到0.36，平均召回率（MAR）达到0.67，显著超过当前0.1573的MAP基准。这项工作引入了一系列新颖的贡献来推进判例法检索。通过从基于事实的检索转向基于法律问题的检索，所提出的方法提供了与法律专业人士需求更紧密相关的上下文相关结果。通过AQgR框架在检索过程中整合法律问题，通过细化查询上下文确保了更精确和有意义的检索。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [699] [Scaling Generative Recommendations with Context Parallelism on Hierarchical Sequential Transducers](https://arxiv.org/abs/2508.04711)
> *在分层序列传感器上使用上下文并行化扩展生成式推荐系统*

*Yue Dong, Han Li, Shen Li, Nikhil Patel, Xing Liu, Xiaodong Wang, Chuanhao Zhuge* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-23**

**Keywords:** 生成式推荐, 上下文并行化, 分层序列传感器, 序列长度, 大规模推荐系统

**Comment:** 

> **TL;DR:** 本文介绍了在分层序列传感器 (HSTU) 上支持不规则张量的上下文并行化 (CP) 方案，旨在扩展生成式推荐系统，使其能够处理更长的用户历史序列，从而显著提升了序列长度支持和扩展性。

**AI_Comments:** 本文的创新之处在于成功地将通常用于大型语言模型（LLMs）的上下文并行化技术，适配并应用于推荐系统特有的不规则张量数据结构，解决了扩展用户历史序列的内存瓶颈。这对于大规模生成式推荐系统至关重要，因为它允许模型利用更长的用户历史，从而有可能显著提高预测准确性。实验结果中5.3倍的序列长度提升和1.55倍的扩展因子，证明了该方法在实际生产环境中的重要性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大规模推荐系统需要有效建模高基数和异构特征以确保准确预测。先前的分层序列传感器 (HSTU) 架构在生成式推荐框架 (GR) 中展现了良好的扩展性。近期研究表明，关注更长的用户历史序列可以显著改善推荐指标。然而，扩展序列长度会导致激活内存消耗过大，需要并行化解决方案来有效分片激活内存。虽然上下文并行化 (CP) 在基于 Transformer 的大型语言模型 (LLMs) 中是常用技术，但生产级排序模型通常利用不规则输入张量来表示用户交互特征，这给 CP 的实现带来了独特的挑战。

**Method:** 本文引入了对分层序列传感器 (HSTU) 注意力支持不规则张量的上下文并行化 (CP) 技术，并将其与分布式数据并行 (DDP) 结合。

**Result:** 该方法使支持的用户交互序列长度增加了5.3倍。与分布式数据并行 (DDP) 结合时，实现了1.55倍的扩展因子。

**Conclusion:** 通过引入支持不规则张量的上下文并行化，可以在分层序列传感器上有效扩展生成式推荐系统，使其能够处理更长的用户历史序列，从而提高推荐性能。

> **ai_Abstract:** 该论文旨在解决生成式推荐系统，特别是分层序列传感器（HSTU）架构在处理更长用户交互序列时的扩展性挑战。针对激活内存消耗大的问题，文章提出了一种支持不规则张量的上下文并行化（CP）解决方案，用于 HSTU 的注意力机制。该方法显著提升了支持的序列长度达5.3倍，并且在与分布式数据并行（DDP）结合时，实现了1.55倍的扩展因子，为通过利用更丰富的用户历史来提高推荐准确性奠定了基础。

> **摘要翻译:** 大规模推荐系统对于处理海量日常用户交互至关重要，需要有效建模高基数和异构特征以确保准确预测。在先前的工作中，我们引入了分层序列传感器（HSTU），这是一种基于注意力的架构，用于建模高基数、非平稳的流式推荐数据，在生成式推荐框架（GR）中提供了良好的扩展性。最近的研究和实验表明，关注更长的用户历史序列可以显著改善指标。然而，扩展序列长度会消耗大量激活内存，因此需要并行化解决方案来有效分片激活内存。在基于 Transformer 的大型语言模型中，上下文并行化（CP）是一种常用技术，它将计算沿序列长度维度分布到多个 GPU 上，有效减少了注意力激活的内存使用。相比之下，生产排序模型通常利用不规则输入张量来表示用户交互特征，这引入了独特的 CP 实现挑战。在这项工作中，我们引入了对 HSTU 注意力支持不规则张量的上下文并行化，为扩展序列维度奠定了基础能力。我们的方法使支持的用户交互序列长度增加了5.3倍，同时与分布式数据并行（DDP）结合时实现了1.55倍的扩展因子。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [705] [A Metric for MLLM Alignment in Large-scale Recommendation](https://arxiv.org/abs/2508.04963)
> *大规模推荐中MLLM对齐的度量标准*

*Yubin Zhang, Yanhua Huang, Haiming Xu, Mingliang Qi, Chang Wang, Jiarui Jin, Xiangyuan Ren, Xiaodan Wang, Ruiwen Xu* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** MLLM, 推荐系统, 对齐, 度量标准, 泄漏影响分数

**Comment:** 

> **TL;DR:** 本文提出了泄漏影响分数（LIS），这是一种用于大规模推荐中多模态大语言模型（MLLM）对齐的新颖度量标准，旨在解决静态基准不准确、在线评估成本高以及传统指标缺乏可操作性洞察的问题。在实际应用中，LIS显著提升了用户停留时间和广告商价值。

**AI_Comments:** 本文的创新之处在于提出了一种间接但高效的度量方法——泄漏影响分数（LIS），以评估多模态大语言模型（MLLM）在大规模推荐系统中的对齐情况。这种方法解决了现有评估方法的痛点，即静态基准的局限性和在线测试的高成本。其在真实世界A/B测试中取得的显著效果，特别是在用户参与度和广告商价值方面的提升，凸显了该方法在实际部署先进AI模型时的重要性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多模态推荐系统依赖于多模态大语言模型（MLLM）的内容表示，但评估这些MLLM与推荐系统的对齐存在显著挑战。具体问题包括：1）静态基准测试不准确，因为实际应用具有动态性；2）在线系统评估虽然准确，但在大规模部署时成本过高；3）当学习到的表示表现不佳时，传统度量标准无法提供可操作的洞察。

**Method:** 为了解决上述挑战，本文提出了一种新颖的多模态推荐度量标准——泄漏影响分数（LIS）。LIS不直接评估MLLM，而是高效地衡量偏好数据的上限。此外，作者还分享了在实际场景中部署结合LIS的MLLM的实践经验。

**Result:** 在小红书探索页（包括内容信息流和展示广告）的在线A/B测试中，本文提出的方法展示了其有效性，显著改善了用户停留时间和广告商价值。

**Conclusion:** 本文提出的泄漏影响分数（LIS）有效解决了大规模推荐系统中评估多模态大语言模型对齐的挑战，并在实际应用中带来了用户参与度和广告商价值的显著提升。

> **ai_Abstract:** 多模态推荐系统依赖于多模态大语言模型（MLLM），但评估其对齐性面临挑战，包括静态基准不准确、在线测试成本高昂以及传统指标缺乏可操作性。为应对此，本文提出了一种新颖的度量标准——泄漏影响分数（LIS），它不直接评估MLLM，而是高效地衡量偏好数据的上限。在小红书的在线A/B测试中，LIS展示了其有效性，显著提高了用户停留时间和广告商价值。

> **摘要翻译:** 多模态推荐已成为现代推荐系统中的一项关键技术，它利用先进的多模态大语言模型（MLLM）的内容表示。为确保这些表示得到良好适应，与推荐系统的对齐至关重要。然而，由于三个关键问题，评估用于推荐的MLLM对齐存在显著挑战：(1) 静态基准测试因实际应用的动态性而不准确，(2) 在线系统评估虽然准确，但在大规模部署时成本过高，以及 (3) 当学习到的表示表现不佳时，传统度量标准无法提供可操作的洞察。为了解决这些挑战，我们提出了一种用于多模态推荐的新颖度量标准——泄漏影响分数（LIS）。LIS不直接评估MLLM，而是高效地衡量偏好数据的上限。我们还分享了在实际场景中结合LIS部署MLLM的实践经验。在小红书探索页（包括内容信息流和展示广告）的在线A/B测试中，我们提出的方法展示了其有效性，显著改善了用户停留时间和广告商价值。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [711] [An End-to-End Multi-objective Ensemble Ranking Framework for Video Recommendation](https://arxiv.org/abs/2508.05093)
> *视频推荐的端到端多目标集成排序框架*

*Tiantian He, Minzhi Xie, Runtong Li, Xiaoxiao Xu, Jiaqi Yu, Zixiu Wang, Lantao Hu, Han Li, Kun Gai* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 多目标排序, 视频推荐, 端到端框架, Transformer, 集成排序

**Comment:** 

> **TL;DR:** 本文提出了一种名为EMER的端到端多目标集成排序框架，旨在提升短视频推荐系统的核心组件性能。该框架通过端到端建模、特殊损失函数、新颖的样本组织和Transformer网络来增强个性化和排序效果，并在快手平台实现了显著的业务指标提升，如App停留时间和用户生命周期。

**AI_Comments:** 这篇论文的创新点在于提出了一个端到端的框架来解决多目标集成排序的复杂性，特别是通过设计专门的损失函数来处理用户满意度难以量化的问题，以及利用Transformer网络捕捉候选之间的比较关系。其重要性在于，它不仅在理论上提出了新的方法，而且在像快手这样的超大规模工业平台得到了验证和部署，取得了显著的业务提升，这表明其具有很高的实用价值和工业影响力。它解决了工业界多目标排序中长期存在的挑战，如离线-在线一致性问题。

<details>
  <summary>Details</summary>

**Motivation:** 短视频推荐系统中，多目标集成排序模块是关键组件，但存在个性化不足（依赖手动启发式公式）、有效监督信号难以定义（用户满意度无单一真实信号）、以及离线模型优化效率不高且与在线效果存在不一致性等挑战。

**Method:** 本文提出端到端多目标集成排序框架（EMER），具体方法包括：1. 用端到端建模范式取代手动设计的启发式公式，以增强个性化。2. 引入精心设计的损失函数，解决集成排序中有效监督信号难以定义的挑战。3. 引入新颖的样本组织方法和基于Transformer的网络架构，以捕获候选项目之间的比较关系。4. 提出离线-在线一致的评估系统，提高离线模型优化的效率。

**Result:** 在真实的工业数据集上进行了大量实证测试，结果充分证明了所提出框架的有效性。该框架已部署到拥有数亿日活跃用户的短视频推荐平台快手的主要场景中，实现了整体App停留时间增加1.39%，7天用户生命周期（LT7）增加0.196%，这些都是显著的改进。

**Conclusion:** EMER框架通过其创新的端到端建模、损失函数设计、样本组织和Transformer网络架构，有效解决了短视频推荐中多目标集成排序的挑战，并在实际工业应用中取得了显著的业务提升和积极的用户指标影响。

> **ai_Abstract:** 本文提出了一种名为EMER的端到端多目标集成排序框架，旨在提升短视频推荐系统的核心组件——多目标集成排序模块的性能。EMER通过引入端到端建模范式替代传统启发式公式，设计特殊的损失函数解决监督信号定义难题，以及采用新颖的样本组织和Transformer网络捕获比较关系，从而增强了推荐的个性化和排序效果。此外，该框架还包含一个离线-在线一致的评估系统，以提高模型优化效率。在真实工业数据集上的实验和在快手平台的部署结果显示，EMER显著提升了App停留时间和用户生命周期等关键业务指标。

> **摘要翻译:** 针对多目标集成排序模块，我们提出了一种新颖的端到端多目标集成排序框架（EMER），该模块是短视频推荐系统中最关键的组成部分。EMER通过用端到端建模范式取代手动设计的启发式公式来增强个性化。EMER引入了一个精心设计的损失函数，以解决为集成排序定义有效监督信号的根本挑战，因为没有单一的真实信号可以完全捕捉用户满意度。此外，EMER引入了新颖的样本组织方法和基于Transformer的网络架构，以捕获候选项目之间的比较关系，这对于有效的排序至关重要。此外，我们还提出了一种离线-在线一致的评估系统，以提高离线模型优化的效率，这是行业内多目标排序领域中一个既定但持续存在的挑战。在真实的工业数据集上进行了大量的实证测试，结果充分证明了我们所提出的框架的有效性。此外，我们的框架已部署到拥有数亿日活跃用户的短视频推荐平台快手的主要场景中，实现了整体App停留时间增加1.39%，7天用户生命周期（LT7）增加0.196%，这些都是显著的改进。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [717] [FIRE: Faithful Interpretable Recommendation Explanations](https://arxiv.org/abs/2508.05225)
> *FIRE：忠实可解释的推荐解释*

*S.M.F. Sani, Asal Meskin, Mohammad Amanlou, Hamid R. Rabiee* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 可解释推荐, 自然语言解释, SHAP, 忠实性, 推荐系统

**Comment:** 

> **TL;DR:** 现有推荐系统中的自然语言解释常混淆用户评论与系统推理，导致解释不忠实。本文提出FIRE框架，结合SHAP和提示驱动的语言生成，提供忠实、多样且用户对齐的解释，显著提升解释质量并保持推荐准确性。

**AI_Comments:** 这篇论文的创新点在于明确指出并解决了现有推荐系统解释方法中“评论即解释”范式的局限性，即解释的忠实性问题。通过引入SHAP-based特征归因和结构化、提示驱动的语言生成，FIRE框架能够提供更准确、更可信且与模型决策过程紧密关联的解释。这对于提高推荐系统的透明度和用户信任度具有重要意义。该工作强调了可问责和可解释性在推荐系统中的重要性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统中的自然语言解释通常将解释视为评论生成任务，但这会将用户意见与系统推理混淆，导致解释虽流畅但不忠实于推荐的真实逻辑。这些解释与模型预测对齐性差、对用户意图识别模糊或不准确，且过于重复或通用。

**Method:** 提出FIRE框架，一个轻量级且可解释的框架。它将基于SHAP的特征归因与结构化、提示驱动的语言生成相结合。

**Result:** FIRE生成忠实、多样且与用户对齐的解释，这些解释基于模型实际的决策过程。实验结果表明，FIRE不仅实现了有竞争力的推荐准确性，还在对齐性、结构和忠实性等关键维度上显著提高了解释质量。

**Conclusion:** 本文强调需要超越“评论即解释”的范式，转向既可问责又可解释的解释方法。

> **ai_Abstract:** 本文针对推荐系统中自然语言解释的现有问题，即其常将用户评论与系统推理混淆，导致解释不忠实且存在对齐性差、模糊、重复等局限。为解决此问题，作者提出了名为FIRE的轻量级可解释框架。FIRE结合了SHAP特征归因与提示驱动的语言生成，能够生成忠实、多样且用户对齐的解释，这些解释基于模型实际决策过程。实验证明，FIRE在保持推荐准确性的同时，显著提升了解释质量。研究呼吁转向更具问责性和可解释性的推荐解释方法。

> **摘要翻译:** 推荐系统中的自然语言解释通常被视为评论生成任务，利用用户评论作为真实监督。虽然这很方便，但这种方法将用户意见与系统推理混淆，导致解释可能流畅，但未能反映推荐背后的真实逻辑。在这项工作中，我们重新审视了可解释推荐的核心目标：通过将用户需求与相关项目特征联系起来，透明地传达推荐某个项目的原因。通过对多个基准数据集上现有方法的全面分析，我们发现了常见的局限性——解释与模型预测的对齐性弱、在识别用户意图时模糊或不准确，以及过于重复或通用。为了克服这些挑战，我们提出了FIRE，一个轻量级且可解释的框架，它将基于SHAP的特征归因与结构化、提示驱动的语言生成相结合。FIRE生成忠实、多样且与用户对齐的解释，这些解释根植于模型的实际决策过程。我们的结果表明，FIRE不仅实现了有竞争力的推荐准确性，而且在对齐性、结构和忠实性等关键维度上显著提高了解释质量。这项工作强调了需要超越“评论即解释”的范式，转向既可问责又可解释的解释方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [723] [Difference Views for Visual Graph Query Building](https://arxiv.org/abs/2508.05314)
> *用于可视化图查询构建的差异视图*

*Benedikt Kantz, Stefan Lengauer, Peter Waldert, Tobias Schreck* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 知识图谱, 可视化查询构建, 差异视图, SPARQL, 自然语言接口

**Comment:** 

> **TL;DR:** 该论文介绍了一种可视化图查询构建器，它利用差异视图和自然语言接口来支持知识图谱上的迭代查询构建和探索性搜索。

**AI_Comments:** 该论文的创新之处在于利用“差异视图”来可视化查询和结果的演变，直接解决了探索性搜索的迭代性质。自然语言的集成进一步增强了非专业用户的可用性。这种方法显著改善了在知识图谱上构建复杂查询的用户体验。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可视化查询构建器在处理用户在探索性搜索过程中不断变化和演进的信息需求时存在不足，导致查询构建过程迭代且复杂。

**Method:** 该方法提出一个可视化查询界面，通过使用图差异来对比查询构建过程中迭代步骤之间的变化。它还集成了自然语言接口，允许用户直接在差异查询视图中表达不断演进的信息需求。此外，系统通过对比结果分布和原型图的单个实例的差异，在结果视图中传达结果的变化。

**Result:** 该系统通过在不同本体和使用场景下的案例研究证明了其适用性，表明其能够促进数据探索和领域特定图的分析。

**Conclusion:** 该系统通过可视化查询和结果的变化，并集成自然语言输入，有效支持知识图谱中迭代和探索性的查询构建。

> **ai_Abstract:** 本文介绍了一种可视化查询接口，旨在促进知识图谱上的迭代和探索性查询构建。它通过采用“差异视图”来可视化图查询及其结果在迭代步骤中的变化，从而解决了用户不断演进的信息需求所带来的挑战。此外，该接口还集成了自然语言输入机制。案例研究证明了该系统在增强领域特定知识图谱的数据探索和分析方面的有效性。

> **摘要翻译:** 知识图谱（KGs）包含大量链接资源，编码了各种领域的知识，可以使用专门的语言（如SPARQL，一种为查询KGs开发的查询语言）进行查询和搜索。现有的可视化查询构建器使非专业用户能够构建SPARQL查询并利用这些图中所包含的知识。然而，查询构建是一个迭代的、通常是可视化的过程，用户的提问在整个过程中可能会发生变化和差异，尤其是在探索性搜索中。我们的可视化查询界面使用图差异来对比图查询中的变化和演进，从而在查询构建过程中的迭代步骤之间传达这些变化。我们还通过将自然语言接口直接集成到差异查询视图中，使用户能够表达其不断演进的信息需求。此外，我们通过对比结果分布和原型图的单个实例的差异，在结果视图中传达结果的变化，并通过对不同本体和使用场景的案例研究展示了系统的适用性，说明了我们的系统如何促进领域特定图的数据探索和分析。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [729] [Does Multimodality Improve Recommender Systems as Expected? A Critical Analysis and Future Directions](https://arxiv.org/abs/2508.05377)
> *多模态是否如预期般提升推荐系统？一项批判性分析与未来方向*

*Hongyu Zhou, Yinan Zhang, Aixin Sun, Zhiqi Shen* | **Category: cs.IR, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 多模态推荐, 评估框架, 稀疏交互, 召回阶段, 集成学习

**Comment:** 

> **TL;DR:** 本文批判性分析了多模态推荐系统，提出了一个结构化评估框架，发现多模态数据在稀疏交互和召回阶段特别有益，且模态重要性取决于任务。集成学习优于融合学习，且更大的模型不一定带来更好的结果。

**AI_Comments:** 本文的重要性在于它对当前热门的多模态推荐系统进行了严谨的实证分析，挑战了业界普遍认为多模态和大型模型必然带来性能提升的假设。其提出的结构化评估框架具有创新性，为后续研究提供了可复现的评估标准。研究结果直接指出了多模态数据在特定场景（如稀疏交互、召回阶段）下的有效性，并提供了关于模态选择、集成策略和模型设计的实用建议，对于推动多模态推荐系统的实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态推荐系统因其整合多样数据类型以提升性能的潜力而日益普及，然而，这种整合的实际益处仍不明确，引发了关于何时以及如何真正增强推荐的疑问。

**Method:** 本文提出了一个结构化评估框架，从比较效率、推荐任务、推荐阶段和多模态数据集成四个维度系统评估多模态推荐。研究人员将一组可复现的多模态模型与强大的传统基线进行基准测试，并在不同平台上评估其性能。此外，还探索了不同的集成策略和模型大小，并包含了案例研究和对其他推荐领域发现的综述。

**Result:** 研究发现，多模态数据在稀疏交互场景和推荐管道的召回阶段特别有益。每种模态的重要性是任务特定的，其中文本特征在电子商务中更有用，而视觉特征在短视频推荐中更有效。此外，集成学习（Ensemble-Based Learning）优于融合学习（Fusion-Based Learning），且更大的模型不一定能带来更好的结果。

**Conclusion:** 本研究为构建高效、有效的多模态推荐系统提供了实践性见解，强调了深思熟虑的模态选择、集成策略和模型设计的重要性。

> **ai_Abstract:** 本文对多模态推荐系统进行了批判性分析，旨在澄清其整合多样数据类型的实际效益。研究提出了一套结构化评估框架，并基于此框架，通过对多模态模型与传统基线的基准测试，揭示了多模态数据在稀疏交互和召回阶段的显著优势。研究还发现模态的重要性因任务而异，并指出集成学习优于融合学习，且模型规模并非越大越好。这些发现为未来构建高效实用的多模态推荐系统提供了宝贵的指导。

> **摘要翻译:** 多模态推荐系统因其整合多样数据类型以提升性能的潜力而日益普及。然而，这种整合的实际益处仍不明确，引发了关于何时以及如何真正增强推荐的疑问。在本文中，我们提出了一个结构化评估框架，以系统地评估多模态推荐在四个维度上的表现：比较效率、推荐任务、推荐阶段和多模态数据集成。我们针对一组可复现的多模态模型与强大的传统基线进行了基准测试，并在不同平台上评估了它们的性能。我们的发现表明，多模态数据在稀疏交互场景和推荐管道的召回阶段特别有益。我们还观察到，每种模态的重要性是任务特定的，其中文本特征在电子商务中更有用，而视觉特征在短视频推荐中更有效。此外，我们探索了不同的集成策略和模型大小，发现集成学习优于融合学习，且更大的模型不一定能带来更好的结果。为了加深理解，我们还包括了案例研究并回顾了其他推荐领域的发现。我们的工作为构建高效、有效的多模态推荐系统提供了实践性见解，强调了深思熟虑的模态选择、集成策略和模型设计的重要性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [735] [On the Reliability of Sampling Strategies in Offline Recommender Evaluation](https://arxiv.org/abs/2508.05398)
> *离线推荐系统评估中采样策略的可靠性研究*

*Bruno L. Pereira, Alan Said, Rodrygo L. T. Santos* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 离线评估, 推荐系统, 采样偏差, 曝光偏差, 可靠性

**Comment:** 

> **TL;DR:** 本文研究了离线推荐系统评估中不同日志和采样策略组合如何影响评估的可靠性，并提供了选择可靠策略的实用指导。

**AI_Comments:** 这篇论文对于理解和改进离线推荐系统评估具有重要意义。它系统地分析了采样和曝光偏差对评估可靠性的影响，并提供了基于实证的实用指导，这对于推荐系统研究者和工程师在进行离线评估时选择合适的策略非常有价值。其创新点在于使用完全观测数据集模拟真实情况并多维度评估采样策略，解决了现有研究的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 离线评估在推荐系统基准测试中扮演核心角色，但容易受到曝光偏差和采样偏差的影响。现有方法通常在固定数据集上评估，而非其在不同曝光条件下或相对于真实用户偏好下支持可靠模型比较的能力。因此，本文旨在探究不同的日志和采样选择如何影响离线评估的可靠性。

**Method:** 使用一个完全观测的数据集作为真实值，系统地模拟了多种曝光偏差，并从采样分辨率（推荐模型可分离性）、保真度（与完整评估的一致性）、鲁棒性（在曝光偏差下的稳定性）和预测能力（与真实值的一致性）四个维度评估了常见采样策略的可靠性。

**Result:** 研究结果强调了采样何时以及如何扭曲评估结果，并为选择能够产生忠实和鲁棒离线比较的策略提供了实用指导。

**Conclusion:** 研究表明，采样策略的选择对离线推荐系统评估的可靠性有显著影响，并提供了选择可靠策略的实用指导，以确保离线评估结果的准确性和稳定性。

> **ai_Abstract:** 本文探讨了离线推荐系统评估中日志记录和采样策略对评估可靠性的影响。研究指出，离线评估存在曝光偏差和采样偏差，而现有方法未能充分评估其在不同曝光条件下的可靠性。作者使用一个完整数据集模拟曝光偏差，并从采样分辨率、保真度、鲁棒性和预测能力四个方面评估了常见采样策略。研究结果揭示了采样如何扭曲评估，并提供了选择有效策略的实用建议，以实现忠实且鲁棒的离线评估。

> **摘要翻译:** 离线评估在推荐系统基准测试中扮演着核心角色，尤其是在在线测试不切实际或存在风险时。然而，它容易受到两个关键偏差源的影响：曝光偏差，即用户只与他们被展示的物品进行互动；以及采样偏差，即评估是在日志记录的物品子集而非完整目录上执行时引入的。尽管先前的研究提出了缓解采样偏差的方法，但这些方法通常是在固定的日志数据集上进行评估，而不是评估它们在不同曝光条件下或相对于真实用户偏好下支持可靠模型比较的能力。在本文中，我们研究了日志记录和采样选择的不同组合如何影响离线评估的可靠性。我们使用一个完全观测的数据集作为真实值，系统地模拟了多种曝光偏差，并从四个维度评估了常见采样策略的可靠性：采样分辨率（推荐模型可分离性）、保真度（与完整评估的一致性）、鲁棒性（在曝光偏差下的稳定性）和预测能力（与真实值的一致性）。我们的研究结果强调了采样何时以及如何扭曲评估结果，并为选择能够产生忠实和鲁棒离线比较的策略提供了实用指导。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [741] [RankArena: A Unified Platform for Evaluating Retrieval, Reranking and RAG with Human and LLM Feedback](https://arxiv.org/abs/2508.05512)
> *RankArena：一个用于评估检索、重排序和RAG的统一平台，支持人类和LLM反馈*

*Abdelrahman Abdallah, Mahmoud Abdalla, Bhawna Piryani, Jamshid Mozafari, Mohammed Ali, Adam Jatowt* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 检索增强生成, 重排序, 评估平台, LLM反馈, 人类反馈

**Comment:** 

> **TL;DR:** RankArena是一个统一平台，通过结构化的人类和LLM反馈，评估检索、重排序和RAG系统的性能，并收集评估数据。

**AI_Comments:** RankArena的创新之处在于其统一的平台设计，能够同时评估检索、重排序和RAG，并且结合了人类和LLM反馈，提供了多视角的评估能力。其生成结构化数据集的能力对于训练未来AI模型具有重要价值。这是一个实用且全面的工具，有望推动相关领域的研究和开发。

<details>
  <summary>Details</summary>

**Motivation:** 评估检索增强生成（RAG）和文档重排序系统面临挑战，原因在于缺乏可扩展、以用户为中心和多视角的评估工具。

**Method:** RankArena是一个统一平台，用于比较和分析检索管道、重排序器和RAG系统的性能。它支持多种评估模式，包括直接重排序可视化、盲配对比较（人类或LLM投票）、有监督的手动文档标注和端到端RAG答案质量评估。它通过配对偏好和完整列表标注捕获细粒度相关性反馈，并整合了LLM作为评判者的评估。

**Result:** 平台的所有交互都存储为结构化评估数据集，可用于训练重排序器、奖励模型、判断代理或检索策略选择器。

**Conclusion:** RankArena提供了一个统一、多视角的评估解决方案，有效解决了RAG和重排序系统评估的挑战，并能生成有价值的训练数据。

> **ai_Abstract:** RankArena是一个统一的评估平台，旨在解决RAG和文档重排序系统评估中缺乏可扩展、用户中心和多视角工具的挑战。它通过整合人类和LLM反馈，支持多种评估模式，包括可视化、配对比较和RAG质量评估，并捕获细粒度反馈。该平台生成的结构化数据集可用于训练各种下游模型，提供了一个全面的评估和数据收集解决方案。

> **摘要翻译:** 评估检索增强生成（RAG）和文档重排序系统的质量仍然具有挑战性，原因在于缺乏可扩展、以用户为中心和多视角的评估工具。我们引入了RankArena，这是一个统一平台，用于使用结构化的人类和基于LLM的反馈来比较和分析检索管道、重排序器和RAG系统的性能，并收集此类反馈。RankArena支持多种评估模式：直接重排序可视化、人类或LLM投票的盲配对比较、有监督的手动文档标注以及端到端RAG答案质量评估。它通过配对偏好和完整列表标注捕获细粒度相关性反馈，以及辅助元数据，如移动指标、标注时间和质量评级。该平台还集成了LLM作为评判者的评估，从而能够比较模型生成的排名和人类真实标注。所有交互都存储为结构化评估数据集，可用于训练重排序器、奖励模型、判断代理或检索策略选择器。我们的平台可在 https://rankarena.ngrok.io/ 公开访问，并提供了演示视频 https://youtu.be/jIYAP4PaSSI。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [747] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
> *NAEx：一个用于解释网络对齐的即插即用框架*

*Shruti Saxena, Arijit Khan, Joydeep Chandra* | **Category: cs.IR, cs.LG, cs.SI** | **Updated: 2025-08-05**

**Keywords:** 网络对齐, 可解释性, 模型无关, 子图, 特征

**Comment:** 

> **TL;DR:** NAEx是一个即插即用的模型无关框架，通过识别关键子图和特征来解释网络对齐模型，解决了现有模型可解释性差的问题，并确保解释的忠实性。

**AI_Comments:** NAEx的创新之处在于其“即插即用”和“模型无关”的特性，使其能够广泛应用于各种现有的网络对齐模型。它通过引入可学习的边和特征掩码来解决保留跨网络联合依赖的关键挑战，并设计了一个创新的优化目标，确保解释的忠实性和可比较性。这对于提高高风险领域中网络对齐决策的信任度和透明度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管网络对齐模型取得了进展，但它们的可解释性仍然有限，使得理解对齐决策变得困难，尤其是在高风险领域，这阻碍了信任的建立。因此，需要一个框架来解释对齐决策。

**Method:** NAEx是一个即插即用的、模型无关的框架，通过识别影响预测的关键子图和特征来解释对齐模型。它通过以下方式解决保留跨网络联合依赖的关键挑战：1) 通过可学习的边和特征掩码联合参数化图结构和特征空间；2) 引入一个优化目标，确保解释忠实于原始预测，并能有意义地比较网络间的结构和基于特征的相似性。NAEx是一个归纳框架，可以高效地为以前未见过的数据生成网络对齐解释。

**Result:** 我们引入了针对对齐可解释性量身定制的评估指标，并通过将其与四种代表性网络对齐模型集成，在基准数据集上证明了NAEx的有效性和效率。

**Conclusion:** NAEx框架提供了一种解释网络对齐模型决策的方法，通过提高可解释性来帮助理解对齐过程并建立信任，尤其是在关键应用中。

> **ai_Abstract:** 本文介绍了NAEx，一个即插即用的模型无关框架，旨在提高网络对齐（NA）模型的可解释性。面对现有NA模型难以理解其决策的问题，NAEx通过识别关键子图和特征来解释预测。它通过联合参数化图结构和特征空间（使用可学习的掩码）以及引入一个确保解释忠实性和可比较性的优化目标来解决跨网络依赖问题。NAEx是一个归纳框架，能够高效地为新数据生成解释。研究通过整合NAEx与四种代表性NA模型并在基准数据集上进行评估，证明了其有效性和效率。

> **摘要翻译:** 网络对齐（NA）识别多个网络中的对应节点，应用于社交网络、合著和生物学等领域。尽管对齐模型取得了进展，但它们的可解释性仍然有限，使得理解对齐决策变得困难，并在建立信任方面构成挑战，尤其是在高风险领域。为了解决这个问题，我们引入了NAEx，一个即插即用的、模型无关的框架，通过识别影响预测的关键子图和特征来解释对齐模型。NAEx通过以下方式解决了保留对齐决策中联合跨网络依赖的关键挑战：(1) 通过可学习的边和特征掩码联合参数化图结构和特征空间，以及 (2) 引入一个优化目标，确保解释忠实于原始预测，并能有意义地比较网络间的结构和基于特征的相似性。NAEx是一个归纳框架，可以高效地为以前未见过的数据生成NA解释。我们引入了针对对齐可解释性量身定制的评估指标，并通过将其与四种代表性NA模型集成，在基准数据集上证明了NAEx的有效性和效率。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [752] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
> *联邦持续推荐*

*Jaehyung Lim, Wonbin Kweon, Woojoo Kim, Junyoung Kim, Seongjin Choi, Dongha Kim, Hwanjo Yu* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 联邦学习, 持续学习, 推荐系统, 隐私保护, 数据流

**Comment:** 

> **TL;DR:** 本文提出了联邦持续推荐（FCRec）任务，旨在解决联邦推荐（FedRec）在非平稳数据流下的性能问题以及持续学习推荐（CLRec）与联邦学习（FL）隐私约束的冲突。作为解决方案，提出了F3CRec框架，通过客户端自适应回放记忆和服务器端项目级时间平均，在保护隐私的同时有效适应数据流变化，并在实验中表现出优越性。

**AI_Comments:** 这篇论文解决了联邦学习和持续学习在推荐系统中的一个重要交叉问题，即如何在保护用户隐私的同时，使推荐系统能够适应不断变化的用户偏好和数据流。F3CRec框架提出的客户端-服务器协作机制，特别是自适应回放记忆和项目级时间平均，是其创新点，为解决联邦持续学习的挑战提供了实用的解决方案。这对于构建更鲁棒、隐私友好的动态推荐系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦推荐（FedRec）方法在处理非平稳数据流时难以保持推荐质量，而持续学习推荐（CLRec）方法虽然能处理用户偏好演变，但通常需要中心化数据访问，与联邦学习（FL）的隐私保护约束不兼容。为了弥合这一差距，本研究提出了联邦持续推荐（FCRec）这一新任务，旨在使模型在保护隐私的同时从流式数据中学习。

**Method:** 本文提出了F3CRec框架来解决FCRec任务，该框架旨在平衡知识保留和适应性。F3CRec包含两个关键组件：客户端的自适应回放记忆（根据用户特定变化选择性地保留过去的偏好）和服务器端的项目级时间平均（整合新知识同时保留先前信息）。

**Result:** 大量实验表明，F3CRec在联邦环境中随时间推移保持推荐质量方面优于现有方法。

**Conclusion:** F3CRec成功地解决了在联邦环境中从流式数据中学习并同时保护隐私的挑战，有效保持了推荐系统的长期性能。

> **ai_Abstract:** 本文针对联邦推荐（FedRec）在非平稳数据流中性能下降以及持续学习推荐（CLRec）与联邦学习（FL）隐私约束不兼容的问题，提出了联邦持续推荐（FCRec）这一新任务。为解决FCRec任务，作者提出了F3CRec框架，该框架通过客户端的自适应回放记忆和服务器端的项目级时间平均，有效平衡知识保留与适应性。实验结果表明，F3CRec在联邦环境中能够持续保持推荐质量，优于现有方法。

> **摘要翻译:** 推荐系统中对隐私日益增长的重视促使联邦学习（FL）被采纳为一种隐私保护解决方案，它能够在不共享用户数据的情况下进行协作训练。虽然联邦推荐（FedRec）有效保护了隐私，但现有方法难以处理非平稳数据流，无法随时间保持一致的推荐质量。另一方面，持续学习推荐（CLRec）方法解决了用户偏好演变的问题，但通常假设中心化数据访问，这使得它们与FL的约束不兼容。为了弥合这一差距，我们引入了联邦持续推荐（FCRec），这是一项整合了FedRec和CLRec的新任务，要求模型在保护隐私的同时从流式数据中学习。作为解决方案，我们提出了F3CRec，一个旨在FCRec严格约束下平衡知识保留和适应性的框架。F3CRec引入了两个关键组件：客户端的自适应回放记忆，它根据用户特定变化选择性地保留过去的偏好；以及服务器端的项目级时间平均，它在保留先前信息的同时整合新知识。大量实验表明，F3CRec在联邦环境中随时间推移保持推荐质量方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [757] [Community-Aware Social Community Recommendation](https://arxiv.org/abs/2508.05107)
> *社区感知社交社区推荐*

*Runhao Jiang, Renchi Yang, Wenqing Lin* | **Category: cs.IR, cs.SI** | **Updated: 2025-08-07**

**Keywords:** 社交社区推荐, 社区感知, 社交网络分析, 协同过滤, 用户嵌入

**Comment:** 

> **TL;DR:** 提出CASO模型，通过整合社交网络结构和用户偏好，解决现有社交推荐模型在社区推荐中的不足。

**AI_Comments:** CASO的创新之处在于其专门为社区推荐设计，而非简单地将现有方法应用于社区。它通过结合社交网络的结构特征（全局和局部）、用户偏好以及独特的社区检测损失，全面捕捉了社区的复杂性。引入社交与协同信号的互斥性，有助于消除冗余信息，提高模型的效率和准确性。这项工作对于提升社交网络中社区发现和推荐的质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有社交推荐模型主要设计用于推荐常规项目，但由于忽视了社区的独特特征（如个体构成、高动态性、丰富结构模式），在社区推荐方面表现不佳。当前研究在全面利用这些信息进行社区推荐方面有限。

**Method:** 本文提出了CASO模型，专门用于社交社区推荐。CASO包含三个用户嵌入编码器：其中两个通过社交模块化最大化和社交亲近度聚合从社交网络中提取社区相关的全局和局部结构；第三个通过协同过滤捕获用户偏好与用户-社区关联。为消除特征冗余，引入社交信号和协同信号之间的互斥。模型优化中还包含社区检测损失，以生成社区感知嵌入。

**Result:** 在六个真实社交网络上，CASO模型与九个强基线模型进行了广泛实验，结果表明其在社区推荐性能方面始终显著优于现有技术。

**Conclusion:** CASO模型通过有效整合社交网络结构和用户偏好，并引入社区感知机制，显著提升了社交社区推荐的性能。

> **ai_Abstract:** 本文提出CASO模型，旨在解决现有社交推荐方法在社区推荐中表现不佳的问题。CASO通过整合社交网络中的全局和局部结构信息以及用户的协同过滤偏好来生成用户嵌入，并通过引入社交与协同信号的互斥以及社区检测损失来优化模型，从而生成社区感知的社区嵌入。实验证明CASO在社区推荐任务上显著优于现有基线模型。

> **摘要翻译:** 社交推荐旨在利用用户之间的社交关系来缓解用户-项目交互的稀疏性问题，已成为提升推荐系统中个性化服务的流行技术。尽管有效，现有的社交推荐模型主要设计用于推荐常规项目，如博客、图片和产品，但由于忽视了社区的独特特征，在社区推荐方面大多失效。具体来说，社区由个体构成，这些个体表现出高度动态性并与社交网络中丰富的结构模式相关。据我们所知，很少有研究致力于全面利用这些信息来推荐社区。
为了弥补这一空白，本文提出了CASO，一种专门为社交社区推荐设计的新颖且有效的模型。CASO利用三个精心设计的编码器进行用户嵌入，其中两个通过社交模块化最大化和社交亲近度聚合从社交网络中提取社区相关的全局和局部结构，而第三个则利用观察到的用户-社区关联通过协同过滤捕获用户偏好。为了进一步消除其中的特征冗余，我们引入了社交信号和协同信号之间的互斥。最后，CASO在模型优化中包含了社区检测损失，从而为社区生成了社区感知嵌入。我们对CASO与六个真实社交网络上的九个强基线模型进行了广泛实验，结果表明其在社区推荐性能方面始终显著优于现有技术。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [762] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
> *在线广告中多阶段一致性的出价感知检索*

*Bin Liu, Yunfei Liu, Ziru Xu, Zhaoyu Zhou, Zhi Kou, Yeqiu Yang, Han Zhu, Jian Xu, Bo Zheng* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 在线广告, 出价感知检索, 多阶段一致性, eCPM, 自动出价

**Comment:** 

> **TL;DR:** 本文提出了一种出价感知检索（BAR）框架，通过在检索阶段整合广告出价信息，解决了在线广告系统中检索与排序阶段之间的不一致性问题，显著提升了平台收入和广告效果。

**AI_Comments:** 本文提出了一种创新的出价感知检索（BAR）框架，解决了在线广告多阶段系统中长期存在且日益严重的出价信息不一致问题。其创新点在于将出价信号通过单调性约束学习和多任务蒸馏融入检索阶段，并通过异步近线推理确保实时性，以及任务感知细化模块区分用户兴趣和商业价值。该方法在实际大规模广告平台上的显著效果提升（收入和曝光量）证明了其重要性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在线广告系统中的检索阶段无法访问实时精确的出价信息，导致其与基于eCPM（预测CTR × 出价）分配流量的排序阶段之间存在不一致性。这种差异导致平台收入和广告主效果不佳。

**Method:** 本文提出了一种模型驱动的出价感知检索（BAR）框架，通过将广告出价价值纳入检索评分函数来解决多阶段不一致性。其核心创新包括：1）出价感知建模，通过单调性约束学习和多任务蒸馏整合出价信号，以确保经济上一致的表示；2）异步近线推理，实现嵌入的实时更新以响应市场变化；3）任务感知细化模块，选择性地增强特征交互，以区分用户兴趣和商业价值信号。

**Result:** 在阿里巴巴展示广告平台进行的大规模离线实验和全面部署验证了BAR的有效性：平台收入增长4.32%，正面运营广告的曝光量提升22.2%。

**Conclusion:** 出价感知检索（BAR）框架通过在在线广告的检索阶段整合出价信息，有效解决了多阶段不一致性问题，显著提升了平台收入和广告主效果。

> **ai_Abstract:** 本文针对在线广告系统中检索阶段与排序阶段之间因出价信息不对称导致的不一致性问题，提出了一种名为出价感知检索（BAR）的新型框架。BAR通过将广告出价价值整合到检索评分函数中来解决这一问题。该框架的核心技术包括出价感知建模（利用单调性约束学习和多任务蒸馏处理出价信号）、异步近线推理（实现实时嵌入更新）以及任务感知细化模块（区分用户兴趣和商业价值）。在阿里巴巴平台的实验结果表明，BAR显著提升了平台收入（4.32%）和广告曝光量（22.2%）。

> **摘要翻译:** 在线广告系统通常采用级联架构来管理海量请求和候选广告，其中排序阶段根据eCPM（预测点击率 × 出价）分配流量。随着自动出价策略的日益普及，计算敏感的检索阶段与排序阶段之间的不一致性变得更加突出，因为前者无法访问海量广告语料库的精确实时出价。这种差异导致平台收入和广告主效果不佳。为了解决这个问题，我们提出了出价感知检索（BAR），一个模型驱动的检索框架，通过将广告出价价值纳入检索评分函数来解决多阶段不一致性。其核心创新是出价感知建模，通过单调性约束学习和多任务蒸馏整合出价信号，以确保经济上一致的表示，而异步近线推理则实现了嵌入的实时更新以响应市场变化。此外，任务感知细化模块选择性地增强特征交互，以区分用户兴趣和商业价值信号。大规模离线实验和在阿里巴巴展示广告平台的全面部署验证了BAR的有效性：平台收入增长4.32%，正面运营广告的曝光量提升22.2%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [767] [PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for Industry-Scale Recommendation Systems](https://arxiv.org/abs/2504.10507)
> *PinRec：面向工业级推荐系统的结果条件多令牌生成式检索*

*Anirudhan Badrinath, Prabhat Agarwal, Laksh Bhasin, Jaewon Yang, Jiajing Xu, Charles Rosenberg* | **Category: cs.IR, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 生成式检索, 推荐系统, 工业规模, 多令牌生成, 结果条件

**Comment:** 

> **TL;DR:** PinRec 是一种新的生成式检索模型，专为 Pinterest 的工业级推荐系统设计，通过结果条件生成和多令牌生成来平衡性能、多样性和效率，解决了现有生成式检索方法在可伸缩性和灵活性方面的不足。

**AI_Comments:** PinRec 的创新之处在于将“结果条件生成”和“多令牌生成”引入工业级推荐系统，以解决现有生成式检索模型在规模化和多目标优化上的不足。其在 Pinterest 这种大规模平台上的首次严格研究，证明了生成式检索在实际应用中的巨大潜力，为该领域树立了新的里程碑。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成式检索方法在学术基准测试中表现良好，但缺乏工业级推荐系统所需的可伸缩性，并且在满足现代系统的多指标要求方面灵活性不足。

**Method:** 本文引入了 PinRec，这是一种新颖的生成式检索模型，它利用结果条件生成，允许建模者平衡各种结果指标（如保存和点击数量），以有效地与业务目标和用户探索保持一致。此外，PinRec 还结合了多令牌生成，以增强输出多样性，同时优化生成过程。

**Result:** 实验表明，PinRec 能够成功地平衡性能、多样性和效率，为使用生成模型的用户带来了显著的积极影响。

**Conclusion:** PinRec 是生成式检索领域的一个重要里程碑，据我们所知，它首次对在 Pinterest 规模上实现生成式检索进行了严格研究。

> **ai_Abstract:** PinRec 是一种专为 Pinterest 工业级推荐系统设计的新型生成式检索模型，旨在克服现有生成式检索方法在可伸缩性和多指标灵活性方面的不足。通过引入结果条件生成，PinRec 允许根据业务目标平衡不同的用户行为指标（如保存和点击），并利用多令牌生成来提升推荐多样性。实验证明，PinRec 在性能、多样性和效率之间取得了良好平衡，为大规模生成式检索的应用提供了有效解决方案。

> **摘要翻译:** 生成式检索方法利用生成式序列建模技术（例如 Transformer）为推荐系统生成候选项目。这些方法在学术基准测试中表现出令人鼓舞的结果，超越了双塔架构等传统检索模型。然而，当前的生成式检索方法缺乏工业级推荐系统所需的可伸缩性，并且在满足现代系统的多指标要求方面不够灵活。本文介绍了 PinRec，这是一种为 Pinterest 应用程序开发的新型生成式检索模型。PinRec 利用结果条件生成，使建模者能够指定如何平衡各种结果指标，例如保存和点击的数量，以有效地与业务目标和用户探索保持一致。此外，PinRec 结合了多令牌生成，以增强输出多样性，同时优化生成。我们的实验表明，PinRec 能够成功地平衡性能、多样性和效率，为使用生成模型的用户带来了显著的积极影响。本文标志着生成式检索领域的一个重要里程碑，据我们所知，它首次对在 Pinterest 规模上实现生成式检索进行了严格研究。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [772] [CB-cPIR: Code-Based Computational Private Information Retrieval](https://arxiv.org/abs/2505.03407)
> *CB-cPIR：基于代码的计算型隐私信息检索*

*Camilla Hollanti, Neehar Verma* | **Category: cs.IR, cs.IT** | **Updated: 2025-08-07**

**Keywords:** 隐私信息检索, 码基密码学, 计算型PIR, 安全性, 漏洞修复

**Comment:** 

> **TL;DR:** 提出了一种名为CB-cPIR的基于代码的计算型隐私信息检索（cPIR）方案，该方案解决了现有基于代码的cPIR方案中的漏洞，并在最坏情况（完全串通）下提供安全性。

**AI_Comments:** 这篇论文通过提出CB-cPIR方案，解决了现有基于代码的cPIR方案中的关键安全漏洞，特别是在面对存储服务器完全串通的最坏情况假设下，这具有重要的实际意义。其创新之处在于利用码基密码学的困难问题来保护查询，并成功修复了前人工作中的缺陷，提升了该领域方案的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私信息检索（PIR）方案在分布式数据存储系统中，依赖于对存储服务器串通能力的假设。如果这些假设不正确，隐私就会丢失。本文关注最坏情况，即完全串通，或将存储系统视为单个诚实但好奇的服务器，旨在提供在这种情况下仍能保护隐私的PIR方案。

**Method:** 本文提出了CB-cPIR，一种单服务器的基于代码的计算型隐私信息检索（cPIR）方案。其安全性源于基于代码的密码学，特别是解码随机线性码的难度。该方案受到Holzbaur等人先前方案的启发，并修复了原方案中因用户查询子矩阵中高度可能的秩差异而产生的漏洞，以及近期发现的另一个漏洞。

**Result:** 提出了CB-cPIR方案，成功修复了Holzbaur等人提出的原始基于代码的cPIR方案中存在的漏洞（包括秩差异问题和Lage, Bartz发现的新漏洞）。此外，还与最先进的基于格的cPIR方案进行了比较以验证其方案。

**Conclusion:** CB-cPIR是一个在完全串通假设下，通过修复现有基于代码的cPIR方案的已知漏洞，提供更高安全性的计算型隐私信息检索方案。

> **ai_Abstract:** 本文提出了一种名为CB-cPIR的单服务器基于代码的计算型隐私信息检索（cPIR）方案，旨在解决分布式存储系统中在最坏情况（完全串通）下隐私可能丢失的问题。该方案的安全性基于解码随机线性码的难度，并成功修复了先前基于代码的cPIR方案中已知的漏洞，包括由秩差异引起的问题以及近期发现的新漏洞。文章还将其与基于格的cPIR方案进行了比较。

> **摘要翻译:** 隐私信息检索（PIR）方案是一种允许用户从数据库中检索文件，而无需向好奇的数据库透露所需文件身份的协议。对于分布式数据存储系统，通过对持有数据库的存储服务器的串通能力做出假设，可以实现高效的PIR。如果这些假设被证明不正确，隐私就会丢失。在这项工作中，我们关注最坏情况的假设：完全串通，或者等效地，将存储系统虚拟地视为一个单一的诚实但好奇的服务器。我们提出了CB-cPIR，一个单服务器的基于代码的计算型隐私信息检索（cPIR）方案，其安全性源于基于代码的密码学。具体来说，查询通过解码随机线性码的难度来保护。该方案受到Holzbaur、Hollanti和Wachter-Zeh在[Holzbaur et al., "Computational Code-Based Single-Server Private Information Retrieval", 2020 IEEE ISIT]中提出的开创性基于代码的cPIR方案的启发，并修复了原方案中因用户查询子矩阵中高度可能的秩差异而产生的漏洞。最近，在[Lage, Bartz, "On the Security of a Code-Based PIR Scheme"]中观察到一个新的漏洞，现在对方案进行了一个简单的修改即可修复此漏洞。为了进一步验证我们的方案，我们将其与最先进的基于格的cPIR方案进行了比较。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [777] [From Generation to Consumption: Personalized List Value Estimation for Re-ranking](https://arxiv.org/abs/2508.02242)
> *从生成到消费：个性化列表价值估计用于重排序*

*Kaike Zhang, Xiaobei Wang, Xiaoyu Yang, Shuchang Liu, Hailan Yang, Xiang Li, Fei Sun, Qi Cao* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 重排序, 列表价值估计, 用户退出行为, 推荐系统, CAVE

**Comment:** 

> **TL;DR:** 现有重排序方法忽略用户提前退出导致价值估计不准确；本文提出CAVE框架，通过建模用户退出概率来更准确地估计实际列表消费价值，并在多个数据集上表现优异。

**AI_Comments:** 这篇论文的创新点在于它首次明确地将用户在推荐列表中的“提前退出”行为纳入到列表价值估计模型中，从而弥补了传统生成-评估范式中估计价值与实际消费价值之间的差距。通过引入个性化的消费感知列表价值估计（CAVE）框架，并结合了用户退出概率的精细化建模（兴趣驱动和随机组件），使得列表重排序能更真实地反映用户体验和平台收益。此外，提供了大规模真实世界数据集也对后续研究有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有推荐系统中的重排序方法在评估推荐列表价值时，通常忽略用户可能在消费完整个列表前退出，导致估计的生成价值与实际消费价值之间存在不匹配。

**Method:** 提出了CAVE（Consumption-Aware list Value Estimation）框架。CAVE将列表价值公式化为子列表价值的期望，并根据用户在每个位置的退出概率进行加权。退出概率被分解为兴趣驱动组件和随机组件，其中随机组件通过威布尔分布建模以捕获疲劳等外部因素。通过联合建模子列表价值和用户退出行为，CAVE能更忠实地估计实际列表消费价值。

**Result:** 在三个来自快手平台的大规模真实列表级基准数据集、两个亚马逊数据集以及快手的在线A/B测试中，CAVE持续优于强大的基线模型。

**Conclusion:** 显式地建模用户退出行为对于重排序任务具有显著益处，CAVE能够提供更准确的列表消费价值估计。

> **ai_Abstract:** 本文提出了CAVE框架，旨在解决推荐系统重排序中现有方法忽略用户在完全消费列表前退出的问题。CAVE通过建模用户在每个位置的退出概率（分解为兴趣驱动和随机成分），并将列表价值视为子列表价值的期望，从而更准确地估计实际列表消费价值。在多个真实世界数据集和在线A/B测试上的实验表明，CAVE显著优于现有基线，证明了显式建模用户退出行为在重排序中的重要性。

> **摘要翻译:** 重排序在推荐系统中至关重要，它能优化推荐列表的顺序，从而提高用户满意度和平台收入。大多数现有方法遵循生成器-评估器范式，其中评估器估计每个候选列表的整体价值。然而，它们通常忽略用户可能在消费完整个列表之前退出，这导致估计的生成价值与实际消费价值之间存在不匹配。为了弥补这一差距，我们提出了CAVE，一个个性化的消费感知列表价值估计框架。CAVE将列表价值公式化为子列表价值的期望，并根据用户在每个位置的特定用户退出概率进行加权。退出概率被分解为兴趣驱动组件和随机组件，后者通过威布尔分布建模，以捕获疲劳等随机外部因素。通过联合建模子列表价值和用户退出行为，CAVE能够对实际列表消费价值进行更忠实的估计。我们进一步贡献了三个来自快手平台的大规模真实世界列表级基准数据集，它们在大小和用户活动模式上各不相同。在这些基准、两个亚马逊数据集以及快手在线A/B测试中进行的大量实验表明，CAVE持续优于强大的基线，突出了在重排序中明确建模用户退出的益处。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [782] [KBest: Efficient Vector Search on Kunpeng CPU](https://arxiv.org/abs/2508.03016)
> *KBest：鲲鹏CPU上的高效向量搜索*

*Kaihao Ma, Meiling Wang, Senkevich Oleg, Zijian Li, Daihao Xue, Dmitriy Malyshev, Yangming Lv, Shihai Xiao, Xiao Yan, Radionov Alexander, Weidi Zeng, Yuanzhan Gao, Zhiyu Zou, Xin Yao, Lin Liu, Junhao Wu, Yiding Liu, Yaoyao Fu, Gongyi Wang, Gong Zhang, Fei Yi, Yingfan Liu* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 向量搜索, 鲲鹏CPU, ARM架构, 性能优化, KBest

**Comment:** 

> **TL;DR:** KBest是一个针对鲲鹏CPU优化的向量搜索库，通过多种软硬件优化实现了比x86 SOTA库更优的性能。

**AI_Comments:** KBest的创新之处在于其专门针对ARM架构的鲲鹏CPU进行深度优化，填补了该领域在ARM平台上的高效向量搜索库的空白。其结合软硬件优化的方法对于充分发挥特定硬件平台的潜力具有重要意义。该工作证明了针对特定CPU架构进行定制化优化可以带来显著的性能提升，对于推动ARM服务器生态系统的发展具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 向量搜索是许多重要应用的基础，需要高效以降低资源消耗。现有向量搜索库主要针对x86 CPU优化，而华为鲲鹏CPU基于ARM架构，具有竞争力，但缺乏为其定制的优化库。

**Method:** KBest针对最新的鲲鹏920 CPU进行了定制，并结合了广泛的硬件感知和算法优化，包括单指令多数据（SIMD）加速距离计算、数据预取、索引优化、早期终止和向量量化。

**Result:** KBest在鲲鹏CPU上的性能优于在x86 CPU上运行的SOTA向量搜索库，并且其优化可以将查询吞吐量提高2倍以上。目前，KBest每天为内部业务和外部企业客户的数千万次查询提供服务。

**Conclusion:** KBest为鲲鹏CPU提供了一个高效的向量搜索解决方案，通过定制化和多重优化显著提升了性能，并已在实际应用中得到验证。

> **ai_Abstract:** 本文介绍了KBest，一个专为华为鲲鹏920 CPU设计的高效向量搜索库。鉴于现有库主要针对x86架构优化，KBest通过结合SIMD加速、数据预取、索引优化、早期终止和向量量化等硬件感知和算法优化，显著提升了在ARM架构上的向量搜索性能。实验证明，KBest的性能超越了x86平台上的现有SOTA库，查询吞吐量提升超过2倍，并已成功应用于实际业务。

> **摘要翻译:** 向量搜索从大型向量数据集中返回与给定查询向量最相似的向量，是搜索、推荐和大型语言模型等许多重要应用的基础。为了经济高效，向量搜索需要高效以减少给定查询工作负载所需的资源。然而，现有的向量搜索库（例如Faiss和DiskANN）是针对x86 CPU架构（即英特尔和AMD CPU）优化的，而华为鲲鹏CPU基于ARM架构并在计算能力上具有竞争力。在本文中，我们提出了KBest作为专为最新鲲鹏920 CPU定制的向量搜索库。为了高效，KBest融合了广泛的硬件感知和算法优化，包括单指令多数据（SIMD）加速距离计算、数据预取、索引优化、早期终止和向量量化。实验结果表明，KBest在鲲鹏CPU上的性能优于在x86 CPU上运行的SOTA向量搜索库，并且我们的优化可以将查询吞吐量提高2倍以上。目前，KBest每天为我们内部业务和外部企业客户的数千万次查询提供服务。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [787] [SSEmb: A Joint Structural and Semantic Embedding Framework for Mathematical Formula Retrieval](https://arxiv.org/abs/2508.04162)
> *SSEmb：一种用于数学公式检索的联合结构与语义嵌入框架*

*Ruyin Li, Xiaoyu Chen* | **Category: cs.IR** | **Updated: 2025-08-07**

**Keywords:** 数学公式检索, 嵌入框架, 图对比学习, 语义嵌入, 数据增强

**Comment:** 

> **TL;DR:** SSEmb是一个新的嵌入框架，通过结合图对比学习捕捉结构特征和Sentence-BERT捕捉语义特征，显著提升了数学公式检索的性能，在ARQMath-3任务中取得了最先进的结果。

**AI_Comments:** SSEmb的创新之处在于其联合结构和语义嵌入的策略，特别是引入图数据增强来提升结构多样性，同时保持数学有效性，这在图表示学习中是一个值得关注的贡献。该框架通过结合多模态信息（结构和文本语义）显著提升了公式检索的性能，并在基准测试中取得了SOTA结果，显示出其在数学信息检索领域的强大潜力和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 公式检索是数学信息检索领域的一个重要课题。

**Method:** 本文提出了SSEmb框架，能够同时捕获数学公式的结构和语义特征。在结构方面，通过图对比学习对表示为运算符图的公式进行编码，并引入一种基于替换策略的新型图数据增强方法，以增强结构多样性同时保持数学有效性。在语义方面，利用Sentence-BERT对公式的周边文本进行编码。最后，对每个查询及其候选公式，分别计算结构和语义相似度，并通过加权方案进行融合。

**Result:** 在ARQMath-3公式检索任务中，SSEmb在P'@10和nDCG'@10指标上均优于现有基于嵌入的方法超过5个百分点。此外，SSEmb提升了其他方法所有运行的性能，并与Approach0结合时取得了最先进（state-of-the-art）的结果。

**Conclusion:** SSEmb通过联合结构和语义嵌入的策略，在数学公式检索任务中取得了显著的性能提升和最先进的结果，证明了其捕获公式多模态信息的能力。

> **ai_Abstract:** SSEmb是一个新颖的数学公式检索嵌入框架，它创新性地结合了结构和语义信息。结构上，利用图对比学习和一种新型图数据增强技术处理运算符图；语义上，采用Sentence-BERT编码周边文本。通过加权融合结构和语义相似度，SSEmb在ARQMath-3任务中显著超越现有方法，并与Approach0结合时达到最先进性能，有效提升了数学公式检索的准确性。

> **摘要翻译:** 公式检索是数学信息检索中的一个重要课题。我们提出了SSEmb，一个新颖的嵌入框架，能够捕获数学公式的结构和语义特征。在结构上，我们采用图对比学习来编码表示为运算符图的公式。为了增强结构多样性同时保持这些公式图的数学有效性，我们通过替换策略引入了一种新颖的图数据增强方法。在语义上，我们利用Sentence-BERT来编码公式的周边文本。最后，对于每个查询及其候选公式，结构和语义相似度分别计算，然后通过加权方案进行融合。在ARQMath-3公式检索任务中，SSEmb在P'@10和nDCG'@10上超越现有基于嵌入的方法超过5个百分点。此外，SSEmb增强了其他方法所有运行的性能，并与Approach0结合时取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [792] [QuMAB: Query-based Multi-Annotator Behavior Modeling with Reliability under Sparse Labels](https://arxiv.org/abs/2507.17653)
> *QuMAB：基于查询的多标注者行为建模及其在稀疏标签下的可靠性*

*Liyun Zhang, Zheng Lian, Hong Liu, Takanori Takebe, Yuta Nakashima* | **Category: cs.IR, cs.MM** | **Updated: 2025-08-07**

**Keywords:** 多标注者学习, 行为建模, 稀疏标签, 可靠性, QuMAB

**Comment:** 

> **TL;DR:** QuMAB提出一种新的多标注者学习范式，从样本聚合转向标注者行为建模，将分歧视为有价值信息，通过轻量级查询建模个体行为并捕获标注者间相关性，以提高稀疏标签下的可靠性、降低成本并解释行为。

**AI_Comments:** QuMAB的创新点在于将多标注者学习的重点从传统的“聚合真实值”转向“建模标注者行为”，并巧妙地将标注者之间的分歧从“噪声”转变为“有价值的信息”。这种范式转变在主观任务和稀疏数据场景下具有重要意义，因为它能更真实地反映复杂标注过程。同时，通过引入轻量级查询和隐式正则化来处理稀疏性，并提供可视化解释，使其在实用性和可解释性方面都有所提升。数据集的贡献也为后续研究提供了宝贵资源。

<details>
  <summary>Details</summary>

**Motivation:** 传统多标注者学习范式面临挑战：主观任务缺乏绝对真值，稀疏标注覆盖导致聚合不可靠，且将标注者分歧视为噪声。

**Method:** 提出QuMAB（基于查询的多标注者行为模式学习），通过轻量级查询建模个体标注者行为，同时捕获标注者间关联作为隐式正则化，以防止对稀疏个体数据过拟合，保持个体化并提高泛化能力。提供标注者关注区域的可视化，以解释行为理解。

**Result:** QuMAB在建模个体标注者行为模式、共识预测及其在稀疏标注下的适用性方面表现出优越性。贡献了两个大规模密集标注数据集：STREET（4,300个标签/标注者）和AMER（平均3,118个标签/标注者），其中AMER是首个多模态多标注者数据集。

**Conclusion:** QuMAB通过将多标注者学习范式从样本聚合转向标注者行为建模，有效利用标注者分歧，在稀疏标签环境下显著提升了标注可靠性、降低了成本并提供了行为可解释性。

> **ai_Abstract:** 本文提出QuMAB，一种新的多标注者学习范式，旨在解决传统方法在主观任务和稀疏标签下聚合不可靠的问题。QuMAB将标注者分歧视为有价值信息，通过轻量级查询建模个体标注者行为，并利用标注者间相关性作为正则化，以提高泛化能力和可靠性。该方法有助于降低标注成本、增强聚合可靠性并解释标注者决策行为。研究还贡献了两个大规模多标注者数据集，并通过实验验证了QuMAB在稀疏标注下的优越性和适用性。

> **摘要翻译:** 多标注者学习传统上将不同的标注聚合以近似单一的真实值，将分歧视为噪声。然而，这种范式面临根本性挑战：主观任务通常缺乏绝对的真实值，并且稀疏的标注覆盖使得聚合在统计上不可靠。我们引入了一种范式转变，从样本级聚合转向标注者级行为建模。通过将标注者分歧视为有价值的信息而非噪声，建模标注者特定的行为模式可以重建未标注数据以降低标注成本，提高聚合可靠性，并解释标注者决策行为。为此，我们提出了QuMAB（基于查询的多标注者行为模式学习），它使用轻量级查询来建模个体标注者，同时捕获标注者之间的相关性作为隐式正则化，防止对稀疏个体数据过拟合，同时保持个体化并提高泛化能力，并通过标注者关注区域的可视化提供行为理解的可解释分析。我们贡献了两个具有密集个体标注者标签的大规模数据集：STREET（4,300个标签/标注者）和AMER（平均3,118个标签/标注者），其中AMER是第一个多模态多标注者数据集。大量的实验证明了我们的QuMAB在建模个体标注者行为模式、其在共识预测中的效用以及在稀疏标注下的适用性方面的优越性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [6] [Modelling and Performance Analysis of Non-Primary Channel Access in Wi-Fi Networks](https://arxiv.org/abs/2504.15774)
> *Wi-Fi网络中非主信道接入的建模与性能分析*

*Boris Bellalta, Francesc Wilhelmi, Lorenzo Galati-Giordano, Giovanni Geraci* | **Category: cs.IT, cs.NI, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 非主信道接入, Wi-Fi, 频谱利用, CTMC, IEEE 802.11bn

**Comment:** 

> **TL;DR:** 本文对IEEE 802.11bn中引入的非主信道接入（NPCA）机制进行了建模和性能分析，发现NPCA能显著提高吞吐量并减少接入延迟，但可能增加次级信道竞争。

**AI_Comments:** 本文创新性地提出了一个CTMC模型来分析NPCA机制在复杂Wi-Fi环境中的性能，这对于理解和优化下一代Wi-Fi网络的频谱利用具有重要意义。研究不仅揭示了NPCA带来的性能提升，也指出了其可能导致的次级信道竞争加剧的潜在局限性，提供了全面的视角。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在增进对非主信道接入（NPCA）机制性能的理解，该机制是IEEE 802.11bn中引入的新特性，旨在提高Wi-Fi网络的频谱利用率。

**Method:** 我们开发了一个连续时间马尔可夫链（CTMC）模型，该模型捕获了在启用NPCA的密集WLAN环境中，重叠基本服务集（OBSS）之间的交互，并包含了NPCA特有的新状态和转换。此外，我们还进行了数值评估和仿真，以量化NPCA在各种场景下对吞吐量和信道接入延迟的影响。

**Result:** 结果表明，在有利条件下，NPCA可以显著提高支持该机制的BSS的吞吐量并减少接入延迟。此外，NPCA有助于缓解OBSS性能异常，即低速率OBSS传输会降低附近所有设备的网络性能。然而，我们也观察到权衡：NPCA可能会增加次级信道上的竞争，从而可能减少在此信道上运行的BSS的传输机会。

**Conclusion:** 所提出的建模方法为下一代Wi-Fi网络中NPCA的分析、优化和开发提供了基础。

> **ai_Abstract:** 本文通过开发一个连续时间马尔可夫链（CTMC）模型，并结合数值评估和仿真，深入分析了IEEE 802.11bn中引入的非主信道接入（NPCA）机制在Wi-Fi网络中的性能。研究发现，NPCA能有效提高频谱利用率，在有利条件下显著提升吞吐量并降低信道接入延迟，同时有助于缓解OBSS性能异常。然而，NPCA也可能导致次级信道竞争加剧。该研究为未来Wi-Fi网络中NPCA的分析、优化和发展奠定了基础。

> **摘要翻译:** 本文旨在增进我们对非主信道接入（NPCA）机制性能的理解，该机制是IEEE 802.11bn中引入的新特性，旨在提高Wi-Fi网络的频谱利用率。NPCA使设备能够在主信道被重叠基本服务集（OBSS）的传输占用时，争用并传输次级信道。我们开发了一个连续时间马尔可夫链（CTMC）模型，该模型捕获了在启用NPCA的密集无线局域网（WLAN）环境中，OBSS之间的交互，并包含了NPCA特有的新状态和转换。除了模型提供的分析见解外，我们还进行了数值评估和仿真，以量化NPCA在各种场景下对吞吐量和信道接入延迟的影响。我们的结果表明，在有利条件下，NPCA可以显著提高支持该机制的BSS的吞吐量并减少接入延迟。此外，NPCA有助于缓解OBSS性能异常，即低速率OBSS传输会降低附近所有设备的网络性能。然而，我们也观察到权衡：NPCA可能会增加次级信道上的竞争，从而可能减少在此信道上运行的BSS的传输机会。总的来说，所提出的建模方法为下一代Wi-Fi网络中NPCA的分析、优化和开发提供了基础。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [797] [Energy Efficient Transmitter Creation by Consuming Free Energy in Molecular Communication](https://arxiv.org/abs/2508.04805)
> *耗散分子通信中自由能的能量高效发射器创建*

*Dongliang Jing, Linjuan Li, Zhen Cheng, Lin Lin, Andrew W. Eckford* | **Category: cs.IT** | **Updated: 2025-08-06**

**Keywords:** 分子通信, 能量效率, 发射器设计, 分子分离, 浓度转移

**Comment:** 

> **TL;DR:** 本文提出了一种能量高效的分子通信发射器设计，通过优化分子在储液器之间的转移来解决环境分子混合和浓度比相同的问题，从而提高传输性能。

**AI_Comments:** 这项研究在分子通信领域具有创新性，特别是在解决能量效率和分子分离的挑战上。通过优化分子转移策略，它为提高分子通信系统的高保真传输能力提供了实用方法。

<details>
  <summary>Details</summary>

**Motivation:** 在分子通信中，从环境中获取信息分子会导致分子混合且初始浓度比相同，这阻碍了分子移位键控（MoSK）等高保真传输技术。因此，需要一种能耗高效的方法来分离这些混合分子。

**Method:** 本文提出了一种发射器设计，该设计从环境中收集分子并将其储存在两个储液器中。为了分离混合分子，通过消耗能量在储液器之间转移分子。通过理论分析和仿真，研究了不同的分子转移方法，以探索能量高效的策略来优化发射器性能。

**Result:** 研究结果表明，转移初始浓度较高的分子可以提高发射器性能，而每次转移使用较少分子可以进一步提高效率。

**Conclusion:** 这些发现为通过能量高效的分子转移技术优化分子通信系统提供了有价值的见解。

> **ai_Abstract:** 本文提出了一种能量高效的分子通信发射器设计，旨在解决从环境中收集到的信息分子混合且初始浓度比相同的问题。该设计通过将分子储存在两个储液器中，并消耗能量在它们之间转移以分离混合分子。研究通过理论分析和仿真，发现转移初始浓度较高的分子能提升发射器性能，而每次转移使用更少分子能进一步提高效率，为优化分子通信系统提供了指导。

> **摘要翻译:** 信息分子在分子通信（MC）中扮演着关键角色，充当信息传输的载体。在分子通信中获取信息分子的常用方法是从环境中收集它们；然而，收集到的分子通常是各种环境分子的混合物，并且储液器中的初始浓度比是相同的，这阻碍了分子移位键控（MoSK）等高保真传输技术。本文提出了一种发射器设计，该设计从周围环境中收集分子并将其储存在两个储液器中。为了分离混合分子，需要消耗能量在储液器之间转移它们。鉴于有限的能源，这项工作探索了能量高效的策略来优化发射器性能。通过理论分析和仿真，我们研究了在储液器之间移动分子的不同方法。结果表明，转移初始浓度较高的分子可以提高发射器性能，而每次转移使用较少分子可以进一步提高效率。这些发现为通过能量高效的分子转移技术优化分子通信系统提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [802] [Energy Efficiency Optimization for Movable Antenna-Aided Communication Systems](https://arxiv.org/abs/2508.05033)
> *移动天线辅助通信系统的能量效率优化*

*Jingze Ding, Zijian Zhou, Yuping Zhao, Bingli Jiao* | **Category: cs.IT, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 移动天线, 能量效率优化, 连续凸逼近, 通信系统

**Comment:** 

> **TL;DR:** 本文研究了移动天线系统考虑移动开销的能量效率优化，并提出了一种基于连续凸逼近的算法，仿真结果表明移动天线系统能提高能量效率。

**AI_Comments:** 这项研究的创新点在于首次将移动天线移动引入的时间延迟和能量消耗纳入能量效率优化模型中。其重要性在于证明了移动天线系统在考虑实际开销的情况下，依然能够带来能量效率的提升，为未来通信系统设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 考虑移动天线（MA）移动引入的时间延迟和能量消耗，优化MA系统的能量效率。

**Method:** 首先，推导了单用户下行通信系统中，用户配备单个MA时的能量效率上限。然后，将能量效率最大化问题表述为优化MA位置的问题，并提出了一种基于连续凸逼近的高效算法来解决这个非凸优化问题。

**Result:** 仿真结果表明，尽管存在MA移动引起的开销，MA系统与传统固定位置天线（FPA）系统相比，仍能提高能量效率。

**Conclusion:** 尽管移动天线系统存在移动开销，但它在能量效率方面优于传统固定位置天线系统。

> **ai_Abstract:** 本文研究了移动天线（MA）系统的能量效率优化，该优化考虑了MA移动带来的时间延迟和能量消耗。研究推导了单用户下行通信系统在单个MA配置下的能量效率上限，并将能量效率最大化问题建模为MA位置优化问题。为解决这一非凸问题，提出了一种基于连续凸逼近的高效算法。仿真结果验证了即使存在移动开销，MA系统也能比传统固定位置天线系统实现更高的能量效率。

> **摘要翻译:** 本文研究了移动天线（MA）系统的能量效率优化，其中考虑了MA移动引入的时间延迟和能量消耗。我们首先推导了单用户下行通信系统中能量效率的上限，该系统中用户配备单个MA。然后，将能量效率最大化问题表述为优化MA位置的问题，并提出了一种基于连续凸逼近的高效算法来解决这个非凸优化问题。仿真结果表明，尽管存在MA移动引起的开销，MA系统与传统固定位置天线（FPA）系统相比，仍能提高能量效率。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [807] [Two tales for a geometric Jensen--Shannon divergence](https://arxiv.org/abs/2508.05066)
> *几何Jensen--Shannon散度的两种解读*

*Frank Nielsen* | **Category: cs.IT, cs.LG** | **Updated: 2025-08-07**

**Keywords:** 几何Jensen--Shannon散度, 扩展G-JSD, 统计散度, 高斯分布, 正则化

**Comment:** 

> **TL;DR:** 本文介绍了几何Jensen--Shannon散度(G-JSD)的一种新定义，称为扩展G-JSD，它适用于正密度且不标准化几何混合。研究了新旧定义之间的差异，并推导了高斯分布的闭式表达式，表明它们都是普通JSD的正则化。

**AI_Comments:** 这项工作通过引入扩展G-JSD，拓宽了几何Jensen--Shannon散度的应用范围，使其能够处理更一般的正测度，而非仅限于概率密度。明确分析新旧定义之间以及与普通JSD的关系，并提供在高斯分布下的闭式解，对于实际应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 几何Jensen--Shannon散度(G-JSD)因其在高斯分布间的闭式表达式而在机器学习和信息科学中流行，但可能存在局限性。本文旨在引入一种新的、更通用的G-JSD定义，并分析其与现有G-JSD的关系。

**Method:** 引入了几何Jensen--Shannon散度（G-JSD）的一种替代定义，称为扩展G-JSD，该定义适用于正密度且不标准化几何混合。明确给出了扩展G-JSD和G-JSD在考虑概率密度时的差距，并报告了以其他统计散度表示的下界和上界。推导了多元高斯分布情况下的相应闭式表达式。最后，展示了这两种类型的几何JSD（G-JSD和扩展G-JSD）都可以被解释为通过加性项对普通JSD的正则化。

**Result:** 引入了一种新的几何Jensen--Shannon散度定义，即扩展G-JSD，适用于正密度。明确给出了扩展G-JSD和G-JSD在概率密度情况下的差距。报告了以其他统计散度表示的下界和上界。推导了多元高斯分布的闭式表达式。发现G-JSD和扩展G-JSD都可以被解释为普通JSD的加性正则化。

**Conclusion:** 本文成功引入并分析了一种新的几何Jensen--Shannon散度（扩展G-JSD），它扩展了G-JSD的应用范围，并通过数学分析揭示了其与现有G-JSD的关系以及在高斯分布下的具体形式，最终表明两者均可视为普通JSD的正则化。

> **ai_Abstract:** 本文针对机器学习和信息科学中流行的几何Jensen--Shannon散度（G-JSD），提出了一种名为扩展G-JSD的新定义。该新散度适用于正密度且不标准化几何混合，从而扩展到更一般的正测度。文章详细分析了扩展G-JSD与现有G-JSD之间的差异、上下界，并推导了多元高斯分布下的闭式表达式。研究发现，这两种几何JSD均可视为普通Jensen--Shannon散度的加性正则化形式。

> **摘要翻译:** 几何Jensen--Shannon散度（G-JSD）因其在高斯分布间的闭式表达式而在机器学习和信息科学中广受欢迎。在这项工作中，我们引入了一种专门针对正密度的几何Jensen--Shannon散度的替代定义，该定义不标准化几何混合。这种新颖的散度被称为扩展G-JSD，因为它扩展到更一般的正测度。我们明确给出了在考虑概率密度时扩展G-JSD和G-JSD之间的差距，并报告了以其他统计散度表示的下界和上界。在考虑应用中常见的多元高斯分布情况时，我们推导了相应的闭式表达式。最后，我们表明这两种类型的几何JSD，即G-JSD和扩展G-JSD，都可以被解释为通过加性项对普通JSD的正则化。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [812] [Neural Estimation of Information Leakage for Secure Communication System Design](https://arxiv.org/abs/2508.05176)
> *安全通信系统设计中的信息泄漏神经估计*

*Darius S. Heerklotz, Ingo Schroeder, Pin-Hsun Lin, Christian Deppe, Eduard A. Jorswieck* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 信息泄漏, 神经估计, 互信息, 物理层安全, 块长度

**Comment:** 

> **TL;DR:** 本文提出了一种基于变分对比对数比上界框架的改进互信息估计器，并利用神经网络参数化的伯努利专家混合模型，能够量化复杂通信系统中的信息泄漏，并可将块长度扩展到255，解决了现有方法在长块长度下低估互信息的问题。

**AI_Comments:** 本文提出了一种新颖的基于神经网络的互信息估计方法，其创新点在于结合了变分对比对数比上界框架和伯努利专家混合模型，使其能够处理离散和连续变量，并适应复杂的通信系统（如使用通用哈希族）。其重要性在于解决了传统方法在长块长度下低估信息泄漏的限制，显著提升了估计的准确性和实用性，为有限块长度下物理层安全设计提供了有力的工具。

<details>
  <summary>Details</summary>

**Motivation:** 低估信息泄漏会损害保密性，而高估则会导致系统设计效率低下。因此，一个可靠的泄漏估计器至关重要。传统的互信息估计方法在不完全了解信道或源分布的情况下存在局限性，尤其是在处理具有复杂数据处理（如通用哈希族）的通信系统时，以及在较大块长度下会显著低估互信息。

**Method:** 本文提出了一种改进的互信息估计器，该估计器基于变分对比对数比（variational contrastive log-ratio）上界框架，并针对离散和连续变量进行了调整。通过使用由神经网络参数化的伯努利专家混合模型，该估计器能够量化采用复杂数据处理（如通用哈希族）的通信系统中的信息泄漏。此外，还提出了一种利用该估计器来设计窃听码或密钥生成设计的通用哈希族的方法。

**Result:** 仿真结果表明，现有方法在较高块长度（n>>16）下，尤其是在使用通用哈希族时，会显著低估互信息。所提出的方法能够将块长度扩展到255，并且推测在有足够的训练数据和模型大小的情况下，该设计可以很好地扩展到更高的块长度。

**Conclusion:** 所提出的估计器和自适应哈希设计框架为将窃听信道的物理层安全考虑扩展到有限块长度范围提供了一种实用方法。

> **ai_Abstract:** 本研究提出了一种基于神经网络的改进互信息估计器，旨在解决安全通信系统中信息泄漏估计不准确的问题。该估计器利用变分对比对数比上界框架和伯努利专家混合模型，能够有效地量化包含复杂数据处理（如通用哈希族）的通信系统中的信息泄漏，并支持高达255的块长度。相较于现有方法，该方法显著提高了长块长度下互信息估计的准确性，为有限块长度下的物理层安全提供了实用解决方案。

> **摘要翻译:** 低估信息泄漏会损害保密性，而高估则可能导致系统设计效率低下。因此，一个可靠的泄漏估计器至关重要。基于神经网络的估计器提供了一种数据驱动的方式来估计互信息，而无需完全了解信道或源分布。在这项工作中，我们的目标是扩展窃听码的块长度，使估计器仍然能够可行地运行。我们提出了一种基于变分对比对数比上界框架的改进互信息估计器，该估计器专为离散和连续变量设计。通过使用由神经网络参数化的伯努利专家混合模型，该估计器能够量化采用复杂数据处理（如通用哈希族）的通信系统中的信息泄漏。我们进一步提出了一种利用所提出的估计器来设计窃听码或秘密密钥生成设计的通用哈希族的方法。仿真结果表明，现有方法显著低估了互信息，尤其是在使用通用哈希族处理更高块长度（n>>16）时。所提出的方法可以将块长度扩展到255，并且我们推测，在有足够的训练数据和模型大小的情况下，该设计可以很好地扩展到更高的块长度。此外，我们认为我们提出的估计器和自适应哈希设计框架为将窃听信道的物理层安全考虑扩展到有限块长度范围提供了一种实用方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [817] [Simultaneous Rational Function Codes: Improved Analysis Beyond Half the Minimum Distance with Multiplicities and Poles](https://arxiv.org/abs/2508.05284)
> *同步有理函数码：超越一半最小距离的改进分析，考虑重数和极点*

*Matteo Abbondati, Eleonora Guerrini, Romain Lebreton* | **Category: cs.IT, cs.SC** | **Updated: 2025-08-07**

**Keywords:** 有理函数码, 重数, 极点, 解码算法, 纠错码

**Comment:** 

> **TL;DR:** 该论文通过处理重数和极点，扩展了同步有理函数码的解码工作，提供了更复杂的场景下解码算法失败概率的严格分析，并提出了新的改进分析。

**AI_Comments:** 这篇论文的创新之处在于其对有理函数码解码的全面扩展，特别是在处理重数和极点方面的贡献。它通过提供更严格的失败概率分析，显著提升了该领域的技术水平，对于需要高可靠性数据传输的应用具有重要意义。该工作构建在现有研究之上，并引入了新的分析框架，使其具有较高的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在扩展先前关于同步有理函数码解码的工作，以解决两个重要场景：重数和极点（分母的零点），从而改进在这些复杂情况下的解码分析。

**Method:** 首先，通过考虑多精度评估，将先前结果推广到具有重数的有理码。然后，使用来自Guerrini等人的混合模型，将方法扩展到可能存在极点的有理函数向量。

**Result:** 贡献包括：对解码算法失败概率的严格分析，该分析推广并改进了几个先前的结果；扩展到处理并非所有错误都可以假定为随机的混合模型；以及在处理重数内极点的更一般上下文中进行新的改进分析。

**Conclusion:** 理论结果为在这些更复杂场景中的重构失败提供了全面的概率分析，从而推进了有理函数码纠错领域的最新技术水平。

> **ai_Abstract:** 本研究在现有同步有理函数码解码工作的基础上，引入了对重数和极点两种复杂情况的处理。通过多精度评估和混合模型，该论文提供了对解码算法失败概率的严格分析，并扩展了对非随机错误的处理能力，从而在更广泛的背景下改进了有理函数码的纠错分析。

> **摘要翻译:** 本文扩展了 Abbondati 等人（2024 年）关于同步有理函数码解码的工作，通过解决两个重要场景：重数和极点（分母的零点）。首先，我们通过考虑多精度评估，将先前的结果推广到具有重数的有理码。然后，使用 Guerrini 等人（2023 年）的混合模型，我们将方法扩展到可能存在极点的有理函数向量。我们的贡献包括：对解码算法失败概率的严格分析，该分析推广并改进了几个先前的结果；扩展到处理并非所有错误都可以假定为随机的混合模型的应用；以及在处理重数内极点的更一般上下文中进行新的改进分析。理论结果为在这些更复杂场景中的重构失败提供了全面的概率分析，从而推进了有理函数码纠错领域的最新技术水平。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [822] [Fundamental limit of Sum Capacity in Pinching Antenna Assisted Multiple Access Channel](https://arxiv.org/abs/2508.05309)
> *挟持天线辅助多址信道和容量的根本限制*

*Guangji Chen, Qingqing Wu, Kangda Zhi* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 挟持天线系统, 和容量, 多址信道, 挟持波束成形, NOMA

**Comment:** 

> **TL;DR:** 本文研究了挟持天线系统（PASS）辅助的多址信道中和容量的根本限制，发现对于理想情况，最佳传输方案是用户间的交替传输，且无需NOMA。

**AI_Comments:** 本文探讨了一种新型天线系统——挟持天线系统（PASS）在多址信道中的容量限制，具有创新性。其发现理想情况下用户交替传输即可达到最优，且NOMA并非必需，这对未来无线通信系统的设计具有重要指导意义。论文通过理论推导和数值验证，为挟持波束成形的应用提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 挟持天线系统（PASS）在通过动态调整挟持天线位置来灵活重构无线信道方面展现出巨大潜力。本文旨在研究挟持天线辅助多址信道中和容量的根本限制。

**Method:** 本文考虑了一种动态挟持波束成形设置，其中在一个传输周期内采用多个挟持波束成形矢量，并考虑了实现容量的非正交多址（NOMA）传输方案。对于理想情况，即挟持波束成形矢量数量渐近大时，推导了和速率的闭合表达式。在此基础上，推导了任意有限数量挟持波束成形矢量下的和速率下界。

**Result:** 研究发现，对于挟持波束成形矢量数量渐近大的理想情况，最佳传输方案是用户间的交替传输，且通过动态挟持波束成形最大化其信道功率增益，这意味着不需要基于NOMA的传输方案。相应的和速率以闭合形式表达式给出，作为和容量的上限。在任意有限数量挟持波束成形矢量下，获得了和速率的下界。数值结果验证了理论发现，并说明了使用动态挟持波束成形提高和容量的实际意义。

**Conclusion:** 本文确定了挟持天线辅助多址信道中和容量的根本限制。研究表明，在理想情况下，用户间的交替传输是最佳方案，且NOMA并非必需。动态挟持波束成形具有提高和容量的实际重要性。

> **ai_Abstract:** 本文研究了挟持天线系统（PASS）辅助的多址信道中和容量的根本限制。在动态挟持波束成形设置下，考虑了多个挟持波束成形矢量和NOMA传输方案。研究发现，在理想情况下，最佳方案是用户间交替传输，且无需NOMA。论文推导了和速率的上下界，并通过数值结果验证了动态挟持波束成形对提高和容量的实际意义。

> **摘要翻译:** 挟持天线系统（PASSs）最近展示了其通过动态调整介质波导上挟持天线位置（称为挟持波束成形）来灵活重构无线信道的巨大潜力。本文研究了PASS辅助多址信道中和容量的根本限制，其中多个用户在平均功率约束下向基站传输独立消息。为此，我们考虑了一种动态挟持波束成形设置，其中在一个传输周期内采用多个挟持波形矢量，并考虑了实现容量的非正交多址（NOMA）传输方案。对于挟持波束成形矢量数量渐近大的理想情况，我们揭示了最佳传输方案是用户间的交替传输，并通过动态挟持波束成形最大化其信道功率增益，这意味着不需要基于NOMA的传输方案。相应的和速率以闭合形式表达式给出，作为和容量的上限。受此结果启发，获得了在任意有限数量挟持波束成形矢量下和速率的下界。数值结果验证了我们的理论发现，并说明了使用动态挟持波束成形提高和容量的实际意义。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [827] [$\mathbb{F}_{2}\mathbb{F}_{4}$-Additive Complementary Dual Codes](https://arxiv.org/abs/2508.05317)
> *$\\mathbb{F}_{2}\\mathbb{F}_{4}$-加性互补对偶码*

*S. Ouagagui, N. Benbelkacem, A. Batoul, T. Abualrub* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 加性互补对偶码, 混合字母表, 二进制线性互补对偶码, 编码理论, $\\mathbb{F}_2\\mathbb{F}_4$

**Comment:** 

> **TL;DR:** 本文研究了在混合字母表$\\mathbb{F}_2\\mathbb{F}_4$上的加性互补对偶(ACD)码的结构和性质，并证明了它们可以用于构造二进制线性互补对偶(LCD)码。

**AI_Comments:** 本文创新性地研究了在混合字母表上的加性互补对偶码，并建立了它们与二进制线性互补对偶码之间的重要联系。这一发现为构造具有特定性质的二进制码提供了新的途径，具有重要的理论和应用价值。特别是在编码理论中，能够将不同代数结构上的码关联起来，并给出具体构造方法，是很有意义的工作。

<details>
  <summary>Details</summary>

**Motivation:** 研究在混合字母表$\\mathbb{F}_2\\mathbb{F}_4$上定义的加性互补对偶(ACD)码的结构和性质。

**Method:** 通过对在$\\mathbb{F}_2\\mathbb{F}_4$上定义的内积，研究了ACD码的结构和性质。建立了ACD码的充分条件。展示了$\\mathbb{F}_{2}\\mathbb{F}_{4}$上的ACD码可以通过线性映射$W$的应用来构造二进制线性互补对偶码。证明了如果一个码的二进制图像是LCD码，那么原始码必然是ACD码。

**Result:** 建立了加性互补对偶(ACD)码的充分条件。证明了在$\\mathbb{F}_{2}\\mathbb{F}_{4}$上的ACD码可以应用于构造二进制线性互补对偶码。证明了如果一个码的二进制图像是LCD码，那么原始码必然是ACD码。给出了一个图像是距离最优二进制LCD码的例子。

**Conclusion:** 在混合字母表$\\mathbb{F}_2\\mathbb{F}_4$上的加性互补对偶码具有特定的结构和性质，并且可以有效地应用于构造二进制线性互补对偶码。

> **ai_Abstract:** 本文深入探讨了在混合字母表$\\mathbb{F}_2\\mathbb{F}_4$上定义的加性互补对偶(ACD)码的结构与属性。研究建立了ACD码的充分条件，并揭示了这些码能够通过线性映射$W$的图像，有效应用于构造二进制线性互补对偶(LCD)码。论文还证明了一个关键结论：若码的二进制图像为LCD码，则原码必定是ACD码。文中提供了一个距离最优二进制LCD码的实例，以支持其发现。

> **摘要翻译:** 本文研究了在混合字母表$\\mathbb{F}_2\\mathbb{F}_4$上相对于某个在$\\mathbb{F}_2\\mathbb{F}_4$上定义的内积的加性互补对偶(ACD)码的结构和性质。我们建立了此类码是加性互补对偶(ACD)码的充分条件。我们还表明，$\\mathbb{F}_{2}\\mathbb{F}_{4}$上的ACD码可以通过线性映射$W$将其图像应用于构造二进制线性互补对偶码。值得注意的是，我们证明了如果一个码的二进制图像是LCD，那么原始码必然是ACD。给出了一个图像是距离最优二进制LCD码的例子。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [832] [On the entropy growth of sums of iid discrete random variables](https://arxiv.org/abs/2508.05348)
> *独立同分布离散随机变量和的熵增长*

*Riccardo Castellano, Pavel Sekatski* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 香农熵, 独立同分布, 离散随机变量, 渐近下界, 不共度秩

**Comment:** 

> **TL;DR:** 论文推导了N个独立同分布离散随机变量和的香农熵的渐近下界，引入了不共度秩r(X)的概念。

**AI_Comments:** 这项工作通过引入“不共度秩”这一新概念，为独立同分布离散随机变量和的熵增长提供了一个新颖的分析视角。其创新之处在于不依赖于传统的中心极限定理，这使得其适用范围可能更广，尤其是在变量不满足中心极限定理条件的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 理解和量化独立同分布离散随机变量和的熵增长行为。

**Method:** 通过推导，而非依赖中心极限定理，建立在多项式分布和独立同分布格点随机变量和的已知渐近熵表达式之上，引入了不共度秩r(X)的概念。

**Result:** 导出了香农熵H的渐近下界：H >= r(X)/2 log(N) + cst，其中r(X)是引入的随机变量的不共度秩。

**Conclusion:** 成功地为独立同分布离散随机变量和的香农熵提供了不依赖中心极限定理的渐近下界，并引入了新的量化指标“不共度秩”。

> **ai_Abstract:** 本文推导了N个任意独立同分布离散随机变量和的香农熵H的渐近下界。该下界形式为H >= r(X)/2 log(N) + cst，其中r(X)是一个新引入的正整数，称为随机变量的不共度秩。此推导不依赖于中心极限定理，而是基于多项式分布和独立同分布格点随机变量和的渐近熵已知表达式。

> **摘要翻译:** 我们推导了N个任意独立同分布离散随机变量和的香农熵H的渐近下界。导出的下界H >= r(X)/2 log(N) + cst 以随机变量的不共度秩r(X)表示——这是一个我们引入的正整数。该推导不依赖于中心极限定理，而是建立在多项式分布和独立同分布格点随机变量和的已知渐近熵表达式之上，后者对应于r(X)=1的情况。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [837] [Communication-Efficient Distributed Computing Through Combinatorial Multi-Access Models](https://arxiv.org/abs/2508.05426)
> *通过组合多址模型实现通信高效的分布式计算*

*Shanuja Sasi, Onur Günlü* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 分布式计算, 多址模型, 组合设计, t-设计, 通信效率

**Comment:** 

> **TL;DR:** 本文提出了一种基于组合t-设计的新的多址分布式计算(MADC)模型，旨在减少通信开销并优化reducer节点数量。

**AI_Comments:** 该论文的创新点在于引入了组合t-设计来优化多址分布式计算模型中的通信效率和节点配置。其重要性体现在提出了一个无需文件复制的分布式计算框架，并能显著减少归约器节点数量。然而，论文也明确指出了其局限性，即以增加通信成本为代价来实现这些优化，这表明该方案在实际应用中需要权衡考虑。

<details>
  <summary>Details</summary>

**Motivation:** 传统的MapReduce框架存在通信开销问题，并且需要文件在mapper节点间复制。本文旨在探索一种新的分布式计算框架（MADC），利用编码理论技术最小化通信开销，同时避免文件在mapper节点间的复制。

**Method:** 本文引入了一种利用组合设计，特别是t-设计的新方法，来构建高效的编码方案。通过建立t-设计与MapReduce数组之间的联系，来表征可实现的通信负载。

**Result:** 所提出的方案实现了1的计算负载，并表征了可实现的通信负载。该方法在选择reducer节点数量方面表现出灵活性。与现有组合拓扑方案相比，该方案显著减少了reducer节点数量，但代价是增加了通信成本。

**Conclusion:** 本文提出了一种基于组合t-设计的新型多址分布式计算(MADC)模型，该模型能够实现高效的编码方案，达到1的计算负载，并在减少reducer节点数量方面表现出优势，尽管伴随着通信成本的增加。

> **ai_Abstract:** 本文提出了一种名为多址分布式计算（MADC）的新型框架，该框架利用组合t-设计构建高效编码方案，以最小化通信开销，并实现1的计算负载。该方法在减少归约器节点数量方面表现出显著优势，但会增加通信成本，与传统MapReduce框架不同，MADC无需文件复制。

> **摘要翻译:** 本文探讨了多址分布式计算（MADC）模型，这是一种新颖的分布式计算框架，其中映射器（mapper）和归约器（reducer）节点是不同的实体。与传统的MapReduce框架不同，MADC利用编码理论技术最大限度地减少通信开销，而无需在映射器节点之间进行文件复制。我们引入了一种利用组合设计，特别是t-设计的新方法，来构建实现计算负载为1的高效编码方案。通过建立t-设计与MapReduce数组之间的联系，我们表征了可实现的通信负载，并展示了我们方法在选择归约器节点数量方面的灵活性。所提出的方案相对于现有组合拓扑方案显著减少了归约器节点的数量，但代价是增加了通信成本。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [842] [Long Polar vs. LDPC Codes under Complexity-Constrained Decoding](https://arxiv.org/abs/2508.05485)
> *长极性码与低密度奇偶校验码在复杂度受限解码下的比较*

*Felix Krieg, Marvin Rübenacke, Andreas Zunker, Stephan ten Brink* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 极性码, LDPC码, 复杂度受限解码, 连续抵消解码, LLR操作

**Comment:** 

> **TL;DR:** 在复杂度受限的解码条件下，长极性码在连续抵消（SC）解码下可以超越LDPC码，特别是简化连续抵消（SSC）解码具有更好的复杂度扩展性和更少的运算量。

**AI_Comments:** 这篇论文通过考虑实际的解码复杂度约束，对长极性码和LDPC码的性能进行了重新评估，挑战了现有认知。其创新点在于强调了在资源受限环境下长极性码的潜在优势，并突出了SSC解码在效率和性能方面的竞争力，对未来编码方案的选择具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 业界和学术界普遍认为长码长的极性码不如LDPC码，因为LDPC码可以进行大量置信传播（BP）迭代。然而，在实际应用中，由于延迟和复杂度限制，BP迭代次数可能非常有限。

**Method:** 本文通过比较长极性码在连续抵消（SC）解码（特别是简化连续抵消（SSC）解码）下与LDPC码在相似的定点对数似然比（LLR）操作次数下的性能。

**Result:** 在相似的定点对数似然比（LLR）操作次数下，长极性码在连续抵消（SC）解码下优于其LDPC对应物。特别是，极性码的简化连续抵消（SSC）解码展现出比N log N更好的复杂度扩展性，并且比相同参数的LDPC码的单次BP迭代所需的运算量更少。

**Conclusion:** 在复杂度受限的解码条件下，长极性码，特别是采用简化连续抵消（SSC）解码的极性码，能够超越LDPC码，挑战了传统观点。

> **ai_Abstract:** 本文针对业界普遍认为长极性码不如LDPC码的观点，提出在实际复杂度受限的解码条件下，这一结论可能不成立。研究表明，在相同运算量限制下，采用连续抵消（SC）解码的长极性码，尤其是简化连续抵消（SSC）解码，其性能优于LDPC码。SSC解码不仅具有更好的复杂度扩展性，而且比LDPC码的单次BP迭代所需操作更少，证明了长极性码在实际应用中的竞争力。

> **摘要翻译:** 业界和学术界的普遍观点认为，极性码在短码长下具有竞争力，但随着码块长度的增加，已无法与低密度奇偶校验（LDPC）码抗衡。这种观点通常基于LDPC码可以通过大量置信传播（BP）迭代进行解码的假设。然而，在实践中，由于延迟和复杂度限制，迭代次数可能相当有限。在本文中，我们表明，在相似的定点对数似然比（LLR）操作次数下，采用连续抵消（SC）解码的长极性码优于其LDPC对应物。特别是，极性码的简化连续抵消（SSC）解码展现出比N log N更好的复杂度扩展性，并且比相同参数的LDPC码的单次BP迭代所需的运算量更少。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [847] [Multivariate Partial Information Decomposition: Constructions, Inconsistencies, and Alternative Measures](https://arxiv.org/abs/2508.05530)
> *多元部分信息分解：构建、不一致性与替代度量*

*Aobo Lyu, Andrew Clark, Netanel Raviv* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** 部分信息分解, 多元信息, 信息论, 不一致性, 协同信息

**Comment:** 

> **TL;DR:** 本文深入探讨了部分信息分解（PID）框架，解决了两源PID问题，揭示了三源及以上PID的根本不一致性，并提出了新的多元唯一信息和协同信息度量方法，强调需要新的多元信息分解框架。

**AI_Comments:** 本文对部分信息分解（PID）框架进行了深入且批判性的分析。其创新之处在于不仅解决了两源PID的理论问题，更重要的是，首次明确指出了传统PID框架在处理三个或更多源时存在的根本性不一致性，并通过严谨的数学证明（反例和不可能定理）揭示了这一局限性。此外，本文提出了一种新的、替代性的多元信息度量方法，为高阶信息交互的量化提供了新的视角和工具，这对于信息论、机器学习和复杂系统分析等领域具有重要意义。这些贡献为未来多元信息分解理论的发展指明了方向，强调了构建一个更鲁棒、一致的新框架的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 互信息无法捕捉多元系统中复杂的细粒度交互。部分信息分解（PID）框架被引入以解决此问题，旨在将源变量与目标变量之间的互信息分解为冗余、唯一和协同等细粒度信息原子。本文旨在回顾PID的公理系统和期望属性，并解决其在多源情况下的局限性。

**Method:** 1. 回顾了PID框架的公理系统和期望属性。2. 为两源PID情况提供了满足所有公理和期望属性的显式闭式公式。3. 证明了对于三个或更多源，PID存在根本性不一致，通过三变量反例和不可能定理进行论证。4. 提出了避免PID格方法不一致性的多元唯一信息和协同信息替代度量方法，这些方法依赖于消除高阶依赖的新随机变量系统。

**Result:** 1. 解决了两源PID问题，提供了所有信息原子的显式闭式公式。2. 证明了对于三个或更多源，PID存在根本不一致性，例如三变量反例中原子之和超过总信息，且证明了不可能定理，表明当源数量超过三个时，没有基于格的分解可以对所有子集保持一致。3. 提出的多元唯一信息和协同信息替代度量满足可加性和连续性等关键公理，为高阶关系提供了强大的理论解释，并在Ising模型上的综合实验中显示出强大的数值性能。

**Conclusion:** 本研究结果强调了研究多元信息分解需要一个新的框架。

> **ai_Abstract:** 本文深入分析了部分信息分解（PID）框架，旨在解决互信息在多元系统中无法捕捉细粒度交互的问题。研究首先为两源PID提供了满足所有公理的闭式公式，随后证明了三源及以上PID存在根本性不一致，通过反例和不可能定理揭示了其局限性。为克服这些不一致性，作者提出了新的多元唯一和协同信息度量方法，这些方法基于消除高阶依赖的新随机变量系统，并表现出良好的理论特性和数值性能。研究结果强调了开发新多元信息分解框架的必要性。

> **摘要翻译:** 互信息能有效量化两个变量之间的依赖关系，但它无法捕捉多元系统中出现的复杂、细粒度交互。部分信息分解（PID）框架的引入旨在解决此问题，通过将一组源变量与一个目标变量之间的互信息分解为细粒度的信息原子，如冗余、唯一和协同分量。在这项工作中，我们回顾了PID框架的公理系统和期望属性，并做出了三个主要贡献。首先，我们通过提供满足所有公理和期望属性的显式闭式公式，解决了两源PID情况。其次，我们证明了对于三个或更多源，PID存在根本性不一致：我们提出了一个三变量反例，其中原子之和超过了总信息，并证明了一个不可能性定理，表明当源数量超过三个时，没有基于格的分解可以对所有子集保持一致。最后，我们偏离了PID格方法以避免其不一致性，并提出了多元唯一信息和协同信息的显式度量。我们提出的度量依赖于消除高阶依赖的新随机变量系统，满足诸如可加性和连续性等关键公理，为高阶关系提供了强大的理论解释，并在Ising模型上的综合实验中显示出强大的数值性能。我们的发现强调了研究多元信息分解需要一个新的框架。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [852] [Latency Minimization for Multi-AAV-Enabled ISCC Systems with Movable Antenna](https://arxiv.org/abs/2508.05574)
> *带有可移动天线的多AAV集成传感、通信和计算系统中的延迟最小化*

*Yiyang Chen, Wenchao Liu, Chunjie Wang, Yinyu Wu, Xuhui Zhang, Yanyan Shen* | **Category: cs.IT, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 可移动天线, 集成传感、通信和计算, 延迟最小化, 优化问题, 粒子群优化

**Comment:** 

> **TL;DR:** 提出一种基于粒子群优化和凸优化的双层迭代算法，用于最小化多AAV集成传感、通信和计算系统中带有可移动天线的最大延迟。

**AI_Comments:** 该论文的创新点在于将可移动天线引入到多AAV的ISCC系统中，并提出了一种联合优化策略来解决复杂的非凸延迟最小化问题。所提出的两层迭代算法结合了启发式优化和凸优化，为解决此类耦合优化问题提供了一种有效途径，对于提升未来空基ISCC系统的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 增强多自主航空器（AAV）集成传感、通信和计算（ISCC）系统的整体性能，特别是通过引入可移动天线来最小化系统中的最大延迟。

**Method:** 提出一个联合优化可移动天线位置、计算资源分配和传输波束成形以最小化最大延迟的优化问题。为了解决该非凸问题，提出了一种结合粒子群优化和凸优化的两层迭代算法。

**Result:** 仿真结果表明，所提出的方案与基线方案相比，显著改善了系统延迟。

**Conclusion:** 所提出的算法能够有效地最小化多自主航空器（AAV）集成传感、通信和计算（ISCC）系统中带有可移动天线的最大延迟，从而提升系统性能。

> **ai_Abstract:** 该论文研究了带有可移动天线（MA）的多自主航空器（AAV）集成传感、通信和计算（ISCC）系统中的延迟最小化问题。为了提升系统性能并最小化最大延迟，作者提出了一个联合优化MA位置、计算资源分配和传输波束成形的优化问题。针对该非凸问题，论文提出了一种结合粒子群优化和凸优化的两层迭代算法。仿真结果验证了该方案能显著降低系统延迟。

> **摘要翻译:** 本文研究了一种由自主航空器（AAV）支持的集成传感、通信和计算系统，特别关注将可移动天线（MA）集成到系统中以增强整体系统性能。具体来说，多个支持MA的AAV执行传感任务，并同时将生成的计算任务传输到基站进行处理。为了在传感和资源约束下最小化最大延迟，我们提出了一个优化问题，该问题联合协调MA的位置、计算资源分配和传输波束成形。由于目标函数的非凸性以及变量之间的强耦合，我们提出了一种利用粒子群优化和凸优化的两层迭代算法来解决它。仿真结果表明，所提出的方案与基线方案相比，实现了显著的延迟改进。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [857] [Power and Limitations of Linear Programming Decoder for Quantum LDPC Codes](https://arxiv.org/abs/2508.04769)
> *量子LDPC码线性规划解码器的能力与局限性*

*Shouzhen Gu, Mehdi Soleimanifar* | **Category: cs.IT, quant-ph** | **Updated: 2025-08-06**

**Keywords:** 量子LDPC码, 线性规划解码, 有序统计解码, 量子纠错

**Comment:** 

> **TL;DR:** 研究揭示了量子LDPC码线性规划（LP）解码器的局限性，即在某些错误模式下产生模糊分数解；通过结合有序统计解码（OSD）后处理，LP解码性能显著提升，甚至优于相同后处理的置信传播解码，为近期量子LDPC码解码提供了有前景的方法。

**AI_Comments:** 该论文的创新之处在于识别并解决了量子LDPC码LP解码器在特定错误模式下的局限性，并引入OSD作为有效的后处理技术。其重要性在于为实现容错量子计算提供了更可靠的解码方案，尤其适用于近期量子计算设备。通过结合OSD，LP解码器超越了传统方法，为量子纠错码的实际应用铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 解码量子纠错码是实现容错量子计算的关键挑战。尽管线性规划（LP）解码器已被提出用于量子码，但其性能和局限性仍未得到充分探索。

**Method:** 本文揭示了量子低密度奇偶校验（LDPC）码LP解码的一个关键局限性：某些恒重错误模式会导致模糊的分数解，无法通过独立舍入解决。为解决此问题，研究引入了一种称为有序统计解码（OSD）的后处理技术。

**Result:** 结果表明，增强了OSD的LP解码器在实际应用中能显著提升性能，对于多达数百个量子比特的中间码尺寸，其性能甚至优于采用相同后处理的置信传播解码。

**Conclusion:** 这些发现表明，配备有效后处理的基于LP的解码器为近期量子LDPC码的解码提供了一种有前景的方法。

> **ai_Abstract:** 本研究探讨了量子低密度奇偶校验（LDPC）码线性规划（LP）解码器的能力与局限性。研究发现LP解码器在处理某些恒重错误模式时会产生无法独立解决的模糊分数解。为克服这一局限性，作者提出将有序统计解码（OSD）作为后处理技术与LP解码器结合。实验结果表明，结合OSD的LP解码器在实践中能显著提升性能，并且对于中等规模的量子比特（数百个），其性能甚至优于采用相同后处理的置信传播解码。这表明LP解码器结合有效的后处理技术是解码近期量子LDPC码的一种有前景的方法。

> **摘要翻译:** 解码量子纠错码是实现容错量子计算的关键挑战。在经典设置中，线性规划（LP）解码器提供可证明的性能保证，并能利用快速实用的优化算法。尽管LP解码器已被提出用于量子码，但其性能和局限性仍未得到充分探索。在这项工作中，我们揭示了量子低密度奇偶校验（LDPC）码LP解码的一个关键局限性：某些恒重错误模式会导致模糊的分数解，无法通过独立舍入解决。为解决此问题，我们引入了一种称为有序统计解码（OSD）的后处理技术，这在实践中显著提升了LP解码性能。我们的结果表明，增强了OSD的LP解码，对于多达数百个量子比特的中间码尺寸，其性能甚至优于采用相同后处理的置信传播。这些发现表明，配备有效后处理的基于LP的解码器为近期量子LDPC码的解码提供了一种有前景的方法。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [862] [Hybrid oscillator-qudit quantum processors: stabilizer states and symplectic operations](https://arxiv.org/abs/2508.04819)
> *混合振子-qudit量子处理器：稳定子态和辛操作*

*Sayan Chakraborty, Victor V. Albert* | **Category: cs.IT, math-ph, math.OA, quant-ph** | **Updated: 2025-08-06**

**Keywords:** 混合量子系统, 稳定子态, 纠错码, GKP码, 辛操作

**Comment:** 

> **TL;DR:** 该研究构建了混合离散-连续变量系统的稳定子态和纠错码，推广了GKP形式论，并展示了这些态的独特量子纠缠特性，无法通过辛操作生成。

**AI_Comments:** 这篇论文通过将离散变量qudit与连续变量谐振子结合，提出了一个新颖的混合量子系统稳定子态和纠错码的构建方法。其创新之处在于将qudit的离散相空间融入连续变量的框架中，并揭示了这些混合态所特有的、无法通过传统辛操作生成的量子纠缠，这对于量子计算和量子信息处理中的资源状态识别具有重要意义。该研究为开发更鲁棒的量子处理器提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 推广Gottesman-Kitaev-Preskill (GKP) 量子格形式论，构建离散-连续变量组合系统上的稳定子态和纠错码，以实现对非对易位置和动量位移的测量，并探索混合量子系统的资源特性。

**Method:** 构建离散-连续变量组合系统上的稳定子态和纠错码；将qudit的离散相空间吸收到谐振子的连续变量参数化的混合相空间中；通过特定操作或编码获得简单混合态；通过将稳定子码与非交换环面关联并通过Morita等价获取逻辑算子来构建通用混合纠错码；提供实例。

**Result:** 成功构建了离散-连续变量组合系统上的稳定子态和纠错码；提出了将qudit离散相空间吸收到连续变量参数化的混合相空间的框架；发现混合量子格的晶胞随qudit维度增长，可同时测量大范围非对易位置和动量位移；这些态的振子-qudit纠缠无法通过辛操作生成，使其成为一种独特的量子资源；构建了通用混合纠错码。

**Conclusion:** 该研究成功构建了混合离散-连续变量系统上的稳定子态和纠错码，并展示了这些态独特的、无法通过辛操作生成的量子纠缠特性，使其成为有价值的量子资源。

> **ai_Abstract:** 本文提出了一种在离散变量和连续变量系统组合上构建稳定子态和纠错码的新框架，该框架是Gottesman-Kitaev-Preskill (GKP) 量子格形式论的推广。研究将qudit的离散相空间融入由谐振子连续变量参数化的混合相空间，实现了对非对易位置和动量位移的广泛测量。文中还探讨了生成简单混合态的方法，并指出这些态独特的振子-qudit纠缠无法通过辛操作生成，从而突显了其作为量子资源的价值。此外，文章还构建了通用混合纠错码，并通过实例进行了验证。

> **摘要翻译:** 我们在离散变量系统和连续变量系统的组合上构建了稳定子态和纠错码，推广了Gottesman-Kitaev-Preskill (GKP) 量子格形式论。我们的框架将qudit的离散相空间吸收到一个完全由谐振子的连续变量参数化的混合相空间中。混合量子格的晶胞随qudit维度增长，提供了一种同时测量任意大范围非对易位置和动量位移的方法。简单的混合态可以通过对Gottesman-Kitaev-Preskill (GKP) 态和Pauli本征态应用条件位移，或者通过将稳定子态的一些物理qudit编码到GKP码中来获得。这些态的振子-qudit纠缠不能使用辛（即高斯-克利福德）操作生成，这将其与振子和qudit稳定子态的张量积区分开来，使其成为一种资源。我们通过将稳定子码与非交换环面关联并通过Morita等价获取逻辑算子来构建通用混合纠错码。我们提供了使用交换矩阵、整数辛矩阵和二元码的例子。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [867] [Anti-Jamming Sensing with Distributed Reconfigurable Intelligent Metasurface Antennas](https://arxiv.org/abs/2508.04964)
> *基于分布式可重构智能超表面天线的抗干扰感知*

*Zhaowei Wang, Yunsong Huang, Weicheng Liu, Hui-Ming Wang* | **Category: cs.IT, cs.LG, eess.SP** | **Updated: 2025-08-07**

**Keywords:** 分布式感知, 可重构智能超表面天线, 深度强化学习, 抗干扰, 射频感知

**Comment:** 

> **TL;DR:** 本文提出了一种基于分布式可重构智能超表面天线（RIMSA）的射频感知系统，利用深度强化学习和神经网络来优化波束形成和感知结果映射，并设计了抗干扰损失函数。仿真结果表明，该系统在对抗环境影响和干扰攻击方面比集中式系统表现出更高效和高精度的感知性能。

**AI_Comments:** 该论文提出了一种创新方法，通过利用分布式RIMSA的可编程特性来增强射频感知的鲁棒性。DRL用于动态波束形成、神经网络用于感知结果映射，并结合考虑SINR的损失函数，有效解决了环境干扰和干扰攻击的关键挑战。分布式架构是一个重要的创新点，显示出优于集中式系统的性能，这对于复杂无线电环境中的实际应用前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 传统的射频感知方法容易受到恶劣传播信道（如衰落和噪声）以及恶意干扰攻击的影响，导致在不可预测和不利的无线电环境中感知精度下降。

**Method:** 1. 部署多个分布式可重构智能超表面天线接收器（RIMSA Rxs）。2. 通过编程RIMSA Rxs的波束形成模式来提高接收信号质量。3. 将射频感知问题建模为波束形成模式和接收信号到感知结果映射的联合优化问题。4. 引入深度强化学习（DRL）算法来计算最佳波束形成模式。5. 使用神经网络将接收信号转换为感知结果。6. 设计一个考虑接收信号信号与干扰加噪声比（SINR）的综合损失函数，以应对干扰攻击。

**Result:** 1. 所提出的分布式RIMSA系统实现了更高效的感知性能。2. 比集中式实现更好地克服了环境影响。3. 即使在干扰攻击下也能确保高精度感知性能。

**Conclusion:** 所提出的分布式RIMSA系统通过集成深度强化学习、神经网络以及考虑SINR的损失函数，相比集中式方法，在对抗环境干扰和干扰攻击方面表现出卓越且鲁棒的射频感知能力。

> **ai_Abstract:** 本文提出了一种新颖的分布式可重构智能超表面天线（RIMSA）系统，用于鲁棒的射频（RF）感知。为解决恶劣传播信道和干扰攻击等挑战，该系统利用多个RIMSA接收器编程波束形成模式，以提高信号质量。射频感知被构建为一个联合优化问题，通过深度强化学习（DRL）算法实现最佳波束形成，并使用神经网络进行信号到结果的映射。为对抗干扰，设计了一个包含信号与干扰加噪声比（SINR）的综合损失函数。仿真结果表明，所提出的分布式RIMSA系统优于集中式实现，即使在易受干扰的环境中也能提供更高效和准确的感知性能。

> **摘要翻译:** 无线电频率（RF）信号用于无线感知已获得越来越多的关注。然而，无线电环境是不可预测且通常不利的，传统射频感测方法的感测精度经常受到从发射器到接收器的不利传播信道（如衰落和噪声）的影响。在本文中，我们提出采用分布式可重构智能超表面天线（RIMSA）来检测物体的存在和位置，其中多个RIMSA接收器（RIMSA Rxs）部署在不同位置。通过编程它们的波束形成模式，RIMSA Rxs可以提高接收信号的质量。射频感知问题被建模为波束形成模式和接收信号到感知结果映射的联合优化问题。为了解决这个挑战，我们引入了一种旨在计算最佳波束形成模式的深度强化学习（DRL）算法，以及一个旨在将接收信号转换为感知结果的神经网络。此外，恶意攻击者可能会发动干扰攻击来扰乱感知过程。为了在易受干扰的环境中实现有效感知，我们设计了一个综合损失函数，该函数考虑了接收信号的信号与干扰加噪声比（SINR）。仿真结果表明，所提出的分布式RIMSA系统可以比集中式实现实现更高效的感知性能，并更好地克服环境影响。此外，所引入的方法即使在干扰攻击下也能确保高精度感知性能。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [872] [Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond Vibes](https://arxiv.org/abs/2508.05469)
> *让我们一步步衡量信息：超越直觉的LLM评估*

*Zachary Robertson, Sanmi Koyejo* | **Category: cs.IT, cs.LG** | **Updated: 2025-08-07**

**Keywords:** AI评估, f-互信息, 博弈抵抗, 无真实标签, 大语言模型

**Comment:** 

> **TL;DR:** 开发了一种基于f-互信息的新型抗博弈机制，用于在没有真实标签的情况下评估AI系统，该机制比LLM评判更鲁棒且能准确区分忠实与策略性智能体。

**AI_Comments:** 这篇论文提出了一种创新的、基于信息论的AI系统评估方法，解决了当前LLM评估中缺乏真实标签和易受操纵的问题。其核心在于利用f-互信息的博弈抵抗特性，为AI评估提供了一个更客观、更鲁棒的框架。特别值得注意的是，该方法在多个领域表现出卓越的鉴别能力和抗操纵性，并且揭示了评估性能与数据压缩比之间的有趣关系。这对于提高AI系统评估的可靠性和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI系统评估方法在缺乏真实标签时存在困难，且LLM评判可能出现系统性评估反转，偏好虚假内容。本研究旨在开发一种更可靠的无真实标签评估机制。

**Method:** 该研究利用博弈抵抗与输出质量之间的联系，证明f-互信息度量是唯一在自然条件下具有博弈抵抗性的机制。虽然香农互信息样本复杂度高，但有界度量如总变差距离仍然可行。

**Result:** 经验上，在十个领域中，所有信息论机制都能完美区分忠实和策略性智能体。LLM评判则出现系统性评估反转。新机制对抗对抗性操纵的鲁棒性比当前实践高10-100倍。性能遵循倒U形曲线，在压缩比为10:1时达到峰值，此时智能体响应表现出最佳信息多样性。

**Conclusion:** f-互信息度量提供了一种有效且鲁棒的无真实标签AI系统评估方法，优于当前的LLM评判，并且在特定压缩比下表现最佳。

> **ai_Abstract:** 本研究提出了一种基于f-互信息的新型无真实标签AI系统评估机制。该机制利用博弈抵抗性原理，证明f-互信息度量是唯一抗博弈的。实证结果表明，与LLM评判偏好虚假内容相反，信息论机制能完美区分忠实和策略性智能体，并表现出10-100倍的对抗性操纵鲁棒性。研究还发现性能与压缩比呈倒U形关系，在特定比率下达到最佳信息多样性。

> **摘要翻译:** 我们开发了在没有真实标签的情况下评估AI系统的机制，方法是利用博弈抵抗与输出质量之间的联系。数据处理不等式确保事后尝试操纵度量会降低信息内容和任务性能。我们证明f-互信息度量是在自然条件下（监督者作为代理）唯一的博弈抵抗机制。虽然香农互信息面临指数级的样本复杂度，但诸如总变差距离等有界度量仍然是可行的。从经验上看，在从翻译到同行评审的十个领域中，所有信息论机制都能完美区分忠实和策略性智能体（d > 0.5）。相比之下，LLM评判表现出系统性评估反转，偏好虚假内容而非准确摘要。我们的机制对抗对抗性操纵的鲁棒性比当前实践高10-100倍。我们还发现性能遵循倒U形曲线，随着压缩比的变化而变化，在10:1时达到峰值，此时智能体响应表现出最佳信息多样性（3个有效维度），这从偏差-方差的角度解释了我们的方法何时最有效。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [877] [Linearity of $\mathbb{Z}_{2^L}$-Linear Codes via Schur Product](https://arxiv.org/abs/2309.12291)
> *通过 Schur 积研究 $\mathbb{Z}_{2^L}$-线性码的线性性质*

*Gustavo T. Bastos, Maiara F. Bollauf, Agnaldo J. Ferrari, Øyvind Ytrehus* | **Category: cs.IT** | **Updated: 2025-08-07**

**Keywords:** $\mathbb{Z}_{2^L}$-线性码, Schur 积, 广义格雷映射, 关联码, 分解码

**Comment:** 

> **TL;DR:** 本文提出了一种利用 Schur 积和广义格雷映射来研究$\mathbb{Z}_{2^L}$-线性码线性性质的创新方法，通过定义关联码和分解码，建立了$\mathbb{Z}_{2^L}$-线性码与分解码线性性质的联系，并构造了新的线性码，同时提供了一种检查非线性的充分条件，最后验证了已知码的线性。

**AI_Comments:** 本文提出了一种新颖的方法，利用 Schur 积和特定的二元码（关联码和分解码）来分析$\mathbb{Z}_{2^L}$-线性码的线性性质，这在编码理论中具有创新性。其方法不仅建立了不同码类型线性性质之间的联系，还提供了一种检查非线性的简便条件，并成功验证了多个著名码的线性，显示了其方法的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种创新方法，用于通过广义格雷映射研究从$\mathbb{Z}_{2^L}$-加性码导出的$\mathbb{Z}_{2^L}$-线性码的线性性质。

**Method:** 研究方法包括定义关联码和分解码，并通过考虑码字之间的 Schur 积来确定$\mathbb{Z}_{2^L}$-线性码的线性性质。此外，还从嵌套二元码构造了$\mathbb{Z}_{2^L}$-加性码，并提出了一个通过简单二元运算检查非线性性质的充分条件。

**Result:** 研究结果建立了$\mathbb{Z}_{2^L}$-线性码的线性性质与$\mathbb{Z}_4$和$\mathbb{Z}_8$-加性码的分解码的线性性质之间的联系。通过构造，得到了线性的$\mathbb{Z}_{2^L}$-线性码。同时，提供了一个通过关联码中的简单二元运算检查$\mathbb{Z}_{2^L}$-线性码非线性性质的充分条件。

**Conclusion:** 本文提出的方法成功地应用于验证了著名的$\mathbb{Z}_{2^L}$-线性码构造（包括 Hadamard、单纯形和 MacDonald 码）的线性性质。

> **ai_Abstract:** 本文提出了一种创新方法，利用广义格雷映射和 Schur 积来探究$\mathbb{Z}_{2^L}$-线性码的线性性质。该方法通过引入关联码和分解码，建立了$\mathbb{Z}_{2^L}$-线性码与分解码线性性质之间的联系，尤其针对$\mathbb{Z}_4$和$\mathbb{Z}_8$-加性码。此外，研究从嵌套二元码构造了线性的$\mathbb{Z}_{2^L}$-加性码，并提出了一个通过简单二元运算检查非线性性质的充分条件。最终，该方法成功验证了包括 Hadamard、单纯形和 MacDonald 码在内的知名$\mathbb{Z}_{2^L}$-线性码构造的线性。

> **摘要翻译:** 我们提出了一种创新方法，用于通过广义格雷映射研究从$\mathbb{Z}_{2^L}$-加性码导出的$\mathbb{Z}_{2^L}$-线性码的线性性质。为此，我们定义了两种相关的二元码：关联码和分解码。通过考虑码字之间的 Schur 积，我们可以确定相应$\mathbb{Z}_{2^L}$-线性码的线性性质。因此，我们建立了$\mathbb{Z}_{2^L}$-线性码的线性性质与$\mathbb{Z}_4$和$\mathbb{Z}_8$-加性码的分解码的线性性质之间的联系。此外，我们从嵌套二元码构造了$\mathbb{Z}_{2^L}$-加性码，从而得到了线性的$\mathbb{Z}_{2^L}$-线性码。这种构造涉及多层二元码，其中一层码是前一层码的平方。我们还提出了一个充分条件，允许通过在其各自关联码中的简单二元运算来检查$\mathbb{Z}_{2^L}$-线性码的非线性性质。最后，我们运用我们的论证来验证了著名的$\mathbb{Z}_{2^L}$-线性码构造（包括 Hadamard、单纯形和 MacDonald 码）的线性性质。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [89] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
> *MissMecha：一个用于研究缺失数据机制的多合一Python软件包*

*Youran Zhou, Mohamed Reda Bouadjenek, Sunil Aryal* | **Category: cs.LG, cs.MS** | **Updated: 2025-08-06**

**Keywords:** 缺失数据, 数据机制, Python包, 数据模拟, 异构数据

**Comment:** 

> **TL;DR:** MissMecha是一个开源Python工具包，用于模拟、可视化和评估混合类型表格数据中的缺失数据，解决了现有工具的局限性。

**AI_Comments:** MissMecha的创新之处在于其“多合一”的特性，解决了现有工具碎片化、机制受限且仅限于数值变量的问题。它对混合类型数据（数值和类别）的支持，以及包含可视化和评估工具，使其在缺失数据机制研究领域具有重要意义。这有助于研究人员更全面地理解和处理真实世界中复杂的缺失数据问题。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界数据集中普遍存在不完整数据，其缺失机制复杂且难以观测。现有工具在模拟缺失数据方面存在碎片化、机制受限且主要关注数值变量的局限性，忽略了真实世界表格数据的异构性。

**Method:** 论文提出了MissMecha，一个开源Python工具包。它能够在MCAR、MAR和MNAR假设下模拟、可视化和评估缺失数据，并支持数值和类别特征，适用于混合类型表格数据集。该工具还包括视觉诊断、MCAR测试实用程序以及类型感知的插补评估指标。

**Result:** MissMecha提供了一个统一的平台，支持对数值和类别特征的混合类型表格数据进行机制感知研究。它能够模拟、可视化和评估缺失数据，并包含视觉诊断、MCAR测试工具和类型感知插补评估指标。

**Conclusion:** MissMecha为处理不完整数据的研究人员和实践者提供了一个统一的平台，旨在支持数据质量研究、基准测试和教育，解决了现有工具的碎片化和局限性。

> **ai_Abstract:** MissMecha是一个新的开源Python工具包，旨在解决现有缺失数据模拟工具的局限性。它提供了一个统一的平台，用于在MCAR、MAR和MNAR假设下模拟、可视化和评估混合类型表格数据（包括数值和类别特征）中的缺失数据。该工具包包含视觉诊断、MCAR测试实用程序和类型感知的插补评估指标，以支持数据质量研究、基准测试和教育。

> **摘要翻译:** 现实世界数据集中的不完整数据是一个持续存在的挑战，通常受复杂且不可观测的缺失机制支配。模拟缺失已成为理解其对学习和分析影响的标准方法。然而，现有工具碎片化、机制受限，并且通常只关注数值变量，忽视了真实世界表格数据的异构性。我们提出了MissMecha，一个开源Python工具包，用于在MCAR、MAR和MNAR假设下模拟、可视化和评估缺失数据。MissMecha支持数值和类别特征，从而能够在混合类型表格数据集上进行机制感知研究。它包括视觉诊断、MCAR测试实用程序和类型感知的插补评估指标。MissMecha旨在支持数据质量研究、基准测试和教育，为处理不完整数据的研究人员和实践者提供了一个统一的平台。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [102] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
> *边缘辅助协同微调，用于多用户个性化人工智能生成内容 (AIGC)*

*Nan Li, Wanting Yang, Marie Siew, Zehui Xiong, Binbin Chen, Shiwen Mao, Kwok-Yan Lam* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 边缘AIGC, 扩散模型, 联邦学习, LoRA, 个性化

**Comment:** 

> **TL;DR:** 提出一种边缘辅助分层联邦聚合框架，利用LoRA和聚类技术，解决边缘设备上多用户个性化AIGC的隐私、效率和通信问题。

**AI_Comments:** 该论文的创新点在于提出了一个结合联邦学习、LoRA和聚类机制的分层聚合框架，有效解决了边缘设备上多用户个性化AIGC的计算效率、隐私保护和个性化需求。其通过簇内和簇间聚合，实现了更精细的个性化和知识共享，同时兼顾了边缘推理的效率和数据隐私。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型计算量大，边缘设备资源受限；云解决方案在多用户边缘AIGC场景中存在隐私风险、个性化效率低和通信成本高的问题。

**Method:** 提出一种新颖的集群感知分层联邦聚合框架。该框架基于LoRA进行参数高效的本地微调，首先根据上传任务需求的相似性对客户端进行聚类，然后在服务器端进行簇内聚合以增强个性化。随后，实现簇间知识交互以实现跨不同簇的混合风格内容生成。该框架通过联邦学习同时训练设备上的个性化模型和服务器上带有多个LoRA适配器的共享全局模型，并在传输前对所有提示进行编码以缓解隐私风险。

**Result:** 评估表明该框架在边缘约束下，实现了加速收敛，同时保持了可扩展多用户个性化AIGC服务的实用可行性。

**Conclusion:** 该框架有效地解决了边缘设备上多用户个性化AIGC的挑战，通过其分层联邦聚合和隐私保护机制，实现了高效、可扩展且个性化的内容生成。

> **ai_Abstract:** 本文针对扩散模型在边缘设备上进行多用户个性化AIGC时面临的计算量大、隐私和通信问题，提出了一种集群感知分层联邦聚合框架。该框架利用LoRA技术进行高效微调，通过客户端聚类、簇内聚合和簇间知识交互，在联邦学习范式下实现个性化模型训练和共享全局模型增强，并对提示进行编码以保护隐私。实验证明，该框架在边缘环境下能加速收敛并提供可扩展的个性化AIGC服务。

> **摘要翻译:** 扩散模型（DMs）已成为高质量内容生成的强大工具，但其密集的推理计算需求对资源受限的边缘设备构成了挑战。基于云的解决方案有助于计算，但在解决多用户边缘AIGC场景中的隐私风险、个性化效率和通信成本方面往往力不从心。为了弥补这一差距，我们首先分析了现有的个性化内容合成中的边缘AIGC应用，揭示了它们在效率和可扩展性方面的局限性。然后，我们提出了一种新颖的集群感知分层联邦聚合框架。该框架基于通过低秩适应（LoRA）进行的参数高效本地微调，首先根据上传任务需求的相似性对客户端进行聚类，然后在服务器端进行簇内聚合以增强个性化。随后，实现簇间知识交互范式，以实现跨不同簇的混合风格内容生成。基于联邦学习（FL）协作，我们的框架同时在设备上训练个体用户的个性化模型，并在服务器上训练一个通过多个LoRA适配器增强的共享全局模型，从而实现高效的边缘推理；同时，所有用于聚类和推理的提示在传输前都经过编码，从而进一步降低了明文泄露的风险。我们的评估表明，该框架在边缘约束下实现了加速收敛，同时保持了可扩展多用户个性化AIGC服务的实用可行性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [110] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
> *一个用于少样本学习的基础多模态模型*

*Pengtao Dang, Tingbo Guo, Sha Cao, Chi Zhang* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 少样本学习, 多模态模型, 大型模型, 科学数据, M3F, M3FD

**Comment:** 

> **TL;DR:** 本文提出了一个大型多模态模型（M3F）和一个新数据集（M3FD），旨在改善少样本学习，特别是在数据稀缺的科学领域。

**AI_Comments:** 本文的创新之处在于利用大型多模态模型解决多模态、少样本学习的挑战，特别是在数据稀缺的科学领域。通过创建专用的M3FD数据集和M3F框架，并提供配套工具，该研究不仅提出了有效的解决方案，也为该领域的进一步研究和应用奠定了基础，具有重要的实践意义和推广价值。

<details>
  <summary>Details</summary>

**Motivation:** 少样本学习（FSL）在生物医学、环境、材料和机械科学等领域至关重要，这些领域样本有限，数据收集成本高昂、耗时或受伦理限制。现有FSL模型在泛化能力方面需要改进。

**Method:** 本研究提出了一种创新方法，通过展示一个在涵盖不同领域、任务类型和输入模态的独立任务集上训练的大型多模态模型（LMMM），可以显著提高FSL模型的泛化能力。为此，研究团队首先构建了一个多模态模型少样本数据集（M3FD，超过10K+少样本），其中包括2D RGB图像、2D/3D医学扫描、表格和时间序列数据集，并从中手动策划了分类等FSL任务。此外，他们引入了M3F（Multi-Modal Model for Few-shot learning framework），一个为数据受限的科学应用量身定制的新型大型多模态模型框架。M3F通过模块化管道支持各种科学数据类型，并通过在M3FD上进行微调来提高模型性能。

**Result:** 该大型多模态模型（M3F）在相同类型的任务上显著提高了少样本学习模型的泛化能力，优于基于传统元学习的模型。通过在M3FD上进行微调，M3F提高了模型性能，使LMMM在现实世界的FSL部署中变得可行。

**Conclusion:** 所构建的数据集（M3FD）和框架（M3F）提供了一个统一、可扩展的解决方案，显著降低了在数据稀缺的科学领域应用大型多模态模型的门槛。

> **ai_Abstract:** 本文介绍了一个名为M3F的新型大型多模态模型框架，以及一个名为M3FD的新型多模态少样本数据集，旨在增强少样本学习，特别是在数据有限的科学领域。M3F通过在多样化的任务和模态上进行训练和微调，展示了优于传统元学习方法的泛化能力，使得大型多模态模型在现实世界的少样本学习应用中变得可行。M3FD和配套工具进一步降低了在数据稀缺科学领域应用LMMM的障碍。

> **摘要翻译:** 少样本学习（FSL）是一种机器学习范式，旨在从少量标记示例（通常每个类别少于10个）中泛化模型。FSL在生物医学、环境、材料和机械科学中尤为关键，这些领域样本有限，数据收集通常成本高昂、耗时或受伦理约束。在本研究中，我们通过展示一个在涵盖不同领域、任务类型和输入模态的独立任务集上训练的大型多模态模型（LMMM），可以显著提高FSL模型的泛化能力，在相同类型的任务上优于基于传统元学习的模型，从而提出了一种创新的FSL方法。为了支持这一点，我们首先构建了一个多模态模型少样本数据集（M3FD，超过10K+少样本），其中包括2D RGB图像、2D/3D医学扫描、表格和时间序列数据集，并从中手动策划了分类等FSL任务。我们进一步引入了M3F（Multi-Modal Model for Few-shot learning framework），一个为数据受限的科学应用量身定制的新型大型多模态模型框架。M3F通过模块化管道支持各种科学数据类型。通过在M3FD上进行微调，M3F提高了模型性能，使LMMM在现实世界的FSL部署中变得可行。源代码位于https://github.com/ptdang1001/M3F。为了普及对复杂FSL数据的访问并促进公共使用的可重复性，M3FD与一个灵活且用户友好的工具配对，该工具能够高效查询、任务特定采样和预处理。总而言之，我们的数据集和框架提供了一个统一、可扩展的解决方案，显著降低了在数据稀缺的科学领域应用LMMM的门槛。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [117] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
> *AttriLens-Mol：属性引导的强化学习在大型语言模型分子性质预测中的应用*

*Xuan Lin, Long Chen, Yile Wang* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 大型语言模型, 分子性质预测, 强化学习, 属性引导, 可解释性

**Comment:** 

> **TL;DR:** AttriLens-Mol是一个利用属性引导强化学习框架，提升大型语言模型在分子性质预测中性能的方法，通过奖励机制引导模型生成相关属性，并实现了优于现有方法的表现。

**AI_Comments:** AttriLens-Mol的创新之处在于其将强化学习与属性引导相结合，解决了LLM在分子性质预测中生成冗余或不相关推理的问题。通过引入精巧设计的奖励机制（格式、计数、合理性奖励），该方法能够有效引导模型挖掘和利用其内在的分子属性知识，从而提升预测性能和可解释性。这项工作为LLM在特定领域（如化学）的应用提供了新的范式，强调了在复杂推理任务中引导模型生成高质量中间表示的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在分子性质预测中显示出潜力，但常依赖人工设计的提示和思维链模板，导致推理冗长且缺乏相关性。现有先进的大型推理模型（如DeepSeek-R1）虽采用强化学习，但其推理过程可能过于冗长且相关性不足。

**Method:** AttriLens-Mol是一个属性引导的强化学习框架。它通过三种奖励机制引导模型的推理过程：1) 格式奖励，鼓励基于属性的结构化输出；2) 计数奖励，避免枚举不相关属性；3) 合理性奖励，利用先进的LLM和RDKit验证生成属性的相关性。这种方法隐式地激发了模型在推理过程中对相关分子属性的内在知识。

**Result:** 在分布内和分布外数据集上的实验表明，使用AttriLens-Mol方法训练7B大小的R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型（仅用4,000个样本）显著提升了性能，取得了与监督微调模型（如Mol-Instructions, ChemDFM）和先进模型（如GPT-3.5, GPT-4o, DeepSeek-V3, DeepSeek-R1）相当或更好的结果。此外，当提取的属性用作可解释决策树模型的特征时，其性能优于通过提示LLM生成的属性。

**Conclusion:** AttriLens-Mol通过属性引导的强化学习有效激发了模型内在的相关且具有预测性的分子属性知识，从而在分子性质预测中实现了更高的可解释性和性能。

> **ai_Abstract:** AttriLens-Mol提出了一种属性引导的强化学习框架，旨在提高大型语言模型在分子性质预测中的效率和相关性。该框架通过设计格式、计数和合理性奖励，引导LLM生成结构化且相关的分子属性，克服了现有方法推理冗长和相关性不足的问题。实验证明，AttriLens-Mol在多种数据集上显著提升了模型的预测性能，甚至超越了多种先进模型和监督微调方法，并且其提取的属性增强了模型的可解释性。

> **摘要翻译:** 大型语言模型（LLMs）在辅助分子性质预测任务中展现出前景，但通常依赖于人工设计的提示和思维链模板。虽然最近先进的大型推理模型如DeepSeek-R1采用强化学习来延长“思考”过程，但它们的推理可能冗长且缺乏相关性。我们引入了AttriLens-Mol，一个用于LLM分子性质预测的属性引导强化学习框架。AttriLens-Mol通过以下方式引导模型的推理：(1) 格式奖励，鼓励基于属性的结构化输出；(2) 计数奖励，避免枚举不相关属性；(3) 合理性奖励，使用先进的LLMs和RDKit来验证生成属性的相关性。这种方法在推理过程中隐式地激发了模型对相关分子属性的内在知识，从而更有效地进行分子性质预测。在分布内和分布外数据集上的实验表明，使用我们提出的AttriLens-Mol方法在4,000个样本上训练7B大小的R1-Distilled-Qwen2.5和R1-Distilled-LLaMA3.1模型，显著提升了性能，获得了与监督微调模型（Mol-Instructions、ChemDFM等）和先进模型（GPT-3.5、GPT-4o、DeepSeek-V3、DeepSeek-R1等）相当或更好的结果。此外，我们为目标性质提取的属性，当用作可解释决策树模型的特征时，与通过提示LLM生成的属性相比，表现出卓越的性能。这表明AttriLens-Mol有效地激发了更相关和更具预测性的分子属性，从而提高了性质预测的可解释性和性能。我们已在https://github.com/szu-tera/AttriLens-Mol发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
> *PA-RNet：多模态时间序列预测的扰动感知推理网络*

*Chanjuan Liu, Shengzhi Wang, Enqiang Zhu* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 多模态时间序列预测, 文本噪声, 扰动感知网络, 鲁棒性, 交叉模态注意力

**Comment:** 

> **TL;DR:** 提出PA-RNet，一个处理文本噪声的多模态时间序列预测模型，通过扰动感知模块和交叉模态注意力提高鲁棒性，并有理论和实验支持。

**AI_Comments:** 本文的创新点在于明确识别并解决了多模态时间序列预测中文本模态噪声的挑战，通过引入扰动感知模块和理论证明提供了强大的鲁棒性保证。提出的文本扰动管道也为未来研究提供了一个标准化的评估方法，具有较高的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态时间序列预测方法忽略了文本数据中固有的扰动（无关、嘈杂或模糊内容），这些扰动会显著降低模型性能，特别是在噪声强度变化或结构不一致时。

**Method:** 本文提出了PA-RNet（扰动感知推理网络），一个鲁棒的多模态预测框架。PA-RNet包含一个扰动感知投影模块和一个跨模态注意力机制，旨在有效分离文本嵌入中的噪声，同时保持语义有意义的表示。此外，还引入了一个文本扰动管道，用于系统评估模型在不同程度文本噪声下的鲁棒性。

**Result:** PA-RNet在不同领域和时间设置的广泛实验中持续优于最先进的基线模型。理论上，PA-RNet对文本输入具有Lipschitz连续性，并且所提出的扰动模块能够降低预期预测误差，为噪声条件下的稳定性提供了强有力的保证。

**Conclusion:** PA-RNet通过其独特的扰动感知设计，成功解决了多模态时间序列预测中文本模态的噪声干扰问题，显著提升了模型的鲁棒性和泛化能力，并得到了理论和实验的双重验证。

> **ai_Abstract:** 本文提出了PA-RNet，一个用于多模态时间序列预测的鲁棒框架，旨在解决文本模态中常见的噪声干扰问题。PA-RNet通过扰动感知投影模块和跨模态注意力机制，有效分离噪声并保持文本语义表示，从而提高模型泛化能力。该方法在理论上证明了其在噪声条件下的稳定性和误差降低能力，并引入了文本扰动管道进行系统评估。实验结果表明PA-RNet性能优于现有SOTA方法。

> **摘要翻译:** 在实际应用中，多模态时间序列数据经常受到干扰，尤其是在文本模态中。现有的多模态时间序列预测方法往往忽略了文本数据中固有的扰动，其中不相关、嘈杂或模糊的内容会显著降低模型性能，特别是当噪声表现出不同强度或源于结构不一致时。为了解决这一挑战，我们提出了PA-RNet（多模态时间序列预测的扰动感知推理网络），一个鲁棒的多模态预测框架。PA-RNet具有扰动感知投影模块和跨模态注意力机制，能够有效分离文本嵌入中的噪声，同时保持语义有意义的表示，从而增强模型的泛化能力。理论上，我们建立了PA-RNet对文本输入的Lipschitz连续性，并证明了所提出的扰动模块可以降低预期预测误差，为噪声条件下的稳定性提供了强有力的保证。此外，我们引入了一个文本扰动管道，可以无缝地集成到现有的多模态时间序列预测任务中，从而系统地评估模型在不同程度文本噪声存在下的鲁棒性。在不同领域和时间设置下的广泛实验表明，PA-RNet持续优于最先进的基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [132] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
> *InfoQ：基于全局信息流的混合精度量化*

*Mehmet Emre Akbulut, Hazem Hesham Yousef Shalby, Fabrizio Pittorino, Manuel Roveri* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 混合精度量化, 信息流, 量化敏感度, 整数线性规划, 深度神经网络

**Comment:** 

> **TL;DR:** InfoQ是一种训练无关的混合精度量化框架，通过测量层量化对全局信息流的影响来分配位宽，实现了更快的搜索和更好的精度。

**AI_Comments:** InfoQ的创新之处在于其“全局信息流”视角来衡量量化敏感度，并将其转化为一个无需训练的位宽搜索过程。这种方法显著降低了计算成本，并解决了传统局部启发式方法的局限性。其提出的通过互信息测量敏感度并结合整数线性规划求解位宽分配，为混合精度量化提供了一个高效且理论上更合理的方案，对于资源受限设备的深度学习部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 混合精度量化对资源受限设备部署深度神经网络至关重要，但寻找最优位宽是一个复杂的组合优化问题。当前最先进的方法计算昂贵或依赖局部启发式，未能捕捉量化误差的全局级联效应。

**Method:** 提出InfoQ框架，在位宽搜索阶段无需训练。它通过一次前向传播，评估不同位宽下各层量化对后续层互信息的相应变化，量化每层量化对网络信息流的影响。然后将这些得分用于构建整数线性规划问题，以在给定预算下最小化总敏感度，并高效求解。

**Result:** InfoQ的搜索阶段无需再训练，相比最先进方法（如LIMPQ）减少了两个数量级的数据使用，同时在MobileNetV2和ResNet18上，ImageNet高压缩率下（14X和10.66X）实现了高达1%的精度提升。

**Conclusion:** InfoQ通过考虑全局信息流来衡量层敏感度，提供了一种高效且高性能的混合精度量化方案，解决了传统方法计算成本高和忽略全局效应的问题。

> **ai_Abstract:** 该论文提出了一种名为InfoQ的混合精度量化（MPQ）新框架，旨在解决现有MPQ方法计算成本高昂且未能捕捉量化误差全局效应的问题。InfoQ的核心思想是通过评估各层量化对整个网络信息流（通过互信息变化衡量）的影响来确定其敏感度，而非仅依赖局部特性。该框架的位宽搜索阶段无需额外训练，通过将位宽分配建模为整数线性规划问题并高效求解，实现了在给定资源预算下的敏感度最小化。实验结果表明，InfoQ在搜索效率上远超现有方法，并在高压缩率下实现了显著的精度提升。

> **摘要翻译:** 混合精度量化（MPQ）对于在资源受限设备上部署深度神经网络至关重要，但为每层找到最佳位宽是一个复杂的组合优化问题。当前最先进的方法依赖于计算成本高昂的搜索算法或局部敏感性启发式代理（如Hessian），这些方法未能捕捉量化误差的级联全局效应。在这项工作中，我们认为层的量化敏感度不应由其局部特性衡量，而应由其对整个网络信息流的影响来衡量。我们引入了InfoQ，一个新颖的MPQ框架，其位宽搜索阶段无需训练。InfoQ通过以不同位宽量化每层，并通过一次前向传播测量后续层互信息的相应变化来评估层敏感度。这量化了每层量化对网络信息流的影响程度。所得分数用于将位宽分配表述为一个整数线性规划问题，该问题被高效求解以在给定预算（例如，模型大小或BitOps）下最小化总敏感度。我们无需再训练的搜索阶段提供了卓越的搜索时间/精度权衡（与LIMPQ等最先进方法相比，数据使用量减少了两个数量级），同时在ImageNet上，MobileNetV2和ResNet18在高压缩率下（14倍和10.66倍）实现了高达1%的精度提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [139] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
> *HCRide：协调乘客公平性与司机偏好以实现以人为本的网约车服务*

*Lin Jiang, Yu Yang, Guang Wang* | **Category: cs.LG, cs.SI** | **Updated: 2025-08-06**

**Keywords:** 网约车, 乘客公平性, 司机偏好, 多智能体强化学习, 订单调度

**Comment:** 

> **TL;DR:** HCRide是一个以人为本的网约车系统，通过新颖的多智能体强化学习算法（Habic）平衡乘客公平性、司机偏好和系统效率，并在真实世界数据集中表现出显著提升。

**AI_Comments:** HCRide的创新点在于其提出了一种新颖的多智能体强化学习方法（Habic）来解决网约车服务中多方利益（运营商效率、乘客公平性、司机偏好）的复杂权衡问题。该研究通过引入“以人为本”的理念，超越了传统上仅关注经济效益的系统设计，具有重要的实践意义。使用真实世界数据集进行验证增加了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有网约车订单调度系统侧重于提高运营商收入，但这往往会损害乘客体验和司机利益。本研究旨在解决这一问题，设计一个能同时考虑乘客公平性、司机偏好且不牺牲整体系统效率的以人为本的网约车系统。

**Method:** 设计了HCRide系统，其核心是新颖的多智能体强化学习算法——协调导向型Actor-Bi-Critic (Habic)。该算法包含三个主要组件：多智能体竞争机制、动态Actor网络和Bi-Critic网络，旨在优化系统效率、乘客公平性并考虑司机偏好。

**Result:** 与最先进的基线相比，HCRide有效提升了系统效率2.02%、公平性5.39%和司机偏好10.21%。

**Conclusion:** HCRide成功地通过其新颖的多智能体强化学习方法，解决了网约车服务中乘客公平性与司机偏好之间的潜在冲突，并在保持系统效率的同时，显著提升了用户体验。

> **ai_Abstract:** HCRide是一个以人为本的网约车系统，旨在解决现有调度系统忽视乘客和司机体验的问题。该系统通过一种名为Harmonization-oriented Actor-Bi-Critic (Habic)的新型多智能体强化学习算法，有效平衡系统效率、乘客公平性与司机偏好之间的冲突。Habic算法包含多智能体竞争机制、动态Actor网络和Bi-Critic网络。在深圳和纽约市的真实数据集上的实验证明，HCRide在提高系统效率、公平性和司机偏好方面均优于现有基线。

> **摘要翻译:** 订单调度系统在网约车服务中扮演着至关重要的角色，直接影响运营商收入、司机利润和乘客体验。大多数现有工作专注于提高运营商收入方面的系统效率，这可能会导致乘客和司机的糟糕体验。因此，在这项工作中，我们旨在通过同时考虑乘客公平性和司机偏好来设计一个以人为本的网约车系统，而不会损害整体系统效率。然而，实现这一目标并非易事，因为乘客公平性和司机偏好之间存在潜在冲突，优化其中一个可能会牺牲另一个。为了解决这一挑战，我们设计了HCRide，一个基于新颖的多智能体强化学习算法——协调导向型Actor-Bi-Critic (Habic)的以人为本的网约车系统，该算法包括三个主要组件（即多智能体竞争机制、动态Actor网络和Bi-Critic网络），以在考虑司机偏好的情况下优化系统效率和乘客公平性。我们使用来自深圳和纽约市的两个真实世界网约车数据集对HCRide进行了广泛评估。实验结果表明，与最先进的基线相比，我们的HCRide有效提高了系统效率2.02%、公平性5.39%和司机偏好10.21%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [148] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
> *Agnostics：通过通用学习环境进行强化学习，掌握任意编程语言的编码能力*

*Aleksander Boruch-Gruszecki, Yangtian Zi, Zixuan Wu, Tejas Oberoi, Carolyn Jane Anderson, Joydeep Biswas, Arjun Guha* | **Category: cs.LG, cs.PL** | **Updated: 2025-08-06**

**Keywords:** 语言无关, 强化学习, 低资源语言, 代码生成, 大型语言模型

**Comment:** 

> **TL;DR:** Agnostics是一个语言无关的后训练流程，通过评估代码的外部行为，使LLMs能够更好地学习低资源编程语言，并在多语言基准测试中取得了SOTA结果。

**AI_Comments:** Agnostics的创新之处在于其“语言无关”的后训练范式，通过聚焦代码的外部行为验证，有效解决了LLMs在低资源语言上面临的数据和工程瓶颈。这使得单一的验证器能够处理多种语言，极大地提高了训练效率和模型泛化能力。其开源数据集和工具的承诺，将对多语言代码生成领域的研究和应用产生重要推动作用，降低了RL后训练的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在低资源编程语言上表现不佳，因为缺乏预训练数据，且每种新语言都需要定制的后训练数据集、测试工具和强化学习基础设施，这导致了瓶颈。

**Method:** Agnostics通过以下方式实现语言无关的后训练：(i) 使用LLM将现有单元测试数据集重写为I/O格式；(ii) 提供简短配置告知验证器如何编译和运行目标语言；(iii) 在鲁棒的代码执行环境中应用可验证奖励的强化学习（RLVR），通过外部可观察行为判断代码。

**Result:** Agnostics应用于Lua、Julia、R、OCaml和Fortran五种低资源语言时：(1) 将Qwen-3 4B的性能提升至可与16B-70B其他开源模型媲美的水平；(2) 清晰地扩展到更大、更多样化的模型家族（Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini）；(3) 对于≤16B参数的模型，在MultiPL-E和新引入的多语言版本LiveCodeBench上取得了新的state-of-the-art pass@1结果。

**Conclusion:** Agnostics通过提供语言无关的训练数据集、训练代码和即用型配置，使任何编程语言的RL后训练变得像编辑一个简短的YAML文件一样简单。

> **ai_Abstract:** Agnostics是一个创新的语言无关后训练流程，旨在解决大型语言模型在低资源编程语言上代码生成能力不足的问题。通过将代码评估基于其外部可观察行为，并结合LLM重写I/O格式测试数据、提供语言配置和应用可验证奖励强化学习，Agnostics消除了每种语言定制工程的需要。该方法在五种低资源语言上显著提升了LLMs的性能，使小参数模型达到或超越了SOTA水平，并计划开源相关数据集和工具，极大简化了多语言代码生成模型的训练。

> **摘要翻译:** 大型语言模型（LLMs）在Python和JavaScript等高资源语言的代码编写方面已经表现出色，但在对科学和工程至关重要的低资源语言上却步履维艰。除了明显的预训练数据短缺外，后训练本身也是一个瓶颈：每种新语言似乎都需要新的数据集、测试工具和强化学习（RL）基础设施。
我们引入了Agnostics，一个语言无关的后训练流程，它消除了这种针对每种语言的工程工作。其核心思想是仅根据代码的外部可观察行为来判断代码，因此一个单一的验证器可以测试用任何语言编写的解决方案。具体来说，我们（i）使用LLM将现有单元测试数据集重写为I/O格式，（ii）提供一个简短的配置，告诉验证器如何编译和运行目标语言，以及（iii）在鲁棒的代码执行环境中应用可验证奖励的强化学习（RLVR）。
Agnostics应用于五种低资源语言——Lua、Julia、R、OCaml和Fortran——（1）将Qwen-3 4B的性能提升至可与16B-70B其他开源模型媲美的水平；（2）清晰地扩展到更大、更多样化的模型家族（Qwen-3 8B，DeepSeek Coder 6.7B Instruct，Phi 4 Mini）；以及（3）对于≤16B参数的模型，在MultiPL-E和我们引入的新的多语言版本LiveCodeBench上取得了新的state-of-the-art pass@1结果。
我们将发布语言无关的训练数据集（Ag-MBPP-X、Ag-Codeforces-X、Ag-LiveCodeBench-X）、训练代码和即用型配置，使任何编程语言的RL后训练变得像编辑一个简短的YAML文件一样简单。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [150] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
> *统一流匹配用于长周期事件预测*

*Xiao Shou* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 事件预测, 流匹配, 时间点过程, 非自回归, 长周期

**Comment:** 

> **TL;DR:** 本文提出了一种统一流匹配框架，用于对长周期标记事件序列进行非自回归、联合建模，并在准确性和生成效率上优于现有基线模型。

**AI_Comments:** 该论文的创新点在于提出了一个统一的流匹配框架，解决了传统自回归模型在长周期事件预测中效率低和误差累积的问题。通过非自回归的联合建模，显著提升了模型的准确性和生成效率，在医疗、金融等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 建模长周期标记事件序列是一个基本挑战，现有神经时间点过程模型通常是自回归的，一次预测一个事件，这限制了它们的效率并导致长距离预测中的误差累积。

**Method:** 本文提出了一种统一流匹配框架，用于标记时间点过程，通过连续和离散流匹配，实现事件间隔时间与事件类型的非自回归、联合建模。通过学习两个分量的连续时间流，该方法无需顺序解码即可生成连贯的长周期事件轨迹。

**Result:** 在六个真实世界基准测试中，该模型在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。

**Conclusion:** 该统一流匹配框架能有效解决长周期事件预测中的效率和误差累积问题，通过非自回归的联合建模在多个真实世界基准测试中取得了显著改进。

> **ai_Abstract:** 本文提出了一种统一流匹配（Unified Flow Matching）框架，旨在解决长周期标记事件序列建模中现有自回归模型的效率低下和误差累积问题。该框架通过连续和离散流匹配，实现了事件间隔时间与事件类型的非自回归、联合建模，从而无需顺序解码即可生成连贯的长周期事件轨迹。实验结果表明，在六个真实世界基准测试中，该模型在准确性和生成效率上均显著优于传统的自回归和基于扩散的基线方法。

> **摘要翻译:** 建模长周期标记事件序列是许多现实世界应用中的一个基本挑战，包括医疗保健、金融和用户行为建模。现有的神经时间点过程模型通常是自回归的，一次预测一个事件，这限制了它们的效率并导致长距离预测中的误差累积。在这项工作中，我们提出了一种统一流匹配框架，用于标记时间点过程，通过连续和离散流匹配，实现事件间隔时间与事件类型的非自回归、联合建模。通过学习两个分量的连续时间流，我们的方法无需顺序解码即可生成连贯的长周期事件轨迹。我们在六个真实世界基准测试中评估了我们的模型，并证明在准确性和生成效率方面均显著优于自回归和基于扩散的基线模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [160] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
> *希尔伯特神经算子：解析信号域中的算子学习*

*Saman Pordanesh, Pejman Shahsavari, Hossein Ghadjari* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 希尔伯特神经算子, 算子学习, 解析信号, 谱卷积, 偏微分方程

**Comment:** 

> **TL;DR:** 本文提出希尔伯特神经算子（HNO），通过希尔伯特变换将输入信号映射到解析表示，并在该域进行谱卷积，以解决现有神经算子（如FNO）的局限性，并更有效地建模因果、相位敏感和非平稳系统。

**AI_Comments:** 该论文的创新点在于将希尔伯特变换引入神经算子框架，利用信号的解析表示来提取瞬时幅度和相位信息作为显式特征。这为处理非平稳、相位敏感和因果系统提供了一种新的思路，可能克服传统傅里叶变换在周期性假设上的局限性，为PDE算子学习开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经算子（如傅里叶神经算子FNN）通过在频域进行卷积取得了成功，但存在傅里叶变换的周期性假设等局限性。此外，信号分析除了相位和幅度之外还有其他方法可以提供有用的信息。因此，需要一种新的架构来克服这些限制并提供更有效的学习。

**Method:** 希尔伯特神经算子（HNO）首先通过希尔伯特变换将输入信号映射到其解析表示，从而使瞬时幅度和相位信息成为学习过程的显式特征。然后，核心可学习操作——谱卷积——应用于这种希尔伯特变换后的表示。其设计根植于解析信号理论，并具有来自信号处理的强归纳偏置。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出希尔伯特神经算子（HNO），这是一种新的神经算子架构，旨在解决傅里叶神经算子（FNO）等现有方法在周期性假设上的局限性。HNO 通过希尔伯特变换将输入信号转换为解析表示，使瞬时幅度和相位信息成为显式特征，然后在此解析域应用谱卷积。这种方法引入了信号处理的归纳偏置，并被假设能更有效地建模因果、相位敏感和非平稳系统。论文形式化了 HNO 架构并提供了其理论基础。

> **摘要翻译:** 神经算子已成为一种强大的数据驱动范式，用于学习偏微分方程（PDE）的解算子。最先进的架构，例如傅里叶神经算子（FNO），通过在频域执行卷积取得了显著成功，使其在各种问题中都非常有效。然而，这种方法存在一些局限性，包括傅里叶变换的周期性假设。此外，除了相位和幅度视角之外，还有其他分析信号的方法，可以为我们提供其他有用的信息来学习有效的网络。我们引入了希尔伯特神经算子（HNO），这是一种新的神经算子架构，通过结合信号处理的强归纳偏置来解决一些优点。HNO 的操作方式是首先通过希尔伯特变换将输入信号映射到其解析表示，从而使瞬时幅度信息和相位信息成为学习过程的显式特征。然后，核心可学习操作——谱卷积——应用于这种希尔伯特变换后的表示。我们假设这种架构使 HNO 能够更有效地为因果、相位敏感和非平稳系统建模算子。我们形式化了 HNO 架构，并提供了其设计的理论动机，其根源在于解析信号理论。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [167] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
> *神经网络的高斯混合层*

*Sinho Chewi, Philippe Rigollet, Yuling Yan* | **Category: cs.LG, math.ST, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 高斯混合层, 神经网络, 概率测度, Wasserstein梯度流, 平均场理论

**Comment:** 

> **TL;DR:** 本文引入了一种新的神经网络层——高斯混合（GM）层，它通过在概率测度上直接实现动态来训练，并在分类任务中表现出与传统网络相当的性能，但行为不同。

**AI_Comments:** 本文的创新之处在于提出了高斯混合（GM）层，并探索了在概率测度上直接实现神经网络动态训练的新范式，这与现有平均场理论的探索方向形成对比。这种方法为理解和设计神经网络提供了一个新颖的非传统视角，尤其是在处理网络参数化和训练动态方面。其重要性在于开辟了神经网络研究的新路径，可能为未来更灵活、表达能力更强的网络架构奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的平均场理论考虑无限宽的神经网络，通过概率测度进行线性参数化，这促进了理论理解。本文旨在探索相反的方向，即直接在概率测度上实现动态训练，以开发新的神经网络层。

**Method:** 作者利用高斯混合模型作为灵活的参数化分布族，并结合Wasserstein梯度流理论，推导出在概率测度上进行训练的动态过程。这引入了一种新的神经网络层——高斯混合（GM）层，可以集成到现有的神经网络架构中。

**Result:** 在简单的分类任务中，高斯混合（GM）层实现了与两层全连接网络相当的测试性能。此外，数值实验表明，GM层的动态行为与经典的、即使在大规模平均场机制下的全连接层也显著不同。

**Conclusion:** 本文成功提出并验证了一种新的神经网络层——高斯混合（GM）层，该层允许直接在概率测度上实现训练动态，为神经网络的设计和理解提供了新的视角。

> **ai_Abstract:** 本文提出并验证了一种新的神经网络层，称为高斯混合（GM）层。该层通过利用高斯混合模型和Wasserstein梯度流理论，在概率测度上直接实现训练动态，与传统的平均场理论探索方向相反。实验证明，GM层在简单分类任务上能达到与两层全连接网络相当的性能，并且其动态行为与传统层有显著差异，为神经网络的设计和理解提供了新思路。

> **摘要翻译:** 两层神经网络的平均场理论考虑了通过参数空间上的概率测度线性参数化的无限宽网络。这种非参数视角显著提升了神经网络的理论和概念理解，并为验证其对中等宽度网络的适用性付出了大量努力。在这项工作中，我们探索了相反的方向，即研究是否可以直接在概率测度上实现动态。具体来说，我们采用高斯混合模型作为一种灵活且富有表达力的参数化分布族，并结合Wasserstein梯度流理论来推导此类测度的训练动态。我们的方法引入了一种新型层——高斯混合（GM）层——可以集成到神经网络架构中。作为概念验证，我们通过在简单分类任务上的实验验证了我们的提议，其中GM层实现了与两层全连接网络相当的测试性能。此外，我们检查了这些动态的行为，并数值证明了GM层表现出与经典全连接层显著不同的行为，即使后者足够大以至于可以被视为处于平均场状态。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [176] [Honest and Reliable Evaluation and Expert Equivalence Testing of Automated Neonatal Seizure Detection](https://arxiv.org/abs/2508.04899)
> *自动化新生儿癫痫检测的诚实可靠评估与专家等效性测试*

*Jovana Kljajic, John M. O'Toole, Robert Hogan, Tamara Skoric* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 新生儿癫痫检测, 机器学习评估, 性能指标, 专家等效性, 临床验证

**Comment:** 

> **TL;DR:** 本研究系统评估了新生儿癫痫检测中机器学习模型的性能评估指标和专家等效性测试，并提出了临床验证的最佳实践建议。

**AI_Comments:** 这项研究对于推动新生儿癫痫检测AI模型的临床应用具有重要意义。它指出了当前评估实践的不足，并提出了一套系统且严谨的评估框架，特别是强调了在类别不平衡情况下的指标选择以及通过多评估者图灵测试进行专家等效性验证，这有助于提高AI评估的透明度和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 当前新生儿癫痫检测机器学习模型的评估方法存在不一致和偏差，阻碍了模型的可比性和可解释性，且声称达到专家水平的AI性能缺乏严格验证，因此需要更可靠的评估方法。

**Method:** 本研究系统评估了新生儿癫痫检测中常用的性能指标、共识策略和人类专家水平等效性测试。研究使用了真实和合成的癫痫标注数据，并在不同类别不平衡、评估者间一致性和评估者数量的条件下进行评估。

**Result:** Matthews和Pearson相关系数在类别不平衡情况下优于曲线下面积（AUC）能更好地反映性能。共识类型对评估者数量及其一致性水平敏感。在人类专家水平等效性测试中，使用Fleiss k的多评估者图灵测试最能捕捉专家级AI性能。

**Conclusion:** 本研究推荐报告至少一个平衡指标、敏感性、特异性、PPV和NPV，以及使用Fleiss k的多评估者图灵测试结果，并且所有这些都应在独立验证集上报告。该框架为新生儿癫痫检测AI方法的彻底和诚实评估提供了重要的临床验证先决条件。

> **ai_Abstract:** 本研究旨在解决新生儿癫痫检测机器学习模型评估中存在的偏倚和不一致问题。通过系统评估多种性能指标、共识策略和专家等效性测试，研究发现Matthews和Pearson相关系数在类别不平衡下表现更优，并提出使用Fleiss k的多评估者图灵测试最适合评估专家级AI性能。最终，论文推荐了一套全面的指标和测试报告框架，以促进AI模型在临床应用前的可靠评估。

> **摘要翻译:** 对新生儿癫痫检测机器学习模型进行可靠评估对于其临床应用至关重要。当前的实践往往依赖于不一致和有偏见的指标，这阻碍了模型的可比性和可解释性。关于人工智能性能达到专家水平的说法经常在没有严格验证的情况下提出，这引发了对其可靠性的担忧。本研究旨在系统地评估常见的性能指标，并提出针对新生儿癫痫检测特定挑战的最佳实践。我们使用真实和合成的癫痫标注数据，在不同的类别不平衡、评估者间一致性和评估者数量的条件下，评估了标准性能指标、共识策略和人类专家水平等效性测试。Matthews和Pearson相关系数在反映类别不平衡下的性能方面优于曲线下面积。共识类型对评估者数量及其之间的一致性水平敏感。在人类专家水平等效性测试中，使用Fleiss k的多评估者图灵测试最能捕捉专家级AI性能。我们建议报告：(1) 至少一个平衡指标，(2) 敏感性、特异性、PPV和NPV，(3) 使用Fleiss k的多评估者图灵测试结果，以及 (4) 以上所有内容均在独立验证集上。这个提出的框架通过对新生儿癫痫检测AI方法进行彻底和诚实的评估，为临床验证提供了重要的先决条件。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [178] [Retrieval-Augmented Water Level Forecasting for Everglades](https://arxiv.org/abs/2508.04888)
> *检索增强型大沼泽地水位预测*

*Rahuul Rangaraj, Jimeng Shi, Rajendra Paudel, Giri Narasimhan, Yanzhao Wu* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 水位预测, 检索增强, 水文学, 大沼泽地, 深度学习

**Comment:** 

> **TL;DR:** 本研究引入了一种名为检索增强型预测（RAF）的新框架，用于水文学领域的水位预测。RAF通过检索历史相似数据来增强模型输入，显著提高了大沼泽地水位预测的准确性，解决了深度学习模型在水文学中泛化能力不足的问题。

**AI_Comments:** 这项研究的创新之处在于将检索增强（Retrieval-Augmented）范式引入了水文学领域，特别是水位预测。它有效地解决了传统深度学习模型在特定领域（如水文学）中泛化能力差的问题，通过利用历史数据来增强模型的上下文理解，而无需耗时的再训练或微调。这对于需要实时、适应性强的预测能力的生态系统管理具有重要意义。该方法提供了一个通用的框架，可能适用于其他时间序列预测任务，特别是在数据稀疏或领域适应性要求高的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 准确的水位预测对于管理大沼泽地等生态系统至关重要，这些系统在防洪、抗旱、水资源规划和生物多样性保护方面发挥着关键作用。尽管深度学习模型在通用预测方面取得了进展，但它们在水文学中的应用尚未得到充分探索，并且由于缺乏有效的适应机制，难以在多样化、未见的数据集和领域中泛化。

**Method:** 为解决现有深度学习模型在水文学中泛化能力不足的问题，本研究引入了检索增强型预测（RAF）框架。该框架通过检索历史上相似的多变量水文事件来丰富模型输入，从而在预测前增强上下文感知。RAF通过维护一个外部历史观测档案，识别并整合历史数据中的相关模式，在不要求模型进行特定任务再训练或微调的情况下，提高预测准确性。此外，研究还探索并比较了基于相似性和基于互信息的RAF方法。

**Result:** 在大沼泽地的真实世界数据上进行的全面评估表明，RAF框架显著提高了水位预测的准确性。

**Conclusion:** 本研究强调了检索增强型预测（RAF）方法在环境水文学中的潜力，并为领域专家在生态系统管理中更广泛地采用自适应人工智能方法铺平了道路。

> **ai_Abstract:** 本研究提出了一种名为检索增强型预测（RAF）的新框架，旨在解决深度学习模型在水文学领域中泛化能力不足的问题。RAF通过从外部历史档案中检索相似的水文事件来增强模型输入，从而在不进行模型微调的情况下提高预测的上下文感知和准确性。在对大沼泽地水位数据的评估中，RAF显著提升了预测精度，展示了其在环境水文学中的应用潜力。

> **摘要翻译:** 准确的水位预测对于管理大沼泽地等生态系统至关重要，大沼泽地是一个亚热带湿地，对于防洪、抗旱、水资源规划和生物多样性保护至关重要。尽管深度学习的最新进展，特别是时间序列基础模型，在通用领域预测中取得了成功，但它们在水文学中的应用仍未得到充分探索。此外，由于缺乏有效的适应机制，它们往往难以在多样化、未见过的数据集和领域中泛化。为了解决这一空白，我们将检索增强型预测（RAF）引入水文学领域，提出了一个框架，该框架在预测前检索历史上相似的多变量水文事件以丰富模型输入。通过维护一个外部历史观测档案，RAF识别并整合历史数据中的相关模式，从而在不需要模型进行特定任务再训练或微调的情况下，增强上下文感知和预测准确性。此外，我们探索并比较了基于相似性和基于互信息的RAF方法。我们对大沼泽地的真实世界数据进行了全面评估，结果表明RAF框架在水位预测准确性方面取得了显著改进。这项研究突出了RAF方法在环境水文学中的潜力，并为领域专家在生态系统管理中更广泛地采用自适应人工智能方法铺平了道路。代码和数据可在https://github.com/rahuul2992000/WaterRAF获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [188] [Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning](https://arxiv.org/abs/2508.04901)
> *稳定性敏感度：迁移学习中自适应数据选择可重复性的理论与实证分析*

*Prabhav Singh, Jessica Sorrell* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 迁移学习, 可重复性, 自适应数据选择, 选择敏感度, 预训练

**Comment:** 

> **TL;DR:** 本文对迁移学习中自适应数据选择的可重复性进行了理论和实证分析，引入了选择敏感度（$\\Delta_Q$）来量化适应性效果与结果一致性之间的权衡，并证明了可重复性失败概率与选择敏感度呈二次方关系，与样本量呈指数关系。研究发现，高度自适应策略性能优异但可重复性差，而源域预训练能有效降低失败率。

**AI_Comments:** 该论文创新性地引入了“选择敏感度”这一概念，为量化迁移学习中自适应数据选择的可重复性问题提供了新的视角和数学框架。其理论分析与实证结果高度吻合，揭示了性能与可重复性之间的内在权衡，并提出了源域预训练作为一种有效的缓解机制。这对于指导实践者设计更可靠的迁移学习系统具有重要意义，尤其是在需要高可靠性的应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 迁移学习的广泛应用虽然提高了效率，但其适应性，尤其是在使用动态数据选择策略时，其可靠性仍不明确。现有研究对适应性效果与结果一致性之间的基本权衡理解不足，阻碍了实践者在性能和可重复性之间做出明智选择。

**Method:** 本文提出了一个数学框架来量化适应性效果与结果一致性之间的基本权衡。引入了“选择敏感度”（$\\Delta_Q$）来衡量自适应选择策略对训练数据扰动的响应。通过理论证明，阐述了可重复性失败概率与选择敏感度呈二次方关系，与样本量呈指数关系。通过在MultiNLI语料库上使用六种自适应选择策略（从均匀采样到基于梯度的选择）进行了广泛的实验验证。

**Result:** 可重复性失败概率与选择敏感度呈二次方关系，而与样本量呈指数关系递减。高度自适应策略（如基于梯度和课程学习）实现了卓越的任务性能，但可重复性失败率高。自适应性较低的方法将失败率保持在7%以下。源域预训练是一种强大的缓解机制，可将失败率降低多达30%，同时保持性能提升。

**Conclusion:** 本文为实践者在性能-可重复性权衡中提供了原则性指导，并强调了现代迁移学习系统中需要设计可重复性感知系统。理论和实验结果都表明，存在一个根本的权衡，需要仔细考虑自适应策略的选择和预训练的作用。

> **ai_Abstract:** 本研究对迁移学习中自适应数据选择的可重复性进行了全面的理论和实证分析。通过引入选择敏感度（$\\Delta_Q$）这一数学框架，量化了适应性效果与结果一致性之间的权衡。研究证明，可重复性失败概率与选择敏感度呈二次方关系，与样本量呈指数关系。实验结果表明，高度自适应策略虽然性能优越，但可重复性差，而源域预训练能有效降低失败率。这些发现为实践者在性能与可重复性之间做出权衡提供了指导。

> **摘要翻译:** 迁移学习的广泛采用通过使预训练模型能够高效适应新领域，彻底改变了机器学习。然而，这些适应的可靠性仍然知之甚少，尤其是在使用动态优先训练样本的自适应数据选择策略时。我们对迁移学习中的可重复性进行了全面的理论和实证分析，引入了一个数学框架，量化了适应性效果和结果一致性之间的基本权衡。我们的主要贡献是形式化了选择敏感度（$\\Delta_Q$），这是一个衡量自适应选择策略如何响应训练数据扰动的指标。我们证明了可重复性失败概率：即两次独立的训练运行产生的模型性能差异超过某个阈值的可能性，随着选择敏感度呈二次方增加，同时随着样本量呈指数级减少。通过在MultiNLI语料库上使用六种自适应选择策略（从均匀采样到基于梯度的选择）进行的大量实验，我们证明了这种理论关系在实践中是精确成立的。我们的结果表明，高度自适应的策略，如基于梯度和课程学习，实现了卓越的任务性能，但可重复性失败率高，而自适应性较低的方法将失败率保持在7%以下。至关重要的是，我们表明源域预训练提供了一种强大的缓解机制，可将失败率降低多达30%，同时保持性能增益。这些发现为实践者在性能-可重复性权衡中提供了原则性指导，并强调了现代迁移学习系统中需要设计可重复性感知系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [195] [Self-Error Adjustment: Theory and Practice of Balancing Individual Performance and Diversity in Ensemble Learning](https://arxiv.org/abs/2508.04948)
> *自误差调整：集成学习中平衡个体性能与多样性的理论与实践*

*Rui Zou* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 集成学习, 自误差调整, 准确性-多样性权衡, 负相关学习, 机器学习

**Comment:** 

> **TL;DR:** 提出了一种名为自误差调整（SEA）的新框架，通过分解集成误差并引入可调参数，更精确地平衡集成学习中个体学习器性能与多样性，从而实现更好的性能。

**AI_Comments:** 这项工作通过引入自误差调整（SEA）框架，为集成学习中的准确性-多样性权衡问题提供了一个新颖且更精细的解决方案。其创新点在于对集成误差的分解以及通过可调参数实现精确控制。相比传统方法和NCL，SEA在理论上提供了更紧密的界限，并在实践中展现出更广泛的调整能力和优越的性能，这对于提升集成学习模型的泛化能力和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 集成学习中，平衡个体学习器准确性与多样性是一个核心挑战。传统方法（如Bagging和Boosting）缺乏对准确性-多样性权衡的精确控制，而负相关学习（NCL）及其变体存在理论界限松散和调整范围有限的问题。

**Method:** 提出了一种名为自误差调整（SEA）的新框架。该框架将集成误差分解为个体性能项（每个基础学习器的自误差）和多样性项（学习器之间的交互）。通过在损失函数中引入一个可调参数，SEA可以精确控制每个组件的贡献，从而实现对集成性能的精细调节。此外，还建立了更紧密的理论界限。

**Result:** 相比NCL及其变体，SEA提供了更广泛的有效调整范围和更一致的多样性变化。在多个公共回归和分类数据集上的实验结果表明，SEA在所有任务中始终优于基线方法。消融研究证实SEA提供了更灵活的调整能力和在微调策略中卓越的性能。

**Conclusion:** 自误差调整（SEA）框架通过对集成误差的精确分解和可调参数的引入，有效解决了集成学习中个体性能与多样性平衡的挑战，实现了卓越的性能和更灵活的调整能力。

> **ai_Abstract:** 本文提出了一种名为自误差调整（SEA）的新型集成学习框架，旨在解决个体学习器性能与多样性平衡的难题。SEA通过将集成误差分解为个体性能和多样性两部分，并在损失函数中引入可调参数，实现了对这一权衡的精确控制。实验证明，SEA在多个数据集上均优于现有方法，并提供了更灵活的调整能力和卓越的微调性能，同时建立了更紧密的理论界限。

> **摘要翻译:** 集成学习通过聚合多个基础学习器的预测来提高性能。一个核心挑战是平衡个体学习器的准确性与多样性。Bagging和Boosting等传统方法通过随机性促进多样性，但缺乏对准确性-多样性权衡的精确控制。负相关学习（NCL）引入惩罚来管理这种权衡，但存在理论界限松散和调整范围有限的问题。为了克服这些限制，我们提出了一种名为自误差调整（SEA）的新颖框架，它将集成误差分解为两个不同的组成部分：个体性能项（代表每个基础学习器的自误差）和多样性项（反映学习器之间的交互）。这种分解使我们能够在损失函数中引入一个可调参数，从而精确控制每个组成部分的贡献，实现对集成性能的更精细调节。与NCL及其变体相比，SEA提供了更广泛的有效调整范围和更一致的多样性变化。此外，我们为可调集成方法建立了更紧密的理论界限，并通过实证实验验证了它们。在几个公共回归和分类数据集上的实验结果表明，SEA在所有任务中始终优于基线方法。消融研究证实SEA提供了更灵活的调整能力和在微调策略中卓越的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [202] [Compressed Decentralized Momentum Stochastic Gradient Methods for Nonconvex Optimization](https://arxiv.org/abs/2508.04950)
> *非凸优化的压缩去中心化动量随机梯度方法*

*Wei Liu, Anweshit Panda, Ujwal Pandey, Christopher Brissette, Yikang Shen, George M. Slota, Naigang Wang, Jie Chen, Yangyang Xu* | **Category: cs.LG, math.OC** | **Updated: 2025-08-07**

**Keywords:** 去中心化优化, 动量方法, 压缩通信, 非凸优化, 随机梯度

**Comment:** 

> **TL;DR:** 本文提出了两种新的压缩去中心化动量随机梯度算法，用于解决非凸随机优化问题，旨在同时实现快速收敛和通信成本节约，并在理论上证明其有效性，实证表现优越。

**AI_Comments:** 本文的创新点在于首次在理论上成功地将动量加速和压缩通信这两种强大的技术有效结合到去中心化优化算法中，解决了多重误差控制的复杂挑战。这对于大规模分布式机器学习，尤其是通信受限的环境，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 在去中心化算法中，同时结合动量加速和压缩通信以实现两方面优势的理论证明非常困难，因为需要同时控制共识误差、压缩误差和动量梯度偏差。此外，现有方法在有界梯度或数据异质性场景下存在不足。

**Method:** 本文设计了两种压缩去中心化算法。对于梯度有界的情况，提出了一种压缩去中心化自适应方法；对于数据异质性且梯度无界的情况，提出了一种压缩去中心化重球方法，并应用了梯度跟踪技术。两种算法均采用了动量技术和消息压缩技术。

**Result:** 两种方法都达到了最优收敛速度，并能在用户指定误差容忍度的特定范围内实现线性加速和采用与拓扑无关的算法参数。在训练深度神经网络（DNNs）和Transformers时，实证性能优于现有最先进的方法。

**Conclusion:** 本文成功设计并理论证明了两种结合动量加速和压缩通信的去中心化算法在非凸随机优化中的有效性，克服了多重误差控制的挑战，并在实践中表现出卓越的性能。

> **ai_Abstract:** 本文针对非凸随机优化问题，提出了两种新颖的压缩去中心化动量随机梯度算法。这两种算法巧妙结合了动量加速和通信压缩技术，旨在实现快速收敛并显著降低通信成本。论文克服了同时控制共识误差、压缩误差和动量偏差的理论挑战，并针对梯度有界和数据异质性两种场景分别提出了特定的自适应和重球方法。研究表明，所提出的方法均能达到最优收敛速度和线性加速，并在深度学习任务中展现出优于现有SOTA方法的实证性能。

> **摘要翻译:** 在本文中，我们设计了两种压缩去中心化算法，用于解决两种不同场景下的非凸随机优化问题。这两种算法都采用了动量技术来实现快速收敛，并采用消息压缩技术来节省通信成本。尽管动量加速和压缩通信已在文献中使用，但要在能够保持两者优势的去中心化算法中理论上证明其组合的有效性是非常非平凡的，因为需要同时控制共识误差、压缩误差以及动量梯度带来的偏差。
对于梯度有界的场景，我们提出的方法是一种压缩去中心化自适应方法。据我们所知，这是第一个具有压缩通信的去中心化自适应随机梯度方法。对于梯度无界且数据异质性的场景，我们提出的方法是一种压缩去中心化重球方法，它应用了梯度跟踪技术来解决数据异质性的挑战。值得注意的是，这两种方法都达到了最优收敛速度，并且它们可以在用户指定误差容忍度的特定范围内实现线性加速并采用与拓扑无关的算法参数。在训练深度神经网络（DNNs）和Transformers时，观察到比现有最先进方法更优越的经验性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [209] [RCUKF: Data-Driven Modeling Meets Bayesian Estimation](https://arxiv.org/abs/2508.04985)
> *RCUKF：数据驱动建模与贝叶斯估计的结合*

*Kumar Anurag, Kasra Azizi, Francesco Sorrentino, Wenbin Wan* | **Category: cs.LG, eess.SY, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 数据驱动建模, 贝叶斯估计, 储层计算, 无迹卡尔曼滤波, 状态估计

**Comment:** 

> **TL;DR:** RCUKF结合了储层计算（数据驱动建模）和无迹卡尔曼滤波（贝叶斯估计），用于复杂系统的准确建模和状态估计，尤其适用于高维或混沌系统。

**AI_Comments:** RCUKF创新性地将数据驱动的储层计算与贝叶斯估计的无迹卡尔曼滤波相结合，有效解决了复杂非线性系统建模和状态估计的挑战。其亮点在于RC作为UKF的替代模型，能够处理高维和混沌系统，同时UKF的测量更新机制有效纠正了数据驱动模型的潜在漂移，增强了模型的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模在许多工程和科学应用中至关重要，但为复杂系统获取可靠的过程模型通常具有挑战性。

**Method:** 提出RCUKF框架，它将通过储层计算（RC）实现的数据驱动建模与通过无迹卡尔曼滤波（UKF）实现的贝叶斯估计相结合。RC组件直接从数据中学习非线性系统动力学，在UKF预测步骤中充当替代过程模型，以在高维或混沌状态下生成状态估计。UKF测量更新集成实时传感器数据，以纠正数据驱动模型中潜在的漂移。

**Result:** RCUKF在知名基准问题和高保真模拟环境中的实时车辆轨迹估计任务上表现出有效性。

**Conclusion:** RCUKF是一种有效且鲁棒的框架，能够解决复杂系统建模和状态估计的挑战，尤其是在传统数学模型可能失效的高维或混沌场景中。

> **ai_Abstract:** RCUKF是一种新颖的混合框架，将数据驱动的储层计算模型与贝叶斯无迹卡尔曼滤波相结合，旨在解决复杂系统的准确建模和状态估计难题。RC负责从数据中学习系统动力学，而UKF则利用传感器数据进行校正并提供鲁棒的状态估计，尤其适用于传统模型失效的高维和混沌环境。该方法在知名基准问题和实时车辆轨迹估计任务中得到了验证。

> **摘要翻译:** 准确建模在许多工程和科学应用中至关重要，然而，为复杂系统获取可靠的过程模型通常具有挑战性。为了应对这一挑战，我们提出了一种新颖的框架，即结合无迹卡尔曼滤波的储层计算（RCUKF），它将通过储层计算（RC）实现的数据驱动建模与通过无迹卡尔曼滤波（UKF）实现的贝叶斯估计相结合。RC组件直接从数据中学习非线性系统动力学，在UKF预测步骤中充当替代过程模型，以在高维或混沌状态下生成状态估计，在这些情况下，标称数学模型可能会失效。同时，UKF测量更新集成实时传感器数据，以纠正数据驱动模型中潜在的漂移。我们在知名基准问题和高保真模拟环境中的实时车辆轨迹估计任务上证明了RCUKF的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.04999)
> *通过建模模态内和模态间因果注意力来解耦多模态情感分析中的偏差*

*Menghua Jiang, Yuxia Lin, Baoliang Chen, Haifeng Hu, Yuncheng Jiang, Sijie Mai* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 多模态情感分析, 因果干预, 偏差解耦, 后门调整, 分布偏移

**Comment:** 

> **TL;DR:** 现有多模态情感分析（MSA）模型受虚假关联困扰，导致泛化能力差。本文提出多关系多模态因果干预（MMCI）模型，利用因果理论的后门调整和注意力机制，解耦因果特征和捷径特征，有效抑制偏差并提高在分布偏移下的性能。

**AI_Comments:** 该论文的创新之处在于将因果推断（后门调整）与多关系图建模和注意力机制相结合，明确地解耦多模态情感分析中的因果特征和捷径特征。这种方法直接解决了由虚假关联引起的泛化问题，这在实际应用中是一个重要挑战。对分布偏移下稳定性的关注也突显了其重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态情感分析（MSA）方法常受模态内部和模态之间虚假关联的影响，导致模型依赖统计捷径而非真正的因果关系，从而损害泛化能力。

**Method:** 本文提出一种多关系多模态因果干预（MMCI）模型。首先，将多模态输入建模为多关系图，以捕获模态内和模态间依赖。其次，应用注意力机制分别估计并解耦因果特征和捷径特征。最后，通过后门调整对捷径特征进行分层，并与因果特征动态结合，以在分布偏移下产生稳定预测。

**Result:** 在多个标准MSA数据集和分布外（OOD）测试集上的大量实验表明，所提方法有效抑制了偏差并提高了性能。

**Conclusion:** 通过建模模态内和模态间因果注意力并采用因果干预（后门调整），MMCI模型能够有效解耦多模态情感分析中的因果特征和捷径特征，从而抑制偏差并提高在分布偏移下的预测稳定性与性能。

> **ai_Abstract:** 本文针对多模态情感分析（MSA）中现有模型因虚假关联而泛化能力受损的问题，提出了一种多关系多模态因果干预（MMCI）模型。该模型通过将多模态输入建模为多关系图来捕获模态内和模态间依赖，并利用注意力机制解耦因果特征和捷径特征。MMCI模型进一步应用因果理论中的后门调整，以确保在分布偏移下也能产生稳定预测。实验结果表明，该方法能有效抑制偏差并显著提升MSA性能。

> **摘要翻译:** 多模态情感分析（MSA）旨在通过整合文本、音频和视觉数据等多种模态的信息来理解人类情感。然而，现有方法常受模态内部和模态之间虚假关联的影响，导致模型依赖统计捷径而非真正的因果关系，从而损害泛化能力。为了缓解这个问题，我们提出了一种多关系多模态因果干预（MMCI）模型，该模型利用因果理论中的后门调整来解决这些捷径的混淆效应。具体而言，我们首先将多模态输入建模为多关系图，以明确捕获模态内和模态间的依赖关系。然后，我们应用注意力机制来分别估计和解耦与这些模态内和模态间关系对应的因果特征和捷径特征。最后，通过应用后门调整，我们对捷径特征进行分层，并将其与因果特征动态结合，以鼓励MMCI在分布偏移下产生稳定的预测。在多个标准MSA数据集和分布外（OOD）测试集上的大量实验表明，我们的方法有效抑制了偏差并提高了性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [223] [TANGO: Graph Neural Dynamics via Learned Energy and Tangential Flows](https://arxiv.org/abs/2508.05070)
> *TANGO：通过学习能量和切向流实现的图神经网络动力学*

*Moshe Eliasof, Eldad Haber, Carola-Bibiane Schönlieb* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 图神经网络, 能量函数, 切向流, 动力系统, 图表示学习

**Comment:** 

> **TL;DR:** TANGO是一种新的图神经网络框架，它通过学习能量函数和切向流来更好地处理节点特征演化，解决了信号传播问题并提高了性能。

**AI_Comments:** TANGO的创新之处在于其将图神经网络的动力学分解为能量梯度下降和切向演化两个正交分量，这不仅保证了模型的收敛性和稳定性，还通过切向流解决了传统能量模型在平坦或病态区域信号传播受限的问题，有效缓解了过压缩，为图表示学习提供了一个更灵活和鲁棒的框架。

<details>
  <summary>Details</summary>

**Motivation:** 图学习中可能出现平坦或病态能量区域，导致信号传播效率低下；需要增强能量基动力学的灵活性，同时保持其收敛性和稳定性优势；解决过压缩问题。

**Method:** 本研究引入了TANGO，一个受动力系统启发的图表示学习框架。其核心是一个可学习的节点嵌入Lyapunov函数，其梯度定义了能量降低方向，保证收敛性和稳定性。为了增强灵活性，该方法引入了一个新颖的切向分量，通过消息传递学习，该分量在保持能量值的同时演化特征。这种方法将动力学分解为正交的能量梯度下降流和切向演化流。

**Result:** TANGO实现了灵活的图动力学形式，即使在平坦或病态能量区域也能实现有效的信号传播，并缓解了过压缩问题。该方法与不同的图神经网络骨干兼容，并在各种节点和图分类及回归基准测试中取得了强大的性能。

**Conclusion:** 联合学习能量函数和切向流对于图神经网络是有效的，TANGO框架在图表示学习中表现出色。

> **ai_Abstract:** TANGO是一种新颖的图表示学习框架，受动力系统启发，通过结合学习能量景观和创新的切向流来演化节点特征。它利用可学习的Lyapunov函数确保收敛性，并通过正交分解的能量梯度下降和切向演化流，解决了图学习中信号传播效率低下的问题，并缓解了过压缩。实验证明TANGO在多种图任务上表现出色。

> **摘要翻译:** 我们引入了TANGO——一个受动力系统启发的图表示学习框架，它通过学习的能量景观及其相关的下降动力学来管理节点特征演化。我们方法的核心是一个可学习的节点嵌入Lyapunov函数，其梯度定义了一个能量降低方向，保证了收敛性和稳定性。为了在保留基于能量动力学优势的同时增强灵活性，我们引入了一个新颖的切向分量，通过消息传递学习，该分量在保持能量值的同时演化特征。这种分解为能量梯度下降和切向演化的正交流，产生了一种灵活的图动力学形式，并即使在图学习中经常出现的平坦或病态能量区域也能实现有效的信号传播。我们的方法缓解了过压缩问题，并且与不同的图神经网络骨干兼容。从经验上看，TANGO在各种节点和图分类和回归基准测试中取得了强大的性能，证明了联合学习能量函数和切向流对于图神经网络的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [230] [ULU: A Unified Activation Function](https://arxiv.org/abs/2508.05073)
> *ULU：一种统一的激活函数*

*Simin Huo* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 激活函数, ULU, AULU, 归纳偏置, 深度学习

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的非单调分段激活函数ULU及其自适应变体AULU，并在图像分类和目标检测任务中展现出优于ReLU和Mish的性能，同时引入了量化模型归纳偏置的LIB度量。

**AI_Comments:** 该论文的创新点在于提出了非单调且对正负输入区别处理的激活函数ULU及其自适应版本AULU，这为激活函数的设计提供了新的思路。AULU的可学习参数使其更具灵活性，而引入LIB度量则为量化模型归纳偏置提供了一个新工具，具有潜在的研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发一种新的激活函数，通过对正负输入进行差异化处理，以改善深度学习模型在图像分类和目标检测任务中的性能。

**Method:** 提出ULU，一种非单调、分段激活函数，定义为$f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0$ ，其中$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$。ULU对正负输入区别对待。其变体AULU具有可学习参数$\beta_1$和$\beta_2$，使其能够自适应地响应正负输入。此外，还引入了LIB（Like Inductive Bias）度量来量化模型的归纳偏置。

**Result:** 实验表明，ULU在图像分类和目标检测任务中显著优于ReLU和Mish。

**Conclusion:** ULU及其变体AULU是有效的激活函数，能够提升深度学习模型在视觉任务上的表现，并且AULU还能用于量化模型的归纳偏置。

> **ai_Abstract:** 本文提出了一种新型的非单调分段激活函数ULU，它通过对正负输入进行区别处理来优化模型性能。实验证明ULU在图像分类和目标检测任务中优于ReLU和Mish。同时，引入了ULU的自适应变体AULU，其参数可学习，并基于AULU提出了LIB度量用于量化模型的归纳偏置。

> **摘要翻译:** 我们提出了**ULU**，一种新颖的非单调、分段激活函数，定义为$f(x;\alpha_1),x<0; f(x;\alpha_2),x>=0$ ，其中$f(x;\alpha)=0.5x(tanh(\alpha x)+1),\alpha >0$。ULU对正负输入进行差异化处理。大量实验表明，ULU在图像分类和目标检测任务中显著优于ReLU和Mish。其变体自适应ULU（**AULU**）表示为$f(x;\beta_1^2),x<0; f(x;\beta_2^2),x>=0$ ，其中$\beta_1$和$\beta_2$是可学习参数，使其能够分别适应正负输入的响应。此外，我们从AULU引入了LIB（Like Inductive Bias）度量来定量测量模型的归纳偏置。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [237] [Analyzing the Impact of Multimodal Perception on Sample Complexity and Optimization Landscapes in Imitation Learning](https://arxiv.org/abs/2508.05077)
> *分析多模态感知对模仿学习中样本复杂度和优化景观的影响*

*Luai Abuelsamen, Temitope Lukman Adebanjo* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 多模态感知, 模仿学习, 样本复杂度, 优化景观, 统计学习理论

**Comment:** 

> **TL;DR:** 本文从统计学习理论角度分析了多模态感知如何改善模仿学习的样本复杂度和优化景观，发现多模态策略能实现更紧的泛化界限和更有利的优化景观。

**AI_Comments:** 这篇论文的创新点在于从统计学习理论的视角深入分析了多模态感知在模仿学习中的作用，为多模态架构的优越性提供了理论解释，而非仅仅停留在经验观察。它连接了实践中的高性能模型与基础学习理论，具有重要的理论指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解多模态感知（如RGB-D、本体感受、语言）如何在理论层面影响模仿学习中的样本复杂度和优化景观。

**Method:** 通过统计学习理论，分析多模态感知对模仿策略的影响，并综合回顾了多模态学习理论的最新进展，将其与Rademacher复杂度、PAC学习和信息论等概念联系起来。

**Result:** 正确整合的多模态策略比其单模态对应物能够实现更紧密的泛化界限和更有利的优化景观。

**Conclusion:** 多模态架构如PerAct和CLIPort之所以能实现卓越性能，是因为它们在理论上能提供更紧密的泛化界限和更有利的优化景观，这与Rademacher复杂度、PAC学习和信息论等基本概念相关。

> **ai_Abstract:** 本文从统计学习理论角度深入探讨了多模态感知对模仿学习中样本复杂度和优化景观的影响。研究表明，与单模态策略相比，整合良好的多模态策略能够实现更紧密的泛化界限和更有利的优化景观。文章还回顾了相关理论框架，解释了PerAct和CLIPort等多模态架构表现优异的深层原因，并将其与Rademacher复杂度、PAC学习和信息论等核心概念联系起来。

> **摘要翻译:** 本文从统计学习理论的角度审视了多模态模仿学习的理论基础。我们分析了多模态感知（RGB-D、本体感受、语言）如何影响模仿策略中的样本复杂度和优化景观。基于多模态学习理论的最新进展，我们表明，适当整合的多模态策略比其单模态对应物能够实现更紧密的泛化界限和更有利的优化景观。我们全面回顾了解释为什么像PerAct和CLIPort这样的多模态架构能够实现卓越性能的理论框架，并将这些经验结果与Rademacher复杂度、PAC学习和信息论中的基本概念联系起来。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [244] [Cold Start Active Preference Learning in Socio-Economic Domains](https://arxiv.org/abs/2508.05090)
> *社会经济领域中的冷启动主动偏好学习*

*Mojtaba Fayaz-Bakhsh, Danial Ataee, MohammadAmin Fazli* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 冷启动, 主动学习, 偏好学习, 自监督, PCA

**Comment:** 

> **TL;DR:** 提出了一种新的冷启动主动偏好学习框架，通过自监督预训练和主动学习循环，在数据稀缺的社会经济领域实现了更高的准确性和样本效率。

**AI_Comments:** 该论文的创新点在于提出了一个结合自监督预训练（利用PCA生成伪标签）和主动学习的框架，有效解决了主动偏好学习中的冷启动问题。这对于数据获取成本高昂或数据稀缺的社会经济领域具有重要意义，因为它显著提高了样本效率和模型的初始性能。

<details>
  <summary>Details</summary>

**Motivation:** 主动偏好学习在没有初始标记数据时会遭遇冷启动问题，这在标记数据稀缺、昂贵且有专家噪声的计算社会系统和经济分析中尤为突出。

**Method:** 提出了一种新的冷启动主动偏好学习框架。该方法通过自监督预训练阶段启动学习过程，利用主成分分析（PCA）从数据固有结构中推导出初始伪标签，从而在没有初始预言机交互的情况下创建冷启动模型。随后，通过主动学习循环对模型进行精炼，该循环策略性地查询模拟的噪声预言机以获取标签。

**Result:** 在金融信誉、职业成功率和社会经济地位等不同领域的数据集上进行了广泛实验。结果表明，该冷启动方法优于从零开始的标准主动学习策略，以显著更少的标记对实现了更高的准确性。

**Conclusion:** 该框架为缓解冷启动问题提供了一个实用且有效的解决方案，增强了偏好学习在数据受限环境中的样本效率和适用性。

> **ai_Abstract:** 该论文提出了一种新的冷启动主动偏好学习框架，旨在解决在没有初始标记数据时性能下降的问题，尤其是在数据稀缺的社会经济领域。该方法首先通过基于PCA的自监督预训练生成初始伪标签，随后通过主动学习循环利用模拟噪声预言机进行模型优化。实验结果表明，该方法在保持高准确性的同时，显著减少了所需标记数据的数量，为数据受限环境下的偏好学习提供了实用且高效的解决方案。

> **摘要翻译:** 主动偏好学习是一种有效建模偏好的强大范式，但它存在冷启动问题：当没有初始标记数据可用时，性能会显著下降。这一挑战在计算社会系统和经济分析中尤为突出，因为标记数据通常稀缺、昂贵且容易受到专家噪声的影响。为了解决这一差距，我们提出了一种新的冷启动主动偏好学习框架。我们的方法通过自监督预训练阶段启动学习过程，利用主成分分析（PCA）从数据固有结构中推导出初始伪标签，从而在没有任何初始预言机交互的情况下创建冷启动模型。随后，通过主动学习循环对模型进行精炼，该循环策略性地查询模拟的噪声预言机以获取标签。我们在金融信誉、职业成功率和社会经济地位等不同领域的数据集上进行了广泛实验。结果表明，我们的冷启动方法优于从零开始的标准主动学习策略，以显著更少的标记对实现了更高的准确性。我们的框架为缓解冷启动问题提供了一个实用且有效的解决方案，增强了偏好学习在数据受限环境中的样本效率和适用性。我们已在https://github.com/Dan-A2/cold-start-preference-learning发布了代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [251] [Learning from Similarity-Confidence and Confidence-Difference](https://arxiv.org/abs/2508.05108)
> *从相似度置信度和置信度差异中学习*

*Tomoya Tate, Kosuke Sugiyama, Masato Uchida* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 弱监督学习, 相似度置信度, 置信度差异, 无偏风险估计, 过拟合

**Comment:** 

> **TL;DR:** 本文提出一种新的弱监督学习（WSL）框架SconfConfDiff分类，它整合了相似度置信度和置信度差异两种弱标签，以解决标注数据有限的问题，并在理论和实验上均表现出优越性。

**AI_Comments:** 该论文的创新点在于提出了一个利用多源弱监督信号（相似度置信度和置信度差异）的WSL框架，这超越了现有方法通常只利用单一弱监督类型的局限性。其理论分析证明了估计器的最优收敛性和对噪声的鲁棒性，为方法的有效性提供了坚实的基础。在标注数据稀缺的实际应用中，这种方法具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在实际机器学习应用中，数据标注困难且标注数据量有限。弱监督学习（WSL）提供了解决方案，但现有WSL方法大多只利用单一类型的弱监督信号，限制了其在数据稀缺场景下的应用。

**Method:** 本文提出SconfConfDiff分类这一新颖的WSL框架，它整合了相似度置信度和置信度差异这两种弱标签，并将其分配给未标记数据对。为实现该方法，推导了两种无偏风险估计器（一种基于现有估计器的凸组合，另一种是新设计的），并引入了风险校正方法以减轻负经验风险导致的过拟合。同时，对所提方法在不准确的类别先验概率和标签噪声下的鲁棒性进行了理论分析。

**Result:** 实验结果表明，所提出的方法在各种设置下始终优于现有基线。

**Conclusion:** 本文提出了一种新颖的弱监督学习框架SconfConfDiff分类，通过有效整合多源互补弱监督信号（相似度置信度和置信度差异），解决了传统弱监督学习在数据受限情况下的局限性，并在理论上证明了其估计器的最优收敛速率和鲁棒性，在实践中也展现出卓越的性能。

> **ai_Abstract:** 本文提出了一种新颖的弱监督学习（WSL）框架——SconfConfDiff分类，旨在解决标注数据有限的问题。该框架创新性地整合了相似度置信度和置信度差异这两种互补的弱监督信号，并推导了两种无偏风险估计器，同时引入风险校正方法以减轻过拟合。理论分析证明了其估计器的最优收敛速率和对噪声的鲁棒性，实验结果也表明其性能优于现有基线。

> **摘要翻译:** 在实际机器学习应用中，为数据分配准确的标签通常具有挑战性，并且增加标注实例的数量往往受到限制。在这种情况下，弱监督学习（WSL）能够通过不完整或不精确的监督进行训练，提供了一种实用且有效的解决方案。然而，大多数现有的WSL方法侧重于利用单一类型的弱监督。在本文中，我们提出了一种新颖的WSL框架，该框架利用来自多个关系视角的互补弱监督信号，这在标注数据有限时尤其有价值。具体来说，我们引入了SconfConfDiff分类，这是一种集成两种不同形式弱标签的方法：相似度置信度和置信度差异，这些弱标签被分配给未标注的数据对。为了实现这种方法，我们推导了两种用于分类的无偏风险估计器：一种基于现有估计器的凸组合，另一种通过建模两种弱标签之间的交互而新设计。我们证明了这两种估计器在估计误差界限方面均实现了最优收敛速率。此外，我们引入了一种风险校正方法来减轻由负经验风险引起的过拟合，并提供了关于所提方法对不准确的类别先验概率和标签噪声的鲁棒性的理论分析。实验结果表明，所提出的方法在各种设置下始终优于现有基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [258] [Deep Neural Networks with General Activations: Super-Convergence in Sobolev Norms](https://arxiv.org/abs/2508.05141)
> *具有通用激活函数的深度神经网络：Sobolev范数中的超收敛性*

*Yahong Yang, Juncai He* | **Category: cs.LG, math.NA** | **Updated: 2025-08-07**

**Keywords:** 深度神经网络, 超收敛, Sobolev范数, 偏微分方程, 近似理论

**Comment:** 

> **TL;DR:** 本文证明了深度神经网络在Sobolev空间中具有超越传统数值方法的近似精度，并称之为“超收敛”，同时为基于神经网络的偏微分方程方法提供了统一的理论基础。

**AI_Comments:** 本文的创新之处在于提出了“超收敛”现象，证明了深度神经网络在特定条件下能够达到超越传统数值方法的近似精度。这对于基于神经网络的偏微分方程求解方法具有重要意义，因为它提供了坚实的理论支撑，并有望推动神经网络在科学计算领域的广泛应用。此外，它弥补了长期存在的误差估计理论空白，为该领域的发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统数值近似技术（如有限元和谱方法）的收敛速度存在局限性，且基于神经网络的偏微分方程方法在误差估计理论方面存在显著空白，本研究旨在超越传统方法的精度并填补理论空白。

**Method:** 本文在Sobolev空间$W^{n,\infty}$中，针对具有常用和通用激活函数的深度全连接神经网络，建立了全面的近似结果，误差以$W^{m,p}$-范数（$m < n$，$1\le p \le \infty$）衡量。

**Result:** 推导出的收敛速度超越了有限元和谱方法等经典数值近似技术，表现出“超收敛”现象。分析表明，具有通用激活函数的深度网络在近似层面能够以优于传统数值方法的精度近似偏微分方程的弱解。

**Conclusion:** 深度神经网络在Sobolev范数中展现出超收敛特性，能够以更高的精度近似偏微分方程的弱解，从而在近似层面优于传统数值方法。这项工作弥补了基于神经网络的偏微分方程方法在误差估计理论方面的重大空白，为它们在科学计算中的应用提供了统一的理论基础。

> **ai_Abstract:** 本文研究了具有通用激活函数的深度全连接神经网络在Sobolev空间中的近似能力。研究结果表明，这些网络的近似速度（即“超收敛”）显著优于传统的有限元和谱方法，特别是在近似偏微分方程弱解方面表现出卓越的精度。这项工作不仅提供了关于深度网络在科学计算中应用的新见解，还填补了神经网络在偏微分方程误差估计理论方面的关键空白，奠定了统一的理论基础。

> **摘要翻译:** 本文在Sobolev空间$W^{n,\infty}$中，针对具有常用和通用激活函数的深度全连接神经网络，建立了全面的近似结果，误差以$W^{m,p}$-范数（$m < n$，$1\le p \le \infty$）衡量。推导出的收敛速度超越了有限元和谱方法等经典数值近似技术，表现出我们称之为“超收敛”的现象。我们的分析表明，具有通用激活函数的深度网络在近似层面能够以优于传统数值方法的精度近似偏微分方程的弱解。此外，这项工作弥补了基于神经网络的偏微分方程方法在误差估计理论方面的重大空白，为它们在科学计算中的应用提供了统一的理论基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [265] [PSEO: Optimizing Post-hoc Stacking Ensemble Through Hyperparameter Tuning](https://arxiv.org/abs/2508.05144)
> *PSEO：通过超参数调优优化事后堆叠集成*

*Beicheng Xu, Wei Liu, Keyao Ding, Yupeng Lu, Bin Cui* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** AutoML, 集成学习, 超参数优化, 堆叠集成, 后处理集成

**Comment:** 

> **TL;DR:** PSEO提出了一种通过超参数调优优化事后堆叠集成的方法，以解决现有AutoML系统在集成阶段策略固定、无法适应特定任务的问题，并在80个数据集上取得了最佳平均测试排名。

**AI_Comments:** PSEO的创新之处在于将超参数优化引入到AutoML的事后集成阶段，解决了传统方法在该阶段策略固定、适应性差的局限性。通过平衡基础模型的性能与多样性，并优化多层堆叠，PSEO显著提升了集成模型的泛化能力和性能，对AutoML领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AutoML系统在组合算法选择和超参数优化（CASH）问题中，虽然对最佳单一模型进行了广泛搜索，但在集成阶段通常采用固定策略，无法适应特定的任务特性，从而未能充分发挥集成学习的潜力。

**Method:** PSEO是一个用于事后堆叠集成优化的框架。首先，通过二元二次规划进行基础模型选择，平衡多样性和性能。其次，引入两种机制以充分发挥多层堆叠的潜力。最后，PSEO构建一个超参数空间并在其中搜索最优的事后集成策略。

**Result:** 在80个公共数据集上的实证结果表明，PSEO在16种方法中取得了最佳平均测试排名（2.96），包括最新AutoML系统中的事后设计和最先进的集成学习方法。

**Conclusion:** PSEO通过优化事后堆叠集成策略，显著提升了AutoML系统在不同任务上的性能，证明了在集成阶段进行超参数调优的重要性。

> **ai_Abstract:** 本研究提出了PSEO框架，旨在通过超参数调优优化AutoML中的事后堆叠集成。针对现有方法在集成阶段策略固定的问题，PSEO通过二元二次规划进行基础模型选择，并引入机制充分利用多层堆叠，同时构建超参数空间搜索最优集成策略。实验结果表明，PSEO在多个数据集上表现优异，超越了现有AutoML系统和先进集成方法。

> **摘要翻译:** 组合算法选择和超参数优化（CASH）问题是自动化机器学习（AutoML）中的基础问题。受集成学习成功的启发，最近的AutoML系统构建事后集成用于最终预测，而不是仅仅依赖于最佳单一模型。然而，尽管大多数CASH方法对最优单一模型进行了广泛搜索，但它们在集成阶段通常采用固定策略，未能适应特定的任务特性。为了解决这个问题，我们提出了PSEO，一个用于事后堆叠集成优化的框架。首先，我们通过二元二次规划进行基础模型选择，权衡多样性和性能。此外，我们引入了两种机制以充分发挥多层堆叠的潜力。最后，PSEO构建了一个超参数空间并在其中搜索最优的事后集成策略。在80个公共数据集上的实证结果表明，PSEO在16种方法中取得了最佳平均测试排名（2.96），包括最近AutoML系统中的事后设计和最先进的集成学习方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [272] [pFedDSH: Enabling Knowledge Transfer in Personalized Federated Learning through Data-free Sub-Hypernetwork](https://arxiv.org/abs/2508.05157)
> *pFedDSH：通过无数据子超网络实现个性化联邦学习中的知识迁移*

*Thinh Nguyen, Le Huy Khiem, Van-Tuan Tran, Khoa D Doan, Nitesh V Chawla, Kok-Seng Wong* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 个性化联邦学习, 知识迁移, 动态客户端入驻, 无数据超网络, 持续学习

**Comment:** 

> **TL;DR:** pFedDSH提出了一种新的联邦学习框架，通过无数据子超网络和数据无关回放策略，解决了动态客户端加入场景下现有客户端性能保持和新客户端知识迁移的挑战。

**AI_Comments:** pFedDSH通过引入无数据子超网络和数据无关回放策略，创新性地解决了个性化联邦学习中动态客户端入驻的实际挑战。其核心在于利用批次专用掩码来保护现有客户端知识，并利用数据无关方法实现知识回溯，这在保护隐私的同时提升了系统灵活性和效率。该方法在处理持续学习和适应性方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的个性化联邦学习（pFL）方法假设客户端参与是静态的，这不符合新客户端不断加入的真实世界场景（动态客户端入驻）。这种动态环境带来了挑战，包括如何在不重新训练的情况下保持现有客户端的性能，以及如何实现客户端批次之间的有效知识迁移。

**Method:** 论文提出了个性化联邦无数据子超网络（pFedDSH）框架。该框架基于一个中央超网络，通过嵌入向量为每个客户端生成个性化模型。为保持现有客户端的知识稳定性，pFedDSH引入了批次专用掩码，激活神经元子集以保留知识。此外，还引入了一种受DeepInversion启发的数据无关回放策略，以促进反向迁移，在不损害隐私的情况下提升现有客户端的性能。

**Result:** 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的大量实验表明，pFedDSH在所研究的场景中优于最先进的pFL和联邦持续学习基线。该方法为现有客户端实现了鲁棒的性能稳定性，同时也能适应新客户端并有效利用神经资源。

**Conclusion:** pFedDSH成功解决了动态客户端入驻场景下个性化联邦学习中的知识迁移和现有客户端性能保持问题，通过其创新的无数据子超网络和回放策略，实现了优异的性能和资源效率。

> **ai_Abstract:** 本文提出了pFedDSH，一个针对个性化联邦学习中动态客户端入驻场景的新框架。它通过一个中央超网络为客户端生成个性化模型，并利用批次专用掩码来保持现有客户端的知识稳定性。此外，引入数据无关回放策略以促进知识反向迁移。实验证明，pFedDSH在现有客户端性能保持和新客户端适应方面优于现有方法，并能有效利用神经资源。

> **摘要翻译:** 联邦学习（FL）实现了分布式客户端之间的协作模型训练，无需共享原始数据，提供了显著的隐私优势。然而，大多数现有的个性化联邦学习（pFL）方法假设客户端参与是静态的，这不反映新客户端可能持续加入联邦系统（即动态客户端入驻）的真实世界场景。在本文中，我们探讨了一种实际场景，其中新一批客户端以增量方式引入，而学习任务保持不变。这种动态环境带来了各种挑战，包括在不重新训练的情况下保持现有客户端的性能，以及实现客户端批次之间的有效知识迁移。为了解决这些问题，我们提出了个性化联邦无数据子超网络（pFedDSH），这是一种基于中央超网络的新颖框架，通过嵌入向量为每个客户端生成个性化模型。为了保持现有客户端的知识稳定性，pFedDSH结合了批次专用掩码，激活神经元子集以保留知识。此外，我们引入了一种受DeepInversion启发的数据无关回放策略，以促进反向迁移，在不损害隐私的情况下提升现有客户端的性能。在CIFAR-10、CIFAR-100和Tiny-ImageNet上进行的大量实验表明，pFedDSH在我们的研究场景中优于最先进的pFL和联邦持续学习基线。我们的方法为现有客户端实现了鲁棒的性能稳定性，同时也能适应新客户端并有效利用神经资源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [279] [S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection](https://arxiv.org/abs/2508.05164)
> *S$^2$M-Former：用于脑听觉注意力检测的脉冲对称混合分支形式网络*

*Jiaqi Wang, Zhengyu Ma, Xiongri Shen, Chenlin Zhou, Leilei Zhao, Han Zhang, Yi Zhong, Siqi Cai, Zhenxi Song, Zhiguo Zhang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 听觉注意力检测, 脉冲神经网络, 脑电图, 对称混合, 能效

**Comment:** 

> **TL;DR:** 提出S$^2$M-Former，一种低功耗、高性能的脉冲神经网络，通过对称结构和轻量级操作，显著提高EEG听觉注意力检测的能效和性能。

**AI_Comments:** 这篇论文的创新点在于其独特的S$^2$M-Former框架，特别是在能效受限的EEG-based AAD领域。它成功地将生物学启发的脉冲神经网络（SNN）与对称混合架构相结合，并通过引入轻量级1D操作大幅减少了参数和能耗，同时保持了高精度。这对于开发实际的神经控制设备具有重要意义，因为它解决了现有方法在功耗和效率方面的限制。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于EEG的听觉注意力检测（AAD）方法缺乏协同框架，无法在能效限制下充分利用互补的EEG特征。

**Method:** 提出S$^2$M-Former，一种新颖的脉冲对称混合框架。主要创新包括：1) 采用由并行空间和频率分支组成的脉冲驱动对称架构，采用镜像模块化设计，利用生物学合理的token-channel混合器增强跨分支的互补学习；2) 引入轻量级1D token序列替代传统3D操作，显著减少参数并降低功耗。

**Result:** 参数减少14.7倍，能耗比近期ANN方法降低5.8倍，在参数效率和性能上超越现有SNN基线，并在三个AAD基准测试中实现与SOTA相当的解码精度。

**Conclusion:** S$^2$M-Former是AAD任务中一种有前景的低功耗、高性能解决方案。

> **ai_Abstract:** 该论文提出了S$^2$M-Former，一种用于脑听觉注意力检测（AAD）的新型脉冲对称混合框架。它通过引入脉冲驱动的对称架构，包含并行空间和频率分支，并利用1D token序列替代传统3D操作，显著减少了模型参数和能耗。实验证明，S$^2$M-Former在保持SOTA解码精度的同时，实现了显著的能效提升，为AAD任务提供了低功耗、高性能的解决方案。

> **摘要翻译:** 听觉注意力检测（AAD）旨在从脑电图（EEG）记录中解码听众在复杂听觉环境中的注意力焦点，这对于开发神经控制的助听设备至关重要。尽管最近取得了进展，但基于EEG的AAD仍然受到缺乏协同框架的阻碍，该框架无法在能效限制下充分利用互补的EEG特征。我们提出了S$^2$M-Former，一种新颖的脉冲对称混合框架来解决这一限制，通过两项关键创新：i) 提出一种由并行空间和频率分支组成的脉冲驱动对称架构，采用镜像模块化设计，利用生物学合理的token-channel混合器增强跨分支的互补学习；ii) 引入轻量级1D token序列替代传统3D操作，将参数减少14.7倍。这种受大脑启发的脉冲架构进一步降低了功耗，与最近的ANN方法相比，能耗降低了5.8倍，同时在参数效率和性能方面也超越了现有的SNN基线。在三个AAD基准测试（KUL、DTU和AV-GC-AAD）以及三种设置（试验内、跨试验和跨受试者）上的综合实验表明，S$^2$M-Former实现了与最先进（SOTA）解码精度相当的性能，使其成为AAD任务中一种有前景的低功耗、高性能解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [286] [Near Optimal Inference for the Best-Performing Algorithm](https://arxiv.org/abs/2508.05173)
> *最优性能算法的近乎最优推断*

*Amichai Painsky* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 算法选择, 子集选择, 多项分布, 近乎最优推断, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了一种新的框架，用于从一组竞争的机器学习算法中，在性能差异微小的情况下，以高置信度识别出在未来未见数据集上表现最佳的算法子集，并提供了优于现有方法的渐近和有限样本方案。

**AI_Comments:** 本文的创新之处在于将识别最佳算法的问题巧妙地转化为多项分布的子集选择问题，并为此引入了一个新颖且理论上得到支持的框架。所提出的渐近和有限样本方案在性能上显著优于现有方法，并通过匹配的下界提供了强有力的理论保证，这对于实际应用中处理性能差异微小的算法选择问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在机器学习领域，面对一组在基准数据集上表现相似的竞争算法时，需要识别出在未来、未见数据集上最有可能排名最高的最佳算法。传统方法可能因性能差异微小而不足，因此需要一种更鲁棒的方法来确定包含最佳算法的最小子集。

**Method:** 将该问题建模为多项分布的子集选择问题。具体来说，给定来自可数字母表的样本，目标是识别一个最小的符号子集，该子集以高置信度包含总体中最频繁的符号。为此，本文引入了一种新颖的子集选择框架。

**Result:** 提出了渐近和有限样本方案，这些方案显著优于目前已知的方法。此外，还提供了匹配的下界，证明了所提出方案的优越性能。

**Conclusion:** 本文为多项分布的子集选择问题引入了一个新颖的框架，并提供了在识别最佳算法方面性能显著优于现有方法的渐近和有限样本方案，并有相应的理论下界支持。

> **ai_Abstract:** 本文针对机器学习算法选择问题，提出了一种识别最佳算法的近乎最优推断方法。该方法将问题建模为多项分布的子集选择，旨在以高置信度从多个性能相近的算法中，识别出包含未来数据集上最佳算法的最小子集。研究引入了一个新颖的框架，并提供了在渐近和有限样本情况下均显著优于现有方法的方案，同时提供了匹配的下界以证明其优越性。

> **摘要翻译:** 考虑一组相互竞争的机器学习算法。给定它们在基准数据集上的表现，我们希望识别出表现最佳的算法。具体来说，哪个算法最有可能在未来的、未见过的数据集上排名最高。一种自然的方法是选择在基准上表现最佳的算法。然而，在许多情况下，性能差异微乎其微，其他候选算法也可能被考虑。这个问题被表述为多项分布的子集选择问题。形式上，给定来自可数字母表的样本，我们的目标是识别一个最小的符号子集，该子集以高置信度包含总体中最频繁的符号。在这项工作中，我们为子集选择问题引入了一个新颖的框架。我们提供了渐近和有限样本方案，这些方案显著优于目前已知的方法。此外，我们还提供了匹配的下界，证明了我们提出的方案的优越性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [294] [Human Activity Recognition from Smartphone Sensor Data for Clinical Trials](https://arxiv.org/abs/2508.05175)
> *临床试验中基于智能手机传感器数据的人体活动识别*

*Stefania Russo, Rafał Klimas, Marta Płonka, Hugo Le Gall, Sven Holm, Dimitar Stanev, Florian Lipsmeier, Mattia Zanon, Lito Kriara* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 人体活动识别, 智能手机传感器, ResNet, 临床试验, 多发性硬化症

**Comment:** 

> **TL;DR:** 开发了一种基于ResNet的HAR模型，利用智能手机数据准确识别日常活动，并在不同佩戴位置表现出高鲁棒性，适用于临床试验。

**AI_Comments:** 这项研究的创新之处在于开发了一种低开销的ResNet模型，并在真实世界的多种智能手机佩戴位置下验证了其高鲁棒性，这对于在临床试验中实际部署和应用基于智能手机的HAR技术至关重要。其在多发性硬化症患者数据上的评估也增加了其在医疗健康领域的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种低开销的人体活动识别模型，用于临床试验中检测步态/非步态活动和日常活动，特别是针对健康对照组和多发性硬化症患者。

**Method:** 开发了一个基于ResNet的人体活动识别（HAR）模型，具有最小的开销。模型旨在检测步态与非步态活动以及日常活动（步行、跑步、楼梯、站立、坐着、躺着、坐到站转换）。使用来自健康对照组（HC）和多发性硬化症患者（PwMS）的智能手机传感器数据进行训练和评估。数据集包括GaitLab研究、内部罗氏数据集和公开可用数据源。评估数据包括34名HC和68名PwMS。

**Result:** 在GaitLab和罗氏数据集中，HAR模型检测步态与非步态活动的准确率分别为98.4%和99.6%，与现有最先进的ResNet模型（99.3%和99.4%）相似。对于日常活动，所提出的模型在内部罗氏数据集上的准确率高于现有最先进的模型（96.2% vs 91.9%）。该模型在9种智能手机佩戴位置（手提包、购物袋、斜挎包、背包、连帽衫口袋、外套/夹克口袋、手、脖子、腰带）上均保持高性能，优于现有最先进模型2.8% - 9.0%。

**Conclusion:** 所提出的HAR模型能准确检测日常活动，并对各种智能手机佩戴位置表现出高度鲁棒性，证明了其在临床试验中的实际适用性。

> **ai_Abstract:** 本文提出了一种基于ResNet的人体活动识别（HAR）模型，利用智能手机传感器数据来识别步态/非步态活动和多种日常活动。该模型在健康对照组和多发性硬化症患者数据上进行了训练和评估。结果显示，该模型在检测步态与非步态活动方面与现有最先进模型表现相当，而在日常活动识别方面，其准确率更高，并且在多种智能手机佩戴位置下展现出卓越的鲁棒性，证明了其在临床试验中的实用价值。

> **摘要翻译:** 我们开发了一个基于ResNet且开销极小的人体活动识别（HAR）模型，用于检测步态与非步态活动以及日常活动（步行、跑步、上下楼梯、站立、坐着、躺着、坐到站转换）。该模型使用来自健康成年对照组（HC）和患有多发性硬化症（PwMS）且Expanded Disability Status Scale（EDSS）评分为0.0-6.5的人群的智能手机传感器数据进行训练和评估。数据集包括GaitLab研究（ISRCTN15993728）、一个罗氏内部数据集以及公开可用的数据源（仅用于训练）。评估中包含了34名HC和68名PwMS的数据（平均[标准差]EDSS：4.7[1.5]）。HAR模型在GaitLab和罗氏数据集中检测步态与非步态活动的准确率分别为98.4%和99.6%，与一个对比性的最先进ResNet模型（99.3%和99.4%）相似。对于日常活动，所提出的模型不仅比最先进模型表现出更高的准确率（96.2% vs 91.9%；罗氏内部数据集），而且在9种智能手机佩戴位置（手提包、购物袋、斜挎包、背包、连帽衫口袋、外套/夹克口袋、手、脖子、腰带）上均保持高性能，比最先进模型高出2.8% - 9.0%。总而言之，所提出的HAR模型能准确检测日常活动，并对各种智能手机佩戴位置表现出高度鲁棒性，证明了其在实际应用中的可行性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [300] [Physics-Informed Time-Integrated DeepONet: Temporal Tangent Space Operator Learning for High-Accuracy Inference](https://arxiv.org/abs/2508.05190)
> *物理信息时间积分DeepONet：用于高精度推理的时间切线空间算子学习*

*Luis Mandl, Dibyajyoti Nayak, Tim Ricken, Somdatta Goswami* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 物理信息神经网络, 深度算子网络, 时间依赖PDEs, 算子学习, 长期预测

**Comment:** 

> **TL;DR:** PITI-DeepONet通过学习时间导数算子并结合经典时间步进，解决了时间依赖PDEs长期预测中传统FR和AR方法的精度和稳定性问题，显著提高了长期预测准确性。

**AI_Comments:** PITI-DeepONet的创新之处在于其通过学习时间导数算子而非直接预测未来状态来解决长期时间依赖PDEs的建模问题，并结合了物理信息训练和残差监测机制，这显著增强了模型的稳定性和泛化能力。其优于传统FR和AR方法的表现，尤其是在误差累积和泛化性方面的改进，使其在科学机器学习领域具有重要意义，为复杂动力学系统的长期模拟提供了更可靠的框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有全展开 (FR) 和自回归 (AR) 方法在长时间范围的时间依赖偏微分方程 (PDEs) 建模和推理中存在局限性。FR 方法泛化性差且无法捕获因果关系，AR 方法则有误差累积问题，两者都限制了长期精度和可靠性。

**Method:** 提出了一种双输出架构的物理信息时间积分深度算子网络 (PITI-DeepONet)。该网络通过完全物理信息或混合物理与数据驱动目标进行训练，以确保长期演化的稳定性和准确性。它不直接预测未来状态，而是学习当前状态的时间导数算子，并使用经典时间步进方案进行积分以推进解。此外，推理过程中可利用残差监测来评估预测质量并检测系统是否超出训练域。

**Result:** PITI-DeepONet 在基准问题上表现出优于传统方法的长期推理精度。一维热方程的平均相对L2误差比FR降低84%，比AR降低79%；一维Burgers方程比FR降低87%，比AR降低98%；二维Allen-Cahn方程比FR降低42%，比AR降低89%。

**Conclusion:** PITI-DeepONet 通过超越传统的FR和AR方案，为复杂时间依赖偏微分方程的更可靠、长期积分提供了新途径。

> **ai_Abstract:** 本文提出了一种名为PITI-DeepONet的新型深度学习架构，旨在解决时间依赖偏微分方程(PDEs)长期预测中传统方法的精度和稳定性问题。与直接预测未来状态不同，PITI-DeepONet学习时间导数算子，并通过经典时间步进方案积分推进解。该模型采用物理信息或混合目标训练，并结合残差监测。在多个基准问题上的实验结果表明，PITI-DeepONet在扩展的推理时间范围内显著提高了精度，有效克服了全展开和自回归方法的局限性，为复杂PDEs的长期模拟提供了更可靠的工具。

> **摘要翻译:** 准确建模和推断长时间范围内的时变偏微分方程 (PDEs) 仍然是科学机器学习中的核心挑战。传统的全展开 (FR) 方法，即一次性预测整个轨迹的方法，通常无法捕捉因果依赖关系，并且在训练时间范围之外的泛化能力差。自回归 (AR) 方法，即逐步演化系统的方法，则存在误差累积问题，限制了长期精度。这些缺点限制了这两种策略的长期精度和可靠性。为了解决这些问题，我们引入了物理信息时间积分深度算子网络 (PITI-DeepONet)，这是一种双输出架构，通过完全物理信息或混合物理与数据驱动目标进行训练，以确保在远超训练范围的长时间演化中保持稳定和准确。该网络不预测未来状态，而是从当前状态学习时间导数算子，并使用经典的步进方案对其进行积分，以使解在时间上向前推进。此外，该框架可以在推理过程中利用残差监测来估计预测质量并检测系统何时超出训练域。应用于基准问题时，与传统方法相比，PITI-DeepONet 在扩展的推理时间范围内显示出更高的精度。对于一维热方程，平均相对L2误差比FR降低84%，比AR降低79%；对于一维Burgers方程，比FR降低87%，比AR降低98%；对于二维Allen-Cahn方程，比FR降低42%，比AR降低89%。通过超越经典的FR和AR方案，PITI-DeepONet 为复杂时变PDEs的更可靠、长期积分铺平了道路。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [307] [DFW: A Novel Weighting Scheme for Covariate Balancing and Treatment Effect Estimation](https://arxiv.org/abs/2508.05215)
> *DFW：一种用于协变量平衡和处理效应估计的新型加权方案*

*Ahmad Saeed Khan, Erik Schaffernicht, Johannes Andreas Stork* | **Category: cs.LG, stat.ME** | **Updated: 2025-08-07**

**Keywords:** 倾向评分, 因果效应估计, 协变量平衡, 权重方案, 解混淆因子

**Comment:** 

> **TL;DR:** 提出DFW，一种新的基于倾向评分的加权方法，通过解混淆因子解决协变量不平衡和处理效应估计中的权重不稳定问题，表现优于现有方法。

**AI_Comments:** DFW的创新之处在于引入了“解混淆因子”来构造更稳定、有界的权重，有效解决了传统倾向评分加权方法（如IPW）中权重不稳定的问题，从而提高了因果效应估计的准确性。其能够扩展到多处理设置也增加了其实用性。该方法对于从观测数据中进行可靠因果推断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从观察性数据中估计因果效应面临挑战，因为选择偏差会导致处理组之间协变量分布不平衡。现有倾向评分加权方法（如IPW）在倾向评分方差高时可能导致权重不稳定，进而降低处理选择偏差和处理效应估计的能力。

**Method:** 本文提出解混淆因子加权（DFW），这是一种新型的基于倾向评分的方法，利用解混淆因子来构建稳定有效的样本权重。DFW优先考虑受混淆较少的样本，同时减轻受高度混淆样本的影响，从而生成一个更好地近似随机对照试验的伪总体。该方法确保权重有界、方差更低并改善协变量平衡，且可自然扩展到多处理设置。

**Result:** 通过在真实世界基准和合成数据集上进行大量实验，结果表明DFW在协变量平衡和处理效应估计方面均优于现有方法，包括IPW和CBPS。

**Conclusion:** DFW是一种有效的新型加权方案，能够克服现有倾向评分加权方法的局限性，显著改善协变量平衡和处理效应估计，尤其在处理权重不稳定问题上表现突出。

> **ai_Abstract:** 本文提出了一种名为解混淆因子加权（DFW）的新型倾向评分加权方法，旨在解决观测数据中因选择偏差导致的协变量不平衡和处理效应估计中的权重不稳定问题。与现有方法（如IPW）不同，DFW利用解混淆因子构建稳定且有界的样本权重，通过优先处理低混淆样本来改善协变量平衡并降低方差，从而更好地模拟随机对照试验。实验结果表明，DFW在协变量平衡和处理效应估计方面均优于IPW和CBPS等现有方法。

> **摘要翻译:** 从观察数据中估计因果效应具有挑战性，因为选择偏差会导致处理组之间协变量分布不平衡。基于倾向评分的加权方法通过重新加权样本来模拟随机对照试验（RCT），广泛用于解决此问题。然而，这些方法的有效性严重依赖于观察数据和倾向评分估计器的准确性。例如，逆倾向加权（IPW）根据倾向评分的倒数分配权重，当倾向评分具有高方差时（无论是由于数据还是模型错误指定），这可能导致权重不稳定，最终降低处理选择偏差和处理效应估计的能力。为了克服这些限制，我们提出了去混淆因子加权（DFW），这是一种新型的基于倾向评分的方法，它利用去混淆因子来构建稳定有效的样本权重。DFW优先考虑受混淆较少的样本，同时减轻受高度混淆样本的影响，从而产生一个更好地近似RCT的伪总体。我们的方法确保权重有界、方差更低并改善协变量平衡。虽然DFW是为二元处理制定的，但它可以自然地扩展到多处理设置，因为去混淆因子是根据每个样本实际接收到的处理的估计概率计算的。通过在真实世界基准和合成数据集上进行大量实验，我们证明DFW在协变量平衡和处理效应估计方面均优于现有方法，包括IPW和CBPS。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [313] [ML-based Short Physical Performance Battery future score prediction based on questionnaire data](https://arxiv.org/abs/2508.05222)
> *基于问卷数据的机器学习短体能表现量表未来得分预测*

*Marcin Kolakowski, Seif Ben Bader* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 机器学习, SPPB, 预测, XGBoost, 问卷数据

**Comment:** 

> **TL;DR:** 本文研究了基于问卷数据预测四年后的短体能表现量表（SPPB）得分的可能性，其中XGBoost算法表现最佳。

**AI_Comments:** 该研究提出了一种利用机器学习预测老年人未来体能表现的方法，这对于早期干预和减缓身体机能衰退具有重要意义。XGBoost的优秀表现及其结合Shapley值进行特征选择的方法，展示了其在处理此类预测任务上的潜力和可解释性。这项工作有助于更早地识别需要干预的老年人。

<details>
  <summary>Details</summary>

**Motivation:** 为了有效减缓老年人身体机能的衰退，需要在症状出现之初就进行干预。因此，预测老年人未来的体能表现至关重要。

**Method:** 本文分析了基于问卷数据预测四年后短体能表现量表（SPPB）得分的可能性。测试的机器学习算法包括随机森林、XGBoost、线性回归、密集神经网络和TabNet神经网络。研究还基于Shapley值分析选择了特征子集，并重新训练了XGBoost回归器。

**Result:** XGBoost算法取得了最佳结果，平均绝对误差为0.79分。基于Shapley值分析选择较小特征子集（10到20个）后，重新训练的XGBoost回归器实现了0.82的平均绝对误差。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究探讨了利用问卷数据预测老年人四年后短体能表现量表（SPPB）得分的可行性。通过比较随机森林、XGBoost、线性回归、密集神经网络和TabNet等机器学习算法，发现XGBoost表现最佳，平均绝对误差为0.79分。此外，通过Shapley值分析进行特征选择后，使用较少特征的XGBoost模型仍能达到0.82的平均绝对误差。

> **摘要翻译:** 有效减缓老年人身体机能的衰退需要在症状出现之初就进行干预。在本文中，我们分析了基于问卷数据预测四年后短体能表现量表（SPPB）得分的可能性。测试的机器学习算法包括随机森林、XGBoost、线性回归、密集神经网络和TabNet神经网络。XGBoost取得了最佳结果（平均绝对误差为0.79分）。基于Shapley值分析，我们选择了较小的特征子集（从10到20个），并重新训练了XGBoost回归器，实现了0.82的平均绝对误差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [321] [Cross-LoRA: A Data-Free LoRA Transfer Framework across Heterogeneous LLMs](https://arxiv.org/abs/2508.05232)
> *Cross-LoRA：一个跨异构LLM的无数据LoRA迁移框架*

*Feifan Xia, Mingyang Liao, Yuyang Fang, Defang Li, Yantong Xie, Weikang Li, Yang Li, Deguo Xia, Jizhou Huang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** LoRA, PEFT, 异构LLM, 无数据迁移, 子空间对齐

**Comment:** 

> **TL;DR:** Cross-LoRA是一个无数据、训练无关的框架，用于在不同的大语言模型（LLM）之间迁移LoRA模块，解决了传统PEFT方法与基础模型紧密耦合的问题。

**AI_Comments:** Cross-LoRA的创新点在于其无数据和训练无关的LoRA模块迁移能力，极大地提升了LoRA在异构LLM环境中的应用灵活性和效率。通过子空间对齐和投影机制，它巧妙地解决了模型架构差异带来的兼容性问题，为LLM的轻量级适配和部署提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的参数高效微调（PEFT）方法（如LoRA）与基础模型架构紧密耦合，限制了它们在异构预训练大语言模型（LLM）中的适用性。本文旨在解决这一局限性。

**Method:** Cross-LoRA包含两个主要组件：(a) LoRA-Align，通过截断奇异值分解（SVD）和Frobenius最优线性变换在源和目标基础模型之间执行子空间对齐，确保维度不匹配下的兼容性；(b) LoRA-Shift，应用对齐的子空间将源LoRA权重更新投影到目标模型参数空间。这两个组件都是无数据、训练无关的。

**Result:** 在ARCs、OBOA和HellaSwag上的实验表明，Cross-LoRA相对于基础模型实现了高达5.26%的相对增益。在其他常识推理基准测试中，Cross-LoRA保持了与直接训练的LoRA适配器相当的性能。

**Conclusion:** Cross-LoRA成功地提供了一个无数据、训练无关的LoRA迁移框架，有效解决了LoRA模块在异构LLM之间迁移的兼容性问题，并展现出与直接训练方法相当或更好的性能。

> **ai_Abstract:** Cross-LoRA是一个创新的无数据框架，旨在解决传统LoRA微调方法在不同大型语言模型之间迁移时的兼容性问题。它通过LoRA-Align进行子空间对齐，并通过LoRA-Shift将LoRA权重更新投影到目标模型空间，实现了LoRA模块在异构LLM间的有效迁移。该方法无需数据和训练，能在短时间内完成适配，并在多个基准测试中展现出与直接训练LoRA相当或更优的性能。

> **摘要翻译:** 传统的参数高效微调（PEFT）方法，如LoRA，与基础模型架构紧密耦合，这限制了它们在异构预训练大型语言模型（LLM）中的适用性。为了解决这一局限性，我们引入了Cross-LoRA，这是一个无需额外训练数据即可在不同基础模型之间迁移LoRA模块的无数据框架。Cross-LoRA由两个关键组件组成：(a) LoRA-Align，它通过截断奇异值分解（SVD）和Frobenius最优线性变换在源和目标基础模型之间执行子空间对齐，确保在维度不匹配下的兼容性；(b) LoRA-Shift，它应用对齐的子空间将源LoRA权重更新投影到目标模型参数空间。这两个组件都是无数据、训练无关的，并能在20分钟内在商用GPU上实现轻量级适配。在ARCs、OBOA和HellaSwag上的实验表明，Cross-LoRA相对于基础模型实现了高达5.26%的相对增益。在其他常识推理基准测试中，Cross-LoRA保持了与直接训练的LoRA适配器相当的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs](https://arxiv.org/abs/2508.05257)
> *MoBE：用于压缩基于MoE的LLM的基专家混合模型*

*Xiaodong Chen, Mingming Ha, Zhenzhong Lan, Jing Zhang, Jianguo Li* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 混合专家, 大语言模型, 模型压缩, MoBE, 内存效率

**Comment:** 

> **TL;DR:** MoBE是一种新的方法，通过将专家矩阵分解为共享基矩阵的线性组合，来压缩基于MoE的大型语言模型，同时将精度损失降至最低，解决了部署时的内存需求问题。

**AI_Comments:** MoBE的创新之处在于其独特的专家矩阵分解和共享基矩阵重参数化策略，这有效地解决了MoE模型在内存效率和精度损失之间的权衡问题。通过引入共享基矩阵，它显著降低了模型的内存占用，同时通过最小化重构误差保持了高精度。这对于大规模MoE-based LLM的实际部署具有重要意义，因为它提供了一个在不牺牲性能的前提下实现显著压缩的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管MoE架构在扩展大型语言模型（LLM）方面表现出色，但基于MoE的LLM在部署时对内存的需求巨大，带来了严峻挑战。现有的MoE压缩方法在适度压缩率下也会导致显著的精度下降（例如相对下降7-14%）。

**Method:** 本文提出了一种新颖的基专家混合（MoBE）方法。具体来说，每个专家中的上/门控矩阵通过秩分解W=AB进行分解，其中矩阵A对每个专家是唯一的。相对较大的矩阵B被进一步重新参数化为给定MoE层中所有专家共享的基矩阵{Bi}的线性组合。通过最小化相对于原始权重矩阵的重构误差来学习这种分解。

**Result:** 实验表明，与现有工作相比，MoBE实现了显著更低的精度下降。例如，MoBE可以将Qwen3-235B-A22B-2507、DeepSeek-V3-0324（671B）和Kimi-K2-Instruct（1T）的参数数量减少24%-30%，而精度下降仅为1%-2%（相对下降约2%）。

**Conclusion:** MoBE通过引入一种新颖的专家矩阵分解和共享基矩阵重参数化方法，成功地大幅压缩了基于MoE的LLM，同时将精度损失降至最低，显著优于现有压缩方法，有效解决了大规模MoE模型部署中的内存挑战。

> **ai_Abstract:** MoBE是一种新颖的混合专家（MoE）压缩方法，旨在解决大型语言模型（LLM）部署中高内存需求的问题。该方法通过将每个专家中的上/门控矩阵分解为W=AB的形式，其中A是专家独有的，B是所有专家共享基矩阵的线性组合。通过最小化重构误差来学习这种分解。实验证明，MoBE在将参数量减少24%-30%的同时，仅导致1%-2%的精度下降（相对下降约2%），显著优于现有方法，为MoE-based LLM的实际部署提供了更高效的解决方案。

> **摘要翻译:** 混合专家（MoE）架构已成为扩展大型语言模型（LLM）的主导范式。尽管MoE-based LLM（如DeepSeek-V3-0324和Kimi-K2-Instruct）提供了强大的性能和计算效率，但其在部署时对内存的巨大需求带来了严峻挑战。虽然最近的工作探索了MoE压缩来解决这个问题，但现有方法即使在适度的压缩率下也经常遭受相当大的精度下降（例如相对下降7-14%）。本文引入了一种新颖的基专家混合（MoBE）方法，该方法在实现模型压缩的同时，仅带来最小的精度下降。具体来说，每个专家中的上/门控矩阵通过秩分解W = AB进行分解，其中矩阵A对每个专家是唯一的。相对较大的矩阵B被进一步重新参数化为给定MoE层中所有专家共享的基矩阵{Bi}的线性组合。通过最小化相对于原始权重矩阵的重构误差来学习这种分解。实验表明，MoBE与现有工作相比，实现了显著更低的精度下降。例如，MoBE可以将Qwen3-235B-A22B-2507、DeepSeek-V3-0324（671B）和Kimi-K2-Instruct（1T）的参数数量减少24%-30%，而精度下降仅为1%-2%（相对下降约2%）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [336] [RLHF Fine-Tuning of LLMs for Alignment with Implicit User Feedback in Conversational Recommenders](https://arxiv.org/abs/2508.05289)
> *RLHF微调大型语言模型以对齐会话推荐器中的隐式用户反馈*

*Zhongheng Yang, Aijia Sun, Yushang Zhao, Yinuo Yang, Dannier Li, Chengrui Zhou* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** RLHF, 大型语言模型, 会话推荐系统, 隐式用户反馈, 微调

**Comment:** 

> **TL;DR:** 本文提出了一种使用强化学习与人类反馈（RLHF）的方法，通过捕获隐式用户反馈来微调大型语言模型（LLMs），以提升会话推荐系统的性能。

**AI_Comments:** 该论文的创新点在于将RLHF应用于会话推荐系统，以解决传统监督学习无法捕捉隐式用户反馈的局限性。通过引入奖励模型和PPO优化，它有效地将LLM与用户的深层偏好对齐，为构建更智能、更个性化的推荐系统提供了新的方向。其对隐式信号重要性的强调及其在实际数据集上的验证，提升了该方法的实用价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的监督微调方法无法捕获会话推荐系统中大型语言模型（LLMs）的隐式用户反馈信号（如停留时间、情感极性、参与模式），导致推荐结果无法持续对齐用户偏好。

**Method:** 本文提出了一种使用强化学习与人类反馈（RLHF）的微调方案，以最大化多轮推荐上下文中的隐含用户反馈（IUF）。该方法通过学习一个基于弱标记参与信息的奖励模型$R_{\phi}$，并使用近端策略优化（PPO）方法优化基础LLM $M_{\theta}$。其架构建模了会话状态转换$s_t \to a_t \to s_{t+1}$，其中动作$a_t$与LLM根据会话历史生成的物品建议相关联。

**Result:** 在合成数据集和真实世界数据集（如REDIAL、OpenDialKG）上的评估表明，经过RLHF微调的模型在top-k推荐准确性、连贯性和用户满意度方面表现更优。

**Conclusion:** 隐式信号对齐能够有效地实现会话推荐系统（CRS）的可扩展和用户自适应设计。

> **ai_Abstract:** 本文提出了一种新颖的RLHF（强化学习与人类反馈）微调方法，旨在解决基于LLM的会话推荐系统（CRS）无法有效捕获隐式用户反馈的问题。通过构建一个基于弱标记参与信息的奖励模型并采用PPO算法优化LLM，该方法能够最大化隐含用户反馈。实验结果表明，与传统方法相比，RLHF微调后的模型在推荐准确性、连贯性和用户满意度方面均有显著提升，证明了隐式信号对齐在实现可扩展和用户自适应CRS设计中的有效性。

> **摘要翻译:** 基于大型语言模型（LLMs）的会话推荐系统（CRS）需要不断与用户偏好保持一致，以提供令人满意且与上下文相关的物品推荐。传统的监督微调无法捕获隐式反馈信号，例如停留时间、情感极性或参与模式。在本文中，我们分享了一种使用人类反馈强化学习（RLHF）的微调解决方案，以在多轮推荐上下文中最大化隐含用户反馈（IUF）。我们指定了一个奖励模型$R_{\phi}$，该模型通过弱标记的参与信息学习，并通过近端策略优化（PPO）方法优化基础LLM $M_{\theta}$来最大化以用户为中心的效用。该架构建模了会话状态转换$s_t \to a_t \to s_{t+1}$，其中动作$a_t$仅在过去会话历史的条件下与LLM生成的物品建议相关联。在合成数据集和真实世界数据集（例如REDIAL、OpenDialKG）上的评估表明，我们经过RLHF微调的模型在top-k推荐准确性、连贯性和用户满意度方面表现更好。本文表明，隐式信号对齐可以有效地实现CRS的可扩展和用户自适应设计。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [344] [Optimal Growth Schedules for Batch Size and Learning Rate in SGD that Reduce SFO Complexity](https://arxiv.org/abs/2508.05297)
> *降低SFO复杂度的SGD中批量大小和学习率的最优增长策略*

*Hikaru Umeda, Hideaki Iiduka* | **Category: cs.LG, math.OC** | **Updated: 2025-08-07**

**Keywords:** 批量大小, 学习率, SGD, SFO复杂度, 最优策略

**Comment:** 

> **TL;DR:** 该论文推导了随机梯度下降（SGD）中批量大小和学习率的最优增长策略，以降低随机一阶预言机（SFO）复杂度，从而提高深度学习训练效率。

**AI_Comments:** 该论文通过理论推导和实验验证，为深度学习训练中的关键超参数调度问题提供了创新的解决方案。其提出的最优增长策略有望显著提高大规模深度学习模型的训练效率和泛化性能，具有重要的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型虽然取得了显著进展，但其训练过程存在巨大的计算瓶颈。随机梯度方法中批量大小和学习率的简单调度会降低优化效率并损害泛化能力。本研究旨在探究如何最优地调整这些超参数以平衡效率和收敛性。

**Method:** 本研究基于随机一阶预言机（SFO）复杂度分析了问题，SFO复杂度定义为达到经验损失的近似驻点所需的梯度评估的预期次数。作者理论推导了能降低SFO复杂度的批量大小和学习率的最优增长策略，并通过大量实验进行了验证。

**Result:** 研究理论推导了能够降低SFO复杂度的批量大小和学习率的最优增长策略。这些理论推导的策略通过广泛的实验得到了验证。

**Conclusion:** 本研究的结果为深度学习中可扩展且高效的大批量训练提供了重要的理论见解和实用的指导方针。

> **ai_Abstract:** 本论文旨在解决深度学习训练中的计算瓶颈问题，通过研究随机梯度下降（SGD）中批量大小和学习率的优化调度。作者基于随机一阶预言机（SFO）复杂度，理论推导并实验验证了能够降低SFO复杂度的最优增长策略。这些成果为深度学习中高效且可扩展的大批量训练提供了理论和实践指导。

> **摘要翻译:** 深度学习模型前所未有的增长带来了显著的进步，但也引入了巨大的计算瓶颈。影响训练效率的一个关键因素是随机梯度方法中的批量大小和学习率调度。然而，这些超参数的简单调度会降低优化效率并损害泛化能力。受近期理论见解的启发，我们研究了在训练过程中如何增加批量大小和学习率以平衡效率和收敛性。我们基于随机一阶预言机（SFO）复杂度分析了这个问题，SFO复杂度定义为达到经验损失的 $\epsilon$-近似驻点所需的梯度评估的预期次数。我们理论推导了能降低SFO复杂度的批量大小和学习率的最优增长策略，并通过大量实验验证了它们。我们的结果为深度学习中可扩展和高效的大批量训练提供了理论见解和实践指导。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [352] [Adaptive Batch Size and Learning Rate Scheduler for Stochastic Gradient Descent Based on Minimization of Stochastic First-order Oracle Complexity](https://arxiv.org/abs/2508.05302)
> *自适应批处理大小和学习率调度器，用于基于最小化随机一阶预言机复杂度的随机梯度下降*

*Hikaru Umeda, Hideaki Iiduka* | **Category: cs.LG, math.OC** | **Updated: 2025-08-07**

**Keywords:** 随机梯度下降, 自适应调度, 批处理大小, 学习率, 随机一阶预言机复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种自适应调度策略，通过调整批处理大小和学习率，加速随机梯度下降（SGD）的收敛，该策略基于最小化随机一阶预言机复杂度的理论。

**AI_Comments:** 该论文的创新之处在于提出了一种基于理论临界批处理大小概念和实际梯度范数衰减观察的自适应调度策略。这种方法有效地解决了SGD中批处理大小和学习率的敏感性问题，并通过实验证明了其在加速收敛方面的有效性。它提供了一种更鲁棒和高效的SGD优化方法。

<details>
  <summary>Details</summary>

**Motivation:** 迷你批次随机梯度下降（SGD）的收敛行为对批处理大小和学习率设置高度敏感。

**Method:** 引入了一种自适应调度策略，该策略利用关于临界批处理大小的理论发现，并根据训练过程中观察到的全梯度范数衰减来调整批处理大小和学习率。

**Result:** 使用基于该策略的自适应联合调度器进行的实验表明，与现有调度器相比，收敛速度有所提高。

**Conclusion:** 所提出的自适应调度策略能有效加速随机梯度下降的收敛。

> **ai_Abstract:** 本文提出了一种基于最小化随机一阶预言机复杂度的自适应批处理大小和学习率调度策略，以解决迷你批次SGD收敛行为对这些参数敏感的问题。该策略根据训练过程中全梯度范数的衰减动态调整批处理大小和学习率。实验结果表明，与现有调度器相比，这种自适应联合调度器能显著提高SGD的收敛速度。

> **摘要翻译:** 迷你批次随机梯度下降（SGD）的收敛行为对批处理大小和学习率设置高度敏感。最近的理论研究已经确定了存在一个临界批处理大小，该大小能最小化随机一阶预言机（SFO）复杂度，SFO复杂度被定义为达到深度神经网络中经验损失函数的平稳点所需的预期梯度评估次数。本文引入了一种自适应调度策略来加速SGD，该策略利用了关于临界批处理大小的理论发现。批处理大小和学习率根据训练过程中观察到的全梯度范数衰减进行调整。使用基于该策略的自适应联合调度器进行的实验表明，与现有调度器相比，收敛速度有所提高。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [360] [Latent Preference Bandits](https://arxiv.org/abs/2508.05367)
> *潜在偏好老虎机*

*Newton Mwai, Emil Carlsson, Fredrik D. Johansson* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 潜在偏好老虎机, 个性化, 偏好排序, 后验采样, 多臂老虎机

**Comment:** 

> **TL;DR:** 针对个性化任务中潜在老虎机模型对奖励分布假设过强的问题，提出了一种仅需偏好排序信息的算法，并在奖励尺度不同时表现更优。

**AI_Comments:** 这项工作通过引入“偏好排序”的概念，巧妙地解决了潜在老虎机模型在处理奖励尺度不一致时的局限性，提升了模型在现实个性化场景中的适用性。其创新点在于对奖励信息需求的放松，使得模型对数据噪声和个体差异具有更好的鲁棒性。这对于医疗健康、推荐系统等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统老虎机算法在个性化任务中探索成本高昂。潜在老虎机虽能减少探索，但要求精确已知的潜在状态与奖励联合分布，这在实践中难以获得，且可能无法解释所有个体（例如，偏好相同但评分尺度不同）。因此，需要一种更宽松的假设来应对奖励尺度差异的问题。

**Method:** 提出放宽潜在老虎机的假设，仅要求每个潜在状态中动作的“偏好排序”模型。这允许相同潜在状态下的问题实例在奖励分布上有所不同，只要它们的偏好排序相同。为此，他们提出了一种后验采样算法。

**Result:** 该算法在奖励分布明确时，性能与完全了解奖励分布的潜在老虎机相当；当相同潜在状态的实例之间奖励尺度不同时，该算法表现优于后者。

**Conclusion:** 通过放松对奖励分布的严格假设，仅依赖偏好排序，所提出的潜在偏好老虎机算法能更有效地处理奖励尺度差异的个性化任务，并在实践中展现出优越性。

> **ai_Abstract:** 这篇论文提出了一种名为“潜在偏好老虎机”的新型多臂老虎机算法，旨在解决个性化任务中传统潜在老虎机对奖励分布假设过于严格的问题。不同于要求精确的潜在状态与奖励联合分布，该方法仅需已知每个潜在状态下行动的偏好排序。通过放宽这一假设，即使奖励的绝对尺度不同，只要偏好顺序一致，算法依然有效。文中提供了一种后验采样算法，并通过实验证明其在奖励尺度差异场景下优于现有潜在老虎机算法，而在奖励分布明确时性能相当。

> **摘要翻译:** 老虎机算法在有足够探索预算的情况下，能够解决各种序列决策问题。然而，对于单个个体面临少量决策点的个性化任务而言，从头开始学习通常成本过高。潜在老虎机在已知潜在状态和行动奖励的联合分布且准确的情况下，能大幅减少此类问题的探索时间。但在实践中，找到这样的模型并非易事，而且可能不存在少量潜在状态能解释所有个体的响应。例如，具有相似潜在病情的患者在治疗上可能有相同的偏好，但他们对症状的评分尺度可能不同。考虑到这一点，我们提出放宽潜在老虎机的假设，仅要求每个潜在状态中行动的“偏好排序”模型。这允许相同潜在状态下的问题实例在奖励分布上有所不同，只要它们的偏好排序相同。我们为此问题提供了一种后验采样算法，并证明其经验性能在奖励分布明确时与完全了解奖励分布的潜在老虎机算法具有竞争力，而在相同潜在状态的实例之间奖励尺度不同时则优于它们。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [368] [NT-ML: Backdoor Defense via Non-target Label Training and Mutual Learning](https://arxiv.org/abs/2508.05404)
> *NT-ML：通过非目标标签训练和相互学习进行后门防御*

*Wenjie Huo, Katinka Wolter* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 后门防御, 深度神经网络, 非目标标签训练, 相互学习, 模型净化

**Comment:** 

> **TL;DR:** NT-ML是一种新的后门防御机制，通过非目标标签训练和相互学习来恢复受污染的模型，有效防御多种后门攻击并优于现有方法。

**AI_Comments:** NT-ML的创新之处在于结合了非目标标签训练和相互学习两种策略，以应对高级后门攻击。其分阶段的方法，先分离出教师和学生模型的优势，再通过相互学习进行融合，是一个新颖且有效的思路。该方法在仅使用少量干净样本的情况下，就能有效防御多种后门攻击并超越现有SOTA方法，显示出其重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）易受后门攻击，攻击者通过在数据集中注入设计好的触发器，导致模型在触发器激活时产生错误预测。因此，需要有效的防御机制来恢复受污染的模型。

**Method:** 本文提出了一种名为非目标标签训练和相互学习（NT-ML）的防御机制。NT阶段通过使用标准训练的输出重新训练模型，以减少中毒数据的影响，从而获得在干净数据上准确的教师模型和在中毒数据上对正确预测更自信的学生模型。然后，通过相互学习（ML）阶段，教师模型和学生模型相互学习彼此的优点，以获得一个纯净的学生模型。

**Result:** 广泛的实验表明，NT-ML能够有效地防御6种后门攻击，只需少量干净样本，并且性能优于5种最先进的后门防御方法。

**Conclusion:** NT-ML通过结合非目标标签训练和相互学习，为深度神经网络提供了一种有效且先进的后门攻击防御方法，显著提升了模型在受污染数据下的鲁棒性。

> **ai_Abstract:** 本文提出了一种名为NT-ML的后门防御机制，旨在解决深度神经网络在后门攻击下的脆弱性。NT-ML包含两个阶段：非目标标签训练（NT）和相互学习（ML）。NT阶段通过重新训练模型以减少中毒数据的影响，生成一个在干净数据上表现良好的教师模型和一个在中毒数据上对正确预测更自信的学生模型。随后，ML阶段使教师和学生模型相互学习，以净化学生模型。实验证明，NT-ML能够有效防御多种后门攻击，且仅需少量干净样本，性能优于现有先进方法。

> **摘要翻译:** 最近的研究表明，深度神经网络（DNNs）容易受到后门攻击，即在数据集中注入设计的触发器，导致在激活时产生错误的预测。在本文中，我们提出了一种新颖的防御机制，非目标标签训练和相互学习（NT-ML），它可以在高级后门攻击下成功恢复受污染的模型。NT旨在通过使用标准训练的输出来重新训练模型，以减少中毒数据造成的危害。在此阶段，可以获得在干净数据上具有高准确性的教师模型和在中毒数据上对正确预测具有更高置信度的学生模型。然后，教师和学生可以通过相互学习（ML）从彼此那里学习优点，以获得一个纯净的学生模型。广泛的实验表明，NT-ML能够有效地防御6种后门攻击，只需少量干净样本，并且性能优于5种最先进的后门防御方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [377] [Cumulative Learning Rate Adaptation: Revisiting Path-Based Schedules for SGD and Adam](https://arxiv.org/abs/2508.05408)
> *累积学习率自适应：重新审视SGD和Adam的基于路径的调度*

*Asma Atamna, Tom Maus, Fabian Kievelitz, Tobias Glasmachers* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 学习率自适应, SGD, Adam, 路径调度, 深度学习

**Comment:** 

> **TL;DR:** 本文重新审视了一种基于路径的累积学习率自适应方案，指出其在Adam优化器上的概念不一致性，并提出了一种修正变体，通过基准测试来评估在线学习率自适应的实际效用。

**AI_Comments:** 这篇论文通过深入分析一种现有的学习率自适应方法，揭示了其在特定优化器（Adam）上的潜在问题，并提出了改进方案，这对于理解和改进深度学习优化器的性能具有重要意义。其关注点在于理论与实践的结合，试图为自适应学习率策略的应用提供更清晰的指导。

<details>
  <summary>Details</summary>

**Motivation:** 学习率是深度学习中一个关键的超参数，其理想值取决于问题并可能在训练期间变化。本文旨在调查自适应学习率机制的实际效用，这些机制能根据损失景观动态调整步长。

**Method:** 1. 重新审视2017年提出的一种累积路径自适应方案，该方案根据观察到的路径长度（归一化梯度步长的时变折扣和）与随机游走预期长度之间的差异来调整学习率。2. 提出了一种修正变体，以更好地反映Adam的更新动态，解决原方案在Adam上概念不一致的问题。3. 对SGD和Adam（有无累积自适应）进行基准测试，并与最近的替代方法进行比较。

**Result:** 发现原有的累积路径自适应方案由于Adam优化器内部的预处理，其在Adam上的自适应机制在概念上是不一致的。提出了一种修正变体。通过基准测试来评估在线学习率自适应的实际价值。

**Conclusion:** 本文旨在阐明何时以及为何此类自适应策略能提供实际益处。

> **ai_Abstract:** 本文重新审视了2017年提出的累积路径学习率自适应方案，并指出其在Adam优化器上存在概念性不一致。作者提出了一种修正变体以适应Adam的更新动态，并通过对SGD和Adam进行基准测试来评估在线学习率自适应的实际效用，旨在明确此类自适应策略的实践价值。

> **摘要翻译:** 学习率是深度学习中一个关键的超参数，其理想值取决于问题，并且在训练过程中可能会发生变化。在本文中，我们调查了自适应学习率机制的实际效用，这些机制能根据损失景观动态调整步长。我们重新审视了2017年提出的一种基于路径的累积自适应方案，该方案根据观察到的路径长度（计算为归一化梯度步长的时间折扣和）与随机游走的预期长度之间的差异来调整学习率。虽然原始方法提供了引人注目的直觉，但我们表明，由于优化器内部的预处理，其对Adam的自适应机制在概念上是不一致的。我们提出了一种修正变体，它能更好地反映Adam的更新动态。为了评估在线学习率自适应的实际价值，我们对SGD和Adam（有无累积自适应）进行了基准测试，并将其与最近的替代方法进行了比较。我们的结果旨在阐明此类自适应策略何时以及为何能提供实际益处。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [MolSnap: Snap-Fast Molecular Generation with Latent Variational Mean Flow](https://arxiv.org/abs/2508.05411)
> *MolSnap：基于潜在变分均值流的快速分子生成*

*Md Atik Ahamed, Qiang Ye, Qiang Cheng* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 分子生成, 变分均值流, 因果感知Transformer, 药物发现, 快速推理

**Comment:** 

> **TL;DR:** MolSnap提出了一种新的因果感知框架，通过结合因果感知Transformer（CAT）和变分均值流（VMF），实现了高质量、高多样性且推理速度极快的分子生成。

**AI_Comments:** MolSnap的创新之处在于其结合了因果感知Transformer和变分均值流，有效地平衡了分子生成中的质量、多样性和推理速度。特别是VMF的单步推理能力，大大提升了计算效率，这对于药物发现等需要大规模生成和筛选的领域具有重要意义。该模型在保持高生成质量的同时，解决了现有方法计算成本高昂的问题，展现了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有分子生成方法在确保高质量、多样性生成的同时，难以实现快速推理。

**Method:** 本研究提出了一种新颖的因果感知框架。首先，引入了因果感知Transformer（CAT），它联合编码分子图令牌和文本指令，并在生成过程中强制执行因果依赖。其次，开发了变分均值流（VMF）框架，通过将潜在空间建模为高斯混合模型，扩展了现有流基方法，增强了表达能力。VMF实现了高效的单步推理，同时保持了强大的生成质量和多样性。

**Result:** 在四个标准分子基准测试中，MolSnap模型表现优于现有最新基线，实现了更高的创新性（高达74.5%）、多样性（高达70.3%）和100%的有效性。此外，VMF在条件生成时仅需要一次函数评估（NFE），在无条件生成时最多需要五次NFE，与基于扩散的方法相比，计算效率显著提高。

**Conclusion:** MolSnap框架通过其创新的因果感知Transformer和变分均值流，成功解决了分子生成中高质量、多样性和快速推理的挑战，并在多个基准测试中展现出卓越的性能和计算效率。

> **ai_Abstract:** MolSnap提出了一种新颖的因果感知框架，旨在解决现有分子生成方法在高质量、多样性和快速推理方面的不足。该框架包含两个核心创新：一是因果感知Transformer（CAT），用于联合编码分子图和文本指令并强制因果依赖；二是变分均值流（VMF），通过高斯混合模型增强潜在空间表达，实现高效的单步推理。实验结果表明，MolSnap在多个分子基准测试中表现优异，显著提高了生成质量、多样性和有效性，并且在计算效率上远超现有扩散模型。

> **摘要翻译:** 分子生成以文本描述为条件是计算化学和药物发现中的一项基本任务。现有方法通常难以同时确保高质量、多样性生成和快速推理。在这项工作中，我们提出了一种新颖的因果感知框架，通过两项关键创新来解决这些挑战。首先，我们引入了因果感知Transformer（CAT），它联合编码分子图令牌和文本指令，并在生成过程中强制执行因果依赖。其次，我们开发了变分均值流（VMF）框架，通过将潜在空间建模为高斯混合模型，扩展了现有流基方法，增强了超越单峰先验的表达能力。VMF实现了高效的单步推理，同时保持了强大的生成质量和多样性。在四个标准分子基准测试中进行的广泛实验表明，我们的模型优于现有最新基线，在所有数据集中均实现了更高的创新性（高达74.5%）、多样性（高达70.3%）和100%的有效性。此外，VMF在条件生成时仅需要一次函数评估（NFE），在无条件生成时最多需要五次NFE，与基于扩散的方法相比，提供了显著的计算效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [392] [Negative Binomial Variational Autoencoders for Overdispersed Latent Modeling](https://arxiv.org/abs/2508.05423)
> *负二项变分自编码器用于过离散潜在建模*

*Yixuan Zhang, Wenxin Zhang, Hua Jiang, Quyu Kong, Feng Zhou* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 变分自编码器, 负二项分布, 过离散, 尖峰计数, 神经建模

**Comment:** 

> **TL;DR:** 提出NegBio-VAE，用负二项分布建模神经元尖峰计数，解决传统VAE和泊松VAE无法处理的过离散问题，提高了重建精度。

**AI_Comments:** 这篇论文的创新点在于将负二项分布引入到VAE框架中，以解决生物数据中常见的过离散性问题，特别是神经元尖峰计数。这超越了现有泊松模型的限制，提供了一个更准确、更灵活的建模工具。其重要性在于提高了对生物信号的建模精度，可能对神经科学研究和生物信号处理产生积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 传统变分自编码器（VAEs）及其泊松-VAE变体无法准确捕捉生物神经元尖峰活动的真实随机性和过离散特性，泊松分布的均值等于方差的限制不符合实际。

**Method:** 引入NegBio-VAE，作为VAE框架的扩展，使用负二项分布对尖峰计数进行建模。开发了两种ELBO优化方案和两种可微分重参数化策略，并引入了一个额外的离散参数，将泊松潜在模型推广到负二项公式。

**Result:** 经验结果表明，引入一个额外的离散参数显著提高了重建保真度。

**Conclusion:** 明确建模尖峰样激活中的过离散性对于提高模型性能至关重要。

> **ai_Abstract:** 该论文介绍了NegBio-VAE，一个扩展了传统变分自编码器（VAE）框架的新模型，旨在解决生物神经元尖峰活动中常见的过离散问题。与现有泊松-VAE的均值-方差相等限制不同，NegBio-VAE采用负二项分布建模尖峰计数，从而能明确控制离散度。通过引入一个额外的离散参数以及定制的优化和重参数化策略，NegBio-VAE显著提高了重建精度，强调了在神经活动建模中考虑过离散性的重要性。

> **摘要翻译:** 生物神经元通过尖峰序列进行交流，这些离散、不规则的活动爆发表现出远超传统变分自编码器（VAEs）建模能力的变异性。最近的工作，例如泊松-VAE，通过使用泊松分布对尖峰计数进行建模，迈出了生物学启发的一步。然而，它们施加了一个严格的约束：均值和方差相等，这未能反映神经活动真实的随机性质。在这项工作中，我们挑战了这一约束，并引入了NegBio-VAE，这是VAE框架的一个原则性扩展，它使用负二项分布对尖峰计数进行建模。这种转变赋予了对离散度的明确控制，解锁了更广泛、更准确的神经表征家族。我们进一步开发了两种ELBO优化方案和两种适用于负二项设置的可微分重参数化策略。通过引入一个额外的离散参数，NegBio-VAE将泊松潜在模型推广到负二项公式。经验结果表明，这一微小但有影响力的改变显著提高了重建保真度，突出了在尖峰样激活中明确建模过离散性的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [400] [Federated Multi-Objective Learning with Controlled Pareto Frontiers](https://arxiv.org/abs/2508.05424)
> *联邦多目标学习与受控帕累托前沿*

*Jiansheng Rao, Jiayi Li, Zhizhi Gong, Soummya Kar, Haoxuan Li* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 联邦学习, 多目标优化, 帕累托最优, 客户端公平性, 偏好锥约束

**Comment:** 

> **TL;DR:** 本文提出了CR-FMOL，一个通过偏好锥约束强制实现客户端帕累托最优的联邦多目标学习框架，以解决现有FMOL中客户端公平性不足的问题。

**AI_Comments:** CR-FMOL的创新之处在于引入了偏好锥约束来显式地强制客户端层面的帕累托最优性，解决了现有FMOL仅关注任务级帕累托平稳点的问题。这对于提升联邦学习在非独立同分布数据下的公平性具有重要意义。其局限性可能在于早期性能略逊于FedAvg，需要更多训练轮次才能达到相同水平。

<details>
  <summary>Details</summary>

**Motivation:** FedAvg优化多数群体而对少数客户端服务不足；现有联邦多目标学习（FMOL）只提供任务级帕累托平稳点，未能保证客户端公平性。

**Method:** 引入锥正则化联邦多目标学习（CR-FMOL），第一个通过新颖的偏好锥约束强制实现客户端帕累托最优的联邦MOO框架。客户端执行本地FMGDA/FSMGDA步骤后，传输聚合的任务损失向量作为隐式偏好；服务器解决以均匀向量为中心的锥约束帕累托-MTL子问题，生成对每个客户端在其锥内帕累托平稳的下降方向。

**Result:** 在非独立同分布基准上的实验表明，CR-FMOL增强了客户端公平性，尽管早期性能略逊于FedAvg，但预计在足够的训练轮次后能达到可比的准确性。

**Conclusion:** CR-FMOL通过强制客户端帕累托最优性，有效解决了联邦多目标学习中客户端公平性不足的问题，并有望在长期训练中达到良好性能。

> **ai_Abstract:** 本文提出锥正则化联邦多目标学习（CR-FMOL），旨在解决现有联邦学习（FL）和联邦多目标学习（FMOL）在客户端公平性方面的不足。CR-FMOL是首个通过引入新颖的偏好锥约束来强制实现客户端帕累托最优的联邦多目标优化框架。该方法涉及客户端本地更新和服务器端解决一个锥约束的帕累托-MTL子问题，以生成对每个客户端都帕累托平稳的下降方向。实验结果显示，CR-FMOL显著提升了客户端公平性，并在长期训练后有望达到与FedAvg相当的性能。

> **摘要翻译:** 联邦学习（FL）是一种广泛采用的隐私保护模型训练范式，但FedAvg优化多数群体，而对少数客户端服务不足。现有的方法，如联邦多目标学习（FMOL），试图将多目标优化（MOO）引入FL。然而，它仅仅提供任务级帕累托平稳点，将客户端公平性留给了偶然。在本文中，我们引入锥正则化联邦多目标学习（CR-FMOL），这是第一个通过新颖的偏好锥约束强制实现客户端帕累托最优的联邦MOO框架。在本地联邦多梯度下降平均（FMGDA）/联邦随机多梯度下降平均（FSMGDA）步骤之后，每个客户端将其聚合的任务损失向量作为隐式偏好传输；服务器随后解决一个以均匀向量为中心的锥约束帕累托-MTL子问题，生成一个在其锥内对每个客户端都帕累托平稳的下降方向。在非独立同分布基准上的实验表明，CR-FMOL增强了客户端公平性，尽管早期性能略逊于FedAvg，但预计在足够的训练轮次后能达到可比的准确性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [408] [Group Causal Policy Optimization for Post-Training Large Language Models](https://arxiv.org/abs/2508.05428)
> *大语言模型后训练中的群组因果策略优化*

*Ziyin Gu, Jingyao Wang, Ran Zuo, Chuxiong Sun, Zeen Song, Changwen Zheng, Wenwen Qiang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 后训练, 因果策略优化, GRPO, 结构因果模型

**Comment:** 

> **TL;DR:** GCPO通过引入因果结构改进了大型语言模型的后训练，解决了GRPO的局限性，并在多个推理基准上表现出卓越的性能。

**AI_Comments:** 该论文通过将因果建模（SCM）引入到大型语言模型后训练的策略优化中，提出了一种创新方法，特别解决了GRPO中被忽视的语义交互问题。这种因果视角提供了对响应依赖性更深入的理解，并带来了更稳健的优化框架。使用因果知情奖励调整和KL正则化项是其关键创新点。其重要性在于提高了LLM微调的有效性，尤其是在复杂的推理任务中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型（LLMs）后训练方法，特别是群组相对策略优化（GRPO），虽然高效，但将候选响应视为独立的，忽略了它们之间的语义交互（如互补性和矛盾性）。

**Method:** 本研究首先引入了一个结构因果模型（SCM）来揭示候选响应之间因条件作用于最终集成输出而产生的隐藏依赖关系。基于因果分析的洞察（将响应投影到因果知情子空间可提高预测质量并提供更好的基线），提出了群组因果策略优化（GCPO）。GCPO通过两个关键组件将因果结构整合到优化中：一个因果知情奖励调整和一个新颖的KL正则化项，该项使策略与因果投影的参考分布对齐。

**Result:** 全面的实验评估表明，GCPO在多个推理基准上始终超越现有方法，包括GRPO。

**Conclusion:** GCPO通过整合因果结构有效解决了现有方法（如GRPO）中候选响应独立性的局限性，从而显著提高了大型语言模型在后训练中的性能。

> **ai_Abstract:** 本文提出了群组因果策略优化（GCPO），用于大型语言模型的后训练，旨在克服群组相对策略优化（GRPO）将候选响应视为独立的问题。GCPO利用结构因果模型（SCM）揭示隐藏依赖关系，并通过因果知情奖励调整和新颖的KL正则化项整合因果洞察。实验结果表明，GCPO在推理基准上优于包括GRPO在内的现有方法。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展拓宽了它们在各种任务中的适用性，但专业领域仍需要有针对性的后训练。在现有方法中，群组相对策略优化（GRPO）因其效率而脱颖而出，它利用群组相对奖励，同时避免了昂贵的价值函数学习。然而，GRPO将候选响应视为独立的，忽略了语义交互，如互补性和矛盾性。为了解决这一挑战，我们首先引入了一个结构因果模型（SCM），该模型揭示了通过条件作用于形成对撞机结构的最终集成输出而引起的候选响应之间的隐藏依赖关系。然后，我们的因果分析得出了两个见解：（1）将响应投影到因果知情子空间可以提高预测质量，（2）这种投影比仅查询条件作用产生更好的基线。基于这些见解，我们提出了群组因果策略优化（GCPO），它通过两个关键组件将因果结构整合到优化中：一个因果知情奖励调整和一个新颖的KL正则化项，该项使策略与因果投影的参考分布对齐。全面的实验评估表明，GCPO在多个推理基准上始终超越现有方法，包括GRPO。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [416] [Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search](https://arxiv.org/abs/2508.05433)
> *通过多模态LLM辅助进化搜索发现可解释的程序化策略*

*Qinglong Hu, Xialiang Tong, Mingxuan Yuan, Fei Liu, Zhichao Lu, Qingfu Zhang* | **Category: cs.LG, cs.NE** | **Updated: 2025-08-07**

**Keywords:** 可解释性, 程序化策略, 多模态LLM, 进化搜索, 控制策略

**Comment:** 

> **TL;DR:** MLES利用多模态LLM和进化搜索来发现可解释的程序化控制策略，性能与PPO相当，且具有透明可追溯的逻辑。

**AI_Comments:** 该论文的创新点在于将多模态大语言模型与进化搜索相结合，用于自动生成和优化可解释的程序化控制策略。这克服了传统深度强化学习“黑箱”模型的局限性，特别是在安全关键任务中，提升了策略的透明度和信任度，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习虽然提高了性能，但其固有的缺乏可解释性阻碍了在安全关键任务中的实际部署。本研究旨在解决高性能与可解释性之间的双重挑战。

**Method:** 本文提出多模态大语言模型辅助进化搜索（MLES）。MLES利用多模态大语言模型作为策略生成器，结合进化机制进行自动策略优化。它还整合了视觉反馈驱动的行为分析，以识别失败模式并促进有针对性的改进。

**Result:** 实验结果表明，MLES在两个控制任务上实现了与近端策略优化（PPO）相当的策略发现能力和效率。它提供了透明的控制逻辑和可追溯的设计过程，克服了预定义领域特定语言的限制，促进了知识转移和重用，并可扩展到各种控制任务。

**Conclusion:** MLES有望成为下一代可解释控制策略发现的领先方法，成功解决了高性能和可解释性并存的挑战。

> **ai_Abstract:** 本文提出了一种名为MLES（多模态大语言模型辅助进化搜索）的新型方法，旨在发现既高性能又可解释的程序化控制策略。MLES结合了多模态大语言模型作为策略生成器和进化机制进行优化，并利用视觉反馈进行行为分析以改进策略。实验证明，MLES在效率和能力上与PPO相当，同时提供了透明、可追溯的控制逻辑，解决了深度强化学习在可解释性上的不足，并展现出良好的通用性和扩展性。

> **摘要翻译:** 可解释性和高性能是设计控制策略的关键目标，尤其对于安全关键任务。深度强化学习极大地提升了性能，但其固有的缺乏可解释性常常损害信任并阻碍实际部署。这项工作通过引入一种新颖的程序化策略发现方法——多模态大语言模型辅助进化搜索（MLES）来解决这些双重挑战。MLES利用多模态大语言模型作为策略生成器，并结合进化机制进行自动策略优化。它在策略生成过程中整合了视觉反馈驱动的行为分析，以识别失败模式并促进有针对性的改进，从而提高了策略发现的效率并生成适应性强、与人类对齐的策略。实验结果表明，MLES在两个控制任务上实现了与近端策略优化（PPO）相当的策略发现能力和效率，同时提供了透明的控制逻辑和可追溯的设计过程。这种范式克服了预定义领域特定语言的限制，促进了知识转移和重用，并可扩展到各种控制任务。MLES有望成为下一代可解释控制策略发现的领先方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [Prediction of Survival Outcomes under Clinical Presence Shift: A Joint Neural Network Architecture](https://arxiv.org/abs/2508.05472)
> *临床存在偏移下生存结果预测：一种联合神经网络架构*

*Vincent Jeanselme, Glen Martin, Matthew Sperrin, Niels Peek, Brian Tom, Jessica Barrett* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 临床存在偏移, 生存预测, 神经网络, 可迁移性, 电子健康记录

**Comment:** 

> **TL;DR:** 本文提出了一种多任务循环神经网络，用于在临床存在偏移下预测生存结果，通过联合建模观察时间和缺失过程来提高模型性能和可迁移性，并在真实世界死亡率预测任务中验证了其有效性。

**AI_Comments:** 该论文的创新点在于首次形式化了“临床存在偏移”的概念，并提出了一种联合神经网络架构来解决由此带来的临床预测模型可迁移性问题。通过同时考虑观察时间、缺失过程和生存结果，该方法提高了模型在真实世界复杂医疗环境中的鲁棒性和泛化能力，对于开发更可靠和可迁移的临床预测模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在使用电子健康记录开发临床预测模型时，通常会忽视“临床存在”（患者与医疗系统之间的复杂交互过程），这会影响模型性能并限制其在交互演变时的可迁移性。

**Method:** 提出了一种多任务循环神经网络，该网络与感兴趣的生存结果并行，共同建模了表征临床交互的观察间时间和缺失过程。工作还形式化了当预测模型部署在新环境（例如不同医院、区域或国家）时临床存在偏移的概念，并从理论上证明了所提出的联合建模为何能在临床存在变化下提高可迁移性。

**Result:** 在MIMIC-III数据集的真实世界死亡率预测任务中，本文证明了所提出的策略与不包含观察过程的最新预测模型相比，能提高性能和可迁移性。

**Conclusion:** 研究结果强调了利用临床存在对于提高性能和创建更具可迁移性的临床预测模型的重要性。

> **ai_Abstract:** 本文提出了一种联合神经网络架构，旨在解决临床预测模型在“临床存在”偏移下性能下降和可迁移性受限的问题。该模型通过一个多任务循环神经网络，同时建模患者与医疗系统交互的观察时间、缺失过程以及生存结果。研究不仅形式化了临床存在偏移的概念，还从理论上证明了联合建模能提高模型在不同部署环境下的可迁移性。在MIMIC-III数据集上的死亡率预测任务中，实验结果表明该方法显著优于不考虑观察过程的现有模型，强调了利用临床存在对提升临床预测模型性能和可迁移性的重要性。

> **摘要翻译:** 电子健康记录源于患者与医疗系统之间复杂的交互。这种交互的观察过程，被称为临床存在，通常会影响观察到的结果。在使用电子健康记录开发临床预测模型时，忽视临床存在是标准做法，这会影响性能并限制当这种交互演变时模型的可迁移性。我们提出了一种多任务循环神经网络，该网络与感兴趣的生存结果并行，共同建模了表征这种交互的观察间时间和缺失过程。我们的工作形式化了当预测模型部署在新环境（例如不同医院、区域或国家）时临床存在偏移的概念，并且我们从理论上证明了所提出的联合建模为何能在临床存在变化下提高可迁移性。我们在MIMIC-III数据集的真实世界死亡率预测任务中证明了所提出的策略与不包含观察过程的最新预测模型相比，如何提高性能和可迁移性。这些结果强调了利用临床存在对于提高性能和创建更具可迁移性临床预测模型的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [431] [Competing Risks: Impact on Risk Estimation and Algorithmic Fairness](https://arxiv.org/abs/2508.05435)
> *竞争风险：对风险估计和算法公平性的影响*

*Vincent Jeanselme, Brian Tom, Jessica Barrett* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 竞争风险, 生存分析, 算法公平性, 风险估计, 偏差

**Comment:** 

> **TL;DR:** 将竞争风险视为删失数据会导致生存估计出现严重偏差，系统性地高估风险并加剧算法公平性方面的不平等；本研究通过理论和实证分析量化了这种错误，并强调了其对风险评估和公平性的关键影响。

**AI_Comments:** 这项研究具有重要的实践意义，因为它揭示了生存分析中一个常见但被忽视的问题——竞争风险的处理。其创新之处在于不仅理论上证明了将竞争风险视为删失的偏差和对公平性的影响，还提供了量化这种误差的框架，并通过实证分析进一步验证。这对于医疗、金融等领域中依赖时间-事件预测的决策制定者和模型开发者来说，是至关重要的见解，有助于构建更准确、更公平的预测模型。

<details>
  <summary>Details</summary>

**Motivation:** 准确的事件发生时间预测对于决策至关重要，但生存分析中常见的一种做法是将“竞争风险”视为“删失数据”。这种做法的后果常被忽视，因为它会导致生存估计中出现严重偏差，系统性地高估风险并加剧现有差异。

**Method:** 本研究首先从理论上证明了将竞争风险误分类为删失数据会导致的偏差。接着，研究形式化了这个问题，并开发了一个框架来量化由此产生的生存估计误差，并展示了其对预测性能和算法公平性的影响。此外，研究还检查了不同人口群体间风险概况差异如何导致特定群体的错误，从而可能加剧不平等。研究结果通过对心血管疾病管理的实证分析得到了支持。

**Result:** 研究发现，将竞争风险视为删失数据会引入实质性偏差，导致系统性地高估风险并加剧不平等。忽略竞争风险会不成比例地影响那些最容易发生这些事件的个体，可能加剧不公平性。通过量化误差并突出这种常见做法对公平性的影响，研究揭示了生存模型开发的关键见解。

**Conclusion:** 实践者在开发生存模型时必须考虑竞争风险，以提高准确性，减少风险评估中的差异，并更好地指导后续决策。

> **ai_Abstract:** 本研究探讨了生存分析中将“竞争风险”错误地视为“删失数据”的普遍做法。作者从理论上证明了这种错误分类会导致生存估计的严重偏差，系统性地高估风险并加剧算法公平性问题。研究开发了一个框架来量化这种误差，并指出其对预测性能和不同人口群体间公平性的负面影响。通过对心血管管理的实证分析，研究证实忽略竞争风险会不成比例地影响高风险个体，加剧不平等。最终，该工作强调了在生存模型中考虑竞争风险对于提高准确性、减少差异和优化决策的重要性。

> **摘要翻译:** 准确的事件发生时间预测对于决策至关重要，它为医疗指南、招聘决策和资源分配提供信息。生存分析是用于建模事件发生时间数据的定量框架，它考虑了在研究期间未经历感兴趣事件的患者，即所谓的删失患者。然而，许多患者会经历阻止观察感兴趣结果的事件。这些竞争风险通常被视为删失，这种做法因对其后果的有限理解而经常被忽视。我们的工作从理论上证明了为什么将竞争风险视为删失会在生存估计中引入实质性偏差，导致系统性地高估风险，并且关键的是，会加剧不平等。首先，我们形式化了将竞争风险错误分类为删失的问题，并量化了由此产生的生存估计误差。具体来说，我们开发了一个框架来估计这种误差，并演示了其对预测性能和算法公平性的相关影响。此外，我们还检查了不同人口群体之间的风险概况差异如何导致特定群体的错误，从而可能加剧现有差异。我们的发现得到了心血管管理实证分析的支持，表明忽略竞争风险会不成比例地影响那些最容易发生这些事件的个体，从而可能加剧不公平性。通过量化误差并强调将竞争风险视为删失的常见做法对公平性的影响，我们的工作为生存模型的开发提供了关键见解：实践者必须考虑竞争风险以提高准确性，减少风险评估中的差异，并更好地指导后续决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [439] [Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge Graph Embedding Models](https://arxiv.org/abs/2508.05587)
> *使用多种负采样解决方案增强 PyKEEN 用于知识图谱嵌入模型*

*Claudia d'Amato, Ivan Diliso, Nicola Fanizzi, Zafar Saeed* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 知识图谱嵌入, 负采样, PyKEEN, 链接预测, 性能增强

**Comment:** 

> **TL;DR:** 本文通过集成多种先进的负采样策略来扩展流行的知识图谱嵌入框架 PyKEEN，以提高知识图谱嵌入模型的性能和开发便利性，并进行了实证研究。

**AI_Comments:** 本文通过增强 PyKEEN 框架的负采样能力，填补了现有知识图谱嵌入库在高级负采样策略方面的空白。其模块化和兼容性设计使得该扩展具有很强的实用性，并能促进知识图谱嵌入领域的研究和应用。通过实证研究验证了其有效性，并为设计更有效的负采样策略提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有的知识图谱嵌入库大多只支持基本的负采样策略，缺乏高级解决方案，这限制了生成有意义的负样本和提升模型性能的能力。

**Method:** 开发了一个 PyKEEN 扩展，集成了多种先进的负采样器（包括静态和动态破坏策略），采用一致的模块化架构，并兼容现有 PyKEEN 工作流。

**Result:** 所开发的扩展不仅增强了 PyKEEN 本身，还使得嵌入方法的开发和定制更加容易和全面。概念验证的实证研究展示了这些扩展及其对不同嵌入方法在链接预测任务上性能的影响，并为设计更有效的策略提供了有用的见解。

**Conclusion:** 通过在 PyKEEN 中引入多种先进的负采样策略，可以有效提高知识图谱嵌入模型的性能，并促进更灵活的开发和定制。

> **ai_Abstract:** 该论文通过引入多种先进的负采样策略（包括静态和动态破坏）来扩展流行的知识图谱嵌入框架 PyKEEN，以解决现有库在负采样方面的不足。该扩展旨在生成更有意义的负样本，提高知识图谱嵌入模型的性能，并简化新嵌入方法的开发和定制。通过实证研究，证明了这些扩展对链接预测任务性能的积极影响，并为未来策略设计提供了见解。

> **摘要翻译:** 嵌入方法因其在知识图谱上的链接预测和/或三元组分类任务中的可扩展性而变得流行。嵌入模型依赖于正样本和负样本的三元组进行训练。然而，在没有负断言的情况下，通常必须使用各种负采样策略人工生成这些负样本，从随机破坏到更复杂的技术，这些技术都会影响整体性能。大多数流行的知识图谱嵌入库只支持基本的此类策略，缺乏高级解决方案。为了解决这一差距，我们为流行的 KGE 框架 PyKEEN 提供了一个扩展，该扩展在一个一致的模块化架构中集成了多种先进的负采样器（包括静态和动态破坏策略），以生成有意义的负样本，同时保持与现有基于 PyKEEN 的工作流和管道的兼容性。所开发的扩展不仅增强了 PyKEEN 本身，还允许更轻松、更全面的嵌入方法开发和/或定制。作为概念验证，我们对所开发的扩展及其对不同嵌入方法性能（链接预测任务）的影响进行了全面的实证研究，这也为设计更有效的策略提供了有用的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [448] [On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification](https://arxiv.org/abs/2508.05629)
> *关于SFT泛化性的研究：一个带有奖励修正的强化学习视角*

*Yongliang Wu, Yizhou Zhou, Zhou Ziheng, Yingzhe Peng, Xinyu Ye, Xinting Hu, Wenbo Zhu, Lu Qi, Ming-Hsuan Yang, Xu Yang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 监督微调, 泛化能力, 强化学习, 动态微调, 大语言模型

**Comment:** 

> **TL;DR:** 本文提出动态微调（DFT）来改进SFT的泛化能力，通过动态调整目标函数解决SFT隐含的奖励结构问题，DFT在多个基准测试中显著优于SFT，并提供了一种更简单有效的离线强化学习替代方案。

**AI_Comments:** 本文通过对SFT内在奖励结构的理论分析，提出了一个简洁而有效的改进方法DFT，其“一行代码”的改动却带来了显著的性能提升，体现了理论与实践的良好结合。该方法在提高SFT泛化能力的同时，也为离线RL提供了一个有潜力的替代方案，具有重要的创新性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的监督微调（SFT）在泛化能力方面相较于强化学习（RL）存在局限性。数学分析表明，标准SFT梯度隐含着一个有问题的奖励结构，这严重限制了模型的泛化能力。

**Method:** 提出动态微调（DFT），通过动态地用令牌的概率重新缩放目标函数来稳定每个令牌的梯度更新。这只需一行代码的改动。

**Result:** DFT在多个具有挑战性的基准测试和基础模型上显著优于标准SFT，显示出大大提高的泛化能力。此外，该方法在离线RL设置中也表现出有竞争力的结果。

**Conclusion:** 本文的工作弥合了理论洞察和实际解决方案之间的差距，显著提升了SFT的性能，并提供了一种有效且更简单的替代方案。

> **ai_Abstract:** 本文针对大型语言模型（LLM）监督微调（SFT）泛化能力不足的问题，从强化学习角度出发，揭示了标准SFT梯度中存在的问题奖励结构。为此，提出了一种名为动态微调（DFT）的新方法，通过动态调整目标函数来稳定梯度更新。实验结果表明，DFT在多个基准测试中显著优于传统SFT，展现出更强的泛化能力，并在离线RL设置中也表现出色，提供了一种更简单有效的替代方案。

> **摘要翻译:** 我们提出了一种对大型语言模型（LLM）监督微调（SFT）的简单而有理论依据的改进，以解决其相较于强化学习（RL）有限的泛化能力。通过数学分析，我们揭示了标准SFT梯度隐式编码了一个有问题的奖励结构，这可能严重限制模型的泛化能力。为了纠正这一点，我们提出了动态微调（DFT），通过动态地用令牌的概率重新缩放目标函数来稳定每个令牌的梯度更新。值得注意的是，这一行代码的更改在多个具有挑战性的基准测试和基础模型上显著优于标准SFT，显示出大大提高的泛化能力。此外，我们的方法在离线RL设置中也表现出有竞争力的结果，提供了一种有效而更简单的替代方案。这项工作弥合了理论洞察和实际解决方案之间的差距，显著提升了SFT的性能。代码将发布在https://github.com/yongliang-wu/DFT。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [Telegrapher's Generative Model via Kac Flows](https://arxiv.org/abs/2506.20641)
> *基于Kac流的电报员生成模型*

*Richard Duong, Jannis Chemseddine, Peter K. Friz, Gabriele Steidl* | **Category: cs.LG, math.AP, math.PR** | **Updated: 2025-08-05**

**Keywords:** 生成模型, Kac流, 电报员方程, 流匹配, 扩散模型

**Comment:** 

> **TL;DR:** 提出一种基于电报员方程和Kac流的新型生成模型，相比扩散模型具有优势。

**AI_Comments:** 该论文的创新之处在于引入了电报员方程和Kac流来构建生成模型，这在理论上提供了优于传统扩散模型的特性，例如速度范数全局有界和Wasserstein距离上的Lipschitz连续性。实验结果也验证了其在可扩展性和性能上的优势，为流生成模型领域开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 旨在突破现有基于流的生成模型范式，提出一种基于电报员方程和Kac流的新模型，以克服扩散模型的局限性，例如速度范数全局有界。

**Method:** 该模型基于阻尼波动方程（电报员方程）和随机Kac过程。它将一维Kac过程扩展到多维空间，确保Wasserstein空间中的绝对连续曲线。通过流匹配框架，训练神经网络来近似速度场，并用于样本生成。

**Result:** 数值实验证明了该方法的可扩展性，并展示了其相对于扩散模型的优势。

**Conclusion:** 该研究成功提出了一种基于Kac流的新型生成模型，该模型具有良好的可扩展性，并在性能上优于扩散模型。

> **ai_Abstract:** 该论文提出了一种基于阻尼波动方程（电报员方程）和随机Kac过程的新型流生成模型。与扩散流不同，Kac流在Wasserstein距离上具有Lipschitz连续性，且速度范数全局有界，并将扩散模型作为其渐近极限。研究将此扩展到多维Kac过程，并分析了其在Wasserstein空间中的性质。通过流匹配框架训练神经网络近似速度场进行样本生成。数值实验表明该方法具有可扩展性，并优于扩散模型。

> **摘要翻译:** 我们通过提出一种基于阻尼波动方程（也称为电报员方程）的新模型，打破了基于流的生成建模的传统模式。与扩散方程和布朗运动类似，电报员方程与一维随机Kac过程之间存在费曼-Kac型关系。Kac流在时间上分步线性演化，因此概率流在Wasserstein距离上是Lipschitz连续的，并且与扩散流相反，其速度范数全局有界。此外，Kac模型以扩散模型作为其渐近极限。我们将这些考虑扩展到由每个空间分量中独立的1D Kac过程组成的多维随机过程。我们证明了该过程在Wasserstein空间中产生一条绝对连续曲线，并解析计算了从Dirac点开始的条件速度场。利用流匹配的框架，我们训练了一个神经网络来近似速度场并将其用于样本生成。我们的数值实验证明了我们方法的可扩展性，并显示了其相对于扩散模型的优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [463] [From Rattle to Roar: Optimizer Showdown for MambaStock on S&P 500](https://arxiv.org/abs/2508.04707)
> *从“嘎嘎作响”到“咆哮”：MambaStock在标普500指数上的优化器对决*

*Alena Chan, Maria Garmonina* | **Category: cs.LG, q-fin.CP** | **Updated: 2025-07-09**

**Keywords:** 优化器, MambaStock, 标普500, 预测, Roaree

**Comment:** 

> **TL;DR:** 本文评估了MambaStock模型在预测标普500指数回报任务中不同优化器的性能。结果显示，梯度平滑和自适应学习率优化器（如Adam和RMSProp）误差最低，而Lion优化器训练速度最快。为结合二者优点，作者引入了新型优化器家族Roaree，它在保持Lion训练速度的同时，能抑制其常见的损失震荡。

**AI_Comments:** 该论文的创新点在于引入了Roaree优化器家族，它有效地结合了现有优化器的优势（Lion的训练速度）并解决了其缺点（损失震荡）。这对于使用MambaStock模型进行金融预测等实际应用具有重要意义，因为它提供了更稳定且高效的训练方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在评估不同优化器在MambaStock模型预测标普500指数回报任务中的表现，并寻找或开发更优的优化策略。

**Method:** 作者通过MambaStock模型在预测标普500指数回报的任务中，评估了多种现有优化器（包括梯度平滑和自适应学习率优化器如Adam、RMSProp，以及Lion优化器）的性能。此外，他们还提出并引入了一个名为Roaree的新型优化器家族。

**Result:** 梯度平滑和自适应学习率优化器（如Adam和RMSProp）在测试中产生了最低的错误率。Lion优化器提供了显著更快的训练速度。新引入的Roaree优化器家族能够在保持Lion训练速度的同时，抑制其常见的损失震荡行为。

**Conclusion:** 研究表明，虽然梯度平滑和自适应学习率优化器在降低测试误差方面表现最佳，而Lion优化器在训练速度上具有优势。本文提出的Roaree优化器家族成功结合了Lion的快速训练优势并解决了其损失震荡问题，提供了一种更优的优化方案。

> **ai_Abstract:** 本文研究了MambaStock模型在预测标普500指数回报时不同优化器的表现。结果显示，Adam和RMSProp等优化器能实现最低的测试误差，而Lion优化器则提供了更快的训练速度。为兼顾速度与稳定性，作者提出了一种名为Roaree的新型优化器家族，该优化器能够抑制Lion优化器常见的损失震荡，同时保持其快速训练的优势。

> **摘要翻译:** 我们评估了MambaStock模型在预测标普500指数回报任务中几种优化器的性能。在最广泛使用的算法中，梯度平滑和自适应学习率优化器（例如Adam和RMSProp）产生了最低的测试误差。相比之下，Lion优化器提供了显著更快的训练。为了结合这些优点，我们引入了一个新颖的优化器家族——Roaree，它在保持Lion训练速度的同时，能抑制Lion优化器常见的损失震荡行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Understanding protein function with a multimodal retrieval-augmented foundation model](https://arxiv.org/abs/2508.04724)
> *使用多模态检索增强基础模型理解蛋白质功能*

*Timothy Fei Truong Jr, Tristan Bepler* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-08-05**

**Keywords:** 蛋白质基础模型, 多模态, 检索增强, 蛋白质功能预测, 变异效应预测

**Comment:** 

> **TL;DR:** PoET-2是一个多模态、检索增强的蛋白质基础模型，通过结合上下文学习和可选结构条件，在蛋白质功能预测和变异效应预测上实现了最先进的性能。

**AI_Comments:** 这篇论文提出了一种新颖的蛋白质基础模型PoET-2，其创新点在于结合了多模态信息（序列和可选结构）、检索增强以及以家族为中心的上下文学习。这种方法有效地解决了现有蛋白质语言模型在处理复杂突变和蛋白质功能预测方面的不足。PoET-2在零样本和少量数据场景下的优异表现，特别是对多重和插入/缺失突变的处理能力，展示了其强大的泛化性和实用价值，对蛋白质工程和生物医学研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的蛋白质语言模型（PLMs）在扩大规模后，虽然改善了结构预测，但未能有效提升对突变理解和蛋白质功能预测的表示质量。

**Method:** 本文提出了PoET-2，一个多模态、检索增强的蛋白质基础模型。它结合了家族特异性进化约束的上下文学习和可选的结构条件，以学习蛋白质序列的生成分布。PoET-2采用了一个对序列上下文顺序等变的层级Transformer编码器，以及一个具有因果和掩码语言建模目标的双解码器架构，使其能够在完全生成模式和双向表示学习模式下运行。

**Result:** PoET-2在零样本变异效应预测上取得了最先进的性能，尤其擅长对多重突变和具有挑战性的插入/缺失突变进行评分。在有监督设置中，PoET-2的嵌入在学习序列-功能关系方面优于现有方法，尤其是在小数据集上。

**Conclusion:** 这项工作强调了将检索增强与多模态、以家族为中心的建模相结合，对于推进蛋白质基础模型的益处。

> **ai_Abstract:** 本文介绍了PoET-2，一个创新的多模态、检索增强的蛋白质基础模型，旨在克服现有蛋白质语言模型在蛋白质功能预测方面的局限性。PoET-2通过结合家族特异性进化约束的上下文学习和结构条件，并采用独特的层级Transformer编码器和双解码器架构，实现了在零样本变异效应预测和有监督的序列-功能关系学习（尤其是在小数据集上）方面的最先进性能。该研究突出了检索增强和多模态、家族中心建模对蛋白质基础模型发展的重要性。

> **摘要翻译:** 蛋白质语言模型（PLMs）学习天然蛋白质序列的概率分布。通过从数亿个天然蛋白质序列中学习，蛋白质的理解和设计能力得以涌现。最近的研究表明，扩大这些模型的规模可以改善结构预测，但似乎未能改善突变理解和蛋白质功能预测的表示质量。我们引入了PoET-2，一个多模态、检索增强的蛋白质基础模型，它结合了家族特异性进化约束的上下文学习和可选的结构条件，以学习蛋白质序列的生成分布。PoET-2使用一个对序列上下文顺序等变的层级Transformer编码器和一个具有因果和掩码语言建模目标的双解码器架构，允许PoET-2在完全生成和双向表示学习模式下操作。PoET-2在零样本变异效应预测上取得了最先进的性能，擅长对多重突变和具有挑战性的插入/缺失突变进行评分。在有监督设置中，PoET-2的嵌入在学习序列-功能关系方面优于现有方法，尤其是在小数据集上。这项工作强调了将检索增强与多模态、以家族为中心的建模相结合，对于推进蛋白质基础模型的益处。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [481] [CodonMoE: DNA Language Models for mRNA Analyses](https://arxiv.org/abs/2508.04739)
> *CodonMoE：用于mRNA分析的DNA语言模型*

*Shiyi Du, Litian Liang, Jiayi Li, Carl Kingsford* | **Category: cs.LG, q-bio.GN** | **Updated: 2025-08-06**

**Keywords:** CodonMoE, DNA语言模型, mRNA分析, 基因组语言模型, RNA预测

**Comment:** 

> **TL;DR:** CodonMoE是一个轻量级适配器，能将DNA语言模型转换为有效的RNA分析器，无需RNA特定预训练，显著提升性能并大幅减少参数，从而统一基因组语言建模。

**AI_Comments:** CodonMoE的创新之处在于其作为轻量级适配器，能够将现有的DNA语言模型有效应用于RNA分析，而无需耗时耗力的RNA特异性预训练，显著提高了效率和资源利用率。它通过减少参数量同时提升性能，为统一基因组语言建模开辟了新的方向，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 基因组语言模型（gLMs）面临效率挑战：为每种生物模态（DNA和RNA）维护独立的专业模型，或开发大型多模态架构。这两种方法都带来了巨大的计算负担，前者需要冗余的基础设施，后者需要大量的参数和广泛的跨模态预训练。

**Method:** 我们引入了CodonMoE（自适应密码子重构专家混合），这是一个轻量级适配器，可以将DNA语言模型转换为有效的RNA分析器，而无需RNA特异性预训练。理论分析表明CodonMoE是密码子层面的通用逼近器。

**Result:** 在跨越稳定性、表达和调控的四项RNA预测任务中，用CodonMoE增强的DNA模型显著优于未修改的对应模型。HyenaDNA+CodonMoE系列实现了最先进的结果，使用的参数比专业RNA模型少80%。

**Conclusion:** 通过保持亚二次复杂度同时实现卓越性能，我们的方法为统一基因组语言建模提供了一条原则性路径，利用更丰富的DNA数据并减少计算开销，同时保留了模态特定的性能优势。

> **ai_Abstract:** 该论文提出了CodonMoE，一个轻量级适配器，旨在解决基因组语言模型在DNA和RNA模态分析中面临的效率挑战。CodonMoE能将现有的DNA语言模型转化为高效的RNA分析工具，无需额外的RNA特异性预训练。理论上，CodonMoE被证明是密码子层面的通用逼近器。实验结果显示，在多项RNA预测任务中，结合CodonMoE的DNA模型性能显著优于基线模型，并且使用更少的参数达到了SOTA水平。这为统一基因组语言建模、降低计算成本并利用更丰富的DNA数据提供了新途径。

> **摘要翻译:** 基因组语言模型（gLMs）面临一个根本性的效率挑战：要么为每种生物模态（DNA和RNA）维护独立的专业模型，要么开发大型多模态架构。这两种方法都带来了巨大的计算负担——模态特异性模型尽管存在固有的生物学联系，却需要冗余的基础设施，而多模态架构则需要大量的参数和广泛的跨模态预训练。为了解决这一限制，我们引入了CodonMoE（自适应密码子重构专家混合），这是一种轻量级适配器，可以将DNA语言模型转换为有效的RNA分析器，而无需RNA特异性预训练。我们的理论分析将CodonMoE确立为密码子层面的通用逼近器，能够在给定足够专家容量的情况下，将密码子序列的任意函数映射到RNA特性。在跨越稳定性、表达和调控的四项RNA预测任务中，用CodonMoE增强的DNA模型显著优于未修改的对应模型，其中HyenaDNA+CodonMoE系列实现了最先进的结果，使用的参数比专业RNA模型少80%。通过保持亚二次复杂度同时实现卓越性能，我们的方法为统一基因组语言建模提供了一条原则性路径，利用更丰富的DNA数据并减少计算开销，同时保留了模态特定的性能优势。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [488] [Discovery of Disease Relationships via Transcriptomic Signature Analysis Powered by Agentic AI](https://arxiv.org/abs/2508.04742)
> *通过智能体AI驱动的转录组特征分析发现疾病关联*

*Ke Chen, Haohan Wang* | **Category: cs.LG, q-bio.GN** | **Updated: 2025-08-06**

**Keywords:** 转录组学, 疾病关联, 智能体AI, 通路相似性, 药物再利用

**Comment:** 

> **TL;DR:** 本研究利用智能体AI分析转录组数据，揭示了疾病间的分子关联及潜在的药物再利用机会。

**AI_Comments:** 该研究的创新之处在于利用智能体AI（GenoMAS）进行大规模转录组分析，并提出了一种新颖的基于通路相似性的框架，从而超越了传统的基于症状的疾病分类，深入到分子机制层面。其重要性在于揭示了隐藏的疾病关联，为药物再利用提供了新机会，并为疾病提供了功能性假设，展示了AI在复杂疾病研究中的可扩展性和解释能力。

<details>
  <summary>Details</summary>

**Motivation:** 现代疾病分类常忽略临床表现差异背后隐藏的分子共性。

**Method:** 本研究引入了一个转录组学驱动的框架，利用全自动智能体AI系统GenoMAS分析了1300多对疾病-条件。开发了一种新颖的基于通路相似性的框架，该框架整合了多数据库富集分析以量化疾病间的功能趋同。

**Result:** 构建的疾病相似性网络揭示了已知的共病和以前未记录的跨类别关联。通过检查共享生物学通路，探索了潜在的分子机制。研究表明肥胖和高血压等背景条件会调节转录组相似性，并根据分子邻近性确定了自闭症谱系障碍等罕见病的治疗再利用机会。

**Conclusion:** 生物学基础的智能体AI能够扩展转录组分析的规模，同时实现复杂疾病图谱的机制解释。该框架提供了超越基于症状分类的功能假设。

> **ai_Abstract:** 本论文提出了一种转录组学驱动的框架，利用智能体AI（GenoMAS）揭示了超过1300对疾病-条件间的分子共性和关系。该框架引入了一种新颖的基于通路相似性的方法，整合了多数据库富集分析以量化功能趋同。研究识别了已知的共病和新的疾病关联，探索了潜在的分子机制，并展示了背景条件如何影响转录组相似性。此外，它还为罕见病确定了治疗再利用机会，突出了智能体AI在扩展转录组分析和促进复杂疾病图谱机制解释方面的潜力。

> **摘要翻译:** 现代疾病分类常忽略临床表现差异背后隐藏的分子共性。本研究引入了一个转录组学驱动的框架，通过使用GenoMAS（一个全自动智能体AI系统）分析超过1300对疾病-条件，来发现疾病关系。除了识别强大的基因层面重叠，我们还开发了一种新颖的基于通路相似性的框架，该框架整合了多数据库富集分析，以量化疾病间的功能趋同。由此产生的疾病相似性网络揭示了已知的共病以及以前未记录的跨类别关联。通过检查共享的生物学通路，我们探索了这些连接背后的潜在分子机制——提供了超越基于症状分类的功能假设。我们进一步展示了肥胖和高血压等背景条件如何调节转录组相似性，并根据自闭症谱系障碍等罕见病与特征更明确的疾病的分子邻近性，确定了其治疗再利用机会。此外，这项工作展示了生物学基础的智能体AI如何在实现复杂疾病图谱的机制解释的同时，扩展转录组分析的规模。所有结果均可在github.com/KeeeeChen/Pathway_Similarity_Network公开访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [496] [Alz-QNet: A Quantum Regression Network for Studying Alzheimer's Gene Interactions](https://arxiv.org/abs/2508.04743)
> *Alz-QNet：一种用于研究阿尔茨海默病基因相互作用的量子回归网络*

*Debanjan Konar, Neerav Sreekumar, Richard Jiang, Vaneet Aggarwal* | **Category: cs.LG, q-bio.GN, q-bio.MN, quant-ph** | **Updated: 2025-08-06**

**Keywords:** 阿尔茨海默病, 量子回归网络, 基因相互作用, Alz-QNet, 基因调控

**Comment:** 

> **TL;DR:** 本文提出了一种名为 Alz-QNet 的量子回归网络，用于揭示阿尔茨海默病中关键基因的相互作用，以期发现潜在的治疗靶点。

**AI_Comments:** 这项研究通过引入量子回归网络（Alz-QNet）来分析基因相互作用，展现了计算生物学领域的一种创新方法，特别是将量子计算的概念应用于基因调控网络。其重要性在于，通过揭示阿尔茨海默病中复杂的基因-基因相互作用，为理解疾病的分子机制提供了新的视角，并有望为开发基于基因的诊断和治疗方法提供潜在靶点。这种跨学科的尝试具有前瞻性。

<details>
  <summary>Details</summary>

**Motivation:** 理解阿尔茨海默病（AD）的分子机制，特别是与疾病相关的关键基因的相互作用，仍然是一个挑战。由于AD是一种多因素疾病，理解其基因-基因相互作用对于治疗和诊断至关重要。

**Method:** 本文提出了一种新颖的量子回归网络（Alz-QNet），该网络借鉴了最先进的量子基因调控网络（QGRN）的见解。利用 Alz-QNet 框架，研究了AD患者内侧嗅皮层（EC）微环境中关键基因（如 APP, FGF14, YY1, EGR1, GAS7, AKT3, SREBF2, PLD3）之间的相互作用，并使用了数据库 GSE138852 中的遗传样本。

**Result:** 研究揭示了复杂的基因-基因相互作用，阐明了AD发病机制中潜在的调控机制。

**Conclusion:** 这些发现有助于寻找潜在的基因抑制剂或调节剂，从而实现AD的治疗诊断。

> **ai_Abstract:** 本文介绍了一种名为 Alz-QNet 的新型量子回归网络，用于深入研究阿尔茨海默病中关键基因的复杂相互作用。该方法结合了量子基因调控网络的先进理念，通过分析AD患者内侧嗅皮层的基因样本（GSE138852），揭示了如 APP、FGF14、YY1 等基因在疾病进展中的相互影响及其潜在调控机制，旨在为AD的基因表达疗法和治疗诊断提供新的靶点。

> **摘要翻译:** 理解阿尔茨海默病（AD）分子层面的机制，通过研究与疾病相关的关键基因仍然是一个挑战。阿尔茨海默病作为一种多因素疾病，需要理解其潜在的基因-基因相互作用，以促进治疗诊断和进展。本文首次尝试使用量子回归来解码AD中一些关键基因，如淀粉样前体蛋白（APP）、固醇调节元件结合转录因子14（FGF14）、阴阳1（YY1）和磷脂酶D家族成员3（PLD3）等，在疾病进展过程中如何受到其他重要转换基因的影响，这可能有助于基于基因表达的AD治疗。我们提出的量子回归网络（Alz-QNet）引入了一种开创性的方法，借鉴了最先进的量子基因调控网络（QGRN）的见解，以揭示AD病理学中涉及的基因相互作用，特别是在早期病理变化发生的内侧嗅皮层（EC）。利用所提出的Alz-QNet框架，我们探索了AD患者CE微环境中关键基因（APP、FGF14、YY1、EGR1、GAS7、AKT3、SREBF2和PLD3）之间的相互作用，研究了来自数据库GSE138852的基因样本，所有这些基因都被认为在AD的进展中起着关键作用。我们的研究揭示了复杂的基因-基因相互作用，阐明了AD发病机制中潜在的调控机制，这有助于我们寻找潜在的基因抑制剂或调节剂以进行治疗诊断。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [502] [GRIT: Graph-Regularized Logit Refinement for Zero-shot Cell Type Annotation](https://arxiv.org/abs/2508.04747)
> *GRIT：用于零样本细胞类型注释的图正则化 Logit 细化*

*Tianxiang Hu, Chenyi Zhou, Jiaxiang Liu, Jiongxin Wang, Ruizhe Chen, Haoxiang Xia, Gaoang Wang, Jian Wu, Zuozhu Liu* | **Category: cs.LG, q-bio.GN** | **Updated: 2025-08-06**

**Keywords:** 零样本学习, 细胞类型注释, 图正则化, 单细胞RNA测序, Logit 细化

**Comment:** 

> **TL;DR:** GRIT通过图正则化细化LangCell的零样本预测，显著提升单细胞RNA测序数据中的细胞类型注释准确性，且无需训练。

**AI_Comments:** GRIT的创新点在于将图正则化引入到零样本学习的后处理阶段，有效地结合了预训练模型的广度和局部结构信息。其“无需训练”和“模型无关”的特性使其成为一个高度实用和可插拔的解决方案，能够轻松集成到现有的零样本注释工作流中，提升实际应用中的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 单细胞RNA测序数据中的细胞类型注释是基础步骤，但专家依赖的K-NN图构建方法劳动密集且不适用于大数据集。现有零样本自动化方法（如LangCell）虽然有潜力，但预测结果次优，尤其是在所有细胞类型上的一致性准确性不足。

**Method:** 本文提出GRIT方法，通过一个图正则化优化框架来细化LangCell产生的零样本logits。它通过在任务特定的基于PCA的k-NN图上强制执行局部一致性，将预训练模型的可扩展性与专家注释中依赖的结构鲁棒性相结合。

**Result:** GRIT方法在14个人类scRNA-seq数据集上持续提高了零样本注释准确性，准确率提升高达10%。进一步分析表明，GRIT通过图有效地传播正确信号，将错误标记的细胞拉回更准确的预测。

**Conclusion:** GRIT是一种无需训练、模型无关的简单而有效的插件，可以增强实践中的自动化细胞类型注释。它通过图正则化细化现有零样本模型的预测，显著提升了准确性。

> **ai_Abstract:** 本文提出了GRIT，一种图正则化Logit细化方法，旨在提升零样本细胞类型注释的准确性。针对现有自动化方法（如LangCell）准确性不足的问题，GRIT利用基于PCA的k-NN图，通过图正则化优化框架细化LangCell的零样本logits，从而强制执行局部一致性。实验结果表明，GRIT显著提高了零样本注释准确性，最高提升10%，并通过有效传播正确信号纠正错误标记的细胞。该方法无需训练、模型无关，可作为自动化细胞类型注释的有效插件。

> **摘要翻译:** 细胞类型注释是单细胞RNA测序 (scRNA-seq) 数据分析中的一个基本步骤。在实践中，人类专家通常依赖于主成分分析 (PCA) 揭示的结构，然后构建 $k$ 近邻 ($k$-NN) 图来指导注释。尽管有效，但这个过程劳动密集，并且无法扩展到大型数据集。CLIP风格模型的最新进展为自动化细胞类型注释提供了一条有前景的道路。通过将scRNA-seq谱与自然语言描述对齐，LangCell等模型实现了零样本注释。虽然LangCell展示了不错的零样本性能，但其预测仍然不尽如人意，尤其是在所有细胞类型上实现一致的准确性方面。在本文中，我们提出通过一个图正则化优化框架来细化LangCell产生的零样本logits。通过在任务特定的基于PCA的k-NN图上强制执行局部一致性，我们的方法将预训练模型的可扩展性与专家注释中依赖的结构鲁棒性相结合。我们在来自4项不同研究的14个已注释的人类scRNA-seq数据集上评估了我们的方法，这些数据集涵盖了11个器官和超过20万个单细胞。我们的方法持续提高了零样本注释准确性，实现了高达10%的准确率提升。进一步的分析展示了GRIT通过图有效传播正确信号的机制，将错误标记的细胞拉回更准确的预测。该方法无需训练，与模型无关，可作为增强实践中自动化细胞类型注释的简单而有效的插件。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [508] [Embedding Is (Almost) All You Need: Retrieval-Augmented Inference for Generalizable Genomic Prediction Tasks](https://arxiv.org/abs/2508.04757)
> *嵌入（几乎）就是你所需要的一切：用于可泛化基因组预测任务的检索增强推理*

*Nirjhor Datta, Swakkhar Shatabda, M Sohel Rahman* | **Category: cs.LG, q-bio.GN** | **Updated: 2025-08-06**

**Keywords:** 基因组预测, 嵌入, 微调, 泛化性, 碳效率

**Comment:** 

> **TL;DR:** 本文提出，在基因组预测任务中，基于嵌入的方法可以替代昂贵的微调，实现竞争性性能，并显著提高泛化能力和效率。

**AI_Comments:** 本文的创新点在于挑战了大型DNA语言模型在基因组任务中必须进行昂贵微调的普遍认知。它提出了一种更高效、更具泛化性的基于嵌入的替代方案，显著降低了推理成本和碳足迹，这对于实际部署，尤其是在资源受限或数据异构的环境中，具有重要意义。其发现为基因组AI的未来发展提供了新的视角，鼓励研究者探索更多轻量级和高效的推理策略。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型预训练DNA语言模型在基因组基准测试中表现出色，但大多数应用依赖于昂贵的微调，且在训练和测试数据分布不同时效果不佳。本文旨在探究任务特异性微调是否总是必要的。

**Method:** 研究人员调查了简单基于嵌入的管道，这些管道从大型预训练DNA语言模型（如DNABERT-2、Nucleotide Transformer和HyenaDNA）中提取固定表示，并将其输入轻量级分类器。

**Result:** 在不同数据分布的评估设置中，基于嵌入的方法通常优于微调，并将推理时间缩短10到20倍。例如，在增强子分类中，HyenaDNA嵌入结合zCurve达到0.68的准确率（微调为0.58），推理时间减少88%，碳排放降低8倍以上。在非TATA启动子分类中，DNABERT-2嵌入结合zCurve或GC content达到0.85的准确率（微调为0.89），碳足迹降低22倍。

**Conclusion:** 基于嵌入的管道不仅是一个强大的基线，而且是微调的一种更具泛化性和效率的替代方案，特别适用于部署在多样化或未见的基因组环境中。它们在保持强大预测性能的同时，提供了超过10倍的碳效率。

> **ai_Abstract:** 本文探讨了在基因组预测任务中，是否总是需要昂贵的模型微调。研究发现，通过大型预训练DNA语言模型（如DNABERT-2、Nucleotide Transformer、HyenaDNA）提取固定嵌入，并结合轻量级分类器，可以构建出性能具有竞争力且泛化能力更强的预测管道。与传统微调相比，这种基于嵌入的方法在不同数据分布下表现更优，并能显著减少推理时间（10-20倍）和碳排放（超过10倍碳效率），尤其适用于多样或未知的基因组环境。

> **摘要翻译:** 大型预训练DNA语言模型，如DNABERT-2、Nucleotide Transformer和HyenaDNA，在各种基因组基准测试中表现出强大的性能。然而，大多数应用依赖于昂贵的微调，而微调在训练和测试数据共享相似分布时效果最佳。在这项工作中，我们调查了任务特异性微调是否总是必要的。我们表明，简单的基于嵌入的管道，即从这些模型中提取固定表示并将其输入轻量级分类器，可以实现具有竞争力的性能。在数据分布不同的评估设置中，基于嵌入的方法通常优于微调，同时将推理时间缩短10到20倍。我们的结果表明，嵌入提取不仅是一个强大的基线，而且是微调的一种更具泛化性和效率的替代方案，特别适用于部署在多样化或未见的基因组环境中。例如，在增强子分类中，HyenaDNA嵌入结合zCurve达到0.68的准确率（而微调为0.58），推理时间减少88%，碳排放降低8倍以上（0.02公斤对0.17公斤二氧化碳）。在非TATA启动子分类中，DNABERT-2嵌入结合zCurve或GC content达到0.85的准确率（而微调为0.89），碳足迹降低22倍（0.02公斤对0.44公斤二氧化碳）。这些结果表明，基于嵌入的管道在保持强大预测性能的同时，提供了超过10倍的碳效率。代码可在此处获取：https://github.com/NIRJHOR-DATTA/EMBEDDING-IS-ALMOST-ALL-YOU-NEED。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [515] [Differentially Private Model-X Knockoffs via Johnson-Lindenstrauss Transform](https://arxiv.org/abs/2508.04800)
> *通过Johnson-Lindenstrauss变换实现差分隐私Model-X Knockoffs*

*Yuxuan Tao, Adel Javanmard* | **Category: cs.LG, math.ST, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 差分隐私, Model-X Knockoffs, Johnson-Lindenstrauss变换, 变量选择, FDR控制

**Comment:** 

> **TL;DR:** 该研究提出了一种通过高斯Johnson-Lindenstrauss变换对数据复制矩阵进行隐私化的新框架，以在差分隐私约束下实现高维变量选择中的严格错误发现率（FDR）控制，并理论分析了其性能。

**AI_Comments:** 该论文的创新之处在于，它提出了一种通过高斯Johnson-Lindenstrauss变换（JLT）实现差分隐私的新颖方法，用于Model-X Knockoff程序，解决了传统噪声注入方法破坏其核心可交换性条件的问题。这种结构性隐私保护方法在理论上被证明优于经典的噪声添加机制，即使在严格的隐私预算下也能保持统计功效，这对于在敏感领域进行可靠的变量选择至关重要。该工作成功地连接了基于Knockoff的FDR控制和私有数据发布这两个关键领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐私机制（如拉普拉斯或高斯噪声注入）会破坏Model-X Knockoff程序的核心可交换性条件，导致无法在差分隐私约束下实现高维受控变量选择中的严格错误发现率（FDR）控制。

**Method:** 通过高斯Johnson-Lindenstrauss变换（JLT）对数据复制矩阵进行隐私化。JLT是一种降维技术，通过近似等距同时保留协变量关系，以实现$(\epsilon,\delta)$-差分隐私。此外，该方法基于一种新颖的“去偏技术”用于高维私有复制程序。

**Result:** 在渐近状态下，理论上表征了所提出的私有变量选择程序的FDR和功效。分析揭示了JLT的降维比、信噪比、差分隐私参数、样本量和特征维度等因素在塑造隐私-功效权衡中的作用。研究还建立了所提程序功效收敛到1的充分条件。分析表明，通过随机投影实现的结构性隐私保护优于经典的噪声添加机制，即使在严格的隐私预算下也能保持统计功效。

**Conclusion:** 这项工作弥合了两个关键范式——基于Knockoff的FDR控制和私有数据发布——从而在敏感领域实现可靠的变量选择。

> **ai_Abstract:** 本研究提出了一种新颖的框架，通过高斯Johnson-Lindenstrauss变换（JLT）对数据复制矩阵进行隐私化，以在高维受控变量选择中实现差分隐私下的严格错误发现率（FDR）控制。该方法解决了现有隐私机制破坏Model-X Knockoff可交换性条件的问题。研究理论上分析了该私有变量选择程序的FDR和功效，并讨论了JLT降维比、信噪比等因素对隐私-功效权衡的影响。结果表明，通过随机投影实现的结构性隐私保护优于传统的噪声添加机制，即使在严格隐私预算下也能保持统计功效，从而在敏感数据领域实现可靠的变量选择。

> **摘要翻译:** 我们引入了一种用于高维受控变量选择的新型隐私化框架。我们的框架能够在差分隐私约束下实现严格的错误发现率（FDR）控制。虽然Model-X Knockoff程序通过构建可证明可交换的“负对照”特征来提供FDR保证，但现有的隐私机制（如拉普拉斯或高斯噪声注入）会破坏其核心可交换性条件。我们的关键创新在于通过高斯Johnson-Lindenstrauss变换（JLT）对数据复制矩阵进行隐私化，JLT是一种降维技术，通过近似等距同时保留协变量关系，以实现$(\epsilon,\delta)$-差分隐私。
我们在渐近状态下，理论上表征了所提出的私有变量选择程序的FDR和功效。我们的理论分析表征了不同因素（如JLT的降维比、信噪比、差分隐私参数、样本量和特征维度）在塑造隐私-功效权衡中的作用。我们的分析基于一种新颖的“去偏技术”用于高维私有复制程序。我们进一步建立了所提程序功效收敛到一的充分条件。这项工作弥合了两个关键范式——基于Knockoff的FDR控制和私有数据发布——从而在敏感领域实现可靠的变量选择。我们的分析表明，通过随机投影实现的结构性隐私保护优于经典的噪声添加机制，即使在严格的隐私预算下也能保持统计功效。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [526] [Keyword Spotting with Hyper-Matched Filters for Small Footprint Devices](https://arxiv.org/abs/2508.04857)
> *小足迹设备中基于超匹配滤波器的关键词识别*

*Yael Segal-Feldman, Ann R. Bradlow, Matthew Goldrick, Joseph Keshet* | **Category: cs.LG, cs.SD, eess.AS** | **Updated: 2025-08-06**

**Keywords:** 关键词识别, 开放词汇, 超网络, 匹配滤波器, 小足迹设备

**Comment:** 

> **TL;DR:** 本文提出了一种用于小足迹设备的开放词汇关键词识别模型，该模型利用超网络生成关键词特定的匹配滤波器权重，实现了最先进的性能，并且非常高效和鲁棒，即使对于第二语言语音也能有效泛化。

**AI_Comments:** 该论文的创新点在于使用超网络生成关键词特定的匹配滤波器权重，这种方法有效地将关键词信息编码到卷积层中，从而实现了高效且鲁棒的开放词汇KWS。其在小足迹设备上达到SOTA性能，并在泛化能力（尤其L2语音）上表现出色，这对于资源受限的边缘设备应用具有重要意义。模型的紧凑性（4.2M参数）和高性能是其突出优势。

<details>
  <summary>Details</summary>

**Motivation:** 开放词汇关键词识别（KWS）需要检测语音记录中的词语，无论它们是否包含在训练数据中。本文的动机是为小足迹设备开发一种具有最先进检测精度的开放词汇KWS模型。

**Method:** 该模型由一个语音编码器（可以是微型Whisper或微型Conformer）、一个目标关键词编码器和一个检测网络组成。目标关键词编码器实现为一个超网络，它将所需关键词作为字符串输入，并为卷积层生成一组独特的权重，这些权重可被视为关键词特定的匹配滤波器。检测网络使用这些匹配滤波器权重执行关键词特定的卷积，从而引导Perceiver模块的交叉注意力机制来确定目标词语是否出现在记录中。

**Result:** 该系统在检测性能上达到了最先进水平，并能有效泛化到域外条件，包括第二语言（L2）语音。最小的模型（仅420万参数）匹配或超越了体积大几倍的模型，展示了效率和鲁棒性。

**Conclusion:** 该研究成功开发了一种高效且鲁棒的开放词汇关键词识别系统，其在小足迹设备上实现了最先进的检测性能，并具有出色的泛化能力，即使面对第二语言语音也能表现良好。

> **ai_Abstract:** 本文提出了一种用于小足迹设备的开放词汇关键词识别（KWS）模型。该模型包含一个语音编码器（微型Whisper或Conformer）、一个基于超网络的目标关键词编码器（生成关键词特定的匹配滤波器权重）和一个检测网络。该系统实现了最先进的检测精度，并能有效泛化到包括第二语言语音在内的域外条件。其最小模型（420万参数）在性能上可与大几倍的模型媲美或超越，展现出高效率和鲁棒性。

> **摘要翻译:** 开放词汇关键词识别（KWS）是指在语音记录中检测词语或术语的任务，无论它们是否包含在训练数据中。本文介绍了一种开放词汇关键词识别模型，该模型在小足迹设备上具有最先进的检测精度。该模型由一个语音编码器、一个目标关键词编码器和一个检测网络组成。语音编码器可以是微型Whisper或微型Conformer。目标关键词编码器实现为一个超网络，它将所需关键词作为字符字符串输入，并为卷积层生成一组独特的权重，这些权重可被视为关键词特定的匹配滤波器。检测网络使用匹配滤波器权重执行关键词特定的卷积，从而引导Perceiver模块的交叉注意力机制来确定目标词语是否出现在记录中。结果表明，我们的系统实现了最先进的检测性能，并能有效地泛化到域外条件，包括第二语言（L2）语音。值得注意的是，我们最小的模型，仅有420万参数，却能匹配或超越大几倍的模型，这证明了其效率和鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [532] [Can SGD Handle Heavy-Tailed Noise?](https://arxiv.org/abs/2508.04860)
> *SGD能处理重尾噪声吗？*

*Ilyas Fatkhullin, Florian Hübler, Guanghui Lan* | **Category: cs.LG, math.OC** | **Updated: 2025-08-06**

**Keywords:** 随机梯度下降, 重尾噪声, 收敛性, 优化, 样本复杂度

**Comment:** 

> **TL;DR:** 研究表明，即使在重尾噪声下，标准SGD在凸、强凸和非凸问题中也能达到最优或具有竞争力的收敛速度，挑战了SGD在重尾噪声下无效的普遍观点。

**AI_Comments:** 这项工作的重要意义在于它在理论上挑战了长期以来关于SGD在重尾噪声环境下表现不佳的假设。通过为标准SGD在多种问题设置下提供严格的收敛保证，它重新确立了SGD作为一种通用且鲁棒的优化算法的地位，即使在方差无界等极端条件下也表现出色。这对于现代机器学习和强化学习应用具有重要指导意义，因为这些领域经常面临重尾噪声。

<details>
  <summary>Details</summary>

**Motivation:** 随机梯度下降（SGD）是大规模优化的基石，然而其在重尾噪声（在现代机器学习和强化学习中常见）下的理论行为仍然知之甚少。

**Method:** 本研究严格调查了朴素SGD，没有任何自适应修改，是否能在不利的随机条件下被证明成功。假设随机梯度仅具有有界$p$阶矩（$p 	ext{ 	extgreater } 1$），我们为（投影）SGD在凸、强凸和非凸问题类别中建立了尖锐的收敛保证。

**Result:** 在凸和强凸设置下，SGD达到了minimax最优样本复杂度，分别为$\\mathcal{O}(\\varepsilon^{-\\frac{p}{p-1}})$和$\\mathcal{O}(\\varepsilon^{-\\frac{p}{2(p-1)}})$。对于H\\"older平滑的非凸目标，证明了收敛到平稳点的速率为$\\mathcal{O}(\\varepsilon^{-\\frac{2p}{p-1}})$，并提供了匹配的下界。非凸Mini-batch SGD在标准平滑和有界中心矩假设下也达到了可比的$\\mathcal{O}(\\varepsilon^{-\\frac{2p}{p-1}})$样本复杂度。

**Conclusion:** 这些结果挑战了重尾噪声使SGD无效的普遍观点，并确立了朴素SGD作为一个鲁棒且理论上合理的基线，即使在方差无界的情况下也适用。

> **ai_Abstract:** 本研究严格探究了标准随机梯度下降（SGD）在重尾噪声下的理论行为，其中随机梯度仅具有有界$p$阶矩（$p \\in (1, 2]$）。研究为凸、强凸和非凸问题建立了尖锐的收敛保证，表明SGD在凸和强凸情况下能达到最优样本复杂度，并在非凸情况下达到竞争性收敛速率。这些发现挑战了SGD在重尾噪声下无效的传统观念，证明了标准SGD即使在方差无界时也是一个鲁棒且理论上可靠的基线。

> **摘要翻译:** 随机梯度下降（SGD）是大规模优化的基石，然而其在重尾噪声——在现代机器学习和强化学习中常见——下的理论行为仍然知之甚少。在这项工作中，我们严格调查了朴素SGD，没有任何自适应修改，是否能在这种不利的随机条件下被证明成功。假设随机梯度仅具有有界$p$阶矩，其中$p \\in (1, 2]$，我们为（投影）SGD在凸、强凸和非凸问题类别中建立了尖锐的收敛保证。特别是，我们表明SGD在凸和强凸情况下，在最小假设下实现了minimax最优样本复杂度：分别为$\\mathcal{O}(\\varepsilon^{-\\frac{p}{p-1}})$和$\\mathcal{O}(\\varepsilon^{-\\frac{p}{2(p-1)}})$。对于H\\"older平滑的非凸目标，我们证明了收敛到平稳点的速率为$\\mathcal{O}(\\varepsilon^{-\\frac{2p}{p-1}})$，并辅以特定于任意多项式步长调度SGD的匹配下界。最后，我们考虑了在标准平滑和有界中心矩假设下的非凸Mini-batch SGD，并表明它也达到了可比的$\\mathcal{O}(\\varepsilon^{-\\frac{2p}{p-1}})$样本复杂度，且平滑常数可能有所改进。这些结果挑战了重尾噪声使SGD无效的普遍观点，并确立了朴素SGD作为一个鲁棒且理论上合理的基线——即使在方差无界的情况下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [538] [The Cosine Schedule is Fisher-Rao-Optimal for Masked Discrete Diffusion Models](https://arxiv.org/abs/2508.04884)
> *余弦调度是掩码离散扩散模型的Fisher-Rao最优解*

*Leo Zhang* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 余弦调度, Fisher-Rao几何, 掩码离散扩散模型, 离散化调度, 信息几何

**Comment:** 

> **TL;DR:** 本文证明了余弦调度在Fisher-Rao几何下是掩码离散扩散模型的最佳离散化调度。

**AI_Comments:** 这项工作通过信息几何为广泛使用的余弦调度提供了理论依据，证明了其在掩码离散扩散模型中的Fisher-Rao最优性，具有重要的理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 研究掩码离散扩散模型采样中的离散化调度选择问题，旨在从信息几何角度找到最优调度。

**Method:** 通过研究诱导概率路径的信息几何，特别是Fisher-Rao几何，来确定最优调度。

**Result:** 在Fisher-Rao几何下，最优调度恢复了广泛使用的余弦调度。

**Conclusion:** 余弦调度对于掩码离散扩散模型而言是Fisher-Rao最优的，这为它的广泛使用提供了理论依据。

> **ai_Abstract:** 本文从诱导概率路径的信息几何角度研究了掩码离散扩散模型的最佳离散化调度问题，并证明了广泛使用的余弦调度在Fisher-Rao几何下是最优的。

> **摘要翻译:** 在这项工作中，我们从诱导概率路径的信息几何角度研究了选择掩码离散扩散模型采样离散化调度的问题。具体来说，我们证明了在Fisher-Rao几何下，最优调度恢复了广泛使用的余弦调度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [550] [An ML-based Approach to Predicting Software Change Dependencies: Insights from an Empirical Study on OpenStack](https://arxiv.org/abs/2508.05034)
> *一种基于机器学习的软件变更依赖预测方法：来自OpenStack实证研究的见解*

*Arabat, Sayagh, Mohammed, Hassine, Jameleddine* | **Category: cs.LG, cs.SE** | **Updated: 2025-08-07**

**Keywords:** 软件变更依赖, 机器学习, 依赖预测, OpenStack, 实证研究

**Comment:** 

> **TL;DR:** 本研究提出了一种半自动化的机器学习方法，用于预测软件变更之间的依赖关系，以解决在复杂软件系统中手动识别依赖所带来的挑战，并在OpenStack上验证了其有效性。

**AI_Comments:** 本文通过对OpenStack的实证研究，量化了软件变更依赖识别的痛点，强调了其重要性。提出的双模型机器学习方法具有创新性，旨在从被动识别转向主动预测，这对于提升CI/CD效率和减少开发成本具有重要意义。尽管模型性能良好，但top-k精度的提升空间表明，在实际应用中，仍需进一步优化以减少误报，提高开发者的采纳度。

<details>
  <summary>Details</summary>

**Motivation:** 随着软件系统日益复杂，准确识别和管理变更之间的依赖关系变得至关重要，因为这能有效支持CI/CD流程，防止构建失败和不完整的功能部署。然而，在现代软件系统中，依赖关系往往跨越多个组件和团队，导致开发人员需要花费大量时间（中位数57.12小时）在代码审查阶段（平均延迟5.06小时）才发现依赖关系，这带来了显著的挑战。

**Method:** 本研究首先对大型软件系统OpenStack中的依赖管理进行了初步的实证研究，发现过去10年间OpenStack中大部分软件变更都是相互依赖的。为了帮助开发人员主动识别依赖关系，研究提出了一种半自动化方法，该方法利用两个机器学习模型：第一个模型预测变更之间存在依赖关系的可能性，第二个模型识别确切的依赖变更对。

**Result:** 实证研究发现，OpenStack中51.08%的依赖关系是在代码审查阶段才被识别出来，平均延迟为5.06小时，而非变更创建时。开发人员平均花费57.12小时在463个其他变更中识别依赖关系。所提出的机器学习模型表现出强大的性能，平均AUC分数分别为79.33%和91.89%，Brier分数分别为0.11和0.014。其中，第二个模型在所有类型的依赖对上都具有良好的top-k召回率，但top-k精度仍有改进空间。

**Conclusion:** 本研究通过实证分析揭示了软件变更依赖识别的挑战，并提出了一种基于机器学习的半自动化方法来主动预测这些依赖关系。该方法在预测变更依赖方面表现出良好的性能，有望显著减少开发人员识别依赖所需的时间和精力，从而提高CI/CD流程的效率和可靠性。

> **ai_Abstract:** 本研究针对复杂软件系统中手动识别变更依赖的挑战，首先对OpenStack进行了实证研究，揭示了依赖识别的延迟和高成本。在此基础上，提出了一种半自动化的机器学习方法，包含两个模型：一个预测依赖可能性，另一个识别具体依赖对。该方法在实验中展现出强大的性能，有望显著提升软件开发中依赖管理的效率和准确性。

> **摘要翻译:** 随着软件系统日益复杂，准确识别和管理变更之间的依赖关系变得越来越重要。例如，一个利用某个功能的变更必须依赖于引入该功能的变更。建立这样的依赖关系使得CI/CD管道能够有效地构建和编排变更，防止构建失败和不完整的功能部署。在现代软件系统中，依赖关系通常跨越多个组件和团队，给开发和部署带来挑战。它们服务于各种目的，从启用新功能到管理配置，甚至可能涉及传统上独立的变更，如文档更新。为了应对这些挑战，我们对大型软件系统OpenStack中的依赖管理进行了初步研究。我们的研究表明，过去10年间OpenStack中很大一部分软件变更都是相互依赖的。令人惊讶的是，这些依赖关系中有51.08%是在代码审查阶段（平均延迟5.06小时）而非变更创建时被识别出来的。开发人员通常花费平均57.12小时来识别依赖关系，在平均463个其他变更中进行搜索。为了帮助开发人员主动识别依赖关系，我们提出了一种利用两个机器学习模型的半自动化方法。第一个模型预测变更之间存在依赖关系的可能性，而第二个模型识别确切的依赖变更对。我们提出的模型表现出强大的性能，平均AUC分数分别为79.33%和91.89%，Brier分数分别为0.11和0.014。事实上，第二个模型在所有类型的依赖对上都具有良好的top-k召回率，而top-k精度仍有改进空间。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [556] [Hybrid quantum tensor networks for aeroelastic applications](https://arxiv.org/abs/2508.05169)
> *混合量子张量网络在气动弹性应用中的研究*

*M. Lautaro Hickmann, Pedro Alves, David Quero, Friedhelm Schwenker, Hans-Martin Rieser* | **Category: cs.LG, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 混合量子张量网络, 气动弹性, 量子机器学习, 时间序列, 分类, 回归

**Comment:** 

> **TL;DR:** 本文研究了混合量子张量网络在气动弹性问题中的应用，结合张量网络和变分量子电路，展示了量子机器学习在时间序列分类和回归任务中的潜力，并在二元分类中取得了高精度。

**AI_Comments:** 本文的创新之处在于将量子张量网络与变分量子电路相结合，形成一个端到端可训练的混合算法，并将其应用于气动弹性这一复杂领域。这展示了量子机器学习在处理实际工程问题上的潜力。其重要性在于为高维时间序列数据的处理和复杂系统建模提供了新的量子计算视角。然而，论文也指出了超参数选择的挑战，这可能是未来研究需要解决的关键限制。

<details>
  <summary>Details</summary>

**Motivation:** 研究混合量子张量网络在气动弹性问题中的应用，并利用量子机器学习（QML）解决复杂的时序分类和回归任务。

**Method:** 本文提出了一种端到端可训练的混合算法。首先将时间序列编码到张量网络中，然后利用可训练的张量网络进行降维，并将生成的张量在编码步骤中转换为量子电路。接着，应用受张量网络启发的、可训练的变分量子电路来解决气动弹性领域的分类、多元或一元回归任务。

**Result:** 混合量子张量网络在二元分类中实现了高精度。在离散变量回归中也观察到有希望的性能。

**Conclusion:** 这项工作显著促进了量子机器学习在解决气动弹性领域复杂问题方面的发展，尽管超参数选择仍是一个挑战，需要仔细优化才能充分发挥这些模型的潜力。

> **ai_Abstract:** 本文探讨了混合量子张量网络在气动弹性问题中的应用，结合量子机器学习（QML）和变分量子电路，以处理复杂的时间序列分类和回归任务。研究提出了一种端到端可训练的混合算法，通过将时间序列编码到张量网络中进行降维，并转换为量子电路，最终利用受张量网络启发的变分量子电路进行分类或回归。实验结果表明，该方法在二元分类中取得了高精度，并在离散变量回归中表现出良好性能。尽管超参数优化仍是挑战，但该工作为解决气动弹性领域的复杂问题提供了新的QML方法。

> **摘要翻译:** 我们研究了混合量子张量网络在气动弹性问题中的应用，利用量子机器学习（QML）的力量。通过将张量网络与变分量子电路相结合，我们展示了QML处理复杂时间序列分类和回归任务的潜力。我们的结果展示了混合量子张量网络在二元分类中实现高精度的能力。此外，我们观察到在回归离散变量方面有希望的性能。尽管超参数选择仍然是一个挑战，需要仔细优化以充分发挥这些模型的潜力，但这项工作对开发QML以解决气动弹性中的复杂问题做出了重大贡献。我们提出了一种端到端可训练的混合算法。我们首先将时间序列编码到张量网络中，然后利用可训练的张量网络进行降维，并将生成的张量在编码步骤中转换为量子电路。然后，应用受张量网络启发的、可训练的变分量子电路来解决气动弹性领域中的分类或多元或一元回归任务。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [562] [High-Dimensional Differentially Private Quantile Regression: Distributed Estimation and Statistical Inference](https://arxiv.org/abs/2508.05212)
> *高维差分隐私分位数回归：分布式估计与统计推断*

*Ziliang Shen, Caixing Wang, Shaoli Wang, Yibo Yan* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 差分隐私, 分位数回归, 分布式估计, 高维数据, 统计推断

**Comment:** 

> **TL;DR:** 本文提出了一种在高维分布式设置下进行差分隐私分位数回归的方法，通过牛顿型变换解决计算挑战，并开发了私有估计器和通信高效的自举法以实现准确的统计推断。

**AI_Comments:** 本文的创新点在于将差分隐私与分位数回归相结合，并解决了高维分布式环境下的计算和统计推断挑战。通过引入牛顿型变换和开发去偏估计器及通信高效的自举法，显著提升了方法的实用性。这对于在敏感数据上进行鲁棒统计分析具有重要意义，尤其是在隐私保护日益受到关注的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 随着大数据和机器学习的发展，处理包含敏感个人信息的异构数据集时，隐私问题变得越来越重要。差分隐私提供了一个严格的框架来保护个人隐私，同时进行有意义的统计分析。分位数回归是一种强大的工具，适用于存在异常值或重尾分布的数据建模。

**Method:** 提出了一种在高维分布式设置下的差分隐私分位数回归方法。通过引入牛顿型变换将分位数回归任务转化为普通最小二乘问题，以解决分位数损失函数的非光滑性带来的计算挑战。开发了一个具有迭代更新的差分隐私估计算法，确保接近最优的统计精度和形式化的隐私保障。进一步提出了一种差分隐私去偏估计器，用于有效的置信区间构建和假设检验。此外，提出了一种通信高效的差分隐私自举法，用于高维分位数回归中的同步假设检验，适用于局部数据量小或丰富的分布式设置。

**Result:** 广泛的模拟结果表明，所提出的方法在实际场景中具有鲁棒性和有效性。

**Conclusion:** 本文提出的差分隐私分位数回归方法在高维分布式设置下，通过创新的计算和推断技术，有效解决了隐私保护下的统计分析挑战，并表现出良好的性能。

> **ai_Abstract:** 本文针对大数据和机器学习背景下的隐私保护需求，提出了一种在高维分布式环境中实现差分隐私分位数回归的新方法。为应对分位数损失函数的非光滑性，作者引入牛顿型变换将其转化为最小二乘问题，并在此基础上开发了迭代更新的差分隐私估计算法，以保障统计精度和隐私。此外，论文还提出了差分隐私去偏估计器和通信高效的自举法，以支持置信区间构建和高维同步假设检验。模拟结果验证了所提方法的鲁棒性和有效性。

> **摘要翻译:** 随着大数据和机器学习的发展，隐私问题变得越来越重要，尤其是在处理包含敏感个人信息的异构数据集时。差分隐私提供了一个严格的框架，用于保护个人隐私，同时进行有意义的统计分析。在本文中，我们提出了一种在高维分布式设置下的差分隐私分位数回归方法。分位数回归是一种强大而稳健的工具，用于在存在异常值或重尾分布的情况下，建模协变量和响应之间的关系。为了解决分位数损失函数非光滑性带来的计算挑战，我们引入了一种牛顿型变换，将分位数回归任务重新表述为普通最小二乘问题。在此基础上，我们开发了一种具有迭代更新的差分隐私估计算法，确保了接近最优的统计精度和形式化的隐私保障。为了进行推断，我们进一步提出了一种差分隐私去偏估计器，这使得有效的置信区间构建和假设检验成为可能。此外，我们提出了一种通信高效的差分隐私自举法，用于高维分位数回归中的同步假设检验，适用于局部数据量小或丰富的分布式设置。广泛的模拟结果证明了我们方法在实际场景中的鲁棒性和有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [568] [Harmonic fractal transformation for modeling complex neuronal effects: from bursting and noise shaping to waveform sensitivity and noise-induced subthreshold spiking](https://arxiv.org/abs/2508.05341)
> *和声分形变换用于建模复杂神经元效应：从爆发和噪声整形到波形敏感性和噪声诱导的阈下放电*

*Mariia Sorokina* | **Category: cs.LG, cs.NE, q-bio.NC** | **Updated: 2025-08-07**

**Keywords:** 分形频率映射, 神经元效应, 噪声整形, 频谱重组, 波形敏感性

**Comment:** 

> **TL;DR:** 提出了一种分形频率映射，能够通过分形重组输入频谱来模拟复杂的神经元效应，提高检测灵敏度、鲁棒性和噪声诱导的信号放大。

**AI_Comments:** 该论文提出了一种创新的分形频率映射方法，突破了传统滤波器的限制，通过频谱的分形重组来模拟神经元复杂行为。其新颖之处在于能够激发新的频谱分量，而非仅仅抑制或放大现有分量，这对于理解和建模神经元在噪声环境下的工作方式具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 复制复杂的神经元效应，并提出一种不同于传统滤波器的新方法来处理输入频谱，以实现高灵敏度检测、对噪声的鲁棒性以及噪声诱导的信号放大。

**Method:** 提出了一种分形频率映射（fractal frequency mapping），通过分形重组输入频谱来激发新的分量，在对采样最优的共振频率处形成尖峰。该模型将神经元功能视为非线性变换频率域上频谱的线性求和。

**Result:** 实现了高灵敏度检测、对噪声的鲁棒性以及噪声诱导的信号放大。

**Conclusion:** 神经元功能可以被视为非线性变换频率域上频谱的线性求和。

> **ai_Abstract:** 本文引入了一种新颖的分形频率映射方法，旨在模拟复杂的神经元效应。与传统滤波器不同，该方法通过分形重组输入频谱来生成新的频率分量，并在共振频率处形成尖峰，从而实现高灵敏度检测、强大的噪声鲁棒性和噪声诱导的信号放大。研究提出神经元功能可以被理解为在非线性变换的频率域上进行的频谱线性求和。

> **摘要翻译:** 我们提出了第一个分形频率映射，它以简单的形式能够复制复杂的神经元效应。与根据滤波器权重抑制或放大输入频谱分量的传统滤波器不同，该变换通过输入频谱的分形重组激发新的分量，从而在对采样最优的共振频率处形成尖峰。这使得高灵敏度检测、对噪声的鲁棒性以及噪声诱导的信号放大成为可能。所提出的模型表明，神经元功能可以被视为非线性变换频率域上频谱的线性求和。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [574] [Learning Geometric-Aware Quadrature Rules for Functional Minimization](https://arxiv.org/abs/2508.05445)
> *学习用于泛函最小化的几何感知求积规则*

*Costas Smaragdakis* | **Category: cs.LG, math.NA** | **Updated: 2025-08-07**

**Keywords:** 几何感知求积, 图神经网络, 非均匀点云, 数值积分, 变分原理

**Comment:** 

> **TL;DR:** QuadrANN是一种基于GNN的求积规则学习方法，能够生成对点云几何和密度自适应的求积规则，显著降低了数值积分的方差，并提升了深度学习变分求解器的稳定性。

**AI_Comments:** QuadrANN的创新之处在于其将图神经网络应用于学习自适应求积规则，尤其是在处理非均匀点云和函数奇点区域时表现出的优越性。通过整合局部几何和全局上下文信息，模型能够动态调整点云密度，有效降低了数值积分的方差，对提高基于深度学习的变分求解器在复杂物理问题中的精度和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在非均匀点云上进行精确数值积分是现代无网格机器学习求解偏微分方程（PDEs）变分原理所面临的挑战。标准蒙特卡洛方法无法处理非均匀点云，而现有神经网络架构虽能处理置换不变输入，但仍需更优的求积规则。

**Method:** 本文引入了QuadrANN，一种图神经网络（GNN）架构，旨在直接从点云的底层几何中学习最优求积权重。该模型利用深度消息传递机制，初始层编码来自绝对和相对位置以及显式局部密度测量的丰富局部几何特征，后续层则整合全局上下文向量。这种架构选择使得QuadrANN能够生成数据驱动的、置换不变且能适应局部点密度和整体域形状的求积规则。

**Result:** QuadrANN在包括凸域和非凸域上的积分以及热方程和Fokker-Planck方程解估计等一系列具有挑战性的测试案例中进行了验证。在所有测试中，通过将点云扭曲以在被积函数存在奇点的关键区域变得更密集，QuadrANN与标准准蒙特卡洛方法相比，显著降低了积分估计的方差。这种在域关键区域增强的稳定性对于能量泛函的优化至关重要，从而改进了基于深度学习的变分求解器。

**Conclusion:** QuadrANN通过学习几何感知的求积规则，有效解决了非均匀点云上数值积分的挑战，显著提高了积分精度和能量泛函优化的稳定性，为深度学习变分求解器提供了关键支持。

> **ai_Abstract:** 本研究提出了一种名为QuadrANN的图神经网络（GNN）架构，用于学习在非均匀点云上进行函数最小化的几何感知求积规则。QuadrANN通过深度消息传递机制，结合局部几何特征和全局上下文信息，生成数据驱动的、置换不变且能自适应点云密度和域形状的求积规则。实验结果表明，QuadrANN在各种积分和PDE求解任务中，相较于传统方法能显著降低积分估计的方差，特别是在被积函数存在奇点的关键区域，从而提高了能量泛函优化的稳定性和深度学习变分求解器的性能。

> **摘要翻译:** 在非均匀点云上进行精确数值积分是现代无网格机器学习求解基于变分原理的偏微分方程（PDEs）所面临的挑战。虽然标准蒙特卡洛（MC）方法无法处理非均匀点云，但现代神经网络架构可以处理置换不变输入，为任何点云创建求积规则。在这项工作中，我们引入了QuadrANN，一种图神经网络（GNN）架构，旨在直接从点云的底层几何中学习最优求积权重。该模型的设计利用了深度消息传递机制，其中初始层从绝对和相对位置以及显式局部密度测量中编码丰富的局部几何特征。相比之下，后续层则整合了全局上下文向量。这些架构选择使得QuadrANN能够生成数据驱动的、置换不变且能适应局部点密度和整体域整体形状的求积规则。我们在包括凸域和非凸域上的积分以及热方程和Fokker-Planck方程解估计在内的一系列具有挑战性的测试案例中测试了我们的方法。在所有测试中，与标准准蒙特卡洛方法相比，QuadrANN通过将点云扭曲以在被积函数存在某些奇点的关键区域变得更密集，从而降低了积分估计的方差。这种在域关键区域增强的稳定性对于能量泛函的优化至关重要，从而改进了基于深度学习的变分求解器。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [580] [Exact and Heuristic Algorithms for Constrained Biclustering](https://arxiv.org/abs/2508.05493)
> *约束双聚类的精确算法与启发式算法*

*Antonio M. Sudoso* | **Category: cs.LG, math.OC** | **Updated: 2025-08-07**

**Keywords:** 双聚类, 约束聚类, 半定规划, 分支切割, 启发式算法

**Comment:** 

> **TL;DR:** 研究了带成对约束的双聚类问题，提出了一种基于SDP松弛的精确分支切割算法和一种基于低秩分解的启发式算法，并在实验中验证了其有效性。

**AI_Comments:** 该论文的创新之处在于其解决了带有先验知识约束的双聚类问题，这在实际应用中非常重要。它提出了一种结合半定规划（SDP）松弛的精确分支切割算法，以及一种基于SDP低秩分解的有效启发式算法。这两种定制算法在实验中表现出优于通用求解器的性能，证明了其在处理约束双聚类问题上的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高双聚类解决方案的质量和可解释性，通过引入背景知识（先验信息）来指导行和列的联合分组。

**Method:** 提出了精确算法和启发式算法。精确算法是基于低维半定规划（SDP）松弛的定制分支切割算法，通过有效不等式加强并以割平面方式求解，并利用整数规划工具将SDP解转换为可行的双聚类。启发式算法基于SDP的低秩分解，通过增广拉格朗日法解决非线性优化问题，子问题通过块坐标投影梯度算法分解求解。

**Result:** 在合成和真实数据集上的大量实验表明，精确方法显著优于通用求解器，而启发式方法在大型实例上能高效获得高质量解决方案。

**Conclusion:** 本文提出的针对约束双聚类的精确和启发式算法能够有效解决相关问题，并在实验中证明了其在性能和效率上的优越性，特别是在处理大规模数据时，通过融入先验知识，能获得高质量的解决方案。

> **ai_Abstract:** 本文研究了带成对约束的双聚类问题，特别是k-最密集不相交双团问题的约束版本。作者提出了两种算法：一种是基于低维半定规划（SDP）松弛并结合舍入方案的精确分支切割算法；另一种是基于SDP低秩分解并利用增广拉格朗日法求解的有效启发式算法。实验结果表明，精确方法显著优于通用求解器，而启发式方法在大型数据集上能高效获得高质量解决方案。

> **摘要翻译:** 双聚类，也称为协同聚类或双向聚类，同时对数据矩阵的行和列进行分区，以揭示具有一致模式的子矩阵。将背景知识纳入聚类以提高解决方案质量和可解释性，在数学优化和机器学习研究中引起了越来越大的兴趣。将这种范式扩展到双聚类，使得先验信息能够指导行和列的联合分组。我们研究了带成对约束的双聚类，即必须链接和不能链接约束，这些约束指定对象是应该属于相同还是不同的双聚类。作为模型问题，我们解决了k-最密集不相交双团问题的约束版本，该问题旨在加权完全二分图中识别k个不相交的完全二分图（称为双团），在满足成对约束的同时最大化总密度。我们提出了精确算法和启发式算法。精确方法是基于低维半定规划（SDP）松弛的定制分支切割算法，通过有效不等式加强并以割平面方式求解。利用整数规划工具，一种舍入方案将SDP解在每个节点转换为可行的双聚类。对于大规模实例，我们引入了一种基于SDP低秩分解的有效启发式算法。由此产生的非线性优化问题通过增广拉格朗日法解决，其中子问题通过块坐标投影梯度算法分解求解。在合成和真实数据集上的大量实验表明，精确方法显著优于通用求解器，而启发式方法在大型实例上能高效获得高质量解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [586] [On the Design of Expressive and Trainable Pulse-based Quantum Machine Learning Models](https://arxiv.org/abs/2508.05559)
> *表达能力和可训练脉冲式量子机器学习模型的设计*

*Han-Xiao Tao, Xin Wang, Re-Bing Wu* | **Category: cs.LG, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 脉冲式量子机器学习, 表达能力, 可训练性, 动态对称性, 必要条件

**Comment:** 

> **TL;DR:** 本文研究了脉冲式量子机器学习模型的设计，旨在确保其在保持可训练性的同时具备表达能力，并提出了一个关键的必要条件。

**AI_Comments:** 这篇论文解决了脉冲式量子机器学习模型设计中的一个核心挑战，即如何在保持可训练性的同时确保其表达能力。通过提出一个明确的必要条件，它为未来QML模型的硬件高效和实用化设计提供了重要的理论指导。其创新性在于将物理系统的初始状态、测量方式与底层对称性结合起来，为解决训练中的“荒漠高原”问题提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲式量子机器学习模型在实际应用中必须同时具备表达能力和可训练性。然而，现有研究表明，虽然动态对称性有助于模型训练，但可能损害其表达能力。因此，本研究旨在探究如何设计模型以平衡这两个关键特性。

**Method:** 本文通过理论分析，提出了一个关于系统初始状态、测量可观测物以及底层动力学对称李代数的必要条件，并通过数值模拟对该条件进行了支持和验证。

**Result:** 研究提出了一个关于系统初始状态、测量可观测物和底层动力学对称李代数的必要条件，该条件对于设计同时具备表达能力和可训练性的脉冲式量子机器学习模型至关重要。

**Conclusion:** 本研究的发现为设计兼顾表达能力和可训练性的实用脉冲式量子机器学习模型建立了一个理论框架。

> **ai_Abstract:** 本文探讨了脉冲式量子机器学习模型在实际应用中如何平衡表达能力和可训练性。研究指出，虽然动态对称性有助于训练，但可能损害表达能力。为此，论文提出了一个与系统初始状态、测量可观测物及动力学对称李代数相关的必要条件，并通过数值模拟进行了验证。该发现为设计实用的、兼顾两者的脉冲式QML模型提供了关键框架。

> **摘要翻译:** 脉冲式量子机器学习（QML）因其卓越的硬件效率而成为量子人工智能领域的新范式。对于实际应用而言，脉冲式模型必须同时具备表达能力和可训练性。先前的研究表明，在动态对称性下的脉冲式模型可以有效地训练，这得益于没有荒漠高原的有利损失景观。然而，当模型设计不充分时，由此产生的不受控性可能会损害表达能力。本文研究了脉冲式QML模型在保持可训练性的同时具备表达能力的要求。我们提出了一个与系统初始状态、测量可观测物和底层动力学对称李代数相关的必要条件，并辅以数值模拟进行支持。我们的研究结果为设计平衡表达能力和可训练性的实用脉冲式QML模型建立了一个框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [591] [L1-Regularized Functional Support Vector Machine](https://arxiv.org/abs/2508.05567)
> *L1-正则化函数支持向量机*

*Bingfan Liu, Peijun Sang* | **Category: cs.LG, stat.CO, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 函数支持向量机, L1正则化, 多变量函数协变量, 二分类, 特征选择

**Comment:** 

> **TL;DR:** 提出了一种L1正则化的函数支持向量机，用于处理多变量函数协变量的二分类问题，并能进行特征选择。

**AI_Comments:** 这篇论文的创新点在于将L1正则化引入函数支持向量机，从而有效处理了多变量函数协变量的分类问题，并实现了重要的特征选择功能。这对于高维函数数据分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的函数数据分析中的二分类研究主要集中在单变量函数协变量，而多变量函数协变量的分类问题研究较少，本文旨在填补这一空白。

**Method:** 提出了一种L1正则化的函数支持向量机（L1-regularized functional support vector machine），并开发了相应的算法来拟合分类器。通过施加L1惩罚，该算法能够识别二元响应的相关函数协变量。

**Result:** 仿真和实际应用中的数值结果表明，所提出的分类器在预测和特征选择方面都表现出良好的性能。

**Conclusion:** 所提出的L1正则化函数支持向量机能够有效处理多变量函数协变量的二分类问题，并具备良好的预测能力和重要的特征选择能力。

> **ai_Abstract:** 本文针对函数数据分析中多变量函数协变量的二分类问题，提出了一种L1正则化的函数支持向量机。该方法通过L1惩罚实现了相关函数协变量的识别，并在仿真和实际应用中验证了其在预测和特征选择上的优良性能，填补了该领域的研究空白。

> **摘要翻译:** 在函数数据分析中，具有一个函数协变量的二元分类已得到广泛研究。我们旨在填补在分类中考虑多变量函数协变量的空白。特别是，我们提出了一种用于二元分类的L1正则化函数支持向量机。开发了一种配套算法来拟合分类器。通过施加L1惩罚，该算法使我们能够识别二元响应的相关函数协变量。来自模拟和一项真实世界应用的数值结果表明，所提出的分类器在预测和特征选择方面都表现出良好的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [598] [High-Order Error Bounds for Markovian LSA with Richardson-Romberg Extrapolation](https://arxiv.org/abs/2508.05570)
> *马尔可夫LSA中Richardson-Romberg外推法的高阶误差界*

*Ilya Levin, Alexey Naumov, Sergey Samsonov* | **Category: cs.LG, math.OC, math.ST, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 线性随机逼近, Richardson-Romberg外推, 误差界, 马尔可夫噪声, 偏差消除

**Comment:** 

> **TL;DR:** 本文研究了马尔可夫噪声下带有Polyak-Ruppert平均的线性随机逼近（LSA）算法的偏差和高阶误差界，并提出通过Richardson-Romberg（RR）外推法有效消除主要偏差项，实现了与渐近最优协方差矩阵对齐的领先误差项。

**AI_Comments:** 本文的创新点在于提出了偏差的新颖分解方法，并创造性地将Richardson-Romberg外推法应用于消除马尔可夫噪声下线性随机逼近算法中的主要偏差项。这一方法有效地解决了传统Polyak-Ruppert平均无法消除线性偏差的问题，显著提升了算法的性能和误差界，使得算法的误差能够达到渐近最优水平，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Polyak-Ruppert (PR) 平均的线性随机逼近（LSA）算法在马尔可夫噪声下，其主要偏差项是线性的，且无法被PR平均消除，这促使研究者寻找一种方法来消除或减少这种偏差。

**Method:** 本文提出了一种通过线性化技术对偏差进行的新颖分解。为了解决现有问题，应用了Richardson-Romberg（RR）外推程序。

**Result:** RR外推法有效地消除了主要偏差项。推导出了RR迭代的高阶矩界，并表明领先误差项与普通平均LSA迭代的渐近最优协方差矩阵对齐。

**Conclusion:** Richardson-Romberg（RR）外推法能够有效消除马尔可夫噪声下线性随机逼近（LSA）算法的主要偏差项，并使误差项达到渐近最优水平，从而显著改善了算法的性能。

> **ai_Abstract:** 本文研究了马尔可夫噪声下带有Polyak-Ruppert平均的线性随机逼近（LSA）算法的偏差和高阶误差界。研究发现，LSA算法在常数步长下，其主要偏差项是线性的且无法通过PR平均消除。为解决此问题，论文提出了一种新颖的偏差分解方法，并引入Richardson-Romberg（RR）外推法。实验结果表明，RR外推法能有效消除主要偏差项，且其高阶矩界显示领先误差项与渐近最优协方差矩阵一致。

> **摘要翻译:** 在本文中，我们研究了马尔可夫噪声下带有Polyak-Ruppert (PR) 平均的线性随机逼近 (LSA) 算法的偏差和高阶误差界。我们关注该算法的常数步长 $\alpha$ 版本，并通过线性化技术提出了一种新颖的偏差分解方法。我们分析了偏差的结构，并表明其主导项是关于 $\alpha$ 的线性项，且无法通过 PR 平均消除。为了解决这个问题，我们应用了 Richardson-Romberg (RR) 外推程序，该程序有效地消除了主导偏差项。我们推导了 RR 迭代的高阶矩界，并表明主导误差项与普通平均 LSA 迭代的渐近最优协方差矩阵对齐。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [604] [Guided Random Forest and its application to data approximation](https://arxiv.org/abs/1909.00659)
> *引导随机森林及其在数据近似中的应用*

*Prashant Gupta, Aashi Jindal, Jayadeva, Debarka Sengupta* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 引导随机森林, 集成分类器, 全局划分, 数据近似, 泛化误差

**Comment:** 

> **TL;DR:** 本文提出了一种名为引导随机森林（GRAF）的新型集成分类器，它通过全局划分改进了斜决策树，并在多数基准数据集上取得了与现有方法相当或更好的性能，同时还提供了一种在随机森林框架下近似数据的新方法。

**AI_Comments:** GRAF的创新之处在于提出了全局划分的概念，并证明其能弥合决策树与Boosting算法的差距，并降低泛化误差。其在大量基准数据集上的实证表现证明了方法的有效性。此外，将数据近似引入随机森林框架也增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了构建一种新的集成分类器，并解决决策树与Boosting算法之间的差距，同时降低泛化误差界限。

**Method:** 本文提出了一种名为引导随机森林（GRAF）的新型集成分类器。GRAF通过局部划分构建倾斜决策树，并将其扩展为全局划分。研究表明全局划分弥合了决策树和Boosting算法之间的鸿沟，并能降低泛化误差界限。此外，还提出了一种在随机森林框架下近似数据集的新方法。

**Result:** 在115个基准数据集上的实验结果表明，GRAF在大多数数据集上取得了与现有方法相当或更好的结果。

**Conclusion:** 引导随机森林（GRAF）是一种有效的集成分类器，它通过全局划分改进了决策树，并能有效降低泛化误差，在实际应用中表现出良好的性能。

> **ai_Abstract:** 本文介绍了一种新型集成分类器——引导随机森林（GRAF）。GRAF通过扩展斜决策树的局部划分思想，实现了全局划分，从而弥合了决策树和Boosting算法之间的差距，并被证明能降低泛化误差。在115个基准数据集上的实验结果表明，GRAF在多数数据集上表现出与现有方法相当或更优的性能。此外，该研究还提出了一种在随机森林框架下进行数据近似的新方法。

> **摘要翻译:** 我们提出了一种构建集成分类器的新方法，在下文中称之为引导随机森林（GRAF）。GRAF扩展了通过局部划分构建倾斜决策树以获得全局划分的思想。我们表明全局划分弥合了决策树和Boosting算法之间的鸿沟。我们通过实证证明全局划分降低了泛化误差界限。在115个基准数据集上的结果显示，GRAF在大多数数据集上取得了相当或更好的结果。我们还提出了一种在随机森林框架下近似数据集的新方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [610] [Optimal Stochastic Non-smooth Non-convex Optimization through Online-to-Non-convex Conversion](https://arxiv.org/abs/2302.03775)
> *通过在线到非凸转换的最优随机非光滑非凸优化*

*Ashok Cutkosky, Harsh Mehta, Francesco Orabona* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 随机优化, 非凸优化, 非光滑优化, 在线学习, 复杂度界限

**Comment:** 

> **TL;DR:** 该论文提出了一种通过在线学习转换来优化非光滑、非凸随机目标的新算法，显著提高了找到平稳点的复杂度。

**AI_Comments:** 本文的创新之处在于其“在线到非凸转换”技术，它通过利用成熟的在线学习理论，简化了复杂的非光滑非凸优化问题。这种方法带来了可证明的最优复杂度改进，为设计优化算法提供了一个强大的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过提出新算法和分析技术，改进当前非光滑、非凸随机优化中寻找 $(\delta,\epsilon)$-平稳点的最佳已知复杂度。

**Method:** 本文的核心技术是将非光滑非凸优化问题归约为在线学习问题。研究结果来源于在线学习中的标准遗憾界。对于确定性和二阶光滑目标，则应用更先进的乐观在线学习技术。

**Result:** 新算法将寻找 $(\delta,\epsilon)$-平稳点的随机梯度查询复杂度从 $O(\epsilon^{-4}\delta^{-1})$ 改进到 $O(\epsilon^{-3}\delta^{-1})$，并证明其是最优的。对于确定性和二阶光滑目标，通过应用更先进的乐观在线学习技术，实现了 $O(\epsilon^{-1.5}\delta^{-0.5})$ 的新复杂度。此外，该技术还恢复了在随机和确定性设置下，寻找光滑或二阶光滑目标 $\epsilon$-平稳点的所有最优或最佳已知结果。

**Conclusion:** 本文通过将非光滑非凸优化问题转化为在线学习，提出了新的算法，显著提高了随机优化中寻找平稳点的复杂度，并达到了最优或最佳已知的结果。

> **ai_Abstract:** 本文介绍了一种通过将非光滑、非凸随机优化问题归约为在线学习来设计新算法的方法。该方法将寻找 $(\delta,\epsilon)$-平稳点的复杂度从 $O(\epsilon^{-4}\delta^{-1})$ 优化至 $O(\epsilon^{-3}\delta^{-1})$，并证明其为最优。对于确定性和二阶光滑目标，通过采用乐观在线学习技术，复杂度进一步降低至 $O(\epsilon^{-1.5}\delta^{-0.5})$。此技术还能够恢复现有光滑目标最优或最佳已知结果。

> **摘要翻译:** 我们提出了基于一种新颖分析技术的优化非光滑、非凸随机目标的新算法。这将寻找 $(\delta,\epsilon)$-平稳点的当前最佳已知复杂度从 $O(\epsilon^{-4}\delta^{-1})$ 的随机梯度查询改进到 $O(\epsilon^{-3}\delta^{-1})$，我们还证明这是最优的。我们的主要技术是将非光滑非凸优化归约为在线学习，之后我们的结果遵循在线学习中的标准遗憾界。对于确定性和二阶光滑目标，应用更先进的乐观在线学习技术可以实现 $O(\epsilon^{-1.5}\delta^{-0.5})$ 的新复杂度。我们的技术还恢复了在随机和确定性设置下，寻找光滑或二阶光滑目标 $\epsilon$-平稳点的所有最优或最佳已知结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [616] [Eliciting Latent Predictions from Transformers with the Tuned Lens](https://arxiv.org/abs/2303.08112)
> *从Tuned Lens中提取Transformer的潜在预测*

*Nora Belrose, Igor Ostrovsky, Lev McKinney, Zach Furman, Logan Smith, Danny Halawi, Stella Biderman, Jacob Steinhardt* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** Transformers, 潜在预测, Tuned Lens, Logit Lens, 模型可解释性

**Comment:** 

> **TL;DR:** 研究人员开发了一种名为“Tuned Lens”的新方法，通过训练仿射探针来理解大型语言模型中逐层预测的细化过程，该方法比现有技术更可靠、更准确，并且可用于检测恶意输入。

**AI_Comments:** 本文创新性地提出了“Tuned Lens”方法，通过训练仿射探针来深入分析Transformer模型内部的预测细化过程，解决了“Logit Lens”的脆弱性问题，提高了分析的可靠性和准确性。其重要性在于不仅提供了更强大的工具来理解大型语言模型的“黑箱”机制，还展示了实际应用潜力，例如利用潜在预测轨迹进行恶意输入检测，这对于模型安全性和可解释性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解Transformer模型如何逐层细化预测，并改进现有“logit lens”技术的脆弱性。

**Method:** 本文提出了一种名为“tuned lens”的方法。该方法通过为冻结的预训练模型中的每个块训练一个仿射探针，从而可以将每个隐藏状态解码为词汇表上的分布。它是早期“logit lens”技术的改进。

**Result:** Tuned lens 在预测性、可靠性和无偏性方面优于 logit lens。Tuned lens 使用与模型本身相似的特征。潜在预测的轨迹可以高精度地用于检测恶意输入。

**Conclusion:** Tuned Lens是一种有效且鲁棒的工具，能够深入理解Transformer的内部工作机制，并具有实际应用价值，例如检测恶意输入。

> **ai_Abstract:** 本文提出了一种名为“Tuned Lens”的新方法，旨在理解大型Transformer模型如何逐层细化其预测。该方法通过为预训练模型的每个块训练一个仿射探针，将隐藏状态解码为词汇表分布，从而改进了先前脆弱的“logit lens”技术。实验证明，Tuned Lens在预测性、可靠性和无偏性方面优于Logit Lens，并且其使用的特征与模型本身相似。此外，研究发现潜在预测的轨迹能够高精度地检测恶意输入。

> **摘要翻译:** 我们从迭代推理的角度分析Transformer，旨在理解模型预测是如何逐层细化的。为此，我们为冻结的预训练模型中的每个块训练一个仿射探针，从而可以将每个隐藏状态解码为词汇表上的分布。我们的方法，即“tuned lens”，是对早期“logit lens”技术的改进，后者虽然提供了有用的见解，但通常很脆弱。我们在各种参数多达200亿的自回归语言模型上测试了我们的方法，结果表明它比logit lens更具预测性、更可靠、更无偏。通过因果实验，我们表明tuned lens使用了与模型本身相似的特征。我们还发现潜在预测的轨迹可以高精度地用于检测恶意输入。重现我们结果所需的所有代码都可以在https://github.com/AlignmentResearch/tuned-lens找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [622] [Explainable Clustering Beyond Worst-Case Guarantees](https://arxiv.org/abs/2411.01576)
> *可解释聚类：超越最坏情况保证*

*Maximilian Fleissner, Maedeh Zarvandi, Debarghya Ghoshdastidar* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 可解释聚类, 决策树, 混合模型, 核聚类, 最坏情况保证

**Comment:** 

> **TL;DR:** 本文研究可解释聚类问题，证明对于聚类良好的数据可以获得更紧密的保证，并通过混合模型和核聚类扩展了分析，显著改进了现有最坏情况界限。

**AI_Comments:** 这篇论文通过将可解释聚类问题置于统计模型（特别是混合模型）的背景下，超越了传统的最坏情况分析，具有重要的创新性。它解决了实际应用中数据通常并非最坏情况的限制，为可解释聚类在“聚类良好”数据上的应用提供了更乐观的理论依据。对于核聚类的扩展分析也增加了其理论贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有关于可解释聚类的研究主要关注最坏情况下的“可解释性代价”保证，但对于数据无关的观点，仍未解决两个重要问题：对于聚类良好的数据是否可能获得更紧密的保证？以及决策树是否能恢复潜在的聚类结构？

**Method:** 作者将研究置于混合模型的统计环境中，设计了一种算法，该算法以混合模型为输入并在数据无关的时间内构建决策树。他们还将分析扩展到核聚类。

**Result:** 证明了对于聚类良好的数据确实可以获得更好的保证。对于核聚类，推导出了显著优于现有最坏情况界限的新保证。

**Conclusion:** 本文证明了在统计混合模型设置下，可解释聚类对于聚类良好的数据可以实现更紧密的性能保证，并且在核聚类方面也取得了显著改进，从而超越了传统的最坏情况分析。

> **ai_Abstract:** 本文探讨了可解释聚类问题，该问题旨在通过轴对齐决策树实现最小聚类成本。针对现有研究主要关注数据无关的最坏情况保证，本文在混合模型的统计设置下，证明了对于聚类良好的数据可以获得更紧密的性能保证。此外，研究还扩展到核聚类，并推导出了显著优于现有最坏情况界限的新保证，从而回答了决策树能否有效恢复聚类结构的问题。

> **摘要翻译:** 我们研究了Moshkovitz、Dasgupta、Rashtchian和Frost（ICML 2020）首次提出的可解释聚类问题。可解释聚类的目标是拟合一个具有K个叶子和最小聚类成本的轴对齐决策树（其中每个叶子都是一个聚类）。这项工作的基本理论问题是“可解释性代价”，定义为树的聚类成本与最优成本之比。大量论文对这个量提供了最坏情况保证。对于K-中位数，最近表明最坏情况下的可解释性代价是$\Theta(\log K)$。虽然这从数据无关的角度解决了问题，但仍有两个重要问题悬而未决：对于聚类良好的数据是否可能获得更紧密的保证？以及我们能否相信决策树能恢复潜在的聚类结构？在本文中，我们将自己置于混合模型的统计环境中来回答这两个问题。我们证明对于聚类良好的数据确实可以实现更好的保证。我们的算法以混合模型为输入，并在数据无关的时间内构建一棵树。然后，我们将分析扩展到核聚类，推导出了显著优于现有最坏情况界限的新保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [628] [Contrastive Representation Modeling for Anomaly Detection](https://arxiv.org/abs/2501.05130)
> *对比表示建模用于异常检测*

*Willian T. Lunardi, Abdulrahman Banabila, Dania Herzalla, Martin Andreoni* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 对比学习, 异常检测, 表示学习, 结构化对比, 无监督学习

**Comment:** 

> **TL;DR:** 提出了一种新的结构化对比学习方法，用于异常检测，通过重新定义正负关系，实现内部分类紧凑、内外部强分离以及保留异常多样性，无需显式异常标签，在多种基准上表现优异。

**AI_Comments:** 这篇论文的创新点在于提出了一个结构化对比目标，解决了传统对比学习在异常检测中无法有效平衡内部分类紧凑性和异常多样性的问题。其无需显式异常标签的特性极具实用价值，尤其是在异常数据稀缺的场景下。引入的补丁级学习策略也增强了其在工业局部异常检测中的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的对比学习策略在异常检测中难以平衡内部分类紧凑性和异常分离度，要么导致内部方差过大，要么未能保留异常的多样性。

**Method:** 提出了一个结构化对比目标，在训练过程中重新定义正负关系，以促进内部分类紧凑、内外部强分离和保留合成异常多样性，且无需显式异常标签。此外，还扩展了一个基于补丁的学习和评估策略，用于提高工业环境中局部异常的检测。

**Result:** 该方法与标准对比方法相比，收敛速度显著加快，性能有所提高。在语义和工业基准上，其性能与依赖判别训练或显式异常标签的异常检测方法相当或超越。

**Conclusion:** 该论文提出了一种有效的结构化对比学习方法，解决了传统对比学习在异常检测中的局限性，实现了优异的性能，且无需异常标签，显示了其在多种场景下的普适性和优越性。

> **ai_Abstract:** 本文针对现有对比学习在异常检测中存在的表示学习挑战，提出了一种新的结构化对比目标。该目标通过重新定义训练中的正负关系，旨在实现内部样本的紧凑聚类、内部与异常的强分离以及保留合成异常的多样性，且无需异常标签。此外，该框架还引入了基于补丁的学习策略以增强局部异常检测。实验结果表明，该方法收敛更快，性能优于标准对比方法，并在多个基准上达到或超越了其他主流异常检测方法。

> **摘要翻译:** 基于距离的异常检测方法依赖于紧凑的内部（ID）嵌入，这些嵌入与异常良好分离。然而，传统的对比学习策略往往难以实现这种平衡，要么促进内部样本之间过度方差，要么未能保留异常的多样性。我们首先分析了异常检测中表示学习的挑战，并确定了预设任务的三个基本属性：(1) 内部样本的紧凑聚类，(2) 内部样本与异常之间的强分离，以及 (3) 合成异常多样性的保留。在此基础上，我们提出了一种结构化对比目标，该目标在训练期间重新定义了正负关系，从而在不需要显式异常标签的情况下促进了这些属性。我们通过一种专门设计用于改善工业环境中局部异常检测的基于补丁的学习和评估策略扩展了该框架。与标准对比方法相比，我们的方法展示了显著更快的收敛速度和改进的性能。它在语义和工业基准上与异常检测方法相当或超越，包括那些依赖判别训练或显式异常标签的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [634] [Can Transformers Learn Full Bayesian Inference in Context?](https://arxiv.org/abs/2501.16825)
> *变压器能否在上下文中学习完整的贝叶斯推断？*

*Arik Reuter, Tim G. J. Rudner, Vincent Fortuin, David Rügamer* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** Transformer, 上下文学习, 贝叶斯推断, 后验分布, 概率模型

**Comment:** 

> **TL;DR:** 本文展示了Transformer可以通过引入一个结合先验拟合网络和连续归一化流的通用框架，在上下文中执行完整的贝叶斯推断，其后验样本质量与现有先进方法相当。

**AI_Comments:** 这篇论文的创新点在于将Transformer的上下文学习能力扩展到完整的贝叶斯推断，这对于理解ICL机制及其在复杂概率建模中的应用具有重要意义。通过结合先验拟合网络和连续归一化流，该方法提供了一种新颖的途径来在不进行额外训练的情况下推断后验分布，这在效率和适用性方面具有潜在优势。其结果表明ICL方法可以与传统SOTA方法匹敌，这进一步证明了Transformer的强大和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 进一步推进对上下文学习（ICL）的理解，并证明Transformer可以在上下文中对常用统计模型执行完整的贝叶斯推断。

**Method:** 引入了一个通用框架，该框架基于先验拟合网络和连续归一化流的思想，能够推断广义线性模型和潜在因子模型等复杂模型的后验分布。

**Result:** 在真实世界数据集上的广泛实验表明，所提出的ICL方法产生的后验样本质量与不进行上下文操作的最先进MCMC或变分推断方法相似。

**Conclusion:** Transformer能够通过上下文学习（ICL）执行完整的贝叶斯推断，其表现与传统的最先进方法相当。

> **ai_Abstract:** 本文探讨了Transformer在上下文学习（ICL）方面的能力，并首次证明Transformer能够对广义线性模型和潜在因子模型等常用统计模型进行完整的贝叶斯推断。研究引入了一个结合先验拟合网络和连续归一化流的通用框架，以实现复杂后验分布的推断。实验结果表明，该ICL方法产生的后验样本质量与最先进的MCMC或变分推断方法相当，凸显了Transformer在贝叶斯推断任务中的潜力。

> **摘要翻译:** Transformer已成为深度学习领域的主导架构，具有广泛的应用和卓越的上下文学习（ICL）能力。虽然ICL尚未完全理解，但它已被证明是一种引人入胜的现象，允许Transformer在上下文中学习——无需进一步训练。在本文中，我们通过证明Transformer可以在上下文中对常用统计模型执行完整的贝叶斯推断，从而进一步推进了对ICL的理解。更具体地说，我们引入了一个通用框架，该框架建立在先验拟合网络和连续归一化流的思想之上，使我们能够推断广义线性模型和潜在因子模型等复杂模型的后验分布。在真实世界数据集上的广泛实验表明，我们的ICL方法产生的后验样本质量与不进行上下文操作的最先进MCMC或变分推断方法相似。本文的源代码可在https://github.com/ArikReuter/ICL_for_Full_Bayesian_Inference 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [640] [Quaternion-Hadamard Network: A Novel Defense Against Adversarial Attacks with a New Dataset](https://arxiv.org/abs/2502.10452)
> *四元数-哈达玛网络：一种针对对抗性攻击的新型防御方法及新数据集*

*Vladimir Frants, Sos Agaian* | **Category: cs.LG, eess.IV** | **Updated: 2025-08-06**

**Keywords:** 对抗性攻击防御, 四元数-哈达玛网络, 图像去噪, 鲁棒性, 新数据集

**Comment:** 

> **TL;DR:** 本文提出了一种名为四元数-哈达玛网络（QHNet）的模型无关防御方法，以对抗针对恶劣天气图像处理模型的白盒对抗性攻击，并引入了一个新的对抗性天气条件视觉数据集（AWCVD）。

**AI_Comments:** 该论文的创新点在于提出了四元数-哈达玛网络（QHNet）及其独特的四元数哈达玛去噪卷积块（QHDCB）和四元数去噪残差块（QDRB），以模型无关的方式有效防御白盒对抗性攻击，这对于保护恶劣天气图像处理模型具有重要意义。此外，引入新的对抗性天气条件视觉数据集（AWCVD）也为该领域的研究提供了宝贵的资源。其模型无关的特性降低了部署成本，具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型在去雨、去雪和去雾方面表现出色，但易受对抗性攻击，从而影响其有效性。传统的防御方法（如对抗训练和模型蒸馏）成本高昂且不切实际。去噪和超分辨率技术虽然对图像分类模型有帮助，但计算成本高且引入视觉伪影，阻碍了图像处理任务。

**Method:** 本文提出了一种模型无关的防御方法，即四元数-哈达玛网络（QHNet），用于对抗一阶白盒对抗性攻击。QHNet引入了四元数哈达玛去噪卷积块（QHDCB）和四元数去噪残差块（QDRB），利用多项式阈值处理。QHNet将这些模块整合到编码器-解码器架构中，并通过特征细化来有效消除对抗性噪声。此外，还创建了一个新的对抗性天气条件视觉数据集（AWCVD），通过对最先进的天气去除技术应用一阶梯度攻击在雾、雨痕和雪场景中生成。

**Result:** 使用PSNR和SSIM指标，本文证明QHNet与最先进的去噪和超分辨率技术相比，显著增强了低级计算机视觉模型对抗对抗性攻击的鲁棒性。

**Conclusion:** 四元数-哈达玛网络（QHNet）及其提出的模块（QHDCB和QDRB）能够有效防御针对恶劣天气图像处理模型的白盒对抗性攻击，显著提升模型鲁棒性，并且新数据集AWCVD为相关研究提供了资源。

> **ai_Abstract:** 本文针对深度学习模型在恶劣天气图像处理中易受对抗性攻击的问题，提出了一种新型模型无关防御方法——四元数-哈达玛网络（QHNet）。QHNet通过引入四元数哈达玛去噪卷积块（QHDCB）和四元数去噪残差块（QDRB），并结合编码器-解码器架构和特征细化来有效消除对抗性噪声。为支持研究，论文还构建了对抗性天气条件视觉数据集（AWCVD）。实验结果表明，QHNet在对抗白盒攻击方面显著提升了低级计算机视觉模型的鲁棒性，优于现有去噪和超分辨率技术。

> **摘要翻译:** 本文探讨了针对去雨、去雪和去雾深度学习模型的脆弱性。尽管这些模型能提升恶劣天气下的图像质量，但它们易受对抗性攻击，从而损害其有效性。传统的防御方法，如对抗训练和模型蒸态，通常需要大量的再训练，这使得它们成本高昂且不适用于实际部署。虽然去噪和超分辨率技术可以辅助图像分类模型，但它们带来了高计算需求并引入视觉伪影，阻碍了图像处理任务。为了解决这些挑战，我们提出了一种模型无关的防御方法，使用四元数-哈达玛网络（QHNet）来对抗一阶白盒对抗性攻击。白盒攻击尤其难以防御，因为攻击者可以完全访问模型的架构、权重和训练过程。我们的防御方法引入了四元数哈达玛去噪卷积块（QHDCB）和四元数去噪残差块（QDRB），利用多项式阈值处理。QHNet将这些块整合到编码器-解码器架构中，并通过特征细化来有效中和对抗性噪声。此外，我们引入了对抗性天气条件视觉数据集（AWCVD），该数据集是通过在雾、雨痕和雪场景中对最先进的天气去除技术应用一阶梯度攻击而创建的。使用PSNR和SSIM指标，我们证明了QHNet与最先进的去噪和超分辨率技术相比，显著增强了低级计算机视觉模型对抗对抗性攻击的鲁棒性。源代码和数据集将随本论文的最终版本一同发布。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [646] [LLM-TabLogic: Preserving Inter-Column Logical Relationships in Synthetic Tabular Data via Prompt-Guided Latent Diffusion](https://arxiv.org/abs/2503.02161)
> *LLM-TabLogic：通过提示引导的潜在扩散在合成表格数据中保留列间逻辑关系*

*Yunbo Long, Liming Xu, Alexandra Brintrup* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 合成表格数据, 列间逻辑关系, 大型语言模型, 扩散模型, 数据生成

**Comment:** 

> **TL;DR:** LLM-TabLogic是一种新方法，它利用大型语言模型推理和扩散模型来生成合成表格数据，同时有效保留复杂的列间逻辑关系，解决了现有方法可靠性差的问题，并在实验中表现出色。

**AI_Comments:** 本文的创新点在于首次将大型语言模型（LLM）的推理能力与扩散模型相结合，用于生成能够保持复杂列间逻辑关系的合成表格数据。其重要性在于解决了现有合成数据生成方法在实际应用中可靠性不足的问题，尤其是在需要高逻辑一致性的领域。此外，该方法无需领域知识，大大降低了应用门槛，为数据隐私保护和数据稀缺问题提供了更可靠的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 合成表格数据在保护隐私和解决数据稀缺方面日益重要，但现有生成模型常忽视列间逻辑关系，导致合成数据在实际应用中不可靠，尤其是在供应链等复杂系统中，字段间的逻辑一致性至关重要。

**Method:** 我们提出了LLM-TabLogic，一种新颖的方法。它利用大型语言模型（LLM）推理来捕获和压缩表格列之间复杂的逻辑关系，并将这些条件约束传递给一个基于分数的扩散模型，用于在潜在空间中生成数据。

**Result:** LLM-TabLogic在逻辑推理方面表现出强大的泛化能力，在未见过的表格上实现了超过90%的准确率。此外，我们的方法在数据生成方面优于所有基线，它完全保留了列间关系，同时在数据保真度、实用性和隐私之间保持了最佳平衡。

**Conclusion:** 本研究提出了第一个无需领域知识即可有效保留合成表格数据中列间关系的方法，为创建逻辑一致的真实世界表格数据提供了新见解。

> **ai_Abstract:** LLM-TabLogic是一种新颖的合成表格数据生成方法，旨在解决现有模型在保留列间逻辑关系方面的不足。它利用大型语言模型（LLM）的推理能力来捕捉和压缩复杂的列间逻辑约束，并将这些约束输入到基于分数的扩散模型中进行数据生成。通过在真实工业数据集上的广泛实验，LLM-TabLogic在逻辑推理方面展现出超过90%的准确率，并在数据生成方面超越了现有基线，成功保留了列间关系，同时优化了数据保真度、实用性和隐私的平衡。该研究首次提出无需领域知识即可有效维护合成表格数据中列间关系的方法，为生成逻辑一致的真实世界数据提供了重要见解。

> **摘要翻译:** 合成表格数据正越来越多地用于替代真实数据，作为一种同时保护隐私和解决数据稀缺的有效解决方案。然而，除了保留全局统计特性外，合成数据集还必须保持特定领域的逻辑一致性——尤其是在供应链等复杂系统中，其中发货日期、地点和产品类别等字段必须保持逻辑一致性以实现实际可用性。现有生成模型通常会忽略这些列间关系，导致实际应用中合成表格数据不可靠。为了解决这些挑战，我们提出了LLM-TabLogic，一种新颖的方法，它利用大型语言模型推理来捕获和压缩表格列之间复杂的逻辑关系，同时将这些条件约束传递给一个基于分数的扩散模型，用于在潜在空间中生成数据。通过在真实世界工业数据集上进行的大量实验，我们评估了LLM-TabLogic在列推理和数据生成方面的性能，并将其与包括SMOTE和最先进生成模型在内的五个基线进行了比较。我们的结果表明，LLM-TabLogic在逻辑推理方面表现出强大的泛化能力，在未见过的表格上实现了超过90%的准确率。此外，我们的方法在数据生成方面优于所有基线，它完全保留了列间关系，同时在数据保真度、实用性和隐私之间保持了最佳平衡。这项研究提出了第一个无需领域知识即可有效保留合成表格数据中列间关系的方法，为创建逻辑一致的真实世界表格数据提供了新见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [652] [Task Vector Quantization for Memory-Efficient Model Merging](https://arxiv.org/abs/2503.06921)
> *任务向量量化以实现内存高效的模型合并*

*Youngeun Kim, Seunghwan Lee, Aecheon Jung, Bogon Ryu, Sungeun Hong* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 任务向量量化, 模型合并, 内存效率, 低精度量化, 残差量化

**Comment:** 

> **TL;DR:** 提出任务向量量化（包括残差任务向量量化）来减少模型合并中存储多个微调检查点所需的内存，同时保持或提高性能。

**AI_Comments:** 该论文的创新点在于提出量化任务向量而非整个模型检查点，并引入残差任务向量量化以应对超低位量化挑战。这种方法显著降低了模型合并的内存需求，对于在资源受限环境下部署大型多任务模型具有重要意义，极大地提高了模型合并的可扩展性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 模型合并需要存储多个任务特定的微调检查点，这需要大量内存，限制了可扩展性，并阻碍了模型合并在更大模型和多样化任务上的应用。

**Method:** 提出量化任务向量（预训练和微调检查点之间的差异）而不是量化整个微调检查点。观察到任务向量具有狭窄的权重范围，支持低精度量化（如4位）。为解决超低位精度（如2位）下的量化误差，引入残差任务向量量化，将任务向量分解为基向量和偏移分量，并根据量化敏感度分配比特。

**Result:** 在图像分类和密集预测任务上的实验表明，该方法在仅使用全精度检查点所需内存的8%的情况下，保持或提高了模型合并的性能。

**Conclusion:** 通过任务向量量化（包括残差任务向量量化），可以显著降低模型合并的内存需求，同时不牺牲甚至提升性能，从而提高多任务模型的效率和可扩展性。

> **ai_Abstract:** 该论文提出了一种名为任务向量量化的新方法，旨在解决模型合并中存储多个微调检查点所导致的内存消耗问题。通过量化预训练和微调检查点之间的差异（即任务向量），可以利用其狭窄的权重范围实现低精度量化。为进一步提高超低位精度下的性能，引入了残差任务向量量化，通过分解任务向量和敏感度比特分配来减少误差。实验证明，该方法在显著减少内存占用的同时，保持或提升了模型合并的性能。

> **摘要翻译:** 模型合并通过结合特定任务的微调检查点来实现高效的多任务模型。然而，存储多个特定任务的检查点需要大量内存，这限制了可扩展性，并将模型合并限制在更大的模型和多样化的任务上。在本文中，我们提出量化任务向量（即预训练和微调检查点之间的差异），而不是量化微调检查点。我们观察到任务向量表现出狭窄的权重范围，这使得在现有任务向量合并框架内可以进行低精度量化（例如4位）。为了进一步缓解超低位精度（例如2位）内的量化误差，我们引入了残差任务向量量化，它将任务向量分解为基向量和偏移分量。我们根据量化敏感度分配比特，在内存预算内确保精度同时最小化误差。在图像分类和密集预测上的实验表明，我们的方法在仅使用全精度检查点所需内存的8%的情况下，保持或提高了模型合并性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [658] [Energy Optimized Piecewise Polynomial Approximation Utilizing Modern Machine Learning Optimizers](https://arxiv.org/abs/2503.09329)
> *能量优化分段多项式逼近利用现代机器学习优化器*

*Hannes Waclawek, Stefan Huber* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 分段多项式逼近, 能量优化, 机器学习优化器, 梯度下降, 凸轮轮廓

**Comment:** 

> **TL;DR:** 本文将能量优化作为额外目标，扩展了机器学习优化的分段多项式逼近，并使用TensorFlow中的现代梯度下降优化器构建了一个框架，以最小化凸轮轮廓中的弹性应变能，从而实现更平滑的运动，实验结果证实了该方法在权衡逼近质量与能耗方面的有效性。

**AI_Comments:** 这篇论文的创新点在于将能量优化引入机器学习优化的分段多项式逼近中，解决了传统方法在处理复杂优化目标时的不足。利用现代机器学习优化器进行能量最小化，为机械设计（如凸轮轮廓）提供了新的优化思路，有望实现更高效、更平稳的系统。其帕累托效率权衡的发现也具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统闭式解在实现连续性和逼近目标时缺乏灵活性，无法适应复杂的优化目标，例如能量优化。

**Method:** 本文通过将能量优化作为额外目标，扩展了机器学习优化的分段多项式逼近方法。具体地，利用TensorFlow中的现代梯度下降优化器，引入了一个框架来最小化凸轮轮廓中的弹性应变能。

**Result:** 实验结果证实了该方法的有效性，并展示了其在逼近质量和能耗之间进行帕累托效率权衡的潜力。

**Conclusion:** 该方法能够有效地在逼近质量和能量消耗之间进行权衡，为实现更平滑的运动提供了新的途径。

> **ai_Abstract:** 本文提出了一种将能量优化融入机器学习优化的分段多项式逼近的新框架。针对传统方法在复杂优化目标上的局限性，该方法利用TensorFlow中的现代梯度下降优化器，最小化凸轮轮廓的弹性应变能，旨在实现更平滑的运动。实验证明，该方法能有效权衡逼近质量与能量消耗。

> **摘要翻译:** 这项工作通过将能量优化作为额外目标，探索了机器学习优化分段多项式逼近的扩展。传统的闭式解能够实现连续性和逼近目标，但在适应复杂优化目标方面缺乏灵活性。通过利用TensorFlow中的现代梯度下降优化器，我们引入了一个框架，该框架可以最小化凸轮轮廓中的弹性应变能，从而实现更平滑的运动。实验结果证实了这种方法的有效性，展示了其在逼近质量和能耗之间进行帕累托效率权衡的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [664] [Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian Neural Networks](https://arxiv.org/abs/2504.10076)
> *通过梯度信息贝叶斯神经网络实现可扩展贝叶斯优化*

*Georgios Makrygiorgos, Joshua Hang Sai Ip, Ali Mesbah* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-06**

**Keywords:** 贝叶斯优化, 贝叶斯神经网络, 梯度信息, 代理模型, 自动微分

**Comment:** 

> **TL;DR:** 本文提出了一种将梯度信息集成到贝叶斯神经网络（BNN）中用于贝叶斯优化（BO）的方法，以提高预测准确性和加速收敛，尤其是在高维问题中。

**AI_Comments:** 本文的创新点在于首次探索了将梯度信息融入贝叶斯神经网络作为贝叶斯优化代理模型的方法。通过引入梯度信息损失函数，它有效地解决了传统贝叶斯优化在可扩展性（高斯过程的限制）和信息利用（BNN未利用梯度）方面的挑战。这项工作对于推动可扩展、高效的贝叶斯优化在高维空间的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 贝叶斯优化（BO）通常使用高斯过程（GP）作为代理模型，但其可扩展性有限。贝叶斯神经网络（BNN）是可扩展的替代方案，但尚未探索如何在其中使用梯度信息。将梯度信息融入BO已被证明能提高性能，因此本文旨在探索如何将梯度信息应用于BNN代理模型。

**Method:** 本文提出了一种梯度信息损失函数，用于贝叶斯神经网络（BNN）的训练。该方法通过利用自动微分技术，将局部梯度信息与函数观测值相结合，从而为BO构建更具信息量的代理模型。

**Result:** 在已知基准测试中，该方法展示了改进的贝叶斯神经网络（BNN）预测能力，并随着决策变量数量的增加，实现了更快的贝叶斯优化（BO）收敛速度。

**Conclusion:** 通过将梯度信息整合到贝叶斯神经网络中，可以显著提高贝叶斯优化的性能，尤其是在处理高维问题时，这为可扩展的贝叶斯优化提供了新的途径。

> **ai_Abstract:** 本文提出了一种通过整合梯度信息来增强贝叶斯神经网络（BNN）以改进贝叶斯优化（BO）的方法。针对传统BO代理模型（如高斯过程和未利用梯度的BNN）的局限性，作者设计了一种新的梯度信息损失函数，利用自动微分技术将局部梯度数据融入BNN训练中。实验结果表明，该方法能够提高BNN的预测准确性，并在高维问题中加速BO的收敛。

> **摘要翻译:** 贝叶斯优化（BO）是一种广泛使用的数据驱动优化方法，通常依赖于目标函数的零阶数据来构建概率代理模型。这些代理模型指导探索-利用过程，以寻找全局最优。虽然高斯过程（GP）通常被用作未知目标函数的代理模型，但最近的研究强调了贝叶斯神经网络（BNN）作为可扩展且灵活的替代方案的潜力。此外，当可用时，将梯度观测值纳入高斯过程已被证明可以提高BO性能。然而，在BNN代理模型中使用梯度信息仍未被探索。通过利用自动微分，梯度信息可以无缝集成到BNN训练中，从而为BO生成更具信息量的代理模型。我们提出了一种用于BNN训练的梯度信息损失函数，有效地将函数观测值与局部梯度信息相结合。这种方法在已知基准测试中得到了验证，体现在改进的BNN预测和随着决策变量数量增加而加快的BO收敛速度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [670] [How Effective are Large Time Series Models in Hydrology? A Study on Water Level Forecasting in Everglades](https://arxiv.org/abs/2505.01415)
> *大型时间序列模型在水文学中有多有效？以大沼泽地水位预测为例的研究*

*Rahuul Rangaraj, Jimeng Shi, Azam Shirali, Rajendra Paudel, Yanzhao Wu, Giri Narasimhan* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 大型时间序列模型, 水文学, 水位预测, 大沼泽地, 基础模型

**Comment:** 

> **TL;DR:** 本研究评估了大型时间序列模型在大沼泽地水位预测中的有效性。结果显示，基础模型Chronos显著优于所有其他模型，而其他基础模型表现相对较差，任务特定模型的表现则因架构而异。

**AI_Comments:** 这篇论文很重要，因为它探讨了先进的大型时间序列模型，特别是基础模型，在一个关键环境领域（水文学/大沼泽地）的适用性，而这些模型在此领域的有效性此前并未得到充分探索。研究发现一个基础模型（Chronos）表现异常出色，而其他模型表现不佳，这提供了有价值且细致的见解，强调了需要仔细选择和进一步研究，而不是盲目采纳。任务特定模型表现的差异性也增加了研究发现的复杂性和丰富性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的水位预测方法（基于物理和统计的方法）计算成本高昂且适应性有限。尽管大型时间序列模型在时间序列预测方面取得了显著进展，但它们在像大沼泽地这样的关键环境系统中的应用仍未得到充分探索。

**Method:** 本研究通过调查十二种任务特定模型和五种时间序列基础模型（涵盖六个类别），针对大沼泽地的水位预测这一实际应用进行了研究。

**Result:** 主要结果显示，基础模型Chronos显著优于所有其他模型，而其余基础模型表现相对较差。研究还发现，任务特定模型的性能随模型架构的不同而变化。

**Conclusion:** 本研究希望其发现能激励社区探索大型时间序列模型在水文应用中的适用性。

> **ai_Abstract:** 本研究旨在评估大型时间序列模型在水文学中，特别是大沼泽地水位预测中的有效性，以解决传统方法的局限性。研究调查了十二种任务特定模型和五种时间序列基础模型，结果表明基础模型Chronos表现最佳，显著优于所有其他模型；而其他基础模型的表现则相对较差。此外，任务特定模型的性能也因其架构而异。本研究旨在鼓励水文学领域对大型时间序列模型进行更深入的探索和应用。

> **摘要翻译:** 大沼泽地在周边地区的洪水和干旱调节、水资源规划和生态系统管理中发挥着关键作用。然而，传统的基于物理和统计的水位预测方法常常面临重大挑战，包括高计算成本以及对多样或不可预见条件的适应性有限。大型时间序列模型的最新进展已显示出解决这些局限性的潜力，最先进的深度学习和基础模型在各种领域的时间序列预测中取得了显著成功。尽管取得了这些进展，但它们在像大沼泽地这样的关键环境系统中的应用仍未得到充分探索。在本研究中，我们通过调查十二种任务特定模型和五种时间序列基础模型（涵盖六个类别），针对大沼泽地水位预测这一实际应用填补了这一空白。我们的主要结果显示，基础模型Chronos显著优于所有其他模型，而其余基础模型表现相对较差。我们还注意到，任务特定模型的性能随模型架构的不同而变化，并讨论了可能的原因。我们希望我们的研究和发现能激励社区探索大型时间序列模型在水文应用中的适用性。代码和数据可在https://github.com/rahuul2992000/Everglades-Benchmark获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [677] [A Structure-Preserving Framework for Solving Parabolic Partial Differential Equations with Neural Networks](https://arxiv.org/abs/2504.10273)
> *神经网络求解抛物型偏微分方程的结构保持框架*

*Gaohang Chen, Lili Ju, Zhonghua Qiao* | **Category: cs.LG, math.NA** | **Updated: 2025-08-07**

**Keywords:** 神经网络, 偏微分方程, 结构保持, 物理一致性, Sidecar

**Comment:** 

> **TL;DR:** 提出“Sidecar”框架，通过引入一个辅助网络，改进现有神经网络求解器在求解抛物型偏微分方程时缺乏物理守恒性的问题，显著提升了精度和结构保持性。

**AI_Comments:** 该论文提出了一个创新的“Sidecar”框架，通过引入辅助网络来确保神经网络求解偏微分方程时满足物理守恒律，解决了现有方法在长期模拟中可能产生非物理解的关键局限性。其灵活性和对各种物理量及现有NN求解器的兼容性是其重要亮点，为提升NN求解PDE的可靠性提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经网络求解偏微分方程的方法主要关注满足方程本身，但忽略了质量、动量守恒或能量耗散等固有的物理性质，导致在长期模拟中可能出现非物理或不稳定的数值解。

**Method:** 提出了一个名为“Sidecar”的新颖框架，通过引入一个受时间依赖谱重整化方法启发的小型“副驾驶”网络，指导主要的函数学习神经网络求解器尊重结构保持特性，从而增强现有神经网络求解抛物型偏微分方程的物理一致性。

**Result:** 在一些基准问题上的实验结果表明，该框架显著提高了现有神经网络求解器的精度和结构保持性。

**Conclusion:** “Sidecar”框架有效解决了现有神经网络求解器在处理抛物型偏微分方程时物理一致性不足的问题，通过引入结构保持特性，显著提升了解决方案的准确性和稳定性。

> **ai_Abstract:** 本文提出了一个名为“Sidecar”的新颖框架，旨在解决现有神经网络求解器在求解抛物型偏微分方程时缺乏物理一致性的问题。通过引入一个小型“副驾驶”网络，该框架能指导主网络遵守质量、动量守恒等结构保持特性。实验证明，“Sidecar”显著提升了神经网络求解器的精度和物理结构保持能力，避免了非物理或不稳定的解。

> **摘要翻译:** 神经网络（NN）求解偏微分方程（PDE）在各种科学和工程领域显示出巨大潜力。然而，大多数现有神经网络求解器主要关注在强或弱意义上满足给定的偏微分方程公式，而没有明确考虑一些固有的物理性质，如质量和动量守恒或能量耗散。这种限制可能导致非物理或不稳定的数值解，特别是在长期模拟中。为了解决这个问题，我们提出了“Sidecar”，一个新颖的框架，旨在增强现有神经网络求解器在求解抛物型偏微分方程时的物理一致性。受时间依赖谱重整化方法的启发，我们的Sidecar框架引入了一个小型网络作为“副驾驶”，指导主要的函数学习神经网络求解器遵守结构保持特性。我们的框架具有高度灵活性，允许将不同偏微分方程的各种物理量的保持融入到各种神经网络求解器中。在一些基准问题上的实验结果表明，所提出的框架显著提高了现有神经网络求解器的精度和结构保持性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [680] [AbbIE: Autoregressive Block-Based Iterative Encoder for Efficient Sequence Modeling](https://arxiv.org/abs/2507.08567)
> *AbbIE：用于高效序列建模的自回归块迭代编码器*

*Preslav Aleksandrov, Meghdad Kurmanji, Fernando Garcia Redondo, David O'Shea, William Shen, Alex Iacob, Lorenzo Sani, Xinchi Qiu, Nicola Cancedda, Nicholas D. Lane* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 自回归编码器, 序列建模, Transformer, 迭代方法, 计算效率

**Comment:** 

> **TL;DR:** AbbIE是一种新型的自回归块迭代编码器，它是一种对编码器专用Transformer架构的递归泛化，在测试时可以动态调整计算资源，并在困惑度和零样本情境学习任务中表现优于标准Transformer和其他迭代方法。

**AI_Comments:** AbbIE的创新之处在于其递归的块迭代设计，以及在训练时迭代次数少但测试时能向上泛化的能力。这为LLM的计算效率和性能扩展提供了一种新颖且有前景的途径，尤其是在资源受限或需要动态调整计算量的场景下。其能够根据任务复杂性调整计算开销的能力，是其重要的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型(LLM)性能提升主要通过增加参数和token数量来实现。本文旨在探索一种新的方法来扩展Transformer性能，允许在测试时动态调整计算资源，以补充现有方法。

**Method:** 本文引入了自回归块迭代编码器（AbbIE），这是一种对编码器专用Transformer架构的新型递归泛化。AbbIE在潜在空间中执行迭代，与潜在推理模型不同，它不需要专门的数据集或训练协议。它在训练时仅使用2次迭代，但在测试时能向上泛化到任意迭代长度。

**Result:** AbbIE在测试时能够向上泛化到任意迭代长度，远远优于其他迭代方法。与标准方法和其他迭代方法相比，AbbIE在零样本情境学习任务中实现了高达12%的改进，在语言困惑度方面实现了高达5%的改进。所有评估都在高达3.5亿参数的模型上进行。

**Conclusion:** AbbIE的引入为Transformer性能扩展开辟了一条新途径，通过允许根据任务复杂性扩展计算开销，实现了更好的性能和资源效率。

> **ai_Abstract:** 本文介绍了一种名为AbbIE的新型自回归块迭代编码器，它是编码器专用Transformer架构的递归泛化。AbbIE能够在测试时动态扩展计算资源，并在潜在空间中执行迭代而无需特殊数据集。它在仅使用2次训练迭代的情况下，在测试时展示了向上泛化到任意迭代长度的能力，并超越了其他迭代方法。与现有方法相比，AbbIE在零样本情境学习任务中实现了高达12%的性能提升，在语言困惑度方面实现了高达5%的提升，为Transformer的性能扩展提供了新方向。

> **摘要翻译:** 我们引入了自回归块迭代编码器（AbbIE），这是一种对编码器专用Transformer架构的新型递归泛化，它比标准Transformer实现了更好的困惑度，并允许在测试时动态扩展计算资源。这种简单、递归的方法是对通过参数和token数量扩展大型语言模型（LLM）性能的补充。AbbIE在潜在空间中执行其迭代，但与潜在推理模型不同，它不需要专门的数据集或训练协议。我们表明，AbbIE在测试时通过仅在训练时使用2次迭代，能够向上泛化（泛化到任意迭代长度），远远优于其他迭代方法。AbbIE根据任务复杂性扩展其计算开销的能力，使其在零样本情境学习任务中比其他迭代和标准方法提高了高达12%，在语言困惑度方面提高了高达5%。这项研究的结果为Transformer性能扩展开辟了一条新途径。我们所有的评估都在高达3.5亿参数的模型上进行。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [688] [Explainable Evidential Clustering](https://arxiv.org/abs/2507.12192)
> *可解释的证据聚类*

*Victor F. Lopes de Souza, Karima Bakhti, Sofiane Ramdani, Denis Mottet, Abdelhak Imoussaten* | **Category: cs.LG** | **Updated: 2025-08-06**

**Keywords:** 证据聚类, 可解释性, 决策树, 不确定性, IEMM

**Comment:** 

> **TL;DR:** 本文提出了一种基于迭代证据错误最小化（IEMM）算法的方法，利用决策树为证据聚类结果提供可解释且谨慎的解释，特别适用于高风险领域。

**AI_Comments:** 这篇论文的创新点在于将可解释性引入到证据聚类中，尤其是在处理数据不确定性和不精确性方面。它通过定义“证据错误”并提出IEMM算法，为高风险应用场景提供了实际的解决方案，强调了在解释中考虑决策者偏好的重要性，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 无监督分类中的真实世界数据常包含不确定性和不精确性，传统方法处理不佳。证据聚类虽能应对这些挑战，但其结果的可解释性研究不足，这在高风险领域（如医疗保健）至关重要。

**Method:** 本文分析了代表性是决策树作为溯因解释器的充要条件。在此基础上，通过效用函数推广了部分标记，从而能够表示“可容忍的”错误，并定义了“证据错误”作为解释成本，构建了适应证据分类器的解释器。最后，提出了迭代证据错误最小化（IEMM）算法，为证据聚类函数提供可解释且谨慎的决策树解释，并在合成和真实世界数据上进行了验证。

**Result:** 所提出的算法在综合和真实世界数据上得到了验证。考虑到决策者的偏好，该方法能够在高达93%的情况下提供满意的解释。

**Conclusion:** 本文成功解决了证据聚类结果解释不足的问题，通过提出的IEMM算法，为证据聚类函数提供了可解释且谨慎的决策树解释，特别适用于高风险领域，并且能够考虑决策者的偏好。

> **ai_Abstract:** 本研究旨在解决证据聚类结果可解释性不足的问题，尤其是在处理不确定性和不精确数据时。通过分析代表性在决策树作为解释器中的作用，并引入效用函数以处理部分标记和定义“证据错误”作为解释成本，本文提出了一种名为迭代证据错误最小化（IEMM）的新算法。该算法能够为证据聚类函数提供可解释且谨慎的决策树解释。实验结果表明，该方法在考虑到决策者偏好时，能提供高达93%的满意解释。

> **摘要翻译:** 无监督分类是一个基础的机器学习问题。真实世界的数据通常包含不完善之处，其特点是不确定性和不精确性，而传统方法对此处理不佳。基于Dempster-Shafer理论的证据聚类解决了这些挑战。本文探讨了证据聚类结果解释这一未被充分探索的问题，这对于医疗保健等高风险领域至关重要。我们的分析表明，在一般情况下，代表性是决策树作为溯因解释器的必要和充分条件。在此代表性概念的基础上，我们通过效用函数推广了这一思想以适应部分标记。这些函数使得能够表示“可容忍的”错误，从而定义了证据错误作为解释成本，并构建了针对证据分类器量身定制的解释器。最后，我们提出了迭代证据错误最小化（IEMM）算法，该算法为证据聚类函数提供了可解释且谨慎的决策树解释。我们在合成数据和真实世界数据上验证了所提出的算法。考虑到决策者的偏好，我们能够提供高达93%满意度的解释。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [693] [A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges](https://arxiv.org/abs/2507.18376)
> *智能农业中扩散模型的综合综述：进展、应用和挑战*

*Xing Hu, Haodong Chen, Qianqian Duan, Choon Ki Ahn, Huiliang Shang, Dawei Zhang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 扩散模型, 智能农业, 深度学习, 图像生成, 可持续农业

**Comment:** 

> **TL;DR:** 该综述探讨了扩散模型在智能农业中的应用进展、优势和挑战，指出其在图像处理、数据增强和遥感分析方面的潜力，以支持可持续农业。

**AI_Comments:** 该综述突出了扩散模型在智能农业领域的重要性和潜力，特别是在解决数据稀缺和不平衡问题方面的优势。其创新之处在于将扩散模型这一前沿生成技术系统性地应用于农业场景。然而，文章也指出了其高计算需求和泛化能力不足的局限性，这对于未来研究和实际部署具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着全球人口增长和耕地资源日益有限，智能和精准农业对于可持续农业发展至关重要。人工智能，特别是深度学习模型，已在农业中广泛应用。扩散模型作为新兴的生成模型，在解决农业场景中带注释数据集有限和样本分布不平衡等挑战方面展现出巨大潜力。

**Method:** 本文对扩散模型在农业中的应用进展进行了综述，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的作用。

**Result:** 扩散模型在农业中被发现有助于改善图像生成、去噪和数据增强等任务，尤其是在存在环境噪声或变异性时。与GANs相比，它们展现出更高的训练稳定性和卓越的图像生成质量，有效解决了农业场景中有限标注数据集和不平衡样本分布的挑战。

**Conclusion:** 随着研究的进展，扩散模型有望支持可持续农业并解决粮食系统中的新兴挑战。

> **ai_Abstract:** 本文全面综述了扩散模型在智能农业中的应用，强调了其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的进展。扩散模型因其在图像生成、去噪和数据增强方面的能力，以及相对于GANs更高的训练稳定性和图像质量，被认为是应对农业中数据限制和不平衡问题的有效工具。尽管存在计算成本高和泛化性受限的挑战，但其在实际应用中正逐步展现出支持可持续农业的潜力。

> **摘要翻译:** 随着全球人口的增长和耕地资源的日益有限，智能和精准农业已成为可持续农业发展的重要方向。人工智能（AI），特别是深度学习模型，已被广泛应用于作物监测、病虫害检测和产量预测等领域。在最近的生成模型中，扩散模型在农业图像处理、数据增强和遥感分析方面显示出巨大的潜力。与传统的生成对抗网络（GANs）相比，扩散模型表现出更高的训练稳定性和卓越的图像生成质量，有效解决了农业场景中带注释数据集有限和样本分布不平衡等挑战。本文综述了扩散模型在农业应用中的最新进展，重点关注其在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理中的作用。扩散模型已被发现有助于改善农业中的图像生成、去噪和数据增强等任务，尤其是在存在环境噪声或变异性时。尽管其高计算需求和跨领域泛化能力有限仍然是关注点，但该方法正逐渐在精准作物监测等实际应用中证明其有效性。随着研究的进展，这些模型可能有助于支持可持续农业并应对粮食系统中的新兴挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [700] [BOASF: A Unified Framework for Speeding up Automatic Machine Learning via Adaptive Successive Filtering](https://arxiv.org/abs/2507.20446)
> *BOASF：一种通过自适应连续过滤加速自动化机器学习的统一框架*

*Guanghui Zhu, Xin Fang, Feng Cheng, Lei Wang, Wenzhong Chen, Chunfeng Yuan, Yihua Huang* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 自动化机器学习, 贝叶斯优化, 超参数优化, 自适应连续过滤, 多臂赌博机

**Comment:** 

> **TL;DR:** BOASF是一种结合贝叶斯优化和自适应连续过滤的统一框架，旨在加速自动化机器学习中的模型选择和超参数优化，并实现更好的性能。

**AI_Comments:** BOASF的创新之处在于其将贝叶斯优化、自适应连续过滤和多臂赌博机框架巧妙地结合起来，形成了一个统一的自动化机器学习加速方案。这种组合不仅提高了模型选择和超参数优化的效率，还通过自适应资源分配确保了性能的提升。其重要性在于降低了机器学习的门槛，使非专家也能更有效地应用机器学习。

<details>
  <summary>Details</summary>

**Motivation:** 对于非专业人士来说，成功且高效地解决机器学习任务具有挑战性，因为从大量备选方案中找到最优模型或超参数组合通常需要大量的专家知识和经验。

**Method:** 本文提出了结合贝叶斯优化（BO）和自适应连续过滤（ASF）的BOASF算法，该算法在一个统一的多臂赌博机框架下运作。BOASF包括多个评估轮次，在每个轮次中，使用贝叶斯优化选择每个“臂”的有希望的配置。然后，ASF使用基于高斯UCB的概率模型自适应地早期淘汰表现不佳的“臂”。此外，采用Softmax模型自适应地为进入下一轮的每个有希望的“臂”分配可用资源，其中前进概率更高的“臂”将获得更多资源。

**Result:** 实验结果表明，BOASF在加速模型选择和超参数优化过程方面是有效的，并且比现有最先进的自动化机器学习方法实现了更鲁棒和更好的预测性能。此外，BOASF在各种时间预算下都取得了更好的实时性能。

**Conclusion:** BOASF通过结合贝叶斯优化和自适应连续过滤，成功地加速了自动化机器学习过程（包括模型选择和超参数优化），同时提供了优于现有方法的鲁棒且更优的预测性能和更好的实时表现。

> **ai_Abstract:** 本文提出了一种名为BOASF的统一框架，该框架结合了贝叶斯优化和自适应连续过滤，旨在解决非专业用户在机器学习任务中面临的模型选择和超参数优化挑战。BOASF在一个多臂赌博机框架下运行，通过多轮评估，利用贝叶斯优化选择有前景的配置，并使用高斯UCB模型自适应淘汰表现不佳的选项。同时，Softmax模型被用于动态分配资源。实验证明，BOASF能够有效加速自动化机器学习过程，并提供比现有先进方法更优异、更鲁棒的预测性能和更好的实时表现。

> **摘要翻译:** 机器学习在许多应用领域取得了巨大成功。然而，对于非专业从业者来说，成功且高效地解决机器学习任务总是非常具有挑战性。从大量可能的备选方案中找到最优的机器学习模型或超参数组合通常需要相当多的专家知识和经验。为了解决这个问题，我们提出了一个结合贝叶斯优化和自适应连续过滤算法（BOASF），在一个统一的多臂赌博机框架下实现模型选择或超参数优化自动化。具体来说，BOASF由多个评估轮次组成，在每个轮次中，我们使用贝叶斯优化为每个臂选择有希望的配置。然后，ASF可以使用基于高斯UCB的概率模型自适应地早期淘汰表现不佳的臂。此外，采用Softmax模型自适应地为每个进入下一轮的有希望的臂分配可用资源。前进概率更高的臂将获得更多资源。实验结果表明，BOASF在加速模型选择和超参数优化过程方面是有效的，同时比现有最先进的自动化机器学习方法实现了更鲁棒和更好的预测性能。此外，BOASF在各种时间预算下都取得了更好的实时性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [707] [An MLI-Guided Framework for Subgroup-Aware Modeling in Electronic Health Records (AdaptHetero)](https://arxiv.org/abs/2507.21197)
> *电子健康记录中子组感知建模的MLI引导框架 (AdaptHetero)*

*Ling Liao, Eva Aagaard* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 机器学习解释, 电子健康记录, 子组感知建模, 异质性, SHAP

**Comment:** 

> **TL;DR:** AdaptHetero是一个MLI驱动的框架，它将机器学习解释性洞察转化为指导电子健康记录中不同亚群模型训练和评估的策略，从而提高预测性能并识别风险。

**AI_Comments:** 该论文的创新点在于将机器学习解释性（MLI）从单纯的洞察提取提升到指导具体的子组模型优化，弥补了MLI在实际操作层面的空白。通过结合SHAP和无监督聚类，AdaptHetero能够有效地处理医疗数据中的异质性，并显著提升不同亚群的预测性能，这对于实现公平和个性化的医疗AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器学习解释性（MLI）主要用于建立临床医生信任和提取洞察，而未能有效地指导特定子组的可操作建模策略。

**Method:** 本文提出了AdaptHetero框架，该框架将解释性洞察转化为可操作的指导，以针对不同亚群定制模型训练和评估。它通过整合基于SHAP的解释和无监督聚类来识别具有临床意义的子组特定特征。

**Result:** AdaptHetero在GOSSIS-1-eICU、WiDS和MIMIC-IV三个大型EHR数据集上进行了评估，持续揭示了在预测ICU死亡率、住院死亡和隐匿性低氧血症时异质的模型行为。该框架显著提高了许多亚群的预测性能（增益高达174.39%），同时主动标记了其他亚群的潜在风险。

**Conclusion:** AdaptHetero框架有望实现更稳健、公平和情境感知的临床部署。

> **ai_Abstract:** 本文提出了AdaptHetero，一个新颖的MLI驱动框架，旨在将机器学习解释性洞察转化为针对电子健康记录中不同亚群定制模型训练和评估的策略。通过整合SHAP解释和无监督聚类，AdaptHetero能够识别临床上有意义的子组特征，并在预测ICU死亡率、住院死亡和隐匿性低氧血症等任务中显著提升多个亚群的预测性能，同时主动识别风险。该框架有望促进更稳健、公平和情境感知的临床模型部署。

> **摘要翻译:** 机器学习解释（MLI）主要被用于促进临床医生信任并从电子健康记录（EHRs）中提取洞察，而不是用于指导特定子组的、可操作的建模策略。为了弥补这一差距，我们提出了AdaptHetero，一个新颖的MLI驱动框架，它将可解释性洞察转化为可操作的指导，以针对不同亚群定制模型训练和评估。在GOSSIS-1-eICU、WiDS和MIMIC-IV三个大规模EHR数据集上进行评估，AdaptHetero持续揭示了在预测ICU死亡率、住院死亡和隐匿性低氧血症时异质的模型行为。AdaptHetero将基于SHAP的解释与无监督聚类相结合，识别出具有临床意义的、子组特定的特征，从而提高了许多亚群的预测性能（增益高达174.39%），同时主动标记了其他亚群的潜在风险。这些结果突出了该框架在实现更稳健、公平和情境感知的临床部署方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [713] [Systolic Array-based Accelerator for Structured State-Space Models](https://arxiv.org/abs/2507.21394)
> *基于脉动阵列的结构化状态空间模型加速器*

*Shiva Raja, Cansu Demirkiran, Aakash Sarkar, Milos Popovic, Ajay Joshi* | **Category: cs.LG, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 脉动阵列, 状态空间模型, 硬件加速器, 序列建模, 能效

**Comment:** 

> **TL;DR:** 本文介绍了一种名为EpochCore的专用硬件加速器，用于高效加速状态空间模型（SSM）的推理，特别适用于长序列任务。

**AI_Comments:** 该论文的创新点在于提出了一个专门针对状态空间模型（SSM）的硬件加速器EpochCore，解决了SSM在传统硬件上计算和内存密集的问题。其通过定制化的脉动阵列设计、多功能处理单元LIMA-PE以及优化的ProDF数据流，显著提升了长序列任务的处理性能和能效，尤其是在与GPU和TPU的对比中展现出显著优势，这对于推动SSM在实际应用中的部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 序列建模对于理解时间数据和检测复杂的时间依赖模式至关重要。尽管循环神经网络、卷积神经网络和Transformer在捕获长程依赖方面有所进展，但由于内存保留有限（固定上下文窗口），它们难以在高精度下处理非常长的序列。状态空间模型（SSM）能更有效地处理超长数据序列，但其训练和推理在传统CPU和GPU上计算和内存开销巨大。

**Method:** 本文提出了一种基于脉动阵列（SA）的专用硬件加速器EpochCore，用于加速SSM。EpochCore内部包含一个名为LIMA-PE的多功能处理单元，能够执行传统和专业的MAC操作以支持传统DNN和SSM。此外，还提出了一种新颖的数据流ProDF，以实现SSM的高效执行。

**Result:** 通过利用LIMA-PE微架构和ProDF数据流，EpochCore在LRA数据集上与GPU相比，性能平均提升了2000倍；与传统基于脉动阵列的加速器（如TPU）相比，性能提升了250倍，能效提升了45倍。

**Conclusion:** EpochCore通过其创新的架构和数据流，显著提高了状态空间模型在处理长序列任务时的推理性能和能效，解决了传统硬件在SSM计算上的瓶颈。

> **ai_Abstract:** 本文提出了一种名为EpochCore的专用硬件加速器，旨在解决状态空间模型（SSM）在处理长序列数据时，传统CPU/GPU计算和内存密集的问题。EpochCore基于脉动阵列，并引入了多功能处理单元LIMA-PE和新颖的数据流ProDF。实验结果表明，EpochCore在性能上相较于GPU提升2000倍，相较于传统脉动阵列加速器提升250倍，并在能效上提升45倍。

> **摘要翻译:** 序列建模对于人工智能理解时间数据和检测复杂的时间依赖模式至关重要。虽然循环神经网络（RNN）、卷积神经网络（CNN）和Transformer在捕获长程依赖方面取得了进展，但由于内存保留有限（固定上下文窗口），它们在处理超长序列时难以实现高精度。状态空间模型（SSM）利用指数衰减内存实现较长的上下文窗口，因此比循环和基于Transformer的模型更有效地处理超长数据序列。与CNN和RNN等传统神经网络模型不同，基于SSM的模型需要通过连续积分求解微分方程，这使得在传统CPU和GPU上进行训练和推理都计算和内存密集。本文介绍了一种名为EpochCore的专用硬件加速器，用于加速SSM。EpochCore基于脉动阵列（SA），旨在提高SSM模型在长程序列任务推理时的能效和吞吐量。在SA中，我们提出了一种多功能处理单元（PE），称为LIMA-PE，用于执行传统和专业的MAC操作，以支持传统DNN和SSM。为了补充EpochCore微架构，我们提出了一种新颖的数据流ProDF，该数据流能够高效执行基于SSM的模型。通过利用LIMA-PE微架构和ProDF，EpochCore在LRA数据集上的性能与GPU相比平均提升了2000倍，与传统的基于SA的加速器（TPU）相比，性能提升了250倍，能效提升了45倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [718] [Data Leakage and Redundancy in the LIT-PCBA Benchmark](https://arxiv.org/abs/2507.21404)
> *LIT-PCBA 基准测试中的数据泄露和冗余*

*Amber Huang, Ian Scott Knight, Slava Naprienko* | **Category: cs.LG, q-bio.QM** | **Updated: 2025-08-07**

**Keywords:** 数据泄露, 分子冗余, LIT-PCBA, 虚拟筛选, 基准测试

**Comment:** 

> **TL;DR:** LIT-PCBA是一个广泛使用的虚拟筛选基准测试，但本研究发现其存在严重的数据泄露和分子冗余问题，导致模型通过记忆而非泛化来取得成功，从而削弱了几乎所有已发表结果的有效性。

**AI_Comments:** 这篇论文揭示了一个广泛使用的生物信息学基准测试（LIT-PCBA）中存在的严重且普遍的缺陷。其重要性在于，它挑战了在该基准上取得的许多现有研究成果的有效性，并强调了在设计和评估机器学习基准测试时数据完整性和多样性的关键性。论文通过提供具体证据和可重现的基线，有力地证明了问题所在，对虚拟筛选和药物发现领域的未来研究具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** LIT-PCBA被广泛用于基准测试虚拟筛选模型，但本研究发现它存在根本性的缺陷，因此旨在揭示其数据完整性问题。

**Method:** 作者对LIT-PCBA基准进行了审计，发现其分割中存在广泛的数据泄露和分子冗余，包括分区内部和跨分区的二维相同配体、普遍存在的类似物重叠以及低多样性查询集。他们还使用一个没有可学习参数的简单记忆基线来验证这些缺陷。

**Result:** 研究发现，在ALDH1靶点中，有323对活性训练-验证类似物对的ECFP4 Tanimoto相似度≥0.6；在所有靶点中，有2,491个二维相同的非活性分子同时出现在训练和验证集中。这些重叠使得模型通过支架记忆而非泛化来成功，从而夸大了富集因子和AUROC分数。一个简单的基于记忆的基线模型可以利用这些缺陷，达到甚至超过最先进的深度学习和3D相似性模型的报告性能。

**Conclusion:** LIT-PCBA基准测试存在严重缺陷，几乎所有在该基准上发表的结果都被削弱了，即使是“零样本”模式下评估的模型也受到影响。该基准在当前形式下无法衡量模型恢复新化学类型的能力，不应作为方法学进步的证据。

> **ai_Abstract:** 本研究揭示了广泛使用的虚拟筛选基准测试LIT-PCBA存在严重的数据泄露和分子冗余问题。通过详细审计，作者发现该基准的训练、验证和测试集中存在大量2D相同或高度相似的配体，导致模型通过记忆而非真正的泛化来取得高分。研究表明，一个简单的记忆基线模型甚至能匹配或超越现有最先进模型的性能。这严重损害了LIT-PCBA上几乎所有已发表研究的有效性，并指出该基准无法准确衡量模型识别新化学类型的能力。

> **摘要翻译:** LIT-PCBA被广泛用于基准测试虚拟筛选模型，但我们的审计显示它存在根本性缺陷。我们发现其分割中存在广泛的数据泄露和分子冗余，包括分区内部和跨分区的二维相同配体、普遍存在的类似物重叠以及低多样性查询集。例如，仅在ALDH1中，就有323对活性训练-验证类似物对的ECFP4 Tanimoto相似度≥0.6；在所有靶点中，有2,491个二维相同的非活性分子同时出现在训练和验证集中，而相应的活性分子却很少。这些重叠使得模型通过支架记忆而非泛化来取得成功，从而夸大了富集因子和AUROC分数。这些缺陷并非偶然——它们是如此严重，以至于一个没有可学习参数的简单基于记忆的基线模型可以利用它们来达到或超过最先进的深度学习和3D相似性模型的报告性能。因此，几乎所有在LIT-PCBA上发表的结果都受到了影响。即使是以“零样本”模式评估的模型也受到类似物泄露到查询集中的影响，削弱了泛化能力的声明。以其当前形式，该基准无法衡量模型恢复新化学类型的能力，不应作为方法学进步的证据。所有代码、数据和基线实现均可在以下网址获取：https://github.com/sievestack/LIT-PCBA-audit

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [724] [On the Theory and Practice of GRPO: A Trajectory-Corrected Approach with Fast Convergence](https://arxiv.org/abs/2508.02833)
> *关于GRPO的理论与实践：一种快速收敛的轨迹校正方法*

*Lei Pang, Ruinan Jin* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** GRPO, 强化学习, 策略优化, 轨迹校正, 理论收敛

**Comment:** 

> **TL;DR:** GRPO在实践中估计的是旧策略的梯度，但这种偏差影响有限。本文提出了TIC GRPO，它使用轨迹级重要性采样来无偏估计当前策略梯度，并首次提供了GRPO类方法的理论收敛分析。

**AI_Comments:** 本文对GRPO的理论基础进行了深入剖析，揭示了其在梯度估计上的潜在偏差，并证明了这种偏差在实践中的影响有限。其创新之处在于提出了TIC GRPO，通过轨迹级重要性采样解决了GRPO的梯度估计偏差问题，并首次为GRPO类方法提供了理论收敛性证明。这对于理解和改进GRPO及其在大型语言模型微调中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是发现GRPO更新规则实际上估计的是旧策略的梯度，而非当前策略，但这种偏差在实践中影响有限；以及一项消融研究表明，即使完全移除重要性采样，简化后的GRPO性能仍与标准GRPO相当。这些发现促使作者探索一种新的、无偏的GRPO变体。

**Method:** 本文首先揭示了GRPO更新规则实际上估计的是旧策略的梯度。接着，通过一项消融研究，证明了即使在固定旧策略下进行更新，性能仍与标准GRPO相当。基于这些发现，本文提出了一种新的算法——轨迹级重要性校正GRPO（TIC GRPO），它用单一的轨迹级概率比替换了token级重要性比，以实现对当前策略梯度的无偏估计，同时保留了无批评器结构。此外，本文首次对GRPO类方法（包括原始GRPO和TIC GRPO）进行了理论收敛分析。

**Result:** 研究表明，GRPO的更新规则实际上估计的是旧策略的梯度，而非当前策略的梯度。然而，由于旧策略会定期刷新，这种偏差的影响在实践中很小。一项消融研究发现，即使完全移除重要性采样，使用固定旧策略的简化版GRPO也能达到与标准GRPO相当的性能。本文提出的TIC GRPO能够对当前策略梯度进行无偏估计。

**Conclusion:** 本文发现GRPO在实践中估计的是旧策略的梯度，但这种偏差影响有限。基于此，提出了一种新的算法TIC GRPO，它通过轨迹级重要性采样提供无偏的当前策略梯度估计，并保持了无批评器结构。此外，本文还首次为GRPO及其变体提供了理论收敛分析。

> **ai_Abstract:** 本文深入分析了DeepSeek提出的无批评器强化学习算法GRPO，发现其更新规则实际上估计的是旧策略的梯度。通过消融研究，作者证明了即使简化GRPO并移除重要性采样，其性能仍与标准GRPO相当。受此启发，本文提出了一种新的算法TIC GRPO，它通过轨迹级重要性比实现对当前策略梯度的无偏估计，同时保持无批评器特性。此外，本文还首次提供了GRPO类方法的理论收敛分析。

> **摘要翻译:** DeepSeek最近提出的组相对策略优化（GRPO）是一种用于微调大型语言模型的无批评器强化学习算法。它用组归一化奖励取代了近端策略优化（PPO）中的价值函数，同时保留了基于旧策略的PPO风格的token级重要性采样。我们发现GRPO的更新规则实际上估计的是旧策略的策略梯度，而非当前策略的。然而，由于旧策略每隔几步就会刷新，两者之间的差异仍然很小，从而限制了这种偏差在实践中的影响。我们通过一项消融研究验证了这一点，在该研究中，重要性采样被完全移除，取而代之的是在多个优化步骤中，使用在固定旧策略下估计的梯度进行更新。值得注意的是，这种简化带来了与标准GRPO相当的性能。受这些发现的启发，我们提出了一种新算法：轨迹级重要性校正GRPO（TIC GRPO）。TIC GRPO用单一的轨迹级概率比替换了token级重要性比，从而在保留无批评器结构的同时，无偏估计当前策略梯度。此外，我们首次对GRPO类方法（包括原始GRPO和我们提出的变体）进行了理论收敛分析。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [730] [One Small Step with Fingerprints, One Giant Leap for De Novo Molecule Generation from Mass Spectra](https://arxiv.org/abs/2508.04180)
> *指纹的一小步，从质谱头生成分子的巨大飞跃*

*Neng Kai Nigel Neo, Lim Jing, Ngoui Yong Zhau Preston, Koh Xue Ting Serene, Bingquan Shen* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 质谱, 分子生成, 分子指纹, MolForge, MIST

**Comment:** 

> **TL;DR:** 该研究提出了一种新的双阶段方法，利用MIST编码器和MolForge解码器，通过预训练和指纹阈值化，显著提高了从质谱头生成分子的准确性，相较于现有最佳方法实现了十倍的性能提升。

**AI_Comments:** 这项工作在从质谱头生成分子领域取得了显著进展。其创新点在于结合了MIST编码器和预训练的MolForge解码器，并引入了指纹概率阈值化策略，有效克服了传统方法中指纹相似度不足的挑战。十倍的性能提升表明了其在准确性上的巨大飞跃，为药物发现和化学分析等领域提供了更强大的工具。该管道被定位为未来研究的强大基线，预示着其对该领域将产生深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 从质谱头生成分子是一个常见但具有挑战性的问题，现有方法通常采用两阶段管道，但仍有提升空间。作者旨在提高从质谱头去新建分子结构（de novo molecule generation）的准确性和效率。

**Method:** 该研究采用双阶段管道：1) 使用MIST作为编码器将质谱编码为分子指纹；2) 使用MolForge作为解码器将指纹解码为分子结构。关键改进包括：对MolForge进行预训练以增强其作为指纹到结构解码器的鲁棒性；以及对指纹概率进行阈值化处理，将其转换为阶梯函数，以帮助解码器更专注于亚结构的存在，即使预测的指纹与真实值相似度不高也能提高准确性。

**Result:** 该编码器和解码器的组合方法比以前最先进的方法实现了十倍的性能提升，能够正确生成28%的top-1分子结构和36%的top-10分子结构。

**Conclusion:** 该研究提出的从质谱头进行de novo分子解析的管道是一个强大的基线，为未来的研究提供了新的方向和性能标准。

> **ai_Abstract:** 本研究提出了一种改进的从质谱头进行de novo分子生成的两阶段方法。该方法将MIST用作质谱到分子指纹的编码器，将预训练的MolForge用作指纹到分子结构的解码器。通过对指纹概率进行阈值化处理，即使在指纹相似度不高的情况下，也能提高分子结构的恢复准确性。与现有最佳方法相比，该管道实现了十倍的性能提升，正确生成了28%的top-1和36%的top-10分子结构，为未来的相关研究提供了强有力的基线。

> **摘要翻译:** 从质谱头进行de novo分子生成问题的一个常见方法涉及一个两阶段管道：(1) 将质谱编码为分子指纹，然后 (2) 将这些指纹解码为分子结构。在我们的工作中，我们采用MIST作为编码器，MolForge作为解码器，并利用预训练来提高性能。值得注意的是，预训练MolForge被证明尤其有效，使其能够作为一个强大的指纹到结构解码器。此外，我们没有传递指纹中每个位的概率，而是将概率阈值化为阶梯函数，这有助于解码器专注于亚结构的存在，即使MIST预测的指纹在Tanimoto相似性方面与真实值仅中等相似，也能提高准确分子结构的恢复。这种编码器和解码器的组合比以前最先进的方法实现了十倍的性能提升，能够正确生成28%的top-1 / 36%的top-10分子结构。我们将这个管道定位为从质谱头进行de novo分子解析未来研究的强大基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [736] [Forgetting: A New Mechanism Towards Better Large Language Model Fine-tuning](https://arxiv.org/abs/2508.04329)
> *遗忘：一种更好的大型语言模型微调新机制*

*Ali Taheri Ghahrizjani, Alireza Taban, Qizhou Wang, Shanshan Ye, Abdolreza Mirzaei, Tongliang Liu, Bo Han* | **Category: cs.LG** | **Updated: 2025-08-07**

**Keywords:** 大型语言模型, 监督微调, 遗忘机制, 数据质量, 性能提升

**Comment:** 

> **TL;DR:** 提出一种新的LLM微调机制，通过区分和“遗忘”无用或误导性tokens来提高模型性能和响应多样性。

**AI_Comments:** 这项工作创新性地引入了“遗忘”这一概念来优化LLM的SFT过程，通过主动识别并排除低质量或误导性数据，有效解决了SFT对数据质量高度依赖的问题。其重要性在于提供了一种新的数据处理范式，有望提升LLM在复杂数据环境下的鲁棒性和学习效率。该机制的有效性在提升模型性能和响应多样性上得到了验证，为未来LLM微调研究提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 监督微调（SFT）对大型语言模型（LLM）至关重要，但其效果严重依赖于数据质量和数据量，否则可能导致性能提升有限甚至下降。

**Method:** 提出将语料库中的tokens分为“积极”和“消极”两部分。积极tokens以常规方式训练，而消极tokens（可能缺乏必要语义或具有误导性）则被明确地“遗忘”。这种分类和遗忘过程有助于模型更精确地学习信息并形成知识边界。

**Result:** 在成熟的基准测试中，该遗忘机制不仅提高了模型的整体性能，还促进了更丰富的模型响应多样性。

**Conclusion:** 通过引入一个明确的“遗忘”机制来处理低质量或误导性数据，可以有效提升大型语言模型的监督微调效果，实现更好的性能和响应多样性。

> **ai_Abstract:** 本文提出一种针对大型语言模型（LLM）监督微调（SFT）的新机制——“遗忘”。鉴于SFT效果受数据质量影响，研究者将tokens分为有益的“积极”和无用的“消极”两类。积极tokens正常训练，而消极tokens则被明确遗忘，以避免学习低信息量或误导性内容。实验表明，该机制能提升模型性能并增加响应多样性。

> **摘要翻译:** 监督微调（SFT）对预训练大型语言模型（LLM）起着关键作用，显著增强了它们获取领域特定知识的能力，同时保持或可能增强其通用能力。然而，SFT的效能取决于数据质量和数据量，否则可能导致性能提升有限，甚至相对于相关基线出现下降。为了减轻这种依赖，我们建议根据tokens是否有助于提高模型性能，将每个语料库中的tokens分为两部分——积极tokens和消极tokens。积极tokens可以以常见方式进行训练，而消极tokens，可能缺乏基本语义或具有误导性，则应被明确地遗忘。总体而言，tokens分类有助于模型学习较少信息量的消息，而遗忘过程形成了一个知识边界，以指导模型更精确地学习哪些信息。我们在成熟的基准测试上进行了实验，发现这种遗忘机制不仅提高了模型的整体性能，还促进了更丰富的模型响应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [742] [Thompson Exploration with Best Challenger Rule in Best Arm Identification](https://arxiv.org/abs/2310.00539)
> *汤普森探索与最佳挑战者规则在最佳臂识别中的应用*

*Jongyeong Lee, Junya Honda, Masashi Sugiyama* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 最佳臂识别, 汤普森采样, 最佳挑战者规则, 固定置信度, 赌博机

**Comment:** 

> **TL;DR:** 本文提出了一种结合汤普森采样和最佳挑战者规则的新策略，用于解决固定置信度最佳臂识别问题，该策略计算效率高，在渐近性上表现优异，且在数值实验中具有竞争力。

**AI_Comments:** 该论文的创新点在于将通常用于最大化累积奖励的汤普森采样方法与计算高效的最佳挑战者规则相结合，应用于最佳臂识别问题。这解决了现有BAI方法在计算效率和探索灵活性上的痛点，尤其是在非高斯模型下。其理论上的渐近最优性和实验中的良好表现，使其成为该领域一个有前景的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的固定置信度最佳臂识别（BAI）策略通常需要在每轮解决优化问题，或强制探索臂一定次数，且大多数不适用于高斯模型之外的情况。为了解决这些限制，本文提出了新的策略。

**Method:** 本文提出了一种结合汤普森采样（Thompson sampling）和计算高效的最佳挑战者规则（best challenger rule）的新策略。

**Result:** 该策略对于任何双臂赌博机问题是渐近最优的，对于K≥3的K臂赌博机问题实现了近似最优。在数值实验中，该策略在样本复杂度方面与渐近最优策略相比表现出竞争力，同时计算成本更低。此外，通过与β-最优性概念进行比较，突出了该策略的优势。

**Conclusion:** 本文提出的结合汤普森采样和最佳挑战者规则的策略，有效解决了现有固定置信度最佳臂识别方法计算效率低和探索限制的问题，并在理论和实验上证明了其渐近最优性和竞争力。

> **ai_Abstract:** 本文针对赌博机框架下的固定置信度最佳臂识别问题，提出了一种结合汤普森采样和最佳挑战者规则的新策略，以解决现有方法计算效率低和强制探索的局限性。该策略被证明对双臂问题是渐近最优的，对多臂问题是近似最优的，并在数值实验中展现出与渐近最优方法相当的性能，同时计算成本更低。

> **摘要翻译:** 本文研究了在经典单参数指数模型中，赌博机框架下的固定置信度最佳臂识别（BAI）问题。对于这个问题，已经提出了许多策略，但其中大多数策略在每轮都需要解决一个优化问题，和/或被迫探索一个臂至少一定次数，除了那些仅限于高斯模型的策略。为了解决这些限制，我们提出了一种新颖的策略，它将汤普森采样与一种计算高效的方法（即最佳挑战者规则）相结合。虽然汤普森采样最初被认为是用于最大化累积奖励的，但我们证明了它可以自然地用于BAI中的臂探索而无需强制。我们证明了我们的策略对于任何双臂赌博机问题都是渐近最优的，并且对于K≥3的一般K臂赌博机问题实现了近似最优。然而，在数值实验中，我们的策略在样本复杂度方面显示出与渐近最优策略相比的竞争力，同时需要更少的计算成本。此外，我们通过将其与β-最优性概念进行比较，突出了我们策略的优势，β-最优性是一种在分析包括所提出的策略在内的一类策略时通常考虑的渐近最优性的宽松概念。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [748] [Robustness of data-driven approaches in limited angle tomography](https://arxiv.org/abs/2403.11350)
> *有限角度断层扫描中数据驱动方法的鲁棒性*

*Yiran Wang, Yimin Zhong* | **Category: cs.LG, math.NA** | **Updated: 2025-08-07**

**Keywords:** 有限角度断层扫描, 数据驱动方法, Radon变换, U-Net, 鲁棒性

**Comment:** 

> **TL;DR:** 在有限角度断层扫描中，数据驱动方法比传统方法能更稳定地重建更多信息，并通过U-Net实验得到验证。

**AI_Comments:** 该论文结合了理论解释和使用流行的神经网络架构（U-Net）的实验验证，这增强了其关于数据驱动方法在挑战性成像问题中鲁棒性和优越性的主张。

<details>
  <summary>Details</summary>

**Motivation:** 有限角度Radon变换因其病态性而难以反演，传统方法如滤波反投影存在局限性。

**Method:** 本研究提供了一个数学解释，并使用基于U-Net神经网络的实验来验证所提出的理论。

**Result:** 数据驱动方法与传统方法相比，可以稳定地重建更多信息。基于U-Net神经网络的实验验证了这一理论。

**Conclusion:** 数据驱动方法在有限角度断层扫描中比传统方法能够提供更稳定、更优越的重建。

> **ai_Abstract:** 本文针对有限角度Radon变换反演的病态性问题，通过数学解释和基于U-Net的实验验证，证明了数据驱动方法与滤波反投影等传统方法相比，能够更稳定地重建更多信息。

> **摘要翻译:** 有限角度Radon变换因其病态性而难以反演。在这项工作中，我们给出了一个数学解释，表明数据驱动方法与滤波反投影等传统方法相比，可以稳定地重建更多信息。此外，我们使用基于U-Net神经网络的实验来验证我们的理论。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [753] [Nonasymptotic Analysis of Stochastic Gradient Descent with the Richardson-Romberg Extrapolation](https://arxiv.org/abs/2410.05106)
> *随机梯度下降与Richardson-Romberg外推的非渐近分析*

*Marina Sheshukova, Denis Belomestny, Alain Durmus, Eric Moulines, Alexey Naumov, Sergey Samsonov* | **Category: cs.LG, math.OC, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 随机梯度下降, Richardson-Romberg外推, 非渐近分析, 均方误差, 马尔可夫链

**Comment:** 

> **TL;DR:** 本文对结合了Richardson-Romberg外推的随机梯度下降（SGD）进行了非渐近分析，展示了均方误差的展开式，其中主导项为O(n^-1/2)，次要项为O(n^-3/4)，并利用了马尔可夫链的性质。

**AI_Comments:** 本文对结合了Richardson-Romberg外推的SGD提供了严谨的理论分析，提出了精确的非渐近误差展开式。利用马尔可夫链性质进行分析是其一个显著特点，有助于更深入地理解超越渐近结果的收敛行为。均方误差的明确分解以及最佳次要项的识别是对优化理论领域的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决使用常数步长随机梯度下降（SGD）算法求解强凸光滑最小化问题。先前的研究提出了将Polyak-Ruppert平均程序与Richardson-Romberg外推相结合以减少SGD的渐近偏差，而本文显著扩展了这些现有结果。

**Method:** 该方法通过对结合了Richardson-Romberg外推的SGD估计器的均方误差进行展开分析。其分析依赖于将SGD迭代视为时齐马尔可夫链的性质，并建立了该链相对于适当定义的加权Wasserstein半度量的几何遍历性。

**Result:** 均方根误差被分解为两项：一个主导项为O(n^-1/2)，明确依赖于一个极小极大最优渐近协方差矩阵；一个次要项为O(n^-3/4)，其中3/4是已知最佳的幂。该结果也推广到了更高阶矩界。

**Conclusion:** 本文对结合了Richardson-Romberg外推的SGD提供了详细的非渐近分析，展示了均方误差的精确展开，并使用马尔可夫链理论将结果推广到更高阶矩。

> **ai_Abstract:** 本文对应用于强凸光滑最小化问题的随机梯度下降（SGD）算法，特别是其与Richardson-Romberg外推结合的情况，进行了非渐近分析。作者通过提供所得估计器均方误差的详细展开式，显著扩展了现有工作。他们表明，均方根误差可以分解为O(n^-1/2)的主导项和O(n^-3/4)的次要项，其中后者是已知最佳的幂。该分析基于将SGD迭代建模为相对于加权Wasserstein半度量呈几何遍历的时齐马尔可夫链。

> **摘要翻译:** 我们解决了使用常数步长的随机梯度下降（SGD）算法求解强凸光滑最小化问题。以前的工作建议将Polyak-Ruppert平均程序与Richardson-Romberg外推相结合，以降低SGD的渐近偏差，代价是方差略有增加。我们通过提供所得估计器均方误差相对于迭代次数$n$的展开式，显著扩展了以前的结果。我们表明，均方根误差可以分解为两项之和：一个主要项为$\mathcal{O}(n^{-1/2})$，明确依赖于一个极小极大最优渐近协方差矩阵，以及一个次要项为$\mathcal{O}(n^{-3/4})$，其中$3/4$是已知最佳的幂。我们还将此结果推广到更高阶矩界。我们的分析依赖于将SGD迭代视为时齐马尔可夫链的性质。特别是，我们确定该链相对于适当定义的加权Wasserstein半度量是几何遍历的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [758] [Online Graph Topology Learning via Time-Vertex Adaptive Filters: From Theory to Cardiac Fibrillation](https://arxiv.org/abs/2411.01567)
> *通过时空自适应滤波器进行在线图拓扑学习：从理论到心房颤动*

*Alexander Jenkins, Thiernithi Variddhisai, Ahmed El-Medany, Fu Siong Ng, Danilo Mandic* | **Category: cs.LG, eess.SP, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 图拓扑学习, 时变系统, 自适应滤波器, 图信号处理, 心房颤动

**Comment:** 

> **TL;DR:** AdaCGP是一种稀疏感知的自适应算法，用于从多元时间序列中估计动态图拓扑，并在模拟和心房颤动应用中表现出色。

**AI_Comments:** 本文提出了一种新颖的在线图拓扑学习算法AdaCGP，其创新点在于结合了稀疏性、自适应性和递归更新，以解决现有方法在处理时变系统和实时应用时的局限性。其在心房颤动中的应用展示了该方法在实际生物医学系统中的巨大潜力，能够捕获动态变化，这对于理解和治疗复杂疾病至关重要。该方法在计算效率和准确性方面的提升使其具有显著的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有图拓扑学习方法难以处理时变系统和实时应用，尤其是在图信号处理（GSP）框架下。

**Method:** 本文提出AdaCGP，一种稀疏感知自适应算法，通过递归更新公式估计图移位算子（GSO），旨在解决稀疏性、移位不变性和偏差问题。采用变量分裂方法来识别因果连接。

**Result:** 在多种图拓扑结构下，AdaCGP在GSO估计方面比现有方法性能提高超过83%，同时保持良好的计算扩展性。变量分裂方法实现了近零误报率和最小漏边的可靠因果连接识别。应用于心房颤动记录时，AdaCGP比Granger因果关系等现有方法更有效地跟踪传播模式的动态变化，并成功识别可能维持心律失常的传导模式的稳定性特征。

**Conclusion:** AdaCGP是一种有效且计算高效的动态图拓扑学习方法，在生物医学系统诊断和治疗等临床应用中具有潜力。

> **ai_Abstract:** 本文提出AdaCGP，一种用于从多元时间序列中估计动态图拓扑的稀疏感知自适应算法。该算法通过递归更新公式估计图移位算子，并在模拟中表现出显著优于现有方法的性能，同时具有良好的计算效率。在心房颤动数据上的应用表明，AdaCGP能有效跟踪动态传播模式并识别关键稳定性特征，预示其在生物医学诊断和治疗领域的应用潜力。

> **摘要翻译:** 图信号处理（GSP）通过将数据建模为图上的信号，为分析复杂、相互连接的系统提供了强大的框架。尽管最近的进展使得从观测信号中学习图拓扑成为可能，但现有方法往往难以处理时变系统和实时应用。为了解决这一空白，我们引入了AdaCGP，一种稀疏感知的自适应算法，用于从多元时间序列中估计动态图拓扑。AdaCGP通过旨在解决稀疏性、移位不变性和偏差的递归更新公式来估计图移位算子（GSO）。通过全面的模拟，我们证明了AdaCGP在各种图拓扑结构下始终优于多个基线方法，与现有技术相比，在GSO估计方面实现了超过83%的改进，同时保持了良好的计算扩展性。我们的变量分裂方法能够以接近零的误报率和最小的漏边可靠地识别因果连接。应用于心房颤动记录时，AdaCGP比Granger因果关系等既有方法更有效地跟踪传播模式的动态变化，捕获了静态方法遗漏的图拓扑时间变化。该算法成功识别了可能维持心律失常的传导模式的稳定性特征，展示了在复杂生物医学系统诊断和治疗中的潜在临床应用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [763] [Fast and Robust Visuomotor Riemannian Flow Matching Policy](https://arxiv.org/abs/2412.10855)
> *快速鲁棒的视觉运动黎曼流匹配策略*

*Haoran Ding, Noémie Jaquier, Jan Peters, Leonel Rozo* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 视觉运动策略, 流匹配, 黎曼流形, 机器人学习, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了黎曼流匹配策略（RFMP）及其鲁棒版本SRFMP，以解决扩散模型在机器人视觉运动策略中推理慢和训练复杂的问题。RFMP结合了流匹配的快速性和黎曼几何约束，并在多项任务上表现出高效且优越的性能。

**AI_Comments:** 这篇论文的创新点在于将流匹配方法引入视觉运动策略，并巧妙地结合了机器人状态所处的黎曼流形几何约束，这对于处理复杂机器人任务中的非欧几里得空间数据具有重要意义。同时，通过引入SRFMP增强鲁棒性也提升了其在实际应用中的潜力。该工作为机器人学习提供了一种高效且理论基础更强的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在机器人视觉运动策略中存在推理速度慢和训练复杂的缺点。

**Method:** 本文提出了黎曼流匹配策略（RFMP），该模型继承了流匹配（FM）易于训练和快速推理的优点，并能内在整合机器人状态在黎曼流形上的几何约束。为了增强RFMP的鲁棒性，进一步提出了稳定RFMP（SRFMP），它利用LaSalle不变性原理使FM的动力学对目标黎曼分布的支持具有稳定性。

**Result:** 在十个模拟和真实世界任务上的严格评估表明，RFMP成功地在欧几里得和黎曼空间中学习并合成了复杂的感知运动策略，训练和推理阶段高效，性能优于扩散策略和一致性策略。

**Conclusion:** RFMP和SRFMP为解决现有扩散模型在视觉运动策略中的局限性提供了一种高效且鲁棒的替代方案，特别是在处理黎曼几何约束方面表现出色。

> **ai_Abstract:** 本文提出了一种名为黎曼流匹配策略（RFMP）的新型视觉运动策略，旨在解决现有扩散模型在机器人任务中推理慢和训练复杂的问题。RFMP继承了流匹配的快速推理和易训练特性，并能有效整合黎曼流形上的几何约束。为提高鲁棒性，作者进一步引入了稳定RFMP（SRFMP）。实验结果表明，RFMP在多种模拟和真实世界任务上表现出高效的训练和推理能力，并优于现有的扩散策略和一致性策略。

> **摘要翻译:** 扩散式视觉运动策略通过有效结合视觉数据与高维、多模态动作分布，在学习复杂机器人任务方面表现出色。然而，扩散模型通常由于昂贵的去噪过程而导致推理缓慢，或者由于最近的蒸馏方法而需要复杂的序列训练。本文介绍了黎曼流匹配策略（RFMP），该模型继承了流匹配（FM）易于训练和快速推理的能力。此外，RFMP内在地结合了现实机器人应用中常见的几何约束，因为机器人状态存在于黎曼流形上。为了增强RFMP的鲁棒性，我们提出了稳定RFMP（SRFMP），它利用LaSalle不变性原理，使FM的动力学对目标黎曼分布的支持具有稳定性。在十个模拟和真实世界任务上的严格评估表明，RFMP成功地在欧几里得和黎曼空间中学习并合成了复杂的感知运动策略，训练和推理阶段高效，性能优于扩散策略和一致性策略。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [768] [Physical Scales Matter: The Role of Receptive Fields and Advection in Satellite-Based Thunderstorm Nowcasting with Convolutional Neural Networks](https://arxiv.org/abs/2504.09994)
> *物理尺度很重要：感受野和平流在基于卫星的雷暴临近预报中卷积神经网络的作用*

*Christoph Metzl, Kianusch Vahid Yousefnia, Richard Müller, Virginia Poli, Miria Celano, Tobias Bölle* | **Category: cs.LG, physics.ao-ph** | **Updated: 2025-08-07**

**Keywords:** 雷暴临近预报, 卷积神经网络, 平流, 感受野, 卫星图像

**Comment:** 

> **TL;DR:** 将平流信息整合到基于卫星的雷暴临近预报的机器学习模型中，在整体表现上提升不显著，但在更长的预报时间和更高的平流速度下，技能提升明显，证实了物理尺度的重要性。

**AI_Comments:** 本文的创新之处在于首次将物理驱动的平流概念引入到基于卫星的雷暴临近预报的机器学习模型中，弥合了传统物理方法与现代数据驱动方法之间的鸿沟。其重要性在于揭示了在设计机器学习预报模型时，考虑并整合物理尺度的关键作用，尤其对于提升长期预报的准确性至关重要。尽管在整体平均得分上提升有限，但其在特定条件下（长预报时间、高平流速度）的显著效果表明了该方法的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 临近预报的重心正从物理驱动的平流方法转向纯数据驱动的机器学习方法。然而，最近的研究表明，将平流整合到机器学习流程中可以提高基于雷达的降水临近预报技能。但这种方法的普适性和其根本原因尚未被探索。本研究首次在基于卫星的雷暴临近预报中探讨其普适性。

**Method:** 本研究通过在基于卫星的雷暴临近预报中探究该方法的普适性。利用尺度论证来解释何时以及为何可以预期技能的提升。训练了ResU-Net模型来解决分割任务，并以闪电观测作为真值。基线神经网络（BNN）的输入是多光谱卫星图像和闪电观测的短时间序列，而平流信息神经网络（AINN）额外接收了所有输入通道在期望预报时间处的拉格朗日持久性临近预报。

**Result:** 总体而言，在考虑完全平均得分时，AINN相对于BNN的技能提升很小。然而，根据预报时间和平流速度评估技能时，本研究表明尺度论证正确预测了AINN相对于BNN在2小时预报时间后的技能提升。研究证实，通常情况下，随着预报时间的延长和平流速度的增加，平流变得越来越重要。

**Conclusion:** 本研究强调了在设计基于机器学习的预报模型时，考虑并整合潜在物理尺度（特别是对于更长的预报时间和更高的平流速度）的重要性。

> **ai_Abstract:** 本研究探讨了将平流信息整合到卷积神经网络中，用于基于卫星的雷暴临近预报。虽然平流信息神经网络（AINN）在整体技能提升上相对基线神经网络（BNN）不显著，但在预报时间超过2小时和高平流速度条件下，AINN的技能提升显著。这验证了物理尺度（特别是平流确保相关模式在感受野内）在提高机器学习预报模型技能中的关键作用，尤其对于较长预报时效而言。

> **摘要翻译:** 临近预报的开发重点正在从物理驱动的平流方法转向纯数据驱动的机器学习（ML）方法。然而，最近的工作表明，将平流整合到ML价值链中可以提高基于雷达的降水临近预报技能。但这种方法的普适性及其潜在原因仍未被探索。本研究首次在基于卫星的雷暴临近预报中探讨了这种普适性。借鉴尺度论证，我们提出了一种解释，说明何时以及为何可以预期技能的提升。本质上，平流保证了与临近预报相关的雷暴模式在长时间预报时仍包含在感受野中。为了验证我们的假设，我们训练了ResU-Net模型，以闪电观测作为真值来解决分割任务。基线神经网络（BNN）的输入是多光谱卫星图像和闪电观测的短时间序列，而平流信息神经网络（AINN）额外接收了所有输入通道在期望预报时间处的拉格朗日持久性临近预报。总体而言，在考虑完全平均得分时，我们发现AINN相对于BNN的技能提升很小。然而，根据预报时间和平流速度评估技能时，我们证明了我们的尺度论证正确预测了AINN相对于BNN在2小时预报时间后的技能提升。我们证实，通常情况下，随着预报时间的延长和平流速度的增加，平流变得越来越重要。我们的工作强调了在设计基于ML的预报模型时，考虑和整合潜在物理尺度的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [773] [A Probabilistic Framework for Imputing Genetic Distances in Spatiotemporal Pathogen Models](https://arxiv.org/abs/2506.09076)
> *时空病原体模型中遗传距离推算的概率框架*

*Haley Stone, Jing Du, Hao Xue, Matthew Scotch, David Heslop, Andreas Züfle, Chandini Raina MacIntyre, Flora Salim* | **Category: cs.LG, q-bio.GN, q-bio.PE** | **Updated: 2025-08-07**

**Keywords:** 遗传距离推算, 病原体模型, 概率框架, 时空建模, 禽流感

**Comment:** 

> **TL;DR:** 本研究提出了一个概率框架，用于在病原体基因组数据不完整时，推断未测序病例与已知序列之间的遗传距离，无需序列比对或已知传播链，并已成功应用于禽流感数据。

**AI_Comments:** 该框架的创新之处在于其无需序列比对或已知传播链即可推断遗传距离，通过时间感知进化距离建模提高了实用性。其支持不确定性感知和可扩展性也增加了其实用价值。该研究解决了基因组数据不完整这一常见问题，对于更准确地进行时空病原体建模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 病原体基因组数据为空间模型提供了有价值的结构，但其效用受限于不完整的测序覆盖。

**Method:** 本文提出了一个概率框架，利用时间感知的进化距离建模，推断未测序病例与已知序列之间的遗传距离。该方法通过集合日期和观察到的遗传距离估计成对分歧，实现基于观察到的分歧模式的生物学上合理的推算，而无需序列比对或已知传播链。

**Result:** 该方法已成功应用于美国野生鸟类高致病性禽流感A/H5病例，支持基因组数据集的可扩展、不确定性感知增强，并增强了进化信息与时空建模工作流的整合。

**Conclusion:** 该概率框架通过推算遗传距离，有效克服了病原体基因组数据不完整的问题，从而提升了进化信息在时空病原体建模中的应用能力和数据利用效率。

> **ai_Abstract:** 本研究提出了一个概率框架，旨在解决病原体基因组数据测序覆盖不完整的问题。该框架利用时间感知的进化距离建模，推断未测序病例与已知序列之间的遗传距离，其优势在于无需序列比对或预先知道传播链。通过估计集合日期和观察到的遗传距离之间的分歧，该方法能够进行生物学上合理的遗传距离推算。研究通过应用于美国野生鸟类高致病性禽流感A/H5病例，证明了其能够支持基因组数据的可扩展增强，并促进进化信息在时空建模中的整合。

> **摘要翻译:** 病原体基因组数据为空间模型提供了有价值的结构，但其效用受限于不完整的测序覆盖。我们提出了一个概率框架，用于在定义的传播链中，利用时间感知的进化距离建模，推断未测序病例与已知序列之间的遗传距离。该方法通过集合日期和观察到的遗传距离估计成对分歧，从而实现基于观察到的分歧模式的生物学上合理的推算，无需序列比对或已知传播链。应用于美国野生鸟类高致病性禽流感A/H5病例，该方法支持基因组数据集的可扩展、不确定性感知增强，并增强了进化信息与时空建模工作流的整合。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [779] [Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows](https://arxiv.org/abs/2506.10153)
> *流量控制中的注意力机制：基于Transformer的强化学习用于高扰动流中的升力调节*

*Zhecheng Liu, Jeff D. Eldredge* | **Category: cs.LG, physics.flu-dyn** | **Updated: 2025-08-06**

**Keywords:** 流量控制, 强化学习, Transformer, 升力调节, 阵风序列

**Comment:** 

> **TL;DR:** 本文提出了一种基于Transformer的强化学习框架，通过俯仰控制在高扰动流中有效调节升力，并展示了其优于传统方法的性能和泛化能力。

**AI_Comments:** 这篇论文的创新点在于将Transformer模型引入到强化学习框架中，以解决流体控制中复杂的非线性相互作用和部分可观测性问题。通过结合预训练和迁移学习，有效提升了训练效率和模型的泛化能力。特别是在高度扰动流中实现升力调节，展示了其在实际应用中的潜力。对不同俯仰配置的深入分析也提供了有价值的工程指导。

<details>
  <summary>Details</summary>

**Motivation:** 针对弱扰动设计的线性流量控制策略在强扰动下失效，且在有限传感器观测的高方差流中存在固有的控制挑战（部分可观测性问题）。

**Method:** 提出了一种基于Transformer的强化学习（RL）框架，通过俯仰控制在任意长阵风序列中调节气动升力。通过专家策略预训练（线性控制）和任务级迁移学习（从孤立阵风扩展到多个阵风）加速训练。Transformer模型用于解决有限表面压力带来的部分可观测性挑战。

**Result:** 所学策略优于最佳比例控制，性能差距随阵风数量增加而扩大。在少量连续阵风环境中学习的策略能有效泛化到任意长阵风序列。四分之一弦长俯仰控制比中弦长俯仰控制能以更少的控制力实现更优的升力调节，这归因于通过四分之一弦长俯仰可获得的主导附加质量贡献。

**Conclusion:** 基于Transformer的强化学习框架能够有效地在高度扰动流中调节升力，其性能优于传统方法，并具有良好的泛化能力。研究还表明，四分之一弦长俯仰控制在效率和效果上优于中弦长俯仰控制。

> **ai_Abstract:** 本文提出了一种基于Transformer的强化学习（RL）框架，用于在高度扰动（任意长阵风序列）的流中通过俯仰控制调节气动升力。该框架利用Transformer处理有限传感器输入下的部分可观测性问题，并通过专家策略预训练和任务级迁移学习加速训练。实验结果表明，该RL策略在升力调节方面优于传统比例控制，且能有效泛化到更长的阵风序列。此外，研究还发现四分之一弦长俯仰控制相比中弦长俯仰控制能以更小的控制代价实现更优的性能，这归因于其对附加质量贡献的有效利用。

> **摘要翻译:** 针对弱扰动设计的线性流量控制策略在强扰动序列中可能因非线性相互作用而失效，但利用它来开发更好的策略是明智的。在本研究中，我们提出了一种基于Transformer的强化学习（RL）框架，通过俯仰控制来学习一种有效的控制策略，以在任意长的阵风序列中调节气动升力。随机阵风产生间歇性、高方差的流，仅通过有限的表面压力传感器观测到，这使得与稳定流相比，该控制问题具有固有的挑战性。Transformer解决了有限表面压力带来的部分可观测性挑战。我们证明了训练可以通过两种技术加速——使用专家策略（此处为线性控制）进行预训练以及任务级迁移学习（此处为将针对孤立阵风训练的策略扩展到多个阵风）。我们展示了所学策略优于最佳比例控制，并且随着阵风数量的增加，性能差距不断扩大。在少量连续阵风环境中学习的控制策略被证明能有效泛化到任意长阵风序列的环境中。我们研究了枢轴配置，结果表明，与中弦长俯仰控制相比，四分之一弦长俯仰控制能以显著更少的控制力实现更优的升力调节。通过升力分解，我们将这一优势归因于通过四分之一弦长俯仰可获得的主导附加质量贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [783] [GRAND: Graph Release with Assured Node Differential Privacy](https://arxiv.org/abs/2507.00402)
> *GRAND：具有节点差分隐私保证的图发布*

*Suqing Liu, Xuan Bi, Tianxi Li* | **Category: cs.LG, math.ST, stat.ME, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 差分隐私, 图发布, 节点隐私, 网络数据, 结构特性

**Comment:** 

> **TL;DR:** GRAND提出了一种新颖的图发布机制，能够在确保节点级差分隐私的同时，发布整个网络并保留其结构特性，解决了现有方法在网络数据隐私保护中的局限性。

**AI_Comments:** 这项工作具有重要意义，因为它首次提出了一个能够发布整个网络并同时保证节点级差分隐私和结构特性保留的机制。这填补了现有图隐私保护方法的空白，尤其是在需要发布完整图结构而非仅限于查询结果的应用场景中。其理论保证（渐近分布一致性）和实验验证增强了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私在数据保护中应用广泛，但在网络数据（尤其是节点级别）的应用仍未充分探索。现有节点级隐私方法要么仅限于查询，要么无法保留网络关键结构特性。

**Method:** 本文提出了GRAND（Graph Release with Assured Node Differential privacy），这是一种网络发布机制，它能发布整个网络，同时确保节点级差分隐私并保留结构特性。在广泛的潜在空间模型下，该方法证明了发布的网络渐近地遵循与原始网络相同的分布。通过在合成和真实世界数据集上的广泛实验来评估其有效性。

**Result:** 在广泛的潜在空间模型下，发布的网络渐近地遵循与原始网络相同的分布。通过在合成和真实世界数据集上的广泛实验，验证了该方法的有效性。

**Conclusion:** GRAND是首个能够发布整个网络，同时确保节点级差分隐私并保留网络结构特性的机制，解决了现有图隐私保护方法的局限性，并证明了其在分布和结构保持方面的有效性。

> **ai_Abstract:** GRAND是一种新颖的图发布机制，旨在解决网络数据中节点级差分隐私保护的不足。与现有方法不同，GRAND能够在发布整个网络的同时，确保节点级差分隐私并保留其关键结构特性。研究表明，在潜在空间模型下，发布的网络渐近地遵循与原始网络相同的分布。该方法通过在合成和真实数据集上的实验进行了验证。

> **摘要翻译:** 差分隐私是保护数据中敏感信息的完善框架。尽管它在各个领域得到了广泛应用，但其在网络数据（尤其是节点级别）中的应用仍未得到充分探索。现有的节点级隐私方法要么只关注基于查询的方法，将输出限制在预先指定的网络统计数据上，要么未能保留网络的关键结构特性。在这项工作中，我们提出了GRAND（Graph Release with Assured Node Differential privacy），据我们所知，这是第一个在确保节点级差分隐私并保留结构特性的同时发布整个网络的机制。在广泛的潜在空间模型下，我们证明了发布的网络渐近地遵循与原始网络相同的分布。通过在合成和真实世界数据集上的广泛实验，评估了该方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [788] [Unified Linear Parametric Map Modeling and Perception-aware Trajectory Planning for Mobile Robotics](https://arxiv.org/abs/2507.09340)
> *移动机器人统一线性参数图建模与感知感知轨迹规划*

*Hongyu Nie, Xu Liu, Zhaotong Tan, Sen Mei, Wenbo Su* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 移动机器人, 感知感知轨迹规划, 线性参数图, 随机映射, ESDF

**Comment:** 

> **TL;DR:** 本文提出RMRP方法构建轻量级线性参数图，并在此基础上开发RPATR框架，实现移动机器人高效、安全的感知感知导航。

**AI_Comments:** 该论文的创新点在于提出了RMRP方法构建轻量级线性参数图，并通过理论定理保证其有效性，这对于解决大规模环境下的计算负担问题具有重要意义。RPATR框架将感知信息与轨迹规划深度融合，特别是对未观测区域的预测和对不同机器人类型的统一处理，提升了导航的鲁棒性和效率。其重要性在于为移动机器人在复杂、动态环境中实现高效、安全的自主导航提供了新的思路和方法。

<details>
  <summary>Details</summary>

**Motivation:** 自主导航在大型复杂环境中面临计算负担重、传感器遮挡失效、不规则地形遍历困难以及缺乏感知感知策略等挑战。

**Method:** 提出随机映射和随机投影（RMRP）方法，通过将数据映射到高维空间并进行稀疏随机投影来构建轻量级线性参数图，并由残余能量保持定理提供理论保证。基于此图，提出RPATR（鲁棒感知感知轨迹规划器）框架。对于UAV，统一网格和欧几里得符号距离场（ESDF）图，利用分析占用梯度和闭式ESDF进行路径优化，并预测未观测区域。对于UGV，模型表征地形并提供闭式梯度，实现在线规避障碍。

**Result:** 在时间、内存和精度方面展现出卓越的建图性能，并实现了高速UAV和UGV的计算高效、安全导航。

**Conclusion:** RMRP和RPATR框架有效解决了移动机器人在复杂环境中的导航挑战，提供了高效、安全的感知感知轨迹规划能力。

> **ai_Abstract:** 该论文提出了一种名为随机映射和随机投影（RMRP）的新方法，用于构建轻量级线性参数图，并通过残余能量保持定理提供理论支持。在此基础上，开发了鲁棒感知感知轨迹规划器（RPATR）框架，旨在解决移动机器人在复杂环境中导航时面临的计算负担、传感器遮挡和地形遍历等挑战。该框架为无人机和地面机器人提供了统一的解决方案，通过预测未观测区域和提供闭式梯度来实现高效、安全的感知感知轨迹规划。实验证明，该方法在建图性能和导航效率方面均表现出色。

> **摘要翻译:** 移动机器人依赖于感知和规划的自主导航，在大型复杂环境中面临重大障碍。其中包括建图的巨大计算负担、无人机（UAV）传感器遮挡失效以及地面机器人（UGV）在不规则地形上遍历的挑战，所有这些都因缺乏感知感知策略而加剧。为了解决这些挑战，我们引入了随机映射和随机投影（RMRP）。该方法通过首先将数据映射到高维空间，然后进行稀疏随机投影以降低维度，从而构建一个轻量级的线性参数图。我们新颖的残余能量保持定理为这一过程提供了理论保证，确保关键的几何特性得以保留。基于该图，我们提出了RPATR（鲁棒感知感知轨迹规划器）框架。对于无人机，我们的方法统一了网格图和欧几里得符号距离场（ESDF）图。前端使用分析占用梯度来细化初始路径以确保安全性和平滑性，而后端使用闭式ESDF进行轨迹优化。利用训练好的RMRP模型的泛化能力，规划器可以预测未观测区域以进行主动导航。对于地面机器人，该模型表征地形并提供闭式梯度，从而实现在线规划以规避大洞。我们的框架在各种场景中得到验证，展示了在时间、内存和精度方面的卓越建图性能，并使高速无人机和地面机器人能够进行计算高效、安全的导航。代码将发布以促进社区协作。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [793] [MIBoost: A Gradient Boosting Algorithm for Variable Selection After Multiple Imputation](https://arxiv.org/abs/2507.21807)
> *MIBoost：一种多重插补后变量选择的梯度提升算法*

*Robert Kuchen* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 变量选择, 多重插补, 梯度提升, MIBoost, 缺失数据

**Comment:** 

> **TL;DR:** MIBoost是一种新的梯度提升算法，用于处理多重插补后数据的变量选择问题，其预测性能与现有方法相当。

**AI_Comments:** 该论文的创新点在于将“统一损失函数”的原则首次应用于梯度提升算法，以解决多重插补后变量选择的挑战，这对于处理实际数据中常见的缺失值问题具有重要意义。它提供了一个比现有简单方法更优，且比复杂方法更易于实现的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在实际应用中，自动化变量选择的统计学习方法常因缺失数据而复杂化。多重插补是处理缺失数据的常用方法，但在多重插补数据集上进行模型选择仍存在争议，现有简单策略效果不佳，复杂方法难以实现。

**Method:** 本文提出了MIBoost，这是一种新颖的算法，它将统一损失函数的原则扩展到分量式梯度提升框架中，从而在多重插补数据集中采用统一的变量选择机制。

**Result:** 模拟研究表明，MIBoost的预测性能与近期提出的其他方法相当。

**Conclusion:** MIBoost算法为多重插补后的变量选择提供了一种有效且实用的解决方案，其性能与现有先进方法相当。

> **ai_Abstract:** 本文提出MIBoost，一种新的梯度提升算法，旨在解决多重插补后数据集的变量选择问题。针对现有模型选择策略在多重插补数据中表现不佳或难以实现的问题，MIBoost将统一损失函数的原理应用于梯度提升框架，实现了跨插补数据集的统一变量选择机制。模拟研究表明，MIBoost的预测性能与近期提出的其他相关方法相当。

> **摘要翻译:** 统计学习方法，如LASSO、弹性网络或梯度提升，作为构建强大预测模型的自动化变量选择工具，已变得越来越流行。然而，在实践中，分析常常因缺失数据而复杂化。处理缺失数据最广泛使用的方法是多重插补，它涉及创建几个完整的数据集。然而，关于如何在存在多个插补数据集的情况下执行模型选择，仍存在持续的争议。简单的策略，例如跨数据集汇集模型，已被证明具有次优的特性。尽管存在更复杂的方法，但它们通常难以实现，因此未被广泛应用。相比之下，最近的两种方法通过定义单一损失函数来修改正则化方法LASSO和弹性网络，从而在不同插补中产生统一的系数集。我们的关键贡献是将这一原则扩展到分量式梯度提升框架中，提出了MIBoost，这是一种新颖的算法，它在插补数据集中采用统一的变量选择机制。模拟研究表明，我们的方法产生的预测性能与这些最近提出的方法相当。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [798] [Efficient optimization of expensive black-box simulators via marginal means, with application to neutrino detector design](https://arxiv.org/abs/2508.01834)
> *通过边际均值对昂贵的黑盒模拟器进行高效优化，及其在中微子探测器设计中的应用*

*Hwanwoo Kim, Simon Mak, Ann-Kathrin Schuetz, Alan Poon* | **Category: cs.LG, stat.CO, stat.ME, stat.ML** | **Updated: 2025-08-07**

**Keywords:** 黑盒优化, 边际均值, 维度灾难, 昂贵模拟器, 中微子探测器设计

**Comment:** 

> **TL;DR:** 提出了一种新的黑盒优化方法BOMM，通过利用边际均值来克服现有方法的维度灾难，并在高维昂贵模拟器优化中表现出更好的性能，尤其适用于中微子探测器设计。

**AI_Comments:** 这篇论文的创新点在于提出了BOMM方法，通过引入边际均值函数来解决高维昂贵黑盒优化中的“维度灾难”问题。与传统“赢者通吃”方法相比，BOMM能够更有效地探索未评估空间，这对于计算资源有限的实际应用（如核物理探测器设计）具有重要意义。理论证明其一致性和对维度灾难的缓解，增强了其可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的黑盒优化方法在优化高维、昂贵的黑盒模拟器时（例如核物理探测器优化），由于每次运行成本高昂且现有方法多采用“赢者通吃”策略，导致优化性能不佳，尤其是在维度增加时效果更差。

**Method:** 提出了一种新的黑盒优化方法——边际均值黑盒优化（BOMM）。其核心思想是利用边际均值函数来估计全局最优解，该函数在高维情况下也能通过有限的运行高效推断。与现有方法不同，BOMM的估计器可以选择未评估过的输入作为解决方案，以提高优化性能。该方法使用变换后的加性高斯过程替代模型实现。

**Result:** 理论上，BOMM估计器不仅在优化上具有一致性，而且其优化速率能够缓解现有方法面临的“维度灾难”，从而在维度增加时表现出更好的性能。数值实验和中微子探测器优化应用都证明了BOMM的有效性。

**Conclusion:** BOMM通过利用边际均值提供了一种高效且一致的黑盒优化方法，在高维、昂贵模拟器优化中显著优于现有方法，并有效缓解了维度灾难问题。

> **ai_Abstract:** 本文提出了一种名为BOMM（Black-box Optimization via Marginal Means）的新型黑盒优化方法，旨在解决高维、昂贵黑盒模拟器优化中的挑战。现有方法常因“赢者通吃”策略在高维环境下性能不佳。BOMM通过引入利用边际均值函数的新型全局优化器估计器，能够在有限运行次数下高效推断，并选择未评估的输入作为解决方案。理论分析证明，BOMM在优化上具有一致性，并能有效缓解“维度灾难”。实验结果，包括中微子探测器设计应用，验证了其有效性。

> **摘要翻译:** 随着科学计算的进步，计算机实验越来越多地用于优化复杂系统。然而，对于现代应用，例如核物理探测器的优化，每次实验运行可能需要数百个CPU小时，这使得在高维空间中优化其黑盒模拟器成为一项具有挑战性的任务。在输入$\mathbf{x}_1, \cdots, \mathbf{x}_n$的有限运行下，从这些评估过的输入中选出的最佳解决方案可能远非最优，特别是随着维度的增加。然而，现有的黑盒方法大多采用这种“赢者通吃”（PW）解决方案，这导致了平庸的优化性能。为了解决这个问题，我们提出了一种新的通过边际均值进行黑盒优化（BOMM）的方法。其关键思想是一种全局优化器$\mathbf{x}^*$的新估计器，它利用了所谓的边际均值函数，该函数可以在高维情况下通过有限的运行高效推断。与PW不同，该估计器可以选择超出已评估输入的解决方案，从而提高优化性能。假设目标函数遵循具有未知链接函数的广义加性模型，并且在温和的条件下，我们证明了BOMM估计器不仅在优化上具有一致性，而且其优化速率能够缓解现有方法面临的“维度灾难”，从而在维度增加时实现更好的性能。我们提出了一个使用变换后的加性高斯过程替代模型实现BOMM的实用框架。最后，我们通过数值实验和在核物理中微子探测器优化应用中证明了BOMM的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [13] [Probabilistic Alternating Simulations for Policy Synthesis in Uncertain Stochastic Dynamical Systems](https://arxiv.org/abs/2508.05062)
> *不确定随机动力系统中策略合成的概率交替仿真*

*Thom Badings, Alessandro Abate* | **Category: cs.LO, eess.SY, math.OC** | **Updated: 2025-08-07**

**Keywords:** 概率交替仿真, 策略合成, 不确定随机系统, 非确定性扰动, 概率仿真关系

**Comment:** 

> **TL;DR:** 本文提出了一种扩展的概率仿真关系，用于处理同时存在随机性和非确定性扰动的系统，并将其应用于策略合成。

**AI_Comments:** 这篇论文的创新点在于提出了一个能够同时处理随机性和非确定性不确定性的概率交替仿真关系，解决了传统概率仿真在复杂系统建模中的局限性。其重要性在于为不确定随机系统中的策略合成和验证提供了更精确的理论基础和工具。

<details>
  <summary>Details</summary>

**Motivation:** 经典的概率仿真关系不足以处理同时存在随机性和非确定性扰动的系统，当系统动力学除了随机性之外，还受到非确定性（即集合值）扰动时，需要一种新的行为关系来确保抽象的正确性。

**Method:** 本文将概率仿真关系扩展到同时具有随机和非确定性扰动的系统，提出了一种受交替仿真概念启发的概率交替仿真关系。该关系允许对随机不确定性进行概率推理，同时对非确定性扰动进行鲁棒（即对抗性）推理。

**Result:** 所提出的关系在4D状态Dubins车辆的策略合成中得到了实验证明，显示了其适用性。

**Conclusion:** 所提出的概率交替仿真关系有效解决了不确定随机动力系统中同时存在随机性和非确定性扰动时策略合成的挑战，并具有实际应用潜力。

> **ai_Abstract:** 本文针对不确定随机动力系统中的策略合成问题，提出了一种新的概率交替仿真关系。该关系扩展了传统的概率仿真关系，使其能够同时处理系统中的随机不确定性和非确定性扰动。通过结合概率推理和鲁棒推理，该方法为在复杂环境下进行正确的行为关系建模提供了工具，并在Dubins车辆的策略合成中得到了实验验证。

> **摘要翻译:** 随机动力系统中形式化策略合成的经典方法是构建有限状态抽象，通常表示为马尔可夫决策过程（MDP）。这些方法的正确性取决于动力系统与其抽象之间的行为关系，例如概率仿真关系。然而，当系统动力学除了随机性之外，还受到非确定性（即集合值）扰动时，概率仿真关系就不够用了。在这项工作中，我们将概率仿真关系扩展到同时具有随机和非确定性扰动的系统。我们的关系受到交替仿真概念的启发，概括了现有用于验证和策略合成的关系。直观地，我们的关系允许对随机不确定性进行概率推理，同时对非确定性扰动进行鲁棒（即对抗性）推理。我们通过实验证明了我们的关系在4D状态Dubins车辆的策略合成中的适用性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [20] [Universal quantification makes automatic structures hard to decide](https://arxiv.org/abs/2306.10432)
> *全称量化使得自动结构难以判定*

*Christoph Haase, Radosław Piórkowski* | **Category: cs.LO** | **Updated: 2025-08-06**

**Keywords:** 自动结构, 全称量化, 复杂性, 下界, EXPSPACE

**Comment:** 

> **TL;DR:** 本研究表明，在自动结构中消除全称量词会导致双指数级的膨胀，并且判定相关语言的空性是EXPSPACE完全的，这否定了避免幼稚双指数膨胀的可能性。

**AI_Comments:** 本文通过提供强有力的下界，对自动结构中全称量词消除的固有复杂性给出了明确的答案，解决了长期存在的开放问题。其创新之处在于构造了具体的反例和技术，证明了双指数膨胀在最坏情况下是不可避免的，并进一步将这些技术应用于其他逻辑片段，展现了其方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，消除全称量词（通过双重补码）在自动结构中可能导致双指数级的状态膨胀。尽管有一些方法可以避免这种膨胀，并且已知某些情况下单指数膨胀是不可避免的，但对于是否能避免幼稚的双指数膨胀（尤其是在受限设置中），仍是一个悬而未决的问题。本文旨在回答这个问题。

**Method:** 本文通过构造一族表示自动关系的非确定性有限自动机（NFA），证明了在消除单个全称量词后，识别所得语言的最小NFA是双指数级的。此外，还证明了判定该语言是否为空是EXPSPACE完全的。

**Result:** 研究结果表明，存在一族NFA，对于它们而言，消除单个全称量词后，识别所得语言的最小NFA是双指数级的。此外，判定该语言是否为空是EXPSPACE完全的。这些技术还为带有固定量词交替数的Büchi算术的某些片段建立了新的下界。

**Conclusion:** 本研究否定地回答了关于是否能避免自动结构中全称量词消除的双指数膨胀的问题，证明了在最坏情况下这种膨胀是不可避免的，并且相关语言的空性判定是EXPSPACE完全的，从而揭示了全称量化对自动结构判定的固有难度。

> **ai_Abstract:** 本文研究了自动结构中全称量词消除的复杂性。自动结构是其域和关系可用正则语言表示的一阶结构，其一阶理论是可判定的。虽然存在量词可以线性时间消除，但全称量词通常通过双重补码消除，这可能导致双指数级的状态膨胀。尽管有研究探索了避免这种膨胀的方法，并且已知某些情况下单指数膨胀是不可避免的，但能否完全避免双指数膨胀仍是开放问题。本文通过构造特定的NFA族，证明了消除单个全称量词后，最小NFA的大小是双指数级的，并且判定所得语言的空性是EXPSPACE完全的。这否定了避免幼稚双指数膨胀的可能性，并为Büchi算术的某些片段建立了新的下界。

> **摘要翻译:** 自动结构是其域和关系可以表示为正则语言的一阶结构。根据正则语言的标准闭包性质，自动结构的一阶理论是可判定的。虽然存在量词可以通过应用同态在线性时间内消除，但全称量词通常通过恒等式 $\forall{x}. \Phi \equiv \neg (\exists{x}. \neg \Phi)$ 来消除。如果 $\Phi$ 以标准方式表示为NFA，这种方法先验地会导致双指数级的膨胀。然而，最近的文献表明，对于某些类别的自动结构，可以通过不同的方式消除全称量词而不会出现这种膨胀，即将其视为一等公民，而不是诉诸双重补码。虽然某些类别的自动结构的现有下界表明，消除一个全称量词时单指数膨胀是不可避免的，但尚不清楚是否存在更好的方法可以避免幼稚的双指数膨胀，也许至少在受限设置中可以。\n在本文中，我们否定地回答了这个问题，并表明存在一族表示自动关系的NFA，对于它们而言，消除单个全称量词后识别该语言的最小NFA是双指数级的，并且判定该语言是否为空是EXPSPACE完全的。\n我们EXPSPACE下界所依据的技术进一步使我们能够为具有固定数量量词交替的Büchi算术的某些片段建立新的下界。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [27] [Modular Reasoning about Error Bounds for Concurrent Probabilistic Programs (Extended Version)](https://arxiv.org/abs/2503.04512)
> *并发概率程序错误界限的模块化推理（扩展版）*

*Kwing Hei Li, Alejandro Aguirre, Simon Oddershede Gregersen, Philipp G. Haselwarter, Joseph Tassarotti, Lars Birkedal* | **Category: cs.LO, cs.PL** | **Updated: 2025-08-07**

**Keywords:** 并发概率程序, 错误界限, 分离逻辑, 模块化推理, 随机逻辑原子性

**Comment:** 

> **TL;DR:** Coneris是一种新的高阶并发分离逻辑，用于模块化推理高阶并发概率程序的错误概率界限，引入了随机逻辑原子性。

**AI_Comments:** 这项工作在并发程序验证领域具有重要创新性，特别是在处理概率方面。通过引入“随机逻辑原子性”和在分离逻辑框架中进行机械化验证，Coneris为推理复杂概率并发程序的可靠性提供了坚实的基础。其扩展性到高阶程序和状态也增加了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的程序逻辑通过逻辑原子性来支持并发（非概率）程序模块的模块化推理。本文的动机在于将这种模块化推理扩展到并发概率程序模块，以推理其错误概率界限。

**Method:** 提出了Coneris，这是第一个用于推理高阶并发概率程序错误概率界限的高阶并发分离逻辑。Coneris通过在逻辑中捕获一种新颖的“随机逻辑原子性”概念来实现对概率并发模块的模块化推理。为此，Coneris利用预采样磁带和一种新颖的概率更新模态来描述线性化点处状态如何概率性地变化。

**Result:** 该方法通过小型合成示例和大型案例研究进行了演示。所有提出的结果，包括元理论，都已在Rocq证明助手和Iris分离逻辑框架中进行了机械化验证。

**Conclusion:** Coneris成功地将模块化推理扩展到了并发概率程序，提供了一种新颖的框架来推理它们的错误概率界限，并通过机械化验证得到了支持。

> **ai_Abstract:** 本文介绍了Coneris，一个首创的高阶并发分离逻辑，旨在对高阶并发概率程序的错误概率界限进行模块化推理。它通过引入“随机逻辑原子性”概念，并利用预采样磁带和概率更新模态，将现有非概率程序逻辑的模块化推理扩展到概率领域。该方法已通过示例和案例研究进行演示，并且其理论和结果已在Rocq和Iris框架中得到机械化验证。

> **摘要翻译:** 我们提出了Coneris，这是第一个用于推理具有高阶状态的高阶并发概率程序的错误概率界限的高阶并发分离逻辑。为了支持对并发（非概率）程序模块的模块化推理，最先进的程序逻辑通过逻辑原子性概念在逻辑内部化了经典的线性化概念。
Coneris将这一思想扩展到概率并发程序模块。因此，Coneris通过在逻辑中捕获一种新颖的随机逻辑原子性概念来支持对概率并发模块的模块化推理。为此，Coneris利用预采样磁带和一种新颖的概率更新模态来描述线性化点处状态如何概率性地变化。我们通过小型合成示例和大型案例研究演示了这种方法。
所有提出的结果，包括元理论，都已在Rocq证明助手和Iris分离逻辑框架中进行了机械化验证。
这是在ICFP 2025上接受的同一篇论文的扩展版本，其中附录中包含了更多证明和案例研究的详细信息。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [34] [2-Coherent Internal Models of Homotopical Type Theory](https://arxiv.org/abs/2503.05790)
> *同伦类型论的2-相干内部模型*

*Joshua Chen* | **Category: cs.LO, math.CT, math.LO** | **Updated: 2025-08-06**

**Keywords:** 同伦类型论, 内部模型, 范畴与族, 2-相干, 依赖类型论

**Comment:** 

> **TL;DR:** 本文通过放宽范畴与族（cwf）的概念，引入2-相干的“野性”或预相干高阶cwf，以研究内部同伦类型论，并定义了分裂2-相干野性cwf，从而实现了同伦类型论2-相干反射的内部化。

**AI_Comments:** 本文通过引入“野性”或预相干高阶cwf的概念，并定义了分裂2-相干的“野性”cwf，为同伦类型论的内部模型理论提供了新的视角和工具。其创新性在于对现有范畴与族概念的泛化，并成功实现了同伦类型论2-相干反射的内部化，这对于理解和发展依赖类型论的范畴模型具有重要意义。该理论的普适性也体现在其能特化为低维高阶cwf，并可能包含其他重要模型。

<details>
  <summary>Details</summary>

**Motivation:** 内部类型论旨在利用依赖类型论自身的语言来发展其范畴模型理论。本文在此基础上，旨在研究内部同伦类型论。

**Method:** 通过将范畴与族（cwf）的概念放宽为“野性”或预相干高阶cwf，并确定足以恢复依赖类型论模型预期性质的相干条件。

**Result:** 定义了一个分裂2-相干的“野性”cwf，该定义将语法和由全集类型给出的“标准模型”都作为实例。这使得同伦类型论自身2-相干反射的概念能够被直接内部化，即作为从语法到标准模型的2-相干野性cwf态射。此外，该理论还能轻松特化以给出“低维”高阶cwf的定义。

**Conclusion:** 本文的理论能够轻松特化以给出“低维”高阶cwf的定义，并且推测性地将容器高阶模型作为进一步的实例。

> **ai_Abstract:** 本文研究内部同伦类型论，通过放宽范畴与族（cwf）的概念至“野性”或预相干高阶cwf，并确定了必要的相干条件。研究成果是定义了一种分裂2-相干的“野性”cwf，它能够将同伦类型论的语法和标准模型都作为实例，从而实现了2-相干反射的内部化。此外，该理论还能推广到低维高阶cwf，并可能包含容器高阶模型。

> **摘要翻译:** 内部类型论旨在利用依赖类型论自身的语言来发展其范畴模型理论。在当前的工作中，我们通过将范畴与族（cwf）的概念放宽为“野性”或预相干高阶cwf来研究内部同伦类型论，并确定了足以恢复依赖类型论模型预期性质的相干条件。结果是定义了一个分裂2-相干的“野性”cwf，该定义将语法和由全集类型给出的“标准模型”都作为实例。这将使我们能够直接内部化同伦类型论自身2-相干反射的概念：即作为从语法到标准模型的2-相干野性cwf态射。我们的理论也能轻松特化以给出“低维”高阶cwf的定义，并且推测性地将容器高阶模型作为进一步的实例。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [42] [Qunity: A Unified Language for Quantum and Classical Computing (Extended Version)](https://arxiv.org/abs/2204.12384)
> *Qunity：一种统一的量子与经典计算语言（扩展版）*

*Finn Voichick, Liyi Li, Robert Rand, Michael Hicks* | **Category: cs.LO, cs.PL, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子编程语言, 统一语法, 指称语义, BQP子程序定理, 量子计算

**Comment:** 

> **TL;DR:** Qunity是一种新的量子编程语言，它将量子计算视为经典计算的自然泛化，通过统一语法和新颖的指称语义实现量子与经典计算的融合，并能编译为量子电路。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的编程语言Qunity，它将量子计算和经典计算融合在一个语法框架内，而非传统地将量子特性作为附加组件。其利用BQP子程序定理进行可逆子程序构建以及提供新颖的指称语义来保证量子力学有效性是其重要贡献。这为未来量子与经典混合计算的编程范式提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有量子编程语言通常将量子特性作为经典语言的附加组件，缺乏统一性。本文的动机是设计一种新的量子编程语言Qunity，将量子计算视为经典计算的自然泛化，提供统一的语法，使熟悉的编程构造同时具有量子和经典效果，从而解决现有语言的集成问题。

**Method:** 引入了Qunity编程语言，它具有统一的语法，允许熟悉的编程构造同时具有量子和经典效果，例如使用和类型实现线性算子的直和，异常处理语法实现投影测量，以及别名诱导纠缠。Qunity利用了BQP子程序定理，通过“垃圾”输出的非计算，从不可逆量子算法构建可逆子程序。此外，Qunity提供了一种新颖的指称语义，确保程序在量子力学上有效。论文还介绍了Qunity的语法、类型系统和指称语义。

**Result:** Qunity能够清晰地表达多种量子算法。该设计可以被编译成OpenQASM等低级量子比特电路语言，证明了其可实现性。Qunity通过统一语法和新颖的指称语义，保证了程序的量子力学有效性。

**Conclusion:** Qunity成功地将量子计算作为经典计算的自然泛化，提供了一种统一的编程语言，其设计不仅在理论上通过指称语义保证了程序的量子有效性，而且在实践中也证明了其可编译性和表达能力。

> **ai_Abstract:** Qunity是一种新型量子编程语言，旨在将量子计算自然地泛化为经典计算。它通过统一的语法和新颖的指称语义，使得熟悉的编程构造能同时产生量子和经典效应，并利用BQP子程序定理实现从不可逆算法构建可逆子程序。该语言能够清晰表达量子算法，并可编译为低级量子电路语言，证明了其设计的有效性和可实现性。

> **摘要翻译:** 我们引入了Qunity，一种新的量子编程语言，旨在将量子计算视为经典计算的自然泛化。Qunity呈现了一种统一的语法，其中熟悉的编程构造可以同时具有量子和经典效果。例如，可以使用和类型来实现线性算子的直和，使用异常处理语法来实现投影测量，以及使用别名来诱导纠缠。此外，Qunity利用了被忽视的BQP子程序定理，允许通过“垃圾”输出的非计算，从不可逆量子算法构建可逆子程序。与现有语言通过单独的附加组件（如附加量子门的经典语言）实现量子方面不同，Qunity提供了一种统一的语法和一种新颖的指称语义，保证程序在量子力学上有效。我们介绍了Qunity的语法、类型系统和指称语义，展示了它如何清晰地表达多种量子算法。我们还详细说明了Qunity如何编译成OpenQASM等低级量子比特电路语言，证明了我们设计的可实现性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [48] [BTPG-max: Achieving Local Maximal Bidirectional Pairs for Bidirectional Temporal Plan Graphs](https://arxiv.org/abs/2508.04849)
> *BTPG-max: 为双向时间计划图实现局部最大双向对*

*Yifan Su, Rishi Veerapaneni, Jiaoyang Li* | **Category: cs.MA, cs.RO** | **Updated: 2025-08-06**

**Keywords:** 多智能体路径规划, 双向时间计划图, 延迟, 鲁棒性, 局部最优

**Comment:** 

> **TL;DR:** BTPG-max算法通过找到更多的双向对来改进BTPG，从而提高多智能体路径规划在延迟情况下的效率和鲁棒性。

**AI_Comments:** 本文通过引入BTPG-max算法，在理论上实现了局部最优的双向对发现，并显著提升了多智能体路径规划在实际延迟环境中的适应性和鲁棒性，对实时MAPF系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体路径规划（MAPF）的现有解决方案在真实系统中因延迟而难以直接遵循，导致碰撞。TPG和BTPG旨在解决这个问题，而BTPG-max旨在进一步提升BTPG在处理延迟方面的效率和鲁棒性。

**Method:** 本文提出了BTPG-max算法，旨在找到局部最大数量的双向对，即构造一个无法添加更多双向对的BTPG。

**Result:** 实践中，BTPG-max生成的BTPG具有显著更多的双向边，表现出更优的随时性行为，并提高了对延迟的鲁棒性。

**Conclusion:** BTPG-max通过优化BTPG中的双向对数量，显著提高了多智能体路径规划在实际延迟环境中的执行效率和鲁棒性。

> **ai_Abstract:** 本文提出了BTPG-max算法，旨在改进多智能体路径规划中的双向时间计划图（BTPG）。针对现有MAPF解决方案在实际延迟环境中难以应用的问题，BTPG-max通过寻找局部最大数量的双向对来优化BTPG的构建，从而显著增加双向边，提升了智能体在延迟下执行路径的效率和鲁棒性，并展现出优越的随时性行为。

> **摘要翻译:** 多智能体路径规划（MAPF）需要在共享环境中为多个智能体计算无碰撞路径。大多数MAPF规划器假设每个智能体在特定时间步到达特定位置，但这在经常发生延迟的真实系统中难以直接遵循。为了解决因智能体偏离延迟引起的碰撞，提出了时间计划图（TPG），它将MAPF时间依赖的解决方案转换为一组时间独立的智能体间依赖关系。最近，提出了一种双向TPG（BTPG），它将一些依赖关系放宽为“双向对”，提高了智能体在延迟情况下执行其MAPF解决方案的效率。我们的工作通过设计一种算法BPTG-max来改进这项现有工作，该算法可以找到更多的双向对。我们的主要理论贡献在于设计BTPG-max算法是局部最优的，即它构造了一个无法添加额外双向对的BTPG。我们还展示了在实践中BTPG-max如何导致BTPG具有显著更多的双向边、更优的随时性行为，并提高了对延迟的鲁棒性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [55] [Congestion Mitigation Path Planning for Large-Scale Multi-Agent Navigation in Dense Environments](https://arxiv.org/abs/2508.05253)
> *大规模多智能体密集环境导航中的拥堵缓解路径规划*

*Takuro Kato, Keisuke Okumura, Yoko Sasaki, Naoya Yokomachi* | **Category: cs.MA** | **Updated: 2025-08-07**

**Keywords:** 拥堵缓解, 路径规划, 多智能体系统, 密集环境, A-CMTS

**Comment:** 

> **TL;DR:** 本文提出一种新的路径规划问题CMPP，通过在成本函数中嵌入拥堵来缓解大规模多智能体系统在密集环境中的局部拥堵，并开发了两种求解器，实验证明能显著提高系统吞吐量。

**AI_Comments:** 本文创新性地将拥堵直接建模为路径规划的成本函数，通过惩罚高流量交叉点来全局优化多智能体流。其提出的A-CMTS算法为大规模问题提供了实用解决方案。这项工作对提升多智能体系统在复杂环境下的导航效率和吞吐量具有重要意义，特别是在物流和自动驾驶等领域。

<details>
  <summary>Details</summary>

**Motivation:** 在大量自主智能体同时以分布式方式移动的高密度环境中，优化全局流以缓解局部拥堵对于维持整体导航效率至关重要。

**Method:** 本文引入了一种新的拥堵缓解路径规划（CMPP）问题，将拥堵直接嵌入到成本函数中，该函数由智能体路径上入边的使用情况定义。CMPP对稀疏图的每个顶点分配基于流的乘法惩罚，该惩罚在频繁遍历路径交叉处急剧增加。为求解该问题，开发了两种求解器：(i) 针对小规模实例的精确混合整数非线性规划求解器；(ii) 针对大规模实例的可扩展两层搜索算法A-CMTS，能快速找到次优解并迭代优化。

**Result:** 经验研究表明，将CMPP增强到最先进的避碰规划器中，在离散和连续空间场景中均显著减少了局部拥堵并提高了系统吞吐量。

**Conclusion:** 这些结果表明CMPP提高了多智能体系统在物流和自动驾驶等实际应用中的性能。

> **ai_Abstract:** 本文提出拥堵缓解路径规划（CMPP）问题，旨在通过在成本函数中直接嵌入拥堵惩罚来优化大规模多智能体在密集环境中的导航效率。CMPP通过对频繁交叉路径顶点施加乘法惩罚来模拟拥堵，并生成粗粒度路径。为解决该问题，开发了精确的混合整数非线性规划求解器（适用于小规模）和可扩展的A-CMTS两层搜索算法（适用于大规模）。实验证明，结合CMPP能显著减少局部拥堵并提高系统吞吐量，从而提升多智能体系统在实际应用中的性能。

> **摘要翻译:** 在大量自主智能体同时以分布式方式移动的高密度环境中，优化全局流以缓解局部拥堵对于维持整体导航效率至关重要。本文介绍了一种新颖的路径规划问题，即拥堵缓解路径规划（CMPP），它将拥堵直接嵌入到成本函数中，该成本函数由智能体路径上入边的使用情况定义。CMPP对稀疏图的每个顶点分配基于流的乘法惩罚，该惩罚在频繁遍历路径交叉处急剧增加，这捕捉了许多智能体从不同方向进入同一区域时拥堵加剧的直觉。最小化总成本可生成一组粗粒度、与时间无关的路线，自主智能体可以遵循这些路线，同时应用自己的局部避碰策略。我们提出了该问题并开发了两种求解器：(i) 针对小规模实例的精确混合整数非线性规划求解器；(ii) 一种可扩展的两层搜索算法A-CMTS，它能快速找到大规模实例的次优解并迭代地将其优化到最优。经验研究表明，将CMPP增强到最先进的避碰规划器中，在离散和连续空间场景中均显著减少了局部拥堵并提高了系统吞吐量。这些结果表明CMPP提高了多智能体系统在物流和自动驾驶等实际应用中的性能。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [62] [Towards Language-Augmented Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2506.05236)
> *面向语言增强的多智能体深度强化学习*

*Maxime Toquebiau, Jae-Yun Jun, Faïz Benamar, Nicolas Bredeche* | **Category: cs.MA** | **Updated: 2025-08-06**

**Keywords:** 多智能体强化学习, 自然语言, 涌现通信, 可解释性, 语言增强

**Comment:** 

> **TL;DR:** 本文提出了一种语言增强的多智能体深度强化学习框架，通过让智能体生成和解释自然语言来提高学习和协调效率，并解决了现有隐式通信方法效率低下和不可解释的问题。

**AI_Comments:** 本文的创新点在于将人类定义的自然语言引入多智能体强化学习中，以解决传统涌现通信的可解释性差和效率低的问题。通过让智能体学习生成和解释语言，不仅提升了通信效率和可解释性，还改善了内部表征和泛化能力，为构建更智能、更易于理解的多智能体系统提供了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数多智能体强化学习中的通信工作都集中在涌现通信上，这往往导致系统效率低下且不可解释。受语言在自然智能中作用的启发，本文旨在研究如何将智能体基于人类定义的语言来改善具身智能体的学习和协调。

**Method:** 本文提出了一种框架，其中智能体不仅被训练来行动，还被训练来生成和解释对其观察的自然语言描述。这种语言增强的学习具有双重作用：实现智能体之间高效且可解释的通信，并指导表征学习。

**Result:** 实验表明，语言增强的智能体在各种任务中都优于涌现通信基线。分析显示，语言基础导致更具信息量的内部表征，更好地泛化到新伙伴，并提高了人机交互的能力。

**Conclusion:** 这些发现证明了将结构化语言整合到多智能体学习中的有效性，并为更可解释和更有能力的多智能体系统开辟了道路。

> **ai_Abstract:** 本文提出了一种语言增强的多智能体深度强化学习框架，旨在解决现有涌现通信方法效率低下和不可解释的问题。该框架训练智能体不仅行动，还能生成和解释自然语言描述，从而实现高效可解释的通信并指导表征学习。实验证明，该方法在多项任务中优于基线，并能生成更具信息量的内部表征，提高泛化能力和人机交互性，表明结构化语言对多智能体学习的有效性。

> **摘要翻译:** 大多数关于多智能体强化学习中通信的现有工作都侧重于涌现通信，这通常会导致低效且不可解释的系统。受语言在自然智能中作用的启发，我们研究了如何将智能体基于人类定义的语言来改善具身智能体的学习和协调。我们提出了一种框架，其中智能体不仅被训练来行动，还被训练来生成和解释对其观察的自然语言描述。这种语言增强的学习具有双重作用：实现智能体之间高效且可解释的通信，并指导表征学习。我们证明了语言增强的智能体在各种任务中都优于涌现通信基线。我们的分析揭示，语言基础导致更具信息量的内部表征，更好地泛化到新伙伴，并提高了人机交互的能力。这些发现证明了将结构化语言整合到多智能体学习中的有效性，并为更可解释和更有能力的多智能体系统开辟了道路。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [69] [Position-Based Flocking for Robust Alignment](https://arxiv.org/abs/2508.04378)
> *基于位置的群体行为模型实现鲁棒对齐*

*Hossein B. Jond* | **Category: cs.MA, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 群体行为, 基于位置, 鲁棒对齐, 集体运动, 机器人

**Comment:** 

> **TL;DR:** 本文提出一种基于位置的群体行为模型，通过近似速度差并引入阈值权重，实现了更强的对齐和鲁棒的群体运动。

**AI_Comments:** 该论文的创新点在于，它仅通过智能体的初始和当前位置来近似速度差，并引入阈值权重来确保持续的对齐，从而简化了模型的同时实现了更强的鲁棒性。这对于需要稳定集体行为的机器人和分布式系统等应用具有重要意义，尤其是在速度信息难以直接获取或存在噪声的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过平衡凝聚-分离和对齐，实现稳定的集体运动，并解决现有基于位置-速度模型在对齐方面的不足，确保持续的鲁棒对齐。

**Method:** 提出一种基于位置的群体行为模型，通过初始位置和当前位置近似速度差，并引入阈值权重以确保持续的对齐。

**Result:** 在2D环境下对50个智能体的仿真结果表明，与基于位置-速度的模型相比，所提出的基于位置的模型产生了更强的对齐，以及更紧密和紧凑的队形。对齐度量和分离距离凸显了该模型在实现鲁棒群体行为方面的有效性。

**Conclusion:** 该模型利用位置信息确保了鲁棒的对齐，并在机器人和集体动力学领域具有应用潜力。

> **ai_Abstract:** 本文提出一种新颖的基于位置的群体行为模型，旨在通过平衡凝聚-分离和对齐实现稳定的集体运动。该模型通过初始和当前位置近似速度差，并引入阈值权重，改进了传统的基于位置-速度的方法。仿真结果显示，相比现有模型，该模型能产生更强的对齐和更紧凑的队形，有效实现鲁棒的群体行为，并在机器人和集体动力学领域具有潜在应用。

> **摘要翻译:** 本文提出了一种用于交互式智能体的基于位置的群体行为模型，通过平衡凝聚-分离和对齐来实现在稳定的集体运动。该模型通过使用初始位置和当前位置近似速度差，修改了基于位置-速度的方法，并引入了一个阈值权重以确保持续的对齐。在2D环境下对50个智能体的仿真结果表明，与基于位置-速度的模型相比，基于位置的模型产生了更强的对齐以及更紧密和紧凑的队形。对齐度量和分离距离突出了所提出模型在实现鲁棒群体行为方面的有效性。该模型利用位置信息确保了鲁棒的对齐，并在机器人和集体动力学领域具有应用潜力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [78] [Adaptive Inference through Bayesian and Inverse Bayesian Inference with Symmetry-Bias in Nonstationary Environments](https://arxiv.org/abs/2505.12796)
> *自适应推理：基于贝叶斯和逆贝叶斯推理在非平稳环境中的对称偏差*

*Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Yoshihiro Nakajima, Yukio-Pegio Gunji, Ung-il Chung* | **Category: cs.MA, stat.ME** | **Updated: 2025-08-07**

**Keywords:** 贝叶斯推理, 逆贝叶斯推理, 自适应推理, 非平稳环境, 临界状态

**Comment:** 

> **TL;DR:** 提出一种结合对称偏差的贝叶斯和逆贝叶斯（BIB）推理框架，解决了传统贝叶斯推理在非平稳环境中适应性与准确性之间的权衡问题，并通过动态学习率和临界状态操作实现高效自适应。

**AI_Comments:** 本文提出了一种创新的BIB推理框架，通过引入“对称偏差”和动态学习率机制，有效地解决了传统贝叶斯方法在非平稳环境下适应性和准确性之间的长期矛盾。其核心创新在于发现BIB系统在临界状态下运行，这不仅解释了其优越的性能，也为理解自然系统中的无标度动力学提供了计算视角，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统贝叶斯推理在非平稳环境中存在适应性与准确性之间的权衡，难以同时实现对环境突变快速适应和在稳定期保持高准确性。

**Method:** 提出贝叶斯和逆贝叶斯（BIB）推理框架，将对称偏差整合到贝叶斯更新过程中，同时执行常规和逆贝叶斯更新，通过逆贝叶斯更新动态调节学习率。在具有随机时变均值的观测高斯分布序列估计任务中进行评估。

**Result:** BIB模型在环境转变期间表现出学习率的自发爆发，短暂进入高敏感状态以促进快速适应，这种爆发-弛豫动态平衡了适应性和准确性。雪崩分析、去趋势波动分析和功率谱分析表明BIB系统可能在临界状态下运行，而标准贝叶斯推理没有此特性。BIB模型独特地实现了计算效率和临界动力学的共存，解决了适应性-准确性权衡，同时保持无标度行为。

**Conclusion:** BIB模型通过结合对称偏差和动态学习率，解决了传统贝叶斯推理在非平稳环境中的适应性-准确性权衡问题，并揭示了其在临界状态下运行的特性，为设计自适应推理系统提供了新视角。

> **ai_Abstract:** 本文提出一种新颖的贝叶斯和逆贝叶斯（BIB）推理框架，该框架通过将对称偏差整合到贝叶斯更新中，并利用逆贝叶斯更新动态调节学习率，以解决传统贝叶斯推理在非平稳环境中适应性与准确性之间的固有权衡。实验结果显示，BIB模型在环境变化时能自发提高学习率以快速适应，并保持平衡的适应性与准确性。此外，分析表明BIB系统可能在临界状态下运行，这使其在计算效率和临界动力学之间实现了独特共存，同时展现出无标度行为。这些发现为设计非平稳环境中的自适应推理系统提供了新思路。

> **摘要翻译:** 本研究提出了一种新颖的推理框架，称为贝叶斯和逆贝叶斯（BIB）推理，它将对称偏差纳入贝叶斯更新过程，以同时执行常规和逆贝叶斯更新。该模型在涉及从具有随机时变均值的高斯分布中提取观测值的序列估计任务中进行了评估。传统的贝叶斯推理受到适应环境突变的能力与稳定期间准确性之间基本权衡的限制。BIB框架通过逆贝叶斯更新动态调节学习率来解决这一限制，从而增强自适应灵活性。值得注意的是，BIB模型在环境转变期间表现出学习率的自发爆发，短暂进入高敏感状态，从而促进了快速适应。这种爆发-弛豫动态是平衡适应性和准确性的一种机制。此外，雪崩分析、去趋势波动分析和功率谱分析表明，BIB系统可能在临界状态下运行——这是标准贝叶斯推理中未观察到的特性。这表明BIB模型独特地实现了计算效率和临界动力学的共存，解决了适应性-准确性权衡，同时保持无标度行为。这些发现为自然系统中的无标度动力学提供了新的计算视角，并为非平稳环境中自适应推理系统的设计提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [96] [SimLabel: Similarity-Weighted Iterative Framework for Multi-annotator Learning with Missing Annotations](https://arxiv.org/abs/2504.09525)
> *SimLabel：多标注者学习中缺失标注的相似度加权迭代框架*

*Liyun Zhang, Zheng Lian, Hong Liu, Takanori Takebe, Yuta Nakashima* | **Category: cs.MM** | **Updated: 2025-08-07**

**Keywords:** 多标注者学习, 缺失标注, 相似度加权, 迭代细化, 众包数据

**Comment:** 

> **TL;DR:** SimLabel是一个新的多标注者学习框架，通过相似度加权和迭代细化来处理缺失标注，并引入了新的数据集AMER2进行评估。

**AI_Comments:** SimLabel创新性地解决了多标注者学习中普遍存在的缺失标注问题，通过引入相似度加权和迭代细化机制，有效提升了数据利用效率和模型性能。特别值得注意的是，该工作还贡献了一个新的、更贴近真实世界情况的数据集AMER2，这将对多标注者学习领域的研究和评估提供重要支持，具有较高的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有多标注者学习(MAL)方法在遇到缺失标注时简单地跳过模型参数更新，导致数据利用效率低下和过拟合风险，尤其在每个标注者只标注小部分样本的众包数据集中。

**Method:** 本文提出了一种名为SimLabel的相似度加权半监督学习框架，利用标注者间的相似度为缺失标注生成加权软标签，以利用未标注样本。此外，引入了基于置信度的迭代细化机制，结合最大概率和基于熵的不确定性来优先处理高质量伪标签以补齐缺失标签，共同增强相似度估计和模型性能。为评估，还贡献了一个新的多模态多标注者数据集AMER2，该数据集具有高且更可变的缺失率，反映真实世界的标注稀疏性并支持不同稀疏水平的评估。

**Result:** 抽象中未明确给出SimLabel的实验结果，但提到贡献了一个新的多模态多标注者数据集AMER2，该数据集具有高且更可变的缺失率，反映了真实世界的标注稀疏性，并能够评估不同稀疏水平下的性能。

**Conclusion:** SimLabel框架通过有效处理缺失标注和利用未标注样本，提高了多标注者学习的数据利用效率和模型性能，并通过引入新的数据集支持更全面的评估。

> **ai_Abstract:** 本文提出了一种名为SimLabel的相似度加权迭代框架，用于解决多标注者学习中缺失标注导致的数据利用率低和过拟合问题。SimLabel通过利用标注者间相似性生成加权软标签来处理未标注样本，并引入基于置信度的迭代细化机制来共同提升相似度估计和模型性能。此外，论文还贡献了一个新的多模态多标注者数据集AMER2，以支持在不同稀疏水平下对SimLabel进行评估。

> **摘要翻译:** 多标注者学习（MAL）旨在建模标注者特定的标注模式。然而，现有方法面临一个关键挑战：当遇到缺失标签时，它们简单地跳过标注者特定模型参数的更新，这在每个标注者只标注小部分样本的真实世界众包数据集中是一种常见情况。这导致数据利用效率低下和过拟合风险。为此，我们提出了一种新颖的相似度加权半监督学习框架（SimLabel），该框架利用标注者间的相似性为缺失标注生成加权软标签，从而能够利用未标注样本而不是完全跳过它们。我们进一步引入了一种基于置信度的迭代细化机制，该机制结合最大概率和基于熵的不确定性来优先处理预测的高质量伪标签以补齐缺失标签，共同随时间增强相似度估计和模型性能。为了进行评估，我们贡献了一个新的多模态多标注者数据集AMER2，该数据集具有高且更可变的缺失率，反映了真实世界的标注稀疏性，并能够评估不同稀疏水平下的性能。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csms'></a>
## cs.MS 

### [82] [Adding complex numbers to expression template algorithmic differentiation tools](https://arxiv.org/abs/2508.05371)
> *将复数添加到表达式模板算法微分工具中*

*Max Sagebaum, Nicolas R. Gauger* | **Category: cs.MS** | **Updated: 2025-08-07**

**Keywords:** 算法微分, 复数, 表达式模板, 运算符重载, CoDiPack

**Comment:** 

> **TL;DR:** 将复数直接集成到表达式模板算法微分（AD）工具中，可以显著减少内存占用并加快梯度计算速度，克服了现有AD工具仅限于浮点值的局限性。

**AI_Comments:** 这篇论文提出了一种优化算法微分（AD）工具处理复数的方法，通过将复数操作直接集成到表达式模板框架中，而非将其分解为基础浮点操作。这种方法具有创新性，因为它解决了现有AD工具在处理复杂数据类型时的效率瓶颈，尤其是在内存和计算时间方面。其重要性在于，对于涉及复数计算的科学和工程应用，这将显著提升AD的性能，使其在复杂优化问题中更具实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的运算符重载算法微分（AD）工具主要为浮点值开发，对复数的处理通常将其分解为单独的浮点操作，或通过外部函数/手动特化引入，导致效率低下。将复数操作直接添加到表达式模板框架中可以带来显著好处，以优化内存和计算效率。

**Method:** 本文讨论了如何将复数集成到现代运算符重载AD工具中，并在CoDiPack中实现了一个示例，通过综合测试案例展示了其性能。

**Result:** 将复数操作直接集成到表达式模板AD工具中，可以隐藏复数操作的内部计算，避免将其分解为单一操作，从而减少记录带的内存占用（更小的内存足迹）并加快梯度计算时间。

**Conclusion:** 通过将复数操作直接集成到表达式模板算法微分工具中，可以有效优化梯度计算的内存和时间效率。

> **ai_Abstract:** 这篇论文探讨了将复数直接集成到基于表达式模板的运算符重载算法微分（AD）工具中的方法。现有AD工具主要处理浮点数，对复数的处理效率不高。研究表明，通过直接集成复数操作而非将其分解为浮点操作，可以隐藏内部计算，从而显著减少AD记录带的内存占用，并加速梯度计算。论文讨论了集成方法，并在CoDiPack中进行了实现和性能验证。

> **摘要翻译:** 运算符重载算法微分（AD）工具通常仅为浮点值开发。例如，线性系统求解器或矩阵-矩阵乘法的算法优化通常通过外部函数或手动函数特化引入。复数可以被视为两个浮点值的集合，对其应用专门的操作。通常，这些操作可以通过AD工具的常规浮点操作来处理。然而，将复数操作添加到现代运算符重载AD工具的表达式模板框架中具有多项优势。复数操作的内部计算被隐藏，并且复数操作不会分解为单一操作。这导致记录带的内存占用更小，梯度计算时间更快。我们将讨论这些问题，分析复数如何集成到现代运算符重载AD工具中，在CoDiPack中演示一个实现，并展示在综合测试案例上的性能结果。

</details>

[⬆️ 返回分类顶部](#csms) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [28] [Modelling the emergence of open-ended technological evolution](https://arxiv.org/abs/2508.04828)
> *开放式技术演进的建模*

*James Winters, Mathieu Charbonneau* | **Category: cs.NE, q-bio.PE, stat.CO** | **Updated: 2025-08-06**

**Keywords:** 开放式技术演化, 文化演化, 技术系统, 搜索空间, 共同演化

**Comment:** 

> **TL;DR:** 本文提出了一个宏观模型，解释了人类开放式技术演进的出现。研究发现，这种演进极其罕见，需要技术系统和搜索空间在特定随机和选择因素下共同演化。

**AI_Comments:** 该论文通过构建宏观模型，深入探讨了开放式技术演进这一复杂现象的内在机制。其创新之处在于强调了技术系统与搜索空间的共同演化，并区分了随机性和选择性因素在其中扮演的关键角色。研究发现开放式增长的稀有性和历史偶然性，为理解人类社会技术进步提供了新的视角。该模型有助于解释为何某些社会能够实现持续的技术进步，而另一些则不能。

<details>
  <summary>Details</summary>

**Motivation:** 人类在开放式地集体和累积改进技术方面独一无二，这种开放性使社会能够持续扩展资源并增强信息存储、传输和处理能力。本文旨在探究这种开放式技术演进是如何出现的。

**Method:** 本文提出了一个宏观层面的模型，其中技术系统（社会中相互依赖的技能、技术和人工制品）和搜索空间（社会中需求、问题和目标的集合）都受到文化演化动态的影响。通过操纵这些动态中随机或选择性过程的程度来演示。

**Result:** 研究表明，开放式增长极其罕见、具有历史偶然性，并且只有当技术系统和搜索空间共同演化时才可能发生。在这种共同演化中，随机因素必须足够强大以持续将动态扰动到远离平衡的状态，而选择性因素有助于维持效率并确保资源的持续生产。

**Conclusion:** 只有当这种共同演化动态维持有效的技术系统、支持搜索空间的持续扩展并导致资源供应增加时，才能观察到开放式技术演进。

> **ai_Abstract:** 本文提出了一个宏观模型来解释开放式技术演进的出现。该模型基于技术系统和搜索空间之间的互动，并认为两者都受文化演化动态影响。研究发现，开放式技术增长极其罕见且依赖于历史条件，只有当技术系统和搜索空间在特定随机和选择性因素的共同作用下持续共同演化时才可能实现，以维持效率、扩展搜索空间并增加资源供应。

> **摘要翻译:** 人类在以开放式方式集体和累积改进技术方面独树一帜。这种开放性使社会能够持续扩展其资源，并提高其在集体层面上存储、传输和处理信息的能力。在此，我们提出资源的产生源于技术系统（一个社会相互依赖的技能、技术和人工制品的集合）与搜索空间（一个社会中需求、问题和目标的总集合）之间的互动。从这个前提出发，我们开发了一个宏观层面的模型，其中技术系统和搜索空间都受到文化演化动态的影响。通过操纵这些动态中随机或选择性过程的特征程度，我们证明了开放式增长极其罕见、具有历史偶然性，并且只有当技术系统和搜索空间共同演化时才可能发生。在此，随机因素必须足够强大以持续将动态扰动到远离平衡的状态，而选择性因素有助于维持效率并确保资源的持续生产。只有当这种共同演化动态维持有效的技术系统，支持搜索空间的持续扩展并导致资源供应增加时，我们才能观察到开放式技术演进。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [35] [Adam assisted Fully informed Particle Swarm Optimization ( Adam-FIPSO ) based Parameter Prediction for the Quantum Approximate Optimization Algorithm (QAOA)](https://arxiv.org/abs/2506.06790)
> *基于Adam辅助全信息粒子群优化（Adam-FIPSO）的量子近似优化算法（QAOA）参数预测*

*Shashank Sanjay Bhat, Peiyong Wang, Udaya Parampalli* | **Category: cs.NE, quant-ph** | **Updated: 2025-08-07**

**Keywords:** QAOA, 参数优化, Adam, FIPSO, 组合优化

**Comment:** 

> **TL;DR:** 本文提出了一种结合Adam优化器和全信息粒子群优化（FIPSO）的框架，用于高效预测量子近似优化算法（QAOA）的参数，以解决贫瘠高原和局部最小值收敛问题，并在不同图实例上表现出优于随机初始化的性能。

**AI_Comments:** 该论文通过将Adam优化器与FIPSO结合，提出了一种新颖的QAOA参数优化方法，有效解决了QAOA中参数选择的挑战，并避免了贫瘠高原和局部最小值问题。其创新性在于将两种成熟的优化技术结合，以适应量子算法的特定需求，提升了QAOA的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 量子近似优化算法（QAOA）在解决组合优化问题（如Max-Cut问题）时面临一个关键挑战：如何高效识别能够产生高质量解的合适参数（gamma, beta）。

**Method:** 本文提出了一种结合全信息粒子群优化（FIPSO）和使用Adam优化器进行自适应梯度校正的框架，以在QAOA参数空间中进行导航。该方法旨在避免贫瘠高原和收敛到局部最小值等问题。

**Result:** 在Erdos Renyi和Watts-Strogatz两类图实例上，跨多个QAOA深度的实验结果一致表明，该算法的性能优于随机初始化。

**Conclusion:** 所提出的结合Adam和FIPSO的优化框架在预测QAOA参数方面是有效且鲁棒的，能够显著提高QAOA的性能并避免常见问题。

> **ai_Abstract:** 本文提出了一种名为Adam-FIPSO的新框架，用于优化量子近似优化算法（QAOA）的参数。该框架结合了全信息粒子群优化（FIPSO）和Adam优化器的自适应梯度校正能力，旨在克服QAOA中常见的贫瘠高原和局部最小值收敛问题。通过在Erdos Renyi和Watts-Strogatz图实例上的实验，结果表明Adam-FIPSO在不同QAOA深度下均能持续提供优于随机初始化的性能，证明了其在QAOA参数预测中的有效性和鲁棒性。

> **摘要翻译:** 量子近似优化算法（QAOA）是一种用于解决组合优化问题（如Max-Cut问题）的著名变分算法。QAOA中的一个关键挑战在于高效识别能够产生高质量解的合适参数（gamma, beta）。在本文中，我们提出了一个结合全信息粒子群优化（FIPSO）和使用Adam优化器进行自适应梯度校正的框架，以在QAOA参数空间中进行导航。这种方法旨在避免贫瘠高原和收敛到局部最小值等问题。所提出的算法针对两类图实例（Erdos Renyi和Watts-Strogatz）进行了评估。跨多个QAOA深度的实验结果一致表明，与随机初始化相比，该算法表现出卓越的性能，突显了所提出的优化框架的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [41] [TeraRIS NOMA-MIMO Communications for 6G and Beyond Industrial Networks](https://arxiv.org/abs/2508.05130)
> *TeraRIS NOMA-MIMO 适用于 6G 及未来工业网络通信*

*Ali Raza, Muhammad Farhan Khan, Zeeshan Alam, Muhammad Saad, Ilyas Saleem, Muhammad Ahmed Mohsin, Muhammad Ali Jamshed* | **Category: cs.NI, eess.SP** | **Updated: 2025-08-07**

**Keywords:** RIS, NOMA, 太赫兹通信, 6G, 工业网络

**Comment:** 

> **TL;DR:** 本文提出一个结合RIS、太赫兹通信和NOMA的联合框架，旨在增强6G及未来工业网络通信的频谱效率、覆盖和可靠性，并通过两种功率分配策略，实现显著的性能提升，尤其是在和速率方面。

**AI_Comments:** 该论文的创新点在于将RIS、太赫兹通信和NOMA这三种前沿技术集成到一个联合框架中，以解决未来工业网络通信的关键挑战。其提出的两种功率分配策略也增强了系统的灵活性和性能。重要性体现在为6G及未来工业网络的通信提供了一种有前景的解决方案，尤其是在频谱效率和可靠性方面。

<details>
  <summary>Details</summary>

**Motivation:** 增强未来6G及未来工业通信的频谱效率、覆盖和可靠性，以满足工业自动化和实时通信的关键需求。

**Method:** 提出一个集成可重构智能表面（RIS）、太赫兹（THz）通信和非正交多址（NOMA）的联合框架。在该框架内，研究了两种功率分配策略：一种优化近端和远端工业节点之间的功率分配，另一种优先考虑网络需求。通过性能评估，将和速率和中断概率与固定功率分配方案进行比较。

**Result:** 所提出的方案在30 dBm功率下，比固定功率分配方案实现了高达23%的和速率增益。仿真结果验证了理论分析，证明了RIS辅助的NOMA MIMO框架在太赫兹工业通信中的有效性和鲁棒性。

**Conclusion:** RIS辅助的NOMA MIMO框架对于太赫兹工业通信是有效和鲁棒的，能够显著提升系统性能，满足未来6G工业网络的需求。

> **ai_Abstract:** 本文介绍了一种为未来6G及工业网络设计的联合通信框架，该框架整合了可重构智能表面（RIS）、太赫兹（THz）通信和非正交多址（NOMA），旨在提升智能工业通信的频谱效率、覆盖和可靠性。研究中提出了两种创新的功率分配策略，并与传统方案进行了性能对比。实验结果表明，该方案在和速率上实现了显著提升（高达23%），验证了其在太赫兹工业通信场景下的有效性和鲁棒性。

> **摘要翻译:** 本文提出了一个联合框架，该框架将可重构智能表面（RIS）与太赫兹（THz）通信和非正交多址（NOMA）相结合，以增强智能工业通信。所提出的系统利用RIS和太赫兹频段的优势，提高了频谱效率、覆盖范围和可靠性，这些是未来6G及更高版本网络中工业自动化和实时通信的关键要求。在此框架内，研究了两种功率分配策略：第一种是在近端和远端工业节点之间优化功率分配，第二种是优先考虑网络需求以进一步增强系统性能。进行了性能评估，以比较和速率和中断概率与固定功率分配方案。我们的方案在30 dBm时比固定功率分配方案实现了高达23%的和速率增益。仿真结果验证了理论分析，证明了RIS辅助的NOMA MIMO框架在太赫兹工业通信中的有效性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [49] [Modular Design and Experimental Evaluation of 5G Mobile Cell Architectures Based on Overlay and Integrated Models](https://arxiv.org/abs/2508.05249)
> *基于叠加和集成模型的5G移动蜂窝架构的模块化设计与实验评估*

*José Ruela, Ivan Cojocaru, André Coelho, Rui Campos, Manuel Ricardo* | **Category: cs.NI** | **Updated: 2025-08-07**

**Keywords:** 5G移动蜂窝, 叠加模型, 集成接入和回程, OpenAirInterface, 网络性能

**Comment:** 

> **TL;DR:** 本文提出并评估了一种5G移动蜂窝（MC）概念，用于在5G基础设施有限或无线电条件恶劣的区域提供连接，并探讨了叠加模型和IAB模型两种设计方法，通过仿真验证了MC概念和位置对网络性能的影响。

**AI_Comments:** 该论文提出并实验验证了5G移动蜂窝（MC）的概念，对于解决5G基础设施覆盖不足和恶劣无线电条件下的连接问题具有重要意义。其创新之处在于提出了叠加模型和IAB模型两种模块化设计，并通过仿真平台进行了性能评估。研究强调了MC定位对网络性能的关键影响，为实际部署提供了有价值的指导。这对于网络运营商在临时覆盖、容量增强以及特殊场景（如海港、工业和公共安全）下的5G网络部署具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在5G固定基础设施有限或无线电条件恶劣的区域，为用户设备（UE）提供5G无线连接。

**Method:** 提出了两种MC设计方法：叠加模型（从5G叠加网络获取回程连接）和基于集成接入和回程（IAB）的模型。使用OpenAirInterface (OAI) 实现的基于仿真的测试平台进行性能验证，并考虑了不同的MC位置。

**Result:** 结果验证了MC概念，并表明MC定位显著影响网络性能。

**Conclusion:** 5G移动蜂窝概念是可行的，并且其部署位置对网络性能至关重要，有助于网络运营商在不同环境下选择和部署MC架构以进行临时覆盖扩展和容量增强。

> **ai_Abstract:** 本文提出了一种5G移动蜂窝（MC）的概念及其模块化设计，旨在为5G基础设施不足或无线电条件恶劣的区域提供无线连接。研究探讨了叠加模型和基于集成接入和回程（IAB）的两种MC架构，并分析了它们的协议栈和架构影响。通过使用OpenAirInterface（OAI）实现的仿真测试平台进行实验评估，验证了MC概念的可行性，并发现MC的部署位置对网络性能有显著影响。该研究为网络运营商在多种场景下部署MC以扩展覆盖和增强容量提供了指导。

> **摘要翻译:** 本文介绍了5G移动蜂窝（MC）的概念、架构设计和性能评估，MC用于在固定5G基础设施有限或无线电条件恶劣的区域为用户设备（UE）提供5G无线连接。我们考虑了两种主要的MC设计方法：叠加模型，其中MC从5G叠加网络获取回程连接；以及基于集成接入和回程（IAB）的模型，并讨论了它们的协议栈和架构影响。为了验证MC的性能，我们使用OpenAirInterface（OAI）实现的基于仿真的测试平台，考虑了不同的MC位置。结果验证了MC概念，并表明MC定位显著影响网络性能。本文有助于网络运营商和服务提供商在不同环境（包括海港、工业场景和公共安全）中选择和部署MC架构，以实现临时覆盖扩展和容量增强。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [56] [A Design for an Early Quantum Network](https://arxiv.org/abs/2508.04967)
> *早期量子网络的设计*

*Yuan Li, Chen Zhang, Hao Zhang, Tao Huang, Yunjie Liu* | **Category: cs.NI, quant-ph** | **Updated: 2025-08-07**

**Keywords:** 量子网络, 早期设计, 量子中继器, 网络仿真, 资源分配

**Comment:** 

> **TL;DR:** 本文提出了一种兼容现有中继技术的早期量子网络设计，旨在有限资源下满足多样化量子应用需求，并通过仿真评估了其可行性及关键参数影响。

**AI_Comments:** 本文提出了一种针对早期量子网络的实用设计，其创新点在于兼容现有量子中继技术，并在资源受限和性能不佳的实际条件下优化网络以满足多样化量子应用需求。通过详细的仿真验证，该研究为量子网络的早期部署提供了宝贵的指导和可行性分析，特别是在考虑噪声和不完善参数方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着量子信息技术的快速发展，量子网络对于支持多种应用变得至关重要，这些应用对保真度和请求完成时间等关键指标有严格要求。

**Method:** 本文提出了一种兼容现有三种量子中继技术的早期量子网络设计。该设计旨在有限的量子资源和次优网络性能条件下，最大限度地满足量子应用的多样化需求。研究还描述了量子网络中所需的标识符以及实现量子请求的具体过程。通过基于离散事件建模的量子网络仿真来评估设计的可行性，仿真考虑了早期网络中可能存在的各种噪声和不完善参数。

**Result:** 仿真分析了各种参数对生成纠缠态的保真度和请求完成时间的影响。此外，研究还探讨了中央控制器除了路径选择之外可以做出的额外决策，例如截止时间的选择和网络资源对请求的分配。

**Conclusion:** 通过仿真评估，所提出的早期量子网络设计在有限资源和存在噪声的条件下，能够满足量子应用的需求，并揭示了关键参数及控制器决策对网络性能的影响，证明了设计的可行性。

> **ai_Abstract:** 本文针对早期量子网络设计提出了一种新方案，该方案兼容现有量子中继技术，旨在有限资源和非理想性能条件下最大化满足多样化量子应用需求。研究详细描述了网络标识符和请求实现过程，并通过离散事件仿真评估了设计在噪声和不完善参数下的可行性，分析了这些因素对纠缠态保真度和请求完成时间的影响，并探讨了中央控制器在资源分配和截止时间选择上的决策。

> **摘要翻译:** 随着量子信息技术的快速发展，量子网络已成为支持各种应用的关键，这些应用通常对保真度和请求完成时间等关键指标有严格要求。在这项工作中，我们提出了一种早期量子网络的设计，该设计与现有三种量子中继技术兼容。该设计旨在即使在量子资源有限和网络性能次优的情况下，也能最大限度地提高网络适应量子应用多样化需求的能力。我们还描述了量子网络中所需的标识符以及实现量子请求的具体过程。为了评估我们设计的可行性，我们基于量子网络的离散事件建模进行了仿真。仿真考虑了早期网络中可能存在的各种类型的噪声和不完善参数。我们分析了这些参数对生成的纠缠态的保真度和请求完成时间的影响。此外，我们还研究了中央控制器除了路径选择之外可以做出的额外决策，例如截止时间的选择和网络资源对请求的分配。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [63] [Performance Comparison of HTTP/3 and HTTP/2 with Proxy Integration](https://arxiv.org/abs/2409.16267)
> *HTTP/3 与 HTTP/2 在代理集成下的性能比较*

*Fan Liu, Behrooz Farkiani, John Dehart, Jyoti Parwatikar, Patrick Crowley* | **Category: cs.NI** | **Updated: 2025-08-07**

**Keywords:** HTTP/3, HTTP/2, 代理, 性能评估, QUIC

**Comment:** 

> **TL;DR:** 本研究系统评估了在代理增强环境中QUIC/HTTP3 (H3) 和 TCP/HTTP2 (H2) 的性能。发现代理显著提升了H2的性能，而对H3影响甚微，H3在高丢包和高延迟条件下表现优异，整体更鲁棒。

**AI_Comments:** 这篇论文的创新点在于系统地评估了代理在HTTP/2和HTTP/3性能中的作用，特别是关注了连接迁移在HTTP/3中的表现。其重要性在于为网络工程师和开发者提供了在复杂网络环境下选择和优化HTTP协议的实践指导，突出了HTTP/3在面对挑战性网络条件时的固有优势。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究显示HTTP/3的性能表现因网络条件而异，但代理和连接迁移在其中的作用尚未得到充分探索，本研究旨在填补这一空白。

**Method:** 本研究评估了多种HTTP/2和HTTP/3客户端实现在有损网络和代理设置下的性能。

**Result:** 研究发现，代理可以显著提升HTTP/2的性能，在严重网络损伤下，单流下载性能可提升90%（结合BBR拥塞控制）。相比之下，代理对HTTP/3的影响最小，HTTP/3由于其内部机制保持了稳定的性能。HTTP/3在高丢包和高延迟条件下表现出色，在连接迁移场景下性能提升高达88.36%，在极端丢包情况下提升81.5%。

**Conclusion:** 尽管经过优化的HTTP/2在某些设置下可以与HTTP/3媲美，但HTTP/3整体上更具鲁棒性，对代理、网络损伤和拥塞控制变体表现出较低的敏感性。

> **ai_Abstract:** 本研究比较了HTTP/3和HTTP/2在代理集成环境下的性能。发现代理能显著提升HTTP/2性能，特别是在有损网络中。而HTTP/3受代理影响小，在高丢包和高延迟条件下表现出更优越的性能和更强的鲁棒性，利用其连接迁移和多路复用特性在极端情况下实现显著提升。

> **摘要翻译:** 本论文系统评估了在代理增强环境下QUIC/HTTP3 (H3) 和 TCP/HTTP2 (H2) 的性能。H3集成了基于UDP的流控流、内置TLS、多路复用和连接迁移，以更好地支持现代网络通信。虽然之前的研究表明H3的性能可能因网络条件而优于或劣于H2，但代理和连接迁移的作用仍未得到充分探索。我们评估了各种H2和H3客户端实现在有损网络和代理设置下的表现。我们的研究结果表明，代理可以显著提升H2的性能，在严重网络损伤下与BBR拥塞控制算法结合使用时，单流下载性能可提高90%。相比之下，代理对H3的影响最小，H3由于其内部机制保持了稳定的性能。H3在高丢包和高延迟条件下表现出色，利用连接迁移和多路复用在迁移场景下提供高达88.36%的性能提升，在极端丢包情况下提升81.5%。虽然经过优化的H2在某些设置下可以与H3媲美，但H3整体上更具鲁棒性，对代理、网络损伤和拥塞控制变体表现出较低的敏感性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='cspf'></a>
## cs.PF 

### [70] [Back to Bits: Extending Shannon's communication performance framework to computing](https://arxiv.org/abs/2508.05621)
> *回归比特：将香农的通信性能框架扩展到计算*

*Max Hawkins, Richard Vuduc* | **Category: cs.PF** | **Updated: 2025-08-07**

**Keywords:** 信息论, 计算性能, 互信息, 性能评估, 香农框架

**Comment:** 

> **TL;DR:** 提出了一种基于信息论的计算性能新单位，通过互信息衡量计算系统性能，以应对传统指标对多样化现代系统衡量不足的问题。

**AI_Comments:** 这项工作的创新之处在于将香农的信息论框架引入计算性能评估，提供了一个比传统FLOPs更全面的视角，尤其适用于衡量新兴和多样化的计算范式。其“与实现无关”的特性使其具有广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 现代计算系统日益多样化，支持低精度格式、硬件专用化以及模拟、量子和可逆逻辑等新兴范式。传统的浮点运算（flops）等指标已无法准确捕捉这种复杂性。

**Method:** 将计算视为信息通过通道的转换，并根据系统输入和输出之间的互信息来定义性能。这种方法衡量的是计算过程中编码、操作和保留的有意义信息的数量，而不仅仅是处理的数据量。

**Result:** 该框架提供了一个原则性的、与实现无关的性能评估基础。

**Conclusion:** 提出的信息论计算性能框架为评估多样化现代计算系统提供了一个普适且准确的基础。

> **ai_Abstract:** 这篇论文提出了一种新颖的、基于信息论的计算性能衡量单位，以应对传统指标如浮点运算在衡量日益多样化的现代计算系统（包括低精度、专用硬件及新兴范式）时的局限性。作者将计算视为信息通过通道的转换，并通过系统输入和输出之间的互信息来定义性能，从而能够衡量计算过程中有意义信息的编码、操作和保留量。该框架旨在提供一个普适且与实现无关的性能评估基础。

> **摘要翻译:** 这项工作提出了一种基于信息论的新型计算性能单位。现代计算系统日益多样化，支持低精度格式、硬件专用化以及模拟、量子和可逆逻辑等新兴范式。传统的浮点运算（flops）等指标已无法准确捕捉这种复杂性。我们将计算框定为信息通过通道的转换，并根据系统输入和输出之间的互信息来定义性能。这种方法衡量的不只是处理的数据量，而是通过计算编码、操作和保留的有意义信息的数量。我们的框架为评估性能提供了一个原则性的、与实现无关的基础。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

### [76] [Dancing with a Robot: An Experimental Study of Child-Robot Interaction in a Performative Art Setting](https://arxiv.org/abs/2508.05208)
> *与机器人共舞：表演艺术环境中儿童-机器人互动实验研究*

*Victor Ngo, Rachel, Ramchurn, Roma Patel, Alan Chamberlain, Ayse Kucukyilmaz* | **Category: cs.PF, cs.RO** | **Updated: 2025-08-07**

**Keywords:** 儿童-机器人互动, 表演艺术, 机器人手臂, HRI, NED

**Comment:** 

> **TL;DR:** 研究儿童在表演艺术环境中与机器人互动时面临的挑战，并强调优化人机交互系统的重要性。

**AI_Comments:** 这项研究通过在真实表演艺术环境中对儿童与机器人的互动进行实验性评估，提供了宝贵的见解。其创新之处在于将HRI研究置于独特的艺术背景中，并具体指出了儿童与机器人互动中的关键挑战。研究结果对于未来设计更具吸引力和互动的艺术机器人以及儿童教育机器人具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在评估儿童在表演艺术装置中与自主机器人手臂表演者NED的实际互动体验，并识别儿童-机器人互动中的挑战，以期优化人机交互系统，为年轻观众提供更具吸引力和意义的体验。

**Method:** 本文评估了18名儿童在英国各地展出的Thingamabobas装置中与自主机器人手臂表演者NED（Never-Ending Dancer）的实际体验。研究详细介绍了NED的设计，包括服装、行为和人机互动。通过观察分析得出结论。

**Result:** 观察分析揭示了儿童-机器人互动中的三个主要挑战：1）启动和维持参与度，2）机器人缺乏表现力和互惠性，3）未满足的期望。研究发现儿童天生好奇，擅长与机器人艺术表演者互动。

**Conclusion:** 强调在表演艺术环境中，需要通过仔细考虑观众的能力、认知和期望来优化人机交互（HRI）系统，从而为年轻观众带来引人入胜且有意义的体验。

> **ai_Abstract:** 本研究评估了18名儿童在Thingamabobas装置中与自主机器人手臂NED的互动体验。研究详细介绍了NED的设计，并发现儿童-机器人互动存在三大挑战：参与度难以维持、机器人表现力不足以及期望未满足。尽管儿童对机器人表现出好奇和适应性，但研究强调，在表演艺术背景下，优化人机交互系统需充分考虑观众的能力、感知和期望，以创造有意义的体验。

> **摘要翻译:** 本文评估了18名儿童在英国各地展出的Thingamabobas装置中与自主机器人手臂表演者NED（Never-Ending Dancer）的实际体验。我们详细介绍了NED的设计，包括服装、行为和人机互动，这些都是装置不可或缺的一部分。我们的观察分析揭示了儿童-机器人互动中的三个主要挑战：1）启动和维持参与度，2）机器人缺乏表现力和互惠性，3）未满足的期望。我们的研究结果表明，儿童天生好奇，擅长与机器人艺术表演者互动。然而，我们的观察强调，在表演艺术环境中，需要通过仔细考虑观众的能力、认知和期望来优化人机交互（HRI）系统，从而为年轻观众带来引人入胜且有意义的体验。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

### [853] [Mapping Sparse Triangular Solves to GPUs via Fine-grained Domain Decomposition](https://arxiv.org/abs/2508.04917)
> *通过细粒度域分解将稀疏三角求解映射到GPU*

*Atharva Gondhalekar, Kjetil Haugen, Thomas Gibson, Wu-chun Feng* | **Category: cs.PF, math.NA** | **Updated: 2025-08-06**

**Keywords:** 稀疏三角求解, GPU, 域分解, 预处理器, BiCGSTAB

**Comment:** 

> **TL;DR:** 该工作利用细粒度域分解策略，将稀疏三角求解适应GPU架构，解决了预处理器应用中的瓶颈，并在AMD Instinct MI210 GPU上实现了显著的加速。

**AI_Comments:** 这项工作的创新之处在于其细粒度域分解策略，该策略专门针对GPU架构进行了优化，特别是通过利用共享内存来规避不规则内存访问和数据依赖性问题。这对于加速稀疏线性系统求解中的关键组成部分——预处理器的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 稀疏线性系统通常使用预处理迭代方法求解，但通过稀疏三角求解应用预处理器会由于不规则内存访问和数据依赖性而引入瓶颈。

**Method:** 开发了一种细粒度域分解策略，生成非重叠子域以增加并行性。每个子域分配给一个线程块，并调整大小使其向量适合GPU共享内存，从而消除块间同步的需要并减少不规则全局内存访问。

**Result:** 与使用ROCm软件栈的其他最先进实现相比，在AMD Instinct MI210 GPU上，三角求解实现了10.7倍的加速，ILU0预处理的双共轭梯度稳定（BiCGSTAB）求解器实现了3.2倍的加速。

**Conclusion:** 该细粒度域分解方法有效地解决了稀疏三角求解在GPU上的瓶颈，显著提高了预处理迭代求解器的性能。

> **ai_Abstract:** 本研究提出了一种细粒度域分解策略，旨在解决稀疏三角求解在GPU上作为预处理器应用时的性能瓶颈。该方法通过创建非重叠子域并将其分配给适合GPU共享内存的线程块，从而最大化并行性并减少不规则全局内存访问和块间同步。实验结果表明，与现有技术相比，在AMD Instinct MI210 GPU上，三角求解和ILU0预处理的BiCGSTAB求解器分别实现了10.7倍和3.2倍的显著加速。

> **摘要翻译:** 稀疏线性系统通常使用预处理迭代方法求解，但通过稀疏三角求解应用预处理器会由于不规则内存访问和数据依赖性而引入瓶颈。这项工作利用细粒度域分解将三角求解适应GPU架构。我们开发了一种细粒度域分解策略，生成非重叠子域，以牺牲迭代次数适度增加为代价，增加了预处理器应用中的并行性。每个子域分配给一个线程块，并调整大小使子域向量适合GPU共享内存，从而消除块间同步的需要并减少不规则全局内存访问。与使用ROCm$^{\text{TM}}$软件栈的其他最先进实现相比，我们在AMD Instinct$^{\text{TM}}$ MI210 GPU上实现了三角求解10.7倍的加速，以及ILU0预处理的双共轭梯度稳定（BiCGSTAB）求解器3.2倍的加速。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [83] [Consistent Updates for Scalable Microservices](https://arxiv.org/abs/2508.04829)
> *可扩展微服务的一致性更新*

*Devora Chait-Roth, Kedar S. Namjoshi, Thomas Wies* | **Category: cs.PL** | **Updated: 2025-08-06**

**Keywords:** 一致性更新, 微服务, 混合模式, 可扩展性, 语义属性

**Comment:** 

> **TL;DR:** 本文提出了首个能够保证微服务混合模式更新一致性的算法，解决了在线服务在不停机情况下更新功能时可能出现的数据不一致问题。

**AI_Comments:** 本文的创新之处在于提出了首个能够保证微服务混合模式更新一致性的算法，这是一个关键且具有挑战性的问题。其对服务操作语义属性的利用以及形式化理论框架的建立是重要的贡献，为此前效率低下或存在风险的更新方法提供了一个健壮的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 在线服务通常采用可扩展微服务架构实现，在服务不中断的情况下进行功能修改具有挑战性。核心难题在于避免“混合模式”操作（新旧版本工作进程并发活动并与数据存储交互）导致潜在的不一致性。现有更新方法要么效率低下（资源加倍或吞吐量减半），要么风险高（不受控的滚动更新可能导致严重服务故障）。

**Method:** 本文提出了首个能保证混合模式更新一致性的算法。这些算法依赖于服务操作的语义属性，例如可交换性。论文还引入了一个形式化框架和基础理论来推理混合模式更新的一致性，并应用该理论推导出新算法并验证其正确性。

**Result:** 论文证明了语义感知是必需的，任何语义不敏感的混合模式更新方法都无法避免不一致性。基于其形式化理论，论文推导出了新的算法，并建立了其正确性。

**Conclusion:** 本文成功提供了算法和理论框架，以实现可扩展微服务的一致性、不停机更新，克服了混合模式操作的挑战。

> **ai_Abstract:** 本文针对可扩展微服务架构中不停机更新的挑战，特别是解决新旧服务版本并发运行时“混合模式”操作引起的一致性问题。论文提出了首个能保证混合模式更新一致性的算法，这些算法通过利用服务操作的语义属性来实现。同时，论文建立了一个形式化框架和基础理论，证明了语义感知对于避免不一致性至关重要，并基于此理论推导并验证了新算法，确保客户端感知到的更新是原子性的。

> **摘要翻译:** 在线服务通常采用可扩展微服务架构实现，其中同构工作进程处理客户端请求，并在后端数据存储中记录持久状态。为了维持服务，对服务功能的任何修改都必须在运行时进行——即在服务继续处理客户端请求时——但这样做具有挑战性。核心难题在于避免由“混合模式”操作引起潜在的不一致性，即当前版本和新版本的工作进程并发活动并通过数据存储进行交互。一些更新方法完全避免了混合模式，但代价是效率低下——通过资源（内存和计算）加倍，或吞吐量减半。另一种选择是所谓的“滚动”更新，这种更新不受控制，并存在因不一致的混合模式行为导致严重服务故障的风险。
在本文中，我们提出了首个保证混合模式更新一致性的算法。这些算法依赖于服务操作的语义属性，例如可交换性。我们通过证明任何语义不敏感的混合模式更新方法都无法避免不一致性，从而表明语义感知是必需的。理想情况下，对于每个客户端来说，服务更新应该看起来是原子性生效的；这确保客户端不会暴露于不一致的混合模式行为。我们引入了一个形式化这种直觉的框架，并开发了推理混合模式更新一致性的基础理论，将该理论应用于推导新算法并建立其正确性。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [179] [On the causality between affective impact and coordinated human-robot reactions](https://arxiv.org/abs/2508.04834)
> *情感影响与人机协调反应之间的因果关系*

*Morten Roed Frederiksen, Kasper Støy* | **Category: cs.RO** | **Updated: 2025-08-06**

**Keywords:** 人机交互, 情感影响, 机器人反应时间, 社交机器人, 因果关系

**Comment:** 

> **TL;DR:** 机器人对共享事件的协调反应，特别是接近人类的反应时间（约200毫秒），能显著影响人类对其情感影响的感知；而100毫秒的反应时间则能让人类感觉对机器人产生最大影响。

**AI_Comments:** 这篇论文通过实证研究，量化了机器人反应时间对人类感知其情感影响的重要性，为设计更具社交能力的机器人提供了具体的指导，特别是关于反应时延的关键参数。其创新性在于精细化地探讨了反应时延与人类情感反馈之间的因果关系。

<details>
  <summary>Details</summary>

**Motivation:** 为了改善机器人在社交环境中的功能，本文研究机器人主动与人类分享对事件的反应是否会改变人类对机器人情感影响的感知。

**Method:** 本文创建了两种不同的测试设置：一种用于突出和隔离机器人情感表达的反应元素；另一种用于研究对机器人与人类物理接触的反应施加特定时间延迟的效果。第一个测试有84名人类观察者参与，分为测试组和对照组，均与机器人互动。第二个测试有110名参与者，每十名参与者增加一次机器人的反应延迟。

**Result:** 结果显示，当机器人对与人类观察者共享的事件做出反应而不是随机反应时，其感知到的情感影响发生统计学上的显著变化（p<0.05）。结果还表明，在共享物理交互中，机器人接近人类的反应时间是最合适的。

**Conclusion:** 论文得出结论，对于小型非人形机器人，大约200毫秒的延迟时间可能对人类观察者产生最大的影响。它进一步得出结论，当目标是让人类观察者感觉他们对机器人产生了最大影响时，大约100毫秒的稍短反应时间是最有效的。

> **ai_Abstract:** 本文旨在探究机器人主动对共享事件做出反应如何影响人类对其情感影响的感知。通过两项实验，一项隔离反应元素，一项测试反应延迟，研究发现机器人对共享事件的协调反应显著增加了其感知到的情感影响。特别地，对于共享物理交互，接近人类的反应时间（约200毫秒）对人类观察者影响最大，而略短的100毫秒反应时间则能使人类感觉对机器人产生最大影响。

> **摘要翻译:** 为了改善机器人在社交环境中的功能，本文研究机器人主动与人类分享对事件的反应是否会改变人类对机器人情感影响的感知。为了验证这一点，我们创建了两种不同的测试设置。一种用于突出和隔离机器人情感表达的反应元素，另一种用于研究对机器人与人类物理接触的反应施加特定时间延迟的效果。第一个测试有两组（n=84）人类观察者进行，一个测试组和一个对照组都与机器人互动。第二个测试有110名参与者进行，每十名参与者增加一次机器人的反应延迟。结果显示，当机器人对与人类观察者共享的事件做出反应而不是随机反应时，其感知到的情感影响发生统计学上的显著变化（p<0.05）。结果还表明，在共享物理交互中，机器人接近人类的反应时间是最合适的。论文得出结论，对于小型非人形机器人，大约200毫秒的延迟时间可能对人类观察者产生最大的影响。它进一步得出结论，当目标是让人类观察者感觉他们对机器人产生了最大影响时，大约100毫秒的稍短反应时间是最有效的。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [189] [Optimal Planning for Multi-Robot Simultaneous Area and Line Coverage Using Hierarchical Cyclic Merging Regulation](https://arxiv.org/abs/2508.04981)
> *多机器人同时区域和线路覆盖的分层循环合并调节优化规划*

*Tianyuan Zheng, Jingang Yi, Kaiyan Yu* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 多机器人系统, 区域覆盖, 线路覆盖, 优化规划, HCMR

**Comment:** 

> **TL;DR:** 本文提出了一种名为分层循环合并调节 (HCMR) 的优化规划算法，用于解决多机器人在已知环境中同时覆盖线性特征和区域的双重覆盖问题，该算法在路径长度、任务时间和冲突避免方面表现优异。

**AI_Comments:** 该论文的创新点在于引入了分层循环合并调节（HCMR）算法来解决多机器人双重覆盖问题，并结合了Morse理论来简化最优解的识别。其通过理论证明算法的最优性，并通过仿真结果量化了在路径长度、任务时间及冲突避免方面的显著改进，显示出重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决多机器人在已知环境中同时高效、无碰撞地覆盖线性特征和区域的“双重覆盖问题”。该问题中机器人需兼顾服务（线性特征覆盖）和探索（区域覆盖）两种角色，其中服务成本更高。

**Method:** 提出了分层循环合并调节（HCMR）算法。该算法从Morse理论角度分析图遍历过程中的流形附着，证明最优解属于Morse有界集合。HCMR通过循环合并搜索调节遍历行为，边缘序列反向传播转换为图边缘遍历序列，并结合平衡分区选择最优序列生成机器人路径。算法在固定扫描方向下被证明为最优。

**Result:** HCMR算法在多机器人仿真中表现优异，规划路径长度平均至少改善10.0%，任务时间平均至少减少16.9%，并确保了无冲突操作，优于其他最先进的规划方法。

**Conclusion:** HCMR算法为多机器人同时区域和线路覆盖问题提供了一种最优规划解决方案，在路径长度、任务时间和冲突避免方面表现出显著的优势。

> **ai_Abstract:** 本文针对多机器人在已知环境中同时进行线性特征和区域覆盖的“双重覆盖问题”，提出了一种名为分层循环合并调节（HCMR）的优化规划算法。该算法结合了摩尔斯理论，通过循环合并搜索和边缘序列反向传播来生成最优的机器人路径序列，并利用平衡分区进行路径选择。仿真结果显示，HCMR算法在规划路径长度、任务时间以及冲突避免方面均显著优于现有方法。

> **摘要翻译:** 双重覆盖问题侧重于确定多机器人在已知环境中同时覆盖线性特征（例如，地表裂缝或道路路线）和勘测区域（例如，停车场或局部区域）的有效、无冲突路线。在这些问题中，每个机器人承担两种功能角色：服务（线性特征足迹覆盖）和探索（完整区域覆盖）。与探索相比，服务的操作足迹较小但成本较高（例如时间）。我们提出了使用分层循环合并调节（HCMR）的双重覆盖问题的优化规划算法。为了降低优化规划解决方案的复杂性，我们从摩尔斯理论的角度分析了图遍历过程中的流形附着过程。我们表明，满足最小路径长度和无冲突约束的解决方案必须属于摩尔斯有界集合。为了识别这个集合，我们引入了HCMR算法。在HCMR中，循环合并搜索调节遍历行为，而边缘序列反向传播将这些调节转换为图边缘遍历序列。结合平衡分区，选择最优序列来为每个机器人生成路线。我们证明了HCMR算法在固定扫描方向下的最优性。多机器人仿真结果表明，与其他最先进的规划方法相比，HCMR算法显著改善了规划路径长度至少10.0%，平均任务时间至少减少16.9%，并确保了无冲突操作。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [196] [MAG-Nav: Language-Driven Object Navigation Leveraging Memory-Reserved Active Grounding](https://arxiv.org/abs/2508.05021)
> *MAG-Nav：利用记忆保留主动接地的语言驱动对象导航*

*Weifan Zhang, Tingguang Li, Yuzhen Liu* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 语言驱动导航, 视觉语言模型, 主动接地, 记忆回溯, 零样本学习

**Comment:** 

> **TL;DR:** 提出MAG-Nav框架，通过主动感知和记忆回溯增强VLM，实现零样本语言驱动的机器人导航，在复杂未知环境中表现出色。

**AI_Comments:** 该论文的创新点在于其主动感知（视角主动接地）和记忆回溯机制，这与现有被动接收视觉输入的方法形成对比，显著提升了在复杂未知环境中的视觉-语言接地能力。其零样本泛化能力和在真实机器人上的部署进一步证明了其实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 智能机器人在未知环境中仅依据自然语言描述进行视觉导航是一项关键能力。现有方法被动依赖偶发视觉输入，无法有效解决歧义。

**Method:** 提出一个基于现成视觉语言模型（VLMs）的导航框架MAG-Nav，引入两种受人类启发的机制：基于视角的“主动接地”（动态调整机器人视角以改进视觉检查）和“历史记忆回溯”（保留并重新评估不确定的观察）。该方法主动优化感知并利用记忆解决歧义，以零样本方式运行。

**Result:** 在Habitat-Matterport 3D (HM3D) 上，该方法优于现有最先进的语言驱动对象导航方法。在四足机器人上的实际部署也证明了其稳健有效的导航性能。

**Conclusion:** MAG-Nav通过结合主动感知和记忆回溯，显著提升了机器人在复杂、未知环境中基于语言描述的零样本导航能力，展现出强大的泛化能力和实用性。

> **ai_Abstract:** 本文提出了MAG-Nav，一个基于视觉语言模型（VLMs）的语言驱动对象导航框架。该框架引入了视角主动接地和历史记忆回溯机制，以主动优化感知并利用记忆解决复杂未知环境中的视觉-语言歧义。MAG-Nav以零样本方式运行，无需训练即可泛化到多样化的语言描述。实验证明，其在HM3D数据集上优于现有方法，并在真实机器人上展示了实用性。

> **摘要翻译:** 基于自然语言描述在未知环境中进行视觉导航是智能机器人的一项关键能力。在这项工作中，我们提出了一个基于现成视觉语言模型（VLMs）的导航框架，该框架通过两种受人类启发的机制得到增强：基于视角的“主动接地”，它动态调整机器人的视角以改进视觉检查；以及“历史记忆回溯”，它使系统能够随着时间保留和重新评估不确定的观察。与现有被动依赖偶发视觉输入的方法不同，我们的方法主动优化感知并利用记忆来解决歧义，显著改善了复杂、未知环境中的视觉-语言接地。我们的框架以零样本方式运行，无需标记数据或模型微调即可对多样化和开放式的语言描述实现强大的泛化能力。在Habitat-Matterport 3D (HM3D) 上的实验结果表明，我们的方法在语言驱动的对象导航方面优于最先进的方法。我们通过在四足机器人上的实际部署进一步证明了其实用性，实现了稳健有效的导航性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [203] [Benchmarking Shortcutting Techniques for Multi-Robot-Arm Motion Planning](https://arxiv.org/abs/2508.05027)
> *多机械臂运动规划中捷径技术基准测试*

*Philip Huang, Yorai Shaoul, Jiaoyang Li* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 多机械臂, 运动规划, 捷径技术, 性能评估, 机器人

**Comment:** 

> **TL;DR:** 本文对多机械臂运动规划中的现有捷径技术进行了全面量化比较，并提出了两种结合策略以优化性能和运行时间权衡。

**AI_Comments:** 本文通过对多机械臂运动规划中捷径技术的全面定量基准测试，填补了现有研究中方法描述模糊和缺乏比较的空白。其创新点在于对不同捷径方法优劣的细致分析以及提出的结合策略，这对于提升多机械臂系统的运动规划质量和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为多机械臂生成高质量运动规划具有挑战性，传统方法往往次优。尽管现有研究常使用捷径技术，但其具体方法和性能影响描述模糊，缺乏定量比较。

**Method:** 本文对现有用于多机械臂轨迹的捷径技术进行了全面的定量比较研究，分析了每种方法的优缺点，并提出了两种简单的策略来结合这些方法，以实现最佳的性能-运行时间权衡。

**Result:** 分析了各种捷径方法的优缺点，并提出了两种新的简单策略，通过结合现有方法来优化性能与运行时间的权衡。

**Conclusion:** 本文通过对多机械臂运动规划中捷径技术的全面量化研究，明确了现有方法的优缺点，并提出了有效的结合策略以提升性能和效率。

> **ai_Abstract:** 针对多机械臂运动规划中捷径技术缺乏定量比较和明确描述的问题，本文进行了一项全面的研究。作者在多种模拟场景下定量评估并比较了现有捷径方法的性能，分析了它们的优缺点，并提出了两种结合策略以优化性能与运行时间的权衡，旨在提升多机械臂运动规划的质量和效率。

> **摘要翻译:** 为多个机械臂生成高质量的运动规划具有挑战性，原因在于系统维度高以及存在臂间碰撞的可能。传统的运动规划方法对于多臂系统而言，在平滑度和执行时间方面往往次优。通过捷径技术进行后处理是改善运动质量以实现高效平稳执行的常用方法。然而，在多臂场景中，优化一个臂的运动不能引入与其他臂的碰撞。尽管现有的多臂规划工作通常使用某种形式的捷径技术，但其具体方法和对性能的影响往往描述模糊。在这项工作中，我们提出了一项全面的研究，在不同的模拟场景中定量比较了现有用于多臂轨迹的捷径方法。我们仔细分析了每种捷径方法的优缺点，并提出了两种简单的策略来结合这些方法，以实现最佳的性能-运行时间权衡。视频、代码和数据集可在 https://philip-huang.github.io/mr-shortcut/ 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [210] [A Vision-Based Collision Sensing Method for Stable Circular Object Grasping with A Soft Gripper System](https://arxiv.org/abs/2508.05040)
> *一种基于视觉的软抓手系统稳定抓取圆形物体碰撞感知方法*

*Boyang Zhang, Jiahui Zuo, Zeyu Duan, Fumin Zhang* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 视觉感知, 碰撞检测, 软抓手, 稳定抓取, 圆形物体

**Comment:** 

> **TL;DR:** 该研究提出了一种基于视觉的碰撞感知方法，用于软抓手系统在抓取圆形物体时检测外部碰撞，以保持稳定抓取。

**AI_Comments:** 该论文的创新点在于提出了一个结合视觉感知和富碰撞策略的软抓手系统，有效解决了机器人抓取圆形物体时遇到的外部碰撞问题。其重要性在于提升了软抓手在复杂动态环境下的鲁棒性和抓取稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人执行器外部碰撞通常对抓取圆形物体构成风险，本研究旨在开发一种方法来应对此问题，以保持稳定抓取。

**Method:** 本研究提出了一种基于视觉的感知模块，该模块采用掌内摄像头，具有广阔视野，可同时监测手指和抓取物体的运动。此外，开发了一种富碰撞抓取策略以确保动态抓取过程的稳定性和安全性。制造了一个物理软抓手并将其安装在协作机械臂上进行评估。

**Result:** 碰撞检测机制的响应时间测试证实系统能够即时响应碰撞。躲避测试表明抓手能够精确检测外部碰撞的方向和规模。

**Conclusion:** 该基于视觉的碰撞感知方法和富碰撞抓取策略能够使软抓手系统在抓取圆形物体时有效检测并响应外部碰撞，从而保持抓取的稳定性和安全性。

> **ai_Abstract:** 本研究提出了一种用于软抓手系统的基于视觉的碰撞感知方法，旨在解决抓取圆形物体时外部碰撞带来的风险。该系统利用掌内摄像头实时监测抓手手指和物体的运动，并结合一种富碰撞抓取策略，以确保抓取过程的稳定性和安全性。实验结果表明，该系统能够即时响应碰撞，并精确检测外部碰撞的方向和规模。

> **摘要翻译:** 机器人执行器外部碰撞通常对抓取圆形物体构成风险。本研究提出了一种基于视觉的感知模块，能够检测碰撞，以通过软抓手系统保持稳定的抓取。该系统采用掌内摄像头，具有广阔视野，可同时监测手指和抓取物体的运动。此外，我们开发了一种富碰撞抓取策略，以确保整个动态抓取过程的稳定性和安全性。制造了一个物理软抓手并将其安装在协作机械臂上，以评估碰撞检测机制的性能。一项关于测试机制响应时间的实验证实，该系统能够即时响应碰撞。进行了一项躲避测试，以证明抓手能够精确检测外部碰撞的方向和规模。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [217] [Examining the legibility of humanoid robot arm movements in a pointing task](https://arxiv.org/abs/2508.05104)
> *探究类人机器人手臂动作在指向任务中的可辨识性*

*Andrej Lúčny, Matilde Antonj, Carlo Mazzola, Hana Hornáčková, Ana Farić, Kristína Malinovská, Michal Vavrecka, Igor Farkaš* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 类人机器人, 动作可辨识性, 指向任务, 多模态, 眼部优先

**Comment:** 

> **TL;DR:** 本研究调查了类人机器人在指向任务中手臂动作的可辨识性，发现多模态线索和眼神在人类预测机器人意图方面很重要。

**AI_Comments:** 这项研究通过实验验证了多模态线索和眼神在提高机器人动作可辨识性方面的重要性，对于设计更安全、更直观的人机交互系统具有指导意义。其创新之处在于通过截断动作来模拟不完整信息下的预测能力，并明确支持了多模态和眼神优先的理论。

<details>
  <summary>Details</summary>

**Motivation:** 人机交互需要机器人动作具有可辨识性，以便人类能够解释、预测其行为并在其周围感到安全。本研究旨在理解人类如何从截断的动作和身体线索中预测机器人的意图。

**Method:** 实验使用NICO类人机器人，参与者观察其手臂指向触摸屏上目标的动作。机器人线索包括：凝视、指向以及指向与凝视一致或不一致的情况。手臂轨迹在完成60%或80%时停止，参与者预测最终目标。

**Result:** 实验支持了多模态优势假说和眼部优先假说。

**Conclusion:** 多模态线索和眼神在人类预测机器人意图方面发挥重要作用，支持了多模态优势和眼部优先的假设。

> **ai_Abstract:** 本研究旨在探究类人机器人手臂动作在指向任务中的可辨识性，以理解人类如何根据截断的动作和身体线索预测机器人意图。实验使用NICO机器人，参与者观察其手臂指向触摸屏目标的动作，并预测最终目标。实验条件包括凝视、指向以及凝视与指向的结合。结果支持了多模态优势和眼部优先假说，表明多模态线索，特别是眼神，对于提高人机交互中机器人行为的可预测性至关重要。

> **摘要翻译:** 人机交互要求机器人的行为具有可辨识性，从而使人类能够解释、预测其行为并在其周围感到安全。本研究调查了类人机器人在指向任务中手臂动作的可辨识性，旨在理解人类如何从截断的动作和身体线索中预测机器人的意图。我们设计了一个使用NICO类人机器人的实验，参与者观察其手臂指向触摸屏上目标的动作。机器人的线索在不同条件下有所不同：凝视、指向，以及指向时眼神一致或不一致。手臂轨迹在完成60%或80%时停止，参与者预测最终目标。我们测试了多模态优势假说和眼部优先假说，实验结果均支持了这两个假说。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [224] [From Canada to Japan: How 10,000 km Affect User Perception in Robot Teleoperation](https://arxiv.org/abs/2508.05143)
> *从加拿大到日本：10,000公里如何影响机器人遥操作中的用户感知*

*Siméon Capy, Thomas M. Kwok, Kevin Joseph, Yuichiro Kawasumi, Koichi Nagashima, Tomoya Sasaki, Yue Hu, Eiichi Yoshida* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人遥操作, 用户感知, 远程控制, 距离效应, 老年护理

**Comment:** 

> **TL;DR:** 本研究探讨了长距离（10,000公里）机器人遥操作对非专业用户感知的影响，发现远程操作与本地操作在用户感知上无显著差异，表明远程机器人是本地控制的可行替代方案。

**AI_Comments:** 这项研究的创新之处在于其对极长距离（10,000公里）机器人遥操作用户感知的实证研究，挑战了直觉上距离会显著影响用户体验的假设。其发现远程操作与本地操作无显著差异，对于推广机器人遥操作技术，特别是在远程医疗和护理等领域具有重要意义。局限性可能在于其对“非专业用户感知”的衡量方式，以及实验环境的真实性是否能完全模拟实际应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 机器人遥操作（RTo）已成为本地控制的一种可行替代方案，尤其是在仍需要人工干预的情况下。本研究旨在探讨距离对RTo中用户感知的影响，并探索遥操作机器人在老年护理中的潜力。

**Method:** 研究设计了一个评估非专业用户对长距离RTo感知的协议，检查了交互前后用户感知的变化，并与本地操作机器人进行了比较。使用了包含多个问卷的特定协议，以及基于机器人操作系统（ROS）和Unity的专用软件架构。

**Result:** 结果显示，本地和远程机器人条件之间没有统计学上的显著差异。

**Conclusion:** 研究表明，机器人可能是传统本地控制的一种可行替代方案。

> **ai_Abstract:** 本研究调查了长距离（10,000公里）机器人遥操作（RTo）对非专业用户感知的影响，并与本地操作进行了比较。通过设计包含问卷和基于ROS/Unity软件的实验协议，研究发现远程与本地操作在用户感知上无显著差异。这表明即使在长距离下，遥操作机器人仍是本地控制的有效替代方案，尤其在老年护理等需要人工干预的场景中具有应用潜力。

> **摘要翻译:** 机器人遥操作（RTo）已成为本地控制的一种可行替代方案，尤其是在仍需要人工干预的情况下。本研究旨在探讨距离对RTo中用户感知的影响，探索遥操作机器人在老年护理中的潜力。我们提出了一种针对非专业用户对长距离RTo感知的评估方法，考察了他们在交互前后感知的变化，并将其与本地操作机器人进行了比较。我们设计了一个由多个问卷组成的特定协议，以及一个使用机器人操作系统（ROS）和Unity的专用软件架构。结果显示，本地和远程机器人条件之间没有统计学上的显著差异，这表明机器人可能是传统本地控制的一种可行替代方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [231] [GhostShell: Streaming LLM Function Calls for Concurrent Embodied Programming](https://arxiv.org/abs/2508.05298)
> *GhostShell：面向并发具身编程的流式LLM函数调用*

*Jian Gong, Youwei Huang, Bo Yuan, Ming Zhu, Juncheng Zhan, Jinke Wang, Hang Shu, Mingyue Xiong, Yanjun Ye, Yufan Zu, Yang Zhou, Yihan Ding, Xuannian Chen, Xingyu Lu, Runjie Ban, Bingchao Huang, Fusen Liu* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 具身编程, LLM, 流式函数调用, 并发控制, 机器人

**Comment:** 

> **TL;DR:** GhostShell提出了一种新颖的方法，通过流式LLM函数调用实现具身系统的并发行为编程，显著提高了响应速度和行为正确性。

**AI_Comments:** GhostShell的创新之处在于其将LLM的流式输出直接转化为具身系统的并发行为，显著提升了响应速度和实时性，解决了传统具身编程中行为序列预设的僵化问题。其多通道调度机制也有效地管理了复杂的多组件机器人动作。这项工作对于推动LLM在机器人领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法依赖预设动作序列或行为树来驱动具身系统，效率低下且缺乏灵活性。GhostShell旨在通过LLM流式增量函数调用，实现具身系统的即时行动和并发行为编程。

**Method:** GhostShell包含一个流式XML函数令牌解析器、一个动态函数接口映射器和一个多通道调度器。该调度器能够协调通道内同步和通道间异步的函数调用，从而根据LLM的指示协调多个机器人组件的串行-并行具身动作。

**Result:** 在机器人原型COCO上对34个真实世界交互任务和多个LLM进行评估，GhostShell在Claude-4 Sonnet上达到了0.85的行为正确性度量（Behavioral Correctness Metric），并且比LLM原生函数调用API快66倍。它在长时多模态任务中也表现出强大的鲁棒性和泛化能力。

**Conclusion:** GhostShell通过流式LLM函数调用实现了具身系统高效、实时的并发行为编程，显著优于传统方法，并在各种任务中展现出卓越的性能和普适性。

> **ai_Abstract:** GhostShell是一种创新的具身编程方法，它利用大型语言模型（LLM）的流式函数调用，实现具身系统的即时和并发行为控制，克服了传统预设动作序列的局限性。该系统包含流式XML解析器、动态接口映射器和多通道调度器，能够协调复杂的机器人动作。实验结果表明，GhostShell在行为正确性和响应速度上均达到最先进水平，尤其在长时多模态任务中展现出强大的鲁棒性和泛化能力。

> **摘要翻译:** 我们提出了GhostShell，一种利用大型语言模型（LLM）实现具身系统流式和并发行为编程的新方法。与依赖预设动作序列或行为树的传统方法不同，GhostShell通过LLM流式输出令牌时增量地发出函数调用，从而驱动具身系统即时行动。GhostShell具有一个流式XML函数令牌解析器、一个动态函数接口映射器和一个多通道调度器，该调度器能够协调通道内同步和通道间异步的函数调用，从而根据LLM的指示协调多个机器人组件的串行-并行具身动作。我们通过在机器人原型COCO上进行34个真实世界交互任务和多个LLM的全面接地实验来评估GhostShell。结果表明，我们的方法在使用Claude-4 Sonnet时达到了0.85的最新行为正确性度量，并且比LLM原生函数调用API的响应时间快66倍。GhostShell在长时多模态任务中也证明了其有效性，展示出强大的鲁棒性和泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [238] [Affecta-Context: The Context-Guided Behavior Adaptation Framework](https://arxiv.org/abs/2508.05359)
> *Affecta-Context：上下文引导的行为适应框架*

*Morten Roed Frederiksen, Kasper Støy* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 社交机器人, 行为适应, 上下文引导, 人机交互, 泛化

**Comment:** 

> **TL;DR:** 提出Affecta-Context框架，使社交机器人能根据物理上下文自主学习和适应行为，并在未访问环境中泛化。

**AI_Comments:** 该论文提出了一种创新的上下文引导行为适应框架，使社交机器人能够根据物理环境和用户偏好自主学习和调整行为。其亮点在于框架的通用性以及机器人对未访问上下文的泛化能力，这对于提高社交机器人的自主性和适应性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 促进社交机器人的行为适应，使其在人机交互中能根据物理上下文指导行为。

**Method:** 框架包含两部分：一是表示遇到的上下文，二是学习通过人机交互优先选择行为。它根据物理属性聚类遇到的上下文，并在每个上下文中学习优化机器人行为的物理属性，以适应当前环境和用户偏好。通过在两种不同物理上下文、6名不同人类参与者的72次交互中训练，使机器人自主学习离散行为的优先级。

**Result:** 机器人能够自主学习离散行为的优先级，并展示了对输入进行泛化以及将其行为匹配到以前未访问的物理上下文的能力。

**Conclusion:** Affecta-Context框架能够使机器人自主学习离散行为的优先级，并验证了其泛化能力，使其行为能适应新的物理环境。

> **ai_Abstract:** 本文提出了Affecta-Context框架，旨在促进社交机器人在人机交互中的行为适应。该框架通过表示和聚类物理上下文，并学习优化机器人行为以适应环境和用户偏好。实验通过在多种交互和上下文下训练，证明了机器人能够自主学习离散行为的优先级，并能泛化到新的、未访问的物理环境。

> **摘要翻译:** 本文提出了Affecta-context，一个通用的框架，旨在促进社交机器人的行为适应。该框架利用物理上下文信息来指导其在人机交互中的行为。它由两部分组成：一部分表示遇到的上下文，另一部分学习通过人机交互优先选择行为。当遇到物理上下文时，框架会根据其测量的物理属性对其进行聚类。在每个上下文中，框架学习优先选择行为，以优化机器人行为的物理属性，使其符合当前环境和与之交互的用户的偏好。本文通过使机器人自主学习离散行为的优先级，展示了Affecta-context框架的能力。这是通过在两种不同物理上下文和6名不同人类测试参与者的72次交互中进行训练实现的。本文通过验证机器人对输入进行泛化以及将其行为匹配到以前未访问的物理上下文的能力，展示了经过训练的Affecta-context框架。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [245] [A Multi-view Landmark Representation Approach with Application to GNSS-Visual-Inertial Odometry](https://arxiv.org/abs/2508.05368)
> *一种多视角地标表示方法及其在GNSS-视觉-惯性里程计中的应用*

*Tong Hua, Jiale Han, Wei Ouyang* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-07**

**Keywords:** GNSS-视觉-惯性里程计, 多视角, 地标表示, 姿态估计, 传感器融合

**Comment:** 

> **TL;DR:** 本文提出了一种多视角姿态估计方法，以解决传统不变扩展卡尔曼滤波器（IEKF）在视觉辅助传感器融合中联合优化相机姿态和地标时计算负担过高的问题，并将其应用于GNSS-视觉-惯性里程计（GVIO），通过仿真和实际实验证明了其在效率和精度上的优越性。

**AI_Comments:** 本文提出了一种创新的多视角地标表示方法，通过构建一个仅姿态的视觉测量模型，有效地解决了传统IEKF在传感器融合中地标和姿态联合优化带来的高计算负担问题。其主要创新点在于直接关联多相机姿态与地标表示，并证明了其紧密耦合和零空间特性。这对于实时、高效的GNSS-视觉-惯性里程计具有重要意义，提升了多传感器融合的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的不变扩展卡尔曼滤波器（IEKF）在视觉辅助传感器融合中，当联合优化相机姿态和地标时，通常会面临较高的计算负担。

**Method:** 本文提出了一种多视角姿态估计方法，其核心贡献在于推导了一个直接将地标表示与多个相机姿态和观测相关联的视觉测量模型。这种仅姿态的测量被证明在地标和姿态之间是紧密耦合的，并保持了一个独立于估计姿态的完美零空间。该方法应用于基于滤波器的GNSS-视觉-惯性里程计（GVIO），并结合了一种新颖的特征管理策略。

**Result:** 通过仿真测试和实际实验，证明了所提出的方法在效率和精度方面优于现有方法。

**Conclusion:** 本文提出的多视角姿态估计方法通过创新的视觉测量模型，有效解决了视觉辅助传感器融合中IEKF的计算负担问题，并在GNSS-视觉-惯性里程计应用中展现出卓越的效率和精度。

> **ai_Abstract:** 本文针对视觉辅助传感器融合中不变扩展卡尔曼滤波器（IEKF）在联合优化相机姿态和地标时计算负担过高的问题，提出了一种多视角姿态估计方法。该方法的核心在于推导了一个将地标表示与多个相机姿态和观测直接关联的视觉测量模型，该模型被证明是紧密耦合且具有独立零空间的。研究将此方法应用于GNSS-视觉-惯性里程计（GVIO），并结合了新颖的特征管理策略。仿真和实际实验结果表明，所提出的方法在效率和精度上均表现出优越性。

> **摘要翻译:** 不变扩展卡尔曼滤波器（IEKF）一直是视觉辅助传感器融合中的一项重要技术。然而，当联合优化相机姿态和地标时，它通常会面临较高的计算负担。为了提高其效率和多传感器融合的适用性，本文提出了一种多视角姿态估计方法，并将其应用于GNSS-视觉-惯性里程计（GVIO）。我们的主要贡献是推导了一个直接将地标表示与多个相机姿态和观测相关联的视觉测量模型。这种仅姿态的测量被证明在地标和姿态之间是紧密耦合的，并保持了一个独立于估计姿态的完美零空间。最后，我们将所提出的方法应用于基于滤波器的GVIO，并结合了一种新颖的特征管理策略。通过仿真测试和实际实验，证明了所提出方法在效率和精度方面的优越性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [252] [Robots can defuse high-intensity conflict situations](https://arxiv.org/abs/2508.05373)
> *机器人可以化解高强度冲突情境*

*Morten Roed Frederiksen, Kasper Støy* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人, 冲突化解, 情感表达, 人机交互, 社交意识

**Comment:** 

> **TL;DR:** 本研究探讨了机器人如何通过五种情感表达方式来化解与人类之间的高强度冲突，发现所有方式都能有效缓解冲突，且社交意识比表达能力更重要。

**AI_Comments:** 本研究的创新点在于系统地评估了不同情感表达方式在机器人化解冲突中的作用。其重要性在于揭示了机器人社交智能的关键在于情境感知和恰当反应，而非单纯的表达能力，这为未来人机交互设计提供了宝贵见解。局限性可能在于模拟环境与真实世界冲突的差异。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在理解机器人如何化解与人类之间的高强度冲突，特别是通过使用不同的情感表达方式来减轻人们对表现不佳的机器人的敌意，并发现每种方式的优缺点。

**Method:** 研究在一个模拟冲突情境中使用了定制的情感机器人，并招募了105名测试参与者。测试重点是机器人通过承认冲突和表达悔恨来化解局势，并评估五种不同情感表达方式的有效性。

**Result:** 所有测试的情感表达方式都能成功用于化解冲突并传达对对抗的承认。各项评分非常相似，但运动模式与其他模式不同（ANON p<.05）。测试参与者对机器人在对抗中受影响程度的情感解释也相似。

**Conclusion:** 化解高强度互动可能不需要特别关注机器人的表达能力，而更需要关注其社交意识以及根据情况做出反应的能力。

> **ai_Abstract:** 本研究探讨了机器人在高强度人机冲突中通过情感表达来化解冲突的有效性。实验中，一个定制机器人与105名参与者在模拟冲突中互动，通过五种不同的情感表达方式（如承认冲突和表达悔恨）来缓解敌意。结果显示，所有表达方式均能有效化解冲突，且对机器人受影响程度的感知相似。研究认为，化解冲突的关键在于机器人的社交意识和情境反应能力，而非其表达能力本身。

> **摘要翻译:** 本文研究了人类与机器人之间高强度对抗的具体场景，以了解机器人如何化解冲突。它侧重于使用五种不同的情感表达方式作为化解冲突的主要驱动因素的有效性。目的是发现使用每种方式来减轻人们对表现不佳的机器人所感到的敌意方面的任何优点或缺点。通过让机器人更好地承认冲突并表达悔恨来化解局势。为了方便测试，我们在模拟冲突情境中使用了定制的情感机器人，有105名测试参与者。结果表明，所有测试的表达方式都可以成功地用于化解局势并传达对对抗的承认。评分非常相似，但运动方式与其他方式不同（ANON p<.05）。测试参与者对机器人在对抗中受到的影响程度的情感解释在所有表达方式中也相似。这表明，化解高强度互动可能不需要特别关注机器人的表达能力，而更需要关注其对情况的社交意识和相应反应的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [259] [Computational Design and Fabrication of Modular Robots with Untethered Control](https://arxiv.org/abs/2508.05410)
> *模块化机器人计算设计与无束缚控制制造*

*Manas Bhargava, Takefumi Hiraki, Malina Strugaru, Michal Piovarci, Chiara Daraio, Daisuke Iwai, Bernd Bickel* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 模块化机器人, 分布式驱动, 液晶弹性体, 无束缚控制, 计算设计

**Comment:** 

> **TL;DR:** 该研究提出了一种计算框架，用于设计和控制具有分布式驱动的模块化机器人，通过3D打印骨骼和LCE肌肉实现无束缚控制和复杂形变，旨在模仿生物的适应性。

**AI_Comments:** 该论文的创新之处在于提出了一种将3D打印骨骼与LCE肌肉相结合的新型模块化构建块，并实现了通过红外辐射的无束缚分布式控制。同时，开发了协同优化计算工具，使得机器人设计和控制更加高效和灵活。这为模仿生物的适应性和多功能性机器人提供了新的思路和方法，对软体机器人和模块化机器人领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的软体机器人系统通常只针对单一功能进行优化，缺乏按需改变形态或功能的能力，或者常常需要连接笨重的控制系统。为了解决这些挑战，该研究旨在开发一种模仿自然生物分布式驱动的机器人。

**Method:** 该研究提出了一种新的构建模块，结合3D打印骨骼和液晶弹性体（LCE）肌肉作为轻量级执行器，实现了肌肉骨骼机器人的模块化组装。开发了响应红外辐射收缩的LCE杆，从而实现对分布式骨骼网络的局部和无束缚控制，进而导致机器人的整体变形。此外，开发了两种计算工具：一个用于优化机器人的骨骼图，实现多个目标变形；另一个用于协同优化骨骼设计和控制步态以实现目标运动。

**Result:** 通过构建多个机器人验证了该系统，这些机器人展示了复杂的形状变形、不同的控制方案以及对环境的适应性。系统整合了模块化材料构建、无束缚分布式控制和计算设计的进步。

**Conclusion:** 该系统整合了模块化材料构建、无束缚分布式控制和计算设计的进步，引入了新一代机器人，使我们更接近生物体的能力。

> **ai_Abstract:** 该论文介绍了一个用于设计和控制模块化机器人的计算框架，旨在模仿生物的分布式驱动。研究提出了一种结合3D打印骨骼和液晶弹性体（LCE）肌肉的新型模块化构建块，通过红外辐射实现无束缚的局部控制和整体变形。为充分利用设计空间，开发了两种计算工具，分别用于优化骨骼图以实现多目标变形，以及协同优化骨骼设计和步态以实现目标运动。实验验证了所构建机器人能展示复杂的形状变形、多样的控制方式和环境适应性，代表了集成模块化材料、无束缚控制和计算设计的新一代机器人。

> **摘要翻译:** 自然生物通过其肌肉骨骼系统利用分布式驱动来调整步态以穿越各种地形，或改变身体形态以执行各种任务。在机器人领域，模仿这种广泛的适应性和运动范围是一个长期存在的挑战。这促使人类开发了各种模仿自然生物的软体机器人系统。然而，此类系统通常只针对单一功能进行优化，缺乏按需改变形态或功能的能力，或者常常需要连接笨重的控制系统。为了解决这些挑战，我们提出了一个用于设计和控制机器人的框架，该框架通过利用分布式驱动来模仿自然的蓝图。我们提出了一种新颖的构建模块，将3D打印骨骼与液晶弹性体（LCE）肌肉结合作为轻量级执行器，并实现了肌肉骨骼机器人的模块化组装。我们开发了响应红外辐射收缩的LCE杆，从而实现了对分布式骨骼网络的局部和无束缚控制，进而导致机器人的整体变形。此外，为了充分利用广阔的设计空间，我们开发了两种计算工具：一个用于优化机器人的骨骼图，实现多个目标变形；另一个用于协同优化骨骼设计和控制步态以实现目标运动。我们通过构建多个机器人验证了我们的系统，这些机器人展示了复杂的形状变形、不同的控制方案以及对环境的适应性。我们的系统整合了模块化材料构建、无束缚分布式控制和计算设计的进步，引入了新一代机器人，使我们更接近生物体的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [266] [Do Robots Really Need Anthropomorphic Hands?](https://arxiv.org/abs/2508.05415)
> *机器人真的需要拟人手吗？*

*Alexander Fabisch, Wadhah Zai El Amri, Chandandeep Singh, Nicolás Navarro-Guerrero* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 拟人手, 机器人操纵, 灵活性, 手部设计, 综述

**Comment:** 

> **TL;DR:** 该研究调查了机器人是否真的需要拟人手，发现复杂的五指手并非总是必需的，简单的三指设计或非拟人手可能在灵活性上表现更好，腕部灵活性和手指外展/内收是关键。

**AI_Comments:** 该论文挑战了机器人需要模仿人类手部设计的普遍假设，为机器人手部设计提供了实用的权衡考量。其创新之处在于提出并支持了非拟人手设计可能在某些方面超越人手的观点，为未来的机器人操纵器设计开辟了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于人类操纵技能的高度复杂性，本研究旨在探讨人类手部及其相关的生物力学特性、传感器和控制机制是否是机器人学中应追求的理想目标，即机器人是否真的需要拟人手。

**Method:** 本研究通过一份调查报告进行，该报告概述了人手，比较了市售的机器人手和假肢手，并系统回顾了手部机制及其所能实现的操作技能。

**Result:** 研究发现，复杂的五指手并非所有任务都必需。腕部灵活性和手指外展/内收对操纵能力很重要。相反，增加手指、执行器或自由度的数量通常不是必需的。三指设计在简单性和灵活性之间取得了很好的折衷。具有两对相对手指的非拟人手设计或具有六根手指的人手可以进一步提高灵活性，这表明人手可能不是最佳选择。

**Conclusion:** 拟人手并非普遍必需；对于某些任务或整体灵活性而言，更简单的设计甚至非拟人设计可能更优。腕部灵活性和手指外展/内收是关键因素。

> **ai_Abstract:** 本论文探讨了机器人是否需要拟人手，通过对人手、市售机器人手和假肢手进行比较，并系统回顾手部机制及技能。研究发现，复杂的五指手并非所有任务都必需，腕部灵活性和手指外展/内收对操纵能力至关重要。论文指出，增加手指数量或自由度通常是不必要的，三指设计在简单性和灵活性之间取得了良好平衡。此外，非拟人手设计（如两对相对手指）或六指人手可以进一步提高灵活性，暗示人手可能并非机器人设计的最佳范本。

> **摘要翻译:** 人类的操纵技能代表了其自主运动功能的巅峰，需要协调多个自由度并处理高维度的传感器输入才能达到如此高水平的灵活性。因此，我们着手回答人类手部及其相关的生物力学特性、传感器和控制机制是否是我们机器人学中应追求的理想目标——我们真的需要拟人机器人手吗？
这项调查可以帮助实践者在手部复杂性和潜在操纵技能之间做出权衡。我们概述了人手，比较了市售的机器人手和假肢手，并系统回顾了手部机制及其所能实现的操作技能。这引出了后续问题：机器人实现其所需大多数技能的机制和传感器的最低要求是什么？要达到人类水平的灵活性还缺少什么？我们能否超越人类的灵活性？
尽管复杂的五指手通常被用作机器人操纵器的最终目标，但它们并非所有任务都必需。我们发现，腕部灵活性和手指外展/内收对操纵能力很重要。相反，增加手指、执行器或自由度的数量通常不是必需的。三指设计在简单性和灵活性之间取得了很好的折衷。具有两对相对手指的非拟人手设计或具有六根手指的人手可以进一步提高灵活性，这表明人手可能不是最佳选择。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [273] [CleanUpBench: Embodied Sweeping and Grasping Benchmark](https://arxiv.org/abs/2508.05543)
> *CleanUpBench：具身清扫与抓取基准*

*Wenbo Li, Guanting Chen, Tao Zhao, Jiyao Wang, Tianxin Hu, Yuwen Liao, Weixiang Guo, Shenghai Yuan* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 具身AI, 移动机器人, 基准测试, 清扫, 抓取

**Comment:** 

> **TL;DR:** CleanUpBench是一个新的具身AI基准，专注于移动清扫和抓取机器人，旨在弥补学术研究与实际应用之间的差距。

**AI_Comments:** CleanUpBench的创新之处在于其专注于移动清洁机器人这一具身AI领域中具有高度商业可行性的特定应用，并填补了该领域系统评估基准的空白。它提供了一个现实且可扩展的测试平台，有助于推动具身智能从实验室走向实际部署，特别是在服务机器人领域。

<details>
  <summary>Details</summary>

**Motivation:** 现有的具身AI基准测试大多针对复杂人形机器人或大规模模拟，与实际部署相距甚远。移动清洁机器人作为现实且商业可行的平台正在迅速兴起，但目前缺乏系统评估其在结构化、多目标清洁任务中表现的基准，这揭示了学术研究与实际应用之间的关键差距。

**Method:** 本文引入了CleanUpBench，一个可复现和可扩展的基准，用于评估具身智能体在现实室内清洁场景中的表现。该基准基于NVIDIA Isaac Sim构建，模拟了一个配备清扫机制和六自由度机械臂的移动服务机器人，使其能够与异质物体进行交互。CleanUpBench包含手动设计的环境和程序生成布局以评估泛化能力，并提供了一个涵盖任务完成度、空间效率、运动质量和控制性能的综合评估套件。为支持比较研究，论文还提供了基于启发式策略和基于地图规划的基线智能体。

**Result:** Not mentioned in abstract

**Conclusion:** CleanUpBench弥补了低级技能评估与全场景测试之间的空白，为日常环境中的具身智能提供了可扩展的测试平台。

> **ai_Abstract:** 本文介绍了CleanUpBench，这是一个为移动清洁机器人设计的具身AI基准测试平台，旨在弥补当前学术研究与实际应用之间的空白。该基准基于NVIDIA Isaac Sim构建，模拟了具备清扫和抓取双模式能力的移动服务机器人，能在现实室内环境中与多种物体交互。CleanUpBench包含多样化的测试环境、全面的评估指标以及基线智能体，为具身智能在日常场景中的研究提供了一个可扩展的测试平台。

> **摘要翻译:** 具身AI基准测试推动了导航、操作和推理的发展，但大多数目标是复杂的类人机器人或大规模模拟，这与实际部署相距甚远。相比之下，具有清扫和抓取等双模式能力的移动清洁机器人正迅速成为现实且商业上可行的平台。然而，目前还没有一个基准能够系统地评估这些智能体在结构化、多目标清洁任务中的表现，这揭示了学术研究与实际应用之间的关键差距。我们引入了CleanUpBench，一个可复现和可扩展的基准，用于评估具身智能体在现实室内清洁场景中的表现。CleanUpBench基于NVIDIA Isaac Sim构建，模拟了一个配备清扫机制和六自由度机械臂的移动服务机器人，能够与异质物体进行交互。该基准包括手动设计的环境和一个程序生成布局，以评估泛化能力，以及一个涵盖任务完成度、空间效率、运动质量和控制性能的综合评估套件。为了支持比较研究，我们提供了基于启发式策略和基于地图规划的基线智能体。CleanUpBench弥补了低级技能评估与全场景测试之间的空白，为日常环境中的具身智能提供了可扩展的测试平台。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [280] [Robust adaptive fuzzy sliding mode control for trajectory tracking for of cylindrical manipulator](https://arxiv.org/abs/2508.05584)
> *圆柱坐标机械手轨迹跟踪的鲁棒自适应模糊滑模控制*

*Van Cuong Pham, Minh Hai Tran, Phuc Anh Nguyen, Ngoc Son Vu, Nga Nguyen Thi* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 模糊滑模控制, 轨迹跟踪, 圆柱坐标机械手, 鲁棒控制, 自适应控制

**Comment:** 

> **TL;DR:** 本研究提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法，以提高圆柱坐标机械手的轨迹跟踪性能，并通过仿真验证了其在精度、稳定性和抗扰动性方面的显著提升。

**AI_Comments:** 这项研究的创新之处在于将模糊逻辑与滑模控制相结合，形成一种鲁棒自适应的控制策略，以有效处理圆柱坐标机械手的不确定动力学。其重要性在于通过提升轨迹跟踪性能，直接贡献于数控和3D打印等工业应用的精度提升。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提高圆柱坐标机械手的轨迹跟踪性能，这类机械手广泛应用于数控和3D打印等领域。

**Method:** 本文提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法。该方法将模糊逻辑与滑模控制（SMC）相结合，其中模糊逻辑用于近似系统的不确定动力学，而滑模控制则确保了强大的性能，从而增强了系统的适应性和鲁棒性。

**Result:** MATLAB/Simulink仿真结果表明，与传统方法相比，AFSMC显著提高了轨迹跟踪精度、稳定性和抗扰动能力。

**Conclusion:** 本研究强调了AFSMC在控制机器人机械手方面的有效性，有助于提高工业机器人应用的精度。

> **ai_Abstract:** 本研究提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法，用于提升圆柱坐标机械手的轨迹跟踪性能。该方法结合了模糊逻辑与滑模控制，以处理系统的不确定性并确保控制器性能。通过MATLAB/Simulink仿真验证，AFSMC在轨迹跟踪精度、稳定性及抗扰动能力方面均优于传统方法，证实了其在工业机器人应用中提高精度的潜力。

> **摘要翻译:** 本研究提出了一种鲁棒自适应模糊滑模控制（AFSMC）方法，以提高圆柱坐标机械手的轨迹跟踪性能，该机械手广泛应用于数控和3D打印等领域。所提出的方法将模糊逻辑与滑模控制（SMC）相结合，以增强适应性和鲁棒性，其中模糊逻辑用于近似系统的不确定动力学，而SMC则确保了强大的性能。MATLAB/Simulink仿真结果表明，AFSMC与传统方法相比，显著提高了轨迹跟踪精度、稳定性和抗扰动能力。这项研究强调了AFSMC在控制机器人机械手方面的有效性，有助于提高工业机器人应用的精度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [287] [Di-NeRF: Distributed NeRF for Collaborative Learning with Relative Pose Refinement](https://arxiv.org/abs/2402.01485)
> *Di-NeRF: 分布式NeRF用于协作学习与相对位姿优化*

*Mahboubeh Asadi, Kourosh Zareinia, Sajad Saeedi* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 分布式NeRF, 协作学习, 相对位姿优化, 多机器人系统, 3D重建

**Comment:** 

> **TL;DR:** Di-NeRF是一种分布式算法，使多机器人能协作优化NeRF参数并精炼相对位姿，实现稳健3D重建。

**AI_Comments:** 该论文创新性地将NeRF应用于多机器人分布式协作学习，并通过联合优化相对位姿解决了传统多机器人系统中位姿精度要求高的问题，提高了3D重建的鲁棒性和效率。这对于未知环境的快速、大规模映射具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 单个机器人对未知环境的协作映射速度慢且鲁棒性差。协作方法需要分布式范式以实现可扩展性并解决通信问题。

**Method:** 本文提出了一种完全分布式算法，使一组机器人能够集体优化神经辐射场（NeRF）的参数。该算法涉及每个机器人通过网状网络通信其训练好的NeRF参数，其中每个机器人训练自己的NeRF并且只访问自己的视觉数据。此外，所有机器人的相对位姿与模型参数一同进行联合优化，从而实现对相对相机位姿精度要求较低的映射。

**Result:** 实验证明了多机器人系统可以从多个NeRF优化得到的、可微分且鲁棒的3D重建中获益。在真实世界和合成数据上的实验验证了所提算法的效率。

**Conclusion:** 该研究证明了通过分布式NeRF和相对位姿联合优化，多机器人系统能够进行更高效、更鲁棒的环境映射，即使在相对相机位姿精度较低的情况下也能实现。

> **ai_Abstract:** 本文提出Di-NeRF，一种完全分布式算法，旨在解决多机器人协作映射中NeRF参数优化和相对位姿精炼问题。每个机器人独立训练NeRF并共享参数，同时联合优化所有机器人的相对位姿。该方法使得在相对相机位姿精度较低的情况下也能进行高效、鲁棒的3D重建，并在真实和合成数据上验证了其有效性。

> **摘要翻译:** 对未知环境的协作映射可以比单个机器人更快、更鲁棒地完成。然而，协作方法需要一个分布式范式来实现可扩展性并解决通信问题。这项工作提出了一种完全分布式算法，使一组机器人能够集体优化神经辐射场（NeRF）的参数。该算法涉及每个机器人通过网状网络通信其训练好的NeRF参数，其中每个机器人训练自己的NeRF并且只访问自己的视觉数据。此外，所有机器人的相对位姿与模型参数一同进行联合优化，从而实现对相对相机位姿精度要求较低的映射。我们展示了多机器人系统可以从多个NeRF优化得到的、可微分且鲁棒的3D重建中获益。在真实世界和合成数据上的实验证明了所提算法的效率。有关实验视频和补充材料，请参阅项目网站（https://sites.google.com/view/di-nerf/home）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [293] [Multi-Fidelity Reinforcement Learning for Time-Optimal Quadrotor Re-planning](https://arxiv.org/abs/2403.08152)
> *用于时间最优四旋翼重新规划的多保真强化学习*

*Gilhyun Ryou, Geoffrey Wang, Sertac Karaman* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 多保真强化学习, 四旋翼无人机, 轨迹规划, 实时, 贝叶斯优化

**Comment:** 

> **TL;DR:** 本文提出了一种多保真强化学习方法（MFRL），通过共同训练规划策略和奖励估计器，解决高速无人机在线轨迹规划的挑战，实现了在模拟和真实世界中更快、更可靠的轨迹更新。

**AI_Comments:** 该论文的创新点在于将多保真强化学习应用于四旋翼无人机的轨迹规划，并引入了策略与奖励估计器的共同训练机制，特别是通过多保真贝叶斯优化高效构建奖励模型，并进一步整合真实世界飞行数据，极大地提高了模型在实际应用中的鲁棒性和效率。其显著的性能提升（轨迹更新时间从数分钟缩短到2毫秒）表明了该方法的实用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 高速无人机在线轨迹规划面临两大挑战：需要精确建模复杂动力学，同时受限于计算能力。现有方法难以在满足计算限制的同时，建立真实的动力学模型并训练可实时部署的规划策略。

**Method:** 本文提出了一种多保真强化学习（MFRL）方法。该方法涉及规划策略和奖励估计器的共同训练。奖励估计器通过多保真贝叶斯优化高效训练，该优化方法建模了不同保真度水平之间的相关性，从而在低保真度基础上构建高保真度模型，并能通过有限的高保真度实验准确开发奖励模型。该框架进一步扩展，将真实世界飞行实验纳入强化学习训练中，使奖励模型精确反映真实世界约束，并拓宽策略在真实世界场景中的适用性。

**Result:** 训练出的策略与基线“snap minimization”方法相比，不仅生成了更快、更可靠的轨迹，而且轨迹更新平均只需2毫秒，而基线方法需要数分钟。

**Conclusion:** 本文提出的多保真强化学习方法能有效解决高速无人机在线轨迹规划的挑战，生成更快、更可靠的轨迹，并显著缩短轨迹更新时间，在模拟和真实世界环境中均表现出色。

> **ai_Abstract:** 本文提出了一种名为多保真强化学习（MFRL）的新方法，旨在解决高速无人机在线轨迹规划中遇到的复杂动力学建模和计算限制问题。该方法通过共同训练规划策略和奖励估计器实现，其中奖励估计器利用多保真贝叶斯优化，有效地结合低保真度数据构建高保真度模型，并纳入真实世界飞行数据以提高准确性。实验证明，与传统方法相比，MFRL能生成更快、更可靠的轨迹，并将轨迹更新时间从数分钟缩短至平均2毫秒。

> **摘要翻译:** 高速无人机在线轨迹规划由于需要精确建模复杂动力学，同时受限于计算能力，因此带来了重大挑战。本文提出了一种多保真强化学习方法（MFRL），旨在有效地创建真实的动力学模型，并同时训练一个可以实时部署的规划策略。所提出的方法涉及规划策略和奖励估计器的共同训练；后者预测策略输出的性能，并通过多保真贝叶斯优化高效训练。这种优化方法建模了不同保真度水平之间的相关性，从而在低保真度基础上构建高保真度模型，这使得可以用有限的高保真度实验准确开发奖励模型。该框架进一步扩展，将真实世界飞行实验纳入强化学习训练中，允许奖励模型精确反映真实世界约束，并拓宽策略在真实世界场景中的适用性。我们通过在模拟和真实世界环境中训练和测试规划策略，进行了严格的评估。与基线“snap minimization”方法相比，训练出的策略不仅生成了更快、更可靠的轨迹，而且平均在2毫秒内完成轨迹更新，而基线方法需要数分钟。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [301] [Quaternion-Based Sliding Mode Control for Six Degrees of Freedom Flight Control of Quadrotors](https://arxiv.org/abs/2403.10934)
> *四元数滑模控制用于四旋翼飞行器六自由度飞行控制*

*Amin Yazdanshenas, Reza Faieghi* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 四元数, 滑模控制, 四旋翼, 六自由度, 飞行控制

**Comment:** 

> **TL;DR:** 本文提出了一种新的基于四元数的六自由度滑模控制器，通过级联架构解决了现有方法的局限性，实现了更好的性能、全局稳定性和无缠绕问题，并在挑战性机动中表现出色。

**AI_Comments:** 该论文通过提出一种结合级联架构和新型四元数姿态控制器的滑模控制方法，有效地解决了四旋翼飞行器控制中长期存在的缠绕问题和稳定性限制，同时优化了控制效率。其创新性在于巧妙地利用四元数特性实现全局稳定性和结构简化，并结合无坐标方法提升了轨迹生成的效率。这项工作对于提升四旋翼飞行器在高难度机动下的鲁棒性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有四旋翼滑模控制方法存在局限性：基于欧拉角的SMC在高俯仰或高滚转机动中性能不佳；基于四元数的SMC有缠绕问题和复杂架构；无坐标方法速度慢且仅近似全局稳定。

**Method:** 本文提出一种新的六自由度滑模飞行控制器，采用级联架构：外环是位置控制器，内环是基于四元数的姿态控制器。位置控制器使用无坐标方法生成姿态控制器所需的期望轨迹。四元数姿态控制器利用四元数超球面的自然特性，具有简单结构，同时提供全局稳定性并避免缠绕问题。

**Result:** 该控制器在存在模型不确定性和干扰的情况下，在翻转和高速轨迹跟踪等挑战性机动中，始终优于其他三种基准控制方法，具有更少的控制工作量和执行器饱和度。

**Conclusion:** 该控制器提供高效且有效的飞行控制。

> **ai_Abstract:** 本文提出了一种创新的六自由度滑模控制（SMC）飞行控制器，旨在解决现有四旋翼SMC方法的固有缺陷，包括欧拉角方法的性能限制、四元数方法的缠绕和复杂性问题，以及无坐标方法的稳定性和速度问题。该控制器采用独特的级联架构，其中外部回路处理位置控制并生成基于无坐标方法的期望轨迹，内部回路则是一个基于四元数的姿态控制器。该姿态控制器利用四元数超球面的特性，实现了结构简化、全局稳定性和无缠绕操作。通过与现有控制方法在复杂机动（如翻转和高速跟踪）中的比较，该控制器在存在不确定性和干扰的情况下表现出卓越的性能，显著减少了控制工作量和执行器饱和度，从而实现了高效且有效的飞行控制。

> **摘要翻译:** 尽管对四旋翼飞行器的滑模控制（SMC）设计进行了广泛研究，但现有方法仍存在某些局限性。基于欧拉角的SMC公式在高俯仰或高滚转机动中性能不佳。基于四元数的SMC方法存在缠绕问题和复杂架构。无坐标方法速度慢且仅近似全局稳定。本文提出了一种新的六自由度SMC飞行控制器，以解决上述局限性。我们使用级联架构，外环为位置控制器，内环为基于四元数的姿态控制器。位置控制器使用无坐标方法为姿态控制器生成期望轨迹。基于四元数的姿态控制器利用四元数超球面的自然特性，结构简单，同时提供全局稳定性并避免缠绕问题。我们将我们的控制器与另外三种常见控制方法进行了比较，在存在模型不确定性和干扰的情况下，进行了翻转和高速轨迹跟踪等挑战性机动。我们的控制器始终优于基准方法，控制工作量和执行器饱和度更少，提供高效且有效的飞行控制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [308] [Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation with Volumetric Visual Data Fusion](https://arxiv.org/abs/2408.01225)
> *现实融合：基于体素视觉数据融合的鲁棒实时沉浸式移动机器人遥操作*

*Ke Li, Reinhard Bacher, Susanne Schmidt, Wim Leemans, Frank Steinicke* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人遥操作, 3D高斯飞溅, 沉浸式VR, 深度传感器, 态势感知

**Comment:** 

> **TL;DR:** Reality Fusion是一个新的机器人遥操作系统，通过将板载深度传感器与3D高斯飞溅表示的远程环境融合，实现了鲁棒的沉浸式VR机器人遥操作，显著提升了用户性能和态势感知。

**AI_Comments:** 该论文的创新点在于将3D高斯飞溅技术应用于机器人遥操作领域，有效解决了传统深度传感器视场有限的问题，并在数据流成本与视觉质量之间取得了平衡。提供开源实现和定制机器人有助于推动相关领域的研究和发展，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人遥操作系统在空间信息获取（深度传感器视场有限）和数据传输效率与视觉质量之间存在权衡，因此需要一种能有效扩展空间信息并平衡这些因素的沉浸式遥操作系统。

**Method:** 本文引入了Reality Fusion系统，该系统通过定位、流式传输、投影和合并板载深度传感器数据与以3D高斯飞溅（3DGS）表示的远程环境的高分辨率、高帧率、宽视场渲染，实现了鲁棒的以自我为中心和以异物为中心的沉浸式VR机器人遥操作。

**Result:** 通过对24名参与者的用户研究表明，Reality Fusion显著提高了用户性能、态势感知和用户偏好。

**Conclusion:** Reality Fusion系统通过有效融合深度传感器数据和3DGS，实现了更优越的沉浸式机器人遥操作体验，显著提升了用户表现和感知能力，并平衡了数据流成本与视觉质量的权衡。

> **ai_Abstract:** 本文提出了Reality Fusion系统，一种新颖的机器人遥操作解决方案。该系统将机器人板载深度传感器数据与基于3D高斯飞溅的远程环境渲染进行融合，实现了在沉浸式VR中鲁棒的机器人遥操作。它通过扩展深度传感器有限的视场并优化数据流效率与视觉质量的平衡，显著提升了用户性能、态势感知和用户偏好。研究团队还提供了开源实现以促进后续研究。

> **摘要翻译:** 我们引入了Reality Fusion，这是一个新颖的机器人遥操作系统，它将典型的板载深度传感器与表示为3D高斯飞溅（3DGS）的复杂远程环境的逼真、高分辨率、高帧率、宽视场（FoV）渲染进行定位、流式传输、投影和合并。我们的框架能够在沉浸式VR中实现鲁棒的以自我为中心和以异物为中心的机器人遥操作，其中3DGS有效地扩展了有限FoV深度传感器的空间信息，并平衡了数据流成本和数据视觉质量之间的权衡。我们通过一项包含24名参与者的用户研究评估了我们的框架，结果显示Reality Fusion显著提高了用户性能、态势感知和用户偏好。为了支持进一步的研究和开发，我们提供了一个开源实现，包括一个易于复制的定制遥在机器人、一个高性能虚拟现实3DGS渲染器和一个沉浸式机器人控制包。(源代码: https://github.com/uhhhci/RealityFusion)

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [315] [Task-driven SLAM Benchmarking For Robot Navigation](https://arxiv.org/abs/2409.16573)
> *机器人导航中的任务驱动型SLAM基准测试*

*Yanwei Du, Shiyu Feng, Carlton G. Cort, Patricio A. Vela* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** SLAM, 基准测试, 机器人导航, 精度, TaskSLAM-Bench

**Comment:** 

> **TL;DR:** 提出TaskSLAM-Bench，一个以精度为关键指标的任务驱动型SLAM基准测试方法，用于评估机器人导航中的SLAM性能。

**AI_Comments:** 该论文的创新点在于提出了一个以精度为核心、任务驱动的SLAM基准测试方法，弥补了现有基准测试在实际应用中对重复性关注不足的缺陷。其发现被动立体SLAM在特定场景下可与LiDAR SLAM媲美，为成本敏感的应用提供了潜在选择，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前SLAM基准测试忽略了重复性（精度）的重要性，而这在实际部署中至关重要，尤其是在移动辅助机器人导航任务中。

**Method:** 提出TaskSLAM-Bench，一种任务驱动的SLAM基准测试方法。该方法以精度作为关键指标，考虑了SLAM的建图能力，且易于实现。通过模拟和真实世界场景测试视觉和LiDAR SLAM方法。

**Result:** 结果表明，在典型的室内环境中，被动立体SLAM的精度水平与LiDAR SLAM相当。TaskSLAM-Bench补充了现有基准测试，并为以导航为中心的场景提供了更丰富的SLAM性能评估。

**Conclusion:** TaskSLAM-Bench提供了一个新的、以精度为导向的SLAM基准测试方法，能够更好地评估SLAM在机器人导航任务中的性能，并发现被动立体SLAM在室内环境中的精度可与LiDAR SLAM媲美。

> **ai_Abstract:** 本文提出了TaskSLAM-Bench，一个针对机器人导航中SLAM性能评估的任务驱动型基准测试框架。该框架强调精度的重要性，并考虑SLAM的建图能力。通过模拟和实际测试，发现被动立体SLAM在室内环境中的精度可与LiDAR SLAM媲美。TaskSLAM-Bench旨在弥补现有基准测试的不足，提供更全面的评估。

> **摘要翻译:** 移动辅助机器人使用SLAM的一个关键用例是在基于导航的任务中支持定位。当前的SLAM基准测试忽略了重复性（精度）的重要性，尽管它在实际部署中非常重要。为了解决这一差距，我们提出了一种任务驱动的SLAM基准测试方法，即TaskSLAM-Bench。它将精度作为关键指标，考虑了SLAM的建图能力，并且具有易于满足的实现要求。对SLAM方法进行的模拟和真实世界测试场景提供了对现代视觉和激光雷达SLAM解决方案导航性能特性的见解。结果表明，在典型的室内环境中，被动立体SLAM的精度水平与激光雷达SLAM相当。TaskSLAM-Bench补充了现有基准测试，并为以导航为中心的场景提供了更丰富的SLAM性能评估。公开可用的代码允许在配备适当机器人的自定义环境中进行现场SLAM测试。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [322] [Motion Planning Diffusion: Learning and Adapting Robot Motion Planning with Diffusion Models](https://arxiv.org/abs/2412.19948)
> *运动规划扩散：使用扩散模型学习和适应机器人运动规划*

*J. Carvalho, A. Le, P. Kicki, D. Koert, J. Peters* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 运动规划, 扩散模型, 机器人, 轨迹优化, B样条

**Comment:** 

> **TL;DR:** 该论文介绍了一种名为运动规划扩散（MPD）的新算法，它使用扩散模型从先前解决的路径规划问题中学习轨迹分布先验，并通过成本引导生成平滑、低维度的机器人运动轨迹。

**AI_Comments:** MPD的创新点在于将扩散模型引入机器人运动规划领域，用于学习轨迹先验，并通过成本引导在去噪过程中生成轨迹。其使用B样条曲线进行低维表示，有效解决了传统方法中轨迹非平滑和高维表示效率低下的问题，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于优化的机器人运动规划算法高度依赖初始解，这些初始解通常通过采样式规划器获得无碰撞路径，但在高维和复杂场景中速度慢且产生非平滑解。因此，需要学习先前解决的问题的分布作为新问题的先验。

**Method:** 本文提出运动规划扩散（MPD）算法，利用扩散模型学习轨迹分布先验。该方法通过构建成本函数，并在去噪过程中结合学习到的先验和成本函数梯度，从后验分布中采样。为提高效率和保证平滑性，MPD使用线性运动原语（特别是B样条曲线）学习轨迹的低维表示。

**Result:** 该方法在从简单2D到使用7自由度机械臂的复杂任务中都得到了验证。除了从模拟数据中学习，还使用了真实世界抓取放置任务中的人类演示数据。

**Conclusion:** MPD提供了一种有效且高效的方式，利用扩散模型学习轨迹先验，生成平滑的机器人运动轨迹，并在多种复杂任务中表现良好。

> **ai_Abstract:** 本文提出了一种名为运动规划扩散（MPD）的新型机器人运动规划算法。MPD利用扩散模型学习先前解决的路径规划问题的轨迹分布先验。该方法通过结合学习到的先验和成本函数梯度，从后验分布中采样生成轨迹。为提高效率和保证平滑性，MPD采用B样条曲线对轨迹进行低维表示。实验结果表明，该方法在2D场景、7自由度机械臂以及真实世界的人类演示任务中均表现出有效性，能够生成平滑且参数高效的运动轨迹。

> **摘要翻译:** 优化型机器人运动规划算法的性能高度依赖于初始解，这些初始解通常通过运行基于采样的规划器来获得无碰撞路径。然而，这些方法在高维和复杂场景中可能速度缓慢，并产生非平滑的解。鉴于先前已解决的路径规划问题，非常希望能够学习它们的分布并将其用作新类似问题的先验。一些工作提出利用这种先验来引导运动规划问题，要么从中采样初始解，要么在最大后验公式中利用其分布进行轨迹优化。在这项工作中，我们引入了运动规划扩散（MPD），这是一种利用扩散模型学习轨迹分布先验的算法。这些生成模型在编码多模态数据方面取得了越来越多的成功，并且对基于梯度的运动规划（如成本引导）具有理想的特性。给定一个运动规划问题，我们构建一个成本函数，并在去噪过程中结合学习到的先验和成本函数梯度，从后验分布中采样。我们不学习所有轨迹点的先验，而是提出使用线性运动原语，特别是B样条曲线，学习轨迹的低维表示。这种参数化保证了生成的轨迹是平滑的，可以在更高频率下插值，并且比密集路点表示需要更少的参数。我们展示了该方法从简单2D到使用7自由度机器人手臂操纵器的更复杂任务的结果。除了从模拟数据中学习，我们还使用了真实世界抓取放置任务中的人类演示。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [329] [APEX-MR: Multi-Robot Asynchronous Planning and Execution for Cooperative Assembly](https://arxiv.org/abs/2503.15836)
> *APEX-MR：多机器人异步规划与执行实现协同装配*

*Philip Huang, Ruixuan Liu, Shobhit Aggarwal, Changliu Liu, Jiaoyang Li* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 多机器人系统, 异步规划, 协同装配, 乐高组装, 机器人协调

**Comment:** 

> **TL;DR:** APEX-MR是一个多机器人异步规划与执行框架，旨在安全高效地协调多个机器人进行协同装配，显著提高了乐高组装任务的执行速度。

**AI_Comments:** APEX-MR的创新之处在于其异步规划与执行框架，有效解决了多机器人系统在不确定性下的协调难题，特别是在提高任务效率和实现复杂装配任务方面表现突出。其在物理乐高组装上的成功部署，尤其是在使用商用乐高积木进行定制组装方面，具有重要的实际应用价值和里程碑意义。

<details>
  <summary>Details</summary>

**Motivation:** 多机器人系统在扩展工作空间、提高任务效率和实现复杂灵巧任务（如协同装配）方面具有优势，但由于系统不确定性、任务效率、算法可扩展性和安全问题，协调多个机器人的任务和运动具有挑战性。

**Method:** 本文提出了APEX-MR，一个异步规划与执行框架，旨在安全高效地协调多个机器人实现协同装配。APEX-MR提供了一种系统方法来后处理多机器人任务和运动规划，以实现在不确定性下的鲁棒异步执行。

**Result:** 实验结果表明，与顺序规划相比，APEX-MR可以将许多长周期乐高组装任务的执行时间平均加快48%；与同步规划相比，平均加快36%。APEX-MR还部署在一个双臂系统中，成功执行了物理乐高组装，是首个使用商用乐高积木进行定制乐高组装的机器人系统。

**Conclusion:** APEX-MR框架能够安全地协调机器人运动，高效地协作，并构建复杂的乐高结构，显著提高了多机器人协同装配的效率。

> **ai_Abstract:** 本文针对多机器人协同装配的挑战，提出了一种名为APEX-MR的异步规划与执行框架。该框架通过系统地后处理任务和运动计划，实现了在不确定性下多机器人的安全高效协调。实验证明，APEX-MR显著缩短了乐高组装任务的执行时间，并在物理双臂系统中成功完成了复杂的乐高结构组装，是首个实现商用乐高定制组装的机器人系统。

> **摘要翻译:** 与单机器人工作站相比，多机器人系统具有多项优势：1）扩展了系统工作空间，2）提高了任务效率，更重要的是，3）使机器人能够完成更复杂和灵巧的任务，例如协同装配。然而，由于系统不确定性、任务效率、算法可扩展性和安全问题等，协调多个机器人的任务和运动具有挑战性。为了解决这些挑战，本文研究了多机器人协调，并提出了APEX-MR，一个异步规划与执行框架，旨在安全高效地协调多个机器人实现协同装配，例如乐高组装。特别是，APEX-MR提供了一种系统方法来后处理多机器人任务和运动规划，以实现在不确定性下的鲁棒异步执行。实验结果表明，与顺序规划相比，APEX-MR可以将许多长周期乐高组装任务的执行时间平均加快48%，与同步规划相比，平均加快36%。为了进一步展示性能，我们将APEX-MR部署在一个双臂系统中，以执行物理乐高组装。据我们所知，这是第一个能够使用商用乐高积木进行定制乐高组装的机器人系统。实验结果表明，配备APEX-MR的双臂系统能够安全地协调机器人运动，高效地协作，并构建复杂的乐高结构。我们的项目网站可在https://intelligent-control-lab.github.io/APEX-MR/上获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [337] [$\textit{RoboTron-Nav}$: A Unified Framework for Embodied Navigation Integrating Perception, Planning, and Prediction](https://arxiv.org/abs/2503.18525)
> *RoboTron-Nav：一个整合感知、规划和预测的具身导航统一框架*

*Yufeng Zhong, Chengjian Feng, Feng Yan, Fanfan Liu, Liming Zheng, Lin Ma* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 具身导航, 感知, 规划, 预测, 大型语言模型

**Comment:** 

> **TL;DR:** RoboTron-Nav是一个统一框架，通过多任务协作和自适应历史采样，在语言引导的具身导航中整合感知、规划和预测，并在CHORES-S基准测试中达到了最先进的性能。

**AI_Comments:** 该论文的创新点在于提出了一个统一的框架RoboTron-Nav，它不仅整合了具身导航中的感知、规划和预测三大核心能力，还通过多任务协作和引入大型语言模型显著增强了指令理解和场景分析能力。此外，自适应3D感知历史采样策略有效地解决了长期导航中历史信息冗余的问题，提高了效率。其在CHORES-S基准测试上取得的SOTA性能证明了其方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在语言引导的视觉导航中，代理需要在未知环境中根据自然语言指令定位目标。为了在不熟悉的场景中实现可靠导航，代理应具备强大的感知、规划和预测能力。此外，在长期导航过程中，代理重新访问先前探索过的区域时，可能会保留不相关和冗余的历史感知信息，导致次优结果。

**Method:** 本文提出了RoboTron-Nav，一个统一框架，通过在导航和具身问答任务上的多任务协作，整合感知、规划和预测能力。此外，RoboTron-Nav采用自适应3D感知历史采样策略，以有效利用历史观测。通过利用大型语言模型，RoboTron-Nav能够理解多样化指令和复杂视觉场景，从而生成适当的导航动作。

**Result:** RoboTron-Nav在CHORES-S基准测试中的物体目标导航任务上取得了81.1%的成功率，创下了新的最先进性能。

**Conclusion:** RoboTron-Nav通过整合感知、规划、预测能力以及有效利用历史信息，显著提升了语言引导的具身导航性能，并在相关基准测试中达到了SOTA水平。

> **ai_Abstract:** RoboTron-Nav是一个针对语言引导的具身导航的统一框架，它通过多任务协作（导航与具身问答）整合了感知、规划和预测能力。该框架还引入了自适应3D感知历史采样策略以高效利用过往数据，并利用大型语言模型理解复杂指令和视觉场景。实验结果显示，RoboTron-Nav在CHORES-S基准测试的物体目标导航任务上取得了81.1%的成功率，达到了当前最佳水平。

> **摘要翻译:** 在语言引导的视觉导航中，代理使用自然语言指令在未知环境中定位目标对象。为了在不熟悉的场景中进行可靠导航，代理应具备强大的感知、规划和预测能力。此外，当代理在长期导航期间重新访问先前探索过的区域时，它们可能会保留不相关和冗余的历史感知信息，导致次优结果。在这项工作中，我们提出了RoboTron-Nav，一个统一框架，通过在导航和具身问答任务上的多任务协作，整合感知、规划和预测能力，从而提高导航性能。此外，RoboTron-Nav采用自适应3D感知历史采样策略，以有效且高效地利用历史观测。通过利用大型语言模型，RoboTron-Nav能够理解多样化的命令和复杂的视觉场景，从而产生适当的导航动作。RoboTron-Nav在CHORES-S基准测试的物体目标导航中实现了81.1%的成功率，创造了新的最先进性能。项目页面：https://yvfengzhong.github.io/RoboTron-Nav

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [345] [How to Adapt Control Barrier Functions? A Learning-Based Approach with Applications to a VTOL Quadplane](https://arxiv.org/abs/2504.03038)
> *如何自适应控制障碍函数？一种基于学习的方法及其在VTOL四旋翼飞机上的应用*

*Taekyung Kim, Randal W. Beard, Dimitra Panagou* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-06**

**Keywords:** 控制障碍函数, 基于学习的控制, 安全关键系统, 在线自适应, VTOL四旋翼飞机

**Comment:** 

> **TL;DR:** 本文提出了一种基于学习的在线自适应控制障碍函数（CBF）参数的新颖理论框架，以确保在输入约束下的有限时域安全性，并在VTOL四旋翼飞机上进行了验证。

**AI_Comments:** 该论文的创新之处在于将控制障碍函数（CBF）的在线自适应与基于学习和不确定性感知的验证过程相结合。这对于在存在不确定性的实际安全关键系统中实时调整安全保障至关重要，尤其是在VTOL飞行器等复杂动态系统中具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在输入约束下，需要在线自适应控制障碍函数（CBF）参数（即CBF条件中包含的K类函数），以保证系统的安全性。

**Method:** 本文提出了一个新颖的理论框架，用于在线自适应CBF参数。该方法引入了局部验证的CBF参数概念，这些参数基于Nagumo定理和切线锥分析导出的条件进行在线调整，以保证有限时域的安全性。为了在线识别这些参数，该方法将基于学习的方法与不确定性感知验证过程相结合，该过程考虑了神经网络预测中固有的认知不确定性和偶然不确定性。

**Result:** 该方法在VTOL四旋翼飞机模型上进行了演示，在具有挑战性的过渡和着陆机动中，展示了在保持安全性的同时，性能得到了增强。

**Conclusion:** 该研究提出的基于学习的在线自适应控制障碍函数参数的方法，能够有效保证系统安全并提升性能，尤其适用于复杂的机器人操作。

> **ai_Abstract:** 本文提出了一种新颖的理论框架，用于在输入约束下在线自适应控制障碍函数（CBF）的参数。该框架引入了局部验证的CBF参数概念，这些参数利用Nagumo定理和切线锥分析的条件进行在线调整，以确保有限时域的安全性。为了在线识别这些参数，该方法将基于学习的方法与不确定性感知验证过程相结合，该过程能够处理神经网络预测中存在的认知和偶然不确定性。该方法在VTOL四旋翼飞机模型上进行了验证，结果表明在具有挑战性的机动中，该方法能够在保持安全性的同时显著提升性能。

> **摘要翻译:** 本文提出了一种用于在线自适应控制障碍函数（CBF）参数（即CBF条件中包含的K类函数）的新颖理论框架，该框架在输入约束下运行。我们引入了局部验证CBF参数的概念，这些参数基于Nagumo定理和切线锥分析导出的条件进行在线调整，以保证有限时域的安全性。为了在线识别这些参数，我们将基于学习的方法与不确定性感知验证过程相结合，该过程考虑了神经网络预测中固有的认知不确定性和偶然不确定性。我们的方法在VTOL四旋翼飞机模型上进行了演示，在具有挑战性的过渡和着陆机动中，展示了在保持安全性的同时性能得到了增强。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [353] [Following Is All You Need: Robot Crowd Navigation Using People As Planners](https://arxiv.org/abs/2504.10828)
> *跟随即所需：利用人类作为规划者进行机器人人群导航*

*Yuwen Liao, Xinhang Xu, Ruofei Bai, Yizhuo Yang, Muqing Cao, Shenghai Yuan, Lihua Xie* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 机器人导航, 人群导航, 人类作为规划者, 人机交互, 社会行为

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的机器人人群导航框架，通过识别并跟随合适的“人类领导者”，利用人类的规划决策和社交行为，实现安全高效的导航，无需复杂的预测或数据驱动模块。

**AI_Comments:** 该论文的创新点在于其独特的“人即规划者”范式，巧妙地利用了人类在复杂人群环境中的固有智能和社交行为，避免了传统复杂规划器对大量预测数据和复杂算法的依赖。这种方法简化了机器人规划的复杂度，并自然地赋予了机器人类人行为，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器人人群导航方法侧重于开发复杂和繁重的规划器，却忽略了人类智能的作用。鉴于人类在人群环境中具有高能力且普遍存在，作者提出利用人类作为规划者来弥补这一不足。

**Method:** 该方法通过一套基于规则的评估来识别合适的、有潜力引导机器人到达目标的人类领导者。机器人使用一个简单的基础规划器，通过设计为易于实现的短距离子目标来跟随选定的领导者。

**Result:** 通过仿真和真实世界实验，该框架与现有规划器相比，能够生成安全高效的机器人路径，即使没有预测或数据驱动模块。该方法还能在不明确定义交通规则和社会规范的情况下，使机器人展现出类人行为。

**Conclusion:** 本文提出的新颖框架通过利用人类作为规划者，为机器人人群导航提供了一种安全、高效且具有类人行为的解决方案，无需复杂的预测或数据驱动模块。

> **ai_Abstract:** 该论文提出了一种名为“跟随即所需”的机器人人群导航新范式，利用人类作为规划者。其核心思想是，机器人通过规则识别并跟随在人群中表现出引导潜力的“人类领导者”，通过简单的短距离子目标实现导航。实验表明，与传统复杂规划器相比，该方法在不依赖预测或数据驱动模块的情况下，能生成更安全、高效且具有类人行为的机器人路径。

> **摘要翻译:** 在拥挤环境中导航需要机器人具备高级推理和规划技术。现有工作侧重于开发复杂而笨重的规划器，却忽视了人类智能的作用。由于人类是能力很强的智能体，并且在人群导航环境中广泛存在，我们提出了一种替代方案，即机器人利用人类作为规划者，以受益于他们有效的规划决策和社交行为。通过一套基于规则的评估，我们识别出表现出有潜力引导机器人实现目标任务的合适人类领导者。机器人使用一个简单的基础规划器，通过设计成易于实现的短距离子目标来跟随选定的领导者。我们通过仿真和真实世界实验证明，与现有规划器相比，我们新颖的框架即使没有预测或数据驱动模块，也能生成安全高效的机器人规划。我们的方法在不明确定义交通规则和社会规范的情况下，也能带来类人机器人行为。代码将发布在 https://github.com/centiLinda/PeopleAsPlanner.git。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [361] [Subframework-based Bearing Rigidity Maintenance Control in Multirobot Networks](https://arxiv.org/abs/2504.17103)
> *多机器人网络中基于子框架的方位刚度保持控制*

*J. Francisco Presenza, Ignacio Mas, J. Ignacio Alvarez-Hamelin, Juan I. Giribet* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-06**

**Keywords:** 方位刚度, 多机器人网络, 子框架, 去中心化控制, 刚度特征值

**Comment:** 

> **TL;DR:** 提出一种新颖的基于子框架的方法，用于在多机器人网络中分析和控制方位刚度，并通过去中心化控制器保持刚度。

**AI_Comments:** 该研究创新性地将全局方位刚度分解为局部属性进行处理，并通过去中心化控制器实现了在复杂多机器人网络中的刚度维护。其强调的可扩展性和实用性是该方法的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 在具有传感约束和动态拓扑的多机器人网络中，对方位刚度进行分析和控制。

**Method:** 将系统框架分解为子框架，将全局方位刚度表示为局部性质，并使用刚度特征值作为局部刚度度量。提出一种去中心化的基于梯度的控制器，仅使用方位测量和子框架内信息交换，通过保持刚度特征值高于阈值来维持方位刚度。

**Result:** 仿真评估证明了该方案的有效性、可扩展性和实用性。

**Conclusion:** 该方法能够有效且实用地在多机器人网络中保持方位刚度，并具有良好的可扩展性。

> **ai_Abstract:** 本文提出了一种新颖的基于子框架的方法，用于在具有传感约束和动态拓扑的多机器人网络中进行方位刚度分析和控制。该方法将全局方位刚度分解为局部性质，并利用刚度特征值作为局部度量。通过一个去中心化的梯度控制器，仅利用方位测量和子框架内信息，该系统能够有效地保持方位刚度，并通过仿真验证了其有效性、可扩展性和实用性。

> **摘要翻译:** 这篇工作提出了一种在具有传感约束和动态拓扑的多机器人网络中进行方位刚度分析和控制的新颖方法。通过将系统框架分解为子框架，我们将方位刚度——一个全局属性——表达为一组局部属性，其中刚度特征值作为自然的局部刚度度量。我们提出了一种去中心化的基于梯度的控制器，仅使用方位测量来执行任务特定指令。该控制器通过将刚度特征值保持在阈值之上来维持方位刚度，仅使用子框架内交换的信息。仿真评估了该方案的有效性，强调了其可扩展性和实用性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [369] [Extracting Visual Plans from Unlabeled Videos via Symbolic Guidance](https://arxiv.org/abs/2505.08444)
> *通过符号引导从未标记视频中提取视觉规划*

*Wenyan Yang, Ahmet Tikna, Yi Zhao, Yuying Zhang, Luigi Palopoli, Marco Roveri, Joni Pajarinen* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 视觉规划, 符号引导, 未标记视频, 机器人操作, Vis2Plan

**Comment:** 

> **TL;DR:** Vis2Plan通过符号引导从未标记视频中提取视觉规划，比现有方法更快、更高效地生成物理一致的视觉子目标，并在真实机器人环境中取得更高的成功率。

**AI_Comments:** Vis2Plan的创新之处在于其结合了符号引导和视觉基础模型，解决了传统视觉规划中视频生成模型的缺陷。其“白盒”和“可解释”的特性在机器人规划领域具有重要意义，因为它提供了清晰的推理步骤。显著的性能提升（更高的成功率和更快的速度）使其在实际机器人应用中具有很高的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉规划方法通常依赖视频生成模型来获取子目标，但这会导致模型幻觉和计算成本高昂的问题。

**Method:** 本文提出了Vis2Plan，一个高效、可解释的白盒视觉规划框架，由符号引导驱动。它利用视觉基础模型从原始未标记的演示数据中自动提取紧凑的任务符号集，并构建一个用于多目标、多阶段规划的高级符号转换图。在测试时，规划器在符号层面进行规划，并组装一系列由底层符号表示接地的物理一致的中间子目标图像。

**Result:** Vis2Plan在真实机器人设置中，比基于扩散视频生成的强大视觉规划器高出53%的综合成功率，同时生成视觉规划的速度快35倍。

**Conclusion:** Vis2Plan能够生成物理一致的图像目标，并提供完全可检查的推理步骤。

> **ai_Abstract:** Vis2Plan是一种新的视觉规划框架，它利用符号引导从未标记的视频中提取视觉计划。该方法通过视觉基础模型自动提取任务符号，并构建符号转换图，从而实现高效、可解释的多目标规划。与依赖视频生成模型的现有方法相比，Vis2Plan显著提高了真实机器人任务的成功率并加快了规划速度，同时克服了模型幻觉和高计算成本的问题。

> **摘要翻译:** 视觉规划通过向目标导向的低级策略提供一系列中间视觉子目标，在长程操作任务中取得了有希望的性能。为了获得子目标，现有方法通常诉诸于视频生成模型，但会受到模型幻觉和计算成本的困扰。我们提出了Vis2Plan，一个由符号引导驱动的高效、可解释和白盒视觉规划框架。Vis2Plan从未标记的原始演示数据中，利用视觉基础模型自动提取一组紧凑的任务符号，从而能够构建一个用于多目标、多阶段规划的高级符号转换图。在测试时，给定一个期望的任务目标，我们的规划器在符号层面进行规划，并组装一系列由底层符号表示接地的物理一致的中间子目标图像。我们的Vis2Plan在真实机器人设置中，比强大的基于扩散视频生成的视觉规划器高出53%的综合成功率，同时生成视觉规划的速度快35倍。结果表明，Vis2Plan能够生成物理一致的图像目标，同时提供完全可检查的推理步骤。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [376] [Bayesian Optimization applied for accelerated Virtual Validation of the Autonomous Driving Function](https://arxiv.org/abs/2507.22769)
> *自动驾驶功能加速虚拟验证中的贝叶斯优化应用*

*Satyesh Shanker Awasthi, Mohammed Irshadh Ismaaeel Sathyamangalam Imran, Stefano Arrigoni, Francesco Braghin* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 贝叶斯优化, 自动驾驶, 虚拟验证, 关键场景发现, 安全性

**Comment:** 

> **TL;DR:** 使用贝叶斯优化加速自动驾驶功能的虚拟验证，以高效发现关键危险场景。

**AI_Comments:** 这项工作通过引入贝叶斯优化，显著提高了自动驾驶功能虚拟验证的效率，尤其是在发现关键危险场景方面。其创新之处在于利用BO的智能搜索能力，避免了传统暴力穷举的高昂成本，对于加速自动驾驶汽车的安全验证具有重要意义。该方法有望缩短开发周期，并提升自动驾驶系统的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶功能的严格验证对于确保安全至关重要，但传统仿真方法在探索广阔参数空间时计算成本高昂且耗时。

**Method:** 引入了一个基于贝叶斯优化（BO）的框架，用于加速关键场景的发现。

**Result:** 该框架在基于模型预测控制器（MPC）的运动规划器上有效，能以远少于暴力实验设计（DoE）方法的仿真次数识别越野事件等危险情况。此外，该研究还探讨了框架在高维参数空间中的可扩展性以及识别多个不同关键区域的能力。

**Conclusion:** 基于贝叶斯优化的框架能够显著加速自动驾驶功能虚拟验证中关键危险场景的发现，提高了验证效率。

> **ai_Abstract:** 本文提出一个基于贝叶斯优化的框架，旨在加速自动驾驶功能虚拟验证中关键危险场景的发现。针对传统仿真验证耗时且计算成本高的问题，该框架能够以显著减少的仿真次数识别出如越野事件等危险情况，并在高维参数空间中展现出良好的可扩展性以及识别多个关键区域的能力，从而提高自动驾驶功能验证的效率和安全性。

> **摘要翻译:** 自动驾驶功能（ADF）的严格验证与确认（V&V）对于确保自动驾驶汽车（AV）的安全性和公众接受度至关重要。当前的验证严重依赖仿真来在车辆的操作设计域（ODD）内实现足够的测试覆盖，但穷尽探索可能的场景的巨大参数空间是计算成本高昂且耗时的。这项工作引入了一个基于贝叶斯优化（BO）的框架，以加速关键场景的发现。我们展示了该框架在基于模型预测控制器（MPC）的运动规划器上的有效性，表明它识别危险情况，例如越野事件，所需的仿真次数比暴力实验设计（DoE）方法少几个数量级。此外，本研究还探讨了该框架在高维参数空间中的可扩展性及其识别作为案例研究的运动规划器ODD内多个不同关键区域的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [385] ["Set It Up": Functional Object Arrangement with Compositional Generative Models (Journal Version)](https://arxiv.org/abs/2508.02068)
> *“Set It Up”：基于组合生成模型的实用物体排列（期刊版本）*

*Yiqing Xu, Jiayuan Mao, Linfeng Li, Yilun Du, Tomas Lozáno-Pérez, Leslie Pack Kaelbling, David Hsu* | **Category: cs.RO** | **Updated: 2025-08-07**

**Keywords:** 功能性物体排列, 神经符号框架, 大型语言模型, 扩散模型, 物体姿态预测

**Comment:** 

> **TL;DR:** SetItUp是一个神经符号框架，它利用LLMs和扩散模型，通过两阶段方法从非明确指令中学习并生成功能性物体排列，表现优于现有模型。

**AI_Comments:** SetItUp的创新之处在于其神经符号方法，将LLMs用于高层语义理解和接地图生成，并结合扩散模型进行精确的姿态预测。这种两阶段分解有效解决了FORM任务中指令欠明确的挑战，提供了一种生成高质量物体排列的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 功能性物体排列（FORM）任务的指令通常不明确，没有明确指定所需的物体目标姿态，这是一个关键挑战。

**Method:** 本文提出了SetItUp，一个神经符号框架，通过少量训练示例和结构化的自然语言任务规范来学习指定物体目标姿态。SetItUp使用一个由抽象空间关系组成的“接地图”作为中间表示，将FORM问题分解为两个阶段：(i) 预测物体间的接地图；(ii) 给定接地图预测物体姿态。对于阶段(i)，SetItUp利用大型语言模型（LLMs）从任务规范和训练示例中诱导Python程序来生成接地图。对于阶段(ii)，SetItUp预训练一系列扩散模型来捕捉原始空间关系，并在线组合这些模型以根据接地图预测物体姿态。

**Result:** SetItUp在涵盖三个不同任务家族（餐桌餐具摆放、书架物品整理、卧室家具布局）的数据集上进行了评估。实验表明，SetItUp在生成功能性、物理可行且美观的物体排列方面优于现有模型。

**Conclusion:** SetItUp框架有效解决了功能性物体排列任务中指令不明确的问题，能够生成高质量的物体排列，并在多个任务家族中表现出卓越的性能。

> **ai_Abstract:** 本文介绍了SetItUp，一个针对功能性物体排列（FORM）任务的神经符号框架，旨在解决指令不明确的问题。该框架将FORM分解为两个阶段：首先利用大型语言模型（LLMs）生成物体间的抽象空间关系图（接地图），然后通过组合预训练的扩散模型，根据接地图预测物体的精确姿态。实验证明，SetItUp在生成功能性、物理可行且美观的物体排列方面，超越了现有模型。

> **摘要翻译:** 功能性物体排列（FORM）的任务是排列物体以实现某种功能，例如“为两人布置餐桌”。这里的一个关键挑战是，FORM的指令通常不明确，并未明确指定所需的物体目标姿态。本文提出了SetItUp，一个神经符号框架，它通过少量训练示例和结构化的自然语言任务规范来学习指定物体目标姿态。SetItUp使用一个由物体间抽象空间关系（例如“左侧”）组成的接地图作为其中间表示。这使得FORM问题分解为两个阶段：(i) 预测物体间的接地图；(ii) 给定接地图预测物体姿态。对于阶段(i)，SetItUp利用大型语言模型（LLMs）从任务规范和少量训练示例中诱导Python程序。这个程序可以被执行，以在新的场景中生成接地图。对于阶段(ii)，SetItUp预训练一系列扩散模型来捕捉原始空间关系，并在线组合这些模型，以根据接地图预测物体姿态。我们在一个涵盖三个不同任务家族的数据集上评估了SetItUp：餐桌上的餐具摆放、书架上的物品整理以及卧室中的家具布局。实验表明，SetItUp在生成功能性、物理可行且美观的物体排列方面优于现有模型。本文扩展了我们发表在Robotics: Science and Systems (RSS) 2024会议上的论文。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [393] [Tunable Leg Stiffness in a Monopedal Hopper for Energy-Efficient Vertical Hopping Across Varying Ground Profiles](https://arxiv.org/abs/2508.02873)
> *单足跳跃机器人可调腿部刚度实现不同地面剖面下的节能垂直跳跃*

*Rongqian Chen, Jun Kwon, Kefan Wu, Wei-Hsi Chen* | **Category: cs.RO, eess.SY** | **Updated: 2025-08-07**

**Keywords:** 可调腿部刚度, 单足跳跃机器人, 能量效率, 地面适应, HASTA

**Comment:** 

> **TL;DR:** 本文介绍了一种名为HASTA的单足垂直跳跃机器人，其腿部刚度可实时调节，旨在优化在不同地面条件下的能量效率。通过实验和仿真，研究发现存在最佳腿部刚度组合，能使机器人在恒定能量输入下达到最大稳态跳跃高度，从而验证了可调刚度能提高能量效率的假设。

**AI_Comments:** 这项研究通过引入可调腿部刚度，为跳跃机器人在复杂地形中的能量高效运动提供了创新解决方案。HASTA的设计和实验验证了其对不同地面条件的适应性，具有重要的工程实践意义。仿真结果为未来智能控制器的开发提供了宝贵的见解，预示着更高级的机器人运动能力的实现。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过实时调整腿部刚度，优化单足跳跃机器人在不同地面条件（包括地面刚度和阻尼）下的能量效率，以最大化跳跃高度。

**Method:** 设计并实现了名为HASTA的垂直跳跃机器人，该机器人具有实时可调的腿部刚度。通过实验测试和仿真，研究了不同地面条件下（地面刚度和阻尼组合）的最佳腿部刚度，以在恒定能量输入下实现最大的稳态跳跃高度。

**Result:** 实验测试和仿真结果表明，对于每种地面刚度和阻尼组合，都存在一个最佳的腿部刚度，使机器人在恒定能量输入下达到最大的稳态跳跃高度。这些结果支持了可调刚度能提高受控实验条件下能量高效运动的假设。此外，仿真结果为未来选择腿部刚度的控制器开发提供了见解。

**Conclusion:** 研究证实了可调腿部刚度能够显著提高单足跳跃机器人在不同地面条件下的能量效率和跳跃性能，从而支持了通过调整刚度来优化运动的假设。

> **ai_Abstract:** 本文介绍了一种名为HASTA的单足垂直跳跃机器人，该机器人具有实时可调的腿部刚度，旨在优化在不同地面条件下的能量效率。研究者假设通过调整刚度，较软的腿适用于软地面，较硬的腿适用于硬地面，以最大化跳跃高度。实验和仿真结果验证了这一假设，表明存在最佳腿部刚度组合，使机器人在恒定能量输入下达到最大稳态跳跃高度，从而提升了能量效率。仿真还为未来控制器开发提供了指导。

> **摘要翻译:** 我们介绍了HASTA（具有可调刚度以适应地形的跳跃者）的设计与实现，这是一种具有实时可调腿部刚度的垂直跳跃机器人，旨在优化在各种地面剖面（一对地面刚度和阻尼条件）下的能量效率。通过调整腿部刚度，我们旨在最大化跳跃顶点高度，这是能量高效垂直跳跃的关键指标。我们假设较软的腿在柔软、阻尼的地面上通过最小化穿透和能量损失表现更好，而较硬的腿在坚硬、阻尼较小的地面上通过减少肢体变形和能量耗散表现出色。通过实验测试和仿真，我们发现针对每种地面刚度和阻尼组合的最佳腿部刚度，使机器人能够在恒定能量输入下实现最大的稳态跳跃高度。这些结果支持了我们的假设，即在受控实验条件下，可调刚度可以提高能量高效的运动。此外，仿真提供了见解，有助于未来开发选择腿部刚度的控制器。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [465] [A General Control Method for Human-Robot Integration](https://arxiv.org/abs/2412.14762)
> *人机集成通用控制方法*

*Maddalena Feder, Giorgio Grioli, Manuel G. Catalano, Antonio Bicchi* | **Category: cs.RO, eess.SY** | **Updated: 2025-01-10**

**Keywords:** 人机集成, 通用控制, 多自由度设备, 辅助机器人, 补偿运动

**Comment:** 

> **TL;DR:** 提出一种通用的多自由度辅助设备控制方法，通过将用户补偿运动转化为机器人指令，实现人机集成，减少用户努力和不适。

**AI_Comments:** 该研究创新性地提出了将用户补偿运动转化为机器人指令的通用框架，旨在实现深层次的人机集成，将机器人视为用户身体的延伸，这对于提升辅助设备的可用性和用户体验具有重要意义。其通用性使其能应用于广泛的多自由度辅助系统。

<details>
  <summary>Details</summary>

**Motivation:** 帮助运动能力有限的人进行日常活动，解决将低维用户运动映射到复杂机器人辅助设备（如假肢、额外肢体、远程机器人化身）的控制接口策略挑战，目标是实现人机一体化系统，减少用户努力和不适。

**Method:** 提出一个控制多自由度辅助系统的通用框架，将用户执行的补偿运动转化为必要的机器人指令，以达到目标并消除或减少补偿。该框架适用于任意自由度假肢乃至全身机器人化身，并已通过模拟场景和涉及机器人部件虚拟孪生和物理人形化身的真实世界试验验证和应用。

**Result:** 该控制策略已通过模拟场景和涉及机器人部件虚拟孪生和物理人形化身的真实世界试验验证和应用。

**Conclusion:** 该论文提出了一种通用的控制方法，能够有效地将人与机器人部件整合为一个独特的系统，通过转化用户补偿运动来控制多自由度辅助设备，从而减少用户努力和不适，并已通过验证。

> **ai_Abstract:** 本文提出了一种通用于多自由度辅助设备的控制方法，旨在帮助运动受限者。该方法通过将用户的低维补偿运动转化为机器人指令，实现人机深度集成，使机器人作为人体的延伸，自主减少用户操作的努力和不适。该框架适用于从假肢到全身机器人化身等多种应用，并通过模拟和真实世界试验进行了验证。

> **摘要翻译:** 本文介绍了一种新的通用控制方法，旨在帮助运动能力有限的人进行日常活动，适用于多自由度设备。挑战在于找到最适合的控制接口策略，以有效地将用户在低维空间中的运动映射到复杂的机器人辅助设备，例如假肢、额外肢体，乃至远程机器人化身。目标是建立一个将人与机器人部分整合为一个独特系统的系统，该系统在达到人所决定的目标的同时，自主减少用户的努力和不适。我们提出了一个控制通用多自由度辅助系统的框架，该框架将用户执行的补偿运动转化为必要的机器人指令，以达到目标同时消除或减少补偿。该框架扩展到任意自由度假肢乃至完整的机器人化身，在此被视为一种全身假肢，使用者将机器人视为其自身身体的人工延伸，没有物理连接但具有感觉运动整合。我们通过涵盖模拟场景和涉及机器人部件（假肢和机器人）的虚拟孪生以及物理人形化身的真实世界试验，验证并应用了这种控制策略。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cssc'></a>
## cs.SC 

### [90] [Software Portability for Computer Algebra](https://arxiv.org/abs/2506.01864)
> *计算机代数软件的可移植性*

*Arthur C. Norman, Stephen M. Watt* | **Category: cs.SC** | **Updated: 2025-08-07**

**Keywords:** 软件可移植性, 计算机代数, 系统开发, 演变, 挑战

**Comment:** 

> **TL;DR:** 论文回顾了计算机代数软件可移植性概念的演变，并描述了作者参与创建的系统如何实现可移植性，以及当前面临的挑战。

**AI_Comments:** 这篇论文通过回顾作者在多个著名计算机代数系统开发中的实践经验，为软件可移植性这一重要议题提供了独特的历史视角和演变洞察。其价值在于结合实际案例分析了可移植性概念的动态性，并指出了未来可能面临的挑战，对软件工程领域具有参考意义。创新性在于其经验回顾和对概念演变的总结。

<details>
  <summary>Details</summary>

**Motivation:** 描述计算机代数软件可移植性概念随时间的变化，以及作者参与开发的系统如何实现可移植性，并探讨相关挑战。

**Method:** 作者通过回顾其在创建包括Reduce、Maple、Axiom和Aldor在内的多个计算机代数软件系统中的经验，观察并分析了软件可移植性的演变、实现方式以及面临的挑战。

**Result:** 论文揭示了软件可移植性的含义随时间的变化，并阐述了作者经验丰富的系统如何实现可移植性。它还指出，核心问题已经发生改变，并且存在一些尚待解决的挑战。

**Conclusion:** 软件可移植性的概念在不断演变，尽管过去的系统已经实现了可移植性，但相关挑战依然存在，并且核心问题也在不断变化。

> **ai_Abstract:** 这篇论文探讨了计算机代数软件的可移植性问题。作者基于其参与开发Reduce、Maple等多个系统的经验，分析了软件可移植性概念随时间的变化、其所涉系统实现可移植性的方式，以及该领域核心问题的演变和当前面临的挑战。

> **摘要翻译:** 我们参与了多个计算机代数软件系统的创建，包括Reduce、Maple、Axiom和Aldor以及一些较小的专用程序。我们阐述了关于软件可移植性含义如何随时间变化以及它如何持续演变的观察。我们描述了我们亲身经历的系统是如何实现可移植性的，核心问题如何随时间变化以及仍然存在的挑战。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [97] [A Scalable Pipeline for Enabling Non-Verbal Speech Generation and Understanding](https://arxiv.org/abs/2508.05385)
> *一种可扩展的非言语语音生成与理解管道*

*Runchuan Ye, Yixuan Zhou, Renjie Yu, Zijian Lin, Kehan Li, Xiang Li, Xin Liu, Guoyang Zeng, Zhiyong Wu* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 非言语语音, 数据集, 语音生成, 语音理解, 人机交互

**Comment:** 

> **TL;DR:** 本文提出了一个名为NonVerbalSpeech-38K的大规模非言语语音数据集及其自动收集管道，并通过微调现有模型验证了其在非言语语音生成和理解任务中的有效性，旨在促进更丰富的人机交互。

**AI_Comments:** 这项工作通过构建和发布NonVerbalSpeech-38K数据集及其自动化收集管道，填补了现有语音系统在非言语交流方面的空白，具有重要的创新性和实用价值。该数据集的规模和多样性有望显著推动非言语语音生成和理解领域的研究进展，从而实现更自然、情感更丰富的人机交互。

<details>
  <summary>Details</summary>

**Motivation:** 现有语音系统主要关注言语内容，缺乏对非言语发声（如笑声、叹息、咳嗽）的理解和生成能力，从而降低了语音界面的情感智能和交流丰富性。

**Method:** 本文介绍了NonVerbalSpeech-38K，一个从真实世界媒体中收集并使用自动管道标注的大型多样化非言语语音数据集。该数据集包含38,718个样本（约131小时），涵盖10类非言语提示。通过微调F5-TTS和Qwen2-Audio等最先进模型来验证数据集的有效性。

**Result:** NonVerbalSpeech-38K数据集在非言语语音生成和理解任务中表现出有效性。通过验证，证明了数据集在非言语语音合成和字幕生成方面的改进，从而促进了更丰富的人机交互。

**Conclusion:** 本文提出了一个用于构建自然多样化非言语语音数据集的实用管道，并发布了一个大规模数据集以推动非言语语音生成和理解的研究，同时通过验证证明了其有效性，有助于实现更丰富的人机交互。

> **ai_Abstract:** 本文提出了一种可扩展的管道，用于构建和利用大规模非言语语音数据集NonVerbalSpeech-38K，以解决现有语音系统在处理非言语发声方面的不足。该数据集包含10类非言语提示的38K样本，并通过微调先进模型验证了其在非言语语音生成和理解任务中的有效性，旨在提升人机交互的情感智能和丰富性。

> **摘要翻译:** 人类口语交流不仅涉及词汇内容，还涉及非言语发声（NVs），如笑声、叹息和咳嗽，它们传达情感、意图和社交信号。然而，大多数现有语音系统仅关注言语内容，缺乏理解和生成此类非言语提示的能力，从而降低了口语界面的情感智能和交流丰富性。在这项工作中，我们引入了NonVerbalSpeech-38K，一个用于非言语语音生成和理解的大型多样化数据集，该数据集从真实世界媒体中收集，并使用自动化管道进行标注。该数据集包含38,718个样本（约131小时），涵盖10类非言语提示，如笑声、嗅探声和清嗓声。我们通过微调F5-TTS和Qwen2-Audio等最先进模型进一步验证了该数据集，证明了其在非言语语音生成和理解任务中的有效性。我们的贡献有三方面：(1) 我们提出了一种用于构建自然多样化非言语语音数据集的实用管道；(2) 我们发布了一个大规模数据集，以推动非言语语音生成和理解的研究；(3) 我们通过展示非言语语音合成和字幕生成方面的改进来验证数据集的有效性，从而促进更丰富的人机交互。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [104] [PESTO: Pitch Estimation with Self-supervised Transposition-equivariant Objective](https://arxiv.org/abs/2309.02265)
> *PESTO: 基于自监督转置等变目标的音高估计*

*Alain Riou, Stefan Lattner, Gaëtan Hadjeres, Geoffroy Peeters* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 音高估计, 自监督学习, 转置等变性, Siamese神经网络, 轻量级模型

**Comment:** 

> **TL;DR:** 该论文提出了一种名为PESTO的轻量级自监督模型，利用音高转置等变性，仅通过小型未标注数据集即可准确进行单声道音频的音高估计，在音高估计任务中超越了自监督基线并缩小了与监督方法的差距。

**AI_Comments:** PESTO的创新之处在于其将音高转置等变性作为自监督学习范式，结合了轻量级Siamese网络和独特的转置等变目标函数。特别值得注意的是引入可学习的Toeplitz矩阵来确保网络架构的转置保持性，这对于音高估计任务至关重要。该方法在仅依赖少量未标注数据的情况下实现了与监督方法相近的性能，显著降低了数据标注成本，并使其适用于资源受限的环境和实时应用，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决音高估计问题，特别是利用自监督学习（SSL）范式，通过音高转置等变性，使模型能够在仅使用小型未标注数据集的情况下，准确执行单声道音频的音高估计。

**Method:** 该方法使用一个轻量级（参数少于30k）的Siamese神经网络。输入是同一音频的两个不同音高偏移版本，通过恒Q变换表示。为防止模型崩溃，提出了一种新颖的基于类的转置等变目标函数。此外，通过引入可学习的Toeplitz矩阵，使网络架构具有转置保持性。

**Result:** 模型在歌唱声音和乐器音高估计两项任务上进行了评估，结果表明模型能够跨任务和数据集进行泛化，同时保持轻量级，适用于低资源设备和实时应用。特别是，其结果超越了自监督基线，并缩小了自监督和监督方法在音高估计方面的性能差距。

**Conclusion:** PESTO模型通过创新的自监督转置等变目标和架构设计，实现了高效、准确的音高估计，在资源受限的环境下表现出色，并有效弥补了自监督与监督方法之间的性能差距。

> **ai_Abstract:** PESTO是一种基于自监督转置等变目标的轻量级（<30k参数）Siamese神经网络，用于单声道音频的音高估计。该模型通过恒Q变换处理音高偏移的音频输入，并采用新颖的基于类的转置等变目标和转置保持的Toeplitz矩阵架构，有效防止模型崩溃并捕获音高信息。实验证明，PESTO在歌唱和乐器音高估计任务上具有良好的泛化能力，适用于低资源和实时应用，其性能优于自监督基线，并缩小了与监督方法的差距。

> **摘要翻译:** 在本文中，我们利用自监督学习（SSL）解决了音高估计问题。我们使用的SSL范式是音高转置等变性，这使得我们的模型在仅使用小型未标注数据集进行训练后，能够准确地执行单声道音频的音高估计。我们使用一个轻量级（参数少于30k）的Siamese神经网络，其输入是同一音频的两个不同音高偏移版本，由其恒Q变换表示。为了防止模型在仅编码器设置中崩溃，我们提出了一种新颖的基于类的转置等变目标函数，该函数捕获音高信息。此外，我们通过引入可学习的Toeplitz矩阵，将我们网络的架构设计为转置保持性。
我们评估了我们的模型在歌唱声音和乐器音高估计两项任务上的表现，并表明我们的模型能够跨任务和数据集进行泛化，同时保持轻量级，因此与低资源设备兼容并适用于实时应用。特别是，我们的结果超越了自监督基线，并缩小了自监督和监督方法在音高估计方面的性能差距。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [111] [ZipVoice: Fast and High-Quality Zero-Shot Text-to-Speech with Flow Matching](https://arxiv.org/abs/2506.13053)
> *ZipVoice：基于流匹配的快速高质量零样本文本到语音合成*

*Han Zhu, Wei Kang, Zengwei Yao, Liyong Guo, Fangjun Kuang, Zhaoqing Li, Weiji Zhuang, Long Lin, Daniel Povey* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-07**

**Keywords:** 零样本TTS, 流匹配, ZipVoice, 语音合成, 快速推理

**Comment:** 

> **TL;DR:** ZipVoice是一种基于流匹配的零样本文本到语音模型，它在保持高质量的同时，显著减小了模型大小并提高了推理速度。

**AI_Comments:** ZipVoice通过结合Zipformer和流蒸馏等创新技术，有效解决了大规模零样本TTS模型在模型大小和推理速度上的瓶颈，实现了效率和质量的平衡，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本文本到语音（TTS）模型虽然语音质量高，但由于参数量庞大，推理速度慢。

**Method:** 本文提出了ZipVoice模型，它采用紧凑的模型尺寸和快速的推理速度。关键设计包括：1）基于Zipformer的矢量场估计器，以在受限尺寸下保持足够的建模能力；2）基于平均上采样的初始语音-文本对齐和基于Zipformer的文本编码器，以提高语音可懂度；3）流蒸馏方法，以减少采样步骤并消除无分类器指导相关的推理开销。

**Result:** 在10万小时多语言数据集上的实验表明，ZipVoice在语音质量上与最先进的模型相当，同时比基于DiT的流匹配基线模型小3倍，快30倍。

**Conclusion:** ZipVoice成功地解决了现有大规模零样本TTS模型推理速度慢的问题，实现了高质量、小尺寸和快速推理的零样本文本到语音合成。

> **ai_Abstract:** ZipVoice是一种新型的零样本文本到语音（TTS）模型，旨在解决现有模型推理速度慢的问题。它利用流匹配技术，并结合Zipformer架构进行矢量场估计和文本编码，同时采用流蒸馏方法来优化性能。实验证明，ZipVoice在保持与最先进模型相当的语音质量的同时，显著减小了模型尺寸并大幅提升了推理速度。

> **摘要翻译:** 现有的大规模零样本文本到语音（TTS）模型提供高质量的语音，但由于参数量庞大，推理速度较慢。为了解决这个问题，本文引入了ZipVoice，一个基于流匹配的高质量零样本TTS模型，它具有紧凑的模型尺寸和快速的推理速度。关键设计包括：1）一个基于Zipformer的矢量场估计器，以在受限尺寸下保持足够的建模能力；2）基于平均上采样的初始语音-文本对齐和基于Zipformer的文本编码器，以提高语音可懂度；3）一种流蒸馏方法，以减少采样步骤并消除与无分类器指导相关的推理开销。在10万小时多语言数据集上的实验表明，ZipVoice在语音质量上与最先进的模型相当，同时比基于DiT的流匹配基线模型小3倍，快30倍。代码、模型检查点和演示样本可在https://github.com/k2-fsa/ZipVoice公开获取。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [118] [Automated Bug Frame Retrieval from Gameplay Videos Using Vision-Language Models](https://arxiv.org/abs/2508.04895)
> *使用视觉-语言模型从游戏视频中自动检索错误帧*

*Wentao Lu, Alexander Senchenko, Abram Hindle, Cor-Paul Bezemer* | **Category: cs.SE** | **Updated: 2025-08-06**

**Keywords:** 错误检索, 游戏视频, 视觉-语言模型, GPT-4o, 关键帧提取

**Comment:** 

> **TL;DR:** 一种自动化流程，利用FFmpeg和视觉-语言模型（GPT-4o）从游戏错误视频中检索最能代表错误的关键帧，显著减少人工审核工作。

**AI_Comments:** 这篇论文通过结合传统的视频处理工具（FFmpeg）和先进的视觉-语言模型（GPT-4o），提出了一种创新的解决方案，有效解决了游戏开发中人工审核大量错误视频的痛点。其核心创新在于将视频缩减为单一关键帧，并利用AI模型进行精确匹配，极大地提高了效率。该方法的实际应用价值高，能显著减轻QA团队和开发人员的工作负担，对于快速迭代的游戏开发流程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代游戏工作室快速发布新版本和补丁，产生大量包含游戏视频的错误报告。人工审核这些视频耗时、费力且难以扩展。

**Method:** 该流程首先使用FFmpeg提取关键帧，将视频帧数大幅减少。然后，一个视觉-语言模型（GPT-4o）根据文本错误描述评估并排序这些关键帧，最终选择最能代表错误的单帧。

**Result:** 该方法在真实世界数据上，对于检索到的首个帧，实现了0.79的F1分数和0.89的准确率。在“光照与阴影”、“物理与碰撞”以及“UI与HUD”错误类别中表现最佳，而在“动画与视觉特效”中表现最差。

**Conclusion:** 该方法通过提供即时信息图像取代视频观看，显著减少了人工工作量，并加快了错误分类和回归检查的速度，为游戏行业的质量保证团队和开发人员带来了实际益处。

> **ai_Abstract:** 该论文提出了一种自动化流程，用于从游戏视频中检索最能代表错误的关键帧。该流程首先利用FFmpeg进行关键帧提取，大幅减少视频帧数。随后，一个视觉-语言模型（GPT-4o）根据文本错误描述对这些关键帧进行评分和选择。在真实世界游戏错误报告上的评估显示，该方法在减少人工视频审查方面表现出色，实现了0.79的F1分数和0.89的准确率，尤其在特定错误类别中表现突出，显著提高了游戏开发中错误分类和回归检查的效率。

> **摘要翻译:** 现代游戏工作室以快速的节奏发布新版本和补丁，产生了数千份错误报告，其中许多嵌入了游戏视频。为了验证和分类这些错误报告，开发人员必须观看提交的视频。这种手动审查是劳动密集型、缓慢且难以扩展的。在本文中，我们引入了一个自动化流程，将每个视频缩减为一个最符合报告错误描述的单帧，为开发人员提供即时视觉证据，精确指出错误。
我们的流程始于使用FFmpeg进行关键帧提取，将每个视频的原始帧数中位数减少到仅1.90%，同时在98.79%的情况下仍然捕获到错误时刻。然后，这些关键帧由一个视觉-语言模型（GPT-4o）进行评估，该模型根据它们与文本错误描述的匹配程度进行排名，并选择最具代表性的帧。我们使用来自一款热门第一人称射击（FPS）游戏的真实世界开发人员提交的游戏视频和JIRA错误报告评估了这种方法。该流程对于检索到的首个帧实现了0.79的总体F1分数和0.89的准确率。在“光照与阴影”（F1 = 0.94）、“物理与碰撞”（0.86）和“UI与HUD”（0.83）错误类别中性能最高，而在“动画与视觉特效”（0.51）中最低。
通过用即时信息图像取代视频观看，我们的方法极大地减少了人工工作量，并加快了分类和回归检查的速度，为整个游戏行业的质量保证（QA）团队和开发人员提供了实际益处。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [126] [Charting Uncertain Waters: A Socio-Technical Framework for Navigating GenAI's Impact on Open Source Communities](https://arxiv.org/abs/2508.04921)
> *绘制不确定的水域：一个社会技术框架，用于应对生成式AI对开源社区的影响*

*Zixuan Feng, Reed Milewicz, Emerson Murphy-Hill, Tyler Menezes, Alexander Serebrenik, Igor Steinmacher, Anita Sarma* | **Category: cs.SE** | **Updated: 2025-08-06**

**Keywords:** 生成式AI, 开源社区, 社会技术框架, 社区韧性, 麦克卢汉四元组

**Comment:** 

> **TL;DR:** 本文提出了一个社会技术框架，用于帮助开源社区应对生成式AI带来的挑战和机遇，以提升社区韧性。

**AI_Comments:** 本文提出了一种及时且重要的视角，以应对生成式AI对开源社区的深远影响。其创新之处在于将麦克卢汉的四元组理论应用于社会技术框架，为分析GenAI带来的复杂性提供了一个结构化的方法。这对于帮助社区从被动应对转变为主动塑造未来具有重要意义。然而，作为一篇概念性探索文章，其局限性在于缺乏实证数据支撑，未来的研究可能需要通过案例研究或定量分析来验证其框架的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI正在迅速改变软件的创建、维护和治理方式，导致开源软件社区面临巨大不确定性。缺乏明确的框架可能使社区不堪重负，威胁到开源软件赖以生存的协作精神。

**Method:** 本文采用了一种情景驱动的、概念性探索方法，使用受麦克卢汉四元组启发的社会技术框架，旨在揭示在生成式AI驱动的开源软件开发中断中，社区在软件实践、文档、社区参与和治理这四个领域所面临的风险和机遇。

**Result:** 本文提供了一个社会技术框架，用于识别生成式AI对开源社区的风险和机遇，涵盖了软件实践、文档、社区参与和治理四个关键领域。通过该框架，开源领袖和研究人员可以更好地理解并主动塑造其生态系统的未来。

**Conclusion:** 通过采用本文提出的社会技术视角，开源领袖和研究人员可以主动塑造其生态系统的未来，而不仅仅是被动应对技术变革。

> **ai_Abstract:** 本文探讨了生成式AI对开源软件社区的影响，指出其带来的不确定性和潜在威胁。作者提出一个受麦克卢汉四元组启发的社会技术框架，通过情景驱动的概念性探索，识别了在软件实践、文档、社区参与和治理四个领域中，生成式AI对社区韧性造成的风险和机遇。该研究旨在帮助开源领袖和研究人员主动应对技术变革，塑造社区未来。

> **摘要翻译:** 开源软件社区正面临着一波不确定性，因为生成式AI正在迅速改变软件的创建、维护和治理方式。如果没有明确的框架，社区可能被生成式AI带来的复杂性和模糊性所淹没，从而威胁到支撑开源软件的协作精神。我们进行了一项情景驱动的概念性探索，使用受麦克卢汉四元组启发的社会技术框架，以揭示在生成式AI驱动的开源软件开发中断中，社区在软件实践、文档、社区参与和治理这四个领域所面临的风险和机遇。通过采用这一视角，开源软件的领导者和研究人员可以主动塑造其生态系统的未来，而不是简单地被动应对技术剧变。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [133] [Generative AI for Object-Oriented Programming: Writing the Right Code and Reasoning the Right Logic](https://arxiv.org/abs/2508.05005)
> *生成式AI用于面向对象编程：编写正确的代码和推理正确的逻辑*

*Gang Xu, Airong Wang, Yushan Pan* | **Category: cs.SE** | **Updated: 2025-08-07**

**Keywords:** 生成式AI, 面向对象编程, 大型语言模型, 代码编写, 逻辑推理

**Comment:** 

> **TL;DR:** 本文旨在探讨大型语言模型（LLMs）与面向对象编程（OOP）的结合，提出一个愿景，即如何利用LLMs提升OOP的学习和代码编写效率，并增强编程体验。

**AI_Comments:** 本文的创新点在于提出了将大型语言模型应用于面向对象编程的愿景，旨在解决当前该交叉领域研究不足的问题。通过从不同利益相关者的角度审视，并识别关键集成点，为未来LLMs在软件开发，特别是OOP领域的应用提供了新的思路和方向。其重要性在于指出了AI辅助编程的潜在未来，但由于是愿景性论文，具体实施和效果仍需进一步研究验证。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能研究，特别是大型语言模型（LLMs）发展迅速，应用广泛。然而，LLMs与面向对象编程（OOP）的结合仍是一个未被充分探索的领域。目前，我们对LLMs如何提升OOP学习和代码编写效率，以及如何评估这些AI工具的理解有限。本文旨在弥补这一空白。

**Method:** 本文通过从OOP任务中关键利益相关者（程序员、海员和经验丰富的程序员）的角度提出一个愿景来解决这一空白。我们识别了典型编码工作流程中整合LLMs可以带来显著效益的关键节点。此外，我们提出了增强现有逻辑推理和代码编写的方法，最终提升编程体验。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在面向对象编程（OOP）领域的应用潜力，指出目前LLMs与OOP的交叉领域仍未被充分研究。作者旨在弥补这一空白，提出一个愿景，从程序员、海员和经验丰富的程序员等关键利益相关者的角度，识别LLMs可以显著增强代码编写流程的关键环节，并提出增强逻辑推理和代码编写的方法，以提升整体编程体验。

> **摘要翻译:** 我们正处于人工智能研究，特别是大型语言模型（LLMs）爆炸式增长的时代。这些模型在金融、常识知识图谱、医学和视觉分析等领域有着广泛的应用。在面向对象编程（OOP）的世界中，已经发展出一套强大的知识体系和方法，通过面向对象的思维来管理复杂的任务。然而，LLMs与OOP的交叉领域仍未被充分探索。经验上，我们目前对LLMs如何提升OOP学习和代码编写的效率，以及如何评估这些由AI驱动的工具的理解有限。我们的工作旨在通过从参与OOP任务的关键利益相关者（程序员、海员和经验丰富的程序员）的角度提出一个愿景来解决这一空白。我们识别了典型编码工作流程中整合LLMs可以带来显著效益的关键节点。此外，我们提出了增强现有逻辑推理和代码编写的方法，最终提升编程体验。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [140] [LadyBug: A GitHub Bot for UI-Enhanced Bug Localization in Mobile Apps](https://arxiv.org/abs/2508.05085)
> *LadyBug：一个用于移动应用UI增强型错误定位的GitHub机器人*

*Junayed Mahmud, James Chen, Terry Achille, Camilo Alvarez-Velez, Darren Dean Bansil, Patrick Ijieh, Samar Karanch, Nadeeshan De Silva, Oscar Chaparro, Andrian Marcus, Kevin Moran* | **Category: cs.SE** | **Updated: 2025-08-07**

**Keywords:** 错误定位, GitHub机器人, UI信息, Android应用, 文本检索

**Comment:** 

> **TL;DR:** LadyBug是一个GitHub机器人，通过结合UI信息和文本检索，自动为Android应用定位错误，并显著提高了定位准确性。

**AI_Comments:** LadyBug的创新点在于将UI交互信息引入到错误定位中，这弥补了传统纯文本检索方法的不足。其作为GitHub机器人的实现方式，也使得该工具能够无缝集成到开发流程中，具有很高的实用价值和潜在影响力。作为开源工具，它也促进了社区的参与和进一步发展。

<details>
  <summary>Details</summary>

**Motivation:** 在移动应用开发中，自动定位错误是一项挑战。本文旨在通过结合用户界面（UI）交互信息和文本检索来提高Android应用错误定位的准确性和效率。

**Method:** 本文介绍了LadyBug，一个GitHub机器人。当GitHub问题跟踪器中报告错误时，LadyBug会被触发。开发者可以录制并上传错误复现轨迹，LadyBug结合原始错误描述文本和复现轨迹中的UI信息，检索并生成最可能包含错误的文件的排名列表。该方法通过一个包含80个错误报告的RedWing基准进行了实证评估。

**Result:** 实验结果表明，LadyBug的性能优于基于文本检索的基线方法，并且利用UI信息能够显著提高错误定位的准确性。

**Conclusion:** 通过结合UI交互信息和文本检索，LadyBug能够更准确地定位Android应用中的错误，为开发者提供了更高效的错误诊断工具。

> **ai_Abstract:** 本文介绍了一个名为LadyBug的GitHub机器人，它通过结合UI交互信息和文本检索，实现Android应用的自动化错误定位。开发者上传错误复现轨迹后，LadyBug利用文本描述和UI信息生成潜在错误文件的排名列表。实验证明，LadyBug在错误定位准确性上优于传统文本检索方法，尤其是在利用UI信息后准确度显著提升。LadyBug是一个开源工具。

> **摘要翻译:** 本文介绍了LadyBug，一个GitHub机器人，它通过结合UI交互信息和文本检索，自动为Android应用定位错误。LadyBug连接到Android应用的GitHub仓库，并在相应的议题追踪器中报告错误时被触发。开发者可以在设备或模拟器上记录错误的复现轨迹，并通过GitHub议题追踪器将轨迹上传到LadyBug。这使得LadyBug能够利用原始错误描述的文本以及复现轨迹中的UI信息，准确地检索出项目中包含报告错误可能性最高的文件列表。
我们使用一个名为RedWing的自动化测试管道和基准对LadyBug进行了实证评估，该基准包含来自39个Android应用的80个完全定位且可复现的错误报告。我们的结果表明，LadyBug优于基于文本检索的基线方法，并且UI信息的利用显著提高了定位准确性。LadyBug是一个开源工具，可在https://github.com/LadyBugML/ladybug获取。
展示LadyBug功能的视频可在此处观看：https://youtu.be/hI3tzbRK0Cw

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [152] [AI-assisted JSON Schema Creation and Mapping](https://arxiv.org/abs/2508.05192)
> *AI辅助的JSON Schema创建与映射*

*Felix Neubauer, Jürgen Pleiss, Benjamin Uekermann* | **Category: cs.SE** | **Updated: 2025-08-07**

**Keywords:** JSON Schema, 大型语言模型, 数据集成, 模型驱动工程, 自然语言处理

**Comment:** 

> **TL;DR:** 本文提出了一种结合大型语言模型和确定性技术的混合方法，以实现基于自然语言输入的JSON Schema创建、修改和映射，显著降低了非专家进行结构化数据建模和数据集成的门槛。

**AI_Comments:** 该论文的创新之处在于其混合方法，结合了LLMs的灵活性和自然语言处理能力与确定性技术的可靠性和可扩展性。这有效解决了非专业用户在创建和管理复杂数据模型方面的痛点，具有重要的实际应用价值，尤其是在数据标准化和集成方面。

<details>
  <summary>Details</summary>

**Motivation:** 在研究数据领域，模型通常以定义数据集结构和语义的Schema形式表达。然而，许多领域仍缺乏标准化模型，且Schema创建对非专家而言是一个重大障碍。

**Method:** 本文提出了一种混合方法，结合大型语言模型（LLMs）与确定性技术，实现基于自然语言输入的JSON Schema创建、修改和Schema映射。这些功能被集成到开源工具MetaConfigurator中。对于数据集成，使用LLMs从异构JSON、CSV、XML和YAML数据生成Schema映射，并通过确定性执行生成的映射规则确保可扩展性和可靠性。

**Result:** 所提出的能力已集成到开源工具MetaConfigurator中。该方法能够从异构数据生成Schema映射。其适用性通过一个化学领域的应用示例得到证明。

**Conclusion:** 通过结合自然语言交互与确定性保障，这项工作显著降低了非专家进行结构化数据建模和数据集成的门槛。

> **ai_Abstract:** 本文提出了一种结合大型语言模型（LLMs）和确定性技术的混合方法，旨在简化JSON Schema的创建、修改和映射过程。该方法允许用户通过自然语言输入操作Schema，并已集成到MetaConfigurator工具中。此外，它还能利用LLMs从多种异构数据源生成Schema映射，并通过确定性规则确保可靠性与可扩展性。此项工作通过在化学领域的应用示例，证明了其能够显著降低非专家进行结构化数据建模和数据集成的门槛。

> **摘要翻译:** 模型驱动工程（MDE）将模型置于系统和数据工程过程的核心。在研究数据背景下，这些模型通常以Schema的形式表达，定义数据集的结构和语义。然而，许多领域仍然缺乏标准化模型，创建它们仍然是一个重大障碍，特别是对于非专家而言。我们提出了一种混合方法，将大型语言模型（LLMs）与确定性技术相结合，使用户能够基于自然语言输入进行JSON Schema的创建、修改和Schema映射。这些功能被集成到开源工具MetaConfigurator中，该工具已提供可视化模型编辑、验证、代码生成和从模型生成表单的功能。对于数据集成，我们使用LLMs从异构JSON、CSV、XML和YAML数据生成Schema映射，同时通过确定性执行生成的映射规则确保可扩展性和可靠性。我们的工作在化学领域的应用示例中得到了验证。通过将自然语言交互与确定性保障相结合，这项工作显著降低了非专家进行结构化数据建模和数据集成的门槛。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [153] [STEPWISE-CODEX-Bench: Evaluating Complex Multi-Function Comprehension and Fine-Grained Execution Reasoning](https://arxiv.org/abs/2508.05193)
> *STEPWISE-CODEX-Bench：评估复杂多函数理解和细粒度执行推理*

*Kaiwen Yan, Yuhang Chang, Zirui Guo, Yaling Mou, Jiang Ming, Jingwei Sun* | **Category: cs.SE** | **Updated: 2025-08-07**

**Keywords:** 代码智能, 大型语言模型, 基准测试, 多函数理解, 执行推理

**Comment:** 

> **TL;DR:** 本文提出了STEPWISE-CODEX-Bench (SX-Bench)，一个用于评估大型语言模型在复杂多函数理解和细粒度执行推理方面能力的新基准，解决了现有基准饱和度高的问题，并揭示了SOTA模型在此类任务中的瓶颈。

**AI_Comments:** 这项工作非常重要，因为它解决了现有代码理解和推理基准的饱和度问题，为评估LLMs在更复杂、更接近真实世界编程场景下的能力提供了新工具。其创新之处在于引入了“计算步骤”的概念，并关注多函数协作和动态执行流，这比传统的I/O匹配更能深入地衡量模型的理解能力。该基准有望推动LLMs在代码智能领域的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型 (LLMs) 代码智能评估基准，如HumanEval和MBPP，主要评估功能正确性，而推理基准如CRUXEVAL则局限于单函数、低复杂度的场景，导致先进模型得分饱和，缺乏区分度。

**Method:** 本文提出了STEPWISE-CODEX-Bench (SX-Bench)，一个新颖的基准，旨在评估复杂多函数理解和细粒度执行推理。SX-Bench的任务涉及多子函数协作（如链式调用、嵌套循环），将评估重点转向整体控制和数据流建模。它将“计算步骤”定义为最小执行单元，并要求模型预测推理任务中的总步骤数，以评估模型对动态执行的深入理解。此外，还发布了一个结合程序合成、符号执行和LLM辅助验证的自动化管道，用于高效的基准生成和质量保证。

**Result:** 对20多个主流模型（包括14个推理增强模型）的评估表明，SX-Bench具有高度区分性：即使是最先进的OpenAI-O3在硬推理任务上的准确率也仅为78.37%，远低于其在先前基准上的饱和分数，从而揭示了在复杂和细粒度推理方面的瓶颈。

**Conclusion:** SX-Bench将代码评估从“单函数验证”推进到“多函数动态推理”，为深入评估先进代码智能模型提供了关键工具。

> **ai_Abstract:** 本文针对现有代码智能评估基准在LLMs复杂代码理解和推理能力评估上的局限性，提出了STEPWISE-CODEX-Bench (SX-Bench)。该基准专注于多函数协作和细粒度执行推理，通过要求模型预测“计算步骤”来深入评估动态执行理解。实验证明，SX-Bench具有高度区分性，即使是SOTA模型也在此基准上表现出显著的性能下降，揭示了当前LLMs在处理复杂推理任务时的瓶颈。研究还提供了一个自动化基准生成管道，并强调SX-Bench推动了代码评估从单函数验证向多函数动态推理的转变。

> **摘要翻译:** 近年来，大型语言模型（LLMs）在代码智能方面取得了显著进展，然而系统地评估它们的代码理解和推理能力仍然具有挑战性。主流基准如HumanEval和MBPP主要评估功能正确性，而推理基准如CRUXEVAL则仅限于单函数、低复杂度的场景。因此，先进模型取得了接近饱和的分数，限制了它们的区分能力。为了解决这个问题，我们提出了STEPWISE-CODEX-Bench (SX-Bench)，一个新颖的基准，旨在评估复杂的多函数理解和细粒度执行推理。SX-Bench的特点是任务涉及多个子函数之间的协作（例如，链式调用、嵌套循环），将评估转向整体控制和数据流建模。它将“计算步骤”定义为最小执行单元，并要求模型预测推理任务中的总步骤数，从而评估模型对动态执行的深入理解，而不仅仅是简单的I/O匹配。对20多个主流模型（包括14个推理增强模型）的评估表明，SX-Bench具有高度区分性：即使是最先进的OpenAI-O3在硬推理任务上的准确率也仅为78.37%，远低于其在先前基准上的饱和分数，从而揭示了复杂和细粒度推理中的瓶颈。我们还发布了一个结合程序合成、符号执行和LLM辅助验证的自动化管道，用于高效的基准生成和质量保证。SX-Bench将代码评估从“单函数验证”推进到“多函数动态推理”，为深入评估先进代码智能模型提供了关键工具。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [161] [Blended PC Peer Review Model: Process and Reflection](https://arxiv.org/abs/2504.19105)
> *混合PC同行评审模型：过程与反思*

*Chakkrit Tantithamthavorn, Nicole Novielli, Ayushi Rastogi, Olga Baysal, Bram Adams* | **Category: cs.SE** | **Updated: 2025-08-07**

**Keywords:** 同行评审, 混合PC, 学术会议, 评审模型, MSR

**Comment:** 

> **TL;DR:** MSR 2025 试验了一种新的混合PC同行评审模型，将一名初级PC成员与两名常规PC成员配对，旨在缓解评审人员短缺、促进包容性并维持高质量评审。

**AI_Comments:** 该论文提出了一种创新的同行评审模型，通过整合初级评审员来缓解当前学术评审系统面临的压力。其创新之处在于将初级评审员融入核心评审团队，而非作为额外补充，这有助于知识传递和能力培养。通过实证调查验证其有效性，为学术会议提供了一个可持续且包容的评审解决方案，具有重要的实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于投稿量增加和可用评审人员有限，学术同行评审系统面临巨大压力，导致决策延迟和评审责任分配不均。

**Method:** MSR 2025 在技术赛道试验了混合程序委员会（PC）同行评审模型。该模型将一名初级PC成员与两名常规PC成员配对，作为给定论文的核心评审团队，而不是将其作为额外评审人员。本文介绍了该模型的原理、实施和反思，包括来自评审后作者调查的实证见解。

**Result:** 研究结果强调了混合PC在缓解评审人员短缺、促进包容性和维持高质量同行评审过程方面的潜力。

**Conclusion:** 本文提供了经验教训和建议，以指导该模型未来的采用和完善。

> **ai_Abstract:** 该论文介绍了MSR 2025 试验的混合程序委员会（PC）同行评审模型，旨在应对日益增长的投稿量和有限的评审人员导致的同行评审系统压力。该模型将一名初级PC成员与两名常规PC成员配对组成核心评审团队。通过实证调查，研究发现该模型有助于缓解评审人员短缺、促进包容性并维持高质量评审，并提供了未来采用和完善的建议。

> **摘要翻译:** 学术同行评审系统正面临越来越大的压力，原因在于投稿量不断增长和可用评审人员池有限，这导致决策延迟和评审责任分配不均。在国际软件仓库挖掘大会（MSR）社区早期影子PC（2021年和2022年）和初级PC（2023年和2024年）经验的基础上，MSR 2025 在其技术赛道试验了一种混合程序委员会（PC）同行评审模型。这种新模型将一名初级PC成员与两名常规PC成员配对，作为给定论文的核心评审团队，而不是将其作为额外评审人员。本文介绍了该模型的原理、实施和反思，包括来自评审后作者调查的实证见解，该调查评估了评审的质量和有用性。我们的研究结果强调了混合PC在缓解评审人员短缺、促进包容性和维持高质量同行评审过程方面的潜力。我们提供了经验教训和建议，以指导该模型未来的采用和完善。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [168] [Modeling roles and trade-offs in multiplex networks](https://arxiv.org/abs/2508.05488)
> *多重网络中的角色建模与权衡*

*Nikolaos Nakis, Sune Lehmann, Nicholas A. Christakis, Morten Mørup* | **Category: cs.SI** | **Updated: 2025-08-07**

**Keywords:** 多重网络, 社会网络, 角色建模, 相互依赖性, 潜在权衡模型

**Comment:** 

> **TL;DR:** 引入多重潜在权衡模型（MLT），用于提取多重网络中的角色并理解相互依赖性，揭示核心社会交换原则和特定层社区结构。

**AI_Comments:** 本文的创新之处在于引入了MLT模型，该模型明确考虑了独立性、依赖性和相互依赖性，并将角色建模为跨层和跨尺度的权衡。与单层网络分析相比，这种多方面的方法提供了对复杂社会系统更全面的理解。对真实世界数据的实证应用以及在社会、健康和经济层面的差异化发现，突显了其在实际中的重要性以及对人类社会结构的新颖见解。

<details>
  <summary>Details</summary>

**Motivation:** 理解多重社会网络的结构具有挑战性，因为不同层可以反映不同但互补的角色，且相互依赖性在多个尺度上出现。现有的方法可能无法充分考虑独立性、依赖性和相互依赖性。

**Method:** 本文引入了多重潜在权衡模型（MLT），这是一个用于提取多重社会网络中角色的框架。MLT将角色定义为权衡，要求每个节点在层之间分配其源和目标角色，同时在分层、多尺度结构中分配社区成员身份。它考虑了独立性、依赖性和相互依赖性。

**Result:** 将MLT应用于来自洪都拉斯西部村庄的176个真实世界的多重网络（由社会、健康和经济层组成），揭示了核心社会交换原则的出现以及局部、层特定和多尺度的社区。链接预测分析表明，对相互依赖性进行建模在社会层中产生了最大的性能提升，而在健康和经济层中的效果则更为微妙。

**Conclusion:** 研究结果为人类社会系统的结构提供了新的见解，表明社会关系是结构性嵌入的，而健康和经济关系主要由个人地位和行为参与塑造。

> **ai_Abstract:** 本文引入了多重潜在权衡模型（MLT），用于刻画多重社会网络中的角色和相互依赖性。MLT将角色建模为跨层和多尺度社区的权衡。应用于真实世界数据时，MLT揭示了核心社会交换原则和特定层社区，表明对相互依赖性进行建模显著提高了社会层中的链接预测性能，这暗示社会关系是结构性嵌入的，与健康和经济关系不同。

> **摘要翻译:** 多重社会网络捕获了同一组人之间的多种社会关系，每层代表一种不同的关系类型。理解此类系统的结构使我们能够识别社会交换如何由个人的自身属性和行为（独立性）、他人的地位或资源（依赖性）以及实体之间的相互影响（相互依赖性）驱动。表征多重网络中的结构具有挑战性，因为不同的层可以反映不同但互补的角色，并且相互依赖性在多个尺度上出现。在此，我们引入了多重潜在权衡模型（MLT），这是一个用于提取多重社会网络中角色的框架，它考虑了独立性、依赖性、和相互依赖性。MLT将角色定义为权衡，要求每个节点在层之间分配其源角色和目标角色，同时在分层、多尺度结构中分配社区成员身份。将MLT方法应用于来自洪都拉斯西部村庄的176个真实世界的多重网络，由社会、健康和经济层组成，我们看到了核心社会交换原则的出现，同时揭示了局部、层特定和多尺度的社区。链接预测分析表明，对相互依赖性进行建模在社会层中产生了最大的性能提升，而在健康和经济层中的效果则更为微妙。这表明社会关系是结构性嵌入的，而健康和经济关系主要由个人地位和行为参与塑造。我们的发现为人类社会系统的结构提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [180] [Weak Identification in Peer Effects Estimation](https://arxiv.org/abs/2508.04897)
> *同伴效应估计中的弱识别问题*

*William W. Wang, Ali Jadbabaie* | **Category: cs.SI, econ.EM, math.ST** | **Updated: 2025-08-06**

**Keywords:** 同伴效应, 弱识别, 线性均值模型, 线性求和模型, 网络模型

**Comment:** 

> **TL;DR:** 在“填充”渐近设置下，传统的基于邻里平均特征的线性均值模型在估计同伴效应时存在渐近共线性导致的偏差或收敛缓慢问题。本研究提出并证明基于邻里总和特征的线性求和模型可以避免这些问题，提供了一种更可靠的替代方案。

**AI_Comments:** 这篇论文的创新点在于揭示了在特定渐近条件下，广泛使用的网络线性均值模型在同伴效应估计中存在的弱识别和估计不可靠问题。它不仅指出了问题，还提出了一个具有实践意义的替代方案——线性求和模型，并证明了其有效性。这对于社会网络分析和计量经济学领域中同伴效应的准确估计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 同伴效应（如个体吸烟习惯与同伴的相关性）普遍存在，而网络线性均值模型是分析此类效应的常用统计模型。然而，尽管模型参数在特定网络结构条件下可识别，但在单一网络规模增长的“填充”渐近设置下，其识别是否能确保可靠估计仍不明确。

**Method:** 研究通过理论分析展示了当协变量独立同分布且节点平均网络度随总体规模增加时，标准估计器会因网络平均引起的渐近共线性而出现偏差或收敛缓慢。作为替代方案，研究提出并证明了基于邻里总和而非平均特征的线性求和模型不会出现这些问题，只要网络度存在非平凡变异。

**Result:** 研究发现，当协变量独立同分布且节点平均网络度随总体规模增加时，标准的线性均值模型估计器由于网络平均引起的渐近共线性而存在偏差或收敛缓慢。相比之下，基于聚合而非平均邻里特征的线性求和模型则没有这些问题，前提是网络度存在一些非平凡的变异，而这通常适用于大多数网络模型。

**Conclusion:** 在“填充”渐近设置下，传统的线性均值模型在估计同伴效应时面临弱识别问题，导致估计器存在偏差或收敛缓慢。线性求和模型作为一种替代方案，能够有效解决这些问题，为同伴效应的可靠估计提供了新的途径。

> **ai_Abstract:** 本研究探讨了在“填充”渐近设置下，同伴效应估计中常用网络线性均值模型所面临的弱识别问题。研究发现，当协变量独立同分布且平均网络度随人口规模增加时，该模型因渐近共线性导致标准估计器存在偏差或收敛缓慢。为解决此问题，论文提出并验证了线性求和模型，即基于邻里总和而非平均特征的模型，该模型在网络度存在非平凡变异的条件下能避免上述问题，从而提供了一种更可靠的同伴效应估计方法。

> **摘要翻译:** 人们普遍认为某些现象具有社会性：例如，个体的吸烟习惯通常与其同伴的习惯相关。这种相关性可能有多种解释，例如直接传染或共享的社会经济环境。网络线性均值模型是一种常用的统计模型，它通过将邻里平均特征作为回归变量来纳入这些同伴效应。尽管该模型的参数在网络的温和结构条件下是可识别的，但尚不清楚在“填充”渐近设置（即单个网络规模增大）下，识别是否能确保可靠的估计。我们表明，当协变量独立同分布且节点的平均网络度随总体规模增加时，由于网络平均引起的渐近共线性，标准估计器会遭受偏差或收敛缓慢的问题。作为替代方案，我们证明了基于邻里总和而非平均特征的线性求和模型不会出现这些问题，只要网络度存在一些非平凡的变异，而这通常适用于大多数网络模型。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [540] [Closed-Form Successive Relative Transfer Function Vector Estimation based on Blind Oblique Projection Incorporating Noise Whitening](https://arxiv.org/abs/2508.04887)
> *结合噪声白化的盲斜投影闭式逐次相对传递函数向量估计*

*Henri Gode, Simon Doclo* | **Category: eess.AS** | **Updated: 2025-08-06**

**Keywords:** 相对传递函数, 盲斜投影, 闭式解, 噪声白化, 声源计数

**Comment:** 

> **TL;DR:** 本文提出了一种改进的盲斜投影方法，通过闭式解、正交附加向量和噪声白化技术，解决了在噪声和混响环境中在线估计逐次激活声源相对传递函数向量的挑战。

**AI_Comments:** 本文通过引入闭式解、正交附加向量和噪声处理技术，显著提升了盲斜投影方法在复杂声学环境下估计相对传递函数向量的效率和鲁棒性，尤其是在低信噪比和多源同时激活的挑战性场景。闭式解的提出是计算效率上的重要突破，而噪声白化则增强了方法的实用性，使其更适用于实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的盲斜投影（BOP）方法在估计逐次激活声源的相对传递函数（RTF）向量时存在局限性：计算复杂度高（依赖迭代梯度下降）、引入随机附加向量可能影响性能，以及假设高信噪比。

**Method:** 本文提出了BOP方法的三项扩展：1. 推导了BOP成本函数的闭式解，以降低计算复杂度。2. 引入正交附加向量代替随机向量，以提高RTF向量估计精度。3. 结合了受协方差减法和白化启发的噪声处理技术，以提高低信噪比条件下的鲁棒性。此外，还提出了一种基于空间相干性的在线声源计数方法来估计声源活动模式。

**Result:** 仿真在包含3个逐次激活说话者的真实世界混响噪声录音上进行，并测试了有无声源活动模式先验知识的情况。结果表明所提方法克服了传统BOP方法的局限性，提升了性能，但摘要中未提供具体的量化结果。

**Conclusion:** 本文通过推导闭式解、引入正交附加向量和结合噪声处理技术，成功克服了传统盲斜投影方法在噪声和混响环境下在线估计逐次激活声源相对传递函数向量的局限性，显著提高了方法的效率和鲁棒性。

> **ai_Abstract:** 本文针对在噪声和混响环境中在线估计逐次激活声源的相对传递函数（RTF）向量这一挑战，对传统盲斜投影（BOP）方法进行了改进。通过引入BOP成本函数的闭式解以降低计算复杂性，采用正交附加向量以提高估计精度，并结合噪声处理技术以增强低信噪比下的鲁棒性，克服了现有方法的不足。此外，还提出了一种基于空间相干性的在线声源计数方法。仿真验证了所提方法的有效性。

> **摘要翻译:** 相对传递函数（RTF）在波束成形中扮演着关键角色，能够有效抑制噪声和干扰。本文解决了在噪声和混响环境中，针对声源逐次激活的特定场景，在线估计多个声源RTF向量的挑战。虽然第一个声源的RTF向量可以简单估计，但主要挑战出现在多个声源同时激活的片段中估计后续声源的RTF向量。盲斜投影（BOP）方法已被提出用于通过最优地阻断新激活声源来估计其RTF向量。然而，该方法面临几个局限性：由于依赖迭代梯度下降优化而导致的高计算复杂度，引入随机附加向量可能对性能产生负面影响，以及假设高信噪比（SNR）。为了克服这些局限性，本文提出了BOP方法的三个扩展。首先，我们推导了优化BOP成本函数的闭式解，显著降低了计算复杂度。其次，我们引入正交附加向量而非随机向量，提高了RTF向量估计精度。第三，我们结合了受协方差减法和白化启发的噪声处理技术，增加了在低信噪比条件下的鲁棒性。为了提供传统BOP方法和所提方法所需的声源活动模式的逐帧估计，我们提出了一种基于空间相干性的在线声源计数方法。仿真使用真实世界的混响噪声录音进行，其中有3个逐次激活的说话者，包括有无声源活动模式先验知识的情况。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [545] [REF-VC: Robust, Expressive and Fast Zero-Shot Voice Conversion with Diffusion Transformers](https://arxiv.org/abs/2508.04996)
> *REF-VC：基于扩散Transformer的鲁棒、富有表现力、快速的零样本语音转换*

*Yuepeng Jiang, Ziqian Ning, Shuai Wang, Chengjia Wang, Mengxiao Bi, Pengcheng Zhu, Lei Xie, Zhonghua Fu* | **Category: eess.AS** | **Updated: 2025-08-07**

**Keywords:** 语音转换, 零样本, 扩散Transformer, 噪声鲁棒性, 表现力

**Comment:** 

> **TL;DR:** REF-VC是一种鲁棒、富有表现力且快速的零样本语音转换系统，通过创新策略解决了现有方法的噪声敏感性和表现力不足问题。

**AI_Comments:** REF-VC的创新点在于结合了多种策略来同时解决零样本语音转换中的噪声鲁棒性、表现力和推理速度问题，特别是随机擦除策略和快捷模型的使用。其兼容歌唱语音转换的能力也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在实际语音转换应用中，源语音中的环境噪声和用户对富有表现力输出的需求构成了严峻挑战。传统ASR方法确保噪声鲁棒性但抑制韵律，而SSL模型提高表现力但存在音色泄露和噪声敏感性。

**Method:** 本文提出了REF-VC，一个噪声鲁棒、富有表现力的零样本语音转换系统。主要创新包括：(1) 随机擦除策略，减轻SSL特征的信息冗余，增强噪声鲁棒性和表现力；(2) 受E2TTS启发的隐式对齐，抑制非必要特征重建；(3) 集成Shortcut Models加速流匹配推理，显著减少到4步。

**Result:** 实验结果表明，在零样本场景下，REF-VC模型在噪声数据集上优于Seed-VC等基线模型，在干净数据集上与Seed-VC表现相当。此外，REF-VC可以在一个模型内兼容歌唱语音转换。

**Conclusion:** REF-VC成功地解决了零样本语音转换中噪声鲁棒性和表现力的挑战，并在速度上有所提升，同时具备歌唱语音转换能力。

> **ai_Abstract:** 本文提出了REF-VC，一个基于扩散Transformer的鲁棒、富有表现力、快速的零样本语音转换系统。针对现有方法在噪声环境下的表现力不足和噪声敏感性问题，REF-VC引入了随机擦除策略增强鲁棒性和表现力，通过隐式对齐抑制冗余特征，并集成快捷模型加速推理。实验证明REF-VC在噪声环境下优于基线模型，在干净环境下表现相当，且支持歌唱语音转换。

> **摘要翻译:** 在实际语音转换应用中，源语音中的环境噪声和用户对富有表现力输出的需求构成了严峻挑战。传统的基于ASR的方法确保了噪声鲁棒性但抑制了韵律，而基于SSL的模型提高了表现力但存在音色泄露和噪声敏感性。本文提出了REF-VC，一种噪声鲁棒、富有表现力的语音转换系统。主要创新包括：(1) 一种随机擦除策略，用于减轻SSL特征中固有的信息冗余，增强噪声鲁棒性和表现力；(2) 受E2TTS启发的隐式对齐，以抑制非必要特征重建；(3) 集成快捷模型（Shortcut Models）以加速流匹配推理，显著减少到4步。实验结果表明，在零样本场景下，我们的模型在噪声数据集上优于Seed-VC等基线模型，同时在干净数据集上与Seed-VC表现相当。此外，REF-VC可以在一个模型内兼容歌唱语音转换。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [551] [MOVER: Combining Multiple Meeting Recognition Systems](https://arxiv.org/abs/2508.05055)
> *MOVER：结合多种会议识别系统*

*Naoyuki Kamo, Tsubasa Ochiai, Marc Delcroix, Tomohiro Nakatani* | **Category: eess.AS** | **Updated: 2025-08-07**

**Keywords:** 会议识别, 系统组合, 语音分离, 自动语音识别, MOVER

**Comment:** 

> **TL;DR:** MOVER是一种新颖的系统组合方法，用于会议识别任务，它能结合不同语音分离和自动语音识别输出的系统，并显著提升性能。

**AI_Comments:** MOVER的创新之处在于它是首个能够同时结合在语音分离和自动语音识别方面都有差异的会议识别系统输出的方法，这解决了现有组合方法的局限性，显著提升了会议识别的性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法可以结合语音分离（如DOVER）或自动语音识别（ASR）系统（如ROVER）的输出，但MOVER是第一个能够结合在语音分离和ASR方面都有差异的会议识别系统输出的方法。

**Method:** MOVER通过一个五阶段的过程组合具有不同时间间隔和说话人标签的假设，该过程包括说话人对齐、片段分组、词语和时间组合等。

**Result:** 在CHiME-8 DASR任务和NOTSOFAR-1任务的多通道轨道上的实验结果表明，MOVER可以成功结合多个具有不同语音分离和识别输出的会议识别系统，相对于两种任务的最新系统，分别实现了9.55%和8.51%的相对tcpWER改进。

**Conclusion:** MOVER能够成功结合多种会议识别系统，并在性能上超越了现有最先进的系统，证明了其在处理多样化会议识别输出方面的有效性。

> **ai_Abstract:** MOVER是一种新颖的会议识别系统组合方法，旨在解决现有方法无法同时结合语音分离和自动语音识别差异的问题。它通过一个五阶段流程（包括说话人对齐、片段分组、词语和时间组合等）来整合不同时间间隔和说话人标签的假设。实验证明，MOVER在CHiME-8 DASR和NOTSOFAR-1任务上，相对于最先进系统，分别带来了9.55%和8.51%的相对tcpWER性能提升，成功结合了多样化的会议识别系统输出。

> **摘要翻译:** 在本文中，我们提出了会议识别器输出投票错误减少（MOVER），这是一种用于会议识别任务的新型系统组合方法。尽管存在结合语音分离（例如DOVER）或自动语音识别（ASR）系统（例如ROVER）输出的方法，但MOVER是第一个能够结合在语音分离和ASR方面都有差异的会议识别系统输出的方法。MOVER通过一个包括说话人对齐、片段分组、词语和时间组合等在内的五阶段过程，组合具有不同时间间隔和说话人标签的假设。在CHiME-8 DASR任务和NOTSOFAR-1任务的多通道轨道上的实验结果表明，MOVER可以成功结合多个具有不同语音分离和识别输出的会议识别系统，相对于两种任务的最新系统，分别实现了9.55%和8.51%的相对tcpWER改进。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [557] [Privacy Disclosure of Similarity in Speech and Language Processing](https://arxiv.org/abs/2508.05250)
> *语音和语言处理中相似度的隐私泄露*

*Tom Bäckström, Mohammad Hassan Vali, My Nguyen, Silas Rech* | **Category: eess.AS** | **Updated: 2025-08-07**

**Keywords:** 隐私泄露, 相似度排名, 生物识别, 个人身份信息, 熵

**Comment:** 

> **TL;DR:** 本文提出了一种量化语音和语言处理中相似度排名隐私泄露的方法，通过估计其概率分布，并发现各种生物特征都包含个人身份信息。

**AI_Comments:** 这篇论文的创新点在于提出了一个量化相似度排名隐私泄露的通用框架，特别是在数据不准确或稀缺的情况下。它将隐私泄露量化为熵，使得不同特征的泄露可以进行比较和叠加，这对于理解和评估生物识别系统中的隐私风险具有重要意义。该研究强调了即使是看似不精确的相似度信息也可能泄露敏感数据，提醒了隐私保护的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 在语音和语言处理中，即使基于不准确相似度测量的相似度排名，也可能泄露有关真实身份的私人信息。因此，需要一种方法来量化这种隐私泄露。

**Method:** 研究人员提出了一种通过估计相似度排名的概率分布来量化隐私泄露的方法。具体地，通过确定真实说话者相似度排名的直方图，或者在数据稀缺时使用beta-binomial分布建模直方图。泄露程度以熵（比特）表示，使得独立特征的泄露可以叠加。

**Result:** 实验表明，所有测试的说话者和作者特征都包含有助于身份识别的个人身份信息（PII），其中来自说话人识别算法的嵌入信息量最大，其次是音素嵌入、语言嵌入和基频。初步实验显示，PII的泄露量随测试样本长度的增加而增加，但受数据库模板长度的限制。

**Conclusion:** 所提出的相似度排名泄露度量提供了一种比较不同生物特征之间PII泄露并将其合并以辅助身份识别的方法，有助于全面评估语音和其他生物识别技术中的隐私威胁。

> **ai_Abstract:** 本文提出了一种量化语音和语言处理中相似度排名隐私泄露的新方法。该方法通过估计真实身份相似度排名的概率分布（使用直方图或beta-binomial分布），并以熵（比特）来衡量泄露程度。实验证明，各种语音和语言特征都含有可用于身份识别的个人身份信息，其中说话人识别嵌入的信息量最大。研究还发现，PII泄露量随测试样本长度增加而增加，但受限于数据库模板长度。该研究提供的相似度排名泄露度量有助于评估和合并不同生物特征的隐私泄露，从而全面评估生物识别技术中的隐私风险。

> **摘要翻译:** 说话人、作者及其他生物识别应用通常通过比较样本与模板数据库的相似度来确定身份。鉴于数据可能存在噪声且相似度测量可能不准确，这种比较可能无法可靠地将真实身份识别为最相似的。然而，即使基于不准确相似度测量的相似度排名，也可能泄露有关真实身份的私人信息。我们提出了一种通过估计其概率分布来量化这种相似度排名隐私泄露的方法。它基于确定真实说话人相似度排名的直方图，或者在数据稀缺时，使用beta-binomial分布对直方图进行建模。我们将泄露程度以熵（比特）表示，使得独立特征的泄露可以叠加。我们的实验表明，所有测试的说话人和作者特征都包含有助于身份识别的个人身份信息（PII），其中来自说话人识别算法的嵌入信息量最大，其次是音素嵌入、语言嵌入和基频。我们的初步实验表明，PII的泄露量随测试样本长度的增加而增加，但受数据库模板长度的限制。所提供的度量——相似度排名泄露，提供了一种比较生物特征之间PII泄露并将其合并以辅助身份识别的方法。因此，它有助于全面评估语音和其他生物识别技术中的隐私威胁。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [563] [Investigation of Speech and Noise Latent Representations in Single-channel VAE-based Speech Enhancement](https://arxiv.org/abs/2508.05293)
> *单通道VAE语音增强中语音和噪声潜在表征研究*

*Jiatong Li, Simon Doclo* | **Category: eess.AS** | **Updated: 2025-08-07**

**Keywords:** 变分自编码器, 语音增强, 潜在表征, 语音噪声分离

**Comment:** 

> **TL;DR:** 本文研究了在基于VAE的单通道语音增强系统中，修改预训练VAE损失项如何影响语音和噪声的潜在表征，以及这些不同表征对语音增强性能的影响。实验表明，语音和噪声表征明显分离的潜在空间能显著提高性能。

**AI_Comments:** 本文的创新点在于深入探讨了VAE中语音和噪声潜在表征的分离程度对语音增强性能的影响，指出了清晰分离的潜在空间对于性能提升的重要性，为未来的语音增强研究提供了新的方向和优化思路。

<details>
  <summary>Details</summary>

**Motivation:** 预训练VAE的损失项修改会影响预训练的语音和噪声潜在表征。本文旨在探究这些不同的表征如何影响语音增强性能。

**Method:** 本文基于先前提出的使用贝叶斯置换训练的VAE单通道语音增强系统，该系统使用两个预训练VAE获取语音和噪声的潜在表征。然后，一个噪声VAE学习从带噪语音中生成语音和噪声的潜在表征以进行语音增强。本文通过修改预训练VAE的损失项，研究不同语音和噪声潜在表征对语音增强性能的影响。

**Result:** 在DNS3、WSJ0-QUT和VoiceBank-DEMAND数据集上的实验表明，与产生重叠语音和噪声表征的标准VAE相比，语音和噪声表征清晰分离的潜在空间显著提高了语音增强性能。

**Conclusion:** 语音和噪声表征在潜在空间中清晰分离，可以显著提高基于VAE的单通道语音增强系统的性能。

> **ai_Abstract:** 本文研究了基于VAE的单通道语音增强系统中，语音和噪声潜在表征对性能的影响。该系统利用预训练的VAE获取语音和噪声的潜在表征，并进一步通过噪声VAE从带噪语音中生成这些表征。研究发现，通过修改预训练VAE的损失项，可以影响这些潜在表征。实验结果表明，当语音和噪声表征在潜在空间中清晰分离时，相比于表征重叠的标准VAE，语音增强性能得到显著提升。

> **摘要翻译:** 最近，一种使用贝叶斯置换训练的基于变分自编码器（VAE）的单通道语音增强系统被提出，该系统利用两个预训练的VAE来获取语音和噪声的潜在表征。在此基础上，一个噪声VAE学习从带噪语音中生成语音和噪声的潜在表征，以实现语音增强。修改预训练VAE的损失项会影响预训练的语音和噪声潜在表征。在本文中，我们研究了这些不同的表征如何影响语音增强性能。在DNS3、WSJ0-QUT和VoiceBank-DEMAND数据集上的实验表明，与产生重叠语音和噪声表征的标准VAE相比，语音和噪声表征明显分离的潜在空间显著提高了性能。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [569] [Overview of Automatic Speech Analysis and Technologies for Neurodegenerative Disorders: Diagnosis and Assistive Applications](https://arxiv.org/abs/2501.03536)
> *神经退行性疾病自动语音分析与技术概述：诊断与辅助应用*

*Shakeel A. Sheikh, Md. Sahidullah, Ina Kodrasi* | **Category: eess.AS** | **Updated: 2025-08-06**

**Keywords:** 神经退行性疾病, 语音分析, 病理语音, 自动语音识别, 辅助技术

**Comment:** 

> **TL;DR:** 本文综述了神经退行性语音障碍的自动语音分析和技术，涵盖了当前最先进的方法、挑战和未来发展方向。

**AI_Comments:** 这是一篇重要的综述性论文，为神经退行性语音障碍的自动语音分析和技术领域提供了全面的概览。它不仅总结了现有技术，还指出了该领域面临的挑战并提出了未来的发展方向，对于研究人员和临床医生都具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经退行性语音障碍的口语技术进展对于满足临床和技术需求至关重要，因此需要一篇综述来推动该领域的发展。

**Method:** 本文对病理语音检测、自动语音识别、病理语音清晰度增强、清晰度和严重程度评估以及病理语音数据增强方法等领域的最新技术进行了全面综述。

**Result:** 本文全面回顾了病理语音检测、自动语音识别、病理语音清晰度增强、清晰度和严重程度评估以及数据增强等方面的最新方法。它还强调了鲁棒性、隐私和可解释性等关键挑战。

**Conclusion:** 论文最后探讨了有前景的未来方向，包括采用多模态方法和整合大型语言模型，以进一步推进神经退行性语音障碍的语音技术。

> **ai_Abstract:** 本文综述了神经退行性语音障碍的自动语音分析和技术，详细介绍了病理语音检测、识别、增强、评估及数据增强的最新方法。同时，文章指出了鲁棒性、隐私和可解释性等关键挑战，并展望了多模态方法和大型语言模型在未来应用中的潜力。

> **摘要翻译:** 神经退行性语音障碍口语技术的进步对于满足临床和技术需求至关重要。这篇概述性论文对于推动该领域的发展至关重要，因为它全面回顾了病理语音检测、自动语音识别、病理语音清晰度增强、清晰度和严重程度评估以及病理语音数据增强方法等领域的最新技术。它还强调了确保鲁棒性、隐私和可解释性等关键挑战。论文最后探讨了有前景的未来方向，包括采用多模态方法和整合大型语言模型，以进一步推进神经退行性语音障碍的语音技术。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [575] [UniTalker: Conversational Speech-Visual Synthesis](https://arxiv.org/abs/2508.04585)
> *UniTalker: 对话式语音-视觉合成*

*Yifan Hu, Rui Liu, Yi Ren, Xiang Yin, Haizhou Li* | **Category: eess.AS** | **Updated: 2025-08-07**

**Keywords:** 对话语音合成, 语音-视觉合成, 多模态, 说话人脸动画, UniTalker

**Comment:** 

> **TL;DR:** UniTalker是一个统一模型，用于对话式语音-视觉合成，通过多模态感知和渲染生成富有情感的语音和自然的说话人脸动画。

**AI_Comments:** 本文的创新之处在于将对话语音合成（CSS）扩展到对话式语音-视觉合成（CSVS），并通过UniTalker系统实现多模态感知和渲染的统一。通过整合视觉线索，它显著提升了人机交互的自然度和情感表达能力。文中提出的三种优化策略，特别是神经地标编解码器和双模态硬对齐解码，对于确保语音-视觉内容的一致性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 现有对话语音合成（CSS）研究仅限于感知对话上下文中的文本和语音，这限制了其有效性，因为在现实世界的人际交流中，“倾听”和“眼神交流”在情感传达中起着关键作用。此外，仅语音的响应进一步限制了交互体验。为解决这些局限性，本文引入了对话式语音-视觉合成（CSVS）任务。

**Method:** 本文提出了一种名为UniTalker的对话式语音-视觉合成（CSVS）系统，这是一个统一模型，无缝集成了多模态感知和多模态渲染能力。它利用大型语言模型全面理解对话上下文中的多模态线索，包括说话者、文本、语音和说话人脸动画。之后，它采用多任务序列预测，首先推断目标话语的情感，然后生成富有同情心的语音和自然的说话人脸动画。为确保生成的语音-视觉内容在情感、内容和持续时间上保持一致，本文引入了三项关键优化：1）设计专门的神经地标编解码器以标记和重建面部表情序列；2）提出双模态语音-视觉硬对齐解码策略；3）在生成阶段应用情感引导渲染。

**Result:** 全面的客观和主观实验表明，本文模型合成了更富有同情心的语音，并为用户提供了更自然、情感更一致的说话人脸动画。

**Conclusion:** UniTalker通过利用多模态对话上下文并提供连贯的音视频响应，有效扩展了传统对话语音合成（CSS）任务，从而生成更富有同情心和自然的语音和说话人脸动画，显著提升了用户-代理交互体验。

> **ai_Abstract:** UniTalker通过引入对话式语音-视觉合成（CSVS）任务，解决了传统对话语音合成（CSS）的局限性。作为一个统一模型，UniTalker无缝集成了多模态感知和渲染能力，利用大型语言模型全面理解对话上下文中的多模态线索。它通过多任务序列预测推断情感并生成富有同情心的语音和自然的说话人脸动画。为确保内容一致性，模型采用了神经地标编解码器、双模态语音-视觉硬对齐解码策略和情感引导渲染。实验证明UniTalker能生成更富有同情心的语音和更自然、情感一致的说话人脸动画。

> **摘要翻译:** 对话语音合成（CSS）是用户-代理交互领域的一项关键任务，旨在为用户生成更具表现力和同理心的语音。然而，众所周知，“倾听”和“眼神交流”在现实世界的人际交流中对情感传达起着至关重要的作用。现有CSS研究仅限于感知对话上下文中的文本和语音，这限制了其有效性。此外，仅语音的响应进一步限制了交互体验。为了解决这些局限性，我们引入了对话式语音-视觉合成（CSVS）任务，作为传统CSS的扩展。通过利用多模态对话上下文，它为用户提供了连贯的音视频响应。为此，我们开发了一个名为UniTalker的CSVS系统，它是一个统一模型，无缝集成了多模态感知和多模态渲染能力。具体而言，它利用大型语言模型全面理解对话上下文中的多模态线索，包括说话者、文本、语音和说话人脸动画。之后，它采用多任务序列预测，首先推断目标话语的情感，然后生成富有同情心的语音和自然的说话人脸动画。为确保生成的语音-视觉内容在情感、内容和持续时间上保持一致，我们引入了三项关键优化：1）设计专门的神经地标编解码器以标记和重建面部表情序列。2）提出双模态语音-视觉硬对齐解码策略。3）在生成阶段应用情感引导渲染。全面的客观和主观实验表明，我们的模型合成了更富有同情心的语音，并为用户提供了更自然、情感更一致的说话人脸动画。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [581] [Neural Field-Based 3D Surface Reconstruction of Microstructures from Multi-Detector Signals in Scanning Electron Microscopy](https://arxiv.org/abs/2508.04728)
> *基于神经场的扫描电子显微镜多探测器信号微结构三维表面重建*

*Shuo Chen, Yijin Li, Xi Zheng, Guofeng Zhang* | **Category: eess.IV, physics.ins-det** | **Updated: 2025-08-05**

**Keywords:** 扫描电子显微镜, 三维重建, 神经场, 微结构, 自校准

**Comment:** 

> **TL;DR:** NFH-SEM是一种基于神经场的混合扫描电子显微镜三维重建方法，能够从多视图、多探测器二维图像中高精度重建复杂微结构，无需手动校准并自动处理阴影。

**AI_Comments:** NFH-SEM的创新之处在于其采用神经场进行连续三维表示，结合了端到端自校准和自动阴影解耦机制。这有效地克服了现有SEM三维重建方法在处理复杂微结构时面临的离散表示、校准困难和阴影误差等关键挑战，显著提升了重建的精度和鲁棒性，对微观形貌分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的二维扫描电子显微镜（SEM）图像无法直接显示微观样品的三维形貌，且现有三维重建方法在重建复杂微结构时面临离散三维表示的局限性、需要参考样品校准以及阴影引起的梯度误差等挑战。

**Method:** 本文提出了一种名为NFH-SEM的基于神经场的混合SEM三维重建方法。该方法以多视图、多探测器二维SEM图像作为输入，将几何和光度信息融合到连续的神经场表示中。NFH-SEM通过端到端自校准消除了手动校准程序，并在训练期间自动将阴影从SEM图像中分离出来。

**Result:** NFH-SEM在真实和模拟数据集上验证了其有效性。实验结果显示，该方法能够对包括双光子光刻微结构、桃子花粉和碳化硅颗粒表面在内的多样且具有挑战性的样品进行高保真重建，展现了精确的细节和广泛的适用性。

**Conclusion:** NFH-SEM方法能够实现复杂微结构的高精度三维重建，具有精确的细节表现和广泛的适用性。

> **ai_Abstract:** 本文提出了一种名为NFH-SEM的创新性神经场混合扫描电子显微镜三维重建方法。该方法利用多视图、多探测器SEM图像，通过连续神经场表示融合几何和光度信息。NFH-SEM通过端到端自校准消除了手动校准需求，并能自动处理阴影问题，从而实现了对复杂微结构的高保真重建。实验证明，该方法在多种真实和模拟微观样品上表现出色，具有精确的细节捕捉能力和广泛的适用性。

> **摘要翻译:** 扫描电子显微镜（SEM）是科学研究和工业应用中广泛使用的成像设备。传统的二维（2D）SEM图像无法直接显示微观样品的三维（3D）形貌，这促使了SEM三维表面重建方法的发展。然而，由于离散三维表示的局限性、需要参考样品校准以及阴影引起的梯度误差，现有方法在复杂微结构重建方面仍然面临挑战。本文介绍了一种名为NFH-SEM的基于神经场的混合SEM三维重建方法，该方法以多视图、多探测器二维SEM图像作为输入，并将几何和光度信息融合到连续的神经场表示中。NFH-SEM通过端到端自校准消除了手动校准程序，并在训练期间自动将阴影从SEM图像中分离出来，从而实现了复杂微结构的精确重建。我们在真实和模拟数据集上验证了NFH-SEM的有效性。我们的实验显示，该方法能够对包括双光子光刻微结构、桃子花粉和碳化硅颗粒表面在内的多样且具有挑战性的样品进行高保真重建，展现了精确的细节和广泛的适用性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [587] [Super-Resolution of Sentinel-2 Images Using a Geometry-Guided Back-Projection Network with Self-Attention](https://arxiv.org/abs/2508.04729)
> *使用几何引导反向投影网络和自注意力机制的Sentinel-2图像超分辨率*

*Ivan Pereira-Sánchez, Daniel Torres, Francesc Alcover, Bartomeu Garau, Julia Navarro, Catalina Sbert, Joan Duran* | **Category: eess.IV** | **Updated: 2025-08-05**

**Keywords:** 超分辨率, Sentinel-2, 几何引导, 反向投影, 自注意力

**Comment:** 

> **TL;DR:** 本文提出了一种几何引导的超分辨率模型，用于融合Sentinel-2图像的10米和20米波段，并通过引入聚类学习和多头自注意力机制，在城市、乡村和沿海景观数据集上表现优于现有方法。

**AI_Comments:** 该论文的创新点在于提出了一个结合几何引导和自注意力机制的超分辨率模型，专门针对Sentinel-2图像的多分辨率波段融合问题。几何引导图像的引入有助于保留精细结构，而多头自注意力机制则有效捕获了图像的非局部依赖性，提升了融合效果。自建数据集也为评估提供了有益的贡献。

<details>
  <summary>Details</summary>

**Motivation:** Sentinel-2任务提供了10米、20米和60米分辨率的多光谱图像，其中10米波段提供精细结构细节，而20米波段捕获更丰富的光谱信息。为了融合这两种信息，并提高图像分辨率，需要一种有效的超分辨率模型。

**Method:** 本文提出了一种几何引导的超分辨率模型，用于融合Sentinel-2图像的10米和20米波段。该方法引入了一个基于聚类的学习过程，从10米波段生成几何丰富的引导图像。该图像被整合到展开的反向投影架构中，该架构通过多头注意力机制利用图像自相似性，建模跨空间和光谱维度的非局部块基交互。

**Result:** 实验结果表明，该方法优于经典的以及基于深度学习的超分辨率和融合技术。

**Conclusion:** 本文提出的几何引导反向投影网络结合自注意力机制，能够有效融合Sentinel-2图像的不同分辨率波段，并实现卓越的超分辨率性能。

> **ai_Abstract:** 本文提出了一种新颖的几何引导超分辨率模型，用于融合Sentinel-2卫星图像的10米和20米多光谱波段。该模型通过聚类学习从10米波段生成几何引导图像，并将其集成到结合多头自注意力机制的反向投影网络中，以有效利用图像的自相似性和捕获非局部特征。在包含城市、乡村和沿海景观的自建数据集上的实验表明，该方法在超分辨率和波段融合方面优于现有的经典和深度学习方法。

> **摘要翻译:** Sentinel-2任务提供13个波段的多光谱图像，分辨率分别为10米、20米和60米。其中，10米波段提供精细的结构细节，而20米波段捕获更丰富的光谱信息。在本文中，我们提出了一种几何引导的超分辨率模型，用于融合10米和20米波段。我们的方法引入了一种基于聚类的学习过程，从10米波段生成几何丰富的引导图像。该图像被整合到一个展开的反向投影架构中，该架构通过多头注意力机制利用图像自相似性，建模跨空间和光谱维度的非局部块基交互。我们还生成了一个用于评估的数据集，包含三个测试集，包括城市、乡村和沿海景观。实验结果表明，我们的方法优于经典的以及基于深度学习的超分辨率和融合技术。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [593] [Deep Distillation Gradient Preconditioning for Inverse Problems](https://arxiv.org/abs/2508.04832)
> *深度蒸馏梯度预处理用于逆问题*

*Romario Gualdrón-Hurtado, Roman Jacome, Leon Suarez, Laura Galvis, Henry Arguello* | **Category: eess.IV** | **Updated: 2025-08-06**

**Keywords:** 深度蒸馏, 梯度预处理, 逆问题, 知识蒸馏, 非线性预处理

**Comment:** 

> **TL;DR:** 本文提出了一种基于知识蒸馏的非线性梯度预处理方法，通过教师-学生模型改进了病态感知矩阵下逆问题的收敛性和重建质量。

**AI_Comments:** 这项工作通过引入知识蒸馏和非线性预处理，为解决成像逆问题中的病态性提供了一个创新性的视角。它克服了传统线性预处理的局限性，并避免了基于学习的线性预处理可能导致的零空间问题，对于提升复杂成像任务的重建质量和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图像逆问题中，病态的感知矩阵会阻碍算法收敛并降低重建质量，即使使用先进的信号先验也无效。传统线性预处理技术性能有限，而基于学习的线性预处理可能导致零空间解。

**Method:** 本文利用知识蒸馏设计了一个非线性预处理算子。通过梯度匹配，一个使用条件更好的（合成）感知矩阵的教师算法经由一个预处理神经网络来指导一个使用病态感知矩阵的学生算法。

**Result:** 该非线性预处理器在单像素、磁共振和超分辨率成像任务的即插即用FISTA中得到了验证，显示出一致的性能改进和更好的经验收敛性。

**Conclusion:** 通过引入深度蒸馏梯度预处理，可以有效解决逆问题中病态感知矩阵导致的收敛和重建质量问题，从而提升成像逆问题的求解性能。

> **ai_Abstract:** 本文提出了一种新颖的深度蒸馏梯度预处理方法，旨在解决图像逆问题中由病态感知矩阵导致的收敛缓慢和重建质量下降问题。研究通过知识蒸馏设计了一个非线性预处理算子，其中一个教师模型利用条件良好的感知矩阵，通过梯度匹配引导学生模型处理病态感知矩阵。该方法在多种成像任务中验证了其有效性，显著提升了算法性能和收敛速度。

> **摘要翻译:** 图像逆问题通常通过最小化测量一致性和信号先验项来解决。尽管人们对开发高性能先验给予了巨大关注，但即使是最先进的信号先验，当与阻碍收敛并降低重建质量的病态感知矩阵配对时，也可能失去其有效性。在优化理论中，预处理器通过转换梯度更新来改善算法的收敛性。传统的线性预处理技术可以增强收敛性，但其性能因依赖于感知矩阵的结构而受到限制。虽然已经提出了基于学习的线性预处理器，但它们仅针对数据保真度优化，这可能导致感知矩阵零空间中的解。本文采用知识蒸馏来设计一个非线性预处理算子。在我们的方法中，一个使用条件更好的（合成）感知矩阵的教师算法通过梯度匹配，经由一个预处理神经网络来指导一个使用病态感知矩阵的学生算法。我们验证了我们的非线性预处理器在单像素、磁共振和超分辨率成像任务中的即插即用FISTA，显示出一致的性能改进和更好的经验收敛性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [599] [MedMambaLite: Hardware-Aware Mamba for Medical Image Classification](https://arxiv.org/abs/2508.05049)
> *MedMambaLite：面向医学图像分类的硬件感知Mamba模型*

*Romina Aalishah, Mozhgan Navardi, Tinoosh Mohsenin* | **Category: eess.IV** | **Updated: 2025-08-07**

**Keywords:** MedMambaLite, 医学图像分类, 边缘设备, 知识蒸馏, Mamba

**Comment:** 

> **TL;DR:** MedMambaLite是一个硬件感知的Mamba模型，通过知识蒸馏优化，实现了在边缘设备上对医学图像进行高效且准确的分类，显著减少了模型参数并提高了能效。

**AI_Comments:** 该论文的创新之处在于将Mamba架构应用于医学图像领域，并结合硬件感知设计和知识蒸馏技术，显著优化了模型在边缘设备上的部署性能。它成功地在保持高准确率的同时，大幅降低了模型尺寸和能耗，这对于实时医疗诊断和设备端AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** AI驱动的医疗设备需要实时、设备上的推理能力，如生物医学图像分类。然而，在边缘设备上部署深度学习模型面临模型尺寸和计算能力的限制，这使得实现高性能成为挑战。

**Method:** 本文提出了MedMambaLite，一个通过知识蒸馏优化的硬件感知Mamba模型，用于医学图像分类。该方法从一个强大的MedMamba模型开始，整合Mamba结构以进行高效特征提取。通过修改和减少架构中的冗余，使模型在训练和推理时更轻更快。随后，通过减少嵌入维度，将其知识蒸馏到一个更小的学生模型中。

**Result:** 优化后的模型在10个MedMNIST数据集上实现了94.5%的总体准确率。与MedMamba相比，参数量减少了22.8倍。在NVIDIA Jetson Orin Nano上部署时，每次推理的能效达到35.6 GOPS/J，比MedMamba的每次推理能效提高了63%。

**Conclusion:** MedMambaLite模型通过硬件感知设计和知识蒸馏，成功解决了在边缘设备上部署医学图像分类模型的挑战，在保持高准确率的同时，大幅降低了模型复杂度和能耗，使其适用于实时、设备上的医疗应用。

> **ai_Abstract:** MedMambaLite是一个针对边缘设备优化的硬件感知Mamba模型，专为医学图像分类设计。它通过修改原始MedMamba架构并采用知识蒸馏技术，显著减少了模型参数和计算开销。该模型在MedMNIST数据集上实现了94.5%的准确率，并展示了相比基线模型更高的能效，有效解决了在资源受限设备上部署AI模型所面临的挑战。

> **摘要翻译:** AI驱动的医疗设备推动了对实时、设备上推理的需求，例如生物医学图像分类。深度学习模型在边缘设备上的部署现在被用于医学图像中的异常检测和分类等应用。然而，由于模型尺寸和计算能力的限制，在边缘设备上实现这种性能水平仍然具有挑战性。为了解决这个问题，我们提出了MedMambaLite，一个通过知识蒸馏优化的硬件感知Mamba模型，用于医学图像分类。我们从一个强大的MedMamba模型开始，整合了Mamba结构以实现医学图像中高效的特征提取。通过修改和减少架构中的冗余，我们使模型在训练和推理时更轻、更快。然后，通过减少嵌入维度，我们将其知识蒸馏到一个更小的学生模型中。优化后的模型在10个MedMNIST数据集上实现了94.5%的总体准确率。与MedMamba相比，它还将参数减少了22.8倍。在NVIDIA Jetson Orin Nano上的部署实现了每次推理35.6 GOPS/J的能耗。这比MedMamba在每次推理能耗上提高了63%。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [605] [MM2CT: MR-to-CT translation for multi-modal image fusion with mamba](https://arxiv.org/abs/2508.05476)
> *MM2CT：基于Mamba的多模态图像融合的MR到CT转换*

*Chaohui Gong, Zhiying Wu, Zisheng Huang, Gaofeng Meng, Zhen Lei, Hongbin Liu* | **Category: eess.IV** | **Updated: 2025-08-07**

**Keywords:** MR-to-CT转换, 多模态图像融合, Mamba, 医学图像合成, 深度学习

**Comment:** 

> **TL;DR:** MM2CT是一种利用Mamba框架进行多模态T1/T2 MRI到CT图像转换的方法，解决了现有方法的局限性，并在公开数据集上达到了SOTA性能。

**AI_Comments:** 该论文的创新点在于首次将Mamba框架应用于多模态医学图像合成，并有效地将其应用于MR到CT的转换，解决了传统CNN和Transformer的局限性。其利用多模态MRI数据进行图像融合也增加了方法的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有MR到CT转换方法主要基于单模态MR，多模态融合研究有限。MR到CT转换本身具有消除CT辐射暴露和减轻患者运动伪影的优势。

**Method:** 本文提出MM2CT方法，利用多模态T1和T2加权MRI数据进行MR到CT转换。该方法引入了一个创新的基于Mamba的框架，旨在克服CNN局部感受野有限和Transformer计算复杂度高的问题，同时保持长距离依赖建模能力并实现多模态MR特征整合。此外，MM2CT还结合了动态局部卷积模块和动态增强模块以改进MRI到CT的合成效果。

**Result:** 在公开的骨盆数据集上进行的实验表明，MM2CT在结构相似性指数（SSIM）和峰值信噪比（PSNR）方面达到了最先进的性能。

**Conclusion:** MM2CT通过利用多模态MRI数据和创新的Mamba框架，实现了高质量的MR到CT图像转换，并达到了领先的性能。

> **ai_Abstract:** 本文提出了一种名为MM2CT的多模态MR到CT图像转换方法，旨在解决现有单模态转换的局限性。MM2CT利用多模态T1和T2加权MRI数据，并引入了基于Mamba的框架，该框架能有效处理长距离依赖并整合多模态特征，同时避免了CNN和Transformer的缺点。通过结合动态局部卷积和动态增强模块，MM2CT在公开骨盆数据集上表现出最先进的性能。

> **摘要翻译:** 磁共振（MR）到计算机断层扫描（CT）转换具有显著优势，包括消除CT扫描相关的辐射暴露和减轻患者运动引起的成像伪影。现有方法基于单模态MR到CT转换，探索多模态融合的研究有限。为解决这一局限性，我们引入了多模态MR到CT（MM2CT）转换方法，该方法利用多模态T1和T2加权MRI数据，是一个创新的基于Mamba的多模态医学图像合成框架。Mamba有效克服了CNN中有限的局部感受野和Transformer中高计算复杂度的问题。MM2CT利用这一优势，在实现多模态MR特征整合的同时，保持了长距离依赖建模能力。此外，我们还结合了动态局部卷积模块和动态增强模块以改进MRI到CT的合成。在公开的骨盆数据集上的实验表明，MM2CT在结构相似性指数（SSIM）和峰值信噪比（PSNR）方面达到了最先进的性能。我们的代码已在https://github.com/Gots-ch/MM2CT 公开。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [617] [Adaptive k-space Radial Sampling for Cardiac MRI with Reinforcement Learning](https://arxiv.org/abs/2508.04727)
> *基于强化学习的心脏MRI自适应k空间径向采样*

*Ruru Xu, Ilkay Oksuz* | **Category: eess.IV, q-bio.QM, q-bio.TO** | **Updated: 2025-08-05**

**Keywords:** 强化学习, 径向采样, 心脏MRI, k空间优化, 图像重建

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的强化学习框架，用于优化心脏MRI中的径向k空间采样，以提高图像重建质量。

**AI_Comments:** 这项工作通过将强化学习应用于非笛卡尔（径向）k空间采样优化，填补了现有研究的空白，特别是针对心脏MRI。其创新点在于结合了双分支架构、交叉注意力融合以及解剖学感知的奖励设计，这些都旨在更有效地平衡图像质量和采集速度。这项研究为加速MRI提供了新的优化思路，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 加速磁共振成像（MRI）需要仔细优化k空间采样模式，以平衡采集速度和图像质量。虽然深度学习在优化笛卡尔采样方面取得了进展，但强化学习（RL）在非笛卡尔轨迹优化方面的潜力仍未得到充分探索。

**Method:** 本文提出了一种新颖的RL框架，用于优化心脏MRI中的径向采样轨迹。该方法采用双分支架构，联合处理k空间和图像域信息，并结合交叉注意力融合机制，促进域间有效信息交换。该框架采用解剖学感知奖励设计和黄金比例采样策略，以确保均匀的k空间覆盖，同时保留心脏结构细节。

**Result:** 实验结果表明，该方法能够有效地学习多种加速因子下的最优径向采样策略，与传统方法相比，实现了更高的重建质量。

**Conclusion:** 本文提出的基于强化学习的框架能够有效地优化心脏MRI的径向采样策略，从而在加速采集的同时提高图像重建质量。

> **ai_Abstract:** 本文提出了一种新颖的强化学习（RL）框架，用于优化心脏MRI中的径向k空间采样轨迹。该框架采用双分支架构处理k空间和图像域信息，并引入交叉注意力融合机制。结合解剖学感知奖励设计和黄金比例采样策略，该方法旨在在加速采集的同时，确保k空间均匀覆盖并保留心脏结构细节。实验证明，该方法能有效学习最优采样策略，显著提高重建图像质量。

> **摘要翻译:** 加速磁共振成像（MRI）需要仔细优化k空间采样模式，以平衡采集速度和图像质量。虽然深度学习的最新进展在优化笛卡尔采样方面显示出前景，但强化学习（RL）在非笛卡尔轨迹优化方面的潜力仍未得到充分探索。在这项工作中，我们提出了一种新颖的RL框架，用于优化心脏MRI中的径向采样轨迹。我们的方法具有双分支架构，联合处理k空间和图像域信息，并结合交叉注意力融合机制，以促进域间有效的​​信息交换。该框架采用解剖学感知奖励设计和黄金比例采样策略，以确保均匀的k空间覆盖，同时保留心脏结构细节。实验结果表明，我们的方法能够有效地学习多种加速因子下的最优径向采样策略，与传统方法相比，实现了更高的重建质量。代码已提供：https://github.com/Ruru-Xu/RL-kspace-Radial-Sampling

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [623] [Constructed Realities? Technical and Contextual Anomalies in a High-Profile Image](https://arxiv.org/abs/2507.12237)
> *构建的现实？高知名度图像中的技术与语境异常*

*Matthias Wjst* | **Category: eess.IV** | **Updated: 2025-08-06**

**Keywords:** 法证评估, 数字合成, 图像真实性, 技术异常, 语境异常

**Comment:** 

> **TL;DR:** 本研究对一张备受关注的照片进行了法证评估，发现其中存在技术和语境异常，暗示该图像可能经过数字合成，而非未经修改的快照。

**AI_Comments:** 这项研究的创新之处在于其采用法证分析方法来评估高知名度图像的真实性，特别是在缺乏原始证据的情况下，通过分析技术和语境异常来推断图像的潜在修改。其重要性在于揭示了数字时代图像传播中可能存在的操纵问题，以及在法律和公共领域中，图像的真实性可能面临的挑战。该研究的局限性在于无法获得原始底片和审计追踪，这限制了得出决定性结论的能力，突显了在数字取证中获取原始数据的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在对一张在公众讨论和法律叙事中发挥关键作用的广为流传的照片进行法证评估，以探究其真实性。

**Method:** 通过分析多个已发布的版本，识别了光线、姿势和身体互动方面的不一致性。

**Result:** 发现多处不一致，包括光线、姿势和身体互动方面的异常，这些更符合数字合成的特征，而非未经修改的快照。

**Conclusion:** 尽管缺乏原始底片和可验证的审计追踪，无法得出明确结论，但技术和语境异常表明该图像可能是经过故意构建的。在没有额外证据的情况下，这张照片仍然是一个未解决但具有象征意义的复杂故事片段。

> **ai_Abstract:** 本研究对一张备受关注的安德鲁王子、弗吉尼亚·朱弗雷和吉斯莱恩·马克斯韦尔的照片进行了法证分析。通过比对不同版本，研究发现光线、姿势和互动存在多处不一致，这些异常迹象与数字合成而非原始照片更为吻合。尽管缺乏原始底片和审计追踪，无法得出最终结论，但技术和语境上的异常强烈暗示该图像可能经过人为构建。该照片在一个关于虐待、记忆和真相的复杂叙事中，仍是一个未解但具有重要象征意义的碎片。

> **摘要翻译:** 这项研究对一张广为流传的、涉及安德鲁王子、弗吉尼亚·朱弗雷和吉斯莱恩·马克斯韦尔的照片进行了法证评估——这张照片在公众讨论和法律叙事中发挥了关键作用。通过对多个已发布版本的分析，识别出若干不一致之处，包括光线、姿势和身体互动方面的异常，这些更符合数字合成而非未经修改的快照的特征。虽然缺乏原始底片和可验证的审计追踪排除了得出明确结论的可能性，但技术和语境异常表明该图像可能经过了故意构建。然而，在没有额外证据的情况下，这张照片在一个关于虐待、记忆和有争议的真相的复杂故事中，仍然是一个未解决但具有象征意义的片段。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [480] [Sub- μ W Battery-Less and Oscillator-Less Wi-Fi Backscattering Transmitter Reusing RF Signal for Harvesting, Communications, and Motion Detection](https://arxiv.org/abs/2508.05479)
> *亚微瓦级无电池无振荡器Wi-Fi反向散射发射器，复用射频信号用于能量收集、通信和运动检测*

*Marco Privitera, Andrea Ballo, Karim Ali Ahmed, Alfio Dario Grasso, Massimo Alioto* | **Category: eess.SP, eess.SY** | **Updated: 2025-08-07**

**Keywords:** Wi-Fi反向散射, 无电池, 无振荡器, 射频能量收集, 运动检测

**Comment:** 

> **TL;DR:** 本文提出一种亚微瓦级Wi-Fi反向散射发射器，通过复用入射射频信号实现能量收集、通信和运动检测，并首次无需电池和本地振荡器。

**AI_Comments:** 这项研究的创新之处在于成功地消除了Wi-Fi反向散射发射器中的电池和本地振荡器，极大地降低了功耗并实现了前所未有的微型化。通过复用射频信号进行能量收集、通信和传感，该技术为物联网（IoT）设备和无源传感应用开辟了新的可能性，尤其是在低功耗和低成本部署方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在实现前所未有的微型化、普及性、无限设备寿命以及低制造成本和维护成本，通过去除电池和任何片外运动传感器。同时，首次打破了Wi-Fi发射器的微瓦功耗壁垒。

**Method:** 提出了一种亚微瓦功耗的802.11b反向散射发射器，通过二次互调双音入射波来提取频率，从而消除了本地振荡器。通过使用收集到的电压作为接收信号强度（RSS）的代理，实现了位置/运动传感。

**Result:** 实现了亚微瓦级功耗，并将累积能量收集/传输/传感灵敏度降至Pmin -19 dBm。成功实现了位置/运动传感，允许感测芯片相对于共享于室内区域中标签的音调发生器的位置。

**Conclusion:** 本文成功展示了一种亚微瓦级、无电池、无振荡器的Wi-Fi反向散射发射器，它能够复用入射射频信号进行能量收集、通信和位置/运动传感，从而在微型化、功耗和成本方面取得了显著突破。

> **ai_Abstract:** 本文介绍了一种创新的亚微瓦级Wi-Fi反向散射发射器，它无需电池和本地振荡器。该发射器通过复用相同的入射射频信号，同时实现能量收集、802.11b通信以及位置/运动传感。这种设计显著降低了功耗，克服了Wi-Fi发射器的微瓦功耗限制，并支持设备的极致微型化、低成本和无限寿命。

> **摘要翻译:** 在本文中，提出了一种亚微瓦功耗的802.11b反向散射发射器，以实现对相同入射波的三个目的复用：射频能量收集、反向散射通信和位置/运动传感。去除电池和任何片外运动传感器（例如MEMS）实现了前所未有的微型化和普及性，无限的设备寿命，以及低制造成本和维护成本。通过消除本地振荡器，首次打破了Wi-Fi发射器的微瓦功耗壁垒，这是通过双音入射波的二次互调来提取其频率实现的。双音方案还将累积能量收集/传输/传感灵敏度降低至Pmin -19 dBm。位置/运动传感通过使用收集到的电压作为接收信号强度（RSS）的代理来实现，从而允许感测芯片相对于室内区域中标签之间共享的音调发生器的位置。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [514] [Skew-Induced Insertion Loss Deviation (SILD) and FOM_SILD: Metrics for Quantifying P/N Skew Effects in High-Speed Channels](https://arxiv.org/abs/2506.15105)
> *偏斜引起插入损耗偏差 (SILD) 和 FOM_SILD：量化高速通道中 P/N 偏斜效应的度量*

*David Nozadze, Zurab Kiguradze, Amendra Koul, Mike Sapozhnikov* | **Category: eess.SP, eess.SY** | **Updated: 2025-08-07**

**Keywords:** P/N偏斜, SILD, FOM_SILD, 高速互连, SerDes

**Comment:** 

> **TL;DR:** 本文引入了SILD和FOM_SILD两个新度量，用于量化高速互连中的P/N偏斜效应，并显示出与误码率的强相关性。

**AI_Comments:** 本文通过引入新颖的、分析推导出的度量，解决了高速数据传输中的一个关键问题。通过S参数测量和仿真中BER相关性的验证，突出了SILD和FOM_SILD在设计和分析下一代互连方面的实际适用性和重要性。其创新之处在于提供了一种量化且全面的方法来评估P/N偏斜，这是传统方法所缺乏的。

<details>
  <summary>Details</summary>

**Motivation:** 由于人工智能工作负载和数据中心需求的增长，需要超过200 Gb/s的超高速互连。然而，即使是几皮秒的P/N偏斜也会降低串行器-解串器(SerDes)的性能，而传统方法无法有效捕捉其影响。

**Method:** 开发了两个新的分析度量：偏斜引起插入损耗偏差 (SILD) 及其互补的品质因数 (FOM_SILD)，用于评估P/N偏斜效应。

**Result:** 测量的S参数证实了FOM_SILD的互易性。224G PAM4 SerDes的仿真结果显示与误码率(BER)趋势具有很强的相关性。

**Conclusion:** 该方法为分析下一代超高速互连中的偏斜提供了一个强大的框架。

> **ai_Abstract:** 由于对超高速互连（超过200 Gb/s）的需求日益增长，P/N偏斜成为SerDes性能的关键限制因素。本文提出了两种新颖的分析度量：偏斜引起插入损耗偏差 (SILD) 和品质因数 (FOM_SILD)，以量化P/N偏斜效应。实验性的S参数测量验证了FOM_SILD的互易性，仿真结果表明其与224G PAM4 SerDes中的误码率(BER)具有很强的相关性。这一新框架为未来高速系统中的偏斜分析提供了强大的解决方案。

> **摘要翻译:** 人工智能工作负载的兴起和数据中心需求的增长推动了对超过 200 Gb/s 的超高速互连的需求。随着单位间隔 (UI) 的缩小，即使是几皮秒的 P/N 偏斜也会降低串行器-解串器 (SerDes) 的性能。传统的偏斜量化方法未能充分捕捉其影响。我们引入了两个新度量：1) 偏斜引起插入损耗偏差 (SILD) 和 2) 其互补的品质因数 (FOM_SILD)，它们经过分析开发以评估 P/N 偏斜效应。测量的 S 参数证实了 FOM_SILD 的互易性，而 224G PAM4 SerDes 的仿真结果显示与误码率 (BER) 趋势具有很强的相关性。这种方法为分析下一代超高速互连中的偏斜提供了一个强大的框架。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [629] [Real-Time Doppler and Ionospheric Dispersion Correction Techniques for Arbitrary Waveforms Utilizing GPU Compute](https://arxiv.org/abs/2508.04951)
> *利用GPU计算的实时多普勒和电离层色散校正技术，用于任意波形*

*Daniel J. Vickers, A. H. Mack, Idahosa A. Osaretin* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 多普勒校正, 电离层色散, GPU计算, 实时处理, 任意波形

**Comment:** 

> **TL;DR:** 本文提出利用GPU对任意波形进行实时多普勒和电离层色散校正，采用FFT和sinc插值方法，实现了高精度和系统灵活性。

**AI_Comments:** 本文创新性地将通用GPU应用于雷达信号处理中的实时多普勒和电离层色散校正，摆脱了对专用硬件的依赖，显著提高了系统灵活性和波形适应性。这对于软件定义无线电系统尤其重要，为未来雷达系统设计提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的雷达数字信号处理中，电离层畸变和多普勒色散校正需要专用雷达硬件或模拟解决方案，这些方案限制了波形灵活性并增加了系统复杂性。随着现代通用计算系统的进步，使用非雷达专用高性能计算实现实时数字信号处理成为可能。

**Method:** 本文分析了用于雷达数字信号处理中任意波形的通用多普勒和电离层校正算法，并重点考虑了使用GPU硬件进行高效软件实现。具体提出了两种色散校正算法：一种是用于电离层色散的基于FFT的方法，另一种是用于多普勒色散的通过sinc插值的数值插值方法。

**Result:** 所提出的两种算法在精度上与波形特定的分析方法相当，并且能够在单个NVIDIA H100 GPU上实时执行。这些方法与波形无关，直接应用于采样数据，显著提高了系统灵活性，并易于集成到现有软件定义无线电系统中。

**Conclusion:** 本文提出的基于GPU的实时多普勒和电离层色散校正方法，通过FFT和sinc插值实现了高精度和波形无关的处理，为雷达数字信号处理提供了更灵活、更易于集成且无需专用硬件的解决方案。

> **ai_Abstract:** 本研究探讨了利用GPU对雷达任意波形进行实时多普勒和电离层色散校正的技术。论文分析了通用算法，并提出了两种高效的软件实现方法：基于FFT的电离层色散校正和基于sinc插值的多普勒色散校正。实验证明，这些算法在单个NVIDIA H100 GPU上实现了与专用分析方法相当的精度和实时性能，并且具有波形无关性和高系统灵活性，易于集成到现有软件定义无线电系统中。

> **摘要翻译:** 雷达数字信号处理的普遍要求是电离层畸变和多普勒色散校正，这在历史上需要雷达专用硬件才能实时实现。尽管模拟解决方案计算效率高，但它们通常带有系统设计缺陷，限制了波形灵活性，并可能导致系统复杂性整体增加。随着现代通用计算系统的改进，使用非雷达专用高性能计算实现实时数字信号处理变得更具可行性。在本文中，我们对用于雷达数字信号处理的任意波形的通用多普勒和电离层校正算法进行了分析。我们还考虑了在软件中高效实现这些算法的因素，特别是使用GPU硬件。这项分析包括性能指标，例如执行时间和纠错精度。我们还为雷达信号处理中的应用提供了建议。我们确定了两种色散校正算法：一种是用于电离层色散的基于FFT的方法，另一种是用于多普勒色散的通过sinc插值的数值插值方法。这两种算法都能够补偿与波形特定分析方法精度相当的色散，并且能够在单个NVIDIA H100 GPU上实时执行。这些方法与波形无关，直接应用于采样数据，提高了系统灵活性，并使其易于集成到现有软件定义无线电系统中。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [635] [Localized Kernel Methods for Signal Processing](https://arxiv.org/abs/2508.04978)
> *信号处理中的局部核方法*

*Sippanon Kitimoon* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 局部核, 信号处理, 参数恢复, 指数模型, 线性啁啾

**Comment:** 

> **TL;DR:** 本论文提出了两种基于局部核的信号处理方法，用于在噪声条件下进行参数恢复，分别解决了多维指数模型中的频率和幅度估计以及线性啁啾分量的分离问题，且无需子空间分解或稀疏性正则化。

**AI_Comments:** 本文的创新点在于提出了两种不依赖传统子空间分解或稀疏性正则化的信号处理方法，而是利用了局部核和高效的FFT实现。这使得它们在低信噪比条件下表现出色，尤其是在多维指数模型估计和线性啁啾分离方面。其无需先验知识（如分量数量）和在极低信噪比下的恢复能力是其重要优势。潜在的局限性可能在于局部核的设计复杂性或其对特定信号类型的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 在噪声条件下进行参数恢复是一个挑战，尤其是在多维指数模型和线性啁啾分量分离方面。传统方法如MUSIC和ESPRIT在低信噪比下可能表现不佳，且许多方法需要子空间分解或稀疏性正则化。

**Method:** 第一种方法：利用局部三角多项式核检测多变量频率，然后进行详细的参数估计。对于多变量情况，开发了逐坐标投影和配准方法。第二种方法：使用局部核构建信号分离算子（SSO）的变体，通过基于FFT的滤波获得瞬时频率估计，然后进行聚类和分段线性回归。两种方法都基于局部核和高效的FFT实现，无需子空间分解或稀疏性正则化。

**Result:** 第一种方法：在单变量情况下，在低信噪比下优于MUSIC和ESPRIT。在多变量情况下，使用显著更少的样本实现了高恢复精度。第二种方法：无需预先知道分量数量，能够以低至-30 dB的信噪比恢复相交和不连续的啁啾。实验结果证实了所提出方法在各种模拟数据条件下的鲁棒性和可行性。

**Conclusion:** 本论文提出的两种基于局部核的信号处理方法在噪声条件下表现出强大的参数恢复能力，特别是在多维指数模型估计和线性啁啾分离方面。这些方法无需子空间分解或稀疏性正则化，且具有高效的FFT实现和良好的鲁棒性。

> **ai_Abstract:** 本学位论文提出了两种创新的信号处理方法，均利用专门设计的局部核在噪声环境下进行参数恢复。第一种方法针对多维指数模型的频率和幅度估计，通过局部三角多项式核和逐坐标投影与配准实现，在低信噪比下表现优于传统方法，并显著减少样本需求。第二种方法专注于从时间局部信号段中分离线性啁啾分量，通过构建局部核的信号分离算子变体，结合FFT滤波、聚类和分段线性回归，即使在极低信噪比下也能有效工作，且无需先验知识。这两种方法均不依赖子空间分解或稀疏性正则化，具有高效的FFT实现和良好的鲁棒性。

> **摘要翻译:** 本学位论文提出了两种使用专门设计的局部核的信号处理方法，用于在噪声条件下进行参数恢复。第一种方法解决了多维指数模型中频率和幅度的估计问题。它利用局部三角多项式核来检测多变量频率，然后进行更详细的参数估计。我们将我们的方法与MUSIC和ESPRIT进行了比较，它们是广泛用于估计指数信号参数的经典基于子空间算法。在单变量情况下，该方法在低信噪比下优于MUSIC和ESPRIT。对于多变量情况，我们开发了一种逐坐标投影和配准方法，该方法使用比其他方法显著更少的样本实现了高恢复精度。
第二种方法侧重于从时间局部信号段中分离线性啁啾分量。使用局部核构建了信号分离算子（SSO）的一种变体。通过基于FFT的滤波获得瞬时频率估计，然后进行聚类并进行分段线性回归拟合。该方法在不需要预先知道分量数量的情况下运行，并显示出能够在低至-30 dB的信噪比下恢复相交和不连续的啁啾。
两种方法都共享基于局部核和高效FFT实现的思想，并且都不需要子空间分解或稀疏性正则化。实验结果证实了所提出的方法在一系列模拟数据条件下的鲁棒性和可行性。潜在的扩展包括应用于非线性啁啾、自适应核设计以及使用提取特征进行信号分类。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [641] [Power-Constrained and Quantized MIMO-RSMA Systems with Imperfect CSIT: Joint Precoding, Antenna Selection, and Power Control](https://arxiv.org/abs/2508.05080)
> *功率受限和量化MIMO-RSMA系统在不完美CSIT下的联合预编码、天线选择和功率控制*

*Jiwon Sung, Seokjun Park, Jinseok Choi* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** MIMO-RSMA, 联合优化, 功率控制, 不完美CSIT, 量化DAC

**Comment:** 

> **TL;DR:** 针对功率受限、量化MIMO-RSMA系统在不完美CSIT下的问题，提出了一种联合预编码、天线选择和功率控制算法，并发现中等分辨率DACs可能比低分辨率DACs更具功率效率。

**AI_Comments:** 该论文通过联合优化预编码、天线选择和功率控制，在实际约束（功率预算、不完美CSIT、量化DAC）下解决了无线通信中的复杂问题。关于中等分辨率DACs在特定条件下比低分辨率DACs更具功率效率的发现是一个重要的见解，这挑战了通常认为低分辨率总是意味着低功耗的假设。问题分解和近似技术的使用使得复杂的优化问题变得可处理。

<details>
  <summary>Details</summary>

**Motivation:** 旨在充分利用基站的可用功率，解决下行多用户MIMO RSMA系统中的和谱效率最大化问题。

**Method:** 提出了一个针对基站总功率预算的联合预编码、天线选择和发射功率控制算法。针对具有任意分辨率数模转换器（DACs）的下行多用户MIMO RSMA系统，建立了和谱效率（SE）最大化问题。通过使用条件平均速率方法定义遍历和谱效率来处理不完美的发射端信道状态信息（CSIT），并使用近似技术使问题更易于处理，从而重新公式化了问题。将问题分解为预编码方向和功率控制子问题，通过识别一个优越的拉格朗日驻点来解决预编码方向子问题，并使用梯度下降法解决功率控制子问题。还提出了一种更适用于大规模MIMO系统的复杂度降低方法。

**Result:** 仿真结果不仅验证了所提出的算法，而且揭示了当充分利用基站的功率预算时，8-11比特的中等分辨率DAC实际上可能比低分辨率DAC更具功率效率。

**Conclusion:** 在充分利用基站功率预算时，中等分辨率DACs（8-11比特）可能比低分辨率DACs更具功率效率。

> **ai_Abstract:** 本文提出了一种针对功率受限和量化MIMO-RSMA系统在不完美CSIT下的联合预编码、天线选择和功率控制算法。通过将和谱效率最大化问题重新公式化并分解为子问题，利用拉格朗日驻点和梯度下降法进行求解。研究结果表明，所提出的算法有效，并且在中等分辨率DAC（8-11比特）下，当充分利用基站功率预算时，其功率效率可能优于低分辨率DAC。

> **摘要翻译:** 为了充分利用基站（BS）的可用功率，我们提出了一种针对基站总功率预算的联合预编码、天线选择和发射功率控制算法。我们针对具有任意分辨率数模转换器（DACs）的下行多用户多输入多输出（MIMO）速率分裂多址（RSMA）系统，建立了和谱效率（SE）最大化问题。我们通过使用条件平均速率方法定义遍历和谱效率来处理不完美的发射端信道状态信息（CSIT），并使用近似技术使问题更易于处理，从而重新公式化了问题。然后，我们将问题分解为预编码方向和功率控制子问题。我们通过识别一个优越的拉格朗日驻点来解决预编码方向子问题，并使用梯度下降法解决功率控制子问题。我们还提出了一种更适用于大规模MIMO系统的复杂度降低方法。仿真结果不仅验证了所提出的算法，而且揭示了当充分利用基站的功率预算时，8-11比特的中等分辨率DAC实际上可能比低分辨率DAC更具功率效率。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [647] [Digital Twin Channel-Aided CSI Prediction: A Environment-based Subspace Extraction Approach for Achieving Low Overhead and Robustness](https://arxiv.org/abs/2508.05142)
> *数字孪生信道辅助的CSI预测：一种基于环境的子空间提取方法，实现低开销和鲁棒性*

*Yichen Cai, Jianhua Zhang, Li Yu, Zhen Zhang, Yuxiang Zhang, Lianzheng Shi, Yuelong Qiu* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 数字孪生信道, CSI预测, 环境子空间基, 6G通信, 低开销

**Comment:** 

> **TL;DR:** 该研究提出了一种基于环境特定信道子空间基（EB）的数字孪生信道（DTC）辅助的部分到整体信道状态信息（CSI）预测方法，旨在降低6G通信系统的开销并提高鲁棒性。

**AI_Comments:** 该论文的创新点在于将数字孪生技术与信道状态信息（CSI）预测相结合，并引入了环境特定信道子空间基（EB）作为先验信息，有效降低了信道预测的开销并增强了鲁棒性。这种基于环境信息的方法为6G通信中的高效CSI获取提供了新思路，尤其在复杂电磁环境中具有重要应用潜力。其在低信噪比和低导频开销下的优异性能，以及对干扰和定位误差的容忍度，是其突出优势。

<details>
  <summary>Details</summary>

**Motivation:** 为满足第六代（6G）移动通信系统在复杂场景下对鲁棒和高速通信的需求，基于感知和人工智能（AI）的数字孪生信道（DTC）技术成为一种有前景的降低系统开销的方法。

**Method:** 本研究提出了一种环境特定信道子空间基（EB）辅助的部分到整体信道状态信息（CSI）预测方法（EB-P2WCP），以实现DTC驱动的低开销信道预测。具体而言，EB用于表征电磁环境的静态特性，其从数字孪生图中提取，作为预测任务的环境先验信息。然后，将EB与实时估计的局部CSI融合，以预测当前和未来时间实例的整个空间-频率域信道。为此，设计了一个基于EB的部分到整体CSI预测网络（EB-P2WNet），以在各种复杂场景下实现鲁棒的信道预测方案。

**Result:** 仿真结果表明，在低信噪比和低导频比条件下，引入EB带来了显著效益，导频开销减少高达50%。此外，所提出的方法对多用户干扰保持鲁棒性，在3米定位误差下，NMSE仅增加0.5 dB，并在1.3毫秒内预测下一个信道相干时间的CSI。

**Conclusion:** 本研究提出的基于环境特定信道子空间基（EB）的数字孪生信道（DTC）辅助的CSI预测方法，在降低导频开销、增强对多用户干扰的鲁棒性以及实现快速CSI预测方面表现出色，为6G通信系统在复杂场景下的高效运行提供了有效方案。

> **ai_Abstract:** 本研究提出了一种基于环境特定信道子空间基（EB）的数字孪生信道（DTC）辅助的部分到整体信道状态信息（CSI）预测方法（EB-P2WCP），旨在降低第六代（6G）移动通信系统的开销并提高鲁棒性。该方法利用从数字孪生图提取的EB作为环境先验信息，并将其与实时局部CSI融合，通过EB-P2WNet预测整个空间-频率域信道。仿真结果显示，该方法在低信噪比和低导频比下能显著降低导频开销（高达50%），并对多用户干扰和定位误差表现出良好的鲁棒性，同时能快速预测CSI。

> **摘要翻译:** 为了满足第六代（6G）移动通信系统在复杂场景下对鲁棒和高速通信的需求，基于感知和人工智能（AI）的数字孪生信道（DTC）技术成为一种有前景的降低系统开销的方法。本文提出了一种环境特定信道子空间基（EB）辅助的部分到整体信道状态信息（CSI）预测方法（EB-P2WCP），以实现DTC驱动的低开销信道预测。具体而言，EB用于表征电磁环境的静态特性，其从数字孪生图中提取，作为预测任务的环境先验信息。然后，我们将EB与实时估计的局部CSI融合，以预测当前和未来时间实例的整个空间-频率域信道。为此，设计了一个基于EB的部分到整体CSI预测网络（EB-P2WNet），以在各种复杂场景下实现鲁棒的信道预测方案。仿真结果表明，引入EB在低信噪比和低导频比条件下提供了显著效益，实现了高达50%的导频开销减少。此外，所提出的方法对多用户干扰保持鲁棒性，在3米定位误差下，NMSE仅增加0.5 dB，并在1.3毫秒内预测下一个信道相干时间的CSI。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [653] [Optimization of Liquid Lens-based Imaging Receiver for MIMO VLC Systems](https://arxiv.org/abs/2508.05204)
> *MIMO可见光通信系统中基于液体透镜的成像接收机优化*

*Kapila W. S. Palitharathna, Christodoulos Skouroumounis, Ioannis Krikidis* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 液体透镜, MIMO可见光通信, 误码率, 空间相关性, 动态调整

**Comment:** 

> **TL;DR:** 本文提出一种基于液体透镜的成像接收机用于MIMO可见光通信系统，通过动态调整透镜参数，有效降低信道空间相关性，显著提升误码率性能，尤其在动态接收机方向变化下优于传统静态透镜。

**AI_Comments:** 这篇论文的创新点在于将液体透镜引入MIMO可见光通信系统，利用其动态可调的特性来解决传统静态透镜在动态环境下的性能瓶颈。通过降低信道空间相关性来优化误码率是一个重要的贡献。这种自适应的接收机设计对于提升未来移动VLC系统的鲁棒性和性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统静态透镜在动态条件下（如用户移动和随机接收机方向）的适应性不足，导致MIMO可见光通信系统中信道空间相关性较高，限制了误码率性能。

**Method:** 提出一种基于液体透镜的成像接收机用于MIMO可见光通信系统。通过动态调整液体透镜的焦距和方向角来降低MIMO信道增益之间的空间相关性。开发了精确的数学框架来建模所提出系统的信道增益，并建立了一个优化问题以最小化误码率。针对复杂信道模型，引入了两种透镜调整方案：CLS方案和VULO方案。

**Result:** 数值结果表明，所提出的基于液体透镜的系统在各种随机接收机方向条件下，比传统基于静态透镜的接收机提供了显著的误码率改进。具体来说，在随机接收机方向方差为10°时，误码率从4×10^-2提高到5×10^-4。

**Conclusion:** 基于液体透镜的成像接收机通过动态调整透镜参数，能够有效降低MIMO可见光通信系统的信道空间相关性，从而在动态环境下显著提高误码率性能，超越了传统静态透镜方案。

> **ai_Abstract:** 本文提出了一种用于MIMO可见光通信系统的新型基于液体透镜的成像接收机。该系统通过动态调整液体透镜的焦距和方向角，有效降低了MIMO信道增益的空间相关性，从而显著提升了误码率性能。研究建立了精确的信道增益数学模型并提出了优化问题，并针对模型复杂性引入了CLS和VULO两种透镜调整方案。数值结果验证了该系统在动态随机接收机方向条件下，相比传统静态透镜接收机，能带来显著的误码率改善，例如在10°方向方差下，误码率从4×10^-2降至5×10^-4。

> **摘要翻译:** 在本文中，提出了一种基于液体透镜的成像接收机，用于多输入多输出（MIMO）可见光通信（VLC）系统。通过动态调整液体透镜的焦距和方向角，可以降低MIMO信道增益之间的空间相关性，从而提高误码率（BER）性能。与静态透镜不同，液体透镜在动态条件下（包括用户移动性和随机接收机方向）具有适应性。开发了一个精确的数学框架来建模所提出系统的信道增益，并建立了一个优化问题以最小化其BER。由于所得信道模型的复杂性，引入了两种透镜调整方案，即（i）CLS方案和（ii）VULO方案。数值结果表明，在各种随机接收机方向条件下，所提出的基于液体透镜的系统比传统的基于静态透镜的接收机提供了显著的BER改进。具体来说，在随机接收机方向方差为10°时，通过采用所提出的液体透镜，BER从4×10^-2提高到5×10^-4。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [659] [Deep Learning Based Dynamic Environment Reconstruction for Vehicular ISAC Scenarios](https://arxiv.org/abs/2508.05226)
> *基于深度学习的车载ISAC场景动态环境重建*

*Junzhe Song, Ruisi He, Mi Yang, Zhengyu Zhang, Bingcheng Liu, Jiahui Han, Haoxiang Zhang, Bo Ai* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 深度学习, ISAC, 环境重建, 动态场景, 智能交通

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的车载ISAC动态环境重建框架，通过多阶段网络实现了高精度和实时性。

**AI_Comments:** 本文的创新点在于提出了一个专门针对车载ISAC动态环境重建的多阶段深度学习框架，有效解决了传统ISAC方法在动态场景跟踪精度和时间一致性上的局限。通过构建特定的解码器，实现了从粗粒度到细粒度的环境重建。其在实时场景中的高效性和低成本潜力，对于推动智能交通系统发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于ISAC的环境重建方法在跟踪动态场景时，缺乏足够的精度和时间一致性，限制了其在实际世界中的应用。

**Method:** 本文提出了一种基于深度学习的车载环境重建框架，利用ISAC信道。首先，建立了一个基于真实城市街道场景多模态测量的联合信道环境数据集。然后，开发了一个多阶段深度学习网络来重建环境，包括一个场景解码器识别环境上下文，一个聚类中心解码器预测粗略的空间布局，以及一个点云解码器恢复精细的环境几何和结构。

**Result:** 实验结果表明，所提出的方法实现了高质量的动态环境重建，Chamfer距离为0.29，F Score@1%为0.87。此外，复杂度分析证明了该方法在实时场景中的效率和实际适用性。

**Conclusion:** 这项工作为未来智能交通中基于ISAC的低成本环境重建提供了一条途径。

> **ai_Abstract:** 本文提出了一种基于深度学习的框架，利用ISAC信道对车辆动态环境进行高精度重建。针对现有ISAC方法在动态场景跟踪上的不足，该研究构建了一个多模态数据集，并开发了一个多阶段深度学习网络，包含场景、聚类中心和点云解码器，以识别环境上下文、预测粗略布局和恢复精细几何结构。实验证明，该方法能实现高质量的动态环境重建，并具备实时性，为未来智能交通的低成本环境感知提供了新途径。

> **摘要翻译:** 集成感知与通信（ISAC）技术通过重用无线信号使车辆感知和重建周围环境，从而减少甚至消除对LiDAR或雷达等额外传感器的需求，在未来智能交通系统中发挥着关键作用。然而，现有的基于ISAC的重建方法往往缺乏足够准确和时间一致地跟踪动态场景的能力，限制了其实际应用。为了解决这一限制，我们提出了一种基于深度学习的框架，用于利用ISAC信道进行车载环境重建。我们首先基于真实城市街道场景的多模态测量，建立了一个联合信道环境数据集。然后，开发了一个多阶段深度学习网络来重建环境。具体来说，一个场景解码器识别环境上下文，如建筑物、树木等；一个聚类中心解码器通过定位主要散射中心来预测粗略的空间布局；一个点云解码器恢复周围环境的精细几何和结构。实验结果表明，所提出的方法实现了高质量的动态环境重建，Chamfer距离为0.29，F Score@1%为0.87。此外，复杂度分析证明了该方法在实时场景中的效率和实际适用性。这项工作为未来智能交通中基于ISAC的低成本环境重建提供了一条途径。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [665] [Unifying Common Signal Analyses with Instantaneous Time-Frequency Atoms](https://arxiv.org/abs/2508.05380)
> *利用瞬时时频原子统一常见信号分析*

*Steven Sandoval, Phillip L. De Leon* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 瞬时时频原子, 信号分析, 瞬时频谱, 二次啁啾信号, 统一框架

**Comment:** 

> **TL;DR:** 本文利用瞬时时频原子，通过将常见信号分析视为AM-FM分解，并使用二次啁啾信号作为模板，实现了对时域、频域、分数傅里叶变换等多种信号分析的瞬时频谱的统一计算，并推导了闭合形式的表达式。

**AI_Comments:** 本文的创新之处在于其将多种看似不同的信号分析方法统一在一个通用的瞬时时频框架下，并通过引入二次啁啾信号作为统一模板，推导出了闭合形式的瞬时频谱表达式。这种统一性不仅简化了理解，也为未来信号处理算法的设计提供了新的视角和工具。其将IS组织成二维连续体的思想也颇具洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 在之前的工作中，作者提出了一个瞬时时频分析的通用框架，但没有提供如何计算特定瞬时频谱（IS）的具体细节。因此，本文旨在解决这一问题。

**Method:** 本文使用瞬时时频原子来获取与常见信号分析（包括时域分析、频域分析、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换）相关的瞬时频谱（IS）。通过将这些分析视为AM-FM分量分解，并识别出每种分析都使用一种特殊的（或极限的）二次啁啾信号作为分析模板，作者推导了相应IS的闭合形式表达式。利用双参数二次啁啾信号，将这些IS组织成一个二维连续体。

**Result:** 研究者成功地利用瞬时时频原子统一了多种常见的信号分析，并为相应的瞬时频谱（IS）开发了闭合形式的表达式。他们将这些IS组织成一个二维连续体。最后，通过几个示例信号，他们以闭合形式计算了各种分析的IS。

**Conclusion:** 本文展示了通用框架如何用于统一多种常见的信号分析，并成功地为相应的瞬时频谱（IS）开发了闭合形式的表达式，并通过示例信号进行了计算。

> **ai_Abstract:** 本文提出了一种利用瞬时时频原子统一多种常见信号分析（如时域、频域、分数傅里叶变换等）的方法。通过将这些分析视为AM-FM分量分解，并基于二次啁啾信号模板，论文推导了对应瞬时频谱（IS）的闭合形式表达式，并将其组织成一个二维连续体，从而展示了通用时频分析框架的统一能力。

> **摘要翻译:** 在之前的工作中，我们提出了一个用于瞬时时频分析的通用框架，但没有提供如何计算特定瞬时频谱（IS）的任何具体细节。在这项工作中，我们使用瞬时时频原子来获得与常见信号分析相关的IS：时域分析、频域分析、分数傅里叶变换、同步压缩短时傅里叶变换和同步压缩短时分数傅里叶变换。通过这样做，我们展示了通用框架如何用于统一这些分析，并且我们开发了相应IS的闭合形式表达式。这是通过将这些分析视为AM-FM分量分解并认识到每种分析在分析过程中都使用了一种专门的（或极限的）二次啁啾信号作为模板来实现的。通过双参数二次啁啾信号，我们可以将这些IS组织成一个二维连续体，平面中的点对应于与其中一种信号分析相关的分解。最后，使用几个示例信号，我们以闭合形式计算了各种分析的IS。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [671] [Phase Noise Tolerance for Low-Pilot-Overhead OFDM Terahertz Links Beyond 64-QAM](https://arxiv.org/abs/2508.05026)
> *低导频开销OFDM太赫兹链路超越64-QAM的相位噪声容忍度*

*Bowen Liu, Takasumi Tanabe* | **Category: eess.SP, physics.optics** | **Updated: 2025-08-07**

**Keywords:** 太赫兹通信, 相位噪声容忍度, OFDM, 64-QAM, 微环谐振器, 导频开销

**Comment:** 

> **TL;DR:** 本文量化了OFDM太赫兹系统中相位噪声的容忍度，并指出微环谐振器是实现低导频开销高阶调制的重要使能技术。

**AI_Comments:** 本文创新性地量化了太赫兹OFDM系统中高阶调制（超越64-QAM）的相位噪声容忍度，并通过引入3σ误差估计和EVM阈值，为实际物理层协议设计提供了量化依据。其重要性在于，它不仅揭示了相位噪声对太赫兹OFDM系统性能的关键限制，更重要的是，通过识别微环谐振器作为低导频开销高阶调制链路的使能技术，为克服这一挑战指明了方向，对推动太赫兹通信的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 太赫兹（THz）通信因其高数据速率潜力受到广泛关注，但高阶调制（如超越64-QAM）的应用受到相位误差的严重限制，特别是OFDM传输容易受到相位噪声引起的子载波间干扰（ICI）。虽然现有技术可以缓解相位误差，但过高的导频开销会降低频谱效率和能耗，且白相位噪声无法恢复。因此，量化相位噪声容忍度对于实际的物理层协议至关重要。

**Method:** 本文在一个64-QAM、2048子载波的OFDM THz传输系统中揭示了相位噪声的影响。提出并应用了3σ误差估计方法来量化相位噪声容忍度。

**Result:** 研究发现，系统对相位噪声的容忍度可以通过约5%的直观EVM（误差矢量幅度）阈值来量化。这个阈值进一步揭示了相位噪声水平、信噪比（SNR）要求和导频开销之间的权衡。通过对具有不同相位噪声频谱的代表性振荡器进行基准测试，发现微环谐振器（MRRs）是实现超越64-QAM的低导频开销OFDM太赫兹链路不可或缺的使能技术。

**Conclusion:** 量化相位噪声容忍度对于开发实用的高阶调制太赫兹OFDM系统至关重要。微环谐振器在实现低导频开销和高阶调制方面表现出巨大潜力，是未来太赫兹通信的关键技术。

> **ai_Abstract:** 本研究聚焦于太赫兹OFDM通信中高阶调制（超越64-QAM）所面临的相位噪声挑战。通过在一个64-QAM、2048子载波的OFDM THz系统中应用3σ误差估计，量化了相位噪声容忍度，并确定了一个约5%的EVM阈值。该阈值揭示了相位噪声、SNR和导频开销之间的权衡。研究结果表明，微环谐振器是实现低导频开销、高阶调制太赫兹OFDM链路的关键技术，为未来太赫兹通信的实际应用提供了重要指导。

> **摘要翻译:** 太赫兹（THz）无线通信因其未开发频谱带来的前所未有的数据速率而受到广泛关注。然而，超越64-QAM的高级调制格式在很大程度上仍未被探索，因为上/下变频期间引入的相位误差严重限制了系统性能。特别是，OFDM传输极易受到相位噪声引起的加剧的ICI影响，从而破坏子载波的正交性。虽然锁相环（PLL）和导频辅助补偿可以减轻相位误差，但过多的导频开销会损害频谱效率和能量消耗，并且白色相位噪声仍然无法恢复。因此，量化相位噪声容忍度对于实际的物理层协议至关重要。本文揭示了在一个64-QAM、2048子载波的OFDM THz传输系统中相位噪声的影响。提出了3σ误差估计来量化相位噪声容忍度，表明约5%的直观EVM阈值。该阈值进一步描绘了相位噪声水平、信噪比要求和导频开销之间的权衡。此外，通过对具有不同相位噪声频谱的代表性振荡器进行基准测试，微环谐振器（MRRs）被认为是实现超越64-QAM的低导频开销OFDM THz链路不可或缺的使能技术。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [679] [0.6-V, uW-Power 4-Stage OTA with Minimal Components and 100X Load Range](https://arxiv.org/abs/2508.05499)
> *0.6V、微瓦功耗、极简元件和100倍负载范围的四级运算跨导放大器*

*M. Privitera, A. D. Grasso, A. Ballo, M. Alioto* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 四级OTA, 超低功耗, 频率补偿, 负载范围, 功率效率

**Comment:** 

> **TL;DR:** 本文提出了一种0.6V、微瓦功耗的四级OTA，通过简化频率补偿，实现了高能效和100倍负载范围下的稳定性。

**AI_Comments:** 这篇论文的创新点在于其极简的组件设计和有效的频率补偿策略，成功将四级OTA的复杂性降低至三级OTA的水平，同时在超低功耗和宽负载范围稳定性方面取得了显著提升。这对于便携式和物联网设备中的模拟电路设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 克服传统四级运算跨导放大器（OTA）频率补偿的困难，并使其设计复杂度接近三级OTA，同时实现超低功耗应用。

**Method:** 提出了一种包含频率补偿的四级OTA电路，该电路只需极少的晶体管和无源元件。

**Result:** 引入了用于超低功耗应用的四级运算跨导放大器（OTA）。所需晶体管和无源元件数量最少，克服了传统四级OTA补偿的困难，使其设计复杂度与三级OTA相当。实现了高功率效率，大信号（小信号）功率效率品质因数FOML（FOMS）比现有四级OTA（亚1V多级OTA）分别提高了>3.7倍（>11.3倍）。由于相位裕度对负载电容的敏感度较低，该OTA在宽负载范围内保持稳定，负载电容的最大/最小比达到>100倍。

**Conclusion:** 本文成功设计了一种0.6V、微瓦功耗的四级OTA，通过创新的补偿方法，实现了高能效和在极宽负载范围内的稳定性，使其适用于超低功耗应用。

> **ai_Abstract:** 本文提出了一种创新的0.6V、微瓦功耗四级运算跨导放大器（OTA），通过极简的组件和频率补偿设计，解决了传统四级OTA补偿复杂的问题，使其设计复杂度与三级OTA相当。该OTA实现了显著的功率效率提升（大信号FOML >3.7X，小信号FOMS >11.3X），并能在超过100倍的宽负载范围内保持稳定，非常适合超低功耗应用。

> **摘要翻译:** 本文介绍了一种用于超低功耗应用的四级运算跨导放大器（OTA）。所提出的电路，包括频率补偿，只需最少的晶体管数量和无源器件，克服了传统四级OTA补偿的困难，并使其简化到三级OTA的程度。同时，所提出的电路实现了高功率效率，与现有的四级OTA（亚1V多级OTA）相比，大信号（小信号）功率效率品质因数FOML（FOMS）分别提高了>3.7倍（>11.3倍）。由于相位裕度对负载电容的敏感度较低，所提出的OTA在宽负载范围（如任何三级或四级OTA的双侧负载）下保持稳定，实现了超过100倍的负载电容最大/最小比。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [682] [Joint parameter estimation and multidimensional reconciliation for CV-QKD](https://arxiv.org/abs/2508.05558)
> *CV-QKD中的联合参数估计与多维协调*

*Jisheng Dai, Xue-Qin Jiang, Peng Huang, Tao Wang, Guihua Zeng* | **Category: eess.SP, quant-ph** | **Updated: 2025-08-07**

**Keywords:** CV-QKD, 参数估计, 信息协调, EM算法, 多维旋转

**Comment:** 

> **TL;DR:** 本文提出了一种新的联合消息传递方案，在贝叶斯框架下统一了CV-QKD中的信道参数估计和信息协调，通过EM算法在解码过程中同时估计参数，并引入混合多维旋转方案减少了经典信道开销，实现了高效且所需导频符号极少的信息协调。

**AI_Comments:** 这项工作在CV-QKD领域具有重要创新性，首次将信道参数估计和多维信息协调统一在一个贝叶斯框架下，并通过EM算法实现参数的同步估计。这一方法显著提高了符号效率，减少了经典信道开销，并有效避免了误差传播，为CV-QKD的实际应用提供了更高效、更鲁棒的解决方案。其主要创新点在于“联合”和“统一”的思想，以及对“极少导频符号”的实现。

<details>
  <summary>Details</summary>

**Motivation:** 传统的最大似然（ML）估计器依赖大量废弃数据（或导频符号），导致符号效率显著降低。此外，估计和协调阶段的分离可能引入误差传播。

**Method:** 提出了一种新颖的联合消息传递方案，在贝叶斯框架下统一了信道参数估计和信息协调。通过利用期望最大化（EM）算法，该方法在解码过程中同时估计未知参数，无需单独的ML估计。此外，引入了一种混合多维旋转方案，消除了对范数反馈的需求，显著减少了经典信道开销。

**Result:** 消除了对单独ML估计的需求，显著减少了经典信道开销。首次统一了CV-QKD中的多维协调和信道参数估计，为高效率且所需导频符号极少的信息协调提供了一个实用解决方案。

**Conclusion:** 本文通过提出一种联合消息传递方案，在贝叶斯框架下统一了CV-QKD中的信道参数估计和信息协调，并结合EM算法和混合多维旋转，为实现高效率且所需导频符号极少的信息协调提供了一个实用且创新的解决方案。

> **ai_Abstract:** 本文提出了一种针对连续变量量子密钥分发（CV-QKD）的联合消息传递方案，旨在解决传统参数估计方法效率低下及估计与协调分离导致的误差传播问题。该方案在贝叶斯框架下统一了信道参数估计和信息协调，利用期望最大化（EM）算法在解码过程中同时估计未知参数，从而无需单独的ML估计。此外，引入的混合多维旋转方案消除了范数反馈需求，显著降低了经典信道开销。这项工作首次在CV-QKD中实现了多维协调与信道参数估计的统一，为高效率且所需导频符号极少的信息协调提供了实用解决方案。

> **摘要翻译:** 准确的量子信道参数估计对于连续变量量子密钥分发（CV-QKD）中有效的信息协调至关重要。然而，传统的最大似然（ML）估计器依赖大量废弃数据（或导频符号），导致符号效率显著降低。此外，估计和协调阶段的分离可能引入误差传播。在本文中，我们提出了一种新颖的联合消息传递方案，在贝叶斯框架下统一了信道参数估计和信息协调。通过利用期望最大化（EM）算法，所提出的方法在解码过程中同时估计未知参数，消除了对单独ML估计的需求。此外，我们引入了一种混合多维旋转方案，消除了对范数反馈的需求，显著减少了经典信道开销。据我们所知，这是首次在CV-QKD中统一多维协调和信道参数估计的工作，为高效率且所需导频符号极少的信息协调提供了一个实用解决方案。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [689] [Shadow Area and Degrees of Freedom for Free-Space Communication](https://arxiv.org/abs/2407.21122)
> *自由空间通信的阴影面积与自由度*

*Mats Gustafsson* | **Category: eess.SP, physics.app-ph, physics.class-ph** | **Updated: 2025-08-06**

**Keywords:** 自由度数量, 阴影面积, 自由空间通信, 解析估计, 奇异值分解

**Comment:** 

> **TL;DR:** 本文提出了一种基于互阴影面积的简单解析估计方法，用于计算自由空间中任意形状收发区域间的自由度数量（NDoF），该方法在电大尺寸极限下近似NDoF，并提供物理洞察力及实用工具。

**AI_Comments:** 该论文的创新之处在于提出了一种基于“相互阴影面积”的解析方法来估计自由空间通信中的自由度数量（NDoF）。相较于传统的数值SVD方法，这种解析方法不仅提供了更直观的物理洞察力，而且在电大尺寸极限下表现出良好的近似效果，并能统一和推广多种现有理论。这对于高容量通信和传感系统的设计与分析具有重要的指导意义和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管信道中的自由度数量（NDoF）可以通过对信道算子进行奇异值分解（SVD）进行数值计算，但这种方法提供的物理洞察力有限。为了克服这一限制并提供更深入的理解，本文旨在引入一种简单、具有物理意义的NDoF解析估计方法。

**Method:** 本文引入了一种简单的解析估计方法来计算自由空间中任意形状收发区域间的自由度数量（NDoF）。在电大尺寸极限下，NDoF可以很好地通过相互阴影面积（以波长平方为单位）来近似。这种面积对应于区域的投影重叠，并对所有视线进行积分，从而捕捉其有效的空间耦合。该估计方法推广并统一了先前的一些结果，并通过与传播信道的数值SVD计算进行比较来验证其准确性。

**Result:** 在电大尺寸极限下，自由度数量（NDoF）可以很好地通过相互阴影面积（以波长平方为单位）来近似。这种方法能够推广并统一多种先前建立的结果，包括基于Weyl定律、阴影面积和傍轴近似的结果。通过对示例配置的分析以及与数值SVD计算的比较，验证了该估计的准确性。

**Conclusion:** 本文提出的结果为高容量通信和传感系统的设计与分析提供了实用的工具和物理洞察力。

> **ai_Abstract:** 本文提出了一种用于计算自由空间中任意形状收发区域间自由度数量（NDoF）的简单解析估计方法。该方法在电大尺寸极限下，将NDoF近似为相互阴影面积，该面积代表区域的有效空间耦合。此估计方法不仅概括并统一了现有理论，还通过数值模拟验证了其准确性，为高容量通信和传感系统的设计提供了实用的工具和物理洞察力。

> **摘要翻译:** 通信信道中的自由度数量（NDoF）从根本上限制了可用于传输和接收信息的独立空间模式的数量。尽管NDoF可以通过对信道算子进行奇异值分解（SVD）来对特定配置进行数值计算，但这种方法提供的物理洞察力有限。在本文中，我们引入了一种简单解析估计方法，用于计算自由空间中任意形状发射器和接收器区域之间的NDoF。在电大尺寸极限下，当NDoF较高时，它可以通过相互阴影面积（以波长平方为单位）很好地近似。该面积对应于区域的投影重叠，并在所有视线方向上进行积分，捕捉了它们有效的空间耦合。所提出的估计方法推广并统一了先前建立的几项结果，包括基于Weyl定律、阴影面积和傍轴近似的结果。我们分析了几个示例配置，以说明估计的准确性，并通过与传播信道的数值SVD计算进行比较来验证它。这些结果为高容量通信和传感系统的设计和分析提供了实用的工具和物理洞察力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [695] [Maximum Likelihood Estimation Based Complex-Valued Robust Chinese Remainder Theorem and Its Fast Algorithm](https://arxiv.org/abs/2503.18625)
> *基于最大似然估计的复值鲁棒中国剩余定理及其快速算法*

*Xiaoping Li, Shiyang Sun, Qunying Liao, Xiang-Gen Xia* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 中国剩余定理, 最大似然估计, 复值信号, 鲁棒估计, 模数转换器

**Comment:** 

> **TL;DR:** 本文提出了一种基于最大似然估计的快速复值中国剩余定理（MLE C-CRT）算法，用于处理具有误差余数的复值信号恢复，并在模数转换器（ADC）中展现出优于现有方法的性能。

**AI_Comments:** 该论文的创新点在于提出了一个快速的、基于最大似然估计的复值中国剩余定理算法，有效地解决了在多通道ADC系统中复值信号恢复过程中由误差余数引起的挑战。其“2L次搜索”的快速性以及对鲁棒估计充要条件的推导，显著提升了该方法的实用性和理论完备性。对于处理复杂高斯噪声下的C-CRT问题，这是一个重要的进步。

<details>
  <summary>Details</summary>

**Motivation:** 最近提出了一种具有复值模数的多通道自复位模数转换器（ADC）系统，该系统能够通过中国剩余定理（CRT）以低采样率恢复高动态范围的复值带限信号。本文研究的是带有误差余数的复值中国剩余定理（C-CRT），其中误差遵循包裹复高斯分布，旨在解决信号恢复中的误差问题。

**Method:** 本文在现有基于最大似然估计（MLE）的实值CRT基础上，提出了一种快速的基于MLE的C-CRT（MLE C-CRT）算法。该算法仅需进行2L次搜索即可获得公共余数的最佳估计，其中L是模数个数。一旦公共余数被估计，复数即可通过C-CRT确定。此外，还获得了快速MLE C-CRT实现鲁棒估计的充要条件。

**Result:** 所提出的算法在应用于模数转换器（ADC）时，结果表明其性能优于现有方法，并且能够实现鲁棒估计。

**Conclusion:** 本文提出的基于最大似然估计的复值鲁棒中国剩余定理及其快速算法，在处理具有误差余数的复值信号恢复方面表现出色，特别适用于模数转换器系统，并具有优于现有方法的性能。

> **ai_Abstract:** 本文提出了一种基于最大似然估计（MLE）的快速复值中国剩余定理（C-CRT）算法，旨在解决多通道ADC系统中复值带限信号在低采样率下通过CRT恢复时出现的误差余数问题。该算法在处理遵循包裹复高斯分布的误差时，仅需2L次搜索即可获得最优估计，并给出了实现鲁棒估计的充要条件。实验结果表明，该算法在ADC应用中性能优于现有方法。

> **摘要翻译:** 最近，提出了一种具有复值模数的多通道自复位模数转换器（ADC）系统。该系统能够通过中国剩余定理（CRT）以低采样率恢复高动态范围的复值带限信号。在本文中，我们研究了带有误差余数的复值CRT（C-CRT），其中误差遵循包裹复高斯分布。基于现有利用最大似然估计（MLE）的实值CRT，我们提出了一种快速的基于MLE的C-CRT（MLE C-CRT）。所提出的算法仅需进行2L次搜索即可获得公共余数的最佳估计，其中L是模数个数。一旦公共余数被估计，复数即可使用C-CRT确定。此外，我们获得了快速MLE C-CRT实现鲁棒估计的充要条件。最后，我们将所提出的算法应用于ADC。结果表明，所提出的算法优于现有方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [701] [Low-Complexity Optimization of Antenna Switching Schemes for Dynamic Channel Sounding](https://arxiv.org/abs/2504.07675)
> *动态信道探测中天线切换方案的低复杂度优化*

*Juan Sanchez, Xuesong Cai, Ali Al-Ameri, Fredrik Tufvesson* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** 天线切换, 信道探测, 傅里叶-费舍尔, 复杂度优化, 费舍尔信息矩阵

**Comment:** 

> **TL;DR:** 本文提出了一种名为“傅里叶-费舍尔”的新方法，用于优化动态信道探测中天线切换序列的设计，该方法在保持性能的同时显著降低了计算复杂度。

**AI_Comments:** 这篇论文的创新点在于提出了“傅里叶-费舍尔”这种结合了傅里叶分析和费舍尔信息矩阵的新型切换序列优化方法。其重要性在于解决了传统方法在处理超大天线阵列时计算复杂度过高的问题，为未来5G/6G等移动通信系统中的动态信道探测提供了更高效、更实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 理解无线信道对于无线系统设计至关重要。对于移动通信，需要具有短测量时间的探测器和天线阵列来同时捕获动态和空间信道特性。开关天线阵列是克服真实阵列高成本和虚拟阵列长测量时间的一种有吸引力的选择。优化切换序列对于避免混叠和提高信道参数估计精度至关重要。

**Method:** 本文首先回顾并扩展了传统的时空模糊函数至双极化天线阵列，并分析了其在超大天线阵列中的高复杂度。为此，提出了一种使用费舍尔信息矩阵来处理估计精度的新方法，并建议通过选择使其傅里叶频谱中旁瓣最小化的切换序列来最小化模糊性。最终，将序列设计问题划分为基于傅里叶的模糊性降低和基于费舍尔的精度提高，并将由此产生的设计方法命名为“傅里叶-费舍尔”。

**Result:** 仿真和测量结果表明，“傅里叶-费舍尔”方法实现了与传统基于模糊性的方法相同的性能，但计算复杂度显著降低。

**Conclusion:** “傅里叶-费舍尔”方法为动态信道探测中的天线切换序列优化提供了一种有效且低复杂度的解决方案，在保持性能的同时显著降低了计算成本。

> **ai_Abstract:** 本文提出了一种新颖的“傅里叶-费舍尔”方法，用于优化动态信道探测中开关天线阵列的切换序列设计。该方法通过结合基于傅里叶的模糊性降低和基于费舍尔的精度提高，解决了传统时空模糊函数在超大天线阵列中计算复杂度过高的问题。实验结果表明，“傅里叶-费舍尔”方法在保持相同性能的同时，显著降低了计算复杂度。

> **摘要翻译:** 理解无线信道对于无线系统设计至关重要。对于移动通信，需要具有短测量时间的探测器和天线阵列来同时捕获动态和空间信道特性。开关天线阵列是一种有吸引力的选择，可以克服真实阵列的高成本和虚拟阵列的长时间测量。然后，切换序列的优化对于避免混叠和提高信道参数估计的准确性至关重要。本文对切换序列的设计提供了新颖而全面的分析。我们首先回顾了传统的时空模糊函数，将其扩展到双极化天线阵列，并分析了其应用于超大天线阵列时令人望而却步的复杂性。因此，我们提出了一种使用费舍尔信息矩阵来解决估计精度问题的新方法。我们还建议通过选择使其傅里叶频谱中的旁瓣最小化的切换序列来最小化模糊性。从这个意义上讲，我们将序列设计问题划分为基于傅里叶的模糊性降低和基于费舍尔的精度提高，并将由此产生的设计方法命名为傅里叶-费舍尔。仿真和测量表明，傅里叶-费舍尔方法实现了与传统基于模糊性的方法相同的性能，并且计算复杂度显著低于后者。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [706] [Multi-dimensional Parameter Estimation in RIS-aided MU-MIMO Channels](https://arxiv.org/abs/2505.02611)
> *RIS辅助MU-MIMO信道中的多维参数估计*

*Linlin Mo, Yi Song, Fabio Saggese, Xinhua Lu, Zhongyong Wang, Petar Popovski* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** RIS, 信道估计, 多维, DS-MDT, MU-MIMO

**Comment:** 

> **TL;DR:** 该论文提出了一种双结构和多维变换（DS-MDT）算法，用于RIS辅助宽带系统中的信道估计，该算法提高了估计性能，并将归一化均方误差（NMSE）降低了高达10 dB，同时保持了较低的复杂度。

**AI_Comments:** DS-MDT算法的创新之处在于其双重方法：利用信道参数的双结构特征和采用多维变换进行高效参数提取。其重要性体现在显著的NMSE改善和复杂性降低上，解决了RIS辅助系统中的一个关键挑战。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决可重构智能表面（RIS）辅助宽带系统中的信道估计问题。

**Method:** 所提出的方法是双结构和多维变换（DS-MDT）算法。它利用信道参数的双结构特征来辅助信道条件较弱的用户，并采用多维变换来有效地从接收张量中分离和提取不同的参数。

**Result:** 数值结果表明，与最先进的方法相比，所提出的算法将归一化均方误差（NMSE）降低了高达10 dB，同时保持了较低的复杂度。

**Conclusion:** 该论文成功提出了一种DS-MDT算法，显著提高了RIS辅助宽带系统中的信道估计性能并降低了复杂度。

> **ai_Abstract:** 本论文提出了一种双结构和多维变换（DS-MDT）算法，以解决RIS辅助宽带系统中的信道估计问题。该算法通过利用信道参数的双结构特征来帮助信道条件较弱的用户，并采用多维变换从接收张量中提取参数，从而提高估计性能。与现有方法相比，该算法将归一化均方误差（NMSE）降低了高达10 dB，并具有更低的复杂度。

> **摘要翻译:** 我们通过提出一种双结构和多维变换（DS-MDT）算法，解决了可重构智能表面（RIS）辅助宽带系统中的信道估计问题。所提出的方法利用信道参数的双结构特征来辅助经历较弱信道条件的用户，从而提高估计性能。此外，鉴于信道参数分布在接收张量的多个维度上，所提出的算法采用多维变换来有效地分离和提取不同的参数。数值结果表明，与最先进的方法相比，所提出的算法将归一化均方误差（NMSE）降低了高达10 dB，同时保持了较低的复杂度。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [712] [Robust Beamforming Design for STAR-RIS Aided RSMA Network with Hardware Impairments](https://arxiv.org/abs/2505.08642)
> *具有硬件损伤的STAR-RIS辅助RSMA网络鲁棒波束成形设计*

*Ziyue Wang, Xiaoyan Ma, Xingyu Peng, Zheao Li, Jinyuan Liu, Yongliang Guan, Chau Yuen* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** STAR-RIS, RSMA, 鲁棒波束成形, 硬件损伤, 分数规划

**Comment:** 

> **TL;DR:** 本文研究了在收发器和STAR-RIS均存在硬件损伤情况下，STAR-RIS辅助的下行速率分裂多址(RSMA)通信系统的鲁棒波束成形设计，旨在最大化用户可实现和速率。

**AI_Comments:** 本文的创新点在于首次将硬件损伤考虑进STAR-RIS辅助的RSMA网络波束成形设计中，并提出了有效的优化算法。其重要性在于提升了实际通信系统中STAR-RIS应用的鲁棒性，为未来6G通信系统中的智能表面技术提供了新的设计思路。

<details>
  <summary>Details</summary>

**Motivation:** 在STAR-RIS辅助的下行速率分裂多址(RSMA)通信系统中，收发器和STAR-RIS均受硬件损伤(HWI)影响，这给系统性能带来了挑战。研究旨在通过鲁棒波束成形设计，在存在HWI的情况下，最大化用户可实现和速率，同时满足发射功率、STAR-RIS系数和公共流实际速率的约束。

**Method:** 为了解决高耦合和非凸的优化问题，本文采用了基于分数规划(FP)的交替优化(AO)方法。每个子问题通过连续凸逼近(SCA)和罚函数(PF)方法进行解决。

**Result:** 数值结果表明，所提出的方案在可实现和速率方面优于其他多址接入方案和传统的无源RIS。此外，考虑收发器和STAR-RIS的硬件损伤使算法比不考虑这些因素时更具鲁棒性。

**Conclusion:** 本文成功提出了针对具有硬件损伤的STAR-RIS辅助RSMA网络的鲁棒波束成形设计，并通过数值结果验证了其优越性和鲁棒性。

> **ai_Abstract:** 本文研究了在收发器和STAR-RIS均存在硬件损伤的STAR-RIS辅助下行RSMA通信系统中，旨在最大化用户和速率的鲁棒波束成形设计。该研究通过基于分数规划的交替优化方法解决了一个高耦合非凸问题，并利用连续凸逼近和罚函数处理子问题。数值结果验证了所提方案在和速率性能上优于其他多址方案和传统RIS，并指出考虑硬件损伤能增强算法的鲁棒性。

> **摘要翻译:** 在本文中，我们研究了同步传输和反射可重构智能表面（STAR-RIS）辅助的下行速率分裂多址（RSMA）通信系统的鲁棒波束成形设计，其中收发器和STAR-RIS都受到硬件损伤（HWI）的影响。基站（BS）被部署用于同时向多个用户传输消息，利用STAR-RIS来提高通信质量和扩展用户覆盖范围。我们的目标是在确保发射功率、STAR-RIS系数以及所有用户公共流实际速率的约束下，最大化用户可实现的总速率。为了解决这个具有挑战性的高耦合和非凸问题，我们采用了基于分数规划（FP）的交替优化（AO）方法，其中每个子问题通过连续凸逼近（SCA）和罚函数（PF）方法解决。数值结果表明，所提出的方案在可实现总速率方面优于其他多址接入方案和传统的无源RIS。此外，考虑收发器和STAR-RIS的HWI使得我们的算法比不考虑这些因素时更具鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [719] [WiFo-CF: Wireless Foundation Model for CSI Feedback](https://arxiv.org/abs/2508.04068)
> *WiFo-CF：用于CSI反馈的无线基础模型*

*Xuanyu Liu, Shijian Gao, Boxun Liu, Xiang Cheng, Liuqing Yang* | **Category: eess.SP** | **Updated: 2025-08-07**

**Keywords:** CSI反馈, 无线基础模型, 自监督预训练, S-R MoE, 异构配置

**Comment:** 

> **TL;DR:** WiFo-CF是一个新型的无线基础模型，通过自监督预训练和S-R MoE架构，解决了现有深度学习CSI反馈方案在异构配置下的泛化性差的问题，并在多样化数据集上表现出色。

**AI_Comments:** 这篇论文通过引入无线基础模型WiFo-CF，为CSI反馈领域带来了重要的创新。其核心贡献在于提出了一个能够处理异构配置的统一框架，通过结合自监督预训练和S-R MoE架构，显著提升了模型的泛化能力和灵活性，克服了传统深度学习方法的局限性。此外，构建异构数据集以支持大规模预训练，并验证了其在下游任务中的适应性，进一步凸显了该模型的实用价值和未来潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于深度学习的信道状态信息（CSI）反馈方案受限于固定的系统配置，导致泛化能力和灵活性不足。

**Method:** 本文提出了一种名为WiFo-CF的无线基础模型，用于CSI反馈，其创新点包括：1) 多用户、多速率自监督预训练策略；2) 共享与路由专家混合（S-R MoE）架构。同时，构建了首个异构信道反馈数据集来支持大规模预训练。

**Result:** WiFo-CF模型在模拟和真实场景中的分布内和分布外数据上都取得了卓越的性能。此外，学习到的表示能够有效地促进对CSI室内定位等下游任务的适应。

**Conclusion:** WiFo-CF通过其创新的架构和预训练策略，成功地解决了深度学习CSI反馈在异构配置下的泛化和灵活性问题，并展示了其可扩展性和部署潜力。

> **ai_Abstract:** WiFo-CF是一种新颖的无线基础模型，旨在解决现有深度学习CSI反馈方案在异构系统配置下泛化能力差的问题。它通过多用户、多速率自监督预训练和S-R MoE架构，在一个统一框架内处理不同的信道维度、反馈速率和数据分布。该模型利用首个异构信道反馈数据集进行大规模预训练，在多样化数据上表现优异，并能有效适应下游任务，展现了其强大的可扩展性和部署潜力。

> **摘要翻译:** 深度学习的信道状态信息（CSI）反馈方案展现出强大的压缩能力，但通常受限于固定的系统配置，这限制了它们的泛化能力和灵活性。为了应对这一挑战，本文提出了一种专为CSI反馈量身定制的新型无线基础模型WiFo-CF，通过其关键创新：(1) 多用户、多速率自监督预训练策略；以及 (2) 共享与路由专家混合（S-R MoE）架构，独特地在一个统一框架内适应了异构配置，例如变化的信道维度、反馈速率和数据分布。支持WiFo-CF大规模预训练的是首个异构信道反馈数据集，其多样化的模式使模型能够在模拟和真实场景中的分布内和分布外数据上都取得卓越的性能。此外，学习到的表示有效地促进了对CSI室内定位等下游任务的适应，验证了WiFo-CF的可扩展性和部署潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [409] [Linear Program-Based Stability Conditions for Nonlinear Autonomous Systems](https://arxiv.org/abs/2508.04871)
> *基于线性规划的非线性自治系统稳定性条件*

*Sadredin Hokmi, Mohammad Khajenejad* | **Category: eess.SY** | **Updated: 2025-08-06**

**Keywords:** 渐近稳定性, 线性规划, 非线性系统, Lyapunov方法, 计算效率

**Comment:** 

> **TL;DR:** 本文提出一种新颖的方法，通过线性规划 (LP) 而非半定规划 (SDP) 来评估非线性自治系统的渐近稳定性，显著降低了计算负担。

**AI_Comments:** 这篇论文的创新点在于将稳定性分析中的半定规划（SDP）问题转化为计算效率更高的线性规划（LP）问题，从而显著降低了高维非线性系统分析的计算成本。这种方法对于实际工程应用，特别是涉及复杂高维系统的稳定性分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统评估非线性自治系统渐近稳定性的半定规划 (SDP) 方法计算负担重，尤其是在高维系统中。

**Method:** 本文利用间接Lyapunov方法，通过Jacobian矩阵线性化系统动力学，并将传统的半定规划 (SDP) 条件替换为计算效率更高的线性规划 (LP) 条件。稳定性准则通过矩阵变换和利用系统结构特性开发，提高了可扩展性。

**Result:** 所提出的方法显著降低了计算负担（包括时间和内存使用），尤其适用于高维系统。通过多个示例证明了其相对于现有基于SDP的准则的计算效率。

**Conclusion:** 本文成功提出了一种基于线性规划的新方法，有效解决了非线性自治系统稳定性评估中的计算效率问题，特别是在高维系统中的表现优于现有方法。

> **ai_Abstract:** 本文提出了一种创新的方法来评估连续和离散时间非线性自治系统的渐近稳定性。该方法将传统的半定规划（SDP）替换为计算效率更高的线性规划（LP）条件，利用间接Lyapunov方法和Jacobian矩阵进行系统线性化。这种改变显著降低了计算负担，并提高了高维系统的可扩展性。实验结果验证了其相较于现有SDP方法的优越计算效率。

> **摘要翻译:** 本文介绍了一种评估连续时间（CT）和离散时间（DT）非线性自治系统平衡点渐近稳定性的新方法。该方法利用间接Lyapunov方法并通过Jacobian矩阵线性化系统动力学，将传统的半定规划（SDP）技术替换为计算效率更高的线性规划（LP）条件。这种替代显著降低了计算负担，包括时间与内存使用，尤其适用于高维系统。稳定性准则通过矩阵变换和利用系统结构特性开发，提高了可扩展性。多个示例证明了所提出的方法与现有基于SDP的准则相比具有计算效率，特别是在高维系统中。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [417] [Uncovering the Influence Flow Model of Transistor Amplifiers, Its Reconstruction and Application](https://arxiv.org/abs/2508.04977)
> *晶体管放大器影响流模型的揭示、重构与应用*

*Mohammed Tuhin Rana, Mishfad Shaikh Veedu, Murti V. Salapaka* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 晶体管放大器, 线性动态影响模型, 网络重构, 故障诊断, 电路分析

**Comment:** 

> **TL;DR:** 本文提出了一种基于线性动态影响模型（LDIM）的数据驱动网络重构方法，用于高效分析、设计和调试多级晶体管放大器，并应用于故障诊断。

**AI_Comments:** 该论文的创新点在于将复杂的晶体管放大器建模为线性动态影响模型，并利用数据驱动的网络重构技术，实现了仅凭外部测量数据就能推断内部网络结构的能力。这对于放大器电路的故障诊断和参数识别具有重要意义，提供了一种非侵入式且高效的分析工具，对于电路设计和维护具有实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多级晶体管放大器可被有效建模为动态系统网络，但其级间动态耦合的表征、故障识别和关键电路参数的确定需要更高效的方法。该研究旨在通过数据驱动技术解决这些问题，提供设计、分析和调试放大器电路的有效工具。

**Method:** 研究将多级晶体管放大器建模为线性动态影响模型（LDIM），其中级间相互作用被建模为线性动态方程。采用图形建模技术和维纳滤波，仅通过电路中指定点的电压时间序列测量数据来重构网络结构。此外，还提出了一种利用这些技术进行故障诊断的方法。

**Result:** 通过Cadence中的多放大器电路的广泛仿真以及物理硬件上的实验结果，证明了所提出的网络重构方法在多级放大器中的有效性。该方法能够直接从测量数据推断网络结构，为设计人员和用户提供了高效的设计、分析和调试放大器电路的工具。

**Conclusion:** 本文提出的基于LDIM的网络重构方法，能够高效地从测量数据中识别晶体管放大器的级间相互作用、故障和关键电路参数。该能力为放大器电路的设计、分析和调试提供了强大的工具，并通过故障诊断方法展示了其实用性。

> **ai_Abstract:** 本研究提出了一种创新性的方法，将多级晶体管放大器建模为线性动态影响模型（LDIM），以表征其级间动态耦合。通过结合数据驱动的网络重构技术、图形建模和维纳滤波，该方法能够仅利用电压时间序列测量数据来重建放大器的内部网络结构。文章通过广泛的仿真和实验验证了该方法的有效性，并展示了其在高效设计、分析、调试以及故障诊断放大器电路方面的巨大潜力。

> **摘要翻译:** 多级晶体管放大器可以有效地建模为动态系统网络，其中各个放大器级通过动态性质的耦合进行交互。利用电路分析技术，我们展示了大量晶体管放大器可以建模为线性动态影响模型（LDIM），其中不同放大器级之间的相互作用被建模为线性动态方程。晶体管电路的LDIM建模使得数据驱动的网络重构技术能够用于有效地表征级间相互作用并识别故障和关键电路参数。采用图形建模技术和维纳滤波，我们证明了网络结构可以仅从电路中指定点采样的电压时间序列测量数据中重构。这些网络重构方法在多级放大器中的有效性通过Cadence中涉及多个放大器电路的广泛仿真以及物理硬件上的实验结果得到了证明。直接从测量数据推断网络结构的能力为设计人员和用户提供了高效的设计、分析和调试放大器电路的工具。为了展示网络重构在多级放大器电路中的实用性，本文提出了一种利用这些技术进行故障诊断的方法。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [428] [Passive nonlinear FIR filters for data-driven control](https://arxiv.org/abs/2508.05279)
> *被动非线性FIR滤波器用于数据驱动控制*

*Zixing Wang, Fulvio Forni* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 被动非线性FIR滤波器, 数据驱动控制, 约束优化, 虚拟参考反馈调谐, 物理系统控制

**Comment:** 

> **TL;DR:** 提出了一种新的被动非线性有限脉冲响应算子，通过约束优化实现高效控制合成，并适用于物理系统控制。

**AI_Comments:** 该论文的创新点在于提出了一类新的被动非线性FIR算子，并通过在提升空间构建和结合约束优化实现了高效控制合成。其强调被动性并通过线性约束实现，使得该方法在控制物理系统方面具有潜在的鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了提出一种新的被动非线性有限脉冲响应算子，以实现通过约束优化进行高效控制合成，并特别适用于物理系统控制。

**Method:** 通过在提升空间中作用有限脉冲响应滤波器来构建新的被动非线性FIR算子。通过基于虚拟参考反馈调谐理论的最小二乘拟合考虑闭环性能，并通过基于频域采样的有效线性约束建立被动性。

**Result:** Not mentioned in abstract

**Conclusion:** 该文提出的一类新的被动非线性有限脉冲响应算子，由于其被动性，特别适用于物理系统，如机电系统的控制。

> **ai_Abstract:** 该论文提出了一种新型的被动非线性有限脉冲响应（FIR）算子，其构建方法涉及在提升空间中应用FIR滤波器。这种方法支持通过约束优化进行高效的控制合成，并通过最小二乘拟合结合虚拟参考反馈调谐理论来优化闭环性能。算子的被动性通过频域采样产生的线性约束确保，使其特别适合控制机电系统等物理系统。

> **摘要翻译:** 我们提出了一类新的被动非线性有限脉冲响应算子。这类算子是通过在提升空间中作用有限脉冲响应滤波器来构建的。这使得通过约束优化实现高效的控制合成成为可能。闭环性能通过基于虚拟参考反馈调谐理论的最小二乘拟合来考虑。被动性通过基于频域采样的有效线性约束来建立。由于被动性，这类算子特别适用于物理系统，例如机电系统的控制。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [429] [Preparing for the worst: Long-term and short-term weather extremes in resource adequacy assessment](https://arxiv.org/abs/2508.05163)
> *做好最坏准备：资源充足性评估中的长期和短期极端天气*

*Aleksander Grochowicz, Hannah C. Bloomfield, Marta Victoria* | **Category: eess.SY, math.OC** | **Updated: 2025-08-07**

**Keywords:** 极端天气, 资源充足性, 电力系统, 韧性, 影子价格

**Comment:** 

> **TL;DR:** 本研究使用基于影子价格的方法，识别并分析极端天气在零碳电力系统中造成的系统定义事件，强调了对充足且财务可行的备用容量的需求，并区分了短期和长期韧性挑战，旨在帮助构建更具韧性的能源系统。

**AI_Comments:** 该论文创新性地利用影子价格方法来识别和分类极端天气下的系统定义事件，并强调了区分短期和长期韧性挑战的重要性。其方法在PyPSA-Eur开放模型中的实现提高了研究的可复用性，对政策制定者具有实际指导意义，有助于构建更具韧性和充足的能源系统。

<details>
  <summary>Details</summary>

**Motivation:** 在将可再生能源整合到零碳电力系统时，供电安全是一个重要且普遍的关注点。极端天气会同时影响电力需求和供应，导致电力系统承受压力，并且在欧洲，这种压力可以超越气象根源，在整个大陆蔓延。

**Method:** 本研究采用基于影子价格的方法来识别高压力时期，并将其称为“系统定义事件”，分析这些事件对电力系统的影响。通过对不同类型的系统定义事件进行分类，识别电力系统运行和规划中的挑战。此外，还利用不同的指标和压力测试来区分短期和长期韧性挑战，以便将其纳入未来的能源建模评估中。

**Result:** 研究发现，需要有足够的韧性备用（电力）容量，但由于天气多变性，这些容量的财务可行性并不稳定。此外，成功地区分了短期和长期韧性挑战。

**Conclusion:** 本研究提出的方法及其在开放模型PyPSA-Eur中的实现，可以重新应用于其他系统，并有助于研究人员和政策制定者构建更具韧性且充足的能源系统。

> **ai_Abstract:** 本研究旨在评估极端天气对零碳电力系统资源充足性的影响。作者提出一种基于影子价格的方法，识别并分类由极端天气引起的“系统定义事件”，分析其对供需的影响。研究发现，需要具备足够的韧性备用容量以应对天气多变性带来的财务挑战，并区分了短期和长期韧性挑战。该方法及其在PyPSA-Eur模型中的实现有助于构建更具韧性和充足的能源系统。

> **摘要翻译:** 供电安全是净零电力系统整合可再生能源时一个普遍且重要的关注点。极端天气影响需求和供应，导致电力系统压力；在欧洲，这种压力超越气象根源，在整个大陆蔓延。我们采用基于影子价格的方法来识别高压力时期，称之为系统定义事件，并分析它们对电力系统的影响。通过对不同类型的系统定义事件进行分类，我们识别了电力系统运行和规划面临的挑战。关键是，我们发现需要足够的韧性备用（电力）容量，但由于天气多变性，其财务可行性不稳定。此外，我们通过不同的指标和压力测试来区分短期和长期韧性挑战，以便将两者纳入未来的能源建模评估中。我们的方法及其在开放模型PyPSA-Eur中的实现可以重新应用于其他系统，并帮助研究人员和政策制定者构建更具韧性且充足的能源系统。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [440] [A 20-Year Retrospective on Power and Thermal Modeling and Management](https://arxiv.org/abs/2508.05495)
> *电力和热建模与管理二十年回顾*

*David Atienza, Kai Zhu, Darong Huang, Luis Costero* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 功耗建模, 热管理, 处理器, 综述, 能源效率

**Comment:** 

> **TL;DR:** 这篇综述回顾了过去二十年处理器中功耗和热建模与管理的研究进展，涵盖了功耗估计、热建模和运行时管理策略，并讨论了未来的挑战和方向。

**AI_Comments:** 这是一篇重要的回顾性综述，它系统地梳理了功耗和热管理领域二十年的研究进展，为理解该领域的演变、当前挑战和未来方向提供了宝贵的视角。对于研究人员和工程师来说，它是一个全面的参考。

<details>
  <summary>Details</summary>

**Motivation:** 随着处理器性能的提升，不断增加的功率密度和复杂的热行为对能源效率和系统可靠性构成威胁，因此对功耗和热管理的研究至关重要。

**Method:** 这篇综述回顾了二十多年来现代处理器中功耗和热建模与管理的研究。具体方法包括：比较分析、基于回归和基于神经网络的功耗估算技术；回顾有限元、有限差分和数据驱动的热建模方法；分类动态运行时管理策略以平衡性能、功耗和可靠性。

**Result:** 本文回顾了多种功耗估计技术（分析、回归、神经网络）、热建模方法（有限元、有限差分、数据驱动）以及动态运行时管理策略，并讨论了新兴挑战和有前景的研究方向。

**Conclusion:** 本文总结了功耗和热建模与管理领域二十多年的研究，并讨论了该领域面临的新兴挑战和有前景的未来研究方向。

> **ai_Abstract:** 本篇综述对过去二十年处理器中功耗和热建模与管理的研究进行了全面回顾。文章首先比较了各种功耗估算技术，接着探讨了不同的热建模方法，然后分类了旨在平衡性能、功耗和可靠性的动态运行时管理策略。最后，文章讨论了该领域面临的新挑战和未来的研究方向。

> **摘要翻译:** 随着处理器性能的提升，不断增加的功率密度和复杂的热行为对能源效率和系统可靠性构成威胁。本综述涵盖了二十多年来现代处理器中功耗和热建模与管理的研究。我们首先比较了分析、基于回归和基于神经网络的功耗估算技术，然后回顾了包括有限元、有限差分和数据驱动方法在内的热建模方法。接下来，我们对平衡性能、功耗和可靠性的动态运行时管理策略进行了分类。最后，我们讨论了新兴挑战和有前景的研究方向。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [449] [Research on integrated intelligent energy management system based on big data analysis and machine learning](https://arxiv.org/abs/2508.05583)
> *基于大数据分析和机器学习的集成智能能源管理系统研究*

*Jinzhou Xu, Yadan Zhang, Paola Tapia* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 大数据分析, 机器学习, 集成智能能源, 文档管理, 效率优化

**Comment:** 

> **TL;DR:** 本文研究了如何利用大数据分析和机器学习优化集成智能能源项目的文档管理效率，并提出了一个实现框架和方法，通过惩罚线性回归模型实现了超过95%的准确率。

**AI_Comments:** 该研究将大数据分析和机器学习应用于集成智能能源的项目文档管理，具有创新性。其提出的实施框架和具体的机器学习优化方法，以及超过95%的预测准确率，表明了该方法在提升项目管理效率和控制力方面的潜力。然而，抽象中未详细说明所使用的三种机器学习方法的具体类型，也未提及数据集的来源、规模以及实验的详细设置，这些都是评估其普适性和可靠性的关键信息。

<details>
  <summary>Details</summary>

**Motivation:** 提高集成智能能源项目文件管理和控制的效率，因为大数据应用对此具有重要意义。

**Method:** 讨论了大数据分析在集成智能能源项目文档管理中的益处和挑战；开发了一个大数据分析在集成智能能源项目文档管理中的实施框架；提出了通过机器学习优化集成智能能源项目文档管理效率的方法；使用三种不同的机器学习方法优化了项目文档控制效率，并具体提到了惩罚线性回归模型。

**Result:** 拟合惩罚线性回归模型的结果显示，在有足够训练数据的情况下，模型准确率可达95%以上。

**Conclusion:** 通过大数据分析和机器学习分析综合智能能源项目文档管理效率，可以跟踪整个项目文档过程并优化业务流程，从而加强项目建设控制并提高项目建设效率。

> **ai_Abstract:** 本文探讨了大数据分析和机器学习在集成智能能源项目文档管理中的应用。研究讨论了大数据分析的益处与挑战，并提出了一个实施框架及通过机器学习优化文档管理效率的方法。通过使用惩罚线性回归等三种机器学习方法，实现了对项目文档控制效率的优化，结果显示模型准确率可达95%以上，证明了该方法在提高项目建设效率和加强控制方面的有效性。

> **摘要翻译:** 大数据应用是集成智能能源的重要特征之一。将其应用于集成智能能源项目的文件管理，对于提高项目管理和控制效率具有重要意义。本文首先讨论了在大数据分析在集成智能能源项目文档管理和控制中实施的益处和挑战。此外，开发了一个大数据分析在集成智能能源项目文档管理中的实施框架，并提出了一种通过机器学习优化集成智能能源项目文档管理效率的方法。利用项目文档管理过程中生成的各种类型的数据和信息，通过三种不同的机器学习方法优化了整个过程项目文档控制的效率。拟合惩罚线性回归模型的结果表明，当有足够的训练数据时，模型精度可以达到95%以上。通过利用大数据分析和机器学习分析综合智能能源项目文档管理效率，可以跟踪综合智能能源项目文档的整个过程并优化业务流程，从而加强项目建设控制并提高项目建设效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [456] [Error Bounds for Radial Network Topology Learning from Quantized Measurements](https://arxiv.org/abs/2508.05620)
> *径向网络拓扑学习中量化测量的误差界限*

*Samuel Talkington, Aditya Rangarajan, Pedro A. de Alcântara, Line Roald, Daniel K. Molzahn, Daniel R. Fuhrmann* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 径向网络拓扑, 量化测量, 误差界限, 非线性模型, 传感器网络

**Comment:** 

> **TL;DR:** 本文研究了从量化测量中学习径向网络拓扑的误差界限，发现误差与量化区间宽度成正比，并随节点数量亚线性增长。

**AI_Comments:** 本文的创新之处在于超越了传统电力系统估计中普遍使用的加性噪声模型，转而关注由传感器精度引入的量化误差，提出了一个更符合实际情况的非线性测量模型。这对于提高实际传感器网络中拓扑学习的准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统电力系统估计算法通常采用加性噪声模型，但实际中传感器精度引入的量化误差会导致非线性测量模型，本文旨在解决这种非线性模型下的网络拓扑学习误差问题。

**Method:** 提出了一种概率性地界定径向网络拓扑学习误差的方法，该方法考虑了由传感器量化引起的非线性测量模型，并分析了连接性和线路参数的估计误差。

**Result:** 学习到的径向网络拓扑误差与量化区间宽度成正比，并且在每个节点的样本数量与节点数量呈对数关系时，误差随节点数量亚线性增长。

**Conclusion:** 论文成功地为量化测量下的径向网络拓扑学习的误差提供了概率界限，揭示了误差与量化精度和网络规模之间的关系。

> **ai_Abstract:** 本文针对从量化测量数据中学习径向网络拓扑的问题，提出了一个考虑传感器量化误差导致的非线性测量模型的分析框架。研究结果表明，在估计网络连接性和线路参数时，学习到的拓扑误差与量化区间宽度成正比，并且在满足特定采样条件下，误差随节点数量呈亚线性增长。

> **摘要翻译:** 我们概率性地界定了径向网络拓扑学习问题的解的误差，其中同时估计了连接性和线路参数。在我们的模型中，数据误差是由传感器的精度（即量化）引入的。这产生了一个非线性测量模型，将传感器通信网络的运行嵌入到学习问题中，超越了电力系统估计算法中常见的加性噪声模型。我们表明，学习到的径向网络拓扑的误差与量化区间宽度成正比，并且在每个节点的样本数量与节点数量呈对数关系时，误差随节点数量亚线性增长。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [473] [Distributionally Robust System Level Synthesis With Output Feedback Affine Control Policy](https://arxiv.org/abs/2508.05466)
> *基于输出反馈仿射控制策略的分布鲁棒系统级综合*

*Yun Li, Jicheng Shi, Colin N. Jones, Neil Yorke-Smith, Tamas Keviczky* | **Category: eess.SY, math.OC** | **Updated: 2025-08-07**

**Keywords:** 分布鲁棒优化, 系统级综合, 输出反馈, 仿射控制, 鲁棒控制

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的基于输出反馈仿射控制策略的分布鲁棒系统级综合(DR-SLS)方法，用于线性系统的鲁棒最优控制，以应对模型失配和随机扰动，并通过数值实验验证了其性能和鲁棒性。

**AI_Comments:** 本文的创新点在于将输出反馈仿射控制策略引入到分布鲁棒系统级综合中，有效处理了模型失配和随机扰动下的不确定性。其重要性体现在提高了线性系统的鲁棒性和弹性。通过可处理的重构，该方法具有较强的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决线性系统在模型失配和附加随机扰动下的有限时域鲁棒最优控制问题，并通过最小化成本函数并确保在最坏情况不确定性分布下的约束满足来提高系统弹性。

**Method:** 本文利用系统级综合(SLS)参数化，提出了一种新颖的基于输出反馈仿射控制策略的SLS设计，并将其扩展到分布鲁棒设置。模型失配和随机扰动的范围分别使用1-范数和基于Wasserstein度量的模糊集进行量化。通过利用鲁棒控制和分布鲁棒优化(DRO)的工具，推导出了分布鲁棒SLS(DR-SLS)问题的可处理重构。

**Result:** 数值实验验证了所提出方法的性能和鲁棒性。

**Conclusion:** 所提出的基于输出反馈仿射控制策略的分布鲁棒系统级综合方法在处理线性系统面临模型失配和随机扰动时的鲁棒最优控制问题上表现出良好的性能和鲁棒性。

> **ai_Abstract:** 本研究提出了一种新颖的分布鲁棒系统级综合（DR-SLS）方法，该方法基于输出反馈仿射控制策略，旨在解决线性系统在模型失配和随机扰动下的有限时域鲁棒最优控制问题。通过利用SLS参数化、1-范数和Wasserstein度量量化不确定性，并结合鲁棒控制和分布鲁棒优化工具，文章推导了一个可处理的DR-SLS问题重构。数值实验验证了该方法的性能和鲁棒性，展示了其在提高系统弹性方面的潜力。

> **摘要翻译:** 本文研究了线性系统在模型失配和附加随机扰动下的有限时域鲁棒最优控制。利用系统级综合（SLS）参数化，我们提出了一种新颖的基于输出反馈仿射控制策略的SLS设计，并将其扩展到分布鲁棒设置，通过最小化成本函数同时确保在最坏情况不确定性分布下满足约束来提高系统弹性。模型失配和随机扰动的范围分别使用1-范数和基于Wasserstein度量的模糊集进行量化。对于闭环动力学，我们分析了预测输出-输入响应（使用名义参数和经验扰动样本计算）与实际闭环分布之间的分布漂移，强调其对模型失配和SLS参数化的依赖性。假设成本函数和约束是凸且Lipschitz连续的，我们通过利用鲁棒控制和分布鲁棒优化（DRO）的工具，推导出了分布鲁棒SLS（DR-SLS）问题的可处理重构。数值实验验证了所提出方法的性能和鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [489] [Design and Analysis of a Vanadium Dioxide-Based Ultra-Broadband Terahertz Metamaterial Absorber](https://arxiv.org/abs/2508.05590)
> *钒基超宽带太赫兹超材料吸波体的设计与分析*

*Robiul Hasan, Nafisa Anjum* | **Category: eess.SY, physics.app-ph, physics.optics** | **Updated: 2025-08-07**

**Keywords:** 太赫兹,超材料吸波体,二氧化钒,超宽带,动态可调

**Comment:** 

> **TL;DR:** 该论文提出了一种基于VO2的超宽带、偏振不敏感太赫兹超材料吸波体，具有高吸收率和动态可调性。

**AI_Comments:** 这篇论文的创新点在于利用VO2的相变特性实现了太赫兹超材料吸波体的动态可调性，同时兼顾了超宽带、高效率和偏振不敏感的性能。其简化的实现方式也增强了实用性，对于太赫兹技术在传感、成像和通信领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有太赫兹超材料吸波体可能存在带宽窄、效率低或实现复杂等问题。该研究旨在设计一种具有更宽带宽、更高效率和更简单实现方式的吸波体，以满足太赫兹传感、成像、无线通信和自适应光子系统等应用的需求。

**Method:** 该吸波体由图案化的VO2超表面、低损耗MF2介质间隔层和金基底组成。利用VO2的相变特性实现电磁吸收的动态控制。通过全波仿真进行性能分析，并进行阻抗分析和参数分析（VO2电导率、MF2厚度、晶胞周期性）。

**Result:** 全波仿真显示，在5.38THz带宽（5.72-11.11THz）内平均吸收率达98.15%，在3.35THz范围内吸收率超过99%。该吸波体在不同偏振角和斜入射下的TE和TM模式下均保持稳定性能。阻抗分析证实与自由空间强匹配，减少了反射并消除了透射。

**Conclusion:** 该设计实现了更宽的带宽、更高的效率和更简单的实现，适用于太赫兹传感、成像、无线通信和自适应光子系统，并有望成为可调谐和可重构太赫兹模块的有前景平台。

> **ai_Abstract:** 本文介绍了一种基于VO2的超宽带太赫兹超材料吸波体，利用VO2的相变特性实现动态吸收控制。该吸波体由VO2超表面、MF2介质和金基底构成。仿真结果表明，其在5.38THz带宽内平均吸收率高达98.15%，并能保持偏振不敏感和斜入射下的稳定性能。该设计具有更宽的带宽、更高的效率和更简单的实现，适用于多种太赫兹应用。

> **摘要翻译:** 本文提出了一种基于VO2的超材料吸波体，该吸波体经过优化，可在太赫兹（THz）频率范围内实现超宽带、偏振不敏感的性能。该吸波体由图案化的VO2超表面、低损耗MF2介质间隔层和金基底组成。利用VO2的相变特性，该设计能够实现电磁吸收的动态控制。全波仿真显示，在5.38THz带宽（5.72-11.11THz）内平均吸收率达98.15%，在3.35THz范围内吸收率持续超过99%。该吸波体在不同偏振角以及斜入射下的TE和TM模式下均保持稳定性能。阻抗分析证实与自由空间强匹配，减少了反射并消除了透射。参数分析研究了VO2电导率、MF2厚度和晶胞周期性对性能的影响。与近期太赫兹超材料吸波体相比，所提出的设计实现了更宽的带宽、更高的效率和更简单的实现。这些特性使其适用于太赫兹传感、成像、无线通信和自适应光子系统，并使其成为可调谐和可重构太赫兹模块的有前景平台。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [497] [On the effects of angular acceleration in orientation estimation using inertial measurement units](https://arxiv.org/abs/2502.03681)
> *基于惯性测量单元的姿态估计中角加速度效应的研究*

*Felix Brändle, David Meister, Marc Seidel, Robin Strässer, Frank Allgöwer* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 姿态估计, 惯性测量单元, 角加速度, 非最小相位, 滤波器动力学

**Comment:** 

> **TL;DR:** 角加速度引起的线加速度会改变姿态估计滤波器动力学，导致非最小相位行为，影响性能。

**AI_Comments:** 这篇论文揭示了IMU姿态估计中一个关键且常被忽视的问题：角加速度引起的线加速度对滤波器动态的深层次影响，而非简单的外部扰动。其创新点在于将这种影响量化为传递函数中的额外零点和非最小相位行为，这对于姿态控制和滤波器设计具有重要指导意义。此外，对现有滤波器（Mahony和Madgwick）的分析及其对验证方法局限性的指出，也为未来研究提供了宝贵启示。

<details>
  <summary>Details</summary>

**Motivation:** 许多姿态估计算法在重力以外的加速度影响下性能下降。本文旨在分析角加速度对姿态估计的影响，特别是其引起的线加速度如何改变滤波器的动态行为。

**Method:** 本文分析了惯性测量单元（IMU）姿态估计问题，并通过实验验证了发现。具体分析了角加速度引起的线加速度对滤波器动态行为的影响，以及Mahony和Madgwick滤波器对加速度的衰减能力。

**Result:** 角加速度引起的线加速度不能被视为外部干扰，而是改变了滤波器自身的动态行为；这导致线性化传递函数中引入额外的零点，进而产生非最小相位行为；Mahony和Madgwick滤波器可以衰减加速度，但代价是带宽降低；基于预收集数据的验证方案未能准确捕捉这些闭环效应。

**Conclusion:** 角加速度引起的线加速度对IMU姿态估计的滤波器动态行为有根本性影响，导致非最小相位行为，需要更深入的理解和处理。传统的验证方法可能无法充分揭示这些效应。

> **ai_Abstract:** 本文深入分析了惯性测量单元（IMU）姿态估计中角加速度效应。研究表明，由角加速度产生的线性加速度并非简单的外部干扰，而是会改变滤波器自身的动态特性，引入额外的零点，导致系统出现非最小相位行为，这给控制带来了挑战。实验验证了这些发现，并指出Mahony和Madgwick滤波器虽然能衰减加速度，但会牺牲带宽。同时，文章强调了基于预收集数据的验证方法在捕捉这些闭环效应方面的局限性。

> **摘要翻译:** 本文分析了使用惯性测量单元进行姿态估计的问题。许多估计算法在重力以外的加速度影响下性能会下降。我们发现，由旋转加速度引起的线性加速度不能被视为需要衰减的外部干扰，相反，它们改变了滤波器本身的动态行为。特别是，这导致在线性化传递函数中引入额外的零点。这些零点导致非最小相位行为，这在控制领域是众所周知的挑战。我们通过实验验证了这些发现。此外，我们证明Mahony和Madgwick滤波器可以衰减加速度，但代价是带宽降低。此外，我们还表明，基于预收集数据的验证方案未能准确捕捉这些闭环效应。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [503] [A Time Splitting Based Optimization Method for Nonlinear MHE](https://arxiv.org/abs/2503.23324)
> *一种基于时间分裂的非线性移动视界估计优化方法*

*Shuting Wu, Yifei Wang, Jingzhe Wang, Apostolos I. Rikos, Xu Du* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 移动视界估计, 时间分裂, 非线性优化, 分布式算法, 实时性

**Comment:** 

> **TL;DR:** 本文针对非线性移动视界估计（MHE）计算量大的问题，提出三种新的高效算法：基于时间分裂的ALADIN、高效灵敏度辅助ALADIN以及分布式SQP，通过数值实验证明这些方法在保持高精度的同时显著提高了计算效率。

**AI_Comments:** 该论文创新性地将时间分裂技术应用于非线性MHE问题，并通过提出三种不同适应性的优化算法（ALADIN、其变体和SQP）有效解决了传统MHE面临的“维度灾难”和计算效率低下的挑战。其方法考虑了不同计算能力限制下的实际应用场景，具有很强的实用价值。通过在机器人案例上的验证，证明了其在实际系统中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的移动视界估计（MHE）方法因问题复杂性和时间视界增长导致的“维度灾难”而计算成本过高，无法满足实时性要求。因此，需要开发计算效率更高的方法来解决非线性MHE问题。

**Method:** 本文首先引入了一种利用时间分裂技术进行分布式重构的方法。基于此重构，开发了高效高斯-牛顿增广拉格朗日交替方向不精确牛顿（ALADIN）算法。此外，针对子问题求解器计算能力有限的情况，提出了高效灵敏度辅助ALADIN算法，允许不精确求解子问题。对于子问题求解器无计算能力的情景，提出了一种仅依赖局部目标函数一阶和二阶信息的分布式序列二次规划（SQP）算法。

**Result:** 通过在差速驱动机器人案例（一个实际的非线性MHE问题）上的数值实验，结果表明所提出的三种算法在保持高精度的同时实现了计算效率，从而满足了MHE的实时要求。

**Conclusion:** 本文提出的三种基于时间分裂的优化算法，即高效ALADIN、高效灵敏度辅助ALADIN和分布式SQP，有效地解决了非线性MHE计算成本高昂的问题，在实际应用中能够满足实时性和高精度的双重需求。

> **ai_Abstract:** 本文针对非线性移动视界估计（MHE）中传统方法计算成本过高的问题，提出了一系列基于时间分裂的优化算法。通过引入分布式重构，作者开发了高效高斯-牛顿增广拉格朗日交替方向不精确牛顿（ALADIN）算法。针对计算能力受限的情况，进一步提出了高效灵敏度辅助ALADIN算法，允许子问题不精确求解。对于无计算能力的子问题求解器，则提出了分布式序列二次规划（SQP）算法。数值实验证明，这些新方法能够显著提高计算效率，同时保持高精度，满足MHE的实时应用需求。

> **摘要翻译:** 移动视界估计（MHE）本质上是一种基于优化的方法，旨在估计动态系统在移动时间视界内的状态。传统的MHE解决方案由于问题复杂性增加和时间视界长度增长导致的“维度灾难”，计算成本变得令人望而却步。为了解决这个问题，我们提出了新颖的计算高效算法来解决非线性MHE问题。具体来说，我们首先引入了一种利用时间分裂技术进行分布式重构的方法。利用这种重构，我们开发了高效高斯-牛顿增广拉格朗日交替方向不精确牛顿（ALADIN）算法以实现计算效率。此外，为了适应某些子问题求解器固有的有限计算能力，我们提出了高效灵敏度辅助ALADIN算法，该算法允许不精确求解子问题而不妨碍计算效率。此外，考虑到子问题求解器不具备计算能力的情况，我们提出了一种仅依赖局部目标函数一阶和二阶信息的分布式序列二次规划（SQP）算法。我们通过在差速驱动机器人案例（一个实际的非线性MHE问题）上的数值实验，证明了我们所提出方法的性能和优势。我们的结果表明，所提出的三种算法在保持高精度的同时实现了计算效率，从而满足了MHE的实时要求。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [509] [Data-Driven Distributed Output Synchronization of Heterogeneous Discrete-Time Multi-Agent Systems](https://arxiv.org/abs/2503.24105)
> *数据驱动的异构离散时间多智能体系统分布式输出同步*

*Giulio Fattore, Maria Elena Valcher* | **Category: eess.SY** | **Updated: 2025-08-07**

**Keywords:** 数据驱动, 分布式控制, 输出同步, 多智能体系统, 离散时间

**Comment:** 

> **TL;DR:** 研究数据驱动的分布式控制律，使异构离散时间多智能体系统的输出与参考输出同步。

**AI_Comments:** 该研究创新性地将数据驱动方法应用于异构多智能体系统的分布式输出同步问题，考虑了领导者-跟随者结构以及不同的观测器设计。其重要性在于为复杂多智能体系统在缺乏精确模型时的控制提供了理论基础和实用方法。

<details>
  <summary>Details</summary>

**Motivation:** 在离散时间异构LTI多智能体系统中，设计一种分布式数据驱动控制律，以使智能体的输出与自主外生系统生成的参考输出同步。

**Method:** 将网络中的智能体分为领导者和跟随者两类，其中领导者可以直接访问外生系统输出，而跟随者仅从邻居获取信息。通过利用自身状态和内部状态观测器提供的外生系统状态估计的状态反馈，使所有智能体实现输出同步。领导者和跟随者的观测器结构不同。解决方案存在的必要和充分条件首先在基于模型的设置中推导，然后在一个数据驱动的上下文中推导。

**Result:** 推导了在基于模型和数据驱动背景下，所提出控制律解决方案存在的必要和充分条件。通过一个例子说明了所提出方法的实现过程和性能。

**Conclusion:** 本文成功提出了数据驱动的分布式控制律，实现了异构离散时间多智能体系统的输出同步，并推导了其存在的条件。

> **ai_Abstract:** 本文研究了离散时间异构多智能体系统的数据驱动分布式输出同步问题。通过设计一种分布式数据驱动控制律，使智能体（包括领导者和跟随者）的输出与自主外生系统的参考输出同步。该方法利用状态反馈和内部状态观测器，并推导了解决方案在基于模型和数据驱动环境下的存在条件。

> **摘要翻译:** 本文假设一个自主外生系统生成一个参考输出，我们考虑为通过有向图连接的一系列离散时间异构LTI智能体设计一种分布式数据驱动控制律的问题，以使智能体的输出与参考输出同步。网络中的智能体分为两类：领导者，可以直接访问外生系统输出；跟随者，只从其邻居接收信息。所有智能体都旨在通过状态反馈实现输出同步，该状态反馈利用它们自身的状态以及由内部状态观测器提供的外生系统状态估计。这种观测器对于领导者和跟随者具有不同的结构。解决方案存在的必要和充分条件首先在基于模型的设置中推导，然后在一个数据驱动的上下文中推导。一个例子说明了所提出方法的实现过程和性能。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [527] [Robust Regret Optimal Control](https://arxiv.org/abs/2307.14297)
> *鲁棒后悔最优控制*

*Jietian Liu, Peter Seiler* | **Category: eess.SY, math.OC** | **Updated: 2025-08-07**

**Keywords:** 鲁棒后悔, 最优控制, 不确定系统, H∞性能, DK迭代

**Comment:** 

> **TL;DR:** 本文提出了一种针对不确定离散时间线性时不变系统的鲁棒后悔最优控制综合方法，通过满足鲁棒H∞性能条件实现，并利用DK迭代法合成控制器，通过多个工程示例验证了其有效性。

**AI_Comments:** 本文将鲁棒控制中的H∞性能条件与后悔最优控制结合，提出了鲁棒后悔的概念，并提供了DK迭代这一成熟的鲁棒控制合成工具，为不确定系统下的最优控制提供了一种新的、实用的设计方法。其创新之处在于将后悔最优这一概念拓展到鲁棒控制领域，并提供了可操作的合成方法。

<details>
  <summary>Details</summary>

**Motivation:** 针对不确定系统，旨在合成一种控制器，使其性能相对于已知扰动的最优非因果控制器而言，能够实现鲁棒后悔最优。

**Method:** 本文提出了一种鲁棒后悔最优控制的综合方法。将设备建模为离散时间不确定线性时不变(LTI)系统。定义鲁棒后悔是相对于利用名义设备模型和已知扰动信息构建的最优非因果控制器的性能。研究表明，控制器实现鲁棒后悔当且仅当其满足鲁棒H∞性能条件。DK迭代法可用于合成满足此条件并达到给定鲁棒后悔水平的控制器。

**Result:** 证明了控制器实现鲁棒后悔当且仅当其满足鲁棒H∞性能条件。DK迭代法可以用于合成此类控制器。该方法通过三个例子进行了验证：一个简单的单输入单输出经典设计、波音747简化模型的纵向控制以及四分之一汽车模型的主动悬架。所有示例都将鲁棒后悔最优控制器与未考虑不确定性设计的后悔最优控制器进行了比较。

**Conclusion:** 本文成功提出了鲁棒后悔最优控制的综合方法，并将其与鲁棒H∞性能条件建立了等价关系，提供了DK迭代的合成途径，并通过多个实际工程案例验证了其有效性。

> **ai_Abstract:** 本文提出了一种针对不确定离散时间线性时不变系统的鲁棒后悔最优控制综合方法。研究定义了鲁棒后悔，并证明了控制器实现鲁棒后悔等价于满足鲁棒H∞性能条件。论文指出DK迭代法可用于合成此类控制器，并通过三个工程示例（包括飞行器和汽车悬架控制）验证了该方法的有效性，并与未考虑不确定性的后悔最优控制器进行了比较。

> **摘要翻译:** 本文提出了一种鲁棒后悔最优控制的综合方法。设备在离散时间中通过不确定线性时不变（LTI）系统建模。利用名义设备模型和给定扰动的完整知识，构建了一个最优非因果控制器。鲁棒后悔被定义为相对于该最优非因果控制的性能。研究表明，控制器实现鲁棒后悔当且仅当它满足鲁棒H∞性能条件。DK迭代法可用于合成满足此条件从而达到给定鲁棒后悔水平的控制器。该方法通过三个例子进行了演示：（i）一个简单的单输入单输出经典设计，（ii）波音747简化模型的纵向控制，以及（iii）四分之一汽车模型的主动悬架。所有例子都将鲁棒后悔最优控制器与未考虑不确定性设计的后悔最优控制器进行了比较。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [533] [Data-driven control of a magnetohydrodynamic flow](https://arxiv.org/abs/2507.12479)
> *磁流体动力学流动的数据驱动控制*

*Adam Uchytil, Milan Korda, Jiří Zemánek* | **Category: eess.SY, physics.flu-dyn** | **Updated: 2025-08-07**

**Keywords:** 磁流体动力学控制, 数据驱动, Koopman算子理论, 模型预测控制, 实时控制

**Comment:** 

> **TL;DR:** 研究通过数据驱动的Koopman理论和模型预测控制，实现了弱导电磁流体动力学流动的实时反馈控制，并能使其匹配预设流场。

**AI_Comments:** 这篇论文的创新点在于将Koopman算子理论应用于磁流体动力学流动的控制，实现了非线性系统的数据驱动线性化，从而使得模型预测控制能够高效实施。其在标准笔记本电脑上实现实时控制的能力，展示了该方法在实际应用中的巨大潜力，尤其是在需要精确流体控制的工业或科研领域。

<details>
  <summary>Details</summary>

**Motivation:** 控制弱导电磁流体动力学（MHD）流动，使其达到预设的速度或涡度模式。

**Method:** 采用模型预测控制（MPC）框架，利用Koopman算子理论从数据中构建预测器，将非线性流体动力学线性化。这使得MPC问题可以通过交替求解两个小的凸二次规划（QPs）来高效解决。通过电极阵列和电磁体施加洛伦兹力，并使用平面粒子图像测速（PIV）提供反馈。

**Result:** 所开发的控制器能够在标准笔记本电脑上以闭环方式运行，实现流动的实时控制。实验证明该方法能够将流动塑造成与一系列参考速度场和时变涡度场匹配。

**Conclusion:** 通过数据驱动的Koopman理论结合模型预测控制，可以有效地实现弱导电磁流体动力学流动的实时、精确控制，并能使其匹配复杂的流场模式。

> **ai_Abstract:** 本文提出了一种数据驱动的磁流体动力学（MHD）流动控制方法。通过结合Koopman算子理论构建的线性预测器和模型预测控制（MPC）框架，实现了对弱导电MHD流动的实时反馈控制。该方法利用电极和电磁体产生的洛伦兹力来引导流体，并通过粒子图像测速（PIV）获取反馈。Koopman理论将复杂的非线性流体动力学线性化，从而使MPC问题能高效求解。实验证明，该控制器能在标准笔记本电脑上实时运行，成功地将流动塑造成预设的速度或涡度模式。

> **摘要翻译:** 我们展示了通过外部施加的电场和磁场产生的洛伦兹力，对弱导电磁流体动力学（MHD）流动进行反馈控制。具体来说，我们使用围绕和位于流体储层下方布置的电极和电磁体阵列，将电解质的流动引导至预设的速度或涡度模式，并通过平面粒子图像测速（PIV）提供反馈。控制是使用模型预测控制（MPC）框架实现的，其中控制信号通过最小化流体预测演化过程中的成本函数来计算。预测器完全根据数据使用Koopman算子理论构建，该理论能够对底层非线性流体动力学进行线性表示。这种线性化允许MPC问题通过在两个小型且可高效求解的凸二次规划（QPs）之间交替来解决：一个用于电极，一个用于电磁体。由此产生的控制器在标准笔记本电脑上以闭环方式运行，实现了流动的实时控制。我们通过实验证明了该方法的功能性，在实验中，流动被塑造成匹配一系列参考速度场和一个时变涡度场。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [7] [A simple linear convergence analysis of the randomized reshuffling Kaczmarz method](https://arxiv.org/abs/2410.01140)
> *随机重排Kaczmarz方法的一种简单线性收敛性分析*

*Deren Han, Jiaxin Xie* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 随机重排Kaczmarz, 线性收敛, 最小范数解, 收敛上界, 随机重排

**Comment:** 

> **TL;DR:** 本文对随机重排Kaczmarz (RRK) 方法进行了新的分析，并证明了其线性收敛性，收敛上界紧密且不依赖于矩阵维度。

**AI_Comments:** 本文的关键创新在于首次对随机重排Kaczmarz (RRK) 方法进行了全面的线性收敛性分析，并得出了紧密且与维度无关的收敛上界。这对于理解和应用RRK方法具有重要意义，因为它填补了现有研究的空白，并提供了更强的理论保证。其结果对于大规模线性系统的求解算法研究具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有的随机重排Kaczmarz (RRK) 方法研究未能全面刻画其收敛性。

**Method:** 本文对随机重排Kaczmarz (RRK) 方法进行了新颖的分析，并证明了其线性收敛性。

**Result:** RRK方法以线性速度收敛到线性系统的唯一最小范数解。其收敛上界是紧密的，并且不依赖于系数矩阵的维度。

**Conclusion:** 本文证明了随机重排Kaczmarz (RRK) 方法的线性收敛性，并提供了紧密且与维度无关的收敛上界，从而全面刻画了其收敛行为。

> **ai_Abstract:** 本文针对随机重排Kaczmarz (RRK) 方法现有研究中收敛性刻画不全面的问题，提出了一种新颖的分析方法。研究证明了RRK方法能够以线性速度收敛到线性系统的唯一最小范数解。此外，本文还指出其收敛上界是紧密的，并且独立于系数矩阵的维度，这为RRK方法的理论分析提供了更全面的理解。

> **摘要翻译:** 随机重排Kaczmarz (RRK) 方法作为一种Kaczmarz型方法，在求解线性系统方面具有简单性和高效性，同时它也继承了带有随机重排 (RR) 的随机梯度下降 (SGD) 相较于原始SGD的实际改进。然而，当前对RRK的研究未能全面刻画其收敛性。在本文中，我们对RRK方法进行了新颖的分析，并证明了其向线性系统唯一最小范数解的线性收敛性。此外，收敛上界是紧密的，并且不依赖于系数矩阵的维度。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [14] [On the choice of optimization norm for Anderson acceleration of the Picard iteration for Navier-Stokes equations](https://arxiv.org/abs/2505.07650)
> *关于 Navier-Stokes 方程 Picard 迭代的 Anderson 加速优化范数选择*

*Elizabeth Hawkins, Leo Rebholz* | **Category: math.NA** | **Updated: 2025-08-06**

**Keywords:** Anderson 加速, Picard 迭代, Navier-Stokes 方程, 优化范数, 收敛理论

**Comment:** 

> **TL;DR:** 本文研究了 Navier-Stokes 方程 Picard 迭代的 Anderson 加速中优化范数的选择，发现计算效率更高的 $L^2$/$\ell^2$ 范数在收敛性上与理论上更复杂的 $H^1_0$ 范数效果相当，从而证明了在大型问题中使用更简单范数的合理性。

**AI_Comments:** 本文的创新之处在于，它从理论和数值两方面证明了在 Navier-Stokes 方程的 Anderson 加速 Picard 迭代中，可以使用计算成本更低的 $L^2$/$\ell^2$ 范数替代传统的 $H^1_0$ 范数，而不会牺牲收敛性能。这对于解决大规模科学计算问题具有重要的实际意义，因为它能显著提高计算效率。该研究通过改进现有理论并提出新理论，为实际应用提供了坚实的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** Anderson 加速 (AA) 的现有收敛理论假设 AA 优化范数与定点函数定义的 Hilbert 空间范数匹配，但在大型高性能计算 (HPC) 环境中，如 Navier-Stokes 方程 (NSE) 的 Picard 迭代，对应的 $H^1_0(\Omega)$ 范数实现效率低下。最近的数值测试表明使用 $\ell^2$ 范数也能产生相似的收敛行为，这促使作者重新审视该问题。

**Method:** 作者重新审视了 [Pollock et al, SINUM 2019] 的收敛理论，并通过对非线性项的更精确处理对其进行了改进。此外，针对 AA 优化范数改为 $L^2$ (以及 $\ell^2$ 或使用对角块质量矩阵的 $L^2$) 的情况，开发了新的收敛理论。

**Result:** 研究发现：i) 现有理论可以通过对非线性项的更精确处理进行改进；ii) 当 AA 优化范数改为 $L^2$ (或 $\ell^2$ 或使用对角块质量矩阵的 $L^2$) 时，开发的新收敛理论提供了与 $H^1_0$ 情况基本等效的估计。数值测试也证实了新理论，并表明 $H^1_0$、$L^2$、$\ell^2$ 或使用对角块质量矩阵的 $L^2$ 范数在 AA 优化问题中可以互换使用，而不会显著影响整体收敛行为。

**Conclusion:** 在 Navier-Stokes 方程的大型问题中，Anderson 加速 Picard 迭代的 AA 优化范数可以合理地使用 $\ell^2$ 或对角块 $L^2$ 范数。

> **ai_Abstract:** 本文研究了 Navier-Stokes 方程 Picard 迭代的 Anderson 加速中优化范数的选择问题。针对 $H^1_0(\Omega)$ 范数在大型 HPC 环境中效率低下的问题，作者重新审视了现有理论并进行了改进，同时为使用计算效率更高的 $L^2$/$\ell^2$ 范数开发了新的收敛理论。研究结果表明，在收敛性方面，$H^1_0$、$L^2$、$\ell^2$ 或使用对角块质量矩阵的 $L^2$ 范数可以互换使用，从而证明了在大型 Navier-Stokes 问题中采用更简单、更高效的 $\ell^2$ 或对角块 $L^2$ 范数进行 Anderson 加速的合理性。

> **摘要翻译:** Anderson 加速 (AA) 最近发展的收敛理论假设 AA 优化范数与定点函数定义的 Hilbert 空间的范数匹配。虽然这似乎是一个自然的假设，但就迭代收敛或计算效率而言，它可能不是最佳选择。对于 Navier-Stokes 方程 (NSE) 的 Picard 迭代，相关的 Hilbert 空间范数是 $H^1_0(\Omega)$，这在大型 HPC 环境中实现效率低下，因为它需要全局系数向量与刚度矩阵的乘法。受最近数值测试的启发，这些测试表明使用 $\ell^2$ 范数产生的收敛行为与 $H^1_0$ 相似，我们重新审视了 [Pollock et al, SINUM 2019] 的收敛理论，并发现：i) 可以通过对非线性项的更精确处理进行改进；ii) 在 AA 优化范数改为 $L^2$ (以及通过扩展 $\ell^2$ 或使用对角块质量矩阵的 $L^2$) 的情况下，开发了一种新的收敛理论，该理论提供了与 $H^1_0$ 情况基本等效的估计。多项数值测试说明了新理论，理论和测试表明，在 AA 优化问题中，可以互换使用 $H^1_0$、$L^2$、$\ell^2$ 或使用对角块质量矩阵的 $L^2$ 范数，而不会显著影响整体收敛行为。因此，在 Navier-Stokes 方程的大型问题中，Anderson 加速 Picard 迭代的 AA 优化范数使用 $\ell^2$ 或对角块 $L^2$ 是合理的。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [803] [On the optimization of discrepancy measures](https://arxiv.org/abs/2508.04926)
> *关于差异度量优化的研究*

*François Clément, Nathan Kirk, Art B. Owen, T. Konstantin Rusch* | **Category: math.NA, math.OC** | **Updated: 2025-08-06**

**Keywords:** 差异度量, $L_2$星型差异度, 平均平方差异度, 低差异点集, 数值优化

**Comment:** 

> **TL;DR:** 本文引入了一种新的差异度量——平均平方差异度，它解决了现有度量计算成本高、缺乏可微性及病态等问题，并通过数值研究证明其在优化性能上的优越性。

**AI_Comments:** 本文创新性地提出了平均平方差异度，有效解决了现有差异度量在计算和理论上的缺陷。通过引入平均化策略，不仅改善了计算效率和可微性，还成功规避了J. Matoušek指出的病态问题。其重要性在于为低差异点集的构建提供了一个更鲁棒、更高效的优化准则，对数值积分和蒙特卡洛方法等领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的$L_\infty$星型差异度计算昂贵且不可微，而$L_2$星型差异度虽然平滑但存在J. Matoušek指出的病态问题。本文旨在解决这些现有差异度量在计算和性质上的缺陷。

**Method:** 本文引入了“平均平方差异度”（average squared discrepancy）。该方法通过对锚定在$[0,1]^d$不同顶点的$2^d$个$L_2$星型差异度版本进行平均。它可以在$O(dn^2)$时间内计算，并且被证明等价于Hickernell的加权对称$L_2$准则（相差一个常数因子）。

**Result:** 平均平方差异度与传统差异度量进行比较后发现，只有它能避免Matoušek提出的问题。此外，全面的数值研究表明，优化平均平方差异度可以为$L_2$星型差异度带来强大的性能，反之则不然。

**Conclusion:** 平均平方差异度是一种优越的差异度量，它克服了现有度量在计算效率和病态方面的缺点，并且在优化性能上表现出色，尤其能有效提升$L_2$星型差异度的性能。

> **ai_Abstract:** 本文针对传统差异度量（如$L_\infty$和$L_2$星型差异度）存在的计算复杂、缺乏可微性及病态等问题，提出了一种新的差异度量——平均平方差异度。该度量通过对多个$L_2$星型差异度版本进行平均，实现了$O(dn^2)$的计算复杂度，并被证明与现有加权对称$L_2$准则等价。数值研究表明，平均平方差异度能够有效避免传统度量的病态问题，并且在优化时能显著提升$L_2$星型差异度的性能。

> **摘要翻译:** 在单位立方体中，低差异度的点集可以通过代数方法或最近通过直接计算优化准则来构建。通常的$L_\infty$星型差异度不适用于此，因为它计算成本高且缺乏可微性。其通常的替代品，$L_2$星型差异度，虽然平滑但表现出J. Matoušek所示的其他病态。为了解决这些问题，我们引入了“平均平方差异度”，它平均了锚定在$[0,1]^d$不同顶点的$2^d$个$L_2$星型差异度版本。这个准则不仅可以像$L_2$星型差异度一样在$O(dn^2)$时间内计算，而且我们还证明它与Hickernell的加权对称$L_2$准则等价，相差一个常数因子。我们将此准则与各种传统差异度量进行比较，并表明只有平均平方差异度避免了Matoušek提出的问题。此外，我们进行了一项全面的数值研究，特别表明优化平均平方差异度可以为$L_2$星型差异度带来强大的性能，而反之则不然。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [808] [Toroidal area-preserving parameterizations of genus-one closed surfaces](https://arxiv.org/abs/2508.05111)
> *环形保面积亏格一闭曲面参数化*

*Marco Sutti, Mei-Heng Yueh* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 环形参数化, 面积保持, 亏格一曲面, 黎曼几何, 优化算法

**Comment:** 

> **TL;DR:** 该论文提出了四种基于黎曼几何的算法，用于计算亏格一闭曲面的环形保面积参数化，并在数值实验中验证了其有效性，并展示了其在曲面配准和纹理映射中的应用。

**AI_Comments:** 该论文的创新点在于将黎曼几何方法应用于环形保面积参数化问题，并提出了多种优化算法。其重要性体现在为几何处理和计算机图形学中的曲面配准和纹理映射提供了新的工具。论文通过数值实验验证了方法的有效性，并展示了实际应用，结构完整，方法新颖。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决亏格一闭曲面环形保面积参数化的计算问题。

**Method:** 该论文提出了四种基于黎曼几何的算法：投影梯度下降法、投影共轭梯度法、黎曼梯度法和黎曼共轭梯度法。目标函数基于拉伸能量泛函，最小化过程受限于嵌入三维欧几里得空间中的环形环面幂流形。

**Result:** 在多个网格模型上的数值实验表明，所提出的框架是有效的。

**Conclusion:** 该论文成功提出了有效的算法来计算亏格一闭曲面的环形保面积参数化，并展示了这些算法在曲面配准和纹理映射应用中的潜力。

> **ai_Abstract:** 该研究探讨了亏格一闭曲面的环形保面积参数化计算问题，并提出了四种基于黎曼几何的优化算法，包括投影梯度下降法和黎曼共轭梯度法。这些算法以拉伸能量泛函为目标函数，并在特定幂流形上进行约束最小化。数值实验验证了所提框架的有效性，并展示了其在曲面配准和纹理映射中的应用潜力。

> **摘要翻译:** 我们考虑计算亏格一闭曲面的环形保面积参数化问题。我们提出了四种基于黎曼几何的算法：投影梯度下降法、投影共轭梯度法、黎曼梯度法和黎曼共轭梯度法。我们的目标函数基于拉伸能量泛函，最小化过程受限于嵌入三维欧几里得空间中的环形环面幂流形。在多个网格模型上的数值实验证明了所提出框架的有效性。最后，我们展示了如何将所提出的算法应用于曲面配准和纹理映射。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [813] [An asymptotic-preserving active flux scheme for the hyperbolic heat equation in the diffusive scaling](https://arxiv.org/abs/2508.05166)
> *扩散尺度下双曲热方程的渐近保真主动通量格式*

*Junming Duan, Wasilij Barsukow, Christian Klingenberg* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 主动通量方法, 渐近保真, 双曲热方程, 扩散尺度, 雅可比分裂

**Comment:** 

> **TL;DR:** 本文证明了基于雅可比分裂的主动通量（AF）方法在无需修改的情况下，对于求解扩散尺度下的双曲热方程具有渐近保真（AP）特性。

**AI_Comments:** 本文的创新之处在于证明了未经修改的基于雅可比分裂的主动通量（AF）方法在扩散尺度下求解双曲热方程时具有渐近保真（AP）特性。这对于该方法在多尺度问题中的应用具有重要意义，因为它表明了该方案在不同尺度下数值行为的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 主动通量（AF）方法相对于标准有限体积方案具有保持结构（structure-preserving）的优势，这促使研究其在扩散尺度下的渐近保真（AP）行为。

**Method:** 采用线法进行时间离散化，并使用依赖雅可比分裂（JS）方法更新点值。通过形式渐近分析、离散傅里叶分析和数值实验来验证研究结果。

**Result:** 结果表明，基于雅可比分裂（JS）的主动通量（AF）方法在未经任何修改的情况下，对于求解双曲热方程具有渐近保真（AP）特性，即其极限格式是极限热方程的离散化。

**Conclusion:** 基于雅可比分裂的主动通量（AF）方法在无需修改的情况下，对于求解双曲热方程具有渐近保真（AP）特性。

> **ai_Abstract:** 本文研究了主动通量（AF）方法在扩散尺度下求解双曲热方程的渐近保真（AP）行为。该研究发现，采用雅可比分裂（JS）方法更新点值的AF方案，无需任何修改即可展现出AP特性，即其极限格式能有效离散化极限热方程。研究结果通过形式渐近分析、离散傅里叶分析和数值实验进行了验证。

> **摘要翻译:** 主动通量（AF）方法是一种紧凑、高阶的有限体积格式，通过引入单元界面处的点值作为除了单元平均值之外的额外自由度来增强灵活性。本文采用线法进行时间离散化。更新点值的常用方法依赖于雅可比分裂（JS）方法，该方法包含了迎风技术。AF方法相对于标准有限体积方案的一个关键优势是其保持结构（structure-preserving）的特性，这促使研究其在扩散尺度下的渐近保真（AP）行为。我们证明了基于JS的AF方法在未经任何修改的情况下，对于求解双曲热方程具有AP特性，其意义在于极限格式是极限热方程的离散化。我们使用形式渐近分析、离散傅里叶分析和数值实验来阐明我们的发现。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [818] [An Investigation into the Distribution of Ratios of Particle Solver-based Likelihoods](https://arxiv.org/abs/2508.05303)
> *粒子求解器似然比分布的研究*

*Emil Løvbak, Sebastian Krumscheid* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** Metropolis-Hastings, 贝叶斯逆问题, 粒子求解器, 似然函数, 高斯噪声

**Comment:** 

> **TL;DR:** 本文研究了在似然函数随机的贝叶斯逆问题中，Metropolis-Hastings算法中近似似然比分布受到的影响，该近似似然比由粒子蒙特卡罗模拟产生并带有高斯噪声。

**AI_Comments:** 本文的创新点在于深入探讨了在似然函数具有随机性的贝叶斯逆问题中，粒子求解器产生的近似似然比的分布特性。这对于理解和改进Metropolis-Hastings算法在处理带有噪声或近似似然函数时的性能至关重要。其重要性体现在为实际应用中处理复杂随机模型提供了理论基础和分析工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究在似然函数是随机的贝叶斯逆问题中，使用Metropolis-Hastings算法进行后验分布采样时，近似似然评估比率的分布如何受到两种高斯分布的影响，因为这对于评估Metropolis-Hastings算法中的接受概率至关重要。

**Method:** 通过Metropolis-Hastings算法采样后验分布，其中似然函数通过基于粒子的蒙特卡罗模拟近似。具体考虑了偏微分方程（一维扩散方程）解的全场观测，并假设观测误差为高斯分布。研究方法包括理论分析和数值实验。

**Result:** 本文研究了在对数似然中具有附加高斯噪声的近似似然函数，以及观测误差的高斯分布，如何影响Metropolis-Hastings算法中所需近似似然评估比率的分布。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了在似然函数随机的贝叶斯逆问题中，使用Metropolis-Hastings算法采样后验分布时遇到的挑战。当似然函数通过粒子蒙特卡罗模拟近似时，对数似然中会引入附加的高斯噪声。研究重点是分析观测误差和粒子模拟引入的这两种高斯噪声如何影响Metropolis-Hastings算法中接受概率所需的近似似然评估比率的分布。研究通过理论分析和数值实验相结合的方式进行。

> **摘要翻译:** 我们研究了在贝叶斯逆问题中使用Metropolis-Hastings算法对后验分布进行采样，其中似然函数是随机的。具体来说，我们考虑了当对偏微分方程（一维扩散方程）解进行全场观测时，存在高斯观测误差的情况。假设在近似似然函数时使用了基于粒子的蒙特卡罗模拟，那么会得到一个在对数似然中带有附加高斯噪声的近似似然。我们研究了这两种高斯分布如何影响近似似然评估比率的分布，因为这在Metropolis-Hastings算法中评估接受概率时是必需的。我们通过理论分析和数值实验来完成这项工作。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [823] [A low-rank solver for the Stokes-Darcy model with random hydraulic conductivity and Beavers-Joseph condition](https://arxiv.org/abs/2508.05328)
> *随机水力传导率和Beavers-Joseph条件的Stokes-Darcy模型的低秩求解器*

*Yujun Zhu, Yulan Ning, Zhipeng Yang, Xiaoming He, Ju Ming* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** Stokes-Darcy模型, 低秩近似, 随机模型, 随机水力传导率, Beavers-Joseph条件

**Comment:** 

> **TL;DR:** 本文提出了一种高效的低秩求解器，用于解决随机Stokes-Darcy模型，该求解器能够显著降低计算成本和内存需求，同时保持高精度。

**AI_Comments:** 该论文的创新之处在于利用广义低秩近似解决了带有随机参数的随机Stokes-Darcy模型所面临的计算挑战。这种方法在计算成本和内存方面提供了显著的效率提升，这对于大规模模拟至关重要。论文还解决了选择最佳压缩比的实际问题，并提供了理论误差分析，增强了所提出方法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为随机Stokes-Darcy界面模型开发一种高效的求解器，特别是考虑到随机水力传导率和各种界面条件，旨在降低计算成本和内存需求。

**Method:** 采用新颖的广义低秩近似来处理大规模刚度矩阵；提出确定最佳数据压缩比的策略；进行误差分析；通过数值实验验证。

**Result:** 低秩求解器在不损失精度的情况下，显著降低了矩阵求逆的计算成本和内存需求；能够以相对较低的计算和空间复杂度保持较高的数值精度。

**Conclusion:** 所提出的低秩求解器对随机Stokes-Darcy模型高效且精确，并通过数值实验和理论分析得到了验证。

> **ai_Abstract:** 本文提出了一种高效的低秩求解器，用于随机Stokes-Darcy界面模型，该模型考虑了多孔介质域和界面上的随机水力传导率，包括Beavers-Joseph条件。该求解器利用新颖的广义低秩近似处理刚度矩阵，显著降低了计算成本和内存需求，同时保持了精度。论文还提供了确定最佳数据压缩比的策略，进行了误差分析，并通过数值实验验证了该方法。

> **摘要翻译:** 本文提出、分析并演示了一种高效的低秩求解器，用于随机Stokes-Darcy界面模型，该模型在多孔介质域和界面上都具有随机水力传导率。我们考虑了三种具有随机性的界面条件，包括在自由流和多孔介质流之间界面上的具有随机水力传导率的Beavers-Joseph界面条件。我们的求解器采用了一种新颖的大规模刚度矩阵广义低秩近似，这可以显著降低与矩阵求逆相关的计算成本和内存需求，同时不损失精度。因此，通过采用合适的数据压缩比，低秩求解器可以以相对较低的计算和空间复杂度保持较高的数值精度。我们还提出了一种确定最佳数据压缩比的策略。此外，我们对广义低秩矩阵近似算法和低秩求解器进行了误差分析。最后，通过数值实验验证了所提出的算法和理论结论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [828] [The domain-of-dependence stabilization for cut-cell meshes is fully discretely stable](https://arxiv.org/abs/2508.05372)
> *切割网格的依赖域稳定性是完全离散稳定的*

*Louis Petri, Gunnar Birke, Christian Engwer, Hendrik Ranocha* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 依赖域稳定性, 切割网格, 完全离散稳定性, 双曲问题, 时间步长限制

**Comment:** 

> **TL;DR:** 本文展示了双曲问题中切割网格的依赖域稳定方法能够实现完全离散稳定性，其时间步长限制不依赖于任意小的单元，有效解决了小切割单元引起的问题。

**AI_Comments:** 这篇论文的创新点在于提出了一个在时间步长限制下不依赖于任意小单元的完全离散稳定方法，有效解决了切割网格中常见的小单元问题。这对于双曲问题的数值模拟具有重要意义，因为它提高了计算的鲁棒性和效率。论文还深入探讨了高阶多项式的挑战，并提供了解决方案，这表明了其在理论和实践上的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 解决双曲问题中由小切割单元引起的数值不稳定性问题。

**Method:** 通过在半离散层面上重新分配小切割单元周围邻域的质量来稳定依赖域，并使用算子范数估计进行完全离散稳定性分析。此外，还提出了一种缓解高阶多项式相关挑战的方法，以推导出可行的CFL类条件。

**Result:** 证明了在时间步长限制下可以实现完全离散稳定性，且该时间步长限制不依赖于任意小的单元。分析提供了对稳定性机制的详细理解，并揭示了高阶多项式相关的一些挑战。提出的解决方案在数值模拟中得到了验证。

**Conclusion:** 依赖域稳定方法能够为切割网格提供完全离散的稳定性，且其时间步长限制不受任意小单元的影响，有效解决了小单元带来的问题。

> **ai_Abstract:** 本文对双曲问题中切割网格的依赖域稳定方法进行了完全离散稳定性分析。该方法通过在半离散层面上重新分配小切割单元周围的质量来解决小切割单元引起的问题。研究表明，在不受任意小单元影响的时间步长限制下，可以实现完全离散稳定性。此外，分析还深入理解了稳定性机制，并指出了高阶多项式相关的一些挑战，同时提出了一种缓解这些问题的可行CFL类条件。分析结果和提出的解决方案已通过数值模拟得到验证。

> **摘要翻译:** 我们提出了双曲问题中依赖域稳定性的完全离散稳定性分析。该方法旨在通过在半离散层面上重新分配小切割单元周围邻域的质量来解决小切割单元引起的问题。我们的分析是针对一维空间中的线性对流模型问题进行的。我们证明，使用算子范数估计，在不依赖于任意小单元的时间步长限制下，可以实现完全离散稳定性。此外，这项分析提供了对稳定性机制的详细理解，并强调了与高阶多项式相关的一些挑战。我们还提出了一种缓解这些问题的方法，以推导出可行的CFL类条件。分析结果以及提出的解决方案在一维和二维模拟中得到了数值验证。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [833] [Inverse inequalities for kernel-based approximation on bounded domains and Riemannian manifolds](https://arxiv.org/abs/2508.05376)
> *核基近似在有界域和黎曼流形上的逆不等式*

*Zhengjie Sun, Leevan Ling* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 核基近似, 逆不等式, 伯恩斯坦不等式, 尼科尔斯基不等式, 黎曼流形

**Comment:** 

> **TL;DR:** 本文建立了核基近似空间在有界 Lipschitz 域和紧致黎曼流形上的逆不等式，扩展了伯恩斯坦和尼科尔斯基不等式。

**AI_Comments:** 本文在将传统上针对多项式空间的逆不等式推广到更具挑战性的核基近似空间方面取得了重要进展，尤其是在有界 Lipschitz 域和黎曼流形上。其创新之处在于扩展了伯恩斯坦不等式并引入了尼科尔斯基不等式，为核基方法的分析提供了新的工具。论文指出了对核函数更高平滑度的潜在要求，这可能是未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 逆不等式在多项式空间中已得到充分研究，但将其扩展到基于核的试探空间面临重大挑战。

**Method:** 对于有界 Lipschitz 域，作者扩展了伯恩斯坦不等式并推导了尼科尔斯基不等式。对于紧致黎曼流形，作者则关注受限核并证明了其对应的逆不等式。

**Result:** 成功扩展了伯恩斯坦不等式至所有 Sobolev 阶，推导了将 $L_\infty$ 范数限制为 $L_2$ 范数的尼科尔斯基不等式，并在紧致黎曼流形上证明了受限核的对应逆不等式。

**Conclusion:** 本文的理论达到了预期形式，但可能需要核函数比通常假设的 $>d/2$ 更高的平滑度。

> **ai_Abstract:** 本文研究了在有界 Lipschitz 域和紧致黎曼流形上核基近似空间的逆不等式。针对将逆不等式从多项式空间扩展到核基空间所面临的挑战，作者扩展了伯恩斯坦不等式并推导了尼科尔斯基不等式以处理有界 Lipschitz 域，同时为紧致黎曼流形上的受限核证明了对应的结果。研究表明，虽然理论形式达到预期，但可能对核函数的平滑度有更高的要求。

> **摘要翻译:** 本文建立了在 $\mathbb{R}^d$ 中有界 Lipschitz 域和紧致黎曼流形上定义的核基近似空间的逆不等式。虽然逆不等式在多项式空间中得到了充分研究，但将其扩展到基于核的试探空间提出了重大挑战。对于有界 Lipschitz 域，我们将先前仅适用于有限 Sobolev 阶范围的伯恩斯坦不等式扩展到下限的所有阶和上限的 $L_2$，并推导出将 $L_\infty$ 范数限制为 $L_2$ 范数的尼科尔斯基不等式。我们的理论达到了预期形式，但可能需要核函数比通常的 $>d/2$ 假设更高的平滑度。对于紧致黎曼流形，我们关注受限核，它们被定义为环境欧几里得空间中正定核到流形的限制，并证明了它们的对应物。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [838] [Randomized Krylov-Schur eigensolver with deflation](https://arxiv.org/abs/2508.05400)
> *随机Krylov-Schur特征值求解器与紧缩*

*Jean-Guillaume de Damas, Laura Grigori* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 随机Krylov-Schur, 特征值问题, 紧缩, 大规模, 数值线性代数

**Comment:** 

> **TL;DR:** 提出了一种新的随机Krylov-Schur算法，用于高效求解大规模特征值问题，并包含实用的紧缩技术。

**AI_Comments:** 该论文引入了一种新颖的随机Krylov-Schur算法，其创新之处在于结合了随机化技术、低维高效操作和实用的紧缩策略，旨在提升大规模特征值问题的求解效率和准确性。其简单实现和数值验证的良好性能表明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决大规模特征值问题并寻找少量特征对。

**Method:** 本文介绍了一种名为随机Krylov-Schur (rKS) 的新算法，该方法实现简单，利用低维空间中快速高效的操作，例如草图正交化过程和Schur分解的稳定重新排序。它还包括一种针对收敛特征对的实用紧缩技术，能够计算与给定频谱部分相关的特征空间。

**Result:** 数值实验证明了该方法的可伸缩性和准确性。

**Conclusion:** 新的随机Krylov-Schur算法通过其简单实现、高效的低维操作和实用的紧缩技术，能够有效且准确地解决大规模特征值问题。

> **ai_Abstract:** 本文提出了一种新颖的随机Krylov-Schur (rKS) 算法，用于高效求解大规模特征值问题。该算法实现简单，利用低维操作如草图正交化和Schur分解重新排序，并包含实用的紧缩技术来处理已收敛的特征对。数值实验验证了其可伸缩性和准确性。

> **摘要翻译:** 本文介绍了一种新颖的算法，用于解决大规模特征值问题并寻找一小部分特征对。该方法名为随机Krylov-Schur (rKS)，实现简单，并受益于低维空间中快速高效的操作，例如草图正交化过程和Schur分解的稳定重新排序。它还包括一种针对收敛特征对的实用紧缩技术，能够计算与给定频谱部分相关的特征空间。提供了数值实验来证明该方法的可伸缩性和准确性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [843] [A unified framework for the analysis, numerical approximation and model reduction of linear operator equations, Part I: Well-posedness in space and time](https://arxiv.org/abs/2508.05407)
> *线性算子方程的分析、数值逼近和模型降阶的统一框架，第一部分：时空适定性*

*Moritz Feuerle, Richard Löscher, Olaf Steinbach, Karsten Urban* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 线性算子方程, 适定性, 变分公式, 时空方法, 模型降阶

**Comment:** 

> **TL;DR:** 本文提出了一个统一框架，用于构建包括PDEs在内的各类线性算子方程的适定公式，为未来的数值方法和模型降阶奠定理论基础。

**AI_Comments:** 这篇论文通过统一各类线性算子方程的适定性分析，做出了重要的理论贡献。其关注于构建一个通用框架，并结合传统与新型变分形式，具有创新性。它为未来的数值和模型降阶应用奠定了基础，突显了其基础性重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了为大类线性算子方程构建适定公式，并为统一的数值逼近方法和模型降阶奠定理论基础。

**Method:** 主要概念是从问题的强形式开始进行算子的完备化和扩展，该方法结合了已知的弱变分公式以及新型时空变分形式。

**Result:** 提出了一个统一框架，用于构建大类线性算子方程（包括椭圆、抛物线和双曲偏微分方程）的适定公式，并引入了双曲波动方程的新型时空变分形式。

**Conclusion:** 本文为参数化线性算子方程的统一数值逼近和模型降阶方法建立了理论基础，后续部分将探讨其具体应用。

> **ai_Abstract:** 本文提出了一个统一框架，用于构建包括椭圆、抛物线和双曲偏微分方程在内的大类线性算子方程的适定公式。该方法通过从问题的强形式开始进行算子的完备化和扩展，整合了已知的弱变分公式以及新型时空变分形式，特别是针对双曲波动方程。这项工作为参数化线性算子方程的统一数值逼近和模型降阶技术奠定了理论基础。

> **摘要翻译:** 我们提出了一个统一框架，用于构建包括椭圆、抛物线和双曲偏微分方程在内的大类线性算子方程的适定公式。这种通用方法结合了已知的弱变分公式以及双曲波动方程的新型时空变分形式。主要概念是从问题的强形式开始进行算子的完备化和扩展。本文为参数化线性算子方程的统一数值逼近方法和模型降阶奠定了理论基础，这将是后续部分的主题。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [868] [A convergence analysis of Lawson's iteration for computing polynomial and rational minimax approximations](https://arxiv.org/abs/2401.00778)
> *Lawson迭代在计算多项式和有理极小极大逼近中的收敛性分析*

*Lei-Hong Zhang, Shanheng Han* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** Lawson迭代, 极小极大逼近, 收敛性分析, d-Lawson, 有理逼近

**Comment:** 

> **TL;DR:** 本文对d-Lawson迭代在多项式和有理极小极大逼近问题中的收敛性进行了理论分析。

**AI_Comments:** 该论文为d-Lawson迭代，特别是对于具有挑战性的有理极小极大逼近问题，提供了关键的理论保证。这项理论分析补充了之前的数值观察结果，并提供了对该方法收敛特性的更深入理解。

<details>
  <summary>Details</summary>

**Motivation:** Lawson迭代在解决线性极小极大逼近问题上有效，但将其扩展到有理极小极大逼近问题并同时保证计算效率和理论依据具有挑战性。近期工作提出了d-Lawson迭代，将其视为对偶问题的求解方法。本文旨在为d-Lawson迭代提供理论收敛性分析。

**Method:** 本文对d-Lawson迭代在线性（多项式）和有理极小极大逼近问题上的收敛性进行了理论分析。

**Result:** 1. 对于线性极小极大逼近问题，β=1是Lawson迭代中的一个近最优Lawson指数。2. 对于有理极小极大逼近问题，在某些条件下，d-Lawson对于任何足够小的β>0都关于对偶目标函数单调收敛，并且极限逼近满足互补松弛条件：任何与正权重相关的节点要么是插值点，要么具有恒定误差。

**Conclusion:** 本文为d-Lawson迭代在多项式和有理极小极大逼近问题上的收敛性提供了理论基础，证实了其特性和有效性。

> **ai_Abstract:** 本文对d-Lawson迭代在多项式和有理极小极大逼近问题中的收敛性进行了理论分析。该研究基于将Lawson迭代视为对偶问题求解器的新近工作，结果表明，对于线性情况，β=1是一个近最优指数；对于有理情况，d-Lawson在特定条件下单调收敛，并且其极限逼近满足互补松弛条件。

> **摘要翻译:** Lawson迭代是解决复平面上线性（多项式）极小极大逼近问题的经典有效方法。将Lawson迭代扩展到有理极小极大逼近问题，同时兼顾计算效率和理论保证是具有挑战性的。最近的一项工作[L.-H. Zhang, L. Yang, W. H. Yang and Y.-N. Zhang, A convex dual problem for the rational minimax approximation and Lawson's iteration, Math. Comp., 94(2025), 2457-2494.]揭示了Lawson迭代可以被视为解决原始有理极小极大逼近问题对偶问题的方法，并提出了一种新型的Lawson迭代，即d-Lawson，它在线性极小极大逼近问题中退化为经典的Lawson迭代。对于有理情况，在Ruttan的充分条件下，这种对偶问题保证能得到原始极小极大解，并且在数值上，观察到d-Lawson关于对偶目标函数单调收敛。在本文中，我们提出了d-Lawson在线性极小极大逼近问题和有理极小极大逼近问题上的理论收敛性分析。具体来说，我们表明：(i) 对于线性极小极大逼近问题，β=1是Lawson迭代中的一个近最优Lawson指数；(ii) 对于有理极小极大逼近问题，在某些条件下，d-Lawson对于任何足够小的β>0都关于对偶目标函数单调收敛，并且极限逼近满足互补松弛条件：任何与正权重相关的节点要么是插值点，要么具有恒定误差。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [873] [Polytopal mesh agglomeration via geometrical deep learning for three-dimensional heterogeneous domains](https://arxiv.org/abs/2406.10587)
> *基于几何深度学习的三维异构域多面体网格聚结*

*Paola F. Antonietti, Mattia Corti, Gabriele Martinelli* | **Category: math.NA** | **Updated: 2025-08-07**

**Keywords:** 网格聚结, 几何深度学习, 图神经网络, 异构域, 计算成本

**Comment:** 

> **TL;DR:** 本文提出了一种基于几何深度学习（GNN）的新算法，用于三维异构域的网格聚结，该算法能够利用几何和物理信息，提高聚结质量和速度，并优于传统方法。

**AI_Comments:** 本文的创新之处在于将几何深度学习（特别是图神经网络）应用于三维异构域的网格聚结问题。传统方法通常只关注连接信息，而该方法能够同时利用几何和物理信息，从而在保证聚结质量的同时，更好地处理异构介质。其在性能和泛化能力上的提升，尤其是在医学图像重建的复杂几何体上的应用潜力，使其在计算力学和数值模拟领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 网格聚结技术可以有效降低数值模拟的计算成本，并作为多级代数求解器的基础。为了实现网格的自动化聚结，研究人员需要一种新的算法。

**Method:** 本文提出了一种新颖的基于几何深度学习的算法，该算法利用底层的计算域的几何和物理信息来构建聚结网格，并同时保证网格质量。具体而言，该方法基于图神经网络（GNN）提出了一个二分模型，用于划分计算三维网格的合适连接图。这种新方法具有高在线推理速度，能够同时处理网格的图结构、几何信息（如单元体积、中心坐标）和域的物理信息（如物理参数）。

**Result:** 该算法能够自动聚结由异构介质组成的域的网格，并自动遵守潜在的异构性。与广泛用于图划分的k-means和METIS算法相比，所提出的GNN方法在质量指标和运行时间方面均优于它们。此外，该算法在应用于复杂几何形状（如从医学图像重建的三维几何形状）时，也表现出良好的泛化能力。最后，该模型在集成到多面体不连续伽辽金有限元求解器中时，其在异构域中执行聚结的能力得到了评估。

**Conclusion:** 本文提出了一种基于几何深度学习的GNN算法，用于三维异构域的网格聚结。该算法能有效利用几何和物理信息，显著提升聚结网格的质量和处理速度，并展现出优于现有方法的性能和良好的泛化能力，尤其适用于处理复杂和异构介质。

> **ai_Abstract:** 本文提出了一种基于几何深度学习（GNN）的新型算法，用于三维异构域的网格聚结。该算法通过GNN二分模型处理网格的几何、物理和连接信息，以自动构建高质量的聚结网格。实验证明，与传统的k-means和METIS算法相比，该方法在聚结质量和运行时间上均表现更优，并对复杂几何形状具有良好的泛化能力，尤其适用于包含异构介质的计算域。

> **摘要翻译:** 网格聚结技术可以成功地用于降低数值模拟的计算成本，并且是多层代数求解器的基础。为了自动执行网格聚结，我们提出了一种新颖的基于几何深度学习的算法，该算法可以利用底层计算域的几何和物理信息来构建聚结网格，并同时保证聚结网格的质量。特别是，我们提出了一种基于图神经网络（GNN）的二分模型，用于划分计算三维网格的合适连接图。这种新方法具有高在线推理速度。它可以同时处理网格的图结构、网格的几何信息（例如，单元体积、中心坐标）和域的物理信息（例如，物理参数）。利用这种新方法，我们的算法可以聚结由异构介质组成的域的网格，自动遵守潜在的异构性。所提出的GNN方法与k-means算法和METIS进行了比较，后者是广泛用于图划分的方法，旨在仅处理网格上的连接信息。我们证明了我们的算法在质量指标和运行时间方面优于k-means和METIS算法。此外，我们证明了我们的算法在应用于复杂几何形状（例如，从医学图像重建的三维几何形状）时也显示出良好的泛化能力。最后，当该模型集成到多面体不连续伽辽金有限元求解器中时，评估了其在异构域中执行聚结的能力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [725] [Introducing Powerwise (PWR): A pairwise and Power Rating method for selecting at-large teams to the NCAA Division I Men's Lacrosse Championship](https://arxiv.org/abs/2508.04919)
> *引入Powerwise (PWR)：一种用于选择NCAA男子I级长曲棍球锦标赛外卡球队的配对和实力评分方法*

*Lawrence Feldman, Matthew Bomparola* | **Category: stat.AP, stat.ME** | **Updated: 2025-08-06**

**Keywords:** Powerwise, 配对比较, 实力评分, NCAA长曲棍球, 球队选拔

**Comment:** 

> **TL;DR:** 本文介绍了一种名为“Powerwise”的新系统，它结合了配对比较和实力评分，用于选择NCAA男子I级长曲棍球锦标赛球队，旨在提高选拔过程的公平性和客观性。

**AI_Comments:** 该方法的创新之处在于将配对比较与实力评分相结合，并专门为长曲棍球球队选拔量身定制，旨在提高透明度和公平性。其重要性在于解决了体育管理中的一个实际问题。一个局限性是摘要中没有提供其有效性的实证验证。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种新的系统，用于NCAA男子I级长曲棍球锦标赛的球队选拔，该系统需易于教练和球迷理解，并能提高选拔过程的公平性、客观性和整体质量。

**Method:** 该方法名为“Powerwise”。它采用分层配对比较，强调场上表现（面对面和共同对手的比赛结果）。当场上结果不确定时，它使用一种类似于Massey/Colley/Sagarin的简单统计数据，称为实力评分（PR）。实力评分基于胜负分差，并隐含地考虑了赛程强度。

**Result:** 该系统旨在以一种教练和球迷都能理解的方式解决球队选拔的复杂性，同时提高选拔过程的公平性、客观性和整体质量。

**Conclusion:** Powerwise系统通过分层配对比较和实力评分，提供了一种简单易懂且更公平、客观的NCAA男子I级长曲棍球锦标赛球队选拔方法。

> **ai_Abstract:** 本文介绍了一种名为Powerwise的新型NCAA男子I级长曲棍球锦标赛球队选拔系统。该系统与NCAA长曲棍球选拔委员会合作开发，利用简单的分层配对比较，侧重于场上表现。当场上结果不确定时，它会结合一种类似于Massey/Colley/Sagarin统计数据的实力评分（PR），该评分基于胜负分差和赛程强度。该系统旨在简化球队选拔过程，使其对教练和球迷都易于理解，同时提高选拔的公平性、客观性和整体质量。

> **摘要翻译:** 本文描述了一种新的系统，用于选拔NCAA男子I级长曲棍球锦标赛的参赛队伍，该系统名为“Powerwise”，是与NCAA长曲棍球选拔标准和排名委员会（SCR）讨论后开发的。该方法简单，采用分层配对比较，强调面对面和共同对手比赛中的场上表现；当场上结果不确定时，则使用一种类似于Massey/Colley/Sagarin的简单统计数据，称为实力评分（PR）。实力评分基于胜负分差，并隐含地考虑了赛程强度。Powerwise以一种教练和球迷都能理解的方式解决了球队选拔的复杂性，同时提高了选拔过程的公平性、客观性和整体质量。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [731] [Plans for acceptance sampling by attributes when observations are destructive](https://arxiv.org/abs/2508.05131)
> *观测具有破坏性时属性接收抽样计划*

*Hugalf Bernburg, Katy Klauenberg* | **Category: stat.AP** | **Updated: 2025-08-07**

**Keywords:** 破坏性抽样, 属性抽样, 接收抽样, 贝叶斯统计, ISO 2859-2

**Comment:** 

> **TL;DR:** 针对破坏性检测，现有ISO 2859-2标准不适用于评估剩余批次质量。本研究提出基于贝叶斯统计的新抽样计划，通过固定剩余批次大小来限制消费者风险，适用于未来标准化。

**AI_Comments:** 该论文的创新点在于识别了现有国际标准在破坏性抽样场景下的局限性，并提出了一种基于贝叶斯统计的替代方案。其提出的固定剩余批次大小的表示方法具有实用价值，有望推动破坏性抽样领域的标准化进程。这对于需要进行破坏性测试的行业（如种子检测、设备寿命评估等）具有重要意义，能更准确地控制风险。

<details>
  <summary>Details</summary>

**Motivation:** 国际标准ISO 2859-2提供的属性接收抽样计划在破坏性测试中不适用，因为它无法描述接受质量不合格的剩余批次的消费者风险。现有的计划导致小剩余批次的消费者风险较高。

**Method:** 研究指出超几何分布无法描述破坏性抽样中剩余批次的消费者风险。论文使用贝叶斯统计方法推断抽样后的批次质量，并设计了限制（贝叶斯）特定消费者风险的破坏性抽样计划。为了便于制表，提出了一种新的表示方法，该方法固定剩余批次大小N-n，而非样本大小n。

**Result:** 国际标准ISO 2859-2提供的抽样计划在破坏性抽样时，对于小剩余批次会导致较高的特定消费者风险。本研究设计的新计划能够限制（贝叶斯）特定消费者风险。提出的新表示方法通用、简洁、高效，适用于未来破坏性抽样标准化。

**Conclusion:** 现有的ISO 2859-2标准不适用于破坏性抽样。本研究设计了基于贝叶斯统计的新型破坏性抽样计划，通过关注剩余批次大小来有效限制消费者风险，并提出了适用于未来标准化的新表示方法。

> **ai_Abstract:** 本研究探讨了国际标准ISO 2859-2在破坏性测试中应用时的问题，指出其基于超几何分布的抽样计划无法准确评估剩余批次的消费者风险，导致在小剩余批次中风险过高。为解决此问题，论文利用贝叶斯统计设计了新的破坏性抽样计划，旨在限制特定消费者风险。此外，为便于未来标准化，提出了一种创新性的表示方法，即固定剩余批次大小而非样本大小进行制表。

> **摘要翻译:** 国际标准ISO 2859-2提供了属性接收抽样计划，该计划使用超几何分布确保孤立批次的定义质量水平。在破坏性测试中，样本本身会受损或改变，因此整个批次的质量不如移除样本后剩余批次的质量重要。例子包括评估种子的发芽率和在役计量表的符合性。
本研究强调，超几何分布无法描述接受质量不合格的剩余批次的频率论消费者风险。因此，像ISO 2859-2中提供的抽样计划不适合在破坏性抽样时评估剩余批次。相比之下，贝叶斯统计本身就能推断抽样后的批次质量。使用参考先验，我们表明ISO 2859-2提供的抽样计划对于小的剩余批次会导致较高的特定消费者风险。
由于ISO 2859-2不适用，我们设计了限制（贝叶斯）特定消费者风险的破坏性抽样计划。为了以类似于ISO 2859-2的方式列出这些计划，我们提出了一种新的表示方法，该方法固定了剩余批次大小N-n，而非样本大小n。这种通用、简洁、高效的表示方法适用于未来破坏性抽样的标准化。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [737] [Enhancing Empathic Accuracy: Penalized Functional Alignment Method to Correct Temporal Misalignment in Real-time Emotional Perception](https://arxiv.org/abs/2409.05343)
> *提高共情准确性：惩罚性函数对齐方法校正实时情绪知觉中的时间错位*

*Linh H Nghiem, Jing Cao, Chrystyna Kouros, Chul Moon* | **Category: stat.AP** | **Updated: 2025-08-07**

**Keywords:** 共情准确性, 时间错位, 函数对齐, 平方根速度, 动态规划

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的惩罚性函数对齐方法，用于校正实时情绪知觉中的时间错位，从而更准确地评估共情准确性，并优于传统方法。

**AI_Comments:** 该论文的创新之处在于解决了共情准确性评估中一个关键且常被简化处理的时间错位问题。通过引入一种具有现实约束的新型函数对齐方法，显著提高了EA测量的精度，这对于心理学和社会学研究至关重要。平方根速度框架和约束动态规划算法的运用是其重要的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 传统的共情准确性（EA）评估方法常因忽略或过度简化感知者与目标自我报告情绪序列之间的时间错位而导致估计偏差。这些错位源于情绪解释的复杂性和个体差异。

**Method:** 本文提出了一种新颖的对齐方法，该方法利用平方根速度框架将情绪评分轨迹分解为幅度和相位分量。通过引入一个正则化约束将时间偏移限制在符合人类知觉能力的范围内，并使用约束动态规划算法高效实现。

**Result:** 该方法通过模拟和涉及视频及音乐数据集的实际应用进行了验证，结果表明其性能优于传统技术。

**Conclusion:** 所提出的惩罚性函数对齐方法能够有效地校正时间错位，从而实现更准确的共情准确性评估，并优于传统方法。

> **ai_Abstract:** 本文旨在解决共情准确性（EA）评估中普遍存在的时间错位问题，传统方法常因此产生偏差。作者提出了一种新颖的惩罚性函数对齐方法，该方法利用平方根速度框架分解情绪评分轨迹，并引入正则化约束以确保时间偏移符合人类感知能力。通过约束动态规划算法实现，该方法在模拟和真实视频及音乐数据集上的表现均优于传统技术，为EA的准确测量提供了更有效途径。

> **摘要翻译:** 共情准确性（EA）是准确理解他人思想和感受的能力，这对于社会和心理互动至关重要。传统上，EA通过比较知觉者对目标情绪状态的瞬时评分与目标自身在相应时间点的自我报告评分来评估。然而，由于情绪解释的复杂性和个体行为反应的差异，这两个序列之间经常出现错位。传统方法通常忽略或过度简化这些错位，例如，假设一个固定的时间滞后，这可能会给EA估计带来偏差。为了解决这个问题，我们提出了一种新颖的对齐方法，可以捕获广泛的错位模式。我们的方法利用平方根速度框架将情绪评分轨迹分解为幅度和相位分量。为了确保现实的对齐，我们引入了一个正则化约束，将时间偏移限制在与人类知觉能力一致的范围内。这种对齐使用约束动态规划算法有效地实现。我们通过模拟和涉及视频和音乐数据集的实际应用验证了我们的方法，证明其性能优于传统技术。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [21] [On a Continuum Model for Random Genetic Drift: A Dynamic Boundary Condition Approach](https://arxiv.org/abs/2309.09484)
> *关于随机遗传漂移的连续体模型：一种动态边界条件方法*

*Chun Liu, Jan-Eric Sulzbach, Yiwei Wang* | **Category: math.AP, math.NA** | **Updated: 2025-08-07**

**Keywords:** 随机遗传漂移, 连续体模型, 动态边界条件, Kimura方程, 正则化

**Comment:** 

> **TL;DR:** 本文提出了一种基于动态边界条件的随机遗传漂移连续体模型，该模型是Kimura方程的正则化版本，并证明了其强解的存在性和唯一性。数值实验表明，该模型能捕捉Kimura方程的关键现象。

**AI_Comments:** 该论文的创新点在于引入了动态边界条件来构建随机遗传漂移的连续体模型，并将其与Kimura方程进行了关联。通过数学证明和数值实验，验证了模型的理论严谨性和实际应用潜力，为遗传漂移研究提供了新的数学工具。

<details>
  <summary>Details</summary>

**Motivation:** 提出一种新的随机遗传漂移连续体模型，以解决现有模型可能存在的问题（例如，Kimura方程的正则化）。

**Method:** 采用动态边界条件方法构建了一个新的连续体模型，并将其视为Kimura方程的正则化版本。通过理论分析证明了正则化系统强解的存在性和唯一性。通过数值实验验证了模型的有效性。

**Result:** 建立了正则化系统强解的存在性和唯一性。数值实验表明，在正则化参数足够小的情况下，该模型能够捕捉到原始Kimura方程的关键现象，如基因固定和一阶矩守恒。

**Conclusion:** 通过引入动态边界条件，成功构建了一个能够有效模拟随机遗传漂移并捕捉Kimura方程关键现象的连续体模型。

> **ai_Abstract:** 本文提出了一种基于动态边界条件的新型随机遗传漂移连续体模型，该模型被视为Kimura方程的正则化形式。研究证明了该正则化系统强解的存在性和唯一性，并通过数值实验验证了模型在捕捉基因固定和一阶矩守恒等Kimura方程核心现象方面的有效性。

> **摘要翻译:** 我们提出了一种通过采用动态边界条件方法来模拟随机遗传漂移的新连续体模型。该模型可以看作是Kimura方程的正则化版本，并允许连续解。我们建立了正则化系统强解的存在性和唯一性。数值实验表明，对于足够小的正则化参数，该模型可以捕捉原始Kimura方程的关键现象，例如基因固定和一阶矩守恒。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

### [849] [Numerical analysis of the stochastic Navier-Stokes equations](https://arxiv.org/abs/2508.05564)
> *随机Navier-Stokes方程的数值分析*

*Dominic Breit, Andreas Prohl, Jörn Wichman* | **Category: math.AP, math.NA, math.PR** | **Updated: 2025-08-07**

**Keywords:** 随机Navier-Stokes方程, 数值分析, 随机流体模型, 确定性方法, 基准测试

**Comment:** 

> **TL;DR:** 本文概述了随机Stokes和Navier-Stokes方程的最优收敛数值方法，并解释了为何确定性方法直接应用于随机问题时表现不佳，同时提出了通用基准测试以比较新算法。

**AI_Comments:** 这篇论文的创新点在于它不仅指出了将确定性数值方法直接应用于随机Navier-Stokes方程的局限性，还深入分析了其失效的原因，并提出了通过修改方法来恢复最优性能的思路。此外，提出一个通用的基准测试对于未来随机流体模拟算法的比较和发展具有重要意义，能够促进更严谨和实际的性能评估。

<details>
  <summary>Details</summary>

**Motivation:** 过去五十年在不可压缩Navier-Stokes方程数值离散化方面的进展，为可靠的近似方法奠定了基础。然而，对于日益重要的随机流体模型，这些工具的理解需要根本性的修正。本文旨在为随机流体模型提供更深入的数值分析和比较方法。

**Method:** 本文回顾并调查了近几十年来获得的随机Stokes和Navier-Stokes方程的最优收敛数值方法。通过计算实例说明了某些确定性方法直接应用于随机情况时的失效原因，并解释了通过修改确定性方法以适应随机问题的概率性质可以恢复其最优性能。此外，提出了一个由不同类型噪声驱动的典型流体流动问题的通用基准测试，以便通过模拟比较新算法的复杂性、效率和潜在局限性。

**Result:** 文章揭示了确定性数值方法直接应用于随机Navier-Stokes方程时表现不佳的原因，并指出通过适当修改可以恢复其最优性能。此外，提出了一个用于比较新算法的通用基准测试，以评估其精度、复杂性、效率和局限性。

**Conclusion:** 本文强调了对随机流体模型数值方法进行根本性修正的必要性，并提出了能有效处理随机问题的最优收敛方法。同时，通过引入通用基准测试，促进了新算法在更实际设置下的性能比较。

> **ai_Abstract:** 本文对随机Stokes和Navier-Stokes方程的数值方法进行了综述和分析。文章指出，传统的确定性Navier-Stokes方程数值离散化方法在直接应用于随机流体模型时会失效或表现次优，并深入探讨了导致这种次优性能的分析差异。研究强调了修改确定性方法以适应随机问题概率性质的重要性，以恢复其最优性能。此外，论文提出了一个通用的基准测试，用于通过模拟比较不同类型噪声驱动的流体流动问题中新算法的精度、复杂性、效率和局限性，旨在弥补理论研究的不足，并促进更实际的性能评估。

> **摘要翻译:** 过去五十年来，关于不可压缩Navier-Stokes方程数值离散化的发展，已经形成了可靠的近似工具：包括正确处理不可压缩性约束的稳定方法、处理对流主导问题的稳定离散化、高效的时间（分裂）方法以及解决其非线性特征的方法。虽然这些工具可以成功应用于可靠地模拟更复杂的流体流动偏微分方程模型，但对于当今日益重要的随机流体模型，需要对其理解进行根本性修订。这项工作旨在激励并调查近几十年来获得的随机Stokes和Navier-Stokes方程的最优收敛数值方法。此外，我们通过计算实例说明了如果将确定性设置中的一些方法直接应用于随机情况，它们会失效。事实上，我们通过强调确定性方程和随机方程之间的关键分析差异，解释了为什么其中一些确定性方法的性能次优——以及如何修改确定性方法以在正确处理随机问题的概率性质时恢复其最优性能。除了方案的数值分析之外，我们还提出了一个由不同类型噪声驱动的典型流体流动问题的通用基准测试，以便通过模拟比较新算法的复杂性、效率和可能的局限性。主要动机是更好地比较新方案在精度和复杂性方面的模拟，并通过更实际的数据设置来补充受限数据设置的理论性能研究。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

### [858] [Modulation of the Monokinetic Limit for Models of Collective Dynamics](https://arxiv.org/abs/2508.05478)
> *集合动力学模型中单动能极限的调制*

*Alina Chertock, Roman Shvydkoy, Trevor Teolis* | **Category: math.AP, math.NA** | **Updated: 2025-08-07**

**Keywords:** 集合动力学, 单动能极限, Cucker-Smale模型, 欧拉对齐系统, 调制分析

**Comment:** 

> **TL;DR:** 本文对从动力学Cucker-Smale模型到无压欧拉对齐系统的单动能极限进行了调制分析，研究了在两种不同机制下（强Fokker-Planck力与纯无噪声Vlasov方案）的收敛行为。

**AI_Comments:** 这项工作通过细致的调制分析，揭示了在不同物理极限下，集体动力学模型从动能描述到流体描述的过渡行为。特别是在两种截然不同的机制下，收敛到高斯分布或特定输运方程的剖面，这对于理解复杂系统中的宏观涌现行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在集合动力学模型中，研究从动力学Cucker-Smale模型到无压欧拉对齐系统的单动能极限的调制行为。

**Method:** 采用调制分析方法，研究了动能Cucker-Smale模型到无压欧拉对齐系统的单动能极限。具体考虑了两种机制：一是具有消失噪声和Knudsen数的强Fokker-Planck力；二是纯无噪声的Vlasov方案。

**Result:** 在强Fokker-Planck力机制下，调制剖面收敛到标准高斯分布。在纯无噪声Vlasov方案下，分布收敛到一个满足沿极限特征线的显式输运方程的剖面。

**Conclusion:** 研究表明，在不同的极限机制下（强Fokker-Planck力与纯无噪声Vlasov方案），Cucker-Smale模型单动能极限的调制剖面表现出不同的收敛行为，分别收敛到标准高斯分布和满足特定输运方程的剖面。

> **ai_Abstract:** 本文对从动力学Cucker-Smale模型到无压欧拉对齐系统的单动能极限进行了调制分析。研究探讨了两种不同的机制：一种是强Fokker-Planck力在噪声和Knudsen数趋零的情况，另一种是纯无噪声Vlasov方案。研究结果显示，在第一种机制下，调制剖面收敛于标准高斯分布；而在第二种机制下，分布收敛于一个沿极限特征线满足显式输运方程的剖面。

> **摘要翻译:** 在这项工作中，我们对从动力学Cucker-Smale模型到无压欧拉对齐系统的单动能极限进行了调制分析。考虑了两种机制——一种是具有消失噪声和Knudsen数的强Fokker-Planck力，另一种是纯无噪声的Vlasov方案。在前一种情况下，我们证明了调制剖面收敛到标准高斯分布，而在后一种情况下，分布收敛到一个满足沿极限特征线的显式输运方程的剖面。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matsoft'></a>
## cond-mat.soft 

### [401] [Stability analysis through folds: An end-loaded elastic with a lever arm](https://arxiv.org/abs/2501.04729)
> *通过折叠进行稳定性分析：一个带杠杆臂的端部加载弹性体*

*Siva Prasad Chakri Dhanakoti* | **Category: cond-mat.soft, cs.RO, math.OC** | **Updated: 2025-08-06**

**Keywords:** 稳定性分析, 折叠, 变分问题, 弹性体, 回弹失稳

**Comment:** 

> **TL;DR:** 该研究通过识别变分问题的特定投影（ distinguished bifurcation diagrams），分析了具有固定-自由端的弹性体在端部加载下的稳定性，并报告了回弹失稳现象，为软机器人和执行器设计提供了潜在应用。

**AI_Comments:** 本文创新性地利用“distinguished bifurcation diagrams”分析了具有固定-自由端变分问题的稳定性，并揭示了弹性体中的回弹失稳现象。其研究方法和发现对于理解复杂力学系统的行为具有重要意义，并为软体机器人的设计提供了理论基础和实际指导。

<details>
  <summary>Details</summary>

**Motivation:** 许多物理系统可以建模为依赖于参数的变分问题，其中存在多个平衡点。这些系统需要评估其稳定性并监测平衡点之间的转换，尤其是在参数空间的折叠（folds）附近，因为平衡点的稳定性特性会在此处发生变化。

**Method:** 本文识别了固定-自由端变分问题的特定投影，即“distinguished bifurcation diagrams”。利用这些图，研究了通过刚性杠杆臂施加端部载荷的弹性体（Elastica）。通过数值示例分析了系统的稳定性。

**Result:** 研究报告了几种回弹失稳（snap-back instability）实例，并揭示了它们对系统参数的依赖性。

**Conclusion:** 这些研究结果在软机器人手臂设计和其他执行器设计中具有潜在应用价值。

> **ai_Abstract:** 本文关注参数依赖的变分问题中多平衡点的稳定性分析及转换监测。研究识别了固定-自由端变分问题的特定投影，即“distinguished bifurcation diagrams”，并利用这些图分析了一个通过刚性杠杆臂施加端部载荷的弹性体。研究报告了回弹失稳现象及其与系统参数的依赖关系，这些发现对软机器人手臂和执行器设计具有潜在应用。

> **摘要翻译:** 许多物理系统可以建模为依赖于参数的变分问题。在许多情况下，多个平衡点共存，需要评估它们的稳定性，并监测它们之间的转换。通常，平衡点的稳定性特性在参数空间中的折叠（folds）附近发生变化。稳定性变化的方向嵌入在解决方案的特定投影中，称为“distinguished bifurcation diagrams”。在本文中，我们为以固定-自由端为特征的变分问题（这是一类在力学中经常遇到的问题）识别了此类投影。使用这些图，我们研究了一个通过刚性杠杆臂施加端部载荷的弹性体（Elastica）。报告了几种回弹失稳（snap-back instability）实例，以及它们通过数值示例对系统参数的依赖性。这些发现对软机器人手臂和其他执行器设计具有潜在应用价值。

</details>

[⬆️ 返回分类顶部](#cond-matsoft) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matmtrl-sci'></a>
## cond-mat.mtrl-sci 

### [519] [Data Driven Insights into Composition Property Relationships in FCC High Entropy Alloys](https://arxiv.org/abs/2508.04841)
> *数据驱动的FCC高熵合金成分-性能关系洞察*

*Nicolas Flores, Daniel Salas Mula, Wenle Xu, Sahu Bibhu, Daniel Lewis, Alexandra Eve Salinas, Samantha Mitra, Raj Mahat, Surya R. Kalidindi, Justin Wilkerson, James Paramore, Ankit Srivastiva, George Pharr, Douglas Allaire, Ibrahim Karaman, Brady Butler, Vahid Attari, Raymundo Arroyave* | **Category: cond-mat.mtrl-sci, cs.LG** | **Updated: 2025-08-06**

**Keywords:** 高熵合金, 成分-性能关系, 数据驱动, 机器学习, 机械性能

**Comment:** 

> **TL;DR:** 本研究利用敏感性分析和编码器-解码器模型，从有限数据中揭示了高熵合金的成分-性能关系，并在预测机械性能方面取得了优异表现。

**AI_Comments:** 该论文创新性地将数据驱动的编码器-解码器模型与贝叶斯优化相结合，以解决高熵合金领域长期存在的成分-性能数据稀缺问题。其重要性在于为HEAs的预测性性能建模提供了一种有效的新方法，有望加速新材料的开发。通过敏感性分析揭示关键元素贡献，也为合金设计提供了宝贵洞察。

<details>
  <summary>Details</summary>

**Motivation:** 结构高熵合金（HEAs）在航空航天、汽车和国防等领域至关重要，但集成化学、工艺、结构和性能数据的稀缺性给预测性性能建模带来了挑战。鉴于合金的巨大设计空间，从有限和异构数据集中揭示潜在模式是必不可少但又困难的。

**Method:** 本研究进行了多项敏感性分析，以揭示关键元素对机械行为的贡献，并深入了解BIRDSHOT中心NiCoFeCrVMnCuAl系统数据集中纳米压痕测试中观察到的脆性和断裂响应相关的成分因素。评估了多个通过贝叶斯多目标超参数优化精心调整的基于编码器-解码器的化学-性能模型，用于将合金成分映射到六种机械性能。

**Result:** 模型在所有性能上都达到了与传统回归器相当或更优的性能，尤其是在屈服强度和UTS/YS比方面，证明了它们在捕获复杂成分-性能关系方面的有效性。

**Conclusion:** 本研究表明，数据驱动的编码器-解码器模型能够有效捕获高熵合金复杂的成分-性能关系，并在机械性能预测方面表现出色。

> **ai_Abstract:** 本研究旨在通过数据驱动的方法解决高熵合金（HEAs）成分-性能关系建模中数据稀缺和设计空间巨大的挑战。作者利用敏感性分析识别了关键元素对机械性能的影响，并特别关注了纳米压痕测试中观察到的脆性和断裂响应。研究进一步开发并评估了基于编码器-解码器的化学-性能模型，并通过贝叶斯多目标优化进行调优，以预测六种机械性能。结果表明，这些模型在所有性能上均优于或媲美传统回归器，尤其在屈服强度和UTS/YS比方面表现突出，有效捕捉了复杂的成分-性能关系。

> **摘要翻译:** 结构高熵合金（HEAs）在航空航天、汽车和国防等各个领域的技术进步中至关重要。然而，集成化学、工艺、结构和性能数据的稀缺性给预测性性能建模带来了重大挑战。鉴于这些合金的巨大设计空间，揭示潜在模式至关重要但又困难，需要能够从有限和异构数据集中学习的先进方法。本工作提出了几项敏感性分析，突出了关键元素对机械行为的贡献，包括对BIRDSHOT中心NiCoFeCrVMnCuAl系统数据集中纳米压痕测试中观察到的脆性和断裂响应相关的成分因素的深入了解。评估了几个通过贝叶斯多目标超参数优化精心调整的基于编码器-解码器的化学-性能模型，用于将合金成分映射到六种机械性能。这些模型在所有性能上都达到了与传统回归器相当或更优的性能，尤其是在屈服强度和UTS/YS比方面，证明了它们在捕获复杂成分-性能关系方面的有效性。

</details>

[⬆️ 返回分类顶部](#cond-matmtrl-sci) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phep'></a>
## astro-ph.EP 

### [521] [Attitude Determination and Control of GPS Satellites: Stabilization, Orbital Insertion, and Operational Control Mechanisms](https://arxiv.org/abs/2508.01660)
> *GPS卫星姿态确定与控制：稳定、入轨与运行控制机制*

*Oliullah Samir* | **Category: astro-ph.EP, astro-ph.IM, eess.SY** | **Updated: 2025-08-07**

**Keywords:** GPS卫星, 姿态确定与控制, 轨道插入, 运行控制, 卫星稳定

**Comment:** 

> **TL;DR:** 本文对GPS卫星的运行动力学、姿态确定与控制系统(ADCS)以及入轨技术进行了全面回顾。

**AI_Comments:** 这篇论文通过对GPS卫星姿态确定与控制的全面回顾，为理解这些关键卫星的复杂操作提供了宝贵的综合性视角，突出了其在精确导航和授时中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 全球定位系统（GPS）卫星对于全球提供精确导航和授时信息至关重要。这些卫星在中地球轨道（MEO）运行，必须保持精确的对地指向姿态以有效传输信号。

**Method:** 本文通过对GPS卫星的运行动力学、姿态确定与控制系统（ADCS）和入轨技术进行全面回顾。探讨了传感器和执行器、控制算法、稳定策略以及部署这些卫星所需的发射程序的集成。讨论了与轨道力学和姿态控制相关的关键方程，并引用了最新的技术文献。

**Result:** 本文提供了GPS卫星运行动力学、姿态确定与控制系统以及入轨技术的全面回顾。它探讨了传感器和执行器、控制算法、稳定策略和发射程序的集成，并讨论了关键方程。

**Conclusion:** 本文的结论是提供了一个关于GPS卫星姿态确定与控制、稳定、入轨和运行控制机制的全面综述。

> **ai_Abstract:** 这篇综述文章全面探讨了全球定位系统（GPS）卫星的姿态确定与控制（ADCS）方面，包括其运行动力学、稳定策略、入轨技术以及操作控制机制。文章详细介绍了传感器与执行器的集成、控制算法、发射程序，并讨论了相关的轨道力学和姿态控制方程，引用了最新文献。

> **摘要翻译:** 全球定位系统（GPS）卫星对于全球提供精确导航和授时信息至关重要。这些卫星在中地球轨道（MEO）运行，必须保持精确的对地指向姿态以有效传输信号。本文对GPS卫星的运行动力学、姿态确定与控制系统（ADCS）以及入轨技术进行了全面回顾。我们探讨了传感器和执行器、控制算法、稳定策略以及部署这些卫星所需的发射程序的集成。文中讨论了与轨道力学和姿态控制相关的关键方程，并引用了最新的技术文献。

</details>

[⬆️ 返回分类顶部](#astro-phep) | [⬆️ 返回总目录](#toc)

---

### [544] [Supervised Machine Learning Methods with Uncertainty Quantification for Exoplanet Atmospheric Retrievals from Transmission Spectroscopy](https://arxiv.org/abs/2508.04982)
> *带有不确定性量化的监督机器学习方法用于透射光谱的系外行星大气反演*

*Roy T. Forestano, Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu* | **Category: astro-ph.EP, astro-ph.IM, cs.LG, physics.data-an** | **Updated: 2025-08-07**

**Keywords:** 系外行星大气反演, 监督机器学习, 透射光谱, 不确定性量化, JWST

**Comment:** 

> **TL;DR:** 本文系统研究了多种监督机器学习方法，并量化了它们在系外行星大气反演中的不确定性，旨在提高计算效率和鲁棒性。

**AI_Comments:** 该论文的创新点在于系统地比较了多种监督机器学习方法在系外行星大气反演中的应用，并强调了不确定性量化。在JWST时代，其提出的高效且鲁棒的替代方案具有重要意义。通过对WASP-39b的案例研究验证了方法的实用性，为未来系外行星大气特征研究提供了有价值的工具。

<details>
  <summary>Details</summary>

**Motivation:** 标准贝叶斯反演在系外行星大气参数推断方面计算成本高昂。在JWST等新一代观测设备时代，需要更高效且鲁棒的替代方案。

**Method:** 系统研究了多种监督机器学习回归技术，包括PLS、SVM、KNN、DT、RF、VOTE、STACK和XGB，并比较了它们在准确性、精度和速度方面的性能。同时，探讨了训练数据预处理方法对模型性能的影响，并对模型不确定性进行了量化。

**Result:** 对不同机器学习算法在准确性、精度和速度方面进行了基准测试。表现最佳的机器学习模型与预处理方案的组合在WASP-39b的JWST观测案例研究中得到了验证。

**Conclusion:** 最佳的机器学习模型和预处理方案组合能够有效且高效地进行系外行星大气反演，并在实际观测案例中展现出良好的性能和不确定性量化能力。

> **ai_Abstract:** 本文系统研究了多种监督机器学习回归技术，并将其应用于系外行星大气参数的透射光谱反演。研究比较了不同算法在准确性、精度和速度方面的表现，并探讨了训练数据预处理对模型性能的影响。此外，还量化了模型不确定性。最终，将表现最佳的机器学习模型和预处理方案组合在WASP-39b的JWST观测案例中进行了验证，证明了其在未来高精度观测时代的应用潜力。

> **摘要翻译:** 透射光谱学中用于系外行星大气参数的标准贝叶斯反演，尽管被广泛理解和使用，但通常计算成本高昂。在JWST和其他即将到来的观测站时代，机器学习方法已成为既高效又鲁棒的可行替代方案。在本文中，我们系统地研究了几种现有的机器学习回归技术，并比较了它们在从透射光谱中反演系外行星大气参数方面的性能。我们对不同算法在准确性、精度和速度方面的性能进行了基准测试。这里测试的回归方法包括偏最小二乘法（PLS）、支持向量机（SVM）、k近邻（KNN）、决策树（DT）、随机森林（RF）、投票（VOTE）、堆叠（STACK）和极端梯度提升（XGB）。我们还研究了训练数据不同预处理方法对模型性能的影响。我们量化了行星参数整个动态范围内的模型不确定性。表现最佳的ML模型和预处理方案的组合在WASP-39b的JWST观测案例研究中得到了验证。

</details>

[⬆️ 返回分类顶部](#astro-phep) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [743] [Dependent Default Modeling through Multivariate Generalized Cox Processes](https://arxiv.org/abs/2508.05022)
> *依赖违约建模通过多元广义Cox过程*

*Djibril Gueye, Alejandra Quintos* | **Category: math.PR, q-fin.MF** | **Updated: 2025-08-07**

**Keywords:** 依赖违约, 广义Cox过程, 多元模型, 共同冲击, 违约风险

**Comment:** 

> **TL;DR:** 本文提出了一个基于多元广义Cox过程的框架，用于建模依赖违约时间，能够处理共同和个体冲击，并统一渐进和突然的违约风险来源。

**AI_Comments:** 该论文的创新点在于提出了一个扩展的多元广义Cox过程框架，成功地将共同和个体冲击纳入违约建模，并通过使用càdlàg过程和Azéma超鞅的分解，在保持分析可处理性的同时，放宽了对补偿器连续性的严格要求。其重要性体现在能够统一处理渐进和突然的违约风险，并且能够捕获广泛的依赖结构，涵盖了现有模型作为特例，为金融风险管理提供了更全面和灵活的工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有违约建模方法可能对补偿器有严格的连续性要求，且难以全面捕获复杂的依赖结构和统一渐进与突然的违约风险，因此需要一个更灵活和全面的框架来建模依赖违约时间。

**Method:** 本文提出了一个多元框架，用于建模依赖违约时间，该框架通过纳入共同和个体冲击来扩展经典的Cox过程。它使用càdlàg、递增过程来建模累积强度，放宽了对绝对连续补偿器的要求。通过在保证确定性补偿器的假设下，使用Azéma超鞅的乘法分解来保持分析可处理性。

**Result:** 该框架能够捕获广泛的依赖结构，并允许同时和非同时违约。推导了联合生存概率的闭式表达式。通过基于Lévy次序器、复合泊松过程和散弹噪声过程的例子，证明了模型的灵活性，这些例子包含了文献中几个知名模型作为特例。

**Conclusion:** 该框架可以扩展以纳入随机连续分量，从而统一渐进和突然的违约风险来源，表明了其广泛的适用性和统一性。

> **ai_Abstract:** 本文提出了一个基于多元广义Cox过程的框架，用于精确建模依赖违约时间。该模型通过引入共同和个体冲击来扩展传统Cox过程，并利用càdlàg递增过程构建累积强度，从而放宽了对补偿器连续性的限制。它通过乘法分解保持了分析可处理性，能够捕获多样的依赖结构，并允许同时及非同时违约。该框架提供了联合生存概率的闭式解，并能统一渐进和突然的违约风险来源。

> **摘要翻译:** 我们提出了一个多元框架，用于建模依赖违约时间，该框架通过纳入共同和个体冲击来扩展经典的Cox过程。我们的构建使用càdlàg、递增过程来建模累积强度，放宽了对绝对连续补偿器的要求。在保证确定性补偿器的假设下，通过Azéma超鞅的乘法分解，保持了分析可处理性。该框架捕获了广泛的依赖结构，并允许同时和非同时违约。我们推导了联合生存概率的闭式表达式，并通过基于Lévy次序器、复合泊松过程和散弹噪声过程的例子，说明了模型的灵活性，这些例子包含了文献中几个知名模型作为特例。最后，我们展示了该框架如何扩展以纳入随机连续分量，从而统一渐进和突然的违约风险来源。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='mathdg'></a>
## math.DG 

### [863] [Non-degenerate Rigid Alignment in a Patch Framework](https://arxiv.org/abs/2303.11620)
> *斑块框架中的非退化刚性对齐*

*Dhruv Kohli, Gal Mishne, Alexander Cloninger* | **Category: math.DG, math.NA, math.OC** | **Updated: 2025-08-06**

**Keywords:** 刚性对齐, 斑块框架, 非退化性, 黎曼梯度下降, 无穷小刚性

**Comment:** 

> **TL;DR:** 本文研究了在存在噪声的情况下，如何对局部视图（斑块）进行刚性对齐，并提出了一个测试非退化性的多项式时间算法和基于黎曼梯度下降的优化方法，同时分析了无噪声情况下的刚性特性。

**AI_Comments:** 这篇论文在处理多视图数据对齐的噪声鲁棒性方面具有重要意义。通过引入“非退化性”的概念并提供其在噪声和无噪声情况下的精确表征，为理解和实现可靠的刚性对齐提供了坚实的理论基础。特别是，多项式时间非退化性测试算法和黎曼梯度下降法的收敛性分析，为实际应用提供了有效工具。对无穷小刚性和全局刚性的探讨也加深了对几何重建稳定性的理解。

<details>
  <summary>Details</summary>

**Motivation:** 解决在存在噪声的情况下，对一组重叠的局部视图（斑块）进行刚性对齐的问题，目标是最小化基于2范数的对齐误差，因为在一般情况下，视图是嘈杂的，可能无法实现完美对齐。

**Method:** 1. 在有噪声环境下，基于特定矩阵的核和正定性来刻画对齐的非退化性。2. 开发了一个多项式时间算法来测试给定对齐的非退化性。3. 采用黎曼梯度下降法来最小化对齐误差，并提供了算法局部线性收敛的充分条件。4. 进行了算法的精确恢复和噪声稳定性分析。5. 在无噪声视图情况下，推导了视图重叠结构的必要和充分条件，以使完美对齐非退化，并使得到的实现具有无穷小刚性。

**Result:** 1. 提出了在噪声环境下刻画对齐非退化性的方法，并给出了一个测试非退化性的多项式时间算法。2. 为黎曼梯度下降法在对齐误差最小化中的局部线性收敛提供了充分条件。3. 提供了算法的精确恢复和噪声稳定性分析。4. 在无噪声视图情况下，证明了非退化完美对齐能够刻画实现的无穷小刚性，从而刻画通用实现的局部刚性。5. 导出了在无噪声情况下，完美对齐非退化（等价于实现无穷小刚性）所需的视图重叠结构的必要和充分条件。6. 获得了关于完美对齐的唯一性和全局刚性的类似结果。

**Conclusion:** 本文成功地在存在噪声的斑块框架中解决了刚性对齐问题，通过对非退化性的深入分析，开发了有效的测试算法和优化方法，并对无噪声情况下的刚性特性进行了全面的理论表征，为多视图数据对齐提供了理论基础和实用工具。

> **ai_Abstract:** 本文研究了在噪声环境下重叠局部视图（斑块）的刚性对齐问题，旨在最小化2范数对齐误差。作者提出了一种基于矩阵核和正定性来刻画对齐非退化性的方法，并开发了一个多项式时间算法来测试非退化性。此外，文章采用黎曼梯度下降法来最小化对齐误差，并给出了算法局部线性收敛的充分条件，同时进行了精确恢复和噪声稳定性分析。对于无噪声视图，研究表明非退化完美对齐能表征实现的无穷小刚性和局部刚性，并推导了实现非退化和无穷小刚性的重叠结构条件，还探讨了完美对齐的唯一性和全局刚性。

> **摘要翻译:** 给定一组数据集的重叠局部视图（斑块），我们考虑寻找一种刚性对齐视图的问题，该对齐能最小化基于2范数的对齐误差。通常情况下，视图是嘈杂的，可能不存在完美的对齐。在这项工作中，我们基于某个矩阵的核和正定性，刻画了噪声环境下对齐的非退化性。这导致了一个用于测试给定对齐非退化性的多项式时间算法。随后，我们专注于使用黎曼梯度下降法最小化对齐误差，并提供了对齐的充分条件，使得算法能（局部）线性收敛到它。此外，我们提供了算法的精确恢复和噪声稳定性分析。在无噪声视图的情况下，存在一个完美的对齐，从而实现了尊重视图几何的点实现。在视图的温和条件下，我们表明一个非退化完美对齐刻画了实现的无穷小刚性，从而刻画了通用实现的局部刚性。通过将非退化条件专门应用于无噪声情况，我们推导出了视图重叠结构的必要和充分条件，以使完美对齐非退化，等价地，使得到的实现具有无穷小刚性。关于完美对齐的唯一性和全局刚性也得出了类似的结果。

</details>

[⬆️ 返回分类顶部](#mathdg) | [⬆️ 返回总目录](#toc)

---

<a id='mathfa'></a>
## math.FA 

### [878] [Acceleration of convergence in approximate solutions of Urysohn integral equations with Green's kernels](https://arxiv.org/abs/2409.01784)
> *具有格林核的乌里松积分方程近似解的收敛加速*

*Shashank K. Shukla, Gobinda Rakshit* | **Category: math.FA, math.NA** | **Updated: 2025-08-07**

**Keywords:** 乌里松积分方程, 格林核, 近似解, 收敛加速, 插值投影

**Comment:** 

> **TL;DR:** 通过基于插值投影的近似方法，显著提高了具有格林核的乌里松积分方程近似解的精度。

**AI_Comments:** 本文的创新点在于提出了新的近似方法，显著提高了乌里松积分方程近似解的精度，超越了传统的配置法。这对于需要高精度数值解的非线性积分方程问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为非线性乌里松积分方程 $x - K(x) = f$ 提供比经典配置法更精确的近似解。

**Method:** 采用基于插值投影的近似方法，将解投影到由关于 $[0, 1]$ 均匀划分的偶次分段多项式构成的近似空间 $\mathcal{X}_n$。

**Result:** 通过这些方法获得的近似解比同方程的经典配置解表现出更高的精度。

**Conclusion:** 所提出的基于插值投影的近似方法能够有效提高乌里松积分方程近似解的精度，并通过数值例子得到了理论支持。

> **ai_Abstract:** 本文研究了具有格林核的乌里松积分方程 $x - K(x) = f$ 的近似解问题。通过采用基于插值投影到偶次分段多项式空间的近似方法，研究发现所得到的近似解比经典配置法具有更高的精度。数值例子验证了理论结果。

> **摘要翻译:** 考虑一个非线性算子方程 $x - K(x) = f$，其中 $f$ 是给定函数，$K$ 是在 $L^\infty [0, 1]$ 上定义的具有格林函数类型核的乌里松积分算子。我们应用基于插值投影到近似空间 $\mathcal{X}_n$ 的近似方法，该空间是关于 $[0, 1]$ 均匀划分的偶次分段多项式空间。与同方程的经典配置解相比，这些方法获得的近似解表现出更高的精度。数值例子支持了我们的理论结果。

</details>

[⬆️ 返回分类顶部](#mathfa) | [⬆️ 返回总目录](#toc)

