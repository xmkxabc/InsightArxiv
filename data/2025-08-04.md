# AI-Enhanced arXiv Daily 2025-08-04

<a id='toc'></a>
## 今日总计: 948 篇论文
### 目录
- [cs.AI](#csai) (52 篇)
- [cs.AR](#csar) (1 篇)
- [cs.CC](#cscc) (3 篇)
- [cs.CE](#csce) (7 篇)
- [cs.CG](#cscg) (2 篇)
- [cs.CL](#cscl) (117 篇)
- [cs.CR](#cscr) (18 篇)
- [cs.CV](#cscv) (194 篇)
- [cs.CY](#cscy) (12 篇)
- [cs.DB](#csdb) (7 篇)
- [cs.DC](#csdc) (6 篇)
- [cs.DL](#csdl) (1 篇)
- [cs.DM](#csdm) (1 篇)
- [cs.DS](#csds) (7 篇)
- [cs.ET](#cset) (2 篇)
- [cs.GR](#csgr) (5 篇)
- [cs.GT](#csgt) (3 篇)
- [cs.HC](#cshc) (39 篇)
- [cs.IR](#csir) (12 篇)
- [cs.IT](#csit) (18 篇)
- [cs.LG](#cslg) (157 篇)
- [cs.LO](#cslo) (8 篇)
- [cs.MA](#csma) (3 篇)
- [cs.MM](#csmm) (3 篇)
- [cs.NE](#csne) (7 篇)
- [cs.NI](#csni) (21 篇)
- [cs.OS](#csos) (1 篇)
- [cs.PF](#cspf) (1 篇)
- [cs.PL](#cspl) (10 篇)
- [cs.RO](#csro) (53 篇)
- [cs.SC](#cssc) (2 篇)
- [cs.SD](#cssd) (6 篇)
- [cs.SE](#csse) (36 篇)
- [cs.SI](#cssi) (4 篇)
- [eess.AS](#eessas) (10 篇)
- [eess.IV](#eessiv) (22 篇)
- [eess.SP](#eesssp) (17 篇)
- [eess.SY](#eesssy) (11 篇)
- [math.NA](#mathna) (15 篇)
- [stat.AP](#statap) (3 篇)
- [q-fin.MF](#q-finmf) (1 篇)
- [stat.ML](#statml) (6 篇)
- [cond-mat.dis-nn](#cond-matdis-nn) (1 篇)
- [q-bio.QM](#q-bioqm) (2 篇)
- [physics.soc-ph](#physicssoc-ph) (1 篇)
- [quant-ph](#quant-ph) (10 篇)
- [math.NT](#mathnt) (1 篇)
- [stat.ME](#statme) (2 篇)
- [math.FA](#mathfa) (1 篇)
- [math.PR](#mathpr) (1 篇)
- [physics.flu-dyn](#physicsflu-dyn) (2 篇)
- [stat.TH](#statth) (1 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [math.OC](#mathoc) (6 篇)
- [q-fin.RM](#q-finrm) (1 篇)
- [math.ST](#mathst) (2 篇)
- [physics.plasm-ph](#physicsplasm-ph) (1 篇)
- [physics.optics](#physicsoptics) (2 篇)
- [econ.TH](#econth) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [math.CO](#mathco) (2 篇)
- [hep-ph](#hep-ph) (2 篇)
- [astro-ph.IM](#astro-phim) (1 篇)
- [q-fin.CP](#q-fincp) (1 篇)

---
<a id='csai'></a>
## cs.AI 

### [73] [FGeo-HyperGNet: Geometric Problem Solving Integrating FormalGeo Symbolic System and Hypergraph Neural Network](https://arxiv.org/abs/2402.11461)
> *FGeo-HyperGNet：融合FormalGeo符号系统与超图神经网络的几何问题求解*

*Xiaokai Zhang, Yang Li, Na Zhu, Cheng Qin, Zhenbing Zeng, Tuo Leng* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 几何问题求解, 神经符号系统, 超图神经网络, FormalGeo, 数学推理

**Comment:** Accepted by IJCAI 2025

> **TL;DR:** FGeo-HyperGNet是一个神经符号系统，通过结合基于FormalGeo的符号系统和超图神经网络来自动解决几何问题，并取得了最先进的结果。

**AI_Comments:** 这篇论文提出了一种创新的神经符号方法来解决几何问题，成功地结合了符号推理和神经网络的能力。利用超图表示几何问题以及“预测-应用”循环生成解决方案是其主要创新点。实现最先进的结果突显了其在推动人工智能在数学推理方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 几何问题求解一直是数学推理和人工智能领域的长期挑战。

**Method:** 本文提出了FGeo-HyperGNet，一个神经符号系统，旨在自动进行类人几何问题求解。该系统包含两个核心组件：符号组件和神经组件。符号组件基于FormalGeo构建，能够自动进行几何关系推理和代数计算，并将解组织成超图，其中条件作为超节点，定理作为超边。神经组件名为HyperGNet，是一个基于注意力机制的超图神经网络，包含一个编码器用于编码超图的结构和语义信息，以及一个定理预测器提供问题求解指导。这两个组件通过“预测-应用”循环协同工作：神经组件根据超图预测定理，符号组件应用定理并更新超图，最终实现可读、可追溯的几何问题自动求解。

**Result:** 实验证明了该神经符号架构的有效性。在FormalGeo7K数据集上，该系统取得了最先进的结果，TPA达到93.50%，PSSR达到88.36%。

**Conclusion:** FGeo-HyperGNet神经符号系统能够有效解决几何问题，实现了可读、可追溯的自动求解，并在相关数据集上达到了最先进的性能。

> **ai_Abstract:** 本文介绍了FGeo-HyperGNet，一个用于自动几何问题求解的新型神经符号系统。它集成了基于FormalGeo的符号系统，用于推理和超图构建，以及基于注意力机制的超图神经网络HyperGNet，用于定理预测。该系统以“预测-应用”循环的方式运行，实现了类人、可读且可追溯的解决方案。在FormalGeo7K数据集上的实验结果表明了其有效性，取得了93.50%的TPA和88.36%的PSSR的最先进性能。

> **摘要翻译:** 几何问题求解一直是数学推理和人工智能领域的长期挑战。我们构建了一个名为FGeo-HyperGNet的神经符号系统，以自动执行类人几何问题求解。其符号组件是一个基于FormalGeo构建的形式系统，能够自动执行几何关系推理和代数计算，并将解组织成一个超图，其中条件作为超节点，定理作为超边。其神经组件名为HyperGNet，是一个基于注意力机制的超图神经网络，包括一个编码器用于编码超图的结构和语义信息，以及一个定理预测器用于提供问题求解指导。神经组件根据超图预测定理，符号组件应用定理并更新超图，从而形成一个“预测-应用”循环，最终实现可读且可追溯的几何问题自动求解。实验证明了该神经符号架构的有效性。我们在FormalGeo7K数据集上取得了93.50%的TPA和88.36%的PSSR，达到了最先进的结果。代码可在https://github.com/BitSecret/HyperGNet获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [115] [When Words Smile: Generating Diverse Emotional Facial Expressions from Text](https://arxiv.org/abs/2412.02508)
> *当文字微笑时：从文本生成多样化的情感面部表情*

*Haidong Xu, Meishan Zhang, Hao Ju, Zhedong Zheng, Erik Cambria, Min Zhang, Hao Fei* | **Category: cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 文本到表情生成, 情感面部表情, 数字人, 情感动态, EmoAva

**Comment:** 19 pages. Resources: https://github.com/WalkerMitty/EmoAva

> **TL;DR:** 提出一个端到端文本到表情模型，能够生成多样化、流畅且情感连贯的面部表情，并引入了大型数据集EmoAva。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的文本到表情生成模型，并明确关注情感动态性，这在现有唇部同步为主的研究中是一个重要突破。同时，引入的大规模高质量数据集EmoAva为未来的研究提供了宝贵资源，有助于推动面部表情合成领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 使数字人表达丰富的情感在对话系统、游戏和其他交互场景中具有重要应用。现有技术在唇部同步方面表现出色，但往往忽视了面部表情的丰富和动态性质。

**Method:** 引入一个端到端文本到表情模型，明确关注情感动态。该模型在连续潜在空间中学习富有表现力的面部变化，并生成多样化、流畅且情感连贯的表情。为了支持这项任务，还引入了一个包含15,000个文本-3D表情对的大规模高质量数据集EmoAva。

**Result:** 在现有数据集和EmoAva上进行的大量实验表明，该方法在多个评估指标上显著优于基线，标志着该领域的重大进步。

**Conclusion:** 该研究通过引入一个端到端文本到表情模型和新的数据集，有效地解决了数字人面部表情动态性不足的问题，并在实验中证明了其优越性，对该领域的发展具有重要意义。

> **ai_Abstract:** 本文提出一个端到端文本到表情模型，旨在解决现有数字人合成技术在面部表情动态性方面的不足。该模型能够在连续潜在空间中学习并生成多样化、流畅且情感连贯的面部表情。为支持研究，作者还引入了大规模高质量数据集EmoAva。实验结果表明，该方法在多个评估指标上显著优于现有基线，推动了该领域的发展。

> **摘要翻译:** 使数字人表达丰富的情感在对话系统、游戏和其他交互场景中具有重要应用。虽然最近在会说话的头部合成方面的进展在唇部同步方面取得了令人印象深刻的成果，但它们往往忽视了面部表情的丰富和动态性质。为了填补这一关键空白，我们引入了一个端到端的文本到表情模型，该模型明确关注情感动态。我们的模型在连续潜在空间中学习富有表现力的面部变化，并生成多样化、流畅且情感连贯的表情。为了支持这项任务，我们引入了EmoAva，一个包含15,000个文本-3D表情对的大规模高质量数据集。在现有数据集和EmoAva上进行的大量实验表明，我们的方法在多个评估指标上显著优于基线，标志着该领域的重大进步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [164] [AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents](https://arxiv.org/abs/2503.18666)
> *AgentSpec：可定制的运行时强制执行，保障LLM代理的安全与可靠*

*Haoyu Wang, Christopher M. Poskitt, Jun Sun* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** LLM代理, 运行时强制, 安全性, 领域特定语言, AgentSpec

**Comment:** Accepted by the 48th IEEE/ACM International Conference on Software
  Engineering (ICSE 2026)

> **TL;DR:** AgentSpec是一种轻量级领域特定语言，用于在运行时对LLM代理施加安全约束，通过定义结构化规则来有效防止不安全行为，且计算开销极低。

**AI_Comments:** AgentSpec的创新点在于其轻量级的领域特定语言（DSL）方法，实现了LLM代理的运行时安全强制执行，显著提升了可解释性、模块化和效率，弥补了现有方法的不足。其在多个关键领域的广泛适用性，以及通过LLM自动化规则生成的能力，都极大地增强了其实用性和潜在影响力，为LLM代理的安全部署提供了强大工具。

<details>
  <summary>Details</summary>

**Motivation:** LLM代理在不同领域的部署日益增多，但其自主性引入了安全风险，包括安全漏洞、法律违规和意外有害行为。现有的缓解方法（如基于模型的保障和早期强制执行策略）在鲁棒性、可解释性和适应性方面存在不足。

**Method:** 本文提出了AgentSpec，一种轻量级领域特定语言（DSL），用于指定和强制执行LLM代理的运行时约束。用户可以定义包含触发器、谓词和强制机制的结构化规则，以确保代理在预定义的安全边界内运行。AgentSpec被应用于代码执行、具身代理和自动驾驶等多个领域。此外，研究还探索了使用LLM自动化规则生成。

**Result:** AgentSpec成功阻止了90%以上的代码代理不安全执行，消除了具身代理任务中的所有危险行为，并强制自动驾驶汽车（AVs）实现了100%的合规性。尽管提供了强大的安全保障，AgentSpec的计算开销仍保持在毫秒级。通过LLM（OpenAI o1）自动生成的规则，在具身代理任务中达到了95.56%的精确率和70.96%的召回率，成功识别了87.26%的危险代码，并在8个自动驾驶场景中阻止了5个场景的违法行为。

**Conclusion:** AgentSpec通过结合可解释性、模块化和效率，为跨不同应用强制执行LLM代理安全性提供了一个实用且可扩展的解决方案。

> **ai_Abstract:** AgentSpec是一种创新的领域特定语言（DSL），旨在解决大型语言模型（LLM）代理日益增长的安全风险。它允许用户定义结构化的运行时规则，包含触发器、谓词和强制机制，以确保LLM代理在预设的安全边界内运行。该系统在代码执行、具身代理和自动驾驶等多个领域进行了成功验证，展示了其在防止不安全行为方面的高效性（例如，代码代理90%以上、具身代理100%、自动驾驶100%），同时保持极低的计算开销。AgentSpec还支持通过LLM自动化生成规则，进一步提升了其实用性和可扩展性，使其成为LLM代理安全保障的实际方案。

> **摘要翻译:** 基于LLM构建的代理正越来越多地部署在不同领域，自动化复杂的决策和任务执行。然而，它们的自主性引入了安全风险，包括安全漏洞、法律违规和意外有害行为。现有的缓解方法，如基于模型的保障和早期强制执行策略，在鲁棒性、可解释性和适应性方面存在不足。为了解决这些挑战，我们提出了AgentSpec，一种轻量级领域特定语言，用于指定和强制执行LLM代理的运行时约束。通过AgentSpec，用户可以定义包含触发器、谓词和强制机制的结构化规则，确保代理在预定义的安全边界内运行。我们在多个领域实现了AgentSpec，包括代码执行、具身代理和自动驾驶，展示了其适应性和有效性。我们的评估表明，AgentSpec成功阻止了90%以上的代码代理不安全执行，消除了具身代理任务中的所有危险行为，并强制自动驾驶汽车（AVs）实现了100%的合规性。尽管提供了强大的安全保障，AgentSpec的计算开销仍保持在毫秒级。通过结合可解释性、模块化和效率，AgentSpec为跨不同应用强制执行LLM代理安全性提供了一个实用且可扩展的解决方案。我们还使用LLM自动化规则生成并评估了它们的有效性。我们的评估显示，OpenAI o1生成的规则在具身代理方面实现了95.56%的精确率和70.96%的召回率，成功识别了87.26%的危险代码，并在8个场景中阻止了5个场景的自动驾驶汽车违法行为。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [206] [Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining](https://arxiv.org/abs/2505.11122)
> *穿越Alpha丛林：一种由LLM驱动的MCTS公式化因子挖掘框架*

*Yu Shi, Yitong Duan, Jian Li* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** Alpha因子挖掘, 大型语言模型, 蒙特卡洛树搜索, 量化投资, 金融回测

**Comment:** 

> **TL;DR:** 本文提出了一种结合大型语言模型（LLM）和蒙特卡洛树搜索（MCTS）的新框架，用于自动化和高效地挖掘可解释的量化投资Alpha因子，并在实际市场数据上表现优异。

**AI_Comments:** 该论文创新性地将LLM的强大推理和生成能力与MCTS的探索机制结合起来，解决了传统自动化Alpha因子挖掘中效率低和可解释性差的问题。通过引入金融回测反馈指导MCTS和频繁子树避免机制，显著提升了搜索效率和因子多样性。其结果表明在实际市场中的优越性能，且生成的因子具有良好可解释性，这对于量化投资领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统公式化Alpha因子挖掘依赖人工经验，而现有的自动化方法（如遗传编程或强化学习）存在搜索效率低下或生成难以解释的Alpha因子的问题。

**Method:** 本框架将大型语言模型（LLM）与蒙特卡洛树搜索（MCTS）相结合。LLM利用其指令遵循和推理能力，在MCTS驱动的探索中迭代生成和优化符号Alpha公式。通过对每个候选因子进行金融回测提供丰富的量化反馈来指导MCTS探索，以高效导航巨大的搜索空间。此外，引入了频繁子树避免机制，以增强搜索多样性并防止公式同质化。

**Result:** 在实际股票市场数据上的实验结果表明，该基于LLM的框架在挖掘具有卓越预测准确性和交易性能的Alpha因子方面优于现有方法。

**Conclusion:** 该框架为公式化Alpha因子挖掘建立了一种更有效和高效的范式，并且生成的公式更易于人工解释。

> **ai_Abstract:** 本文提出了一种结合大型语言模型（LLM）和蒙特卡洛树搜索（MCTS）的新型框架，旨在解决量化投资中Alpha因子挖掘的效率和可解释性问题。该框架利用LLM生成和优化Alpha公式，并通过金融回测的量化反馈指导MCTS进行高效探索。同时，引入频繁子树避免机制以增加搜索多样性。实验证明，该框架在实际市场数据上挖掘的Alpha因子具有更高的预测准确性和交易性能，且公式更易于人工理解，从而提供了一种更有效和高效的Alpha因子挖掘方法。

> **摘要翻译:** Alpha因子挖掘在量化投资中至关重要，用于从复杂的金融数据中识别预测信号。虽然传统的公式化Alpha挖掘依赖于人类专业知识，但当代自动化方法，例如基于遗传编程或强化学习的方法，通常存在搜索效率低下或生成的Alpha因子难以解释的问题。本文介绍了一种将大型语言模型（LLM）与蒙特卡洛树搜索（MCTS）相结合的新颖框架，以克服这些限制。我们的框架利用LLM的指令遵循和推理能力，在MCTS驱动的探索中迭代生成和优化符号Alpha公式。一个关键的创新是通过对每个候选因子进行金融回测提供丰富的量化反馈来指导MCTS探索，从而实现对巨大搜索空间的有效导航。此外，引入了频繁子树避免机制，以增强搜索多样性并防止公式同质化，进一步提高性能。在实际股票市场数据上的实验结果表明，我们的基于LLM的框架在挖掘具有卓越预测准确性和交易性能的Alpha因子方面优于现有方法。生成的公式也更易于人工解释，为公式化Alpha挖掘建立了一种更有效和高效的范式。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [248] [Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory](https://arxiv.org/abs/2505.17696)
> *增强AI系统弹性：基于控制理论的LSTM弹性公式化与保证*

*Sota Yoshihara, Ryosuke Yamamoto, Hiroyuki Kusumoto, Masanari Shimura* | **Category: cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** LSTM弹性, 控制理论, 恢复时间, 弹性感知训练

**Comment:** 9 pages, 6 figures. Appendix: 17 pages. First three listed authors
  have equal contributions

> **TL;DR:** 本文提出一个新理论框架，通过引入“恢复时间”并改进$\delta$ISS理论，为LSTM网络在控制系统中的弹性提供保证和评估，并实现弹性感知训练。

**AI_Comments:** 本文创新性地将控制理论应用于深度学习模型（LSTM）的弹性分析，特别是引入“恢复时间”这一量化指标，并基于$\delta$ISS理论推导出可操作的恢复时间上限，为AI系统的鲁棒性和可靠性提供了理论支撑和实践指导，尤其对于安全关键领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为控制系统中的长短期记忆（LSTM）网络提供保证和评估其弹性的新理论框架，特别是在安全关键型AI应用中进行严格的质量保证。

**Method:** 提出了一种新的弹性度量标准“恢复时间”，用于量化LSTM在异常输入后恢复正常状态所需的时间。通过数学上改进LSTM的增量输入到状态稳定性（$\delta$ISS）理论，推导出一个实用的、与数据无关的恢复时间上限。

**Result:** 导出的恢复时间上限使得弹性感知训练成为可能。在简单模型上的实验验证表明，所提出的弹性估计和控制方法是有效的。

**Conclusion:** 本文的研究为安全关键型AI应用中严格的质量保证奠定了基础，通过提供LSTM弹性的公式化和保证方法。

> **ai_Abstract:** 本文提出了一种基于控制理论的新型框架，旨在量化并保证LSTM网络在控制系统中的弹性。研究引入了“恢复时间”这一新度量，并基于对增量输入到状态稳定性（$\delta$ISS）理论的改进，推导出了一个实用的、与数据无关的恢复时间上限。这一上限有助于实现弹性感知训练。实验结果验证了该方法的有效性，为安全关键AI应用的质量保证提供了基础。

> **摘要翻译:** 本文提出了一个新颖的理论框架，用于保证和评估控制系统中长短期记忆（LSTM）网络的弹性。我们引入“恢复时间”作为一种新的弹性度量标准，以量化LSTM在异常输入后恢复到正常状态所需的时间。通过对LSTM的增量输入到状态稳定性（$\delta$ISS）理论进行数学上的精炼，我们推导出了一个实用的、与数据无关的恢复时间上限。这个上限使我们能够进行弹性感知训练。在简单模型上的实验验证证明了我们弹性估计和控制方法的有效性，为安全关键型AI应用中的严格质量保证奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [291] [Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding](https://arxiv.org/abs/2505.19219)
> *路径交汇之处：经典与学习型多智能体路径规划的综合调查*

*Shiyue Wang, Haozheng Xu, Yuhan Zhang, Jingran Lin, Changhong Lu, Xiangfeng Wang, Wenhao Li* | **Category: cs.AI, cs.LG, cs.MA, math.CO** | **Updated: 2025-07-31**

**Keywords:** 多智能体路径规划, 综述, 经典算法, 学习方法, 基准测试

**Comment:** 112 pages, 21 figures, 20 tables. The project website is:
  https://wangsh1yue.github.io/Where-Paths-Collide

> **TL;DR:** 本调查综合回顾了多智能体路径规划（MAPF）领域的经典算法和新兴学习方法，揭示了评估方法上的差异，并提出了未来研究方向和标准化基准测试的需求。

**AI_Comments:** 这篇综述非常有价值，因为它首次全面地弥合了经典MAPF算法与新兴学习型方法之间的鸿沟。其创新之处在于提出了一个统一的框架，并对200多篇论文的实验实践进行了系统分析，揭示了当前评估方法上的显著差异和不足。该论文的重要性在于其强调了标准化基准测试的紧迫性，并为未来研究指明了清晰的方向，特别是结合深度学习和大型语言模型的新型求解器架构。这对于推动MAPF从理论走向更广泛的实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体路径规划（MAPF）已从理论挑战演变为现实世界多机器人协调的关键技术。然而，经典算法方法与新兴的学习型方法之间存在长期分歧。本调查旨在弥合这一分歧，并为研究人员和实际部署提供全面参考和指导。

**Method:** 本调查提出了一个统一框架，涵盖了搜索型方法（如基于冲突搜索、基于优先级搜索、大邻域搜索）、编译型方法（如SAT、SMT、CSP、ASP、MIP公式）和数据驱动技术（如强化学习、监督学习、混合策略）。通过对200多篇论文的实验实践进行系统分析，并提供了评估指标、环境类型和基线选择的全面分类。

**Result:** 调查发现评估方法存在显著差异：经典方法通常在更大规模的实例（高达200x200网格，1000多个智能体）上进行测试，而学习型方法主要在10-100个智能体上进行。这突显了对标准化基准测试协议的需求。

**Conclusion:** 本调查概述了有前景的未来方向，包括考虑博弈论的混合动机MAPF、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构。它为研究人员提供了全面参考，并为在日益复杂的实际应用中部署MAPF解决方案提供了实用指南。

> **ai_Abstract:** 本调查对多智能体路径规划（MAPF）领域进行了全面回顾，系统地分析了经典算法方法和新兴学习型方法。它提出了一个统一的框架，涵盖了搜索型、编译型和数据驱动型技术。通过分析200多篇论文，调查揭示了不同方法在评估规模上的显著差异，并强调了建立标准化基准测试协议的必要性。最后，该调查指出了MAPF未来研究的几个重要方向，旨在为该领域的研究人员和实际应用提供全面的指导。

> **摘要翻译:** 多智能体路径规划（MAPF）是人工智能和机器人学中的一个基本问题，它要求为多个智能体计算从起始位置到指定目标的无碰撞路径。随着自主系统在仓库、城市交通和其他复杂环境中变得越来越普及，MAPF已从一个理论挑战演变为现实世界多机器人协调的关键促成因素。这项全面的调查弥合了MAPF研究中经典算法方法与新兴学习型方法之间长期存在的分歧。我们提出了一个统一的框架，涵盖了基于搜索的方法（包括基于冲突的搜索、基于优先级的搜索和大邻域搜索）、基于编译的方法（SAT、SMT、CSP、ASP和MIP公式）以及数据驱动技术（强化学习、监督学习和混合策略）。通过对200多篇论文的实验实践进行系统分析，我们发现了评估方法上的显著差异，与学习型方法（主要为10-100个智能体）相比，经典方法通常在更大规模的实例（高达200x200网格，1000多个智能体）上进行测试。我们提供了评估指标、环境类型和基线选择的全面分类，强调了标准化基准测试协议的需求。最后，我们概述了有前景的未来方向，包括考虑博弈论的混合动机MAPF、基于大型语言模型的语言接地规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构。这项调查既是研究人员的综合参考，也是在日益复杂的实际应用中部署MAPF解决方案的实用指南。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [314] [BCR-DRL: Behavior- and Context-aware Reward for Deep Reinforcement Learning in Human-AI Coordination](https://arxiv.org/abs/2408.07877)
> *BCR-DRL：面向人机协作中深度强化学习的行为与上下文感知奖励*

*Xin Hao, Bahareh Nakisa, Mohmmad Naim Rastgoo, Gaoyang Pang* | **Category: cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 深度强化学习, 人机协作, 稀疏奖励, 行为感知, 上下文感知

**Comment:** 

> **TL;DR:** BCR-DRL提出了一种行为和上下文感知的奖励机制，以解决人机协作中深度强化学习的稀疏奖励和不可预测的人类行为问题，从而提高探索和利用效率。

**AI_Comments:** BCR-DRL的创新之处在于其结合了行为和上下文信息来设计奖励，尤其是在人机协作这一复杂领域。双重内在奖励和上下文感知加权机制的设计，有效地解决了DRL在此领域面临的关键挑战。其贡献在于为人机协作中的AI训练提供了更有效的奖励信号，有望推动相关应用的发展。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习在人机协作中面临稀疏奖励和不可预测的人类行为两大挑战，这限制了其识别有效协作策略的能力，并损害了探索和利用的优化。

**Method:** 本文提出了一种创新的行为和上下文感知奖励（BCR）机制，用于深度强化学习，通过利用人机协作中的人类行为和上下文信息来优化探索和利用。BCR包含两个组件：1) 一种新颖的双重内在奖励方案，通过AI自我激励和人类激励的内在奖励来增强探索，并采用基于对数的策略捕获稀疏奖励；2) 一种新的上下文感知加权机制，利用反映学习演进的上下文信息，帮助AI智能体优先选择更好地与人类伙伴协作的行动，从而改善利用。

**Result:** 在Overcooked环境中的大量模拟表明，与最先进的基线相比，我们的方法可以将累积稀疏奖励提高约20%，并将样本效率提高约38%。

**Conclusion:** BCR-DRL通过引入行为和上下文感知奖励，有效解决了人机协作中深度强化学习的稀疏奖励和人类行为不可预测性问题，显著提升了AI智能体与人类伙伴的协作性能和学习效率。

> **ai_Abstract:** 本文提出BCR-DRL，一种行为和上下文感知的奖励机制，旨在解决人机协作中深度强化学习面临的稀疏奖励和人类行为不可预测性问题。BCR包含双重内在奖励方案以增强探索，以及上下文感知加权机制以改善利用。实验结果表明，该方法能显著提高累积稀疏奖励和样本效率。

> **摘要翻译:** 深度强化学习（DRL）为训练人工智能（AI）智能体与人类伙伴协作提供了一个强大的框架。然而，DRL在人机协作（HAIC）中面临两个关键挑战：稀疏奖励和不可预测的人类行为。这些挑战由于其探索和利用能力受损，极大地限制了DRL识别有效协作策略。为了解决这些限制，我们为DRL提出了一种创新的行为和上下文感知奖励（BCR），它通过利用人机协作中的人类行为和上下文信息来优化探索和利用。我们的BCR由两个组件组成：(i) 一种新颖的双重内在奖励方案，以增强探索。该方案包含AI自我激励的内在奖励和人类激励的内在奖励，旨在通过基于对数的策略增加稀疏奖励的捕获；以及(ii) 一种新的上下文感知加权机制，用于设计的奖励以改善利用。该机制通过利用可以反映学习演进的上下文信息，帮助AI智能体优先选择更好地与人类伙伴协作的行动。在Overcooked环境中的大量模拟表明，我们的方法可以将累积稀疏奖励提高约20%，并将样本效率提高约38%与最先进的基线相比。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [325] [GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis](https://arxiv.org/abs/2507.21035)
> *GenoMAS：一个通过代码驱动的基因表达分析实现科学发现的多智能体框架*

*Haoyang Liu, Yijiang Li, Haohan Wang* | **Category: cs.AI, cs.LG, cs.MA, q-bio.GN** | **Updated: 2025-07-31**

**Keywords:** 基因表达分析, 多智能体系统, LLM, 科学发现, 生物信息学

**Comment:** 51 pages (13 pages for the main text, 9 pages for references, and 29
  pages for the appendix)

> **TL;DR:** GenoMAS是一个多智能体框架，结合了结构化工作流和自主代理的优点，通过LLM代理团队进行基因表达分析，并在基因表达分析任务中取得了显著的性能提升。

**AI_Comments:** GenoMAS的创新之处在于其结合了LLM的强大能力与多智能体协作框架，解决了传统自动化方法在基因表达分析中灵活性和精度不足的问题。其引导式规划框架允许代理在保持逻辑连贯性的同时适应数据特异性，显著提升了科学发现的效率和准确性。该方法在基准测试中的出色表现，以及发现生物学上合理关联的能力，凸显了其在生物医学研究领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 基因表达分析是许多生物医学发现的关键，但从原始转录组数据中提取见解非常困难，原因在于多重大型半结构化文件的复杂性以及对广泛领域专业知识的需求。当前的自动化方法受限于不灵活的工作流（在边缘情况下会崩溃）或缺乏科学研究所需精度的全自主代理。

**Method:** GenoMAS提出了一个由基于LLM的科学家组成的团队，该团队整合了结构化工作流的可靠性和自主代理的适应性。它通过类型化消息传递协议协调六个专门的LLM代理，每个代理都为共享的分析画布贡献互补的优势。GenoMAS的核心是一个引导式规划框架：编程代理将高级任务指南分解为行动单元，并在每个关节点选择前进、修改、绕过或回溯，从而在适应基因组数据特性的同时保持逻辑连贯性。

**Result:** 在GenoTEX基准测试中，GenoMAS在数据预处理方面达到了89.13%的复合相似性相关性，在基因识别方面达到了60.48%的F1分数，分别超越了现有最佳技术10.61%和16.85%。除了这些指标，GenoMAS还发现了经文献证实的生物学上合理的基因-表型关联，同时调整了潜在的混杂因素。

**Conclusion:** GenoMAS通过其独特的多智能体框架，在基因表达分析中实现了卓越的性能提升，并能够发现生物学上合理的基因-表型关联，证明了其在科学发现方面的潜力。

> **ai_Abstract:** GenoMAS提出了一个创新的多智能体框架，旨在解决基因表达分析中数据复杂性和专业知识需求带来的挑战。它结合了LLM驱动的智能体团队，通过结构化工作流和自主适应性，实现了基因表达分析的自动化和精确化。GenoMAS的核心是引导式规划框架，使代理能够灵活处理基因组数据的特殊性。在GenoTEX基准测试中，GenoMAS在数据预处理和基因识别方面均显著优于现有技术，并能发现生物学上合理的基因-表型关联。

> **摘要翻译:** 基因表达分析是许多生物医学发现的关键，然而，由于多个大型半结构化文件的复杂性以及对广泛领域专业知识的需求，从原始转录组数据中提取见解仍然非常困难。当前的自动化方法往往受限于不灵活的工作流（在边缘情况下会崩溃）或缺乏严谨科学研究所需精度的全自主代理。GenoMAS 通过提出一个基于大型语言模型（LLM）的科学家团队，整合了结构化工作流的可靠性与自主代理的适应性，开辟了一条不同的道路。GenoMAS 通过类型化消息传递协议协调六个专门的 LLM 代理，每个代理都为共享的分析画布贡献互补的优势。GenoMAS 的核心是一个引导式规划框架：编程代理将高级任务指南展开为行动单元，并在每个关节点选择前进、修改、绕过或回溯，从而在适应基因组数据特性的同时保持逻辑连贯性。在 GenoTEX 基准测试中，GenoMAS 在数据预处理方面达到了 89.13% 的复合相似性相关性，在基因识别方面达到了 60.48% 的 F1 分数，分别超越了现有最佳技术 10.61% 和 16.85%。除了这些指标，GenoMAS 还发现了经文献证实的生物学上合理的基因-表型关联，同时调整了潜在的混杂因素。代码可在 https://github.com/Liu-Hy/GenoMAS 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [339] [Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification](https://arxiv.org/abs/2506.07528)
> *在事实核查中协调搜索引导推理与推理引导搜索*

*Qisheng Hu, Quanyu Long, Wenya Wang* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 多跳事实核查, 信息检索, 推理, 强化学习, HARIS

**Comment:** Work in progress

> **TL;DR:** HARIS通过协调高层推理代理和低层搜索代理，显著提高了多跳事实核查的准确性和可解释性。

**AI_Comments:** HARIS的创新之处在于其明确建模并协调了推理和搜索这两个核心过程，通过分层代理的设计实现了专业化和协同作用。这对于需要复杂信息检索和逻辑推理的多跳事实核查任务至关重要，提升了系统性能和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 多跳事实核查具有挑战性，需要多步骤推理来构建验证链，并迭代搜索信息以发现隐藏的桥接事实。这是一个交织过程，因为有效的推理依赖于动态检索的证据，而有效的搜索需要推理来根据部分信息优化查询。

**Method:** 我们提出了分层代理推理和信息搜索（HARIS），它明确建模了推理驱动搜索和搜索知情推理的协调过程。HARIS包含一个专注于构建主要验证链并在需要时生成事实问题的高层推理代理，以及一个迭代检索更多信息并根据中间发现优化搜索的低层搜索代理。HARIS使用基于结果的强化学习进行训练。

**Result:** 在EX-FEVER和HOVER基准测试中的实验结果表明，HARIS取得了强大的性能，极大地推进了多跳事实核查。

**Conclusion:** HARIS通过其独特的分层代理设计和协调机制，显著提高了多跳事实核查的准确性和可解释性，并在现有基准上表现出色。

> **ai_Abstract:** 该论文提出了分层代理推理和信息搜索（HARIS），旨在解决多跳事实核查中搜索与推理的固有交织挑战。HARIS包含一个高层推理代理和一个低层搜索代理，分别负责构建验证链和迭代信息检索。这种协调设计提高了验证准确性和可解释性。通过强化学习训练，HARIS在EX-FEVER和HOVER基准测试中表现出色，显著推动了多跳事实核查领域的发展。

> **摘要翻译:** 多跳事实核查本身就具有挑战性，它需要多步骤推理来构建验证链，同时迭代搜索信息以揭示隐藏的桥接事实。这个过程是根本上交织的，因为有效的推理依赖于动态检索的证据，而有效的搜索则需要推理来根据部分信息细化查询。为了实现这一点，我们提出了分层代理推理和信息搜索（HARIS），它明确建模了推理驱动搜索和搜索知情推理的协调过程。HARIS由一个专注于构建主要验证链、在需要更多信息时生成事实问题的高层推理代理，以及一个迭代检索更多信息、根据中间发现细化其搜索的低层搜索代理组成。这种设计允许每个代理专注于各自的任务，从而提高验证准确性和可解释性。HARIS使用基于结果的强化学习进行训练。在EX-FEVER和HOVER基准测试中的实验结果表明，HARIS取得了强大的性能，极大地推进了多跳事实核查。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [369] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
> *Pro2Guard：通过概率模型检测实现LLM代理安全的主动运行时强制执行*

*Haoyu Wang, Chris M. Poskitt, Jun Sun, Jiali Wei* | **Category: cs.AI, cs.SE** | **Updated: 2025-08-01**

**Keywords:** LLM代理安全, 运行时强制执行, 概率模型检测, 主动安全, 离散时间马尔可夫链

**Comment:** 

> **TL;DR:** Pro2Guard是一个主动运行时安全框架，通过概率模型检测预测LLM代理的未来风险，并在违规发生前进行干预。

**AI_Comments:** Pro2Guard的创新之处在于其主动而非被动的安全强制执行范式，通过引入概率模型检测和DTMC学习，实现了对LLM代理未来风险的预测和提前干预。这克服了现有规则系统在处理不确定性和长周期依赖方面的不足，对于提升LLM代理在安全关键领域的可靠性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于规则的LLM代理安全强制执行系统是反应式的，只能在不安全行为即将发生或已发生时作出响应，缺乏远见，难以处理长周期依赖和分布变化。为了解决这些局限性，本文提出了Pro2Guard。

**Method:** Pro2Guard通过概率可达性分析，将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC）。在运行时，它通过估计达到不安全状态的概率来预测未来风险，当预测风险超过用户定义的阈值时，在违规发生前触发干预。它还结合了语义有效性检查并利用PAC界限来确保统计可靠性。

**Result:** 在具身家庭代理任务中，Pro2Guard使用低阈值可以提前阻止高达93.6%的不安全任务，同时通过可配置模式（如反射）平衡安全与任务成功，维持高达80.4%的任务完成率。在自动驾驶场景中，Pro2Guard实现了100%的交通法规违规和碰撞预测，提前38.66秒预测风险。

**Conclusion:** Pro2Guard通过主动预测和干预，显著提升了LLM代理在安全关键领域（如具身代理和自动驾驶）的运行时安全性，克服了现有反应式系统的局限性。

> **ai_Abstract:** Pro2Guard是一个针对大型语言模型（LLM）代理的主动运行时安全强制执行框架，旨在解决现有反应式系统在处理LLM代理随机行为所带来的安全风险方面的局限性。该框架通过将代理行为抽象为符号状态并学习离散时间马尔可夫链（DTMC），利用概率可达性分析来预测未来风险。当预测风险超过预设阈值时，Pro2Guard会在不安全行为发生之前进行干预。实验结果表明，Pro2Guard在具身代理任务中能有效提前阻止不安全行为，并能在自动驾驶场景中准确预测交通违规和碰撞，显著提升了LLM代理的安全性。

> **摘要翻译:** 大型语言模型（LLM）代理在机器人、虚拟助手和网络自动化等领域展现出强大的自主能力。然而，它们的随机行为引入了难以预料的重大安全风险。现有的基于规则的强制执行系统，如AgentSpec，侧重于开发反应性安全规则，这些规则通常只在不安全行为即将发生或已经发生时才做出响应。这些系统缺乏远见，难以处理长周期依赖和分布变化。为了解决这些局限性，我们提出了Pro2Guard，一个基于概率可达性分析的主动运行时强制执行框架。Pro2Guard将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC）。在运行时，它通过估计达到不安全状态的概率来预测未来风险，当预测风险超过用户定义的阈值时，在违规发生前触发干预。通过结合语义有效性检查并利用PAC界限，Pro2Guard在近似底层真实模型的同时确保了统计可靠性。我们在两个安全关键领域：具身家庭代理和自动驾驶中对Pro2Guard进行了广泛评估。在具身代理任务中，Pro2Guard使用低阈值可以提前阻止高达93.6%的不安全任务，同时可配置模式（例如，反射）允许平衡安全与任务成功，维持高达80.4%的任务完成率。在自动驾驶场景中，Pro2Guard实现了100%的交通法规违规和碰撞预测，提前38.66秒预测风险。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [376] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
> *超性质约束的安全强化学习*

*Ernest Bonnah, Luan Viet Nguyen, Khaza Anuarul Hoque* | **Category: cs.AI, cs.LG, cs.LO, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 安全强化学习, 超性质, HyperTWTL, 玻尔兹曼softmax, 机器人

**Comment:** Accepted in IEEE/ACM MEMOCODE 2025

> **TL;DR:** 本文提出了一种使用动态玻尔兹曼softmax强化学习，在满足HyperTWTL约束下学习安全感知最优策略的方法，解决了超性质在安全强化学习中的应用空白。

**AI_Comments:** 本文的创新点在于首次将超性质（通过HyperTWTL）引入到安全强化学习中，填补了该领域的显著空白。其重要性体现在为机器人等关键应用提供了更严格的安全保障，通过形式化方法确保学习策略的安全性。该方法结合了形式化规约和强化学习，为构建更可靠的AI系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间逻辑约束安全强化学习(SRL)研究已有一些进展，但利用超性质探索安全感知强化学习(RL)的研究存在显著空白。

**Method:** 作者提出了一种方法，利用动态玻尔兹曼softmax强化学习来学习安全感知的最优策略，同时满足HyperTWTL约束。该方法将智能体动态建模为马尔可夫决策过程(MDP)，并将不透明性/安全约束形式化为HyperTWTL。

**Result:** 所提出的方法通过一个取放机器人任务案例研究证明了其有效性和可扩展性。与两种基线强化学习算法相比，该方法表现更优。

**Conclusion:** 本文成功地弥补了超性质在安全强化学习中应用的空白，提出了一种有效且可扩展的HyperTWTL约束安全强化学习方法，并在机器人应用中验证了其优越性。

> **ai_Abstract:** 本文关注HyperTWTL约束的安全强化学习(SecRL)，旨在弥补现有研究中利用超性质进行安全感知强化学习的空白。作者提出了一种新方法，该方法在马尔可夫决策过程(MDP)框架下，通过动态玻尔兹曼softmax强化学习学习满足HyperTWTL安全约束的最优策略。实验结果表明，该方法在机器人取放任务中有效且可扩展，并优于其他基线算法。

> **摘要翻译:** 时间窗时序逻辑的超性质 (HyperTWTL) 是一种领域特定的形式化规约语言，以其在紧凑表示机器人应用的安全、不透明性和并发属性方面的有效性而闻名。本文专注于HyperTWTL约束的安全强化学习 (SecRL)。尽管时序逻辑约束的安全强化学习 (SRL) 是一个不断发展的研究问题，并且已有几篇现有文献，但在利用超性质探索安全感知强化学习 (RL) 方面存在显著的研究空白。鉴于智能体的动态行为是一个马尔可夫决策过程 (MDP)，并且不透明性/安全约束被形式化为HyperTWTL，我们提出了一种方法，用于使用动态玻尔兹曼softmax强化学习来学习安全感知的最优策略，同时满足HyperTWTL约束。我们通过一个取放机器人任务案例研究证明了我们所提出方法的有效性和可扩展性。我们还将我们的结果与其他两种基线RL算法进行了比较，表明我们所提出的方法优于它们。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [381] [Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models](https://arxiv.org/abs/2506.17114)
> *数学证明作为试金石：揭示先进大型推理模型的失效模式*

*Dadi Guo, Jiayu Liu, Zhiyuan Fan, Zhitao He, Haoran Li, Yumeng Wang, Yi R. Fung* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 大型推理模型, 数学证明, 失效模式, 逻辑推理, RFMDataset

**Comment:** 

> **TL;DR:** 大型推理模型在数学证明方面存在严重缺陷，需要更精细化的逻辑训练。

**AI_Comments:** 这篇论文的创新点在于提出了一个新颖的诊断方法，利用数学证明的严谨性来系统性地揭示大型推理模型隐藏的推理缺陷，而非仅仅依赖传统的数值评估。其重要性在于揭示了当前大型语言模型（LLMs）在逻辑推理，特别是多步、严谨逻辑推理方面的深层局限性，并提出了未来训练方向的建议。RFMDataset的构建也为后续研究提供了有价值的基准。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型推理模型在流行数据集上报告的高准确率、纯数值评估以及潜在的基准泄露掩盖了其真实的推理缺陷。为了解决这个问题，需要一种诊断工具来揭示这些隐藏的失败。

**Method:** 本文提出利用数学证明固有的严谨性和方法复杂性作为诊断工具来揭示大型推理模型的隐藏失败。为此，研究者引入了RFMDataset，一个包含200个不同数学证明问题的集合，并彻底评估了先进模型在其上的性能。

**Result:** 深入分析揭示了10种细粒度错误类型，表明当前大型推理模型存在根本性局限：1）模型在数学证明方面表现挣扎，对不到20%的问题能生成完全正确的证明，甚至在基本问题上失败；2）模型表现出多种推理失败，单步推理的正确性和严谨性缺乏保证；3）模型在推理过程中出现幻觉和不完整性。

**Conclusion:** 模型的自我反思不足以解决当前的逻辑困境，因此需要形式化和细粒度的逻辑训练。

> **ai_Abstract:** 本文提出使用数学证明作为诊断工具，以揭示大型推理模型被高报告准确率和基准泄露所掩盖的真实推理缺陷。研究者引入了包含200个数学证明问题的RFMDataset，并对先进模型进行了评估。分析揭示了10种细粒度错误类型，表明模型在数学证明中表现挣扎，单步推理缺乏正确性保证，并存在幻觉和不完整性。研究强调模型自我反思不足，需要形式化和细粒度的逻辑训练。

> **摘要翻译:** 大型推理模型（例如R1，o3）在数学问题解决方面表现出卓越的能力。然而，这些先进模型在流行数据集上报告的高准确率、对纯数值评估的依赖以及潜在的基准泄露，常常掩盖了它们真实的推理缺陷。为了解决这个问题，我们提出利用数学证明固有的严谨性和方法复杂性作为诊断工具，以揭示这些隐藏的失败。具体而言，我们引入了RFMDataset（揭示失效模式），这是一个包含200个不同数学证明问题的集合，并彻底评估了先进模型在其上的性能。我们对其失败的深入分析揭示了10种细粒度错误类型，这表明当前大型推理模型存在根本性局限：1）大型推理模型在数学证明方面表现出深刻的挣扎，一些模型对不到20%的问题生成完全正确的证明，甚至在基本问题上失败；2）模型表现出多种推理失败，突出表明单步推理的正确性和严谨性缺乏保证；3）模型在推理过程中表现出幻觉和不完整性。我们的发现表明，模型的自我反思不足以解决当前的逻辑困境，需要形式化和细粒度的逻辑训练。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [408] [AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift](https://arxiv.org/abs/2507.07820)
> *人工智能应更好地感知，而非仅是更大规模：自适应感知作为一种范式转变*

*Eunsu Baek, Keondo Park, Jeonggil Ko, Min-hwan Oh, Taesik Gong, Hyung-Sin Kim* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 自适应感知, AI可持续性, 小型模型, 范式转变, 生物启发

**Comment:** 

> **TL;DR:** 当前人工智能依赖模型和数据规模化，带来高昂成本。本文提出受生物启发的自适应感知作为范式转变，通过在输入端调节传感器参数，使小型模型也能超越大型模型，实现可持续、高效、公平的AI。

**AI_Comments:** 这篇论文提出了一个非常及时且重要的概念，挑战了当前AI领域“越大越好”的主流趋势。它从生物系统获得灵感，提出自适应感知，为开发更高效、可持续和鲁棒的AI提供了有前景的方向，并解决了关键的环境和伦理问题。文中引用的简短经验证据支持了其潜在影响。提出的路线图和研究方向对指导未来的工作具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前人工智能的进步过度依赖于扩展神经网络模型和增大训练数据集，这导致了显著的环境、经济和伦理成本，限制了AI的可持续性和公平可及性。

**Method:** 本文倡导将自适应感知作为一种基础性转变，该方法受生物感知系统启发，在输入层动态调节传感器参数（如曝光、灵敏度、多模态配置），以显著缓解协变量偏移并提高效率。文章还概述了自适应感知在实际应用中的集成路线图，评估了技术和伦理挑战，并提出了有针对性的研究方向。

**Result:** 经验证据表明，自适应感知能够使小型模型（例如EfficientNet-B0）超越使用更多数据和计算进行训练的、实质上更大的模型（例如OpenCLIP-H）。

**Conclusion:** 本文旨在推动AI社区向可持续、鲁棒和公平的人工智能系统转型，倡导自适应感知作为实现这一目标的关键范式转变，并提出了具体的实施路线图和研究方向。

> **ai_Abstract:** 本文提出自适应感知作为人工智能领域的一种范式转变，旨在解决当前AI过度依赖大规模模型和数据集所带来的高昂成本问题。受生物感知系统启发，自适应感知通过在输入端动态调节传感器参数，提高了AI的效率和鲁棒性。经验证据表明，采用自适应感知的小型模型能够超越更大型的模型。作者还为自适应感知的实际应用整合提供了路线图，讨论了相关挑战，并提出了未来的研究方向，以促进可持续和公平的AI发展。

> **摘要翻译:** 当前人工智能的进步主要依赖于扩展神经网络模型和增大训练数据集以实现泛化和鲁棒性。尽管取得了显著成功，但这种范式带来了巨大的环境、经济和伦理成本，限制了可持续性和公平可及性。受生物感知系统的启发——其中适应性在输入端动态发生（例如，调整瞳孔大小、重新聚焦视觉）——我们倡导将自适应感知作为一种必要的基础性转变。自适应感知在输入层主动调节传感器参数（例如，曝光、灵敏度、多模态配置），显著缓解协变量偏移并提高效率。最近研究的经验证据表明，自适应感知使小型模型（例如，EfficientNet-B0）能够超越使用更多数据和计算进行训练的、实质上更大的模型（例如，OpenCLIP-H）。我们（i）概述了将自适应感知广泛整合到人形机器人、医疗保健、自主系统、农业和环境监测等实际应用中的路线图，（ii）批判性地评估了技术和伦理整合挑战，以及（iii）提出了有针对性的研究方向，例如标准化基准、实时自适应算法、多模态集成和隐私保护方法。总而言之，这些努力旨在将人工智能社区转向可持续、鲁棒和公平的人工智能系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [413] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
> *通过音视频记录进行多智能体游戏生成与评估*

*Alexia Jolicoeur-Martineau* | **Category: cs.AI, cs.MA, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 多智能体系统, 游戏生成, 音视频记录, 内容评估, AI局限性

**Comment:** 

> **TL;DR:** 鉴于AI在生成交互式音视频内容（如视频游戏）方面的挑战，本文提出了AVR-Eval，一种基于音视频记录（AVR）的多媒体内容相对评估指标，以及AVR-Agent，一个多智能体系统，用于生成和迭代改进JavaScript游戏。结果表明AVR-Agent优于一次性生成，但模型在利用自定义资产和AVR反馈方面仍存在不足。

**AI_Comments:** 该论文引入了一种创新方法来评估和生成复杂的交互式内容，超越了简单的内容生成，解决了多智能体系统和迭代改进的挑战。AVR-Eval度量标准是其关键贡献，提供了一种结构化的方式来评估多媒体质量。论文中识别出的关于AI无法像人类一样有效利用资产和反馈的“关键差距”是一个重要的见解，突出了当前内容创建模型的根本局限性，并为未来的研究指明了重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI在生成文本、音频、图像和视频方面表现出色，但创建交互式音视频内容（如视频游戏）仍然充满挑战。当前的LLM可以生成JavaScript游戏和动画，但缺乏自动化评估指标，并且难以处理通常需要人类团队花费数月时间（多镜头、多智能体）使用艺术家制作的资产才能完成的复杂内容。

**Method:** 本文构建了一个新的度量标准AVR-Eval和一个多智能体系统AVR-Agent。AVR-Eval是一种使用音视频记录（AVR）的多媒体内容质量的相对度量标准，通过全模态模型比较两个内容的AVR，并由文本模型审查评估以确定优劣，能够识别良好、损坏或不匹配的内容。AVR-Agent是一个多智能体系统，它从多媒体资产库生成JavaScript代码，编码智能体选择相关资产，生成多个初始代码，使用AVR-Eval识别最佳版本，并通过AVR的全模态智能体反馈迭代改进。

**Result:** 在游戏和动画上进行的AVR-Eval实验表明，AVR-Agent生成的内容相对于一次性生成的内容具有显著更高的胜率。然而，模型难以有效利用自定义资产和AVR反馈，没有显示出更高的胜率。

**Conclusion:** 研究揭示了一个关键差距：虽然人类受益于高质量资产和音视频反馈，但当前的编码模型似乎未能有效利用这些资源，这突显了人类和机器内容创建方法之间的根本差异。

> **ai_Abstract:** 本文旨在解决AI在生成和评估复杂交互式音视频内容（尤其是视频游戏）方面的挑战。为此，论文提出了AVR-Eval，一种基于音视频记录的新型多媒体内容相对质量评估指标，以及AVR-Agent，一个多智能体系统，该系统利用多媒体资产库生成JavaScript代码，并通过AVR-Eval和全模态反馈迭代改进。实验结果表明，AVR-Agent生成的内容优于一次性生成，但同时也揭示了当前AI模型在有效利用自定义资产和音视频反馈方面存在的局限性，与人类表现形成对比。

> **摘要翻译:** 尽管人工智能在生成文本、音频、图像和视频方面表现出色，但创建交互式音视频内容（如视频游戏）仍然充满挑战。当前的LLM可以生成JavaScript游戏和动画，但缺乏自动化评估指标，并且难以处理通常需要人类团队花费数月时间（多镜头、多智能体）使用艺术家制作的资产才能完成的复杂内容。为了解决这些问题，我们构建了一个新的度量标准和一个多智能体系统。
我们提出了AVR-Eval，这是一种使用音视频记录（AVR）的多媒体内容质量的相对度量标准。一个全模态模型（处理文本、视频和音频）比较两个内容的AVR，文本模型审查评估以确定优劣。我们表明AVR-Eval能够正确识别出良好、损坏或不匹配的内容。
我们构建了AVR-Agent，这是一个多智能体系统，它从多媒体资产库（音频、图像、3D模型）生成JavaScript代码。编码智能体选择相关资产，生成多个初始代码，使用AVR-Eval识别最佳版本，并通过AVR的全模态智能体反馈迭代改进它。
我们对游戏和动画进行了AVR-Eval实验（内容A对抗内容B的胜率）。我们发现AVR-Agent生成的内容相对于一次性生成的内容具有显著更高的胜率。然而，模型难以有效利用自定义资产和AVR反馈，没有显示出更高的胜率。这揭示了一个关键的差距：虽然人类受益于高质量资产和音视频反馈，但当前的编码模型似乎未能有效利用这些资源，这突显了人类和机器内容创建方法之间的根本差异。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [450] [MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors](https://arxiv.org/abs/2507.21872)
> *MultiEditor：使用3D高斯泼溅先验的可控多模态驾驶场景对象编辑*

*Shouyi Lu, Zihan Lin, Chao Lu, Huanran Wang, Guirong Zhuo, Lianqing Zheng* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 多模态编辑, 3D高斯泼溅, 自动驾驶, 数据增强, 潜在扩散模型

**Comment:** 

> **TL;DR:** MultiEditor是一个使用3DGS先验的多模态编辑框架，用于生成驾驶场景中的稀有车辆数据，以提高自动驾驶感知模型的性能。

**AI_Comments:** MultiEditor的创新点在于结合3DGS作为多模态编辑的先验，以及其独特的多级外观控制和深度引导的跨模态条件模块。这有效解决了自动驾驶领域稀有数据泛化能力差的问题，对于提升自动驾驶系统的鲁棒性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统高度依赖多模态感知数据来理解复杂环境，然而，真实世界数据的长尾分布阻碍了泛化能力，特别是对于稀有但对安全至关重要的车辆类别。

**Method:** 提出MultiEditor，一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和LiDAR点云。核心是引入3D高斯泼溅（3DGS）作为目标对象的结构和外观先验。设计了多级外观控制机制（包括像素级粘贴、语义级引导和多分支细化）以实现跨模态高保真重建。进一步提出深度引导的可变形跨模态条件模块，利用3DGS渲染的深度自适应地实现模态间的相互引导，显著增强跨模态一致性。

**Result:** MultiEditor在视觉和几何保真度、编辑可控性以及跨模态一致性方面表现出色。通过MultiEditor生成稀有类别车辆数据，显著提升了感知模型对代表性不足类别的检测精度。

**Conclusion:** MultiEditor通过其可控的多模态编辑能力，有效解决了自动驾驶中稀有类别数据不足的问题，显著提升了感知模型对这些类别的检测精度和泛化能力。

> **ai_Abstract:** MultiEditor是一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和LiDAR点云，以解决自动驾驶中稀有车辆数据不足的问题。它引入3D高斯泼溅（3DGS）作为结构和外观先验，并通过多级外观控制机制和深度引导的跨模态条件模块实现高保真和一致性的跨模态重建。实验证明，MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面表现优异，并能显著提升感知模型对稀有类别的检测精度。

> **摘要翻译:** 自动驾驶系统高度依赖多模态感知数据来理解复杂环境。然而，真实世界数据的长尾分布阻碍了泛化能力，特别是对于稀有但对安全至关重要的车辆类别。为了解决这一挑战，我们提出了MultiEditor，一个双分支潜在扩散框架，旨在联合编辑驾驶场景中的图像和LiDAR点云。我们方法的核心是引入3D高斯泼溅（3DGS）作为目标对象的结构和外观先验。利用这一先验，我们设计了一个多级外观控制机制——包括像素级粘贴、语义级引导和多分支细化——以实现跨模态的高保真重建。我们进一步提出了一种深度引导的可变形跨模态条件模块，该模块利用3DGS渲染的深度自适应地实现模态间的相互引导，显著增强了跨模态一致性。广泛的实验表明，MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面取得了卓越性能。此外，利用MultiEditor生成稀有类别车辆数据，显著提升了感知模型在代表性不足类别上的检测精度。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [464] [How Far Are AI Scientists from Changing the World?](https://arxiv.org/abs/2507.23276)
> *AI科学家离改变世界还有多远？*

*Qiujie Xie, Yixuan Weng, Minjun Zhu, Fuchen Shen, Shulin Huang, Zhen Lin, Jiahui Zhou, Zilan Mao, Zijie Yang, Linyi Yang, Jian Wu, Yue Zhang* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** AI科学家, 大型语言模型, 科学发现, 综述, 自动化科学

**Comment:** 

> **TL;DR:** 这篇综述探讨了AI科学家系统的现状、局限性以及未来发展方向，以评估它们离改变科学研究范式还有多远。

**AI_Comments:** 这篇综述论文的重要性在于其及时性，它提供了一个关于AI科学家系统发展现状的全面视角。它不仅总结了当前成就，更重要的是，它识别了未来的挑战和所需的核心能力，为该领域的研究者指明了方向。对于评估AI在科学发现中的真正潜力及其对社会的潜在影响，该综述具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）推动自动化科学发现进入新阶段，AI科学家系统在科学研究中日益重要。本文旨在回答“AI科学家离改变世界和重塑科学研究范式还有多远？”这一核心问题，并评估其当前成就和未来潜力。

**Method:** 本文采用前瞻性综述的方法，全面分析了AI科学家系统当前的成就，识别了关键瓶颈，并指出了产生突破性发现以解决重大挑战所需的关键组成部分。

**Result:** 该综述旨在帮助人们更清晰地理解当前AI科学家系统的局限性，展示了我们所处的位置、缺失的部分以及科学AI的最终目标，并识别了关键瓶颈和必要组件。

**Conclusion:** AI科学家系统正迅速发展，但仍面临挑战。本综述提供了对当前局限性的清晰理解，并指明了实现突破性科学发现的未来方向和所需要素。

> **ai_Abstract:** 这篇综述全面审视了基于大型语言模型（LLMs）的AI科学家系统的当前进展，评估它们离彻底改变科学研究范式还有多远。文章分析了现有成就、关键瓶颈以及实现人类水平、能产出突破性发现的科学智能体所需的要素，旨在明确当前局限性并为科学AI的未来发展设定目标。

> **摘要翻译:** 大型语言模型（LLMs）的出现正在将自动化科学发现推向新的高度，基于LLM的人工智能（AI）科学家系统现在在科学研究中处于领先地位。AI科学家领域已经出现了几项有影响力的工作，AI生成的科研论文已被ICLR 2025研讨会接受，这表明一个能够揭示人类以前未知现象的人类水平AI科学家可能很快就会成为现实。在这项综述中，我们关注核心问题：AI科学家离改变世界和重塑科学研究范式还有多远？为了回答这个问题，我们提供了一项前瞻性回顾，全面分析了AI科学家系统当前的成就，识别了关键瓶颈以及产生突破性发现以解决重大挑战所需的关键组成部分。我们希望这项综述能有助于更清晰地理解当前AI科学家系统的局限性，展示我们所处的位置、缺失的部分以及科学AI的最终目标。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [473] [AI Must not be Fully Autonomous](https://arxiv.org/abs/2507.23330)
> *人工智能不能完全自主*

*Tosin Adewumi, Lama Alkhaled, Florent Imbert, Hui Han, Nudrat Habib, Karl Löwenmark* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 自主AI, 人类监督, 超人工智能, AI风险, 伦理

**Comment:** 11 pages, 1 figure

> **TL;DR:** 鉴于潜在风险，尤其是考虑到超人工智能的临近，人工智能不应完全自主，人类监督至关重要。

**AI_Comments:** 这篇论文的创新之处在于它明确地将AI自主性划分为不同级别，并系统地构建了一系列论点和证据来支持其“AI不应完全自主”的核心立场。其重要性在于，在AI快速发展的当下，它提出了一个关键的伦理和安全问题，即人类在AI系统中的角色和控制权，特别是在超人工智能可能出现的前景下。论文通过提供具体论点和证据，为关于AI治理和监督的讨论提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自主AI有益，但其固有的风险促使作者论证AI不应完全自主，特别是考虑到未来超人工智能可能带来的巨大风险。

**Method:** 作者首先确定了自主AI的三个级别。为了支持其立场，论文讨论了自主性、AI和代理的理论，提出了12个不同的论点，并对6个反论点进行了驳斥，同时在附录中提供了15项关于AI价值观错位和其他风险的最新证据。

**Result:** 论文识别了自主AI的3个级别，并通过结构化的论证（包括12个论点和对6个反驳的驳斥）以及15个AI风险证据，论证了AI不应完全自主。

**Conclusion:** 鉴于自主AI，特别是完全自主的第三级AI，存在巨大风险且可能缺乏人类监督，因此人类的负责任监督对于规避这些风险至关重要，AI不应被赋予完全自主权。

> **ai_Abstract:** 这篇论文探讨了自主人工智能的潜在风险和益处，并提出了一个核心论点：AI不应被赋予完全自主权。作者区分了自主AI的三个级别，指出最高级别的完全自主AI在缺乏人类监督的情况下风险巨大。为了支持这一观点，论文讨论了相关理论，提出了12个论点，并反驳了6个对立观点，同时提供了大量AI风险的证据，强调了负责任的人类监督在风险缓解中的关键作用。

> **摘要翻译:** 自主人工智能（AI）有许多好处，但也存在许多风险。在这项工作中，我们确定了自主AI的3个级别。我们认为，鉴于许多风险，尤其是考虑到超人工智能（ASI）可能在未来几十年内出现，AI绝不能完全自主。完全自主的AI，即能够发展自身目标的AI，属于第3级，并且缺乏负责任的人类监督。然而，负责任的人类监督对于减轻风险至关重要。为了支持我们的立场，我们讨论了自主性、AI和代理的理论。然后，我们提供了12个不同的论点和6个反论点，并对反论点进行了驳斥。我们还在附录中提供了15项关于AI价值观错位和其他风险的最新证据。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [487] [DSBC : Data Science task Benchmarking with Context engineering](https://arxiv.org/abs/2507.23336)
> *DSBC：数据科学任务基准测试与上下文工程*

*Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Giulio Martini, Suman Debnath, Hamza Farooq* | **Category: cs.AI, cs.CL, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 数据科学智能体, 基准测试, 大型语言模型, 上下文工程, 性能评估

**Comment:** 32 pages

> **TL;DR:** 论文介绍了DSBC，一个用于评估数据科学智能体在真实场景下性能的综合基准测试，发现不同大型语言模型和方法在数据科学任务上表现各异。

**AI_Comments:** 这篇论文通过引入一个基于真实世界交互的综合基准测试DSBC，填补了数据科学智能体系统性评估的空白。其创新之处在于考虑了上下文工程、多步交互、提示问题敏感性以及温度参数等实际部署中的关键因素，为理解大型语言模型在数据科学任务中的表现提供了宝贵的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据科学智能体被广泛采用，但缺乏系统性的基准测试来评估其有效性和局限性。

**Method:** 引入了一个基于商业应用用户交互的综合基准测试DSBC。评估了Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini三个大型语言模型，采用零样本上下文工程、多步上下文工程和SmolAgent三种方法。基准测试涵盖八个数据科学任务类别，并探究了模型对提示问题（如数据泄露、模糊指令）的敏感性以及温度参数的影响。

**Result:** 评估结果揭示了不同模型和方法之间在性能上存在明显差异，并突出了影响实际部署的关键因素。

**Conclusion:** 本文引入的基准数据集和评估框架旨在为未来研究更健壮、更有效的数据科学智能体提供基础。

> **ai_Abstract:** 本文提出了DSBC，一个针对数据科学智能体的综合基准测试，旨在弥补现有系统性评估的不足。通过观察商业应用的用户交互，DSBC模拟真实世界场景，并评估了Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini等大型语言模型在零样本、多步上下文工程及SmolAgent方法下的表现。基准测试涵盖八类数据科学任务，并考察了模型对提示问题和温度参数的敏感性。研究发现不同模型和方法间存在显著性能差异，为未来开发更有效的数据科学智能体提供了基础。

> **摘要翻译:** 大型语言模型（LLMs）的最新进展显著影响了数据科学工作流程，催生了旨在自动化分析任务的专用数据科学智能体。尽管这些智能体得到了迅速采用，但评估其效能和局限性的系统性基准测试仍然稀缺。在本文中，我们引入了一个综合性基准测试，该基准测试通过观察我们商业应用程序的使用情况，专门设计用于反映用户与数据科学智能体的真实世界交互。我们评估了三个大型语言模型：Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini，采用三种方法：零样本上下文工程、多步上下文工程和SmolAgent。我们的基准测试评估了八个不同数据科学任务类别的性能，并额外探讨了模型对常见提示问题（如数据泄露和轻微模糊指令）的敏感性。我们进一步研究了温度参数对每个模型和方法的整体及特定任务结果的影响。我们的研究结果揭示了评估模型和方法之间存在明显的性能差异，突出了影响实际部署的关键因素。本文介绍的基准数据集和评估框架旨在为未来研究更健壮、更有效的数据科学智能体提供基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [490] [Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis](https://arxiv.org/abs/2507.21875)
> *Tiny-BioMoE: 生物信号分析的轻量级嵌入模型*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 生物信号分析, 疼痛评估, 轻量级模型, 嵌入学习, 多模态

**Comment:** 

> **TL;DR:** Tiny-BioMoE是一个轻量级预训练嵌入模型，用于自动疼痛识别中的生物信号分析。

**AI_Comments:** Tiny-BioMoE的创新之处在于其轻量化设计（仅730万参数）和在大量生物信号数据上的预训练，使其能够高效提取高质量嵌入，并有效应用于多模态疼痛识别任务。其开源代码和权重也促进了后续研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛是一种复杂且普遍的病症，准确一致的评估对于患者和医疗系统至关重要。自动疼痛评估系统能够持续监测、支持临床决策并减少患者痛苦。利用生理信号提供客观精确的见解，多模态框架可进一步提高系统性能。

**Method:** 提出了Tiny-BioMoE，一个轻量级预训练嵌入模型，用于生物信号分析。该模型在440万个生物信号图像表示上进行训练，仅包含730万个参数，可有效提取高质量嵌入用于下游任务。

**Result:** 对包括电皮活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合在内的广泛实验表明，该模型在自动疼痛识别任务中对不同模态均有效。

**Conclusion:** Tiny-BioMoE作为一个轻量级预训练嵌入模型，能够有效从生物信号中提取高质量嵌入，并在多模态自动疼痛识别任务中表现出良好的性能。

> **ai_Abstract:** 本文提出了Tiny-BioMoE，一个轻量级预训练嵌入模型，专门用于生物信号分析，以支持自动疼痛评估。该模型在大量生物信号图像表示上训练，参数量小，能够有效提取高质量嵌入。通过对多种生理信号的实验验证，Tiny-BioMoE在多模态自动疼痛识别任务中展现出卓越的性能。

> **摘要翻译:** 疼痛是一种复杂且普遍的病症，影响着相当一部分人口。准确和一致的评估对于遭受疼痛的个体以及在医疗保健系统中制定有效的管理策略至关重要。自动疼痛评估系统能够实现持续监测，支持临床决策，并有助于最大限度地减少患者痛苦，同时降低功能恶化的风险。利用生理信号可以客观而精确地洞察一个人的状态，并且将它们整合到多模态框架中可以进一步提高系统性能。这项研究已提交给《第二届下一代疼痛评估多模态感知大挑战 (AI4PAIN)》。所提出的方法引入了Tiny-BioMoE，一个用于生物信号分析的轻量级预训练嵌入模型。它在440万个生物信号图像表示上进行训练，仅包含730万个参数，是提取高质量嵌入以进行下游任务的有效工具。涉及电皮活动、血容量脉搏、呼吸信号、外周血氧饱和度及其组合的广泛实验突出表明，该模型在自动疼痛识别任务中对不同模态均有效。该模型的架构（代码）和权重可在https://github.com/GkikasStefanos/Tiny-BioMoE获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [491] [World Model-Based Learning for Long-Term Age of Information Minimization in Vehicular Networks](https://arxiv.org/abs/2505.01712)
> *基于世界模型的车载网络长期信息年龄最小化学习*

*Lingyi Wang, Rashed Shelim, Walid Saad, Naren Ramakrishnan* | **Category: cs.AI, cs.NI** | **Updated: 2025-08-01**

**Keywords:** 世界模型, 信息年龄, 车载网络, 强化学习, 毫米波V2X

**Comment:** 

> **TL;DR:** 本文提出了一种基于世界模型的学习框架，用于在车载网络中最小化信息年龄（CAoI），通过在想象轨迹中学习策略，显著提高了数据效率，并在毫米波V2X通信场景中优于传统的模型基和无模型强化学习方法。

**AI_Comments:** 本文的创新点在于将世界模型引入到车载网络的强化学习中，有效地克服了传统强化学习在数据效率和长期规划方面的不足。通过在想象轨迹中学习策略，该方法能够处理复杂动态的毫米波V2X环境，并在缺乏实时观测的情况下依然做出高效决策，这对于实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习（RL）方法在无线网络中依赖昂贵的试错机制和大量的环境交互以获取实时反馈，导致数据效率低下和策略短视。这些局限性在具有高不确定性和长期规划需求的复杂动态网络中尤为突出。

**Method:** 本文提出了一种新颖的基于世界模型的学习框架，旨在最小化车载网络中的数据包完整性感知信息年龄（CAoI）。该框架特别考虑了毫米波（mmWave）车联网（V2X）通信网络这一具有高移动性、频繁信号阻塞和极短相干时间的挑战性场景。所提出的世界模型框架能够联合学习毫米波V2X环境的动态模型，并利用其想象轨迹来学习如何执行链路调度。长期策略是在可微分的想象轨迹中学习的，而非通过环境交互。此外，世界模型凭借其想象能力，可以联合预测时变无线数据并优化现实世界无线和V2X网络中的链路调度，从而在没有实际观测的间隔内也能做出高效决策。实验在一个基于Sionna的真实模拟器上进行，该模拟器集成了基于物理的端到端信道建模、射线追踪和具有材料属性的场景几何。

**Result:** 仿真结果表明，所提出的世界模型在数据效率方面取得了显著提升，并且与基于模型的强化学习（MBRL）方法和无模型强化学习（MFRL）方法相比，CAoI分别提高了26%和16%。

**Conclusion:** 本文提出的基于世界模型的学习框架能够有效解决传统强化学习在动态车载网络中数据效率低和策略短视的问题，显著提升了信息年龄性能。

> **ai_Abstract:** 本文提出了一种新颖的基于世界模型的学习框架，旨在解决传统强化学习在动态无线网络中数据效率低和策略短视的问题，特别是在毫米波V2X车载网络中最小化数据包完整性感知信息年龄（CAoI）。该框架通过学习环境的动态模型并在想象的轨迹中规划长期策略，避免了大量的真实环境交互。仿真结果表明，与传统的模型基和无模型强化学习方法相比，所提出的世界模型显著提高了数据效率，并分别将CAoI性能提升了26%和16%。

> **摘要翻译:** 传统上，基于强化学习（RL）的无线网络学习方法依赖于昂贵的试错机制和基于大量环境交互的实时反馈，这导致数据效率低下和策略短视。这些局限性在具有高不确定性和长期规划需求的复杂动态网络中变得尤为突出。为了解决这些局限性，本文提出了一种新颖的基于世界模型的学习框架，旨在最小化车载网络中的数据包完整性感知信息年龄（CAoI）。特别地，本文考虑了一个具有挑战性的代表性场景，即毫米波（mmWave）车联网（V2X）通信网络，该网络以高移动性、频繁信号阻塞和极短相干时间为特征。然后，提出了一种世界模型框架，用于联合学习毫米波V2X环境的动态模型，并利用其想象轨迹来学习如何执行链路调度。具体而言，长期策略是在可微分的想象轨迹中学习的，而不是通过环境交互。此外，由于其想象能力，世界模型可以联合预测时变无线数据并优化现实世界无线和V2X网络中的链路调度。因此，在没有实际观测的间隔期间，世界模型仍能做出高效决策。在基于Sionna的真实模拟器上进行了大量实验，该模拟器集成了基于物理的端到端信道建模、射线追踪和具有材料属性的场景几何。仿真结果表明，所提出的世界模型在数据效率方面取得了显著提升，并且与基于模型的强化学习（MBRL）方法和无模型强化学习（MFRL）方法相比，CAoI分别提高了26%和16%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [501] [LLM4Rail: An LLM-Augmented Railway Service Consulting Platform](https://arxiv.org/abs/2507.23377)
> *LLM4Rail：一个LLM增强的铁路服务咨询平台*

*Zhuo Li, Xianghuai Deng, Chiwei Feng, Hanmeng Li, Shenjie Wang, Haichao Zhang, Teng Jia, Conlin Chen, Louis Linchun Wu, Jia Wang* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 铁路服务, 对话推荐系统, QTAO框架, CRFD-25数据集

**Comment:** 

> **TL;DR:** 开发了一个名为LLM4Rail的LLM增强铁路服务咨询平台，利用QTAO框架和CRFD-25数据集提供个性化铁路服务。

**AI_Comments:** 该论文提出了一种创新的LLM应用，将大型语言模型的能力扩展到特定领域，如铁路服务。QTAO框架的提出有助于提高LLM在任务导向型交互中的准确性和效率。CRFD-25数据集的构建填补了铁路餐饮领域公开数据的空白，对后续研究具有重要意义。零样本推荐与后处理结合的方式也为实际应用提供了鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 为满足日益增长的个性化铁路服务需求。

**Method:** 开发了LLM4Rail平台，提供票务、餐饮推荐、天气信息和闲聊等模块。提出了迭代的“问题-思考-行动-观察（QTAO）”提示框架，将语言推理与任务导向行动相结合。构建了中文铁路餐饮（CRFD-25）公开数据集。引入了基于LLM的零样本对话推荐器用于铁路餐饮，并采用基于特征相似度的后处理步骤确保推荐项与数据集对齐。

**Result:** 成功开发了LLM4Rail平台，能够提供定制化的铁路服务咨询。构建了公开可访问的CRFD-25铁路餐饮数据集。实现了基于LLM的零样本对话推荐系统和相应的后处理机制。

**Conclusion:** LLM4Rail平台及其创新的QTAO框架和CRFD-25数据集的开发，能够为用户提供个性化的铁路服务咨询和餐饮推荐。

> **ai_Abstract:** 本文介绍了LLM4Rail，一个基于大型语言模型（LLM）的铁路服务咨询平台，旨在满足个性化服务需求。该平台整合了票务、餐饮推荐、天气查询和闲聊等功能，并提出了迭代的“问题-思考-行动-观察（QTAO）”提示框架，以实现精准响应。为支持个性化餐饮服务，研究者构建了公开的中文铁路餐饮数据集（CRFD-25），并开发了基于LLM的零样本对话推荐系统，辅以特征相似度后处理机制，确保推荐的准确性和相关性。

> **摘要翻译:** 大型语言模型（LLMs）已显著重塑了各行各业。为满足日益增长的个性化铁路服务需求，我们开发了LLM4Rail——一个新颖的LLM增强铁路服务咨询平台。LLM4Rail通过LLM赋能，可以提供票务、铁路餐饮推荐、天气信息和闲聊等定制模块。在LLM4Rail中，我们提出了迭代的“问题-思考-行动-观察（QTAO）”提示框架。它精心地将语言推理与任务导向的行动相结合，即推理指导行动选择，以有效检索与铁路运营和服务相关的外部观察结果，从而生成准确的响应。为了提供个性化的车载餐饮服务，我们首先构建了中文铁路餐饮（CRFD-25）——一个为铁路服务量身定制的公开外卖数据集。CRFD-25涵盖了按城市、菜系、年龄组和辣度分类的各种招牌菜。我们进一步引入了一个基于LLM的零样本对话推荐器，用于铁路餐饮。为了解决开放推荐的无限制性，引入了基于特征相似度的后处理步骤，以确保所有推荐项目都与CRFD-25数据集对齐。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [515] [Chatting with your ERP: A Recipe](https://arxiv.org/abs/2507.23429)
> *与您的ERP对话：一个秘诀*

*Jorge Ruiz Gómez, Lidia Andrés Susinos, Jorge Alamo Olivé, Sonia Rey Osorno, Manuel Luis Gonzalez Hernández* | **Category: cs.AI, cs.DB, cs.ET, cs.HC, cs.MA, 68T50, 68P20, I.2.7; H.2.5; H.2.8; H.5.m** | **Updated: 2025-07-31**

**Keywords:** LLM代理, ERP系统, 自然语言处理, SQL生成, 双代理架构

**Comment:** 11 pages, includes 3 tables summarizing schema and model performance.
  Submitted on July 31, 2025. Targets integration of LLM agents with ERP
  systems using open-weight models and Ollama deployment

> **TL;DR:** 本文设计并实现了一个基于大型语言模型（LLM）的代理，使其能够通过自然语言与工业级ERP系统进行交互，并将查询转换为SQL语句，采用了新颖的双代理架构。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于企业资源规划（ERP）系统，实现了通过自然语言与复杂企业系统交互的能力。特别是提出的双代理架构（结合推理和批判）有望显著提升查询生成的准确性和可靠性，为企业级应用提供了新的交互范式和潜在的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 使工业生产级ERP系统能够理解自然语言查询并将其转换为可执行的SQL语句，从而实现更直观的交互。

**Method:** 设计、实现并评估了一个利用开源大型语言模型（LLM）的代理。该研究提出了一种结合推理和批判阶段的新颖双代理架构，以提高查询生成的可靠性。

**Result:** 该代理能够解释自然语言查询并将其转换为可执行的SQL语句。提出的双代理架构旨在提高查询生成的可靠性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一个用于与工业生产级ERP系统交互的大型语言模型（LLM）代理的设计、实现和评估。该代理利用开源LLM，能够将自然语言查询转换为可执行的SQL语句。为提升查询生成的可靠性，研究提出了一种结合推理和批判阶段的新颖双代理架构。

> **摘要翻译:** 本文介绍了与工业生产级ERP系统聊天的LMM（大型语言模型）代理的设计、实现和评估。该代理能够解释自然语言查询并将其转换为可执行的SQL语句，利用了开源LMM。提出了一种新颖的结合推理和批判阶段的双代理架构，以提高查询生成的可靠性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [522] [TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Dataflow and Analytical Modelling](https://arxiv.org/abs/2408.01254)
> *TrIM，用于卷积神经网络的三角输入移动脉动阵列：数据流与分析建模*

*Cristian Sestito, Shady Agwa, Themis Prodromakis* | **Category: cs.AI, cs.AR** | **Updated: 2025-07-31**

**Keywords:** 脉动阵列, 数据流, 卷积神经网络, 冯·诺依曼瓶颈, TrIM

**Comment:** This work has been accepted by IEEE TCASAI for publication

> **TL;DR:** TrIM是一种新的脉动阵列数据流，通过优化数据移动显著减少内存访问并提高CNN的吞吐量。

**AI_Comments:** TrIM的创新在于其独特的三角输入移动数据流，有效解决了传统脉动阵列中数据冗余和内存访问效率低下的问题。通过优化数据流，它在能效和性能上都取得了显著提升，对于加速CNNs在边缘设备和高性能计算中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对最先进AI模型日益增长的计算复杂度和数据密集度，需要新的计算范式来通过减轻冯·诺依曼瓶颈（与处理核心和内存之间数据移动的能量成本相关）来提高能效。卷积神经网络（CNNs）由于需要管理海量数据而易受此瓶颈影响。脉动阵列（SAs）是缓解数据传输成本的有前景的架构，但数据冗余是影响面积、功耗和能耗的主要问题。

**Method:** 本文提出TrIM：一种基于三角输入移动的新型脉动阵列数据流，兼容CNN计算。TrIM最大化本地输入利用率，最小化权重数据移动，并解决数据冗余问题。此外，TrIM不会产生行驻留数据流引入的显著片上内存开销。

**Result:** 与最先进的脉动阵列数据流相比，TrIM提供的高数据利用率保证了约10倍的内存访问减少。此外，考虑到处理单元（PEs）持续重叠乘法和累加，TrIM实现了高吞吐量（比行驻留高出81.8%），并且只需要有限数量的寄存器（比行驻留少15.6倍）。

**Conclusion:** TrIM作为一种新型脉动阵列数据流，通过优化数据移动和利用率，显著降低内存访问、提高吞吐量并减少寄存器需求，有效缓解了冯·诺依曼瓶颈和数据冗余问题，为CNN计算提供了高效解决方案。

> **ai_Abstract:** 本文提出TrIM，一种用于卷积神经网络（CNNs）脉动阵列（SAs）的新型数据流，旨在解决AI模型中数据移动引起的冯·诺依曼瓶颈和数据冗余问题。TrIM采用三角输入移动，最大化本地输入利用率并最小化权重数据移动，从而显著减少内存访问（约10倍）并大幅提高吞吐量（最高81.8%），同时降低寄存器需求（最多15.6倍），且避免了传统数据流的片上内存开销。

> **摘要翻译:** 为了应对最先进AI模型日益增长的计算复杂度和数据密集度，正在提出新的计算范式。这些范式旨在通过减轻与处理核心和内存之间数据移动的能量成本相关的冯·诺依曼瓶颈来提高能效。卷积神经网络（CNNs）由于需要管理海量数据而易受此瓶颈影响。脉动阵列（SAs）是缓解数据传输成本的有前景的架构，这得益于处理单元（PEs）的高数据利用率。这些PEs基于特定的数据流（如权重驻留和行驻留）在本地持续交换和处理数据，从而减少对主内存的访问次数。在SAs中，卷积要么作为矩阵乘法管理，要么利用滑动窗口的栅格顺序扫描。然而，数据冗余是影响面积、功耗和能耗的主要问题。在本文中，我们提出了TrIM：一种基于三角输入移动的新型脉动阵列数据流，兼容CNN计算。TrIM最大化本地输入利用率，最小化权重数据移动，并解决了数据冗余问题。此外，TrIM不会产生行驻留数据流引入的显著片上内存开销。与最先进的SA数据流相比，TrIM提供的高数据利用率保证了约10倍的内存访问减少。此外，考虑到PEs持续重叠乘法和累加，TrIM实现了高吞吐量（比行驻留高出81.8%），并且只需要有限数量的寄存器（比行驻留少15.6倍）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [529] [Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation](https://arxiv.org/abs/2507.23440)
> *Self-Foveate：通过多级注视增强无监督文本合成指令的多样性和难度*

*Mingzhe Li, Xin Lu, Yanyan Zhao* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 指令合成, LLM, 无监督文本, 多样性, 难度, 多级注视

**Comment:** Accepted by Findings of ACL 2025

> **TL;DR:** Self-Foveate 是一种新的LLM驱动方法，通过多级注视从无监督文本中合成更具多样性和难度的指令，解决了现有方法在多样性和难度上的局限性。

**AI_Comments:** 本文提出了一种新颖的多级注视方法（Micro-Scatter-Macro），用于指导LLM从无监督文本中合成高质量的指令，特别是在增强指令的多样性和难度方面具有创新性。这对于减少人工标注依赖，提升LLM训练数据的自动化生成效率和质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化指令合成方法在确保合成指令的足够多样性和难度方面存在显著局限性。

**Method:** 提出Self-Foveate，一种创新的LLM驱动指令合成方法。该方法引入“微观-分散-宏观”（Micro-Scatter-Macro）多级注视方法，有效引导LLM深入挖掘无监督文本中嵌入的细粒度信息，从而增强合成指令的多样性和难度。

**Result:** 在多个无监督语料库和不同模型架构上的综合实验验证了所提方法的有效性和优越性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了Self-Foveate，一种创新的LLM驱动指令合成方法，旨在解决现有自动化合成方法在生成指令多样性和难度方面的局限性。该方法采用“微观-分散-宏观”多级注视策略，引导LLM从无监督文本中挖掘细粒度信息，从而显著提高了合成指令的质量。实验结果验证了其在多个语料库和模型架构上的有效性。

> **摘要翻译:** 大型语言模型（LLMs）的指令遵循能力展示了令人印象深刻的问题解决能力。虽然从无监督文本合成指令数据已成为训练此类模型的常用方法，但传统方法严重依赖人工进行数据标注。尽管现有的自动化合成范式缓解了这一限制，但它们在确保合成指令的足够多样性和难度方面仍表现出显著局限性。为了应对这些挑战，我们提出了Self-Foveate，一种创新的LLM驱动指令合成方法。该方法引入了一种“微观-分散-宏观”（Micro-Scatter-Macro）多级注视方法，有效引导LLM深入挖掘无监督文本中嵌入的细粒度信息，从而增强合成指令的多样性和难度。在多个无监督语料库和不同模型架构上的综合实验验证了我们提出方法的有效性和优越性。我们公开了我们的数据和代码：https://github.com/Mubuky/Self-Foveate

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [532] [Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image](https://arxiv.org/abs/2507.21881)
> *用于疼痛识别的多表示图：将各种皮肤电活动信号整合到单个图像中*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 疼痛识别, 皮肤电活动, 多表示图, 信号融合, 自动评估

**Comment:** arXiv admin note: text overlap with arXiv:2507.21875

> **TL;DR:** 本研究提出了一种将多种皮肤电活动信号表示整合到单个多表示图中以进行疼痛识别的方法，实验证明其效果与传统融合方法相当甚至更优。

**AI_Comments:** 该论文的创新之处在于提出了一种将多种皮肤电活动信号表示整合到单个可视化图中的方法，这可能简化了多模态数据分析。其重要性在于为自动疼痛评估提供了一种鲁棒且高效的信号融合策略，有望提高疼痛识别的准确性和可靠性。此方法特别适合处理生理信号的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛是一种复杂且影响广泛的现象，可靠的评估对患者和治疗发展至关重要。自动疼痛评估系统能够提供持续监测、辅助临床决策并减少痛苦，通过生理信号提供客观准确的洞察。

**Method:** 该方法引入了一个管道，利用皮肤电活动信号作为输入模态。信号的多种表示被创建并可视化为波形，然后共同可视化在单个多表示图中。研究结合了各种处理和滤波技术以及多种表示组合。

**Result:** 广泛的实验表明，所提出的方法始终能产生与传统融合方法相当，在某些情况下甚至更优的结果。

**Conclusion:** 该方法被确立为整合不同信号表示或模态的强大替代方案。

> **ai_Abstract:** 本研究提出了一种针对疼痛识别的新型管道，该管道利用皮肤电活动（EDA）信号。通过创建EDA信号的多种表示并将其统一可视化在一个多表示图中，该方法旨在提供客观的疼痛评估。实验结果表明，与传统融合方法相比，该方法表现出可比甚至更优的性能，证明了其作为整合多种生理信号表示的有效替代方案。

> **摘要翻译:** 疼痛是一种影响相当一部分人口的多方面现象。可靠和一致的评估有益于经历疼痛的人，并支撑着有效和先进管理策略的开发。自动疼痛评估系统提供持续监测，为临床决策提供信息，旨在减轻痛苦，同时防止功能下降。通过整合生理信号，这些系统能客观、准确地洞察个体状况。本研究已提交给《第二届下一代疼痛评估多模态感知大挑战 (AI4PAIN)》。所提出的方法引入了一个利用皮肤电活动信号作为输入模态的管道。信号的多种表示被创建并可视化为波形，并共同可视化在单个多表示图中。结合各种处理和滤波技术以及多种表示组合的广泛实验，证明了所提出方法的有效性。它始终能产生与传统融合方法相当，在某些情况下甚至更优的结果，从而确立了其作为整合不同信号表示或模态的强大替代方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [550] [Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery](https://arxiv.org/abs/2507.23488)
> *因果推理分块进行：模块化上下文学习用于因果发现*

*Kacper Kadziolka, Saber Salehkaleybar* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 因果发现, 大型语言模型, 上下文学习, 模块化管道, 推理模型

**Comment:** 

> **TL;DR:** 本文研究了大型语言模型在因果发现方面的能力，发现推理优先的模型表现优异，并通过引入模块化上下文学习管道，实现了显著的性能提升，强调了结构化框架的重要性。

**AI_Comments:** 本文的创新点在于提出了一个模块化上下文学习管道，将LLMs的推理能力应用于因果发现这一复杂任务，并取得了显著的性能提升。它不仅证明了现有SOTA推理模型在特定任务上的潜力，还通过引入结构化的上下文框架，为LLMs在复杂推理任务中的应用提供了可推广的范式，对于克服传统模型在数据扰动下的过拟合问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的因果推理仍是基本挑战；传统因果发现模型在数据扰动下常出现严重过拟合和接近随机的性能；探索SOTA推理模型是否能稳健地执行因果发现。

**Method:** 在Corr2Cause基准上使用OpenAI的o系列和DeepSeek-R模型家族进行因果发现研究；引入了一个受Tree-of-Thoughts和Chain-of-Thoughts方法启发的模块化上下文管道；通过分析推理链长度、复杂性，并进行常规模型和推理模型之间的定性和定量比较，探讨了管道的影响。

**Result:** 推理优先的架构（OpenAI的o系列和DeepSeek-R）在因果发现方面比以前的方法取得了显著更大的原生增益；引入的模块化上下文管道比传统基线模型实现了近三倍的改进。

**Conclusion:** 先进的推理模型代表了巨大的进步；精心构建的上下文框架对于最大化这些模型的能力至关重要；这种方法为跨不同领域的因果发现提供了一个可推广的蓝图。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在因果发现任务中的应用，该任务对传统模型而言挑战重重。研究发现，OpenAI o系列和DeepSeek-R等推理优先的LLMs在此任务上表现出显著的原生优势。为进一步提升性能，作者提出了一种受Tree-of-Thoughts和Chain-of-Thoughts启发的模块化上下文学习管道，该管道将性能提升了近三倍。研究强调，尽管先进的推理模型潜力巨大，但精心设计的上下文框架对于充分发挥其能力并实现跨领域因果发现至关重要。

> **摘要翻译:** 大型语言模型的因果推理仍然是一个基本挑战。最近大型语言模型内部推理的进展引发了人们的兴趣，即最先进的推理模型是否能够稳健地执行因果发现——这项任务中，传统模型在数据扰动下常常遭受严重的过拟合和接近随机的性能。我们使用新兴的OpenAI o系列和DeepSeek-R模型家族在Corr2Cause基准上研究了因果发现，发现这些推理优先的架构比以前的方法取得了显著更大的原生增益。为了利用这些优势，我们引入了一个受Tree-of-Thoughts和Chain-of-Thoughts方法启发的模块化上下文管道，比传统基线模型实现了近三倍的改进。我们通过分析推理链长度、复杂性，并对传统模型和推理模型进行定性和定量比较，进一步探讨了该管道的影响。我们的研究结果表明，虽然先进的推理模型代表了实质性的飞跃，但精心构建的上下文框架对于最大化其能力至关重要，并为跨不同领域的因果发现提供了可推广的蓝图。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [560] [Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline](https://arxiv.org/abs/2507.21886)
> *通过呼吸信号进行高效疼痛识别：一个单一的交叉注意力Transformer多窗口融合管道*

*Stefanos Gkikas, Ioannis Kyprakis, Manolis Tsiknakis* | **Category: cs.AI, cs.LG, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 疼痛识别, 呼吸信号, 交叉注意力Transformer, 多窗口融合, 自动化疼痛评估

**Comment:** arXiv admin note: text overlap with arXiv:2507.21881,
  arXiv:2507.21875

> **TL;DR:** 研究提出一种基于呼吸信号的交叉注意力Transformer多窗口融合管道，用于高效自动疼痛识别，并证明其有效性和紧凑模型的优越性。

**AI_Comments:** 该研究的创新点在于将呼吸信号作为核心输入，并结合了高效的交叉注意力Transformer和多窗口融合策略，实现了紧凑模型的高性能。这对于实际应用中资源受限的场景具有重要意义，同时也突出了生理信号在疼痛评估中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 疼痛评估的准确性和一致性对于患者至关重要，自动化疼痛评估系统能提供持续监测并支持临床决策，旨在减轻痛苦并防止功能下降。

**Method:** 提出一个利用呼吸信号作为输入，并结合高效交叉注意力Transformer和多窗口策略的管道。

**Result:** 实验证明呼吸是疼痛评估的宝贵生理模态；紧凑高效的模型在优化后能达到甚至超越大型模型的性能；多窗口方法有效捕获短期、长期特征和全局特性，增强模型表示能力。

**Conclusion:** 呼吸信号是疼痛评估的有效模态，所提出的基于交叉注意力Transformer和多窗口融合的紧凑模型能高效准确地识别疼痛。

> **ai_Abstract:** 本文提出了一种基于呼吸信号的自动化疼痛识别方法，该方法采用单一交叉注意力Transformer与多窗口融合管道。研究表明呼吸信号是疼痛评估的有效生理模态，并且所提出的紧凑模型在捕获短期、长期及全局特征方面表现出色，实现了高效且高性能的疼痛识别。

> **摘要翻译:** 疼痛是一种影响大量人口的复杂病症。对疼痛患者进行准确和一致的评估对于开发有效和先进的治疗策略至关重要。自动化疼痛评估系统提供持续监测并支持临床决策，旨在减轻痛苦并防止功能下降。本研究已提交给“第二届下一代疼痛评估多模态感知挑战赛 (AI4PAIN)”。所提出的方法引入了一个管道，该管道利用呼吸作为输入信号，并结合了高效的交叉注意力Transformer以及多窗口策略。大量实验表明，呼吸是疼痛评估中一种有价值的生理模态。此外，实验表明，紧凑高效的模型在适当优化后可以实现强大的性能，通常超越大型模型。所提出的多窗口方法有效捕获了短期和长期特征以及全局特性，从而增强了模型的表示能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [571] [Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification](https://arxiv.org/abs/2507.23497)
> *图像分类中充分、对比和完整特征集的因果识别*

*David A Kelly, Hana Chockler* | **Category: cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 因果解释, 图像分类, 特征集, 黑盒模型, 可解释人工智能

**Comment:** 13 pages, 13 figures, appendix included

> **TL;DR:** 论文提出了一种基于因果的图像分类器解释方法，该方法形式严谨、适用于黑盒模型，并引入了对比和完整因果解释，实验证明其高效且通用。

**AI_Comments:** 这篇论文的创新点在于将因果推理引入到图像分类器解释领域，解决了现有解释方法在形式严谨性和黑盒模型适用性上的痛点。其提出的对比和完整因果解释增加了解释的实用性和深度。算法的高效性和完全黑盒特性使其具有很强的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像分类器解释算法缺乏形式严谨性；基于逻辑的解释虽然严谨但对模型有严格假设，不适用于图像分类器。

**Method:** 提出因果解释，证明其与逻辑解释具有相同的形式属性，且适用于黑盒算法和图像分类器。引入对比因果解释和考虑置信度的完整因果解释（与原始图像置信度完全相同）。

**Result:** 实验结果表明不同模型具有不同的充分性、对比性和完整性模式。算法高效，平均每张图像在ResNet50上计算所有类型解释仅需6秒，且是完全黑盒，无需模型内部知识、梯度或特定模型属性。

**Conclusion:** 因果解释提供了一种形式严谨、高效且适用于黑盒图像分类器的解释方法，能够识别充分、对比和完整的特征集。

> **ai_Abstract:** 本文提出了一种新颖的因果解释框架，用于图像分类器输出的解释，旨在解决现有方法缺乏形式严谨性或不适用于黑盒模型的局限性。该框架引入了充分、对比和完整的因果解释，并证明了其形式严谨性、对黑盒模型的适用性以及计算效率。实验结果验证了其在识别不同模型解释模式方面的有效性，且无需模型内部知识。

> **摘要翻译:** 现有图像分类器输出解释算法基于多种方法，但其解释缺乏形式严谨性。另一方面，基于逻辑的解释虽然形式严谨且定义明确，但其可计算性依赖于对模型严格的假设，而这些假设在图像分类器上不成立。
在本文中，我们展示了因果解释除了形式严谨和定义明确外，还享有与基于逻辑的解释相同的形式属性，同时适用于黑盒算法并自然地契合图像分类器。我们证明了因果解释的形式属性，并为图像分类器引入了对比因果解释。此外，我们用置信度感知增强了解释的定义，并引入了完整的因果解释：即与原始图像具有完全相同置信度分类的解释。
我们实现了我们的定义，实验结果表明不同的模型具有不同的充分性、对比性和完整性模式。我们的算法计算高效，在ResNet50模型上平均每张图像计算所有类型解释需要6秒，并且是完全黑盒的，无需模型知识、无需访问模型内部、无需访问梯度，也不需要模型的任何属性，例如单调性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [588] [LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models](https://arxiv.org/abs/2507.22359)
> *LLM-Crowdsourced: 一种无基准的大语言模型相互评估范式*

*Qianhong Guo, Wei Xie, Xiaofang Cai, Enze Wang, Shuoyoucheng Ma, Kai Chen, Xiaofeng Wang, Baosheng Wang* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** LLM评估, 无基准, 相互评估, 大语言模型, LLM-Crowdsourced

**Comment:** 

> **TL;DR:** 本文提出了一种名为LLM-Crowdsourced的无基准评估范式，利用LLM生成问题、独立回答并相互评估，以克服现有评估方法的挑战，并验证了其在区分LLM性能方面的优势。

**AI_Comments:** 这项研究提出了一种创新的、无基准的LLM评估方法，通过让LLM相互评估来克服传统方法的局限性。其创新之处在于利用LLM的生成和评估能力，实现了动态、透明和客观的评估。它不仅提供了一种新的评估范式，还揭示了LLM行为的一些新颖见解，例如“记忆式回答”，这对于LLM的未来发展和评估具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLM）在各种任务中表现出卓越的能力，但评估其能力仍然是一项具有挑战性的任务。现有评估方法存在数据污染、黑盒操作和主观偏好等问题，这使得全面评估LLM的真实能力变得困难。

**Method:** 我们提出了一种新颖的无基准评估范式，LLM-Crowdsourced。它利用LLM生成问题、独立回答并相互评估。该方法整合了四个关键评估标准：动态、透明、客观和专业，这是现有评估方法无法同时满足的。

**Result:** 在数学和编程领域的八个主流LLM上的实验验证了我们方法在区分LLM性能方面的优势。此外，我们的研究揭示了传统方法难以检测到的几个新颖发现，包括但不限于：(1) Gemini在所有模型中表现出最高的原始和专业问题设计能力；(2) 某些LLM通过将问题误认为结构相似的熟悉问题而表现出“基于记忆的回答”；(3) LLM评估结果表现出高度一致性（鲁棒性）。

**Conclusion:** LLM-Crowdsourced范式成功克服了现有LLM评估方法的挑战，并提供了一种更动态、透明、客观和专业的评估方式，能够有效区分LLM性能并揭示传统方法难以发现的见解。

> **ai_Abstract:** 本文提出了一种新颖的无基准评估范式LLM-Crowdsourced，旨在解决现有LLM评估方法中数据污染、黑盒和主观性等问题。该方法通过利用LLM自身来生成问题、独立回答并进行相互评估，集成了动态、透明、客观和专业四个评估标准。在数学和编程领域对八个主流LLM进行的实验表明，该方法能有效区分模型性能，并揭示了传统方法难以发现的新发现，例如Gemini的问题设计能力、某些LLM的“记忆式回答”以及评估结果的高度一致性。

> **摘要翻译:** 尽管大型语言模型（LLM）在各种任务中表现出卓越的能力，但评估其能力仍然是一项具有挑战性的任务。现有评估方法存在数据污染、黑盒操作和主观偏好等问题，这使得全面评估LLM的真实能力变得困难。为了解决这些挑战，我们提出了一种新颖的无基准评估范式，LLM-Crowdsourced。它利用LLM生成问题、独立回答并相互评估。该方法整合了四个关键评估标准：动态、透明、客观和专业，这是现有评估方法无法同时满足的。在数学和编程领域的八个主流LLM上的实验验证了我们方法在区分LLM性能方面的优势。此外，我们的研究揭示了传统方法难以检测到的几个新颖发现，包括但不限于：(1) Gemini在所有模型中表现出最高的原始和专业问题设计能力；(2) 某些LLM通过将问题误认为结构相似的熟悉问题而表现出“基于记忆的回答”；(3) LLM评估结果表现出高度一致性（鲁棒性）。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [592] [DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer](https://arxiv.org/abs/2507.23554)
> *DICE：通过高效知识迁移在LLM智能体中进行动态上下文示例选择*

*Ruoyu Wang, Junda Wu, Yu Xia, Tong Yu, Ryan A. Rossi, Julian McAuley, Lina Yao* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** LLM智能体, 上下文学习, 示例选择, 知识迁移, 动态选择

**Comment:** 

> **TL;DR:** DICE是一种理论上严谨的动态上下文示例选择框架，用于LLM智能体，它在每个推理步骤选择最相关的示例，通过分解可迁移和不可迁移知识来提高性能，并且可以作为插件集成而无需额外训练。

**AI_Comments:** DICE的创新点在于其理论基础，通过因果视角分解知识并提出有性能保证的逐步选择标准，这为上下文学习中的示例选择提供了更坚实的理论支撑。其作为通用插件模块的特性，使其具有很高的实用价值和广阔的应用前景，能够无缝集成到现有LLM智能体框架中，降低了部署成本，有望显著提升LLM智能体在复杂任务中的鲁棒性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，上下文学习（ICL）的有效性对演示示例的选择高度敏感，次优示例会导致性能不稳定或下降。现有示例选择方法通常依赖启发式或特定任务设计，缺乏通用且有理论基础的有效演示选择标准，因此难以开发出一种原则性的通用方法来持续提升智能体性能。

**Method:** 本文提出了DICE（LLM智能体的动态上下文示例选择），这是一个有理论基础的ICL框架，用于在智能体任务的每个推理步骤中选择最相关的演示。该方法通过因果视角将演示知识分解为可迁移和不可迁移组件，并提出了一个带有正式性能提升保证的逐步选择标准。DICE是一种通用的、与框架无关的解决方案，可作为插件模块集成到现有智能体框架中，无需额外训练成本。

**Result:** 在不同领域的广泛实验证明了DICE方法的有效性和通用性，强调了原则性、上下文感知演示选择对于构建健壮高效的LLM智能体的重要性。

**Conclusion:** DICE提供了一种理论上严谨、通用且无需额外训练成本的动态上下文示例选择方法，显著提升了LLM智能体在复杂推理和工具使用任务中的性能和鲁棒性。

> **ai_Abstract:** 本文提出了DICE，一种针对大型语言模型（LLM）智能体的动态上下文示例选择（ICL）框架。DICE解决了当前ICL方法对演示示例选择敏感且缺乏通用理论基础的问题。它通过因果视角将演示知识分解为可迁移和不可迁移部分，并在每个推理步骤中动态选择最相关的示例，提出了一种具有性能保证的逐步选择标准。DICE是一个通用且无需额外训练成本的插件模块，实验证明其能有效提升LLM智能体的性能和泛化能力。

> **摘要翻译:** 大型语言模型（LLM）智能体在上下文学习（ICL）的赋能下，在复杂推理和工具使用任务中展现出强大的能力。然而，现有研究表明，ICL的有效性对演示示例的选择高度敏感，次优示例常导致性能不稳定或下降。尽管此前的工作已探索了示例选择，包括在某些智能体或多步骤设置中，但现有方法通常依赖启发式或特定任务设计，缺乏一个通用且有理论基础的、适用于不同推理步骤的有效演示标准。因此，开发一种原则性的、通用的方法来选择能持续提升智能体性能的演示并非易事。在本文中，我们通过DICE（LLM智能体的动态上下文示例选择）解决了这一挑战，DICE是一个有理论基础的ICL框架，用于在智能体任务的每个推理步骤中选择最相关的演示。我们的方法通过因果视角将演示知识分解为可迁移和不可迁移组件，展示了后者如何引入虚假依赖并损害泛化能力。我们进一步提出了一个带有正式性能提升保证的逐步选择标准。重要的是，DICE是一个通用的、与框架无关的解决方案，可以作为插件模块集成到现有智能体框架中，无需任何额外的训练成本。在不同领域的广泛实验证明了我们方法的有效性和通用性，强调了原则性、上下文感知演示选择对于构建健壮高效的LLM智能体的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [619] [Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI](https://arxiv.org/abs/2507.23565)
> *语义信任链：基于超图辅助智能体的协作方选择自主信任编排*

*Botao Zhu, Xianbin Wang, Dusit Niyato* | **Category: cs.AI** | **Updated: 2025-08-01**

**Keywords:** 信任编排, 智能体AI, 超图, 协作系统, 语义信任链

**Comment:** 

> **TL;DR:** 本文提出了一种基于语义信任链的自主信任编排方法，利用智能体AI和超图在设备空闲时进行信任评估，以实现分布式协作中高效的资源利用和信任管理。

**AI_Comments:** 该论文提出了一种新颖的自主信任编排范式，通过结合智能体AI和超图来解决分布式协作中信任评估的效率和准确性问题。其创新点在于引入“语义信任链”概念，并利用设备空闲时间进行评估，有效降低了资源开销。信任超图的分层管理和多跳协作支持也增强了其在大规模系统中的实用性。未来研究可以探索其在不同复杂任务和异构设备环境下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 在协作系统中，任务的有效完成依赖于对潜在设备的任务特定信任评估。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。不合时宜或过于频繁的信任评估会降低受限资源的利用率，对协作任务执行产生负面影响。

**Method:** 本文提出了一种基于语义信任链的自主信任编排方法。该方法利用智能体AI和超图来建立和维护设备间的信任关系。智能体AI通过自主感知、任务分解和语义推理，仅在设备空闲期间根据历史性能数据对协作方进行信任评估，从而实现分布式资源的高效利用。智能体AI通过分析资源能力与任务需求的一致性，对协作方资源进行任务特定信任评估。通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI实现协作方的分层管理，并根据信任语义识别需要信任评估的协作方，从而在开销和信任准确性之间取得平衡。此外，来自多个设备的本地信任超图可以链接起来支持多跳协作，从而实现大规模系统中的高效协调。

**Result:** 实验结果表明，所提出的方法实现了资源高效的信任评估。

**Conclusion:** 所提出的基于语义信任链的自主信任编排方法，利用智能体AI和超图，能够实现分布式协作中资源高效的信任评估，并在评估开销和信任准确性之间取得平衡，支持大规模系统中的多跳协作。

> **ai_Abstract:** 本文提出了一种名为“语义信任链”的自主信任编排方法，旨在解决分布式协作系统中信任评估的复杂性和资源消耗问题。该方法利用智能体AI和超图技术，仅在设备空闲时基于历史数据进行任务特定的信任评估，并通过维护嵌入信任语义的信任超图来分层管理协作方。这不仅实现了资源的高效利用，还在评估开销和信任准确性之间取得了平衡，并支持大规模系统中的多跳协作。实验证明其能实现资源高效的信任评估。

> **摘要翻译:** 在协作系统中，任务的有效完成依赖于对潜在设备的任务特定信任评估，以实现分布式协作。然而，任务的复杂性、分布式设备资源的时空动态性以及不可避免的评估开销，极大地增加了信任评估过程的复杂性和资源消耗。因此，不合时宜或过于频繁的信任评估会降低受限资源的利用率，对协作任务执行产生负面影响。为了解决这一挑战，本文提出了一种基于语义信任链新概念的自主信任编排方法。我们的技术采用智能体AI和超图来建立和维护设备间的信任关系。通过利用其在自主感知、任务分解和语义推理方面的优势，我们提出智能体AI仅在设备空闲期间根据历史性能数据感知设备状态并自主执行协作方信任评估，从而实现分布式资源的高效利用。此外，智能体AI通过分析资源能力与任务需求之间的一致性，对协作方资源进行任务特定信任评估。此外，通过为每个设备维护一个嵌入信任语义的信任超图，智能体AI实现协作方的分层管理，并根据信任语义识别需要信任评估的协作方，从而在开销和信任准确性之间取得平衡。此外，来自多个设备的本地信任超图可以链接起来支持多跳协作，从而实现大规模系统中的高效协调。实验结果表明，所提出的方法实现了资源高效的信任评估。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [623] [Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies](https://arxiv.org/abs/2507.22782)
> *基于注意力机制的Actor-Critic策略增强多智能体协作*

*Hugo Garrido-Lestache, Jeremy Kedziora* | **Category: cs.AI, cs.LG, I.2.0; I.2.8** | **Updated: 2025-07-31**

**Keywords:** 多智能体协作, 强化学习, 注意力机制, Actor-Critic, 集中式训练

**Comment:** 8 pages

> **TL;DR:** 本文提出TAAC算法，通过注意力机制和惩罚损失函数提升多智能体在合作环境中的协作能力，并在模拟足球环境中表现出优越性能。

**AI_Comments:** 该论文的创新点在于将多头注意力机制引入Actor和Critic，并结合惩罚损失函数，有效解决了多智能体协作中联合行动空间爆炸的问题，并促进了角色多样性。其在模拟足球环境中的优越表现证明了该方法的有效性，为多智能体强化学习领域提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在合作环境中，多智能体协作面临联合行动空间指数级增长的挑战，需要有效管理并确保高度协作。

**Method:** 本文提出Team-Attention-Actor-Critic (TAAC) 算法。TAAC采用集中式训练/集中式执行方案，在Actor和Critic中均引入多头注意力机制，以促进动态的智能体间通信，使智能体能够明确查询队友。此外，引入惩罚损失函数以促进智能体之间多样化但互补的角色。

**Result:** TAAC在模拟足球环境中与PPO和MAAC等基准算法进行比较，在胜率、净胜球、Elo等级分、智能体间连接性、平衡空间分布以及频繁的战术互动（如控球权交换）等多种指标上，TAAC表现出卓越的性能和增强的协作行为。

**Conclusion:** TAAC算法能够有效提升多智能体在复杂合作环境中的协作能力和整体性能。

> **ai_Abstract:** 本文提出了一种名为Team-Attention-Actor-Critic (TAAC) 的强化学习算法，旨在增强合作环境中的多智能体协作。TAAC采用集中式训练/集中式执行架构，并在Actor和Critic中融入多头注意力机制，以实现高效的智能体间通信并管理联合行动空间。此外，通过引入惩罚损失函数来促进智能体角色的多样性与互补性。在模拟足球环境中的实验表明，TAAC在多项性能指标上均优于现有基准算法，展现出更强的协作能力。

> **摘要翻译:** 本文介绍了Team-Attention-Actor-Critic (TAAC)，一种旨在增强合作环境中多智能体协作的强化学习算法。TAAC采用集中式训练/集中式执行方案，在Actor和Critic中均结合了多头注意力机制。这种设计促进了动态的智能体间通信，允许智能体明确查询队友，从而有效地管理联合行动空间的指数级增长，同时确保高度协作。我们进一步引入了一个惩罚损失函数，以促进智能体之间多样化但互补的角色。我们在模拟足球环境中评估了TAAC，并将其与代表其他多智能体范式的基准算法（包括近端策略优化和多智能体Actor-Attention-Critic）进行了比较。我们发现TAAC在各种指标（胜率、净胜球、Elo等级分、智能体间连接性、平衡空间分布以及频繁的战术互动，如控球权交换）上均表现出卓越的性能和增强的协作行为。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [648] [MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying](https://arxiv.org/abs/2507.23633)
> *MemoCue：通过策略引导查询赋能基于LLM的智能体进行人类记忆回忆*

*Qian Zhao, Zhuo Sun, Bin Guo, Zhiwen Yu* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 记忆回忆, LLM智能体, 策略引导查询, Recall Router, MemoCue

**Comment:** 

> **TL;DR:** MemoCue提出一种策略引导的LLM智能体，通过将查询转化为线索丰富的查询来辅助人类记忆回忆，解决了传统方法记忆模块有限和记忆召回性能低的问题。

**AI_Comments:** MemoCue的创新之处在于其将记忆理论中的“线索激活”概念融入到LLM智能体的查询策略中，并提出了一个结构化的Recall Router框架来解决策略选择和响应生成问题。这种结合认知科学原理与大语言模型技术的方法，为提升人机交互中的记忆辅助功能提供了新的思路和有效的解决方案。其在回忆启发方面的显著性能提升和人类评估的积极结果，都表明了该研究的重要性和实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统代理辅助记忆回忆方法中，记忆模块大小有限，阻碍了完整记忆的获取并影响了记忆回忆性能。受记忆理论启发，即通过有效线索可以主动激活相关记忆，作者旨在解决这一问题。

**Method:** 作者提出了Recall Router框架，设计了5W回忆图将记忆查询分类为五种典型场景，并定义了十五种回忆策略模式。他们还提出了分层回忆树结合蒙特卡洛树搜索算法来优化策略选择和策略响应生成。通过构建指令微调数据集并微调开源LLM，开发了MemoCue。

**Result:** MemoCue在三个代表性数据集上的实验表明，其在回忆启发方面超越了基于LLM的方法17.74%。进一步的人类评估也突出了其在记忆回忆应用中的优势。

**Conclusion:** MemoCue通过其策略引导的查询方法和Recall Router框架，显著提升了基于LLM的智能体在人类记忆回忆方面的表现，并在实际应用中展现出优势。

> **ai_Abstract:** 本论文提出MemoCue，一个基于LLM的智能体，旨在通过策略引导的查询来增强人类记忆回忆。针对传统方法中记忆模块的局限性，MemoCue引入Recall Router框架，该框架包含5W回忆图和分层回忆树与蒙特卡洛树搜索相结合的策略优化机制。通过指令微调构建，MemoCue在实验中表现出显著优于现有LLM方法的回忆启发能力，并在人类评估中证实了其在记忆回忆应用中的优势。

> **摘要翻译:** 智能体辅助记忆回忆是人机交互领域的一个关键研究问题。在传统方法中，智能体可以从其配备的记忆模块中检索信息，以帮助人们回忆不完整或模糊的记忆。然而，记忆模块的有限大小阻碍了完整记忆的获取，并影响了实际中的记忆回忆性能。记忆理论表明，通过一些有效的线索可以主动激活人的相关记忆。受此启发，我们提出了一种新颖的策略引导智能体辅助记忆回忆方法，允许智能体通过精心设计的策略将原始查询转换为线索丰富的查询，以帮助人们回忆记忆。为此，存在两个关键挑战。(1) 如何针对具有不同记忆回忆特征的各种遗忘场景选择合适的回忆策略？(2) 在只有抽象和稀疏标注的策略模式下，如何利用回忆策略获得高质量的响应？为了解决这些挑战，我们提出了一个Recall Router框架。具体来说，我们设计了一个5W回忆图，将记忆查询分为五种典型场景，并定义了对应场景下的十五种回忆策略模式。然后，我们提出了一个结合蒙特卡洛树搜索算法的分层回忆树来优化策略的选择和策略响应的生成。我们构建了一个指令微调数据集，并微调了多个开源大型语言模型（LLM），开发了MemoCue，一个擅长提供记忆启发式响应的智能体。在三个代表性数据集上的实验表明，MemoCue在回忆启发方面比基于LLM的方法高出17.74%。进一步的人类评估强调了其在记忆回忆应用中的优势。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [669] [Personalized Education with Ranking Alignment Recommendation](https://arxiv.org/abs/2507.23664)
> *个性化教育与排序对齐推荐*

*Haipeng Liu, Yuxuan Liu, Ting Long* | **Category: cs.AI, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 个性化问题推荐, 强化学习, 探索, 排序对齐推荐

**Comment:** 

> **TL;DR:** 本文提出排序对齐推荐（RAR）框架，通过将协作思想融入强化学习的探索机制，解决了个性化问题推荐中探索效率低下的问题，并有效提升了推荐性能。

**AI_Comments:** RAR的创新在于将协作思想引入强化学习的探索机制，解决了传统RL方法在个性化推荐中探索效率低下的痛点。其普适性使其能够集成到现有RL推荐系统中，具有较高的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 个性化问题推荐旨在帮助学生提高学习目标掌握度，但现有基于强化学习的方法在训练过程中探索效率低下，难以找到适合每个学生的最佳问题。

**Method:** 提出排序对齐推荐（RAR）框架，该框架将协作思想融入强化学习的探索机制，以在有限的训练回合内实现更高效的探索。

**Result:** 实验表明，RAR有效地提高了推荐性能。

**Conclusion:** RAR框架可以应用于任何基于强化学习的问题推荐系统，并能有效提高推荐性能。

> **ai_Abstract:** 本文针对个性化问题推荐中强化学习方法探索效率低下的问题，提出了一种名为排序对齐推荐（RAR）的新框架。RAR通过将协作思想融入探索机制，显著提高了在有限训练回合内的探索效率，并在实验中验证了其在提升推荐性能方面的有效性。该框架具有普适性，可应用于其他基于强化学习的问题推荐系统。

> **摘要翻译:** 个性化问题推荐旨在通过引导学生完成问题来提高他们对学习目标的掌握程度。大多数先前的方法将此任务建模为马尔可夫决策过程并使用强化学习来解决，但它们在高效探索方面存在困难，无法在训练期间为每个学生识别出最佳问题。为了解决这个问题，我们提出了排序对齐推荐（RAR），它将协作思想融入到探索机制中，从而在有限的训练回合内实现更高效的探索。实验表明，RAR有效地提高了推荐性能，并且我们的框架可以应用于任何基于强化学习的问题推荐器。我们的代码可在https://github.com/wuming29/RAR.git获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [684] [TextQuests: How Good are LLMs at Text-Based Video Games?](https://arxiv.org/abs/2507.23701)
> *TextQuests：大型语言模型在文本类电子游戏中的表现如何？*

*Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 文本冒险游戏, 基准测试, 长期推理, 自主学习

**Comment:** 

> **TL;DR:** 引入TextQuests基准，用于评估LLM在需要长期自主推理和试错学习的文本冒险游戏中的能力，不依赖外部工具。

**AI_Comments:** TextQuests的创新之处在于其专注于评估LLM在复杂、探索性环境中进行“内在”长期上下文推理的能力，通过禁用外部工具，它能更纯粹地测试模型自身的推理极限。这个基准的重要性在于它模拟了真实世界中需要持续、自主解决问题的场景，对于推动AI在更通用和复杂的任务上的发展具有重要意义。它强调了LLM在动态、不确定环境中的自适应和学习能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有AI智能体基准未能充分评估智能体在需要长期、自主推理和探索性环境中操作的能力。为了推动智能体在长背景下进行更强大的内在推理，需要一个新的评估工具。

**Method:** 引入TextQuests，一个基于Infocom交互式小说游戏的基准。该基准专门设计用于评估LLM智能体的独立问题解决能力，通过禁止使用外部工具，专注于在需要试错学习和持续问题解决的探索性环境中进行内在的长期上下文推理。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了TextQuests，一个用于评估大型语言模型（LLMs）在复杂文本冒险游戏中的自主推理能力的基准。该基准旨在弥补现有评估工具在衡量LLMs在需要长期、自导式推理和试错学习的探索性环境中表现方面的不足。TextQuests基于Infocom交互式小说游戏，要求LLMs在不使用外部工具的情况下，纯粹依靠内在的长上下文推理能力来解决问题。

> **摘要翻译:** 在反映现实世界挑战的复杂、交互式环境中评估AI智能体对于理解其实际能力至关重要。虽然现有智能体基准能够有效评估工具使用或结构化任务中的表现等技能，但它们通常未能充分捕捉智能体在需要长期、自主推理的探索性环境中自主操作的能力。为了促进能够进行更强大内在推理的智能体的开发，我们引入了TextQuests，这是一个基于Infocom交互式小说游戏套件的基准。这些文本冒险游戏人类玩家可能需要30多个小时才能完成，并需要数百个精确动作来解决，它们可以作为评估AI智能体在专注、有状态任务上的有效代理。该基准专门设计用于评估LLM智能体的独立问题解决能力，通过禁止使用外部工具，从而专注于在以试错学习和单一交互会话中持续问题解决为特征的探索性环境中进行内在的长期上下文推理能力。我们在https://textquests.ai发布TextQuests。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [704] [Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving](https://arxiv.org/abs/2507.23726)
> *Seed-Prover：自动化定理证明的深度与广度推理*

*Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu* | **Category: cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 定理证明, 自动化推理, 大型语言模型, 形式化验证, Lean

**Comment:** 

> **TL;DR:** Seed-Prover是一个利用Lean反馈和迭代改进的定理证明模型，在IMO、MiniF2F和PutnamBench上表现出色，显著推动了自动化数学推理。

**AI_Comments:** Seed-Prover的创新之处在于其结合了领域特定语言（Lean）提供的明确监督信号与迭代细化机制，并通过引入Seed-Geometry弥补了几何推理的不足。其在多个基准测试上的卓越表现，特别是IMO竞赛中的成功，凸显了形式化验证在推动自动化数学推理方面的巨大潜力。这项工作为未来开发更强大、更可靠的AI数学家奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在数学推理方面表现出强大能力，但由于缺乏清晰的监督信号，它们在定理证明方面仍然面临挑战。

**Method:** 本文提出了Seed-Prover，一个引理风格的整体证明推理模型。它通过Lean反馈、已证明的引理和自我总结来迭代完善证明。为解决IMO级别的竞赛问题，设计了三种测试时推理策略以实现深度和广度推理。此外，为弥补Lean在几何支持方面的不足，引入了几何推理引擎Seed-Geometry。

**Result:** Seed-Prover证明了78.1%的IMO形式化历史问题，饱和了MiniF2F，并在PutnamBench上取得了超过50%的成绩，大幅超越了之前的最新技术。Seed-Geometry优于之前的形式化几何引擎。这两个系统在IMO 2025中完全证明了6个问题中的5个。

**Conclusion:** 这项工作代表了自动化数学推理的重大进展，证明了形式化验证与长思维链推理的有效性。

> **ai_Abstract:** 本文提出了Seed-Prover，一个利用Lean反馈和自我总结进行迭代证明完善的引理风格整体证明推理模型，旨在解决LLM在定理证明中缺乏监督信号的问题。为应对IMO级别问题，模型结合深度和广度推理策略。实验结果显示，Seed-Prover在IMO、MiniF2F和PutnamBench上均大幅超越现有SOTA。此外，为弥补Lean在几何方面的不足，引入了Seed-Geometry。该研究表明形式化验证与长思维链推理在自动化数学推理领域具有显著效果。

> **摘要翻译:** 大型语言模型（LLMs）通过利用强化学习和长链式思维，在数学推理方面表现出强大的能力，但由于仅使用自然语言时缺乏清晰的监督信号，它们在定理证明方面仍然面临挑战。像Lean这样的专用领域特定语言通过对证明进行形式化验证提供了清晰的监督，从而能够通过强化学习进行有效训练。在这项工作中，我们提出了Seed-Prover，一个引理风格的整体证明推理模型。Seed-Prover可以根据Lean反馈、已证明的引理和自我总结迭代地完善其证明。为了解决IMO级别的竞赛问题，我们设计了三种测试时推理策略，以实现深度和广度推理。Seed-Prover证明了78.1%的IMO形式化历史问题，饱和了MiniF2F，并在PutnamBench上取得了超过50%的成绩，大幅超越了之前的最新技术。为了解决Lean中缺乏几何支持的问题，我们引入了几何推理引擎Seed-Geometry，它优于之前的形式化几何引擎。我们使用这两个系统参加了IMO 2025，并完全证明了6个问题中的5个。这项工作代表了自动化数学推理的重大进展，证明了形式化验证与长链式思维推理的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [710] [EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework](https://arxiv.org/abs/2504.14928)
> *EducationQ：通过多智能体对话框架评估大型语言模型的教学能力*

*Yao Shi, Rongkeng Liang, Yong Xu* | **Category: cs.AI, cs.CE, cs.CL, cs.CY, cs.HC** | **Updated: 2025-07-31**

**Keywords:** LLM, 教学能力评估, 多智能体系统, EducationQ, 教育AI

**Comment:** Paper URL: https://aclanthology.org/2025.acl-long.1576 ;Presentation
  Video: https://www.youtube.com/watch?v=j63ooKE50I0

> **TL;DR:** 开发了EducationQ框架，通过模拟对话评估LLM的教学能力，发现教学效果与模型规模或通用推理能力并非线性相关，小型模型也能表现出色，表明LLM作为教师需要专门优化。

**AI_Comments:** 该研究创新性地提出了多智能体对话框架来评估LLM的教学能力，解决了传统评估的复杂性问题。其发现教学效果不与模型规模线性相关，挑战了现有对LLM能力的普遍认知，并强调了针对教学场景进行专门优化的重要性，对未来教育AI的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）作为教育工具日益普及，然而，由于师生互动是资源密集型、情境依赖型且方法学复杂的，评估其教学能力仍然具有挑战性。

**Method:** 引入EducationQ，一个多智能体对话框架，通过模拟动态教育场景高效评估教学能力，该框架包含专门用于教学、学习和评估的智能体。测试了来自主要AI组织的14个LLM，涉及13个学科和10个难度级别的1,498个问题，并采用定量指标结合定性分析和专家案例研究的混合方法进行评估。

**Result:** 教学效果与模型规模或通用推理能力不呈线性相关；一些小型开源模型在教学情境中表现优于大型商业模型；顶尖模型展现出独特的教学优势（如复杂的提问策略、自适应反馈机制）。人类专家评估显示，我们对有效教学行为的自动化定性分析与专家意见有78%的一致性。

**Conclusion:** 作为教师的LLM需要专门优化，超越简单的规模扩展；下一代教育AI应优先针对性地提高特定教学效果。

> **ai_Abstract:** 本文提出了EducationQ，一个多智能体对话框架，用于高效评估大型语言模型（LLMs）的教学能力。通过模拟师生互动，该框架测试了14个LLM在多学科和多难度问题上的表现。研究发现，LLM的教学效果与模型规模或通用推理能力无线性关系，一些小型模型甚至优于大型模型。这表明LLM作为教育工具需要专门的教学优化，而非仅仅依靠模型规模的扩大，为未来教育AI的发展提供了新方向。

> **摘要翻译:** 大型语言模型（LLMs）越来越多地作为教育工具，然而，由于师生互动是资源密集型、情境依赖型且方法学复杂的，评估其教学能力仍然具有挑战性。我们引入了EducationQ，一个多智能体对话框架，通过模拟动态教育场景，有效地评估教学能力，该框架包含专门用于教学、学习和评估的智能体。我们测试了来自主要AI组织（OpenAI、Meta、Google、Anthropic等）的14个LLM，涉及13个学科和10个难度级别的1,498个问题，结果显示教学效果与模型规模或通用推理能力并非线性相关——一些较小的开源模型在教学情境中表现优于较大的商业模型。这一发现突出了当前评估中存在的关键差距，即它们优先考虑知识回忆而非交互式教学法。我们的混合方法评估，结合了定量指标、定性分析和专家案例研究，识别出表现最佳模型所采用的独特教学优势（例如，复杂的提问策略、自适应反馈机制）。人类专家评估显示，我们对有效教学行为的自动化定性分析与专家意见有78%的一致性，从而验证了我们的方法。EducationQ表明，作为教师的LLM需要专门优化，超越简单的规模扩展，这表明下一代教育AI应优先针对性地提高特定教学效果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [718] [CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks](https://arxiv.org/abs/2507.23751)
> *CoT-Self-Instruct：构建用于推理和非推理任务的高质量合成提示*

*Ping Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, Jing Xu* | **Category: cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** CoT-Self-Instruct, 合成数据, 思维链, 大型语言模型, 推理, 指令遵循

**Comment:** 

> **TL;DR:** CoT-Self-Instruct是一种通过Chain-of-Thought（CoT）生成高质量合成提示的方法，在推理和非推理任务上均优于现有数据集。

**AI_Comments:** CoT-Self-Instruct的创新之处在于将思维链（CoT）与自指导（Self-Instruct）范式相结合，使得LLM能够生成更高质量、更复杂的合成训练数据。这种方法不仅提升了模型在复杂推理任务上的性能，也增强了其在通用指令遵循任务上的能力，为未来LLM的训练提供了新的高效数据生成途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有训练数据集在大型语言模型（LLMs）的训练中可能存在质量或数量不足的问题，尤其是在需要复杂推理或遵循指令的任务上。本文旨在通过生成高质量的合成提示来改进LLM的训练。

**Method:** CoT-Self-Instruct方法指导大型语言模型（LLMs）首先基于给定的种子任务通过思维链（CoT）进行推理和规划，然后生成质量和复杂性相似的新合成提示，最后通过自动指标过滤以获得高质量数据。

**Result:** 在可验证的推理任务中，CoT-Self-Instruct生成的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond等基准测试上显著优于s1k和OpenMathReasoning等现有训练数据集。对于不可验证的指令遵循任务，该方法在AlpacaEval 2.0和Arena-Hard上均超越了人工或标准自指导提示的性能。

**Conclusion:** CoT-Self-Instruct通过结合CoT推理和数据过滤，能够生成高质量的合成提示，从而显著提升大型语言模型在推理和指令遵循任务上的表现，优于现有的人工或合成数据集。

> **ai_Abstract:** 本文提出了CoT-Self-Instruct，一种合成数据生成方法。该方法利用大型语言模型（LLMs）通过思维链（CoT）进行推理和规划，以生成高质量的合成提示，并随后进行自动过滤。实验结果表明，在可验证的推理任务（如MATH500、AMC23、AIME24、GPQA-Diamond）中，其合成数据显著优于现有训练数据集。同时，在不可验证的指令遵循任务（如AlpacaEval 2.0、Arena-Hard）中，CoT-Self-Instruct的表现也超越了人工或标准自指导提示。

> **摘要翻译:** 我们提出了CoT-Self-Instruct，这是一种合成数据生成方法，它指导大型语言模型（LLMs）首先基于给定的种子任务通过思维链（CoT）进行推理和规划，然后生成质量和复杂性相似的新合成提示，用于LLM训练，随后通过自动指标过滤以获得高质量数据。在可验证的推理任务中，我们的合成数据在MATH500、AMC23、AIME24和GPQA-Diamond上显著优于现有的训练数据集，例如s1k和OpenMathReasoning。对于不可验证的指令遵循任务，我们的方法在AlpacaEval 2.0和Arena-Hard上均超越了人工或标准自指导提示的表现。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [724] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
> *基于模型的长期人类权力适宜度量软最大化*

*Jobst Heitzig, Ram Potham* | **Category: cs.AI, cs.CY, cs.LG, econ.TH, math.OC, 68Txx, I.2** | **Updated: 2025-07-31**

**Keywords:** AI安全, 人类权力, 目标函数, 强化学习, 权力平衡

**Comment:** 

> **TL;DR:** 本文提出了一种基于模型的方法，通过软最大化人类权力指标来提升AI安全性和人类福祉，这被认为比直接基于效用的目标更安全。

**AI_Comments:** 这篇论文提出了一种新颖且重要的AI安全目标设计方法，即通过软最大化人类权力指标而非直接效用函数。其创新点在于将“权力”作为核心概念引入AI目标设计，并考虑了人类的有限理性和社会规范。这对于解决AI对齐问题和防止潜在的AI失控具有重要意义。该方法提供了一个潜在的更安全、更符合人类福祉的AI发展方向。

<details>
  <summary>Details</summary>

**Motivation:** AI安全中，权力是一个关键概念，包括作为工具性目标的权力寻求、人类权力的丧失、人机互动中的权力平衡以及国际AI治理。同时，作为追求多样化目标能力存在的权力对人类福祉至关重要。本文旨在通过明确地赋能人类并以期望的方式管理人机权力平衡，来同时促进安全和福祉。

**Method:** 本文采用了一种有原则的、部分公理化的方法，设计了一个可参数化和可分解的目标函数，该函数代表了一个对不平等和风险规避的长期人类权力聚合指标。它考虑了人类的有限理性和社会规范，并包含了各种可能的人类目标。作者推导了通过逆向归纳法计算该指标的算法，或通过一种多智能体强化学习形式从给定世界模型中近似计算。

**Result:** 本文通过多种典型情境示例说明了（软）最大化此指标的后果，并描述了它可能隐含的工具性子目标。

**Conclusion:** 初步评估认为，软最大化人类权力适宜聚合指标可能构成对智能AI系统而言有益的目标，并且比直接基于效用的目标更安全。

> **ai_Abstract:** 本文提出了一种基于模型的长期人类权力聚合指标的软最大化方法，旨在通过明确赋能人类和管理人机权力平衡来提升AI安全性和人类福祉。该方法设计了一个考虑人类有限理性和社会规范的可参数化目标函数，并通过逆向归纳或多智能体强化学习进行计算。研究认为，这种软最大化人类权力指标的目标比传统的基于效用的目标更安全，对具身AI系统具有潜在益处。

> **摘要翻译:** 权力是AI安全中的一个关键概念：作为工具性目标的权力寻求、人类突然或逐渐的权力丧失、人机互动中的权力平衡以及国际AI治理。同时，作为追求多样化目标的能力，权力对福祉至关重要。
本文探讨了通过明确强制AI智能体赋能人类并以期望的方式管理人机权力平衡，来同时促进安全和福祉的理念。我们采用了一种有原则的、部分公理化的方法，设计了一个可参数化和可分解的目标函数，该函数代表了一个规避不平等和风险的长期人类权力聚合指标。它考虑了人类的有限理性和社会规范，并且，至关重要的是，考虑了各种可能的人类目标。
我们推导了通过逆向归纳法计算该指标的算法，或通过一种多智能体强化学习形式从给定世界模型中近似计算。我们通过多种典型情境示例说明了（软）最大化此指标的后果，并描述了它可能隐含的工具性子目标。我们谨慎的评估是，软最大化人类权力适宜聚合指标可能构成对智能AI系统而言有益的目标，并且比直接基于效用的目标更安全。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [725] [DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search](https://arxiv.org/abs/2507.07426)
> *DrugMCTS：一个结合多智能体、RAG和蒙特卡洛树搜索的药物重定向框架*

*Zerui Yang, Yuwei Wan, Siyu Yan, Yudai Matsuda, Tong Xie, Bram Hoex, Linqi Song* | **Category: cs.AI, cs.CE** | **Updated: 2025-07-31**

**Keywords:** 药物重定向, 多智能体, RAG, 蒙特卡洛树搜索

**Comment:** 

> **TL;DR:** DrugMCTS是一个结合多智能体、RAG和蒙特卡洛树搜索的新框架，用于药物重定向，在DrugBank和KIBA数据集上表现出更高的召回率和鲁棒性。

**AI_Comments:** DrugMCTS通过结合多智能体、RAG和蒙特卡洛树搜索，为药物重定向提供了一种新颖的解决方案，有效解决了LLM在处理超出预训练知识范围的结构化科学数据时的局限性。其采用的五个专业智能体实现结构化和迭代推理，提升了药物重定向的召回率和鲁棒性，对LLM在科学领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在药物重定向等科学领域的推理能力受限于预训练知识，且传统方法（如微调或检索增强生成）存在计算开销大或未能充分利用结构化科学数据的局限性。

**Method:** 本文提出了DrugMCTS框架，该框架协同整合了检索增强生成（RAG）、多智能体协作和蒙特卡洛树搜索（MCTS）进行药物重定向。它采用五个专门的智能体，负责检索和分析分子与蛋白质信息，从而实现结构化和迭代推理。

**Result:** 在DrugBank和KIBA数据集上进行的广泛实验表明，DrugMCTS与通用LLMs和深度学习基线相比，实现了更高的召回率和鲁棒性。

**Conclusion:** 研究结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物重定向应用中的重要性。

> **ai_Abstract:** 本文提出了DrugMCTS框架，旨在解决现有LLM在药物重定向中推理能力受限及传统方法效率低下的问题。DrugMCTS通过整合RAG、多智能体协作和蒙特卡洛树搜索，并利用五个专门智能体进行分子和蛋白质信息检索分析，实现了结构化和迭代推理。实验证明，该框架在DrugBank和KIBA数据集上比通用LLM和深度学习基线具有更高的召回率和鲁棒性，突出了结构化推理和智能体协作的重要性。

> **摘要翻译:** 大型语言模型在药物重定向等科学领域已展现出巨大潜力。然而，当推理超出预训练期间获得的知识时，它们的有效性仍然受限。传统的微调或检索增强生成等方法，要么计算开销大，要么未能充分利用结构化科学数据，面临局限性。为了克服这些挑战，我们提出了DrugMCTS，一个创新框架，协同整合了RAG、多智能体协作和蒙特卡洛树搜索用于药物重定向。该框架采用五个专门的智能体，负责检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。在DrugBank和KIBA数据集上进行的广泛实验表明，与通用LLM和深度学习基线相比，DrugMCTS实现了更高的召回率和鲁棒性。我们的结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物重定向应用中的重要性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [732] [SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model](https://arxiv.org/abs/2507.23773)
> *SimuRA：基于LLM世界模型的模拟推理架构，迈向通用目标导向型智能体*

*Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing* | **Category: cs.AI, cs.CL, cs.LG, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 通用智能体, 世界模型, LLM, 模拟推理, 网页浏览

**Comment:** 

> **TL;DR:** SimuRA引入了一个基于LLM的世界模型，通过模拟推理克服了传统LLM智能体在通用性和规划能力上的局限性，在网页浏览任务中表现出显著优势。

**AI_Comments:** SimuRA的创新之处在于其引入了基于LLM的世界模型进行模拟推理，这有效解决了现有LLM智能体在任务通用性和复杂规划方面的不足。通过模拟机制，智能体能够更好地预测行动结果，从而在未知环境中进行更有效的决策。该研究的重要性在于它为构建更接近人类通用智能的AI智能体提供了一条有前景的路径，并有望打破“一任务一智能体”的瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于大型语言模型（LLM）构建的AI智能体普遍采用“一任务一智能体”的方法，这导致了可扩展性和通用性的不足，并且受限于自回归LLM的根本局限。受人类通过心理模拟行动结果进行推理的启发，研究旨在构建一个更通用、更强大的AI智能体。

**Method:** 本文提出了SimuRA，一个用于通用智能体推理的目标导向型架构。它基于最优智能体在任何环境中的原理性公式，通过引入一个用于模拟规划的世界模型来克服自回归推理的局限性。这个通用世界模型通过LLM实现，能够利用自然语言丰富的潜在空间在广泛的环境中灵活规划。

**Result:** 在困难的网页浏览任务中，SimuRA将航班搜索的成功率从0%提高到32.2%。基于世界模型的规划，特别是，相比自回归规划显示出高达124%的一致优势，证明了世界模型模拟作为一种推理范式的优势。

**Conclusion:** SimuRA通过引入基于LLM的世界模型进行模拟推理，有效克服了传统自回归LLM智能体在通用性和规划方面的局限性，并有望训练出单一、通用的LLM基础智能体，使其在所有环境中都能表现出超智能行为。

> **ai_Abstract:** SimuRA是一种新的目标导向型智能体架构，旨在通过引入基于LLM的世界模型进行模拟推理，克服现有LLM智能体在通用性和规划能力上的局限。它借鉴人类通过心理模拟进行推理的方式，使智能体能够在一个概念丰富的潜在空间中灵活规划。实验证明，SimuRA在网页浏览任务中显著提升了成功率，并展现出基于世界模型的规划相比自回归规划的显著优势，为构建更通用、更强大的AI智能体奠定了基础。

> **摘要翻译:** 基于大型语言模型（LLM）构建的AI智能体具有巨大的前景，但目前的实践集中于“一任务一智能体”的方法，这不仅缺乏可扩展性和通用性，而且还受到自回归LLM根本局限性的困扰。另一方面，人类是通用智能体，他们通过心理模拟行动和计划的结果进行推理。为了迈向更通用、更强大的AI智能体，我们引入了SimuRA，一个用于广义智能体推理的目标导向型架构。基于任何环境中最优智能体的原则性公式，SimuRA通过引入一个用于模拟规划的世界模型来克服自回归推理的局限性。通用世界模型使用LLM实现，可以利用自然语言概念丰富的潜在空间在广泛的环境中灵活规划。在困难的网页浏览任务上的实验表明，SimuRA将航班搜索的成功率从0%提高到32.2%。特别是，基于世界模型的规划比自回归规划显示出高达124%的一致优势，证明了世界模型模拟作为一种推理范式的优势。我们对训练一个基于LLM的单一通用智能体模型，使其能够在所有环境中表现出超智能行为的可能性感到兴奋。为此，我们首先发布了SimuRA，一个基于SimuRA模型和预训练LLM构建的网页浏览智能体，作为研究演示供公众测试。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [752] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
> *RL-PLUS：通过混合策略优化对抗LLM在强化学习中的能力边界崩溃*

*Yihong Dong, Xue Jiang, Yongding Tao, Huanyu Liu, Kechi Zhang, Lili Mou, Rongyu Cao, Yingwei Ma, Jue Chen, Binhua Li, Zhi Jin, Fei Huang, Yongbin Li, Ge Li* | **Category: cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 强化学习, 能力边界崩溃, 混合策略优化, 多重重要性采样

**Comment:** 

> **TL;DR:** RL-PLUS通过结合内部探索和外部数据，解决了强化学习中LLM能力边界崩溃的问题，并在多个推理任务上取得了SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了RL-PLUS框架，通过结合内部探索和外部数据，并引入多重重要性采样和基于探索的优势函数，有效地解决了LLM在强化学习中面临的能力边界崩溃问题。这对于提升LLM在复杂推理任务上的表现和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可验证奖励强化学习（RLVR）方法受限于LLM固有的能力边界，并且由于其在线策略、巨大的动作空间和稀疏奖励，难以突破这些边界，甚至可能导致能力边界崩溃，缩小LLM解决问题的范围。

**Method:** 本文提出RL-PLUS方法，它结合了内部利用（思考）和外部数据（学习），以增强推理能力并超越基础模型的边界。RL-PLUS包含两个核心组件：多重重要性采样（解决外部数据分布不匹配问题）和基于探索的优势函数（引导模型走向高价值、未探索的推理路径）。

**Result:** RL-PLUS在六个数学推理基准测试中，与现有RLVR方法相比达到了最先进的性能，并在六个分布外推理任务中表现出色。它在不同模型家族中实现了持续显著的增益，平均相对改进范围为21.1%至69.2%。此外，Pass@k曲线表明RL-PLUS有效解决了能力边界崩溃问题。

**Conclusion:** RL-PLUS通过混合策略优化成功解决了LLM在强化学习中能力边界崩溃的问题，显著提升了LLM的推理能力和泛化性。

> **ai_Abstract:** 本文提出RL-PLUS，一种结合内部探索（思考）和外部数据（学习）的新型强化学习方法，旨在解决现有RLVR方法中LLM能力边界崩溃的问题。RL-PLUS通过多重重要性采样和基于探索的优势函数，使LLM能够突破固有能力限制，探索高价值推理路径。实验结果表明，RL-PLUS在多个数学推理和分布外任务上均取得了SOTA性能和显著提升，有效缓解了能力边界崩溃。

> **摘要翻译:** 可验证奖励强化学习（RLVR）显著提升了大型语言模型（LLM）的复杂推理能力。然而，由于其固有的在线策略、LLM巨大的动作空间和稀疏奖励，它难以突破基础LLM固有的能力边界。此外，RLVR可能导致能力边界崩溃，从而缩小LLM解决问题的范围。为了解决这个问题，我们提出了RL-PLUS，这是一种新颖的方法，它将内部利用（即思考）与外部数据（即学习）相结合，以实现更强的推理能力并超越基础模型的边界。RL-PLUS集成了两个核心组件：多重重要性采样，用于解决外部数据带来的分布不匹配问题；以及一个基于探索的优势函数，用于引导模型走向高价值、未探索的推理路径。我们提供了理论分析和大量的实验，以证明我们方法的优越性和通用性。结果表明，RL-PLUS在六个数学推理基准测试中，与现有RLVR方法相比达到了最先进的性能，并在六个分布外推理任务中表现出色。它还在不同模型家族中实现了持续显著的增益，平均相对改进范围为21.1%至69.2%。此外，多个基准测试的Pass@k曲线表明RL-PLUS有效解决了能力边界崩溃问题。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [891] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
> *多频带可变滞后格兰杰因果关系：一个用于跨频率因果时间序列推断的统一框架*

*Chakattrai Sookkongwaree, Tattep Lakmuang, Chainarong Amornbunchornvej* | **Category: cs.AI, cs.LG, econ.EM, stat.ME** | **Updated: 2025-08-01**

**Keywords:** 格兰杰因果关系, 时间序列, 因果推断, 多频带, 可变滞后

**Comment:** First draft

> **TL;DR:** 本文提出了多频带可变滞后格兰杰因果关系（MB-VLGC），这是一个新的框架，用于在时间序列中进行因果推断，它不仅考虑了可变滞后，还考虑了跨频率的因果相互作用，并在实验中显著优于现有方法。

**AI_Comments:** 该论文的创新之处在于提出了MB-VLGC，成功地将可变滞后和多频带分析相结合，克服了传统格兰杰因果关系及其变体的两大限制。通过考虑因果关系在时间和频率上的双重变化，该框架更贴近复杂系统的实际情况，尤其是在神经科学等领域具有重要意义。其高效的推断流程和在多个数据集上的优异表现，进一步证实了其实用性和广泛适用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的格兰杰因果关系框架假设固定的因果滞后，这在复杂系统中往往不切实际。虽然可变滞后格兰杰因果关系（VLGC）解决了时间点上的可变滞后问题，但它未能考虑到因果相互作用不仅可能在时间延迟上变化，还可能跨频率带变化，例如脑信号中不同频带的延迟可能不同。

**Method:** 本文将多频带可变滞后格兰杰因果关系（MB-VLGC）形式化，并提出了一个新颖的框架，通过明确建模频率依赖的因果延迟来推广传统的VLGC。该方法提供了MB-VLGC的正式定义，论证了其理论上的合理性，并提出了一个高效的推断流程。

**Result:** 在多个领域的合成数据集和真实世界数据集上进行的广泛实验表明，该框架显著优于现有方法。

**Conclusion:** 该框架证实了其对任何类型时间序列数据的广泛适用性。

> **ai_Abstract:** 本研究提出了多频带可变滞后格兰杰因果关系（MB-VLGC），一个统一的框架，用于在时间序列中进行跨频率的因果推断。它解决了传统格兰杰因果关系固定滞后和现有可变滞后方法忽略频率依赖性因果交互的局限性。MB-VLGC通过明确建模频率依赖的因果延迟来推广现有框架。实验证明，该方法在合成和真实世界数据上均显著优于现有方法，展现出广泛的适用性。

> **摘要翻译:** 理解时间序列中的因果关系对于许多领域至关重要，包括神经科学、经济学和行为科学。格兰杰因果关系是时间序列中推断因果关系的著名技术之一。通常，格兰杰因果关系框架在因果之间具有强烈的固定滞后假设，这在复杂系统中往往不切实际。虽然最近关于可变滞后格兰杰因果关系（VLGC）的工作通过允许原因在每个时间点以不同的时间滞后影响结果来解决这一限制，但它未能考虑到因果相互作用不仅可能在时间延迟上变化，而且可能跨频率带变化。例如，在脑信号中，α波段活动可能比较慢的δ波段振荡以更短的延迟影响另一个区域。在这项工作中，我们形式化了多频带可变滞后格兰杰因果关系（MB-VLGC），并提出了一个新颖的框架，通过明确建模频率依赖的因果延迟来推广传统VLGC。我们提供了MB-VLGC的正式定义，证明了其理论上的合理性，并提出了一个高效的推断流程。在多个领域的广泛实验表明，我们的框架在合成数据集和真实世界数据集上都显著优于现有方法，证实了其对任何类型时间序列数据的广泛适用性。代码和数据集已公开可用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [893] [Unifying Post-hoc Explanations of Knowledge Graph Completions](https://arxiv.org/abs/2507.22951)
> *统一知识图谱补全的后验解释*

*Alessandro Lonardi, Samy Badreddine, Tarek R. Besold, Pablo Sanchez Martin* | **Category: cs.AI, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 知识图谱补全, 后验解释, 可解释性, 评估协议, 统一框架

**Comment:** 

> **TL;DR:** 本文提出了一个统一的框架来表征知识图谱补全的后验解释，并改进了评估协议，以提高可重现性和影响力。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的框架来规范KGC的后验解释，并通过多目标优化平衡解释的质量。它还关注了评估标准的改进和用户导向的可解释性，这对于推动KGC可解释性研究的标准化和实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识图谱补全（KGC）的后验可解释性缺乏形式化和一致的评估，阻碍了可重现性和跨研究比较。

**Method:** 首先，提出了一个通过多目标优化来表征后验解释的通用框架，平衡其有效性和简洁性，并统一了现有KGC后验可解释性算法及其产生的解释。其次，建议并经验性地支持使用平均倒数排名（Mean Reciprocal Rank）和Hits@k等流行指标改进评估协议。最后，强调了可解释性作为解释能够解决对终端用户有意义的查询的能力的重要性。

**Result:** 统一了现有的KGC后验可解释性算法及其产生的解释；经验性地支持了改进的评估协议。

**Conclusion:** 通过统一方法和完善评估标准，这项工作旨在使KGC可解释性研究更具可重现性和影响力。

> **ai_Abstract:** 本文提出了一个统一的框架来表征知识图谱补全（KGC）的后验解释，旨在解决现有方法缺乏形式化和一致评估的问题。该框架通过多目标优化平衡解释的有效性和简洁性，并统一了现有KGC解释算法。此外，文章还提出了改进的评估协议，并强调了可解释性对用户查询的重要性，以期提高KGC可解释性研究的可重现性和影响力。

> **摘要翻译:** 知识图谱补全（KGC）的后验可解释性缺乏形式化和一致的评估，阻碍了可重现性和跨研究比较。本文主张对KGC中的后验可解释性采用统一的方法。首先，我们提出了一个通用框架，通过多目标优化来表征后验解释，平衡其有效性和简洁性。这统一了KGC中现有的后验可解释性算法及其产生的解释。接下来，我们建议并经验性地支持使用流行指标如平均倒数排名（Mean Reciprocal Rank）和Hits@k改进评估协议。最后，我们强调可解释性作为解释能够解决对终端用户有意义的查询的能力的重要性。通过统一方法和完善评估标准，这项工作旨在使KGC可解释性研究更具可重现性和影响力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [900] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
> *通过以数据为中心的多模态可解释人工智能实现透明自适应学习*

*Maryam Mosleh, Marie Devlin, Ellis Solaiman* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 自适应学习, 可解释AI, 多模态, 透明度, 用户个性化

**Comment:** 

> **TL;DR:** 本文提出一个混合框架，结合传统可解释AI和生成式AI，并根据用户角色和学习目标生成多模态、个性化的解释，旨在提高自适应学习系统的透明度和用户体验。

**AI_Comments:** 该论文的创新点在于将传统可解释AI与生成式AI和用户个性化相结合，以解决自适应学习系统中透明度不足的问题。它重新定义了可解释性，强调了用户角色和学习目标的重要性，使其更具实用价值。该研究对于提升AI教育应用的信任度和接受度具有重要意义，但抽象中并未提供具体的实验结果来验证其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI驱动自适应学习系统缺乏透明度，对决策过程的洞察有限。大多数可解释AI技术侧重于技术输出，却忽视了用户角色和理解。

**Method:** 本文提出了一个混合框架，该框架将传统可解释AI技术与生成式AI模型和用户个性化相结合，以生成针对用户需求定制的多模态、个性化解释。它将可解释性重新定义为一种根据用户角色和学习目标定制的动态沟通过程。

**Result:** Not mentioned in abstract

**Conclusion:** 该研究旨在推动可解释AI的发展，以增强透明度，同时支持以用户为中心的体验。框架设计、教育领域XAI的局限性以及关于准确性、公平性和个性化的研究方向已被概述。

> **ai_Abstract:** 本文针对AI驱动自适应学习系统缺乏透明度的问题，提出了一种混合可解释AI框架。该框架结合了传统XAI技术与生成式AI和用户个性化，旨在生成多模态、个性化的解释，并将可解释性定义为一种动态的用户中心沟通过程。研究概述了框架设计、教育XAI的局限性，并指出了未来在准确性、公平性和个性化方面的研究方向，以实现更透明和用户友好的自适应学习体验。

> **摘要翻译:** 人工智能驱动的自适应学习系统正在通过数据驱动的学习体验适应性改造教育。然而，许多此类系统缺乏透明度，对决策过程的洞察有限。大多数可解释人工智能（XAI）技术侧重于技术输出，却忽视了用户角色和理解。本文提出了一个混合框架，该框架将传统XAI技术与生成式AI模型和用户个性化相结合，以生成针对用户需求定制的多模态、个性化解释。我们将可解释性重新定义为一种根据用户角色和学习目标定制的动态沟通过程。我们概述了该框架的设计、教育领域XAI的关键局限性以及关于准确性、公平性和个性化的研究方向。我们的目标是迈向既能增强透明度又能支持以用户为中心体验的可解释人工智能。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [901] [Data Readiness for Scientific AI at Scale](https://arxiv.org/abs/2507.23018)
> *科学AI规模化数据准备度*

*Wesley Brewer, Patrick Widener, Valentine Anantharaj, Feiyi Wang, Tom Beck, Arjun Shankar, Sarp Oral* | **Category: cs.AI, cs.CE, cs.DC, cs.LG, I.2.6** | **Updated: 2025-07-30**

**Keywords:** 科学AI, 数据准备度, 高性能计算, 基础模型, 数据框架

**Comment:** 10 pages, 1 figure, 2 tables

> **TL;DR:** 本文探讨了AI数据准备度原则如何应用于大型科学数据集，并提出了一个二维框架来指导科学AI基础设施的开发。

**AI_Comments:** 本文提出了一个新颖的二维数据准备度框架，将数据准备度级别和处理阶段结合起来，为大规模科学AI数据处理提供了结构化的指导。其创新之处在于将DRAI原则具体应用于HPC环境下的科学数据集，并强调了对Transformer模型的支持。该框架有望推动科学AI基础设施的标准化和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨AI数据准备度（DRAI）原则如何应用于用于训练基础模型的领导规模科学数据集，以识别将科学数据转化为可扩展AI训练所面临的关键挑战。

**Method:** 本文分析了气候、核聚变、生物/健康和材料四个代表性领域的典型工作流程，以识别常见的预处理模式和领域特定约束。在此基础上，引入了一个由数据准备度级别（从原始到AI就绪）和数据处理阶段（从摄取到分片）组成的二维准备度框架，该框架专为高性能计算（HPC）环境量身定制。

**Result:** 该框架概述了将科学数据转化为可扩展AI训练（特别是强调基于Transformer的生成模型）的关键挑战。这些维度共同形成了一个概念性成熟度矩阵，用于表征科学数据准备度。

**Conclusion:** 该二维数据准备度框架和成熟度矩阵旨在指导基础设施开发，以实现对科学领域可扩展和可复现AI的标准化、跨领域支持。

> **ai_Abstract:** 本文研究了大规模科学数据集的AI数据准备度，通过分析气候、核聚变、生物/健康和材料等领域的典型工作流程，识别了数据预处理模式和约束。作者提出了一个针对高性能计算环境的二维数据准备度框架，包括数据准备度级别和数据处理阶段，旨在解决科学数据向可扩展AI训练转化的挑战，并指导构建标准化、跨领域的科学AI基础设施。

> **摘要翻译:** 本文探讨了AI数据准备度（DRAI）原则如何应用于用于训练基础模型的领导规模科学数据集。我们分析了气候、核聚变、生物/健康和材料四个代表性领域的典型工作流程，以识别常见的预处理模式和领域特定约束。我们引入了一个由数据准备度级别（从原始到AI就绪）和数据处理阶段（从摄取到分片）组成的二维准备度框架，两者均专为高性能计算（HPC）环境量身定制。该框架概述了将科学数据转化为可扩展AI训练（强调基于Transformer的生成模型）的关键挑战。这些维度共同构成了一个概念性成熟度矩阵，用于表征科学数据准备度，并指导基础设施开发，以实现对科学领域可扩展和可复现AI的标准化、跨领域支持。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [909] [FairReason: Balancing Reasoning and Social Bias in MLLMs](https://arxiv.org/abs/2507.23067)
> *FairReason: 平衡多模态大语言模型中的推理能力与社会偏见*

*Zhenyu Pan, Yutong Zhang, Jianshu Zhang, Haoran Lu, Haozheng Luo, Yuwei Han, Philip S. Yu, Manling Li, Han Liu* | **Category: cs.AI** | **Updated: 2025-07-30**

**Keywords:** 多模态大语言模型, 社会偏见, 推理能力, 偏见缓解, 强化学习

**Comment:** 

> **TL;DR:** 本研究探讨了多模态大语言模型中推理能力提升与社会偏见缓解之间的权衡，并发现通过强化学习以特定样本比例训练可有效平衡两者。

**AI_Comments:** 该论文的创新之处在于明确探讨了多模态大语言模型中推理能力提升与社会偏见缓解之间的内在权衡，并量化了不同策略和样本比例对这一权衡的影响。特别是，它提供了一个具体的“甜点”比例（1:4的去偏见与推理样本，通过RL训练），为实际应用中平衡模型的性能和公平性提供了有价值的指导。这对于构建更负责任的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大语言模型（MLLMs）在各种任务中表现出色，但提升其推理能力的方法（如高级提示和后训练微调）常导致模型输出中出现明显的社会偏见。目前尚不清楚推理能力提升与偏见缓解如何相互作用，以及两者之间是否存在固有的权衡，这是一个紧迫的研究问题。

**Method:** 本研究首先在相同条件下基准测试了三种偏见缓解策略：监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL），以建立它们的优缺点。在此基础上，研究人员在每种范式内改变以去偏见为重点和以推理为中心的样本比例，以绘制推理与偏见之间的权衡图。

**Result:** 研究发现了一个持续的最佳点：通过强化学习以大约1:4的去偏见与推理样本混合比例进行训练，可以将刻板印象分数降低10%，同时保留模型原始推理准确性的88%。

**Conclusion:** 通过强化学习以特定比例（约1:4）的去偏见与推理样本进行训练，可以有效平衡多模态大语言模型中的公平性和能力，为解决推理能力提升与社会偏见之间的权衡提供了具体指导。

> **ai_Abstract:** 本研究探讨了多模态大语言模型（MLLMs）在提升推理能力时面临的社会偏见问题。文章首先对比评估了监督微调、知识蒸馏和强化学习三种偏见缓解策略。在此基础上，通过调整去偏见和推理样本的比例，揭示了推理能力与社会偏见之间的权衡关系。研究发现，采用强化学习并以1:4的去偏见与推理样本比例进行训练，能在降低10%刻板印象得分的同时，保持88%的原始推理准确性，为在MLLMs中平衡公平性和能力提供了实用指导。

> **摘要翻译:** 多模态大语言模型（MLLMs）已在广泛的任务和模态中取得了最先进的成果。为了进一步提升其推理能力，最近的研究探索了高级提示方案和后训练微调。尽管这些技术提高了逻辑准确性，但它们常常使模型的输出带有明显的社会偏见。因此，弄清推理能力的提升如何与偏见缓解相互作用——以及这两个目标是否固有地存在权衡——仍然是一个开放且紧迫的研究问题。我们的研究首先在相同条件下基准测试了三种偏见缓解策略——监督微调（SFT）、知识蒸馏（KD）和基于规则的强化学习（RL）——建立了它们的基线优势和劣势。在此结果的基础上，我们改变每种范式中以去偏见为重点和以推理为中心的样本比例，以绘制推理与偏见之间的权衡图。我们的扫描揭示了一个持续的最佳点：通过强化学习以大约1:4的混合比例进行训练，可以将刻板印象分数降低10%，同时保留模型原始推理准确性的88%，为平衡多模态大语言模型中的公平性和能力提供了具体指导。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [917] [Moravec's Paradox: Towards an Auditory Turing Test](https://arxiv.org/abs/2507.23091)
> *莫拉维克悖论：迈向听觉图灵测试*

*David Noever, Forrest McKee* | **Category: cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 听觉图灵测试, 莫拉维克悖论, AI听觉, 音频理解, 人机差距

**Comment:** 

> **TL;DR:** 当前AI系统在人类轻松完成的听觉任务上表现灾难性失败。本研究引入了一个听觉图灵测试，评估了最先进的音频模型，发现其准确率极低（低于7%），远低于人类表现（52%），揭示了AI在处理复杂听觉场景时的根本性缺陷，并提出未来需要新的方法。

**AI_Comments:** 这篇论文的创新之处在于引入了一个全新的“听觉图灵测试”基准，系统性地量化并揭示了当前最先进AI模型在复杂听觉场景理解上的严重缺陷。它不仅指出了问题，还深入分析了AI失败的根本原因，即缺乏类似人类的选择性注意、噪声鲁棒性和上下文适应能力。这对于推动多模态AI研究，特别是听觉智能领域的发展具有重要意义，指明了未来研究的方向。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在证明当前AI系统在人类能够轻松完成的听觉任务上表现出灾难性的失败。受到莫拉维克悖论的启发，即人类容易的任务对机器而言往往很难，反之亦然，研究希望量化人机听觉差距并理解失败原因。

**Method:** 研究引入了一个包含917个挑战的听觉图灵测试，涵盖七个类别：重叠语音、噪音中的语音、时间失真、空间音频、咖啡馆噪音、电话失真和感知错觉。研究评估了包括GPT-4音频能力和OpenAI Whisper在内的最先进音频模型。

**Result:** 评估结果显示，当前AI系统在听觉图灵测试中表现出惊人的失败率，超过93%。即使是表现最好的模型，准确率也仅为6.9%，而人类在相同任务上的成功率为52%，是AI的7.5倍。这些结果揭示了AI系统在处理复杂听觉场景时存在聚焦失败，特别是在选择性注意、噪声鲁棒性和上下文适应方面。

**Conclusion:** 本基准测试不仅量化了人机听觉差距，还深入探讨了这些失败发生的原因，表明当前架构缺乏类人听觉场景分析的基本机制。研究强调需要新的方法，将选择性注意、基于物理的音频理解和上下文感知整合到多模态AI系统中，以衡量机器听觉达到人类水平的进展。

> **ai_Abstract:** 本研究揭示当前AI系统在复杂听觉任务上与人类存在巨大差距，其表现远低于人类水平。通过引入一个包含917项挑战的听觉图灵测试，研究评估了GPT-4和Whisper等先进音频模型，发现其准确率不足7%，而人类成功率高达52%。这表明AI在选择性注意、噪声鲁棒性和上下文适应方面存在根本性缺陷。该工作不仅量化了人机听觉差异，也为未来开发更类人听觉AI指明了方向，强调需整合选择性注意和基于物理的理解。

> **摘要翻译:** 这项研究工作表明，当前的人工智能系统在人类轻松完成的听觉任务上表现出灾难性的失败。受莫拉维克悖论（即人类简单的任务对机器来说往往很难，反之亦然）的启发，我们引入了一个听觉图灵测试，包含七个类别的917个挑战：重叠语音、噪音中的语音、时间失真、空间音频、咖啡馆噪音、电话失真和感知错觉。我们对包括GPT-4音频能力和OpenAI Whisper在内的最先进音频模型的评估显示，其失败率惊人地超过93%，即使是表现最好的模型，在人类以高出7.5倍的成功率（52%）解决的任务上，也仅达到6.9%的准确率。这些结果揭示了人工智能系统在处理复杂听觉场景时存在的聚焦失败，特别是在选择性注意、噪声鲁棒性和上下文适应方面。我们的基准测试不仅量化了人机听觉差距，还提供了关于这些失败原因的见解，表明当前的架构缺乏类人听觉场景分析的基本机制。音频CAPTCHA的传统设计突出了人类进化出的常见过滤器，但机器在多模态语言模型中未能选择这些过滤器。这项工作建立了一个诊断框架，用于衡量机器听觉达到人类水平的进展，并强调需要将选择性注意、基于物理的音频理解和上下文感知整合到多模态人工智能系统中的新方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [921] [Argumentatively Coherent Judgmental Forecasting](https://arxiv.org/abs/2507.23163)
> *论证连贯的判断式预测*

*Deniz Gorur, Antonio Rago, Francesca Toni* | **Category: cs.AI, I.2.7** | **Updated: 2025-07-30**

**Keywords:** 判断式预测, 论证连贯性, 大型语言模型, 预测准确性, 意见过滤

**Comment:** 17 pages, 18 figures, ECAI 2025

> **TL;DR:** 本文定义并评估了判断式预测中的“论证连贯性”概念，结果表明，过滤掉不连贯的预测可以提高人类和大型语言模型（LLM）的预测准确性，但用户通常不符合这一连贯性，因此需要在基于论证的判断式预测中集成不连贯意见的过滤机制。

**AI_Comments:** 这篇论文引入了判断式预测中“论证连贯性”的新颖概念，鉴于大型语言模型在预测中的日益广泛应用，这一概念尤为重要。研究发现过滤不连贯的预测能提高准确性，这对实际应用具有重要意义。同时，指出连贯性的实用性与用户自然行为之间存在的差距，也为未来设计更好的人机协作预测系统指明了关键挑战和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 在判断式预测中，当意见形成围绕预测的论证结构时，研究其论证属性是很有用的。本文旨在倡导并正式定义一种“论证连贯性”的属性，即预测者的推理应与其预测保持一致，以期提高预测准确性。

**Method:** 本文正式定义了“论证连贯性”这一属性。随后进行了三项评估：首先，评估了强制执行连贯性对人类预测者和大型语言模型（LLM）预测者的影响；其次，通过众包用户实验，考察了用户是否普遍符合这种连贯性属性。

**Result:** 研究结果表明，在人类和LLM预测中，过滤掉不连贯的预测能够持续提高预测准确性，这支持了连贯性在实践中的价值。然而，尽管论证连贯性具有明显的直观性和实用性，但用户通常不符合这一连贯性属性。

**Conclusion:** 论证连贯性在提高人类和LLM判断式预测的准确性方面具有实际价值。鉴于用户普遍不符合这一连贯性属性，因此需要在基于论证的判断式预测中集成机制，以便在获得群体预测之前过滤掉不连贯的意见。

> **ai_Abstract:** 本文引入并正式定义了判断式预测中的“论证连贯性”概念，该属性要求预测者的推理与其预测保持一致。通过评估，研究表明，强制执行连贯性显著提高了人类和大型语言模型（LLM）预测的准确性。然而，众包实验揭示，用户并非天然地遵循这种连贯性。因此，论文强调在基于论证的群体预测中，集成过滤不连贯意见的机制是必要的，以提高预测质量。

> **摘要翻译:** 判断式预测采用人类意见对未来事件进行预测，而非像定量预测那样仅依赖历史数据。当这些意见围绕预测形成论证结构时，从论证角度研究预测的属性是有用的。在本文中，我们倡导并正式定义了论证连贯性这一属性，其本质要求预测者的推理与其预测保持一致。随后，我们对连贯性概念进行了三项评估。首先，我们评估了强制执行连贯性对人类预测者以及基于大型语言模型（LLM）的预测者的影响，考虑到LLM最近已显示出与人类预测者具有竞争力。在这两种情况下，我们都表明，过滤掉不连贯的预测可以持续提高预测准确性，支持了连贯性在人类和LLM预测中的实用价值。然后，通过众包用户实验，我们发现，尽管其具有明显的直观性和实用性，用户通常并不符合这一连贯性属性。这表明，在基于论证的判断式预测中，需要在获得群体预测之前集成机制来过滤掉不连贯的意见。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [922] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
> *社交媒体中可解释AI推荐的上下文感知可视化：一项用户对齐解释的愿景*

*Banan Alkhateeb, Ellis Solaiman* | **Category: cs.AI, cs.HC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 可解释AI, 社交媒体, 上下文感知, 可视化, 用户对齐解释

**Comment:** 

> **TL;DR:** 该愿景论文提出了一种上下文感知和用户分段的可视化解释系统，用于社交媒体中的AI推荐，旨在通过适应用户需求和上下文（包括专家和普通用户）来提高解释的理解度和信任度。

**AI_Comments:** 该论文提出了一种具有前瞻性的解决方案，通过将可解释AI（XAI）与用户体验（UX）紧密结合，特别是在社交媒体这一复杂场景中。其创新点在于强调“上下文感知”和“用户分段”，并首次在一个框架内实现了解释风格和粒度的自适应。这对于提升AI推荐的透明度和用户信任度具有重要意义，尤其是在应对不同用户群体的多样化需求方面。

<details>
  <summary>Details</summary>

**Motivation:** 当前社交媒体平台上的AI推荐因用户不理解其背后原因而价值降低。现有解释普遍且缺乏与用户特定需求的一致性，导致用户体验不佳和信任度下降。

**Method:** 提出了一种用户分段和上下文感知的解释层，通过一个具有多种解释方法的可视化解释系统来实现。该系统根据用户需求和上下文，以不同的可视化形式展示解释，包括技术细节版本（针对AI专家）和简化版本（针对普通用户）。该框架首次在一个单一流程中联合适应解释风格（视觉 vs. 数字）和粒度（专家 vs. 普通用户）。

**Result:** Not mentioned in abstract

**Conclusion:** 该论文提出了一种新颖的框架，首次在一个单一流程中联合适应解释风格（视觉与数字）和解释粒度（专家与普通用户），以提高社交媒体中AI推荐的可解释性。

> **ai_Abstract:** 这篇愿景论文旨在解决社交媒体中AI推荐解释性不足的问题，指出现有解释未能与用户需求对齐。为此，论文提出了一种用户分段和上下文感知的可视化解释系统。该系统能够根据不同的用户需求和上下文，提供多种可视化形式的解释，包括针对AI专家的详细版本和针对普通用户的简化版本。其核心创新在于首次在一个单一流程中整合并自适应解释风格（视觉/数字）和粒度（专家/普通用户），旨在提升用户对AI推荐的理解、决策和信任。

> **摘要翻译:** 当今社交媒体平台致力于通过AI推荐来改善用户体验，然而，由于用户不理解其背后的原因，这些推荐的价值便会消失。这个问题出现的原因是社交媒体中的可解释性普遍且缺乏与用户特定需求的一致性。在这篇愿景论文中，我们通过提出一个具有多种解释方法的可视化解释系统，概述了一个用户分段和上下文感知的解释层。所提出的系统以用户需求和上下文的多样性为框架，以不同的可视化形式展示解释，包括面向AI专家的技术详细版本和面向普通用户的简化版本。我们的框架是第一个在单一流程中联合适应解释风格（视觉与数字）和粒度（专家与普通用户）的。一项针对30名X用户的公开试点将验证其对决策和信任的影响。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [932] [Tractable Responsibility Measures for Ontology-Mediated Query Answering](https://arxiv.org/abs/2507.23191)
> *可处理的本体中介查询回答责任度量*

*Meghyn Bienvenu, Diego Figueira, Pierre Lafourcade* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** 责任度量, 本体中介查询回答, Shapley值, 复杂度分析, 可处理性

**Comment:** Long version of a paper to appear at KR 2025, which contains further
  proof details in the appendix

> **TL;DR:** 本文研究了本体中介查询回答中Shapley值责任度量（WSMS）的计算复杂度，识别了可处理和不可处理的情况。

**AI_Comments:** 本文的创新之处在于首次系统地分析了本体中介查询回答中Shapley值责任度量（WSMS）的计算复杂度，明确了其在不同本体语言和查询类型下的可处理性边界。这对于理解和应用这些解释性度量具有重要意义，尤其是在需要可解释AI的背景下。研究结果既指出了计算的难点，也提供了在特定条件下的积极解决方案，具有重要的理论和实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 最近关于解释查询答案的定量方法使用责任度量来量化事实对获得给定答案的贡献，但计算这些度量的复杂性尚不清楚，尤其是在本体中介查询回答的背景下。

**Method:** 本文研究了本体中介查询回答背景下计算责任分数（特别是基于Shapley值的WSMS度量）的复杂度。通过利用数据库设置中的结果和仔细分析，他们研究了数据复杂度和组合复杂度，并识别了结构受限的合取查询类别。

**Result:** 对于一阶可重写类的本体中介查询，WSMS度量具有多项式数据复杂度。当本体语言可以编码可达性查询时，问题变为“shP”-hard。如果本体语言支持合取，即使是原子查询也存在不可处理性。对于“行为良好”的合取查询的并集，即使没有本体，也存在不可处理性。对于常见的DL-Lite方言，通过仔细分析，识别出允许可处理WSMS计算的结构受限合取查询类别。

**Conclusion:** 本文详细分析了本体中介查询回答中基于Shapley值的责任度量（WSMS）的计算复杂度，揭示了其可处理性边界，并为某些DL-Lite方言下的特定查询类型提供了积极的可处理性结果。

> **ai_Abstract:** 本文深入研究了在本体中介查询回答（OMQA）环境中计算基于Shapley值的责任度量（WSMS）的复杂度。研究结果表明，对于一阶可重写OMQ，WSMS具有多项式数据复杂度，但在本体语言支持可达性查询时则变得难以处理。此外，在组合复杂度方面，即使是原子查询在本体支持合取时也可能难以处理。然而，研究也为DL-Lite方言中的特定结构受限合取查询类别找到了可处理的计算方法，从而明确了WSMS在OMQA中的可处理性边界。

> **摘要翻译:** 最近关于解释查询答案的定量方法采用责任度量来给事实分配分数，以量化它们对获得给定答案的各自贡献。在本文中，我们研究了本体中介查询回答背景下计算此类责任分数的复杂度，重点关注最近引入的一系列基于Shapley值的责任度量，这些度量定义为最小支持的加权和（WSMS）。通过利用数据库设置中的结果，我们可以表明，对于一阶可重写类的本体中介查询，此类度量具有多项式数据复杂度，而当本体语言可以编码可达性查询（通过像 $\exists R. A \sqsubseteq A$ 这样的公理）时，问题变得“shP”-hard。为了更好地理解可处理性边界，我们接下来探讨了WSMS计算的组合复杂度。我们证明，如果本体语言支持合取，即使是原子查询也已经存在不可处理性，以及对于“行为良好”的合取查询的并集，即使没有本体也存在不可处理性。相比之下，我们的研究为常见的DL-Lite方言带来了积极的结果：通过仔细分析，我们识别出结构受限的合取查询类别（直观上不允许查询原子之间发生不良交互），这些类别允许可处理的WSMS计算。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [941] [Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification](https://arxiv.org/abs/2507.23197)
> *解决方案感知与全局ReLU选择：部分MILP在DNN验证中反击*

*Yuke Liao, Blaise Genest, Kuldeep Meel, Shaan Aryaman* | **Category: cs.AI** | **Updated: 2025-07-31**

**Keywords:** DNN验证, ReLU选择, 部分MILP, 混合整数线性规划, 解决方案感知

**Comment:** 

> **TL;DR:** 提出一种新的解决方案感知ReLU选择方法（SAS）和混合MILP框架，用于DNN验证。SAS能更高效地选择关键ReLU，与现有方法相比，二进制变量数量减少6倍，并显著降低未判定实例数，同时保持合理运行时间。

**AI_Comments:** 这篇论文的创新点在于提出了“解决方案感知ReLU评分”（SAS）方法，它通过智能地选择关键ReLU变量来优化部分MILP的效率。这种方法显著减少了所需的二元变量数量，从而降低了计算成本，是DNN验证领域的一个重要进展。此外，结合α,β-CROWN的“混合MILP”框架展示了实际应用中的高效性，使其成为解决大规模DNN验证问题的有力工具。该研究的贡献在于提供了一种更实用、可扩展的DNN验证解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 为了处理深度神经网络（DNN）验证中的复杂实例，现有方法在选择少量但重要的ReLU变量方面表现不佳，导致子优化。

**Method:** 采用分而治之的方法，通过多次小型“部分MILP”调用而非少数复杂BaB调用来分解复杂性。提出一种新颖的“解决方案感知ReLU评分”（SAS）方法来选择需要用二元变量处理的关键ReLU。将BaB-SR和BaB-FSB分支函数调整为“全局ReLU评分”（GS）函数。对SAS和GS进行理论和实验比较。在“混合MILP”框架中实现，该框架首先使用短时限的α,β-CROWN解决较简单的实例，然后调用部分MILP。

**Result:** SAS在选择使用二元变量打开的变量集方面效率更高。与现有尝试相比，SAS将二元变量的数量减少了约6倍，同时保持了相同的精度水平。在“混合MILP”中实现后，该验证器非常准确且高效。将未判定实例的数量降低了高达40%，达到较低水平（8-15%）。即使对于拥有200万参数的相当大的CNN，也能保持合理的运行时间（平均每个实例46秒-417秒）。

**Conclusion:** 通过引入解决方案感知ReLU评分（SAS）和混合MILP框架，该方法显著提高了深度神经网络验证的效率和准确性，减少了未判定实例的数量，同时保持了可接受的运行时间。

> **ai_Abstract:** 本研究提出了一种改进深度神经网络（DNN）验证效率和准确性的方法。通过采用分而治之的策略，该方法利用多个小型部分混合整数线性规划（MILP）调用。核心创新在于引入了“解决方案感知ReLU评分”（SAS）来高效选择关键的ReLU变量，这比传统的全局ReLU评分方法更有效。实验结果表明，SAS能够将验证所需的二元变量数量减少六倍，同时保持验证精度。结合α,β-CROWN预处理的“混合MILP”框架进一步提升了性能，将未判定实例的比例显著降低至8-15%，且在处理大型卷积神经网络时也能保持合理的运行时间，从而提供了一个既准确又高效的DNN验证器。

> **摘要翻译:** 为了处理复杂实例，我们重新审视了一种分而治之的方法来分解复杂性：我们依赖于许多小型“部分”MILP调用，而不是少数复杂的BaB调用。关键步骤是选择极少数但非常重要的ReLU，并使用（昂贵的）二元变量进行处理。之前的尝试在这方面是次优的。为了选择这些重要的ReLU变量，我们提出了一种新颖的“解决方案感知”ReLU评分（SAS），并调整了BaB-SR和BaB-FSB分支函数作为“全局”ReLU评分（GS）函数。我们对它们进行了理论和实验比较，SAS在选择一组要用二元变量打开的变量方面效率更高。与之前的尝试相比，SAS将二元变量的数量减少了约6倍，同时保持了相同的精度水平。在“混合MILP”中实现，首先使用短时限的α,β-CROWN解决较简单的实例，然后调用部分MILP，产生了一个非常准确且高效的验证器，将未判定实例的数量降低了高达40%至低水平（8-15%），同时保持了合理的运行时间（平均每个实例46秒-417秒），即使对于拥有200万参数的相当大的CNN也是如此。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [931] [E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer](https://arxiv.org/abs/2508.00475)
> *E2ATST：一种用于训练脉冲Transformer的时空优化节能架构*

*Yunhao Ma, Yanyu Lin, Mingjing Li, Puli Quan, Chenlin Zhou, Wenyue Zhang, Zhiwei Zhong, Wanyi Jia, Xueke Zhu, Qingyan Meng, Huihui Zhou, Fengwei An* | **Category: cs.AR, cs.NE** | **Updated: 2025-08-01**

**Keywords:** 摘要中未提及。

**Comment:** 

> **TL;DR:** 摘要中仅包含作者单位信息，未提供论文内容，因此无法生成TLDR。

**AI_Comments:** 由于摘要中未提供论文的具体内容，无法对其创新性、重要性或局限性进行评论。

<details>
  <summary>Details</summary>

**Motivation:** 摘要中未提及。

**Method:** 摘要中未提及。

**Result:** 摘要中未提及。

**Conclusion:** 摘要中未提及。

> **ai_Abstract:** 由于摘要中仅包含作者单位信息，未提供论文的具体内容，因此无法生成新的总结。

> **摘要翻译:** 摘要中仅包含作者单位信息，未提供论文内容。具体单位如下：(1) 鹏城实验室, (2) 南方科技大学, (3) 中国科学院深圳先进技术研究院, (4) 中国科学院大学。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [543] [Exponential Lower Bounds on the Size of ResLin Proofs of Nearly Quadratic Depth](https://arxiv.org/abs/2507.23008)
> *指数级下界：关于接近二次深度ResLin证明的尺寸*

*Sreejata Kishor Bhattacharya, Arkadev Chattopadhyay* | **Category: cs.CC** | **Updated: 2025-07-30**

**Keywords:** Res($\oplus$)证明, 指数下界, 证明复杂性, Tseitin公式, 小工具

**Comment:** 35 pages

> **TL;DR:** 本文对接近二次深度的异或消解（Res($\oplus$)）证明的尺寸给出了指数级下界，显著改进了现有结果。

**AI_Comments:** 这项工作显著推进了对异或消解（Res($\oplus$)）证明复杂性的理解，特别是对于更深度的证明，解决了长期存在的开放问题。引入新型小工具以及应用“欺骗安全仿射空间”的概念是关键创新。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作对特定深度的异或消解（Res($\oplus$)）证明缺乏超多项式下界，尤其是对深度为$\Omega(N^{1+\epsilon})$的证明，这是一个有待解决的问题。

**Method:** 本文使用Tseitin公式在扩展图上，并结合一种新型的小相关性小工具进行提升。关键在于证明使用此类小工具提升的任意分布可以欺骗“安全”仿射空间。

**Result:** 本文证明了当异或消解（Res($\oplus$)）证明的深度为$O(N^{2-\epsilon})$时，其尺寸下界为$\text{exp}(\tilde{\Omega}}(N^{\epsilon}))$，这相对于之前的$O(N\log N)$深度结果是显著改进。

**Conclusion:** 本文显著改进了对接近二次深度的异或消解（Res($\oplus$)）证明尺寸下界的证明。

> **ai_Abstract:** 本文解决了对具有显著深度的异或消解（Res($\oplus$)）证明证明超多项式下界的开放问题。通过证明当Res($\oplus$)证明的深度为$O(N^{2-\epsilon})$时，其尺寸存在$\text{exp}(\tilde{\Omega}}(N^{\epsilon}))$的指数级下界，本文取得了显著进展。该方法利用扩展图上的Tseitin公式，并结合与奇偶校验具有小相关性的新型小工具进行提升，其核心思想源于欺骗安全仿射空间的概念。

> **摘要翻译:** Itsykson和Sokolov将异或消解（$\text{Res}(\oplus)$）识别为$\text{AC}^0[2]$-Frege的一个自然而简单的片段，对于它，目前还没有已知的超多项式证明尺寸下界。基于最近的一系列工作，Efremenko和Itsykson证明了深度上限为$O(N\log N)$的$\text{Res}(\oplus)$证明的尺寸下界形式为$\text{exp}(N^{\Omega(1)})$，其中$N$是不满足合取范式（CNF）公式的变量数量。他们使用的困难公式是Tseitin在适当扩展图上的应用，并通过一个$2$-stifling小工具进行提升。他们提出了一个自然的问题，即对深度为$\Omega(N^{1+\epsilon})$（对于任何常数$\epsilon > 0$）的证明尺寸证明超多项式下界。
我们提供了一个显著的改进，证明了尺寸下界形式为$\text{exp}(\tilde{\Omega}}(N^{\epsilon}))$，只要$\text{Res}(\oplus)$证明的深度为$O(N^{2-\epsilon})$（对于每个$\epsilon > 0$）。我们使用的困难公式仍然是扩展图上的Tseitin公式，但使用了不同类型的小工具进行提升。我们的小工具需要与所有奇偶校验具有小相关性。
我们工作中一个重要的组成部分是表明使用此类小工具提升的任意分布可以欺骗“安全”仿射空间，这个思想源于Bhattacharya、Chattopadhyay和Dvorak的早期工作。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [557] [On a better complexity upper bound of Ward-Szabo theorem](https://arxiv.org/abs/2507.23345)
> *关于Ward-Szabo定理更优复杂度上界的研究*

*Takashi Ishizuka* | **Category: cs.CC, cs.DM** | **Updated: 2025-07-31**

**Keywords:** Ward-Szabó定理, 复杂度上界, TFNP, PPP, 双色三角形

**Comment:** 

> **TL;DR:** 本文证明了Ward-Szabó问题属于复杂度类PPP，从而改进了其复杂度上界。

**AI_Comments:** 这篇论文通过将Ward-Szabó问题精确地归类到PPP，解决了该问题在TFNP中具体子类归属的开放性问题。这一成果对于理解Ward-Szabó问题的计算复杂性具有重要意义，因为它提供了一个更紧密的上界，并将其与基于鸽巢原理的问题联系起来，这在理论计算机科学中是一个重要的进展。

<details>
  <summary>Details</summary>

**Motivation:** Ward-Szabó问题被证明是PWPP-hard且属于TFNP类，但其具体属于TFNP的哪个子类仍是一个未解决的问题。

**Method:** 通过数学证明，将Ward-Szabó问题归入复杂度类PPP。

**Result:** 证明了Ward-Szabó问题属于复杂度类PPP。

**Conclusion:** Ward-Szabó问题被成功地归类到PPP，这提供了一个更精确的复杂度上界。

> **ai_Abstract:** 本文旨在改进Ward-Szabó问题的复杂度上界。Ward-Szabó是一个关于在特定着色完全图中寻找双色三角形的完全搜索问题，此前已被证明是PWPP-hard并属于TFNP类。针对其在TFNP中具体子类归属的开放问题，本研究通过证明Ward-Szabó问题属于复杂度类PPP，成功地提高了其复杂度上界。PPP是TFNP的一个子类，其解的存在性由鸽巢原理保证。

> **摘要翻译:** Ward和Szabó [WS94] 已经证明了一个具有 $N^2$ 个节点且边用 $N$ 种颜色着色并至少包含两种颜色的完全图包含一个双色三角形。这一事实引出了一个完全搜索问题：给定一个用至少两种颜色和至多 $N$ 种颜色对一个具有 $N^2$ 个节点的完全图进行边着色，找到一个双色三角形。Bourneuf、Folwarczn´y、Hubácek、Rosen和Schwartzbach [Bou+23] 已经证明了这样一个被称为Ward-Szabó的完全搜索问题是PWPP-hard的，并且属于TFNP类，TFNP是一类完全搜索问题，其中每个候选解的正确性都可以被有效验证。然而，Ward-Szabó属于哪个TFNP子类仍然是一个开放问题。本文将改进Ward-Szabó的复杂度上界。我们证明Ward-Szabó属于复杂度类PPP，PPP是TFNP的一个子类，其中鸽巢原理保证了解的存在。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [578] [The Complexity of Logarithmic Space Bounded Counting Classes](https://arxiv.org/abs/2507.23563)
> *对数空间有界计数类的复杂性*

*T. C. Vijayaraghavan* | **Category: cs.CC** | **Updated: 2025-07-31**

**Keywords:** 对数空间,复杂性类,计数类,非确定性图灵机,计算复杂性

**Comment:** 

> **TL;DR:** 这篇专著研究了对数空间有界非确定性图灵机定义的复杂性类，并证明了该领域的重要计算复杂性结果，旨在作为一本综合性教科书。

**AI_Comments:** 这篇专著并非提出新的研究成果，而是一本旨在系统梳理和呈现对数空间有界计数类复杂性领域现有重要定理和概念的综合性教科书。它的价值在于其作为教育和参考资料的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 这篇专著旨在成为一本关于对数空间有界计数类复杂性主题的综合性教科书，系统地研究并呈现该领域的显著成果。

**Method:** 该专著通过研究使用$O(\log n)$-空间有界非确定性图灵机定义的复杂性类，并证明计算复杂性在该主题中的显著结果，例如Immerman-Szelepcsényi定理、隔离引理以及Mahajan-Vinay关于行列式的定理。

**Result:** 专著中涵盖并证明了计算复杂性在该主题中的显著结果，包括Immerman-Szelepcsényi定理、隔离引理、Mahajan-Vinay关于行列式的定理以及这些重要结果的许多推论。

**Conclusion:** 这篇手稿旨在成为一本关于对数空间有界计数类复杂性主题的综合性教科书。

> **ai_Abstract:** 这篇专著深入探讨了由对数空间有界非确定性图灵机定义的复杂性类，旨在作为该领域的综合性教科书。文中详细阐述并证明了计算复杂性中的重要理论，包括Immerman-Szelepcsényi定理、隔离引理以及Mahajan-Vinay关于行列式的定理及其众多推论。

> **摘要翻译:** 在这本专著中，我们研究了使用$O(\log n)$-空间有界非确定性图灵机定义的复杂性类。我们证明了计算复杂性在该主题中的显著结果，例如Immerman-Szelepcsényi定理、隔离引理、Mahajan-Vinay关于行列式的定理以及这些非常重要结果的许多推论。这份手稿旨在成为一本关于对数空间有界计数类复杂性主题的综合性教科书。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [404] [LEO: An Open-Source Platform for Linking OMERO with Lab Notebooks and Heterogeneous Metadata Sources](https://arxiv.org/abs/2508.00654)
> *LEO：一个连接OMERO与实验室笔记本和异构元数据源的开源平台*

*Rodrigo Escobar Díaz Guerrero, Jamile Mohammad Jafari, Tobias Meyer-Zedler, Michael Schmitt, Juergen Popp, Thomas Bocklitz* | **Category: cs.CE, cs.SE** | **Updated: 2025-08-01**

**Keywords:** 数据整合, 显微镜研究, FAIR原则, OMERO, 电子实验记录本, 开源平台

**Comment:** 

> **TL;DR:** LEO是一个开源的、基于网络的平台，旨在解决显微镜研究中异构数据整合的挑战，通过插件架构连接OMERO、电子实验记录本和其他数据源，以实现数据管理中的FAIR原则。

**AI_Comments:** LEO的创新之处在于其插件式架构，这使其能够灵活地集成多种异构数据源，而非仅限于OMERO和ELNs。这种设计显著增强了平台的可扩展性和适应性，对于促进跨学科显微镜研究中的数据互操作性和可重用性具有重要意义。它直接解决了数据管理中FAIR原则的实现难题。

<details>
  <summary>Details</summary>

**Motivation:** 显微镜研究领域中，管理和整合存储在不同平台上的大量数据是一个主要挑战。生物图像、实验记录和光谱信息等数据类型通常保存在独立的存储库中，遵循不同的管理标准。尽管需要将这些数据源在研究生命周期中进行链接以符合FAIR原则，但目前缺乏能够有效整合和链接来自异构来源数据的工具。

**Method:** 本文提出了LEO（将电子实验记录本与OMERO链接），一个基于网络的平台，旨在创建和管理分布式数据系统之间的链接。LEO最初开发用于链接电子实验记录本（ELNs）和OMERO之间的对象，但其功能已通过基于插件的架构得到扩展，允许集成额外的数据源。

**Result:** LEO平台提供了一个可扩展且灵活的解决方案，适用于广泛的显微镜研究工作流程，有效解决了缺乏工具来整合和链接异构数据源的问题。

**Conclusion:** LEO平台通过其可扩展的插件架构，成功地提供了一个连接OMERO、电子实验记录本和其他异构数据源的解决方案，从而促进了显微镜研究领域中数据管理FAIR原则的实现。

> **ai_Abstract:** LEO是一个开源的、基于网络的平台，旨在解决显微镜研究中异构数据整合的挑战。它通过插件架构连接OMERO、电子实验记录本（ELNs）以及其他多种数据源，从而实现数据在研究生命周期中的链接，以符合FAIR原则。LEO提供了可扩展和灵活的解决方案，有效弥补了当前缺乏此类集成工具的空白。

> **摘要翻译:** 在显微镜研究的跨学科领域中，管理和整合存储在不同平台上的大量数据仍然是一个重大挑战。生物图像、实验记录和光谱信息等数据类型通常保存在独立的存储库中，每个存储库都遵循不同的管理标准。然而，在整个研究生命周期中链接这些数据源对于符合数据管理的FAIR原则（可查找性、可访问性、互操作性和可重用性）至关重要。尽管有此需求，但目前缺乏能够有效整合和链接来自异构来源数据的工具。为了弥补这一空白，我们提出了LEO（将电子实验记录本与OMERO链接），一个基于网络的平台，旨在创建和管理分布式数据系统之间的链接。LEO最初开发用于链接电子实验记录本（ELNs）和OMERO之间的对象，但其功能已通过基于插件的架构得到扩展，允许集成额外的数据源。这种可扩展性使LEO成为适用于广泛显微镜研究工作流程的可扩展和灵活的解决方案。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [416] [A Practical Finite Element Approach for Simulating Dynamic Crack Growth in Cu/Ultra Low-k Interconnect Structures](https://arxiv.org/abs/2508.00193)
> *一种用于模拟铜/超低k互连结构中动态裂纹扩展的实用有限元方法*

*Yuxi Xie, Ethan J. Wu, Lu Xu, Jimmy Perez, Shaofan Li* | **Category: cs.CE, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 动态裂纹扩展, 有限元方法, 裂纹单元法, ES-FEM, 铜/超低k

**Comment:** 

> **TL;DR:** 本文提出了一种实用的有限元方法——裂纹单元法（CEM），用于模拟二维结构中的动态裂纹扩展。该方法采用基于ES-FEM的单元分裂算法，可有效捕获裂纹扩展并减少畸形单元，同时开发了相应的能量释放率公式。CEM已通过基准问题验证，并成功应用于铜/超低k互连结构。

**AI_Comments:** 本文的创新之处在于提出了裂纹单元法（CEM），该方法集成了基于ES-FEM的单元分裂算法，通过减轻动态裂纹扩展模拟过程中畸形单元的形成，提高了精度和计算效率。其在铜/超低k互连结构上的实际应用凸显了其对微电子可靠性的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在提出一种实用的有限元建模策略，用于模拟二维结构中的动态裂纹扩展，并解决现有方法中可能损害数值精度和计算性能的畸形单元形成问题。

**Method:** 本研究提出了裂纹单元法（CEM）。该方法采用基于边光滑有限元法（ES-FEM）的单元分裂算法，以捕获单元级裂纹扩展，同时减少畸形单元的形成。此外，还基于分裂单元的演变拓扑结构开发了裂纹能量释放率公式。

**Result:** 所提出的方法通过一系列经典基准问题进行了验证，证明了其在处理动态断裂情景方面的准确性和鲁棒性。其在涉及图案化铜/超低k互连结构案例研究中的适用性也得到了体现。

**Conclusion:** 裂纹单元法（CEM）为模拟动态裂纹扩展提供了一种准确、鲁棒且实用的有限元方法，能够有效解决铜/超低k互连等复杂材料结构中的挑战。

> **ai_Abstract:** 本文介绍了一种名为裂纹单元法（CEM）的实用有限元方法，用于模拟二维结构中的动态裂纹扩展。CEM利用基于边光滑有限元法（ES-FEM）的单元分裂算法，能够精确捕获裂纹扩展，同时最大程度地减少网格畸变。该方法还提出了一种新的裂纹能量释放率公式。CEM已通过基准问题验证了其准确性和鲁棒性，并在模拟铜/超低k互连结构中的裂纹扩展方面展现了其效用。

> **摘要翻译:** 这项工作提出了一种实用的有限元建模策略，即裂纹单元法（CEM），用于模拟二维结构中的动态裂纹扩展。该方法采用基于边光滑有限元法（ES-FEM）的单元分裂算法，以捕获单元级的裂纹扩展，同时减少可能损害数值精度和计算性能的畸形单元的形成。还基于分裂单元的演变拓扑结构开发了裂纹能量释放率公式。所提出的方法通过一系列经典基准问题进行了验证，证明了其在处理动态断裂情景方面的准确性和鲁棒性。最后，通过涉及图案化铜/超低k互连结构的案例研究，说明了CEM的适用性。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [548] [Online Fine-Tuning of Carbon Emission Predictions using Real-Time Recurrent Learning for State Space Models](https://arxiv.org/abs/2508.00804)
> *状态空间模型的实时循环学习在线微调碳排放预测*

*Julian Lemmel, Manuel Kranzl, Adam Lamine, Philipp Neubauer, Radu Grosu, Sophie Neubauer* | **Category: cs.CE, cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 状态空间模型, 实时循环学习, 在线微调, 碳排放预测, 嵌入式系统

**Comment:** 6 pages

> **TL;DR:** 本文提出一种使用实时循环学习在线微调状态空间模型预测的方法，在碳排放预测上显著降低了在线推理误差。

**AI_Comments:** 这篇论文的创新点在于解决了状态空间模型在部署后无法在线适应新数据的局限性，通过引入实时循环学习实现了模型的在线微调。这对于需要实时响应和适应动态变化的应用场景（如资源受限的嵌入式系统）具有重要意义。其贡献在于提升了SSMs在实际应用中的灵活性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 状态空间模型（SSMs）虽然高效且具备长程建模能力，但通常离线训练且部署后保持静态，无法适应实时数据变化。

**Method:** 本文引入了一种新的方法，利用实时循环学习在推理时在线微调结构化状态空间模型（SSMs）的预测，通过连续更新模型参数来响应传入数据。该方法针对线性循环单元SSMs，并使用小型汽车嵌入式硬件收集的碳排放数据集进行评估。

**Result:** 实验结果表明，该方法在推理过程中持续降低了在线预测误差。

**Conclusion:** 该方法在动态、资源受限的环境中具有应用潜力，能够实现SSMs的在线自适应。

> **ai_Abstract:** 本文提出一种新颖的在线自适应方法，通过实时循环学习在推理阶段微调状态空间模型（SSMs）的预测。针对SSMs离线训练且部署后静态的局限性，该方法实现了模型参数的持续在线更新以适应新数据。在针对线性循环单元SSMs的碳排放预测任务上，实验证明该方法有效降低了在线预测误差，展现了其在动态、资源受限环境中的实用性。

> **摘要翻译:** 本文介绍了一种在推理时使用实时循环学习对结构化状态空间模型（SSMs）预测进行微调的新方法。尽管SSMs以其高效和长程建模能力而闻名，但它们通常离线训练并在部署期间保持静态。我们的方法通过连续更新模型参数以响应传入数据来实现在线自适应。我们使用从嵌入式汽车硬件收集的小型碳排放数据集，对线性循环单元SSMs评估了我们的方法。实验结果表明，我们的方法在推理过程中持续降低了在线预测误差，展示了其在动态、资源受限环境中的潜力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [564] [Axioms for Model Fidelity Evaluation](https://arxiv.org/abs/2507.23020)
> *模型保真度评估的公理*

*Evan Taylor, Edward Louis, Gregory Mocko* | **Category: cs.CE** | **Updated: 2025-07-30**

**Keywords:** 模型保真度, 数字工程, 评估框架, 公理, 仿真

**Comment:** This is the authors' preprint (submitted version) of a paper accepted
  for ASME IDETC/CIE 2025, edited only to note preprint status. Posted in
  compliance with ASME 's preprint and copyright policy. The final version is
  copyrighted by ASME and will appear in the ASME Digital Collection. The DOI
  will be added once published

> **TL;DR:** 本文提出了七个基本公理，旨在帮助开发未来的模型保真度评估框架，以解决现有定义在实际应用中缺乏严格性导致评估模糊的问题。

**AI_Comments:** 本文通过提出一套公理，为模型保真度这一关键但定义模糊的概念提供了形式化的基础，具有重要的理论和实践意义。它解决了数字工程领域中一个核心的挑战，即如何确保仿真结果的可靠性。这些公理有望成为未来保真度评估方法和工具开发的基石。

<details>
  <summary>Details</summary>

**Motivation:** 数字工程的效用依赖于模拟与现实一致的假设，即模型保真度。然而，尽管该术语被广泛使用，现有的模型保真度定义在实际应用中往往缺乏形式上的严谨性，导致如何评估这种相似性存在模糊性。

**Method:** 本文提出了七个基本公理，旨在帮助开发未来的保真度评估框架。通过一个现有保真度评估框架下的地面车辆模型示例，观察了这些公理的适用性。此外，这些公理被用作未来模型保真度相关工作的参考点。

**Result:** 通过一个地面车辆模型示例，观察了所提出的七个公理在现有保真度评估框架下的适用性。

**Conclusion:** 这些公理有助于解决模型保真度评估中缺乏形式严谨性的问题，并为未来保真度评估框架的开发以及相关研究提供了基础和参考点。

> **ai_Abstract:** 本文针对数字工程中模型保真度评估现有定义缺乏形式严谨性、导致评估模糊的问题，提出了七个基本公理。这些公理旨在为未来的保真度评估框架开发提供指导，并通过一个地面车辆模型示例验证了其适用性，同时为未来的相关研究提供了参考。

> **摘要翻译:** 数字工程改变了设计和开发过程。然而，数字工程的效用根本上取决于模拟提供与现实一致信息的假设。这种关系被描述为模型保真度。尽管该术语被广泛使用，但现有的模型保真度定义在实际应用中往往缺乏形式上的严谨性，这导致如何评估这种相似性存在模糊性。本文提出了七个基本公理，旨在帮助开发未来的保真度评估框架。一个地面车辆模型的例子被用于现有保真度评估框架下，以观察这些公理的适用性。此外，这些公理被用作考虑未来模型保真度相关工作的参考点。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [586] [An Information Bottleneck Asset Pricing Model](https://arxiv.org/abs/2507.23218)
> *一个信息瓶颈资产定价模型*

*Che Sun* | **Category: cs.CE, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 深度神经网络, 资产定价, 信息瓶颈, 互信息, 噪声过滤

**Comment:** 

> **TL;DR:** 本文提出了一种信息瓶颈资产定价模型，通过压缩低信噪比数据来消除冗余信息，保留关键信息，以解决深度神经网络在金融资产定价中容易过拟合噪声的问题。

**AI_Comments:** 该论文创新性地将信息瓶颈原理应用于金融资产定价领域，有效解决了深度学习模型在处理金融数据时易受噪声干扰导致过拟合的关键问题。通过明确的互信息约束来引导信息压缩和特征学习，该模型提供了一种理论上更严谨、实践中更鲁棒的方法来提取金融数据中的有效信号，对于提升金融预测模型的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）在金融资产定价中因其强大的复杂非线性关系建模能力而受到关注。然而，复杂的模型容易过拟合金融数据中的噪声信息，导致性能不佳。

**Method:** 本文提出了一种信息瓶颈资产定价模型。该模型在非线性映射过程中施加互信息约束，具体而言，它逐步减少输入数据与压缩表示之间的互信息，同时增加压缩表示与输出预测之间的互信息。这种设计旨在在不影响最终资产定价的情况下，确保在金融非线性关系建模过程中遗忘无关信息（即数据中的噪声）。

**Result:** 该模型通过信息瓶颈的约束，不仅利用了深度网络的非线性建模能力来捕捉金融数据中复杂的内在关系，而且确保在信息压缩过程中过滤掉噪声信息，从而保留了资产定价的关键信息。

**Conclusion:** 本文提出的信息瓶颈资产定价模型有效地解决了深度神经网络在金融数据中过拟合噪声的问题，通过在信息压缩过程中过滤无关信息，同时保留关键信息，从而提升了模型在资产定价中的性能和鲁棒性。

> **ai_Abstract:** 本文针对深度神经网络在金融资产定价中易过拟合噪声的问题，提出了一种信息瓶颈资产定价模型。该模型通过在非线性映射过程中施加互信息约束，实现对低信噪比数据的压缩，从而有效滤除数据中的冗余和噪声信息，同时保留对资产定价至关重要的关键信息。这种方法结合了深度网络的强大非线性建模能力与信息瓶颈的噪声过滤机制，旨在提高金融资产定价模型的鲁棒性和性能。

> **摘要翻译:** 深度神经网络（DNNs）因其在金融数据中建模复杂非线性关系的强大能力，在金融资产定价中获得了广泛关注。然而，复杂的模型容易过拟合金融数据中的噪声信息，导致性能不佳。为了解决这个问题，我们提出了一种信息瓶颈资产定价模型，该模型通过压缩低信噪比数据来消除冗余信息，并保留资产定价的关键信息。我们的模型在非线性映射过程中施加互信息约束。具体来说，我们逐步减少输入数据与压缩表示之间的互信息，同时增加压缩表示与输出预测之间的互信息。这种设计确保了在金融非线性关系建模过程中，无关信息（本质上是数据中的噪声）被遗忘，而不影响最终的资产定价。通过利用信息瓶颈的约束，我们的模型不仅利用了深度网络的非线性建模能力来捕捉金融数据中复杂的内在关系，而且确保在信息压缩过程中过滤掉噪声信息。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [606] [Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models](https://arxiv.org/abs/2507.23443)
> *基于扩散模型学习流形约束的伴随法气动外形优化*

*Long Chen, Emre Oezkaya, Jan Rottmayer, Nicolas R. Gauger, Zebang Shen, Yinyu Ye* | **Category: cs.CE, cs.LG, math.OC** | **Updated: 2025-07-31**

**Keywords:** 伴随法优化, 扩散模型, 气动外形优化, 流形约束, 自动微分

**Comment:** 

> **TL;DR:** 本文提出了一种将扩散模型学习到的气动可行形状流形作为约束，与伴随法相结合的气动外形优化框架，通过自动微分计算梯度，实现了更鲁棒、性能更优的优化。

**AI_Comments:** 本文的创新点在于将扩散模型学习到的数据驱动流形约束引入到传统的伴随法气动外形优化中，通过自动微分实现了梯度的有效计算。这种结合不仅提高了优化过程的鲁棒性，减少了手动调优的需求，还提升了最终设计性能，为高保真度气动优化提供了一条新途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有气动外形优化方法存在参数调优和变量缩放问题，且对初始化和优化器选择敏感，性能有待提高。本文旨在通过引入AI生成的先验知识来解决这些局限性，实现更鲁棒、高性能的优化。

**Method:** 该方法引入了一个基于扩散模型学习到的气动可行形状平滑流形，并将其作为等式约束纳入伴随法气动外形优化问题。关键在于计算设计目标（如阻力、升力）相对于流形空间的伴随梯度，这通过首先计算相对于传统形状设计参数的形状导数，然后通过自动微分将它们反向传播到扩散模型的潜在空间来获得。

**Result:** 该框架在跨音速RANS翼型设计案例中得到了广泛验证，使用现成的通用非线性优化器，消除了临时参数调优和变量缩放的需要，在初始化和优化器选择方面保持了鲁棒性，并实现了优于传统方法的空气动力学性能。

**Conclusion:** 这项工作确立了AI生成的先验知识如何有效地与伴随方法结合，通过自动微分实现鲁棒、高保真度的气动外形优化。

> **ai_Abstract:** 本文提出了一种创新的基于伴随法的气动外形优化框架，该框架将扩散模型学习到的气动可行形状流形作为优化问题的等式约束。通过自动微分计算设计目标在流形空间中的伴随梯度，该方法克服了传统优化中参数调优和鲁鲁棒性问题。实验证明，该方法在跨音速翼型设计中表现出卓越的性能和鲁棒性，有效结合了AI先验知识与伴随优化。

> **摘要翻译:** 我们引入了一个基于伴随法的气动外形优化框架，该框架整合了一个在现有设计上训练的扩散模型，以学习气动可行形状的平滑流形。该流形被作为等式约束施加到形状优化问题中。我们方法的核心是计算设计目标（例如，阻力和升力）相对于流形空间的伴随梯度。这些梯度首先通过计算相对于传统形状设计参数（例如，Hicks-Henne参数）的形状导数，然后通过自动微分将其反向传播到扩散模型的潜在空间来获得。我们的框架保留了数学严谨性，并且可以以最小的修改集成到现有的基于伴随的设计工作流程中。在广泛的跨音速RANS翼型设计案例中，使用现成的通用非线性优化器进行了演示，我们的方法消除了临时参数调优和变量缩放，在初始化和优化器选择方面保持了鲁棒性，并实现了优于传统方法的空气动力学性能。这项工作确立了AI生成的先验知识如何有效地与伴随方法结合，通过自动微分实现鲁棒、高保真度的气动外形优化。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [697] [Modelling and simulation of electro-mechanically coupled dielectric elastomers and myocardial tissue using smoothed finite element methods](https://arxiv.org/abs/2507.22838)
> *使用平滑有限元方法对电机械耦合介电弹性体和心肌组织进行建模与仿真*

*Tan Tran, Denisa Martonova, Sigrid Leyendecker* | **Category: cs.CE** | **Updated: 2025-07-31**

**Keywords:** 平滑有限元方法, 介电弹性体, 心肌组织, 电机械耦合, 仿真

**Comment:** 

> **TL;DR:** 本研究将平滑有限元方法（S-FEM）扩展到电机械耦合问题，并发现混合面/节点平滑有限元方法（FSNS-FEM）在模拟介电弹性体和心肌组织时，在准确性和计算效率之间取得了最佳平衡，有效解决了传统有限元方法的刚度过大和体积锁定问题。

**AI_Comments:** 该研究的创新之处在于将S-FEMs扩展到电机械耦合问题，并系统地比较了不同S-FEM变体与标准FEM的性能。其重要性在于为生物医学工程，特别是心脏电机械模拟，提供了一种更准确、更鲁棒的计算建模方法，克服了传统FEM在处理复杂几何和不可压缩材料时的局限性。FSNS-FEM被证明是最佳选择，这对于未来的生物医学设备开发和疾病研究具有实际指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算建模是生物医学工程中实验研究的一种经济高效且省时的替代方案。然而，在心肌电机械领域，基于有限元方法（FEM）的模拟常因自动生成的四面体网格导致数值问题，如响应过硬和体积锁定，尤其是在不可压缩材料中。

**Method:** 本研究将平滑有限元方法（S-FEM）公式扩展到电机械耦合问题，并将其性能与标准线性有限元方法进行比较。在Abaqus环境中通过自定义用户单元实现了四种方法：标准线性FEM、面平滑有限元方法（FS-FEM）、节点平滑有限元方法（NS-FEM）和混合面/节点平滑有限元方法（FSNS-FEM）。研究了两个基准问题：可压缩介电弹性体的电致收缩和不可压缩、正交各向异性心肌组织样本。参考解通过更高阶单元网格获得。

**Result:** 结果表明，FSNS-FEM在准确性和计算效率之间提供了最佳平衡，与参考数据非常匹配。NS-FEM产生的结果偏软，导致对真实变形的过高估计。FS-FEM和标准FEM始终表现出过硬的行为，在心肌案例中出现明显的体积锁定。

**Conclusion:** 这些发现支持了S-FEMs，特别是FSNS-FEM，在复杂生物医学应用中准确模拟耦合电机械行为的潜力。

> **ai_Abstract:** 本研究旨在解决传统有限元方法（FEM）在生物医学电机械耦合模拟中存在的刚度过大和体积锁定问题。论文将平滑有限元方法（S-FEMs）扩展到电机械耦合问题，并比较了四种不同的有限元方法（标准FEM、FS-FEM、NS-FEM、FSNS-FEM）在模拟介电弹性体和心肌组织时的性能。结果表明，混合面/节点平滑有限元方法（FSNS-FEM）在准确性和计算效率之间取得了最佳平衡，能够有效解决传统FEM的数值问题，为复杂生物医学应用中的电机械耦合行为模拟提供了更准确的工具。

> **摘要翻译:** 计算建模为生物医学工程中的实验研究提供了一种经济高效且省时的替代方案。在心肌电机械领域，基于有限元方法（FEM）的模拟为病变组织行为和介电弹性体致动器等辅助系统的开发提供了宝贵的见解。然而，由于几何复杂性而常用的自动生成四面体网格通常会导致数值问题，包括响应过硬和体积锁定，尤其是在不可压缩材料中。平滑有限元方法（S-FEMs）通过在定义的平滑域上平滑梯度来软化刚度矩阵，提供了一种有前景的替代方案。这项工作将S-FEM公式扩展到电机械耦合问题，并将其性能与标准线性FEM进行比较。我们在Abaqus环境中通过自定义用户单元实现了并评估了四种方法：标准线性FEM、面平滑有限元方法（FS-FEM）、节点平滑有限元方法（NS-FEM）以及混合面/节点平滑有限元方法（FSNS-FEM）。研究了两个基准问题：可压缩介电弹性体的电致收缩和不可压缩、正交各向异性心肌组织样本。参考解使用由更高阶单元组成的网格获得。我们的结果表明，FSNS-FEM在准确性和计算效率之间提供了最佳平衡，与参考数据非常匹配。NS-FEM产生的结果偏软，导致对真实变形的过高估计。FS-FEM和标准FEM始终表现出过硬的行为，在心肌案例中出现明显的体积锁定。这些发现支持了S-FEMs，特别是FSNS-FEM，在复杂生物医学应用中准确模拟耦合电机械行为的潜力。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [613] [The Squishy Grid Problem](https://arxiv.org/abs/2507.23105)
> *弹性网格问题*

*Zixi Cai, Kuowen Chen, Shengquan Du, Arnold Filtser, Seth Pettie, Daniel Skora* | **Category: cs.CG, cs.DM, cs.DS, math.CO, math.PR** | **Updated: 2025-07-30**

**Keywords:** 欧几里得距离, 整数网格图, 边权重, 渐近等距, 第一渗流

**Comment:** 

> **TL;DR:** 本文探讨了如何通过调整边权重，使无限整数网格图中的距离渐近地近似于欧几里得距离，并提出了三种不同的方法。

**AI_Comments:** 本文解决了通过调整网格图边权重来近似欧几里得距离的独特问题。其创新点在于提出了三种不同性质的方法（两种确定性，一种随机实验性），并对它们的性能进行了量化比较。特别是，实验性方法发现了一个简单的两点分布即可实现高精度近似，这对于第一渗流理论的开放问题提供了有益的实验证据。

<details>
  <summary>Details</summary>

**Motivation:** 在无限整数网格图中，通过控制边权重，使网格距离渐近地等距于欧几里得距离。

**Method:** 本文提出了三种方法：1. 基于Radin和Conway的递归非周期风车平铺嵌入整数网格；2. 基于“高速公路”的分层排列；3. 从共同分布中独立采样边权重，并通过实验展示了一种简单的两点分布。

**Result:** 1. 风车平铺法：乘法失真为$(1+1/\Theta(\log^\xi \log D))$。2. 高速公路法：拉伸为$(1 + 1/\Theta(D^{1/9}))$，收敛速度比风车平铺法快两倍指数级。3. 实验法：通过简单的两点分布（权重为0.41或4.75，概率分别为44%和56%），可使网格距离达到欧几里得距离的1%精度。

**Conclusion:** 本文提出了三种解决“弹性网格问题”的方法，旨在使网格距离渐近地近似于欧几里得距离，并量化了它们的性能，展示了通过调整边权重实现高精度近似的可行性。

> **ai_Abstract:** 本文探讨了“弹性网格问题”，即如何在无限整数网格图中分配边权重，使网格距离渐近地近似于欧几里得距离。文章提出了三种方法：基于风车平铺的嵌入方法，其乘法失真为$(1+1/\Theta(\log^\xi \log D))$；基于分层“高速公路”的方法，其拉伸为$(1 + 1/\Theta(D^{1/9}))$且收敛更快；以及一种实验性的方法，通过简单的两点分布（权重0.41或4.75，概率分别为44%和56%）可使网格距离达到欧几里得距离的1%精度。

> **摘要翻译:** 在本文中，我们考虑了通过无限整数网格图来近似欧几里得距离的问题。尽管图的拓扑结构是固定的，但我们可以控制边权重赋值 $w:E\to \mathbb{R}_{\ge 0}$，并希望网格距离渐近地等距于欧几里得距离，即对于所有网格点 $u,v$，$\mathrm{dist}_w(u,v) = (1\pm o(1))\|u-v\|_2$。我们给出了三种解决此问题的方法，每种方法都有其吸引力。
* 我们的第一个构造基于Radin和Conway的递归非周期风车平铺嵌入整数网格。风车图中的距离渐近地等距于欧几里得距离，但收敛速度的明确界限未知。我们证明风车图的乘法失真为 $(1+1/\Theta(\log^\xi \log D))$，其中 $D$ 是欧几里得距离，$\xi=\Theta(1)$。风车平铺方法概念上简单，但可以在数量上进行改进。
* 我们的第二个构造基于“高速公路”的分层排列。它很简单，实现了 $(1 + 1/\Theta(D^{1/9}))$ 的拉伸，收敛速度比风车平铺方法快两倍指数级。
* 前两种方法是确定性的。一种更简单的方法是从共同分布 $\mathscr{D}$ 中独立采样边权重。是否存在一个分布 $\mathscr{D}^*$ 使得网格距离在渐近和期望意义上都是欧几里得距离，这是第一渗流理论中的一个主要开放问题。之前的实验表明，当 $\mathscr{D}$ 是费舍尔分布时，网格距离在欧几里得距离的1%以内。我们通过实验证明，通过一个简单的两点分布，即以44%和56%的概率分别赋予权重0.41或4.75，可以达到这种精度水平。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [641] [Dudeney's Dissection is Optimal](https://arxiv.org/abs/2412.03865)
> *杜德尼的切割是最佳的*

*Erik D. Demaine, Tonan Kamata, Ryuhei Uehara* | **Category: cs.CG, cs.DM, math.GT** | **Updated: 2025-08-01**

**Keywords:** 几何切割, 杜德尼谜题, 最优解, 等边三角形, 正方形

**Comment:** 26 pages, 32 figures. The previous version mistakenly compiled an
  outdated file. This update corrects that and includes the intended version
  with refined and corrected case analysis of cut graphs

> **TL;DR:** 本文证明了杜德尼提出的将等边三角形切割成正方形的最少块数问题中，四块解决方案是最佳的，因为不可能用三块或更少的块完成。

**AI_Comments:** 这项研究的创新之处在于，它通过严谨的数学证明，最终解决了困扰几何学界一个多世纪的杜德尼切割谜题，确立了其四块方案的最优性。这不仅是对一个经典几何问题的终结，也展示了将几何问题转化为图结构分析的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 解决亨利·欧内斯特·杜德尼在1907年提出的一个百年难题：将等边三角形切割成最少块数以形成一个完美正方形。

**Method:** 通过将问题简化为分析表示每个多边形形成块的边和顶点之间对应关系的离散图结构。

**Result:** 证明了等边三角形和正方形没有由三块或更少多边形块组成的共同切割。

**Conclusion:** 杜德尼的四块解决方案被证明是最佳的，这意味着不可能用更少的块来完成切割。

> **ai_Abstract:** 本文解决了杜德尼在1907年提出的一个著名的几何切割难题。该研究通过证明等边三角形和正方形无法用三块或更少的几何块进行切割和重组，从而证实了杜德尼最初提出的四块解决方案是实现等边三角形到正方形转换的最优解。研究方法涉及将问题转化为对离散图结构的分析，这些结构代表了构成多边形的块的边和顶点之间的对应关系。

> **摘要翻译:** 1907年，亨利·欧内斯特·杜德尼提出了一个谜题：“将任何等边三角形……切割成尽可能少的块，使其能够组合成一个完美的正方形”（无重叠，通过平移和旋转）。四周后，杜德尼展示了一个漂亮的四块解决方案，这在今天仍然是最著名的切割例子。在这篇论文中（一个多世纪后），我们最终解决了杜德尼的谜题，通过证明等边三角形和正方形没有由三块或更少多边形块组成的共同切割。我们将问题简化为分析表示构成每个多边形的块的边和顶点之间对应关系的离散图结构。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [8] [A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations](https://arxiv.org/abs/2507.22919)
> *一种用于从临床试验的前瞻性注册信息中预测严重不良事件结果的新型语言模型*

*Qixuan Hu, Xumou Zhang, Jinman Kim, Florence Bourgeois, Adam G. Dunn* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 语言模型, 临床试验, 严重不良事件, 预测, 迁移学习

**Comment:** 

> **TL;DR:** 本研究开发并评估了一种基于预训练语言模型（如ClinicalT5、BioBERT）的方法，用于在临床试验开始前，仅利用注册信息预测严重不良事件（SAE）的发生率及哪组（实验组或对照组）SAE发生率更高。结果显示，该模型预测效果良好，并强调了ClinicalTrials.gov数据未被充分利用的潜力。

**AI_Comments:** 该研究提出了一种创新的方法，将预训练语言模型应用于临床试验安全结果的早期预测，这对于优化试验设计、降低风险具有重要意义。滑动窗口方法的引入有效地解决了长文本输入限制问题，提升了模型的实用性。研究也指出了现有临床试验数据未被充分利用的现状，为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了避免临床试验终止并限制参与者暴露于不必要的风险，需要准确估计预期的安全性结果。本研究旨在评估仅利用临床试验注册信息预测严重不良事件（SAE）结果的方法。

**Method:** 分析了来自ClinicalTrials.gov的22,107项具有结构化总结结果的两臂平行干预性临床试验数据。开发了两种预测模型：一个分类器用于预测实验组是否会有更高的SAE发生率（AUC），一个回归模型用于预测对照组的SAE比例（RMSE）。采用迁移学习方法，利用预训练语言模型（如ClinicalT5、BioBERT）进行特征提取，并结合下游模型进行预测。为处理超出语言模型输入限制的长文本，开发了一种滑动窗口方法进行嵌入提取。

**Result:** 最佳模型（ClinicalT5+Transformer+MLP）在预测哪个试验组有更高比例的SAE患者时，AUC为77.6%。在预测对照组经历SAE的参与者比例时，同一模型达到了18.6%的RMSE。滑动窗口方法始终优于没有使用该方法的方法。在12个分类器中，平均绝对AUC增加了2.00%；在12个回归器中，平均绝对RMSE减少了1.58%。

**Conclusion:** ClinicalTrials.gov上可用的总结结果数据仍未被充分利用。在试验开始前估计试验结果的潜力是改进试验设计并发现预期与报告安全结果之间差异的机会。

> **ai_Abstract:** 本研究开发了一种新型语言模型，利用临床试验注册信息预测严重不良事件（SAE）结果。通过分析ClinicalTrials.gov上的22,107项试验数据，构建了分类器和回归器，并结合预训练语言模型（如ClinicalT5、BioBERT）和滑动窗口方法进行特征提取和预测。结果显示，该模型在预测SAE发生率方面表现良好（AUC 77.6%，RMSE 18.6%），且滑动窗口方法提升了模型性能。研究强调了ClinicalTrials.gov数据在改进临床试验设计和早期风险评估方面的巨大潜力。

> **摘要翻译:** 目的：通过准确估计预期的安全性结果，可以设计临床试验以避免终止并限制参与者暴露于不必要的风险。我们评估了仅利用临床试验注册前的信息来预测临床试验中严重不良事件（SAE）结果的方法。
材料与方法：我们分析了来自ClinicalTrials.gov的22,107项具有结构化总结结果的两臂平行干预性临床试验。开发了两种预测模型：一个分类器预测实验组是否会比对照组有更高的SAE发生率（受试者工作特征曲线下面积；AUC），以及一个回归模型预测对照组中SAE的比例（均方根误差；RMSE）。使用预训练语言模型（例如ClinicalT5、BioBERT）的迁移学习方法用于特征提取，并结合下游模型进行预测。为了在超出局部语言模型输入限制的长试验文本中保持语义表示，开发了一种滑动窗口方法用于嵌入提取。
结果：最佳模型（ClinicalT5+Transformer+MLP）在预测哪个试验组有更高比例的SAE患者时，AUC为77.6%。当预测对照组中经历SAE的参与者比例时，同一模型实现了18.6%的RMSE。滑动窗口方法始终优于没有使用该方法的方法。在12个分类器中，平均绝对AUC增加了2.00%；在12个回归器中，平均绝对RMSE减少了1.58%。
讨论：ClinicalTrials.gov上可用的总结结果数据仍未被充分利用。在试验开始前估计试验结果的潜力是改进试验设计并发现预期与报告安全结果之间差异的机会。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [16] [Unveiling Super Experts in Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2507.23279)
> *揭示混合专家大型语言模型中的超级专家*

*Zunhai Su, Qingyuan Li, Hao Zhang, YuLei Qian, Yuchen Xie, Kehong Yuan* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 混合专家, 大型语言模型, 超级专家, 注意力汇聚, 模型压缩

**Comment:** 

> **TL;DR:** 本文首次发现并研究了混合专家（MoE）大型语言模型中的“超级专家”（SEs），这些专家数量虽少但至关重要，能引发注意力汇聚，其剪枝会导致模型性能显著下降。

**AI_Comments:** 本文对MoE LLMs的内部工作机制进行了开创性探索，首次提出了“超级专家”的概念，超越了传统依赖经验的专家识别方法。发现少量专家能对模型性能产生如此深远的影响，尤其是在诱导注意力汇聚方面，具有高度的创新性和重要性。这为未来MoE模型的设计、压缩和优化提供了全新的视角，对理解MoE模型的鲁棒性和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有识别关键专家的方法常依赖经验准则，缺乏对专家异质重要性的深入探索和理解，限制了MoE LLMs专家级压缩技术的发展。本研究旨在填补这一空白，深入理解并发现真正关键的专家。

**Method:** 本研究首次发现并调查了混合专家（MoE）大型语言模型中一个独特的专家子集，即“超级专家”（SEs）。通过分析SEs在down_proj输出中的激活模式及其对隐藏状态的影响，评估其分布特性。通过剪枝SEs，评估它们在多种任务（特别是数学推理）中对模型整体性能的影响。进一步分析了SEs在诱导注意力汇聚（attention sinks）中的作用及其对注意力分数分布的影响。

**Result:** 1. 首次发现并定义了“超级专家”（SEs），它们在开源MoE LLMs中普遍存在，数量有限但对模型的前向推理机制至关重要。2. 剪枝少量SEs会导致模型性能显著下降（例如，剪枝Qwen3-30B-A3B的三个SEs会导致重复和无信息输出）。3. SEs的特征是down_proj输出中出现罕见但极端的激活异常值，这会在解码器层之间的隐藏状态中产生大量激活。4. SEs的分布是模型特有的，不受训练后处理过程的影响。5. SEs对模型整体性能有显著影响，尤其是在数学推理任务中。6. MoE LLMs依赖SEs来诱导注意力汇聚（attention sinks），这对于注意力分数的分布至关重要，而剪枝SEs会严重破坏这一机制。

**Conclusion:** 超级专家（SEs）是MoE大型语言模型中一个关键且数量稀少的专家子集，它们通过诱导注意力汇聚对注意力分数的分布至关重要。剪枝这些SEs会导致模型性能的显著下降，这突显了它们在MoE LLMs功能和性能中的核心作用。

> **ai_Abstract:** 本文首次发现并深入研究了混合专家（MoE）大型语言模型中的一个关键子集，命名为“超级专家”（SEs）。与以往依赖经验准则识别关键专家的方法不同，本研究提供了对这些重要组件的更深层次理解。研究表明，即使剪枝少量SEs也会导致模型性能显著下降，尤其是在数学推理方面。分析揭示，SEs的特征是极端激活异常值，并且它们对于诱导“注意力汇聚”（attention sinks）至关重要，而注意力汇聚对于注意力分数的正确分布至关重要。这些发现强调了SEs在MoE LLMs功能和性能中的基础作用。

> **摘要翻译:** 稀疏激活的混合专家（MoE）模型在增强大型语言模型（LLMs）的学习能力方面显示出前景。利用专家之间固有的重要性差异，最近的研究探索了专家级压缩技术以提高MoE LLMs的效率。然而，现有方法通常依赖经验标准来识别关键专家，缺乏对专家异质重要性的更深入探索和理解。在本研究中，我们首次发现并调查了一个独特的专家子集，它们在模型前向推理的底层机制中发挥着关键作用。这些专家在开源MoE LLMs中普遍存在，尽管数量有限，但剪枝它们会导致模型性能显著下降（例如，剪枝三个会导致Qwen3-30B-A3B产生重复和无信息输出）。我们将这些专家称为超级专家（SEs）。我们的全面分析提供了对SEs逐步深入的见解。(i) SEs的特点是down_proj输出中出现罕见但极端的激活异常值，这会在解码器层之间的隐藏状态中产生大量激活。此外，SEs的分布保持模型特异性，不受训练后过程的影响。(ii) 通过剪枝SEs，我们评估了它们在各种任务中的重要性，揭示了它们对模型整体性能的巨大影响，特别是在数学推理方面。(iii) 我们进一步增强了对SEs压缩影响的理解。我们的发现证实，MoE LLMs依赖SEs来诱导注意力汇聚（attention sinks），这对于注意力分数的分布至关重要，但SEs剪枝会严重破坏这一机制。代码可在https://github.com/ZunhaiSu/Super-Experts-Profilling 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [36] [Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey](https://arxiv.org/abs/2507.22920)
> *多模态LLM的离散分词：一项综合调查*

*Jindong Li, Yali Fu, Jiahong Liu, Linxiao Cao, Wei Ji, Menglin Yang, Irwin King, Ming-Hsuan Yang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-21**

**Keywords:** 离散分词, 多模态LLM, 向量量化, 综述, 码本

**Comment:** 

> **TL;DR:** 本文对多模态大语言模型（LLMs）中的离散分词，特别是向量量化（VQ）技术进行了首次全面调查，分类了代表性方法，分析了挑战，并提出了未来研究方向。

**AI_Comments:** 该论文的重要性在于它首次对多模态LLM中的离散分词（特别是向量量化）进行了全面和结构化的调查。它不仅系统地分类和分析了现有方法，还识别了当前面临的关键挑战并指出了未来的研究方向，这对于快速发展的多模态LLM领域具有重要的指导意义和参考价值。其创新性在于填补了这一特定领域缺乏系统性综述的空白。

<details>
  <summary>Details</summary>

**Motivation:** 由于大语言模型（LLMs）的快速发展，需要有效的机制将连续多模态数据转换为适合基于语言处理的离散表示。尽管离散分词（以向量量化VQ为核心方法）的重要性日益增长，但目前缺乏对其在LLM系统中系统性研究的综合性调查。

**Method:** 本文填补了这一空白，首次提出了针对LLMs设计的离散分词方法的结构化分类和分析。作者分类了8种代表性VQ变体，并分析了它们的算法原理、训练动态以及与LLM管道的集成挑战。除了算法层面的调查，本文还讨论了无LLM的经典应用、基于LLM的单模态系统和基于LLM的多模态系统中的现有研究，并指出了量化策略如何影响对齐、推理和生成性能。此外，还识别了关键挑战并讨论了新兴研究方向。

**Result:** 该调查对8种代表性VQ变体进行了分类，分析了它们的原理、训练动态和集成挑战。它讨论了量化策略如何影响LLM的对齐、推理和生成性能。此外，还识别了关键挑战，包括码本崩溃、不稳定的梯度估计和模态特定的编码约束，并提出了新兴研究方向，如动态和任务自适应量化、统一的分词框架和受生物学启发的码本学习。

**Conclusion:** 这项调查弥合了传统向量量化与现代LLM应用之间的差距，为开发高效和可泛化的多模态系统提供了基础性参考。

> **ai_Abstract:** 本篇综合性调查旨在填补多模态大语言模型（LLMs）中离散分词技术（特别是向量量化，VQ）领域缺乏系统性研究的空白。文章首次提出了针对LLM的离散分词方法的结构化分类和分析，详细介绍了8种代表性VQ变体的原理、训练和集成挑战。此外，该调查还探讨了VQ在不同LLM应用中的影响，指出了码本崩溃等关键挑战，并展望了动态量化等未来研究方向，为开发高效的多模态LLM系统提供了重要参考。

> **摘要翻译:** 大型语言模型（LLM）的快速发展，加剧了将连续多模态数据转化为适合基于语言处理的离散表示的有效机制的需求。离散分词，以向量量化（VQ）作为核心方法，既提供了计算效率，又与LLM架构兼容。尽管其重要性日益增长，但在LLM系统背景下系统地考察VQ技术的综合性调查仍有欠缺。本工作通过首次提出为LLM设计的离散分词方法的结构化分类和分析来填补这一空白。我们对跨越经典和现代范式的8种代表性VQ变体进行了分类，并分析了它们的算法原理、训练动态以及与LLM管道的集成挑战。除了算法层面的调查，我们还讨论了现有研究在没有LLM的经典应用、基于LLM的单模态系统和基于LLM的多模态系统中的情况，强调了量化策略如何影响对齐、推理和生成性能。此外，我们还指出了关键挑战，包括码本崩溃、不稳定的梯度估计和模态特定的编码约束。最后，我们讨论了新兴的研究方向，如动态和任务自适应量化、统一的分词框架以及受生物学启发的码本学习。这项调查弥合了传统向量量化与现代LLM应用之间的差距，为开发高效和可泛化的多模态系统提供了基础性参考。持续更新的版本可在https://github.com/jindongli-Ai/LLM-Discrete-Tokenization-Survey获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [37] [What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content](https://arxiv.org/abs/2507.23319)
> *你认为什么是禁忌？——大型语言模型对敏感内容行为的实证评估*

*Alfio Ferrara, Sergio Picascia, Laura Pinnavaia, Vojimir Ranitovic, Elisabetta Rocchetti, Alice Tuveri* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 敏感内容, 隐式审查, GPT-4o-mini, 内容审查

**Comment:** 

> **TL;DR:** 研究发现GPT-4o-mini在复述敏感内容时会系统性地进行隐式内容审查，减少冒犯性和禁忌语言。

**AI_Comments:** 这项研究创新性地揭示了LLM在没有显式指令的情况下进行“自我审查”或“隐式审查”的行为，填补了现有研究的空白。这对理解LLM的伦理和社会影响，以及开发更可控和负责任的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要集中于明确训练大型语言模型（LLM）进行内容审查，但对于LLM是否在没有明确指令的情况下隐式净化语言的探索有限。

**Method:** 本研究实证分析了GPT-4o-mini在复述敏感内容时的隐式审查行为，并评估了敏感性变化的程度。此外，还评估了LLM在零样本分类句子敏感性方面的能力，并将其性能与传统方法进行了比较。

**Result:** 实验表明，GPT-4o-mini系统性地将内容审查为敏感度较低的类别，显著减少了贬损性和禁忌语言。

**Conclusion:** 大型语言模型（特别是GPT-4o-mini）在处理敏感内容时表现出显着的隐式内容审查能力，即使没有明确指令也会净化语言。

> **ai_Abstract:** 本研究探讨了专有大型语言模型（LLM）在处理敏感内容时是否会进行隐式审查。通过对GPT-4o-mini的实证分析，发现该模型在复述敏感内容时会系统性地将其转化为敏感度较低的类别，显著减少了贬损性和禁忌语言。研究还评估了LLM在零样本敏感性分类方面的能力，并与传统方法进行了比较。

> **摘要翻译:** 专有大型语言模型（LLM）表现出礼貌、正式和隐式内容审查的倾向。虽然之前的研究主要集中于明确训练模型来审查和净化敏感内容，但对于LLM是否在没有明确指令的情况下隐式净化语言的探索有限。本研究实证分析了GPT-4o-mini在复述敏感内容时的隐式审查行为，并评估了敏感性变化的程度。我们的实验表明，GPT-4o-mini系统性地将内容审查为敏感度较低的类别，显著减少了贬损性和禁忌语言。此外，我们还评估了LLM在零样本分类句子敏感性方面的能力，并将其性能与传统方法进行了比较。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [38] [Splits! A Flexible Dataset and Evaluation Framework for Sociocultural Linguistic Investigation](https://arxiv.org/abs/2504.04640)
> *Splits！一个用于社会文化语言学研究的灵活数据集和评估框架*

*Eylon Caplan, Tania Chakraborty, Dan Goldwasser* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 社会文化语言学, 数据集, Reddit, 计算语言学, 评估框架

**Comment:** Preprint, under review

> **TL;DR:** 引入了一个名为Splits!的970万条Reddit帖子数据集和一个评估框架，旨在促进社会文化语言现象的系统性计算研究，并通过自动化验证和“意外性”度量来加速新发现。

**AI_Comments:** 该论文的创新点在于构建了一个大规模、结构化的社会文化语言学数据集，并提出了一个独特的评估框架。该框架不仅自动化了潜在现象的验证过程，还引入了“意外性”度量，这对于区分真正的新颖洞察和显而易见的发现至关重要，极大地提高了研究效率和发现质量。这对于推动社会文化语言学领域的计算研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算研究社会文化语言现象（SLP）通常局限于特定群体或主题的定制分析，阻碍了科学发现的进展，因此需要一个更系统和灵活的研究方法。

**Method:** 该研究引入了Splits!，一个包含970万条Reddit帖子的数据集，来自53,000多名用户的6个不同人口统计群体，并按89个讨论主题进行组织。同时，还提出了一个评估框架，该框架利用高效检索方法快速验证潜在的SLP，并引入了一个人工验证的“意外性”度量来区分新颖和明显的见解。

**Result:** 通过自我识别和成功复现现有文献中的已知SLP，验证了Splits!数据集。该双阶段框架将需要人工检查的统计显著发现数量减少了1.5-1.8倍，从而简化了有前景现象的发现过程。

**Conclusion:** Splits!数据集和评估框架为社会文化语言现象的系统性计算研究提供了一个灵活且高效的工具，显著加速了潜在新发现的验证过程。

> **ai_Abstract:** 本研究提出了Splits!，一个包含970万条Reddit帖子的灵活数据集，旨在促进社会文化语言现象的系统性计算研究。该数据集涵盖了来自不同人口统计群体的用户和讨论主题，并通过复现已知现象进行了验证。此外，论文还引入了一个评估框架，该框架利用高效检索方法和“意外性”度量来自动化潜在SLP的验证过程，显著减少了需要人工检查的发现数量，从而加速了科学发现。

> **摘要翻译:** 语言使用中的变异，受说话者的社会文化背景和特定使用语境的影响，为文化视角、价值观和观点提供了丰富的视角。然而，这些社会文化语言现象（SLP）的计算研究通常局限于特定群体或主题的定制分析，阻碍了科学发现的步伐。为了解决这个问题，我们引入了Splits!，一个来自Reddit的970万条帖子的数据集，专为系统和灵活的研究而设计。该数据集包含来自6个人口统计群体、超过53,000名用户的帖子，并组织成89个讨论主题，以实现比较分析。我们通过自我识别和成功复现现有文献中已知的SLP来验证Splits!。我们用一个框架来补充这个数据集，该框架利用高效的检索方法，通过自动评估给定假设是否得到我们数据的支持，来快速验证潜在的SLP（PSLP）。至关重要的是，为了区分新颖和明显的见解，该框架纳入了一个经过人工验证的衡量假设“意外性”的指标。我们证明，这个两阶段过程将需要人工检查的统计显著发现的数量减少了1.5-1.8倍，从而简化了有前景现象的发现过程，以便进行进一步调查。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [50] [Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers](https://arxiv.org/abs/2507.22921)
> *使用级联语言模型链和候选答案的快速准确上下文知识提取*

*Lee Harris* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-21**

**Keywords:** 语言模型链, 知识提取, 幻觉, 级联, 候选答案

**Comment:** 

> **TL;DR:** 语言模型链（LMC）通过级联语言模型和候选答案，显著提高了知识提取的速度和准确性，并减少了幻觉。

**AI_Comments:** LMC算法通过引入级联验证和多阶段处理机制，有效解决了语言模型在知识提取中面临的幻觉和效率问题。其创新点在于结合了候选答案进行验证，并根据验证结果动态调整模型的使用，实现了速度与准确性的平衡。这对于需要高精度和可靠性（如医疗）的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型在处理文本时成本高昂且容易产生“幻觉”（即生成不存在的信息），导致资源浪费且信息不可靠。

**Method:** 本文提出并实现了语言模型链（LMC）算法。该算法通过将语言模型的响应与预定义的候选答案集合进行比对，只有当响应存在于候选答案中时才被认为是正确的。如果响应不正确，则将相应的文本输入到下一个更具预测性但速度较慢的语言模型中。此过程将重复进行，直到所有预测都正确或用尽所有语言模型。

**Result:** 在从医疗文档中提取患者出生日期的应用中，LMC算法通过多阶段级联组合语言模型，显著提高了预测速度和准确性，并大大减少了相应的幻觉数量，表现优于单个语言模型。

**Conclusion:** LMC算法对知识提取领域做出了重要贡献，未来应进一步深入探索。

> **ai_Abstract:** 本文提出了一种名为语言模型链（LMC）的新算法，旨在解决传统语言模型成本高、易产生幻觉的问题。LMC通过将语言模型的输出与预设的候选答案进行比对，若不符则将文本传递给更强大但速度较慢的语言模型进行迭代处理，直至获得正确结果。实验表明，在医疗文档中提取出生日期时，LMC显著提升了知识提取的速度和准确性，并有效减少了幻觉。

> **摘要翻译:** 语言模型能够捕捉给定文本中的复杂关系，但它们因成本高昂和产生不存在的信息（即幻觉）而臭名昭著。此外，如果生成的信息不正确，投入到生产这些信息中的资源将被浪费。我们通过提出、实现和应用语言模型链（LMC）算法来解决这些问题。在该算法中，语言模型对给定文本的提示响应只有在存在于可能的（即候选）答案集合中时才是正确的，并且对应于不正确响应的文本会被输入到更具预测性（但速度较慢）的语言模型中。这个过程会针对一系列语言模型重复进行，或者直到所有关于文本的预测都正确。我们使用LMC算法从医疗文档中提取患者出生日期，并且通过多阶段级联组合一系列语言模型，显著提高了预测速度和准确性，同时大大减少了相应的幻觉数量，优于单个语言模型。我们相信新颖的LMC算法对知识提取领域做出了重大贡献，并且未来应进一步深入探索。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [58] [MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation](https://arxiv.org/abs/2507.23334)
> *MUST-RAG：基于检索增强生成技术的音乐文本问答*

*Daeyong Kwon, SeungHeon Doh, Juhan Nam* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 音乐问答, 检索增强生成, 大型语言模型, 向量数据库, 领域适应

**Comment:** 8 pages, 2 figures

> **TL;DR:** MusT-RAG框架利用检索增强生成技术和音乐专业知识库，显著提升了大型语言模型在音乐文本问答任务上的表现。

**AI_Comments:** 这篇论文通过引入领域特定的知识库和优化RAG机制，有效解决了大型语言模型在专业领域知识不足的普遍问题。其创新点在于为音乐问答任务定制了检索增强生成框架，并构建了专业的音乐知识库，为未来LLMs在特定垂直领域的应用提供了有益的范例。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在音乐相关应用中表现有限，因为其训练数据中音乐特定知识的比例相对较小。

**Method:** 提出MusT-RAG框架，一个基于检索增强生成（RAG）的方法，用于使通用LLMs适应文本音乐问答（MQA）任务。具体包括：1) 构建音乐专业向量数据库MusWikiDB用于检索阶段；2) 在推理和微调过程中利用上下文信息，将通用LLMs转化为音乐专用模型。

**Result:** MusT-RAG在增强LLMs音乐领域适应能力方面显著优于传统微调方法，在域内和域外MQA基准测试中均显示出持续改进。MusWikiDB比通用维基百科语料库更有效，提供了卓越的性能和计算效率。

**Conclusion:** MusT-RAG通过结合RAG技术和音乐专业知识库，有效解决了LLMs在音乐文本问答领域的知识限制，显著提升了其在该领域的性能和效率。

> **ai_Abstract:** 本文提出了MusT-RAG框架，旨在通过检索增强生成（RAG）技术提升大型语言模型在音乐文本问答（MQA）任务上的表现。为解决LLMs音乐知识不足的问题，MusT-RAG引入了音乐专业向量数据库MusWikiDB，并在推理和微调阶段利用上下文信息。实验证明，MusT-RAG显著优于传统微调方法，且MusWikiDB比通用语料库更高效。

> **摘要翻译:** 大型语言模型（LLMs）最近的进展在不同领域展示了卓越的能力。尽管它们在各种任务上表现出强大的零样本性能，但由于训练数据中音乐特定知识的比例相对较小，LLMs在音乐相关应用中的有效性仍然有限。为了解决这一限制，我们提出了MusT-RAG，一个基于检索增强生成（RAG）的综合框架，旨在使通用LLMs适应纯文本音乐问答（MQA）任务。RAG是一种通过在生成问题答案时检索相关上下文信息来为LLMs提供外部知识的技术。为了优化RAG在音乐领域的应用，我们（1）提出了MusWikiDB，一个用于检索阶段的音乐专业向量数据库，并且（2）在推理和微调过程中利用上下文信息，有效地将通用LLMs转化为音乐专用模型。我们的实验表明，MusT-RAG在增强LLMs的音乐领域适应能力方面显著优于传统的微调方法，在域内和域外MQA基准测试中均显示出持续的改进。此外，我们的MusWikiDB被证明比通用维基百科语料库更有效，提供了卓越的性能和计算效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [64] [Predicting stock prices with ChatGPT-annotated Reddit sentiment](https://arxiv.org/abs/2507.22922)
> *使用ChatGPT标注的Reddit情绪预测股票价格*

*Mateusz Kmak, Kamil Chmurzyński, Kamil Matejuk, Paweł Kotzbach, Jan Kocoń* | **Category: cs.CL, cs.AI, cs.SI** | **Updated: 2025-07-21**

**Keywords:** Reddit情绪, 股票价格, ChatGPT, RoBERTa, 社交媒体

**Comment:** International Conference on Computational Science 2025

> **TL;DR:** 本文研究Reddit情绪对股票价格的影响，发现社交媒体情绪与股价关联较弱，而评论量和谷歌搜索趋势有更强的预测信号。

**AI_Comments:** 本文创新性地引入了ChatGPT标注和微调的RoBERTa模型来处理社交媒体的非正式语言，但在预测股票价格方面，其效果并不如预期。研究结果挑战了社交媒体情感直接影响股价的普遍看法，强调了散户行为的复杂性，并指出其他简单指标（如评论量、搜索趋势）可能更具预测价值。这对于理解数字时代市场动态具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 2021年GameStop事件等散户在社交媒体上的活跃度激增，引发了关于在线情绪对股票价格影响的疑问。本文旨在探讨社交媒体讨论中提取的情绪是否能有效预测股市波动。

**Method:** 研究聚焦Reddit的r/wallstreetbets版块，分析GameStop (GME) 和AMC Entertainment (AMC) 的相关情绪。采用两种现有文本情感分析方法，并引入第三种：一个经过ChatGPT标注和微调的基于RoBERTa的模型，旨在更好地解释社交媒体中非正式语言和表情符号。使用相关性和因果关系指标来确定这些模型的预测能力。

**Result:** 研究发现社交媒体情绪与股票价格仅有微弱相关性。同时，评论量和谷歌搜索趋势等更简单的指标显示出更强的预测信号。

**Conclusion:** 这些结果突显了散户行为的复杂性，并表明传统情感分析可能无法完全捕捉影响市场在线讨论的细微差别。

> **ai_Abstract:** 本文研究社交媒体（Reddit）情绪对股票价格的预测能力。研究使用两种传统情感分析方法和一个新的ChatGPT标注的RoBERTa模型，分析GameStop和AMC股票的Reddit讨论。结果显示社交媒体情绪与股价关联较弱，而评论量和谷歌搜索趋势等简单指标具有更强的预测力，揭示了散户行为的复杂性及传统情感分析的局限性。

> **摘要翻译:** 散户投资者在社交媒体上的活动激增，以2021年GameStop轧空事件为例，引发了关于在线情绪对股票价格影响的疑问。本文探讨了从社交媒体讨论中提取的情绪是否能有效预测股市波动。我们重点关注Reddit的r/wallstreetbets版块，并分析了与两家公司相关的情绪：GameStop (GME) 和AMC Entertainment (AMC)。为了评估情绪的作用，我们采用了两种现有的基于文本的情绪分析方法，并引入了第三种方法，即一个经过ChatGPT标注和微调的基于RoBERTa的模型，旨在更好地解释社交媒体讨论中普遍存在的非正式语言和表情符号。我们使用相关性和因果关系指标来确定这些模型的预测能力。令人惊讶的是，我们的研究结果表明社交媒体情绪与股票价格仅有微弱相关性。同时，评论量和谷歌搜索趋势等更简单的指标显示出更强的预测信号。这些结果突显了散户投资者行为的复杂性，并表明传统情绪分析可能无法完全捕捉影响市场在线讨论的细微差别。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [78] [How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting](https://arxiv.org/abs/2507.22923)
> *如何以及在哪里翻译？翻译策略对跨语言LLM提示的影响*

*Aman Gupta, Yingying Zhuang, Zhou Yu, Ziji Zhang, Anurag Beniwal* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-21**

**Keywords:** LLM提示, 跨语言, 翻译策略, RAG, 多语言系统

**Comment:** Accepted at Prompt Optimization KDD '25

> **TL;DR:** 本文系统评估了多语言RAG系统中LLM提示的不同翻译策略的影响，发现优化的策略可以显著提高跨语言知识共享和下游任务性能。

**AI_Comments:** 该论文解决了在全球部署LLM，特别是针对低资源语言的一个关键实际挑战。其系统性评估为提示翻译策略提供了明确的指导，这对于改进多语言RAG系统具有高度价值。对优化跨语言提示的强调可能极大地促进LLM能力在非高资源语言中的普及。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务上的表现差异很大。在多语言检索增强生成（RAG）系统中，知识库（KB）通常从高资源语言（如英语）共享到低资源语言，导致从KB检索到的信息与上下文的其余部分语言不同。在这种情况下，预翻译创建单语言提示和跨语言提示直接推理是两种常见做法，但这些选择的影响尚不清楚。

**Method:** 本文系统评估了多语言系统中，RAG增强型LLM在分类任务中不同提示翻译策略的影响。

**Result:** 实验结果表明，优化的提示策略可以显著改善跨语言的知识共享，从而提高下游分类任务的性能。

**Conclusion:** 研究结果倡导更广泛地利用多语言资源共享和针对非英语语言，特别是低资源语言的跨语言提示优化。

> **ai_Abstract:** 本文探讨了跨语言LLM提示中不同翻译策略的影响，特别是在多语言检索增强生成（RAG）系统中。鉴于LLMs在不同语言间的性能差异以及知识库与提示上下文语言不一致的常见问题，本研究系统评估了预翻译和跨语言提示在分类任务中的作用。实验结果表明，采用优化的提示策略能显著增强跨语言知识共享，进而提升下游任务表现。研究结论倡导更广泛地应用多语言资源共享和针对非英语及低资源语言的跨语言提示优化。

> **摘要翻译:** 尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务上的表现差异很大。在多语言检索增强生成（RAG）系统中，知识库（KB）通常从高资源语言（如英语）共享到低资源语言，导致从知识库检索到的信息与上下文的其余部分语言不同。在这种情况下，预翻译以创建单语言提示和跨语言提示进行直接推理是两种常见做法。然而，这些选择的影响尚不清楚。在本文中，我们系统地评估了多语言系统中，RAG增强型LLMs在分类任务中不同提示翻译策略的影响。实验结果表明，优化的提示策略可以显著改善跨语言的知识共享，从而提高下游分类任务的性能。这些发现倡导更广泛地利用多语言资源共享和针对非英语语言，特别是低资源语言的跨语言提示优化。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [79] [MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models](https://arxiv.org/abs/2507.23382)
> *MPCC：多模态大语言模型中具有复杂约束的多模态规划新基准*

*Yiyan Ji, Haoran Chen, Qiguang Chen, Chengyue Wu, Libo Qin, Wanxiang Che* | **Category: cs.CL, cs.AI, cs.CV, I.2.8; I.2.10** | **Updated: 2025-07-31**

**Keywords:** 多模态规划, 复杂约束, MLLM, 基准, 约束感知推理

**Comment:** Accepted to ACM Multimedia 2025

> **TL;DR:** MPCC是一个新的多模态规划基准，包含复杂约束，揭示了当前多模态大语言模型在真实世界规划和约束处理方面的显著不足。

**AI_Comments:** MPCC基准的引入填补了评估多模态大语言模型在处理真实世界复杂多模态约束方面的一个重要空白。其分级难度设计具有创新性，有助于更清晰地理解约束复杂性对模型性能的影响。研究结果明确指出了当前MLLM的主要局限性，强调了开发更鲁棒的约束感知推理能力的必要性，这对MLLM的实际应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多模态规划基准无法直接评估真实世界规划能力，且缺乏跨模态的显式或隐式约束，这阻碍了对多模态大语言模型（MLLM）在复杂推理和决策能力方面的有效评估。

**Method:** 本研究引入了多模态复杂约束规划（MPCC）基准，这是首个系统评估MLLM处理多模态规划中复杂约束能力的基准。MPCC涵盖航班规划、日历规划和会议规划等三个真实世界任务，并引入了预算、时间、空间等复杂约束，同时设置了简单、中等、困难的分级难度，以区分约束复杂性和搜索空间扩展。

**Result:** 对13个先进MLLM的实验表明，模型表现不佳：闭源模型仅能生成21.3%的可行计划，而开源模型平均低于11%。此外，MLLM对约束复杂性高度敏感，且传统的多模态提示策略在多约束场景中失效。

**Conclusion:** 本研究工作规范了规划中的多模态约束，提供了一个严谨的评估框架，并强调了在真实世界MLLM应用中，推进约束感知推理能力的紧迫性。

> **ai_Abstract:** 本文提出了MPCC，一个新颖的基准，旨在评估多模态大语言模型（MLLM）在具有复杂真实世界约束的多模态规划任务中的能力。MPCC解决了现有基准的局限性，包含了如航班和日历规划等任务，并融入了预算、时间、空间等复杂约束，且设有不同难度等级。对13个MLLM的实验结果显示，模型在生成可行计划方面的表现非常差，且对约束复杂性高度敏感，这揭示了当前MLLM在处理真实世界受限规划方面存在显著的差距。

> **摘要翻译:** 多模态规划能力是指在多模态语境下预测、推理和设计任务执行步骤的能力，这对于跨多步骤的复杂推理和决策至关重要。然而，当前的基准面临两个关键挑战：(1) 它们无法直接评估多模态真实世界规划能力；(2) 它们缺乏跨模态的约束或隐式约束。为了解决这些问题，我们引入了多模态复杂约束规划（MPCC），这是第一个系统评估多模态大语言模型（MLLM）处理规划中多模态约束能力的基准。为了解决第一个挑战，MPCC专注于三个真实世界的任务：航班规划、日历规划和会议规划。为了解决第二个挑战，我们在这些任务中引入了复杂约束（例如预算、时间和空间），并设置了分级难度（简单、中等、困难），以将约束复杂性与搜索空间扩展分开。对13个先进MLLM的实验揭示了严峻的挑战：闭源模型仅实现了21.3%的可行计划，而开源模型平均低于11%。此外，我们观察到MLLM对约束复杂性高度敏感，并且传统的多模态提示策略在多约束场景中失效。我们的工作规范了规划中的多模态约束，提供了一个严格的评估框架，并强调了在真实世界MLLM应用中推进约束感知推理的必要性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [80] [Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance](https://arxiv.org/abs/2504.09753)
> *提高大型语言模型的多语言能力并增强其原生性能，同时融入文化和本地知识*

*Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Siddhant Gupta, Drishti Sharma, Jebish Purbey, Kanwal Mehreen, Muhammad Arham, Suman Debnath, Hamza Farooq* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 多语言LLM, 印地语-英语, 指令微调, 低资源语言, 文化知识

**Comment:** 24 pages, 18 figures

> **TL;DR:** 本文提出了Mantra-14B，一个印地语-英语双语大型语言模型，通过使用精选的文化和本地化指令数据集进行适度微调，在不牺牲原生性能的情况下，显著提高了多语言能力，甚至超越了两倍大小的模型，且避免了资源密集型技术。

**AI_Comments:** 这项研究的创新之处在于其高效地提升了LLM的多语言能力，特别是在低资源语言方面，而无需采用资源密集型技术。通过适度的微调和精心策划的文化及本地化数据集，实现了显著的性能提升并保持了模型的小尺寸，这对于实际应用和资源受限的环境非常重要。开源其代码、数据集和模型也极大地促进了该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的发展主要集中在英语和其他高资源语言上，导致许多其他语言的服务不足和性能差距。

**Method:** 研究人员构建了一个包含48.5万个英语和印地语指令数据的精选数据集，并使用该数据集对Qwen-2.5-14B-Instruct和Phi-4等模型进行了指令微调。该方法避免了词汇扩展或架构修改等资源密集型技术。

**Result:** 研究提出了Mantra-14B，一个印地语-英语双语LLM，其基准分数在两种语言上平均提高了约3%，并超越了两倍大小的模型。实验涉及七种不同参数大小的LLM和超过140次训练尝试，证明了在不损害原生性能的情况下显著提高多语言性能是可能的。

**Conclusion:** 通过使用文化和本地化信息数据进行适度微调，可以在不产生显著计算开销的情况下弥合大型语言模型的性能差距，从而有效提升多语言能力同时保持原生性能。

> **ai_Abstract:** 本文介绍了一个名为Mantra-14B的印地语-英语双语大型语言模型，旨在解决LLMs在非高资源语言中表现不佳的问题。通过使用一个包含48.5万个样本的精选印地语-英语指令数据集对现有模型进行指令微调，研究团队在不进行词汇扩展或架构修改的情况下，实现了约3%的平均基准分数提升，并超越了体量是其两倍的模型。这项工作证明了通过适度的微调和利用文化及本地化数据，可以在不牺牲原生性能的前提下显著增强LLMs的多语言能力。研究团队还开源了训练代码、数据集和模型，以促进对低资源语言的进一步研究。

> **摘要翻译:** 大型语言模型（LLM）展现出卓越的能力，但其发展主要集中在英语和其他高资源语言上，导致许多语言服务不足。我们展示了我们最新的印地语-英语双语LLM **Mantra-14B**，其在两种语言的基准测试分数上平均提高了约3%，并且超越了其两倍大小的模型。我们使用一个由48.5万个英语和印地语指令数据组成的精选数据集，对Qwen-2.5-14B-Instruct和Phi-4等模型进行了指令微调，以提高其在英语和印地语上的性能。我们的实验涵盖了七种不同参数大小的LLM和超过140次训练尝试，使用了不同比例的英语-印地语训练数据，结果表明在不损害原生性能的情况下显著提高多语言性能是可能的。此外，我们的方法避免了词汇扩展或架构修改等资源密集型技术，从而保持了模型的小尺寸。我们的结果表明，通过使用文化和本地化信息数据进行适度微调，可以在不产生显著计算开销的情况下弥合性能差距。我们将在MIT和Apache许可下发布我们的训练代码、数据集和模型，以帮助进一步研究未充分代表和低资源的语言。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [89] [Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories](https://arxiv.org/abs/2504.16604)
> *用对话揭穿？探索人工智能生成的反驳言论以挑战阴谋论*

*Mareike Lisker, Christina Gottschalk, Helena Mihaljević* | **Category: cs.CL, cs.AI, cs.SI, I.2.7** | **Updated: 2025-08-01**

**Keywords:** 阴谋论, 反驳言论, 大型语言模型, GPT-4o, 幻觉

**Comment:** 16 pages, Association for Computational Linguistics, Proceedings of
  the 9th Workshop on Online Abuse and Harms (WOAH 2025)

> **TL;DR:** 大型语言模型（LLM）可以生成反驳阴谋论的言论，但目前模型如GPT-4o、Llama 3和Mistral生成的内容常通用、重复、肤浅且存在幻觉，限制了实际应用。

**AI_Comments:** 这篇论文揭示了当前大型语言模型在揭穿阴谋论这一敏感领域的一个关键局限性。尽管大型语言模型提供了可扩展性，但它们倾向于产生通用、重复的反应，尤其是幻觉，这使得它们在需要事实准确性和细致沟通的任务中不可靠。这项研究强调，在将大型语言模型有效部署到高风险信息干预之前，需要更专业的训练数据和改进的事实基础机制。

<details>
  <summary>Details</summary>

**Motivation:** 反驳言论是应对有害在线内容的关键策略，但专家驱动的工作难以规模化。大型语言模型（LLM）提供了一个潜在解决方案，然而它们在反驳阴谋论方面的应用尚未得到充分研究，且缺乏相关数据集。

**Method:** 研究评估了GPT-4o、Llama 3和Mistral通过结构化提示应用源自心理学研究的反驳言论策略的能力。

**Result:** 模型生成的反驳言论通常是通用、重复或肤浅的。此外，它们过度承认恐惧，并频繁地臆造事实、来源或数据。

**Conclusion:** 鉴于当前大型语言模型在生成反驳阴谋论言论时存在质量问题（通用、重复、肤浅、幻觉），其基于提示的实际应用存在问题。

> **ai_Abstract:** 本论文探讨了大型语言模型（LLM）如GPT-4o、Llama 3和Mistral在生成反驳在线阴谋论言论方面的潜力，以解决专家驱动方法的可扩展性问题和相关数据集的缺乏。通过评估模型在结构化提示下应用心理学反驳策略的能力，研究发现当前LLM生成的内容通常是通用、重复、肤浅且存在事实错误（幻觉）的，这表明它们在揭穿阴谋论的实际应用中存在显著局限性。

> **摘要翻译:** 反驳言论是应对有害在线内容的关键策略，但扩大专家驱动的工作面临挑战。大型语言模型（LLM）提供了一个潜在的解决方案，尽管它们在反驳阴谋论方面的应用尚未得到充分研究。与仇恨言论不同，目前没有将阴谋论评论与专家精心制作的反驳言论配对的数据集。我们通过评估GPT-4o、Llama 3和Mistral在通过结构化提示提供的心理学研究中有效应用反驳言论策略的能力来弥补这一空白。我们的结果表明，这些模型通常生成通用、重复或肤浅的结果。此外，它们过度承认恐惧，并频繁地臆造事实、来源或数据，使得它们在实际应用中基于提示的使用存在问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [92] [Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers](https://arxiv.org/abs/2507.22924)
> *使用情感分析调查母语和非母语英语使用者之间的同行反馈*

*Brittney Exline, Melanie Duffin, Brittany Harbison, Chrissa da Gomez, David Joyner* | **Category: cs.CL, I.2.7; K.3.1** | **Updated: 2025-07-23**

**Keywords:** 情感分析, 同行反馈, 母语使用者, 非母语使用者, 在线教育

**Comment:** 

> **TL;DR:** 本研究使用情感分析调查了在线美国计算机课程中，母语和非母语英语使用者之间同行反馈的情感差异，发现语言背景对反馈体验有复杂影响。

**AI_Comments:** 这项研究通过引入情感分析方法，为理解在线学习环境中语言背景对同行反馈质量和感知的影响提供了新的视角，具有创新性。其发现揭示了国际学生在英语学习环境中所面临的潜在沟通和反馈接收挑战，对在线教育的教学设计和教师培训具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着美国研究生CS项目中国际学生人数的增加（2023年硕士学位60.2%授予非美国学生），其中许多学生参加在线课程，同行反馈在这些课程中用于学生参与和教学改进。由于课程以英语进行，许多学生使用非母语学习，因此有必要研究母语和非母语英语使用者身份如何影响在线计算课程中同行反馈体验的三个指标。

**Method:** 本研究使用基于Twitter-roBERTa的模型，分析了500名学生的随机样本中，由他们撰写和接收的同行评审的情感。然后将情感得分和同行反馈评级与学生的语言背景相关联，并控制了性别和年龄。

**Result:** 结果显示，母语为英语的学生对反馈的评价较低，而非母语为英语的学生写出的反馈更积极，但收到的积极情感较少。在控制性别和年龄后，出现了显著的交互作用，表明语言背景在塑造同行反馈体验中扮演着适度但复杂的角色。

**Conclusion:** 语言背景在塑造在线美国计算课程中，母语和非母语英语使用者之间的同行反馈体验中，扮演着适度但复杂的角色。

> **ai_Abstract:** 本研究调查了在美国在线计算机研究生课程中，母语和非母语英语使用者之间同行反馈的情感差异。利用Twitter-roBERTa模型对500名学生的同行评审进行情感分析，并将结果与学生的语言背景、性别和年龄关联。研究发现，母语使用者对反馈评价较低，而非母语使用者书写反馈更积极但收到的积极情感较少，表明语言背景对同行反馈体验有复杂影响。

> **摘要翻译:** 美国研究生计算机科学项目招收的国际学生越来越多，2023年有60.2%的硕士学位授予非美国学生。这些学生中有许多人参加在线课程，其中同行反馈被用于吸引学生并以可扩展的方式改进教学。由于这些课程以英语进行，许多学生使用非母语学习。本文探讨了母语和非母语英语使用者身份如何影响在线美国计算课程中同行反馈体验的三个指标。我们使用基于Twitter-roBERTa的模型，分析了500名学生随机样本中，由他们撰写和接收的同行评审的情感。然后我们将情感得分和同行反馈评级与学生的语言背景相关联。结果显示，母语为英语的学生对反馈的评价较低，而非母语为英语的学生写出的反馈更积极，但收到的积极情感较少。在控制性别和年龄后，出现了显著的交互作用，表明语言背景在塑造同行反馈体验中扮演着适度但复杂的角色。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [107] [Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models](https://arxiv.org/abs/2507.23386)
> *Causal2Vec：改进仅解码器LLMs作为多功能嵌入模型*

*Ailiang Lin, Zhuoyun Li, Kotaro Funakoshi* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 仅解码器LLM, 嵌入模型, 因果注意力, 文本嵌入, Causal2Vec

**Comment:** 

> **TL;DR:** Causal2Vec通过引入轻量级预编码器和特殊的池化策略，显著提升了仅解码器LLM作为嵌入模型的性能，在MTEB基准上实现了SOTA，并大幅减少了计算成本。

**AI_Comments:** Causal2Vec的创新之处在于其独特且轻量级的预编码和池化策略，它在不改变LLM核心架构的前提下，解决了仅解码器模型在嵌入任务中的固有挑战。其重要性体现在显著提升了性能，并大幅降低了计算成本，尤其是在序列长度和推理时间上的优化，使其在实际应用中更具吸引力。尽管抽象中未明确提及局限性，但该方法主要在检索数据集上进行了验证，其在其他更广泛的嵌入任务上的泛化能力可能需要进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有将仅解码器大型语言模型（LLMs）用作嵌入模型的方法存在局限性：移除因果注意力掩码可能损害模型预训练获得的语义信息，而依赖额外输入文本则会增加计算成本。因此，需要一种能在不改变LLM原始架构或引入显著计算开销的情况下提升其性能的方法。

**Method:** 本文提出了Causal2Vec。首先，使用一个轻量级BERT风格模型将输入文本预编码成一个单一的“上下文”（Contextual）标记。然后，将此标记添加到LLM的输入序列之前，使每个标记都能捕获上下文信息。为了减轻近因偏见并更好地利用上下文信息，将“上下文”标记和EOS标记的最后一个隐藏状态连接起来作为最终的文本嵌入。

**Result:** Causal2Vec在大型文本嵌入基准（MTEB）上，在仅使用公开可用检索数据集训练的模型中，达到了最先进的性能。与表现最佳的方法相比，所需的序列长度减少了高达85%，推理时间减少了高达82%。

**Conclusion:** Causal2Vec通过创新的轻量级预编码和池化策略，有效提升了仅解码器LLM在嵌入任务中的表现，同时解决了现有方法的局限性，实现了卓越的性能和显著的计算效率提升，且无需改变LLM的原始架构。

> **ai_Abstract:** 本文提出了Causal2Vec，一种旨在提升仅解码器LLM作为通用嵌入模型性能的新方法。它通过引入一个轻量级BERT风格预编码器生成“上下文”标记，并采用将“上下文”和EOS标记的隐藏状态连接作为最终嵌入的策略，有效克服了现有方法（如因果注意力限制和高计算成本）的缺点。Causal2Vec在MTEB基准上取得了最先进的性能，同时显著减少了序列长度和推理时间，且无需修改LLM的原始架构。

> **摘要翻译:** 仅解码器大型语言模型（LLMs）正越来越多地被用于构建嵌入模型，这些模型能有效地将自然语言文本的语义信息编码成密集向量表示，以用于各种嵌入任务。然而，许多现有方法主要侧重于移除LLM中的因果注意力掩码以实现双向注意力，这可能损害模型在预训练期间获取语义信息的能力。此外，领先的单向方法通常依赖额外的输入文本来克服因果注意力的固有局限性，不可避免地增加了计算成本。在这项工作中，我们提出了Causal2Vec，一个通用嵌入模型，旨在在不改变其原始架构或引入显著计算开销的情况下，提高仅解码器LLM的性能。具体来说，我们首先采用一个轻量级BERT风格模型将输入文本预编码成一个单一的“上下文”（Contextual）标记，然后将其添加到LLM的输入序列之前，从而使每个标记即使在不关注未来标记的情况下也能捕获上下文信息。此外，为了减轻由最后一个标记池化引入的近因偏见，并帮助LLM更好地利用编码在“上下文”标记中的语义信息，我们将“上下文”标记和EOS标记的最后一个隐藏状态连接起来作为最终的文本嵌入。在实践中，Causal2Vec在仅使用公开可用的检索数据集训练的模型中，在大型文本嵌入基准（MTEB）上达到了最先进的性能，同时与表现最佳的方法相比，所需的序列长度减少了高达85%，推理时间减少了高达82%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [120] [Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents](https://arxiv.org/abs/2507.22925)
> *LLM智能体中用于高效长期推理的分层记忆*

*Haoran Sun, Shaoning Zeng* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-23**

**Keywords:** 分层记忆, LLM智能体, 长期推理, 记忆检索, 语义抽象

**Comment:** 

> **TL;DR:** 提出了一种名为H-MEM的分层记忆架构，通过多层次组织和索引路由机制，显著提高了LLM智能体在长期推理任务中的记忆检索效率和性能。

**AI_Comments:** 该论文的创新点在于提出了分层记忆架构，并通过引入位置索引和索引路由机制，解决了现有LLM智能体记忆机制中结构化组织不足和检索效率低下的问题。这种方法避免了传统基于相似度搜索的计算开销，对于提升LLM在复杂、长期推理任务中的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型智能体（LLM Agents）在长期推理能力上受到记忆机制的限制，当前的记忆存储和检索方法（如基于相似度的向量搜索或图组织）在结构化记忆组织和高效检索方面存在不足。

**Method:** 本文提出了一种名为分层记忆（H-MEM）的架构，它根据语义抽象程度以多层次方式组织和更新记忆。每个记忆向量都嵌入了一个指向下一层语义相关子记忆的位置索引编码。在推理阶段，通过基于索引的路由机制实现高效的逐层检索，无需进行穷尽的相似度计算。

**Result:** 在LoCoMo数据集的五个任务设置上进行评估，实验结果表明该方法持续优于五种基线方法。

**Conclusion:** H-MEM架构通过其独特的分层组织和高效的索引路由机制，有效解决了LLM智能体在长期推理中记忆组织和检索的效率问题，显著提升了其在长期对话场景中的表现。

> **ai_Abstract:** 本文提出了一种名为分层记忆（H-MEM）的新型架构，旨在提升大型语言模型智能体（LLM Agents）的长期推理能力。H-MEM通过多层次地组织和更新记忆，并为每个记忆向量嵌入指向其子记忆的位置索引。这种设计结合了基于索引的路由机制，实现了高效的逐层记忆检索，避免了耗时的相似度计算。实验结果表明，H-MEM在LoCoMo数据集上的表现优于现有基线方法，验证了其在长期对话场景中的有效性。

> **摘要翻译:** 长期记忆是影响大型语言模型智能体（LLM Agents）推理能力的关键因素之一。整合有效融合过去交互的记忆机制可以显著增强LLM智能体的决策能力和上下文连贯性。尽管最近的工作在记忆存储和检索方面取得了进展，例如将记忆编码成密集向量进行基于相似度的搜索或以图的形式组织知识，但这些方法往往在结构化记忆组织和高效检索方面存在不足。为了解决这些限制，我们为LLM智能体提出了一种分层记忆（H-MEM）架构，它根据语义抽象程度以多层次方式组织和更新记忆。每个记忆向量都嵌入了一个指向下一层语义相关子记忆的位置索引编码。在推理阶段，基于索引的路由机制能够实现高效的逐层检索，而无需执行穷尽的相似度计算。我们在LoCoMo数据集的五个任务设置上评估了我们的方法。实验结果表明，我们的方法持续优于五种基线方法，证明了其在长期对话场景中的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [122] [Robust and Fine-Grained Detection of AI Generated Texts](https://arxiv.org/abs/2504.11952)
> *鲁棒且细粒度的AI生成文本检测*

*Ram Mohan Rao Kadiyala, Siddartha Pullakhandam, Kanwal Mehreen, Drishti Sharma, Siddhant Gupta, Jebish Purbey, Ashay Srivastava, Subhasya TippaReddy, Arvind Reddy Bobbili, Suraj Telugara Chandrashekhar, Modabbir Adeeb, Srinadh Vura, Suman Debnath, Hamza Farooq* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** AI生成文本检测, token分类, 人机合著文本, 大语言模型, 数据集

**Comment:** 18 pages, 6 figures

> **TL;DR:** 本文提出了一套基于token分类的模型，用于检测人类与LLM合著的文本，并在未见领域、生成器、非母语者和对抗性输入上表现良好，同时引入了一个包含240万多条多语言合著文本的新数据集。

**AI_Comments:** 本文的创新点在于专注于处理人类与LLM合著的“部分案例”，这反映了对当前AI内容生成复杂性的深刻理解。引入一个包含240万多条多语言合著文本的新数据集是其重要贡献，为未来研究提供了宝贵的资源。模型在未见领域和对抗性输入上的良好表现，也凸显了其鲁棒性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 理想的机器生成内容检测系统应能适应不断涌现的新LLM。现有系统在短文本上难以准确识别AI生成内容，且无法有效处理人类与LLM合著的文本（部分案例），这促使了本研究的进行。

**Method:** 本文引入了一套用于token分类的模型，这些模型在一个包含大量人类与机器合著文本的数据集上进行训练。同时，作者还构建了一个新的数据集，包含超过240万条主要由流行专有LLM合著的23种语言的文本。

**Result:** 模型在未见领域、未见生成器、非母语者文本以及对抗性输入上表现良好。研究还展示了模型在不同领域和生成器文本上的性能，并比较了模型在对抗性方法、输入文本长度以及生成文本特征与原始人类文本之间的性能。

**Conclusion:** 本文成功开发了一套鲁棒且细粒度的AI生成文本检测系统，特别针对人类与LLM合著文本，并在多种复杂情况下表现出良好的性能，同时贡献了一个大型多语言合著文本数据集。

> **ai_Abstract:** 本文针对AI生成内容检测中现有系统在短文本和人机合著文本上的不足，提出了一套基于token分类的模型。这些模型在一个包含240万多条多语言人机合著文本的新数据集上进行训练，并在未知领域、生成器、非母语者文本和对抗性输入上展现出鲁棒且细粒度的检测能力。研究还对比了模型在不同条件下的性能，为AI生成文本检测提供了新的解决方案和大规模数据集。

> **摘要翻译:** 一个理想的机器生成内容检测系统应该能够很好地适用于任何生成器，因为每天都有更多先进的LLM出现。现有系统在准确识别较短文本中的AI生成内容时常常遇到困难。此外，并非所有文本都可能完全由人类或LLM撰写，因此我们更关注部分情况，即人类与LLM合著的文本。我们的论文介绍了一套为token分类任务而构建的模型，这些模型在一个广泛的人机合著文本集合上进行训练，并在未见领域、未见生成器、非母语者撰写的文本以及具有对抗性输入的文本上表现良好。我们还引入了一个包含超过240万条此类文本的新数据集，这些文本主要由几个流行的专有LLM以23种语言合著。我们还展示了我们的模型在每个领域和生成器的文本上的性能结果。其他发现包括与每种对抗性方法、输入文本长度以及生成文本与原始人类撰写文本特征的性能比较。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [134] [Multi-Relation Extraction in Entity Pairs using Global Context](https://arxiv.org/abs/2507.22926)
> *实体对中基于全局上下文的多关系抽取*

*Nilesh, Atul Gupta, Avinash C Panday* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-23**

**Keywords:** 文档级关系抽取, 全局上下文, 多关系抽取, 实体对, 输入嵌入

**Comment:** 11 pages, 9 figures

> **TL;DR:** 本文提出一种新的输入嵌入方法，通过捕获文档中实体提及的全局位置来处理文档级关系抽取，优于仅关注实体出现句子的传统方法，并在DocRED、Re-DocRED和REBEL基准数据集上表现良好。

**AI_Comments:** 本文的创新点在于提出了一个新颖的输入嵌入方法，通过捕获文档中实体提及的全局位置并将其表示为独立段落，有效解决了传统方法仅关注局部上下文的局限性。这对于文档级关系抽取中的全局上下文建模和多句推理是一个重要的进步，有望提升实际NLP应用的性能。

<details>
  <summary>Details</summary>

**Motivation:** 在文档级关系抽取中，现有方法仅关注实体出现的句子，无法捕获完整的文档上下文，导致不能准确预测实体间的关系。

**Method:** 本文提出一种新颖的输入嵌入方法，该方法通过捕获文档中实体在整个文档中的提及位置，而不是仅仅关注它们出现的局部跨度。所提出的方法将实体表示为独立的段落，独立于它们在文档中的位置，从而利用全局关系和多句推理。

**Result:** 所提出的方法在DocRED、Re-DocRED和REBEL三个基准关系抽取数据集上进行了测试。实验结果表明，该方法在文档级设置中能够准确预测实体之间的关系。

**Conclusion:** 该研究在理论上推进了文档级关系抽取中的全局上下文建模和多句推理，在实践中增强了关系检测能力，提高了需要全面实体级洞察和可解释性的实际NLP应用的性能。

> **ai_Abstract:** 本文针对文档级关系抽取中现有方法未能捕获完整文档上下文的问题，提出了一种新颖的输入嵌入方法。该方法通过捕获文档中实体提及的全局位置，并将实体表示为独立的段落，以实现全局上下文建模和多句推理。实验结果表明，该方法在DocRED、Re-DocRED和REBEL等基准数据集上能准确预测实体关系，具有重要的理论和实践意义。

> **摘要翻译:** 在文档级关系抽取中，实体可能在文档中多次出现，并且它们的关系可以从一个上下文转移到另一个上下文。准确预测整个文档中两个实体之间的关系需要构建一个涵盖所有相关句子的全局上下文。以前的方法只关注实体被提及的句子，这未能捕获准确关系抽取所需的完整文档上下文。因此，本文引入了一种新颖的输入嵌入方法，以捕获文档中实体提及的位置，而不是仅仅关注它们出现的跨度。所提出的输入编码方法通过将实体表示为独立的段落，独立于它们在文档中的位置，从而利用全局关系和多句推理。该方法的性能已在DocRED、Re-DocRED和REBEL三个基准关系抽取数据集上进行了测试。实验结果表明，所提出的方法在文档级设置中准确预测了实体之间的关系。所提出的研究也具有理论和实践意义。理论上，它推动了文档级关系抽取中的全局上下文建模和多句推理。实际上，它增强了关系检测，从而提高了在需要全面实体级洞察和可解释性的实际NLP应用中的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [135] [MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization](https://arxiv.org/abs/2507.23400)
> *MRGSEM-Sum：一种基于多关系图和结构熵最小化的无监督多文档摘要框架*

*Yongbing Zhang, Fang Nan, Shengxiang Gao, Yuxin Huang, Kaiwen Tan, Zhengtao Yu* | **Category: cs.CL, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 多文档摘要, 无监督学习, 多关系图, 结构熵最小化, 图聚类

**Comment:** 

> **TL;DR:** MRGSEM-Sum是一种无监督多文档摘要框架，它使用多关系图和结构熵最小化来解决文档间复杂关系和信息冗余问题，性能优于现有无监督方法，并接近监督模型和大型语言模型。

**AI_Comments:** MRGSEM-Sum的创新之处在于引入多关系图来全面捕捉句子间的复杂关系，以及利用结构熵最小化实现无监督的自适应聚类，无需预设聚类数量。其在无监督设置下达到与监督模型和大型语言模型相媲美的性能，显示了其重要性和潜力，尤其是在数据标注成本高昂的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 多文档摘要面临文档间关系复杂性和信息冗余的核心挑战。现有图聚类方法通常只考虑单关系图，且需要预定义聚类数量，这限制了它们充分表示丰富关系信息和自适应划分句子组以减少冗余的能力。

**Method:** 本文提出了MRGSEM-Sum，一个无监督多文档摘要框架。具体方法包括：首先，构建一个集成语义和语篇关系的多关系图，全面建模文档间句子之间复杂动态的连接。其次，应用二维结构熵最小化算法进行聚类，自动确定最佳聚类数量并有效地将句子组织成连贯的组。最后，引入位置感知压缩机制来提炼每个聚类，生成简洁且信息丰富的摘要。

**Result:** 在四个基准数据集（Multi-News、DUC-2004、PubMed和WikiSum）上进行的广泛实验表明，MRGSEM-Sum始终优于以前的无监督方法，并且在某些情况下，其性能可与监督模型和大型语言模型相媲美。人工评估表明，MRGSEM-Sum生成的摘要表现出高一致性和覆盖率，接近人类水平的质量。

**Conclusion:** MRGSEM-Sum通过引入多关系图和结构熵最小化，有效地解决了多文档摘要中的复杂关系和信息冗余问题，实现了卓越的性能，并生成了高质量的摘要。

> **ai_Abstract:** 本文提出了MRGSEM-Sum，一个无监督多文档摘要框架，旨在解决现有图聚类方法在处理复杂文档关系和信息冗余方面的局限性。MRGSEM-Sum通过构建整合语义和语篇关系的多关系图，并利用二维结构熵最小化算法进行自适应聚类，自动确定最佳聚类数量。结合位置感知压缩机制，该框架能生成高质量的摘要。实验证明，MRGSEM-Sum在多个数据集上优于现有无监督方法，并接近监督模型和大型语言模型的性能，人工评估也证实其摘要质量接近人类水平。

> **摘要翻译:** 多文档摘要面临的核心挑战是文档间关系的复杂性和信息冗余的存在。图聚类是解决此问题的有效范式，因为它使用图结构建模文档间的复杂关系，并通过聚类减少信息冗余，取得了显著的研究进展。然而，现有方法通常只考虑单关系图，并且需要预定义聚类数量，这阻碍了它们充分表示丰富关系信息和自适应划分句子组以减少冗余的能力。为了克服这些限制，我们提出了MRGSEM-Sum，一个基于多关系图和结构熵最小化的无监督多文档摘要框架。具体来说，我们构建了一个多关系图，该图集成了句子间的语义和语篇关系，全面建模了文档间句子之间复杂动态的连接。然后，我们应用二维结构熵最小化算法进行聚类，自动确定最佳聚类数量并有效地将句子组织成连贯的组。最后，我们引入了位置感知压缩机制来提炼每个聚类，生成简洁且信息丰富的摘要。在四个基准数据集（Multi-News、DUC-2004、PubMed和WikiSum）上进行的广泛实验表明，我们的方法始终优于以前的无监督方法，并且在某些情况下，其性能可与监督模型和大型语言模型相媲美。人工评估表明，MRGSEM-Sum生成的摘要表现出高一致性和覆盖率，接近人类水平的质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [162] [How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding](https://arxiv.org/abs/2507.22928)
> *链式思考是如何思考的？通过稀疏自编码对链式思考推理进行机制可解释性研究*

*Xi Chen, Aske Plaat, Niki van Stein* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 链式思考, 机制可解释性, 稀疏自编码, 激活修补, 大型语言模型

**Comment:** 

> **TL;DR:** 本文通过特征级因果研究，结合稀疏自编码和激活修补，发现CoT提示在大型LLM（如Pythia-2.8B）中能诱导更可解释的内部结构，提高模型性能和信心，但在小型模型（Pythia-70M）中效果不明显，揭示了明显的规模阈值。

**AI_Comments:** 这篇论文的创新点在于首次从特征层面，结合稀疏自编码和激活修补，对CoT的内部推理机制进行了因果研究，提供了关于CoT“思考”忠实度的有力证据。它不仅验证了CoT的有效性，更揭示了CoT对LLM内部结构（如激活稀疏性、特征可解释性）的影响，并明确了其效果存在的模型规模阈值，这对理解和优化LLM的推理过程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 链式思考（CoT）提示虽能提高大型语言模型在多步任务上的准确性，但其生成的“思考”是否反映了真实的内部推理过程尚未解决。

**Method:** 结合稀疏自编码器和激活修补技术，从Pythia-70M和Pythia-2.8B模型中提取单义特征。在这些模型处理GSM8K数学问题时，比较CoT和普通（noCoT）提示的效果。通过将少量CoT推理特征交换到noCoT运行中，进行特征级因果研究。引入了patch-curves和random-feature patching基线。

**Result:** 将少量CoT推理特征交换到noCoT运行中，在2.8B模型中显著提高了答案的对数概率，但在70M模型中没有可靠效果，揭示了明显的规模阈值。CoT还在较大模型中导致显著更高的激活稀疏性和特征可解释性分数，表明内部计算更模块化。例如，模型生成正确答案的信心从1.2提高到4.3。有用的CoT信息不仅存在于top-K补丁中，而且广泛分布。

**Conclusion:** 我们的结果表明，CoT可以在高容量LLM中诱导更可解释的内部结构，验证了其作为结构化提示方法的有效性。

> **ai_Abstract:** 本文通过结合稀疏自编码器和激活修补，对链式思考（CoT）提示在大型语言模型中的内部推理过程进行了首次特征级因果研究。研究发现，CoT提示能够在大容量模型（如Pythia-2.8B）中诱导更具可解释性的内部结构，显著提高模型性能和信心，并促进更模块化的内部计算。然而，这种效果在小型模型（如Pythia-70M）中不明显，揭示了CoT有效性的规模阈值。研究还表明，CoT相关的有用信息广泛分布于模型内部。这些发现验证了CoT作为一种结构化提示方法，能够促使高容量LLM形成更可解释的内部推理机制。

> **摘要翻译:** **论文题目：** 链式思考是如何思考的？通过稀疏自编码对链式思考推理进行机制可解释性研究

**论文摘要：** 链式思考（CoT）提示显著提升了大型语言模型在多步任务上的准确性，然而，生成的“思考”是否反映了真实的内部推理过程仍未解决。我们首次提出了CoT忠实度的特征级因果研究。结合稀疏自编码器和激活修补技术，我们从Pythia-70M和Pythia-2.8B模型中提取了单义特征，同时它们在CoT和普通（noCoT）提示下解决GSM8K数学问题。将少量CoT推理特征交换到noCoT运行中，在2.8B模型中显著提高了答案的对数概率，但在70M模型中没有可靠效果，揭示了明显的规模阈值。CoT还在较大模型中导致显著更高的激活稀疏性和特征可解释性分数，表明内部计算更模块化。例如，模型生成正确答案的信心从1.2提高到4.3。我们引入了patch-curves和random-feature patching基线，表明有用的CoT信息不仅存在于top-K补丁中，而且广泛分布。总的来说，我们的结果表明CoT可以在高容量LLM中诱导更可解释的内部结构，验证了其作为结构化提示方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [163] [Enhanced Arabic Text Retrieval with Attentive Relevance Scoring](https://arxiv.org/abs/2507.23404)
> *增强型阿拉伯语文本检索与注意力相关性评分*

*Salah Eddine Bekhouche, Azeddine Benlamoudi, Yazid Bounab, Fadi Dornaika, Abdenour Hadid* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 阿拉伯语文本检索, 密集段落检索, 注意力相关性评分, 自然语言处理, 信息检索

**Comment:** 

> **TL;DR:** 针对阿拉伯语文本检索，本文提出了一种增强型密集段落检索（DPR）框架，核心是新颖的注意力相关性评分（ARS），能够有效提高检索性能和排名准确性。

**AI_Comments:** 该论文通过引入注意力相关性评分（ARS）和专门为阿拉伯语优化的DPR框架，有效地解决了阿拉伯语文本检索的特有挑战。其创新性在于ARS替代了传统交互机制，能够更精细地捕捉语义关联，对于资源相对匮乏的阿拉伯语NLP领域具有重要意义。代码的公开也促进了研究的复现和发展。

<details>
  <summary>Details</summary>

**Motivation:** 阿拉伯语因其复杂的形态、可选的变音符号以及现代标准阿拉伯语和各种方言的共存，对自然语言处理（NLP）和信息检索（IR）构成了特殊挑战。尽管其全球重要性日益增长，但在NLP研究和基准资源中仍代表不足。

**Method:** 本文提出了一种专门为阿拉伯语开发的增强型密集段落检索（DPR）框架。其核心是新颖的注意力相关性评分（ARS），用自适应评分函数取代了标准交互机制，以更有效地建模问题与段落之间的语义相关性。该方法还集成了预训练的阿拉伯语语言模型和架构改进。

**Result:** 该方法提高了检索性能，并显著增加了回答阿拉伯语问题时的排名准确性。

**Conclusion:** 通过提出的增强型密集段落检索（DPR）框架和新颖的注意力相关性评分（ARS），可以有效克服阿拉伯语文本检索的挑战，显著提升检索和排名性能。

> **ai_Abstract:** 本文针对阿拉伯语在自然语言处理和信息检索中的挑战，提出了一种增强型密集段落检索（DPR）框架。该框架的核心是新颖的注意力相关性评分（ARS），它通过自适应评分函数更有效地建模问题与段落间的语义相关性。结合预训练的阿拉伯语语言模型和架构改进，该方法显著提升了阿拉伯语文本检索的性能和排名准确性。

> **摘要翻译:** 阿拉伯语由于其复杂的形态、可选的变音符号以及现代标准阿拉伯语（MSA）和各种方言的共存，对自然语言处理（NLP）和信息检索（IR）构成了特殊挑战。尽管阿拉伯语的全球重要性日益增长，但在NLP研究和基准资源中，它仍然代表不足。在本文中，我们提出了一种专门为阿拉伯语开发的增强型密集段落检索（DPR）框架。我们方法的核心是一种新颖的注意力相关性评分（ARS），它用自适应评分函数取代了标准交互机制，从而更有效地建模问题与段落之间的语义相关性。我们的方法集成了预训练的阿拉伯语语言模型和架构改进，以提高检索性能并显著增加回答阿拉伯语问题时的排名准确性。代码已在GitHub上公开。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [171] [Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation](https://arxiv.org/abs/2504.16060)
> *视觉-语言模型在指称表达生成中不具备语用能力*

*Ziqiao Ma, Jing Ding, Xuejun Zhang, Dezhi Luo, Jiahe Ding, Sihan Xu, Yuchen Huang, Run Peng, Joyce Chai* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 指称表达生成, 语用能力, 视觉-语言模型, 数据集, 评估

**Comment:** COLM 2025 & CVinW @ CVPR 2025 (Spotlight). Homepage:
  https://vlm-reg.github.io/

> **TL;DR:** 视觉-语言模型在指称表达生成（REG）中缺乏语用能力，现有评估方法忽视了语用维度。本研究引入新数据集并系统评估了最先进的视觉-语言模型，揭示了其在语用方面的三项主要失败，并指出标准自动化评估未能捕捉这些语用违规。

**AI_Comments:** 该论文通过引入新的数据集和系统的评估方法，深刻揭示了当前视觉-语言模型在指称表达生成任务中存在的语用能力缺陷，这是对现有评估范式的重要批判和补充。其创新性在于将Gricean原则引入VLM的评估，并明确指出了模型在实际交流中可能遇到的具体问题，如冗余信息和对人类偏好的误解。这对于推动VLM向更自然、更有效的人机交互发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉-语言模型（VLM）在指称表达生成（REG）任务上的评估往往忽视了语用维度，将其简化为基于区域的描述任务，并忽略了格赖斯合作原则，导致无法真正评估其语用能力。

**Method:** 研究从语用角度重新审视了指称表达生成（REG）任务，并引入了一个名为RefOI的新数据集，该数据集包含1.5k张图像，并标注了书面和口头指称表达。通过对最先进的视觉-语言模型进行系统评估来识别其语用能力方面的失败。

**Result:** 系统评估发现视觉-语言模型在语用能力方面存在三项主要失败：1）未能唯一识别指称物；2）包含了过多或不相关的信息；3）与人类语用偏好不符，例如对最小空间线索的利用不足。研究还表明，标准的自动化评估未能捕捉这些语用违规，反而强化了肤浅的线索而非真正的指称成功。

**Conclusion:** 研究结果呼吁重新关注语用知情的模型和评估框架，使其与真实的人类交流对齐。

> **ai_Abstract:** 本研究指出当前视觉-语言模型（VLM）在指称表达生成（REG）任务中缺乏语用能力，现有评估方法未能充分考虑语用原则。为解决此问题，作者引入了一个新的数据集RefOI，包含1.5k张带书面和口头指称表达标注的图像，并对最先进的VLMs进行了系统评估。结果揭示了VLMs在语用方面的三大失败：无法唯一识别指称物、信息冗余以及与人类语用偏好不符。此外，研究还发现标准自动化评估未能有效捕捉这些语用缺陷。论文强调需要开发更具语用意识的模型和评估框架，以更好地模拟人类交流。

> **摘要翻译:** 指称表达生成（REG）是评估视觉-语言系统语用能力的核心任务，它不仅需要准确的语义接地，还需要遵循合作交流原则（Grice, 1975）。然而，当前对视觉-语言模型（VLMs）的评估往往忽视语用维度，将REG简化为基于区域的描述任务，并忽略了格赖斯准则。在这项工作中，我们从语用角度重新审视REG，引入了一个新的数据集（RefOI），包含1.5k张图像，并标注了书面和口头指称表达。通过对最先进的VLMs进行系统评估，我们确定了语用能力方面的三个关键失败：(1) 未能唯一识别指称物，(2) 包含了过多或不相关的信息，以及 (3) 与人类语用偏好不符，例如对最小空间线索的利用不足。我们还表明，标准自动化评估未能捕捉这些语用违规，反而强化了肤浅的线索而非真正的指称成功。我们的发现呼吁重新关注语用知情的模型和与真实人类交流对齐的评估框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [176] [PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation](https://arxiv.org/abs/2507.22927)
> *PRGB基准：一种用于基准测试检索增强生成鲁棒的占位符辅助算法*

*Zhehao Tan, Yihan Jiao, Dan Yang, Lei Liu, Jie Feng, Duolin Sun, Yue Shen, Jian Wang, Peng Wei, Jinjie Gu* | **Category: cs.CL** | **Updated: 2025-07-23**

**Keywords:** 检索增强生成, 大型语言模型, 基准测试, 占位符, 文档利用

**Comment:** 

> **TL;DR:** 本文提出了PRGB基准测试，通过创新的占位符辅助方法，对检索增强生成（RAG）系统中大型语言模型（LLM）的生成能力进行多层次细粒度评估，并揭示了现有LLM在错误恢复和上下文忠实度方面的局限性。

**AI_Comments:** 本文的创新点在于提出了一个细粒度、多维度的RAG基准测试PRGB，特别是引入了“占位符辅助”方法来解耦LLM自身知识与外部知识的贡献，这对于深入理解LLM在RAG中的具体作用至关重要。它弥补了现有基准在评估LLM特定能力和文档利用方面的不足，为RAG系统的优化提供了更精准的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有RAG基准测试主要关注整体系统性能，缺乏对LLM在RAG系统中特定能力（如文档利用）的系统性、细粒度评估，尤其是在噪声鲁棒性之外的方面。

**Method:** 引入PRGB（Placeholder-RAG-Benchmark），一个多层次细粒度基准测试，强调评估LLM的多层次过滤能力、组合能力和引用推理能力。采用创新的基于占位符的方法，以解耦LLM的参数知识和外部知识的贡献。

**Result:** 实验表明，代表性LLM在RAG系统的生成能力方面存在局限性，特别是在错误恢复能力和上下文忠实度方面。

**Conclusion:** PRGB基准提供了一个可复现的框架，用于开发更可靠和高效的RAG系统。

> **ai_Abstract:** 本文提出了PRGB（Placeholder-RAG-Benchmark），一个多层次细粒度的RAG系统基准测试。针对现有基准缺乏对LLM特定能力和文档利用细粒度评估的问题，PRGB通过引入占位符方法，解耦LLM的参数知识和外部知识贡献，并评估LLM的多层次过滤、组合和引用推理能力。实验揭示了当前LLM在RAG生成能力上，尤其在错误恢复和上下文忠实度方面的局限性。该基准为开发更可靠高效的RAG系统提供了可复现的框架。

> **摘要翻译:** 检索增强生成 (RAG) 通过整合外部知识来增强大型语言模型 (LLM)，其中 LLM 根据给定查询和检索到的文档组合生成响应的能力至关重要。然而，大多数基准测试侧重于整体 RAG 系统性能，很少评估 LLM 的特定能力。当前的基准测试强调噪声鲁棒性等广泛方面，但缺乏对文档利用的系统和细粒度评估框架。为此，我们引入了 \textit{Placeholder-RAG-Benchmark}，这是一个多层次细粒度基准测试，强调以下渐进维度：(1) 多层次过滤能力，(2) 组合能力，以及 (3) 引用推理。为了更细致地理解 LLM 在 RAG 系统中的作用，我们制定了一种创新的基于占位符的方法，以解耦 LLM 的参数知识和外部知识的贡献。实验表明，代表性 LLM 在 RAG 系统的生成能力方面存在局限性，特别是在错误恢复能力和上下文忠实度方面。我们的基准测试为开发更可靠和高效的 RAG 系统提供了一个可复现的框架。我们的代码可在 https://github.com/Alipay-Med/PRGB 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [191] [Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration](https://arxiv.org/abs/2507.23407)
> *超越被动批判性思维：培养主动提问以增强人机协作*

*Ante Wang, Yujie Lin, Jingyao Liu, Suhang Wu, Hao Liu, Xinyan Xiao, Jinsong Su* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 主动批判性思维, 人机协作, 强化学习, 数学推理, 基准

**Comment:** 

> **TL;DR:** 本文引入了AI的主动批判性思维，即模型主动询问缺失信息。通过新基准GSM-MC/MCE评估发现，当前模型在此方面表现不佳，但强化学习能显著提升该能力。

**AI_Comments:** 本文提出了一种从被动到主动批判性思维的创新范式转变，这对构建真正协作的AI系统至关重要。引入了专门的基准（GSM-MC、GSM-MCE）来评估这种新能力，具有很高的价值。通过强化学习显著提升模型能力的证明，为未来研究如何增强AI与用户智能交互、超越简单任务执行以实现更强大的问题解决能力指明了有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 以往的AI批判性思维研究主要集中在被动方面，即模型仅拒绝有问题的问题而不采取建设性措施。本文旨在通过让AI主动寻求缺失或澄清信息来更好地解决用户请求，从而提升人机协作，克服被动批判性思维的局限性。

**Method:** 本文提出了“主动批判性思维”范式，并开发了两个基于GSM8K的新型基准GSM-MC（缺少关键变量）和GSM-MCE（引入不相关细节）来评估该能力。研究通过在Qwen3和Llama系列模型上进行实验，并采用增强型强化学习（RL）算法来提高模型的主动批判性思维能力。

**Result:** 实验表明，尽管Qwen3和Llama系列模型在传统推理任务中表现出色，但它们在主动批判性思维方面表现不佳，尤其是小型模型。然而，研究证明强化学习（RL）可以显著提高这种能力。使用增强型RL算法，Qwen3-1.7B在GSM-MC上的准确率从0.15%大幅提升至73.98%。

**Conclusion:** 主动批判性思维对于实现有效的人机协作至关重要，并且强化学习可以显著增强模型实现这种能力。

> **ai_Abstract:** 本文提出了一种新的AI范式——“主动批判性思维”，即AI模型主动向用户寻求缺失或澄清信息，而非仅被动拒绝不完整请求，以增强人机协作。为评估此能力，论文构建了两个基于GSM8K的新型数学推理基准GSM-MC和GSM-MCE。实验发现，当前主流大型语言模型在此方面表现不足，但通过强化学习可显著提升其主动提问能力，例如将Qwen3-1.7B在GSM-MC上的准确率从0.15%提升至73.98%，为构建更高效的AI协作系统奠定基础。

> **摘要翻译:** 批判性思维对于构建健壮的AI系统至关重要，可以防止它们盲目接受有缺陷的数据或有偏见的推理。然而，以往的工作主要集中在被动批判性思维上，即模型仅仅拒绝有问题的问题，而没有采取建设性的步骤来解决用户请求。在这项工作中，我们引入了主动批判性思维，这是一种模型主动向用户寻求缺失或澄清信息以更好地解决其查询的范式。为了评估这种能力，我们提出了GSM-MC和GSM-MCE，这是基于GSM8K的两个新颖基准，用于评估在不完整或误导性条件下的数学推理能力。GSM-MC包含1368个数学问题，其中一个关键变量被故意移除，要求模型识别并请求缺失的信息。GSM-MCE通过引入不相关的细节进一步增加了难度，以测试对干扰的鲁棒性。对Qwen3和Llama系列模型的实验表明，尽管这些模型由于广泛的后训练和推理时缩放而在传统推理任务中表现出色，但它们在主动批判性思维方面表现不佳，尤其是小型模型。然而，我们证明了强化学习（RL）可以显著提高这种能力。使用我们增强的RL算法，我们取得了显著的进步，将Qwen3-1.7B在GSM-MC上的准确率从0.15%提高到73.98%。我们希望这项工作能够通过主动批判性思维，促进模型在解决问题时与用户更有效地协作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [203] [Enhancing RAG Efficiency with Adaptive Context Compression](https://arxiv.org/abs/2507.22931)
> *通过自适应上下文压缩提高RAG效率*

*Shuyu Guo, Zhaochun Ren* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** RAG, 上下文压缩, 效率, 自适应, 大型语言模型

**Comment:** 

> **TL;DR:** ACC-RAG通过动态调整压缩率来优化检索增强生成（RAG）的推理效率和准确性，解决了现有固定压缩率方法的不足。

**AI_Comments:** ACC-RAG的创新之处在于其动态调整上下文压缩率的机制，这模仿了人类阅读时的“略读”行为，能更智能地处理不同复杂度的查询。该方法有效解决了RAG在大规模应用中面临的效率瓶颈，对未来LLM的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）虽然通过外部知识增强了大型语言模型（LLMs），但由于检索到的上下文过长，导致推理成本高昂。现有上下文压缩方法采用固定压缩率，可能对简单查询过度压缩或对复杂查询压缩不足。

**Method:** 本文提出了自适应上下文压缩RAG（ACC-RAG）框架，该框架根据输入复杂性动态调整压缩率。ACC-RAG结合了分层压缩器（用于多粒度嵌入）和上下文选择器，以保留最少但足够的信息，类似于人类的略读。

**Result:** ACC-RAG在Wikipedia和五个QA数据集上进行了评估，性能优于固定压缩率方法，并且与标准RAG相比，在保持或提高准确性的同时，推理速度快了四倍以上。

**Conclusion:** ACC-RAG通过动态上下文压缩显著提高了RAG的推理效率和准确性，克服了传统固定压缩率方法的局限性。

> **ai_Abstract:** 本文提出了自适应上下文压缩RAG（ACC-RAG）框架，旨在解决现有RAG模型因检索上下文过长导致的推理成本高和固定压缩率方法效率低下的问题。ACC-RAG通过结合分层压缩器和上下文选择器，能够根据输入复杂性动态调整上下文压缩率，以保留最少但足够的信息。实验结果表明，ACC-RAG在维持或提高准确性的同时，显著提高了推理速度，并优于固定压缩率方法。

> **摘要翻译:** 检索增强生成（RAG）通过外部知识增强了大型语言模型（LLMs），但由于检索到的上下文过长，导致推理成本高昂。虽然上下文压缩可以缓解这个问题，但现有方法采用固定的压缩率，可能导致对简单查询过度压缩或对复杂查询压缩不足。我们提出了RAG的自适应上下文压缩（ACC-RAG），这是一个根据输入复杂性动态调整压缩率的框架，在不牺牲准确性的情况下优化推理效率。ACC-RAG结合了分层压缩器（用于多粒度嵌入）和上下文选择器，以保留最少但足够的信息，类似于人类的略读。在Wikipedia和五个QA数据集上进行评估，ACC-RAG的性能优于固定压缩率方法，并且与标准RAG相比，在保持或提高准确性的同时，推理速度快了四倍以上。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [213] [Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages](https://arxiv.org/abs/2505.14874)
> *迈向包容性ASR：低资源语言中构音障碍语音识别的语音转换研究*

*Chin-Jou Li, Eunjung Yeo, Kwanghee Choi, Paula Andrea Pérez-Toro, Masao Someki, Rohan Kumar Das, Zhengjun Yue, Juan Rafael Orozco-Arroyave, Elmar Nöth, David R. Mortensen* | **Category: cs.CL, cs.SD, eess.AS** | **Updated: 2025-07-31**

**Keywords:** 构音障碍语音识别, 语音转换, 低资源语言, 数据增强, 多语言ASR

**Comment:** 5 pages, 1 figure, Accepted to Interspeech 2025

> **TL;DR:** 通过语音转换生成构音障碍语音数据，以改善低资源语言的构音障碍语音识别，效果优于传统增强方法。

**AI_Comments:** 该研究的创新之处在于利用语音转换技术生成合成的构音障碍语音数据，以弥补低资源语言中真实数据的不足。这种方法不仅解决了数据稀缺的挑战，而且在多语言环境中表现出优于传统数据增强的性能，对于推动包容性ASR发展具有重要意义。未来可以探索更复杂的韵律和发音特征模拟。

<details>
  <summary>Details</summary>

**Motivation:** 构音障碍语音的自动语音识别（ASR）面临数据稀缺的挑战，尤其是在非英语语言中。

**Method:** 研究通过以下步骤解决问题：1. 在英语构音障碍语音（UASpeech）上微调语音转换模型，以编码说话者特征和韵律失真。2. 将该模型应用于将健康的非英语语音（FLEURS）转换为非英语构音障碍类语音。3. 使用生成的数据微调多语言ASR模型（Massively Multilingual Speech, MMS），以改进构音障碍语音识别。4. 通过客观和主观分析验证生成数据的构音障碍特征。

**Result:** 在PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）上的评估表明，结合说话者和韵律转换的语音转换显著优于现成的MMS性能和传统的增强技术（如语速和节奏扰动）。对生成数据的客观和主观分析进一步证实，生成的语音模拟了构音障碍特征。

**Conclusion:** 语音转换技术可以有效地生成构音障碍类语音数据，显著提高低资源语言中构音障碍语音识别的性能，并优于传统数据增强方法。

> **ai_Abstract:** 该研究旨在解决低资源语言中构音障碍语音ASR的数据稀缺问题。作者微调了一个语音转换模型，将健康非英语语音转换为构音障碍类语音，然后用生成的数据微调多语言ASR模型。实验结果表明，该语音转换方法显著优于基线MMS模型和传统数据增强技术，有效提升了多语言构音障碍语音识别的性能，并且生成的数据成功模拟了构音障碍特征。

> **摘要翻译:** 自动语音识别（ASR）对于构音障碍语音来说仍然具有挑战性，这主要是由于数据稀缺，特别是在非英语语言中。为了解决这个问题，我们对一个语音转换模型进行了微调，使其在英语构音障碍语音（UASpeech）上编码说话者特征和韵律失真，然后将其应用于将健康的非英语语音（FLEURS）转换为非英语构音障碍类语音。生成的数据随后用于微调多语言ASR模型（Massively Multilingual Speech, MMS），以改进构音障碍语音识别。在PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）上的评估表明，结合说话者和韵律转换的语音转换显著优于现成的MMS性能和传统的增强技术，如语速和节奏扰动。对生成数据的客观和主观分析进一步证实，生成的语音模拟了构音障碍特征。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [218] [EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow](https://arxiv.org/abs/2507.22929)
> *EH-Benchmark 眼科幻觉基准和代理驱动的自上而下可追溯推理工作流*

*Xiaoyu Pan, Yang Bai, Ke Zou, Yang Zhou, Jun Zhou, Huazhu Fu, Yih-Chung Tham, Yong Liu* | **Category: cs.CL, cs.CV, cs.MA** | **Updated: 2025-07-24**

**Keywords:** 眼科, 幻觉, 医学大语言模型, 基准, 代理驱动

**Comment:** 9 figures, 5 tables. submit/6621751

> **TL;DR:** 本文介绍了EH-Benchmark，一个用于评估医学大语言模型（MLLMs）在眼科诊断中幻觉的新基准，并提出了一个三阶段代理驱动框架来有效缓解这些幻觉。

**AI_Comments:** 本文创新性地提出了一个专注于眼科领域MLLM幻觉评估的基准EH-Benchmark，并根据幻觉类型进行了细致分类。更重要的是，其引入的代理驱动三阶段推理框架，针对MLLM基于语言推理的特点，提供了一种可追溯且有效缓解幻觉的解决方案，对于提高医疗AI的可靠性和临床应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 医学大语言模型（MLLMs）在眼科诊断中具有巨大潜力，但其准确性受限于幻觉，这些幻觉源于眼科知识有限、视觉定位和推理能力不足以及多模态眼科数据稀缺，从而阻碍了精确的病灶检测和疾病诊断。此外，现有医学基准未能有效评估各种类型的幻觉或提供可行的缓解方案。

**Method:** 本文引入了EH-Benchmark，一个用于评估MLLMs幻觉的新型眼科基准，并将MLLMs的幻觉根据特定任务和错误类型分为视觉理解和逻辑组成两大类，每类包含多个子类。鉴于MLLMs主要依赖基于语言的推理而非视觉处理，作者提出了一个以代理为中心的三阶段框架，包括知识级检索阶段、任务级案例研究阶段和结果级验证阶段。

**Result:** 实验结果表明，所提出的多代理框架显著减轻了两种类型的幻觉，提高了准确性、可解释性和可靠性。

**Conclusion:** 本文提出的EH-Benchmark基准和代理驱动的三阶段框架能够有效评估并显著缓解医学大语言模型在眼科诊断中出现的幻觉问题，从而提高其准确性、可解释性和可靠性。

> **ai_Abstract:** 该研究针对医学大语言模型（MLLMs）在眼科诊断中存在的幻觉问题，提出了EH-Benchmark，一个新型眼科幻觉评估基准，并根据任务和错误类型将幻觉分为视觉理解和逻辑组成两大类。为缓解这些幻觉，文章设计了一个代理驱动的三阶段框架，包括知识级检索、任务级案例研究和结果级验证。实验证明，该多代理框架能有效减轻幻觉，提升MLLMs的准确性、可解释性和可靠性。

> **摘要翻译:** 医学大语言模型（MLLMs）在眼科诊断中扮演着关键角色，在解决威胁视力的疾病方面具有重要潜力。然而，它们的准确性受到源于有限眼科知识、不足的视觉定位和推理能力以及多模态眼科数据稀缺的幻觉的限制，这些共同阻碍了精确的病灶检测和疾病诊断。此外，现有医学基准未能有效评估各种类型的幻觉或提供可行的解决方案来缓解它们。为了应对上述挑战，我们引入了EH-Benchmark，一个旨在评估MLLMs中幻觉的新型眼科基准。我们根据特定任务和错误类型将MLLMs的幻觉分为两大主要类别：视觉理解和逻辑组成，每个类别包含多个子类。鉴于MLLMs主要依赖基于语言的推理而非视觉处理，我们提出了一个以代理为中心的三阶段框架，包括知识级检索阶段、任务级案例研究阶段和结果级验证阶段。实验结果表明，我们的多代理框架显著减轻了两种类型的幻觉，提高了准确性、可解释性和可靠性。我们的项目可在https://github.com/ppxy1/EH-Benchmark 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [219] [Role-Aware Language Models for Secure and Contextualized Access Control in Organizations](https://arxiv.org/abs/2507.23465)
> *面向组织中安全和情境化访问控制的角色感知语言模型*

*Saeed Almheiri, Yerulan Kongrat, Adrian Santosh, Ruslan Tasmukhanov, Josemaria Vera, Muhammad Dehan Al Kautsar, Fajri Koto* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 角色感知语言模型, 访问控制, 企业LLMs, 安全, 微调

**Comment:** 

> **TL;DR:** 研究如何微调大型语言模型以根据用户角色生成符合访问权限的响应，并评估其在不同组织结构和安全攻击下的性能。

**AI_Comments:** 这项工作具有重要的实际意义，因为它解决了LLMs在企业部署中的一个关键安全和合规性挑战。通过引入“角色感知”的概念，它超越了传统的通用安全过滤，为构建更细粒度、更具情境化的LLM访问控制系统提供了新的思路。对不同建模策略的探索和对鲁棒性的评估也增加了其研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在企业中部署，根据用户角色控制模型行为成为一项基本要求。现有安全方法通常假设统一访问，并专注于防止有害或有毒输出，但未解决角色特定的访问限制。

**Method:** 探索了三种建模策略：基于BERT的分类器、基于LLM的分类器和角色条件生成。构建了两个互补数据集：一个通过聚类和角色标注改编自现有指令微调语料库，另一个合成生成以反映现实的角色敏感企业场景。评估了模型在不同组织结构下的性能，并分析了对提示注入、角色不匹配和越狱尝试的鲁棒性。

**Result:** 评估了模型在不同组织结构下的性能，并分析了对提示注入、角色不匹配和越狱尝试的鲁棒性。具体结果未在摘要中提及。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决大型语言模型在企业应用中缺乏角色感知访问控制的问题。论文探讨了通过微调LLMs使其能够根据用户角色生成符合访问权限的响应的可能性。为此，研究人员提出了基于BERT的分类器、基于LLM的分类器和角色条件生成三种建模策略，并构建了两个专用数据集（一个改编自现有语料库，一个合成生成）进行评估。研究还评估了模型在不同组织结构下的性能及其对提示注入、角色不匹配和越狱尝试的鲁棒性。

> **摘要翻译:** 随着大型语言模型（LLMs）在企业环境中的部署日益增加，根据用户角色控制模型行为成为一项基本要求。现有安全方法通常假设统一访问，并侧重于防止有害或有毒输出，而没有解决角色特定的访问限制。在这项工作中，我们研究了是否可以对LLMs进行微调，使其生成的响应能够反映与不同组织角色相关的访问权限。我们探索了三种建模策略：基于BERT的分类器、基于LLM的分类器以及角色条件生成。为了评估这些方法，我们构建了两个互补的数据集。第一个数据集通过聚类和角色标注改编自现有的指令微调语料库，而第二个数据集是合成生成的，以反映现实的、对角色敏感的企业场景。我们评估了模型在不同组织结构下的性能，并分析了对提示注入、角色不匹配和越狱尝试的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [225] [SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology](https://arxiv.org/abs/2507.22941)
> *SigBERT：结合叙述性医疗报告和粗路径签名理论进行肿瘤生存风险估计*

*Paul Minchella, Loïc Verlingue, Stéphane Chrétien, Rémi Vaucher, Guillaume Metzler* | **Category: cs.CL, cs.CY, cs.LG, stat.AP** | **Updated: 2025-07-25**

**Keywords:** 生存分析, 医疗报告, 粗路径理论, BERT, 风险估计

**Comment:** 12 pages, 2 figures, accepted for ECML PKDD 2025

> **TL;DR:** SigBERT结合医疗报告和粗路径签名理论，通过捕获复杂的时序动态，提高肿瘤生存风险估计的准确性。

**AI_Comments:** SigBERT的创新之处在于将粗路径签名理论引入到叙述性医疗报告的序列分析中，以捕捉复杂的时序动态，为生存分析提供了一种新颖且强大的特征工程方法。通过结合BERT的嵌入能力和粗路径理论，它能更有效地从非结构化文本中提取有价值的时间信息，从而显著提高风险预测的准确性。这对于充分利用EHR数据进行临床决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有生存分析方法难以有效处理文本数据的复杂性，特别是其序列形式，导致电子医疗报告中的大量信息未被充分利用。

**Method:** SigBERT框架处理带时间戳的医疗报告，首先提取并平均词嵌入为句子嵌入。接着，应用粗路径理论的签名提取来从句子嵌入坐标的时间序列中导出几何特征，以捕获复杂的时间动态。最后，这些特征被整合到LASSO惩罚的Cox模型中以估计患者特异性风险分数。

**Result:** 该模型在来自Léon Bérard中心语料库的真实肿瘤数据集上进行训练和评估，在独立测试队列上的C-index分数为0.75 (sd 0.014)。

**Conclusion:** SigBERT通过整合序列医疗数据并利用粗路径签名理论捕获时间动态，显著增强了风险估计的准确性，推动了基于叙述的生存分析发展。

> **ai_Abstract:** SigBERT是一个创新的时间生存分析框架，旨在高效利用电子医疗报告中的叙述性文本数据进行肿瘤生存风险估计。它通过将带时间戳的医疗报告转换为句子嵌入，并利用粗路径理论提取几何特征来捕获复杂的时序动态。这些特征随后被整合到LASSO惩罚的Cox模型中。在真实的肿瘤数据集上，SigBERT在独立测试队列上取得了0.75的C-index分数，验证了其在增强叙述性医疗数据风险估计方面的有效性。

> **摘要翻译:** 电子医疗报告（EHR）包含大量信息，可用于医疗保健领域的机器学习应用。然而，现有的生存分析方法往往难以有效处理文本数据的复杂性，特别是其序列形式。本文提出SigBERT，一个创新的时间生存分析框架，旨在高效处理每个患者的大量临床报告。SigBERT通过提取词嵌入并将其平均为句子嵌入来处理带时间戳的医疗报告。为了从句子嵌入坐标的时间序列中捕获时间动态，我们应用粗路径理论的签名提取来为每位患者推导几何特征，这通过捕获复杂的时间动态显著增强了生存模型的性能。这些特征随后被整合到LASSO惩罚的Cox模型中，以估计患者特异性风险分数。该模型在来自Léon Bérard中心语料库的真实肿瘤数据集上进行了训练和评估，在独立测试队列上的C-index分数为0.75 (sd 0.014)。SigBERT整合序列医疗数据以增强风险估计，推动了基于叙述的生存分析。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [239] [Text-to-SQL Task-oriented Dialogue Ontology Construction](https://arxiv.org/abs/2507.23358)
> *文本到SQL面向任务对话本体构建*

*Renato Vukovic, Carel van Niekerk, Michael Heck, Benjamin Ruppik, Hsien-Chin Lin, Shutong Feng, Nurul Lubis, Milica Gasic* | **Category: cs.CL, cs.AI, cs.DB, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 文本到SQL, 面向任务对话, 本体构建, 大型语言模型, 可解释性

**Comment:** 

> **TL;DR:** TeQoDO是一种无需监督的文本到SQL面向任务对话本体构建方法，它利用LLM的SQL能力和对话理论，从零开始自主构建本体，并在对话状态跟踪任务上表现竞争力，优于迁移学习。

**AI_Comments:** TeQoDO的创新点在于利用LLM的固有能力（SQL编程）结合领域知识（对话理论）实现无监督的本体构建，这显著降低了传统本体构建对人工标注或监督训练的依赖。其重要性在于为面向任务对话系统提供了一种高效、可扩展的本体构建新范式，并为解决LLM解释性和可信度问题提供了一条有前景的路径。通过将LLM与外部显式本体结合，该方法有助于提升LLM在特定任务上的可控性和透明度。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）作为通用知识源，依赖参数知识，导致解释性和可信度受限。在面向任务的对话（TOD）系统中，为确保解释性和可控性，通常需要由显式本体结构化的外部数据库。然而，构建这些本体通常需要手动标注或监督训练，这是一个耗时耗力的过程。

**Method:** 本文引入了TeQoDO（Text-to-SQL task-oriented Dialogue Ontology construction）方法。该方法利用LLM固有的SQL编程能力，结合在提示中提供的对话理论，无需监督即可自主地从零开始构建面向任务对话（TOD）本体。

**Result:** TeQoDO方法优于传统的迁移学习方法。其构建的本体在下游的对话状态跟踪任务上具有竞争力。消融研究表明，对话理论在TeQoDO中起着关键作用。此外，TeQoDO还具有良好的可扩展性，能够构建更大的本体，并在Wikipedia和ArXiv数据集上进行了验证。

**Conclusion:** TeQoDO代表了本体更广泛应用于提高大型语言模型（LLM）可解释性的一步。

> **ai_Abstract:** 本文提出了一种名为TeQoDO的文本到SQL面向任务对话本体构建方法。该方法创新性地利用大型语言模型（LLM）的SQL编程能力和对话理论，实现了无需监督地从零开始自主构建面向任务对话（TOD）本体。实验结果表明，TeQoDO在性能上优于迁移学习方法，其生成的本体在对话状态跟踪任务上具有竞争力，并且具有良好的可扩展性。这项工作被视为提升LLM可解释性，促进本体更广泛应用的重要一步。

> **摘要翻译:** 大型语言模型（LLM）作为通用知识源被广泛使用，但它们依赖参数知识，限制了解释性和可信度。在面向任务的对话（TOD）系统中，这种分离是明确的，通过使用由显式本体结构化的外部数据库来确保解释性和可控性。然而，构建此类本体需要手动标注或监督训练。我们引入了TeQoDO：一种文本到SQL的面向任务对话本体构建方法。在此，LLM利用其固有的SQL编程能力结合提示中提供的对话理论，无需监督地从零开始自主构建TOD本体。我们表明TeQoDO优于迁移学习方法，其构建的本体在下游对话状态跟踪任务上具有竞争力。消融研究表明对话理论的关键作用。TeQoDO还可扩展以构建更大的本体，我们在一项Wikipedia和ArXiv数据集上进行了研究。我们认为这是本体更广泛应用于提高LLM可解释性的一步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [240] [A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains](https://arxiv.org/abs/2507.23486)
> *医用大型语言模型的新型评估基准：阐明临床领域的安全性和有效性*

*Shirui Wang, Zhihui Tang, Huaxia Yang, Qiuhong Gong, Tiantian Gu, Hongyang Ma, Yongxin Wang, Wubin Sun, Zeliang Lian, Kehang Mao, Yinan Jiang, Zhicheng Huang, Lingyun Ma, Wenjie Shen, Yajie Ji, Yunhui Tan, Chunbo Wang, Yunlu Gao, Qianling Ye, Rui Lin, Mingyu Chen, Lijuan Niu, Zhihao Wang, Peng Yu, Mengran Lang, Yue Liu, Huimin Zhang, Haitao Shen, Long Chen, Qiguang Zhao, Si-Xuan Liu, Lina Zhou, Hua Gao, Dongqiang Ye, Lingmin Meng, Youtao Yu, Naixin Liang, Jianxiong Wu* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 医用大型语言模型, 安全性评估, 有效性验证, 临床基准, CSEDB

**Comment:** 

> **TL;DR:** 开发了一个名为CSEDB的多维基准，用于评估医用大型语言模型在临床场景中的安全性和有效性。结果显示LLM表现一般，在高风险场景下性能显著下降，而特定领域模型表现更优。

**AI_Comments:** 这项研究的创新之处在于其开发了一个基于临床专家共识的多维评估基准（CSEDB），专门用于衡量医用大型语言模型在实际临床场景中的安全性和有效性。通过引入加权后果度量和高风险场景测试，该基准能够更真实地反映LLM在医疗应用中的潜在风险。其重要性在于为医用LLM的标准化评估提供了一个急需的工具，有助于识别模型缺陷并指导未来的改进方向，从而促进LLM在医疗领域更安全、更负责任的部署。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在临床决策支持方面具有潜力，但在安全评估和有效性验证方面面临重大挑战。

**Method:** 开发了临床安全-有效性双轨基准（CSEDB），这是一个基于临床专家共识的多维框架，包含30项标准，涵盖危重症识别、指南依从性和用药安全等关键领域，并带有加权后果度量。32位专科医生开发并审查了2069个开放式问答项，这些问答项与标准对齐，涵盖26个临床科室，以模拟真实世界场景。对六个LLM进行了基准测试。

**Result:** 基准测试显示LLM的整体表现中等（平均总分57.2%，安全性54.7%，有效性62.3%），在高风险场景中性能显著下降13.3%（p < 0.0001）。领域特定的医用LLM比通用模型表现出持续的性能优势，在安全性（0.912）和有效性（0.861）方面具有相对较高的最高得分。

**Conclusion:** 本研究的结果不仅为评估医用LLM的临床应用提供了一个标准化的衡量指标，有助于不同场景下的比较分析、风险暴露识别和改进方向，而且有望促进大型语言模型在医疗环境中更安全、更有效地部署。

> **ai_Abstract:** 本研究旨在解决大型语言模型在临床应用中安全性和有效性评估的挑战。为此，研究团队开发了一个名为临床安全-有效性双轨基准（CSEDB）的多维评估框架，该框架基于临床专家共识，包含30项关键评估标准和2069个由32位专科医生创建的开放式问答项，覆盖26个临床科室。对六个LLM的测试结果显示，LLM的整体表现一般，尤其在高风险场景下性能显著下降。然而，领域特定的医用LLM展现出优于通用模型的持续性能优势。这项研究为医用LLM的临床评估提供了一个标准化的工具，有助于推动其在医疗领域更安全有效的部署。

> **摘要翻译:** 大型语言模型（LLMs）在临床决策支持方面具有广阔前景，但在安全性评估和有效性验证方面面临重大挑战。我们开发了临床安全-有效性双轨基准（CSEDB），这是一个基于临床专家共识的多维框架，包含30项标准，涵盖危重症识别、指南依从性和用药安全等关键领域，并带有加权后果度量。32位专科医生开发并审查了2069个开放式问答项，这些问答项与这些标准对齐，涵盖26个临床科室，以模拟真实世界场景。对六个LLM进行的基准测试显示，其整体表现中等（平均总分57.2%，安全性54.7%，有效性62.3%），在高风险场景中性能显著下降13.3%（p < 0.0001）。领域特定的医用LLM比通用模型表现出持续的性能优势，在安全性（0.912）和有效性（0.861）方面具有相对较高的最高得分。本研究的结果不仅为评估医用LLM的临床应用提供了一个标准化的衡量指标，有助于不同场景下的比较分析、风险暴露识别和改进方向，而且有望促进大型语言模型在医疗环境中更安全、更有效地部署。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [253] [Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection](https://arxiv.org/abs/2507.22930)
> *保护脆弱的声音：用于自我披露检测的合成数据集生成*

*Shalini Jangra, Suparna De, Nishanth Sastry, Saeed Fadaei* | **Category: cs.CL, cs.SI** | **Updated: 2025-07-24**

**Keywords:** 自我披露检测, 合成数据, PII, 大型语言模型, 隐私

**Comment:** 15 pages, 4 Figures, Accepted in "The 17th International Conference
  on Advances in Social Networks Analysis and Mining -ASONAM-2025"

> **TL;DR:** 本研究提出了一种生成合成数据集的新颖方法，用于在社交媒体上检测个人信息披露（PII），以解决缺乏可公开共享的标注数据集的问题，从而促进可复现的研究。

**AI_Comments:** 本论文的创新之处在于其通过生成合成数据来克服真实PII数据带来的隐私限制，从而为个人信息披露检测领域的可复现研究提供了解决方案。利用多个大型语言模型（LLMs）并采用严格的评估标准（可复现性、不可关联性、不可区分性）增强了研究的严谨性。其重要性体现在它为解决社交媒体中关键的隐私问题提供了实用的工具和方法。

<details>
  <summary>Details</summary>

**Motivation:** 社交平台上用户自我披露的个人信息（PII）存在隐私风险和在线危害。然而，缺乏开源的标注数据集阻碍了对识别和检索此类高风险自我披露的研究。

**Method:** 开发了一种新颖的方法来创建PII披露数据的合成等效物。具体包括：创建19个PII披露类别的分类法；使用Llama2-7B、Llama3-8B和zephyr-7b-beta三种大型语言模型（LLMs）通过顺序指令提示生成合成的PII标注多文本跨度数据集，以模仿原始Reddit帖子。该方法的效用通过三个指标进行评估：模型在合成数据上训练的结果应与在原始数据上训练的结果相当（可复现性等效）；合成数据应无法与原始用户关联（不可关联性）；经过训练的人类应无法区分合成数据和原始数据（不可区分性）。

**Result:** 创建并发布了一个合成的PII标注多文本跨度数据集，该数据集由三种大型语言模型生成，并旨在满足可复现性、不可关联性和不可区分性等效性要求。数据集和代码已公开发布。

**Conclusion:** 本研究通过创建和发布一个合成的PII标注数据集及其生成方法，旨在促进在线社交媒体中PII隐私风险领域的可复现研究。

> **ai_Abstract:** 本论文提出了一种新颖的方法来生成合成数据集，以解决社交媒体上个人身份信息（PII）自我披露检测研究中缺乏可公开共享的标注数据集的问题。研究团队创建了一个包含19个PII披露类别的分类法，并利用Llama2、Llama3和Zephyr等大型语言模型生成了一个合成的PII标注多文本跨度数据集，旨在模拟真实的Reddit帖子。该方法的有效性通过评估数据集的可复现性、与原始用户的不可关联性以及与原始数据的不可区分性来验证。最终，研究成果包括发布了该合成数据集及其生成代码，以促进PII隐私风险领域的可复现研究。

> **摘要翻译:** 保护脆弱的声音：用于自我披露检测的合成数据集生成

摘要：Reddit等社交平台拥有共享兴趣的社区网络，其中普遍存在的帖子和评论可以推断出用户的个人身份信息（PII）。虽然这种自我披露可以带来有益的社交互动，但它们也带来了隐私风险和在线危害的威胁。对识别和检索此类高风险PII自我披露的研究受到了缺乏开源标注数据集的阻碍。为了促进PII披露文本检测的可复现研究，我们开发了一种新颖的方法来创建PII披露数据的合成等效物，这些数据可以安全共享。我们的贡献包括：为脆弱人群创建了19个PII披露类别的分类法，以及创建并发布了一个由3个大型语言模型（LLMs），即Llama2-7B、Llama3-8B和zephyr-7b-beta通过顺序指令提示生成，以模仿原始Reddit帖子的合成PII标注多文本跨度数据集。我们生成此合成数据集的方法的效用通过三个指标进行评估：首先，我们要求可复现性等效，即在合成数据上训练模型的结果应与在原始帖子数据上训练相同模型获得的结果相当。其次，我们要求合成数据通过Google搜索等常见机制无法与原始用户关联。第三，我们希望确保合成数据与原始数据无法区分，即受过训练的人类应该无法区分它们。我们已在https://netsys.surrey.ac.uk/datasets/synthetic-self-disclosure/发布了我们的数据集和代码，以促进在线社交媒体中PII隐私风险领域的可复现研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [255] [Augmented Vision-Language Models: A Systematic Review](https://arxiv.org/abs/2507.22933)
> *增强型视觉-语言模型：系统综述*

*Anthony C Davis, Burhan Sadiq, Tianmin Shu, Chien-Ming Huang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 视觉-语言模型, 神经符号系统, 系统综述, 可解释性, 知识整合

**Comment:** 

> **TL;DR:** 本系统综述旨在分类通过与外部符号信息系统交互来增强视觉-语言模型的技术，以解决现有模型的局限性。

**AI_Comments:** 这篇综述关注当前大型视觉-语言模型的局限性，并提出了神经符号系统作为一种有前景的解决方案，强调了其在可解释性和知识整合方面的优势。它为未来增强型视觉-语言模型的研究方向提供了系统性的分类和展望。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉-语言机器学习模型在可解释性、新信息整合、资源效率和逻辑推理方面存在局限性，需要一种新的范式来克服这些问题。

**Method:** 本系统文献综述旨在对通过与外部符号信息系统交互来改进视觉-语言理解的技术进行分类。

**Result:** Not mentioned in abstract

**Conclusion:** 将强大的预训练视觉-语言模型与外部符号信息系统集成，形成神经符号系统，是一种有前景且实用的方法，可以增强模型的推理和记忆能力，提供更可解释的输出，并能高效地吸收新信息。

> **ai_Abstract:** 本系统综述旨在探讨如何通过与外部符号信息系统交互来增强视觉-语言模型。现有视觉-语言模型虽能理解视觉场景，但在可解释性、新信息整合、资源效率和逻辑推理方面存在不足。将神经网络与外部符号系统结合形成的神经符号系统，有望提供更可解释的输出，并能高效整合新信息。本文将系统回顾并分类利用预训练VLM作为核心，并通过外部系统增强视觉-语言理解的各种技术。

> **摘要翻译:** 近期视觉-语言机器学习模型的进展在利用自然语言理解视觉场景方面展现出卓越的能力，通过在大型非结构化数据集上进行训练。然而，这种训练范式无法为其输出提供可解释的解释，集成新信息需要重新训练，资源消耗巨大，并且在某些形式的逻辑推理方面存在困难。一个有前景的解决方案是将神经网络与外部符号信息系统集成，形成神经符号系统，从而增强推理和记忆能力。这些神经符号系统为其输出提供更可解释的解释，并能够在不进行大量再训练的情况下吸收新信息。利用强大的预训练视觉-语言模型（VLMs）作为核心神经组件，并通过外部系统进行增强，为实现神经符号集成的好处提供了一种实用方法。本系统文献综述旨在对通过与外部符号信息系统交互来改进视觉-语言理解的技术进行分类。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [256] [Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning](https://arxiv.org/abs/2507.23541)
> *Med-R$^3$: 通过渐进式强化学习增强LLM的医学检索增强推理能力*

*Keer Lu, Zheng Liang, Youquan Li, Jiejun Tan, Da Pan, Shusen Zhang, Guosheng Dong, Huang Leng* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 医学检索, 强化学习, LLMs, 推理, 联合优化

**Comment:** 

> **TL;DR:** Med-R$^3$是一个通过渐进式强化学习驱动的医学检索增强推理框架，它通过联合优化检索和推理能力，解决了现有方法在医学领域中孤立优化、SFT限制和奖励函数不足的问题，并取得了最先进的性能。

**AI_Comments:** Med-R$^3$的创新之处在于其采用渐进式强化学习的方法，实现了检索和推理能力的联合优化，这在医学领域尤为重要。它有效克服了传统SFT方法在泛化能力上的限制，并针对医学领域的特殊性设计了优化策略。其分阶段优化检索和推理协调的机制，以及在多个LLM上取得的显著性能提升，证明了该框架的有效性和前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作主要孤立地增强模型的检索或推理能力，导致两者协调性有限。此外，当前方法过度依赖监督微调（SFT），限制了模型在处理新问题时的泛化能力。通用领域中探索的强化学习方法，其奖励函数未能充分捕捉医学领域的特定需求。

**Method:** 本文引入了Med-R$^3$，一个由渐进式强化学习驱动的医学检索增强推理框架。该框架首先培养模型对医学问题进行逻辑推理的能力，随后在此基础上自适应地优化检索能力以更好地与知识语料库和外部信息利用的特性对齐，最后对模型的检索和推理协调进行联合优化。

**Result:** Med-R$^3$取得了最先进的性能。LLaMA3.1-8B-Instruct + Med-R$^3$在可比参数规模下超越闭源的GPT-4o-mini 3.93%，而增强了Med-R$^3$的Qwen2.5-14B显示出更显著的13.53%的提升。

**Conclusion:** Med-R$^3$框架通过渐进式强化学习有效提升了LLM在医学场景中的检索增强推理能力，解决了现有方法的局限性，并实现了卓越的性能。

> **ai_Abstract:** 本文提出了Med-R$^3$，一个利用渐进式强化学习来联合优化大型语言模型（LLMs）在医学场景中检索和推理能力的框架。针对现有方法在检索与推理协调不足、监督微调泛化受限以及医学领域奖励函数设计缺陷等问题，Med-R$^3$通过分阶段优化：首先发展逻辑推理能力，然后自适应优化检索能力，最终进行检索与推理的联合协调优化。实验结果表明，Med-R$^3$显著提升了LLMs在医学任务上的表现，实现了最先进的性能，并超越了包括GPT-4o-mini在内的现有模型。

> **摘要翻译:** 在医学场景中，有效检索外部知识并利用其进行严谨的逻辑推理至关重要。尽管现有工作具有潜力，但主要侧重于孤立地增强模型的检索或推理能力，很少关注它们的联合优化，这导致两个过程之间的协调性有限。此外，当前方法严重依赖监督微调（SFT），这可能导致模型记忆现有问题解决路径，从而限制了它们在面对新问题情境时的泛化能力。再者，尽管一些研究探索通过强化学习改进通用领域的检索增强推理，但它们的奖励函数设计未能充分捕捉医学领域的特定需求。为了解决这些挑战，我们引入了Med-R$^3$，一个由渐进式强化学习驱动的医学检索增强推理框架。在该框架中，我们首先培养模型对医学问题进行逻辑推理的能力。随后，在此基础上，我们自适应地优化检索能力，以更好地与推理过程中知识语料库和外部信息利用的特性对齐。最后，我们对模型的检索和推理协调进行联合优化。大量实验表明，Med-R$^3$可以实现最先进的性能，其中LLaMA3.1-8B-Instruct + Med-R$^3$在可比参数规模下超越闭源的GPT-4o-mini 3.93%，而增强了Med-R$^3$的Qwen2.5-14B则显示出更显著的13.53%的提升。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [260] [The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models](https://arxiv.org/abs/2505.18497)
> *机器的语用心智：追溯大型语言模型中语用能力的出现*

*Kefan Yu, Qingcheng Zeng, Weihao Xuan, Wanxin Li, Jingyi Wu, Rob Voigt* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 语用能力, ALTPRAG, 训练阶段, 对比推理

**Comment:** 

> **TL;DR:** 本研究引入ALTPRAG数据集，系统评估了不同训练阶段的22个大型语言模型在语用能力方面的表现，发现语用能力是LLM训练过程中出现并逐步增强的特性。

**AI_Comments:** 这项研究通过引入一个新颖的ALTPRAG数据集，并采用对比推理的方法，系统地探究了大型语言模型语用能力的形成和发展，具有重要的创新性。它不仅填补了LLM语用能力习得机制的空白，还为未来设计更符合人类交流习惯的LLM提供了实证基础和理论指导。其发现语用能力是LLM训练中的一个涌现特性，对于理解LLM的认知机制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型（LLMs）在社交智能任务中展现出新兴能力，但它们如何在训练过程中获得语用能力仍不清楚。

**Method:** 研究引入了一个名为ALTPRAG的数据集，该数据集基于语用学中的替代概念，旨在评估LLMs在不同训练阶段能否准确推断说话者的细微意图。数据集的每个实例包含两种同样合理但语用上不同的延续，要求模型推断说话者的预期含义并解释选择特定话语的原因。研究系统评估了22个LLMs在预训练、监督微调（SFT）和偏好优化三个关键训练阶段的语用能力发展。

**Result:** 结果显示，即使是基础模型也对语用线索表现出显著的敏感性，并且这种敏感性随着模型和数据规模的增加而持续提高。此外，SFT和RLHF进一步提升了模型的语用能力，尤其是在认知-语用场景中。

**Conclusion:** 这些发现强调语用能力是LLM训练过程中出现并具有组合性的特性，为使模型与人类交流规范保持一致提供了新的见解。

> **ai_Abstract:** 本研究旨在探究大型语言模型（LLMs）如何获得语用能力。为此，研究引入了ALTPRAG数据集，该数据集通过对比推理评估模型对说话者意图的理解。通过对22个LLMs在不同训练阶段（预训练、SFT、偏好优化）的系统评估，研究发现LLMs对语用线索具有敏感性，且该能力随模型和数据规模的增大而增强，SFT和RLHF也带来显著提升。这表明语用能力是LLM训练过程中一种新兴且组合的特性，为模型与人类交流规范对齐提供了新视角。

> **摘要翻译:** 当前的大型语言模型（LLMs）在社交智能任务中展现出新兴能力，包括言外之意理解和心智理论推理，这两者都需要大量的语用理解。然而，LLMs如何在整个训练过程中获得这种语用能力仍然知之甚少。在这项工作中，我们引入了ALTPRAG数据集，该数据集以语用学中的“替代”概念为基础，旨在评估处于不同训练阶段的LLMs能否准确推断说话者的细微意图。每个实例都配对了两个同样合理但在语用上有所不同的延续，并要求模型（i）推断说话者的预期含义，以及（ii）解释说话者何时以及为何会选择一个话语而不是其替代话语，从而通过对比推理直接探究语用能力。我们系统地评估了22个LLMs在三个关键训练阶段的表现：预训练之后、监督微调（SFT）和偏好优化，以检查语用能力的发展。我们的结果表明，即使是基础模型也对语用线索表现出显著的敏感性，并且这种敏感性随着模型和数据规模的增加而持续提高。此外，SFT和RLHF带来了进一步的提升，特别是在认知-语用场景中。这些发现强调语用能力是LLM训练过程中出现并具有组合性的特性，并为使模型与人类交流规范保持一致提供了新的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [267] [Opacity as Authority: Arbitrariness and the Preclusion of Contestation](https://arxiv.org/abs/2507.22944)
> *不透明性即权威：任意性与抗辩的排除*

*Naomi Omeonga wa Kayembe* | **Category: cs.CL, cs.AI, cs.CY** | **Updated: 2025-07-25**

**Keywords:** 任意性, 不透明性, 权威, 抗辩, 可解释性

**Comment:** 

> **TL;DR:** 本文将任意性重新定义为一种功能性机制，即不透明性，它通过阻止抗辩来保护权威。该理论通过熵进行形式化，并适用于人类系统和人工智能的可解释性。

**AI_Comments:** 本文对任意性进行了创新性重新诠释，将其从纯粹的负面概念转变为一种具有功能的机制。其跨学科方法，融合了符号学、法律、社会动力学和信息论（香农熵），尤其值得关注。将该框架扩展到人工智能可解释性领域，突显了其当代相关性和潜在的广泛影响。“不透明性即权威”的理念引人深思。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在重新定义任意性，将其从传统的规范性缺陷或支配的表征，转变为一种构建人类系统和互动的基础功能机制。研究旨在解释这种不透明性如何保护权威，并探索其在人工智能可解释性方面的应用。

**Method:** 本文将任意性重新定义为一种符号学特征，使其能够有效运作而隐藏内部原理。研究基于费迪南·德·索绪尔的“符号的任意性”概念，并将其扩展到法律和社会动态。论文引入了“动机 -> 可证实性 -> 可争议性”链条，并分析了通过“去动机化”或“冲突横向化”打破此链条如何导致可审理性被排除。此外，本文利用香农的熵模型，将任意性形式化为 A = H(L|M)（条件熵）。

**Result:** 研究结果表明，任意性是一种符号学特征，使系统在不暴露其内部原理的情况下有效运作。论文提出，结构性不透明性是一种蓄意设计，旨在保护权威免受问责。它还提出了一种关于任意性的现代理论，将其视为控制和关怀的核心中性操作符。此外，该框架为分析先进人工智能系统中的可解释性提供了新的途径。

**Conclusion:** 本文的结论是，任意性应被视为一种中性操作符，它通过结构性不透明性来保护权威，同时在控制和关怀中发挥核心作用，并对理解人工智能系统的可解释性具有重要启示。

> **ai_Abstract:** 本文将任意性重新定义为一种基本功能机制，而非传统意义上的缺陷，它通过使系统在隐藏其内部原理的同时有效运作来构建人类系统。论文借鉴索绪尔的理论，并利用香农的熵模型（A = H(L|M)）进行形式化，认为这种“结构性不透明性”通过打破“动机 -> 可证实性 -> 可争议性”链条来蓄意保护权威免受问责，从而排除可审理性。文章提出任意性是控制和关怀的核心中性操作符，并为人类社会动态及人工智能的可解释性提供了新的见解。

> **摘要翻译:** 本文将任意性重新定义为一种基础的功能机制，而非规范性缺陷或支配的表征，它构建了人类系统和互动。本文不同于将任意性与不公混为一谈的批判传统，而是将任意性视为一种符号学特征：一种使系统（无论是语言、法律还是社会系统）能够有效运作，同时又隐藏其内部原理的特性。本文以费迪南·德·索绪尔的“符号的任意性”概念为基础，将这一原则从语言扩展到其他领域，以证明其跨领域适用性，尤其是在法律和社会动态中。本文引入了“动机 -> 可证实性 -> 可争议性”链条，认为动机是使行为逻辑易受主体间争议的关键接口。当通过“去动机化”或“冲突横向化”（例如“淹没在鱼群中的狼的模糊性”）等机制打破这一链条时，行为会产生约束性效果，而无需暴露其理由，从而排除了可审理性。这种结构性不透明性，虽然看似不合逻辑，却是一种旨在保护权威免受问责的蓄意设计。本文借鉴香农的熵模型，将任意性形式化为 A = H(L|M)（条件熵）。因此，本文提出了一种关于任意性的现代理论，将其视为控制和关怀的核心中性操作符，这是人际关系中一个被忽视的维度。尽管该框架主要通过人类社会系统发展而来，但它也为分析先进人工智能系统中的可解释性提供了新的途径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [283] [T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text](https://arxiv.org/abs/2507.23577)
> *T-Detect：针对对抗性机器生成文本的尾部感知统计归一化鲁棒检测方法*

*Alva West, Luodan Zhang, Liuliu Zhang, Minjun Zhu, Yixuan Weng, Yue Zhang* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 机器生成文本检测, 对抗性文本, 学生t-分布, 统计归一化, 鲁棒性

**Comment:** 

> **TL;DR:** T-Detect通过用学生t-分布替换高斯归一化，实现了对对抗性机器生成文本的鲁棒检测，性能优于基线并达到SOTA。

**AI_Comments:** 本文的创新之处在于通过引入基于t-分布的归一化方法来解决对抗性文本的非高斯特性，这在理论上通过观察到的峰度得到了证明。这使得检测方法对复杂的规避尝试更加鲁棒。持续的性能提升和最先进的结果证明了其在对抗机器生成内容泛滥方面的实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 随着复杂文本生成模型的普及，需要开发鲁棒的检测方法来识别机器生成内容，特别是那些旨在通过对抗性扰动逃避检测的文本。现有零样本检测器依赖于隐式假设高斯分布的统计测量，但在面对对抗性或非母语英语文本特有的重尾统计伪影时会失效。

**Method:** T-Detect是一种新颖的检测方法，它从根本上重新设计了基于曲率的检测器的统计核心。其主要创新是将标准高斯归一化替换为源自学生t-分布的重尾差异分数。T-Detect通过将文本段落的对数似然与t-分布的预期矩进行归一化来计算检测分数。

**Result:** T-Detect在强基线上提供了持续的性能提升，在目标领域中AUROC提高了高达3.9%。当集成到二维检测框架（CT）中时，该方法实现了最先进的性能，在RAID的Books领域达到了0.926的AUROC。

**Conclusion:** 本文的贡献在于为文本检测提供了一个新的、理论上合理的统计基础，一个经过消融验证的方法，证明了卓越的鲁棒性，以及对其在对抗性条件下的性能的全面分析。

> **ai_Abstract:** 本文介绍了T-Detect，一种鲁棒检测对抗性机器生成文本的新方法。它解决了现有零样本检测器假设高斯分布的局限性，该假设在处理重尾对抗性文本时失效。T-Detect将高斯归一化替换为基于学生t-分布的差异分数，利用对抗性文本中观察到的显著峰度。这种方法对异常值表现出卓越的弹性。在RAID和HART数据集上的实验表明，T-Detect持续优于基线，AUROC提高了高达3.9%，并且当集成到二维框架中时，实现了最先进的性能（AUROC 0.926）。

> **摘要翻译:** 复杂文本生成模型的激增使得开发鲁棒的检测方法变得必要，这些方法能够识别机器生成的内容，特别是旨在通过对抗性扰动逃避检测的文本。现有的零样本检测器通常依赖于隐式假设高斯分布的统计测量，当遇到对抗性或非母语英语文本特有的重尾统计伪影时，这一前提就会失效。本文介绍了T-Detect，一种新颖的检测方法，它从根本上重新设计了基于曲率的检测器的统计核心。我们的主要创新是将标准高斯归一化替换为源自学生t-分布的重尾差异分数。这种方法在理论上基于经验观察，即对抗性文本表现出显著的峰度（leptokurtosis），使得传统的统计假设不足。T-Detect通过将文本段落的对数似然与t-分布的预期矩进行归一化来计算检测分数，从而提供对统计异常值的卓越弹性。我们在具有挑战性的对抗性文本RAID基准测试和综合HART数据集上验证了我们的方法。实验表明，T-Detect在强基线上提供了持续的性能提升，在目标领域中AUROC提高了高达3.9%。当集成到二维检测框架（CT）中时，我们的方法实现了最先进的性能，在RAID的Books领域达到了0.926的AUROC。我们的贡献是为文本检测提供了一个新的、理论上合理的统计基础，一个经过消融验证的方法，证明了卓越的鲁棒性，以及对其在对抗性条件下的性能的全面分析。我们的代码已在 https://github.com/ResearAI/t-detect 发布。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [295] [Deep Learning Approaches for Multimodal Intent Recognition: A Survey](https://arxiv.org/abs/2507.22934)
> *深度学习方法在多模态意图识别中的应用：一项综述*

*Jingwei Zhao, Yuhua Wen, Qifei Li, Minchi Hu, Yingying Zhou, Jingyao Xue, Junyang Wu, Yingming Gao, Zhengqi Wen, Jianhua Tao, Ya Li* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 意图识别, 多模态, 深度学习, Transformer, 综述

**Comment:** Submitted to ACM Computing Surveys

> **TL;DR:** 本文综述了深度学习在多模态意图识别中的应用，涵盖了从单模态到多模态的演变、Transformer模型、数据集、方法、应用和挑战。

**AI_Comments:** 这篇综述文章为多模态意图识别领域的研究人员提供了宝贵的资源，系统地梳理了该领域的演变、关键技术（尤其是Transformer模型）、挑战和未来方向。其价值在于整合了分散的知识，并指明了潜在的研究空白。

<details>
  <summary>Details</summary>

**Motivation:** 随着对自然人机交互需求的增长，意图识别领域已发展到结合深度学习和多模态方法，并且Transformer模型的引入带来了突破。因此，需要对这些进展进行系统性回顾。

**Method:** 本文通过综述的方式，系统性地回顾了深度学习在多模态意图识别中的应用，特别是从单模态到多模态技术的转变，并涵盖了相关数据集、方法、应用和当前挑战。

**Result:** 综述了深度学习在多模态意图识别中的最新进展，包括从单模态到多模态的转变、Transformer模型的应用、相关数据集、方法论、应用和当前挑战。

**Conclusion:** 本文旨在为研究人员提供多模态意图识别领域的最新发展见解和未来研究方向。

> **ai_Abstract:** 本文对深度学习在多模态意图识别领域的应用进行了全面综述。它追溯了意图识别从传统文本分析到整合音频、视觉和生理信号的多模态方法的演变，并强调了Transformer模型带来的最新突破。综述内容涵盖了相关数据集、方法论、应用及当前挑战，旨在为研究人员提供该领域的最新洞察和未来研究方向。

> **摘要翻译:** 意图识别旨在识别用户的潜在意图，传统上在自然语言处理中侧重于文本。随着对自然人机交互需求的增长，该领域通过深度学习和多模态方法得到了发展，整合了来自音频、视觉和生理信号的数据。最近，基于Transformer模型的引入在该领域取得了显著突破。本文综述了用于意图识别的深度学习方法，涵盖了从单模态到多模态技术的转变、相关数据集、方法论、应用和当前挑战。它为研究人员提供了多模态意图识别（MIR）最新进展的见解和未来研究方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [297] [AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora](https://arxiv.org/abs/2505.23628)
> *AutoSchemaKG：通过网络规模语料库的动态模式归纳实现自主知识图谱构建*

*Jiaxin Bai, Wei Fan, Qi Hu, Qing Zong, Chunyang Li, Hong Ting Tsang, Hongyu Luo, Yauwai Yim, Haoyu Huang, Xiao Zhou, Feng Qin, Tianshi Zheng, Xi Peng, Xin Yao, Huiwen Yang, Leijie Wu, Yi Ji, Gong Zhang, Renhai Chen, Yangqiu Song* | **Category: cs.CL, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识图谱构建, 动态模式归纳, 大型语言模型, 自主学习, ATLAS

**Comment:** 9 pages, preprint, code:
  https://github.com/HKUST-KnowComp/AutoSchemaKG

> **TL;DR:** AutoSchemaKG是一个利用大型语言模型从海量文本中自主构建知识图谱的框架，无需预定义模式，它能同时提取知识三元组并归纳模式，构建了十亿规模的知识图谱ATLAS，并在多跳问答任务中超越现有基线，增强了大型语言模型的真实性。

**AI_Comments:** 这项工作具有重要意义，因为它解决了传统知识图谱构建中对预定义模式的依赖问题，实现了完全自主的构建。通过利用大型语言模型，它能够从海量非结构化文本中自动提取知识并归纳模式，极大地提高了知识图谱的构建效率和灵活性。其在十亿规模知识图谱上的成功应用，以及对LLM性能的提升，展示了其巨大的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的知识图谱构建需要预定义的模式，这限制了其灵活性和自主性。本文旨在消除对预定义模式的需求，实现完全自主的知识图谱构建。

**Method:** 本文提出了AutoSchemaKG框架，利用大型语言模型（LLMs）从文本中同时提取知识三元组并归纳全面的模式。该方法对实体和事件进行建模，并采用概念化将实例组织成语义类别。通过处理超过5000万份文档，构建了ATLAS（Automated Triple Linking And Schema induction）知识图谱家族。

**Result:** AutoSchemaKG构建了ATLAS知识图谱家族，包含9亿多节点和59亿条边。该方法在多跳问答任务中优于最先进的基线，并增强了大型语言模型的真实性。此外，其模式归纳在零人工干预下，实现了与人工制作模式92%的语义对齐。

**Conclusion:** 十亿规模的、具有动态归纳模式的知识图谱可以有效地补充大型语言模型中的参数化知识，并且AutoSchemaKG展示了无需预定义模式的自主知识图谱构建的可行性和优越性。

> **ai_Abstract:** AutoSchemaKG是一个创新的框架，它通过利用大型语言模型从网络规模语料库中自主地构建知识图谱，无需预设模式。该系统能够同时提取知识三元组并动态归纳全面的模式，涵盖实体和事件，并通过概念化组织实例。通过处理5000万份文档，AutoSchemaKG构建了十亿规模的ATLAS知识图谱，并在多跳问答任务中表现出色，提升了LLM的真实性，其模式归纳与人工模式实现了高度语义对齐，且无需人工干预。

> **摘要翻译:** 我们提出了AutoSchemaKG，一个用于完全自主知识图谱构建的框架，它消除了对预定义模式的需求。我们的系统利用大型语言模型，同时从文本中提取知识三元组并归纳全面的模式，对实体和事件进行建模，同时采用概念化将实例组织成语义类别。通过处理超过5000万份文档，我们构建了ATLAS（自动化三元组链接和模式归纳），这是一个拥有9亿多节点和59亿条边的知识图谱家族。这种方法在多跳问答任务中优于最先进的基线，并增强了大型语言模型的真实性。值得注意的是，我们的模式归纳在零人工干预下，实现了与人工制作模式92%的语义对齐，这表明具有动态归纳模式的十亿规模知识图谱可以有效地补充大型语言模型中的参数化知识。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [298] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
> *长上下文语言模型优化技术系统评估*

*Ammar Ahmed, Sheng Di, Franck Cappello, Zirui Liu, Jingoo Han, Ali Anwar* | **Category: cs.CL, cs.LG, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 长上下文语言模型, 优化技术, 系统评估, 内存使用, 性能基准

**Comment:** 

> **TL;DR:** 本文系统评估了用于长上下文语言模型的修剪、量化和令牌丢弃等优化技术，揭示了朴素组合优化算法在大型模型上可能因复合近似误差而产生负面影响，并强调了系统级分析与任务特定洞察相结合的重要性。

**AI_Comments:** 该论文的创新点在于系统地评估了多种优化技术及其组合在长上下文LLM上的性能，并特别指出了朴素组合优化可能对大型模型产生负面影响的风险。其重要性在于为LLM的实际部署提供了关键的性能和质量权衡见解，有助于从业者更好地选择和应用优化策略。论文强调了超越单一指标（如F1）进行全面系统级分析的必要性，这是其价值所在。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言处理任务中表现出色，但面临资源需求高和上下文窗口受限的问题。尽管修剪、量化和令牌丢弃等技术可以缓解这些问题，但它们在长上下文场景中的效率和系统评估尚未得到充分探索。

**Method:** 本文系统地对LLM的优化技术（如修剪、量化和令牌丢弃）进行了基准测试。研究了这些方法对内存使用、延迟和吞吐量的影响，以及它们如何影响文本生成质量。首先分析了两种支持长上下文的LLM架构的个体优化方法，然后系统评估了这些技术的组合。随后，研究了单个优化方法在700亿参数的更大变体模型上的可扩展性。

**Result:** 研究发现，与小型模型相比，朴素组合推理优化算法可能由于复合近似误差而对大型模型产生不利影响。实验表明，仅依赖F1分数会掩盖问答任务中精确度-召回率的权衡，从而隐藏这些影响。

**Conclusion:** 通过将系统级分析与任务特定洞察相结合，这项研究有助于LLM从业者和研究人员在不同任务和硬件配置下探索和平衡效率、准确性和可扩展性。

> **ai_Abstract:** 本文系统评估了用于长上下文大型语言模型（LLMs）的优化技术，如修剪、量化和令牌丢弃。研究关注这些技术在内存、延迟、吞吐量和文本生成质量方面的影响，特别是在长上下文和更大模型上的表现。研究发现，简单的优化技术组合可能对大型模型产生负面影响，且仅凭F1分数不足以全面评估效果。该研究强调了系统级性能与任务特定质量之间平衡的重要性，为LLM的实际应用提供了指导。

> **摘要翻译:** 大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但面临资源需求和上下文窗口受限的问题。尽管修剪、量化和令牌丢弃等技术可以缓解这些问题，但它们在长上下文场景中的效率和系统评估仍未得到充分探索。本文系统地对这些优化措施进行基准测试，描述了内存使用、延迟和吞吐量，并研究了这些方法如何影响文本生成质量。我们首先分析了支持长上下文的两种LLM架构的个体优化方法，然后系统地评估了这些技术的组合，以评估这种更深入的分析如何影响性能指标。随后，我们研究了单个优化方法在具有700亿参数的更大变体模型上的可扩展性。我们的新颖见解表明，与小型模型相比，朴素组合推理优化算法由于复合近似误差，可能对大型模型产生不利影响。实验表明，仅依赖F1会通过隐藏问答任务中的精确度-召回率权衡来掩盖这些影响。通过将系统级分析与任务特定洞察相结合，这项研究有助于LLM从业者和研究人员在不同任务和硬件配置下探索和平衡效率、准确性和可扩展性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [302] [FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification](https://arxiv.org/abs/2507.22932)
> *FinMarBa: 一个市场信息驱动的金融情感分类数据集*

*Baptiste Lefort, Eric Benhamou, Beatrice Guez, Jean-Jacques Ohana, Ethan Setrouk, Alban Etienne* | **Category: cs.CL, q-fin.GN** | **Updated: 2025-07-24**

**Keywords:** 投资组合优化, 深度强化学习, 大型语言模型, 金融情感, 分层框架

**Comment:** 8 pages

> **TL;DR:** 本文提出了一个新颖的投资组合优化分层框架，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合，以整合金融新闻中的情绪信号与传统市场指标，实现了高额回报并超越了基准。

**AI_Comments:** 该论文通过将大型语言模型（LLMs）和深度强化学习（DRL）以分层结构结合应用于投资组合优化，提出了一种创新方法，这对于利用复杂数据进行金融决策具有重要意义。分层设计可能有助于其报告的稳定性，而开源特性对于可复现性而言值得称赞。报告的性能指标令人印象深刻，表明具有实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过整合金融新闻中的情绪信号与传统市场指标，利用轻量级大型语言模型（LLMs）和深度强化学习（DRL）来改进投资组合优化，以期做出更优的投资决策。

**Method:** 该研究提出了一个新颖的、结合轻量级LLMs与DRL的分层投资组合优化框架。该框架采用三层架构：基础RL代理处理混合数据，元代理聚合这些决策，而超级代理则根据市场数据和情感分析来合并最终决策。

**Result:** 该框架在2018年至2024年的数据上（在2000年至2017年数据上训练）进行了评估，实现了26%的年化回报率和1.2的夏普比率，表现优于等权重和标普500基准。

**Conclusion:** 主要贡献包括可扩展的跨模态集成、增强稳定性的分层RL结构以及开源可复现性。该框架成功地结合了情感和市场数据，实现了卓越的投资组合优化。

> **ai_Abstract:** 本文提出了一个新颖的分层深度强化学习框架，该框架集成了轻量级大型语言模型，旨在将金融新闻情感与传统市场指标相结合，以优化投资组合。其三层架构处理混合数据并聚合决策，在2018-2024年的评估数据上实现了26%的年化回报率和1.2的夏普比率，表现优于标准基准。主要贡献包括可扩展的跨模态集成、通过分层RL增强稳定性以及开源可复现性。

> **摘要翻译:** 本文提出了一个新颖的投资组合优化分层框架，将轻量级大型语言模型（LLMs）与深度强化学习（DRL）相结合，以整合金融新闻中的情绪信号与传统市场指标。我们的三层架构采用基础RL代理处理混合数据，元代理聚合其决策，以及一个超级代理根据市场数据和情感分析合并决策。该框架在2018年至2024年的数据上进行了评估（在2000年至2017年数据上训练），实现了26%的年化回报率和1.2的夏普比率，优于等权重和标普500基准。主要贡献包括可扩展的跨模态集成、增强稳定性的分层RL结构以及开源可复现性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [309] [Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators](https://arxiv.org/abs/2507.23399)
> *超越云端：评估本地大型语言模型部署对翻译人员的益处与挑战*

*Peter Sandrini* | **Category: cs.CL, cs.CY, I.2.7; K.4.3** | **Updated: 2025-07-31**

**Keywords:** 本地部署, 大型语言模型, 数据隐私, 翻译, 开源模型

**Comment:** 

> **TL;DR:** 本研究探讨了针对翻译人员的本地部署大型语言模型的可能性和性能，旨在解决数据隐私和访问问题，并发现本地部署在数据控制、隐私和减少对云服务依赖方面具有显著优势，从而推动AI的民主化。

**AI_Comments:** 该论文创新性地将焦点从传统的云端大型语言模型应用转向本地部署，这对于关注数据隐私和自主控制的翻译专业人士及小型企业具有重要的实际意义。研究强调了AI民主化的潜力，并为未来在资源受限环境下推广LLM应用提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于云的商业大型语言模型在翻译领域备受关注，但数据隐私、安全性及公平访问方面的担忧促使研究人员探索替代的部署模式。

**Method:** 本研究调查了本地部署的免费语言模型作为专有云端AI解决方案的可行性和性能。研究评估了安装在基于CPU平台上的三个开源模型，并与商业在线聊天机器人进行了比较。评估侧重于功能性能而非人机翻译质量的比较分析。

**Result:** 尽管本地部署带来了一些挑战，但增强的数据控制、改进的隐私保护和减少对云服务的依赖等优势是引人注目的。

**Conclusion:** 本研究的发现有助于推动AI技术民主化，并为未来的研究和开发工作提供信息，旨在使大型语言模型对更广泛的用户（特别是个人翻译人员和小型企业）更易于访问和实用。

> **ai_Abstract:** 本研究旨在评估本地部署大型语言模型对翻译专业人员的可行性和优势，以应对云端解决方案带来的数据隐私和访问挑战。研究比较了三个基于CPU的开源模型与商业在线聊天机器人的功能性能。结果表明，尽管存在一些挑战，本地部署在数据控制、隐私保护和降低对云服务的依赖方面具有显著益处，这对于推动AI技术的民主化，特别是为个人翻译人员和小型企业提供更实用、可访问的LLM解决方案具有重要意义。

> **摘要翻译:** 大型语言模型的迅速普及为翻译领域带来了机遇与挑战。尽管商业的、基于云的AI聊天机器人在翻译研究中引起了广泛关注，但对数据隐私、安全性和公平访问的担忧促使人们探索替代的部署模式。本文研究了本地部署的免费语言模型作为专有云端AI解决方案的可行性和性能。本研究评估了安装在基于CPU平台上的三个开源模型，并与商业在线聊天机器人进行了比较。评估侧重于功能性能，而非人机翻译质量的比较分析，后者已是广泛研究的领域。所评估的平台因其在各种操作系统上的可访问性和易用性而被选中。虽然本地部署带来了自身的挑战，但增强数据控制、改进隐私和减少对云服务的依赖等好处是引人注目的。本研究的发现有助于日益增长的关于人工智能技术民主化的知识体系，并为未来的研究和开发工作提供信息，旨在使大型语言模型对更广泛的用户，特别是针对个人翻译人员和小型企业的需求，更易于访问和实用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [310] [DiffLoRA: Differential Low-Rank Adapters for Large Language Models](https://arxiv.org/abs/2507.23588)
> *DiffLoRA：大型语言模型的差分低秩适配器*

*Alexandre Misrahi, Nadezhda Chirkova, Maxime Louis, Vassilina Nikoulina* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** DiffLoRA, 低秩适配器, 差分注意力, 大语言模型, 参数高效微调

**Comment:** 

> **TL;DR:** DiffLoRA引入了一种参数高效的差分注意力机制，通过在正负注意力项上使用低秩适配器来提高大型语言模型的性能。尽管在大多数任务中表现不如其他PEFT方法，但在特定领域（如HumanEval）显示出有趣的结果。

**AI_Comments:** DiffLoRA的创新之处在于将差分注意力机制与LoRA相结合，以实现参数高效的微调。尽管在通用任务上表现不佳，但其在特定领域（如HumanEval）的显著提升表明其在处理特定类型任务（可能与代码或需要精细逻辑推理的任务有关）时具有独特优势。这提示了未来研究方向，即如何识别和利用这种方法的特定适用场景。同时，对注意力模式的分析也增加了对模型行为的理解。

<details>
  <summary>Details</summary>

**Motivation:** 最近提出的差分Transformer通过去噪注意力机制消除噪声来提高Transformer模型的性能。这项工作的动机是引入一种参数高效的差分注意力机制的适应版本，以期在保持LoRA效率的同时，受益于差分注意力的性能提升。

**Method:** 本文引入了DiffLoRA，它是差分注意力机制的一种参数高效适应方法，在正注意力和负注意力项上都使用了低秩适配器。这种方法旨在保留LoRA的效率，同时受益于差分注意力的性能增益。

**Result:** DiffLoRA在广泛的NLP任务中进行了评估，包括通用基准测试、多样本上下文学习、RAG和长上下文测试。结果表明，尽管DiffLoRA在大多数评估任务中未能超越其他参数高效微调方法，但在某些领域显示出有趣的结果（在HumanEval上比LoRA高出11分）。研究还分析了微调后的注意力模式，以找出这种行为的原因。

**Conclusion:** DiffLoRA作为差分注意力机制的参数高效适应方法，在特定领域（如HumanEval）展现出潜力，尽管在多数NLP任务中未能全面超越现有参数高效微调方法。这表明其在特定噪声敏感或需要精细注意力控制的任务中可能具有优势，值得进一步研究其特定应用场景和内在机制。

> **ai_Abstract:** 本文提出了DiffLoRA，一种结合了差分注意力机制和低秩适配器的参数高效微调方法。DiffLoRA在大型语言模型的正负注意力项上应用低秩适配器，旨在在保持LoRA效率的同时，利用差分注意力去噪的优势。尽管在多数NLP任务中表现未及其他参数高效微调方法，DiffLoRA在特定领域，如代码生成（HumanEval），展现出显著的性能提升。研究还通过分析注意力模式来探究其性能特点。

> **摘要翻译:** 差分Transformer最近被提出，旨在通过去噪注意力机制消除噪声来提高Transformer模型的性能。在这项工作中，我们引入了DiffLoRA，它是差分注意力机制的一种参数高效适应方法，在正注意力和负注意力项上都使用了低秩适配器。这种方法旨在保留LoRA的效率，同时受益于差分注意力的性能增益。我们在广泛的NLP任务中评估了DiffLoRA，包括通用基准测试、多样本上下文学习、RAG和长上下文测试。我们观察到，尽管DiffLoRA在大多数评估任务中未能超越其他参数高效微调方法，但在某些领域显示出有趣的结果（在HumanEval上比LoRA高出11分）。我们分析了微调后的注意力模式，以找出这种行为的原因。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [337] [Trusted Knowledge Extraction for Operations and Maintenance Intelligence](https://arxiv.org/abs/2507.22935)
> *用于运营和维护智能的可信知识提取*

*Kathleen Mealey, Jonathan A. Karr Jr., Priscila Saboia Moreira, Paul R. Brenner, Charles F. Vardeman II* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-24**

**Keywords:** 知识提取, 运营维护, 大型语言模型, 自然语言处理, 可信应用

**Comment:** 

> **TL;DR:** 本文讨论了在运营和维护领域，从组织数据中提取可信知识所面临的挑战，并评估了NLP工具和大型语言模型在知识图谱构建中的表现，特别关注航空业的应用，并指出了现有工具的性能限制和对可信度的需求。

**AI_Comments:** 本文创新性地关注了在数据保密性要求高的关键行业（如航空业）中，知识提取的可信度问题，并对现有NLP和LLM工具的性能进行了实证评估。其提供的开源数据集对于后续研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于数据保密性与数据集成目标之间的矛盾，以及自然语言处理（NLP）工具在运营和维护等特定领域知识结构方面的局限性，从组织数据存储库中获取运营智能是一个关键挑战。

**Method:** 本文讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取等功能组件。作者评估了16种NLP工具，并将其与大型语言模型（LLM）的进步能力进行比较或结合使用。研究重点是航空业中可信应用的运营和维护智能用例。基线数据集来源于美国联邦航空管理局关于设备故障或维护需求的公开数据集。作者评估了可在受控、保密环境中运行的NLP和LLM工具的零样本性能。

**Result:** 作者观察到NLP和LLM工具在性能上存在显著限制，并讨论了与可信NLP和LLM工具相关的挑战，以及它们在航空等任务关键型行业中更广泛使用的技术成熟度水平。

**Conclusion:** 本文总结了增强信任的建议，并提供了开源的精选数据集，以支持进一步的基线测试和评估。

> **ai_Abstract:** 本文探讨了在运营和维护领域，从组织数据中提取可信知识的挑战，特别是数据保密性和NLP工具的局限性。研究分解了知识提取过程，并评估了16种NLP工具与大型语言模型在航空业运营维护智能用例中的零样本性能。研究发现现有工具性能存在显著限制，并讨论了可信工具的挑战和技术成熟度，最后提出了增强信任的建议并发布了开源数据集。

> **摘要翻译:** 从组织数据存储库中获取运营智能是一个关键挑战，这既因为数据保密性与数据集成目标之间的二分法，也因为自然语言处理（NLP）工具相对于运营和维护等领域特定知识结构的局限性。在这项工作中，我们讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取等功能组件。然后，我们评估了16种NLP工具，结合或比较了大型语言模型（LLM）的快速发展能力。我们专注于航空业中可信应用程序的运营和维护智能用例。基线数据集来源于一个丰富的公共领域美国联邦航空管理局数据集，该数据集侧重于设备故障或维护要求。我们评估了可在受控、保密环境中运行（数据不发送给第三方）的NLP和LLM工具的零样本性能。基于我们观察到的显著性能限制，我们讨论了与可信NLP和LLM工具相关的挑战，以及它们在航空等任务关键型行业中更广泛使用的技术成熟度水平。最后，我们总结了增强信任的建议，并提供了我们的开源精选数据集，以支持进一步的基线测试和评估。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [338] [Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning](https://arxiv.org/abs/2507.23661)
> *阿拉伯语社交媒体仇恨言论识别与屏蔽：基于深度学习模型和预训练模型微调*

*Salam Thabet Doghmash, Motaz Saad* | **Category: cs.CL, I.2.7** | **Updated: 2025-07-31**

**Keywords:** 阿拉伯语仇恨言论, 深度学习, Transformer, 文本屏蔽, 社交媒体

**Comment:** 23 pages, 5 figures

> **TL;DR:** 本研究利用深度学习模型和Transformer解决了阿拉伯语社交媒体中的仇恨言论检测和屏蔽（用星号替换）问题，并在两项任务中均取得了良好效果。

**AI_Comments:** 本文的创新点在于同时解决了阿拉伯语仇恨言论的检测和屏蔽问题，并将屏蔽任务创新性地视为机器翻译问题。其在检测任务上取得了较高的F1分数和准确率，在屏蔽任务上也取得了与现有技术相当的结果，为处理阿拉伯语仇恨言论提供了有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 社交媒体中的仇恨言论识别近年来变得日益重要。本研究旨在解决阿拉伯语文本中的仇恨言论检测和清理（屏蔽）问题。

**Method:** 对于仇恨言论检测，研究者使用深度学习模型和Transformer进行实验以确定F1分数最佳模型。对于仇恨言论清理（屏蔽），研究者将其视为机器翻译任务，将包含仇恨言论的句子作为输入，输出为用星号替换仇恨词的相同句子。

**Result:** 仇恨言论检测的最佳模型达到了92%的Macro F1分数和95%的准确率。仇恨言论屏蔽模型的最佳BLEU分数（1-gram）达到了0.3，与现有最先进的机器翻译系统相比表现良好。

**Conclusion:** 提出的方法在阿拉伯语仇恨言论检测和屏蔽方面取得了有效的结果，尤其是在检测任务上表现出色，并在屏蔽任务上取得了与先进机器翻译系统相当的性能。

> **ai_Abstract:** 本文旨在解决阿拉伯语社交媒体中的仇恨言论问题，并提出了检测与屏蔽两种方案。在检测任务中，研究者利用深度学习模型和Transformer实现了92%的Macro F1分数和95%的准确率。在屏蔽任务中，通过将问题建模为机器翻译，用星号替换仇恨词，取得了0.3的BLEU分数（1-gram），显示出其有效性。

> **摘要翻译:** 社交媒体中的仇恨言论识别近年来已成为一个日益重要的问题。在本研究中，我们解决了两个问题：1）检测阿拉伯语文本中的仇恨言论，2）清理给定文本中的仇恨言论。这里“清理”的含义是根据每个单词的字母数量用星号替换每个不良词语。关于第一个问题，我们使用深度学习模型和Transformer进行了多项实验，以确定F1分数方面的最佳模型。关于第二个问题，我们将其视为一个机器翻译任务，其中输入是包含“脏”文本的句子，输出是相同句子但“脏”文本被屏蔽。所提出的方法在仇恨言论检测中取得了最佳模型，Macro F1分数达到92%，准确率达到95%。关于文本清理实验，仇恨言论屏蔽模型的最佳结果在BLEU分数（1-gram）上达到了0.3，与现有最先进的机器翻译系统相比，这是一个不错的结果。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [344] [CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering](https://arxiv.org/abs/2507.22937)
> *CoE-Ops：基于LLM专家的AIOps问答协作*

*Jinkun Zhao, Yuanshuai Wang, Xingjian Zhang, Ruibo Chen, Xingchuang Liao, Junle Wang, Lei Huang, Kui Zhang, Wenjun Wu* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** AIOps, LLM, 专家协作, 问答, DevOps

**Comment:** 

> **TL;DR:** 本文提出了CoE-Ops，一个基于LLM的专家协作框架，用于AIOps问答，显著提高了现有方法的准确性。

**AI_Comments:** 本文的创新之处在于将“专家协作”范式应用于AIOps问答，该范式受到了集成学习和LLM训练的启发。通用LLM任务分类器和检索增强生成的使用是其关键优势。其重要性在于解决了AIOps中领域特定知识的挑战，并展示了显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 现有AIOps模型受限于领域特定知识，只能处理特定任务。结合多个模型已被证明能获得更高效的结果，这启发了作者为AIOps挑战提出类似方法。

**Method:** 本文提出了CoE-Ops，一个专家协作框架，其中包含一个通用大型语言模型任务分类器。引入了检索增强生成机制，以提高框架处理高级（代码、构建、测试等）和低级（故障分析、异常检测等）问答任务的能力。该方法在AIOps领域实现，并在DevOps-EVAL数据集上进行了广泛实验。

**Result:** CoE-Ops在高级AIOps任务的路由准确性方面比现有CoE方法提高了72%。在DevOps问题解决方面，比单一AIOps模型提高了高达8%的准确性。在准确性方面，比更大规模的专家混合（MoE）模型高出高达14%。

**Conclusion:** CoE-Ops通过有效结合基于LLM的专家和检索增强生成，显著增强了AIOps问答能力，并在各种任务级别上表现出卓越的性能。

> **ai_Abstract:** 本文介绍了CoE-Ops，一个专家协作框架，它利用大型语言模型和检索增强生成机制，以解决AIOps问答中单一模型方法的局限性。该框架旨在改进对高级和低级AIOps任务的处理能力。在DevOps-EVAL数据集上的实验表明，CoE-Ops在各种AIOps问题解决的准确性方面显著优于现有CoE方法、单一AIOps模型以及更大规模的专家混合模型。

> **摘要翻译:** 随着人工智能的快速发展，AIOps已成为DevOps中一个突出的范式。许多工作被提出以改善不同AIOps阶段的性能。然而，受限于领域特定知识，单一模型只能处理特定任务的操作需求，例如日志解析器、根本原因分析。同时，结合多个模型可以获得更高效的结果，这在之前的集成学习和最近的LLM训练领域都已得到证明。受这些工作的启发，为了解决AIOps中类似的挑战，本文首次提出了一个专家协作框架（CoE-Ops），其中包含一个通用大型语言模型任务分类器。引入了检索增强生成机制，以提高框架处理高级（代码、构建、测试等）和低级（故障分析、异常检测等）问答任务的能力。最后，所提出的方法在AIOps领域中实现，并在DevOps-EVAL数据集上进行了广泛实验。实验结果表明，与现有CoE方法相比，CoE-Ops在高级AIOps任务的路由准确性方面提高了72%，在DevOps问题解决方面比单一AIOps模型提高了高达8%的准确性，并且在准确性方面比更大规模的专家混合（MoE）模型高出高达14%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [346] [Framing Political Bias in Multilingual LLMs Across Pakistani Languages](https://arxiv.org/abs/2506.00068)
> *巴基斯坦语言多语言大型语言模型中的政治偏见框架*

*Afrozah Nadeem, Mark Dras, Usman Naseem* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 政治偏见, 多语言LLM, 巴基斯坦语言, 文化适应, 偏见审计

**Comment:** Preprint

> **TL;DR:** 大型语言模型在巴基斯坦语言中存在政治偏见，尤其在地区语言中表现出更多的威权主义倾向，这突出表明了语言对意识形态的调制作用，并强调了文化适应的多语言偏见审计框架的必要性。

**AI_Comments:** 这项研究填补了大型语言模型偏见评估在低资源、多语言地区（如巴基斯坦）的空白，具有重要的创新性。其方法结合了文化适应的政治罗盘测试和多层次框架分析，深入揭示了语言对LLM意识形态输出的影响。这项工作对于推动全球自然语言处理领域的偏见审计框架发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLM）政治和经济偏见评估主要集中在西方高资源语言和语境，导致在巴基斯坦等低资源、多语言地区存在盲点，而这些地区的语言身份与政治、宗教和地区意识形态紧密相关。

**Method:** 本研究对13个最先进的LLM进行了系统性政治偏见评估，涵盖乌尔都语、旁遮普语、信德语、普什图语和俾路支语五种巴基斯坦语言。研究框架整合了文化适应的政治罗盘测试（PCT）与多层次框架分析，以捕捉意识形态立场（经济/社会轴）和文体框架（内容、语气、强调）。提示与巴基斯坦特有的11个社会政治主题对齐。

**Result:** 结果显示，LLM主要反映与西方训练数据一致的自由左翼倾向，但在地区语言中表现出更多的威权主义框架，这突出了语言条件下的意识形态调制。研究还识别出跨语言一致的模型特定偏见模式。

**Conclusion:** 这些发现表明，在全球自然语言处理（NLP）领域，需要建立 culturally grounded、multilingual 的偏见审计框架。

> **ai_Abstract:** 本论文评估了13个大型语言模型在五种巴基斯坦语言中的政治偏见。研究发现，尽管模型主要呈现与西方训练数据一致的自由左翼倾向，但在巴基斯坦的地区语言中表现出更多威权主义的框架，揭示了语言对意识形态输出的调制作用。研究强调了在全球自然语言处理领域，建立文化适应的多语言偏见审计框架的必要性。

> **摘要翻译:** 大型语言模型（LLM）日益塑造着公共话语，然而，大多数关于政治和经济偏见的评估都集中在高资源、西方语言和语境。这在巴基斯坦等低资源、多语言地区留下了关键的盲点，因为在这些地区，语言身份与政治、宗教和地区意识形态紧密相连。我们对13个最先进的LLM在五种巴基斯坦语言（乌尔都语、旁遮普语、信德语、普什图语和俾路支语）中的政治偏见进行了系统性评估。我们的框架整合了文化适应的政治罗盘测试（PCT）与多层次框架分析，捕捉意识形态立场（经济/社会轴）和文体框架（内容、语气、强调）。提示与巴基斯坦特有的11个社会政治主题对齐。结果显示，虽然LLM主要反映与西方训练数据一致的自由左翼倾向，但它们在地区语言中表现出更多的威权主义框架，这突出了语言条件下的意识形态调制。我们还识别出跨语言一致的模型特定偏见模式。这些发现表明，在全球NLP领域，需要建立 culturally grounded、multilingual 的偏见审计框架。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [352] [Explaining vague language](https://arxiv.org/abs/2404.18154)
> *解释模糊语言*

*Paul Égré, Benjamin Spector* | **Category: cs.CL, cs.GT, cs.IT, math.IT, 91A86, I.2.7** | **Updated: 2025-07-31**

**Keywords:** 模糊语言, 博弈论, 贝叶斯理论, 语义, 信号策略

**Comment:** 

> **TL;DR:** 本文比较了两种模糊语言解释理论（博弈论和贝叶斯理论），并论证了语义解释的必要性。

**AI_Comments:** 本文通过比较两种看似矛盾的模糊语言解释理论，巧妙地解决了博弈论解释中的“模糊性难题”，并引入了语义内容在解释模糊性中的关键作用。其创新之处在于提供了一个整合性的视角，强调了语义层面对语言实用性和信息传递理解的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 解释语言为何模糊，并探讨模糊语言是否比精确语言更有用。

**Method:** 本文旨在比较Lipman提出的博弈论模糊性解释与'Egr'e et al.提出的贝叶斯模糊性解释，并分析两者为何不矛盾。

**Result:** 发现Lipman的模糊性定义侧重于信号策略且不涉及词汇假设，而'Egr'e et al.的定义则包含语义内容层。研究认为语义层面的模糊性解释是必要的。

**Conclusion:** 语义层面的模糊性解释是必要、更充分且更具解释力的。

> **ai_Abstract:** 本文探讨了语言模糊性的原因，并比较了两种主要的模糊性解释理论：利普曼的博弈论视角和埃格雷等人的贝叶斯视角。论文指出，两种理论看似矛盾，实则通过对模糊性定义中是否包含语义内容的区分而得以调和。最终，论文强调了语义解释对于理解语言模糊性而言是更为必要、充分和具有解释力的。

> **摘要翻译:** 语言为何模糊？如果能证明模糊语言对说话者和听者而言比精确语言更有用，那么模糊性就可以得到解释和合理化。在一篇著名的论文中，利普曼（Lipman）提出了一种基于混合策略的模糊性博弈论解释，这导致了一个难题：在均衡状态下，模糊性不可能严格优于精确性。最近，埃格雷（'Egr'e）、斯佩克托（Spector）、莫蒂埃（Mortier）和维尔海恩（Verheyen）提出了一种贝叶斯模糊性解释，确立了使用模糊词语可以比使用精确词语传递更严格的信息。本文旨在比较这两种结果，并解释它们为何不矛盾。利普曼对模糊性的定义完全依赖于信号策略的一个属性，没有对词汇做任何假设，而埃格雷等人的定义则涉及一层语义内容。我们认为，语义层面的模糊性解释是必要的，并且对模糊性来说更充分和具有解释力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [364] [Better Embeddings with Coupled Adam](https://arxiv.org/abs/2502.08441)
> *使用耦合Adam获得更好的嵌入*

*Felix Stollenwerk, Tobias Stollenwerk* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 词嵌入, 各向异性, Adam优化器, 耦合Adam, 大语言模型

**Comment:** ACL 2025 (Main), see https://aclanthology.org/2025.acl-long.1321/

> **TL;DR:** 本文提出耦合Adam优化器，通过解决Adam优化器中二阶矩导致的各向异性问题，显著改善了LLM的词嵌入质量和模型性能。

**AI_Comments:** 这篇论文通过深入分析Adam优化器在LLM嵌入各向异性中的作用，并提出了一种新颖的解决方案——耦合Adam，展示了对现有优化器机制的深刻理解和创新性改进。其贡献在于不仅解释了LLM嵌入的一个关键问题，还提供了实用的改进方法，有望提升LLM的整体性能。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）学习到的词表示存在各向异性（anisotropy）这一不良且未被充分理解的特性。

**Method:** 作者认为Adam优化器中的二阶矩是导致嵌入各向异性的原因，并提出了一种名为“耦合Adam”（Coupled Adam）的改进优化器来缓解这个问题。

**Result:** 实验表明，耦合Adam显著提高了嵌入的质量，并且在足够大的数据集上，也带来了更好的上游和下游任务性能。

**Conclusion:** 耦合Adam优化器能够有效改善词嵌入的质量，并提升大语言模型的整体性能。

> **ai_Abstract:** 本文研究了大语言模型（LLMs）词嵌入中存在的各向异性问题，并指出Adam优化器中的二阶矩是导致该问题的原因。为解决此问题，作者提出了一种名为“耦合Adam”的新型优化器。实验结果表明，耦合Adam不仅显著提升了嵌入质量，还在大型数据集上改善了模型的上游和下游任务表现。

> **摘要翻译:** 尽管大语言模型（LLMs）具有卓越的能力，但它们学习到的词表示却表现出各向异性这一不受欢迎且知之甚少的特征。在本文中，我们认为Adam优化器中的二阶矩是导致嵌入各向异性的原因，并提出了一种名为“耦合Adam”的改进优化器来缓解这个问题。我们的实验表明，耦合Adam显著提高了嵌入的质量，同时在足够大的数据集上，也带来了更好的上游和下游任务性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [366] [Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs](https://arxiv.org/abs/2507.23740)
> *规则到文本：知识图谱中逻辑规则的自然语言解释*

*Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 知识图谱, 逻辑规则, 自然语言解释, 大型语言模型, 提示工程

**Comment:** 

> **TL;DR:** 本文探索使用大型语言模型为知识图谱中的复杂逻辑规则生成自然语言解释，并通过人工评估验证其在解释正确性和清晰度方面的潜力。

**AI_Comments:** 这项研究通过利用大型语言模型将复杂的知识图谱逻辑规则转化为人类可理解的自然语言解释，具有创新性。这对于提升知识图谱的可解释性和可用性至关重要，特别是在需要人工干预或验证的场景中。其通过探索多种提示策略和进行全面的人工评估，为LLM在知识图谱解释领域的应用提供了宝贵的见解。未来研究可以进一步关注如何克服幻觉问题和提高解释的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 知识图谱中的逻辑规则虽然能提升图谱完整性、发现错误、揭示模式并增强推理能力，但其复杂性及独特的标签约定使得人类难以理解。

**Method:** 使用AMIE 3.5.1算法从FB15k-237、FB-CVT-REV和FB+CVT-REV数据集中提取逻辑规则。研究了零样本、少样本、包含变量实体类型和思维链推理等多种提示策略。通过人工评估（基于正确性、清晰度和幻觉）和大型语言模型作为自动评判来评估生成的解释。

**Result:** 在解释的正确性和清晰度方面表现出有前景的性能。

**Conclusion:** 大型语言模型在为知识图谱中的逻辑规则生成自然语言解释方面展现出潜力，尽管仍存在一些挑战需要未来研究解决。

> **ai_Abstract:** 本文旨在解决知识图谱中逻辑规则难以被人理解的问题，提出利用大型语言模型（LLMs）生成规则的自然语言解释。研究通过AMIE 3.5.1算法从多个知识图谱数据集中提取规则，并探索了多种LLM提示策略。通过人工评估，结果显示LLMs在生成正确且清晰的规则解释方面表现良好，证明了其潜力，但也指出仍有待解决的挑战。

> **摘要翻译:** 知识图谱（KGs）通常包含足够的信息来支持新事实的推断。识别逻辑规则不仅可以提高知识图谱的完整性，还可以检测潜在错误，揭示微妙的数据模式，并增强整体的推理和解释能力。然而，这些规则的复杂性，加上每个知识图谱独特的标签约定，使得人类难以理解它们。在本文中，我们探索了大型语言模型为逻辑规则生成自然语言解释的潜力。具体来说，我们使用AMIE 3.5.1规则发现算法从基准数据集FB15k-237以及两个大规模数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则。我们研究了各种提示策略，包括零样本和少样本提示，包括变量实体类型，以及思维链推理。我们根据正确性、清晰度和幻觉对生成的解释进行了全面的 H 人工评估，并评估了将大型语言模型用作自动评判的效用。我们的结果表明，在解释的正确性和清晰度方面表现出有前景的性能，尽管未来研究仍面临一些挑战。本研究中使用的所有脚本和数据均可在 https://github.com/idirlab/KGRule2NL 公开获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [371] [Do Large Language Models Know How Much They Know?](https://arxiv.org/abs/2502.19573)
> *大型语言模型知道自己知道多少吗？*

*Gabriele Prato, Jerry Huang, Prasanna Parthasarathi, Shagun Sodhani, Sarath Chandar* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 知识意识, 自我认知, 基准测试

**Comment:** ublished as a long paper at the 2024 Conference on Empirical Methods
  in Natural Language Processing (EMNLP). Official version of paper within
  conference proceedings is available at
  https://aclanthology.org/2024.emnlp-main.348/

> **TL;DR:** 研究表明，大规模语言模型（LLMs）似乎知道自己拥有多少知识，尽管不同架构的出现速度不同，这可能是一个普遍属性。

**AI_Comments:** 该论文的创新之处在于其设计了一个特定的基准来量化大型语言模型对自身知识的认知程度，这超越了传统性能评估。其重要性在于触及了LLMs更高层次的认知能力，对于理解和构建更可靠、更透明的人工智能系统具有重要意义。然而，论文也指出，目前的研究结果仍需进一步验证，且其潜在机制尚不明朗，这构成了当前的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）被广泛部署，但对其内部机制、能力和局限性的理解仍不足。本研究旨在探究LLMs是否具备智能系统所期望的、识别自身知识范围的能力。

**Method:** 研究人员开发了一个基准测试，旨在挑战LLMs列举其在特定主题上拥有的所有信息。该基准评估模型回忆的信息量是过多、不足还是精确，以此衡量它们对其自身知识的认知程度。

**Result:** 所有经过测试的大型语言模型，在达到足够规模时，都表现出对自身在特定主题上知识量的理解。尽管不同架构展现出这种能力出现的速率不同。

**Conclusion:** 知识意识可能是大型语言模型的一个可泛化属性，但需要进一步研究来证实这一潜力并充分阐明其潜在机制。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）是否具备识别自身知识范围的能力。通过开发一个专门的基准测试，评估LLMs在特定主题上枚举信息量的准确性，研究发现所有测试的LLMs在达到足够规模后，均能展现出对其知识量的理解。这表明知识意识可能是LLMs的一个普遍属性，但仍需深入研究以确认并揭示其机制。

> **摘要翻译:** 大型语言模型（LLMs）已成为能力强大的系统，并正日益被整合到各种用途中。然而，它们的部署速度已经超越了对其内部机制的全面理解以及对其能力和局限性的界定。智能系统的一个理想属性是其识别自身知识范围的能力。为了调查LLMs是否具备这一特性，我们开发了一个基准测试，旨在挑战这些模型列举它们在特定主题上拥有的所有信息。该基准评估模型回忆的信息量是过多、不足还是精确，从而表明它们对其自身知识的认知程度。我们的研究结果显示，所有经过测试的LLMs，在达到足够规模时，都表现出对自身在特定主题上知识量的理解。尽管不同架构展现出这种能力出现的速率不同，但结果表明，知识意识可能是LLMs的一个可泛化属性。需要进一步研究来证实这一潜力并充分阐明其潜在机制。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [386] [Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities](https://arxiv.org/abs/2507.23776)
> *用于广义问题解决能力评估的级联信息披露*

*Yunxiang Yan, Tomohiro Sawada, Kartik Goyal* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 问题解决能力, 级联信息披露, 评估方法, 推理

**Comment:** Under review

> **TL;DR:** 本文提出了一种基于级联问题披露的框架，用于更准确地评估大型语言模型（LLMs）的问题解决能力，同时保持可扩展性和自动化，并发现它能更好地比较LLMs并诱导更好的中间推理过程。

**AI_Comments:** 这项研究通过引入“级联信息披露”的评估范式，为LLM能力评估提供了一个新颖且重要的视角。其创新之处在于从间接评估转向更直接地探究模型的问题解决过程，通过阶段性信息披露来激发和观察模型的推理能力。这对于理解LLM的真实能力和局限性具有重要意义，并可能推动未来评估基准的发展。该方法揭示了传统QA范式可能高估模型性能差异的缺陷，为LLM研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的问题回答（QA）基准测试虽然自动化且可扩展，但它们是评估大型语言模型（LLMs）底层问题解决能力的间接方法，且可能高估模型间的性能差异。

**Method:** 本文提出了一种基于“级联问题披露”的整体化、通用化框架。该方法以阶段性方式收集模型响应，每个阶段披露关于问题的一部分信息，旨在激发LLMs的通用推理能力。

**Result:** 研究发现，该方法不仅能更好地比较LLMs，而且与标准QA范式相比，能在模型中诱导更好的中间推理痕迹。该方法缩小了在标准QA评估设置中观察到的性能差距，表明流行的间接QA评估范式高估了模型间的性能差异。

**Conclusion:** 基于级联信息披露的评估框架能更准确地评估LLMs的问题解决能力，并揭示了传统QA评估可能夸大模型间性能差异的问题。

> **ai_Abstract:** 本文提出了一种名为“级联信息披露”的新型框架，旨在更准确、直接地评估大型语言模型（LLMs）的问题解决能力，而非依赖间接的问答（QA）基准测试。该框架通过分阶段披露问题信息来收集模型响应，以激发LLMs的通用推理。实验结果表明，该方法不仅能提供更好的LLM性能比较，还能诱导更优的中间推理过程，并显著缩小了传统QA评估中观察到的性能差距，揭示了现有范式可能高估模型间差异的局限性。

> **摘要翻译:** 虽然问答（QA）基准测试性能是比较LLMs的自动化和可扩展方法，但它是评估其底层问题解决能力的间接方法。因此，我们提出了一种基于“级联问题披露”的整体化、通用化框架，该框架能更准确地评估模型的问题解决能力，同时保持可扩展性和自动化。这种方法以阶段性方式收集模型响应，每个阶段揭示问题的部分信息，旨在激发LLMs的通用推理能力。我们发现，我们的方法不仅能更好地比较LLMs，而且与标准QA范式相比，能在模型中诱导更好的中间推理痕迹。我们通过比较不同大小和系列的LLMs，在多样化的推理和知识密集型QA数据集上经验性地验证了这种行为。我们的方法缩小了在标准QA评估设置中观察到的性能差距，表明流行的间接QA评估范式高估了模型间的性能差异。我们通过广泛的消融研究进一步验证了我们的发现。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [387] [A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents](https://arxiv.org/abs/2507.22938)
> *一种基于图的方法，用于电信文档中流程图的多模态问答*

*Sumit Soman, H. G. Ranjani, Sujoy Roychowdhury, Venkata Dharma Surya Narayana Sastry, Akshat Jain, Pranav Gangrade, Ayaaz Khan* | **Category: cs.CL, cs.AI, 68T50, I.2.7** | **Updated: 2025-07-25**

**Keywords:** 多模态问答, 流程图, 图表示, 检索增强生成, 电信文档

**Comment:** Accepted for publication at the KDD 2025 Workshop on Structured
  Knowledge for Large Language Models

> **TL;DR:** 该研究提出了一种将流程图的图表示集成到文本RAG系统中，以实现电信领域多模态问答的方法，并在检索性能和成本效益方面表现良好。

**AI_Comments:** 该论文的创新点在于将流程图的视觉信息（通过VLM转换为图表示）与文本检索增强生成（RAG）系统相结合，有效解决了传统文本RAG系统无法处理图像中答案的问题。其重要性在于为技术文档中的复杂多模态问答提供了实用且高效的解决方案，特别是在电信等专业领域。此外，通过在推理阶段避免对VLM的依赖，该方法在实际部署中具有显著的成本效益，提升了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统基于文本的检索增强生成（RAG）系统在处理技术文档中涉及图表（如流程图）的问题时表现不佳，无法有效回答答案存在于图像中的问题。

**Method:** 该方法利用视觉大型语言模型（VLM）获取流程图的图表示，并将其整合到基于文本的RAG系统中。具体步骤包括处理技术文档、图像类型分类、构建图表示，并将其与文本嵌入管道结合以实现高效检索。该方法在专有的电信产品信息文档数据集上进行了基准测试。

**Result:** 使用微调VLM模型获得的图表示与真实值相比具有更低的编辑距离，这表明这些表示对于流程图图像的鲁棒性。此外，使用这些表示的问答方法通过基于文本的嵌入模型（包括针对电信领域调整的模型）获得了良好的检索性能。该方法还降低了推理时对VLM的需求，为部署的问答系统带来了重要的成本效益。

**Conclusion:** 该研究成功地将流程图的图表示与文本RAG系统结合，实现了电信领域的多模态问答。该方法不仅在检索性能上表现出色，而且通过消除推理时对VLM的需求，显著降低了部署成本，为处理技术文档中的视觉信息提供了有效的解决方案。

> **ai_Abstract:** 本研究提出了一种解决技术文档中多模态问答（QA）难题的新方法，特别关注流程图。鉴于传统文本RAG系统在处理图像内容方面的局限性，该方法创新性地利用视觉大型语言模型（VLM）生成流程图的图表示，并将其无缝集成到现有的文本RAG系统中。实验结果表明，这种图表示具有高鲁棒性，并且在电信领域的问答任务中实现了优秀的检索性能。此外，该方法显著降低了推理阶段对VLM的依赖，从而带来了显著的成本优势，使其成为一种高效且经济的多模态QA解决方案。

> **摘要翻译:** 技术文档中的问答（QA）通常涉及那些答案存在于图表（如流程图或流程图）中的问题。基于文本的检索增强生成（RAG）系统可能无法回答此类问题。我们利用从视觉大型语言模型（VLM）获得的流程图的图表示，并将其整合到基于文本的RAG系统中，以表明这种方法可以实现电信领域的图像检索问答。我们提出了一个端到端的方法，包括处理技术文档、分类图像类型、构建图表示，并将其与文本嵌入管道结合以实现高效检索。我们在基于专有电信产品信息文档创建的问答数据集上对此进行了基准测试。结果表明，使用微调的VLM模型获得的图表示相对于真实值具有更低的编辑距离，这说明了这些表示对于流程图图像的鲁棒性。此外，使用这些表示的问答方法通过基于文本的嵌入模型（包括针对电信领域调整的模型）获得了良好的检索性能。我们的方法还减轻了推理时对VLM的需求，这对已部署的问答系统来说是一个重要的成本效益。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [388] [Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models](https://arxiv.org/abs/2506.07106)
> *思维定理：一种用于语言模型中溯因、演绎和归纳推理的多智能体框架*

*Samir Abdaljalil, Hasan Kurban, Khalid Qaraqe, Erchin Serpedin* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 思维定理, 多智能体, 语言模型, 推理, 思维链

**Comment:** ACL 2025 KnowFM

> **TL;DR:** Theorem-of-Thought (ToTh) 是一种多智能体框架，通过模拟溯因、演绎和归纳推理，提高了大型语言模型（LLMs）的推理能力，并生成可解释的、逻辑上可靠的推理链，在多个基准测试中优于现有方法。

**AI_Comments:** ToTh 的创新之处在于其将推理过程显式地解构为溯因、演绎和归纳三种模式的多智能体协作，并通过形式化的推理图和贝叶斯信念传播来增强逻辑结构和一致性评估，解决了现有CoT方法在逻辑严谨性方面的不足。其生成可解释推理链的能力对于LLMs的可靠性和透明度至关重要。这为未来构建更具人类认知特性的AI推理系统提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言推理任务中表现出色，但其推理过程仍然脆弱且难以解释。现有的提示技术，如思维链（CoT），虽然通过引出中间推理步骤或聚合多个输出来提高可靠性，但缺乏强制执行逻辑结构和评估内部一致性的机制。

**Method:** 本文引入了思维定理（ToTh）框架，该框架将推理建模为三个并行智能体之间的协作，每个智能体模拟一种独特的推理模式：溯因、演绎和归纳。每个智能体生成一个推理轨迹，并将其结构化为形式化的推理图。为了评估一致性，该框架应用了由自然语言推理（NLI）引导的贝叶斯信念传播，为每个步骤分配置信度分数。最终选择最连贯的图来得出最终答案。

**Result:** 在符号推理（WebOfLies）和数值推理（MultiArith）基准测试上的实验表明，ToTh 在多个大型语言模型中始终优于思维链（CoT）、自洽性（Self-Consistency）和思维链解码（CoT-Decoding），同时产生可解释且逻辑上可靠的推理链。

**Conclusion:** 本研究结果为构建更鲁棒和受认知启发的LLM推理提供了一个有前景的方向。

> **ai_Abstract:** 该论文提出了 Theorem-of-Thought (ToTh)，一个多智能体框架，旨在提高大型语言模型（LLMs）的推理能力和可解释性。ToTh 模拟溯因、演绎和归纳三种推理模式，每个智能体生成一个结构化的推理图。通过结合自然语言推理（NLI）的贝叶斯信念传播来评估一致性并选择最连贯的推理路径。实验结果表明，ToTh 在符号和数值推理任务上显著优于传统的 Chain-of-Thought (CoT) 及其变体，并能生成逻辑上可靠且可解释的推理链，为构建更健壮和认知启发的LLM推理提供了新方向。

> **摘要翻译:** 大型语言模型（LLMs）在自然语言推理任务中表现出强大的性能，但其推理过程仍然脆弱且难以解释。思维链（CoT）等提示技术通过引出中间推理步骤或聚合多个输出来提高可靠性。然而，它们缺乏强制执行逻辑结构和评估内部一致性的机制。我们引入了思维定理（ToTh），一个新颖的框架，将推理建模为三个并行智能体之间的协作，每个智能体模拟一种独特的推理模式：溯因、演绎和归纳。每个智能体生成一个推理轨迹，并将其结构化为形式化的推理图。为了评估一致性，我们应用了由自然语言推理（NLI）引导的贝叶斯信念传播，为每个步骤分配置信度分数。选择最连贯的图来得出最终答案。在符号（WebOfLies）和数值（MultiArith）推理基准测试上的实验表明，ToTh 在多个LLMs中始终优于CoT、自洽性（Self-Consistency）和CoT-Decoding，同时产生可解释且逻辑上可靠的推理链。我们的发现为构建更鲁棒和受认知启发的LLM推理提供了一个有前景的方向。该实现可在 https://github.com/KurbanIntelligenceLab/theorem-of-thought 获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [393] [PARROT: An Open Multilingual Radiology Reports Dataset](https://arxiv.org/abs/2507.22939)
> *PARROT：一个开放的多语言放射学报告数据集*

*Bastien Le Guellec, Kokou Adambounou, Lisa C Adams, Thibault Agripnidis, Sung Soo Ahn, Radhia Ait Chalal, Tugba Akinci D Antonoli, Philippe Amouyel, Henrik Andersson, Raphael Bentegeac, Claudio Benzoni, Antonino Andrea Blandino, Felix Busch, Elif Can, Riccardo Cau, Armando Ugo Cavallo, Christelle Chavihot, Erwin Chiquete, Renato Cuocolo, Eugen Divjak, Gordana Ivanac, Barbara Dziadkowiec Macek, Armel Elogne, Salvatore Claudio Fanni, Carlos Ferrarotti, Claudia Fossataro, Federica Fossataro, Katarzyna Fulek, Michal Fulek, Pawel Gac, Martyna Gachowska, Ignacio Garcia Juarez, Marco Gatti, Natalia Gorelik, Alexia Maria Goulianou, Aghiles Hamroun, Nicolas Herinirina, Krzysztof Kraik, Dominik Krupka, Quentin Holay, Felipe Kitamura, Michail E Klontzas, Anna Kompanowska, Rafal Kompanowski, Alexandre Lefevre, Tristan Lemke, Maximilian Lindholz, Lukas Muller, Piotr Macek, Marcus Makowski, Luigi Mannacio, Aymen Meddeb, Antonio Natale, Beatrice Nguema Edzang, Adriana Ojeda, Yae Won Park, Federica Piccione, Andrea Ponsiglione, Malgorzata Poreba, Rafal Poreba, Philipp Prucker, Jean Pierre Pruvo, Rosa Alba Pugliesi, Feno Hasina Rabemanorintsoa, Vasileios Rafailidis, Katarzyna Resler, Jan Rotkegel, Luca Saba, Ezann Siebert, Arnaldo Stanzione, Ali Fuat Tekin, Liz Toapanta Yanchapaxi, Matthaios Triantafyllou, Ekaterini Tsaoulia, Evangelia Vassalou, Federica Vernuccio, Johan Wasselius, Weilang Wang, Szymon Urban, Adrian Wlodarczak, Szymon Wlodarczak, Andrzej Wysocki, Lina Xu, Tomasz Zatonski, Shuhang Zhang, Sebastian Ziegelmayer, Gregory Kuchcinski, Keno K Bressem* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 放射学报告, 多语言, 数据集, NLP, 虚构报告

**Comment:** 

> **TL;DR:** PARROT是一个大型开放的多语言虚构放射学报告数据集，旨在推动放射学领域的自然语言处理（NLP）应用，并克服隐私限制。

**AI_Comments:** PARROT数据集的创新之处在于其“虚构”性质，这巧妙地解决了真实医疗数据普遍存在的隐私问题，从而能够创建一个大型、开放的多语言数据集供研究使用。这对于推动放射学领域的NLP应用至关重要，因为它降低了数据获取的门槛。然而，虚构数据的局限性在于其可能无法完全捕捉真实临床报告的所有细微差别和复杂性。尽管如此，人与AI报告区分研究的结果（尤其是放射科医生表现更好）表明，这些虚构报告具有一定的真实性，足以进行有意义的NLP研究。该数据集的重要性在于其规模、多语言特性和开放性，将极大地加速该领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 开发和验证PARROT（多语种标注放射学报告开放测试），一个大型、多中心、开放获取的虚构放射学报告数据集，涵盖多种语言，用于测试放射学领域的自然语言处理应用程序。

**Method:** 2024年5月至9月，邀请放射科医生根据其标准报告实践贡献虚构放射学报告。贡献者提供至少20份报告，并附带元数据，包括解剖区域、影像模态、临床背景，以及非英语报告的英语翻译。所有报告均分配了ICD-10编码。进行了一项人与AI报告区分研究，154名参与者（放射科医生、医疗保健专业人员和非医疗保健专业人员）评估报告是人类撰写还是AI生成。

**Result:** 该数据集包含来自21个国家76位作者的2658份放射学报告，涵盖13种语言。报告涵盖多种影像模态（CT：36.1%，MRI：22.8%，X线摄影：19.0%，超声：16.8%）和解剖区域，其中胸部（19.9%）、腹部（18.6%）、头部（17.3%）和骨盆（14.1%）最为普遍。在区分研究中，参与者在区分人类和AI生成的报告时，准确率为53.9%（95% CI：50.7%-57.1%），其中放射科医生的表现（56.9%，95% CI：53.3%-60.6%，p<0.05）显著优于其他组。

**Conclusion:** PARROT代表了最大的开放多语言放射学报告数据集，能够在没有隐私限制的情况下，跨语言、地理和临床边界开发和验证自然语言处理应用程序。

> **ai_Abstract:** PARROT是一个新创建的大型、多中心、开放获取的多语言虚构放射学报告数据集，旨在促进放射学领域的自然语言处理（NLP）应用开发和验证。该数据集包含来自21个国家76位作者的2658份报告，涵盖13种语言和多种影像模态及解剖区域，并附带详细元数据和ICD-10编码。一项人与AI报告区分研究显示，参与者平均准确率为53.9%，其中放射科医生表现更佳。PARROT克服了隐私限制，为跨语言、地理和临床边界的NLP研究提供了宝贵资源。

> **摘要翻译:** 原理和目标：开发和验证PARROT（多语种标注放射学报告开放测试），一个大型、多中心、开放获取的虚构放射学报告数据集，涵盖多种语言，用于测试放射学领域的自然语言处理应用程序。材料和方法：从2024年5月到9月，邀请放射科医生根据其标准报告实践贡献虚构放射学报告。贡献者提供至少20份报告，并附带相关元数据，包括解剖区域、影像模态、临床背景，以及非英语报告的英语翻译。所有报告均分配了ICD-10编码。进行了一项人与AI报告区分研究，154名参与者（放射科医生、医疗保健专业人员和非医疗保健专业人员）评估报告是人类撰写还是AI生成。结果：该数据集包含来自21个国家76位作者的2658份放射学报告，涵盖13种语言。报告涵盖多种影像模态（CT：36.1%，MRI：22.8%，X线摄影：19.0%，超声：16.8%）和解剖区域，其中胸部（19.9%）、腹部（18.6%）、头部（17.3%）和骨盆（14.1%）最为普遍。在区分研究中，参与者在区分人类和AI生成的报告时，准确率为53.9%（95% CI：50.7%-57.1%），其中放射科医生的表现（56.9%，95% CI：53.3%-60.6%，p<0.05）显著优于其他组。结论：PARROT代表了最大的开放多语言放射学报告数据集，能够在没有隐私限制的情况下，跨语言、地理和临床边界开发和验证自然语言处理应用程序。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [420] [Unable to Forget: Proactive Interference Reveals Working Memory Limits in LLMs Beyond Context Length](https://arxiv.org/abs/2506.08184)
> *无法遗忘：主动干扰揭示了LLM超越上下文长度的工作记忆限制*

*Chupei Wang, Jiaqiu Vince Sun* | **Category: cs.CL, cs.AI, q-bio.NC** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 主动干扰, 工作记忆, 信息检索, 上下文限制

**Comment:** Accepted at ICML 2025 Workshop on Long Context Foundation Models
  (ICFM). Code: https://github.com/zhuangziGiantfish/Unable-to-Forget

> **TL;DR:** 大型语言模型（LLM）在信息检索中存在主动干扰问题，导致检索精度随干扰累积而对数线性下降，这揭示了LLM超越上下文长度的工作记忆限制。

**AI_Comments:** 这篇论文通过引入认知科学中的“主动干扰”概念来分析LLM的记忆能力，非常具有创新性。它不仅揭示了LLM在处理动态信息时的深层限制——即其“工作记忆”瓶颈，而不仅仅是上下文长度问题，还强调了未来研究应关注如何增强LLM抑制不相关信息的能力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人们普遍认为更长的上下文能改善LLM的信息检索能力，但上下文内部干扰的影响却未得到充分研究。

**Method:** 研究团队改编了认知科学中的主动干扰（PI）范式，并引入了PI-LLM评估方法。该方法通过顺序传输语义相关的键值对更新，并仅查询最终值来评估LLM的检索能力。

**Result:** 结果显示，尽管最终值紧邻查询，但LLM的检索精度随干扰累积呈对数线性下降至零，错误源于检索到先前被覆盖的值。通过提示工程试图缓解干扰的效果有限。

**Conclusion:** 这些发现揭示了LLM在解缠干扰和灵活操作信息方面的根本限制，表明存在超越单纯上下文访问的工作记忆瓶颈。

> **ai_Abstract:** 本文研究了大型语言模型（LLM）中上下文内部干扰对信息检索的影响。通过引入源自认知科学的主动干扰（PI）范式，并设计了PI-LLM评估方法，研究发现LLM的检索精度会随着干扰的累积而对数线性下降，即使最新信息紧邻查询。这种下降是由于模型检索了被覆盖的旧值。研究还表明，简单的提示工程并不能有效缓解这种干扰。这揭示了LLM在处理干扰和灵活操作信息方面的根本性工作记忆限制，超越了上下文长度本身。

> **摘要翻译:** 大型语言模型（LLM）中的信息检索正日益被认为是与生成能力交织在一起，而非单纯的查找。尽管通常认为更长的上下文会改善检索，但上下文内部干扰的影响仍未得到充分研究。为了解决这个问题，我们改编了认知科学中的主动干扰（PI）范式，其中早期信息会干扰对新更新的召回。在人类中，对这种干扰的敏感性与工作记忆容量呈负相关。我们引入了PI-LLM，这是一种顺序传输语义相关键值更新并仅查询最终值的评估方法。尽管这些最终值明确位于查询之前，但LLM的检索精度随干扰累积呈对数线性下降至零；错误源于检索到先前被覆盖的值。通过提示工程（例如，指示模型忽略早期输入）试图缓解干扰的尝试效果有限。这些发现揭示了LLM解缠干扰和灵活操作信息能力的根本限制，表明存在超越单纯上下文访问的工作记忆瓶颈。这呼吁采取方法来加强模型在检索过程中抑制不相关内容的能力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [424] [Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes](https://arxiv.org/abs/2507.22940)
> *可信推理：评估和增强大型语言模型中间思维过程中的事实准确性*

*Rui Jiao, Yue Zhang, Jinku Li* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-25**

**Keywords:** 大型语言模型, 事实准确性, 中间推理, 可信推理, 强化学习

**Comment:** 

> **TL;DR:** 大型语言模型在中间推理步骤中常出现事实错误，即使最终答案正确，这存在高风险。RELIANCE框架通过事实核查分类器、强化学习和可解释性模块，显著提升了LLM的事实准确性，并为未来训练提供了新见解。

**AI_Comments:** 该论文具有创新性，它关注了大型语言模型中一个关键但常被忽视的问题：即使最终答案正确，其中间推理过程也可能存在事实错误。RELIANCE框架通过结合事实核查、强化学习和机械可解释性模块，提供了一个全面的解决方案。其激活层分析为未来提升模型事实鲁棒性的训练方法提供了可操作的见解，对于提高LLM在医疗、法律等高风险领域的可信度至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）存在一个关键漏洞：尽管最终答案正确，但在中间推理步骤中普遍存在事实不准确性。这种现象在高风险领域（如医疗保健、法律分析和科学研究）中构成重大风险，因为错误但自信呈现的推理可能误导用户做出危险的决定。

**Method:** 该研究提出了RELIANCE框架，包含三个核心组件：1）一个专门的事实核查分类器，通过反事实增强数据训练，用于检测推理链中细微的事实不一致性；2）一个群组相对策略优化（GRPO）强化学习方法，通过多维度奖励平衡事实性、连贯性和结构正确性；3）一个机械可解释性模块，用于检查事实性改进如何在推理过程中体现在模型激活中。

**Result:** 对十个最先进模型的广泛评估显示出令人担忧的模式：即使是Claude-3.7和GPT-o1等领先模型，其推理事实准确性也分别仅为81.93%和82.57%。RELIANCE显著增强了事实鲁棒性（高达49.90%的改进），同时在Math-500、AIME-2024和GPQA等挑战性基准测试中保持或提高了性能。

**Conclusion:** 该研究表明，即使是顶尖LLM在中间推理步骤中也存在显著的事实不准确性。RELIANCE框架能够显著提升LLM的事实鲁棒性，并通过激活层分析为未来以事实鲁棒性为目标的训练方法奠定了基础。

> **ai_Abstract:** 本文提出了RELIANCE框架，旨在解决大型语言模型（LLMs）中间推理步骤中的事实不准确性问题。该框架结合了事实核查分类器、平衡事实性和连贯性的强化学习方法（GRPO）以及一个机械可解释性模块。评估显示，即使是领先的LLMs在推理中也存在显著的事实错误（例如，Claude-3.7为81.93%，GPT-o1为82.57%）。RELIANCE将事实鲁棒性提高了高达49.90%，同时保持了基准测试性能，其激活层分析为未来以事实鲁棒性为目标的训练提供了见解。

> **摘要翻译:** 我们提出了RELIANCE（基于逻辑完整性和准确性的推理评估以增强置信度），这是一个新颖的框架，旨在解决大型语言模型（LLMs）中的一个关键漏洞：尽管最终答案正确，但在中间推理步骤中普遍存在事实不准确性。这种现象在高风险领域，包括医疗保健、法律分析和科学研究中，构成了重大风险，因为错误但自信呈现的推理可能误导用户做出危险的决定。我们的框架整合了三个核心组件：（1）一个专门的事实核查分类器，通过反事实增强数据训练，用于检测推理链中细微的事实不一致性；（2）一个群组相对策略优化（GRPO）强化学习方法，通过多维度奖励平衡事实性、连贯性和结构正确性；（3）一个机械可解释性模块，用于检查事实性改进如何在推理过程中体现在模型激活中。对十个最先进模型的广泛评估显示出令人担忧的模式：即使是Claude-3.7和GPT-o1等领先模型，其推理事实准确性也分别仅为81.93%和82.57%。RELIANCE显著增强了事实鲁棒性（高达49.90%的改进），同时在Math-500、AIME-2024和GPQA等挑战性基准测试中保持或提高了性能。此外，我们的激活层分析提供了关于事实增强如何重塑模型架构内推理轨迹的可操作见解，为未来通过激活引导优化明确针对事实鲁棒性的训练方法奠定了基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [430] [A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies](https://arxiv.org/abs/2507.22943)
> *借助自然语言处理和多波自适应抽样加速大型数据库研究中基于代码算法验证的图表审查流程*

*Shirley V Wang, Georg Hahn, Sushama Kattinakere Sreedhara, Mufaddal Mahesri, Haritha S. Pillai, Rajendra Aldis, Joyce Lii, Sarah K. Dutcher, Rhoda Eniafe, Jamal T. Jones, Keewan Kim, Jiwei He, Hana Lee, Sengwee Toh, Rishi J Desai, Jie Yang* | **Category: cs.CL, stat.ME** | **Updated: 2025-07-25**

**Keywords:** 自然语言处理, 自适应抽样, 代码算法验证, 大型数据库, 图表审查

**Comment:** 

> **TL;DR:** 本文提出了一种结合NLP和多波自适应抽样的方法，以加速大型数据库研究中基于代码算法的验证过程，显著减少了时间和资源消耗。

**AI_Comments:** 这篇论文通过结合NLP和创新的自适应抽样方法，有效地解决了大型数据库研究中代码算法验证耗时耗力的问题。其创新点在于将两种不同的效率提升机制（自动化和智能抽样）结合起来，显著减少了人工工作量，同时保持了验证结果的精度。这对于促进基于大型数据库的流行病学和临床研究的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型索赔数据库中，验证用于识别健康结果或关键研究参数的基于代码算法的测量特性对于增强分析至关重要。然而，通过人工审查链接电子健康记录中的自由文本笔记来创建参考标准标签通常需要大量时间和资源。

**Method:** 本文描述了一种加速验证过程的方法，通过两种机制提高效率：1) 使用自然语言处理（NLP）减少人工审查每份图表的时间；2) 采用具有预定义停止标准的多波自适应抽样方法，一旦性能特征以足够的精度确定，就停止验证研究。该过程在一个验证肥胖患者故意自伤索赔结果算法的案例研究中进行了说明。

**Result:** 经验证明，NLP辅助的注释过程使每份图表的审查时间减少了40%，并且使用预定义停止规则的多波抽样可以避免审查77%的患者图表，同时对导出的测量特性精度影响有限。

**Conclusion:** 这种方法可以促进对用于定义关键研究参数的基于代码算法进行更常规的验证，最终增强对源自数据库研究结果可靠性的理解。

> **ai_Abstract:** 本文提出了一种创新的图表审查流程，旨在加速大型数据库研究中基于代码算法的验证。该方法结合了自然语言处理（NLP）以减少人工审查时间，并采用了多波自适应抽样策略以在达到足够精度时提前终止研究。在一个验证自伤算法的案例研究中，NLP将审查时间减少了40%，而自适应抽样避免了77%的图表审查，同时保持了高精度。这项工作为更高效、常规地验证数据库研究中的算法提供了途径，从而提高了研究结果的可靠性。

> **摘要翻译:** 背景：通过验证用于识别健康结果或其他关键研究参数的基于代码算法的测量特性，是增强大型索赔数据库分析的方法之一。这些指标可用于定量偏差分析，以评估推论研究结果的稳健性，考虑到结果误分类可能造成的潜在偏差。方法：我们描述了一种加速流程，通过两种不同的机制提高验证研究的效率：1）使用自然语言处理（NLP）减少人工审查员审查每份图表所花费的时间；2）采用具有预定义标准的多波自适应抽样方法，一旦性能特征以足够的精度确定，就停止验证研究。我们通过一个案例研究来说明这一过程，该案例验证了肥胖患者故意自伤索赔结果算法的性能。结果：我们通过经验证明，NLP辅助的注释过程使每份图表的审查时间减少了40%，并且使用预定义停止规则的多波抽样可以避免审查77%的患者图表，同时对导出的测量特性精度影响有限。结论：这种方法可以促进对用于定义关键研究参数的基于代码算法进行更常规的验证，最终增强对源自数据库研究结果可靠性的理解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [448] [Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics](https://arxiv.org/abs/2506.12365)
> *大型语言模型在推理、适应性、效率和伦理方面的进展*

*Asifullah Khan, Muhammad Zaeem Khan, Saleha Jamshed, Sadia Ahmad, Aleesha Zainab, Kaynat Khatib, Faria Bibi, Abdul Rehman* | **Category: cs.CL, cs.DB** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 推理, 适应性, 效率, 伦理

**Comment:** 

> **TL;DR:** 这篇综述概述了大型语言模型在推理、适应性、效率和伦理方面的最新进展，涵盖了关键技术、挑战和未来方向。

**AI_Comments:** 这篇综述全面涵盖了大型语言模型当前的关键发展方向，不仅关注技术进步，还深入探讨了效率、伦理和社会应用，如代理AI。其价值在于提供了一个宏观视角，整合了分散的研究点，并明确指出了未来的研究挑战和未探索的领域，对于LLM研究者和开发者具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在概述大型语言模型（LLMs）在推理能力、任务适应性、计算效率和伦理决策方面的关键发展，并提供一个超越单一方面的更广泛视角。

**Method:** 本文通过综述现有技术和发展，包括思维链提示、指令微调、人类反馈强化学习、多模态学习、少样本/零样本技术、Mixture-of-Experts (MoE) 架构，并探讨LLMs在Agentic AI和自主决策系统中的作用，同时识别未充分探索的领域。

**Result:** 综述指出，通过思维链提示、指令微调、人类反馈强化学习等技术，LLMs在推理、适应性和效率方面取得了显著进步；多模态学习和少样本/零样本技术增强了LLMs处理复杂任务的能力；MoE架构提高了预测准确性并优化了资源分配。同时，LLMs在代理AI和自主决策系统中发挥作用。

**Conclusion:** 尽管LLMs取得了显著进展，但仍面临高计算成本、偏见和伦理风险等挑战。未来的研究应侧重于偏见缓解、透明决策和明确的伦理指导，并增强模型处理多输入的能力，使其更智能、安全和可靠。

> **ai_Abstract:** 这篇综述论文全面概述了大型语言模型（LLMs）在推理、适应性、效率和伦理方面的最新进展。它详细介绍了关键技术，如思维链提示、指令微调和人类反馈强化学习，以及多模态学习和MoE架构。论文还探讨了LLMs在代理AI和自主决策系统中的应用，并指出了可解释性、跨模态集成和可持续性等未充分探索的领域。尽管LLMs取得了显著进步，但仍面临计算成本高、偏见和伦理风险等挑战，未来研究需关注偏见缓解和透明伦理指导。

> **摘要翻译:** 这篇综述论文概述了大型语言模型（LLMs）领域的关键发展，包括其推理技能的增强、对各种任务的适应性、计算效率的提高以及做出伦理决策的能力。在弥合人机通信差距方面最有效的技术包括思维链提示（Chain-of-Thought prompting）、指令微调（Instruction Tuning）和人类反馈强化学习（Reinforcement Learning from Human Feedback）。多模态学习以及少样本或零样本技术的改进进一步赋予LLMs处理复杂任务的能力，且只需少量输入。论文重点关注效率，详细介绍了扩展策略、优化技术和具有影响力的专家混合（Mixture-of-Experts, MoE）架构，该架构战略性地将输入路由到专门的子网络，以提高预测准确性，同时优化资源分配。本综述还提供了LLMs最新进展的更广阔视角，超越了模型架构或伦理问题等孤立方面。此外，它探讨了LLMs在代理AI（Agentic AI）中的作用及其作为自主决策系统的使用，并对增强LLM推理、效率和伦理对齐的新兴方法进行了分类。本综述还指出了未充分探索的领域，如可解释性、跨模态集成和可持续性。尽管LLMs取得了显著进展，但高计算成本、偏见和伦理风险等挑战依然存在。克服这些挑战需要关注偏见缓解、透明决策和明确的伦理指导。未来的研究将普遍侧重于增强模型处理多输入的能力，从而使其更智能、安全和可靠。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [460] [WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation](https://arxiv.org/abs/2506.21875)
> *WildSpeech-Bench：在自然语音对话中评估音频LLM*

*Jian Zhang, Linhao Zhang, Bokai Lei, Chuhan Wu, Wei Jia, Xiao Zhou* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 音频LLM, 语音对话, 基准测试, WildSpeech-Bench, 查询感知评估

**Comment:** 

> **TL;DR:** WildSpeech-Bench是一个新的基准测试，旨在全面评估音频大型语言模型（LLM）在自然语音对话中的表现，通过引入语音特有现象和查询感知评估方法来弥补现有文本基准的不足。

**AI_Comments:** WildSpeech-Bench的创新点在于其关注真实世界语音对话中的细微差别，并引入了“查询感知评估”这一新颖方法，以更准确地评估音频LLM。这解决了现有文本基准无法捕捉语音特有挑战的局限性，对推动音频LLM在实际应用中的优化具有重要意义。该工作强调了对语音特有现象（如韵律、同音异义词、口吃）的关注，使其成为评估语音LLM性能的关键工具。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态大型语言模型（LLM）在直接语音交互方面表现出强大能力，但缺乏专门且全面的端到端语音LLM评估基准，这阻碍了在实际应用中优化音频LLM的用户体验。现有评估方法通常改编自文本基准，忽略了语音的独特特征和挑战，如韵律、同音异义词、口吃和不同的用户期望。

**Method:** 本文提出了一种新颖的方法来彻底评估LLM在实际语音对话中的表现。具体方法包括：系统地整理与口语场景相关的真实世界聊天数据；在说话人属性和声学条件中引入多样性，并用语音特有现象增强数据集；设计一种查询感知评估方法，使用定制的评估清单和提示来提高自动评估的准确性。

**Result:** 通过对各种主流语音模型进行全面的测试和详细分析，揭示了模型在不同语音场景下的性能存在显著差异。此外，查询感知评估的使用进一步实现了在各种语音特定场景下更细粒度的评估。

**Conclusion:** 我们提出的基准测试可以为语音模型的开发和评估提供宝贵的见解。

> **ai_Abstract:** 本文介绍了WildSpeech-Bench，这是一个旨在全面评估音频大型语言模型（LLM）在自然语音对话中表现的新型基准测试。针对现有文本基准未能捕捉语音特有挑战的问题，该研究通过整理真实世界语音数据、引入说话人多样性和声学条件、并增强语音特有现象来构建数据集。此外，还设计了一种查询感知评估方法以提高自动评估的准确性。对主流语音模型的测试显示，在不同语音场景下模型性能存在显著差异，且查询感知评估能实现更细粒度的评估。该基准为语音模型开发与评估提供了宝贵见解。

> **摘要翻译:** 最近的多模态大型语言模型（LLM），如GPT-4o，已经展示了直接语音交互的强大能力。然而，缺乏专门且全面的端到端语音LLM评估基准，阻碍了在实际应用中优化音频LLM的用户体验。现有评估方法通常改编自文本基准，忽略了语音的独特特征和挑战，包括韵律、同音异义词、同音异义词、口吃和不同的用户期望。在此，我们提出了一种新颖的方法来彻底评估LLM在实际语音对话中的表现。我们系统地整理了与口语场景相关的真实世界聊天数据，引入了说话人属性和声学条件的多样性，并用语音特有现象增强了数据集。我们进一步设计了一种查询感知评估方法，使用定制的评估清单和提示来提高自动评估的准确性。我们对各种主流语音模型进行了全面的测试和详细分析，揭示了模型在不同语音场景下的性能存在显著差异。查询感知评估的使用进一步实现了在各种语音特定场景下更细粒度的评估。我们的基准测试可以为语音模型的开发和评估提供宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [467] [C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations](https://arxiv.org/abs/2507.22968)
> *C3：一个用于探索复杂对话挑战的口语对话模型双语基准*

*Chengqian Ma, Wei Tao, Yiwen Guo* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 口语对话模型, 双语基准, 复杂对话, 大语言模型评估

**Comment:** 

> **TL;DR:** 本文提出了C3，一个双语基准测试集，用于评估口语对话模型在复杂对话中的表现，并采用基于LLM的评估方法。

**AI_Comments:** 该论文的创新之处在于提出了一个双语（英语和中文）基准数据集C3，并结合了与人类判断高度一致的基于大语言模型（LLM）的评估方法，专门用于评估口语对话模型（SDMs）在处理复杂对话（如语音固有的歧义和上下文依赖性）中的表现。这填补了口语对话模型评估领域的一个重要空白，为未来SDM的研发提供了宝贵的工具和方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管口语对话模型（SDMs）日益普及，但目前缺乏对其在理解和模仿人类对话方面实际有效性的全面研究，尤其与受益于广泛基准测试的文本大语言模型（LLMs）相比。人类语音交互因其独特的口语特征（如歧义和上下文依赖）比文本更复杂。

**Method:** 为了解决这些挑战并评估口语对话模型的发展现状，本文提出了一个双语基准数据集，包含1,079个英语和中文实例。该数据集辅以一种与人类判断高度一致的基于大语言模型（LLM）的评估方法。

**Result:** 本文成功构建了一个包含1,079个英语和中文实例的双语基准数据集C3，并开发了一种基于大语言模型（LLM）的评估方法，用于全面探索口语对话模型在处理复杂对话挑战时的性能。

**Conclusion:** 该基准数据集和评估方法有助于全面探索口语对话模型在应对复杂实际对话挑战时的性能。

> **ai_Abstract:** 本文介绍了C3，一个包含1,079个英汉双语实例的基准数据集，并辅以一种基于LLM的评估方法。该研究旨在弥补当前在全面理解口语对话模型（SDMs）在复杂人类对话中实际有效性方面的研究空白。与已进行广泛基准测试的文本大语言模型（LLMs）不同，口语对话因其固有的歧义和上下文依赖性而更具挑战。该基准将有助于全面探索SDM在这些实际场景中的表现。

> **摘要翻译:** 口语对话模型（SDMs）因其能够直接对用户的口语查询生成语音响应而最近受到了广泛关注。尽管它们越来越受欢迎，但在全面理解其在理解和模仿人类对话方面的实际有效性方面存在研究空白。与受益于广泛基准测试的文本大语言模型（LLMs）相比，这一点尤为突出。人类语音交互由于口语特有的特征（如多义词、异形同音异义词、重音模式等语义和语音歧义，以及省略、指代和多轮交互等上下文依赖性）本质上比文本更复杂。为了阐明SDM的当前发展状况并应对这些挑战，本文提出了一个基准数据集，包含1,079个英语和中文实例。该数据集辅以一种与人类判断高度一致的基于LLM的评估方法，有助于全面探索SDM在应对这些实际挑战时的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [474] [Math Natural Language Inference: this should be easy!](https://arxiv.org/abs/2507.23063)
> *数学自然语言推理：这应该很容易！*

*Valeria de Paiva, Qiyue Gao, Hai Hu, Pavel Kovalev, Yikang Liu, Lawrence S. Moss, Zhiheng Qian* | **Category: cs.CL, 68T50, I.2.7** | **Updated: 2025-07-30**

**Keywords:** 数学自然语言推理, 大型语言模型, 语料库, 数学文本, 推理能力

**Comment:** 9 pages plus appendices

> **TL;DR:** 研究发现，尽管LLM在数学自然语言推理任务中表现出一些潜力（多数投票接近人类水平），但它们在理解数学语言和进行基本推理方面仍面临挑战。

**AI_Comments:** 这篇论文通过构建专门的数学自然语言推理语料库，并对当前LLMs进行系统性评估，填补了LLM在数学推理能力评估上的一个空白。其创新之处在于专门针对数学文本的NLI任务，并探讨了LLM生成假设的质量和模型间一致性。研究结果揭示了LLMs在数学领域NLI的潜力和局限性，特别是指出了它们在数学语言理解和基本推理上的不足，这对于未来LLM的改进具有重要指导意义。提供新的语料库也对社区贡献巨大。

<details>
  <summary>Details</summary>

**Motivation:** 探究当代大型语言模型（LLMs）是否能够对数学文本执行自然语言推理（NLI）任务。

**Method:** 构建了一个数学NLI语料库，其前提来自现有数学文本，假设和黄金标签由具有数学研究和NLI领域经验的人员提供。还研究了使用相同前提但假设由LLM自身提供的语料库质量，并调查了不同LLM群体的性能和组间一致性。

**Result:** 结果喜忧参半。积极方面：在某些设置下，LLM的多数投票在数学NLI领域约等于使用人类标注数据。消极方面：LLM在处理数学语言时仍然存在困难，偶尔甚至在基本推理上也会失败。当前模型不像上一代那样容易出现仅基于假设的“推理”。

**Conclusion:** 尽管通过多数投票等方式，LLM在数学自然语言推理方面显示出一定的潜力，但它们在理解和推理数学语言方面仍存在显著的局限性，特别是在基本推理上。

> **ai_Abstract:** 本文研究了当前大型语言模型（LLMs）在数学文本自然语言推理（Math NLI）任务上的表现。研究者构建了一个新的Math NLI语料库，并评估了LLMs在该任务上的性能及不同LLM之间的推理一致性。结果显示，LLMs的表现喜忧参半：在某些情况下，LLM的多数投票能达到接近人类标注数据的效果，但它们在理解数学语言和进行基本推理方面仍存在显著不足。论文还提供了所构建的语料库以促进未来的研究。

> **摘要翻译:** 标题：数学自然语言推理：这应该很容易！

摘要：
我们探究当代大型语言模型（LLMs）是否能够对数学文本执行自然语言推理（NLI）任务。我们将此称为数学NLI问题。我们构建了一个数学NLI对的语料库，其前提来自现有数学文本，而假设和黄金标签由在研究级数学和NLI领域均有经验的人员提供。我们还研究了使用相同前提但假设由LLM自身提供的语料库的质量。我们不仅调查了不同LLM群体的性能，还调查了它们的组间一致性。我们既有积极的发现，也有消极的发现。在我们的积极发现中：在某些设置下，使用LLM的多数投票近似等同于在数学NLI领域使用人类标注数据。在消极方面：LLM在处理数学语言时仍然存在困难。它们偶尔甚至会在基本推理上失败。当前模型在我们的数据中不像上一代那样容易出现仅基于假设的“推理”。除了我们的发现之外，我们还提供我们的语料库作为数据，以支持未来在数学NLI方面的工作。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [497] [Perception-Aware Policy Optimization for Multimodal Reasoning](https://arxiv.org/abs/2507.06448)
> *多模态推理中的感知感知策略优化*

*Zhenhailong Wang, Xuehang Guo, Sofia Stoica, Haiyang Xu, Hongru Wang, Hyeonjeong Ha, Xiusi Chen, Yangyi Chen, Ming Yan, Fei Huang, Heng Ji* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 多模态推理, 强化学习, 感知感知, 策略优化, 隐式感知损失

**Comment:** 

> **TL;DR:** 本文提出了PAPO算法，通过引入隐式感知损失和双熵损失，解决了RLVR在多模态推理中视觉感知不足的问题，显著提升了模型性能，尤其是在视觉依赖性高的任务上，且无需额外数据或模型。

**AI_Comments:** PAPO的创新点在于将“感知”作为核心学习目标的一部分整合到RL框架中，解决了LLMs在多模态推理中视觉感知不足的问题。其优势在于无需额外标注数据或更强的教师模型，通过简单的损失函数设计实现了显著的性能提升和感知能力的改善。这为未来构建更鲁棒、更具视觉接地能力的RL系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习与可验证奖励（RLVR）在纯文本推理中表现出色，但应用于多模态推理时性能不佳，主要问题在于对视觉输入的感知错误。

**Method:** 提出PAPO，一种新的策略梯度算法，旨在使模型在推理的同时学习感知。通过引入形式为KL散度项的隐式感知损失，可无缝集成到GRPO和DAPO等主流RLVR算法中。为增强训练稳定性，引入了双熵损失来正则化新的KL目标。PAPO不依赖额外数据、奖励模型或更强的教师模型。

**Result:** PAPO在多种多模态基准测试中实现4.4%-17.5%的整体性能提升。在视觉依赖性高的任务上，提升更显著，达到8.0%-19.1%。感知错误显著减少30.5%。

**Conclusion:** PAPO将感知感知监督更深层次地整合到核心学习目标中，为鼓励视觉接地推理的新型强化学习框架奠定了基础。

> **ai_Abstract:** 本文提出了PAPO，一种针对多模态推理的感知感知策略优化算法。鉴于现有RLVR方法在处理视觉输入时存在感知瓶颈，PAPO通过引入隐式感知损失和双熵损失，使模型能够在推理过程中同时提升感知能力。该方法无需额外数据或模型，并在多模态基准测试中展现出显著性能提升，尤其是在视觉依赖性强的任务上，同时大幅降低了感知错误。

> **摘要翻译:** 强化学习与可验证奖励（RLVR）已被证明是赋予大型语言模型（LLMs）强大多步推理能力的有效策略。然而，其设计和优化仍仅限于纯文本领域，导致应用于多模态推理任务时性能不佳。特别是，我们观察到当前多模态推理中一个主要的错误来源在于视觉输入的感知。为了解决这一瓶颈，我们提出了PAPO，一种新颖的策略梯度算法，它鼓励模型在学习推理的同时学习感知。具体来说，我们以KL散度项的形式引入了隐式感知损失，该损失可以无缝地插入到GRPO和DAPO等主流RLVR算法中。值得注意的是，PAPO不依赖于额外的数据整理、奖励模型或更强的教师模型。为了进一步提高PAPO的训练稳定性，我们引入了双熵损失，它在不损害性能的情况下有效正则化了新的KL目标。尽管其简单，PAPO在多种多模态基准测试中取得了4.4%-17.5%的显著整体改进。在视觉依赖性高的任务上，改进更为显著，接近8.0%-19.1%。我们还观察到感知错误大幅减少了30.5%，这表明PAPO提高了感知能力。总的来说，我们的工作将感知感知监督更深层次地整合到核心学习目标中，并为鼓励视觉接地推理的新型强化学习框架奠定了基础。代码和数据将公开提供用于研究目的。项目页面：https://mikewangwzhl.github.io/PAPO。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [516] [Exploring In-Context Learning for Frame-Semantic Parsing](https://arxiv.org/abs/2507.23082)
> *探索上下文学习在框架语义解析中的应用*

*Diego Garat, Guillermo Moncecchi, Dina Wonsever* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 上下文学习, 框架语义解析, 大型语言模型, FrameNet, 自然语言处理

**Comment:** 

> **TL;DR:** 本文研究了如何利用大型语言模型的上下文学习能力，在不进行模型微调的情况下进行框架语义解析，并提出了一种自动生成任务特定提示的方法，在暴力事件相关框架上取得了有竞争力的结果。

**AI_Comments:** 本文的创新之处在于探索了利用大型语言模型的上下文学习能力进行框架语义解析，而无需进行耗时的模型微调。这为特定领域的自然语言处理任务提供了一种高效且实用的新范式。其重要性在于证明了在资源有限或需要快速部署的场景下，上下文学习能够达到与传统微调相当甚至有竞争力的性能。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究利用大型语言模型（LLMs）的上下文学习（ICL）能力来执行框架语义解析（FSP），而无需进行模型微调，以提供一种传统微调的替代方案。

**Method:** 本文提出了一种方法，该方法仅依靠FrameNet数据库，自动为框架识别（FI）和框架语义角色标注（FSRL）子任务生成任务特定的提示。这些提示由框架定义和标注示例构建，用于指导六种不同的大型语言模型。实验在与暴力事件相关的一部分框架上进行。

**Result:** 该方法在框架识别（FI）上取得了94.3%的F1分数，在框架语义角色标注（FSRL）上取得了77.4%的F1分数，结果具有竞争力。

**Conclusion:** 研究结果表明，上下文学习（ICL）为特定领域的框架语义解析（FSP）任务提供了一种实用且有效的替代传统微调的方法。

> **ai_Abstract:** 本文探讨了使用大型语言模型（LLMs）的上下文学习（ICL）能力进行框架语义解析（FSP），从而避免了模型微调。研究提出了一种基于FrameNet数据库自动生成框架识别（FI）和框架语义角色标注（FSRL）子任务提示的方法。该方法在暴力事件相关框架上的实验中表现出竞争力，FI的F1分数为94.3%，FSRL为77.4%，证明ICL是领域特定FSP任务中传统微调的有效替代方案。

> **摘要翻译:** 框架语义解析（FSP）涉及根据框架语义识别谓词并标注其论元。本文研究了利用大型语言模型（LLMs）的上下文学习（ICL）能力来执行FSP，而无需进行模型微调。我们提出了一种方法，该方法仅依靠FrameNet数据库，自动为框架识别（FI）和框架语义角色标注（FSRL）子任务生成任务特定的提示。这些由框架定义和标注示例构建的提示被用来指导六种不同的大型语言模型。实验在与暴力事件相关的一部分框架上进行。该方法取得了有竞争力的结果，FI的F1分数达到94.3%，FSRL的F1分数达到77.4%。研究结果表明，ICL为特定领域的FSP任务提供了一种实用且有效的替代传统微调的方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [539] [KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities](https://arxiv.org/abs/2507.07695)
> *KeyKnowledgeRAG (K^2RAG)：一种增强型RAG方法，用于提高LLM问答能力*

*Hruday Markondapatnaikuni, Basem Suleiman, Abdelkarim Erradi, Shijing Chen* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 检索增强生成 (RAG), 大型语言模型 (LLM), 问答, 知识图谱, 文本摘要

**Comment:** 21 pages, 14 figures

> **TL;DR:** KeyKnowledgeRAG (K2RAG) 是一种新的RAG框架，结合了密集和稀疏向量搜索、知识图谱和文本摘要，显著提高了大型语言模型(LLM)问答的准确性、效率和可扩展性，同时降低了资源消耗。

**AI_Comments:** 这篇论文的创新点在于其融合了多种先进技术（密集/稀疏向量搜索、知识图谱、文本摘要）来构建一个更高效和准确的RAG框架。特别是，引入训练数据摘要作为预处理步骤，显著提升了训练效率，是解决LLM知识扩展中资源瓶颈的关键贡献。该研究的重要性在于为当前LLM在知识整合和问答方面的挑战提供了一个实用的解决方案，尤其是在降低计算成本和提高系统性能方面。文中未明确提及局限性，但通常复杂的集成系统在泛化性或特定领域适应性方面可能面临挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的微调过程在知识扩展方面资源消耗巨大，尽管已有多种微调技术来降低成本，但随着LLM规模和复杂性的增长，挑战依然存在。现有的检索增强生成（RAG）方法虽然提供了一种替代方案，但其朴素实现存在可扩展性和答案准确性方面的显著局限性。因此，需要一种新的方法来解决这些问题。

**Method:** 本论文引入了KeyKnowledgeRAG (K2RAG) 框架，旨在克服现有RAG方法的局限性。该框架受分而治之范式启发，集成了密集和稀疏向量搜索、知识图谱以及文本摘要技术，以提高检索质量和系统效率。K2RAG还包含一个预处理步骤，对训练数据进行摘要，从而显著减少训练时间。该方法在MultiHopRAG数据集上进行了评估，其中所提出的管道在文档语料库上进行训练，并在单独的评估集上进行测试。

**Result:** K2RAG在MultiHopRAG数据集上的评估结果显示，相对于常见的朴素RAG实现有显著改进。K2RAG实现了0.57的最高平均答案相似性分数，并达到了0.82的最高第三四分位（Q3）相似性，表明与真实答案有更好的一致性。此外，该框架表现出高效性，摘要步骤将单个组件的平均训练时间缩短了93%，执行速度比传统的基于知识图谱的RAG系统快40%。K2RAG还展现出卓越的可扩展性，所需的VRAM比本研究中测试的几种朴素RAG实现少三倍。

**Conclusion:** KeyKnowledgeRAG (K2RAG) 框架通过整合多种先进技术，成功克服了现有RAG方法的局限性，在LLM问答能力方面实现了显著提升。该方法在准确性、训练效率、执行速度和资源可扩展性方面均表现出优于朴素RAG实现的性能，为LLM的知识扩展提供了一个更有效和高效的解决方案。

> **ai_Abstract:** 该论文提出了KeyKnowledgeRAG (K2RAG)，一个增强型检索增强生成（RAG）框架，旨在解决大型语言模型（LLM）微调资源消耗大和朴素RAG实现存在的准确性及可扩展性限制。K2RAG融合了密集和稀疏向量搜索、知识图谱以及文本摘要技术，并引入了训练数据摘要预处理步骤以提高效率。在MultiHopRAG数据集上的评估表明，K2RAG在答案相似性（平均0.57，Q3 0.82）上优于朴素RAG，同时显著减少了93%的训练时间，提高了40%的执行速度，并降低了三倍的VRAM需求，展现出卓越的性能和效率。

> **摘要翻译:** 当需要纳入更庞大的知识体系时，对大型语言模型（LLM）进行微调是一个极其耗费资源的过程。尽管已经开发了许多微调技术来减少所涉及的时间和计算成本，但随着LLM规模和复杂性的不断增长，这一挑战依然存在。为了解决这个问题，需要一种新的LLM知识扩展方法。检索增强生成（RAG）提供了一种这样的替代方案，通过在数据库中存储外部知识并检索相关块来支持问答。然而，RAG的朴素实现面临可扩展性和答案准确性方面的显著局限性。本文介绍了KeyKnowledgeRAG (K2RAG)，一个旨在克服这些局限性的新颖框架。受分而治之范式的启发，K2RAG集成了密集和稀疏向量搜索、知识图谱和文本摘要，以提高检索质量和系统效率。该框架还包括一个预处理步骤，对训练数据进行摘要，显著减少了训练时间。K2RAG使用MultiHopRAG数据集进行评估，其中所提出的管道在文档语料库上进行训练，并在单独的评估集上进行测试。结果表明，与常见的朴素RAG实现相比，K2RAG有显著改进。K2RAG实现了0.57的最高平均答案相似性分数，并达到了0.82的最高第三四分位（Q3）相似性，表明与真实答案有更好的一致性。除了提高准确性外，该框架还被证明高效。摘要步骤将单个组件的平均训练时间减少了93%，执行速度比传统的基于知识图谱的RAG系统快40%。K2RAG还展示了卓越的可扩展性，所需的VRAM比本研究中测试的几种朴素RAG实现少三倍。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [565] [Context-aware Rotary Position Embedding](https://arxiv.org/abs/2507.23083)
> *上下文感知旋转位置嵌入*

*Ali Veisi, Delaram Fartoot, Hamidreza Amirzadeh* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 位置编码, Transformer, 旋转位置嵌入, 上下文感知, 困惑度

**Comment:** 4 pages, 1 table

> **TL;DR:** 本文提出了CARoPE（上下文感知旋转位置嵌入），它通过动态生成基于token嵌入的频率模式，改进了RoPE在Transformer模型中的上下文敏感性，并在实验中表现出更好的性能和效率。

**AI_Comments:** CARoPE的创新之处在于其动态生成上下文敏感频率模式的能力，这克服了传统RoPE静态模式的局限性。通过将token嵌入信息融入位置编码，它提供了一种更精细、更具表现力的位置表示。其在保持效率的同时提升性能的特点，使其成为Transformer模型中一个重要且实用的改进。

<details>
  <summary>Details</summary>

**Motivation:** Transformer架构中的位置编码至关重要，而Rotary Positional Embeddings（RoPE）虽被广泛采用，但其依赖静态、与输入无关的正弦频率模式，限制了其对上下文敏感关系的建模能力。

**Method:** 本文提出了CARoPE（Context-Aware Rotary Positional Embedding），作为RoPE的新颖泛化。CARoPE通过对token嵌入进行条件化，动态生成头部特定的频率模式。具体来说，它利用token嵌入的有界变换计算输入相关的相位偏移，并将其整合到注意力头的旋转机制中，从而引入了token和上下文敏感的位置表示，同时保留了RoPE的效率和架构简洁性。

**Result:** CARoPE在FineWeb-Edu-10B数据集上使用GPT-2变体进行下一token预测任务的评估中，始终优于RoPE和其他常见的位置编码基线。实验结果显示，CARoPE实现了显著更低的困惑度，即使在更长的上下文长度下也是如此。此外，CARoPE还能在不牺牲模型稳定性的情况下实现更快的训练吞吐量。

**Conclusion:** CARoPE为Transformer模型中现有的位置编码策略提供了一种可扩展、富有表现力且高效的升级方案，证明了其在处理上下文敏感关系方面的优越性。

> **ai_Abstract:** 本文提出了上下文感知旋转位置嵌入（CARoPE），旨在解决现有旋转位置嵌入（RoPE）在建模上下文敏感关系方面的局限性。CARoPE通过动态生成基于token嵌入的头部特定频率模式，实现了token和上下文敏感的位置表示，同时保持了RoPE的效率和架构简洁性。在FineWeb-Edu-10B数据集上进行的评估显示，CARoPE在下一token预测任务中表现优异，显著降低了困惑度，并提升了训练吞吐量，证明了其作为Transformer模型中高效且富有表现力的位置编码升级方案的潜力。

> **摘要翻译:** 位置编码是Transformer架构的重要组成部分，它使模型能够将序列顺序纳入自注意力机制。旋转位置嵌入（RoPE）因其与相对位置编码的兼容性和计算效率而成为一种广泛采用的解决方案。然而，RoPE依赖于静态的、与输入无关的正弦频率模式，这限制了其建模上下文敏感关系的能力。在这项工作中，我们提出了CARoPE（上下文感知旋转位置嵌入），这是RoPE的一种新颖的泛化，它根据token嵌入动态生成头部特定的频率模式。这种设计引入了token和上下文敏感的位置表示，同时保留了RoPE的效率和架构简洁性。CARoPE使用token嵌入的有界变换计算输入相关的相位偏移，并将其整合到注意力头的旋转机制中。我们在FineWeb-Edu-10B数据集上使用在下一token预测任务上训练的GPT-2变体评估了CARoPE。实验结果表明，CARoPE始终优于RoPE和其他常见的位置编码基线，即使在更长的上下文长度下也能实现显著更低的困惑度。此外，CARoPE还能在不牺牲模型稳定性的情况下实现更快的训练吞吐量。这些发现表明，CARoPE为Transformer模型中现有的位置编码策略提供了一种可扩展、富有表现力且高效的升级方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [567] [DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures](https://arxiv.org/abs/2507.08606)
> *DocPolarBERT：一种用于文档理解的预训练模型，具有布局结构的相对极坐标编码*

*Benno Uthayasooriyar, Antoine Ly, Franck Vermet, Caio Corro* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 文档理解, BERT, 布局感知, 极坐标编码, 预训练模型

**Comment:** 

> **TL;DR:** DocPolarBERT是一个新的布局感知BERT模型，它使用相对极坐标编码代替绝对2D位置嵌入，在更小的数据集上实现了文档理解的最新SOTA结果。

**AI_Comments:** DocPolarBERT的创新之处在于其独特的相对极坐标编码方式，成功地替代了传统的绝对2D位置嵌入，简化了模型对布局信息的处理。其重要性体现在能够在更小的数据集上实现SOTA性能，这对于资源受限的研究和应用具有重要意义，提供了一个高效且有效的文档理解解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文档理解模型通常需要绝对2D位置嵌入。本文旨在开发一种更高效、更有效的文档理解替代方案，通过精心设计的注意力机制来减少对大量预训练数据的依赖。

**Method:** 本文引入了DocPolarBERT，这是一个布局感知的BERT模型。它通过扩展自注意力机制，将文本块的位置考虑在相对极坐标系统中，而非传统的笛卡尔坐标系统，从而消除了对绝对2D位置嵌入的需求。

**Result:** DocPolarBERT在比广泛使用的IIT-CDIP语料库小六倍以上的数据集上进行预训练，但仍取得了最先进的（SOTA）结果。

**Conclusion:** 这些结果表明，精心设计的注意力机制可以弥补预训练数据量的减少，为文档理解提供了一种高效且有效的替代方案。

> **ai_Abstract:** DocPolarBERT是一种新型的布局感知BERT模型，专为文档理解设计，其核心创新在于采用相对极坐标系统来编码文本块的位置，从而无需传统的绝对2D位置嵌入。尽管在规模远小于IIT-CDIP语料库的数据集上进行预训练，DocPolarBERT依然能够达到最先进的性能。这表明通过优化注意力机制，可以有效弥补预训练数据量的不足，为文档理解提供了一种高效且实用的新方法。

> **摘要翻译:** 我们引入了DocPolarBERT，一个用于文档理解的布局感知BERT模型，它消除了对绝对2D位置嵌入的需求。我们扩展了自注意力机制，以在相对极坐标系而非笛卡尔坐标系中考虑文本块的位置。尽管其预训练数据集比广泛使用的IIT-CDIP语料库小六倍以上，DocPolarBERT仍取得了最先进的结果。这些结果表明，精心设计的注意力机制可以弥补预训练数据的减少，为文档理解提供了一种高效且有效的替代方案。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [572] [Leveraging LLMs to Create Content Corpora for Niche Domains](https://arxiv.org/abs/2505.02851)
> *利用大型语言模型为小众领域创建内容语料库*

*Franklin Zhang, Sonya Zhang, Alon Halevy* | **Category: cs.CL, cs.AI, cs.CY, I.2.7; H.3.1; H.3.3** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 内容语料库, 数据整理, 领域特定, 习惯养成

**Comment:** 9 pages (main content), 5 figures. Supplementary materials can be
  found at https://github.com/pigfyy/30DayGen-Supplementary-Materials

> **TL;DR:** 本文提出了一种利用大型语言模型（LLMs）从网络数据中高效创建高质量、领域特定内容语料库的方法，并在行为教育领域进行了验证，取得了高用户满意度。

**AI_Comments:** 该论文的创新点在于利用大型语言模型（LLMs）自动化和优化了传统上耗时且复杂的数据整理过程，特别是在为小众领域构建专业内容语料库方面。其重要性体现在提供了一个可扩展的解决方案，能够高效地从海量网络数据中提取和合成高质量的结构化内容。通过在实际应用中取得高用户满意度，验证了该方法的实用性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 为领域特定应用从大量非结构化网络源构建专业内容语料库带来了巨大的数据整理挑战。

**Method:** 引入了一种流线型方法，通过高效获取、过滤、结构化和清理网络数据来生成高质量、领域特定的语料库。该方法利用大型语言模型（LLMs）解决大规模复杂数据整理问题，并提出了一个结合LLM增强技术的策略框架，用于结构化内容提取和语义去重。具体实现通过名为30DayGen的数据管道完成。

**Result:** 数据管道30DayGen成功从超过1.5万个网页中提取并合成了3,531个独特的30天挑战。用户调查报告满意度为4.3分（满分5分），91%的受访者表示愿意使用整理后的内容来实现他们的习惯养成目标。

**Conclusion:** 利用大型语言模型能够有效解决领域特定内容语料库构建中的数据整理挑战，并生成高质量、用户满意的结果。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLMs）从非结构化网络数据中高效构建高质量、领域特定内容语料库的流线型方法。该方法通过LLM增强的策略框架进行数据获取、过滤、结构化和语义去重。在行为教育领域的习惯养成应用中，通过名为30DayGen的数据管道成功提取了数千个独特挑战，用户满意度高，证明了LLMs在解决大规模数据整理挑战方面的有效性。

> **摘要翻译:** 为领域特定应用从大量非结构化网络源构建专业内容语料库带来了巨大的数据整理挑战。在本文中，我们介绍了一种流线型方法，通过高效获取、过滤、结构化和清理网络数据来生成高质量、领域特定的语料库。我们展示了如何利用大型语言模型（LLMs）来解决大规模复杂数据整理问题，并提出了一个结合LLM增强技术的策略框架，用于结构化内容提取和语义去重。我们在行为教育领域验证了我们的方法，将其集成到习惯养成应用30 Day Me中。我们的数据管道，名为30DayGen，能够从超过1.5万个网页中提取并合成了3,531个独特的30天挑战。用户调查报告满意度为4.3分（满分5分），91%的受访者表示愿意使用整理后的内容来实现他们的习惯养成目标。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [594] [Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires](https://arxiv.org/abs/2507.10073)
> *大型语言模型中的文化偏见：通过道德问卷评估AI代理*

*Simon Münker* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 文化偏见, 大型语言模型, 道德问卷, AI对齐, 文化多样性

**Comment:** 15pages, 1 figure, 2 tables

> **TL;DR:** 研究发现大型语言模型（LLMs）未能代表多元文化道德框架，反而系统性地同化了道德多样性，对当前AI对齐方法提出了挑战。

**AI_Comments:** 这项研究揭示了大型语言模型在文化代表性方面的一个关键局限性，即它们倾向于同化而非反映多元文化道德。这对于AI伦理和公平性具有重要意义，尤其是在AI系统日益融入社会应用的背景下。其创新之处在于通过跨文化道德问卷的实证方法，量化揭示了LLMs的文化偏见，并对现有AI对齐策略提出了挑战。研究结果强调了开发更具文化敏感性的AI模型和评估框架的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探讨AI系统是否真正代表了人类价值观，或者仅仅是取其平均值，并关注大型语言模型在文化道德框架表示方面的不足。

**Method:** 研究通过在19种文化背景下应用道德基础问卷（Moral Foundations Questionnaire），并将多个最先进的大型语言模型的起源与人类基线数据进行比较。

**Result:** 研究发现大型语言模型未能代表多元文化道德框架，AI生成与人类道德直觉之间存在显著差距。这些模型系统性地同化了道德多样性，且模型规模的增加并未持续改善文化代表性保真度。

**Conclusion:** 研究结果挑战了将大型语言模型用作社会科学研究中合成人群的日益增长的趋势，并突出了当前AI对齐方法中的一个根本局限性。没有超出提示的数据驱动对齐，这些系统无法捕捉细致的、文化特定的道德直觉。研究呼吁制定更扎实的对齐目标和评估指标，以确保AI系统代表多元的人类价值观，而不是扁平化道德图景。

> **ai_Abstract:** 本研究通过在19种文化背景下使用道德基础问卷，评估了大型语言模型（LLMs）对多元文化道德框架的代表能力。结果显示，LLMs未能准确代表不同文化背景下的道德直觉，反而系统性地同化了道德多样性，即使模型规模增大也未能显著改善。这表明当前AI对齐方法存在根本局限性，并对将LLMs用作社会科学研究中的合成人群提出了质疑，强调需要更完善的对齐目标和评估指标来确保AI能代表多元人类价值观。

> **摘要翻译:** AI系统是真正代表了人类价值观，还是仅仅取其平均值？我们的研究揭示了一个令人担忧的现实：大型语言模型（LLMs）尽管具备语言能力，却未能代表多元的文化道德框架。我们通过在19种文化背景下应用道德基础问卷，揭示了AI生成与人类道德直觉之间的显著差距。通过比较多个最先进大型语言模型的起源与人类基线数据，我们发现这些模型系统性地同化了道德多样性。令人惊讶的是，模型规模的增加并未持续改善文化代表性保真度。我们的研究结果挑战了将大型语言模型用作社会科学研究中合成人群的日益增长的趋势，并突出了当前AI对齐方法中的一个根本局限性。如果没有超出提示的数据驱动对齐，这些系统无法捕捉细致的、文化特定的道德直觉。我们的结果呼吁制定更扎实的对齐目标和评估指标，以确保AI系统代表多元的人类价值观，而不是扁平化道德图景。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [614] [SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity](https://arxiv.org/abs/2507.23095)
> *SMART-Editor：一种具有结构完整性的人类般设计编辑多智能体框架*

*Ishani Mondal, Meera Bharadwaj, Ayush Roy, Aparna Garimella, Jordan Lee Boyd-Graber* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 设计编辑, 全局连贯性, 多智能体框架, 奖励引导, 偏好优化

**Comment:** Under Submission

> **TL;DR:** SMART-Editor是一个新的框架，通过奖励引导策略在结构化和非结构化领域实现保持全局连贯性的设计编辑，并引入了新的基准测试，表现优于现有模型。

**AI_Comments:** 这篇论文的创新点在于提出了一个多智能体框架SMART-Editor，通过奖励引导策略（Reward-Refine和RewardDPO）有效解决了设计编辑中保持全局连贯性的难题，这对于生成更自然、更高质量的编辑至关重要。同时，引入了新的多领域基准SMARTEdit-Bench，为该领域的研究提供了有价值的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的模型在进行设计编辑时通常只进行局部修改，无法保持全局的全局连贯性。

**Method:** 提出了SMART-Editor框架，它通过两种策略来保持全局连贯性：Reward-Refine（一种推理时奖励引导的细化方法）和RewardDPO（一种训练时使用奖励对齐布局对的偏好优化方法。同时，引入了SMARTEdit-Bench基准来评估模型性能。

**Result:** SMART-Editor在多领域级联编辑场景中表现优于InstructPix2Pix和HIVE等强基线模型。RewardDPO在结构化设置中实现了高达15%的增益，而Reward-Refine在自然图像上显示出优势。自动和人工评估证实了奖励引导规划在生成语义一致和视觉对齐的编辑方面的价值。

**Conclusion:** 奖励引导的规划方法对于在结构化和非结构化领域生成语义一致且视觉对齐的设计编辑是有效的，SMART-Editor框架及其策略能够显著提升编辑的全局连贯性。

> **ai_Abstract:** SMART-Editor是一个用于设计编辑的框架，它通过Reward-Refine和RewardDPO两种策略解决了现有模型在进行局部编辑时缺乏全局连贯性的问题。该框架在结构化和非结构化领域均能进行布局和内容编辑，并通过新引入的SMARTEdit-Bench基准进行评估。实验结果表明，SMART-Editor在性能上超越了现有强基线，尤其在结构化设置中RewardDPO带来了显著提升，Reward-Refine在自然图像上表现出色，证明了奖励引导规划在生成高质量、一致性编辑方面的有效性。

> **摘要翻译:** 我们提出了SMART-Editor，一个用于跨结构化（海报、网站）和非结构化（自然图像）领域进行组合布局和内容编辑的框架。与执行局部编辑的现有模型不同，SMART-Editor通过两种策略保持全局连贯性：Reward-Refine，一种推理时奖励引导的细化方法；以及RewardDPO，一种使用奖励对齐布局对的训练时偏好优化方法。为了评估模型性能，我们引入了SMARTEdit-Bench，一个涵盖多领域、级联编辑场景的基准。SMART-Editor优于InstructPix2Pix和HIVE等强大的基线模型，其中RewardDPO在结构化设置中实现了高达15%的增益，Reward-Refine在自然图像上显示出优势。自动和人工评估证实了奖励引导规划在生成语义一致和视觉对齐的编辑方面的价值。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [621] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
> *大型语言模型中缓解对阿拉伯人和穆斯林文化偏见的提示工程技术：一项系统综述*

*Bushra Asseri, Estabrag Abdelaziz, Areej Al-Wabil* | **Category: cs.CL, cs.AI, cs.CY, cs.HC** | **Updated: 2025-07-30**

**Keywords:** 提示工程, 文化偏见, 大型语言模型, 阿拉伯人, 穆斯林

**Comment:** Research is incomplete

> **TL;DR:** 本系统综述探讨了通过提示工程技术来缓解大型语言模型中对阿拉伯人和穆斯林的文化偏见，发现了几种有效方法，但仍存在显著研究空白。

**AI_Comments:** 该论文创新性地将系统综述方法应用于提示工程领域，专门关注文化偏见，特别是针对阿拉伯人和穆斯林群体的偏见，这在伦理AI研究中具有重要意义。其重要性在于揭示了无需访问模型参数即可缓解偏见的实用策略，为LLM开发者和研究人员提供了宝贵指导。然而，论文也指出研究数量有限，表明该领域仍处于早期阶段，需要更多深入探究，特别是针对不同偏见类型和更深层次刻板印象的缓解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）存在对阿拉伯人和穆斯林的文化偏见，这通过固化有害刻板印象和边缘化造成了严重的伦理挑战。尽管人们日益认识到LLMs中的偏见问题，但专门针对阿拉伯和穆斯林表征的提示工程策略仍未得到充分研究。

**Method:** 本研究采用混合方法系统综述，遵循PRISMA指南和Kitchenham的系统综述方法论。分析了2021-2024年间发表的8项调查偏见缓解策略的实证研究。

**Result:** 研究发现了五种主要的提示工程方法：文化提示、情感启动、自去偏技术、结构化多步管道和参数优化连续提示。所有方法都显示出减少偏见的潜力，但有效性因研究和偏见类型而异。结构化多步管道的总体效果最佳，可将偏见减少高达87.7%，但需要更高的技术专业知识。文化提示具有更广泛的可及性和显著的有效性。结果强调了提示工程在无需访问模型参数的情况下缓解文化偏见的易用性。

**Conclusion:** 研究发现，尽管提示工程在缓解文化偏见方面具有潜力，但该领域的研究数量有限，存在显著的研究空白。未来的研究应侧重于开发文化适应性提示技术、创建阿拉伯和穆斯林特定评估资源，并将提示工程与互补的去偏方法相结合，以解决更深层次的刻板印象，同时保持模型效用。

> **ai_Abstract:** 本系统综述旨在探讨大型语言模型中通过提示工程技术缓解对阿拉伯人和穆斯林文化偏见的有效性。研究遵循PRISMA和Kitchenham方法论，分析了8项相关实证研究，识别出文化提示、情感启动、自去偏技术、结构化多步管道和参数优化连续提示五种主要方法。结果显示，所有方法均有潜力减少偏见，其中结构化多步管道效果最佳但技术要求高，文化提示则更易于使用且效果显著。研究强调了提示工程在不需修改模型参数的情况下缓解偏见的潜力，但也指出该领域研究不足，需进一步关注文化适应性技术和评估资源的开发。

> **摘要翻译:** 大型语言模型在各个领域展示了卓越的能力，然而，对文化偏见——特别是针对阿拉伯人和穆斯林的偏见——的担忧构成了重大的伦理挑战，因为它固化了有害的刻板印象和边缘化。尽管人们日益认识到大型语言模型中的偏见问题，但专门解决阿拉伯和穆斯林表征的提示工程策略仍未得到充分研究。这项混合方法系统综述审查了此类技术，为研究人员和实践者提供了基于证据的指导。遵循PRISMA指南和Kitchenham的系统综述方法论，我们分析了2021-2024年间发表的8项调查偏见缓解策略的实证研究。我们的发现揭示了五种主要的提示工程方法：文化提示、情感启动、自去偏技术、结构化多步管道和参数优化连续提示。尽管所有方法都显示出减少偏见的潜力，但有效性在不同研究和偏见类型之间差异显著。证据表明，某些偏见类型可能比其他类型更难以通过基于提示的方法缓解。结构化多步管道表现出最高的整体有效性，偏见减少高达87.7%，尽管它们需要更高的技术专业知识。文化提示具有更广泛的可及性和显著的有效性。这些结果强调了提示工程在无需访问模型参数的情况下缓解文化偏见的易用性。识别出的研究数量有限突显了这一关键领域的显著研究空白。未来的研究应侧重于开发文化适应性提示技术，创建阿拉伯和穆斯林特定评估资源，并将提示工程与互补的去偏方法相结合，以解决更深层次的刻板印象，同时保持模型效用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [630] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
> *ILID：印度语言的本地文字语言识别*

*Yash Ingle, Pruthwik Mishra* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 语言识别, 印度语言, 数据集, Transformer模型, 自然语言处理

**Comment:** 10 pages, 1 figure, 6 tables, Paper accepted in RANLP 2025

> **TL;DR:** 本文针对印度语言的语言识别挑战，创建了一个包含23种语言的25万句数据集，并开发了优于现有最先进模型的基线模型，且数据集和代码已开源。

**AI_Comments:** 本文的创新之处在于专门针对印度语言的语言识别挑战，构建了一个大规模、多语言的标注数据集，并提供了高性能的基线模型。考虑到印度语言的多样性和复杂性，该数据集和模型的发布对推动印度语言NLP研究具有重要意义，尤其是在多语言处理和信息检索等应用中。其开源性质也大大降低了后续研究的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 语言识别是NLP中的关键预处理步骤，但在嘈杂、短文本和代码混合环境下，尤其对于词汇和语音相似但文字不同的印度语言，挑战更大。许多印度语言共享相同文字，进一步增加了难度。

**Method:** 1. 开发并发布了一个包含23种语言（包括英语和所有22种官方印度语言）的25万句标注数据集，其中大部分数据是新创建的。2. 开发并发布了使用机器学习SOTA方法和微调预训练Transformer模型的基线模型。

**Result:** 团队开发的模型在语言识别任务上优于现有最先进的预训练Transformer模型。

**Conclusion:** 本文成功解决了印度语言的语言识别挑战，通过构建大规模数据集和高性能模型，为该领域提供了重要的资源和基线。

> **ai_Abstract:** 本文旨在解决印度语言的语言识别（LID）挑战，该任务因印度语言的相似性和共享文字而变得复杂。为此，研究人员构建了一个包含23种语言（包括英语和所有22种官方印度语言）的25万句大规模数据集，并开发了基于SOTA机器学习和Transformer模型微调的基线模型。实验结果表明，所提出的模型在LID任务上超越了现有最先进的预训练Transformer模型。所有数据集和代码均已开源。

> **摘要翻译:** 语言识别任务是自然语言处理中一个至关重要的基本步骤。它通常作为多语言机器翻译、信息检索、问答和文本摘要等广泛使用的自然语言处理应用的预处理步骤。语言识别的核心挑战在于在嘈杂、短文本和代码混合环境中区分语言。对于词汇和语音相似但具有明显差异的多元印度语言来说，这变得更加困难。许多印度语言共享相同的文字，使得这项任务更具挑战性。考虑到所有这些挑战，我们开发并发布了一个包含25万个句子的数据集，其中包含23种语言，包括英语和所有22种官方印度语言，并标有其语言标识符，其中大多数语言的数据是新创建的。我们还使用机器学习中的最先进方法和微调预训练Transformer模型开发并发布了基线模型。我们的模型在语言识别任务上优于最先进的预训练Transformer模型。数据集和代码可在 https://yashingle-ai.github.io/ILID/ 和 Huggingface 开源库中获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [634] [Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis](https://arxiv.org/abs/2507.22936)
> *评估大型语言模型（LLMs）在金融自然语言处理（NLP）中的应用：一项关于财务报告分析的比较研究*

*Md Talha Mohsin* | **Category: cs.CL, cs.AI, cs.CE, cs.HC, q-fin.CP** | **Updated: 2025-07-24**

**Keywords:** 大型语言模型, 金融NLP, 财务报告分析, 比较研究, 性能评估

**Comment:** 22 Pages, 6 Tables, 7 Figures

> **TL;DR:** 本研究对GPT、Claude、Perplexity、Gemini和DeepSeek五种主流大型语言模型在金融NLP任务中的表现进行了比较评估，发现GPT表现最佳，其次是Claude和Perplexity，而Gemini和DeepSeek表现出较大变异性。

**AI_Comments:** 本文通过对当前主流大型语言模型在金融NLP领域进行系统性比较，填补了现有研究的空白，具有重要的实践意义。其创新之处在于结合了人工标注、自动化指标和模型行为诊断多种评估方法，提供了更全面的性能视角。研究结果为金融分析师和开发者选择合适的LLM提供了宝贵参考。同时，也揭示了提示工程和源材料对LLM性能的关键影响，强调了未来研究和应用中需关注这些方面。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在金融自然语言处理（FinNLP）任务中展现出卓越能力，但对常用LLMs之间进行系统性比较的研究仍不足。鉴于LLMs在金融分析中快速发展且影响力日益增长，本研究旨在填补这一空白。

**Method:** 本研究对GPT、Claude、Perplexity、Gemini和DeepSeek五种主流LLMs进行了彻底的比较评估。数据源自“七大科技巨头”的10-K财务报告。研究创建了一系列领域特定提示，并采用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示层面的方差和模型间相似性）。

**Result:** 结果显示，GPT提供了最连贯、语义对齐和上下文相关的答案，其次是Claude和Perplexity。Gemini和DeepSeek则表现出更大的变异性和较低的一致性。此外，输出的相似性和稳定性因公司和时间而异，表明它们对提示的编写方式和使用的源材料很敏感。

**Conclusion:** 本研究通过对主流大型语言模型在金融报告分析中的系统比较，揭示了不同模型在性能上的显著差异，其中GPT表现最佳。同时强调了提示工程和源材料对模型输出质量和稳定性影响的重要性。

> **ai_Abstract:** 本研究旨在系统比较主流大型语言模型（LLMs）在金融报告分析中的表现。通过对GPT、Claude、Perplexity、Gemini和DeepSeek五种模型使用“七大科技巨头”的10-K文件进行评估，并结合人工标注、自动化指标和行为诊断，研究发现GPT在生成连贯、语义对齐和上下文相关答案方面表现最佳，其次是Claude和Perplexity。而Gemini和DeepSeek则显示出更高的变异性。研究还指出模型输出的稳定性和相似性受公司和时间影响，提示工程和源材料是关键因素。

> **摘要翻译:** 大型语言模型（LLMs）在各种金融自然语言处理（FinNLP）任务中展现出卓越的能力。然而，对广泛使用的LLMs之间的系统性比较仍未得到充分探索。鉴于LLMs在金融分析中快速发展且影响力日益增长，本研究对GPT、Claude、Perplexity、Gemini和DeepSeek五种领先的LLMs进行了彻底的比较评估，使用了“七大科技巨头”的10-K文件。我们创建了一组领域特定提示，然后使用三种方法评估模型性能：人工标注、自动化词汇语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示层面的方差和跨模型相似性）。结果显示，GPT给出了最连贯、语义对齐和上下文相关的答案；其次是Claude和Perplexity。另一方面，Gemini和DeepSeek表现出更大的变异性和较低的一致性。此外，输出的相似性和稳定性因公司而异且随时间变化，表明它们对提示的编写方式和使用的源材料很敏感。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [643] [LiMe: a Latin Corpus of Late Medieval Criminal Sentences](https://arxiv.org/abs/2404.12829)
> *LiMe：一个晚期中世纪拉丁语刑事判决语料库*

*Alessandra Bassani, Beatrice Del Bo, Alfio Ferrara, Marta Mangini, Sergio Picascia, Ambra Stefanello* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 拉丁语语料库, 中世纪刑事判决, LiMe数据集, 自然语言处理, 语料库标注

**Comment:** 

> **TL;DR:** LiMe是一个新的、专家标注的晚期中世纪拉丁语刑事判决语料库，旨在解决拉丁语数据稀缺问题，以支持掩码语言模型和监督式自然语言处理任务。

**AI_Comments:** LiMe语料库的创新之处在于其专注于晚期中世纪拉丁语刑事判决这一特定领域，并由专家进行高质量标注，这对于历史语言和法律文本的计算分析具有重要意义。它直接解决了拉丁语数据不足的问题，为未来的拉丁语NLP研究提供了宝贵资源，有助于缩小与现代语言模型性能的差距。

<details>
  <summary>Details</summary>

**Motivation:** 尽管计算语言学界已为拉丁语构建了一些资源，但与现代语言相比，拉丁语的可用数据量存在巨大差异，导致拉丁语大型语言模型的性能滞后。因此，需要更多高质量的拉丁语语料库来提升模型性能。

**Method:** 本文介绍了LiMe数据集，这是一个包含325份文档的语料库，这些文档提取自一系列名为《Libri sententiarum potestatis Mediolani》的中世纪手稿。该语料库由专家进行了彻底标注，旨在用于掩码语言模型以及监督式自然语言处理任务。

**Result:** LiMe数据集被成功创建并呈现，它是一个包含325份文档的晚期中世纪拉丁语刑事判决语料库，并经过专家彻底标注，可用于训练和评估拉丁语的计算语言学模型。

**Conclusion:** 本文通过引入LiMe数据集，为拉丁语计算语言学领域提供了一个新的、经过专家标注的语料库，有助于弥补拉丁语数据稀缺的现状，从而支持和改进拉丁语的自然语言处理任务和模型开发。

> **ai_Abstract:** 本文介绍了LiMe数据集，一个专门针对晚期中世纪拉丁语刑事判决的语料库。该数据集包含325份经过专家彻底标注的文档，旨在弥补拉丁语计算语言学领域数据稀缺的现状。LiMe语料库可用于训练掩码语言模型以及执行监督式自然语言处理任务，以提升拉丁语语言模型的性能。

> **摘要翻译:** 拉丁语受到了计算语言学研究界的关注，多年来，该领域已经构建了许多有价值的资源，从详细标注的语料库到复杂的语言分析工具。随着大型语言模型的最新出现，研究人员也开始开发能够生成拉丁语文本向量表示的模型。鉴于可用数据的差异，此类模型的性能仍落后于现代语言模型。在本文中，我们介绍了LiMe数据集，这是一个包含325份文档的语料库，这些文档提取自一系列名为《Libri sententiarum potestatis Mediolani》的中世纪手稿，并由专家进行了彻底标注，以便用于掩码语言模型以及监督式自然语言处理任务。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [663] [RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL](https://arxiv.org/abs/2507.23104)
> *RASL：用于大规模数据库文本到SQL的检索增强模式链接*

*Jeffrey Eben, Aitzaz Ahmad, Stephen Lau* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 文本到SQL, 大规模数据库, 检索增强, 模式链接, 自然语言接口

**Comment:** 

> **TL;DR:** RASL提出一种检索增强架构，通过分解和索引数据库模式及元数据，解决了LLM文本到SQL在企业级大规模数据库上的可扩展性问题，无需领域特定微调。

**AI_Comments:** 这篇论文通过引入检索增强架构，巧妙地解决了LLM在处理大规模企业数据库时面临的上下文限制和微调成本问题。其创新点在于将数据库模式和元数据分解为细粒度的语义单元进行索引和检索，这不仅提高了检索效率，也使得系统无需昂贵的领域特定微调即可适应多样化的数据库结构，极大地提升了文本到SQL系统的实用性和可部署性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于大型语言模型（LLM）的数据库自然语言接口有所进展，但扩展到企业级数据目录仍是一个未充分探索的挑战。现有工作依赖领域特定微调（使部署复杂化）且未能利用数据库元数据中的重要语义上下文。

**Method:** RASL引入了一种基于组件的检索架构，该架构将数据库模式和元数据分解为离散的语义单元，每个单元独立索引以进行有针对性的检索。该方法优先考虑有效的表识别，同时利用列级信息，确保检索到的表总数保持在可管理的上下文预算内。

**Result:** 实验表明，RASL方法保持了高召回率和准确性，其系统在具有不同结构和可用元数据的大规模数据库上优于基线。

**Conclusion:** RASL解决方案实现了可在不同企业环境中部署的实用文本到SQL系统，无需专门的微调，解决了自然语言数据库接口中关键的可扩展性差距。

> **ai_Abstract:** RASL提出了一种检索增强模式链接方法，旨在解决基于LLM的自然语言接口在企业级大规模数据库上部署时遇到的可扩展性问题。它通过将数据库模式和元数据分解为可独立检索的语义单元，并优先进行高效的表识别，确保在有限的上下文预算内实现高召回率和准确性。该方法无需领域特定微调，在实验中表现优于现有基线，为实用且可广泛部署的文本到SQL系统提供了解决方案。

> **摘要翻译:** 尽管基于大型语言模型（LLM）的数据库自然语言接口取得了进展，但扩展到企业级数据目录仍然是一个未充分探索的挑战。先前解决这一问题的工作依赖于领域特定的微调——这使部署复杂化——并且未能利用数据库元数据中包含的重要语义上下文。为了解决这些限制，我们引入了一种基于组件的检索架构，该架构将数据库模式和元数据分解为离散的语义单元，每个单元独立索引以进行有针对性的检索。我们的方法优先考虑有效的表识别，同时利用列级信息，确保检索到的表总数保持在可管理的上下文预算内。实验表明，我们的方法保持了高召回率和准确性，我们的系统在具有不同结构和可用元数据的大规模数据库上优于基线。我们的解决方案实现了可在不同企业环境中部署的实用文本到SQL系统，无需专门的微调，解决了自然语言数据库接口中关键的可扩展性差距。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [666] [FinGAIA: A Chinese Benchmark for AI Agents in Real-World Financial Domain](https://arxiv.org/abs/2507.17186)
> *FinGAIA：一个针对现实世界金融领域AI智能体的中文基准测试*

*Lingfeng Zeng, Fangqi Lou, Zixuan Wang, Jiajie Xu, Jinyi Niu, Mengping Li, Yifan Dong, Qi Qi, Wei Zhang, Ziwei Yang, Jun Han, Ruilun Feng, Ruiqi Hu, Lejie Zhang, Zhengbo Feng, Yicheng Ren, Xin Guo, Zhaowei Liu, Dongpo Cheng, Weige Cai, Liwen Zhang* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** AI智能体, 金融领域, 基准测试, FinGAIA, 评估

**Comment:** 

> **TL;DR:** FinGAIA是一个新的中文基准测试，用于评估AI智能体在现实世界金融任务中的表现，结果显示当前智能体（如ChatGPT）与人类专家相比表现不佳，并揭示了常见的失败模式。

**AI_Comments:** FinGAIA的创新之处在于它是首个专门针对金融领域AI智能体的中文基准测试，填补了该领域评估工具的空白。其重要性体现在它能客观评估现有AI智能体在复杂金融任务中的实际能力，并揭示了当前模型存在的关键局限性，例如在跨模态对齐和金融术语理解方面的不足。这为未来的研究提供了明确的方向，有助于推动AI智能体在金融领域的实用化发展。

<details>
  <summary>Details</summary>

**Motivation:** AI智能体在自动化复杂任务方面展现出巨大潜力，但在金融领域，其多步骤、多工具协作能力尚未得到充分探索。因此，需要一个专门的基准测试来评估和推动AI智能体在该领域的发展。

**Method:** 本文引入了FinGAIA，一个端到端的基准测试平台，旨在评估AI智能体在金融领域的实际能力。FinGAIA包含407个精心设计的任务，涵盖证券、基金、银行、保险、期货、信托和资产管理七个主要金融子领域。这些任务根据场景深度分为三个层次：基本业务分析、资产决策支持和战略风险管理。研究团队在零样本设置下评估了10个主流AI智能体。

**Result:** 在评估的10个主流AI智能体中，表现最好的ChatGPT整体准确率为48.9%，虽然优于非专业人士，但仍比金融专家低35个百分点以上。错误分析揭示了五种常见的失败模式，包括跨模态对齐缺陷、金融术语偏差、操作流程意识障碍等。

**Conclusion:** 当前AI智能体在金融领域的实际应用能力仍有待提高，与金融专家存在显著差距。本研究识别出的失败模式为未来AI智能体研究指明了关键方向。FinGAIA作为首个与金融领域紧密相关的智能体基准测试，旨在客观评估和促进智能体在该关键领域的发展。

> **ai_Abstract:** 本文介绍了FinGAIA，这是首个针对现实世界金融领域AI智能体进行评估的中文端到端基准测试。FinGAIA包含407项任务，涵盖七个金融子领域和三个场景深度层次，旨在评估智能体的多步骤、多工具协作能力。对10个主流AI智能体的评估显示，最佳表现的ChatGPT准确率仅为48.9%，显著低于金融专家。研究还识别了常见的错误模式，为未来金融AI智能体研究指明了重要方向。

> **摘要翻译:** AI智能体的蓬勃发展为自动化各个领域的复杂任务带来了前所未有的机遇。然而，它们在金融领域的多步骤、多工具协作能力仍未得到充分探索。本文介绍了FinGAIA，一个端到端的基准测试，旨在评估AI智能体在金融领域的实际能力。FinGAIA包含407个精心设计的任务，涵盖证券、基金、银行、保险、期货、信托和资产管理七个主要金融子领域。这些任务分为三个层次的场景深度：基本业务分析、资产决策支持和战略风险管理。我们在零样本设置下评估了10个主流AI智能体。表现最好的智能体ChatGPT的整体准确率为48.9%，虽然优于非专业人士，但仍比金融专家低35个百分点以上。错误分析揭示了五种常见的失败模式：跨模态对齐缺陷、金融术语偏差、操作流程意识障碍等。这些模式指出了未来研究的关键方向。我们的工作提供了第一个与金融领域紧密相关的智能体基准测试，旨在客观评估和促进智能体在这个关键领域的发展。部分数据可在https://github.com/SUFE-AIFLM-Lab/FinGAIA获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [668] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
> *NusaAksara：一个用于保护印度尼西亚本土文字的多模态多语言基准*

*Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur'aini, Derry Wijaya, Alham Fikri Aji* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-02-25**

**Keywords:** 印度尼西亚本土文字, 多模态基准, 多语言基准, 低资源语言, NLP性能

**Comment:** 

> **TL;DR:** NusaAksara是一个多模态多语言基准数据集，用于印度尼西亚本土文字，旨在解决现有NLP技术无法处理这些文字的问题。

**AI_Comments:** 这篇论文通过构建一个独特的多模态多语言基准数据集，填补了NLP领域对印度尼西亚本土文字研究的空白。其创新之处在于包含了多种模态（文本和图像）和任务，并特别关注了低资源和未被Unicode支持的文字。基准测试结果揭示了现有主流NLP技术在处理这些文字时的严重不足，强调了未来研究的紧迫性和重要性，对于文化遗产保护和语言多样性维护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 印度尼西亚拥有丰富的语言和文字，但大多数NLP研究进展都集中在罗马化文本上，缺乏对本土文字的支持。

**Method:** 提出了NusaAksara，一个新颖的公共基准数据集，包含印度尼西亚语言及其原始文字。该基准涵盖文本和图像模态，并包括图像分割、OCR、音译、翻译和语言识别等任务。数据由人类专家通过严格步骤构建，涵盖7种语言的8种文字，包括低资源语言和不支持Unicode的Lampung文字。研究者使用多种模型（如GPT-4o、Llama 3.2、Aya 23、PP-OCR和LangID）对数据进行了基准测试。

**Result:** 大多数NLP技术无法处理印度尼西亚的本地文字，许多模型表现接近于零。

**Conclusion:** 现有NLP技术在处理印度尼西亚本土文字方面存在显著不足，需要进一步研究和开发以支持这些低资源语言和文字。

> **ai_Abstract:** 本文介绍了NusaAksara，一个用于保护印度尼西亚本土文字的多模态多语言公共基准数据集。该数据集由人类专家构建，涵盖8种文字和7种语言，包括低资源和Unicode不支持的文字，并支持图像分割、OCR、音译、翻译和语言识别等任务。通过对GPT-4o、Llama 3.2等多种模型进行基准测试，研究表明现有NLP技术在处理印度尼西亚本土文字方面表现极差，多数性能接近零。

> **摘要翻译:** 印度尼西亚拥有丰富的语言和文字。然而，大多数自然语言处理（NLP）的进展都是使用罗马化文本完成的。在本文中，我们提出了NusaAksara，这是一个新颖的印度尼西亚语言公共基准，其中包含它们的原始文字。我们的基准涵盖文本和图像两种模态，并包含图像分割、光学字符识别（OCR）、音译、翻译和语言识别等多种任务。我们的数据由人类专家通过严格的步骤构建。NusaAksara涵盖7种语言的8种文字，包括在NLP基准中不常见的低资源语言。尽管Unicode不支持，但Lampung文字也被包含在此数据集中。我们使用多种模型对数据进行基准测试，包括大型语言模型（LLM）和视觉语言模型（VLM），如GPT-4o、Llama 3.2和Aya 23，以及特定任务系统，如PP-OCR和LangID，结果表明大多数NLP技术无法处理印度尼西亚的本地文字，许多模型的性能接近于零。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [688] [Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability](https://arxiv.org/abs/2406.14313)
> *用于处理不可回答问题的知识库问答中少样本迁移的弱验证器迭代修复*

*Riya Sawhney, Samrat Yadav, Indrajit Bhattacharya, Mausam* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** KBQA, 少样本迁移, 不可回答问题, 迭代修复, FUn-FuSIC

**Comment:** 

> **TL;DR:** 本文提出并解决了知识库问答中包含不可回答问题的少样本迁移任务，并提出了FUn-FuSIC模型，该模型通过弱验证器和自一致性迭代修复，显著优于现有模型。

**AI_Comments:** 本文的创新点在于提出了一个现实且具有挑战性的新任务：在少样本设置下处理包含不可回答问题的KBQA。通过引入FUn模块，该研究有效地解决了现有模型（如FuSIC-KBQA）在处理不可回答问题时的局限性。结合强弱验证器反馈和自一致性适应，FUn-FuSIC在性能上取得了显著提升，并为相关领域树立了新的基准。该工作对于提升KBQA在真实世界应用中的鲁棒性和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的知识库问答（KBQA）应用需要模型在有限的域内标注训练数据下处理不可回答的问题。现有最先进的少样本迁移模型（FuSIC KBQA）在迭代修复时假设所有问题都是可回答的，这在处理不可回答问题时存在局限性。

**Method:** 我们提出了FUn-FuSIC，它是FuSIC KBQA的扩展。FUn-FuSIC通过引入“不可回答性反馈”（FUn）来解决FuSIC KBQA的局限性。FUn使用来自一组强弱验证器的反馈进行迭代修复，并针对不可回答性问题调整了自一致性机制，以更好地评估问题的可回答性。我们还贡献了两个新的数据集用于性能评估。

**Result:** 实验表明，FUn-FuSIC在我们的任务上显著优于多种基于LLM和监督的SoTA模型的适当改编版。此外，它还在可回答的少样本迁移任务上建立了新的SoTA。

**Conclusion:** FUn-FuSIC模型有效解决了知识库问答中包含不可回答问题的少样本迁移任务，并在该任务上取得了显著的性能提升，同时也在可回答的少样本迁移任务上树立了新的SOTA。

> **ai_Abstract:** 本文提出了一个知识库问答（KBQA）中包含不可回答问题的少样本迁移新任务，并为此贡献了两个新数据集。针对此任务，作者提出了FUn-FuSIC模型，该模型是对现有最先进的少样本迁移模型FuSIC KBQA的扩展。FUn-FuSIC通过引入“不可回答性反馈”（FUn）来改进迭代修复过程，FUn利用强弱验证器的反馈并适应自一致性机制以更好地判断问题的可回答性。实验结果表明，FUn-FuSIC在所提出的任务上显著优于多种基线模型，并且在仅处理可回答问题的少样本迁移任务上也达到了新的最先进水平。

> **摘要翻译:** 现实世界中的知识库问答（KBQA）应用要求模型在有限的域内标记训练数据的情况下处理不可回答的问题。我们提出了一个关于知识库问答中包含不可回答问题的少样本迁移的新任务，并贡献了两个新的数据集用于性能评估。我们提出了FUn-FuSIC——一个针对我们任务的新颖解决方案，它扩展了FuSIC KBQA，即目前最先进的仅针对可回答问题的少样本迁移模型。我们首先注意到FuSIC-KBQA的迭代修复做了一个强假设，即所有问题都是不可回答的。作为补救措施，我们提出了“不可回答性反馈”（FUn），它利用来自一组强验证器和弱验证器的反馈进行迭代修复，并对不可回答性问题进行了自一致性调整，以更好地评估问题的可回答性。我们的实验表明，FUn-FuSIC在我们的任务上显著优于多种基于大型语言模型（LLM）和监督的最先进模型的适当改编版，同时也在可回答的少样本迁移任务上建立了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [689] [Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages](https://arxiv.org/abs/2507.21568)
> *低资源语言多语言神经翻译模型的多假设蒸馏*

*Aarón Galiano-Jiménez, Juan Antonio Pérez-Ortiz, Felipe Sánchez-Martínez, Víctor M. Sánchez-Cartagena* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 知识蒸馏, 多假设蒸馏, 低资源语言, 神经机器翻译, 性别偏见

**Comment:** 17 pages, 12 figures

> **TL;DR:** 本文提出多假设蒸馏（MHD）方法，通过生成多个翻译假设来利用教师模型的完整输出分布，以改进低资源语言的知识蒸馏，提高学生模型性能并减轻性别偏见。

**AI_Comments:** 本文创新性地提出多假设蒸馏（MHD），突破了传统知识蒸馏中仅依赖束搜索近似模式的局限性。通过引入多假设生成和探索替代解码策略（如采样），有效利用了教师模型的完整输出分布，为低资源语言的翻译模型带来了显著改进，尤其在提升语料多样性和缓解性别偏见方面展现出重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识蒸馏方法主要依赖束搜索生成的近似模式，未能充分利用教师模型的完整输出分布中的宝贵信息。特别是在低资源语言场景下，需要更丰富的目标端前缀表示和更高变异性的语料来提升学生模型性能并解决偏见问题。

**Method:** 本文提出了多假设蒸馏（Multi-Hypothesis Distillation, MHD）方法，这是一种序列级知识蒸馏方法。MHD通过为每个源语句生成多个翻译假设来提供教师模型分布的更大表示，并使学生模型接触到更广泛的目标端前缀。该方法利用束搜索的n-best列表来指导学生学习，并探索了替代解码方法（如采样）来解决低变异性和罕见词表征不足的问题。

**Result:** 对于低资源语言，研究表明，虽然采样方法可能比基于束搜索的方法略微降低翻译质量，但它们显著增强了生成语料的变异性和词汇丰富度。这最终提高了学生模型的性能，并减轻了知识蒸馏中常见的性别偏见放大问题。

**Conclusion:** 通过多假设蒸馏和利用采样等替代解码方法，可以有效利用教师模型的完整输出分布，为低资源语言的知识蒸馏提供更丰富的训练信号，从而提升学生模型性能并缓解性别偏见。

> **ai_Abstract:** 本文提出了一种名为多假设蒸馏（MHD）的序列级知识蒸馏方法，旨在解决多语言神经翻译模型在低资源语言场景下，传统束搜索在知识蒸馏中无法充分利用教师模型完整输出分布的问题。MHD通过为每个源语句生成多个翻译假设，扩大了教师模型分布的表示范围，并使学生模型接触到更多样化的目标端前缀。研究发现，对于低资源语言，尽管采样方法可能略微影响翻译质量，但能显著提升生成语料的变异性和词汇丰富度，从而有效提高学生模型性能并减轻知识蒸馏导致的性别偏见放大。

> **摘要翻译:** 本文探讨了多语言预训练编码器-解码器翻译模型的序列级知识蒸馏（KD）。我们认为，教师模型的输出分布为学生提供了宝贵的见解，超越了通过束搜索（标准解码方法）获得的近似模式。我们提出了多假设蒸馏（MHD），这是一种序列级KD方法，它为每个源句生成多个翻译。这提供了教师模型分布的更大表示，并使学生模型接触到更广泛的目标端前缀。我们利用束搜索的n-best列表来指导学生的学习，并研究了替代解码方法，以解决低变异性和不常见词汇表征不足等问题。对于低资源语言，我们的研究表明，虽然采样方法与基于束搜索的方法相比可能会略微损害翻译质量，但它们增强了生成语料的更大变异性和词汇丰富度。这最终提高了学生模型的性能，并减轻了知识蒸馏中常见的性别偏见放大。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [698] [Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity](https://arxiv.org/abs/2507.23121)
> *通过中文文本歧义揭示可信LLM的脆弱性*

*Xinwei Wu, Haojie Li, Hongyu Liu, Xinyu Ji, Ruohan Li, Yule Chen, Yigeng Zhang* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 文本歧义, 中文, 可信度, 脆弱性

**Comment:** Accepted at KDD workshop on Evaluation and Trustworthiness of Agentic
  and Generative AI Models (Agentic & GenAI Evaluation Workshop KDD '25)

> **TL;DR:** 本研究发现大型语言模型（LLMs）在处理中文文本歧义时表现出显著的脆弱性，它们无法可靠区分歧义文本，对单一解释过度自信，并在理解多重含义时过度思考，这表明当前LLM存在根本性局限。

**AI_Comments:** 本文通过专注于中文文本歧义，深入探讨了大型语言模型（LLMs）可信度的重要方面。其创新之处在于构建了一个结构化且细致的歧义数据集，这对于量化LLM在复杂语言现象中的表现至关重要。研究结果明确指出了当前LLM在处理不确定性和多义性方面的根本性局限，这对于未来LLM的鲁棒性改进具有重要的指导意义。该工作揭示了LLM与人类理解的差异，为开发更符合人类认知模式的AI系统提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨大型语言模型（LLMs）在遇到歧义叙述文本时的行为，特别是中文文本歧义，以解决LLM可信度方面的一个关键研究问题。

**Method:** 研究团队创建了一个基准数据集，通过收集和生成带有上下文的歧义句子及其对应的消歧对，这些句子代表了多种可能的解释。这些带注释的例子被系统地分为3个主要类别和9个子类别。

**Result:** 实验发现LLMs在处理歧义时表现出显著的脆弱性，其行为与人类大相径庭。具体来说，LLMs无法可靠地区分歧义文本和非歧义文本，在解释歧义文本时过度自信地认为只有一个含义而非多个含义，并且在试图理解各种可能含义时表现出过度思考。

**Conclusion:** 研究结果突出了当前LLMs的一个根本性局限，这对它们在语言歧义普遍存在的实际应用中的部署具有重要影响，并呼吁改进处理语言理解中不确定性的方法。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在处理中文文本歧义时的可信度问题。通过构建一个包含歧义句子及其消歧对的基准数据集，并将其系统分类，实验揭示了LLMs在处理歧义时的显著脆弱性。具体表现为LLMs难以区分歧义文本，对单一解释过度自信，以及在理解多重含义时过度思考。这些发现揭示了当前LLMs的根本性局限，对它们在实际应用中的部署具有重要启示，并强调了开发更优方法来处理语言理解中不确定性的必要性。

> **摘要翻译:** 在这项工作中，我们研究了一个关于大型语言模型（LLMs）可信度的关键研究问题：LLMs在遇到歧义叙述文本时如何表现，特别关注中文文本歧义。我们通过收集和生成带有上下文的歧义句子及其对应的消歧对，创建了一个基准数据集，这些句子代表了多种可能的解释。这些带注释的例子被系统地分为3个主要类别和9个子类别。通过实验，我们发现LLMs在处理歧义时表现出显著的脆弱性，揭示出与人类截然不同的行为。具体来说，LLMs无法可靠地区分歧义文本和非歧义文本，在解释歧义文本时过度自信地认为只有一个含义而非多个含义，并且在试图理解各种可能含义时表现出过度思考。我们的发现突出了当前LLMs的一个根本性局限，这对它们在语言歧义普遍存在的实际应用中的部署具有重要影响，并呼吁改进处理语言理解中不确定性的方法。数据集和代码已在此GitHub仓库公开：https://github.com/ictup/LLM-Chinese-Textual-Disambiguation。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [721] [Unveiling the Influence of Amplifying Language-Specific Neurons](https://arxiv.org/abs/2507.22581)
> *揭示放大语言特异性神经元的影响*

*Inaya Rahmanisa, Lyzander Marciano Andrylie, Mahardika Krisna Ihsani, Alfan Farizki Wicaksono, Haryo Akbarianto Wibowo, Alham Fikri Aji* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 语言特异性神经元, 大型语言模型, 多语言行为, 语言引导, 低资源语言

**Comment:** Our code and dataset are made available at
  https://github.com/tauimbz/lang-task-neuron

> **TL;DR:** 本文研究了放大语言特异性神经元对大型语言模型多语言行为的影响，发现其能有效引导输出到目标语言，对自语言性能有益，但对跨语言迁移效果有限。

**AI_Comments:** 本文创新性地探讨了放大语言特异性神经元而非失活的影响，揭示了其在多语言LLM中引导语言输出的潜力。研究发现放大对低资源语言有益，但对跨语言迁移的局限性也值得关注，为未来多语言模型优化提供了新视角。

<details>
  <summary>Details</summary>

**Motivation:** 语言特异性神经元在大型语言模型中被发现与特定语言相关并能通过失活影响模型行为，但其在“放大”方面的作用尚未得到充分探索。本文旨在探究放大语言特异性神经元的影响。

**Method:** 通过对18种语言（包括低资源语言）进行干预，使用三种主要用不同语言训练的模型来放大语言特异性神经元。通过提出的语言引导偏移（LSS）评估分数比较放大因子在引导目标语言方面的有效性，并在下游任务（常识推理XCOPA、XWinograd，知识Include，翻译FLORES）上进行评估。

**Result:** 最优放大因子能有效引导输出到几乎所有测试语言。在下游任务上使用该因子进行干预，在某些情况下能提高自语言性能，但通常会降低跨语言结果。放大对低资源语言特别有益，但对跨语言迁移的优势有限。

**Conclusion:** 放大语言特异性神经元可以有效引导大型语言模型输出到目标语言，对自语言性能（尤其是低资源语言）有益，但在跨语言迁移方面效果有限。

> **ai_Abstract:** 本文研究了在大型语言模型中放大语言特异性神经元对模型多语言行为的影响。研究通过对18种语言进行干预，并使用三种不同训练语言的模型，评估了放大因子在语言引导和下游任务上的效果。结果表明，最优放大因子能有效将输出引导至目标语言，对自语言性能（特别是低资源语言）有益，但对跨语言任务的性能有负面影响，且跨语言迁移的优势有限。

> **摘要翻译:** 大型语言模型中与个体语言高度相关的语言特异性神经元，已被证明通过失活可以影响模型行为。然而，它们在“放大”方面的作用仍未得到充分探索。本工作通过对18种语言（包括低资源语言）进行干预，并使用三种主要用不同语言训练的模型，研究了放大语言特异性神经元的影响。我们通过提出的语言引导偏移（LSS）评估分数，比较了放大因子在引导到目标语言方面的有效性，然后在下游任务：常识推理（XCOPA，XWinograd）、知识（Include）和翻译（FLORES）上进行评估。最优放大因子能有效引导输出到几乎所有测试语言。在下游任务上使用此因子进行干预，在某些情况下可以提高自语言性能，但通常会降低跨语言结果。这些发现突出了语言特异性神经元在多语言行为中的作用，其中放大可能特别有益于低资源语言，但为跨语言迁移提供的优势有限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [727] [Cutting Through the Noise: Boosting LLM Performance on Math Word Problems](https://arxiv.org/abs/2406.15444)
> *切割噪音：提升LLM在数学文字问题上的表现*

*Ujjwala Anantheswaran, Himanshu Gupta, Kevin Scaria, Shreyas Verma, Chitta Baral, Swaroop Mishra* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 数学文字问题, 对抗性样本, 鲁棒性, 微调

**Comment:** Published at ICLR 2025 Workshop on Reasoning and Planning for LLMs

> **TL;DR:** 论文提出了一个提示框架和数据集PROBLEMATHIC，通过添加无关信息生成对抗性数学文字问题，发现LLMs易受噪音干扰，导致性能下降；通过在对抗性样本上微调LLMs，可以提高其对噪音的鲁棒性，但面对新的对抗性数据仍有挑战。

**AI_Comments:** 这项研究的创新之处在于其构建对抗性数学文字问题的提示框架和PROBLEMATHIC数据集，这为评估和提升LLM在真实世界复杂问题中的鲁棒性提供了一个新的视角和工具。通过微调LLM来提高其对无关信息的识别能力，对于LLM在实际应用中的可靠性具有重要意义。然而，GSM-8K-Adv上的结果也揭示了LLM泛化能力的局限性，表明在面对未见过或更复杂的对抗性噪音时，LLM仍需进一步的改进。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在解决数学文字问题（MWPs）方面表现出色，但难以处理包含无关信息的真实世界问题。

**Method:** 提出了一个提示框架，通过添加无关变量来生成MWPs的对抗性变体；引入了数据集PROBLEMATHIC，包含对抗性和非对抗性MWPs；在对抗性样本上对LLMs（Llama-2, Mistral）进行微调；引入了GSM-8K-Adv，作为GSM-8K基准的对抗性变体，以评估提示框架的泛化能力。

**Result:** LLMs容易受到数字噪音的干扰，在对抗性MWPs上的平均相对性能下降约26%；在对抗性训练实例上进行微调后，LLMs在对抗性MWPs上的性能提高了约8%，表明对噪音的鲁棒性增强，识别相关数据进行推理的能力提高；LLMs在面对对抗性信息时仍然表现不佳，性能下降高达6%（在GSM-8K-Adv上）。

**Conclusion:** 通过在对抗性样本上微调LLMs，可以提高其对噪音的鲁棒性和识别相关数据的能力。然而，LLMs在面对新的对抗性信息时仍面临挑战，表明需要进一步提升其泛化能力。

> **ai_Abstract:** 本研究针对大型语言模型（LLMs）在处理含有无关信息的数学文字问题（MWPs）时遇到的困难，提出了一个生成对抗性MWPs的提示框架，并构建了PROBLEMATHIC数据集。实验发现LLMs易受数字噪音干扰，导致性能显著下降。通过在对抗性样本上对LLMs进行微调，能有效提升其对噪音的鲁棒性约8%。同时，引入GSM-8K-Adv基准测试表明，LLMs在面对新的对抗性信息时仍存在泛化挑战，性能仍有下降。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中表现出色，包括解决数学文字问题（MWPs），但难以处理包含无关信息的真实世界问题。为了解决这个问题，我们提出了一个提示框架，通过添加无关变量来生成MWPs的对抗性变体。我们引入了一个数据集PROBLEMATHIC，其中包含对抗性和非对抗性MWPs。我们的实验表明，LLMs容易受到数字噪音的干扰，导致在对抗性MWPs上的平均相对性能下降约26%。为了缓解这种情况，我们使用我们数据集中的对抗性样本对LLMs（Llama-2，Mistral）进行微调。在对抗性训练实例上进行微调使对抗性MWPs的性能提高了约8%，这表明对噪音的鲁棒性增强，并且识别相关数据进行推理的能力提高。最后，为了评估我们提示框架的泛化能力，我们引入了GSM-8K-Adv，这是GSM-8K基准的对抗性变体。LLMs在面对对抗性信息时仍然表现不佳，性能下降高达6%。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [733] [ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans](https://arxiv.org/abs/2507.23135)
> *ISO-Bench：通过程序计划基准测试视觉-语言模型中的多模态因果推理*

*Ananya Sadana, Yash Kumar Lal, Jiawei Zhou* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 多模态因果推理, 视觉-语言模型, 基准测试, 程序计划, ISO-Bench

**Comment:** 

> **TL;DR:** ISO-Bench是一个新的基准，用于评估视觉-语言模型在视觉观察和程序文本之间的因果依赖推理能力。当前最先进的模型表现不佳，显著落后于人类。

**AI_Comments:** 这项工作通过引入ISO-Bench，填补了评估多模态因果推理能力的空白，具有重要的创新性。它明确揭示了当前视觉-语言模型在该关键能力上的显著不足，即使是最先进的模型也远未达到人类水平。这强调了未来研究在提升模型对现实世界因果关系理解方面的迫切性，并为多模态AI的发展提供了清晰的挑战和方向。

<details>
  <summary>Details</summary>

**Motivation:** 在现实世界环境中运行的多模态模型面临的核心挑战之一是理解跨模态的因果关系。

**Method:** 研究人员引入了ISO-Bench，这是一个用于评估模型能否推断视觉观察和程序文本之间因果依赖关系的基准。每个示例都包含一个任务步骤的图像和一个来自计划的文本片段，目标是判断视觉步骤是在引用的文本步骤之前还是之后发生。研究人员在十个前沿视觉-语言模型上进行了评估。

**Result:** 对十个前沿视觉-语言模型的评估结果显示，它们的性能令人失望：最佳零样本F1得分仅为0.57，而思维链推理仅带来适度提升（最高0.62 F1），远低于人类（0.98 F1）。

**Conclusion:** 多模态模型在因果理解方面表现不佳，并且该分析为改进多模态模型的因果理解指明了具体方向。

> **ai_Abstract:** 本研究介绍了ISO-Bench，这是一个旨在评估视觉-语言模型在视觉观察与程序文本之间因果推理能力的基准。该基准通过要求模型判断视觉步骤与文本步骤的先后顺序来测试其因果理解能力。对当前最先进的视觉-语言模型进行的评估显示，它们在这项任务上的表现远低于人类水平，即使采用思维链推理也只有有限的提升。研究分析指出了未来改进多模态模型因果理解的方向。

> **摘要翻译:** 理解跨模态的因果关系是多模态模型在现实世界环境中运行的核心挑战。我们引入了ISO-Bench，这是一个用于评估模型能否推断视觉观察和程序文本之间因果依赖关系的基准。每个示例都包含一个任务步骤的图像和一个来自计划的文本片段，目标是判断视觉步骤是在引用的文本步骤之前还是之后发生。对十个前沿视觉-语言模型的评估结果显示，它们的性能令人失望：最佳零样本F1得分仅为0.57，而思维链推理仅带来适度提升（最高0.62 F1），远低于人类（0.98 F1）。我们的分析进一步强调了改进多模态模型因果理解的具体方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [738] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
> *LLM的表格数据理解：最新进展与挑战综述*

*Xiaofeng Wu, Alan Ritter, Wei Xu* | **Category: cs.CL, cs.DB, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 表格数据理解, 大型语言模型, 综述, 挑战, 表格表示

**Comment:** 

> **TL;DR:** 本论文综述了大型语言模型（LLMs）在表格数据理解方面的最新进展与挑战，指出现有方法的局限性，并强调了未来研究的关键领域。

**AI_Comments:** 这篇综述论文对于理解LLM在表格数据处理领域的现状及其面临的挑战具有重要意义。它清晰地指出了当前研究的不足之处，特别是模型在推理能力、处理复杂结构和泛化能力方面的局限性，为未来的研究方向提供了宝贵的指引。其分类学方法有助于系统地理解表格理解任务。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据因其复杂和灵活的结构在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）中受到广泛关注。然而，表格格式和用途的多样性导致了表格理解任务的复杂性，缺乏通用方法，使得导航和解决这些任务充满挑战。

**Method:** 本文通过对表格输入表示进行分类，并介绍表格理解任务，从而引入关键概念，旨在梳理和分析LLM在表格数据理解领域的最新进展和面临的挑战。

**Result:** 本文指出了该领域的几个关键研究空白：1) 现有任务主要侧重于检索，对数学和逻辑运算之外的推理要求较低；2) 模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临显著挑战；3) 模型在不同表格表示和格式之间的泛化能力有限。

**Conclusion:** 表格数据理解对于LLMs和MLLMs而言是一个复杂且充满挑战的领域，特别是在推理能力、处理复杂表格和模型泛化方面存在显著不足，需要进一步深入研究以弥补这些关键空白。

> **ai_Abstract:** 这篇综述论文探讨了大型语言模型（LLM）在理解表格数据方面的最新进展和挑战。鉴于表格的二维和多样化特性，其理解任务比线性文本更为复杂。论文引入了表格输入表示的分类法和表格理解任务，并强调了当前研究存在的关键空白，包括对检索任务的过度依赖、处理复杂表格的挑战以及模型泛化能力的局限性。

> **摘要翻译:** 表格因其复杂灵活的结构在大型语言模型 (LLM) 和多模态大型语言模型 (MLLM) 中获得了广泛关注。与线性文本输入不同，表格是二维的，其格式范围从结构良好的数据库表格到复杂的多层电子表格，每种表格都有不同的用途。这种格式和用途的多样性导致了专门方法和任务的开发，而非通用方法，使得表格理解任务的探索充满挑战。为了应对这些挑战，本文通过表格输入表示的分类法和表格理解任务的介绍，引入了关键概念。我们强调了该领域的几个关键空白，这些空白表明需要进一步研究：(1) 主要以检索为中心的任务，这些任务除了数学和逻辑运算外，几乎不需要额外的推理；(2) 模型在处理复杂表格结构、大规模表格、长上下文或多表格场景时面临的显著挑战；以及 (3) 模型在不同表格表示和格式之间的泛化能力有限。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [746] [OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching](https://arxiv.org/abs/2503.21813)
> *OAEI-LLM-T：一个用于理解本体匹配中大型语言模型幻觉的TBox基准数据集*

*Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-05-14**

**Keywords:** 大型语言模型幻觉, 本体匹配, 基准数据集, TBox, OAEI-LLM-T

**Comment:** 14 pages, 4 figures, 4 tables, 2 prompt templates

> **TL;DR:** 本文介绍了OAEI-LLM-T，一个用于评估和减少大型语言模型在本体匹配任务中幻觉的新基准数据集。

**AI_Comments:** 这篇论文通过创建一个专门的基准数据集，创新性地解决了LLM在本体匹配领域中“幻觉”这一核心问题。其重要性在于为评估和改进LLM在特定下游任务中的可靠性提供了具体工具和方法。通过对幻觉进行分类，也为未来更细致的错误分析和模型改进奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型（LLMs）在下游任务中，特别是基于LLM的本体匹配（OM）系统中普遍存在的幻觉问题。

**Method:** 引入了一个名为OAEI-LLM-T的新基准数据集。该数据集基于本体对齐评估倡议（OAEI）中的七个TBox数据集构建，捕获了十个不同LLM在执行OM任务时产生的幻觉，并将其组织成两个主要类别和六个子类别。

**Result:** 该数据集可用于构建本体匹配任务的LLM排行榜，以及用于微调本体匹配任务中使用的LLM。

**Conclusion:** OAEI-LLM-T数据集是理解和解决大型语言模型在本体匹配中幻觉的关键工具，有助于评估和改进LLM在该特定领域中的性能。

> **ai_Abstract:** 本文介绍了OAEI-LLM-T，一个专门用于评估和解决大型语言模型（LLM）在本体匹配（OM）任务中产生幻觉的TBox基准数据集。该数据集源自OAEI的七个TBox数据集，记录并分类了十个不同LLM在执行OM任务时的幻觉表现。研究表明，此数据集对于构建LLM在OM任务中的性能排行榜和对LLM进行微调以减少幻觉具有重要价值。

> **摘要翻译:** 使用大型语言模型（LLM）的下游任务中，幻觉往往是不可避免的。为了解决LLM本体匹配（OM）系统中处理幻觉的重大挑战，我们引入了一个新的基准数据集OAEI-LLM-T。该数据集源自本体对齐评估倡议（OAEI）中的七个TBox数据集，捕获了十个不同LLM在执行OM任务时的幻觉。这些OM特有的幻觉被组织成两个主要类别和六个子类别。我们展示了该数据集在构建OM任务的LLM排行榜和用于微调OM任务中使用的LLM方面的有用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [768] [User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal](https://arxiv.org/abs/2507.23158)
> *人类-大型语言模型对话中的用户反馈：理解用户的视角但作为学习信号时存在噪声*

*Yuhan Liu, Michael J. Q. Zhang, Eunsol Choi* | **Category: cs.CL** | **Updated: 2025-07-30**

**Keywords:** 用户反馈, 大型语言模型, 隐式反馈, 学习信号, 对话系统

**Comment:** Earlier version of this paper was presented at 2nd Workshop on Models
  of Human Feedback for AI Alignment (MoFA), ICML 2025

> **TL;DR:** 研究发现，从人类-LLM交互日志中获取的隐式用户反馈有助于理解用户，但作为学习信号时存在局限性，尤其在复杂问题上，且其有效性与用户初始提示质量相关。

**AI_Comments:** 这篇论文创新性地将用户-LLM交互日志中的隐式反馈作为研究对象，而非依赖显式反馈，这对于LLM的持续改进具有重要意义。它揭示了隐式反馈作为学习信号的复杂性，特别是在处理复杂任务时，并强调了初始提示质量的重要性，为未来LLM的反馈学习机制设计提供了宝贵见解。其局限性在于，虽然指出了反馈的“噪声”问题，但并未提出具体的降噪或优化方案。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型部署后，理想情况是能根据用户反馈持续进化。直接的用户反馈可能具有干扰性，因此研究人员希望从用户-LM交互日志中获取隐式用户反馈。

**Method:** 研究人员在两个用户-LM交互数据集（WildChat和LMSYS）中研究隐式用户反馈。首先，分析用户反馈在用户-LLM对话轨迹中的出现时间和原因。其次，研究如何从这些隐式用户反馈中获取学习信号。

**Result:** 用户反馈的内容（例如用户需要澄清），而不仅仅是极性（例如用户对之前的模型响应不满意），可以提高模型在短小、人类设计问题（MTBench）上的性能；但在更长、更复杂的问题（WildBench）上，这种改进不明显。用户反馈的有用性在很大程度上取决于用户初始提示的质量。

**Conclusion:** 这项研究对隐式用户反馈进行了深入探讨，展示了其潜力与局限性。

> **ai_Abstract:** 本文研究了从人类-大型语言模型（LLM）交互日志中获取隐式用户反馈的潜力与局限性。通过分析WildChat和LMSYS数据集，研究揭示了用户反馈的发生时机和原因，并探讨了将其作为学习信号的有效性。结果表明，用户反馈的内容而非仅其极性，可提升模型在简短问题上的表现，但在复杂问题上效果不佳，且反馈的有用性与用户初始提示质量密切相关。

> **摘要翻译:** 一旦语言模型（LMs）部署，它们就可以与用户进行长期互动，理想情况下，能够根据用户反馈持续进化。要求直接的用户反馈可能会造成干扰；因此，我们研究从用户-LM交互日志中获取用户反馈。我们在两个用户-LM交互数据集（WildChat和LMSYS）中研究了隐式用户反馈。首先，我们分析了用户-LLM对话轨迹中的用户反馈，提供了关于此类反馈何时以及为何发生的见解。其次，我们研究了如何从这些隐式用户反馈中获取学习信号。我们发现，用户反馈的内容（例如，用户需要澄清），而不仅仅是极性（例如，用户对之前的模型响应不满意），可以提高模型在短小、人类设计问题（MTBench）上的性能，但在更长、更复杂的问题（WildBench）上则不能。我们还发现，用户反馈的有用性在很大程度上取决于用户初始提示的质量。总而言之，我们对隐式用户反馈进行了深入研究，展示了其潜力与局限性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [769] [Neutral Residues: Revisiting Adapters for Model Extension](https://arxiv.org/abs/2410.02744)
> *中性残差：重新审视适配器以进行模型扩展*

*Franck Signe Talla, Edouard Grave, Hervé Jégou* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 适配器, 领域适应, 中性残差, 模型扩展

**Comment:** Accepted at ICML 2025

> **TL;DR:** 本文提出了一种名为“中性残差”的新方法，通过修改适配器来扩展预训练大型语言模型到新领域，同时保持原始领域的性能。

**AI_Comments:** 这项研究的创新之处在于其“中性残差”概念，通过巧妙地修改适配器，使得新增容量对原始领域的影响最小化，有效解决了模型扩展中的灾难性遗忘问题。这为大型语言模型在多领域应用中的持续学习和适应提供了一条有前景的路径。其在权衡新旧领域性能方面的显著提升，显示了该方法在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型扩展方法（如微调或LoRA）在领域适应时，往往面临在新领域表现良好与原始领域性能下降之间的权衡，因为它们没有正式增加模型容量。

**Method:** 本文重新审视并改进了适配器，从数据、架构和训练过程三个角度共同考虑。提出的“中性残差”方法修改适配器，使得每个新的残差块在原始领域输出接近零，从而在扩展模型容量的同时不影响原始性能。

**Result:** 该方法在将一个最先进的英文模型适应到新语言时取得了显著效果。与微调、LoRA或普通适配器等竞争方法相比，中性残差在学习新语言和不遗忘英文之间的权衡方面表现显著优越。

**Conclusion:** 中性残差方法通过独特地修改适配器，有效地解决了大型语言模型扩展到新领域时性能下降的问题，实现了在新领域表现优异同时保持原始领域性能。

> **ai_Abstract:** 该论文提出了一种名为“中性残差”的新方法，旨在解决大型语言模型在扩展到新领域时，现有方法（如微调或LoRA）导致原始领域性能下降的问题。通过从数据、架构和训练过程三个方面改进适配器，中性残差确保新增的残差块在原始领域输出接近零，从而有效增加模型容量并实现新领域适应，同时保持原始性能。实验结果表明，该方法在语言适应任务中显著优于其他竞争方法，成功平衡了新语言学习与原始语言保持。

> **摘要翻译:** 我们解决了将预训练大型语言模型扩展到训练期间未见的新领域的问题。标准技术，如微调或低秩适应（LoRA），在领域适应方面是成功的，但并未正式增加模型的容量。这通常导致在新领域表现良好与原始领域性能下降之间的权衡。在这里，我们重新审视并改进了适配器，从数据、架构和训练过程三个角度共同扩展大型语言模型，这些角度被有利地联合考虑。由此产生的方法，称为中性残差，以一种方式修改适配器，使得每个新的残差块在原始领域输出接近零。当将一个最初在英文上训练的最先进模型适应到新语言时，该解决方案带来了强大的结果。中性残差在学习新语言和不遗忘英文之间的权衡方面，显著优于微调、LoRA或普通适配器等竞争方法。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [774] [Large Language Models in the Travel Domain: An Industrial Experience](https://arxiv.org/abs/2507.22910)
> *大型语言模型在旅游领域的应用：一项工业实践*

*Sergio Di Meglio, Aniello Somma, Luigi Libero Lucio Starace, Fabio Scippacercola, Giancarlo Sperlì, Sergio Di Martino* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 大型语言模型, 旅游领域, 数据一致性, Mistral 7B, Mixtral 8x7B, 工业实践

**Comment:** Manuscript accepted to the International Conference on Software
  Engineering and Knowledge Engineering (SEKE) 2025

> **TL;DR:** 在旅游预订平台中，Mixtral 8x7B在数据一致性方面优于Mistral 7B，但计算成本更高，研究提供了模型质量与资源效率的权衡。

**AI_Comments:** 本文通过一个具体的工业案例展示了大型语言模型在解决实际数据一致性问题上的应用潜力。其创新点在于直接比较了两种流行的LLM在特定业务场景下的表现，并量化了性能与成本之间的权衡，为企业级LLM部署提供了宝贵的实践经验。这对于考虑在生产环境中应用LLM的企业具有重要的参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 在线住宿预订平台依赖第三方数据，但这些数据常不完整或不一致，导致用户受挫和市场损失。

**Method:** 将大型语言模型（LLMs）集成到FERVENTO开发的CALEIDOHOTELS平台。评估了两种LLM：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。评估标准是生成一致且同质描述的能力，并最小化幻觉。

**Result:** Mixtral 8x7B在完整性（99.6% vs 93%）、精确性（98.8% vs 96%）和幻觉率（1.2% vs 4%）方面优于Mistral 7B，生成内容更短更简洁（平均249字 vs 277字）。然而，其计算成本显著更高（50GB VRAM和$1.61/小时 vs 5GB和$0.16/小时）。

**Conclusion:** 研究结果提供了模型质量与资源效率权衡的实用见解，为在生产环境中部署LLM提供了指导，并证明了LLM在增强住宿数据一致性和可靠性方面的有效性。

> **ai_Abstract:** 本文介绍了一项将大型语言模型（LLMs）集成到住宿预订平台CALEIDOHOTELS的工业案例研究，旨在解决第三方数据源不完整或不一致的问题。研究比较了Mistral 7B（QLoRA微调）和Mixtral 8x7B（优化提示）在生成一致描述和减少幻觉方面的表现。结果显示Mixtral 8x7B在数据完整性、精确度和幻觉率方面表现更优，但计算成本显著高于Mistral 7B。研究强调了LLM在提升住宿数据一致性和可靠性方面的潜力，并提供了关于模型性能与资源成本权衡的实践指导。

> **摘要翻译:** 在线住宿预订平台被广泛使用，并严重依赖于关于住宿设施的一致、最新的信息，这些信息通常来源于第三方供应商。然而，这些外部数据源经常受到不完整或不一致细节的影响，这可能使用户感到沮丧并导致市场损失。为了应对这些挑战，我们提出了一个工业案例研究，涉及将大型语言模型（LLMs）集成到FERVENTO开发的住宿预订平台CALEIDOHOTELS中。我们在此背景下评估了两种知名LLM：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。评估这两种模型是基于它们生成一致和同质描述同时最小化幻觉的能力。Mixtral 8x7B在完整性（99.6% 对比 93%）、精确度（98.8% 对比 96%）和幻觉率（1.2% 对比 4%）方面优于Mistral 7B，生成的内容更短但更简洁（平均249字 对比 277字）。然而，这带来了显著更高的计算成本：50GB VRAM和1.61美元/小时，而Mistral 7B为5GB和0.16美元/小时。我们的研究结果提供了关于模型质量和资源效率之间权衡的实用见解，为在生产环境中部署LLM提供了指导，并证明了它们在增强住宿数据一致性和可靠性方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [794] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
> *EdgeInfinite-Instruct：弥合基于SFT的优化与NPU级边缘设备效率之间的鸿沟*

*Jiyu Chen, Poh Seng Lim, Shuang Peng, Daxiong Luo, JungHau Foo, Yap Deep, Timothy Lee Jun Jie, Kelvin Teh Kae Wen, Fan Yang, Danyu Feng, Hao-Yun Chen, Peng-Wen Chen, Fangyuan Li, Xiaoxin Chen, Wong Wai Mun* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 边缘设备, LLM, 指令微调, NPU, 量化

**Comment:** 9 pages

> **TL;DR:** EdgeInfinite-Instruct通过分段SFT和NPU优化，提升了边缘设备上长序列LLM的性能和效率。

**AI_Comments:** 该论文的创新点在于结合了SFT优化和NPU级效率提升，特别针对边缘设备上的长序列LLM部署。通过引入分段SFT解决了现有EdgeInfinite指令遵循能力不足的问题，并利用PTQ和固定形状计算图实现了高效的NPU部署。这对于推动LLM在资源受限移动设备上的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的边缘设备上部署基于Transformer的大型语言模型（LLMs）以处理长序列任务，面临自注意力二次时间复杂度和KV缓存需求增长的挑战。现有优化方案未能有效缩短首个令牌生成时间（TTFT）或可能降低性能，而替代架构则需要全面重新训练且缺乏基础设施支持。EdgeInfinite虽能减少计算和内存成本，但其指令遵循能力有限且缺乏移动端优化。

**Method:** 提出EdgeInfinite-Instruct，引入分段监督微调（S-SFT）策略以适应长序列任务；通过细粒度训练后量化（PTQ）降低计算需求并保持精度；实现固定形状计算图，通过场景定制输入令牌和缓存大小来平衡内存使用和设备效率。

**Result:** 在长上下文基准测试和真实移动任务上的实验表明，该方法在NPU加速的边缘设备上提高了特定领域的性能，同时保持了效率。

**Conclusion:** EdgeInfinite-Instruct通过结合S-SFT、PTQ和定制计算图，有效解决了边缘设备上LLM处理长序列任务的挑战，实现了性能与效率的平衡。

> **ai_Abstract:** 本文提出了EdgeInfinite-Instruct，旨在解决大型语言模型在边缘设备上处理长序列任务时面临的效率和性能挑战。通过引入分段监督微调（S-SFT）策略、细粒度训练后量化（PTQ）以及定制的固定形状计算图，EdgeInfinite-Instruct在保持模型质量的同时，显著降低了计算和内存开销，并优化了NPU部署效率。实验证明，该方法在长上下文任务上提升了性能，同时在边缘设备上保持了高效率。

> **摘要翻译:** 在资源受限的边缘设备上部署基于Transformer的大型语言模型（LLMs）以处理长序列任务仍然具有挑战性，这归因于自注意力的二次时间复杂度和不断增长的键值（KV）缓存需求。尽管现有的KV缓存优化提高了内存效率，但它们通常无法缩短首个令牌生成时间（TTFT），并且可能通过令牌修剪降低性能。替代的序列建模架构解决了其中一些限制，但通常需要全面重新训练并且缺乏基础设施支持。EdgeInfinite通过仅微调一小部分参数提供了一种高效的解决方案，在保持质量的同时降低了计算和内存成本，包括改进的TTFT。然而，其指令遵循能力有限，并且缺乏针对移动设备的优化。为了解决这些问题，我们提出了EdgeInfinite-Instruct，它引入了一种分段监督微调（S-SFT）策略，专为摘要和问答等长序列任务量身定制。我们通过采用细粒度训练后量化（PTQ）来降低计算需求同时保持精度，并通过实现固定形状计算图（通过针对特定场景定制输入令牌和缓存大小来平衡内存使用和设备效率）进一步优化了EdgeInfinite-Instruct，使其能够在边缘NPU上高效部署。在长上下文基准测试和真实世界移动任务上的实验表明，我们的方法在NPU加速的边缘设备上提高了特定领域的性能，同时保持了效率。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [795] [ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing](https://arxiv.org/abs/2507.22911)
> *ElectriQ：电力营销领域大型语言模型响应能力评估基准*

*Jinzhi Wang, Qingke Peng, Haozhou Li, Zeyuan Zeng, Qinfeng Song, Kaixuan Yang, Jiangbo Zhang, Yaoying Wang, Ruimeng Li, Biyi Zhou* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-19**

**Keywords:** 大型语言模型, 电力营销, 基准, 知识增强, 客户服务

**Comment:** 

> **TL;DR:** ElectriQ是一个评估和提升大型语言模型在电力营销客户服务中表现的基准，通过领域知识增强，小型模型甚至能超越GPT-4o。

**AI_Comments:** 该论文的创新之处在于首次为电力营销领域的大型语言模型评估和开发建立了专门的基准ElectriQ。其重要性体现在它解决了现有电力客服系统效率低下和通用LLM领域知识不足的问题，并证明了通过领域知识增强，小型模型也能在特定领域超越大型通用模型，这为垂直领域LLM的落地提供了宝贵的经验和方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的电力营销客户服务系统（如95598热线）存在响应慢、流程不灵活和准确性有限的问题。通用大型语言模型（LLMs）虽然能力强大，但在该领域缺乏所需的领域专业知识和同理心，因此需要一个专门的基准来弥补这一差距。

**Method:** 引入了ElectriQ基准，包含一个涵盖六个关键服务类别的对话数据集，并提出了专业性、受欢迎度、可读性和用户友好性四种评估指标。此外，还整合了领域特定知识库，并提出了一种知识增强方法来提升模型性能。

**Result:** 对13个大型语言模型进行的实验表明，经过微调和知识增强的小型模型（如LLama3-8B）在专业性和用户友好性方面可以超越GPT-4o。

**Conclusion:** ElectriQ为开发适应电力营销服务需求的大型语言模型奠定了全面基础。

> **ai_Abstract:** 该论文介绍了ElectriQ，一个用于评估和提升大型语言模型在电力营销客户服务中表现的基准。面对现有系统响应慢和通用LLM缺乏领域专业知识的问题，ElectriQ提供了一个包含多类别对话数据集和四项评估指标的框架。通过结合领域知识库和知识增强方法，实验证明经过优化的小型模型在特定指标上能超越顶尖通用模型，为开发专业的电力营销LLM奠定了基础。

> **摘要翻译:** 电力营销客户服务在处理查询、投诉和服务请求方面发挥着关键作用。然而，当前系统，如中国的95598热线，经常面临响应时间慢、程序不灵活以及领域特定任务准确性有限的问题。尽管GPT-4o和Claude 3等大型语言模型（LLMs）展现出强大的通用能力，但它们在该领域缺乏所需的领域专业知识和同理心。为了弥合这一差距，我们引入了ElectriQ，这是第一个旨在评估和增强大型语言模型在电力营销场景中表现的基准。ElectriQ包含一个涵盖六个关键服务类别的对话数据集，并引入了专业性、受欢迎度、可读性和用户友好性四种评估指标。我们进一步整合了领域特定知识库，并提出了一种知识增强方法来提升模型性能。对13个大型语言模型进行的实验表明，经过微调和增强的小型模型，如LLama3-8B，在专业性和用户友好性方面可以超越GPT-4o。ElectriQ为开发适应电力营销服务需求的大型语言模型奠定了全面基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [796] [LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration](https://arxiv.org/abs/2507.23167)
> *LENS: 从神经状态学习集成置信度以实现多大型语言模型答案集成*

*Jizhou Guo* | **Category: cs.CL, cs.AI, cs.LG, cs.MA** | **Updated: 2025-07-31**

**Keywords:** LLM集成, 模型置信度, 神经状态, 内部表示, LENS

**Comment:** 

> **TL;DR:** LENS通过分析LLM的内部表示来学习模型置信度，从而在多LLM集成中显著优于传统方法。

**AI_Comments:** LENS的创新之处在于利用LLM的内部神经状态来估计上下文相关的模型置信度，这比传统的简单投票或logits集成方法更精细。其无需修改原始模型参数且计算开销小的特点，使其具有较高的实用性。该研究强调了LLM内部表示在理解模型行为和提升集成性能方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型 (LLM) 集成方法（如投票或logits集成）忽略了模型在不同上下文中的置信度和可靠性差异，导致系统鲁棒性和性能提升受限。

**Method:** 提出LENS（Learning ENsemble confidence from Neural States），一种通过分析LLM内部表示来估计模型置信度的新方法。LENS为每个LLM训练一个轻量级线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入，从而根据上下文相关可靠性对模型预测进行更细致的加权。该方法无需修改模型参数，且计算开销可忽略不计。

**Result:** 在多项选择和布尔问答任务上的实验结果表明，LENS显著优于传统集成方法。

**Conclusion:** 内部表示为确定模型置信度提供了有价值的信号，并且可以有效地用于集成学习。

> **ai_Abstract:** 该论文提出LENS，一种新颖的多大型语言模型（LLM）答案集成方法。LENS通过分析LLM的内部表示（如逐层隐藏状态和归一化概率）来学习估计模型的上下文相关置信度，并训练轻量级线性预测器进行加权。与传统简单集成方法相比，LENS无需修改模型参数且计算开销小，并在多项选择和布尔问答任务上表现出显著优越性，证明了内部表示在集成学习中确定模型置信度的价值。

> **摘要翻译:** 大型语言模型（LLM）在各种任务中展现出令人印象深刻的性能，不同的模型在不同的领域和特定能力上表现出色。有效结合多个LLM的预测对于增强系统鲁棒性和性能至关重要。然而，现有的集成方法通常依赖于简单的技术，如投票或logits集成，这些方法忽略了模型在不同上下文中的置信度和可靠性差异。在这项工作中，我们提出了LENS（Learning ENsemble confidence from Neural States），这是一种通过分析内部表示来学习估计模型置信度的新方法。对于每个LLM，我们训练一个轻量级线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这使得可以根据模型上下文相关的可靠性对其预测进行更细致的加权。我们的方法不需要修改模型参数，并且只需要可忽略不计的额外计算。在多项选择和布尔问答任务上的实验结果表明，LENS以显著优势优于传统集成方法。我们的研究结果表明，内部表示为确定模型置信度提供了有价值的信号，并且可以有效地用于集成学习。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [803] [Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks](https://arxiv.org/abs/2507.23194)
> *Geak: 介绍Triton内核AI代理与评估基准*

*Jianghui Wang, Vinay Joshi, Saptarshi Majumder, Xu Chao, Bin Ding, Ziqiong Liu, Pratik Prabhanjan Brahma, Dong Li, Zicheng Liu, Emad Barsoum* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** GPU内核生成, Triton, AI代理, 大型语言模型, AMD GPU

**Comment:** 

> **TL;DR:** GEAK是一个利用LLM为AMD GPU生成高性能Triton内核的框架，并在评估中显著优于基线，显示出加速硬件采用和普及专家级性能的潜力。

**AI_Comments:** GEAK的创新之处在于其结合了LLM与Reflexion风格的反馈机制，专门针对GPU内核生成，特别是Triton语言和AMD硬件。其在正确性和执行速度上的显著提升，表明AI驱动的代码生成在自动化低级硬件优化方面具有巨大潜力，有望降低开发门槛并加速AI在多样化硬件上的部署。

<details>
  <summary>Details</summary>

**Motivation:** 对AI生成GPU内核的需求迅速增长，需要可扩展、硬件优化的解决方案。随着深度学习工作负载的复杂性增加，自动化低级内核开发以满足性能和生产力需求变得至关重要。业界正大力投资AI驱动的GPU代码生成，以减少手动优化工作并实现接近专家级的性能。

**Method:** 本文提出了一个用于Triton-based GPU内核的评估套件，并介绍了GEAK（生成高效AI中心GPU内核）框架。GEAK利用尖端大型语言模型（LLMs）生成针对AMD GPU（包括AMD MI300X和MI250）的高性能Triton代码。GEAK通过借鉴Reflexion风格反馈机制的推理循环，利用推理时计算扩展来生成Triton-based GPU内核。

**Result:** 在两个评估基准上，GEAK在正确性上高达63%，执行速度提升高达2.59倍，显著优于直接提示前沿LLM以及基于Reflexion的生成管道的基线。

**Conclusion:** GEAK类代理式代码生成在加速多样化硬件平台采用和普及专家级内核性能方面具有巨大潜力。

> **ai_Abstract:** 本文介绍了GEAK，一个利用尖端大型语言模型（LLMs）为AMD GPU（如MI300X和MI250）生成高性能Triton内核的框架。GEAK采用受Reflexion启发的推理循环。在评估基准测试中，GEAK在正确性上高达63%，执行速度提升高达2.59倍，显著优于直接提示LLM和基于Reflexion的基线。这表明GEAK类代理式代码生成在加速硬件平台采纳和普及专家级内核性能方面具有巨大潜力。

> **摘要翻译:** 对AI生成GPU内核的需求正在迅速增长，这受到工业界和学术界对可扩展、硬件优化解决方案的需求影响。随着深度学习工作负载的复杂性和多样性增加，自动化低级内核开发以满足性能和生产力需求变得至关重要。目前，主要的云提供商、半导体公司和研究机构正在大力投资AI驱动的GPU代码生成，旨在减少手动优化工作，同时在AMD MI300X等硬件上实现接近专家级的性能。Triton语言，一种基于Python的GPU编程DSL，因其在性能和编码简易性之间的平衡，已成为此类AI生成内核的流行目标。在这项工作中，我们提出了一个用于基于Triton的GPU内核的评估套件，以及GEAK（生成高效AI中心GPU内核）——一个利用尖端LLM专门为AMD GPU（包括AMD MI300X和MI250）生成高性能Triton代码的框架。GEAK利用推理时计算扩展，通过借鉴Reflexion风格反馈机制的推理循环来生成基于Triton的GPU内核。在两个评估基准上，GEAK显著优于直接提示前沿LLM以及基于Reflexion的生成管道的基线，实现了高达63%的正确性和高达2.59倍的执行速度提升。这些结果凸显了GEAK类代理式代码生成在加速多样化硬件平台采用和普及专家级内核性能方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [811] [Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation](https://arxiv.org/abs/2411.18337)
> *大型语言模型能否辅助消歧？对各种大型语言模型在词义消歧方面的定量评估*

*T. G. D. K. Sumanathilaka, Nicholas Micallef, Julian Hough* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 词义消歧, 提示工程, 思维链, 词汇歧义

**Comment:** 12 pages,6 tables, 1 figure, Proceedings of the 1st International
  Conference on NLP & AI for Cyber Security

> **TL;DR:** 本研究探讨了大型语言模型（LLMs）在词义消歧（WSD）中的应用，通过结合系统性提示增强机制和知识库，并引入人工参与的提示增强方法，显著提高了性能。

**AI_Comments:** 该论文的创新点在于结合了系统性提示增强机制与知识库，并引入了人工参与的提示增强，这为LLM在词义消歧任务中的应用提供了新思路。特别是利用少样本思维链（COT）提示，有效地提升了模型的性能，对于解决传统WSD方法数据受限的问题具有重要意义。该研究对于提升数字通信中的词汇理解准确性具有积极作用。

<details>
  <summary>Details</summary>

**Motivation:** 现代数字通信中普遍存在歧义词汇，传统词义消歧方法因数据限制而面临挑战，从而阻碍了翻译、信息检索和问答系统的效率。

**Method:** 该研究提出了一种新颖的方法，结合了系统性提示增强机制和包含不同词义解释的知识库。该方法融入了人工参与的提示增强，通过词性标注（POS）、歧义词的同义词、基于方面的情感过滤和少样本提示来指导LLM。利用少样本思维链（COT）提示方法。

**Result:** 通过利用少样本思维链（COT）提示方法，该工作展示了性能的显著提升。评估使用了FEWS测试数据和词义标签。

**Conclusion:** 本研究推动了社交媒体和数字通信中准确词汇解释的进展。

> **ai_Abstract:** 本研究旨在解决数字通信中词汇歧义对传统词义消歧（WSD）方法的挑战。论文提出了一种利用大型语言模型（LLMs）的新方法，该方法结合了系统性提示增强机制和知识库，并通过人工参与的词性标注、同义词、基于方面的情感过滤和少样本思维链（COT）提示来指导LLM。实验结果表明，该方法在WSD性能上取得了显著提升，有助于提高社交媒体和数字通信中词汇解释的准确性。

> **摘要翻译:** 歧义词在现代数字通信中普遍存在。由于数据有限，词汇歧义对传统词义消歧（WSD）方法构成了挑战。因此，翻译、信息检索和问答系统的效率受到这些限制的阻碍。本研究调查了使用大型语言模型（LLMs）通过一种新颖的方法来改进WSD，该方法结合了系统性提示增强机制和由不同词义解释组成的知识库（KB）。所提出的方法纳入了人工参与的提示增强方法，其中提示通过词性标注（POS）标记、歧义词的同义词、基于方面的情感过滤和少样本提示来支持和指导LLM。通过利用少样本思维链（COT）提示方法，这项工作展示了性能的显著提升。评估是使用FEWS测试数据和词义标签进行的。这项研究促进了社交媒体和数字通信中准确词汇解释的进步。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [814] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
> *多层注意力是示例有效性的放大器*

*Dingzirui Wang, Xuangliang Zhang, Keyan Xu, Qingfu Zhu, Wanxiang Che, Yang Deng* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 上下文学习, 示例有效性, 梯度流, 多层注意力, 示例选择

**Comment:** 

> **TL;DR:** 本文研究了上下文学习（ICL）中示例无效的原因，发现多层模型会放大示例间的有效性差异，并提出了一种基于梯度流的示例选择方法GradS，该方法显著提升了ICL性能。

**AI_Comments:** 本文的创新点在于从梯度流的角度深入分析了上下文学习中示例无效的原因，并揭示了多层模型中注意力机制对示例有效性差异的放大作用。提出的GradS方法基于此洞察，通过利用梯度流进行示例选择，提供了一种新颖且有效的解决方案，解决了现有方法忽视模型已学习信息的问题。这对于优化ICL的性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究普遍假设上下文学习（ICL）中提供的示例是有效的，但许多研究表明并非所有示例都有效，无法带来性能提升。因此，本文旨在探究示例无效的原因。

**Method:** 本文基于梯度流和线性自注意力模型进行分析。通过将梯度流设为零，推断出示例无效的原因是其信息已被模型学习或与用户查询无关。此外，提出了一种名为GradS的新方法，该方法利用梯度流的幅度作为选择示例的标准，以确保所选示例的有效性。

**Result:** 实验结果证实，随着模型层数的增加，示例之间的有效性差异会被放大，这验证了本文的推导。此外，GradS方法在四个主流大型语言模型和五个主流数据集上，相对于最强基线平均实现了6.8%的相对性能提升，证明了其有效性。

**Conclusion:** 本文的推导得到证实，即多层模型会放大示例有效性的差异。所提出的GradS方法通过利用梯度流进行示例选择，能够有效提升上下文学习的性能。

> **ai_Abstract:** 本文深入探究了上下文学习（ICL）中示例无效的原因，并发现多层模型中的注意力机制会放大有效示例和无效示例之间的差异。研究基于梯度流和线性自注意力模型分析了示例无效的条件，即信息已被学习或与查询无关。针对现有示例选择方法不足的问题，提出了一种名为GradS的新方法，该方法利用梯度流的幅度作为选择示例的标准，从而显著提升了ICL的性能。实验结果验证了理论推导，并证明了GradS的有效性。

> **摘要翻译:** 许多研究调查了上下文学习（ICL）有效性的潜在机制，以启发相关方法的设计。然而，现有工作主要假设ICL中提供的示例是有效的，而许多研究表明并非所有示例都有效，未能带来ICL期间的任何性能提升。因此，在本文中，我们调查了示例无效背后的原因。我们的分析基于梯度流和线性自注意力模型。通过将梯度流设为零，我们推断出如果示例的信息已被模型学习或与用户查询无关，则该示例将变得无效。此外，我们证明在多层模型中，示例之间的有效性差异随着层数的增加而被放大，导致模型更关注有效的示例。考虑到当前的示例选择方法主要关注与用户查询的相关性，而忽略了模型已经同化的信息，我们提出了一种名为GradS的新方法，该方法利用梯度流进行示例选择。我们使用示例相对于给定用户查询的梯度流大小作为标准，从而确保所选示例的有效性。我们在四个著名的大型语言模型和五个主流数据集上验证了我们的推导和GradS。实验结果证实，示例之间的有效性差异随着模型层数的增加而被放大，证实了我们的推导。此外，GradS相对于最强基线平均实现了6.8%的相对改进，证明了其有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [816] [A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms](https://arxiv.org/abs/2507.22912)
> *一种语言模型驱动的半监督集成框架，用于跨深/暗网和社交平台非法市场检测*

*Navid Yazdanjue, Morteza Rakhshaninejad, Hossein Yazdanjouei, Mohammad Sadegh Khorshidi, Mikko S. Niemela, Fang Chen, Amir H. Gandomi* | **Category: cs.CL, cs.AI, cs.LG, 68T07, 68T50** | **Updated: 2025-07-19**

**Keywords:** 非法市场检测, 语言模型, 半监督学习, 集成框架, 深度/暗网

**Comment:** 16 pages, 5 figures, 9 tables

> **TL;DR:** 本文提出了一种结合微调语言模型和半监督集成学习的分层分类框架，用于检测和分类深/暗网和社交平台上的非法市场内容，并在多个数据集上表现优于现有基线。

**AI_Comments:** 该论文的创新点在于结合了领域特定微调的语言模型（ModernBERT）与半监督集成学习策略，以应对非法市场内容检测中标记数据稀缺和语言模式复杂的问题。其分层分类方法和结合多源特征的策略增强了模型的鲁棒性和泛化能力，对于打击网络犯罪具有重要意义。在实际应用中，这种方法能有效识别和分类深/暗网及社交平台上的非法交易信息。

<details>
  <summary>Details</summary>

**Motivation:** 非法市场日益转向深/暗网和社交平台，使得匿名交易非法商品成为可能。由于标记数据有限、非法语言不断演变以及在线来源结构异构，检测和分类此类内容仍然具有挑战性。

**Method:** 本文提出一个分层分类框架，结合微调的语言模型（ModernBERT，针对领域特定数据微调）和半监督集成学习策略。该框架提取语义表示，并结合人工设计的特征（如文档结构、比特币地址、电子邮件、IP和元数据）。分类流程分两阶段：第一阶段使用XGBoost、Random Forest和SVM的半监督集成模型检测销售相关文档；第二阶段将这些文档进一步分类为毒品、武器或凭证销售。

**Result:** 在包括多源语料库、DUTA和CoDA在内的三个数据集上进行了实验，模型性能优于BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird等多个基线。模型实现了0.96489的准确率、0.93467的F1分数和0.95388的TMCC，表现出强大的泛化能力、有限监督下的鲁棒性以及在实际非法内容检测中的有效性。

**Conclusion:** 该模型在有限监督下表现出强大的泛化能力和鲁棒性，并且在实际非法内容检测中有效。

> **ai_Abstract:** 本文提出了一种基于语言模型驱动的半监督集成框架，用于检测和分类深/暗网和社交平台上的非法市场内容。该框架结合了针对领域数据微调的ModernBERT模型，提取语义表示，并辅以人工设计的结构和元数据特征。通过两阶段的分层分类流程，首先识别销售相关文档，然后进一步细分为具体非法商品类型。实验证明，该方法在多个数据集上显著优于现有基线，展现了在有限监督下对非法内容检测的有效性和鲁棒性。

> **摘要翻译:** 非法市场日益转向互联网的隐蔽部分，包括深网和暗网，以及Telegram、Reddit和Pastebin等平台。这些渠道使得包括毒品、武器和被盗凭证在内的非法商品能够匿名交易。由于标记数据有限、非法语言不断演变以及在线来源的结构异构性，检测和分类此类内容仍然具有挑战性。本文提出了一种分层分类框架，该框架结合了微调的语言模型和半监督集成学习策略，用于检测和分类跨不同平台的非法市场内容。我们使用ModernBERT提取语义表示，ModernBERT是一种用于长文档的Transformer模型，它在来自深网和暗网页面、Telegram频道、Subreddits和Pastebin帖子的领域特定数据上进行了微调，以捕获专业术语和模糊的语言模式。此外，我们还结合了人工设计的特征，如文档结构、嵌入模式（包括比特币地址、电子邮件和IP）以及元数据，这些特征补充了语言模型嵌入。分类管道分两个阶段运行。第一阶段使用XGBoost、Random Forest和SVM的半监督集成模型，采用基于熵的加权投票来检测销售相关文档。第二阶段将这些文档进一步分类为毒品、武器或凭证销售。在包括我们的多源语料库、DUTA和CoDA在内的三个数据集上进行的实验表明，我们的模型优于多个基线，包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird。该模型实现了0.96489的准确率、0.93467的F1分数和0.95388的TMCC，表现出强大的泛化能力、有限监督下的鲁棒性以及在实际非法内容检测中的有效性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [822] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
> *ReaGAN：节点即智能体推理图智能网络*

*Minghao Guo, Xi Zhu, Jingyuan Huang, Kai Mei, Yongfeng Zhang* | **Category: cs.CL, cs.LG, cs.MA** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 智能体系统, 检索增强生成, 节点决策, 少样本学习

**Comment:** 17 pages, work in progress

> **TL;DR:** ReaGAN是一个基于智能体的图神经网络框架，通过赋予每个节点自主决策能力，并结合检索增强生成，解决了传统GNN在节点信息不平衡和全局语义关系捕获上的局限性。

**AI_Comments:** ReaGAN的创新之处在于将图中的每个节点视为一个独立的智能体，赋予其自主决策和规划能力，这打破了传统GNN固定消息传递的限制。结合检索增强生成（RAG）机制，使得节点能够获取全局语义信息，有效解决了信息不平衡和远距离依赖问题。这种将LLM的“智能体”范式引入图学习，特别是在无需微调LLM的情况下展现出强大性能，预示着图学习领域的新方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的图神经网络（GNNs）在信息传播中存在两个主要限制：一是无法处理节点信息量的不平衡问题（有些节点信息丰富，有些则稀疏）；二是预定义的消息传递机制主要利用局部结构相似性，而忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。

**Method:** ReaGAN（Retrieval-augmented Graph Agentic Network）是一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为一个智能体，根据其内部记忆独立规划下一步行动，实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容，并在图中建立全局关系。

**Result:** ReaGAN在少样本上下文设置下，使用冻结的LLM骨干网络（无需微调）取得了具有竞争力的性能。

**Conclusion:** ReaGAN通过智能体规划和局部-全局检索机制，有效解决了传统GNN在处理节点信息不平衡和捕获全局语义关系方面的挑战，展现了其在图学习领域的潜力。

> **ai_Abstract:** ReaGAN是一种新型的图神经网络框架，通过将每个节点视为一个具有自主决策能力的智能体，并结合检索增强生成（RAG）机制，克服了传统GNN在处理节点信息不平衡和捕获全局语义关系方面的局限性。该模型允许节点独立规划行动并访问全局语义内容，在少样本设置下无需微调冻结的LLM骨干网络即可达到竞争性能，展示了其在图学习中的巨大潜力。

> **摘要翻译:** 图神经网络（GNNs）通过预定义的聚合机制在邻居节点之间传播信息，在基于图的学习中取得了显著成功。然而，这种固定的方案常常面临两个关键限制。首先，它们无法处理节点信息丰富度不平衡的问题——有些节点信息丰富，而另一些则稀疏。其次，预定义的消息传递主要利用局部结构相似性，而忽略了图中的全局语义关系，限制了模型捕获远距离但相关信息的能力。我们提出了检索增强图智能网络（ReaGAN），这是一个基于智能体的框架，赋予每个节点自主的节点级决策能力。每个节点作为一个智能体，根据其内部记忆独立规划其下一步行动，从而实现节点级规划和自适应消息传播。此外，检索增强生成（RAG）允许节点访问语义相关内容并在图中建立全局关系。ReaGAN在少样本上下文设置下，使用冻结的LLM骨干网络（无需微调）取得了具有竞争力的性能，展示了智能体规划和局部-全局检索在图学习中的潜力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [836] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
> *PaPaformer：来自预训练并行路径的语言模型*

*Joonas Tapaninaho, Mourad Oussala* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** PaPaformer, 语言模型, Transformer, 并行路径, 训练效率

**Comment:** 

> **TL;DR:** PaPaformer通过训练并组合低维并行路径，显著减少大型语言模型的训练时间和计算资源，同时提高性能并支持任务定制。

**AI_Comments:** PaPaformer的创新之处在于其并行路径的架构设计，允许独立训练低维路径并进行组合，这有望显著降低大型语言模型的训练成本和时间。此外，这种模块化的设计为模型定制和适应不同任务需求提供了新的思路，具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代大型语言模型（LLMs）和小型语言模型（SLMs）的训练需要大量的计算资源和时间，通常需要数天甚至数周，并且依赖多GPU。

**Method:** 本文提出了PaPaformer，一种解码器专用的Transformer架构变体。该架构将低维并行路径组合成一个更大的模型，并且这些低维路径可以分别用不同类型的数据独立训练，然后合并成一个整体模型。

**Result:** 该方法能够显著减少模型的总参数数量和训练时间，同时提高性能。

**Conclusion:** PaPaformer的并行路径结构不仅能显著缩短语言模型的训练时间并提高效率，还为根据特定任务需求定制模型路径提供了新的可能性。

> **ai_Abstract:** 本文提出PaPaformer，一种新型解码器专用Transformer架构，旨在解决大型语言模型训练耗时耗力的问题。PaPaformer通过将多个可独立训练的低维并行路径组合成一个更大的模型，实现了在数小时内而非数天/数周内完成训练。该方法不仅能减少模型参数和训练时间，同时提升性能，并且其并行路径结构为根据特定任务需求进行定制提供了灵活性。

> **摘要翻译:** 现代大型语言模型的训练需要越来越多的计算能力和时间。即使是较小的变体，例如小型语言模型（SLMs），在最佳情况下也需要几天时间进行训练，并且通常需要多个GPU。本文探讨了在数小时而非数天/数周内训练和评估仅解码器Transformer语言模型的方法。我们引入了PaPaformer，一种仅解码器Transformer架构变体，其低维并行路径组合成一个更大的模型。本文表明，这些低维路径可以分别用不同类型的训练数据进行独立训练，然后组合成一个更大的模型。这种方法可以选择在提高性能的同时减少模型参数总数和训练时间。此外，使用并行路径结构为定制路径以适应特定任务要求开辟了有趣的可能性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [837] [A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models](https://arxiv.org/abs/2507.22913)
> *一种主题分析的混合框架：整合基于嵌入的回归模型与大型语言模型*

*Jinyu Liu, Xiaoying Song, Diana Zhang, Jason Thomale, Daqing He, Lingzi Hong* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-19**

**Keywords:** 主题分析, 混合框架, 大型语言模型, 机器学习, LCSH

**Comment:** 13 pages, 2 figures, accepted by ASIST 2025

> **TL;DR:** 本文提出了一种混合框架，结合机器学习模型和大型语言模型进行主题分析，以提高准确性并减少幻觉。

**AI_Comments:** 该论文的创新之处在于其混合框架设计，巧妙地结合了传统机器学习模型的精确性和大型语言模型的生成能力。通过使用ML模型进行预测引导和后编辑，有效解决了LLM在主题分析中常见的过度生成和幻觉问题，使得LLM的输出更加受控和符合既定词汇表，这对于图书馆信息管理系统等对准确性和一致性要求高的领域具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 为信息资源提供主题访问是图书馆管理系统的重要功能。大型语言模型（LLMs）在分类和摘要任务中应用广泛，但其进行主题分析的能力尚未充分探索，且存在过度生成和幻觉的问题。传统机器学习模型在主题分析中用于多标签分类，但难以处理未见情况。

**Method:** 本文提出一个混合框架，整合了基于嵌入的机器学习（ML）模型与大型语言模型（LLMs）。该方法使用ML模型来：1) 预测最佳的国会图书馆主题词（LCSH）标签数量以指导LLM预测；2) 使用实际LCSH词汇对预测术语进行后编辑，以减轻幻觉。实验使用LCSH预测书籍主题词。

**Result:** 实验结果表明，提供初始预测来指导LLM生成以及进行后编辑，能够产生更受控且与词汇表对齐的输出。

**Conclusion:** 所提出的混合框架通过引导LLM的生成和进行后编辑，有效提高了主题分析的准确性和与词汇表的对齐度。

> **ai_Abstract:** 本文提出了一种用于主题分析的混合框架，结合了基于嵌入的机器学习（ML）模型与大型语言模型（LLMs）。该框架旨在解决LLMs在主题分析中过度生成和幻觉的问题，以及传统ML模型处理未见情况的不足。其中，ML模型负责预测最佳主题词数量以指导LLM，并对LLM的输出进行后编辑以确保与国会图书馆主题词（LCSH）的对齐。实验结果表明，该混合方法能够生成更受控且与词汇表一致的主题预测。

> **摘要翻译:** 为信息资源提供主题访问是任何图书馆管理系统的基本功能。大型语言模型（LLMs）已广泛用于分类和摘要任务，但其执行主题分析的能力尚未充分探索。传统机器学习（ML）模型的多标签分类已用于主题分析，但难以处理未见情况。LLMs 提供了一种替代方案，但常常过度生成和产生幻觉。因此，我们提出了一种混合框架，整合了基于嵌入的ML模型与LLMs。这种方法使用ML模型来（1）预测最佳的LCSH标签数量以指导LLM预测，以及（2）使用实际LCSH词汇对预测的术语进行后编辑，以减轻幻觉。我们使用LLMs和混合框架进行了实验，以使用国会图书馆主题词（LCSH）预测书籍的主题词。实验结果表明，提供初始预测以指导LLM生成并施加后编辑，能够产生更受控且与词汇表对齐的输出。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [845] [Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples](https://arxiv.org/abs/2507.23211)
> *失败是成功之母：通过利用负样本增强少样本上下文学习*

*Yunhao Liang, Ruixuan Ying, Takuya Taniguchi, Zhe Cui* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 少样本学习, 上下文学习, 负样本, 大语言模型, 示例选择

**Comment:** 

> **TL;DR:** 本文提出一种利用负样本信息来更好地选择正样本，从而提升大语言模型少样本上下文学习性能的方法。

**AI_Comments:** 该论文的创新点在于首次系统地利用负样本来优化少样本上下文学习中的正样本选择，这为ICL的示例选择策略提供了新的视角。通过引入负样本的对比信息，模型能够更精确地识别出有益的正样本，从而有效提升了ICL的性能。这一方法对于提高大语言模型在低资源场景下的应用效果具有重要意义，并可能启发未来在其他机器学习任务中利用“失败”或“负面”信息的新思路。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLM）的少样本上下文学习（ICL）性能对提供的示例高度敏感。现有研究主要侧重于利用正样本，而忽略了负样本中包含的额外信息，这限制了ICL的性能提升。

**Method:** 该方法首先基于Zero-Shot-Cot构建正样本和负样本语料库。推理时，对于给定查询，通过语义相似度从正样本和负样本语料库中选择最相似的示例。随后，根据负样本与正样本语料库中正样本的语义相似度，进一步检索正样本，并将其与之前选择的正样本拼接作为ICL的演示。

**Result:** 实验结果表明，该方法优于仅依赖最相似正样本进行上下文学习的方法。

**Conclusion:** 负样本中的额外信息有助于通过改进正样本选择来提升少样本上下文学习（ICL）的性能。

> **ai_Abstract:** 本文提出了一种新颖的少样本上下文学习（ICL）增强方法，通过利用负样本来优化正样本的选择。现有ICL研究主要关注正样本，忽略了负样本的潜在价值。该方法首先构建正负样本语料库，然后在推理时，结合语义相似度从正负样本中筛选示例，并进一步利用负样本信息检索额外的正样本作为ICL演示。实验证明，该方法在ICL性能上优于仅使用最相似正样本的方法，证实了负样本在改进正样本选择方面的重要性。

> **摘要翻译:** 大型语言模型展现出强大的少样本上下文学习（ICL）能力，但其性能对所提供的示例高度敏感。最近的研究主要集中于为每个输入查询检索相应的示例，这不仅提高了学习过程的效率和可扩展性，还减轻了手动示例选择中固有的偏差。然而，这些研究主要强调利用正样本，而忽视了负样本中用于上下文学习的额外信息。
我们提出了一种新颖的方法，该方法利用负样本更好地选择正样本示例，从而增强少样本ICL的性能。首先，我们基于Zero-Shot-Cot构建正负样本语料库。然后，在推理过程中，我们采用基于语义相似度的方法，为给定查询从正负样本语料库中选择最相似的示例。随后，我们根据负样本与正样本语料库中正样本的语义相似度，进一步检索正样本，然后将它们与之前选择的正样本拼接起来作为ICL演示。实验结果表明，我们的方法超越了仅依赖最相似正样本进行上下文学习的方法，验证了负样本中的额外信息通过改进正样本选择有助于增强ICL性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [853] [Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette](https://arxiv.org/abs/2412.11167)
> *文化调色板：通过多智能体调色板实现文化对齐的多元化*

*Jiahao Yuan, Zixiang Di, Shangzixin Zhao, Zhiqing Cui, Hanqing Wang, Guisong Yang, Usman Naseem* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 文化调色板, 多智能体, 文化对齐, 大型语言模型, 文化地理

**Comment:** 20 pages, 10 figures

> **TL;DR:** 本文提出了“文化调色板”多智能体框架，将文化对齐视为自适应的“色彩混合”过程，旨在解决大型语言模型在多元文化对齐中的挑战。

**AI_Comments:** 这篇论文通过引入“文化调色板”多智能体框架，提出了一种新颖的、将文化对齐视为“色彩混合”的自适应方法，解决了大型语言模型在处理多元文化细微差别方面的固有挑战。其创新点在于结合了文化地理学、构建了专门的数据集以及设计了分层的多智能体协作机制（包括洲级代理和元代理的动态融合），以实现更精细和灵活的文化适应性，这对于提升LLM的全球适用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）尽管在生成方面表现出色，但由于固有的单一文化偏见和难以捕捉细微的文化语义，在与多样文化价值观对齐方面面临挑战。现有方法在微调后难以适应未知文化。

**Method:** 论文提出了“文化调色板”（Cultural Palette）多智能体框架，将文化对齐重新定义为国家特定的自适应“色彩混合”过程。该方法利用五大洲的文化地理，包含三个关键步骤：首先，使用GPT-4o合成“五色文化调色板数据集”，并结合霍夫斯泰德文化维度细化洲际对话，建立基础文化表示。其次，五个洲级对齐智能体形成专业文化社区，生成区域特定的草稿回复。第三，一个元智能体利用“文化合并”（Cultural MoErges）通过注意力门控参数合并，动态混合这些文化“色彩”，解决冲突同时保留文化细微差别，以生成最终的文化对齐响应。

**Result:** 在不同国家进行的广泛实验表明，“文化调色板”在文化对齐方面超越了现有基线。

**Conclusion:** “文化调色板”框架通过其多智能体和自适应“色彩混合”方法，有效解决了大型语言模型在多元文化对齐中的挑战，并在实验中表现出优越的性能。

> **ai_Abstract:** 本文提出了“文化调色板”框架，旨在解决大型语言模型在多元文化对齐中的挑战。该框架将文化对齐视为一种自适应的“色彩混合”过程，通过构建“五色文化调色板数据集”、利用洲级对齐智能体生成区域草稿，并由元智能体通过注意力门控参数合并动态混合文化“色彩”，最终生成文化对齐的响应。实验结果表明，该方法在文化对齐方面优于现有基线。

> **摘要翻译:** 大型语言模型（LLMs）尽管在生成方面表现出色，但由于固有的单一文化偏见和难以捕捉细微的文化语义，在与多样文化价值观对齐方面面临挑战。现有方法在微调后难以适应未知文化。受五大洲文化地理的启发，我们提出了“文化调色板”（Cultural Palette），一个多智能体框架，它将文化对齐重新定义为针对特定国家的自适应“色彩混合”过程。我们的方法利用五大洲（非洲、美洲、亚洲、欧洲、大洋洲）的文化地理，通过三个关键步骤实现：首先，我们使用GPT-4o合成“五色文化调色板数据集”，并结合霍夫斯泰德文化维度细化洲际对话，以建立基础文化表示。其次，五个洲级对齐智能体形成专业文化社区，生成区域特定的草稿回复。第三，一个元智能体利用“文化合并”（Cultural MoErges）通过注意力门控参数合并，动态混合这些文化“色彩”，类似于在调色板上混合颜料，在解决冲突的同时保留文化细微差别，以生成最终的文化对齐响应。在不同国家进行的广泛实验表明，“文化调色板”在文化对齐方面超越了现有基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [857] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
> *大型语言模型中用于置信度估计的上下文感知双度量框架*

*Mingruo Yuan, Shuyi Zhang, Ben Kao* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 置信度估计, 上下文感知, CRUX, 不确定性量化

**Comment:** 

> **TL;DR:** CRUX是一个上下文感知的双度量框架，通过结合上下文忠实度和一致性来提高LLM的置信度估计，并在多个数据集上表现优异。

**AI_Comments:** CRUX的创新点在于首次将上下文忠实度和一致性整合到LLM的置信度估计中，并通过双度量方法全面捕捉数据和模型的潜在不确定性。这对于提升LLM在实际应用中的可靠性和透明度具有重要意义，尤其是在需要高可信度的场景。

<details>
  <summary>Details</summary>

**Motivation:** 准确的置信度估计对于可信赖的大型语言模型（LLM）系统和安全关键应用至关重要。然而，现有LLM置信度估计方法忽略了响应与上下文信息之间的相关性，而这在提供背景知识时对输出质量评估至关重要。

**Method:** 本文提出了CRUX（Context-aware entropy Reduction and Unified consistency eXamination）框架，这是第一个将上下文忠实度和一致性整合到置信度估计中的框架。它通过两个新颖的度量实现：1. 上下文熵减少：通过有无上下文的对比采样，表示数据不确定性（信息增益）。2. 统一一致性检查：通过有无上下文生成的答案的全局一致性，捕捉潜在的模型不确定性。

**Result:** 实验在三个基准数据集（CoQA、SQuAD、QuAC）和两个领域特定数据集（BioASQ、EduQG）上进行，结果表明CRUX有效，并取得了比现有基线最高的AUROC。

**Conclusion:** CRUX框架通过引入上下文感知和双度量方法，显著提高了大型语言模型的置信度估计能力，使其在实际应用中更加可靠和可信赖。

> **ai_Abstract:** 本文提出了CRUX，一个用于大型语言模型置信度估计的上下文感知双度量框架。针对现有方法忽略上下文相关性的问题，CRUX通过上下文熵减少和统一一致性检查这两个新颖度量，分别衡量数据不确定性和模型不确定性。实验证明CRUX在多个问答数据集上优于现有基线，提高了LLM输出的可信度。

> **摘要翻译:** 准确的置信度估计对于值得信赖的大型语言模型（LLM）系统至关重要，因为它使用户能够确定何时信任输出，并实现在安全关键应用中的可靠部署。当前LLM的置信度估计方法忽略了响应与上下文信息之间的相关性，这是输出质量评估中的一个关键因素，尤其是在提供了背景知识的场景中。为了弥补这一差距，我们提出了CRUX（Context-aware entropy Reduction and Unified consistency eXamination），这是第一个通过两个新颖度量整合上下文忠实度和一致性进行置信度估计的框架。首先，上下文熵减少通过有无上下文的对比采样来表示数据不确定性（信息增益）。其次，统一一致性检查通过有无上下文生成的答案的全局一致性来捕捉潜在的模型不确定性。在三个基准数据集（CoQA、SQuAD、QuAC）和两个领域特定数据集（BioASQ、EduQG）上的实验表明，CRUX的有效性，其AUROC高于现有基线。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [858] [Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs](https://arxiv.org/abs/2507.22914)
> *全三元组匹配器：集成异构知识图谱间的所有三元组元素*

*Victor Eiti Yamamoto, Hideaki Takeda* | **Category: cs.CL** | **Updated: 2025-07-20**

**Keywords:** 知识图谱集成, 上下文匹配, 三元组匹配, 实体匹配, 异构知识图谱

**Comment:** 

> **TL;DR:** 本文提出了一种名为“全三元组匹配器”的新型知识图谱集成方法，通过结合标签匹配和三元组匹配来解决异构知识图谱中上下文匹配的挑战，并在实体匹配方面取得了有竞争力的性能。

**AI_Comments:** 该论文的创新之处在于其专注于解决知识图谱集成中长期被忽视的上下文匹配问题，并提出了结合标签匹配和三元组匹配的独特方法。通过利用三元组层面的信息来改进实体匹配，该方法为异构知识图谱的集成提供了一个更全面和鲁棒的解决方案。引入新的数据集也为未来的三元组匹配研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识图谱集成方法在模式和身份匹配方面已成熟，但对上下文匹配的探索不足。由于真实世界知识图谱在来源、大小和信息密度上差异显著，当前实体匹配方法在处理多样化和复杂上下文时表现不佳，因此需要新的方法来弥补这一空白。

**Method:** 提出了一种新颖的知识图谱集成方法，包括标签匹配和三元组匹配。标签匹配使用字符串操作、模糊匹配和向量相似性技术来对齐实体和谓词标签。三元组匹配识别传达可比信息的三元组之间的映射，并利用这些映射来提高实体匹配精度。此外，还引入了一个新的数据集来更全面地评估三元组匹配步骤。

**Result:** 该方法在OAEI竞赛中与领先系统相比表现出有竞争力的性能，并与监督方法相比，在多样化测试案例中实现了高精度。

**Conclusion:** 通过整合标签匹配和三元组匹配，该方法有效地解决了异构知识图谱中的上下文匹配挑战，并在实体匹配方面取得了显著的改进和竞争力，同时为三元组匹配评估提供了新的数据集。

> **ai_Abstract:** 本文提出了一种名为“全三元组匹配器”的新型知识图谱集成方法，旨在解决异构知识图谱中未被充分探索的上下文匹配问题。该方法结合了标签匹配（使用字符串操作、模糊匹配和向量相似性）和三元组匹配，通过识别和利用可比三元组的映射来提高实体匹配精度。实验结果表明，该方法在实体匹配方面表现出与现有领先系统和监督方法相当或更优的竞争力，并在多样化测试案例中实现了高精度。此外，研究还引入了一个新的数据集，用于更全面地评估三元组匹配步骤。

> **摘要翻译:** 知识图谱（KGs）是表示和推理结构化信息的强大工具。它们的主要组成部分包括模式、身份和上下文。虽然模式和身份匹配在本体和实体匹配研究中已得到充分建立，但上下文匹配在很大程度上仍未被探索。这一点尤为重要，因为现实世界的知识图谱在来源、大小和信息密度方面往往差异显著——这些因素通常未在当前实体匹配方法所评估的数据集中体现。因此，现有方法在需要集成多样化和复杂上下文的场景中可能会力不从心。
为了解决这一空白，我们提出了一种新颖的知识图谱集成方法，包括标签匹配和三元组匹配。我们使用字符串操作、模糊匹配和向量相似性技术来对齐实体和谓词标签。接下来，我们识别传达可比信息的三元组之间的映射，并利用这些映射来提高实体匹配精度。我们的方法与OAEI竞赛中的领先系统以及监督方法相比，表现出有竞争力的性能，并在多样化测试案例中实现了高精度。此外，我们引入了一个从基准数据集中衍生出的新数据集，以更全面地评估三元组匹配步骤。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [873] [Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders](https://arxiv.org/abs/2507.23220)
> *建模方向，而非词语：使用稀疏自编码器的机械化主题模型*

*Carolina Zheng, Nicolas Beltran-Velez, Sweta Karlekar, Claudia Shi, Achille Nazaret, Asif Mallik, Amir Feder, David M. Blei* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 主题模型, 稀疏自编码器, 文本生成, 语义特征, LLM评估

**Comment:** 

> **TL;DR:** 本文介绍了机械化主题模型（MTMs），它利用稀疏自编码器（SAEs）学习的可解释特征来克服传统主题模型在语义抽象和复杂主题表达上的限制，并能实现可控的文本生成，在多项评估中表现优于现有基线。

**AI_Comments:** 这项工作通过将主题建模与稀疏自编码器结合，提供了一种新颖的、更具语义深度的方法来理解文本数据。其创新之处在于超越了传统的词袋表示和词列表主题，允许模型在更抽象的特征空间中操作。此外，能够实现可控文本生成是其显著的优势，为下游应用提供了新的可能性。引入“topic judge”作为LLM辅助的评估框架，也为主题模型的评估提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 传统主题模型依赖词袋表示或将主题表达为词列表，难以捕捉语义抽象特征和表达复杂主题。

**Method:** 引入了机械化主题模型（MTMs），该模型在稀疏自编码器（SAEs）学习到的可解释特征上运行。此外，提出了一个基于LLM的成对比较评估框架“topic judge”来评估MTM主题。

**Result:** 在五个数据集上，MTMs在一致性指标上匹配或超过传统和神经基线，始终被“topic judge”偏好，并能够有效引导LLM输出。

**Conclusion:** 机械化主题模型（MTMs）通过利用稀疏自编码器学习的语义丰富的特征，克服了传统主题模型在捕捉深层概念主题上的限制，并独特地实现了基于主题的文本生成控制，在多个评估中表现出色。

> **ai_Abstract:** 本文提出了机械化主题模型（MTMs），旨在克服传统主题模型在捕捉语义抽象特征和表达复杂主题上的局限性。MTMs利用稀疏自编码器（SAEs）学习到的可解释且语义丰富的特征来定义主题，从而能够揭示更深层次的概念主题并提供更具表达性的特征描述。此外，MTMs独特地支持使用主题引导向量进行可控文本生成。为评估MTMs，文章提出了一个基于LLM的成对比较框架“topic judge”。实验结果表明，在五个数据集上，MTMs在一致性指标上表现与现有基线相当或更优，并持续获得“topic judge”的偏好，同时能有效引导大型语言模型（LLM）的输出。

> **摘要翻译:** 传统主题模型在揭示大型文本集合中的潜在主题方面是有效的。然而，由于它们依赖词袋表示，它们难以捕捉语义抽象特征。虽然一些神经变体使用更丰富的表示，但它们同样受到将主题表达为词列表的限制，这限制了它们阐明复杂主题的能力。我们引入了机械化主题模型（MTMs），这是一类在稀疏自编码器（SAEs）学习到的可解释特征上运行的主题模型。通过在这个语义丰富的空间中定义主题，MTMs可以揭示具有表达性特征描述的更深层次的概念主题。此外，在主题模型中独一无二的是，MTMs能够使用基于主题的引导向量实现可控的文本生成。为了正确评估MTM主题与基于词列表的方法，我们提出了“topic judge”，一个基于LLM的成对比较评估框架。在五个数据集上，MTMs在一致性指标上匹配或超过传统和神经基线，始终被“topic judge”偏好，并能够有效引导LLM输出。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [874] [RAVine: Reality-Aligned Evaluation for Agentic Search](https://arxiv.org/abs/2507.16725)
> *RAVine：面向智能体搜索的现实对齐评估*

*Yilong Xu, Xiang Long, Zhi Zheng, Jinhua Gao* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 智能体搜索, 评估框架, RAVine, LLM, 检索增强

**Comment:** 

> **TL;DR:** RAVine是一个新的评估框架，用于解决现有智能体搜索评估中复杂查询不真实、真值提取有噪声以及忽视迭代过程评估的问题。

**AI_Comments:** RAVine的创新之处在于它全面解决了现有智能体搜索评估的多个痛点，特别是强调了现实对齐、细粒度真值归因以及对迭代过程的关注，这对于理解和改进智能体搜索的复杂行为至关重要。其提出的评估范式有望推动该领域研究的深入发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估框架未能很好地与智能体搜索的目标对齐。具体存在三个问题：1) 当前基准中常用的复杂查询偏离了真实用户搜索场景；2) 先前方法在提取端到端评估的真值时引入噪声，导致细粒度评估失真；3) 大多数当前框架只关注最终答案的质量，忽视了智能体搜索固有的迭代过程评估。

**Method:** 我们提出了RAVine，一个面向智能体LLM的现实对齐评估框架。RAVine针对更好地反映用户意图的多点查询和长篇答案，并引入了一种可归因的真值构建策略，以提高细粒度评估的准确性。此外，RAVine检查模型在迭代过程中与搜索工具的交互，并考虑效率因素。

**Result:** 我们使用RAVine对一系列模型进行了基准测试，并得出了一些见解。

**Conclusion:** RAVine旨在解决现有智能体搜索评估的局限性，通过更真实的查询、更准确的真值构建和对迭代过程的评估，为智能体搜索系统的发展做出贡献。

> **ai_Abstract:** 本论文提出了RAVine，一个用于评估智能体LLM搜索能力的现实对齐框架。该框架旨在解决现有评估方法中查询不真实、真值提取有噪声以及忽视迭代过程评估的局限性。RAVine通过支持多点查询和长篇答案、引入可归因的真值构建策略，并评估模型与搜索工具的迭代交互及效率，从而提供更准确和全面的评估。研究人员使用RAVine对多种模型进行了基准测试，并获得了有助于智能体搜索系统发展的见解。

> **摘要翻译:** 智能体搜索作为一种更自主、更具适应性的检索增强范式，正在推动智能搜索系统的演进。然而，现有评估框架未能很好地与智能体搜索的目标对齐。首先，当前基准中常用的复杂查询往往偏离了真实的用户搜索场景。其次，先前的方法在提取端到端评估的真值时往往引入噪声，导致细粒度评估失真。第三，大多数当前框架只关注最终答案的质量，而忽视了对智能体搜索固有的迭代过程的评估。为了解决这些局限性，我们提出了RAVine——一个用于智能体LLM（大语言模型）的现实对齐评估框架。RAVine针对更好地反映用户意图的多点查询和长篇答案，并引入了一种可归因的真值构建策略，以提高细粒度评估的准确性。此外，RAVine检查模型在迭代过程中与搜索工具的交互，并考虑效率因素。我们使用RAVine对一系列模型进行了基准测试，并得出了一些见解，我们希望这些见解将有助于推动智能体搜索系统的发展。代码和数据集可在https://github.com/SwordFaith/RAVine获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [878] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
> *DACTYL：从大型语言模型生成的多种对抗性文本语料库*

*Shantanu Thorat, Andrew Caines* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** AI生成文本检测, DACTYL, 单样本生成, 深度X风险优化, 分布外检测

**Comment:** MPhil in Advanced Computer Science thesis for University of Cambridge

> **TL;DR:** 该研究引入了DACTYL，一个针对单次/少次生成和领域特定文本的AIG文本检测新数据集，并发现现有检测器在此数据集上表现不佳。同时，研究表明深度X风险优化（DXO）训练的分类器在分布外（OOD）文本检测方面优于标准二元交叉熵（BCE）训练的分类器，泛化能力更强。

**AI_Comments:** DACTYL数据集的引入对于AI生成文本检测领域具有重要意义，因为它填补了少样本/单样本生成和领域特定CPT文本检测的空白，这些是现有数据集较少关注的。研究结果揭示了当前检测器的局限性，并强调了泛化能力的重要性。DXO优化方法在OOD文本上的优越表现，特别是其在模拟学生论文检测场景中的显著提升，表明了其在实际应用中的巨大潜力，为构建更鲁棒的AI文本检测系统提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI生成文本检测器在实际应用中表现不佳，尽管在内部测试中成功，这表明它们可能不够鲁棒。大多数当前的AI生成文本检测数据集侧重于零样本生成，而对模型以人类文本作为示例的少样本或单样本生成的研究较少。

**Method:** 研究引入了DACTYL数据集，这是一个具有挑战性的AI生成文本检测数据集，专注于单样本/少样本生成，并包含来自领域特定持续预训练（CPT）语言模型的文本。研究还使用标准二元交叉熵（BCE）优化和深度X风险优化（DXO）两种方法训练了自己的分类器。

**Result:** 现有AI生成文本检测器在DACTYL数据集上表现显著不佳，表明它们对单样本/少样本和CPT生成的文本存在潜在漏洞。BCE训练的分类器在DACTYL测试集上略优于DXO分类器，但DXO分类器在分布外（OOD）文本上表现出色。在模拟学生论文检测场景中，最佳DXO分类器在最低误报率下，宏观F1分数比最佳BCE训练分类器高出50.56分。

**Conclusion:** DXO分类器具有更好的泛化能力，没有过度拟合测试集。实验结果突出了AI生成文本检测器需要改进的几个方面。

> **ai_Abstract:** 该论文介绍了DACTYL，一个用于AI生成文本检测的新型对抗性语料库，专注于大型语言模型的单样本/少样本生成和领域特定持续预训练文本。研究发现，现有检测器在此挑战性数据集上表现不佳，揭示了其对新生成范式的脆弱性。此外，通过比较标准BCE和深度X风险优化（DXO）训练的分类器，论文指出DXO在分布外文本检测上表现出显著优势，泛化能力更强，为AI生成文本检测的未来发展提供了改进方向。

> **摘要翻译:** 现有的AI生成（AIG）文本检测器尽管在内部测试中取得成功，但在实际应用中却表现不力，这表明它们可能不够鲁棒。为了解决这个问题，我们严格审查了构建这些检测器的机器学习过程。目前大多数AIG文本检测数据集都侧重于零样本生成，但很少有关于少样本或单样本生成的研究，即大型语言模型（LLMs）以人类文本作为示例进行生成。为此，我们引入了DACTYL（从语言模型生成的多种对抗性文本语料库），这是一个具有挑战性的AIG文本检测数据集，专注于单样本/少样本生成。我们还纳入了来自领域特定持续预训练（CPT）语言模型的文本，我们使用内存高效的优化方法完全训练了所有参数。许多现有的AIG文本检测器在我们的数据集上表现显著不佳，这表明它们对单样本/少样本和CPT生成的文本存在潜在漏洞。我们还使用两种方法训练了自己的分类器：标准二元交叉熵（BCE）优化和一种更新的方法，深度X风险优化（DXO）。虽然BCE训练的分类器在DACTYL测试集上略优于DXO分类器，但后者在分布外（OOD）文本上表现出色。在我们模拟的学生论文检测部署场景中，使用OOD学生论文数据集，在两种分类器最低误报率下，最佳DXO分类器比最佳BCE训练分类器在宏观F1分数上高出50.56分。我们的结果表明DXO分类器泛化能力更好，没有过度拟合测试集。我们的实验突出了AIG文本检测器需要改进的几个方面。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [879] [Theoretical Foundations and Mitigation of Hallucination in Large Language Models](https://arxiv.org/abs/2507.22915)
> *大型语言模型幻觉的理论基础与缓解*

*Esmail Gumaan* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-20**

**Keywords:** 大型语言模型, 幻觉, 理论基础, 缓解策略, 风险评估

**Comment:** 12 pages

> **TL;DR:** 本文深入探讨了大型语言模型中的幻觉问题，包括正式定义、理论分析、风险界定、检测策略、缓解方法以及评估协议，旨在为解决幻觉提供理论基础和实践指导。

**AI_Comments:** 本文对大型语言模型中的幻觉问题进行了系统性的理论和实践探索，其创新之处在于首次对幻觉进行了形式化定义和风险量化，并通过学习理论框架提供了理论保障。提出的统一检测和缓解工作流程具有重要的实践指导意义，为后续研究和应用提供了清晰的路径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型 (LLMs) 中生成与输入或事实不符的内容（即幻觉）是一个关键挑战。本文旨在对LLMs中的幻觉进行严格处理，提供理论基础和实践指导。

**Method:** 本文对幻觉进行了正式定义和理论分析，区分了内禀和外禀幻觉，并定义了“幻觉风险”，使用PAC-Bayes和Rademacher复杂度等学习理论框架推导出风险界限。文中还调查了幻觉检测策略（如token级不确定性估计、置信度校准、注意力对齐检查）和缓解方法（如检索增强生成、幻觉感知微调、logits校准、事实验证模块集成）。此外，提出了一种统一的检测和缓解工作流程，并概述了幻觉的评估协议。

**Result:** 本文推导了幻觉风险的界限，提出了一个统一的检测和缓解幻觉的工作流程，并推荐了评估幻觉的数据集、度量标准和实验设置。

**Conclusion:** 本文为解决大型语言模型中的幻觉这一关键挑战奠定了理论基础，并提供了实用的指导方针。

> **ai_Abstract:** 本文深入探讨了大型语言模型中的幻觉问题，提供了其正式定义和理论分析，并区分了内禀和外禀幻觉。研究推导了幻觉风险的理论界限，并全面综述了多种幻觉检测和缓解策略。此外，论文提出了一种统一的检测与缓解工作流程，并给出了幻觉评估的协议建议，旨在为解决LLMs幻觉问题提供全面的理论基础和实践指导。

> **摘要翻译:** 大型语言模型（LLMs）中的幻觉是指生成与输入或现实世界事实不符的内容。本文对LLMs中的幻觉进行了严格处理，包括正式定义和理论分析。我们区分了内禀幻觉和外禀幻觉，并为模型定义了“幻觉风险”。我们使用学习理论框架（PAC-Bayes和Rademacher复杂度）推导了这种风险的界限。然后，我们调查了幻觉的检测策略，例如token级不确定性估计、置信度校准和注意力对齐检查。在缓解方面，我们讨论了包括检索增强生成、幻觉感知微调、logits校准和事实验证模块的集成等方法。我们提出了一个统一的检测和缓解工作流程，并用图表进行了说明，以整合这些策略。最后，我们概述了幻觉的评估协议，推荐了数据集、度量标准和实验设置来量化和减少幻觉。我们的工作为解决LLMs中幻觉这一关键挑战奠定了理论基础和实践指导。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [895] [Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs](https://arxiv.org/abs/2507.23227)
> *使用大型语言模型在表格生物标志物数据上实现少量样本阿尔茨海默病诊断*

*Sophie Kearney, Shu Yang, Zixuan Wen, Bojian Hou, Duy Duong-Tran, Tianlong Chen, Jason Moore, Marylyn Ritchie, Li Shen* | **Category: cs.CL, cs.LG, q-bio.QM** | **Updated: 2025-07-31**

**Keywords:** 阿尔茨海默病诊断, 大型语言模型, 表格数据, 少量样本学习, 生物标志物

**Comment:** 

> **TL;DR:** TAP-GPT是一个基于LLM的新框架，它将TableGPT2适配到表格生物标志物数据上，实现了少量样本的阿尔茨海默病诊断，并优于其他高级模型。

**AI_Comments:** 这项工作具有创新性，因为它首次将LLMs应用于使用表格生物标志物数据进行AD预测，并展示了LLMs在处理小样本量结构化生物医学数据方面的潜力。其将特定领域LLM（TableGPT2）适配到医疗任务的方法，以及利用少量样本学习的能力，为生物医学信息学中的未来LLM应用开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 阿尔茨海默病（AD）的早期准确诊断需要分析异构生物标志物，这些标志物通常以表格形式表示。大型语言模型（LLMs）凭借其灵活的少量样本推理、多模态集成和基于自然语言的可解释性，为结构化生物医学数据的预测提供了前所未有的机会。

**Method:** 本文提出了一个名为TAP-GPT（Tabular Alzheimer's Prediction GPT）的新颖框架，该框架将最初为商业智能任务开发的TableGPT2（一种多模态表格专用LLM）适配用于使用少量样本的结构化生物标志物数据进行AD诊断。该方法通过使用结构化生物医学数据中的上下文学习示例构建少量样本表格提示，并使用参数高效的qLoRA适配对TableGPT2进行微调，以进行AD或认知正常（CN）的临床二分类任务。

**Result:** TAP-GPT框架利用TableGPT2强大的表格理解能力和LLMs编码的先验知识，在预测任务中优于更先进的通用LLMs和专门开发的表格基础模型（TFM）。

**Conclusion:** 这是LLMs首次应用于使用表格生物标志物数据进行预测任务，为未来生物医学信息学中LLM驱动的多智能体框架铺平了道路。

> **ai_Abstract:** 本文提出了一种名为TAP-GPT的新型框架，旨在利用大型语言模型（LLMs）对表格生物标志物数据进行少量样本阿尔茨海默病（AD）诊断。TAP-GPT通过将TableGPT2（一个专门用于表格数据的LLM）适配到AD诊断任务，并通过上下文学习和qLoRA微调实现少量样本分类。实验结果表明，TAP-GPT在AD诊断任务中优于其他通用LLMs和表格基础模型，标志着LLMs在表格生物医学数据预测领域的首次应用。

> **摘要翻译:** 阿尔茨海默病（AD）是一种复杂的神经退行性疾病，其早期准确诊断需要分析异构生物标志物（例如，神经影像学、遗传风险因素、认知测试和脑脊液蛋白），这些生物标志物通常以表格形式表示。凭借灵活的少量样本推理、多模态集成和基于自然语言的可解释性，大型语言模型（LLMs）为结构化生物医学数据的预测提供了前所未有的机会。我们提出了一个名为TAP-GPT（Tabular Alzheimer's Prediction GPT）的新颖框架，它将TableGPT2（一个最初为商业智能任务开发的多模态表格专用LLM）适配用于使用小样本量结构化生物标志物数据进行AD诊断。我们的方法使用来自结构化生物医学数据的上下文学习示例构建少量样本表格提示，并使用参数高效的qLoRA适配对TableGPT2进行微调，以进行AD或认知正常（CN）的临床二分类任务。TAP-GPT框架利用TableGPT2强大的表格理解能力和LLMs编码的先验知识，在预测任务中优于更先进的通用LLMs和专门开发的表格基础模型（TFM）。据我们所知，这是LLMs首次应用于使用表格生物标志物数据进行预测任务，为未来生物医学信息学中LLM驱动的多智能体框架铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [896] [Inside-Out: Hidden Factual Knowledge in LLMs](https://arxiv.org/abs/2503.15299)
> *由内而外：大型语言模型中隐藏的事实知识*

*Zorik Gekhman, Eyal Ben David, Hadas Orgad, Eran Ofek, Yonatan Belinkov, Idan Szpektor, Jonathan Herzig, Roi Reichart* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 隐藏知识, 事实知识, 生成能力, 闭卷问答

**Comment:** Accepted to COLM 2025

> **TL;DR:** 本研究提出了一个框架来评估大型语言模型（LLMs）在其参数中编码的事实知识是否多于其在输出中表达的知识。研究发现LLMs内部编码的事实知识始终多于外部表达的知识，平均相对差距为40%，且有些知识即使内部完美掌握也难以生成。

**AI_Comments:** 这项研究创新性地提出了“隐藏知识”的概念及其量化方法，为理解LLMs的内部工作机制提供了新的视角。其重要性在于揭示了LLMs生成能力与内部知识存储之间的脱节，指出了当前模型在知识利用上的局限性，对未来LLMs的架构设计和训练优化具有指导意义。同时，它也对当前通过大规模采样来提高模型性能的实践提出了挑战，表明并非所有内部知识都能通过简单的生成策略被利用。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究暗示大型语言模型（LLMs）可能在其参数中编码了比其输出表达更多的知识，但尚未有明确的定义或证明这一现象。本研究旨在填补这一空白，明确定义并量化LLMs内部的隐藏知识。

**Method:** 本研究提出了一个知识的正式定义，将其量化为正确-错误答案对中正确答案排名更高的比例。这区分了外部知识（基于模型可观察的token级概率）和内部知识（基于其中间计算）。当内部知识超过外部知识时，便产生隐藏知识。研究将此框架应用于闭卷问答设置中的三个流行开源LLM进行案例研究，并通过大规模重复采样1000个答案来评估其生成能力。

**Result:** 1. LLMs内部编码的事实知识始终多于其外部表达的知识，平均相对差距为40%。
2. 令人惊讶的是，一些知识隐藏得如此之深，以至于模型即使在内部完美掌握答案，但在大规模重复采样1000个答案后也未能生成该答案。
3. 这对LLMs的生成能力提出了根本性限制，并对通过重复答案采样来扩展闭卷问答中的测试时间计算施加了实际约束，因为一些答案实际上从未被采样，即使它们被采样，也能保证被排在第一位。

**Conclusion:** 大型语言模型在其内部参数中存储了大量未被其生成能力完全表达的事实知识。这种“隐藏知识”的存在揭示了LLMs生成能力上的根本性限制，并表明简单地增加测试时的采样次数并不能完全弥补这些限制，因为某些内部已知的答案在实践中可能永远不会被生成。

> **ai_Abstract:** 本研究提出一个框架来量化大型语言模型（LLMs）中“隐藏事实知识”的现象，即模型内部编码的知识多于其在输出中表达的知识。通过定义外部知识（基于输出概率）和内部知识（基于中间计算），研究发现LLMs内部知识平均比外部知识高40%。此外，即使模型内部完美掌握某些答案，也可能因生成能力的限制而无法输出，这揭示了LLMs在生成方面的根本性瓶颈，并限制了通过增加采样来提升性能的有效性。

> **摘要翻译:** 这项工作提出了一个框架，用于评估大型语言模型（LLMs）在其参数中编码的事实知识是否多于其在输出中表达的知识。虽然少数研究暗示了这种可能性，但没有一项明确定义或证明这种现象。我们首先提出了一个知识的正式定义，将其量化为给定问题中正确-错误答案对中正确答案排名更高的比例。这产生了外部知识和内部知识，具体取决于用于对单个答案候选进行评分的信息：要么是模型可观察的token级概率，要么是其中间计算。当内部知识超过外部知识时，便产生隐藏知识。然后，我们提出了一个案例研究，将此框架应用于闭卷问答设置中的三个流行开源LLM。我们的结果表明：(1) LLMs内部编码的事实知识始终多于其外部表达的知识，平均相对差距为40%。(2) 令人惊讶的是，一些知识隐藏得如此之深，以至于模型即使在内部完美掌握答案，但在大规模重复采样1000个答案后也未能生成该答案。(3) 这揭示了LLMs生成能力的根本性限制，这（3）对通过重复答案采样在闭卷问答中扩展测试时间计算施加了实际约束：显著的性能提升仍然无法实现，因为一些答案实际上从未被采样，但如果它们被采样，我们则能保证将它们排在第一位。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [902] [Reading Between the Timelines: RAG for Answering Diachronic Questions](https://arxiv.org/abs/2507.22917)
> *解读时间线之间：用于回答历时问题的RAG*

*Kwun Hang Lau, Ruiyuan Zhang, Weijie Shi, Xiaofang Zhou, Xiaojun Cheng* | **Category: cs.CL, cs.AI, cs.IR** | **Updated: 2025-07-21**

**Keywords:** RAG, 历时问题, 时间逻辑, 问答系统, ADQAB

**Comment:** 

> **TL;DR:** 本文提出了一种新的RAG框架，通过引入时间逻辑来解决现有RAG在处理需要跨时间跟踪实体和现象的历时查询时的不足，并在新基准测试ADQAB上实现了显著的准确性提升。

**AI_Comments:** 这项研究创新性地解决了RAG在处理时间敏感型查询方面的局限性，特别是在需要跟踪实体随时间变化的情况。通过引入时间逻辑和专门的检索器，它弥补了传统语义检索的不足，为RAG系统处理更复杂的真实世界问题提供了重要的改进。引入新的评估基准ADQAB也对未来的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成（RAG）系统在处理需要跨时间跟踪实体和现象的历时查询时存在关键缺陷，因为传统的语义驱动检索方法无法收集既主题相关又时间连贯的证据。

**Method:** 本文提出了一种重新设计RAG流程的新框架，以融入时间逻辑。具体方法包括：将用户查询分解为核心主题和时间窗口；使用专门的检索器，该检索器根据时间相关性校准语义匹配，确保收集到跨整个查询期间的连续证据集。同时，引入了分析历时问答基准（ADQAB）用于严格评估。

**Result:** 在ADQAB基准测试上的实证结果表明，该方法在回答准确性方面取得了显著提升，超越标准RAG实现13%至27%。

**Conclusion:** 这项工作为能够进行复杂、真实世界问题所需的细致、演化分析的RAG系统提供了一条经过验证的途径。

> **ai_Abstract:** 本文提出了一种新的RAG框架，旨在解决现有RAG在处理需要跨时间跟踪信息（即历时问题）时的不足。该框架通过将查询分解为主题和时间窗口，并利用一个结合语义和时间相关性的专业检索器来确保证据的时间连贯性。为评估此能力，研究者还引入了新的基准测试ADQAB。实验结果显示，该方法在ADQAB上显著提高了回答准确性，性能优于标准RAG。这项工作为开发能进行复杂演化分析的RAG系统开辟了道路。

> **摘要翻译:** 虽然检索增强生成（RAG）在向大型语言模型（LLM）注入静态、事实知识方面表现出色，但它在处理需要跨时间跟踪实体和现象的纵向查询时表现出关键缺陷。这种盲点出现的原因是，传统的、语义驱动的检索方法无法收集到既主题相关又时间连贯的指定持续时间内的证据。我们通过提出一个从根本上重新设计RAG管道以注入时间逻辑的新框架来解决这一挑战。我们的方法始于将用户的查询分解为其核心主题和时间窗口。然后，它采用一个专门的检索器，该检索器根据时间相关性校准语义匹配，确保收集到跨越整个查询期间的连续证据集。为了对这项能力进行严格评估，我们还引入了分析历时问答基准（ADQAB），这是一个基于真实和合成金融新闻混合语料库的挑战性评估套件。ADQAB上的实证结果表明，我们的方法在回答准确性方面取得了显著提升，超越标准RAG实现13%至27%。这项工作为能够进行复杂、真实世界问题所需的细致、演化分析的RAG系统提供了一条经过验证的途径。本研究的数据集和代码已在https://github.com/kwunhang/TA-RAG公开可用。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [908] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
> *LLM时代的医学推理：增强技术和应用的系统综述*

*Wenxuan Wang, Zizhan Ma, Meidan Ding, Shiyi Zheng, Shengyuan Liu, Jie Liu, Jiaming Ji, Wenting Chen, Xiang Li, Linlin Shen, Yixuan Yuan* | **Category: cs.CL, cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 医学推理, 大型语言模型, 系统综述, 增强技术, 临床应用

**Comment:** 

> **TL;DR:** 本文对LLM在医学推理中的增强技术和应用进行了首次系统综述，提出了一个分类法，分析了技术应用和评估基准的演变，并指出了未来的挑战和方向。

**AI_Comments:** 本文作为该新兴领域的首次系统综述，为理解LLM在医学推理中的发展现状、挑战和未来方向提供了宝贵的框架。其提出的分类法有助于组织和理解现有技术，而对评估基准演变的分析则强调了该领域对更复杂和可解释评估的需求。指出的挑战，特别是忠实度-合理性差距和多模态推理，对于指导未来研究至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在医学领域展现出令人印象深刻的能力，但它们在执行系统性、透明和可验证的推理方面仍存在关键差距，而这正是临床实践的基石。因此，研究人员正从单一答案生成转向专门为医学推理设计的LLM开发。

**Method:** 本文进行了该新兴领域的首次系统综述。研究提出了一种推理增强技术的分类法，分为训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统）。研究分析了这些技术如何在不同数据模态（文本、图像、代码）和关键临床应用（如诊断、教育、治疗计划）中应用。此外，研究还调查了评估基准从简单准确性指标到推理质量和视觉可解释性复杂评估的演变。基于对2022-2025年60项开创性研究的分析，得出结论。

**Result:** 研究提出了一个医学推理增强技术的分类法，包括训练时策略和测试时机制。分析了这些技术在不同数据模态（文本、图像、代码）和关键临床应用（诊断、教育、治疗计划）中的应用。同时，调查了评估基准从简单准确性指标到复杂推理质量和视觉可解释性评估的演变。

**Conclusion:** 基于对60项开创性研究的分析，本文指出了关键挑战，包括忠实度-合理性差距以及对原生多模态推理的需求，并概述了构建高效、鲁棒且符合社会技术责任的医学AI的未来方向。

> **ai_Abstract:** 本文首次对大型语言模型（LLMs）在医学推理领域的增强技术和应用进行了系统综述。研究提出了一个推理增强技术的分类法，涵盖训练时策略和测试时机制，并分析了这些技术在不同数据模态和关键临床应用中的应用。此外，论文还调查了评估基准的演变。基于对60项研究的分析，文章总结了当前面临的挑战，如忠实度-合理性差距和对多模态推理的需求，并指出了未来医学AI发展的方向。

> **摘要翻译:** 大型语言模型（LLMs）在医学领域的普及使其具备了令人印象深刻的能力，然而，它们在执行系统性、透明和可验证的推理方面仍存在关键差距，而这正是临床实践的基石。这促使了从单一答案生成向专门为医学推理设计的LLM开发转变。本文首次对这一新兴领域进行了系统综述。我们提出了一种推理增强技术的分类法，分为训练时策略（例如，监督微调、强化学习）和测试时机制（例如，提示工程、多智能体系统）。我们分析了这些技术如何在不同数据模态（文本、图像、代码）以及诊断、教育和治疗计划等关键临床应用中应用。此外，我们调查了评估基准从简单准确性指标到推理质量和视觉可解释性复杂评估的演变。基于对2022-2025年60项开创性研究的分析，我们总结了关键挑战，包括忠实度-合理性差距和对原生多模态推理的需求，并概述了构建高效、鲁棒且符合社会技术责任的医学AI的未来方向。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [918] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
> *先分段，后检索：基于修辞角色的查询实现真实法律检索*

*Shubham Kumar Nigam, Tanmay Dubey, Noel Shallum, Arnab Bhattacharya* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 法律检索, 判例检索, 修辞角色, 文档分段, TraceRetriever

**Comment:** 

> **TL;DR:** TraceRetriever是一种新的法律判例检索系统，它通过提取修辞上重要的文本片段并结合BM25、向量数据库和交叉编码器模型进行检索，以应对法律文档的复杂性和数量挑战，尤其适用于只有部分案件信息的情况。

**AI_Comments:** 该论文提出了一种新颖的法律检索方法TraceRetriever，其创新点在于“先分段”的策略，即通过识别并利用修辞上重要的文本片段进行检索，而非处理整个文档。这符合真实世界法律搜索中信息有限的场景，提高了检索效率和相关性。其结合多种检索模型（BM25、向量数据库、交叉编码器）并通过倒数排名融合进行优化，展现了强大的工程整合能力。在应对法律文档日益增长的复杂性和数量方面，该方法提供了一个实用且可扩展的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 法律判例检索是判例法系统的基石，但日益增长的法律文档复杂性和数量对传统检索方法构成了挑战。

**Method:** TraceRetriever通过仅提取修辞上重要的文本片段（而非完整文档）进行操作，模仿真实世界的法律检索。其检索流程整合了BM25、向量数据库和交叉编码器模型，通过倒数排名融合（Reciprocal Rank Fusion）组合初始结果，然后进行最终重排序。修辞标注是使用在印度判决书上训练的层次BiLSTM CRF分类器生成的。

**Result:** TraceRetriever在IL-PCR和COLIEE 2025数据集上进行了评估，结果表明它能够应对日益增长的文档数量挑战，同时符合实际搜索限制。

**Conclusion:** TraceRetriever为判例检索提供了一个可靠且可扩展的基础，在只有部分案件知识可用时，能够增强法律研究。

> **ai_Abstract:** TraceRetriever是一种针对法律判例检索的新方法，旨在解决传统方法在处理大量复杂法律文档时面临的挑战。该系统通过提取文档中修辞上重要的片段进行检索，而非依赖完整文档。其核心流程融合了BM25、向量数据库和交叉编码器，并利用倒数排名融合进行结果合并与重排序。修辞标注通过在印度判决书上训练的层次BiLSTM CRF分类器生成。在IL-PCR和COLIEE 2025数据集上的评估表明，TraceRetriever在有限案件信息下，能够有效提升法律检索的可靠性和可扩展性。

> **摘要翻译:** 法律判例检索是判例法系统的基石，受“遵循先例”原则的约束，该原则要求司法裁决保持一致性。然而，日益增长的法律文档复杂性和数量对传统检索方法构成了挑战。TraceRetriever通过仅使用有限的案件信息，提取修辞上重要的片段而非要求完整文档，从而模拟现实世界的法律检索。我们的管道集成了BM25、向量数据库和交叉编码器模型，通过倒数排名融合（Reciprocal Rank Fusion）组合初始结果，然后进行最终重排序。修辞标注是使用在印度判决书上训练的层次BiLSTM CRF分类器生成的。在IL-PCR和COLIEE 2025数据集上进行评估，TraceRetriever解决了日益增长的文档数量挑战，同时符合实际搜索限制，为判例检索提供了一个可靠且可扩展的基础，在只有部分案件知识可用时，增强了法律研究。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [920] [P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication](https://arxiv.org/abs/2507.23247)
> *P-ReMIS：心理健康中的语用推理和社会影响*

*Sneha Oram, Pushpak Bhattacharyya* | **Category: cs.CL** | **Updated: 2025-07-31**

**Keywords:** 语用推理, 心理健康, 大型语言模型, 隐含意义, 预设, 污名

**Comment:** 

> **TL;DR:** 本文探讨了大型语言模型在心理健康领域中的语用推理能力，引入了P-ReMe数据集，并评估了不同模型在处理隐含意义、预设和心理健康污名方面的表现。

**AI_Comments:** 本文的创新之处在于首次将语用推理的概念引入心理健康领域的大型语言模型研究，并为此构建了专门的数据集和任务。通过修改语用现象的定义，使其更适用于心理健康场景，为后续研究奠定了基础。同时，对模型处理心理健康污名问题的探索也具有重要的社会意义，有助于推动更负责任的AI应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管心理健康领域的个性化聊天机器人和可解释性取得了进展，但针对心理健康的可解释性和对话语篇的推理方面尚未被充分探索。

**Method:** 研究调查了大型语言模型（LLMs）在心理健康领域的语用推理能力。引入了P-ReMe数据集，并修改了心理健康中隐含意义和预设的语用现象定义。基于新定义，制定了两个隐含意义任务和一个预设任务。使用Llama3.1、Mistral、MentaLLaMa和Qwen进行基准测试。此外，还提出了StiPRompts来研究LLMs（GPT-4o mini、Deepseek-chat和Claude-3.5-haiku）在处理心理健康污名方面的能力。

**Result:** 实验结果表明，Mistral和Qwen在心理健康领域显示出显著的推理能力。在处理心理健康污名方面，Claude-3.5-haiku比其他两个LLMs（GPT-4o mini、Deepseek-chat）表现出更负责任的态度。

**Conclusion:** 大型语言模型在心理健康领域的语用推理方面具有潜力，特别是Mistral和Qwen表现出色。同时，在处理心理健康污名方面，特定模型如Claude-3.5-haiku展现出更高的负责任性。

> **ai_Abstract:** 本文研究了大型语言模型（LLMs）在心理健康领域中的语用推理能力，填补了该领域推理方面研究的空白。研究引入了P-ReMe数据集，并重新定义了心理健康中的隐含意义和预设现象，基于此设计了相关任务。通过对Llama3.1、Mistral、MentaLLaMa和Qwen进行基准测试，发现Mistral和Qwen展现出强大的推理能力。此外，研究还提出了StiPRompts，并评估了GPT-4o mini、Deepseek-chat和Claude-3.5-haiku在处理心理健康污名方面的表现，结果显示Claude-3.5-haiku更为负责任。

> **摘要翻译:** 近年来，心理健康领域的可解释性和个性化聊天机器人开发取得了显著进展。然而，针对心理健康的可解释性和对话语篇的推理方面此前尚未被探索。因此，我们正在调查大型语言模型（LLMs）在该领域的语用推理能力。我们引入了P-ReMe数据集，并提出了心理健康中隐含意义（implied meaning）和预设（implicit assumption）这两种语用现象的修改定义。根据该定义，我们制定了两个隐含意义任务和一个预设任务。为了对数据集和所提出的任务进行基准测试，我们考虑了四种模型——Llama3.1、Mistral、MentaLLaMa和Qwen。实验结果表明，Mistral和Qwen在该领域显示出显著的推理能力。此外，我们还提出了StiPRompts，以利用最先进的LLMs（GPT-4o mini、Deepseek-chat和Claude-3.5-haiku）研究围绕心理健康的污名。我们的评估结果显示，与另外两个LLMs相比，Claude-3.5-haiku在处理污名方面表现得更负责任。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [924] [Semantic Convergence: Investigating Shared Representations Across Scaled LLMs](https://arxiv.org/abs/2507.22918)
> *语义收敛：探究不同规模大型语言模型中的共享表征*

*Daniel Son, Sanjana Rathore, Andrew Rufail, Adrian Simon, Daniel Zhang, Soham Dave, Cole Blondin, Kevin Zhu, Sean O'Brien* | **Category: cs.CL, cs.LG, 68T50, I.2.6; I.2.7** | **Updated: 2025-07-21**

**Keywords:** 语义收敛, 大型语言模型, 特征普遍性, 稀疏自编码器, 模型可解释性

**Comment:** Submitted to ACL 2025 Student Research Workshop (poster)

> **TL;DR:** 研究发现，即使规模差异很大，Gemma-2大型语言模型也能在内部概念上趋于一致，尤其在中层，这支持了跨模型可解释性的基础。

**AI_Comments:** 这项研究通过实证方法探究了不同规模LLM内部表征的“语义收敛”现象，特别是发现中间层具有最强的特征重叠，为理解LLM的内部工作机制和实现跨模型可解释性提供了重要线索。其创新点在于使用SAE和多维度比较方法来量化和分析这种收敛性。

<details>
  <summary>Details</summary>

**Motivation:** 探究不同规模的大型语言模型（LLMs）是否会收敛到可比较的内部概念，即特征的普遍性，以理解它们内部表征的一致性。

**Method:** 使用稀疏自编码器（SAE）字典学习流程，在每个模型的残差流激活上应用SAE，通过激活相关性对齐单义特征，并使用SVCCA和RSA比较匹配的特征空间。初步实验还将分析从单令牌扩展到多令牌子空间。

**Result:** 中间层表现出最强的特征重叠，而早期和晚期层的相似性远低于此。语义相似的多令牌子空间与语言模型的交互方式相似。

**Conclusion:** 尽管大型语言模型在规模上存在差异，但它们将世界划分为大致相似的、可解释的特征，这强化了普遍性作为跨模型可解释性基础的观点。

> **ai_Abstract:** 本文调查了Gemma-2大型语言模型（Gemma-2-2B和Gemma-2-9B）中特征的普遍性，以确定不同规模的模型是否能收敛到相似的内部概念。研究利用稀疏自编码器（SAE）和激活相关性对齐方法，并结合SVCCA和RSA进行特征空间比较。结果表明，中间层展现出最强的特征重叠，而早期和晚期层相似性较低。此外，语义相似的多令牌子空间与模型交互方式相似。这些发现支持了大型语言模型即使规模不同，也能形成普遍且可解释的内部特征，为跨模型可解释性提供了基础。

> **摘要翻译:** 我们研究了Gemma-2语言模型（Gemma-2-2B和Gemma-2-9B）中的特征普遍性，探讨了规模相差四倍的模型是否仍能收敛到可比较的内部概念。我们使用稀疏自编码器（SAE）字典学习流程，在每个模型的残差流激活上利用SAE，通过激活相关性对生成的单义特征进行对齐，并使用SVCCA和RSA比较匹配的特征空间。结果显示，中间层产生了最强的重叠，而早期和晚期层的相似性则低得多。初步实验将分析从单令牌扩展到多令牌子空间，表明语义相似的子空间与语言模型的交互方式相似。这些结果进一步证明，尽管大型语言模型在规模上存在差异，但它们将世界划分为大致相似的、可解释的特征，这强化了普遍性作为跨模型可解释性基础的观点。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [930] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
> *NyayaRAG：在印度普通法体系下基于RAG的现实法律判决预测*

*Shubham Kumar Nigam, Balaramamahanthi Deepak Patnaik, Shivam Mishra, Ajay Varghese Thomas, Noel Shallum, Kripabandhu Ghosh, Arnab Bhattacharya* | **Category: cs.CL, cs.AI, cs.IR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 法律判决预测, 检索增强生成, 印度普通法, 法律AI, 司法先例

**Comment:** 

> **TL;DR:** NyayaRAG是一个RAG框架，通过结合事实描述、法律法规和先例，显著提高了印度法律判决预测的准确性和解释质量。

**AI_Comments:** NyayaRAG的创新之处在于它将外部结构化法律知识（法规和先例）整合到RAG框架中，以解决传统LJP模型在普通法体系下缺乏现实性的问题。这对于提升AI在法律领域的实际应用价值和可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的印度法律判决预测（LJP）方法主要依赖内部案件内容，但忽略了普通法系统中对成文法规定和司法先例的依赖，这促使研究者寻求更现实的方法来预测司法结果和增强法律推理的可解释性。

**Method:** 本研究提出了NyayaRAG，一个检索增强生成（RAG）框架，通过向模型提供事实案件描述、相关法律法规和语义检索的先前案例来模拟现实法庭场景。NyayaRAG使用针对印度法律系统量身定制的特定领域管道来评估这些组合输入在预测法院判决和生成法律解释方面的有效性，并使用标准词汇和语义指标以及LLM评估器（如G-Eval）评估性能。

**Result:** 结果表明，用结构化法律知识增强事实输入显著提高了预测准确性和解释质量。

**Conclusion:** 通过将结构化法律知识（如法规和先例）整合到检索增强生成框架中，可以显著提高印度普通法体系下法律判决预测的准确性和解释质量。

> **ai_Abstract:** NyayaRAG是一个为印度普通法系统设计的检索增强生成（RAG）框架，旨在通过整合案件事实、相关法律法规和司法先例来改进法律判决预测（LJP）。该研究发现，与仅依赖案件内部内容的方法相比，结合结构化法律知识能显著提高预测准确性和法律解释的质量，从而更真实地模拟法庭场景。

> **摘要翻译:** 法律判决预测（LJP）已成为人工智能在法律领域的一个关键研究方向，旨在自动化司法结果预测并增强法律推理的可解释性。虽然印度背景下的先前方法依赖于内部案件内容，如事实、问题和推理，但它们往往忽视了普通法体系的核心要素，即对成文法规定和司法先例的依赖。在这项工作中，我们提出了NyayaRAG，一个检索增强生成（RAG）框架，通过向模型提供事实案件描述、相关法律法规和语义检索的先前案例来模拟现实法庭场景。NyayaRAG使用针对印度法律系统量身定制的特定领域管道来评估这些组合输入在预测法院判决和生成法律解释方面的有效性。我们使用标准词汇和语义指标以及LLM评估器（如G-Eval）评估了各种输入配置下的性能。我们的结果表明，用结构化法律知识增强事实输入显著提高了预测准确性和解释质量。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [940] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
> *将心理测量学应用于大型语言模型模拟人群：使用生成式智能体重现HEXACO人格量表实验*

*Sarah Mercer, Daniel P. Martin, Phil Swatton* | **Category: cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 生成式智能体, 大型语言模型, 心理测量学, HEXACO, 人格评估

**Comment:** 26 pages, 14 figures

> **TL;DR:** 本研究通过对310个GPT-4智能体进行HEXACO人格量表实验，探索了生成式智能体作为人类参与者替代品的有效性，发现智能体能恢复部分与HEXACO一致的人格结构，但存在模型特有的偏差。

**AI_Comments:** 这项研究具有创新性，它将心理测量学这一成熟的人类行为测量工具应用于大型语言模型模拟人群，为LLM在社会科学研究中的应用提供了实证基础。其重要性在于验证了生成式智能体作为研究参与者的潜力，并同时指出了模型特有的局限性和偏差，这对于未来设计更可靠、更具代表性的AI代理至关重要。研究还提供了实用的指导，有助于提升AI模拟的质量和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型驱动的生成式智能体因其能够扮演角色并展现类人特征，被认为是社会科学研究中人类参与者的经济有效替代品。本研究旨在探讨这些基于角色设定的智能体在代表人类群体方面的有效性。

**Method:** 研究通过对310个由GPT-4驱动的智能体进行HEXACO人格量表实验，对其回答进行因子分析，并将结果与Ashton、Lee和Goldberg在2004年提出的原始发现进行比较。

**Result:** 1) 从智能体的回答中恢复出连贯且可靠的人格结构，部分与HEXACO框架对齐。2) 在结合充分策划的人群时，GPT-4内部导出的人格维度保持一致且可靠。3) 跨模型分析显示人格剖析存在变异性，表明模型特有的偏差和局限性。

**Conclusion:** 本研究探讨了在社会科学研究中使用生成式智能体的潜在益处和局限性，并为设计一致且具有代表性的智能体角色提供了有用指导，以最大限度地覆盖和代表人类人格特质。

> **ai_Abstract:** 本研究评估了大型语言模型驱动的生成式智能体作为社会科学研究中人类参与者替代品的有效性。通过对310个GPT-4智能体进行HEXACO人格量表实验，并进行因子分析，研究发现智能体能恢复出部分与HEXACO框架一致的、连贯可靠的人格结构。结果表明，在适当策划下，GPT-4内部的人格维度具有一致性和可靠性，但跨模型分析揭示了模型特有的偏差。研究讨论了实验中的挑战，并为设计代表性智能体提供了指导，以期最大化地捕捉人类人格特质。

> **摘要翻译:** 由大型语言模型驱动的生成式智能体通过复杂的自然语言交互展现出类人特征。它们根据预定义的角色传记扮演角色和个性的能力，使其成为社会科学研究中人类参与者的经济有效替代品。本文探讨了此类基于角色的智能体在代表人​​类群体方面的有效性；我们通过调查310个由GPT-4驱动的智能体，对其回答进行因子分析，并将这些结果与Ashton、Lee和Goldberg在2004年提出的原始发现进行比较，从而重现了HEXACO人格量表实验。我们的结果发现：1) 从智能体的回答中可恢复出连贯且可靠的人格结构，表明与HEXACO框架部分对齐。2) 当与充分策划的人群结合时，GPT-4内部导出的人格维度保持一致且可靠。3) 跨模型分析揭示了人格剖析的变异性，表明模型特有的偏差和局限性。我们讨论了实验过程中遇到的实际考虑和挑战。这项研究有助于正在进行的关于在社会科学研究中使用生成式智能体的潜在益处和局限性的讨论，并为设计一致且具有代表性的智能体角色提供了有用指导，以最大限度地覆盖和代表人​​类人格特质。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [943] [Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis](https://arxiv.org/abs/2507.23248)
> *评估大型语言模型在孟加拉语上的多语言能力：基准创建与性能分析*

*Shimanto Bhowmik, Tawsif Tashwar Dipto, Md Sazzad Islam, Sheryl Hsu, Tahsin Reasat* | **Category: cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 孟加拉语, 大型语言模型, 多语言能力, 基准测试, 分词效率

**Comment:** 

> **TL;DR:** 该研究评估了大型语言模型在孟加拉语上的性能，发现与英语相比存在差距，并强调了更好的基准和分词优化的重要性。

**AI_Comments:** 本文通过为孟加拉语创建首个标准化评估基准，填补了该领域的一项空白。其创新之处在于系统地揭示了大型语言模型在处理低资源语言时面临的具体挑战，特别是揭示了分词效率与模型性能之间的关键反比关系。这项工作对于推动多语言NLP，尤其是对代表性不足语言的NLP发展具有重要意义，有助于促进全球语言技术的普及。

<details>
  <summary>Details</summary>

**Motivation:** 孟加拉语在自然语言处理（NLP）研究中代表性不足，且由于其独特的语言结构和计算限制，仍然是一个挑战。本研究旨在通过关注标准化评估基准的缺失，系统地调查阻碍孟加拉语NLP性能的挑战。

**Method:** 研究评估了10个近期开源大型语言模型（LLMs）在8个翻译数据集上的表现，并进行了全面的错误分析，以找出它们主要的失败模式。

**Result:** 研究发现孟加拉语与英语相比存在一致的性能差距，尤其是在小型模型和Mistral等特定模型家族中。DeepSeek等某些架构展现出良好的鲁棒性，在不同语言间保持更稳定的性能。分析揭示了分词效率与LLM准确性之间存在反比关系，即过度分词会导致模型性能下降，而更高效简洁的分词则能提高性能。

**Conclusion:** 当前模型在处理孟加拉语时存在不足，需要改进数据集质量和针对多语言环境的评估方法。这项工作将促进对代表性不足语言的自然语言处理研究，有助于普及全球先进的语言技术。

> **ai_Abstract:** 该研究评估了大型语言模型在孟加拉语上的多语言能力，孟加拉语是自然语言处理中代表性不足的语言。通过创建新的基准并评估10个开源LLM，研究发现孟加拉语与英语相比存在性能差距，特别是对于小型模型和某些模型家族。同时，论文指出分词效率对模型性能有显著影响，并强调了改进数据集质量和评估方法的重要性，以促进对代表性不足语言的NLP研究。

> **摘要翻译:** 孟加拉语在自然语言处理（NLP）研究中代表性不足。然而，由于其独特的语言结构和计算限制，它仍然是一个挑战。在这项工作中，我们通过关注标准化评估基准的缺失，系统地调查了阻碍孟加拉语NLP性能的挑战。然后，我们评估了10个近期开源大型语言模型（LLMs）在8个翻译数据集上的表现，并进行了全面的错误分析，以找出它们主要的失败模式。我们的发现揭示了孟加拉语与英语相比存在一致的性能差距，特别是对于小型模型和Mistral等特定模型家族。我们还发现某些架构（如DeepSeek）具有良好的鲁棒性，能够保持更稳定的跨语言性能。我们的分析揭示了分词效率与LLM准确性之间存在反比关系，即当输入被过度分词时，模型表现往往更差，而更高效、简洁的分词则能提高性能。这些发现突出了当前模型不足的关键领域，并强调了需要改进数据集质量和针对多语言环境的评估方法。这项工作将促进对代表性不足语言的自然语言处理的进一步研究，有助于普及全球先进的语言技术。本研究中使用的代码和数据集已公开发布在https://github.com/BengaliAI/bn-llm-benchmark。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [944] [Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer](https://arxiv.org/abs/2503.15768)
> *一刀切可行吗？：衡量多文档摘要领域迁移中的失败*

*Alexandra DeLucia, Mark Dredze* | **Category: cs.CL, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 多文档摘要, 领域迁移, 零样本, 事实性, 评估指标

**Comment:** 

> **TL;DR:** 本文评估了多文档摘要模型在不同训练方法和领域间的表现，并分析了零样本领域迁移中模型失败的原因，同时探讨了摘要评估指标的应用问题。

**AI_Comments:** 本文关注了多文档摘要模型在跨领域应用时的关键挑战，即“一刀切”方法是否可行。其创新点在于明确定义了领域迁移“失败”的标准，并系统性地评估了不同训练方法和领域对模型性能的影响。这项工作的重要性在于，它揭示了当前MDS模型在泛化能力上的局限性，并指出了现有评估指标在领域迁移场景下可能存在的问题，为未来研究提供了明确的方向和改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 当前多文档摘要（MDS）模型在不同领域间的泛化能力尚不清楚，尤其是在零样本领域迁移设置下，模型从一个领域训练后在另一个领域进行摘要时可能出现失败。此外，流行的摘要评估指标直接应用于不同领域时也可能存在问题。因此，本研究旨在分析MDS模型在领域迁移中失败的原因，并探讨评估指标的适用性。

**Method:** 研究评估了多种训练方法（直接、分块-摘要、提取-摘要、GPT风格模型推理）下的多文档摘要模型。评估涵盖了不同领域（新闻、科学、对话）和多个维度（参考相似度、质量、事实性）。研究定义了领域迁移“失败”为事实性下降、与目标偏差增大以及摘要质量普遍下降。此外，还探究了直接应用流行摘要评估指标可能存在的问题。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究评估了抽象多文档摘要（MDS）模型在不同训练方法、领域和评估维度上的表现，特别关注零样本领域迁移设置下，模型从一个领域训练后在另一个领域（新闻、科学、对话）进行摘要时失败的原因。研究将领域迁移失败定义为事实性下降、与目标偏差增大及摘要质量下降。此外，本文还探讨了直接应用流行摘要评估指标可能存在的问题。

> **摘要翻译:** 抽象多文档摘要（MDS）是自动总结多个文档信息的任务，从新闻文章到多说话人对话。当前MDS模型的训练方法可分为四种：带有特殊预训练的端到端（“直接”）、分块-摘要、提取-摘要，以及使用GPT风格模型进行推理。在这项工作中，我们评估了MDS模型在不同训练方法、领域和维度（参考相似度、质量和事实性）上的表现，以分析在零样本领域迁移设置下，在一个领域训练的模型如何以及为何无法总结来自另一个领域（新闻、科学和对话）的文档。我们将领域迁移“失败”定义为事实性下降、与目标偏差增大以及摘要质量普遍下降。除了探索MDS模型的领域迁移外，我们还检查了直接应用流行摘要评估指标的潜在问题。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [948] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
> *智能体大型语言模型改进基于检索的放射学问答*

*Sebastian Wind, Jeta Sopa, Daniel Truhn, Mahshad Lotfinia, Tri-Thien Nguyen, Keno Bressem, Lisa Adams, Mirabela Rusu, Harald Köstler, Gerhard Wellein, Andreas Maier, Soroosh Tayebi Arasteh* | **Category: cs.CL, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 智能体RAG, 大型语言模型, 放射学问答, 检索增强生成, 诊断准确性

**Comment:** 

> **TL;DR:** 本研究提出了一种智能体RAG框架，使LLM能够自主分解放射学问题、迭代检索证据并动态合成回答，显著提高了放射学问答的诊断准确性，尤其对中小型模型效果显著，并减少了幻觉。

**AI_Comments:** 该研究提出了一种创新的智能体RAG框架，通过引入迭代检索和自主问题分解能力，显著提升了LLM在放射学复杂临床推理任务中的表现。其重要性在于，它不仅提高了诊断准确性，还有效减少了LLM的幻觉问题，增强了响应的事实性。特别值得关注的是，该方法对中小型LLM的性能提升最为显著，这对于资源受限的部署场景具有重要意义。同时，研究还指出检索与模型微调具有互补作用，为未来的研究方向提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统的放射学问答（QA）检索增强生成（RAG）系统通常依赖单步检索，限制了其处理复杂临床推理任务的能力。

**Method:** 提出了一种智能体RAG框架，使LLMs能够自主分解放射学问题，迭代地从Radiopaedia检索目标临床证据，并动态合成基于证据的响应。评估了24种LLM（参数规模从0.5B到>670B），使用了来自RSNA-RadioQA和ExtendedQA数据集的104个专家整理的放射学问题。

**Result:** 智能体检索显著提高了平均诊断准确性：相较于零样本提示（73% vs. 64%；P<0.001）和传统在线RAG（73% vs. 68%；P<0.001）。在中型模型（如Mistral Large从72%提高到81%）和小型模型（如Qwen 2.5-7B从55%提高到71%）中增益最大，而超大型模型（>200B参数）变化最小（<2%）。此外，智能体检索将幻觉减少了9.4%，并在46%的案例中检索到临床相关上下文。临床微调模型也表现出显著改进（如MedGemma-27B从71%提高到81%）。

**Conclusion:** 智能体框架有潜力提高放射学问答的事实性和诊断准确性，尤其对于中型LLM，未来研究需验证其临床实用性。

> **ai_Abstract:** 本研究提出了一种智能体RAG框架，旨在解决传统RAG系统在放射学问答中处理复杂临床推理的局限性。该框架使LLM能够自主分解问题、迭代检索证据并动态生成响应。实验结果表明，与零样本提示和传统RAG相比，智能体检索显著提高了诊断准确性，尤其在中小型模型中表现突出，并有效减少了幻觉，增强了事实性。这表明智能体框架在提升放射学问答质量方面具有巨大潜力。

> **摘要翻译:** 放射学中的临床决策日益受益于人工智能（AI），特别是通过大型语言模型（LLM）。然而，用于放射学问答（QA）的传统检索增强生成（RAG）系统通常依赖于单步检索，限制了它们处理复杂临床推理任务的能力。在此，我们提出了一种智能体RAG框架，使LLM能够自主分解放射学问题，迭代地从Radiopaedia检索目标临床证据，并动态合成基于证据的响应。我们评估了24种LLM，涵盖了不同的架构、参数规模（0.5B到>670B）和训练范式（通用、推理优化、临床微调），使用了来自先前建立的RSNA-RadioQA和ExtendedQA数据集的104个由专家整理的放射学问题。智能体检索显著提高了平均诊断准确性，优于零样本提示（73% vs. 64%；P<0.001）和传统在线RAG（73% vs. 68%；P<0.001）。最大的增益发生在中型模型（例如，Mistral Large从72%提高到81%）和小型模型（例如，Qwen 2.5-7B从55%提高到71%），而超大型模型（>200B参数）变化最小（<2%的改进）。此外，智能体检索减少了幻觉（平均9.4%），并在46%的案例中检索到临床相关上下文，极大地帮助了事实基础。即使是临床微调模型也表现出有意义的改进（例如，MedGemma-27B从71%提高到81%），表明检索和微调具有互补作用。这些结果突出了智能体框架在放射学问答中增强事实性和诊断准确性的潜力，特别是在中型LLM中，这需要未来的研究来验证其临床实用性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='cscr'></a>
## cs.CR 

### [1] [A Zero-Knowledge Proof for the Syndrome Decoding Problem in the Lee Metric](https://arxiv.org/abs/2502.11641)
> *Lee度量下综合征解码问题的零知识证明*

*Mladen Kovačević, Tatjana Grbić, Darko Čapko, Nemanja Nedić, Srdjan Vukmirović* | **Category: cs.CR, cs.IT, math.IT, 94A60, 68P25** | **Updated: 2025-07-31**

**Keywords:** 零知识证明, 综合征解码问题, Lee度量, 基于编码密码学

**Comment:** 

> **TL;DR:** 本文提出了Lee度量下综合征解码问题的零知识证明。

**AI_Comments:** 本文的创新点在于为Lee度量下的综合征解码问题构建了零知识证明，这对于基于编码的密码学领域，尤其是在追求更高效系统方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 综合征解码问题是基于编码密码学的核心NP完全问题之一。最近，Lee度量下的变体因其在构建更高效的基于编码的密码系统方面的潜在相关性而受到关注。

**Method:** 本文提出了一种针对Lee度量下综合征解码问题的零知识知识证明。

**Result:** 本文成功地提出了Lee度量下综合征解码问题的一种零知识知识证明。

**Conclusion:** 本文为Lee度量下的综合征解码问题提供了零知识证明，这可能有助于未来基于编码的密码系统的发展。

> **ai_Abstract:** 本文针对基于编码密码学中的NP完全问题——综合征解码问题，特别是其在Lee度量下的变体，提出了一种零知识知识证明。该变体因其在构建高效密码系统方面的潜力而备受关注。

> **摘要翻译:** 综合征解码问题是基于编码密码学基础的NP完全问题之一。其中，向量间距离使用Lee度量而非更常用的Hamming度量来衡量的变体，由于其在构建更高效的基于编码的密码系统方面的潜在相关性，最近在多项工作中得到了分析。本文的目的是为该问题的这一变体提出一个零知识知识证明。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [29] [Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application](https://arxiv.org/abs/2503.06989)
> *多模态大型语言模型越狱的概率建模：从量化到应用*

*Wenzhuo Xu, Zhipeng Wei, Xiongtao Sun, Zonghao Ying, Deyue Zhang, Dongdong Yang, Xiangzheng Zhang, Quanchen Zou* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多模态大语言模型, 越狱, 概率建模, 对抗性攻击, 微调

**Comment:** 

> **TL;DR:** 本文提出越狱概率来量化多模态大语言模型（MLLMs）的越狱潜力，并基于此开发了越狱攻击（JPA/MJPA）和防御（JPF）方法，实验证明了其有效性。

**AI_Comments:** 这篇论文的创新点在于引入了“越狱概率”这一概念来量化多模态大语言模型（MLLMs）的越狱潜力，摆脱了传统二元分类的局限性，更符合MLLM响应的随机性。基于此概率，论文不仅提出了有效的越狱攻击方法（JPA/MJPA），还开发了相应的防御机制（JPF），形成了从量化到应用的完整框架。其重要性在于为MLLM安全对齐的评估和增强提供了一个更精细和实用的视角。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型（MLLMs）易受越狱攻击，这些攻击利用其安全对齐的弱点生成有害响应。以往将越狱分类为成功或失败的二元方法，由于MLLM响应的随机性，是不恰当的。

**Method:** 引入越狱概率来量化输入的越狱潜力，表示MLLM在给定输入下生成恶意响应的可能性。通过多次查询MLLM来近似此概率。使用越狱概率预测网络（JPPN）建模输入隐藏状态与越狱概率的关系，并使用连续越狱概率进行优化。提出了基于越狱概率的攻击（JPA），通过优化输入图像上的对抗性扰动来最大化越狱概率，并将其增强为多模态JPA（MJPA），纳入单调文本重述。为对抗攻击，提出了基于越狱概率的微调（JPF），通过更新MLLM参数来最小化越狱概率。

**Result:** 1. (M)JPA 在白盒和黑盒设置下攻击各种模型时都取得了显著改进。
2. JPF 将越狱减少了至多超过 60%。

**Conclusion:** 引入越狱概率对于区分输入越狱能力的细微差别具有重要意义。

> **ai_Abstract:** 本文提出了一种新的越狱量化方法，即“越狱概率”，以克服传统二元分类的局限性。基于此概率，作者开发了两种应用：一是基于越狱概率的攻击（JPA和MJPA），通过优化对抗性扰动来最大化越狱概率，以提高攻击成功率；二是基于越狱概率的微调（JPF），通过模型参数更新来最小化越狱概率，以增强防御能力。实验证明，(M)JPA显著提升了攻击效果，而JPF则能有效降低越狱风险，验证了越狱概率在区分输入越狱能力方面的有效性。

> **摘要翻译:** 多模态大型语言模型（MLLMs）最近展示了其理解多模态内容的卓越能力。然而，它们仍然容易受到越狱攻击，这些攻击利用其安全对齐中的弱点来生成有害响应。先前的研究根据响应是否包含恶意内容将越狱分为成功或失败。然而，考虑到MLLM响应的随机性，这种对输入越狱MLLM能力的二元分类是不恰当的。基于此观点，我们引入了越狱概率来量化输入的越狱潜力，它表示MLLM在被该输入提示时生成恶意响应的可能性。我们通过对MLLM进行多次查询来近似此概率。在使用越狱概率预测网络（JPPN）建模输入隐藏状态及其相应越狱概率之间的关系后，我们使用连续越狱概率进行优化。具体来说，我们提出了基于越狱概率的攻击（JPA），通过优化输入图像上的对抗性扰动来最大化越狱概率，并通过包含单调文本重述将其进一步增强为多模态JPA（MJPA）。为了对抗攻击，我们还提出了基于越狱概率的微调（JPF），通过更新MLLM参数来最小化越狱概率。大量实验表明：（1）(M)JPA 在白盒和黑盒设置下攻击各种模型时都取得了显著改进。（2）JPF 将越狱减少了至多超过 60%。以上两项结果都证明了引入越狱概率对于在输入越狱能力之间做出细微区分的重要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [57] [CEE: An Inference-Time Jailbreak Defense for Embodied Intelligence via Subspace Concept Rotation](https://arxiv.org/abs/2504.13201)
> *CEE：一种通过子空间概念旋转实现的具身智能推理时越狱防御*

*Jirui Yang, Zheyu Lin, Zhihui Lu, Yinggui Wang, Lei Wang, Tao Wei, Xin Du, Shuhan Yang* | **Category: cs.CR, cs.LG, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 具身智能, 越狱防御, 推理时防御, 概念增强工程, 子空间概念旋转

**Comment:** 

> **TL;DR:** CEE是一种高效的推理时越狱防御框架，通过直接操纵模型内部表示来保护具身智能系统，无需额外训练或复杂调优。

**AI_Comments:** CEE的创新点在于其推理时防御的特性，无需额外训练和复杂调优，这显著降低了部署成本和复杂性。其通过直接操纵内部表示和引入旋转控制机制的设计，有效解决了现有方法的局限性，特别是在保持输出质量和效率方面表现突出，对于具身智能的安全落地具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）作为具身智能（EI）系统的核心面临严重的越狱风险，恶意指令可能转化为危险的物理动作。现有防御机制存在训练成本高、推理延迟大和超参数调优复杂等缺点，限制了其实际应用。

**Method:** 本文提出了一种新颖高效的推理时防御框架——概念增强工程（CEE）。CEE通过直接操纵模型的内部表示来增强其固有的安全机制，无需额外的训练或外部模块，从而提高了防御效率。此外，CEE引入了一种基于旋转的控制机制，实现了模型行为的稳定且线性可调的控制，避免了手动调优和输出退化问题。

**Result:** 在多个具身智能安全基准和多样攻击场景下的广泛实验表明，CEE显著提高了各种多模态LLM的防御成功率。它有效缓解了安全风险，同时保持了高质量的生成和推理效率。

**Conclusion:** CEE为部署更安全的具身智能系统提供了一个有前景的解决方案。

> **ai_Abstract:** 本文提出了一种名为CEE（概念增强工程）的新型推理时防御框架，旨在解决大型语言模型在具身智能系统中面临的越狱风险。CEE通过直接操纵模型内部表示来增强安全机制，无需额外训练或外部模块，并引入了基于旋转的控制机制以实现稳定可调的行为控制。实验证明CEE在提高防御成功率、缓解安全风险、保持生成质量和推理效率方面表现出色，为具身智能的安全部署提供了有效方案。

> **摘要翻译:** 大型语言模型（LLMs）正日益成为具身智能（EI）系统（如机器人和自动驾驶汽车）的认知核心。然而，这种集成也使它们面临严重的越狱风险，即恶意指令可以转化为危险的物理动作。现有防御机制存在显著缺点——包括高训练成本、显著的推理延迟和复杂的超参数调优——这些限制了它们的实际适用性。为解决这些挑战，我们提出了一种新颖高效的推理时防御框架：概念增强工程（CEE）。CEE通过直接操纵模型的内部表示来增强模型固有的安全机制，无需额外的训练或外部模块，从而提高了防御效率。此外，CEE引入了一种基于旋转的控制机制，能够实现模型行为的稳定且线性可调的控制。这种设计消除了繁琐的手动调优需求，并避免了其他表示工程方法中常见的输出退化问题。在多个EI安全基准和多样攻击场景下的大量实验表明，CEE显著提高了各种多模态LLM的防御成功率。它有效缓解了安全风险，同时保持了高质量的生成和推理效率，为部署更安全的具身智能系统提供了一个有前景的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [84] [Graph Representation-based Model Poisoning on Federated Large Language Models](https://arxiv.org/abs/2507.01694)
> *基于图表示的联邦大型语言模型模型中毒攻击*

*Hanlin Cai, Haofan Dong, Houtianfu Wang, Kai Li, Ozgur B. Akan* | **Category: cs.CR, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 联邦大型语言模型, 模型中毒, 图表示, 安全聚合, 攻击

**Comment:** 7 pages, 5 figures (Submitted to IEEE Communication Magazine)

> **TL;DR:** 本文研究了联邦大语言模型（FedLLMs）中基于图表示的模型中毒攻击（GRMP），这种攻击能够绕过现有防御，并提出了未来的研究方向。

**AI_Comments:** 本文创新性地提出了基于图表示的模型中毒（GRMP）攻击，揭示了现有联邦学习防御机制在面对复杂、自适应攻击时的脆弱性，尤其是在联邦大型语言模型领域。其重要性在于，它不仅指出了当前防御的局限性，还为未来更鲁棒的联邦学习防御机制设计提供了明确的研究方向，特别是强调了图感知方法的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦大型语言模型（FedLLMs）在保护数据隐私的同时提供了强大的生成能力，但它们容易受到模型中毒攻击。现有防御机制，特别是针对非IID文本数据时，存在显著局限性，因为它们依赖于恶意更新与良性统计模式显著不同的假设，而这在对抗自适应攻击者时变得不足。

**Method:** 本文研究了一种新兴的攻击范式：基于图表示的模型中毒（GRMP）。GRMP通过利用良性客户端梯度之间的高阶相关性来精心制作恶意更新，使其与合法更新无法区分。

**Result:** GRMP可以有效地规避先进的防御系统，导致模型精度和整体性能的显著下降。

**Conclusion:** 基于图表示的模型中毒（GRMP）是一种针对联邦大型语言模型（FedLLMs）的有效攻击，能够规避现有防御。未来的研究应侧重于图感知安全聚合方法、专门针对FedLLMs的漏洞指标以及评估框架，以增强联邦语言模型部署的鲁棒性。

> **ai_Abstract:** 本文探讨了联邦大型语言模型（FedLLMs）面临的模型中毒攻击威胁。文章首先回顾了现有攻击和防御的局限性，特别是指出当前防御策略在面对非IID数据和自适应攻击者时的不足。随后，文章详细介绍了基于图表示的模型中毒（GRMP）这一新型攻击方式，该攻击利用梯度的高阶相关性生成难以察觉的恶意更新，从而有效规避现有防御并降低模型性能。最后，文章提出了一个未来研究路线图，强调了开发图感知安全聚合方法和专门评估框架的重要性，以提升FedLLMs的鲁棒性。

> **摘要翻译:** 联邦大型语言模型（FedLLMs）在无线网络中实现了强大的生成能力，同时保护了数据隐私。然而，FedLLMs仍然容易受到模型中毒攻击。本文首先回顾了FedLLMs模型中毒技术和现有防御机制的最新进展，强调了关键局限性，尤其是在处理非IID文本数据分布时。当前的防御策略主要采用基于距离或相似度的异常检测机制，其依赖于恶意更新与良性统计模式显著不同的假设。然而，这一假设在对抗针对数十亿参数LLMs的自适应攻击者时变得不足。本文进一步研究了基于图表示的模型中毒（GRMP），这是一种新兴的攻击范式，它利用良性客户端梯度之间的高阶相关性来精心制作与合法更新无法区分的恶意更新。GRMP可以有效地规避先进的防御系统，导致模型精度和整体性能的显著下降。此外，本文概述了一个前瞻性的研究路线图，强调了图感知安全聚合方法、专门针对FedLLMs的漏洞指标以及评估框架的必要性，以增强联邦语言模型部署的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [127] [White-Basilisk: A Hybrid Model for Code Vulnerability Detection](https://arxiv.org/abs/2507.08540)
> *White-Basilisk: 一种用于代码漏洞检测的混合模型*

*Ioannis Lamprou, Alexander Shevtsov, Ioannis Arapakis, Sotiris Ioannidis* | **Category: cs.CR, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 代码漏洞检测, 混合模型, Mamba, 专家混合, 计算效率

**Comment:** 

> **TL;DR:** White-Basilisk是一种紧凑高效的混合模型，结合Mamba层、线性自注意力、MoE框架，在代码漏洞检测中实现SOTA性能，超越大型LLM的上下文限制。

**AI_Comments:** White-Basilisk的创新之处在于其混合架构，特别是结合了Mamba层、线性自注意力和MoE，以及其仅200M参数量就达到SOTA性能并超越LLM上下文限制的能力。这挑战了AI模型越大越好的普遍假设，为资源受限或需要高效率的领域特定AI应用提供了新的优化方向。

<details>
  <summary>Details</summary>

**Motivation:** 软件漏洞的扩散对网络安全构成重大挑战，需要更有效的检测方法。

**Method:** 引入White-Basilisk，一种新颖的漏洞检测方法。其创新架构集成了Mamba层、线性自注意力以及专家混合（Mixture of Experts）框架。

**Result:** White-Basilisk在漏洞检测任务中取得了最先进的结果，参数量仅为200M。它能够处理前所未有的长序列，对大型代码库进行单次全面分析，超越了当前大型语言模型的上下文限制。该模型在不平衡的真实世界数据集上表现出强大的性能，同时保持计算效率。

**Conclusion:** 该研究不仅在代码安全领域建立了新基准，还提供了经验证据，表明紧凑、高效设计的模型在专业任务中可以胜过大型模型，可能重新定义AI开发中针对特定领域应用的优化策略。

> **ai_Abstract:** White-Basilisk是一种创新的混合模型，用于代码漏洞检测。它结合了Mamba层、线性自注意力机制和专家混合框架，以2亿参数量实现了代码漏洞检测的SOTA性能。该模型能处理超长代码序列，超越了传统LLM的上下文限制，并在真实世界不平衡数据集上表现出色，同时保持高计算效率。研究表明，紧凑高效的模型在特定任务中也能超越大型模型。

> **摘要翻译:** 软件漏洞的扩散对网络安全构成了重大挑战，需要更有效的检测方法。我们引入了White-Basilisk，一种新颖的漏洞检测方法，它展示了卓越的性能，同时挑战了人工智能模型扩展中的普遍假设。White-Basilisk利用集成了Mamba层、线性自注意力以及专家混合（Mixture of Experts）框架的创新架构，在漏洞检测任务中以仅200M的参数量实现了最先进的结果。该模型处理前所未有的序列长度的能力，使得能够对大量代码库进行单次全面分析，超越了当前大型语言模型（LLMs）的上下文限制。White-Basilisk在不平衡的真实世界数据集上表现出强大的性能，同时保持了计算效率，便于在不同组织规模下部署。这项研究不仅在代码安全领域建立了新基准，还提供了经验证据，表明紧凑、高效设计的模型在专业任务中可以胜过大型模型，可能重新定义人工智能开发中针对特定领域应用的优化策略。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [169] [PurpCode: Reasoning for Safer Code Generation](https://arxiv.org/abs/2507.19060)
> *PurpCode：推理以实现更安全的代码生成*

*Jiawei Liu, Nirav Diwan, Zhe Wang, Haoyu Zhai, Xiaona Zhou, Kiet A. Nguyen, Tianjiao Yu, Muntasir Wahed, Yinlin Deng, Hadjer Benkraouda, Yuxiang Wei, Lingming Zhang, Ismini Lourentzou, Gang Wang* | **Category: cs.CR, cs.CL, cs.LG, cs.SE** | **Updated: 2025-07-31**

**Keywords:** 代码生成, 网络安全, 推理模型, 强化学习, 安全编码

**Comment:** 

> **TL;DR:** PurpCode是一种训练安全代码推理模型的方法，通过两阶段训练和红队数据生成安全代码并抵御恶意网络活动，其模型PurpCode-32B在网络安全方面表现出色。

**AI_Comments:** PurpCode的创新之处在于其两阶段训练方法，特别是结合了显式规则学习和强化学习来解决代码生成中的安全性问题。通过引入内部红队生成高质量的负面示例数据，有效提升了模型的鲁棒性。该研究对于AI生成代码的安全性具有重要意义，尤其是在防御恶意网络活动方面。其在保持实用性同时提升安全性的平衡策略也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 现有代码生成模型可能生成不安全的代码或助长恶意网络活动，因此需要一种训练安全代码推理模型的方法来生成安全代码并防御恶意网络活动。

**Method:** 引入PurpCode，一种训练安全代码推理模型的后训练方法，分为两个阶段：(i) 规则学习，明确教导模型参考网络安全规则生成无漏洞代码并避免促进恶意网络活动；(ii) 强化学习，通过多样化、多目标奖励机制优化模型安全性并保持模型效用。为了获取全面的网络安全数据，进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型中的不安全网络活动。

**Result:** 基于PurpCode开发了推理型编码模型PurpCode-32B，它展示了最先进的网络安全性能，超越了各种前沿模型。同时，该对齐方法降低了模型在通用和网络安全特定场景中的过度拒绝率，并保持了模型在代码生成和通用安全知识方面的效用。

**Conclusion:** PurpCode是首个用于训练安全代码推理模型的后训练方案，能够生成安全代码并抵御恶意网络活动，其开发的模型PurpCode-32B在网络安全方面表现出色，并有效平衡了安全性与实用性。

> **ai_Abstract:** PurpCode是一种新颖的后训练方法，用于开发能够生成安全代码并抵御网络攻击的推理模型。它采用两阶段训练（规则学习和强化学习）并利用内部红队生成的高质量网络安全数据。基于此方法开发的PurpCode-32B模型在网络安全性能上超越了现有模型，并有效平衡了安全性与实用性，降低了过度拒绝率。

> **摘要翻译:** 我们引入了 PurpCode，这是首个用于训练安全代码推理模型的后训练方案，旨在生成安全代码并抵御恶意网络活动。PurpCode 分两个阶段训练推理模型：(i) 规则学习，明确教导模型参考网络安全规则以生成无漏洞代码并避免助长恶意网络活动；(ii) 强化学习，通过多样化、多目标奖励机制优化模型安全性并保持模型实用性。为了为训练管道提供全面的网络安全数据，我们进行了内部红队演练，基于真实世界任务合成全面且高覆盖率的提示，以诱导模型中的不安全网络活动。基于 PurpCode，我们开发了一个基于推理的编码模型，即 PurpCode-32B，它展示了最先进的网络安全性能，超越了各种前沿模型。同时，我们的对齐方法降低了模型在通用和网络安全特定场景中的过度拒绝率，同时在代码生成和通用安全知识方面保持了模型的实用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [329] [UTrace: Poisoning Forensics for Private Collaborative Learning](https://arxiv.org/abs/2409.15126)
> *UTrace：私有协同学习中的投毒溯源*

*Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 隐私保护机器学习, 数据投毒, 溯源, 梯度相似性, 安全多方计算

**Comment:** 28 pages, 10 figures; update ack

> **TL;DR:** UTrace是一个用于隐私保护机器学习（PPML）中投毒攻击的用户级溯源框架，通过计算梯度相似性来识别恶意数据贡献者，有效应对低投毒率和多所有者投毒。

**AI_Comments:** UTrace的创新之处在于其能够在隐私保护机器学习环境下实现用户级投毒溯源，这在不暴露原始私有数据的情况下识别恶意行为者至关重要。其利用梯度相似性进行责任归因，并对多所有者分布式投毒攻击表现出色的鲁棒性，是其核心优势。此外，低存储开销的梯度检查点机制提升了该方法在实际部署中的可行性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 隐私保护机器学习（PPML）虽然提升了数据隐私，但同时也加剧了数据投毒的风险。现有安全多方计算（MPC）机制无法完全缓解所有投毒攻击，因此需要补充现有防御措施来识别和溯源投毒行为。

**Method:** UTrace是一个用户级投毒攻击溯源框架。它通过聚合数据所有者数据集中最相关样本的梯度相似性度量来计算用户责任分数，从而识别投毒者。该方法还引入了低存储开销的梯度检查点技术，以便在部署时即使数据所有者不在场也能进行溯源。此外，UTrace设计了多项优化措施以减少MPC环境下的溯源时间和通信开销。

**Result:** UTrace在低投毒率下表现出高效性，并且与现有基于反学习的方法不同，它对分布在多个数据所有者之间的投毒攻击具有弹性。在四种数据集和三种数据模态（视觉、文本、恶意软件）上进行了全面评估，结果显示UTrace对10种不同的投毒攻击均有效。

**Conclusion:** UTrace为隐私保护协同学习提供了一个有效的用户级投毒攻击溯源框架，通过梯度相似性计算用户责任分数，能够补充现有防御机制，提升了PPML的安全性。

> **ai_Abstract:** 本文提出了UTrace，一个用于隐私保护机器学习（PPML）中数据投毒攻击的用户级溯源框架。该框架通过计算并聚合数据所有者数据集中相关样本的梯度相似性来确定用户责任分数，从而有效识别投毒者。UTrace在低投毒率下表现出色，并对跨多个数据所有者的投毒攻击具有鲁棒性，优于现有基于反学习的方法。此外，UTrace引入了低存储开销的梯度检查点机制，并设计了优化方案以减少溯源时间和通信。在多种数据集和数据模态上的全面评估验证了UTrace对10种投毒攻击的有效性。

> **摘要翻译:** 隐私保护机器学习（PPML）允许多个数据所有者将其数据私密地贡献给一组服务器，这些服务器运行安全多方计算（MPC）协议来训练一个联合ML模型。在这些协议中，输入数据在整个训练过程中保持私密，并且只提供最终的模型。虽然这种方法有利于隐私，但它也加剧了数据投毒的风险，即受损的数据所有者通过贡献恶意数据集来诱导不良模型行为。现有的MPC机制可以缓解某些投毒攻击，但这些措施并不详尽。为了补充现有的投毒防御，我们引入了UTrace：一个用于PPML中投毒攻击用户级溯源的框架。UTrace使用在数据所有者数据集中最相关样本上聚合的梯度相似性度量来计算用户责任分数。UTrace在低投毒率下有效，并且与现有基于反学习的方法不同，它对分布在多个数据所有者之间的投毒攻击具有弹性。我们引入了低存储开销的梯度检查点方法，使得在部署时没有数据所有者的情况下也能进行溯源。我们还设计了几种优化方案，以减少MPC中的溯源时间和通信。我们对UTrace在来自三种数据模态（视觉、文本和恶意软件）的四个数据集上进行了全面评估，并展示了其对10种投毒攻击的有效性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [357] [ExclaveFL: Providing Transparency to Federated Learning using Exclaves](https://arxiv.org/abs/2412.10537)
> *ExclaveFL：使用飞地为联邦学习提供透明度*

*Jinnan Guo, Kapil Vaswani, Andrew Paverd, Peter Pietzuch* | **Category: cs.CR, cs.DC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 可信执行环境, 侧信道攻击, 数据完整性, 透明度

**Comment:** 

> **TL;DR:** ExclaveFL通过将可信执行环境（TEEs）用作不含秘密的“飞地”并对运行时数据转换进行认证，为联邦学习提供端到端完整性和透明度，有效抵御侧信道攻击，且开销低。

**AI_Comments:** ExclaveFL的创新点在于其“飞地”范式，将TEEs设计为不含秘密的执行环境，并结合运行时数据转换认证，有效规避了传统TEE方案中侧信道攻击对密钥泄露的风险。这显著增强了联邦学习的透明度和完整性，尤其是在对抗高级攻击方面。其低开销也表明了该方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 在联邦学习中，恶意数据提供者可能在不被发现的情况下偏离训练协议，从而损害训练模型。现有利用可信执行环境（TEEs）的解决方案通常未考虑针对TEEs的侧信道攻击，但此类攻击可能泄露密钥，使攻击者能够冒充TEE并任意偏离正确的训练协议，从而破坏安全属性。

**Method:** 本文提出了ExclaveFL，一个联邦学习平台。它引入了一种新范式，将现有TEEs用作“飞地”——即不包含任何秘密、免疫侧信道攻击的完整性保护执行环境。与以往认证TEE本身并将其绑定到TEE持有密钥的方法不同，ExclaveFL在运行时认证单个数据转换。这些运行时认证形成一个可检查的认证数据流图，以确保联邦学习训练任务满足声明，例如检测与正确计算的偏差。ExclaveFL通过扩展流行的NVFlare联邦学习框架实现。

**Result:** ExclaveFL与不使用TEEs的相同联邦学习框架相比，引入的开销不到10%，同时提供了更强的安全保障。

**Conclusion:** ExclaveFL成功地为联邦学习提供了端到端完整性和透明度，即使在存在TEEs侧信道攻击的情况下也能保持安全，并且具有较低的性能开销。

> **ai_Abstract:** 本文提出了ExclaveFL，一个联邦学习平台，旨在解决现有方案中恶意数据提供者可能在不被检测的情况下偏离训练协议以及可信执行环境（TEEs）面临侧信道攻击的问题。ExclaveFL通过将TEEs用作不含秘密的“飞地”并对运行时的数据转换进行认证，构建一个可验证的认证数据流图，从而提供端到端的数据完整性和透明度。实验证明，ExclaveFL与不使用TEE的联邦学习框架相比，开销低于10%，同时提供了更强的安全保障。

> **摘要翻译:** 在联邦学习（FL）中，数据提供者在不披露其训练数据的情况下共同训练一个模型。尽管其具有固有的隐私优势，但恶意的数数据提供者可能在不被发现的情况下简单地偏离正确的训练协议，这可能会损害训练模型。虽然目前的解决方案已经探索使用可信执行环境（TEEs）来对抗此类攻击，但它们通常假设针对TEEs的侧信道攻击不在考虑范围之内。然而，此类侧信道攻击可能会破坏基于TEE的FL框架的安全属性，其方式不是提取FL数据，而是泄露允许攻击者冒充TEE并任意偏离正确训练协议的密钥。
我们描述了ExclaveFL，一个FL平台，即使在存在TEEs侧信道攻击的情况下也能提供端到端完整性和透明度。我们提出了一种新范式，其中现有TEEs被用作飞地——即不包含任何秘密、免疫侧信道攻击的完整性保护执行环境。而以前的方法是认证TEE本身并将此认证绑定到TEE持有的密钥，ExclaveFL在运行时认证单个数据转换。这些运行时认证形成一个认证数据流图，可以检查该图以确保FL训练任务满足声明，例如与正确计算的偏差。我们通过扩展流行的NVFlare FL框架来使用飞地实现了ExclaveFL，并实验表明，与不使用TEEs的相同FL框架相比，ExclaveFL引入的开销不到10%，同时提供了更强的安全保障。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [434] [Unveiling Dynamic Binary Instrumentation Techniques](https://arxiv.org/abs/2508.00682)
> *揭示动态二进制插桩技术*

*Oscar Llorente-Vazquez, Xabier Ugarte-Pedrero, Igor Santos-Grueiro, Pablo Garcia Bringas* | **Category: cs.CR, cs.SE** | **Updated: 2025-08-01**

**Keywords:** 动态二进制插桩, DBI, 运行时插桩, 性能评估, 技术比较

**Comment:** 

> **TL;DR:** 本文深入探讨了动态二进制插桩（DBI）技术，比较了不同方法在性能和适用性方面的优缺点，指出没有一种技术在所有情况下都表现最佳。

**AI_Comments:** 这篇论文对动态二进制插桩（DBI）领域进行了系统性的梳理和比较，其创新之处在于将进程级和全系统级方法统一起来进行分析，并对它们的性能进行了实证评估。其重要性在于为研究人员和开发者选择合适的DBI技术提供了有价值的指导，强调了不存在通用最优解的现实。论文的价值在于其对现有DBI技术的深入剖析和性能对比，有助于读者理解不同方法的适用性和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 动态二进制插桩（DBI）技术在工业界和学术界广泛应用，但多年来提出了多种不同的方法，每种方法都有其局限性或适用范围。因此，需要对这些多样化的DBI技术进行系统性的梳理和分析，以理解它们的构建块、底层技术、性能和适用场景。

**Method:** 本文对进程级和全系统级的动态二进制插桩（DBI）方法进行了综合分析。具体方法包括：描述其构建块、分析底层插桩技术并比较它们对不同原语和运行时事件的插桩能力。此外，还评估了每种原语实现时的性能，并强调了相关观察结果。

**Result:** 研究结果表明，在所有情况下，没有单一的动态二进制插桩技术优于其他所有技术。

**Conclusion:** 结论是，动态二进制插桩领域没有“一劳永逸”的解决方案；不同的技术在不同的应用场景和性能要求下各有优劣。

> **ai_Abstract:** 本文对动态二进制插桩（DBI）技术进行了全面回顾和分析，涵盖了进程级和全系统级方法。文章详细阐述了不同DBI技术的构建块、底层实现以及它们对各种运行时事件的插桩能力，并评估了其性能。研究发现，没有一种DBI技术能在所有场景下都表现最佳，每种技术都有其特定的优缺点和适用范围。

> **摘要翻译:** 动态二进制插桩 (DBI) 是一组在运行时对程序进行插桩的技术，使得监控和修改已编译二进制文件或整个系统的执行成为可能。DBI 被用于无数的安全应用和分析，并在工业界和学术界的许多领域中得到广泛应用。多年来，基于不同技术并实现多样化方法的几种 DBI 方法被提出。每种解决方案都试图克服某些限制，但它们有时会带来其他缺点。有些专门用于某个特定领域或任务，而另一些则具有更广泛的范围。
在本文中，我们深入探讨了 DBI 的复杂性，汇集了进程级和全系统级的方法。我们描绘了它们的构建块并分析了底层的插桩技术，比较了它们插桩不同原语和运行时事件的能力。然后，我们评估了它们在实现每个原语时的性能，并强调了相关的观察结果。我们的结果表明，在所有情况下，没有单一的技术比其他技术更好。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [739] [Fine-Grained Privacy Extraction from Retrieval-Augmented Generation Systems via Knowledge Asymmetry Exploitation](https://arxiv.org/abs/2507.23229)
> *通过知识不对称利用从检索增强生成系统中进行细粒度隐私提取*

*Yufei Chen, Yao Wang, Haibin Zhang, Tao Gu* | **Category: cs.CR** | **Updated: 2025-07-31**

**Keywords:** 检索增强生成, 隐私提取, 黑盒攻击, 知识不对称, 链式思考推理

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的黑盒攻击框架，通过利用检索增强生成（RAG）系统和标准大型语言模型之间的知识不对称，实现跨异构知识环境的细粒度隐私提取，解决了现有攻击在隔离敏感内容和跨域鲁棒性方面的不足。

**AI_Comments:** 本文的创新点在于提出了一个黑盒攻击框架，通过利用知识不对称性实现对RAG系统中细粒度隐私信息的精确提取。它解决了现有攻击在隔离特定敏感内容和跨领域泛化方面的局限性，特别强调了无需预定义知识的迭代细化能力，这对于实际应用具有重要意义。该研究不仅揭示了RAG系统的潜在隐私漏洞，也为未来开发更鲁棒的防御机制奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）系统虽然通过集成外部知识库增强了大型语言模型（LLM），但也带来了显著的隐私风险。现有的针对RAG系统的隐私攻击虽然能触发数据泄露，但往往无法准确地从混合响应中隔离出源自知识库的句子，并且在应用于多个领域时缺乏鲁棒性。本文旨在解决这些挑战。

**Method:** 本文提出了一种新颖的黑盒攻击框架，通过利用RAG系统和标准LLM之间的知识不对称来实现细粒度隐私提取。该方法采用链式思考推理策略来创建自适应提示，以引导RAG系统偏离敏感内容。具体步骤包括：首先，分解对抗性查询以最大化信息差异；其次，应用语义关系评分以解决词汇和句法歧义；最后，在此特征分数上训练一个神经网络以精确识别包含私有信息的句子。该框架通过迭代细化，无需预定义知识即可泛化到未见领域。

**Result:** 实验结果表明，在单领域场景中，隐私提取率超过91%，在多领域场景中达到83%。在案例研究中，敏感句子暴露量减少了65%以上。

**Conclusion:** 这项工作弥合了RAG系统攻击与防御之间的差距，实现了私有信息的精确提取，并为自适应缓解措施奠定了基础。

> **ai_Abstract:** 本文提出了一种针对检索增强生成（RAG）系统的新型黑盒攻击框架，旨在解决现有隐私攻击在精确隔离知识库敏感信息和跨领域泛化能力方面的不足。该框架利用RAG系统与标准大型语言模型之间的知识不对称性，采用链式思考推理策略，通过分解对抗性查询、语义关系评分和神经网络分类，实现对混合响应中细粒度隐私信息的精确提取。实验证明，该方法在单领域和多领域场景下均表现出高提取率和显著的敏感信息暴露减少，并能泛化到未见领域，为RAG系统的隐私攻击与防御提供了新的视角和基础。

> **摘要翻译:** 检索增强生成（RAG）系统通过集成外部知识库增强了大型语言模型（LLM），但这种进步也带来了显著的隐私风险。现有针对RAG系统的隐私攻击可以触发数据泄露，但往往无法准确地从混合响应中隔离出源自知识库的句子。它们在应用于多个领域时也缺乏鲁棒性。本文通过提出一种新颖的黑盒攻击框架来应对这些挑战，该框架利用RAG和标准LLM之间的知识不对称，以实现跨异构知识环境的细粒度隐私提取。我们提出了一种链式思考推理策略，创建自适应提示以引导RAG系统远离敏感内容。具体来说，我们首先分解对抗性查询以最大化信息差异，然后应用语义关系评分来解决词汇和句法歧义。我们最终在这些特征分数上训练一个神经网络，以精确识别包含私有信息的句子。与先前的工作不同，我们的框架通过迭代细化，无需预定义知识即可泛化到未见领域。实验结果表明，在单领域场景中，我们实现了超过91%的隐私提取率，在多领域场景中达到83%，在案例研究中将敏感句子暴露量减少了65%以上。这项工作弥合了RAG系统攻击与防御之间的差距，实现了私有信息的精确提取，同时为自适应缓解措施提供了基础。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [753] [Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems](https://arxiv.org/abs/2507.23453)
> *基于LLM的评估系统中盲攻击检测的反事实评估*

*Lijia Liu, Takumi Kondo, Kyohei Atarashi, Koh Takeuchi, Jiyi Li, Shigeru Saito, Hisashi Kashima* | **Category: cs.CR, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 反事实评估, 盲攻击, LLM评估系统, 提示注入, 安全性

**Comment:** 

> **TL;DR:** 本文提出了一种结合反事实评估（CFE）的框架，用于检测基于LLM的评估系统中的盲攻击，显著提高了安全性。

**AI_Comments:** 该论文的创新点在于引入了反事实评估（CFE）来检测LLM评估系统中的盲攻击，这是一种新颖且有效的防御策略。其重要性在于提升了LLM在敏感评估场景下的可靠性和安全性。该方法通过在两种不同的“真实”条件下验证答案，巧妙地利用了LLM的推理特性来识别恶意行为，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决基于大型语言模型（LLM）的评估系统面临的提示注入威胁，特别是针对一种称为“盲攻击”的威胁，即候选答案独立于真实答案被精心设计以欺骗评估者。

**Method:** 本文提出了一个将标准评估（SE）与反事实评估（CFE）相结合的框架。CFE通过对提交的答案进行重新评估，但使用一个刻意错误的真实答案作为参照。如果系统在标准和反事实条件下都验证了某个答案，则认为检测到攻击。

**Result:** 实验表明，虽然标准评估极易受到攻击，但SE+CFE框架显著提高了安全性，在攻击检测方面有显著提升，同时性能权衡最小。

**Conclusion:** 结合反事实评估的框架能够有效检测基于LLM的评估系统中的盲攻击，并在提高安全性的同时保持了良好的性能。

> **ai_Abstract:** 本文针对基于LLM的评估系统中的提示注入威胁，特别是盲攻击，提出了一种防御框架。该框架结合了标准评估和反事实评估（CFE），通过在两种条件下验证答案来检测攻击。实验证明，与标准评估相比，该方法显著提升了攻击检测能力，同时对性能影响甚微。

> **摘要翻译:** 本文研究了基于LLM的评估系统针对提示注入的防御。我们形式化了一种称为盲攻击的威胁，即候选答案独立于真实答案精心制作以欺骗评估者。为了对抗此类攻击，我们提出了一个框架，通过反事实评估（CFE）增强标准评估（SE），该评估针对一个刻意错误的真实答案重新评估提交的内容。如果系统在标准和反事实条件下都验证了一个答案，则检测到攻击。实验表明，虽然标准评估极易受到攻击，但我们的SE+CFE框架显著提高了安全性，通过提升攻击检测能力，同时性能权衡最小。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [767] [LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora](https://arxiv.org/abs/2507.23611)
> *基于LLM的从截图中识别信息窃取器感染向量：以Aurora为例*

*Estelle Ruellan, Eric Clay, Nicholas Ascoli* | **Category: cs.CR, cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 信息窃取器, LLM, 感染向量, 屏幕截图, 威胁情报

**Comment:** 

> **TL;DR:** 利用LLM分析信息窃取器感染截图，以识别感染向量并追踪恶意活动，提高威胁情报能力。

**AI_Comments:** 这篇论文的创新点在于首次将LLM应用于信息窃取器感染截图的被动分析，填补了现有研究的空白。通过利用LLM的图像理解和文本提取能力，实现了大规模自动化识别感染向量和追踪恶意活动，为威胁情报提供了新的、可扩展的分析途径。其重要性在于提供了一种应对海量窃取器日志的有效手段，有助于实现早期干预和提高网络安全防御能力。

<details>
  <summary>Details</summary>

**Motivation:** 每年报告大量信息窃取器日志，传统手动分析和大规模缓解不切实际。现有研究多关注主动检测，而对窃取器日志及相关工件（特别是感染截图）的被动分析存在显著空白。

**Method:** 引入一种新颖的方法，利用大型语言模型（LLMs，具体是gpt-4o-mini）分析感染截图，提取潜在的妥协指标（IoCs），映射感染向量，并追踪活动。以Aurora信息窃取器为例，演示LLM如何处理截图以识别恶意URL、安装程序文件和被利用的软件主题等感染向量。

**Result:** 从1000张截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件分发方法和社会工程策略。通过关联提取的文件名、URL和感染主题，识别了三个不同的恶意软件活动。

**Conclusion:** 该研究通过将恶意软件分析从传统的基于日志的方法转向利用感染截图的被动、工件驱动的方法，提出了一种可扩展的识别感染向量和实现早期干预的方法，展示了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。

> **ai_Abstract:** 本文提出一种利用大型语言模型（LLMs， specifically gpt-4o-mini）分析信息窃取器感染截图的新方法。针对Aurora信息窃取器，该方法能从截图中识别恶意URL、安装程序文件等感染向量，并追踪恶意活动。实验从1000张截图中提取了大量可操作的IoCs，并识别出多个恶意软件活动，展示了LLM在威胁情报和早期干预方面的潜力，将恶意软件分析从传统日志转向了基于工件的被动分析。

> **摘要翻译:** 信息窃取器从受感染系统中窃取凭据、会话Cookie和敏感数据。2024年报告的窃取器日志超过2900万条，大规模手动分析和缓解几乎不可行/不切实际。虽然大多数研究侧重于主动恶意软件检测，但在利用窃取器日志及其相关工件进行被动分析方面存在显著空白。具体来说，感染工件，如在受损时捕获的屏幕截图，在现有文献中很大程度上被忽视。本文介绍了一种利用大型语言模型（LLMs），更具体地说是gpt-4o-mini，分析感染屏幕截图以提取潜在的妥协指标（IoCs）、映射感染向量和追踪活动的新颖方法。我们以Aurora信息窃取器为例，展示了LLM如何处理屏幕截图以识别感染向量，例如恶意URL、安装程序文件和被利用的软件主题。我们的方法从1000张屏幕截图中提取了337个可操作的URL和246个相关文件，揭示了关键的恶意软件分发方法和社会工程策略。通过关联提取的文件名、URL和感染主题，我们识别了三个不同的恶意软件活动，证明了LLM驱动分析在揭示感染工作流程和增强威胁情报方面的潜力。通过将恶意软件分析从传统的基于日志的检测方法转向利用感染屏幕截图的被动、工件驱动的方法，本研究提出了一种可扩展的识别感染向量并实现早期干预的方法。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [787] [Preliminary Investigation into Uncertainty-Aware Attack Stage Classification](https://arxiv.org/abs/2508.00368)
> *攻击阶段不确定性感知分类的初步研究*

*Alessandro Gaudenzi, Lorenzo Nodari, Lance Kaplan, Alessandra Russo, Murat Sensoy, Federico Cerutti* | **Category: cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 高级持续性威胁, 攻击阶段分类, 不确定性感知, 证据深度学习, 分布外检测

**Comment:** Proceedings for SPAIML2025 workshop, 26/10/2025 Bologna Italy,
  co-located with ECAI2025

> **TL;DR:** 本研究提出一种基于证据深度学习（EDL）的方法，用于在存在不确定性和分布外（OOD）输入的情况下，对高级持续性威胁（APT）的攻击阶段进行分类。

**AI_Comments:** 本论文创新性地将证据深度学习应用于网络安全中的一个关键问题：实时、不确定性感知地对APT攻击阶段进行分类。其量化不确定性和检测分布外输入的能力尤其有价值，因为它直接解决了网络威胁的动态性和对抗性，相比传统的二元分类系统提供了显著改进。对OOD输入的鲁棒性是其关键优势，增强了模型的实际适用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统网络安全检测系统仅以二元方式（良性或恶意）识别恶意活动，未能考虑攻击的进展，而有效的响应策略依赖于对攻击当前阶段的准确推断。高级持续性威胁（APTs）因其长期性、多阶段性和复杂性构成重大挑战，因此需要在不确定性下准确推断攻击阶段，并对分布外（OOD）输入具有鲁棒性。

**Method:** 本文提出了一种基于证据深度学习（EDL）的分类方法。EDL通过输出可能阶段的狄利克雷分布参数来建模预测不确定性。这使得系统不仅能预测攻击最可能的阶段，还能指示何时存在不确定性或输入超出训练分布。

**Result:** 在模拟环境中的初步实验表明，所提出的模型能够以校准的置信度准确推断攻击阶段，同时有效检测分布外（OOD）输入，这可能预示着攻击者策略的变化。

**Conclusion:** 研究结果支持在动态和对抗性环境中部署不确定性感知模型进行分阶段威胁检测的可行性。

> **ai_Abstract:** 本论文旨在解决在不确定性下准确分类高级持续性威胁（APT）阶段的挑战，这对于有效的网络安全响应至关重要。研究提出了一种基于证据深度学习（EDL）的方法，通过使用狄利克雷分布来建模预测不确定性。该方法不仅能够预测攻击阶段，还能识别不确定性并检测分布外（OOD）输入。初步实验证明，该模型能够以校准的置信度准确推断攻击阶段，并有效检测新的攻击者策略，从而支持在分阶段威胁检测中应用不确定性感知模型。

> **摘要翻译:** 高级持续性威胁（APTs）因其长期性、多阶段性以及操作者的复杂性，在网络安全领域构成重大挑战。传统的检测系统通常侧重于以二元方式（良性或恶意）识别恶意活动，而没有考虑攻击的进展。然而，有效的响应策略依赖于对攻击当前阶段的准确推断，因为反措施必须根据对手是处于早期侦察阶段还是正在积极进行利用或数据外泄来量身定制。这项工作解决了不确定性下攻击阶段推断的问题，重点关注对分布外（OOD）输入的鲁棒性。我们提出了一种基于证据深度学习（EDL）的分类方法，该方法通过输出可能阶段的狄利克雷分布参数来模拟预测不确定性。这使得系统不仅能预测攻击最可能的阶段，还能指示何时存在不确定性或输入超出训练分布。在模拟环境中的初步实验表明，所提出的模型能够以校准的置信度准确推断攻击阶段，同时有效检测OOD输入，这可能表明攻击者策略的变化。这些结果支持在动态和对抗性环境中部署不确定性感知模型进行分阶段威胁检测的可行性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [788] [Polynomial Lattices for the BIKE Cryptosystem](https://arxiv.org/abs/2507.23641)
> *BIKE密码系统中的多项式格*

*Michael Schaller* | **Category: cs.CR, 11T71, 94A60** | **Updated: 2025-07-31**

**Keywords:** 多项式格, BIKE密码系统, 弱密钥, 最短向量问题, 规约基

**Comment:** 

> **TL;DR:** 本文介绍了BIKE密码系统公钥中出现的一种多项式环上的2阶格，研究了其性质，并推广了弱密钥恢复的方法。通过获得规约基，可以检查更多的弱密钥。

**AI_Comments:** 本文的创新之处在于明确地构建并分析了BIKE密码系统公钥所对应的多项式格。其重要性在于，通过提供一种更全面的方法来识别弱密钥（即计算规约基而非仅单个最短向量），从而加强了BIKE的密码分析，有助于更深入地理解BIKE的安全性。

<details>
  <summary>Details</summary>

**Motivation:** 研究BIKE密码系统公钥产生的格结构，并推广弱密钥恢复的方法，以期发现更多弱密钥。

**Method:** 引入并研究了BIKE密码系统公钥产生的多项式环上的2阶格的性质。通过获得该格的规约基，而非仅仅最短向量，来推广弱密钥的恢复。

**Result:** 研究表明，先前的工作隐式地解决了所构建格中的最短向量问题。本文的方法通过获得格的规约基，使得检查更多弱密钥成为可能。

**Conclusion:** 通过对BIKE密码系统公钥产生的多项式格进行深入分析并获得其规约基，可以更有效地识别和检查比以往方法更多的弱密钥。

> **ai_Abstract:** 本文引入并研究了BIKE密码系统公钥中出现的一种多项式环上的2阶格。研究表明，之前的弱密钥恢复方法隐式地解决了该格中的最短向量问题。作者通过获得该格的规约基，而非仅限于寻找最短向量，从而推广了弱密钥的恢复方法，使得检查更多弱密钥成为可能。

> **摘要翻译:** 本文介绍了BIKE密码系统\cite{aragon2022bike}公钥中出现的一种多项式环上的2阶格。秘密密钥是该格中的一个稀疏向量。我们研究了该格的性质，并推广了\cite{BardetDLO16}中弱密钥恢复的方法。特别是，我们表明他们隐式地解决了我们所构建的格中的最短向量问题。我们不仅找到了最短向量，还获得了该格的一个规约基，这使得检查更多弱密钥成为可能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [864] [LeakSealer: A Semisupervised Defense for LLMs Against Prompt Injection and Leakage Attacks](https://arxiv.org/abs/2508.00602)
> *LeakSealer：一种针对LLM提示注入和泄漏攻击的半监督防御*

*Francesco Panebianco, Stefano Bonfanti, Francesco Trovò, Michele Carminati* | **Category: cs.CR, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** LLM安全, 提示注入, 数据泄露, 半监督防御, LeakSealer

**Comment:** 22 pages, preprint

> **TL;DR:** 本文提出LeakSealer，一个半监督防御框架，旨在保护大型语言模型（LLMs）免受提示注入和数据泄露攻击，通过结合历史数据分析、静态取证和动态人机协作实现高效防御。

**AI_Comments:** 该论文的创新点在于提出了一个结合历史数据分析、静态取证和动态人机协作的全面防御框架LeakSealer，并且它是模型无关的。其半监督方法利用了现有数据，提高了防御效率。在RAG应用中解决数据泄露问题也具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的广泛部署带来了越狱和数据泄露等安全威胁。检索增强生成（RAG）虽然提升了LLM的上下文感知能力，却也无意中引入了敏感信息泄露的漏洞。

**Method:** 本文的贡献有两方面：1. 引入一种分析LLM系统历史交互数据的方法，用于生成按主题分类的使用图（包括对抗性交互），并提供跟踪越狱攻击模式演变的取证见解。2. 提出LeakSealer，一个模型无关的框架，它结合了用于取证见解的静态分析和人机协作（HITL）管道中的动态防御。该技术识别主题组并检测异常模式，从而实现主动防御机制。

**Result:** 在静态设置中，LeakSealer在ToxicChat数据集上识别提示注入时，实现了最高的精确度和召回率。在动态设置中，PII（个人身份信息）泄露检测的AUPRC达到0.97，显著优于Llama Guard等基线。

**Conclusion:** LeakSealer是一个有效的半监督防御框架，能够有效识别和防御LLM的提示注入和PII泄露攻击，显著优于现有基线。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）面临的提示注入和数据泄露安全威胁，提出了一种名为LeakSealer的半监督防御框架。该框架首先通过分析历史交互数据生成使用图和取证见解，以跟踪攻击模式。其次，LeakSealer结合静态分析和动态人机协作（HITL）管道，识别主题组并检测异常模式，实现主动防御。实验证明，LeakSealer在提示注入检测上表现出高精确度和召回率，在PII泄露检测上显著优于现有基线。

> **摘要翻译:** 大型语言模型（LLMs）的泛化能力使其被广泛部署到各种应用中。然而，这种日益增长的采用也引入了几种安全威胁，特别是越狱和数据泄露攻击。此外，检索增强生成（RAG）虽然增强了LLM响应的上下文感知能力，却无意中引入了可能导致敏感信息泄露的漏洞。我们的贡献是双重的。首先，我们引入了一种分析LLM系统历史交互数据的方法，能够生成按主题分类的使用图（包括对抗性交互）。这种方法进一步提供了跟踪越狱攻击模式演变的取证见解。其次，我们提出了LeakSealer，一个模型无关的框架，它结合了用于取证见解的静态分析和人机协作（HITL）管道中的动态防御。该技术识别主题组并检测异常模式，从而实现主动防御机制。我们在两种场景下对LeakSealer进行了实证评估：(1) 越狱尝试，采用公共基准数据集；(2) PII泄露，由一个经过整理的、带有标签的LLM交互数据集支持。在静态设置中，LeakSealer在ToxicChat数据集上识别提示注入时，实现了最高的精确度和召回率。在动态设置中，PII泄露检测的AUPRC达到0.97，显著优于Llama Guard等基线。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [872] [An Inversion-based Measure of Memorization for Diffusion Models](https://arxiv.org/abs/2405.05846)
> *扩散模型记忆化的一种基于反演的度量方法*

*Zhe Ma, Qingming Li, Xuhong Zhang, Tianyu Du, Ruixiao Lin, Zonghui Wang, Shouling Ji, Wenzhi Chen* | **Category: cs.CR, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 扩散模型, 记忆化, 反演, 隐私保护, 风险评估

**Comment:** Accepted by ICCV 2025

> **TL;DR:** 本研究提出了一种名为InvMM的基于反演的记忆化度量方法，用于量化扩散模型中的训练数据记忆化问题，并可作为风险评估的审计工具。

**AI_Comments:** 该研究提出了一种新颖的、基于反演的记忆化度量方法InvMM，解决了扩散模型中训练数据记忆化这一重要且紧迫的问题。其创新之处在于通过反演噪声分布来量化记忆化，并提出自适应算法以提高准确性。这对于增强扩散模型的信任度、解决版权和隐私问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像生成方面取得了显著进展，但存在训练数据记忆化的问题，引发了版权侵犯和隐私泄露的担忧。因此，需要对扩散模型中的记忆化进行严格分析和可靠量化。

**Method:** 本研究引入了一种名为InvMM的基于反演的记忆化度量方法，该方法基于反演敏感的潜在噪声分布来解释图像的复制。为了准确估计该度量，还提出了一种自适应算法，用于平衡噪声分布的正态性和敏感性。

**Result:** 在四个数据集上对无条件和文本引导的扩散模型进行的综合实验表明，InvMM提供了一种可靠且完整的记忆化量化方法。值得注意的是，InvMM在样本之间是可比较的，可以从对抗的角度揭示记忆化的真实程度，并暗示了记忆化与成员身份的区别。

**Conclusion:** InvMM可以作为开发人员评估记忆化风险的审计工具，从而有助于增强扩散模型的信任度和隐私保护能力。

> **ai_Abstract:** 本研究提出了一种名为InvMM的基于反演的记忆化度量方法，旨在量化扩散模型中训练数据的记忆化问题。该方法通过反演敏感的潜在噪声分布来评估图像复制，并引入自适应算法以提高估计准确性。实验证明，InvMM能可靠且全面地量化记忆化，并能作为评估扩散模型隐私风险的实用工具。

> **摘要翻译:** 在过去的几年里，扩散模型在图像生成方面取得了实质性进展。然而，研究表明扩散模型容易受到训练数据记忆化的影响，引发了对版权侵犯和隐私泄露的重大担忧。本研究深入分析了扩散模型中的记忆化问题。我们引入了InvMM，一种基于反演的记忆化度量方法，它基于反演敏感的潜在噪声分布来解释图像的复制。为了准确估计该度量，我们提出了一种自适应算法，用于平衡噪声分布的正态性和敏感性。在四个数据集上，对无条件和文本引导的扩散模型进行的综合实验表明，InvMM提供了一种可靠且完整的记忆化量化方法。值得注意的是，InvMM在样本之间是可比较的，可以从对抗的角度揭示记忆化的真实程度，并暗示了记忆化与成员身份的区别。在实践中，它可作为开发人员可靠评估记忆化风险的审计工具，从而有助于增强扩散模型的信任度和隐私保护能力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [894] [A Privacy-Preserving DAO Model Using NFT Authentication for the Punishment not Reward Blockchain Architecture](https://arxiv.org/abs/2405.13156)
> *使用NFT认证的惩罚而非奖励区块链架构中的隐私保护型DAO模型*

*Talgar Bayan, Richard Banach* | **Category: cs.CR, cs.SE** | **Updated: 2025-07-31**

**Keywords:** 去中心化自治组织, 非同质化代币, 隐私保护, 惩罚而非奖励区块链, Layer 2

**Comment:** This paper was accepted and presented at the International Conference
  on Blockchain Research and Applications (BCRA 2024), Hangzhou, China, July
  26-27, 2024. An extended version has been submitted to the journal
  Blockchain: Research and Applications (Elsevier) for publication
  consideration. This arXiv version corresponds to the conference-accepted
  manuscript

> **TL;DR:** 本文提出了一种在惩罚而非奖励区块链架构中，利用NFT进行身份管理和隐私保护交互的去中心化自治组织（DAO）模型。

**AI_Comments:** 该论文的创新点在于将双重NFT架构与Layer 2解决方案相结合，以在惩罚而非奖励的区块链环境中实现高效且隐私保护的DAO。通过引入成员NFT和交互NFT，它在身份认证和隐私交互之间取得了平衡。97%的Gas成本降低是一个重要的优势，显示了其在实际应用中的潜力。此外，结合去中心化KYC和灵魂绑定代币特性来增强Sybil攻击抵抗，以及通过智能合约进行声誉管理和惩罚机制，都增加了模型的健壮性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决在惩罚而非奖励（PnR）区块链机制中，实现去中心化自治组织（DAO）的身份管理和隐私保护交互的需求。

**Method:** 该模型引入了部署在Layer 2网络上的双重NFT架构：用于认证和访问控制的成员NFT（\(NFT_{auth}\)）和用于参与者之间私密交互的交互NFT（\(NFT_{priv}\)）。身份管理系统结合了去中心化KYC流程和使用灵魂绑定代币特性的Sybil攻击抵抗。治理通过智能合约运作，管理声誉并执行惩罚措施，包括在检测到不当行为时进行有条件身份披露。

**Result:** Layer 2实现显著降低了97%的Gas成本，并通过跨链机制保持了安全性。

**Conclusion:** 本文成功提出了一个在惩罚而非奖励区块链架构中，通过双重NFT和Layer 2实现隐私保护、高效且安全的DAO模型，并有效管理身份、声誉及惩罚措施。

> **ai_Abstract:** 本文提出了一种创新的去中心化自治组织（DAO）模型，专为“惩罚而非奖励”（PnR）区块链架构设计。该模型利用双重NFT（成员NFT用于认证，交互NFT用于隐私）实现身份管理和私密交互。通过部署在Layer 2网络上，该方案显著降低了97%的Gas成本，并集成了去中心化KYC和基于灵魂绑定代币的Sybil攻击抵抗。治理由智能合约驱动，负责声誉管理和执行惩罚，包括在必要时有条件地披露身份。

> **摘要翻译:** 本文提出了一种去中心化自治组织（DAO）模型，该模型在惩罚而非奖励（PnR）区块链机制中，使用非同质化代币（NFT）进行身份管理和隐私保护交互。所提出的模型引入了部署在Layer 2网络上的双重NFT架构：用于认证和访问控制的成员NFT（\(NFT_{auth}\)）和用于参与者之间私密交互的交互NFT（\(NFT_{priv}\)）。我们的Layer 2实现达到了97%的Gas成本降低，同时通过跨链机制保持了安全性。身份管理系统结合了去中心化KYC流程和使用灵魂绑定代币特性的Sybil攻击抵抗。治理通过智能合约运作，管理声誉并执行惩罚措施，包括为取证目的进行有条件身份披露。当检测到不当行为时，治理通过智能合约运作，管理声誉并执行惩罚措施，包括有条件身份披露。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [919] [On the Formalization of Cryptographic Migration](https://arxiv.org/abs/2408.05997)
> *论密码迁移的形式化*

*Daniel Loebenberger, Stefan-Lukas Gazdag, Daniel Herzinger, Eduard Hirsch, Christian Näther, Jan-Philipp Steghöfer* | **Category: cs.CR** | **Updated: 2025-07-31**

**Keywords:** 密码迁移, 形式化模型, 密码学, 复杂性分析, 后量子密码

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的方法来形式化密码迁移问题，使用数学模型评估其复杂性，并提供了实际案例分析，为未来的密码迁移策略奠定基础。

**AI_Comments:** 这篇论文通过引入形式化模型和利用经典数学工具，为理解和管理复杂的密码迁移项目提供了一个新颖且系统的方法。其创新之处在于将抽象的迁移问题转化为可量化分析的数学模型，并证明了其固有的复杂性。通过提供数值数据和实际案例（如GitLab和电网迁移），增强了研究的实用性和可信度。这项工作对于未来大规模IT基础设施的密码升级和安全转型具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 密码迁移是应用密码学中的经典问题，但其结构、固有的依赖性和复杂性缺乏深入的理解。本文旨在通过形式化方法深入了解这些问题。

**Method:** 本文采用了一种新颖的正式模型来捕捉密码迁移的固有依赖性和复杂性。利用组合学、概率论和组合分析的经典数学结果，评估了迁移大型密码IT基础设施的挑战，并分析了所提出的模型在现实世界模式和实际适用性方面的表现。

**Result:** 研究证明，在适当的意义上，密码迁移表现出一定的预期复杂性。提供了选定参数集的数值数据。分析了模型在现实世界模式和实际适用性方面的表现，并以GitLab向后量子密码的过渡和配电网的多级技术过渡作为具体示例进行了检验。

**Conclusion:** 这项工作为未来密码迁移策略的理论理解和实际实施方面的进步铺平了道路。

> **ai_Abstract:** 本文提出了一种形式化方法来分析密码迁移问题，该方法使用数学模型捕捉其固有的依赖性和复杂性。研究利用组合学和概率论证明了密码迁移具有可预期的复杂性，并提供了数值数据。论文还探讨了模型的实际适用性，并通过GitLab向后量子密码的过渡和配电网的技术迁移等具体案例进行了验证，为密码迁移的理论和实践发展奠定了基础。

> **摘要翻译:** 我们提出了一种新颖的方法，旨在深入了解密码迁移问题的结构，这些问题是应用密码学中的经典问题。我们使用一个形式化模型来捕捉此类转换固有的依赖性和复杂性。利用组合学、概率论和组合分析的经典数学结果，我们评估了迁移大型密码IT基础设施所面临的挑战，并证明——在适当的意义上——密码迁移表现出一定的预期复杂性。我们还提供了选定参数集的数值数据。此外，我们分析了所提出的模型在现实世界模式及其实际适用性方面的表现。另外，我们讨论了建模现实世界迁移项目的挑战。作为具体示例，我们考察了CI/CD系统GitLab向后量子密码的过渡以及配电网的多级技术过渡。这项工作为未来密码迁移策略的理论理解和实际实施方面的进步铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [2] [Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.23237)
> *歧义引导的可学习分布校准用于半监督小样本类增量学习*

*Fan Lyu, Linglan Zhao, Chengyan Liu, Yinying Mei, Zhang Zhang, Jian Zhang, Fuyuan Hu, Liang Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 半监督小样本类增量学习, 分布校准, 歧义引导, 广义半监督, 特征分布

**Comment:** 6 pages, 5 figures

> **TL;DR:** 本文重新定义了半监督小样本类增量学习（GSemi-FSCIL），使其更贴近实际，并提出ALDC策略，通过利用大量基类样本校准少样本新类特征分布，实现了最先进的性能。

**AI_Comments:** 本文的创新点在于重新定义了半监督小样本类增量学习的范式，使其更贴近现实世界的复杂性，即未标记数据可能包含已见过的基类和新类。提出的ALDC策略通过利用基类信息来纠正新类特征分布的偏差，有效解决了这一新挑战，显示出其在处理实际场景中数据分布复杂性方面的潜力。该工作对于推动小样本学习在更复杂、更贴近实际的应用场景中的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的半监督小样本类增量学习（Semi-FSCIL）研究通常假设未标记数据仅限于当前会话的新类，这视角狭隘且不符合实际场景。为了更好地反映真实世界场景，本文将Semi-FSCIL重新定义为广义半监督小样本类增量学习（GSemi-FSCIL），将基类和所有已见过的新类都纳入未标记数据集。这种未标记样本组成的变化对现有方法构成了新挑战，因为它们难以区分来自基类和新类的未标记样本。

**Method:** 本文提出了一种歧义引导的可学习分布校准（Ambiguity-guided Learnable Distribution Calibration, ALDC）策略。ALDC动态地利用大量的基类样本来纠正少样本新类的有偏特征分布。

**Result:** 在三个基准数据集上的实验表明，本文方法优于现有工作，取得了新的最先进结果。

**Conclusion:** 本文提出的ALDC策略有效解决了GSemi-FSCIL中未标记样本区分的挑战，并通过校准特征分布显著提升了模型性能，实现了最先进的成果。

> **ai_Abstract:** 本文针对半监督小样本类增量学习（Semi-FSCIL）中未标记数据来源假设过于狭隘的问题，将其重新定义为广义半监督小样本类增量学习（GSemi-FSCIL），即未标记数据包含基类和所有已见过的新类。为解决现有方法在此新设定下难以区分不同来源未标记样本的挑战，本文提出了一种歧义引导的可学习分布校准（ALDC）策略，该策略利用丰富的基类样本动态校正少样本新类的有偏特征分布。实验证明，ALDC在三个基准数据集上超越了现有方法，取得了最先进的性能。

> **摘要翻译:** 小样本类增量学习（FSCIL）侧重于模型从有限数据中学习新概念，同时保留对先前类别的知识。最近，许多研究开始利用未标记样本来帮助模型从少样本中学习，从而产生了半监督小样本类增量学习（Semi-FSCIL）领域。然而，这些研究通常假设未标记数据的来源仅限于当前会话的新类，这呈现出狭隘的视角，无法与实际场景很好地对齐。为了更好地反映真实世界场景，我们通过在未标记集中纳入基类和所有已见过的新类，将Semi-FSCIL重新定义为广义半监督小样本类增量学习（GSemi-FSCIL）。未标记样本组成的这种变化对现有方法提出了新的挑战，因为它们难以区分来自基类和新类的未标记样本。为了解决这个问题，我们提出了一种歧义引导的可学习分布校准（ALDC）策略。ALDC动态地利用丰富的基类样本来校正少样本新类的有偏特征分布。在三个基准数据集上的实验表明，我们的方法优于现有工作，取得了新的最先进结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [3] [CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes](https://arxiv.org/abs/2507.23473)
> *CST 反无人机：复杂场景下微型无人机跟踪的热红外基准*

*Bin Xie, Congxuan Zhang, Fagan Wang, Peng Liu, Feng Lu, Zhen Chen, Weiming Hu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 无人机跟踪, 热红外, 单目标跟踪, 数据集, 微型无人机

**Comment:** Accepted by ICCVW2025

> **TL;DR:** CST Anti-UAV是一个新的热红外数据集，用于在复杂场景中跟踪微型无人机，实验表明现有方法在此任务上表现不佳，凸显了进一步研究的必要性。

**AI_Comments:** 这项工作具有重要意义，因为它解决了现有无人机跟踪数据集在真实世界应用中普遍存在的局限性，特别是缺乏对微型无人机和复杂场景的关注。CST Anti-UAV数据集的创建，尤其是其独特的手动帧级属性标注，为未来无人机跟踪算法的开发和评估提供了一个宝贵的、更具挑战性的基准。实验结果清晰地揭示了当前SOT方法在处理此类任务时的不足，强调了该领域研究的紧迫性。

<details>
  <summary>Details</summary>

**Motivation:** 现有无人机跟踪数据集主要关注显眼目标，缺乏场景复杂性和属性多样性，限制了它们在真实世界反无人机任务中的应用，而无人机感知对于公共安全和隐私至关重要。

**Method:** 提出了CST Anti-UAV，这是一个新的热红外数据集，专门用于复杂场景下微型无人机（CST）的单目标跟踪（SOT）。该数据集包含220个视频序列和超过24万个高质量边界框标注，具有大量微型无人机目标和多样复杂的场景。CST Anti-UAV首次包含了完整的手动帧级属性标注，以实现精确评估。研究者还在该数据集上评估了20种现有的SOT方法。

**Result:** 实验结果表明，在复杂环境中跟踪微型无人机仍然是一个挑战。现有最先进的方法在CST Anti-UAV数据集上仅达到35.92%的状态准确率，远低于在Anti-UAV410数据集上观察到的67.69%。

**Conclusion:** 这些发现强调了现有基准的局限性以及无人机跟踪研究需要进一步发展。CST Anti-UAV基准的公开发布将促进更鲁棒的SOT方法的发展，并推动反无人机系统的创新。

> **ai_Abstract:** 本论文介绍了CST Anti-UAV，这是一个专门用于复杂场景中微型无人机跟踪的新型热红外数据集。针对现有数据集的不足，该数据集提供了220个视频序列和24万高质量标注，并首次包含完整的帧级属性标注。通过评估20种现有单目标跟踪方法，研究发现当前技术在跟踪复杂环境中的微型无人机时仍面临巨大挑战，最高准确率仅为35.92%。这表明需要进一步研究和开发更鲁棒的无人机跟踪算法，CST Anti-UAV的发布旨在推动这一领域的发展。

> **摘要翻译:** 无人机（UAV）的广泛应用引发了严重的公共安全和隐私问题，使得无人机感知对于反无人机任务至关重要。然而，现有的无人机跟踪数据集主要包含显眼目标，并且缺乏场景复杂性和属性表示的多样性，限制了它们在真实世界场景中的适用性。为了克服这些局限性，我们提出了CST Anti-UAV，这是一个专门为复杂场景下微型无人机（CST）的单目标跟踪（SOT）设计的新型热红外数据集。它包含220个视频序列，拥有超过24万个高质量的边界框标注，突出了两个关键特性：大量微型无人机目标以及多样复杂的场景。据我们所知，CST Anti-UAV是第一个包含完整手动帧级属性标注的数据集，能够在各种挑战下进行精确评估。为了对CST Anti-UAV进行深入的性能分析，我们评估了20种现有SOT方法在所提出的数据集上的表现。实验结果表明，在复杂环境中跟踪微型无人机仍然是一个挑战，因为最先进的方法仅达到35.92%的状态准确率，远低于在Anti-UAV410数据集上观察到的67.69%。这些发现强调了现有基准的局限性以及无人机跟踪研究需要进一步发展。CST Anti-UAV基准即将公开发布，它不仅促进了更鲁棒的SOT方法的发展，而且推动了反无人机系统的创新。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [6] [BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM](https://arxiv.org/abs/2507.14632)
> *BusterX++: 面向统一跨模态AI生成内容检测与解释的MLLM框架*

*Haiquan Wen, Tianxiao Li, Zhenglin Huang, Yiwei He, Guangliang Cheng* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 跨模态检测, AI生成内容, MLLM, 强化学习, 合成媒体

**Comment:** 

> **TL;DR:** BusterX++是一个新颖的框架，用于跨模态检测和解释合成媒体，解决了现有单模态检测系统的局限性，并通过强化学习和多阶段训练实现了性能提升。同时提出了GenBuster++数据集用于评估。

**AI_Comments:** 该论文的创新点在于提出了一个统一的跨模态检测框架BusterX++，解决了现有AI生成内容检测系统仅限于单模态的局限性。引入强化学习后训练策略、多阶段训练、思维奖励和混合推理等技术，显著提升了检测性能。同时，构建高质量的跨模态基准数据集GenBuster++也为该领域的研究提供了重要的评估工具，具有较高的实用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI的进步显著提高了图像和视频合成能力，增加了虚假信息传播的风险。现有检测方法（包括MLLM）主要限于单模态设计，无法有效应对结合多种媒体格式的合成内容。

**Method:** 本文提出了BusterX++，一个专为跨模态合成媒体检测和解释设计的框架。它采用了先进的强化学习（RL）后训练策略，消除了冷启动问题。通过多阶段训练（Multi-stage Training）、思维奖励（Thinking Reward）和混合推理（Hybrid Reasoning），BusterX++实现了稳定且显著的性能提升。为实现全面评估，还推出了GenBuster++，一个利用最先进图像和视频生成技术的跨模态基准数据集，包含4000个由人类专家精心策划的图像和视频片段。

**Result:** BusterX++在跨模态合成媒体检测和解释方面表现出有效性和泛化能力。GenBuster++基准数据集有助于实现全面的评估。

**Conclusion:** BusterX++成功地解决了现有单模态检测系统在处理结合多种媒体格式的合成内容时的局限性，并通过其创新的训练策略和框架设计，在跨模态AI生成内容检测和解释方面取得了显著的性能提升和泛化能力。

> **ai_Abstract:** BusterX++是一个新颖的跨模态AI生成内容检测和解释框架，旨在解决现有单模态检测系统在处理结合多种媒体格式的合成内容时的局限性。该框架采用先进的强化学习后训练策略，结合多阶段训练、思维奖励和混合推理，实现了稳定且显著的性能提升。为评估其有效性，论文还提出了GenBuster++，一个包含4000个高质量图像和视频片段的跨模态基准数据集。广泛的实验证明了BusterX++的有效性和泛化能力。

> **摘要翻译:** 生成式AI的最新进展极大地提高了图像和视频合成能力，显著增加了通过复杂虚假内容传播错误信息的风险。为此，检测方法已从传统方法发展到多模态大型语言模型（MLLM），在识别合成媒体方面提供了增强的透明度和可解释性。然而，当前的检测系统仍受其单模态设计的根本限制。这些方法分别分析图像或视频，使其在对抗结合多种媒体格式的合成内容时效率低下。为了应对这些挑战，我们引入了\textbf{BusterX++}，一个专为跨模态合成媒体检测和解释设计的新颖框架。我们的方法结合了先进的强化学习（RL）后训练策略，消除了冷启动问题。通过多阶段训练、思维奖励和混合推理，BusterX++实现了稳定且显著的性能改进。为了实现全面评估，我们还推出了\textbf{GenBuster++}，一个利用最先进的图像和视频生成技术的跨模态基准数据集。该基准包含4000个图像和视频片段，由人类专家使用新颖的过滤方法精心策划，以确保高质量、多样性和实际适用性。广泛的实验证明了我们方法的有效性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [23] [Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents](https://arxiv.org/abs/2507.23242)
> *针对非结构化真实世界文档的检索器专用查询重写广义强化学习*

*Sungguk Cha, DongWook Kim, Taeseung Hahn, Mintae Kim, Youngsub Han, Byoung-Ki Jeon* | **Category: cs.CV, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 查询重写, RAG, 信息检索, 非结构化文档

**Comment:** 

> **TL;DR:** RL-QR是一个基于强化学习的查询重写框架，旨在优化RAG系统在处理非结构化真实世界文档时的查询效果，无需人工标注数据。它在多模态和词法检索器上取得了显著提升，但在语义和混合检索器上仍面临挑战。

**AI_Comments:** 本文的创新之处在于引入了基于强化学习的查询重写框架RL-QR，成功地避免了对大量人工标注数据的依赖，这对于真实世界中多样化且非结构化的文档处理具有重要意义。其通过合成数据和GRPO训练特定检索器重写器的方法具有较高的实用价值和可扩展性。尽管在多模态和词法检索器上表现出色，但在语义和混合检索器上的局限性揭示了训练对齐仍是未来需要深入研究的挑战，这可能限制了其在某些复杂应用场景中的普适性。总的来说，该工作为RAG系统的查询优化提供了一个有前景的、无需标注的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）系统严重依赖有效的查询公式来解锁外部知识，但为多样化、非结构化的真实世界文档优化查询仍然是一个挑战。现有的方法可能需要大量人工标注数据集，限制了其可扩展性和适用性。

**Method:** 本文提出了RL-QR，一个用于检索器专用查询重写的强化学习框架。该框架通过合成场景-问题对，并利用广义奖励策略优化（GRPO）来训练针对特定检索器量身定制的查询重写器。RL-QR消除了对人工标注数据集的需求，并可应用于文本和多模态数据库。

**Result:** 在工业内部数据上的实验表明，RL-QR取得了显著的性能提升。其中，RL-QR_multi-modal在多模态RAG中实现了NDCG@3的11%相对增益，RL-QR_lexical为词法检索器带来了9%的增益。然而，在语义和混合检索器方面仍存在挑战，查询重写器未能改善性能，这可能归因于训练对齐问题。

**Conclusion:** RL-QR展现了彻底改变RAG系统查询优化的潜力，为真实世界的检索任务提供了一个可扩展、无需标注的解决方案。同时，研究也指明了在语义检索背景下进一步完善的方向。

> **ai_Abstract:** 本文介绍了RL-QR，一个基于强化学习的检索器专用查询重写框架，旨在解决RAG系统在非结构化真实世界文档中查询优化面临的挑战。RL-QR通过合成场景-问题对并利用广义奖励策略优化（GRPO），训练无需人工标注数据的查询重写器，并适用于文本和多模态数据库。实验结果显示，RL-QR在多模态和词法检索器上取得了显著性能提升，但在语义和混合检索器上的表现不佳，提示可能存在训练对齐问题。该研究强调了RL-QR作为一种可扩展、无需标注的真实世界检索解决方案的潜力，并指出了未来在语义检索方面改进的方向。

> **摘要翻译:** 检索增强生成（RAG）系统严重依赖有效的查询公式来解锁外部知识，但优化针对多样化、非结构化真实世界文档的查询仍然是一个挑战。我们引入了RL-QR，一个用于检索器专用查询重写的强化学习框架，它消除了对人工标注数据集的需求，并将适用性扩展到文本和多模态数据库。通过合成场景-问题对并利用广义奖励策略优化（GRPO），RL-QR训练出针对特定检索器量身定制的查询重写器，从而提高各种领域的检索性能。在工业内部数据上的实验表明取得了显著改进，其中RL-QR_multi-modal在多模态RAG中实现了NDCG@3的11%相对增益，RL-QR_lexical为词法检索器带来了9%的增益。然而，在语义和混合检索器方面仍存在挑战，查询重写器未能改善性能，这可能归因于训练对齐问题。我们的发现突出了RL-QR彻底改变RAG系统查询优化的潜力，为真实世界的检索任务提供了一个可扩展、无需标注的解决方案，同时也指明了在语义检索背景下进一步完善的方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [30] [Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2](https://arxiv.org/abs/2507.23272)
> *面向3D乳腺MRI的可负担肿瘤分割与可视化：基于SAM2*

*Solha Kang, Eugene Kim, Joris Vankerschaver, Utku Ozbulak* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 乳腺MRI, 肿瘤分割, SAM2, 3D图像分析, 零样本学习

**Comment:** Accepted for publication in the 28th International Conference on
  Medical Image Computing and Computer Assisted Intervention (MICCAI), 2nd Deep
  Breast Workshop on AI and Imaging for Diagnostic and Treatment Challenges in
  Breast Care (DeepBreath), 2025

> **TL;DR:** 本研究探索了如何利用通用基础模型SAM2，通过最小输入实现3D乳腺MRI肿瘤的经济高效分割，为资源受限地区提供了一种可行的替代方案。

**AI_Comments:** 这篇论文的创新点在于探索了通用基础模型SAM2在专业医疗图像分析领域的应用潜力，特别是在资源受限环境下的可负担性。其通过“单切片边界框+3D传播”的策略，有效解决了零样本模型在体积数据上的应用难题，并证明了其在乳腺肿瘤分割上的有效性，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺MRI的3D扫描手动解释费时且主观。尽管AI工具有潜力，但商业医疗AI产品由于高昂的许可费、专有软件和基础设施要求，在低收入和中等收入国家普及受限。

**Method:** 本研究调查了Segment Anything Model 2 (SAM2) 如何适应低成本、最小输入的3D乳腺MRI肿瘤分割。方法是在一个切片上使用单个边界框标注，然后通过三种不同的切片级追踪策略（从上到下、从下到上、中心向外）在3D体积中传播分割预测。

**Result:** 在评估的三种策略中，中心向外传播产生了最一致和准确的分割结果。尽管SAM2是一个未针对体积医学数据训练的零样本模型，但在最小监督下仍实现了强大的分割性能。研究还分析了分割性能与肿瘤大小、位置和形状的关系，并识别了主要的失败模式。

**Conclusion:** 结果表明，像SAM2这样的通用基础模型可以在最小监督下支持3D医学图像分析，为资源受限的环境提供了一种可访问且经济实惠的替代方案。

> **ai_Abstract:** 本研究探讨了如何利用通用基础模型SAM2实现3D乳腺MRI肿瘤的经济高效分割。针对手动解释和商业AI高成本的痛点，论文提出通过在单个切片上提供边界框，结合中心向外等三种传播策略，在3D体积中进行肿瘤分割。实验表明，SAM2作为零样本模型，在最小监督下仍能获得良好的分割效果，尤其以中心向外策略最佳，为资源受限地区提供了可行的替代方案。

> **摘要翻译:** 乳腺MRI提供高分辨率的体积成像，对于肿瘤评估和治疗计划至关重要，但3D扫描的手动解释仍然是劳动密集型和主观的。虽然AI驱动的工具承诺加速医学图像分析，但由于高昂的许可费、专有软件和基础设施要求，商业医疗AI产品在低收入和中等收入国家的采用仍然有限。在这项工作中，我们研究了Segment Anything Model 2 (SAM2) 是否可以适应低成本、最小输入的乳腺MRI 3D肿瘤分割。通过在一个切片上使用单个边界框标注，我们使用三种不同的切片级追踪策略：从上到下、从下到上和中心向外，在3D体积中传播分割预测。我们在大量患者队列中评估了这些策略，发现中心向外传播产生了最一致和准确的分割。尽管SAM2是一个未针对体积医学数据训练的零样本模型，但在最小监督下实现了强大的分割性能。我们进一步分析了分割性能与肿瘤大小、位置和形状的关系，识别了主要的失败模式。我们的结果表明，像SAM2这样的通用基础模型可以在最小监督下支持3D医学图像分析，为资源受限的环境提供了一种可访问且经济实惠的替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [31] [SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions](https://arxiv.org/abs/2507.23784)
> *SUB：通过合成属性替换基准测试CBM泛化能力*

*Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 概念瓶颈模型, 分布偏移, 可解释AI, 基准测试, 合成图像

**Comment:** Accepted at ICCV 2025

> **TL;DR:** CBMs在分布变化下识别概念困难。本文提出了SUB基准和TDG方法来评估和生成受控图像，以测试CBM的鲁棒性。

**AI_Comments:** 本文通过引入一个新颖的合成数据集和生成方法（TDG），有效地解决了概念瓶颈模型在分布偏移下泛化能力不足的问题。其创新点在于通过精确控制属性替换来系统性地评估模型鲁棒性，为可解释AI领域提供了一个重要的评估工具，有助于推动更可靠AI系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 概念瓶颈模型（CBMs）在分布偏移下难以可靠地识别正确概念，这阻碍了其在医学等需要透明度的领域中的应用。

**Method:** 本文引入了SUB，一个包含38,400张基于CUB数据集的合成图像的细粒度图像和概念基准。为了创建SUB，选择了CUB数据集中33种鸟类和45个概念的子集来生成替换特定概念的图像。此外，引入了一种新颖的Tied Diffusion Guidance (TDG) 方法，通过两个并行去噪过程中的噪声共享，精确控制生成的图像，确保生成正确的鸟类类别和属性。

**Result:** 该新基准能够对CBMs和类似可解释模型进行严格评估。

**Conclusion:** 本文通过引入新基准和方法，有助于开发更鲁棒的概念瓶颈模型和可解释模型。

> **ai_Abstract:** 本文提出了SUB，一个用于评估概念瓶颈模型（CBMs）在分布偏移下概念识别鲁棒性的新基准。SUB包含38,400张合成图像，通过引入Tied Diffusion Guidance (TDG) 方法精确控制图像生成，以替换特定概念。该基准旨在促进更鲁棒的可解释AI模型的发展，特别是在CBMs难以在分布变化下可靠识别概念的问题上。

> **摘要翻译:** 概念瓶颈模型（CBMs）和其他基于概念的可解释模型在使AI应用更透明方面展现出巨大潜力，这在医学等领域至关重要。尽管取得了成功，我们证明CBMs在分布偏移下难以可靠地识别正确概念。为了评估CBMs对概念变异的鲁棒性，我们引入了SUB：一个包含38,400张基于CUB数据集的合成图像的细粒度图像和概念基准。为了创建SUB，我们选择了CUB数据集中33种鸟类和45个概念的子集来生成替换特定概念（如翅膀颜色或腹部图案）的图像。我们引入了一种新颖的Tied Diffusion Guidance (TDG) 方法来精确控制生成的图像，其中两个并行去噪过程的噪声共享确保了正确鸟类类别和正确属性的生成。这个新颖的基准能够对CBMs和类似可解释模型进行严格评估，有助于开发更鲁棒的方法。我们的代码可在https://github.com/ExplainableML/sub获取，数据集可在http://huggingface.co/datasets/Jessica-bader/SUB获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [32] [Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions](https://arxiv.org/abs/2507.23778)
> *半物理：使运动学3D人体模型具备物理交互能力*

*Li Siyao, Yao Feng, Omid Tehari, Chen Change Loy, Michael J. Black* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D人体模型, 物理交互, 运动学, 半物理, SMPL-X

**Comment:** 

> **TL;DR:** 本文提出一种名为“半物理”的新方法，将运动学3D人体模型嵌入物理模拟中，使其能与环境进行物理交互，解决穿透和不真实动态问题，且无需学习、实时运行。

**AI_Comments:** 这项工作的创新之处在于提出了一种“半物理”机制，将运动学3D人体模型与物理模拟相结合，解决了现有模型在物理交互方面的局限性。其重要性体现在提供了一个无需大量学习、实时且泛化能力强的方法，有效解决了人体模型与环境交互时的穿透和不真实动态问题，对于虚拟现实、动画和机器人等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前通用的3D人体模型（如SMPL-X）虽然能有效表示人体形状和姿态，但由于其运动学性质，缺乏与环境进行物理交互的能力，导致基于运动学的交互模型常出现穿透和不真实的物体动态等问题。

**Method:** 提出一种“半物理”机制，将SMPL-X嵌入一个能够与周围环境进行动态物理交互的实体中。该方法将3D运动学动作转化为物理模拟，在保持固有SMPL-X姿态的运动学控制的同时，确保与场景和物体的物理合理交互。

**Result:** 有效消除了穿透和不真实的物体动态。该方法无需学习，可泛化到任何身体形状和动作，并能实时运行；同时，它保留了原始运动学动作的保真度，并无缝集成了物理交互。

**Conclusion:** “半物理”方法通过使运动学3D人体模型能够进行真实的物理交互，成功解决了其局限性，提供了一种无需大量训练、实时、可泛化且高保真度的解决方案。

> **ai_Abstract:** 本文提出一种名为“半物理”的新方法，旨在解决运动学3D人体模型（如SMPL-X）缺乏物理交互能力的问题。该方法将运动学人体模型嵌入物理模拟中，使其能与环境进行真实物理交互，从而消除穿透和不真实的物体动态。与强化学习方法不同，该方法无需学习、实时运行，并能泛化到不同身体形状和动作，同时保持原始运动学动作的保真度。

> **摘要翻译:** 尽管当前通用的3D人体模型（例如SMPL-X）能有效地表示准确的人体形状和姿态，但由于其运动学性质，它们缺乏与环境进行物理交互的能力。因此，基于运动学的交互模型经常面临诸如穿透和不真实的物体动态等问题。为了解决这一局限性，我们引入了一种新颖的方法，将SMPL-X嵌入一个能够与周围环境进行动态物理交互的实体中。具体来说，我们提出了一种“半物理”机制，将3D运动学动作转化为物理模拟。我们的方法在保持固有SMPL-X姿态的运动学控制的同时，确保与场景和物体的物理合理交互，有效消除了穿透和不真实的物体动态。与需要大量复杂训练的基于强化学习的方法不同，我们的半物理方法无需学习，并且可以泛化到任何身体形状和动作；同时，它能实时运行。此外，它在无缝集成物理交互的同时，保留了原始运动学动作的保真度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [33] [PLMP -- Point-Line Minimal Problems for Projective SfM](https://arxiv.org/abs/2503.04351)
> *PLMP -- 射影SfM中的点线最小问题*

*Kim Kiehn, Albin Ahlbäck, Kathlén Kohn* | **Category: cs.CV, math.AG** | **Updated: 2025-07-31**

**Keywords:** SfM, 最小问题, 点线排列, 非标定相机, 几何分解

**Comment:** 

> **TL;DR:** 该论文完整分类了多视角非标定针孔相机下，由点和线排列构成的SfM最小问题，共发现291个，其中73个有唯一解且可线性求解。

**AI_Comments:** 这项研究的创新之处在于首次对非标定SfM中点线配置的最小问题进行了全面的分类和分析，提供了291个问题的详细信息，并识别出可线性求解的子集。其提出的基于稳定器子群的几何系统方法，为未来在欠约束问题中识别和分解最小问题提供了普适性框架，对于SfM理论和实际应用都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是完整分类并解决在多视角、非标定针孔相机设置下，基于点和线排列的结构恢复（SfM）中的所有最小问题。

**Method:** 该论文通过对点和线排列在多个未校准针孔相机下进行观察，完全分类了所有结构恢复（SfM）的最小问题。研究方法包括识别291个最小问题，计算每个问题的解的数量以衡量其内在难度，并通过探索子排列的稳定器子群，开发了一种几何和系统的方法来分解最小问题、识别欠约束问题中的最小问题，并形式化证明非最小性。

**Result:** 研究共发现了291个最小问题，其中73个具有唯一解且可线性求解。两个线性问题允许任意数量的视图，而所有其他最小问题最多有9个相机。所有最小问题最多包含7个点和12条线。每个最小问题的解数量相对较低（例如，与校准相机下的最小问题相比）。

**Conclusion:** 该论文成功地完整分类了多视角非标定相机下基于点线排列的SfM最小问题，并提出了一种几何和系统的方法来分析、分解和验证这些问题，为SfM领域提供了全面的理论基础和实用工具。

> **ai_Abstract:** 该论文对多视角、非标定针孔相机下，由点和线排列构成的结构恢复（SfM）中的所有最小问题进行了完整分类。研究识别出291个最小问题，其中73个具有唯一解且可线性求解。论文还探讨了问题的解数量，发现其相对较低，并提出了一种基于稳定器子群的几何系统方法，用于问题分解、识别最小问题以及证明非最小性。

> **摘要翻译:** 我们完整分类了在多视角、非标定针孔相机完全观察点和线排列情况下的结构恢复（SfM）的所有最小问题。我们发现了291个最小问题，其中73个具有唯一解，因此可以线性求解。其中两个线性问题允许任意数量的视图，而所有其他最小问题最多有9个相机。所有最小问题最多包含7个点和12条线。我们计算了每个最小问题的解的数量，因为这提供了衡量问题内在难度的一个指标，并发现这些数量相对较低（例如，与校准相机下的最小问题相比）。最后，通过探索子排列的稳定器子群，我们开发了一种几何和系统的方法来1）将最小问题分解为更小的问题，2）识别欠约束问题中的最小问题，以及3）形式化证明非最小性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [41] [MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image](https://arxiv.org/abs/2507.18371)
> *MVG4D：基于图像矩阵的多视角和运动生成，用于从单张图像创建4D内容*

*DongFu Yin, Xiaotian Chen, Fei Richard Yu, Xuanchen Li, Xinhao Zhang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 4D内容生成, 多视角合成, 4D高斯泼溅, 单图像输入, 时间一致性

**Comment:** 

> **TL;DR:** MVG4D是一个新颖的框架，通过结合多视角合成和4D高斯泼溅，从单张图像生成高保真且时间一致的动态4D内容。

**AI_Comments:** MVG4D的创新点在于其图像矩阵模块，能够从单张图像生成高质量、时间连贯的多视角图像，这为后续的4D重建提供了强大的基础。结合4D Gaussian Splatting和轻量级变形网络，有效地解决了现有4D生成方法中的时间不一致性和细节丢失问题，显著提升了生成内容的质量和效率。该方法为从有限输入创建沉浸式AR/VR内容开辟了新的可能性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成建模在2D、3D内容创建方面取得了显著进展，但生成高保真和时间一致的动态4D内容仍然是一个挑战。

**Method:** MVG4D框架通过结合多视角合成和4D高斯泼溅（4D GS）从单张静止图像生成动态4D内容。其核心是一个图像矩阵模块，用于合成时间连贯且空间多样的多视角图像，为后续的3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级变形网络进一步扩展到时间域。

**Result:** 在Objaverse数据集上的大量实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于最先进的基线方法。它显著减少了闪烁伪影，并锐化了跨视角和时间的结构细节。

**Conclusion:** MVG4D为从最小输入高效且可控地生成4D内容开辟了新方向，有效增强了时间一致性、几何保真度和视觉真实感，解决了现有4D GS方法中运动不连续性和背景退化等关键挑战。

> **ai_Abstract:** 本文提出了MVG4D，一个从单张图像生成动态4D内容的新框架。它通过图像矩阵模块生成时间连贯的多视角图像，并结合4D Gaussian Splatting和轻量级变形网络进行4D重建。该方法解决了现有4D GS方法的挑战，提高了时间一致性、几何保真度和视觉真实感，并在实验中表现出优越的性能，减少了伪影，增强了细节，为AR/VR体验提供了更高效可控的4D生成方案。

> **摘要翻译:** 生成建模的进步显著增强了数字内容创作，从2D图像扩展到复杂的3D和4D场景。尽管取得了实质性进展，但生成高保真且时间一致的动态4D内容仍然是一个挑战。在本文中，我们提出了MVG4D，一个新颖的框架，通过结合多视角合成和4D高斯泼溅（4D GS），从单张静止图像生成动态4D内容。MVG4D的核心是图像矩阵模块，它合成时间连贯且空间多样的多视角图像，为下游的3D和4D重建提供丰富的监督信号。这些多视角图像用于优化3D高斯点云，并通过轻量级变形网络进一步扩展到时间域。我们的方法有效增强了时间一致性、几何保真度和视觉真实感，解决了影响先前基于4D GS的方法的运动不连续性和背景退化等关键挑战。在Objaverse数据集上的大量实验表明，MVG4D在CLIP-I、PSNR、FVD和时间效率方面优于最先进的基线方法。值得注意的是，它减少了跨视角和时间的闪烁伪影并锐化了结构细节，从而实现了更沉浸式的AR/VR体验。MVG4D为从最小输入高效且可控地生成4D内容开辟了新方向。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [44] [Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas](https://arxiv.org/abs/2507.23245)
> *自动绘制颅神经II、III、V和VII/VIII通路图：一种多参数多阶段弥散纤维束成像图谱*

*Lei Xie, Jiahao Huang, Jiawei Zhang, Jianzhong He, Yiang Pan, Guoqiang Xie, Mengjun Li, Qingrun Zeng, Mingchu Li, Yuanjing Feng* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 颅神经, 弥散纤维束成像, 脑图谱, 自动化映射, 多阶段聚类

**Comment:** 

> **TL;DR:** 该研究开发了一种自动化多阶段弥散纤维束成像图谱，用于绘制颅神经II、III、V和VII/VIII的通路图，并证明其与专家注释具有高度准确性。

**AI_Comments:** 该论文通过开发一种自动化且鲁棒的颅神经通路绘制方法，在神经影像学领域取得了重大进展。利用多阶段纤维聚类方法处理大型数据集（HCP）是其创新之处，有效解决了颅底复杂性带来的固有挑战。该自动化图谱具有强大的临床相关性，特别是对于术前规划，因为它能提供颅神经精确的空间关系。在多个数据集（包括临床病例）上的验证进一步突显了其实用性和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 由于每对颅神经独特的解剖结构和颅底环境的复杂性，绘制全面详细的颅神经（CN）图谱具有挑战性。然而，从弥散MRI（dMRI）映射其通路对于提供颅神经与关键组织之间空间关系的宝贵术前见解至关重要。

**Method:** 本研究开发了一个综合性的弥散纤维束成像图谱，用于自动映射人脑中的颅神经通路。该颅神经图谱通过对来自人类连接组计划（HCP）的50名受试者生成的约1,000,000条流线进行多参数纤维束成像后，采用多阶段纤维聚类方法生成。

**Result:** 所提出的颅神经图谱在多个采集站点（包括HCP数据集、多壳弥散MRI（MDM）数据集和两个垂体腺瘤患者的临床病例）与专家手动注释达到了高度的空间对应。它能够自动识别与5对颅神经（包括视神经CN II、动眼神经CN III、三叉神经CN V和面听神经CN VII/VIII）相关的8个纤维束，并实验证明了其鲁棒性。

**Conclusion:** 这项工作通过促进更高效和自动地映射多对颅神经的通路，从而增强了通过可视化其与附近解剖结构的空间关系来分析和理解复杂大脑结构的能力，从而为弥散成像领域做出了贡献。

> **ai_Abstract:** 本文首次提出了一种综合性的弥散纤维束成像图谱，用于自动绘制人脑中颅神经（CN II、III、V、VII/VIII）的通路图。该图谱通过对来自大量数据集（HCP）的流线采用新颖的多阶段纤维聚类策略生成。实验证明，该图谱与专家注释具有高度一致性，并能鲁棒地识别关键纤维束，显著提高了弥散成像中复杂脑结构分析和理解的效率。

> **摘要翻译:** 颅神经（CNs）在人脑的各种基本功能中起着至关重要的作用，通过弥散MRI（dMRI）绘制其通路图可以为个体颅神经与关键组织之间的空间关系提供宝贵的术前见解。然而，由于每对颅神经独特的解剖结构和颅底环境的复杂性，绘制全面详细的颅神经图谱具有挑战性。在这项工作中，我们提出了我们认为是第一个开发用于人脑颅神经通路自动映射的综合弥散纤维束成像图谱的研究。该颅神经图谱是通过对每对颅神经的多参数纤维束成像生成的流线进行纤维聚类而生成的。我们没有采用一次性聚类，而是探索了一种新的多阶段纤维聚类策略，用于对来自人类连接组计划（HCP）的50名受试者生成的约1,000,000条流线进行多重分析。定量和视觉实验表明，我们的颅神经图谱与多个采集站点（包括HCP数据集、多壳弥散MRI（MDM）数据集和两个垂体腺瘤患者的临床病例）的专家手动注释达到了高度的空间对应。所提出的颅神经图谱可以自动识别与5对颅神经相关的8个纤维束，包括视神经CN II、动眼神经CN III、三叉神经CN V和面听神经CN VII/VIII，并且实验证明了其鲁棒性。这项工作通过促进更高效和自动地映射多对颅神经的通路，从而增强了通过可视化其与附近解剖结构的空间关系来分析和理解复杂大脑结构的能力，从而为弥散成像领域做出了贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [45] [3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding](https://arxiv.org/abs/2507.23478)
> *3D-R1：增强3D VLM中的推理能力以实现统一场景理解*

*Ting Huang, Zeyu Zhang, Hao Tang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D VLM, 场景理解, 推理, 强化学习, 动态视角选择

**Comment:** 

> **TL;DR:** 3D-R1模型通过高质量数据集、强化学习和动态视角选择，显著提升了3D视觉语言模型在场景理解中的推理和泛化能力。

**AI_Comments:** 这篇论文通过结合高质量合成数据生成、强化学习（RLHF）以及创新的动态视角选择策略，为3D VLM的推理和泛化能力提升提供了一个全面的解决方案。特别是利用Gemini 2.5 Pro生成高质量CoT数据，以及RLHF与定制奖励函数的设计，是其创新点，有望推动3D场景理解技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D视觉语言模型（3D VLMs）在鲁棒推理和泛化方面存在困难，原因在于高质量空间数据的限制以及静态视角假设。

**Method:** 本文提出了3D-R1基础模型来解决上述挑战。具体方法包括：1. 构建了一个名为Scene-30K的高质量合成数据集，该数据集利用现有3D-VL数据集和基于Gemini 2.5 Pro的数据引擎，作为3D-R1的冷启动初始化数据。2. 在强化学习训练过程中利用GRPO等RLHF策略来增强推理能力，并引入感知奖励、语义相似度奖励和格式奖励三种奖励函数，以保持检测精度和答案语义精度。3. 引入了动态视角选择策略，自适应选择信息最丰富的视角进行3D场景理解。

**Result:** 3D-R1在各种3D场景基准测试中平均取得了10%的提升。

**Conclusion:** 3D-R1有效增强了3D场景理解中的推理和泛化能力。

> **ai_Abstract:** 本文提出了3D-R1，一个旨在增强3D视觉语言模型推理能力的基础模型。为解决现有3D VLM在推理和泛化方面的不足，3D-R1通过构建高质量合成数据集Scene-30K进行初始化，并结合强化学习（RLHF，如GRPO）及三种定制奖励函数来提升推理能力和精度。此外，引入动态视角选择策略以优化3D场景理解。实验结果表明，3D-R1在多个3D场景基准测试中平均性能提升10%，证明了其在提升3D场景理解推理和泛化方面的有效性。

> **摘要翻译:** 大型视觉语言模型（VLM）在2D视觉理解任务中取得了显著进展，激发了将这些能力扩展到3D场景理解的兴趣。然而，当前的3D VLM由于高质量空间数据的限制和静态视角假设的固有性质，往往难以实现鲁棒的推理和泛化。为了应对这些挑战，我们提出了3D-R1，一个增强3D VLM推理能力的基础模型。具体而言，我们首先利用现有的3D-VL数据集和基于Gemini 2.5 Pro的数据引擎，构建了一个名为Scene-30K的CoT高质量合成数据集。它作为3D-R1的冷启动初始化数据。此外，我们在强化学习训练过程中利用GRPO等RLHF策略来增强推理能力，并引入了感知奖励、语义相似度奖励和格式奖励三种奖励函数，以保持检测精度和答案语义精度。此外，我们引入了一种动态视角选择策略，可以自适应地选择信息最丰富的视角进行3D场景理解。广泛的实验表明，3D-R1在各种3D场景基准测试中平均取得了10%的提升，突显了其在增强3D场景理解中的推理和泛化能力方面的有效性。代码：https://github.com/AIGeeksGroup/3D-R1。网站：https://aigeeksgroup.github.io/3D-R1。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [60] [Revisiting the Evaluation Bias Introduced by Frame Sampling Strategies in Surgical Video Segmentation Using SAM2](https://arxiv.org/abs/2502.20934)
> *重新审视使用SAM2在手术视频分割中帧采样策略引入的评估偏差*

*Utku Ozbulak, Seyed Amir Mousavi, Francesca Tozzi, Niki Rashidian, Wouter Willaert, Wesley De Neve, Joris Vankerschaver* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 手术视频分割, 帧采样, 评估偏差, SAM2, 实时AI

**Comment:** Accepted for publication in the 28th International Conference on
  Medical Image Computing and Computer Assisted Intervention (MICCAI) Workshop
  on Fairness of AI in Medical Imaging (FAIMI), 2025

> **TL;DR:** 手术视频分割中的稀疏帧采样可能会隐藏时间不一致性，使低帧率看似表现更好，但高帧率对于实时稳定性和人类偏好至关重要。

**AI_Comments:** 这篇论文揭示了手术视频AI中一个关键且常被忽视的评估偏差，该偏差源于不同的数据采样策略。其创新之处在于证明了稀疏采样如何误导性地夸大性能指标，同时未能捕捉到在手术环境中至关重要的实时稳定性。纳入人类感知（调查）进一步强化了其对实时、高帧率评估的论点。这项工作对于指导未来医学AI中的数据集创建和基准测试实践非常重要，有助于确保开发出更稳健和临床相关的模型。

<details>
  <summary>Details</summary>

**Motivation:** 实时视频分割对AI辅助手术至关重要，但现有数据集的标注协议（特别是帧采样率）差异很大，研究旨在探究这些不一致性如何影响零样本分割模型的评估。

**Method:** 本研究以SAM2在胆囊切除术中的应用为例，调查了标注密度和帧率采样对零样本分割模型评估的影响。此外，还对外科医生、护士和机器学习工程师进行了调查，以了解人类对不同帧率分割效果的感知和偏好。

**Result:** 研究发现，在传统的稀疏评估设置下，较低的帧率可能由于平滑效应而显得优于较高的帧率，从而掩盖了时间上的一致性问题。然而，在实时流媒体条件下评估时，较高的帧率能够产生卓越的分割稳定性，特别是对于手术抓钳等动态物体。对外科医生、护士和机器学习工程师的调查显示，参与者始终偏好高帧率的分割叠加。

**Conclusion:** 不一致的数据集协议会引入评估偏差，因此在手术视频AI中，需要进行时间公平的基准测试，强调在实时应用中评估每一帧的重要性，而非依赖稀疏采样策略。

> **ai_Abstract:** 本研究探讨了手术视频分割中帧采样策略对零样本分割模型评估的潜在偏差。研究发现，在稀疏评估下，低帧率可能因平滑效应而表现出虚假的高性能，掩盖了时间不一致性。然而，在实时流媒体条件下，高帧率能提供更好的分割稳定性，尤其对动态物体。一项对外科医生、护士和机器学习工程师的调查也表明，他们普遍偏好高帧率的分割结果。这强调了在实时手术AI应用中，需要对每一帧进行评估，以避免因不一致的数据集协议引入的评估偏差，并呼吁建立时间公平的基准测试。

> **摘要翻译:** 实时视频分割是人工智能辅助手术的一个有前景的机会，通过识别工具和解剖结构提供术中指导。尽管对手术视频分割的兴趣日益增长，但数据集的标注协议差异很大——有些提供密集的逐帧标签，而另一些则依赖于低帧率（如1 FPS）采样的稀疏标注。在本研究中，我们以SAM2在胆囊切除术中的应用为例，调查了标注密度和帧率采样的不一致性如何影响零样本分割模型的评估。令人惊讶的是，我们发现，在传统的稀疏评估设置下，较低的帧率可能由于平滑效应而显得优于较高的帧率，这掩盖了时间上的一致性问题。然而，在实时流媒体条件下评估时，较高的帧率能够产生卓越的分割稳定性，特别是对于手术抓钳等动态物体。为了了解这些差异与人类感知的契合度，我们对外科医生、护士和机器学习工程师进行了一项调查，发现参与者始终偏好高帧率的分割叠加，这强调了在实时应用中评估每一帧的重要性，而不是依赖稀疏采样策略。我们的发现突出了由不一致的数据集协议引入的评估偏差风险，并提请注意在手术视频AI中进行时间公平基准测试的必要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [65] [A Deep Dive into Generic Object Tracking: A Survey](https://arxiv.org/abs/2507.23251)
> *深入探讨通用目标跟踪：一项综述*

*Fereshteh Aghaee Meibodi, Shadi Alijani, Homayoun Najjaran* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 通用目标跟踪, 综述, 暹罗网络追踪器, 判别式追踪器, Transformer基追踪器

**Comment:** 55 pages, 29 figures, 9 tables

> **TL;DR:** 这是一篇关于通用目标跟踪的综述，全面回顾了暹罗网络、判别式和Transformer基追踪器，并特别强调了Transformer方法，提供了新的分类和比较。

**AI_Comments:** 这篇综述的重要性在于它不仅全面回顾了通用目标跟踪领域的三大主流范式，还特别强调了新兴且快速发展的Transformer基方法。其创新之处在于引入了新颖的分类方法和统一的比较，这对于研究人员理解该领域的演进和现状具有重要价值，尤其是在Transformer技术日益普及的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 通用目标跟踪在计算机视觉中仍是一个重要但具有挑战性的任务，现有综述要么集中于单一类别，要么覆盖不全面，因此需要一篇全面回顾所有三类追踪器，特别是快速发展的Transformer基方法的综述。

**Method:** 作者对暹罗网络、判别式和Transformer基追踪器这三类方法进行了全面回顾，分析了它们的核心设计原则、创新和局限性，通过定性和定量比较，引入了新的分类，并提供了统一的视觉和表格比较。此外，还从多个角度组织了现有追踪器，并总结了主要的评估基准。

**Result:** 论文提供了一个全面的回顾，特别是对Transformer基方法的强调；分析了每种方法的设计原则、创新和局限性；引入了新的分类；提供了统一的视觉和表格比较；组织了现有追踪器；总结了主要评估基准，并强调了Transformer基追踪在时空建模能力方面的快速发展。

**Conclusion:** 通用目标跟踪仍然是一个挑战，而Transformer基追踪器因其强大的时空建模能力正在快速发展，成为该领域的重要方向。本综述全面回顾了现有方法，为该领域的研究提供了结构化的理解。

> **ai_Abstract:** 这篇综述深入探讨了通用目标跟踪领域，回顾了过去二十年间发展起来的暹罗网络、判别式和Transformer基追踪器。论文特别关注了快速发展的Transformer基方法，分析了各类方法的设计原则、创新和局限性，并提出了新的分类和统一的比较，同时总结了评估基准，突出了Transformer在时空建模方面的优势。

> **摘要翻译:** 通用目标跟踪在计算机视觉中仍然是一项重要但具有挑战性的任务，原因在于复杂的时空动态，尤其是在存在遮挡、相似干扰物和外观变化的情况下。在过去的二十年里，为了应对这些挑战，引入了广泛的跟踪范式，包括基于暹罗网络的追踪器、判别式追踪器以及最近突出的基于Transformer的方法。虽然该领域现有的一些综述论文要么专注于单一类别，要么广泛涵盖多个类别以捕捉进展，但我们的论文对所有这三类进行了全面回顾，特别强调了快速发展的基于Transformer的方法。我们通过定性和定量比较分析了每种方法的核心设计原则、创新和局限性。我们的研究引入了一种新颖的分类方法，并提供了代表性方法的统一视觉和表格比较。此外，我们从多个角度组织了现有追踪器，并总结了主要的评估基准，强调了基于Transformer的跟踪因其强大的时空建模能力而实现的快速发展。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [66] [MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion](https://arxiv.org/abs/2507.23782)
> *MonoFusion：通过单目融合进行稀疏视图4D重建*

*Zihan Wang, Jeff Tan, Tarasha Khurana, Neehar Peri, Deva Ramanan* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 稀疏视图, 4D重建, 单目融合, 动态场景, 新视图

**Comment:** ICCV 2025. Project Page:
  https://imnotprepared.github.io/research/25_DSR/

> **TL;DR:** MonoFusion提出了一种从稀疏视图视频重建动态场景的方法，通过对齐独立的单目重建来克服传统密集多视图方法的局限性，并在新视图渲染方面表现出更高的重建质量。

**AI_Comments:** MonoFusion的创新点在于它解决了稀疏视图4D重建的难题，通过巧妙地融合独立的单目重建结果，避免了昂贵的密集多视图设置。这对于在更广泛、更自然的场景中进行动态行为捕获和重建具有重要意义。其在生成新视图方面的优越性也显示了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的动态场景重建方法通常需要昂贵且难以在野外部署的密集多视图捕获（例如，使用数百个校准相机）。这些方法在稀疏视图设置下由于视点之间重叠有限而难以适应，无法有效重建多样化的动态人类行为。

**Method:** MonoFusion通过仔细对齐每个相机独立的单目重建结果，以生成时间上和视图上一致的动态场景重建。

**Result:** 在PanopticStudio和Ego-Exo4D上的大量实验表明，MonoFusion方法比现有技术实现了更高质量的重建，尤其是在渲染新视图时。

**Conclusion:** MonoFusion有效解决了稀疏视图动态场景重建的挑战，通过创新的单目融合方法，在重建质量上超越了现有技术，特别是在生成新颖视角方面表现出色。

> **ai_Abstract:** MonoFusion提出了一种从稀疏视图视频重建动态场景的新方法，旨在解决传统密集多视图设置成本高昂且在野外受限的问题。该方法通过精心对齐来自每个摄像头的独立单目重建结果，从而实现时间上和视图上的一致性，克服了稀疏视图下视图重叠不足的挑战。实验证明，MonoFusion在动态场景重建质量上超越了现有技术，尤其在生成新颖视图方面表现突出。

> **摘要翻译:** 我们解决了从稀疏视图视频重建动态场景的问题。现有工作通常需要数百个校准摄像头的密集多视图捕获（例如Panoptic Studio）。这种多视图设置构建成本过高，无法在野外捕获多样化的场景。相比之下，我们的目标是从一小组稀疏视图摄像头（例如四个等距离向内放置的静态摄像头）重建动态人类行为，例如修理自行车或跳舞，并实现完整的场景覆盖。我们发现，由于视点之间重叠有限，密集多视图重建方法难以适应这种稀疏视图设置。为了解决这些限制，我们仔细对齐每个摄像头的独立单目重建，以生成时间和视图一致的动态场景重建。在PanopticStudio和Ego-Exo4D上进行的广泛实验表明，我们的方法比现有技术实现了更高质量的重建，特别是在渲染新视图时。代码、数据和数据处理脚本可在https://github.com/ImNotPrepared/MonoFusion上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [68] [Recovering Partially Corrupted Objects via Sketch-Guided Bidirectional Feature Interaction](https://arxiv.org/abs/2503.07047)
> *通过草图引导的双向特征交互恢复部分损坏的物体*

*Yongle Zhang, Yimin Liu, Yan Huang, Qiang Wu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 草图引导, 物体修复, 扩散模型, 双向特征交互, 空间控制

**Comment:** 13 pages. This work has been submitted to the IEEE for possible
  publication

> **TL;DR:** 本文提出一种草图引导的双向特征交互框架，用于部分损坏物体的修复，解决了现有方法在空间控制和一致性方面的问题。

**AI_Comments:** 本文的创新点在于提出了双向特征交互机制，解决了现有草图引导修复方法中草图与未损坏内容脱节的问题。通过引入上下文到草图的反馈和基于视觉掩码的草图调节，显著提升了部分损坏物体修复的空间一致性和保真度，对图像修复领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有文本引导扩散模型在物体修复中缺乏精确的像素级空间控制，尤其是在涉及部分损坏物体且关键未损坏线索仍然存在的场景中。现有草图引导方法通常只建立从草图到掩蔽区域的单向映射，忽略了来自未掩蔽物体区域的上下文信息，这导致草图与未损坏内容之间的脱节，从而引起草图引导的不一致性和结构不匹配。

**Method:** 本文提出一个基于预训练Stable Diffusion模型的草图引导双向特征交互框架。该框架包含两个互补的方向：上下文到草图（context-to-sketch）和草图到修复（sketch-to-inpainting）。在上下文到草图方向，从未损坏物体区域的多尺度潜在特征传播到草图分支，以生成一个视觉掩码，使草图特征适应可见上下文和去噪进度。在草图到修复方向，草图条件仿射变换根据学习到的视觉掩码调节草图引导的影响，确保与未损坏物体内容的一致性。这种交互在扩散U-Net编码器内的多个尺度上应用。

**Result:** 在两个新建的基准数据集上的广泛实验表明，我们的方法优于最先进的方法。

**Conclusion:** 本文提出的草图引导双向特征交互框架通过协同利用上下文信息和草图引导，显著提升了部分损坏物体修复的空间保真度和一致性，有效克服了现有方法的局限性。

> **ai_Abstract:** 针对现有文本引导扩散模型在部分损坏物体修复中缺乏精确空间控制和草图引导方法单向交互导致的不一致性问题，本文提出一种基于预训练Stable Diffusion的草图引导双向特征交互框架。该框架包含“上下文到草图”和“草图到修复”两个方向，通过多尺度潜在特征传播生成视觉掩码并进行草图条件仿射变换，实现草图特征与可见上下文的适应以及与未损坏内容的协同，从而增强物体结构的空间保真度。实验证明，该方法优于现有最先进技术。

> **摘要翻译:** 文本引导的扩散模型通过文本提示提供高级语义指导，在物体修复方面取得了显著成功。然而，它们通常缺乏精确的像素级空间控制，尤其是在涉及部分损坏物体且关键未损坏线索仍然存在的场景中。为了克服这一限制，引入了草图引导方法，通过间接梯度调制或直接草图注入来改善结构控制。然而，现有方法通常只建立从草图到掩蔽区域的单向映射，忽略了来自未掩蔽物体区域的上下文信息。这导致草图与未损坏内容之间的脱节，从而引起草图引导的不一致性和结构不匹配。为了解决这一挑战，我们提出了一种基于预训练Stable Diffusion模型的草图引导双向特征交互框架。我们的双向交互具有两个互补的方向，即上下文到草图和草图到修复，这使得对部分损坏的物体修复能够实现细粒度的空间控制。在上下文到草图方向，从未损坏物体区域的多尺度潜在特征传播到草图分支，以生成一个视觉掩码，使草图特征适应可见上下文和去噪进度。在草图到修复方向，草图条件仿射变换根据学习到的视觉掩码调节草图引导的影响，确保与未损坏物体内容的一致性。这种交互在扩散U-Net编码器内的多个尺度上应用，使模型能够以增强的空间保真度恢复物体结构。在两个新建的基准数据集上的广泛实验表明，我们的方法优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [72] [Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification](https://arxiv.org/abs/2507.23315)
> *超参数优化对轻量级深度学习模型实时图像分类准确性的影响*

*Vineet Kumar Rakesh, Soumya Mazumdar, Tapas Samanta, Sarbajit Pal, Amitabha Das* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 超参数优化, 轻量级深度学习模型, 实时图像分类, 边缘计算, 消融研究

**Comment:** 13 pages, 4 figures, 4 tables. Includes ablation study and evaluation
  on 7 lightweight deep learning models. Code and logs available at
  https://github.com/VineetKumarRakesh/lcnn-opt

> **TL;DR:** 研究了超参数优化对轻量级深度学习模型在实时图像分类中准确性和收敛性的影响。

**AI_Comments:** 该研究通过对多种当前流行的轻量级模型进行超参数的系统性消融研究，为资源受限环境下的实时图像分类提供了宝贵的实践指导。其创新点在于全面评估了超参数对模型性能（包括准确性和部署成本）的综合影响，并识别出关键的优化策略。研究结果具有很强的实用性，特别是对于边缘计算和嵌入式系统开发者而言。论文还公开了代码和训练日志，增强了研究的透明性和可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 轻量级卷积和基于Transformer的模型在资源受限应用（如嵌入式系统和边缘设备）中对实时图像分类至关重要。本工作旨在分析超参数调整对这些模型准确性和收敛行为的影响。

**Method:** 本研究分析了七种高效深度学习架构（EfficientNetV2-S, ConvNeXt-T, MobileViT v2 (XXS/XS/S), MobileNetV3-L, TinyViT-21M, RepVGG-A2），在ImageNet-1K数据集上以一致的训练设置进行训练，并强调实时实用性。进行了全面的消融研究，以分离关键超参数（包括学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择）的影响。为了评估对实时应用的适用性，每个模型不仅在Top-1和Top-5分类准确性方面进行评估，还在GPU加速的边缘部署模拟中评估了推理时间、参数数量、模型大小和每秒帧数（FPS）。

**Result:** 结果表明，余弦学习率衰减和可调节批量大小可以显著提高准确性和收敛速度，同时保持低延迟和内存成本。值得注意的是，RepVGG-A2以高效的推理性能实现了超过80%的Top-1准确率，为VGG风格模型提供了准确性和部署成本之间令人信服的平衡。

**Conclusion:** 本研究结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。

> **ai_Abstract:** 本研究探讨了超参数优化对七种轻量级深度学习模型（如EfficientNetV2-S, MobileViT v2, RepVGG-A2等）在实时图像分类任务中准确性和收敛性的影响。通过在ImageNet-1K数据集上进行全面的消融研究，分析了学习率、批量大小、数据增强等超参数的作用。结果表明，余弦学习率衰减和可调节批量大小能显著提升模型性能，并发现RepVGG-A2在保持高效推理的同时达到了高准确率。研究为构建资源高效的实时图像处理模型提供了实用建议。

> **摘要翻译:** 轻量级卷积和基于Transformer的模型对于资源受限应用（如嵌入式系统和边缘设备）中的实时图像分类至关重要。这项工作分析了超参数调整对七种高效深度学习架构（EfficientNetV2-S、ConvNeXt-T、MobileViT v2 (XXS/XS/S)、MobileNetV3-L、TinyViT-21M 和 RepVGG-A2）的准确性和收敛行为的影响。所有模型都在ImageNet-1K数据集上以一致的训练设置进行训练，并强调实时实用性。进行了一项全面的消融研究，以分离关键超参数的影响，包括学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择。为了评估对实时应用的适用性，每个模型不仅在Top-1和Top-5分类准确性方面进行评估，还在GPU加速的边缘部署模拟中评估了推理时间、参数数量、模型大小和每秒帧数（FPS）。结果表明，余弦学习率衰减和可调节批量大小可以大大提高准确性和收敛速度，同时保持低延迟和内存成本。值得注意的是，RepVGG-A2以高效的推理性能实现了超过80%的Top-1准确性，为VGG风格的模型提供了准确性和部署成本之间令人信服的平衡。这些结果为构建适用于实时图像处理管道的资源高效深度学习模型提供了实用指导。所有代码和训练日志均可在 https://github.com/VineetKumarRakesh/lcnn-opt 公开访问。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [76] [Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks](https://arxiv.org/abs/2507.18675)
> *推进基于视觉的人体动作识别：探索视觉-语言CLIP模型在领域无关任务中的泛化能力*

*Utkarsh Shandilya, Marsha Mariya Kappan, Sanyam Jain, Vijeta Sharma* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 人体动作识别, CLIP模型, 视觉-语言模型, 泛化能力, 医疗健康

**Comment:** 

> **TL;DR:** 本文评估了CLIP模型在人体动作识别任务中的泛化能力，发现其在视觉线索受损时表现不佳，并提出通过引入类别特异性噪声来提高其性能和泛化能力。

**AI_Comments:** 本文创新性地将视觉-语言CLIP模型应用于人体动作识别，并针对其在视觉线索受损时的局限性提出了引入类别特异性噪声的解决方案，有效提升了模型性能。这对于推动CLIP模型在医疗健康等对泛化能力要求高的领域应用具有重要意义。局限性在于，虽然提出了改进方法，但仍需进一步探索其在真实复杂医疗场景中的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的人体动作识别模型（如CNN和RNN）难以泛化到多样和复杂的动作。视觉-语言模型，特别是基于Transformer的CLIP模型，在从视频数据中泛化动作识别方面展现出潜力。

**Method:** 研究人员在UCF-101数据集上评估了CLIP模型，并系统分析了其在三种遮罩策略下的性能：（1）10%、30%和50%的基于百分比和形状的黑色遮罩；（2）特征特异性遮罩以抑制偏差引入元素；（3）隔离遮罩，仅保留类别特定区域。为了克服CLIP的局限性，提出通过定制损失函数学习并引入类别特异性噪声，以增强对类别定义特征的关注。

**Result:** 结果显示，CLIP模型表现出不一致的行为和频繁的错误分类，尤其是在关键视觉线索被遮蔽时。通过引入类别特异性噪声的增强方案，提高了分类准确性和模型置信度，并减少了偏差。

**Conclusion:** 尽管CLIP模型在人体动作识别中面临挑战，特别是在关键视觉线索受损时，但通过引入类别特异性噪声可以有效提升其性能和泛化能力。未来工作将致力于改善模型在领域无关医疗场景中的泛化能力。

> **ai_Abstract:** 本文探讨了视觉-语言CLIP模型在基于视觉的人体动作识别中的泛化能力，特别是在医疗健康应用中。研究人员在UCF-101数据集上评估了CLIP在不同视觉遮蔽策略下的表现，发现其在关键视觉线索缺失时性能不佳。为解决此问题，论文提出通过学习并引入类别特异性噪声来强化对核心特征的关注，从而有效提升了模型的分类准确性、置信度并减少了偏差。文章最后讨论了在临床领域应用的挑战及未来的研究方向。

> **摘要翻译:** 人体动作识别在医疗健康领域中扮演着关键角色，支持患者行为监测、跌倒检测、手术机器人监督和程序技能评估等应用。尽管CNN和RNN等传统模型取得了中等成功，但它们通常难以泛化到多样和复杂的动作。视觉-语言模型，特别是基于Transformer的CLIP模型，在从视频数据中泛化动作识别方面提供了有前景的能力。在这项工作中，我们在UCF-101数据集上评估了CLIP模型，并系统分析了其在三种遮罩策略下的性能：（1）10%、30%和50%的基于百分比和形状的黑色遮罩；（2）特征特异性遮罩以抑制偏差引入元素；（3）隔离遮罩，仅保留类别特定区域。我们的结果显示，CLIP模型表现出不一致的行为和频繁的错误分类，特别是在关键视觉线索被遮蔽时。为了克服这些局限性，我们提出通过定制损失函数学习并引入类别特异性噪声，以增强对类别定义特征的关注。这一增强提高了分类准确性和模型置信度，同时减少了偏差。最后，我们讨论了在临床领域应用此类模型的挑战，并概述了未来工作方向，以提高在领域无关医疗场景中的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [86] [Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality](https://arxiv.org/abs/2507.23253)
> *走向通过图像模态测量和建模时间序列预测中的几何结构*

*Mingyang Yu, Xiahui Guo, Peng chen, Zhenkai Li, Yang Shu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 时间序列预测, 几何结构, 图像模态, TGSI, SATL

**Comment:** 

> **TL;DR:** 提出TGSI评估时间序列几何结构，并引入SATL训练损失，通过结合一阶差分、频域和感知特征损失，有效提升时间序列预测中几何结构建模能力。

**AI_Comments:** 这项工作创新性地将图像模态引入时间序列分析，通过TGSI量化了传统指标无法衡量的几何结构。SATL的设计巧妙地解决了TGSI不可微的问题，通过多组件损失函数在时间序列模态下实现了几何结构的建模，为时间序列预测提供了一种更全面的评估和训练范式。其优势在于提升了预测的“形状”准确性，而非仅是点对点精度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的时间序列预测数值指标（如MSE）无法评估时间序列数据的几何结构，而几何结构对于理解时间动态至关重要。

**Method:** 提出时间序列几何结构指数（TGSI）作为新的评估指标，通过将时间序列转换为图像来利用其二维几何表示。由于TGSI不可微分，进一步引入了形状感知时间损失（SATL）作为多组件损失函数，用于训练阶段增强结构建模。SATL包含三个组件：测量结构一致性的一阶差分损失、捕获周期模式的频域损失，以及通过对齐时间特征与几何结构特征来测量几何结构差异的感知特征损失。

**Result:** 实验表明，使用SATL训练的模型在MSE和所提出的TGSI指标上均优于基线方法，且在推理过程中没有额外的计算成本。

**Conclusion:** 通过引入TGSI评估指标和SATL训练损失，可以有效提升时间序列预测模型对几何结构的测量和建模能力，从而改善预测性能。

> **ai_Abstract:** 本文提出了一种新的时间序列几何结构评估指标TGSI，通过将时间序列转换为图像来捕捉其二维几何特征。鉴于TGSI不可微分，作者进一步引入了形状感知时间损失SATL，这是一种多组件训练损失，包含一阶差分损失、频域损失和感知特征损失，旨在提升模型在训练阶段对时间序列几何结构的建模能力。实验结果表明，SATL显著提高了预测模型在传统精度和几何结构评估上的表现，且不增加推理开销。

> **摘要翻译:** 时间序列预测在天气预报、金融投资和交通管理等不同领域至关重要。虽然均方误差（MSE）等传统数值指标可以量化点式精度，但它们未能评估时间序列数据的几何结构，而几何结构对于理解时间动态至关重要。为了解决这个问题，我们提出了时间序列几何结构指数（TGSI），这是一种新颖的评估指标，它将时间序列转换为图像以利用其固有的二维几何表示。然而，由于图像转换过程是不可微分的，TGSI无法直接作为训练损失集成。我们进一步引入了形状感知时间损失（SATL），这是一种在时间序列模态中运行的多组件损失函数，旨在弥补这一差距并在训练期间增强结构建模。SATL结合了三个组件：通过一阶差分之间的MSE测量结构一致性的一阶差分损失；利用快速傅里叶变换捕获基本周期模式同时最小化噪声的频域损失；以及通过预训练的时间特征提取器和时间序列图像自编码器将时间特征与几何结构特征对齐来测量时间序列中几何结构差异的感知特征损失。在多个数据集上的实验表明，与基线方法相比，使用SATL训练的模型在MSE和所提出的TGSI指标上均取得了优异的性能，且在推理过程中没有额外的计算成本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [87] [Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning](https://arxiv.org/abs/2507.23479)
> *以少见多：基于多任务学习的视频胶囊内窥镜*

*Julia Werner, Oliver Bause, Julius Oexle, Maxime Le Floch, Franz Brinkmann, Jochen Hampe, Oliver Bringmann* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频胶囊内窥镜, 多任务学习, 自定位, 异常检测, 边缘计算

**Comment:** Accepted at Applications of Medical AI (AMAI workshop) at MICCAI 2025
  (submitted version)

> **TL;DR:** 本文提出了一种多任务神经网络，用于视频胶囊内窥镜，在一个小型模型中结合了胃肠道内精确自定位和异常检测功能，解决了电池寿命和资源限制问题，并在Galar数据集上取得了优于现有单任务模型的成果。

**AI_Comments:** 本文创新性地提出了一种紧凑的多任务AI模型，有效解决了视频胶囊内窥镜在电池寿命和设备资源方面的实际限制。其在一个小型模型中结合定位和异常检测的能力，为可实际部署的智能胶囊提供了重要的诊断和导航功能。仅需100万参数即可超越基线性能，这一点尤其值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 视频胶囊内窥镜的电池寿命短，且由于数据稀疏性和设备资源有限，集成人工智能以实现智能实时决策面临挑战。本文旨在通过AI降低能耗，延长电池寿命。

**Method:** 研究引入了一个多任务神经网络，在一个模型中结合了胃肠道内精确自定位和检测小肠异常的功能。开发过程中严格限制了总参数数量以适应小型胶囊部署。模型集成了已建立的多任务方法和维特比解码，并使用Galar数据集进行评估。

**Result:** 该模型在定位任务上实现了93.63%的准确率，在异常检测任务上实现了87.48%的准确率。该方法仅需要100万个参数，同时超越了当前的基线。

**Conclusion:** 所提出的多任务模型在视频胶囊内窥镜的AI应用方面取得了重大进展，其紧凑的设计和优越的性能使其能够克服现有设备的局限性，并有望实际部署。

> **ai_Abstract:** 本文提出了一种针对视频胶囊内窥镜的多任务神经网络，旨在解决设备电池寿命短和资源受限的问题。该模型在一个紧凑的框架内集成了胃肠道内的精确自定位和异常检测功能。通过严格控制模型参数数量（仅100万），确保了在小型胶囊中的部署可行性。在Galar数据集上的实验表明，该多任务模型在定位和异常检测任务上分别达到了93.63%和87.48%的准确率，性能超越了现有的单任务基线模型，代表了该领域AI应用的重要进展。

> **摘要翻译:** 视频胶囊内窥镜在胃肠道小肠检查中变得越来越重要。然而，此类紧凑型传感器边缘设备的电池寿命短是一个持续存在的挑战。集成人工智能可以通过实现智能实时决策来帮助克服这一限制，从而降低能耗并延长电池寿命。然而，由于数据稀疏性和设备资源有限，这仍然具有挑战性，限制了整体模型大小。在这项工作中，我们引入了一种多任务神经网络，在一个模型中结合了胃肠道内精确自定位功能和检测小肠异常的能力。在整个开发过程中，我们始终限制总参数数量，以确保此类模型在小型胶囊中部署的可行性。我们报告了使用最近发布的Galar数据集的首次多任务结果，集成了已建立的多任务方法和用于后续时间序列分析的维特比解码。这优于当前的单任务模型，代表了该领域基于人工智能方法的重大进展。我们的模型在定位任务上达到了93.63%的准确率，在异常检测任务上达到了87.48%的准确率。该方法仅需要100万个参数，同时超越了当前的基线。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [88] [Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space](https://arxiv.org/abs/2503.09215)
> *其他车辆轨迹也需要：一种驾驶世界模型统一视频潜在空间中的自我-其他车辆轨迹*

*Jian Zhu, Zhengyu Jia, Tian Gao, Jiaxin Deng, Shidi Li, Lang Zhang, Fu Liu, Peng Jia, Xianpeng Lang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 驾驶世界模型, 轨迹预测, 视频生成, 自动驾驶, 潜在空间

**Comment:** 8 pages, 7 figures

> **TL;DR:** 现有的自动驾驶世界模型主要关注自车轨迹，限制了真实交互。本文提出了EOT-WM，一个统一自车和其他车辆轨迹的驾驶世界模型，用于视频潜在空间中的驾驶模拟，并在性能上显著优于现有技术。

**AI_Comments:** 该论文通过整合其他车辆轨迹，解决了自动驾驶世界模型中的一个关键局限性，这对于实现真实的交互模拟至关重要。所提出的EOT-WM模型及其多阶段方法（投影、时空变分自编码器、扩散Transformer）和新颖的评估指标，展示了在可控驾驶场景视频生成方面的显著性能提升，突显了其创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动驾驶世界模型主要强调自车轨迹，而忽略了对其他车辆的控制，这阻碍了它们真实模拟自车与驾驶场景之间交互的能力。

**Method:** 本文提出了EOT-WM（自车-其他车辆轨迹世界模型）。具体方法包括：1. 将BEV空间中的自车-其他车辆轨迹通过像素位置投影到图像坐标中，以实现车辆-轨迹匹配。2. 使用时空变分自编码器（Spatial-Temporal Variational Auto Encoder）对轨迹视频进行编码，使其在统一的视觉空间中与驾驶视频潜在空间进行时空对齐。3. 设计一个轨迹注入扩散Transformer，用于在自车-其他车辆轨迹的引导下去噪视频潜在空间以生成视频。4. 提出一种基于控制潜在相似性的新度量来评估轨迹的可控性。

**Result:** 在nuScenes数据集上进行了大量实验，结果表明：所提出的模型在FID（Fréchet Inception Distance）上优于现有最先进方法30%，在FVD（Fréchet Video Distance）上优于55%。该模型还可以通过自生成轨迹预测未见的驾驶场景。

**Conclusion:** EOT-WM模型通过统一自车和其他车辆的轨迹，有效解决了现有世界模型在驾驶模拟中的局限性，实现了更真实的交互模拟，并在生成可控驾驶场景方面取得了卓越性能。

> **ai_Abstract:** 本文提出了EOT-WM，一种新颖的驾驶世界模型，通过在视频潜在空间中统一自车和其他车辆的轨迹来解决现有模型仅关注自车轨迹的局限性。该模型将BEV轨迹投影到图像坐标，利用时空变分自编码器进行对齐，并使用轨迹注入扩散Transformer进行视频生成。在nuScenes数据集上的实验表明，EOT-WM在性能上显著优于现有技术（FID提高30%，FVD提高55%），并且能够预测未见的场景，从而增强了自动驾驶模拟的真实性。

> **摘要翻译:** 先进的端到端自动驾驶系统预测其他车辆的运动并规划自车轨迹。能够预见轨迹结果的世界模型已被用于评估自动驾驶系统。然而，现有的世界模型主要强调自车轨迹，而使其他车辆不可控。这一限制阻碍了它们真实模拟自车与驾驶场景之间交互的能力。在本文中，我们提出了一种名为EOT-WM的驾驶世界模型，统一了视频中的自车-其他车辆轨迹，用于驾驶模拟。具体而言，将BEV空间中的多条轨迹与视频中的每辆车匹配以控制视频生成仍然是一个挑战。我们首先通过像素位置将BEV空间中的自车-其他车辆轨迹投影到图像坐标中，以进行车辆-轨迹匹配。然后，通过时空变分自编码器对轨迹视频进行编码，以在统一的视觉空间中在空间和时间上与驾驶视频潜在空间对齐。进一步设计了一个轨迹注入扩散Transformer来去噪嘈杂的视频潜在空间，以便在自车-其他车辆轨迹的引导下生成视频。此外，我们提出了一种基于控制潜在相似性的度量来评估轨迹的可控性。在nuScenes数据集上进行了大量实验，所提出的模型在FID上优于现有最先进方法30%，在FVD上优于55%。该模型还可以通过自生成轨迹预测未见的驾驶场景。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [95] [Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis](https://arxiv.org/abs/2507.23785)
> *高保真视频到4D合成的高斯变异场扩散*

*Bowen Zhang, Sicheng Xu, Chuxin Wang, Jiaolong Yang, Feng Zhao, Dong Chen, Baining Guo* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频到4D合成, 高斯泼溅, 扩散模型, 4D内容生成, 变异场

**Comment:** ICCV 2025. Project page: https://gvfdiffusion.github.io/

> **TL;DR:** 本文提出了一种新颖的视频到4D生成框架，通过引入直接4DMesh到GS变异场VAE和高斯变异场扩散模型，解决了4D扩散建模的挑战，实现了从单视频输入生成高质量动态3D内容，并展现出卓越的泛化能力。

**AI_Comments:** 这项工作通过引入创新的高斯变异场VAE和扩散模型，有效地解决了视频到4D合成中高维度和数据构建的挑战。其在合成数据上训练却能泛化到真实世界视频的能力，是其重要的创新点，显示了该方法在实际应用中的巨大潜力。它为未来高质量动态3D内容生成提供了新的思路和技术路线。

<details>
  <summary>Details</summary>

**Motivation:** 直接进行4D扩散建模极具挑战性，原因在于数据构建成本高昂以及联合表示3D形状、外观和运动所需的高维度性质。

**Method:** 本文引入了一个直接4DMesh到GS变异场VAE，用于直接编码规范高斯泼溅（GS）及其时间变化，并将高维动画压缩到紧凑的潜在空间。在此基础上，训练了一个高斯变异场扩散模型，该模型带有时间感知的扩散Transformer，并以输入视频和规范GS为条件。

**Result:** 与现有方法相比，本文模型展示了卓越的生成质量。尽管仅在合成数据上训练，但对野外视频输入也表现出显著的泛化能力。

**Conclusion:** 本文提出的框架通过有效的表示和扩散模型，成功解决了视频到4D合成中的挑战，实现了高质量的动态3D内容生成，并具有良好的泛化性，为创建高质量动画3D内容铺平了道路。

> **ai_Abstract:** 本文提出了一种名为高斯变异场扩散的新颖框架，用于从单视频输入生成高保真4D动态3D内容。为克服直接4D扩散建模的高成本和高维度挑战，该方法引入了直接4DMesh到GS变异场VAE，将高维动画压缩到紧凑潜在空间。在此基础上，训练了一个时间感知的Diffusion Transformer高斯变异场扩散模型。该模型在合成数据上训练，表现出优于现有方法的生成质量，并对野外视频输入具有出色的泛化能力，为高质量动画3D内容生成开辟了新途径。

> **摘要翻译:** 在本文中，我们提出了一种新颖的视频到4D生成框架，可以从单个视频输入创建高质量的动态3D内容。由于昂贵的数据构建和联合表示3D形状、外观和运动所需的高维性质，直接进行4D扩散建模极具挑战性。我们通过引入一个直接4DMesh到GS变异场VAE来应对这些挑战，该VAE直接编码规范高斯泼溅（GS）及其来自3D动画数据的时间变化，无需每个实例拟合，并将高维动画压缩到紧凑的潜在空间。基于这种高效的表示，我们训练了一个高斯变异场扩散模型，该模型带有时间感知的扩散Transformer，并以输入视频和规范GS为条件。我们的模型在精心策划的来自Objaverse数据集的可动画3D对象上进行训练，与现有方法相比，展示了卓越的生成质量。尽管仅在合成数据上训练，它对野外视频输入也表现出显著的泛化能力，为生成高质量动画3D内容铺平了道路。项目页面：https://gvfdiffusion.github.io/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [96] [RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground Simulation](https://arxiv.org/abs/2503.10410)
> *RoCo-Sim：通过前景模拟增强路边协同感知*

*Yuwen Du, Anning Hu, Zichen Chao, Yifan Lu, Junhao Ge, Genjia Liu, Weitao Wu, Lanjun Wang, Siheng Chen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 路边协同感知, 模拟框架, 前景模拟, 3D目标检测, 数据增强

**Comment:** 

> **TL;DR:** RoCo-Sim是一个模拟框架，通过动态前景编辑和全场景风格迁移，生成多样化、多视图一致的模拟路边数据，显著提升路边3D目标检测性能，解决了现有路边协同感知数据问题。

**AI_Comments:** RoCo-Sim的创新之处在于它是第一个针对路边协同感知的模拟框架，通过引入动态前景编辑和全场景风格迁移来解决实际数据问题。其模块化的设计（摄像头外参优化、MOAS、DepthSAM、后处理工具包）使其能够系统地生成高质量、多视图一致的模拟数据。该工作对于提升路边协同感知的性能具有重要意义，尤其是在数据获取和标注成本高昂的实际应用中。

<details>
  <summary>Details</summary>

**Motivation:** 现有路边感知方法侧重于模型设计，但忽视了标定误差、信息稀疏和多视图一致性等数据问题，导致在最新发布的数据集上性能不佳。为显著增强路边协同感知并解决关键数据问题，本文提出了RoCo-Sim。

**Method:** RoCo-Sim是第一个用于路边协同感知的模拟框架。它通过动态前景编辑和单图像的全场景风格迁移来生成多样化、多视图一致的模拟路边数据。RoCo-Sim包含四个组件：(1) 摄像头外参优化，确保路边摄像头的准确3D到2D投影；(2) 一种新颖的多视图遮挡感知采样器（MOAS），用于确定不同数字资产在3D空间中的放置；(3) DepthSAM，创新性地从单帧固定视图图像中建模前景-背景关系，确保前景的多视图一致性；(4) 可扩展的后处理工具包，通过风格迁移和其他增强生成更真实和丰富的场景。

**Result:** RoCo-Sim显著改善了路边3D目标检测，在Rcooper-Intersection数据集上AP70性能超越SOTA方法83.74，在TUMTraf-V2X数据集上超越SOTA方法83.12。

**Conclusion:** RoCo-Sim填补了路边感知模拟中的一个关键空白。

> **ai_Abstract:** 本文提出了RoCo-Sim，一个创新的路边协同感知模拟框架，旨在解决现有方法中存在的数据问题，如校准误差、信息稀疏和多视图一致性。RoCo-Sim通过动态前景编辑和全场景风格迁移，能够生成多样化且多视图一致的模拟数据。该框架包含摄像头外参优化、多视图遮挡感知采样器（MOAS）、DepthSAM以及可扩展的后处理工具包等关键组件。实验结果表明，RoCo-Sim显著提升了路边3D目标检测的性能，在多个数据集上超越了现有SOTA方法。

> **摘要翻译:** 路边协同感知是指一个系统，其中多个路边单元协作汇集其感知数据，以帮助车辆增强其环境感知能力。现有的路边感知方法专注于模型设计，但忽视了标定误差、信息稀疏和多视图一致性等数据问题，导致在最新发布的数据集上性能不佳。为显著增强路边协同感知并解决关键数据问题，我们提出了第一个用于路边协同感知的模拟框架RoCo-Sim。RoCo-Sim能够通过动态前景编辑和单图像的全场景风格迁移来生成多样化、多视图一致的模拟路边数据。RoCo-Sim由四个组件组成：(1) 摄像头外参优化，确保路边摄像头的准确3D到2D投影；(2) 一种新颖的多视图遮挡感知采样器（MOAS），用于确定不同数字资产在3D空间中的放置；(3) DepthSAM创新性地从单帧固定视图图像中建模前景-背景关系，确保前景的多视图一致性；(4) 可扩展的后处理工具包，通过风格迁移和其他增强生成更真实和丰富的场景。RoCo-Sim显著改善了路边3D目标检测，在Rcooper-Intersection数据集上AP70性能超越SOTA方法83.74，在TUMTraf-V2X数据集上超越SOTA方法83.12。RoCo-Sim填补了路边感知模拟中的一个关键空白。代码和预训练模型将很快发布：https://github.com/duyuwen-duen/RoCo-Sim

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [100] [FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning](https://arxiv.org/abs/2507.23318)
> *FastDriveVLA：通过即插即用重建式令牌剪枝实现高效端到端驾驶*

*Jiajun Cao, Qizhe Zhang, Peidong Jia, Xuhui Zhao, Bo Lan, Xiaoan Zhang, Xiaobao Wei, Sixiang Chen, Zhuo Li, Yang Wang, Liyun Li, Xianming Liu, Ming Lu, Shanghang Zhang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 视觉-语言-动作模型, 令牌剪枝, 自动驾驶, 前景重建, FastDriveVLA

**Comment:** 9 pages, 5 figures

> **TL;DR:** FastDriveVLA通过重建式令牌剪枝，提升VLA模型在自动驾驶中的效率和性能，专注于保留前景信息。

**AI_Comments:** 本文提出了一种新颖的重建式令牌剪枝方法，专为自动驾驶场景优化，通过优先处理前景信息，有效解决了VLA模型高计算成本的问题。其即插即用的设计和新数据集的引入增加了其实用性和影响力，为VLA模型在自动驾驶中的高效部署提供了重要途径。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作（VLA）模型在自动驾驶中计算成本高昂，且现有视觉令牌剪枝方法在自动驾驶场景中表现不佳，未能有效关注前景信息。

**Method:** 提出FastDriveVLA框架，包含一个即插即用的ReconPruner视觉令牌剪枝器。ReconPruner通过MAE风格的像素重建优先处理前景信息，并采用对抗性前景-背景重建策略进行训练。该方法引入了nuScenes-FG数据集（24.1万张图像-掩码对），并且ReconPruner训练后可无缝应用于具有相同视觉编码器的不同VLA模型。

**Result:** 在nuScenes闭环规划基准测试中，在不同剪枝率下均取得了最先进的结果。

**Conclusion:** FastDriveVLA通过其新颖的重建式令牌剪枝方法，显著提高了VLA模型在自动驾驶中的效率和性能，有效解决了高计算成本问题。

> **ai_Abstract:** FastDriveVLA是一个为自动驾驶设计的视觉令牌剪枝框架，旨在解决VLA模型计算成本高和现有剪枝方法效率低的问题。它引入了ReconPruner，一个基于MAE风格像素重建的即插即用剪枝器，通过对抗性重建策略训练，优先保留前景信息。该方法在nuScenes闭环规划基准上达到了最先进的性能，并引入了nuScenes-FG数据集。

> **摘要翻译:** 视觉-语言-动作（VLA）模型在复杂场景理解和动作推理方面展现出巨大潜力，因此在端到端自动驾驶系统中得到越来越多的应用。然而，VLA模型的长视觉令牌极大地增加了计算成本。当前视觉-语言模型（VLM）中的视觉令牌剪枝方法要么依赖于视觉令牌相似性，要么依赖于视觉-文本注意力，但这两种方法在自动驾驶场景中都表现不佳。鉴于人类驾驶员在驾驶时会集中于相关的前景区域，我们认为保留包含前景信息的视觉令牌对于有效的决策至关重要。受此启发，我们提出了FastDriveVLA，一个专门为自动驾驶设计的基于重建的新型视觉令牌剪枝框架。FastDriveVLA包含一个即插即用的视觉令牌剪枝器，名为ReconPruner，它通过MAE风格的像素重建优先处理前景信息。设计了一种新颖的对抗性前景-背景重建策略来训练VLA模型的视觉编码器ReconPruner。一旦训练完成，ReconPruner可以无缝应用于具有相同视觉编码器的不同VLA模型而无需重新训练。为了训练ReconPruner，我们还引入了一个名为nuScenes-FG的大型数据集，包含24.1万张带有前景区域标注的图像-掩码对。我们的方法在nuScenes闭环规划基准测试中，在不同剪枝率下均取得了最先进的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [105] [CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam](https://arxiv.org/abs/2507.22958)
> *CHECK-MAT：检查俄罗斯统一国家考试手写数学答案*

*Ruslan Khrulev* | **Category: cs.CV, cs.AI, cs.LG, 68T07, 97D50, I.2.7; I.4; K.3.1** | **Updated: 2025-07-29**

**Keywords:** 数学评估, 视觉-语言模型, 手写识别, 俄罗斯统一国家考试, 基准测试

**Comment:** 15 pages, 3 figures, 10 tables. Code is available at:
  https://github.com/Karifannaa/Auto-check-EGE-math

> **TL;DR:** 本文介绍了EGE-Math Solutions Assessment Benchmark，这是一个用于评估视觉-语言模型评估手写数学解题能力的基准，揭示了当前模型在数学推理和人类评分标准对齐方面的局限性。

**AI_Comments:** 该论文通过引入一个专注于评估手写数学答案的新基准，填补了现有视觉-语言模型评估领域的一个空白。其创新之处在于将评估重点从问题解决转移到理解和评分学生解决方案，这对于AI辅助教育和考试评估具有重要意义。结果揭示了当前模型在数学推理和与人类评分标准对齐方面的局限性，为未来的研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有基准侧重于问题解决，而本文的动机是评估视觉-语言模型理解学生手写数学解决方案、识别错误并根据固定标准进行评分的能力。

**Method:** 本文编译了122份来自俄罗斯统一国家考试(EGE)的扫描解决方案，以及官方专家评分。然后，评估了来自Google、OpenAI、Arcee AI和Alibaba Cloud的七种现代视觉-语言模型，采用三种推理模式。

**Result:** 结果显示，当前模型在数学推理和人类评分标准对齐方面存在局限性。

**Conclusion:** 视觉-语言模型在评估手写数学答案方面仍有待改进，为AI辅助评估开辟了新的研究方向。

> **ai_Abstract:** 本文提出了EGE-Math Solutions Assessment Benchmark，一个用于评估视觉-语言模型对手写数学答案进行评估的新基准。该基准不同于以往的解题型基准，它专注于理解学生解题过程、发现错误并依据既定标准评分。研究收集了122份俄罗斯统一国家考试的扫描答案及专家评分，并用此评估了七种主流视觉-语言模型。结果表明，现有模型在数学推理能力和与人工评分标准的一致性方面存在不足，这为AI辅助评估领域指明了新的研究方向。

> **摘要翻译:** 本文介绍了一个新颖的基准——EGE-Math Solutions Assessment Benchmark，用于评估视觉-语言模型（VLM）评估手写数学解决方案的能力。与现有专注于问题解决的基准不同，我们的方法侧重于理解学生解决方案、识别错误并根据固定标准分配分数。我们汇编了122份来自俄罗斯统一国家考试（EGE）的扫描解决方案以及官方专家评分，并以三种推理模式评估了来自Google、OpenAI、Arcee AI和Alibaba Cloud的七种现代VLM。结果揭示了当前在数学推理和人类评分标准对齐方面的局限性，为AI辅助评估开辟了新的研究途径。代码可在https://github.com/Karifannaa/Auto-check-EGE-math找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [114] [Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels](https://arxiv.org/abs/2507.23263)
> *学习语义感知阈值用于部分标签的多标签图像识别*

*Haoxian Ruan, Zhihua Xu, Zhijing Yang, Guang Ma, Jieming Xie, Changxiang Fan, Tianshui Chen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多标签图像识别, 部分标签, 语义感知阈值, 伪标签, 差分排序损失

**Comment:** 15 pages, 13 figures, publish to ESWA (Expert Systems With
  Applications)

> **TL;DR:** 针对部分标签多标签图像识别，本文提出语义感知阈值学习（SATL）算法，通过动态计算类别特异性阈值并结合差分排序损失，显著提升了在有限标签场景下的性能。

**AI_Comments:** 本文创新点在于提出了动态的、类别特异性的阈值学习方法（SATL），并引入差分排序损失来优化阈值判别。这有效解决了传统方法中预设固定阈值带来的伪标签不准确问题，对于部分标签的多标签图像识别任务具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的部分标签多标签图像识别方法依赖预设阈值生成伪标签，但忽略了类别间分数分布差异，导致伪标签不准确和不完整，从而影响性能。

**Method:** 本文提出语义感知阈值学习（SATL）算法。该算法为每个类别计算正负样本的分数分布，并基于这些分布确定类别特异性阈值，这些分布和阈值在学习过程中动态更新。此外，引入差分排序损失以增大正负样本分数分布间的差距，增强阈值判别力。

**Result:** 在Microsoft COCO和VG-200等大规模多标签数据集上的综合实验和分析表明，所提出的方法显著提升了在有限标签场景下的性能。

**Conclusion:** 本文提出的SATL算法通过动态、类别特异性的阈值学习和差分排序损失，有效解决了部分标签多标签图像识别中伪标签不准确的问题，显著提高了模型性能。

> **ai_Abstract:** 本文针对部分标签多标签图像识别（MLR-PL）中传统方法预设阈值导致伪标签不准确的问题，提出了一种语义感知阈值学习（SATL）算法。该算法通过动态计算每个类别的正负样本分数分布，并据此确定类别特异性阈值。为增强阈值判别力，还引入了差分排序损失。实验证明，该方法在有限标签场景下显著提升了性能。

> **摘要翻译:** 部分标签多标签图像识别（MLR-PL）旨在利用已知和未知标签的混合数据训练模型。传统方法依赖语义或特征相关性，通过预设阈值创建未识别标签的伪标签。这种方法通常忽略了类别间分数分布的差异，导致伪标签不准确和不完整，从而影响性能。在我们的研究中，我们引入了语义感知阈值学习（SATL）算法。这种创新方法计算每个类别中正样本和负样本的分数分布，并根据这些分布确定类别特异性阈值。这些分布和阈值在学习过程中动态更新。此外，我们实施了差分排序损失，以在正负样本的分数分布之间建立显著差距，从而增强阈值的判别能力。在Microsoft COCO和VG-200等大规模多标签数据集上的综合实验和分析表明，我们的方法显著提升了在有限标签场景下的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [116] [Learning to Align and Refine: A Foundation-to-Diffusion Framework for Occlusion-Robust Two-Hand Reconstruction](https://arxiv.org/abs/2503.17788)
> *学习对齐与细化：一种从基础到扩散的遮挡鲁棒双手重建框架*

*Gaoge Han, Yongkang Cheng, Zhe Chen, Shaoli Huang, Tongliang Liu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 双手重建, 遮挡鲁棒, 扩散模型, 基础模型, 姿态估计

**Comment:** 

> **TL;DR:** 本文提出了一个双阶段“基础到扩散”框架，用于从单目图像中进行遮挡鲁棒的双手重建，有效解决了现有方法在复杂手势和遮挡下对齐和穿透伪影的问题。

**AI_Comments:** 该论文的创新点在于其独特的双阶段“基础到扩散”框架，巧妙地结合了视觉基础模型提供的2D先验知识与扩散模型的3D生成和细化能力。这种结合不仅有效解决了双手重建中长期存在的遮挡和穿透难题，而且通过轻量级编码器设计实现了高效推理，具有重要的实践意义和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 从单目图像中进行双手重建面临复杂动态手势和遮挡的持续挑战，导致难以实现合理的交互对齐。现有方法在处理这些对齐问题时表现不佳，常常导致错位和穿透伪影。

**Method:** 本文提出了一个双阶段的“基础到扩散”框架。首先，引入一个轻量级融合对齐编码器，在训练期间对齐来自视觉基础模型的多模态2D先验（如关键点、分割图和深度线索），从而在测试时无需重型基础模型编码器即可实现高效推理并保持高重建精度。其次，实现了一个双手扩散模型，该模型经过专门训练，将相互穿透的3D姿态转换为可信的、无穿透的对应物，并通过碰撞梯度引导去噪来纠正伪影，同时保留手部之间自然的空间关系。

**Result:** 该方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，显著提升了遮挡处理和交互鲁棒性。

**Conclusion:** 该“基础到扩散”框架通过精确对齐2D先验指导和扩散生成3D交互细化，有效解决了单目图像双手重建中的遮挡和穿透问题，实现了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为“基础到扩散”的双阶段框架，旨在解决单目图像双手重建中常见的遮挡和穿透问题。该框架首先利用轻量级融合对齐编码器，在训练阶段整合来自视觉基础模型的2D先验信息，为后续处理提供鲁棒指导，并在推理时保持高效。接着，一个专门训练的双手扩散模型通过碰撞梯度引导去噪，将不合理的3D穿透姿态修正为自然无穿透的形态。实验结果表明，该方法在多个标准数据集上表现出最先进的性能，显著提升了遮挡处理和交互的鲁棒性。

> **摘要翻译:** 从单目图像中进行双手重建面临复杂动态手势和遮挡带来的持续挑战，导致实现合理的交互对齐非常困难。现有方法在处理此类对齐问题时表现不佳，常常导致错位和穿透伪影。为了解决这个问题，我们提出了一个双阶段的“基础到扩散”框架，该框架精确对齐来自视觉基础模型的2D先验指导，并结合基于扩散的生成式3D交互细化，以实现遮挡鲁棒的双手重建。首先，我们引入了一个轻量级融合对齐编码器，该编码器在训练期间对齐来自视觉基础模型的多模态2D先验，如关键点、分割图和深度线索。这提供了鲁棒的结构化指导，进一步使得在测试时无需重型基础模型编码器即可进行高效推理，同时保持高重建精度。其次，我们实现了一个双手扩散模型，该模型经过显式训练，将相互穿透的3D姿态转换为可信的、无穿透的对应物。通过碰撞梯度引导去噪，该模型纠正了伪影，同时保留了手部之间自然的空间关系。广泛的评估表明，我们的方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，显著提升了遮挡处理和交互鲁棒性。我们的代码将公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [117] [Human-in-the-Loop Local Corrections of 3D Scene Layouts via Infilling](https://arxiv.org/abs/2503.11806)
> *循环中的人对3D场景布局的局部修正通过填充*

*Christopher Xie, Armen Avetisyan, Henry Howard-Jenkins, Yawar Siddiqui, Julian Straub, Richard Newcombe, Vasileios Balntas, Jakob Engel* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 3D场景布局, 人机协作, 局部修正, 填充, SceneScript

**Comment:** Project page: https://www.projectaria.com/scenescript/

> **TL;DR:** 本文提出了一种新颖的人机协作方法，通过将3D场景布局的局部修正建模为“填充”任务，显著提高了模型的局部修正能力，并支持对复杂布局的准确建模。

**AI_Comments:** 这项工作创新性地将自然语言处理中的“填充”概念应用于3D场景布局的局部修正，并成功地将其集成到一个人机协作系统中。其“一键修复”的工作流设计降低了用户交互的摩擦，显著提升了可用性。通过允许最终布局偏离训练分布，该系统在处理复杂和新颖的场景布局方面展现出强大的灵活性和潜力，超越了传统数据驱动方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过引入人类反馈来提高3D场景布局估计的准确性和灵活性，特别是解决局部错误修正的问题，并使最终布局能够偏离训练分布以建模更复杂的场景。

**Method:** 该方法基于SceneScript框架，引入了一个新的局部修正任务，将问题结构化为自然语言处理中的“填充”任务。研究者训练了一个多任务版本的SceneScript，并在一个集成的人机协作系统中实现了“一键修复”的迭代修正工作流。

**Result:** 训练后的多任务SceneScript在保持全局预测性能的同时，显著提高了局部修正能力。该系统允许最终修正的布局偏离训练分布，从而能够更准确地建模复杂布局。

**Conclusion:** 该研究成功开发了一个人机协作系统，通过将自然语言处理中的“填充”概念创新性地应用于3D场景布局的局部修正，提高了复杂场景建模的准确性和灵活性。

> **ai_Abstract:** 本文提出了一种新颖的人机协作方法，用于3D场景布局的局部修正。该方法基于SceneScript框架，将局部错误修正任务建模为自然语言处理中的“填充”问题。通过训练多任务版本的SceneScript，系统在保持全局预测能力的同时，显著提升了局部修正能力。该人机协作系统允许用户通过“一键修复”工作流迭代地完善布局，并能够处理偏离训练分布的复杂场景，从而实现更准确的建模。

> **摘要翻译:** 我们提出了一种新颖的人机协作方法，利用以自我为中心的人类反馈来估计3D场景布局。我们通过引入一个新的局部修正任务来研究这种方法，用户识别局部错误并提示模型自动修正它们。在SceneScript（一个利用结构化语言进行3D场景布局估计的最新框架）的基础上，我们提出了一种将此问题结构化为“填充”（自然语言处理中研究的任务）的解决方案。我们训练了一个多任务版本的SceneScript，它在保持全局预测性能的同时，显著提高了其局部修正能力。我们将此集成到一个人机协作系统中，使用户能够通过低摩擦的“一键修复”工作流迭代地完善场景布局估计。我们的系统使最终完善的布局能够偏离训练分布，从而能够更准确地建模复杂布局。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [118] [Exemplar Med-DETR: Toward Generalized and Robust Lesion Detection in Mammogram Images and beyond](https://arxiv.org/abs/2507.19621)
> *Exemplar Med-DETR：迈向乳腺X线图像及其他领域中广义和鲁棒性病灶检测*

*Sheethal Bhat, Bogdan Georgescu, Adarsh Bhandary Panambur, Mathias Zinnen, Tri-Thien Nguyen, Awais Mansoor, Karim Khalifa Elbarbary, Siming Bayer, Florin-Cristian Ghesu, Sasa Grbic, Andreas Maier* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 病灶检测, 乳腺X线, 多模态, 对比学习, Exemplar Med-DETR

**Comment:** I am asking for a withdrawal of the paper as I did not have
  institutional approval to release this paper right now

> **TL;DR:** Exemplar Med-DETR是一种新型多模态对比检测器，通过使用类特异性范例特征和迭代训练策略，在乳腺X线图像、胸部X光和血管造影等多种医学图像模态中实现了广义和鲁棒的病灶检测，并取得了最先进的性能。

**AI_Comments:** Exemplar Med-DETR的创新之处在于其独特的多模态对比学习框架和对类特异性范例特征的利用，这显著增强了模型在不同医学图像模态和任务中的泛化能力和鲁棒性。该方法通过解决现有检测方法在学习有效类特异性特征方面的局限性，为医学图像分析领域提供了一个重要的进步。在多种数据集和模态上取得的显著性能提升，特别是对出分布数据的有效性，强调了其在临床应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像中的异常检测面临独特挑战，因为特征表示差异以及解剖结构与异常之间复杂的相互关系。尤其是在乳腺X线摄影中，致密乳腺组织可能遮挡病灶，使放射学判读复杂化。尽管利用了解剖和语义上下文，现有检测方法仍难以学习有效的类特异性特征，限制了它们在不同任务和成像模态中的适用性。

**Method:** 本文引入了Exemplar Med-DETR，这是一种新颖的多模态对比检测器，能够进行基于特征的检测。它采用交叉注意力机制，利用固有派生、直观的类特异性范例特征，并采用迭代策略进行训练。

**Result:** 该方法在来自四个公共数据集的三种不同成像模态中均达到了最先进的性能。在越南致密乳腺X线图像上，肿块检测的mAP达到0.7，钙化检测的mAP达到0.55，绝对提高了16个百分点。此外，对来自分布外中国队列的100张乳腺X线图像进行的放射科医生支持的评估显示，病灶检测性能提高了两倍。对于胸部X光和血管造影，肿块检测的mAP达到0.25，狭窄检测的mAP达到0.37，分别提高了4和7个百分点。

**Conclusion:** 这些结果凸显了我们方法在推进用于医学成像的鲁棒和可泛化检测系统方面的潜力。

> **ai_Abstract:** 本研究提出Exemplar Med-DETR，一种新型多模态对比检测器，旨在解决医学图像中病灶检测的泛化性和鲁棒性挑战。该方法通过引入类特异性范例特征和迭代训练策略，能够有效学习和利用特征表示。实验结果表明，Exemplar Med-DETR在乳腺X线图像、胸部X光和血管造影等多种模态上均取得了最先进的性能，尤其在乳腺X线肿块和钙化检测、以及出分布数据上展现了显著提升，证明了其在构建通用且鲁棒的医学图像检测系统方面的巨大潜力。

> **摘要翻译:** 在医学图像中检测异常面临独特的挑战，这源于特征表示的差异以及解剖结构与异常之间错综复杂的关系。这在乳腺X线摄影中尤为明显，致密的乳腺组织可能会遮挡病灶，从而使放射学判读复杂化。尽管利用了解剖和语义上下文，现有的检测方法仍难以学习有效的类特异性特征，从而限制了它们在不同任务和成像模态中的适用性。在这项工作中，我们引入了Exemplar Med-DETR，这是一种新颖的多模态对比检测器，可实现基于特征的检测。它采用交叉注意力机制，利用固有派生、直观的类特异性范例特征，并采用迭代策略进行训练。我们在来自四个公共数据集的三种不同成像模态中均取得了最先进的性能。在越南致密乳腺X线图像上，我们实现了肿块检测0.7的mAP和钙化检测0.55的mAP，绝对提高了16个百分点。此外，对来自分布外中国队列的100张乳腺X线图像进行的放射科医生支持的评估表明，病灶检测性能提高了两倍。对于胸部X光和血管造影，我们实现了肿块检测0.25的mAP和狭窄检测0.37的mAP，分别提高了4和7个百分点。这些结果凸显了我们方法在推进用于医学成像的鲁棒和可泛化检测系统方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [124] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
> *用于自我中心视觉惯性跟踪的 Monado SLAM 数据集*

*Mateo de Mayo, Daniel Cremers, Taihú Pire* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** SLAM, VIO, 数据集, 头戴式设备, 视觉惯性跟踪

**Comment:** Accepted to IROS 2025

> **TL;DR:** 现有视觉惯性SLAM系统在头戴式场景中表现不佳，因为现有数据集缺乏挑战性数据。本文提出了Monado SLAM数据集，包含来自VR头显的真实序列，以推动VIO/SLAM研究。

**AI_Comments:** 该论文的创新之处在于识别并着手解决现有VIO/SLAM数据集在应对头戴式设备复杂使用场景（如极端运动、光照变化等）时的不足。通过发布一个专门针对这些挑战的真实世界数据集，它为研究人员提供了一个宝贵的资源，有望推动该领域更鲁棒、更实用的跟踪系统开发。其重要性在于，它直接服务于混合现实和机器人等前沿应用对高精度、高鲁棒性跟踪的需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉惯性里程计（VIO）和同步定位与建图（SLAM）系统在头戴式使用场景（如高强度运动、动态遮挡、长时间跟踪、低纹理区域、恶劣照明条件、传感器饱和等）中表现不佳，而现有数据集未能充分覆盖这些具有挑战性的真实世界问题。

**Method:** 作者提出了 Monado SLAM 数据集，该数据集包含从多个虚拟现实头戴设备中获取的真实序列，旨在解决现有数据集在头戴式使用场景中覆盖不足的问题。

**Result:** 结果是发布了 Monado SLAM 数据集，这是一个包含来自多个虚拟现实头戴设备的真实序列的集合，并以 CC BY 4.0 许可发布。

**Conclusion:** 通过发布 Monado SLAM 数据集，研究人员旨在推动视觉惯性里程计（VIO）和同步定位与建图（SLAM）领域的研究和发展，以更好地应对头戴式使用场景中的挑战。

> **ai_Abstract:** 本文针对现有视觉惯性里程计（VIO）和同步定位与建图（SLAM）系统在头戴式设备应用中面临的挑战（如高强度运动、动态遮挡、恶劣照明等）以及现有数据集未能充分覆盖这些真实世界问题的情况，提出了 Monado SLAM 数据集。该数据集包含从多个虚拟现实头戴设备获取的真实序列，并以开放许可发布，旨在促进 VIO/SLAM 领域的研究进展，以更好地应对复杂现实场景。

> **摘要翻译:** 人类机器人和混合现实头戴设备受益于使用头戴式传感器进行跟踪。尽管视觉惯性里程计（VIO）和同步定位与建图（SLAM）的进步已经产生了新的、高质量的先进跟踪系统，但我们表明，这些系统仍然无法优雅地处理头戴式使用场景中出现的许多挑战性设置。诸如高强度运动、动态遮挡、长时间跟踪会话、低纹理区域、恶劣照明条件、传感器饱和等常见场景，现有文献中的数据集仍然覆盖不足。通过这种方式，系统可能会无意中忽略这些重要的现实世界问题。为了解决这个问题，我们提出了 Monado SLAM 数据集，这是一组从多个虚拟现实头戴设备中获取的真实序列。我们根据宽松的 CC BY 4.0 许可发布该数据集，以推动 VIO/SLAM 研究和开发。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [129] [FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction](https://arxiv.org/abs/2507.23480)
> *FastPoint：通过样本点距离预测加速3D点云模型推理*

*Donghyun Lee, Dawoon Jeong, Jae W. Lee, Hongil Yoon* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D点云, 模型推理, 加速, 最远点采样, 距离预测

**Comment:** Accepted to ICCV 2025

> **TL;DR:** FastPoint是一种软件加速技术，通过预测最远点采样中的距离趋势，显著加速3D点云模型的推理，在不牺牲准确性的前提下实现2.55倍的端到端加速。

**AI_Comments:** FastPoint的创新之处在于其利用点云采样过程中的内在距离趋势进行预测，从而避免了传统方法中耗时的距离计算。这种基于软件的优化方案在不依赖特定硬件加速的情况下，显著提升了3D点云模型的推理效率，具有很高的实用价值和普适性。其在保证精度的前提下实现显著加速，对于实时3D应用和大规模点云处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在3D点云处理中面临的挑战是高效处理大型和不规则点云。

**Method:** 本文引入了FastPoint，一种新颖的基于软件的加速技术。它利用最远点采样过程中样本点之间可预测的距离趋势，通过预测距离曲线来高效识别后续样本点，而无需穷举计算所有成对距离。它加速了最远点采样和邻居搜索操作。

**Result:** FastPoint在不牺牲采样质量和模型性能的情况下，显著加速了最远点采样和邻居搜索操作。将其集成到最先进的3D点云模型中，在NVIDIA RTX 3090 GPU上实现了2.55倍的端到端加速，且不牺牲精度。

**Conclusion:** FastPoint通过优化3D点云处理中的关键采样和搜索操作，提供了一种高效且准确的加速解决方案，显著提升了现有模型的推理速度。

> **ai_Abstract:** FastPoint是一种创新的软件加速技术，旨在解决3D点云处理中大型和不规则点云的效率问题。它利用最远点采样中样本点距离的可预测趋势，通过预测距离曲线来避免昂贵的成对距离计算，从而加速后续样本点的识别。该方法显著提升了最远点采样和邻居搜索操作的速度，同时保持了采样质量和模型性能。实验结果表明，FastPoint在集成到现有3D点云模型后，能在NVIDIA RTX 3090 GPU上实现2.55倍的端到端加速，且不损失精度。

> **摘要翻译:** 深度神经网络彻底改变了3D点云处理，然而，高效处理大型和不规则点云仍然具有挑战性。为了解决这个问题，我们引入了FastPoint，一种新颖的基于软件的加速技术，它利用最远点采样过程中样本点之间可预测的距离趋势。通过预测距离曲线，我们可以高效地识别后续样本点，而无需穷举计算所有成对距离。我们的提议在保持采样质量和模型性能的同时，显著加速了最远点采样和邻居搜索操作。通过将FastPoint集成到最先进的3D点云模型中，我们在NVIDIA RTX 3090 GPU上实现了2.55倍的端到端加速，且不牺牲精度。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [142] [PixNerd: Pixel Neural Field Diffusion](https://arxiv.org/abs/2507.23268)
> *PixNerd: 像素神经场扩散*

*Shuai Wang, Ziteng Gao, Chenhui Zhu, Weilin Huang, Limin Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 像素神经场, 扩散模型, 图像生成, VAE, 端到端

**Comment:** a single-scale, single-stage, efficient, end-to-end pixel space
  diffusion model

> **TL;DR:** PixNerd提出了一种基于神经场的像素级扩散模型，无需VAE或复杂级联，实现了高效的端到端图像生成，并在ImageNet和文本到图像任务上取得了优异性能。

**AI_Comments:** 该论文的创新点在于将神经场引入扩散模型，实现了直接在像素空间进行高效的图像生成，避免了传统VAE-based扩散模型中的潜在误差和复杂性。其单阶段、端到端的设计简化了训练流程，并取得了有竞争力的性能，这对于未来扩散模型的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的扩散Transformer依赖预训练的VAE压缩潜在空间，但这会导致累积误差和解码伪影。回到像素空间虽然能解决这些问题，但代价是复杂的级联管道和增加的token复杂度。

**Method:** 我们提出使用神经场对逐块解码进行建模，并提出了一个名为PixNerd的单尺度、单阶段、高效的端到端解决方案。该方法直接在像素空间操作，无需复杂的级联管道或VAE。

**Result:** 在ImageNet $256\times256$上实现了2.15 FID，在ImageNet $512\times512$上实现了2.84 FID。在文本到图像应用中，PixNerd-XXL/16在GenEval基准上获得了0.73的总分，在DPG基准上获得了80.9的总分。

**Conclusion:** PixNerd通过引入神经场表示，成功实现了高效的像素级扩散模型，解决了传统扩散模型中VAE引入的误差和复杂性问题，并在图像生成和文本到图像任务上取得了有竞争力的结果。

> **ai_Abstract:** PixNerd提出了一种新颖的像素神经场扩散模型，旨在解决传统扩散模型中VAE引入的累积误差和解码伪影问题，以及像素空间方法固有的复杂性。该模型通过利用神经场进行逐块解码，实现了单阶段、单尺度、高效的端到端图像生成。实验结果表明，PixNerd在ImageNet上无需VAE或复杂级联即可达到领先的FID分数，并在文本到图像生成任务中展现出强大的竞争力。

> **摘要翻译:** 当前扩散Transformer的成功严重依赖于预训练变分自编码器（VAE）形成的压缩潜在空间。然而，这种两阶段训练范式不可避免地引入了累积误差和解码伪影。为了解决上述问题，研究人员以复杂的级联管道和增加的token复杂度为代价，回到了像素空间。与他们的努力相反，我们提出使用神经场对逐块解码进行建模，并提出了一个单尺度、单阶段、高效的端到端解决方案，命名为像素神经场扩散（PixelNerd）。得益于PixNerd中高效的神经场表示，我们直接在ImageNet $256\times256$上实现了2.15 FID，在ImageNet $512\times512$上实现了2.84 FID，而无需任何复杂的级联管道或VAE。我们还将PixNerd框架扩展到文本到图像应用。我们的PixNerd-XXL/16在GenEval基准上取得了有竞争力的0.73总分，在DPG基准上取得了80.9总分。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [145] [VisNumBench: Evaluating Number Sense of Multimodal Large Language Models](https://arxiv.org/abs/2503.14939)
> *VisNumBench: 评估多模态大型语言模型的数字感*

*Tengjin Weng, Jingyi Wang, Wenhao Jiang, Zhong Ming* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多模态大型语言模型, 数字感, VisNumBench, 视觉数字任务, 评估

**Comment:** accepted by ICCV 2025

> **TL;DR:** 多模态大型语言模型（MLLMs）在数字感任务上表现远低于人类水平，即使是大型模型或思维链（CoT）模型也未显著改善。

**AI_Comments:** 这项研究通过引入一个全面的视觉数字基准，揭示了当前多模态大型语言模型在数字感方面与人类的巨大差距。其创新之处在于构建了一个多维度、多任务的评估体系。研究结果强调了提升MLLMs数字感能力的重要性，并指出仅仅增加模型规模或采用CoT等策略不足以解决这一问题，为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 评估多模态大型语言模型（MLLMs）是否能发展出类似人类的直观数字感。

**Method:** 引入Visual Number Benchmark (VisNumBench) 来评估MLLMs的数字感能力。VisNumBench包含约1,900个来自合成和真实世界视觉数据的多项选择问答对，涵盖七种视觉数字属性和四种视觉数字估计任务。实验测试了17个MLLMs。

**Result:** (i) 17个测试的MLLMs（包括开源和专有模型）在数字感相关任务上的表现远低于人类水平。(ii) 多模态数学模型和多模态思维链（CoT）模型在数字感能力上没有表现出显著提升。(iii) 参数量更大、通用能力更强的MLLMs在数字感能力上表现出适度提升。

**Conclusion:** VisNumBench将成为研究社区的宝贵资源，鼓励进一步提升MLLMs的数字感能力。

> **ai_Abstract:** 本文介绍了VisNumBench，一个用于评估多模态大型语言模型（MLLMs）数字感的基准。该基准包含约1,900个来自合成和真实世界数据的视觉数字任务。实验结果表明，当前MLLMs在数字感任务上远低于人类水平，且多模态数学模型和思维链（CoT）模型未能显著提升此能力，尽管更强的MLLMs表现出适度提升。VisNumBench旨在推动MLLMs数字感能力的进一步研究。

> **摘要翻译:** 多模态大型语言模型（MLLMs）能否发展出类似人类的直观数字感？针对这个问题，我们引入了视觉数字基准（VisNumBench）来评估MLLMs在各种视觉数字任务中的数字感能力。VisNumBench包含约1,900个多项选择问答对，这些数据来源于合成和真实世界的视觉数据，涵盖了七种视觉数字属性和四种视觉数字估计任务。我们在VisNumBench上的实验得出了以下关键发现：(i) 我们测试的17个MLLMs，包括Qwen2.5-VL和InternVL2.5等开源模型，以及GPT-4o和Gemini 2.0 Flash等专有模型，在数字感相关任务上的表现远低于人类水平。(ii) 多模态数学模型和多模态思维链（CoT）模型在数字感能力上没有表现出显著提升。(iii) 参数量更大、通用能力更强的MLLMs在数字感能力上表现出适度提升。我们相信VisNumBench将成为研究社区的宝贵资源，鼓励进一步提升MLLMs的数字感能力。代码和数据集可在https://wwwtttjjj.github.io/VisNumBench/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [148] [Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction](https://arxiv.org/abs/2507.23006)
> *城市场景重建的鲁棒高效三维高斯泼溅*

*Zhensheng Yuan, Haozhi Huang, Zhen Xiong, Di Wang, Guanghua Yang* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 3D Gaussian Splatting, Urban Scene Reconstruction, Real-time Rendering, Level-of-Detail, Appearance Variation

**Comment:** 

> **TL;DR:** 该论文提出了一个鲁棒高效的三维高斯泼溅框架，用于快速重建和实时渲染城市场景，同时解决了多视角捕获中外观变化的问题。

**AI_Comments:** 该论文的创新之处在于其整合了一系列策略来解决城市规模3D高斯泼溅重建中的核心挑战，特别是外观变化和效率问题。通过引入场景分区、可见性图像选择、可控LOD和外观变换模块，该方法显著提升了城市环境重建的鲁棒性和效率，是高斯泼溅技术在实际应用中的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 旨在实现城市规模场景的快速重建和实时渲染，同时保持对多视角捕获中外观变化的鲁棒性。

**Method:** 本方法首先进行场景分区以实现并行训练，并采用基于可见性的图像选择策略来优化训练效率。引入了可控的细节层次（LOD）策略，在用户定义的预算下明确调节高斯密度，以实现高效训练和渲染，同时保持高视觉保真度。外观变换模块减轻了图像间外观不一致的负面影响，并支持灵活调整。此外，还利用了深度正则化、尺度正则化和抗锯齿等增强模块来提高重建保真度。

**Result:** 实验结果表明，该方法能够有效重建城市规模场景，并在效率和质量方面优于以往的方法。

**Conclusion:** 本方法能够有效重建城市规模场景，并在效率和质量上优于现有方法。

> **ai_Abstract:** 本文提出了一种鲁棒高效的3D高斯泼溅框架，用于城市规模场景的快速重建和实时渲染。该框架通过场景分区、基于可见性的图像选择、可控的细节层次（LOD）策略、外观变换模块以及深度、尺度正则化和抗锯齿等增强模块，解决了多视角捕获中的外观变化问题，并优化了训练和渲染效率。实验证明，该方法在城市规模场景重建的效率和质量上均优于现有方法。

> **摘要翻译:** 我们提出了一个框架，能够实现城市规模场景的快速重建和实时渲染，同时保持对多视角捕获中外观变化的鲁棒性。我们的方法从场景分区开始，实现并行训练，并采用基于可见性的图像选择策略来优化训练效率。一个可控的细节层次（LOD）策略在用户定义的预算下明确调节高斯密度，从而实现高效的训练和渲染，同时保持高视觉保真度。外观变换模块减轻了图像间外观不一致的负面影响，同时支持灵活调整。此外，我们利用了深度正则化、尺度正则化和抗锯齿等增强模块来提高重建保真度。实验结果表明，我们的方法能够有效重建城市规模场景，并在效率和质量方面优于以往的方法。源代码可在以下地址获取：https://yzslab.github.io/REUrbanGS。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [152] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
> *基于运动序列的多视角驾驶场景可控行人视频编辑*

*Danzhen Fu, Jiagao Hu, Daiguo Zhou, Fei Wang, Zepeng Wang, Wenhua Liao* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 行人视频编辑, 多视角, 自动驾驶, 数据增强, 运动控制

**Comment:** ICCV 2025 Workshop (HiGen)

> **TL;DR:** 本文提出了一种新颖的框架，通过整合视频修复和人体运动控制技术，实现多视角驾驶场景下的可控行人视频编辑，旨在解决自动驾驶训练数据中危险行人场景表示不足的问题，并展示了高质量、真实且一致的编辑效果，可用于数据增强和场景模拟。

**AI_Comments:** 该论文提出了一种创新的方法来解决自动驾驶领域中行人检测模型数据不足的关键问题。通过整合视频修复和人体运动控制，实现了多视角、可控的行人视频编辑，其能够生成高真实感、时空一致且跨视图一致的视频，这对于自动驾驶系统的数据增强和场景模拟具有重要意义，有助于提升模型的鲁棒性。其灵活性（插入、替换、移除）是其主要优势之一。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统中的行人检测模型由于训练数据集中危险行人场景的表示不足而缺乏鲁棒性。

**Method:** 本方法通过整合视频修复和人体运动控制技术，实现多视角驾驶场景下的可控行人视频编辑。具体步骤包括：识别多相机视图中的行人感兴趣区域，以固定比例扩展检测边界框，将这些区域调整大小并拼接成统一画布同时保持跨视图空间关系；应用二值掩码指定可编辑区域；通过姿态序列控制条件指导行人编辑，支持行人插入、替换和移除。

**Result:** 我们的框架实现了高质量的行人编辑，具有强大的视觉真实感、时空连贯性和跨视图一致性。

**Conclusion:** 所提出的方法为多视角行人视频生成提供了一个鲁棒且通用的解决方案，在自动驾驶的数据增强和场景模拟方面具有广阔的应用潜力。

> **ai_Abstract:** 本文提出一个新颖的可控行人视频编辑框架，用于多视角驾驶场景，以解决自动驾驶训练数据中危险行人场景不足的问题。该方法结合视频修复和人体运动控制，通过识别、拼接多视图行人区域并使用姿态序列控制可编辑区域，实现了行人插入、替换和移除。实验证明，该框架能生成高质量、真实、时空连贯且跨视图一致的行人视频，为自动驾驶中的数据增强和场景模拟提供了有效的解决方案。

> **摘要翻译:** 自动驾驶系统中的行人检测模型因训练数据集中危险行人场景的表示不足而往往缺乏鲁棒性。为解决这一限制，我们提出了一种新颖的框架，通过整合视频修复和人体运动控制技术，在多视角驾驶场景下实现可控的行人视频编辑。我们的方法首先识别跨多个相机视图的行人感兴趣区域，以固定比例扩展检测边界框，并将这些区域调整大小并拼接成一个统一的画布，同时保持跨视图的空间关系。然后应用一个二值掩码来指定可编辑区域，在该区域内，行人编辑由姿态序列控制条件引导。这使得灵活的编辑功能成为可能，包括行人插入、替换和移除。大量的实验表明，我们的框架实现了高质量的行人编辑，具有强大的视觉真实感、时空连贯性和跨视图一致性。这些结果确立了所提出的方法作为一种鲁棒且通用的多视角行人视频生成解决方案，在自动驾驶的数据增强和场景模拟方面具有广阔的应用潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [160] [Dual-Stream Global-Local Feature Collaborative Representation Network for Scene Classification of Mining Area](https://arxiv.org/abs/2507.20216)
> *矿区场景分类的双流全局-局部特征协同表示网络*

*Shuqi Fan, Haoyi Wang, Xianju Li* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 矿区场景分类, 全局-局部特征, 协同表示, 双流网络, 多尺度

**Comment:** Accepted to IJCNN 2025

> **TL;DR:** 提出一种双流全局-局部特征协同表示网络，有效解决了矿区场景分类中复杂空间布局和多尺度特征的挑战，实现了83.63%的总体精度，优于其他模型。

**AI_Comments:** 该论文的创新之处在于提出了一种双流方法，结合全局和局部特征以及协同表示与特定融合策略，以解决矿区场景分类中多尺度和复杂空间布局的挑战，该领域具有重要的实际应用价值。模型明确的三组件设计和多损失计算也体现了周密的考虑。此外，构建新的多模态数据集也是一项重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 矿区场景分类为地质环境监测和资源开发规划提供基础数据，但其复杂的空间布局和多尺度特征带来了挑战。

**Method:** 提出一种双分支融合模型，利用协同表示将全局特征分解为关键语义向量。该模型包含三个核心组件：多尺度全局Transformer分支、局部增强协同表示分支和双分支深度特征融合模块。模型还采用多损失计算以平衡模块集成。

**Result:** 模型总体精度达到83.63%，优于其他对比模型，并在所有其他评估指标上均表现最佳。

**Conclusion:** 所提出的双流网络有效解决了矿区场景分类的挑战，取得了优越的性能，为地质环境监测和资源开发规划提供了更准确的数据。

> **ai_Abstract:** 本文针对矿区场景分类中的复杂空间布局和多尺度特征挑战，提出了一种新颖的双流全局-局部特征协同表示网络。该模型采用双分支架构，包括多尺度全局Transformer分支和局部增强协同表示分支，并通过深度特征融合模块进行融合，有效捕捉了矿区场景的整体和细粒度特征。在新构建的多模态数据集上，该模型实现了83.63%的总体精度，优于其他对比模型，并在所有评估指标上均表现最佳。

> **摘要翻译:** 矿区场景分类为地质环境监测和资源开发规划提供准确的基础数据。本研究融合多源数据构建了一个多模态矿区土地覆盖场景分类数据集。矿区分类的一个显著挑战在于其复杂的空间布局和多尺度特征。通过提取全局和局部特征，可以全面反映空间分布，从而更准确地捕捉矿区场景的整体特征。我们提出了一种利用协同表示的双分支融合模型，将全局特征分解为一组关键语义向量。该模型包含三个关键组件：(1) 多尺度全局Transformer分支：它利用相邻的大尺度特征为小尺度特征生成全局通道注意力特征，有效捕获多尺度特征关系。(2) 局部增强协同表示分支：它利用局部特征和重建的关键语义集细化注意力权重，确保矿区的局部上下文和详细特征得到有效整合，从而增强模型对细粒度空间变化的敏感性。(3) 双分支深度特征融合模块：它融合两个分支的互补特征以纳入更多场景信息，这种融合增强了模型区分和分类复杂矿区景观的能力。最后，本研究采用多损失计算以确保模块的平衡集成。该模型的总体精度为83.63%，优于其他对比模型。此外，它在所有其他评估指标上均取得了最佳性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [167] [DiFuse-Net: RGB and Dual-Pixel Depth Estimation using Window Bi-directional Parallax Attention and Cross-modal Transfer Learning](https://arxiv.org/abs/2506.14709)
> *DiFuse-Net：使用窗口双向视差注意力与跨模态迁移学习的RGB和双像素深度估计*

*Kunal Swami, Debtanu Gupta, Amrit Kumar Muduli, Chirag Jaiswal, Pankaj Kumar Bajpai* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 深度估计, 双像素, DiFuse-Net, 跨模态迁移学习, DCDP数据集

**Comment:** Accepted in IROS 2025

> **TL;DR:** 本文提出DiFuse-Net，一个结合RGB和双像素数据进行深度估计的新型网络，引入了WBiPAM和CmTL机制，并发布了高质量的DCDP数据集，实验证明其性能优于现有基线方法。

**AI_Comments:** 本文的创新点在于提出了DiFuse-Net网络架构，巧妙地结合了RGB和双像素数据进行深度估计，特别是引入了窗口双向视差注意力机制（WBiPAM）来处理双像素的细微视差信息。此外，跨模态迁移学习（CmTL）的引入有效解决了大规模RGB-DP-D数据集稀缺的挑战。更重要的是，作者还贡献了一个高质量的真实世界RGB-DP-D数据集（DCDP），这对于推动该领域的研究具有重要的实践价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 深度估计对智能系统至关重要，但传统深度传感器存在成本、功耗和鲁棒性限制。双像素（DP）技术是可行的替代方案，但缺乏大规模RGB-DP-D数据集限制了其应用。

**Method:** 本文提出DiFuse-Net，一种模态解耦网络，用于解耦的RGB和DP深度估计。它包含一个窗口双向视差注意力机制（WBiPAM）以捕捉细微的DP视差线索，并使用一个独立的编码器提取RGB图像上下文信息进行融合。同时，提出跨模态迁移学习（CmTL）机制，利用现有大规模RGB-D数据集克服RGB-DP-D数据集获取的局限性。此外，还贡献了一个新的高质量真实世界RGB-DP-D训练数据集（DCDP）。

**Result:** 所提出的DiFuse-Net方法在评估和比较中表现出优于基于DP和立体基线方法的性能。成功创建并贡献了一个新的高质量真实世界RGB-DP-D训练数据集（DCDP）。

**Conclusion:** DiFuse-Net通过结合RGB和双像素信息，并利用WBiPAM和CmTL机制，有效提升了深度估计的性能。新发布的DCDP数据集为该领域的研究提供了宝贵资源，有望推动智能系统在深度感知方面的发展。

> **ai_Abstract:** DiFuse-Net是一种创新的深度估计网络，它结合了RGB和双像素数据，并通过独特的窗口双向视差注意力机制（WBiPAM）捕捉细微视差。为解决数据集稀缺问题，该网络还引入了跨模态迁移学习（CmTL）机制。实验结果显示，DiFuse-Net的性能优于现有基线方法，并且论文还贡献了一个新的高质量RGB-DP-D训练数据集（DCDP），为智能系统中的深度感知提供了有效解决方案。

> **摘要翻译:** 深度估计对于智能系统至关重要，它支持从自动导航到增强现实等应用。传统的立体和主动深度传感器在成本、功耗和鲁棒性方面存在局限性，而现代相机中普遍存在的双像素（DP）技术提供了一种引人注目的替代方案。本文介绍了DiFuse-Net，一种新颖的模态解耦网络设计，用于解耦的RGB和基于DP的深度估计。DiFuse-Net具有一个窗口双向视差注意力机制（WBiPAM），专门设计用于捕获智能手机相机小光圈特有的细微DP视差线索。一个独立的编码器从RGB图像中提取上下文信息，并将这些特征融合以增强深度预测。我们还提出了一种跨模态迁移学习（CmTL）机制，以利用文献中的大规模RGB-D数据集来应对获取大规模RGB-DP-D数据集的局限性。我们对所提出方法的评估和比较表明，它优于基于DP和立体基线的现有方法。此外，我们贡献了一个新的、高质量的真实世界RGB-DP-D训练数据集，名为Dual-Camera Dual-Pixel（DCDP）数据集，该数据集是使用我们新颖的对称立体相机硬件设置、立体标定和校正协议以及AI立体视差估计方法创建的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [170] [iLRM: An Iterative Large 3D Reconstruction Model](https://arxiv.org/abs/2507.23277)
> *iLRM：一个迭代式大型三维重建模型*

*Gyeongjin Kang, Seungtae Nam, Xiangyu Sun, Sameh Khamis, Abdelrahman Mohamed, Eunbyung Park* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D Reconstruction, Gaussian Splatting, Iterative Refinement, Scalability

**Comment:** Project page: https://gynjn.github.io/iLRM/

> **TL;DR:** iLRM是一种迭代式3D重建模型，通过解耦表示、两阶段注意力机制和分层高分辨率信息注入，解决了现有前馈3D建模方法的可扩展性问题，提高了重建质量和速度。

**AI_Comments:** 该论文提出了一种创新的迭代式3D重建模型iLRM，有效解决了当前基于Transformer的前馈3D建模方法面临的严重可扩展性问题。通过解耦表示、两阶段注意力以及分层注入高分辨率信息，iLRM不仅提升了重建质量和速度，更显著增强了模型处理大量输入视图时的效率，这对于未来大规模3D重建应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有前馈三维建模方法（特别是基于Transformer的）在处理多视图或高分辨率图像时面临严重的计算成本和可扩展性问题，因为它们依赖于跨图像token的完全注意力机制。

**Method:** 本文提出iLRM（迭代式大型三维重建模型），通过迭代细化机制生成3D高斯表示。其核心原则包括：1) 将场景表示与输入视图图像解耦，实现紧凑的3D表示；2) 将全注意力多视图交互分解为两阶段注意力方案，降低计算成本；3) 在每一层注入高分辨率信息，实现高保真重建。

**Result:** 在RE10K和DL3DV等数据集上的实验结果表明，iLRM在重建质量和速度上优于现有方法。它还显示出卓越的可扩展性，在相似的计算成本下，通过有效利用更多输入视图，提供了显著更高的重建质量。

**Conclusion:** iLRM通过其迭代细化机制和三个核心原则，成功解决了前馈3D重建的可扩展性问题，并在质量和效率上超越了现有方法，尤其在处理大量输入视图时表现出色。

> **ai_Abstract:** 本文提出iLRM，一种迭代式大型三维重建模型，旨在解决现有前馈三维建模方法在可扩展性方面的挑战。iLRM通过迭代细化生成3D高斯表示，并遵循三项核心原则：解耦场景表示、采用两阶段注意力机制和逐层注入高分辨率信息。实验证明，iLRM在重建质量、速度和可扩展性方面均优于现有技术，尤其在处理大量输入视图时表现出色。

> **摘要翻译:** 前馈三维建模已成为一种有前景的快速高质量三维重建方法。特别是，直接生成显式三维表示，如三维高斯泼溅，因其快速高质量的渲染以及众多的应用而受到广泛关注。然而，许多最先进的方法，主要基于Transformer架构，由于依赖于来自多个输入视图的图像token之间的完全注意力机制，导致严重的扩展性问题，随着视图数量或图像分辨率的增加，计算成本变得 prohibitive。为了实现可扩展且高效的前馈三维重建，我们引入了一个迭代式大型三维重建模型（iLRM），它通过迭代细化机制生成三维高斯表示，并由三个核心原则指导：(1) 将场景表示与输入视图图像解耦，以实现紧凑的三维表示；(2) 将完全注意力的多视图交互分解为两阶段注意力方案，以降低计算成本；(3) 在每一层注入高分辨率信息以实现高保真重建。在RE10K和DL3DV等常用数据集上的实验结果表明，iLRM在重建质量和速度方面均优于现有方法。值得注意的是，iLRM表现出卓越的扩展性，在可比的计算成本下，通过有效利用更多输入视图，提供了显著更高的重建质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [173] [Learning 3D Scene Analogies with Neural Contextual Scene Maps](https://arxiv.org/abs/2503.15897)
> *使用神经上下文场景图学习3D场景类比*

*Junho Kim, Gwangtak Bae, Eun Sun Lee, Young Min Kim* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 3D场景类比, 神经上下文场景图, 场景理解, 轨迹转移, 空间关系

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 提出神经上下文场景图来学习3D场景类比，通过对齐空间关系实现场景级映射，可用于轨迹转移和物体重新排列等应用，增强机器在复杂3D环境中的适应性。

**AI_Comments:** 该论文通过引入“3D场景类比”和“神经上下文场景图”的概念，为3D场景理解提供了一种新颖且有前景的方法。其创新之处在于从传统的点或对象级表示转向更宏观的场景级映射，这使得模型对噪声和变化更具鲁棒性，并能实现更复杂的应用，如轨迹和长演示转移。这种方法对于克服数据驱动学习在处理多样化3D环境时的局限性具有重要意义，尤其是在机器人和AR/VR领域。

<details>
  <summary>Details</summary>

**Motivation:** 机器在未见过或嘈杂的3D环境中执行任务和应用先验知识时，理解场景上下文至关重要。由于数据驱动学习难以全面涵盖多样化的布局和开放空间，因此需要一种方法来识别3D空间中的关系共性。

**Method:** 提出3D场景类比，即3D场景区域之间平滑映射以对齐空间关系。为此，引入神经上下文场景图，它提取总结语义和几何上下文的描述符场，并以从粗到细的方式整体对齐它们以进行地图估计。这种方法减少了对单个特征点的依赖，使其对输入噪声或形状变化具有鲁棒性。

**Result:** 实验证明了该方法在识别场景类比以及在多样化室内场景中转移轨迹或物体放置的有效性，表明其在机器人和AR/VR应用中的潜力。

**Conclusion:** 通过学习3D场景类比和使用神经上下文场景图，本研究提供了一种有效且鲁棒的方法来理解和利用3D场景的上下文，从而能够实现轨迹转移和上下文感知物体重新排列等应用，对机器人和AR/VR领域具有重要意义。

> **ai_Abstract:** 该论文提出了一种名为“3D场景类比”的新概念，旨在通过学习3D场景区域之间的平滑映射来识别空间关系共性。为实现这一目标，作者引入了“神经上下文场景图”，该方法通过提取语义和几何上下文描述符场并进行粗到细的对齐来估计这些场景级映射。与传统的点或对象级表示不同，这种方法更侧重于大场景区域的连接，从而增强了对输入噪声和形状变化的鲁棒性。实验结果表明，该方法在识别场景类比以及在不同室内场景中进行轨迹和物体放置转移方面表现出色，预示着其在机器人和AR/VR领域的广阔应用前景。

> **摘要翻译:** 理解场景上下文对于机器在未见或嘈杂的3D环境中执行任务和适应先验知识至关重要。由于数据驱动学习难以全面封装多样化的布局和开放空间，我们提出教机器识别3D空间中的关系共性。我们不关注点对点或对象对点表示，而是引入3D场景类比，即3D场景区域之间平滑映射以对齐空间关系。与研究充分的单实例级地图不同，这些场景级地图平滑地连接大型场景区域，可能在AR/VR中的轨迹转移、模仿学习中的长演示转移以及上下文感知物体重新排列方面实现独特的应用。为了找到3D场景类比，我们提出了神经上下文场景图，它提取总结语义和几何上下文的描述符场，并以从粗到细的方式整体对齐它们以进行地图估计。这种方法减少了对单个特征点的依赖，使其对输入噪声或形状变化具有鲁棒性。实验证明了我们方法在识别场景类比以及在多样化室内场景中转移轨迹或物体放置方面的有效性，表明其在机器人和AR/VR应用中的潜力。包含代码的项目页面可通过此链接访问：https://82magnolia.github.io/3d_scene_analogies/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [178] [Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion](https://arxiv.org/abs/2507.23483)
> *Stable-Sim2Real：探索基于两阶段深度扩散的真实捕捉3D数据模拟*

*Mutian Xu, Chongjie Ye, Haolin Liu, Yushuang Wu, Jiahao Chang, Xiaoguang Han* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D数据模拟, 深度扩散, Stable-Sim2Real, Sim2Real, 数据驱动

**Comment:** ICCV 2025 (Highlight). Project page:
  https://mutianxu.github.io/stable-sim2real/

> **TL;DR:** 本文提出了一种名为Stable-Sim2Real的两阶段深度扩散模型，用于数据驱动的3D数据模拟，旨在缩小模拟数据与真实捕捉数据之间的差距，并在实际3D视觉任务中显著提升性能。

**AI_Comments:** 本文提出了一种新颖的两阶段深度扩散模型Stable-Sim2Real，创新性地解决了3D数据模拟中合成与真实数据之间差距问题。其数据驱动的方法克服了传统方法对预定义物理先验的依赖，并通过精细的两阶段扩散过程，尤其是引入3D判别器来优化局部细节，有效提升了模拟数据的真实感和在下游任务中的实用性。这对于推动3D视觉领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 3D数据模拟旨在弥合模拟3D数据与真实捕捉3D数据之间的鸿沟，这对于现实世界的3D视觉任务是一个基本问题。大多数现有方法注入预定义的物理先验，但难以捕捉真实数据的完整复杂性。数据驱动地学习从合成到真实数据的隐式映射是一种最优方法，但近期研究在此方面进展停滞。

**Method:** 本文提出了一种名为Stable-Sim2Real的数据驱动3D模拟新路径，其基于新颖的两阶段深度扩散模型。第一阶段微调Stable-Diffusion以生成真实与合成配对深度之间的残差，产生稳定但粗糙的深度。为了改进，将合成深度和第一阶段输出深度输入到第二阶段扩散中，并调整扩散损失以优先处理由3D判别器识别出的独特区域。此外，本文还提供了一种新的基准方案来评估3D数据模拟方法。

**Result:** 广泛的实验表明，使用本方法生成的3D模拟数据训练网络，能够显著提升现实世界3D视觉任务的性能。此外，评估结果显示本方法的3D模拟数据与真实捕捉模式之间具有高度相似性。

**Conclusion:** 本研究提出的Stable-Sim2Real方法通过两阶段深度扩散模型，有效实现了数据驱动的3D数据模拟，成功缩小了模拟与真实数据之间的差距，并显著提升了在真实世界3D视觉任务中的表现。

> **ai_Abstract:** 本文提出Stable-Sim2Real，一种基于两阶段深度扩散模型的数据驱动3D数据模拟方法。针对现有方法在捕捉真实数据复杂性上的不足，该方法通过第一阶段微调Stable-Diffusion生成粗糙深度，再通过第二阶段结合3D判别器精修局部区域。实验证明，该方法生成的模拟数据显著提升了真实世界3D视觉任务的性能，并展现出与真实数据的高度相似性。

> **摘要翻译:** 3D数据模拟旨在弥合模拟3D数据与真实捕捉3D数据之间的鸿沟，这对于现实世界的3D视觉任务是一个基本问题。大多数3D数据模拟方法注入预定义的物理先验，但难以捕捉真实数据的完整复杂性。一种最优方法涉及以数据驱动的方式学习从合成数据到真实数据的隐式映射，但近期研究在此解决方案上进展停滞。这项工作探索了一种数据驱动的3D模拟新路径，称为Stable-Sim2Real，其基于一种新颖的两阶段深度扩散模型。初始阶段微调Stable-Diffusion以生成真实与合成配对深度之间的残差，产生稳定但粗糙的深度，其中一些局部区域可能偏离真实模式。为了增强这一点，合成深度和初始输出深度都被输入到第二阶段扩散中，其中调整扩散损失以优先处理由3D判别器识别出的这些独特区域。我们提供了一种新的基准方案来评估3D数据模拟方法。广泛的实验表明，使用我们方法生成的3D模拟数据训练网络，能够显著提升现实世界3D视觉任务的性能。此外，评估结果显示我们的3D模拟数据与真实捕捉模式之间具有高度相似性。项目页面：https://mutianxu.github.io/stable-sim2real/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [180] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
> *缩小通用数据与聚光太阳能发电厂航空图像之间的差距*

*M. A. Pérez-Cutiño, J. Valverde, J. Capitán, J. M. Díaz-Báñez* | **Category: cs.CV, cs.AI, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 聚光太阳能发电, 航空图像, 合成数据, 故障检测, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了AerialCSP，一个模拟聚光太阳能发电厂航空图像的虚拟数据集，旨在通过合成数据预训练模型，从而减少对真实航空图像进行大量手动标注的需求，显著提升故障检测能力。

**AI_Comments:** 本文的创新点在于提出了一个高质量的合成数据集AerialCSP，有效解决了特定工业领域（如CSP）中真实数据标注成本高昂和数据稀缺的问题。通过合成数据进行预训练，显著提升了模型在真实世界故障检测中的性能，尤其对罕见和小型缺陷的识别能力。这种方法为专业领域计算机视觉任务提供了一个高效且实用的解决方案，具有重要的工业应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 聚光太阳能发电厂（CSP）的航空图像因其高反光表面和特有元素，使得通用机器学习模型难以直接应用，且收集和标注大量真实数据成本高昂、耗时。

**Method:** 本文提出了一种名为AerialCSP的虚拟数据集，该数据集模拟了聚光太阳能发电厂的航空图像，生成与真实世界条件相似的合成数据。通过此数据集，旨在实现模型部署前的预训练。

**Result:** 1. 引入了AerialCSP，一个用于CSP工厂航空检查的高质量合成数据集，提供了目标检测和图像分割的标注数据。 2. 在AerialCSP上对多种模型进行了基准测试，为CSP相关的视觉任务建立了基线。 3. 证明了在AerialCSP上进行预训练能显著改善真实世界中的故障检测，特别是对于稀有和小型缺陷，从而减少了大量手动标注的需求。

**Conclusion:** 通过创建和利用AerialCSP虚拟数据集，可以有效弥补通用数据与聚光太阳能发电厂航空图像之间的差距，显著减少模型在特定工业应用中对昂贵且耗时的人工标注数据的依赖，提高故障检测的效率和准确性。

> **ai_Abstract:** 本文针对聚光太阳能发电厂（CSP）航空图像中存在的挑战，提出了一种创新方法：创建名为AerialCSP的虚拟数据集。该数据集通过生成模拟真实场景的合成图像，旨在弥补通用数据与CSP特定图像之间的差距。研究表明，在AerialCSP上预训练的模型能显著提高真实世界中故障检测的准确性，尤其是在识别稀有和微小缺陷方面，从而大幅减少了对耗时且昂贵的人工标注数据的依赖。AerialCSP数据集已公开可用。

> **摘要翻译:** 在聚光太阳能发电厂（CSP）的背景下，无人机捕获的航空图像带来了一系列独特的挑战。与现有数据集中常见的城市或自然景观不同，太阳能场包含高反光表面和传统计算机视觉基准中不常见的领域特定元素。因此，在通用数据集上训练的机器学习模型在没有大量再训练和大量标注数据的情况下，很难推广到这种设置。然而，收集和标注此类数据成本高昂且耗时，使其在工业应用中快速部署不切实际。
为了解决这个问题，我们提出了一种新颖的方法：创建AerialCSP，一个模拟CSP工厂航空图像的虚拟数据集。通过生成与真实世界条件高度相似的合成数据，我们的目标是在模型部署前促进模型的预训练，显著减少对大量手动标注的需求。我们的主要贡献有三方面：（1）我们引入了AerialCSP，一个用于CSP工厂航空检查的高质量合成数据集，为目标检测和图像分割提供标注数据；（2）我们在AerialCSP上对多种模型进行了基准测试，为CSP相关的视觉任务建立了基线；（3）我们证明了在AerialCSP上进行预训练能显著改善真实世界中的故障检测，特别是对于稀有和小型缺陷，从而减少了大量手动标注的需求。AerialCSP已在https://mpcutino.github.io/aerialcsp/公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [181] [Accurate Cross-modal Reconstruction of Vehicle Target from Sparse-aspect Multi-baseline SAR data](https://arxiv.org/abs/2406.04158)
> *从稀疏视角多基线SAR数据中精确跨模态重建车辆目标*

*Da Li, Guoqiang Zhao, Chen Yao, Kaiqiang Zhu, Houjun Sun, Jiacheng Bao, Maokun Li* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** SAR, 3D重建, 跨模态学习, 深度学习, 车辆目标

**Comment:** 

> **TL;DR:** 本文提出了一种名为CMAR-Net的跨模态深度学习方法，通过融合2D光学图像信息，显著提高了稀疏视角多基线SAR数据对车辆目标的3D重建精度，并展现出强大的泛化能力。

**AI_Comments:** CMAR-Net的创新之处在于其引入了跨模态学习范式，将光学图像的互补信息融合到SAR 3D重建中，突破了传统单模态学习的局限。这种方法显著提升了稀疏SAR数据对小目标（如车辆）的重建精度和视觉结构化程度，并且在仅依赖模拟数据训练的情况下仍能实现强大的真实世界泛化能力，这对于实际应用具有重要意义。该工作为雷达成像领域的研究提供了一个新颖且高效的框架。

<details>
  <summary>Details</summary>

**Motivation:** 多视角多基线SAR 3D成像在城市测绘和监测中至关重要，但稀疏观测会导致成像质量下降，尤其对于车辆等各向异性小目标。现有深度学习方法通常只使用高分辨率雷达图像进行单模态学习，限制了重建性能的进一步提升。

**Method:** 本文引入了跨模态学习，并提出了一种名为CMAR-Net的跨模态3D-SAR重建网络。该网络通过融合异构信息来增强稀疏3D SAR重建，并利用来自2D光学图像的跨模态监督以及可微分渲染保证的误差传播来实现高效训练。

**Result:** CMAR-Net能够将高度稀疏的SAR图像重建为视觉结构化且精确的3D图像，特别是对于车辆目标。该网络仅在模拟数据上训练，但在包含大量民用车辆的停车场实测数据上表现出强大的泛化能力，并在结构精度上优于最先进的CS和DL方法。

**Conclusion:** 本文工作突出了跨模态学习在3D SAR重建中的潜力，并为雷达成像研究引入了一个新颖的框架。

> **ai_Abstract:** 本研究针对稀疏观测下多视角多基线SAR 3D成像中车辆目标重建质量下降的问题，提出了一种创新的跨模态深度学习方法——CMAR-Net。该网络通过融合雷达数据与2D光学图像的异构信息，并利用可微分渲染进行误差传播，有效提升了稀疏SAR数据的3D重建精度和效率。实验结果表明，CMAR-Net在模拟数据上训练后，在真实世界车辆数据集上展现出卓越的泛化能力，并在结构准确性方面超越了现有的压缩感知和深度学习方法，为3D SAR重建和雷达成像研究开辟了新方向。

> **摘要翻译:** 多视角多基线SAR 3D成像是一项关键的遥感技术，在城市测绘和监测中具有广阔前景。然而，由于受限的飞行轨迹导致的稀疏观测会降低成像质量，特别是对于车辆和飞机等各向异性小目标。过去，压缩感知（CS）是稀疏3D SAR重建的主流方法。最近，深度学习（DL）作为一种强大的替代方案出现，通过其强大的数据驱动表示能力和快速推理特性，显著提升了重建质量和效率。然而，现有的深度学习方法通常仅使用高分辨率雷达图像来训练深度神经网络（DNNs）。这种单模态学习范式排除了整合来自其他数据源的互补信息的可能性，从而限制了重建性能的潜在改进。在本文中，我们引入了跨模态学习，并提出了一种跨模态3D-SAR重建网络（CMAR-Net），该网络通过融合异构信息来增强稀疏3D SAR重建。CMAR-Net利用来自2D光学图像的跨模态监督以及可微分渲染保证的误差传播，实现了高效训练，并将高度稀疏的SAR图像重建为视觉结构化且精确的3D图像，特别是对于车辆目标。CMAR-Net仅在模拟数据上进行训练，但在包含大量民用车辆的停车场测量数据的广泛实际评估中表现出强大的泛化能力，在结构精度方面优于最先进的CS和DL方法。我们的工作突出了跨模态学习在3D SAR重建中的潜力，并为雷达成像研究引入了一个新颖的框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [190] [Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction](https://arxiv.org/abs/2507.23021)
> *使用扩散模型建模人类注视行为以实现统一扫视路径预测*

*Giuseppe Cartella, Vittorio Cuculo, Alessandro D'Amelio, Marcella Cornia, Giuseppe Boccignone, Rita Cucchiara* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 注视预测, 扫视路径, 扩散模型, Vision Transformers, 视觉注意力

**Comment:** Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV), 2025

> **TL;DR:** ScanDiff是一个结合扩散模型和Vision Transformer的新架构，用于生成多样化且真实的人类注视扫视路径，超越了现有SOTA方法。

**AI_Comments:** ScanDiff的创新之处在于首次将扩散模型引入人类注视行为预测，并结合Vision Transformer，有效解决了传统模型无法捕捉注视路径多样性的问题。其引入的文本条件功能也极具实用性，使得模型能够适应不同的任务需求，这对于人机交互和认知机器人等领域具有重要意义。该工作显著推动了注视预测研究的进展。

<details>
  <summary>Details</summary>

**Motivation:** 预测人类注视扫视路径对于理解视觉注意力至关重要，并在人机交互、自主系统和认知机器人等领域有应用。然而，现有深度学习模型通常生成平均行为，未能捕捉人类视觉探索的变异性。

**Method:** 本文提出了ScanDiff，一个将扩散模型与Vision Transformers相结合的新颖架构，用于生成多样化和真实的扫视路径。该方法通过利用扩散模型的随机性明确建模扫视路径的变异性，并引入文本条件以实现任务驱动的扫视路径生成。

**Result:** 在基准数据集上的实验表明，ScanDiff在自由观看和任务驱动场景中均超越了现有SOTA方法，生成了更多样化和准确的扫视路径。

**Conclusion:** ScanDiff模型能够更好地捕捉人类视觉行为的复杂性，推动了注视预测研究的发展。

> **ai_Abstract:** 本文介绍了ScanDiff，一种结合扩散模型和Vision Transformers的新颖架构，旨在解决现有扫视路径预测模型无法捕捉人类注视行为多样性的问题。ScanDiff利用扩散模型的随机性生成多样且真实的扫视路径，并通过引入文本条件支持任务驱动的生成。实验证明，ScanDiff在多种场景下均优于现有最先进方法，能够更准确地反映人类视觉行为的复杂性。

> **摘要翻译:** 预测人类注视扫视路径对于理解视觉注意力至关重要，并在人机交互、自主系统和认知机器人等领域有应用。尽管深度学习模型在扫视路径预测方面取得了进展，但大多数现有方法生成的是平均行为，未能捕捉人类视觉探索的变异性。在这项工作中，我们提出了ScanDiff，一个结合扩散模型与Vision Transformers的新颖架构，用于生成多样化且真实的扫视路径。我们的方法通过利用扩散模型的随机性明确建模扫视路径的变异性，生成了广泛的合理注视轨迹。此外，我们引入了文本条件以实现任务驱动的扫视路径生成，允许模型适应不同的视觉搜索目标。在基准数据集上的实验表明，ScanDiff在自由观看和任务驱动场景中均超越了现有SOTA方法，生成了更多样化和准确的扫视路径。这些结果突出了其更好地捕捉人类视觉行为复杂性的能力，推动了注视预测研究。源代码和模型已在 https://aimagelab.github.io/ScanDiff 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [198] [UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing](https://arxiv.org/abs/2507.23278)
> *UniLiP：使CLIP适应统一的多模态理解、生成和编辑*

*Hao Tang, Chenwei Xie, Xiaoyi Bao, Tingyu Weng, Pandeng Li, Yun Zheng, Liwei Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** CLIP, 多模态理解, 图像生成, 图像编辑, 统一模型

**Comment:** 

> **TL;DR:** UniLiP扩展了CLIP，通过两阶段训练和自蒸馏，使其能在保持原有理解能力的同时，实现高效的图像重建、生成和编辑，并在多项基准测试中超越现有模型。

**AI_Comments:** 该论文提出UniLIP，通过创新的两阶段训练和自蒸馏策略，成功地将CLIP的理解能力扩展到生成和编辑任务，同时避免了传统方法的性能下降问题。其双条件架构有效地整合了MLLM的推理能力和UniLIP的特征信息。这种方法为构建更统一的多模态模型提供了新的思路，并展现了在多个任务上的SOTA性能，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于CLIP的统一方法在支持重建和生成任务时，常需要额外的解码器或量化，导致重建不一致或原有理解性能下降。

**Method:** 提出了UniLIP模型，通过两阶段训练方案和自蒸馏策略，逐步将重建能力整合到CLIP中，同时保持原始理解性能。此外，引入了一个双条件架构，连接MLLM和扩散Transformer，利用可学习查询和多模态隐藏状态作为联合条件。

**Result:** 在文本到图像生成任务中，UniLIP在GenEval和WISE基准测试中分别获得0.87和0.53分，超越了所有类似规模的现有统一模型。在图像编辑任务中，UniLIP在ImgEdit基准测试中获得3.62分，超越了BAGEL和UniWorld-V1等最新SOTA模型。

**Conclusion:** UniLIP有效地扩展了CLIP的应用范围，使其连续特征不仅是理解任务的最佳选择，也能在生成和编辑任务中取得极具竞争力的性能。

> **ai_Abstract:** UniLIP是一种将CLIP扩展到统一多模态理解、生成和编辑任务的新模型。它通过两阶段训练和自蒸馏策略，在保持CLIP原有理解能力的同时，有效实现了图像重建。此外，其双条件架构结合了MLLM和扩散Transformer，提升了生成和编辑任务的性能。实验证明，UniLIP在文本到图像生成和图像编辑基准测试中均超越了现有SOTA模型，显著扩展了CLIP的应用范围。

> **摘要翻译:** 在本文中，我们提出了UniLIP，它将CLIP扩展到重建、生成和编辑，从而在其卓越的理解能力之上构建了一个统一的tokenizer。以前基于CLIP的统一方法通常需要额外的扩散解码器或量化来支持重建和生成任务，这导致了重建不一致或原有理解性能的下降。相比之下，我们引入了一种两阶段训练方案和自蒸馏策略，逐步将重建能力整合到CLIP中，使其在实现有效图像重建的同时保持原始理解性能。此外，我们提出了一种双条件架构来连接MLLM和扩散Transformer，使用可学习查询和最后一层多模态隐藏状态作为联合条件。这种方法不仅能够利用MLLM在生成任务中的强大推理能力，而且在编辑任务中最大限度地利用了UniLIP特征中的丰富信息。在文本到图像生成任务中，UniLIP在GenEval和WISE基准测试中分别获得0.87和0.53分，超越了所有类似规模的现有统一模型。在图像编辑中，UniLIP还在ImgEdit基准测试中获得了3.62分，超越了BAGEL和UniWorld-V1等最新SOTA模型。UniLIP有效地扩展了CLIP的应用范围，使得CLIP的连续特征不仅可以作为理解任务的最佳选择，而且在生成和编辑任务中也取得了极具竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [201] [Beyond the Encoder: Joint Encoder-Decoder Contrastive Pre-Training Improves Dense Prediction](https://arxiv.org/abs/2503.17526)
> *超越编码器：联合编码器-解码器对比预训练改进密集预测*

*Sébastien Quetin, Tapotosh Ghosh, Farhad Maleki* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 对比学习, 自监督学习, 编码器-解码器, 密集预测, 预训练

**Comment:** 

> **TL;DR:** DeCon框架通过联合预训练编码器和解码器，显著提升了密集预测任务的性能。

**AI_Comments:** 本文的创新点在于突破了传统对比学习仅关注编码器预训练的范式，提出了编码器-解码器联合预训练的方法。DeCon框架通过引入非竞争性加权损失，有效解决了联合训练的难题，并在多个密集预测任务上取得了SOTA结果，证明了其重要性。这为未来自监督学习在复杂下游任务中的应用开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的自监督对比学习主要侧重于预训练编码器，而忽略了联合预训练编码器和解码器对下游密集预测任务的潜在益处。

**Method:** 本文提出了DeCon，一个高效的编码器-解码器自监督学习（SSL）框架，支持联合对比预训练。它扩展了现有SSL架构以适应不同的解码器及其相应的对比损失，并引入了一个加权编码器-解码器对比损失，其目标是非竞争性的，以实现编码器-解码器架构的联合预训练。

**Result:** DeCon在COCO目标检测和实例分割任务上（在COCO数据集上预训练）实现了新的最先进结果；在COCO+和ImageNet-1K上预训练时，在几乎所有密集下游基准任务上都表现出色。结果表明，联合预训练增强了编码器的表示能力，并提高了密集预测任务的性能。这种增益在异构解码器架构、各种编码器架构以及域外有限数据场景中都持续存在。

**Conclusion:** 联合预训练编码器和解码器能够增强编码器的表示能力并提高密集预测任务的性能，且这种优势在不同架构和数据场景下均保持。

> **ai_Abstract:** 本文提出了DeCon，一个用于密集预测任务的自监督学习框架，通过联合预训练编码器和解码器来克服传统方法中仅预训练编码器的局限性。DeCon扩展了现有SSL架构以支持多样化的解码器，并引入了一种加权对比损失以实现非竞争性联合训练。实验证明，DeCon在COCO目标检测和实例分割以及其他密集预测基准任务上取得了最先进的性能，验证了联合预训练能显著提升模型在密集预测任务中的表示能力和性能。

> **摘要翻译:** 自监督设置中的对比学习方法主要侧重于预训练编码器，而解码器通常是为下游密集预测任务单独引入和训练的。然而，这种传统方法忽略了联合预训练编码器和解码器的潜在益处。在本文中，我们提出了DeCon，一个高效的编码器-解码器自监督学习（SSL）框架，支持联合对比预训练。我们首先扩展了现有的SSL架构以适应不同的解码器及其相应的对比损失。然后，我们引入了一个加权编码器-解码器对比损失，其目标是非竞争性的，以实现编码器-解码器架构的联合预训练。通过为密集预测任务调整一个成熟的对比SSL框架，DeCon取得了新的最先进结果：在COCO数据集上预训练时，在COCO目标检测和实例分割任务上；在COCO+和ImageNet-1K上预训练时，在几乎所有密集下游基准任务上。我们的结果表明，联合预训练增强了编码器的表示能力，并提高了密集预测任务的性能。这种增益在异构解码器架构、各种编码器架构以及域外有限数据场景中都持续存在。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [202] [Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach](https://arxiv.org/abs/2507.20356)
> *检测增强现实中的视觉信息操纵攻击：一种多模态语义推理方法*

*Yanming Xiu, Maria Gorlatova* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 增强现实, 视觉信息操纵, 多模态语义推理, VIM-Sense, AR-VIM

**Comment:** 11 pages, 7 figures

> **TL;DR:** 该论文提出了 VIM-Sense，一个结合视觉语言模型和 OCR 的多模态语义推理框架，用于检测增强现实中的视觉信息操纵攻击，并在其新建的 AR-VIM 数据集上实现了 88.94% 的准确率。

**AI_Comments:** 这篇论文在解决增强现实中一个关键且新兴的安全威胁——视觉信息操纵方面具有创新性。创建专门的分类法和新的数据集（AR-VIM）是一项重要贡献，为未来的研究提供了结构化的方法和资源。结合 VLM 和 OCR 的多模态 VIM-Sense 框架是一个鲁棒的解决方案，展示了集成不同模态进行复杂语义推理在 AR 安全中的强大潜力。其实用的延迟也突显了其在实际部署中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 增强现实（AR）中的虚拟内容可能引入误导性或有害信息，导致语义误解或用户错误，尤其是在虚拟内容以微妙但有影响力的方式改变真实世界场景含义的视觉信息操纵（VIM）攻击方面。

**Method:** 作者首先提出了一个 VIM 攻击的分类法，将其分为字符、短语、模式操纵以及信息替换、信息混淆、额外错误信息。基于此分类法，他们构建了一个包含 452 对原始 AR 视频、涵盖 202 个不同场景的数据集 AR-VIM。为检测此类攻击，他们提出了 VIM-Sense，一个多模态语义推理框架，它结合了视觉语言模型（VLM）的语言和视觉理解能力与基于光学字符识别（OCR）的文本分析。

**Result:** VIM-Sense 在 AR-VIM 数据集上实现了 88.94% 的攻击检测准确率，持续优于仅视觉和仅文本的基线方法。该系统在模拟视频处理框架中平均攻击检测延迟为 7.07 秒，在移动 Android AR 应用程序上的真实世界评估中为 7.17 秒。

**Conclusion:** 所提出的 VIM-Sense 框架通过多模态语义推理方法有效检测增强现实中的视觉信息操纵攻击，展示了高准确率和实用的检测延迟，从而解决了 AR 领域的一个关键安全问题。

> **ai_Abstract:** 本论文旨在解决增强现实（AR）中的视觉信息操纵（VIM）攻击问题，即虚拟内容微妙地改变真实世界场景的含义。作者提出了一种 VIM 攻击分类法，并据此构建了一个包含 452 对视频的新数据集 AR-VIM。他们引入了 VIM-Sense，一个利用视觉语言模型和 OCR 进行检测的多模态语义推理框架。VIM-Sense 在 AR-VIM 上实现了 88.94% 的准确率，并在模拟和真实 AR 环境中展示了实用的检测延迟，优于单模态基线方法。

> **摘要翻译:** 增强现实 (AR) 中的虚拟内容可能引入误导性或有害信息，导致语义误解或用户错误。在这项工作中，我们专注于 AR 中的视觉信息操纵 (VIM) 攻击，其中虚拟内容以微妙但有影响力的方式改变真实世界场景的含义。我们引入了一个分类法，将这些攻击分为三种格式：字符、短语和模式操纵，以及三种目的：信息替换、信息混淆和额外错误信息。基于该分类法，我们构建了一个数据集 AR-VIM。它包含 452 对原始 AR 视频，涵盖 202 个不同的场景，每个场景都模拟一个真实世界的 AR 场景。为了检测此类攻击，我们提出了一种多模态语义推理框架 VIM-Sense。它结合了视觉语言模型 (VLM) 的语言和视觉理解能力与基于光学字符识别 (OCR) 的文本分析。VIM-Sense 在 AR-VIM 上实现了 88.94% 的攻击检测准确率，始终优于仅视觉和仅文本的基线。该系统在模拟视频处理框架中达到平均 7.07 秒的攻击检测延迟，在移动 Android AR 应用程序上进行的真实世界评估中达到 7.17 秒。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [205] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
> *瓦片与滑动：一种将NeRF从局部扩展到全球三维地球观测的新框架*

*Camille Billouard, Dawa Derksen, Alexandre Constantin, Bruno Vallet* | **Category: cs.CV, cs.AI, cs.GR, cs.LG** | **Updated: 2025-07-31**

**Keywords:** NeRF, 3D重建, 大规模场景, 卫星图像, Snake-NeRF

**Comment:** Accepted at ICCV 2025 Workshop 3D-VAST (From street to space: 3D
  Vision Across Altitudes). Our code will be made public after the conference
  at https://github.com/Ellimac0/Snake-NeRF

> **TL;DR:** Snake-NeRF是一个新的框架，通过分块处理和图像裁剪，实现了在单个设备上对大规模卫星图像进行高效高质量的NeRF三维重建。

**AI_Comments:** 这篇论文通过提出Snake-NeRF框架，有效地解决了NeRF在大规模场景（特别是地球观测）应用中的主要瓶颈——内存效率和可扩展性。其创新点在于结合了3D瓦片划分、重叠图像裁剪以及专门的瓦片边缘误差处理策略（$2\times 2$ 3D瓦片渐进策略和分段采样器），使得NeRF能够从局部扩展到全球范围。这对于大规模三维地球建模具有重要意义，因为它允许在单个设备上进行高效处理，降低了对昂贵硬件的需求，并提高了实际应用的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的NeRF方法在处理大规模场景时受到内存限制，难以扩展，需要同时加载所有图像和网络。

**Method:** 本文引入了Snake-NeRF框架，采用离核（out-of-core）方法。该方法将感兴趣区域划分为无重叠的3D NeRF瓦片，同时对图像进行重叠裁剪，以确保每个NeRF获得所有必要像素。此外，还引入了一种新颖的$2\times 2$ 3D瓦片渐进策略和分段采样器，以防止瓦片边缘的三维重建误差。

**Result:** 实验证明，大规模卫星图像可以在单个GPU上以线性时间复杂度有效处理，且不影响质量。

**Conclusion:** Snake-NeRF框架能够有效解决大规模NeRF重建的内存和效率问题，实现高质量的全球三维地球观测。

> **ai_Abstract:** 本文提出了Snake-NeRF框架，旨在解决现有神经辐射场（NeRF）方法在处理大规模三维地球观测时面临的内存限制问题。该框架采用离核方法，通过将大规模场景划分为无重叠的3D NeRF瓦片，并对输入图像进行重叠裁剪，确保每个瓦片都能获得充足的训练数据。此外，引入了$2\times 2$ 3D瓦片渐进策略和分段采样器，有效避免了瓦片边缘的重建误差。实验结果表明，Snake-NeRF能够在单个GPU上以线性时间复杂度高效处理大规模卫星图像，同时保持高质量的三维重建效果。

> **摘要翻译:** 神经辐射场（NeRF）最近已成为从多视图卫星图像进行三维重建的一种范式。然而，最先进的NeRF方法通常受限于小场景，原因在于训练期间的内存占用，这也是本文研究的重点。以前关于大规模NeRF的工作通过将场景划分为多个NeRF来缓解这一问题。本文引入了Snake-NeRF，一个可以扩展到大场景的框架。我们的离核方法消除了同时加载所有图像和网络的需要，并且可以在单个设备上运行。我们通过将感兴趣区域划分为无重叠的3D NeRF瓦片来实现这一点。重要的是，我们对图像进行重叠裁剪，以确保每个NeRF都使用所有必要的像素进行训练。我们引入了一种新颖的$2\times 2$ 3D瓦片渐进策略和分段采样器，它们共同防止了沿瓦片边缘的三维重建误差。我们的实验得出结论，大规模卫星图像可以在单个GPU上以线性时间复杂度有效处理，且不影响质量。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [220] [Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions](https://arxiv.org/abs/2507.23487)
> *遮挡条件下桌面种植草莓质量的在线估计*

*Jinshan Zhen, Yuanyue Ge, Tianxiao Zhu, Hui Zhao, Ya Xiong* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 草莓质量估计, 在线估计, 遮挡, RGB-D传感, 深度学习, CycleGAN

**Comment:** Accepted by IROS 2025

> **TL;DR:** 本研究提出了一种结合RGB-D传感和深度学习的视觉管道，用于在野外遮挡条件下在线估计桌面种植草莓的质量。

**AI_Comments:** 这项研究创新性地结合了RGB-D传感、YOLOv8-Seg和CycleGAN来解决野外草莓质量估计中常见的遮挡问题，提供了实时、非破坏性的解决方案。特别是在遮挡恢复方面，CycleGAN的优异表现是其亮点，这对于复杂农业环境下的自动化系统具有重要意义。该方法为自动化采摘和产量监测提供了坚实的基础，具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 由于频繁的遮挡和姿态变化，在野外条件下准确估计桌面种植草莓的质量仍然具有挑战性。

**Method:** 本研究提出了一种集成RGB-D传感和深度学习的视觉管道，用于非破坏性、实时和在线质量估计。该方法采用YOLOv8-Seg进行实例分割，Cycle-consistent生成对抗网络（CycleGAN）完成遮挡区域，并进行倾斜角度校正以优化正面投影面积计算。然后，多项式回归模型将几何特征映射到质量。

**Result:** 实验表明，孤立草莓的平均质量估计误差为8.11%，遮挡情况下的平均误差为10.47%。CycleGAN在遮挡恢复方面优于大型掩膜修复（LaMa）模型，在[0.9-1]范围内实现了更高的像素面积比（PAR）（平均：0.978 vs. 1.112）和更高的交并比（IoU）分数（92.3% vs. 47.7%）。

**Conclusion:** 该方法解决了传统方法的关键局限性，为具有复杂遮挡模式的自动化采摘和产量监测提供了鲁棒的解决方案。

> **ai_Abstract:** 本研究提出了一种基于RGB-D传感和深度学习的视觉管道，用于在野外遮挡条件下在线、非破坏性地估计桌面种植草莓的质量。该方法利用YOLOv8-Seg进行实例分割，CycleGAN进行遮挡区域补全，并结合倾斜角度校正和多项式回归模型。实验结果显示，该方法在孤立和遮挡草莓质量估计上表现良好，且CycleGAN在遮挡恢复方面优于LaMa模型，为自动化采摘和产量监测提供了有效方案。

> **摘要翻译:** 由于频繁的遮挡和姿态变化，在野外条件下准确估计桌面种植草莓的质量仍然具有挑战性。本研究提出了一种结合RGB-D传感和深度学习的视觉管道，以实现非破坏性、实时和在线的质量估计。该方法采用YOLOv8-Seg进行实例分割，Cycle-consistent生成对抗网络（CycleGAN）完成遮挡区域，并进行倾斜角度校正以优化正面投影面积计算。然后，多项式回归模型将几何特征映射到质量。实验表明，孤立草莓的平均质量估计误差为8.11%，遮挡情况下的平均误差为10.47%。CycleGAN在遮挡恢复方面优于大型掩膜修复（LaMa）模型，实现了更高的像素面积比（PAR）（平均：0.978 vs. 1.112）和更高的交并比（IoU）分数（在[0.9-1]范围内分别为92.3% vs. 47.7%）。该方法解决了传统方法的关键局限性，为具有复杂遮挡模式的自动化采摘和产量监测提供了鲁棒的解决方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [223] [Simultaneous Motion And Noise Estimation with Event Cameras](https://arxiv.org/abs/2504.04029)
> *事件相机同时运动与噪声估计*

*Shintaro Shiba, Yoshimitsu Aoki, Guillermo Gallego* | **Category: cs.CV, cs.AI, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 事件相机, 噪声估计, 运动估计, 同时估计, 去噪

**Comment:** 13 pages, 13 figures, 6 tables, Project page
  https://github.com/tub-rip/ESMD

> **TL;DR:** 本文提出了一种新方法，首次同时估计事件相机的运动（包括自我运动和光流）和噪声，并在去噪基准上取得了最先进的结果。

**AI_Comments:** 这项工作的主要创新在于首次实现了事件相机运动和噪声的同步估计，解决了传统方法独立处理导致的信息丢失问题。其方法灵活性强，能够兼容不同的运动估计器，具有较强的普适性。在性能上，达到了SOTA水平，并提供了开源代码，对事件相机领域具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 事件相机噪声难以表征，现有去噪方法通常独立设计，将运动估计等任务分开处理。然而，运动是事件数据的内在部分，因此需要一种能同时处理运动和噪声的方法。

**Method:** 本研究提出了一种同时估计事件相机各种形式运动（如自我运动、光流）和噪声的方法。该方法具有灵活性，允许用其他运动估计器（如深度神经网络）替换广泛使用的对比度最大化框架中的一步运动估计。

**Result:** 实验表明，所提出的方法在E-MLB去噪基准上取得了最先进的结果，在DND21基准上取得了有竞争力的结果，同时在运动估计和强度重建任务中也表现出有效性。

**Conclusion:** 该方法推进了事件数据去噪理论，并通过开源代码扩展了实际去噪用例。

> **ai_Abstract:** 本论文提出了一种新颖的方法，首次实现了事件相机运动（包括自我运动和光流）与噪声的同时估计。针对现有去噪方法忽视运动与噪声内在关联的问题，该方法具有高度灵活性，可集成不同的运动估计器。实验证明，该方法在多个去噪基准测试中达到了领先水平，并在运动估计和强度重建任务中展现出有效性，为事件数据去噪理论和实际应用带来了进展。

> **摘要翻译:** 事件相机是新兴的视觉传感器，其噪声难以表征。现有的事件相机去噪方法通常是独立设计的，因此将其他任务（如运动估计）分开考虑（即在去噪后顺序进行）。然而，运动是事件数据的内在部分，因为没有运动就无法感知场景边缘。据我们所知，我们提出了第一个同时估计各种形式运动（例如，自我运动、光流）和噪声的方法。该方法具有灵活性，因为它允许用任何其他运动估计器（例如，深度神经网络）替换广泛使用的对比度最大化框架中的一步运动估计。实验表明，所提出的方法在E-MLB去噪基准上取得了最先进的结果，并在DND21基准上取得了有竞争力的结果，同时在运动估计和强度重建任务中也表现出有效性。我们的方法推进了事件数据去噪理论，并通过开源代码扩展了实际去噪用例。项目页面：https://github.com/tub-rip/ESMD

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [226] [Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval](https://arxiv.org/abs/2507.23284)
> *基于多模态大语言模型的双向似然估计用于文本-视频检索*

*Dohwan Ko, Ji Soo Lee, Minhyuk Choi, Zihang Meng, Hyunwoo J. Kim* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 文本-视频检索, 多模态大语言模型, 双向似然估计, 候选先验偏差, 候选先验归一化

**Comment:** ICCV 2025 Highlight

> **TL;DR:** 本文提出了一种名为BLiM的新型文本-视频检索框架，通过双向似然估计和候选先验归一化（CPN）模块，有效解决了多模态大语言模型在检索中引入的候选先验偏差问题，并在多个基准测试中显著超越现有SOTA模型。

**AI_Comments:** 该论文创新性地指出了多模态大语言模型在文本-视频检索中存在的“候选先验偏差”问题，并提出了BLiM框架和CPN模块来有效解决此问题。BLiM的双向似然估计思路独到，而CPN作为训练无关的校准模块，其简洁性和有效性尤为突出，且在其他多模态任务中也表现出普适性，这对于多模态领域的泛化性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态大语言模型（MLLMs）在文本-视频检索中的直接应用存在候选先验偏差问题，导致模型偏好固有先验高的候选而非与查询更相关的候选。

**Method:** 本文提出了一种名为BLiM（基于多模态大语言模型的双向似然估计）的检索框架，通过训练模型从视频生成文本和从文本生成视频特征，以利用查询和候选似然。此外，引入了候选先验归一化（CPN）模块，一个简单而有效的无需训练的得分校准模块，旨在减轻候选先验偏差。

**Result:** 在四个文本-视频检索基准测试中，结合CPN的BLiM平均R@1性能超越现有SOTA模型6.4，有效缓解了候选先验偏差并强调了查询-候选相关性。深入分析表明，CPN在检索之外的各种多模态任务中也具有广泛适用性，通过减少对文本先验的依赖来增强视觉理解。

**Conclusion:** BLiM和CPN有效解决了多模态大语言模型在文本-视频检索中存在的候选先验偏差问题，显著提升了检索性能，并证明了CPN在增强视觉理解方面的普适性。

> **ai_Abstract:** 本文提出了一种名为BLiM（基于多模态大语言模型的双向似然估计）的新型文本-视频检索框架，旨在解决多模态大语言模型在检索中引入的候选先验偏差问题。BLiM通过训练模型进行文本到视频和视频到文本的双向生成，利用查询和候选似然。此外，引入了无需训练的候选先验归一化（CPN）模块来校准得分，进一步减轻偏差。实验证明，BLiM结合CPN在多个基准测试中显著优于现有最先进模型，平均R@1提升6.4，有效缓解了偏差并增强了查询-候选相关性。研究还表明CPN在其他多模态任务中也具有广泛适用性，有助于增强视觉理解。

> **摘要翻译:** 文本-视频检索旨在从大规模在线数据库中，给定视频（或文本）查询，找到最相关的文本（或视频）候选。最近的工作利用多模态大语言模型（MLLMs）来改进检索，特别是对于长或复杂的查询-候选对。然而，我们观察到MLLMs的简单应用，即基于候选似然的检索，引入了候选先验偏差，使得模型偏好固有先验较高的候选而非与查询更相关的候选。为此，我们提出了一种新颖的检索框架，即基于MLLM的双向似然估计（BLiM），它通过训练模型从给定视频生成文本以及从给定文本生成视频特征来利用查询和候选似然。此外，我们引入了候选先验归一化（CPN），一个简单但有效的无需训练的得分校准模块，旨在减轻候选似然中的候选先验偏差。在四个文本-视频检索基准测试中，我们配备CPN的BLiM平均R@1性能超越现有最先进模型6.4，有效缓解了候选先验偏差并强调了查询-候选相关性。我们在检索之外的各种多模态任务中的深入分析突出了CPN的广泛适用性，它通过减少对文本先验的依赖来增强视觉理解。代码可在https://github.com/mlvlab/BLiM获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [229] [ClaraVid: A Holistic Scene Reconstruction Benchmark From Aerial Perspective With Delentropy-Based Complexity Profiling](https://arxiv.org/abs/2503.17856)
> *ClaraVid: 基于差熵的复杂性分析的航空视角整体场景重建基准*

*Radu Beche, Sergiu Nedevschi* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 航空场景重建, 合成数据集, 差熵, 场景复杂性, ClaraVid, 基准测试

**Comment:** Accepted ICCV 2025

> **TL;DR:** ClaraVid是一个新的航空合成数据集，旨在克服现有数据集的局限性，并引入了基于差熵的DSP指标来评估场景复杂性。研究发现，场景复杂性与神经重建精度之间存在一致的关联，高差熵与更高的重建误差强烈相关，验证了DSP作为可靠复杂性先验的有效性。

**AI_Comments:** 这项工作的创新之处在于同时解决了航空场景重建中数据集稀缺性和现有合成数据集质量不足的问题，并引入了一个新颖的、基于信息论的复杂性度量（DSP）。DSP能够定量评估场景难度并与重建误差相关联，这对于指导神经重建模型的设计和评估具有重要意义。ClaraVid数据集的发布及其多模态特性，将极大地推动航空场景理解和重建领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 航空整体场景理解算法的发展受到缺乏能够同时实现语义和几何重建的综合数据集的阻碍。现有合成数据集存在任务特定限制、不真实的场景构成和渲染伪影，影响了实际应用性。

**Method:** 引入了ClaraVid，一个专门设计用于克服现有数据集限制的合成航空数据集，包含16,917张高分辨率图像及多模态数据。引入了Delentropic Scene Profile (DSP)，一种源自差熵分析的新颖复杂性度量，旨在定量评估场景难度。利用DSP系统地基准测试了神经重建方法。

**Result:** 揭示了场景复杂性与重建精度之间存在一致且可测量的关联。经验结果表明，更高的差熵与更高的重建误差强烈相关。

**Conclusion:** DSP被验证为一种可靠的复杂性先验。

> **ai_Abstract:** 本论文介绍了ClaraVid，一个用于航空整体场景重建的新型合成数据集，旨在解决现有数据集在语义和几何重建方面的不足以及合成数据集的现实性问题。ClaraVid包含大量高分辨率图像及多模态数据，并优化了渲染质量。此外，论文还提出了Delentropic Scene Profile (DSP)，一种基于差熵的场景复杂性度量。通过使用DSP对神经重建方法进行基准测试，研究发现场景复杂性与重建精度之间存在显著关联，且高差熵与高重建误差强相关，从而验证了DSP作为可靠复杂性先验的有效性。

> **摘要翻译:** 航空整体场景理解算法的发展受到缺乏能够同时实现语义和几何重建的综合数据集的阻碍。虽然合成数据集提供了一种替代方案，但现有选项存在任务特定限制、不真实的场景构成和渲染伪影，这些都损害了实际应用性。我们引入了ClaraVid，一个专门设计用于克服这些限制的合成航空数据集。ClaraVid包含16,917张高分辨率图像，以4032x3024的分辨率从不同景观的多个视角捕获，提供密集深度图、全景分割、稀疏点云和动态对象遮罩，同时减轻了常见的渲染伪影。为了进一步推进神经重建，我们引入了差熵场景剖面（Delentropic Scene Profile，DSP），这是一种源自差熵分析的新颖复杂性度量，旨在定量评估场景难度并为重建任务提供信息。利用DSP，我们系统地基准测试了神经重建方法，揭示了场景复杂性与重建精度之间存在一致且可测量的关联。经验结果表明，更高的差熵与更高的重建误差强烈相关，验证了DSP作为一种可靠的复杂性先验。数据和代码可在项目页面获取：https://rdbch.github.io/claravid/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [232] [Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging](https://arxiv.org/abs/2507.23027)
> *恢复诊断价值：超分辨率辅助的心脏超声分类在资源受限成像中的应用*

*Krishan Agyakari Raja Babu, Om Prabhu, Annu, Mohanasankar Sivaprakasam* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 超分辨率, 心脏超声, 深度学习, 图像分类, 资源受限环境

**Comment:** Accepted at the MICCAI Workshop on "Medical Image Computing in
  Resource Constrained Settings & Knowledge Interchange (MIRASOL)" 2025

> **TL;DR:** 在资源受限环境下，超分辨率技术（特别是SRResNet）能有效提升低质量心脏超声图像的分类准确性，恢复诊断价值。

**AI_Comments:** 这项工作创新性地将超分辨率技术应用于心脏超声领域，解决了资源受限环境下图像质量差导致诊断困难的问题。其重要性在于，通过提升低质量图像的诊断价值，能够使AI辅助诊断在更广泛的地区（特别是资源匮乏地区）得到有效应用，具有显著的临床和社会意义。SRResNet在提升性能的同时兼顾计算效率，也表明了其在实际部署中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 资源受限环境下，低质量心脏超声图像阻碍了自动化心脏解释和诊断模型的有效性。超分辨率技术在MRI和CT中表现良好，但在心脏超声领域的应用尚未充分探索。

**Method:** 本研究旨在探讨深度学习超分辨率技术改善低质量2D心脏超声图分类准确性的潜力。使用公开的CAMUS数据集，按图像质量分层样本。评估了两个临床相关任务：二腔心与四腔心视图分类（2CH vs. 4CH）和舒张末期与收缩末期相位分类（ED vs. ES）。应用了SRGAN和SRResNet两种超分辨率模型来增强低质量图像。

**Result:** 研究观察到性能指标显著提升，特别是SRResNet，它同时提供了计算效率。

**Conclusion:** 超分辨率技术能有效恢复退化超声扫描的诊断价值，使其成为资源受限环境下AI辅助医疗的可行工具，实现事半功倍的效果。

> **ai_Abstract:** 本文探讨了在资源受限环境下，使用深度学习超分辨率技术（特别是SRGAN和SRResNet）改善低质量二维心脏超声图像分类准确性的潜力。研究利用CAMUS数据集，针对2CH/4CH视图分类和ED/ES相位分类两项任务进行评估。结果显示，超分辨率技术，尤其是SRResNet，能显著提升分类性能，有效恢复退化超声图像的诊断价值，为AI辅助心脏诊断在资源匮乏地区的应用提供了可行方案。

> **摘要翻译:** 在资源受限环境（RCS）中，自动化心脏解释常因低质量超声心动图成像而受阻，从而限制了下游诊断模型的有效性。虽然超分辨率（SR）技术在增强磁共振成像（MRI）和计算机断层扫描（CT）方面已显示出前景，但其在超声心动图——一种广泛可及但易受噪声影响的模态——中的应用仍未得到充分探索。在这项工作中，我们研究了基于深度学习的SR技术改善低质量二维超声心动图分类准确性的潜力。我们使用公开可用的CAMUS数据集，根据图像质量对样本进行分层，并评估了两个临床相关的、复杂程度不同的任务：一个相对简单的二腔心与四腔心（2CH vs. 4CH）视图分类，以及一个更复杂的舒张末期与收缩末期（ED vs. ES）相位分类。我们应用了两种广泛使用的SR模型——超分辨率生成对抗网络（SRGAN）和超分辨率残差网络（SRResNet），来增强低质量图像，并观察到性能指标显著提升——特别是SRResNet，它还提供了计算效率。我们的研究结果表明，SR能够有效恢复退化超声扫描的诊断价值，使其成为RCS中人工智能辅助护理的可行工具，实现事半功倍的效果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [233] [AGA: An adaptive group alignment framework for structured medical cross-modal representation learning](https://arxiv.org/abs/2507.23402)
> *AGA：一种用于结构化医学跨模态表示学习的自适应分组对齐框架*

*Wei Li, Xun Gong, Jiao Li, Xiaobin Sun* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 医学跨模态学习, 自适应分组对齐, 结构化表示学习, 视觉-语言预训练, 实例感知对齐

**Comment:** 

> **TL;DR:** 本文提出了AGA框架，通过自适应分组对齐机制，解决了医学领域跨模态表示学习中报告结构简化和负样本依赖的问题，在图像-文本检索和分类任务上表现出色。

**AI_Comments:** 本文的创新点在于提出了自适应分组对齐（AGA）框架，通过双向分组机制和动态阈值门控模块，有效捕捉了医学报告的结构化语义，克服了传统方法简化报告结构的问题。特别值得注意的是，其引入的实例感知组对齐损失，避免了对外部难负样本的依赖，这对于小规模医学数据集尤其重要，显著提升了模型在资源受限环境下的实用性。该框架为医学跨模态表示学习提供了一个更鲁棒和高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 当前的医学领域视觉-语言预训练方法常简化临床报告，忽略其固有结构；同时，对比学习框架通常需要大量难负样本，这对于小规模医学数据集不切实际。

**Method:** 本文提出了自适应分组对齐（AGA）框架，用于捕获配对医学图像和报告中的结构化语义。AGA引入了基于稀疏相似度矩阵的双向分组机制，计算文本词元和图像块之间的细粒度相似度。每个词元选择其最匹配的图像块形成视觉组，每个图像块选择其最相关的词元形成语言组。为实现自适应分组，设计了语言分组阈值门和视觉分组阈值门两个阈值门控模块，动态学习分组阈值。组表示通过基于相似度分数的加权平均计算。为将每个词元与其组表示对齐，引入了实例感知组对齐损失，该损失在每个图像-文本对内部操作，无需外部负样本。最后，应用双向跨模态分组对齐模块，以增强视觉和语言组表示之间的细粒度对齐。

**Result:** 在公共和私人数据集上的大量实验表明，所提出的方法在微调和零样本设置下的图像-文本检索和分类任务上均取得了强大的性能。

**Conclusion:** AGA框架通过引入自适应分组对齐机制和实例感知组对齐损失，有效解决了医学跨模态表示学习中报告结构利用不足和负样本依赖的问题，在多项任务上实现了高性能，证明了其在捕获结构化语义方面的有效性。

> **ai_Abstract:** 本文提出了一种名为AGA（自适应分组对齐）的新框架，旨在解决医学领域跨模态表示学习中现有方法忽略临床报告结构和对大量负样本依赖的问题。AGA通过引入基于稀疏相似度矩阵的双向分组机制，实现图像块与文本词元之间的细粒度对齐，并利用动态阈值门控模块进行自适应分组。此外，通过实例感知组对齐损失，消除了对外部负样本的需求。实验证明，AGA在图像-文本检索和分类任务上表现出色，适用于微调和零样本场景。

> **摘要翻译:** 从配对图像和报告中学习医学视觉表示是表示学习中一个有前景的方向。然而，当前医学领域的视觉-语言预训练方法常常将临床报告简化为单一实体或碎片化词元，忽略了其固有的结构。此外，对比学习框架通常依赖大量难负样本，这对于小规模医学数据集来说是不切实际的。为了解决这些挑战，我们提出了自适应分组对齐（AGA），这是一个捕获配对医学图像和报告中结构化语义的新框架。AGA引入了一种基于稀疏相似度矩阵的双向分组机制。对于每个图像-报告对，我们计算文本词元和图像块之间的细粒度相似度。每个词元选择其最匹配的图像块形成一个视觉组，每个图像块选择其最相关的词元形成一个语言组。为了实现自适应分组，我们设计了两个阈值门控模块，称为语言分组阈值门和视觉分组阈值门，它们动态学习分组阈值。组表示根据相似度分数进行加权平均计算。为了将每个词元与其组表示对齐，我们引入了一种实例感知组对齐损失，该损失在每个图像-文本对内部操作，从而无需外部负样本。最后，应用双向跨模态分组对齐模块，以增强视觉和语言组表示之间的细粒度对齐。在公共和私人数据集上的大量实验表明，我们的方法在微调和零样本设置下的图像-文本检索和分类任务上均取得了强大的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [236] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
> *基于上下文的自动驾驶开放词汇运动检索*

*Stefan Englmeier, Max A. Büttner, Katharina Winter, Fabian B. Flohr* | **Category: cs.CV, cs.CL, cs.IR, cs.RO, 68T45, 68P20, 68T10, 68T50, 68T07, 68T40, I.2.10; I.4.8; I.2.9; H.3.3** | **Updated: 2025-08-01**

**Keywords:** 自动驾驶, 运动检索, 开放词汇, SMPL, WayMoCo

**Comment:** 9 pages, 10 figure, project page
  https://iv.ee.hm.edu/contextmotionclip/, submitted to IEEE Transactions on
  Intelligent Vehicles (T-IV), This work has been submitted to the IEEE for
  possible publication

> **TL;DR:** 该论文提出了一种基于上下文的运动检索框架，利用开放词汇方法从大规模数据集中检索自动驾驶中罕见的人类行为场景，并引入了WayMoCo数据集，在运动-上下文检索方面优于现有技术。

**AI_Comments:** 该论文的创新点在于结合了SMPL运动数据和视频帧，并通过自然语言对齐的多模态嵌入空间实现了基于文本查询的运动检索，这对于自动驾驶中长尾分布的边缘案例识别具有重要意义。引入的WayMoCo数据集也为未来的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统在涉及弱势道路使用者（VRUs）异常或复杂行为的安全关键场景中必须可靠运行。识别这些驾驶数据集中的边缘案例对于鲁棒评估和泛化至关重要，但在大规模数据集的长尾中检索此类罕见人类行为场景具有挑战性。

**Method:** 本文提出了一种新颖的上下文感知运动检索框架。该方法结合了基于Skinned Multi-Person Linear (SMPL) 的运动序列和相应的视频帧，然后将它们编码到一个与自然语言对齐的共享多模态嵌入空间中。该方法通过文本查询实现人类行为及其上下文的可扩展检索。同时引入了WayMoCo数据集，该数据集是Waymo开放数据集的扩展，包含从生成的伪地面真值SMPL序列和相应图像数据中自动标注的运动和场景上下文描述。

**Result:** 在WayMoCo数据集上评估时，该方法在运动-上下文检索方面的准确率比最先进的模型高出27.5%。

**Conclusion:** 该研究成功开发了一种有效的上下文感知运动检索框架和相应的WayMoCo数据集，显著提升了自动驾驶系统中罕见人类行为场景的检索能力，有助于自动驾驶系统的靶向评估和鲁棒性提升。

> **ai_Abstract:** 该论文提出了一种新颖的上下文感知运动检索框架，旨在解决自动驾驶中检索罕见弱势道路使用者（VRUs）行为边缘案例的挑战。该框架将SMPL运动序列和视频帧编码到与自然语言对齐的多模态嵌入空间中，从而可以通过文本查询实现人类行为及其上下文的可扩展检索。研究还引入了WayMoCo数据集，并在此数据集上验证了其方法在运动-上下文检索方面相较于现有技术有显著的性能提升。

> **摘要翻译:** 自动驾驶系统必须在安全关键场景中可靠运行，特别是那些涉及弱势道路使用者（VRUs）异常或复杂行为的场景。识别驾驶数据集中的这些边缘案例对于鲁棒评估和泛化至关重要，但在大规模数据集的长尾中检索此类罕见人类行为场景具有挑战性。为了支持在多样化、以人为中心的场景中对自动驾驶系统进行靶向评估，我们提出了一种新颖的上下文感知运动检索框架。我们的方法结合了蒙皮多人线性（SMPL）运动序列和相应的视频帧，然后将它们编码到一个与自然语言对齐的共享多模态嵌入空间中。我们的方法通过文本查询实现了人类行为及其上下文的可扩展检索。这项工作还介绍了我们的数据集WayMoCo，它是Waymo开放数据集的扩展。它包含从生成的伪地面真值SMPL序列和相应图像数据中自动标记的运动和场景上下文描述。在WayMoCo数据集上评估时，我们的方法在运动-上下文检索方面的准确率比最先进的模型高出27.5%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [244] [Indian Sign Language Detection for Real-Time Translation using Machine Learning](https://arxiv.org/abs/2507.20414)
> *基于机器学习的印度手语实时翻译检测*

*Rajat Singhal, Jatin Gupta, Akhil Sharma, Anushka Gupta, Navya Sharma* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 印度手语, 实时翻译, 机器学习, 卷积神经网络, MediaPipe

**Comment:** 7 pages, 6 figures, 2 tables. Published in Proceedings of the 6th
  International Conference on Recent Advances in Information Technology (RAIT),
  2025, IEEE

> **TL;DR:** 该研究提出了一种基于CNN的实时印度手语检测和翻译系统，实现了99.95%的分类准确率，旨在弥合印度聋哑社区的沟通鸿沟。

**AI_Comments:** 该论文的创新点在于专注于印度手语（ISL），这是一个相比其他全球手语技术发展较少的领域。其提出的基于CNN和MediaPipe的实时系统，实现了99.95%的极高准确率，这对于实际应用具有重要意义，能够显著改善印度聋哑社区的沟通状况。该研究为手语翻译技术在特定地区的应用提供了强有力的范例。

<details>
  <summary>Details</summary>

**Motivation:** 聋哑社区在全球范围内，尤其是在印度，由于熟练翻译人员的稀缺和可及翻译技术的不足，在有效沟通方面面临巨大障碍。本研究旨在通过开发印度手语（ISL）的机器学习技术解决方案，来弥合这一关键沟通鸿沟，因为相较于其他全球手语，印度手语的技术解决方案发展较少。

**Method:** 本研究提出了一种基于卷积神经网络（CNN）的鲁棒、实时印度手语检测和翻译系统。该模型在全面的印度手语数据集上进行训练，并利用MediaPipe进行精确的手部跟踪和运动检测，以实现动态手势的无缝翻译。文中详细阐述了模型的架构、数据预处理流程和分类方法。

**Result:** 该模型在印度手语检测上实现了99.95%的分类准确率，表现出卓越的性能。系统的有效性通过准确率、F1分数、精确率和召回率等关键性能指标进行了严格评估，确保了其在实际应用中的可靠性。

**Conclusion:** 本研究提出的基于CNN的实时印度手语检测和翻译系统，凭借其高准确率和可靠性，能够有效增强印度聋哑社区的沟通能力，弥合沟通障碍。

> **ai_Abstract:** 本研究旨在解决印度聋哑社区在沟通中面临的挑战，通过开发一种基于卷积神经网络（CNN）的实时印度手语（ISL）检测和翻译系统。该系统利用MediaPipe进行手部跟踪，并在全面的ISL数据集上训练，实现了99.95%的分类准确率。研究强调了其高精度和通过多项性能指标验证的可靠性，旨在弥合印度的沟通鸿沟。

> **摘要翻译:** 手势语言被聋哑社区用来通过手势和身体动作进行交流，这些动作依赖于被称为手语的视觉空间模式。手语，依靠手势和身体动作的视觉空间模式，是全球聋哑社区的主要交流方式。有效的沟通是人类互动的基础，然而这些社区中的个体经常面临严重的障碍，因为熟练的口译员和可访问的翻译技术稀缺。本研究通过专注于印度手语（ISL）来专门解决印度背景下的这些挑战。通过利用机器学习，本研究旨在弥合印度聋哑和听障人群的关键沟通鸿沟，因为与其他全球手语相比，印度手语的技术解决方案发展较少。我们提出了一种基于卷积神经网络（CNN）的鲁棒、实时ISL检测和翻译系统。我们的模型在一个全面的ISL数据集上进行训练，并展示了卓越的性能，实现了99.95%的分类准确率。这种高精度突显了模型识别不同手语细微视觉特征的能力。系统的有效性通过关键性能指标（包括准确率、F1分数、精确率和召回率）进行了严格评估，确保了其在实际应用中的可靠性。对于实时实现，该框架集成了MediaPipe以实现精确的手部跟踪和运动检测，从而实现动态手势的无缝翻译。本文详细介绍了模型的架构、数据预处理流程和分类方法。该研究详细阐述了模型架构、预处理和分类方法，以增强聋哑社区的沟通。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [247] [LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis](https://arxiv.org/abs/2507.23295)
> *LED基准：诊断文档布局分析中的结构布局错误*

*Inbum Heo, Taewook Hwang, Jeesu Jung, Sangkeun Jung* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 文档布局分析, 结构错误, 评估基准, 布局错误检测, 多模态模型

**Comment:** 

> **TL;DR:** 提出LED基准和数据集，用于评估文档布局分析的结构鲁棒性，揭示传统指标遗漏的错误。

**AI_Comments:** 该论文的创新之处在于提出了一个专门用于诊断文档布局分析中结构性错误的新型基准（LED）和合成数据集（LED-Dataset），填补了现有评估指标的空白。它对于推动更鲁棒的文档布局分析模型（特别是基于大型语言模型和多模态模型）的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型和多模态模型显著改进了文档布局检测，但现有评估指标（如IoU和mAP）无法有效检测区域合并、分割和内容缺失等关键结构性错误。

**Method:** 提出了布局错误检测（LED）基准，用于评估文档布局预测的结构鲁棒性。LED定义了八种标准化错误类型，并提出了三种互补任务：错误存在检测、错误类型分类和元素级错误类型分类。此外，构建了LED-Dataset，一个基于DLA模型经验分布注入真实结构错误的人工数据集。

**Result:** 对一系列LMMs的实验结果表明，LED能有效区分结构理解能力，揭示了传统指标无法发现的模态偏差和性能权衡。

**Conclusion:** LED基准能够有效诊断文档布局分析中的结构性错误，并揭示传统指标无法捕捉的性能差异和模态偏差。

> **ai_Abstract:** 本文提出了布局错误检测（LED）基准和LED-Dataset合成数据集，旨在解决传统指标（如IoU和mAP）在评估文档布局分析中结构性错误（如合并、分割、内容缺失）的局限性。LED定义了八种错误类型和三种评估任务，以衡量结构鲁棒性。实验结果表明，LED能够有效诊断结构理解能力，并揭示传统方法无法捕捉的见解。

> **摘要翻译:** 大型语言模型和多模态模型在文档布局分析方面的最新进展显著改善了布局检测。然而，尽管取得了这些改进，但在解决关键结构性错误（如区域合并、分割和内容缺失）方面仍然存在挑战。传统的评估指标，如IoU和mAP，主要关注空间重叠，不足以检测这些错误。为了解决这一限制，我们提出了布局错误检测（LED），一个旨在评估文档布局预测结构鲁棒性的新型基准。LED定义了八种标准化错误类型，并提出了三种互补任务：错误存在检测、错误类型分类和元素级错误类型分类。此外，我们构建了LED-Dataset，一个通过根据DLA模型的经验分布注入真实结构错误而生成的人工数据集。对一系列大型多模态模型（LMMs）的实验结果表明，LED能够有效区分结构理解能力，揭示了传统指标无法看到的模态偏差和性能权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [257] [Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion](https://arxiv.org/abs/2507.23508)
> *红外-可见光图像融合的双曲循环对齐*

*Timing Li, Bing Cao, Jiahe Feng, Haifang Cao, Qinghau Hu, Pengfei Zhu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 双曲空间, 图像配准, 图像融合, 跨模态, 循环对齐

**Comment:** 

> **TL;DR:** 现有欧几里得配准方法在跨模态图像融合中效果不佳。本文提出Hy-CycleAlign，首个基于双曲空间的图像配准方法，显著提升了多模态图像的对齐和融合质量。

**AI_Comments:** 本文的创新点在于首次将双曲空间引入图像配准领域，特别是针对跨模态图像融合的挑战。其提出的双路径循环配准框架和H²CA模块有效解决了模态差异和几何一致性问题，为多模态图像配准提供了新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像配准方法通常基于欧几里得空间，但无法有效处理跨模态图像的错位问题，导致图像对齐和融合质量不佳。

**Method:** 本文提出Hyperbolic Cycle Alignment Network (Hy-CycleAlign)，这是首个基于双曲空间的图像配准方法。它引入了一个双路径跨模态循环配准框架，包括前向配准网络和后向配准网络，以确保几何一致性。此外，设计了一个Hyperbolic Hierarchy Contrastive Alignment (H²CA) 模块，将图像映射到双曲空间并施加配准约束，以减少模态差异的影响。研究还分析了欧几里得空间和双曲空间中的图像配准特性。

**Result:** 在错位多模态图像上的大量实验表明，所提出的方法在图像对齐和融合方面均显著优于现有方法。

**Conclusion:** 双曲空间能够实现更灵敏和有效的多模态图像配准，所提出的Hy-CycleAlign方法显著提升了跨模态图像的对齐和融合质量。

> **ai_Abstract:** 本文提出了一种名为Hy-CycleAlign的双曲循环对齐网络，旨在解决现有欧几里得空间图像配准方法在跨模态图像融合中配准效果不佳的问题。Hy-CycleAlign是首个基于双曲空间的图像配准方法，它引入了双路径跨模态循环配准框架，并通过双曲层级对比对齐（H²CA）模块有效减少模态差异。实验证明，该方法在图像对齐和融合方面均显著优于现有方法。

> **摘要翻译:** 图像融合综合了来自多个源的互补信息，减轻了单模态成像系统固有的局限性。准确的图像配准对于有效的多源数据融合至关重要。然而，现有的配准方法，通常基于欧几里得空间中的图像平移，无法有效处理跨模态错位，导致次优的对齐和融合质量。为了克服这一限制，我们探索了非欧几里得空间中的图像对齐，并提出了一种双曲循环对齐网络（Hy-CycleAlign）。据我们所知，Hy-CycleAlign是第一个基于双曲空间的图像配准方法。它引入了一个双路径跨模态循环配准框架，其中前向配准网络对齐跨模态输入，而后向配准网络重建原始图像，形成具有几何一致性的闭环配准结构。此外，我们设计了一个双曲层级对比对齐（H²CA）模块，该模块将图像映射到双曲空间并施加配准约束，有效减少了模态差异造成的干扰。我们进一步分析了欧几里得空间和双曲空间中的图像配准，证明双曲空间能够实现更灵敏和有效的多模态图像配准。对错位多模态图像进行的广泛实验表明，我们的方法在图像对齐和融合方面均显著优于现有方法。我们的代码将公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [258] [Machine learning and machine learned prediction in chest X-ray images](https://arxiv.org/abs/2507.23455)
> *机器学习与胸部X射线图像中的机器学习预测*

*Shereiff Garrett, Abhinav Adhikari, Sarina Gautam, DaShawn Marquis Morris, Chandra Mani Adhikari* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 机器学习, 胸部X射线, 卷积神经网络, DenseNet-121, 疾病预测

**Comment:** 8 pages, 7 figures

> **TL;DR:** 本文使用CNN和DenseNet-121在5824张胸部X射线图像上进行疾病预测，结果显示两者表现良好，DenseNet-121的关注区域更准确。

**AI_Comments:** 这篇论文展示了机器学习，特别是深度学习模型，在医学图像分析中的潜力，通过自动化模式识别来辅助疾病诊断。DenseNet-121在关注图像关键区域方面的优势表明了其在可解释性方面可能优于简单的CNN模型，这对于医疗应用至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习和人工智能能够利用数据训练算法、学习模式并进行预测，从而以显著的准确性解决复杂问题，无需显式编程。本文旨在利用此方法对胸部X射线图像进行疾病预测。

**Method:** 论文使用了5824张胸部X射线图像数据集。实现了两种机器学习算法：基线卷积神经网络 (CNN) 和 DenseNet-121。通过二分类问题进行性能评估，并使用梯度加权类激活映射 (Grad-CAM) 分析模型决策。

**Result:** 基线CNN和DenseNet-121在二分类问题上表现非常好。梯度加权类激活映射显示DenseNet-121在决策时能更准确地关注胸部X射线图像的关键部分，优于基线CNN。

**Conclusion:** 两种机器学习模型（基线CNN和DenseNet-121）在胸部X射线图像的疾病预测二分类任务中表现出色，其中DenseNet-121在识别图像关键区域方面表现更优。

> **ai_Abstract:** 本文探讨了机器学习在胸部X射线图像疾病预测中的应用。研究人员使用5824张胸部X射线图像，比较了基线卷积神经网络（CNN）和DenseNet-121两种算法的性能。结果表明，这两种模型在二分类预测任务中均表现良好，特别是DenseNet-121，其通过梯度加权类激活映射显示出在决策时能更准确地聚焦于图像的关键区域。

> **摘要翻译:** 机器学习和人工智能是快速发展的研究领域，其中数据用于训练算法、学习模式和进行预测。这种方法通过识别数据中复杂的关系，无需明确编程即可高精度地解决看似复杂的问题。我们以5824张胸部X射线图像为例，实现了两种机器学习算法，即基线卷积神经网络（CNN）和DenseNet-121，并展示了我们在胸部X射线图像中进行机器学习预测以预测患病患者的分析。基线CNN和DenseNet-121在这项工作中提出的二分类问题中都表现出色。梯度加权类激活映射显示，DenseNet-121在决策时比基线CNN更能正确地关注输入胸部X射线图像的重要部分。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [264] [Accenture-NVS1: A Novel View Synthesis Dataset](https://arxiv.org/abs/2503.18711)
> *Accenture-NVS1：一个新颖视图合成数据集*

*Thomas Sugg, Kyle O'Brien, Lekh Poudel, Alex Dumouchelle, Michelle Jou, Marc Bosch, Deva Ramanan, Srinivasa Narasimhan, Shubham Tulsiani* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 新颖视图合成, 数据集, 机载图像, 地面图像, ACC-NVS1

**Comment:** 6 pages, 7 figures

> **TL;DR:** 本文介绍了ACC-NVS1，这是一个专门用于机载和地面图像新颖视图合成研究的数据集，包含从奥斯汀和匹兹堡收集的148,000张图像，旨在补充现有数据集。

**AI_Comments:** 该数据集的创新之处在于其专门针对机载和地面图像的新颖视图合成，并明确指出其旨在补充现有资源而非作为基准，这有助于研究人员理解其定位。其重要性在于为NVS领域提供了大量真实世界数据，特别关注了不同高度和瞬态物体等实际挑战。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机是为新颖视图合成（NVS）研究提供一个专门的数据集，特别是针对机载和地面图像，以解决现有数据集可能未涵盖的各种高度和瞬态物体等挑战。

**Method:** 数据集ACC-NVS1是通过在2023年和2024年于德克萨斯州奥斯汀和宾夕法尼亚州匹兹堡收集数据而创建的。数据收集涵盖了六个不同的真实世界场景，这些场景由机载和地面摄像机捕获。

**Result:** ACC-NVS1数据集共包含148,000张图像，涵盖了六个多样化的真实世界场景，这些场景是从机载和地面摄像机捕获的。该数据集旨在解决不同高度和瞬态物体等挑战。

**Conclusion:** ACC-NVS1是一个专门为机载和地面图像的新颖视图合成研究而设计的数据集。它旨在补充现有数据集，为全面的研究提供额外的资源，而不是作为基准。

> **ai_Abstract:** 本文推出了Accenture-NVS1，一个专为机载和地面图像的新颖视图合成研究设计的专用数据集。该数据集于2023年至2024年在奥斯汀和匹兹堡收集，包含来自六个真实世界场景的148,000张图像，旨在解决不同高度和瞬态物体等挑战。它作为现有数据集的补充资源，而非基准。

> **摘要翻译:** 本文介绍了ACC-NVS1，这是一个专门为机载和地面图像的新颖视图合成研究设计的数据集。ACC-NVS1的数据于2023年和2024年在德克萨斯州奥斯汀和宾夕法尼亚州匹兹堡收集。该数据集包含从机载和地面摄像机捕获的六个多样化的真实世界场景，总计148,000张图像。ACC-NVS1解决了不同高度和瞬态物体等挑战。该数据集旨在补充现有数据集，为全面的研究提供额外资源，而非作为基准。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [268] [Training-free Geometric Image Editing on Diffusion Models](https://arxiv.org/abs/2507.23300)
> *扩散模型上的免训练几何图像编辑*

*Hanshen Zhu, Zhen Zhu, Kaile Zhang, Yiming Gong, Yuliang Liu, Xiang Bai* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 几何图像编辑, 扩散模型, 免训练, 解耦管道, GeoBench

**Comment:** Accepted by ICCV2025

> **TL;DR:** 本文提出了一种名为FreeFine的免训练扩散方法，用于几何图像编辑，通过解耦变换、修复和细化步骤，在复杂变换下优于现有方法。

**AI_Comments:** 这篇论文的创新点在于提出了一个解耦的几何图像编辑管道，有效地解决了现有扩散模型在处理复杂变换时遇到的挑战。通过将任务分解并引入免训练的FreeFine方法进行修复和细化，显著提升了编辑的精度和图像保真度。同时，引入新的GeoBench基准测试也为该领域的研究提供了有价值的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散的图像编辑方法在处理大型或结构复杂的几何变换时表现不佳，因为它们试图在一个步骤中处理所有子任务。

**Method:** 提出了一种解耦的管道，将对象变换、源区域修复和目标区域细化分开。修复和细化都使用一种名为FreeFine的免训练扩散方法实现。

**Result:** 在新的GeoBench基准测试（包含2D和3D编辑场景）中，FreeFine在图像保真度和编辑精度方面优于最先进的替代方法，尤其是在要求高的变换下。

**Conclusion:** FreeFine通过其解耦的管道和免训练的扩散方法，显著提升了几何图像编辑的性能，尤其是在复杂变换场景下。

> **ai_Abstract:** 本文提出了一种名为FreeFine的免训练扩散方法，用于几何图像编辑。针对现有扩散模型在处理复杂几何变换时的不足，FreeFine采用解耦管道，将对象变换、源区域修复和目标区域细化分开处理。实验结果表明，在新的GeoBench基准测试中，FreeFine在图像保真度和编辑精度方面，尤其是在要求高的变换下，优于现有最先进的方法。

> **摘要翻译:** 我们处理几何图像编辑任务，即在保持整体场景连贯性的同时，重新定位、重新定向或重塑图像中的对象。以前的基于扩散的编辑方法通常试图在一个步骤中处理所有相关的子任务，当变换变得较大或结构复杂时，这被证明是困难的。我们通过提出一种解耦的管道来解决这个问题，该管道将对象变换、源区域修复和目标区域细化分开。修复和细化都使用一种免训练的扩散方法FreeFine实现。在我们的新GeoBench基准测试（包含2D和3D编辑场景）中的实验表明，FreeFine在图像保真度和编辑精度方面优于最先进的替代方法，尤其是在要求苛刻的变换下。代码和基准可在以下网址获取：https://github.com/CIawevy/FreeFine

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [Priority-Aware Clinical Pathology Hierarchy Training for Multiple Instance Learning](https://arxiv.org/abs/2507.20469)
> *多示例学习中关注优先级的临床病理学层级训练*

*Sungrae Hong, Kyungeun Kim, Juhyeon Kim, Sol Lee, Jisu Shin, Chanjae Song, Mun Yong Yi* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多示例学习, 临床病理学, 层级训练, 优先级感知, 误诊

**Comment:** 10 pages, 4 figures, Accepted for oral presentation by The 2nd MICCAI
  Student Board (MSB) EMERGE Workshop

> **TL;DR:** 提出了一种新的多示例学习（MIL）方法，通过引入垂直和水平层级来解决临床病理诊断中症状和诊断类别的优先级问题，有效减少了误诊并能优先处理更重要的症状。

**AI_Comments:** 该论文的创新点在于首次将优先级概念引入到临床病理学的多示例学习中，通过设计独特的垂直和水平层级结构，有效解决了现有MIL模型忽略临床重要性的局限。这对于提高病理诊断的准确性和临床实用性具有重要意义，尤其是在处理复杂的多症状病例时。

<details>
  <summary>Details</summary>

**Motivation:** 现有的临床多示例学习（MIL）方法未能充分解决病理症状和诊断类别之间存在的优先级问题，导致MIL模型忽略了类别间的优先级。

**Method:** 提出了一种新的方法，通过使用两种层级（垂直层级间和水平层级内）来解决优先级问题。该方法在每个层级上对MIL预测进行对齐，并在训练期间采用隐式特征重用，以促进同级别内临床上更严重的类别。

**Result:** 使用真实世界患者数据的实验表明，所提出的方法有效地减少了误诊，并在多类别场景中优先处理更重要的症状。进一步的分析验证了所提出组件的有效性，并定性证实了MIL在具有多种症状的挑战性病例中的预测能力。

**Conclusion:** 该研究提出的优先级感知层级训练方法成功解决了临床多示例学习在病理诊断中忽略优先级的问题，通过引入垂直和水平层级结构和特征重用，显著提高了诊断的准确性，减少了误诊，并能有效识别和优先处理临床上更重要的症状。

> **ai_Abstract:** 本文针对临床病理诊断中多示例学习（MIL）未充分考虑症状和诊断类别优先级的问题，提出了一种新的优先级感知层级训练方法。该方法引入了垂直层级间和水平层级内两种结构来处理优先级，并通过对齐预测和隐式特征重用来优先处理更严重的类别。实验结果表明，该方法能有效减少误诊，并在多类别场景中优先识别重要症状，提高了临床诊断的准确性和可靠性。

> **摘要翻译:** 多示例学习（MIL）正越来越多地被用作临床环境中病理诊断决策的支持工具，实现了高性能并减轻了标注负担。然而，现有的临床MIL任务方法未能充分解决病理症状和诊断类别之间存在的优先级问题，导致MIL模型忽略了类别间的优先级。为了克服MIL的这一临床局限性，我们提出了一种新的方法，该方法通过使用两种层级：垂直层级间和水平层级内来解决优先级问题。所提出的方法在每个层级上对MIL预测进行对齐，并在训练期间采用隐式特征重用，以促进同级别内临床上更严重的类别。使用真实世界患者数据的实验表明，所提出的方法有效地减少了误诊，并在多类别场景中优先处理更重要的症状。进一步的分析验证了所提出组件的有效性，并定性证实了MIL在具有多种症状的挑战性病例中的预测能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [274] [Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields](https://arxiv.org/abs/2507.23033)
> *自适应时间步训练以增强基于脉冲的神经辐射场*

*Ranxi Lin, Canming Yao, Jiayi Li, Weihang Liu, Xin Lou, Pingqiang Zhou* | **Category: cs.CV, cs.NE** | **Updated: 2025-07-30**

**Keywords:** 神经辐射场, 脉冲神经网络, 自适应时间步, 能量效率, 3D重建

**Comment:** 

> **TL;DR:** 本文提出PATA，一种基于脉冲的神经辐射场（NeRF）框架，采用自适应时间步训练策略，旨在降低3D重建和渲染的计算成本，显著减少推理时间步和功耗，同时保持渲染质量。

**AI_Comments:** 本文的创新之处在于将脉冲神经网络（SNNs）引入到神经辐射场（NeRF）中，并提出了一种自适应时间步训练策略（PATA），以解决传统NeRF计算量大的问题。其重要性在于，通过显著降低推理时间和功耗，使NeRF技术在边缘计算等资源受限的实际应用场景中变得更加可行。

<details>
  <summary>Details</summary>

**Motivation:** 现有的神经辐射场（NeRF）模型在训练和推理过程中严重依赖于沿光线的密集点采样，导致浮点运算量激增，严重限制了它们在边缘计算等资源受限场景中的应用。脉冲神经网络（SNNs）因其节能特性提供了一种有前景的替代方案。

**Method:** 本文提出了一个基于脉冲的NeRF框架，并采用动态时间步训练策略，命名为预训练-自适应时间步调整（PATA）。该方法在训练过程中自动探索渲染质量和时间步长度之间的权衡，从而实现可变时间步的场景自适应推理，并减少推理过程中的额外计算资源消耗。该方法锚定于Instant-NGP架构。

**Result:** 实验结果表明，PATA在保持渲染保真度的同时，可将推理时间步减少64%，运行功耗降低61.55%。

**Conclusion:** 本文提出的PATA框架通过实现高效、场景自适应的推理，并减少计算资源消耗，同时保持渲染质量，有效地增强了基于脉冲的神经辐射场，使其更适用于资源受限的环境。

> **ai_Abstract:** 本文提出了预训练-自适应时间步调整（PATA），一个新颖的基于脉冲的神经辐射场（NeRF）框架，旨在解决传统NeRF模型的高计算成本问题。PATA采用动态时间步训练策略，优化了渲染质量和时间步长度之间的平衡，从而实现了场景自适应和资源高效的推理。在Instant-NGP架构上进行评估，PATA显著减少了推理时间步（64%）和功耗（61.55%），同时不影响渲染保真度，使NeRF在资源受限环境中更具可行性。

> **摘要翻译:** 神经辐射场（NeRF）模型在3D重建和渲染任务中取得了显著成功。然而，在训练和推理过程中，这些模型严重依赖于沿光线从多个视角进行的密集点采样，导致浮点运算量激增，严重限制了它们在边缘计算等资源受限场景中的应用。脉冲神经网络（SNNs）通过离散时间步的二进制脉冲进行通信，因其节能特性提供了一种有前景的替代方案。鉴于神经渲染中场景尺度和纹理复杂性的固有变异性，以及目前每个场景训练单独模型的普遍做法，我们提出了一种基于脉冲的NeRF框架，并采用动态时间步训练策略，命名为预训练-自适应时间步调整（PATA）。这种方法在训练过程中自动探索渲染质量和时间步长度之间的权衡。因此，它能够实现可变时间步的场景自适应推理，并减少推理过程中额外的计算资源消耗。以Instant-NGP架构为基础，我们在不同的数据集上评估了我们的方法。实验结果表明，PATA在保持渲染保真度的同时，可将推理时间步减少64%，运行功耗降低61.55%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [285] [GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers](https://arxiv.org/abs/2503.19480)
> *GenHancer：不完美的生成模型是强大的以视觉为中心的增强器*

*Shijie Ma, Yuying Ge, Teng Wang, Yuxin Guo, Yixiao Ge, Ying Shan* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 生成模型, 视觉增强, CLIP, 细粒度知识, GenHancer

**Comment:** ICCV 2025. Project released at:
  https://mashijie1028.github.io/GenHancer/

> **TL;DR:** 本文提出GenHancer，一种利用生成模型增强判别模型视觉特征的方法。研究发现，视觉上不完美的生成对表示增强更有效，并提出全局视觉token作为条件、两阶段训练和轻量级去噪器等策略，在MMVP-VLM基准上显著优于现有技术。

**AI_Comments:** 这篇论文的创新点在于挑战了“完美生成等同于最佳增强”的传统观念，提出并验证了“不完美生成”在提取细粒度视觉知识方面的潜力。其对条件机制、去噪配置和生成范式的深入分析，为生成模型在表示增强中的应用提供了新的视角和实用策略。GenHancer不仅提升了CLIP等判别模型的性能，也为未来多模态大模型的视觉能力增强提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法中，生成模型常以CLIP的视觉特征为条件进行重建，以增强表示，但其潜在原理尚未得到充分探索。特别是，研究发现视觉上完美的生成不总是对表示增强最优，关键在于从生成模型中有效提取细粒度知识并减少无关信息。

**Method:** 本文提出了GenHancer方法，通过深入探索三个方面：1) 条件机制：发现仅使用全局视觉token作为条件是最有效的策略，避免了局部token导致的训练崩溃。2) 去噪配置：提出两阶段训练策略以优先学习有用的视觉知识，并证明轻量级去噪器也能带来显著改进。3) 生成范式：探索了连续和离散去噪器，均取得了理想结果，验证了方法的通用性。

**Result:** GenHancer在MMVP-VLM基准上持续优于现有技术，例如在OpenAICLIP上提升了6.0%。增强后的CLIP模型可以进一步集成到多模态大型语言模型中，以提高以视觉为中心的性能。

**Conclusion:** 本文通过深入探索，提出了一种名为GenHancer的有效方法，证明了不完美的生成模型可以作为强大的视觉中心增强器，并通过优化条件机制、去噪配置和生成范式，显著提升了判别模型的视觉表示能力。

> **ai_Abstract:** 本文提出GenHancer，一种利用不完美的生成模型作为视觉中心增强器的新方法。研究发现，视觉上完美的生成并非总是最佳的表示增强方式，关键在于从生成模型中有效提取细粒度知识并减少无关信息。通过对条件机制、去噪配置和生成范式的深入探索，GenHancer优化了生成模型与判别模型（如CLIP）的协同作用，使其在细粒度视觉感知上表现更佳。实验证明，GenHancer在MMVP-VLM基准上显著超越现有技术，可有效提升多模态模型的视觉性能。

> **摘要翻译:** 生成模型和判别模型之间的协同作用日益受到关注。判别式对比语言-图像预训练（CLIP）在高级语义方面表现出色，但在感知细粒度视觉细节方面却力不从心。通常，为了增强表示，生成模型将CLIP的视觉特征作为重建的条件。然而，其潜在原理仍未得到充分探索。在这项工作中，我们凭经验发现，视觉上完美的生成不总是对表示增强最优。其本质在于有效提取生成模型中的细粒度知识，同时减轻无关信息。为了探索关键因素，我们深入研究了三个方面：(1) 条件机制：我们发现，即使少量局部token也能大大降低重建难度，导致训练崩溃。因此，我们得出结论，仅利用全局视觉token作为条件是最有效的策略。(2) 去噪配置：我们观察到端到端训练引入了无关信息。为了解决这个问题，我们提出了一种两阶段训练策略，以优先学习有用的视觉知识。此外，我们证明了轻量级去噪器也能产生显著改进。(3) 生成范式：我们探索了连续和离散去噪器，均取得了理想结果，验证了我们方法的通用性。通过我们的深入探索，我们最终得到了一种有效的方法，即GenHancer，它在MMVP-VLM基准上持续优于现有技术，例如在OpenAICLIP上提升了6.0%。增强后的CLIP可以进一步插入到多模态大型语言模型中，以实现更好的以视觉为中心的性能。所有模型和代码都已公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [289] [ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection](https://arxiv.org/abs/2507.23307)
> *ST-SAM：SAM驱动的半监督伪装目标检测自训练框架*

*Xihang Hu, Fuming Sun, Jiazhe Liu, Feilong Xu, Xiaoli Zhang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 半监督伪装目标检测, 自训练, Segment Anything Model, 伪标签, 单一模型

**Comment:** 10 pages, 6 figures, ACM MM 2025

> **TL;DR:** ST-SAM提出了一种高效的自训练框架，利用SAM生成高质量伪标签，解决了现有半监督伪装目标检测方法的预测偏差和计算开销问题，以极少量标注数据实现了SOTA性能。

**AI_Comments:** ST-SAM的创新之处在于其结合了自训练策略和SAM模型，有效解决了传统半监督伪装目标检测中存在的预测偏差和错误累积问题。通过采用单一网络架构，它显著降低了计算成本并提高了可扩展性。以极少量的标注数据实现SOTA性能，显示了其在实际应用中的巨大潜力，为标注数据稀缺的场景提供了高效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的半监督伪装目标检测(SSCOD)方法（基于Teacher-Student框架）在稀疏监督下存在严重的预测偏差和错误传播问题，并且其多网络架构导致高计算开销和有限的可扩展性。

**Method:** ST-SAM提出了一种高效且简洁的自训练框架。它采用自训练策略，动态过滤和扩展高置信度伪标签，以增强单一模型架构，从而从根本上避免了模型间的预测偏差。此外，通过将伪标签转换为包含领域特定知识的混合提示，ST-SAM有效利用了Segment Anything Model (SAM) 在特定任务中的潜力，以减轻自训练中的错误累积。

**Result:** 在COD基准数据集上的实验表明，ST-SAM仅使用1%的标注数据就达到了最先进的性能，优于现有的SSCOD方法，甚至与全监督方法相媲美。

**Conclusion:** ST-SAM为标注高效的半监督伪装目标检测建立了一种新范式，它仅需训练一个网络，不依赖特定模型或损失函数。

> **ai_Abstract:** 本文提出了ST-SAM，一个用于半监督伪装目标检测（SSCOD）的高效自训练框架。它通过动态过滤和扩展高置信度伪标签来增强单一模型，并利用Segment Anything Model（SAM）将伪标签转换为混合提示，以减轻自训练中的偏差和错误传播。实验证明，ST-SAM在仅使用1%标注数据的情况下，性能超越了现有SSCOD方法，并与全监督方法相当，同时显著降低了计算开销。

> **摘要翻译:** 半监督伪装目标检测（SSCOD）旨在通过利用有限的标注数据和大量的未标注数据来减少对昂贵的像素级标注的依赖。然而，现有基于Teacher-Student框架的SSCOD方法在稀疏监督下存在严重的预测偏差和错误传播，同时其多网络架构带来了高计算开销和有限的可扩展性。为了克服这些限制，我们提出了ST-SAM，一个高度标注高效且简洁的框架，它打破了传统的SSCOD约束。具体来说，ST-SAM采用自训练策略，动态过滤和扩展高置信度伪标签以增强单一模型架构，从而从根本上规避了模型间的预测偏差。此外，通过将伪标签转换为包含领域特定知识的混合提示，ST-SAM有效地利用了Segment Anything Model（SAM）在专业任务中的潜力，以减轻自训练中的错误累积。在COD基准数据集上的实验表明，ST-SAM仅使用1%的标注数据就达到了最先进的性能，优于现有的SSCOD方法，甚至与全监督方法相媲美。值得注意的是，ST-SAM仅需训练一个网络，不依赖特定模型或损失函数。这项工作为标注高效的SSCOD建立了一种新范式。代码将在https://github.com/hu-xh/ST-SAM提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [292] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
> *IGL-Nav: 增量式3D高斯定位用于图像目标导航*

*Wenxuan Guo, Xiuwei Xu, Hang Yin, Ziwei Wang, Jianjiang Feng, Jie Zhou, Jiwen Lu* | **Category: cs.CV, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 图像目标导航, 3D高斯, 增量式定位, 机器人导航, 视觉定位

**Comment:** Accepted to ICCV 2025. Project page:
  https://gwxuan.github.io/IGL-Nav/

> **TL;DR:** IGL-Nav 是一种基于增量式3D高斯表示的图像目标导航框架，解决了传统方法的局限性，并实现了高效准确的3D感知导航。

**AI_Comments:** IGL-Nav 的创新之处在于将增量式3D高斯表示引入图像目标导航，有效解决了传统方法无法充分建模3D几何关系的问题，并克服了直接使用3DGS的计算效率瓶颈。其分阶段的定位策略（粗略几何匹配和精细优化）提升了效率和准确性。该方法在处理自由视角目标和真实世界部署方面的能力也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像目标导航方法依赖端到端强化学习或基于拓扑图/BEV地图的模块化策略，无法充分建模已探索的3D环境与目标图像之间的几何关系，且直接利用3DGS进行图像定位效率低下。

**Method:** 提出IGL-Nav框架。它通过前馈单目预测增量更新场景表示；然后利用几何信息进行离散空间匹配，实现粗略目标定位（等效于高效3D卷积）；当接近目标时，通过可微分渲染优化解决精细目标姿态。

**Result:** IGL-Nav 在各种实验配置下，性能显著优于现有最先进的方法。它还能处理更具挑战性的自由视角图像目标设置，并可部署在真实机器人平台上。

**Conclusion:** IGL-Nav 通过引入增量式3D高斯定位，有效解决了图像目标导航中3D几何关系建模的挑战，实现了高效、准确且鲁棒的导航性能。

> **ai_Abstract:** IGL-Nav 是一种新颖的图像目标导航框架，它解决了传统方法在建模3D环境与目标图像几何关系方面的不足。该方法利用增量式3D高斯表示，通过前馈单目预测更新场景，并结合粗略的几何匹配（3D卷积）和精细的可微分渲染优化，实现了高效且3D感知的目标定位。实验表明，IGL-Nav 在性能上显著超越了现有技术，并支持自由视角目标和真实世界部署。

> **摘要翻译:** 图像作为目标的视觉导航是一个基础且具有挑战性的问题。传统方法要么依赖端到端强化学习，要么采用基于拓扑图或BEV地图作为记忆的模块化策略，这些方法无法充分建模已探索的3D环境与目标图像的几何关系。为了在3D空间中高效准确地定位目标图像，我们基于可渲染的3D高斯（3DGS）表示构建了我们的导航系统。然而，由于3DGS优化的计算强度和6自由度相机姿态的巨大搜索空间，在代理探索过程中直接利用3DGS进行图像定位效率极低。为此，我们提出了IGL-Nav，一个用于高效和3D感知图像目标导航的增量式3D高斯定位框架。具体来说，我们通过前馈单目预测，随着新图像的到来增量更新场景表示。然后，我们利用几何信息进行离散空间匹配，粗略定位目标，这可以等效于高效的3D卷积。当代理接近目标时，我们最终通过可微分渲染优化来解决精细目标姿态。所提出的IGL-Nav在各种实验配置下，性能显著优于现有最先进的方法。它还可以处理更具挑战性的自由视角图像目标设置，并可以使用手机在任意姿态下捕获目标图像，部署到真实世界机器人平台上。项目页面：https://gwxuan.github.io/IGL-Nav/。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [303] [Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection](https://arxiv.org/abs/2507.23461)
> *联邦学习中缓解分辨率漂移：以关键点检测为例*

*Taeheon Lim, Joohyung Lee, Kyungjae Lee, Jungchan Cho* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 联邦学习, 分辨率漂移, 关键点检测, 知识蒸馏, 人体姿态估计

**Comment:** 

> **TL;DR:** 联邦学习在非分类任务（如关键点检测）中存在“分辨率漂移”问题，本文提出RAF方法，通过多分辨率知识蒸馏有效缓解此问题，提高性能并具有通用性。

**AI_Comments:** 本文创新性地识别并解决了联邦学习在非分类任务（特别是高分辨率表示任务）中长期被忽视的“分辨率漂移”问题，扩展了联邦学习的应用范围。通过引入多分辨率知识蒸馏，提供了一种有效且通用的解决方案，对于推动联邦学习在计算机视觉等领域的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在非分类任务（如人体姿态估计）中的应用尚未充分探索。具体而言，由于客户端之间分辨率差异导致性能显著下降的“分辨率漂移”是一个关键问题，它揭示了分辨率作为非独立同分布（non-IID）数据的另一个重要维度。

**Method:** 提出了一种名为“分辨率自适应联邦学习”（RAF）的方法。该方法利用基于热图的知识蒸馏，通过在更高分辨率输出（教师）和更低分辨率输出（学生）之间进行多分辨率知识蒸馏，以增强分辨率鲁棒性，同时避免过拟合。

**Result:** 广泛的实验和理论分析表明，RAF不仅有效缓解了分辨率漂移，实现了显著的性能提升，而且可以无缝集成到现有联邦学习框架中。此外，尽管本文主要关注人体姿态估计，但t-SNE分析揭示了分类任务和高分辨率表示任务之间的显著区别，支持了RAF对其他依赖于保留空间细节的任务的通用性。

**Conclusion:** RAF方法有效解决了联邦学习在非分类任务中面临的分辨率漂移问题，通过多分辨率知识蒸馏显著提升了性能和鲁棒性，并且该方法具有良好的通用性，适用于其他需要保留空间细节的任务。

> **ai_Abstract:** 本文针对联邦学习在人体姿态估计等非分类任务中存在的分辨率漂移问题，提出了一种名为分辨率自适应联邦学习（RAF）的新方法。RAF利用基于热图的多分辨率知识蒸馏，通过教师-学生模型在不同分辨率输出间传递知识，有效增强了模型对分辨率变化的鲁棒性并避免过拟合。实验证明，RAF显著缓解了性能下降，提升了关键点检测的性能，且易于集成。此外，研究还表明RAF对其他需要保留空间细节的高分辨率表示任务具有良好的通用性。

> **摘要翻译:** 联邦学习（FL）方法能够在分布式系统之间实现有效学习，同时保护用户数据隐私。迄今为止，研究主要集中于解决统计异质性和通信效率问题，通过这些努力，FL在分类任务中取得了成功。然而，其在非分类任务（例如人体姿态估计）中的应用仍未得到充分探索。本文识别并研究了一个关键问题，即“分辨率漂移”，其中性能由于客户端之间的分辨率差异而显著下降。与类别级异质性不同，分辨率漂移强调了分辨率作为另一个非独立同分布（non-IID）数据轴的重要性。为了解决这个问题，我们提出了分辨率自适应联邦学习（RAF），这是一种利用基于热图的知识蒸馏的方法。通过在更高分辨率输出（教师）和更低分辨率输出（学生）之间进行多分辨率知识蒸馏，我们的方法在不发生过拟合的情况下增强了分辨率鲁棒性。广泛的实验和理论分析表明，RAF不仅有效缓解了分辨率漂移并实现了显著的性能改进，而且可以无缝集成到现有FL框架中。此外，尽管本文侧重于人体姿态估计，但我们的t-SNE分析揭示了分类任务和高分辨率表示任务之间的显著特征差异，支持了RAF对其他依赖于保留空间细节的任务的通用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [304] [3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection](https://arxiv.org/abs/2507.23567)
> *3D-MOOD：将2D提升到3D用于单目开放集目标检测*

*Yung-Hsu Yang, Luigi Piccinelli, Mattia Segu, Siyuan Li, Rui Huang, Yuqian Fu, Marc Pollefeys, Hermann Blum, Zuria Bauer* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 单目3D目标检测, 开放集检测, 2D到3D提升, 几何先验, 3D-MOOD

**Comment:** ICCV 2025

> **TL;DR:** 本文提出了3D-MOOD，首个端到端单目开放集3D目标检测器，通过将2D检测提升到3D空间并结合几何先验和规范图像空间，解决了现有方法在开放集设置下的局限性，并在多项基准测试中达到最先进水平。

**AI_Comments:** 这项工作具有重要创新性，因为它首次提出了针对单目3D开放集目标检测的端到端解决方案，突破了现有方法在封闭集上的局限。通过巧妙地将2D检测“提升”到3D空间并引入几何先验和规范图像空间，有效提升了模型在未见过场景和新颖物体类别上的泛化能力，对真实世界应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的单目3D目标检测方法局限于封闭集设置，即训练和测试集包含相同的场景和/或对象类别，无法应对真实世界应用中出现的新环境和新颖对象类别的挑战。

**Method:** 提出3D-MOOD，一个端到端3D单目开放集目标检测器。通过设计的3D边界框头部将开放集2D检测提升到3D空间，实现2D和3D任务的端到端联合训练。利用几何先验条件化对象查询，以克服3D估计在不同场景下的泛化问题。设计规范图像空间以实现更高效的跨数据集训练。

**Result:** 在封闭集设置（Omni3D）和开放集设置（Omni3D到Argoverse 2，ScanNet）上评估了3D-MOOD，并取得了新的最先进结果。

**Conclusion:** 3D-MOOD成功解决了单目开放集3D目标检测的挑战，通过创新的2D到3D提升机制、几何先验和规范图像空间设计，实现了在开放集和封闭集设置下的卓越性能，推动了该领域的发展。

> **ai_Abstract:** 本文介绍了3D-MOOD，一个用于单目开放集3D目标检测的首个端到端检测器。针对现有方法在封闭集设置下的局限性，3D-MOOD通过将开放集2D检测提升至3D空间，并结合几何先验和规范图像空间设计，实现了2D和3D任务的联合训练。实验结果表明，该方法在封闭集和开放集设置下均达到了最先进的性能。

> **摘要翻译:** 单目3D目标检测对于机器人和AR/VR等各种应用都很有价值。现有方法仅限于封闭集设置，其中训练和测试集由相同的场景和/或对象类别组成。然而，真实世界的应用通常会引入新的环境和新颖的对象类别，这对这些方法构成了挑战。在本文中，我们解决了开放集设置中的单目3D目标检测问题，并推出了第一个端到端3D单目开放集目标检测器（3D-MOOD）。我们建议通过我们设计的3D边界框头部将开放集2D检测提升到3D空间，从而实现2D和3D任务的端到端联合训练，以产生更好的整体性能。我们用几何先验条件化对象查询，并克服了3D估计在不同场景下的泛化问题。为了进一步提高性能，我们设计了规范图像空间以实现更高效的跨数据集训练。我们在封闭集设置（Omni3D）和开放集设置（Omni3D到Argoverse 2，ScanNet）上评估了3D-MOOD，并取得了新的最先进结果。代码和模型可在royyang0714.github.io/3D-MOOD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [305] [Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention](https://arxiv.org/abs/2507.17745)
> *Ultra3D：基于部分注意力的D高效高保真3D生成*

*Yiwen Chen, Zhihao Li, Yikai Wang, Hu Zhang, Qin Li, Chi Zhang, Guosheng Lin* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 3D生成, 稀疏体素, 注意力机制, 效率, Part Attention

**Comment:** Project Page: https://buaacyw.github.io/ultra3d/

> **TL;DR:** Ultra3D提出了一种高效的3D生成框架，通过引入紧凑的VecSet表示和几何感知的局部注意力机制（Part Attention），显著加速了稀疏体素建模，同时保持了高分辨率和高质量，解决了现有方法计算效率低下的问题。

**AI_Comments:** Ultra3D的创新之处在于其两阶段的优化策略，特别是引入了“Part Attention”机制，通过限制注意力计算范围，巧妙地解决了全局注意力机制带来的二次复杂度问题。这不仅大幅提升了3D生成的速度，还保持了高保真度，对于推动3D内容生成技术走向实际应用具有重要意义。其提出的可扩展部分标注管道也为未来的研究提供了支持。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D生成框架由于两阶段扩散管道中注意力机制的二次复杂度，导致计算效率低下。

**Method:** 我们提出了Ultra3D，一个高效的3D生成框架。第一阶段，利用紧凑的VecSet表示高效生成粗糙的对象布局，减少token数量并加速体素坐标预测。第二阶段，引入Part Attention，一种几何感知的局部注意力机制，将注意力计算限制在语义一致的部分区域内，以细化每个体素的潜在特征。为了支持该机制，我们构建了一个可扩展的部分标注管道，将原始网格转换为部分标记的稀疏体素。

**Result:** Ultra3D在潜在生成方面实现了高达6.7倍的加速，支持1024分辨率的高分辨率3D生成，并在视觉保真度和用户偏好方面均达到最先进的性能。

**Conclusion:** Ultra3D成功地解决了现有3D生成框架的计算效率问题，同时保持了高质量的3D内容生成，实现了高分辨率和最先进的性能。

> **ai_Abstract:** Ultra3D是一个高效的3D生成框架，旨在解决现有稀疏体素表示方法中注意力机制导致的计算效率低下问题。该方法通过两阶段流程实现：首先，利用紧凑的VecSet表示快速生成粗糙对象布局，减少计算负担；其次，引入创新的Part Attention机制，这是一种几何感知的局部注意力，将计算限制在语义部分区域内，从而在保持结构连续性的同时显著加速了潜在特征的细化。Ultra3D还开发了一个部分标注管道来支持该机制。实验证明，Ultra3D在保持高质量和高分辨率（1024）的同时，实现了显著的加速（高达6.7倍），并在视觉保真度和用户偏好方面达到了最先进的性能。

> **摘要翻译:** 稀疏体素表示的最新进展显著提高了3D内容生成的质量，实现了高分辨率建模和精细几何。然而，现有框架由于其两阶段扩散管道中注意力机制的二次复杂度，导致严重的计算效率低下。在这项工作中，我们提出了Ultra3D，一个高效的3D生成框架，在不影响质量的情况下显著加速了稀疏体素建模。我们的方法利用紧凑的VecSet表示在第一阶段高效生成粗糙的对象布局，减少了token数量并加速了体素坐标预测。为了在第二阶段细化每个体素的潜在特征，我们引入了Part Attention，一种几何感知的局部注意力机制，它将注意力计算限制在语义一致的部分区域内。这种设计在保持结构连续性的同时避免了不必要的全局注意力，在潜在生成方面实现了高达6.7倍的加速。为了支持这种机制，我们构建了一个可扩展的部分标注管道，将原始网格转换为部分标记的稀疏体素。广泛的实验表明，Ultra3D支持1024分辨率的高分辨率3D生成，并在视觉保真度和用户偏好方面均达到最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [307] [Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy](https://arxiv.org/abs/2507.21358)
> *协作感知器：通过局部密度感知空间占用提升基于视觉的3D目标检测*

*Jicheng Yuan, Manh Nguyen Duc, Qian Liu, Manfred Hauswirth, Danh Le Phuoc* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D目标检测, 视觉感知, 空间占用, 多任务学习, BEV

**Comment:** The manuscript has been accepted by ICONIP2025

> **TL;DR:** 提出协作感知器（CoP）框架，通过引入空间占用辅助信息和多任务学习，提升基于视觉的3D目标检测性能。

**AI_Comments:** 该论文的创新点在于提出了一个多任务学习框架CoP，通过引入空间占用作为辅助信息来弥补现有视觉BEV 3D目标检测方法忽略环境上下文的不足。通过结合局部密度感知、体素高度引导采样和全局-局部特征融合，CoP能够有效利用两个任务（目标检测和占用预测）的互补知识，生成更丰富和鲁棒的BEV表示，这对于提升自动驾驶中的环境感知能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于视觉的鸟瞰图（BEV）3D目标检测方法在构建BEV表示时，常忽略道路和人行道等内在环境上下文，阻碍了对物理世界特征的全面感知。

**Method:** 提出多任务学习框架协作感知器（CoP），利用空间占用作为辅助信息。该框架包括：1) 生成结合局部密度信息（LDO）的密集占用真值；2) 采用体素高度引导采样（VHS）策略提炼细粒度局部特征；3) 开发全局-局部协作特征融合（CFF）模块，整合两任务间的互补知识。

**Result:** 在nuScenes基准测试中，CoP超越现有基于视觉的框架，在测试集上实现了49.5%的mAP和59.2%的NDS。

**Conclusion:** 通过利用空间占用作为辅助信息和多任务学习，协作感知器（CoP）框架能够有效提升基于视觉的3D目标检测性能，生成更鲁棒的BEV表示。

> **ai_Abstract:** 本文提出了协作感知器（CoP）框架，一个基于多任务学习的视觉3D目标检测方法。针对现有方法忽略环境上下文的问题，CoP利用空间占用作为辅助信息，通过生成局部密度感知的占用真值、体素高度引导的特征采样和全局-局部特征融合模块，有效整合3D目标检测与占用预测任务的知识，从而构建更鲁棒的BEV表示。实验证明CoP在nuScenes基准上取得了优异性能。

> **摘要翻译:** 基于视觉的鸟瞰图（BEV）3D目标检测在自动驾驶领域取得了显著进展，因其成本效益和丰富的上下文信息。然而，现有方法通常通过折叠提取到的目标特征来构建BEV表示，忽略了道路和人行道等内在环境上下文。这阻碍了检测器全面感知物理世界的特征。为了缓解这个问题，我们引入了一个多任务学习框架——协作感知器（CoP），该框架利用空间占用作为辅助信息，挖掘3D目标检测和占用预测任务之间共享的一致结构和概念相似性，弥合空间表示和特征细化方面的差距。为此，我们首先提出一个生成密集占用真值的管道，该管道结合了局部密度信息（LDO），用于重建详细的环境信息。接下来，我们采用体素高度引导采样（VHS）策略，根据不同的目标属性提炼细粒度的局部特征。此外，我们开发了一个全局-局部协作特征融合（CFF）模块，无缝整合两个任务之间的互补知识，从而构成更鲁棒的BEV表示。在nuScenes基准测试上进行的广泛实验表明，CoP优于现有基于视觉的框架，在测试集上实现了49.5%的mAP和59.2%的NDS。代码和补充材料可在该链接获取 https://github.com/jichengyuan/Collaborative-Perceiver。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [316] [Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving](https://arxiv.org/abs/2507.23042)
> *早期目标引导的多尺度融合用于实时视觉-语言驾驶*

*Santosh Patapati, Trisanth Srinivasan* | **Category: cs.CV, cs.AI, cs.LG, cs.MM, cs.RO, I.2.6; I.2.9; I.2.10; C.3.3** | **Updated: 2025-07-30**

**Keywords:** 自动驾驶, 视觉-语言融合, 实时推理, 多尺度融合, NovaDrive

**Comment:** 6 pages

> **TL;DR:** NovaDrive是一个单分支视觉-语言架构，通过早期目标引导的多尺度融合和新型平滑度损失，实现了实时自动驾驶，并在基准测试中显著提升了成功率、路径效率并降低了碰撞率。

**AI_Comments:** NovaDrive的创新之处在于其单分支视觉-语言架构，以及将早期目标引导的多尺度融合与新型平滑度损失相结合，从而在不依赖循环记忆的情况下实现了实时高性能自动驾驶。这不仅提高了自动驾驶系统的反应速度和安全性，还通过优化路径降低了能耗，为自动驾驶堆栈的精简和更新提供了新思路。其在具身AI领域的潜在扩展性也增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆需要在毫秒级时间内对道路几何和交通意图进行推理，以应对复杂情况，但现有系统可能存在反应速度和复杂性问题。

**Method:** 本研究提出了NovaDrive，一个单分支视觉-语言架构，它处理前置摄像头图像、高清地图瓦片、激光雷达深度和文本航点。它采用一个轻量级的两阶段交叉注意力模块，首先对齐航点令牌与高清地图，然后细化图像和深度补丁上的注意力。结合一种新型平滑度损失以避免突然的转向和速度变化，该设计消除了对循环记忆的需求。模型通过微调11B LLaMA-3.2视觉-语言骨干的顶部15层实现实时推理。

**Result:** 在MD-NEX Outdoor基准的nuScenes / Waymo子集上，NovaDrive将成功率提高到84%（+4%），路径效率（SPL）提升到0.66（+0.11），并将碰撞频率从2.6%降低到1.2%（-1.4%），超越了之前的最先进水平。消融实验证实，航点令牌、部分VLM微调和交叉注意力融合对这些增益贡献最大。

**Conclusion:** NovaDrive通过其创新的架构和损失函数，显著提升了自动驾驶的性能，不仅提高了安全性，还通过更短的路线减少了燃料/电池消耗，并具有扩展到其他具身AI领域的潜力。

> **ai_Abstract:** 本论文介绍了NovaDrive，一个用于实时自动驾驶的单分支视觉-语言架构。该系统通过早期目标引导的多尺度融合处理多种传感器输入和文本航点，并采用两阶段交叉注意力机制和新型平滑度损失，有效避免了循环记忆并实现了实时推理。实验结果显示，NovaDrive在关键性能指标上显著超越了现有技术，提升了安全性、效率，并降低了资源消耗，同时具备向其他具身AI领域扩展的潜力。

> **摘要翻译:** 自主车辆必须在毫秒级时间内对道路几何和交通意图进行推理，以应对复杂情况。我们引入了NovaDrive，一个单分支视觉-语言架构，它在单个分支中处理前置摄像头图像、高清地图瓦片、激光雷达深度和文本航点。一个轻量级的两阶段交叉注意力模块首先将航点令牌与高清地图对齐，然后细化对细粒度图像和深度补丁的注意力。结合一种新型的平滑度损失，该损失阻止了突然的转向和速度变化，这种设计消除了对循环记忆的需求。我们微调了11B LLaMA-3.2视觉-语言骨干的顶部15层，实现了实时推理。在MD-NEX Outdoor基准的nuScenes / Waymo子集上，NovaDrive将成功率提高到84%（+4%），将路径效率（SPL）提升到0.66（+0.11），并将碰撞频率从2.6%降低到1.2%（-1.4%），相对于之前的最先进水平。我们的消融实验证实，航点令牌、部分VLM微调和交叉注意力融合对这些增益贡献最大。除了安全性，NovaDrive更短的路线（源于新型平滑度损失）转化为更低的燃料或电池使用量，指向更精简、更容易更新的驾驶堆栈。NovaDrive也可以扩展到其他具身AI领域。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [317] [PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving](https://arxiv.org/abs/2507.23309)
> *PriorFusion：统一整合先验知识以实现自动驾驶中鲁棒的道路感知*

*Xuewei Tang, Mengmeng Yang, Tuopu Wen, Peijin Jia, Le Cui, Mingshang Luo, Kehua Sheng, Bo Zhang, Diange Yang, Kun Jiang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 道路感知, 自动驾驶, 先验知识, 融合, 扩散模型

**Comment:** 

> **TL;DR:** PriorFusion是一个统一框架，通过有效整合语义、几何和生成先验知识来增强道路元素感知，显著提高了复杂环境下的感知准确性。

**AI_Comments:** PriorFusion的创新点在于其统一框架能够有效整合多种类型的先验知识（语义、几何、生成），并通过实例感知注意力机制和数据驱动的形状模板空间来生成高质量的先验锚点。这种方法有望在没有高精地图支持的复杂自动驾驶环境中，显著提高道路感知的准确性和鲁棒性，是解决自动驾驶感知挑战的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 在没有高精地图支持的复杂环境中，自动驾驶车辆需要独立解释周围环境以确保安全和鲁棒的决策。然而，现有方法未能充分利用道路元素中固有的结构化先验知识，导致预测不规则、不准确。

**Method:** 我们提出了PriorFusion，一个统一的框架，有效整合语义、几何和生成先验知识来增强道路元素感知。我们引入了一个由形状先验特征引导的实例感知注意力机制，然后构建了一个数据驱动的形状模板空间，编码道路元素的低维表示，从而通过聚类生成锚点作为参考先验。我们设计了一个基于扩散的框架，利用这些先验锚点生成准确和完整的预测。

**Result:** 在大型自动驾驶数据集上的实验表明，我们的方法显著提高了感知准确性，特别是在具有挑战性的条件下。可视化结果进一步证实，我们的方法产生了更准确、更规则、更连贯的道路元素预测。

**Conclusion:** PriorFusion通过有效整合多种先验知识，显著提升了自动驾驶中道路元素的感知准确性和鲁棒性，尤其在复杂和无高精地图支持的环境下表现出色。

> **ai_Abstract:** 本文提出了PriorFusion，一个创新的统一框架，旨在通过整合语义、几何和生成先验知识，显著提升自动驾驶中道路元素的感知准确性和鲁棒性。针对现有方法在复杂环境下因未能充分利用结构化先验而导致预测不准确的问题，PriorFusion引入了实例感知注意力机制和数据驱动的形状模板空间来生成参考先验锚点，并结合基于扩散的框架进行精确预测。实验证明，该方法在挑战性条件下表现卓越，能够生成更准确、规则和连贯的道路元素预测。

> **摘要翻译:** 随着对自动驾驶兴趣的增长，对准确可靠的道路感知技术的需求也日益增加。在没有高精地图支持的复杂环境中，自动驾驶车辆必须独立解释周围环境以确保安全和鲁棒的决策。然而，由于道路元素数量多、几何形状复杂和频繁遮挡，这些场景带来了巨大挑战。现有方法的一个关键局限在于它们未能充分利用道路元素中固有的结构化先验知识，导致不规则、不准确的预测。为了解决这个问题，我们提出了PriorFusion，一个统一的框架，有效整合语义、几何和生成先验知识以增强道路元素感知。我们引入了一个由形状先验特征引导的实例感知注意力机制，然后构建了一个数据驱动的形状模板空间，编码道路元素的低维表示，从而通过聚类生成锚点作为参考先验。我们设计了一个基于扩散的框架，利用这些先验锚点生成准确和完整的预测。在大型自动驾驶数据集上的实验表明，我们的方法显著提高了感知准确性，特别是在具有挑战性的条件下。可视化结果进一步证实，我们的方法产生了更准确、更规则、更连贯的道路元素预测。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [320] [One Look is Enough: Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation on High-Resolution Images](https://arxiv.org/abs/2503.22351)
> *一眼即得：高分辨率图像零样本单目深度估计的无缝分块细化*

*Byeongjun Kwon, Munchurl Kim* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 零样本, 深度估计, 高分辨率, 分块细化, 泛化

**Comment:** ICCV 2025 (camera-ready version). [Project
  page](https://kaist-viclab.github.io/One-Look-is-Enough_site)

> **TL;DR:** 本文提出Patch Refine Once (PRO) 框架，通过分组分块一致性训练和无偏掩码，解决了高分辨率图像零样本深度估计中存在的深度不连续性、效率低下和泛化性差的问题。

**AI_Comments:** 这篇论文为零样本深度估计，特别是针对高分辨率图像的挑战提供了一个实用的解决方案。其“分组分块一致性训练”在解决基于分块的不连续性方面具有创新性，而“无偏掩码”则解决了关键的泛化性问题。它能够无缝集成到现有模型中，这使得它具有高度的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本深度估计模型在处理高分辨率图像时表现不佳，原因在于训练和推理图像分辨率存在差异，导致估计精度下降或边缘模糊。流行的分块方法会引入深度不连续性并导致测试效率低下。此外，这些方法依赖合成数据集，导致泛化性差。

**Method:** 本文提出Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。PRO包含两个关键组件：(i) 分组分块一致性训练：通过联合处理四个重叠分块并在一个反向传播步骤中对它们的重叠区域强制执行一致性损失，从而提高测试效率并减轻深度不连续性问题。(ii) 无偏掩码：防止深度估计模型过拟合于特定数据集的偏差，即使在合成数据训练后也能更好地泛化到真实世界数据集。

**Result:** 在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，PRO可以无缝集成到现有深度估计模型中。

**Conclusion:** PRO框架通过其创新的分组分块一致性训练和无偏掩码组件，有效解决了高分辨率图像零样本单目深度估计中的深度不连续性和泛化性差的局限性，提供了一个高效且可泛化的解决方案。

> **ai_Abstract:** 本文提出了一种名为Patch Refine Once (PRO) 的新型基于瓦片的框架，旨在解决高分辨率图像上零样本单目深度估计的挑战。现有方法存在分辨率不匹配导致的精度问题、分块重组引起的深度不连续性以及依赖合成数据导致的泛化性差。PRO框架通过“分组分块一致性训练”来减轻不连续性并提高效率，并通过“无偏掩码”来增强对真实世界数据的泛化能力。实验结果表明，PRO可以无缝集成到现有深度估计模型中。

> **摘要翻译:** 零样本深度估计（DE）模型由于在大规模数据集上训练而表现出强大的泛化性能。然而，现有模型在处理高分辨率图像时遇到困难，原因在于训练（分辨率较低）和推理（分辨率较高）的图像分辨率存在差异。以全分辨率处理会导致深度估计精度下降，同时消耗大量内存，而下采样到训练分辨率则会导致估计深度图像中边缘模糊。流行的分块深度估计方法采用基于分块的方法，这在重新组装估计的深度分块时引入了深度不连续性问题，导致测试时效率低下。此外，为了获得细粒度的深度细节，这些方法由于真实世界稀疏的地面真值深度而依赖于合成数据集，导致泛化性差。为了解决这些限制，我们提出了Patch Refine Once (PRO)，一个高效且可泛化的基于瓦片的框架。我们的PRO包含两个关键组件：(i) 分组分块一致性训练，通过联合处理四个重叠分块并在单个反向传播步骤中对它们的重叠区域强制执行一致性损失，从而提高测试时效率并减轻深度不连续性问题；以及(ii) 无偏掩码，防止DE模型过拟合于特定数据集的偏差，即使在合成数据训练后也能更好地泛化到真实世界数据集。在Booster、ETH3D、Middlebury 2014和NuScenes上的零样本评估表明，我们的PRO可以无缝集成到现有深度估计模型中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Learn2Synth: Learning Optimal Data Synthesis Using Hypergradients for Brain Image Segmentation](https://arxiv.org/abs/2411.16719)
> *Learn2Synth：使用超梯度学习最优数据合成用于脑图像分割*

*Xiaoling Hu, Xiangrui Zeng, Oula Puonti, Juan Eugenio Iglesias, Bruce Fischl, Yael Balbastre* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 数据合成, 脑图像分割, 域随机化, 超梯度, 深度学习

**Comment:** 16 pages, 5 figures. Accepted by ICCV'25

> **TL;DR:** Learn2Synth提出了一种利用少量真实标注数据自动学习最优数据合成参数的方法，以训练用于脑图像分割的网络，从而提高泛化能力并避免手动调优和直接使用真实数据训练带来的偏差。

**AI_Comments:** 该论文提出了一种优化数据合成的创新方法，解决了域随机化中的一个常见挑战。它的优势在于通过优化真实数据上的下游任务性能来间接学习合成参数，这是一种利用有限的真实标注数据而不引入偏差的巧妙方式。这可能显著减少为各种医学影像任务准备多样化训练数据的工作量。

<details>
  <summary>Details</summary>

**Motivation:** 虽然通过合成进行域随机化是训练无偏网络以提高泛化能力的一种强大策略，但它依赖于对大量控制合成图像概率分布的超参数的精确调整。手动调整这些参数非常困难且耗时。

**Method:** 本文引入了Learn2Synth，这是一种新颖的程序，利用少量真实标注数据学习合成参数。与通过约束来对齐合成数据和真实数据（如对比或对抗技术）的方法不同，Learn2Synth通过调整增强引擎，使得在合成数据上训练的分割网络在应用于真实数据时具有最佳准确性。这种方法允许训练过程从真实标注示例中受益，而无需使用这些真实示例来直接训练分割网络，从而避免了网络偏向于训练集的特性。具体而言，该方法开发了参数化和非参数化策略来增强合成图像，以提高分割网络的性能。

**Result:** 该学习策略在合成和真实世界的脑部扫描上均表现出有效性。

**Conclusion:** Learn2Synth提供了一种有效的方法来自动学习脑图像分割的最佳数据合成参数，从而提高了泛化能力，并避免了直接使用真实数据进行网络训练所带来的偏差。

> **ai_Abstract:** Learn2Synth提出了一种新颖的方法，用于自动学习训练鲁棒分割网络的最佳数据合成参数。该方法不依赖手动调优或直接的合成-真实数据对齐，而是利用少量真实标注数据来优化增强引擎。这确保了仅在合成数据上训练的分割网络在真实世界脑部扫描上也能达到高精度，从而有效提高了泛化能力并避免了数据集偏差。

> **摘要翻译:** 通过合成进行域随机化是一种强大的策略，可以训练对输入图像域无偏的网络。随机化允许网络在训练期间看到几乎无限范围的强度和伪影，从而最大限度地减少对外观的过拟合，并最大限度地提高对未见数据的泛化能力。尽管功能强大，但这种方法依赖于大量控制合成图像概率分布的超参数的精确调整。我们没有手动调整这些参数，而是引入了Learn2Synth，这是一种新颖的程序，其中使用少量真实标注数据来学习合成参数。与通过施加约束来对齐合成数据和真实数据（例如，对比或对抗技术）的方法不同，后者有使图像及其标签图错位的风险，我们调整了一个增强引擎，使得在合成数据上训练的分割网络在应用于真实数据时具有最佳准确性。这种方法允许训练过程从真实标注示例中受益，而无需使用这些真实示例来训练分割网络，从而避免了网络偏向于训练集的特性。具体而言，我们开发了参数化和非参数化策略来增强合成图像，以提高分割网络的性能。我们证明了这种学习策略在合成和真实世界脑部扫描上的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [343] [TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs](https://arxiv.org/abs/2507.21584)
> *TARS：用于减少多模态大语言模型幻觉的最小-最大令牌自适应偏好策略*

*Kejia Zhang, Keda Tao, Zhiming Luo, Chang Liu, Jiasheng Tang, Huan Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多模态大语言模型, 幻觉减少, 令牌自适应策略, 最小-最大优化, 直接偏好优化

**Comment:** 

> **TL;DR:** TARS是一种新的令牌自适应偏好策略，通过最小-最大优化减少多模态大语言模型中的幻觉，性能优于DPO并媲美GPT-4o。

**AI_Comments:** TARS的创新之处在于将传统的DPO重构为最小-最大优化问题，引入了令牌自适应的偏好策略，有效解决了现有DPO在处理幻觉时容易过拟合语言线索、损害视觉接地的问题。这种方法通过模拟对齐不确定性，使得模型能够更好地关注因果相关的视觉信息，而非表面的语言模式。其在少量偏好样本下就能取得显著效果，并超越传统DPO，甚至媲美GPT-4o的性能，显示了其在提高MLLMs可靠性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在视觉-语言推理中存在生成事实不正确或视觉上无根据的幻觉问题，影响其可靠性。现有直接偏好优化（DPO）策略将幻觉相关偏好视为固定目标，导致过拟合语言线索，损害与视觉信息的因果关联。

**Method:** 本文提出TARS，一种令牌自适应偏好策略，它将直接偏好优化（DPO）重新表述为最小-最大优化问题。TARS在语义约束下最大化令牌级别的分布偏移以模拟对齐不确定性，同时最小化这些受控扰动下的预期偏好损失。这种联合目标旨在减轻对偏好模式的过拟合，同时保持因果接地，从而减少多模态推理中的幻觉。

**Result:** 在多个幻觉基准测试上表现出色。仅使用4.8k偏好样本且无专家反馈，TARS将幻觉率从26.4%降低到13.2%，并将认知值从2.5降低到0.4。其性能优于标准DPO，并在多项关键指标上与GPT-4o持平。

**Conclusion:** TARS通过其创新的最小-最大令牌自适应偏好策略，有效解决了多模态大语言模型中的幻觉问题，显著提高了模型的可靠性和因果接地能力，且无需大量专家反馈。

> **ai_Abstract:** 本文提出TARS，一种用于减少多模态大语言模型（MLLMs）幻觉的令牌自适应偏好策略。针对现有直接偏好优化（DPO）在处理幻觉时过拟合语言线索的问题，TARS将DPO重构为最小-最大优化问题，通过在语义约束下最大化令牌级分布偏移并最小化预期偏好损失，以保持因果接地并减轻过拟合。实验结果表明，TARS在多个幻觉基准测试上表现出色，显著降低幻觉率并提高认知值，且性能优于标准DPO并与GPT-4o媲美。

> **摘要翻译:** 多模态大语言模型（MLLMs）实现了视觉-语言推理，但通常会生成看似合理但事实不正确或视觉上无根据的输出，从而损害其可靠性。直接偏好优化（DPO）是一种通过将模型输出与人类偏好对齐来纠正幻觉的常用策略。现有的DPO策略通常将与幻觉相关的偏好视为固定目标，在训练期间依赖静态监督信号。这种方法倾向于过度拟合偏好数据中表面的语言线索，导致分布刚性和虚假关联，从而损害与因果相关视觉信息的接地。为了克服这一限制，我们提出了TARS，一种令牌自适应偏好策略，它将DPO重新表述为一个最小-最大优化问题。TARS在语义约束下最大化令牌级别的分布偏移以模拟对齐不确定性，并同时最小化这些受控扰动下的预期偏好损失。这种联合目标在减轻对偏好模式的过拟合的同时保持因果接地，从而减少多模态推理中的幻觉。我们在多个幻觉基准测试上评估了TARS，并发现其性能始终强劲。仅使用4.8k偏好样本且无需专家反馈，TARS将幻觉率从26.4%降低到13.2%，并将认知值从2.5降低到0.4。它优于标准DPO，并在多项关键指标上与GPT-4o持平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [345] [Forgetting of task-specific knowledge in model merging-based continual learning](https://arxiv.org/abs/2507.23311)
> *基于模型合并的持续学习中任务特定知识的遗忘*

*Timm Hess, Gido M van de Ven, Tinne Tuytelaars* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 模型合并, 持续学习, 知识遗忘, 任务特定知识, 增量训练

**Comment:** 

> **TL;DR:** 模型合并在持续学习中能保留共享知识但遗忘任务特定知识；增量训练的模型合并效果优于并行训练。

**AI_Comments:** 该研究揭示了模型合并在持续学习中对不同类型知识（共享与任务特定）的影响，并提出了增量训练在模型合并中的优势，对持续学习中的知识遗忘问题提供了新的视角和实用建议。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探究模型线性合并在持续学习中对知识保留和遗忘的影响，特别是任务特定知识的遗忘情况。

**Method:** 通过在计算机视觉实验中使用受控的视觉线索来演示模型合并的效果，并比较了增量训练和并行训练的模型合并性能。

**Result:** 模型合并在很大程度上保留或增强了共享知识，而未共享的任务特定知识则迅速退化。合并来自增量训练过程的模型始终优于合并并行训练的模型。

**Conclusion:** 模型合并在持续学习中会造成任务特定知识的遗忘，但对共享知识有益。增量训练的模型更适合进行合并。

> **ai_Abstract:** 该论文探讨了持续学习中模型线性合并对知识的影响。研究表明，合并能有效保留或增强共享知识，但会导致任务特定知识的快速遗忘。此外，增量训练的模型合并效果优于并行训练的模型合并。

> **摘要翻译:** 本文研究了持续学习（CL）背景下模型的线性合并。通过在计算机视觉实验中使用受控的视觉线索，我们证明了合并在很大程度上保留或增强了共享知识，而未共享的任务特定知识则迅速退化。我们进一步发现，合并来自增量训练过程的模型始终优于合并并行训练的模型。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [353] [Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization](https://arxiv.org/abs/2507.23569)
> *高斯泼溅特征场用于隐私保护的视觉定位*

*Maxime Pietrantoni, Gabriela Csurka, Torsten Sattler* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视觉定位, 高斯泼溅, 特征场, 隐私保护, 场景表示

**Comment:** CVPR 2025

> **TL;DR:** 本文提出高斯泼溅特征场（GSFFs），结合3DGS和隐式特征场，实现准确且隐私保护的视觉定位，在多个真实世界数据集上达到SOTA性能。

**AI_Comments:** 该论文的创新点在于将3D高斯泼溅（3DGS）的显式几何优势与隐式特征场相结合，创建了一种新颖的场景表示（GSFFs）。通过引入3D结构引导的聚类并将特征转换为分割，它有效地解决了视觉定位中隐私保护的关键挑战。这项工作的重要性体现在其在保持定位精度的同时，提供了隐私友好的解决方案，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 视觉定位是估计相机在已知环境中的姿态的任务，需要一种能够同时实现准确性和隐私保护的表示方法。

**Method:** 本文提出了高斯泼溅特征场（GSFFs），一种结合了3D高斯泼溅（3DGS）的显式几何模型和隐式特征场的场景表示。它利用3DGS的密集几何信息和可微分光栅化算法来学习鲁棒的3D特征表示。通过对比学习框架将3D尺度感知特征场与2D特征编码器在共同嵌入空间中对齐。此外，使用3D结构引导的聚类过程来正则化表示学习，并将特征转换为分割，以实现隐私保护的视觉定位。定位通过将查询图像的特征图或分割与从GSFFs渲染的特征图或分割进行对齐（姿态优化）来完成。

**Result:** 在多个真实世界数据集上进行评估，所提出的隐私保护和非隐私保护的定位流程均达到了最先进（state-of-the-art）的性能。

**Conclusion:** 本文提出的高斯泼溅特征场（GSFFs）能够实现准确且隐私保护的视觉定位，并在多个真实世界数据集上表现出最先进的性能。

> **ai_Abstract:** 本文提出高斯泼溅特征场（GSFFs），一种结合3D高斯泼溅（3DGS）几何模型和隐式特征场的场景表示，用于实现准确且隐私保护的视觉定位。GSFFs利用3DGS的优势学习鲁棒的3D特征，并通过对比学习和3D结构引导的聚类进行优化。该方法能将特征转换为分割以实现隐私保护。在多个真实世界数据集上的实验证明，该方法在隐私和非隐私保护的视觉定位任务上均达到了最先进的性能。

> **摘要翻译:** 视觉定位是估计相机在已知环境中的姿态的任务。在本文中，我们利用基于3D高斯泼溅（3DGS）的表示来实现准确且隐私保护的视觉定位。我们提出了高斯泼溅特征场（GSFFs），这是一种结合了显式几何模型（3DGS）和隐式特征场的场景表示，用于视觉定位。我们利用3DGS的密集几何信息和可微分光栅化算法来学习扎根于3D的鲁棒特征表示。特别是，我们通过对比框架将3D尺度感知特征场和2D特征编码器对齐在一个共同的嵌入空间中。利用3D结构引导的聚类过程，我们进一步正则化表示学习，并将特征无缝转换为分割，这些分割可用于隐私保护的视觉定位。姿态优化涉及将查询图像的特征图或分割与从GSFFs场景表示中渲染的特征图或分割对齐，以实现定位。在多个真实世界数据集上评估的结果表明，所得到的隐私保护和非隐私保护定位流程均达到了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [355] [Balancing Task-invariant Interaction and Task-specific Adaptation for Unified Image Fusion](https://arxiv.org/abs/2504.05164)
> *统一图像融合中任务不变交互与任务特定适应的平衡*

*Xingyu Hu, Junjun Jiang, Chenyang Wang, Kui Jiang, Xianming Liu, Jiayi Ma* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 图像融合, 统一框架, 任务不变交互, 任务特定适应, 泛化能力

**Comment:** Accepted by ICCV 2025

> **TL;DR:** TITA是一种新的统一图像融合框架，通过平衡任务不变交互和任务特定适应，在保持竞争性性能的同时，显著提升了对未知融合任务的泛化能力。

**AI_Comments:** 该论文的创新点在于提出了一个动态平衡任务不变交互和任务特定适应的统一图像融合框架TITA，有效解决了现有方法在泛化性和性能之间的权衡问题。特别是通过避免推理时的显式任务识别，提升了模型对未知任务的泛化能力，这对于实际应用具有重要意义。IPA和OAF模块的设计也体现了对图像融合过程深层次的理解和优化。

<details>
  <summary>Details</summary>

**Motivation:** 现有统一图像融合方法在促进任务不变知识共享的同时，常忽略任务特定特性，限制了整体性能。显式任务识别虽能适应不同任务，但在推理时对任务的依赖限制了模型对未知融合任务的泛化能力。

**Method:** 本文提出了一种名为“TITA”的统一图像融合框架，它动态平衡任务不变交互和任务特定适应。通过引入交互增强像素注意力（IPA）模块用于任务不变交互以提取互补信息，以及基于操作的自适应融合（OAF）模块动态调整操作权重以适应任务特性。此外，还结合了快速自适应多任务优化（FAMO）策略来缓解联合训练中任务间的梯度冲突。

**Result:** TITA不仅在三种图像融合场景中与专业方法相比取得了竞争性性能，而且对未知融合任务表现出强大的泛化能力。

**Conclusion:** TITA框架通过动态平衡任务不变交互和任务特定适应，有效解决了现有统一图像融合方法的局限性，实现了高性能和强大的泛化能力。

> **ai_Abstract:** 本文提出了一种名为“TITA”的新型统一图像融合框架，旨在解决现有方法在处理多样化融合任务时，对任务特定特性关注不足及对未知任务泛化能力受限的问题。TITA通过引入交互增强像素注意力（IPA）模块实现任务不变交互，有效提取多源互补信息；同时，利用基于操作的自适应融合（OAF）模块根据任务属性动态调整权重，实现任务特定适应。此外，结合快速自适应多任务优化（FAMO）策略，缓解了多任务训练中的梯度冲突。实验证明，TITA在多种图像融合场景中表现出竞争性性能，并对未知融合任务具有强大的泛化能力。

> **摘要翻译:** 统一图像融合旨在整合多源图像的互补信息，通过一个适用于多种融合任务的统一框架来提升图像质量。尽管将所有融合任务视为一个统一问题有助于任务不变知识共享，但它往往忽视任务特定的特性，从而限制了整体性能。现有的通用图像融合方法通过引入显式任务识别来实现对不同融合任务的适应。然而，这种在推理时的依赖性限制了模型对未知融合任务的泛化能力。为了解决这些问题，我们提出了一种名为“TITA”的新型统一图像融合框架，它动态平衡了任务不变交互和任务特定适应。对于任务不变交互，我们引入了交互增强像素注意力（IPA）模块，以增强像素级交互，从而更好地提取多源互补信息。对于任务特定适应，基于操作的自适应融合（OAF）模块根据任务属性动态调整操作权重。此外，我们还结合了快速自适应多任务优化（FAMO）策略，以减轻联合训练期间任务间梯度冲突的影响。广泛的实验表明，TITA不仅在三种图像融合场景中与专业方法相比取得了竞争性性能，而且对未知融合任务表现出强大的泛化能力。源代码已在https://github.com/huxingyuabc/TITA发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [358] [Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation](https://arxiv.org/abs/2507.23058)
> *参考引导扩散修复用于多模态反事实生成*

*Alexandru Buburuzan* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 扩散修复, 多模态, 反事实生成, 合成数据, 自动驾驶, 医学图像分析

**Comment:** A dissertation submitted to The University of Manchester for the
  degree of Bachelor of Science in Artificial Intelligence

> **TL;DR:** 本文提出了MObI和AnydoorMed两种新方法，利用参考引导扩散修复技术，在自动驾驶和医学图像分析中生成逼真且可控的多模态合成数据，以应对真实数据采集的挑战。

**AI_Comments:** 本文创新性地将参考引导扩散修复技术应用于多模态合成数据生成，尤其是在自动驾驶和医学影像两大关键领域。MObI是首个实现多模态（相机与激光雷达）物体修复的框架，其利用3D边界框进行精确空间定位和缩放，显著提升了合成数据的真实性和可控性。AnydoorMed则展示了该技术在医学异常修复中的潜力。这项工作的重要性在于，它为创建高度逼真、可控的多模态反事实场景提供了有效途径，这对于需要大量测试数据的安全关键应用至关重要，有望推动下一代合成数据系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 安全关键应用（如自动驾驶和医学图像分析）需要大量的多模态数据进行严格测试。由于收集真实世界数据的成本和复杂性，合成数据方法日益受到关注，但它们需要高度的真实性和可控性才能发挥作用。

**Method:** 本文介绍了两种新颖的合成数据生成方法：MObI和AnydoorMed。MObI是一个多模态物体修复框架，利用扩散模型在相机和激光雷达等感知模态上生成逼真和可控的物体修复，通过单个参考RGB图像和3D边界框指导，实现无缝物体插入。AnydoorMed将该范式扩展到医学成像领域，专注于乳腺X线摄影扫描的参考引导修复，利用基于扩散的模型修复异常，保持参考异常的结构完整性并与周围组织语义融合。

**Result:** MObI能够在指定3D位置将物体无缝插入现有多模态场景中，同时保持语义一致性和多模态连贯性，并利用3D边界框条件确保精确的空间定位和逼真的缩放。AnydoorMed能够以令人印象深刻的细节保留来修复异常，同时保持参考异常的结构完整性并与周围组织语义融合。

**Conclusion:** 这些方法共同证明了自然图像中用于参考引导修复的基础模型可以很容易地适应不同的感知模态，为构建高度逼真、可控和多模态反事实场景的下一代系统铺平了道路。

> **ai_Abstract:** 本文针对安全关键应用中合成数据对真实性和可控性的需求，提出了MObI和AnydoorMed两种基于参考引导扩散修复的新方法。MObI专注于自动驾驶领域的多模态物体修复，通过3D边界框指导实现跨相机和激光雷达的无缝物体插入。AnydoorMed则将此范式应用于医学图像（如乳腺X线摄影）的异常修复。这两种方法共同证明了参考引导修复的基础模型能够适应不同感知模态，为生成逼真、可控的多模态反事实场景奠定基础。

> **摘要翻译:** 安全关键应用，如自动驾驶和医学图像分析，需要大量的多模态数据进行严格测试。由于收集真实世界数据的成本和复杂性，合成数据方法日益受到关注，但它们需要高度的真实性和可控性才能发挥作用。这项工作介绍了两种用于自动驾驶和医学图像分析的合成数据生成新方法，即MObI和AnydoorMed。MObI是首个多模态物体修复框架，它利用扩散模型在感知模态上生成逼真且可控的物体修复，同时在相机和激光雷达上进行了演示。给定单个参考RGB图像，MObI能够在指定的3D位置将物体无缝插入现有多模态场景中，由边界框引导，同时保持语义一致性和多模态连贯性。与仅依赖编辑掩码的传统修复方法不同，这种方法使用3D边界框条件来确保精确的空间定位和逼真的缩放。AnydoorMed将这一范式扩展到医学成像领域，专注于乳腺X线摄影扫描的参考引导修复。它利用基于扩散的模型以令人印象深刻的细节保留来修复异常，同时保持参考异常的结构完整性并与周围组织语义融合。总的来说，这些方法表明，自然图像中用于参考引导修复的基础模型可以很容易地适应不同的感知模态，为构建高度逼真、可控和多模态反事实场景的下一代系统铺平了道路。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Color as the Impetus: Transforming Few-Shot Learner](https://arxiv.org/abs/2507.22136)
> *颜色作为动力：变革少样本学习器*

*Chaofei Qi, Zhitai Liu, Jianbin Qiu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 少样本学习, 颜色感知, 元学习, 知识蒸馏, 特征提取

**Comment:** 

> **TL;DR:** 本文提出ColorSense Learner和ColorSense Distiller，模拟人类颜色感知机制，通过颜色通道交互和知识蒸馏，显著提升了少样本学习的泛化能力、鲁棒性和可迁移性。

**AI_Comments:** 本文创新性地将人类的颜色感知机制引入到少样本学习中，提出ColorSense Learner框架，通过强调颜色信息来提高特征的判别性。同时，结合知识蒸馏引入ColorSense Distiller，进一步增强了模型的元学习能力。这一生物启发视角为少样本学习提供了一个新颖且有效的解决方案，突破了传统方法仅关注抽象特征的局限，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的元学习方法忽视了颜色信息这一最直观的视觉特征，而人类卓越的颜色感知能力在元学习中发挥着重要作用。

**Method:** 本文提出了ColorSense Learner，一个受生物启发的元学习框架，利用通道间特征提取和交互式学习，战略性地强调不同颜色信息以过滤无关特征并捕捉判别性特征。此外，还引入了基于知识蒸馏的元蒸馏器ColorSense Distiller，通过整合教师先验知识来增强学生网络的元学习能力。

**Result:** 在11个少样本基准测试上进行的粗/细粒度和跨域实验表明，所提出的方法具有极强的泛化能力、鲁棒性和可迁移性，能够轻松地从颜色感知的角度处理少样本分类。

**Conclusion:** 本文通过协同的颜色通道交互，弥补了传统方法在颜色信息利用上的不足，从而更好地提取类内共性并区分类间差异，并通过知识蒸馏进一步增强了模型的元学习能力。

> **ai_Abstract:** 本文提出ColorSense Learner，一个受人类颜色感知启发的少样本元学习框架。该框架利用通道间颜色特征提取和交互式学习，以更好地提取类内共性并区分类间差异。为进一步提升性能，引入了ColorSense Distiller，一个基于知识蒸馏的元蒸馏器。在多项少样本基准测试上的实验证明，该方法在泛化能力、鲁棒性和可迁移性方面表现出色，有效利用颜色信息解决了少样本分类问题。

> **摘要翻译:** 人类天生具备元学习能力，部分归因于其卓越的颜色感知。在本文中，我们通过模拟人类颜色感知机制，开创性地提出了少样本学习的新视角。我们提出了ColorSense Learner，一个受生物启发的元学习框架，它利用通道间特征提取和交互式学习。通过策略性地强调不同通道的独特颜色信息，我们的方法有效地过滤了无关特征，同时捕获了判别性特征。颜色信息代表着最直观的视觉特征，然而传统的元学习方法却主要忽视了这一方面，反而专注于跨类别的抽象特征区分。我们的框架通过协同的颜色通道交互弥补了这一空白，从而能够更好地提取类内共性并区分更大的类间差异。此外，我们引入了一个基于知识蒸馏的元蒸馏器ColorSense Distiller，它整合了教师先验知识以增强学生网络的元学习能力。我们已经在11个少样本基准测试上进行了全面的粗/细粒度和跨域实验以进行验证。大量实验表明，我们的方法具有极强的泛化能力、鲁棒性和可迁移性，并且能够轻松地从颜色感知的角度处理少样本分类。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [368] [PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction](https://arxiv.org/abs/2507.19119)
> *PatchTraj：通过动态补丁实现统一时频表示学习的轨迹预测*

*Yanghong Liu, Xingping Dong, Ming Li, Weixing Zhang, Yidong Lou* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 轨迹预测, 时频表示学习, 动态补丁, 跨模态注意力, Transformer

**Comment:** 

> **TL;DR:** PatchTraj提出了一种动态补丁的时频联合建模框架，通过分解轨迹、多尺度分割、自适应嵌入和跨模态注意力，解决了现有轨迹预测方法在建模运动动态和时频交互方面的不足，并在多个数据集上取得了最先进的性能。

**AI_Comments:** PatchTraj的创新点在于其统一的时频表示学习方法，通过动态补丁有效结合了时间序列和频率分量，弥补了现有方法在平衡局部细节和长程依赖以及时频交互方面的不足。其在多个数据集上取得的最先进性能，特别是显著提升了在具身智能场景下的预测精度，凸显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于点和基于网格的轨迹预测方法存在两个主要局限性：一是未能充分建模人类运动动态，难以平衡局部运动细节与长程时空依赖；二是时间表示缺乏与频率分量的交互，无法联合建模轨迹序列。

**Method:** 本文提出了PatchTraj，一个基于动态补丁的框架，用于集成时频联合建模的轨迹预测。具体而言，它将轨迹分解为原始时间序列和频率分量，并采用动态补丁划分进行多尺度分割，以捕获分层运动模式。每个补丁都经过自适应嵌入和尺度感知特征提取，然后进行分层特征聚合，以建模细粒度和长程依赖。两个分支的输出通过跨模态注意力进一步增强，促进时间信息和频谱线索的互补融合。

**Result:** 在ETH-UCY、SDD、NBA和JRDB数据集上进行了广泛实验，结果表明PatchTraj实现了最先进的性能。尤其是在以自我为中心的JRDB数据集上，PatchTraj在ADE（平均位移误差）上取得了26.7%的显著相对改进，在FDE（最终位移误差）上取得了17.4%的显著相对改进。

**Conclusion:** PatchTraj通过其统一的时频表示学习框架，有效解决了轨迹预测中建模运动动态和时频交互的挑战，并在多个基准数据集上取得了优异的性能，展现了在具身智能方面的巨大潜力。

> **ai_Abstract:** PatchTraj提出了一种新颖的动态补丁框架，通过统一的时频表示学习来解决轨迹预测中的关键挑战。该方法通过将轨迹分解为时间序列和频率分量，并利用动态补丁划分、多尺度分割、自适应嵌入和跨模态注意力机制，有效捕获了细粒度和长程依赖。实验证明，PatchTraj在多个数据集上均达到了最先进的性能，特别是在JRDB数据集上取得了显著的ADE和FDE改进，展现了其在具身智能领域的强大潜力。

> **摘要翻译:** 行人轨迹预测对于自动驾驶和机器人技术至关重要。然而，现有的基于点和基于网格的方法存在两个主要局限性：未能充分建模人类运动动态，因为它们未能平衡局部运动细节与长程时空依赖；以及时间表示缺乏与频率分量的交互，无法联合建模轨迹序列。为了应对这些挑战，我们提出了PatchTraj，一个基于动态补丁的框架，它集成了时频联合建模以进行轨迹预测。具体而言，我们将轨迹分解为原始时间序列和频率分量，并采用动态补丁划分来执行多尺度分割，捕获分层运动模式。每个补丁都经过自适应嵌入与尺度感知特征提取，然后进行分层特征聚合，以建模细粒度和长程依赖。两个分支的输出通过跨模态注意力进一步增强，促进时间信息和频谱线索的互补融合。由此产生的增强嵌入表现出强大的表达能力，即使使用香草Transformer架构也能实现准确预测。在ETH-UCY、SDD、NBA和JRDB数据集上进行的广泛实验表明，我们的方法取得了最先进的性能。值得注意的是，在以自我为中心的JRDB数据集上，PatchTraj在ADE上取得了26.7%的显著相对改进，在FDE上取得了17.4%的显著相对改进，突显了其在具身智能方面的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [373] [The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models](https://arxiv.org/abs/2507.23313)
> *伦勃朗的奶牛——分析文本到图像模型中艺术提示的解释*

*Alfio Ferrara, Sergio Picascia, Elisabetta Rocchetti* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 文本到图像模型, 扩散模型, 艺术提示, 内容-风格分离, 交叉注意力热图

**Comment:** to be published in: Applications of AI in the Analysis of Cultural
  and Artistic Heritage, organized within the 35th IEEE International Workshop
  on Machine Learning for Signal Processing (MLSP) 2025

> **TL;DR:** 本文研究文本到图像扩散模型如何在其内部表示艺术作品中的内容和风格概念，发现模型在没有明确监督的情况下，通过交叉注意力热图展现出不同程度的内容-风格分离。

**AI_Comments:** 该论文通过创新的方法（利用交叉注意力热图）深入探究了文本到图像模型内部对艺术概念（内容与风格）的理解机制。这一研究填补了现有知识的空白，揭示了模型在无明确监督下如何学习和区分复杂艺术元素的内在机制，对于理解和改进大型生成模型具有重要意义。同时，公开代码和工具也促进了该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到图像扩散模型在生成艺术内容方面表现出色，但这些模型如何在内部表示绘画中的内容和风格等概念这一基本问题仍未被探索。

**Method:** 利用交叉注意力热图，将生成图像中的像素归因于特定的提示词元，从而分离出受内容描述词元和风格描述词元影响的图像区域。

**Result:** 扩散模型根据特定的艺术提示和所需风格，表现出不同程度的内容-风格分离。在许多情况下，内容词元主要影响与对象相关的区域，而风格词元则影响背景和纹理区域，这表明模型对内容-风格区分有了一种新兴的理解。

**Conclusion:** 这些见解有助于我们理解大型生成模型在没有明确监督的情况下，如何内部表示复杂的艺术概念。

> **ai_Abstract:** 本文深入探讨了基于Transformer的文本到图像扩散模型在生成艺术作品时如何编码内容和风格概念。研究利用交叉注意力热图将生成图像的像素与特定提示词元关联起来，从而区分受内容和风格词元影响的图像区域。研究发现，模型根据艺术提示和风格的不同，展现出不同程度的内容与风格分离，通常内容词元影响对象区域，而风格词元影响背景和纹理，表明模型对内容-风格区分有潜在的理解。这些发现增进了对大型生成模型内部表示复杂艺术概念的认识。

> **摘要翻译:** 文本到图像扩散模型通过学习数十亿张图像，包括流行的艺术作品，展示了生成艺术内容的卓越能力。然而，这些模型如何在内部表示概念，例如绘画中的内容和风格，这一基本问题仍未被探索。传统的计算机视觉假设内容和风格是正交的，但扩散模型在训练期间没有收到关于这种区别的明确指导。在这项工作中，我们研究了基于Transformer的文本到图像扩散模型在生成艺术作品时如何编码内容和风格概念。我们利用交叉注意力热图将生成图像中的像素归因于特定的提示词元，使我们能够分离出受内容描述词元和风格描述词元影响的图像区域。我们的发现表明，扩散模型根据特定的艺术提示和所需风格，表现出不同程度的内容-风格分离。在许多情况下，内容词元主要影响与对象相关的区域，而风格词元则影响背景和纹理区域，这表明模型对内容-风格区分有了一种新兴的理解。这些见解有助于我们理解大型生成模型在没有明确监督的情况下，如何内部表示复杂的艺术概念。我们分享了代码和数据集，以及一个用于可视化注意力图的探索性工具，网址为https://github.com/umilISLab/artistic-prompt-interpretation。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [374] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
> *指令引导的视觉投影器用于生成式视觉-语言模型的持续学习*

*Hyundong Jin, Hyung Jin Chang, Eunwoo Kim* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 持续学习, 视觉-语言模型, 视觉投影器, 指令引导, 专家系统

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 本文提出了一种新颖的框架，通过引入视觉投影器混合体和专家推荐策略，解决了持续学习中预训练视觉-语言模型可能忽视语言指令的问题，使其能够生成遵循指令的响应。

**AI_Comments:** 这项工作提出了一种新颖且实用的方法来解决持续学习中生成式视觉-语言模型对语言指令的忽视问题。通过引入指令引导的视觉投影器混合体、专家推荐和专家剪枝，该方法有效地平衡了视觉输入和语言指令的重要性，提高了模型在动态学习环境中的适应性和指令遵循能力。其创新点在于对视觉-语言翻译过程的精细控制和对专家知识的智能管理。

<details>
  <summary>Details</summary>

**Motivation:** 现有的持续学习方法在更新视觉投影器以适应新任务时，可能导致预训练的生成式视觉-语言模型（VLMs）优先处理视觉输入而非语言指令，尤其是在学习具有重复文本指令类型的任务时。这造成了对语言指令的忽视。

**Method:** 我们提出了一种新颖的框架，将视觉信息翻译基于语言模型的指令。具体来说，我们引入了视觉投影器混合体，每个投影器作为基于给定指令上下文的专业视觉到语言翻译专家。为了避免为不相关的指令上下文使用专家，我们提出了一种专家推荐策略，该策略为与先前学习任务相似的任务重用专家。此外，我们引入了专家剪枝来减轻先前任务中累积激活的专家所造成的干扰。

**Result:** 在各种视觉-语言任务上的大量实验表明，我们的方法通过生成遵循指令的响应，优于现有的持续学习方法。

**Conclusion:** 通过将视觉信息翻译与语言指令相结合，并引入视觉投影器混合体、专家推荐策略和专家剪枝，我们提出的框架成功解决了持续学习中对语言指令的忽视问题，并显著提高了生成式视觉-语言模型在遵循指令方面的表现。

> **ai_Abstract:** 本文针对持续学习中生成式视觉-语言模型（VLMs）可能忽视语言指令的问题，提出了一种名为“指令引导的视觉投影器”的新型框架。该框架通过引入一个视觉投影器混合体，使每个投影器根据指令上下文作为专业的视觉-语言翻译专家。为提高效率，研究者还提出了一种专家推荐策略来重用相似任务的专家，并引入专家剪枝以减少干扰。实验结果表明，该方法在多种视觉-语言任务上能生成更符合指令的响应，表现优于现有持续学习方法。

> **摘要翻译:** 持续学习使预训练的生成式视觉-语言模型（VLMs）能够整合来自新任务的知识，而无需重新训练旧任务的数据。最近的方法通过更新视觉投影器来翻译新任务的视觉信息，从而将预训练的视觉编码器与大型语言模型连接起来。然而，这种调整可能导致模型优先处理视觉输入而非语言指令，尤其是在学习具有重复类型文本指令的任务时。为了解决对语言指令的忽视问题，我们提出了一种新颖的框架，将视觉信息的翻译基于语言模型的指令。我们引入了视觉投影器混合体，每个投影器都作为基于给定指令上下文的专业视觉到语言翻译专家，以适应新任务。为了避免为不相关的指令上下文使用专家，我们提出了一种专家推荐策略，该策略为与先前学习任务相似的任务重用专家。此外，我们引入了专家剪枝来减轻先前任务中累积激活的专家所造成的干扰。在各种视觉-语言任务上的大量实验表明，我们的方法通过生成遵循指令的响应，优于现有的持续学习方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [377] [Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation](https://arxiv.org/abs/2507.22886)
> *迈向指代性音视频分割中的全模态表达与推理*

*Kaining Ying, Henghui Ding, Guangquan Jie, Yu-Gang Jiang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 指代性音视频分割, 多模态表达, 数据集, 推理, MLLM

**Comment:** ICCV 2025, Project Page: https://henghuiding.com/OmniAVS/

> **TL;DR:** 本文提出了OmniAVS数据集和OISA模型，以解决指代性音视频分割（RAVS）中多模态信息整合、深度理解和推理的挑战。OmniAVS包含多种多模态表达和复杂推理，OISA利用MLLM实现卓越的分割性能。

**AI_Comments:** 本文的主要创新在于提出了一个高质量、多模态且包含复杂推理的新数据集OmniAVS，这对于推动RAVS领域的发展至关重要。同时，引入OISA模型并利用MLLM处理多模态推理任务，展现了解决该领域核心挑战的有效途径。该工作有望促进RAVS从简单的检测走向更深层次的理解和推理。

<details>
  <summary>Details</summary>

**Motivation:** 指代性音视频分割（RAVS）在整合多模态信息、深度理解和推理音视频内容方面仍面临挑战，本研究旨在扩展RAVS的边界并促进该领域未来的研究。

**Method:** 本文提出了一个名为OmniAVS的新数据集，包含2,104个视频和61,095个多模态指代表达。OmniAVS具有三项创新：1) 8种灵活组合文本、语音、声音和视觉线索的多模态表达；2) 强调对音频内容的深度理解而非仅检测其存在；3) 包含复杂推理和世界知识的表达。此外，本文还引入了全模态指令分割助手（OISA），它使用多模态大型语言模型（MLLM）来理解复杂线索并执行基于推理的分割。

**Result:** 实验结果表明，OISA在OmniAVS数据集上优于现有方法，并在其他相关任务上取得了有竞争力的结果。

**Conclusion:** 本文通过提出OmniAVS数据集和OISA模型，成功解决了指代性音视频分割中多模态信息整合、深度理解和复杂推理的挑战，并为该领域的未来研究奠定了基础。

> **ai_Abstract:** 本文针对指代性音视频分割（RAVS）中多模态信息整合和复杂推理的挑战，提出了OmniAVS数据集和OISA模型。OmniAVS数据集包含多达8种灵活组合文本、语音、声音和视觉线索的多模态表达，并强调对音频内容的深度理解及复杂推理。OISA模型利用多模态大型语言模型（MLLM）来处理OmniAVS中的多模态推理和细粒度理解任务。实验证明，OISA在OmniAVS上表现优异，并在相关任务中也具有竞争力。

> **摘要翻译:** 指代性音视频分割（RAVS）近期取得了显著进展，但在整合多模态信息以及深度理解和推理音视频内容方面仍面临挑战。为了扩展RAVS的边界并促进该领域的未来研究，我们提出了全模态指代音视频分割（OmniAVS），这是一个包含2,104个视频和61,095个多模态指代表达的新数据集。OmniAVS以三项关键创新脱颖而出：(1) 8种灵活组合文本、语音、声音和视觉线索的多模态表达；(2) 强调对音频内容的理解超越了仅仅检测它们的存在；(3) 表达中包含了复杂的推理和世界知识。此外，我们引入了全模态指令分割助手（OISA），以解决OmniAVS中多模态推理和音视频内容细粒度理解的挑战。OISA使用多模态大型语言模型（MLLM）来理解复杂线索并执行基于推理的分割。大量实验表明，OISA在OmniAVS上优于现有方法，并在其他相关任务上取得了有竞争力的结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [380] [I Am Big, You Are Little; I Am Right, You Are Wrong](https://arxiv.org/abs/2507.23509)
> *我大你小；我对我错*

*David A. Kelly, Akchunya Chanchal, Nathan Blake* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 图像分类, 模型解释, 最小充分像素集, 模型集中度, 深度学习

**Comment:** 10 pages, International Conference on Computer Vision, ICCV 2025

> **TL;DR:** 该研究提出使用“最小充分像素集”来衡量图像分类模型的“集中度”，以理解不同模型（尤其是ConvNext和EVA）如何做出决策，并发现不同架构在像素集大小和位置上存在统计学差异，且错误分类的图像与更大的像素集相关联。

**AI_Comments:** 这篇论文通过引入“最小充分像素集”的概念，为图像分类模型的黑箱解释提供了一种量化且直观的方法。它不仅揭示了不同模型架构（如ConvNext和EVA）在特征关注点上的差异，还为诊断模型错误提供了一个新的线索，即错误分类与更广泛的像素依赖性相关。这种方法对于模型选择、优化和可解释性研究都具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管可以从统计学上评估模型的分类准确性，但我们对这些模型工作方式的理解有限。随着不同大小和架构分类器的激增，选择正确模型的问题变得越来越重要。因此，需要深入了解不同视觉模型的决策过程。

**Method:** 提出使用“最小充分像素集”来衡量模型的“集中度”（即通过模型视角捕捉图像本质的像素）。通过比较像素集的位置、重叠和大小，来识别不同架构之间的差异。

**Result:** 发现不同架构在像素集的大小和位置上具有统计学上的不同集中度。特别是ConvNext和EVA模型与其他模型显著不同。还发现错误分类的图像与正确分类相比，关联着更大的像素集。

**Conclusion:** 本研究通过分析模型的像素“集中度”，提供了一种洞察图像分类模型决策过程的方法，揭示了不同模型架构之间的差异，并指出错误分类与更大像素集的相关性。

> **ai_Abstract:** 该论文提出了一种新颖的方法，通过“最小充分像素集”来分析图像分类模型的“集中度”，以克服对模型决策过程理解的局限性。研究发现，不同的模型架构，尤其是ConvNext和EVA，在捕获图像本质的像素集大小和位置上表现出统计学上的显著差异。此外，错误分类的图像与更大的像素集相关联，这为理解模型行为和分类错误提供了新的视角。

> **摘要翻译:** 机器学习图像分类是一个活跃且快速发展的领域。随着不同大小和架构分类器的激增，选择正确模型的问题变得越来越重要。虽然我们可以从统计学上评估模型的分类准确性，但我们对这些模型工作方式的理解不幸地是有限的。为了深入了解不同视觉模型的决策过程，我们建议使用最小充分像素集来衡量模型的“集中度”：即通过模型视角捕捉图像本质的像素。通过比较像素集的位置、重叠和大小，我们发现不同架构在大小和位置上具有统计学上的不同集中度。特别是ConvNext和EVA模型与其他模型显著不同。我们还发现错误分类的图像与正确分类相比，关联着更大的像素集。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [391] [EP-Diffuser: An Efficient Diffusion Model for Traffic Scene Generation and Prediction via Polynomial Representations](https://arxiv.org/abs/2504.05422)
> *EP-Diffuser：一种通过多项式表示实现交通场景生成与预测的高效扩散模型*

*Yue Yao, Mohamed-Khalil Bouzidi, Daniel Goehring, Joerg Reichardt* | **Category: cs.CV, cs.LG, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 交通场景预测, 扩散模型, 自动驾驶, 多模态预测, 参数高效

**Comment:** 

> **TL;DR:** EP-Diffuser是一种参数高效的扩散模型，能够为自动驾驶车辆生成多样且合理的交通场景未来演变，并在保持小模型尺寸的同时，在准确性和合理性方面超越了现有技术。

**AI_Comments:** 本文提出了一种新颖的EP-Diffuser模型，其创新点在于将扩散模型应用于交通场景的生成和预测，并特别强调了参数效率。这对于资源受限的自动驾驶系统至关重要。其在准确性、合理性以及在OOD设置下的鲁棒性方面的表现，尤其是在模型尺寸更小的情况下，显示了其巨大的潜力。该工作有效解决了自动驾驶中对多模态未来预测的需求。

<details>
  <summary>Details</summary>

**Motivation:** 随着预测范围的增加，由于智能体运动的多模态性质，预测交通场景的未来演变变得越来越困难。大多数现有技术（SotA）预测模型主要侧重于预测最可能发生的未来，但对于自动驾驶车辆的安全运行，覆盖合理运动替代方案的分布同样重要。

**Method:** 我们引入了EP-Diffuser，这是一种新颖的、参数高效的扩散生成模型，旨在捕获可能的交通场景演变分布。该模型以道路布局和智能体历史为条件，作为预测器生成多样、合理的场景延续。

**Result:** EP-Diffuser在Argoverse 2数据集上，在预测准确性和合理性方面与两种现有技术模型进行了基准测试。尽管模型尺寸显著更小，但我们的方法实现了高度准确和合理的交通场景预测。我们进一步在Waymo Open数据集上使用分布外（OoD）测试设置评估了模型的泛化能力，并显示出我们方法卓越的鲁棒性。

**Conclusion:** EP-Diffuser是一种高效且鲁棒的扩散模型，能够生成多样且高度准确的交通场景预测，有效解决了自动驾驶中多模态未来预测的挑战。

> **ai_Abstract:** EP-Diffuser是一种参数高效的扩散生成模型，专为交通场景的生成和预测设计。它通过捕获多模态的未来演变分布，解决了现有模型仅关注最可能未来而忽略其他合理替代方案的局限性。该模型以道路布局和智能体历史为条件，能够生成多样且合理的场景延续。在Argoverse 2数据集上的基准测试表明，EP-Diffuser在模型尺寸显著更小的情况下，仍能实现高准确性和合理性的预测。此外，在Waymo Open数据集的分布外测试中，该模型表现出卓越的泛化能力和鲁棒性。

> **摘要翻译:** 随着预测范围的增加，由于智能体运动的多模态性质，预测交通场景的未来演变变得越来越困难。大多数现有技术（SotA）预测模型主要侧重于预测最可能发生的未来。然而，对于自动驾驶车辆的安全运行，覆盖合理运动替代方案的分布同样重要。为了解决这个问题，我们引入了EP-Diffuser，这是一种新颖的、参数高效的扩散生成模型，旨在捕获可能的交通场景演变分布。以道路布局和智能体历史为条件，我们的模型作为预测器生成多样、合理的场景延续。我们在Argoverse 2数据集上，在预测准确性和合理性方面将EP-Diffuser与两种现有技术模型进行了基准测试。尽管模型尺寸显著更小，但我们的方法实现了高度准确和合理的交通场景预测。我们进一步在分布外（OoD）测试设置中使用Waymo Open数据集评估了模型的泛化能力，并显示出我们方法卓越的鲁棒性。代码和模型检查点可在以下网址获取：https://github.com/continental/EP-Diffuser。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [394] [FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models](https://arxiv.org/abs/2507.23325)
> *FASTopoWM：基于潜世界模型的快慢车道段拓扑推理*

*Yiming Yang, Hongbin Lin, Yueru Luo, Suzhong Fu, Chao Zheng, Xinrui Yan, Shuqi Mei, Kun Tang, Shuguang Cui, Zhen Li* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 车道拓扑推理, 潜在世界模型, 快慢系统, 时间感知, 自动驾驶

**Comment:** 

> **TL;DR:** FASTopoWM引入了快慢系统和潜在世界模型，显著提升了车道拓扑推理的性能，解决了现有方法对时间信息利用不足和姿态估计失败的局限性。

**AI_Comments:** FASTopoWM的创新之处在于其“快慢”系统设计和引入“潜在世界模型”来有效利用时间信息和处理姿态估计失败，这对于提升自动驾驶系统中的道路场景理解至关重要。通过并行监督和状态传播，该方法有效解决了现有方法的痛点，并在关键基准测试上取得了显著的性能提升，表明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有车道拓扑推理方法在有效利用时间信息以提升检测和推理性能方面表现不足。特别是，流式时间传播方法存在过度依赖历史查询、易受姿态估计失败影响以及时间传播不足的局限性。

**Method:** 本文提出了FASTopoWM，一个新颖的、增强了潜在世界模型的快慢车道段拓扑推理框架。该框架通过对历史查询和新初始化查询进行并行监督，实现快慢系统间的相互强化，以减少姿态估计失败的影响。此外，引入了以动作潜在变量为条件的潜在查询和BEV世界模型，用于将状态表示从过去观测传播到当前时间步，从而显著提高慢速管道中的时间感知性能。

**Result:** 在OpenLane-V2基准测试中，FASTopoWM在车道段检测（mAP从33.6%提升至37.4%）和中心线感知（OLS从41.5%提升至46.3%）方面均优于现有最先进方法。

**Conclusion:** FASTopoWM通过其独特的快慢系统和潜在世界模型设计，有效克服了现有车道拓扑推理方法的局限性，显著提升了在车道段检测和中心线感知方面的性能，并为自动驾驶系统中的关键感知模块提供了更强的能力。

> **ai_Abstract:** 本文提出了FASTopoWM，一个新颖的快慢车道段拓扑推理框架，通过引入潜在世界模型来解决现有方法在时间信息利用、历史查询依赖和姿态估计失败等方面的局限。该框架采用并行监督机制强化快慢系统，并利用潜在查询和BEV世界模型进行状态传播，从而显著提升了时间感知能力。在OpenLane-V2基准测试上的实验结果表明，FASTopoWM在车道段检测和中心线感知方面均超越了现有最先进水平。

> **摘要翻译:** 车道段拓扑推理提供了全面的鸟瞰图（BEV）道路场景理解，可以作为面向规划的端到端自动驾驶系统中的关键感知模块。现有的车道拓扑推理方法在有效利用时间信息以增强检测和推理性能方面往往表现不足。最近，基于流的时间传播方法通过在查询和BEV级别整合时间线索，展示了有希望的结果。然而，它仍然受到过度依赖历史查询、易受姿态估计失败影响以及时间传播不足的限制。为了克服这些限制，我们提出了FASTopoWM，一种新颖的、增强了潜在世界模型的快慢车道段拓扑推理框架。为了减少姿态估计失败的影响，这个统一的框架能够对历史查询和新初始化查询进行并行监督，促进快慢系统之间的相互强化。此外，我们引入了以动作潜在变量为条件的潜在查询和BEV世界模型，用于将状态表示从过去观测传播到当前时间步。这种设计显著提高了慢速管道中的时间感知性能。在OpenLane-V2基准测试上进行的广泛实验表明，FASTopoWM在车道段检测（mAP为37.4% 对比 33.6%）和中心线感知（OLS为46.3% 对比 41.5%）方面均优于现有最先进方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [395] [Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2507.23575)
> *超越语素：一种以手部为中心的无语素手语翻译框架*

*Sobhan Asasi, Mohamed Ilyas Lakhal, Ozge Mercanoglu Sincan, Richard Bowden* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 手语翻译, 无语素, 视频大语言模型, 以手部为中心, 对比学习

**Comment:** Accepted at BMVC 2025

> **TL;DR:** 本文提出BeyondGloss，一个基于VideoLLM和手部特征的无语素手语翻译框架，并在主流基准上达到了最先进的性能。

**AI_Comments:** 该论文的创新之处在于其“以手部为中心”和“无语素”的手语翻译方法，解决了现有视频大语言模型在处理长视频时的不足，并专注于细粒度的手部动态。引入HaMeR特征蒸馏和特定的对比损失是其关键创新点，有效提升了手语翻译的性能。

<details>
  <summary>Details</summary>

**Motivation:** 手语翻译面临模态鸿沟和捕捉手部细微变化等挑战。现有视频大语言模型难以详细建模长视频。

**Method:** 本文提出了BeyondGloss框架，利用视频大语言模型的时空推理能力。具体方法包括：生成手部动作的细粒度、时间感知文本描述；通过对比对齐模块在预训练期间将描述与视频特征对齐；从HaMeR中提取细粒度特征以丰富手部特定表示；在手语视频表示与目标语言嵌入之间应用对比损失以减少模态鸿沟。

**Result:** 在Phoenix14T和CSL-Daily基准测试中达到了最先进的性能。

**Conclusion:** 所提出的BeyondGloss框架在无语素手语翻译中表现出有效性。

> **ai_Abstract:** 本文提出了BeyondGloss，一个新颖的无语素手语翻译框架。该框架利用视频大语言模型的时空推理能力，并通过生成细粒度手部动作描述、对比对齐、HaMeR特征蒸馏以及应用对比损失来弥合模态鸿沟。BeyondGloss在Phoenix14T和CSL-Daily基准测试中取得了最先进的性能。

> **摘要翻译:** 手语翻译（SLT）是一项具有挑战性的任务，需要弥合视觉和语言信息之间的模态鸿沟，同时捕捉手形和动作的细微变化。为应对这些挑战，我们引入了\textbf{BeyondGloss}，一个新颖的无语素手语翻译框架，它利用了视频大语言模型（VideoLLMs）的时空推理能力。由于现有VideoLLMs难以详细建模长视频，我们提出了一种新方法来生成手部动作的细粒度、时间感知文本描述。一个对比对齐模块在预训练期间将这些描述与视频特征对齐，鼓励模型关注以手部为中心的时间动态并更有效地区分手语。为了进一步丰富手部特异性表示，我们从HaMeR中提取了细粒度特征。此外，我们在手语视频表示和目标语言嵌入之间应用了对比损失，以减少预训练中的模态鸿沟。\textbf{BeyondGloss}在Phoenix14T和CSL-Daily基准测试中达到了最先进的性能，证明了所提出框架的有效性。论文接收后我们将发布代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [405] [Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation](https://arxiv.org/abs/2507.23326)
> *学习语义方向用于领域泛化医学图像分割中的特征增强*

*Yingkai Wang, Yaoyao Zhu, Xiuding Cai, Yuhao Xiao, Haotian Wu, Yu Yao* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 领域泛化, 医学图像分割, 特征增强, 语义方向, 鲁棒性

**Comment:** 

> **TL;DR:** 本文提出了一种新的领域泛化框架，通过学习语义方向进行特征增强，以解决医学图像分割中跨领域性能下降的问题，并在多中心基准测试中表现优异。

**AI_Comments:** 该论文提出了一种新颖的领域泛化框架，通过学习语义方向进行特征增强，以解决医学图像分割中领域漂移的挑战。其创新点在于引入了语义方向选择器、协方差语义强度采样器以及自适应一致性约束，这些机制能够有效地调制领域变异特征同时保持任务相关的一致性。该方法在医学图像领域泛化方面具有重要意义，有望提升分割模型在真实临床应用中的可靠性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像分割在临床工作流程中至关重要，但由于成像条件、扫描仪类型和采集协议的变化，模型在未见过的临床领域应用时常因领域漂移导致性能下降，从而限制了分割模型的实际部署。

**Method:** 本文提出了一种针对医学图像分割的领域泛化框架。该方法通过引入由领域统计数据引导的隐式特征扰动来提高对领域特定变化的鲁棒性。具体来说，它使用一个可学习的语义方向选择器和一个基于协方差的语义强度采样器来调制领域变异特征，同时保留任务相关的解剖一致性。此外，还设计了一个自适应一致性约束，仅当特征调整导致分割性能下降时才选择性应用，以促使调整后的特征与原始预测对齐，从而稳定特征选择并提高分割的可靠性。

**Result:** 在两个公共多中心基准测试上的大量实验表明，该框架始终优于现有的领域泛化方法，在不同的临床领域实现了鲁棒和可泛化的分割性能。

**Conclusion:** 本文提出的领域泛化框架通过学习语义方向进行特征增强，有效解决了医学图像分割中的领域漂移问题，并在多样化的临床领域中实现了鲁棒且可泛化的分割性能。

> **ai_Abstract:** 本文提出了一种针对医学图像分割的领域泛化框架，旨在解决由于领域漂移导致的性能下降问题。该方法通过引入由领域统计数据引导的隐式特征扰动来增强鲁棒性，具体包括可学习的语义方向选择器和基于协方差的语义强度采样器，以调制领域变异特征并保持解剖一致性。此外，还引入了自适应一致性约束来稳定特征选择。实验结果表明，该框架在多个公共多中心基准测试上优于现有方法，实现了跨临床领域的鲁棒和可泛化分割性能。

> **摘要翻译:** 医学图像分割在临床工作流程中扮演着关键角色，但领域漂移常常导致模型在应用于未见的临床领域时性能下降。这一挑战源于成像条件、扫描仪类型和采集协议的变化，限制了分割模型的实际部署。与自然图像不同，医学图像通常在患者之间表现出一致的解剖结构，而领域特定的变异主要由成像条件引起。这一独特特性使得医学图像分割尤其具有挑战性。
为了应对这一挑战，我们提出了一种专为医学图像分割设计的领域泛化框架。我们的方法通过引入由领域统计数据引导的隐式特征扰动来提高对领域特定变化的鲁棒性。具体来说，我们采用了一个可学习的语义方向选择器和一个基于协方差的语义强度采样器来调制领域变异特征，同时保留任务相关的解剖一致性。此外，我们设计了一个自适应一致性约束，仅当特征调整导致分割性能下降时才选择性应用。这一约束鼓励调整后的特征与原始预测对齐，从而稳定特征选择并提高分割的可靠性。
在两个公共多中心基准测试上的大量实验表明，我们的框架始终优于现有的领域泛化方法，在不同的临床领域实现了鲁棒和可泛化的分割性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [407] [Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints](https://arxiv.org/abs/2507.23064)
> *实时自动驾驶中的视觉-语言融合：相机、高清地图和路径点的目标中心交叉注意力*

*Santosh Patapati, Trisanth Srinivasan, Murari Ambati* | **Category: cs.CV, cs.AI, cs.LG, cs.RO, I.4.8; I.2.10; I.2.6; C.3.3; I.4.9** | **Updated: 2025-07-30**

**Keywords:** 自动驾驶, 视觉-语言模型, 多模态融合, 交叉注意力, 实时驾驶

**Comment:** 5 pages

> **TL;DR:** XYZ-Drive是一个单分支视觉-语言模型，通过目标中心交叉注意力融合相机图像、高清地图和路径点信息，实现了高精度、实时、透明的自动驾驶，并在基准测试中表现优异。

**AI_Comments:** 该论文的创新点在于提出了一个统一的视觉-语言模型XYZ-Drive，通过目标中心交叉注意力机制，实现了多模态（视觉、高清地图、路径点）的早期、令牌级融合，解决了传统自动驾驶堆栈中几何精度和语义理解分离的问题。其将路径点作为引导查询，使得模型能够更有效地关注相关信息，并支持可解释性。实验结果表明了其在性能、效率和安全性上的显著提升，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车需要几何精度和语义理解来应对复杂环境，但大多数现有系统将两者分开处理。本文旨在通过一个统一的模型解决这一问题。

**Method:** 提出XYZ-Drive，一个单一的视觉-语言模型。该模型读取前置摄像头画面、25m x 25m的俯视图和下一个路径点，然后输出转向和速度。一个轻量级目标中心交叉注意力层让路径点标记突出图像和地图中的相关区域，支持动作和文本解释，然后融合的标记进入部分微调的LLaMA-3.2 11B模型。

**Result:** 在MD-NEX户外驾驶基准测试中，XYZ-Drive取得了95%的成功率和0.80的路径长度加权成功率（SPL），超越PhysNav-DG 15%，并将碰撞次数减半，同时通过使用单一分支显著提高了效率。消融实验表明，去除任何模态（视觉、路径点、地图）会使成功率下降高达11%；将目标中心注意力替换为简单拼接会使性能下降3%；冻结Transformer会损失5%的性能；将地图分辨率从10厘米粗化到40厘米会模糊车道边缘并提高碰撞率。

**Conclusion:** 早期、令牌级别的意图和地图布局融合能够实现精确、透明、实时的驾驶。

> **ai_Abstract:** 本文提出了XYZ-Drive，一种用于实时自动驾驶的单一视觉-语言模型。该模型通过目标中心交叉注意力机制，有效融合来自前置摄像头、高清地图和路径点的信息，输出转向和速度指令。其核心创新在于利用路径点令牌引导注意力，突出图像和地图中的关键区域，并支持文本解释。在MD-NEX基准测试中，XYZ-Drive显著提高了驾驶成功率和效率，并减少了碰撞。消融实验进一步验证了多模态融合、目标中心注意力以及模型微调的重要性，证明了早期令牌级融合在实现精确、透明、实时自动驾驶方面的有效性。

> **摘要翻译:** 自动驾驶汽车需要几何精度和语义理解来应对复杂环境，但大多数堆栈将其分开处理。我们提出了XYZ-Drive，一个单一的视觉-语言模型，它读取前置摄像头画面、25m x 25m的俯视图和下一个路径点，然后输出转向和速度。一个轻量级目标中心交叉注意力层让路径点令牌突出相关的图像和地图补丁，在融合的令牌进入部分微调的LLaMA-3.2 11B模型之前，支持动作和文本解释。
在MD-NEX户外驾驶基准测试中，XYZ-Drive取得了95%的成功率和0.80的路径长度加权成功率（SPL），超越PhysNav-DG 15%，并将碰撞次数减半，同时通过使用单一分支显著提高了效率。十六项消融实验解释了这些增益。移除任何模态（视觉、路径点、地图）会使成功率下降高达11%，证实了它们的互补作用和丰富的连接。将目标中心注意力替换为简单拼接会使性能下降3%，表明基于查询的融合更有效地注入地图知识。保持Transformer冻结会损失5%，表明在将VLM应用于自动驾驶等特定任务时微调的重要性。将地图分辨率从10厘米粗化到40厘米会模糊车道边缘并提高碰撞率。
总的来说，这些结果表明，意图和地图布局的早期、令牌级别融合能够实现精确、透明、实时的驾驶。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
> *Cued-Agent: 一种用于自动线索语识别的协作多智能体系统*

*Guanjie Huang, Danny H. K. Tsang, Shan Yang, Guangzhi Lei, Li Liu* | **Category: cs.CV, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 线索语识别, 多智能体系统, 多模态融合, 有限数据, 自校正

**Comment:** 9 pages

> **TL;DR:** Cued-Agent是首个用于自动线索语识别的协作多智能体系统，通过集成四个专门的子智能体来解决数据有限和多模态融合挑战，并在实验中表现出色。

**AI_Comments:** 该论文的创新点在于首次提出并实现了用于自动线索语识别的协作多智能体系统，有效解决了传统方法中多模态融合的复杂性和数据有限的挑战。特别是其训练无关的手势提示解码和语义细化的自校正音素到单词转换，展现了新颖的技术路径。该系统在听障场景下的出色表现，对辅助听障人士交流具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动线索语识别（ACSR）中，手势和唇部动作的时间异步性需要复杂的多模态融合模块。然而，受限于有限的数据可用性，现有方法在训练这些融合机制方面能力不足，导致性能不佳。

**Method:** 本文提出了首个协作多智能体系统Cued-Agent，用于自动线索语识别（ACSR）。该系统集成了四个专门的子智能体：一个基于多模态大语言模型的手势识别智能体（采用关键帧筛选和CS专家提示策略解码手部动作），一个预训练的基于Transformer的唇部识别智能体（从输入视频中提取唇部特征），一个手势提示解码智能体（在推理阶段以无训练方式动态整合手势提示与唇部特征），以及一个自校正音素到单词智能体（首次通过语义细化实现从音素序列到自然语言句子的后处理和端到端转换）。此外，为支持本研究，通过收集八名听障线索语使用者的数据，扩展了现有普通话CS数据集，建立了包含十四个受试者的混合数据集。

**Result:** 广泛的实验表明，与现有最先进的方法相比，Cued-Agent在正常和听障场景中均表现出色。

**Conclusion:** Cued-Agent是首个用于ACSR的协作多智能体系统，通过创新的多智能体架构和语义细化，有效解决了数据有限和多模态融合的挑战，并在各种场景下取得了卓越的性能，为自动线索语识别领域带来了显著的进步。

> **ai_Abstract:** 本文提出了Cued-Agent，一个用于自动线索语识别（ACSR）的协作多智能体系统，旨在解决现有方法在处理手唇异步性和数据有限性方面的不足。Cued-Agent包含四个专业子智能体，分别负责手势识别、唇部识别、手势提示解码以及音素到单词的自校正转换。研究还扩展了普通话CS数据集。实验证明，Cued-Agent在正常和听障场景下均优于现有方法。

> **摘要翻译:** 线索语（CS）是一种视觉交流系统，它将唇读与手部编码相结合，以促进听力障碍者的交流。自动线索语识别（ACSR）旨在通过人工智能驱动的方法将CS手势和唇部动作转换为文本。传统上，手部和唇部动作之间的时间异步性需要设计复杂的模块以促进有效多模态融合。然而，受限于有限的数据可用性，现有方法在充分训练这些融合机制方面能力不足，导致性能不佳。最近，多智能体系统在处理数据有限的复杂任务方面显示出有前景的能力。为此，我们提出了首个用于ACSR的协作多智能体系统，命名为Cued-Agent。它集成了四个专门的子智能体：一个基于多模态大语言模型的手势识别智能体，采用关键帧筛选和CS专家提示策略来解码手部动作；一个预训练的基于Transformer的唇部识别智能体，从输入视频中提取唇部特征；一个手势提示解码智能体，在推理时以无训练方式动态整合手势提示与唇部特征；以及一个自校正音素到单词智能体，首次通过语义细化实现从音素序列到自然语言句子的后处理和端到端转换。为了支持这项研究，我们通过收集八名听障线索语使用者的数据，扩展了现有的普通话CS数据集，建立了一个包含十四个受试者的混合数据集。广泛的实验表明，我们的Cued-Agent与现有最先进的方法相比，在正常和听障场景中均表现出色。实现代码可在 https://github.com/DennisHgj/Cued-Agent 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [Consistent Point Matching](https://arxiv.org/abs/2507.23609)
> *一致点匹配*

*Halid Ziya Yerebakan, Gerardo Hermosillo Valadez* | **Category: cs.CV, cs.DC, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 点匹配, 一致性启发式, 医学图像, 鲁棒性, 地标定位

**Comment:** 

> **TL;DR:** 本研究通过在点匹配算法中加入一致性启发式方法，提高了医学图像解剖位置匹配的鲁棒性，并在多种数据集上验证了其优越性，无需机器学习模型或训练数据即可实现高精度导航。

**AI_Comments:** 该论文的创新点在于将一致性启发式方法引入点匹配算法，显著提升了医学图像匹配的鲁棒性。其重要性体现在能够无需依赖复杂的机器学习模型和大量训练数据，即可实现高精度的医学图像导航，这对于临床应用具有实际价值。此外，该方法在标准CPU上的高效运行也使其具有良好的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过在点匹配算法中引入一致性启发式方法，提高医学图像中解剖位置匹配的鲁棒性。

**Method:** 本研究将一致性启发式方法整合到现有的点匹配算法中。该算法可在标准CPU硬件上高效运行，并允许在速度和鲁棒性之间进行可配置的权衡。

**Result:** 该方法提高了医学图像对之间解剖位置匹配的鲁棒性。它在CT和MRI模态的各种纵向内部和公共数据集上得到了验证，并在Deep Lesion Tracking数据集上超越了最先进的结果。此外，该方法还能有效解决地标定位问题。

**Conclusion:** 该方法无需机器学习模型或训练数据，即可实现医学图像之间的高精度导航。

> **ai_Abstract:** 本研究提出了一种在点匹配算法中整合一致性启发式方法的新方法，旨在提高医学图像中解剖位置匹配的鲁棒性。该方法在CT和MRI的内部及公共数据集上进行了验证，并在Deep Lesion Tracking数据集上取得了超越现有技术水平的成果。其优势在于无需机器学习模型或训练数据即可实现高精度导航，且能在标准CPU上高效运行，并提供速度与鲁棒性的权衡配置。

> **摘要翻译:** 本研究表明，将一致性启发式方法纳入点匹配算法
\cite{yerebakan2023hierarchical}可以提高医学图像对之间解剖位置匹配的鲁棒性。我们
在涵盖CT和MRI模态的各种纵向内部和公共数据集上验证了我们的方法。值得注意的是，
它在Deep Lesion Tracking数据集上超越了最先进的结果。此外，我们表明该方法有效
地解决了地标定位问题。该算法在标准CPU硬件上高效运行，并允许在速度和鲁棒性
之间进行可配置的权衡。该方法无需机器学习模型或训练数据即可实现医学图像之间
的高精度导航。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [422] [KAN or MLP? Point Cloud Shows the Way Forward](https://arxiv.org/abs/2504.13593)
> *KAN或MLP？点云指明前进方向*

*Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 点云分析, Kolmogorov-Arnold Networks (KANs), 多层感知机 (MLP), 3D视觉, 特征学习

**Comment:** 

> **TL;DR:** PointKAN将KANs应用于点云分析，通过改进的网络结构和高效的KAN变体，解决了MLP在点云处理中的局限性，并在多个基准数据集上表现优异，参数量和计算复杂度显著降低。

**AI_Comments:** 这项工作创新性地将新兴的Kolmogorov-Arnold Networks (KANs) 引入到3D点云分析领域，解决了传统MLP在点云处理中存在的局限性。通过设计专门的几何仿射模块和高效KANs变体，PointKAN在保持甚至提升性能的同时，显著降低了模型复杂度和计算成本，这对于资源受限的3D应用具有重要意义。该研究为3D视觉领域探索更高效、更具解释性的神经网络架构提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多层感知机（MLPs）在处理点云复杂几何结构时，其固定激活函数难以有效地捕获局部几何特征，且存在参数效率低下和模型冗余度高的问题。

**Method:** 论文提出了PointKAN，将Kolmogorov-Arnold Networks (KANs) 应用于点云分析。具体包括：引入几何仿射模块（Geometric Affine Module, GAM）来转换局部特征，提高对几何变化的鲁棒性；在局部特征处理（Local Feature Processing, LFP）中，使用并行结构提取组级特征和全局上下文；将这些特征组合并在全局特征处理（Global Feature Processing, GFP）中进行处理，逐步扩展感受野；为克服标准KANs参数量大和计算效率低的问题，在PointKAN-elite变体中开发了高效KANs（Efficient-KANs），显著减少了参数。

**Result:** PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上优于PointMLP，在少样本学习任务中表现尤为出色。此外，PointKAN显著降低了参数数量和计算复杂度（FLOPs）。

**Conclusion:** 这项工作突出了基于KANs的架构在3D视觉领域的潜力，并为点云理解的研究开辟了新途径。

> **ai_Abstract:** 本文提出PointKAN，一种将Kolmogorov-Arnold Networks (KANs) 应用于点云分析的新架构，旨在解决传统MLP在处理复杂点云几何结构时效率低和冗余高的问题。PointKAN通过引入几何仿射模块、并行局部特征处理和全局特征处理来增强特征表示能力，并开发了高效KANs变体以优化参数和计算效率。实验证明PointKAN在多个点云基准数据集上性能优于PointMLP，特别是在少样本学习中表现突出，同时显著降低了模型复杂性，为3D视觉中的KANs应用开辟了新方向。

> **摘要翻译:** 多层感知机（MLPs）因其有效的特征学习机制，已成为点云分析中基本的架构组件之一。然而，在处理点云中复杂的几何结构时，MLPs固定的激活函数难以有效地捕获局部几何特征，同时还存在参数效率低下和模型冗余度高的问题。本文提出了PointKAN，将Kolmogorov-Arnold Networks (KANs) 应用于点云分析任务，以研究其在分层特征表示中的效用。首先，我们引入了几何仿射模块（Geometric Affine Module, GAM）来转换局部特征，提高了模型对几何变化的鲁棒性。其次，在局部特征处理（Local Feature Processing, LFP）中，一个并行结构同时提取组级特征和全局上下文，提供了丰富且细致的细节和整体结构表示。最后，这些特征在全局特征处理（Global Feature Processing, GFP）中进行组合和处理。通过重复这些操作，感受野逐渐扩展，使模型能够捕获点云的完整几何信息。为了克服标准KANs高参数量和计算效率低下的问题，我们在PointKAN-elite变体中开发了高效KANs（Efficient-KANs），显著减少了参数同时保持了准确性。实验结果表明，PointKAN在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上优于PointMLP，在少样本学习任务中表现尤为出色。此外，PointKAN显著降低了参数数量和计算复杂度（FLOPs）。这项工作突出了基于KANs的架构在3D视觉领域的潜力，并为点云理解的研究开辟了新途径。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [427] [MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model](https://arxiv.org/abs/2507.23595)
> *MamV2XCalib：基于V2X和状态空间模型的无目标基础设施相机标定*

*Yaoye Zhu, Zhe Wang, Yan Wang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** V2X, 基础设施相机标定, 无目标标定, 激光雷达-相机标定, Mamba模型

**Comment:** ICCV25 poster

> **TL;DR:** MamV2XCalib是一种新的基于V2X的无目标基础设施相机自动标定方法，利用车载激光雷达和Mamba模型，解决了传统方法的局限性，并在V2X场景中表现出更好的性能。

**AI_Comments:** 本文的创新点在于提出了首个基于V2X的无目标基础设施相机标定方法，并引入了Mamba模型来处理V2X场景中常见的车载数据缺陷和视角差异问题，显著提升了标定的鲁棒性和自动化程度。这对于大规模部署依赖路边基础设施的自动驾驶系统至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着利用路边摄像头辅助自动驾驶感知的合作系统日益普及，大规模精确的基础设施摄像头标定成为关键问题。传统的标定方法耗时、费力且可能需要封路。

**Method:** 本文提出了MamV2XCalib，首个利用车载激光雷达辅助的V2X基础设施相机标定方法。它无需特定参考物体或人工干预，只需配备激光雷达的自动驾驶车辆驶过待标定相机即可。该方法结合多尺度特征和4D相关体积来估计车载点云与路边图像的相关性。利用Mamba模型对时间信息进行建模并估计旋转角度，有效解决了V2X场景中因车载数据缺陷（如遮挡）和视角差异导致的标定失败问题。

**Result:** 在V2X-Seq和TUMTraf-V2X真实世界数据集上进行了评估，证明了该V2X自动标定方法的有效性和鲁棒性。与之前针对单车标定的LiDAR-相机方法相比，MamV2XCalib在V2X场景中以更少的参数实现了更好、更稳定的标定性能。

**Conclusion:** MamV2XCalib提供了一种有效、鲁棒且自动化的基础设施相机标定解决方案，克服了传统方法的局限性，并为V2X应用提供了优越的标定性能。

> **ai_Abstract:** MamV2XCalib提出了一种创新的V2X基础设施相机自动标定方法，利用车载激光雷达和Mamba模型来解决传统手动标定耗时费力的问题。该方法无需特定参考物，通过结合多尺度特征和4D相关体积进行LiDAR-相机校准，并利用Mamba处理时间信息和视角差异。实验结果表明，MamV2XCalib在V2X场景中比现有方法更有效、更鲁棒，且参数更少，实现了更优异的标定性能。

> **摘要翻译:** 随着利用路边摄像头辅助自动驾驶感知的合作系统日益普及，大规模精确的基础设施摄像头标定已成为一个关键问题。传统的手动标定方法通常耗时、费力，并且可能需要封闭道路。本文提出了MamV2XCalib，这是首个在车载激光雷达辅助下，基于V2X的基础设施摄像头标定方法。MamV2XCalib仅需要配备激光雷达的自动驾驶车辆在基础设施中驶过待标定的摄像头附近，无需特定参考物体或人工干预。我们还介绍了一种新的无目标激光雷达-摄像头标定方法，它结合了多尺度特征和4D相关体积来估计车载点云与路边图像之间的相关性。我们利用Mamba模型对时间信息进行建模并估计旋转角度，有效解决了V2X场景中因车载数据缺陷（如遮挡）和视角差异导致的标定失败问题。我们在V2X-Seq和TUMTraf-V2X真实世界数据集上评估了MamV2XCalib，展示了我们基于V2X的自动标定方法的有效性和鲁棒性。与之前为单车标定设计的激光雷达-摄像头方法相比，我们的方法在V2X场景中以更少的参数实现了更好、更稳定的标定性能。代码可在https://github.com/zhuyaoye/MamV2XCalib获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [431] [Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision](https://arxiv.org/abs/2507.23331)
> *对比学习驱动的交通标志感知：文本与视觉的多模态融合*

*Qiang Lu, Waikit Xiu, Xiying Li, Shenyu Hu, Shengbo Sun* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 交通标志识别, 对比学习, 多模态融合, 长尾分布, 小目标检测

**Comment:** 11pages, 5 figures

> **TL;DR:** 本文提出一种结合开放词汇检测和跨模态学习的两阶段框架，用于解决交通标志识别中长尾分布和小目标难题，并在TT100K数据集上达到SOTA性能。

**AI_Comments:** 本文的创新点在于提出了一个结合开放词汇检测和跨模态对比学习的两阶段框架，尤其通过引入视觉-语言路径聚合网络和SPD-Conv模块来处理小目标及尺度变化问题，并通过对比学习有效解决了交通标志识别中的长尾分布和数据不平衡问题。其在TT100K数据集上取得的SOTA性能验证了方法的有效性和重要性，对自动驾驶感知系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 交通标志识别作为自动驾驶感知系统的核心组成部分，面临两大挑战：一是交通标志数据集存在显著的长尾分布，导致传统网络在处理低频和分布外类别时性能下降；二是交通标志多为小目标且尺度变化大，难以提取多尺度特征。

**Method:** 提出一个新型两阶段框架，结合开放词汇检测和跨模态学习。检测阶段，使用NanoVerse YOLO模型，集成可重参数化的视觉-语言路径聚合网络（RepVL-PAN）和SPD-Conv模块，以增强小、多尺度目标的特征提取。分类阶段，设计交通标志识别多模态对比学习模型（TSR-MCL），通过对比Vision Transformer的视觉特征和基于规则的BERT的语义特征，学习鲁棒、频率无关的表示，以缓解数据不平衡。

**Result:** 在TT100K数据集上，该方法在所有类别的长尾检测任务中实现了最先进的78.4% mAP。模型还获得了91.8%的准确率和88.9%的召回率，显著优于主流算法，并在复杂、开放世界场景中表现出卓越的准确性和泛化能力。

**Conclusion:** 该方法通过结合开放词汇检测和跨模态对比学习，有效解决了交通标志识别中长尾分布和小目标检测的挑战，并在TT100K数据集上取得了最先进的性能，展现了在复杂开放世界场景中的优越准确性和泛化能力。

> **ai_Abstract:** 本文提出一个新颖的两阶段框架，用于解决自动驾驶中交通标志识别面临的长尾分布和小目标检测挑战。该框架结合了开放词汇检测和跨模态学习。在检测阶段，NanoVerse YOLO模型通过集成RepVL-PAN和SPD-Conv增强小目标特征提取。在分类阶段，TSR-MCL模型利用视觉和语义特征的对比学习来缓解数据不平衡问题。实验结果表明，该方法在TT100K数据集上实现了SOTA性能，在长尾检测任务中mAP达到78.4%，并展示了在复杂场景下的优越泛化能力。

> **摘要翻译:** 交通标志识别作为自动驾驶感知系统的核心组成部分，直接影响车辆的环境感知和驾驶安全。当前技术面临两大挑战：首先，交通标志数据集呈现出明显的长尾分布，导致传统卷积网络在处理低频和分布外类别时识别性能大幅下降；其次，现实场景中的交通标志主要是小目标，且尺度变化显著，使得多尺度特征难以提取。
为了克服这些问题，我们提出了一种结合开放词汇检测和跨模态学习的新型两阶段框架。在交通标志检测方面，我们的NanoVerse YOLO模型集成了可重参数化的视觉-语言路径聚合网络（RepVL-PAN）和SPD-Conv模块，以专门增强对小目标和多尺度目标的特征提取。在交通标志分类方面，我们设计了一个交通标志识别多模态对比学习模型（TSR-MCL）。通过对比来自Vision Transformer的视觉特征和来自基于规则的BERT的语义特征，TSR-MCL学习了鲁棒的、与频率无关的表示，有效缓解了数据不平衡引起的类别混淆。在TT100K数据集上，我们的方法在所有类别的长尾检测任务中实现了78.4%的mAP，达到了最先进的水平。该模型还获得了91.8%的准确率和88.9%的召回率，显著优于主流算法，并在复杂、开放世界场景中表现出卓越的准确性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [443] [Vocabulary-free Fine-grained Visual Recognition via Enriched Contextually Grounded Vision-Language Model](https://arxiv.org/abs/2507.23070)
> *基于丰富上下文接地视觉-语言模型的无词汇细粒度视觉识别*

*Dmitry Demidov, Zaigham Zaheer, Omkar Thawakar, Salman Khan, Fahad Shahbaz Khan* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 细粒度视觉识别, 视觉-语言模型, 大型语言模型, 零样本学习, 免训练方法

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 针对细粒度图像分类中传统方法和现有视觉-语言模型（VLM）+大型语言模型（LLM）方法面临的词汇限制和LLM利用不足问题，本文提出了一种免训练方法Enriched-FineR（E-FineR）。该方法在细粒度视觉识别中取得了最先进的性能，并在零样本和少样本分类中表现出色，同时提高了可解释性，支持向灵活的语言驱动分类转变。

**AI_Comments:** 该论文的创新之处在于提出了一种免训练的细粒度视觉识别方法Enriched-FineR，有效克服了传统方法对固定词汇的依赖以及现有VLM+LLM方法在LLM利用上的局限性。其免训练特性和在零样本/少样本场景下的出色表现，极大地提升了模型在真实世界中处理新类别和减少人工标注的实用性。此外，其增强的可解释性也为该领域带来了额外的价值。这代表了图像分类从刚性预测向更灵活、语言驱动理解的重要转变。

<details>
  <summary>Details</summary>

**Motivation:** 传统的细粒度图像分类方法严重依赖固定词汇和封闭集分类范式，限制了其在真实世界中对新类别的可扩展性和适应性。尽管结合大型语言模型（LLM）与视觉-语言模型（VLM）的最新研究使得开放集识别成为可能，但现有方法在分类阶段利用LLM的能力方面存在局限性，并且过度依赖LLM猜测的未经彻底分析和细化的类别名称。

**Method:** 本文提出了一种免训练方法Enriched-FineR（E-FineR），旨在解决现有方法中LLM利用不足和猜测类别名称未细化的问题。该方法通过丰富上下文接地的视觉-语言模型，更好地利用LLM在分类阶段的能力。

**Result:** Enriched-FineR在细粒度视觉识别中展示了最先进的结果，并提供了更高的可解释性。在零样本和少样本分类中，该方法表现出与现有最先进（SOTA）方法相当的性能，同时是免训练且无需人工干预的。

**Conclusion:** 本文提出的无词汇框架支持图像分类从刚性标签预测向灵活的、语言驱动的理解转变，从而为实际应用提供可扩展和可推广的系统。

> **ai_Abstract:** 本文针对细粒度视觉识别中传统方法对固定词汇的依赖以及现有视觉-语言模型（VLM）与大型语言模型（LLM）结合方法在LLM利用和类别名称细化方面的不足，提出了一种名为Enriched-FineR（E-FineR）的免训练方法。E-FineR在细粒度视觉识别中取得了最先进的性能，并在零样本和少样本分类中展现出与现有SOTA相当的实力，同时具有更高的可解释性。该框架支持图像分类从 rigid 标签预测转向灵活的语言驱动理解，为实际应用提供了可扩展和可推广的系统，尤其适用于新类别频繁出现或专家标注难以获取的场景。

> **摘要翻译:** 细粒度图像分类是区分更广泛类别中视觉相似子类别（例如，鸟类、汽车模型、花卉类型）的任务，这是一个具有挑战性的计算机视觉问题。传统方法严重依赖固定词汇和封闭集分类范式，限制了它们在频繁出现新类别的真实世界环境中的可扩展性和适应性。最近的研究表明，将大型语言模型（LLM）与视觉-语言模型（VLM）结合可以实现无需预定义类别标签的开放集识别。然而，现有方法在分类阶段利用LLM的能力方面往往受到限制，并且严重依赖LLM提供的猜测类别名称而没有经过彻底分析和细化。为了解决这些瓶颈，我们提出了我们的免训练方法Enriched-FineR（简称E-FineR），该方法在细粒度视觉识别中展示了最先进的结果，同时提供了更高的可解释性，突显了其在难以获得专家标注的真实世界场景和新领域中的强大潜力。此外，我们展示了我们提出的方法在零样本和少样本分类中的应用，它表现出与现有SOTA相当的性能，同时是免训练且无需人工干预的。总的来说，我们的无词汇框架支持图像分类从刚性标签预测向灵活的、语言驱动的理解转变，从而为实际应用提供可扩展和可推广的系统。完善的代码可在https://github.com/demidovd98/e-finer 上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [452] [Step1X-Edit: A Practical Framework for General Image Editing](https://arxiv.org/abs/2504.17761)
> *Step1X-Edit: 一个实用的通用图像编辑框架*

*Shiyu Liu, Yucheng Han, Peng Xing, Fukun Yin, Rui Wang, Wei Cheng, Jiaqi Liao, Yingming Wang, Honghao Fu, Chunrui Han, Guopeng Li, Yuang Peng, Quan Sun, Jingwei Wu, Yan Cai, Zheng Ge, Ranchen Ming, Lei Xia, Xianfang Zeng, Yibo Zhu, Binxing Jiao, Xiangyu Zhang, Gang Yu, Daxin Jiang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 图像编辑, 多模态LLM, 扩散模型, 开源模型, GEdit-Bench

**Comment:** code: https://github.com/stepfun-ai/Step1X-Edit

> **TL;DR:** Step1X-Edit是一个开源图像编辑模型，性能接近GPT-4o和Gemini2 Flash等闭源模型，并发布了新的数据集和基准。

**AI_Comments:** 这项工作通过发布高性能的开源模型Step1X-Edit，并提供高质量的数据生成管道和新的评估基准GEdit-Bench，显著推动了通用图像编辑领域的发展，缩小了开源与闭源模型之间的差距。其创新性在于结合多模态LLM和扩散模型，并注重实际应用场景的评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有开源图像编辑算法与GPT-4o和Gemini2 Flash等闭源模型之间存在巨大差距，需要一个能提供可比性能的开源模型。

**Method:** 采用多模态LLM处理参考图像和编辑指令，提取潜在嵌入并与扩散图像解码器集成以生成目标图像。构建数据生成管道以生成高质量数据集，并开发了基于真实用户指令的新基准GEdit-Bench进行评估。

**Result:** Step1X-Edit在GEdit-Bench上显著优于现有开源基线，并接近领先的专有模型性能。

**Conclusion:** Step1X-Edit作为一个新的开源图像编辑模型，在性能上接近闭源模型，对图像编辑领域做出了重要贡献。

> **ai_Abstract:** 本文介绍了Step1X-Edit，一个先进的开源图像编辑模型，旨在缩小与GPT-4o和Gemini2 Flash等闭源模型之间的性能差距。该模型利用多模态LLM处理图像和指令，并结合扩散解码器生成编辑后的图像。为训练模型，开发了高质量数据生成管道，并创建了基于真实用户指令的评估基准GEdit-Bench。实验证明Step1X-Edit超越了现有开源模型，性能接近领先的专有模型。

> **摘要翻译:** 近年来，图像编辑模型取得了显著而迅速的发展。GPT-4o和Gemini2 Flash等尖端多模态模型的最新发布引入了极具前景的图像编辑能力。这些模型在满足绝大多数用户驱动的编辑需求方面表现出令人印象深刻的才能，标志着图像处理领域的一大进步。然而，开源算法与这些闭源模型之间仍存在巨大差距。因此，在本文中，我们旨在发布一个最先进的图像编辑模型，名为Step1X-Edit，它可以提供与GPT-4o和Gemini2 Flash等闭源模型相当的性能。更具体地说，我们采用多模态LLM来处理参考图像和用户的编辑指令。提取潜在嵌入并与扩散图像解码器集成以获得目标图像。为了训练该模型，我们构建了一个数据生成管道来生成高质量数据集。为了进行评估，我们开发了GEdit-Bench，一个植根于真实用户指令的新颖基准。在GEdit-Bench上的实验结果表明，Step1X-Edit以显著优势超越了现有开源基线，并接近领先的专有模型性能，从而为图像编辑领域做出了重大贡献。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [457] [MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction](https://arxiv.org/abs/2507.23597)
> *MoGA：用于单目高斯头像重建的3D生成式头像先验*

*Zijian Dong, Longteng Duan, Jie Song, Michael J. Black, Andreas Geiger* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D高斯头像, 单目重建, 生成式模型, 扩散模型, 3D一致性

**Comment:** ICCV 2025 (Highlight), Project Page: https://zj-dong.github.io/MoGA/

> **TL;DR:** MoGA通过结合3D生成式头像模型和2D扩散模型，实现了从单张图像重建高质量3D高斯头像。

**AI_Comments:** MoGA的创新之处在于巧妙地结合了3D生成式模型作为先验，弥补了纯2D扩散模型在3D一致性上的不足，并克服了3D数据稀缺的挑战。这种结合利用了3D先验的结构优势和2D扩散模型的细节生成能力，为单目3D重建提供了一条有前景的路径。其生成的头像可动画性也增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的从单张图像重建3D头像的方法依赖于2D扩散模型生成稀疏且不一致的视图，导致不真实的三维伪影和模糊的外观，难以推断看不见的细节并确保3D一致性和真实感。

**Method:** MoGA利用一个生成式头像模型作为先验，该模型通过从学习到的先验分布中采样变形高斯来生成多样化的3D头像。为了解决3D训练数据有限的问题，它将输入图像投影到生成模型的潜在空间，并施加额外的3D外观和几何约束，确保3D一致性。它将高斯头像创建公式化为模型反演过程，通过将生成式头像拟合到来自2D扩散模型的合成视图。生成式头像为模型拟合提供有意义的初始化，强制执行3D正则化并帮助改进姿态估计。

**Result:** 实验表明，MoGA超越了最先进的技术，并且对真实世界场景具有良好的泛化能力。生成的高斯头像本质上是可动画的。

**Conclusion:** MoGA通过结合3D生成式头像先验和2D扩散模型，有效解决了单目3D头像重建中的挑战，实现了高保真、3D一致且可动画的头像重建，超越了现有技术。

> **ai_Abstract:** MoGA是一种新颖的方法，可以从单张图像重建高保真3D高斯头像。它通过结合一个能够生成多样化3D头像的生成式头像模型作为先验，并将其与2D扩散模型生成的合成视图相结合进行模型反演，解决了现有方法在推断看不见细节和确保3D一致性方面的局限性。MoGA提供了有意义的初始化、3D正则化和姿态估计改进，实验证明其性能优于现有技术，并能生成可动画的头像。

> **摘要翻译:** 我们提出了MoGA，一种从单视图图像重建高保真3D高斯头像的新方法。主要挑战在于推断看不见的外观和几何细节，同时确保3D一致性和真实感。大多数以前的方法依赖于2D扩散模型来合成看不见的视图；然而，这些生成的视图稀疏且不一致，导致不真实的三维伪影和模糊的外观。为了解决这些局限性，我们利用一个生成式头像模型，该模型可以通过从学习到的先验分布中采样变形高斯来生成多样化的3D头像。由于3D训练数据量有限，单独的3D模型无法捕捉看不见身份的所有图像细节。因此，我们将其作为一个先验进行整合，通过将输入图像投影到其潜在空间并强制执行额外的3D外观和几何约束来确保3D一致性。我们新颖的方法将高斯头像创建公式化为模型反演过程，通过将生成式头像拟合到来自2D扩散模型的合成视图。生成式头像为模型拟合提供了有意义的初始化，强制执行3D正则化，并有助于改进姿态估计。实验表明，我们的方法超越了最先进的技术，并且对真实世界场景具有良好的泛化能力。我们的高斯头像本质上也是可动画的。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [458] [MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting](https://arxiv.org/abs/2507.23340)
> *MagicRoad: 基于障碍物修复的语义感知三维路面重建*

*Xingyue Peng, Yuandong Lyu, Lang Zhang, Jian Zhu, Songtao Wang, Jiaxin Deng, Songxin Lu, Weiliang Ma, Dangen She, Peng Jia, XianPeng Lang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D Road Reconstruction, Obstacle Inpainting, Semantic-Aware, Autonomous Driving, Gaussian Splatting

**Comment:** 

> **TL;DR:** MagicRoad通过语义引导的障碍物修复，实现了鲁棒的3D路面重建，解决了传统方法在复杂环境下的局限性。

**AI_Comments:** 该论文的创新点在于结合了2D高斯表面元素、语义引导的障碍物修复和颜色增强，有效地解决了3D路面重建中动态和静态障碍物带来的挑战。其在真实世界复杂环境下的鲁棒性对于自动驾驶的高精地图和感知具有重要意义。该方法通过修复来清理场景，而非简单地忽略或平均，提供了一种更精确的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 路面重建对于自动驾驶中厘米级车道感知和高精地图至关重要。然而，现有基于网格渲染或3D高斯泼溅的方法在复杂城市环境中，如动态障碍物遮挡、静态杂波和光照天气变化导致的图像退化等问题下表现不佳。

**Method:** 本文提出了一种鲁棒的重建框架，集成了遮挡感知的2D高斯表面元素和语义引导的颜色增强。具体方法包括：利用平面适应的高斯表示进行高效大规模建模；采用分割引导的视频修复技术移除动态和静态前景物体；通过HSV空间中的语义感知校正增强颜色一致性。

**Result:** 在城市规模数据集上的大量实验表明，该框架生成了视觉连贯且几何忠实的路面重建，在真实世界条件下显著优于现有方法。

**Conclusion:** MagicRoad提供了一种在复杂真实世界条件下，鲁棒且精确的3D路面重建方法，有效解决了现有技术面临的遮挡和环境退化问题，对自动驾驶的高精地图和感知至关重要。

> **ai_Abstract:** 本文提出了MagicRoad，一个用于3D路面重建的鲁棒框架，旨在解决现有方法在复杂城市环境中遇到的遮挡、杂波和环境退化问题。该框架结合了遮挡感知的2D高斯表面元素和语义引导的颜色增强，通过平面适应的高斯表示、分割引导的视频修复和语义感知颜色校正，实现了对动态和静态障碍物的高效移除和颜色一致性增强，从而生成了高质量的路面重建。实验证明其在真实世界条件下表现优异。

> **摘要翻译:** 路面重建对于自动驾驶至关重要，支持在复杂的城市环境中实现厘米级的车道感知和高精地图。虽然近期基于网格渲染或3D高斯泼溅（3DGS）的方法在干净和静态条件下取得了有希望的结果，但它们仍然容易受到动态代理的遮挡、静态障碍物的视觉杂波以及光照和天气变化引起的图像退化的影响。我们提出了一种鲁棒的重建框架，该框架集成了遮挡感知的2D高斯表面元素和语义引导的颜色增强，以恢复干净、一致的路面。我们的方法利用平面适应的高斯表示进行高效的大规模建模，采用分割引导的视频修复来移除动态和静态前景物体，并通过HSV空间中的语义感知校正增强颜色一致性。在城市规模数据集上进行的大量实验表明，我们的框架产生了视觉连贯且几何忠实的路面重建，在真实世界条件下显著优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [469] [ART: Adaptive Relation Tuning for Generalized Relation Prediction](https://arxiv.org/abs/2507.23543)
> *ART：广义关系预测的自适应关系调优*

*Gopika Sudhakaran, Hikaru Shindo, Patrick Schramowski, Simone Schaub-Meyer, Kristian Kersting, Stefan Roth* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 视觉关系检测, 指令调优, 视觉语言模型, 自适应采样, 关系预测

**Comment:** Accepted for publication in ICCV 2025

> **TL;DR:** ART是一个通过指令调优和自适应实例选择来适应视觉语言模型（VLMs）进行视觉关系检测（VRD）的框架，显著提高了对未见关系概念的泛化能力。

**AI_Comments:** ART框架的创新点在于将指令调优引入视觉关系检测领域，并结合了自适应实例选择策略，有效解决了传统VRD模型泛化能力差以及提示调优局限性的问题。其能够推断未见关系概念的能力是其显著优势，为VRD领域带来了新的研究方向和应用潜力。这表明了指令调优在视觉-语言任务中泛化能力的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉关系检测（VRD）模型在训练数据之外的泛化能力较差。虽然提示调优（prompt tuning）已用于适应视觉语言模型（VLMs）进行VRD，但其依赖手工提示且难以处理新颖或复杂的关系。

**Method:** 本文提出了ART（Adaptive Relation Tuning）框架，通过指令调优和策略性实例选择来使视觉语言模型（VLMs）适应视觉关系检测（VRD）。具体方法是将VRD数据集转换为指令调优格式，并采用自适应采样算法，引导VLM关注信息丰富的关系，同时保持泛化能力。研究重点是关系分类，即给定主客体框，模型预测它们之间的谓词。

**Result:** ART方法显著优于基线，并且能够推断出未见过的关系概念，这是主流VRD方法所不具备的能力。通过使用预测的关系进行复杂场景分割，证明了ART的实用价值。

**Conclusion:** ART框架通过指令调优和自适应实例选择，有效提升了视觉语言模型在视觉关系检测任务上的泛化能力，尤其是在处理未见关系方面表现出色，并具有实际应用价值。

> **ai_Abstract:** 本文提出了一种名为ART（Adaptive Relation Tuning）的新框架，旨在解决视觉关系检测（VRD）模型泛化能力不足的问题。ART通过将视觉语言模型（VLMs）与指令调优相结合，并采用自适应采样算法，使其能够更有效地学习和识别物体间的关系，尤其是在面对未见关系时。该方法在关系分类任务上表现出色，并能推断出新的关系概念，优于现有基线，并展示了在复杂场景分割中的实际应用潜力。

> **摘要翻译:** 视觉关系检测（VRD）是识别场景中物体之间关系的任务。仅在关系检测数据上训练的VRD模型难以泛化到其训练关系之外。虽然提示调优已被用于适应视觉语言模型（VLMs）进行VRD，但它使用手工制作的提示，并且难以处理新颖或复杂的关系。我们认为指令调优通过在多样化的指令数据上微调VLM提供了一个更有效的解决方案。因此，我们引入了ART，一个自适应关系调优框架，通过指令调优和策略性实例选择来适应VLM进行VRD。通过将VRD数据集转换为指令调优格式并采用自适应采样算法，ART引导VLM专注于信息丰富的关系，同时保持泛化能力。具体来说，我们专注于关系分类，其中给定主客体框，模型预测它们之间的谓词。我们在一个内部数据集上进行调优，并在多个不同复杂度的外部数据集上进行评估。我们的方法比其基线有显著改进，并且可以推断出未见过的关系概念，这是主流VRD方法所不具备的能力。我们通过使用预测的关系进行复杂场景分割来证明ART的实用价值。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [476] [LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks](https://arxiv.org/abs/2507.22477)
> *LIDAR：轻量级自适应线索感知融合视觉Mamba用于结构裂缝的多模态分割*

*Hui Liu, Chen Jia, Fan Shi, Xu Cheng, Mengfei Shi, Xia Xie, Shengyong Chen* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 裂缝分割, 多模态融合, Vision Mamba, 轻量级网络, 像素级分割

**Comment:** This paper has been accepted by ACM MM 2025

> **TL;DR:** LIDAR是一种轻量级自适应多模态裂缝分割网络，结合了Mamba架构和新颖的融合策略，以低计算成本实现高精度像素级裂缝分割。

**AI_Comments:** 该论文的创新点在于将Vision Mamba架构引入多模态裂缝分割任务，并设计了多个轻量级且高效的模块，如LacaVSS、LD3CF和LDMK，以实现自适应线索感知和跨模态融合。其强调低计算成本同时保持高精度的特点，对于实际应用具有重要意义。在资源受限的环境下，这种轻量级高效的模型能够提供更实用的解决方案。其性能在多个数据集上超越SOTA，进一步验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 在裂缝分割任务中，使用多模态数据以低计算成本实现像素级分割仍然是一个关键挑战。现有方法缺乏自适应感知和高效的跨模态特征交互融合能力。

**Method:** 本文提出了一个轻量级自适应线索感知视觉Mamba网络（LIDAR），它包含两个核心模块：轻量级自适应线索感知视觉状态空间模块（LacaVSS）和轻量级双域动态协作融合模块（LD3CF）。LacaVSS通过掩码引导的有效动态引导扫描策略（EDG-SS）自适应地建模裂缝线索。LD3CF利用自适应频域感知器（AFDP）和双池化融合策略有效捕获跨模态的空间和频域线索。此外，还设计了轻量级动态调制多核卷积（LDMK）来感知复杂的形态结构，以最小的计算开销替代了LIDAR中的大部分卷积操作。

**Result:** 在三个数据集上的实验表明，所提出的方法优于其他最先进（SOTA）的方法。在光场深度数据集上，该方法在F1得分上达到0.8204，mIoU达到0.8465，且参数量仅为5.35M。

**Conclusion:** LIDAR成功地解决了多模态裂缝分割中计算成本和像素级精度之间的平衡问题，通过其创新的模块设计，实现了高效的跨模态信息融合和裂缝线索感知，并在多个数据集上表现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为LIDAR的轻量级自适应线索感知视觉Mamba网络，旨在解决多模态裂缝分割中低计算成本下实现像素级分割的挑战。LIDAR通过其独特的LacaVSS模块（利用掩码引导的EDG-SS进行裂缝线索建模）和LD3CF模块（采用AFDP和双池化策略进行跨模态空间和频域线索融合）实现高效的跨模态特征感知与整合。此外，LIDAR采用轻量级动态调制多核卷积（LDMK）以降低计算开销。实验结果表明，LIDAR在多个数据集上均超越了现有SOTA方法，并在光场深度数据集上以极低的参数量（5.35M）取得了0.8204的F1和0.8465的mIoU，验证了其在精度和效率上的优越性。

> **摘要翻译:** 在裂缝分割任务中，使用多模态数据以低计算成本实现像素级分割仍然是一个关键挑战。现有方法缺乏自适应感知和高效的跨模态特征交互融合能力。为了解决这些挑战，我们提出了一种轻量级自适应线索感知视觉Mamba网络（LIDAR），它能有效地感知和整合多模态裂缝场景下不同模态的形态和纹理线索，生成清晰的像素级裂缝分割图。具体来说，LIDAR由一个轻量级自适应线索感知视觉状态空间模块（LacaVSS）和一个轻量级双域动态协作融合模块（LD3CF）组成。LacaVSS通过所提出的掩码引导的有效动态引导扫描策略（EDG-SS）自适应地建模裂缝线索，而LD3CF则利用自适应频域感知器（AFDP）和双池化融合策略有效捕获跨模态的空间和频域线索。此外，我们设计了一种轻量级动态调制多核卷积（LDMK）来感知复杂的形态结构，以最小的计算开销，替代了LIDAR中的大多数卷积操作。在三个数据集上的实验表明，我们的方法优于其他最先进（SOTA）的方法。在光场深度数据集上，我们的方法在F1得分上达到0.8204，mIoU达到0.8465，且参数量仅为5.35M。代码和数据集可在https://github.com/Karl1109/LIDAR-Mamba获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [477] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
> *真的是你吗？探索逼真会说话头像视频中的生物识别验证场景*

*Laura Pedrouzo-Rodriguez, Pedro Delgado-DeRobles, Luis F. Gomez, Ruben Tolosana, Ruben Vera-Rodriguez, Aythami Morales, Julian Fierrez* | **Category: cs.CV, cs.AI, cs.CR, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 生物识别验证, 逼真头像, 面部运动, 身份冒充, 图卷积网络

**Comment:** Accepted at the IEEE International Joint Conference on Biometrics
  (IJCB 2025)

> **TL;DR:** 逼真头像视频存在身份冒充风险。本研究探索面部运动模式作为行为生物特征进行身份验证，并提出了一个基于图卷积网络的轻量级系统，结果显示面部运动线索可有效验证身份。

**AI_Comments:** 这篇论文创新性地提出利用面部运动模式作为一种行为生物特征来解决逼真头像视频中的身份冒充问题，这在传统视觉和听觉识别受限的情况下具有重要意义。其引入的新数据集和轻量级GCN模型为该领域的研究提供了有价值的基准和工具，对于提升虚拟通信的安全性和信任度具有重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 逼真会说话的头像在虚拟会议、游戏和社交平台中越来越普遍，但它们带来了严重的安全风险，特别是身份冒充，攻击者可以窃取用户头像，使其外观和声音保持不变，仅凭视觉或听觉几乎无法检测到欺诈性使用。

**Method:** 引入了一个新的真实头像视频数据集，使用最先进的单次头像生成模型GAGAvatar创建，包含真实和冒充者头像视频。同时，提出了一种轻量级、可解释的时空图卷积网络（Graph Convolutional Network）架构，该架构带有时间注意力池化，仅使用面部标志点来建模动态面部手势。

**Result:** 实验结果表明，面部运动线索能够实现有意义的身份验证，AUC值接近80%。

**Conclusion:** 面部运动线索在头像介导的场景中可以作为可靠的行为生物特征进行身份验证。研究提出的基准和生物识别系统可供研究社区使用，以促使人们关注在基于头像的通信系统中对更先进的行为生物识别防御的迫切需求。

> **ai_Abstract:** 本文探讨了在逼真会说话头像视频中进行身份验证的挑战，尤其是在头像外观和声音被冒充时。研究提出利用个体的面部运动模式作为行为生物特征来验证身份。为此，作者构建了一个包含真实和冒充者头像视频的新数据集，并开发了一个基于面部标志点的轻量级时空图卷积网络。实验证明，面部运动线索能够有效识别身份，AUC值接近80%，突显了在头像通信中加强行为生物识别防御的必要性。

> **摘要翻译:** 逼真会说话的头像在虚拟会议、游戏和社交平台中变得越来越普遍。这些头像允许更沉浸式的交流，但也带来了严重的安全风险。一个新出现的威胁是身份冒充：攻击者可以窃取用户的头像——保留其外观和声音——使得仅凭视觉或听觉几乎不可能检测到其欺诈性使用。在本文中，我们探讨了在此类头像介导的场景中生物识别验证的挑战。我们的主要问题是，当头像的视觉外观是其所有者的复制品时，个体的面部运动模式是否可以作为可靠的行为生物特征来验证其身份。为了回答这个问题，我们引入了一个新的真实头像视频数据集，该数据集使用最先进的单次头像生成模型GAGAvatar创建，包含真实和冒充者头像视频。我们还提出了一种轻量级、可解释的时空图卷积网络架构，该架构带有时间注意力池化，仅使用面部标志点来建模动态面部手势。实验结果表明，面部运动线索能够实现有意义的身份验证，AUC值接近80%。所提出的基准和生物识别系统可供研究社区使用，以促使人们关注在基于头像的通信系统中对更先进的行为生物识别防御的迫切需求。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [482] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
> *图像分辨率对人脸检测的影响：MTCNN、YOLOv XI和YOLOv XII模型的比较分析*

*Ahmet Can Ömercikoğlu, Mustafa Mansur Yönügül, Pakize Erdoğmuş* | **Category: cs.CV, 68T45, 68T07, I.4.8; I.4.9; I.5.4** | **Updated: 2025-07-31**

**Keywords:** 人脸检测, 图像分辨率, MTCNN, YOLOv11, YOLOv12

**Comment:** 6 pages, 5 figures, 4 tables

> **TL;DR:** 本研究系统地调查了输入分辨率对MTCNN、YOLOv11和YOLOv12三种深度学习人脸检测器准确性和鲁棒性的影响，发现YOLOv11在检测精度方面表现最佳，尤其是在高分辨率下。

**AI_Comments:** 该论文通过系统比较不同分辨率下多种流行人脸检测模型的性能，提供了实际应用中选择模型的宝贵指导。其重要性在于揭示了分辨率对模型表现的直接影响，有助于优化AI驱动应用在复杂现实条件下的性能。

<details>
  <summary>Details</summary>

**Motivation:** 人脸检测是许多AI驱动应用中的关键组成部分，但低分辨率图像等现实世界条件会显著降低检测性能，因此需要系统研究输入分辨率对检测器性能的影响。

**Method:** 本研究系统地调查了MTCNN、YOLOv11和YOLOv12三种深度学习人脸检测器在不同输入分辨率（160x160、320x320和640x640）下对准确性和鲁棒性的影响。使用WIDER FACE数据集，并评估了模型的精度、召回率、mAP50、mAP50-95和推理时间。

**Result:** 结果表明，YOLOv11在检测精度方面优于YOLOv12和MTCNN，尤其是在较高分辨率下；YOLOv12表现出略好的召回率；MTCNN在实时推理速度方面落后，尽管在地标定位方面具有竞争力。

**Conclusion:** 研究结果为选择适合不同操作约束的分辨率感知人脸检测模型提供了可操作的见解。

> **ai_Abstract:** 本研究旨在探讨图像分辨率对人脸检测模型性能的影响，比较了MTCNN、YOLOv11和YOLOv12三种模型。研究人员在WIDER FACE数据集上，通过不同分辨率（160x160、320x320、640x640）评估了这些模型在精度、召回率、mAP和推理时间等方面的表现。结果显示，YOLOv11在检测精度方面表现最优，尤其是在高分辨率下；YOLOv12在召回率上略胜一筹；MTCNN在实时推理速度上存在不足。研究为选择适合特定操作条件的人脸检测模型提供了实用指导。

> **摘要翻译:** 人脸检测是许多人工智能驱动应用中的关键组成部分，例如监控、生物识别认证和人机交互。然而，低分辨率图像等现实世界条件带来了严峻挑战，会降低检测性能。在本研究中，我们系统地调查了输入分辨率对三种主要基于深度学习的人脸检测器：YOLOv11、YOLOv12和MTCNN的准确性和鲁棒性的影响。我们使用WIDER FACE数据集，在多种图像分辨率（160x160、320x320和640x640）下进行了广泛评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标评估了每个模型的性能。结果表明，YOLOv11在检测精度方面优于YOLOv12和MTCNN，尤其是在较高分辨率下，而YOLOv12表现出略好的召回率。MTCNN虽然在地标定位方面具有竞争力，但在实时推理速度方面落后。我们的发现为选择适合不同操作约束的分辨率感知人脸检测模型提供了可操作的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [484] [Prompt-Based Exemplar Super-Compression and Regeneration for Class-Incremental Learning](https://arxiv.org/abs/2311.18266)
> *基于Prompt的类增量学习范例超压缩与再生*

*Ruxiao Duan, Jieneng Chen, Adam Kortylewski, Alan Yuille, Yaoyao Liu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 类增量学习, 范例压缩, 扩散模型, 内存效率, 数据增强

**Comment:** BMVC 2025. Code: https://github.com/KerryDRX/PESCR

> **TL;DR:** PESCR通过将图像压缩为提示并利用扩散模型再生多样化范例，显著提高了类增量学习的性能，同时大幅减少了内存消耗。

**AI_Comments:** 该论文的创新点在于将图像压缩为提示并结合预训练扩散模型进行范例再生，这巧妙地解决了类增量学习中内存限制和范例多样性不足的痛点。通过显著的内存节省和性能提升，为CIL领域提供了一个有前景的新方向，尤其是在资源受限的环境下具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 类增量学习中基于重放的方法受限于内存，导致存储的范例数量有限且多样性差。

**Method:** 本文提出PESCR方法，利用预训练的通用扩散模型，将图像压缩成视觉和文本提示进行存储（内存减少24倍），而非原始图像。在后续阶段，通过扩散模型再生多样化的范例。此外，还提出了部分压缩和基于扩散的数据增强，以最小化生成范例与真实图像之间的域差距。

**Result:** PESCR显著提高了类增量学习在多个基准上的性能，例如在ImageNet-100上比现有最先进水平高出3.2%。

**Conclusion:** PESCR通过有效的范例压缩和再生策略，成功解决了类增量学习中内存限制和范例多样性不足的问题，并取得了显著的性能提升。

> **ai_Abstract:** 本文提出了一种名为PESCR的新型类增量学习方法，旨在解决现有重放方法中范例存储受内存限制且多样性不足的问题。PESCR通过将图像高效压缩为视觉和文本提示进行存储，大幅减少了内存占用，并利用预训练的扩散模型再生多样化范例。此外，通过部分压缩和扩散数据增强技术，有效减小了生成图像与真实图像间的域差距。实验结果表明，PESCR显著提升了类增量学习的性能，并在ImageNet-100上超越了现有最先进水平。

> **摘要翻译:** 类增量学习（CIL）中基于重放的方法取得了显著成功。尽管它们有效，但固有的内存限制导致只能保存数量有限且多样性差的范例。在本文中，我们引入了PESCR，这是一种新颖的方法，它基于预训练的通用扩散模型，显著增加了范例的数量并增强了其多样性，而无需在目标数据集上进行微调或将其存储在内存缓冲区中。图像被压缩成视觉和文本提示，这些提示被保存而不是原始图像，从而将内存消耗降低了24倍。在后续阶段，多样化的范例由扩散模型再生。我们进一步提出了部分压缩和基于扩散的数据增强，以最小化生成范例与真实图像之间的域差距。PESCR显著提高了多个基准上的CIL性能，例如在ImageNet-100上比以前的最先进水平高出3.2%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [Sparfels: Fast Reconstruction from Sparse Unposed Imagery](https://arxiv.org/abs/2505.02178)
> *稀疏像素：从稀疏未校准图像中快速重建*

*Shubhendu Jena, Amine Ouasfi, Mae Younes, Adnane Boukhayma* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 稀疏视图重建, 2D高斯溅射, 3D基础模型, 未校准图像, 形状重建

**Comment:** ICCV 2025. Project page :
  https://shubhendu-jena.github.io/Sparfels-web/

> **TL;DR:** Sparfels是一种在消费级GPU上3分钟内从稀疏未校准图像中快速准确进行形状重建的方法，它利用一个3D基础模型和新的颜色方差公式。

**AI_Comments:** 该论文的创新点在于结合了最新的3D基础模型与2D高斯溅射技术，并引入了独特的颜色方差优化策略，以高效地解决稀疏未校准图像的形状重建难题。其在消费级硬件上的快速运行时间以及在复杂设置下达到SOTA性能，显示了其重要性和实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在稀疏未校准相机设置下，对稀疏辐射场学习的关注较少，尤其是在形状恢复方面。传统方法依赖数据先验或外部单目几何先验。

**Method:** 提出一个高效简单的流水线，利用单一的3D基础模型。该模型利用其点云图和相机初始化来实例化一个捆绑调整的2D高斯溅射(2DGS)模型，并使用图像对应来指导2DGS训练中的相机优化。关键贡献是提出了一种新的沿射线溅射颜色方差的计算公式，通过减少训练中的该方差实现更准确的形状重建。

**Result:** 该方法在消费级GPU上3分钟内完成重建。在基于多视图数据集的重建和新视图基准测试中，在稀疏未校准设置下表现出最先进的性能。

**Conclusion:** Sparfels通过引入高效的3D基础模型利用和创新的颜色方差公式，显著提升了从稀疏未校准图像中进行形状重建的速度和准确性，实现了该领域的最先进性能。

> **ai_Abstract:** 本文提出了Sparfels，一种用于从稀疏未校准图像进行快速形状重建的新方法。该方法利用单一的3D基础模型及其任务头（如点云图和相机初始化）来构建一个捆绑调整的2D高斯溅射（2DGS）模型，并利用图像对应关系优化相机姿态。通过引入一种新颖的沿射线溅射颜色方差公式并将其最小化，实现了更准确的形状重建。该方法在消费级GPU上仅需3分钟，并在稀疏未校准设置下，在重建和新视图合成方面达到了最先进的性能。

> **摘要翻译:** 我们提出了一种基于表面元素溅射的稀疏视图重建方法，该方法在消费级GPU上可在3分钟内运行。虽然很少有方法解决从噪声或未校准的稀疏相机中学习稀疏辐射场的问题，但在此设置下，形状恢复仍然相对未被充分探索。一些辐射场和形状学习的测试时间优化方法通过学习数据先验或使用外部单目几何先验的组合来解决稀疏校准设置。不同的是，我们提出了一种高效且简单的流水线，利用一个单一的最新3D基础模型。我们利用其各种任务头，特别是点云图和相机初始化来实例化一个捆绑调整的2D高斯溅射（2DGS）模型，并利用图像对应来指导2DGS训练中的相机优化。我们贡献的关键在于提出了一种新的沿射线溅射颜色方差的计算公式，该公式可以高效地计算。在训练中减少这一矩可以带来更准确的形状重建。我们基于已建立的多视图数据集，在重建和新视图基准测试中，在稀疏未校准设置下展示了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [504] [DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation](https://arxiv.org/abs/2507.23599)
> *DA-Occ：通过定向2D实现高效三维体素占用预测以保留几何结构*

*Yuchen Zhou, Yan Luo, Xiangang Wang, Xingjian Gu, Mingzhou Lu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D占用预测, 自动驾驶, 定向2D, 几何结构, 实时性

**Comment:** 

> **TL;DR:** 本文提出DA-Occ，一种通过定向2D方法进行高效3D体素占用预测，平衡了自动驾驶中的准确性和推理速度，即使在边缘设备上也能表现良好。

**AI_Comments:** 该论文提出了一种新颖的定向2D方法，通过在2D平面上处理3D体素特征并引入定向注意力机制，有效地解决了3D占用预测中精度与实时性难以兼顾的问题。其创新点在于通过保留垂直几何信息来弥补BEV表示的不足，并实现了在边缘设备上的高效部署，这对于自动驾驶的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的三维占用预测方法在追求高精度的同时牺牲了实时处理能力，这对于自动驾驶系统来说是一个挑战。本文旨在解决精度和推理速度之间的平衡问题。

**Method:** 本文提出一种定向纯2D方法，通过切片3D体素特征来保留完整的垂直几何信息，弥补了鸟瞰图（BEV）表示中高度线索的损失，从而保持3D几何结构的完整性。此外，通过采用定向注意力机制，高效地从不同方向提取几何特征，以平衡精度和计算效率。

**Result:** 在Occ3D-nuScenes数据集上，所提出的DA-Occ方法实现了39.3%的mIoU和27.7 FPS的推理速度，有效平衡了精度和效率。在边缘设备上的仿真中，推理速度达到14.8 FPS，进一步证明了该方法在资源受限环境中的适用性。

**Conclusion:** DA-Occ方法通过其独特的定向2D和注意力机制，成功地在3D体素占用预测中实现了高精度与实时推理速度的平衡，特别适用于自动驾驶系统中的资源受限环境。

> **ai_Abstract:** 本文提出DA-Occ，一种针对自动驾驶系统的高效3D体素占用预测方法。为解决现有方法精度与速度不平衡的问题，DA-Occ采用定向纯2D方法，通过切片3D体素特征并利用定向注意力机制来保持3D几何结构的完整性，同时高效提取特征。实验证明，该方法在Occ3D-nuScenes上实现了高精度（mIoU 39.3%）和快速推理（27.7 FPS），并在边缘设备上达到14.8 FPS，有效平衡了性能与效率。

> **摘要翻译:** 高效、高精度的三维占用预测对于确保自动驾驶（AD）系统的性能至关重要。然而，许多现有方法专注于高精度，却牺牲了实时处理需求。为了解决平衡精度和推理速度的挑战，我们提出了一种定向纯2D方法。我们的方法涉及切片三维体素特征，以保留完整的垂直几何信息。这种策略弥补了鸟瞰图（BEV）表示中高度线索的损失，从而保持了三维几何结构的完整性。通过采用定向注意力机制，我们高效地从不同方向提取几何特征，在精度和计算效率之间取得了平衡。实验结果突出了我们方法在自动驾驶方面的显著优势。在Occ3D-nuScenes数据集上，所提出的方法实现了39.3%的mIoU和27.7 FPS的推理速度，有效平衡了精度和效率。在边缘设备上的仿真中，推理速度达到14.8 FPS，进一步证明了该方法在资源受限环境中实时部署的适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [505] [Robust Adverse Weather Removal via Spectral-based Spatial Grouping](https://arxiv.org/abs/2507.22498)
> *基于光谱空间分组的鲁棒恶劣天气去除*

*Yuhwan Jeong, Yunseo Yang, Youngho Yoon, Kuk-Jin Yoon* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 恶劣天气去除, 光谱分解, 空间分组, Transformer, 图像恢复

**Comment:** accepted by ICCV25

> **TL;DR:** 本文提出SSGformer，一种利用光谱分解和分组注意力的新型Transformer模型，能有效去除图像中各种恶劣天气影响。

**AI_Comments:** 该论文的创新之处在于将光谱分解与空间分组和分组注意力机制相结合，构建了一个Transformer模型来处理多样化和局部化的天气退化，这显著优于传统的全局滤波方法。同时，空间分组Transformer块中对通道注意力和空间注意力的整合，也增强了模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 恶劣天气条件导致多样且复杂的图像退化模式，现有的一体化（AiO）模型在处理这些多样化退化时仍面临挑战，因为全局滤波方法（如直接在频域操作）无法处理高度可变和局部化的失真。

**Method:** 本文提出了基于光谱空间分组的Transformer（SSGformer），这是一种新颖的方法，它利用光谱分解和分组注意力进行多天气图像恢复。SSGformer通过传统的边缘检测将图像分解为高频边缘特征，通过奇异值分解获取低频信息。模型利用多头线性注意力有效建模这些特征之间的关系。融合后的特征与输入集成，生成一个基于空间相似性和图像纹理对区域进行聚类的分组掩码。为了充分利用这个掩码，引入了一种分组注意力机制，实现鲁棒的恶劣天气去除并确保在不同天气条件下的一致性能。此外，还提出了一个空间分组Transformer块，该块同时使用通道注意力和空间注意力，有效平衡特征关系和空间依赖性。

**Result:** 广泛的实验证明了我们方法的优越性，验证了其在处理各种复杂恶劣天气退化方面的有效性。

**Conclusion:** SSGformer有效解决了多样化和局部化天气退化带来的挑战，在各种天气条件下提供了鲁棒且一致的图像恢复性能。

> **ai_Abstract:** SSGformer旨在解决当前一体化（AiO）模型在处理多样恶劣天气条件下的局限性。该模型利用光谱分解将图像分解为高频和低频特征，并通过多头线性注意力建模它们的关系。它生成一个基于空间相似性和纹理的分组掩码，并引入了独特的分组注意力机制，以实现鲁棒的恶劣天气去除。此外，SSGformer还包含一个结合通道和空间注意力的空间分组Transformer块。实验结果表明，该方法在处理各种复杂恶劣天气退化方面表现出卓越的性能。

> **摘要翻译:** 恶劣天气条件导致多样且复杂的退化模式，推动了一体化（AiO）模型的发展。然而，最近的AiO解决方案仍然难以捕捉多样化的退化，因为像直接在频域操作这样的全局滤波方法无法处理高度可变和局部化的失真。为了解决这些问题，我们提出了基于光谱空间分组的Transformer（SSGformer），这是一种新颖的方法，它利用光谱分解和分组注意力进行多天气图像恢复。SSGformer通过传统的边缘检测将图像分解为高频边缘特征，并通过奇异值分解获取低频信息。我们利用多头线性注意力有效建模这些特征之间的关系。融合后的特征与输入集成，生成一个基于空间相似性和图像纹理对区域进行聚类的分组掩码。为了充分利用这个掩码，我们引入了一种分组注意力机制，实现鲁棒的恶劣天气去除并确保在不同天气条件下的一致性能。我们还提出了一个空间分组Transformer块，该块同时使用通道注意力和空间注意力，有效平衡特征关系和空间依赖性。广泛的实验证明了我们方法的优越性，验证了其在处理各种复杂恶劣天气退化方面的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [510] [Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads](https://arxiv.org/abs/2507.23343)
> *谁是更好的“说话者”：AI生成说话人头像的主观和客观质量评估*

*Yingjie Zhou, Jiezhang Cao, Zicheng Zhang, Farong Wen, Yanwei Jiang, Jun Jia, Xiaohong Liu, Xiongkuo Min, Guangtao Zhai* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-31**

**Keywords:** AI生成说话人头像, 质量评估, 主观评估, 客观评估, 数据集

**Comment:** 

> **TL;DR:** 本文提出了迄今为止最大的AI生成说话人头像（AGTH）质量评估数据集THQA-10K，并提出了一个基于首帧、Y-T切片和音唇一致性的客观质量评估方法，该方法在AGTH质量评估中达到了最先进的性能。

**AI_Comments:** 该论文通过构建迄今最大的数据集并结合主客观评估，为AI生成说话人头像的质量评估领域做出了重要贡献。其提出的客观评估方法具有创新性，并通过实验证明达到了SOTA性能，对于推动数字人媒体的发展具有重要意义。数据集的公开也为后续研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到图像（T2I）模型快速发展，AI生成说话人头像（AGTHs）已成为新兴的数字人物媒体，但这些“说话者”及其生成的AGTHs的质量仍存在挑战，且针对这些问题的全面研究有限。

**Method:** 本文构建了迄今为止最大的AGTH质量评估数据集THQA-10K，该数据集包含12个T2I模型和14个先进的“说话者”为14个提示生成的10,457个AGTHs。然后，招募志愿者对AGTHs进行主观评分并给出对应的失真类别。在此基础上，提出了一种基于首帧、Y-T切片和音唇一致性的客观质量评估方法。

**Result:** 在主观实验结果分析中，评估了“说话者”在泛化性和质量方面的性能，并揭示了现有AGTHs的失真。提出的客观质量评估方法在AGTH质量评估中达到了最先进（SOTA）的性能。

**Conclusion:** 本文通过构建大型数据集和提出有效的客观评估方法，显著推进了AI生成说话人头像的质量评估研究，并揭示了现有技术的局限性。

> **ai_Abstract:** 本文针对AI生成说话人头像（AGTHs）的质量评估挑战，构建了迄今为止最大的质量评估数据集THQA-10K（包含10,457个AGTHs），并进行了大规模的主观评估以分析现有“说话者”的性能和AGTHs的失真。在此基础上，提出了一种创新的基于首帧、Y-T切片和音唇一致性的客观质量评估方法，该方法在AGTH质量评估中展现出最先进的性能，为未来AGTHs的开发提供了重要的评估工具和基准。

> **摘要翻译:** 语音驱动的人像方法因其能够合成说话的嘴型和面部动作而被形象地称为“说话者”。特别是随着文本到图像（T2I）模型的快速发展，AI生成说话人头像（AGTHs）已逐渐成为一种新兴的数字人物媒体。然而，这些“说话者”及其生成的AGTHs的质量仍然存在挑战，并且解决这些问题的全面研究仍然有限。为了弥补这一空白，本文提出了迄今为止最大的AGTH质量评估数据集THQA-10K，该数据集选择了12个著名的T2I模型和14个先进的“说话者”为14个提示生成AGTHs。在排除AGTH生成不成功的情况后，THQA-10K数据集包含10,457个AGTHs。然后，招募志愿者对AGTHs进行主观评分并给出相应的失真类别。在我们对主观实验结果的分析中，我们评估了“说话者”在泛化性和质量方面的性能，并揭示了现有AGTHs的失真。最后，提出了一种基于首帧、Y-T切片和音唇一致性的客观质量评估方法。实验结果表明，该方法在AGTH质量评估中可以达到最先进（SOTA）的性能。这项工作已在https://github.com/zyj-2000/Talker 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [512] [Sparse Reconstruction of Optical Doppler Tomography with Alternative State Space Model and Attention](https://arxiv.org/abs/2404.17484)
> *基于替代状态空间模型和注意力的光学多普勒层析稀疏重建*

*Zhenghong Li, Jiaxiang Ren, Wensheng Cheng, Yanzuo Liu, Congwu Du, Yingtian Pan, Haibin Ling* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-30**

**Keywords:** 光学多普勒层析成像, 稀疏重建, 状态空间模型, 注意力机制, 血流成像

**Comment:** MICCAI25, 10 pages, 3 figures

> **TL;DR:** 本文提出了一种名为ASSAN的新型稀疏ODT重建框架，通过结合状态空间模型和注意力机制，有效减少了光学多普勒层析成像所需的原始A扫描数量。

**AI_Comments:** 该论文的创新点在于结合了状态空间模型和注意力机制来处理光学多普勒层析成像中的不同维度信息，有效地实现了稀疏重建。这对于减少ODT的扫描时间和存储需求具有重要意义，有望推动ODT技术在临床和研究中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 光学相干多普勒层析成像（ODT）需要密集的A扫描才能获得高保真B扫描，这导致扫描时间延长和存储需求增加。

**Method:** 本文提出了一种名为ASSAN（Alternative State Space Attention Network）的稀疏ODT重建框架。ASSAN利用1D状态空间模型（SSM）处理每条A扫描以学习A扫描内部表示，同时沿B扫描使用1D门控自注意力机制来捕获A扫描间特征。此外，还采用了一种基于沿不同轴的顺序1D卷积的有效前馈网络来增强局部特征。

**Result:** 在真实动物数据上的验证实验表明，与现有最先进的重建方法相比，ASSAN在重建方面表现出明显的有效性。

**Conclusion:** ASSAN能够有效实现光学多普勒层析成像的稀疏重建，减少扫描时间和存储需求，并提供高保真的B扫描图像。

> **ai_Abstract:** 本文提出了一种名为ASSAN的替代状态空间注意力网络，用于光学多普勒层析成像（ODT）的稀疏重建。该方法旨在解决ODT中密集A扫描导致的扫描时间长和存储需求大的问题。ASSAN结合了1D状态空间模型处理A扫描内部特征和1D门控自注意力机制捕获A扫描间特征，并通过1D卷积增强局部特征。实验结果表明，ASSAN在真实动物数据上实现了有效的稀疏重建，优于现有方法。

> **摘要翻译:** 光学相干多普勒层析成像（ODT）是一种新兴的血流成像技术。ODT的基本单位是名为原始A扫描（或A线）的1D深度分辨轨迹。通过对沿B线的原始A扫描进行多普勒相位减法重建横截面流图像，形成2D ODT图像（B扫描）。为了获得高保真B扫描，目前需要密集采样的A扫描，这导致扫描时间延长和存储需求增加。为了解决这个问题，我们提出了一种新型的稀疏ODT重建框架，即替代状态空间注意力网络（ASSAN），它有效地减少了所需的原始A扫描数量。受A线和B线信息不同分布的启发，ASSAN将1D状态空间模型（SSM）应用于每条A线，以学习A扫描内部表示，同时沿B线使用1D门控自注意力机制来捕获A扫描间特征。此外，还采用了一种基于沿不同轴的顺序1D卷积的有效前馈网络来增强局部特征。在真实动物数据上的验证实验中，与现有最先进的重建方法相比，ASSAN在重建方面表现出明显的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors](https://arxiv.org/abs/2507.22530)
> *HRVVS：一种通过分层自回归残差先验的高分辨率视频脉管分割网络*

*Xincheng Yao, Yijun Yang, Kangwei Guo, Ruiqiang Xiao, Haipeng Zhou, Haisu Tao, Jian Yang, Lei Zhu* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 肝脏脉管分割, 高分辨率视频, 自回归模型, 动态记忆解码器, HRVVS

**Comment:** Accepted by MICCAI 2025

> **TL;DR:** 针对肝切除术中肝脏脉管分割的挑战，本文提出了一个高分辨率视频肝脏脉管分割网络HRVVS，并构建了一个新的高质量数据集。HRVVS通过引入预训练的视觉自回归模型作为先验信息和设计动态记忆解码器，显著优于现有SOTA方法。

**AI_Comments:** 本文的创新点在于构建了高质量的肝脏脉管视频数据集，这对于解决该领域数据稀缺的难题至关重要。同时，提出的HRVVS网络融合了预训练的视觉自回归模型作为先验信息，有效缓解了高分辨率图像下采样带来的信息损失，并利用动态记忆解码器优化了视频帧间的细节保留，这些都是针对视频分割任务的有效改进。其优越的性能和数据集的公开性将对肝脏手术辅助系统及相关研究产生积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 肝切除术中肝脏脉管的分割具有重要的临床意义，但由于缺乏合适的数据集和任务本身的复杂性，该领域的研究较少。

**Method:** 本文首先构建了一个包含35个肝切除视频和11442帧高分辨率图像的高质量肝脏脉管数据集。在此基础上，提出了一种名为HRVVS的高分辨率视频脉管分割网络。该网络创新性地将预训练的视觉自回归建模（VAR）模型作为先验信息嵌入到分层编码器的不同层中，以减少下采样过程中产生的信息退化。此外，还在多视图分割网络上设计了一个动态记忆解码器，以最大限度地减少冗余信息传输，同时保留帧间的更多细节。

**Result:** 在手术视频数据集上的大量实验表明，所提出的HRVVS显著优于现有最先进的方法。

**Conclusion:** 本文通过构建新的数据集和提出创新的HRVVS网络，有效解决了肝脏脉管分割的挑战，并取得了优异的性能，为该领域的研究提供了新的方向和资源。

> **ai_Abstract:** 本文针对肝切除术中肝脏脉管分割面临的数据集匮乏和任务复杂性问题，首次构建了一个大规模高质量的肝脏脉管视频数据集。在此基础上，提出了一种新颖的高分辨率视频脉管分割网络HRVVS。HRVVS通过在编码器中嵌入预训练的视觉自回归模型来利用先验信息减少下采样损失，并设计了动态记忆解码器以优化帧间信息传输。实验结果表明，HRVVS在手术视频数据集上显著超越了现有最先进的方法。

> **摘要翻译:** 肝切除术中手术视频中的肝脏脉管分割具有重要的临床意义。然而，由于缺乏合适的数据集和任务固有的复杂特性，该领域的研究报道较少。为了解决这个问题，我们首先引入了一个高质量的逐帧标注的肝脏脉管数据集，其中包含35个长肝切除视频和11442帧高分辨率图像。在此基础上，我们提出了一种新颖的高分辨率视频脉管分割网络，命名为HRVVS。我们创新性地将预训练的视觉自回归建模（VAR）模型作为先验信息嵌入到分层编码器的不同层中，以减少下采样过程中产生的信息退化。此外，我们还在多视图分割网络上设计了一个动态记忆解码器，以最大限度地减少冗余信息传输，同时保留帧间的更多细节。在手术视频数据集上的大量实验表明，我们提出的HRVVS显著优于现有最先进的方法。源代码和数据集将公开可用，网址为{https://github.com/scott-yjyang/HRVVS}。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [527] [BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation](https://arxiv.org/abs/2505.12620)
> *BusterX：基于多模态大语言模型的AI生成视频伪造检测与解释*

*Haiquan Wen, Yiwei He, Zhenglin Huang, Tianxiao Li, Zihan Yu, Xingru Huang, Lu Qi, Baoyuan Wu, Xiangtai Li, Guangliang Cheng* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** AI生成视频, 伪造检测, 多模态大语言模型, 可解释性, 数据集

**Comment:** 

> **TL;DR:** 本文提出了GenBuster-200K，一个大规模AI生成视频数据集，并引入了BusterX框架，利用多模态大语言模型和强化学习进行AI生成视频伪造检测和解释。

**AI_Comments:** 该论文通过构建大规模高质量数据集GenBuster-200K，并提出创新的BusterX框架，将多模态大语言模型和强化学习引入AI生成视频检测，解决了现有方法在数据集和可解释性方面的两大痛点。其创新性在于首次将MLLM与强化学习结合用于可解释的视频伪造检测，这对于提升公众对数字内容的信任至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI生成模型的发展，超现实视频合成加剧了社交媒体上的信息误导风险，侵蚀了人们对数字内容的信任。当前缺乏大规模、高质量的AI生成视频数据集用于伪造检测，且现有检测方法多为二分类，缺乏模型决策的可解释性，未能提供可操作的见解或指导。

**Method:** 为解决上述挑战，本文提出了GenBuster-200K，一个包含20万高分辨率视频片段、涵盖最新生成技术和真实场景的大规模AI生成视频数据集。此外，还引入了BusterX，一个新颖的AI生成视频检测与解释框架，该框架利用多模态大语言模型（MLLM）和强化学习进行真实性判断和可解释性理由生成。

**Result:** GenBuster-200K是首个结合最新生成技术用于真实场景的大规模高质量AI生成视频数据集。BusterX是首个将多模态大语言模型与强化学习结合用于可解释AI生成视频检测的框架。广泛的与最先进方法的比较和消融研究验证了BusterX的有效性和泛化能力。

**Conclusion:** 该研究通过构建GenBuster-200K数据集和提出BusterX框架，有效解决了AI生成视频伪造检测中数据集不足和缺乏可解释性的问题，并验证了所提出方法的有效性和创新性。

> **ai_Abstract:** 针对AI生成视频伪造带来的信息误导风险及现有检测方法面临的数据集匮乏和解释性不足的问题，本文提出了GenBuster-200K，一个包含20万高分辨率视频片段的大规模高质量AI生成视频数据集。同时，引入了BusterX框架，该框架利用多模态大语言模型（MLLM）和强化学习，实现了对AI生成视频的真实性判断并提供可解释的理由。实验结果证明了BusterX的有效性和泛化能力，且GenBuster-200K和BusterX分别是首个融入最新生成技术的大规模数据集和首个结合MLLM与强化学习的可解释检测框架。

> **摘要翻译:** AI生成模型的技术进步促进了超现实视频的合成，通过社交媒体放大了错误信息的风险，并侵蚀了人们对数字内容的信任。一些研究工作已经探索了AI生成图像上的新型深度伪造检测方法以减轻这些风险。然而，随着Sora和WanX等视频生成模型的快速发展，目前缺乏用于伪造检测的大规模、高质量AI生成视频数据集。此外，现有检测方法主要将任务视为二分类，缺乏模型决策的可解释性，未能为公众提供可操作的见解或指导。为了应对这些挑战，我们提出了GenBuster-200K，一个大规模AI生成视频数据集，包含20万高分辨率视频片段、多样化的最新生成技术和真实世界场景。我们进一步引入了BusterX，一个新颖的AI生成视频检测与解释框架，利用多模态大语言模型（MLLM）和强化学习进行真实性判断和可解释性理由。据我们所知，GenBuster-200K是第一个包含最新生成技术用于真实场景的大规模高质量AI生成视频数据集。BusterX是第一个将MLLM与强化学习集成用于可解释AI生成视频检测的框架。与最先进方法的广泛比较和消融研究验证了BusterX的有效性和泛化能力。代码、模型和数据集将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [530] [Details Matter for Indoor Open-vocabulary 3D Instance Segmentation](https://arxiv.org/abs/2507.23134)
> *细节决定室内开放词汇3D实例分割的成败*

*Sanghun Jung, Jingjing Zheng, Ke Zhang, Nan Qiao, Albert Y. C. Chen, Lu Xia, Chi Liu, Yuyin Sun, Xiao Zeng, Hsiang-Wei Huang, Byron Boots, Min Sun, Cheng-Hao Kuo* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 开放词汇3D实例分割, 视觉-语言模型, Alpha-CLIP, SMS分数, 3D提议聚合

**Comment:** ICCV 2025

> **TL;DR:** 本文提出了一种新的最先进的室内开放词汇3D实例分割解决方案，通过精心设计和结合现有概念并加以改进，在ScanNet200和S3DIS数据集上取得了卓越的性能，甚至超越了闭词汇方法。

**AI_Comments:** 本文的创新点在于其并非提出全新的概念，而是通过“精心设计”的组合和精炼现有概念，并引入了Alpha-CLIP和SMS分数等具体的技术改进，有效解决了开放词汇3D实例分割中的背景噪声和假阳性问题。其超越闭词汇方法的性能，凸显了这种集成和优化策略的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开放词汇3D实例分割（OV-3DIS）方法通常利用视觉-语言模型（VLMs）生成3D实例提议并进行分类，但研究者观察到这些独立的现有概念并非互斥，而是互补的，需要一种更好的方式来结合和优化它们以解决关键挑战。

**Method:** 本文提出了一种两阶段方案：3D提议生成和实例分类。在提议生成阶段，采用鲁棒的3D跟踪式提议聚合来生成3D提议，并通过迭代合并/移除来消除重叠或部分提议。在分类阶段，将标准CLIP模型替换为Alpha-CLIP（通过合并对象掩码作为alpha通道来减少背景噪声并获得以对象为中心的表示），并引入标准化最大相似度（SMS）分数来归一化文本到提议的相似度，以有效过滤假阳性并提高精度。

**Result:** 该框架在ScanNet200和S3DIS数据集的所有AP和AR指标上均取得了最先进的性能，甚至超越了端到端的闭词汇方法。

**Conclusion:** 通过精心设计结合和完善现有概念，并引入Alpha-CLIP和标准化最大相似度（SMS）分数等关键改进，该方法成功解决了开放词汇3D实例分割中的挑战，显著提升了性能，并达到了新的SOTA水平。

> **ai_Abstract:** 本文提出了一种用于室内开放词汇3D实例分割（OV-3DIS）的最先进解决方案。该方案通过精心设计，将现有概念有效结合并加以改进，解决了OV-3DIS中的关键挑战。其采用两阶段方法：首先通过鲁棒的3D跟踪式聚合生成并优化3D提议；其次在分类阶段，使用Alpha-CLIP模型减少背景噪声，并通过标准化最大相似度（SMS）分数过滤假阳性。该方法在ScanNet200和S3DIS数据集上实现了所有AP和AR指标的最优性能，甚至超越了传统的闭词汇方法。

> **摘要翻译:** 与通常进行端到端训练的闭词汇3D实例分割不同，开放词汇3D实例分割（OV-3DIS）通常利用视觉-语言模型（VLMs）来生成3D实例提议并对其进行分类。尽管现有研究提出了各种概念，但我们观察到这些独立的概念并非互斥，而是互补的。在本文中，我们通过精心设计一种方案来结合这些概念并对其进行完善以解决关键挑战，从而提出了一种新的最先进的OV-3DIS解决方案。我们的解决方案遵循两阶段方案：3D提议生成和实例分类。我们采用鲁棒的基于3D跟踪的提议聚合来生成3D提议，并通过迭代合并/移除来消除重叠或部分提议。对于分类阶段，我们将标准CLIP模型替换为Alpha-CLIP，后者将对象掩码作为alpha通道合并以减少背景噪声并获得以对象为中心的表示。此外，我们引入了标准化最大相似度（SMS）分数来归一化文本到提议的相似度，有效过滤假阳性并提高精度。我们的框架在ScanNet200和S3DIS数据集的所有AP和AR指标上均取得了最先进的性能，甚至超越了端到端的闭词汇方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [FovEx: Human-Inspired Explanations for Vision Transformers and Convolutional Neural Networks](https://arxiv.org/abs/2408.02123)
> *FovEx：受人类启发的视觉Transformer和卷积神经网络解释方法*

*Mahadev Prasad Panda, Matteo Tiezzi, Martina Vilas, Gemma Roig, Bjoern M. Eskofier, Dario Zanca* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** XAI, 可解释人工智能, FovEx, 视觉Transformer, 卷积神经网络

**Comment:** Accepted in the International Journal of Computer Vision (Springer
  Nature)

> **TL;DR:** FovEx是一种受人类视觉启发的XAI方法，通过结合生物启发式扰动和梯度来高效生成归因图，在Transformer和CNN上均实现了最先进的解释性能，并与人类注视模式高度对齐。

**AI_Comments:** FovEx的创新之处在于其将人类视觉的“中央凹”概念引入XAI，并巧妙地结合了扰动和梯度两种解释方法的优点，克服了传统方法的局限性。其在多种模型架构上的SOTA表现以及与人类注意力的对齐，显著提升了模型解释的可靠性和直观性，对于增强AI系统的可信度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉解释技术（如基于梯度或类激活的方法）对模型架构依赖性强，而基于扰动的方法计算成本高昂。因此，需要一种高效且模型无关的XAI方法。

**Method:** FovEx通过迭代创建图像的中央凹渲染（受人类视觉启发）来集成生物启发式扰动，并将其与基于梯度的视觉探索相结合，以高效确定感兴趣的位置。这些位置被选择以最大化模型在下游任务上的性能，然后组合生成归因图。

**Result:** FovEx在Transformer模型上（5项指标中的4项）和卷积模型上（5项指标中的3项）均实现了最先进的性能。此外，FovEx生成的解释图与人类注视模式高度对齐（与RISE相比，NSS提高了14%；与GradCAM相比，NSS提高了203%）。

**Conclusion:** FovEx是一种新颖的XAI方法，它通过模仿人类视觉机制，有效地为视觉Transformer和卷积神经网络提供了高质量的解释，显著缩小了人机解释之间的差距。

> **ai_Abstract:** FovEx是一种受人类视觉启发的创新型可解释人工智能（XAI）方法，旨在解决现有视觉解释技术（如梯度或扰动方法）的局限性。它通过迭代生成图像的中央凹渲染，并结合梯度信息来高效识别关键区域，从而生成归因图。FovEx在视觉Transformer和卷积神经网络上均取得了最先进的解释性能，并且其生成的解释图与人类注视模式高度一致，有助于增强人机信任和理解。

> **摘要翻译:** 人工智能可解释性（XAI）仍然是培养机器学习模型信任和理解的关键方面。当前的视觉解释技术，例如基于梯度或基于类激活的方法，通常对特定模型架构表现出强烈的依赖性。相反，基于扰动的方法，尽管与模型无关，但计算成本高昂，因为它们需要对大量前向传播进行模型评估。在这项工作中，我们引入了基于中央凹的解释（FovEx），这是一种受人类视觉启发的新颖XAI方法。FovEx通过迭代创建图像的中央凹渲染，无缝地整合了生物启发式扰动，并将其与基于梯度的视觉探索相结合，以高效确定感兴趣的位置。选择这些位置是为了最大化被解释模型在下游任务上的性能，然后将它们组合起来生成归因图。我们通过对既定基准进行定性和定量评估，提供了全面的评估。我们的方法在Transformer（5项指标中的4项）和卷积模型（5项指标中的3项）上均实现了最先进的性能，展示了其在各种架构中的多功能性。此外，我们展示了FovEx生成的解释图与人类注视模式之间的一致性（与RISE相比，NSS提高了14%；与GradCAM相比，NSS提高了203%）。这种比较增强了我们对FovEx弥合人机解释差距能力的信心。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [545] [IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025](https://arxiv.org/abs/2507.23357)
> *IN45023 计算机视觉中的神经网络设计模式研讨会报告，2025年夏季*

*Radu-Andrei Bourceanu, Neil De La Fuente, Jan Grimm, Andrei Jardan, Andriy Manucharyan, Cornelius Weiss, Roman Pflugfelder* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 神经网络设计模式, 计算机视觉, 生成模型, 自监督学习, 深度学习架构

**Comment:** 

> **TL;DR:** 本报告分析了计算机视觉中神经网络设计模式的演变，通过考察六篇有影响力的论文，涵盖了基础架构、生成模型和自监督学习技术。

**AI_Comments:** 这篇研讨会报告对计算机视觉中神经网络设计模式的重大进展提供了良好的概述。它涵盖了从基础架构到最先进的生成模型和自监督学习的广泛主题。其价值在于综合了多篇关键论文的信息。

<details>
  <summary>Details</summary>

**Motivation:** 分析计算机视觉中关键设计模式的演变。

**Method:** 通过分析六篇有影响力的论文（ResNet、Vision Transformer、生成对抗网络、潜在扩散模型、DINO和掩码自编码器）来回顾计算机视觉中的神经网络设计模式，并描述它们的核心概念和贡献。

**Result:** 报告详细阐述了ResNet通过残差连接解决梯度消失问题；Vision Transformer将Transformer应用于图像块，展示了注意力模型的有效性；生成对抗网络通过对抗训练学习复杂数据分布；潜在扩散模型在潜在空间中去噪，实现高效高保真图像生成；DINO利用自蒸馏框架学习特征；掩码自编码器通过非对称编解码器设计进行大规模视觉模型的预训练。

**Conclusion:** 报告总结了计算机视觉中神经网络设计模式的演变，并探讨了DINO和掩码自编码器等自监督学习技术，它们减少了对标注数据的依赖并提供了可扩展的预训练方法。

> **ai_Abstract:** 本报告通过回顾六篇有影响力的论文，分析了计算机视觉中神经网络设计模式的演变。内容涵盖了ResNet和Vision Transformer等基础图像识别架构，GANs和潜在扩散模型等生成模型，以及DINO和掩码自编码器等自监督学习技术，强调了它们各自在该领域的贡献。

> **摘要翻译:** 本报告通过考察六篇有影响力的论文，分析了计算机视觉中关键设计模式的演变。分析从图像识别的基础架构开始。我们回顾了ResNet，它引入了残差连接以克服梯度消失问题，并能够有效训练更深层的卷积网络。随后，我们考察了Vision Transformer (ViT)，它通过将Transformer架构应用于图像块序列，确立了一种新范式，展示了基于注意力模型在大规模图像识别中的有效性。在这些视觉表示骨干网络的基础上，我们研究了生成模型。生成对抗网络 (GANs) 因其新颖的对抗训练过程而受到分析，该过程使生成器与判别器对抗以学习复杂的数据分布。接着，介绍了潜在扩散模型 (LDMs)，它通过在感知压缩的潜在空间中执行顺序去噪过程，改进了先前的生成方法。LDMs 以更高的计算效率实现了高保真合成，代表了图像生成的当前最先进水平。最后，我们探讨了减少对标注数据依赖的自监督学习技术。DINO是一种自蒸馏框架，其中学生网络学习匹配动量更新教师网络的输出，从而产生具有强大k-NN分类性能的特征。我们以掩码自编码器 (MAE) 作为结尾，它利用非对称编码器-解码器设计来重建严重遮蔽的输入，为大规模视觉模型的预训练提供了一种高度可扩展且有效的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [546] [Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection](https://arxiv.org/abs/2507.23601)
> *基于Mamba的高效时空-频率运动感知用于视频伪装目标检测*

*Xin Li, Keren Fu, Qijun Zhao* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频伪装目标检测, Mamba, 时空-频率, 运动感知, 状态空间模型

**Comment:** 11 pages, 11 figures

> **TL;DR:** Vcamba是一种基于Mamba的模型，通过结合时空和频率特征来提高视频伪装目标检测的准确性和效率。

**AI_Comments:** 该论文的创新之处在于其将空间和频率域特征创新性地融合应用于视频伪装目标检测，特别是利用Mamba状态空间模型实现高效的远程运动感知。这种结合双域特征的方法，配合Mamba的能力，有效解决了伪装检测中前景背景高度相似的挑战，并提升了效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频伪装目标检测（VCOD）方法主要依赖空间外观特征，但由于前景背景相似度高，其辨别能力有限，影响检测精度和完整性。频率特征可以增强表示并感知运动，而新兴的Mamba模型能够高效地建模长序列运动线索。

**Method:** 本文提出了一种新颖的基于Mamba的视觉伪装模型（Vcamba），它集成了频率和空间特征以实现高效准确的VCOD。具体包括：感受野视觉状态空间（RFVSS）模块用于提取多尺度空间特征；自适应频率分量增强（AFE）模块用于频率学习，并采用频域顺序扫描策略；基于空间的远程运动感知（SLMP）模块和基于频率的远程运动感知（FLMP）模块用于建模时空和频率时间序列；以及空间和频率运动融合（SFMF）模块用于整合双域特征。

**Result:** 实验结果表明，Vcamba在两个数据集的6个评估指标上均优于现有最先进的方法，并且计算成本更低。

**Conclusion:** 本文提出的Vcamba通过利用时空-频率运动感知和Mamba的效率，有效提高了视频伪装目标检测的性能，展示了其卓越的性能和效率。

> **ai_Abstract:** 本文提出了一种新颖的基于Mamba的视频伪装目标检测（VCOD）模型Vcamba，旨在解决现有方法仅依赖空间特征的局限性。Vcamba结合了空间和频率特征，并利用Mamba模型高效的长序列运动感知能力。其核心组件包括用于空间特征提取的RFVSS模块、用于频率学习的AFE模块、用于时空和频率时间序列建模的SLMP/FLMP模块，以及用于特征融合的SFMF模块。实验结果表明，Vcamba在准确性和计算成本方面均优于现有最先进的方法。

> **摘要翻译:** 现有视频伪装目标检测（VCOD）方法主要依靠空间外观特征来感知运动线索以打破伪装。然而，VCOD中前景与背景之间的高度相似性导致空间外观特征（如颜色和纹理）的辨别能力有限，从而限制了检测的准确性和完整性。最近的研究表明，频率特征不仅可以增强特征表示以弥补外观限制，还可以通过频率能量的动态变化来感知运动。此外，新兴的状态空间模型Mamba凭借其线性时间长序列建模能力，能够高效感知帧序列中的运动线索。受此启发，我们提出了一种新颖的基于Mamba的视觉伪装模型（Vcamba），它基于时空-频率运动感知，集成了频率和空间特征，以实现高效准确的VCOD。具体来说，我们提出了一个感受野视觉状态空间（RFVSS）模块，用于在序列建模后提取多尺度空间特征。对于频率学习，我们引入了一个自适应频率分量增强（AFE）模块，该模块采用新颖的频域顺序扫描策略来保持语义一致性。然后，我们提出了一个基于空间的远程运动感知（SLMP）模块和一个基于频率的远程运动感知（FLMP）模块，用于在空间和频率相位域中建模时空和频率时间序列。最后，空间和频率运动融合（SFMF）模块整合了双域特征，以实现统一的运动表示。实验结果表明，我们的Vcamba在两个数据集上的6个评估指标上优于现有最先进的方法，并且计算成本更低，证实了Vcamba的优越性。我们的代码可在以下网址获取：https://github.com/BoydeLi/Vcamba。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [554] [SDFit: 3D Object Pose and Shape by Fitting a Morphable SDF to a Single Image](https://arxiv.org/abs/2409.16178)
> *SDFit: 通过将可变形SDF拟合到单张图像来恢复3D物体姿态和形状*

*Dimitrije Antić, Georgios Paschalidis, Shashank Tripathi, Theo Gevers, Sai Kumar Dwivedi, Dimitrios Tzionas* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D物体恢复, 姿态估计, 形状恢复, 可变形SDF, 单张图像

**Comment:** ICCV'25 Camera Ready; 12 pages, 11 figures, 5 tables

> **TL;DR:** SDFit是一个新颖的渲染-比较优化框架，通过将可变形SDF模型拟合到单张图像，从单张图像中恢复3D物体姿态和形状，对遮挡和不常见姿态表现出独特的鲁棒性。

**AI_Comments:** SDFit的创新之处在于其结合了可变形SDF模型与渲染-比较优化框架，提供了一个显式的反馈循环来细化估计，这弥补了现有深度学习方法在泛化性和处理复杂场景（如遮挡）方面的不足。其无需重新训练即可泛化到未见图像的能力是一个显著优势，表明了其在实际应用中的潜力。通过利用mSDF约束形状流形和整合基础模型进行高效检索，该方法有效地平衡了灵活性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 从单张图像中恢复3D物体姿态和形状是一个具有挑战性的不适定问题，原因包括强遮挡、深度模糊、巨大的类内和类间形状差异以及缺乏真实图像的3D真值。现有深度网络方法在合成数据集上训练，泛化到真实世界图像时常遇到困难，缺乏细化噪声估计的显式反馈循环，并且主要关注几何而未直接考虑像素对齐。

**Method:** SDFit是一个新颖的渲染-比较优化框架，具有三个关键创新点：1. 使用学习到的类别特定可变形符号距离函数（mSDF）模型，通过迭代细化3D姿态和形状将其拟合到图像。mSDF通过限制在有效形状流形上的搜索来增强推理，同时允许任意形状拓扑。2. 利用基础模型高效查询3D形状数据库，检索与图像可能匹配的初始3D形状。3. 通过基础特征在图像和mSDF之间建立丰富的2D-3D对应关系来初始化姿态。

**Result:** SDFit在Pix3D、Pascal3D+和COMIC三个图像数据集上进行了评估。对于无遮挡图像和常见姿态，SDFit的性能与最先进的前馈网络相当，但对遮挡和不常见姿态表现出独特的鲁棒性。此外，它不需要对未见过的图像进行重新训练。

**Conclusion:** SDFit为在野外泛化提供了新的见解，通过其新颖的渲染-比较优化框架和可变形SDF模型，有效解决了从单张图像恢复3D姿态和形状的挑战。

> **ai_Abstract:** SDFit提出了一种新颖的渲染-比较优化框架，用于从单张图像中恢复3D物体姿态和形状。该方法克服了现有深度网络在泛化能力和处理遮挡方面的局限性。SDFit的核心在于使用可变形符号距离函数（mSDF）模型，通过迭代优化姿态和形状来拟合图像。它通过利用基础模型进行初始形状检索和通过基础特征建立2D-3D对应关系进行姿态初始化。实验结果表明，SDFit在标准数据集上表现与SotA网络相当，并且在处理遮挡和不常见姿态时展现出卓越的鲁棒性，无需对未见图像进行再训练。

> **摘要翻译:** 从单张图像中恢复3D物体姿态和形状是一个具有挑战性的不适定问题。这是由于强烈的（自）遮挡、深度模糊、巨大的类内和类间形状差异，以及自然图像缺乏3D真值。现有的深度网络方法在合成数据集上训练以预测3D形状，因此它们在泛化到真实世界图像时常常遇到困难。此外，它们缺乏用于细化噪声估计的显式反馈循环，并且主要关注几何而未直接考虑像素对齐。为了解决这些限制，我们开发了一个名为SDFit的新颖的渲染-比较优化框架。它有三个关键创新点：首先，它使用学习到的类别特定可变形符号距离函数（mSDF）模型，并通过迭代细化3D姿态和形状将其拟合到图像。mSDF通过限制在有效形状流形上的搜索来增强推理，同时允许任意形状拓扑。其次，SDFit通过利用基础模型高效查询3D形状数据库来检索可能与图像匹配的初始3D形状。第三，SDFit通过基础特征在图像和mSDF之间建立丰富的2D-3D对应关系来初始化姿态。我们在三个图像数据集（即Pix3D、Pascal3D+和COMIC）上评估了SDFit。对于无遮挡图像和常见姿态，SDFit的性能与最先进的前馈网络相当，但对遮挡和不常见姿态表现出独特的鲁棒性。此外，它不需要对未见过的图像进行重新训练。因此，SDFit为在野外泛化提供了新的见解。代码可在https://anticdimi.github.io/sdfit获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [569] [Uncovering Cultural Representation Disparities in Vision-Language Models](https://arxiv.org/abs/2505.14729)
> *揭示视觉-语言模型中的文化表征差异*

*Ram Mohan Rao Kadiyala, Siddhant Gupta, Jebish Purbey, Srishti Yadav, Suman Debnath, Alejandro Salamanca, Desmond Elliott* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视觉-语言模型, 文化偏见, 图像识别, 数据集偏见, 泛化能力

**Comment:** 28 pages, 36 figures

> **TL;DR:** 研究发现视觉-语言模型在图像国家识别任务中存在文化偏见，性能因国家和提问方式而异，表明偏见源于预训练数据。

**AI_Comments:** 这项研究通过系统性地评估VLMs在文化敏感任务中的表现，揭示了其内在的文化偏见，具有重要的实践意义。它强调了在模型训练和评估中考虑文化多样性的必要性，对未来构建更公平、更具包容性的AI模型提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言模型（VLMs）虽能力强大，但存在潜在偏见。本研究旨在调查主流VLMs在图像国家识别任务中表现出的文化偏见程度。

**Method:** 使用地理多元的Country211数据集，在开放式问题、多项选择题（包括多语言和对抗性设置）等多种提示策略下，评估多个大型视觉-语言模型在国家层面的图像国家识别任务上的性能。

**Result:** 分析揭示了模型在不同国家和问题格式上的准确性存在显著差异，表明VLMs的性能变化很大。

**Conclusion:** 视觉-语言模型虽然具有显著的视觉理解能力，但它们从预训练数据和规模中继承了偏见，这些偏见影响了它们在全球多样化语境中统一泛化的能力。

> **ai_Abstract:** 本文研究了视觉-语言模型（VLMs）中的文化偏见问题。通过在Country211数据集上，采用多种提问方式对VLMs进行图像国家识别任务的评估，发现模型在不同国家和问题格式上存在显著的准确性差异。研究结果表明，VLMs的性能受到预训练数据偏见的影响，限制了其在全球多样化背景下的泛化能力。

> **摘要翻译:** 视觉-语言模型（VLMs）在一系列任务中展示了令人印象深刻的能力，但对其潜在偏见的担忧依然存在。这项工作通过在国家层面评估主流VLMs在基于图像的国家识别任务中的表现，来调查它们表现出文化偏见的程度。我们利用地理多样化的Country211数据集，在各种提示策略下（开放式问题、多项选择题，包括多语言和对抗性设置等挑战性设置）探究了几个大型视觉-语言模型。我们的分析旨在揭示模型在不同国家和问题格式上的准确性差异，从而提供关于训练数据分布和评估方法如何影响VLMs中文化偏见的见解。研究结果突出显示了性能上的显著差异，表明尽管VLMs拥有相当大的视觉理解能力，但它们从预训练数据和规模中继承了偏见，这些偏见影响了它们在多样化全球语境中统一泛化的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [574] [DivControl: Knowledge Diversion for Controllable Image Generation](https://arxiv.org/abs/2507.23620)
> *DivControl：可控图像生成中的知识分流*

*Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 可控图像生成, 扩散模型, 知识分流, ControlNet, 零样本泛化

**Comment:** 

> **TL;DR:** DivControl提出了一种可分解的预训练框架，通过SVD分解ControlNet并进行知识分流，实现了统一的可控图像生成和高效的新条件适应，显著降低了训练成本并提升了性能。

**AI_Comments:** DivControl的创新之处在于其通过SVD分解ControlNet并引入知识分流机制，实现了模型参数的有效解耦，从而解决了现有方法在多条件可控生成中泛化能力差和适应成本高的问题。其提出的动态门和表示对齐损失进一步提升了模型的零样本泛化能力和训练效率。这项工作为构建更高效、更灵活的可控生成模型提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在文本到图像（T2I）和图像到图像（I2I）生成中，通过结合深度图等结构化输入实现了细粒度空间控制。然而，这些方法要么为每个条件单独训练模型，要么依赖于表示纠缠的统一架构，导致对新条件的泛化能力差和适应成本高。

**Method:** DivControl是一个可分解的预训练框架，用于统一的可控生成和高效适应。它通过SVD将ControlNet分解为基本组件（奇异向量对），并通过多条件训练中的知识分流将其解耦为条件无关的学习基因（learngenes）和条件特定的裁缝（tailors）。知识分流通过一个动态门实现，该门根据条件指令的语义对裁缝进行软路由，从而实现零样本泛化和对新条件的参数高效适应。此外，引入了表示对齐损失，将条件嵌入与早期扩散特征对齐，以提高条件保真度和训练效率。

**Result:** DivControl在可控性方面达到了最先进的水平，训练成本降低了36.4倍，同时提高了基本条件的平均性能。它还在未见条件上表现出强大的零样本和少样本性能，展示了卓越的可扩展性、模块化和可迁移性。

**Conclusion:** DivControl通过其创新的分解和知识分流机制，为可控图像生成提供了一个高效、可扩展且泛化能力强的新范式，显著降低了训练成本并提升了对新条件的适应能力。

> **ai_Abstract:** 本文提出了DivControl，一个针对可控图像生成的创新可分解预训练框架。该方法通过SVD将ControlNet分解并利用知识分流将参数解耦为条件无关和条件特定部分，并通过动态门实现零样本泛化和高效适应。结合表示对齐损失，DivControl显著降低了训练成本，提升了基本条件性能，并在新条件下展现出强大的零样本和少样本能力，体现了其卓越的可扩展性和可迁移性。

> **摘要翻译:** 扩散模型已经从文本到图像（T2I）发展到图像到图像（I2I）生成，通过结合深度图等结构化输入，实现了细粒度空间控制。然而，现有方法要么为每个条件单独训练模型，要么依赖于表示纠缠的统一架构，导致对新条件的泛化能力差和适应成本高。为此，我们提出了DivControl，一个可分解的预训练框架，用于统一的可控生成和高效适应。DivControl通过SVD将ControlNet分解为基本组件——奇异向量对——在多条件训练期间通过知识分流将其解耦为条件无关的学习基因（learngenes）和条件特定的裁缝（tailors）。知识分流通过一个动态门实现，该门根据条件指令的语义对裁缝进行软路由，从而实现零样本泛化和对新条件的参数高效适应。为了进一步提高条件保真度和训练效率，我们引入了一种表示对齐损失，将条件嵌入与早期扩散特征对齐。大量实验表明，DivControl在可控性方面达到了最先进的水平，训练成本降低了36.4倍，同时提高了基本条件的平均性能。它还在未见条件上表现出强大的零样本和少样本性能，展示了卓越的可扩展性、模块化和可迁移性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [579] [X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention](https://arxiv.org/abs/2507.23143)
> *X-NeMo：通过解耦潜在注意力实现富有表现力的神经运动重演*

*Xiaochen Zhao, Hongyi Xu, Guoxian Song, You Xie, Chenxu Zhang, Xiu Li, Linjie Luo, Jinli Suo, Yebin Liu* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 人像动画, 零样本, 扩散模型, 身份泄露, 运动重演

**Comment:** ICLR 2025, code is available at
  https://github.com/bytedance/x-nemo-inference

> **TL;DR:** X-NeMo是一种零样本扩散模型，通过解耦的1D潜在运动描述符和交叉注意力实现富有表现力的人像动画，有效解决了身份泄露问题。

**AI_Comments:** X-NeMo的创新点在于其独特的1D身份无关潜在运动描述符和通过交叉注意力进行运动控制的设计，这有效解决了人像动画中长期存在的身份泄露问题。其端到端学习且不依赖预训练运动检测器的特性，也展现了其通用性和鲁棒性。该方法在零样本设置下实现了高表现力和身份相似性，对虚拟形象、娱乐等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法存在身份泄露和难以捕捉细微及极端表情的问题。

**Method:** 提出X-NeMo，一个新颖的零样本扩散式人像动画流水线。该方法引入了一个完全端到端训练的框架，从驱动图像中提取1D身份无关的潜在运动描述符，并通过交叉注意力在图像生成过程中有效控制运动。其隐式运动描述符能够捕捉细致的面部表情，并从多样化视频数据集中端到端学习，不依赖预训练运动检测器。通过使用双GAN解码器以及空间和颜色增强来监督学习，进一步增强表现力并解耦运动潜在变量与身份线索。通过将驱动运动嵌入1D潜在向量并通过交叉注意力而非附加空间引导来控制运动，该设计显著减轻了身份泄露。

**Result:** X-NeMo超越了现有最新技术基线，产生了高度富有表现力的动画，并具有卓越的身份相似性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** X-NeMo是一种新颖的零样本扩散式人像动画方法，旨在解决现有技术中身份泄露和表情捕捉不足的问题。它通过一个端到端训练框架，从驱动视频中提取1D身份无关的潜在运动描述符，并利用交叉注意力在图像生成中精确控制面部运动。该方法通过解耦运动和身份信息，并结合双GAN解码器和数据增强，显著提高了动画的表现力和身份保持性。实验证明，X-NeMo在生成富有表现力且身份相似度高的人像动画方面优于现有最先进的方法。

> **摘要翻译:** 我们提出了X-NeMo，一种新颖的零样本扩散式肖像动画流水线，它使用来自不同个体的驱动视频中的面部动作来动画化静态肖像。我们的工作首先识别了先前方法中关键问题的根本原因，例如身份泄露以及难以捕捉细微和极端表情。为了解决这些挑战，我们引入了一个完全端到端训练的框架，该框架从驱动图像中提取1D身份无关的潜在运动描述符，在图像生成过程中通过交叉注意力有效控制运动。我们的隐式运动描述符能够捕捉细致的面部表情运动，并从多样化的视频数据集中端到端学习，不依赖预训练的运动检测器。我们通过使用双GAN解码器以及空间和颜色增强来监督它们的学习，进一步增强了表现力并解耦了运动潜在变量与身份线索。通过将驱动运动嵌入1D潜在向量并通过交叉注意力而非附加空间引导来控制运动，我们的设计消除了将空间对齐的结构线索从驱动条件传输到扩散骨干网络，从而显著减轻了身份泄露。广泛的实验表明，X-NeMo超越了最先进的基线，生成了高度富有表现力且身份相似性卓越的动画。我们的代码和模型可供研究使用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [580] [Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers](https://arxiv.org/abs/2507.23362)
> *Short-LVLM：通过剪枝冗余层压缩和加速大型视觉-语言模型*

*Ji Ma, Wei Suo, Peng Wang, Yanning Zhang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 大型视觉-语言模型, 模型压缩, 层剪枝, 视觉-语言Token, Short-LVLM

**Comment:** Accepted By ACM MM 25

> **TL;DR:** 大型视觉-语言模型（LVLMs）因参数量大和计算成本高而受限。本文发现直接应用NLP层剪枝方法对LVLMs无效，并提出了Short-LVLM框架。该框架通过利用重要视觉-语言（VL）token和缓解层间特征差距，实现了性能与效率的优越权衡，并具有免训练、模型无关和高兼容性等优点。

**AI_Comments:** 这项工作针对大型视觉-语言模型（LVLMs）的实际应用瓶颈——高计算成本和庞大参数量，提出了创新的层剪枝解决方案。其创新点在于：1. 明确指出并验证了NLP层剪枝方法对LVLM的无效性及其原因（VL token和层间特征差距）。2. 提出Short-LVLM框架，针对性地解决了这些挑战，实现了性能与效率的平衡。其重要性在于提供了一种训练无关、模型无关且高度兼容的LVLM压缩和加速方法，有望推动LVLMs在资源受限环境下的部署。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型视觉-语言模型（LVLMs）在多模态理解和推理方面表现出色，但其庞大的模型参数和高计算成本限制了实际应用。自然语言处理（NLP）领域的层剪枝技术虽有效，但由于视觉和语言的模态差异，其在LVLMs中的有效性尚不明确。

**Method:** 本文首先经验性地证明了直接将NLP中的层剪枝方法应用于LVLMs是无效的。通过大量实验，发现非必需的视觉-语言（VL）token和层间特征差距是LVLM中层剪枝的关键挑战。基于这些发现，提出了一种新颖的框架Short-LVLM（SVL），该框架能够利用重要的VL token并缓解层级特征差距。

**Result:** Short-LVLM不仅在性能和效率之间取得了优越的权衡，而且还展现出训练无关、模型无关和高度兼容等潜在优势。

**Conclusion:** 本文提出Short-LVLM框架，有效解决了大型视觉-语言模型中层剪枝的挑战，实现了性能和效率的平衡，并具有训练无关、模型无关和高度兼容的优点。

> **ai_Abstract:** 大型视觉-语言模型（LVLMs）因其高成本而限制了应用。本文发现直接将NLP的层剪枝技术应用于LVLMs无效，主要原因是存在非必需的视觉-语言（VL）token和层间特征差距。为此，提出Short-LVLM框架，通过利用重要VL token和缓解层级特征差距来解决这些问题。实验表明，Short-LVLM在性能与效率之间实现了优越的权衡，并具有免训练、模型无关和高度兼容的优点，为LVLMs的压缩和加速提供了有效方案。

> **摘要翻译:** 尽管大型视觉-语言模型（LVLMs）在多模态理解和推理方面展现出令人印象深刻的能力，但其实际应用仍受到庞大模型参数和高计算成本的限制。自然语言处理（NLP）领域最近的研究表明层剪枝的有效性，提供了一种可行的免训练压缩解决方案。然而，由于视觉和语言之间的模态差异，目前尚不清楚这些NLP技术在LVLMs中是否仍然有效。在本文中，我们经验性地证明直接将这些层剪枝方法应用于LVLMs是无效的。通过大量实验，我们发现非必需的视觉-语言（VL）token和层间特征差距对LVLM中的层剪枝构成了关键挑战。基于这些见解，我们提出了一种新颖的框架Short-LVLM（SVL），该框架可以利用重要的VL token并缓解层级特征差距。值得注意的是，Short-LVLM不仅在性能和效率之间取得了优越的权衡，而且还展现出多项潜在优势，即免训练、模型无关和高度兼容。本工作的代码已在https://github.com/ASGO-MM/Short-LVLM 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [581] [FLOAT: Generative Motion Latent Flow Matching for Audio-driven Talking Portrait](https://arxiv.org/abs/2412.01064)
> *FLOAT：基于生成运动潜在流匹配的音频驱动人像生成*

*Taekyung Ki, Dongchan Min, Gyeongsu Chae* | **Category: cs.CV, cs.AI, cs.LG, cs.MM, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 音频驱动人像生成, 流匹配, 运动潜在空间, 视频动画, 生成模型

**Comment:** ICCV 2025. Project page:
  https://deepbrainai-research.github.io/float/

> **TL;DR:** FLOAT是一种新的音频驱动人像视频生成方法，它使用流匹配和运动潜在空间来提高视频生成的时间一致性和效率。

**AI_Comments:** 该论文的创新点在于将流匹配生成模型应用于音频驱动的人像动画，并引入了独特的运动潜在空间，有效解决了扩散模型在时间一致性和采样效率上的局限。结合Transformer和情感增强机制，使得生成的视频更加自然和富有表现力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于扩散的生成模型在人像图像动画方面表现出色，但在时间一致的视频生成和快速采样方面仍面临挑战。

**Method:** 本文提出了FLOAT，一种基于流匹配生成模型的音频驱动说话人像视频生成方法。该方法利用学习到的正交运动潜在空间，而非像素级潜在空间，以实现时间一致运动的高效生成和编辑。引入了基于Transformer的矢量场预测器和有效的逐帧条件机制。此外，该方法支持语音驱动的情感增强。

**Result:** 广泛的实验表明，FLOAT在视觉质量、运动保真度和效率方面均优于最先进的音频驱动说话人像方法。

**Conclusion:** FLOAT通过利用运动潜在空间和流匹配，有效解决了音频驱动人像视频生成中的时间一致性和效率问题，并取得了优异的性能。

> **ai_Abstract:** 本文提出FLOAT，一种用于音频驱动说话人像视频生成的新方法。针对现有扩散模型在时间一致性和采样速度上的不足，FLOAT利用流匹配生成模型和学习到的正交运动潜在空间，而非传统的像素级空间，以实现高效且时间一致的运动生成。该方法结合了基于Transformer的矢量场预测器和逐帧条件机制，并支持语音驱动的情感增强。实验证明，FLOAT在视觉质量、运动保真度和效率方面均超越了现有SOTA方法。

> **摘要翻译:** 随着基于扩散的生成模型的快速发展，人像图像动画取得了显著成果。然而，由于其迭代采样性质，它在时间一致的视频生成和快速采样方面仍然面临挑战。本文提出了FLOAT，一种基于流匹配生成模型的音频驱动说话人像视频生成方法。我们利用学习到的正交运动潜在空间，而非基于像素的潜在空间，从而实现时间一致运动的高效生成和编辑。为了实现这一点，我们引入了一个基于Transformer的矢量场预测器，并辅以有效的逐帧条件机制。此外，我们的方法支持语音驱动的情感增强，从而能够自然地融入富有表现力的动作。大量的实验表明，我们的方法在视觉质量、运动保真度和效率方面优于最先进的音频驱动说话人像方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [582] [Understanding implementation pitfalls of distance-based metrics for image segmentation](https://arxiv.org/abs/2410.02630)
> *了解用于图像分割的基于距离度量的实现陷阱*

*Gasper Podobnik, Tomaz Vrtovec* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 图像分割, 距离度量, Hausdorff距离, 实现差异, 开源工具

**Comment:** 

> **TL;DR:** 基于距离的图像分割度量在不同开源工具中存在显著实现差异，导致结果不可靠，需谨慎选择和改进。

**AI_Comments:** 这项研究非常重要，它揭示了在科学研究中常常被忽视但却至关重要的“实现细节”问题。通过系统地分析和量化不同开源工具在计算相同度量时的差异，该论文有力地证明了这些看似微小的差异如何能导致巨大的结果偏差，甚至影响到统计显著性。这对于依赖这些度量进行评估、基准测试和临床决策的（生物）医学图像领域具有深远的警示意义。论文不仅指出了问题，还提供了实用建议，并为未来的工具开发指明了方向，具有很强的实践指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 距离度量（如Hausdorff距离）在医学图像分割验证中广泛使用，但其实现复杂，开源工具间的关键差异未被社区充分认识，这些差异会损害基准测试、引入生物标记物计算偏差，并可能扭曲医疗设备开发和临床调试。

**Method:** 系统地剖析了11个实现距离度量计算的开源工具，通过对其计算步骤进行概念分析和在代表性二维和三维图像数据集上的经验分析。

**Result:** 观察到HD偏差超过100毫米，并识别出工具之间存在多个统计学上的显著差异，表明仅通过选择特定实现就可以在同一组分割上实现统计学上的显著改进。

**Conclusion:** 这些发现对先前研究之间未考虑度量实现差异的结果比较的有效性提出了质疑。研究提供了工具选择的实用建议，并且概念分析为未来开源工具的实现演进提供了信息。

> **ai_Abstract:** 本研究揭示了医学图像分割中基于距离的度量（如Hausdorff距离）在不同开源工具实现中存在的严重差异。通过对11个工具进行概念和经验分析，发现这些差异导致显著的结果偏差，甚至能仅通过选择工具就实现“统计学显著”的改进。这严重影响了基准测试和生物标记物计算的可靠性，并对以往未考虑实现差异的研究结果有效性提出质疑。研究提供了工具选择建议，并为未来开源工具的开发提供了方向。

> **摘要翻译:** 基于距离的度量，例如Hausdorff距离（HD），被广泛用于验证（生物）医学图像中的分割性能。然而，它们的实现很复杂，并且开源工具之间的关键差异在社区中仍未被充分认识。这些差异破坏了基准测试工作，在生物标志物计算中引入了偏差，并可能扭曲医疗设备开发和临床调试。在这项研究中，我们系统地剖析了11个实现基于距离度量计算的开源工具，通过对其计算步骤进行概念分析和在代表性二维和三维图像数据集上进行经验分析。令人震惊的是，我们观察到HD偏差超过100毫米，并识别出工具之间存在多个统计学上的显著差异——这表明只需选择特定的实现，就可以在同一组分割上实现统计学上的显著改进。这些发现对先前研究之间未考虑度量实现差异的结果比较的有效性提出了质疑。为了解决这个问题，我们为工具选择提供了实用建议；此外，我们的概念分析为未来开源工具的实现演进提供了信息。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [602] [FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks](https://arxiv.org/abs/2507.23643)
> *FFGAF-SNN: 基于前向-前向的无梯度近似训练脉冲神经网络框架*

*Changqing Xu, Ziqiang Yang, Yi Liu, Xinfang Liao, Guiqi Mo, Hao Zeng, Yintang Yang* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 脉冲神经网络, 前向-前向, 无梯度近似, 训练框架, 节能计算

**Comment:** 

> **TL;DR:** 本文提出FFGAF-SNN，一个基于前向-前向的无梯度近似训练框架，旨在解决脉冲神经网络（SNNs）训练中的挑战，并在多个基准数据集上取得了超越现有FF-based SNN方法的性能。

**AI_Comments:** 该论文的创新点在于提出了一个无需梯度近似的SNN训练框架，这对于解决SNNs的非可微性问题和降低计算复杂度至关重要，尤其有利于SNNs在边缘设备上的部署。其提出的类别感知复杂度适应机制也增强了模型的效率和资源分配能力，使其在性能和效率上都表现突出。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲神经网络（SNNs）因其节能特性在神经形态计算中具有潜力，但其非可微性导致训练困难。现有梯度近似方法常牺牲精度，且反向传播的高计算需求限制了SNNs在边缘设备上的部署。

**Method:** 提出FFGAF-SNN框架，基于前向-前向（FF）算法，将脉冲激活视为黑盒模块，从而无需梯度近似，显著降低计算复杂度。此外，引入类别感知复杂度适应机制，根据类间难度动态优化损失函数，实现网络资源高效分配。

**Result:** 在MNIST、Fashion-MNIST和CIFAR-10数据集上分别实现了99.58%、92.13%和75.64%的测试精度，超越了所有现有基于FF的SNN方法。同时，在内存访问和计算功耗方面也表现出显著优势。

**Conclusion:** FFGAF-SNN框架有效解决了脉冲神经网络训练中的非可微性和高计算成本问题，在精度、内存效率和计算功耗方面均优于现有基于FF的SNN方法。

> **ai_Abstract:** 本文提出FFGAF-SNN，一个基于前向-前向的无梯度近似脉冲神经网络训练框架，旨在解决SNNs训练中非可微性和高计算成本的挑战。该框架将脉冲激活视为黑盒，避免了梯度近似，并引入类别感知复杂度适应机制以优化资源分配。实验证明，FFGAF-SNN在多个数据集上取得了超越现有FF-based SNN方法的精度，并在内存和功耗方面具有显著优势。

> **摘要翻译:** 脉冲神经网络（SNNs）为节能神经形态计算提供了一个生物学上可行的框架。然而，由于其不可微性，高效训练SNNs是一个挑战。现有的梯度近似方法经常牺牲精度，并且由于反向传播的巨大计算需求，在边缘设备上面临部署限制。为了解决这些挑战，我们提出了一种基于前向-前向（FF）的无梯度近似脉冲神经网络训练框架，该框架将脉冲激活视为黑盒模块，从而消除了对梯度近似的需求，同时显著降低了计算复杂度。此外，我们引入了一种类别感知复杂度适应机制，该机制基于类间难度指标动态优化损失函数，从而实现在不同类别之间高效分配网络资源。实验结果表明，我们提出的训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上分别达到了99.58%、92.13%和75.64%的测试精度，超越了所有现有的基于FF的SNN方法。此外，我们提出的方法在内存访问和计算功耗方面也表现出显著优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [610] [LidaRefer: Context-aware Outdoor 3D Visual Grounding for Autonomous Driving](https://arxiv.org/abs/2411.04351)
> *LidaRefer: 自动驾驶中上下文感知的室外3D视觉定位*

*Yeong-Seung Baek, Heung-Seon Oh* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D视觉定位, 上下文感知, 自动驾驶, LiDAR, 伪标签

**Comment:** 18 pages, 5 figures

> **TL;DR:** 提出LidaRefer框架，通过上下文感知和新颖的监督策略，解决了室外3D视觉定位的挑战，并在Talk2Car-3D数据集上达到SOTA性能。

**AI_Comments:** 该论文的创新点在于其针对室外3D视觉定位的特有挑战，提出了上下文感知框架LidaRefer，特别是在处理大规模LiDAR数据和利用参照上下文方面。DiSCo监督策略和伪标签方法的引入，有效解决了数据稀缺和复杂空间关系建模的问题，对自动驾驶领域的3D视觉感知具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 室外3D视觉定位由于大规模LiDAR场景背景点多、前景信息有限导致跨模态对齐和上下文理解困难，以及大多数室外数据集缺乏参照非目标对象的空间标注而发展不足。

**Method:** 提出LidaRefer框架，包含：1) 对象中心特征选择策略，聚焦语义相关视觉特征并减少计算开销；2) 基于Transformer的编解码器架构，实现精细的跨模态对齐和全局上下文捕获；3) 判别-支持协作定位（DiSCo）监督策略，明确建模目标、上下文和模糊对象间的空间关系；4) 伪标签方法，为参照非目标对象检索3D定位标签。

**Result:** LidaRefer在Talk2Car-3D数据集的各种评估设置下实现了最先进的性能。

**Conclusion:** LidaRefer通过其上下文感知设计和新颖的监督策略，有效克服了室外3D视觉定位的挑战，并显著提升了性能。

> **ai_Abstract:** 本文提出了LidaRefer，一个针对自动驾驶中室外3D视觉定位的上下文感知框架。该框架旨在解决室外LiDAR场景中跨模态对齐和上下文理解困难以及缺乏非目标对象空间标注的问题。LidaRefer结合了对象中心特征选择、基于Transformer的编解码器架构以及判别-支持协作定位（DiSCo）监督策略，并通过伪标签方法解决了数据标注难题。实验证明，LidaRefer在Talk2Car-3D数据集上达到了最先进的性能。

> **摘要翻译:** 3D视觉定位（VG）旨在根据自然语言描述在3D场景中定位对象或区域。尽管室内3D VG已取得进展，但室外3D VG由于两个挑战仍未得到充分探索：(1) 大规模室外LiDAR场景由背景点主导，前景信息有限，使得跨模态对齐和上下文理解更加困难；(2) 大多数室外数据集缺乏参照非目标对象的空间标注，这阻碍了参照上下文的显式学习。
为此，我们提出了LidaRefer，一个用于室外场景的上下文感知3D VG框架。LidaRefer采用对象中心特征选择策略，专注于语义相关的视觉特征，同时减少计算开销。然后，其基于Transformer的编解码器架构擅长在精炼的视觉特征和词级文本特征之间建立细粒度的跨模态对齐，并捕获全面的全局上下文。此外，我们提出了判别-支持协作定位（DiSCo），一种新颖的监督策略，它明确建模目标、上下文和模糊对象之间的空间关系，以实现准确的目标识别。为了在没有手动标注的情况下实现这一点，我们引入了一种伪标签方法，用于检索参照非目标对象的3D定位标签。LidaRefer在Talk2Car-3D数据集的各种评估设置下实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [611] [YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation](https://arxiv.org/abs/2505.20884)
> *YOLO-FireAD：通过注意力引导的倒残差学习和双池化特征保留实现高效火灾检测*

*Weichao Pan, Bohan Xu, Xu Wang, Chengze Lv, Shuoyang Wang, Zhenke Duan, Zhen Tian* | **Category: cs.CV** | **Updated: 2025-08-01**

**Keywords:** 火灾检测, YOLO-FireAD, 注意力机制, 倒残差, 双池化

**Comment:** 2025 International Conference on Intelligent Computing (ICIC 2025)

> **TL;DR:** YOLO-FireAD提出了一种新的高效火灾检测模型，通过注意力引导的倒残差块和双池化下采样融合块，解决了现有YOLO模型中的特征提取限制和信息丢失问题，并在参数量和mAP75上优于主流模型。

**AI_Comments:** 本文提出的YOLO-FireAD模型在实时火灾检测领域具有显著创新性。它通过引入注意力机制和改进的特征融合策略，有效解决了传统YOLO模型在复杂环境下的误检、漏检以及小目标检测困难等问题。特别是在保持模型轻量化的同时，实现了性能的提升，这对于实际部署具有重要意义。其核心贡献在于AIR和DPDF模块的设计，它们分别从特征增强和多尺度信息保留两方面提升了模型的鲁棒性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 在动态环境中，火灾检测面临持续挑战，包括光照变化干扰、高误报或漏报，以及难以同时实现效率和准确性。现有基于YOLO的模型存在特征提取受限和信息丢失问题。

**Method:** 本研究提出了YOLO-FireAD模型，包含两项核心创新：1. 注意力引导的倒残差块（AIR）：结合混合通道-空间注意力与倒残差，自适应增强火灾特征并抑制环境噪声。2. 双池化下采样融合块（DPDF）：通过可学习的max-average池化输出融合，保留多尺度火灾模式，缓解小火灾检测失败。

**Result:** 在两个公共数据集上的广泛评估显示，YOLO-FireAD模型性能高效。其参数总量为1.45M（比YOLOv8n低51.8%），GFLOPs为4.6G（比YOLOv8n低43.2%），mAP75比主流实时目标检测模型YOLOv8n、YOLOv9t、YOLOv10n、YOLOv11n、YOLOv12n以及其他YOLOv8变体高1.3-5.5%。

**Conclusion:** 本研究提出的YOLO-FireAD模型通过其创新性的AIR和DPDF模块，有效解决了现有YOLO模型在火灾检测中面临的挑战，实现了在保持高效性的同时，提升了检测准确率。

> **ai_Abstract:** 本论文提出了一种名为YOLO-FireAD的高效火灾检测模型，旨在解决动态环境中火灾检测的挑战以及现有YOLO模型在特征提取和信息丢失方面的局限性。YOLO-FireAD通过引入注意力引导的倒残差块（AIR）和双池化下采样融合块（DPDF）进行创新。AIR模块利用混合通道-空间注意力增强火灾特征并抑制噪声，而DPDF模块通过融合多尺度池化输出来保留小火灾模式。实验结果表明，YOLO-FireAD在保持较低参数量和计算量的同时，其检测精度（mAP75）优于多种主流YOLO系列模型。

> **摘要翻译:** 在动态环境中，火灾检测面临持续挑战，包括光照变化的干扰、大量的误报或漏报，以及难以同时实现效率和准确性。为解决现有基于YOLO模型中特征提取受限和信息丢失的问题，本研究提出了YOLO-FireAD（You Only Look Once for Fire Detection with Attention-guided Inverted Residual and Dual-pooling Downscale Fusion），包含两项核心创新：(1) 注意力引导的倒残差块（AIR）集成了混合通道-空间注意力与倒残差，以自适应地增强火灾特征并抑制环境噪声；(2) 双池化下采样融合块（DPDF）通过可学习的max-average池化输出融合，保留多尺度火灾模式，从而缓解小火灾检测失败。在两个公共数据集上的广泛评估显示了我们模型的高效性能。我们提出的模型参数总量为1.45M（比YOLOv8n低51.8%），计算量为4.6G（比YOLOv8n低43.2%），并且mAP75高于主流实时目标检测模型YOLOv8n、YOLOv9t、YOLOv10n、YOLOv11n、YOLOv12n以及其他YOLOv8变体1.3-5.5%。更多详情，请访问我们的仓库：https://github.com/JEFfersusu/YOLO-FireAD

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [615] [VMatcher: State-Space Semi-Dense Local Feature Matching](https://arxiv.org/abs/2507.23371)
> *VMatcher：状态空间半稠密局部特征匹配*

*Ali Youssef* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 特征匹配, Mamba, Transformer, 状态空间模型, 半稠密

**Comment:** 

> **TL;DR:** VMatcher是一种结合Mamba和Transformer的新型网络，用于半稠密特征匹配，旨在通过Mamba的线性复杂度和Transformer的有效性来提高效率和性能，特别适用于实时应用。

**AI_Comments:** VMatcher的创新在于其混合架构，成功地将Mamba模型在长序列处理方面的线性复杂度优势与Transformer在特征匹配中的强大表达能力相结合。这对于需要高性能但同时对计算资源敏感的实时应用（如机器人视觉、AR/VR）具有重要意义。通过解决Transformer的二次复杂度瓶颈，VMatcher为未来的高效视觉匹配算法开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的学习型特征匹配方法（无论是基于检测器还是无检测器）虽然性能先进，但严重依赖Transformer的注意力机制，其二次复杂度导致计算成本高昂。

**Method:** 本文提出了VMatcher，一种混合Mamba-Transformer网络。它结合了Mamba高效处理长序列的能力（通过选择性状态空间模型SSM实现线性复杂度）和Transformer的注意力机制。论文中提出了多种VMatcher配置，包括分层架构。

**Result:** VMatcher在半稠密特征匹配任务中有效建立了新的基准，并实现了高效、鲁棒且实用的性能，尤其适用于需要快速推理的实时应用。

**Conclusion:** VMatcher成功地将Mamba的效率与Transformer的有效性结合起来，为特征匹配提供了一个计算成本更低但性能优异的解决方案，适用于实际的实时应用。

> **ai_Abstract:** VMatcher是一种创新的混合Mamba-Transformer网络，专为解决传统学习型特征匹配方法中Transformer注意力机制带来的高计算成本问题而设计。它巧妙地结合了Mamba的线性复杂度状态空间模型（SSM）和Transformer的有效注意力机制，从而在半稠密特征匹配任务中实现了高效、高性能且适用于实时应用的解决方案，并提供了多种配置和分层架构。

> **摘要翻译:** 本文介绍了VMatcher，一种用于图像对之间半稠密特征匹配的混合Mamba-Transformer网络。基于学习的特征匹配方法，无论是基于检测器还是无检测器，都达到了最先进的性能，但严重依赖于Transformer的注意力机制。尽管Transformer有效，但其二次复杂度会带来高昂的计算成本。相比之下，Mamba引入了一种选择性状态空间模型（SSM），以线性复杂度实现可比或更优的性能，提供了显著的效率提升。VMatcher利用混合方法，将Mamba高效的长序列处理与Transformer的注意力机制相结合。论文中提出了多种VMatcher配置，包括分层架构，展示了它们在高效设置新基准方面的有效性，同时确保了实时应用中的鲁棒性和实用性，在这些应用中快速推理至关重要。源代码可在：https://github.com/ayoussf/VMatcher 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [636] [Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis](https://arxiv.org/abs/2507.23652)
> *自适应蒸馏ControlNet：用于医学图像合成的加速训练和卓越采样*

*Kunpeng Qiu, Zhiying Zhou, Yongxin Guo* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 医学图像合成, ControlNet, 知识蒸馏, 扩散模型, 隐私保护

**Comment:** Accepted by MICCAI2025

> **TL;DR:** 提出一种自适应蒸馏ControlNet，通过双模型蒸馏加速医学图像合成训练，并在采样时仅使用学生模型，实现优越性能和隐私保护。

**AI_Comments:** 该论文创新性地将双模型蒸馏应用于ControlNet，实现了医学图像合成的加速训练和隐私保护采样。其自适应正则化策略和仅学生模型采样机制是亮点，有效解决了医学领域数据稀缺和隐私敏感的挑战，为医学图像合成提供了新的高效解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 医学图像标注受隐私问题和劳动密集型标记的限制，严重影响分割模型的性能和泛化能力。虽然掩膜可控扩散模型在合成方面表现出色，但难以实现精确的病变掩膜对齐。

**Method:** 提出自适应蒸馏ControlNet，一个任务无关的框架，通过双模型蒸馏加速训练和优化。训练期间，一个以掩膜-图像对为条件的教师模型通过参数空间中预测噪声对齐来正则化一个仅掩膜学生模型，并通过病变-背景比的自适应正则化进一步增强。采样期间，仅使用学生模型，实现隐私保护的医学图像生成。

**Result:** 在两个不同的医学数据集上的综合评估显示出最先进的性能：TransUNet在KiTS19上mDice/mIoU提高了2.4%/4.2%，而SANet在Polyps上获得了2.6%/3.5%的增益，突显了其有效性和优越性。

**Conclusion:** 该方法在医学图像合成方面表现出显著的有效性和优越性，实现了加速训练、卓越采样以及隐私保护的图像生成。

> **ai_Abstract:** 本文提出了自适应蒸馏ControlNet，一个用于医学图像合成的任务无关框架，旨在解决医学图像标注受限和现有扩散模型难以精确对齐的问题。该框架通过双模型蒸馏加速训练和优化：教师模型在训练期间正则化学生模型，并通过自适应正则化增强。采样时仅使用学生模型，确保隐私保护。实验证明，该方法在两个医学数据集上均达到最先进性能，显著提升了分割模型的mDice和mIoU指标，显示出其有效性和优越性。

> **摘要翻译:** 医学图像标注受隐私问题和劳动密集型标记的限制，严重限制了分割模型的性能和泛化能力。虽然掩膜可控扩散模型在合成方面表现出色，但它们难以实现精确的病变掩膜对齐。我们提出了自适应蒸馏ControlNet，一个任务无关的框架，通过双模型蒸馏加速训练和优化。具体而言，在训练期间，一个以掩膜-图像对为条件的教师模型通过参数空间中的预测噪声对齐来正则化一个仅掩膜学生模型，并通过基于病变-背景比的自适应正则化进一步增强。在采样期间，仅使用学生模型，从而实现隐私保护的医学图像生成。在两个不同的医学数据集上的综合评估证明了其最先进的性能：TransUNet在KiTS19上将mDice/mIoU提高了2.4%/4.2%，而SANet在Polyps上获得了2.6%/3.5%的增益，突显了其有效性和优越性。代码可在GitHub上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [637] [MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild](https://arxiv.org/abs/2411.11098)
> *MolParser：野外分子结构端到端视觉识别*

*Xi Fang, Jiankun Wang, Xiaochen Cai, Shangqian Chen, Shuwen Yang, Haoyi Tao, Nan Wang, Lin Yao, Linfeng Zhang, Guolin Ke* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 分子结构识别, OCSR, MolParser, 马库什结构, SMILES

**Comment:** 

> **TL;DR:** MolParser是一个新的端到端光学化学结构识别（OCSR）方法，能够高效准确地识别真实文档中的化学结构，包括复杂的马库什结构，并显著优于现有方法。

**AI_Comments:** MolParser的创新点在于其端到端的识别方法，以及构建了目前最大的标注分子图像数据集MolParser-7M。通过结合扩展SMILES编码、主动学习和课程学习，它有效解决了真实世界文档中分子结构识别的挑战，特别是对复杂马库什结构的处理，这对于促进化学、生物和制药领域的大规模信息利用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 化学出版物和专利中包含大量分子结构图，其中嵌入了关键信息，但现有方法难以大规模搜索和利用这些信息，特别是对于马库什结构和图像质量、绘图风格、噪声等变化，限制了大型语言模型在相关领域的应用。因此，自动精确提取化学结构至关重要。

**Method:** MolParser是一种新颖的端到端光学化学结构识别（OCSR）方法。它使用扩展SMILES编码规则标注训练数据集，并构建了迄今为止最大的标注分子图像数据集MolParser-7M。该方法结合了大量合成数据，并通过主动学习将从真实专利和科学文献中裁剪的野外数据纳入训练过程。MolParser采用课程学习方法训练了一个端到端分子图像字幕模型。

**Result:** MolParser在大多数场景下显著优于经典和基于学习的方法，并具有更广泛的下游应用潜力。MolParser-7M数据集已公开可用。

**Conclusion:** MolParser通过其新颖的端到端方法、大规模数据集和主动学习策略，显著提升了从真实文档中准确识别化学结构的能力，特别是在处理复杂马库什结构方面，这对于促进化学信息的大规模利用具有重要意义。

> **ai_Abstract:** 本研究提出了MolParser，一种新颖的端到端光学化学结构识别（OCSR）方法，旨在解决现有方法在处理真实文档中复杂分子结构（包括马库什结构）和图像质量变化时的性能限制。MolParser利用扩展SMILES编码规则构建了迄今最大的标注分子图像数据集MolParser-7M，并通过结合合成数据和主动学习策略纳入野外真实数据进行训练。实验结果表明，MolParser在多种场景下显著优于传统及基于学习的方法，为化学信息的大规模提取和下游应用提供了有效工具。

> **摘要翻译:** 在最近几十年里，化学出版物和专利数量迅速增长。其中很大一部分关键信息嵌入在分子结构图中，这使得大规模文献搜索变得复杂，并限制了大型语言模型在生物、化学和制药等领域的应用。自动提取精确的化学结构至关重要。然而，真实文档中存在大量马库什结构，加上分子图像质量、绘图风格和噪声的变化，严重限制了现有光学化学结构识别（OCSR）方法的性能。我们提出了MolParser，一种新颖的端到端OCSR方法，能够高效准确地识别真实文档中的化学结构，包括复杂的马库什结构。我们使用扩展SMILES编码规则标注了我们的训练数据集。在此规则下，我们构建了MolParser-7M，据我们所知，这是最大的标注分子图像数据集。在利用大量合成数据的同时，我们采用主动学习方法将大量野外数据，特别是从真实专利和科学文献中裁剪的样本，纳入训练过程。我们使用课程学习方法训练了一个端到端分子图像字幕模型MolParser。MolParser在大多数场景下显著优于经典和基于学习的方法，并具有更广泛的下游应用潜力。该数据集已在huggingface上公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [638] [Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation](https://arxiv.org/abs/2507.23642)
> *高效掩码注意力Transformer用于少样本分类与分割*

*Dustin Carrión-Ojeda, Stefan Roth, Simone Schaub-Meyer* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 少样本学习, 分类, 分割, Transformer, 注意力机制

**Comment:** Accepted for GCPR 2025. Project page: https://visinf.github.io/emat

> **TL;DR:** 本文提出了高效掩码注意力Transformer (EMAT)，显著提升了少样本分类和分割任务的精度，尤其是在小目标上，并且参数效率更高。同时，引入了两种新的评估设置以更好地反映实际场景。

**AI_Comments:** 本文的创新点在于提出了EMAT模型，通过改进注意力机制、下采样策略和参数效率，有效提升了少样本分类与分割在小目标上的性能，并实现了显著的参数效率。同时，引入新的评估设置，考虑了实际应用中对标注数据的利用，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前少样本分类和分割 (FS-CS) 方法在处理小目标时表现不佳。此外，现有评估设置在评估时会丢弃成本高昂的可用标注，未能反映实际应用场景。

**Method:** 提出高效掩码注意力Transformer (EMAT)，包含：1) 新颖的内存高效掩码注意力机制；2) 可学习的下采样策略；3) 参数效率增强。同时，引入两种考虑可用标注的新评估设置，以更好地反映实际场景。

**Result:** EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上超越所有FS-CS方法，并且使用的可训练参数量至少减少了四倍。

**Conclusion:** EMAT有效解决了少样本分类和分割任务中处理小目标和参数效率的问题，并通过引入新的评估设置更好地反映了实际应用场景，提升了该领域的实用性。

> **ai_Abstract:** 本文针对少样本分类与分割（FS-CS）任务中现有方法对小目标处理不佳及评估设置不合理的问题，提出了一种高效掩码注意力Transformer（EMAT）模型。EMAT通过引入内存高效掩码注意力机制、可学习下采样策略和参数效率增强，显著提升了分类和分割精度，尤其是在小目标上，同时大幅减少了参数量。此外，作者还提出了两种新的评估设置，以更好地反映实际应用中对可用标注的利用。

> **摘要翻译:** 少样本分类与分割（FS-CS）专注于使用少量标注样本联合执行多标签分类和多类别分割。尽管当前最先进（SOTA）方法在这两项任务中均取得了高精度，但它们在处理小目标时表现不佳。为了克服这一点，我们提出了高效掩码注意力Transformer（EMAT），它提高了分类和分割精度，尤其是在小目标方面。EMAT引入了三项改进：一种新颖的内存高效掩码注意力机制、一种可学习的下采样策略和参数效率增强。EMAT在PASCAL-5$^i$和COCO-20$^i$数据集上优于所有FS-CS方法，并且使用的可训练参数至少减少了四倍。此外，由于当前的FS-CS评估设置尽管标注成本高昂却丢弃了可用的标注，我们引入了两种新颖的评估设置，这些设置考虑了这些标注，以更好地反映实际场景。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [644] [Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet](https://arxiv.org/abs/2507.19209)
> *查询自动驾驶车辆点云：通过CounterNet进行3D目标计数增强*

*Xiaoyu Zhang, Zhifeng Bao, Hai Dong, Ziwei Wang, Jiajun Liu* | **Category: cs.CV, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 点云, 目标计数, 自动驾驶, CounterNet, 查询

**Comment:** 

> **TL;DR:** 该论文正式定义了点云查询，并引入了CounterNet以实现准确的3D目标计数，从而提高了查询的可靠性。

**AI_Comments:** 本文的创新之处在于其不仅形式化了点云查询，更重要的是提出了一种专门用于3D目标精确计数的网络（CounterNet），而非仅仅关注目标定位。这种针对性的方法解决了自动驾驶中点云分析可靠性的关键瓶颈。此外，动态模型选择和特征图分区策略也为性能提升带来了显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆生成大量的点云数据，但现有技术在3D点云数据上无法提供可靠的目标计数，导致查询结果出现重大错误。为了实现有效的点云查询以进行碰撞检测、交通分析等任务，精确的目标计数至关重要。

**Method:** 论文正式定义了三种核心点云查询类型：检索（RETRIEVAL）、计数（COUNT）和聚合（AGGREGATION）。为解决3D目标计数不准确的问题，提出了一种名为CounterNet的基于热力图的网络，该网络通过查找目标中心来检测目标存在，从而提高计数精度。CounterNet通过使用重叠区域的特征图分区策略进一步增强性能，并引入了逐帧动态模型选择策略以适应不同的帧特性。

**Result:** 在三个真实的自动驾驶车辆数据集上评估显示，CounterNet在所有目标类别上的计数精度提高了5%到20%，从而在所有支持的查询类型中产生了更可靠的查询结果。

**Conclusion:** CounterNet通过提供准确的3D目标计数，显著提高了自动驾驶车辆应用中点云查询的可靠性，这对各种分析任务至关重要。

> **ai_Abstract:** 本论文解决了自动驾驶车辆生成的大规模点云数据查询中的挑战。它形式化了三种核心查询类型（检索、计数、聚合），并强调了精确目标计数的重要性。为克服现有3D检测模型在提供可靠计数方面的局限性，作者提出了CounterNet，一个基于热力图的网络，专注于通过检测目标中心来提高计数精度。通过特征图分区策略和动态模型选择的增强，CounterNet在真实世界数据集中将计数精度提高了5%到20%，从而显著提升了查询结果的可靠性。

> **摘要翻译:** 自动驾驶车辆生成大量的点云数据，然而只有一部分与特定任务相关，例如碰撞检测、交通分析或拥堵监控。有效地查询这些数据对于实现有针对性的分析至关重要。在这项工作中，我们通过定义三种核心查询类型来形式化点云查询：检索（RETRIEVAL）、计数（COUNT）和聚合（AGGREGATION），每种类型都与不同的分析场景相对应。所有这些查询都严重依赖准确的目标计数才能产生有意义的结果，这使得精确的目标计数成为查询执行的关键组成部分。先前的工作主要集中在2D视频数据的索引技术上，假设检测模型提供了准确的计数信息。然而，当应用于3D点云数据时，最先进的检测模型通常无法生成可靠的目标计数，导致查询结果出现重大错误。为了解决这一限制，我们提出了CounterNet，一个基于热力图的网络，旨在在大规模点云数据中实现准确的目标计数。CounterNet没有专注于精确的目标定位，而是通过寻找目标中心来检测目标存在，从而提高计数精度。我们通过使用重叠区域的特征图分区策略进一步增强了其性能，从而更好地处理复杂交通场景中的小型和大型目标。为了适应不同的帧特性，我们引入了一种逐帧动态模型选择策略，为每个输入选择最有效的配置。在三个真实的自动驾驶车辆数据集上的评估显示，CounterNet在所有目标类别上的计数精度提高了5%到20%，从而在所有支持的查询类型中产生了更可靠的查询结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [650] [UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries](https://arxiv.org/abs/2507.23372)
> *UniEmo：使用可学习专家查询统一情感理解与生成*

*Yijie Zhu, Lingsen Zhang, Zitong Yu, Rui Shao, Tao Tan, Liqiang Nie* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 情感理解, 情感生成, 统一框架, 可学习专家查询, 扩散模型

**Comment:** 

> **TL;DR:** UniEmo是一个统一的情感理解与生成框架，通过可学习的专家查询和双向反馈机制，显著提升了情感理解和生成任务的性能。

**AI_Comments:** UniEmo的创新之处在于其统一情感理解和生成任务的框架，这在传统上是分开处理的。通过引入可学习的专家查询来提取多尺度情感特征，并结合扩散模型进行图像生成，构建了强大的基础。更重要的是，其独特的生成驱动的双重反馈机制（包括隐式反馈和基于数据过滤的显式反馈）是其成功的关键，它有效地增强了模型的理解能力，形成了相互促进的闭环。这不仅提升了性能，也为未来多模态情感AI研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 情感理解和生成通常被视为独立任务，但它们本质上是互补的，可以相互增强。核心挑战在于情感的抽象性，需要提取对两项任务都有益的视觉表示。

**Method:** 本文提出了UniEmo框架，它无缝整合了情感理解和生成任务。首先，通过一个带有可学习专家查询的分层情感理解链，逐步提取多尺度情感特征。其次，将这些专家查询和情感表示融合以指导扩散模型生成情感图像，并引入情感相关系数和情感条件损失来增强生成图像的多样性和保真度。此外，通过联合训练使生成组件为理解部分提供隐式反馈。最后，提出了一种新颖的数据过滤算法，选择高质量、多样化的生成图像，显式地反馈到理解部分，形成生成驱动的双重反馈过程，增强模型的理解能力。

**Result:** 大量实验表明，UniEmo在情感理解和生成任务上均显著优于现有最先进的方法。

**Conclusion:** UniEmo成功地将情感理解和生成任务统一在一个框架中，并通过创新的机制（如可学习专家查询和生成驱动的双重反馈）显著提高了在这两个任务上的性能。

> **ai_Abstract:** UniEmo是一个创新的统一框架，旨在整合情感理解和生成任务，以解决它们通常被独立处理的局限性。该框架通过一个分层情感理解链和可学习专家查询来提取多尺度情感特征，并将其与扩散模型结合，以生成高质量、多样化的情感图像。通过引入情感相关系数和情感条件损失，并设计生成驱动的隐式和显式双重反馈机制，UniEmo显著提升了模型的理解能力。实验结果表明，UniEmo在两项任务上均超越了现有最先进的方法。

> **摘要翻译:** 情感理解和生成通常被视为独立任务，但它们本质上是互补的，可以相互增强。在本文中，我们提出了UniEmo，一个无缝整合这两项任务的统一框架。关键挑战在于情感的抽象性，需要提取对两项任务都有益的视觉表示。为了解决这个问题，我们提出了一个带有可学习专家查询的分层情感理解链，该链逐步提取多尺度情感特征，从而成为统一的基础步骤。同时，我们将这些专家查询和情感表示融合，以指导扩散模型生成引发情感的图像。为了增强生成情感图像的多样性和保真度，我们进一步在融合过程中引入了情感相关系数和情感条件损失。这一步骤促进了由理解引导的情感生成的融合和对齐。反过来，我们证明了联合训练允许生成组件向理解部分提供隐式反馈。此外，我们提出了一种新颖的数据过滤算法，用于选择由训练有素的模型生成的高质量和多样化的情感图像，这些图像明确地反馈到理解部分。总之，这些生成驱动的双重反馈过程增强了模型的理解能力。大量实验表明，UniEmo在情感理解和生成任务上均显著优于现有最先进的方法。所提出方法的代码可在https://github.com/JiuTian-VL/UniEmo获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [658] [Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots](https://arxiv.org/abs/2304.01430)
> *分段注意力：基于上下文分离槽的无监督多目标发现*

*Dong Lao, Zhengyang Hu, Francesco Locatello, Yanchao Yang, Stefano Soatto* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 无监督学习, 多目标发现, 运动分割, 分段注意力, 光流

**Comment:** 

> **TL;DR:** 本文提出了一种名为DivA的无监督方法，用于实时多目标分割，该方法不依赖语义标注或预训练特征，实现了最先进的性能和速度，并可用于预训练静态分类器。

**AI_Comments:** 该论文的创新之处在于其完全无监督的多目标发现方法，不依赖任何语义标签或预训练特征，并且能够处理可变数量和分辨率的对象。其实时性能（104 FPS）和具有竞争力的准确性，尤其是在缩小与监督方法差距以及用于预训练静态分类器方面的效用，突显了其在推进计算机视觉无监督学习方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 研究在没有任何语义标注的情况下，视觉感知中物体是如何出现的，并开发一种能够将图像分割成多个独立运动区域的方法。

**Method:** 采用一种名为“分段注意力”（DivA）的多模态条件编码器-解码器架构。其中，光流输入编码器以生成潜在代码（槽），彩色图像调节解码器从这些槽中生成光流。训练准则旨在促进槽之间的“信息分离”，同时架构明确地将激活分配给单个槽。

**Result:** DivA在可比方法中实现了最先进的性能，运行速度提高了三倍（高达104 FPS），并将与监督方法的性能差距缩小到12%或更少。DivA自举的物体可以用于通过对比学习预训练静态分类器，在少于5,000个视频片段上，在DivA的物体提议上训练DINO，与直接在视频帧上训练相比，将与ImageNet训练的性能差距缩小了高达30.2%。

**Conclusion:** DivA是一种有效的无监督多目标发现和分割方法，在速度和性能上都有显著提升，并且可以作为其他视觉任务的强大预训练步骤。

> **ai_Abstract:** 本文提出了一种名为“分段注意力”（DivA）的无监督方法，用于视觉感知中的多目标发现和运动分割。该模型不依赖监督或预训练特征，通过多模态编码器-解码器架构，利用光流和彩色图像生成上下文分离的潜在槽。DivA能实时处理可变数量的对象，并在速度和性能上达到最先进水平，将与监督方法的差距缩小至12%以内。此外，DivA生成的对象提议可有效用于对比学习，显著提升静态分类器的性能，缩小与大规模数据集预训练的差距。

> **摘要翻译:** 我们研究了在没有任何语义标注的情况下，视觉感知中物体是如何出现的。由此产生的模型没有经过任何监督，不使用任何预训练特征，但它能够将图像域分割成多个独立运动的区域。由此产生的运动分割方法可以实时处理未知且数量变化的对象。其核心多模态条件编码器-解码器架构中，一种模态（光流）输入编码器以生成一系列潜在代码（槽），另一种模态（彩色图像）调节解码器从这些槽中生成第一种模态（光流）。训练准则旨在促进槽之间的“信息分离”，同时该架构明确地将激活分配给各个槽，从而形成我们称之为“分段注意力”（DivA）的方法。在测试时，DivA 可以处理与训练时不同的对象数量和图像分辨率，并且对槽的排列是不变的。DivA 在将可比方法的运行时间速度提高三倍（高达104 FPS）的同时，实现了最先进的性能，并将与监督方法的性能差距缩小到12%或更少。DivA 自举的物体随后可以通过对比学习来预训练静态分类器。在少于5,000个视频片段上，在DivA的物体提议上训练DINO，与直接在视频帧上训练相比，将与ImageNet训练的性能差距缩小了高达30.2%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [660] [EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models](https://arxiv.org/abs/2505.21567)
> *EaqVLA: 面向视觉-语言-动作模型的编码对齐量化*

*Feng Jiang, Zihao Zheng, Xiuping Cui, Maoliang Li, JIayu Chen, Xiang Chen* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量化, 视觉-语言-动作模型, 编码对齐, 混合精度, 具身智能

**Comment:** There is an error in this paper, and as the author, I request
  retraction

> **TL;DR:** EaqVLA提出了一种编码对齐量化框架，通过分析和解决VLA模型中的令牌对齐问题，实现了更好的量化性能和计算加速，以应对现有VLA模型高昂的计算/存储成本。

**AI_Comments:** 这项工作创新性地指出了VLA模型中令牌对齐问题对量化效率的影响，并提出了针对性的编码对齐量化框架EaqVLA。通过引入全面的不对齐分析和混合精度量化，该方法有效地解决了VLA模型在实际部署中的计算和存储开销问题，对于推动具身AI领域VLA模型的实用化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉-语言-动作（VLA）模型面临昂贵的计算/存储成本，需要优化。量化被认为是最有效的方法，但VLA模型的令牌对齐问题阻碍了现有量化方法的应用。

**Method:** 提出了一个名为EaqVLA的优化框架，将编码对齐量化应用于VLA模型。具体地，提出了一种完整的分析方法来发现各种粒度上的不对齐问题，并基于分析结果提出了一个具有编码对齐意识的混合精度量化方案。

**Result:** 所提出的EaqVLA比现有量化方法实现了更好的量化性能，具有最小的端到端动作控制量化损失和xxx倍的加速。

**Conclusion:** EaqVLA通过解决VLA模型中的令牌对齐问题，有效地提升了量化性能，降低了计算/存储成本，使其成为VLA模型优化的有效方案。

> **ai_Abstract:** 本文针对视觉-语言-动作（VLA）模型高昂的计算和存储成本问题，提出了一种名为EaqVLA的编码对齐量化框架。研究发现，VLA模型的令牌对齐问题限制了现有量化方法的应用。为解决此问题，EaqVLA提出了一种全面的分析方法来识别不同粒度上的不对齐，并基于此设计了编码对齐的混合精度量化方案。实验结果表明，EaqVLA在保持最小量化损失的同时，实现了优于现有方法的性能和显著的计算加速。

> **摘要翻译:** 随着具身人工智能的发展，视觉-语言-动作（VLA）模型等端到端控制策略已成为主流。现有的VLA模型面临昂贵的计算/存储成本，需要进行优化。量化被认为是最有效的方法，它不仅可以降低内存成本，还可以实现计算加速。然而，我们发现VLA模型的令牌对齐阻碍了现有量化方法的应用。为了解决这个问题，我们提出了一个名为EaqVLA的优化框架，它将编码对齐量化应用于VLA模型。具体来说，我们提出了一种完整的分析方法来发现各种粒度上的不对齐问题。基于分析结果，我们提出了一种具有编码对齐意识的混合精度量化。实验表明，所提出的EaqVLA比现有量化方法实现了更好的量化性能（端到端动作控制的量化损失最小，并加速了xxx倍）。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [665] [Multi-Task Label Discovery via Hierarchical Task Tokens for Partially Annotated Dense Predictions](https://arxiv.org/abs/2411.18823)
> *通过分层任务令牌进行多任务标签发现用于部分标注的密集预测*

*Jingdong Zhang, Hanrong Ye, Xin Li, Wenping Wang, Dan Xu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多任务学习, 密集预测, 部分标注, 任务令牌, 伪标签

**Comment:** 

> **TL;DR:** 该论文提出了一种新颖的方法，利用可学习的分层任务令牌来发现像素级伪监督信号，以解决部分标注的多任务密集预测问题，并在多个基准数据集上取得了显著优于现有SOTA方法的性能。

**AI_Comments:** 该论文的创新之处在于引入了分层任务令牌机制，以直接从部分标注数据中发现像素级的伪监督信号。这有效解决了以往方法中缺乏直接像素级监督和需要复杂映射网络的问题，为多任务密集预测提供了一种更直接且高效的监督方式。其贡献在于通过可学习的令牌生成高质量的像素级标签，从而提升了模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 在部分标注数据下同时学习多个密集预测任务是一个重要的研究领域。现有方法主要依赖于跨任务关系或对抗性训练，但仍面临缺乏直接像素级监督和需要额外训练大型映射网络的问题。

**Method:** 本文提出了一种优化紧凑的可学习分层任务令牌（包括全局和细粒度令牌）的新方法。全局任务令牌用于全局上下文中的有效跨任务特征交互。然后，从相应的全局任务令牌中学习一组针对每个任务的细粒度任务特定空间令牌，并嵌入以与每个任务特定特征图进行密集交互。学习到的全局和局部细粒度任务令牌进一步用于发现不同粒度级别的伪任务特定密集标签，并直接监督多任务密集预测框架的学习。

**Result:** 在NYUD-v2、Cityscapes和PASCAL Context等挑战性数据集上的大量实验结果表明，该方法在部分标注的多任务密集预测方面比现有最先进的方法有显著改进。

**Conclusion:** 本文提出的通过分层任务令牌发现像素级监督信号的新方法，有效解决了部分标注多任务密集预测的挑战，并在多个基准数据集上取得了显著的性能提升。

> **ai_Abstract:** 该论文提出了一种新颖的框架，通过优化可学习的分层任务令牌（包括全局和细粒度令牌）来解决部分标注的多任务密集预测问题。这些令牌旨在发现一致的像素级监督信号，并通过生成伪密集标签来直接监督模型。全局令牌促进跨任务特征交互，而细粒度令牌与任务特定特征图进行密集交互。实验结果表明，该方法在多个标准数据集上显著优于现有的最先进方法。

> **摘要翻译:** 近年来，在部分标注标签数据下同时学习多个密集预测任务已成为一个重要的研究领域。以前的工作主要集中在利用跨任务关系或进行对抗性训练以进行额外正则化，这些方法取得了可喜的性能改进，但仍然存在缺乏直接像素级监督和额外训练繁重映射网络的问题。为了有效解决这一挑战，我们提出了一种新颖的方法来优化一组紧凑的可学习分层任务令牌，包括全局和细粒度令牌，以在特征和预测级别发现一致的像素级监督信号。具体来说，全局任务令牌旨在实现全局上下文中的有效跨任务特征交互。然后，针对每个任务学习一组细粒度任务特定空间令牌，这些令牌从相应的全局任务令牌中学习，并嵌入以与每个任务特定特征图进行密集交互。学习到的全局和局部细粒度任务令牌进一步用于发现不同粒度级别的伪任务特定密集标签，并且可以用于直接监督多任务密集预测框架的学习。在具有挑战性的NYUD-v2、Cityscapes和PASCAL Context数据集上的大量实验结果表明，与现有最先进的部分标注多任务密集预测方法相比，该方法取得了显著改进。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [670] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
> *DeepShade：通过文本条件图像生成实现阴影模拟*

*Longchao Da, Xiangrui Liu, Mithun Shivakoti, Thirulogasankar Pranav Kutralingam, Yezhou Yang, Hua Wei* | **Category: cs.CV, cs.CY, 68T45, 68U10, 62H35, I.2.10; I.4.8; I.5.1** | **Updated: 2025-07-30**

**Keywords:** 阴影模拟, 文本条件图像生成, 扩散模型, 城市规划, 热浪

**Comment:** 7pages, 4 figures

> **TL;DR:** DeepShade是一个扩散模型，通过结合大规模数据集和文本条件图像生成，解决热浪下路径规划中阴影信息缺失的问题，从而改进城市规划和环境应用。

**AI_Comments:** DeepShade的创新之处在于其结合了大规模合成数据集的构建和基于扩散模型的文本条件图像生成，以解决城市阴影模拟的挑战。其通过Blender模拟生成高质量的阴影数据，并结合RGB和Canny边缘信息来增强模型对阴影细节的学习能力。该方法对于城市规划和公共健康具有重要意义，尤其是在全球变暖背景下，能够为创建更舒适的城市环境提供工具。

<details>
  <summary>Details</summary>

**Motivation:** 热浪对公众健康构成重大威胁，但当前的路径规划系统（如在线地图）未能整合阴影信息，原因是难以直接从噪声卫星图像中估计阴影，且生成模型的训练数据有限。

**Method:** 本文通过两项主要贡献解决了这些挑战。首先，构建了一个广泛的数据集，涵盖不同的经纬度区域、建筑密度和城市布局。利用基于Blender的3D模拟和建筑轮廓，捕捉一年中不同时间、不同太阳天顶角下的建筑阴影，并将其与卫星图像对齐。其次，提出了DeepShade，一个基于扩散的模型，旨在学习和合成随时间变化的阴影。它通过联合考虑RGB和Canny边缘层来强调边缘特征的细微差别，并结合对比学习来捕捉阴影的时间变化规律。通过已知条件（如一天中的时间、太阳角度）的文本描述进行条件化，提高了阴影图像的生成性能。

**Result:** 通过使用DeepShade的阴影预测来计算亚利桑那州坦佩市实际路线规划中的阴影比率，证明了该方法的实用性。

**Conclusion:** 这项工作有望通过为极端高温天气下的城市规划提供参考及其在环境中的潜在实际应用来造福社会。

> **ai_Abstract:** DeepShade是一种新颖的扩散模型，旨在通过文本条件图像生成来模拟阴影，以解决当前路径规划系统中阴影信息缺失的问题。该研究首先构建了一个大规模、多样的阴影数据集，该数据集通过Blender的3D模拟生成并与卫星图像对齐。接着，DeepShade模型被提出，它结合RGB和Canny边缘层来学习边缘特征，并利用对比学习捕捉阴影的时间变化规律。通过文本描述进行条件化，该模型能够更准确地生成阴影图像。研究展示了其在亚利桑那州坦佩市路线规划中计算阴影比率的实用性，并强调了其在城市规划和环境应用中的潜力，以应对极端高温天气。

> **摘要翻译:** 热浪对公众健康构成重大威胁，尤其是在全球变暖加剧的情况下。然而，当前的路径规划系统（例如在线地图）未能整合阴影信息，原因是难以直接从噪声卫星图像中估计阴影，以及生成模型训练数据的可用性有限。在本文中，我们通过两项主要贡献解决了这些挑战。首先，我们构建了一个广泛的数据集，涵盖不同的经纬度区域、不同程度的建筑密度和不同的城市布局。利用基于Blender的3D模拟以及建筑轮廓，我们捕捉了一年四季和一天中不同时间在各种太阳天顶角下的建筑阴影。这些模拟的阴影与卫星图像对齐，为学习阴影模式提供了丰富的资源。其次，我们提出了DeepShade，一个基于扩散的模型，旨在学习和合成随时间变化的阴影变化。它通过联合考虑RGB与Canny边缘层来强调边缘特征的细微差别，并结合对比学习来捕捉阴影的时间变化规律。然后，通过已知条件（例如，一天中的时间、太阳角度）的文本描述进行条件化，我们的框架在生成阴影图像方面提供了改进的性能。我们通过使用我们的阴影预测来计算亚利桑那州坦佩市实际路线规划中的阴影比率，证明了我们方法的实用性。我们相信这项工作将通过为极端高温天气下的城市规划提供参考及其在环境中的潜在实际应用来造福社会。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [673] [OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction](https://arxiv.org/abs/2507.23657)
> *OmniTraj：基于异构数据预训练的自适应零样本人体轨迹预测*

*Yang Gao, Po-Chien Luan, Kaouther Messaoud, Lan Feng, Alexandre Alahi* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 人体轨迹预测, 零样本迁移, 预训练, 异构数据, Transformer

**Comment:** 

> **TL;DR:** OmniTraj是一个基于Transformer的模型，通过显式条件化帧率，在异构数据上预训练，实现了对不同时间动态数据集的SOTA零样本迁移和微调性能，解决了现有模型在零样本迁移中面临的挑战。

**AI_Comments:** 这篇论文通过深入分析现有预训练模型在时间动态变化数据集上的局限性，提出了一个创新且实用的解决方案。通过显式地将时间元数据（如帧率）引入模型条件化，OmniTraj显著提升了模型在零样本迁移场景下的鲁棒性和泛化能力，这对于实际应用中处理多样化数据具有重要意义。其在多个数据集上达到SOTA性能也证明了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的预训练模型在零样本迁移到具有不同时间动态（如帧率或观察范围）的未见数据集时面临挑战，通常需要微调，这限制了它们的可扩展性和实用性。

**Method:** 研究者系统地调查了现有模型的局限性，发现对时间元数据进行简单的、显式的条件化是一种非常有效的解决方案。基于此，他们提出了OmniTraj，一个基于Transformer的模型，在大规模异构数据集上进行预训练，并通过显式条件化帧率来提升性能。

**Result:** OmniTraj在具有挑战性的跨设置场景中，将预测误差降低了70%以上，实现了最先进的零样本迁移性能。经过微调后，OmniTraj在NBA、JTA、WorldPose和ETH-UCY四个数据集上均取得了最先进的结果。

**Conclusion:** 显式地对帧率等时间元数据进行条件化，是实现人体轨迹预测中鲁棒零样本迁移的关键。OmniTraj通过这种方法，显著提升了模型在不同时间动态数据集上的适应性和泛化能力。

> **ai_Abstract:** 本文提出OmniTraj，一个基于Transformer的模型，通过在大规模异构数据集上预训练并显式条件化帧率，解决了人体轨迹预测中零样本迁移到不同时间动态数据集的挑战。研究表明，显式时间元数据条件化能显著提升模型在未见设置下的泛化能力，使其在零样本和微调场景下均达到最先进性能。

> **摘要翻译:** 虽然大规模预训练已经推动了人体轨迹预测的发展，但一个关键挑战依然存在：零样本迁移到具有不同时间动态的未见数据集。最先进的预训练模型通常需要微调才能适应具有不同帧率或观察范围的新数据集，这限制了它们的可扩展性和实用性。在这项工作中，我们系统地调查了这一限制并提出了一个稳健的解决方案。我们首先证明了现有数据感知离散模型在转移到时间设置发生变化的新场景时表现不佳。然后，我们将时间泛化与数据集偏移分离，揭示了一个简单的、对时间元数据进行显式条件化的机制是一种非常有效的解决方案。基于这一见解，我们提出了OmniTraj，一个基于Transformer的模型，在大规模异构数据集上进行预训练。我们的实验表明，显式地对帧率进行条件化使OmniTraj能够实现最先进的零样本迁移性能，在具有挑战性的跨设置场景中将预测误差降低了70%以上。经过微调后，OmniTraj在NBA、JTA、WorldPose和ETH-UCY四个数据集上均取得了最先进的结果。代码已公开：https://github.com/vita-epfl/omnitraj

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [Neural Multi-View Self-Calibrated Photometric Stereo without Photometric Stereo Cues](https://arxiv.org/abs/2507.23162)
> *神经多视角自校准光度立体，无需光度立体线索*

*Xu Cao, Takafumi Taketomi* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 神经逆渲染, 光度立体, 多视角, 几何重建, 反射率估计

**Comment:** Accepted to ICCV 2025

> **TL;DR:** 提出一种无需光照校准或中间线索的神经逆渲染方法，从多视角图像联合重建几何、反射和光照。

**AI_Comments:** 该论文的创新点在于其“自校准”特性，即无需预先的光照校准或中间法线图，通过端到端的神经逆渲染实现场景参数的联合优化。这种方法简化了光度立体流程，提高了实用性，并展现了神经隐式场在复杂逆渲染任务中的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多视角光度立体方法需要光照校准或中间线索（如每视角的法线图），这限制了其应用。

**Method:** 提出一种神经逆渲染方法，从原始图像单阶段联合优化所有场景参数。几何和反射表示为神经隐式场，并应用阴影感知体渲染。一个空间网络预测每个场景点的SDF和反射潜在编码，一个反射网络根据潜在编码、表面法线、视角和光照方向估计反射值。

**Result:** 该方法在形状和光照估计精度上优于最先进的法线引导方法，能泛化到视角未对齐的多光照图像，并处理具有挑战性几何和反射的对象。

**Conclusion:** 该方法通过联合优化和神经隐式场，实现了无需外部校准或中间线索的高精度几何、反射和光照重建，展现了优越的性能和泛化能力。

> **ai_Abstract:** 这篇论文提出了一种创新的神经逆渲染方法，用于从多视角图像中联合重建三维几何、空间变化的反射率和光照。该方法摒弃了传统多视角光度立体方法所需的外部光照校准或中间线索（如法线图），通过在一个单阶段流程中直接从原始图像联合优化所有场景参数。它利用神经隐式场表示几何和反射，并结合阴影感知体渲染。实验结果表明，该方法在精度和泛化能力上均优于现有技术，尤其在处理复杂几何和反射对象时表现出色。

> **摘要翻译:** 我们提出一种神经逆渲染方法，可以从在不同方向光照下捕获的多视角图像中联合重建几何、空间变化的反射率和光照条件。与之前需要光照校准或中间线索（如每视角法线图）的多视角光度立体方法不同，我们的方法在一个阶段内从原始图像中联合优化所有场景参数。我们将几何和反射率表示为神经隐式场，并应用阴影感知体渲染。一个空间网络首先预测每个场景点的有符号距离和反射潜在编码。然后，一个反射网络根据潜在编码和角度编码的表面法线、视角和光照方向估计反射值。所提出的方法在形状和光照估计精度上优于最先进的法线引导方法，能够泛化到视角未对齐的多光照图像，并处理具有挑战性几何和反射的对象。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [686] [Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation](https://arxiv.org/abs/2507.23373)
> *多提示渐进对齐用于多源无监督域适应*

*Haoran Chen, Zexiao Wang, Haidong Cao, Zuxuan Wu, Yu-Gang Jiang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 无监督域适应, CLIP, 渐进对齐, 多源, 伪标签

**Comment:** 

> **TL;DR:** 针对多源无监督域适应中CLIP模型对齐噪声样本困难的问题，本文提出了一种渐进对齐策略（MP^2A），通过从高置信度样本开始逐步引入挑战性样本，实现了更好的域不变特征学习和最先进的性能。

**AI_Comments:** 本文的创新点在于提出了渐进式对齐策略来解决多源无监督域适应中伪标签噪声和难样本对齐的挑战。通过从易到难的学习路径，有效避免了误差累积和确认偏差，提升了模型学习域不变特征的能力，对于基于预训练大模型的域适应研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于CLIP的无监督域适应方法在对齐源域和目标域时，通常一次性使用所有伪标签数据，这在面对噪声大、难以分类的样本时表现不佳，导致误差传播和次优的特征学习。在多源场景下，这个问题甚至被进一步放大，其中多样化的域间隙和多个源域中不同的噪声水平进一步破坏了对齐过程的稳定性。

**Method:** 本文提出了一种名为MP^2A的渐进对齐策略。该方法首先在目标样本的高置信度子集上训练模型，使其能够首先从最可靠的数据中学习到良好对齐的表示。随着训练的进行，模型逐步纳入更具挑战性的样本，从而在不被初始标签噪声淹没的情况下细化其理解，有效缓解确认偏差并促进更鲁棒的收敛。

**Result:** MP^2A在ImageCLEF、Office-Home和DomainNet三个流行的无监督域适应基准测试中，与最新的基于CLIP的多源无监督域适应方法相比，取得了最先进的性能。

**Conclusion:** 本文提出的MP^2A渐进对齐策略有效解决了多源无监督域适应中噪声样本导致的对齐问题，通过逐步学习的方式实现了更鲁棒的域不变特征学习，并在多个基准测试中展现出卓越的性能。

> **ai_Abstract:** 本文针对基于CLIP的无监督域适应在多源场景下因伪标签噪声导致的一次性对齐困难问题，提出了一种名为MP^2A的渐进对齐策略。该方法通过从高置信度目标样本开始，逐步引入更具挑战性的样本进行训练，有效缓解了确认偏差，促进了鲁棒的域不变特征学习。实验结果表明，MP^2A在多个标准UDA基准测试中达到了最先进的性能。

> **摘要翻译:** 大型视觉-语言模型（如CLIP）因其强大的零样本泛化能力，已成为无监督域适应的强大基础。最先进的方法通常利用CLIP为目标域生成伪标签，然后微调模型以学习域不变特征。然而，这些方法尝试同时使用所有伪标签数据来对齐源域和目标域。这种一次性对齐难以处理噪声大、难以分类的样本，导致误差传播和次优特征学习。在多源场景中，这个问题甚至被进一步放大，其中多样化的域间隙和多个源域中不同的噪声水平进一步破坏了对齐过程的稳定性。为了解决这个问题，在这项工作中，我们提出了一种渐进对齐策略，用于将CLIP适应于未标记的下游任务。我们的方法首先在目标样本的高置信度子集上训练模型，使其能够首先从最可靠的数据中学习到良好对齐的表示。随着训练的进行，它逐渐整合更具挑战性的样本，引导模型在不被初始标签噪声淹没的情况下细化其理解。这种渐进式方法有效地缓解了确认偏差，并促进了更鲁棒的收敛，从而能够学习到真正的域不变特征。我们将我们的方法命名为MP^2A，并在三个流行的UDA基准测试（即ImageCLEF、Office-Home和最具挑战性的DomainNet）上进行了测试。实验表明，与最新的基于CLIP的MS-UDA方法相比，MP^2A取得了最先进的性能，证明了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [700] [SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2507.23673)
> *SAMSA：基于光谱角度增强的即时分割模型用于高光谱交互式医学图像分割*

*Alfie Roddan, Tobias Czempiel, Chi Xu, Daniel S. Elson, Stamatia Giannarou* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 高光谱成像, 交互式分割, 医学图像, 光谱分析, 少样本学习

**Comment:** 

> **TL;DR:** SAMSA是一个新颖的高光谱交互式医学图像分割框架，结合了RGB基础模型和光谱分析，旨在克服高光谱成像的数据限制和硬件挑战，并在少量点击和极少训练样本下表现出高效能。

**AI_Comments:** 该论文的创新之处在于将RGB基础模型（可能是Segment Anything Model，SAM）与高光谱数据特有的光谱分析相结合，并通过独特的光谱特征融合策略克服了高光谱图像分割中数据限制和硬件差异的关键挑战。其重要性体现在能够实现少样本和零样本学习，并提供了一个灵活的框架，可以无缝集成具有不同光谱特征的数据集，这对于实际医学应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱成像（HSI）为医学成像提供了丰富的光谱信息，但由于数据限制和硬件差异，其应用面临重大挑战。

**Method:** SAMSA是一个新颖的交互式分割框架，它将RGB基础模型与光谱分析相结合。该方法利用用户点击来指导RGB分割和光谱相似度计算，并通过一种独特的光谱特征融合策略来解决HSI分割的局限性，该策略独立于光谱波段数量和分辨率。

**Result:** 在神经外科高光谱数据集上，SAMSA的1次点击DICE得分为81.0%，5次点击DICE得分为93.4%；在术中猪高光谱数据集上，1次点击DICE得分为81.1%，5次点击DICE得分为89.2%。实验结果表明，SAMSA在少样本和零样本学习场景中以及使用少量训练样本时都表现出有效性，并且能够无缝集成具有不同光谱特征的数据集。

**Conclusion:** SAMSA在高光谱医学图像分析中表现出卓越的有效性和灵活性，尤其是在数据受限和多样化数据集集成方面，为该领域提供了一个强大的框架。

> **ai_Abstract:** SAMSA是一个新颖的交互式高光谱医学图像分割框架，它结合了RGB基础模型和光谱分析。该模型通过用户点击引导分割和光谱相似度计算，并采用独特的光谱特征融合策略，克服了高光谱数据限制和硬件差异带来的挑战。实验证明，SAMSA在少样本和零样本学习场景下表现出色，在不同医学高光谱数据集上取得了高DICE分数，并能灵活集成不同光谱特性的数据集。

> **摘要翻译:** 高光谱成像（HSI）为医学成像提供了丰富的光谱信息，但由于数据限制和硬件差异而面临重大挑战。我们引入了SAMSA，这是一种新颖的交互式分割框架，它将RGB基础模型与光谱分析相结合。SAMSA有效地利用用户点击来指导RGB分割和光谱相似度计算。该方法通过一种独特的光谱特征融合策略解决了HSI分割中的关键限制，该策略独立于光谱波段数量和分辨率。在公开数据集上的性能评估显示，在神经外科数据集中，1次点击DICE得分为81.0%，5次点击DICE得分为93.4%；在术中猪高光谱数据集中，1次点击DICE得分为81.1%，5次点击DICE得分为89.2%。实验结果表明，SAMSA在少样本和零样本学习场景中以及使用少量训练样本时都表现出有效性。我们的方法能够无缝集成具有不同光谱特征的数据集，为高光谱医学图像分析提供了一个灵活的框架。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [701] [Pruning All-Rounder: Rethinking and Improving Inference Efficiency for Large Vision Language Models](https://arxiv.org/abs/2412.06458)
> *剪枝全能手：重新思考并提升大型视觉语言模型的推理效率*

*Wei Suo, Ji Ma, Mengyang Sun, Lin Yuanbo Wu, Peng Wang, Yanning Zhang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 大型视觉语言模型, 推理效率, 剪枝, 自适应剪枝, 自监督学习

**Comment:** Accepted by ICCV 25

> **TL;DR:** 大型视觉语言模型（LVLMs）计算成本高昂。本文提出了一个名为“剪枝全能手”（PAR）的新型框架，通过在token和层之间自适应地组织剪枝流，并结合自监督学习，以实现性能和效率的卓越平衡，从而提升LVLMs的推理效率。

**AI_Comments:** 本文提出的PAR框架是LVLMs推理效率提升领域的一个创新性工作。其核心创新点在于引入了“元路由器”的概念，实现了跨token和跨层的自适应剪枝，这克服了现有单一维度剪枝方法的局限性。结合自监督学习，PAR能够更好地平衡性能和效率，并提供了多种剪枝版本以满足不同应用场景的需求，展现了其“全能手”的特性。这项工作对于推动LVLMs的实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉语言模型（LVLMs）的计算成本高昂，严重阻碍了其广泛应用。现有的推理效率提升方法，无论是参数依赖型还是token依赖型，都存在局限性：参数依赖型方法需要重新训练LVLMs以恢复性能，而token依赖型策略则难以持续选择最相关的token。

**Method:** 本文提出了一个名为“剪枝全能手”（Pruning All-Rounder, PAR）的新型框架。PAR不同于以往的工作，它开发了一个元路由器（meta-router）来跨token和层自适应地组织剪枝流。该方法采用自监督学习方式。

**Result:** PAR在性能和效率之间实现了卓越的平衡。此外，PAR具有高度灵活性，提供了多种剪枝版本以应对不同的加速场景。

**Conclusion:** 本文通过系统分析挑战并提出名为PAR的新型框架，有效解决了大型视觉语言模型推理效率低下的问题。PAR通过其独特的自适应剪枝策略和自监督学习方式，在性能和效率之间取得了优异的平衡，并展现出高度的灵活性。

> **ai_Abstract:** 大型视觉语言模型（LVLMs）的高计算成本限制了其广泛应用，且现有参数依赖或token依赖的效率提升方法存在各自局限。本文系统分析了这些挑战，并提出了“剪枝全能手”（PAR）框架。PAR通过一个元路由器，能够自适应地在token和层之间组织剪枝流，并采用自监督学习，从而在性能和效率之间达到卓越平衡。PAR还具有高度灵活性，可适应多种加速场景。

> **摘要翻译:** 尽管大型视觉语言模型（LVLMs）取得了令人印象深刻的成果，但其高昂的计算成本对其广泛应用构成了重大障碍。为了提高推理效率，大多数现有方法可归类为参数依赖型或token依赖型策略，以降低计算需求。然而，参数依赖型方法需要重新训练LVLMs以恢复性能，而token依赖型策略则难以持续选择最相关的token。在本文中，我们系统地分析了上述挑战，并为推理加速提供了一系列有价值的见解。基于这些发现，我们提出了一个新颖的框架，即“剪枝全能手”（Pruning All-Rounder, PAR）。与之前的工作不同，PAR开发了一个元路由器，以自适应地组织跨token和层的剪枝流。通过自监督学习方式，我们的方法在性能和效率之间实现了卓越的平衡。值得注意的是，PAR具有高度灵活性，提供多种剪枝版本以应对一系列加速场景。本工作的代码已在https://github.com/ASGO-MM/Pruning-All-Rounder 公开。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [705] [CNN-based solution for mango classification in agricultural environments](https://arxiv.org/abs/2507.23174)
> *基于CNN的农业环境下芒果分类解决方案*

*Beatriz Díaz Peón, Jorge Torres Gómez, Ariel Fajardo Márquez* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 芒果分类, 卷积神经网络, 图像处理, 农业环境, Resnet-18

**Comment:** 

> **TL;DR:** 本文提出了一种基于CNN的芒果检测与分类系统，旨在实现农场库存管理的自动化水果质量评估。

**AI_Comments:** 这篇论文提出了一种结合CNN和级联检测器在农业环境中进行芒果分类的实用解决方案。其创新点在于将成熟的深度学习模型（Resnet-18）与传统的检测器相结合，以平衡性能与资源消耗，并通过用户友好的MatLab GUI展示结果，体现了工程实用性。该方法对于农产品自动化质量控制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个能够自动评估水果质量的系统，用于农场库存管理。

**Method:** 开发了一种使用图像处理的芒果分类方法，结合Resnet-18进行分类，并使用级联检测器进行检测，以平衡速度和资源消耗。结果通过MatLab App Designer开发的图形界面显示。

**Result:** 卷积神经网络和级联检测器的集成提供了一个可靠的水果分类和检测解决方案。

**Conclusion:** CNN和级联检测器相结合的方法为水果分类和检测提供了一个可靠的解决方案，在农业质量控制方面具有潜在应用。

> **ai_Abstract:** 本文介绍了一种基于卷积神经网络（CNN）的芒果检测与分类系统。该系统旨在通过图像处理自动评估水果质量，以实现农场库存管理。研究中采用了Resnet-18进行分类，并使用级联检测器进行检测，以优化速度和资源消耗。所有结果通过MatLab App Designer开发的图形界面展示。该集成方案为水果分类和检测提供了一个可靠的解决方案，并在农业质量控制方面具有应用潜力。

> **摘要翻译:** 本文阐述了使用卷积神经网络（CNN）设计水果检测和分类系统。目标是开发一个自动评估水果质量以进行农场库存管理的系统。具体而言，开发了一种使用图像处理的芒果水果分类方法，确保了准确性和效率。Resnet-18被选为分类的初步架构，而级联检测器用于检测，以平衡执行速度和计算资源消耗。检测和分类结果通过在MatLab App Designer中开发的图形界面显示，从而简化了系统交互。卷积神经网络和级联检测器的集成提供了一个可靠的水果分类和检测解决方案，在农业质量控制方面具有潜在应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [711] [DisTime: Distribution-based Time Representation for Video Large Language Models](https://arxiv.org/abs/2505.24329)
> *DisTime：基于分布的时间表示用于视频大型语言模型*

*Yingsen Zeng, Zepeng Huang, Yujie Zhong, Chengjian Feng, Jie Hu, Lin Ma, Yang Liu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频大语言模型, 时间表示, 分布式时间解码, InternVid-TG, 时间定位

**Comment:** Accepted by ICCV 2025

> **TL;DR:** DisTime通过连续时间嵌入和分布解码器提升视频大语言模型的时间理解，并提出自动化标注范式构建了大型时间定位数据集InternVid-TG，在时间敏感任务上达到SOTA。

**AI_Comments:** 本文的创新点在于提出了基于分布的时间表示DisTime，通过连续时间嵌入和概率分布解码器，有效解决了视频大语言模型在精确时间定位上的核心挑战，特别是时间边界模糊问题。同时，其提出的自动化数据集标注范式和由此构建的大规模InternVid-TG数据集，极大地弥补了现有时间感知数据集的不足，为未来视频时间理解研究提供了宝贵的资源，对推动该领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频大型语言模型（Video-LLMs）在精确时间定位方面面临挑战，主要原因包括离散的时间表示和有限的时间感知数据集。现有时间表达方法存在将时间与文本数值混淆、添加专用时间标记或使用专用时间定位头进行时间回归等问题。

**Method:** 本文引入了轻量级框架DisTime以增强Video-LLMs的时间理解。DisTime采用可学习的标记来创建连续的时间嵌入空间，并结合了一个基于分布的时间解码器来生成时间概率分布，从而减轻边界模糊并保持时间连续性。此外，一个基于分布的时间编码器重新编码时间戳以提供时间标记。为克服现有数据集的时间粒度限制，论文提出了一种自动化标注范式，结合了Video-LLMs的字幕能力和专用时间模型的定位专业知识，从而创建了大型时间定位数据集InternVid-TG。

**Result:** DisTime在三个时间敏感任务的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。通过自动化标注范式，创建了InternVid-TG数据集，该数据集包含1.25M个时间定位事件，跨越179k个视频，比ActivityNet-Caption大55倍。

**Conclusion:** DisTime通过其创新的基于分布的时间表示方法和大规模自动化生成的数据集，显著提升了视频大语言模型在时间理解和精确时间定位方面的能力，并在多项时间敏感任务中取得了最先进的表现，同时在视频问答任务中保持了竞争力。

> **ai_Abstract:** 本文针对视频大语言模型在精确时间定位上的挑战，提出了DisTime框架。DisTime通过引入可学习标记构建连续时间嵌入空间，并利用分布式的编解码器处理时间信息，有效缓解了时间边界模糊问题。此外，为解决数据稀缺问题，作者提出了一种自动化标注范式，并构建了大规模时间定位数据集InternVid-TG。实验证明，DisTime在时间敏感任务上表现优异，并在视频问答任务中保持竞争力。

> **摘要翻译:** 尽管通用视频理解取得了进展，但视频大型语言模型（Video-LLMs）由于离散的时间表示和有限的时间感知数据集，在精确时间定位方面面临挑战。现有时间表达方法要么将时间与基于文本的数值混淆，要么添加一系列专用时间标记，要么使用专用时间定位头回归时间。为了解决这些问题，我们引入了DisTime，一个轻量级框架，旨在增强Video-LLMs的时间理解能力。DisTime采用可学习的标记来创建连续的时间嵌入空间，并结合了一个基于分布的时间解码器，该解码器生成时间概率分布，有效减轻边界模糊并保持时间连续性。此外，基于分布的时间编码器重新编码时间戳，为Video-LLMs提供时间标记。为了克服现有数据集的时间粒度限制，我们提出了一种自动化标注范式，该范式结合了Video-LLMs的字幕能力和专用时间模型的定位专业知识。这促成了InternVid-TG的创建，这是一个包含179k个视频中1.25M个时间定位事件的大型数据集，超过ActivityNet-Caption 55倍。广泛的实验表明，DisTime在三个时间敏感任务的基准测试中实现了最先进的性能，同时在视频问答任务中保持了有竞争力的性能。代码和数据已在https://github.com/josephzpng/DisTime 发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [714] [EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos referring to Procedural Texts](https://arxiv.org/abs/2410.05343)
> *EgoOops：一个用于从以自我为中心的视频中检测错误行为的数据集，参考程序文本*

*Yuto Haneji, Taichi Nishimura, Hirotaka Kameko, Keisuke Shirai, Tomoya Yoshida, Keiya Kajimura, Koki Yamamoto, Taiyu Cui, Tomohiro Nishimoto, Shinsuke Mori* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 错误行为检测, 以自我为中心视频, 程序文本, 数据集, 视频-文本对齐

**Comment:** Main 8 pages, supplementary 6 pages

> **TL;DR:** 提出了EgoOops数据集，用于在遵循程序文本的以自我为中心的视频中检测错误行为，并证明结合文本对于错误检测至关重要。

**AI_Comments:** 这项研究通过引入EgoOops数据集，有效填补了现有错误行为检测领域在处理“遵循程序文本”活动时的空白。其创新之处在于强调并实际利用了程序文本信息，这对于理解和检测依赖于指令的复杂错误至关重要。数据集的提出及其多样的标注类型，为未来相关研究提供了宝贵资源。该工作的重要性在于为开发更智能、更能理解上下文的错误检测系统奠定了基础，尤其是在工业指导、技能培训等场景下具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的错误行为检测研究主要集中于自由活动中视觉上明显的错误，且现有数据集很少使用程序文本。然而，在遵循文本的活动中，模型如果不参考文本，就无法确定某些行为的正确性。本研究旨在弥补这些空白。

**Method:** 提出了EgoOops数据集，其中包含遵循程序文本进行错误活动的以自我为中心的视频，涵盖多个领域。该数据集具有视频-文本对齐、错误标签和错误描述三种标注类型。此外，还提出了一种结合视频-文本对齐和错误标签分类的错误检测方法。

**Result:** 实验结果表明，结合程序文本对于错误行为检测至关重要。

**Conclusion:** 结合程序文本对于在遵循文本的活动中进行错误行为检测是必不可少的，EgoOops数据集及其方法为此提供了支持。

> **ai_Abstract:** 本文针对现有错误行为检测研究在处理遵循程序文本活动时的不足，提出了EgoOops数据集。该数据集包含以自我为中心的视频，记录了用户在遵循不同领域程序文本时犯下的错误，并提供了视频-文本对齐、错误标签和错误描述等标注。作者还提出了一种结合文本信息的错误检测方法，实验证明程序文本对于准确检测错误至关重要。

> **摘要翻译:** 错误行为检测对于开发能够检测工人错误并提供反馈的智能档案至关重要。现有研究主要集中于自由活动中视觉上明显的错误，导致了仅基于视频的错误检测方法。然而，在遵循文本的活动中，模型如果不参考文本，就无法确定某些行为的正确性。此外，除了烹饪之外，当前的错误数据集很少使用程序文本进行视频录制。为了弥补这些空白，本文提出了EgoOops数据集，其中以自我为中心的视频记录了在遵循不同领域程序文本时发生的错误活动。它具有三种类型的标注：视频-文本对齐、错误标签和错误描述。我们还提出了一种错误检测方法，结合了视频-文本对齐和错误标签分类，以利用文本信息。我们的实验结果表明，结合程序文本对于错误检测至关重要。数据可通过https://y-haneji.github.io/EgoOops-project-page/获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [717] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
> *探索深度学习技术从眼部图像准确进行性别分类的可行性*

*Basna Mohammed Salih Hasan, Ramadhan J. Mstafa* | **Category: cs.CV, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 性别分类, 深度学习, 卷积神经网络, 眼周区域, 图像识别

**Comment:** 12 pages, 18 figures, 5 tables

> **TL;DR:** 本研究探索使用深度学习技术，特别是卷积神经网络，通过分析眼周区域图像实现准确的性别分类，并在两个数据集上取得了96%和99%的高准确率。

**AI_Comments:** 该研究创新性地将眼周区域作为性别分类的关键信息源，有效规避了面部化妆和伪装带来的干扰，提高了分类准确性。其在安全和监控领域的潜在应用价值显著。模型在不同数据集上的高准确率和相对较少的参数量，体现了其高效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 性别分类在安全、人机交互、监控和广告等领域至关重要，但现有方法的准确性易受化妆和伪装的影响。本研究旨在通过关注眼周区域图像来解决这一问题。

**Method:** 本研究引入了一种复杂的卷积神经网络（CNN）模型，利用彩色图像数据库评估眼周区域在性别分类中的有效性。模型在CVBL和(Female and Male)两个眼部数据集上进行了测试和验证。

**Result:** 所推荐的架构在CVBL数据集上达到了99%的准确率，在(Female and Male)数据集上以少量可学习参数（7,235,089个）达到了96%的准确率。结果表明该模型在性别分类方面具有显著的有效性。

**Conclusion:** 研究结果明确证明了该模型在利用眼周区域进行性别分类方面的有效性，并预示其在安全和监控等实际应用领域中的潜力。

> **ai_Abstract:** 本论文旨在解决传统性别分类受化妆和伪装影响的问题，提出了一种基于眼周区域彩色图像的深度学习性别分类方法。研究引入了一个先进的卷积神经网络（CNN）模型，并在CVBL和(Female and Male)两个眼部数据集上进行了验证。该模型在CVBL数据集上实现了99%的准确率，在(Female and Male)数据集上实现了96%的准确率，证明了其在从眼部图像进行性别分类方面的有效性和实际应用潜力。

> **摘要翻译:** 性别分类已成为安全、人机交互、监控和广告等各个领域的关键方面。然而，这种分类的准确性可能受到化妆和伪装等因素的影响。因此，我们的研究致力于通过关注使用眼周区域彩色图像进行性别分类来解决这一问题。眼周区域指眼睛周围的区域，包括眼睑、眉毛以及它们之间的区域。它包含有价值的视觉线索，可用于提取性别分类的关键特征。本文介绍了一种复杂的卷积神经网络（CNN）模型，该模型利用彩色图像数据库评估眼周区域在性别分类中的有效性。为了验证模型的性能，我们在两个眼部数据集上进行了测试，即CVBL和（女性和男性）。所推荐的架构在之前未使用的CVBL数据集上取得了99%的卓越准确率，同时在（女性和男性）数据集上以少量可学习参数（7,235,089个）取得了96%的值得称赞的准确率。为了确定我们提出的模型在利用眼周区域进行性别分类方面的有效性，我们通过广泛的指标评估了其性能，并将其与其他最先进的方法进行了比较。结果明确证明了我们模型的有效性，从而表明其在安全和监控等领域具有实际应用潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [728] [I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation](https://arxiv.org/abs/2507.23683)
> *I2V-GS：基于高斯泼溅的自动驾驶数据生成基础设施到车辆视图转换*

*Jialei Chen, Wuhao Xu, Sipeng He, Baoru Huang, Dongchun Ren* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** I2V-GS, 高斯泼溅, 自动驾驶, 数据生成, 视图转换

**Comment:** 

> **TL;DR:** I2V-GS是一种新颖的方法，利用高斯泼溅将基础设施视图转换为车辆视图，以高效生成自动驾驶数据，并通过引入RoadSight数据集和多项技术显著提升了合成质量。

**AI_Comments:** I2V-GS的创新之处在于首次提出了基础设施到车辆的视图转换框架，解决了自动驾驶数据采集成本高、效率低的问题。通过结合高斯泼溅、自适应深度扭曲、级联修复和置信度引导优化等技术，它在数据生成质量上取得了显著提升，并为未来自动驾驶数据合成提供了新的范式。引入RoadSight数据集也为该领域的研究提供了宝贵的资源。

<details>
  <summary>Details</summary>

**Motivation:** 端到端自动驾驶系统需要大量高质量数据，但目前主要由车辆收集数据，成本高且效率低。通过合成真实世界图像数据是一种潜在解决方案，尤其是在3D重建和新颖视图合成方面取得进展后。

**Method:** 本文提出了I2V-GS方法，利用高斯泼溅技术将基础设施视图转换为车辆视图。该方法采用自适应深度扭曲生成密集训练视图，并使用级联策略修复扭曲图像以扩展视图范围并确保内容一致性。此外，它利用交叉视图信息进行置信度引导优化以确保扩散模型可靠性。论文还引入了RoadSight，一个多模态、多视图的基础设施视角真实场景数据集。

**Result:** 实验结果表明，I2V-GS显著提高了车辆视图下的合成质量，在NTA-Iou、NTL-Iou和FID方面分别优于StreetGaussian 45.7%、34.2%和14.9%。

**Conclusion:** I2V-GS是首个利用基础设施到车辆视图转换生成自动驾驶数据集的框架。

> **ai_Abstract:** 本文提出了I2V-GS，一种基于高斯泼溅的新颖方法，旨在将基础设施视图转换为车辆视图，以高效生成自动驾驶所需的大量高质量数据。针对稀疏视图重建和大幅度视图转换的挑战，I2V-GS采用了自适应深度扭曲生成密集训练视图，并通过级联策略修复图像以扩展视图范围并保持一致性，同时利用交叉视图信息进行置信度引导优化。论文还引入了RoadSight数据集。实验证明，I2V-GS在车辆视图合成质量上显著优于现有方法。

> **摘要翻译:** 海量高质量数据对于端到端自动驾驶系统至关重要。然而，目前的驾驶数据主要由车辆收集，成本高昂且效率低下。一个潜在的解决方案是从真实世界的图像中合成数据。3D重建的最新进展展示了逼真的新颖视图合成，突显了从道路上捕获的图像生成驾驶数据的潜力。本文介绍了一种新颖的方法I2V-GS，利用高斯泼溅将基础设施视图转换为车辆视图。从稀疏基础设施视角进行重建并在大视图变换下进行渲染是一个具有挑战性的问题。我们采用自适应深度扭曲来生成密集的训练视图。为了进一步扩大视图范围，我们采用级联策略来修复扭曲图像，这也确保了修复内容在不同视图之间的一致性。为了进一步确保扩散模型的可靠性，我们利用交叉视图信息执行置信度引导优化。此外，我们引入了RoadSight，一个来自基础设施视图真实场景的多模态、多视图数据集。据我们所知，I2V-GS是第一个通过基础设施-车辆视图转换生成自动驾驶数据集的框架。实验结果表明，I2V-GS显著提高了车辆视图下的合成质量，在NTA-Iou、NTL-Iou和FID方面分别优于StreetGaussian 45.7%、34.2%和14.9%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [729] [Acknowledging Focus Ambiguity in Visual Questions](https://arxiv.org/abs/2501.02201)
> *承认视觉问题中的焦点模糊性*

*Chongyan Chen, Yu-Yun Tseng, Zhuoheng Li, Anush Venkatesh, Danna Gurari* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视觉问答, 焦点模糊性, 数据集, 视觉接地, 基准测试

**Comment:** 

> **TL;DR:** 引入VQ-FocusAmbiguity数据集，解决VQA中图像内容位置的焦点模糊性问题，并发现现有模型在该数据集上表现不佳。

**AI_Comments:** 本文的创新之处在于首次提出了视觉问答（VQA）中的“焦点模糊性”问题，并构建了首个专门解决此问题的数据集VQ-FocusAmbiguity。这填补了现有VQA研究的空白，推动了VQA领域向更复杂、更贴近实际场景的理解能力发展。通过引入新的数据集和评估任务，为未来的研究提供了重要的基础和挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉问答（VQA）工作中没有考虑到问题中描述的内容在图像中位置的模糊性。为了填补这一空白，本文旨在解决视觉问题中焦点模糊性的识别和定位问题。

**Method:** 引入了VQ-FocusAmbiguity数据集，这是第一个在VQA中对问题可能指代的所有合理图像区域进行视觉接地的VQA数据集。接着，分析并比较了该数据集与现有数据集的独特属性。最后，对现代模型在两个与焦点模糊性相关的新任务上进行了基准测试：识别视觉问题是否存在焦点模糊性，以及定位图像中所有合理的焦点区域。

**Result:** 结果表明，该数据集对现代模型来说具有挑战性。

**Conclusion:** VQ-FocusAmbiguity数据集对现有模型构成了挑战，并已公开共享以促进未来在该领域的研究进展。

> **ai_Abstract:** 本文针对视觉问答（VQA）领域中未被解决的焦点模糊性问题，即问题中描述的内容在图像中的具体位置不明确，引入了首个专门处理此问题的数据集VQ-FocusAmbiguity。该数据集对问题可能指代的所有合理图像区域进行了视觉接地。研究人员对数据集进行了分析和比较，并在此基础上提出了识别和定位焦点模糊性的两项新任务，对现有模型进行了基准测试。结果显示，该数据集对现有模型构成挑战，并且已公开共享以促进未来的研究。

> **摘要翻译:** 视觉问答（VQA）领域中，目前没有任何已发表的工作考虑到问题中描述的内容在图像中位置的模糊性。为了填补这一空白，我们引入了VQ-FocusAmbiguity，这是第一个在得出有效答案时，将问题可能指代的所有合理图像区域进行视觉接地的VQA数据集。接下来，我们分析并比较了我们的数据集与现有数据集，以揭示其独特的属性。最后，我们对现代模型在两个与承认焦点模糊性相关的新任务上进行了基准测试：识别视觉问题是否存在焦点模糊性，以及定位图像中所有合理的焦点区域。结果表明，该数据集对现代模型来说具有挑战性。为了促进这些任务的未来进展，我们公开共享了该数据集，并在https://vizwiz.org/tasks-and-datasets/focus-ambiguity-in-visual-questions 提供了评估服务器。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [731] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
> *SAM-PTx：基于参数高效并行文本适配器的文本引导SAM微调*

*Shayan Jalilian, Abdul Bais* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** SAM, 文本引导分割, 参数高效, 适配器, CLIP

**Comment:** 

> **TL;DR:** SAM-PTx引入了一种参数高效的方法，通过并行文本适配器将CLIP文本嵌入注入SAM的图像编码器，以实现文本引导的图像分割，并显示出优于纯空间提示基线的性能。

**AI_Comments:** 这项工作的创新之处在于其参数高效的“并行文本”适配器设计，它巧妙地将文本嵌入集成到SAM的图像编码器中，以实现语义引导的分割，同时最大限度地减少对原始架构的修改。这是首次在COD10K数据集上利用文本提示进行分割，突出了其在探索文本语义潜力方面的开创性。这种方法为SAM的高效适应提供了一条实用且计算复杂度低的途径。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Segment Anything Model (SAM) 在基于提示的分割方面表现出色，但与点和框等传统空间提示相比，语义文本提示的潜力仍未得到充分探索。

**Method:** 本文提出了SAM-PTx，一种参数高效的方法，通过使用冻结的CLIP派生文本嵌入作为类别级语义指导来调整SAM。具体来说，我们提出了一种名为“并行文本”的轻量级适配器设计，它将文本嵌入注入SAM的图像编码器，从而实现语义引导的分割，同时保持大部分原始架构冻结。该适配器仅修改每个Transformer块的MLP并行分支，保留注意力路径用于空间推理。

**Result:** 通过在COD10K数据集以及COCO和ADE20K的低数据子集上进行的监督实验和消融研究表明，将固定文本嵌入作为输入可以提高分割性能，优于纯空间提示基线。据作者所知，这是首次在COD10K数据集上使用文本提示进行分割的工作。

**Conclusion:** 这些结果表明，将语义条件集成到SAM的架构中，为高效适应提供了一条实用且可扩展的途径，且计算复杂度极低。

> **ai_Abstract:** SAM-PTx提出了一种新颖的参数高效方法，通过引入“并行文本”适配器来增强Segment Anything Model (SAM) 的文本引导分割能力。该适配器将冻结的CLIP文本嵌入注入SAM的图像编码器，作为类别级语义指导，同时保持SAM大部分原始架构冻结，仅修改Transformer块的MLP并行分支。实验证明，这种方法在多个数据集上显著提升了分割性能，优于纯空间提示基线，并展示了将语义条件集成到SAM中以实现高效且可扩展适应的潜力。

> **摘要翻译:** 尽管Segment Anything Model (SAM) 在基于提示的分割方面表现出色，但与点和框等传统空间提示相比，语义文本提示的潜力仍未得到充分探索。本文介绍了SAM-PTx，一种参数高效的方法，通过使用冻结的CLIP派生文本嵌入作为类别级语义指导来调整SAM。具体来说，我们提出了一种名为“并行文本”的轻量级适配器设计，它将文本嵌入注入SAM的图像编码器，从而实现语义引导的分割，同时保持大部分原始架构冻结。我们的适配器仅修改每个Transformer块的MLP并行分支，保留注意力路径用于空间推理。通过在COD10K数据集以及COCO和ADE20K的低数据子集上进行的监督实验和消融研究表明，将固定文本嵌入作为输入可以提高分割性能，优于纯空间提示基线。据我们所知，这是首次在COD10K数据集上使用文本提示进行分割的工作。这些结果表明，将语义条件集成到SAM的架构中，为高效适应提供了一条实用且可扩展的途径，且计算复杂度极低。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [734] [NeRF Is a Valuable Assistant for 3D Gaussian Splatting](https://arxiv.org/abs/2507.23374)
> *NeRF 是 3D Gaussian Splatting 的宝贵助手*

*Shuangkang Fang, I-Chao Shen, Takeo Igarashi, Yufeng Wang, ZeSheng Wang, Yi Yang, Wenrui Ding, Shuchang Zhou* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** NeRF, 3D Gaussian Splatting, 3D 场景表示, 联合优化, 混合框架

**Comment:** Accepted by ICCV

> **TL;DR:** NeRF-GS 框架通过联合优化 NeRF 和 3D Gaussian Splatting (3DGS)，利用 NeRF 的连续空间表示来解决 3DGS 的局限性，实现了最先进的性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个混合框架 NeRF-GS，有效地结合了 NeRF 的连续性表示和 3DGS 的高效渲染能力。它通过解决 3DGS 的固有弱点，如对初始化的敏感性，显著提升了 3D 场景表示的质量和效率。这项工作强调了两种看似不同方法之间的互补性，为未来的 3D 视觉研究开辟了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决 3D Gaussian Splatting (3DGS) 的局限性，包括对高斯初始化敏感、空间感知有限以及高斯间关联性弱的问题。

**Method:** 引入了 NeRF-GS 框架，该框架联合优化 NeRF 和 3DGS。它通过共享 3D 空间信息，逐步将 3DGS 的空间特征与 NeRF 对齐，并优化隐式特征和高斯位置的残差向量，以增强 3DGS 的个性化能力。

**Result:** 在基准数据集上的实验结果表明，NeRF-GS 超越了现有方法，并取得了最先进的性能。

**Conclusion:** NeRF 和 3DGS 是互补而非竞争的关系，这为结合 3DGS 和 NeRF 的混合方法提供了新的见解，以实现高效的 3D 场景表示。

> **ai_Abstract:** NeRF-GS 是一个新颖的框架，它通过联合优化 NeRF 和 3DGS 来克服 3DGS 的局限性，如初始化敏感性和空间感知不足。该方法通过将 3DGS 的空间特征与 NeRF 对齐，并优化残差向量来增强 3DGS 的个性化能力。实验证明 NeRF-GS 取得了最先进的性能，表明 NeRF 和 3DGS 结合能实现高效的 3D 场景表示。

> **摘要翻译:** 我们引入了 NeRF-GS，这是一个联合优化神经辐射场 (NeRF) 和 3D Gaussian Splatting (3DGS) 的新型框架。该框架利用 NeRF 固有的连续空间表示来缓解 3DGS 的几个局限性，包括对高斯初始化的敏感性、有限的空间感知和弱的高斯间关联性，从而增强其性能。在 NeRF-GS 中，我们重新审视了 3DGS 的设计，并逐步将其空间特征与 NeRF 对齐，使两种表示能够通过共享的 3D 空间信息在同一场景中进行优化。我们通过优化隐式特征和高斯位置的残差向量，进一步解决了两种方法之间的形式区别，以增强 3DGS 的个性化能力。基准数据集上的实验结果表明，NeRF-GS 超越了现有方法并取得了最先进的性能。这一结果证实了 NeRF 和 3DGS 是互补而非竞争的关系，为结合 3DGS 和 NeRF 的混合方法提供了新的见解，以实现高效的 3D 场景表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [740] [Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network](https://arxiv.org/abs/2507.23185)
> *基于Harris角点损失和R-CBAM网络的单幅图像雨纹去除*

*Jongwook Si, Sungyoung Kim* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-31**

**Keywords:** 单幅图像雨纹去除, 角点损失, R-CBAM, 图像恢复, 深度学习

**Comment:** 21 pages

> **TL;DR:** 本文提出了一种结合角点损失和R-CBAM网络的图像恢复方法，用于单幅图像雨纹去除，有效提升了恢复图像的细节保留和视觉质量。

**AI_Comments:** 该论文的创新点在于结合了角点损失来防止细节丢失，并引入R-CBAM模块增强网络对雨纹区域的关注，这对于图像去雨任务中细节和结构保持至关重要。其在公开数据集上的表现也证明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 单幅图像雨纹去除不仅是简单的去噪，还需要同时保留精细的结构细节和整体视觉质量，这是一个挑战。

**Method:** 本文提出了一种新颖的图像恢复网络，通过引入角点损失（Corner Loss）来防止在恢复过程中丢失物体边界和详细纹理信息。此外，在编码器和解码器中引入了残差卷积块注意力模块（R-CBAM）块，以动态调整空间和通道维度特征的重要性，使网络能更有效地关注受雨纹严重影响的区域。

**Result:** 在Rain100L和Rain100H数据集上的定量评估表明，所提出的方法显著优于现有方法，在Rain100L上实现了33.29 dB的PSNR，在Rain100H上实现了26.16 dB的PSNR。

**Conclusion:** 所提出的结合角点损失和R-CBAM网络的图像恢复方法，在单幅图像雨纹去除任务中表现出色，有效提升了图像细节保留和整体视觉质量，优于现有方法。

> **ai_Abstract:** 本文针对单幅图像雨纹去除中细节保留的挑战，提出了一种新型图像恢复网络。该网络引入了角点损失以保护图像边界和纹理细节，并结合残差卷积块注意力模块（R-CBAM）以增强网络对雨纹区域的关注。实验结果表明，该方法在Rain100L和Rain100H数据集上均取得了优异的性能，显著超越了现有技术。

> **摘要翻译:** 单幅图像雨纹去除问题超越了简单的噪声抑制，需要同时保留精细的结构细节和整体视觉质量。在本研究中，我们提出了一种新颖的图像恢复网络，通过引入角点损失来有效约束恢复过程，从而防止在恢复过程中丢失物体边界和详细纹理信息。此外，我们在编码器和解码器中引入了残差卷积块注意力模块（R-CBAM）块，以动态调整空间和通道维度特征的重要性，使网络能够更有效地关注受雨纹严重影响的区域。在Rain100L和Rain100H数据集上进行的定量评估表明，所提出的方法显著优于现有方法，在Rain100L上实现了33.29 dB的PSNR，在Rain100H上实现了26.16 dB的PSNR。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [745] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
> *视觉少样本分类中的以对象为中心的裁剪*

*Aymane Abdali, Bartosz Boguslawski, Lucas Drumetz, Vincent Gripon* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 少样本分类, 对象中心裁剪, 图像歧义, Segment Anything Model, 前景提取

**Comment:** 

> **TL;DR:** 在少样本图像分类中，通过聚焦于图像中的单个对象位置信息，即使是使用少量监督或无监督方法，也能显著提高分类性能。

**AI_Comments:** 这篇论文的创新点在于提出了在少样本分类中利用对象中心化信息来解决图像歧义问题，并展示了这种方法在低监督甚至无监督情况下的有效性，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在少样本图像分类中，由于图像中存在多个对象或复杂背景导致的歧义会严重降低性能。

**Method:** 通过结合图像中对象局部位置的额外信息来增强分类，并展示了通过使用Segment Anything Model（仅需指出对象的一个像素）或采用完全无监督的前景对象提取方法，可以实现大部分改进。

**Result:** 在现有基准测试中，显著提高了分类性能。

**Conclusion:** 通过利用以对象为中心的信息，即使是使用少量监督或无监督的方法，也能有效解决少样本分类中的图像歧义问题，从而显著提升性能。

> **ai_Abstract:** 本文针对少样本图像分类中多对象和复杂背景导致的性能下降问题，提出引入对象局部位置信息。研究表明，这种对象中心化的方法能显著提升分类性能，并且大部分改进可以通过仅需少量交互的Segment Anything Model或完全无监督的前景提取方法实现。

> **摘要翻译:** 在少样本图像分类领域，即使每类只有一个示例，由多个对象或复杂背景引起的图像歧义也会显著降低性能。我们的研究表明，结合图像中对象局部位置的额外信息可以显著增强在既定基准测试中的分类效果。更重要的是，我们展示了通过使用Segment Anything Model（仅需指出感兴趣对象的一个像素）或采用完全无监督的前景对象提取方法，可以实现大部分的性能提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [756] [LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning](https://arxiv.org/abs/2503.15621)
> *LLaVA-MORE：大型语言模型和视觉骨干网络在增强视觉指令微调中的比较研究*

*Federico Cocchi, Nicholas Moratelli, Davide Caffagni, Sara Sarto, Lorenzo Baraldi, Marcella Cornia, Rita Cucchiara* | **Category: cs.CV, cs.AI, cs.CL, cs.MM** | **Updated: 2025-07-31**

**Keywords:** 多模态大语言模型, 视觉骨干, 语言模型, 视觉指令微调, 比较研究

**Comment:** ICCV 2025 Workshop on What is Next in Multimodal Foundation Models

> **TL;DR:** LLaVA-MORE通过统一训练协议，系统比较了不同大型语言模型（LLM）和视觉骨干对多模态大语言模型（MLLM）性能的影响，并提供了一个可复现的评估框架。

**AI_Comments:** 这项工作通过引入统一的评估框架和系统比较不同LLM与视觉骨干，解决了当前MLLM研究中缺乏公平比较和设计权衡探索的问题。其创新点在于对多种组件进行细致的交叉分析，并公开了代码和模型，极大地促进了领域的可复现性和未来研究。

<details>
  <summary>Details</summary>

**Motivation:** 当前多模态大型语言模型（MLLM）研究主要关注组件的规模扩展，但模型大小、架构与性能之间的权衡仍未得到充分探索。此外，训练数据和评估协议的不一致阻碍了直接比较，使得难以确定最佳设计选择。

**Method:** 本文引入了LLaVA-MORE，一个整合了最新语言模型和多样化视觉骨干的新型MLLM家族。为确保公平比较，采用统一训练协议，并将其一致应用于所有架构。系统探索了Phi-4、LLaMA-3.1、Gemma-2等小型和中型LLM，评估其多模态推理、生成和指令遵循能力。此外，全面研究了包括CLIP-based、DINOv2、SigLIP和SigLIP2在内的各种视觉编码器，并额外实验了图像分辨率和预训练数据集变化的影响。

**Result:** 研究结果为设计更有效的MLLM提供了深入见解，并提供了一个可复现的评估框架，该框架有助于直接比较并能指导未来的模型开发。

**Conclusion:** 本文通过引入LLaVA-MORE，系统性地比较了不同大型语言模型和视觉骨干在多模态大语言模型中的表现，揭示了设计更有效MLLM的关键见解，并建立了促进未来研究的可复现评估框架。

> **ai_Abstract:** 本文介绍了LLaVA-MORE，一个用于公平比较不同大型语言模型（LLM）和视觉骨干在多模态大语言模型（MLLM）中表现的新框架。通过统一的训练协议，系统研究了Phi-4、LLaMA-3.1、Gemma-2等LLM和CLIP-based、DINOv2、SigLIP等视觉编码器对多模态推理、生成和指令遵循的影响。研究还探讨了模型大小、图像分辨率和预训练数据集的作用。其结果为MLLM设计提供了关键见解，并提供了一个可复现的评估框架，以指导未来模型开发。

> **摘要翻译:** 多模态大型语言模型（MLLM）的最新进展凸显了视觉骨干和底层语言模型的关键作用。虽然先前的工作主要集中于将这些组件扩展到数十亿参数，但模型大小、架构和性能之间的权衡仍未得到充分探索。此外，训练数据和评估协议的不一致阻碍了直接比较，使得难以得出最佳设计选择。在本文中，我们引入了LLaVA-MORE，这是一个新的MLLM家族，它将最新的语言模型与多样化的视觉骨干相结合。为了确保公平比较，我们采用统一的训练协议，并将其一致应用于所有架构。我们的分析系统地探索了小型和中型LLM——包括Phi-4、LLaMA-3.1和Gemma-2——以评估多模态推理、生成和指令遵循能力，同时检查模型大小与性能之间的关系。除了评估LLM对最终结果的影响外，我们还对各种视觉编码器进行了全面研究，范围从基于CLIP的架构到DINOv2、SigLIP和SigLIP2等替代方案。额外的实验研究了图像分辨率增加和预训练数据集变化的影响。总的来说，我们的结果为设计更有效的MLLM提供了见解，提供了一个可复现的评估框架，该框架有助于直接比较并能指导未来的模型开发。我们的源代码和训练模型已公开提供：https://github.com/aimagelab/LLaVA-MORE。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [757] [DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging](https://arxiv.org/abs/2502.02171)
> *DeepForest：利用航空成像感知自遮挡植被体积*

*Mohamed Youssef, Jian Peng, Oliver Bimber* | **Category: cs.CV, eess.IV** | **Updated: 2025-07-31**

**Keywords:** 遥感, 植被体积, 航空成像, 3D卷积神经网络, 合成孔径

**Comment:** 

> **TL;DR:** DeepForest提出了一种利用常规航空图像和3D卷积神经网络深入感知茂密自遮挡植被体积的方法，显著改善了传统遥感在穿透致密冠层方面的局限性。

**AI_Comments:** 这篇论文提出了一种创新方法，显著提升了遥感能力，通过使用通常仅限于表面数据的标准航空图像，实现了对致密植被的体积感知。合成孔径成像与3D卷积神经网络的结合巧妙地解决了生态监测中的一个关键挑战。其无需专门的LiDAR或雷达系统即可穿透自遮挡体积的能力，使其在大规模生态研究中可能更具可及性和成本效益。

<details>
  <summary>Details</summary>

**Motivation:** 获取冠层下方的体积植被数据对于理解生态系统动态至关重要，而现有遥感技术（如LiDAR、雷达和相机）在深入穿透茂密冠层方面存在长期限制。

**Method:** 该方法使用常规高分辨率航空图像，通过无人机进行合成孔径成像扫描焦距栈，并利用预训练的3D卷积神经网络以均方误差（MSE）作为损失函数来减少离焦信号的贡献。最终生成包含植被体积低频表示的体积反射率栈，并结合多个光谱通道的反射率栈。

**Result:** 与模拟地面真实数据相比，该校正方法对于220棵树/公顷至1680棵树/公顷的森林密度，平均改善了约7倍（最小：约2倍，最大：约12倍）。在野外实验中，与经典多光谱航空成像测量的顶部植被层相比，实现了0.05的均方误差。

**Conclusion:** DeepForest方法有效地克服了遥感在穿透致密冠层方面的限制，能够提供有价值的体积植被数据，从而促进对生态系统的理解。

> **ai_Abstract:** 该论文介绍了DeepForest，一种利用常规高分辨率航空图像和3D卷积神经网络的新方法，旨在克服传统遥感在穿透致密、自遮挡植被体积方面的局限性。通过无人机合成孔径成像扫描焦距栈并减少离焦信号，DeepForest能够生成体积反射率栈，为冠层下方的植被提供关键见解。实验结果表明，与现有方法相比，该方法在感知深度和准确性方面取得了显著改进。

> **摘要翻译:** 获取冠层下方的体积植被数据对于理解生态系统动态至关重要。我们解决了遥感难以深入穿透茂密冠层这一长期存在的限制。目前，激光雷达（LiDAR）和雷达被认为是测量三维植被结构的主要选择，而相机只能提取顶层的反射率和深度。我们的方法使用传统的、高分辨率的航空图像，能够深入感知自遮挡的植被体积，例如森林。其原理与宽场显微成像过程相似，但可以处理更大的尺度和强遮挡。我们使用无人机通过合成孔径成像扫描焦距栈，并使用预训练的3D卷积神经网络以均方误差（MSE）作为损失函数来减少离焦信号的贡献。生成的体积反射率栈包含植被体积的低频表示。结合来自各种光谱通道的多个反射率栈可以深入了解整个植被体积的植物健康、生长和环境条件。与模拟地面真实数据相比，我们的校正对于220棵树/公顷至1680棵树/公顷的森林密度，平均改善了约7倍（最小：约2倍，最大：约12倍）。在我们的野外实验中，与经典多光谱航空成像测量的顶部植被层相比，我们实现了0.05的均方误差。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [758] [Continual-MEGA: A Large-scale Benchmark for Generalizable Continual Anomaly Detection](https://arxiv.org/abs/2506.00956)
> *持续MEGA：一个用于可泛化持续异常检测的大规模基准*

*Geonu Lee, Yujeong Oh, Geonhui Jang, Soyoung Lee, Jeonghyo Song, Sungmin Cha, YoungJoon Yoo* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 持续异常检测, 大规模基准, 零样本泛化, Continual-MEGA, ContinualAD

**Comment:** 

> **TL;DR:** 本文引入了Continual-MEGA，一个大规模的持续异常检测基准，旨在更好地反映真实世界部署场景。该基准包含大规模数据集和新的零样本泛化评估场景，并提出了一个统一的基线算法。研究发现现有方法仍有改进空间，而所提方法表现优异，且新数据集能提升模型性能。

**AI_Comments:** 这篇论文通过引入Continual-MEGA基准，解决了持续异常检测领域缺乏大规模、真实世界场景评估工具的问题。其创新点在于结合了现有数据和新数据集，并首次提出了衡量持续学习中零样本泛化能力的新场景，这对于推动异常检测在实际部署中的应用具有重要意义。同时，提出的统一基线算法也为未来的研究提供了强有力的起点。

<details>
  <summary>Details</summary>

**Motivation:** 现有异常检测的持续学习评估设置未能很好地反映真实世界部署场景，缺乏一个大规模且能衡量零样本泛化能力的基准。

**Method:** 引入Continual-MEGA基准，包含结合现有数据集和新提出的ContinualAD数据集的大规模多样化数据；提出测量对未见类零样本泛化的新场景；并提出一个统一的基线算法以提高少样本检测的鲁棒性和保持强泛化性。

**Result:** (1) 现有方法存在显著改进空间，特别是在像素级缺陷定位方面；(2) 所提出的方法持续优于现有方法；(3) 新引入的ContinualAD数据集增强了强大的异常检测模型的性能。

**Conclusion:** Continual-MEGA基准和所提出的方法为持续异常检测，特别是零样本泛化和少样本鲁棒性方面，提供了重要的评估工具和改进方向，表明该领域仍有巨大潜力。

> **ai_Abstract:** 本文推出了Continual-MEGA，一个针对持续异常检测的大规模基准，旨在模拟真实世界场景。该基准整合了现有数据与新 ContinualAD 数据集，并引入了衡量对未见类零样本泛化的新评估范式。研究还提出了一种统一的基线算法，以增强少样本检测的鲁棒性和泛化能力。实验结果表明，现有方法仍有改进空间，而所提出的方法表现优异，且 ContinualAD 数据集能提升模型的性能。

> **摘要翻译:** 在本文中，我们引入了一个用于异常检测中持续学习的新基准，旨在更好地反映现实世界的部署场景。我们的基准Continual-MEGA包含一个大规模且多样化的数据集，通过将精心策划的现有数据集与我们新提出的数据集ContinualAD相结合，显著扩展了现有的评估设置。除了数量上扩展的标准持续学习，我们提出了一个新颖的场景，用于测量对未见类（在持续适应期间未观察到的类）的零样本泛化能力。此设置提出了一个新的问题，即持续适应也能增强零样本性能。我们还提出了一种统一的基线算法，该算法提高了少样本检测的鲁棒性并保持了强大的泛化能力。通过广泛的评估，我们报告了三个关键发现：(1) 现有方法仍有很大的改进空间，特别是在像素级缺陷定位方面；(2) 我们提出的方法持续优于现有方法；(3) 新引入的ContinualAD数据集增强了强大的异常检测模型的性能。我们已在https://github.com/Continual-Mega/Continual-Mega 发布了该基准和代码。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [763] [UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration](https://arxiv.org/abs/2507.23685)
> *UniLDiff：释放扩散先验在一体化图像恢复中的潜力*

*Zihan Cheng, Liangtai Zhou, Dian Chen, Ni Tang, Xiaotong Luo, Yanyun Qu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 一体化图像恢复, 潜在扩散模型, 扩散先验, 图像恢复, 降质

**Comment:** 

> **TL;DR:** UniLDiff：一种基于潜在扩散模型的新型一体化图像恢复框架，通过整合低质量先验和专用模块（DAFF、DAEM）来处理多样化降质并保留细节，实现了最先进的性能。

**AI_Comments:** 该论文提出了一种新颖的基于潜在扩散模型的统一图像恢复框架UniLDiff，其创新点在于结构化地整合低质量视觉先验到扩散过程，并设计了DAFF和DAEM模块以分别处理多样化降质和恢复细节。其重要性在于解决了一体化图像恢复（AiOIR）的挑战，并在多任务和混合降质设置下取得了最先进的性能。抽象中未提及局限性。

<details>
  <summary>Details</summary>

**Motivation:** 一体化图像恢复（AiOIR）是一个有前景但具有挑战性的研究方向。

**Method:** 提出了一种基于潜在扩散模型（LDM）的新型统一图像恢复框架。该方法将低质量视觉先验结构化地整合到扩散过程中，以利用扩散模型强大的生成能力处理多样化降质。具体地，设计了一个降质感知特征融合（DAFF）模块来适应性处理不同类型的降质。此外，为了减轻LDM高压缩和迭代采样导致的细节损失，在解码器中设计了一个细节感知专家模块（DAEM）来增强纹理和精细结构的恢复。

**Result:** 在多任务和混合降质设置下的广泛实验表明，该方法持续实现了最先进的性能，突出了扩散先验在统一图像恢复中的实际潜力。

**Conclusion:** 该论文通过实现最先进的性能，展示了扩散先验在统一图像恢复中的实际潜力。

> **ai_Abstract:** 本文介绍了UniLDiff，一种利用潜在扩散模型进行一体化图像恢复（AiOIR）的新型统一图像恢复框架。UniLDiff将低质量视觉先验整合到扩散过程中，以处理多样化的降质。它包含一个降质感知特征融合（DAFF）模块用于自适应降质处理，以及一个细节感知专家模块（DAEM）以减轻细节损失。实验表明，UniLDiff在各种降质设置下均实现了最先进的性能，证明了扩散先验在统一图像恢复中的有效性。

> **摘要翻译:** 一体化图像恢复（AiOIR）已成为一个有前景但具有挑战性的研究方向。为了解决其核心挑战，我们提出了一种基于潜在扩散模型（LDM）的新型统一图像恢复框架。我们的方法将低质量视觉先验结构化地整合到扩散过程中，从而释放扩散模型强大的生成能力以应对多样化的降质。具体而言，我们设计了一个降质感知特征融合（DAFF）模块，以实现对不同降质类型的自适应处理。此外，为了减轻LDM高压缩和迭代采样导致的细节损失，我们在解码器中设计了一个细节感知专家模块（DAEM），以增强纹理和精细结构的恢复。在多任务和混合降质设置下进行的广泛实验表明，我们的方法持续实现了最先进的性能，突出了扩散先验在统一图像恢复中的实际潜力。我们的代码将发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [775] [Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space](https://arxiv.org/abs/2507.23188)
> *通过学习细粒度联合嵌入空间实现多模态运动检索*

*Shiyao Yu, Zi-An Wang, Kangning Yin, Zheng Tian, Mingyuan Zhang, Weixin Si, Shihao Zou* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 多模态运动检索, 联合嵌入空间, 对比学习, 序列表示, 音频模态

**Comment:** Accepted by IEEE TMM 2025

> **TL;DR:** 该论文提出了一种新的多模态运动检索框架，首次将文本、音频、视频和运动四种模态对齐到一个细粒度联合嵌入空间中，显著提升了运动检索的性能。

**AI_Comments:** 该论文的创新点在于首次将音频模态引入运动检索，并成功地将文本、音频、视频、运动四种模态对齐到一个细粒度的联合嵌入空间中，这大大增强了用户交互的直观性和便利性。通过序列级对比学习，模型能够捕获更精细的跨模态信息，从而显著提升了检索性能。其提出的4模态框架优于3模态框架的发现，也为未来多模态研究提供了有价值的见解。这对于运动获取和相关应用领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的运动检索方法主要利用文本或视觉模态，缺乏更直观和用户友好的交互模式，并且常常忽略大多数模态的序列表示，从而限制了检索性能。

**Method:** 提出一个将文本、音频、视频和运动四种模态对齐到细粒度联合嵌入空间的框架。首次引入音频模态以增强用户沉浸感和便利性。通过序列级对比学习实现细粒度空间，以捕获跨模态的关键细节。为评估框架，通过合成多样化音频记录扩充现有文本-运动数据集，创建了两个多模态运动检索数据集。

**Result:** 在多个子任务上表现优于现有最先进方法，例如在HumanML3D数据集上，文本到运动检索的R@10提高了10.16%，视频到运动检索的R@1提高了25.43%。4模态框架显著优于3模态对应框架。

**Conclusion:** 多模态运动检索，特别是结合四种模态的框架，在推进运动获取方面具有巨大潜力。

> **ai_Abstract:** 本论文提出了一种新颖的多模态运动检索框架，旨在解决现有方法在交互模式和序列表示利用方面的不足。该框架首次将文本、音频、视频和运动四种模态整合并对齐到一个细粒度的联合嵌入空间中，通过序列级对比学习实现跨模态的细节捕获。通过在扩充的数据集上进行实验，结果显示该方法在多项检索任务中显著优于现有技术，特别是在文本到运动和视频到运动检索上取得了显著性能提升，并证明了四模态集成相较于三模态的优越性，强调了多模态方法在运动获取领域的巨大潜力。

> **摘要翻译:** 运动检索对于运动获取至关重要，与运动生成相比，它提供了卓越的精度、真实感、可控性和可编辑性。现有方法利用对比学习为文本或视觉模态的运动检索构建统一的嵌入空间。然而，这些方法缺乏更直观和用户友好的交互模式，并且常常忽略大多数模态的序列表示以提高检索性能。为了解决这些限制，我们提出了一个框架，将文本、音频、视频和运动四种模态在细粒度联合嵌入空间中对齐，首次在运动检索中引入音频以增强用户沉浸感和便利性。这个细粒度空间是通过序列级对比学习方法实现的，该方法捕获了跨模态的关键细节以实现更好的对齐。为了评估我们的框架，我们通过合成但多样化的音频记录扩充了现有的文本-运动数据集，创建了两个多模态运动检索数据集。实验结果表明，在多个子任务上，我们的方法优于最先进的方法，包括在HumanML3D数据集上，文本到运动检索的R@10提高了10.16%，视频到运动检索的R@1提高了25.43%。此外，我们的结果表明，我们的4模态框架显著优于其3模态对应框架，突显了多模态运动检索在推进运动获取方面的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [776] [Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories](https://arxiv.org/abs/2507.23411)
> *基于扩散轨迹的医学图像分布外检测*

*Lemar Abdi, Francisco Caetano, Amaan Valiuddin, Christiaan Viviers, Hamdi Joudeh, Fons van der Sommen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 医学图像, 分布外检测, 扩散模型, Stein分数, 计算机辅助诊断

**Comment:** Accepted at Uncertainty for Safe Utilization of Machine Learning in
  Medical Imaging, MICCAI 2025

> **TL;DR:** 本文提出了一种基于Stein分数去噪扩散模型（SBDDM）的无重建分布外（OOD）检测方法，通过捕获扩散轨迹曲率，仅需五步扩散即可实现准确的异常评分，并在医学图像OOD检测中达到最先进的性能，同时显著降低了计算成本。

**AI_Comments:** 该论文的创新点在于提出了利用扩散模型前向轨迹的曲率进行OOD检测，避免了传统生成模型中常见的重建或似然计算，从而大幅提高了推理效率。其在医学影像领域的应用潜力巨大，尤其是在处理罕见病理情况和数据不平衡问题上具有显著优势。该方法在计算成本和性能上的改进，使其成为实际部署的有力候选。

<details>
  <summary>Details</summary>

**Motivation:** 在医学成像中，无监督的分布外（OOD）检测对于识别发病率极低的病理病例具有吸引力。然而，现有的生成方法（如基于似然估计或重建误差的方法）计算成本高昂、不可靠，并且在内部分布数据发生变化时需要重新训练，这限制了它们高效、一致且稳健地区分正常和异常输入的能力。

**Method:** 我们提出了一种无重建的OOD检测方法，该方法利用了基于Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹。通过估计的Stein分数捕获轨迹曲率，我们的方法仅需五步扩散即可实现准确的异常评分。单个SBDDM在大型、语义对齐的医学数据集上进行预训练。

**Result:** 该方法在多个近OOD和远OOD基准测试中有效泛化，实现了最先进的性能，同时显著降低了推理期间的计算成本。与现有方法相比，SBDDM在近OOD和远OOD检测方面分别取得了高达10.43%和18.10%的相对改进。

**Conclusion:** SBDDM方法在医学图像OOD检测中表现出卓越的性能和计算效率，使其成为实时、可靠计算机辅助诊断的实用构建模块。

> **ai_Abstract:** 本文提出了一种新颖的无重建分布外（OOD）检测方法，专门用于医学成像领域，以解决现有方法的局限性。该方法利用了基于Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹，通过捕获轨迹曲率来实现高效且准确的异常评分，仅需五步扩散。实验证明，预训练的SBDDM在多种OOD检测任务上均达到最先进的性能，同时显著降低了计算成本，为实时计算机辅助诊断提供了实用的解决方案。

> **摘要翻译:** 在医学成像中，无监督的分布外（OOD）检测提供了一种有吸引力的方法，用于识别发病率极低的病理病例。与监督方法相反，基于OOD的方法无需标签即可运行，并且对数据不平衡具有固有的鲁棒性。当前的生成方法通常依赖于似然估计或重建误差，但这些方法可能计算成本高昂、不可靠，并且在内部分布数据发生变化时需要重新训练。这些限制阻碍了它们高效、一致且稳健地区分正常输入和异常输入的能力。我们提出了一种无重建的OOD检测方法，该方法利用了基于Stein分数去噪扩散模型（SBDDM）的前向扩散轨迹。通过估计的Stein分数捕获轨迹曲率，我们的方法仅需五步扩散即可实现准确的异常评分。单个SBDDM在大型、语义对齐的医学数据集上进行预训练，在多个近OOD和远OOD基准测试中有效泛化，实现了最先进的性能，同时显著降低了推理期间的计算成本。与现有方法相比，SBDDM在近OOD和远OOD检测方面分别取得了高达10.43%和18.10%的相对改进，使其成为实时、可靠计算机辅助诊断的实用构建模块。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [780] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
> *个性化文本到图像扩散模型的引导策略*

*Sunghyun Park, Seokeon Choi, Hyoungwoo Park, Sungrack Yun* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 文本到图像扩散模型, 个性化, 引导, 微调, 图像生成

**Comment:** ICCV 2025

> **TL;DR:** 本文提出了一种名为“个性化引导”的新方法，通过利用一个基于空文本提示的未学习弱模型，并动态控制其未学习程度，以解决个性化文本到图像扩散模型中目标概念对齐和原始模型知识保留之间的权衡问题，从而在不增加计算开销的情况下提高文本对齐和目标分布保真度。

**AI_Comments:** 这项研究的创新之处在于提出了一种新型的“个性化引导”机制，通过结合未学习弱模型和动态权重插值，巧妙地解决了个性化文本到图像扩散模型中长期存在的保真度与可编辑性之间的矛盾。其无需额外计算开销的特性使其具有较高的实用价值和集成潜力，对于推动个性化图像生成技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 个性化文本到图像扩散模型在适应特定目标概念和实现多样化图像生成方面至关重要。然而，使用少量图像进行微调时，会在与目标分布对齐（如主体保真度）和保留原始模型广泛知识（如文本可编辑性）之间产生固有的权衡。现有采样引导方法（如CFG和AG）未能有效引导输出达到平衡空间：CFG限制了对目标分布的适应，而AG则损害了文本对齐。

**Method:** 本文提出了一种名为“个性化引导”的简单而有效的方法。该方法利用一个基于空文本提示的未学习弱模型，并在推理过程中通过预训练模型和微调模型之间的权重插值来动态控制弱模型中未学习的程度。与仅依赖引导尺度的现有方法不同，该方法明确地将输出引导至平衡的潜在空间，且不增加额外的计算开销。

**Result:** 实验结果表明，所提出的引导方法可以提高文本对齐和目标分布保真度，并能与各种微调策略无缝集成。

**Conclusion:** 通过引入“个性化引导”，本文成功解决了个性化文本到图像扩散模型中目标概念对齐和原始模型知识保留之间的权衡问题，显著提升了模型性能。

> **ai_Abstract:** 本文针对个性化文本到图像扩散模型在少量图像微调时面临的目标概念对齐与原始模型知识保留之间的权衡问题，提出了一种名为“个性化引导”的新方法。该方法通过利用一个基于空文本提示的未学习弱模型，并动态控制其未学习程度，旨在实现输出在文本对齐和目标分布保真度上的平衡。实验证明，该方法在不增加计算开销的情况下，有效提升了模型性能，并能与多种微调策略兼容。

> **摘要翻译:** 个性化文本到图像扩散模型对于使预训练模型适应特定目标概念，从而实现多样化图像生成至关重要。然而，使用少量图像进行微调时，会在与目标分布对齐（例如，主体保真度）和保留原始模型的广泛知识（例如，文本可编辑性）之间产生固有的权衡。现有的采样引导方法，例如无分类器引导（CFG）和自动引导（AG），未能有效地将输出引导至平衡空间：CFG限制了对目标分布的适应，而AG则损害了文本对齐。为了解决这些局限性，我们提出了一种个性化引导方法，这是一种简单而有效的方法，它利用一个基于空文本提示的未学习弱模型。此外，我们的方法在推理过程中通过预训练模型和微调模型之间的权重插值动态控制弱模型中未学习的程度。与仅依赖引导尺度的现有引导方法不同，我们的方法在不增加额外计算开销的情况下，明确地将输出引导至平衡的潜在空间。实验结果表明，我们提出的引导方法可以提高文本对齐和目标分布保真度，并能与各种微调策略无缝集成。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [784] [DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models](https://arxiv.org/abs/2411.18659)
> *DHCP：通过跨模态注意力模式检测大型视觉-语言模型中的幻觉*

*Yudong Zhang, Ruobing Xie, Xingwu Sun, Yiqing Huang, Jiansheng Chen, Zhanhui Kang, Di Wang, Yu Wang* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 幻觉检测, 跨模态注意力, 大型视觉-语言模型, DHCP, 可靠性

**Comment:** Accepted by ACM Multimedia 2025

> **TL;DR:** 提出DHCP，一个轻量级检测器，通过分析LVLM中的跨模态注意力模式来有效检测幻觉，无需额外训练或推理。

**AI_Comments:** DHCP的创新点在于利用LVLM内部固有的跨模态注意力模式差异来检测幻觉，避免了对LVLM进行额外训练或推理的开销，使其成为一个高效且实用的解决方案。这对于提升LVLM在实际应用中的可信度和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在多模态任务中表现出色，但仍存在严重的幻觉问题（包括对象、属性和关系幻觉），需要准确检测这些幻觉。

**Method:** 通过研究幻觉和非幻觉状态下跨模态注意力模式的差异，开发了一个轻量级检测器DHCP。该方法不需要额外的LVLM训练或额外的LVLM推理步骤。

**Result:** 实验结果表明DHCP在幻觉检测方面取得了显著性能。

**Conclusion:** DHCP通过提供识别和分析LVLMs中幻觉的新颖见解，有助于提高这些模型的可靠性和可信度。

> **ai_Abstract:** 本文提出了一种名为DHCP（通过跨模态注意力模式检测幻觉）的轻量级检测器，旨在解决大型视觉-语言模型（LVLMs）中普遍存在的幻觉问题。该方法通过分析幻觉和非幻觉状态下LVLM的跨模态注意力模式差异来识别幻觉，无需额外的模型训练或推理步骤。实验证明DHCP在幻觉检测上表现出色，为提升LVLM的可靠性提供了新方法。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在复杂的跨模态任务中展现出卓越的性能。然而，它们仍然受到严重的幻觉问题困扰，包括对象幻觉、属性幻觉和关系幻觉。为了准确检测这些幻觉，我们研究了幻觉和非幻觉状态之间跨模态注意力模式的变化。利用这些区别，我们开发了一个能够识别幻觉的轻量级检测器。我们提出的方法，通过跨模态注意力模式检测幻觉（DHCP），是直接的，并且不需要额外的LVLM训练或额外的LVLM推理步骤。实验结果表明DHCP在幻觉检测方面取得了显著性能。通过为LVLMs中幻觉的识别和分析提供新颖的见解，DHCP有助于提高这些模型的可靠性和可信度。代码已在https://github.com/btzyd/DHCP提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [785] [Learning from Rendering: Realistic and Controllable Extreme Rainy Image Synthesis for Autonomous Driving Simulation](https://arxiv.org/abs/2502.16421)
> *从渲染中学习：用于自动驾驶模拟的真实可控极端雨天图像合成*

*Kaibin Zhou, Kaifeng Huang, Hao Deng, Zelin Tao, Ziniu Liu, Lin Zhang, Shengjie Zhao* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 自动驾驶, 雨天图像合成, 模拟, 语义分割, CARLA

**Comment:** 

> **TL;DR:** 本文提出了一种结合渲染和学习优势的极端雨天图像合成器CARLARain，用于自动驾驶模拟，显著提高了语义分割模型在雨天场景中的准确性。

**AI_Comments:** 该论文的创新点在于结合了渲染和学习方法的优势，解决了现有雨天图像合成器在真实感和可控性方面的痛点。通过集成到CARLA模拟器并生成带有标签的数据，它为自动驾驶视觉感知模型的训练和评估提供了宝贵的资源，具有重要的实际应用价值。其结果表明，合成数据可以有效提高模型在复杂极端天气下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶模拟器在评估或增强视觉感知模型方面具有成本效益，但其可靠性依赖于生成场景的多样性和真实性。极端天气（尤其是极端降雨）在现实世界中难以捕捉且成本高昂。现有雨天图像合成器通常存在光照控制差和真实感有限的问题，这严重影响了模型评估的有效性。

**Method:** 提出了一种“从渲染中学习”的雨天图像合成器，该合成器结合了基于渲染方法的真实感优势和基于学习方法的可控性优势。通过将该合成器与CARLA驾驶模拟器集成，开发了CARLARain，一个极端雨天街景模拟器，能够在复杂光照条件下获取配对的雨天-干净图像和标签。

**Result:** 定性和定量实验验证了CARLARain能够有效提高语义分割模型在极端雨天场景中的准确性，在合成数据集上，模型的mIoU提高了5% - 8%，并且在复杂光照下的真实极端雨天场景中也得到了显著增强。

**Conclusion:** 所提出的CARLARain合成器能够有效生成真实且可控的极端雨天图像，显著提升了自动驾驶模拟中视觉感知模型的性能。

> **ai_Abstract:** 针对自动驾驶模拟中极端雨天场景数据不足且现有合成器真实感和可控性差的问题，本文提出了一种“从渲染中学习”的雨天图像合成器。该合成器结合了渲染的真实性和学习的可控性，并与CARLA模拟器集成，形成了CARLARain。CARLARain能够生成带有配对标签的真实雨天图像，并显著提升了语义分割模型在极端雨天场景下的准确性，在合成和真实数据集上均表现出显著改进。

> **摘要翻译:** 自动驾驶模拟器为评估或增强视觉感知模型提供了一种有效且低成本的替代方案。然而，评估的可靠性取决于生成场景的多样性和真实性。极端天气条件，特别是极端降雨，在现实世界中很少见且捕捉成本高昂。虽然模拟环境可以帮助解决这一限制，但现有的雨天图像合成器通常存在光照控制差和真实感有限的问题，这显著削弱了模型评估的有效性。为此，我们提出了一种从渲染中学习的雨天图像合成器，它结合了基于渲染方法的真实感优势和基于学习方法的可控性优势。为了验证我们的极端雨天图像合成器在语义分割任务上的有效性，我们需要一组连续的、标记良好的极端雨天图像。通过将所提出的合成器与CARLA驾驶模拟器集成，我们开发了CARLARain，一个极端雨天街景模拟器，它可以在复杂光照条件下获取配对的雨天-干净图像和标签。定性和定量实验验证了CARLARain能够有效提高语义分割模型在极端雨天场景中的准确性，在合成数据集上，模型的准确性（mIoU）提高了5% - 8%，并在复杂光照下的真实极端雨天场景中得到了显著增强。我们的源代码和数据集可在https://github.com/kb824999404/CARLARain/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [798] [Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation](https://arxiv.org/abs/2507.23709)
> *可解释的图像分类与降低过高置信度用于组织表征*

*Alfie Roddan, Chi Xu, Serine Ajlouni, Irini Kakaletri, Patra Charalampaki, Stamatia Giannarou* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 图像分类, 可解释性, 像素归因, 过高置信度, 风险估计

**Comment:** 

> **TL;DR:** 提出一种新的像素归因方法，将风险估计纳入其中，以提高图像分类的可解释性，同时降低过高置信度，并在医疗图像和ImageNet上表现优异。

**AI_Comments:** 该论文的创新点在于首次将风险估计引入像素归因方法，从而有效解决了深度学习模型过高置信度导致解释性不可靠的问题。这对于医疗诊断等高风险应用场景尤为重要，因为它不仅提供了决策依据，还量化了这种决策的潜在风险。该方法通过迭代生成PA图体积和像素级分布来细化解释性，并利用CV量化风险，提升了模型透明度和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习模型在图像分类预测中存在过高置信度，这导致像素归因也存在过高置信度，影响了模型解释性，尤其是在需要辅助决策的医疗场景中，使得模型部署面临挑战。

**Method:** 本文提出了一种将风险估计纳入像素归因方法的新方法。该方法迭代地将分类模型与像素归因方法应用于图像，以创建PA（像素归因）图的体积。首次利用该体积生成像素级的PA值分布，并通过估计像素级分布的期望值来生成增强的PA图。此外，使用变异系数（CV）来估计增强PA图的像素级风险。

**Result:** 在基于探头的共聚焦激光内窥镜（pCLE）数据和ImageNet上的性能评估验证了所提出的改进可解释性方法优于现有技术。

**Conclusion:** 所提出的方法不仅提供改进的PA图，而且还能对输出PA值进行风险估计，并在医疗图像和ImageNet数据集上取得了优于现有技术的可解释性表现。

> **ai_Abstract:** 本文提出了一种创新的图像分类可解释性方法，旨在解决深度学习模型预测中普遍存在的过高置信度问题。通过将风险估计整合到像素归因（PA）过程中，该方法能够生成改进的PA图，并提供像素级的风险估计。具体而言，它迭代地生成PA图体积，从中推导出像素级PA值分布，并利用期望值和变异系数分别生成增强PA图和风险图。在pCLE和ImageNet数据集上的实验结果表明，该方法在可解释性方面优于现有技术。

> **摘要翻译:** 将机器学习模型在术中用于组织表征可以辅助决策并指导安全的肿瘤切除。对于图像分类模型，像素归因方法是推断可解释性的流行方法。然而，深度学习模型预测中的过高置信度会转化为像素归因中的过高置信度。在本文中，我们提出了第一个将风险估计纳入像素归因方法以改进图像分类可解释性的方法。所提出的方法迭代地将分类模型与像素归因方法应用于图像，以创建PA图的体积。该体积首次用于生成像素级PA值分布。我们引入了一种通过估计像素级分布的期望值来生成增强PA图的方法。此外，变异系数（CV）用于估计此增强PA图的像素级风险。因此，所提出的方法不仅提供改进的PA图，而且还对输出PA值产生风险估计。在基于探头的共聚焦激光内窥镜（pCLE）数据和ImageNet上的性能评估验证了我们改进的可解释性方法优于现有技术。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [800] [Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification](https://arxiv.org/abs/2506.19330)
> *电子元件分类中微调ImageNet预训练模型的比较性能*

*Yidi Shao, Longfei Zhou, Fangshuo Tang, Xinyi Shi, Dalang Chen, Shengtao Xia* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 电子元件分类, ImageNet, 预训练模型, 迁移学习, 深度学习

**Comment:** Due to issues related to author order and some problems in the
  current version regarding methodology, we would like to withdraw the preprint
  to avoid potential conflicts

> **TL;DR:** 本文比较了12种ImageNet预训练模型在电子元件分类中的性能，MobileNet-V2表现最佳，达到99.95%的准确率，证明了预训练模型在工业应用中的有效性。

**AI_Comments:** 该研究通过比较多种ImageNet预训练模型在电子元件分类中的表现，为工业界选择合适的模型提供了实用参考。其创新点在于对特定工业应用场景下不同通用预训练模型的性能进行了量化比较，验证了迁移学习在有限数据条件下的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 电子元件分类和检测在制造业中至关重要，能够显著降低劳动力成本并促进技术和工业发展。预训练模型在图像分类中非常有效，即使数据有限也能让研究人员取得优异成果。

**Method:** 本文比较了十二种ImageNet预训练模型在电子元件分类中的性能。

**Result:** 所有测试模型都提供了可观的准确率。MobileNet-V2的准确率最高，达到99.95%，而EfficientNet-B0的准确率最低，为92.26%。

**Conclusion:** 使用ImageNet预训练模型在图像分类任务中具有显著优势，并证实了这些方法在电子制造领域的实际适用性。

> **ai_Abstract:** 本文比较了十二种在ImageNet上预训练的模型在电子元件分类任务中的性能。研究发现，所有模型均表现出良好的准确性，其中MobileNet-V2以99.95%的准确率表现最佳，EfficientNet-B0为92.26%。结果表明ImageNet预训练模型在图像分类任务中具有显著优势，并证明了其在电子制造业的实用性。

> **摘要翻译:** 电子元件分类和检测在制造业中至关重要，能够显著降低劳动力成本并促进技术和工业发展。预训练模型，特别是那些在ImageNet上训练的模型，在图像分类中非常有效，即使数据有限也能让研究人员取得优异成果。本文比较了十二种ImageNet预训练模型在电子元件分类中的性能。我们的研究结果表明，所有测试模型都提供了可观的准确率。MobileNet-V2的准确率最高，达到99.95%，而EfficientNet-B0的准确率最低，为92.26%。这些结果强调了在图像分类任务中使用ImageNet预训练模型的巨大优势，并证实了这些方法在电子制造领域的实际适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [801] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
> *通过Adapt-WeldNet和缺陷检测可解释性分析推进海事作业中的焊缝缺陷检测*

*Kamal Basha S, Athira Nambiar* | **Category: cs.CV, cs.AI, cs.CE, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 焊缝缺陷检测, Adapt-WeldNet, 可解释性, 可解释人工智能, 海事作业

**Comment:** 

> **TL;DR:** 本文提出了Adapt-WeldNet和缺陷检测可解释性分析（DDIA）框架，旨在提高海洋环境中焊缝缺陷检测的性能、可解释性和系统信任度。

**AI_Comments:** 本文的创新之处在于其双重方法：一方面通过Adapt-WeldNet提供了一个自适应框架来优化模型性能，另一方面通过DDIA框架深度解决了AI模型在关键安全领域（如海洋焊缝检测）中长期存在的信任和可解释性问题。DDIA整合了XAI技术、领域专家验证和人机协作，这对于确保AI决策的可靠性、公平性和问责制至关重要，极大地促进了AI在高风险工业应用中的实际部署和信任建立。

<details>
  <summary>Details</summary>

**Motivation:** 传统无损检测方法难以发现细微或内部缺陷，导致潜在故障和高成本停机。现有基于神经网络的缺陷分类方法依赖任意选择的预训练架构且缺乏可解释性，在部署时存在安全隐患。因此，确保油气行业管道系统在挑战性海洋和海上环境中的安全性和可靠性至关重要。

**Method:** 本文提出了“Adapt-WeldNet”，一个自适应的焊缝缺陷检测框架，它系统地评估各种预训练架构、迁移学习策略和自适应优化器，以识别最佳性能模型和超参数，从而优化缺陷检测并提供可操作的见解。此外，还提出了一个新颖的缺陷检测可解释性分析（DDIA）框架，通过采用可解释人工智能（XAI）技术（如Grad-CAM和LIME），并结合经ASNT NDE二级专业人员验证的领域特定评估，增强系统透明度。DDIA还结合了人机协作（HITL）方法并遵循可信人工智能原则，通过专家验证确保缺陷检测系统的可靠性、公平性和问责制。

**Result:** 通过提高性能和可解释性，该工作增强了焊缝缺陷检测系统的信任、安全性和可靠性。

**Conclusion:** 通过提高性能和可解释性，本文的工作增强了焊缝缺陷检测系统的信任、安全性和可靠性，支持海上和海洋环境中的关键操作。

> **ai_Abstract:** 本文针对海洋作业中焊缝缺陷检测面临的挑战，提出了Adapt-WeldNet和缺陷检测可解释性分析（DDIA）框架。Adapt-WeldNet是一个自适应框架，通过系统评估预训练架构、迁移学习策略和优化器来优化缺陷检测性能。DDIA通过采用可解释AI技术（如Grad-CAM和LIME），并结合由ASNT NDE二级专业人员验证的领域特定评估和人机协作（HITL）方法，增强了系统透明度和可信度。这项工作旨在通过提高性能和可解释性，提升焊缝缺陷检测系统的信任、安全性和可靠性，支持关键的海上和海洋作业。

> **摘要翻译:** 焊缝缺陷检测对于确保油气行业管道系统的安全性和可靠性至关重要，尤其是在充满挑战的海洋和海上环境中。传统的无损检测（NDT）方法往往无法检测到细微或内部缺陷，导致潜在的故障和昂贵的停机时间。此外，现有的基于神经网络的缺陷分类方法通常依赖于任意选择的预训练架构，并且缺乏可解释性，这为部署带来了安全隐患。为了解决这些挑战，本文引入了“Adapt-WeldNet”，一个用于焊缝缺陷检测的自适应框架，它系统地评估各种预训练架构、迁移学习策略和自适应优化器，以识别最佳性能模型和超参数，从而优化缺陷检测并提供可操作的见解。此外，还提出了一个新颖的缺陷检测可解释性分析（DDIA）框架，以增强系统透明度。DDIA采用可解释人工智能（XAI）技术，如Grad-CAM和LIME，并结合经ASNT NDE二级专业人员验证的领域特定评估。通过结合人机协作（HITL）方法并遵循可信人工智能原则，DDIA确保了缺陷检测系统的可靠性、公平性和问责制，通过专家验证增强了对自动化决策的信心。通过提高性能和可解释性，这项工作增强了焊缝缺陷检测系统的信任、安全性和可靠性，支持海上和海洋环境中的关键操作。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [804] [Enhanced Velocity Field Modeling for Gaussian Video Reconstruction](https://arxiv.org/abs/2507.23704)
> *高斯视频重建的增强速度场建模*

*Zhenyang Li, Xiaoyang Bai, Tongchen Zhang, Pengfei Shen, Weiwei Xu, Yifan Peng* | **Category: cs.CV, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 高斯辐射场, 视频重建, 速度场, 光流, 动态场景

**Comment:** 17 pages, 8 figures

> **TL;DR:** 针对高斯视频重建中复杂运动和尺度变化导致的过拟合和次优视觉质量问题，本文提出了FlowGaussian-VR，一种基于光流的速度场建模方案，通过速度场渲染和光流辅助自适应密度策略，显著提高了动态场景的重建质量，减少了模糊伪影，并使高斯轨迹更规律。

**AI_Comments:** 该论文通过将光流与高斯辐射场相结合，为动态场景重建提供了一种创新方法，尤其解决了现有变形网络在处理复杂运动时的局限性以及静态密度化策略的不足。利用速度场和光流辅助的自适应密度化是提高挑战性运动场景中鲁棒性和视觉质量的新颖途径，这使得高斯辐射场在VR/AR应用中更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于视频重建的3D高斯辐射场在处理复杂运动和显著尺度变化的视频时，变形网络常会过拟合不规则的高斯轨迹，导致视觉质量不佳。此外，为静态场景重建设计的基于梯度的密度化策略也无法有效处理动态内容。

**Method:** 本文提出了FlowGaussian-VR，一种为高斯视频重建量身定制的、由光流驱动的速度场建模方案。它包含两个核心组件：一个速度场渲染（VFR）管道，支持基于光流的优化；以及一个光流辅助自适应密度化（FAD）策略，用于调整动态区域高斯点的数量和大小。

**Result:** 在多视角动态重建和新视角合成任务中，FlowGaussian-VR在多个包含挑战性运动场景的真实世界数据集上验证了其有效性，展示了显著的视觉改进（PSNR增益超过2.5 dB），减少了动态纹理中的模糊伪影，并使每个高斯点的轨迹更加规律和可追踪。

**Conclusion:** FlowGaussian-VR通过引入流驱动的速度场建模和自适应密度化策略，有效解决了高斯视频重建中复杂动态场景的挑战，显著提升了视觉质量并稳定了高斯轨迹。

> **ai_Abstract:** 本文提出FlowGaussian-VR，一种增强高斯视频重建的方法，旨在解决现有变形网络在复杂动态场景中过拟合和模糊伪影的问题。该方法引入了光流驱动的速度场建模，包括一个基于光流优化的速度场渲染管道和一个光流辅助的自适应密度化策略，以动态调整高斯点的数量和大小。实验结果表明，FlowGaussian-VR在视觉质量上取得了显著提升（PSNR增益超2.5 dB），减少了动态纹理的模糊，并使高斯轨迹更加稳定和可追踪。

> **摘要翻译:** 高保真3D视频重建对于在虚拟现实/增强现实（VR/AR）中实现具有真实运动的动态场景实时渲染至关重要。3D高斯辐射场的变形场范式由于深度变形网络强大的表示能力，在视频重建中取得了近乎真实感的结果。然而，在具有复杂运动和显著尺度变化的视频中，变形网络经常过拟合不规则的高斯轨迹，导致次优的视觉质量。此外，为静态场景重建设计的基于梯度的密度化策略不足以解决动态内容的缺失问题。鉴于这些挑战，我们提出了一种专为高斯视频重建量身定制的、由光流驱动的速度场建模方案，称为FlowGaussian-VR。它由两个核心组件组成：一个速度场渲染（VFR）管道，支持基于光流的优化；以及一个光流辅助自适应密度化（FAD）策略，用于调整动态区域高斯点的数量和大小。我们在包含挑战性运动场景的多个真实世界数据集上，通过多视角动态重建和新视角合成验证了我们模型的有效性，不仅展示了显著的视觉改进（PSNR增益超过2.5 dB）和动态纹理中更少的模糊伪影，而且还实现了规律且可追踪的每个高斯点轨迹。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [808] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
> *$MV_{Hybrid}$: 利用混合状态空间-视觉Transformer骨干改进病理视觉基础模型中的空间转录组预测*

*Won June Cho, Hongjun Yoon, Daeky Jeong, Hyeongyeol Lim, Yosep Chong* | **Category: cs.CV, cs.AI, cs.CE, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 空间转录组学, 视觉Transformer, 状态空间模型, 病理学, 基因表达预测

**Comment:** Accepted (Oral) in MICCAI 2025 COMPAYL Workshop

> **TL;DR:** 为了克服现有病理视觉基础模型在空间基因表达预测上的不足，本文引入了一种结合状态空间模型和视觉Transformer的混合骨干架构$MV_{Hybrid}$，并在多项任务中展现出卓越的性能和鲁棒性。

**AI_Comments:** 该论文的创新点在于提出了$MV_{Hybrid}$，一个将状态空间模型 (SSMs) 与视觉Transformer (ViT) 相结合的混合骨干架构，用于病理视觉基础模型。其重要性在于通过更好地捕捉病理图像中的低频形态模式，显著提高了空间基因表达预测的准确性和鲁棒性，这对于推动精准肿瘤学和临床应用具有重要意义。该方法有望成为下一代病理VFM骨干。

<details>
  <summary>Details</summary>

**Motivation:** 空间转录组技术成本高昂且复杂，限制了其临床应用。通过常规组织病理图像预测空间基因表达是一种实用替代方案，但目前基于Vision Transformer (ViT) 的病理视觉基础模型 (VFMs) 表现未达临床标准。研究者假设超越ViT的架构创新能更好地捕捉与分子表型相关的低频、细微形态模式。

**Method:** 通过证明负实特征值初始化的状态空间模型 (SSMs) 具有强烈的低频偏差，我们引入了$MV_{Hybrid}$，这是一种结合SSMs和ViT的混合骨干架构。我们比较了其他五种不同的病理VFM骨干架构，所有模型都在相同的结直肠癌数据集上使用DINOv2自监督学习方法进行预训练，并使用随机分割和留一研究 (LOSO) 设置对预训练模型进行评估。

**Result:** 在LOSO评估中，$MV_{Hybrid}$在基因表达预测方面比表现最佳的ViT高出57%的关联性，并且与随机分割相比，性能下降减少了43%，分别显示出卓越的性能和鲁棒性。此外，$MV_{Hybrid}$在分类、补丁检索和生存预测任务中也显示出与ViT相同或更好的下游性能。

**Conclusion:** $MV_{Hybrid}$展现出作为下一代病理VFM骨干的潜力。

> **ai_Abstract:** 本研究旨在改进从组织病理图像预测空间基因表达的性能，以克服现有空间转录组技术的局限性。针对当前基于ViT的病理视觉基础模型 (VFMs) 表现不佳的问题，研究者提出$MV_{Hybrid}$，一种结合状态空间模型 (SSMs) 和ViT的混合骨干架构，利用SSMs捕捉低频形态模式的优势。在结直肠癌数据集上预训练后，通过随机分割和留一研究 (LOSO) 评估，$MV_{Hybrid}$在基因表达预测中显示出比最佳ViT更高的相关性和更小的性能下降，并在其他下游任务中表现出同等或更优的性能，证明了其作为下一代病理VFM骨干的巨大潜力。

> **摘要翻译:** 空间转录组学揭示了组织背景下的基因表达模式，从而实现了如治疗反应预测等精准肿瘤学应用，但其高成本和技术复杂性限制了临床采用。从常规组织病理图像预测空间基因表达（生物标志物）提供了一种实用的替代方案，然而目前基于视觉Transformer（ViT）骨干的病理学视觉基础模型（VFMs）表现低于临床标准。鉴于VFMs已经在大规模多样化的全玻片图像上进行训练，我们假设超越ViT的架构创新可能更好地捕捉与分子表型相关的低频、细微形态模式。通过证明以负实特征值初始化的状态空间模型表现出强烈的低频偏差，我们引入了$MV_{Hybrid}$，这是一种结合状态空间模型（SSMs）和ViT的混合骨干架构。我们比较了病理VFMs的五种其他不同骨干架构，所有这些都使用DINOv2自监督学习方法在相同的结直肠癌数据集上进行预训练。我们使用相同生物标志物数据集的随机分割和留一研究（LOSO）设置来评估所有预训练模型。在LOSO评估中，$MV_{Hybrid}$在基因表达预测方面比表现最佳的ViT高出57%的关联性，并且与随机分割相比，性能下降减少了43%，分别显示出卓越的性能和鲁棒性。此外，$MV_{Hybrid}$在分类、补丁检索和生存预测任务中也显示出与ViT相同或更好的下游性能，这表明其作为下一代病理VFM骨干的潜力。我们的代码已公开可用：https://github.com/deepnoid-ai/MVHybrid。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [810] [A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery](https://arxiv.org/abs/2507.23193)
> *一种对卫星图像季节性变化具有鲁棒性的新型洪水检测数据集*

*Youngsun Jang, Dongyoun Kim, Chulwoo Pack, Kwanghee Won* | **Category: cs.CV, I.4.6; I.2.10; I.5.4** | **Updated: 2025-07-31**

**Keywords:** 洪水检测, 卫星图像, 数据集, 语义分割, 遥感

**Comment:** 8 pages, 2 figures. Presented at ACM RACS 2024 (Pompei, Italy, Nov
  5-8, 2024)

> **TL;DR:** 本研究引入了一个新的数据集，用于在卫星图像中分割洪水区域，以解决现有数据集中缺乏合适数据集的问题。对最先进模型的测试结果表明，需要未来的多模态和时间学习策略。

**AI_Comments:** 这项研究的创新之处在于创建了一个针对卫星图像洪水检测的专用数据集，填补了现有数据空白。其重要性在于为未来研究提供了宝贵的资源，并明确指出当前模型在处理此类复杂任务时面临的挑战，从而指引了未来多模态和时间学习方法的发展方向。

<details>
  <summary>Details</summary>

**Motivation:** 研究人员在审查了77个现有的利用卫星图像的基准数据集后，发现缺乏适用于洪水区域分割的合适数据集，因此创建了一个新数据集来填补这一空白。

**Method:** 研究人员从Planet Explorer收集了2019年美国中西部洪水的卫星图像，创建了一个包含每个位置10张卫星图像（包括洪水和非洪水区域）的数据集。数据集涵盖爱荷华州、堪萨斯州、蒙大拿州、内布拉斯加州和南达科他州各十个地点，并确保了数据处理过程中统一的分辨率和大小调整。为了评估语义分割性能，研究人员在该数据集上测试了计算机视觉和遥感领域的最先进模型，并进行了不同窗口大小的消融研究以捕捉时间特性。

**Result:** 最先进的模型在该数据集上表现出适度的结果。

**Conclusion:** 模型表现出的适度结果表明，未来需要多模态和时间学习策略来改进洪水检测。

> **ai_Abstract:** 本研究提出了一个针对卫星图像中洪水检测的新型数据集，旨在解决现有基准数据集中相关数据不足的问题。该数据集包含2019年美国中西部洪水的卫星图像，覆盖五个州共50个地点，每个地点提供10张图像。研究团队在该数据集上测试了最先进的语义分割模型，结果显示模型表现平平，这突出表明未来在洪水检测方面需要开发多模态和时间学习策略。该数据集将公开可用。

> **摘要翻译:** 本研究引入了一个用于在卫星图像中分割洪水区域的新型数据集。在审查了77个利用卫星图像的现有基准数据集后，我们发现缺乏适用于这项特定任务的合适数据集。为了填补这一空白，我们从Planet Labs的Planet Explorer收集了2019年美国中西部洪水的卫星图像（图像版权所有 2024 Planet Labs PBC）。该数据集包含每个位置10张卫星图像，每张图像都包含洪水和非洪水区域。我们从爱荷华州、堪萨斯州、蒙大拿州、内布拉斯加州和南达科他州这五个州中各选择了十个地点。在数据处理过程中，数据集确保了统一的分辨率和大小调整。为了评估语义分割性能，我们测试了计算机视觉和遥感领域最先进的模型。此外，我们还进行了一项消融研究，改变窗口大小以捕捉时间特征。总体而言，模型表现出适度的结果，这表明未来需要多模态和时间学习策略。该数据集将在 https://github.com/youngsunjang/SDSU_MidWest_Flood_2019 公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [813] [Vector-Quantized Vision Foundation Models for Object-Centric Learning](https://arxiv.org/abs/2502.20263)
> *用于以对象为中心学习的矢量量化视觉基础模型*

*Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 以对象为中心学习, 视觉基础模型, 矢量量化, 对象发现, 视觉预测

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出了一种名为 VQ-VFM-OCL (VVO) 的统一架构，通过共享量化视觉基础模型表示作为重建目标，显著提升了以对象为中心学习的性能。

**AI_Comments:** 该论文的创新点在于提出了一个统一的架构 VQ-VFM-OCL (VVO)，通过对视觉基础模型 (VFM) 表示进行共享量化作为重建目标，有效解决了以对象为中心学习 (OCL) 在处理复杂纹理时的局限性。其简洁而有效的设计，以及通过数学建模和统计验证来解释 VFM 在 OCL 中的作用，都增加了其重要性。实验结果显示其在多项任务中均优于基线，表明了该方法的普适性和有效性。

<details>
  <summary>Details</summary>

**Motivation:** 以对象为中心学习 (OCL) 在从聚合槽重建输入时，难以处理复杂的对象纹理。现有方法虽利用视觉基础模型 (VFM) 表示，但未能充分发挥其潜力。

**Method:** 本文提出了一种名为矢量量化视觉基础模型用于以对象为中心学习 (VQ-VFM-OCL, 简称 VVO) 的简洁架构，该架构统一了主流的 OCL 方法。其核心在于共享量化相同的 VFM 表示作为重建目标。此外，通过数学建模和统计验证，分析了 VFM 表示如何促进 OCL 聚合以及共享量化如何增强 OCL 监督。

**Result:** 实验结果表明，在不同的 VFM、聚合器和解码器上，VVO 在对象发现和识别以及下游视觉预测和推理方面始终优于基线方法。

**Conclusion:** VQ-VFM-OCL (VVO) 是一种有效且统一的架构，它通过共享量化 VFM 表示作为重建目标，显著提升了以对象为中心学习的性能，并在多项任务中展现出优越性。

> **ai_Abstract:** 本文提出了一种名为 VQ-VFM-OCL (VVO) 的新架构，旨在解决以对象为中心学习 (OCL) 在处理复杂纹理时的挑战，并充分利用视觉基础模型 (VFM) 的潜力。VVO 通过统一主流 OCL 方法，并采用共享量化 VFM 表示作为重建目标，显著提升了对象发现、识别以及下游视觉预测和推理的性能。

> **摘要翻译:** 将视觉场景感知为对象和背景——正如人类所做的那样——以对象为中心学习 (OCL) 将图像或视频特征图聚合为对象级别的特征向量，称为“槽”。OCL 通过从这些聚合槽重建输入进行自监督，但这种方法在处理复杂对象纹理时面临困难，因此使用视觉基础模型 (VFM) 表示作为聚合输入和重建目标。然而，现有方法以多种方式利用 VFM 表示，并且往往未能充分发挥其潜力。为此，我们提出了一种简洁的架构——用于 OCL 的矢量量化 VFM (VQ-VFM-OCL，或 VVO)——它统一了主流的 OCL 方法。我们统一的关键在于简单而有效，即共享量化相同的 VFM 表示作为重建目标。通过数学建模和统计验证，我们进一步分析了 VFM 表示为何有助于 OCL 聚合以及它们作为重建目标的共享量化如何加强 OCL 监督。实验表明，在不同的 VFM、聚合器和解码器上，我们的 VVO 在对象发现和识别以及下游视觉预测和推理方面始终优于基线。实现代码和模型检查点可在 https://github.com/Genera1Z/VQ-VFM-OCL 上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [818] [Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2507.23416)
> *使用高光谱成像和机器学习检测蜂蜜掺假*

*Mokhtar A. Al-Awadhi, Ratnadeep R. Deshmukh* | **Category: cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 蜂蜜掺假, 高光谱成像, 机器学习, 线性判别分析, K近邻

**Comment:** 

> **TL;DR:** 本文提出了一种基于高光谱成像和机器学习的系统，用于自动检测蜂蜜中糖浆掺假，并实现了96.39%的检测准确率。

**AI_Comments:** 该研究提出了一种非侵入性、高效的蜂蜜掺假检测方法，通过结合高光谱成像和机器学习，为食品安全检测提供了新的思路。其高准确率表明了该方法在实际应用中的潜力，有望替代耗时且可能破坏样本的传统化学方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在开发一个基于机器学习的系统，用于根据蜂蜜高光谱成像数据自动检测蜂蜜中糖浆掺假。

**Method:** 该系统包括两个子系统：植物来源识别和掺假检测。每个子系统都包含两个步骤：首先使用线性判别分析（LDA）提取相关特征，然后使用K近邻（KNN）模型进行分类（植物来源）或识别掺假水平。

**Result:** 所提出的系统能够以96.39%的总交叉验证准确率检测蜂蜜中的掺假。

**Conclusion:** 该系统可以作为当前基于化学检测方法的合适替代方案。

> **ai_Abstract:** 本文提出了一种利用高光谱成像和机器学习技术检测蜂蜜中糖浆掺假的自动化系统。该系统包含植物来源识别和掺假检测两个子系统，均采用线性判别分析（LDA）进行特征提取，并结合K近邻（KNN）模型进行分类和浓度量化。在公共数据集上的评估显示，该系统在蜂蜜掺假检测方面达到了96.39%的总交叉验证准确率，证明其可作为现有化学检测方法的有效替代。

> **摘要翻译:** 本文旨在开发一个基于机器学习的系统，用于根据蜂蜜高光谱成像数据自动检测蜂蜜中糖浆掺假。首先，通过植物来源识别子系统对蜂蜜样本的花源进行分类。然后，通过掺假检测子系统识别糖浆掺假并量化其浓度。这两个子系统都包含两个步骤。第一步是使用线性判别分析（LDA）从蜂蜜样本中提取相关特征。第二步，我们利用K近邻（KNN）模型在第一个子系统中对蜂蜜植物来源进行分类，并在第二个子系统中识别掺假水平。我们在一个公共蜂蜜高光谱图像数据集上评估了所提出系统的性能。结果表明，所提出的系统能够以96.39%的总交叉验证准确率检测蜂蜜中的掺假，使其成为当前基于化学检测方法的合适替代方案。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [828] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
> *IN2OUT：使用分层判别器对视频修复模型进行微调以实现视频外绘*

*Sangwoo Youn, Minji Lee, Nokap Tony Park, Yeonggyoo Jeon, Taeyoung Na* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 视频外绘, 视频修复, 分层判别器, 对抗训练, 损失函数

**Comment:** ICIP 2025. Code: https://github.com/sang-w00/IN2OUT

> **TL;DR:** 提出IN2OUT方法，通过引入分层判别器和专门的外绘损失函数，有效微调视频修复模型进行视频外绘，解决了传统方法模糊和一致性差的问题，并优于现有技术。

**AI_Comments:** 本文的创新点在于认识到视频修复模型在对象流学习和重建方面的优势，并提出通过引入分层判别器和专门的损失函数来克服直接将其应用于视频外绘时产生的模糊和不一致问题。这种方法有效地弥补了现有判别器在评估扩展区域感知质量方面的不足，从而实现了高质量的视频外绘。其重要性在于为视频内容扩展提供了一种更有效、更一致的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 视频外绘在扩展边界的同时保持内容一致性是一个挑战。直接应用或微调视频修复模型进行外绘效果不佳，常导致模糊结果。主要问题在于缺乏能够有效评估扩展区域感知质量的判别器。

**Method:** 本文提出IN2OUT方法，建议使用擅长对象流学习和重建的视频修复模型进行外绘。为了解决直接应用导致的问题，研究引入了一个分层判别器，将对抗训练目标分为全局和局部目标。此外，开发了一个专门的外绘损失函数，利用判别器的局部和全局特征，并通过此对抗性损失函数进行微调。

**Result:** 提出的方法在定量和定性上都优于现有最先进的方法。微调增强了生成器生成视觉吸引且全局连贯的外绘场景的能力。

**Conclusion:** 通过引入分层判别器和专门的外绘损失函数，可以有效地将视频修复模型微调用于视频外绘任务，从而克服了现有方法的局限性并取得了卓越的性能。

> **ai_Abstract:** 本文提出IN2OUT方法，旨在通过微调视频修复模型来解决视频外绘的挑战。针对直接应用修复模型效果不佳且产生模糊结果的问题，作者发现关键在于缺乏有效的感知质量判别器。为此，他们引入了一个分层判别器，将对抗性训练目标分解为全局和局部，并开发了一个利用这些特征的专门外绘损失函数。实验证明，该方法能有效提升生成器生成视觉吸引且全局连贯的外绘场景的能力，并在定量和定性上超越了现有最先进的方法。

> **摘要翻译:** 视频外绘在扩展边界的同时保持与给定内容的一致性方面提出了独特的挑战。在本文中，我们建议使用在对象流学习和重建方面表现出色的视频修复模型进行外绘，而不是像现有方法那样仅仅生成背景。然而，直接应用或微调修复模型进行外绘已被证明是无效的，常常导致模糊的结果。我们对判别器设计的广泛实验表明，外绘微调过程中缺失的关键组件是能够有效评估扩展区域感知质量的判别器。为了解决这一限制，我们将对抗训练的目标区分为全局和局部目标，并引入了一个满足这两个目标的分层判别器。此外，我们开发了一种专门的外绘损失函数，该函数利用了判别器的局部和全局特征。在此对抗性损失函数上进行微调，增强了生成器生成视觉吸引且全局连贯的外绘场景的能力。我们提出的方法在定量和定性上都优于最先进的方法。包括演示视频和代码在内的补充材料可在SigPort中获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [830] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
> *CLIPTime：图像和文本的时间感知多模态表示学习*

*Anju Rani, Daniel Ortiz-Arroyo, Petar Durdevic* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 时间感知,多模态学习,视觉-语言模型,生物生长,CLIPTime

**Comment:** 11 pages, 8 figures

> **TL;DR:** CLIPTime是一个基于CLIP的多任务框架，能从图像和文本中预测生物生长时间和阶段，无需显式时间输入，有效解决了现有视觉语言模型在捕获时间动态方面的局限。

**AI_Comments:** 这篇论文的创新点在于将时间维度引入到现有的视觉-语言模型（如CLIP）中，使其能够理解和预测生物生长的时间动态。通过多任务学习（分类和回归）和合成数据集的构建，解决了现有模型在处理时间序列数据方面的局限性。其无需显式时间输入的推理能力，在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 理解生物生长的时序动态在微生物学、农业和生物降解研究等领域至关重要。现有视觉语言模型（如CLIP）在联合视觉-文本推理方面能力强大，但在捕获时间进程方面的有效性有限。

**Method:** 提出CLIPTime，一个多模态、多任务框架，旨在从图像和文本输入中预测真菌生长的发育阶段和对应的时间戳。该模型基于CLIP架构，学习联合视觉-文本嵌入，并能在测试时无需显式时间输入进行时间感知推理。为训练和评估，引入了一个合成真菌生长数据集，该数据集标注了对齐的时间戳和分类阶段标签。CLIPTime同时执行分类和回归任务，预测离散的生长阶段和连续的时间戳。还提出了自定义评估指标，包括时间准确性和回归误差。

**Result:** 实验结果表明，CLIPTime能有效模拟生物进程，并产生可解释的、时间上具有依据的输出。

**Conclusion:** CLIPTime展示了视觉语言模型在实际生物监测应用中的潜力，有效解决了生物生长时序动态理解的挑战。

> **ai_Abstract:** CLIPTime是一个新颖的多模态、多任务框架，它扩展了CLIP模型，使其能够从图像和文本输入中预测生物生长的发育阶段和时间戳。该模型无需显式时间输入即可进行时间感知推理，并通过引入合成真菌生长数据集和自定义评估指标进行训练和验证。实验证明，CLIPTime能有效建模生物进程，为生物监测应用提供了有前景的解决方案。

> **摘要翻译:** 理解生物生长的时序动态在微生物学、农业和生物降解研究等不同领域都至关重要。尽管像对比语言图像预训练（CLIP）这样的视觉-语言模型在联合视觉-文本推理方面表现出强大的能力，但它们在捕获时间进程方面的有效性仍然有限。为了解决这个问题，我们提出了CLIPTime，一个多模态、多任务框架，旨在从图像和文本输入中预测真菌发育阶段和相应的时间戳。我们的模型建立在CLIP架构之上，学习联合视觉-文本嵌入，并能在测试时无需显式时间输入实现时间感知推理。为了方便训练和评估，我们引入了一个合成真菌生长数据集，该数据集标注了对齐的时间戳和分类阶段标签。CLIPTime联合执行分类和回归，预测离散的生长阶段和连续的时间戳。我们还提出了自定义评估指标，包括时间准确性和回归误差，以评估时间感知预测的精确度。实验结果表明，CLIPTime能有效建模生物进程，并产生可解释的、时间上具有依据的输出，突出了视觉-语言模型在现实世界生物监测应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [833] [DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching](https://arxiv.org/abs/2507.23715)
> *DiffuMatch：用于鲁棒非刚性形状匹配的类别无关谱扩散先验*

*Emery Pierson, Lei Li, Angela Dai, Maks Ovsjanikov* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 非刚性形状匹配, 泛函映射, 扩散模型, 谱域, 数据驱动正则化

**Comment:** Presented at ICCV 2025

> **TL;DR:** 现有的深度泛函映射方法在学习方面受限于特征函数，并依赖于公理化模型进行损失或正则化。本文首次提出用数据驱动方法完全替代网络内正则化和泛函映射训练，通过在谱域中训练泛函映射的生成模型，并证明其类别无关性，在零样本非刚性形状匹配上优于公理化方法。

**AI_Comments:** 这篇论文通过用数据驱动的生成模型取代深度泛函映射框架中传统的公理化正则化和训练，实现了重要的创新。它解决了以往方法的一个关键限制，提高了准确性和适用性。所学模型的类别无关性尤其值得注意，表明其广泛的适用性。谱扩散先验和新颖蒸馏策略的运用是重要的技术贡献。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有深度泛函映射方法将学习限制在特征函数上，并仍依赖于公理化建模来制定训练损失或进行网络内部的泛函映射正则化。这限制了所得方法的准确性和适用性，使其仅限于公理化模型假设成立的场景。

**Method:** 首先，使用基于分数的生成建模，从大量高质量映射中构建，在谱域中训练泛函映射的生成模型。然后，利用所得模型来提升新形状集合上真实泛函映射的结构特性。关键技术贡献是谱域中扩散模型的一种新颖蒸馏策略。

**Result:** 所学习的模型是类别无关的，并且可以完全取代常用的策略，例如强制拉普拉斯交换性或泛函映射的正交性。实验表明，学习到的正则化在零样本非刚性形状匹配方面比公理化方法取得了更好的结果。

**Conclusion:** 本文首次证明了在深度泛函映射框架中，网络内正则化和泛函映射训练都可以完全由数据驱动方法替代。这克服了公理化模型的局限性，显著提高了零样本非刚性形状匹配的性能。

> **ai_Abstract:** DiffuMatch 是一项关于非刚性形状匹配的新方法，它在深度泛函映射框架中引入了完全数据驱动的解决方案。与现有方法不同，DiffuMatch 通过使用基于分数的生成建模在谱域中训练泛函映射的生成模型，并结合一种新的扩散模型蒸馏策略，取代了传统的公理化正则化和训练。该方法证明了其学习到的正则化是类别无关的，并能有效替代传统约束，在零样本非刚性形状匹配中表现优于传统方法。

> **摘要翻译:** 深度泛函映射最近已成为解决非刚性形状对应任务的强大工具。使用这种方法的方法结合了泛函映射框架的强大功能和灵活性，以及数据驱动学习以提高准确性和通用性。然而，该领域大多数现有方法仅将学习方面限制在特征函数上，并且仍然依赖于公理化建模来制定训练损失或网络内部的泛函映射正则化。这限制了所得方法的准确性和适用性，使其仅限于公理化模型假设成立的场景。在这项工作中，我们首次展示了网络内正则化和泛函映射训练都可以用数据驱动方法代替。为此，我们首先使用基于分数的生成建模，从大量高质量映射中构建，在谱域中训练泛函映射的生成模型。然后，我们利用所得模型来提升新形状集合上真实泛函映射的结构特性。值得注意的是，我们证明了所学习的模型是类别无关的，并且可以完全取代常用的策略，例如强制拉普拉斯交换性或泛函映射的正交性。我们的关键技术贡献是谱域中扩散模型的一种新颖蒸馏策略。实验表明，我们学习到的正则化在零样本非刚性形状匹配方面比公理化方法取得了更好的结果。我们的代码可在 https://github.com/daidedou/diffumatch/ 获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [841] [VRM: Knowledge Distillation via Virtual Relation Matching](https://arxiv.org/abs/2502.20760)
> *VRM：通过虚拟关系匹配进行知识蒸馏*

*Weijia Zhang, Fei Xie, Weidong Cai, Chao Ma* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 知识蒸馏, 关系匹配, 虚拟关系, 亲和图, 过拟合

**Comment:** Accepted by ICCV 2025 (Highlight)

> **TL;DR:** 本文提出了一种名为VRM的虚拟关系匹配方法，通过构建和修剪亲和图来解决关系型知识蒸馏中存在的过拟合和虚假响应问题，并在多个数据集和任务上取得了最先进的性能。

**AI_Comments:** 该论文通过引入虚拟视图和关系来构建更丰富的亲和图，并结合动态修剪机制，有效地解决了关系型知识蒸馏长期存在的过拟合和虚假响应问题，使其性能超越了基于实例匹配的方法。其创新性在于对知识形式的重新定义和对蒸馏过程的精细化控制，对于推动知识蒸馏领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，基于关系的知识蒸馏方法在性能上落后于基于实例匹配的方法，且存在过拟合和虚假响应等关键问题，本文旨在重振关系型知识蒸馏。

**Method:** 本文提出VRM（虚拟关系匹配）方法，通过利用虚拟视图和关系作为一种新型知识，构建并转移紧凑封装了样本间、类别间和视图间相关性的亲和图，为学生模型提供更丰富的指导信号和更强的正则化。为进一步减轻虚假响应的不利影响，动态修剪亲和图，移除冗余和不可靠的边。

**Result:** 在CIFAR-100、ImageNet和MS-COCO数据集上的大量实验表明，所提出的VRM方法表现优异，在多种模型、架构、任务和设置中持续创造了新的最先进记录。例如，VRM首次将ImageNet上ResNet50到MobileNetV2蒸馏的准确率提高到74.0%，并使用ResNet56教师将CIFAR-100上的DeiT-T性能提升了14.44%。

**Conclusion:** VRM方法通过解决关系型知识蒸馏的关键问题，显著提升了知识蒸馏的性能，并在多个基准测试中达到了新的最先进水平，证明了关系型知识蒸馏的潜力。

> **ai_Abstract:** 本文提出了一种名为VRM（虚拟关系匹配）的新型知识蒸馏方法，旨在解决现有关系型知识蒸馏方法中存在的过拟合和虚假响应问题。VRM通过构建并转移包含丰富样本间、类别间和视图间相关性的亲和图，并动态修剪这些图以消除冗余和不可靠的边，从而为学生模型提供更强的指导和正则化。实验结果表明，VRM在多个数据集和任务上均取得了显著的性能提升，并创下了新的最先进记录，成功重振了关系型知识蒸馏。

> **摘要翻译:** 知识蒸馏（KD）旨在将更强大但笨重的教师模型的知识转移到轻量级的学生模型。近年来，基于关系的知识蒸馏方法已经落后，因为它们的实例匹配对应方法在性能上占据主导地位。在本文中，我们通过识别和解决关系型方法中的几个关键问题，包括它们对过拟合和虚假响应的敏感性，从而重振了关系型知识蒸馏。具体来说，我们通过利用虚拟视图和关系作为一种新型知识，转移了新颖构建的亲和图，这些图紧凑地封装了丰富的样本间、类别间和视图间相关性。因此，学生在蒸馏过程中可以获得更丰富的指导信号和更强的正则化。为了进一步减轻虚假响应的不利影响，我们通过动态分离冗余和不可靠的边来修剪亲和图。在CIFAR-100、ImageNet和MS-COCO数据集上的大量实验表明，所提出的虚拟关系匹配（VRM）方法表现优异，在多种模型、架构、任务和设置中持续创造了新的最先进记录。例如，VRM首次将ImageNet上ResNet50到MobileNetV2蒸馏的准确率提高到74.0%，并使用ResNet56教师将CIFAR-100上的DeiT-T性能提升了14.44%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [842] [ZIP: Scalable Crowd Counting via Zero-Inflated Poisson Modeling](https://arxiv.org/abs/2506.19955)
> *ZIP：通过零膨胀泊松建模实现可扩展人群计数*

*Yiming Ma, Victor Sanchez, Tanaya Guha* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 人群计数, 零膨胀泊松模型, 可扩展性, 稀疏性, 密度图

**Comment:** 15 pages, 11 figures

> **TL;DR:** 本文提出了ZIP框架，通过零膨胀泊松模型解决了现有方法在人群计数中稀疏性数据和计数数据类型不匹配的问题，并在不同模型规模下均优于现有最先进方法。

**AI_Comments:** 这篇论文的创新点在于引入了零膨胀泊松模型来解决人群计数中普遍存在的零值过多和数据分布不匹配的问题。通过将空块的概率建模和非空块的计数建模分开，ZIP更准确地反映了真实世界中人群分布的特点。此外，对可扩展性的强调和在不同模型规模下的SOTA表现，表明了其在实际应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人群计数方法直接使用均方误差（MSE）损失回归块状密度图，存在两个关键限制：1) 未能解释注释的极端空间稀疏性，导致信息区域的监督信号被过多的零稀释；2) MSE对应的高斯误差模型与离散、非负的计数数据不匹配。

**Method:** 本文引入了ZIP框架，通过零膨胀泊松似然对块计数进行建模。该模型包含一个零膨胀项，用于学习块在结构上为空的概率（处理过多的零），以及一个泊松分量，用于在有人存在时捕获预期计数（尊重离散性）。泛化分析表明，在训练分辨率适度大的情况下，ZIP比基于MSE和DMCount的损失具有更紧密的风险界限。作者还在参数/计算量相差超过100倍的骨干网络上实例化了ZIP以评估其可扩展性。

**Result:** 在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd数据集上的实验表明，ZIP在所有模型规模下都始终超越了最先进的方法。

**Conclusion:** ZIP通过零膨胀泊松模型有效地解决了人群计数中稀疏性和数据类型不匹配的问题，并实现了更好的泛化能力和卓越的性能，证明了其可扩展性和有效性。

> **ai_Abstract:** 本文提出了ZIP，一个可扩展的人群计数框架，旨在解决现有方法在处理极端稀疏注释和离散计数数据时的局限性。ZIP采用零膨胀泊松似然模型，通过零膨胀项处理空块，泊松分量捕获非空块的计数。理论分析显示ZIP具有更紧密的风险界限，并在多个基准数据集上，无论模型规模大小，均超越了现有最先进的方法，展示了其优越的性能和可扩展性。

> **摘要翻译:** 大多数人群计数方法直接使用均方误差（MSE）损失回归块状密度图。这种做法有两个关键限制：（1）它未能解释注释的极端空间稀疏性——在标准基准测试中，超过95%的8x8块是空的，因此信息区域的监督信号被主要的零稀释了；（2）MSE对应于高斯误差模型，与离散、非负的计数数据不匹配。为了解决这些问题，我们引入了ZIP，一个可扩展的人群计数框架，它使用零膨胀泊松似然来建模块状计数：一个零膨胀项学习块在结构上为空的概率（处理过多的零），而泊松分量在有人存在时捕获预期计数（尊重离散性）。我们提供了一个泛化分析，表明在训练分辨率适度大的情况下，ZIP比基于MSE的损失和DMCount具有更紧密的风险界限。为了评估ZIP的可扩展性，我们在参数/计算量相差超过100倍的骨干网络上实例化了它。在ShanghaiTech A & B、UCF-QNRF和NWPU-Crowd上的实验表明，ZIP在所有模型规模下都始终超越了最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [843] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
> *基于扩散模型的关节对象生成：通过部分点云对齐和物理合理性约束进行引导*

*Jens U. Kreber, Joerg Stueckler* | **Category: cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 关节对象生成, 点云对齐, 物理合理性, 符号距离函数

**Comment:** Accepted for publication at the IEEE/CVF International Conference on
  Computer Vision (ICCV), 2025

> **TL;DR:** PhysNAP是一种基于扩散模型的方法，用于生成与部分点云对齐且物理上更合理的关节对象，通过SDF、对齐损失和物理约束实现。

**AI_Comments:** PhysNAP的创新之处在于将物理合理性约束（非穿透和可移动性）和点云对齐损失集成到扩散模型中，以生成更实用的关节对象。这种方法对于需要精确物理交互的虚拟环境和机器人应用具有重要意义。它在提高约束一致性方面的表现值得关注，尽管与生成能力存在权衡，这可能是在实际应用中需要进一步优化的方向。

<details>
  <summary>Details</summary>

**Motivation:** 关节对象是日常环境中重要的可交互对象，现有生成方法可能缺乏与部分点云的对齐或物理合理性，本研究旨在解决这些问题。

**Method:** 本文提出PhysNAP，一种基于扩散模型的方法，用于生成关节对象。它通过符号距离函数（SDFs）表示零件形状，并使用基于预测SDFs计算的点云对齐损失来引导反向扩散过程。此外，它还施加基于零件SDFs的非穿透和可移动性约束，以生成更物理合理的物体。该方法还支持类别感知以进一步改善点云对齐。

**Result:** PhysNAP在PartNet-Mobility数据集上评估显示，与无引导的基线扩散模型相比，它能提高约束一致性，并在生成能力上提供权衡。

**Conclusion:** PhysNAP通过结合点云对齐和物理合理性约束，成功地改进了关节对象的生成，使其在物理上更加合理且与给定点云对齐。

> **ai_Abstract:** 本文提出PhysNAP，一种新颖的扩散模型，旨在生成与部分点云对齐且物理上更合理的关节对象。该方法利用符号距离函数（SDFs）表示零件形状，并通过点云对齐损失、非穿透和可移动性约束来引导扩散过程。PhysNAP还支持类别感知以增强对齐。在PartNet-Mobility数据集上的评估表明，PhysNAP显著提高了生成对象的约束一致性，并在此与生成能力之间取得了平衡。

> **摘要翻译:** 关节对象是日常环境中一类重要的可交互对象。在本文中，我们提出了PhysNAP，一种新颖的基于扩散模型的方法，用于生成关节对象，该方法能使其与部分点云对齐并提高其物理合理性。该模型通过符号距离函数（SDFs）表示零件形状。我们使用通过预测SDFs计算的点云对齐损失来引导反向扩散过程。此外，我们基于零件SDFs施加非穿透和可移动性约束，以引导模型生成更物理合理的物体。如果类别信息可用，我们还使我们的扩散方法具有类别感知能力，以进一步改善点云对齐。我们使用PartNet-Mobility数据集评估了PhysNAP生成的样本的生成能力和约束一致性。我们还将其与无引导的基线扩散模型进行了比较，并证明PhysNAP可以提高约束一致性并提供与生成能力的权衡。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [851] [Medical Image De-Identification Benchmark Challenge](https://arxiv.org/abs/2507.23608)
> *医疗图像去识别基准挑战赛*

*Linmin Pei, Granger Sutton, Michael Rutherford, Ulrike Wagner, Tracy Nolan, Kirk Smith, Phillip Farmer, Peter Gu, Ambar Rana, Kailing Chen, Thomas Ferleman, Brian Park, Ye Wu, Jordan Kojouharov, Gargi Singh, Jon Lemon, Tyler Willis, Milos Vukadinovic, Grant Duffy, Bryan He, David Ouyang, Marco Pereanez, Daniel Samber, Derek A. Smith, Christopher Cannistraci, Zahi Fayad, David S. Mendelson, Michele Bufano, Elmar Kotter, Hamideh Haghiri, Rajesh Baidya, Stefan Dvoretskii, Klaus H. Maier-Hein, Marco Nolden, Christopher Ablett, Silvia Siggillino, Sandeep Kaushik, Hongzhu Jiang, Sihan Xie, Zhiyu Wan, Alex Michie, Simon J Doran, Angeline Aurelia Waly, Felix A. Nathaniel Liang, Humam Arshad Mustagfirin, Michelle Grace Felicia, Kuo Po Chih, Rahul Krish, Ghulam Rasool, Nidhal Bouaynaya, Nikolas Koutsoubis, Kyle Naddeo, Kartik Pandit, Tony O'Sullivan, Raj Krish, Qinyan Pan, Scott Gustafson, Benjamin Kopchick, Laura Opsahl-Ong, Andrea Olvera-Morales, Jonathan Pinney, Kathryn Johnson, Theresa Do, Juergen Klenk, Maria Diaz, Arti Singh, Rong Chai, David A. Clunie, Fred Prior, Keyvan Farahani* | **Category: cs.CV, cs.CR** | **Updated: 2025-07-31**

**Keywords:** 医疗图像去识别, 患者隐私, DICOM, 基准挑战赛, 保护健康信息

**Comment:** 19 pages

> **TL;DR:** 本文报告了MIDI-B挑战赛的设计、实施和结果，该挑战赛旨在为医学图像去识别工具提供标准化基准，以确保患者隐私并保留研究元数据。

**AI_Comments:** MIDI-B挑战赛的重要性在于其为医疗图像去识别领域提供了一个急需的标准化基准平台，这对于促进医学图像安全共享和推动AI在医疗领域的应用至关重要。其创新之处在于使用了大规模、多样化的真实去识别图像与合成PHI/PII相结合的数据集，并鼓励参与者探索多种去识别技术（如LLM和OCR）。挑战赛的高分结果表明当前去识别技术的成熟度，同时也为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 出于患者隐私保护法规（如HIPAA）的合规性要求，共享医疗图像时需要对受保护的健康信息（PHI）和个人身份信息（PII）进行去识别。同时，保留非PHI元数据对于下游成像人工智能（AI）的开发至关重要。MIDI-B挑战赛旨在提供一个标准化平台，用于对DICOM图像去识别工具进行基准测试。

**Method:** MIDI-B挑战赛提供了一个标准化平台，遵循HIPAA安全港法规、DICOM属性保密配置文件和TCIA定义的最佳实践。挑战赛分为训练、验证和测试三个阶段，使用了大量、多样化、多中心、多模态的真实去识别放射学图像，并插入了合成的PHI/PII。通过计算正确操作的百分比来衡量去识别工具的成功率。

**Result:** 十支团队成功完成了测试阶段，得分范围从97.91%到99.93%。参与者采用了多种开源和专有工具，以及定制配置、大型语言模型和光学字符识别（OCR）。

**Conclusion:** 本文全面报告了MIDI-B挑战赛的设计、实施、结果和经验教训。挑战赛成功地为医学图像去识别工具提供了一个标准化基准测试平台，并展示了现有技术的有效性。

> **ai_Abstract:** MIDI-B挑战赛旨在为医学图像去识别工具建立一个标准化的基准平台，以确保患者隐私合规性并保留对AI开发至关重要的非PHI元数据。该挑战赛分为训练、验证和测试三个阶段，使用了包含合成PHI/PII的真实放射学图像进行测试。最终，十支团队完成了测试，其去识别准确率在97.91%至99.93%之间，并采用了包括大型语言模型和OCR在内的多种技术。本文详细报告了此次挑战赛的设计、实施、结果和所获经验。

> **摘要翻译:** 受保护健康信息（PHI）和个人身份信息（PII）的去识别（deID）是共享医学图像，特别是通过公共存储库共享时的一项基本要求，以确保符合患者隐私法。此外，保留非PHI元数据以告知和支持下游成像人工智能（AI）的开发是生物医学研究中的一个重要考量。MIDI-B的目标是提供一个标准化平台，用于根据符合HIPAA安全港法规、DICOM属性保密配置文件以及癌症影像档案（TCIA）定义的保存研究关键元数据的最佳实践，对DICOM图像去识别工具进行基准测试。挑战赛采用了大量、多样化、多中心、多模态的真实去识别放射学图像集，并插入了合成的PHI/PII。
MIDI-B挑战赛包括三个阶段：训练、验证和测试。八十名个人注册了挑战赛。在训练阶段，我们鼓励参与者使用其内部或公共数据来调整算法。验证和测试阶段分别使用了包含合成标识符的DICOM图像（分别来自216和322名受试者）。十支团队成功完成了挑战赛的测试阶段。为了衡量基于规则的图像去识别方法的成功率，分数被计算为正确操作占所需操作总数的百分比。分数范围从97.91%到99.93%。参与者采用了各种开源和专有工具以及定制配置、大型语言模型和光学字符识别（OCR）。在本文中，我们提供了关于MIDI-B挑战赛设计、实施、结果和经验教训的全面报告。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [852] [Adversarial-Guided Diffusion for Multimodal LLM Attacks](https://arxiv.org/abs/2507.23202)
> *对多模态大型语言模型攻击的对抗引导扩散*

*Chengwei Xia, Fan Ma, Ruijie Quan, Kun Zhan, Yi Yang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 对抗性攻击, 扩散模型, 多模态LLM, 对抗引导扩散, 鲁棒性

**Comment:** 

> **TL;DR:** 提出一种对抗引导扩散 (AGD) 方法，通过在扩散模型的噪声中注入对抗性语义来攻击多模态LLM，同时保持图像质量并增强对防御的鲁棒性。

**AI_Comments:** 该论文的创新点在于其独特的对抗性扰动注入方式。通过将对抗性信号嵌入到扩散模型的全频谱噪声中，而非传统的高频扰动，AGD在保持图像视觉质量的同时，显著增强了对抗性样本对常见防御（如低通滤波）的）鲁棒性。这对于理解和防御多模态LLM的潜在安全漏洞具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在生成对抗性图像以欺骗多模态LLM时，可能导致图像严重失真，且对防御措施不鲁棒。本文旨在生成能欺骗MLLM且不显著扭曲原始图像的对抗性图像。

**Method:** 提出对抗引导扩散 (AGD) 方法。与传统攻击不同，AGD将目标语义注入到逆向扩散过程的噪声分量中，而非直接嵌入高频扰动。由于扩散模型的噪声覆盖整个频谱，嵌入的对抗信号也具有全频谱特性。在逆向扩散中，对抗性图像是干净图像和噪声的线性组合，使得噪声中的对抗性图像在低通滤波等防御下不易被抑制。

**Result:** 广泛的实验表明，AGD在攻击性能和模型对某些防御措施的鲁棒性方面均优于现有最先进的方法。

**Conclusion:** AGD通过在扩散噪声中注入全频谱对抗信号，成功实现了对MLLM的有效攻击，同时保持了图像质量并增强了对各种防御的鲁棒性。

> **ai_Abstract:** 本文提出一种名为对抗引导扩散（AGD）的新方法，用于生成针对多模态大型语言模型（MLLMs）的对抗性图像。与传统方法不同，AGD通过在逆向扩散过程中将目标对抗语义注入到噪声分量中，而非直接修改图像高频部分。这种全频谱的噪声注入方式使得生成的对抗性图像在保持原始图像质量的同时，对低通滤波等防御措施表现出更强的鲁棒性。实验证明，AGD在攻击有效性和防御鲁棒性方面均优于现有先进方法。

> **摘要翻译:** 本文解决了使用扩散模型生成对抗性图像以欺骗多模态大型语言模型（MLLMs）生成目标响应，同时避免干净图像显著失真的挑战。为了解决上述挑战，我们提出了一种用于对抗性攻击MLLMs的对抗引导扩散（AGD）方法。我们引入对抗引导噪声以确保攻击效果。我们设计中的一个关键观察是，与大多数直接将高频扰动嵌入干净图像的传统对抗性攻击不同，AGD将目标语义注入到逆向扩散的噪声分量中。由于扩散模型中添加的噪声跨越整个频率频谱，因此嵌入其中的对抗信号也继承了这种全频谱特性。重要的是，在逆向扩散过程中，对抗性图像是干净图像和噪声的线性组合。因此，当应用简单的低通滤波等独立作用于每个组件的防御措施时，噪声分量中的对抗性图像不太可能被抑制，因为它不局限于高频带。这使得AGD本质上对各种防御具有鲁棒性。广泛的实验表明，我们的AGD在攻击性能以及模型对某些防御的鲁棒性方面优于现有最先进的方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [860] [Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification](https://arxiv.org/abs/2507.23436)
> *超越线性瓶颈：基于样条的知识蒸馏用于文化多样性艺术风格分类*

*Abdellah Zakaria Sellam, Salah Eddine Bekhouche, Cosimo Distante, Abdelmalik Taleb-Ahmed* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 艺术风格分类, 知识蒸馏, Kolmogorov-Arnold网络, 非线性特征关联

**Comment:** 

> **TL;DR:** 该论文通过将双教师知识蒸馏框架中的线性层替换为Kolmogorov-Arnold网络（KANs），以更好地建模非线性风格交互，从而改进了艺术风格分类，并实现了更高的准确性。

**AI_Comments:** 该论文的创新之处在于将Kolmogorov-Arnold网络（KANs）应用于艺术风格分类的知识蒸馏，特别是用于捕获非线性特征交互。这解决了复杂美学任务中线性模型的常见局限性。利用KANs解开风格流形是该研究的一个重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 艺术风格分类面临挑战，原因在于专业标注数据集的稀缺性以及风格元素之间复杂且通常是非线性的相互作用。虽然最近的双教师自监督框架减少了对标注数据的依赖，但其线性投影层和局部关注难以建模全局构图上下文和复杂的风格特征交互。

**Method:** 本研究通过用Kolmogorov-Arnold网络（KANs）取代传统的MLP投影和预测头，增强了双教师知识蒸馏框架。该方法利用KANs基于样条的激活函数来精确建模非线性特征相关性，同时保留了两个教师网络的互补指导（一个侧重于局部纹理和笔触模式，另一个捕获更广泛的风格层次）。

**Result:** 在WikiArt和Pandora18k数据集上的实验表明，该方法在Top-1准确率上优于基础双教师架构。研究结果强调了KANs在解开复杂风格流形方面的重要性，从而实现了比MLP投影更好的线性探测准确率。

**Conclusion:** 研究结果强调了Kolmogorov-Arnold网络（KANs）在解开复杂风格流形方面的重要性，从而带来了更好的性能。

> **ai_Abstract:** 本论文旨在解决艺术风格分类中现有双教师自监督框架的局限性，即线性投影层难以处理非线性风格交互和全局上下文。文章提出通过将Kolmogorov-Arnold网络（KANs）集成到双教师知识蒸馏框架中，取代传统的MLP投影和预测头。KANs利用其基于样条的激活函数，能够精确建模非线性特征相关性。在WikiArt和Pandora18k数据集上的实验结果表明，这种基于KANs的增强方法在Top-1准确率和线性探测准确率上均显著优于基础双教师架构，突出了KANs在解开复杂风格流形中的关键作用。

> **摘要翻译:** 艺术风格分类在计算美学领域仍然是一个严峻的挑战，这归因于专家标注数据集的稀缺性以及风格元素之间复杂且通常是非线性的相互作用。尽管最近的双教师自监督框架减少了对标注数据的依赖，但它们的线性投影层和局部关注难以建模全局构图上下文和复杂的风格特征交互。我们通过用Kolmogorov-Arnold网络（KANs）取代传统的MLP投影和预测头，增强了双教师知识蒸馏框架以解决这些局限性。我们的方法保留了来自两个教师网络的互补指导，一个侧重于局部纹理和笔触模式，另一个捕获更广泛的风格层次，同时利用KANs基于样条的激活函数以数学精度建模非线性特征相关性。在WikiArt和Pandora18k上的实验表明，我们的方法在Top-1准确率上优于基础双教师架构。我们的发现强调了KANs在解开复杂风格流形方面的重要性，从而实现了比MLP投影更好的线性探测准确率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [861] [Meta CLIP 2: A Worldwide Scaling Recipe](https://arxiv.org/abs/2507.22062)
> *Meta CLIP 2：全球扩展配方*

*Yung-Sung Chuang, Yang Li, Dong Wang, Ching-Feng Yeh, Kehan Lyu, Ramya Raghavendra, James Glass, Lifei Huang, Jason Weston, Luke Zettlemoyer, Xinlei Chen, Zhuang Liu, Saining Xie, Wen-tau Yih, Shang-Wen Li, Hu Xu* | **Category: cs.CV, cs.CL** | **Updated: 2025-08-01**

**Keywords:** CLIP, 多语言, 预训练, 图像-文本, 全球数据

**Comment:** 10 pages

> **TL;DR:** Meta CLIP 2 提出了一个从头开始训练 CLIP 的全球网络规模图像-文本对的配方，解决了多语言数据处理和“多语言诅咒”问题，并在多语言基准测试中取得了新的最先进成果。

**AI_Comments:** Meta CLIP 2 的创新之处在于其提供了一个从零开始训练 CLIP 的“全球扩展配方”，有效解决了多语言数据处理的难题和“多语言诅咒”问题。其方法通过实现英语和非英语数据的相互受益，显著提升了模型在多语言环境下的性能，并且在不依赖复杂系统级改动的情况下达到了SOTA，这对于构建更普适和强大的基础模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管 CLIP 已成功在数十亿级英语图像-文本对上训练，但将其训练进一步扩展到全球网络数据仍面临挑战：1）缺乏处理非英语数据的整理方法；2）现有多语言 CLIP 的英语性能低于其纯英语对应版本，即常见的“多语言诅咒”。

**Method:** 本文提出了 Meta CLIP 2，这是第一个从头开始训练 CLIP 的全球网络规模图像-文本对的配方。为了概括研究结果，作者进行了严格的消融实验，仅进行了必要的最小改动来解决上述挑战，并提出了一个能让英语和非英语世界数据相互受益的配方。

**Result:** 在零样本 ImageNet 分类中，Meta CLIP 2 ViT-H/14 比其纯英语对应版本高出 0.8%，比 mSigLIP 高出 0.7%。在多语言基准测试中，Meta CLIP 2 在没有系统级混淆因素（例如翻译、定制架构更改）的情况下，在 CVQA 上达到了 57.4%，在 Babel-ImageNet 上达到了 50.2%，在图像到文本检索的 XM3600 上达到了 64.3%，创造了新的最先进水平。

**Conclusion:** Meta CLIP 2 成功地解决了在全球范围内扩展 CLIP 训练的挑战，通过其提出的配方实现了英语和非英语世界数据的相互受益，并在多语言基准测试中取得了显著的性能提升，超越了现有模型并设置了新的最先进记录。

> **ai_Abstract:** 本文介绍了 Meta CLIP 2，一个旨在解决现有 CLIP 模型在处理全球多语言数据时面临的挑战（如数据整理困难和“多语言诅咒”）的新训练配方。通过从头开始在海量全球图像-文本对上进行训练，并进行严格的消融实验，Meta CLIP 2 实现了英语和非英语数据的相互增益。实验结果显示，Meta CLIP 2 在零样本 ImageNet 分类上超越了纯英语和多语言基线，并在多个多语言基准测试中，在不引入额外系统复杂性的前提下，取得了新的最先进性能。

> **摘要翻译:** 对比语言-图像预训练（CLIP）是一个流行的基础模型，支持零样本分类、检索以及多模态大型语言模型（MLLMs）的编码器。尽管 CLIP 已成功在数十亿级英语图像-文本对上训练，但将其训练进一步扩展到从全球网络数据中学习仍然具有挑战性：(1) 没有可用的整理方法来处理非英语世界的数据点；(2) 现有多语言 CLIP 的英语性能比其纯英语对应版本差，即大型语言模型中常见的“多语言诅咒”。在此，我们提出了 Meta CLIP 2，这是第一个从头开始训练 CLIP 的全球网络规模图像-文本对的配方。为了概括我们的发现，我们进行了严格的消融实验，仅进行了必要的最小更改来解决上述挑战，并提出了一个能够使英语和非英语世界数据相互受益的配方。在零样本 ImageNet 分类中，Meta CLIP 2 ViT-H/14 比其纯英语对应版本高出 0.8%，比 mSigLIP 高出 0.7%，并且令人惊讶地在多语言基准测试（例如 CVQA 达到 57.4%，Babel-ImageNet 达到 50.2%，图像到文本检索的 XM3600 达到 64.3%）中，在没有系统级混淆因素（例如翻译、定制架构更改）的情况下，创造了新的最先进水平。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [863] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
> *潜在扩散空间中的语义和时间整合用于高保真视频超分辨率*

*Yiwen Wang, Xinning Chai, Yuhong Zhang, Zhengxue Cheng, Jun Zhao, Rong Xie, Li Song* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 视频超分辨率, 潜在扩散空间, 语义引导, 时间一致性, SeTe-VSR

**Comment:** 

> **TL;DR:** 本文提出SeTe-VSR，一种在潜在扩散空间中结合语义和时空引导的新型方法，以解决视频超分辨率中高保真对齐和时间一致性的挑战。

**AI_Comments:** 该论文通过在潜在扩散空间中引入语义和时空引导，创新性地解决了视频超分辨率中保真度和时间一致性之间的权衡问题。将高层语义信息融入扩散模型，为生成高质量、时间连贯的视频提供了新的视角，提升了复杂VSR任务的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频超分辨率（VSR）模型在增强低分辨率视频方面表现出色，但由于难以充分控制生成过程，在保持高保真度与低分辨率输入对齐的同时维持帧间时间一致性仍是重大挑战。

**Method:** 本文提出语义和时间引导视频超分辨率（SeTe-VSR），一种在潜在扩散空间中结合语义和时空引导的新方法。通过整合高级语义信息以及空间和时间信息，该方法在恢复复杂细节和确保时间连贯性之间实现了平衡。

**Result:** SeTe-VSR不仅保留了高真实感的视觉内容，还显著增强了保真度。大量实验表明，SeTe-VSR在细节恢复和感知质量方面优于现有方法。

**Conclusion:** SeTe-VSR通过在潜在扩散空间中结合语义和时空引导，有效地解决了高保真视频超分辨率中的挑战，并在细节恢复和感知质量方面表现出色。

> **ai_Abstract:** 本文提出了一种名为SeTe-VSR的新型视频超分辨率方法，该方法通过在潜在扩散空间中整合语义和时空引导，解决了现有VSR模型在保持高保真度和时间一致性方面的挑战。SeTe-VSR在恢复细节和确保时间连贯性之间取得了平衡，并在实验中表现出优于现有方法的细节恢复和感知质量。

> **摘要翻译:** 视频超分辨率（VSR）模型的最新进展在增强低分辨率视频方面取得了令人印象深刻的成果。然而，由于对生成过程控制不足的限制，在保持与低分辨率输入高度保真对齐的同时维持帧间时间一致性仍然是一个重大挑战。在这项工作中，我们提出了一种名为语义和时间引导视频超分辨率（SeTe-VSR）的新方法，该方法在潜在扩散空间中结合了语义和时空引导，以解决这些挑战。通过结合高级语义信息并整合空间和时间信息，我们的方法在恢复复杂细节和确保时间连贯性之间实现了无缝平衡。我们的方法不仅保留了高真实感的视觉内容，而且显著增强了保真度。大量实验表明，SeTe-VSR在细节恢复和感知质量方面优于现有方法，突出了其在复杂视频超分辨率任务中的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [868] [RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping](https://arxiv.org/abs/2507.23734)
> *RAGNet：面向通用抓取的大规模基于推理的物体功能性分割基准*

*Dongming Wu, Yanping Fu, Saike Huang, Yingfei Liu, Fan Jia, Nian Liu, Feng Dai, Tiancai Wang, Rao Muhammad Anwer, Fahad Shahbaz Khan, Jianbing Shen* | **Category: cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 机器人抓取, 功能性分割, 大规模数据集, 开放世界, 推理

**Comment:** Accepted by ICCV 2025. The code is at
  https://github.com/wudongming97/AffordanceNet

> **TL;DR:** 本文构建了大规模推理驱动的功能性分割基准RAGNet，并提出了AffordanceNet框架，以提升机器人通用抓取在开放世界场景下的表现。

**AI_Comments:** 本文的创新点在于构建了迄今为止最大规模的、面向通用抓取且包含复杂推理指令的功能性分割数据集RAGNet，显著弥补了当前研究在数据量和推理能力方面的不足。通过移除类别名只提供功能性描述，有效地提升了指令的难度，这对于训练更通用、更鲁棒的机器人抓取系统至关重要。所提出的AffordanceNet框架也验证了该数据集的有效性，对于推动机器人领域在开放世界场景下的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 通用机器人抓取系统在开放世界场景中需要准确的物体功能性感知，并遵循人类指令。然而，当前研究缺乏基于推理的大规模功能性预测数据，这引发了对开放世界有效性的担忧。

**Method:** 本文构建了一个名为RAGNet的大规模面向抓取的功能性分割基准，包含27.3万张图像、180个类别和2.6万条基于推理的指令。这些图像涵盖了野外、机器人、自我中心和仿真等多种数据领域，并经过精心标注了功能性地图，同时通过移除类别名称和仅提供功能性描述来增加语言指令的难度。此外，作者提出了一种名为AffordanceNet的综合性基于功能性的抓取框架，该框架由一个在大规模功能性数据上预训练的VLM和一个根据功能性地图抓取目标的抓取网络组成。

**Result:** 在功能性分割基准和真实机器人操作任务上的大量实验表明，所提出的模型具有强大的开放世界泛化能力。

**Conclusion:** 通过构建大规模基于推理的功能性分割数据集RAGNet和提出相应的AffordanceNet抓取框架，有效解决了通用机器人抓取中缺乏推理数据和开放世界泛化能力不足的问题，并展示了强大的泛化能力。

> **ai_Abstract:** 本文旨在解决通用机器人抓取中缺乏基于推理的大规模功能性感知数据的问题。作者构建了一个名为RAGNet的大规模功能性分割基准，该基准包含27.3万张图像和2.6万条高难度推理指令，涵盖多种数据领域。在此基础上，提出了AffordanceNet抓取框架，该框架结合了在大规模功能性数据上预训练的VLM和抓取网络。实验结果表明，该模型在开放世界中展现出强大的泛化能力。

> **摘要翻译:** 通用机器人抓取系统需要在遵循人类指令的各种开放世界场景中准确感知物体功能性。然而，当前研究面临缺乏基于推理的大规模功能性预测数据的问题，导致对开放世界有效性的巨大担忧。为了解决这一限制，我们构建了一个大规模的、面向抓取的功能性分割基准，其中包含类似人类的指令，名为RAGNet。它包含27.3万张图像、180个类别和2.6万条推理指令。图像涵盖了多种具身数据领域，例如野外、机器人、自我中心甚至仿真数据。它们都经过精心标注了功能性地图，同时通过移除类别名称并仅提供功能性描述，大大增加了语言指令的难度。此外，我们提出了一种综合性的基于功能性的抓取框架，名为AffordanceNet，它由一个在我们海量功能性数据上预训练的VLM和一个根据功能性地图抓取目标的抓取网络组成。在功能性分割基准和真实机器人操作任务上的大量实验表明，我们的模型具有强大的开放世界泛化能力。我们的数据和代码可在https://github.com/wudongming97/AffordanceNet获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [869] [LiteGS: A High-performance Framework to Train 3DGS in Subminutes via System and Algorithm Codesign](https://arxiv.org/abs/2503.01199)
> *LiteGS：一种通过系统和算法协同设计在数分钟内训练3DGS的高性能框架*

*Kaimin Liao, Hua Wang, Zhi Chen, Luchao Wang, Yaohua Tang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D Gaussian Splatting, 高性能训练, 系统协同设计, 算法优化, LiteGS

**Comment:** 

> **TL;DR:** LiteGS通过系统和算法协同设计，显著加速了3DGS的训练过程，使其能在数分钟内完成，同时保持或提升了重建质量。

**AI_Comments:** LiteGS的创新之处在于其全面的系统和算法协同设计，从底层计算优化到高层算法改进，系统性地解决了3DGS训练效率问题。特别是“warp-based raster”和基于不透明度梯度方差的密集化准则具有显著创新性。其重要性在于将3DGS的训练时间从小时级缩短到分钟级，极大地降低了其应用门槛，使其更具实用性。抽象中未提及明显局限性。

<details>
  <summary>Details</summary>

**Motivation:** 3D高斯溅射（3DGS）作为一种有前景的3D表示方法，其高昂的训练成本是主要瓶颈。

**Method:** LiteGS是一个高性能框架，通过多方面优化3DGS训练流程。具体包括：在低层计算层设计“warp-based raster”和硬件感知优化以减少梯度归约开销；在中层数据管理层引入基于Morton编码的动态空间排序，实现“Cluster-Cull-Compact”流水线并提高数据局部性；在顶层算法层建立基于不透明度梯度方差的稳健密集化准则和更稳定的不透明度控制机制。

**Result:** LiteGS将原始3DGS训练加速高达13.4倍，且质量相当或更优；在轻量级模型中超越当前SOTA高达1.4倍的速度提升。对于高质量重建任务，LiteGS创下新的精度记录并将训练时间缩短了一个数量级。

**Conclusion:** LiteGS通过系统和算法协同设计，显著提高了3DGS的训练效率和重建质量，使其能够在数分钟内完成高质量的3DGS训练，极大地提升了其应用潜力。

> **ai_Abstract:** 本文提出了LiteGS，一个高性能框架，旨在解决3D高斯溅射（3DGS）训练成本高昂的问题。LiteGS通过系统和算法协同设计，在计算、数据管理和算法层面进行了全面优化，包括引入“warp-based raster”、动态空间排序和基于不透明度梯度方差的密集化准则。实验结果表明，LiteGS将3DGS训练速度提升高达13.4倍，同时保持或提升了质量，并显著缩短了高质量重建的训练时间，实现了分钟级的训练。

> **摘要翻译:** 3D高斯溅射 (3DGS) 已成为3D表示领域一个有前景的替代方案。然而，它仍然面临高昂的训练成本。本文介绍了LiteGS，一个高性能框架，它从多个方面系统地优化了3DGS训练流程。在底层计算层，我们设计了一种“基于warp的光栅化”并结合两种硬件感知优化，以显著减少梯度归约开销。在中层数据管理层，我们引入了基于Morton编码的动态空间排序，以实现高性能的“Cluster-Cull-Compact”流水线并提高数据局部性，从而减少缓存未命中。在顶层算法层，我们基于不透明度梯度方差建立了一个新的稳健密集化准则，并结合更稳定的不透明度控制机制，以实现更精确的参数增长。实验结果表明，LiteGS将原始3DGS训练加速高达13.4倍，且质量相当或更优，并超越了当前轻量级模型的SOTA达1.4倍的速度提升。对于高质量重建任务，LiteGS创下新的精度记录并将训练时间缩短了一个数量级。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [877] [Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration](https://arxiv.org/abs/2506.21509)
> *通过动态Logits校准减轻大型视觉-语言模型的幻觉*

*Jiahe Chen, Jiaying He, Qian Shao, Qiyuan Chen, Jiahe Ying, Hongxia Xu, Jintai Chen, Jianwei Zheng, Jian Wu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 大型视觉-语言模型, 幻觉, 动态Logits校准, 解码策略, 视觉接地

**Comment:** 

> **TL;DR:** 本文提出动态Logits校准（DLC）框架，通过在推理时动态调整输出Logits来减轻大型视觉-语言模型（LVLMs）的幻觉，提高了生成文本与视觉输入的对齐性，且保持了推理效率。

**AI_Comments:** DLC的创新之处在于其动态调整Logits的机制，克服了现有免训练方法中静态约束和多前向传播的局限性。通过实时评估语义对齐和自适应加权，它在保证生成质量的同时显著提升了LVLMs的可靠性，对于提升多模态模型的实际应用价值具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但常受到幻觉问题困扰，即生成与视觉输入矛盾的文本。现有免训练解码策略存在局限性，包括静态约束无法适应生成过程中的语义漂移、需要多次前向传播导致效率低下，以及过于严格的干预规则导致细节退化。

**Method:** 本文引入动态Logits校准（DLC），一种新颖的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步使用CLIP评估输入图像与生成文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出Logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数提供信息的自适应加权机制，在平衡视觉指导的同时，确保文本输出的整体质量。

**Result:** 在各种基准和不同的LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的大量实验表明，DLC显著减少了幻觉，优于现有方法，并通过避免多次前向传播保持了高推理效率。

**Conclusion:** 本文提出了一种有效且高效的解码时解决方案来减轻幻觉，从而增强了LVLMs在更多实践中的可靠性。

> **ai_Abstract:** 本文提出了一种名为动态Logits校准（DLC）的新型免训练解码框架，旨在解决大型视觉-语言模型（LVLMs）在生成文本时出现的幻觉问题。DLC通过在解码阶段利用CLIP模型动态评估生成文本与视觉输入的语义对齐度，并基于相对视觉优势（RVA）自适应调整输出Logits，从而在推理时促进视觉接地气的文本生成。此外，一个自适应加权机制平衡了视觉指导与文本质量。实验证明，DLC能有效减少多种LVLM架构的幻觉，同时保持高推理效率，优于现有方法。

> **摘要翻译:** 大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但它们经常受到幻觉的困扰——即生成与视觉输入矛盾的文本。现有的免训练解码策略存在严重的局限性，包括使用静态约束，这些约束无法适应生成过程中的语义漂移；需要多次前向传播导致的低效率；以及由于过于严格的干预规则导致的细节退化。为了克服这些挑战，本文引入了动态Logits校准（DLC），一种新颖的免训练解码框架，旨在推理时动态地将文本生成与视觉证据对齐。在解码阶段，DLC逐步采用CLIP评估输入图像与生成文本序列之间的语义对齐。然后，根据动态更新的上下文基线评估候选tokens的相对视觉优势（RVA），自适应地调整输出Logits以偏向视觉上接地气的tokens。此外，一个由实时上下文对齐分数提供信息的自适应加权机制，在平衡视觉指导的同时，仔细确保文本输出的整体质量。在各种基准和不同的LVLM架构（如LLaVA、InstructBLIP和MiniGPT-4）上进行的大量实验表明，DLC显著减少了幻觉，优于现有方法，并通过避免多次前向传播保持了高推理效率。总的来说，我们提出了一种有效且高效的解码时解决方案来减轻幻觉，从而增强了LVLMs在更多实践中的可靠性。代码将在Github上发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [880] [Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images](https://arxiv.org/abs/2507.23206)
> *二维显微食品晶体图像的置信度感知团聚分类与分割*

*Xiaoyu Ji, Ali Shakouri, Fengqing Zhu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 食品晶体, 团聚, 图像分割, 分类, 伪标签

**Comment:** 

> **TL;DR:** 本文提出了一种用于二维显微食品晶体图像团聚分类和分割的方法，通过结合监督基线模型和实例分类模型，并引入后处理模块，提高了分类准确性和尺寸分布预测，有效应对了手动标注的挑战。

**AI_Comments:** 该论文通过计算机视觉技术解决了食品科学中的一个实际问题。利用伪标签处理粗糙数据，并将分类与像素级分割相结合，是解决手动标注困难挑战的有趣方法。置信度感知方面以及在不同置信度水平下的评估突显了该方法的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 由于水键的透明性和图像样本单一切片有限的视角，在二维显微图像中手动标注食品晶体团聚特别困难，而团聚现象会使水分被困在晶体之间，影响食品产品质量。

**Method:** 首先，提出了一个监督基线模型，为粗略标记的分类数据集生成分割伪标签。其次，训练了一个同时执行像素级分割的实例分类模型。这两个模型都在推理阶段使用，以结合它们在分类和分割方面的各自优势。为了保持晶体特性，设计并包含了一个后处理模块。该方法在两个置信度水平下进行了评估，以应对手动标注置信度水平的可变性。

**Result:** 与现有方法相比，该方法提高了真阳性团聚分类准确性和尺寸分布预测。它成功分类了潜在的团聚实例，即使在手动标注置信度水平可变的情况下。

**Conclusion:** 所提出的置信度感知方法有效解决了二维显微食品晶体图像中团聚的分类和分割问题，克服了手动标注的挑战，并提高了准确性。

> **ai_Abstract:** 本文介绍了一种针对二维显微食品晶体图像中团聚现象的置信度感知分类与分割新方法。为解决手动标注因透明度和视角限制而面临的挑战，该方法通过使用监督基线模型从粗略标记数据生成分割伪标签，随后训练一个执行像素级分割的实例分类模型。推理阶段结合了这两种模型，并辅以一个旨在保留晶体特性的后处理模块。实验结果表明，该方法在真阳性团聚分类准确性和尺寸分布预测方面均有所提升，并能有效处理手动标注置信度水平的变异性。

> **摘要翻译:** 食品晶体团聚是结晶过程中发生的一种现象，它会使水分被困在晶体之间，从而影响食品产品质量。由于水键的透明性和图像样本单一切片有限的视角，在二维显微图像中手动标注团聚特别困难。为了解决这一挑战，我们首先提出了一个监督基线模型，为粗略标记的分类数据集生成分割伪标签。接下来，训练了一个同时执行像素级分割的实例分类模型。这两个模型都在推理阶段使用，以结合它们在分类和分割方面的各自优势。为了保持晶体特性，设计并包含了一个后处理模块。与其他现有方法相比，我们的方法提高了真阳性团聚分类准确性和尺寸分布预测。鉴于手动标注置信度水平的可变性，我们提出的方法在两个置信度水平下进行了评估，并成功分类了潜在的团聚实例。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [885] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
> *深度学习人脸检测中的后门攻击*

*Quentin Le Roux, Yannick Teglia, Teddy Furon, Philippe Loubet-Moundi* | **Category: cs.CV, cs.AI, cs.CR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 后门攻击, 人脸检测, 深度学习, 地标偏移, 对象生成攻击

**Comment:** 

> **TL;DR:** 本文展示了针对深度学习人脸检测的两种新型后门攻击（人脸生成攻击和地标偏移攻击），并提出了缓解措施。

**AI_Comments:** 本文的创新之处在于首次揭示了深度学习人脸检测中存在的两种新型后门攻击，特别是针对坐标回归任务的地标偏移攻击，这对于提高人脸识别系统的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 人脸识别系统在非受限环境下运行时面临光照不一致、姿态多样等挑战，需要人脸检测模块进行边界框和地标坐标回归以实现人脸对齐。因此，研究人脸检测模块的潜在漏洞变得重要。

**Method:** 本文展示了对人脸检测有效的对象生成攻击，并将其命名为“人脸生成攻击”。此外，首次展示了一种“地标偏移攻击”，该攻击通过后门方式影响人脸检测器执行的坐标回归任务。

**Result:** 论文展示了对象生成攻击（即人脸生成攻击）对人脸检测的有效性，并首次证明了地标偏移攻击能够对人脸检测器执行的坐标回归任务进行后门攻击。

**Conclusion:** 本文针对这些漏洞提出了缓解措施。

> **ai_Abstract:** 本文研究了深度学习人脸检测模块的漏洞。研究人员展示了两种新型后门攻击：对象生成攻击（或称人脸生成攻击）和首次提出的地标偏移攻击。地标偏移攻击通过后门方式影响人脸检测器的坐标回归任务。此外，论文还提出了针对这些漏洞的缓解措施。

> **摘要翻译:** 在非受限环境下运行的人脸识别系统在不同条件下捕获图像，例如光照不一致或人脸姿态多样。这些挑战需要包含一个人脸检测模块，该模块回归边界框和地标坐标以实现正确的人脸对齐。本文展示了对象生成攻击（被称为人脸生成攻击）对人脸检测的有效性，并首次展示了一种地标偏移攻击，该攻击通过后门方式影响人脸检测器执行的坐标回归任务。然后，我们提出了针对这些漏洞的缓解措施。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [898] [VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning](https://arxiv.org/abs/2507.22607)
> *VL-Cogito：渐进式课程强化学习用于高级多模态推理*

*Ruifeng Yuan, Chenghao Xiao, Sicong Leng, Jianyu Wang, Long Li, Weiwen Xu, Hou Pong Chan, Deli Zhao, Tingyang Xu, Zhongyu Wei, Hao Zhang, Yu Rong* | **Category: cs.CV, cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 多模态推理, 强化学习, 课程学习, VL-Cogito, PCuRL

**Comment:** 21 pages, 5 figures, 6 tables. Work in progress

> **TL;DR:** VL-Cogito提出一种新颖的多阶段渐进式课程强化学习（PCuRL）框架，以解决现有模型在复杂多模态推理任务中性能不稳定的问题，并在多个主流基准测试中取得了优异或相当的性能。

**AI_Comments:** 本文提出的PCuRL框架是其主要创新点，特别是其在线难度软加权和动态长度奖励机制，这些机制有效地解决了多模态推理任务的复杂性和多样性带来的挑战，提升了模型训练的稳定性和推理效率。这对于推动多模态AI的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在增强大型语言模型的推理能力方面已显示出其有效性，并逐渐扩展到多模态推理任务。然而，由于多模态任务固有的复杂性和多样性（尤其是在语义内容和问题表述方面），现有模型在不同领域和难度级别上表现出不稳定的性能。

**Method:** 本文提出了VL-Cogito，一个通过新颖的多阶段渐进式课程强化学习（PCuRL）框架训练的高级多模态推理模型。PCuRL系统地引导模型逐步完成难度增加的任务，显著提高了其在不同多模态上下文中的推理能力。该框架引入了两项关键创新：(1) 在线难度软加权机制，动态调整连续RL训练阶段的训练难度；(2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调节其推理路径长度，从而平衡推理效率和正确性。

**Result:** 实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和通用理解的主流多模态基准测试中，始终与现有推理导向模型持平或超越，验证了该方法的有效性。

**Conclusion:** VL-Cogito模型及其多阶段渐进式课程强化学习（PCuRL）框架通过有效应对多模态任务的复杂性和多样性，显著提升了多模态推理能力，并在多个主流基准测试中展现出卓越的性能。

> **ai_Abstract:** VL-Cogito通过引入多阶段渐进式课程强化学习（PCuRL）框架，旨在解决现有模型在复杂多模态推理任务中性能不稳定的问题。PCuRL框架包含在线难度软加权机制和动态长度奖励机制，能够系统地引导模型学习，平衡推理效率与正确性。实验结果表明，VL-Cogito在多个主流多模态基准测试中表现出与现有模型相当或更优的性能，验证了其有效性。

> **摘要翻译:** 强化学习已证明其在增强大型语言模型推理能力方面的有效性。最近的研究工作已逐步将这种范式扩展到多模态推理任务。由于多模态任务固有的复杂性和多样性，尤其是在语义内容和问题表述方面，现有模型在各种领域和难度级别上往往表现出不稳定的性能。为了解决这些局限性，我们提出了VL-Cogito，一个通过新颖的多阶段渐进式课程强化学习（PCuRL）框架训练的高级多模态推理模型。PCuRL系统地引导模型逐步完成难度增加的任务，显著提高了其在不同多模态上下文中的推理能力。该框架引入了两项关键创新：(1) 在线难度软加权机制，动态调整连续RL训练阶段的训练难度；(2) 动态长度奖励机制，鼓励模型根据任务复杂性自适应地调节其推理路径长度，从而平衡推理效率和正确性。实验评估表明，VL-Cogito在涵盖数学、科学、逻辑和通用理解的主流多模态基准测试中，始终与现有推理导向模型持平或超越，验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [899] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
> *一种用于扩展VIIRS类人工夜间灯光图像重建（1986-2024）的新型建模框架和数据产品*

*Yihe Tian, Kwan Man Cheng, Zhengbo Zhang, Tao Zhang, Suju Li, Dongmei Yan, Bing Xu* | **Category: cs.CV, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 夜间灯光, VIIRS, 图像重建, 时间序列, EVAL

**Comment:** 

> **TL;DR:** 本文提出了一种新的建模框架，用于重建1986年至2024年扩展的VIIRS类人工夜间灯光图像，解决了现有方法的低估和结构遗漏问题，并生成了名为EVAL的高质量数据集。

**AI_Comments:** 本文提出了一种创新的双阶段重建框架，有效地解决了现有VIIRS类夜间灯光数据在时间覆盖、强度低估和结构遗漏方面的局限性。其核心贡献在于引入了HFD和DFR，显著提升了重建数据的质量。EVAL数据集的发布，将夜间灯光数据的时间跨度大幅扩展至1986年，为长期社会经济研究提供了重要的基础数据，具有较高的实用价值和影响力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管NPP-VIIRS传感器提供了高质量的夜间灯光（NTL）观测数据，但其时间覆盖范围始于2012年，限制了更早时期的长期时间序列研究。现有扩展VIIRS类NTL时间序列的方法存在两个显著缺点：灯光强度低估和结构遗漏。

**Method:** 本文提出了一种新颖的重建框架，包括两个阶段：构建和细化。构建阶段采用分层融合解码器（HFD）以增强初始重建的保真度。细化阶段采用双特征细化器（DFR），利用高分辨率不透水表面掩膜来指导和增强精细的结构细节。基于此框架，开发了用于中国的扩展VIIRS类人工夜间灯光（EVAL）产品。

**Result:** 定量评估显示，EVAL显著优于现有最先进的产品，将R²从0.68提高到0.80，同时将RMSE从1.27降低到0.99。此外，EVAL表现出出色的时间一致性，并与社会经济参数保持高度相关性。

**Conclusion:** EVAL数据集为研究社区提供了一个有价值的新资源，并可用于长期分析，证实了其可靠性。

> **ai_Abstract:** 本文提出了一种新颖的建模框架，用于重建1986年至2024年扩展的VIIRS类人工夜间灯光（NTL）图像。该框架包含构建和细化两个阶段，分别采用分层融合解码器（HFD）和双特征细化器（DFR），旨在解决现有NTL数据在灯光强度低估和结构遗漏方面的缺陷。基于此框架，研究团队开发了用于中国的EVAL数据集，其性能显著优于现有产品，在R²和RMSE方面均有提升，并表现出良好的时间一致性和社会经济相关性，为长期人类活动分析提供了宝贵资源。

> **摘要翻译:** 人工夜间灯光（NTL）遥感是量化人类活动强度和空间分布的重要替代指标。尽管NPP-VIIRS传感器提供了高质量的NTL观测数据，但其时间覆盖范围（始于2012年）限制了延伸至更早时期的长期时间序列研究。尽管在扩展VIIRS类NTL时间序列方面取得了进展，但现有方法仍存在两个显著缺点：灯光强度低估和结构遗漏。为了克服这些限制，我们提出了一种新颖的重建框架，包括两阶段过程：构建和细化。构建阶段采用分层融合解码器（HFD），旨在增强初始重建的保真度。细化阶段采用双特征细化器（DFR），利用高分辨率不透水表面掩膜来指导和增强精细的结构细节。基于此框架，我们开发了用于中国的扩展VIIRS类人工夜间灯光（EVAL）产品，将标准数据记录向后扩展了26年，始于1986年。定量评估显示，EVAL显著优于现有最先进的产品，将R²从0.68提高到0.80，同时将RMSE从1.27降低到0.99。此外，EVAL表现出出色的时间一致性，并与社会经济参数保持高度相关性，证实了其长期分析的可靠性。由此产生的EVAL数据集为研究社区提供了一个有价值的新资源，并可在https://doi.org/10.11888/HumanNat.tpdc.302930公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [903] [YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection](https://arxiv.org/abs/2507.23225)
> *YOLO-ROC：一种用于实时道路损伤检测的高精度超轻量模型*

*Zicheng Lin, Weichao Pan* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 道路损伤检测, YOLO-ROC, 轻量级模型, 多尺度特征提取, 实时检测

**Comment:** 

> **TL;DR:** YOLO-ROC是一种高精度、超轻量级的道路损伤检测模型，通过改进多尺度特征提取和通道压缩，显著提高了小目标检测性能并大幅降低了模型大小和计算量，适用于实时部署。

**AI_Comments:** 该论文的创新点在于结合了改进的多尺度特征提取（BMS-SPPF模块）和高效的通道压缩策略，成功地在道路损伤检测领域实现了高精度与超轻量化的平衡。特别是对小目标检测性能的显著提升，解决了实际应用中的一大痛点。模型尺寸仅2.0 MB，对于边缘设备和实时部署具有重要意义。其局限性可能在于模型的泛化能力是否能在更多样化的实际道路环境下得到验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习道路损伤检测方法存在两个主要挑战：一是多尺度特征提取能力不足，导致对裂缝、坑洼等小尺度损伤的漏检率高；二是主流模型参数量大、计算需求高，难以在实际应用中实现高效实时检测。

**Method:** 本文提出了一种高精度、轻量级模型YOLO-ROC。该模型设计了双向多尺度空间金字塔池化快速（BMS-SPPF）模块以增强多尺度特征提取，并通过双向空间-通道注意力机制改进小目标检测。同时，采用了分层通道压缩策略来降低计算复杂度，减少参数量和GFLOPs。

**Result:** YOLO-ROC在RDD2022_China_Drone数据集上mAP50达到67.6%，比基线YOLOv8n提高2.11%。其中，小目标D40类别的mAP50提高了16.8%。模型最终大小仅为2.0 MB，参数量从3.01M降至0.89M，GFLOPs从8.1降至2.6。此外，该模型在RDD2022_China_Motorbike数据集上表现出优异的泛化性能。

**Conclusion:** YOLO-ROC模型通过其创新的BMS-SPPF模块和分层通道压缩策略，有效解决了道路损伤检测中多尺度特征提取不足和模型计算开销大的问题，实现了高精度、超轻量级的实时检测能力，并展示了良好的泛化性。

> **ai_Abstract:** 本文提出YOLO-ROC，一种针对道路损伤检测的高精度超轻量模型，旨在解决现有方法在多尺度特征提取不足和模型复杂性高的问题。YOLO-ROC引入了双向多尺度空间金字塔池化快速（BMS-SPPF）模块以增强多尺度特征提取和对小目标的检测能力，并通过分层通道压缩策略显著减小模型尺寸和计算量。实验证明，YOLO-ROC在检测精度（尤其对小目标）和模型效率上均优于基线模型，模型大小仅2.0 MB，且具有良好的泛化性能，非常适合实时道路损伤检测应用。

> **摘要翻译:** 道路损伤检测是确保交通安全和维护基础设施完整性的关键任务。尽管基于深度学习的检测方法现已广泛采用，但它们仍面临两个核心挑战：首先，现有网络对裂缝和坑洼等多样化目标的多尺度特征提取能力不足，导致小尺度损伤的漏检率高；其次，主流模型的庞大参数量和计算需求阻碍了它们在实际应用中进行高效、实时检测的部署。为了解决这些问题，本文提出了一种高精度、轻量级模型——YOLO-Road Orthogonal Compact（YOLO-ROC）。我们设计了一个双向多尺度空间金字塔池化快速（BMS-SPPF）模块来增强多尺度特征提取，并实施了分层通道压缩策略以降低计算复杂度。BMS-SPPF模块利用双向空间-通道注意力机制来改进小目标的检测。同时，通道压缩策略将参数量从3.01M减少到0.89M，GFLOPs从8.1减少到2.6。在RDD2022_China_Drone数据集上的实验表明，YOLO-ROC的mAP50达到67.6%，超越基线YOLOv8n 2.11%。值得注意的是，小目标D40类别的mAP50提高了16.8%，最终模型大小仅为2.0 MB。此外，该模型在RDD2022_China_Motorbike数据集上表现出优异的泛化性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [904] [Adjustable Spatio-Spectral Hyperspectral Image Compression Network](https://arxiv.org/abs/2507.23447)
> *可调节空谱高光谱图像压缩网络*

*Martin Hermann Paul Fuchs, Behnood Rasti, Begüm Demir* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 高光谱图像压缩, 空谱压缩, 深度学习, 遥感, HyCASS

**Comment:** 

> **TL;DR:** 本文提出了HyCASS，一个基于学习的可调节高光谱图像压缩网络，旨在有效平衡空谱压缩，并提供不同压缩比下的平衡指南。

**AI_Comments:** 该论文的创新点在于提出了一个可调节的空谱高光谱图像压缩网络，并首次全面探讨了光谱和空间压缩的独立及联合效应。其重要性在于为高光谱数据的高效存储提供了新的解决方案，并为如何平衡空谱压缩提供了实用的指导方针，这对于遥感领域的数据处理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着遥感高光谱数据档案的快速增长，高效存储变得至关重要，促使人们关注基于学习的高光谱图像（HSI）压缩。然而，目前尚未对光谱和空间压缩在基于学习的HSI压缩中的单独和联合效应进行全面深入的研究，而进行此类分析对于理解空谱冗余如何影响HSI压缩至关重要。

**Method:** 我们提出了可调节空谱高光谱图像压缩网络（HyCASS），这是一个基于学习的模型，旨在实现光谱和空间维度的可调节HSI压缩。HyCASS包含六个主要模块：1）光谱编码器；2）空间编码器；3）压缩比（CR）适配器编码器；4）CR适配器解码器；5）空间解码器；6）光谱解码器模块。这些模块采用卷积层和Transformer块来捕获短程和长程冗余。

**Result:** 在两个HSI基准数据集上的实验结果表明，与现有基于学习的压缩模型相比，我们提出的可调节模型是有效的。

**Conclusion:** 基于我们的结果，我们为在高光谱图像空间分辨率的考量下，如何在不同压缩比下有效平衡光谱和空间压缩建立了指导方针。

> **ai_Abstract:** 本文提出了一种名为HyCASS的可调节空谱高光谱图像压缩网络，旨在解决当前基于学习的HSI压缩中对空谱压缩效应缺乏全面研究的问题。HyCASS模型包含六个核心模块，利用卷积层和Transformer块来捕获图像的短程和长程冗余。实验证明，该模型在两个基准数据集上优于现有方法，并且提供了一套在不同压缩比下平衡空谱压缩的有效指南，同时考虑了高光谱图像的空间分辨率。

> **摘要翻译:** 随着遥感（RS）中高光谱数据档案的快速增长，对高效存储的需求变得至关重要，这促使人们对基于学习的高光谱图像（HSI）压缩给予了极大的关注。然而，目前尚未对光谱和空间压缩在基于学习的HSI压缩中的单独和联合效应进行全面深入的研究。进行此类分析对于理解如何利用光谱、空间和联合空谱冗余来影响HSI压缩至关重要。为了解决这个问题，我们提出了可调节空谱高光谱图像压缩网络（HyCASS），这是一个基于学习的模型，旨在实现光谱和空间维度的可调节HSI压缩。HyCASS包含六个主要模块：1）光谱编码器；2）空间编码器；3）压缩比（CR）适配器编码器；4）CR适配器解码器；5）空间解码器；6）光谱解码器模块。这些模块采用卷积层和Transformer块来捕获短程和长程冗余。在两个HSI基准数据集上的实验结果表明，我们提出的可调节模型与现有基于学习的压缩模型相比是有效的。基于我们的结果，我们为在考虑HSI空间分辨率的情况下，如何在不同压缩比下有效平衡光谱和空间压缩建立了指导方针。我们的代码和预训练模型权重已公开可用，地址为 https://git.tu-berlin.de/rsim/hycass。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [905] [Slot Attention with Re-Initialization and Self-Distillation](https://arxiv.org/abs/2507.23755)
> *具有重新初始化和自蒸馏的Slot Attention*

*Rongzhen Zhao, Yi Zhao, Juho Kannala, Joni Pajarinen* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** Slot Attention, 目标中心学习, 自蒸馏, 重新初始化, 对象发现

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出了DIAS，通过重新初始化和自蒸馏改进了Slot Attention，解决了冗余槽位和内部信息利用不足的问题，并在目标中心学习任务上达到了SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了两种机制来改进Slot Attention：一是“重新初始化”，解决了现有方法中槽位冗余和对象错误分割的问题；二是“自蒸馏”，通过利用内部信息提供了额外的监督信号。这些改进使得模型在目标中心学习任务上取得了显著的性能提升，特别是对于复杂视觉场景的理解和表示具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的目标中心学习（OCL）方法中，Slot Attention在初始化后简单地重用槽位，导致冗余槽位与有效槽位竞争，造成对象错误分割。此外，主流方法仅依赖槽位解码到输入重建的监督信号，忽略了基于内部信息的潜在监督。

**Method:** 本文提出了DIAS（Slot Attention with re-Initialization and self-Distillation）：1) 减少聚合槽位中的冗余，并重新初始化额外聚合以更新剩余槽位；2) 驱动第一次聚合迭代中的不良注意力图近似最后一次迭代中的良好注意力图，以实现自蒸馏。

**Result:** DIAS在目标发现和识别等OCL任务上取得了最先进的性能，并改进了高级视觉预测和推理。

**Conclusion:** DIAS通过引入重新初始化和自蒸馏机制，有效解决了Slot Attention中冗余槽位和内部监督不足的问题，显著提升了目标中心学习任务的性能。

> **ai_Abstract:** 本文针对目标中心学习（OCL）中Slot Attention存在的冗余槽位和内部信息利用不足的问题，提出了DIAS（Slot Attention with Re-Initialization and Self-Distillation）模型。DIAS通过引入槽位重新初始化机制减少冗余，并利用自蒸馏方法从内部信息中获取监督信号。实验证明，DIAS在目标发现、识别以及视觉预测和推理等OCL任务上均达到了当前最佳性能。

> **摘要翻译:** 与基于密集特征图的流行解决方案不同，目标中心学习（OCL）将视觉场景表示为亚符号对象级特征向量，称为槽位，这对于涉及视觉模态的任务具有高度通用性。OCL通常通过迭代应用竞争性交叉注意力（称为Slot Attention，以槽位作为查询）将对象超像素聚合到槽位中。然而，一旦初始化，这些槽位就会被天真地重用，导致冗余槽位与信息丰富的槽位竞争以表示对象。这通常会导致对象被错误地分割成部分。此外，主流方法仅从将槽位解码为输入的重建中获取监督信号，忽略了基于内部信息的潜在监督。为了解决这些问题，我们提出了具有重新初始化和自蒸馏的Slot Attention（DIAS）：i) 我们减少聚合槽位中的冗余，并重新初始化额外聚合以更新剩余槽位；ii) 我们驱动第一次聚合迭代中的不良注意力图近似最后一次迭代中的良好注意力图，以实现自蒸馏。实验表明，DIAS在目标发现和识别等OCL任务上取得了最先进的性能，同时还改进了高级视觉预测和推理。我们的代码可在https://github.com/Genera1Z/DIAS上获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [906] [Mocap-2-to-3: Multi-view Lifting for Monocular Motion Recovery with 2D Pretraining](https://arxiv.org/abs/2503.03222)
> *Mocap-2-to-3: 基于2D预训练的单目运动恢复多视角提升*

*Zhumei Wang, Zechen Hu, Ruoxi Guo, Huaijin Pi, Ziyong Feng, Sida Peng, Xiaowei Zhou, Mingtao Pei, Siyuan Huang* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 单目运动恢复, 2D预训练, 多视角提升, 3D人体姿态估计, 绝对位置恢复

**Comment:** Project page: https://wangzhumei.github.io/mocap-2-to-3/

> **TL;DR:** Mocap-2-to-3通过2D数据预训练和多视角提升，解决了从单目输入恢复绝对人体运动的挑战，实现了度量准确的3D运动重建。

**AI_Comments:** Mocap-2-to-3的创新之处在于其利用了丰富的2D数据进行预训练，有效缓解了3D数据稀缺的瓶颈，显著提升了模型的泛化能力。其分解3D运动为多视角合成以及解耦局部姿态与全局运动的策略，为单目3D人体运动恢复提供了新的思路，尤其是在恢复绝对位置方面取得了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法依赖有限的3D训练数据，导致泛化能力受限，且难以从单目输入估计度量尺度的姿态。本文旨在解决这两个问题，以从单目输入恢复绝对人体运动。

**Method:** 本文提出了Mocap-2-to-3框架，通过利用2D数据预训练实现从单目输入的多视角提升。首先，在大量2D数据集上预训练单视角扩散模型；然后，使用公共3D数据微调多视角模型，以实现从单目输入生成视角一致的运动。此外，提出了一种新颖的人体运动表示，解耦局部姿态和全局运动的学习，并编码地面几何先验以加速收敛，从而在推理过程中逐步恢复绝对空间中的运动。

**Result:** Mocap-2-to-3在“野外”基准测试中，在相机空间运动真实性和世界地面人体定位方面超越了最先进的方法，并展现出卓越的泛化能力。

**Conclusion:** Mocap-2-to-3通过创新的2D预训练和多视角提升策略，有效解决了单目输入下绝对人体运动恢复的挑战，显著提升了3D运动重建的准确性、真实性和泛化能力。

> **ai_Abstract:** 本文提出了Mocap-2-to-3框架，旨在解决从单目输入恢复绝对人体运动的挑战，特别是对3D训练数据依赖和度量尺度估计困难的问题。该方法通过在大量2D数据上预训练单视角扩散模型，再结合少量3D数据微调多视角模型，实现了多视角提升和视角一致的运动生成。同时，引入了一种新的运动表示，解耦局部姿态和全局运动，并利用地面几何先验，以恢复绝对位置。实验证明，Mocap-2-to-3在运动真实性、人体定位和泛化能力方面均优于现有方法。

> **摘要翻译:** 从单目输入恢复绝对人体运动面临两大挑战。首先，现有方法依赖于从有限环境中收集的3D训练数据，这限制了其对分布外数据的泛化能力。第二个问题是难以从单目输入估计度量尺度的姿态。为了解决这些挑战，我们引入了Mocap-2-to-3，这是一个新颖的框架，它通过利用2D数据预训练，从单目输入执行多视角提升，从而能够重建具有绝对位置的度量准确的3D运动。为了利用丰富的2D数据，我们将复杂的3D运动分解为多视角合成。我们首先在大量的2D数据集上预训练一个单视角扩散模型，然后使用公共3D数据微调一个多视角模型，以实现从单目输入生成视角一致的运动，从而使模型通过2D数据获得动作先验和多样性。此外，为了恢复绝对姿态，我们提出了一种新颖的人体运动表示，该表示解耦了局部姿态和全局运动的学习，同时编码了地面的几何先验以加速收敛。这使得在推理过程中能够逐步恢复绝对空间中的运动。在“野外”基准测试上的实验结果表明，我们的方法在相机空间运动真实性和世界地面人体定位方面均超越了最先进的方法，同时展现出卓越的泛化能力。我们的代码将公开发布。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [913] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
> *图谱谱系和骨架图积*

*Eric Mjolsness, Cory B. Scott* | **Category: cs.CV, cs.LG, cs.NA, math.CT, math.NA** | **Updated: 2025-07-31**

**Keywords:** 图谱谱系, 骨架图积, 分级图谱, 分层模型, 代数类型理论

**Comment:** 42 pages. 33 Figures. Under review

> **TL;DR:** 该论文定义了“图谱谱系”和“分级图谱”，并推导了其“骨架”代数操作符，旨在为机器学习和计算科学中的分层模型架构提供一个代数类型理论。

**AI_Comments:** 本文在图论和代数拓扑的交叉领域进行了创新性探索，通过引入“图谱谱系”和“分级图谱”的概念，为理解和构建分层模型提供了一个新的、统一的代数框架。特别是“骨架”操作符的推导，为处理大规模分层图谱带来了计算效率的潜力。其将抽象的数学理论与深度学习、多重网格等实际应用联系起来，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 图谱及其增长序列可用于指定机器学习和计算科学等许多领域的数学模型架构。本文旨在定义结构化的图谱谱系，以分层方式增长，并在此基础上开发新的代数操作，以更好地描述和构建分层模型。

**Method:** 本文定义了结构化的“图谱谱系”（按级别编号排序），它们以分层方式增长。具体方法包括：1) 定义了顶点和边数量随级别呈指数增长的图谱谱系；2) 使用二分图连接连续级别并约束矩阵；3) 利用延长映射定义级别间的距离度量；4) 定义了“分级图谱”范畴，并推导了标准代数图操作和类型构造函数（笛卡尔积、盒积、不相交和、函数类型）的低成本“骨架”变体；5) 推导了空间高效的一元操作符，如“增厚”（创建多尺度图谱谱系）和“升级”（创建搜索前沿的图谱谱系）。

**Result:** 研究结果是为分级图谱和（分层）图谱谱系建立了一个代数类型理论。推导出的骨架二元操作符具有与标准对应物相似但不完全相同的代数和范畴论性质。图谱谱系及其骨架积构造函数可以逼近连续极限对象。该方法有望很好地适用于定义分层模型架构（“分层架构”）以及在其上进行局部采样、搜索或优化算法。

**Conclusion:** 本文成功为分级图谱和分层图谱谱系建立了一个代数类型理论，通过引入图谱谱系、分级图谱和骨架操作符，为构建和分析复杂的分层模型架构提供了新的数学工具。该方法特别适用于深度神经网络和多重网格数值方法等领域。

> **ai_Abstract:** 本文提出了一种新的“图谱谱系”概念，它描述了以分层方式增长的图谱序列，其中顶点和边数量呈指数增长。在此基础上，文章定义了“分级图谱”范畴，并推导了标准代数图操作（如笛卡儿积、盒积等）的低成本“骨架”变体，以及空间高效的一元操作符。核心贡献是建立了一个针对分级图谱和分层图谱谱系的代数类型理论，旨在为机器学习和计算科学中的分层模型（“分层架构”）及其相关算法提供数学基础和工具，并展示了其在深度神经网络和多重网格方法中的应用。

> **摘要翻译:** 图谱及其增长序列可用于指定机器学习和计算科学等许多领域的数学模型架构。本文定义了结构化的“图谱谱系”（按级别编号排序），它们以分层方式增长，因此：(1) 图谱顶点和边的数量随级别呈指数增长；(2) 二分图连接图谱谱系内的连续级别，并像多重网格方法一样，可以约束连接连续级别的矩阵；(3) 使用图谱谱系内的延长映射，可以定义连续级别图谱之间的过程衍生距离度量；(4) 可以定义“分级图谱”的范畴，并利用它为分级图谱以及分层图谱谱系推导出标准代数图操作和类型构造函数（笛卡儿积、盒积、不相交和以及函数类型）的低成本“骨架”变体；(5) 这些骨架二元操作符具有与标准对应物相似但不完全相同的代数和范畴论性质；(6) 图谱谱系及其骨架积构造函数可以逼近连续极限对象。此外，还推导了分级图谱上的空间高效一元操作符：“增厚”（创建多尺度图谱谱系）和“升级”（创建搜索前沿的图谱谱系，可用作自适应网格的推广和定义“骨架”函数）。结果是为分级图谱和（分层）图谱谱系建立了一个代数类型理论。该方法有望很好地适用于定义分层模型架构——“分层架构”——以及在其上进行局部采样、搜索或优化算法。我们展示了其在深度神经网络（包括视觉和特征尺度空间）和多重网格数值方法中的应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [916] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
> *Butter：自动驾驶目标检测中的频率一致性与分层融合*

*Xiaojian Lin, Wenxin Zhang, Yuchu Jiang, Wangyu Wu, Yiran Guo, Kangxu Wang, Zongzheng Zhang, Guijin Wang, Lei Jin, Hao Zhao* | **Category: cs.CV, I.4.8; I.2.10; H.5.1; I.2.6** | **Updated: 2025-07-31**

**Keywords:** 自动驾驶, 目标检测, 分层特征, 频率一致性, 特征融合

**Comment:** 10 pages, 6 figures. Supplementary material: 8 pages, 7 figures.
  Accepted at ACM Multimedia 2025

> **TL;DR:** Butter是一个新的目标检测框架，通过频率自适应特征一致性增强和渐进式分层特征融合网络，解决了自动驾驶中多尺度特征表示的挑战，提高了检测精度和效率。

**AI_Comments:** Butter通过引入频率一致性增强和分层特征融合，创新性地解决了自动驾驶目标检测中多尺度特征表示的难题。其对特征一致性的关注以及在多个主流数据集上的验证，表明了其在实际应用中的潜力，有望提高自动驾驶系统的感知鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有目标检测架构（如YOLO和DETR）在自动驾驶中识别行人、车辆和交通标志时，难以在保持不同尺度特征一致性的同时平衡检测精度和计算效率。

**Method:** 提出了Butter框架，包含两个关键创新：频率自适应特征一致性增强（FAFCE）组件，利用自适应频率滤波增强结构和边界精度，细化多尺度特征一致性；以及渐进式分层特征融合网络（PHFFNet）模块，逐步整合多级特征以弥合语义鸿沟并加强分层特征学习。

**Result:** 在BDD100K、KITTI和Cityscapes数据集上进行了广泛实验，Butter展示了卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂度。

**Conclusion:** Butter通过关注分层特征的细化和整合，为目标检测提供了一种先进的方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的平衡。

> **ai_Abstract:** 本文提出了一个名为Butter的新型目标检测框架，旨在解决自动驾驶中现有模型在多尺度特征一致性和效率方面的挑战。Butter引入了频率自适应特征一致性增强（FAFCE）和渐进式分层特征融合网络（PHFFNet）两个核心组件，以优化分层特征表示。实验结果表明，Butter在BDD100K、KITTI和Cityscapes数据集上显著提高了检测精度并降低了模型复杂度，为自动驾驶目标检测提供了高效且准确的解决方案。

> **摘要翻译:** 分层特征表示在计算机视觉中扮演着关键角色，尤其是在自动驾驶的目标检测中。多级语义理解对于在动态环境中准确识别行人、车辆和交通标志至关重要。然而，现有的架构，如YOLO和DETR，在平衡检测精度和计算效率的同时，难以保持不同尺度特征的一致性。为了解决这些挑战，我们提出了Butter，一个新颖的目标检测框架，旨在增强分层特征表示以提高检测的鲁棒性。具体来说，Butter引入了两项关键创新：频率自适应特征一致性增强（FAFCE）组件，它通过利用自适应频率滤波来增强结构和边界精度，从而细化多尺度特征一致性；以及渐进式分层特征融合网络（PHFFNet）模块，它逐步整合多级特征以弥合语义鸿沟并加强分层特征学习。通过在BDD100K、KITTI和Cityscapes上的广泛实验，Butter展示了卓越的特征表示能力，显著提高了检测精度，同时降低了模型复杂度。通过关注分层特征的细化和整合，Butter提供了一种先进的目标检测方法，在实时自动驾驶场景中实现了精度、可部署性和计算效率之间的平衡。我们的模型和实现已在https://github.com/Aveiro-Lin/Butter公开提供，以促进自动驾驶社区的进一步研究和验证。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [925] [Toward Safe, Trustworthy and Realistic Augmented Reality User Experience](https://arxiv.org/abs/2507.23226)
> *迈向安全、可信和真实的增强现实用户体验*

*Yanming Xiu* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 增强现实, AR安全, 可信度, 视觉语言模型, 多模态攻击

**Comment:** 2 pages, 4 figures

> **TL;DR:** 该研究开发了ViDDAR和VIM-Sense系统，利用视觉语言模型检测增强现实（AR）中可能损害用户体验或操纵感知的有害内容，并提出了未来在AR内容质量评估、多模态攻击检测和VLM部署方面的研究方向。

**AI_Comments:** 该论文着眼于AR领域一个日益重要且紧迫的问题：虚拟内容的安全性和可信度。其创新之处在于利用视觉语言模型和多模态推理来检测有害内容，这为AR安全防护提供了新思路。所提出的未来研究方向，特别是感知对齐的质量评估和多模态攻击检测，具有重要的实践意义和研究价值。这为未来AR技术的健康发展奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 随着增强现实（AR）日益融入日常生活，确保其虚拟内容的安全性和可信度至关重要。本研究旨在解决AR内容可能带来的风险，特别是那些阻碍关键信息或微妙操纵用户感知的有害内容。

**Method:** 研究开发了ViDDAR和VIM-Sense两个系统，利用视觉语言模型（VLMs）和多模态推理模块来检测有害的AR内容攻击。

**Result:** 研究开发了ViDDAR和VIM-Sense系统来检测AR中的有害内容攻击，并提出了三个未来研究方向：自动化、感知对齐的虚拟内容质量评估；多模态攻击检测；以及将视觉语言模型（VLMs）适应性部署到AR设备上。

**Conclusion:** 本研究旨在建立一个可扩展、以人为本的框架，以保障增强现实体验的安全。未来的工作将集中于虚拟内容质量评估、多模态攻击检测以及视觉语言模型在AR设备上的高效部署。

> **ai_Abstract:** 本研究关注增强现实（AR）中虚拟内容的安全性和可信度问题，特别是那些可能阻碍关键信息或操纵用户感知的有害内容。为解决此问题，研究开发了ViDDAR和VIM-Sense系统，利用视觉语言模型（VLMs）和多模态推理模块来检测此类攻击。在此基础上，论文提出了未来三个研究方向，包括虚拟内容质量评估、多模态攻击检测以及VLMs在AR设备上的高效部署。总体目标是建立一个可扩展、以人为本的AR体验安全保障框架。

> **摘要翻译:** 随着增强现实（AR）日益融入日常生活，确保其虚拟内容的安全性和可信度至关重要。我们的研究解决了对任务有害的AR内容的风险，特别是那些阻碍关键信息或微妙操纵用户感知的AR内容。我们开发了ViDDAR和VIM-Sense两个系统，利用视觉语言模型（VLMs）和多模态推理模块来检测此类攻击。在此基础上，我们提出了三个未来方向：自动化、感知对齐的虚拟内容质量评估；多模态攻击检测；以及将VLMs适应性地部署到AR设备上，以实现高效和以用户为中心的部署。总的来说，我们的工作旨在建立一个可扩展的、以人为本的框架，以保障AR体验的安全，并寻求在感知建模、多模态AR内容实现和轻量级模型适应方面的反馈。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [936] [Phi-Ground Tech Report: Advancing Perception in GUI Grounding](https://arxiv.org/abs/2507.23779)
> *Phi-Ground 技术报告：推进 GUI 接地中的感知*

*Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo* | **Category: cs.CV, cs.AI, cs.MM** | **Updated: 2025-07-31**

**Keywords:** GUI接地, 计算机使用代理, Phi-Ground, 感知, 最先进性能

**Comment:** 

> **TL;DR:** Phi-Ground模型家族在GUI接地任务上取得了最先进的性能，解决了当前模型准确率低的问题。

**AI_Comments:** Phi-Ground模型家族的引入显著提升了GUI接地任务的最新技术水平，这是计算机使用代理（CUA）实现实际应用的关键一步。该工作通过从数据收集到模型训练的实证研究方法，为该领域提供了宝贵的见解。其在挑战性基准测试上取得SOTA性能，特别是在100亿参数以下模型中，突显了其高效性和有效性。此外，论文强调阐明模型构建并惠及其他感知任务，进一步扩大了其潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 当前端到端GUI接地模型在挑战性基准测试上的准确率低于65%，远未达到部署要求，因此需要提升其性能和准确性。

**Method:** 本研究对接地模型的训练进行了实证研究，详细考察了从数据收集到模型训练的各个环节，并在此基础上开发了Phi-Ground模型家族。

**Result:** Phi-Ground模型家族在代理设置中，对于参数小于100亿的模型，在所有五个接地基准测试上均取得了最先进的性能。在端到端模型设置中，模型在ScreenSpot-pro上取得了43.2分，在UI-Vision上取得了27.2分的最先进结果。

**Conclusion:** 本文讨论的各种细节，以及Phi-Ground模型的成功和失败，不仅阐明了接地模型的构建，而且也有益于其他感知任务。

> **ai_Abstract:** 本研究针对当前GUI接地模型准确率低、无法实际部署的问题，通过对接地模型训练的实证研究，从数据收集到模型训练进行了详细探究。最终，开发了Phi-Ground模型家族，该模型在代理设置中，对于参数小于100亿的模型，在所有五个接地基准测试上均达到了最先进的性能。在端到端模型设置中，该模型在ScreenSpot-pro和UI-Vision上也取得了SOTA结果。论文中讨论的经验和教训不仅有助于接地模型的构建，也对其他感知任务具有借鉴意义。

> **摘要翻译:** 随着多模态推理模型的发展，类似于《钢铁侠》中贾维斯的计算机使用代理（CUA）正在成为现实。GUI接地是CUA执行实际行动的核心组件，类似于机器人中的机械控制，它直接决定了系统的成败。它决定了点击和打字等操作，以及点击坐标等相关参数。当前的端到端接地模型在ScreenSpot-pro和UI-Vision等挑战性基准测试上的准确率仍低于65%，这表明它们远未达到部署要求。在这项工作中，我们对接地模型的训练进行了实证研究，检查了从数据收集到模型训练的细节。最终，我们开发了Phi-Ground模型家族，该家族在代理设置中，对于参数小于100亿的模型，在所有五个接地基准测试上均取得了最先进的性能。在端到端模型设置中，我们的模型在ScreenSpot-pro上仍取得了43.2分，在UI-Vision上取得了27.2分的最先进结果。我们相信，本文中讨论的各种细节，以及我们的成功和失败，不仅阐明了接地模型的构建，而且也有益于其他感知任务。项目主页：https://zhangmiaosen2000.github.io/Phi-Ground/

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [939] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
> *SU-ESRGAN：用于卫星和无人机图像超分辨率的语义和不确定性感知ESRGAN，并针对跨域评估进行微调*

*Prerana Ramkumar* | **Category: cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 超分辨率, ESRGAN, 语义感知, 不确定性量化, 遥感图像

**Comment:** 

> **TL;DR:** SU-ESRGAN是一种新的超分辨率框架，将ESRGAN与语义分割和不确定性映射相结合，以提高遥感图像的可信度，并在特定数据集上通过微调显示出良好的跨域适应性。

**AI_Comments:** SU-ESRGAN的创新之处在于其将语义分割和不确定性量化引入了超分辨率领域，这对于提高遥感等关键应用中超分辨率结果的可信度和实用性至关重要。模块化设计使其易于集成，而对跨域适应性的强调及其发现（领域感知训练的重要性）为未来研究提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成对抗网络（GANs）在图像超分辨率方面表现出色，但缺乏语义一致性和像素级置信度，这限制了它们在灾害响应、城市规划和农业等关键遥感应用中的可信度。

**Method:** 本文引入了语义和不确定性感知ESRGAN（SU-ESRGAN），这是第一个专为卫星图像设计的超分辨率框架。它集成了ESRGAN、通过DeepLabv3的分割损失以保留类别细节，以及蒙特卡洛dropout以生成像素级不确定性图。该模型具有模块化设计，可以集成到无人机数据管道中进行机载或后处理超分辨率。此外，模型还进行了微调，以评估其在跨域应用中的性能，并在两个不同的无人机数据集上进行了测试。

**Result:** SU-ESRGAN在航空图像上产生的PSNR、SSIM、LPIPS结果与Baseline ESRGAN相当。对微调模型进行性能评估表明，其对航空海洋无人机数据集的适应性更强，该数据集的成像特性与训练数据一致，这突出了在超分辨率应用中领域感知训练的重要性。

**Conclusion:** SU-ESRGAN通过整合语义一致性和不确定性感知，提高了遥感图像超分辨率的可信度。研究结果强调了在超分辨率应用中进行领域感知训练的重要性，以实现更好的跨域适应性。

> **ai_Abstract:** 本文提出了一种名为SU-ESRGAN的新型超分辨率框架，旨在解决现有GANs在遥感图像超分辨率中缺乏语义一致性和像素级置信度的问题。SU-ESRGAN结合了ESRGAN、DeepLabv3的分割损失和蒙特卡洛dropout，以生成语义一致且具有不确定性图的超分辨率图像。该模型在航空图像上表现与基线ESRGAN相当，并能有效应用于卫星和无人机系统。通过对跨域数据集的微调评估，研究强调了领域感知训练在提高模型适应性方面的重要性。

> **摘要翻译:** 生成对抗网络（GANs）在图像的逼真超分辨率（SR）方面取得了成就，但它们缺乏语义一致性和像素级置信度，这限制了它们在灾害响应、城市规划和农业等关键遥感应用中的可信度。本文介绍了语义和不确定性感知ESRGAN（SU-ESRGAN），这是第一个专为卫星图像设计的SR框架，它集成了ESRGAN、通过DeepLabv3进行分割损失以保留类别细节，以及蒙特卡洛dropout以生成像素级不确定性图。SU-ESRGAN在航空图像上产生的结果（PSNR、SSIM、LPIPS）与Baseline ESRGAN相当。这种新颖的模型对于使用宽视场（FoV）摄像头的卫星系统或无人机很有价值，它们牺牲空间分辨率以换取覆盖范围。模块化设计允许集成到无人机数据管道中，用于机载或后处理SR，以增强因运动模糊、压缩和传感器限制而产生的图像。此外，模型还进行了微调，以评估其在跨域应用中的性能。测试在两个基于无人机的数据集上进行，它们在高度和成像视角上有所不同。微调模型的性能评估显示出对航空海洋无人机数据集的更强适应性，其成像特性与训练数据一致，这突出了在SR应用中领域感知训练的重要性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [945] [SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting](https://arxiv.org/abs/2507.23772)
> *SeqAffordSplat：3D高斯泼溅上的场景级序列化功能推理*

*Di Li, Jie Feng, Jiahao Chen, Weisheng Dong, Guanbin Li, Yuhui Zheng, Mingtao Feng, Guangming Shi* | **Category: cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D功能推理, 3D高斯泼溅, 序列化任务, 大型语言模型, 场景理解

**Comment:** 

> **TL;DR:** 引入了SeqAffordSplat基准和SeqSplatNet框架，将3D高斯泼溅上的功能推理从单步扩展到复杂的场景级序列任务。

**AI_Comments:** 这篇论文通过引入序列化功能推理任务和SeqAffordSplat基准，显著推动了3D功能理解领域的发展，特别是将现有局限于单步交互的方法扩展到更符合现实需求的长期、复杂场景任务。SeqSplatNet框架结合了大型语言模型、几何先验学习和多模态特征融合，体现了多领域技术融合的创新性。其对复杂几何和语义歧义的处理机制是其鲁棒性的关键。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于3D高斯泼溅（3DGS）的功能推理方法仅限于单对象、单步交互，无法处理复杂现实应用所需的长期、多对象任务。

**Method:** 本文引入了“序列化3D高斯功能推理”新任务，并建立了SeqAffordSplat大规模基准。提出了SeqSplatNet端到端框架，该框架将指令直接映射到一系列3D功能掩码。SeqSplatNet使用大型语言模型自回归生成文本和分割token来引导条件解码器。为处理复杂场景几何，引入了条件几何重建预训练策略。为解决语义歧义，设计了特征注入机制，将2D视觉基础模型的语义特征融合到3D解码器中。

**Result:** 实验证明，该方法在其挑战性基准上达到了新的最先进水平。

**Conclusion:** 该方法有效地将功能推理从单步交互推进到复杂、场景级的序列任务。

> **ai_Abstract:** 本文针对现有3D高斯泼溅（3DGS）功能推理方法在处理长期、多对象场景任务上的局限性，提出了“序列化3D高斯功能推理”新任务。为此，作者构建了大规模基准SeqAffordSplat，并开发了端到端框架SeqSplatNet。SeqSplatNet结合大型语言模型、条件几何重建预训练和2D视觉基础模型的特征注入机制，能够将指令映射为一系列3D功能掩码，从而实现场景级的复杂序列功能理解。实验结果表明，该方法在所提出的基准上取得了最先进的性能。

> **摘要翻译:** 3D功能推理，即将人类指令与3D对象的功能区域关联起来的任务，是具身智能体的关键能力。当前基于3D高斯泼溅（3DGS）的方法从根本上局限于单对象、单步交互，这种范式无法满足复杂现实应用所需的长期、多对象任务。为了弥补这一差距，我们引入了序列化3D高斯功能推理这一新任务，并建立了SeqAffordSplat，这是一个包含1800多个场景的大规模基准，旨在支持复杂3DGS环境中长期功能理解的研究。随后，我们提出了SeqSplatNet，一个端到端框架，它将指令直接映射到一系列3D功能掩码。SeqSplatNet采用大型语言模型，自回归地生成文本并穿插特殊分割token，引导条件解码器生成相应的3D掩码。为了处理复杂的场景几何，我们引入了一种预训练策略，即条件几何重建，模型从中学习从已知几何观测中重建完整的功能区域掩码，从而建立稳健的几何先验。此外，为了解决语义歧义，我们设计了一种特征注入机制，从2D视觉基础模型（VFM）中提取丰富的语义特征，并将其多尺度融合到3D解码器中。广泛的实验表明，我们的方法在具有挑战性的基准上树立了新的最先进水平，有效地将功能推理从单步交互推进到复杂、场景级的序列任务。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [946] [WeakSupCon: Weakly Supervised Contrastive Learning for Encoder Pre-training](https://arxiv.org/abs/2503.04165)
> *WeakSupCon: 弱监督对比学习用于编码器预训练*

*Bodong Zhang, Hamid Manoochehri, Xiwen Li, Beatrice S. Knudsen, Tolga Tasdizen* | **Category: cs.CV** | **Updated: 2025-07-30**

**Keywords:** 弱监督学习, 对比学习, 多实例学习, 特征表示学习, 编码器预训练

**Comment:** Medical Image Computing and Computer Assisted Intervention (MICCAI)
  2025 workshop on Efficient Medical AI

> **TL;DR:** WeakSupCon提出了一种新的弱监督对比学习方法，利用包级标签进行特征表示学习，显著提升了多实例学习（MIL）的分类性能。

**AI_Comments:** 该论文的创新点在于将弱监督学习与对比学习相结合，专门针对多实例学习（MIL）中的特征表示学习问题。它解决了当前MIL方法通常只关注特征聚合而忽视特征本身学习的局限性。通过利用包级标签来指导特征学习，WeakSupCon有效地提升了分类性能，这对于只有弱标签可用的实际应用（如病理图像分析）具有重要意义。该方法的提出为弱监督特征学习提供了一个新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多实例学习（MIL）方法主要关注特征聚合，而弱监督特征表示学习常被忽略。这些特征通常由不利用弱标签的自监督学习方法或在其他大型数据集上预训练的基础编码器生成，导致在MIL设置下特征学习的不足。

**Method:** 本文提出了一种名为Weakly Supervised Contrastive Learning (WeakSupCon) 的弱监督特征表示学习方法，该方法利用包级标签。在WeakSupCon中，采用了多任务学习，并为具有不同包标签的样本定义了不同的对比损失。

**Result:** 实验表明，与自监督方法相比，使用有限计算资源通过WeakSupCon生成的特征在三个数据集上显著提升了多实例学习（MIL）的分类性能。

**Conclusion:** WeakSupCon是一种有效的弱监督特征表示学习方法，它通过利用包级标签和多任务学习显著提高了多实例学习任务的分类性能。

> **ai_Abstract:** 本文提出了一种名为WeakSupCon的弱监督对比学习方法，旨在解决多实例学习（MIL）中特征表示学习被忽视的问题。该方法利用包级标签，并通过多任务学习为不同包标签的样本定义了独特的对比损失。实验结果表明，WeakSupCon在有限计算资源下，能生成有效特征，显著提升了MIL在多个数据集上的分类性能，优于传统的自监督方法。

> **摘要翻译:** 弱监督多实例学习（MIL）是一项具有挑战性的任务，因为只提供了包级标签，而每个包通常包含多个实例。该主题在组织病理学图像分析中得到了广泛研究，其中标签通常只在全玻片图像（WSI）级别可用，而每个WSI可以被分成数千个小的图像块进行训练。主流的MIL方法侧重于特征聚合，并以固定的补丁特征作为输入。然而，MIL设置中的弱监督特征表示学习总是被忽视。这些特征通常由不利用弱标签的自监督学习方法生成，或由在其他大型数据集上预训练的基础编码器生成。在本文中，我们提出了一种新颖的弱监督特征表示学习方法，称为弱监督对比学习（WeakSupCon），它利用包级标签。在我们的方法中，我们采用多任务学习，并为具有不同包标签的样本定义了不同的对比损失。我们的实验表明，与自监督方法相比，使用有限计算资源通过WeakSupCon生成的特征在三个数据集上显著提升了MIL分类性能。我们的WeakSupCon代码可在github.com/BzhangURU/Paper_WeakSupCon获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [15] [ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios](https://arxiv.org/abs/2507.22947)
> *ELMES：一个用于评估教育场景中大型语言模型的自动化框架*

*Shou'ang Wei, Xinyun Wang, Shuzhen Bi, Jian Chen, Ruijia Li, Bo Jiang, Xin Lin, Min Zhang, Yu Song, BingDong Li, Aimin Zhou, Hao Hao* | **Category: cs.CY, cs.CL, cs.LG** | **Updated: 2025-07-27**

**Keywords:** 大型语言模型, 教育, 评估框架, 教学能力, 自动化

**Comment:** 

> **TL;DR:** ELMES是一个开源的自动化评估框架，专门用于评估大型语言模型（LLMs）在教育场景中的表现，通过模块化架构和基于LLM-as-a-Judge的混合评估引擎，解决了现有评估指标不足和侧重通用智能而非教学能力的问题，并揭示了不同模型在特定教育场景中的优势和局限。

**AI_Comments:** ELMES通过其模块化架构和创新的“LLM即评委”方法，解决了LLMs在教育领域评估的痛点，即现有评估缺乏针对性和客观性。该框架的开源性质和对教育场景的专门设计是其重要创新点，有望显著降低LLMs在教育应用中的部署和评估门槛，促进LLMs在教学实践中的有效落地。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）为教育带来了变革性机遇，但现有评估指标在不同教育场景中差异很大，许多新兴场景缺乏合适的评估指标，且当前基准测试主要衡量通用智能而非教学能力，因此需要一个专门评估LLMs教学能力的框架。

**Method:** 研究人员开发了ELMES，一个开源的自动化评估框架，用于评估教育场景中的LLMs。该框架具有模块化架构，允许通过简单的配置文件创建动态、多代理对话，实现灵活的场景设计。它还包含一个混合评估引擎，使用“LLM即评委”的方法客观量化传统上主观的教学指标。研究人员在知识点解释、引导式问题解决教学、跨学科教案生成和情境化问题生成这四个关键教育场景中，采用与教育专家合作开发的细粒度指标，对最先进的LLMs进行了系统基准测试。

**Result:** 基准测试结果显示，不同模型之间存在明显的能力分布差异，揭示了它们在特定情境下的优势和局限。

**Conclusion:** ELMES为教育工作者和研究人员提供了一个易于使用的评估框架，显著降低了各种教育应用的适应障碍，并推动了LLMs在教学中的实际应用。

> **ai_Abstract:** 本论文介绍了ELMES，一个开源的自动化评估框架，旨在解决大型语言模型（LLMs）在教育场景中评估指标不足和侧重通用智能而非教学能力的问题。ELMES采用模块化架构和LLM-as-a-Judge的混合评估引擎，能够灵活设计场景并客观量化教学指标。研究团队在四个关键教育场景中对SOTA LLMs进行了系统基准测试，并发现模型能力分布存在情境化差异。ELMES提供了一个可访问的评估工具，有助于推动LLMs在教育领域的实际应用。

> **摘要翻译:** 大型语言模型（LLMs）的出现为教育带来了变革性机遇，产生了众多新颖的应用场景。然而，仍存在重大挑战：评估指标在不同教育场景中差异很大，而许多新兴场景缺乏合适的评估指标。当前的基准测试主要衡量通用智能而非教学能力。为了解决这一差距，我们引入了ELMES，一个专门为评估教育环境中的LLMs而设计的开源自动化评估框架。ELMES具有模块化架构，使研究人员能够通过简单的配置文件创建动态、多代理对话，从而在不需要大量编程专业知识的情况下实现灵活的场景设计。该框架整合了一个混合评估引擎，使用“LLM即评委”的方法客观量化传统上主观的教学指标。我们与教育专家合作开发了细粒度指标，在知识点解释、引导式问题解决教学、跨学科教案生成和情境化问题生成这四个关键教育场景中，对最先进的LLMs进行了系统基准测试。我们的结果显示，模型之间存在明显的能力分布差异，揭示了特定情境下的优势和局限。ELMES为教育工作者和研究人员提供了一个易于使用的评估框架，显著降低了各种教育应用的适应障碍，同时推动了LLMs在教学中的实际应用。该框架已公开发布于\emph{https://github.com/sii-research/elmes.git}。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [43] [Future Illiteracies -- Architectural Epistemology and Artificial Intelligence](https://arxiv.org/abs/2507.23434)
> *未来文盲——建筑认识论与人工智能*

*Mustapha El Moussaoui* | **Category: cs.CY** | **Updated: 2025-07-31**

**Keywords:** 建筑认识论, 人工智能, 标准化, 创造力, 数据

**Comment:** 14 pages, 7 figures. MDPI - Architecture 2025

> **TL;DR:** 论文探讨了人工智能时代建筑实践中数据、标准化与创新的矛盾，强调建筑师需主动运用批判性思维，使AI成为促进垂直和水平增长的工具，而非导致重复性设计的陷阱。

**AI_Comments:** 这篇论文的创新之处在于它将“文盲”的概念引入到AI时代的建筑实践中，强调了非技术性但更深层次的“知识贫乏”风险。它不仅指出了AI可能带来的标准化问题，更重要的是提出了建筑师需要主动参与和批判性思维的重要性，将AI定位为增强人类创造力的工具，而非替代。这对于理解人类与AI在创意领域的关系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在人工智能时代，建筑实践面临巨大潜力与日益标准化之间的矛盾。AI生成内容可能导致建筑成为重复性设计，缺乏真正的创新和深度。

**Method:** 本文探讨了数据在AI系统中的关键作用，审视了构成AI生成能力基础的训练数据集及其对建筑实践的影响。通过考察AI时代的建筑认识论，提出了一个范式。

**Result:** 论文认为，当建筑师被动地使用AI，而不主动运用其创造性和批判性能力时，他们可能会陷入无意义的水平扩张循环，缺乏有意义的垂直增长。

**Conclusion:** 建筑师只有掌握AI这种动态关系，才能避免被动、标准化的设计陷阱，并释放AI的真正潜力，使AI成为促进垂直和水平增长的工具，这取决于人类的创造力和能动性。

> **ai_Abstract:** 本文探讨了人工智能时代建筑实践中面临的挑战，即AI在带来巨大潜力的同时，也可能导致设计的标准化和重复。作者分析了AI训练数据的作用，并指出如果建筑师被动地使用AI，将限制创新和深度发展。论文强调，建筑师必须主动运用创造性和批判性思维，将AI视为促进垂直和水平增长的工具，以避免陷入被动标准化设计的困境，从而充分发挥AI的潜力。

> **摘要翻译:** 在人工智能时代，建筑实践面临着巨大潜力与日益标准化并存的悖论。随着人类越来越依赖AI生成的结果，建筑面临着沦为重复性景观的风险——一种数据的重组，既不能真正创新，也无法在创意深度上垂直进步。本文探讨了数据在AI系统中的关键作用，审视了构成AI生成能力基础的训练数据集及其对建筑实践的影响。我们认为，当建筑师被动地对待AI，而不主动运用他们自身的创造性和批判性能力时，他们就有可能成为被动的用户，陷入无休止的水平扩张循环，而没有有意义的垂直增长。通过审视AI时代的建筑认识论，本文呼吁建立一种范式，即AI作为垂直和水平增长的工具，这取决于人类的创造力和能动性。只有掌握这种动态关系，建筑师才能避免被动、标准化的设计陷阱，并释放AI的真正潜力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [71] [Architectural practice process and artificial intelligence -- an evolving practice](https://arxiv.org/abs/2507.23653)
> *建筑实践过程与人工智能——一种演进中的实践*

*Mustapha El Moussaoui* | **Category: cs.CY** | **Updated: 2025-07-31**

**Keywords:** 人工智能, 建筑实践, 设计过程, 技术进步, 生成式设计

**Comment:** 15 pages, 7 figures. De Gruyter Brill - Open Engineering 2025

> **TL;DR:** 人工智能正在重塑建筑实践，提升效率和创造力，但建筑师需将其视为协作伙伴，并关注空间的多感官体验和批判性思维。

**AI_Comments:** 本文深刻分析了人工智能在建筑领域的应用及其对传统实践的重塑。其创新点在于不仅探讨了AI提升效率和创造力的潜力，还批判性地指出了其在捕捉空间体验维度上的局限性。文章强调了建筑师与AI协作的重要性，并呼吁行业在未来发展中更加关注空间的整体感官体验和批判性思维，这为AI时代下的建筑教育和实践提供了宝贵的思考方向。

<details>
  <summary>Details</summary>

**Motivation:** 在技术飞速发展的时代，人工智能（AI）已成为建筑领域的变革力量，重塑了传统设计和施工实践。本文旨在探讨AI在建筑过程中的多方面作用，强调其提升创造力和效率的潜力，同时指出其在捕捉空间多感官和体验维度方面的局限性。

**Method:** 本文采用叙述性综述方法，重点关注选择的学术资源，这些资源因其相关性、新近性和可信度而被选中。

**Result:** 研究结果表明，AI正日益融入建筑过程的各个阶段，从早期概念化和场地分析到生成式设计和施工细节。AI工具擅长自动化重复性任务并生成创新的设计解决方案，使建筑师能够专注于创造力和解决问题。此外，AI的（文本到图像）视觉表现力挑战了建筑中以视觉为中心的方法，这应促使未来的建筑师关注空间的整体感官和体验品质或建筑设计固有的批判性思维。

**Conclusion:** 虽然人工智能具有变革潜力，但建筑师必须将其视为协作伙伴，而非被动工具。未来的建筑师应解决空间的整体感官和体验品质以及建筑设计中固有的批判性思维。

> **ai_Abstract:** 本文探讨了人工智能（AI）在建筑实践中的变革作用。研究发现AI正日益融入建筑设计和施工的各个阶段，能够自动化重复任务并生成创新设计，从而提升效率和创造力。然而，文章也指出AI在捕捉空间多感官体验方面的局限性，并强调建筑师应将AI视为协作伙伴，而非单纯的工具，同时需要关注整体感官品质和批判性思维。

> **摘要翻译:** 在技术飞速发展的时代，人工智能（AI）已成为建筑领域的变革力量，重塑了传统设计和施工实践。本文探讨了人工智能在建筑过程中的多方面作用，强调其提升创造力和效率的潜力，同时指出其在捕捉空间多感官和体验维度方面的局限性。从基本工具到先进的计算机辅助设计系统，建筑创新历来与技术进步并行。然而，人工智能的整合带来了独特的挑战，要求建筑师批判性地评估其在设计中的作用。本文采用叙述性综述方法，重点关注因其相关性、新近性和可信度而被选中的学术资源。研究结果表明，人工智能正日益融入建筑过程的各个阶段，从早期概念化和场地分析到生成式设计和施工细节。人工智能工具擅长自动化重复性任务并生成创新的设计解决方案，使建筑师能够专注于创造力和解决问题。此外，人工智能（文本到图像）的视觉表现力挑战了建筑中以视觉为中心的方法，这应促使未来的建筑师解决空间的整体感官和体验品质或建筑设计固有的批判性思维。虽然人工智能具有变革潜力，但建筑师必须将其视为协作伙伴，而非被动工具。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [99] [Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database](https://arxiv.org/abs/2507.23669)
> *自动化AI故障追踪：AI事件数据库中报告的语义关联*

*Diego Russo, Gian Marco Orlando, Valerio La Gatta, Vincenzo Moscato* | **Category: cs.CY, cs.AI, cs.IR** | **Updated: 2025-07-31**

**Keywords:** AI故障追踪, 语义关联, AI事件数据库, 检索框架, Transformer嵌入

**Comment:** Accepted at the 28th European Conference on Artificial Intelligence
  (ECAI 2025)

> **TL;DR:** 该论文提出了一种基于检索的框架，通过语义相似性建模自动化将新的AI故障报告与现有AI事件相关联，以提高AI事件数据库的可扩展性和效率。

**AI_Comments:** 该论文提出了一种创新的方法来解决AI故障报告管理中的可扩展性问题。通过引入语义相似性建模和基于Transformer的嵌入，它显著提升了自动化关联的准确性，对于维护大型AI事件数据库（如AIID）至关重要。其贡献在于提供了一个鲁棒且高效的自动化工具，有助于及时识别和缓解AI系统中的潜在风险。

<details>
  <summary>Details</summary>

**Motivation:** AI系统在关键领域部署时暴露出的漏洞可能导致严重的社会危害。现有AI事件数据库（如AIID）中，将新报告与适当的AI事件关联依赖于人工专家干预，这限制了可扩展性并延迟了新故障模式的识别。

**Method:** 提出了一种基于检索的框架，通过语义相似性建模自动化关联新报告与现有AI事件。将任务形式化为排序问题，通过嵌入余弦相似度比较报告（包含标题和完整文本描述）与现有AI事件。基准测试了传统词汇方法、交叉编码器架构和基于Transformer的句子嵌入模型。

**Result:** 基于Transformer的句子嵌入模型表现最佳。结合标题和描述比单独使用标题能显著提高排序准确性。检索性能在描述长度变化时保持稳定。随着训练集的扩展，检索性能持续提高。

**Conclusion:** 该方法为支持AI事件数据库的维护提供了一个可扩展且高效的解决方案。

> **ai_Abstract:** 本研究提出了一种基于检索的框架，旨在自动化AI故障报告与AI事件数据库中现有事件的关联过程。通过将此任务视为排序问题，并利用基于Transformer的句子嵌入模型进行语义相似度比较，该框架显著提高了关联的准确性和效率。实验证明，结合报告的标题和描述能带来最佳性能，且该方法在不同描述长度下表现稳定，并随训练数据量的增加而提升，为大规模AI故障追踪提供了可扩展的解决方案。

> **摘要翻译:** 人工智能（AI）系统正在改变医疗保健、金融和交通等关键领域，提高运营效率和决策过程。然而，它们在高风险领域的部署暴露了可能导致严重社会危害的漏洞。为了系统地研究和缓解这些风险，AI事件数据库（AIID）等倡议应运而生，收录了3000多份真实世界的AI故障报告。目前，将新报告与适当的AI事件关联依赖于人工专家干预，这限制了可扩展性并延迟了新故障模式的识别。

为了解决这一限制，我们提出了一种基于检索的框架，通过语义相似性建模自动化将新报告与现有AI事件关联。我们将该任务形式化为排序问题，其中每份报告（包含标题和完整文本描述）都根据嵌入余弦相似度与先前记录的AI事件进行比较。通过对传统词汇方法、交叉编码器架构和基于Transformer的句子嵌入模型进行基准测试，我们发现后者始终表现出卓越的性能。我们的分析进一步表明，与单独使用标题相比，结合标题和描述能显著提高排序准确性。此外，检索性能在描述长度变化时保持稳定，突出了该框架的鲁棒性。最后，我们发现随着训练集的扩展，检索性能持续提高。我们的方法为支持AIID的维护提供了一个可扩展且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [141] [Informing AI Risk Assessment with News Media: Analyzing National and Political Variation in the Coverage of AI Risks](https://arxiv.org/abs/2507.23718)
> *利用新闻媒体为人工智能风险评估提供信息：分析人工智能风险报道中的国家和政治差异*

*Mowafak Allaham, Kimon Kieslich, Nicholas Diakopoulos* | **Category: cs.CY** | **Updated: 2025-07-31**

**Keywords:** 人工智能风险评估, 新闻媒体, 跨国比较, 政治差异, 风险治理

**Comment:** Accepted to 8th AAAI/ACM Conference on AI, Ethics, and Society (2025)

> **TL;DR:** 本研究分析了新闻媒体如何报道人工智能风险，发现不同国家和政治立场对风险的优先排序和语言使用存在差异。

**AI_Comments:** 该研究的创新之处在于将新闻媒体作为社会背景的来源，以补充传统上以技术为中心的人工智能风险评估。其重要性在于揭示了国家和政治差异如何影响人工智能风险的公共认知和优先排序，为更全面的AI治理提供了新视角。研究结果强调了媒体议程设置和框架效应在塑造风险认知中的作用，对政策制定者具有实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人工智能治理风险评估方法主要关注技术本身，忽视了人工智能系统与社会复杂互动产生的系统性风险。新闻媒体作为反映这些互动的重要来源，其对人工智能风险的强调和讨论对公众认知至关重要。然而，不同国家和政治价值体系的新闻媒体可能通过议程设置和框架效应，差异化地塑造风险的优先排序，因此需要更好地理解这些差异。

**Method:** 本研究对来自6个国家（美国、英国、印度、澳大利亚、以色列和南非）的新闻媒体样本进行了比较分析。

**Result:** 研究发现，人工智能风险在不同国家之间被优先排序的方式不同；在美国，左右翼媒体不仅在人工智能风险的优先排序上存在差异，而且在报道这些风险时也使用了政治化的语言。

**Conclusion:** 这些发现可以为风险评估人员和政策制定者提供参考，使其在将新闻媒体作为基于风险的治理方法的补充来源时，能够考虑到报道中的细微差别。

> **ai_Abstract:** 本研究旨在通过分析新闻媒体报道，将社会背景纳入人工智能风险评估。研究指出，现有评估方法侧重技术本身而忽视系统性社会风险。新闻媒体作为反映人工智能与社会互动的重要载体，其报道方式影响公众对风险的认知。通过对6个国家新闻媒体的比较分析，本研究发现人工智能风险在不同国家和政治立场（如美国左右翼媒体）中被优先排序的方式存在显著差异，且政治化语言被用于风险报道。这些发现为政策制定者和风险评估者在利用新闻媒体作为风险治理辅助信息时，提供了重要的考量依据。

> **摘要翻译:** 人工智能治理的风险方法通常将技术本身作为风险评估的主要焦点，而忽视了人工智能系统与社会复杂互动所产生的系统性风险。新闻媒体是将其纳入这些方法的一个潜在来源，因为它嵌入并反映了人工智能系统、人类利益相关者和更广泛社会之间的复杂互动。新闻媒体在哪些人工智能风险被强调和在公共领域讨论方面具有影响力，从而决定了哪些风险被认为重要。然而，不同国家和不同价值体系（例如政治倾向）之间新闻媒体的差异，可能通过媒体的议程设置和框架过程，差异化地塑造风险的优先排序。为了更好地理解这些差异，这项工作对来自6个国家（美国、英国、印度、澳大利亚、以色列和南非）的跨国新闻媒体样本进行了比较分析。我们的研究结果表明，人工智能风险在不同国家之间被优先排序的方式不同，并揭示了美国左右翼媒体不仅在人工智能风险报道的优先排序上存在差异，而且在报道这些风险时也使用了政治化的语言。这些发现可以为风险评估人员和政策制定者提供信息，使其在将新闻媒体作为基于风险的治理方法的补充来源时，应考虑到其中的细微差别。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [208] [Towards Efficient Certification of Maritime Remote Operation Centers](https://arxiv.org/abs/2508.00543)
> *迈向海事远程操作中心的高效认证*

*Christian Neurohr, Marcel Saager, Lina Putze, Jan-Patrick Osterloh, Karina Rothemann, Hilko Wiards, Eckard Böde, Axel Hahn* | **Category: cs.CY, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 海事远程操作中心, 危害数据库, 认证, 自动化船舶, 风险评估

**Comment:** 

> **TL;DR:** 本文提出了一个危害数据库的概念，旨在支持海事远程操作中心的安全保障和认证，以应对船舶自动化带来的船员岸基化和远程监控需求。

**AI_Comments:** 本文针对船舶自动化发展带来的新型风险管理需求，提出了一个危害数据库的创新概念。其重要性在于为海事远程操作中心（ROCs）的认证和安全保障提供了潜在的框架性支持。通过构建危害数据库并识别适用的分析方法，该研究有助于提升ROCs的风险管理效率和安全性。然而，作为概念性工作，其具体实施细节、数据库内容填充的准确性以及在实际应用中的有效性仍需进一步验证和完善。

<details>
  <summary>Details</summary>

**Motivation:** 随着船舶自动化程度的提高，船员将从船上转移到岸基远程操作中心（ROCs）进行船舶的监控和远程控制。为了确保这些远程操作中心的安全运行并对其进行认证，需要一种有效的方法来识别和管理潜在危害。

**Method:** 本文提出了一个危害数据库的概念。该概念基于从通用功能架构中导出的危害源分类。随后，通过初步适用性分析，确定了哪些危害分析和风险评估方法可以充分填充该危害数据库。

**Result:** 提出了一种支持海事远程操作中心安全保障和认证的危害数据库概念。初步适用性分析揭示了哪些危害分析和风险评估方法能够有效填充该数据库。

**Conclusion:** 该研究提出的危害数据库概念能够支持海事远程操作中心的安全保障和认证。

> **ai_Abstract:** 本研究针对船舶自动化导致船员岸基化和远程操作中心（ROCs）兴起的趋势，提出了一个危害数据库的概念。该数据库旨在支持ROCs的安全保障和认证。其核心方法是基于通用功能架构对危害源进行分类，并通过初步适用性分析确定了适用于填充该数据库的危害分析和风险评估方法。

> **摘要翻译:** 船舶中正在构建的额外自动化意味着船员将从船上转移到岸上。然而，自动化船舶仍然需要被监控，并在某些情况下进行远程控制。这些任务由位于岸基远程操作中心的人类操作员执行。在这项工作中，我们提出了一个危害数据库的概念，该概念支持此类远程操作中心的安全保障和认证。该概念基于从通用功能架构中导出的危害源分类。随后的初步适用性分析揭示了哪些危害分析和风险评估方法可以充分填充该危害数据库。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [211] [Toward Integrated Solutions: A Systematic Interdisciplinary Review of Cybergrooming Research](https://arxiv.org/abs/2503.05727)
> *走向综合解决方案：网络诱骗研究的系统跨学科综述*

*Heajun An, Marcos Silva, Qi Zhang, Arav Singh, Minqian Liu, Xinyi Zhang, Sarvech Qadir, Sang Won Lee, Lifu Huang, Pamela J. Wisniewski, Jin-Hee Cho* | **Category: cs.CY, cs.CR** | **Updated: 2025-07-31**

**Keywords:** 网络诱骗, 系统综述, 跨学科, 预防, 检测

**Comment:** 

> **TL;DR:** 网络诱骗研究在社会科学和计算方法之间存在碎片化。本系统综述整合了这两个领域，以识别挑战并指导未来综合性的预防和检测策略。

**AI_Comments:** 本论文的创新之处在于它系统地弥合了网络诱骗领域中社会科学和计算研究之间的鸿沟，而这个领域通常是孤立研究的。其重要性在于识别了当前方法中的关键挑战（例如，数据质量、资源密集性、指标局限性），并为未来的跨学科合作提供了路线图，这对于制定全面有效的预防策略至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 网络诱骗研究仍然分散，限制了整体预防。社会科学和计算方法之间的整合不足。本综述旨在弥合这些差距，推动跨学科研究，以实现更有效的预防和检测。

**Method:** 本研究采用PRISMA框架，对网络诱骗研究中的社会科学和计算方法进行了系统的跨学科综述。

**Result:** 定性方法提供了深刻见解但资源密集；机器学习模型依赖于数据质量；标准指标在不平衡和文化细微差别方面存在困难。

**Conclusion:** 本综述通过弥合社会科学和计算方法之间的差距，推动了跨学科网络诱骗研究，指导未来的努力走向更有效的预防和检测策略。

> **ai_Abstract:** 本论文对网络诱骗研究进行了系统的跨学科综述，旨在解决社会科学和计算方法之间的碎片化问题。它利用PRISMA框架综合了这两个领域的发现，强调了当前方法面临的挑战，例如定性方法的资源密集性、机器学习模型对数据质量的依赖以及标准指标的局限性。本综述旨在弥合这些差距，以促进更有效的网络诱骗预防和检测的综合解决方案。

> **摘要翻译:** 网络诱骗通过在线建立信任来剥削未成年人，但现有研究仍然分散，限制了整体预防。社会科学侧重于行为洞察，而计算方法强调检测，但它们的整合仍然不足。本综述使用PRISMA框架系统地综合了这两个领域，以提高清晰度、可重复性和跨学科协作。研究结果表明，定性方法提供了深刻的见解，但资源密集；机器学习模型依赖于数据质量；标准指标在不平衡和文化细微差别方面存在困难。通过弥合这些差距，本综述推动了跨学科网络诱骗研究，指导未来的努力走向更有效的预防和检测策略。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [436] [How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment](https://arxiv.org/abs/2401.13481)
> *人工智能思想如何影响人类思想的创造力、多样性和演变：来自一项大型动态实验的证据*

*Joshua Ashkinaze, Julia Mendelsohn, Li Qiwei, Ceren Budak, Eric Gilbert* | **Category: cs.CY, cs.AI, cs.CL, cs.HC** | **Updated: 2025-07-31**

**Keywords:** AI影响, 创造力, 多样性, 动态实验, 集体思想

**Comment:** Accepted at ACM Collective Intelligence 2025. Originally posted 2024

> **TL;DR:** 高AI暴露增加了集体思想多样性，但未影响个体创造力；AI使思想不同而非更好。

**AI_Comments:** 这项研究通过其独特的动态实验设计，有效地模拟了AI在文化创造循环中的长期影响，具有重要的创新性。它提供了关于AI对人类创造力影响的细致见解，区分了个体创造力和集体多样性，纠正了AI可能直接提升个体创造力的普遍假设。研究结果对于理解AI与人类协作的未来以及设计更有效的人机交互系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型输出的日益普及，研究旨在探究看到AI生成思想如何影响人类思想。

**Method:** 进行了一项大型动态实验（800多名参与者，40多个国家），参与者观看来自ChatGPT或先前实验参与者的创意想法，然后进行头脑风暴。实验变量包括AI生成示例的数量（无、低、高暴露）以及示例是否被标记为“AI”（披露）。动态设计使得先前参与者的想法作为未来参与者的刺激，以捕捉LLMs“在文化循环中”的复合效应。

**Result:** 高AI暴露（但非低AI暴露）不影响个体思想的创造力，但增加了集体思想多样性的平均数量和变化率。AI使思想不同，而非更好。没有披露的主要影响。自我报告的创意人群受AI来源影响较小，且在任务困难时参与者可能有意采纳AI思想。

**Conclusion:** 引入AI思想可能增加集体多样性，但不会增加个体创造力。

> **ai_Abstract:** 本研究通过一项大型动态实验，探究了暴露于AI生成想法对人类创造力、多样性和思想演变的影响。实验发现，高AI暴露（而非低暴露）并未提升个体思想的创造力，却显著增加了集体思想多样性的平均水平和变化速度，表明AI使思想变得不同而非更好。研究还指出，AI来源的披露没有主要影响，且自我报告的创意人群受AI影响较小，任务困难时参与者可能主动采纳AI想法。结论是引入AI思想可促进集体多样性，但无益于个体创造力。

> **摘要翻译:** 大型语言模型输出的暴露量正在迅速增加。看到人工智能生成的想法将如何影响人类的想法？我们进行了一项实验（800多名参与者，40多个国家），参与者观看来自ChatGPT或先前实验参与者的创意想法，然后集思广益提出自己的想法。我们改变了人工智能生成示例的数量（无、低或高暴露）以及示例是否被标记为“AI”（披露）。我们的动态实验设计——实验条件中先前参与者的想法被用作同一实验条件下未来参与者的刺激——说明了文化创造的相互依赖过程：创意想法建立在先前的想法之上。因此，我们捕捉到大型语言模型“在文化循环中”的复合效应。我们发现，高人工智能暴露（但非低人工智能暴露）不影响个体想法的创造力，但确实增加了集体想法多样性的平均数量和变化率。人工智能使想法不同，而不是更好。披露没有主要影响。我们还发现，自我报告的创意人士受知道想法来自人工智能的影响较小，并且在任务困难时，参与者可能会有意采纳人工智能想法。我们的研究结果表明，引入人工智能想法可能会增加集体多样性，但不会增加个体创造力。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [481] ["I will never pay for this" Perception of fairness and factors affecting behaviour on 'pay-or-ok' models](https://arxiv.org/abs/2505.12892)
> *“我绝不会为此付费”：关于“付费或同意”模式中公平感知及影响行为的因素*

*Victor Morel, Farzaneh Karegar, Cristiana Santos* | **Category: cs.CY** | **Updated: 2025-07-31**

**Keywords:** Cookie付费墙, 公平感知, 用户行为, 隐私权, GDPR

**Comment:** Accepted for publication at APF2025

> **TL;DR:** 本研究探讨了用户对“付费或同意”模型（即cookie付费墙）的看法、对公平性的判断以及考虑付费的条件，发现用户普遍认为其是逐利的，且对付费持不情愿态度，并对经济排斥和GDPR下同意的有效性提出了担忧。

**AI_Comments:** 本文通过结合焦点小组访谈和法律分析，深入探讨了用户对“付费或同意”模型的复杂感知，特别是其对公平性、隐私权和经济排斥的影响，具有较强的现实意义和创新性。研究结果揭示了当前模型在用户接受度和GDPR合规性方面的潜在问题，并提出了切实可行的改进建议，对于政策制定者和数字服务提供商具有重要的参考价值。其创新点在于从用户视角出发，结合法律框架，全面分析了这一新兴模式的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 尽管“付费或同意”模型（cookie付费墙）日益普及，但关于用户如何感知这些模型以及何种因素影响他们选择同意追踪或付费的研究有限。本研究旨在弥补这一空白，探讨用户对cookie付费墙的看法、公平性判断以及可能考虑付费的条件。

**Method:** 本研究采用了四场焦点小组访谈（n=14）来考察用户对cookie付费墙的感知、公平性判断以及可能考虑付费的条件。此外，还进行了欧盟数据保护法律框架内的法律分析。

**Result:** 参与者主要将cookie付费墙视为逐利行为，对公平性的看法因是否存在除同意或支付之外的第三个选项、数据实践的透明度以及付费内容的真实性或独特性等因素而异。尽管在某些条件下（如受信任的提供商、独家内容、合理定价）参与者可能会考虑付费，但大多数人表达了不情愿或不愿付费的态度。研究结果还引发了对经济排斥的担忧，即隐私和数据保护可能成为特权而非基本权利。在经济压力下做出的同意可能不符合GDPR要求的“自由给予”标准。

**Conclusion:** 在同意驱动的数字环境中，为支持公平性、有意义的选择和用户自主权，需要采取以用户为中心的方法，增强透明度、减少强制性、确保付费内容的价值并探索包容性替代方案。在经济压力下做出的同意可能不符合GDPR要求的GDPR“自由给予”标准。

> **ai_Abstract:** 本研究探讨了用户对日益增长的“付费或同意”模型（即cookie付费墙）的感知、公平性判断及其行为影响因素。通过四场焦点小组访谈和法律分析，研究发现用户普遍认为这些模型是逐利的，对公平性的看法受多种因素影响，且多数用户不愿为此付费。研究强调了经济排斥的风险，并质疑在经济压力下获得的同意是否符合GDPR标准。文章呼吁采取以用户为中心的方法，增强透明度、减少强制性，并探索更具包容性的替代方案，以维护数字环境中的公平性和用户自主权。

> **摘要翻译:** cookie付费墙（“付费或同意”模式）的兴起引发了关于隐私权和数据保护、货币化以及用户同意合法性的日益激烈的争论。尽管这些模式在各个领域的使用日益增多，但探索用户如何感知这些模式或何种因素影响他们选择同意追踪或付费的研究却很有限。为了弥补这一空白，我们进行了四场焦点小组（n=14），以考察用户对cookie付费墙的看法、对公平性的判断以及在何种条件下他们可能会考虑付费，同时在欧盟数据保护法律框架内进行了法律分析。
参与者主要将cookie付费墙视为逐利行为，对公平性的看法因是否存在除同意或支付之外的第三个选项、数据实践的透明度以及付费内容的真实性或独特性等因素而异。参与者表示期待更高的透明度、对数据收集的有效控制以及更少强制性的替代方案，例如情境广告或“拒绝所有”按钮。尽管在某些条件下，包括受信任的提供商、独家内容和合理定价，可能会使参与者考虑付费，但大多数人表达了不情愿或不愿付费的态度。
至关重要的是，我们的研究结果引发了对经济排斥的担忧，即隐私和数据保护最终可能成为一种特权而非基本权利。在经济压力下做出的同意可能不符合GDPR要求的“自由给予”标准。为了解决这些担忧，我们建议采用以用户为中心的方法，增强透明度、减少强制性、确保付费内容的价值并探索包容性替代方案。这些措施对于在同意驱动的数字环境中支持公平性、有意义的选择和用户自主权至关重要。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [659] [Green Computing: The Ultimate Carbon Destroyer for a Sustainable Future](https://arxiv.org/abs/2508.00153)
> *绿色计算：可持续未来的终极碳消除器*

*Sayed Mahbub Hasan Amiri, Prasun Goswami, Md. Mainul Islam, Mohammad Shakhawat Hossen, Marzana Mithila, Naznin Akter* | **Category: cs.CY, cs.SC** | **Updated: 2025-07-31**

**Keywords:** 绿色计算, 脱碳, 可持续IT, 能源效率, 电子垃圾

**Comment:** 26 Pages, 6 Tables

> **TL;DR:** 绿色计算是实现数字经济脱碳的关键途径，通过节能硬件、AI优化数据中心和循环电子垃圾系统，可大幅减少能耗并带来经济效益，是应对气候危机的强大工具。

**AI_Comments:** 这篇论文的创新之处在于它不仅强调了绿色计算的重要性，还提供了一个实用的框架和具体的节能数据（40-60%）。它将计算视为一个积极的“碳消除器”而非仅仅是减少排放的工具，这种视角非常有意义。论文还识别了实施过程中的系统性障碍，并展望了未来技术的潜力，使其更具全面性和指导性。

<details>
  <summary>Details</summary>

**Motivation:** 应对气候危机，实现数字经济脱碳，同时保持技术进步，并将计算转变为净碳汇。

**Method:** 本文通过分析行业最佳实践和新兴技术（如量子计算和可生物降解电子产品），并研究了当前解决方案的效益、系统性障碍和下一代创新的潜力。提出一个实用框架，为利益相关者提供加速转型的指导。

**Result:** 1. 当前解决方案已提供环境和经济效益，典型投资回收期为3-5年；2. 系统性障碍（如成本溢价和政策碎片化）需要协调行动；3. 下一代创新有望实现效率的数量级改进；4. 可实现40-60%的能耗降低，同时不影响性能。

**Conclusion:** 对绿色IT的战略投资可以为未来所有部门带来不成比例的可持续性红利，计算具有作为气候解决方案的独特潜力，需要采取紧急行动并提供清晰的路线图以实现其作为强大碳消除工具的潜力。

> **ai_Abstract:** 本文探讨了绿色计算作为数字经济脱碳的关键途径。通过分析节能硬件、AI优化数据中心和循环电子垃圾系统等可持续IT策略，文章指出计算可以转变为净碳汇，并实现40-60%的能耗降低。研究强调现有解决方案已带来环境和经济效益，但需克服系统性障碍，同时指出下一代创新潜力巨大。文章提出了一个实用框架，并强调了计算在应对气候危机中的独特潜力，呼吁立即采取行动以实现其作为强大碳消除工具的作用。

> **摘要翻译:** 绿色计算代表了在保持技术进步的同时，实现数字经济脱碳的关键途径。本文探讨了可持续IT策略，包括节能硬件、AI优化数据中心和循环电子垃圾系统，如何将计算转变为净碳汇。通过对行业最佳实践以及量子计算和可生物降解电子产品等新兴技术的分析，我们证明了在不影响性能的情况下，可实现40-60%的能耗降低。研究强调了三个主要发现：（1）当前解决方案已经提供了环境和经济效益，典型投资回收期为3-5年；（2）包括成本溢价和政策碎片化在内的系统性障碍需要协调行动；（3）下一代创新有望实现效率的数量级改进。我们提出了一个实用的框架，供从采用可再生能源云服务的公司到延长设备寿命的个人等利益相关者加速转型。这项研究强调了计算通过其快速创新周期和可衡量影响作为气候解决方案的独特潜力，并得出结论认为，今天对绿色IT的战略投资可以在明天为所有部门带来不成比例的可持续性红利。这项工作为采取紧急行动提供了有力的论证，也为在气候危机时代实现计算作为强大碳消除工具的潜力提供了清晰的路线图。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [933] [SmartCourse: A Contextual AI-Powered Course Advising System for Undergraduates](https://arxiv.org/abs/2507.22946)
> *SmartCourse：一个面向本科生的情境感知人工智能驱动课程咨询系统*

*Yixuan Mi, Yiduo Yu, Yiyi Zhao* | **Category: cs.CY, cs.AI** | **Updated: 2025-07-26**

**Keywords:** 课程咨询系统, 人工智能, 情境感知, 本科生, 学术规划

**Comment:** 7 pages, 6 figures, 1 table. *Corresponding author: Yixuan Mi. Code:
  https://github.com/EthanYixuanMi/Smartcourse-Contextual-Advising

> **TL;DR:** SmartCourse是一个集成课程管理和AI驱动的咨询系统，通过结合成绩单和学习计划提供个性化课程推荐，并实验证明其情境感知能力能显著提升推荐的相关性。

**AI_Comments:** 该论文的创新点在于将学生成绩单和学习计划等个性化情境信息深度整合到AI驱动的课程咨询系统中，并利用本地大型语言模型提供个性化推荐。这解决了传统工具缺乏个性化的问题。其重要性在于为学生提供了更精准、更相关的学术规划支持，有助于提高学习效率和满意度。自定义评估指标的引入也增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 传统课程咨询工具存在局限性，无法整合学生成绩单和学习计划等个性化信息。SmartCourse旨在通过情境感知AI来解决这一问题，为本科生提供更个性化的课程建议。

**Method:** SmartCourse是一个集成的课程管理和AI驱动的咨询系统，专门为计算机科学专业的本科生设计。它整合了命令行界面（CLI）和Gradio网络GUI供教师和学生使用，管理用户账户、课程注册、评分和四年制学位计划。系统内部集成了一个本地托管的大型语言模型（通过Ollama）以提供个性化课程推荐。它利用学生的成绩单和专业计划来提供情境感知建议，例如优先考虑课程要求或重修。系统通过25个代表性咨询查询进行评估，并引入了PlanScore、PersonalScore、Lift和Recall等自定义指标来评估不同情境条件下的推荐质量。

**Result:** 实验结果表明，使用完整情境（即成绩单和学习计划信息）比不使用情境的模式能产生显著更相关的推荐。这证实了成绩单和学习计划信息对于个性化学术咨询的必要性。

**Conclusion:** SmartCourse系统展示了情境感知AI（特别是利用成绩单信息）如何有效增强学术规划，为学生提供更个性化的课程建议。

> **ai_Abstract:** SmartCourse是一个创新的AI驱动课程咨询系统，专为本科生设计，特别是计算机科学专业。该系统通过整合学生的成绩单和学习计划，克服了传统咨询工具的局限性，提供个性化的课程推荐。它结合了CLI和Web GUI，并利用本地大型语言模型进行推荐。通过实验评估，SmartCourse证明了其情境感知能力能显著提升推荐的相关性，强调了学生历史数据在学术咨询中的关键作用。

> **摘要翻译:** 我们提出了SmartCourse，一个为本科生（特别是针对计算机科学（CPS）专业）设计的集成课程管理和AI驱动的咨询系统。SmartCourse通过整合学生的成绩单和学习计划信息来解决传统咨询工具的局限性，从而提供学生特定的情境。该系统结合了命令行界面（CLI）和Gradio网络GUI供教师和学生使用，管理用户账户、课程注册、评分和四年制学位计划，并集成了一个本地托管的大型语言模型（通过Ollama）以提供个性化课程推荐。它利用成绩单和专业计划提供情境化建议（例如，优先考虑要求或重修）。我们对系统进行了25个代表性咨询查询的评估，并引入了自定义指标：PlanScore、PersonalScore、Lift和Recall来评估不同情境条件下的推荐质量。实验表明，使用完整情境比省略情境模式能产生显著更相关的推荐，证实了成绩单和计划信息对于个性化学术咨询的必要性。因此，SmartCourse展示了成绩单感知型AI如何增强学术规划。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [938] [Data Bias in Human Mobility is a Universal Phenomenon but is Highly Location-specific](https://arxiv.org/abs/2508.00149)
> *人类出行数据中的偏差是一种普遍现象，但具有高度地域特异性*

*Katinka den Nijs, Elisa Omodei, Vedran Sekara* | **Category: cs.CY, cs.SI, physics.soc-ph** | **Updated: 2025-07-31**

**Keywords:** 数据偏差, 人类出行, 地域特异性, 数据生产, 人口统计学

**Comment:** 

> **TL;DR:** 人类出行大数据存在普遍但地域特异的数据偏差，受财富、种族、教育等因素影响，需要特定地点模型来解决。

**AI_Comments:** 这项研究的创新之处在于其对“数据生产”的关注，量化了个人产生的数据量及其与人口统计学特征（如财富、种族、教育）的关联。其重要性在于揭示了大规模人类出行数据集中普遍存在的、影响深远的偏差，并指出这种偏差具有高度地域特异性。这挑战了当前通用的数据去偏差方法，强调了针对不同城市制定特定去偏差策略的必要性，对依赖此类数据进行决策的领域具有重要警示作用。

<details>
  <summary>Details</summary>

**Motivation:** 大规模人类出行数据集在算法系统、业务流程和政策决策中日益重要，但对其偏差及如何影响下游分析和预测任务的关注不足。

**Method:** 研究来自十个美国主要城市的匿名智能手机GPS出行数据。构建模型预测人口普查区内不同人口群体生成数据点的数量，分析财富、种族和教育对数据生成的影响。

**Result:** 发现用户间数据点分布不均程度甚至高于财富不均。财富、种族和教育对数据生成有显著影响。数据偏差是普遍现象，存在于所有城市，但每个城市表现形式不同，需要地域特定的模型来建模偏差。

**Conclusion:** 本研究对通用的人类出行数据去偏差方法提出质疑，并呼吁进一步研究。

> **ai_Abstract:** 本研究关注大规模人类出行数据集中普遍存在的偏差问题，探讨了数据生产中个体被代表的程度和数据量。通过分析十个美国主要城市的匿名智能手机GPS数据，发现数据点在用户间的分布不均程度甚至超过财富，且财富、种族和教育对数据生成有显著影响。研究指出数据偏差是普遍现象，但在不同城市表现各异，因此需要地域特定的模型来解决。这挑战了当前通用的去偏差方法，并强调了未来研究的必要性。

> **摘要翻译:** 大规模人类出行数据集在许多算法系统、业务流程和政策决策中扮演着日益重要的角色。不幸的是，人们很少关注理解这些数据集的偏差和其他基本缺陷，以及它们如何影响下游分析和预测任务。在这项工作中，我们研究“数据生产”，不仅量化个体是否在大规模数字数据集中被代表，还量化他们如何被代表，即他们产生多少数据。我们研究了从十个美国主要城市的匿名智能手机收集的GPS出行数据，发现用户之间的数据点分布不均程度可能比财富不均更严重。我们建立了模型来预测人口普查区内不同人口群体产生的预期数据点数量，发现财富、种族和教育对数据生产有强烈影响。虽然我们发现偏差是一种普遍现象，存在于所有城市，但我们进一步发现每个城市都有其自身的表现形式，并且需要地域特定的模型来建模每个城市的偏差。这项工作对通用的人类出行数据去偏差方法提出了严重质疑，并敦促进一步研究。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [113] [AutoIndexer: A Reinforcement Learning-Enhanced Index Advisor Towards Scaling Workloads](https://arxiv.org/abs/2507.23084)
> *AutoIndexer：一种面向扩展工作负载的强化学习增强型索引推荐器*

*Taiyi Wang, Eiko Yoneki* | **Category: cs.DB, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 索引选择, 强化学习, 数据库性能, 工作负载扩展, AutoIndexer

**Comment:** 14 pages

> **TL;DR:** AutoIndexer是一个利用强化学习、工作负载压缩和查询优化来有效选择索引的框架，它显著提高了数据库性能，并在处理大规模工作负载方面优于现有方法。

**AI_Comments:** AutoIndexer的创新之处在于其将工作负载压缩与强化学习相结合，有效解决了RL-based索引推荐器在处理扩展工作负载时面临的动作空间爆炸和高昂试错成本问题。这对于提升数据库在实际大规模应用中的性能优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高效选择索引对于数据库性能优化至关重要，特别是对于处理大规模分析工作负载的系统。现有的基于强化学习的索引推荐器在适应扩展工作负载时面临挑战，因为动作空间呈指数级增长且试错成本高昂。

**Method:** AutoIndexer框架结合了工作负载压缩、查询优化和专门的强化学习模型来有效扩展索引选择。通过在压缩工作负载上运行，它在不牺牲太多索引质量的情况下大幅降低了搜索复杂性。

**Result:** 与非索引基线相比，AutoIndexer将端到端查询执行时间减少了高达95%。与最先进的基于强化学习的索引推荐器相比，它在工作负载成本节约方面平均提高了约20%，同时将调优时间缩短了50%以上。

**Conclusion:** AutoIndexer的实验结果证实了其对于处理大型和多样化工作负载的实用性。

> **ai_Abstract:** 本文提出了AutoIndexer，一个针对大规模分析工作负载的强化学习增强型索引推荐器。它通过结合工作负载压缩、查询优化和专门的强化学习模型来解决现有RL-based索引推荐器在扩展性上的挑战。AutoIndexer能在大幅降低搜索复杂度的同时保持索引质量，实验结果表明它能显著减少查询执行时间，并在成本节约和调优时间上优于现有方法，证明了其在大规模和多样化工作负载下的实用性。

> **摘要翻译:** 高效选择索引对于数据库性能优化至关重要，特别是对于处理大规模分析工作负载的系统。虽然深度强化学习（DRL）通过其从经验中学习的能力在自动化索引选择方面展现出前景，但很少有工作解决这些基于强化学习的索引推荐器如何适应扩展工作负载，因为动作空间呈指数级增长且试错成本高昂。为了解决这些挑战，我们引入了AutoIndexer，一个结合了工作负载压缩、查询优化和专门强化学习模型的框架，以有效扩展索引选择。通过在压缩工作负载上操作，AutoIndexer在不牺牲太多索引质量的情况下大幅降低了搜索复杂性。广泛的评估表明，与非索引基线相比，它将端到端查询执行时间缩短了高达95%。平均而言，它在工作负载成本节约方面比最先进的基于强化学习的索引推荐器高出约20%，同时将调优时间缩短了50%以上。这些结果证实了AutoIndexer对于大型和多样化工作负载的实用性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [155] [Jelly-Patch: a Fast Format for Recording Changes in RDF Datasets](https://arxiv.org/abs/2507.23499)
> *Jelly-Patch：一种用于记录RDF数据集变化的快速格式*

*Piotr Sowinski, Kacper Grzymkowski, Anastasiya Danilenka* | **Category: cs.DB** | **Updated: 2025-07-31**

**Keywords:** RDF, 数据变化, 序列化, 压缩, Jelly-Patch

**Comment:** 

> **TL;DR:** Jelly-Patch是一种新的压缩二进制格式，用于快速记录RDF数据集的变化，相比现有格式，它提供了更好的压缩和更高的吞吐量。

**AI_Comments:** Jelly-Patch的创新在于其作为一种高性能、压缩的二进制序列化格式，专门用于优化RDF数据集变化的记录。其重要性体现在解决了大规模RDF系统中数据更新带来的性能挑战，对于需要高效处理数据变化的场景（如审计、备份和实时流）具有重要意义。通过显著提升压缩和吞吐量，该方法有望成为RDF数据管理领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 在RDF系统中记录数据变化对于审计、增量备份、数据库复制和事件驱动型工作流至关重要。然而，在大规模和低延迟的RDF应用中，高频率和大量的更新会导致数据变化的序列化和传输出现性能瓶颈。

**Method:** 本文提出了Jelly-Patch，一种用于RDF数据集变化的高性能、压缩二进制序列化格式。为了评估其性能，研究人员使用两个代表不同用例（数据变更捕获和IoT流）的数据集，将Jelly-Patch与现有RDF Patch格式进行了基准测试。

**Result:** Jelly-Patch实现了3.5-8.9倍的更好压缩，以及在序列化和解析方面分别高达2.5倍和4.6倍的吞吐量提升。

**Conclusion:** Jelly-Patch在吞吐量和压缩方面的显著进步有望提高大规模和低延迟RDF系统的性能。

> **ai_Abstract:** 本文提出了一种名为Jelly-Patch的高性能、压缩二进制序列化格式，用于记录RDF数据集的变化。该格式旨在解决大规模和低延迟RDF应用中数据更新序列化和传输的性能瓶颈。通过基准测试，Jelly-Patch在压缩率和吞吐量方面均显著优于现有RDF Patch格式，预计将提升相关系统的性能。

> **摘要翻译:** 记录RDF系统中的数据变化是一项关键能力，支持审计、增量备份、数据库复制和事件驱动型工作流。在大规模和低延迟的RDF应用中，高容量和高频率的更新可能导致变化的序列化和传输出现性能瓶颈。为了缓解这一问题，我们提出了Jelly-Patch——一种用于RDF数据集变化的高性能、压缩二进制序列化格式。为了评估其性能，我们使用代表不同用例（数据变更捕获和物联网流）的两个数据集，将Jelly-Patch与现有RDF Patch格式进行基准测试。Jelly-Patch被证明实现了3.5-8.9倍的更好压缩，以及在序列化和解析方面分别高达2.5倍和4.6倍的更高吞吐量。这些在吞吐量和压缩方面的显著进步有望提高大规模和低延迟RDF系统的性能。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [197] [DataLens: Enhancing Dataset Discovery via Network Topologies](https://arxiv.org/abs/2507.23515)
> *DataLens：通过网络拓扑增强数据集发现*

*Anaïs Ollagnier, Aline Menin* | **Category: cs.DB** | **Updated: 2025-07-31**

**Keywords:** 数据集发现, 网络拓扑, 可视化, 分面搜索, DataLens

**Comment:** 

> **TL;DR:** DataLens是一个基于网络的平台，结合分面搜索和高级可视化技术，以增强文本资源发现，解决现有搜索方法缺乏关联性的问题。

**AI_Comments:** DataLens的创新之处在于其将分面搜索与网络拓扑可视化相结合，克服了传统关键词搜索和元数据过滤的局限性，尤其是在揭示资源间隐藏联系方面。其引入的“链式视图”也为用户提供了更灵活的数据探索方式，提升了数据集发现的效率和深度。用户研究证实了其方法的有效性和用户对可视化探索的偏好，但研究规模较小，未来可进行更大规模的验证。

<details>
  <summary>Details</summary>

**Motivation:** 公共文本资源（如词典和特定领域语料库）的快速增长，使得有效识别相关资源面临挑战。现有存储库通常缺乏高级搜索和探索功能，大多数搜索方法依赖于关键词查询和元数据过滤，这需要先验知识并且无法揭示资源之间的联系。

**Method:** 本文提出了DataLens，一个基于网络的平台，它结合了分面搜索和高级可视化技术来增强资源发现。DataLens提供基于网络的的可视化，其网络结构可以根据特定的分析任务进行调整。它还支持链式视图方法，使用户能够从多个角度探索数据。

**Result:** 一项包含六名数据从业者的形成性用户研究表明，用户高度重视可视化工具——特别是基于网络的探索——并提供了有助于完善DataLens方法以更好地支持数据集搜索的见解。

**Conclusion:** 用户高度重视可视化工具，特别是基于网络的探索，DataLens通过结合分面搜索和网络可视化有效提升了数据集发现体验。

> **ai_Abstract:** 针对现有数据集发现方法缺乏关联性和高级探索功能的问题，本文提出了DataLens，一个结合分面搜索和网络可视化技术的web平台。DataLens通过提供可适应的网络结构和链式视图，使用户能够从多角度探索数据并发现资源间联系。一项用户研究表明，用户高度认可其可视化探索功能，尤其是在网络拓扑方面的应用。

> **摘要翻译:** 公共文本资源（如词典和特定领域语料库）的快速增长，使得有效识别相关资源面临挑战。尽管存储库正在出现，但它们通常缺乏高级搜索和探索功能。大多数搜索方法依赖于关键词查询和元数据过滤，这需要先验知识并且无法揭示资源之间的联系。为了解决这个问题，我们提出了DataLens，一个结合分面搜索和高级可视化技术以增强资源发现的基于网络的平台。DataLens提供基于网络的的可视化，其网络结构可以根据特定的分析任务进行调整。它还支持链式视图方法，使用户能够从多个角度探索数据。一项包含六名数据从业者的形成性用户研究表明，用户高度重视可视化工具——特别是基于网络的探索——并提供了有助于完善我们方法以更好地支持数据集搜索的见解。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [281] [Jelly: a Fast and Convenient RDF Serialization Format](https://arxiv.org/abs/2506.11298)
> *Jelly：一种快速便捷的RDF序列化格式*

*Piotr Sowinski, Karolina Bogacka, Anastasiya Danilenka, Nikita Kozlov* | **Category: cs.DB, cs.NI** | **Updated: 2025-07-31**

**Keywords:** RDF序列化, Jelly, 语义网, 二进制格式, Protocol Buffers

**Comment:** Developers Workshop, co-located with SEMANTiCS'25: International
  Conference on Semantic Systems, September 3-5, 2025, Vienna, Austria

> **TL;DR:** Jelly是一种新的二进制RDF序列化格式，旨在解决现有格式在性能、压缩比和流支持方面的不足，提供快速、高效且易于集成的解决方案。

**AI_Comments:** Jelly的创新之处在于其作为二进制RDF序列化格式，同时解决了现有格式的性能、压缩和流处理痛点。其基于Protocol Buffers的设计和开源实现使其具有良好的集成性和可重用性，对于提升语义网应用的效率和便捷性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RDF序列化格式（如Turtle、N-Quads和JSON-LD）在知识图谱和语义网应用中广泛使用，但它们在性能、压缩比和对RDF流的本地支持方面存在局限性。

**Method:** 本文引入了Jelly，一种用于RDF数据的快速便捷的二进制序列化格式，支持批处理和流式使用场景。Jelly旨在最大化序列化吞吐量，通过轻量级流式压缩减小文件大小，并最小化计算资源使用。它基于Protocol Buffers构建，易于与现代编程语言和RDF库集成。Jelly具有开放协议规范、Java和Python的开源实现以及多功能命令行工具。

**Result:** Jelly能够最大化序列化吞吐量，通过轻量级流式压缩减小文件大小，并最小化计算资源使用。它易于集成，并通过具体的用例展示了其效益。

**Conclusion:** Jelly将实用可用性与最先进的效率相结合，是对语义网工具栈的重要贡献。

> **ai_Abstract:** 本文提出了一种名为Jelly的新型二进制RDF序列化格式，旨在克服现有格式（如Turtle、N-Quads、JSON-LD）在性能、压缩比和流支持方面的不足。Jelly基于Protocol Buffers构建，专注于提高序列化吞吐量、通过轻量级压缩减小文件大小以及降低资源消耗。它提供了开放的协议规范、多种语言的开源实现和命令行工具，易于集成和使用，被视为对语义网工具栈的重要贡献。

> **摘要翻译:** 现有的RDF序列化格式，如Turtle、N-Quads和JSON-LD，在知识图谱和语义网应用中被广泛用于通信和存储。然而，它们在性能、压缩比和缺乏对RDF流的本地支持方面存在局限性。为了解决这些缺点，我们引入了Jelly，一种快速便捷的RDF数据二进制序列化格式，支持批处理和流式用例。Jelly旨在最大化序列化吞吐量，通过轻量级流式压缩减小文件大小，并最小化计算资源使用。Jelly基于Protocol Buffers构建，易于与现代编程语言和RDF库集成。为了最大化可重用性，Jelly拥有开放的协议规范、与流行RDF库集成的Java和Python开源实现以及一个多功能的命令行工具。为了说明其用途，我们概述了Jelly可以提供实际效益的具体用例。我们认为，Jelly通过将实用可用性与最先进的效率相结合，是对语义网工具栈的重要贡献。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [323] [Towards Serverless Processing of Spatiotemporal Big Data Queries](https://arxiv.org/abs/2507.06005)
> *迈向时空大数据查询的无服务器处理*

*Diana Baumann, Tim C. Rese, David Bermbach* | **Category: cs.DB, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 时空大数据, 无服务器, FaaS, 查询处理, 可伸缩性

**Comment:** Accepted for publication in 13th IEEE International Conference on
  Cloud Engineering (IC2E 2025)

> **TL;DR:** 本文提出了一种利用无服务器FaaS平台对时空大数据查询进行并行处理的方法，以解决现有系统在可伸缩性方面的局限性。

**AI_Comments:** 这篇论文提出了一种新颖的方法，将无服务器计算（FaaS）应用于时空大数据查询处理，解决了传统关系数据库系统在可伸缩性方面的固有局限性。其创新点在于利用FaaS的按需伸缩特性实现查询的细粒度并行化，对于未来大数据处理架构具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 时空数据量持续增长，许多应用领域依赖于对这些数据的快速分析。然而，现有的基于关系数据库系统的时空数据处理系统（如PostGIS或MobilityDB）在处理大规模时空数据时，即使许多查询类型易于并行化，其可伸缩性仍然有限。

**Method:** 本文提出了一种原生的无服务器数据处理方法，用于时空数据。该方法将查询分解为小的子查询，然后利用函数即服务（FaaS）平台的近乎即时伸缩性来并行执行这些子查询。

**Result:** 通过所提出的方法，部分解决了大规模时空数据处理的可伸缩性需求。

**Conclusion:** 利用无服务器FaaS平台并行处理分解后的时空数据查询，可以有效提升大规模时空数据处理的可伸缩性。

> **ai_Abstract:** 本文针对现有基于关系数据库的时空数据处理系统在处理大规模数据时的可伸缩性限制，提出了一种创新的无服务器数据处理方法。该方法将复杂的时空查询分解为多个小型子查询，并利用函数即服务（FaaS）平台的即时伸缩能力进行并行执行，从而有效提升了大数据量下时空数据处理的可伸缩性。

> **摘要翻译:** 时空数据正由各种数据源以持续增长的体量产生，并且各种应用领域都依赖于对这些数据的快速分析。现有系统，如PostGIS或MobilityDB，通常建立在关系数据库系统之上，因此继承了其横向扩展特性。结果是，即使许多查询类型可以很容易地并行化，大型时空数据场景仍然支持有限。在本文中，我们提出了我们对时空数据的原生无服务器数据处理方法的愿景：我们将查询分解为小的子查询，然后利用函数即服务（Function-as-a-Service）平台的近乎即时伸缩性来并行执行它们。通过这种方式，我们部分解决了大型时空数据处理的可伸缩性需求。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [365] [Is SHACL Suitable for Data Quality Assessment?](https://arxiv.org/abs/2507.22305)
> *SHACL 适用于数据质量评估吗？*

*Carolina Cortés, Lisa Ehrlinger, Lorena Etcheverry, Felix Naumann* | **Category: cs.DB** | **Updated: 2025-07-31**

**Keywords:** 知识图谱, 数据质量, SHACL, 约束语言, 数据质量评估

**Comment:** 43 pages

> **TL;DR:** 本文探讨了SHACL在知识图谱数据质量评估方面的适用性，通过为69个数据质量指标定义SHACL形状并实现原型进行验证。

**AI_Comments:** 这项研究通过系统地将数据质量指标映射到SHACL形状，为知识图谱的数据质量评估提供了一个具体且可重复的方法，填补了现有SHACL应用在全面性方面的空白。其创新点在于将理论上的数据质量维度转化为可操作的SHACL约束，并提供了原型实现，对于提高知识图谱的实用性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 知识图谱因缺乏强制模式而存在潜在的数据质量问题，而现有评估方法（包括SHACL）未能全面覆盖所有数据质量维度。

**Method:** 作者为Zaveri等人提出的69个数据质量指标定义了SHACL形状，并实现了一个原型，该原型能够自动实例化这些形状并根据验证结果计算相应的数据质量度量。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了形状约束语言（SHACL）在知识图谱数据质量评估中的适用性，旨在解决现有方法未能全面覆盖所有数据质量维度的问题。研究者为69个数据质量指标定义了SHACL形状，并开发了一个原型系统，通过验证结果自动计算数据质量度量。

> **摘要翻译:** 知识图谱已被企业（如谷歌知识图谱）和开放平台（如维基数据）广泛采用，用于表示领域知识和支持人工智能应用。它们将现实世界信息建模为节点和边。为了实现灵活性，知识图谱通常缺乏强制模式（即本体），这导致潜在的数据质量问题，例如语义重叠的节点。然而，确保其质量至关重要，因为数据中的问题可能会影响依赖它们的应用。为了评估知识图谱的质量，现有工作要么提出包含各种数据质量维度但缺乏具体实现的高级框架，要么定义使用临时SPARQL查询测量数据质量的工具，要么提倡使用约束语言（如形状约束语言SHACL）来评估和改进图的质量。尽管后一种方法声称解决了数据质量评估问题，但它们都没有全面尝试覆盖所有数据质量维度。在本文中，我们通过调查SHACL在知识图谱中评估数据质量的程度来探索这一空白。具体而言，我们为Zaveri等人[1]提出的69个数据质量指标定义了SHACL形状，并实现了一个原型，该原型能够自动实例化这些形状并根据其验证结果计算相应的数据质量度量。所有资源均已提供，以确保可重复性。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [419] [SAM: A Stability-Aware Cache Manager for Multi-Tenant Embedded Databases](https://arxiv.org/abs/2507.22701)
> *SAM：一种多租户嵌入式数据库的稳定性感知缓存管理器*

*Haoran Zhang, Decheng Zuo, Yu Yan, Zhiyu Liang, Hongzhi Wang* | **Category: cs.DB, H.2.4; H.2.7** | **Updated: 2025-07-31**

**Keywords:** 缓存管理, 稳定性感知, 多租户, 嵌入式数据库, 自主管理

**Comment:** 17 pages, 10 figures. An extended version of a paper under review at
  the VLDB 2026 conference

> **TL;DR:** SAM是一种稳定性感知的缓存管理器，通过平衡历史效率和边际增益，在多租户嵌入式数据库中实现持续高性能和鲁棒性。

**AI_Comments:** 该论文的创新点在于将“决策稳定性”作为核心设计原则引入缓存管理，并通过H-factor和V-factor的独特结合来解决经典的开发-探索困境。这使得SAM在多租户、资源受限的边缘环境中，能提供比传统方案更稳定和鲁棒的性能，尤其在应对复杂工作负载变化和缓存污染方面表现出色。其在可扩展性和服务质量方面的表现也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的边缘节点上，多数据库实例的共存导致严重的缓存争用，传统方案在动态工作负载下效率低下且不稳定。

**Method:** 提出SAM（稳定性感知管理器），一个自主缓存管理器，将决策稳定性作为首要设计原则。其核心控制策略是AURA（自主效用平衡资源分配器），通过结合H-factor（历史效率）和V-factor（估计边际增益）来解决开发-探索困境，实现实用合成和自适应控制。

**Result:** SAM在14个不同基线测试中表现优越，实现了顶级的吞吐量，对复杂工作负载变化和缓存污染等对抗性工作负载具有独特的弹性。决策延迟具有高度可扩展性，系统扩展到120个数据库时仍保持几乎不变。最重要的是，SAM实现了卓越的决策稳定性，保持一致的优化方向，避免性能振荡，并确保可预测的服务质量。

**Conclusion:** 原则性的、稳定性感知的设计对于真实世界、大规模系统中持续实现高性能至关重要。

> **ai_Abstract:** SAM是一种为多租户嵌入式数据库设计的稳定性感知缓存管理器。它通过AURA策略，结合历史效率和边际增益，解决了缓存争用问题，并在动态和对抗性工作负载下实现了持续高吞吐量、高弹性、低决策延迟和卓越的决策稳定性，证明了稳定性感知设计对大规模系统性能的重要性。

> **摘要翻译:** 在资源受限的边缘节点上，多个数据库实例的共存会产生显著的缓存争用，导致传统方案在动态工作负载下效率低下且不稳定。为了解决这个问题，我们提出了SAM（稳定性感知管理器），一个自主缓存管理器，它将决策稳定性确立为一流的设计原则。它通过其核心控制策略AURA（自主效用平衡资源分配器）实现这一点，AURA通过综合两个正交因素：代表已验证历史效率（开发）的H-factor和代表估计边际增益（探索）的V-factor，解决了经典的开发-探索困境。通过这种实用的综合和自适应控制，SAM在波动条件下实现了持续的高性能，并具有战略稳定性和鲁棒性。
针对14个不同基线的广泛实验证明了SAM的优越性。它实现了顶级吞吐量，同时对复杂的工作负载变化和缓存污染等对抗性工作负载具有独特的弹性。此外，其决策延迟具有高度可扩展性，随着系统扩展到120个数据库，其延迟几乎保持不变。至关重要的是，SAM实现了卓越的决策稳定性——尽管存在噪声，仍保持一致的优化方向，避免了性能振荡，同时确保了可预测的服务质量。这些结果证明，原则性的、稳定性感知的设计对于真实世界、大规模系统中持续实现高性能至关重要。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [246] [SGEMM-cube: Emulating FP32 GEMM on Ascend NPUs Using FP16 Cube Units with Precision Recovery](https://arxiv.org/abs/2507.23387)
> *SGEMM-cube: 在昇腾NPU上使用FP16 Cube单元模拟FP32 GEMM并恢复精度*

*Weicheng Xue, Baisong Xu, Kai Yang, Yongxiang Liu, Dengdeng Fan, Pengxiang Xu, Yonghong Tian* | **Category: cs.DC** | **Updated: 2025-08-01**

**Keywords:** FP32 GEMM, FP16 Cube, 精度恢复, 昇腾NPU, 数值稳定性

**Comment:** 

> **TL;DR:** SGEMM-cube提出了一种在仅支持FP16的AI加速器上高效模拟FP32 GEMM的方法，通过分解FP32操作数、误差补偿和优化计算顺序，实现了接近FP32的精度和性能。

**AI_Comments:** 这项工作的创新之处在于，它通过巧妙地利用现有FP16硬件来模拟更高精度的FP32计算，有效地解决了AI加速器在精度和性能之间的权衡问题。其分解和误差补偿策略，以及对计算顺序和缓存优化的考虑，使其在不牺牲过多性能的情况下，在缺乏原生FP32支持的硬件上实现了高精度计算，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 低精度矩阵引擎（如FP16 cube）虽然吞吐量高，但缺乏对全精度计算的支持，这限制了它们在需要FP32精度的应用中的使用。

**Method:** SGEMM-cube通过以下方法实现：1) 将每个FP32操作数分解为两个FP16值；2) 通过可调缩放策略补偿数值误差，并进行详细的数值误差分析（包括下溢条件和精度损失）以指导参数选择，从而保留高达22位的尾数精度；3) 研究计算顺序对精度的影响，并引入逐项累加方案，在低指数范围内改善数值稳定性；4) 引入缓存感知阻塞策略和双缓冲流水线，以重叠内存传输和计算。

**Result:** SGEMM-cube在缺乏原生FP32支持的昇腾910A NPU上实现了理论FP32等效峰值性能的77%。数值实验证实，该方法不仅恢复了原生FP32 GEMM的精度，而且在某些条件下，由于其结构化和误差感知的计算顺序，表现出卓越的数值稳定性。

**Conclusion:** SGEMM-cube成功地在仅支持FP16的AI加速器上模拟了FP32 GEMM，实现了高精度和高效率，并通过结构化和误差感知的计算顺序提高了数值稳定性。

> **ai_Abstract:** SGEMM-cube提出了一种在仅支持FP16计算单元的AI加速器（如昇腾NPU）上高效模拟FP32通用矩阵乘法（GEMM）的方法。该方法通过将FP32操作数分解为两个FP16值，并利用可调缩放策略进行误差补偿，同时通过详细的误差分析和优化的计算顺序（如逐项累加）来保持或提高精度。此外，通过缓存感知阻塞和双缓冲流水线优化了性能。实验表明，SGEMM-cube在昇腾910A NPU上达到了理论FP32峰值性能的77%，并展现出与原生FP32 GEMM相当的精度和更优的数值稳定性。

> **摘要翻译:** 低精度矩阵引擎，如FP16 cube，提供了高吞吐量，但缺乏对全精度计算的支持。在这项工作中，我们提出了SGEMM-cube，一种高性能算法，用于在代表性AI加速器上仅使用FP16计算单元模拟FP32通用矩阵乘法（GEMM）。该方法将每个FP32操作数分解为两个FP16值，并通过可调缩放策略补偿数值误差。对数值误差（包括下溢条件和精度损失）的详细分析指导了缩放参数的选择，以保留高达22位的尾数精度。我们进一步研究了计算顺序对精度的影响，并证明逐项累加方案在低指数范围内比传统FP32 GEMM提高了数值稳定性。最后，引入了缓存感知阻塞策略和双缓冲流水线，以重叠内存传输与计算，使SGEMM-cube在缺乏原生FP32支持的昇腾910A NPU上达到理论FP32等效峰值性能的77%。广泛的数值实验证实，我们的方法不仅恢复了原生FP32 GEMM的精度，而且在某些条件下，由于其结构化和误差感知的计算顺序，表现出卓越的数值稳定性。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [288] [Towards a Testbed for Scalable FaaS Platforms](https://arxiv.org/abs/2507.23431)
> *迈向可扩展FaaS平台的测试平台*

*Trever Schirmer, David Bermbach* | **Category: cs.DC** | **Updated: 2025-07-31**

**Keywords:** FaaS, 可扩展性, 测试平台, 云平台, 架构

**Comment:** Accepted for Publication at the 13th IEEE International Conference on
  Cloud Engineering (IC2E 2025)

> **TL;DR:** 本文提出了一个用于评估可扩展函数即服务（FaaS）平台架构的测试平台。

**AI_Comments:** 本文的创新点在于提供了一个专用且可适应的测试平台，用于FaaS可扩展性研究，这对于优化云原生应用程序至关重要。其重要性在于促进对FaaS架构的系统评估。

<details>
  <summary>Details</summary>

**Motivation:** 为了更好地理解云平台架构如何影响其函数即服务（FaaS）产品的性能，尤其是在可扩展性方面。

**Method:** 本文提出了一个以研究为重点的测试平台，该平台可以进行调整，以快速评估不同架构和技术对可扩展性FaaS平台特性产生的影响。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一个面向研究的测试平台，旨在评估不同架构和技术对可扩展函数即服务（FaaS）平台性能特征的影响。其目的是增进对FaaS平台架构如何影响其性能的理解。

> **摘要翻译:** 大多数云平台都提供函数即服务（FaaS），使用户能够轻松编写高度可扩展的应用程序。为了更好地理解平台架构如何影响其性能，我们提出了一个以研究为重点的测试平台，该平台可以进行调整，以快速评估不同架构和技术对可扩展性FaaS平台特性产生的影响。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [330] [Threshold-Driven Streaming Graph: Expansion and Rumor Spreading](https://arxiv.org/abs/2507.23533)
> *阈值驱动的流图：扩展与谣言传播*

*Flora Angileri, Andrea Clementi, Emanuele Natale, Michele Salvi, Isabella Ziccardi* | **Category: cs.DC, math.PR** | **Updated: 2025-07-31**

**Keywords:** 动态图, 流图, 扩展图, 谣言传播, RAES算法

**Comment:** 

> **TL;DR:** 本文研究了在动态图模型下，基于阈值的随机分布式算法RAES的行为，并证明了其在每个时间步都具有良好的扩展性，同时为谣言传播协议提供了对数上界。

**AI_Comments:** 这项工作的重要创新在于将现有算法RAES的分析从静态图扩展到更具挑战性和实际意义的动态图模型，特别是考虑了节点流失这一关键特性。其结果不仅理论上解决了RAES在动态环境下的开放问题，也为理解和设计在动态网络中高效的分布式算法（如谣言传播）提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 先前的RAES算法是在静态图模型下分析的，而在动态模型下的分析是一个重要的开放问题。本文旨在解决这一问题，研究RAES在流式节点流失过程（滑动窗口模型）下的行为。

**Method:** 本文在流式节点流失过程（滑动窗口模型）诱导的动态图模型下，研究了RAES算法的行为。该模型中，每个离散回合都有新节点加入和最旧节点离开，从而产生一个有界度的动态图序列。

**Result:** 结果表明，动态图序列中的每个快照$G_t$都以高概率具有良好的扩展性。此外，利用这一特性，本文为在动态图$\\mathcal{G}$上的PUSH和PULL谣言传播协议的完成时间建立了对数上界。

**Conclusion:** 本文成功地将RAES算法的分析扩展到动态图模型，证明了其在节点流失环境下的扩展性保持良好，并进一步揭示了其在谣言传播应用中的效率。

> **ai_Abstract:** 本文研究了随机分布式算法RAES在流式节点流失（滑动窗口）动态图模型下的行为。该模型模拟了点对点网络中的节点流失和连接阈值。研究证明，在该动态模型下，图的每个快照仍能以高概率保持良好的扩展性，并基于此结果，为PUSH和PULL谣言传播协议在动态图上的完成时间提供了对数上界。

> **摘要翻译:** 在[Becchetti et al., SODA 2020]中引入了一种名为RAES的随机分布式算法，用于从一个密集的$n$顶点扩展图$G = (V, E)$中提取一个有界度扩展图。该算法依赖于一个简单的基于阈值的过程。[Becchetti et al., SODA 2020]中的一个关键假设是输入图$G$是静态的——即，其顶点集$V$和边集$E$在整个过程中保持不变——而RAES在动态模型中的分析则被留作一个主要的开放问题。
在这项工作中，我们研究了RAES在由流式节点流失过程（也称为滑动窗口模型）引起的动态图模型下的行为，在该模型中，在每个离散回合，一个新节点加入图，最老的节点离开。这个过程产生了一个有界度的动态图$\mathcal{G} =\{ G_t = (V_t, E_t) : t \in \mathbb{N}\}$，它捕捉了点对点网络的基本特征——特别是节点流失和每个节点可以管理的连接数阈值。我们证明了动态图序列中的每个快照$G_t$都以高概率具有良好的扩展性。此外，我们利用这一特性，为在动态图$\mathcal{G}$上的著名PUSH和PULL谣言传播协议的完成时间建立了对数上界。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [372] [The ArborX library: version 2.0](https://arxiv.org/abs/2507.23700)
> *ArborX 库：2.0 版本*

*Andrey Prokopenko, Daniel Arndt, Damien Lebrun-Grandié, Bruno Turcksin* | **Category: cs.DC** | **Updated: 2025-07-31**

**Keywords:** ArborX, 几何搜索, Kokkos, 数据结构, 算法

**Comment:** 

> **TL;DR:** 本文概述了高性能可移植几何搜索库 ArborX 2.0 版本的主要更新和新特性。

**AI_Comments:** 该论文详细介绍了 ArborX 库的重要更新，通过引入新接口、数据结构和算法，显著扩展了其功能和适用性，使其能支持更广泛的几何搜索问题。其基于 Kokkos 的性能可移植性是该库的一个关键优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了支持更广泛的用户问题，并提高库的可用性和功能，ArborX 库发布了 2.0 版本。

**Method:** ArborX 2.0 版本引入了新的库接口、新的搜索数据结构（包括暴力搜索和分布式搜索）、支持用户函数（回调）在结果上执行，并扩展了支持的算法集（如光线追踪和聚类）。

**Result:** ArborX 库 2.0 版本已发布，它是一个基于 Kokkos 的高性能可移植几何搜索库，包含上述新特性和改进。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了高性能可移植几何搜索库 ArborX 的 2.0 版本。新版本基于 Kokkos，引入了改进的接口、新的搜索数据结构（如暴力搜索和分布式搜索）、对用户回调函数的支持，并扩展了算法集，包括光线追踪和聚类，旨在解决更广泛的用户问题。

> **摘要翻译:** 本文概述了 ArborX 库的 2.0 版本，这是一个基于 Kokkos 的高性能可移植几何搜索库。我们描述了 ArborX 2.0 中的主要变化，包括支持更广泛用户问题的新库接口、新的搜索数据结构（暴力搜索、分布式）、支持对结果执行用户函数（回调），以及扩展的支持算法集（光线追踪、聚类）。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [456] [Minos: Exploiting Cloud Performance Variation with Function-as-a-Service Instance Selection](https://arxiv.org/abs/2505.12928)
> *Minos：利用函数即服务实例选择来利用云性能变化*

*Trever Schirmer, Valentin Carl, Nils Höller, Tobias Pfandzelter, David Bermbach* | **Category: cs.DC** | **Updated: 2025-07-31**

**Keywords:** FaaS, 性能优化, 云计算, 实例选择, Minos

**Comment:** Accepted for Publication at the 13th IEEE International Conference on
  Cloud Engineering (IC2E 2025)

> **TL;DR:** Minos是一个系统，通过主动终止慢速FaaS实例并重用快速实例来利用云性能差异，从而为用户提供更快的执行速度和更低的成本。

**AI_Comments:** Minos的创新之处在于其“浪费”平台资源以优化用户体验的逆向思维。通过主动淘汰低性能实例并培养高性能实例池，它有效解决了FaaS环境中常见的性能不确定性问题。这种方法对于追求成本效益和高性能的云用户具有重要意义，特别是在批处理和机器学习等需要稳定性能的场景下。然而，这种策略的有效性高度依赖于云平台实际的资源调度和计费模型，并且可能在某些情况下导致平台资源利用率的下降。

<details>
  <summary>Details</summary>

**Motivation:** FaaS实例在共享基础设施上运行，导致性能波动。慢速实例不仅延长完成时间，还因按使用量计费模式而增加成本。因此，需要一种方法来应对这种性能差异。

**Method:** Minos通过有意终止慢速FaaS实例来利用性能差异。它在函数执行前运行一个简短的基准测试，如果基准测试未通过，则请求重新排队，实例自行崩溃，以便平台分配给另一个可能更快的实例。快速实例不会被终止，以便后续调用可以重用。

**Result:** 实验表明，在数据处理工作流的资源密集部分，Minos可实现高达13%的加速，整体性能提高高达4%，成本降低4%。对于更长更复杂的工作流，由于快速实例池的重复使用，可以节省更多。

**Conclusion:** 对于表现出性能差异的FaaS平台，Minos使用户能够通过“浪费”平台资源来获得更好的性能并节省资金。

> **ai_Abstract:** Minos是一个旨在解决FaaS中实例性能波动的系统。它通过在执行前对函数实例进行基准测试来识别并终止慢速实例，同时保留快速实例以供重用。这种方法使得用户能够获得更快的执行速度和更低的成本，尤其是在数据处理和机器学习工作流中，实验显示整体性能提升高达4%，并相应地降低了成本。

> **摘要翻译:** 无服务器函数即服务（FaaS）是一种流行的云范式，可以快速且廉价地实现复杂的应用程序。由于云提供商启动以执行用户代码的函数实例在共享基础设施上运行，因此它们的性能可能会有所不同。从用户角度来看，较慢的实例不仅需要更长时间才能完成，而且由于FaaS服务的按使用量付费模式（执行持续时间以微秒精度计费），还会增加成本。在本文中，我们提出了Minos，一个利用这种性能变化的系统，通过有意终止慢速实例。快速实例不会被终止，因此可以重复用于后续调用。其中一个用例是数据处理和机器学习工作流，它们通常在第一步下载文件，在此期间Minos可以运行一个简短的基准测试。只有当基准测试通过时，函数的主要部分才会被实际执行。否则，请求会被重新排队，实例自行崩溃，以便平台必须将请求分配给另一个（可能更快）的实例。在我们的实验中，这使得数据处理工作流的资源密集部分的速度提高了13%，导致整体性能提高4%（因此价格也便宜4%）。更长更复杂的工作流会带来更大的节省，因为快速实例池被更频繁地重用。对于表现出这种行为的平台，用户通过浪费更多的平台资源来获得更好的性能并节省资金。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [495] [GALE: Leveraging Heterogeneous Systems for Efficient Unstructured Mesh Data Analysis](https://arxiv.org/abs/2507.15230)
> *GALE：利用异构系统高效分析非结构化网格数据*

*Guoxi Liu, Thomas Randall, Rong Ge, Federico Iuricich* | **Category: cs.DC, cs.GR** | **Updated: 2025-07-30**

**Keywords:** 非结构化网格, 异构系统, GPU, 数据分析, 任务并行

**Comment:** Accepted at IEEE VIS 2025

> **TL;DR:** GALE提出了一种新颖的异构CPU-GPU任务并行方法，通过将网格连接性计算卸载到GPU，显著加速了非结构化网格数据分析，相较于现有方法实现了高达2.7倍的提速。

**AI_Comments:** 该论文的创新点在于提出了GALE，一个将非结构化网格数据分析中的计算密集型连接性构建任务卸载到GPU的异构任务并行数据结构。这种方法有效地解决了现有CPU-bound方法的资源竞争问题，显著提升了性能。其重要性在于为大规模非结构化网格的可视化和分析提供了更高效的解决方案，并且作为第一个开源的CUDA基实现，具有重要的实践价值和研究推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 非结构化网格因其不规则分布和复杂连接性给科学数据分析带来了挑战。连接性信息的计算和存储是可视化算法的主要瓶颈，影响时间和内存性能。现有任务并行数据结构虽然通过运行时预计算来隐藏计算成本，但它们受限于CPU，导致数据结构和分析算法竞争相同的计算资源，从而限制了潜在的加速。

**Method:** 本文提出了一种新颖的、针对异构CPU-GPU系统优化的任务并行方法GALE（GPU-Aided Localized data structurE）。该方法将网格连接性信息的计算卸载到GPU线程，使CPU线程能够专注于执行可视化算法。GALE是第一个专为异构任务并行设计的开源CUDA基数据结构。

**Result:** 在两颗20核CPU和一块NVIDIA V100 GPU上的实验表明，GALE比最先进的局部数据结构实现了高达2.7倍的加速，同时保持了内存效率。

**Conclusion:** GALE通过有效利用异构计算资源（特别是将连接性计算卸载到GPU），成功克服了现有非结构化网格数据分析方法中CPU资源竞争的限制，显著提高了分析性能。

> **ai_Abstract:** 本文针对非结构化网格数据分析中连接性计算的性能瓶颈，提出了一种名为GALE的新型任务并行数据结构。现有方法因CPU资源竞争而受限，GALE通过将网格连接性计算卸载到GPU，使CPU专注于可视化算法执行，从而充分利用异构CPU-GPU系统的优势。作为首个开源CUDA基异构任务并行数据结构，GALE在实验中展示了比现有技术高达2.7倍的加速，并保持了内存效率。

> **摘要翻译:** 非结构化网格因其不规则分布和复杂连接性给科学数据分析带来了挑战。连接性信息的计算和存储是可视化算法的主要瓶颈，影响时间和内存性能。最近的任务并行数据结构通过在分析算法执行时运行时预计算连接性信息来解决这个问题，有效地隐藏了计算成本并提高了性能。然而，现有方法受限于CPU，迫使数据结构和分析算法竞争相同的计算资源，从而限制了潜在的加速。为了克服这一限制，我们引入了一种新颖的、针对异构CPU-GPU系统优化的任务并行方法。具体来说，我们将网格连接性信息的计算卸载到GPU线程，使CPU线程能够专注于执行可视化算法。遵循这一范式，我们提出了GALE（GPU辅助局部数据结构），这是第一个专为异构任务并行设计的开源CUDA基数据结构。在两颗20核CPU和一块NVIDIA V100 GPU上的实验表明，GALE比最先进的局部数据结构实现了高达2.7倍的加速，同时保持了内存效率。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [379] [AI-Reporter: A Path to a New Genre of Scientific Communication](https://arxiv.org/abs/2507.05903)
> *AI-Reporter：通往科学交流新体裁的道路*

*Gerd Graßhoff* | **Category: cs.DL, cs.CL** | **Updated: 2025-07-31**

**Keywords:** AI-Reporter, 科学交流, 出版实践, 大型语言模型, 学术演示

**Comment:** 

> **TL;DR:** AI-Reporter系统能在几分钟内将学术演示文稿转化为可发表的章节，弥合了临时演示和永久科学文档之间的鸿沟。

**AI_Comments:** 本文介绍的AI-Reporter工具极具创新性，解决了学术出版中的一个实际痛点：将演示文稿转化为正式出版物。其在不到三分钟内完成此操作的能力是简化科学交流的重要一步，有可能使研究更易于获取和持久。弥合“短暂演示与永久科学文档”之间鸿沟的概念突显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将学术演示文稿快速转化为可供发表的章节，以弥合短暂演示与永久科学文档之间的鸿沟。

**Method:** 该系统将学术演示文稿转化为可发表的章节。通过一个具体的案例研究，以Arno Simons关于大型语言模型的讲座为例，展示了这一转化过程。

**Result:** 该系统在不到三分钟的时间内将学术演示文稿转化为可供发表的章节。

**Conclusion:** AI-Reporter 代表着科学出版实践的范式转变，并弥合了短暂演示与永久科学文档之间的鸿沟。

> **ai_Abstract:** AI-Reporter是一个创新系统，旨在彻底改变科学出版方式。它能在三分钟内将学术演示文稿转化为可发表的章节，有效解决了临时性演示与永久性科学文档之间的衔接问题。通过一个具体的案例研究，该论文展示了其在提高科学交流效率方面的潜力。

> **摘要翻译:** AI-Reporter 代表着科学出版实践的范式转变。本文通过一个具体的案例研究，展示了我们的系统如何在不到三分钟的时间内将学术演示文稿转化为可供发表的章节。以 Arno Simons 在“大型语言模型在科学史、哲学和社会学中的应用”研讨会 (NEPI) 上关于大型语言模型的讲座为例，我们展示了技术创新如何弥合短暂演示与永久科学文档之间的鸿沟。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [544] [Computational Verification of the Buratti--Horak--Rosa Conjecture for Small Integers and Inductive Approaches](https://arxiv.org/abs/2507.00059)
> *Buratti--Horak--Rosa 猜想在小整数上的计算验证和归纳方法*

*Ranjan N Naik* | **Category: cs.DM, cs.DS, math.CO** | **Updated: 2025-07-31**

**Keywords:** Buratti--Horak--Rosa 猜想, 哈密顿路径, 计算验证, 归纳构造, 频率分区

**Comment:** This result supports the results by Mariusz Meszka for all primes up
  to 23 (included) with the aid of a computer. Additional results on Coprime
  BHR Conjecture verifications for p < 31 and Inductive Approaches are included
  in this revision

> **TL;DR:** 本文通过计算验证和归纳方法，为Buratti--Horak--Rosa (BHR) 猜想在小整数上的有效性提供了强有力的证据。

**AI_Comments:** 该论文通过大规模计算验证和引入归纳构造策略，显著推进了Buratti--Horak--Rosa (BHR) 猜想的研究。其创新之处在于结合了穷举搜索与启发式归纳方法，验证了猜想在较大范围内的有效性，并展示了计算方法的可伸缩性。计算结果的详细报告（如耗时和处理的集合数量）增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 验证 Buratti--Horak--Rosa (BHR) 猜想，该猜想提出在特定条件下，完全图 $K_p$ 中存在边长符合给定多重集 $L$ 的哈密顿路径。

**Method:** 作者开发了一个Python程序，通过系统生成边长频率分区（FPs）并采用递归回溯算法进行验证。此外，还引入并实现了两种构造性归纳策略：1) 增加现有边长的多重性；2) 添加新的边长，并辅以重用-插入启发式和回溯搜索。

**Result:** 成功验证了所有整数 $p < 32$ 的频率分区，并具体展示了 $p=31$ 和合数 $p=26$ 的结果。对于合数 $p=30$，验证耗时约11小时；对于 $p=16$，处理了167,898个有效多重集，耗时约20小时。归纳策略成功构建了高达 $p=40$ 的演化频率分区。

**Conclusion:** 本文通过大量的计算测试和性能指标，为Buratti--Horak--Rosa (BHR) 猜想在测试范围内的有效性提供了强有力的计算证据，并概述了该方法扩展到更高整数值的可伸缩性。

> **ai_Abstract:** 本文通过一个Python程序，对Buratti--Horak--Rosa (BHR) 猜想进行了广泛的计算验证，该猜想涉及完全图中具有特定边长多重集的哈密顿路径存在性。研究成功验证了 $p < 32$ 的所有频率分区，并扩展了先前的验证范围。此外，论文还提出了两种归纳策略，通过增加或添加边长来构造哈密顿路径，并在高达 $p=40$ 的情况下验证了这些策略的有效性，为BHR猜想提供了强有力的计算证据。

> **摘要翻译:** 本文提出了一种全面的计算方法，用于验证和归纳构造 Buratti--Horak--Rosa (BHR) 猜想的哈密顿路径。该猜想认为，对于任何不超过 $\lfloor p/2 \rfloor$ 的 $p-1$ 个正整数的多重集 $L$，当且仅当对于 $p$ 的每个除数 $d$， $L$ 中 $d$ 的倍数数量至多为 $p-d$ 时，在顶点集为 ${0, 1, \dots, p-1}$ 的完全图 $K_p$ 中存在一条哈密顿路径，其边长（在循环度量下）与 $L$ 匹配。
在 Mariusz Meszka 先前计算工作（验证了 $p=23$ 以下的所有素数）的基础上，我们的 Python 程序显著扩展了这一验证范围。我们通过系统生成边长频率分区（FPs）并采用递归回溯算法来解决问题。我们报告了对整数 $p < 32$ 的所有频率分区进行计算验证的成功结果，特别是展示了 $p=31$ 和合数 $p=26$ 的结果。对于合数 $p=30$，Python 代码在联想笔记本电脑上验证耗时约11小时。对于 $p=16$，处理了167,898个有效多重集，在 Google Colab Pro+ 上耗时约20小时。
此外，我们引入并实现了两种构造性归纳策略来构建哈密顿路径：(1) 增加现有边长的多重性，以及 (2) 添加新的边长。这些方法在重用-插入启发式和回溯搜索的支持下，展示了高达 $p=40$ 的演化频率分区的成功构建。通过这些经验测试和性能指标，我们在测试范围内为 BHR 猜想的有效性提供了强有力的计算证据，并概述了我们方法对更高整数值进行扩展的可伸缩性。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [502] [Nyldon Factorization of Thue-Morse Words and Fibonacci Words](https://arxiv.org/abs/2507.23659)
> *Nyldon分解在图厄-莫尔斯词和斐波那契词中的应用*

*Kaisei Kishi, Kazuki Kai, Yuto Nakashima, Shunsuke Inenaga, Hideo Bannai* | **Category: cs.DS, cs.DM** | **Updated: 2025-07-31**

**Keywords:** Nyldon分解, 图厄-莫尔斯词, 斐波那契词, 字符串分解, 组合词学

**Comment:** A full version of our conference paper accepted for SPIRE 2025

> **TL;DR:** 本文研究了有限和无限图厄-莫尔斯词以及有限斐波那契词的Nyldon分解特性。

**AI_Comments:** 本文对新近定义的Nyldon词和Nyldon分解进行了初步且深入的探索，将其应用于经典的斐波那契词和图厄-莫尔斯词，为组合词学领域引入了新的分析工具和视角。其创新性在于对这些新概念的首次系统性应用和特性表征。

<details>
  <summary>Details</summary>

**Motivation:** Nyldon词和Nyldon分解是受Lyndon词和Lyndon分解启发而新近定义的组合对象，本文旨在深入研究它们的特性。

**Method:** 本文通过表征有限斐波那契词和有限图厄-莫尔斯词的Nyldon分解，并证明了无限图厄-莫尔斯词存在一个Nyldon词的非递减乘积分解。

**Result:** 完全表征了有限斐波那契词和有限图厄-莫尔斯词的Nyldon分解。证明了无限图厄-莫尔斯词存在一个Nyldon词的非递减乘积分解。

**Conclusion:** 本文成功地表征了有限斐波那契词和有限图厄-莫尔斯词的Nyldon分解，并揭示了无限图厄-莫尔斯词的Nyldon分解特性。

> **ai_Abstract:** 本文深入探讨了Nyldon分解，这是一种受Lyndon分解启发而新近提出的字符串分解方法。研究主要集中在有限斐波那契词和有限图厄-莫尔斯词的Nyldon分解特性，并对其进行了全面表征。此外，研究还发现无限图厄-莫尔斯词可以表示为Nyldon词的非递减乘积分解。

> **摘要翻译:** Nyldon分解是一种字符串分解，它是Nyldon词的非递减乘积。Nyldon词和Nyldon分解是最近定义的组合对象，其灵感来源于著名的Lyndon词和Lyndon分解。在本文中，我们研究了几种词的Nyldon分解。首先，我们完全表征了（有限）斐波那契词和（有限）图厄-莫尔斯词的Nyldon分解。此外，我们证明了存在一个Nyldon词的非递减乘积，它是无限图厄-莫尔斯词的一个分解。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [537] [A Simple $(1-ε)$-Approximation Semi-Streaming Algorithm for Maximum (Weighted) Matching](https://arxiv.org/abs/2307.02968)
> *一种简单的 $(1-ε)$-近似半流算法，用于最大（加权）匹配*

*Sepehr Assadi* | **Category: cs.DS, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 半流算法, 加权匹配, 近似算法, 乘法权重更新, 原始-对偶分析

**Comment:** 25 pages. This is the TheoretiCS journal version

> **TL;DR:** 提出了一种简单的半流算法，在 $O(\log{\!(n)}/\epsilon)$ 次遍历中实现二分图和一般图加权匹配的 $(1-\epsilon)$-近似，性能与现有最佳算法相当但更简单。

**AI_Comments:** 这篇论文的创新点在于其算法的显著简单性，同时达到了与更复杂的最先进算法相同的性能。其自包含的原始-对偶分析方法也可能在其他领域具有独立的理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有“$\epsilon$-高效”算法在 $\epsilon$ 依赖性上表现良好，但可能在 $n$ 上有轻微依赖性且复杂。本文旨在提供一个更简单但性能相当的算法。

**Method:** 算法依赖于乘法权重更新方法的直接应用，并结合了独立的原始-对偶分析。对于加权匹配，还结合了匹配理论的标准工具。

**Result:** 提出了一个简单的半流算法，在 $O(\log{\!(n)}/\epsilon)$ 次遍历中实现二分图匹配的 $(1-\epsilon)$-近似，并扩展到一般图的加权匹配，同样在 $O(\log{\!(n)}/\epsilon)$ 次遍历中实现。性能与现有最先进的“$\epsilon$-高效”算法相当。

**Conclusion:** 该算法的简单性及其在不同图类型上的适用性，以及其独立的原始-对偶分析的潜在价值。

> **ai_Abstract:** 本文提出了一种新颖的半流算法，用于在 $O(\log{\!(n)}/\epsilon)$ 次遍历中实现最大（加权）匹配的 $(1-\epsilon)$-近似。该算法通过直接应用乘法权重更新方法并结合原始-对偶分析，在保持与现有最先进“$\epsilon$-高效”算法相当的性能的同时，显著简化了算法设计。它适用于二分图匹配和一般图的加权匹配。

> **摘要翻译:** 我们提出了一种简单的半流算法，用于在 $O(\log{\!(n)}/\epsilon)$ 次遍历中实现二分图匹配的 $(1-\epsilon)$-近似。这与最先进的“$\epsilon$-高效”算法的性能相匹配——这些算法对 $\epsilon$ 的依赖性要好得多，尽管对 $n$ 有轻微的依赖性——同时算法本身要简单得多。
该算法依赖于乘法权重更新方法的直接应用，并带有独立的原始-对偶分析，这可能具有独立的兴趣。为了展示这一点，我们使用相同的思想，结合匹配理论的标准工具，提出了一种同样简单的半流算法，用于在一般（不一定是二分图）图中实现加权匹配的 $(1-\epsilon)$-近似，同样在 $O(\log{\!(n)}/\epsilon)$ 次遍历中完成。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [551] [Competitive Bundle Trading](https://arxiv.org/abs/2507.23047)
> *竞争性捆绑交易*

*Yossi Azar, Niv Buchbinder, Roie Levin, Or Vardi* | **Category: cs.DS, cs.GT** | **Updated: 2025-07-30**

**Keywords:** 捆绑交易, 在线算法, 竞争比, 动态定价, 线性规划

**Comment:** 

> **TL;DR:** 本文研究零售商在在线环境下进行捆绑商品买卖以最大化利润的问题，并设计了一个具有对数竞争比的算法。

**AI_Comments:** 本文的创新之处在于解决了更普遍的在线捆绑交易问题，而非仅限于初始库存销售的特殊情况。其提出的基于指数权重更新的动态定价算法，并结合双重拟合分析，为在线资源管理和定价提供了理论基础和实用方法。对数竞争比的证明及其与最优离线解的接近性能，显示了该算法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 零售商在在线环境下进行捆绑商品的买卖，面临供应商和客户的在线到达以及库存限制，需要最大化利润。此前，捆绑交易算法仅限于销售初始库存的特殊情况，缺乏针对更一般在线交易问题的解决方案。

**Method:** 论文设计了一种算法，通过指数权重更新动态定价方案来实现。分析方法是双重拟合零售商利润与线性规划公式，该公式上限了最优离线利润。

**Result:** 该算法与最优离线解决方案相比，具有对数竞争比。作者还证明了（几乎）匹配的下限，并将结果扩展到激励兼容机制。

**Conclusion:** 论文成功为在线捆绑交易问题设计了一个高效的算法，解决了之前仅限于初始库存销售的局限性，并证明了其性能接近最优。

> **ai_Abstract:** 本文研究了一个普遍的在线捆绑交易问题，即零售商在面对供应商和客户在线到达、以及库存限制时，如何通过买卖捆绑商品来最大化利润。作者设计了一种基于指数权重更新动态定价方案的算法，并证明其相对于最优离线解具有对数竞争比。研究还包括了匹配的下限证明，并将结果推广到激励兼容机制，填补了此前仅有初始库存销售特殊情况算法的空白。

> **摘要翻译:** 零售商从供应商处批量采购商品，然后将这些商品批量销售给客户；她的目标是最大化利润，即销售商品所得收入减去采购商品的成本。本文从零售商的角度研究了这一普遍的交易问题，其中供应商和客户都是在线到达的。零售商对每种商品可以储存的数量有库存限制，她必须在每个供应商/客户到达时决定购买/销售哪些商品以最大化利润。
我们设计了一种算法，与最优离线解决方案相比，具有对数竞争比。我们通过指数权重更新动态定价方案实现这一目标，我们的分析通过线性规划公式将零售商的利润与最优离线利润进行双重拟合。我们证明了（几乎）匹配的下限，并且还将结果扩展到激励兼容机制。在我们工作之前，捆绑交易算法仅适用于销售初始库存的特殊情况。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [600] [Efficient algorithm for linear diophantine equations in two variables](https://arxiv.org/abs/2507.23216)
> *高效求解二元线性丢番图方程的算法*

*Mayank Deora, Pinakpani Pal* | **Category: cs.DS** | **Updated: 2025-07-31**

**Keywords:** 线性丢番图方程, 高效算法, DEA-OPTD, 递归调用, 性能比较

**Comment:** 

> **TL;DR:** 本文提出了一种用于求解二元线性丢番图方程的优化算法DEA-OPTD，该算法在理论和实践中均优于现有算法，如DEA-R和广泛使用的其他算法，在至少96%的输入情况下表现更佳。

**AI_Comments:** 本文的创新点在于对现有已较优的DEA-R算法进行了进一步的优化，通过改进递归调用中的计算序列，实现了更高的效率。其重要性在于为二元线性丢番图方程的求解提供了更高效的实际应用算法。尽管实验结果显示了显著的性能提升，但“特定输入设置”的描述可能暗示其普适性或在其他场景下的表现仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 二元线性丢番图方程在计算机科学和数学中有着广泛的应用。本文旨在优化现有的DEA-R算法，以进一步减少递归调用次数，从而提高求解效率。

**Method:** 本文提出了DEA-R算法的优化版本DEA-OPTD，通过在递归函数调用中引入更高效的计算序列。作者对DEA-OPTD算法和DEA-R算法的执行时间进行了理论比较，以确定DEA-OPTD优于DEA-R的可能界限。此外，他们还实现并比较了DEA-OPTD的迭代版本（DEA-OPTDI）与两种广泛使用的算法在特定输入设置下的性能。

**Result:** 理论比较表明DEA-OPTD在特定条件下优于DEA-R。在实验比较中，DEA-OPTDI算法在至少96%的输入情况下优于其他广泛使用的算法。

**Conclusion:** 本文提出的DEA-OPTD/DEA-OPTDI算法是一种高效的二元线性丢番图方程求解方法，在性能上显著优于现有算法。

> **ai_Abstract:** 本文针对二元线性丢番图方程的求解，提出了一种名为DEA-OPTD的优化算法。该算法是现有DEA-R算法的改进版本，旨在通过更高效的计算序列来减少递归调用次数。通过理论分析，论文探讨了DEA-OPTD相对于DEA-R的性能优势边界。实验方面，作者将DEA-OPTD的迭代版本（DEA-OPTDI）与两种广泛使用的算法进行了对比，结果显示DEA-OPTDI在至少96%的测试输入上表现出卓越的性能。

> **摘要翻译:** 解决二元线性丢番图方程在计算机科学和数学中都有应用。在本文中，我们重新审视了一种解决二元线性丢番图方程的算法，我们称之为DEA-R算法。与扩展欧几里得算法相比，DEA-R算法总是产生相等或更少的递归次数或递归调用。为了利用较少的递归调用次数，我们提出了DEA-R算法的优化版本DEA-OPTD。在DEA-OPTD的递归函数调用中，我们提出了一系列更高效的计算。我们对DEA-OPTD算法和DEA-R算法的执行时间进行了理论比较，以找出DEA-OPTD优于DEA-R时c值的任何可能界限。我们实现并比较了DEA-OPTD的迭代版本（DEA-OPTDI）与两种广泛使用的算法在特定输入设置下的性能。在这种比较中，我们发现我们的算法在至少96%的输入情况下优于其他算法。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [712] [Advancing Quantum State Preparation Using Decision Diagram with Local Invertible Maps](https://arxiv.org/abs/2507.17170)
> *使用局部可逆映射决策图改进量子态制备*

*Xin Hong, Aochu Dai, Chenjian Li, Sanjiang Li, Shenggang Ying, Mingsheng Ying* | **Category: cs.DS, quant-ph** | **Updated: 2025-07-31**

**Keywords:** 量子态制备, 决策图, 局部可逆映射, 量子电路复杂度, 可扩展性

**Comment:** arXiv admin note: text overlap with arXiv:2507.14496

> **TL;DR:** 本文提出了一种利用局部可逆映射张量决策图（LimTDDs）的有效量子态制备（QSP）算法家族，在运行时和门复杂度方面均优于现有方法并具有更好的可扩展性。

**AI_Comments:** 该论文的创新之处在于将局部可逆映射张量决策图（LimTDDs）应用于量子态制备，这种方法提供了一种高度紧凑的量子态表示，有效降低了量子电路复杂性。其重要性体现在显著优于现有方法的性能以及对大规模量子态的更好可扩展性，尤其是在最佳情况下表现出的指数级改进，这对于推进量子计算的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 量子态制备（QSP）是量子计算和量子信息处理中的一项基本任务，它对许多量子算法（包括量子机器学习中的算法）的执行至关重要。

**Method:** 提出了一系列高效的QSP算法，针对不同数量的可用辅助量子比特进行定制（从无辅助量子比特到单个辅助量子比特，再到足够多的辅助量子比特）。该方法利用局部可逆映射张量决策图（LimTDDs），这是一种结合张量网络和决策图以降低量子电路复杂度的紧凑量子态表示。

**Result:** 实验证明，该方法在运行时和门复杂度方面均显著优于现有方法，并对大规模量子态表现出更好的可扩展性。在最佳情况下，该方法显示出指数级的改进。

**Conclusion:** 该方法在量子态制备方面取得了显著进展，通过利用LimTDDs实现了更高的效率和和可扩展性，并超越了现有技术。

> **ai_Abstract:** 本文提出了一系列高效的量子态制备（QSP）算法，这些算法针对不同数量的辅助量子比特进行了优化。该方法利用局部可逆映射张量决策图（LimTDDs），这是一种结合张量网络和决策图的紧凑量子态表示，旨在降低量子电路复杂度。实验结果表明，该方法在运行时和门复杂度方面均显著优于现有方法，并对大规模量子态具有更好的可扩展性，在最佳情况下甚至实现了指数级改进。

> **摘要翻译:** 量子态制备（QSP）是量子计算和量子信息处理中的一项基本任务。它对于许多量子算法（包括量子机器学习中的算法）的执行至关重要。在本文中，我们提出了一系列高效的QSP算法，这些算法根据可用辅助量子比特的数量进行定制——从无辅助量子比特，到一个辅助量子比特，到足够多的辅助量子比特。我们的方法利用了局部可逆映射张量决策图（LimTDDs）的强大功能——这是一种高度紧凑的量子态表示，它结合了张量网络和决策图以降低量子电路复杂度。广泛的实验表明，我们的方法在运行时和门复杂度方面均显著优于现有方法，并对大规模量子态表现出更好的可扩展性。此外，在最佳情况下，我们的方法显示出指数级的改进。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [748] [Settling Weighted Token Swapping up to Algorithmic Barriers](https://arxiv.org/abs/2507.22450)
> *加权令牌交换的算法障碍界限*

*Nicole Wein, Guanyu Tony Zhang* | **Category: cs.DS** | **Updated: 2025-07-31**

**Keywords:** 加权令牌交换, 近似算法, 算法障碍, 图论, NP-难

**Comment:** 

> **TL;DR:** 本文首次为加权令牌交换问题提供了近似算法，并在通用图和树上取得了紧密的障碍结果，其近似比分别为 $2+2W/w$ 和 $1+W/w$。

**AI_Comments:** 这项工作填补了加权令牌交换问题中近似算法的空白，特别是对于正权重的情况。通过提供具体近似比和紧密障碍结果，该研究在理论上“解决了”该问题，直至其算法复杂性的内在限制。这是对图算法和组合优化领域的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的无权令牌交换问题已有研究成果，但对于加权令牌交换问题（特别是正权重情况），缺乏近似算法，且已知下界仅继承自无权版本。因此，需要为加权令牌交换问题开发近似算法并确定其算法障碍。

**Method:** 本文提供了针对加权令牌交换问题的近似算法，并为这些算法确定了紧密的障碍结果。

**Result:** 对于通用图，近似比为 $2+2W/w$；对于树，近似比为 $1+W/w$。其中 $w$ 和 $W$ 分别是最小和最大令牌权重。

**Conclusion:** 本文首次为加权令牌交换问题在通用图和树上提供了近似算法，并得到了紧密的算法障碍结果，从而在算法障碍层面解决了该问题。

> **ai_Abstract:** 本文研究了加权令牌交换问题，旨在寻找将令牌从初始配置交换到最终配置的最小成本序列。针对该问题，此前在正权重情况下缺乏近似算法。本文首次为通用图和树上的加权令牌交换问题提供了近似算法，并给出了紧密的算法障碍结果。具体而言，对于通用图，近似比为 $2+2W/w$，对于树，近似比为 $1+W/w$，其中 $w$ 和 $W$ 分别是最小和最大令牌权重。

> **摘要翻译:** 我们研究加权令牌交换问题，在该问题中，我们给定一个包含 $n$ 个顶点的图， $n$ 个加权令牌，每个顶点一个令牌的初始分配，以及每个顶点一个令牌的最终分配。目标是找到一个最小成本的相邻令牌交换序列，以从初始分配达到最终分配，其中成本是所有交换中两个被交换令牌的权重之和。无权令牌交换已被广泛研究：将其近似到优于 $14/13$ 的因子是 NP-难的，并且存在一个多项式时间 4-近似算法，以及一个紧密的“障碍”结果，表明局部最优算法无法实现优于 4 的比率。对于树，该问题仍然是精确解决的 NP-难问题，并且存在一个多项式时间 2-近似算法，以及一个紧密的障碍结果，表明 $\ell$-straying 算法无法实现优于 2 的比率。权重为 {0,1} 的加权令牌交换在近似方面要困难得多：即使对于任何常数 $\varepsilon>0$，将其近似到 $(1-\varepsilon) \cdot \ln n$ 的因子也是 NP-难的。限制为正权重时，没有已知的近似算法，并且唯一已知的下界是直接从无权版本继承的。我们为树和通用图上的加权令牌交换提供了第一个近似算法，以及紧密的障碍结果。令 $w$ 和 $W$ 分别为最小和最大令牌权重，我们的近似比对于通用图为 $2+2W/w$，对于树为 $1+W/w$。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [829] [Scalable contribution bounding to achieve privacy](https://arxiv.org/abs/2507.23432)
> *可扩展的贡献边界以实现隐私*

*Vincent Cohen-Addad, Alessandro Epasto, Jason Lee, Morteza Zadimoghaddam* | **Category: cs.DS, cs.CR, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 差分隐私, 贡献边界, 分布式算法, 超图, 可扩展性

**Comment:** 

> **TL;DR:** 该论文提出了一种新颖高效的分布式算法，通过对用户贡献进行边界限制，解决了在大规模数据集中实现用户级差分隐私的扩展性问题。

**AI_Comments:** 该论文的创新点在于提出了一个基于超图模型的分布式算法，有效解决了用户级差分隐私中“贡献边界”在处理大规模数据集时的可扩展性挑战。其并行处理和一致性协议设计，对于在实际大规模系统中部署隐私保护技术具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在现代数据集中，单条记录可能拥有多个所有者，要实现用户级差分隐私，需要限制每个用户的总贡献。现有用于此任务的序列算法计算量大，无法扩展到当前流行的大规模数据集，因此存在可扩展性瓶颈。

**Method:** 提出了一种新颖高效的分布式算法。该方法将复杂的拥有权结构建模为超图，其中用户是顶点，记录是超边。算法分轮进行，允许用户并行提议记录。只有当所有所有者一致同意时，记录才会被添加到最终数据集中，从而确保不违反用户预定义的贡献限制。

**Result:** 旨在最大化最终数据集的大小以获得高实用性，同时为在大型真实世界系统中实现用户级隐私提供实用、可扩展的解决方案。

**Conclusion:** 该论文提供了一种实用且可扩展的解决方案，用于在大规模真实世界系统中实现用户级隐私，有效解决了贡献边界的扩展性瓶颈。

> **ai_Abstract:** 为解决在大规模数据集中实现用户级差分隐私时，现有贡献边界算法扩展性差的问题，本文提出了一种新颖高效的分布式算法。该算法将数据拥有权结构建模为超图，允许多用户并行提议记录，并通过所有者一致同意机制确保用户贡献限制不被违反。此方法旨在最大化数据集实用性的同时，提供一个可扩展的解决方案，以在大规模真实系统中实现用户级隐私。

> **摘要翻译:** 在现代数据集中，单条记录可以有多个所有者，强制执行用户级差分隐私需要限制每个用户的总贡献。这种“贡献边界”成为一个重大的组合挑战。现有用于此任务的序列算法计算量大，无法扩展到当前流行的大规模数据集。为了解决这个可扩展性瓶颈，我们提出了一种新颖高效的分布式算法。我们的方法将复杂的拥有权结构建模为超图，其中用户是顶点，记录是超边。算法分轮进行，允许用户并行提议记录。只有当所有所有者一致同意时，记录才会被添加到最终数据集中，从而确保不违反用户预定义的贡献限制。该方法旨在最大化最终数据集的大小以获得高实用性，同时为在大型真实世界系统中实现用户级隐私提供实用、可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='cset'></a>
## cs.ET 

### [719] [WiRM: Wireless Respiration Monitoring Using Conjugate Multiple Channel State Information and Fast Iterative Filtering in Wi-Fi Systems](https://arxiv.org/abs/2507.23419)
> *WiRM: 基于共轭多通道状态信息和Wi-Fi系统中快速迭代滤波的无线呼吸监测*

*James Rhodes, Lawrence Ong, Duy T. Ngo* | **Category: cs.ET, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 无线呼吸监测, 信道状态信息, 呼吸频率, 呼吸波形, 抗噪声

**Comment:** 

> **TL;DR:** WiRM是一种两阶段无线呼吸监测方法，通过改进呼吸频率估计和呼吸波形提取，显著提升了准确性和抗噪性。

**AI_Comments:** WiRM的创新之处在于其两阶段方法，特别是结合共轭乘法和AMTC来提高呼吸频率估计的精度，并进一步利用此信息优化呼吸波形提取。其显著的性能提升（呼吸频率RMSE降低38%，波形相关性提升178.3%）证明了其重要性。此外，开发专用仿真工具来评估噪声鲁棒性，填补了现有研究的空白，增强了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于CSI的呼吸监测方法多关注呼吸频率或胸部运动波形，但存在精度和抗噪性问题，且难以在噪声环境下比较算法鲁棒性。

**Method:** WiRM是一个两阶段的非接触式呼吸监测方法。第一阶段：通过共轭乘法进行相位净化和自适应多轨迹雕刻（AMTC）来改进呼吸频率估计。第二阶段：利用改进的呼吸频率估计指导从CSI数据中分解和选择呼吸波形。此外，本文还开发了一个专用仿真工具包，用于评估呼吸监测解决方案在各种噪声条件（包括热噪声、乘性噪声和相位噪声）下的鲁棒性。

**Result:** WiRM在呼吸频率均方根误差（RMSE）方面平均降低了38%。在与真实呼吸波形的平均绝对相关性方面提高了178.3%。WiRM对常见噪声源（如热噪声、乘性噪声和相位噪声）表现出更好或相当的鲁棒性。

**Conclusion:** WiRM在无线呼吸监测方面取得了显著进展，特别是在提高呼吸频率和波形提取精度以及增强抗噪性方面表现出色，并通过专用仿真工具验证了其鲁棒性。

> **ai_Abstract:** 本文介绍了WiRM，一种基于Wi-Fi CSI的两阶段非接触式呼吸监测方法。它通过共轭乘法和AMTC改进了呼吸频率估计，实现了呼吸频率RMSE平均降低38%。在此基础上，WiRM进一步提高了呼吸波形提取的准确性，与真实值相关性提升178.3%。此外，研究还开发了专用仿真工具，验证了WiRM在各种噪声环境下的优越鲁棒性。

> **摘要翻译:** 使用信道状态信息（CSI）监测呼吸健康已显示出有前景的结果。许多现有方法仅关注监测呼吸频率，而另一些则关注监测患者呼吸时胸部的运动，这被称为呼吸波形。本文提出了WiRM，一种非接触式呼吸监测的两阶段方法。在第一阶段，WiRM通过使用共轭乘法进行相位净化和自适应多轨迹雕刻（AMTC）来跟踪呼吸频率随时间的变化，从而改进了现有的呼吸频率估计技术。与三种最先进的方法相比，WiRM在呼吸频率均方根误差（RMSE）方面平均降低了38%。在第二阶段，WiRM利用这种改进的呼吸频率估计来指导从CSI数据中分解和选择呼吸波形。值得注意的是，WiRM在与真实呼吸波形的平均绝对相关性方面提高了178.3%。在现有文献中，很难比较现有算法在嘈杂环境中的鲁棒性。在本文中，我们开发了一个专用仿真工具包，用于评估呼吸监测解决方案在各种噪声条件下的鲁棒性，包括热噪声、乘性噪声和相位噪声。我们的结果表明，WiRM对这些常见噪声源表现出更好或相当的弹性。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

### [754] [SOME: Symmetric One-Hot Matching Elector -- A Lightweight Microsecond Decoder for Quantum Error Correction](https://arxiv.org/abs/2507.23618)
> *SOME: 对称独热匹配选择器——一种用于量子纠错的轻量级微秒级解码器*

*Xinyi Guo, Geguang Miao, Shinichi Nishizawa, Hiromitsu Awano, Shinji Kimura, Takashi Sato* | **Category: cs.ET, quant-ph** | **Updated: 2025-07-31**

**Keywords:** 量子纠错, 解码器, QUBO, 对称独热匹配, 微秒级解码

**Comment:** 

> **TL;DR:** SOME是一种新的量子纠错解码器，它通过将解码任务重新表述为独热QUBO问题，实现了变量数量的大幅减少和微秒级的解码时间，同时保持了高物理错误率下的性能。

**AI_Comments:** SOME的创新点在于将QEC解码问题巧妙地转化为QUBO问题，并设计了高效的求解策略。其在变量数量、解码速度和错误率阈值上的显著提升，对于实现实用化的量子计算机具有重要意义。特别是微秒级的解码时间，是量子纠错领域的一个重大突破，有望加速量子计算的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统的量子纠错解码器（如MWPM和UF）要么拓扑复杂性高，要么解码时间长。基于伊辛模型的解码器虽然降低了拓扑复杂性，但解码时间长。因此，需要一种既能降低复杂性又能快速解码的新方法。

**Method:** 本文提出了对称独热匹配选择器（SOME）。它将量子纠错解码任务重新表述为二次无约束二元优化（QUBO）问题，命名为独热QUBO（OHQ）。OHQ中的每个变量表示给定的一对翻转综合征是否匹配，错误概率编码为交互系数。SOME通过构建最小化总权重的排列矩阵来解决OHQ，具体方法是：从最小权重的综合征对初始化每个候选矩阵，然后按权重升序迭代添加额外的对，最后选择总能量最低的排列矩阵。

**Result:** SOME在变量数量上实现了高达99.9倍的减少，并在单线程商用CPU上将解码时间从毫秒级缩短到微秒级。OHQ在高达10.5%的物理错误率下仍能保持性能，超过了MWPM已知的最高阈值。

**Conclusion:** SOME通过创新的QUBO表述和高效的求解策略，克服了现有量子纠错解码器的局限性，实现了高性能、低复杂度和超快速的解码。

> **ai_Abstract:** 本文提出了一种名为SOME（Symmetric One-Hot Matching Elector）的新型量子纠错解码器。SOME将解码任务转化为独热二次无约束二元优化（OHQ）问题，通过构建自逆排列矩阵来最小化总权重。与现有解码器相比，SOME显著降低了变量数量和拓扑复杂性，实现了微秒级的解码速度，并在高物理错误率下保持了优异性能，超越了传统方法。

> **摘要翻译:** 传统的量子纠错（QEC）解码器，如最小权重完美匹配（MWPM）和并查集（UF），分别提供了高阈值和快速解码，但两者都面临高拓扑复杂性。相比之下，基于伊辛模型的解码器降低了拓扑复杂性，但需要大量的解码时间。我们提出了一种新颖的解码器——对称独热匹配选择器（SOME），它将QEC解码任务重新表述为二次无约束二元优化（QUBO）问题——称为独热QUBO（OHQ）。QUBO中的每个变量表示给定的一对翻转综合征是否匹配，而该对之间的错误概率被编码为交互系数（权重）。约束条件确保每个翻转的综合征都只匹配一次。OHQ的有效解对应于自逆排列矩阵，其特征是对称独热编码。为了有效地解决OHQ，SOME将解码任务重新表述为构建最小化总权重的排列矩阵。它从最小权重综合征对之一初始化每个候选矩阵，然后按权重升序迭代添加额外的对，最后选择总能量最低的排列矩阵。SOME实现了变量数量高达99.9倍的减少，并将单线程商用CPU上的解码时间从毫秒缩短到微秒。OHQ还在高达10.5%的物理错误率下保持性能，超过了MWPM已知的最高阈值。

</details>

[⬆️ 返回分类顶部](#cset) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [93] [XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding](https://arxiv.org/abs/2507.23777)
> *XSpecMesh：通过多头推测解码加速质量保持自回归网格生成*

*Dian Chen, Yansong Qu, Xinyang Li, Ming Li, Shengchuan Zhang* | **Category: cs.GR, cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 自回归网格生成, 推测解码, 加速, 质量保持, XSpecMesh

**Comment:** 

> **TL;DR:** XSpecMesh 通过多头推测解码加速自回归网格生成，同时保持质量。

**AI_Comments:** XSpecMesh 的创新在于将多头推测解码引入自回归网格生成，并通过结合验证重采样和蒸馏策略，有效地解决了现有模型速度慢的问题，同时严格保证了生成质量，为高效能的网格生成提供了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 当前的自回归模型在网格生成推理过程中需要大量的下一令牌预测，导致显著的延迟。

**Method:** XSpecMesh 采用轻量级、多头推测解码方案，在一个前向传播中并行预测多个令牌。此外，它还提出了一种验证和重采样策略来确保质量，并采用蒸馏策略训练解码头以提高推测预测的成功率。

**Result:** 在不牺牲生成质量的情况下，实现了1.7倍的加速。

**Conclusion:** XSpecMesh 成功地加速了自回归网格生成模型，同时保持了高质量的输出。

> **ai_Abstract:** XSpecMesh 提出了一种用于加速自回归网格生成模型的方法，旨在解决现有模型推理速度慢的问题。它通过采用轻量级、多头推测解码方案实现并行令牌预测，并结合验证和重采样策略以确保生成质量。此外，该方法还引入了蒸馏策略来优化解码头的预测分布。实验结果表明，XSpecMesh 在不牺牲生成质量的前提下，实现了1.7倍的速度提升。

> **摘要翻译:** 当前自回归模型能够生成高质量、拓扑精确的网格；然而，它们在推理过程中需要数千甚至数万次的下一令牌预测，导致显著的延迟。我们引入了XSpecMesh，一种用于自回归网格生成模型的质量保持加速方法。XSpecMesh采用轻量级、多头推测解码方案，在一个前向传播中并行预测多个令牌，从而加速推理。我们进一步提出了一种验证和重采样策略：骨干模型验证每个预测的令牌，并对不符合质量标准的任何令牌进行重采样。此外，我们提出了一种蒸馏策略，通过从骨干模型中蒸馏来训练轻量级解码头，鼓励它们的预测分布对齐并提高推测预测的成功率。广泛的实验表明，我们的方法在不牺牲生成质量的情况下实现了1.7倍的加速。我们的代码将会发布。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [149] [Winding Clearness for Differentiable Point Cloud Optimization](https://arxiv.org/abs/2401.13639)
> *可微分点云优化的缠绕清晰度*

*Dong Xiao, Yueji Ma, Zuoqiang Shi, Shiqing Xin, Wenping Wang, Bailin Deng, Bin Wang* | **Category: cs.GR** | **Updated: 2025-07-31**

**Keywords:** 缠绕清晰度, 点云优化, 可微分损失, 缠绕数, 几何约束

**Comment:** Accepted by Computer-Aided Design through SPM 2025

> **TL;DR:** 引入“缠绕清晰度”概念作为点云质量度量，并提出可微分的缠绕清晰度误差作为损失函数，用于优化点云和3D生成模型，尤其擅长处理带噪声的薄结构点云。

**AI_Comments:** 这篇论文的创新点在于引入了“缠绕清晰度”这一新颖的几何概念，并将其转化为可微分的损失函数，为点云优化提供了一种非基于深度学习的、纯几何驱动的强大工具。其在处理薄结构和噪声点云方面的优越性，以及能够直接优化点云或作为生成模型约束的能力，都体现了其重要性和广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在点云质量评估和优化方面可能存在不足，尤其是在处理噪声和复杂结构时。论文旨在通过引入“缠绕清晰度”来提供一种新的、基于几何属性的方法来评估和提升点云质量，特别是解决点云内部/外部关系模糊的问题。

**Method:** 提出“缠绕清晰度”概念，用于衡量点云缠绕数场的内外关系清晰度。基于此，构建了一个仅利用点云坐标的缠绕清晰度误差目标函数，并证明其可微分性，可作为点云处理的损失函数。该方法在两个方面进行了应用：1) 通过反向传播损失函数直接更新点云坐标以改善质量，不涉及神经网络；2) 将缠绕清晰度作为几何约束引入基于扩散的3D生成模型，以生成更少噪声的点云。

**Result:** 实验结果表明，优化缠绕清晰度能有效提升点云质量。该方法在处理带有薄结构噪声点云时表现出卓越的性能，突出了缠绕数全局视角的优势。

**Conclusion:** 缠绕清晰度作为一种新的点云质量度量和可微分损失函数，能够有效优化点云质量，尤其在处理复杂和噪声点云方面表现出色，证明了其在几何建模和点云处理中的潜力。

> **ai_Abstract:** 本文引入了“缠绕清晰度”这一新概念，用于量化点云中内部/外部关系的清晰度，并基于此提出了一种可微分的缠绕清晰度误差作为损失函数。该误差函数仅依赖于点云坐标，可用于直接优化点云质量，或作为几何约束集成到3D生成模型中以减少噪声。实验证明，该方法能有效提升点云质量，尤其在处理带有薄结构的噪声点云时表现优异，体现了缠绕数全局视角的独特优势。

> **摘要翻译:** 我们提出通过“缠绕清晰度”来探索原始点云的特性，这是一个我们首次引入的概念，用于衡量点云缠绕数场表示的内部/外部关系的清晰度。在几何建模中，缠绕数是区分给定表面∂Ω内部和外部的强大工具，此前已被用于点法线定向和表面重建。在这项工作中，我们引入了一种基于缠绕清晰度评估和优化点云质量的新方法。我们观察到噪声较少的点云通常表现出更好的缠绕清晰度。因此，我们提出了一个量化缠绕清晰度误差的目标函数，该函数仅利用点云的坐标。此外，我们证明了缠绕清晰度误差是可微分的，可以作为点云处理中的损失函数。我们从两个方面展示了这一观察：1) 我们通过反向传播单个点云的损失函数来更新点的坐标，从而在不涉及神经网络的情况下实现整体改进。2) 我们将缠绕清晰度作为几何约束纳入基于扩散的3D生成模型中，并更新网络参数以生成噪声较少的点云。实验结果表明，优化缠绕清晰度在提高点云质量方面是有效的。值得注意的是，我们的方法在处理带有薄结构噪声点云时表现出卓越的性能，突出了缠绕数所实现的全局视角的优势。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [177] [Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties](https://arxiv.org/abs/2507.21288)
> *学习具有空间变异本构性质的布料可模拟模型*

*Guanxiong Chen, Shashwat Suri, Yuhao Wu, Etienne Voulga, David I. W. Levin, Dinesh K. Pai* | **Category: cs.GR, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 布料模拟, 质量-弹簧网络, 空间变异材料, 机器学习, 膜锁定

**Comment:** Added middle name of Prof. Pai

> **TL;DR:** 提出了一种名为Mass-Spring Net的通用框架，通过运动观测学习布料的复杂材料特性，克服了传统有限元方法计算量大、速度慢和“膜锁定”的问题，实现了更快的训练、更高的精度和更好的泛化能力。

**AI_Comments:** 这项工作通过引入Mass-Spring Net，为复杂布料材料的模拟提供了一个创新且高效的解决方案。其核心创新在于能够直接从运动数据中学习空间变异的材料参数，并有效规避了传统有限元方法中的“膜锁定”问题。这对于需要高精度和高效率布料模拟的应用（如电影、游戏和时尚设计）具有重要意义。该方法的优点在于其学习范式和对常见数值问题的免疫力，但其对特定数据源的依赖性以及在极端复杂或罕见材料行为上的泛化能力可能仍需进一步探讨。

<details>
  <summary>Details</summary>

**Motivation:** 真实布料材料复杂且具有空间变异性，而现有的有限元模拟方法计算量大、速度慢，并且存在导致布料僵硬的“膜锁定”数值伪影问题。

**Method:** 提出了一个名为Mass-Spring Net的通用框架，它是一个简单高效的替代模型。该方法通过将布料离散化为质量-弹簧网络，并利用新颖的力-冲量损失函数，直接从运动数据中学习未知的材料参数。

**Result:** 该方法能够准确建模各种数据源的空间变异材料特性，并且对有限元模拟中常见的“膜锁定”问题具有免疫力。与基于图网络和神经ODE的架构相比，该方法实现了显著更快的训练时间、更高的重建精度以及对新颖动态场景更好的泛化能力。

**Conclusion:** Mass-Spring Net框架能够有效学习和模拟具有复杂空间变异特性的布料，克服了传统有限元方法的局限性，提供了更高效、准确且鲁棒的解决方案。

> **ai_Abstract:** 本文提出了一种名为Mass-Spring Net的通用框架，旨在解决真实布料复杂空间变异特性模拟的挑战。针对现有有限元方法计算成本高、速度慢以及“膜锁定”伪影的问题，该框架通过从运动观测中学习质量-弹簧网络的材料参数，构建了一个简单高效的替代模型。研究结果表明，该方法能够准确建模空间变异材料，避免了“膜锁定”，并在训练速度、重建精度和泛化能力方面优于现有的图网络和神经ODE架构。

> **摘要翻译:** 真实服装中使用的材料由于缝合、包边、染色、印花、填充和粘合等常见工艺，表现出显著的复杂性和空间变异性。模拟这些材料，例如使用有限元方法，通常计算量大且速度慢。更糟糕的是，这些方法可能会遭受称为“膜锁定”的数值伪影，使布料显得异常僵硬。本文提出了一种名为Mass-Spring Net的通用框架，用于学习一个简单而高效的替代模型，该模型仅使用运动观测就能捕捉这些复杂材料的效果。布料被离散化为一个质量-弹簧网络，其未知材料参数使用新颖的力-冲量损失函数直接从运动数据中学习。我们的方法展示了从各种数据源准确建模空间变异材料特性的能力，并且对困扰基于有限元模拟的“膜锁定”具有免疫力。与基于图网络和神经ODE的架构相比，我们的方法实现了显著更快的训练时间、更高的重建精度以及对新颖动态场景更好的泛化能力。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [518] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
> *SpA2V：利用空间听觉线索进行音频驱动的空间感知视频生成*

*Kien T. Pham, Yingqing He, Yazhou Xing, Qifeng Chen, Long Chen* | **Category: cs.GR, cs.AI, cs.CV, cs.MM, cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 音频驱动视频生成, 空间听觉线索, 视频场景布局, 扩散模型, SpA2V

**Comment:** The 33rd ACM Multimedia Conference (MM '25)

> **TL;DR:** SpA2V是一个新颖的框架，首次明确利用音频中的空间听觉线索来生成具有高语义和空间对应性的视频，解决了现有方法只关注语义信息而忽略空间属性的局限。

**AI_Comments:** 该论文的创新点在于首次明确引入并利用音频中的空间听觉线索来提升视频生成质量，解决了以往方法忽视空间信息的问题。通过引入中间表示“视频场景布局”（VSL）和结合扩散模型，提供了一个有效且无需训练的生成范式，对于提升音频驱动视频生成的真实感和空间准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有音频驱动视频生成方法主要关注语义信息（如发声源类别），导致生成视频在内容和空间构成上不够准确。然而，人类不仅能识别语义，还能感知发声源的空间属性（如位置和移动方向），这些信息来源于声音的物理特性，但被现有方法所忽略。

**Method:** 提出SpA2V框架，首次明确利用音频中的空间听觉线索生成视频。该框架分为两个阶段：1）音频引导视频规划：改造最先进的多模态大语言模型（MLLM），从输入音频中提取空间和语义线索，构建视频场景布局（VSL）作为中间表示。2）布局引导视频生成：开发高效方法，将VSL作为条件指导无缝集成到预训练扩散模型中，以实现无需训练的VSL引导视频生成。

**Result:** 大量实验证明，SpA2V在生成与输入音频具有语义和空间对齐的逼真视频方面表现出色。

**Conclusion:** SpA2V通过整合音频中的空间听觉线索，显著提升了音频驱动视频生成在语义和空间准确性上的能力，实现了与输入音频高度一致的逼真视频生成。

> **ai_Abstract:** SpA2V是一个创新的音频驱动视频生成框架，它首次利用音频中的空间听觉线索（如位置、方向）来克服现有方法仅关注语义信息的局限性。该框架包含两个阶段：首先，利用多模态大语言模型（MLLM）从音频中提取空间和语义线索生成视频场景布局（VSL）；其次，将VSL作为条件指导集成到预训练扩散模型中，以生成与音频在语义和空间上高度对齐的逼真视频。实验验证了其在生成高质量视频方面的优越性。

> **摘要翻译:** 音频驱动视频生成旨在合成与输入音频录音对齐的逼真视频，类似于人类从听觉输入中可视化场景的能力。然而，现有方法主要侧重于探索语义信息，例如音频中存在的声音源类别，这限制了它们生成具有准确内容和空间构成的视频的能力。相比之下，我们人类不仅可以自然地识别发声源的语义类别，还可以确定其深度编码的空间属性，包括位置和移动方向。这种有用的信息可以通过考虑源自声音固有物理特性（例如响度或频率）的特定空间指标来阐明。由于先前的方法在很大程度上忽略了这一因素，我们提出了SpA2V，这是第一个明确利用音频中的这些空间听觉线索来生成具有高语义和空间对应性的视频的框架。SpA2V将生成过程分解为两个阶段：1）音频引导视频规划：我们精心调整了一个最先进的MLLM，用于一项新任务，即利用输入音频中的空间和语义线索来构建视频场景布局（VSL）。这作为一种中间表示，弥合了音频和视频模态之间的差距。2）布局引导视频生成：我们开发了一种高效且有效的方法，将VSL作为条件指导无缝集成到预训练扩散模型中，从而以无需训练的方式实现VSL引导的视频生成。大量实验表明，SpA2V在生成与输入音频具有语义和空间对齐的逼真视频方面表现出色。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [809] [Noise-Coded Illumination for Forensic and Photometric Video Analysis](https://arxiv.org/abs/2507.23002)
> *用于法证和光度视频分析的噪声编码照明*

*Peter F. Michael, Zekun Hao, Serge Belongie, Abe Davis* | **Category: cs.GR, cs.CR, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 噪声编码照明, 视频取证, 信息不对称, 视频验证, 时间水印

**Comment:** ACM Transactions on Graphics (2025), presented at SIGGRAPH 2025

> **TL;DR:** 通过在场景照明中编码微妙的噪声状调制，为视频添加时间水印，以创造信息不对称，从而帮助检测伪造视频，即使对手知道该技术也难以伪造。

**AI_Comments:** 这项研究的创新之处在于其独特的视频验证方法，即通过控制照明而不是直接修改视频内容来嵌入不可见的验证信息。它创造了一种信息不对称，使得伪造者在信息劣势下工作，这与传统的数字水印或内容分析方法不同。其重要性在于为打击深度伪造等日益复杂的视频操纵提供了一种新的、潜在更鲁棒的防御机制，尤其适用于高风险且照明可控的场景。

<details>
  <summary>Details</summary>

**Motivation:** 先进的视频操纵工具的普及导致虚假视频与真实视频越来越难以区分，且恶意操纵者拥有与真实视频相同的访问优势，这使得检测和揭露虚假信息变得困难。

**Method:** 该方法通过在场景照明中编码非常微妙的、类似噪声的调制，从而为在编码照明下录制的任何视频添加一个时间水印。这个水印编码的是场景在仅由编码照明照亮时的图像，而不是特定的消息。

**Result:** 即使对手知道该技术正在被使用，创建一个看似合理的编码伪造视频也相当于在信息劣势下解决一个更困难的对抗性内容创建问题。这为保护公共活动和采访等高风险场景提供了有前景的途径。

**Conclusion:** 通过在照明中编码噪声状调制来创建信息不对称，是一种有前景的视频验证方法，即使在对手知情的情况下也能有效提高伪造难度，适用于照明可控但相机不可控的场景。

> **ai_Abstract:** 本研究提出了一种通过在场景照明中嵌入微妙的噪声状调制来对抗视频伪造的新方法。这种“噪声编码照明”为视频添加了一个时间水印，该水印编码了场景在特定照明下的图像，而非特定消息。该方法旨在创造信息不对称，使得即使在对手知情的情况下，伪造一个可信的视频也变得极其困难。这为在照明可控但摄像机不可控的高风险场景（如公共活动）中验证视频提供了有前景的解决方案。

> **摘要翻译:** 先进的视频操纵工具的普及导致了一场军备竞赛，将那些希望散布虚假信息的人与那些想要检测和揭露虚假信息的人对立起来。不幸的是，在这场竞赛中时间有利于心怀不轨者，因为虚假视频越来越难以与真实视频区分。这种趋势的根源在于媒体操纵者拥有的一个根本优势：他们可以平等地访问我们认为是真实的（即“自然”）视频的分布。在本文中，我们展示了如何将非常微妙的、类似噪声的调制编码到场景照明中，通过创造有利于验证的信息不对称来帮助对抗这种优势。我们的方法有效地为在编码照明下录制的任何视频添加了一个时间水印。然而，这个水印并非编码特定消息，而是编码了未被操纵场景在仅由编码照明照亮时的图像。我们表明，即使对手知道我们的技术正在被使用，创建一个看似合理的编码伪造视频也相当于在信息劣势下解决一个更困难的原始对抗性内容创建问题。这为保护公共活动和采访等高风险环境提供了一个有前景的途径，在这些环境中，展示的内容很可能是操纵的目标，并且虽然照明可以控制，但捕捉视频的摄像机却无法控制。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [296] [Learning with Episodic Hypothesis Testing in General Games: A Framework for Equilibrium Selection](https://arxiv.org/abs/2507.23149)
> *在一般博弈中基于情景假设检验的学习：一个均衡选择框架*

*Ruifan Yang, Manxi Wu* | **Category: cs.GT, cs.SY, eess.SY** | **Updated: 2025-07-30**

**Keywords:** 学习动力学, 假设检验, 均衡选择, 纳什均衡, 一般博弈

**Comment:** 

> **TL;DR:** 本文提出了一种新的学习动力学，结合了情景假设检验和效用驱动的探索，证明了在一般有限范式博弈中收敛到近似纳什均衡，并能选择最大化所有玩家最小效用的均衡。

**AI_Comments:** 本文的创新之处在于将假设检验与效用驱动的探索相结合，从而在一般博弈中实现了一种特定的均衡选择（最大化最小效用）。这为博弈论和博弈学习领域提供了一种有价值的新机制。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在引入一种新的基于假设检验的学习动力学，以解决在一般博弈中玩家如何更新策略以及如何实现均衡选择的问题。

**Method:** 提出了一种新的学习动力学，其中玩家通过结合假设检验和效用驱动的探索来更新策略。玩家形成关于对手策略的信念，并使用经验观察进行情景性测试。当假设检验被拒绝或通过探索时，信念会被重新采样，探索的概率随玩家（转换后的）效用降低。

**Result:** 学习过程收敛到一组近似纳什均衡，更重要的是，收敛到一个能选择最大化所有玩家最小（转换后的）效用的均衡的改进。该结果确立了在一般有限博弈中的均衡收敛性。

**Conclusion:** 本文确立了在一般有限博弈中学习过程的均衡收敛性，并揭示了一种由学习动力学结构引起的新的均衡选择机制。

> **ai_Abstract:** 本文提出了一种在一般有限范式博弈中新的基于假设检验的学习动力学框架。该框架将情景假设检验与效用驱动的探索相结合，使得玩家能够更新策略。研究表明，这种学习过程能够收敛到近似纳什均衡，并且显著地，它能够选择最大化所有玩家最小效用的均衡，从而揭示了一种新颖的均衡选择机制。

> **摘要翻译:** 我们引入了一种新的基于假设检验的学习动力学，其中玩家通过结合假设检验和效用驱动的探索来更新他们的策略。在这种动力学中，每个玩家形成关于对手策略的信念，并使用经验观察对这些信念进行情景性测试。当假设检验被拒绝或通过探索时，信念会被重新采样，其中探索的概率随玩家（转换后的）效用降低。在一般有限范式博弈中，我们表明学习过程收敛到一组近似纳什均衡，更重要的是，收敛到一个能选择最大化所有玩家最小（转换后的）效用的改进均衡。我们的结果确立了在一般有限博弈中的均衡收敛性，并揭示了一种由学习动力学结构引起的新的均衡选择机制。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [324] [Expectation in Stochastic Games with Prefix-independent Objectives](https://arxiv.org/abs/2405.18048)
> *具有前缀无关目标的随机博弈中的期望*

*Laurent Doyen, Pranshu Gaba, Shibashis Guha* | **Category: cs.GT** | **Updated: 2025-07-31**

**Keywords:** 随机博弈, 前缀无关目标, 期望值, 几乎确定满足, 窗口平均收益

**Comment:** 31 pages, 5 figures. Full version of paper accepted in CONCUR 2025

> **TL;DR:** 本文研究了随机博弈中具有前缀无关目标的期望值问题，并提出了一种将其简化为几乎确定满足问题的通用方法，同时分析了记忆需求，并将其应用于计算期望窗口平均收益。

**AI_Comments:** 这项工作提供了一种将复杂的期望问题简化为更易处理的几乎确定满足问题的通用方法，这在理论上具有重要意义。它不仅简化了问题，还证明了在记忆效率上的优势。将其应用于窗口平均收益度量并分析其复杂性，进一步展示了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 随机双人博弈对兼具对抗性和随机性的系统进行建模，理解和计算这类博弈中特定目标的期望值对于分析和设计鲁棒系统至关重要。

**Method:** 本文提出了一种通用的归约方法，将有界定量前缀无关目标的期望问题归约为线性多个阈值布尔目标的几乎确定满足问题实例。该方法通过将博弈的顶点划分为“值类”来实现，其中每个类由具有相同值的顶点组成。

**Result:** 1. 期望问题可以被通用归约为线性多个几乎确定满足问题实例。2. 为期望问题进行最优博弈所需的记忆量不超过为相应阈值布尔目标几乎确定满足问题进行最优博弈所需的记忆量。3. 该框架可应用于计算随机博弈中的期望窗口平均收益度量。4. 当窗口长度为一元表示时，检查期望窗口平均收益值是否至少达到给定阈值的判定问题在 UP $\cap$ coUP 中。

**Conclusion:** 本文成功地将随机博弈中前缀无关目标的期望问题归约为更简单的几乎确定满足问题，并展示了其在计算期望窗口平均收益方面的应用，同时分析了其计算复杂性。

> **ai_Abstract:** 本文研究了随机双人博弈中前缀无关目标的期望值问题。作者提出了一种通用的归约方法，将期望问题转化为一系列几乎确定满足问题，并证明了其在最优策略记忆需求上的效率。此外，该框架被应用于计算期望窗口平均收益，并分析了其决策问题的计算复杂性。

> **摘要翻译:** 随机双人博弈对兼具对抗性和随机性的系统进行建模。在本文中，我们研究了随机博弈背景下有界定量前缀无关目标的期望值。我们展示了一种通用的归约方法，将期望问题归约为线性多个阈值布尔目标的几乎确定满足问题实例。该结果源于将博弈的顶点划分为所谓的价值类，其中每个类由具有相同值的顶点组成。我们的过程进一步表明，两名玩家为期望问题进行最优博弈所需的记忆量不超过玩家为相应阈值布尔目标的几乎确定满足问题进行最优博弈所需的记忆量。 我们展示了该框架在计算随机博弈中期望窗口平均收益度量方面的适用性。窗口平均收益度量通过计算沿着无限路径滑动的有界长度窗口上的平均收益来强化经典的平均收益度量。我们表明，当窗口长度以一元表示时，检查期望窗口平均收益值是否至少达到给定阈值的判定问题在 UP $\cap$ coUP 中。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [649] [Online Combinatorial Allocation with Interdependent Values](https://arxiv.org/abs/2507.23500)
> *在线组合分配与相互依赖的价值*

*Michal Feldman, Simon Mauras, Divyarthi Mohan, Rebecca Reiffenhäuser* | **Category: cs.GT, cs.DS** | **Updated: 2025-07-31**

**Keywords:** 在线组合分配, 相互依赖价值, 秘书问题, 竞争算法, 真实机制

**Comment:** 

> **TL;DR:** 本文将在线秘书问题中的相互依赖价值模型扩展到组合分配场景，为广泛的估值函数提供了2e竞争算法，并为战略设置下的在线二分匹配提供了4e竞争的真实机制。

**AI_Comments:** 这篇论文的创新之处在于将相互依赖价值的概念引入到更复杂的在线组合分配问题中，这是对现有在线秘书问题研究的重大扩展。它成功地处理了组合结构和价值相互依赖性带来的双重挑战，并提供了具有竞争力的近似算法和真实机制。其结果在不同估值函数类别和战略设置下都达到了或接近了非相互依赖情况下的最佳已知界限，显示了其理论贡献和实用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究首次将相互依赖价值引入在线设置（秘书问题），但仅限于单一选择场景。本文的动机在于将这一框架扩展到更复杂的组合秘书问题，即代理人对物品捆绑拥有相互依赖的估值，这引入了组合结构和相互依赖性的额外挑战。

**Method:** 本文通过引入2e竞争算法来解决具有广泛估值函数（包括子模和XOS函数）的组合秘书问题。此外，研究还扩展到战略设置，并提供了一个4e竞争的真实机制，用于具有相互依赖估值的在线二分匹配。

**Result:** 为广泛的估值函数（包括子模和XOS函数）提供了2e竞争算法，与单一选择秘书设置中的近似保证相匹配。结果覆盖了经典（非相互依赖）秘书设置中存在常数因子算法的相同估值类别，而仅因相互依赖性而额外增加了2倍因子。在战略设置中，为具有相互依赖估值的在线二分匹配提供了一个4e竞争的真实机制，这与已知的前沿结果相符，即使在没有相互依赖的情况下也是如此。

**Conclusion:** 本研究成功地将在线秘书问题中的相互依赖价值框架扩展到组合分配场景，并为多种估值函数和战略设置提供了具有竞争力的算法和机制，填补了该领域的重要空白。

> **ai_Abstract:** 本文研究了秘书设置下具有相互依赖价值的在线组合分配问题。在前人研究的基础上，本文首次将该框架扩展到代理人对物品捆绑拥有相互依赖估值的组合秘书问题。研究为广泛的估值函数（如子模和XOS函数）提供了2e竞争算法，并将其与单一选择秘书设置的近似保证进行匹配。此外，研究还考虑了战略设置，并为具有相互依赖估值的在线二分匹配提供了一个4e竞争的真实机制，其性能可与非相互依赖情况下的最新成果媲美。

> **摘要翻译:** 我们研究了秘书设置下具有相互依赖价值的在线组合分配问题。在Milgrom和Weber（1982）引入的相互依赖模型中，每个代理人拥有一个私有信号，该信号捕获了她关于待售物品的信息，并且每个代理人的价值取决于所有代理人持有的信号。Mauras、Mohan和Reiffenhäuser（2024）首次研究了在线设置中的相互依赖价值，为代理人在线到达及其信号和价值的秘书设置提供了常数近似保证，目标是选择价值最高的代理人。在这项工作中，我们将此框架扩展到组合秘书问题，其中代理人对物品捆绑具有相互依赖的估值，由于组合结构和相互依赖性，这引入了额外的挑战。我们为广泛的估值函数（包括子模和XOS函数）提供了2e竞争算法，与单一选择秘书设置中的近似保证相匹配。此外，我们的结果涵盖了在经典（非相互依赖）秘书设置中存在常数因子算法的相同估值类别，而仅因相互依赖性而额外增加了2倍因子。最后，我们将研究扩展到战略设置，并为具有相互依赖估值的在线二分匹配提供了一个4e竞争的真实机制，再次达到了已知的前沿水平，即使在没有相互依赖的情况下也是如此。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [47] [AudioMiXR: Spatial Audio Object Manipulation with 6DoF for Sound Design in Augmented Reality](https://arxiv.org/abs/2502.02929)
> *AudioMiXR：用于增强现实中声音设计的六自由度空间音频对象操作*

*Brandon Woodard, Margarita Geleta, Joseph J. LaViola Jr., Andrea Fanelli, Rhonda Wilson* | **Category: cs.HC, cs.SD, eess.AS, H.5.2; H.5.5; H.5.1** | **Updated: 2025-08-01**

**Keywords:** 增强现实, 空间音频, 6自由度, 声音设计, 本体感受

**Comment:** Revision necessary for accuracy

> **TL;DR:** AudioMiXR是一个增强现实界面，用于评估用户如何在物理空间中通过六自由度（6DoF）操作虚拟音频对象进行3D声音设计。研究旨在探索AR中6DoF声音设计的指导原则，并提出了两个设计经验：本体感受和平衡音视频模态。

**AI_Comments:** 这项研究通过引入AudioMiXR，首次探索了在增强现实环境中利用六自由度进行3D声音设计。其创新之处在于将空间音频操作从传统的桌面环境转移到更具沉浸感和空间感知的AR头显中。研究通过用户实验得出的两个设计经验——本体感受和音视频模态平衡，对于未来AR声音交互界面的设计具有重要指导意义，填补了该领域研究的空白。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D声音设计工具通常受限于桌面显示器，这可能限制在执行环境中的空间感知。利用XR头戴式显示器（HMD）创建音景可以提供实时测试环境，但目前缺乏针对XR中六自由度（6DoF）声音设计的设计指南研究。

**Method:** 研究团队提出了AudioMiXR，一个用于3D声音设计的增强现实（AR）界面，通过Apple Vision Pro头显部署。他们进行了一项探索性研究，招募了27名参与者（包括专家和非专家声音设计师），采用受试者内设计，要求用户设计音乐和电影音景。研究数据通过主题分析。

**Result:** 通过对参与者数据进行主题分析，研究构建了两个设计经验：1. AR声音设计的本体感受，2. AR图形用户界面中音视频模态的平衡。此外，研究还根据结果提供了最能受益于6DoF声音设计的应用领域。

**Conclusion:** 本研究为识别AR中6DoF声音设计相关的研究方向迈出了第一步，并提供了可用于未来3D声音设计研究的设计经验。

> **ai_Abstract:** AudioMiXR是一个增强现实界面，旨在探索在AR头显（如Apple Vision Pro）上通过六自由度（6DoF）操作虚拟音频对象进行3D声音设计。针对现有工具的局限性以及XR中6DoF声音设计指南的缺失，研究招募了27名声音设计师进行探索性研究，让他们设计音乐和电影音景。研究结果提出了两个关键设计经验：AR声音设计的本体感受和AR图形用户界面中音视频模态的平衡，并指出了6DoF声音设计的潜在应用领域，为未来研究奠定基础。

> **摘要翻译:** 我们提出了AudioMiXR，一个增强现实（AR）界面，旨在评估用户如何使用部署在头戴式显示器（Apple Vision Pro）上的六自由度（6DoF）来操作其物理空间中的虚拟音频对象，以进行3D声音设计。现有的3D声音设计工具通常受限于桌面显示器，这可能会限制在执行环境中的混音空间感知。利用XR头戴式显示器创建音景可以为3D声音设计提供实时测试环境，因为现代头戴式显示器可以在跨模态交互的辅助下提供精确的空间定位。然而，目前没有关于XR中六自由度（6DoF）声音设计的具体设计指南研究。为了朝着识别该领域的设计相关研究方向迈出第一步，我们进行了一项探索性研究，招募了27名参与者，其中包括专家和非专家声音设计师。目标是评估可用于为未来3D声音设计研究提供信息的经验教训。我们进行了一项受试者内研究，用户设计了音乐和电影音景。在对参与者数据进行主题分析后，我们构建了两个设计经验：1. AR声音设计的本体感受，以及2. AR图形用户界面中音视频模态的平衡。此外，我们还根据结果提供了最能受益于6DoF声音设计的应用领域。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [94] [An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System](https://arxiv.org/abs/2309.12365)
> *一种高效智能半自动化仓库库存盘点系统*

*Chunan Tong* | **Category: cs.HC, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 智能库存管理, 仓库盘点, 大数据分析, Flutter应用, 自动化库存

**Comment:** 

> **TL;DR:** 本研究提出了一种结合条形码、分布式Flutter应用和大数据分析的智能库存管理系统，以提高库存管理的自动化、精度和智能化水平。

**AI_Comments:** 该论文的创新点在于结合了条形码、分布式Flutter应用和大数据分析，构建了一个能够实现秒级监控和AI驱动预测的智能半自动化库存系统，有效解决了传统库存管理中的痛点。其重要性在于提升了库存管理的效率和智能化水平，对现代供应链管理具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的人工和经验型库存管理方法难以满足现代市场需求，存在数据不准确、监控延迟以及过度依赖主观经验进行预测的问题。

**Method:** 该系统整合了条形码和分布式Flutter应用技术进行智能感知，并结合全面的大数据分析以实现数据驱动的决策。通过分析、系统设计、关键技术探索和仿真验证来展示其有效性。

**Result:** 该智能系统实现了秒级监控、高频检查和人工智能驱动的预测，成功提高了库存管理的自动化、精度和智能化水平。

**Conclusion:** 该系统通过准确预测和明智决策，有助于降低成本和优化库存规模，最终实现互利共赢的局面。

> **ai_Abstract:** 本研究提出了一种智能库存管理系统，旨在解决传统方法中数据不准确、监控延迟和过度依赖经验的问题。该系统结合了条形码、分布式Flutter应用和大数据分析技术，实现了智能感知和数据驱动决策。通过仿真验证，系统展现了秒级监控、高频检查和AI驱动预测的能力，显著提升了库存管理的自动化、精度和智能化水平，从而有效降低成本并优化库存。

> **摘要翻译:** 在供应链管理不断发展的背景下，高效库存管理对企业的重要性显著增加。然而，传统的、基于人工和经验的方法往往难以满足现代市场需求的复杂性。本研究引入了一种智能库存管理系统，以解决数据不准确、监控延迟以及预测过度依赖主观经验等挑战。所提出的系统整合了条形码和分布式Flutter应用技术进行智能感知，并结合全面的大数据分析以实现数据驱动的决策。通过细致的分析、系统设计、关键技术探索和仿真验证，成功证明了所提出系统的有效性。该智能系统促进了秒级监控、高频检查和人工智能驱动的预测，从而增强了库存管理的自动化、精度和智能化。该系统通过准确的预测和明智的决策，有助于降低成本和优化库存规模，最终实现互利共赢的局面。本研究的成果提供……

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [136] [EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition](https://arxiv.org/abs/2408.09186)
> *脑电图-SCMM：用于跨语料库脑电图情感识别的软对比掩码建模*

*Qile Liu, Weishan Ye, Lingli Zhang, Zhen Liang* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 脑电图情感识别, 跨语料库, 软对比学习, 掩码建模, 泛化

**Comment:** 18 pages, 10 figures, 14 tables. Accepted in ACMMM 2025

> **TL;DR:** 提出EEG-SCMM框架，结合软对比学习和混合掩码策略，解决跨语料库EEG情感识别的泛化性问题，并达到SOTA性能。

**AI_Comments:** 该论文创新性地将软对比学习与混合掩码策略结合，并引入软加权机制和相似性感知聚合器，有效解决了EEG情感识别在跨语料库泛化方面的核心难题。其提出的双重设计理念，旨在生成更具判别性和可迁移性的表示，对提升EEG情感识别的鲁棒性具有重要意义。实验结果也验证了其优越性，为该领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有脑电图情感识别方法在跨语料库设置中泛化能力差，因为数据分布和记录条件不同，导致模型无法直接应用于新数据集。

**Method:** 提出SCMM（Soft Contrastive Masked Modeling）框架，该框架基于情感连续性理论，整合软对比学习与混合掩码策略。在自监督学习阶段，引入软加权机制为样本对分配相似性分数，以建模情感转换和捕捉时间连续性。此外，设计了一个相似性感知聚合器，根据成对相似性融合语义相关样本的互补信息，以增强特征表达和重建质量。这种双重设计旨在生成更具判别性和可迁移性的表示。

**Result:** 在SEED、SEED-IV和DEAP数据集上进行了广泛实验，SCMM实现了最先进（SOTA）的性能。在同类和异类跨语料库设置下，平均准确率比次优方法高出4.26%。

**Conclusion:** SCMM通过其软对比学习和混合掩码策略，有效解决了跨语料库EEG情感识别的泛化性挑战，并取得了显著的性能提升，证明了其生成判别性和可迁移表示的能力。

> **ai_Abstract:** 本文提出EEG-SCMM框架，旨在解决跨语料库脑电图情感识别的泛化性挑战。该框架基于情感连续性理论，结合软对比学习和混合掩码策略。它引入了软加权机制来建模情感转换和时间连续性，并设计了相似性感知聚合器以增强特征表达。实验结果表明，SCMM在多个数据集上实现了SOTA性能，显著提升了跨语料库情感识别的准确率。

> **摘要翻译:** 近年来，利用脑电图（EEG）信号进行情感识别越来越受到关注。然而，现有方法在跨语料库设置中往往缺乏泛化性，即在不重新训练的情况下将一个数据集上训练的模型直接应用于另一个数据集时，由于数据分布和记录条件的不同，其性能会下降。为了解决跨语料库脑电图情感识别的挑战，我们提出了一种名为软对比掩码建模（SCMM）的新型框架。SCMM 以情感连续性理论为基础，将软对比学习与混合掩码策略相结合，以有效捕捉情感动态（指短期连续性）。具体而言，在自监督学习阶段，我们提出了一种软加权机制，为样本对分配相似性分数，从而实现对情感转换的细粒度建模并捕捉人类情感的时间连续性。为了进一步增强表示学习，我们设计了一个相似性感知聚合器，根据成对相似性融合来自语义相关样本的互补信息，从而提高特征表达能力和重建质量。这种双重设计有助于生成更具判别性和可迁移性的表示，这对于强大的跨语料库泛化至关重要。在SEED、SEED-IV和DEAP数据集上进行的广泛实验表明，SCMM在同类和异类跨语料库设置下均实现了最先进（SOTA）的性能，平均准确率比次优方法高出4.26%。源代码可在https://github.com/Kyler-RL/SCMM获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [183] [Knowledge Is More Than Performance: How Knowledge Diversity Drives Human-Human and Human-AI Interaction Synergy and Reveals Pure-AI Interaction Shortfalls](https://arxiv.org/abs/2507.22889)
> *知识超越表现：知识多样性如何驱动人-人与人-AI交互协同并揭示纯AI交互的不足*

*Tom Sheffer, Alon Miron, Yaniv Dover, Ariel Goldstein* | **Category: cs.HC, cs.CY** | **Updated: 2025-06-15**

**Keywords:** 知识多样性, 人机交互, 大型语言模型, 协同效应, 协作问题解决

**Comment:** 

> **TL;DR:** 研究发现，人类和人机混合交互能提升准确性，而纯LLM交互效果不佳，原因是LLM知识高度相似缺乏多样性。因此，AI发展应注重培养多样性而非单纯追求个体性能。

**AI_Comments:** 本文创新性地通过对比实验揭示了当前LLM在纯AI协作中的局限性，并指出了关键原因在于知识多样性的缺乏。其重要性在于为未来AI模型的设计和训练提供了新的方向，即从个体性能导向转变为群体协同能力导向，强调了“知识多样性”这一新颖的优化目标，对构建更高效、更具鲁棒性的AI协作系统具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了探究AI智能体之间的交互能否复制人类讨论中观察到的协同效应。

**Method:** 研究系统比较了四种对话配置：两两LLM、三LLM、三人组和人-LLM混合对。参与者首先独立回答问题，然后进行开放式讨论，最后重新考虑其初始答案。

**Result:** 涉及人类的交互在对话后持续提高准确性，使强弱参与者均受益。相比之下，纯基于LLM的对和三人组准确性下降，表现出有限的对话协同。对参与者信心和答案切换行为的分析表明，知识多样性是实现协作改进的关键因素。LLM-LLM交互缺乏收益并非源于模型协作能力的根本局限，而是由于高度相似的知识状态，导致生产性交流空间不足。

**Conclusion:** 研究结果认为AI开发应范式转变：与其仅为独立性能优化单个模型，不如明确培养代理间的多样性（即使以略低的个体准确性为代价），这可能使AI协作者在与人类或其他AI系统进行群体设置时更有效。

> **ai_Abstract:** 本研究探讨了人类、AI和人机混合团队在解决问题时的协同效应。通过比较纯人类、纯LLM和人-LLM混合对话配置，发现人类参与的交互能显著提升准确性，而纯LLM交互因知识同质性导致准确性下降。研究强调知识多样性是协作改进的关键，并建议AI开发应从单纯追求个体性能转向培养智能体的多样性，以提升其在群体环境中的协作能力。

> **摘要翻译:** 对话将个体知识转化为集体洞察力，使人类群体和越来越多的AI（人工智能）智能体群体能够协作解决复杂问题。AI智能体之间的交互能否复制人类讨论中观察到的协同效应仍是一个悬而未决的问题。为了调查这一点，我们系统地比较了四种对话配置：两两大型语言模型（LLM-LLM）、三LLM、三人组和人-LLM混合对。在智能体独立回答问题后，它们进行开放式讨论，然后重新考虑其初始答案。涉及人类的交互在对话后持续提高准确性，使强弱参与者均受益。相比之下，纯基于LLM的对和三人组准确性下降，表现出有限的对话协同。对参与者信心和答案切换行为的分析表明，知识多样性是实现协作改进的关键因素。重要的是，LLM-LLM交互缺乏收益并非源于模型协作能力的根本局限，而是由于高度相似的知识状态，导致生产性交流空间不足。我们的发现认为AI开发应范式转变：与其仅为独立性能优化单个模型，不如明确培养代理间的多样性（即使以略低的个体准确性为代价），这可能使AI协作者在与人类或其他AI系统进行群体设置时更有效。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [185] [AI vs. Human Paintings? Deciphering Public Interactions and Perceptions towards AI-Generated Paintings on TikTok](https://arxiv.org/abs/2409.11911)
> *AI与人类绘画的对决？解读TikTok上公众对AI生成绘画的互动与感知*

*Jiajun Wang, Xiangzhe Yuan, Siying Hu, Zhicong Lu* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** AI生成绘画, TikTok, 公众感知, 用户互动, 情感分析

**Comment:** Published online in International Journal of Human Computer
  Interaction

> **TL;DR:** 本研究调查了TikTok上公众对AI生成绘画的互动和感知，发现了一些导致负面看法的原因，并为未来的AI技术发展提供建议。

**AI_Comments:** 该论文创新性地将社交媒体数据分析与公众对AI艺术的感知研究相结合，弥补了以往研究中对公众反馈关注不足的空白。其采用情感分析和主题建模的方法，深入剖析了负面情绪的来源，为AI艺术的伦理和发展提供了宝贵的洞察。研究的重要性在于，它不仅揭示了当前AI艺术面临的社会挑战，更提出了具体的建议，有助于引导AI技术朝着更负责任、更符合公众期待的方向发展，促进人机在创意领域的和谐共存。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI技术的发展，AI生成绘画（AIGP）在社交媒体上广为流传，但也伴随着负面新闻，例如2022年因AI模型训练中的侵权问题引发了全球画家的反AI运动。这反映出在生成式AI发展和应用过程中，公众的反馈和感受可能被忽视，因此本研究旨在调查公众对AIGP在社交媒体上的互动和感知。

**Method:** 研究分析了TikTok上AI生成绘画的用户参与度水平和评论情感得分，并以人类绘画视频作为基线进行对比。在分析用户参与度时，考虑了绘画美学质量的调节效应。此外，研究利用主题建模识别了导致公众对AIGP产生负面感知的七个原因。

**Result:** 研究识别出七个导致公众对AI生成绘画产生负面感知的原因，包括超现实质量、矛盾反应、对艺术被盗的感知等。

**Conclusion:** 本研究为未来的生成式AI技术发展提供了指导性建议，并有助于避免在人机协作中潜在的危机。

> **ai_Abstract:** 本研究旨在调查公众在TikTok上对AI生成绘画（AIGP）的互动和感知。通过分析AIGP的用户参与度和评论情感得分，并以人类绘画作为基线，研究发现公众对AIGP存在负面看法，并利用主题建模识别了七个主要原因，如超现实质量和对艺术侵权的担忧。研究结果为未来生成式AI技术的发展提供了建议，以避免潜在的人机协作危机。

> **摘要翻译:** 随着生成式AI技术的发展，大量的AI生成绘画（AIGP）在TikTok等社交媒体上走红。然而，一些关于AIGP的负面新闻也随之出现。例如，2022年，全球众多画家组织了一场大规模的反AI运动，原因是生成式AI模型训练中的侵权问题。这一事件反映了一个社会问题，即随着生成式AI的发展和应用，公众对其的反馈和感受可能被忽视了。因此，为了调查公众在社交媒体上对AIGP的互动和感知，我们以人类绘画视频为基线，分析了AIGP的用户参与度水平和评论情感得分。在分析用户参与度时，我们还考虑了绘画美学质量的可能调节作用。利用主题建模，我们识别了导致公众对AIGP产生负面感知的七个原因，包括超现实质量、矛盾反应、感知到的艺术盗窃等。我们的工作可能为未来的生成式AI技术发展提供指导性建议，并避免人机协作中潜在的危机。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [227] [Visual Story-Writing: Writing by Manipulating Visual Representations of Stories](https://arxiv.org/abs/2410.07486)
> *视觉故事创作：通过操纵故事的视觉表示进行写作*

*Damien Masson, Zixin Zhao, Fanny Chevalier* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** 视觉故事创作, 叙事文本编辑, 可视化, 写作支持, 创造力

**Comment:** In Proceedings of the 38th Annual ACM Symposium on User Interface
  Software and Technology (UIST '25)

> **TL;DR:** 本文定义并演示了“视觉故事创作”，即使用可视化工具辅助叙事文本的写作和修订。研究发现，这种视觉方法能帮助用户进行高层次修改规划、追踪故事元素和探索故事变体，从而激发创造力。

**AI_Comments:** 本文提出了一种新颖的写作支持范式——“视觉故事创作”，其创新之处在于将抽象的叙事结构具象化为可交互的视觉元素。这对于提升写作者的结构规划能力、追踪复杂故事线以及激发创造力具有重要意义。该方法超越了传统的纯文本编辑，为叙事创作工具的发展提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在定义并演示“视觉故事创作”这一方法，即利用故事元素的视觉表示来支持叙事文本的写作和修订。

**Method:** 作者开发了一个文本编辑器，该编辑器能自动可视化实体互动图、地点移动和故事事件时间线。用户与这些可视化界面互动（如连接角色、移动实体、重新排列事件）会触发文本编辑建议。

**Result:** 通过两项关于叙事文本编辑和写作的用户研究发现，视觉化工具支持参与者规划高层次修订、追踪故事元素，并以鼓励创造力的方式探索故事变体。

**Conclusion:** 这项工作为不仅仅通过文字，还通过视觉提供写作支持奠定了基础。

> **ai_Abstract:** 本文定义了“视觉故事创作”为利用故事元素的视觉表示来支持叙事文本的写作和修订。为验证此方法，作者开发了一个文本编辑器，该编辑器能自动生成实体互动图、地点移动和事件时间线等可视化内容，并通过用户与这些视觉元素的互动来建议文本修改。两项用户研究表明，这种视觉方法能有效帮助作者进行高层次的修订规划、追踪故事元素以及探索故事变体，从而激发创造力。这项工作为未来通过视觉而非仅仅文字提供写作支持奠定了基础。

> **摘要翻译:** 我们将“视觉故事创作”定义为使用故事元素的视觉表示来支持叙事文本的写作和修订。为了演示这种方法，我们开发了一个文本编辑器，它能自动可视化实体互动的图表、地点之间的移动以及故事事件的时间线。与这些可视化界面的互动会产生建议的文本编辑：例如，在图中连接两个角色会创建它们之间的互动，移动一个实体会更新其描述的位置，重新排列时间线上的事件会重新组织叙事顺序。通过两项关于叙事文本编辑和写作的用户研究，我们发现视觉支持参与者规划高层次修订、追踪故事元素，并以鼓励创造力的方式探索故事变体。广义而言，我们的工作为写作支持奠定了基础，不仅仅通过文字，也通过视觉。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [269] [Agentic Visualization: Extracting Agent-based Design Patterns from Visualization Systems](https://arxiv.org/abs/2505.19101)
> *代理可视化：从可视化系统中提取基于代理的设计模式*

*Vaishali Dhanoa, Anton Wolter, Gabriela Molina León, Hans-Jörg Schulz, Niklas Elmqvist* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** 代理可视化, 设计模式, 大型语言模型, 人机协作, 可视化系统

**Comment:** 

> **TL;DR:** 该论文通过重新解读现有可视化系统，提取了代理可视化（Agentic Visualization）的设计模式，旨在平衡AI代理的能力与人类的洞察力和控制。

**AI_Comments:** 本文创新性地将代理视角引入可视化系统设计，以应对大型语言模型带来的新挑战。其重要性在于为未来人机协作可视化系统的开发提供了具体的设计模式，有助于在利用AI强大分析能力的同时，确保人类在决策过程中的核心作用。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型驱动的自主代理正在改变人工智能领域，这使得可视化领域必须采纳代理框架。然而，可视化领域以人为中心的特性，对如何在代理可视化中平衡自主性、委托和协调，同时保持人类能动性并增强分析能力提出了关键问题。

**Method:** 本研究通过代理视角重新解读了现有带有半自动化或全自动化AI组件的可视化系统，并在此分析基础上，提取了一系列代理可视化的设计模式。

**Result:** 研究提取了一系列代理可视化的设计模式，包括代理角色、通信和协调。

**Conclusion:** 这些设计模式为未来的代理可视化系统奠定了基础，使其能够有效利用AI代理，同时保持人类的洞察力和控制。

> **ai_Abstract:** 随着大型语言模型驱动的自主代理对人工智能领域的变革，可视化领域亟需采纳代理框架。本文旨在解决代理可视化中如何平衡AI自主性与人类能动性的问题。研究通过代理视角重新解读现有带有AI组件的可视化系统，并从中提取了代理可视化的设计模式，涵盖代理角色、通信和协调等方面。这些模式为未来构建既能有效利用AI代理又能保持人类洞察力和控制的可视化系统提供了基础。

> **摘要翻译:** 由大型语言模型驱动的自主代理正在改变人工智能，这使得可视化领域必须采纳代理框架。然而，我们领域对人类在意义建构循环中的关注，对这种“代理可视化”的自主性、委托和协调提出了关键问题，即如何在增强分析能力的同时保留人类的能动性。本文通过代理视角重新解读了现有带有半自动化或全自动化AI组件的可视化系统，从而解决了这些问题。基于这项分析，我们提取了一系列代理可视化的设计模式，包括代理角色、通信和协调。这些模式为未来的代理可视化系统奠定了基础，使其能够有效利用AI代理，同时保持人类的洞察力和控制。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [311] [Ragged Blocks: Rendering Structured Text with Style](https://arxiv.org/abs/2507.06460)
> *不规则块：带样式渲染结构化文本*

*Sam Cohen, Ravi Chugh* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** 不规则块, 结构化文本, 文本可视化, 布局算法, 排版布局

**Comment:** UIST 2025 Paper + Appendices

> **TL;DR:** 本文提出了一种名为“不规则块”（ragged blocks）的新型布局算法，用于渲染带有任意嵌套样式（如边框和填充）的结构化文本，同时保持紧凑性并最小化对原始排版布局的干扰，其效果优于传统方法。

**AI_Comments:** 本文提出了一种新颖的“不规则块”布局算法，解决了在显示结构化文本时，如何有效结合丰富的样式信息（如边框和填充）与保持良好排版布局的挑战。其创新点在于通过生成非矩形的“不规则块”来更紧凑地适应嵌套结构，避免了传统矩形块导致的空白浪费或布局破坏。这对于代码编辑器、文档渲染等需要可视化复杂文本结构的应用具有重要意义，提供了一种更高效、更美观的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本可视化方法，无论是扁平的行级装饰还是嵌套盒，都无法在传达文本结构的同时保持良好的排版布局，这限制了与文本一同显示的信息类型。

**Method:** 提出了一种布局算法，用于生成“不规则块”（rocks），这是一种矩形多边形，即使在添加边框和填充的情况下，也能紧凑地渲染嵌套文本，同时最大限度地减少对底层排版布局的干扰。

**Result:** 在多种编程语言的源代码基准测试中，与传统技术生成的矩形块布局相比，本文算法生成的不规则块布局在统一为语法树中的每个元素添加边框和填充时，明显更紧凑。

**Conclusion:** 本文证明了通过提出的不规则块布局算法，可以实现任意嵌套的文本装饰，同时最大程度地减少对底层排版布局的干扰，并且其生成的布局比传统技术更紧凑。

> **ai_Abstract:** 本文提出了一种新的布局算法，用于渲染结构化文本，如源代码或散文。针对现有文本可视化方法无法兼顾结构信息和良好排版布局的问题，该算法引入了“不规则块”（ragged blocks）概念，这是一种矩形多边形，能够实现任意嵌套的文本装饰（如边框和填充），同时最小化对原始排版布局的干扰并保持紧凑性。实验结果表明，与传统矩形块布局相比，不规则块布局在样式化元素时能显著提高空间效率。

> **摘要翻译:** 无论是编程语言中的源代码，自然语言中的散文，还是其他形式，文本都具有高度的结构性。目前，文本可视化要么局限于“扁平的、基于行的”装饰，这只能传达有限的文本结构信息；要么是“嵌套盒”，它们能够传达结构，但往往破坏了底层文本的排版布局。我们假设，缺乏丰富的样式选项限制了与文本一同显示的信息种类，无论文本显示在哪里。
在本文中，我们展示了在最小化干扰底层排版布局的同时，实现任意嵌套装饰是可能的。具体来说，我们提出了一种布局算法，该算法生成“不规则块”（ragged blocks），也称为“rocks”，它们是矩形多边形，即使在添加边框和填充的情况下，也允许紧凑地渲染嵌套文本。我们的布局算法在包含多种编程语言中代表性源代码文件的基准测试套件上进行了评估。当统一为语法树中的每个元素添加边框和填充时，我们的算法生成的不规则块布局比传统技术生成的矩形块布局显著更紧凑。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [331] [Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models](https://arxiv.org/abs/2507.23470)
> *使用大型语言模型对学生生成的UML和ER图提供自动化反馈*

*Sebastian Gürtl, Gloria Schimetta, David Kerschbaumer, Michael Liut, Alexander Steinmaurer* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-31**

**Keywords:** UML图, ER图, 自动化反馈, 大型语言模型, 计算机教育

**Comment:** Learnersourcing: Student-generated Content @ Scale Workshop at L@S
  2025

> **TL;DR:** DUET是一个基于LLM的工具原型，用于为学生生成的UML和ER图提供自动化、结构化反馈，解决了传统教学中难以提供可扩展个性化反馈的问题，并已通过访谈评估，显示出其潜力和局限性。

**AI_Comments:** DUET的创新之处在于利用LLM自动化UML和ER图的反馈过程，解决了传统方法难以扩展和个性化的问题。其重要性在于为计算机科学教育提供了一个潜在的、高效的辅助工具。然而，LLM的可靠性和潜在误用是其局限性，需要进一步的研究和改进以确保其在实际教学中的有效性和安全性。

<details>
  <summary>Details</summary>

**Motivation:** UML和ER图是计算机科学教育的基础，但学生在掌握其语法和语义、进行抽象思维和理解上下文方面面临挑战。传统教学方法难以提供可扩展的个性化反馈，尤其是在大型班级中。

**Method:** 我们引入了DUET（Diagrammatic UML & ER Tutor），一个基于大型语言模型（LLM）的工具原型。DUET将参考图和学生提交的图转换为文本表示，并利用多阶段LLM管道比较图并生成结构化反馈。该工具还为教育者提供分析洞察。

**Result:** 通过对六名参与者（包括两名教育者和四名助教）的半结构化访谈评估了DUET。参与者指出了其优点，如可访问性、可扩展性和学习支持，同时也提出了局限性，包括可靠性和潜在滥用。他们还建议了改进措施，如批量上传功能和交互式澄清功能。

**Conclusion:** DUET为将大型语言模型整合到建模教育中提供了一个有前景的方向，并为未来的课堂整合和实证评估奠定了基础。

> **ai_Abstract:** 本研究介绍了DUET，一个基于大型语言模型（LLM）的工具原型，旨在为学生生成的UML和ER图提供自动化、结构化反馈。针对传统教学难以提供可扩展个性化反馈的问题，DUET通过将图转换为文本表示并利用多阶段LLM管道进行比较和生成反馈。初步评估显示DUET在可访问性、可扩展性和学习支持方面具有优势，但也存在可靠性和潜在滥用等局限性，并提出了改进建议。该工具为LLM在建模教育中的应用提供了新方向。

> **摘要翻译:** UML和ER图是计算机科学教育的基础，但由于需要抽象思维、上下文理解以及对语法和语义的掌握，给学习者带来了挑战。这些复杂性很难通过传统的教学方法解决，因为传统方法往往难以提供可扩展的个性化反馈，尤其是在大型班级中。我们引入了DUET（Diagrammatic UML & ER Tutor），一个基于大型语言模型（LLM）的工具原型，它将参考图和学生提交的图转换为文本表示，并根据差异提供结构化反馈。它使用多阶段LLM管道来比较图并生成反思性反馈。此外，该工具还能为教育者提供分析洞察，旨在促进自主学习并指导教学策略。我们通过对六名参与者（包括两名教育者和四名助教）进行半结构化访谈评估了DUET。他们指出了其优点，如可访问性、可扩展性和学习支持，同时也提出了局限性，包括可靠性和潜在滥用。参与者还建议了潜在的改进措施，例如批量上传功能和交互式澄清功能。DUET为将LLM整合到建模教育中提供了一个有前景的方向，并为未来的课堂整合和实证评估奠定了基础。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [334] [The SPACE of AI: Real-World Lessons on AI's Impact on Developers](https://arxiv.org/abs/2508.00178)
> *人工智能的SPACE：人工智能对开发者影响的真实世界经验*

*Brian Houck, Travis Lowdermilk, Cody Beyer, Steven Clarke, Ben Hanrahan* | **Category: cs.HC, cs.AI, cs.SE** | **Updated: 2025-07-31**

**Keywords:** 人工智能影响, 开发者生产力, SPACE框架, 软件工程, 混合方法研究

**Comment:** 

> **TL;DR:** 一项混合方法研究发现，人工智能在软件开发中被广泛采用，能提高开发者的效率和满意度，尤其是在常规任务上。其益处因任务复杂度和团队支持而异，表明人工智能是辅助而非取代开发者，其有效整合依赖于团队文化和支持结构。

**AI_Comments:** 该论文通过混合方法研究，提供了人工智能在软件开发领域实际影响的宝贵见解，超越了纯理论探讨。其使用SPACE框架全面评估了AI对开发者多维度的影响，特别是强调了AI的辅助作用以及团队文化和组织支持对成功整合AI的关键性，这对于指导企业和团队有效采纳AI具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能工具日益融入软件开发工作流程，关于它们对开发者生产力和体验的真实影响仍存在疑问。本研究旨在探讨开发者如何看待人工智能在SPACE框架（满意度、绩效、活动、协作和效率）维度上的影响。

**Method:** 本研究采用混合方法，通过调查500多名开发者的反馈以及访谈和观察性研究的定性见解，来考察开发者如何感知人工智能的影响。

**Result:** 研究发现，人工智能被广泛采用，并普遍被认为能提高生产力，尤其是在常规任务上。然而，其益处因任务复杂性、个人使用模式和团队采纳程度而异。开发者报告效率和满意度提高，但对协作的影响证据较少。组织支持和同行学习在最大化人工智能价值方面发挥关键作用。这些发现表明人工智能是辅助而非取代开发者，其有效整合同样取决于团队文化和支持结构。

**Conclusion:** 人工智能是增强开发者能力而非取代他们，并且人工智能的有效整合在很大程度上取决于团队文化和支持结构，而非仅仅是工具本身。本研究为寻求在软件工程中利用人工智能潜力的团队、组织和研究人员提供了实用建议。

> **ai_Abstract:** 本研究采用混合方法，基于对500多名开发者的调查和定性访谈，探讨了人工智能工具对开发者生产力和体验的影响，并以SPACE框架（满意度、绩效、活动、协作、效率）进行评估。研究发现，人工智能被广泛采纳，能显著提升开发者在常规任务上的生产力、效率和满意度，但其效果因任务复杂度和团队采纳情况而异。结果表明，人工智能是辅助而非取代开发者，且其有效整合高度依赖于组织支持和团队文化。文章最后为软件工程中利用人工智能提供了实践建议。

> **摘要翻译:** 随着人工智能（AI）工具日益嵌入软件开发工作流程，关于它们对开发者生产力和体验的真实影响仍存在疑问。本文介绍了混合方法研究的结果，该研究考察了开发者如何看待人工智能在SPACE框架的各个维度上的影响：满意度、绩效、活动、协作和效率。我们根据500多名开发者的调查回复以及访谈和观察性研究的定性见解，发现人工智能被广泛采用，并普遍被认为能提高生产力，尤其是在常规任务上。然而，其益处因任务复杂性、个人使用模式和团队采纳程度而异。开发者报告效率和满意度提高，但对协作的影响证据较少。组织支持和同行学习在最大化人工智能价值方面发挥关键作用。这些发现表明人工智能是辅助而非取代开发者，并且其有效整合同样取决于团队文化和支持结构，而非仅仅是工具本身。我们最后为寻求在软件工程中利用人工智能潜力的团队、组织和研究人员提供了实用建议。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [336] [Policy Maps: Tools for Guiding the Unbounded Space of LLM Behaviors](https://arxiv.org/abs/2409.18203)
> *策略地图：指导LLM行为无限空间的工具*

*Michelle S. Lam, Fred Hohman, Dominik Moritz, Jeffrey P. Bigham, Kenneth Holstein, Mary Beth Kery* | **Category: cs.HC, cs.AI, cs.CL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 策略地图, LLM行为, AI政策, Policy Projector, 行为管理

**Comment:** UIST 2025

> **TL;DR:** 引入“策略地图”和交互工具“Policy Projector”，帮助AI从业者在LLM的广阔行为空间中设计和导航AI策略，以管理不当行为。

**AI_Comments:** 这篇论文提出了一种新颖且实用的方法来解决LLM行为管理中的核心挑战，即其行为空间的无限性。将AI政策设计类比为物理地图制作是一个富有创意的类比，它将难以捉摸的抽象问题具象化。Policy Projector作为具体工具的实现，提升了政策制定的交互性和可操作性。其创新点在于从“全面覆盖”转向“有效导航”，这对于实际应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）的广阔行为空间中，确保AI策略能够有效覆盖并设定可接受行为边界是一项挑战。

**Method:** 提出“策略地图”方法，灵感来源于实体地图绘制，通过有意的设计选择（捕获和抽象某些方面）来辅助有效导航，而非追求全面覆盖。同时，开发了交互工具“Policy Projector”，支持AI从业者调查模型输入-输出对，定义自定义区域（如“暴力”），并使用if-then策略规则（结合LLM分类和引导）来导航这些区域，并可视化策略工作。

**Result:** 在对12位AI安全专家的评估中，该系统帮助策略设计者围绕诸如不正确的性别假设和处理即时人身安全威胁等问题模型行为制定了策略。

**Conclusion:** “策略地图”和“Policy Projector”是有效指导LLM行为和制定策略的工具，尤其在处理大型语言模型中复杂且难以界定的行为问题方面表现出实用性。

> **ai_Abstract:** 本文提出“策略地图”概念和配套交互工具“Policy Projector”，旨在解决大型语言模型行为边界难以界定的挑战。该方法借鉴物理地图制作，通过选择性地捕获和抽象行为空间，帮助AI从业者更有效地导航和制定策略。Policy Projector允许用户定义特定行为区域并设置if-then规则来管理LLM输出。经12位AI安全专家评估，该系统在处理性别偏见和安全威胁等问题行为方面表现出有效性。

> **摘要翻译:** 人工智能政策为人工智能模型的行为设定了可接受的边界，但在大型语言模型（LLM）的背景下，这极具挑战性：如何确保覆盖广阔的行为空间？我们引入了策略地图，这是一种受实体地图制作实践启发的人工智能政策设计方法。策略地图不是旨在实现完全覆盖，而是通过有意地选择要捕获和抽象的方面来帮助有效导航。借助Policy Projector（一个用于设计LLM策略地图的交互式工具），AI从业者可以调查模型输入-输出对的景象，定义自定义区域（例如，“暴力”），并使用可以作用于LLM输出的if-then策略规则（例如，如果输出包含“暴力”和“图形细节”，则在不包含“图形细节”的情况下重写）来导航这些区域。Policy Projector支持使用LLM分类和引导进行交互式策略创作，并提供反映AI从业者工作的地图可视化。在对12位AI安全专家的评估中，我们的系统帮助策略设计者围绕诸如不正确的性别假设和处理即时人身安全威胁等问题模型行为制定了策略。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [351] [Breaking the mould of Social Mixed Reality -- State-of-the-Art and Glossary](https://arxiv.org/abs/2507.23454)
> *打破社交混合现实的固有模式——现状与词汇表*

*Marta Bieńkiewicz, Julia Ayache, Panayiotis Charalambous, Cristina Becchio, Marco Corragio, Bertram Taetz, Francesco De Lellis, Antonio Grotta, Anna Server, Daniel Rammer, Richard Kulpa, Franck Multon, Azucena Garcia-Palacios, Jessica Sutherland, Kathleen Bryson, Stéphane Donikian, Didier Stricker, Benoît Bardy* | **Category: cs.HC, cs.CY, cs.ET, cs.GR, q-bio.NC, I.3.0; I.2; J.4; K.4** | **Updated: 2025-08-01**

**Keywords:** 混合现实, 社交互动, 具身性, 词汇表, 人工智能伦理

**Comment:** pre-print

> **TL;DR:** 本文探讨了社交混合现实技术在真实复制人类具身性与社会运动交互方面的不足，并通过提供一个综合词汇表来推动以人为中心的MR技术发展，以实现更丰富的数字连接。

**AI_Comments:** 本文创新性地指出社交混合现实领域在具身性和社会交互方面的关键空白，并提出通过构建综合词汇表的方式来梳理和推动该领域的发展。其重要性在于强调了以人为中心的MR技术发展方向，并关注了责任AI、伦理设计和心理安全等重要议题，为未来MR系统的设计提供了重要的指导框架。

<details>
  <summary>Details</summary>

**Motivation:** 混合现实（MR）技术在真实复制人类具身性（embodiment）和社会运动交互（socio-motor interaction）方面存在关键性不足，限制了其实现有意义的社交体验。

**Method:** 本文提出了一个全面的词汇表，涵盖了虚拟角色与自主化、负责任的人工智能、设计伦理以及神经科学、具身性与技术中社交MR的科学挑战等关键主题。

**Result:** 论文提供了一个综合词汇表，涵盖了社交混合现实领域的重要概念和挑战，旨在推动以人为本的MR技术发展。

**Conclusion:** 为了实现有意义的社交混合现实体验，MR系统需要整合多模态数据流和多智能体交互能力，并且应优先考虑以人为中心的创新，增强人与虚拟自主智能体之间的社交互动和协作，同时确保包容性、伦理设计和心理安全。

> **ai_Abstract:** 本文指出了混合现实（MR）技术在真实再现人类具身性和社会运动交互方面的关键缺陷，认为这阻碍了有意义的社交体验。为解决此问题，作者提出了一个全面的词汇表，涵盖了虚拟角色、负责任AI、伦理设计以及社交MR的科学挑战等核心议题。研究旨在推动以人为本的MR技术发展，以实现更丰富的数字连接，并倡导开发能够增强人与虚拟智能体间社交互动、同时确保包容性、伦理性和心理安全的MR系统。

> **摘要翻译:** 这篇文章探讨了混合现实（MR）技术中的一个关键空白：尽管取得了进步，MR在真实复制人类具身性（embodiment）和社会运动交互（socio-motor interaction）方面仍然面临困难。为了让MR能够实现真正有意义的社交体验，它需要整合多模态数据流和多智能体交互能力。为了应对这一挑战，我们提出了一个全面的词汇表，涵盖了虚拟角色与自主化、负责任的人工智能、设计伦理以及神经科学、具身性与技术中社交MR的科学挑战等关键主题。我们的目标是推动MR技术的变革性发展，优先考虑以人为本的创新，促进更丰富的数字连接。我们倡导MR系统能够增强人类与虚拟自主智能体之间的社交互动和协作，并在此过程中确保包容性、伦理设计和心理安全。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [359] [Digital literacy interventions can boost humans in discerning deepfakes](https://arxiv.org/abs/2507.23492)
> *数字素养干预可提高人类识别深度伪造的能力*

*Dominique Geissler, Claire Robertson, Stefan Feuerriegel* | **Category: cs.HC, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 数字素养, 深度伪造, 图像识别, 干预措施, 信息信任

**Comment:** 

> **TL;DR:** 数字素养干预措施能有效提高人们识别深度伪造图像的能力，同时保持对真实图像的信任。

**AI_Comments:** 该研究的创新之处在于系统性地比较了多种数字素养干预措施，并量化了其对深度伪造识别的积极影响。其重要性在于提供了一种可扩展且有效的解决方案，以应对深度伪造带来的社会信任危机和信息安全挑战。特别强调了在提高识别能力的同时维护对真实信息的信任，这是非常关键的一点。研究结果对于数字素养教育和公共政策制定具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 深度伪造图像（由AI生成）正在侵蚀机构信任并可能影响选举结果，因为人们难以辨别真实图像和深度伪造图像。虽然提高数字素养有助于解决这些问题，但可扩展且有效的方法仍未被充分探索。

**Method:** 研究比较了五种数字素养干预措施在提高人们识别深度伪造能力方面的效果：1) 深度伪造常见指标的文本指导；2) 这些指标的视觉演示；3) 识别深度伪造的游戏化练习；4) 通过重复接触和反馈的隐性学习；5) 解释深度伪造如何通过AI生成。实验招募了1200名美国参与者，测试了干预措施的即时和长期效果。

**Result:** 干预措施能将深度伪造识别能力提高多达13个百分点，同时保持对真实图像的信任。

**Conclusion:** 研究结果表明，所提出的方法具有可扩展性，适用于不同人群，并且在提高深度伪造检测能力的同时，能有效保持对真实信息的信任。

> **ai_Abstract:** 本研究探讨了五种数字素养干预措施在提高人们识别深度伪造图像能力方面的有效性。通过对1200名美国参与者的实验，结果显示这些干预措施能将深度伪造识别能力提升高达13个百分点，同时保持对真实图像的信任。研究强调了其方法的可扩展性、普适性以及在增强深度伪造检测和维护信息信任方面的有效性。

> **摘要翻译:** 深度伪造，即人工智能（AI）生成的图像，可以侵蚀对机构的信任并损害选举结果，因为人们常常难以辨别真实图像和深度伪造图像。提高数字素养有助于解决这些挑战，但可扩展且有效的方法仍未被充分探索。在此，我们比较了五种数字素养干预措施的效力，以提高人们识别深度伪造的能力：(1) 关于深度伪造常见指标的文本指导；(2) 这些指标的视觉演示；(3) 识别深度伪造的游戏化练习；(4) 通过重复接触和反馈的隐性学习；以及(5) 借助AI解释深度伪造的生成方式。我们对1200名美国参与者进行了一项实验，以测试我们干预措施的即时和长期有效性。我们的结果表明，我们的干预措施可以将深度伪造识别能力提高多达13个百分点，同时保持对真实图像的信任。总而言之，我们的方法具有可扩展性，适用于不同人群，并且在提高深度伪造检测能力的同时，能非常有效地保持对真实信息的信任。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [360] [Multidimensional Assessment of Takeover Performance in Conditionally Automated Driving](https://arxiv.org/abs/2507.22252)
> *有条件自动驾驶中接管性能的多维度评估*

*Kexin Liang, Jan Luca Kästle, Bani Anvari, Simeon C. Calvert, J. W. C. van Lint* | **Category: cs.HC** | **Updated: 2025-07-31**

**Keywords:** 接管性能, 情境意识, 备用能力, 有条件自动驾驶, XGBoost

**Comment:** 

> **TL;DR:** 本研究通过驾驶模拟器实验，多维度评估了有条件自动驾驶中驾驶员的接管性能，发现情境意识（SA）和备用能力（SC）对响应效率、用户体验和驾驶安全有不同但互补的影响。

**AI_Comments:** 这篇论文通过多维度评估和机器学习模型，深入分析了情境意识和备用能力在有条件自动驾驶接管过程中的关键作用，为未来自动驾驶系统的人机交互设计和安全性提升提供了重要的实证依据。其创新点在于结合了用户体验和驾驶安全等多维度评估，并量化了SA和SC的影响。

<details>
  <summary>Details</summary>

**Motivation:** 当自动驾驶系统遇到超出操作能力的复杂情况并发出接管请求时，驾驶员需要及时响应并进行高质量干预。为了确保安全舒适的控制转换，深入理解影响接管性能的关键因素至关重要。

**Method:** 本研究使用驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估驾驶员的接管性能。采用极限梯度提升（XGBoost）模型，通过与仅依赖基本驾驶员特征（DC）的基线模型进行比较，研究情境意识（SA）和备用能力（SC）对预测各种接管性能指标的贡献。

**Result:** 研究结果显示：(i) 更高的情境意识（SA）能使驾驶员更快地响应接管请求，尤其是在反射性响应方面；(ii) 备用能力（SC）对接管质量的整体影响大于情境意识（SA），更高的SC通常会带来更高的主观评分和客观执行轨迹。

**Conclusion:** 情境意识（SA）和备用能力（SC）在塑造接管性能组成部分方面扮演着独特而互补的角色，为优化人车交互和增强自动驾驶系统设计提供了宝贵的见解。

> **ai_Abstract:** 本研究通过驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估了有条件自动驾驶中驾驶员的接管性能。利用XGBoost模型，探讨了情境意识（SA）和备用能力（SC）对不同接管性能指标的贡献。结果表明，SA能提高响应速度，特别是反射性响应；而SC对接管质量的整体影响更大，能提升主观评分和客观执行轨迹。研究强调了SA和SC在塑造接管性能中的独特且互补作用，为优化人车交互和自动驾驶系统设计提供了见解。

> **摘要翻译:** 当自动驾驶系统遇到超出其操作能力范围的复杂情况时，它们会发出接管请求，提示驾驶员恢复车辆控制并返回驾驶循环，作为关键的安全备份。然而，这种控制转换对驾驶员提出了很高的要求，需要他们及时响应接管请求，同时执行高质量的干预。为了确保安全舒适的控制转换，深入理解影响各种接管性能方面的关键因素至关重要。本研究通过驾驶模拟器实验，从响应效率、用户体验和驾驶安全三个维度评估了驾驶员的接管性能。采用极限梯度提升（XGBoost）模型，通过将预测结果与仅依赖基本驾驶员特征（DC）的基线模型进行比较，研究了情境意识（SA）和备用能力（SC）这两个关键因素在预测各种接管性能指标方面的贡献。结果显示：(i) 更高的情境意识（SA）使驾驶员能够更快地响应接管请求，特别是对于反射性响应；(ii) 备用能力（SC）对接管质量的整体影响大于情境意识（SA），其中更高的SC通常会带来更高的主观评分和客观执行轨迹。这些发现突出了SA和SC在塑造性能组成部分方面的独特而互补的作用，为优化人车交互和增强自动驾驶系统设计提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [409] [Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation](https://arxiv.org/abs/2507.22892)
> *混合脑电图驱动的脑机接口：一个用于个性化语言康复的大语言模型框架*

*Ismail Hossain, Mridul Banik* | **Category: cs.HC, cs.CL** | **Updated: 2025-06-18**

**Keywords:** 脑电图, 脑机接口, 大语言模型, 语言康复, 个性化

**Comment:** 

> **TL;DR:** 该研究提出了一个结合脑电图（EEG）驱动的脑机接口（BCI）与大语言模型（LLM）的混合框架，旨在为患有严重言语或运动障碍的用户提供个性化的语言康复。

**AI_Comments:** 这项研究的创新之处在于将脑电图驱动的脑机接口与大语言模型相结合，为语言康复提供了一个高度个性化和自适应的解决方案。它有望显著改善神经系统疾病患者的语言学习和沟通能力。该框架通过整合神经意图捕捉和上下文语言生成，克服了现有系统的局限性，具有重要的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的辅助沟通（AAC）系统和语言学习平台无法实时适应用户的认知和语言需求，特别是在中风后失语症或肌萎缩侧索硬化症等神经系统疾病患者中。

**Method:** 该论文提出并评估了一种新颖的混合框架，该框架利用实时脑电图信号来驱动一个由大语言模型支持的语言康复助手。该系统旨在通过精神指令使用户能够导航语言学习模块，动态个性化词汇、句子构建练习和纠正反馈，并监测认知努力的神经标记以实时调整任务难度。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文提出了一个创新的混合框架，结合脑电图驱动的脑机接口（BCI）与大语言模型（LLM），旨在解决传统语言康复系统在适应用户个性化需求方面的不足。该系统通过实时EEG信号驱动LLM，使患有严重言语或运动障碍的用户能通过意念指令进行语言学习，并能动态调整学习内容和难度，提供个性化的康复体验。

> **摘要翻译:** 传统的增强和替代沟通（AAC）系统和语言学习平台往往无法实时适应用户的认知和语言需求，尤其是在中风后失语症或肌萎缩侧索硬化症等神经系统疾病中。非侵入性脑电图（EEG）脑机接口（BCI）和基于Transformer的大语言模型（LLM）的最新进展提供了互补的优势：BCI以低疲劳度捕捉用户的神经意图，而LLM则生成符合语境的语言内容。我们提出并评估了一个新颖的混合框架，该框架利用实时脑电图信号来驱动一个由LLM支持的语言康复助手。该系统旨在：（1）使有严重言语或运动障碍的用户能够通过心理指令导航语言学习模块；（2）动态个性化词汇、句子构建练习和纠正反馈；以及（3）监测认知努力的神经标记以实时调整任务难度。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [425] [Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment](https://arxiv.org/abs/2507.22898)
> *语音引导的临床评估协同智能 (VOICE)：一种院前卒中评估语音人工智能代理系统*

*Julian Acosta, Scott Adams, Julius Kernbach, Romain Hardy, Sung Eun Kim, Luyang Luo, Xiaoman Zhang, Shreya Johri, Mohammed Baharoon, Pranav Rajpurkar* | **Category: cs.HC, cs.CL** | **Updated: 2025-06-25**

**Keywords:** 语音AI, 卒中评估, 院前护理, 紧急医疗, 人工智能

**Comment:** 

> **TL;DR:** VOICE是一个语音驱动的AI系统，旨在通过自然对话和视频捕捉，指导非专业人员进行院前卒中评估，以解决当前急救中卒中识别不准确的问题。

**AI_Comments:** VOICE系统通过语音交互将专家级卒中评估能力普及到非专业人员手中，这一创新性方法有望解决院前卒中识别不准确的关键问题，具有重要的临床应用潜力。然而，当前系统在准确性方面仍存在局限性，尤其是在区分非卒中病例和为医生提供足够信心以做出初步治疗决策方面，这表明在实际部署前仍需进一步改进和验证。

<details>
  <summary>Details</summary>

**Motivation:** 当前急救人员对卒中的识别不一致且常不准确，卒中检测的敏感性低至58%，导致治疗出现危及生命的延误。

**Method:** 研究开发了一个名为VOICE的语音驱动人工智能系统，该系统通过自然对话指导用户进行专家级卒中评估，并支持智能手机视频捕捉关键检查组件。该系统由三名非医疗志愿者对十名模拟卒中患者（包括可能的大血管闭塞性卒中和类卒中情况）进行了评估，测量了诊断准确性、完成时间、用户信心和专家医生对AI生成报告的审查。

**Result:** AI系统正确识别了84%的个体卒中体征，检测到75%的可能大血管闭塞性卒中，评估耗时略超过6分钟。用户报告了高信心（中位数4.5/5）和易用性（平均4.67/5）。系统成功识别了86%的实际卒中，但也错误地将3个非卒中病例中的2个标记为卒中。专家医生在审查带有视频的AI报告时，100%的病例得到了正确诊断，但由于观察到的AI错误（包括评分不正确和虚假信息），仅在40%的病例中对初步治疗决策有足够信心。

**Conclusion:** 尽管当前系统存在局限性，需要人工监督，但语音到语音AI模型的快速发展预示着未来版本能够实现高度准确的评估。实现人类水平的语音交互可能彻底改变紧急医疗护理，使专家知情的评估能力普及到每个人手中。

> **ai_Abstract:** 该研究开发了VOICE，一个语音驱动的AI系统，旨在通过自然对话和智能手机视频捕捉，为非专业人员提供院前卒中评估指导。系统在模拟测试中显示出对卒中体征和LVO的较高识别率，且用户信心和易用性高。然而，系统存在一定的误报，且专家医生在审查AI报告时，尽管能做出正确诊断，但对初步治疗决策的信心有限。研究认为，尽管当前版本需人工监督，但未来语音AI的进步有望实现更准确的评估，从而革新紧急医疗护理。

> **摘要翻译:** 我们开发了一个语音驱动的人工智能（AI）系统，该系统能够通过自然对话指导任何人——从护理人员到家庭成员——进行专家级别的卒中评估，同时还能够通过智能手机视频捕捉关键检查组件，以便记录和潜在的专家审查。这解决了紧急护理中的一个关键空白：目前急救人员对卒中的识别不一致且常不准确，卒中检测的敏感性低至58%，导致治疗出现危及生命的延误。三名非医疗志愿者使用我们的AI系统评估了十名模拟卒中患者，包括可能的大血管闭塞（LVO）卒中和类卒中情况，我们测量了诊断准确性、完成时间、用户信心以及专家医生对AI生成报告的审查。该AI系统正确识别了84%的个体卒中体征，检测到75%的可能LVO，并在6分多钟内完成了评估。用户报告了高信心（中位数4.5/5）和易用性（平均4.67/5）。该系统成功识别了86%的实际卒中，但也错误地将3个非卒中病例中的2个标记为卒中。当专家医生审查带有视频的AI报告时，他们在100%的病例中识别出正确诊断，但由于观察到的AI错误，包括评分不正确和虚假信息，仅在40%的病例中对初步治疗决策有足够信心。尽管当前系统的局限性需要人工监督，但语音到语音AI模型持续快速的进步表明，未来版本有望实现高度准确的评估。实现人类水平的语音交互可以改变紧急医疗护理，将专家知情的评估能力普及到每个人手中。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [437] [Real-time energy monitoring infrastructure for residential collective self-consumption operations using Linky meter](https://arxiv.org/abs/2507.22891)
> *基于Linky电表的住宅集体自用电实时能源监测基础设施*

*Jérôme Ferrari, Benoit Delinchant, Frédéric Wurtz, Olga Rouchouze* | **Category: cs.HC** | **Updated: 2025-06-17**

**Keywords:** 实时监测, 集体自用电, Linky电表, 能源转型, 开源基础设施

**Comment:** Cired 2025, Jun 2025, Gen{\`e}ve (CH), Switzerland

> **TL;DR:** 本文介绍了一种新的开源实时能源监测基础设施，利用Linky电表数据，帮助法国集体自用电项目的参与者实时调整用电行为，以提高自用电率。

**AI_Comments:** 该论文的创新点在于提出了一个开源的、基于Linky电表的实时能源监测基础设施，有效解决了现有“日+1”数据滞后性问题。其重要性在于能够赋能用户实时管理能源消费，对于提升集体自用电效率和促进能源转型具有积极意义。该方案的通用性和可扩展性是其潜在优势。

<details>
  <summary>Details</summary>

**Motivation:** 在能源转型和能源价格上涨的背景下，法国的集体自用电项目数量不断增加。然而，当前的能源流量监测依赖于Linky电表提供的历史“日+1”数据，无法提供实时反馈，导致参与者难以调整其能源消费行为。

**Method:** 本文引入了一种基于Linky电表数据的开源实时监测基础设施，包括描述了xKy设备，并将其应用于一个涉及九名参与者的集体自用电项目。该项目包括在参与者家中部署网关，并开发和运营实时监测网站。

**Result:** 该系统旨在使参与者能够做出明智的决策并及时采取行动，从而提高参与者的自用电率。

**Conclusion:** 该文提出的实时监测基础设施能够有效解决当前能源监测滞后问题，赋能用户实时调整用电行为，有望提升集体自用电项目的效率和自用电率。

> **ai_Abstract:** 针对法国集体自用电项目当前依赖滞后数据导致用户无法实时调整用电行为的问题，本文提出并实现了一种基于Linky电表的开源实时能源监测基础设施。该系统通过部署xKy设备和家庭网关，并开发实时监测网站，旨在为参与者提供即时能源反馈，从而帮助他们做出明智决策，提高自用电率。

> **摘要翻译:** 作为能源转型和能源价格上涨的一部分，法国的集体自用电项目数量正在稳步增长。然而，当前的能源流量监测依赖于Linky电表提供的历史“日+1”数据，这无法提供实时反馈来帮助参与者调整其能源消费行为。本文介绍了一种新的基于Linky电表数据的开源实时监测基础设施，使参与者能够做出明智的决策并及时采取行动。它包括对xKy设备的描述，该设备应用于一个由能源转型观察站（OTE）支持的、涉及九名参与者的集体自用电项目。该项目包括在参与者家中实施网关以及开发和运营实时监测网站，旨在提高参与者的自用电率。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [455] [When no one shows up (at first): Navigating the uncertainties of participatory workshops in interdisciplinary research](https://arxiv.org/abs/2507.22894)
> *当无人出现时（起初）：驾驭跨学科研究中参与式工作坊的不确定性*

*Monique Munarini* | **Category: cs.HC** | **Updated: 2025-06-20**

**Keywords:** 参与式工作坊, 跨学科研究, 早期职业研究人员, 协同设计, 生活经验

**Comment:** Presented at HHAI25:The 4th International Conference Series on Hybrid
  Human-Artificial Intelligence, workshop Mind the AI-GAP 2025:Co-Designing
  Socio-Technical Systems. (June 9-13, 2025 in Pisa, Italy)

> **TL;DR:** 本文探讨了设计和促成参与式工作坊中常被忽视的挑战，为早期职业研究人员提供了应对低参与度等不确定性的实用策略，并强调了将感知到的失败转化为学习机会以及生活经验在研究中的核心地位。

**AI_Comments:** 本文的创新之处在于其对参与式研究“混乱”现实的坦诚反思，尤其关注了低参与度等不那么光鲜的方面。其重要性在于为早期职业研究人员提供了接地气的实用建议，将挑战重新定义为学习机会，并强调了生活经验在研究中的核心价值，这对公平的研究实践至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探讨在设计和促成协同设计和参与式工作坊时常被忽视的挑战，并为早期职业研究人员（ECRs）提供实用策略，特别是当参与度不符合预期时，以帮助他们驾驭这些方法。

**Method:** 本文是一篇反思性论文，借鉴了作者在组织一系列名为“如何在人工智能生态系统中思考公平”的工作坊中的亲身经验。它追踪了工作坊从概念化、活动规划到参与者招募和促成的完整过程，并审视了在缺乏机构支持、经济激励或未整合到大型活动中时，吸引非专家参与者的方法论挑战。

**Result:** 尽管初期面临参与人数不足等困难，但工作坊在人口结构多元的群体中促成了丰富的讨论，并最终促使一名参与者自愿共同促成后续会议。这种从参与者到共同促成者的转变，例证了认知权威的重新分配。

**Conclusion:** 本文通过将感知到的失败重新定义为富有成效的学习场所，为跨学科工作的早期职业研究人员提供了实用策略，这些研究人员经常驾驭不熟悉的方法论领域，从而促进了关于实践中进行跨学科、参与性工作的现实的更广泛对话。它强调了将生活经验置于研究和参与实践的核心地位。

> **ai_Abstract:** 本文是一篇反思性论文，探讨了早期职业研究人员在设计和促成参与式工作坊中遇到的实际挑战，特别是当参与度低于预期时。作者通过分享其“如何在人工智能生态系统中思考公平”系列工作坊的亲身经验，详细阐述了从规划到执行的整个过程。尽管面临初步的参与不足和缺乏外部支持，工作坊仍促成了深入的讨论，并成功地将一名参与者转变为共同促成者，这凸显了生活经验的价值和认知权威的重新分配。本文将感知到的失败视为宝贵的学习机会，为跨学科背景下的参与式研究提供了实用的应对策略。

> **摘要翻译:** 这篇反思性论文探讨了设计和促成协同设计和参与式工作坊中常被忽视的挑战，为早期职业研究人员（ECRs）提供了应对这些方法的实用策略。论文借鉴了个人经验，即开展了一系列名为“如何在人工智能生态系统中思考公平”的工作坊。它追踪了工作坊体验的完整过程，从概念化和活动规划到参与者招募和促成，提供了一个关于当参与不符合预期时所发生情况的扎实描述。论文审视了吸引非专家参与者的方法论挑战，特别是在缺乏机构支持、经济激励或未整合到大型活动中的情况下。尽管初期面临参与人数不足等困难，但工作坊在一个人口结构多元的群体中促成了丰富的讨论，并最终促使一名参与者自愿共同促成后续会议。这种从参与者到共同促成者的转变，例证了认知权威的重新分配，将生活经验置于研究和参与实践的核心地位。通过将感知到的失败重新定义为富有成效的学习场所，论文为跨学科工作的早期职业研究人员提供了实用策略，这些研究人员经常驾驭不熟悉的方法论领域，从而促进了关于实践中进行跨学科、参与性工作的现实的更广泛对话。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [489] [Brain motor intention Extraction Amplifier: Non-invasive brain-muscle interface](https://arxiv.org/abs/2507.22895)
> *脑运动意图提取放大器：非侵入式脑肌接口*

*Ye Sun, Bowei Zhao, Dezhong Yao, Rui Zhang, Bohan Zhang, Xiaoyuan Li, Jing Wang, Mingxuan Qu, Gang Liu* | **Category: cs.HC** | **Updated: 2025-06-21**

**Keywords:** 脑机接口, 脑肌接口, 运动意图, 非侵入式, 肌电图

**Comment:** 18 pages, 9 figures

> **TL;DR:** 该论文提出了一种非侵入式脑肌接口（BMuI），通过利用肌电图（EMG）作为高保真中继，改善BCI中的运动意图解码，并验证了其可行性和有效性。

**AI_Comments:** 本文的创新之处在于利用脑肌接口（BMuI）来改善运动意图解码，巧妙地将EMG作为高保真中继。这种方法直接解决了传统运动想象BCI中伪标签的问题，通过模拟更自然的神经通路，有望构建更鲁棒和准确的BCI系统。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于运动的脑机接口（BCI）范式，如运动想象BCI，存在标签不精确的问题，导致EEG信号与真实行为意图不匹配，产生伪标签，从而损害解码精度和系统鲁棒性。

**Method:** 本文提出了一种基于非侵入式脑肌接口（BMuI）的新型运动意图提取框架。该方法模拟从大脑到肌肉的神经通路，以捕获和增强来自大脑的微弱运动意图信号，并利用EMG作为高保真中继介质，实现更准确的意图识别和传输。通过离线和在线实验验证了其可行性和有效性。

**Result:** 离线实验结果表明BMuI是可行的，预测准确率达到0.8314；在线实验中，所有参与者都能够成功控制Unity虚拟手臂。

**Conclusion:** BMuI方法对于提高BCI中的运动意图识别和控制是可行且有效的。

> **ai_Abstract:** 本文提出了一种新颖的非侵入式脑肌接口（BMuI）框架，旨在解决传统基于运动的BCI中运动意图解码不精确的问题。通过模拟脑-肌神经通路并利用肌电图（EMG）作为高保真中继，BMuI旨在捕获和放大微弱的脑运动意图信号，以实现更准确的识别。实验结果证实了BMuI的可行性，在离线测试中预测准确率为0.8314，并在在线实验中实现了对虚拟手臂的成功实时控制。

> **摘要翻译:** 脑机接口（BCI）通过解码神经信号实现大脑与外部设备的实时交互。然而，现有的基于运动的BCI范式，如运动想象BCI，在实际使用中面临标签不精确的挑战。脑电图（EEG）信号与真实行为意图之间的这种不匹配导致伪标签，从而损害解码精度和系统鲁棒性。为了克服这一瓶颈，本文首次提出了一种基于非侵入式脑肌接口（BMuI）的新型运动意图提取框架（$	ext{BCI} = \frac{\text{Brain}}{\text{Computer}} \text{ Interface} = \frac{\text{Brain}}{\not\text{Muscle}}\! \text{ (BMuI)} \times \!\frac{\not\text{Muscle}}{\text{Computer}}\! \text{ Interface}$）。该方法模拟了从大脑到肌肉的神经通路，以捕获和增强源自大脑的微弱运动意图信号。然后，它利用肌电图（EMG）作为高保真中继介质，实现更准确的意图识别和传输。为了系统地验证该方法的可行性和有效性，我们进行了离线实验（重复验证可行性）和在线实验（构建实时交互系统并评估其性能）。结果表明，BMuI是可行的，预测准确率达到0.8314；在在线实验中，所有参与者都能够成功控制Unity虚拟手臂。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [517] [A visual analytics tool for taxonomy-based trajectory data exploration](https://arxiv.org/abs/2507.22899)
> *一种基于分类学的轨迹数据探索可视化分析工具*

*Ivan A. Hanono Cozzetti, Ahmad Abdou* | **Category: cs.HC** | **Updated: 2025-06-26**

**Keywords:** 时空数据分析, 可视化工具, 轨迹数据, 机器学习, 分类学

**Comment:** 71 pages, 92 figures

> **TL;DR:** 该项目提出了一种结合数据可视化和统计计算的可视化分析工具，通过多层次方法对时空数据进行分析，并利用机器学习模型将移动对象分类，以揭示复杂的运动模式。

**AI_Comments:** 该论文提出了一种创新的可视化分析工具，通过结合机器学习和统计计算，有效地解决了时空数据分析的复杂性。其亮点在于能够将复杂的轨迹数据结构化，并通过具体案例展示了其在识别和解释特定行为模式方面的强大能力，为跨领域应用提供了宝贵的框架。

<details>
  <summary>Details</summary>

**Motivation:** 由于运动模式的复杂性和异构性，时空数据分析面临巨大挑战，本项目旨在提出一种工具来促进时空数据分析。

**Method:** 该工具结合数据可视化和统计计算，采用多层次方法，并利用机器学习模型将移动对象分类到不同的分类学中。

**Result:** 在北极狐轨迹案例研究中，成功识别并标记了具有几何或运动学行为的狐狸，并进一步分为曲率和加速度组。统计指标显示，具有加速度行为的狐狸表现出恒定、稳定的加速度，而具有曲率行为的狐狸则表现出加速度峰值和突然减速。在热带气旋数据案例研究中，通过独特的统计变量标记了具有速度、曲率和混合几何行为的轨迹。对混合几何行为（曲率和压痕结合）的分析确定了对飓风形状和几何结构影响最大的特定角度。

**Conclusion:** 该方法和工具表明，尽管时空数据固有的复杂性，但仍可以对其进行详细分析和解释，为多个领域提供了理论和实践蓝图。

> **ai_Abstract:** 本研究提出了一种用于时空数据分析的可视化工具，该工具结合了数据可视化、统计计算和机器学习，以处理复杂的运动模式。通过将移动对象分类到不同的分类学中，该工具为数据分析提供了结构。通过北极狐轨迹和热带气旋数据的案例研究，证明了该工具在识别和解释不同行为模式方面的有效性，并为多领域应用提供了理论和实践框架。

> **摘要翻译:** 时空数据分析由于运动模式的复杂性和异构性而面临巨大挑战。本项目提出了一种数据分析工具，该工具结合了数据可视化和统计计算，通过多层次方法促进时空数据分析。该工具使用机器学习模型将移动对象分类为不同的分类学，为分析增加了有意义的结构。两个案例研究证明了该方法的有效性。第一个案例研究分析了北极狐的轨迹，成功识别并标记了具有几何或运动学行为的狐狸，并进一步分为曲率和加速度组。统计指标显示，具有加速度行为的狐狸表现出恒定、稳定的加速度，而具有曲率行为的狐狸则表现出加速度峰值和突然减速。第二个案例研究检查了热带气旋数据，通过独特的统计变量标记了具有速度、曲率和混合几何行为的轨迹。对混合几何行为（曲率和压痕结合）的分析确定了对飓风形状和几何结构影响最大的特定角度。所提出的方法和工具表明，尽管时空数据固有的复杂性，但仍可以对其进行详细分析和解释，为多个领域提供了理论和实践蓝图。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [552] [Accelerated and Optimized Search of Imperceptible Color Vibration for Embedding Information into LCD images](https://arxiv.org/abs/2507.22901)
> *加速和优化不可察觉颜色振动搜索以在LCD图像中嵌入信息*

*Shingo Hattori, Takefumi Hiraki* | **Category: cs.HC** | **Updated: 2025-06-27**

**Keywords:** 不可察觉颜色振动, 信息嵌入, LCD图像, 并行搜索, 公共显示

**Comment:** Presented at ACM SIGGRAPH Asia 2022 Posters

> **TL;DR:** 本论文提出了一种加速和优化在LCD图像中嵌入不可察觉颜色振动信息的搜索方法，以解决现有方法搜索时间过长的问题。

**AI_Comments:** 该论文解决了隐形信息嵌入技术（颜色振动）的一个关键实际限制——搜索时间过长。通过引入并行化搜索，它为这种通信方法在公共显示器中的实际应用铺平了道路，具有重要的实用价值。其创新点在于对现有方法的效率提升，使其更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 公共显示器需要一种不影响显示内容的方式来与带有摄像头和传感器的设备进行通信。现有方法如显示二维码会损害图像外观，而先前的颜色振动方法在搜索颜色对时因巨大的搜索空间而导致处理时间过长。

**Method:** 本文提出了一种加速和优化不可察觉颜色振动颜色对的搜索方法。通过使用表示移动量的数组和从数组中提取满足条件的元素的操作，将之前单独进行的搜索过程并行化，从而实现快速颜色对搜索。此外，还研究了使用不可察觉颜色振动在九种彩色图像上可叠加的信息量。

**Result:** 本文提出了一种加速和优化颜色对搜索的方法，并研究了使用不可察觉颜色振动在九种彩色图像上可叠加的信息量，阐明了使用颜色振动将信息嵌入图像的适用性。

**Conclusion:** 通过提出加速和优化的搜索方法，使不可察觉颜色振动在LCD图像中嵌入信息变得更加实用，并明确了该技术的适用性。

> **ai_Abstract:** 本论文针对在LCD图像中嵌入不可察觉颜色振动信息时，现有颜色对搜索方法耗时过长的问题，提出了一种加速和优化的搜索方法。通过并行化搜索过程并利用数组操作，显著提高了搜索效率。此外，研究还评估了该技术在不同颜色图像上的信息嵌入能力，并明确了其应用可行性，旨在实现公共显示器与设备之间不影响视觉效果的隐形通信。

> **摘要翻译:** 城市中安装了大量高分辨率显示器作为公共显示屏。通过在这些显示屏的图像上叠加不可见信息，大量带有摄像头和传感器的设备无需事先配对即可与显示屏通信。已经提出了几种应用，例如操作机器人或通过在图像上显示二维码向用户传递信息。然而，显示二维码存在损害显示内容外观的问题。
Abe等人提出了一种通过在市售液晶显示器（LCD）上显示的图像上使用颜色振动叠加不可见信息来与设备通信的方法。使用这种方法，我们可以在不干扰显示内容的情况下将设备信息嵌入图像中。Abe等人使用简单的串行循环操作来搜索构成颜色振动的颜色对，由于搜索空间巨大，这需要非常长的处理时间。
在本文中，我们提出了一种加速和优化搜索方法，用于在LCD图像中嵌入信息的不可察觉颜色振动的颜色对。为了实现快速颜色对搜索，我们通过使用表示移动量的数组和从数组中提取满足条件的元素的操作，将之前单独进行的搜索过程并行化。此外，我们还研究了使用不可察觉颜色振动在九种彩色图像上可叠加的信息量，并阐明了使用颜色振动将信息嵌入图像的适用性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [587] [A blessing or a burden? Exploring worker perspectives of using a social robot in a church](https://arxiv.org/abs/2507.22903)
> *是福是祸？探讨教堂工作人员对使用社交机器人的看法*

*Andrew Blair, Peggy Gregory, Mary Ellen Foster* | **Category: cs.HC, cs.RO** | **Updated: 2025-06-28**

**Keywords:** 社交机器人, 教堂, 工作人员视角, 人机协作, 非营利组织

**Comment:** Accepted by the 2025 34th IEEE International Conference on Robot and
  Human Interactive Communication (ROMAN)

> **TL;DR:** 本研究探讨了教堂工作人员对在教堂中使用社交机器人的看法，发现存在复杂反应，既有对同理心责任和潜在意外后果的担忧，也有对信息提供和减轻繁琐任务的潜在用途的认可。研究强调在引入机器人时需考虑社会和无形价值。

**AI_Comments:** 本研究的创新之处在于将机器人应用的研究范围扩展到非营利和以社会效益为导向的组织，如教堂，这与以往多关注商业利润的场景不同。它揭示了在这些特殊环境中引入机器人时，除了技术和经济因素外，情感、责任和社会价值等无形因素的重要性，为未来人机协作的设计和部署提供了宝贵的见解。该研究的局限性可能在于样本量较小，且仅限于一个特定机构。

<details>
  <summary>Details</summary>

**Motivation:** 当前对机器人在以社会效益而非利润为主要驱动的真实世界组织中的应用关注不足。本研究旨在探索这些机会，特别是在教堂环境中引入社交机器人对工作人员的影响。

**Method:** 研究与一个正在运营的教堂和旅游景点合作，对来自教堂内不同利益相关者群体的15名参与者进行了访谈，并使用反思性主题分析法对结果进行了分析。

**Result:** 研究发现，参与者对使用机器人反应不一，他们强调教堂对人的同理心责任以及可能产生的意想不到的后果。然而，信息提供和减轻繁琐或日常任务被认为是潜在的用例。

**Conclusion:** 研究强调，在引入机器人时，不仅要考虑财务方面，还要考虑社会和无形价值如何塑造机器人在组织中应扮演的角色。

> **ai_Abstract:** 本研究探讨了教堂工作人员对引入社交机器人的看法。通过对15名教堂利益相关者进行访谈并进行主题分析，结果显示工作人员对机器人持复杂态度，既担忧其对人际互动和责任的影响，也认为其在信息提供和减轻繁琐任务方面有潜在用途。研究强调，在非营利组织中引入机器人时，除了经济效益外，还需充分考虑其社会和无形价值。

> **摘要翻译:** 最近的技术进步使得机器人能够协助服务业，并因此加速了就业和行业转型。然而，对于机器人在以社会效益而非利润为主要驱动的真实世界组织中的应用关注较少。为了探索这些机会，我们与一个正在运营的教堂和旅游景点合作。我们对来自教堂内不同利益相关者群体的15名参与者进行了访谈，以了解工作人员对在教堂中引入社交机器人的看法，并使用反思性主题分析法对结果进行了分析。研究结果表明，对使用机器人的反应不一，参与者强调教堂对人的同理心责任以及可能产生的意想不到的后果。然而，信息提供和减轻繁琐或日常任务被认为是潜在的用例。这突出表明，在引入机器人时，不仅需要考虑财务方面，还需要考虑社会和无形价值如何塑造机器人在组织中应扮演的角色。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [622] [Exploring LLM-generated Culture-specific Affective Human-Robot Tactile Interaction](https://arxiv.org/abs/2507.22905)
> *探索LLM生成文化特定情感人机触觉交互*

*Qiaoqiao Ren, Tony Belpaeme* | **Category: cs.HC** | **Updated: 2025-07-02**

**Keywords:** LLM, 情感触觉, 人机交互, 文化特异性, 触觉行为

**Comment:** 

> **TL;DR:** 本研究探讨了LLM生成文化特定触觉行为在人机交互中传达情感的潜力。结果显示，文化匹配、情感类型和交互方向显著影响情感解码准确性和行为适宜性。

**AI_Comments:** 这项研究的创新之处在于首次系统地探索了LLM在生成文化特定情感触觉行为方面的能力，填补了人机交互领域的一个空白。其重要性在于为未来设计更自然、更具文化敏感性的人机触觉交互提供了实证基础和指导。研究揭示了情感类型、交互方向和文化匹配对触觉行为感知的重要影响，为LLM在具身智能中的应用提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）日益融入机器人系统，但其生成社会和文化上适当的情感触觉的潜力仍未被充分探索。

**Method:** 本研究调查了GPT-3.5、GPT-4和GPT-4o能否生成文化适应性触觉行为来传达情感。研究为中国、比利时和未指定三种文化背景下的12种不同情感生成了基于文本的触觉描述，并在机器人到人及人到机器人场景中检验了其可解释性。90名参与者（36名中国人、36名比利时人、18名文化未指定）评估了这些LLM生成的触觉行为的情感解码和感知适宜性。

**Result:** 1. 在文化匹配条件下，参与者成功解码了12种情感中的6种，主要是社交导向情感（如爱）和Ekman情感（如愤怒），而自我中心情感（如骄傲和尴尬）更难解释。
2. 人到机器人的触觉行为比机器人到人的更被认为合适，揭示了基于交互角色的社会期望不对称性。
3. 被解释为攻击性（如愤怒）、过度亲密（如爱）或情感模糊的行为被评为不合适的可能性显著更高。
4. 文化不匹配降低了解码准确性并增加了行为被判断为不合适的可能性。

**Conclusion:** LLM生成文化特定情感触觉行为是可行的，但其成功解码和适宜性受到文化匹配、情感类型和交互方向的显著影响，这表明在设计情感人机触觉交互时需考虑这些因素。

> **ai_Abstract:** 本研究探索了大型语言模型（LLMs）在生成文化特定情感触觉行为以应用于人机交互方面的潜力。通过让GPT-3.5、GPT-4和GPT-4o生成触觉描述，并在中国、比利时及未指定文化背景下由90名参与者评估其情感解码和适宜性。研究发现，情感解码成功率受文化匹配、情感类型（社交导向情感易于解码，自我中心情感难）和交互方向（人到机器人更易接受）的影响。此外，攻击性、过度亲密或情感模糊的行为更可能被认为不合适，而文化不匹配会降低解码准确性并增加不适宜性判断。

> **摘要翻译:** 随着大型语言模型（LLMs）日益融入机器人系统，它们生成社会和文化上适当的情感触觉的潜力仍未被充分探索。本研究调查了LLMs——特别是GPT-3.5、GPT-4和GPT-4o——能否生成文化适应性触觉行为以在人机交互中传达情感。我们为三种文化背景（中国、比利时和未指定）下的12种不同情感生成了基于文本的触觉描述，并检验了它们在机器人到人以及人到机器人场景中的可解释性。共有90名参与者（36名中国人、36名比利时人、18名文化未指定）评估了这些LLM生成的触觉行为的情感解码和感知适宜性。结果显示：(1) 在文化匹配条件下，参与者成功解码了12种情感中的6种——主要是社交导向情感如爱和Ekman情感如愤怒，然而，自我中心情感如骄傲和尴尬更难解释；(2) 当触觉行为从人指向机器人时，比从机器人指向人时更被认为合适，这揭示了基于交互角色的社会期望不对称性；(3) 被解释为攻击性（例如愤怒）、过度亲密（例如爱）或情感模糊（即无法清晰解码）的行为被评为不合适的可能性显著更高；(4) 文化不匹配降低了解码准确性并增加了行为被判断为不合适的可能性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [657] [Automated Label Placement on Maps via Large Language Models](https://arxiv.org/abs/2507.22952)
> *地图自动标注放置：基于大型语言模型*

*Harry Shomer, Jiejun Xu* | **Category: cs.HC, cs.CV, cs.LG** | **Updated: 2025-07-29**

**Keywords:** 地图标注放置, 大型语言模型, 检索增强生成, MAPLE数据集, 空间编辑

**Comment:** Workshop on AI for Data Editing (AI4DE) at KDD 2025

> **TL;DR:** 本文提出一种利用大型语言模型（LLM）和检索增强生成（RAG）实现地图标签自动放置的新范式，并通过构建MAPLE数据集验证了其有效性和可扩展性。

**AI_Comments:** 本文创新性地将地图标签放置问题转化为LLM的数据编辑任务，通过引入RAG和专用数据集MAPLE，有效解决了现有自动化方法的局限性。其提出的框架具有良好的可扩展性，并为AI在地图制图领域的应用开辟了新方向，特别是展示了基础模型在复杂空间数据处理方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 地图标签放置是地图设计中的关键环节，但目前主要依赖人工操作且难以规模化，现有自动化系统难以整合制图规范、适应上下文或解释标注指令。

**Method:** 将标签放置任务构建为数据编辑问题，利用大型语言模型（LLMs）进行上下文感知的空间标注。具体方法包括：1) 整理了首个用于评估真实世界地图ALP的基准数据集MAPLE；2) 利用检索增强生成（RAG）检索与地标类型相关的标注指南；3) 将指南整合到提示中；4) 使用指令调优的LLMs生成理想的标签坐标；5) 在MAPLE数据集上评估了四种开源LLM的性能和泛化能力。

**Result:** 结果表明，在结构化提示和领域特定检索的指导下，LLMs能够学习执行准确的空间编辑，使生成的输出符合专家制图标准。

**Conclusion:** 该工作提出了一个可扩展的AI辅助地图后期处理框架，并展示了基础模型在结构化数据编辑任务中的潜力。

> **ai_Abstract:** 本文介绍了一种基于大型语言模型（LLM）的地图标签自动放置（ALP）新范式，将该任务重新定义为数据编辑问题。为支持此方向，作者构建了首个用于评估真实世界地图ALP的基准数据集MAPLE。该方法通过检索增强生成（RAG）获取相关标注指南，并将其整合到提示中，然后利用指令调优的LLM生成理想的标签坐标。实验结果表明，在结构化提示和领域特定检索的指导下，LLM能够准确执行空间编辑，达到专家制图标准。这项工作提供了一个可扩展的AI辅助地图制作框架，并展示了基础模型在结构化数据编辑任务中的潜力。

> **摘要翻译:** 标签放置是地图设计的一个关键方面，作为一种空间注释形式，它直接影响地图的清晰度和可解释性。尽管其重要性，标签放置在很大程度上仍然是手动的且难以规模化，因为现有的自动化系统难以整合制图规范、适应上下文或解释标注指令。在这项工作中，我们引入了一种自动标签放置（ALP）的新范式，将该任务表述为数据编辑问题，并利用大型语言模型（LLM）进行上下文感知的空间注释。为了支持这一方向，我们整理了MAPLE，这是第一个已知的用于评估真实世界地图上ALP的基准数据集，其中包括不同地标类型和来自开源数据的标签放置注释。我们的方法利用检索增强生成（RAG）检索与每种地标类型相关的标注指南，将其整合到提示中，并采用指令调优的LLM生成理想的标签坐标。我们在MAPLE上评估了四种开源LLM，分析了整体性能以及在不同类型地标上的泛化能力。这包括零样本和指令调优的性能。我们的结果表明，LLM在结构化提示和领域特定检索的指导下，可以学习执行准确的空间编辑，使生成的输出与专家制图标准保持一致。总的来说，我们的工作提出了一个可扩展的AI辅助地图后期处理框架，并展示了基础模型在结构化数据编辑任务中的潜力。代码和数据可在https://github.com/HarryShomer/MAPLE找到。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [699] [ChatVis: Large Language Model Agent for Generating Scientific Visualizations](https://arxiv.org/abs/2507.23096)
> *ChatVis：用于生成科学可视化的语言模型代理*

*Tom Peterka, Tanwi Mallick, Orcun Yildiz, David Lenz, Cory Quammen, Berk Geveci* | **Category: cs.HC** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 科学可视化, 代码生成, ParaView, 检索增强生成

**Comment:** 

> **TL;DR:** ChatVis是一个大型语言模型助手，通过简化提示、检索增强和错误检查，帮助LLM生成科学可视化代码，显著提高了可视化任务的性能。

**AI_Comments:** ChatVis的创新之处在于其无需重新训练或微调LLM，通过结合多种策略（链式思考、RAG、迭代纠错）来提升LLM在专业领域的代码生成能力。其提出的基准套件也为未来研究提供了评估标准，对于推动LLM在科学可视化领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在专业编程任务（如科学可视化）方面仍存在困难，因此需要一个辅助系统来帮助LLM生成相关代码。

**Method:** ChatVis采用链式思考提示简化、使用文档和代码示例的向量数据库进行检索增强的提示生成，以及带迭代提示反馈的错误检查来纠正错误。该方法还包括一个包含基准测试套件、ParaView回归测试和科学用例的综合评估指标。

**Result:** 与各种顶尖的非辅助LLM相比，ChatVis显著改善了所有评估指标。

**Conclusion:** ChatVis能够有效帮助大型语言模型生成科学可视化代码，显著提高性能，无需对LLM进行再训练或微调。

> **ai_Abstract:** 本文介绍了一个名为ChatVis的LLM助手，旨在帮助大型语言模型生成科学可视化（特别是ParaView）的Python代码。ChatVis通过结合链式思考提示简化、基于向量数据库的检索增强生成和迭代错误检查来提高代码生成能力。研究团队还开发了一个包含多种可视化任务和评估指标的基准套件。实验结果表明，与未辅助的LLM相比，ChatVis显著提升了科学可视化代码生成的性能，且无需对LLM进行重新训练或微调。

> **摘要翻译:** 大型语言模型（LLM）的能力正在迅速提升，但它们在高度专业化的编程任务（如科学可视化）方面仍然面临挑战。我们提出了一种LLM助手ChatVis，它帮助LLM生成用于ParaView科学可视化任务的Python代码，而无需对LLM进行再训练或微调。ChatVis采用链式思考提示简化、使用文档和代码示例的向量数据库进行检索增强的提示生成，以及带迭代提示反馈的错误检查，以纠正错误直到生成可视化。我们方法的一个组成部分是一个规范可视化任务、ParaView回归测试和科学用例的基准套件，其中包括全面的评估指标。我们通过将结果与各种表现最佳的非辅助LLM进行比较来评估我们的可视化助手。我们发现ChatVis显著改善了所有指标。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [722] [DeformTune: A Deformable XAI Music Prototype for Non-Musicians](https://arxiv.org/abs/2508.00160)
> *DeformTune：一个面向非音乐家的可变形XAI音乐原型*

*Ziqing Xu, Nick Bryan-Kinns* | **Category: cs.HC, cs.AI, cs.SD, eess.AS** | **Updated: 2025-07-31**

**Keywords:** AI音乐生成, 可变形界面, 可解释人工智能, 非音乐家, 触觉交互

**Comment:** In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts
  2025) arXiv:2406.14485

> **TL;DR:** DeformTune是一个结合触觉可变形界面和MeasureVAE模型的原型系统，旨在为非音乐家提供更直观、具身化和可解释的AI音乐创作体验。

**AI_Comments:** DeformTune的创新之处在于其将可变形触觉界面与AI音乐生成模型相结合，为非音乐家提供了新颖的交互方式。这对于降低AI音乐创作门槛、提升用户体验具有重要意义。研究通过用户反馈揭示了现有AI音乐系统在可解释性和易用性方面的局限性，并提出了具体的改进方向，如多模态反馈和渐进式支持，这些都是非常有价值的设计机会。

<details>
  <summary>Details</summary>

**Motivation:** 许多现有的AI音乐生成工具依赖于文本提示、复杂界面或乐器式控制，这可能需要非音乐家不具备的音乐或技术知识。因此，需要一种更直观的AI音乐创作方式。

**Method:** 本文介绍了DeformTune，一个将触觉可变形界面与MeasureVAE模型相结合的原型系统。研究人员对11名没有正式音乐训练的成年参与者进行了一项初步研究，以调查他们使用AI辅助音乐创作的体验，并对他们的反馈进行了主题分析。

**Result:** 主题分析揭示了反复出现的挑战，包括不明确的控制映射、有限的表达范围以及在使用过程中需要指导。

**Conclusion:** 这些发现为使AI音乐系统对新手用户更具可解释性和赋能提供了早期见解。论文讨论了几种增强AI可解释性的设计机会，包括多模态反馈和渐进式交互支持。

> **ai_Abstract:** DeformTune是一个针对非音乐家设计的AI音乐原型系统，它通过结合触觉可变形界面和MeasureVAE模型，旨在提供直观、具身化和可解释的音乐创作体验。一项对11名非专业音乐人士的初步研究发现，现有系统存在控制映射不清、表达范围有限以及缺乏指导等问题。研究结果为未来AI音乐系统设计提供了洞察，强调了多模态反馈和渐进式交互支持在增强可解释性和用户赋能方面的重要性。

> **摘要翻译:** 许多现有的AI音乐生成工具依赖于文本提示、复杂界面或乐器式控制，这可能需要非音乐家不具备的音乐或技术知识。本文介绍了DeformTune，一个结合触觉可变形界面与MeasureVAE模型的原型系统，旨在探索更直观、具身化和可解释的AI交互。我们对11名没有正式音乐训练的成年参与者进行了一项初步研究，以调查他们使用AI辅助音乐创作的体验。对他们反馈的主题分析揭示了反复出现的挑战——包括不明确的控制映射、有限的表达范围以及在使用过程中需要指导。我们讨论了几种增强AI可解释性的设计机会，包括多模态反馈和渐进式交互支持。这些发现为使AI音乐系统对新手用户更具可解释性和赋能提供了早期见解。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [742] [Silent Impact: Tracking Tennis Shots from the Passive Arm](https://arxiv.org/abs/2507.23215)
> *沉默冲击：从非持拍手臂追踪网球击球*

*Junyong Park, Saelyne Yang, Sungho Jo* | **Category: cs.HC, H.5.2; I.5.4** | **Updated: 2025-07-31**

**Keywords:** 网球击球, 非持拍手臂, 可穿戴技术, 体育分析, 神经网络

**Comment:** 15 pages, 9 figures,

> **TL;DR:** 该研究提出了一种名为Silent Impact的新型系统，通过放置在非持拍手臂上的传感器来分析网球击球，实现了与持拍手臂相当的准确性，并显著提高了用户舒适度。

**AI_Comments:** 这项研究的创新之处在于其颠覆性地将传感器放置在非持拍手臂上，有效解决了现有方案中传感器对运动员自然动作的干扰和不适问题。这不仅提升了用户体验，也为可穿戴运动分析技术开辟了新的思路。其实现的精度与传统方法相当，并得到了用户体验的积极反馈，显示出良好的应用前景和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可穿戴运动分析技术通常设置繁琐，会抑制自然运动，尤其是在网球运动中，将传感器放置在球拍或持拍手臂上会分散注意力并引起不适。

**Method:** 研究团队开发了一个名为Silent Impact的系统，通过在非持拍手臂上放置传感器来分析网球击球。他们收集了20名业余网球运动员的惯性测量单元（IMU）传感器数据，并开发了专门利用非持拍手臂数据来检测和分类六种击球的神经网络模型。这些模型被整合到一个端到端原型中，该原型通过智能手表记录非持拍手臂的运动，并在移动应用程序上显示击球摘要。

**Result:** 该系统在击球分类上达到了88.2%的准确率，在检测上达到了86.0%的F1分数，与持拍手臂的表现相当。用户研究（N=10）表明，参与者使用Silent Impact在非持拍手臂上时，身体和精神上的负担更小。

**Conclusion:** 该研究证明非持拍手臂是进行网球击球分析的一种有效且舒适的替代方案，从而推动了用户友好的体育分析技术的发展。

> **ai_Abstract:** 本研究提出了一种创新的“Silent Impact”系统，旨在克服现有网球击球分析可穿戴设备带来的不适和干扰。该系统通过在非持拍手臂上放置传感器，利用IMU数据和神经网络模型检测并分类网球击球。实验结果显示，其击球分类准确率达到88.2%，检测F1分数为86.0%，性能与持拍手臂相当。用户研究进一步证实了其在减轻用户负担方面的优势。该研究成功证明了非持拍手臂作为网球击球分析的有效且舒适替代方案的可行性，推进了用户友好型体育分析技术的发展。

> **摘要翻译:** 可穿戴技术已经改变了体育分析，为增强运动员体验提供了新的维度。然而，许多解决方案涉及繁琐的设置，会抑制自然运动。在网球运动中，现有产品需要将传感器放置在球拍或持拍手臂上，这会导致分心和不适。我们提出了Silent Impact，一种新颖且用户友好的系统，它使用放置在非持拍手臂上的传感器来分析网球击球。我们收集了20名业余网球运动员的惯性测量单元传感器数据，开发了专门利用非持拍手臂数据来检测和分类六种击球的神经网络，实现了88.2%的分类准确率和86.0%的检测F1分数，与持拍手臂的表现相当。这些模型随后被整合到一个端到端原型中，该原型通过智能手表记录非持拍手臂的运动，并在移动应用程序上显示击球摘要。用户研究（N=10）表明，参与者在使用Silent Impact在非持拍手臂上时，身体和精神上的负担更小。总的来说，我们的研究确立了非持拍手臂作为网球击球分析的一种有效、舒适的替代方案，从而推动了用户友好的体育分析技术的发展。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [760] [Evaluating LLMs for Visualization Generation and Understanding](https://arxiv.org/abs/2507.22890)
> *评估大型语言模型在可视化生成与理解方面的能力*

*Saadiq Rauf Khan, Vinit Chandak, Sougata Mukherjea* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-16**

**Keywords:** 大型语言模型, 可视化生成, 可视化理解, 信息可视化, LLMs

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLMs）在生成可视化代码和理解现有可视化方面的能力。结果显示LLMs能生成简单可视化并回答简单问题，但在复杂可视化生成和复杂问题回答上存在局限性。

**AI_Comments:** 该论文对LLMs在可视化领域的应用进行了初步但重要的探索。它不仅展示了LLMs的潜力（如生成简单可视化和回答基本问题），也明确指出了其当前存在的局限性（如复杂可视化生成和精确理解的不足）。这些发现对于指导未来LLMs和信息可视化系统的发展方向具有重要意义，提示研究者需要关注如何提升LLMs处理复杂视觉信息的能力。

<details>
  <summary>Details</summary>

**Motivation:** 信息可视化被用于从复杂数据中获取洞察。鉴于大型语言模型（LLMs）在许多任务中表现出色，本研究旨在探索LLMs在可视化生成和理解方面的潜力。

**Method:** 本研究展示了不同流行LLMs基于简单提示生成可视化代码的能力，并通过回答问题来分析LLMs理解常见可视化的能力。

**Result:** 研究表明，LLMs可以为条形图和饼图等简单可视化生成代码，并能回答关于可视化的简单问题。然而，LLMs也存在局限性，例如难以生成小提琴图等复杂可视化，并在回答可视化相关问题时（如识别接近边界之间的关系和确定形状长度）出现错误。

**Conclusion:** 研究结果有望用于改进大型语言模型和信息可视化系统。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在信息可视化领域的应用能力，具体包括生成可视化代码和理解现有可视化。实验结果显示，LLMs能够有效地生成条形图和饼图等简单可视化的代码，并能回答关于可视化的基本问题。然而，LLMs在生成如小提琴图等复杂可视化时表现出局限性，并且在处理涉及复杂关系（如紧密边界识别）和精确测量（如形状长度判断）的可视化理解问题时会出现错误。本研究的发现为未来改进LLMs和信息可视化系统提供了有价值的见解。

> **摘要翻译:** 信息可视化已被用于从复杂数据中获取洞察。近期，大型语言模型（LLMs）在许多任务中表现出色。在本文中，我们展示了不同流行LLMs基于简单提示生成可视化代码的能力。我们还通过回答问题来分析LLMs理解一些常见可视化的能力。我们的研究表明，LLMs可以为条形图和饼图等一些更简单的可视化生成代码。此外，它们可以回答关于可视化的简单问题。然而，LLMs也存在一些局限性。例如，其中一些模型在生成复杂可视化（如小提琴图）时遇到困难。LLMs在回答关于可视化的一些问题时也出现错误，例如识别接近边界之间的关系和确定形状的长度。我们相信我们的见解可以用于改进LLMs和信息可视化系统。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [773] [MetaExplainer: A Framework to Generate Multi-Type User-Centered Explanations for AI Systems](https://arxiv.org/abs/2508.00300)
> *MetaExplainer：一个为AI系统生成多类型以用户为中心解释的框架*

*Shruthi Chari, Oshani Seneviratne, Prithwish Chakraborty, Pablo Meyer, Deborah L. McGuinness* | **Category: cs.HC, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 用户中心解释, 神经符号框架, 大型语言模型, 解释本体, AI可解释性

**Comment:** 

> **TL;DR:** MetaExplainer是一个神经符号框架，利用LLM和解释本体生成多类型、以用户为中心的AI解释，旨在提高AI系统的可解释性和可信度。

**AI_Comments:** MetaExplainer的创新之处在于其神经符号方法，巧妙地结合了LLM在处理自然语言方面的能力与解释本体提供的结构化指导，从而能够生成真正符合用户需求的多类型解释。这种方法有效地弥补了模型生成解释与用户实际需求之间的差距，是提升AI系统可信度的关键一步。该框架的通用性和从本体指导LLM所体现的可追溯性，也预示着其在更广泛领域中的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 解释对于构建可信赖的AI系统至关重要，但模型提供的解释与用户需求的解释之间存在差距。

**Method:** MetaExplainer是一个神经符号框架，采用三阶段过程：首先，使用大型语言模型（LLM）将用户问题分解为机器可读格式；其次，将生成系统推荐的任务委托给模型解释器方法；最后，合成自然语言解释以总结解释器输出。整个过程利用解释本体来指导LLM和解释器方法，并支持对比、反事实、理由、基于案例和数据等多种解释类型。

**Result:** 在问题重构中实现了59.06%的F1分数，模型解释忠实度达到70%，自然语言合成中的上下文利用率为67%。用户研究证实了生成解释的创造性和全面性。该框架已在糖尿病（PIMA Indian）表格数据集上进行了测试。

**Conclusion:** MetaExplainer通过提供以用户为中心、问题驱动的解释，显著增强了AI系统的可解释性和可信度，并凭借其通用性和可追溯性展现出广泛的适用性。

> **ai_Abstract:** MetaExplainer是一个神经符号框架，旨在通过整合大型语言模型（LLM）和解释本体来生成多类型、以用户为中心的AI解释。该框架采用三阶段方法：将用户问题分解、生成系统推荐以及合成自然语言解释。评估结果显示其在问题重构、模型解释忠实度和自然语言合成方面表现良好，并通过用户研究验证了生成解释的质量。MetaExplainer支持多种解释类型，并在糖尿病数据集上成功应用，展现出增强AI系统可解释性和可信度的巨大潜力。

> **摘要翻译:** 解释对于构建可信赖的AI系统至关重要，但模型提供的解释与用户需求的解释之间通常存在差距。为了弥补这一差距，我们引入了MetaExplainer，一个旨在生成以用户为中心解释的神经符号框架。我们的方法采用三阶段过程：首先，我们使用最先进的大型语言模型（LLM）将用户问题分解为机器可读的格式；其次，我们将生成系统推荐的任务委托给模型解释器方法；最后，我们合成自然语言解释，以总结解释器输出。在整个过程中，我们利用解释本体来指导语言模型和解释器方法。通过利用LLM和结构化的解释生成方法，MetaExplainer旨在增强AI系统在各种应用中的可解释性和可信度，为用户提供量身定制、问题驱动的解释，从而更好地满足他们的需求。对MetaExplainer的全面评估表明，它在评估和利用当前最先进的解释框架方面迈出了一步。我们的结果显示在所有阶段都表现出色，问题重构的F1分数为59.06%，模型解释的忠实度为70%，自然语言合成中的上下文利用率为67%。用户研究证实了这些发现，强调了生成解释的创造性和全面性。MetaExplainer在糖尿病（PIMA Indian）表格数据集上进行了测试，支持多种解释类型，包括对比、反事实、理由、基于案例和数据解释。该框架的通用性和从使用本体指导LLM所体现的可追溯性表明其在测试场景之外具有广泛的适用性，将MetaExplainer定位为增强各种领域AI可解释性的一个有前景的工具。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [781] [Invisible Architectures of Thought: Toward a New Science of AI as Cognitive Infrastructure](https://arxiv.org/abs/2507.22893)
> *思想的隐形架构：迈向将AI视为认知基础设施的新科学*

*Giuseppe Riva* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-19**

**Keywords:** AI, 认知基础设施, 分布式认知, 认知能动性, 基础设施分解方法

**Comment:** 

> **TL;DR:** AI预处理以无形方式重塑人类认知，本文提出“认知基础设施研究”（CIS）新领域，将AI视为影响思想和行动的基础设施，并提供研究其影响的方法。

**AI_Comments:** 该论文的创新之处在于提出了“认知基础设施”这一新颖概念，将AI的影响从显性交互层面提升到更深层次的、无形且预先影响人类认知的层面。其重要性在于填补了当前人机交互研究的盲点，并提供了一个跨学科的理论框架和具体方法（如“基础设施分解方法”）来研究AI对分布式认知和集体认识论的深远影响。这对于理解数字时代的人类认知演变和AI伦理治理具有重要意义。局限性可能在于，作为一个新提出的领域，其理论框架和方法论的实际应用和验证尚需进一步的实证研究。

<details>
  <summary>Details</summary>

**Motivation:** 当代人机交互研究忽视了人工智能系统如何在无意识层面从根本上重塑人类认知，这是理解分布式认知的一个关键盲点。

**Method:** 本文引入“认知基础设施研究”（CIS）作为一个新的跨学科领域，将AI重新概念化为“认知基础设施”，描述其特征（传输意义、预测性个性化、适应性隐形、自动化“相关性判断”）。通过叙事场景阐述其影响，并提出“基础设施分解方法”等实验方法，通过系统性撤回AI预处理来研究隐形算法影响。

**Result:** 本文描述了认知基础设施如何重塑人类认知、公共推理和社会认识论，并旨在解决认知科学、数字社会学和计算方法等跨学科研究中的关键空白。

**Conclusion:** 本文引入“认知基础设施研究”（CIS）这一新领域，旨在解决AI预处理对个体、集体和文化层面分布式认知的重塑问题，并提供了研究这种隐形影响的方法论创新。

> **ai_Abstract:** 本文提出“认知基础设施研究”（CIS）新领域，旨在解决当前人机交互研究忽视AI系统如何无意识地重塑人类认知的问题。该研究将AI重新概念化为“认知基础设施”，这些隐形系统通过预先判断和个性化影响数字社会中可认知和可操作的内容，并将认知能动性转移到非人类系统。通过叙事场景，文章阐述了认知基础设施如何在个体、集体和社会层面重塑人类认知、公共推理和社会认识论。CIS还提出了“基础设施分解方法”等实验方法，以研究AI预处理对分布式认知的隐形影响，并弥补了跨学科研究的空白。

> **摘要翻译:** 当代人机交互研究忽视了人工智能系统如何在无意识层面从根本上重塑人类认知，这是理解分布式认知的一个关键盲点。本文引入“认知基础设施研究”（CIS）作为一个新的跨学科领域，将人工智能重新概念化为“认知基础设施”：这些基础性的、通常是隐形的系统，制约着数字社会中什么是可知的和可行动的。这些语义基础设施传输意义，通过预测性个性化运作，并展现出适应性隐形，使其影响难以察觉。关键的是，它们自动化了“相关性判断”，将“认知能动性中心”转移到非人类系统。通过涵盖个体（认知依赖）、集体（民主审议）和社会（治理）层面的叙事场景，我们描述了认知基础设施如何重塑人类认知、公共推理和社会认识论。CIS旨在解决人工智能预处理如何在个体、集体和文化层面重塑分布式认知，这需要前所未有的多学科方法整合。该框架还解决了跨学科的关键空白：认知科学缺乏人口规模的预处理分析能力，数字社会学无法访问个体认知机制，而计算方法则错失了文化传播动态。为了实现这一目标，CIS还提供了研究隐形算法影响的方法论创新：“基础设施分解方法”，这是一种实验方法，通过在习惯期后系统地撤回人工智能预处理来揭示认知依赖。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [783] [Real-time Generation of Various Types of Nodding for Avatar Attentive Listening System](https://arxiv.org/abs/2507.23298)
> *用于虚拟形象专注倾听系统的实时生成各种类型点头*

*Kazushi Kato, Koji Inoue, Divesh Lala, Keiko Ochi, Tatsuya Kawahara* | **Category: cs.HC, cs.SD, eess.AS** | **Updated: 2025-07-31**

**Keywords:** 点头生成, 实时系统, 虚拟形象, 专注倾听, 非语言行为

**Comment:** Accepted by 27th ACM International Conference on Multimodal
  Interaction (ICMI '25), Long paper

> **TL;DR:** 提出了一种实时预测虚拟形象点头时机和类型的新模型，优于传统方法。

**AI_Comments:** 该研究的创新点在于将VAP模型扩展到实时预测多种类型点头，并引入多任务学习和预训练以提高性能。其重要性体现在提升了语音对话系统中虚拟形象的非语言交互能力，使其听起来更自然、更具吸引力。

<details>
  <summary>Details</summary>

**Motivation:** 在人类对话中，非语言信息如点头和面部表情与语言信息同样重要。语音对话系统也应能表达此类非语言行为。本文关注点头，其在专注倾听系统中至关重要。

**Method:** 提出了一种模型，它建立在语音活动预测（VAP）模型之上，该模型能从听者和说话者音频中预测语音活动。该模型被扩展为连续实时预测各种类型的点头，并结合了与语言反馈预测的多任务学习以及在通用对话数据上的预训练。

**Result:** 多任务学习在点头时机和类型预测任务中效果显著。降低处理速率可在不大幅降低准确性的情况下实现实时操作。主观评估显示，该模型优于总是与语言反馈同步点头的传统方法。

**Conclusion:** 该模型能够实时生成各种类型的点头，并成功集成到虚拟形象专注倾听系统中，表现优于传统方法。

> **ai_Abstract:** 本文提出了一种用于虚拟形象专注倾听系统的实时点头生成模型。该模型基于VAP模型并扩展其功能，能够连续实时地预测不同类型点头的时机和类型。通过整合多任务学习和预训练，模型在预测任务中表现出显著效果，并在实时操作中保持高准确性。主观评估表明，该模型优于传统方法，能更自然地生成点头行为。

> **摘要翻译:** 在人类对话中，点头和面部表情等非语言信息与语言信息同样重要，语音对话系统也期望能表达此类非语言行为。我们关注在专注倾听系统中至关重要的点头，并提出了一种能实时预测其时机和类型的模型。所提出的模型建立在语音活动预测（VAP）模型的基础上，该模型从听者和说话者的音频中预测语音活动。与传统模型不同，我们将其扩展到连续实时地预测各种类型的点头。此外，所提出的模型结合了多任务学习（与语言反馈预测）和在通用对话数据上进行预训练。在时机和类型预测任务中，多任务学习的有效性得到了显著证明。我们确认，降低处理速率可以在不大幅降低准确性的情况下实现实时操作，并将该模型集成到虚拟形象专注倾听系统中。主观评估显示，它优于总是与语言反馈同步点头的传统方法。代码和训练好的模型可在 https://github.com/MaAI-Kyoto/MaAI 获取。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [802] [iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement](https://arxiv.org/abs/2507.22896)
> *iLearnRobot：一种基于交互式学习的持续改进多模态机器人*

*Kohou Wang, ZhaoXiang Liu, Lin Bai, Kun Fan, Xiang Liu, Huan Hu, Kai Wang, Shiguo Lian* | **Category: cs.HC, cs.AI, cs.CV, cs.RO** | **Updated: 2025-06-25**

**Keywords:** 交互式学习, 多模态机器人, MLLM, 持续改进, 双模态检索

**Comment:** 17 pages, 12 figures

> **TL;DR:** iLearnRobot是一个基于多模态大语言模型的交互式学习机器人系统，它能通过与非专家用户的自然对话进行学习，并利用提问链和双模态检索模块避免重复犯错，从而在部署后持续改进性能。

**AI_Comments:** 该论文的创新点在于提出了一个基于MLLM的交互式学习机器人系统，其核心亮点是能够通过自然对话与非专家用户进行学习，并利用“问题链”和“双模态检索模块”在模型更新前有效避免重复错误，从而实现部署后的持续性能改进。这为机器人提供了更强的适应性和用户体验，与现有系统形成鲜明对比，具有重要的实际应用价值和研究意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人部署后性能提升至关重要，因为它们必然会遇到前所未见的陌生场景。

**Method:** 本文提出了一种基于交互式学习的多模态大语言模型（MLLM）机器人系统。该系统通过与非专家用户的自然对话进行学习，并引入了“问题链”以澄清意图，以及“双模态检索模块”来利用交互事件避免重复犯错。

**Result:** 通过定量和定性实验，证明了该方法的有效性和改进。

**Conclusion:** iLearnRobot系统通过整合交互式学习，在机器人领域标志着一种新颖的方法，为在不同环境中实现卓越的适应性和性能铺平了道路。

> **ai_Abstract:** 本文提出iLearnRobot，一个基于多模态大语言模型（MLLM）的交互式学习机器人系统，旨在解决机器人部署后性能持续改进的关键问题。该系统允许机器人通过与非专家用户的自然对话进行学习，并引入了“问题链”来明确用户意图，以及“双模态检索模块”来利用过往交互避免重复错误。这与现有主流MLLM机器人系统形成对比，实现了在模型更新前提供无缝体验。实验结果表明，该方法在适应性和性能方面均有显著提升，为机器人技术带来了新的发展方向。

> **摘要翻译:** 机器人部署后能够提升性能至关重要，因为它们必然会遇到前所未见的陌生场景。本文提出了一种创新解决方案：一个由多模态大语言模型（MLLM）驱动的基于交互式学习的机器人系统。我们系统的一个关键特征是它能够通过与非专家用户的自然对话进行学习。我们还提出了问题链，以在提供答案之前澄清问题的确切意图，以及双模态检索模块，以利用这些交互事件避免重复相同的错误，确保在模型更新前提供无缝的用户体验，这与当前主流的基于MLLM的机器人系统形成对比。我们的系统通过整合交互式学习，标志着机器人领域的一种新颖方法，为在不同环境中实现卓越的适应性和性能铺平了道路。我们通过定量和定性实验，证明了我们方法的有效性和改进。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [823] [RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems](https://arxiv.org/abs/2507.22897)
> *RecUserSim：一个用于评估对话推荐系统的真实且多样化的用户模拟器*

*Luyu Chen, Quanyu Dai, Zeyu Zhang, Xueyang Feng, Mingyu Zhang, Pengcheng Tang, Xu Chen, Yue Zhu, Zhenhua Dong* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-25**

**Keywords:** 对话推荐系统, 用户模拟器, 大型语言模型, 评估, 有限理性理论

**Comment:** Accepted by TheWebConf'25 Industry Track

> **TL;DR:** RecUserSim是一个基于LLM的用户模拟器，旨在为对话推荐系统（CRS）提供更真实、多样化的评估，并能生成明确的评分。

**AI_Comments:** RecUserSim的创新之处在于其模块化设计，特别是引入了受有限理性理论启发的“核心动作模块”和“细化模块”，这使得模拟的用户行为和响应更加真实和细致。该工作解决了当前LLM用户模拟器在真实性和多样性方面的不足，并通过提供明确的评分机制，为对话推荐系统的定量评估提供了有效工具。其“即使使用较小的基础LLM也能实现”的特点，也显示了其潜在的广泛适用性。

<details>
  <summary>Details</summary>

**Motivation:** 对话推荐系统（CRS）的评估具有挑战性，现有基于大型语言模型（LLM）的用户模拟器在模拟真实用户、多样化场景以及提供明确的定量评估机制方面存在不足。

**Method:** 本文提出了RecUserSim，一个基于LLM代理的用户模拟器，旨在增强模拟的真实性和多样性，并提供明确的分数。RecUserSim包含几个关键模块：用于定义真实多样用户画像的配置文件模块；用于跟踪交互历史和发现未知偏好的记忆模块；受有限理性理论启发的核心动作模块，该模块能够实现细致的决策并生成更细粒度的动作和个性化响应；以及一个细化模块，用于微调最终响应以增强输出控制。

**Result:** 实验证明RecUserSim能够生成多样化、可控的输出，并产生真实、高质量的对话，即使使用较小的基础LLM也能实现。RecUserSim生成的评分在不同基础LLM之间表现出高度一致性。

**Conclusion:** RecUserSim在评估对话推荐系统方面表现出有效性，能够提供真实、多样化的用户模拟和一致的定量评分。

> **ai_Abstract:** 本文提出了RecUserSim，一个基于大型语言模型（LLM）代理的用户模拟器，旨在解决对话推荐系统（CRS）评估中现有模拟器在真实性、多样性及定量评分机制方面的不足。RecUserSim通过集成配置文件、记忆、核心动作和细化模块，实现了对真实且多样化用户行为的模拟，并能生成明确的评分。实验结果表明，RecUserSim能够生成高质量、多样化且可控的对话，其产生的评分在不同LLM间具有高度一致性，有效提升了CRS的评估能力。

> **摘要翻译:** 对话推荐系统（CRS）通过多轮交互增强用户体验，但评估CRS仍然具有挑战性。用户模拟器可以通过与CRS的交互提供全面的评估，但构建真实且多样化的模拟器很困难。尽管最近的工作利用大型语言模型（LLM）来模拟用户交互，但它们在模拟不同场景下的个体真实用户方面仍有不足，并且缺乏明确的评分机制进行定量评估。为了解决这些问题，我们提出了RecUserSim，一个基于LLM代理的用户模拟器，它增强了模拟的真实性和多样性，同时提供了明确的分数。RecUserSim具有几个关键模块：用于定义真实多样用户画像的配置文件模块；用于跟踪交互历史和发现未知偏好的记忆模块；以及受有限理性理论启发的核心动作模块，该模块能够实现细致的决策，同时生成更细粒度的动作和个性化响应。为了进一步增强输出控制，还设计了一个细化模块来微调最终响应。实验证明，RecUserSim能够生成多样化、可控的输出，并产生真实、高质量的对话，即使使用较小的基础LLM也能实现。RecUserSim生成的评分在不同基础LLM之间表现出高度一致性，突显了其在CRS评估方面的有效性。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [825] [Agency Among Agents: Designing with Hypertextual Friction in the Algorithmic Web](https://arxiv.org/abs/2507.23585)
> *代理中的能动性：在算法网络中设计超文本摩擦*

*Sophia Liu, Shm Garanganao Almeda* | **Category: cs.HC, cs.AI, cs.MM, cs.SI** | **Updated: 2025-07-31**

**Keywords:** 超文本摩擦, 用户能动性, 算法网络, 界面设计, 比较分析

**Comment:** To appear in: Adjunct Proceedings of the 36th ACM Conference on
  Hypertext and Social Media, Chicago, IL, USA, September 15-18, 2025

> **TL;DR:** 本文提出“超文本摩擦”的设计理念，旨在通过重新强调超文本原则来帮助用户在算法驱动的网络环境中重新获得能动性。

**AI_Comments:** 本文提出了一个新颖且重要的概念“超文本摩擦”，通过重新审视经典超文本原则，为解决算法时代用户能动性缺失问题提供了有益的设计视角。其通过具体案例的比较分析，清晰地揭示了不同界面设计范式对用户体验和控制力的影响，具有较强的实践指导意义。这一创新性方法论有望启发未来在人机交互和算法设计领域中，更加注重用户中心的设计。

<details>
  <summary>Details</summary>

**Motivation:** 当今的算法驱动界面（如推荐信息流和生成式AI工具）常常以牺牲用户能动性为代价，优先考虑参与度和效率。随着系统承担更多决策，用户对其所见内容以及内容之间意义或关系的构建控制力减弱。

**Method:** 本文引入了“超文本摩擦”这一概念性设计立场，将经典的超文本原则——摩擦、可追溯性和结构——重新定位为在算法中介环境中恢复能动性的可行价值。通过对现实世界界面（如维基百科与Instagram Explore，Are.na与生成式AI图像工具）进行比较分析，研究了不同系统如何构建用户体验、导航和创作。

**Result:** 研究表明，超文本系统强调出处、联想思维和用户驱动的意义构建，而算法系统则倾向于模糊过程并扁平化参与。这揭示了界面结构如何塑造用户驱动系统与代理驱动系统中的能动性。

**Conclusion:** 本文贡献了：(1) 对界面结构如何塑造用户驱动系统与代理驱动系统中的能动性的比较分析；(2) 一种概念性立场，提出超文本价值作为在日益算法化的网络中恢复能动性的设计承诺。

> **ai_Abstract:** 本研究探讨了当前算法驱动界面（如推荐系统和生成式AI）如何通过优先考虑效率和参与度来削弱用户能动性。为此，论文提出了“超文本摩擦”这一设计理念，旨在通过重新引入经典的超文本原则（摩擦、可追溯性、结构）来帮助用户在算法环境中重新获得控制权。通过比较分析维基百科与Instagram Explore、Are.na与生成式AI图像工具等实际案例，研究发现超文本系统能增强出处、联想思维和用户主导的意义构建，而算法系统则倾向于模糊过程并降低用户参与度。最终，论文提供了一项关于界面结构如何影响能动性的比较分析，并提出了以超文本价值为基础的设计承诺，以期在日益算法化的网络中恢复用户能动性。

> **摘要翻译:** 当今的算法驱动界面，从推荐信息流到生成式AI工具，常常以牺牲用户能动性为代价，优先考虑参与度和效率。随着系统承担更多决策，用户对其所见内容以及内容之间意义或关系的构建控制力减弱。本文引入了“超文本摩擦”，这是一种概念性设计立场，它将经典的超文本原则——摩擦、可追溯性和结构——重新定位为在算法中介环境中恢复能动性的可行价值。通过对现实世界界面——维基百科与Instagram Explore，以及Are.na与生成式AI图像工具——进行比较分析，我们审视了不同系统如何构建用户体验、导航和创作。我们展示了超文本系统强调出处、联想思维和用户驱动的意义构建，而算法系统则倾向于模糊过程并扁平化参与。我们的贡献包括：(1) 对界面结构如何塑造用户驱动系统与代理驱动系统中的能动性的比较分析，以及 (2) 一种概念性立场，它提供超文本价值作为在日益算法化的网络中恢复能动性的设计承诺。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [844] [Tool or Trouble? Exploring Student Attitudes Toward AI Coding Assistants](https://arxiv.org/abs/2507.22900)
> *工具还是麻烦？探索学生对AI编码助手的态度*

*Sergio Rojas-Galeano* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-26**

**Keywords:** AI编码助手, 学生态度, 编程教育, 过度依赖, 知识迁移

**Comment:** 

> **TL;DR:** 本研究探讨了新手程序员如何看待AI编码助手，发现AI有帮助但可能导致过度依赖和知识迁移困难。

**AI_Comments:** 这项研究及时地探讨了AI在编程教育中的应用，揭示了其潜在益处和风险（如过度依赖）。其创新之处在于通过分阶段考试设计来观察知识迁移问题，对未来AI辅助学习的教学设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 探索AI编码助手如何影响新手程序员在入门编程课程中的学习体验，特别是在考试场景下。

**Method:** 一项探索性研究，20名学生在入门编程课程的两部分考试中完成任务：第一部分有AI支持，第二部分无AI。研究通过收集Likert量表和开放式回答来评估学生的看法和挑战。

**Result:** AI工具被认为有助于理解代码和提高信心，尤其是在初始开发阶段。然而，学生报告将知识迁移到无AI任务时遇到困难，揭示了可能的过度依赖和概念理解上的不足。

**Conclusion:** 研究结果强调需要制定教学策略，以有意义地整合AI，同时强化学生的基础编程技能，以避免过度依赖并促进知识的有效迁移。

> **ai_Abstract:** 本探索性研究调查了20名新手程序员在编程考试中使用AI编码助手的态度。结果显示，AI在理解代码和提升信心方面有帮助，但可能导致学生过度依赖并难以将知识迁移到无AI任务。研究强调需要制定教学策略，以有意义地整合AI并同时强化基础编程技能。

> **摘要翻译:** 这项探索性研究考察了人工智能代码助手如何在入门编程课程的两部分考试中塑造新手程序员的体验。在第一部分中，学生在人工智能支持下完成编程任务；在第二部分中，他们在没有人工智能的情况下扩展了他们的解决方案。我们收集了20名学生的李克特量表和开放式回答，以评估他们的看法和挑战。研究结果表明，人工智能工具被认为有助于理解代码和提高信心，特别是在初始开发阶段。然而，学生报告将知识迁移到无辅助任务时遇到困难，揭示了可能的过度依赖和概念理解上的不足。这些见解强调了需要有意义地整合人工智能，同时强化基础编程技能的教学策略。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [859] [VRISE: A Virtual Reality Platfrom for Immersive and Interactive Surveying Education](https://arxiv.org/abs/2507.22810)
> *VRISE: 沉浸式互动测量教育的虚拟现实平台*

*Daniel Udekwe, Dimitrios Bolkas, Eren Erman Ozguven, Ren Moses, Qianwen Guo* | **Category: cs.HC, cs.ET, cs.SE** | **Updated: 2025-07-31**

**Keywords:** 虚拟现实, 测量教育, 沉浸式学习, 技能发展, 土木工程

**Comment:** 

> **TL;DR:** VRISE是一个虚拟现实平台，通过沉浸式互动模块，提升测量教育中学生的测量精度和任务效率。

**AI_Comments:** VRISE通过虚拟现实技术解决了传统测量教育中实践操作的挑战，提升了学习的可及性和效率。其创新之处在于提供了可重复、沉浸式的学习环境，有助于学生在低风险环境下掌握复杂技能。该平台有望显著改善土木工程领域的测量教学质量和学生参与度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的测量教育存在后勤和认知方面的挑战，阻碍了可及性和学生参与度。现有虚拟实验室很少专门为测量领域的灵活适应性学习而设计。

**Method:** 开发了VRISE，一个沉浸式虚拟现实实验室，通过可定制、易于访问和用户友好的模块复制地面和空中测量任务。VRISE提供互动体验，如使用数字水准仪进行高程测量和基于航点的无人机导航，并通过输入平滑、自适应界面和实时反馈进行增强。

**Result:** 多用户会话的评估表明，测量精度、任务效率和交互质量持续提高，并且在地面和空中测量模式下技能发展有明显的进步。

**Conclusion:** VRISE展示了沉浸式、可重复的数字环境在安全和引人入胜的环境中增强测量教育、扩大参与度和加强核心能力的潜力，同时减少了认知负荷和身体需求。

> **ai_Abstract:** 本文介绍了VRISE，一个专为测量教育设计的沉浸式虚拟现实平台。针对传统教学的局限性，VRISE提供可定制的模块，模拟地面和空中测量任务，并支持互动体验。通过用户评估，VRISE在提高测量精度、任务效率和技能发展方面表现出色，证明了其在安全和沉浸式环境中提升测量教育的潜力。

> **摘要翻译:** 测量是土木工程教育的核心组成部分，要求学生进行实践性的空间测量、仪器操作和基于现场的决策。然而，传统的教学方法常常带来后勤和认知方面的挑战，这会阻碍可及性和学生参与度。尽管虚拟实验室在工程教育中已受到关注，但很少有专门设计用于支持测量领域灵活、适应性学习的。为了弥补这一空白，我们开发了沉浸式互动测量教育虚拟现实平台（VRISE），这是一个沉浸式虚拟现实实验室，通过可定制、易于访问且用户友好的模块，复制地面和空中测量任务。VRISE提供互动体验，例如使用数字水准仪进行高程测量和基于航点的无人机导航，并通过输入平滑、自适应界面和实时反馈进行增强，以适应不同的学习风格。对多用户会话的评估表明，在测量精度、任务效率和交互质量方面持续提高，并且在地面和空中测量模式下技能发展有明显的进步。通过减少认知负荷和身体需求，即使在需要精细运动控制和空间推理的任务中，VRISE也展示了沉浸式、可重复的数字环境在安全和引人入胜的环境中增强测量教育、扩大参与度和加强核心能力方面的潜力。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [865] [Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting](https://arxiv.org/abs/2507.22902)
> *迈向自主AI医生：在真实世界环境中对自主代理AI与委员会认证临床医生的定量基准测试*

*Hashim Hayat, Maksim Kudrautsau, Evgeniy Makarov, Vlad Melnichenko, Tim Tsykunou, Piotr Varaksin, Matt Pavelle, Adam Z. Oskowitz* | **Category: cs.HC, cs.AI, cs.CL, cs.MA** | **Updated: 2025-06-27**

**Keywords:** AI医生, 大型语言模型, 紧急护理, 临床决策, 医疗短缺

**Comment:** 

> **TL;DR:** 一项研究首次在真实世界虚拟紧急护理环境中，对自主AI医生Doctronic与人类临床医生进行了大规模比较，结果显示AI在诊断和治疗方案上与人类医生高度一致，且在某些情况下表现更优，有望缓解医疗人员短缺。

**AI_Comments:** 这项研究的创新之处在于首次对端到端自主AI医生在真实世界临床环境（虚拟紧急护理）中进行了大规模定量基准测试。其重要性在于验证了多代理AI系统在临床决策上的潜力，特别是在诊断和治疗方案上与人类医生的高度一致性，以及在某些情况下超越人类的表现，为缓解全球医疗人员短缺提供了有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 全球预计到2030年将面临1100万医疗从业人员短缺，且行政负担消耗了50%的临床时间。人工智能（AI）有潜力帮助缓解这些问题。然而，尚未有端到端自主大型语言模型（LLM）驱动的AI系统在真实临床实践中得到严格评估，本研究旨在填补这一空白。

**Method:** 研究回顾性比较了多代理AI系统Doctronic与委员会认证临床医生在500次连续紧急护理远程医疗问诊中的表现。主要评估指标包括诊断一致性、治疗方案一致性和安全指标，这些指标通过盲法LLM裁决和专家人工审查进行评估。

**Result:** Doctronic与临床医生的首要诊断在81%的病例中匹配，治疗方案在99.2%的病例中一致。未发生临床幻觉。在对不一致病例的专家审查中，AI性能在36.1%的病例中更优，人类性能在9.3%的病例中更优；其余病例诊断等效。

**Conclusion:** 这项首次大规模验证的自主AI医生研究表明，AI在诊断和治疗方案上与人类临床医生具有强大的、可比甚至超越的一致性。这些发现表明多代理AI系统能实现与人类提供者相当的临床决策能力，并为医疗劳动力短缺提供潜在解决方案。

> **ai_Abstract:** 本研究首次大规模评估了名为Doctronic的多代理大型语言模型（LLM）驱动的AI系统在虚拟紧急护理环境中作为自主AI医生的表现。研究通过回顾性比较Doctronic与委员会认证临床医生在500次远程医疗问诊中的诊断和治疗方案一致性及安全性。结果显示，AI在诊断和治疗方案上与人类医生高度一致，且在专家审查中，AI在部分不一致病例中的表现优于人类医生。研究得出结论，该AI系统能够实现与人类医生相当的临床决策能力，并有望成为解决全球医疗劳动力短缺的有效方案。

> **摘要翻译:** 背景：全球预计到2030年将面临1100万医疗从业人员短缺，行政负担消耗了50%的临床时间。人工智能（AI）有潜力帮助缓解这些问题。然而，尚未有端到端自主大型语言模型（LLM）驱动的AI系统在真实世界临床实践中得到严格评估。在本研究中，我们评估了一个多代理LLM驱动的AI框架是否能在虚拟紧急护理环境中自主地作为AI医生运行。
方法：我们回顾性比较了多代理AI系统Doctronic和委员会认证临床医生在500次连续紧急护理远程医疗问诊中的表现。主要终点：诊断一致性、治疗方案一致性和安全指标，通过盲法LLM裁决和专家人工审查进行评估。
结果：Doctronic和临床医生的首要诊断在81%的病例中匹配，治疗方案在99.2%的病例中一致。未发生临床幻觉（例如，诊断或治疗不受临床发现支持）。在对不一致病例的专家审查中，AI性能在36.1%的病例中更优，人类性能在9.3%的病例中更优；其余病例诊断等效。
结论：在首次大规模验证自主AI医生中，我们展示了与人类临床医生强大的诊断和治疗方案一致性，AI性能与执业临床医生匹配，在某些情况下甚至超越。这些发现表明多代理AI系统实现了与人类提供者相当的临床决策能力，并为医疗劳动力短缺提供潜在解决方案。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [866] [Accessibility Scout: Personalized Accessibility Scans of Built Environments](https://arxiv.org/abs/2507.23190)
> *Accessibility Scout：内置环境的个性化无障碍扫描*

*William Huang, Xia Su, Jon E. Froehlich, Yang Zhang* | **Category: cs.HC, cs.AI, cs.CV, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 无障碍, LLM, 建成环境, 个性化, 人机协作

**Comment:** 18 pages, 16 figures. Presented at ACM UIST 2025

> **TL;DR:** Accessibility Scout是一个基于LLM的系统，它通过分析照片并根据用户的移动水平、偏好和环境兴趣进行定制，来识别内置环境中的无障碍问题，解决了手动评估的费力性和自动化方法的非个性化问题。

**AI_Comments:** 这项研究的创新之处在于利用大型语言模型（LLM）实现无障碍评估的个性化和可扩展性，解决了现有手动和自动化方法的不足。通过结合照片分析和人机协作，系统能够更细致地理解用户需求和环境特征，提供了比传统ADA标准更全面的评估。其重要性在于提升了残疾人对建成环境的自主评估能力，对未来的智能辅助技术发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 对于残疾人来说，评估不熟悉的建成环境的可访问性至关重要。然而，手动评估费力且不可扩展，而现有的自动化机器学习方法往往忽略个体用户的独特需求。

**Method:** 本研究提出了一个名为Accessibility Scout的基于大型语言模型（LLM）的无障碍扫描系统。该系统通过分析建成环境的照片来识别无障碍问题。它通过人机协作评估，根据用户的移动水平、偏好和特定环境兴趣，个性化地定制无障碍扫描。研究通过三项研究验证了系统：一项包含六名参与者的形成性研究、一项针对500张建成环境图像的技术评估，以及一项包含10名不同移动能力参与者的用户研究。

**Result:** 技术评估和用户研究的结果表明，Accessibility Scout能够生成超越传统ADA考虑的个性化无障碍扫描。

**Conclusion:** 研究讨论了其工作的意义以及未来构建更具可扩展性和个性化的物理世界无障碍评估系统的步骤。

> **ai_Abstract:** Accessibility Scout是一个基于大型语言模型（LLM）的系统，旨在解决残疾人评估建成环境无障碍性的挑战。它通过分析环境照片来识别无障碍问题，并能根据用户的个性化需求（如移动水平和偏好）进行定制化评估，从而克服了手动评估的局限性和传统自动化方法的非个性化问题。该系统通过技术评估和用户研究证明了其生成个性化无障碍扫描的能力，其结果超越了传统的ADA标准。

> **摘要翻译:** 评估不熟悉的建成环境的可访问性对残疾人至关重要。然而，由用户或其个人健康专业人员进行的手动评估既费力又不可扩展，而自动机器学习方法往往忽视个体用户的独特需求。大型语言模型（LLMs）的最新进展为解决这个问题提供了新颖的方法，平衡了个性化与可扩展性，从而实现更具适应性和上下文感知的可访问性评估。我们提出了Accessibility Scout，一个基于LLM的可访问性扫描系统，它能从建成环境的照片中识别可访问性问题。通过使用，Accessibility Scout会变得越来越有能力，成为一个“可访问性侦察兵”，通过人机协作评估，根据个人的移动水平、偏好和特定环境兴趣来定制可访问性扫描。我们展示了三项研究的结果：一项有六名参与者参与的形成性研究，旨在为Accessibility Scout的设计提供信息；一项对500张建成环境图像进行的技术评估；以及一项有10名不同移动能力参与者参与的用户研究。我们的技术评估和用户研究结果表明，Accessibility Scout可以生成超越传统ADA考虑的个性化可访问性扫描。最后，我们讨论了我们工作的意义以及未来构建更具可扩展性和个性化的物理世界可访问性评估的步骤。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [886] [SketchMind: A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches](https://arxiv.org/abs/2507.22904)
> *SketchMind：一种评估学生科学素描的多智能体认知框架*

*Ehsan Latif, Zirak Khan, Xiaoming Zhai* | **Category: cs.HC, cs.AI** | **Updated: 2025-06-29**

**Keywords:** 科学素描, 多智能体系统, 认知框架, 自动化评估, 学生理解

**Comment:** Submitted to NeurIPS2025

> **TL;DR:** SketchMind是一个多智能体框架，用于评估和改进学生绘制的科学素描，显著提高了评估准确性并提供有益反馈。

**AI_Comments:** SketchMind的创新之处在于其采用多智能体认知框架来解决自由形式科学素描评估的复杂性，这比传统的图像分类或单一视觉-语言模型方法更具可解释性和教学对齐性。其模块化设计增强了适应性，并能提供个性化和透明的反馈，这对于学生概念成长至关重要。研究结果表明了其在自动化评估和辅助教学方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AI驱动的自由形式、视觉多样化科学素描的自动化评估解决方案缺乏可解释性、教学对齐性以及跨认知水平的适应性，且通常将素描评估视为图像分类或单一的视觉-语言模型任务。

**Method:** 提出SketchMind，一个基于认知理论的多智能体框架，用于评估和改进学生绘制的科学素描。它包含负责评估标准解析、素描感知、认知对齐和通过素描修改进行迭代反馈的模块化智能体，从而实现个性化和透明的评估。该框架在一组包含3,575个学生生成素描的数据集上进行了评估，这些素描来自六个需要学生绘制模型来解释现象的不同布鲁姆最高认知水平的科学评估项目。

**Result:** 与基线GPT-4o（平均准确率：55.6%）相比，集成SRG后SketchMind的平均准确率达到77.1%（平均绝对增益+21.4%）。多智能体与SRG的协同增强了SketchMind的性能，例如，GPT-4.1的素描预测准确率平均提高了8.9%，在所有项目中都优于单智能体管道。人类评估者对SketchMind（GPT-4.1）生成的反馈和共同创建的素描平均评分为4.1/5，显著高于基线模型（例如GPT-4o的2.3分）。专家指出该系统通过引导性修订有意义地支持概念成长的潜力。

**Conclusion:** SketchMind通过其创新的多智能体认知框架，显著提高了学生科学素描的自动化评估准确性和反馈质量，证明了其在支持学生概念成长方面的巨大潜力。

> **ai_Abstract:** SketchMind是一个新颖的多智能体认知框架，旨在解决学生科学素描自动化评估中存在的解释性、教学对齐性和适应性挑战。通过模块化智能体进行评估标准解析、素描感知、认知对齐和迭代反馈，SketchMind在大型数据集上表现出显著优于基线模型的评估准确性，并能生成高质量的反馈和共同创建的素描，有望促进学生的概念理解。

> **摘要翻译:** 科学素描（例如模型）为洞察学生的概念理解提供了强大的视角，然而，对此类自由形式、视觉多样化作品的AI驱动自动化评估仍然是一个严峻的挑战。现有解决方案通常将素描评估视为图像分类任务或单一的视觉-语言模型，这缺乏可解释性、教学对齐性以及跨认知水平的适应性。为了解决这些局限性，我们提出了SketchMind，一个基于认知理论的多智能体框架，用于评估和改进学生绘制的科学素描。SketchMind包含负责评估标准解析、素描感知、认知对齐以及通过素描修改进行迭代反馈的模块化智能体，从而实现个性化和透明的评估。我们在一组包含3,575个学生生成素描的精选数据集上评估了SketchMind，这些素描来自六个需要学生绘制模型来解释现象的不同布鲁姆最高认知水平的科学评估项目。与没有SRG的基线GPT-4o性能（平均准确率：55.6%）相比，集成SRG后达到了77.1%的平均准确率（平均绝对增益+21.4%）。我们还证明，多智能体与SRG的协同增强了SketchMind的性能，例如，GPT-4.1的素描预测准确率平均提高了8.9%，在所有项目中都优于单智能体管道。人类评估者对SketchMind与GPT-4.1生成的反馈和共同创建的素描评分为平均4.1分（满分5分），显著高于基线模型（例如GPT-4o的2.3分）。专家指出该系统通过引导性修订有意义地支持概念成长的潜力。我们的代码和（待批准）数据集将发布，以支持AI驱动教育领域的可复现性和未来研究。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [275] [KLAN: Kuaishou Landing-page Adaptive Navigator](https://arxiv.org/abs/2507.23459)
> *KLAN：快手落地页自适应导航器*

*Fan Li, Chang Meng, Jiaqi Fu, Shuchang Liu, Jiashuo Zhang, Tianke Zhang, Xueliang Wang, Xiaoqiang Feng* | **Category: cs.IR, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 个性化落地页, 推荐系统, 页面导航, 快手, KLAN

**Comment:** We propose PLPM, a new task for selecting optimal landing pages upon
  user entry. Our solution, KLAN, models static and dynamic user interests and
  is successfully deployed on Kuaishou, improving DAU and user lifetime

> **TL;DR:** 该论文定义了个性化落地页建模（PLPM）任务，并提出了KLAN模型，旨在优化用户在快手平台上的首个落地页选择，以提升短期和长期用户指标。

**AI_Comments:** 该论文的创新点在于首次明确定义了个性化落地页建模（PLPM）这一推荐系统中的新任务，填补了此前研究主要集中于页内推荐而忽视页面导航的空白。其提出的KLAN分层模型通过结合用户静态偏好和动态兴趣转换，为实现更精准的初始页面导航提供了有效方案。在真实世界平台上的成功部署和显著效果（DAU和LT的提升）证明了其重要性和实用价值。此外，作者计划发布数据集和代码，将极大地促进该领域未来的研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注第二阶段（页内交互）的序列推荐，而对第一阶段（页面导航）如何实现更好的页面导航缺乏深入探讨。为弥补这一空白，本文正式定义了个性化落地页建模（PLPM）任务。

**Method:** 本文提出了KLAN（快手落地页自适应导航器），一个分层解决方案框架，用于在PLPM的背景下提供个性化落地页。KLAN包含三个关键组件：KLAN-ISP捕获日间静态页面偏好；KLAN-IIT捕获日内动态兴趣转换；KLAN-AM自适应地整合这两个组件以做出最优导航决策。

**Result:** 在快手平台上进行的广泛在线实验表明，KLAN是有效的，使日活跃用户（DAU）和用户生命周期（LT）分别提高了+0.205%和+0.192%。KLAN最终已在快手在线平台全面部署，服务数亿用户。

**Conclusion:** 本文定义了个性化落地页建模（PLPM）任务，并提出了一种名为KLAN的分层解决方案框架，以优化用户在平台入口处的落地页选择。实验证明KLAN能显著提升用户活跃度和生命周期，并已成功部署于快手平台，服务数亿用户，有望推动该领域进一步研究。

> **ai_Abstract:** 该论文提出了个性化落地页建模（PLPM）任务，旨在为用户在应用入口处主动选择最优落地页，以提升用户体验和平台指标。为此，论文设计了KLAN（快手落地页自适应导航器）框架，该框架包含KLAN-ISP（捕获日间偏好）、KLAN-IIT（捕获日内动态兴趣）和KLAN-AM（自适应集成）三个核心组件。在线实验验证了KLAN的有效性，显著提升了日活跃用户和用户生命周期，并已在快手平台部署，服务数亿用户。

> **摘要翻译:** 现代在线平台配置多个页面以适应不同的用户需求。这种多页面架构固有地建立了用户与平台之间的两阶段交互范式：(1) 第一阶段：页面导航，将用户导航到特定页面；(2) 第二阶段：页内交互，用户在特定页面内与定制内容进行互动。虽然大多数研究一直专注于改进第二阶段用户反馈的序列推荐任务，但对于如何在第一阶段实现更好的页面导航却鲜有研究。为了填补这一空白，我们正式将个性化落地页建模（PLPM）任务定义到推荐系统领域：给定用户进入应用时，PLPM的目标是从一组候选（例如，功能标签、内容频道或聚合页面）中主动选择最合适的落地页，以优化短期PDR指标和长期用户参与度及满意度指标，同时遵守行业约束。此外，我们提出了KLAN（快手落地页自适应导航器），一个分层解决方案框架，旨在根据PLPM的公式提供个性化落地页。KLAN包含三个关键组件：(1) KLAN-ISP捕获日间静态页面偏好；(2) KLAN-IIT捕获日内动态兴趣转换；(3) KLAN-AM自适应地整合这两个组件以做出最优导航决策。在快手平台进行的广泛在线实验证明了KLAN的有效性，使日活跃用户（DAU）和用户生命周期（LT）分别提高了+0.205%和+0.192%。我们的KLAN最终已在在线平台全面部署，服务数亿用户。为了促进这一重要领域的进一步研究，我们将在论文被接受后发布我们的数据集和代码。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [383] [Audio Prototypical Network For Controllable Music Recommendation](https://arxiv.org/abs/2508.00194)
> *用于可控音乐推荐的音频原型网络*

*Fırat Öncel, Emiliano Penaloza, Haolun Wu, Shubham Gupta, Mirco Ravanelli, Laurent Charlin, Cem Subakan* | **Category: cs.IR, eess.AS** | **Updated: 2025-07-31**

**Keywords:** 音乐推荐, 音频原型网络, 可解释性, 可控性, 用户偏好

**Comment:** Accepted to MLSP2025

> **TL;DR:** 本文提出了一种音频原型网络，用于可控音乐推荐，解决了传统推荐系统缺乏可解释性的问题，并在保持竞争性推荐性能的同时，提供了可解释和可控的用户画像。

**AI_Comments:** 该论文的创新点在于提出了一个音频原型网络，它不仅在音乐推荐中实现了有竞争力的性能，更重要的是解决了传统黑盒模型缺乏可解释性和用户控制能力的关键痛点。通过将用户偏好表达为语义原型，该方法为用户提供了对其音乐偏好建模方式的理解和控制，这在个性化且不断变化的音乐偏好领域尤为重要。这代表了推荐系统领域向更透明和用户中心化方向迈出的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 传统的推荐系统使用黑盒编码模型表示用户偏好，虽然性能强大，但缺乏可解释性，用户无法理解或控制系统如何建模他们的偏好。在音乐推荐中，由于用户偏好高度个性化且基于细微的音乐品质（如情绪、流派、节奏、乐器）演变，这一限制尤为突出。

**Method:** 本文提出了一种音频原型网络，用于可控音乐推荐。该网络通过代表音乐品质语义特征的原型来表达用户偏好。

**Result:** 该模型与流行的基线模型相比，获得了具有竞争力的推荐性能，同时提供了可解释和可控的用户画像。

**Conclusion:** 本文提出的音频原型网络在音乐推荐中实现了与现有模型相当的推荐性能，并显著增强了用户偏好的可解释性和可控性，解决了传统黑盒模型的局限性。

> **ai_Abstract:** 本文提出了一种音频原型网络，旨在解决传统音乐推荐系统缺乏可解释性和用户控制能力的问题。该网络通过语义上有意义的音乐特征原型来表达用户偏好，从而提供可解释的用户画像。实验结果表明，该模型在保持与现有基线模型相当的推荐性能的同时，成功实现了用户偏好的可解释性和可控性。

> **摘要翻译:** 传统推荐系统通过黑盒编码模型获得的密集表示来表示用户偏好。虽然这些模型通常提供强大的推荐性能，但它们缺乏对用户的可解释性，导致用户无法理解或控制系统如何建模他们的偏好。这一限制在音乐推荐中尤其具有挑战性，因为用户偏好高度个性化，并且通常根据情绪、流派、节奏或乐器等细微品质而演变。在本文中，我们提出了一种用于可控音乐推荐的音频原型网络。该网络根据代表音乐品质语义特征的原型来表达用户偏好。我们表明，与流行的基线模型相比，该模型获得了具有竞争力的推荐性能，同时还提供了可解释和可控的用户画像。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [524] [Are Recommenders Self-Aware? Label-Free Recommendation Performance Estimation via Model Uncertainty](https://arxiv.org/abs/2507.23208)
> *推荐系统具有自我意识吗？基于模型不确定性的无标签推荐性能估计*

*Jiayu Li, Ziyi Ye, Guohao Jian, Zhiqiang Guo, Weizhi Ma, Qingyao Ai, Min Zhang* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 推荐系统, 模型不确定性, 无标签性能估计, 自我意识, LiDu

**Comment:** 

> **TL;DR:** 本文提出LiDu方法，通过量化模型不确定性，实现无标签的推荐性能估计，并揭示了推荐不确定性与性能之间的经验联系。

**AI_Comments:** 这项工作提出了一个新颖且重要的概念——推荐系统的“自我意识”，并通过量化模型不确定性来提供无标签的性能估计，这对于推荐系统在实际部署前的预评估具有重要意义。LiDu方法为理解模型内部动态和提高系统透明度提供了一个新视角。

<details>
  <summary>Details</summary>

**Motivation:** 推荐模型在与用户交互之前，需要一种无需标签的性能评估方法，以实现更明智的理解和决策。现有方法可能无法充分量化模型的“自我意识”或不确定性。

**Method:** 本文提出了一种直观且有效的基于概率的列表分布不确定性（LiDu）方法。LiDu通过根据单个项目的预测分布，确定推荐器生成特定排名列表的概率来衡量不确定性。该方法在合成数据集上的矩阵分解模型和真实世界数据集上的流行推荐算法上进行了验证。

**Result:** 实验结果表明，LiDu与推荐性能的相关性高于一系列无标签的性能估计器。此外，LiDu还提供了模型在训练和推理过程中动态内部状态的宝贵见解。

**Conclusion:** 本研究建立了推荐不确定性与性能之间的经验联系，是迈向更透明和自评估推荐系统的重要一步。

> **ai_Abstract:** 本文探讨了推荐模型的自我意识概念，并提出了一种名为LiDu的无标签性能估计方法。LiDu通过量化模型生成特定推荐列表的不确定性来评估其性能。研究在合成和真实数据集上验证了LiDu的有效性，结果表明LiDu与推荐性能高度相关，并能提供模型内部状态的洞察。这项工作建立了推荐不确定性与性能的经验联系，旨在推动透明和自评估推荐系统的发展。

> **摘要翻译:** 推荐模型能够自我感知吗？本文通过量化推荐模型的不确定性来研究其自我意识，这提供了一种无标签的性能估计方法。这种自我评估可以在推荐器与任何用户互动之前，实现更明智的理解和决策。为此，我们提出了一种直观且有效的方法，即基于概率的列表分布不确定性（LiDu）。LiDu通过根据单个项目的预测分布，确定推荐器生成特定排名列表的概率来衡量不确定性。我们在两种设置下验证了LiDu表示模型自我意识的能力：(1) 使用合成数据集上的矩阵分解模型，以及 (2) 使用真实世界数据集上的流行推荐算法。实验结果表明，LiDu与推荐性能的相关性高于一系列无标签的性能估计器。此外，LiDu为模型在训练和推理过程中的动态内部状态提供了宝贵见解。这项工作建立了推荐不确定性与性能之间的经验联系，将其视为迈向更透明和自评估推荐系统的一步。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [559] [Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation](https://arxiv.org/abs/2507.23209)
> *不仅是“什么”，更是“何时”：将不规则时间间隔整合到LLM中用于序列推荐*

*Wei-Wei Du, Takuma Udagawa, Kei Tateno* | **Category: cs.IR, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 序列推荐, 时间间隔, 大型语言模型, 冷启动, 时间间隔注入注意力

**Comment:** Accepted by RecSys 2025 short paper track

> **TL;DR:** 提出IntervalLLM框架，将时间间隔信息融入大型语言模型（LLM）用于序列推荐，并通过引入时间间隔视角改进了冷启动场景的评估和性能。

**AI_Comments:** 这项工作通过将动态时间间隔信息集成到LLM中，并引入“时间间隔注入注意力”机制，为序列推荐领域带来了创新。其独特之处在于提出了“时间间隔视角”来更全面地评估冷启动问题，揭示了该视角下冷启动挑战的严重性，为未来的研究指明了方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的序列推荐方法常忽略商品购买之间的时间间隔，或假定间隔是静态的，而动态时间间隔对用户画像至关重要，且能描述具有相同商品历史的不同用户。

**Method:** 本文提出了IntervalLLM框架，将时间间隔信息整合到大型语言模型（LLM）中，并引入了新颖的“时间间隔注入注意力”机制，以共同考虑商品和时间间隔的信息。此外，与以往仅从用户和商品的角度解决冷启动问题不同，本研究引入了“时间间隔视角”作为评估推荐方法在暖启动和冷启动场景中的额外指标。

**Result:** 在3个基准数据集上进行的大量实验表明，IntervalLLM与传统和基于LLM的基线相比，平均性能提升了4.4%，并且在所有用户、商品以及所提出的时间间隔视角下，在暖启动和冷启动场景中均表现最佳。研究还发现从时间间隔视角来看，冷启动场景在所有推荐方法中性能下降最显著。

**Conclusion:** 该研究强调了进一步研究基于时间间隔的冷启动挑战的必要性，并证实了在序列推荐任务中整合时间间隔信息的重要性。

> **ai_Abstract:** 本文提出了IntervalLLM框架，旨在解决现有序列推荐模型忽略商品购买间动态时间间隔的问题。该框架将时间间隔信息整合到大型语言模型（LLM）中，并引入了“时间间隔注入注意力”机制。此外，作者创新性地引入了“时间间隔视角”来评估冷启动和暖启动场景下的推荐性能。实验结果表明，IntervalLLM在多个基准测试上显著优于现有基线，平均性能提升4.4%，尤其在冷启动场景下从时间间隔视角观察到最显著的性能提升空间。

> **摘要翻译:** 购买商品之间的时间间隔是序列推荐任务中的关键因素，然而现有方法专注于商品序列，并常常通过假设商品之间的时间间隔是静态的而忽视了这一点。然而，动态时间间隔作为一个维度，不仅描述了用户内部的历史，还描述了具有相同商品历史的不同用户。在这项工作中，我们提出了IntervalLLM，一个新颖的框架，它将时间间隔信息整合到大型语言模型（LLM）中，并结合了新颖的“时间间隔注入注意力”机制，以共同考虑商品和时间间隔的信息。此外，与以往仅从用户和商品的角度解决冷启动问题不同，我们引入了一个新的视角：时间间隔视角，作为评估推荐方法在暖启动和冷启动场景中的额外指标。在3个基准数据集上，针对传统和基于LLM的基线进行了大量实验，结果表明我们的IntervalLLM不仅平均提升了4.4%的性能，而且在所有用户、商品以及所提出的时间间隔视角下，在暖启动和冷启动场景中均表现最佳。此外，我们观察到从时间间隔视角来看，冷启动场景在所有推荐方法中经历了最显著的性能下降。这一发现强调了进一步研究基于时间间隔的冷启动挑战以及我们在序列推荐任务领域整合时间间隔信息的必要性。我们的代码可在此处获取：https://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [573] [Holistic Evaluations of Topic Models](https://arxiv.org/abs/2507.23364)
> *主题模型的整体评估*

*Thomas Compton* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 主题模型, BERTopic, 评估, 黑箱, 无监督学习

**Comment:** 10 pages, 6 tables

> **TL;DR:** 本文从数据库角度评估主题模型，利用1140次BERTopic模型运行来理解参数优化中的权衡，并探讨其对负责任使用的意义，旨在避免模型沦为“黑箱”。

**AI_Comments:** 该论文解决了无监督模型中“黑箱”行为的关键问题，这对于实际应用和信任至关重要。大量的模型运行（1140次BERTopic）表明了彻底的实证评估。

<details>
  <summary>Details</summary>

**Motivation:** 主题模型虽然在文本摘要方面越来越受欢迎，但存在成为“黑箱”的风险，用户可能未经审查就接受其输出。本文旨在通过严格评估来解决这一问题。

**Method:** 本文从“数据库”的角度评估主题模型，并从1140次BERTopic模型运行中获取见解。

**Result:** 本文旨在识别优化模型参数时的权衡。

**Conclusion:** 本文旨在反思这些发现对主题模型的解释和负责任使用意味着什么。

> **ai_Abstract:** 本文评估了主题模型，这类模型虽然在文本摘要方面很受欢迎，但可能表现为“黑箱”。研究从数据库视角出发，分析了1140次BERTopic模型运行，旨在识别参数优化中的权衡，并探讨这些发现对模型解释和负责任使用的意义。

> **摘要翻译:** 主题模型因其总结大量非结构化文本的能力而获得越来越多的商业和学术兴趣。作为无监督机器学习方法，它们使研究人员能够探索数据，并帮助普通用户理解大型文本集合中的关键主题。然而，它们有沦为“黑箱”的风险，用户输入数据并接受输出作为准确的摘要而不加审查。本文从数据库的角度评估主题模型，从1140次BERTopic模型运行中获取见解。目标是识别优化模型参数时的权衡，并反思这些发现对主题模型的解释和负责任使用意味着什么。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [593] [Your Spending Needs Attention: Modeling Financial Habits with Transformers](https://arxiv.org/abs/2507.23267)
> *您的消费需要关注：使用Transformer模型建模金融习惯*

*D. T. Braithwaite, Misael Cavalcanti, R. Austin McEver, Hiroto Udagawa, Daniel Silva, Rohan Ramanath, Felipe Meneses, Arissa Yoshida, Evan Wingert, Matheus Ramos, Brian Zanfelice, Aman Gupta* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** Transformer, 金融习惯, 自监督学习, 交易数据, 表示学习

**Comment:** 

> **TL;DR:** 本文提出了一种名为nuFormer的新方法，利用基于Transformer的自监督学习模型处理金融交易数据，以提升大规模推荐系统的性能，并在Nubank的实验中取得了显著改进。

**AI_Comments:** 本文的创新点在于将Transformer架构和自监督学习成功应用于复杂的金融交易数据，解决了传统机器学习方法对特征工程依赖的问题。通过学习更丰富的用户行为表示，该方法在不引入新数据源的情况下，显著提升了大规模推荐系统的性能，展示了深度学习在金融领域应用的巨大潜力。未来可以探索其在更多金融任务如风险评估、欺诈检测中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 金融行业中，预测模型对风险预测、欺诈检测和个性化推荐至关重要，但现有模型多采用传统机器学习方法，依赖手动特征工程，难以有效处理复杂且大规模的非结构化金融数据。其他领域（如自然语言处理）已成功利用自监督学习从原始数据中学习丰富的表示，因此本文旨在探索将Transformer模型应用于交易数据以更好地理解客户行为。

**Method:** 本文提出了一种名为nuFormer的新方法，通过改编基于Transformer的模型来处理文本和结构化属性，从而实现交易数据的自监督学习。该方法包括一个端到端微调过程，将用户嵌入与现有表格特征相结合。

**Result:** 实验证明，该方法在Nubank的大规模推荐问题上取得了改进。这些提升完全是通过增强表示学习实现的，而非引入新的数据源。

**Conclusion:** 基于Transformer的表示学习模型为理解客户行为提供了一种新颖而强大的方法，并通过在金融交易数据上应用自监督学习，显著提升了金融预测模型的性能和推荐系统的效果。

> **ai_Abstract:** 本文针对金融行业中复杂且大规模交易数据处理的挑战，提出了一种名为nuFormer的新型基于Transformer的自监督学习方法。该方法旨在从原始交易数据中学习丰富的表示，并能同时处理文本和结构化属性，通过端到端微调将用户嵌入与现有表格特征结合。实验证明，nuFormer在Nubank的大规模推荐任务上实现了性能提升，凸显了其在理解客户行为和改进金融模型方面的潜力，且这些提升仅来源于增强的表示学习。

> **摘要翻译:** 您的消费需要关注：使用Transformer模型建模金融习惯

预测模型在金融行业中扮演着关键角色，能够实现风险预测、欺诈检测和个性化推荐，其中核心模型性能的微小变化都可能带来数十亿美元的收入或损失。尽管金融机构拥有海量的用户数据（例如银行交易、应用内事件和客户支持日志），但由于其复杂性和规模，有效利用这些数据仍然具有挑战性。因此，在许多金融机构中，大多数生产模型遵循传统的机器学习（ML）方法，通过将非结构化数据转换为手动设计的表格特征。相反，其他领域（例如自然语言处理）已有效利用自监督学习（SSL）从原始数据中学习丰富的表示，从而无需手动特征提取。在本文中，我们研究了使用基于Transformer的表示学习模型处理交易数据，假设这些在海量数据上训练的模型可以提供一种新颖而强大的方法来理解客户行为。我们提出了一种新方法，通过调整基于Transformer的模型来处理文本和结构化属性，从而实现交易数据的自监督学习。我们的方法，命名为nuFormer，包括一个端到端的微调方法，将用户嵌入与现有表格特征相结合。我们的实验证明了在Nubank大规模推荐问题上的改进。值得注意的是，这些收益完全是通过增强表示学习实现的，而不是通过整合新的数据源。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [629] [Towards LLM-Enhanced Product Line Scoping](https://arxiv.org/abs/2507.23410)
> *迈向LLM增强的产品线范围界定*

*Alexander Felfernig, Damian Garber, Viet-Man Le, Sebastian Lubos, Thi Ngoc Trang Tran* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** 产品线范围界定, 大型语言模型, 特征模型, 自然语言交互

**Comment:** 

> **TL;DR:** 本文探讨了如何利用大型语言模型（LLMs）通过自然语言交互来支持产品线范围界定任务，以解决传统手动分析耗时的问题。

**AI_Comments:** 本文提出了一种新颖的方法，将LLMs引入产品线范围界定，有望大幅减少传统手动分析的时间消耗，提升效率。其创新点在于利用LLMs的自然语言处理能力，使范围界定过程更加直观和自动化。尽管目前仅是初步探讨和草拟，但为未来该领域的研究开辟了新的方向。文章也坦诚地指出了开放的研究挑战，这有助于推动后续的深入研究。

<details>
  <summary>Details</summary>

**Motivation:** 传统的产品线范围界定方法依赖于形式化的特征模型，需要大量手动分析，这非常耗时。

**Method:** 本文草拟了如何应用大型语言模型（LLMs）通过基于自然语言交互的范围界定过程来支持产品线范围界定任务。

**Result:** 通过一个智能家居领域的工作实例，本文草拟了LLMs如何应用于评估不同的特征模型替代方案。

**Conclusion:** 本文讨论了LLMs与产品线范围界定集成方面的开放研究挑战。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLMs）改进产品线范围界定任务的方法。针对传统手动分析耗时的问题，研究者们探讨了如何通过自然语言交互实现产品线范围界定过程，并以智能家居为例，展示了LLMs在评估不同特征模型替代方案中的应用潜力。文章还讨论了LLMs与产品线范围界定集成面临的开放研究挑战。

> **摘要翻译:** 产品线范围界定的思想是确定产品线应包含的功能和配置集，即为配置目的提供的内容。在此背景下，一项主要的范围界定任务是在商业相关性和技术可行性之间找到平衡。传统的产品线范围界定方法依赖于形式化的特征模型，并且需要手动分析，这可能相当耗时。在本文中，我们草拟了如何应用大型语言模型（LLMs）通过基于自然语言交互的范围界定过程来支持产品线范围界定任务。通过一个智能家居领域的工作实例，我们草拟了LLMs如何应用于评估不同的特征模型替代方案。我们讨论了LLMs与产品线范围界定集成方面的开放研究挑战。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [664] [TransFR: Transferable Federated Recommendation with Adapter Tuning on Pre-trained Language Models](https://arxiv.org/abs/2402.01124)
> *TransFR：基于预训练语言模型适配器微调的可迁移联邦推荐*

*Honglei Zhang, Zhiwei Li, Haoxuan Li, Xin Zhou, Jie Zhang, Yidong Li* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** 联邦推荐, 适配器微调, 预训练模型, 可迁移性, 隐私保护

**Comment:** 

> **TL;DR:** TransFR提出了一种可迁移的联邦推荐模型，通过结合预训练模型和适配器微调解决了传统联邦推荐在可迁移性、冷启动和隐私方面的局限性。

**AI_Comments:** TransFR的创新之处在于将预训练语言模型的通用能力与联邦学习相结合，并通过适配器微调实现了高效的个性化和隐私保护。这为解决联邦推荐在跨领域迁移和冷启动场景下的挑战提供了一个有前景的解决方案，尤其是在保护用户隐私方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统联邦推荐（FRs）普遍采用离散身份表示客户端和物品，并映射到特定领域嵌入进行训练，但这存在三个固有局限性：跨领域不可迁移性、冷启动设置下无效以及联邦训练期间潜在的隐私泄露。

**Method:** 提出TransFR模型，该模型巧妙地结合了预训练模型赋予的通用能力和通过微调本地私有数据实现的个性化能力。具体而言，它首先利用公共文本语料库中的预训练模型学习物品的领域无关表示。为了适应FR任务，进一步引入了高效的联邦适配器微调和测试时适应机制，通过拟合客户端的私有数据分布，为每个客户端定制个性化本地适配器。

**Result:** 理论证明了在联邦推荐中引入适配器微调在有效性和隐私方面的优势。通过广泛实验表明，TransFR模型在可迁移性方面超越了几个最先进的联邦推荐模型。

**Conclusion:** 本文理论证明了在联邦推荐中引入适配器微调在有效性和隐私方面的优势。实验结果也证实了TransFR模型在可迁移性方面优于现有最先进的联邦推荐模型。

> **ai_Abstract:** TransFR是一种新型的可迁移联邦推荐模型，旨在克服传统联邦推荐在跨领域可迁移性、冷启动和隐私方面的挑战。该模型利用预训练模型学习领域无关的物品表示，并通过联邦适配器微调和测试时适应机制为每个客户端提供个性化适配器。理论和实验结果均表明，TransFR在有效性、隐私保护和可迁移性方面表现出色，超越了现有最先进的联邦推荐系统。

> **摘要翻译:** 联邦推荐（FRs）作为一种流行的设备端服务，旨在促进多个本地客户端在不泄露用户私有数据的情况下共同学习一个全局模型。在传统的FRs中，主流范式是利用离散身份来表示客户端和物品，然后将其映射到特定领域嵌入以参与模型训练。尽管性能可观，但我们揭示了在联邦设置中无法忽视的三个固有局限性：跨领域不可迁移性、冷启动设置下无效以及联邦训练期间潜在的隐私泄露。为此，我们提出了一种可迁移的联邦推荐模型TransFR，它巧妙地结合了预训练模型赋予的通用能力和通过微调本地私有数据实现的个性化能力。具体而言，它首先利用公共文本语料库的预训练模型学习物品的领域无关表示。为了适应FR任务，我们进一步引入了高效的联邦适配器微调和测试时适应机制，通过拟合其私有数据分布，为每个客户端定制个性化本地适配器。我们从有效性和隐私两方面理论证明了在FRs中引入适配器微调的优势。通过广泛的实验，我们表明我们的TransFR模型在可迁移性方面超越了几个最先进的FRs。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [706] [KeyB2: Selecting Key Blocks is Also Important for Long Document Ranking with Large Language Models](https://arxiv.org/abs/2411.06254)
> *KeyB2：选择关键块对于使用大型语言模型进行长文档排序也很重要*

*Minghan Li, Eric Gaussier, Juntao Li, Guodong Zhou* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** 长文档排序, 大型语言模型, 块选择, 信息检索, KeyB2

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）在长文档重排序中效率低下且计算成本高昂。本文提出的KeyB2框架通过结合块预选择和解码器专用LLM，显著提升了长文档排序的性能和效率，在TREC DL 2019任务上达到SOTA，并大幅降低了延迟和内存使用。

**AI_Comments:** 这项工作通过深入分析LLM在长文档处理中的注意力模式，揭示了其效率下降的原因，并在此基础上提出了一个结合块选择和LLM的创新框架KeyB2。其核心贡献在于证明了“选择关键块”对于提升LLM在长文档排序中的性能和效率至关重要。KeyB2不仅提升了性能达到SOTA，还显著降低了计算资源消耗，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 将大型语言模型（LLM）应用于长文档重排序计算成本高昂且可能效率低下。此外，LLM在文档相关性判断中的内部行为仍未得到充分探索。研究发现LLM的注意力对相关性信号的对齐会随着不相关内容的增加而恶化，这促使作者重新审视并扩展块选择范式。

**Method:** 通过深入分析解码器专用LLM的注意力模式，发现相关性信号与注意力头的一致性会随不相关内容的增加而下降。在此基础上，提出了KeyB2框架，它将块预选择与强大的解码器专用LLM相结合。KeyB2泛化了选择阶段以支持BM25、交叉编码器和双编码器，并调整LLM以计算细粒度的相关性分数。此外，还引入了一种新的高效双编码器策略。

**Result:** KeyB2在TREC DL 2019/2023文档任务、Robust04和MLDR-zh等数据集上进行了广泛实验，结果表明它优于包括RankLLaMA、RankLLaMA-MaxP/AvgP和KeyB在内的基线模型，并在TREC DL 2019文档重排序任务上取得了新的最先进（SOTA）结果。此外，与RankLLaMA相比，KeyB2将重排序延迟降低了83%以上，内存使用量降低了74%以上。

**Conclusion:** KeyB2是一个实用且有效的解决方案，适用于使用大型语言模型进行长文档排序，因为它在性能上达到了SOTA，并显著降低了计算延迟和内存消耗。

> **ai_Abstract:** 本文提出了KeyB2，一个针对长文档重排序的可扩展框架，旨在解决大型语言模型（LLM）在此任务中效率低下的问题。研究发现LLM的注意力在无关内容增多时对相关性信号的对齐会变差。KeyB2通过结合块预选择（支持BM25、交叉编码器和双编码器）和解码器专用LLM来计算细粒度相关性分数，并引入了新的双编码器策略。实验表明，KeyB2在多个数据集上超越了现有基线，并在TREC DL 2019任务上达到了SOTA，同时显著降低了重排序的延迟和内存消耗，证明了其在长文档排序中的实用性和有效性。

> **摘要翻译:** 大型语言模型（LLM）的出现，如Llama，极大地推动了神经信息检索（IR）的发展。然而，将LLM应用于长文档重排序仍然计算成本高昂且可能效率低下。此外，LLM在文档相关性判断过程中的内部行为仍未得到充分探索。在本文中，我们首先深入分析了解码器专用LLM的注意力模式，发现一些注意力头持续与相关性信号对齐，但这种对齐随着不相关内容的增加而恶化。受此观察的启发，我们重新审视并扩展了块选择范式，引入了KeyB2，一个将块预选择与强大的解码器专用LLM相结合的可扩展重排序框架。KeyB2将选择阶段泛化以支持BM25、交叉编码器和双编码器，并调整LLM以计算细粒度的相关性分数。我们进一步引入了一种新的双编码器策略，该策略表现强劲且高效。在TREC DL 2019/2023文档任务、Robust04和MLDR-zh上的广泛实验表明，KeyB2优于包括RankLLaMA、RankLLaMA-MaxP/AvgP和KeyB在内的基线，在TREC DL 2019文档重排序任务上取得了新的最先进（SOTA）结果。此外，与RankLLaMA相比，KeyB2将重排序延迟降低了83%以上，内存使用量降低了74%以上，这使其成为使用LLM进行长文档排序的实用且有效的解决方案。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [747] [An Ecosystem for Ontology Interoperability](https://arxiv.org/abs/2507.12311)
> *本体互操作性生态系统*

*Zhangcheng Qiang* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** 本体互操作性, 知识图谱, 本体工程, 本体设计模式, 本体匹配与版本控制

**Comment:** 5 pages, 8 figures

> **TL;DR:** 本文提出了一个本体互操作性生态系统，该系统在本体工程生命周期的不同阶段采用本体设计模式、本体匹配与版本控制以及本体兼容知识图谱，以解决知识图谱中本体互操作性的复杂问题。

**AI_Comments:** 该论文通过提出一个结构化的生态系统来解决本体互操作性问题，这具有创新性。它将不同的先进语义技术整合到本体工程的各个阶段，提供了一个全面的解决方案。其重要性在于能够促进知识图谱中本体的更广泛应用和数据集成。然而，抽象中没有详细说明该生态系统的具体实现细节或其在更广泛领域的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 本体互操作性是限制本体在知识图谱中使用的复杂问题。不同本体之间概念的冲突和重叠使得为下游任务设计、开发和部署可互操作的本体变得困难。

**Method:** 本文提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种最先进的语义技术：设计阶段的本体设计模式（ODPs），开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的本体兼容知识图谱（OCKGs）。

**Result:** 通过在建筑领域传感器观测的案例研究，验证了所提出生态系统的有用性。

**Conclusion:** 该生态系统通过在本体工程生命周期的不同阶段应用特定的语义技术，实现了更好的本体互操作性和实际应用中的数据集成。

> **ai_Abstract:** 本文提出了一个本体互操作性生态系统，旨在解决知识图谱中因本体概念冲突和重叠导致的互操作性难题。该生态系统在本体工程生命周期的设计、开发和部署阶段分别整合了本体设计模式、本体匹配与版本控制以及本体兼容知识图谱，以提升本体互操作性和数据集成能力。一个关于建筑领域传感器观测的案例研究证实了其有效性。

> **摘要翻译:** 本体互操作性是限制本体在知识图谱（KGs）中使用的复杂问题之一。不同本体之间冲突和重叠的概念使得为下游任务设计、开发和部署可互操作的本体变得困难。我们提出了一个本体互操作性生态系统。该生态系统在本体工程生命周期的不同阶段采用了三种最先进的语义技术：设计阶段的本体设计模式（ODPs），开发阶段的本体匹配与版本控制（OM&OV），以及部署阶段的本体兼容知识图谱（OCKGs），以在实际应用中实现更好的本体互操作性和数据集成。建筑领域传感器观测的案例研究验证了所提出生态系统的有用性。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [790] [Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment](https://arxiv.org/abs/2507.18518)
> *查询前转换：一种基于嵌入空间对齐的隐私保护向量检索方法*

*Ruiqi He, Zekun Fei, Jiaqi Li, Xinyuan Zhu, Biao Yi, Siyi Lv, Weijie Liu, Zheli Liu* | **Category: cs.IR** | **Updated: 2025-07-31**

**Keywords:** 向量检索, 隐私保护, 嵌入空间对齐, 向量数据库, STEER

**Comment:** 

> **TL;DR:** STEER是一种保护查询文本隐私的向量检索框架，它使用近似嵌入在不修改现有向量数据库的情况下实现高精度检索。

**AI_Comments:** 该论文提出了一种创新的、无需修改服务器端的隐私保护向量检索方法，解决了现有VDB服务中敏感信息泄露的关键问题。其通过嵌入空间对齐生成近似嵌入的思路，在保障隐私的同时，还能维持甚至提升检索性能，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的向量数据库服务提供商强制用户通过API暴露原始查询文本以获取向量检索服务，当查询文本涉及敏感信息时，会导致用户敏感信息的关键泄露。

**Method:** 本文引入了STEER（Secure Transformed Embedding Vector Retrieval）框架，它利用不同嵌入模型语义空间之间的对齐关系来推导出查询文本的近似嵌入。STEER使用这些近似嵌入在原始VDB中执行检索，且无需修改服务器端。

**Result:** 理论和实验分析表明STEER有效保护查询文本隐私，同时保持检索准确性。近似嵌入能阻止提供商通过嵌入反演攻击（EIAs）恢复查询文本。实验结果显示，STEER的Recall@100基本可以实现不到5%的下降。在数百万条目文本语料库中，STEER的Recall@20准确率比现有基线高20%。

**Conclusion:** STEER框架能够有效保护用户查询文本的隐私，同时在不修改现有向量数据库的情况下保持高水平的检索准确性，甚至在某些情况下优于现有基线。

> **ai_Abstract:** 本文提出了STEER框架，旨在解决向量数据库服务中用户敏感查询文本隐私泄露的问题。STEER通过生成查询文本的近似嵌入，并在不修改现有VDB的情况下进行检索，从而有效保护隐私，同时保持高检索精度，甚至在某些情况下优于现有方法。

> **摘要翻译:** 向量数据库（VDB）能够高效索引和搜索来自非结构化数据的高维向量嵌入，这对于现代AI应用（如生成式AI和推荐系统）中必不可少的快速语义相似性搜索至关重要。由于当前的VDB服务提供商主要使用专有的黑盒模型，用户被迫通过API向其暴露原始查询文本以获取向量检索服务。因此，如果查询文本涉及金融或医疗领域的机密记录，这种机制不可避免地会导致用户敏感信息的关键泄露。为了解决这个问题，我们引入了STEER（安全转换嵌入向量检索），这是一种私有向量检索框架，它利用不同嵌入模型语义空间之间的对齐关系来导出查询文本的近似嵌入。STEER在原始VDB中利用近似嵌入执行检索，并且不需要对服务器端进行任何修改。我们的理论和实验分析表明，STEER有效地保护了查询文本隐私，同时保持了检索准确性。尽管近似嵌入是专有模型嵌入的近似值，但它们仍然可以防止提供商通过嵌入反演攻击（EIAs）恢复查询文本。大量的实验结果表明，STEER的Recall@100基本可以实现不到5%的下降。此外，即使在数百万条目的文本语料库中搜索时，STEER的Recall@20准确率也比当前基线高20%。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [832] [RecGPT Technical Report](https://arxiv.org/abs/2507.22879)
> *RecGPT 技术报告*

*Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou, Ziqi Zhang* | **Category: cs.IR, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 推荐系统, 大型语言模型, 用户意图, RecGPT, 淘宝

**Comment:** 

> **TL;DR:** RecGPT是一个以用户意图为中心的推荐系统，通过整合大型语言模型解决现有推荐系统过度依赖历史数据导致的问题，并在淘宝上线并取得显著效果。

**AI_Comments:** RecGPT的创新点在于其以用户意图为中心的推荐范式，并通过集成大型语言模型（LLMs）来解决传统推荐系统过度依赖历史数据和日志拟合的问题。它通过多阶段训练和人-LLM协作判断系统，有效地将LLM应用于推荐任务。该工作的重要性在于其在实际工业系统（淘宝）中的成功部署和显著效果，为LLM在推荐领域的应用提供了强有力的实践验证，并指出了未来推荐系统发展的一个可持续方向。

<details>
  <summary>Details</summary>

**Motivation:** 大多数当前工业推荐系统过度依赖历史共现模式和日志拟合目标，导致对狭窄历史偏好的过拟合，未能捕捉用户不断演变和潜在的兴趣，加剧了过滤气泡和长尾现象，最终损害用户体验并威胁推荐生态系统的可持续性。

**Method:** 提出了RecGPT框架，将用户意图置于推荐流程的中心。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，将日志拟合推荐转变为以意图为中心的过程。RecGPT采用多阶段训练范式，包括推理增强的预对齐和自训练演进，并由人-LLM协作判断系统指导。

**Result:** RecGPT已在淘宝App上全面部署。在线实验表明，RecGPT在所有利益相关者之间都取得了持续的性能提升：用户受益于内容多样性和满意度的增加，商家和平台获得了更大的曝光和转化。

**Conclusion:** LLM驱动的、以意图为中心的设计可以促进一个更可持续和互惠互利的推荐生态系统。

> **ai_Abstract:** 本技术报告介绍了RecGPT，一个旨在通过将用户意图置于核心来革新推荐系统的新框架。当前系统过度依赖历史数据，导致用户兴趣捕获不足和过滤气泡。RecGPT通过在用户兴趣挖掘、物品检索和解释生成中集成大型语言模型（LLMs），并采用多阶段训练范式，将推荐过程从日志拟合转变为意图中心。RecGPT已在淘宝App部署，在线实验显示其显著提升了用户满意度、内容多样性以及商家和平台的曝光与转化，验证了LLM驱动的意图中心设计对构建可持续推荐生态系统的有效性。

> **摘要翻译:** 推荐系统是人工智能最具影响力的应用之一，是连接用户、商家和平台的关键基础设施。然而，大多数当前的工业系统仍然严重依赖历史共现模式和日志拟合目标，即优化过去的用户交互而没有明确建模用户意图。这种日志拟合方法常常导致对狭窄历史偏好的过拟合，未能捕捉用户不断演变和潜在的兴趣。结果，它加剧了过滤气泡和长尾现象，最终损害了用户体验并威胁到整个推荐生态系统的可持续性。
为了解决这些挑战，我们重新思考了推荐系统的整体设计范式，并提出了RecGPT，一个将用户意图置于推荐流程中心的新一代框架。通过将大型语言模型（LLMs）整合到用户兴趣挖掘、物品检索和解释生成等关键阶段，RecGPT将日志拟合推荐转变为以意图为中心的过程。为了有效地将通用LLMs大规模地应用于上述领域特定的推荐任务，RecGPT整合了多阶段训练范式，包括推理增强的预对齐和自训练演进，并由人-LLM协作判断系统指导。目前，RecGPT已在淘宝App上全面部署。在线实验表明，RecGPT在所有利益相关者之间都取得了持续的性能提升：用户受益于内容多样性和满意度的增加，商家和平台获得了更大的曝光和转化。这些在所有利益相关者之间取得的全面改进结果验证了LLM驱动的、以意图为中心的设计可以促进一个更可持续和互惠互利的推荐生态系统。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [17] [From Link Diversity to Cross-Band Feedback Collaboration: A New Perspective on Hybrid Optical-RF Systems](https://arxiv.org/abs/2507.23686)
> *从链路分集到跨频带反馈协作：混合光-射频系统的新视角*

*Menghan Li, Yulin Shao, Runxin Zhang, Lu Lu* | **Category: cs.IT, cs.SY, eess.SY, math.IT** | **Updated: 2025-07-31**

**Keywords:** 混合光-射频系统, 跨频带协作, 反馈信道编码, 上行链路吞吐量, 光无线通信

**Comment:** 

> **TL;DR:** 本文提出将混合光-射频（O-RF）系统中的光下行链路用于射频上行链路的实时反馈信道编码，实现跨频带协作，显著提升上行吞吐量。

**AI_Comments:** 这篇论文的创新点在于它改变了对混合光-射频（O-RF）系统中光学链路的传统认知，从被动的链路分集转变为主动的跨频带协作。通过将光下行链路重新定义为射频上行链路的实时反馈信道，它为提升混合无线网络的性能开辟了新途径，特别是显著提高了上行链路吞吐量。这种协同而非冗余的视角对于未来无线通信系统的设计具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统混合光-射频（O-RF）系统将光学链路主要视为增强鲁棒性的分集驱动网络，仅在射频和光链路之间切换。本文旨在挑战这一传统观点，并探索光学链路的新用途。

**Method:** 提出了一种名为O-RF跨频带反馈（O-RF-CBF）的新颖架构。该架构利用光下行链路提供结构化解码器反馈，以指导发射机的编码策略，从而在射频上行链路实现实时反馈信道编码，促进自适应射频上行链路编码。

**Result:** 数值结果表明，O-RF-CBF架构比传统O-RF系统实现了显著的上行链路吞吐量增益。

**Conclusion:** 混合无线网络的全部潜力在于频带间的协同作用，而非冗余。

> **ai_Abstract:** 本文挑战了混合光-射频（O-RF）系统仅依赖链路分集的传统观念，提出了一种新的架构——O-RF跨频带反馈（O-RF-CBF）。该架构创新性地利用光下行链路为射频上行链路提供实时反馈信道编码，从而实现跨频带协作。数值结果表明，这种方法显著提升了上行链路吞吐量，强调了频带间协同作用对混合无线网络潜力的重要性。

> **摘要翻译:** 我们建议重新审视混合光-射频（O-RF）系统主要作为分集驱动网络，通过在射频和光链路之间切换以增强鲁棒性的传统观点。相反，我们发现了一个新的架构机会：重新利用光下行链路，以在射频上行链路实现实时反馈信道编码，其中结构化解码器反馈从接入点传递，以指导发射机的编码策略。这一见解标志着从被动链路分集到主动跨频带协作的概念范式转变，其中宽带、无干扰的光无线通信（OWC）不再仅仅是下行链路的备份，而是上行链路可靠性的功能性促成者。为了实现这一愿景，我们提出了一种新颖的架构，即带有跨频带反馈的O-RF（O-RF-CBF），它利用光下行链路反馈来促进自适应射频上行链路编码。数值结果表明，O-RF-CBF比传统O-RF系统实现了显著的上行链路吞吐量增益。我们的发现强调，频带间协同作用而非冗余，是释放混合无线网络全部潜力的关键。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [34] [Active IRS-Enabled Integrated Sensing and Communications with Extended Targets](https://arxiv.org/abs/2508.00379)
> *主动式IRS赋能的扩展目标综合感知与通信*

*Yuan Fang, Xianxin Song, Huazhou Hou, Ziguo Zhong, Xianghao Yu, Jie Xu, Yongming Huang* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** 主动式IRS, 综合感知与通信, 克拉默-劳界, 波束成形优化, 交替优化

**Comment:** 

> **TL;DR:** 本文研究了主动式IRS赋能的ISAC系统，通过优化基站和IRS的波束成形来最小化感知CRB并满足通信要求。提出了AO算法，并证明主动式IRS总是以最大增益放大信号。

**AI_Comments:** 本文将主动式IRS引入ISAC系统，以解决非视距环境下的路径损耗问题，这是一项重要的创新。对基站和主动式IRS波束成形进行联合优化，兼顾感知CRB最小化和通信SINR要求，其复杂性通过所提出的AO算法得到了很好的解决。主动式IRS总是以最大放大增益运行的发现为系统设计提供了有价值的见解。与被动式IRS的比较突出了主动式方法的实际优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服非视距（NLoS）通信和感知中显著的反射路径损耗，部署主动式智能反射面（IRS），以实现对多个通信用户（CU）和扩展目标的综合感知与通信（ISAC）。

**Method:** 推导了用于估计目标响应矩阵的感知克拉默-劳界（CRB）。联合优化基站的发射波束成形和主动式IRS的反射波束成形，以最小化感知CRB，同时满足通信用户的信噪比（SINR）要求、发射功率预算和功率放大增益约束。针对非凸优化问题，首先考虑纯感知场景推导闭合形式的最优发射波束成形，然后提出两种高效的基于交替优化（AO）的算法来解决通用ISAC场景问题。分析了基站功率缩放与主动式IRS放大缩放之间的关系。

**Result:** 推导出了纯感知场景下闭合形式的最优发射波束成形。所提出的基于AO的算法能够为通用ISAC场景获得高质量的解决方案。结果表明，在实际系统设置下，主动式IRS总是使用最大放大增益来放大信号。数值结果验证了所提出AO算法的有效性以及主动式IRS赋能的ISAC相较于被动式IRS的优势。

**Conclusion:** 本文有效证明了主动式IRS在ISAC系统中的优势，提供了高效的优化算法，并深入分析了其功率放大行为，显示出比被动式IRS更优越的性能。

> **ai_Abstract:** 本文研究了主动式智能反射面（IRS）赋能的综合感知与通信（ISAC）系统，其中主动式IRS辅助基站服务通信用户并感知非视距扩展目标。为克服路径损耗，主动式IRS具备信号放大能力。文章推导了感知克拉默-劳界（CRB），并联合优化基站发射波束成形和主动式IRS反射波束成形以最小化CRB，同时满足通信SINR等约束。针对非凸优化问题，论文首先分析了纯感知场景以推导闭合解，随后提出了两种高效的交替优化（AO）算法用于通用ISAC场景。研究还发现，主动式IRS在实际系统设置下总是以最大放大增益运行。数值结果验证了所提算法的有效性以及主动式IRS在ISAC中相较于被动式IRS的优势。

> **摘要翻译:** 本文研究了主动式智能反射面（IRS）赋能的综合感知与通信（ISAC），其中部署主动式IRS来辅助基站（BS）服务多个通信用户（CU）并同时感知基站非视距（NLoS）区域的扩展目标。主动式IRS能够放大反射信号，以克服NLoS通信和感知中显著的反射路径损耗。具体而言，我们推导了用于估计目标响应矩阵的感知克拉默-劳界（CRB）。因此，我们联合优化基站的发射波束成形和主动式IRS的反射波束成形，以最小化感知CRB，同时满足通信用户的信噪比（SINR）要求、基站和主动式IRS的发射功率预算以及主动式IRS的功率放大增益约束。CRB最小化问题是高度非凸的，因此通常难以解决。为了应对这一挑战，我们首先关注两种特定条件，通过忽略通信的SINR约束来考虑纯感知场景，并推导出了闭合形式的最优发射波束成形。然后，我们提出了两种高效的基于交替优化（AO）的算法，以获得通用ISAC场景的高质量解。接下来，我们分析了基站功率缩放与主动式IRS放大缩放之间的内在关系。结果表明，在实际系统设置下，主动式IRS总是使用最大放大增益来放大信号。最后，提供了数值结果以验证所提出的基于AO的算法的有效性以及主动式IRS赋能的ISAC相较于其被动式IRS对应物的优势。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [59] [Cell-Free Massive MIMO SWIPT with Beyond Diagonal Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2507.23702)
> *采用超越对角线可重构智能表面的无蜂窝大规模MIMO SWIPT*

*Duc Thien Hua, Mohammadali Mohammadi, Hien Quoc Ngo, Michail Matthaiou* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** BDRIS, CFmMIMO, SWIPT, 能量收集, 优化

**Comment:** 

> **TL;DR:** 本文研究了将超越对角线可重构智能表面（BDRIS）集成到无蜂窝大规模MIMO（CFmMIMO）系统中，以增强同时无线信息与功率传输（SWIPT）性能，并通过联合优化和先进算法实现了显著的能量收集增益。

**AI_Comments:** 该论文创新性地将超越对角线可重构智能表面（BDRIS）引入无蜂窝大规模MIMO SWIPT系统，旨在突破传统对角线RIS的局限性。其最大的亮点在于通过BDRIS的灵活配置和精细的联合优化（包括AP选择、功率控制和散射矩阵设计），以及采用深度强化学习等先进算法，实现了显著的能量收集性能提升。高达七倍的能量增益证明了BDRIS在该领域的重要潜力和应用价值。这项工作为未来无线通信中能量收集与信息传输的协同优化提供了新的思路和强大的技术支持。

<details>
  <summary>Details</summary>

**Motivation:** 为了增强无蜂窝大规模MIMO（CFmMIMO）系统中的同时无线信息与功率传输（SWIPT）性能，通过引入超越对角线可重构智能表面（BDRIS）来提升系统效率。

**Method:** 研究将BDRIS集成到CFmMIMO系统中，以同时支持能量接收器（ERs）和信息接收器（IRs）两组用户。部分接入点（APs）在BDRIS的辅助下服务ERs，其余APs服务IRs。采用保护性部分零迫（PZF）预编码技术来管理ERs和IRs之间的非相干干扰。基于长期统计信道状态信息，提出了一个联合优化AP选择、AP功率控制以及BDRIS散射矩阵设计的综合优化问题。该问题被转化为更易处理的形式，并提出高效算法进行求解，包括用于散射矩阵设计的启发式搜索，以及用于AP模式选择和功率控制的连续凸逼近（SCA）和深度强化学习（DRL）方法。

**Result:** 数值结果表明，采用分组或全连接架构的BDRIS比传统对角线RIS实现了显著的能量收集增益。特别是，当采用基于启发式的散射矩阵设计时，平均收集能量总和可提高高达七倍。

**Conclusion:** 将超越对角线可重构智能表面（BDRIS）集成到无蜂窝大规模MIMO SWIPT系统中能够显著提升能量收集性能，尤其是在采用特定架构和优化设计时，相比传统RIS具有压倒性优势。

> **ai_Abstract:** 本文探讨了将超越对角线可重构智能表面（BDRIS）应用于无蜂窝大规模MIMO（CFmMIMO）系统，以提升同时无线信息与功率传输（SWIPT）效率。为同时服务能量接收器（ERs）和信息接收器（IRs），系统将部分接入点（APs）与BDRIS结合服务ERs，其余APs服务IRs，并采用保护性部分零迫预编码技术管理干扰。研究构建了一个联合优化AP选择、功率控制和BDRIS散射矩阵设计的复杂问题，并利用启发式搜索、连续凸逼近和深度强化学习等算法进行求解。数值结果显示，相比传统对角线RIS，BDRIS（尤其是分组或全连接架构）能显著提高能量收集增益，在最佳情况下可达七倍。

> **摘要翻译:** 我们研究了将超越对角线可重构智能表面（BDRIS）集成到无蜂窝大规模多输入多输出（CFmMIMO）系统中，以增强同时无线信息与功率传输（SWIPT）。为了在不牺牲时频资源的情况下同时支持能量接收器（ERs）和信息接收器（IRs）两组用户，一部分接入点（APs）在BDRIS的辅助下专门服务ERs，而其余APs则专注于支持IRs。在APs处实施了一种保护性部分零迫预编码技术，以管理ERs和IRs之间的非相干干扰。随后，利用IRs的频谱效率和ERs的平均总收集能量的闭合表达式，建立了一个综合优化问题。该问题基于长期统计信道状态信息，联合优化了AP选择、AP功率控制和BDRIS的散射矩阵设计。这个具有挑战性的问题随后被有效地转化为更易处理的形式。为了解决这些子问题，提出了高效的算法，包括用于散射矩阵设计的启发式搜索，以及用于联合AP模式选择和功率控制设计的连续凸逼近和深度强化学习方法。数值结果表明，具有分组或全连接架构的BDRIS比传统的对角线RIS实现了显著的能量收集增益，特别是在采用基于启发式的散射矩阵设计时，平均收集能量总和可提高高达七倍。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [69] [LO-Aware Adaptive Modulation for Rydberg Atomic Receivers](https://arxiv.org/abs/2508.00458)
> *里德堡原子接收机的LO感知自适应调制*

*Jiuyu Liu, Yi Ma, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** 里德堡原子接收机, 自适应调制, 本地振荡器, 量子通信, 幅度检测

**Comment:** Accepted by IEEE GLOBECOM 2025

> **TL;DR:** 本文提出了一种名为LOAM的自适应调制方案，专门用于里德堡原子接收机，以克服其仅检测信号幅度的限制，并在仿真中显示出相较于传统调制方案超过45 dB的性能增益。

**AI_Comments:** 这项研究通过引入LOAM方案，有效地解决了里德堡原子接收机在无线通信中面临的关键相位信息丢失问题。其创新点在于提出了一种自适应的共线星座架构，并根据参考信号强度调整星座分布，这对于量子通信领域是重要的进展。超过45 dB的性能增益表明了该方案的巨大潜力，预示着里德堡原子接收机在实际应用中的可行性将大大提高。

<details>
  <summary>Details</summary>

**Motivation:** 里德堡原子（RA）接收机作为一种革命性的量子无线通信技术，具有超越传统射频（RF）天线的灵敏度。然而，这些接收机仅能检测信号幅度，导致关键相位信息的丢失。尽管本地振荡器（LO）生成的参考信号可以辅助相位恢复，但现有为传统系统设计的调制方案在这种量子检测机制下表现不佳。

**Method:** 本文提出了一种突破性的LO感知自适应调制（LOAM）方案，专为里德堡原子接收机开发，能够动态适应复杂的衰落信道系数。LOAM通过最大化星座点之间的最小幅度差来确保最佳检测性能。该创新采用了与参考信号和信道系数组合相位对齐的自适应共线星座结构。对于强参考信号，LOAM生成以原点为中心的对称星座点；对于弱信号，它采用非对称分布。论文还数学推导了控制这些操作区域的阈值。

**Result:** 仿真结果显示了LOAM的变革性影响，与包括正交幅度调制（QAM）、相移键控（PSK）和脉冲幅度调制（PAM）在内的传统调制方案相比，性能增益超过45 dB。

**Conclusion:** LOAM方案显著提高了里德堡原子接收机在无线通信中的性能，通过自适应调制克服了仅检测信号幅度的限制，并实现了远超传统方案的检测性能。

> **ai_Abstract:** 本文提出了一种名为LO-Aware Adaptive Modulation (LOAM) 的新型自适应调制方案，专门用于里德堡原子（RA）接收机。针对RA接收机仅检测信号幅度而丢失相位信息的固有问题，LOAM通过动态调整星座点以最大化最小幅度差，并根据参考信号强度采用对称或非对称星座分布。仿真结果表明，LOAM在性能上比传统调制方案有显著提升，增益超过45 dB。

> **摘要翻译:** 里德堡原子（RA）接收机代表了一种革命性的无线通信量子技术，提供了超越传统射频（RF）天线的空前灵敏度。然而，这些接收机仅检测信号幅度，丢失了关键的相位信息。尽管本地振荡器（LO）生成的参考信号可以辅助相位恢复，但现有为传统系统设计的调制方案在这种量子检测机制下表现不佳。本文引入了一种突破性的LO感知自适应调制（LOAM）方案，专门为RA接收机开发，能够动态适应复杂的衰落信道系数。LOAM通过最大化星座点之间的最小幅度差，确保最佳检测性能。该创新采用了与参考信号和信道系数组合相位对齐的自适应共线星座结构。对于强参考信号，LOAM生成以原点为中心的对称星座点；对于弱信号，它采用非对称分布。论文数学推导了控制这些操作区域的阈值。仿真结果揭示了LOAM的变革性影响，证明其相较于包括正交幅度调制（QAM）、相移键控（PSK）和脉冲幅度调制（PAM）在内的传统调制方案，性能增益超过45 dB。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [104] [Appendices for "Closed-Form BER Analysis for Uplink NOMA with Dynamic SIC Decoding"](https://arxiv.org/abs/2508.00540)
> *“上行NOMA动态SIC解码闭式BER分析”的附录*

*Hequn Zhang, Qu Luo, Pei Xiao, Yue Zhang, Huiyu Zhou* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** NOMA, SIC解码, BER分析, 信道增益, 概率密度函数

**Comment:** 

> **TL;DR:** 本文档为一篇关于上行NOMA动态SIC解码的闭式BER分析论文提供了补充数学推导。

**AI_Comments:** 本文档是主论文的补充材料，提供了详细的数学基础。其价值在于为主论文的分析结果提供了严格的证明和推导，这对于理解和验证原始研究至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 为“上行NOMA动态SIC解码的闭式BER分析”论文提供补充材料。

**Method:** 本文档提供了详细的数学推导和证明，包括：有序信道增益的累积分布函数、NOMA动态SIC解码中归一化信号加干扰方差的概率密度函数、双用户成对错误概率（PEP）的闭式表达式、双用户情况下信道增益排序的概率推导、M-QAM调制方案的BER分析、各种排序条件下信道增益的PDF推导，以及各种排序条件下信道增益实部PDF推导的挑战。

**Result:** 这些数学基础支持了瑞利衰落信道下具有动态SIC解码的上行NOMA系统的闭式BER分析，并支持各种调制方案和系统配置的分析表达式。

**Conclusion:** 本附录提供的数学基础能够支持瑞利衰落信道下上行NOMA系统动态SIC解码的闭式BER分析，并为各种调制方案和系统配置提供了分析表达式。

> **ai_Abstract:** 本文档是“上行NOMA动态SIC解码闭式BER分析”论文的附录。它提供了详细的数学推导和证明，包括有序信道增益的累积分布函数、信号加干扰方差的概率密度函数、双用户成对错误概率的闭式表达式、信道增益排序概率以及各种M-QAM方案的BER分析。这些数学基础支持了瑞利衰落信道下具有动态SIC解码的上行NOMA系统的闭式BER分析，并适用于各种调制方案和系统配置。

> **摘要翻译:** 本文档为“上行NOMA动态SIC解码的闭式BER分析”论文提供了补充材料。本附录提供了详细的数学推导和证明，以支持主论文的分析框架。具体而言，我们包括：(i) 有序信道增益的累积分布函数；(ii) NOMA动态SIC解码中归一化信号加干扰方差的概率密度函数；(iii) 双用户成对错误概率（PEP）的闭式表达式；(iv) 双用户情况下信道增益排序的概率推导，特别是当UE 1和UE 2具有最强或第二强信道增益时；(v) 包括BPSK、4QAM、16QAM和64QAM在内的M-QAM调制方案的BER分析；(vi) 各种排序条件下信道增益的PDF推导；以及 (vii) 各种排序条件下信道增益实部PDF推导的挑战。这些数学基础支持了瑞利衰落信道下具有动态SIC解码的上行NOMA系统的闭式BER分析，并支持各种调制方案和系统配置的分析表达式。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [146] [Deep Learning-Based Rate-Adaptive CSI Feedback for Wideband XL-MIMO Systems in the Near-Field Domain](https://arxiv.org/abs/2508.00626)
> *宽带近场XL-MIMO系统中基于深度学习的速率自适应CSI反馈*

*Zhenyu Liu, Yi Ma, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-08-01**

**Keywords:** CSI反馈, XL-MIMO, 深度学习, 速率自适应, 近场通信

**Comment:** 

> **TL;DR:** 针对宽带近场XL-MIMO系统中的CSI反馈挑战，本文提出了WideNLNet-CA，一个基于深度学习的速率自适应框架，它在各种压缩比和带宽下均优于现有方法。

**AI_Comments:** 该论文创新性地将深度学习应用于宽带近场XL-MIMO系统的CSI反馈，特别引入了速率自适应模块，使得单一模型能适应多种压缩比，这对于实际部署具有重要意义。其轻量级架构也解决了模型复杂度和推理速度的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 准确高效的信道状态信息（CSI）反馈对于在未来6G网络中释放超大规模MIMO（XL-MIMO）系统的巨大频谱效率增益至关重要。然而，宽带场景中近场球面波传播和频率相关波束分裂效应的结合对CSI表示和压缩提出了重大挑战。

**Method:** 论文提出了WideNLNet-CA，一个速率自适应的深度学习框架，用于宽带近场XL-MIMO系统中的高效CSI反馈。该框架引入了轻量级编码器-解码器架构，具有多级下采样和上采样，并结合了计算效率高的残差块以捕获复杂的多尺度信道特征。它还引入了一个带有特征重要性估计的新型压缩比自适应模块，以基于目标压缩比动态调制特征选择，从而使用单一模型实现大范围反馈速率的灵活适应。

**Result:** 评估结果表明，WideNLNet-CA在各种压缩比和带宽下始终优于现有的压缩感知和基于深度学习的方法，同时保持快速推理和低模型存储要求。

**Conclusion:** WideNLNet-CA能够有效解决宽带近场XL-MIMO系统中的CSI反馈挑战，通过其速率自适应和高性能设计，显著提升了CSI反馈的效率和准确性。

> **ai_Abstract:** 本文提出了WideNLNet-CA，一个针对宽带近场XL-MIMO系统设计的速率自适应深度学习框架，旨在解决CSI反馈中的挑战。该框架采用轻量级编码器-解码器架构和新型压缩比自适应模块，能够高效捕获多尺度信道特征，并灵活适应不同反馈速率。实验结果表明，WideNLNet-CA在性能、推理速度和存储效率方面均优于现有方法。

> **摘要翻译:** 准确高效的信道状态信息（CSI）反馈对于在未来6G网络中释放超大规模MIMO（XL-MIMO）系统的巨大频谱效率增益至关重要。然而，宽带场景中近场球面波传播和频率相关波束分裂效应的结合对CSI表示和压缩提出了重大挑战。本文提出了WideNLNet-CA，一个速率自适应的深度学习框架，旨在实现宽带近场XL-MIMO系统中的高效CSI反馈。WideNLNet-CA引入了一个轻量级的编码器-解码器架构，具有多级下采样和上采样，并结合了计算效率高的残差块，以更低的开销捕获复杂的多尺度信道特征。引入了一个带有特征重要性估计的新型压缩比自适应模块，以基于目标压缩比动态调制特征选择，从而使用单一模型实现大范围反馈速率的灵活适应。评估结果表明，WideNLNet-CA在各种压缩比和带宽下始终优于现有的压缩感知和基于深度学习的方法，同时保持快速推理和低模型存储要求。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [367] [A New Upper Bound for Distributed Hypothesis Testing Using the Auxiliary Receiver Approach](https://arxiv.org/abs/2409.14148)
> *使用辅助接收器方法对分布式假设检验的新上界*

*Zhenduo Wen, Amin Gohari* | **Category: cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 分布式假设检验, 上界, 辅助接收器, 加减技术, 信息论

**Comment:** 

> **TL;DR:** 本文利用辅助接收器方法的加减技术，为分布式假设检验问题建立了一个新的上界，该上界假设更少，至少与现有界限一样紧密，并在某些高斯设置下表现更优。

**AI_Comments:** 该论文的创新之处在于引入了辅助接收器方法并采用了独特的加减技术，解决了现有分布式假设检验上界假设过多或性能不足的问题。通过减少假设并提升性能，该研究对分布式假设检验领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进分布式假设检验问题的上界，减少现有方法的假设，并提高其性能。

**Method:** 采用辅助接收器方法的加减技术（add-and-subtract technique），并对单字母化采用不同于Rahman和Wagner的操纵方式，将附加接收器视为辅助接收器。

**Result:** 建立了分布式假设检验问题的新上界。该新上界与Rahman和Wagner提出的上界相比，假设更少，至少一样紧密，并且在某些高斯设置下表现更优。

**Conclusion:** 通过辅助接收器方法的加减技术，可以为分布式假设检验问题建立一个更优越、更具普适性的上界。

> **ai_Abstract:** 本文利用辅助接收器方法的加减技术，为分布式假设检验问题提出了一个新的上界。该上界与现有方法相比，具有更少的假设，至少同等紧密，并在特定高斯场景下表现更佳。研究者将辅助接收器视为一个独立的实体，并采用了不同于传统方法的单字母化处理。

> **摘要翻译:** 本文采用辅助接收器方法的加减技术，为分布式假设检验问题建立了一个新的上界。这个新界限比Rahman和Wagner提出的上界假设更少，至少与Rahman和Wagner的界限一样紧密，并且在某些高斯设置下可以超越它。从概念上讲，与将额外接收器视为旁信息的Rahman和Wagner不同，我们将它视为辅助接收器，并使用不同的单字母化操作。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [402] [Harnessing Rydberg Atomic Receivers: From Quantum Physics to Wireless Communications](https://arxiv.org/abs/2501.11842)
> *利用里德堡原子接收器：从量子物理到无线通信*

*Yuanbin Chen, Xufeng Guo, Chau Yuen, Yufei Zhao, Yong Liang Guan, Chong Meng Samson See, Merouane Débbah, Lajos Hanzo* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** 里德堡原子接收器, 无线通信, 量子物理, 信噪比增益, 高阶调制

**Comment:** This revised manuscript has been submitted to IEEE journal, 16 pages,
  10 figures

> **TL;DR:** 该研究提出将里德堡原子接收器集成到无线通信系统中，设计了两种接收器（LO-dressed和LO-free），并开发了相应的无线模型。结果显示，LO-dressed系统比传统射频接收器实现了显著的信噪比增益（40-50 dB），从而降低了误码率并支持高阶调制。

**AI_Comments:** 该论文创新性地将量子物理中的里德堡原子概念引入无线通信接收器设计，为突破传统射频接收器的性能限制提供了新途径。LO-dressed接收器在信噪比方面展现出的巨大优势（40-50 dB）是其核心亮点，预示着未来无线通信在灵敏度和效率上可能实现的飞跃。该研究通过详细建模和仿真，不仅验证了其理论可行性，也为实际应用中的失真控制提供了指导。其重要性在于为6G及未来通信技术提供了潜在的量子增强解决方案，尽管实际部署可能面临工程复杂性挑战。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过利用量子物理原理，将里德堡原子接收器集成到无线通信系统中，以提升无线通信的性能和效率。

**Method:** 研究提出了两种里德堡原子接收器：一种包含本地振荡器（LO-dressed），另一种不含本地振荡器（LO-free）。为每种配置开发了相应的无线模型，详细阐述了接收器对射频信号的响应、潜在噪声源以及信噪比性能。该模型符合经典射频框架。此外，还研究了可能发生的失真效应，确定了失真产生的条件并展示了线性动态范围的边界。最后，通过广泛的仿真结果表征了系统的性能。

**Result:** 仿真结果表明，在标准量子极限状态下，LO-dressed系统比传统射频接收器实现了约40-50 dB的显著信噪比增益。这种信噪比余量转化为更低的符号错误率，从而能够实现高效、可靠的更高阶星座传输。

**Conclusion:** 里德堡原子接收器，特别是带有本地振荡器的LO-dressed系统，在无线通信中表现出巨大的潜力，能够显著提高信噪比，降低误码率，并支持更高效的传输。

> **ai_Abstract:** 本论文提出了一种将里德堡原子接收器集成到无线通信系统中的方法，利用量子物理原理。研究设计了两种类型的里德堡原子接收器：LO-dressed和LO-free，并为它们构建了详细的无线模型，分析了信号响应、噪声和信噪比。模型与经典射频框架兼容，并探讨了失真效应及线性动态范围。仿真结果显示，LO-dressed系统相比传统射频接收器在信噪比上实现了40-50 dB的显著增益，从而有效降低了符号错误率，支持高阶调制，提升了无线传输的效率和可靠性。

> **摘要翻译:** 里德堡原子接收器与无线通信系统的内在集成被提出，通过在无线通信中利用量子物理原理。更具体地说，我们构想了一对里德堡原子接收器，其中一个包含本地振荡器（LO），被称为LO-dressed接收器，而另一个在没有LO的情况下运行，被称为LO-free接收器。为每种配置开发了适当的无线模型，详细阐述了接收器对射频（RF）信号的响应、潜在噪声源以及信噪比（SNR）性能。所开发的无线模型符合经典射频框架，便于与已建立的信号处理方法兼容。接下来，我们研究了可能发生的相关的失真效应，特别是识别了失真发生的条件，并展示了线性动态范围的边界。这为其在无线系统中的实际实现提供了关键见解。最后，提供了广泛的仿真结果，用于表征利用这对里德堡原子接收器的无线系统的性能。我们的结果表明，在标准量子极限状态下，LO-dressed系统比传统射频接收器实现了约40~50 dB的显著信噪比增益。这种信噪比余量转化为降低的符号错误率，从而能够实现高效、可靠的更高阶星座传输。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [432] [Totally Disjoint 3-Digit Decimal Check Digit Codes](https://arxiv.org/abs/2504.05326)
> *全不相交的三位十进制校验码*

*Larry A. Dunning* | **Category: cs.IT, math.CO, math.IT, 68P30, 94B25, 05B15, 05B40, 20N15, H.1.1; G.2.1; F.2.1** | **Updated: 2025-07-31**

**Keywords:** 校验码, 错误检测, 不相交代码, Verhoeff码, 无排列代码

**Comment:** 

> **TL;DR:** 本文介绍了三组新的、两两不相交的三位十进制校验码，它们仅通过数字的多重集合即可确定整个码字，从而消除了循环错误和语音错误，是对Verhoeff在1969年提出的错误检测码的改进。

**AI_Comments:** 这篇论文通过引入“无排列”的校验码概念，巧妙地解决了传统校验码中“循环错误”和“语音错误”的问题，是对Verhoeff早期工作的显著改进。其创新点在于利用数字多重集合来确定码字，这为设计更鲁棒的错误检测码提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 1969年J. Verhoeff提出了首个使用单个校验位来检测所有单一错误、转置错误和相邻双胞胎错误的十进制错误检测码。他提出的三种代码是长度为三位、带有两位信息数字的代码。存在一个四位代码将意味着存在10个这样的不相交三位代码。本文的动机是提出改进的、两两不相交的三位代码，并实现Verhoeff消除“循环错误”的愿望，同时消除语音错误。

**Method:** 本文提出了三组两两不相交的三位代码。这些代码的特性是，即使数字的位置未知，仅凭一个词中包含的数字的多重集合就能确定整个码字。这使得代码是无排列的，并满足了Verhoeff消除“循环错误”的愿望。同时，也消除了X0和1X形式的两位数字对互换的语音错误。

**Result:** 论文成功提出了三组两两不相交的三位代码。这些代码具有仅通过数字多重集合即可确定整个码字的特性，从而消除了循环错误和语音错误。

**Conclusion:** 本文成功构建了满足特定误差检测要求（包括消除循环错误和语音错误）的三位十进制校验码，证明了在特定条件下，仅通过数字内容即可恢复完整码字的可能性，是对Verhoeff早期工作的有效扩展和改进。

> **ai_Abstract:** 本文介绍了三组新的、两两不相交的三位十进制校验码，扩展了J. Verhoeff在1969年提出的错误检测码。这些新代码的关键特性在于，仅凭码字中数字的多重集合（无论其位置如何）即可完全确定整个码字。这一特性使得代码“无排列”，成功消除了Verhoeff所期望的“循环错误”以及特定的“语音错误”，显著提升了错误检测的鲁棒性。

> **摘要翻译:** 1969年，J. Verhoeff首次提供了使用单个校验位来提供对所有单一错误、转置错误和相邻双胞胎错误的保护的十进制错误检测码示例。他提出的此类代码的三个版本是带有两个信息数字的三位长度代码。四位代码的存在将意味着存在10个这样的不相交三位代码。本文提出了三组两两不相交的三位代码。本文开发的代码具有这样的特性：即使数字的位置未知，仅凭一个词中包含的数字的多重集合就足以确定整个码字。因此，这些代码是无排列的，这满足了Verhoeff消除“循环错误”的愿望。两位数字对X0和1X形式互换的语音错误也被消除了。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [671] [A CPFSK Transceiver with Hybrid CSS-DSSS Spreading for LPWAN PHY Communication](https://arxiv.org/abs/2507.23029)
> *一种用于LPWAN PHY通信的混合CSS-DSSS扩频CPFSK收发器*

*Wenkun Wen, Ruiqi Zhang, Peiran Wu, Tierui Min, Minghua Xia* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-30**

**Keywords:** CPFSK, CSS, DSSS, LPWAN, 收发器, 接收灵敏度

**Comment:** 15 pages, 12 figures, and 4 tables. To appear in IEEE Internet of
  Things Journal

> **TL;DR:** 本文提出了一种新型LPWAN收发器，通过混合CSS-DSSS扩频和优化的接收技术，实现了高接收灵敏度、低复杂度和成本效益。

**AI_Comments:** 本文的创新点在于结合了CSS和DSSS的优点，特别是在前导码和有效载荷中分别利用它们的不同特性来优化同步和扩频增益。双峰检测和非相干联合解扩解调方案的引入，在提升接收灵敏度的同时保持了实现简单性，这对于资源受限的LPWAN设备至关重要。该研究通过SDR原型和实际测试验证了其工程实用性，具有较高的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的低功耗广域网（LPWAN）收发器通常以牺牲数据速率为代价来实现深度覆盖，而本文旨在开发一种能同时实现高接收灵敏度和低计算复杂度的收发器。

**Method:** 发射端：用啁啾扩频（CSS）前导码（包含一对共轭的下行和上行啁啾信号）取代传统直接序列扩频（DSSS）前导码，以简化数据包同步。有效载荷结合连续相位频移键控（CPFSK）和DSSS，以保持恒定包络和相位连续性并实现高扩频增益。接收端：开发了双峰检测方法以改善同步，并提出了一种非相干联合解扩和解调方案，以提高接收灵敏度并保持实现简单性。此外，优化了前导码检测阈值和扩频序列，以实现最大的非相干接收器性能。通过GNU Radio和USRP开发了软件定义无线电（SDR）原型。

**Result:** 大量的蒙特卡洛仿真和现场测试表明，该收发器在接收灵敏度方面优于传统收发器，同时具有低复杂度和成本效益，满足LPWAN的要求。

**Conclusion:** 本文提出的新型CPFSK收发器，通过混合CSS-DSSS扩频和优化的接收技术，有效解决了传统LPWAN收发器在覆盖深度和数据速率之间的权衡问题，实现了高接收灵敏度、低复杂度和成本效益。

> **ai_Abstract:** 本文介绍了一种新型LPWAN收发器，旨在解决传统方案在数据速率和覆盖范围上的权衡。该收发器在发射端采用混合CSS-DSSS扩频，将CSS前导码与CPFSK-DSSS有效载荷结合，以简化同步和提高扩频增益。接收端则通过双峰检测和非相干联合解扩解调方案，显著提升了接收灵敏度并保持了低复杂度。通过SDR原型验证和广泛的仿真与现场测试，证明了其在灵敏度、复杂度和成本效益方面优于现有LPWAN方案。

> **摘要翻译:** 传统的低功耗广域网（LPWAN）收发器通常以牺牲数据速率为代价来实现深度覆盖。本文提出了一种新型收发器，可实现高接收灵敏度和低计算复杂度。在发射端，我们用啁啾扩频（CSS）前导码取代了传统的直接序列扩频（DSSS）前导码，该前导码由一对相互共轭的下行和上行啁啾信号组成，简化了数据包同步。为了增强覆盖范围，有效载荷结合了连续相位频移键控（CPFSK）以保持恒定包络和相位连续性，并结合DSSS以实现高扩频增益。在接收端，我们开发了一种双峰检测方法来改善同步，以及一种非相干联合解扩和解调方案，该方案在保持实现简单性的同时提高了接收灵敏度。此外，我们优化了前导码检测阈值和扩频序列，以实现最大的非相干接收器性能。使用GNU Radio和USRP开发的软件定义无线电（SDR）原型以及操作快照展示了其实际工程应用。大量的蒙特卡洛仿真和现场测试表明，我们的收发器在接收灵敏度方面优于传统收发器，同时具有低复杂度和成本效益，满足LPWAN的要求。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [713] [Optimal compressed sensing for mixing stochastic processes](https://arxiv.org/abs/2507.23175)
> *混合随机过程的最优压缩感知*

*Yonatan Gutman, Adam Śpiewak* | **Category: cs.IT, math.DS, math.IT, math.PR, 68P30, 94A29, 31E05, 37A35, 60G10** | **Updated: 2025-07-31**

**Keywords:** 压缩感知, 随机过程, 均值信息维度, 相关维度率, 无损恢复

**Comment:** 

> **TL;DR:** 本文证明了对于$\\psi^*$-混合过程，均值信息维度是压缩感知中几乎无损恢复的根本限制和精确阈值，并引入了新的相关维度率作为任意平稳随机过程的下限。

**AI_Comments:** 本文的创新之处在于精确地确定了$\\psi^*$-混合过程压缩感知的根本限制和精确阈值，填补了先前工作只给出上限的空白。引入的相关维度率是一个重要的新概念，为更广泛的平稳随机过程的压缩感知提供了理论基础，具有重要的理论意义。

<details>
  <summary>Details</summary>

**Motivation:** Jalali和Poor的工作表明，任何严格大于均值信息维度的速率都可以作为$\\psi^*$-混合过程几乎无损恢复所需随机线性测量数量的上限。本文的动机是确定压缩感知中恢复的下限，从而建立该设置的根本限制和精确阈值。

**Method:** 本文引入了一个新的量：相关维度率，它与几何测度理论的技术相关，并将其证明为任意平稳随机过程压缩感知的下限。通过证明当标准化随机线性测量数量严格小于均值信息维度时，几乎无损恢复是不可能的，从而确立了均值信息维度为根本限制。

**Result:** 研究结果表明，如果标准化随机线性测量的数量严格小于均值信息维度，那么任何解压器序列都无法实现$\\psi^*$-混合过程的几乎无损恢复。这确立了均值信息维度是该设置中压缩感知的根本限制和精确阈值。此外，引入的相关维度率被证明是任意平稳随机过程压缩感知的下限。

**Conclusion:** 均值信息维度被确立为在特定设置下对$\\psi^*$-混合过程进行压缩感知时实现几乎无损恢复的根本限制和精确阈值。

> **ai_Abstract:** 本文研究了$\\psi^*$-混合随机过程的压缩感知问题，在Jalali和Poor先前工作的基础上，证明了均值信息维度是实现几乎无损恢复的精确阈值和根本限制。研究表明，当随机线性测量数量低于该维度时，几乎无损恢复是不可能的。此外，论文还引入了新的概念——相关维度率，并证明其为任意平稳随机过程压缩感知的下限。

> **摘要翻译:** Jalali和Poor引入了一个随机过程压缩感知的渐近框架，证明了任何严格大于均值信息维度的速率都可以作为衡量$\\psi^*$-混合过程（在归一化$L^2$范数下）几乎无损恢复所需随机线性测量数量的上限。在这项工作中，我们证明，如果随机线性测量的归一化数量严格小于均值信息维度，那么任何解压器序列都无法实现$\\psi^*$-混合过程的几乎无损恢复。这确立了均值信息维度是该设置中压缩感知的根本限制（事实上，是该问题的精确阈值）。为此，我们引入了一个新的量，与几何测度理论中的技术相关：相关维度率，它被证明是任意平稳随机过程压缩感知的下限。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [755] [The Construction of Near-optimal Universal Coding of Integers](https://arxiv.org/abs/2507.23180)
> *整数准最优通用编码的构建*

*Wei Yan, Yunghsiang S. Han* | **Category: cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 通用整数编码, 准最优编码, 扩展因子, $\nu$码, $\Delta\delta$码

**Comment:** 

> **TL;DR:** 本文构建了名为$\nu$码的准最优整数通用编码，其扩展因子为2.0386，将最优UCI的扩展因子范围缩小至$2\leq C_{\mathcal{C}}^{*}\leq 2.0386$，并提出了新的$\Delta\delta$码，证明这两种码在最小扩展因子方面是当前最优的，同时给出了最优UCI最小扩展因子下限为2的新证明。

**AI_Comments:** 本文在通用整数编码领域取得了重要进展，通过提出两种新的编码方案（$\nu$码和$\Delta\delta$码），显著提升了编码的压缩性能，特别是将最优UCI的最小扩展因子范围进一步收窄。其创新点在于构造出性能接近理论极限的编码方法，并提供了新的理论下限证明，对于数据压缩和信息论研究具有实际和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 通用整数编码（UCI）适用于未知概率分布和无限可数字母表的离散无记忆信源。现有最优UCI的最小扩展因子范围为$2\leq C_{\mathcal{C}}^{*}\leq 2.5$，研究的动机是为了找到性能更好的UCI，即具有更小最小扩展因子的编码方法，以提高压缩性能。

**Method:** 本文通过构建两种新的UCI类别：$\nu$码和$\Delta\delta$码。对于$\nu$码，证明其能达到2.0386的扩展因子。对于$\Delta\delta$码，专门进行了构造。此外，还提出了一种新的证明方法来证明最优UCI的最小扩展因子下限为2。

**Result:** 提出了名为$\nu$码的准最优UCI，其扩展因子$K_\nu=2.0386$，将最优UCI的最小扩展因子范围缩小到$2\leq C_{\mathcal{C}}^{*}\leq 2.0386$。构建了新的$\Delta\delta$码。证明$\Delta\delta$码和$\nu$码在最小扩展因子方面是目前最优的。提供了最优UCI最小扩展因子下限为2的新证明。

**Conclusion:** 本文成功构建了具有更小扩展因子的准最优通用整数编码，显著提升了通用整数编码的压缩性能，并将最优UCI的最小扩展因子范围进一步收窄，为该领域的进一步研究奠定了基础。

> **ai_Abstract:** 本文研究了整数通用编码（UCI）的性能优化，UCI是一种适用于未知概率分布离散信源的前缀码。通过引入“最小扩展因子”$K_{\mathcal{C}}^{*}$作为衡量压缩性能的指标，文章旨在构建具有更小$K_{\mathcal{C}}^{*}$的准最优UCI。研究提出了一种名为$\nu$码的新型UCI，实现了2.0386的扩展因子，从而将最优UCI的最小扩展因子范围从$2\leq C_{\mathcal{C}}^{*}\leq 2.5$缩小到$2\leq C_{\mathcal{C}}^{*}\leq 2.0386$。同时，还构建了另一种新的$\Delta\delta$码，并证明$\nu$码和$\Delta\delta$码在最小扩展因子方面是目前最优的。此外，文章还提供了最优UCI最小扩展因子下限为2的新证明。

> **摘要翻译:** 整数通用编码（UCI）适用于具有未知概率分布和无限可数字母表的离散无记忆信源。UCI是一类前缀码，使得平均码字长度与$\max\{1, H(P)\}$之比在任何递减概率分布$P$下都处于一个常数扩展因子$K_{\mathcal{C}}$内，其中$H(P)$是$P$的熵。对于任何UCI码$\mathcal{C}$，定义“最小扩展因子”$K_{\mathcal{C}}^{*}$表示$\mathcal{C}$的扩展因子集合的下确界。每个$\mathcal{C}$都有一个唯一对应的$K_{\mathcal{C}}^{*}$，并且$K_{\mathcal{C}}^{*}$越小，$\mathcal{C}$的压缩性能越好。一类实现最小$K_{\mathcal{C}}^{*}$的UCI $\mathcal{C}$（或族$\{\mathcal{C}_i\}_{i=1}^{\infty}$）被定义为“最优UCI”。目前最好的结果是最优UCI的$C_{\mathcal{C}}^{*}$范围是$2\leq C_{\mathcal{C}}^{*}\leq 2.5$。在本文中，我们证明存在一类准最优UCI，称为$\nu$码，实现了$K_\nu=2.0386$。这使得最优UCI的最小扩展因子范围缩小到$2\leq C_{\mathcal{C}}^{*}\leq 2.0386$。另一类新的UCI，称为$\Delta\delta$码，被专门构建。我们表明$\Delta\delta$码和$\nu$码在最小扩展因子方面目前是最优的。此外，我们提出了一种新的证明，表明最优UCI的最小扩展因子下限为2。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [797] [Efficient DFT of Zadoff-Chu Sequences using lmFH Pattern](https://arxiv.org/abs/2507.23200)
> *Zadoff-Chu序列使用lmFH模式的高效DFT*

*Fanping Du* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** Zadoff-Chu序列, 离散傅里叶变换, 线性微跳频, 广义二次高斯和, 累积频率点

**Comment:** 8 pages, 7 figures

> **TL;DR:** 本文展示了使用lmFH模式高效计算Zadoff-Chu序列的DFT和IDFT的方法，并引入了一种新的累积和计算形式，证明ZC序列的DFT可转换为带频移和相偏的lmFH符号。

**AI_Comments:** 本文利用Zadoff-Chu序列与线性微跳频符号的内在联系，为ZC序列的DFT计算提供了一种新颖且可能更高效的视角。其创新点在于将复杂的DFT计算转换为更直观的lmFH符号处理，并提出了新的累积和计算方法。

<details>
  <summary>Details</summary>

**Motivation:** 提高Zadoff-Chu序列DFT计算的效率和理解。

**Method:** 本文首先利用lmFH模式直观展示ZC序列DFT和IDFT的计算；随后引入了使用广义二次高斯和计算ZC序列累积和的替代形式；最后，基于mFH概念，将ZC序列的DFT转换为带有频移和相偏的lmFH符号，并通过累积频率点进行计算。

**Result:** 使用lmFH模式计算DFT和IDFT产生了有趣的结果。ZC序列的DFT可以转换为带有频移和相偏的lmFH符号。

**Conclusion:** Zadoff-Chu序列的DFT可以通过累积频率点计算，类似于普通微跳频符号的计算，从而实现高效计算。

> **ai_Abstract:** 本文提出了一种使用线性微跳频（lmFH）模式高效计算Zadoff-Chu（ZC）序列DFT和IDFT的方法。研究表明，ZC序列的DFT可以被转换为带有频移和相偏的lmFH符号，从而可以通过累积频率点进行计算，类似于常规mFH符号。文章还介绍了一种利用广义二次高斯和计算ZC序列累积和的替代形式。

> **摘要翻译:** 鉴于Zadoff-Chu (ZC)序列本质上是线性微跳频 (lmFH) 符号，本文首先利用lmFH模式直观且形象地阐述了ZC序列离散傅里叶变换 (DFT) 和逆离散傅里叶变换 (IDFT) 的计算。这产生了有趣的结果。随后，本文介绍了使用广义二次高斯和计算ZC序列累积和的另一种形式。此外，基于微跳频 (mFH) 概念，本文表明ZC序列的DFT可以转换为带有频移和相偏的lmFH符号。因此，ZC序列的DFT可以通过累积频率点计算，类似于普通mFH符号的计算。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [817] [Graph Reconstruction from Noisy Random Subgraphs](https://arxiv.org/abs/2405.04261)
> *从噪声随机子图重建图*

*Andrew McGregor, Rik Sengupta* | **Category: cs.IT, cs.DS, math.IT** | **Updated: 2025-07-31**

**Keywords:** 图重建, 噪声子图, 随机图, 轨迹, 复杂性

**Comment:** 6 pages, to appear in ISIT 2024

> **TL;DR:** 研究了如何从带有噪声的随机子图（“轨迹”）重建无向图G的问题，并给出了在不同图类型下所需轨迹数量的界限。

**AI_Comments:** 该论文的关键创新在于量化了从噪声子图重建图所需的轨迹数量，并明确区分了随机图和任意图的重建难度。对于随机图，重建效率较高（多项式），而对于任意图，则面临显著的计算挑战（指数级），这对于理解图重建问题的复杂性边界具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决从多个随机噪声子图或“轨迹”重建无向图的问题。

**Method:** 通过采样每个顶点并获取诱导子图，然后添加噪声（删除边或删除/转换非边）来生成轨迹。分析在特定概率参数下，重建图所需的轨迹数量。

**Result:** 在对$p_v$、$p_e$和$f_e$的温和假设下，如果G是随机均匀选择的，则$O(p_e^{-1} p_v^{-2} 	ext{log} n)$或$O((f_e-1/2)^{-2} p_v^{-2} 	ext{log} n)$个轨迹足以高概率重建G。相反，如果G是任意的，即使在$p_v=1, p_e=1/2$的情况下，也需要$	ext{exp}(\Omega(n))$个轨迹。

**Conclusion:** 在温和条件下，对于随机图，从噪声随机子图重建图所需的轨迹数量是多项式级别的；而对于任意图，则需要指数级别的轨迹数量。

> **ai_Abstract:** 本研究探讨了从带有噪声的随机子图（称为“轨迹”）重建无向图G的问题。轨迹的生成涉及顶点采样、诱导子图形成以及两种类型的边噪声添加。研究发现，在温和的参数假设下，如果目标图G是随机选择的，则仅需要对数级别的轨迹数量即可高概率重建；然而，如果G是任意图，即使在特定理想条件下，也需要指数级别的轨迹数量才能完成重建。

> **摘要翻译:** 我们考虑从多个随机噪声子图或“轨迹”重建一个n个顶点的无向图G的问题。具体来说，轨迹是通过以概率$p_v$采样每个顶点，然后获取采样顶点上的诱导子图，然后以两种形式添加噪声生成的：(a) 以概率$1-p_e$删除子图中的每条边，或者(b) 以概率$f_e$删除每条边，并以概率$f_e$将非边转换为边。我们表明，在对$p_v$、$p_e$和$f_e$的温和假设下，如果G是随机均匀选择的，则$O(p_e^{-1} p_v^{-2} 	ext{log} n)$或$O((f_e-1/2)^{-2} p_v^{-2} 	ext{log} n)$个轨迹足以高概率重建G。相比之下，如果G是任意的，即使在$p_v=1, p_e=1/2$的情况下，也需要$	ext{exp}(\Omega(n))$个轨迹。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [839] [Secure Integrated Sensing and Communication Networks: Stochastic Performance Analysis](https://arxiv.org/abs/2507.23234)
> *安全集成传感与通信网络：随机性能分析*

*Marziyeh Soltani, Mahtab Mirmohseni, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** 集成传感与通信, 安全, 随机性能分析, MIMO, 窃听

**Comment:** 

> **TL;DR:** 本文分析了MIMO集成传感与通信（ISAC）系统在下行链路场景下的随机安全性能，考虑了通信窃听者、传感窃听者和恶意目标，并推导了遍历保密速率（ESR）和克拉美-劳下界（CRB）以评估通信与传感性能之间的权衡。

**AI_Comments:** 本文的创新之处在于其对ISAC系统安全性能的全面分析，特别是在存在多种窃听威胁（包括通信窃听者、传感窃听者以及恶意目标）的复杂场景下。通过结合随机几何和信息论工具，推导了关键性能指标（ESR和CRB），并量化了通信和传感之间的权衡，为未来安全ISAC系统的设计提供了重要的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在分析多输入多输出（MIMO）集成传感与通信（ISAC）系统在下行链路场景中的随机安全性能，特别是当基站同时进行通信、目标定位并对抗窃听威胁时。

**Method:** 本文分析了一个MIMO ISAC系统，其中基站（BS）发送多功能信号。攻击模型包括被动单天线通信窃听者和多天线传感窃听者，以及将目标视为通信窃听者的恶意目标场景。BS-用户和BS-窃听者信道遵循瑞利衰落，目标方位角均匀分布。为评估性能，推导了遍历保密速率（ESR）和用于目标定位的遍历克拉美-劳下界（CRB），计算了信噪比（SNR）和CRB的概率密度函数（PDF），并利用中心极限定理提高了可处理性。

**Result:** 本文推导了基站和传感窃听者处的遍历保密速率（ESR）和目标定位的遍历克拉美-劳下界（CRB）。通过计算信噪比（SNR）和CRB的概率密度函数（PDF），表征了CRB-保密速率区域的边界。

**Conclusion:** 本文解释了在随机ISAC网络中，在保证一定安全和隐私水平的同时，通信和传感性能之间的权衡。

> **ai_Abstract:** 本研究对多输入多输出（MIMO）集成传感与通信（ISAC）系统在下行链路场景中的随机安全性能进行了分析。文章考虑了多类窃听威胁，包括通信窃听、传感窃听以及恶意目标作为通信窃听者的场景。通过推导遍历保密速率（ESR）和目标定位的克拉美-劳下界（CRB），并计算相关概率密度函数，论文揭示了在保证安全隐私的前提下，ISAC网络中通信与传感性能之间的权衡边界。

> **摘要翻译:** 本文分析了下行链路场景下多输入多输出（MIMO）集成传感与通信（ISAC）系统的随机安全性能。基站（BS）发射多功能信号，同时与用户通信、感知目标的角度位置并对抗窃听威胁。攻击模型考虑了截获通信数据的被动单天线通信窃听者，以及试图推断目标位置的多天线传感窃听者。我们还考虑了恶意目标场景，其中目标扮演通信窃听者的角色。基站-用户和基站-窃听者信道遵循瑞利衰利，而目标的方位角均匀分布。为了评估此随机网络中的性能，我们推导了基站和传感窃听者的遍历保密速率（ESR）和目标定位的遍历克拉美-劳下界（CRB）。这涉及利用中心极限定理计算信噪比（SNR）和CRB的概率密度函数（PDF）以提高可处理性。我们表征了CRB-保密速率区域的边界，并解释了在随机ISAC网络中保证一定安全和隐私水平的同时，通信和传感之间的性能权衡。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [850] [Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience](https://arxiv.org/abs/2508.00596)
> *信息论去中心化安全聚合与串谋弹性*

*Xiang Zhang, Zhou Li, Shuangyang Li, Kai Wan, Derrick Wing Kwan Ng, Giuseppe Caire* | **Category: cs.IT, cs.CR, cs.DC, cs.LG, math.IT** | **Updated: 2025-08-01**

**Keywords:** 去中心化安全聚合, 信息论, 联邦学习, 串谋弹性, 性能限制

**Comment:** Submitted to IEEE for potential journal publication

> **TL;DR:** 本文从信息论角度研究了去中心化安全聚合问题，确定了通信和密钥使用的最优速率区域，并建立了其基本性能限制。

**AI_Comments:** 本文的创新之处在于首次从信息论角度全面分析了去中心化安全聚合问题，并给出了通信和密钥使用的最优下界，填补了现有研究在该领域理论基础上的空白。其重要性在于为未来设计具有可证明安全性和通信效率的分布式学习协议提供了基础性的理论指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有安全聚合工作主要关注协议设计和计算保证，对信息论极限的理解有限。此外，在没有中央聚合器的去中心化设置中，通信和密钥使用的最优界限仍然未知。为了填补这些空白，本文进行了研究。

**Method:** 本文从信息论角度研究了去中心化安全聚合（DSA）问题。具体来说，考虑了一个由K个全连接用户组成的网络，每个用户持有一个私有输入，目标是安全地计算所有输入的总和。安全约束要求即使与多达T个其他用户串谋，任何用户都不能学习到超出输入总和的任何信息。本文刻画了最优速率区域，该区域指定了DSA可实现的最小通信和秘密密钥速率。

**Result:** 研究结果表明，为了安全地计算一个所需输入总和的符号，每个用户必须(i)向其他用户至少传输一个符号，(ii)持有至少一个秘密密钥符号，以及(iii)所有用户必须共同持有不少于K-1个独立的密钥符号。这些结果建立了DSA的基本性能限制。

**Conclusion:** 本文建立了去中心化安全聚合（DSA）的基本性能限制，为分布式学习系统中可证明安全且通信高效协议的设计提供了深刻见解。

> **ai_Abstract:** 本文从信息论角度深入研究了去中心化联邦学习中的安全聚合问题，特别是针对无中心聚合器且存在用户串谋的场景。研究目标是安全计算所有用户私有输入的总和，同时确保信息隐私。通过刻画最优速率区域，论文量化了通信和秘密密钥的最小需求，并建立了去中心化安全聚合的基本性能极限，为设计高效安全的分布式学习协议提供了理论基础。

> **摘要翻译:** 在去中心化联邦学习（FL）中，多个客户端通过中间模型更新的交互式交换，利用其分布在网络中的私有数据集，协同学习共享的机器学习（ML）模型。为了确保数据安全，通常采用密码技术来保护聚合过程中的模型更新。尽管对安全聚合的兴趣日益增长，但现有工作主要集中在协议设计和计算保证上，对这类系统的基本信息论极限的理解有限。此外，在没有中央聚合器的去中心化设置中，通信和密钥使用的最优界限仍然未知。受这些空白的启发，我们从信息论的角度研究了去中心化安全聚合（DSA）问题。具体来说，我们考虑一个由K个全连接用户组成的网络，每个用户持有一个私有输入——本地训练数据的抽象——旨在安全地计算所有输入的总和。安全约束要求即使与多达T个其他用户串谋，任何用户也无法学习到超出输入总和的任何信息。我们刻画了最优速率区域，该区域指定了DSA可实现的最小通信和秘密密钥速率。特别是，我们表明，为了安全地计算一个所需输入总和的符号，每个用户必须(i)向其他用户至少传输一个符号，(ii)持有至少一个秘密密钥符号，并且(iii)所有用户必须共同持有不少于K-1个独立的密钥符号。我们的结果建立了DSA的基本性能限制，为分布式学习系统中可证明安全且通信高效的协议设计提供了见解。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [881] [Exploiting Movable Elements of Intelligent Reflecting Surface for Enhancement of Integrated Sensing and Communication](https://arxiv.org/abs/2507.23296)
> *利用智能反射面可移动单元增强集成传感与通信性能*

*Xingyu Peng, Qin Tao, Yong Liang Guan, Xiaoming Chen* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** 智能反射面, 集成传感与通信, 可移动单元, 波束赋形, 优化

**Comment:** 16 pages, 13 figures

> **TL;DR:** 本文提出利用智能反射面（IRS）的可移动单元来提升集成传感与通信（ISAC）系统的整体性能，通过对单用户和多用户场景的优化设计，仿真结果表明移动IRS单元能显著提高通信速率、传感精度并拓宽ISAC覆盖范围。

**AI_Comments:** 本文的创新点在于提出了利用智能反射面（IRS）的可移动单元来提升集成传感与通信（ISAC）系统性能的新思路，并针对单用户和多用户场景进行了详细的优化设计。这种动态调整IRS单元位置的方法为未来ISAC系统的设计提供了新的维度，具有重要的研究价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升集成传感与通信（ISAC）系统的整体性能，本文提出利用智能反射面（IRS）的可移动单元。

**Method:** 首先，在单用户场景下，通过性能分析揭示了可移动单元的功能，并设计了联合波束赋形和单元位置优化方案。接着，将该方案扩展到多用户场景，并根据推导出的性能表达式提出了单元位置优化方案。

**Result:** 仿真结果证实，IRS单元的移动可以提高通信速率和传感精度，尤其能拓宽ISAC的覆盖范围。

**Conclusion:** IRS单元的移动能够有效提升集成传感与通信（ISAC）系统的通信速率、传感精度，并扩大其覆盖范围。

> **ai_Abstract:** 本文提出通过利用智能反射面（IRS）的可移动单元来提升集成传感与通信（ISAC）系统的性能。研究首先在单用户场景下分析了可移动单元的作用，并设计了联合波束赋形和单元位置优化方案，随后将其推广至多用户场景并提出了相应的单元位置优化方案。仿真结果验证了IRS单元的移动能够有效提高通信速率和传感精度，并显著扩大ISAC的覆盖范围。

> **摘要翻译:** 在本文中，我们提出利用智能反射面（IRS）的可移动单元来增强集成传感与通信（ISAC）系统的整体性能。首先，针对单用户场景，我们通过性能分析揭示了可移动单元的功能，然后设计了联合波束赋形和单元位置优化方案。接着，我们将其扩展到一般多用户场景，并根据推导出的性能表达式也提出了一种单元位置优化方案。最后，仿真结果证实了IRS单元的移动可以提高通信速率和传感精度，尤其能拓宽ISAC的覆盖范围。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [926] [Hybrid Generative Semantic and Bit Communications in Satellite Networks: Trade-offs in Latency, Generation Quality, and Computation](https://arxiv.org/abs/2507.23528)
> *卫星网络中混合生成语义与比特通信：延迟、生成质量与计算的权衡*

*Chong Huang, Gaojie Chen, Jing Zhu, Qu Luo, Pei Xiao, Wei Huang, Rahim Tafazolli* | **Category: cs.IT, eess.SP, math.IT** | **Updated: 2025-07-31**

**Keywords:** 卫星通信, 语义通信, 深度强化学习, 资源分配, 效率指标

**Comment:** 6 pages, accepted for pulication in IEEE Globecom 2025

> **TL;DR:** 本文提出了一种多层混合比特与生成语义通信框架，以解决卫星通信中链路预算有限和语义通信计算资源消耗大的问题，并通过引入语义通信效率指标（SEM）和深度强化学习算法GRPO来优化资源分配，模拟结果验证了其灵活性和有效性。

**AI_Comments:** 该论文创新性地将比特通信与生成语义通信结合，并针对卫星网络的特点提出了多层混合框架，这在当前语义通信研究中具有重要意义。引入的SEM指标为评估语义通信效率提供了新的视角，而DRL的应用则增强了系统的自适应优化能力。该研究对未来卫星通信发展具有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 卫星通信中链路预算有限以及语义通信引入的计算资源消耗增加是当前研究面临的挑战。

**Method:** 本文提出了一种多层混合比特与生成语义通信框架，可以适应动态卫星通信网络。引入了一种新的语义通信效率指标（SEM）来评估延迟、计算消耗和语义重建质量之间的权衡。利用深度强化学习（DRL）算法组相对策略优化（GRPO）来优化所提网络中的资源分配。

**Result:** 仿真结果表明了所提出的传输框架的灵活性和所提出的指标SEM的有效性，并阐明了各种语义通信指标之间的关系。

**Conclusion:** 所提出的混合比特与生成语义通信框架及其优化方法能够有效解决卫星通信中的资源限制问题，并在延迟、计算消耗和语义重建质量之间取得平衡，展示了其在未来无线网络中的潜力。

> **ai_Abstract:** 本文提出了一种针对卫星网络的混合比特与生成语义通信框架，旨在解决有限链路预算和语义通信高计算消耗的挑战。为平衡效率与性能，引入了语义通信效率指标（SEM）来权衡延迟、计算消耗和语义重建质量。同时，采用深度强化学习算法GRPO优化资源分配。仿真结果验证了该框架的灵活性和SEM的有效性。

> **摘要翻译:** 随着卫星通信在未来无线网络中扮演越来越重要的角色，卫星系统中有限链路预算的问题在当前研究中引起了广泛关注。尽管语义通信作为解决这些限制的一种有前景的解决方案出现，但它带来了无线通信中计算资源消耗增加的挑战。为了解决这些挑战，我们提出了一种多层混合比特和生成语义通信框架，该框架可以适应动态卫星通信网络。此外，为了平衡卫星到地面传输中的语义通信效率和性能，我们引入了一种新颖的语义通信效率指标（SEM），用于评估所提出框架中延迟、计算消耗和语义重建质量之间的权衡。此外，我们利用一种新颖的深度强化学习（DRL）算法组相对策略优化（GRPO）来优化所提出网络中的资源分配。仿真结果证明了我们提出的传输框架的灵活性和所提出的指标SEM的有效性，并阐明了各种语义通信指标之间的关系。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [7] [Safe machine learning model release from Trusted Research Environments: The SACRO-ML package](https://arxiv.org/abs/2212.01233)
> *安全机器学习模型从可信研究环境发布：SACRO-ML软件包*

*Jim Smith, Richard J. Preen, Andrew McCarthy, Maha Albashir, Alba Crespi-Boixader, Shahzad Mumtaz, Christian Cole, James Liley, Jost Migenda, Simon Rogers, Yola Jones* | **Category: cs.LG, cs.CR, cs.IR** | **Updated: 2025-08-01**

**Keywords:** 机器学习安全, 统计性信息披露控制, 隐私保护, 开源工具, 可信研究环境

**Comment:** 

> **TL;DR:** SACRO-ML是一个开源Python工具套件，用于在公开机器学习模型之前，对其进行统计性信息披露控制，以保护机密数据。

**AI_Comments:** 该论文介绍的SACRO-ML提供了一个创新且全面的方法来解决机器学习模型发布中的隐私保护问题。它结合了事前和事后两种统计性信息披露控制策略，对于在可信研究环境中安全共享敏感数据训练的模型具有重要意义。其开源特性也促进了研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型在处理机密数据后需要公开发布，但存在信息泄露的风险，因此需要一个工具来控制这种统计性信息披露。

**Method:** SACRO-ML包含两个主要部分：(i) SafeModel包，通过评估训练方案带来的泄露漏洞，提供事前统计性信息披露控制（ante-hoc SDC）；(ii) Attacks包，通过模拟各种攻击，在训练后严格评估模型的经验性泄露风险，提供事后统计性信息披露控制（post-hoc SDC）。

**Result:** Not mentioned in abstract

**Conclusion:** SACRO-ML提供了一个集成的开源Python工具套件，用于在公开发布基于机密数据训练的机器学习模型之前，对其进行统计性信息披露控制。

> **ai_Abstract:** SACRO-ML是一个开源Python工具套件，用于在发布基于机密数据训练的机器学习模型前进行统计性信息披露控制。它通过结合SafeModel包（评估训练方案的泄露风险提供事前SDC）和Attacks包（通过模拟攻击评估经验性泄露风险提供事后SDC）来实现这一目标，旨在确保模型的安全发布。

> **摘要翻译:** 我们介绍了SACRO-ML，一个集成的开源Python工具套件，旨在促进对在机密数据上训练的机器学习（ML）模型在公开发布前的统计性信息披露控制（SDC）。SACRO-ML结合了：(i) 一个SafeModel包，该包扩展了常用的ML模型，通过评估训练方案带来的泄露漏洞来提供事前SDC；(ii) 一个Attacks包，该包通过在训练后模拟各种攻击，严格评估模型的经验性泄露风险，从而提供事后SDC。SACRO-ML的代码和文档可在https://github.com/AI-SDC/SACRO-ML上以MIT许可证获得。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [11] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
> *可解释模型的基础*

*Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Mateja Jamnik, Giuseppe Marra* | **Category: cs.LG, cs.AI, cs.NE, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 可解释性, 可解释模型, 定义, 设计蓝图, 开源库

**Comment:** 

> **TL;DR:** 本文指出现有可解释性定义不可操作，提出一个通用、简单且可操作的新定义，并基于此提出可解释模型设计蓝图和开源库，旨在为可解释AI研究提供坚实基础。

**AI_Comments:** 本文通过重新定义可解释性，为可解释AI领域奠定了更坚实的基础，解决了现有定义在实践中指导性不足的问题。提出通用蓝图和开源库进一步提升了其实用性和影响力，对未来可解释AI研究具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可解释性定义不可操作，无法指导通用、健全、鲁棒的可解释模型设计，导致当前可解释性研究从根本上来说是基础不稳固的。

**Method:** 本文提出了一个通用、简单且涵盖可解释人工智能社区现有非正式概念的可解释性定义。基于此定义，文章提出了一个设计可解释模型的通用蓝图，并引入了第一个原生支持可解释数据结构和过程的开源库。

**Result:** 本文提出的可解释性定义是可操作的，因为它直接揭示了设计可解释模型所需的基础属性、潜在假设、原则、数据结构和架构特征。

**Conclusion:** 新提出的可解释性定义是可操作的，为可解释模型的设计提供了坚实的基础，并有助于解决当前可解释性研究的根本问题。

> **ai_Abstract:** 本文指出现有可解释性定义缺乏可操作性，导致可解释AI研究面临基础性问题。为解决此，作者提出了一个通用、简单且可操作的新可解释性定义，该定义能揭示可解释模型设计的关键属性和原则。基于此，文章进一步提出了一个通用设计蓝图，并推出了首个支持可解释数据结构和过程的开源库。

> **摘要翻译:** 我们认为，现有可解释性定义不可操作，因为它们未能向用户提供关于通用、健全和鲁棒的可解释模型设计的指导。这使得当前可解释性研究从根本上来说是病态的。为了解决这个问题，我们提出了一个通用、简单且涵盖可解释人工智能社区现有非正式概念的可解释性定义。我们表明，我们的定义是可操作的，因为它直接揭示了设计可解释模型所需的基础属性、潜在假设、原则、数据结构和架构特征。在此基础上，我们提出了一个设计可解释模型的通用蓝图，并引入了第一个原生支持可解释数据结构和过程的开源库。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [14] [Gradient Leakage Defense with Key-Lock Module for Federated Learning](https://arxiv.org/abs/2305.04095)
> *联邦学习中带密钥锁模块的梯度泄漏防御*

*Hanchi Ren, Jingjing Deng, Xianghua Xie* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 梯度泄漏, 隐私保护, 密钥锁模块, 模型防御

**Comment:** The source code can be found at https://github.com/Rand2AI/FedKL

> **TL;DR:** 本文提出了一种基于私有密钥锁模块的联邦学习梯度泄漏防御技术，旨在保护隐私数据不被共享梯度泄露，同时保持模型性能。

**AI_Comments:** 这项研究通过引入“密钥锁模块”为联邦学习中的梯度泄漏防御提供了一个新颖且理论上得到支持的解决方案。其创新点在于将隐私保护能力与模型性能保持相结合，并通过双重保障（数据不可重建和模型性能受损）来强化防御效果，对于提升联邦学习的实用安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）虽然是一种保护隐私的机器学习方法，但最近研究发现共享梯度可能泄露敏感信息，导致隐私泄露问题。

**Method:** 本文对梯度泄漏问题进行了详细分析，并提出了一种新的梯度泄漏防御技术。该技术使用一个私有密钥锁模块来保护任意模型架构，只有经过锁定的梯度才会被传输到参数服务器进行全局模型聚合。密钥锁模块经过设计和训练，以确保在没有其私有信息的情况下，无法从共享梯度重建私有训练数据，并且全局模型的推理性能将显著受损。研究还提供了梯度泄漏原理的理论基础和所提方法有效性的理论证明。

**Result:** 在多个流行基准上对多种模型进行了广泛的实证评估，结果表明所提出的方法在保持模型性能和防御梯度泄漏攻击方面都具有鲁棒性。

**Conclusion:** 本文提出的带密钥锁模块的联邦学习梯度泄漏防御方法能够有效抵御梯度泄漏攻击，同时保持了模型性能。

> **ai_Abstract:** 本文深入探讨了联邦学习中梯度泄漏导致的隐私泄露问题，并提出了一种创新的防御机制。该机制引入了一个私有密钥锁模块，确保只有经过安全处理的梯度被传输，从而有效阻止敏感训练数据从共享梯度中被重建。通过理论分析和广泛的实验验证，该方法被证明在抵御梯度泄漏攻击的同时，能够有效维持模型的性能。

> **摘要翻译:** 联邦学习（FL）是一种广泛采用的隐私保护机器学习方法，其中私有数据保留在本地，从而实现安全计算以及本地客户端和第三方参数服务器之间本地模型梯度的交换。然而，最近的研究发现隐私可能会受到损害，敏感信息可能从共享梯度中恢复。在本研究中，我们对梯度泄漏问题进行了详细分析，并提供了理解该问题的新颖视角。这些理论工作引出了一种新的梯度泄漏防御技术，该技术使用私有密钥锁模块来保护任意模型架构。只有锁定的梯度才会被传输到参数服务器进行全局模型聚合。我们提出的学习方法能够抵抗梯度泄漏攻击，并且密钥锁模块经过设计和训练，以确保在没有密钥锁模块的私有信息的情况下：a) 从共享梯度重建私有训练数据是不可行的；b) 全局模型的推理性能会显著受损。我们讨论了梯度为何会泄漏私有信息的理论基础，并提供了我们方法有效性的理论证明。我们对许多模型在多个流行基准上进行了广泛的实证评估，证明了我们提出的方法在保持模型性能和防御梯度泄漏攻击方面的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [20] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
> *关注权重：微调LLM的无监督监控与控制*

*Ziqian Zhong, Aditi Raghunathan* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-31**

**Keywords:** LLM监控, 权重解释, 后门检测, 模型审计, 无监督学习

**Comment:** 

> **TL;DR:** 新方法通过分析权重而非激活来无监督地监控和控制微调LLM，有效检测后门和“遗忘”信息，并揭示商业模型的微调侧重点。

**AI_Comments:** 该论文提出了一种创新的、基于权重而非激活的LLM可解释性方法，有效解决了现有方法在处理分布外威胁时的局限性。其无监督的特性使其在实际应用中更具普适性。在检测后门和恢复“遗忘”信息方面的卓越表现，以及揭示商业模型微调侧重点的潜力，都显示了该方法的重要性和广阔应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型（LLMs）可解释性方法，尤其是基于激活的方法，通常需要或假设数据分布相似，这在检测和防御像后门这种本质上属于分布外的新型潜在威胁时存在显著局限性。

**Method:** 本文引入了一种新的方法，通过解释权重而非激活来理解、监控和控制微调LLMs，从而避免了对与未知训练数据分布相似的数据的需求。具体来说，该方法证明了微调模型与其基础模型之间权重差异的顶部奇异向量对应于新获得的 KNOWLEDGE。通过监控激活沿这些方向的余弦相似度，可以高精度地检测微调期间引入的显著行为。

**Result:** 对于绕过安全机制的后门模型，该方法能阻止高达100%的攻击，误报率低于1.2%。对于经过“遗忘”训练的模型，该方法能以高达95.42%的准确率检测对被擦除主题的推断，甚至可以引导模型恢复“遗忘”的信息。除了监控，该方法还显示了部署前模型审计的潜力：通过分析商业指令微调模型（OLMo、Llama、Qwen），能够揭示模型特定的微调重点，包括营销策略和Midjourney提示生成。

**Conclusion:** 本文提出了一种基于权重而非激活的新方法，实现了对微调LLMs的无监督监控和控制，有效解决了现有方法在处理分布外威胁（如后门）时的局限性，并在检测“遗忘”信息和进行模型审计方面展现出巨大潜力。

> **ai_Abstract:** 本文提出一种名为“Watch the Weights”的新方法，用于无监督地监控和控制微调大型语言模型（LLMs）。该方法通过分析模型权重而非激活来规避对分布相似数据的需求，从而有效检测和防御后门攻击等分布外威胁。研究表明，该方法能通过分析微调模型与基础模型之间的权重差异的奇异向量来识别新行为，并能高精度地检测微调过程中引入的显著行为。实验证明，该方法能有效阻止后门攻击，检测并恢复“遗忘”信息，并能揭示商业模型的微调策略。

> **摘要翻译:** 强大的开源大型语言模型（LLMs）的发布通常不附带其完整的训练数据。现有的可解释性方法，特别是那些基于激活的方法，通常需要或假设数据分布相似。这在检测和防御像后门这种本质上属于分布外的新型潜在威胁时是一个显著的局限性。
在这项工作中，我们引入了一种理解、监控和控制微调LLMs的新方法，该方法解释权重而非激活，从而规避了对与未知训练数据分布相似的数据的需求。我们证明，微调模型与其基础模型之间权重差异的顶部奇异向量对应于新获得的 KNOWLEDGE。通过监控激活沿这些方向的余弦相似度，我们可以高精度地检测微调期间引入的显著行为。
对于在存在秘密触发器时绕过安全机制的后门模型，我们的方法能阻止高达100%的攻击，误报率低于1.2%。对于经过“遗忘”训练的模型，我们能以高达95.42%的准确率检测对被擦除主题的推断，甚至可以引导模型恢复“遗忘”的信息。除了监控，我们的方法还显示了部署前模型审计的潜力：通过分析商业指令微调模型（OLMo、Llama、Qwen），我们能够揭示模型特定的微调重点，包括营销策略和Midjourney提示生成。
我们的实现代码可在https://github.com/fjzzq2002/WeightWatch找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [21] [Tackling Size Generalization of Graph Neural Networks on Biological Data from a Spectral Perspective](https://arxiv.org/abs/2305.15611)
> *从谱视角解决生物数据上图神经网络的尺寸泛化问题*

*Gaotang Li, Danai Koutra, Yujun Yan* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 尺寸泛化, 谱分析, 分布偏移, 生物数据

**Comment:** KDD 2025

> **TL;DR:** 本文从谱视角研究了图神经网络在生物数据上尺寸泛化中的分布偏移问题，并提出了一种有效的尺寸密集注意力策略来提高性能。

**AI_Comments:** 本文的创新点在于首次从谱视角深入探讨了GNN的尺寸泛化问题，并揭示了谱差异与性能的相关性。提出的模型无关的尺寸密集注意力策略具有通用性，且在实验中取得了显著的性能提升，尤其是在处理尺寸差异大的图时，这对于生物信息学等领域具有重要意义。该研究为解决GNN的尺寸泛化挑战提供了一个新的有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络（GNNs）在处理尺寸诱导的分布偏移时面临泛化挑战，尤其是在推广到更大的图时。现有研究对分布偏移的假设各异，导致对GNN泛化能力得出不同结论。本文旨在通过数据驱动的方法，从尚未充分探索的谱视角，识别和表征尺寸诱导的分布偏移类型及其对GNN性能的影响。

**Method:** 本文采用数据驱动的方法，利用真实生物数据集中图尺寸的显著差异，分析生物图并发现谱差异（由子图模式驱动，如平均循环长度）与GNN在更大、未见图上的性能强相关。基于这些见解，提出了三种模型无关的策略来增强GNN对关键子图模式的感知，并确定尺寸密集注意力为最有效的方法。通过对六种GNN架构和七种模型无关策略在五个数据集上进行大量实验来验证。

**Result:** 研究发现，由子图模式（例如平均循环长度）驱动的谱差异与GNN在更大、未见图上的性能强相关。提出的尺寸密集注意力策略显著改善了图分类性能，在比训练图大2到10倍的测试图上，F1分数比强基线提高了8%。

**Conclusion:** 尺寸密集注意力策略能够有效提高图神经网络在生物数据上处理尺寸泛化问题的能力，使其在面对更大的未见图时表现出更好的泛化性能。

> **ai_Abstract:** 本文从谱视角研究了图神经网络（GNNs）在生物数据上处理尺寸泛化中尺寸诱导的分布偏移问题。通过数据驱动分析，发现由子图模式驱动的谱差异与GNN性能高度相关。在此基础上，提出了一种模型无关的尺寸密集注意力策略，该策略被证明能显著提高GNN在比训练图大2到10倍的测试图上的图分类性能，F1分数提升高达8%。

> **摘要翻译:** 我们解决了图神经网络（GNNs）中尺寸引起的分布偏移的关键挑战及其对GNN泛化到更大图的影响。现有文献在分布偏移方面存在不同的假设，导致对GNN泛化能力得出不同的结论。与现有工作不同，我们采用数据驱动的方法来识别和表征尺寸引起的分布偏移类型，并从谱角度探讨它们对GNN性能的影响，这是一个很大程度上未被充分探索的视角。利用真实生物数据集中图尺寸的显著差异，我们分析了生物图，发现由子图模式（例如，平均循环长度）驱动的谱差异与GNN在更大、未见图上的性能密切相关。基于这些见解，我们提出了三种模型无关的策略来增强GNN对关键子图模式的感知，并确定尺寸密集注意力是最有效的方法。对六种GNN架构和七种模型无关策略在五个数据集上的广泛实验表明，我们的尺寸密集注意力策略显著改善了测试图上的图分类性能，这些测试图比训练图大2到10倍，F1分数比强基线提高了8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [28] [Sampling-enabled scalable manifold learning unveils discriminative cluster structure of high-dimensional data](https://arxiv.org/abs/2401.01100)
> *采样式可伸缩流形学习揭示高维数据的判别性聚类结构*

*Dehua Peng, Zhipeng Gui, Wenzhang Wei, Fa Li, Jie Gui, Huayi Wu, Jianya Gong* | **Category: cs.LG, I.5.3** | **Updated: 2025-08-01**

**Keywords:** 流形学习, 可伸缩性, 高维数据, 聚类结构, 采样

**Comment:** 80 pages, 37 figures

> **TL;DR:** 提出了一种名为SUDE的采样式可伸缩流形学习技术，解决了现有方法在处理大规模高维数据时聚类结构失真和可伸缩性差的问题，并在聚类分离、完整性和全局结构保持方面表现出色。

**AI_Comments:** 这篇论文的创新点在于提出了SUDE，一个结合采样和约束局部线性嵌入的流形学习方法，有效地解决了传统流形学习在大规模高维数据处理中面临的聚类结构失真和可伸缩性差的问题。其在保持聚类分离和全局结构方面的优势，以及对采样率变化的鲁棒性，使其在实际应用（如生物医学数据分析）中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有流形学习技术在揭示高维数据内在低维结构时，存在聚类结构严重扭曲的问题，这阻碍了对底层模式的理解。同时，其可伸缩性问题也限制了其在大规模数据处理中的应用。

**Method:** 本文提出了一种基于采样的可伸缩流形学习技术SUDE（Uniform and Discriminative Embedding）。该方法首先通过寻找一组地标点来构建整个数据的低维骨架，然后基于约束局部线性嵌入（CLLE）将非地标点整合到学习到的空间中。

**Result:** SUDE在合成数据集和真实世界基准测试上均表现出有效性，并成功应用于分析单细胞数据和检测心电图（ECG）信号中的异常。它在数据大小和嵌入维度方面展现出明显的可伸缩性优势，并在聚类分离、完整性和全局结构保持方面具有良好的性能。实验还表明，随着采样率的降低，嵌入质量仍具有显著的鲁棒性。

**Conclusion:** SUDE是一种有效的、可伸缩的流形学习技术，能够更好地揭示高维数据的判别性聚类结构，解决了现有方法的局限性，并成功应用于实际数据分析任务。

> **ai_Abstract:** 本文提出了一种名为SUDE的采样式可伸缩流形学习技术，旨在解决现有方法在高维大规模数据处理中存在的聚类结构失真和可伸缩性差的问题。SUDE通过先构建地标点骨架再整合非地标点的方式，实现了数据的均匀和判别性嵌入。实验证明，SUDE在可伸缩性、聚类分离、完整性及全局结构保持方面表现优异，并在单细胞数据分析和ECG异常检测中得到成功应用。

> **摘要翻译:** 作为机器学习的一个关键分支，流形学习揭示了高维空间中复杂非线性流形的内在低维结构，用于可视化、分类、聚类和获取关键见解。尽管现有技术取得了显著成功，但它们存在聚类结构严重扭曲的问题，这阻碍了对底层模式的理解。可伸缩性问题也限制了它们处理大规模数据的适用性。因此，我们提出了一种基于采样的可伸缩流形学习技术，该技术能够实现均匀和判别性嵌入，即SUDE，用于处理大规模高维数据。它首先通过寻找一组地标点来构建整个数据的低维骨架，然后基于约束局部线性嵌入（CLLE）将非地标点整合到学习到的空间中。我们通过实验验证了SUDE在合成数据集和真实世界基准测试上的有效性，并将其应用于分析单细胞数据和检测心电图（ECG）信号中的异常。SUDE在数据大小和嵌入维度方面表现出明显的可伸缩性优势，并在聚类分离、完整性和全局结构保持方面具有良好的性能。实验还表明，随着采样率的降低，嵌入质量仍具有显著的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [35] [Loss Landscape Degeneracy and Stagewise Development in Transformers](https://arxiv.org/abs/2402.02364)
> *损失函数景观的退化与Transformer的阶段性发展*

*Jesse Hoogland, George Wang, Matthew Farrugia-Roberts, Liam Carroll, Susan Wei, Daniel Murfet* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 损失函数景观, 退化, Transformer, 奇异学习理论, 局部学习系数

**Comment:** To appear, TMLR. Material on essential dynamics from v1 of this
  preprint has been removed and developed in arXiv:2501.17745

> **TL;DR:** 本研究提出Transformer模型的发展与损失函数景观的局部几何退化深度相关，并通过监测训练过程中损失函数景观的退化程度（由局部学习系数量化）证实，退化程度的变化阶段与Transformer内部计算结构和输入/输出行为的显著变化相吻合，为理解深度学习提供了基于退化的新视角。

**AI_Comments:** 这项研究通过将奇异学习理论引入Transformer的训练分析，提供了一个新颖的视角来理解深度学习中模型结构和行为的演变。它揭示了损失函数景观的几何特性（退化）与模型实际发展阶段之间的潜在联系，这对于解释Transformer等复杂模型内部机制具有重要意义。该研究的创新点在于量化了训练过程中的退化程度，并将其与模型行为变化相关联，为未来优化训练策略或设计更高效模型提供了理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 深入学习的科学需要揭示神经网络结构和行为发展背后的原理。本研究旨在探索模型发展与损失函数景观局部几何退化之间的深层联系，以更好地理解深度学习的训练过程和计算结构形成。

**Method:** 研究利用奇异学习理论的框架，通过监测训练过程中损失函数景观的退化程度（使用局部学习系数进行量化），在Transformer语言模型和上下文线性回归Transformer上进行了调查。

**Result:** 研究发现，训练过程可以划分为损失函数景观退化程度发生变化的明显阶段。这些退化程度的变化与Transformer内部计算结构和输入/输出行为的显著变化同时发生。

**Conclusion:** 这些发现提供了暗示性证据，表明在Transformer中，退化与发展是相互关联的，强调了基于退化的视角在理解现代深度学习方面的潜力。

> **ai_Abstract:** 本研究基于奇异学习理论，提出Transformer模型的发展与损失函数景观的局部几何退化紧密相关。通过监测Transformer语言模型和上下文线性回归Transformer在训练过程中损失函数景观的退化程度（由局部学习系数衡量），研究发现训练可分为退化程度变化的阶段，且这些变化与模型内部计算结构及输入/输出行为的显著改变同步。这表明退化与发展在Transformer中存在关联，为理解现代深度学习提供了新的退化视角。

> **摘要翻译:** 深度学习涉及在神经网络参数空间中导航高维损失函数景观。在训练过程中，复杂的计算结构在神经网络内部形成和重塑，导致输入/输出行为的转变。揭示神经网络结构和行为发展背后的原理是深度学习科学的优先事项。借鉴奇异学习理论的框架，我们提出模型发展与损失函数景观局部几何的退化深度相关。我们通过监测训练过程中损失函数景观的退化程度（由局部学习系数进行量化），针对Transformer语言模型和上下文线性回归Transformer，调查了这种联系。我们发现训练可以分为损失函数景观退化程度发生变化的明显阶段，并且这些退化程度的变化与Transformer内部计算结构和输入/输出行为的显著变化同时发生。这一发现提供了暗示性证据，表明在Transformer中，退化与发展是相互关联的，强调了基于退化的视角在理解现代深度学习方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [42] [Model Stock: All we need is just a few fine-tuned models](https://arxiv.org/abs/2403.19522)
> *模型库存：我们只需要少量微调模型*

*Dong-Hwan Jang, Sangdoo Yun, Dongyoon Han* | **Category: cs.LG, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 模型库存, 微调, 大型预训练模型, 分布外泛化, 权重平均

**Comment:** ECCV 2024 oral presenetation; Code at
  https://github.com/naver-ai/model-stock

> **TL;DR:** 本文提出了一种名为“模型库存”的高效微调方法，仅用少量（例如两个）微调模型即可获得优于现有方法（如Model Soup）的性能，特别是在分布内（ID）和分布外（OOD）任务上。

**AI_Comments:** 这项研究的创新之处在于它挑战了传统上需要大量模型进行平均的微调范式，并通过发现权重空间中的关键洞察，提出了一种仅用少量模型就能达到甚至超越SOTA性能的有效方法。Model Stock的概念简洁而强大，有望显著提高大型模型微调的效率和可扩展性，对于资源受限或需要快速部署的场景尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 传统方法需要大量微调模型进行平均以获得最终权重，导致效率低下。本文旨在开发一种仅需少量模型即可实现卓越性能的高效微调方法。

**Method:** 该方法基于对微调权重空间中关键见解的发现，即性能与权重空间中心接近度之间存在强关联。基于此，提出了一种使用仅两个微调模型近似中心附近权重的方法，可在训练期间或之后应用。其创新之处在于分层权重平均技术，并将其命名为“模型库存”。

**Result:** Model Stock方法仅使用两个微调模型，在基于预训练CLIP架构的模型上，在标准基准测试的ID和OOD任务上均取得了显著性能，且几乎不带来额外的计算开销。它超越了如Model Soup等现有最先进的模型方法。

**Conclusion:** 本文提出的Model Stock方法通过仅利用少量微调模型，显著提高了大型预训练模型的微调效率和性能，尤其在处理ID和OOD任务时表现出色。

> **ai_Abstract:** 本文提出了一种名为“Model Stock”的高效微调方法，旨在减少大型预训练模型微调所需的模型数量。该方法基于对权重空间中性能与中心接近度关系的洞察，通过创新的分层权重平均技术，仅使用少量（如两个）微调模型，即可在分布内和分布外任务上实现超越现有最先进方法（如Model Soup）的卓越性能，同时保持计算效率。

> **摘要翻译:** 本文介绍了一种高效的预训练大型模型微调方法，该方法在分布内（ID）和分布外（OOD）性能方面表现出色。与需要大量微调模型进行平均的传统做法不同，我们的方法使用显著更少的模型来获得最终权重，却能产生更高的精度。借鉴微调权重空间中的关键见解，我们发现性能与权重空间中心接近度之间存在密切联系。基于此，我们提出了一种仅使用两个微调模型即可近似中心附近权重的方法，该方法可在训练期间或之后应用。我们创新的分层权重平均技术超越了Model Soup等最先进的模型方法，且仅使用了两个微调模型。这种策略可以恰当地命名为“模型库存”（Model Stock），突显其依赖于选择最少数量的模型来获得更优化的平均模型。我们通过基于预训练CLIP架构的微调模型证明了Model Stock的有效性，在标准基准测试的ID和OOD任务上均取得了卓越性能，同时几乎不带来额外的计算开销。我们的代码和预训练模型可在https://github.com/naver-ai/model-stock获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [49] [SPLITZ: Certifiable Robustness via Split Lipschitz Randomized Smoothing](https://arxiv.org/abs/2407.02811)
> *SPLITZ：通过分离Lipschitz随机平滑实现可认证鲁棒性*

*Meiyu Zhong, Ravi Tandon* | **Category: cs.LG, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 可认证鲁棒性, 随机平滑, Lipschitz常数, 对抗样本, 深度学习

**Comment:** IEEE Transactions on Information Forensics and Security, accepted

> **TL;DR:** SPLITZ结合Lipschitz约束和随机平滑，提高分类器的可认证鲁棒性，并在多个数据集上超越SOTA。

**AI_Comments:** SPLITZ的创新之处在于其将两种主流的可认证鲁棒性技术（Lipschitz约束和随机平滑）巧妙地结合起来，并通过“分割”网络来利用深度网络中Lipschitz常数的异质性，这提供了一个新的视角来构建更鲁棒的深度学习模型。其在多个数据集上超越SOTA的结果也证明了其有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度网络层间Lipschitz常数存在异质性，且现有可认证鲁棒性方法（Lipschitz约束和随机平滑）各有优缺点，需要结合两者的优势。

**Method:** 本文提出了SPLITZ，一种将分类器分为两半的实用新颖方法。对前半部分约束Lipschitz常数，对后半部分通过随机化进行平滑。该方法利用了深度网络层间Lipschitz常数的异质性，并继承了随机平滑的可扩展性。同时提供了原则性的训练方法和理论分析以推导出推理期间的可认证鲁棒性保证。

**Result:** SPLITZ在MNIST、CIFAR-10和ImageNet数据集上，在鲁棒性-准确性权衡方面持续改进了现有最先进方法。例如，在CIFAR-10数据集上，当$\ell_2$范数扰动预算为$\epsilon=1$时，SPLITZ实现了43.2%的top-1测试准确率，而现有最先进的top-1测试准确率为39.8%。

**Conclusion:** SPLITZ是一种结合Lipschitz约束和随机平滑的实用且新颖的方法，可以有效提高分类器的可认证鲁棒性，并在多个基准数据集上超越现有SOTA。

> **ai_Abstract:** 本文提出了SPLITZ，一种结合了Lipschitz约束和随机平滑的新型框架，旨在提高神经网络的可认证鲁棒性。该方法通过将分类器分成两部分，分别应用Lipschitz约束和随机平滑，有效利用了网络层间Lipschitz常数的异质性。实验结果表明，SPLITZ在多个标准数据集上显著提升了鲁棒性-准确性权衡，超越了现有最先进技术。

> **摘要翻译:** 可认证鲁棒性保证了分类器输入周围的微小扰动不会改变预测结果。有两种方法可以为对抗性样本提供可认证鲁棒性：a) 明确训练具有小Lipschitz常数的分类器，以及 b) 随机平滑，它通过向输入添加随机噪声来创建平滑分类器。我们提出了SPLITZ，一种实用且新颖的方法，它将上述两种思想的协同优势整合到一个单一框架中。我们的主要思想是将分类器分为两半，约束前半部分的Lipschitz常数，并通过随机化平滑后半部分。SPLITZ的动机来自于观察到许多标准深度网络在层间表现出Lipschitz常数的异质性。SPLITZ可以利用这种异质性，同时继承随机平滑的可扩展性。我们提出了一种原则性的方法来训练SPLITZ，并提供理论分析以在推理期间推导出可认证鲁棒性保证。我们对鲁棒性-准确性权衡进行了全面比较，并表明SPLITZ在MNIST、CIFAR-10和ImageNet数据集上持续改进了现有最先进的方法。例如，在$\ell_2$范数扰动预算为$\epsilon=1$的情况下，SPLITZ在CIFAR-10数据集上达到了43.2%的top-1测试准确率，而现有最先进的top-1测试准确率为39.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [51] [Evaluating the Dynamics of Membership Privacy in Deep Learning](https://arxiv.org/abs/2507.23291)
> *评估深度学习中成员隐私的动态性*

*Yuetian Chen, Zhiqi Wang, Nathalie Baracaldo, Swanand Ravindra Kadhe, Lei Yu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 成员隐私, 深度学习, 成员推理攻击, 隐私泄露动态, 样本脆弱性

**Comment:** 

> **TL;DR:** 本文提出了一个动态分析框架，用于理解深度学习训练过程中成员隐私泄露的动态性，发现样本的隐私风险在训练早期就已确定。

**AI_Comments:** 这项研究通过引入一个动态分析框架，为理解深度学习中成员隐私泄露的机制提供了新的视角。其创新点在于能够追踪个体样本的隐私脆弱性动态，并揭示了隐私风险与样本学习难度之间的关联以及风险在训练早期确定的特性。这对于开发更具前瞻性的隐私保护训练方法具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 成员推理攻击（MIAs）对深度学习中训练数据的隐私构成了严重威胁。尽管攻击方法取得了显著进展，但我们对模型在训练期间何时以及如何编码成员信息的理解仍然有限。

**Method:** 本文提出了一个动态分析框架，用于在个体样本层面剖析和量化隐私泄露动态。通过在整个训练过程中跟踪FPR-TPR平面上的每个样本的脆弱性，该框架系统地测量了数据集复杂性、模型架构和优化器选择等因素如何影响样本变得脆弱的速度和严重程度。

**Result:** 研究发现样本的内在学习难度与其隐私风险之间存在强相关性，并且最终训练模型中高度脆弱样本的隐私风险在训练早期就已基本确定。

**Conclusion:** 我们的结果提供了对隐私风险在训练过程中如何动态出现的更深入理解，为主动的、隐私感知的模型训练策略奠定了基础。

> **ai_Abstract:** 本文提出了一个动态分析框架，旨在深入理解深度学习训练过程中成员隐私泄露的动态性。该框架通过跟踪FPR-TPR平面上的个体样本脆弱性，量化了数据集复杂性、模型架构和优化器选择等因素对隐私风险形成的影响。研究发现，样本的内在学习难度与隐私风险密切相关，且最终模型的隐私风险在训练早期便已基本确定。这些发现为开发主动的隐私保护训练策略提供了基础。

> **摘要翻译:** 成员推理攻击（MIAs）对深度学习中训练数据的隐私构成了严重威胁。尽管攻击方法取得了显著进展，但我们对模型在训练期间何时以及如何编码成员信息的理解仍然有限。本文提出了一个动态分析框架，用于在个体样本层面剖析和量化隐私泄露动态。通过在整个训练过程中跟踪FPR-TPR平面上的每个样本的脆弱性，我们的框架系统地测量了数据集复杂性、模型架构和优化器选择等因素如何影响样本变得脆弱的速度和严重程度。至关重要的是，我们发现样本的内在学习难度之间存在着稳健的关联，并且发现最终训练模型中高度脆弱样本的隐私风险在训练早期就已基本确定。因此，我们的结果提供了对隐私风险在训练过程中如何动态出现的更深入理解，为主动的、隐私感知的模型训练策略奠定了基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [52] [Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System](https://arxiv.org/abs/2507.23756)
> *在主动学习中利用情绪和疲劳感知的推荐系统改进标注者选择*

*Diana Mortagua* | **Category: cs.LG, cs.HC** | **Updated: 2025-07-31**

**Keywords:** 主动学习, 标注者选择, 推荐系统, 情绪, 疲劳

**Comment:** Master's thesis

> **TL;DR:** 本研究提出了一种考虑标注者情绪和疲劳水平的推荐系统，以改进主动学习中的标注者选择，从而减少标注错误并提高模型准确性。

**AI_Comments:** 这项研究的创新之处在于将标注者的情绪和疲劳等内部认知因素纳入主动学习的标注者选择过程中，这在以往的研究中较少被考虑。通过引入推荐系统，它提供了一个更人性化、更高效的标注者选择机制，有望显著提升数据标注质量和模型训练效率。该方法为解决主动学习中长期存在的“人”的因素影响标注质量的挑战提供了新的视角和实用方案，对于提高标注数据质量和降低成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 主动学习在获取标注数据时面临成本和时间挑战，需要减少标注错误以提高效率并更快达到预期准确率。现有查询-标注者配对策略大多未考虑影响生产力的内部因素，如情绪、注意力和疲劳水平。本研究旨在弥补这一空白。

**Method:** 本研究提出了一种新的查询-标注者配对策略，利用基于知识的推荐系统（RS）。该系统根据标注者过去的准确率、情绪和疲劳水平以及查询实例的信息对可用标注者进行排名，以选择一个或多个标注者来标注查询实例。研究基于现有关于情绪和疲劳对人类表现影响的文献，通过模拟标注者来预测其表现。

**Result:** 结果表明，与不使用内部因素相比，考虑过去的准确率以及情绪和疲劳水平可以减少标注者产生的标注错误数量，并降低模型在训练过程中的不确定性。所提出的方法在准确率和F1-score值方面也表现更好，尽管提升不如上述显著。

**Conclusion:** 本研究提出的方法通过考虑标注者的内部认知因素（情绪和疲劳），有效减少了主动学习中的标注错误，并提高了模型性能，为探索人类认知因素对主动学习的影响提供了初步见解。

> **ai_Abstract:** 本研究旨在解决主动学习中选择最佳标注者以减少错误分类的问题。针对现有方法忽视标注者内部因素的不足，论文提出了一种新的查询-标注者配对策略，该策略基于一个考虑标注者历史准确率、情绪和疲劳水平的知识型推荐系统。实验结果表明，该方法能有效减少标注错误，降低模型不确定性，并在准确率和F1-score上有所提升，为主动学习中融入人类认知因素提供了新思路。

> **摘要翻译:** 本研究旨在克服主动学习（AL）中为每个查询选择最佳标注者的挑战，以最大限度地减少错误分类。主动学习认识到获取标注数据时与成本和时间相关的挑战，并减少所需的标注数据量。然而，仍然有必要减少标注错误，旨在尽可能高效地更快地达到预期准确性。大多数查询-标注者配对策略没有考虑影响生产力的内部因素，如情绪、注意力、动机和疲劳水平。这项工作通过不仅考虑内部因素如何影响标注者（情绪和疲劳水平），而且提出一种新的查询-标注者配对策略，使用基于知识的推荐系统（RS），解决了现有文献中的这一空白。RS对可用标注者进行排名，允许选择一个或多个标注者使用他们过去的准确率值、情绪和疲劳水平以及有关查询实例的信息来标注查询实例。这项工作基于现有关于情绪和疲劳对人类表现影响的文献，以现实的方式模拟标注者，并用RS预测他们的表现。结果表明，与不使用内部因素相比，考虑过去的准确率值以及情绪和疲劳水平可以减少标注者产生的标注错误数量，并降低模型在训练过程中的不确定性。所提出的方法在准确率和F1-score值方面也表现更好，尽管提升不如上述显著。本研究中提出的方法和发现开始探索人类认知因素影响主动学习的开放性挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [55] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
> *RL作为回归器：一种用于函数逼近的强化学习方法*

*Yongchao Huang* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 回归, 函数逼近, Actor-Critic, 自定义奖励

**Comment:** 7 pages

> **TL;DR:** 本文提出将回归问题视为强化学习问题，通过定义自定义奖励信号来克服传统回归方法的局限性，并展示了其在函数逼近中的有效性。

**AI_Comments:** 该论文创新性地将回归问题重新定义为强化学习问题，提供了一种解决传统回归方法在非对称成本和不可微分目标方面局限性的新视角。其优势在于通过自定义奖励信号，使模型能够更灵活地捕捉复杂行为。这种方法为函数逼近提供了一个强大的替代方案，并可能在需要复杂、非标准损失函数的领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 标准回归技术受限于预定义的、可微分的损失函数，这些函数可能无法完全捕捉系统期望的行为，尤其是在处理非对称成本或复杂、不可微分目标时。

**Method:** 将模型的预测视为一个动作，并根据预测误差定义自定义奖励信号，从而利用强化学习算法进行函数逼近。通过学习一个带噪声的正弦波的案例研究，开发并迭代增强了一个Actor-Critic智能体，使用了优先经验回放、增加网络容量和位置编码。

**Result:** RL框架不仅成功解决了回归问题，而且在定义目标和指导学习过程方面提供了增强的灵活性。

**Conclusion:** 强化学习框架可以成功地应用于回归问题，并在定义目标和指导学习过程方面提供比传统方法更大的灵活性。

> **ai_Abstract:** 该论文提出了一种新颖的方法，将回归问题重新定义为强化学习（RL）任务，以克服传统回归技术在处理非对称成本或不可微分目标时的局限性。通过将模型预测视为动作并基于预测误差设计奖励信号，研究人员利用RL算法进行函数逼近。通过对学习噪声正弦波的案例研究，他们展示了如何开发和优化一个Actor-Critic智能体以执行此任务。结果表明，RL框架不仅能有效解决回归问题，还在目标定义和学习过程指导方面提供了更大的灵活性。

> **摘要翻译:** 标准的回归技术虽然功能强大，但通常受限于预定义的、可微分的损失函数，例如均方误差。这些函数可能无法完全捕捉系统的期望行为，尤其是在处理不对称成本或复杂、不可微分目标时。在本文中，我们探索了一种替代范式：将回归问题框架化为强化学习（RL）问题。我们通过将模型的预测视为一个动作，并根据预测误差定义自定义奖励信号来证明这一点，从而可以利用强大的RL算法来执行函数逼近。通过对学习带噪声正弦波的渐进案例研究，我们展示了一个Actor-Critic智能体的开发，并逐步通过优先经验回放、增加网络容量和位置编码来增强它，以使RL智能体能够胜任此回归任务。我们的结果表明，RL框架不仅成功解决了回归问题，而且在定义目标和指导学习过程方面提供了增强的灵活性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [56] [Convergence of Implicit Gradient Descent for Training Two-Layer Physics-Informed Neural Networks](https://arxiv.org/abs/2407.02827)
> *用于训练两层物理信息神经网络的隐式梯度下降的收敛性*

*Xianliang Xu, Ting Du, Wang Kong, Bin Shan, Ye Li, Zhongyi Huang* | **Category: cs.LG, math.OC** | **Updated: 2025-08-01**

**Keywords:** 隐式梯度下降, 物理信息神经网络, 收敛性分析, 过参数化, 线性收敛

**Comment:** 

> **TL;DR:** 本文对隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）时的收敛性进行了分析，证明了其能线性收敛到全局最优解，且学习率选择更灵活。

**AI_Comments:** 该论文的创新点在于首次对隐式梯度下降（IGD）在物理信息神经网络（PINNs）中的收敛性进行了严格的理论分析，并揭示了其在收敛速度、学习率选择灵活性以及网络宽度要求上的优势。这对于理解和改进PINNs的训练过程具有重要意义，尤其是在处理多尺度问题时，IGD可能提供更鲁棒的优化途径。其理论分析的严谨性以及经验验证的结合，增加了研究的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 优化算法对物理信息神经网络（PINNs）的训练至关重要，不合适的算法可能导致较差的解决方案。相比常见的梯度下降（GD），隐式梯度下降（IGD）在处理某些多尺度问题上表现更优。

**Method:** 本文提供了隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）时的收敛性分析。研究首先推导了IGD的训练动力学，然后利用过参数化理论证明了随机初始化的IGD能够以线性收敛速度收敛到全局最优解。此外，该分析还指出IGD的学习率选择可以独立于样本大小和Gram矩阵的最小特征值，并且对网络宽度要求更宽松。

**Result:** 随机初始化的隐式梯度下降（IGD）以线性收敛速度收敛到全局最优解。学习率的选择可以独立于样本大小和Gram矩阵的最小特征值。收敛分析方法对网络宽度施加了更宽松的要求。经验结果验证了理论发现。

**Conclusion:** 本文为隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）中提供了严格的收敛性分析，并揭示了其在收敛性、学习率选择和网络宽度要求方面的优势，通过实证结果验证了理论。

> **ai_Abstract:** 本文深入分析了隐式梯度下降（IGD）在训练过参数化两层物理信息神经网络（PINNs）时的收敛性。研究首先推导了IGD的训练动力学，并证明了其在过参数化条件下能以线性速度收敛到全局最优解。重要的是，IGD的学习率选择不受样本大小和Gram矩阵最小特征值的影响，且其收敛分析对网络宽度要求更低。这些理论结果得到了经验验证，凸显了IGD在PINNs训练中的优势。

> **摘要翻译:** 优化算法在训练物理信息神经网络（PINNs）中至关重要，因为不合适的方法可能导致较差的解决方案。与常见的梯度下降（GD）算法相比，隐式梯度下降（IGD）在处理某些多尺度问题上表现更优。在本文中，我们提供了IGD在训练过参数化两层PINNs时的收敛性分析。我们首先推导了IGD在训练两层PINNs时的训练动力学。然后，过参数化使我们能够证明随机初始化的IGD以线性收敛速度收敛到全局最优解。此外，由于IGD与GD独特的训练动力学，学习率的选择可以独立于样本大小和Gram矩阵的最小特征值。另外，我们收敛分析中采用的新颖方法对网络宽度施加了更宽松的要求。最后，经验结果验证了我们的理论发现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [63] [TensorSocket: Shared Data Loading for Deep Learning Training](https://arxiv.org/abs/2409.18749)
> *TensorSocket：深度学习训练的共享数据加载*

*Ties Robroek, Neil Kim Nielsen, Pınar Tözün* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 深度学习, 数据加载, 共享数据, TensorSocket, 训练效率

**Comment:** 

> **TL;DR:** TensorSocket 允许深度学习训练过程共享数据加载器，从而减少 CPU 瓶颈、提高吞吐量并节省成本。

**AI_Comments:** TensorSocket 为深度学习训练中常见的数据供应瓶颈提供了一个实用的解决方案。它能够跨不同模型大小和批次大小实现数据共享，结合其硬件无关的特性，使其具有高度通用性。报告的性能提升和成本节约是巨大的，凸显了其在资源密集型深度学习工作流中提高效率的潜力。它在性能和易用性方面优于现有解决方案，这是一项重要的创新。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型训练是重复且资源密集的过程，数据处理管道反复运行导致计算成本高昂，尤其当 GPU 吞吐量高但 CPU 数据加载速度慢时，会产生 CPU 端瓶颈。

**Method:** TensorSocket 通过允许并发训练过程共享相同的数据加载器来减少计算需求。它通过减少协同训练过程中的冗余计算和数据重复，并利用现代 GPU-GPU 互连来实现。TensorSocket 能够训练和平衡不同大小的模型，并同时服务多个批次大小，且与硬件和管道无关。

**Result:** TensorSocket 实现了在没有数据共享的情况下不可行的场景，将训练吞吐量提高了高达 100%，在使用云实例时通过减少 CPU 端的硬件资源需求实现了 50% 的成本节约。它优于最先进的共享数据加载解决方案（如 CoorDL 和 Joader），更容易部署和维护，并且在需要更少 CPU 资源的情况下，要么实现更高的吞吐量，要么与它们持平。

**Conclusion:** TensorSocket 通过实现共享数据加载，有效解决了深度学习训练中的数据加载瓶颈，与现有解决方案相比，提供了显著的性能和成本效益。

> **ai_Abstract:** TensorSocket 旨在解决深度学习训练中 CPU 端的数据加载瓶颈，通过允许并发训练过程共享单一数据加载器来实现。这减少了冗余计算和数据重复，并利用了 GPU-GPU 互连。它显著提高了训练吞吐量（高达 100%），降低了云成本（50%），并且优于现有解决方案如 CoorDL 和 Joader，同时具有硬件/管道无关性和更易部署的特点。

> **摘要翻译:** 深度学习模型训练是一个重复且资源密集的过程。数据科学家通常会训练多个模型，才能确定一组能够产生最高准确率的参数（例如超参数调优）和模型架构（例如神经架构搜索）等。这些训练任务的计算效率高度依赖于训练数据如何良好地供应给训练过程。这些任务的重复性导致相同的数据处理管道反复运行，加剧了对计算资源的需求和成本。在本文中，我们提出了 TensorSocket，通过使并发训练过程能够共享相同的数据加载器来减少深度学习训练的计算需求。TensorSocket 在协同训练工作负载在 GPU 上具有高吞吐量，但受限于 CPU 上较低数据加载吞吐量的情况下，缓解了 CPU 端的瓶颈。TensorSocket 通过减少协同训练过程中的冗余计算和数据重复，并利用现代 GPU-GPU 互连来实现这一点。在此过程中，TensorSocket 能够训练和平衡不同大小的模型，并同时服务多个批次大小，并且本质上与硬件和管道无关。我们的评估表明，TensorSocket 实现了在没有数据共享的情况下不可行的场景，将训练吞吐量提高了高达 100%，并且在使用云实例时，通过减少 CPU 端的硬件资源需求，实现了 50% 的成本节约。此外，TensorSocket 优于最先进的共享数据加载解决方案，如 CoorDL 和 Joader；它更容易部署和维护，并且在需要更少 CPU 资源的情况下，要么实现更高的吞吐量，要么与它们持平。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [70] [Sampling from Energy-based Policies using Diffusion](https://arxiv.org/abs/2410.01312)
> *使用扩散模型从基于能量的策略中采样*

*Vineet Jain, Tara Akhound-Sadegh, Siamak Ravanbakhsh* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 能量策略, 扩散模型, 强化学习, 多模态行为, 样本效率

**Comment:** 

> **TL;DR:** 提出了一种基于扩散模型的新方法DQS，用于从能量策略中采样，解决了连续动作空间中多模态行为建模的挑战，提高了样本效率。

**AI_Comments:** 这篇论文的创新点在于将扩散模型引入到强化学习中的策略采样问题，特别是针对能量基策略的复杂多模态行为建模。它提供了一种有效的方法来克服传统参数化策略的局限性，并提高了样本效率，这对于处理现实世界中复杂决策问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在最大熵强化学习中，最优策略是玻尔兹曼分布，但在连续动作空间中直接从中采样计算上不可行。现有方法使用简单的参数分布（如高斯分布）限制了捕捉多模态动作分布的能力。

**Method:** 引入了一种基于扩散模型的方法，用于从能量策略中采样，其中负Q函数定义能量函数。基于此，提出了一种名为Diffusion Q-Sampling (DQS) 的actor-critic方法，以实现更具表达力的策略表示。

**Result:** 该方法在连续控制任务中提高了样本效率，并能够捕获多模态行为。

**Conclusion:** 所提出的DQS方法通过提高样本效率和捕获多模态行为，解决了现有方法在处理复杂、多模态行为时面临的关键限制。

> **ai_Abstract:** 本文提出了一种名为Diffusion Q-Sampling (DQS) 的新型actor-critic方法，它利用扩散模型从基于能量的策略中采样。该方法旨在解决在最大熵强化学习中从连续动作空间的玻尔兹曼分布中直接采样计算不可行的问题，以及现有方法难以捕捉多模态行为的局限性。DQS通过将负Q函数定义为能量函数，实现了更具表达力的策略表示，并在连续控制任务中展示了更高的样本效率和捕获多模态行为的能力。

> **摘要翻译:** 基于能量的策略为强化学习（RL）中复杂、多模态行为建模提供了一个灵活的框架。在最大熵强化学习中，最优策略是源自软Q函数的玻尔兹曼分布，但在连续动作空间中直接从该分布中采样在计算上是不可行的。因此，现有方法通常使用更简单的参数分布，如高斯分布，进行策略表示——这限制了它们捕捉多模态动作分布全部复杂性的能力。在本文中，我们引入了一种基于扩散模型的方法，用于从基于能量的策略中采样，其中负Q函数定义了能量函数。基于这种方法，我们提出了一种名为扩散Q采样（DQS）的actor-critic方法，该方法能够实现更具表达力的策略表示，从而在不同环境中实现稳定学习。我们表明，我们的方法提高了连续控制任务中的样本效率，并捕获了多模态行为，解决了现有方法的关键限制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [77] [Federated Time Series Generation on Feature and Temporally Misaligned Data](https://arxiv.org/abs/2410.21072)
> *联邦时间序列生成在特征和时间错位数据上的应用*

*Zhi Wen Soi, Chenrui Fan, Aditya Shankar, Abele Mălan, Lydia Y. Chen* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 时间序列, 数据错位, 扩散模型, 数据蒸馏

**Comment:** 

> **TL;DR:** FedTDD是一种联邦时间序列扩散模型，通过蒸馏和聚合合成数据输出来处理特征和时间错位问题，并在实验中表现出显著优于本地训练的性能。

**AI_Comments:** 这篇论文提出了一种创新的联邦时间序列生成方法，解决了现实世界分布式数据集中常见的特征和时间错位这一关键问题。利用数据蒸馏和交换合成输出而非模型参数，是其新颖的贡献，有助于在保护隐私的同时实现有效的知识迁移。实验中显著的性能提升突显了FedTDD的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 分布式时间序列数据在联邦学习中面临挑战，因为客户端通常拥有不同的特征集和错位的时间步长。现有的联邦时间序列模型受限于客户端之间完美时间或特征对齐的假设。

**Method:** 本文提出了FedTDD，一种新颖的联邦时间序列扩散模型，它在客户端之间共同学习一个合成器。FedTDD的核心是一个新颖的数据蒸馏和聚合框架，通过插补错位的时间步长和特征来协调客户端之间的差异。与传统的联邦学习不同，FedTDD通过交换本地合成输出而不是模型参数来学习客户端时间序列之间的相关性。协调器通过交换合成数据，利用客户端的共享知识，迭代地改进全局蒸馏器网络。

**Result:** 在五个数据集上的实验结果表明，与集中式训练相比，FedTDD是有效的，并且共享合成输出以传输本地时间序列知识也是有效的。值得注意的是，FedTDD在Context-FID和相关性分数上比本地训练分别提高了79.4%和62.8%。

**Conclusion:** FedTDD通过新颖的数据蒸馏和聚合框架以及合成输出的交换，有效地解决了联邦时间序列生成中数据错位的问题，并表现出优于现有方法的性能。

> **ai_Abstract:** 本文介绍了FedTDD，一种新颖的联邦时间序列扩散模型，旨在解决分布式时间序列数据中特征和时间错位带来的挑战。与传统联邦学习不同，FedTDD采用数据蒸馏和聚合框架，通过插补缺失数据并交换本地合成输出来学习相关性，而非模型参数。中央协调器迭代优化全局蒸馏器网络，进而提升客户端的本地特征估计和插补质量。在五个数据集上的实验结果表明，FedTDD的性能优于集中式训练和本地训练，在Context-FID和相关性分数上取得了显著提升。

> **摘要翻译:** 分布式时间序列数据对联邦学习提出了挑战，因为客户端通常拥有不同的特征集和错位的时间步长。现有的联邦时间序列模型受限于客户端之间完美时间或特征对齐的假设。在本文中，我们提出了FedTDD，一种新颖的联邦时间序列扩散模型，它在客户端之间共同学习一个合成器。FedTDD的核心是一个新颖的数据蒸馏和聚合框架，通过插补错位的时间步长和特征来协调客户端之间的差异。与传统的联邦学习不同，FedTDD通过交换本地合成输出而不是模型参数来学习客户端时间序列之间的相关性。协调器通过交换合成数据，利用客户端的共享知识，迭代地改进全局蒸馏器网络。随着蒸馏器随时间变得更加精炼，它随后提高了客户端本地特征估计的质量，从而允许每个客户端使用最新、更准确的蒸馏器改进其缺失数据的本地插补。在五个数据集上的实验结果表明，与集中式训练相比，FedTDD是有效的，并且共享合成输出以传输本地时间序列知识也是有效的。值得注意的是，FedTDD在Context-FID和相关性分数上比本地训练分别提高了79.4%和62.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [85] [Un-mixing Test-time Adaptation under Heterogeneous Data Streams](https://arxiv.org/abs/2411.15173)
> *异构数据流下测试时间适应的解耦*

*Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Kaizhu Huang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 测试时间适应, 分布偏移, 异构数据, 频域, 去中心化学习

**Comment:** 

> **TL;DR:** 针对测试时间适应（TTA）在混合分布偏移下的性能下降问题，本文提出了一种名为FreDA的基于频率的去中心化适应框架。FreDA通过在频域分解异构数据并采用去中心化学习，显著优于现有方法。

**AI_Comments:** 本文的创新点在于从频域视角重新审视测试时间适应（TTA），并提出了一种新颖的框架FreDA来解决异构数据流下TTA的固有挑战。通过在频域进行域感知分离和数据分解，并结合去中心化学习，FreDA有效地处理了现实世界中常见的复杂混合分布偏移问题，超越了传统的同质适应范式，为TTA领域带来了重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 深度模型在训练与部署环境之间存在分布偏移时性能显著下降。测试时间适应（TTA）是一种有前景的解决方案，但在实际应用中常见的复杂、混合分布偏移（存在多个潜在域）下，其有效性会显著降低。在无标签和在线条件下，在固有异构性下进行适应仍然是一个开放且未充分探索的挑战。

**Method:** 本文研究了混合分布偏移下的TTA，并超越了传统的同质适应范式。通过从频域视角重新审视TTA，作者观察到分布异构性通常在傅里叶空间中表现出来，例如高频分量倾向于携带域特定的变化。这促使他们利用高频纹理线索进行域感知分离，使不同的偏移模式更易处理。为此，他们提出了FreDA（Frequency-based Decentralized Adaptation），一个新颖的基于频率的去中心化适应框架，它在频域将全局异构数据分解为局部同质分量，并进一步采用去中心化学习和增强策略，以在复杂、不断变化的偏移下进行鲁棒适应。

**Result:** 在各种环境（损坏、自然和医学）中进行的广泛实验表明，所提出的框架优于最先进的方法。

**Conclusion:** FreDA通过利用频域分析和去中心化适应，有效地解决了异构分布偏移下测试时间适应的挑战，并取得了优越的性能。

> **ai_Abstract:** 深度模型在面对分布偏移时性能会下降，测试时间适应（TTA）是解决方案之一，但在实际场景中，面对复杂、混合的异构数据流时，TTA的有效性会大打折扣。本文提出了一种名为FreDA（Frequency-based Decentralized Adaptation）的新颖框架，旨在解决异构数据流下的TTA问题。FreDA通过观察到分布异构性常在频域中显现，利用高频纹理线索将全局异构数据在频域分解为局部同质分量，并结合去中心化学习和增强策略来实现鲁棒适应。广泛的实验证明，FreDA在多种环境下均优于现有最先进的方法。

> **摘要翻译:** 由于训练和部署环境之间的分布偏移，在实际场景中部署深度模型仍然面临挑战，导致性能显著下降。测试时间适应（TTA）最近作为一种有前景的解决方案出现，它能够在不访问源数据的情况下进行即时模型适应。然而，在存在复杂、混合分布偏移（在实际设置中很常见，其中多个潜在域共存）的情况下，其有效性会显著降低。在这种固有的异构性下进行适应，特别是在无标签和在线条件下，仍然是一个开放且未充分探索的挑战。在本文中，我们研究了混合分布偏移下的TTA，并超越了传统的同质适应范式。通过从频域视角重新审视TTA，我们观察到分布异构性通常在傅里叶空间中表现出来——例如，高频分量倾向于携带域特定的变化。这促使我们利用高频纹理线索进行域感知分离，使不同的偏移模式更易处理。为此，我们提出了FreDA，一个新颖的基于频率的去中心化适应框架，它在频域将全局异构数据分解为局部同质分量。它进一步采用去中心化学习和增强策略，以在复杂、不断变化的偏移下进行鲁棒适应。在各种环境（损坏、自然和医学）中进行的广泛实验表明，我们提出的框架优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [90] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
> *无滞后EMA：偏差校正迭代平均方案*

*Adam Block, Cyril Zhang* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-07-31**

**Keywords:** 指数移动平均, 偏差校正, 语言模型微调, 收敛加速, 稳定性

**Comment:** 

> **TL;DR:** BEMA通过校正EMA在语言模型微调中的偏差，实现了更快的收敛和更好的性能，消除了优化滞后。

**AI_Comments:** 本文的创新点在于提出了BEMA，一种简单而有效的偏差校正机制，解决了EMA在模型训练中引入滞后的问题。其重要性在于，在语言模型微调这种对稳定性要求较高的场景下，BEMA能够提供更快的收敛速度和更好的最终性能，具有实际应用价值。理论证明与实验验证相结合，增强了研究的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 语言模型微调中，小批量大小导致的随机性会使训练不稳定并引入大波动。指数移动平均（EMA）能减少随机性但会引入偏差和优化滞后。本文旨在提出一种方法，在保留EMA方差减少优点的同时，消除其偏差和滞后。

**Method:** 本文提出了偏差校正指数移动平均（BEMA），这是对传统EMA的一种简单实用的增强。BEMA基于一个理论模型，该模型证明了其相对于标准EMA和普通训练的加速效果。

**Result:** 在语言模型上的大量实验表明，BEMA在各种标准LM基准测试中，相对于EMA和普通训练，显著提高了收敛速度和最终性能。

**Conclusion:** BEMA是一种实用且有理论依据的干预措施，可实现更稳定、更高效的语言模型微调。

> **ai_Abstract:** 本文提出了一种名为偏差校正指数移动平均（BEMA）的新方法，旨在解决语言模型微调中指数移动平均（EMA）引入的优化滞后问题。通过消除EMA的偏差，BEMA在理论上证明了比标准EMA和普通训练更快的加速效果。实验结果表明，BEMA在多个语言模型基准测试中显著提高了收敛速度和最终性能，为更稳定和高效的微调提供了一个实用的解决方案。

> **摘要翻译:** 语言模型微调中的随机性，通常由该机制下使用的小批量大小引起，可能通过引入生成质量的大幅波动而不稳定训练。缓解这种不稳定性的一个流行方法是在整个训练过程中对权重进行指数移动平均（EMA）。虽然EMA减少了随机性，从而平滑了训练，但旧迭代引入的偏差往往导致优化相对于普通训练产生滞后。在这项工作中，我们提出了偏差校正指数移动平均（BEMA），这是一种对EMA的简单实用增强，它保留了方差减少的优点，同时消除了偏差。BEMA的动机是一个简单的理论模型，在该模型中我们证明了BEMA相对于标准EMA和普通训练的可证明加速。通过在语言模型上进行的大量实验，我们表明BEMA在各种标准LM基准测试中，相对于EMA和普通训练，显著提高了收敛速度和最终性能，这使得BEMA成为一种实用且有理论依据的干预措施，可实现更稳定、更高效的微调。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [91] [Embracing Large Language Models in Traffic Flow Forecasting](https://arxiv.org/abs/2412.12201)
> *在交通流量预测中拥抱大型语言模型*

*Yusheng Zhao, Xiao Luo, Haomin Wen, Zhiping Xiao, Wei Ju, Ming Zhang* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 交通流量预测, 大型语言模型, 时空依赖, 智能交通系统, LEAF

**Comment:** Accepted by ACL 2025

> **TL;DR:** 本文提出了一种名为LEAF的新方法，通过引入大型语言模型（LLMs）来解决交通流量预测中现有方法难以适应测试时环境变化的问题，并利用LLM选择最佳预测结果。

**AI_Comments:** 该论文的创新点在于将大型语言模型引入交通流量预测领域，并以一种新颖的方式利用LLM，即不直接进行预测，而是作为一种决策机制来选择或优化来自传统时空模型的预测结果。这为LLM在智能交通系统中的应用开辟了新的思路，尤其是在提高模型对环境变化的适应性方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的交通流量预测方法主要关注捕获和利用时空依赖性，但在适应交通状况的测试时环境变化方面存在不足。

**Method:** 本文提出了一种名为LEAF（Large Language Model Enhanced Traffic Flow Predictor）的新方法。LEAF包含两个分支，分别使用图结构和超图结构捕获不同的时空关系。这两个分支首先单独预训练，在测试时产生不同的预测结果。基于这些预测，使用大型语言模型选择最可能的结果。然后，应用排序损失作为学习目标，以增强两个分支的预测能力。

**Result:** 在多个数据集上进行的广泛实验证明了所提出的LEAF方法的有效性。

**Conclusion:** 通过引入大型语言模型，LEAF方法能够有效提高交通流量预测在面对测试时环境变化时的适应性，并取得了良好的预测效果。

> **ai_Abstract:** 本文提出了一种名为LEAF（Large Language Model Enhanced Traffic Flow Predictor）的新型交通流量预测方法，旨在解决现有方法在适应测试时环境变化方面的不足。LEAF通过结合两个分别基于图和超图结构的时空预测分支，并在测试阶段利用大型语言模型（LLM）从这两个分支的预测中选择最可能的结果。此外，采用排序损失来优化分支的预测能力。多项实验证明了LEAF的有效性。

> **摘要翻译:** 交通流量预测旨在根据历史交通状况和路网预测未来的交通流量。这是智能交通系统中的一个重要问题，已经提出了大量方法。现有工作主要侧重于捕获和利用时空依赖性来预测未来的交通流量。尽管前景光明，但它们在适应交通状况的测试时环境变化方面存在不足。为了解决这一挑战，我们提出引入大型语言模型（LLMs）来帮助交通流量预测，并设计了一种名为大型语言模型增强交通流量预测器（LEAF）的新方法。LEAF采用两个分支，分别使用图和超图结构捕获不同的时空关系。这两个分支首先单独预训练，在测试时，它们会产生不同的预测。基于这些预测，使用大型语言模型选择最可能的结果。然后，应用排序损失作为学习目标，以增强两个分支的预测能力。在多个数据集上进行的广泛实验证明了所提出的LEAF的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [98] [A comparative analysis of rank aggregation methods for the partial label ranking problem](https://arxiv.org/abs/2502.17077)
> *针对部分标签排序问题的秩聚合方法比较分析*

*Jiayi Wang, Juan C. Alfaro, Viktor Bengs* | **Category: cs.LG, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 秩聚合, 部分标签排序, 监督学习, 评分方法, 不完整信息

**Comment:** Full version of the paper accepted at ECAI 2025

> **TL;DR:** 本文比较了用于部分标签排序问题的秩聚合方法，发现基于评分的方法优于现有技术，而基于非参数概率的方法表现不佳。

**AI_Comments:** 这篇论文通过比较不同的秩聚合方法，为部分标签排序问题提供了新的视角和有效的解决方案。它不仅指出了现有方法的局限性，还通过实验验证了基于评分的方法在处理平局和不完整信息方面的优越性，对该领域的研究具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的部分标签排序问题学习方法在最终预测步骤中依赖于秩聚合的近似算法，本文旨在探索更合适的替代聚合方法，特别是为了更好地处理预测中的平局。

**Method:** 论文探索了几种替代的秩聚合方法，包括基于评分和基于非参数概率的方法。为了提高它们对更一般的部分标签排序问题的适用性，所研究的方法被扩展以增加产生平局的可能性。

**Result:** 在标准基准测试上的实验评估表明，基于评分的变体在处理不完整信息方面始终优于现有最先进的方法。相比之下，基于非参数概率的变体未能达到有竞争力的性能。

**Conclusion:** 基于评分的秩聚合方法更适用于部分标签排序问题，尤其是在处理不完整信息方面表现优异，而基于非参数概率的方法则不适用。

> **ai_Abstract:** 这篇论文比较分析了用于部分标签排序问题的多种秩聚合方法，部分标签排序问题是标签排序的泛化，允许预测结果中存在平局。研究探索了基于评分和非参数概率的聚合方法，并对其进行了修改以更好地处理平局。实验结果表明，基于评分的方法在处理不完整信息时表现优于现有技术，而基于非参数概率的方法则表现不佳。

> **摘要翻译:** 标签排序问题是一种监督学习场景，学习器需要为给定的输入实例预测类别标签的完整顺序。最近，研究日益关注部分标签排序问题，它是标签排序问题的一种泛化，允许预测顺序中存在平局。到目前为止，大多数现有的部分标签排序问题学习方法在最终预测步骤中都依赖于秩聚合的近似算法。本文探讨了针对这一关键步骤的几种替代聚合方法，包括基于评分和基于非参数概率的秩聚合方法。为了增强它们对更一般的部分标签排序问题的适用性，所研究的方法被扩展以增加产生平局的可能性。在标准基准测试上的实验评估表明，基于评分的变体在处理不完整信息方面始终优于现有最先进的方法。相比之下，基于非参数概率的变体未能达到有竞争力的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [106] [Unlocking Multi-Modal Potentials for Link Prediction on Dynamic Text-Attributed Graphs](https://arxiv.org/abs/2502.19651)
> *释放多模态潜力以实现动态文本属性图上的链接预测*

*Yuanyuan Xu, Wenjie Zhang, Ying Zhang, Xuemin Lin, Xiwei Xu* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 动态文本属性图, 链接预测, 多模态学习, 双域对齐, 节点表示

**Comment:** 

> **TL;DR:** MoMent模型通过显式建模、整合和对齐时间、文本和结构三种模态，显著提升了动态文本属性图上的链接预测性能和效率。

**AI_Comments:** 这篇论文的创新点在于明确识别了动态文本属性图中的时间、文本和结构三种核心模态，并提出了一种新颖的多模态融合与对齐机制（双域对齐损失），有效解决了异构模态分布不相交的问题。其重要性在于通过充分利用多模态信息，显著提升了动态图链接预测的性能和效率，为未来相关研究提供了新的视角和方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在动态文本属性图（DyTAGs）上的链接预测中，普遍忽视了时间模态和文本模态的重要性，导致性能不佳。DyTAGs本质上包含时间、文本和结构三种模态，且这些模态的分布通常是完全不相交的。

**Method:** 论文提出了MoMent模型，该模型通过显式建模、整合和对齐动态文本属性图中的时间、文本和结构三种模态来学习节点表示。具体而言，它首先为每种模态构建特定特征并使用独立的编码器进行编码，以捕获跨模态的相关性。然后，将生成的模态特定token融合为全面的节点表示。为了解决异构模态之间不相交的子空间问题，MoMent引入了一种双域对齐损失，该损失首先全局对齐模态分布，然后在实例级别微调一致性，从而增强多视图的连贯表示。

**Result:** 在七个数据集上的大量实验表明，MoMent模型相比八个基线模型，准确率最高提升了17.28%，速度最高提升了31倍。

**Conclusion:** MoMent通过有效建模、整合和对齐动态文本属性图中的多模态信息，显著提高了链接预测的准确性和效率，解决了现有方法忽视时间与文本模态的局限性。

> **ai_Abstract:** 本文针对动态文本属性图（DyTAGs）上的链接预测问题，提出了一种名为MoMent的多模态模型。MoMent通过显式地建模、整合和对齐DyTAGs中的时间、文本和结构三种模态来学习节点表示。它首先构建模态特定特征并使用独立编码器进行编码，然后将生成的模态特定token融合。为解决模态分布不相交的问题，MoMent引入了双域对齐损失，以在全球和实例级别上对齐模态分布，从而增强表示的连贯性。实验结果表明，MoMent在准确性和运行速度上均显著优于现有基线方法。

> **摘要翻译:** 动态文本属性图（DyTAGs）是一种新颖的图范式，它捕获不断演变的时间事件（边）以及丰富的文本属性。现有研究大致可分为TGNN驱动和LLM驱动的方法，这两种方法都编码文本属性和时间结构以进行DyTAG表示。我们观察到DyTAGs本质上包含三种不同的模态：时间、文本和结构，这些模态通常表现出完全不相交的分布。然而，前两种模态在现有研究中很大程度上被忽视，导致性能不佳。为了解决这个问题，我们提出了MoMent，一个多模态模型，它显式地建模、整合和对齐每种模态，以学习用于链接预测的节点表示。考虑到原始模态分布的不相交性质，我们首先构建特定于模态的特征，并使用单独的编码器对其进行编码，以捕获跨时间模式、语义上下文和局部结构的相关性。每个编码器生成模态特定的token，然后将其融合为具有理论保证的综合节点表示。为了避免这些异构模态的不相交子空间，我们提出了一种双域对齐损失，该损失首先全局对齐它们的分布，然后在实例级别微调一致性。这增强了时间、文本和结构视图的连贯表示。在七个数据集上的大量实验表明，MoMent相比八个基线模型，准确率最高提升了17.28%，速度最高提升了31倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [112] [ULTHO: Ultra-Lightweight yet Efficient Hyperparameter Optimization in Deep Reinforcement Learning](https://arxiv.org/abs/2503.06101)
> *ULTHO：深度强化学习中超轻量级高效超参数优化*

*Mingqi Yuan, Bo Li, Xin Jin, Wenjun Zeng* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 超参数优化, 深度强化学习, 多臂老虎机, ULTHO, 计算效率

**Comment:** 24 pages, 25 figures

> **TL;DR:** ULTHO是一种超轻量级、高效的深度强化学习超参数优化框架，通过将HPO建模为MABC来解决现有方法的样本效率低和计算成本高的问题，并在多个基准测试中表现出色。

**AI_Comments:** ULTHO的创新点在于将深度强化学习中的复杂超参数优化问题转化为更易于处理的多臂老虎机问题，并引入了聚类臂的概念，这可能有效地解决了非平稳性和计算成本高的问题。其“超轻量级”和“单次运行”的特点是其核心优势，预示着该方法在实际应用中具有高效率和实用性，有望推动强化学习系统的自动化发展。

<details>
  <summary>Details</summary>

**Motivation:** 深度强化学习中的超参数优化（HPO）由于其高非平稳性和计算成本而极具挑战性。现有方法（如基于群体训练或贝叶斯优化）样本效率低下且计算成本高昂，无法广泛应用于实际场景。

**Method:** 本文提出了ULTHO框架，一个超轻量级但功能强大的深度强化学习快速超参数优化方法。ULTHO将HPO过程公式化为具有聚类臂的多臂老虎机（MABC）问题，并将其直接与长期回报优化联系起来。此外，ULTHO还提供了一种量化和统计的视角来高效过滤超参数。

**Result:** ULTHO在ALE、Procgen、MiniGrid和PyBullet等多个深度强化学习基准测试中进行了广泛评估。实验结果表明，ULTHO即使采用简单的架构也能实现卓越的性能。

**Conclusion:** ULTHO为深度强化学习中的超参数优化提供了一个高效且轻量级的解决方案，有助于开发先进和自动化的强化学习系统。

> **ai_Abstract:** 本文提出了ULTHO，一个针对深度强化学习中超参数优化（HPO）的超轻量级高效框架。针对现有方法在深度RL中样本效率低和计算成本高的问题，ULTHO将HPO建模为具有聚类臂的多臂老虎机（MABC），并将其与长期回报优化相结合，同时利用量化统计视角高效过滤超参数。实验证明，ULTHO在多个基准测试中以简单架构取得了卓越性能，有助于构建先进的自动化RL系统。

> **摘要翻译:** 超参数优化（HPO）是机器学习中一个价值数十亿美元的问题，它显著影响训练效率和模型性能。然而，由于其高非平稳性和计算成本，在深度强化学习（RL）中实现高效且稳健的HPO一直是一个挑战。为了解决这个问题，现有方法试图将常见的HPO技术（例如，基于群体训练或贝叶斯优化）应用于RL场景。然而，它们仍然样本效率低下且计算成本高昂，无法促进广泛的应用。在本文中，我们提出了ULTHO，一个超轻量级但功能强大的框架，用于在单次运行中快速进行深度RL中的HPO。具体来说，我们将HPO过程公式化为具有聚类臂的多臂老虎机（MABC），并将其直接与长期回报优化联系起来。ULTHO还提供了一种量化和统计的视角来高效过滤超参数。我们在ALE、Procgen、MiniGrid和PyBullet等基准测试中测试了ULTHO。大量实验表明，ULTHO可以通过简单的架构实现卓越的性能，有助于开发先进和自动化的RL系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [119] [Panopticon: Advancing Any-Sensor Foundation Models for Earth Observation](https://arxiv.org/abs/2503.10845)
> *Panopticon：推进地球观测的任意传感器基础模型*

*Leonard Waldmann, Ando Shah, Yi Wang, Nils Lehmann, Adam J. Stewart, Zhitong Xiong, Xiao Xiang Zhu, Stefan Bauer, John Chuang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 地球观测, 任意传感器模型, 基础模型, DINOv2, 传感器无关

**Comment:** First two authors contributed equally. Code is available at:
  https://github.com/Panopticon-FM/panopticon. Accepted to CVPR 2025

> **TL;DR:** Panopticon是一个基于DINOv2的任意传感器基础模型，通过处理多样的地球观测数据，在GEO-Bench上取得了最先进的性能，并实现了对现有和未来卫星平台的即时泛化。

**AI_Comments:** Panopticon的创新之处在于其对DINOv2框架的扩展，使其能够处理任意传感器输入，这对于地球观测领域的多样化数据处理具有重要意义。通过将地理定位图像视为增强和灵活的通道处理机制，该模型提高了对未知传感器配置的泛化能力，是推进传感器无关EO的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 地球观测(EO)数据具有多样化的传感平台，光谱波段、空间分辨率和传感模式各不相同。虽然大多数现有工作将输入限制在固定传感器上，但最近出现了一类能够处理任意传感器的新型任意传感器基础模型。本文旨在贡献于这一领域。

**Method:** 本文提出了Panopticon，一个基于DINOv2框架构建的任意传感器基础模型。它通过以下方式扩展了DINOv2：(1) 将跨传感器的相同地理定位图像视为自然增强；(2) 对通道进行子采样以使光谱输入多样化；(3) 增加一个跨通道的交叉注意力作为灵活的补丁嵌入机制。通过分别编码光学和合成孔径雷达传感器的波长和模式，Panopticon可以有效地处理任意通道的任意组合。

**Result:** 在广泛的评估中，Panopticon在GEO-Bench上取得了最先进的性能，尤其是在广泛使用的Sentinel-1和Sentinel-2传感器上，同时在独特的传感器配置上超越了其他任意传感器模型以及领域适应的固定传感器模型。

**Conclusion:** Panopticon能够立即泛化到现有和未来的卫星平台，从而推进了传感器无关的地球观测。

> **ai_Abstract:** Panopticon是一个基于DINOv2框架构建的任意传感器基础模型，旨在解决地球观测数据多样性带来的挑战。它通过将相同地理定位图像视为增强、对通道进行子采样以及添加跨通道注意力机制来扩展DINOv2，并能编码传感器波长和模式以处理任意通道组合。该模型在GEO-Bench上取得了最先进的性能，特别是在Sentinel-1和Sentinel-2传感器上表现出色，并能泛化到不同的卫星平台，推动了传感器无关的地球观测。

> **摘要翻译:** 地球观测（EO）数据具有多样的传感平台，其光谱波段、空间分辨率和传感模式各不相同。虽然大多数现有工作将输入限制在固定传感器上，但最近出现了一类能够处理任意传感器的新型任意传感器基础模型。为贡献于这项工作，我们提出了Panopticon，一个基于DINOv2框架构建的任意传感器基础模型。我们通过以下方式扩展了DINOv2：(1) 将跨传感器的相同地理定位图像视为自然增强；(2) 对通道进行子采样以使光谱输入多样化；(3) 增加一个跨通道的交叉注意力作为灵活的补丁嵌入机制。通过分别编码光学和合成孔径雷达传感器的波长和模式，Panopticon可以有效地处理任意通道的任意组合。在广泛的评估中，我们在GEO-Bench上取得了最先进的性能，尤其是在广泛使用的Sentinel-1和Sentinel-2传感器上，同时在独特的传感器配置上超越了其他任意传感器模型以及领域适应的固定传感器模型。Panopticon能够立即泛化到现有和未来的卫星平台，从而推进了传感器无关的地球观测。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [123] [Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation](https://arxiv.org/abs/2507.23000)
> *规划凉爽城市：一个多模态人工智能框架，通过城市景观转型预测和缓解城市热应力*

*Shengao Yi, Xiaojiang Li, Wei Tu, Tianhong Zhao* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 城市热应力, 深度学习, 多模态AI, 城市规划, 气候适应

**Comment:** 

> **TL;DR:** 本研究提出了GSM-UTCI，一个多模态深度学习框架，用于高分辨率预测和缓解城市热应力，其计算效率远超传统模型，并通过模拟景观转型展示了显著的降温效果。

**AI_Comments:** 该论文的创新点在于提出了一个结合深度学习和多模态数据的框架GSM-UTCI，显著提高了城市热应力预测的效率和可扩展性，同时保持了高精度。其重要性体现在为城市规划者提供了一个实用的工具，能够快速评估不同绿化策略的降温效果，从而有效应对气候变化带来的城市高温挑战。

<details>
  <summary>Details</summary>

**Motivation:** 由于气候变化和城市化导致极端高温事件加剧，城市在缓解室外热应力方面面临日益严峻的挑战。传统物理模型（如SOLWEIG和ENVI-met）虽然能提供详细的人体感知热暴露评估，但其计算需求限制了城市尺度的可扩展性。

**Method:** 本研究提出了GSM-UTCI，一个多模态深度学习框架，用于预测1米超局部分辨率的白天平均通用热气候指数（UTCI）。该模型融合了地表形态（nDSM）、高分辨率土地覆盖数据和每小时气象条件，并使用了特征线性调制（FiLM）架构，该架构根据大气环境动态调节空间特征。模型在SOLWEIG衍生的UTCI地图上进行训练。

**Result:** GSM-UTCI达到了近乎物理的精度，R2为0.9151，平均绝对误差（MAE）为0.41°C，同时将整个城市的推理时间从数小时缩短到五分钟以内。应用于费城模拟景观转型场景，结果显示出空间异质但持续强烈的降温效果，其中不透水面转换为树冠产生了最高的总效益（在270.7平方公里范围内UTCI平均变化-4.18°C）。地块层面双变量分析进一步揭示了热量减少潜力与土地覆盖比例之间的强相关性。

**Conclusion:** 这些发现强调了GSM-UTCI作为一种可扩展、精细化的城市气候适应决策支持工具的实用性，能够对不同城市环境中的绿化策略进行情景评估。

> **ai_Abstract:** 本研究提出了一种名为GSM-UTCI的多模态深度学习框架，旨在解决传统物理模型在城市尺度热应力预测中可扩展性不足的问题。GSM-UTCI能够以1米超局部分辨率预测UTCI，通过融合多种数据源并采用FiLM架构，在保证高精度的同时大幅提升了计算效率。该模型在模拟城市景观转型方面表现出色，特别是不透水面转换为树冠能带来显著的降温效果，为城市管理者提供了高效、精细的气候适应决策支持工具。

> **摘要翻译:** 由于气候变化和城市化导致极端高温事件加剧，城市在缓解室外热应力方面面临日益严峻的挑战。虽然SOLWEIG和ENVI-met等传统物理模型能提供详细的人体感知热暴露评估，但其计算需求限制了城市尺度规划的可扩展性。在本研究中，我们提出了GSM-UTCI，一个多模态深度学习框架，旨在预测1米超局部分辨率的白天平均通用热气候指数（UTCI）。该模型融合了地表形态（nDSM）、高分辨率土地覆盖数据和每小时气象条件，并使用特征线性调制（FiLM）架构，该架构根据大气环境动态调节空间特征。GSM-UTCI在SOLWEIG衍生的UTCI地图上进行训练，实现了近乎物理的精度，R2为0.9151，平均绝对误差（MAE）为0.41°C，同时将整个城市的推理时间从数小时缩短到五分钟以内。为了展示其规划相关性，我们将GSM-UTCI应用于模拟费城的系统性景观转型情景，用树冠取代裸露地面、草地和不透水面。结果显示出空间异质但持续强烈的降温效果，其中不透水面转换为树冠产生了最高的总效益（在270.7平方公里范围内UTCI平均变化-4.18°C）。地块层面双变量分析进一步揭示了热量减少潜力与土地覆盖比例之间的强相关性。这些发现强调了GSM-UTCI作为一种可扩展、精细化的城市气候适应决策支持工具的实用性，能够对不同城市环境中的绿化策略进行情景评估。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [125] [Decision by Supervised Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization](https://arxiv.org/abs/2503.13544)
> *基于深度集成监督学习的决策：稳健投资组合优化的实用框架*

*Juhyeong Kim, Sungyoon Choi, Youngbin Lee, Yejin Kim, Yongmin Choi, Yongjae Lee* | **Category: cs.LG, q-fin.CP, q-fin.PM** | **Updated: 2025-08-01**

**Keywords:** 投资组合优化, 监督学习, 深度集成, 机器学习, 稳健性

**Comment:** 8 pages, 3 figures

> **TL;DR:** DSL是一个通过监督学习和深度集成进行稳健投资组合优化的实用框架，表现优于传统和现有机器学习方法。

**AI_Comments:** 这项研究的创新之处在于将复杂的投资组合优化问题转化为监督学习范式，并巧妙地引入了深度集成方法来增强模型的鲁棒性和稳定性。通过将优化目标（如夏普比率）作为监督信号，而不是直接优化，简化了问题。深度集成的使用有效地解决了单一模型可能存在的过拟合和不稳定性问题，这对于金融应用至关重要。其重要性在于提供了一个在实践中表现出色的框架，尤其是在面对市场波动时能保持稳健性，这对于资产管理领域具有实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决传统投资组合优化方法的不足，并提高投资组合构建的稳定性和可靠性，本文提出了一个实用的框架，旨在通过监督学习和深度集成方法实现稳健的投资组合优化。

**Method:** 本文提出了“基于监督学习的决策”（DSL）框架，将投资组合构建重构为监督学习问题。模型通过交叉熵损失进行训练，以预测最优投资组合权重，其优化目标是最大化夏普比率或索蒂诺比率。为了增强稳定性和可靠性，DSL采用了深度集成方法来显著降低投资组合分配的方差。

**Result:** 通过在不同市场环境和神经网络架构下的全面回测，DSL表现出优于传统策略和包括“预测焦点学习”及“端到端学习”在内的领先机器学习方法的性能。研究表明，增加集成规模可以带来更高的中位数收益和更稳定的风险调整表现。

**Conclusion:** DSL框架通过将投资组合优化重构为监督学习问题并结合深度集成方法，提供了一种实用且性能优越的稳健投资组合优化方案，显著提高了投资组合分配的稳定性和收益表现。

> **ai_Abstract:** 本文提出了一个名为“基于监督学习的决策”（DSL）的实用框架，旨在实现稳健的投资组合优化。DSL将投资组合构建视为一个监督学习问题，通过训练模型预测最优权重，并利用深度集成方法显著降低投资组合分配的方差。全面的回测结果表明，DSL在各种市场条件下均优于传统策略和现有的机器学习方法，并且增加集成规模能提高收益和稳定性。

> **摘要翻译:** 我们提出了基于监督学习的决策（DSL），一个用于稳健投资组合优化的实用框架。DSL将投资组合构建重构为一个监督学习问题：模型通过使用交叉熵损失和通过最大化夏普比率或索蒂诺比率构建的投资组合来训练以预测最优投资组合权重。为了进一步增强稳定性和可靠性，DSL采用了深度集成方法，大幅降低了投资组合分配的方差。通过在不同市场环境和神经网络架构下的全面回测，结果显示DSL相比传统策略和领先的基于机器学习的方法（包括预测焦点学习和端到端学习）表现出卓越的性能。我们证明，增加集成规模可以带来更高的中位数收益和更稳定的风险调整表现。代码可在https://github.com/DSLwDE/DSLwDE获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [126] [Data-driven tool wear prediction in milling, based on a process-integrated single-sensor approach](https://arxiv.org/abs/2412.19950)
> *铣削中基于过程集成单传感器方法的刀具磨损数据驱动预测*

*Eric Hirsch, Christian Friedrich* | **Category: cs.LG, cs.RO, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 刀具磨损预测, 数据驱动, 单传感器, 深度学习, 迁移学习

**Comment:** This work has been submitted to the IEEE Transactions on Automation
  Science and Engineering for possible publication. ,14 pages, 12 figures

> **TL;DR:** 本文提出一种基于单加速度传感器的低成本数据驱动方法，利用深度学习（特别是ConvNeXt）实现铣削中刀具磨损的准确预测，即使在数据量有限的情况下也能实现99.1%的精度，并具有良好的可迁移性。

**AI_Comments:** 本文的创新点在于提出了一个基于单传感器的低成本数据生成方法，并通过迁移学习解决了传统数据驱动方法在工业环境中泛化能力差和多传感器集成不切实际的问题。尤其在数据量受限的情况下，ConvNeXt模型表现出卓越的性能，证明了其在实际应用中的巨大潜力。这对于推动工业4.0背景下的智能制造和预测性维护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 铣削中准确的刀具磨损预测对于保持生产力和最小化成本至关重要。然而，刀具磨损过程的复杂性使得可靠预测面临挑战。传统的基于多传感器和大量数据的预测方法难以推广到新环境且在工业中不实用。

**Method:** 本研究探索了数据驱动方法，特别是深度学习，进行刀具磨损预测。采用单加速度传感器实现低成本数据生成，并通过迁移学习提高模型对其他过程的泛化能力。研究评估了多种机器学习模型，包括ConvNeXt、CNN、LSTM、SVM和决策树，输入格式包括特征向量和短时傅里叶变换（STFT），并在两种机器和不同训练数据量下进行验证。

**Result:** 结果表明特定模型和配置在刀具磨损预测方面的潜力。值得注意的是，ConvNeXt模型表现出色，仅使用四把铣刀的磨损数据就实现了99.1%的刀具磨损识别准确率。

**Conclusion:** 本研究的结果有助于开发更具适应性和效率的铣削预测性维护策略。

> **ai_Abstract:** 本文提出了一种创新的数据驱动方法，利用单个加速度传感器实现铣削过程中的刀具磨损预测。针对传统多传感器设置和大量数据需求的局限性，该研究探索了深度学习（包括ConvNeXt、CNN、LSTM等）在有限训练数据和跨过程迁移学习下的表现。实验结果表明，该方法在低成本单传感器设置下能够实现高精度预测，特别是ConvNeXt模型在极少量数据（四把刀具）下达到了99.1%的准确率，为开发更适应工业环境的预测性维护策略提供了可能。

> **摘要翻译:** 铣削中刀具磨损的数据驱动预测，基于过程集成单传感器方法。
准确的刀具磨损预测对于保持机械加工的生产力和最小化成本至关重要。然而，刀具磨损过程的复杂性给实现可靠预测带来了重大挑战。本研究探索了数据驱动方法，特别是深度学习，用于刀具磨损预测。传统的数据驱动方法通常侧重于单一过程，依赖于多传感器设置和大量数据生成，这限制了其在新环境下的泛化能力。此外，多传感器集成在工业环境中通常不切实际。为了解决这些局限性，本研究探讨了预测模型的可迁移性，使用最少的训练数据，并在两个过程中进行了验证。此外，它采用一个带有单个加速度传感器的简单设置，建立了一种低成本的数据生成方法，通过迁移学习促进模型向其他过程的泛化。本研究评估了几种机器学习模型，包括受Transformer启发的卷积神经网络（CNN）、长短期记忆网络（LSTM）、支持向量机（SVM）和决策树，这些模型在不同输入格式（如特征向量和短时傅里叶变换（STFT））上进行训练。模型的性能在两台机器和不同数量的训练数据上进行了评估，包括数据量显著减少的场景，从而深入了解它们在受限数据条件下的有效性。结果证明了特定模型和配置在有效刀具磨损预测方面的潜力，有助于开发更具适应性和效率的机械加工预测性维护策略。值得注意的是，ConvNeXt模型表现出卓越的性能，仅使用来自四把铣刀（直至磨损）的数据就实现了99.1%的刀具磨损识别准确率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [132] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
> *RecoMind：一个用于优化推荐系统中会话内用户满意度的强化学习框架*

*Mehdi Ben Ayed, Fei Feng, Jay Adams, Vishwakarma Singh, Kritarth Anand, Jiajing Xu* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 推荐系统, 会话优化, 用户满意度, 网络规模

**Comment:** 

> **TL;DR:** 本文介绍了 RecoMind，一个用于优化网络规模推荐系统中会话内用户满意度的强化学习框架，通过离线模拟和在线 A/B 测试表明其性能显著优于监督学习方法。

**AI_Comments:** RecoMind的创新之处在于其将强化学习应用于网络规模推荐系统的实际挑战，特别是通过利用现有模型进行模拟和策略引导，以及自定义探索策略来处理庞大的动作空间。这使得RL方法能够更实际地部署，并优化长期用户满意度，而非仅仅即时反馈。其在真实世界在线A/B测试中的显著效果证明了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有网络规模推荐系统主要采用监督学习方法，侧重于即时用户反馈，而非会话内参与度等长期目标。尽管强化学习（RL）能优化长期目标，但由于动作空间巨大和工程复杂性，将其应用于网络规模推荐系统极具挑战性。

**Method:** RecoMind 是一个基于模拟器的强化学习框架，旨在优化网络规模的会话目标。它利用现有推荐模型建立模拟环境并引导RL策略以优化即时用户交互。该方法与现有行业流程集成良好，并引入了自定义探索策略以有效探索庞大的动作空间。

**Result:** 离线模拟和在线 A/B 测试（在视频流媒体平台上进行）表明，使用 RecoMind 训练的 RL 策略在会话内用户满意度方面显著优于传统监督学习方法。在线 A/B 测试显示，观看超过 10 秒的视频增加了 15.81%，会话深度（对于至少 10 次交互的会话）提高了 4.71%。

**Conclusion:** RecoMind 为将强化学习嵌入到网络规模推荐系统提供了一种系统化和可扩展的方法，在优化基于会话的用户满意度方面展现出巨大潜力。

> **ai_Abstract:** 本文提出了 RecoMind，一个新颖的强化学习框架，旨在优化网络规模推荐系统中的会话内用户满意度。为了解决巨大动作空间和工程复杂性等挑战，RecoMind 利用现有推荐模型进行模拟和策略引导，并与现有行业流程无缝集成。通过广泛的离线模拟和在线 A/B 测试，RecoMind 的强化学习策略在视频流媒体平台上显著优于传统监督学习方法，使观看超过 10 秒的视频增加了 15.81%，会话深度提高了 4.71%。这项工作为将强化学习集成到实际推荐系统提供了可扩展的解决方案。

> **摘要翻译:** 现有的网络规模推荐系统通常使用监督学习方法，优先考虑即时用户反馈。尽管强化学习（RL）为优化长期目标（例如会话内参与度）提供了解决方案，但由于极其庞大的动作空间和工程复杂性，将其应用于网络规模具有挑战性。在本文中，我们介绍了 RecoMind，一个基于模拟器的强化学习框架，旨在有效优化网络规模的基于会话的目标。RecoMind 利用现有推荐模型建立模拟环境并引导强化学习策略，从一开始就优化即时用户交互。这种方法与现有行业流水线良好集成，简化了强化学习策略的训练和部署。此外，RecoMind 引入了一种自定义探索策略，以有效地探索包含数亿个物品的网络规模动作空间。我们通过广泛的离线模拟和在线 A/B 测试在一个视频流媒体平台上评估了 RecoMind。两种方法都表明，使用 RecoMind 训练的强化学习策略在会话内用户满意度方面显著优于传统的监督学习推荐方法。在在线 A/B 测试中，强化学习策略使观看超过 10 秒的视频增加了 15.81%，并将会话深度（对于至少有 10 次交互的会话）提高了 4.71%。因此，RecoMind 提出了一种系统化和可扩展的方法，用于将强化学习嵌入到网络规模推荐系统中，在优化基于会话的用户满意度方面展现出巨大的前景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [133] [Directional Sign Loss: A Topology-Preserving Loss Function that Approximates the Sign of Finite Differences](https://arxiv.org/abs/2504.04202)
> *方向符号损失：一种近似有限差分符号的拓扑保持损失函数*

*Harvey Dam, Tripti Agarwal, Ganesh Gopalakrishnan* | **Category: cs.LG, I.2.6** | **Updated: 2025-07-31**

**Keywords:** 方向符号损失, 拓扑保持, 损失函数, 表示学习, 有限差分

**Comment:** 

> **TL;DR:** 引入了方向符号损失（DSL），这是一种可微分的损失函数，用于在潜在空间中保留拓扑特征，并显示出与传统损失函数结合使用时性能有所提高。

**AI_Comments:** 创新点：引入了一种新颖的可微分损失函数（DSL），解决了表示学习中拓扑保持的长期挑战，由于拓扑度量的不可微分性，这通常是困难的。重要性：通过使拓扑保持适用于基于梯度的优化框架，DSL显著扩展了拓扑方法在深度学习中对更大、更复杂问题的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 在学习到的潜在空间中保留拓扑特征是表示学习中的一个基本挑战，特别是对于拓扑敏感数据。

**Method:** 本文引入了方向符号损失（DSL），这是一种高效、可微分的损失函数，用于近似两个数组对应元素之间有限差分符号不匹配的数量。通过惩罚输入和重建数据之间关键点的差异，DSL鼓励自编码器和其他可学习压缩器保留原始数据的拓扑特征。论文还提供了DSL的公式和复杂性分析，并将其与其他不可微分的拓扑度量进行了比较。

**Result:** 在多维数组数据上的实验表明，将DSL与传统损失函数结合使用比单独使用传统损失函数能更有效地保留拓扑特征。

**Conclusion:** DSL可作为常见基于拓扑度量的一种可微分、高效的替代，从而使得在以前不切实际的问题规模和更广泛的基于梯度的优化框架中实现拓扑特征保留。

> **ai_Abstract:** 本文旨在解决在学习到的潜在空间中保留拓扑特征的挑战，特别是对于拓扑敏感数据。为此，它提出了一种高效、可微分的损失函数——方向符号损失（DSL），该函数近似计算有限差分符号的不匹配数量。DSL通过惩罚输入和重建数据之间关键点的差异，促使自编码器保留原始数据的拓扑特征。论文详细阐述了DSL的公式和复杂性分析，并在多维数组数据上进行了实验，结果表明将DSL与传统损失函数结合使用能更有效地保留拓扑特征。DSL作为一种可微分、高效的拓扑度量替代品，使得在以往不切实际的问题规模和更广泛的基于梯度的优化框架中实现拓扑特征保留成为可能。

> **摘要翻译:** 在学习到的潜在空间中保留拓扑特征是表示学习中的一个基本挑战，特别是对于拓扑敏感数据。本文引入了方向符号损失（DSL），这是一种高效、可微分的损失函数，它近似计算了两个数组对应元素之间有限差分符号不匹配的数量。通过惩罚输入和重建数据之间关键点的差异，DSL鼓励自编码器和其他可学习压缩器保留原始数据的拓扑特征。我们提出了DSL的公式和复杂性分析，并将其与其他不可微分的拓扑度量进行了比较。在多维数组数据上的实验表明，将DSL与传统损失函数结合使用比单独使用传统损失函数能更有效地保留拓扑特征。DSL可作为常见基于拓扑度量的一种可微分、高效的替代，从而使得在以前不切实际的问题规模和更广泛的基于梯度的优化框架中实现拓扑特征保留。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [140] [Adapting to the Unknown: Robust Meta-Learning for Zero-Shot Financial Time Series Forecasting](https://arxiv.org/abs/2504.09664)
> *适应未知：零样本金融时间序列预测的鲁棒元学习*

*Anxian Liu, Junying Ma, Guang Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 零样本预测, 元学习, 金融时间序列, 高斯混合模型, 鲁棒性

**Comment:** 

> **TL;DR:** 提出一种基于GMM的元任务构建方法，用于鲁棒的零样本金融时间序列预测，优于现有方法。

**AI_Comments:** 该论文的创新点在于采用基于GMM的软聚类来构建元任务，生成了更丰富和多样化的任务，并通过硬任务挖掘增强了泛化能力。这对于在高度波动或数据稀缺的金融环境中进行实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 零样本金融时间序列预测对投资决策至关重要，尤其是在市场剧烈波动或新兴市场数据有限的情况下。然而，现有的模型无关元学习（MAML）方法在高度动荡的金融序列中，由于元任务构建策略不佳，表现不佳。

**Method:** 提出一种新颖的任务构建方法，利用学习到的嵌入进行元任务和下游预测。具体来说，使用高斯混合模型（GMM）对嵌入进行软聚类，构建两种互补的元任务类型：簇内任务和簇间任务。此外，通过硬任务挖掘增强簇间泛化。

**Result:** 该方法在实际金融数据（包括高波动时期和多个国际市场数据）上的验证结果表明，其显著优于现有方法，并在零样本场景中表现出更强的泛化能力。

**Conclusion:** 所提出的基于GMM的元任务构建方法有效解决了动荡市场中零样本金融时间序列预测的挑战，提供了卓越的性能和泛化能力。

> **ai_Abstract:** 本文提出了一种新颖的元学习方法，用于鲁棒的零样本金融时间序列预测，旨在解决现有MAML方法在动荡市场中的局限性。该方法利用高斯混合模型（GMM）对学习到的嵌入进行软聚类，创建了簇内和簇间两种互补的元任务类型。这种双重方法结合硬任务挖掘，使模型能够快速适应局部模式并捕获不变的跨序列特征，从而实现更丰富、更多样化的元学习。在实际金融数据上的验证表明，该方法显著优于现有方法，并在零样本场景中展现出更强的泛化能力。

> **摘要翻译:** 零样本设置下的金融时间序列预测对于投资决策至关重要，尤其是在市场体系突然转变或历史数据有限的新兴市场。尽管模型无关元学习（MAML）方法显示出前景，但现有元任务构建策略在高度动荡的金融序列中往往表现不佳。为了解决这个问题，我们提出了一种新颖的任务构建方法，该方法利用学习到的嵌入进行元任务和下游预测，从而实现有效的零样本元学习。具体来说，我们使用高斯混合模型（GMM）对嵌入进行软聚类，构建两种互补的元任务类型：簇内任务和簇间任务。通过概率性地将嵌入分配到多个潜在状态，GMMs 能够实现更丰富、更多样化的元学习。这种双重方法确保模型能够快速适应局部模式，同时捕获不变的跨序列特征。此外，我们通过硬任务挖掘增强了簇间泛化，该方法识别了不同市场体系中的鲁棒模式。我们的方法使用来自高波动时期和多个国际市场（包括新兴市场）的真实金融数据进行了验证。结果表明，该方法显著优于现有方法，并在零样本场景中具有更强的泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [147] [MOSIC: Model-Agnostic Optimal Subgroup Identification with Multi-Constraint for Improved Reliability](https://arxiv.org/abs/2504.20908)
> *MOSIC：一种用于提高可靠性的模型无关多约束最优亚组识别方法*

*Wenxin Chen, Weishen Pan, Kyra Gan, Fei Wang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 亚组识别, 多约束优化, 模型无关, CATE, 临床决策

**Comment:** 

> **TL;DR:** MOSIC提出了一种统一的优化框架，通过将约束问题重新表述为无约束的min-max目标来直接解决亚组识别中的多约束问题，从而在识别高收益亚组的同时更好地满足实际约束。

**AI_Comments:** MOSIC的创新点在于其统一的优化框架，将通常事后应用的实际约束直接整合到优化过程中，解决了现有两步法中约束处理的局脱节问题。其模型无关的特性和可扩展性增强了其实用性，特别是在需要严格满足多重约束（如临床决策）的场景中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的亚组识别方法通常采用两步法，先估计条件平均治疗效果（CATE），然后应用阈值或基于规则的程序来定义亚组。这种解耦方法未能整合现实世界临床决策中必不可少的关键约束，例如亚组大小和倾向重叠。这些约束与CATE估计不在同一维度，现有框架无法自然地容纳它们，从而限制了这些方法的实际应用性。

**Method:** 本文提出了一个统一的优化框架MOSIC，直接解决原始约束优化问题以识别最优亚组。其核心创新是将约束原始问题重新表述为一个无约束的可微分min-max目标，并通过梯度下降-上升算法求解。与将约束作为事后过滤器的基于阈值的CATE方法不同，MOSIC在优化过程中直接强制执行这些约束。该框架是模型无关的，兼容多种CATE估计器，并且可扩展到成本限制或公平性标准等附加约束。

**Result:** 在合成数据集和真实世界数据集上的大量实验表明，MOSIC在识别高收益亚组的同时，能够更好地满足约束条件，展现了其有效性。

**Conclusion:** MOSIC提供了一个统一的、模型无关的优化框架，通过直接在优化过程中整合多重实际约束，克服了现有亚组识别方法的局限性，从而更可靠、更有效地识别出高收益亚组。

> **ai_Abstract:** 本文提出了一种名为MOSIC的模型无关优化框架，旨在解决现有亚组识别方法无法有效整合实际约束（如亚组大小和倾向重叠）的问题。MOSIC通过将约束优化问题重新表述为无约束的可微分min-max目标，并利用梯度下降-上升算法进行求解，实现了在优化过程中直接强制执行多重约束。该框架兼容多种CATE估计器，并可扩展至其他约束。实验证明，MOSIC能有效识别高收益亚组，并更好地满足约束条件，提高了方法的实用性和可靠性。

> **摘要翻译:** 当前亚组识别方法通常遵循两步法：首先估计条件平均治疗效果（CATE），然后应用阈值或基于规则的程序来定义亚组。虽然直观，但这种解耦方法未能整合现实世界临床决策中必不可少的关键约束，例如亚组大小和倾向重叠。这些约束与CATE估计不在根本上不同的轴上操作，并且在现有框架中无法自然地容纳，从而限制了这些方法的实际适用性。我们提出了一个统一的优化框架，直接解决原始约束优化问题以识别最优亚组。我们的关键创新是将约束原始问题重新表述为一个无约束的可微分min-max目标，通过梯度下降-上升算法求解。我们从理论上证明了我们的解决方案收敛到一个可行且局部最优的解决方案。与将约束作为事后过滤器的基于阈值的CATE方法不同，我们的方法在优化过程中直接强制执行它们。该框架是模型无关的，兼容多种CATE估计器，并且可扩展到成本限制或公平性标准等附加约束。在合成数据集和真实世界数据集上的大量实验表明，它在识别高收益亚组的同时，能够更好地满足约束条件。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [154] [Transfer learning-enhanced deep reinforcement learning for aerodynamic airfoil optimisation subject to structural constraints](https://arxiv.org/abs/2505.02634)
> *基于迁移学习增强的深度强化学习在结构约束下气动翼型优化中的应用*

*David Ramos, Lucas Lacasa, Eusebio Valero, Gonzalo Rubio* | **Category: cs.LG, physics.comp-ph** | **Updated: 2025-08-01**

**Keywords:** 深度强化学习, 迁移学习, 翼型优化, 气动, 结构约束

**Comment:** Accepted in Physics of Fluids 20 pages, 7 figures

> **TL;DR:** 本文提出了一种结合迁移学习的深度强化学习方法，用于在考虑结构完整性的同时优化翼型气动性能，并证明其在计算效率和优化效果上优于传统方法。

**AI_Comments:** 本文的创新点在于将迁移学习引入深度强化学习框架，用于解决气动翼型在结构约束下的优化问题，实现了多目标优化。该方法在计算效率和资源节约方面表现出显著优势，为复杂工程优化问题提供了新的高效解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 本文的主要目标是引入一种结合迁移学习的深度强化学习（DRL）方法，该方法能够在兼顾气动和结构完整性标准的情况下优化任何翼型的几何形状。

**Method:** 本文提出了一种迁移学习增强的深度强化学习（DRL）方法。该方法旨在最大化升阻比（$C_L/C_D$），同时通过最大厚度建模来保持翼型的结构完整性。研究中使用了多种不同的迁移学习（TL）策略来训练DRL智能体。此外，将DRL智能体的性能与传统的无梯度优化方法粒子群优化（PSO）进行了比较。

**Result:** 结果表明，DRL智能体能够执行纯气动优化以及气动/结构混合形状优化。在计算效率和气动改进方面，DRL方法优于PSO。迁移学习增强的DRL智能体实现了与标准DRL相当的性能，同时进一步节省了大量的计算资源。

**Conclusion:** 本文提出的迁移学习增强的深度强化学习方法能够有效且高效地在结构约束下进行气动翼型优化，并在计算效率和优化效果上表现出色。

> **ai_Abstract:** 本文介绍了一种结合迁移学习的深度强化学习（DRL）方法，用于在考虑结构完整性的前提下优化翼型气动性能。该方法旨在最大化升阻比，并通过控制最大厚度来保持结构完整性。研究通过与粒子群优化（PSO）的对比，证明了DRL在气动和混合优化上的能力，并在计算效率和优化效果上优于PSO。特别地，迁移学习增强的DRL在保持性能的同时显著节省了计算资源。

> **摘要翻译:** 本文的主要目标是引入一种迁移学习增强的深度强化学习（DRL）方法，该方法能够根据伴随的气动和结构完整性标准优化任何翼型的几何形状。为了展示该方法，我们旨在最大化升阻比$C_L/C_D$，同时保持翼型的结构完整性——通过其最大厚度建模——并使用一系列不同的迁移学习（TL）策略训练DRL智能体。DRL智能体的性能与粒子群优化（PSO）这种传统的无梯度优化方法进行了比较。结果表明，DRL智能体能够执行纯气动和混合气动/结构形状优化，DRL方法在计算效率和气动改进方面优于PSO，并且TL增强的DRL智能体实现了与DRL相当的性能，同时进一步节省了大量的计算资源。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [161] [Latent Diffeomorphic Dynamic Mode Decomposition](https://arxiv.org/abs/2505.06351)
> *潜在微分同胚动态模态分解*

*Willem Diepeveen, Jon Schwenk, Andrea Bertozzi* | **Category: cs.LG, math.DS** | **Updated: 2025-08-01**

**Keywords:** 潜在微分同胚动态模态分解, 非线性系统, 动态模态分解, 循环神经网络, 数据降维

**Comment:** 

> **TL;DR:** LDDMD 结合 DMD 和 RNN 分析非线性系统，实现可解释性和准确预测。

**AI_Comments:** 该论文提出了一种创新的数据降维方法 LDDMD，通过融合传统 DMD 的可解释性与 RNN 的强大预测能力，有效解决了非线性系统分析中的挑战。其在保持简单性的同时实现了对复杂系统建模和准确预测，特别是在径流预测领域的成功应用，展示了其潜在的广泛应用价值。这种结合可解释性和预测能力的思路是当前机器学习领域的重要方向。

<details>
  <summary>Details</summary>

**Motivation:** 为分析非线性系统，需要一种新的数据降维方法，该方法既能保持可解释性又能进行准确预测。

**Method:** 本文提出潜在微分同胚动态模态分解 (LDDMD)，这是一种用于非线性系统分析的新型数据降维方法，它结合了动态模态分解 (DMD) 的可解释性与循环神经网络 (RNN) 的预测能力。

**Result:** LDDMD 保持了简单性，增强了可解释性，同时有效地建模和学习了具有记忆的复杂非线性系统，实现了准确预测。其在径流预测中得到了成功应用。

**Conclusion:** LDDMD 通过结合 DMD 的可解释性和 RNN 的预测能力，提供了一种有效且可解释的方法来分析和预测复杂的非线性系统。

> **ai_Abstract:** 本文提出了一种名为潜在微分同胚动态模态分解 (LDDMD) 的新型数据降维方法，旨在分析非线性系统。LDDMD 创新性地结合了动态模态分解 (DMD) 的可解释性与循环神经网络 (RNN) 的预测能力，在保持方法简单性的同时，能够有效建模和学习复杂的非线性系统并提供准确预测。其有效性已通过在径流预测中的成功应用得到验证。

> **摘要翻译:** 我们提出了潜在微分同胚动态模态分解 (LDDMD)，这是一种用于非线性系统分析的新型数据降维方法，它结合了动态模态分解 (DMD) 的可解释性与循环神经网络 (RNN) 的预测能力。值得注意的是，LDDMD 保持了简单性，这增强了可解释性，同时有效地建模和学习了具有记忆的复杂非线性系统，从而实现了准确的预测。其在径流预测中的成功应用证明了这一点。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [168] [Adaptive Branch Specialization in Spectral-Spatial Graph Neural Networks for Certified Robustness](https://arxiv.org/abs/2505.08320)
> *谱空间图神经网络中自适应分支特化以实现可验证鲁棒性*

*Yoonhyuk Choi, Jiho Choi, Chong-Kwon Kim* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 可验证鲁棒性, 谱空间, 对抗训练, 节点分类

**Comment:** 

> **TL;DR:** SpecSphere是一种新的GNN模型，通过专门的谱和空间分支以及自适应门控网络和对抗性训练，实现了最先进的可验证鲁棒性和节点分类性能。

**AI_Comments:** 该论文的创新之处在于其自适应分支特化和量身定制的对抗训练方案，解决了谱空间GNNs中常被忽视的可验证鲁棒性问题。通过上下文感知门控网络实现的动态路由是一个重要贡献，它通过利用每个特化分支对抗不同类型扰动的优势，实现了更可靠的预测。理论保证进一步巩固了其方法的合理性，实验结果也证实了其在实践中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有结合谱空间架构的图神经网络（GNNs）在可验证鲁棒性方面关注不足，尤其是在训练策略和基本原理方面。

**Method:** 本文提出对谱和空间分支进行特化训练：谱网络用于抵御l0边翻转并捕获同质结构，而空间部分则抵抗linf特征扰动和异质模式。一个上下文感知的门控网络自适应地融合这两种表示，动态路由预测到更可靠的分支。该方法采用分支特定的对抗性训练（结构与特征攻击的内部最大化）和一个统一的对齐目标。

**Result:** 该方法提供了理论保证，包括门控机制超越1-WL的表达能力、谱空间频率偏差以及具有权衡的可验证鲁棒性。实验证明，SpecSphere在真实世界基准上达到了最先进的节点分类精度和更严格的可验证鲁棒性。

**Conclusion:** 通过自适应地特化谱和空间分支并采用新颖的对抗训练方案，所提出的SpecSphere模型显著提高了GNNs的可验证鲁棒性和节点分类性能。

> **ai_Abstract:** 本文介绍了SpecSphere，一种为可验证鲁棒性设计的谱空间图神经网络。它针对谱（l0边翻转、同质性）和空间（linf特征扰动、异质性）分支进行专门训练，并通过门控网络自适应融合。SpecSphere利用分支特定的对抗训练和统一对齐目标，获得了理论保证，并在经验上展现了最先进的节点分类精度和更严格的可验证鲁棒性。

> **摘要翻译:** 最近的图神经网络（GNNs）结合了谱空间架构以增强表示学习。然而，对可验证鲁棒性的关注有限，特别是在训练策略和基本原理方面。在本文中，我们明确地对每个分支进行了特化：谱网络被训练以抵御l0边翻转并捕获同质结构，而空间部分则被设计用于抵抗linf特征扰动和异质模式。一个上下文感知的门控网络自适应地融合这两种表示，动态地将每个节点的预测路由到更可靠的分支。这种专门的对抗训练方案使用分支特定的内部最大化（结构攻击与特征攻击）和一个统一的对齐目标。我们提供了理论保证：（i）门控机制超越1-WL的表达能力，（ii）谱空间频率偏差，以及（iii）具有权衡的可验证鲁棒性。在经验上，SpecSphere在真实世界基准上实现了最先进的节点分类精度，并提供了更严格的可验证鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [172] [SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms](https://arxiv.org/abs/2505.06275)
> *SinBasis 网络：类波光学光谱的矩阵等效特征提取*

*Yuzhou Zhu, Zheng Zhang, Ruyi Zhang, Liang Zhou* | **Category: cs.LG, cs.AI, cs.CV, physics.optics** | **Updated: 2025-07-31**

**Keywords:** Sin-Basis Networks, 类波图像, 特征提取, 正弦映射, 深度学习

**Comment:** 

> **TL;DR:** 提出 SinBasis 网络，通过将卷积和注意力重构为线性变换并引入正弦映射，有效提取类波图像中的谐波结构，提高性能。

**AI_Comments:** 该论文的创新点在于提出了一个统一的矩阵等效框架，并巧妙地通过对权重矩阵应用正弦映射来注入光谱先验知识，从而使网络对周期性图案更加敏感。这种“物理信息驱动”的方法为处理特定类型的数据（类波图像）提供了新的视角和有效的解决方案，提升了模型在数据稀疏条件下的表达能力和稳定性，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的特征提取器难以有效处理类波图像（如光谱、声谱、视频帧）中编码的关键谐波结构。

**Method:** 提出一个统一的、矩阵等效的框架，将卷积和注意力重新解释为扁平化输入上的线性变换，将滤波器权重视为跨越潜在特征子空间的基向量。通过对每个权重矩阵应用逐元素 $\sin(\cdot)$ 映射来注入光谱先验。将这些变换嵌入到 CNN、ViT 和 Capsule 架构中，形成 Sin-Basis 网络。

**Result:** 在各种类波图像数据集上（包括合成的阿秒条纹光谱图、拉曼、光致发光和 FTIR 光谱、AudioSet 的 mel-spectrograms 以及 Kinetics 的循环模式帧）取得了显著的改进。具体表现为重建精度、平移鲁棒性和零样本跨域迁移方面的显著提升。理论分析通过矩阵同构和 Mercer 核截断量化了正弦重参数化如何在数据稀疏条件下丰富表达能力同时保持稳定性。

**Conclusion:** Sin-Basis 网络为所有波形成像模态的深度学习提供了一种轻量级、物理信息驱动的方法。

> **ai_Abstract:** 本论文提出了 Sin-Basis 网络，这是一个针对类波图像（如光谱图、声谱图）的深度学习新框架。该框架将传统的卷积和注意力机制重新解释为线性变换，并将滤波器权重视为基向量。通过对权重矩阵应用逐元素正弦映射，Sin-Basis 网络能够有效地捕捉类波图像中的关键谐波结构，并对空间位移具有内置不变性。实验证明，该网络在重建精度、平移鲁棒性和零样本跨域迁移方面均表现出显著提升，为波形成像模态提供了一种轻量级且物理信息驱动的深度学习方法。

> **摘要翻译:** 类波图像——从阿秒条纹光谱图到光学光谱、音频梅尔频谱图和周期性视频帧——编码了传统特征提取器难以捕捉的关键谐波结构。我们提出了一个统一的、矩阵等效的框架，将卷积和注意力重新解释为扁平化输入上的线性变换，揭示了滤波器权重是跨越潜在特征子空间的基向量。为了注入光谱先验知识，我们对每个权重矩阵应用逐元素 $\sin(\cdot)$ 映射。将这些变换嵌入到 CNN、ViT 和 Capsule 架构中，产生了 Sin-Basis 网络，该网络对周期性图案具有更高的敏感性，并内置了空间位移不变性。在各种类波图像数据集上进行的实验——包括 80,000 张合成阿秒条纹光谱图、数千张拉曼、光致发光和 FTIR 光谱、来自 AudioSet 的梅尔频谱图以及来自 Kinetics 的循环模式帧——证明了在重建精度、平移鲁棒性和零样本跨域迁移方面取得了显著的提升。通过矩阵同构和 Mercer 核截断进行的理论分析量化了正弦重参数化如何在数据稀疏条件下丰富表达能力同时保持稳定性。因此，Sin-Basis 网络为所有波形成像模态的深度学习提供了一种轻量级、物理信息驱动的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [174] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
> *利用Khatri-Rao积实现参数高效微调中更高有效秩*

*Paul Albert, Frederic Z. Zhang, Hemanth Saratchandran, Anton van den Hengel, Ehsan Abbasnejad* | **Category: cs.LG, cs.CL, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 参数高效微调, LoRA, Khatri-Rao积, 有效秩, KRAdapter

**Comment:** To appear in ICCV 2025

> **TL;DR:** LoRA在处理高有效秩矩阵时存在局限性。本文提出KRAdapter，一种利用Khatri-Rao积的参数高效微调（PEFT）算法，旨在实现更高有效秩的权重更新，从而在保持效率的同时提升大型模型性能。

**AI_Comments:** KRAdapter通过引入Khatri-Rao积，巧妙地解决了LoRA在处理高有效秩数据时的固有局限性，这在多模态和大型语言模型中尤为重要。其创新点在于从数学原理上提升了PEFT方法的有效秩，而非简单增加参数量。该方法在保持LoRA高效性的同时，提升了性能，这对于未来大型模型的高效适应具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 参数高效微调（PEFT）方法中的低秩适应（LoRA）在适应大型预训练模型方面取得了显著成功，但近期研究指出其与全秩方法相比存在局限性，尤其是在应用于多模态和大型语言模型时，LoRA难以近似具有相对平坦谱或高频分量的矩阵（即高有效秩的迹象）。

**Method:** 本文首先使用具有受控谱特性的合成矩阵近似基准，对全秩和低秩PEFT方法进行了定量比较。在此基础上，提出了一种名为KRAdapter的新型PEFT算法，该算法利用Khatri-Rao积来生成权重更新，这种构造方式天然倾向于产生具有高有效秩的矩阵乘积。

**Result:** 定量比较结果证实LoRA在近似具有高有效秩（即平坦谱或高频分量）的矩阵时表现不佳。KRAdapter在高达10亿参数的视觉-语言模型和高达80亿参数的大型语言模型上，特别是在未见过的常识推理任务上，展示了性能提升。此外，KRAdapter保持了LoRA的内存和计算效率。

**Conclusion:** KRAdapter是LoRA的一种实用且鲁棒的替代方案，适用于微调十亿级参数模型。它通过利用Khatri-Rao积来生成高有效秩的权重更新，有效解决了LoRA在处理高有效秩任务时的局限性，同时保持了高效性。

> **ai_Abstract:** 本文针对参数高效微调（PEFT）中LoRA方法在处理高有效秩任务时的局限性，引入了一种名为KRAdapter的新型PEFT算法。通过定量比较，作者证实LoRA难以近似具有高有效秩的矩阵。KRAdapter通过利用Khatri-Rao积生成权重更新，这些更新天然具有高有效秩。实验结果表明，KRAdapter在视觉-语言模型和大型语言模型上（尤其是在常识推理任务中）取得了性能提升，同时保持了与LoRA相当的内存和计算效率，证明其是微调大型模型的实用且强大的替代方案。

> **摘要翻译:** 参数高效微调（PEFT）已成为适应大型预训练模型的标准方法。在PEFT方法中，低秩适应（LoRA）取得了显著成功。然而，最近的研究强调了其与全秩替代方案相比的局限性，尤其是在应用于多模态和大型语言模型时。在这项工作中，我们使用具有受控谱特性的合成矩阵近似基准，对全秩和低秩PEFT方法进行了定量比较。我们的结果证实，LoRA难以近似具有相对平坦谱或高频分量的矩阵——这是高有效秩的迹象。为此，我们引入了KRAdapter，一种新颖的PEFT算法，它利用Khatri-Rao积来生成权重更新，通过构造，这种更新倾向于产生具有高有效秩的矩阵乘积。我们证明了KRAdapter在高达10亿参数的视觉-语言模型和高达80亿参数的大型语言模型上，特别是在未见过的常识推理任务上，性能有所提升。此外，KRAdapter保持了LoRA的内存和计算效率，使其成为微调十亿级参数模型的实用且鲁棒的替代方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [175] [Towards Fair In-Context Learning with Tabular Foundation Models](https://arxiv.org/abs/2505.09503)
> *迈向基于表格基础模型的公平上下文学习*

*Patrik Kenfack, Samira Ebrahimi Kahou, Ulrich Aïvodji* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 表格基础模型, 上下文学习, 公平性, 偏见缓解, 样本选择

**Comment:** 30 pages, 12 figures, 5 tables

> **TL;DR:** 本文首次探讨了表格上下文学习中的公平性问题，评估了三种基础模型，并提出了一种基于不确定性的样本选择策略，以在不显著影响准确性的前提下提高公平性。

**AI_Comments:** 本文创新性地将公平性问题引入到新兴的表格上下文学习领域，填补了该领域的一个空白。其提出的基于不确定性的样本选择方法为提升表格基础模型在实际应用中的公平性提供了一个有效且实用的策略，同时兼顾了性能，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** Transformer-based表格基础模型在结构化数据上的上下文学习表现出色，但其公平性影响尚未被充分探索，这是本文研究的动机。

**Method:** 作者首次对表格上下文学习中的公平性进行了调查，评估了TabPFNv2、TabICL和TabDPT这三种基础模型。为了缓解偏见，他们探索了三种预处理的公平性增强方法：相关性移除、组平衡样本选择和基于不确定性的样本选择。

**Result:** 实验表明，基于不确定性的策略能持续改善群体公平性指标（如人口统计学均等、均等化赔率和均等机会），同时对预测准确性的影响最小。

**Conclusion:** 基于不确定性的样本选择是一种有效的方法，可以在表格上下文学习中提高公平性，而不会显著牺牲预测性能。

> **ai_Abstract:** 本文首次深入研究了表格上下文学习（ICL）中的公平性问题，评估了TabPFNv2、TabICL和TabDPT等表格基础模型在公平性方面的表现。为解决偏差问题，作者提出了三种预处理方法，其中基于不确定性的样本选择策略被证明能有效提升人口统计学均等、均等化赔率等群体公平性指标，且对模型预测准确率影响甚微。

> **摘要翻译:** 基于Transformer的表格基础模型最近在结构化数据上展示了有前景的上下文学习（ICL）性能，成为梯度提升树的有力竞争者。然而，这种新范式的公平性影响在很大程度上仍未被探索。本文首次对表格ICL中的公平性进行了调查，评估了TabPFNv2、TabICL和TabDPT这三种近期提出的基础模型在多个基准数据集上的表现。为了缓解偏见，我们探索了三种预处理的公平性增强方法：相关性移除（使输入特征与敏感属性去相关）、组平衡样本选择（确保上下文示例中受保护群体的平等代表性）和基于不确定性的样本选择（优先选择具有高敏感属性预测不确定性的上下文示例）。我们的实验表明，基于不确定性的策略能持续改善群体公平性指标（例如，人口统计学均等、均等化赔率和均等机会），同时对预测准确性的影响最小。我们发布了代码以方便复现（https://github.com/patrikken/Fair-TabICL）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [182] [Rethinking Irregular Time Series Forecasting: A Simple yet Effective Baseline](https://arxiv.org/abs/2505.11250)
> *重新思考不规则时间序列预测：一个简单却有效的基线*

*Xvyuan Liu, Xiangfei Qiu, Xingjian Wu, Zhengyu Li, Chenjuan Guo, Jilin Hu, Bin Yang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 不规则时间序列预测, 时间感知补丁聚合, 数据保真度, 计算效率, APN

**Comment:** 

> **TL;DR:** APN是一个通用且高效的框架，通过新颖的时间感知补丁聚合模块，在不规则多元时间序列预测中实现了最先进的性能，同时保持了数据保真度和计算效率。

**AI_Comments:** APN的创新之处在于其Time-Aware Patch Aggregation (TAPA) 模块，它通过直接聚合原始数据而不是插值或重采样来处理不规则时间序列，这对于保持数据保真度至关重要。其“简单却有效”的理念，通过轻量级查询模块和MLP实现高效预测，为计算资源受限的场景提供了有价值的解决方案。该方法在医疗保健和气候科学等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 不规则多元时间序列（IMTS）预测面临两个主要挑战：1) 数据固有的非均匀性和缺失数据使得时间动态建模复杂化；2) 现有方法通常依赖于计算成本高昂的架构。

**Method:** 论文提出了APN框架，其核心是时间感知补丁聚合（TAPA）模块。TAPA通过学习动态时间边界来定义数据驱动的段，并直接通过所有原始观测值的时间感知加权聚合来计算补丁表示，避免了重采样或插值。这种方法保留了数据保真度并确保了完整的信息覆盖。生成的补丁表示随后被用于轻量级的查询模块进行历史上下文聚合，并使用简单的MLP进行最终预测。

**Result:** 在多个真实世界数据集上的广泛实验表明，APN在预测准确性和计算效率方面均显著优于现有方法，达到了新的最先进水平。

**Conclusion:** APN通过其创新的时间感知补丁聚合方法，成功克服了不规则时间序列预测中的挑战，实现了优异的性能和效率，为该领域提供了一个简单而有效的基线。

> **ai_Abstract:** 该论文提出了APN框架，用于解决不规则多元时间序列（IMTS）预测中的数据非均匀性、缺失数据以及现有方法计算成本高昂的问题。APN的核心是时间感知补丁聚合（TAPA）模块，它通过动态学习时间边界并直接加权聚合原始观测值来创建信息丰富的补丁表示，避免了传统插值或重采样。这种方法保留了数据保真度并提高了效率。实验证明，APN在预测准确性和计算效率上均超越了现有方法，达到了新的最先进水平。

> **摘要翻译:** 不规则多元时间序列（IMTS）的预测是医疗保健和气候科学等领域的关键任务。然而，这项任务面临两个重大障碍：1）IMTS固有的非均匀性和缺失数据使得时间动态建模复杂化；2）现有方法通常依赖于计算成本高昂的架构。为了应对这些双重挑战，我们引入了APN，一个通用且高效的预测框架。APN的核心是一个新颖的时间感知补丁聚合（TAPA）模块，它引入了一种基于聚合的自适应补丁范式，超越了固定跨度分割和基于插值方法的局限性。TAPA首先学习动态时间边界以定义数据驱动的段。至关重要的是，它不是重采样或插值，而是通过对所有原始观测值进行时间感知加权聚合直接计算补丁表示，其中权重由每个观测值与该段的时间相关性决定。这种方法提供了两个关键优势：它通过避免引入人工数据点来保留数据保真度，并通过设计确保了完整的信息覆盖。由此产生的正则化和信息丰富的补丁表示使得可以使用轻量级查询模块进行历史上下文聚合，并使用简单的MLP进行最终预测。在多个真实世界数据集上的广泛实验表明，APN建立了一个新的最先进水平，在预测准确性和计算效率方面均显著优于现有方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [189] [Conformal Predictive Distributions for Order Fulfillment Time Forecasting](https://arxiv.org/abs/2505.17340)
> *订单履约时间预测的共形预测分布*

*Tinghan Ye, Amira Hijazi, Pascal Van Hentenryck* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 订单履约时间预测, 共形预测, 分布预测, 机器学习, 电子商务物流

**Comment:** 

> **TL;DR:** 本文提出了一种基于共形预测系统和交叉维恩-阿伯斯预测器的新型框架，用于预测订单履约时间，该方法在工业数据集上显著优于传统规则系统，并能有效识别延迟交付。

**AI_Comments:** 该论文创新性地将共形预测系统和交叉维恩-阿伯斯预测器应用于订单履约时间预测，提供了具有严格统计保证的分布预测。其模型无关性使其具有广泛的适用性。同时，结合细粒度的时空特征和成本敏感决策规则，有效提升了预测准确性和对延迟交付的识别能力，对实际电子商务物流具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 电子商务物流中准确估计订单履约时间至关重要，但传统基于规则的方法难以捕捉交付操作中的固有不确定性。

**Method:** 本文引入了一个新颖的订单履约时间分布预测框架，利用共形预测系统（Conformal Predictive Systems）和交叉维恩-阿伯斯预测器（Cross Venn-Abers Predictors），这些是模型无关的技术，提供严格的覆盖或有效性保证。所提出的机器学习方法整合了细粒度的时空特征，捕捉履约地点和承运商性能动态以提高预测准确性。此外，还开发了一种成本敏感的决策规则，将概率预测转换为可靠的点预测。

**Result:** 在大型工业数据集上的实验评估表明，所提出的方法生成了具有竞争力的分布预测，而基于机器学习的点预测显著优于现有的基于规则的系统，预测准确率提高了14%，识别延迟交付的准确率提高了75%。

**Conclusion:** 本文提出的基于共形预测系统和交叉维恩-阿伯斯预测器的方法在订单履约时间预测方面表现出色，尤其在点预测方面显著优于传统规则系统，并能有效提高对延迟交付的识别能力。

> **ai_Abstract:** 本文针对电子商务物流中订单履约时间预测的挑战，提出了一种基于共形预测系统和交叉维恩-阿伯斯预测器的新型分布预测框架。该方法整合细粒度的时空特征，并开发了成本敏感的决策规则以生成可靠的点预测。实验结果表明，该方法在分布预测上表现出色，且其点预测显著优于传统规则系统，预测准确率和识别延迟交付的能力均有显著提升。

> **摘要翻译:** 订单履约时间的准确估计对于电子商务物流至关重要，然而传统的基于规则的方法往往无法捕捉交付操作中固有的不确定性。本文引入了一种新颖的订单履约时间分布预测框架，利用共形预测系统和交叉维恩-阿伯斯预测器——这些是模型无关的技术，提供严格的覆盖或有效性保证。所提出的机器学习方法整合了细粒度的时空特征，捕捉履约地点和承运商性能动态以提高预测准确性。此外，还开发了一种成本敏感的决策规则，将概率预测转换为可靠的点预测。在大型工业数据集上的实验评估表明，所提出的方法生成了具有竞争力的分布预测，而基于机器学习的点预测显著优于现有的基于规则的系统——预测准确率提高了14%，识别延迟交付的准确率提高了75%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [195] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
> *将基于性能的抗震设计视为逆向工程问题：迈向使用可解释数据驱动代理模型*

*Mohsen Zaker Esteghamati* | **Category: cs.LG, stat.AP, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 基于性能抗震设计, 逆向工程, 可解释机器学习, 代理模型, 遗传优化

**Comment:** 

> **TL;DR:** 本研究提出了一种利用可解释机器学习模型和遗传优化算法，将基于性能的抗震设计视为逆向工程问题的方法，以提高计算效率并直接推导出设计参数。

**AI_Comments:** 这项研究的创新之处在于将可解释的机器学习模型引入到基于性能的抗震设计中，将其视为一个逆向工程问题。这不仅提高了计算效率，而且通过提供可解释性，增强了设计过程的透明度和可靠性。将机器学习与遗传优化相结合，为结构工程领域提供了一个强大的新工具，有望在实际应用中带来显著的效益。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决基于性能的抗震设计中存在的计算效率低下问题，通过直接推导设计参数以实现特定的性能目标。

**Method:** 该方法通过实施可解释的机器学习模型，直接映射设计变量和性能指标。由此产生的机器学习模型被集成到遗传优化算法中作为评估函数，以解决逆向问题。该方法应用于洛杉矶和查尔斯顿的钢框架和混凝土框架，以获得最小化预期年度地震损失的构件截面特性。

**Result:** 代理模型在不同建筑类型、几何形状、抗震设计和场地危险条件下均表现出高精度（例如R2>90%）。优化算法能够为固定几何变量识别出构件属性的最佳值，且与工程原理一致。

**Conclusion:** 该研究成功地将基于性能的抗震设计转化为逆向工程问题，并通过可解释的机器学习代理模型和遗传优化算法，有效地解决了计算效率问题，并能准确识别出符合工程原理的最优设计参数。

> **ai_Abstract:** 本研究提出了一种将基于性能的抗震设计转化为逆向工程问题的新方法。该方法利用可解释的机器学习模型来直接映射设计变量和性能指标，从而解决了传统基于性能设计中的计算效率问题。研究将训练好的机器学习模型作为评估函数整合到遗传优化算法中，以求解逆向问题。通过在洛杉矶和查尔斯顿的钢结构和混凝土框架上的应用，结果显示代理模型具有高精度，并且优化算法能够识别出与工程原理一致的最优构件属性，从而最小化预期年度地震损失。

> **摘要翻译:** 本研究提出了一种将基于性能的抗震设计视为逆向工程问题的方法，通过该方法可以直接推导出设计参数以实现特定的性能目标。通过实施可解释的机器学习模型，该方法直接映射设计变量和性能指标，解决了基于性能设计的计算效率低下问题。由此产生的机器学习模型被集成到遗传优化算法中作为评估函数，以解决逆向问题。然后，将开发的方法应用于洛杉矶和查尔斯顿的两种不同钢结构和混凝土弯矩框架库存，以获得框架构件的截面特性，从而最大限度地降低以维修成本计的预期年度地震损失。结果表明，代理模型在不同建筑类型、几何形状、抗震设计和场地危险条件下均具有高精度（例如R2>90%），其中优化算法可以识别出固定几何变量下构件属性的最佳值，与工程原理一致。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [196] [How to Evaluate Participant Contributions in Decentralized Federated Learning](https://arxiv.org/abs/2505.23246)
> *如何评估去中心化联邦学习中的参与者贡献*

*Honoka Anada, Tatsuya Kaneko, Shinya Takamaeda-Yamazaki* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 去中心化联邦学习, 参与者贡献, Shapley值, TRIP-Shapley, 贡献评估

**Comment:** 

> **TL;DR:** TRIP-Shapley是一种新颖的去中心化联邦学习（DFL）贡献评估方法，它通过追踪贡献传播来解决现有方法的挑战，并在实验中表现出准确性、可扩展性和鲁棒性。

**AI_Comments:** 该论文的创新之处在于提出了一种针对去中心化联邦学习（DFL）特性的贡献评估方法TRIP-Shapley，解决了传统集中式方法在DFL中面临的模型不可访问和贡献传播追踪难题。其重要性在于为DFL中的激励机制和透明度提供了关键工具，通过轻量级协调和对延迟影响的捕捉，提升了DFL的实用性和可持续性。

<details>
  <summary>Details</summary>

**Motivation:** 在去中心化联邦学习（DFL）中，评估参与者的贡献对于激励积极参与和提高透明度至关重要。然而，现有的联邦学习（FL）贡献评估方法是为集中式设置设计的，无法直接应用于DFL，因为DFL存在客户端无法访问非邻近客户端模型以及需要追踪贡献随时间传播的挑战。

**Method:** 本文提出了TRIP-Shapley，一种用于DFL的新型贡献评估方法。TRIP-Shapley通过追踪轮次本地贡献的传播来量化客户端的整体贡献。这种方法允许一个轻量级协调节点在不收集模型的情况下，仅基于客户端报告的本地可观察贡献来估计整体贡献。

**Result:** 实验表明，TRIP-Shapley足够接近真实Shapley值，可扩展到大规模场景，并且在存在不诚实客户端的情况下仍保持鲁棒性。

**Conclusion:** TRIP-Shapley有效地解决了去中心化联邦学习中参与者贡献评估的挑战，提供了一种准确、可扩展且鲁棒的解决方案，有助于激励参与和提高透明度。

> **ai_Abstract:** 本文提出了一种名为TRIP-Shapley的新型贡献评估方法，专门用于去中心化联邦学习（DFL）。针对现有方法无法适应DFL中无中心服务器、模型不可访问以及贡献传播追踪困难的挑战，TRIP-Shapley通过追踪轮次本地贡献的传播来计算客户端的整体贡献。该方法能够准确反映贡献的延迟和渐进影响，并允许一个轻量级协调节点仅基于本地可观察贡献进行评估，无需收集模型。实验证明TRIP-Shapley接近真实Shapley值，具有良好的可扩展性，并对不诚实客户端表现出鲁棒性。

> **摘要翻译:** 联邦学习（FL）允许多个客户端在不共享本地数据的情况下协同训练机器学习模型。特别是，去中心化联邦学习（DFL）由于客户端无需中央服务器即可交换模型，在缓解通信瓶颈方面受到了关注。在DFL中，评估参与者的贡献对于激励积极参与和提高透明度至关重要。然而，现有的FL贡献评估方法假定集中式设置，由于两个挑战无法直接应用于DFL：每个客户端无法访问非邻近客户端的模型，以及需要追踪贡献如何随着点对点模型交换随时间传播。为了解决这些挑战，我们提出了TRIP-Shapley，一种新颖的DFL贡献评估方法。TRIP-Shapley通过追踪轮次本地贡献的传播来量化客户端的整体贡献。通过这种方式，TRIP-Shapley准确反映了延迟和渐进的影响传播，并且允许一个轻量级协调节点在不收集模型的情况下，仅基于每个客户端报告的本地可观察贡献来估计整体贡献。实验表明，TRIP-Shapley足够接近真实Shapley值，可扩展到大规模场景，并且在存在不诚实客户端的情况下仍保持鲁棒性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [204] [EVINET: Towards Open-World Graph Learning via Evidential Reasoning Network](https://arxiv.org/abs/2506.07288)
> *EVINET：迈向开放世界图学习的证据推理网络*

*Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 开放世界图学习, 证据推理网络, 误分类检测, 分布外检测, 不确定性估计

**Comment:** KDD 2025

> **TL;DR:** EVINET是一个基于证据推理的网络，通过集成Beta嵌入和主观逻辑框架，解决了开放世界图学习中的误分类检测和分布外检测问题，并取得了SOTA性能。

**AI_Comments:** EVINET的创新之处在于将证据推理和主观逻辑引入图学习，特别是在处理开放世界场景下的不确定性。通过区分误分类和分布外情况，它提高了模型的鲁棒性和可靠性，为图学习在真实世界的应用提供了新的视角。其明确区分两种不确定性来源的设计是其亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图学习方法通常在封闭世界假设下进行研究，即所有可能的数据标签都是先验已知的。然而，在开放和嘈杂的环境中，需要告知模型用户何时模型对已知类别的分布内数据做出错误预测（误分类检测），以及何时模型遇到来自新类别的分布外数据（分布外检测）。

**Method:** 本文提出了证据推理网络（EVINET），一个通过在主观逻辑框架内集成Beta嵌入来解决误分类检测和分布外检测这两个挑战的框架。EVINET包含两个关键模块：用于误分类检测的“不和谐推理”（Dissonance Reasoning）和用于分布外检测的“空缺推理”（Vacuity Reasoning）。

**Result:** 广泛的实验表明，EVINET在分布内分类、误分类检测和分布外检测任务中，在多项指标上优于最先进的方法。

**Conclusion:** EVINET证明了不确定性估计和逻辑推理对于误分类检测和分布外检测的必要性，并为开放世界图学习铺平了道路。

> **ai_Abstract:** 本文提出了EVINET，一个针对开放世界图学习的证据推理网络。它通过结合Beta嵌入和主观逻辑框架，解决了传统图学习中封闭世界假设的局限性，特别是在误分类检测和分布外检测方面的挑战。EVINET包含不和谐推理和空缺推理模块，并在实验中表现出优于现有方法的性能，强调了不确定性估计和逻辑推理在开放世界图学习中的重要性。

> **摘要翻译:** 图学习在许多现实世界任务中至关重要，但它们通常在封闭世界假设下进行研究，即所有可能的数据标签都是先验已知的。为了在开放和嘈杂的环境中实现有效的图学习，关键在于当模型对已知类别的分布内数据做出错误预测时（即误分类检测），或者当模型遇到来自新类别的分布外数据时（即分布外检测），告知模型用户。本文介绍了证据推理网络（EVINET），这是一个通过在主观逻辑框架内集成Beta嵌入来解决这两个挑战的框架。EVINET包括两个关键模块：用于误分类检测的“不和谐推理”和用于分布外检测的“空缺推理”。广泛的实验表明，EVINET在分布内分类、误分类检测和分布外检测任务中，在多项指标上优于最先进的方法。EVINET证明了不确定性估计和逻辑推理对于误分类检测和分布外检测的必要性，并为开放世界图学习铺平了道路。我们的代码和数据可在https://github.com/SSSKJ/EviNET获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [209] [Flow Matching Policy Gradients](https://arxiv.org/abs/2507.21053)
> *流匹配策略梯度*

*David McAllister, Songwei Ge, Brent Yi, Chung Min Kim, Ethan Weber, Hongsuk Choi, Haiwen Feng, Angjoo Kanazawa* | **Category: cs.LG, cs.RO** | **Updated: 2025-08-01**

**Keywords:** 流匹配, 策略梯度, 强化学习, 扩散模型, 流策略优化

**Comment:** See our blog post at https://flowreinforce.github.io

> **TL;DR:** 本文提出了流策略优化（FPO），一种将流匹配技术融入策略梯度框架的在策略强化学习算法。FPO能够训练扩散式策略，捕获多模态动作分布，并在连续控制任务中表现优于传统高斯策略。

**AI_Comments:** 这项工作创新性地将流匹配技术引入强化学习的策略梯度框架，解决了传统方法中精确似然计算的挑战，并提高了策略对复杂、多模态动作分布的建模能力。其与采样方法无关的特性也增强了算法的通用性和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 流基生成模型在建模高维连续分布方面表现出色，但将其应用于强化学习（RL）的策略优化需要一种新方法，该方法应能避免精确似然计算并保持生成能力。

**Method:** 本文引入了流策略优化（FPO），这是一种简单的在策略强化学习算法，它将流匹配技术引入策略梯度框架。FPO通过最大化从条件流匹配损失计算出的优势加权比率来进行策略优化，并与流行的PPO-clip框架兼容。该方法避免了对精确似然计算的需求，同时保留了流基模型的生成能力，并且在训练和推理时都与扩散或流积分的选择无关。

**Result:** FPO 能够在各种连续控制任务中从头开始训练扩散式策略。研究发现，基于流的模型可以捕获多模态动作分布，并比高斯策略实现更高的性能，尤其是在欠条件设置下。

**Conclusion:** 流匹配策略梯度方法（FPO）提供了一种有效且灵活的方式，将流基生成模型应用于强化学习中的策略优化，能够成功处理复杂的、多模态的动作分布并提升性能。

> **ai_Abstract:** 本文提出了流策略优化（FPO），一种创新的在策略强化学习算法，将流匹配技术整合到策略梯度框架中。FPO通过最大化基于条件流匹配损失的优势加权比率来优化策略，兼容PPO-clip，并解决了精确似然计算的难题。该方法在训练和推理时对扩散或流积分方法保持无关性，使其具有高度灵活性。实验证明，FPO能够从零开始训练扩散型策略，有效捕获多模态动作分布，并在连续控制任务中，尤其是在欠条件环境下，表现优于传统高斯策略。

> **摘要翻译:** 流基生成模型，包括扩散模型，在建模高维空间中的连续分布方面表现出色。在这项工作中，我们引入了流策略优化（FPO），这是一种简单的在策略强化学习算法，它将流匹配引入策略梯度框架。FPO将策略优化转化为最大化从条件流匹配损失计算出的优势加权比率，其方式与流行的PPO-clip框架兼容。它避免了精确似然计算的需求，同时保留了流基模型的生成能力。与之前将训练绑定到特定采样方法的基于扩散的强化学习方法不同，FPO在训练和推理时都与扩散或流积分的选择无关。我们表明FPO可以在各种连续控制任务中从头开始训练扩散式策略。我们发现基于流的模型可以捕获多模态动作分布，并比高斯策略实现更高的性能，特别是在欠条件设置下。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [210] [Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices](https://arxiv.org/abs/2506.20644)
> *面向数据异构边缘设备的加密数据共享高效联邦学习*

*Hangyu Li, Hongyue Wu, Guodong Fan, Zhen Zhang, Shizhan Chen, Zhiyong Feng* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 联邦学习, 加密数据共享, 数据异构, 边缘设备, 收敛速度

**Comment:** Accepted by ICWS 2025

> **TL;DR:** FedEDS通过加密数据共享，解决边缘设备联邦学习中的数据异构问题，加速收敛并提升模型性能。

**AI_Comments:** FedEDS的创新点在于引入了加密数据共享机制，这在联邦学习中通常是为了保护隐私，但本文将其用于加速收敛和缓解数据异构，是一个有趣且实用的结合点。该方法通过局部数据和加密共享数据结合训练，可能有效利用了异构数据的信息，同时兼顾了隐私和效率。

<details>
  <summary>Details</summary>

**Motivation:** 当前联邦学习研究忽视了网络拓扑、物理距离和数据异构对边缘设备的影响，导致延迟增加和模型性能下降。

**Method:** 提出FedEDS方案，利用客户端模型和随机层训练数据加密器，生成加密数据并与其他客户端共享。客户端结合本地私有数据和加密共享数据训练和调整本地模型。

**Result:** FedEDS加速了联邦学习训练的收敛速度，减轻了数据异构的负面影响，并有效提升了模型性能。

**Conclusion:** FedEDS是一种有效的联邦学习方案，能够解决边缘设备数据异构问题，加速收敛并提升模型性能，适用于需要快速收敛的边缘应用服务。

> **ai_Abstract:** 本文提出一种名为FedEDS的联邦学习方案，旨在解决边缘设备上联邦学习中因网络拓扑、物理距离和数据异构导致的高延迟和性能下降问题。FedEDS通过训练数据加密器生成并共享加密数据，使客户端能够利用本地私有数据和加密共享数据进行模型训练。实验证明，FedEDS能有效加速联邦学习收敛，缓解数据异构影响，并提升模型性能，特别适用于需要快速收敛的边缘应用。

> **摘要翻译:** 随着隐私保护日益重要，越来越多的模型在边缘设备上进行训练，并通过联邦学习（FL）合并到中央服务器。然而，当前研究忽视了网络拓扑、物理距离和数据异构对边缘设备的影响，导致延迟增加和模型性能下降等问题。为解决这些问题，我们提出了一种新的边缘设备联邦学习方案，称为带加密数据共享的联邦学习（FedEDS）。FedEDS利用客户端模型和模型的随机层训练数据加密器。数据加密器生成加密数据并与其它客户端共享。客户端使用相应客户端的随机层和加密数据来训练和调整本地模型。FedEDS使用客户端的本地私有数据和来自其它客户端的加密共享数据来训练模型。这种方法加速了联邦学习训练的收敛速度，并减轻了数据异构的负面影响，使其适用于需要快速收敛的边缘设备部署应用服务。实验结果表明FedEDS在提升模型性能方面的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [216] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
> *校准语言模型及其使用标签平滑的寻找方法*

*Jerry Huang, Peng Lu, Qiuhao Zeng* | **Category: cs.LG, cs.AI, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 校准, 标签平滑, 指令微调, 内存优化

**Comment:** Accepted to the Forty-second International Conference on Machine
  Learning (ICML) 2025. First two authors contributed equally

> **TL;DR:** 本文研究了指令微调后大型语言模型的校准退化问题，并提出标签平滑作为一种有效的解决方案，同时解决了其在大型词汇模型中的局限性及内存效率问题。

**AI_Comments:** 这篇论文的创新点在于系统地研究了指令微调对LLM校准的影响，并首次深入探讨了标签平滑在LLM监督微调中的应用及其局限性。特别值得关注的是，它不仅理论上解释了大型词汇LLM中标签平滑效果不佳的原因，还提出了一个实用的定制内核来优化内存效率，这对于LLM的实际部署具有重要意义。该研究对于提升LLM的可靠性和实用性具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管指令微调提升了大型语言模型的交互能力，但其对置信度校准的影响尚未得到充分研究。研究发现指令微调会导致显著的校准退化，因此需要寻找一种实用的解决方案来维持模型输出的可靠性。

**Method:** 研究检查了各种开源大型语言模型，以识别指令微调后的校准退化。提出并深入探讨了标签平滑作为一种正则化方法，以解决过自信预测问题，并解释了其在SFT过程中保持校准的有效性。针对大型词汇LLM中标签平滑效果减弱的问题，从理论和实验上分析了其原因。最后，设计了一个定制内核以显著减少标签平滑损失计算中的内存消耗。

**Result:** 发现指令微调后，所有被检查的开源大型语言模型都存在显著的校准退化。证明了标签平滑足以在SFT过程中保持校准。指出在大型词汇LLM中标签平滑的有效性会严重降低，并将其原因归结为与隐藏层大小和词汇量直接相关的过自信能力。设计了一个定制内核，显著降低了标签平滑损失计算的内存消耗，且不牺牲速度或性能。

**Conclusion:** 指令微调会导致大型语言模型的校准退化，而标签平滑是解决这一问题的有效方法。尽管在大型词汇模型中存在局限性，但通过理解其根本原因并优化计算方法，可以提高其适用性。该工作为提高大型语言模型输出的可靠性提供了实用见解和技术方案。

> **ai_Abstract:** 本文探讨了大型语言模型在指令微调后出现的置信度校准退化问题。研究发现标签平滑是一种有效的校准保持方法，但在大型词汇模型中其效果会减弱，原因在于模型过自信能力与隐藏层和词汇量有关。为解决标签平滑损失计算中的内存效率问题，文章还提出了一种定制的计算内核，显著降低了内存消耗，同时保持了性能。

> **摘要翻译:** 自然语言处理（NLP）的最新进展为通过改进指令遵循能力，使微调后的大型语言模型（LLM）成为更强大的交互式代理提供了更大的机会。然而，理解这如何影响置信度校准以实现可靠的模型输出尚未得到充分研究。在这项工作中，我们检查了各种开源LLM，发现指令微调后它们都存在显著的校准退化。为了寻找一个实用的解决方案，我们转向标签平滑，它已被证明是一种有效的方法来正则化过自信的预测，但在LLM的监督微调（SFT）中尚未被广泛采用。我们首先深入探讨了为什么标签平滑足以在整个SFT过程中保持校准。然而，在某些情况下，平滑的有效性会严重降低，特别是对于大型词汇LLM（LV-LLM）。我们认为其原因源于模型变得过自信的能力，这与隐藏层大小和词汇量有直接关系，并从理论和实验上证明了这一点。最后，我们解决了标签平滑损失设置中交叉熵损失计算的内存占用问题，设计了一个定制内核，与现有非平滑损失解决方案相比，在不牺牲速度或性能的情况下显著减少了内存消耗。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [217] [OmniDraft: A Cross-vocabulary, Online Adaptive Drafter for On-device Speculative Decoding](https://arxiv.org/abs/2507.02659)
> *OmniDraft：一种用于设备端推测解码的跨词汇、在线自适应草稿器*

*Ramchalam Kinattinkara Ramakrishnan, Zhaocong Yuan, Shaojie Zhuo, Chen Feng, Yicheng Lin, Chenzheng Su, Xiaopeng Zhang* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 推测解码, 设备端LLM, 在线适应, 跨词汇, OmniDraft

**Comment:** 

> **TL;DR:** OmniDraft是一个通用的草稿模型框架，能与任何目标模型配合，并在线适应用户数据，提高设备端推测解码速度。

**AI_Comments:** OmniDraft的创新在于提出了一个“一个草稿器适用于所有”的通用框架，解决了推测解码在设备端部署时的核心兼容性和效率问题。其结合在线n-gram缓存和混合蒸馏微调的方法是新颖的，能够动态适应不同目标模型和用户数据，这对于资源受限的设备端LLM应用具有重要意义。速度提升和跨模型兼容性是其主要亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有推测解码的草稿模型存在与目标模型不兼容以及无法在线适应以提高延迟的挑战。本文旨在解决这些问题，实现“一个草稿器适用于所有”的范式，特别适用于对模型成本、效率和用户定制有高要求的设备端LLM应用。

**Method:** 本文提出了OmniDraft框架，通过引入在线n-gram缓存与混合蒸馏微调相结合的方式，解决草稿模型和目标模型之间的跨词汇不匹配问题；并通过利用自适应草稿技术进一步提高解码速度。

**Result:** OmniDraft在数学推理、编码和文本生成任务上展示了在线学习能力。它使单个Llama-68M模型能够与Vicuna-7B、Qwen2-7B和Llama3-8B等各种目标模型配对进行推测解码，并提供了高达1.5-2倍的速度提升。

**Conclusion:** OmniDraft框架通过解决跨词汇兼容性和在线适应性问题，实现了“一个草稿器适用于所有”的范式，特别适用于对模型成本、效率和用户定制有高要求的设备端LLM应用。

> **ai_Abstract:** OmniDraft是一个针对设备端推测解码的通用框架，旨在解决现有草稿模型与目标模型不兼容以及在线适应性差的问题。它通过在线n-gram缓存和混合蒸馏微调处理跨词汇不匹配，并利用自适应草稿技术加速解码。实验表明，OmniDraft能使小型草稿模型与多种大型目标模型兼容，并在多项任务上实现显著的速度提升，特别适用于对成本、效率和定制化有要求的设备端LLM应用。

> **摘要翻译:** 推测解码通常要求有一个小而高效的草稿模型，该模型要么是预训练的，要么是离线蒸馏到特定的目标模型系列，例如Llama或Qwen模型。然而，在在线部署设置中存在两个主要挑战：1）使用与草稿模型不兼容的目标模型；2）期望随着使用和时间的推移提高延迟。在这项工作中，我们提出了OmniDraft，一个统一的框架，使单个草稿模型能够与任何目标模型操作并动态适应用户数据。我们引入了一个在线n-gram缓存与混合蒸馏微调相结合，以解决草稿模型和目标模型之间的跨词汇不匹配问题；并通过利用自适应草稿技术进一步提高解码速度。OmniDraft特别适用于设备端LLM应用，其中模型成本、效率和用户定制是主要的争论点。这进一步强调了解决上述挑战的需求，并促使了“一个草稿器适用于所有”的范式。我们通过在数学推理、编码和文本生成任务上进行在线学习，展示了OmniDraft框架的熟练程度。值得注意的是，OmniDraft使单个Llama-68M模型能够与包括Vicuna-7B、Qwen2-7B和Llama3-8B模型在内的各种目标模型配对进行推测解码；此外还提供了高达1.5-2倍的速度提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms](https://arxiv.org/abs/2507.02724)
> *跨生物体蛋白质-蛋白质相互作用预测的层次多标签对比学习*

*Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu* | **Category: cs.LG, q-bio.BM** | **Updated: 2025-08-01**

**Keywords:** 蛋白质-蛋白质相互作用, 对比学习, 层次结构, 跨物种预测, 零样本学习

**Comment:** 

> **TL;DR:** 本文提出了HIPPO，一个用于跨生物体蛋白质-蛋白质相互作用（PPI）预测的层次对比学习框架，通过多层生物表示匹配和层次对比损失，实现了最先进的性能，并在低数据量和零样本迁移场景中表现出色。

**AI_Comments:** HIPPO的创新之处在于其层次对比学习框架，它不仅利用了对比学习的优势，还通过模拟蛋白质功能层次结构和自适应融合领域知识，显著提升了跨生物体PPI预测的准确性和泛化能力。其在低数据量和零样本迁移方面的表现尤其突出，为生物学研究中数据稀疏的挑战提供了有力的解决方案，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 当前的AI科学进展强调了对比学习在连接异构生物数据模态方面的潜力。本文旨在利用这一范式，解决蛋白质-蛋白质相互作用（PPI）预测的挑战，特别是在跨生物体、数据稀疏或不平衡的场景中。

**Method:** 本文提出了HIPPO（Hierarchical Protein-Protein interaction prediction across Organisms），一个层次对比学习框架，用于蛋白质-蛋白质相互作用（PPI）预测。该方法通过多层生物表示匹配来对齐蛋白质序列及其层次属性。它结合了模拟蛋白质功能类别之间结构化关系的层次对比损失函数，并通过数据驱动的惩罚机制自适应地融合域和家族知识，以确保学习到的嵌入空间与蛋白质功能的内在层次结构一致。

**Result:** 实验表明，HIPPO在基准数据集上取得了最先进的性能，优于现有方法，并在低数据量情况下表现出鲁棒性。值得注意的是，该模型无需重新训练即可对其他物种表现出强大的零样本迁移能力，即使在实验数据有限的特征较少或稀有生物体中，也能实现可靠的PPI预测和功能推断。进一步分析表明，层次特征融合对于捕获保守的相互作用决定因素（如结合基序和功能注释）至关重要。

**Conclusion:** 这项工作推动了跨物种PPI预测的进展，并为数据稀疏或不平衡的多物种场景中的相互作用预测提供了一个统一的框架。

> **ai_Abstract:** 本文提出了HIPPO，一个新颖的层次对比学习框架，用于跨生物体蛋白质-蛋白质相互作用（PPI）预测。该框架通过多层表示匹配和层次对比损失，将蛋白质序列及其属性对齐，并自适应整合领域知识。实验证明，HIPPO在基准测试中达到了最先进的性能，在数据稀缺环境下表现稳健，并具有出色的零样本跨物种迁移能力，为稀有生物体的PPI预测提供了可靠手段。研究强调了层次特征融合对捕获保守相互作用决定因素的重要性。

> **摘要翻译:** AI科学的最新进展突出了对比学习在连接异构生物数据模态方面的强大能力。在此范式基础上，我们提出了HIPPO（Hierarchical Protein-Protein interaction prediction across Organisms），一个用于蛋白质-蛋白质相互作用（PPI）预测的层次对比框架，其中通过多层生物表示匹配来对齐蛋白质序列及其层次属性。所提出的方法结合了层次对比损失函数，该函数模拟了蛋白质功能类别之间的结构化关系。该框架通过数据驱动的惩罚机制自适应地整合域和家族知识，强制学习到的嵌入空间与蛋白质功能的内在层次结构保持一致。在基准数据集上的实验表明，HIPPO取得了最先进的性能，优于现有方法，并在低数据量情况下表现出鲁棒性。值得注意的是，该模型无需重新训练即可对其他物种表现出强大的零样本迁移能力，即使在实验数据有限的特征较少或稀有生物体中，也能实现可靠的PPI预测和功能推断。进一步分析表明，层次特征融合对于捕获保守的相互作用决定因素（如结合基序和功能注释）至关重要。这项工作推动了跨物种PPI预测的进展，并为数据稀疏或不平衡的多物种场景中的相互作用预测提供了一个统一的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [231] [Evaluating LLMs on Real-World Forecasting Against Human Superforecasters](https://arxiv.org/abs/2507.04562)
> *评估大型语言模型在真实世界预测中与人类超级预测员的表现*

*Janna Lu* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 预测, 超级预测员, Metaculus, 布莱尔分数

**Comment:** 

> **TL;DR:** 大型语言模型在真实世界预测中表现出比普通人群更好的能力，但仍显著逊于人类超级预测员。

**AI_Comments:** 这项研究通过将LLMs的预测能力与人类超级预测员进行对比，提供了一个重要的基准。结果表明，尽管LLMs取得了显著进步，但它们在复杂、真实世界的预测任务中仍未能超越顶尖的人类专家，这为未来LLMs在预测领域的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在各种任务中展现出卓越能力，但其预测未来事件的能力仍未得到充分研究。一年前，LLMs在准确性上远不及人类群体。因此，本文旨在评估当前最先进的LLMs在预测任务上的表现。

**Method:** 作者在来自Metaculus的464个预测问题上评估了最先进的LLMs，并将其表现与人类超级预测员进行了比较。

**Result:** 前沿LLMs的布莱尔分数表面上超越了人类群体，但仍显著低于一组超级预测员的表现。

**Conclusion:** 大型语言模型在真实世界预测任务上取得了进步，能够超越普通人群，但尚未达到人类超级预测员的水平。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在真实世界预测任务中的表现，将其与人类超级预测员进行比较。通过在Metaculus的464个问题上测试，发现尽管前沿LLMs在布莱尔分数上超越了普通人类群体，但其表现仍显著逊于专业的超级预测员。这表明LLMs在预测能力上有所提升，但与顶尖人类专家仍有差距。

> **摘要翻译:** 大型语言模型（LLMs）在各种任务中展现出卓越的能力，但其预测未来事件的能力仍未得到充分研究。一年前，大型语言模型在准确性上远不及人类群体。我评估了最先进的LLMs在来自Metaculus的464个预测问题上的表现，并将其表现与人类超级预测员进行了比较。前沿模型取得了表面上超越人类群体的布莱尔分数，但仍显著低于一组超级预测员的表现。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [238] [EmissionNet: Air Quality Pollution Forecasting for Agriculture](https://arxiv.org/abs/2507.05416)
> *EmissionNet：农业空气质量污染预测*

*Prady Saligram, Tanvir Bhathal* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 空气质量预测, 农业排放, 深度学习, EmissionNet, Transformer

**Comment:** The appendix figures are mixed up - several emission plots (e.g. CO2,
  CH4, GWP) are mislabeled and appear in the wrong order, leading to confusion
  in interpreting the results

> **TL;DR:** 本文提出了两种新颖的深度学习架构EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，用于预测农业排放的N2O空气污染，旨在克服传统物理模型在处理复杂非线性污染物相互作用方面的局限性。

**AI_Comments:** 该论文创新性地将深度学习应用于农业空气污染预测，特别是引入了Transformer架构来处理时空依赖性，这可能为该领域的复杂非线性问题提供更准确的解决方案。其重要性在于解决了传统物理模型的局限性，并有望为环境保护和公共健康提供更好的预测工具。抽象中未提及模型的具体性能评估结果，这可能是其局限性。

<details>
  <summary>Details</summary>

**Motivation:** 农业排放造成的空气污染是一个重要但常被忽视的环境和公共健康问题。传统的空气质量预测模型依赖于基于物理的方法，但难以捕捉复杂的非线性污染物相互作用。

**Method:** 通过评估流行的架构，并提出了两种新颖的深度学习架构：EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)。这些模型利用卷积和基于Transformer的架构从高分辨率排放数据中提取时空依赖性，用于预测N2O农业排放。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究针对农业排放造成的空气污染问题，指出传统物理模型难以处理复杂的污染物相互作用。为此，论文提出了两种新颖的深度学习架构EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，它们结合了卷积和Transformer技术，旨在从高分辨率排放数据中有效提取时空依赖性，以预测N2O农业排放。

> **摘要翻译:** 农业排放造成的空气污染是一个重要但常被忽视的环境和公共健康挑战。传统的空气质量预测模型依赖于基于物理的方法，这些方法难以捕捉复杂的非线性污染物相互作用。在这项工作中，我们通过评估流行的架构，并提出了两种新颖的深度学习架构，EmissionNet (ENV) 和 EmissionNet-Transformer (ENT)，来探索预测N2O农业排放。这些模型利用卷积和基于Transformer的架构从高分辨率排放数据中提取时空依赖性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [241] [Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation](https://arxiv.org/abs/2507.23344)
> *采用可微分智能体仿真设计共享单车系统的动态定价*

*Tatsuya Mitomi, Fumiyasu Makinoshima, Fumiya Makihara, Eigo Segawa* | **Category: cs.LG, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 共享单车, 动态定价, 可微分仿真, 智能体, 库存平衡

**Comment:** 

> **TL;DR:** 本文提出一种可微分智能体仿真方法，用于快速设计共享单车系统的动态定价策略，有效解决库存不平衡问题，并显著提高求解速度和准确性。

**AI_Comments:** 该论文的创新点在于引入了“可微分智能体仿真”来解决共享单车动态定价这一复杂问题，成功地将系统中的用户概率性选择和时空异质性纳入考量。其重要性体现在显著提高了定价策略的求解效率和准确性，并能实现库存的自动平衡，从而降低运营成本，提升用户体验。这对于优化共享经济平台运营具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 共享单车系统中，时空变化的用户需求导致站点库存不平衡，产生额外的调配成本。由于用户背景多样且选择具有概率性，设计最优动态定价来管理用户需求具有挑战性。

**Method:** 本文开发了一种可微分智能体仿真方法，旨在快速设计共享单车系统的动态定价策略，以实现在时空异质出行和概率性用户决策下的自行车库存平衡。

**Result:** 1. 在25个站点的实验中，相比传统方法，新方法在损失上减少了73%至78%，收敛速度提高了100倍以上，获得了更准确的解决方案。2. 在289个站点的大规模城市共享单车系统场景中，获得的定价策略可以自然地实现库存平衡，无需人工调配。3. 通过设置合适的初始条件，可以最小化为实现库存平衡而产生的折扣成本。

**Conclusion:** 本文提出的可微分智能体仿真方法能够有效、快速地为共享单车系统设计动态定价策略，从而在没有人工调配的情况下自然地平衡库存，并能最小化相关成本。

> **ai_Abstract:** 本研究提出了一种基于可微分智能体仿真的动态定价设计方法，旨在解决共享单车系统中因用户需求时空变化导致的库存不平衡及高昂的调配成本问题。该方法能够快速生成有效的定价策略，以管理用户需求并实现自行车库存的自动平衡，避免人工调配。实验结果表明，与传统方法相比，该方法在收敛速度和解决方案准确性方面均有显著提升，并且在大规模场景下也能有效运行，同时能通过优化初始条件来最小化折扣成本。

> **摘要翻译:** 共享单车系统作为一种新型环保交通系统正在各个城市兴起。在这些系统中，时空变化的用户需求导致自行车站点库存不平衡，从而产生额外的调配成本。因此，通过最优动态定价来管理用户需求对系统至关重要。然而，为此类系统设计最优定价具有挑战性，因为系统涉及背景多样且选择具有概率性的用户。为了解决这个问题，我们开发了一种可微分智能体仿真，以快速设计共享单车系统中的动态定价，尽管存在时空异质的出行和概率性用户决策，仍能实现平衡的自行车库存。我们首先通过涉及25个自行车站点和五个时间段的数值实验验证了我们的方法，产生了100个参数。与传统方法相比，我们的方法获得了更准确的解决方案，损失减少了73%到78%，同时收敛速度提高了100倍以上。我们进一步在一个涉及289个自行车站点的、大规模城市共享单车系统场景中验证了我们的方法，总共产生了1156个参数。通过使用获得的定价策略进行仿真，我们证实这些策略可以自然地实现库存平衡，无需任何人工调配。此外，我们发现通过设置适当的初始条件，可以最小化为实现库存平衡而产生的折扣成本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [242] [Recursive Learning-Based Virtual Buffering for Analytical Global Placement](https://arxiv.org/abs/2506.17247)
> *基于递归学习的分析性全局布局虚拟缓冲*

*Andrew B. Kahng, Yiting Liu, Zhiang Wang* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 全局布局, 虚拟缓冲, 递归学习, 时序收敛, ERC

**Comment:** 

> **TL;DR:** 提出MLBuf-RePlAce，一个基于递归学习的虚拟缓冲分析性全局布局框架，显著改善时序，并解决ERC违规问题。

**AI_Comments:** 该论文的创新点在于提出了一个开源的、学习驱动的虚拟缓冲感知分析性全局布局框架MLBuf-RePlAce，它有效地结合了递归学习来预测缓冲并在全局布局阶段解决ERC违规。这解决了传统方法计算成本高和现有机器学习方法忽视ERC的问题。其在时序上的显著改进以及开源性质，使其在物理设计领域具有重要意义和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现代技术节点中互连与单元延迟的非线性缩放使得考虑缓冲孔隙率（即单元密度）的布局对于时序收敛至关重要。然而，现有方法面临两大挑战：(i) 传统的van Ginneken-Lillis风格缓冲方法在全局布局期间计算成本高昂；(ii) 基于机器学习的方法（如BufFormer）缺乏对电气规则检查（ERC）违规的彻底考虑，并且未能“闭环”回到物理设计流程。

**Method:** 提出MLBuf-RePlAce，第一个开源的由学习驱动的虚拟缓冲感知分析性全局布局框架，构建在OpenROAD基础设施之上。MLBuf-RePlAce采用一种高效的基于递归学习的生成式缓冲方法来预测缓冲类型和位置，并在全局布局期间解决ERC违规问题。

**Result:** 在开源OpenROAD流程中，MLBuf-RePlAce在总负时序余量（TNS）上实现了（最大，平均）56%和31%的改进，且后布线功耗无退化。在商业流程中评估时，MLBuf-RePlAce在TNS上实现了（最大，平均）53%和28%的改进，同时后布线功耗平均改善0.2%。

**Conclusion:** MLBuf-RePlAce通过其递归学习方法，有效地解决了全局布局中的虚拟缓冲问题，显著提高了时序性能，同时兼顾了电气规则检查，并在开源和商业流程中均表现出优越性。

> **ai_Abstract:** 本文提出了MLBuf-RePlAce，一个基于递归学习的虚拟缓冲感知分析性全局布局框架。该框架旨在解决现有全局布局方法在时序收敛和电气规则检查方面的挑战。MLBuf-RePlAce通过高效的递归学习预测缓冲类型和位置，并在全局布局阶段处理ERC违规。实验结果表明，与OpenROAD默认布局器相比，MLBuf-RePlAce在开源和商业流程中均显著改善了总负时序余量（TNS），且对功耗影响极小。

> **摘要翻译:** 由于现代技术节点中互连与单元延迟的非线性缩放，在物理综合流程中，考虑缓冲孔隙率（即单元密度）的布局对于时序收敛至关重要。然而，现有方法面临两个关键挑战：(i) 传统的van Ginneken-Lillis风格缓冲方法在全局布局期间计算成本高昂；(ii) 基于机器学习的方法（如BufFormer）缺乏对电气规则检查（ERC）违规的彻底考虑，并且未能“闭环”回到物理设计流程。在这项工作中，我们提出了MLBuf-RePlAce，这是第一个开源的、学习驱动的虚拟缓冲感知分析性全局布局框架，构建在OpenROAD基础设施之上。MLBuf-RePlAce采用一种高效的基于递归学习的生成式缓冲方法来预测缓冲类型和位置，并在全局布局期间解决ERC违规问题。我们将MLBuf-RePlAce与OpenROAD中默认的基于虚拟缓冲的时序驱动全局布局器进行比较，使用了来自TILOS MacroPlacement和OpenROAD-flow-scripts仓库的开源测试用例。在不降低后布线功耗的情况下，MLBuf-RePlAce在开源OpenROAD流程中，总负时序余量（TNS）实现了（最大，平均）56%和31%的改进。当在商业流程中评估时，MLBuf-RePlAce在TNS上实现了（最大，平均）53%和28%的改进，同时后布线功耗平均改善0.2%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [245] [Disentangling Neural Disjunctive Normal Form Models](https://arxiv.org/abs/2507.10546)
> *解耦神经析取范式模型*

*Kexin Gu Baugh, Vincent Perreault, Matthew Baugh, Luke Dickens, Katsumi Inoue, Alessandra Russo* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 神经析取范式, 解耦, 神经-符号学习, 可解释性, 分类

**Comment:** Accepted at NeSy 2025

> **TL;DR:** 本文提出了一种新的解耦方法，通过拆分节点来解决神经析取范式（DNF）模型在训练后符号翻译过程中性能下降的问题，从而在分类任务中获得更紧凑、可解释的逻辑表示，并使性能更接近翻译前。

**AI_Comments:** 这项工作具有重要的创新性，它解决了神经符号学习中一个关键的挑战：如何有效地将神经网络学习到的知识转化为可解释的符号规则，同时最小化性能损失。通过提出节点拆分的解耦策略，该研究不仅提升了模型的可解释性，也显著改善了其在实际应用中的性能。这对于推动神经符号AI的发展具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 神经析取范式（DNF）模型在神经-符号学习中表现出色，但在训练后的符号翻译过程中，由于知识未解耦，其性能会下降。

**Method:** 提出了一种新的解耦方法，通过将编码嵌套规则的节点拆分成更小的独立节点，从而更好地保留模型性能。

**Result:** 在二元、多类别和多标签分类任务（包括需要谓词发明的任务）上的实验表明，所提出的解耦方法为神经DNF模型提供了紧凑且可解释的逻辑表示，并且性能更接近其翻译前的对应模型。

**Conclusion:** 通过解耦学习到的知识，可以有效改善神经析取范式模型在符号翻译过程中的性能下降问题，并获得更优的逻辑表示。

> **ai_Abstract:** 该论文提出了一种新的解耦方法，旨在解决神经析取范式（DNF）模型在训练后符号翻译过程中因未解耦知识而导致的性能下降问题。通过将编码嵌套规则的节点拆分为更小的独立节点，该方法能够更好地保持模型性能。实验证明，在多种分类任务中，该解耦方法能为神经DNF模型提供紧凑且可解释的逻辑表示，并使其性能更接近翻译前的水平。

> **摘要翻译:** 神经析取范式（DNF）模型是强大且可解释的神经-符号学习方法，在没有先验任务知识的情况下，在分类和强化学习设置中显示出有希望的结果。然而，它们的性能会因训练后符号翻译过程中的阈值处理而下降。我们在此表明，翻译过程中部分性能下降是由于未能解耦以网络权重形式表示的学习到的知识。我们通过提出一种新的解耦方法来解决这个问题；通过将编码嵌套规则的节点拆分成更小的独立节点，我们能够更好地保留模型的性能。通过在二元、多类别和多标签分类任务（包括那些需要谓词发明的任务）上的实验，我们证明了我们的解耦方法为神经DNF模型提供了紧凑且可解释的逻辑表示，其性能更接近于其翻译前的对应模型。我们的代码可在 https://github.com/kittykg/disentangling-ndnf-classification 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [251] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
> *为一百万学生优化反馈的学习：大规模在线辅导中多臂和上下文强盗算法的洞察*

*Robin Schmucker, Nimish Pachapurkar, Shanmuga Bala, Miral Shah, Tom Mitchell* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 在线辅导, 多臂强盗, 上下文强盗, 学生反馈, 个性化学习

**Comment:** 

> **TL;DR:** 一个在线辅导系统使用多臂和上下文强盗算法为百万学生优化反馈，发现多臂算法已能显著提升学生表现，而上下文算法的个性化提升有限。

**AI_Comments:** 该论文的创新之处在于其大规模的实验和部署，涉及一百万学生和数万种辅助行为，这在教育技术领域是显著的。它通过实证比较了多臂强盗和上下文强盗算法在教育反馈优化中的有效性，并提供了一个重要的发现：在某些情况下，简单的、优化良好的非个性化策略（MAB）可能已经足够有效，而更复杂的个性化策略（CB）带来的边际效益可能不显著。这对于资源有限的实际部署具有重要指导意义。论文的局限性可能在于其对特定在线辅导系统的适用性，但其方法论和洞察具有普遍参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在开发一个在线辅导系统，该系统能学习为答错问题的学生提供有效的反馈，以优化学生学习。

**Method:** 研究使用了多臂强盗 (MAB) 框架和离线策略评估来评估43,000种辅助行为。设计了一种算法，为每个问题选择合适的策略训练目标。进一步使用上下文强盗 (CB) 策略和因果推断来探索个性化反馈的效果。

**Result:** 在166,000次练习会话中，MAB策略显著改善了学生学习成果。分析显示，尽管某些辅助行为对某些学生表现出效果异质性，但上下文强盗策略带来的额外显著提升通常有限，不如优化良好的MAB策略。

**Conclusion:** 该系统优化后的教学策略目前每天为数千名学生提供支持，并提供了大规模部署数据驱动系统的洞察和未来改进的启示。

> **ai_Abstract:** 该论文介绍了一个大规模在线辅导系统，该系统利用多臂强盗 (MAB) 算法，通过分析一百万学生的行为数据，学习为答错问题的学生提供最优反馈。研究评估了43,000种辅助行为，并展示了MAB策略在提升学生学习成果方面的显著效果。此外，论文探讨了上下文强盗 (CB) 算法能否通过个性化反馈进一步改善结果，但发现尽管存在效果异质性，CB策略相较于优化良好的MAB策略所带来的额外提升通常不显著。研究提供了大规模数据驱动系统部署的实践洞察。

> **摘要翻译:** 我们介绍了一个在线辅导系统，该系统学习在学生答错问题后提供有效的反馈。利用来自一百万学生的数据，该系统学习为每个问题提供哪种辅助行为（例如，多种提示之一）以优化学生学习。采用多臂强盗 (MAB) 框架和离线策略评估，我们评估了43,000种辅助行为，并确定了针对不同学生结果（例如，回答正确性、会话完成度）优化的辅助策略之间的权衡。我们设计了一种算法，为每个问题决定合适的策略训练目标，以提高学生的即时第二次尝试成功率和整体练习会话表现。我们在166,000次练习会话中评估了由此产生的MAB策略，验证了学生结果的显著改善。虽然MAB策略为整体学生群体优化反馈，但我们进一步调查了上下文强盗 (CB) 策略是否可以通过根据个体学生特征（例如，能力估计、反应时间）个性化反馈来改善结果。利用因果推断，我们检查了 (i) 辅助行为的效果如何在学生之间变化，以及 (ii) 利用这种效果异质性的CB策略是否优于MAB策略。虽然我们的分析表明，某些问题的某些行为确实表现出效果异质性，但效果大小通常可能太小，以至于CB策略无法在优化良好的MAB策略（为所有学生提供相同的行为）已经实现的成果之外提供显著改进。我们讨论了大规模部署数据驱动系统所获得的洞察以及对未来改进的启示。如今，我们系统优化的教学策略每天支持数千名学生。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [252] [Geometric Multi-color Message Passing Graph Neural Networks for Blood-brain Barrier Permeability Prediction](https://arxiv.org/abs/2507.18926)
> *用于血脑屏障渗透性预测的几何多色消息传递图神经网络*

*Trung Nguyen, Md Masud Rana, Farjana Tasnim Mukta, Chang-Guo Zhan, Duc Duy Nguyen* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 血脑屏障渗透性, 几何特征, 药物发现, 分子性质预测

**Comment:** 

> **TL;DR:** GMC-MPNN是一种新型图神经网络，通过结合原子级几何特征和长程相互作用，显著提高了血脑屏障渗透性预测的准确性。

**AI_Comments:** 该论文的创新点在于将分子三维几何信息和长程相互作用显式地整合到图神经网络中，解决了传统GNN忽略关键空间信息的局限性。其提出的GMC-MPNN在血脑屏障渗透性预测任务中取得了显著的性能提升，为药物发现和开发提供了更准确、更具泛化性的预测工具，具有重要的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测血脑屏障渗透性对于中枢神经系统药物开发至关重要。现有图神经网络通常依赖分子拓扑结构，而忽略了对建模转运机制至关重要的三维几何信息。

**Method:** 本文引入了几何多色消息传递图神经网络（GMC-MPNN）。该模型通过基于原子类型构建加权彩色子图，显式地整合原子级几何特征和长程相互作用，以捕捉控制血脑屏障渗透性的空间关系和化学背景。模型在三个基准数据集上进行了分类和回归任务评估，并采用严格的支架式拆分确保泛化能力。

**Result:** GMC-MPNN在分类任务中表现优异（AUC-ROC分别为0.9704和0.9685），在回归任务中也取得了卓越性能（RMSE为0.4609，皮尔逊相关系数为0.7759），始终优于现有最先进模型。消融研究表明，模型的预测能力源于其学习常见和稀有但化学上重要的功能基团的能力。

**Conclusion:** 通过将空间几何整合到图表示中，GMC-MPNN为血脑屏障渗透性预测设定了新的性能基准，并为药物发现流程提供了一个更准确和更具泛化性的工具。

> **ai_Abstract:** 本研究提出了一种几何多色消息传递图神经网络（GMC-MPNN），旨在提高血脑屏障渗透性预测的准确性。与传统GNNs不同，GMC-MPNN通过整合原子级几何特征和长程相互作用来捕捉分子三维空间信息。该模型通过构建加权彩色子图来表示原子间的空间关系和化学环境。在多个基准数据集上的实验结果表明，GMC-MPNN在分类和回归任务上均显著优于现有最先进模型，为药物发现提供了更精确的工具。

> **摘要翻译:** 准确预测血脑屏障渗透性（BBBP）对于中枢神经系统（CNS）药物开发至关重要。尽管图神经网络（GNNs）在分子性质预测方面取得了进展，但它们通常依赖于分子拓扑结构，而忽略了对建模转运机制至关重要的三维几何信息。本文引入了几何多色消息传递图神经网络（GMC-MPNN），这是一个新颖的框架，通过显式地整合原子级几何特征和长程相互作用，增强了标准消息传递架构。我们的模型基于原子类型构建加权彩色子图，以捕捉控制血脑屏障渗透性的空间关系和化学背景。我们在三个基准数据集上对GMC-MPNN进行了分类和回归任务的评估，并采用严格的支架式拆分来确保对泛化能力的稳健评估。结果表明，GMC-MPNN始终优于现有最先进模型，在将化合物分类为可渗透/不可渗透（AUC-ROC分别为0.9704和0.9685）和回归连续渗透值（RMSE为0.4609，皮尔逊相关系数为0.7759）方面均取得了卓越性能。一项消融研究进一步量化了特定原子对相互作用的影响，揭示了模型的预测能力源于其从常见和稀有但化学上重要的功能基团中学习的能力。通过将空间几何整合到图表示中，GMC-MPNN设定了新的性能基准，并为药物发现流程提供了一个更准确和更具泛化性的工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [254] [Binarizing Physics-Inspired GNNs for Combinatorial Optimization](https://arxiv.org/abs/2507.13703)
> *二值化物理启发式图神经网络用于组合优化*

*Martin Krutský, Gustav Šír, Vyacheslav Kungurtsev, Georgios Korpas* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 物理启发式图神经网络, 组合优化, 二值化, 图神经网络, 模糊逻辑

**Comment:** Accepted to the 28th European Conference on Artificial Intelligence
  (ECAI 2025). This archival version includes supplementary appendices

> **TL;DR:** 本文指出物理启发式图神经网络（PI-GNNs）在处理高密度组合优化问题时性能会急剧下降，并提出基于模糊逻辑和二值化神经网络的替代方案，显著提升了PI-GNNs在高密度场景下的性能。

**AI_Comments:** 这篇论文识别并解决了物理启发式图神经网络在处理高密度组合优化问题时的一个关键限制。其创新之处在于通过引入模糊逻辑和二值化神经网络的原理，有效地弥合了模型实值输出与问题二值解之间的鸿沟。这不仅提升了PI-GNNs的实用性，也为未来在复杂离散优化问题中应用GNNs提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 物理启发式图神经网络（PI-GNNs）作为一种有效的无监督框架，在解决组合优化问题方面表现出潜力。然而，研究发现随着组合问题图密度的增加，PI-GNNs的性能会系统性地急剧下降。分析揭示了训练动态中存在有趣的相变，这与密度更大问题的退化解相关，凸显了松弛的实值模型输出与二值问题解之间的差异。

**Method:** 为了解决实值模型输出与二值问题解之间的差异，本文基于模糊逻辑和二值化神经网络的见解，提出了替代PI-GNNs中朴素策略的原则性方法。

**Result:** 实验证明，所提出的一系列方法显著改善了PI-GNNs在日益密集的设置中的性能。

**Conclusion:** 本文证明了物理启发式图神经网络在处理高密度组合优化问题时性能下降的问题，并成功提出了基于模糊逻辑和二值化神经网络的二值化方法，有效提升了其在高密度场景下的性能。

> **ai_Abstract:** 本文研究了物理启发式图神经网络（PI-GNNs）在组合优化问题中的应用，发现其性能会随着问题图密度的增加而下降。这种下降源于实值模型输出与二值问题解之间的不一致。为解决此问题，作者提出了基于模糊逻辑和二值化神经网络的改进方法，实验证明这些方法在高密度场景下显著提升了PI-GNNs的性能。

> **摘要翻译:** 物理启发式图神经网络（PI-GNNs）已被用作一种高效的无监督框架，用于松弛通过特定图结构和损失编码的组合优化问题，反映了问题变量之间的依赖关系。尽管该框架在各种组合问题中取得了有希望的结果，但我们发现随着组合问题图密度的增加，PI-GNNs的性能会系统性地急剧下降。我们的分析揭示了PI-GNNs训练动态中一个有趣的相变，这与密度更大问题的退化解相关，突出了松弛的实值模型输出与二值问题解之间的差异。为了解决这一差异，我们基于模糊逻辑和二值化神经网络的见解，提出了替代PI-GNNs中朴素策略的原则性方法。我们的实验表明，所提出的一系列方法显著改善了PI-GNNs在日益密集的设置中的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [265] [SourceSplice: Source Selection for Machine Learning Tasks](https://arxiv.org/abs/2507.22186)
> *SourceSplice：机器学习任务的源选择*

*Ambarish Singh, Romila Pradhan* | **Category: cs.LG, cs.AI, cs.DB, I.2.6** | **Updated: 2025-07-31**

**Keywords:** 数据源选择, 机器学习, 数据质量, SourceSplice, 基因剪接

**Comment:** 

> **TL;DR:** 针对机器学习任务，本文提出了SourceGrasp和SourceSplice框架，旨在高效选择最佳数据源子集以最大化模型效用，其中SourceSplice受基因剪接启发，并在实验中表现出以更少的探索识别高效用子集的能力。

**AI_Comments:** 本文的创新点在于将生物学中的基因剪接概念引入到机器学习的数据源选择问题中，为解决数据质量对模型性能的影响提供了一个新颖的视角。SourceSplice在减少探索次数的同时保持高效性，这对于处理大规模数据源具有重要意义。该研究强调了数据源选择在ML流程中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 现代组织中海量的数据源使得数据质量对机器学习任务的预测性能至关重要，然而现有数据发现工作主要关注元数据匹配或语义相似性，未能充分考虑数据源质量对下游机器学习任务高性能的影响。本文旨在解决如何确定最佳数据源子集以构建给定ML任务的训练数据集的问题。

**Method:** 本文提出了SourceGrasp和SourceSplice两种框架，旨在高效选择合适的源子集以最大化下游ML模型的效用。这两种算法的核心思想是数据源（或其组合）对任务效用的贡献不同，需要审慎选择。SourceGrasp采用基于贪婪准则和随机化的元启发式算法，而SourceSplice框架则提出了一种受基因剪接（蛋白质合成中的核心概念）启发的源选择机制。

**Result:** 作者在三个真实世界数据集和合成数据集上对算法进行了实证评估，结果表明，SourceSplice以显著更少的子集探索，有效地识别了能带来高任务效用的数据源子集。此外，研究还报告了SourceSplice在多种设置下对决策选择的敏感性。

**Conclusion:** SourceSplice提供了一种高效且有效的数据源选择机制，能够为机器学习任务识别出高质量的数据源子集，从而显著提升任务效用。

> **ai_Abstract:** 本文提出SourceGrasp和SourceSplice两个框架，旨在解决机器学习任务中从海量数据源中高效选择最佳子集以构建高质量训练数据集的问题。区别于传统数据发现方法，它们重点关注数据源对下游ML模型效用的贡献。SourceSplice尤其创新性地借鉴了基因剪接机制，并在实验中证明了其能以显著更少的探索次数识别出高任务效用的数据源子集，同时还分析了其敏感性。

> **摘要翻译:** 数据质量在机器学习（ML）任务的预测性能中起着关键作用——现代组织中海量的数据源放大了这一挑战。先前的数据发现工作主要关注元数据匹配、语义相似性或识别应连接以回答特定查询的表格，但并未考虑数据源质量对下游ML任务高性能的影响。本文解决了确定必须组合哪些最佳数据源子集以构建给定ML任务的基础训练数据集的问题。我们提出了SourceGrasp和SourceSplice，这两个框架旨在高效选择合适的源子集，从而最大化下游ML模型的效用。这两种算法都依赖于核心思想，即数据源（或其组合）对任务效用的贡献不同，必须审慎选择。SourceGrasp利用基于贪婪准则和随机化的元启发式算法，而SourceSplice框架则提出了一种受基因剪接——蛋白质合成中使用的核心概念——启发的源选择机制。我们通过三个真实世界数据集和合成数据集对我们的算法进行了实证评估，结果表明，SourceSplice以显著更少的子集探索，有效地识别了能带来高任务效用的数据源子集。我们还进行了研究，报告了SourceSplice在多种设置下对决策选择的敏感性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [270] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
> *扩散模型在数据受限设置中超越自回归模型*

*Mihir Prabhudesai, Mengning Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak* | **Category: cs.LG, cs.AI, cs.CV, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 扩散模型, 自回归模型, 数据受限, 语言模型, 缩放定律

**Comment:** Project Webpage: https://diffusion-scaling.github.io

> **TL;DR:** 在计算资源充足但数据稀缺的场景下，扩散模型显著优于自回归模型，因其能更好地利用重复数据并进行隐式数据增强。

**AI_Comments:** 这篇论文揭示了扩散模型在特定场景下（数据受限）相对于自回归模型的显著优势，具有重要意义。提出“隐式数据增强”的概念来解释其优越性，以及推导新的缩放定律和临界计算阈值，为语言模型训练中的模型选择和资源分配提供了宝贵的理论指导。这项工作可能会推动未来更数据高效的语言模型架构研究。

<details>
  <summary>Details</summary>

**Motivation:** 自回归（AR）模型长期以来主导大型语言模型领域，但基于扩散的语言模型作为一种有前景的替代方案正在兴起。然而，它们相对于AR模型的优势，尤其是在数据受限环境中的表现，尚未得到充分探索。

**Method:** 本文系统地研究了在数据受限设置下（训练涉及对有限数据进行重复传递）的掩码扩散模型，并与AR模型进行了比较。研究中还发现了扩散模型的新缩放定律，并推导出了扩散模型开始超越AR模型的临界计算阈值的闭合形式表达式。

**Result:** 当计算资源充足但数据稀缺时，扩散模型显著优于AR模型。扩散模型能更好地利用重复数据，从而实现更低的验证损失和卓越的下游性能。这种优势被解释为隐式数据增强，即掩码扩散使模型暴露于多样化的词元排序和预测任务。论文还发现了扩散模型的新缩放定律，并推导出了临界计算阈值的闭合形式表达式。

**Conclusion:** 当数据而非计算是瓶颈时，扩散模型为标准的自回归范式提供了一个引人注目的替代方案。

> **ai_Abstract:** 本文研究了数据受限环境下的掩码扩散模型，发现当计算资源充足但数据有限时，它们显著优于传统的自回归模型。这种优势源于扩散模型能更好地利用重复数据和进行隐式数据增强，从而在验证损失和下游性能上均表现更佳。研究还建立了扩散模型的新缩放定律和临界计算阈值，表明当数据稀缺是主要瓶颈时，扩散模型是一个有力的替代方案。

> **摘要翻译:** 自回归 (AR) 模型长期以来主导着大型语言模型领域，推动了广泛任务的进展。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相对于 AR 模型的优势尚未得到充分探索。在本文中，我们系统地研究了数据受限设置（训练涉及对有限数据进行重复传递）中的掩码扩散模型，发现当计算资源充足但数据稀缺时，它们显著优于 AR 模型。扩散模型能更好地利用重复数据，实现更低的验证损失和卓越的下游性能。我们将这种优势解释为隐式数据增强：与 AR 模型固定的从左到右分解不同，掩码扩散模型使模型暴露于多样化的词元排序和预测任务分布。我们发现了扩散模型的新缩放定律，并推导出了扩散模型开始超越 AR 模型的临界计算阈值的闭合形式表达式。这些结果表明，当数据而非计算是瓶颈时，扩散模型为标准 AR 范式提供了一个引人注目的替代方案。我们的代码可在以下网址获取：https://diffusion-scaling.github.io。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [273] [Teaching the Teacher: Improving Neural Network Distillability for Symbolic Regression via Jacobian Regularization](https://arxiv.org/abs/2507.22767)
> *教导教师：通过雅可比正则化提高神经网络对符号回归的可蒸馏性*

*Soumyadeep Dhar, Kei Sen Fong, Mehul Motani* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 神经网络蒸馏, 符号回归, 雅可比正则化, 可解释AI, 模型保真度

**Comment:** 

> **TL;DR:** 提出一种基于雅可比正则化的新训练范式，显著提高了从神经网络中提取可解释符号模型的可蒸馏性。

**AI_Comments:** 这项工作的创新之处在于提出了一个主动的“教师教学”范式，通过雅可比正则化从源头改善教师网络的可蒸馏性，而不是简单地进行被动蒸馏。这解决了传统知识蒸馏中教师模型复杂性导致学生模型保真度低的关键问题。其重要性在于为构建更可信、更可解释的AI模型提供了一条有效的路径，尤其是在符号回归领域。

<details>
  <summary>Details</summary>

**Motivation:** 将大型神经网络蒸馏成简单、人类可读的符号公式的过程通常很脆弱，因为标准网络学习到的复杂函数不适合符号发现，导致学生模型保真度低。

**Method:** 提出一种新的训练范式，引入基于雅可比的正则化器，主动鼓励“教师”网络学习不仅准确而且固有更平滑、更适合蒸馏的函数，而不是被动蒸馏预训练网络。

**Result:** 在真实世界回归基准上的广泛实验表明，该方法非常有效。通过优化每个问题的正则化强度，与标准蒸馏流程相比，最终蒸馏的符号模型的R²分数平均提高了120%（相对），同时保持了教师网络的预测精度。

**Conclusion:** 本工作提出了一种实用且有原则的方法，显著提高了从复杂神经网络中提取可解释模型的保真度。

> **ai_Abstract:** 该论文提出了一种名为“教导教师”的新训练范式，旨在解决将复杂神经网络蒸馏为简单符号公式时保真度低的问题。通过引入基于雅可比的正则化器，该方法主动促使教师网络学习更平滑、更易于蒸馏的函数。实验结果表明，与标准蒸馏方法相比，该方法能将蒸馏出的符号模型的R²分数平均提高120%，同时不牺牲教师网络的预测准确性，从而显著提升了可解释模型的提取质量。

> **摘要翻译:** 将大型神经网络蒸馏成简单、人类可读的符号公式是实现可信和可解释人工智能的一条有前途的途径。然而，这个过程通常很脆弱，因为标准网络学习到的复杂函数不适合符号发现，导致学生模型保真度低。在这项工作中，我们提出了一种新颖的训练范式来解决这一挑战。我们不是被动地蒸馏预训练网络，而是引入了一种基于雅可比的正则化器，它主动鼓励“教师”网络学习不仅准确而且固有更平滑、更适合蒸馏的函数。我们通过在真实世界回归基准套件上进行的大量实验证明，我们的方法非常有效。通过优化每个问题的正则化强度，与标准蒸馏流程相比，我们最终蒸馏的符号模型的R²分数平均提高了120%（相对），同时保持了教师的预测精度。我们的工作提出了一种实用且有原则的方法，可以显著提高从复杂神经网络中提取的可解释模型的保真度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [279] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
> *不变图Transformer用于分布外泛化*

*Tianyin Liao, Ziwei Zhang, Yufei Sun, Chunyu Hu, Jianxin Li* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图Transformer, 分布外泛化, 不变学习, 图表示学习, 子图解耦

**Comment:** 

> **TL;DR:** 本文提出GOODFormer，一个基于不变学习的图Transformer，旨在解决图数据在分布偏移下的泛化问题。它通过三个模块实现不变子图分离、动态编码和不变表示学习，实验证明其在分布偏移下优于现有SOTA方法。

**AI_Comments:** 本文提出了一种新颖的图Transformer架构GOODFormer，其创新点在于将不变学习原理融入到图Transformer的设计中，特别是通过解耦不变/变异子图和动态编码来增强模型在分布偏移下的泛化能力。这对于现实世界中数据分布经常变化的图应用具有重要意义，解决了现有GTs的一大局限性。理论证明和实验验证也增强了其说服力。

<details>
  <summary>Details</summary>

**Motivation:** 现有图Transformer（GTs）在处理来自相同分布的图数据时表现出色，但在数据分布发生偏移时，其泛化能力不足。图不变学习是解决此问题的一个潜在方案，然而，如何基于图不变学习原则设计注意力机制以及位置和结构编码（PSEs）仍然是一个挑战。

**Method:** 本文提出了图分布外泛化Transformer（GOODFormer），旨在通过捕获预测图结构和标签之间的不变关系来学习广义图表示。它通过联合优化以下三个模块实现：
1. 基于GT的熵引导不变子图解耦器：用于分离不变子图和变异子图，同时保持注意力函数的锐度。
2. 演化子图位置和结构编码器：用于高效地捕获训练过程中动态变化的子图的编码信息。
3. 不变学习模块：利用子图节点表示和编码来推导出可以泛化到未见图的广义图表示。
此外，本文还提供了该方法的理论依据。

**Result:** 在基准数据集上进行的广泛实验表明，在分布偏移的条件下，该方法优于最先进的基线模型。

**Conclusion:** GOODFormer通过捕获预测图结构和标签之间的不变关系，有效地解决了图Transformer在分布偏移下的泛化问题，并取得了优异的性能。

> **ai_Abstract:** 本文提出了一种名为GOODFormer的图Transformer模型，旨在解决现有图Transformer在面对分布偏移数据时泛化能力不足的问题。GOODFormer通过整合不变学习原理，联合优化了三个关键模块：熵引导不变子图解耦器、演化子图位置和结构编码器以及不变学习模块。这些模块协同作用，旨在捕获图结构与标签之间的不变关系，从而学习到更具泛化能力的图表示，使其能够适应未见过的图数据。实验结果表明，该方法在分布偏移场景下，其性能优于当前最先进的基线模型。

> **摘要翻译:** 图Transformer（GTs）在各种图分析任务中表现出卓越的有效性。然而，现有的GTs专注于训练和测试来自相同分布的图数据，但在分布偏移下泛化失败。图不变学习旨在捕获分布偏移下具有标签的可泛化图结构模式，可能是一个有前景的解决方案，但如何根据图不变学习原理设计注意力机制以及位置和结构编码（PSEs）仍然具有挑战性。为了解决这些挑战，我们引入了图分布外泛化Transformer（GOODFormer），旨在通过联合优化三个模块来捕获预测图结构和标签之间的不变关系，从而学习广义图表示。具体来说，我们首先开发了一个基于GT的熵引导不变子图解耦器，用于分离不变和变异子图，同时保持注意力函数的锐度。接下来，我们设计了一个演化子图位置和结构编码器，以有效且高效地捕获训练期间动态变化的子图的编码信息。最后，我们提出了一个不变学习模块，利用子图节点表示和编码来推导出可泛化到未见图的广义图表示。我们还为我们的方法提供了理论依据。在基准数据集上进行的广泛实验表明，在分布偏移下，我们的方法优于最先进的基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [280] [Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design](https://arxiv.org/abs/2507.23437)
> *Coflex：利用稀疏高斯过程增强硬件感知神经架构搜索，实现高效可扩展的深度神经网络加速器设计*

*Yinhui Ma, Tomomasa Yamasaki, Zhehui Wang, Tao Luo, Bo Wang* | **Category: cs.LG, I.2.6; C.1.3; C.3** | **Updated: 2025-08-01**

**Keywords:** HW-NAS, 稀疏高斯过程, 贝叶斯优化, 深度神经网络加速器, 边缘计算

**Comment:** Accepted to the 2025 International Conference on Computer-Aided
  Design (ICCAD); 9 pages, including 6 figures and 7 tables

> **TL;DR:** Coflex是一个新的硬件感知神经架构搜索（HW-NAS）框架，通过结合稀疏高斯过程和多目标贝叶斯优化，解决了HW-NAS搜索空间大和计算成本高的问题，显著提高了效率和可扩展性，并在性能上超越了现有技术。

**AI_Comments:** Coflex的创新点在于将稀疏高斯过程引入到HW-NAS中，有效解决了传统高斯过程在处理大规模搜索空间时的计算复杂度问题。这种方法显著提升了HW-NAS的效率和可扩展性，对于边缘设备上DNN加速器的快速开发具有重要意义。其在保持高预测精度的同时大幅降低计算开销的能力是其主要优势。

<details>
  <summary>Details</summary>

**Motivation:** 硬件感知神经架构搜索（HW-NAS）在边缘设备上开发深度神经网络加速器方面非常有用，但其庞大的搜索空间和高计算成本严重阻碍了其实际应用。

**Method:** 我们提出了Coflex，一个新颖的HW-NAS框架，它将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程核的复杂度从立方级别降低到接近线性级别，从而实现了大规模搜索空间的可扩展近似，显著降低了计算开销，同时保持了高预测精度。

**Result:** 实验结果表明，Coflex在网络精度和能量延迟积方面优于现有最先进的方法，同时实现了1.9倍到9.5倍的计算加速。

**Conclusion:** Coflex通过引入稀疏高斯过程和多目标贝叶斯优化，有效解决了HW-NAS的计算开销和可扩展性问题，显著提升了深度神经网络加速器设计的效率和性能。

> **ai_Abstract:** Coflex是一种新型的硬件感知神经架构搜索（HW-NAS）框架，旨在解决现有HW-NAS方法面临的巨大搜索空间和高计算成本问题。该框架通过结合稀疏高斯过程（SGP）和多目标贝叶斯优化，利用稀疏诱导点将高斯过程核的复杂度从立方降低到接近线性，从而在不牺牲优化性能的前提下，实现了大规模搜索空间的高效近似。实验证明，Coflex在网络精度和能量延迟积上均优于现有技术，并实现了显著的计算加速。

> **摘要翻译:** 硬件感知神经架构搜索（HW-NAS）是一种有效的方法，可以自动协同优化神经网络性能和硬件能效，使其特别适用于边缘设备上的深度神经网络加速器开发。然而，庞大的搜索空间和高计算成本对其实际应用构成了重大挑战。为了解决这些限制，我们提出了Coflex，一个新颖的HW-NAS框架，它将稀疏高斯过程（SGP）与多目标贝叶斯优化相结合。通过利用稀疏诱导点，Coflex将高斯过程核的复杂度从相对于训练样本数量的立方级别降低到接近线性级别，而不会损害优化性能。这使得大规模搜索空间的可扩展近似成为可能，显著降低了计算开销，同时保持了高预测精度。我们在各种基准测试中评估了Coflex的功效，重点关注加速器特定架构。我们的实验结果表明，Coflex在网络精度和能量延迟积方面优于现有最先进的方法，同时实现了1.9倍到9.5倍的计算加速。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [315] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
> *PnP-DA：面向变分数据同化与生成模型原理性即插即用集成*

*Yongquan Qu, Matthieu Blanke, Sara Shamekh, Pierre Gentine* | **Category: cs.LG, physics.comp-ph** | **Updated: 2025-08-01**

**Keywords:** 数据同化, 生成模型, 即插即用, 预测误差, 非高斯

**Comment:** 

> **TL;DR:** PnP-DA通过结合变分数据同化和生成模型，解决了地球系统建模中预测误差积累的问题，提高了预测精度。

**AI_Comments:** PnP-DA的创新之处在于其即插即用的集成方法，巧妙地结合了变分数据同化和生成模型，解决了传统方法在处理非高斯误差和计算效率上的局限性。通过避免复杂的神经网络梯度反向传播，它提高了实际应用的效率和可行性。这项工作对于提高复杂地球系统预测的准确性和鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地球系统建模面临捕捉复杂、多尺度非线性动力学以及最小化预测误差的挑战。即使是最强大的AI或物理驱动的预测系统也存在误差累积。传统变分数据同化方法常假设高斯误差统计，但混沌动力学系统通常是非高斯行为，这限制了其性能。

**Method:** 提出PnP-DA，一种即插即用算法。它交替执行两个步骤：(1) 轻量级的、基于梯度的分析更新（对新观测使用马哈拉诺比斯距离失配）；(2) 通过条件Wasserstein耦合，对预训练生成先验进行一次前向传播，该先验以背景预测为条件。这种策略放宽了限制性统计假设，利用了丰富的历史数据，无需显式正则化泛函，并避免了在同化循环中通过复杂神经网络反向传播梯度。

**Result:** 在标准混沌测试台上进行的实验表明，该策略在不同观测稀疏度和噪声水平下，持续降低了预测误差，优于经典变分方法。

**Conclusion:** PnP-DA提供了一种原则性的即插即用方法，有效结合了变分数据同化和生成模型，解决了传统数据同化方法的局限性，显著提高了复杂系统预测的准确性。

> **ai_Abstract:** PnP-DA是一种新的即插即用算法，旨在解决地球系统建模中预测误差累积和传统数据同化方法对非高斯误差处理不佳的问题。它通过交替进行基于梯度的分析更新和利用预训练生成先验的前向传播来工作，从而放宽了统计假设并避免了复杂的梯度反向传播。实验证明，PnP-DA在减少预测误差方面优于经典变分方法。

> **摘要翻译:** 地球系统建模在科学计算中提出了一个根本性挑战：如何在计算高效的模型中捕捉复杂的、多尺度的非线性动力学，同时最小化由必要简化引起的预测误差。即使是最强大的基于AI或物理的预测系统也会出现逐渐的误差累积。数据同化（DA）旨在通过将（有噪声的）观测与先验模型预测进行最佳融合来减轻这些误差，但传统的变分方法通常假设高斯误差统计，而这未能捕捉到混沌动力学系统真实、非高斯行为。我们提出了PnP-DA，一种即插即用算法，它交替进行 (1) 轻量级的、基于梯度的分析更新（使用新观测的马哈拉诺比斯距离失配）和 (2) 通过条件Wasserstein耦合，对预训练的生成先验进行一次前向传播，该先验以背景预测为条件。这种策略放宽了限制性统计假设，并在不需要显式正则化泛函的情况下利用了丰富的历史数据，同时避免了在同化循环中通过编码先验的复杂神经网络进行梯度反向传播的需求。在标准混沌测试台上进行的实验表明，该策略在不同观测稀疏度和噪声水平下，持续降低了预测误差，优于经典变分方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [328] [Curious Causality-Seeking Agents Learn Meta Causal World](https://arxiv.org/abs/2506.23068)
> *好奇的因果寻求智能体学习元因果世界*

*Zhiyu Zhao, Haoxuan Li, Haifeng Zhang, Jun Wang, Francesco Faccio, Jürgen Schmidhuber, Mengyue Yang* | **Category: cs.LG, cs.AI, stat.AP** | **Updated: 2025-08-01**

**Keywords:** 元因果图, 因果寻求智能体, 世界模型, 好奇心驱动, 因果推断

**Comment:** 33 pages

> **TL;DR:** 提出元因果图作为世界模型，通过好奇心驱动的智能体识别并学习不同潜在世界状态下因果结构的变化，有效应对动态因果环境。

**AI_Comments:** 这项工作的创新之处在于提出了“元因果图”来统一表示动态变化的因果结构，而非假设单一不变的因果规则，更符合现实世界复杂性。结合“好奇心驱动的因果寻求智能体”进行探索和学习，提供了一种处理非平稳因果机制的有效范式。其重要性在于为构建更鲁棒、更具泛化能力的世界模型提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统世界模型假设环境有单一不变的因果规则，但现实中，即使策略或环境状态微小变化也可能改变观察到的因果机制，导致世界模型构建困难。

**Method:** 引入“元因果图”作为世界模型，它是一个最小统一表示，有效编码了因果结构在不同潜在世界状态下转变的规则。元因果图由多个因果子图组成，每个子图由潜在状态空间中的元状态触发。在此基础上，引入“因果寻求智能体”，其目标是 (1) 识别触发每个子图的元状态，(2) 通过好奇心驱动的干预策略发现相应的因果关系，以及 (3) 通过持续的好奇心驱动探索和智能体经验迭代完善元因果图。

**Result:** 在合成任务和具有挑战性的机械臂操作任务上的实验表明，该方法能够稳健地捕获因果动态的变化，并有效地泛化到以前未见的上下文。

**Conclusion:** 该研究成功开发了一种新的世界模型表示（元因果图）和学习范式（因果寻求智能体），能够有效处理现实世界中动态变化的因果机制，并展现出良好的泛化能力。

> **ai_Abstract:** 本文提出了一种新的世界模型表示——元因果图，用于编码因果结构在不同潜在世界状态下的转变规则。同时，引入一个好奇心驱动的因果寻求智能体，其目标是识别元状态、发现因果关系并迭代完善元因果图。实验证明，该方法能有效捕获因果动态变化并泛化到新环境。

> **摘要翻译:** 在构建世界模型时，一个常见的假设是环境具有单一、不变的潜在因果规则，就像将牛顿定律应用于每种情况一样。实际上，看似漂移的因果机制往往是通过狭窄的观察窗口看到的固定潜在机制的体现。这就带来了一个问题，即在构建世界模型时，即使策略或环境状态的微小变化也可能改变所观察到的因果机制。在这项工作中，我们引入了**元因果图**作为世界模型，这是一种最小的统一表示，可以有效地编码因果结构在不同潜在世界状态下如何转变的转换规则。单个元因果图由多个因果子图组成，每个子图由潜在状态空间中的元状态触发。在此表示的基础上，我们引入了**因果寻求智能体**，其目标是 (1) 识别触发每个子图的元状态，(2) 通过智能体好奇心驱动的干预策略发现相应的因果关系，以及 (3) 通过持续的好奇心驱动探索和智能体经验迭代完善元因果图。在合成任务和具有挑战性的机械臂操作任务上的实验表明，我们的方法能够稳健地捕获因果动态的变化，并有效地泛化到以前未见的上下文。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [349] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
> *语言模型的胚胎学*

*George Wang, Garrett Baker, Andrew Gordon, Daniel Murfet* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 语言模型, 敏感性分析, UMAP, 结构发展, 可解释性

**Comment:** 

> **TL;DR:** 研究引入胚胎学方法，利用UMAP和敏感性矩阵可视化语言模型训练过程中的语言模型结构发展，揭示了新的内部计算结构。

**AI_Comments:** 这项工作创新性地将“胚胎学”概念引入语言模型研究，通过可视化敏感性矩阵揭示了模型内部结构的动态形成过程。它不仅验证了已知特征的出现，还发现了新的功能性结构，为理解大型语言模型的“黑箱”操作提供了一个新颖且强大的视角，对深度学习的可解释性研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解语言模型如何发展其内部计算结构是深度学习科学中的一个核心问题。尽管源自统计物理学的敏感性提供了一种有前景的分析工具，但其在可视化网络组织方面的全部潜力尚未被发掘。

**Method:** 引入胚胎学方法，将UMAP应用于敏感性矩阵，以可视化模型在训练过程中的结构发展。

**Result:** 可视化揭示了清晰的“身体蓝图”的出现，描绘了已知特征（如归纳电路）的形成，并发现了以前未知的结构（如专门用于计算空格令牌的“间距鳍”）。

**Conclusion:** 敏感性分析可以超越验证，揭示新颖的机制，为研究复杂神经网络的发展原理提供强大、整体的视角。

> **ai_Abstract:** 本文提出一种“胚胎学”方法，通过将UMAP应用于敏感性矩阵来可视化语言模型在训练过程中的内部结构发展。研究揭示了模型内部“身体蓝图”的形成，包括已知特征的出现和新颖结构的发现，例如“间距鳍”。这表明敏感性分析是研究复杂神经网络发展原理的有效工具。

> **摘要翻译:** 理解语言模型如何发展其内部计算结构是深度学习科学中的一个核心问题。尽管源自统计物理学的敏感性提供了一种有前景的分析工具，但其在可视化网络组织方面的全部潜力尚未被发掘。在这项工作中，我们引入了一种胚胎学方法，将UMAP应用于敏感性矩阵，以可视化模型在训练过程中的结构发展。我们的可视化揭示了清晰的“身体蓝图”的出现，描绘了已知特征（如归纳电路）的形成，并发现了以前未知的结构，例如专门用于计算空格令牌的“间距鳍”。这项工作表明，敏感性分析可以超越验证，揭示新颖的机制，为研究复杂神经网络的发展原理提供强大、整体的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [370] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
> *BOOD：基于边界的分布外数据生成*

*Qilin Liao, Shuo Yang, Bo Zhao, Ping Luo, Hengshuang Zhao* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 分布外检测, 扩散模型, 数据生成, 潜在空间, 决策边界

**Comment:** 14 pages, 8 figures, To be published in the Proceedings of the
  International Conference on Machine Learning (ICML) 2025

> **TL;DR:** BOOD利用扩散模型通过扰动靠近决策边界的分布内特征来生成高质量的分布外（OOD）数据，显著提升了OOD检测性能。

**AI_Comments:** BOOD的创新点在于其独特的基于边界扰动的OOD数据生成策略，有效解决了在潜在空间中难以提取OOD特征的挑战。通过利用扩散模型生成高质量且具有区分性的OOD数据，该方法为OOD检测提供了一个高效且性能卓越的解决方案，在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在潜在空间中难以有效识别决策边界并提取分布外（OOD）特征，这限制了OOD检测的性能。

**Method:** 本文提出了一种名为BOOD（Boundary-based Out-Of-Distribution data generation）的新框架。BOOD首先从分布内（ID）数据集学习一个文本条件的潜在特征空间，然后选择最接近决策边界的ID特征，并对其进行扰动使其跨越决策边界，从而形成合成的OOD特征。最后，这些合成的OOD特征通过扩散模型被解码成像素空间的图像，以生成高质量的OOD数据。

**Result:** BOOD提供了一种更训练高效的策略来合成信息丰富的OOD特征，促进了ID和OOD数据之间更清晰的区分。在常见的基准测试中，BOOD显著超越了现有最先进的方法，在CIFAR-100数据集上，平均FPR95降低了29.64%（从40.31%降至10.67%），平均AUROC提高了7.27%（从90.15%提高至97.42%）。

**Conclusion:** BOOD通过其新颖的基于边界扰动的数据生成方法，有效解决了在潜在空间中提取OOD特征的挑战，并显著提升了OOD检测的性能。

> **ai_Abstract:** BOOD是一种新颖的框架，它利用扩散模型通过扰动靠近决策边界的分布内（ID）特征来生成高质量的分布外（OOD）数据。该方法首先学习文本条件的潜在特征空间，选择并扰动靠近决策边界的ID特征以形成OOD特征，然后将其解码为图像。实验结果表明，BOOD在OOD检测方面显著优于现有最先进的方法，在CIFAR-100数据集上，平均FPR95降低了29.64%，平均AUROC提高了7.27%。

> **摘要翻译:** 利用扩散模型合成基于潜在空间特征的辅助训练数据已被证明能有效提高分布外（OOD）检测性能。然而，由于难以识别类别间的决策边界，在潜在空间中提取分布内（ID）边界之外的有效特征仍然具有挑战性。本文提出了一种名为基于边界的分布外数据生成（BOOD）的新颖框架，该框架利用扩散模型合成高质量的OOD特征并生成与人类兼容的异常图像。BOOD首先从ID数据集中学习一个文本条件的潜在特征空间，然后选择最接近决策边界的ID特征，并对其进行扰动使其跨越决策边界以形成OOD特征。这些合成的OOD特征随后通过扩散模型解码为像素空间的图像。与以往的工作相比，BOOD提供了一种更训练高效的策略来合成信息丰富的OOD特征，有助于ID和OOD数据之间更清晰的区分。在常见基准上的大量实验结果表明，BOOD显著超越了现有最先进的方法，在CIFAR-100数据集上，平均FPR95降低了29.64%（40.31%对比10.67%），平均AUROC提高了7.27%（90.15%对比97.42%）。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
> *束图神经网络通过PAC-贝叶斯谱优化*

*Yoonhyuk Choi, Jiho Choi, Chong-Kwon Kim* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 束神经网络, 过平滑, PAC-贝叶斯, 节点分类

**Comment:** 

> **TL;DR:** 本文提出了一种名为SGPC的新型束图神经网络（Sheaf GNNs）架构，旨在解决传统GNN的过平滑问题以及现有束网络在泛化和稳定性方面的不足。SGPC结合了细胞束消息传递、最优传输提升、方差缩减扩散和PAC-贝叶斯谱正则化，实现了鲁棒的半监督节点分类。该方法不仅在理论上提供了性能界限，还在实验中超越了现有最先进的模型，并具有线性计算复杂度。

**AI_Comments:** 这篇论文通过引入SGPC，巧妙地结合了多种先进技术（如最优传输、PAC-贝叶斯正则化）来解决GNN中的核心问题——过平滑，特别是在处理异配图时的挑战。其创新性在于构建了一个统一且具有理论性能保证的束GNN架构，弥补了现有束网络在泛化和稳定性上的不足。同时，线性计算复杂度的实现也增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 传统图神经网络（GNNs）存在过平滑问题，导致节点特征崩溃，尤其在相邻节点具有不同标签的异配图上。现有束神经网络虽然部分缓解了该问题，但通常依赖于静态或参数化过重的束结构，这阻碍了泛化和可扩展性，且缺乏严格的稳定性保证。

**Method:** 本文引入了一种名为SGPC（Sheaf GNNs with PAC-Bayes Calibration）的新颖方案。SGPC是一种统一的架构，将细胞束消息传递与多种机制相结合，包括基于最优传输的提升、方差缩减扩散和PAC-贝叶斯谱正则化，用于鲁棒的半监督节点分类。

**Result:** 在九个同配和异配基准测试上的实验表明，SGPC优于最先进的谱和基于束的GNNs，同时为未见节点提供了经过认证的置信区间。理论上，该方法建立了性能界限，并证明了由此产生的界限感知目标可以通过线性计算复杂度的端到端训练实现。

**Conclusion:** SGPC通过其创新的架构和机制，有效解决了GNN的过平滑问题以及现有束网络的局限性，实现了卓越的性能、理论保证和计算效率，使其成为半监督节点分类的强大工具。

> **ai_Abstract:** 本文提出了一种新颖的束图神经网络架构SGPC，旨在解决传统GNN的过平滑问题以及现有束网络在泛化、可扩展性和稳定性方面的局限性。SGPC结合了细胞束消息传递、最优传输提升、方差缩减扩散和PAC-贝叶斯谱正则化。该方法在理论上提供了性能界限，并实现了线性计算复杂度的端到端训练。实验结果表明，SGPC在同配和异配图数据集上均优于现有的谱和束基GNN模型，并能提供置信区间。

> **摘要翻译:** 图神经网络（GNNs）中的过平滑现象导致不同节点特征的崩溃，特别是在相邻节点通常具有不同标签的异配图上。尽管束神经网络部分缓解了这个问题，但它们通常依赖于静态或参数化过重的束结构，这阻碍了泛化和可扩展性。现有的基于束的模型要么预定义限制映射，要么引入过度的复杂性，却未能提供严格的稳定性保证。在本文中，我们引入了一种名为SGPC（Sheaf GNNs with PAC-Bayes Calibration）的新颖方案，这是一种统一的架构，将细胞束消息传递与多种机制相结合，包括基于最优传输的提升、方差缩减扩散和PAC-贝叶斯谱正则化，用于鲁棒的半监督节点分类。我们理论上建立了性能界限，并证明了由此产生的界限感知目标可以通过线性计算复杂度的端到端训练实现。在九个同配和异配基准测试上的实验表明，SGPC优于最先进的谱和基于束的GNNs，同时为未见节点提供了经过认证的置信区间。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability](https://arxiv.org/abs/2507.21004)
> *组合函数网络：一种具有内置可解释性的高性能深度神经网络替代方案*

*Fang Li* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 组合函数网络, 可解释性, 深度学习, 数学函数, 梯度下降

**Comment:** The project has been open sourced at Github
  (https://github.com/fanglioc/Compositional_Function_Networks)

> **TL;DR:** 组合函数网络（CFNs）是一种新型的可解释模型框架，通过组合基本数学函数来构建，旨在提供与深度神经网络（DNNs）竞争的性能，同时保持透明度，并且支持多种组合模式，可通过梯度下降有效训练。

**AI_Comments:** CFNs的创新之处在于其结合了深度学习的复杂建模能力和数学函数的固有可解释性，通过可微分的组合结构实现了端到端的训练。这对于高风险领域（如医疗、金融）的应用具有重要意义，因为这些领域对模型透明度和决策依据有严格要求。其支持多种组合模式，而非仅限于加性结构，也增强了其表达能力。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNNs）性能优异，但其“黑箱”性质限制了它们在需要透明度的高风险领域的部署。

**Method:** 本文引入了组合函数网络（CFNs），这是一种通过组合具有清晰语义的基本数学函数来构建固有可解释模型的新颖框架。CFNs支持序列、并行和条件等多种组合模式，能够处理复杂的特征交互。CFNs是完全可微分的，因此可以通过标准梯度下降进行高效训练。

**Result:** CFNs在多个领域（从符号回归到图像分类）展示了其多功能性。经验评估表明，CFNs在与黑箱模型竞争的同时取得了有竞争力的性能（CIFAR-10上达到96.24%的准确率），并且优于最先进的可解释模型（如可解释提升机）。

**Conclusion:** 组合函数网络（CFNs）通过结合深度学习的层次表达能力和高效训练与明确定义数学函数的内在可解释性，为性能和可解释性都至关重要的应用提供了一个强大的框架。

> **ai_Abstract:** 本文提出了组合函数网络（CFNs），这是一种新型的可解释机器学习框架，旨在解决深度神经网络（DNNs）的黑箱问题。CFNs通过组合具有明确语义的基本数学函数来构建模型，支持多种复杂的组合模式（序列、并行、条件），从而实现复杂的特征交互。该框架完全可微分，可使用梯度下降高效训练。实验证明，CFNs在保持透明度的同时，在性能上可与黑箱模型竞争，并在可解释性方面优于现有最先进的可解释模型，为需要高性能和高可解释性的应用提供了强大工具。

> **摘要翻译:** 深度神经网络（DNNs）表现出令人印象深刻的性能，但其黑箱性质限制了它们在需要透明度的高风险领域的部署。我们引入了组合函数网络（CFNs），这是一种通过组合具有清晰语义的基本数学函数来构建固有可解释模型的新颖框架。与现有的限于简单加性结构的可解释方法不同，CFNs支持多样化的组合模式——序列、并行和条件——从而实现复杂的特征交互，同时保持透明度。一个关键创新是CFNs是完全可微分的，允许通过标准梯度下降进行高效训练。我们展示了CFNs在多个领域的多功能性，从符号回归到使用深度分层网络的图像分类。我们的经验评估表明，CFNs在与黑箱模型竞争的同时取得了有竞争力的性能（在CIFAR-10上达到96.24%的准确率），同时优于最先进的可解释模型，如可解释提升机。通过结合深度学习的层次表达能力和高效训练与明确定义数学函数的内在可解释性，CFNs为性能和可解释性都至关重要的应用提供了一个强大的框架。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [390] [Insights into Closed-form IPM-GAN Discriminator Guidance for Diffusion Modeling](https://arxiv.org/abs/2306.01654)
> *深入理解闭式IPM-GAN判别器指导扩散模型*

*Aadithya Srikanth, Siddarth Asokan, Nishanth Shetty, Chandra Sekhar Seelamantula* | **Category: cs.LG, cs.CV, stat.ML** | **Updated: 2025-07-31**

**Keywords:** 扩散模型, GAN, 判别器指导, 分数匹配, IPM

**Comment:** 

> **TL;DR:** 本文从理论上分析了GAN判别器如何指导扩散模型，揭示了IPM-GAN优化与平滑分数匹配的关系，并提出了一种闭式核基判别器指导方法，在多种扩散模型上显著提升了生成质量。

**AI_Comments:** 本文的创新点在于为GAN判别器指导扩散模型这一经验现象提供了坚实的理论基础，并通过将IPM-GAN优化与平滑分数匹配联系起来，实现了对两种重要生成模型范式的统一。这不仅加深了我们对扩散模型生成机制的理解，也为未来设计更高效、更高质量的生成模型提供了新的理论指导和实践方向。其提出的闭式核基判别器指导在实践中展现出显著的性能提升，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 经验研究表明，使用GAN判别器指导扩散模型可以提高生成质量，但其背后的理论机制尚不明确。本文旨在提供一个理论框架来分析GAN判别器对Langevin采样扩散模型的影响。

**Method:** 本文提出了一个理论框架来分析GAN判别器对基于Langevin采样的影响，并证明IPM-GAN的优化可以看作是平滑分数匹配的一种形式，其中数据和生成器分布的分数与IPM相关的核函数进行卷积。此方法统一了基于分数的训练和IPM-GAN的优化。

**Result:** 研究表明，基于闭式核的判别器指导可以显著改善基线扩散模型（如DDIM和LDM）的性能（通过CLIP-FID和KID指标衡量），并在各种标准数据集上得到验证。此外，该方法可以与现有加速扩散技术结合，以改进潜在空间图像生成。

**Conclusion:** 本文为GAN判别器指导扩散模型提供了理论见解，统一了基于分数的训练和IPM-GAN的优化方法。所提出的闭式核基判别器指导在实践中有效提升了扩散模型的生成质量和效率。

> **ai_Abstract:** 本文提出了一个理论框架，用于分析GAN判别器如何指导扩散模型中的Langevin采样。研究表明，IPM-GAN的优化可以被视为一种平滑分数匹配，从而统一了基于分数的训练和IPM-GAN的优化。基于这些理论见解，论文展示了闭式核基判别器指导能够显著提升基线扩散模型（如DDIM和LDM）的生成质量（通过CLIP-FID和KID指标衡量），并可在多种数据集上实现，且能与现有加速扩散技术结合以进一步优化潜在空间图像生成。

> **摘要翻译:** 扩散模型是一种最先进的生成建模框架，通过Langevin采样，在分数（即数据分布对数的梯度）的指导下，将噪声转化为图像。最近的研究经验性地表明，当由分类器网络（通常是在生成对抗网络（GAN）设置中训练的判别器）指导时，生成质量可以得到改善。在本文中，我们提出了一个理论框架来分析GAN判别器对基于Langevin采样模型的影响，并表明IPM-GAN优化可以看作是平滑分数匹配的一种形式，其中数据和生成器分布的分数与IPM相关的核函数进行卷积。所提出的方法旨在统一基于分数的训练和IPM-GAN的优化。基于这些见解，我们证明了闭式核基判别器指导在应用于基线扩散模型时，能带来性能提升（在CLIP-FID和KID指标方面）。我们在去噪扩散隐式模型（DDIM）和潜在扩散模型（LDM）设置上，在各种标准数据集上验证了这些结果。我们还表明，所提出的方法可以与现有加速扩散技术结合，以改善潜在空间图像生成。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [396] [Continual Learning with Synthetic Boundary Experience Blending](https://arxiv.org/abs/2507.23534)
> *持续学习与合成边界经验融合*

*Chih-Fan Hsu, Ming-Ching Chang, Wei-Chao Chen* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 持续学习, 经验回放, 合成边界数据, 决策边界, 差分隐私

**Comment:** 

> **TL;DR:** 提出“经验融合”框架，通过生成合成边界数据，稳定决策边界，有效缓解持续学习中的灾难性遗忘问题。

**AI_Comments:** 该论文通过引入“合成边界数据”来增强经验回放，解决了传统方法中决策边界过于简化的问题，具有创新性。其利用差分隐私噪声机制生成SBD的思路独特，且实验结果显示出显著的性能提升，对持续学习领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 持续学习（CL）中存在灾难性遗忘问题，且经验回放方法因存储关键样本分布稀疏，导致决策边界过于简化，限制了其有效性。

**Method:** 本文提出了一种新颖的“经验融合”训练框架，旨在通过整合存储的关键样本和合成的边界附近数据来解决持续学习中的灾难性遗忘。该框架包含两个核心组件：1) 一种多元差分隐私（DP）噪声机制，用于向低维特征表示注入批次噪声以生成合成边界数据（SBD）；2) 一种端到端训练策略，共同利用存储的关键样本和SBD。

**Result:** 在CIFAR-10、CIFAR-100和Tiny ImageNet数据集上进行的广泛实验表明，该方法优于九个持续学习基线，准确率分别提高了10%、6%和13%。

**Conclusion:** 通过在训练中引入合成边界数据（SBD）作为隐式正则化器，并将其与存储的关键样本相结合，能够有效稳定决策边界，从而显著减轻持续学习中的灾难性遗忘并提高模型性能。

> **ai_Abstract:** 本文提出了一种名为“经验融合”的新型持续学习框架，旨在解决模型在多任务顺序训练中的灾难性遗忘问题。该框架通过生成决策边界附近的合成数据（SBD）并将其与传统经验回放的关键样本相结合进行训练，以稳定决策边界。具体方法包括利用多元差分隐私噪声机制生成SBD，并采用端到端策略共同利用这两种数据。实验结果表明，该方法在多个基准数据集上显著优于现有持续学习方法，实现了显著的准确率提升。

> **摘要翻译:** 持续学习（CL）旨在解决模型在多个任务上顺序训练时出现的灾难性遗忘问题。虽然经验回放已显示出前景，但其有效性常受限于存储关键样本的稀疏分布，导致决策边界过于简化。我们假设在训练过程中引入决策边界附近的合成数据（合成边界数据，SBD）可作为一种隐式正则化器，从而提高边界稳定性并减轻遗忘。为了验证这一假设，我们提出了一种新颖的训练框架——“经验融合”，该框架整合了来自存储关键样本和合成的边界附近数据的知识。经验融合包含两个核心组件：(1) 一种多元差分隐私（DP）噪声机制，它向低维特征表示注入批次噪声，生成SBD；(2) 一种端到端训练策略，共同利用存储的关键样本和SBD。在CIFAR-10、CIFAR-100和Tiny ImageNet上进行的大量实验表明，我们的方法优于九个持续学习基线，准确率分别提高了10%、6%和13%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [398] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
> *OID-PPO：通过将设计指南转化为奖励函数进行近端策略优化实现最佳室内设计*

*Chanyoung Yoon, Sangbong Yoo, Soobin Yim, Chansoo Kim, Yun Jang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 室内设计, 强化学习, 近端策略优化, 奖励函数, 家具布局

**Comment:** 

> **TL;DR:** OID-PPO是一种新的强化学习框架，它通过将设计指南转化为奖励函数，实现了连续且高效的室内家具布局优化，性能优于现有方法。

**AI_Comments:** OID-PPO的创新之处在于将复杂的室内设计指南转化为可学习的强化学习奖励函数，并实现了连续的家具放置，这克服了传统RL方法离散动作空间的限制。其重要性在于提供了一种高效、高质量的自动化室内设计方案，减轻了对专家知识的依赖，并降低了计算成本。

<details>
  <summary>Details</summary>

**Motivation:** 设计住宅室内空间对居住者满意度影响深远但极具挑战性，现有优化或深度学习方法计算成本高昂或受数据稀缺限制，而现有强化学习方法则将家具放置限制在离散位置且未能充分整合设计原则。

**Method:** 提出OID-PPO，一个基于近端策略优化（PPO）的新型强化学习框架。该方法将专家定义的功能和视觉指南整合到结构化奖励函数中，并利用对角高斯策略实现连续灵活的家具放置，有效探索部分可观察环境下的潜在环境动态。

**Result:** 在不同房间形状和家具配置下进行的实验表明，OID-PPO在布局质量和计算效率方面显著优于现有最先进方法。消融研究进一步证明了结构化指南整合的有效性以及各个设计约束的独特贡献。

**Conclusion:** OID-PPO通过将设计指南整合为奖励函数并使用连续动作空间，能够有效解决室内设计中的挑战，生成高质量且计算高效的布局。

> **ai_Abstract:** 本文提出了OID-PPO，一个基于近端策略优化（PPO）的新型强化学习框架，旨在解决室内设计中家具布局的挑战。它通过将专家定义的功能和视觉设计指南转化为结构化奖励函数，并采用对角高斯策略实现连续家具放置。实验证明，OID-PPO在布局质量和计算效率上优于现有方法，并能有效整合设计约束。

> **摘要翻译:** 设计住宅室内空间对居住者满意度影响深远，但由于非结构化空间布局、高计算需求和对专家知识的依赖，仍然极具挑战性。现有基于优化或深度学习的方法要么计算成本高昂，要么受数据稀缺的限制。强化学习（RL）方法通常将家具放置限制在离散位置，并且未能充分整合设计原则。我们提出了OID-PPO，一个用于最佳室内设计（Optimal Interior Design）的新型RL框架，它利用近端策略优化（Proximal Policy Optimization），将专家定义的功能和视觉指南整合到结构化奖励函数中。OID-PPO利用对角高斯策略实现连续灵活的家具放置，有效探索部分可观察环境下的潜在环境动态。在不同房间形状和家具配置下进行的实验表明，OID-PPO在布局质量和计算效率方面显著优于现有最先进的方法。消融研究进一步证明了结构化指南整合的影响，并揭示了各个设计约束的独特贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [400] [Transparent AI: The Case for Interpretability and Explainability](https://arxiv.org/abs/2507.23535)
> *透明人工智能：可解释性和可解释性的案例*

*Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval* | **Category: cs.LG, cs.AI, cs.CY** | **Updated: 2025-07-31**

**Keywords:** 透明人工智能, 可解释性, 可信赖AI, 实施指导, 设计原则

**Comment:** 

> **TL;DR:** 本文强调了透明度对于负责任和可信赖的人工智能至关重要，并提供了将可解释性作为核心设计原则而非事后补充的实用策略和实施指导。

**AI_Comments:** 本文强调了在AI系统设计初期就融入可解释性的重要性，而不是将其作为事后补救措施，这对于构建可信赖和负责任的AI具有重要的指导意义和创新性。它从实践经验出发，为不同AI成熟度的组织提供了具体的实施策略。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能系统越来越多地影响各领域的高风险决策，透明度已成为负责任和可信赖的人工智能实施的基础。本文旨在分享将可解释性作为核心设计原则而非事后补充的实践经验和指导。

**Method:** 本文通过在一个领先研究机构的角色，从实践中的可解释性应用中总结并提出了关键见解、经验教训、可操作的策略和实施指导。

**Result:** 本文提供了针对不同AI成熟度阶段组织的实用策略和实施指导，强调将可解释性作为核心设计原则进行整合。

**Conclusion:** 结论是，可解释性应被视为人工智能的核心设计原则，而不是事后附加的补充，这对于负责任和可信赖的AI实施至关重要。

> **ai_Abstract:** 本文探讨了透明人工智能的重要性，尤其是在高风险决策场景中。作者基于其作为领先研究机构的经验，提供了在实际应用中实现可解释性的关键见解、经验教训、实用策略和实施指导，并强调应将可解释性作为AI设计的核心原则。

> **摘要翻译:** 随着人工智能系统越来越多地影响各领域的高风险决策，透明度已成为负责任和可信赖的人工智能实施的基础。作为在推进人工智能研究和促进行业应用方面处于领先地位的机构，我们展示了从不同领域实际可解释性应用中获得的关键见解和经验教训。本文为处于不同人工智能成熟度阶段的组织提供了可操作的策略和实施指导，强调将可解释性作为核心设计原则而非事后附加的补充进行整合。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [411] [MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse](https://arxiv.org/abs/2507.21433)
> *MemShare：通过KV缓存重用实现大型推理模型的高效内存推理*

*Kaiwen Chen, Xin Tan, Minchen Yu, Hong Xu* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** KV缓存重用, 大型推理模型, 内存效率, 推理优化, 协同过滤

**Comment:** 11 pages, 7 figures

> **TL;DR:** MemShare通过重用KV缓存块，显著降低大型推理模型的内存开销并提高吞吐量，同时保持准确性。

**AI_Comments:** MemShare的创新点在于发现了大型推理模型中KV缓存的相似性并利用协同过滤算法进行重用，有效解决了内存瓶颈，对提高大型模型推理效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型推理模型（LRMs）在数学推理和形式逻辑任务中取得了显著进展，但其生成冗长的思维链序列导致推理过程中巨大的内存开销。研究观察到LRMs经常产生高度相似的中间推理步骤，这对应于跨层相似的KV缓存状态。

**Method:** MemShare提出了一种新颖的KV缓存管理方法，采用协同过滤算法高效识别可重用的KV缓存块，并实现零拷贝缓存重用，以显著减少内存开销。

**Result:** 实验结果表明，MemShare在保持更好准确性的同时，吞吐量提升高达84.79%，优于现有KV缓存管理方法。

**Conclusion:** MemShare通过高效的KV缓存重用，有效解决了大型推理模型内存开销大的问题，显著提高了推理吞吐量并保持了准确性。

> **ai_Abstract:** MemShare是一种针对大型推理模型（LRMs）的KV缓存管理新方法，旨在解决其推理过程中由于生成冗长思维链序列而导致的巨大内存开销。该方法基于LRMs中间推理步骤中KV缓存状态相似的观察，通过协同过滤算法识别并重用KV缓存块，实现零拷贝缓存重用。实验证明，MemShare在显著提升吞吐量（高达84.79%）的同时，能保持甚至提高推理准确性。

> **摘要翻译:** 大型推理模型（LRMs）在数学推理和形式逻辑任务中取得了显著进展。然而，它们生成冗长思维链序列的倾向导致推理过程中巨大的内存开销。我们观察到LRMs频繁产生高度相似的中间推理步骤，这对应于跨层相似的KV缓存状态。受此观察启发，我们提出了MemShare，一种新颖的KV缓存管理方法，可有效减少内存开销。MemShare采用协同过滤算法来高效识别可重用的KV缓存块，并实现零拷贝缓存重用，以显著减少内存开销，提高吞吐量，同时保持准确性。实验结果表明，与现有KV缓存管理方法相比，MemShare在保持更好准确性的同时，吞吐量提升高达84.79%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [417] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
> *双重适应性：最小化凸函数自适应遗憾的通用算法*

*Lijun Zhang, Wenhao Yang, Guanghui Wang, Wei Jiang, Zhi-Hua Zhou* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 自适应遗憾, 在线凸优化, 通用算法, 元专家框架, 双重适应性

**Comment:** arXiv admin note: text overlap with arXiv:1906.10851

> **TL;DR:** 本文提出了一种具有双重适应性的通用算法，通过元专家框架，解决了在线凸优化中最小化自适应遗憾算法缺乏通用性的问题，使其能自动适应不同的函数类型和动态环境。

**AI_Comments:** 本文的创新点在于提出了“双重适应性”的概念，并设计了一个元专家框架，解决了现有在线凸优化算法在函数类型和环境适应性方面的局限。其通用性使其在面对未知或动态变化的优化问题时更具潜力，具有重要的理论和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对不断变化的环境，在线学习中提出了自适应遗憾这一新的性能度量。然而，现有用于最小化自适应遗憾的算法缺乏通用性，它们只能处理特定类型的凸函数，并且需要参数的先验知识，这阻碍了它们在实际场景中的应用。

**Method:** 本文提出一个用于双重自适应算法的元专家框架，其中动态创建多个专家并由元算法聚合。该元算法需要产生一个二阶界以适应未知函数类型。进一步，引入休眠专家技术来捕捉变化的环境。为了构建专家，引入了两种策略：增加专家数量或增强专家能力，以实现通用性。

**Result:** 理论分析表明，所提出的算法能够同时最小化多种类型凸函数的自适应遗憾，并且允许函数类型在回合间切换。此外，将元专家框架扩展到在线复合优化，开发了用于最小化复合函数自适应遗憾的通用算法。

**Conclusion:** 本文提出的双重自适应通用算法有效解决了现有自适应遗憾最小化算法在函数类型和环境适应性方面的局限性，使其能应对不同类型的凸函数和动态环境，并成功扩展到复合优化领域。

> **ai_Abstract:** 针对在线学习中现有自适应遗憾最小化算法缺乏通用性的问题，本文提出了一种具有双重适应性的通用算法。该算法基于一个元专家框架，通过动态创建和聚合专家，并结合休眠专家技术，使其能够自动适应不同类型的凸函数（包括凸、指数凹或强凸）以及变化的在线环境。理论分析证明了算法在同时处理多种函数类型和允许函数类型切换方面的有效性，并成功将其扩展到在线复合优化领域。

> **摘要翻译:** 为了应对不断变化的环境，在线学习中提出了一种新的性能度量——自适应遗憾，其定义为任意区间上的最大静态遗憾。在在线凸优化的设置下，已经成功开发了几种算法来最小化自适应遗憾。然而，现有算法缺乏通用性，因为它们只能处理一种类型的凸函数，并且需要参数的先验知识，这阻碍了它们在实际场景中的应用。为了解决这一限制，本文研究了具有双重适应性的通用算法，这些算法能自动适应函数的性质（凸、指数凹或强凸）以及环境的性质（静态或变化）。具体来说，我们提出了一种用于双重自适应算法的元专家框架，其中动态创建多个专家并由元算法聚合。该元算法需要产生一个二阶界，以适应未知的函数类型。我们进一步结合了休眠专家技术来捕捉变化的环境。为了构建专家，我们引入了两种策略（增加专家数量或增强专家能力）来实现通用性。理论分析表明，我们的算法能够同时最小化多种类型凸函数的自适应遗憾，并且还允许函数类型在回合间切换。此外，我们将我们的元专家框架扩展到在线复合优化，并开发了一种用于最小化复合函数自适应遗憾的通用算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [418] [From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices](https://arxiv.org/abs/2507.23536)
> *从LLMs到边缘：边缘设备上的参数高效微调*

*Georg Slamanig, Francesco Corti, Olga Saukh* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 参数高效微调, 边缘设备, 卷积神经网络, LoRA, 计算效率

**Comment:** 

> **TL;DR:** 本文对边缘设备上使用的卷积神经网络中的参数高效微调（PEFT）方法进行了基准测试和分析，发现与LLMs相比，某些架构的内存效率较低，但浮点运算（FLOPs）可显著减少。

**AI_Comments:** 该论文通过将参数高效微调（PEFT）的研究从大型语言模型（LLM）扩展到边缘优化的卷积神经网络（CNN），解决了AI部署在资源受限环境中的一个关键空白。其对不同CNN架构在内存效率和浮点运算（FLOPs）方面的详细基准测试和具体发现，为实际应用提供了宝贵的见解。这项工作有助于使AI在边缘计算中更具可访问性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 参数高效微调（PEFT）方法在大型语言模型（LLM）中得到了广泛研究，但在边缘设备上使用的小型模型（如卷积神经网络）中的应用仍未得到充分探索。本文旨在解决在资源受限的边缘环境中更新模型时降低计算成本的需求。

**Method:** 本文对LoRA、DoRA和GaLore等流行的PEFT方法在标准和深度可分离卷积架构上进行了基准测试和分析，以处理分布偏移和适应未见类别。研究利用PyTorch分析器比较了这些PEFT方法与传统微调方法的更新模型性能和计算成本，并探讨了它们在不同秩维度上的更新行为。

**Result:** 研究发现，所评估的PEFT方法应用于深度可分离卷积架构时，内存效率仅为LLM的一半。然而，当针对为边缘部署优化的卷积架构时，基于适配器的PEFT方法在模型更新期间可以将浮点运算（FLOPs）减少高达95%。

**Conclusion:** 这些研究结果为根据硬件限制、性能要求和应用需求选择参数高效微调（PEFT）方法提供了宝贵的指导。

> **ai_Abstract:** 本文对用于资源受限边缘设备的卷积神经网络中的参数高效微调（PEFT）方法进行了基准测试和分析，填补了PEFT研究从大型语言模型（LLM）向小型边缘模型扩展的空白。研究评估了LoRA、DoRA和GaLore等方法在处理分布偏移和新类别时的性能和计算成本，并与传统微调进行了比较。主要发现包括，PEFT在深度可分离卷积架构上的内存效率不如LLM，但基于适配器的PEFT方法在针对边缘优化的卷积架构上可将浮点运算（FLOPs）减少高达95%。这些结果为根据特定硬件和应用需求选择PEFT方法提供了实用指导。

> **摘要翻译:** 参数高效微调（PEFT）方法通过最小化用于使模型适应下游任务的额外参数数量，从而降低更新深度学习模型的计算成本。尽管在大型语言模型（LLM）中得到了广泛研究，但它们在边缘设备上使用的小型模型（如卷积神经网络）中的应用仍未得到充分探索。本文对通常部署在资源受限边缘环境中的卷积架构上的流行PEFT方法进行了基准测试和分析。我们评估了LoRA、DoRA和GaLore用于更新标准和深度可分离卷积架构，以处理分布偏移和适应未见类别。我们利用最近提出的PyTorch分析器来比较这些PEFT方法与传统微调方法的更新模型性能和计算成本。考虑到资源效率，我们研究了它们在不同秩维度上的更新行为。我们发现，与LLM相比，所评估的PEFT方法应用于深度可分离卷积架构时，内存效率仅为一半。相反，当针对为边缘部署优化的卷积架构时，基于适配器的PEFT方法在模型更新期间可以将浮点运算（FLOPs）减少高达95%。这些见解为根据硬件限制、性能要求和应用需求选择PEFT方法提供了宝贵的指导。我们的代码已在线提供。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [423] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
> *ExeKGLib: 一个基于知识图谱的机器学习分析平台*

*Antonis Klironomos, Baifan Zhou, Zhipeng Tan, Zhuoxun Zheng, Mohamed H. Gad-Elrab, Heiko Paulheim, Evgeny Kharlamov* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 知识图谱, 机器学习管道, 图形界面, ExeKGLib, 可重用性

**Comment:** 

> **TL;DR:** ExeKGLib是一个Python库，通过知识图谱和图形界面，帮助非机器学习专家轻松构建和执行机器学习管道。

**AI_Comments:** ExeKGLib的创新之处在于其利用知识图谱将复杂的机器学习知识简化，并通过直观的图形界面提供给非专业用户，极大地降低了机器学习应用开发的门槛。这对于促进机器学习在更广泛的科学和工程领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习管道的开发复杂，需要专业知识和训练，而科学和工程领域的领域专家缺乏这些知识，但又迫切需要基于机器学习的分析。

**Method:** 本文提出了ExeKGLib，一个增强了图形界面层的Python库。它通过依赖知识图谱来编码机器学习知识，使其对非机器学习专家可访问，从而允许用户以最少的机器学习知识构建机器学习管道。

**Result:** ExeKGLib提高了构建的机器学习工作流的透明度和可重用性，并确保它们是可执行的。通过真实的用例展示了其可用性和实用性。

**Conclusion:** ExeKGLib成功地使非机器学习专家能够构建机器学习管道，提高了透明度和可重用性。

> **ai_Abstract:** 本文介绍了ExeKGLib，一个基于知识图谱和图形界面的Python库，旨在帮助缺乏机器学习专业知识的领域专家轻松构建和执行机器学习管道。通过将机器学习知识编码为简单易懂的知识图谱，ExeKGLib降低了机器学习工作流的开发门槛，同时提高了其透明度、可重用性和可执行性，并通过真实用例验证了其有效性。

> **摘要翻译:** 如今，机器学习(ML)从业者可以访问在线的众多ML库。这些库可用于创建ML管道，这些管道由一系列步骤组成，每个步骤可以调用多达几个ML库，用于各种数据驱动的分析任务。开发高质量的ML管道并非易事；它需要培训、ML专业知识以及每个步骤的精心开发。同时，科学和工程领域的领域专家可能不具备此类ML专业知识和培训，但他们迫切需要基于ML的分析。在本文中，我们提出了ExeKGLib，这是一个通过图形界面层增强的Python库，它允许具有最少ML知识的用户构建ML管道。这是通过依赖以简单术语编码ML知识的知识图谱实现的，这些知识图谱对非ML专家来说是可访问的。ExeKGLib还允许提高构建的ML工作流的透明度和可重用性，并确保它们是可执行的。我们通过展示真实的用例来展示ExeKGLib的可用性和实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [433] [DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data](https://arxiv.org/abs/2507.23676)
> *DepMicroDiff：基于扩散的依赖感知多模态微生物组数据插补*

*Rabeya Tus Sadia, Qiang Cheng* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 微生物组数据, 数据插补, 扩散模型, 依赖感知Transformer, 多模态

**Comment:** 

> **TL;DR:** DepMicroDiff是一种新的基于扩散的模型，通过捕获微生物依赖性和利用元数据，显著提高了微生物组数据的插补准确性，优于现有方法。

**AI_Comments:** DepMicroDiff的创新之处在于其将扩散模型与依赖感知Transformer结合，并融入多模态元数据（通过LLM编码），有效解决了微生物组数据插补中依赖关系捕获不足和上下文信息利用不充分的问题，为下游生物标志物发现等任务提供了更准确的数据基础。

<details>
  <summary>Details</summary>

**Motivation:** 微生物组数据分析对理解宿主健康和疾病至关重要，但其固有的稀疏性和噪声给准确插补带来了巨大挑战，阻碍了生物标志物发现等下游任务。现有插补方法，包括最近基于扩散的模型，未能捕获微生物分类群之间复杂的相互依赖关系，并忽视了可用于插补的上下文元数据。

**Method:** DepMicroDiff是一个新颖的框架，它结合了基于扩散的生成建模与依赖感知Transformer（DAT），以明确捕获相互成对依赖关系和自回归关系。DepMicroDiff通过在不同癌症数据集上进行基于VAE的预训练，并通过大型语言模型（LLM）编码的患者元数据进行条件化，进一步增强。

**Result:** 在TCGA微生物组数据集上的实验表明，DepMicroDiff显著优于最先进的基线方法，在多种癌症类型中实现了更高的皮尔逊相关系数（高达0.712）、余弦相似度（高达0.812），以及更低的RMSE和MAE，证明了其在微生物组插补方面的鲁棒性和泛化能力。

**Conclusion:** DepMicroDiff通过有效捕获微生物依赖性和利用元数据，显著提高了微生物组数据的插补准确性、鲁棒性和泛化能力。

> **ai_Abstract:** 本文介绍了DepMicroDiff，一种新颖的基于扩散的框架，用于微生物组数据的多模态插补。它通过结合依赖感知Transformer（DAT）捕捉微生物分类群间的复杂依赖关系，并利用VAE预训练和LLM编码的患者元数据进行增强。实验结果表明，DepMicroDiff在TCGA微生物组数据集上显著优于现有SOTA方法，在准确性、鲁棒性和泛化能力方面表现出色。

> **摘要翻译:** 微生物组数据分析对于理解宿主健康和疾病至关重要，但其固有的稀疏性和噪声给准确插补带来了重大挑战，阻碍了生物标志物发现等下游任务。现有的插补方法，包括最近基于扩散的模型，往往未能捕获微生物分类群之间复杂的相互依赖关系，并忽略了可为插补提供信息的上下文元数据。我们引入了DepMicroDiff，这是一个新颖的框架，它将基于扩散的生成建模与依赖感知Transformer（DAT）相结合，以明确捕获相互成对依赖关系和自回归关系。DepMicroDiff通过在不同癌症数据集上进行基于VAE的预训练，并通过大型语言模型（LLM）编码的患者元数据进行条件化，进一步增强。在TCGA微生物组数据集上的实验表明，DepMicroDiff显著优于最先进的基线方法，在多种癌症类型中实现了更高的皮尔逊相关系数（高达0.712）、余弦相似度（高达0.812），以及更低的RMSE和MAE，展示了其在微生物组插补方面的鲁棒性和泛化能力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [435] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
> *Co-Reward：通过对比一致性进行大语言模型推理的自监督强化学习*

*Zizhuo Zhang, Jianing Zhu, Xinmu Ge, Zihua Zhao, Zhanke Zhou, Xuan Li, Xiao Feng, Jiangchao Yao, Bo Han* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 自监督学习, 强化学习, 大型语言模型, 推理, 对比学习

**Comment:** 

> **TL;DR:** Co-Reward是一种新的自监督强化学习框架，通过在语义相似问题上利用对比一致性作为奖励，解决了大语言模型推理中RLVR的扩展问题和自奖励信号的崩溃问题，并在多个基准测试中取得了优异性能。

**AI_Comments:** Co-Reward的创新点在于将自监督学习中的对比一致性思想引入到强化学习的奖励机制中，有效解决了LLM推理中RLVR的扩展性瓶颈和自奖励的崩溃问题。这种无需人工标注的奖励塑造机制，对于降低LLM训练成本和提升推理稳定性具有重要意义，尤其是在复杂推理任务上表现出色，证明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管可验证奖励强化学习（RLVR）在提高大型语言模型（LLMs）的推理能力方面显示出前景，但由于对人工标注标签的依赖（尤其对于复杂任务），其扩展性仍然是一个难题。最近探索各种自奖励信号的替代方案展现了LLM推理的激发潜力，但存在不可忽视的崩溃问题。

**Method:** 我们提出了Co-Reward，一个新颖的RL框架，它利用语义相似问题之间的对比一致性作为奖励基础。具体来说，我们为每个训练样本（无标签）构建一个相似问题，并通过简单的rollout投票合成它们各自的代理标签，然后通过交叉引用每对问题的标签来构建奖励，以强制执行跨类比输入的内部推理一致性。这种自监督的奖励塑造机制增加了学习崩溃到琐碎解决方案的难度，并通过扩展输入样本变体促进了稳定的推理激发和改进。

**Result:** Co-Reward在多个推理基准和LLM系列上，与其他的自奖励基线相比，实现了卓越的性能，并达到了甚至超越了真实（GT）标签奖励，在Llama-3.2-3B-Instruct上的MATH500任务中，相对于GT奖励，性能提升高达+6.8%。

**Conclusion:** Co-Reward通过引入自监督的对比一致性作为奖励机制，有效解决了大语言模型推理中强化学习的扩展性和自奖励信号的崩溃问题，显著提升了模型在复杂推理任务上的性能，并有望替代对昂贵人工标注的依赖。

> **ai_Abstract:** Co-Reward是一个针对大型语言模型（LLMs）推理能力提升的自监督强化学习框架。它通过构建语义相似问题对，并利用它们之间的一致性作为奖励信号，克服了传统强化学习对人工标注的依赖以及自奖励方法中存在的崩溃问题。该方法通过强制内部推理一致性来稳定学习过程，并在多个推理基准测试中展现出优于现有自奖励基线甚至超越真实标签奖励的性能。

> **摘要翻译:** 尽管可验证奖励强化学习（RLVR）在提高大型语言模型（LLMs）的推理能力方面显示出前景，但由于对人工标注标签的依赖（尤其对于复杂任务），其扩展性仍然是一个难题。最近探索各种自奖励信号的替代方案展现了LLM推理的激发潜力，但存在不可忽视的崩溃问题。受自监督学习成功的启发，我们提出了Co-Reward，一个新颖的RL框架，它利用语义相似问题之间的对比一致性作为奖励基础。具体来说，我们为每个训练样本（无标签）构建一个相似问题，并通过简单的rollout投票合成它们各自的代理标签，然后通过交叉引用每对问题的标签来构建奖励，以强制执行跨类比输入的内部推理一致性。直观地，这种自监督的奖励塑造机制增加了学习崩溃到琐碎解决方案的难度，并通过扩展输入样本变体促进了稳定的推理激发和改进。经验上，Co-Reward在多个推理基准和LLM系列上，与其他的自奖励基线相比，实现了卓越的性能，并达到了甚至超越了真实（GT）标签奖励，在Llama-3.2-3B-Instruct上的MATH500任务中，相对于GT奖励，性能提升高达+6.8%。我们的代码已在https://github.com/tmlr-group/Co-Reward 公开。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [446] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
> *基于能量感知图神经扩散的大规模城市网络动态预测*

*Tong Nie, Jian Sun, Wei Ma* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 城市网络, 动态预测, 图神经网络, Transformer, 可扩展性

**Comment:** Accepted at IEEE Transactions on Industrial Informatics

> **TL;DR:** 本文提出了一种名为ScaleSTF的线性复杂度时空Transformer模型，通过借鉴物理定律来解决大规模城市网络动态预测中现有图神经网络的效率与效果权衡问题，并在交通流、太阳能和智能电表等大规模城市系统上验证了其最先进的性能和卓越的可扩展性。

**AI_Comments:** 该论文的创新点在于将物理定律的启发融入到图神经网络的设计中，以解决大规模城市网络动态预测中的效率与效果权衡问题。通过引入线性复杂度的Transformer结构，显著提升了模型的可扩展性，使其能够有效处理大规模数据。这种结合领域知识（物理定律）与先进神经网络架构（Transformer）的方法，为复杂系统建模提供了新的思路，具有重要的研究价值和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前用于预测城市系统时空动态的数据驱动模型（如图神经网络）在效率和效果之间存在权衡，计算需求高，难以应用于大规模网络。

**Method:** 本文提出了一种可扩展的时空Transformer（ScaleSTF），其灵感来源于物理定律，以避免架构冗余并与基本原理对齐。该模型基于Transformer类结构，其注意力层由低维嵌入诱导，具有线性复杂度。

**Result:** ScaleSTF在交通流、太阳能和智能电表等大规模城市系统上得到了验证，显示出最先进的性能和卓越的可扩展性。

**Conclusion:** 本文提出的ScaleSTF为大规模城市网络中的动态预测提供了一个新的视角，通过结合物理定律和Transformer结构，有效解决了现有方法的效率与效果权衡问题，并实现了高性能和高可扩展性。

> **ai_Abstract:** 本文针对大规模城市网络动态预测中现有图神经网络的效率与效果权衡问题，提出了一种名为ScaleSTF（可扩展时空Transformer）的新模型。该模型借鉴物理定律，采用Transformer类结构，其注意力层由低维嵌入诱导，具有线性复杂度。ScaleSTF在交通流、太阳能和智能电表等大规模城市系统上实现了最先进的性能和卓越的可扩展性，为城市网络动态预测提供了新的解决方案。

> **摘要翻译:** 联网的城市系统促进了人员、资源和服务的流动，对经济和社会互动至关重要。这些系统通常涉及具有未知控制规则的复杂过程，通过基于传感器的时序数据进行观测。为了辅助工业和工程领域的决策，数据驱动的预测模型被用于预测城市系统的时空动态。当前的模型，如图神经网络，已显示出前景，但由于计算需求面临效率和效果之间的权衡。因此，它们在大规模网络中的应用仍需进一步努力。本文通过借鉴物理定律来指导基本模型设计，使其与基本原理保持一致并避免架构冗余，从而解决了这种权衡挑战。通过理解微观和宏观过程，我们提出了一种基于Transformer类结构的、具有原理可解释性的神经扩散方案，其注意力层由低维嵌入诱导。所提出的具有线性复杂度的可扩展时空Transformer（ScaleSTF）在包括交通流、太阳能和智能电表在内的大规模城市系统上得到了验证，显示出最先进的性能和卓越的可扩展性。我们的结果为大规模城市网络中的动态预测提供了一个新的视角。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [447] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
> *变革信用风险分析：一种时间序列驱动的ResE-BiLSTM框架用于贷后违约检测*

*Yue Yang, Yuxiang Lin, Ying Zhang, Zihan Su, Chang Chuan Goh, Tangtangfang Fang, Anthony Graham Bellotti, Boon Giin Lee* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 信用风险分析, 贷后违约检测, ResE-BiLSTM, 时间序列, 机器学习

**Comment:** 

> **TL;DR:** 本研究提出了一种名为ResE-BiLSTM的新模型，用于贷后违约检测，并在Freddie Mac抵押贷款数据集上表现优于基线模型。

**AI_Comments:** 该论文提出了一种创新的ResE-BiLSTM模型，结合了残差连接和双向LSTM的优势，并应用于时间序列数据的贷后违约检测，这在金融风险管理领域具有重要意义。通过详尽的基线模型比较、消融研究和SHAP可解释性分析，增强了研究的严谨性和模型的说服力。

<details>
  <summary>Details</summary>

**Motivation:** 贷后违约预测是信用风险管理中的一项重要任务，可以通过机器学习进行金融异常检测来解决。

**Method:** 本研究引入了ResE-BiLSTM模型，采用滑动窗口技术，并在Freddie Mac美国抵押贷款数据集的44个独立队列上进行评估。将ResE-BiLSTM与LSTM、BiLSTM、GRU、CNN和RNN等五种基线模型在准确率、精确率、召回率、F1和AUC等多个指标上进行比较。还进行了消融研究以评估ResE-BiLSTM架构中各个组件的贡献。此外，使用SHAP分析来解释模型预测所依赖的底层特征。

**Result:** 实验结果表明，与基线模型相比，ResE-BiLSTM取得了卓越的预测性能。

**Conclusion:** ResE-BiLSTM模型在贷后违约检测中表现出优越的预测性能，凸显了其在实际场景中的实用价值和适用性。

> **ai_Abstract:** 本研究提出了一种时间序列驱动的ResE-BiLSTM框架，用于贷后违约检测。该模型在Freddie Mac美国抵押贷款数据集上进行了评估，并与多种基线模型进行比较，在准确率、精确率、召回率、F1和AUC等指标上均表现出卓越的预测性能。研究还通过消融研究和SHAP分析，深入探讨了模型组件的贡献和特征解释。

> **摘要翻译:** 贷后违约预测是信用风险管理中的一项重要任务，可以通过使用机器学习检测金融异常来解决。本研究引入了一种ResE-BiLSTM模型，使用滑动窗口技术，并在Freddie Mac美国抵押贷款数据集的44个独立队列上进行评估，以提高预测性能。ResE-BiLSTM与五种基线模型（长短期记忆网络（LSTM）、双向长短期记忆网络（BiLSTM）、门控循环单元（GRU）、卷积神经网络（CNN）和循环神经网络（RNN））在多个指标上进行了比较，包括准确率、精确率、召回率、F1和AUC。进行了一项消融研究，以评估ResE-BiLSTM架构中各个组件的贡献。此外，还采用SHAP分析来解释模型预测所依赖的底层特征。实验结果表明，与基线模型相比，ResE-BiLSTM取得了卓越的预测性能，强调了其在实际场景中的实用价值和适用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [451] [Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic](https://arxiv.org/abs/2507.22174)
> *用于非马尔可夫流量网络路由的时空强化学习*

*Molly Wang, Kin. K Leung* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 时空强化学习, 网络路由, 非马尔可夫流量, 深度强化学习, 网络拓扑

**Comment:** 

> **TL;DR:** 本文提出了一种时空强化学习（STRL）框架，用于处理非马尔可夫流量的网络路由问题，其性能优于传统基线。

**AI_Comments:** 本文的创新点在于提出了一个时空强化学习框架，专门解决了网络路由中非马尔可夫流量的现实问题，并考虑了网络拓扑的空间结构。其重要性在于提升了复杂网络环境下路由决策的效率和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习（RL）方法在网络路由中依赖于马尔可夫假设，但实际互联网流量是非马尔可夫的，并且历史状态会影响路由性能。此外，常见的深度RL方法未对网络拓扑中的空间结构进行建模。

**Method:** 设计了一个具有非马尔可夫流量的网络环境，并引入了一个时空强化学习（STRL）框架用于数据包路由。

**Result:** 与传统基线相比，该方法在训练期间性能提升超过19%，在拓扑结构变化的情况下，推理性能提升7%。

**Conclusion:** 本文提出的时空强化学习（STRL）框架能够有效解决非马尔可夫流量下的网络路由问题，并显著优于传统方法，即使在网络拓扑发生变化时也能保持性能。

> **ai_Abstract:** 本文针对传统强化学习在网络路由中面临的非马尔可夫流量和空间结构建模不足的问题，提出了一种时空强化学习（STRL）框架。该框架在一个非马尔可夫流量环境下进行设计，并被证明在训练和推理阶段均显著优于传统基线方法，即使在网络拓扑发生变化时也能保持性能优势。

> **摘要翻译:** 强化学习（RL）已广泛应用于通信网络中的数据包路由，但传统的RL方法依赖于马尔可夫假设，即当前状态包含决策所需的所有必要信息。实际上，互联网流量是非马尔可夫的，并且过去的状态确实会影响路由性能。此外，常见的深度RL方法使用函数逼近器（例如神经网络），但它们不模拟网络拓扑中的空间结构。为了解决这些缺点，我们设计了一个具有非马尔可夫流量的网络环境，并引入了一个时空强化学习（STRL）框架用于数据包路由。尽管网络拓扑发生了变化，我们的方法在训练期间仍比传统基线高出19%以上，在推理方面高出7%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [466] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
> *一种用于表格数据生成的条件GAN，具有潜在子空间的概率采样*

*Leonidas Akritidis, Panayiotis Bozanis* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 条件GAN, 表格数据生成, 类别不平衡, 概率采样, 潜在子空间

**Comment:** 

> **TL;DR:** ctdGAN是一种条件GAN，通过空间划分和概率采样在表格数据中生成高保真样本，以解决类别不平衡问题并提高分类精度。

**AI_Comments:** ctdGAN的创新之处在于其考虑了输入样本的向量子空间，并通过空间划分、新颖的概率采样策略以及结合聚类和类别误预测的新损失函数来指导数据生成，从而解决了现有GAN在表格数据生成中存在的关键问题。此外，引入的聚类加权缩放技术也提升了模型捕获复杂数据模式的能力。该研究对于处理表格数据中的类别不平衡问题具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据普遍存在类别不平衡问题，导致机器学习任务性能严重下降。现有GAN模型在生成数据时未考虑输入样本的向量子空间，导致数据生成位置随意，且类标签在训练中被视为普通类别变量，使得条件采样效果不佳。

**Method:** 本文提出了ctdGAN，一种用于缓解表格数据集中类别不平衡的条件GAN。ctdGAN首先执行空间划分步骤，为输入样本分配聚类标签。随后，利用这些标签通过新颖的概率采样策略和惩罚聚类及类别误预测的新损失函数来合成样本。此外，还引入了其他改进，包括一种简单有效的聚类加权缩放技术，可在不影响数据维度的情况下捕获多种特征模式。

**Result:** 通过对14个不平衡数据集的详尽评估，ctdGAN在生成高保真样本和提高分类准确性方面表现出优越性。

**Conclusion:** ctdGAN通过考虑数据子空间、采用概率采样和新的损失函数，有效解决了表格数据中的类别不平衡问题，能够生成高保真样本并显著提高分类性能。

> **ai_Abstract:** 本研究提出了一种名为ctdGAN的条件生成对抗网络，旨在解决表格数据中普遍存在的类别不平衡问题。针对现有GAN模型未考虑数据子空间及条件采样效率低下的缺陷，ctdGAN引入了空间划分步骤来分配聚类标签，并通过新颖的概率采样策略和惩罚聚类与类别误预测的损失函数来合成高保真样本。此外，还包含一项捕获多特征模式的聚类加权缩放技术。实验结果表明，ctdGAN在生成高质量样本和提升分类准确性方面优于现有方法。

> **摘要翻译:** 表格形式是关系数据库系统和电子表格中表示数据的标准方式。但是，与其他形式类似，表格数据也存在类别不平衡问题，这个问题在各种机器学习任务中会导致严重的性能下降。最有效的解决方案之一是使用生成对抗网络（GAN）来合成欠表示类的人工数据实例。尽管它们表现良好，但目前提出的GAN模型都没有考虑真实数据空间中输入样本的向量子空间，导致数据在任意位置生成。此外，在训练过程中，类标签与其他分类变量以相同的方式处理，因此按类进行的条件采样效果不佳。为了克服这些问题，本研究提出了ctdGAN，一个用于缓解表格数据集中类别不平衡的条件GAN。最初，ctdGAN执行一个空间划分步骤，为输入样本分配聚类标签。随后，它利用这些标签通过新颖的概率采样策略和惩罚聚类及类别误预测的新损失函数来合成样本。通过这种方式，ctdGAN被训练成在类似于原始数据分布的子空间中生成样本。我们还引入了其他几项改进，包括一种简单而有效的聚类加权缩放技术，可以在不影响数据维度的情况下捕获多种特征模式。对ctdGAN在14个不平衡数据集上的详尽评估表明，它在生成高保真样本和提高分类准确性方面具有优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [468] [InfAlign: Inference-aware language model alignment](https://arxiv.org/abs/2412.19792)
> *InfAlign：推理感知语言模型对齐*

*Ananth Balashankar, Ziteng Sun, Jonathan Berant, Jacob Eisenstein, Michael Collins, Adrian Hutter, Jong Lee, Chirag Nagpal, Flavien Prost, Aradhana Sinha, Ananda Theertha Suresh, Ahmad Beirami* | **Category: cs.LG, cs.CL, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 语言模型对齐, 推理感知, 强化学习人类反馈, 奖励变换, Best-of-N

**Comment:** 

> **TL;DR:** InfAlign提出了一种推理感知对齐框架，解决了语言模型对齐中训练与推理不匹配的问题，通过奖励变换优化推理时胜率，并在特定场景下实现了显著提升。

**AI_Comments:** InfAlign的创新之处在于它明确解决了语言模型对齐中训练与推理时的“失配”问题，这在当前广泛使用复杂解码策略的背景下尤为重要。通过理论证明奖励变换的有效性并提出实用的InfAlign-CTRL算法，该工作为提升语言模型在实际应用中的表现提供了坚实的基础和显著的改进。其对推理时胜率的关注，使其更贴近实际部署需求。

<details>
  <summary>Details</summary>

**Motivation:** 现代生成式语言模型越来越多地使用推理时算法（如Best-of-N、受控解码、树搜索）进行解码，而非标准采样。研究表明，这种训练/测试不匹配导致标准的RLHF（强化学习人类反馈）框架在面对此类推理时方法时表现不佳，因此需要一种推理感知的对齐方法来优化推理时胜率。

**Method:** 本文提出了一个名为InfAlign的推理感知对齐框架，旨在优化对齐策略相对于基础模型的推理时胜率。研究证明，对于任何推理时解码过程，最优对齐策略是标准RLHF问题通过奖励变换后的解。基于此，提出了calibrate-and-transform RL (InfAlign-CTRL) 算法来解决此问题，该算法包括奖励校准步骤和结合校准奖励变换的KL正则化奖励最大化步骤。

**Result:** 对于Best-of-N采样和Best-of-N越狱场景，InfAlign提出了特定的奖励变换，实现了推理时胜率高达3-8%的提升。此外，所提出的奖励校准方法也被证明是优化标准胜率的一个强基线。

**Conclusion:** InfAlign框架通过引入推理感知对齐和奖励变换，有效解决了语言模型对齐中训练与推理不匹配的问题，显著提升了模型在实际推理场景下的表现，并为未来对齐研究提供了新的方向和强大的基线方法。

> **ai_Abstract:** 该论文提出了InfAlign，一个推理感知语言模型对齐框架，旨在解决现代语言模型训练中RLHF与实际推理时解码算法（如Best-of-N）之间的不匹配问题。作者证明，最优对齐策略是标准RLHF问题经过奖励变换后的解，并据此提出了InfAlign-CTRL算法。该算法包含奖励校准和KL正则化奖励最大化步骤。实验结果表明，在Best-of-N采样和越狱场景中，InfAlign可将推理时胜率提升3-8%，且其奖励校准方法在优化标准胜率方面表现出色。

> **摘要翻译:** 语言模型对齐是训练现代生成式语言模型的关键一步。对齐旨在提高对齐模型样本相对于基础模型的胜率。如今，我们越来越多地使用推理时算法（例如，N中选优、受控解码、树搜索）从语言模型进行解码，而不是标准采样。我们发现这种训练/测试不匹配使得标准的RLHF（强化学习人类反馈）框架在面对此类推理时方法时表现不佳。为此，我们提出了一个推理感知对齐框架（InfAlign），旨在优化对齐策略相对于基础模型的推理时胜率。我们证明，对于任何推理时解码过程，最优对齐策略是标准RLHF问题通过奖励变换后的解。这促使我们提供了校准-变换强化学习（InfAlign-CTRL）算法来解决这个问题，该算法包括一个奖励校准步骤和一个结合校准奖励变换的KL正则化奖励最大化步骤。对于N中选优采样和N中选优越狱，我们提出了特定的变换，可将推理时胜率提高3-8%。最后，我们还表明，我们提出的奖励校准方法是优化标准胜率的一个强基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [472] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
> *LLM 法庭：通过多LLM协作进行证据增强生成，用于文本属性图异常检测*

*Yiming Xu, Jiarun Chen, Zhen Peng, Zihan Chen, Qika Lin, Lan Ma, Bin Shi, Bo Dong* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 文本属性图, 异常检测, 大型语言模型, 图神经网络, 多模态融合

**Comment:** Accepted by ACM Multimedia 2025 (MM '25)

> **TL;DR:** CoLL是一个新颖的框架，结合LLM和GNN，通过多LLM协作进行证据增强生成，以改进文本属性图（TAG）异常检测，并提供可读的异常解释。

**AI_Comments:** 本文提出了一种新颖的框架CoLL，通过结合LLM的语义理解能力和GNN的结构编码能力，解决了文本属性图异常检测中文本模态利用不足和LLM难以处理高阶图结构的问题。其创新点在于引入了多LLM协作进行证据增强生成，不仅提高了检测性能，还提供了人类可读的异常解释，这对于实际应用具有重要意义。同时，GNN与门控机制的结合有效地融合了多模态信息。该研究为LLM在图异常检测领域的应用开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有图异常检测（GAD）方法主要关注图域内的复杂优化目标，忽视了文本模态的补充价值，其特征通常通过浅层嵌入技术编码，导致可能错过与异常相关的语义上下文。大语言模型（LLMs）在TAG异常检测中的应用尚处于起步阶段，并且由于输入长度限制，它们难以编码图中固有的高阶结构信息。

**Method:** 我们提出了CoLL框架，它结合了LLM和图神经网络（GNN）的优势。CoLL采用多LLM协作进行证据增强生成，以捕获与异常相关的上下文，并为检测到的异常提供人类可读的解释。此外，CoLL集成了一个配备门控机制的GNN，用于自适应地将文本特征与证据融合，同时保留高阶拓扑信息。

**Result:** CoLL在实验中表现出优越性，平均AP（平均精度）提高了13.37%。

**Conclusion:** 本研究为将LLM应用于推进图异常检测开辟了一条新途径。

> **ai_Abstract:** CoLL是一个新颖的框架，旨在通过结合大型语言模型（LLMs）和图神经网络（GNNs）来改进文本属性图（TAG）的异常检测。针对现有方法忽视文本模态和LLM难以处理高阶图结构的问题，CoLL利用多LLM协作进行证据增强生成，以捕获异常相关上下文并提供可解释的理由。同时，集成的GNN通过门控机制融合文本特征和证据，并保留高阶拓扑信息。实验结果表明，CoLL显著优于现有方法，平均AP提高了13.37%。

> **摘要翻译:** 文本属性图（TAGs）中复杂的拓扑结构和丰富的文本信息的自然结合为图异常检测（GAD）开辟了新的视角。然而，现有的GAD方法主要关注图域内的复杂优化目标，忽视了文本模态的补充价值，其特征通常通过浅层嵌入技术（如词袋或skip-gram）编码，因此可能会错过与异常相关的语义上下文。为了释放文本模态的巨大潜力，大型语言模型（LLMs）凭借其强大的语义理解和推理能力，已成为有前景的替代方案。然而，它们在TAG异常检测中的应用仍处于起步阶段，并且由于输入长度限制，它们难以编码图中固有的高阶结构信息。为了在TAGs中实现高质量的异常检测，我们提出了CoLL，一个结合LLM和图神经网络（GNN）的新颖框架，以利用它们的互补优势。CoLL采用多LLM协作进行证据增强生成，以捕获与异常相关的上下文，同时为检测到的异常提供人类可读的理由。此外，CoLL集成了一个配备门控机制的GNN，用于自适应地将文本特征与证据融合，同时保留高阶拓扑信息。广泛的实验证明了CoLL的优越性，平均AP（平均精度）提高了13.37%。这项研究为将LLM应用于推进GAD开辟了一条新途径。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [475] [SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy](https://arxiv.org/abs/2507.23292)
> *SequenceLayers：让序列处理和流式神经网络变得简单*

*RJ Skerry-Ryan, Julian Salazar, Soroosh Mariooryad, David Kao, Daisy Stanton, Eric Battenberg, Matt Shannon, Ron J. Weiss, Robin Scheibler, Jonas Rothfuss, Tom Bagby* | **Category: cs.LG, cs.CL, cs.PL, cs.SE, eess.AS** | **Updated: 2025-07-31**

**Keywords:** 序列建模, 神经网络, 流式处理, API, 状态管理

**Comment:** 

> **TL;DR:** SequenceLayers是一个新的神经网络层API和库，旨在简化序列模型（如Transformer、RNN）的构建，使其能够轻松进行逐层训练和逐步自回归采样，同时确保正确性并减少常见错误。

**AI_Comments:** SequenceLayers的创新之处在于其对神经网络层状态的显式管理，以及将逐层（训练）和逐步（推理）执行统一到一个API中。这解决了现有框架在处理序列模型时常见的复杂性和错误问题，特别是在流式和自回归场景下。其可组合和声明式的设计理念，加上跨框架的潜力，使其在简化生产级序列模型开发方面具有重要意义。这是一个实用且深思熟虑的工程解决方案，对于需要高效部署和维护复杂序列模型的开发者来说非常有价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有序列模型在逐层（如教师强制训练）和逐步（如自回归采样）执行时存在挑战，且在流式和并行序列处理中容易出现常见错误。本文旨在提供一个解决方案，简化复杂序列模型的构建并确保其正确性。

**Method:** 本文引入了一个用于序列建模的神经网络层API和库，名为SequenceLayers。该库的核心思想是让层定义其随时间变化的显式状态表示（例如，Transformer的KV缓存、卷积缓冲区、RNN隐藏状态），并提供一个逐步演进该状态的`step`方法，该方法经测试与无状态的逐层调用结果相同。这种设计实现了复杂模型的即时流式处理，并可应用于任何深度学习库。

**Result:** SequenceLayers使复杂模型能够立即进行流式处理，缓解了流式和并行序列处理中出现的各种常见错误。其可组合和声明式的API，以及全面的层和组合器套件，简化了从简单流式组件构建生产规模模型的过程，同时保留了强大的正确性保证。目前已在JAX和TensorFlow 2中实现。

**Conclusion:** SequenceLayers提供了一个创新的神经网络层API和库，通过显式状态管理和统一的逐层/逐步执行机制，极大地简化了序列模型的构建、部署和调试，提高了其在生产环境中的可靠性和效率。

> **ai_Abstract:** SequenceLayers是一个新颖的神经网络层API和库，专注于简化序列模型的构建和部署。它通过要求层显式定义其时间状态（如KV缓存、RNN隐藏状态）并提供一个统一的`step`方法，实现了模型在逐层训练和逐步自回归采样之间无缝切换。这不仅使得复杂模型能够即时流式处理，还显著减少了流式和并行处理中常见的错误，同时提供了强大的正确性保证。该API具有可组合性和声明性，支持在任何深度学习库中实现，目前已在JAX和TensorFlow 2中可用。

> **摘要翻译:** 我们介绍了一个用于序列建模的神经网络层API和库，旨在简化序列模型的创建，使其既可以逐层执行（例如，教师强制训练），也可以逐步执行（例如，自回归采样）。为了实现这一点，层定义了其随时间变化的显式状态表示（例如，Transformer的KV缓存、卷积缓冲区、RNN隐藏状态），以及一个演进该状态的`step`方法，该方法经测试与无状态的逐层调用结果相同。这一特性以及SequenceLayers契约的其他方面使得复杂模型能够立即进行流式处理，缓解了流式和并行序列处理中出现的各种常见错误，并且可以在任何深度学习库中实现。可组合和声明式的API，以及一套全面的层和组合器，简化了从简单流式组件构建生产规模模型的过程，同时保留了强大的正确性保证。我们目前实现的SequenceLayers（JAX、TensorFlow 2）可在https://github.com/google/sequence-layers 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [478] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
> *混合LSTM-Transformer模型用于高速公路-铁路平交道口剖面测量*

*Kaustav Chatterjee, Joshua Q. Li, Fatemeh Ansari, Masud Rana Munna, Kundan Parajulee, Jared Schwennesen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 高速公路-铁路平交道口, 深度学习, LSTM, Transformer, 剖面测量

**Comment:** 

> **TL;DR:** 本研究开发了一种混合LSTM-Transformer深度学习框架，利用IMU/GPS数据快速准确地测量高速公路-铁路平交道口剖面，以提高安全性。

**AI_Comments:** 这项研究的创新之处在于将LSTM和Transformer这两种强大的深度学习架构结合起来，创建了一个混合模型，用于解决高速公路-铁路平交道口剖面测量的实际问题。其重要性在于提供了一种比传统方法更经济、高效且安全的HRGC剖面测量方案，有望显著提高交通安全性。

<details>
  <summary>Details</summary>

**Motivation:** 高速公路-铁路平交道口（HRGCs）的驼峰交叉口对车辆构成安全风险，传统测量方法成本高、耗时、扰乱交通且存在安全隐患。

**Method:** 研究采用先进、经济高效的技术和创新建模方法。开发了一种结合长短期记忆（LSTM）和Transformer架构的新型混合深度学习框架。使用配备惯性测量单元（IMU）和全球定位系统（GPS）传感器的高速公路测试车辆收集仪表数据，并通过工业标准步行剖面仪获取地面真实数据。在俄克拉荷马州的Red Rock铁路走廊收集了现场数据。评估了三种深度学习模型：Transformer-LSTM顺序（模型1）、LSTM-Transformer顺序（模型2）和LSTM-Transformer并行（模型3）。

**Result:** 模型2（LSTM-Transformer顺序）和模型3（LSTM-Transformer并行）表现优于其他模型，并被部署用于生成2D/3D HRGC剖面。

**Conclusion:** 深度学习模型通过实现对HRGC挂车敏感性的快速准确评估，展现出增强公路和铁路安全的巨大潜力。

> **ai_Abstract:** 本文针对高速公路-铁路平交道口（HRGCs）驼峰交叉口对车辆造成的安全隐患以及传统测量方法存在的问题，提出了一种创新的解决方案。研究开发了一种结合LSTM和Transformer架构的新型混合深度学习框架，利用配备IMU和GPS传感器的高速公路测试车辆收集的仪表数据以及步行剖面仪获得的地面真实数据来测量HRGC剖面。通过评估三种模型架构，发现LSTM-Transformer顺序模型和LSTM-Transformer并行模型表现最佳，并成功应用于生成2D/3D HRGC剖面。该方法有望实现对HRGC挂车敏感性的快速准确评估，显著提升公路和铁路的安全性。

> **摘要翻译:** 驼峰交叉口，或称高剖面高速公路-铁路平交道口（HRGCs），因潜在的车辆挂底风险而对公路车辆构成安全隐患。这些交叉口通常是由于铁路轨道后期维护活动或不符合HRGC垂直对齐设计指南而产生的。测量HRGC剖面的传统方法成本高、耗时、扰乱交通且存在安全挑战。为解决这些问题，本研究采用了先进、经济高效的技术和创新的建模方法进行HRGC剖面测量。通过利用仪表数据和地面真实数据，开发了一种结合长短期记忆（LSTM）和Transformer架构的新型混合深度学习框架。仪表数据是使用配备惯性测量单元（IMU）和全球定位系统（GPS）传感器的高速公路测试车辆收集的，而地面真实数据是通过工业标准步行剖面仪获得的。现场数据是在俄克拉荷马州的Red Rock铁路走廊收集的。评估了三种先进的深度学习模型：Transformer-LSTM顺序（模型1）、LSTM-Transformer顺序（模型2）和LSTM-Transformer并行（模型3），以确定最有效的架构。模型2和模型3表现优于其他模型，并被部署用于生成2D/3D HRGC剖面。这些深度学习模型通过实现对HRGC挂车敏感性的快速准确评估，展现出增强公路和铁路安全的巨大潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [480] [KLLM: Fast LLM Inference with K-Means Quantization](https://arxiv.org/abs/2507.23035)
> *KLLM: 基于 K-Means 量化实现快速 LLM 推理*

*Xueying Wu, Baijun Zhou, Zhihui Gao, Yuzhe Fu, Qilin Zheng, Yintao He, Hai Li* | **Category: cs.LG, cs.AR** | **Updated: 2025-07-30**

**Keywords:** LLM 推理, K-Means 量化, 软硬件协同设计, 异常值检测, 能效

**Comment:** 

> **TL;DR:** KLLM 提出了一种软硬件协同设计框架，通过 K-Means 量化和高效的异常值检测，显著加速 LLM 推理并提高能效。

**AI_Comments:** KLLM 的创新之处在于其软硬件协同设计，特别是基于索引的计算方案，它解决了 K-Means 量化非均匀性带来的执行效率问题，避免了大量的反量化操作。此外，Orizuru 异常值检测引擎的在线高效性也很有价值，解决了现有方法在精度和运行时开销上的痛点。该工作对推动低精度 LLM 推理的实用化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型 (LLM) 推理面临内存和计算密集型挑战。尽管权重和激活量化 (WAQ) 有望解决这些问题，但现有 WAQ 设计存在两大挑战：1) 传统均匀整数WAQ在低精度下精度显著下降；非均匀的 K-Means 量化虽然精度高，但无法直接在低精度计算单元上执行，需要反量化和浮点矩阵乘法。2) 激活异常值阻碍低精度 WAQ 的有效性，离线阈值法导致性能下降，现有在线检测技术引入高运行时开销。

**Method:** 本文提出了 KLLM，一个软硬件协同设计框架。KLLM 采用基于索引的计算方案，有效执行 K-Means 量化数据的矩阵乘法和非线性操作，从而避免了大部分反量化和全精度计算。此外，KLLM 还集成了名为 Orizuru 的新型异常值检测引擎，能在在线推理期间高效识别激活数据流中的前 k 个最大和最小元素。

**Result:** 实验表明，与 A100 GPU 和 Atom 相比，KLLM 平均分别实现了 9.67 倍、7.03 倍的加速，以及 229.50 倍、150.21 倍的能效提升。

**Conclusion:** KLLM 通过其创新的软硬件协同设计，成功解决了 LLM 推理中 K-Means 量化所面临的挑战，显著提高了推理速度和能效，证明了其在低精度 LLM 推理中的巨大潜力。

> **ai_Abstract:** KLLM 是一种软硬件协同设计框架，旨在解决大型语言模型 (LLM) 推理中 K-Means 量化所面临的挑战。它通过引入基于索引的计算方案来高效处理 K-Means 量化数据，并集成了一个名为 Orizuru 的新型在线异常值检测引擎。实验结果表明，KLLM 在推理速度和能效方面均取得了显著提升，证明了其在加速低精度 LLM 推理方面的有效性。

> **摘要翻译:** 大型语言模型 (LLM) 推理由于其密集的内存和计算需求而带来了重大挑战。权重和激活量化 (WAQ) 通过减少内存占用和算术复杂度提供了一个有前景的解决方案。然而，现有 WAQ 设计中仍然存在两个关键挑战。(1) 传统的 WAQ 设计依赖于基于均匀整数的量化以实现硬件效率，但这通常会导致低精度下的显著精度下降。基于 K-Means 的量化是一种非均匀量化技术，通过匹配 LLM 中权重和激活的高斯状分布，实现了更高的精度。然而，其非均匀性阻碍了在低精度计算单元上的直接执行，在推理过程中需要反量化和浮点矩阵乘法 (MatMuls)。(2) 激活异常值进一步阻碍了有效的低精度 WAQ。用于异常值检测的离线阈值方法可能导致显著的模型性能下降，而现有在线检测技术引入了大量的运行时开销。
为了解决上述挑战并充分释放带有 K-Means 量化的 WAQ 在 LLM 推理中的潜力，在本文中，我们提出了 KLLM，一个软硬件协同设计框架。KLLM 采用了一种基于索引的计算方案，用于高效执行 K-Means 量化数据的矩阵乘法和非线性操作，这避免了大部分的反量化和全精度计算。此外，KLLM 结合了一个新颖的异常值检测引擎 Orizuru，它在在线推理期间有效地识别激活数据流中的前 k 个最大和最小元素。
广泛的实验表明，与 A100 GPU 和 Atom 相比，KLLM 平均分别实现了 9.67 倍、7.03 倍的加速，以及 229.50 倍、150.21 倍的能效提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [486] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
> *基于多尺度跨模态和单模态对比学习的文本属性图异常检测*

*Yiming Xu, Xu Hua, Zhen Peng, Bin Shi, Jiarun Chen, Xingbo Fu, Song Wang, Bo Dong* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 文本属性图异常检测,对比学习,跨模态,图神经网络,数据集

**Comment:** Accepted by ECAI 2025

> **TL;DR:** 本文提出了一种名为CMUCL的端到端范式，用于文本属性图异常检测，通过跨模态和单模态多尺度对比学习，显著提高了检测精度，并发布了8个新数据集。

**AI_Comments:** 该论文的创新点在于提出了一个端到端的文本属性图异常检测范式CMUCL，有效解决了文本信息与图异常检测目标分离的问题。通过引入多尺度跨模态和单模态对比学习，实现了文本和图数据的深度融合，从而更准确地识别异常。其重要性不仅体现在性能的显著提升上，还体现在发布了新的基准数据集，填补了该领域数据集的空白，将极大地促进未来研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有图异常检测方法在处理文本属性图时，文本编码过程与图域的异常检测目标分离，导致文本特征难以聚焦于异常检测相关信息，严重限制了检测能力。如何无缝整合原始文本和图拓扑以发挥跨模态数据的潜力是一个挑战。

**Method:** 本文提出了一种新颖的端到端文本属性图异常检测范式CMUCL。它同时对文本和图结构数据进行建模，并通过利用跨模态和单模态多尺度一致性来共同训练文本和图编码器，以发现潜在的异常相关信息。此外，还设计了一个基于不一致性挖掘的异常分数估计器来推导节点特异性异常分数。

**Result:** 广泛的评估表明，CMUCL在文本属性图异常检测方面取得了显著进展，平均精度（AP）比次优方法提高了11.13%。此外，为了促进未来的研究，本文发布了8个新的基准数据集。

**Conclusion:** CMUCL通过其端到端的多尺度跨模态和单模态对比学习范式，有效解决了文本属性图异常检测中文本特征与检测目标分离的问题，显著提升了检测性能，并为该领域提供了新的基准数据集。

> **ai_Abstract:** 本文针对文本属性图（TAGs）异常检测中，现有方法文本特征与图异常检测目标分离导致性能受限的问题，提出了一种名为CMUCL的端到端新范式。CMUCL通过同时建模文本和图结构数据，并利用多尺度跨模态和单模态对比学习联合训练编码器，以发现异常信息，并设计了基于不一致性挖掘的异常分数估计器。实验证明，CMUCL显著提高了检测精度，平均AP提升11.13%。此外，为推动研究，本文还发布了8个TAGs异常检测新数据集。

> **摘要翻译:** 图数据在各种高风险场景中的广泛应用使得图异常检测（GAD）受到越来越多的关注。面对现实世界中通常以原始文本序列形式携带节点描述的图（称为文本属性图，TAGs），现有的图异常检测流程通常涉及浅层嵌入技术来编码此类文本信息为特征，然后依赖图域内复杂的自监督任务来检测异常。然而，这种文本编码过程与图域的异常检测训练目标是分离的，这使得难以确保提取的文本特征聚焦于GAD相关信息，严重限制了检测能力。如何无缝整合原始文本和图拓扑以发挥TAGs中跨模态数据的巨大潜力进行异常检测，这是一个具有挑战性的问题。本文提出了一种新颖的端到端文本属性图异常检测范式，名为CMUCL。我们同时对来自文本和图结构的数据进行建模，并通过利用跨模态和单模态多尺度一致性来共同训练文本和图编码器，以揭示潜在的异常相关信息。因此，我们设计了一个基于不一致性挖掘的异常分数估计器来推导节点特异性异常分数。考虑到缺乏专门为TAGs异常检测设计的基准数据集，我们发布了8个数据集以促进未来的研究。广泛的评估表明，CMUCL在文本属性图异常检测方面取得了显著进展，平均精度（AP）比次优方法提高了11.13%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [493] [Adapt before Continual Learning](https://arxiv.org/abs/2506.03956)
> *持续学习前的适应*

*Aojun Lu, Tao Feng, Hangjie Yuan, Chunhui Ding, Yanan Sun* | **Category: cs.LG, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 持续学习, 预训练模型, 稳定性-可塑性权衡, 模型适应, 灾难性遗忘

**Comment:** 

> **TL;DR:** 提出ACL框架，在持续学习前先对预训练模型进行适应，通过对齐嵌入与原始类别原型并远离不相关类别，有效平衡了稳定性和可塑性，显著提升了持续学习性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个在持续学习核心过程之前进行预训练模型适应的“即插即用”阶段，这提供了一种新颖的视角来解决持续学习中稳定性与可塑性之间的核心矛盾。通过在学习新任务前对模型进行预适应，而不是简单地冻结或完全微调，该方法有望在保持模型旧知识的同时，更好地适应新的、差异较大的数据分布，对于提升基于PTM的持续学习性能具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于预训练模型的持续学习方法在平衡模型可塑性（学习新知识）和稳定性（保留旧知识）之间面临挑战，特别是当新数据分布与预训练数据差异较大时，冻结主干网络会限制可塑性，而微调整个模型则会导致灾难性遗忘。

**Method:** 提出“在核心持续学习过程前适应预训练模型”(ACL) 的新框架。该框架在学习每个新任务之前引入一个即插即用的适应阶段，在此阶段通过将嵌入与原始类别原型对齐并使其远离不相关类别来优化预训练模型的主干网络。

**Result:** 理论和实验证明，ACL在稳定性和可塑性之间实现了理想的平衡，显著提高了基准测试和集成方法上的持续学习性能。

**Conclusion:** ACL框架通过在持续学习前引入一个适应阶段，成功解决了预训练模型在持续学习中稳定性与可塑性之间的关键权衡问题，从而显著提升了模型的整体表现。

> **ai_Abstract:** 本文提出了ACL（在核心持续学习过程前适应预训练模型）框架，旨在解决基于预训练模型的持续学习中稳定性与可塑性的平衡问题。ACL在学习新任务前引入一个适应阶段，通过调整预训练模型主干的嵌入，使其与原始类别原型对齐并远离不相关类别。实验结果表明，ACL有效平衡了稳定性和可塑性，显著提升了持续学习的性能。

> **摘要翻译:** 持续学习（CL）旨在使神经网络在逐步获取新知识（可塑性）的同时保留现有知识（稳定性）。尽管预训练模型（PTMs）为持续学习提供了坚实的基础，但现有方法在平衡这两个相互竞争的目标方面面临根本性挑战。当前方法通常通过冻结PTM主干来解决稳定性问题，这严重限制了模型的可塑性，特别是当传入数据分布与预训练数据差异较大时。或者，顺序微调整个PTM可以适应新知识，但常常导致灾难性遗忘，这突出了基于PTM的持续学习中关键的稳定性-可塑性权衡。为了解决这一局限性，我们提出了在核心持续学习过程之前适应PTMs（ACL），这是一个新颖的框架，在学习每个新任务之前引入一个即插即用的适应阶段。在此阶段，ACL通过将嵌入与原始类别原型对齐，同时使其远离不相关类别来优化PTM主干。该机制在理论和经验上都展示了稳定性与可塑性之间理想的平衡，显著提高了基准测试和集成方法上的持续学习性能。代码可在https://github.com/byyx666/ACL_code获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [500] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
> *强盗设置下延迟反馈的在线非次模优化*

*Sifan Yang, Yuanyu Wan, Lijun Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 在线优化, 非次模优化, 延迟反馈, 强盗设置, 遗憾界

**Comment:** 

> **TL;DR:** 本文提出了两种新的算法，用于解决强盗设置下延迟反馈的在线非次模优化问题，改进了现有方法的遗憾界对最大延迟的敏感性以及延迟与强盗反馈的耦合效应。

**AI_Comments:** 本文的创新点在于提出了两种算法来解决在线非次模优化中延迟反馈带来的挑战。特别是第二种算法通过解耦延迟和强盗反馈的影响，使得在特定延迟条件下能够达到与无延迟设置相媲美的性能，这在理论和实践上都具有重要意义。对平均延迟的考虑也使得算法对不规则延迟的鲁棒性更强。

<details>
  <summary>Details</summary>

**Motivation:** 现有工作在强盗设置下延迟反馈的在线非次模优化中，其遗憾界依赖于最大延迟，对不规则延迟敏感，且将延迟和强盗反馈的影响耦合在一起。

**Method:** 1. 提出DBGD-NF算法，采用单点梯度估计器，并利用每轮所有可用的估计梯度来更新决策。2. 通过引入阻塞更新机制扩展DBGD-NF，以解耦延迟和强盗反馈的联合效应。

**Result:** 1. DBGD-NF算法实现了$\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$遗憾界，与平均延迟$\\bar{d}$相关。2. 扩展算法实现了$\\mathcal{O}(n(T^{2/3} + \\sqrt{dT}))$遗憾界，当$d = \\mathcal{O}(T^{1/3})$时，该遗憾界与无延迟反馈的强盗设置中的$\\mathcal{O}(nT^{2/3})$遗憾界匹配。当最大延迟$d = o(\\bar{d}^{2/3}T^{1/3})$时，该方法更具优势。实验在结构化稀疏学习上验证了方法的优越性。

**Conclusion:** 本文提出的两种算法成功解决了现有在线非次模优化中延迟反馈对最大延迟的敏感性以及延迟与强盗反馈耦合的问题，并通过实验验证了其优越性。

> **ai_Abstract:** 本文研究了强盗设置下延迟反馈的在线非次模优化问题，针对现有方法遗憾界对最大延迟的敏感性和延迟与强盗反馈的耦合问题，提出了两种新算法。DBGD-NF算法利用单点梯度估计器和所有可用梯度，实现了与平均延迟相关的$\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$遗憾界。在此基础上，通过阻塞更新机制扩展的算法进一步解耦了延迟和强盗反馈的影响，获得了$\\mathcal{O}(n(T^{2/3} + \\sqrt{dT}))$遗憾界，并在特定条件下达到了无延迟的遗憾界水平。实验验证了所提方法的有效性。

> **摘要翻译:** 我们研究了强盗设置下延迟反馈的在线非次模优化，其中损失函数是 $\\alpha$-弱DR-次模和 $\\beta$-弱DR-超模的。先前的工作已经建立了 $\\mathcal{O}(nd^{1/3}T^{2/3})$ 的 $(\\alpha,\\beta)$-遗憾界，其中 $n$ 是维度，$d$ 是最大延迟。然而，其遗憾界依赖于最大延迟，因此对不规则延迟很敏感。此外，它将延迟和强盗反馈的影响耦合在一起，因为其界是延迟项和在没有延迟反馈的强盗设置中 $\\mathcal{O}(nT^{2/3})$ 遗憾界的乘积。在本文中，我们分别开发了两种算法来解决这些限制。首先，我们提出了一种新颖的方法，即 DBGD-NF，它采用单点梯度估计器，并利用每轮所有可用的估计梯度来更新决策。它实现了更好的 $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ 遗憾界，这与平均延迟 $\\bar{d} = \\frac{1}{T}\\sum_{t=1}^T d_t\\leq d$ 相关。其次，我们通过采用阻塞更新机制扩展了 DBGD-NF，以解耦延迟和强盗反馈的联合效应，它享有 $\\mathcal{O}(n(T^{2/3} + \\sqrt{dT}))$ 遗憾界。当 $d = \\mathcal{O}(T^{1/3})$ 时，我们的遗憾界与无延迟反馈的强盗设置中的 $\\mathcal{O}(nT^{2/3})$ 界匹配。与我们的第一个 $\\mathcal{O}(n\\bar{d}^{1/3}T^{2/3})$ 界相比，当最大延迟 $d = o(\\bar{d}^{2/3}T^{1/3})$ 时，它更具优势。最后，我们对结构化稀疏学习进行了实验，以证明我们方法的优越性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [506] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
> *基于广义动态因子模型和生成对抗网络的风电情景生成*

*Young-ho Cho, Hao Zhu, Duehee Lee, Ross Baldick* | **Category: cs.LG, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 风电情景生成, 广义动态因子模型, 生成对抗网络, 时空特征, 资源充足性

**Comment:** 

> **TL;DR:** 结合广义动态因子模型（GDFM）和生成对抗网络（GAN）生成具有时空特征的长期风电情景，性能优于现有方法。

**AI_Comments:** 本文创新性地结合了GDFM和GAN的优点，解决了单一模型在风电情景生成中无法同时捕捉复杂时空特征的局限性，为风电资源充足性研究提供了更准确和可靠的工具。

<details>
  <summary>Details</summary>

**Motivation:** 为进行资源充足性研究，需要同时合成多个分布式风电场的长期风电情景，并捕捉其复杂的时空特征，包括空间和时间相关性、波形、边际和斜率分布、功率谱密度以及统计特性。

**Method:** 本文提出一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的方法。具体而言，使用GAN提供一个滤波器，该滤波器从观测数据中提取带有时间信息的动态因子，然后将此滤波器应用于GDFM，以表示合理波形的空间和频率相关性。GDFM擅长提取公共因子，而GAN擅长合成时间相关性。

**Result:** 数值测试表明，GDFM和GAN的组合在合成澳大利亚风电情景方面，比现有替代方案（如仅使用基于实际动态滤波器分布合成滤波器的GDFM，或不含动态因子直接合成的GAN）表现出性能改进，能更好地实现与实际风电相似的统计特性。

**Conclusion:** 结合GDFM和GAN的方法能够有效且更准确地生成具有复杂时空特征的长期风电情景，为风电资源充足性研究提供了更可靠的工具。

> **ai_Abstract:** 本文提出一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的新方法，用于同时生成多个分布式风电场的长期风电情景。该方法旨在捕捉风电情景复杂的时空特征，包括空间和时间相关性、波形等。研究利用GAN作为滤波器提取动态时间信息，并将其整合到GDFM中以模拟空间和频率相关性。数值测试结果显示，与现有方法相比，该组合模型在合成风电情景方面表现出显著的性能提升，能够更好地再现实际风电的统计特性。

> **摘要翻译:** 为了进行资源充足性研究，我们利用时空特征：空间和时间相关性、波形、波形的边际和斜率分布、功率谱密度以及统计特性，同时合成了多个分布式风电场的长期风电情景。在情景中生成空间相关性需要为相邻风电场设计共同因子，为远距离风电场设计对立因子。广义动态因子模型（GDFM）可以通过交叉谱密度分析提取共同因子，但它不能紧密模仿波形。生成对抗网络（GAN）可以通过伪样本判别器验证样本，从而合成代表时间相关性的合理样本。为了结合GDFM和GAN的优点，我们使用GAN提供一个滤波器，从观测数据中提取具有时间信息的动态因子，然后将此滤波器应用于GDFM，以表示合理波形的空间和频率相关性。对GDFM和GAN组合的数值测试表明，在合成澳大利亚风电情景方面，其性能优于竞争替代方案，与仅使用基于实际动态滤波器分布合成滤波器的GDFM以及不含动态因子直接合成的GAN等替代方案相比，能更好地实现实际风电的合理统计特性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [507] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
> *相位锁定信噪比波段选择用于高光谱图像中弱矿物信号检测*

*Judy X Yang* | **Category: cs.LG, Cs** | **Updated: 2025-08-01**

**Keywords:** 高光谱图像, 弱矿物信号, 信噪比, 波段选择, 丰度解混

**Comment:** 8 pages, 6 figures

> **TL;DR:** 提出一种两阶段框架，通过相位锁定信噪比波段选择和KMeans聚类及NNLS解混，提高高光谱图像中弱矿物信号的检测精度。

**AI_Comments:** 该论文的创新点在于结合了相位锁定信噪比波段选择与Savitzky-Golay滤波，以及KMeans聚类与NNLS解混的两阶段策略，有效地解决了高光谱图像中弱矿物信号受噪声和冗余波段影响的问题。其提出的方法具有实用性和可复现性，对于地质高光谱遥感领域的弱信号检测具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高光谱成像中，弱矿物信号常被噪声和冗余波段掩盖，限制了检测性能。

**Method:** 提出一个两阶段集成框架。第一阶段：计算每个光谱波段的信噪比（SNR），应用相位锁定阈值技术丢弃低SNR波段，并采用Savitzky-Golay滤波进行光谱平滑。第二阶段：将精炼的高光谱数据重新引入模型，使用KMeans聚类提取12个端元光谱，然后使用非负最小二乘法（NNLS）进行丰度解混。

**Result:** 实验结果证实，所提出的流程提高了弱矿物区域的解混精度和检测能力。

**Conclusion:** 这种两阶段策略为地质高光谱图像应用中的光谱降维和解混提供了一个实用且可重现的解决方案。

> **ai_Abstract:** 本文提出一种用于高光谱图像中弱矿物信号检测的两阶段集成框架。第一阶段通过计算信噪比并采用相位锁定阈值和Savitzky-Golay滤波进行波段选择和光谱平滑，以去除冗余和噪声。第二阶段利用KMeans聚类提取端元光谱，并通过非负最小二乘法进行丰度解混。实验结果表明，该方法有效提高了弱矿物区域的解混精度和检测能力，为地质高光谱应用提供了一种实用的解决方案。

> **摘要翻译:** 高光谱成像为矿物测绘提供了详细的光谱信息；然而，弱矿物特征常常被嘈杂和冗余的波段掩盖，从而限制了检测性能。为了解决这个问题，我们提出了一个两阶段的集成框架，用于增强Cuprite矿区矿物检测。在第一阶段，我们计算每个光谱波段的信噪比（SNR），并应用相位锁定阈值技术来丢弃低SNR波段，从而有效去除冗余并抑制背景噪声。然后采用Savitzky-Golay滤波进行光谱平滑，其作用有二：首先在波段选择期间稳定趋势，其次在预处理期间保留精细的光谱特征。在第二阶段，将精炼的高光谱数据重新引入模型，其中使用KMeans聚类提取12个端元光谱（W1 custom），然后使用非负最小二乘法（NNLS）进行丰度解混。将得到的端元光谱与实验室光谱（W1 raw）使用余弦相似度和RMSE指标进行定量比较。实验结果证实，我们提出的流程提高了混分解精度并增强了弱矿物区域的检测。这种两阶段策略为地质高光谱图像应用中的光谱降维和解混提供了一个实用且可重现的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [508] [Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform](https://arxiv.org/abs/2507.23562)
> *硬件感知型脉冲Q网络在SpiNNaker2神经形态平台上的微调*

*Sirine Arfa, Bernhard Vogginger, Christian Mayr* | **Category: cs.LG, cs.AR** | **Updated: 2025-07-31**

**Keywords:** 脉冲神经网络, 强化学习, SpiNNaker2, 神经形态计算, 能量效率

**Comment:** 8 pages, 5 figures, 3 tables

> **TL;DR:** 本文在SpiNNaker2神经形态平台上实现了能量高效的脉冲Q网络，用于解决控制任务，并展示了其在能耗方面优于GPU的显著优势。

**AI_Comments:** 这项工作展示了神经形态硬件在能耗效率方面的巨大潜力，特别是在强化学习任务中。通过将SNNs与Q-learning结合，并在专门的神经形态芯片（SpiNNaker2）上进行硬件感知型微调和量化，实现了显著的能耗降低。这对于边缘计算和需要低功耗AI解决方案的机器人应用具有重要意义。其创新之处在于结合了SNN、Q-learning和特定的神经形态硬件优化。

<details>
  <summary>Details</summary>

**Motivation:** SNNs有望在神经形态硬件上实现极低的功耗和低延迟推理。本研究旨在利用SNNs实现节能的强化学习算法，并评估SpiNNaker2神经形态平台相对于传统计算平台的优势。

**Method:** 研究使用量化的脉冲神经网络（SNNs）实现强化学习（Q-learning）算法，以解决两个经典控制任务。网络经过Q-learning训练后，被微调并量化到8位精度，部署在SpiNNaker2神经形态芯片上。通过分析推理延迟、动态功耗和每次推理的能耗，将SpiNNaker2的性能与GTX 1650 GPU基线进行比较。

**Result:** SpiNNaker2在能耗方面实现了高达32倍的降低。推理延迟与基于GPU的执行保持一致，并在某些任务设置中有所改进。这些结果表明SpiNNaker2在可扩展、低能耗神经形态计算方面具有强大潜力。

**Conclusion:** SpiNNaker2的强大潜力使其成为实时神经形态控制的可行选择，并使神经形态方法成为高效深度Q学习的一个引人注目的方向。

> **ai_Abstract:** 本文提出了一种在SpiNNaker2神经形态平台上实现能量高效强化学习的方法。通过将Q学习训练的脉冲神经网络微调并量化至8位精度，并在SpiNNaker2芯片上进行部署。研究评估了SpiNNaker2在推理延迟、功耗和能耗方面的表现，并与GPU进行了比较。结果显示，SpiNNaker2在能耗上实现了显著降低（高达32倍），同时保持了与GPU相当的推理延迟，证明了其在低能耗神经形态计算和实时控制方面的潜力。

> **摘要翻译:** 脉冲神经网络（SNNs）有望在神经形态硬件上为广泛的机器人任务提供数量级更低的功耗和低延迟推理。在这项工作中，我们提出了一种使用量化SNNs实现强化学习（RL）算法的节能方法，以解决两个经典的控制任务。该网络使用Q学习算法进行训练，然后进行微调并量化到低位（8位）精度，以便在SpiNNaker2神经形态芯片上进行嵌入式部署。为了评估SpiNNaker2相对于传统计算平台的比较优势，我们分析了SNN模型的推理延迟、动态功耗和每次推理的能耗，并将性能与GTX 1650 GPU基线进行比较。我们的结果表明SpiNNaker2在可扩展、低能耗神经形态计算方面具有强大潜力，实现了高达32倍的能耗降低。推理延迟与基于GPU的执行保持一致，在某些任务设置中观察到改进，这增强了SpiNNaker2在实时神经形态控制方面的可行性，并使神经形态方法成为高效深度Q学习的一个引人注目的方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [509] [Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead](https://arxiv.org/abs/2507.23009)
> *停止用人类测试评估人工智能，转而开发有原则的、针对人工智能的测试*

*Tom Sühr, Florian E. Dorner, Olawale Salaudeen, Augustin Kelava, Samira Samadi* | **Category: cs.LG, cs.AI, 91E45, I.2** | **Updated: 2025-07-30**

**Keywords:** AI评估, 人类测试, 语言模型, 基准测试, 心理测量学

**Comment:** 

> **TL;DR:** 本文主张停止使用为人类设计的测试来评估人工智能，因为这会导致对AI能力的错误解读；相反，应该开发有原则的、针对AI系统量身定制的专用测试。

**AI_Comments:** 本文提出一个及时且重要的观点，挑战了当前AI评估中普遍存在的范式。其创新之处在于明确指出将人类测试应用于AI可能导致的“本体论错误”，并强调了评估工具与被评估主体之间匹配的重要性。论文的价值在于促使AI研究社区反思现有评估方法的局限性，并呼吁开发更科学、更符合AI特性的评估标准，这对于AI的健康发展至关重要。其局限性可能在于，提出问题的同时，具体如何构建这些“AI特定测试”的详细方法论在摘要中并未深入阐述。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在为评估人类认知和心理特征而设计的标准化测试中取得了显著成果，但作者认为将这些结果解释为LLMs具有类人特征是一种本体论错误。人类心理和教育测试是理论驱动的测量工具，专门针对特定人群校准，未经实证验证将其应用于非人类主体存在测量误读的风险。此外，AI在基准测试上的表现被框定为“智能”等特性的测量，尽管存在有效性、数据污染、文化偏见和对提示变化的敏感性等已知问题。

**Method:** 本文提出一个明确的立场和论证，即应停止使用人类测试来评估人工智能。作者呼吁开发有原则的、针对AI系统量身定制的、特定于AI的评估框架。这些框架可以借鉴现有的心理测量测试构建和验证框架，或者完全从零开始创建以适应AI的独特背景。

**Result:** Not mentioned in abstract

**Conclusion:** 结论是，我们应该停止使用人类测试来评估人工智能，而是应该开发有原则的、针对人工智能的特定测试。论文呼吁构建专门为AI系统设计的评估框架。

> **ai_Abstract:** 本文指出，大型语言模型在人类设计测试上的成功表现常被误读为具备类人特征，这是一种本体论错误。作者强调，人类测试是为特定人群设计的，将其应用于AI存在有效性、数据污染和文化偏见等问题。因此，论文主张停止使用人类测试来评估AI，并呼吁为AI系统开发有原则的、专门的评估框架，这些框架可以借鉴现有心理测量学方法或全新创建。

> **摘要翻译:** 大型语言模型（LLMs）在原本旨在评估人类认知和心理特征（如智力和人格）的一系列标准化测试中取得了显著成果。尽管这些结果常被解释为LLMs具有类人特征的强有力证据，但本文认为此类解释构成了一种本体论错误。人类心理和教育测试是理论驱动的测量工具，针对特定人类群体进行校准。未经经验验证将这些测试应用于非人类主体，存在错误描述所测量内容的风险。此外，一种日益增长的趋势将AI在基准测试上的表现框定为“智能”等特性的测量，尽管其存在有效性、数据污染、文化偏见和对表面提示变化的敏感性等已知问题。我们认为，将基准测试表现解释为类人特性的测量，缺乏足够的理论和经验依据。这导致了我们的立场：停止用人类测试评估人工智能，转而开发有原则的、针对人工智能的测试。我们呼吁开发针对AI系统量身定制的、有原则的、特定于AI的评估框架。此类框架可以建立在现有的心理测量测试构建和验证框架之上，也可以完全从零开始创建以适应AI的独特背景。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [513] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
> *基于运行电价预测的态势感知条件神经过程与多准则决策支持*

*Abhinav Das, Stephan Schlüter* | **Category: cs.LG, math.PR, stat.AP, stat.ML, 60J20, 68T07** | **Updated: 2025-07-31**

**Keywords:** 电力价格预测, 条件神经过程, 态势检测, 多准则决策, 电池储能优化

**Comment:** 

> **TL;DR:** 本文提出了一种结合贝叶斯态势检测和条件神经过程（R-NP）的24小时德国电力价格预测方法，并通过多准则决策支持（TOPSIS）评估其在电池储能优化框架中的运行效用，结果显示R-NP是2021-2023年最平衡和首选的解决方案。

**AI_Comments:** 该论文的创新之处在于将贝叶斯态势检测与条件神经过程相结合，为电力价格预测引入了“态势感知”能力，这对于电力市场的高度动态性非常重要。更重要的是，它超越了传统的预测精度评估，通过将预测集成到实际的电池储能优化框架中，并引入多准则决策支持（TOPSIS）来评估模型的运行效用，这使得研究结果更具实际指导意义。这种从“预测准确性”到“操作实用性”的范式转变，为能源预测领域提供了一个新的评估视角，对于实际应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的预测精度不总能转化为最优的运行结果，因此需要一种新的方法来提高电力价格预测在实际运行中的效用，并提供多准则决策支持。

**Method:** 本研究将贝叶斯态势检测与条件神经过程相结合，用于德国市场的24小时电力价格预测。方法论包括：1. 使用解耦的粘性分层狄利克雷过程隐马尔可夫模型（DS-HDP-HMM）对每日电价进行态势检测。2. 每个识别出的态势由一个独立的条件神经过程（CNP）建模，学习从输入上下文到24维小时价格轨迹的局部映射。3. 最终预测是这些CNP输出的态势加权混合。4. 将R-NP与深度神经网络（DNN）和Lasso估计自回归（LEAR）模型进行比较，通过将它们的预测集成到包括价格套利、风险管理、电网服务和成本最小化在内的电池储能优化框架中进行评估。5. 采用TOPSIS作为全面的多准则评估层，以解决原始预测精度与最优运行结果不一致的问题。

**Result:** 运行效用评估揭示了复杂的性能权衡：LEAR模型通常能产生更高的绝对利润或更低的成本，而DNN在特定的成本最小化场景中表现出卓越的最优性。TOPSIS分析显示，LEAR是2021年的最佳模型，但提出的R-NP模型在2021、2022和2023年被认为是更平衡和首选的解决方案。

**Conclusion:** 尽管原始预测精度不总是能转化为最优的运行结果，但本文提出的态势感知条件神经过程（R-NP）结合多准则决策支持（TOPSIS）在实际电池储能优化应用中表现出最佳的平衡性和偏好，尤其是在长周期评估中。

> **ai_Abstract:** 本研究提出了一种结合贝叶斯态势检测和条件神经过程（R-NP）的电力价格预测新方法，旨在提高预测在实际运行中的效用。该方法首先利用DS-HDP-HMM识别电力价格态势，然后为每个态势训练独立的条件神经过程，最终通过态势加权混合生成预测。通过将预测集成到电池储能优化框架中，并采用TOPSIS多准则评估，结果表明，尽管其他模型在某些单一指标上表现突出，但R-NP模型在2021-2023年间被证明是最平衡和首选的解决方案，强调了运行效用而非单纯预测精度的重要性。

> **摘要翻译:** 这项工作将贝叶斯态势检测与条件神经过程相结合，用于德国市场24小时电力价格预测。我们的方法论将使用应用于每日电价的解耦粘性分层狄利克雷过程隐马尔可夫模型（DS-HDP-HMM）进行态势检测。每个识别出的态势随后由一个独立的条件神经过程（CNP）建模，该过程经过训练以学习从输入上下文到24维小时价格轨迹的局部映射，最终预测计算为这些CNP输出的态势加权混合。我们通过将R-NP的预测整合到各种电池储能优化框架中，包括价格套利、风险管理、电网服务和成本最小化，从而严格评估R-NP与深度神经网络（DNN）和Lasso估计自回归（LEAR）模型。这种运行效用评估揭示了复杂的性能权衡：LEAR通常能产生更高的绝对利润或更低的成本，而DNN在特定的成本最小化场景中表现出卓越的最优性。认识到原始预测精度不总能转化为最优的运行结果，我们采用TOPSIS作为全面的多准则评估层。我们的TOPSIS分析将LEAR确定为2021年的最佳模型，但重要的是，我们提出的R-NP模型在2021、2022和2023年被认为是平衡性最佳和首选的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [514] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
> *肽中氢原子转移反应势能面的学习*

*Marlen Neubert, Patrick Reiser, Frauke Gräter, Pascal Friederich* | **Category: cs.LG, cond-mat.mtrl-sci, physics.chem-ph, physics.comp-ph, q-bio.BM** | **Updated: 2025-08-01**

**Keywords:** 氢原子转移, 机器学习势能, 图神经网络, 肽, 反应势垒

**Comment:** 19 pages, 12 figures, and 4 tables (references and SI included)

> **TL;DR:** 该研究利用机器学习（特别是MACE图神经网络）精确预测肽中氢原子转移的势能面和反应势垒，从而实现大规模模拟，推进对生物过程中HAT机制的理解。

**AI_Comments:** 这篇论文展示了将机器学习应用于复杂生物反应模拟的重大进展。其创新点在于系统地生成数据和严格基准测试不同的图神经网络架构，特别是MACE所展现出的卓越性能。能够在生物学相关尺度上实现接近量子的精度，并支持大规模模拟，对于理解基本的生物过程至关重要。论文中对模型泛化能力和未来改进策略的讨论进一步突显了其潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 氢原子转移（HAT）反应在许多生物过程中（如受损蛋白质中的自由基迁移）至关重要，但其作用机制路径仍未完全理解。在生物相关尺度上实现量子化学精度模拟HAT具有挑战性，传统的经典力场和基于DFT的分子动力学方法均不适用。机器学习势能面提供了一种替代方案，但训练这些模型以泛化到各种HAT配置，特别是在蛋白质中的自由基位置，是其主要挑战。

**Method:** 研究人员系统地生成了肽中的HAT配置，并使用半经验方法和DFT构建了大型数据集。他们评估了三种图神经网络架构（SchNet、Allegro和MACE）在学习HAT势能面和间接从能量预测反应势垒方面的能力。此外，他们还分析了标度律、模型可迁移性和成本-性能权衡，并提出了通过结合ML势能面与过渡态搜索算法和主动学习来改进的策略。

**Result:** MACE在能量、力和势垒预测方面始终优于SchNet和Allegro。在离分布的DFT势垒预测中，MACE实现了1.13 kcal/mol的平均绝对误差。这种高精度使得机器学习势能面能够集成到大规模胶原蛋白模拟中，从而根据预测的势垒计算反应速率。

**Conclusion:** 本研究的方法推进了对肽中HAT和自由基迁移的机制理解，并可推广到其他生物分子系统，从而实现复杂环境中化学反应的量子精确模拟。

> **ai_Abstract:** 本论文解决了在肽中精确模拟氢原子转移（HAT）反应的挑战，该反应在生物过程中至关重要但难以用量子精度大规模建模。作者开发了一种机器学习方法，利用半经验方法和DFT生成了大量的HAT构型数据集。他们对三种图神经网络进行了基准测试，发现MACE在能量、力和势垒预测方面始终表现最佳，实现了高精度（势垒预测的平均绝对误差为1.13 kcal/mol）。这使得ML势能面能够集成到大规模模拟中以理解HAT机制，并可推广到其他生物分子系统。

> **摘要翻译:** 氢原子转移 (HAT) 反应在许多生物过程中至关重要，例如受损蛋白质中的自由基迁移，但其作用机制路径仍未完全理解。模拟 HAT 具有挑战性，因为它需要在生物学相关尺度上达到量子化学精度；因此，无论是经典力场还是基于 DFT 的分子动力学都不可适用。机器学习势能面提供了一种替代方案，能够以接近量子的精度学习势能面 (PES)。然而，训练这些模型以泛化到各种 HAT 配置，特别是在蛋白质中的自由基位置，需要定制的数据生成和仔细的模型选择。
在此，我们系统地生成肽中的 HAT 配置，利用半经验方法和 DFT 构建大型数据集。我们评估了三种图神经网络架构（SchNet、Allegro 和 MACE）在学习 HAT PES 和间接从能量预测反应势垒方面的能力。MACE 在能量、力和势垒预测方面始终优于其他模型，在离分布的 DFT 势垒预测中实现了 1.13 kcal/mol 的平均绝对误差。这种精度使得机器学习势能面能够集成到大规模胶原蛋白模拟中，从而根据预测的势垒计算反应速率，从而推进对肽中 HAT 和自由基迁移的机制理解。我们分析了标度律、模型可迁移性和成本-性能权衡，并概述了通过将机器学习势能面与过渡态搜索算法和主动学习相结合来改进的策略。我们的方法可推广到其他生物分子系统，从而实现复杂环境中化学反应的量子精确模拟。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [521] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
> *主动学习在现代机器学习中的作用*

*Thorben Werner, Lars Schmidt-Thieme, Vijaya Krishna Yalavarthi* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 主动学习, 数据增强, 半监督学习, 低数据场景, 性能优化

**Comment:** 

> **TL;DR:** 主动学习（AL）因计算成本高且在低数据场景下提升小而未被广泛应用。研究发现，数据增强（DA）和半监督学习（SSL）在低数据场景下更有效。然而，当AL与DA和SSL结合时，仍能提供性能提升。因此，AL应被视为在应用DA和SSL后，进一步提升模型性能的最后一步。

**AI_Comments:** 这篇论文的创新点在于它重新定义了主动学习（AL）在现代机器学习流程中的角色。它挑战了传统观念，即AL是解决数据标签稀缺的首选方法，并指出在基础数据增强（DA）和半监督学习（SSL）之后，AL才能发挥其最大价值，作为一种精细调优的工具。这对于指导实际应用中选择合适的数据策略具有重要意义，避免了对AL的过度期望和不当使用。

<details>
  <summary>Details</summary>

**Motivation:** 主动学习（AL）尽管被广泛研究，但很少在其自身科学文献之外的背景下应用。作者认为这是因为AL的计算成本高，并且在标记点较少的情况下，它通常只能产生相对较小的提升。

**Method:** 本研究通过比较数据增强（DA）、半监督学习（SSL）和主动学习（AL）这三种方法，来研究它们在低数据场景下的影响。

**Result:** 研究发现，主动学习（AL）是解决低数据问题效率最低的方法，与随机抽样相比仅能产生1-4%的提升。而数据增强（DA）和半监督学习（SSL）方法与随机抽样结合时，可以产生高达60%的提升。然而，当AL与强大的DA和SSL技术结合时，它仍然能够提供改进。

**Conclusion:** 基于研究结果，论文将主动学习（AL）重新定义为，在应用了适当的数据增强（DA）和半监督学习（SSL）方法之后，从数据中挤出最后一点性能的最终构建模块，而非一种对抗标签缺失的方法。

> **ai_Abstract:** 本研究探讨了主动学习（AL）在实际应用中受限的原因，即其高计算成本和在低数据场景下性能提升有限。通过比较AL、数据增强（DA）和半监督学习（SSL）在解决低数据问题上的效果，论文发现DA和SSL比AL更有效。然而，当AL与强大的DA和SSL技术结合时，它仍能带来性能提升。因此，论文提出应将AL视为在数据经过DA和SSL处理后，用于进一步优化性能的最后一步，而非主要的数据缺失处理方法。

> **摘要翻译:** 尽管主动学习（AL）被广泛研究，但它很少应用于其自身科学文献之外的场景。我们认为这是因为AL的高计算成本以及在标记点较少的情况下，它通常只能产生相对较小的提升。在这项工作中，我们研究了对抗这种低数据场景的不同方法的影响，即数据增强（DA）、半监督学习（SSL）和AL。我们发现，AL是解决低数据问题效率最低的方法，与随机抽样相比仅能产生1-4%的提升，而DA和SSL方法与随机抽样结合时，可以产生高达60%的提升。然而，当AL与强大的DA和SSL技术结合时，它出人意料地仍然能够提供改进。基于这些结果，我们将AL不再视为一种对抗缺失标签的方法，而是将其视为在应用了适当的DA和SSL方法之后，从数据中挤出最后一点性能的最终构建模块。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [523] [Disparate Conditional Prediction in Multiclass Classifiers](https://arxiv.org/abs/2206.03234)
> *多类别分类器中的差异条件预测*

*Sivan Sabato, Eran Treister, Elad Yom-Tov* | **Category: cs.LG, cs.CY, stat.ML** | **Updated: 2025-07-31**

**Keywords:** 多类别分类器, 公平性, 差异条件预测, 均衡赔率, 局部优化

**Comment:** Published at ICML 2025

> **TL;DR:** 本文提出了一种将差异条件预测（DCP）推广到多类别分类器的方法，并开发了新的局部优化方法来估计多类别DCP，以审计分类器的公平性并检测不公平对待。

**AI_Comments:** 本文的创新点在于将DCP这一衡量公平性的指标推广到更复杂的多元分类场景，并提出了在数据可访问性受限情况下仍能进行公平性审计的实用方法，这对于提升机器学习模型的公平性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 审计多类别分类器在多类别均衡赔率下的公平性，并通过估计分类器不完全公平时与均衡赔率的偏差。

**Method:** 将Sabato & Yom-Tov (2020) 为二元分类器提出的差异条件预测（DCP）度量推广到多类别分类器。提出了新的局部优化方法来估计多类别DCP，适用于两种情况：一是已知每个受保护子群体的条件混淆矩阵，二是无法估计这些矩阵（例如分类器不可访问或缺乏高质量个体数据）。

**Result:** 实验证明了所提出方法的准确性。这些方法可以用于检测可能不公平对待大部分人群的分类器。

**Conclusion:** 本文提出的方法能够有效审计多类别分类器的公平性，并通过估计多类别DCP来识别对人群进行不公平对待的分类器，且方法已被实验证明准确。

> **ai_Abstract:** 本文提出了一套用于审计多类别分类器公平性的方法，特别是在多类别均衡赔率框架下。核心贡献是将原用于二元分类器的差异条件预测（DCP）度量推广至多类别场景，并开发了新的局部优化算法以估计多类别DCP。这些算法适用于已知或未知条件混淆矩阵的两种不同数据可访问性情况。实验证明了这些方法的准确性，它们能够有效识别那些可能对大量人口进行不公平对待的分类器。

> **摘要翻译:** 我们提出了在多类别均衡赔率下审计多类别分类器公平性的方法，通过估算当分类器不完全公平时与均衡赔率的偏差。我们将Sabato & Yom-Tov (2020) 最初为二元分类器提出的差异条件预测（DCP）度量推广到多类别分类器。DCP被定义为分类器以与最接近的共同基线不同的条件预测概率进行预测的人口比例。我们提供了新的局部优化方法，用于在两种不同情况下估计多类别DCP：一种是已知每个受保护子群体的条件混淆矩阵，另一种是无法估计这些矩阵的情况，例如分类器不可访问或无法获得高质量的个体级别数据。这些方法可用于检测可能不公平对待大部分人群的分类器。实验证明了这些方法的准确性。代码可在 https://github.com/sivansabato/DCPmulticlass 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [528] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
> *基于相似性自构建图模型，利用图神经网络和EHR数据预测患者危重程度*

*Mukesh Kumar Sahu, Pinki Roy* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 患者危重程度预测, 图神经网络, 电子健康记录, 相似性图, ICU

**Comment:** 

> **TL;DR:** 提出一种基于相似性的自构建图模型（SBSCGM）和混合图神经网络（HybridGraphMedGNN），利用EHR数据预测ICU患者危重程度，并取得SOTA性能。

**AI_Comments:** 该论文的创新点在于提出了动态构建患者相似性图的SBSCGM模型，并通过混合相似性度量有效利用了EHR数据中的关系结构。结合多种GNN层的HybridGraphMedGNN架构增强了模型学习鲁棒表示的能力。模型的SOTA性能和可解释性使其在临床应用中具有重要潜力。

<details>
  <summary>Details</summary>

**Motivation:** 准确预测ICU患者的危重程度（如ICU内死亡风险）对于早期干预至关重要。然而，传统模型通常独立处理每个患者，难以利用电子健康记录（EHR）中的关系结构。

**Method:** 提出相似性自构建图模型（SBSCGM），从多模态EHR数据中动态构建患者相似性图。采用混合相似性度量（结合基于特征和结构相似性）实时连接临床特征相似的患者。在此图上运行HybridGraphMedGNN架构，该架构集成了图卷积网络（GCN）、GraphSAGE和图注意力网络（GAT）层，以学习鲁棒的患者表示，利用局部和全局图模式预测患者死亡率和连续危重程度评分。

**Result:** 在MIMIC-III数据集的6,000名ICU患者实验中，模型达到最先进性能（AUC-ROC 0.94），优于基线分类器和单一类型GNN模型。还展示了改进的精度/召回率，并且注意力机制提供了可解释的洞察力。

**Conclusion:** 该框架为危重症风险预测提供了一个可扩展和可解释的解决方案，并有潜力支持临床医生在真实ICU中的部署。

> **ai_Abstract:** 该论文提出了一种名为SBSCGM的相似性自构建图模型，用于从多模态EHR数据中动态构建患者相似性图，并结合HybridGraphMedGNN架构（集成GCN、GraphSAGE、GAT）在该图上进行危重症预测。该模型在MIMIC-III数据集上取得了0.94的AUC-ROC，优于现有方法，并提供了可解释的预测，为ICU危重症风险预测提供了可扩展和可解释的解决方案。

> **摘要翻译:** 准确预测ICU患者的危重程度（如ICU内死亡风险）对于危重症护理中的早期干预至关重要。然而，传统模型通常独立处理每个患者，并且难以利用电子健康记录（EHR）中的关系结构。我们提出了一种基于相似性的自构建图模型（SBSCGM），该模型从多模态EHR数据中动态构建患者相似性图，以及一个在此图上运行的HybridGraphMedGNN架构，用于预测患者死亡率和连续危重程度评分。SBSCGM使用混合相似性度量（结合基于特征和结构相似性）实时连接具有相似临床特征的患者。HybridGraphMedGNN集成了图卷积网络（GCN）、GraphSAGE和图注意力网络（GAT）层，以学习鲁棒的患者表示，利用局部和全局图模式。在MIMIC-III数据集的6,000名ICU患者实验中，我们的模型取得了最先进的性能（AUC-ROC 0.94），优于基线分类器和单一类型GNN模型。我们还展示了改进的精度/召回率，并表明注意力机制提供了对模型预测的可解释性洞察。我们的框架为危重症风险预测提供了一个可扩展和可解释的解决方案，并有潜力支持临床医生在真实ICU中的部署。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [531] [Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates](https://arxiv.org/abs/2507.23607)
> *基于深度学习的临床试验招募预测及不确定性估计*

*Tien Huu Do, Antoine Masquelier, Nae Eoun Lee, Jonathan Crowther* | **Category: cs.LG, cs.AI, cs.CL** | **Updated: 2025-07-31**

**Keywords:** 深度学习, 临床试验, 患者招募, 不确定性估计, 预训练语言模型

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的深度学习方法，结合预训练语言模型和注意力机制，并引入伽马分布的概率层，以更准确地预测临床试验患者招募人数并提供不确定性估计，实验证明其优于现有基线模型。

**AI_Comments:** 该论文的创新点在于将预训练语言模型与传统的表格数据处理相结合，并通过引入基于伽马分布的概率层来量化预测的不确定性，这对于临床试验这种高风险、高投入的领域尤为重要。提供不确定性估计能让决策者更好地评估风险，优化资源分配。该方法对临床试验规划具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 临床试验的成功在很大程度上依赖于准确的患者招募预测，然而，在规划阶段准确预测患者招募人数是一个主要挑战。现有的方法可能无法充分捕捉临床文档的复杂性和招募过程中的不确定性。

**Method:** 本文提出了一种新颖的深度学习方法。该方法使用神经网络模型，利用预训练语言模型（PLMs）将临床文档转换为表达性表示，然后通过注意力机制将这些表示与编码的表格特征结合。为解决招募预测中的不确定性，模型增强了一个基于伽马分布的概率层，以实现范围估计。该模型应用于预测临床试验持续时间，假设站点级招募遵循泊松-伽马过程。

**Result:** 在真实世界临床试验数据上的广泛实验表明，所提出的方法能够有效预测给定临床试验在多个站点招募的患者数量，并且优于已建立的基线模型。

**Conclusion:** 本文提出的深度学习方法，通过整合预训练语言模型和概率层，显著提高了临床试验患者招募预测的准确性，并能提供不确定性估计，为临床试验的规划提供了更可靠的工具。

> **ai_Abstract:** 本文提出了一种创新的深度学习模型，旨在解决临床试验患者招募预测的挑战。该模型结合了预训练语言模型（PLMs）处理临床文档的复杂性，并利用注意力机制整合表格特征。为提供预测的不确定性估计，模型引入了基于伽马分布的概率层。实验结果表明，该方法在预测临床试验招募人数方面表现出色，并优于现有基线模型，为临床试验的有效规划提供了有力支持。

> **摘要翻译:** 临床试验是评估新药或新疗法安全性与有效性的系统性努力。进行此类试验通常需要大量的财政投入和细致的规划，这凸显了准确预测试验结果的必要性。准确预测患者招募人数是试验成功的关键因素，也是规划阶段的主要挑战之一。在这项工作中，我们提出了一种新颖的基于深度学习的方法来解决这一关键挑战。我们的方法以神经网络模型实现，利用预训练语言模型（PLMs）来捕捉临床文档的复杂性和细微差别，将其转化为富有表现力的表示。然后，这些表示通过注意力机制与编码的表格特征相结合。为了考虑招募预测中的不确定性，我们通过一个基于伽马分布的概率层增强了模型，该层能够进行范围估计。我们应用所提出的模型来预测临床试验持续时间，假设站点级招募遵循泊松-伽马过程。我们在真实世界的临床试验数据上进行了广泛实验，结果表明，所提出的方法能够有效预测给定临床试验在多个站点招募的患者数量，并且优于已建立的基线模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [535] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
> *IAMAP：为非编码人员和有限计算资源在QGIS中解锁深度学习*

*Paul Tresson, Pierre Le Coz, Hadrien Tulet, Anthony Malkassian, Maxime Réjou Méchain* | **Category: cs.LG, I.4.9; I.4.6** | **Updated: 2025-08-01**

**Keywords:** 深度学习, QGIS, 遥感, 自监督学习, 基础模型

**Comment:** 11 pages, 5 figures

> **TL;DR:** IAMAP是一个QGIS插件，使非专业人士能够在有限资源下使用深度学习进行遥感图像分析。

**AI_Comments:** IAMAP的创新之处在于它通过一个用户友好的QGIS插件，将复杂的深度学习技术民主化，使其对非编码人员和资源受限的用户可用。它利用了自监督学习和基础模型的最新进展，有效解决了传统深度学习在遥感领域应用中的主要障碍（数据、算力、技能）。这对于推动地理空间分析和遥感领域的AI应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 遥感领域深度学习的应用受限于需要大量参考数据集、强大的计算资源和高超的编码技能，导致其实施主要局限于专业人员。

**Method:** 本文介绍了IAMAP，一个用户友好的QGIS插件。它利用自监督学习策略（基础模型）提供的稳健特征提取器，支持少量样本或零样本场景。IAMAP的界面允许用户简化遥感图像分析的几个关键步骤，包括：提取图像特征、使用内置算法降维、对特征进行聚类、生成特征相似性图以及校准和验证监督机器学习模型进行预测。

**Result:** IAMAP使得非AI专业人员无需GPU容量或大量参考数据集，即可利用最新的深度学习方法提供的高质量特征。

**Conclusion:** IAMAP有助于计算高效和节能的深度学习方法的民主化，使非AI专家也能利用深度学习的优势。

> **ai_Abstract:** IAMAP是一个创新的QGIS插件，旨在解决遥感领域深度学习应用中面临的挑战，即需要大量数据、计算资源和编码技能。该插件利用自监督学习和基础模型，提供强大的特征提取能力，并支持少量样本或零样本学习。IAMAP通过直观的界面，使用户能够执行图像特征提取、降维、聚类、生成特征相似性图以及模型校准和验证等关键步骤。它使得非AI专业人员也能高效利用深度学习，无需昂贵的GPU或大量数据集，从而推动了计算高效和节能深度学习方法的普及。

> **摘要翻译:** 随着人工智能方法的快速发展，遥感进入了一个新时代。然而，深度学习的实施在很大程度上仍局限于专家，并且不切实际，因为它通常需要 (i) 用于模型训练和验证的大型参考数据集；(ii) 大量计算资源；以及 (iii) 强大的编码技能。在此，我们介绍了 IAMAP，一个用户友好的 QGIS 插件，它以一种简单而灵活的方式解决了这三个挑战。IAMAP 建立在自监督学习策略的最新进展之上，这些策略现在提供了强大的特征提取器，通常被称为基础模型。这些通用模型通常可以在少量样本或零样本场景中可靠地使用（即，几乎无需微调）。IAMAP 的界面允许用户简化遥感图像分析的几个关键步骤：(i) 使用各种深度学习架构提取图像特征；(ii) 使用内置算法降维；(iii) 对特征或其降维表示进行聚类；(iv) 生成特征相似性图；以及 (v) 校准和验证用于预测的监督机器学习模型。通过使非 AI 专业人员能够利用最新的深度学习方法提供的高质量特征，而无需 GPU 容量或大量的参考数据集，IAMAP 有助于计算高效和节能的深度学习方法的民主化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [542] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
> *分离变量谱神经网络：一种用于高频偏微分方程的物理信息学习方法*

*Xiong Xiong, Zhuo Zhang, Rongchun Hu, Chen Gao, Zichen Deng* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 谱偏差, 物理信息神经网络, 偏微分方程, 分离变量, 高频

**Comment:** 

> **TL;DR:** SV-SNN是一种新型物理信息神经网络，通过结合变量分离和自适应谱方法，解决了传统PINN在求解高频偏微分方程时存在的谱偏差问题，显著提高了精度并减少了计算资源。

**AI_Comments:** 这项工作在解决物理信息神经网络（PINNs）长期存在的谱偏差问题上取得了显著进展，特别是在处理高频偏微分方程方面。其创新之处在于结合了变量分离和自适应谱方法，这不仅提高了模型的准确性，还大幅优化了计算效率，减少了参数量和训练时间。这对于科学计算领域，尤其是涉及复杂物理系统的模拟，具有重要的实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决高频振荡偏微分方程（PDEs）在科学计算中的关键挑战，特别是传统物理信息神经网络（PINNs）存在的谱偏差问题，该问题限制了其捕捉高频解分量的能力。

**Method:** 本文引入了分离变量谱神经网络（SV-SNN）框架，通过整合变量分离和自适应谱方法来解决传统PINN的局限性。其核心创新包括：1）将多元函数分解为单变量函数乘积，实现独立的空间和时间网络；2）采用具有可学习频率参数的自适应傅里叶谱特征以捕捉高频信息；3）基于奇异值分解的理论框架来量化谱偏差。

**Result:** 在包括热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程在内的基准问题上，SV-SNN的精度提高了1-3个数量级，同时参数数量减少了90%以上，训练时间减少了60%。

**Conclusion:** SV-SNN被确立为解决神经网络PDE求解中谱偏差问题的有效方案。

> **ai_Abstract:** 本文提出了一种名为分离变量谱神经网络（SV-SNN）的新型物理信息学习框架，旨在解决传统物理信息神经网络（PINNs）在求解高频偏微分方程时存在的谱偏差问题。SV-SNN通过将多元函数分解、引入自适应傅里叶谱特征以及建立量化谱偏差的理论框架来实现。实验结果表明，SV-SNN在精度、参数数量和训练时间上均显著优于现有方法，为高频PDE的神经求解提供了有效方案。

> **摘要翻译:** 解决高频振荡偏微分方程（PDEs）是科学计算中的一个关键挑战，其应用涵盖流体力学、量子力学和电磁波传播。传统的物理信息神经网络（PINNs）存在谱偏差问题，限制了它们捕捉高频解分量的能力。我们引入了分离变量谱神经网络（SV-SNN），这是一个新颖的框架，通过将变量分离与自适应谱方法相结合来解决这些局限性。我们的方法具有三个关键创新点：（1）将多元函数分解为单变量函数乘积，从而实现独立的空间和时间网络；（2）具有可学习频率参数的自适应傅里叶谱特征，用于捕捉高频信息；（3）基于奇异值分解的理论框架，用于量化谱偏差。对包括热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程在内的基准问题的综合评估表明，SV-SNN在精度上实现了1-3个数量级的提升，同时参数数量减少了90%以上，训练时间减少了60%。这些结果确立了SV-SNN作为神经网络PDE求解中谱偏差问题的有效解决方案。该实现将在被接受后公开发布在https://github.com/xgxgnpu/SV-SNN。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [547] [H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity](https://arxiv.org/abs/2507.22633)
> *H2Tune：混合异构联邦基础模型微调*

*Wei Guo, Siyuan Lu, Yiqi Tong, Zhaojun Hu, Fuzhen Zhuang, Xiao Zhang, Tao Fan, Jin Dong* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 联邦学习, 基础模型微调, 混合异构性, 知识解耦, 稀疏化三重矩阵分解

**Comment:** 

> **TL;DR:** H2Tune通过解决模型架构和下游任务双重异构性，改进了联邦基础模型微调，实现了显著的性能提升。

**AI_Comments:** H2Tune的创新点在于其提出了一个全面的框架来应对联邦学习中基础模型微调的双重异构性，特别是在维度对齐和知识解耦方面的设计。这对于实际部署中客户端资源和任务多样性较大的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有联邦微调（FFT）方法未充分探索混合异构联邦微调（HHFFT）场景，即客户端同时存在模型架构和下游任务的异构性。这导致两大挑战：1）异构矩阵聚合，因客户端采用不同大尺寸基础模型而导致LoRA参数聚合时维度不匹配；2）多任务知识干扰，本地共享参数中任务共享和任务特定知识未能有效分离，导致知识传输不纯。

**Method:** 本文提出了H2Tune框架，包含三个关键组件：(i) 稀疏化三重矩阵分解，通过构建秩一致的中间矩阵对齐客户端隐藏维度，并根据资源自适应稀疏化；(ii) 关系引导矩阵层对齐，处理异构层结构和表示能力；(iii) 交替任务知识解缠机制，通过交替优化解耦本地模型参数的共享和特定知识。

**Result:** 理论分析证明收敛率为O(1/√T)。广泛实验表明，与现有最先进的基线相比，H2Tune实现了高达15.4%的准确率提升。

**Conclusion:** H2Tune有效解决了混合异构联邦基础模型微调中的异构矩阵聚合和多任务知识干扰挑战，显著提高了性能。

> **ai_Abstract:** 本文提出了H2Tune，一种针对混合异构联邦基础模型微调（HHFFT）的新方法。HHFFT面临模型架构和下游任务双重异构性带来的异构矩阵聚合和多任务知识干扰问题。H2Tune通过稀疏化三重矩阵分解对齐维度，关系引导矩阵层对齐处理异构结构，以及交替任务知识解缠机制分离共享和特定知识来解决这些挑战。理论分析显示其收敛率为O(1/√T)，实验结果表明其准确率比现有基线提高高达15.4%。

> **摘要翻译:** 与现有针对基础模型的联邦微调（FFT）方法不同，混合异构联邦微调（HHFFT）是一个探索不足的场景，其中客户端在模型架构和下游任务方面都表现出双重异构性。这种混合异构性引入了两个重大挑战：1）异构矩阵聚合，即客户端根据其任务要求和资源限制采用不同的D大尺寸基础模型，导致LoRA参数聚合期间的维度不匹配；2）多任务知识干扰，即本地共享参数在训练时既包含任务共享知识又包含任务特定知识，无法确保只有任务共享知识在客户端之间传输。为了解决这些挑战，我们提出了H2Tune，一种具有混合异构性的联邦基础模型微调方法。我们的H2Tune框架由三个关键组件组成：(i)稀疏化三重矩阵分解，通过构建秩一致的中间矩阵来对齐客户端之间的隐藏维度，并根据客户端资源进行自适应稀疏化；(ii)关系引导矩阵层对齐，用于处理异构层结构和表示能力；(iii)交替任务知识解缠机制，通过交替优化解耦本地模型参数的共享和特定知识。理论分析证明了O(1/√T)的收敛速度。广泛的实验表明，与最先进的基线相比，我们的方法实现了高达15.4%的准确率提升。我们的代码可在https://anonymous.4open.science/r/H2Tune-1407获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [549] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
> *KFS：基于KAN的自适应频率选择学习架构，用于长期时间序列预测*

*Changning Wu, Gao Wu, Rongyao Cai, Yong Liu, Kexin Zhang* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 时间序列预测, 多尺度分解, KAN, 频率选择, 自适应学习

**Comment:** 

> **TL;DR:** KFS是一个基于KAN的自适应频率选择学习架构，通过处理跨尺度噪声和复杂模式建模，在长期时间序列预测中实现了最先进的性能。

**AI_Comments:** KFS的创新点在于结合了KAN和Parseval定理，并引入了FreK模块进行自适应频率选择，以有效处理时间序列中的噪声和复杂模式。其简单有效的设计使其在长期时间序列预测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多尺度分解架构在时间序列预测中存在跨尺度噪声干扰和不同频率分量间异构信息分布导致次优多尺度表示的问题。

**Method:** KFS（KAN based adaptive Frequency Selection learning architecture）框架通过其FreK模块在频谱域进行基于能量分布的优势频率选择，以解决跨尺度噪声干扰和复杂模式建模的预测挑战。同时，KAN支持复杂的模式表示，时间戳嵌入对齐同步跨尺度的时间表示。特征混合模块融合尺度特定模式与对齐的时间特征。

**Result:** 在多个真实世界时间序列数据集上的大量实验表明，KFS作为一个简单而有效的架构，实现了最先进的性能。

**Conclusion:** KFS通过其创新的频率选择和模式表示机制，有效解决了时间序列预测中的多尺度噪声干扰和复杂模式建模问题，达到了SOTA性能。

> **ai_Abstract:** 本文提出了KFS（KAN based adaptive Frequency Selection learning architecture），一个用于长期时间序列预测的新架构，旨在解决多尺度分解中存在的跨尺度噪声干扰和异构信息分布导致的次优表示问题。KFS受到KAN和Parseval定理的启发，包含一个FreK模块，用于在频谱域进行基于能量分布的优势频率选择，以及利用KAN进行复杂模式表示和时间戳嵌入对齐以同步时间特征。通过特征混合模块融合这些信息。实验证明，KFS在多个真实世界数据集上达到了最先进的性能。

> **摘要翻译:** 多尺度分解架构已成为时间序列预测中的主要方法。然而，真实世界的时间序列在不同尺度上表现出噪声干扰，而不同尺度的频率分量之间异构的信息分布导致次优的多尺度表示。受Kolmogorov-Arnold网络（KAN）和Parseval定理的启发，我们提出了一种基于KAN的自适应频率选择学习架构（KFS）来解决这些挑战。该框架通过其FreK模块解决源于跨尺度噪声干扰和复杂模式建模的预测挑战，该模块在频谱域执行基于能量分布的优势频率选择。同时，KAN支持复杂的模式表示，而时间戳嵌入对齐则同步跨尺度的时间表示。然后，特征混合模块将尺度特定模式与对齐的时间特征融合。在多个真实世界时间序列数据集上的大量实验表明，KFS作为一个简单而有效的架构，实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [555] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
> *强化学习在无人机蜂群防御中决策级拦截优先级方面的应用*

*Alessandro Palmas* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 强化学习, 无人机蜂群, 拦截优先级, 防御系统, 决策级

**Comment:** 11 pages, 10 figures

> **TL;DR:** 本文展示了强化学习如何有效应对无人机蜂群威胁，通过学习优化拦截优先级，显著提高了防御效率和降低了伤害。

**AI_Comments:** 该论文创新性地将强化学习应用于无人机蜂群防御的决策级拦截优先级问题，特别是在高保真模拟环境中进行训练和验证，增强了实际应用的可行性。其优势在于能够学习复杂的协调策略，超越传统规则，且不取代现有系统，具有重要的理论和实践意义。代码和资产的公开性也大大提高了研究的可复现性。

<details>
  <summary>Details</summary>

**Motivation:** 低成本自杀式无人机蜂群对现代防御系统构成严峻挑战，需要快速和战略性地决策，以在多个效应器和高价值目标区域之间优先进行拦截。

**Method:** 引入了一个高保真模拟环境，在此环境中，一个决策级强化学习智能体学习协调多个效应器以实现最优拦截优先级。该智能体在离散动作空间中操作，根据观察到的状态特征（如位置、类别和效应器状态）为每个效应器选择要交战的无人机。

**Result:** 强化学习策略在数百个模拟攻击场景中，始终比手工规则基线实现了更低的平均损害和更高的防御效率。

**Conclusion:** 强化学习作为防御架构中的战略层，具有增强韧性的潜力，而无需取代现有控制系统。

> **ai_Abstract:** 本文通过一个案例研究，探讨了强化学习在应对低成本无人机蜂群威胁中的应用。研究团队开发了一个高保真模拟环境，并训练了一个决策级强化学习智能体来优化多个效应器对无人机的拦截优先级。实验结果表明，与传统的规则基线相比，强化学习策略能显著降低平均损害并提高防御效率，证明了其在增强防御系统韧性方面的潜力。

> **摘要翻译:** 低成本自杀式无人机蜂群日益增长的威胁对现代防御系统构成了严峻挑战，要求快速和战略性地决策，以在多个效应器和高价值目标区域之间优先进行拦截。在这项工作中，我们提出了一个案例研究，展示了强化学习在解决这一挑战方面的实际优势。我们引入了一个高保真模拟环境，该环境捕捉了现实的操作约束，在此环境中，一个决策级强化学习智能体学习协调多个效应器以实现最优拦截优先级。该智能体在离散动作空间中操作，根据观察到的状态特征（如位置、类别和效应器状态）为每个效应器选择要交战的无人机。我们针对数百个模拟攻击场景，评估了所学策略与手工规则基线的表现。基于强化学习的策略在保护关键区域方面始终实现了更低的平均损害和更高的防御效率。本案例研究强调了强化学习作为防御架构中战略层的潜力，在不取代现有控制系统的情况下增强了韧性。所有代码和模拟资产均已公开发布，以实现完全可复现性，并且视频演示说明了策略的定性行为。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [556] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
> *像人类一样学习：通过认知发展阶段实现资源高效的联邦微调*

*Yebo Wu, Jingguang Li, Zhijiang Guo, Li Li* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 联邦微调, 大型语言模型, 认知发展, 资源高效, 边缘设备

**Comment:** 

> **TL;DR:** DevFT 是一种受人类认知发展启发的资源高效联邦微调方法，能加速收敛、减少通信开销并提升性能。

**AI_Comments:** 该论文的创新之处在于将人类认知发展阶段的概念引入到联邦微调中，通过分阶段构建和知识迁移，有效解决了LLM在边缘设备上联邦微调的资源效率问题。其提出的冲突消解引导的层分组和基于差异的层融合方法也极具创新性，有助于高效提取和整合模型知识。这项工作对于推动LLM在资源受限环境下的广泛部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦微调虽然能使大型语言模型（LLMs）适应下游任务并保护数据隐私，但其资源密集型特性限制了在边缘设备上的部署。

**Method:** 该论文提出了发展式联邦微调（DevFT）方法，该方法受认知发展启发，将微调过程分解为多个发展阶段，每个阶段优化具有递增参数容量的子模型。早期阶段的知识会转移到后续子模型，提供优化的初始化参数。DevFT 还引入了冲突消解引导的层分组和基于差异的层融合，以提取关键信息并构建代表性层。

**Result:** 在多个基准测试中，DevFT 显著优于现有最先进方法，实现了高达 4.59 倍的收敛速度提升，10.67 倍的通信开销减少，以及平均 9.07% 的性能提升，同时保持与现有方法的兼容性。

**Conclusion:** DevFT 是一种受人类认知发展启发的、资源高效且有效的联邦微调大型语言模型的方法。

> **ai_Abstract:** 该论文提出了一种名为发展式联邦微调（DevFT）的资源高效方法，旨在解决联邦微调大型语言模型（LLMs）在边缘设备上部署的资源限制问题。DevFT 受人类认知发展启发，将微调过程分解为多个阶段，逐步构建LLM，并通过知识迁移和创新的层操作（如冲突消解引导的层分组和基于差异的层融合）来优化训练。实验结果表明，DevFT 在收敛速度、通信开销和性能方面均显著优于现有方法。

> **摘要翻译:** 联邦微调使大型语言模型（LLMs）能够适应下游任务，同时保护数据隐私，但其资源密集型特性限制了在边缘设备上的部署。在本文中，我们引入了发展式联邦微调（DevFT），这是一种受认知发展启发的资源高效方法，它从紧凑的基础逐步构建一个强大的LLM。DevFT 将微调过程分解为多个发展阶段，每个阶段优化具有递增参数容量的子模型。早期阶段的知识会转移到后续子模型，提供优化的初始化参数，从而防止收敛到局部最小值并加速训练。这种范式模仿了人类学习，在完善现有技能的同时逐步构建全面的知识结构。为了高效地构建特定阶段的子模型，DevFT 引入了冲突消解引导的层分组和基于差异的层融合，以提取基本信息并构建代表性层。在多个基准测试中的评估表明，DevFT 显著优于现有最先进方法，实现了高达 4.59 倍的收敛速度提升，10.67 倍的通信开销减少，以及平均 9.07% 的性能提升，同时保持与现有方法的兼容性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods](https://arxiv.org/abs/2507.23010)
> *探讨多模态潜在空间的可逆性：基于优化方法的局限性*

*Siwoo Park* | **Category: cs.LG, cs.AI, cs.CV, cs.SD, eess.AS** | **Updated: 2025-07-30**

**Keywords:** 多模态潜在空间, 可逆性, 优化方法, 逆向映射, 语义可解释性

**Comment:** 

> **TL;DR:** 研究发现，尽管基于优化的方法可以强制多模态模型进行逆向映射，但其潜在空间在语义和感知上不具备一致的可逆性，逆向结果质量差且缺乏语义可解释性。

**AI_Comments:** 这项研究揭示了当前多模态AI模型的一个重要局限性，即其潜在空间在逆向任务中表现不佳，缺乏语义连贯性和可解释性。这表明现有模型虽然在生成和理解方面表现出色，但其内部表示可能并非真正“理解”了多模态数据之间的双向关系。这项工作为未来多模态模型的设计指明了方向，即需要考虑潜在空间的双向可逆性，以实现更深层次的多模态理解和推理。

<details>
  <summary>Details</summary>

**Motivation:** 现有多模态AI模型在正向任务上表现出色，但其逆向映射的潜力尚未被充分探索。研究旨在揭示这些模型在逆向任务中的局限性，特别是其潜在空间是否支持有意义的逆向映射。

**Method:** 提出了一种基于优化的框架，用于从期望输出推断输入特征。该框架双向应用于文本-图像（BLIP, Flux.1-dev）和文本-音频（Whisper-Large-V3, Chatterbox-TTS）模态。

**Result:** 实验结果一致验证了假设：虽然优化可以迫使模型产生与目标文本一致的输出，但这些逆向映射的感知质量是混乱且不连贯的。此外，从生成模型中推断原始语义输入时，重建的潜在空间嵌入通常缺乏语义可解释性，并与无意义的词汇标记对齐。

**Conclusion:** 多模态潜在空间主要针对特定正向任务进行优化，不具备支持鲁棒和可解释逆向映射所需的固有结构。这强调了需要进一步研究开发真正语义丰富且可逆的多模态潜在空间。

> **ai_Abstract:** 本文探讨了多模态AI模型潜在空间的可逆性，发现尽管基于优化的方法可以强制模型进行逆向任务，但其逆向映射在感知质量上混乱且语义上缺乏可解释性。研究通过文本-图像和文本-音频模态的实验验证了这一局限性，并指出当前多模态潜在空间主要针对正向任务优化，不具备支持鲁棒可解释逆向映射的内在结构，强调了未来研究应致力于开发真正语义丰富且可逆的潜在空间。

> **摘要翻译:** 本文研究了任务特定AI（人工智能）模型中多模态潜在空间的逆向能力和更广泛的实用性。尽管这些模型擅长其设计的正向任务（例如，文本到图像生成、音频到文本转录），但它们进行逆向映射的潜力在很大程度上仍未被探索。我们提出了一种基于优化的框架，用于从期望输出推断输入特征，并将其双向应用于文本-图像（BLIP、Flux.1-dev）和文本-音频（Whisper-Large-V3、Chatterbox-TTS）模态。
我们的核心假设认为，虽然优化可以引导模型执行逆向任务，但其多模态潜在空间不会持续支持语义上有意义且感知上连贯的逆向映射。实验结果一致验证了这一假设。我们证明，虽然优化可以强制模型产生与目标文本一致的输出（例如，文本到图像模型生成图像，图像字幕模型可以正确描述；或者ASR模型准确转录优化后的音频），但这些逆向的感知质量是混乱且不连贯的。此外，当试图从生成模型推断原始语义输入时，重建的潜在空间嵌入经常缺乏语义可解释性，并与无意义的词汇标记对齐。
这些发现凸显了一个关键局限性。多模态潜在空间，主要针对特定正向任务进行优化，并未固有地具备鲁棒和可解释逆向映射所需的结构。我们的工作强调了需要进一步研究开发真正语义丰富且可逆的多模态潜在空间。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [563] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
> *傅里叶神经算子的轻量级扩散乘子与不确定性量化*

*Albert Matveev, Sanmitra Ghosh, Aamal Hussain, James-Michael Leahy, Michalis Michaelides* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 傅里叶神经算子, 不确定性量化, 扩散乘子, 算子学习, 贝叶斯神经算子

**Comment:** 

> **TL;DR:** 本文引入了DINOZAUR，一种基于扩散的神经算子，它用轻量级扩散乘子替代了傅里叶神经算子（FNOs）中的密集张量乘子，显著减少了参数量和内存占用，同时通过贝叶斯方法提供了有效的性能和不确定性量化。

**AI_Comments:** 这项工作通过引入创新的扩散乘子和贝叶斯不确定性量化机制，有效解决了傅里叶神经算子在可扩展性和可靠性方面的核心限制。其通过减少参数量和提供原生不确定性量化，为科学和工程应用中的偏微分方程求解提供了更高效和可靠的工具，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 傅里叶神经算子（FNOs）在解决偏微分方程方面面临显著的可扩展性挑战，主要表现为过度参数化。此外，FNOs缺乏原生的不确定性量化能力，而这对于可靠的科学和工程应用至关重要。现有的神经算子依赖于事后不确定性量化方法，这些方法忽略了几何归纳偏差。

**Method:** 本文提出了DINOZAUR：一种基于扩散的神经算子参数化方法，具备不确定性量化能力。DINOZAUR受到热核结构的启发，用一个维度独立的扩散乘子替代了FNOs中的密集张量乘子，该乘子每个通道只有一个可学习的时间参数，从而显著减少了参数数量和内存占用。通过对这些时间参数定义先验，DINOZAUR被构建为一个贝叶斯神经算子，以产生空间相关的输出和校准的不确定性估计。

**Result:** DINOZAUR在多个偏微分方程基准测试中取得了具有竞争力或更优的性能，同时提供了高效的不确定性量化。

**Conclusion:** DINOZAUR通过引入轻量级扩散乘子和贝叶斯不确定性量化，成功解决了傅里叶神经算子的可扩展性问题并提供了可靠的不确定性估计，在性能和效率上均表现出色。

> **ai_Abstract:** 本文提出了一种名为DINOZAUR的新型神经算子，旨在解决傅里叶神经算子（FNOs）面临的过度参数化和缺乏原生不确定性量化的问题。DINOZAUR通过引入一个受热核启发的轻量级、维度独立的扩散乘子，显著减少了模型参数和内存需求。此外，通过将DINOZAUR构建为贝叶斯神经算子，它能够提供空间相关的输出和校准的不确定性估计。实验结果表明，DINOZAUR在多个偏微分方程基准测试中表现出竞争或更优的性能，并提供了高效的不确定性量化。

> **摘要翻译:** 算子学习是解决偏微分方程的强大范式，其中傅里叶神经算子（FNOs）作为广泛采用的基础。然而，FNOs面临显著的可扩展性挑战，这源于过度参数化，并且不提供原生的不确定性量化——这是可靠的科学和工程应用的关键要求。相反，神经算子依赖于事后不确定性量化方法，这些方法忽略了几何归纳偏差。在这项工作中，我们引入了DINOZAUR：一种基于扩散的神经算子参数化方法，具备不确定性量化能力。受热核结构的启发，DINOZAUR用一个维度独立的扩散乘子替代了FNOs中的密集张量乘子，该乘子每个通道只有一个可学习的时间参数，从而显著减少了参数数量和内存占用，同时不影响预测性能。通过对这些时间参数定义先验，我们将DINOZAUR构建为一个贝叶斯神经算子，以产生空间相关的输出和校准的不确定性估计。我们的方法在多个偏微分方程基准测试中取得了具有竞争力或更优的性能，同时提供了高效的不确定性量化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [566] [L-GTA: Latent Generative Modeling for Time Series Augmentation](https://arxiv.org/abs/2507.23615)
> *L-GTA：时间序列增强的潜在生成建模*

*Luis Roque, Carlos Soares, Vitor Cerqueira, Luis Torgo* | **Category: cs.LG, cs.AI, 68T01, I.5.1; G.3; H.2.8; I.2.1** | **Updated: 2025-07-31**

**Keywords:** 时间序列增强, 潜在生成模型, Transformer, 数据增强, 变分循环自编码器

**Comment:** 

> **TL;DR:** L-GTA是一种基于Transformer的变分循环自编码器，用于时间序列数据增强，通过潜在空间中的受控变换生成保持原始数据特性的新时间序列，并在预测准确性和相似性方面优于直接变换方法。

**AI_Comments:** 该论文提出了一种创新的时间序列数据增强方法L-GTA，其核心在于利用Transformer架构和潜在空间中的受控变换。这种方法克服了传统直接变换方法的局限性，能够生成更真实、更可控的增强数据，对于时间序列预测、分类和异常检测等任务具有重要意义。通过在潜在空间进行操作，L-GTA能够更好地捕捉和保留时间序列的内在结构，这在数据稀缺或需要特定类型增强的场景下尤为重要。

<details>
  <summary>Details</summary>

**Motivation:** 数据增强在时间序列分析的各个方面（从预测到分类和异常检测任务）都变得越来越重要。

**Method:** 提出L-GTA模型，这是一种基于Transformer的变分循环自编码器生成方法。该模型利用模型潜在空间中的受控变换来生成保留原始数据集内在属性的新时间序列。L-GTA能够应用从简单抖动到幅度扭曲等多种变换，并结合这些基本变换来生成更复杂的合成时间序列数据集。

**Result:** L-GTA在多个真实世界数据集上的评估表明，它能够生成更可靠、一致且可控的增强数据。与直接变换方法相比，这显著提高了预测准确性和相似性度量。

**Conclusion:** L-GTA通过在潜在空间进行受控变换，为时间序列数据增强提供了一种更优、更可靠的方法，从而显著提升了预测性能。

> **ai_Abstract:** L-GTA是一种新颖的基于Transformer的变分循环自编码器模型，专为时间序列数据增强设计。它通过在潜在空间中执行受控变换来生成新的时间序列，同时保留原始数据的关键特性。该模型支持多种增强技术，并能组合它们以创建复杂的合成数据。实验证明，L-GTA生成的数据更可靠、一致且可控，显著提高了预测准确性和相似性度量，优于传统的直接变换方法。

> **摘要翻译:** 数据增强在时间序列分析的各个方面（从预测到分类和异常检测任务）都变得越来越重要。我们引入了潜在生成Transformer增强（L-GTA）模型，这是一种使用基于Transformer的变分循环自编码器的生成方法。该模型利用模型潜在空间中的受控变换来生成保留原始数据集内在属性的新时间序列。L-GTA能够应用从简单抖动到幅度扭曲等多种变换，并结合这些基本变换来生成更复杂的合成时间序列数据集。我们对几个真实世界数据集的评估表明，L-GTA能够产生更可靠、一致且可控的增强数据。与直接变换方法相比，这转化为预测准确性和相似性度量的显著改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [570] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
> *TrajSurv：从电子健康记录中学习连续潜在轨迹以实现可信的生存预测*

*Sihang Zeng, Lucas Jing Liu, Jun Wen, Meliha Yetisgen, Ruth Etzioni, Gang Luo* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 生存预测, 电子健康记录, 潜在轨迹, 神经受控微分方程, 可解释性

**Comment:** Accepted by MLHC 2025

> **TL;DR:** TrajSurv是一个利用神经受控微分方程从不规则采样的电子健康记录中学习连续潜在轨迹的模型，旨在提高生存预测的准确性和可解释性。

**AI_Comments:** TrajSurv的创新之处在于结合了神经受控微分方程和时间感知对比学习来建模不规则采样的纵向EHR数据中的连续临床进展。其两步解释过程显著提升了模型的透明度，这对于临床决策至关重要。该方法在准确性和可解释性之间取得了良好的平衡，是深度学习在医疗领域应用的一个重要进步。

<details>
  <summary>Details</summary>

**Motivation:** 准确建模患者连续的临床进展以及透明地将进展与生存结果联系起来具有挑战性，而可信的生存预测对临床决策至关重要。

**Method:** TrajSurv使用神经受控微分方程（NCDE）从不规则采样的EHR数据中提取连续时间潜在状态，形成连续潜在轨迹。它通过时间感知对比学习将潜在状态空间与患者状态空间对齐，并采用两步分治解释过程将临床进展与生存结果透明地联系起来：首先解释临床特征变化如何转化为潜在轨迹演变，然后聚类潜在轨迹以识别与不同生存结果相关的关键临床进展模式。

**Result:** 在MIMIC-III和eICU两个真实世界医疗数据集上的评估表明，TrajSurv比现有深度学习方法具有竞争性的准确性和卓越的透明度。

**Conclusion:** TrajSurv成功地从纵向电子健康记录中学习了连续潜在轨迹，并在生存预测中实现了高准确性和透明度，解决了当前方法的关键挑战。

> **ai_Abstract:** TrajSurv是一种新模型，旨在从纵向电子健康记录（EHR）中学习连续潜在轨迹，以实现可信的生存预测。它通过神经受控微分方程（NCDE）处理不规则采样的EHR数据以提取连续时间潜在状态，并通过时间感知对比学习确保这些轨迹反映临床进展。此外，TrajSurv采用两步解释过程，透明地揭示临床特征变化如何影响潜在轨迹演变，并识别与生存结果相关的临床进展模式。在MIMIC-III和eICU数据集上的实验证明，TrajSurv在准确性和透明度方面优于现有深度学习方法。

> **摘要翻译:** 可信的生存预测对于临床决策至关重要。纵向电子健康记录（EHRs）为预测提供了独特而强大的机会。然而，准确建模患者在不规则采样临床特征下的连续临床进展，并透明地将进展与生存结果联系起来具有挑战性。为了应对这些挑战，我们开发了TrajSurv，一个从纵向EHR数据中学习连续潜在轨迹以实现可信生存预测的模型。TrajSurv采用神经受控微分方程（NCDE）从不规则采样数据中提取连续时间潜在状态，形成连续潜在轨迹。为了确保潜在轨迹反映临床进展，TrajSurv通过时间感知对比学习方法将潜在状态空间与患者状态空间对齐。为了透明地将临床进展与生存结果联系起来，TrajSurv在两步分治解释过程中使用潜在轨迹。首先，它使用学习到的向量场解释临床特征的变化如何转化为潜在轨迹的演变。其次，它聚类这些潜在轨迹以识别与不同生存结果相关的关键临床进展模式。在MIMIC-III和eICU两个真实世界医疗数据集上的评估表明，TrajSurv比现有深度学习方法具有竞争性的准确性和卓越的透明度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [575] [G-Core: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2507.22789)
> *G-Core：一个简单、可扩展且平衡的RLHF训练器*

*Junyu Wu, Weiming Chang, Xiaotao Liu, Guanyou He, Haoqiang Hong, Boqi Liu, Hongtao Tian, Tao Yang, Yunsheng Shi, Feng Lin, Ting Yao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** RLHF, 大语言模型, 可扩展性, 训练框架, 资源管理

**Comment:** I haven't received company approval yet, and I uploaded it by mistake

> **TL;DR:** G-Core是一个新的RLHF训练框架，通过并行控制器和动态资源调度解决了现有系统在可扩展性和资源利用方面的挑战。

**AI_Comments:** G-Core的创新之处在于其并行控制器编程模型和动态放置方案，有效解决了RLHF训练中长期存在的扩展性和资源效率问题。通过消除单点瓶颈和优化资源利用，它为大规模LLM和扩散模型的RLHF训练提供了更健壮和高效的解决方案。其在微信产品中的实际应用案例进一步证明了其实用价值和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有RLHF训练系统在扩展到多模态和扩散工作流以及适应动态工作负载时面临挑战，特别是在控制器可扩展性、灵活资源放置和高效编排方面存在局限性。

**Method:** G-Core引入了并行控制器编程模型，以实现复杂RLHF工作流的灵活高效编排，并提出了动态放置方案，自适应地划分资源和调度工作负载。

**Result:** G-Core成功训练了支持微信产品功能的模型，显著减少了硬件空闲时间并提高了利用率，并在真实场景中展示了有效性和鲁棒性，推动了RLHF训练的最新技术。

**Conclusion:** G-Core通过解决现有RLHF系统的可扩展性和效率问题，为未来大规模、人类对齐模型的研发和部署奠定了坚实基础。

> **ai_Abstract:** 本文介绍了G-Core，一个为应对现有强化学习人类反馈（RLHF）训练系统在可扩展性、资源放置和编排方面挑战而设计的框架。G-Core通过引入并行控制器编程模型和动态放置方案，有效解决了单中心控制器瓶颈和资源利用率问题，显著减少了硬件空闲时间。它已成功应用于微信产品功能模型的训练，证明了其在实际场景中的有效性和鲁棒性，并推动了RLHF训练领域的发展。

> **摘要翻译:** 从人类反馈中进行的强化学习（RLHF）已成为训练大型语言模型（LLM）和扩散模型日益流行的范式。尽管现有的RLHF训练系统取得了显著进展，但它们在扩展到多模态和扩散工作流以及适应动态工作负载时经常面临挑战。特别是，当前方法在处理复杂RLHF管道时，尤其是在涉及动态采样或生成奖励建模的场景中，可能会遇到控制器可扩展性、灵活资源放置和高效编排方面的限制。在本文中，我们提出了G-Core，一个简单、可扩展且平衡的RLHF训练框架，旨在解决这些挑战。G-Core引入了一种并行控制器编程模型，能够灵活高效地编排复杂的RLHF工作流，而没有单一集中式控制器的瓶颈。此外，我们提出了一种动态放置方案，可以自适应地划分资源和调度工作负载，即使在高度可变的训练条件下，也能显著减少硬件空闲时间并提高利用率。G-Core已成功训练出支持微信产品功能、服务大量用户群体的模型，展示了其在实际场景中的有效性和鲁棒性。我们的结果表明，G-Core推动了RLHF训练的最新技术，为未来大规模、人类对齐模型的研发和部署提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [577] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
> *DP-DGAD：一种具有动态原型的通用动态图异常检测器*

*Jialun Zheng, Jie Liu, Jiannong Cao, Xiao Wang, Hanchen Yang, Yankai Chen, Philip S. Yu* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 动态图异常检测, 通用模型, 动态原型, 跨域适应, 自监督学习

**Comment:** 

> **TL;DR:** DP-DGAD是一种新的通用动态图异常检测器，它利用动态原型和自监督适应来处理动态图中不断演变的领域特定和领域无关异常，并在多个真实世界数据集中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于引入了“动态原型”来捕获动态图中不断演变的正常和异常模式，并通过“选择性记忆缓冲区”巧妙地平衡了领域无关的通用知识与新出现的领域特定知识。此外，采用基于置信度的伪标签进行自监督适应，显著增强了模型在缺乏标记数据的新目标领域中的泛化能力和实用性，对于跨域动态图异常检测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 动态图异常检测（DGAD）对于识别演化图中的异常至关重要，但现有的通用图异常检测（GAD）模型在静态图上表现良好，却难以捕获动态图中不断演变的异常。此外，新领域的不断出现和标记数据的缺乏进一步挑战了通用DGAD。有效的跨域DGAD需要同时考虑领域特定和领域无关的异常模式，且这些模式会随时间演变。

**Method:** 本文提出了DP-DGAD模型，它通过以下步骤捕获演变的领域特定和领域无关模式：1. 从时间自我图中提取动态原型（即正常和异常模式的演化表示），并将其存储在记忆缓冲区中。2. 记忆缓冲区被选择性更新，以保留通用的领域无关模式，同时整合新的领域特定模式。3. 异常评分器将传入数据与动态原型进行比较，以标记通用和领域特定异常。4. 采用基于置信度的伪标签进行有效的自监督适应，以适应目标领域。

**Result:** 在来自不同领域的十个真实世界数据集上进行了广泛实验，结果表明DP-DGAD取得了最先进的性能。

**Conclusion:** DP-DGAD模型通过捕获演变的领域特定和领域无关模式，并利用动态原型和自监督适应，有效解决了动态图异常检测中的挑战，并在多个真实世界数据集中实现了最先进的性能。

> **ai_Abstract:** DP-DGAD是一种针对动态图异常检测（DGAD）提出的通用模型，旨在解决现有通用模型在处理动态图中演变异常时的不足。该模型通过从时间自我图中提取动态原型，并将其存储在可选择性更新的记忆缓冲区中，以同时捕获领域特定和领域无关的演变模式。随后，一个异常评分器将新数据与这些动态原型进行比较以识别异常。此外，DP-DGAD利用基于置信度的伪标签进行自监督适应，以有效应对新领域和标记数据缺乏的挑战。在十个真实世界数据集上的广泛实验证明，DP-DGAD达到了最先进的性能。

> **摘要翻译:** 动态图异常检测（DGAD）对于识别金融、交通和社交网络等领域中演化图中的异常至关重要。最近，通用图异常检测（GAD）模型显示出有希望的结果。它们在多个源数据集上进行预训练，并能跨领域泛化。尽管它们在静态图上有效，但难以捕获动态图中不断演变的异常。此外，新领域的持续出现和标记数据的缺乏进一步挑战了通用DGAD。有效的跨域DGAD需要领域特定和领域无关的异常模式。重要的是，这些模式在域内和域间都会随时间演变。基于这些洞察，我们提出了一种带有动态原型（DP）的DGAD模型，以捕获演变的领域特定和领域无关模式。首先，DP-DGAD从时间自我图中提取动态原型，即正常和异常模式的演化表示，并将其存储在记忆缓冲区中。该缓冲区被选择性更新，以保留通用的领域无关模式，同时整合新的领域特定模式。然后，异常评分器将传入数据与动态原型进行比较，以标记通用和领域特定异常。最后，DP-DGAD采用基于置信度的伪标签进行有效的自监督适应，以适应目标领域。广泛的实验证明，该模型在来自不同领域的十个真实世界数据集上取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [584] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
> *精神病学临床笔记按诊断分类：深度学习和机器学习方法*

*Sergio Rubio-Martín, María Teresa García-Ordás, Antonio Serrano-García, Clara Margarita Franch-Pato, Arturo Crespo-Álvaro, José Alberto Benítez-Andrades* | **Category: cs.LG, cs.CL** | **Updated: 2025-08-01**

**Keywords:** 精神病学临床笔记, 诊断分类, 深度学习, 机器学习, 超参数调优

**Comment:** 

> **TL;DR:** 本研究比较了机器学习和深度学习模型在精神病学临床笔记诊断分类中的性能，并评估了过采样和超参数调优的影响，发现超参数调优显著提高了模型准确性。

**AI_Comments:** 该研究通过比较多种机器学习和深度学习模型，并系统评估过采样策略和超参数调优对精神病学临床笔记分类的影响，为AI辅助诊断工具提供了宝贵的见解。其创新点在于对不同模型架构和数据平衡方法进行了全面的性能评估。研究强调了超参数调优的重要性，这对于实际应用中优化模型性能具有指导意义。然而，研究仅关注两种诊断类别，未来可以扩展到更广泛的精神疾病分类。

<details>
  <summary>Details</summary>

**Motivation:** 在医疗保健领域，尤其是精神健康状况（如焦虑症和适应障碍）的诊断中，将临床笔记分类到特定的诊断类别至关重要。本研究旨在比较不同AI模型在此任务上的性能。

**Method:** 研究比较了多种传统机器学习模型（随机森林、支持向量机、K-近邻、决策树和eXtreme Gradient Boost）和深度学习模型（DistilBERT和SciBERT），用于将临床笔记分类为焦虑症和适应障碍。同时，实施了三种过采样策略（无过采样、随机过采样和SMOTE）以评估其对模型性能的影响。还应用了超参数调优来优化模型准确性。

**Result:** 过采样技术对模型整体性能影响最小，SMOTE对基于BERT的模型有积极影响。超参数优化显著提高了所有模型的准确性。决策树和eXtreme Gradient Boost在机器学习方法中达到96%的最高准确率，DistilBERT和SciBERT在深度学习类别中也达到96%的准确率。

**Conclusion:** 超参数调优在最大化模型性能方面至关重要。本研究通过提供不同模型架构和数据平衡方法的有效性见解，为AI辅助精神健康诊断工具的持续研究做出了贡献。

> **ai_Abstract:** 本研究旨在比较机器学习和深度学习模型在精神病学临床笔记诊断分类中的性能。研究评估了多种传统ML模型（如决策树、XGBoost）和DL模型（如DistilBERT、SciBERT），并探讨了过采样策略（无、随机、SMOTE）和超参数调优的影响。结果显示，超参数调优显著提升了模型准确性，而过采样除SMOTE对BERT模型外影响甚微。决策树、XGBoost、DistilBERT和SciBERT均达到96%的准确率，强调了超参数调优在优化AI辅助诊断工具中的关键作用。

> **摘要翻译:** 将临床笔记分类到特定的诊断类别在医疗保健领域至关重要，特别是对于焦虑症和适应障碍等精神健康状况。在本研究中，我们比较了各种人工智能模型（包括传统机器学习方法：随机森林、支持向量机、K-近邻、决策树和eXtreme Gradient Boost，以及深度学习模型：DistilBERT和SciBERT）在将临床笔记分类为这两种诊断方面的性能。此外，我们实施了三种过采样策略：无过采样、随机过采样和合成少数类过采样技术（SMOTE），以评估它们对模型性能的影响。还应用了超参数调优来优化模型准确性。我们的结果表明，过采样技术对模型整体性能影响最小。唯一的例外是SMOTE，它专门对基于BERT的模型显示出积极效果。然而，超参数优化显著提高了所有模型的准确性，增强了它们在数据集上的泛化和性能能力。决策树和eXtreme Gradient Boost模型在机器学习方法中均达到了96%的最高准确率，而DistilBERT和SciBERT模型在深度学习类别中也达到了96%的准确率。这些发现强调了超参数调优在最大化模型性能方面的重要性。本研究通过提供不同模型架构和数据平衡方法的有效性见解，为AI辅助精神健康诊断工具的持续研究做出了贡献。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [Parallel Split Learning with Global Sampling](https://arxiv.org/abs/2407.15738)
> *并行拆分学习与全局采样*

*Mohammad Kohankhaki, Ahmad Ayad, Mahdi Barhoush, Anke Schmeink* | **Category: cs.LG, cs.AI, cs.DC** | **Updated: 2025-07-31**

**Keywords:** 分布式深度学习, 全局采样, 拆分学习, 资源受限, 边缘计算

**Comment:** 

> **TL;DR:** 提出一种服务器驱动的全局采样策略，通过动态调整客户端批次大小，解决资源受限环境下分布式深度学习的批次大小和数据分布挑战，提高模型性能和训练效率。

**AI_Comments:** 这篇论文通过引入服务器驱动的全局采样策略，巧妙地解决了分布式深度学习中有效批次大小与设备数量耦合的问题，并改善了数据分布不均的影响。其在理论上提供了更严格的偏差保证，并在实践中提升了模型性能，对于边缘计算场景下的分布式学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 资源受限环境下的分布式深度学习面临可扩展性和泛化性挑战，原因在于有效的批次大小过大以及客户端数据非独立同分布。

**Method:** 引入一种服务器驱动的采样策略，通过动态调整客户端侧的批次大小来维持固定的全局批次大小。这使得有效批次大小与参与设备数量解耦，并确保全局批次更好地反映整体数据分布。利用标准集中界限，建立了比现有方法更严格的偏差保证。

**Result:** 在基准数据集上的实证结果证实，所提出的方法提高了模型精度、训练效率和收敛稳定性。

**Conclusion:** 所提出的方法为网络边缘的学习提供了一个可扩展的解决方案，有效解决了分布式深度学习在资源受限环境下的挑战。

> **ai_Abstract:** 本文针对资源受限环境中分布式深度学习的可扩展性和泛化性挑战，提出了一种服务器驱动的全局采样策略。该策略通过动态调整客户端批次大小来维持固定的全局批次大小，从而解耦有效批次大小与设备数量，并确保全局批次更好地反映数据分布。理论分析表明其偏差保证更严格，实验结果验证了该方法能提升模型精度、训练效率和收敛稳定性，为边缘学习提供可扩展方案。

> **摘要翻译:** 资源受限环境下的分布式深度学习面临可扩展性和泛化性挑战，这源于大的有效批次大小和非独立同分布的客户端数据。我们引入了一种服务器驱动的采样策略，通过动态调整客户端侧的批次大小来维持固定的全局批次大小。这使得有效批次大小与参与设备数量解耦，并确保全局批次更好地反映整体数据分布。利用标准集中界限，我们建立了比现有方法更严格的偏差保证。在基准数据集上的实证结果证实，所提出的方法提高了模型精度、训练效率和收敛稳定性，为网络边缘的学习提供了一个可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [591] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
> *无需手工输入学习网络拆解*

*Haozhe Tian, Pietro Ferraro, Robert Shorten, Mahdi Jalili, Homayoun Hamedmoghadam* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 网络拆解, 图神经网络, 注意力机制, 消息传递, 合成网络

**Comment:** 

> **TL;DR:** MIND模型通过引入注意力机制和消息迭代配置文件，并利用多样化的合成网络进行训练，无需手工特征即可高效且泛化地解决网络拆解问题，性能超越现有SOTA方法。

**AI_Comments:** 该论文的创新点在于成功地消除了图神经网络在网络拆解任务中对手工特征的依赖，通过引入注意力机制和消息迭代配置文件，并结合合成网络训练，显著提高了模型的效率和泛化能力。这是一个重要的进步，因为它解决了现有方法计算成本高且引入偏差的问题，使得网络表示更加纯粹和数据驱动。模型的通用性也预示着其在其他复杂网络问题中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的消息传递图神经网络在解决网络科学问题时，其竞争性能往往依赖于手工设计的结构特征作为输入，这增加了计算成本并引入了偏差。

**Method:** 本文通过引入注意力机制和利用消息迭代配置文件，消除了对手工特征的需求。此外，还采用了一种有效的算法方法来生成结构多样化的小型合成网络训练集。在此基础上，构建了一个富有表现力的消息传递框架，并提出了MIND（Message Iteration Network Dismantler）模型，用于高效解决网络拆解（即重要节点识别）这一NP-hard问题。

**Result:** MIND模型仅在多样化的合成网络上进行训练，就能泛化到拥有数百万节点的大型未见真实网络，并且性能优于最先进的网络拆解方法。

**Conclusion:** 所提出的MIND模型提高了效率和泛化能力，其应用可以超越网络拆解，扩展到一系列复杂的网络问题中。

> **ai_Abstract:** 本文提出了一种名为MIND（Message Iteration Network Dismantler）的新型消息传递框架，旨在解决网络拆解（即重要节点识别）这一NP-hard问题，同时避免了对传统手工特征的依赖。通过引入注意力机制、利用消息迭代配置文件以及采用算法生成多样化的合成训练网络，MIND模型能够高效学习。实验结果表明，该模型仅在合成数据上训练，便能成功泛化到大型真实网络，并超越了现有最先进的网络拆解方法，展现出更高的效率和泛化能力，有望应用于更广泛的复杂网络问题。

> **摘要翻译:** 消息传递图神经网络的应用是解决重要网络科学问题的一项突破。然而，其竞争性能往往依赖于使用手工设计的结构特征作为输入，这增加了计算成本并对原本纯粹的数据驱动网络表示引入了偏差。在此，我们通过引入注意力机制和利用消息迭代配置文件，消除了对手工特征的需求，此外还采用了一种有效的算法方法来生成结构多样化的小型合成网络训练集。因此，我们构建了一个富有表现力的消息传递框架，并利用它高效地解决了网络拆解这一NP-hard问题，该问题实际上等同于重要节点识别，并具有重要的现实世界应用。我们提出的模型——MIND：消息迭代网络拆解器——仅在多样化的合成网络上进行训练，就能泛化到拥有数百万节点的大型、未见真实网络，并且性能优于最先进的网络拆解方法。所提出模型的效率和泛化能力提升，可以超越网络拆解，应用于一系列复杂的网络问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [596] [Accumulator-Aware Post-Training Quantization for Large Language Models](https://arxiv.org/abs/2409.17092)
> *大语言模型的累加器感知后训练量化*

*Ian Colbert, Giuseppe Franco, Fabian Grob, Jinjie Zhang, Rayan Saab* | **Category: cs.LG, cs.AI, cs.DM** | **Updated: 2025-07-31**

**Keywords:** 后训练量化, 累加器感知, 大语言模型, 溢出避免, AXE

**Comment:** 

> **TL;DR:** 提出AXE，首个累加器感知的后训练量化框架，为大语言模型提供溢出避免保证，并在保持性能的同时优于传统方法。

**AI_Comments:** 该论文的创新点在于首次将累加器感知量化与后训练量化 (PTQ) 相结合，并提供了溢出避免保证，这对于在实际部署中高效量化大型语言模型具有重要意义。通过支持多阶段累加，该框架为更全面的数据路径优化提供了可能性。其在Llama3 8B上的出色表现凸显了其在保持模型性能的同时实现高效量化的潜力，对于推动大模型在资源受限设备上的应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 在低精度量化中，加法成本开始主导乘法成本，而低精度累加虽能提高性能但有溢出风险。目前的累加器感知量化仅限于量化感知训练 (QAT)，但QAT对于大型模型和数据集而言成本过高。因此，需要一种能够结合累加器感知和后训练量化 (PTQ) 的方法来解决这一瓶颈并避免溢出。

**Method:** 本文引入了AXE，这是首个明确设计用于为PTQ算法提供溢出避免保证的累加器感知量化框架。AXE有理论支撑，并通过在GPFQ和OPTQ两种现有算法上实现来展示其灵活性。AXE还被设计为支持多阶段累加，首次实现了完整数据路径优化。

**Result:** AXE在最近的语言生成模型上进行了评估。当对Llama3 8B进行16位多阶段累加数据路径量化时，AXE保持了高达98%的FP16困惑度，比简单的位宽操作高出15%。

**Conclusion:** AXE是首个为后训练量化提供溢出避免保证的累加器感知框架，通过支持多阶段累加实现了完整数据路径优化，并在大语言模型上表现出优异的性能，显著优于现有方法。

> **ai_Abstract:** 该论文提出了一种名为AXE的新型累加器感知后训练量化 (PTQ) 框架，旨在解决低精度量化中加法成本高昂及现有累加器感知方法仅限于昂贵的量化感知训练 (QAT) 的问题。AXE是首个为PTQ算法提供溢出避免保证的框架，并支持多阶段累加以实现完整数据路径优化。实验结果表明，AXE在量化大型语言模型（如Llama3 8B）时，能保持接近原始FP16性能（98%困惑度），并显著优于传统位宽操作。

> **摘要翻译:** 当将权重和激活量化到越来越窄的表示时，乘加 (MAC) 单元中的加法成本开始主导乘法成本。最近的研究表明，通过低精度累加降低加法成本可以提高推理平台的吞吐量、功耗和面积，尽管溢出风险会增加。迄今为止，累加器感知量化研究仅考虑了量化感知训练 (QAT) 范式，其中模型在量化循环中进行微调或从头开始训练。随着模型和数据集规模的不断增长，QAT技术变得越来越昂贵，这促使了近期后训练量化 (PTQ) 研究的激增。为了弥合这一差距，我们引入了AXE，这是首个明确设计用于为PTQ算法提供溢出避免保证的累加器感知量化框架。我们提出了AXE的理论动机，并通过在两种现有算法：GPFQ和OPTQ之上实现它来展示其灵活性。我们设计AXE以支持多阶段累加，首次为完整数据路径优化打开了大门。我们使用最近的语言生成模型评估了AXE；当对Llama3 8B进行16位多阶段累加数据路径量化时，AXE保持了高达98%的FP16困惑度，比简单的位宽操作高出15%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [597] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
> *通过权重相似性改进地形CNN的鲁棒性和功能局部化*

*Nhut Truong, Uri Hasson* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 地形神经网络, 权重相似性, 激活相似性, 鲁棒性, 功能局部化

**Comment:** 

> **TL;DR:** 研究发现，在地形卷积神经网络中，权重相似性（WS）约束相比激活相似性（AS）和标准CNN，能显著提高模型的鲁棒性和功能局部化能力。

**AI_Comments:** 这项研究通过系统比较不同的地形约束实现方式，为地形神经网络的设计提供了重要见解。其创新点在于明确指出权重相似性（WS）在提升模型鲁棒性和功能局部化方面的优越性，这对于构建更接近生物大脑机制且性能更强的神经网络模型具有重要意义。它强调了权重层面约束而非仅仅激活层面约束在塑造网络行为中的关键作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的地形神经网络中，地形约束的实现方式多种多样，但其对网络学习到的表征影响尚未得到系统性检验。

**Method:** 本文比较了两种空间约束下的地形卷积神经网络：权重相似性（WS），该方法促使相邻单元发展相似的输入权重；以及激活相似性（AS），该方法强制单元激活的相似性。模型在分类准确性、对权重扰动和输入降级的鲁棒性以及学习表征的空间组织方面进行了评估。

**Result:** 与AS和标准CNN相比，WS提供了三大优势：1) 提高了对噪声的鲁棒性，并在权重损坏下显示出更高的准确性；2) 具有更高的输入敏感性，体现在更高的激活方差；3) 具有更强的功能局部化，激活相似的单元位置更近。此外，WS还导致了单元的方向调谐、对称敏感性和偏心率剖面的差异。

**Conclusion:** 研究结果表明，在端到端训练过程中，WS约束比AS或非地形CNN产生更鲁棒的表征。这些发现还表明，基于权重的空间约束可以塑造生物物理启发模型中的特征学习和功能组织。

> **ai_Abstract:** 本文系统性地比较了两种地形卷积神经网络中的空间约束：权重相似性（WS）和激活相似性（AS）。研究发现，与AS和标准CNN相比，WS约束显著提升了模型的鲁棒性、输入敏感性和功能局部化能力，并影响了单元的特征调谐。这表明基于权重的空间约束在生物物理启发模型中能产生更稳健的特征表征和功能组织。

> **摘要翻译:** 地形神经网络是能够模拟大脑空间和功能组织的计算模型。神经网络中的地形约束可以通过多种方式实现，对网络学习到的表征可能产生不同的影响。然而，这种不同实现方式的影响尚未得到系统性检验。为此，我们比较了两种空间约束下训练的地形卷积神经网络：权重相似性（WS），它促使相邻单元发展相似的输入权重；以及激活相似性（AS），它强制单元激活的相似性。我们评估了所得模型在分类准确性、对权重扰动和输入降级的鲁棒性以及学习表征的空间组织方面的表现。与AS和标准CNN相比，WS提供了三个主要优势：i) 提高了对噪声的鲁棒性，并在权重损坏下显示出更高的准确性；ii) 具有更高的输入敏感性，体现在更高的激活方差；iii) 具有更强的功能局部化，激活相似的单元位置更近。此外，WS还导致了单元的方向调谐、对称敏感性和偏心率剖面的差异，表明这种空间约束对网络表征几何形状的影响。我们的研究结果表明，在端到端训练过程中，WS约束比AS或非地形CNN产生更鲁棒的表征。这些发现还表明，基于权重的空间约束可以塑造生物物理启发模型中的特征学习和功能组织。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [598] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
> *鲁棒因子化马尔可夫决策过程的有效求解与学习*

*Yannik Schnitzer, Alessandro Abate, David Parker* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 鲁棒马尔可夫决策过程, 因子化状态空间, 样本效率, 线性规划, 性能保证

**Comment:** 

> **TL;DR:** 本文提出了一种基于因子化状态空间表示的新方法，用于求解和学习鲁棒马尔可夫决策过程（r-MDPs），能够显著提高样本效率并生成更有效的鲁棒策略。

**AI_Comments:** 该论文的创新点在于将因子化状态空间表示引入鲁棒马尔可夫决策过程的求解与学习中，并巧妙地将困难的非凸优化问题转化为可处理的线性规划。这显著提高了学习效率，并为合成具有更强保证的鲁棒策略提供了有效途径，对于在不确定环境下进行决策具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 鲁棒马尔可夫决策过程（r-MDPs）在从未知环境中学习时，需要大量的样本交互才能合成具有可证明性能保证的鲁棒策略。

**Method:** 本文提出了基于因子化状态空间表示的新方法来求解和学习r-MDPs，利用系统组件间模型不确定性的独立性。尽管因子化r-MDPs的策略合成是非凸优化问题，但作者展示了如何将其重新表述为可处理的线性规划。在此基础上，还提出了直接学习因子化模型表示的方法。

**Result:** 实验结果表明，利用因子化结构可以带来样本效率上的维度增益，与现有最先进方法相比，能够产生更有效的鲁棒策略和更紧密的性能保证。

**Conclusion:** 利用因子化结构可以显著提高鲁棒马尔可夫决策过程的求解和学习效率，并获得更好的策略性能保证。

> **ai_Abstract:** 本文针对鲁棒马尔可夫决策过程（r-MDPs）在学习时所需的巨大样本量问题，提出了一种基于因子化状态空间表示的新型求解和学习方法。该方法利用系统组件间模型不确定性的独立性，将策略合成的非凸优化问题转化为可处理的线性规划，并能直接学习因子化模型。实验证明，该方法在样本效率上具有维度增益，能生成比现有技术更有效、性能保证更紧密的鲁棒策略。

> **摘要翻译:** 鲁棒马尔可夫决策过程 (r-MDPs) 通过明确建模关于转移动态的认知不确定性来扩展 MDPs。从未知环境中学习 r-MDPs 能够合成具有可证明 (PAC) 性能保证的鲁棒策略，但这可能需要大量的样本交互。我们提出了基于因子化状态空间表示的求解和学习 r-MDPs 的新方法，这些方法利用了系统组件之间模型不确定性的独立性。尽管因子化 r-MDPs 的策略合成会导致困难的非凸优化问题，但我们展示了如何将其重新表述为可处理的线性规划。在此基础上，我们还提出了直接学习因子化模型表示的方法。我们的实验结果表明，利用因子化结构可以在样本效率方面产生维度增益，与现有最先进的方法相比，能够产生更有效的鲁棒策略和更紧密的性能保证。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [601] [OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting](https://arxiv.org/abs/2507.23638)
> *OptiGradTrust：基于多特征梯度分析和强化学习信任加权的拜占庭鲁棒联邦学习*

*Mohammad Karami, Fatemeh Ghassemi, Hamed Kebriaei, Hamid Azadegan* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 联邦学习, 拜占庭鲁棒性, 梯度分析, 强化学习, 数据异构性

**Comment:** 

> **TL;DR:** OptiGradTrust通过多特征梯度分析和强化学习信任加权，增强了联邦学习在拜占庭攻击和数据异构性下的鲁棒性。

**AI_Comments:** OptiGradTrust的创新之处在于其结合了多维梯度特征分析与强化学习进行信任加权，以及针对数据异构性提出的FedBN-Prox。这种综合方法有效提升了联邦学习在复杂攻击和非IID数据环境下的鲁棒性和准确性，对于隐私保护的分布式机器学习具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）在保护患者隐私的同时实现了分布式医疗机构的协作模型训练，但仍易受拜占庭攻击和统计异构性的影响。

**Method:** 本文提出了OptiGradTrust框架，通过包含VAE重构误差、余弦相似度、L2范数、符号一致性比率和蒙特卡洛Shapley值在内的六维指纹评估梯度更新，并驱动混合RL-注意力模块进行自适应信任评分。为解决数据异构性下的收敛挑战，开发了FedBN-Prox，结合联邦批量归一化和近端正则化以优化准确性-收敛性权衡。

**Result:** 在MNIST、CIFAR-10和阿尔茨海默病MRI数据集上，各种拜占庭攻击场景下的广泛评估表明，OptiGradTrust显著优于现有最先进的防御方法，在非独立同分布（non-IID）条件下比FLGuard提高了高达1.6个百分点，并通过自适应学习方法保持了对不同攻击模式的鲁棒性能。

**Conclusion:** OptiGradTrust框架通过多特征梯度分析和强化学习信任加权，结合FedBN-Prox处理数据异构性，有效提升了联邦学习在面对拜占庭攻击时的鲁棒性和性能。

> **ai_Abstract:** 本文提出OptiGradTrust，一个针对联邦学习中拜占庭攻击和数据异构性的防御框架。该框架通过一个六维梯度指纹和强化学习-注意力模块进行自适应信任评分，并引入FedBN-Prox以优化异构数据下的收敛。实验证明，OptiGradTrust在多种数据集和攻击场景下均显著优于现有SOTA防御，展现了优异的鲁棒性和性能提升。

> **摘要翻译:** 联邦学习（FL）能够在分布式医疗机构之间实现协作模型训练，同时保护患者隐私，但仍然容易受到拜占庭攻击和统计异构性的影响。我们提出了OptiGradTrust，一个全面的防御框架，它通过一个新颖的六维指纹评估梯度更新，该指纹包括VAE重构误差、余弦相似度指标、$L_2$范数、符号一致性比率和蒙特卡洛Shapley值，这些特征驱动一个混合RL-注意力模块进行自适应信任评分。为了解决数据异构性下的收敛挑战，我们开发了FedBN-Prox（FedBN-P），它结合了联邦批量归一化和近端正则化，以实现最佳的准确性-收敛性权衡。在MNIST、CIFAR-10和阿尔茨海默病MRI数据集上，在各种拜占庭攻击场景下的广泛评估表明，与现有最先进的防御方法相比，OptiGradTrust取得了显著改进，在非独立同分布（non-IID）条件下比FLGuard提高了高达1.6个百分点，并通过我们的自适应学习方法保持了对不同攻击模式的鲁棒性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [605] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
> *JSON-Bag：一种通用的游戏轨迹表示方法*

*Dien Nguyen, Diego Perez-Liebana, Simon Lucas* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 游戏轨迹表示, JSON-Bag, Jensen-Shannon距离, 游戏分类, 自动特征提取

**Comment:** 8 pages, 3 figures, 6 tables, to be published in IEEE Conference on
  Games 2025

> **TL;DR:** JSON-Bag是一种通用的游戏轨迹表示方法，通过对JSON描述进行分词并使用Jensen-Shannon距离进行度量。它在多种游戏轨迹分类任务中表现优于基线，并能有效进行特征提取。

**AI_Comments:** 该论文提出了一种新颖且通用的游戏轨迹表示方法JSON-Bag，其创新点在于将游戏轨迹的JSON描述进行分词并结合信息论中的Jensen-Shannon距离进行度量，而非依赖传统的手工特征。这使得该方法具有更强的泛化能力和自动化特征提取潜力。其在多个游戏和分类任务上的优异表现，以及与代理策略距离的高度相关性，突出了其在游戏AI分析领域的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 开发一种通用的方法来表示游戏轨迹，并评估其在分类游戏代理、游戏参数或游戏种子方面的有效性，以克服传统手工特征的局限性。

**Method:** 研究引入了JSON Bag-of-Tokens模型（JSON-Bag）来表示游戏轨迹，通过对JSON描述进行分词。使用Jensen-Shannon距离（JSD）作为距离度量，并通过基于原型的最近邻搜索（P-NNS）在六款桌面游戏上评估了其有效性。此外，还通过将词元作为独立特征用于随机森林（Random Forest）来展示其自动特征提取能力。

**Result:** JSON-Bag方法在大多数任务中优于使用手工特征的基线方法。在N-shot分类中，使用JSON-Bag原型表示游戏轨迹类别具有样本效率。将词元作为特征用于随机森林显著提高了在表现不佳任务上的准确性。最后，在所有六款游戏中，JSON-Bag代理类别原型之间的JSD与代理策略之间的距离高度相关。

**Conclusion:** JSON-Bag是一种有效且通用的游戏轨迹表示方法，它在分类任务中表现出色，具有样本效率，并能进行有效的自动特征提取。此外，它表示的距离与代理策略的距离高度相关。

> **ai_Abstract:** 本研究提出了一种名为JSON-Bag的通用游戏轨迹表示模型，该模型通过对JSON描述进行分词，并结合Jensen-Shannon距离进行距离度量。通过基于原型的最近邻搜索，在六款桌面游戏的代理、参数或种子分类任务中验证了JSON-Bag的有效性。实验结果表明，JSON-Bag在多数任务中超越了手工特征基线，并展现出样本效率和自动特征提取能力，显著提升了分类准确性。研究还发现，JSON-Bag代理原型之间的距离与代理策略的距离高度相关。

> **摘要翻译:** 我们引入了JSON词袋模型（JSON-Bag）作为一种通用表示游戏轨迹的方法，通过对其JSON描述进行分词，并应用Jensen-Shannon距离（JSD）作为它们的距离度量。使用基于原型的最近邻搜索（P-NNS），我们在六款桌面游戏——《七大奇迹》、《领土》、《海盐与纸》、《停不下来》、《四子棋》、《点与盒》——上评估了JSON-Bag与JSD的有效性，每款游戏都进行了三种游戏轨迹分类任务：分类所使用的游戏代理、游戏参数或游戏种子。
我们的方法在大多数任务中优于使用手工特征的基线方法。在N-shot分类上的评估表明，使用JSON-Bag原型来表示游戏轨迹类别也具有样本效率。此外，我们通过将词元视为单独的特征用于随机森林来解决上述任务，从而展示了JSON-Bag的自动特征提取能力，这显著提高了在表现不佳任务上的准确性。最后，我们表明，在所有六款游戏中，代理类别JSON-Bag原型之间的JSD与代理策略之间的距离高度相关。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [608] [TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses](https://arxiv.org/abs/2507.23674)
> *TweakLLM：一种用于动态调整缓存响应的路由架构*

*Muhammad Taha Cheema, Abeer Aamir, Khawaja Gul Muhammad, Naveed Anwar Bhatti, Ihsan Ayyub Qazi, Zafar Ayyub Qazi* | **Category: cs.LG, cs.CL** | **Updated: 2025-07-31**

**Keywords:** TweakLLM, 缓存, 大型语言模型, 路由架构, 效率

**Comment:** 13 pages, 9 figures

> **TL;DR:** TweakLLM是一种新的路由架构，它使用轻量级LLM动态调整缓存响应，以提高LLM的缓存效率和响应质量。

**AI_Comments:** TweakLLM的创新之处在于利用一个轻量级LLM来动态调整缓存响应，从而克服了传统缓存方案在个性化和语义相似性方面的局限性。这对于降低LLM的运营成本和提高响应速度具有重要意义，尤其是在高流量场景下。其通过用户研究和LLM辩论进行评估的方法也增强了结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）每天处理数百万个查询，高效的响应缓存可以显著降低成本和延迟。然而，由于聊天机器人交互的个性化性质和语义相似性搜索的准确性有限，保持缓存响应与用户查询的相关性很困难。

**Method:** 我们提出了TweakLLM，一种新颖的路由架构，它采用一个轻量级LLM来动态地调整缓存响应以适应传入的提示。通过全面的评估，包括用户研究（并排比较、满意度投票）以及多智能体LLM辩论。

**Result:** TweakLLM在保持与前沿模型相当的响应质量的同时，显著提高了缓存效率。在真实世界数据集上的结果表明TweakLLM是一种可扩展、资源高效的缓存解决方案，适用于高流量LLM部署，且不损害用户体验。

**Conclusion:** TweakLLM提供了一种可扩展且资源高效的缓存解决方案，用于高流量LLM部署，在不牺牲用户体验的情况下，显著提高了缓存效率并保持了响应质量。

> **ai_Abstract:** TweakLLM是一种新颖的路由架构，旨在解决大型语言模型（LLM）响应缓存中保持相关性的挑战。它利用一个轻量级LLM动态调整缓存响应以匹配用户查询，从而在不牺牲响应质量的前提下，显著提高缓存效率，并被证明是高流量LLM部署的可扩展且资源高效的解决方案。

> **摘要翻译:** 大型语言模型 (LLM) 每天处理数百万个查询，因此高效的响应缓存成为降低成本和延迟的一种引人注目的优化方案。然而，由于聊天机器人交互的个性化性质以及语义相似性搜索的准确性有限，使用这种方法保持与用户查询的相关性变得困难。为了解决这个问题，我们提出了 TweakLLM，一种新颖的路由架构，它采用一个轻量级 LLM 动态调整缓存响应以适应传入的提示。通过全面的评估，包括用户研究（包含并排比较、满意度投票）以及多智能体 LLM 辩论，我们证明 TweakLLM 在保持与前沿模型相当的响应质量的同时，显著提高了缓存效率。我们在真实世界数据集上的结果突出表明，TweakLLM 是一种可扩展、资源高效的缓存解决方案，适用于高流量 LLM 部署，且不损害用户体验。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [609] [Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback](https://arxiv.org/abs/2507.15066)
> *Time-RA：基于LLM反馈的时间序列异常推理研究*

*Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen* | **Category: cs.LG, cs.AI, cs.MM** | **Updated: 2025-08-01**

**Keywords:** 时间序列异常检测, 异常推理, 大型语言模型 (LLMs), 多模态数据集, 可解释性AI

**Comment:** Under review. 19 pages, 8 figures, 12 tables. Code and dataset are
  publicly available

> **TL;DR:** 提出Time-RA任务和RATs40K数据集，将时间序列异常检测转化为基于LLM的生成式推理任务，旨在提升可解释性。

**AI_Comments:** 该论文的创新点在于提出了一个全新的时间序列异常推理任务，将传统的判别式检测转变为生成式推理，并引入了LLMs。其核心贡献是构建了一个大规模、多模态、高质量标注的真实世界数据集RATs40K，填补了该领域缺乏可解释性数据的空白。通过结合GPT-4进行标注，确保了数据的准确性和可解释性，这对于推动可解释AI在时间序列领域的应用具有重要意义。同时，开源数据集和代码将极大促进后续研究。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列异常检测方法仅限于二元分类，缺乏详细的异常类别划分和解释性推理。

**Method:** 本文提出了一项新颖的“时间序列异常推理 (Time-RA)”任务，旨在将传统的时间序列异常检测从判别式任务转变为利用大型语言模型（LLMs）的生成式、推理密集型任务。为支持此任务，研究引入了首个真实世界多模态基准数据集RATs40K，该数据集包含约40,000个样本，涵盖10个真实世界领域。每个样本都包含数值时间序列数据、上下文文本信息和视觉表示，并标注了细粒度类别（单变量14种，多变量6种）和结构化解释性推理。数据集的标注采用复杂的框架，通过集成生成的标签并由GPT-4驱动的反馈进行完善，以确保准确性和可解释性。

**Result:** 对LLMs和多模态LLMs的广泛基准测试展示了当前模型的能力和局限性，并强调了监督微调在提升模型性能中的关键作用。

**Conclusion:** 该数据集和任务为可解释时间序列异常检测和推理的重大进展铺平了道路，并有望加速该领域的未来研究。

> **ai_Abstract:** 本文提出了Time-RA（时间序列异常推理）这一新任务，旨在克服传统时间序列异常检测仅限于二元分类且缺乏解释性推理的局限。通过将该任务转化为基于大型语言模型（LLMs）的生成式推理，并构建了首个多模态真实世界基准数据集RATs40K。该数据集包含40,000个样本，涵盖数值、文本和视觉数据，并带有细粒度异常类别和结构化解释性推理标注，其中标注过程利用GPT-4进行完善。研究通过对LLMs的基准测试，揭示了当前模型的潜力与不足，并强调监督微调的重要性。该工作为可解释时间序列异常检测及推理领域的发展奠定了基础，并开源了代码和数据集。

> **摘要翻译:** 时间序列异常检测在各个领域都至关重要，但当前的方法通常将分析限制在仅仅的二元异常分类，缺乏详细的分类或进一步的解释性推理。为了解决这些限制，我们提出了一项新颖的任务——时间序列异常推理（Time-RA），它将经典的时间序列异常检测从判别式任务转变为利用大型语言模型（LLMs）的生成式、推理密集型任务。此外，我们引入了第一个专门为异常推理而标注的真实世界多模态基准数据集RATs40K，该数据集包含约40,000个样本，涵盖10个真实世界领域。每个样本都包含数值时间序列数据、上下文文本信息和视觉表示，并标注了细粒度类别（单变量异常14种，多变量异常6种）和结构化解释性推理。我们开发了一个复杂的标注框架，利用集成生成的标签并通过GPT-4驱动的反馈进行完善，以确保准确性和可解释性。对LLMs和多模态LLMs的广泛基准测试展示了当前模型的能力和局限性，强调了监督微调的关键作用。我们的数据集和任务为可解释时间序列异常检测和推理的重大进展铺平了道路。代码（https://github.com/yyysjz1997/Time-RA）和数据集（https://huggingface.co/datasets/Time-RA/RATs40K）已完全开源，以支持和加速该领域的未来研究。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [612] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
> *嵌套图伪标签细化用于噪声标签域适应学习*

*Yingxu Wang, Mengzhu Wang, Zhichao Huang, Suyu Liu* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图域适应, 噪声标签, 伪标签细化, 嵌套机制, 噪声感知正则化

**Comment:** 

> **TL;DR:** 提出NeGPR框架，通过双分支预训练、嵌套细化和噪声感知正则化，解决图域适应中源域标签噪声问题，显著提升性能。

**AI_Comments:** NeGPR的创新点在于其针对图域适应中普遍存在的噪声标签问题提出了全面的解决方案。通过结合双分支预训练、嵌套细化机制和理论证明的噪声感知正则化，该方法有效地减轻了噪声监督和伪标签噪声的影响，并解决了源域过拟合的问题。这种多管齐下的方法显著提升了模型在真实世界复杂场景下的鲁棒性和适应性能，对图域适应研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图域适应（GDA）方法大多假设源标签是干净的，但这在真实世界中很少成立，标签噪声会严重损害特征对齐并降低适应性能。

**Method:** 提出NeGPR，一个用于带噪声标签的图级域适应框架。它首先预训练语义和拓扑双分支，通过强制特征空间中的邻域一致性来减少噪声监督影响。其次，采用嵌套细化机制，一个分支选择高置信度目标样本指导另一个分支的适应，实现渐进式跨域学习。最后，引入噪声感知正则化策略，理论证明可减轻伪标签噪声的不利影响，即使在源过拟合也能增强鲁棒性。

**Result:** 在基准数据集上的大量实验表明，NeGPR在严重标签噪声下始终优于现有先进方法，准确率提升高达12.7%。

**Conclusion:** NeGPR有效解决了图级域适应中噪声标签的问题，通过其独特的设计实现了优越的性能和鲁棒性。

> **ai_Abstract:** 本文提出了嵌套图伪标签细化（NeGPR）框架，旨在解决图域适应中源域标签噪声问题。NeGPR通过预训练语义和拓扑双分支以减少噪声影响，采用嵌套细化机制进行跨域学习，并引入噪声感知正则化策略以应对伪标签噪声和源域过拟合。实验证明，NeGPR在存在严重标签噪声的情况下，性能显著优于现有SOTA方法。

> **摘要翻译:** 图域适应（GDA）通过学习域不变表示，促进了从有标签源图到无标签目标图的知识迁移，这在分子性质预测和社交网络分析等应用中至关重要。然而，大多数现有的GDA方法都依赖于源标签干净的假设，这在标签噪声普遍存在的真实场景中很少成立。这种标签噪声严重损害了特征对齐，并降低了域偏移下的适应性能。为了解决这一挑战，我们提出了一种新颖的框架——嵌套图伪标签细化（NeGPR），专为带有噪声标签的图级域适应而设计。NeGPR首先通过在特征空间中强制执行邻域一致性来预训练双分支，即语义分支和拓扑分支，从而减少噪声监督的影响。为了弥合域间隙，NeGPR采用了一种嵌套细化机制，其中一个分支选择高置信度目标样本来指导另一个分支的适应，从而实现渐进式跨域学习。此外，由于伪标签可能仍然包含噪声，并且预训练的分支已经对源域中的噪声标签过拟合，NeGPR引入了一种噪声感知正则化策略。理论证明，这种正则化可以减轻伪标签噪声的不利影响，即使在源过拟合的情况下也能增强适应过程的鲁棒性。在基准数据集上进行的大量实验表明，NeGPR在严重标签噪声下始终优于最先进的方法，准确率提升高达12.7%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [620] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
> *通过开源合成数据SDK实现表格数据访问的民主化*

*Ivona Krchova, Mariana Vargas Vieyra, Mario Scriminaci, Andrey Sidorenko* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 合成数据, 表格数据, SDK, 数据访问, 差分隐私

**Comment:** 

> **TL;DR:** 本文介绍了一个开源的合成数据SDK，旨在通过生成高质量的表格合成数据来解决数据访问障碍，该SDK具有差分隐私、公平性等特性，并提升了速度和可用性。

**AI_Comments:** 该论文的创新之处在于提供了一个全面、开源的表格合成数据SDK，并集成了差分隐私和公平性等关键特性。它有效地解决了机器学习开发中的数据访问瓶颈，并展示了其在实际应用中的潜力和性能改进，具有重要的现实意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习开发严重依赖高质量数据，但隐私、专有利益和伦理问题导致数据可访问性面临巨大障碍。合成数据提供了一个可行的解决方案，可以在不损害敏感信息的情况下实现安全、广泛的数据使用。

**Method:** 本文提出了MOSTLY AI合成数据软件开发工具包（SDK），这是一个专为合成高质量表格数据而设计的开源工具包。该SDK将差分隐私保证、公平性感知数据生成和自动化质量保证等强大功能集成到一个灵活易用的Python接口中。它利用TabularARGN自回归框架，支持多样的数据类型以及复杂的多表和序列数据集。

**Result:** 该SDK在性能上具有竞争力，并在速度和可用性方面有显著提升。目前，该SDK已作为云服务和本地可安装软件部署，并已被迅速采用。

**Conclusion:** 该SDK在解决现实世界数据瓶颈和促进数据民主化方面具有实用性。

> **ai_Abstract:** 本文介绍了MOSTLY AI合成数据SDK，这是一个开源Python工具包，旨在生成高质量的表格合成数据。它解决了机器学习中因隐私和伦理问题导致的数据可访问性日益增长的挑战。该SDK融合了差分隐私和公平性感知生成等特性，利用TabularARGN框架，并展示了速度和可用性方面的提升，从而促进了更广泛、更安全的数据利用。

> **摘要翻译:** 机器学习开发严重依赖高质量数据。然而，由于隐私、专有利益和伦理问题日益增多的限制，数据可访问性面临巨大障碍。合成数据提供了一个可行的解决方案，可以在不损害敏感信息的情况下实现安全、广泛的数据使用。本文介绍了MOSTLY AI合成数据软件开发工具包（SDK），这是一个专为合成高质量表格数据而设计的开源工具包。该SDK将差分隐私保证、公平性感知数据生成和自动化质量保证等强大功能集成到一个灵活易用的Python接口中。该SDK利用TabularARGN自回归框架，支持多样的数据类型以及复杂的多表和序列数据集，在性能上具有竞争力，并在速度和可用性方面有显著提升。目前，该SDK已作为云服务和本地可安装软件部署，并已被迅速采用，突显了其在解决现实世界数据瓶颈和促进数据民主化方面的实用性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [626] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
> *自适应机器学习驱动的多精度分层抽样用于非线性随机系统故障分析*

*Liuyun Xu, Seymour M. J. Spence* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多精度抽样, 分层抽样, 机器学习, 故障分析, 随机系统

**Comment:** 

> **TL;DR:** 该研究提出了一种自适应机器学习驱动的多精度分层抽样方案，用于高效地估计非线性随机系统中的小故障概率，并在计算成本显著降低的情况下保持准确性。

**AI_Comments:** 该论文创新性地将多精度分层抽样与自适应机器学习元模型相结合，有效解决了复杂非线性随机系统中小故障概率估计的计算效率问题。其核心贡献在于利用深度学习构建成本效益高的低精度模型，并通过自适应训练平衡精度与计算开销，这对于工程领域中的可靠性分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有用于稀有事件分析的随机模拟方差减少技术，在估计小故障概率时仍需要大量的模型评估，这在复杂的非线性有限元建模环境中（特别是对于受随机激励的系统）计算成本高昂。

**Method:** 该方法引入了一种具有自适应机器学习元模型的的多精度分层抽样方案。它利用分层抽样生成的高精度数据集来训练一个基于深度学习的元模型作为低成本、高相关的低精度模型。提出了自适应训练方案来平衡近似质量和计算需求。通过将低精度输出与额外的高精度结果相结合，使用多精度蒙特卡罗框架获得分层故障概率的无偏估计。总故障概率通过全概率定理计算。

**Result:** 在应用于受随机风激励的全尺寸高层钢结构建筑时，所提出的方案能够准确估计感兴趣的非线性响应的超限概率曲线，并且与单精度方差减少方法相比，实现了显著的计算节省。

**Conclusion:** 所提出的自自适应机器学习驱动的多精度分层抽样方案，能够高效且准确地估计非线性随机系统中的小故障概率，显著降低了计算成本。

> **ai_Abstract:** 本研究提出了一种自适应机器学习驱动的多精度分层抽样方法，旨在解决现有稀有事件分析中高昂的计算成本问题。通过使用深度学习元模型作为低精度代理，并在高精度数据上进行自适应训练，该方法能够高效地估计非线性随机系统（如受随机风激励的高层建筑）的小故障概率。实验结果表明，该方案在保证准确性的同时，显著降低了计算量。

> **摘要翻译:** 现有用于稀有事件分析的随机模拟方差减少技术，在估计小故障概率时仍需要大量的模型评估。在复杂的非线性有限元建模环境中，这可能在计算上极具挑战性——特别是对于受随机激励的系统。为了解决这一挑战，本文引入了一种具有自适应机器学习元模型的多精度分层抽样方案，用于高效地传播不确定性并估计小故障概率。在该方法中，通过分层抽样生成的高精度数据集用于训练一个基于深度学习的元模型，该元模型随后作为一种成本效益高且高度相关的低精度模型。提出了一种自适应训练方案来平衡与低精度模型开发相关的近似质量和计算需求之间的权衡。通过将低精度输出与额外的高精度结果相结合，使用多精度蒙特卡罗框架获得分层故障概率的无偏估计。然后使用全概率定理计算总故障概率。应用于受随机风激励的全尺寸高层钢结构建筑的案例表明，所提出的方案能够准确估计感兴趣的非线性响应的超限概率曲线，同时与单精度方差减少方法相比，实现了显著的计算节省。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [633] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
> *一种简单有效的量化不确定性和OOD检测方法*

*Yaxin Ma, Benjamin Colburn, Jose C. Principe* | **Category: cs.LG, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 不确定性量化, OOD检测, 特征空间密度, 核密度估计, 单个确定性模型

**Comment:** 

> **TL;DR:** 本文提出了一种基于特征空间密度的方法，利用单个确定性模型来有效量化不确定性并检测分布偏移和OOD样本，解决了现有方法计算密集和存储需求大的问题。

**AI_Comments:** 本文的创新之处在于提出了一种利用单个确定性模型进行不确定性量化和OOD检测的方法，显著降低了计算复杂度和存储需求。通过利用特征空间密度和信息势场的概念，提供了一种新颖且有效的解决方案，克服了现有方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的贝叶斯神经网络和深度集成方法在量化不确定性时计算成本高昂且需要大量存储空间。

**Method:** 本文提出了一种基于特征空间密度的方法来量化不确定性并进行OOD检测。具体来说，该方法利用核密度估计导出的信息势场来近似训练集的特征空间密度，并通过比较测试样本的特征空间表示与此密度来判断是否存在分布偏移。

**Result:** 实验在二维合成数据集（Two Moons和Three Spirals）以及OOD检测任务（CIFAR-10 vs. SVHN）上进行，结果表明该方法优于基线模型。

**Conclusion:** 本文提出的基于特征空间密度的不确定性量化和OOD检测方法，利用单个确定性模型，在计算效率和存储方面优于现有方法，并能有效识别分布偏移和OOD样本。

> **ai_Abstract:** 本文提出了一种简单有效的基于特征空间密度的方法，用于量化不确定性和检测离群点（OOD）。该方法通过利用单个确定性模型，解决了传统贝叶斯神经网络和深度集成方法计算密集和存储需求大的问题。它通过核密度估计的信息势场近似训练集特征空间密度，并与测试样本进行比较以识别分布偏移。实验证明，该方法在合成数据集和OOD检测任务上均优于现有基线模型。

> **摘要翻译:** 贝叶斯神经网络和深度集成方法已被提出用于不确定性量化；然而，它们计算密集且需要大量存储。通过利用单个确定性模型，我们可以解决上述问题。我们提出了一种基于特征空间密度的有效方法，用于量化分布偏移的不确定性以及进行离群点（OOD）检测。具体来说，我们利用从核密度估计导出的信息势场来近似训练集的特征空间密度。通过将此密度与测试样本的特征空间表示进行比较，我们可以有效地确定是否发生了分布偏移。实验在二维合成数据集（Two Moons和Three Spirals）以及一个OOD检测任务（CIFAR-10 vs. SVHN）上进行。结果表明，我们的方法优于基线模型。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [635] [Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks](https://arxiv.org/abs/2504.10403)
> *空间计算能力网络中基础模型的卫星联邦微调*

*Yan Zhu, Jingyang Zhu, Ting Wang, Yuanming Shi, Chunxiao Jiang, Khaled Ben Letaief* | **Category: cs.LG, cs.DC, cs.NI** | **Updated: 2025-07-31**

**Keywords:** 卫星联邦学习, 基础模型微调, 空间计算网络, 协同训练, 通信策略

**Comment:** 

> **TL;DR:** 提出了一种卫星-地面协同联邦微调框架，用于解决大型基础模型在卫星上微调时面临的计算和通信挑战，显著缩短了训练时间。

**AI_Comments:** 该论文的创新点在于提出了卫星-地面协同的联邦微调框架，有效结合了卫星和地面的计算能力，并针对空间通信的特殊性设计了定制化的通信策略。这对于推动大型AI模型在空间计算网络中的实际应用具有重要意义，尤其是在数据隐私和带宽受限的场景下。其贡献在于为未来星载AI模型的部署和更新提供了可行的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 大型遥感基础模型在地面进行微调面临隐私和带宽限制。传统的卫星联邦学习框架中，卫星的计算能力不足以支持大型基础模型的有效星载微调。空间传输网络特殊的通信拓扑结构（如间歇性星地通信、短时星地通信窗口、不稳定的星间链路）带来了通信挑战。

**Method:** 提出了一种卫星-地面协同联邦微调框架。关键在于如何合理分解和分配模型组件，以缓解星载计算能力不足。在微调过程中，卫星与地面站或其他卫星交换中间结果进行前向传播和反向传播。为减少传输延迟，引入了结合通信和计算资源的定制通信策略，具体包括：并行轨道内通信策略、拓扑感知星地通信策略和延迟最小化轨道间通信策略。

**Result:** 仿真结果表明训练时间显著减少，提升了约33%。

**Conclusion:** 该研究提出的卫星-地面协同联邦微调框架及其定制通信策略，有效解决了大型基础模型在空间计算能力网络中进行微调时面临的计算和通信挑战，显著缩短了训练时间。

> **ai_Abstract:** 本论文提出了一种卫星-地面协同联邦微调框架，旨在解决大型基础模型在空间计算能力网络中进行星载微调时面临的计算能力不足和通信挑战。该框架通过合理分解和分配模型组件来优化星载计算，并引入了并行轨道内、拓扑感知星地和延迟最小化轨道间通信策略以减少传输延迟。仿真结果显示，该方法可将训练时间缩短约33%。

> **摘要翻译:** 人工智能（AI）和低地球轨道（LEO）卫星的进步促进了大型遥感基础模型在各种下游任务中的应用。然而，由于隐私问题和有限的带宽，直接下载这些模型到地面进行微调受到了阻碍。卫星联邦学习（FL）通过在卫星上直接进行模型微调并聚合模型更新而无需下载数据，提供了一种解决方案。尽管如此，对于大型基础模型，卫星的计算能力不足以支持传统卫星联邦学习框架中有效的星载微调。为了解决这些挑战，我们提出了一种卫星-地面协同联邦微调框架。该框架的关键在于如何合理分解和分配模型组件，以缓解星载计算能力不足。在微调过程中，卫星与地面站或其他卫星交换中间结果进行前向传播和反向传播，这由于空间传输网络特殊的通信拓扑结构（例如间歇性星地通信、短时星地通信窗口和不稳定的轨道间卫星链路（ISLs））带来了通信挑战。为了减少传输延迟，我们进一步引入了结合通信和计算资源的定制通信策略。具体来说，我们提出了一种并行轨道内通信策略、一种拓扑感知星地通信策略和一种延迟最小化轨道间通信策略，以降低空间通信成本。仿真结果表明训练时间显著减少，提升了约33%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [639] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
> *强化学习中部分可观测性基准测试，采用一套记忆可改进域*

*Ruo Yu Tao, Kaicheng Guo, Cameron Allen, George Konidaris* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 部分可观测性, 基准测试, 记忆可改进, POBAX, JAX

**Comment:** To appear at RLC 2025. 1 cover page, 10 pages, 3 reference pages + 13
  pages for supplementary material

> **TL;DR:** 该研究引入了一个名为 POBAX 的新基准测试套件和最佳实践指南，用于评估强化学习算法在各种具有挑战性的部分可观测环境中的表现，旨在推动记忆驱动的部分可观测性研究。

**AI_Comments:** 这篇论文的创新点在于它识别并解决了现有部分可观测性强化学习基准的不足。通过提出“记忆可改进”这一关键概念，并构建了一个涵盖多种复杂部分可观测形式的基准测试套件 POBAX，它为研究人员提供了一个更全面、更具挑战性的评估工具。这对于推动通用强化学习算法在真实世界复杂环境中的应用至关重要，因为它强调了记忆和推理在处理不确定性方面的核心作用。

<details>
  <summary>Details</summary>

**Motivation:** 缓解部分可观测性是通用强化学习算法的一项必要但具有挑战性的任务。现有的大多数部分可观测性基准测试仅限于简单的状态混叠形式，无法代表真实世界中多种形式的部分可观测性，因此研究人员缺乏全面的基准来衡量算法在此方面的进展。

**Method:** 作者提出了部分可观测性基准应具备的两个关键特性：一是部分可观测形式的覆盖广度，确保算法的泛化能力；二是具有显著的性能差距，表明环境是记忆可改进的。在此基础上，他们引入了在部分可观测性下经验性地测试强化学习的最佳实践指南，并发布了开源库 POBAX (Partially Observable Benchmarks in JAX)。该库选择了包含定位与建图、视觉控制和游戏等多种代表性环境，并提供了推荐的超参数和算法实现，以及在 JAX 中实现的高性能环境，支持 GPU 可扩展实验。

**Result:** 论文表明，所选的基准测试任务都是记忆可改进的，并且需要学习难以掌握的记忆功能，这为部分可观测性研究提供了具体的信号。POBAX 框架提供了一个快速、开箱即用的评估工具。

**Conclusion:** 该研究通过引入 POBAX 基准测试套件和最佳实践指南，为强化学习中部分可观测性问题的评估提供了全面且具有挑战性的工具，有助于推动该领域算法的进步，特别是那些需要复杂记忆功能的算法。

> **ai_Abstract:** 本文旨在解决现有强化学习部分可观测性基准测试的局限性，提出了一套新的最佳实践指南和一个名为 POBAX 的开源基准测试库。POBAX 包含多种记忆可改进的、具有挑战性的部分可观测环境（如定位、视觉控制和游戏），这些环境旨在全面评估算法应对复杂部分可观测性的能力。研究表明，这些任务确实需要复杂的记忆功能，为该领域的研究提供了具体的测试信号。该框架还提供了易于使用的评估工具和高性能环境，以促进相关研究进展。

> **摘要翻译:** 缓解部分可观测性是通用强化学习算法的一项必要但具有挑战性的任务。为了提高算法缓解部分可观测性的能力，研究人员需要全面的基准来衡量进展。大多数处理部分可观测性的算法仅在具有简单状态混叠形式（例如特征遮蔽和高斯噪声）的基准上进行评估。此类基准无法代表真实领域中存在的多种形式的部分可观测性，例如视觉遮挡或未知的对手意图。我们认为，部分可观测性基准应具有两个关键特性。首先是其部分可观测形式的覆盖范围，以确保算法的通用性。其次是具有更多或更少状态信息的智能体之间的性能差距较大，其他所有因素大致相等。这种差距意味着环境是记忆可改进的：域中的性能提升来自于算法应对部分可观测性的能力，而不是其他因素。我们介绍了在部分可观测性下经验性地测试强化学习的最佳实践指南，以及开源库 POBAX：JAX 中的部分可观测性基准。我们描述了各种环境中存在的部分可观测性类型，并为我们的基准选择了代表性环境。这些环境包括定位与建图、视觉控制、游戏等。此外，我们还表明这些任务都是记忆可改进的，并且需要难以学习的记忆功能，为部分可观测性研究提供了具体的信号。该框架包括推荐的超参数以及用于快速、开箱即用评估的算法实现，以及在 JAX 中实现的高性能环境，可用于 GPU 可扩展实验。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [640] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
> *表格数据异常检测的扩散调度去噪自编码器*

*Timur Sattarov, Marco Schreyer, Damian Borth* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 异常检测, 表格数据, 去噪自编码器, 扩散模型, 对比学习

**Comment:** 22 pages, 16 figures, 7 tables, preprint version

> **TL;DR:** 提出DDAE，结合扩散模型噪声调度和对比学习，显著提升表格数据异常检测性能，尤其在半监督场景下优于现有SOTA模型。

**AI_Comments:** 这项工作通过将扩散模型的噪声调度机制和对比学习引入去噪自编码器，为表格数据异常检测提供了一种新颖且有效的方法。其创新点在于克服了传统去噪自编码器噪声固定和扩散模型缺乏重建映射的局限性。在多个数据集上的显著性能提升，特别是对噪声策略的深入探讨，为该领域的研究提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 表格数据异常检测因特征交互复杂和异常样本稀缺而困难。现有去噪自编码器噪声固定，适应性差；扩散模型虽引入调度噪声但缺乏重建映射。

**Method:** 提出扩散调度去噪自编码器 (DDAE)，一个将基于扩散的噪声调度和对比学习整合到编码过程中的框架，以改善异常检测。在ADBench的57个数据集上进行了评估。

**Result:** 在半监督设置中表现优异，在无监督设置中达到有竞争力的结果。PR-AUC比现有自编码器(扩散)模型基线提高了高达65%(9%)，ROC-AUC提高了16%(6%)。观察到较高噪声水平有利于无监督训练，而较低噪声的线性调度在半监督设置中最佳。

**Conclusion:** 这些发现强调了在表格异常检测中原则性噪声策略的重要性。

> **ai_Abstract:** 本文针对表格数据异常检测中的挑战，提出了一种新型框架——扩散调度去噪自编码器（DDAE）。DDAE巧妙地结合了扩散模型中的噪声调度机制和对比学习，以增强去噪自编码器的性能。在ADBench的57个数据集上进行的广泛实验表明，DDAE在半监督环境下显著超越现有最先进模型，在无监督环境下也表现出色，并在PR-AUC和ROC-AUC上取得了显著提升。研究还发现，不同的噪声水平和调度策略对无监督和半监督训练效果有特定影响，强调了噪声策略在表格异常检测中的关键作用。

> **摘要翻译:** 表格数据中的异常检测由于复杂的特征交互和异常样本的稀缺性仍然具有挑战性。去噪自编码器依赖于固定幅度的噪声，限制了对不同数据分布的适应性。扩散模型引入了调度噪声和迭代去噪，但缺乏明确的重建映射。我们提出了扩散调度去噪自编码器（DDAE），一个将基于扩散的噪声调度和对比学习整合到编码过程中以改进异常检测的框架。我们在ADBench的57个数据集上评估了DDAE。我们的方法在半监督设置中表现优异，并在无监督设置中取得了有竞争力的结果，与最先进的自编码器（扩散）模型基线相比，PR-AUC提高了高达65%（9%），ROC-AUC提高了16%（6%）。我们观察到较高的噪声水平有利于无监督训练，而较低噪声的线性调度在半监督设置中是最佳的。这些发现强调了在表格异常检测中原则性噪声策略的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [647] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
> *评估变分量子机器学习中的角度和振幅编码策略：它们对模型准确性的影响*

*Antonio Tudisco, Andrea Marchesin, Maurizio Zamboni, Mariagrazia Graziano, Giovanna Turvani* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 变分量子机器学习, 量子编码, 角度编码, 振幅编码, 超参数

**Comment:** 

> **TL;DR:** 本文评估了变分量子机器学习中角度和振幅编码策略及其所用旋转门对模型分类准确性的影响，发现编码方式是VQC模型的关键超参数，其选择可导致显著的性能差异。

**AI_Comments:** 这项研究通过系统地比较不同的数据编码策略和旋转门对变分量子电路（VQC）模型性能的影响，揭示了数据嵌入在QML中的重要性。其创新之处在于量化了不同编码选择带来的巨大准确性差异，并明确指出编码本身是VQC模型的关键超参数。这对于QML模型的设计和优化具有重要的指导意义，为未来的研究提供了明确的方向，即需要深入探索和优化数据编码方法。

<details>
  <summary>Details</summary>

**Motivation:** 随着量子计算和机器学习的进步，量子机器学习（QML）受到关注，其中变分量子电路（VQC）是常用模型。VQC的编码层将数据加载到电路中，本研究旨在探究不同的编码策略（角度和振幅编码）以及旋转门类型如何影响模型的分类性能。

**Method:** 作者通过考虑振幅和角度编码模型，并检查所应用的旋转门类型如何影响模型的分类性能来进行分析。他们通过在Wine和Diabetes这两个数据集上训练不同的模型并评估其性能来进行比较。

**Result:** 研究表明，在相同的模型拓扑结构下，最佳模型和最差模型之间的准确性差异范围为10%到30%，最高可达41%。此外，结果强调了编码中使用的旋转门的选择可以显著影响模型的分类性能。

**Conclusion:** 研究结果证实，嵌入（编码策略）是VQC模型的超参数。

> **ai_Abstract:** 本文研究了变分量子机器学习（QML）中变分量子电路（VQC）的角度和振幅编码策略及其所用旋转门对模型分类准确性的影响。通过在Wine和Diabetes数据集上训练和比较不同编码模型，研究发现，即使在相同的模型拓扑下，不同编码策略和旋转门的选择会导致模型准确性存在10%到41%的显著差异。这表明数据嵌入方式是VQC模型的关键超参数，对其性能有重要影响。

> **摘要翻译:** 近期量子计算和机器学习的进展增加了对量子机器学习（QML）的关注，该领域旨在利用量子计算范式开发机器学习模型。该领域中广泛使用的模型之一是变分量子电路（VQC），这是一种混合模型，其中量子电路处理数据推理，而经典优化则调整电路参数。量子电路由一个编码层（将数据加载到电路中）和一个模板电路（称为ansatz，负责处理数据）组成。这项工作通过考虑振幅和角度编码模型，并检查所应用的旋转门类型如何影响模型的分类性能来进行分析。这种比较是通过在Wine和Diabetes这两个数据集上训练不同的模型并评估其性能来进行的。研究表明，在相同的模型拓扑结构下，最佳模型和最差模型之间的准确性差异范围为10%到30%，最高可达41%。此外，结果强调了编码中使用的旋转门的选择可以显著影响模型的分类性能。研究结果证实，嵌入（encoding）是VQC模型的超参数。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [654] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
> *基于考试的学生评估中的可解释人工智能和机器学习：社会学、学术和经济因素的因果和预测分析*

*Bushra Akter, Md Biplob Hosen, Sabbir Ahmed, Mehrin Anannya, Md. Farhad Hossain* | **Category: cs.LG** | **Updated: 2025-08-01**

**Keywords:** 可解释AI, 机器学习, 学生评估, 因果分析, 学业表现

**Comment:** 

> **TL;DR:** 本研究利用可解释AI和机器学习，通过因果和预测分析，探究社会学、学术和经济因素对学生学业表现（CGPA）的影响，并开发了一个帮助学生提升表现的网络应用。

**AI_Comments:** 该论文的创新点在于结合了因果分析和可解释AI技术来理解影响学生学业表现的复杂因素，并进一步将研究成果转化为实际应用（网络平台）。其重要性体现在为学生提供了个性化、数据驱动的指导，有助于提升教育效果。潜在的局限性可能包括在线调查的样本偏差，以及模型对其他未考虑因素的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 学业表现受多变量的社会学、学术和经济因素影响，本研究旨在调查这些影响，以制定优化学生平均绩点（CGPA）的有效策略。

**Method:** 研究回顾了文献以识别关键影响因素，构建了初步假设因果图。通过在线调查收集了1050名学生的数据。数据经过严格的预处理（清洗和可视化）。采用因果分析验证变量间关系。使用回归模型预测CGPA（Ridge Regression），分类模型对学生表现分级（Random Forest）。利用SHAP、LIME和Interpret等可解释AI技术增强模型可解释性。最终开发了一个提供个性化洞察的网络应用。

**Result:** Ridge Regression在CGPA预测中表现出强大的预测准确性，平均绝对误差（MAE）为0.12，均方误差（MSE）为0.023。Random Forest在分类中表现出色，F1分数接近完美，准确率为98.68%。可解释AI技术突出了学习时间、奖学金、父母教育和先前的学业表现等关键因素。

**Conclusion:** 本研究成功开发了一个基于可解释AI和机器学习的网络应用程序，该应用能够预测学生学业表现，识别需要改进的领域，并帮助学生做出明智决策以提升学习成果，证明了社会学、学术和经济因素对CGPA的重要影响。

> **ai_Abstract:** 本研究利用可解释AI和机器学习，深入分析社会学、学术和经济因素对学生学业表现（CGPA）的影响。通过文献综述、千名学生调查和数据预处理，构建了因果模型并应用了回归（Ridge Regression）和分类（Random Forest）模型进行预测和评估。结果显示模型具有高准确性，并通过SHAP、LIME等可解释AI技术揭示了关键影响因素。最终，研究开发了一个网络应用，旨在为学生提供个性化指导，以优化其学业成果。

> **摘要翻译:** 学业表现取决于社会学、学术和经济因素的多变量联系。本研究调查这些影响，以制定优化学生平均绩点（CGPA）的有效策略。为此，我们查阅了各种文献以确定关键影响因素，并根据研究结果构建了初始假设因果图。此外，还进行了一项在线调查，共有1050名学生参与，为分析提供了全面的数据。在分析之前，采用了严格的数据预处理技术，包括数据清洗和可视化，以确保数据质量。因果分析验证了变量之间的关系，为它们对CGPA的直接和间接影响提供了更深入的见解。回归模型用于CGPA预测，而分类模型根据表现水平对学生进行分类。岭回归（Ridge Regression）表现出强大的预测准确性，平均绝对误差为0.12，均方误差为0.023。随机森林（Random Forest）在分类中表现出色，F1分数接近完美，准确率为98.68%。SHAP、LIME和Interpret等可解释人工智能技术增强了模型的可解释性，突出了学习时间、奖学金、父母教育和先前的学业表现等关键因素。本研究最终开发了一个基于网络的应用程序，为学生提供个性化洞察，使他们能够预测学业表现，识别需要改进的领域，并做出明智的决策以提高他们的成绩。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [661] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
> *Adacc：面向LLM内存管理的自适应压缩与激活检查点*

*Ping Chen, Zhuohong Deng, Ping Li, Shuibing He, Hongzi Zhu, Yi Zheng, Zhefeng Wang, Baoxing Huai, Minyi Guo* | **Category: cs.LG, cs.DC** | **Updated: 2025-08-01**

**Keywords:** 自适应压缩, 激活检查点, LLM, 内存管理, 训练加速

**Comment:** 8 pages

> **TL;DR:** Adacc是一个新颖的内存管理框架，通过结合自适应压缩和激活检查点来减少LLM训练的GPU内存占用，从而加速训练并保持模型精度。

**AI_Comments:** Adacc的创新之处在于其结合了自适应压缩和激活检查点技术，并通过三个模块实现了内存管理的精细化和动态化。特别是层特定压缩算法考虑了LLM张量的异常值，避免了直接量化可能带来的精度损失，以及自适应策略演化机制能够动态调整优化策略以适应训练变化，这些都显著提升了其实用性和性能。该研究对于缓解LLM训练中的内存瓶颈并提高训练效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 训练大型语言模型时，通常采用重新计算来缓解内存压力，但这在实际场景中会引入高达30%的开销。

**Method:** 本文提出了Adacc，一个结合自适应压缩和激活检查点的新型内存管理框架。它包含三个模块：1) 设计了针对LLM张量中异常值的层特定压缩算法，以确保模型精度；2) 提出了一个利用MILP确定每个张量最佳内存优化的最优调度策略；3) 引入了自适应策略演化机制，以适应训练张量的变化并在训练过程中调整策略以提高吞吐量。

**Result:** 实验结果表明，与现有最先进的框架相比，Adacc可以将LLM训练加速1.01倍到1.37倍，同时保持与基线模型相当的精度。

**Conclusion:** Adacc通过创新的自适应压缩和激活检查点方法，有效解决了LLM训练中的内存压力问题，显著提升了训练速度并维持了模型精度，是LLM内存管理领域的一个有效解决方案。

> **ai_Abstract:** Adacc是一个旨在优化大型语言模型（LLM）训练内存管理的新框架，旨在解决现有重计算方法带来的高达30%的开销。该框架结合了自适应压缩和激活检查点技术，通过三个核心模块实现：一是设计了针对LLM张量异常值的层特定压缩算法以保证精度；二是通过MILP实现最优的张量内存优化调度；三是引入自适应策略演化机制以动态调整优化策略。实验证明，Adacc能将LLM训练速度提升1.01至1.37倍，同时保持与基线模型相当的精度。

> **摘要翻译:** 训练大型语言模型通常采用重新计算来缓解内存压力，这在实际场景中会引入高达30%的开销。在本文中，我们提出了Adacc，一个新颖的内存管理框架，它结合了自适应压缩和激活检查点来减少GPU内存占用。它包括三个模块：(1) 我们设计了层特定的压缩算法，这些算法考虑了LLM张量中的异常值，而不是直接将FP16浮点数量化为INT4，以确保模型精度。(2) 我们提出了一种最优调度策略，该策略采用MILP来确定每个张量的最佳内存优化。(3) 为了适应训练张量的变化，我们引入了一种自适应策略演化机制，该机制在训练过程中调整策略以提高吞吐量。实验结果表明，与现有最先进的框架相比，Adacc可以将LLM训练加速1.01倍到1.37倍，同时保持与基线模型相当的模型精度。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [662] [Scientific Machine Learning with Kolmogorov-Arnold Networks](https://arxiv.org/abs/2507.22959)
> *基于柯尔莫哥洛夫-阿诺德网络的科学机器学习*

*Salah A. Faroughi, Farinaz Mostajeran, Amin Hamed Mashhadzadeh, Shirko Faroughi* | **Category: cs.LG, cs.CE, math-ph, math.MP** | **Updated: 2025-07-30**

**Keywords:** 科学机器学习, 柯尔莫哥洛夫-阿诺德网络, KANs, MLPs, 综述

**Comment:** 

> **TL;DR:** 该综述探讨了柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习中取代传统多层感知器（MLPs）的优势，总结了其在数据驱动学习、物理信息建模和深度算子学习方面的进展，并指出了未来的研究挑战。

**AI_Comments:** 这篇综述突出了KANs作为MLPs在科学机器学习中更具优势的替代方案。其创新之处在于系统性地总结了KANs在不同应用场景下的进展，并明确指出了其相比MLPs在性能上的提升。文章的价值在于为研究人员提供了KANs的全面视图，包括其优点、当前挑战和未来研究方向，对于推动科学机器学习领域的发展具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 科学机器学习领域最初使用多层感知器（MLPs），但MLPs存在解释性差、激活函数固定以及难以捕捉局部或高频特征等局限性。柯尔莫哥洛夫-阿诺德网络（KANs）通过增强解释性和灵活性来解决这些问题，从而更有效地建模复杂的非线性相互作用，克服了传统MLP架构的限制。

**Method:** 本文综述了KANs在科学机器学习中的应用进展，将其分为三个主要视角：(i)数据驱动学习，(ii)物理信息建模，以及(iii)深度算子学习。每个视角都从架构设计、训练策略、应用效果以及与MLP对应物的比较评估等方面进行了考察。通过将KANs与MLPs进行基准测试，突出了KANs的优势。

**Result:** 通过与MLPs的基准测试，KANs在准确性、收敛性和频谱表示方面均表现出持续改进，这表明KANs在捕捉复杂动力学和更有效学习方面具有明显优势。

**Conclusion:** KANs在科学机器学习中展现出优于MLPs的性能，尤其在解释性和处理复杂非线性方面。然而，KANs的发展仍面临计算效率、理论保证、超参数调整和算法复杂性等挑战。未来的研究方向包括提高KANs框架的鲁棒性、可扩展性和物理一致性。

> **ai_Abstract:** 本综述探讨了柯尔莫哥洛夫-阿诺德网络（KANs）在科学机器学习领域取代传统多层感知器（MLPs）的趋势。文章指出MLPs存在解释性差、激活函数固定及难以捕捉局部特征等问题，而KANs通过增强解释性和灵活性，能更有效地建模复杂非线性关系。综述将KANs的进展分为数据驱动学习、物理信息建模和深度算子学习三个方面进行详细考察，并指出KANs在准确性、收敛性和频谱表示上均优于MLPs。文章最后讨论了KANs面临的计算效率、理论保证等挑战，并提出了未来的研究方向。

> **摘要翻译:** 科学机器学习领域最初使用多层感知器（MLPs），但目前正越来越多地采用柯尔莫哥洛夫-阿诺德网络（KANs）进行数据编码。这种转变是由MLPs的局限性所驱动的，包括解释性差、激活函数固定以及难以捕捉局部或高频特征。KANs通过增强解释性和灵活性来解决这些问题，从而能够更有效地建模复杂的非线性相互作用，并有效克服与传统MLP架构相关的限制。这篇综述从三个不同视角对基于KAN的模型近期进展进行了分类：(i)数据驱动学习，(ii)物理信息建模，以及(iii)深度算子学习。每个视角都从架构设计、训练策略、应用效果以及与基于MLP的对应物的比较评估方面进行了考察。通过将KANs与MLPs进行基准测试，我们强调了在准确性、收敛性和频谱表示方面的一致改进，阐明了KANs在捕捉复杂动力学和更有效学习方面的优势。最后，本综述指出了KANs发展中的关键挑战和开放性研究问题，特别是关于计算效率、理论保证、超参数调整和算法复杂性。我们还概述了旨在提高基于KAN框架的鲁棒性、可扩展性和物理一致性的未来研究方向。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [681] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
> *TriP-LLM：一种用于时间序列异常检测的三分支分块大型语言模型框架*

*Yuan-Cheng Yu, Yen-Chieh Ouyang, Chun-An Lin* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 时间序列异常检测, 大型语言模型, 三分支, 分块处理, 无监督学习

**Comment:** 11 pages, 2 figures

> **TL;DR:** TriP-LLM是一种新颖的基于LLM的时间序列异常检测框架，通过三分支分块处理，在性能和内存效率上超越了现有方法。

**AI_Comments:** TriP-LLM的创新之处在于其将大型语言模型应用于时间序列异常检测，并采用独特的三分支分块处理机制，有效融合局部和全局特征。该方法不仅在性能上超越了现有技术，还在内存效率方面取得了显著提升，解决了LLM在资源受限环境中应用的挑战，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统统计方法在处理物联网和智能制造中日益增长的大规模、高维度、高异构性和复杂时间序列数据时面临局限性。受大型语言模型（LLMs）在语言和视觉等多模态任务中成功的启发，研究人员寻求开发一种新的解决方案。

**Method:** 本文提出了TriP-LLM，一个无监督的时间序列异常检测框架。它采用三分支设计（分块、选择和全局）来整合局部和全局时间特征，将输入时间序列编码为分块令牌，然后由一个冻结的预训练LLM进行处理。一个轻量级的逐块解码器用于重建输入，并从中导出异常分数。该模型在多个公共基准数据集上使用PATE（一种无阈值评估指标）进行评估，并在统一的开源框架中进行比较。

**Result:** 实验结果表明，TriP-LLM在所有数据集上持续优于现有最先进的方法，展示出强大的检测能力。广泛的消融研究验证了LLM对整体架构的实质性贡献。与使用通道独立性（CI）分块处理的基于LLM的方法相比，TriP-LLM实现了显著更低的内存消耗，更适用于GPU内存受限的环境。

**Conclusion:** TriP-LLM在时间序列异常检测中表现出强大的检测能力，并证明了LLM在该架构中的重要贡献，同时具有较低的内存消耗，使其适用于资源受限的环境。

> **ai_Abstract:** 本文提出了TriP-LLM，一个新颖的无监督时间序列异常检测框架，它借鉴了大型语言模型在多模态任务上的成功。TriP-LLM采用三分支（分块、选择、全局）设计，将时间序列编码为分块令牌，通过预训练的LLM处理，并使用轻量级解码器重建输入以生成异常分数。实验证明，TriP-LLM在多个基准数据集上持续优于现有最先进方法，且相比其他基于LLM的方法具有显著更低的内存消耗，使其适用于GPU内存受限环境。

> **摘要翻译:** 时间序列异常检测在广泛的应用领域中扮演着核心角色。随着物联网（IoT）和智能制造的日益普及，时间序列数据在规模和维度上都急剧增加。这种增长暴露了传统统计方法在处理此类数据的高度异构性和复杂性方面的局限性。受大型语言模型（LLMs）在语言和视觉等多模态任务中近期成功的启发，我们提出了一种新颖的无监督异常检测框架：TriP-LLM（一种用于时间序列异常检测的三分支分块大型语言模型框架）。TriP-LLM通过三分支设计——分块、选择和全局——整合局部和全局时间特征，将输入时间序列编码为分块令牌，然后由一个冻结的预训练LLM进行处理。一个轻量级的逐块解码器重建输入，从中导出异常分数。我们使用PATE（一种最近提出的无阈值评估指标）在几个公共基准数据集上评估了TriP-LLM，并在统一的开源框架内进行所有比较以确保公平性。实验结果表明，TriP-LLM在所有数据集上持续优于最近的最先进方法，展示出强大的检测能力。此外，通过广泛的消融研究，我们验证了LLM对整体架构的实质性贡献。与使用通道独立性（CI）分块处理的基于LLM的方法相比，TriP-LLM实现了显著更低的内存消耗，使其更适用于GPU内存受限的环境。所有代码和模型检查点均在https://github.com/YYZStart/TriP-LLM.git上公开可用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [682] [PATH: A Discrete-sequence Dataset for Evaluating Online Unsupervised Anomaly Detection Approaches for Multivariate Time Series](https://arxiv.org/abs/2411.13951)
> *PATH：一个用于评估多元时间序列在线无监督异常检测方法的离散序列数据集*

*Lucas Correia, Jan-Christoph Goos, Thomas Bäck, Anna V. Kononova* | **Category: cs.LG, cs.AI, cs.CE, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 异常检测, 多元时间序列, 离散序列, 数据集, 无监督学习

**Comment:** Submitted to the Big Data Research journal

> **TL;DR:** 本文提出了一个名为PATH的新型、多样化、大规模的离散序列数据集，用于评估多元时间序列的在线无监督异常检测方法，以解决现有数据集的不足，并提供了基线结果。

**AI_Comments:** 这项工作通过引入一个高质量、多样化且大规模的离散序列数据集PATH，填补了多元时间序列异常检测领域的一个重要空白。其创新之处在于模拟真实汽车动力总成行为来生成数据，并特别关注了离散序列问题，这是现有数据集和方法中未被充分解决的。数据集的不同版本设计考虑了多种应用场景（无监督、半监督、生成、预测）。论文提供的基线结果不仅验证了数据集的可用性，也明确指出了未来研究的方向，例如开发对污染数据更鲁棒的无监督方法以及无需标记数据的阈值选择策略，这对于推动该领域的发展至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 由于缺乏高质量的数据集，多元时间序列的异常检测方法基准测试具有挑战性。当前的公开数据集太小，缺乏多样性，并且特征是微不足道的异常，这阻碍了该研究领域的可衡量进展。

**Method:** 我们提出了一个解决方案：一个通过最先进的模拟工具生成的多样化、广泛且非平凡的数据集，该数据集反映了汽车动力总成的真实行为，包括其多元、动态和可变状态特性。此外，我们的数据集代表了一个离散序列问题。为了满足无监督和半监督异常检测设置，以及时间序列生成和预测，我们提供了不同版本的数据集，其中训练和测试子集根据任务提供受污染和干净的版本。我们还提供了基于确定性变分自编码器和非参数方法的基线结果。

**Result:** 基线实验表明，在半监督版本数据集上训练的方法优于其无监督对应方法，这突出表明需要对受污染训练数据更鲁棒的方法。此外，结果表明，所使用的阈值对检测性能有很大影响，因此需要投入更多工作来寻找无需标记数据即可找到合适阈值的方法。

**Conclusion:** 该研究表明，在半监督数据集上训练的模型表现优于无监督模型，并强调了开发对受污染训练数据更鲁棒的方法以及无需标记数据即可找到合适阈值方法的必要性。

> **ai_Abstract:** 本文针对多元时间序列异常检测领域高质量数据集稀缺的问题，提出了一个名为PATH的离散序列数据集。该数据集通过先进的模拟工具生成，具有多样性、广泛性和非平凡性，能反映汽车动力总成的真实行为，并解决了现有方法未能处理的离散序列问题。为支持不同任务，数据集提供多种版本，包含受污染和干净的训练/测试子集。文章还提供了基于自编码器和非参数方法的基线实验结果，并指出半监督方法优于无监督方法，且阈值选择对性能影响显著，强调了对更鲁棒方法和无监督阈值选择方法的需求。

> **摘要翻译:** 由于缺乏高质量的数据集，多元时间序列的异常检测方法基准测试是一项具有挑战性的任务。当前的公开数据集太小，缺乏多样性，并且特征是微不足道的异常，这阻碍了该研究领域的可衡量进展。我们提出了一个解决方案：一个通过最先进的模拟工具生成的多样化、广泛且非平凡的数据集，该数据集反映了汽车动力总成的真实行为，包括其多元、动态和可变状态特性。此外，我们的数据集代表了一个离散序列问题，这在文献中以前提出的解决方案中仍未解决。为了满足无监督和半监督异常检测设置，以及时间序列生成和预测，我们提供了不同版本的数据集，其中训练和测试子集根据任务提供受污染和干净的版本。我们还提供了基于确定性变分自编码器和非参数方法选择的基线结果。正如预期的那样，基线实验表明，在半监督版本数据集上训练的方法优于其无监督对应方法，这突出表明需要对受污染训练数据更鲁棒的方法。此外，结果表明，所使用的阈值对检测性能有很大影响，因此需要投入更多工作来寻找无需标记数据即可找到合适阈值的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [685] [On the Sustainability of AI Inferences in the Edge](https://arxiv.org/abs/2507.23093)
> *边缘侧AI推理的可持续性研究*

*Ghazal Sobhani, Md. Monzurul Amin Ifath, Tushar Sharma, Israat Haque* | **Category: cs.LG, cs.AI, cs.PF** | **Updated: 2025-07-30**

**Keywords:** 边缘计算, AI推理, 能源效率, 性能评估, 物联网

**Comment:** 14 pages, 8 figures, 6 tables, in preparation for journal submission

> **TL;DR:** 本研究通过严格表征传统模型、神经网络和大型语言模型在边缘设备上的性能，填补了现有研究中缺乏对设备和模型选择进行知情决策的空白，分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。

**AI_Comments:** 本研究的创新之处在于首次系统地评估了不同AI模型（包括传统模型、神经网络和大型语言模型）在多种主流边缘设备上的性能和能耗，并分析了关键指标之间的权衡。这对于指导实际的边缘AI部署中的设备和模型选择具有重要意义，有助于实现更可持续和高效的边缘计算。

<details>
  <summary>Details</summary>

**Motivation:** 物联网(IoT)及其AI增强型应用（如自动驾驶和智能工业）在边缘侧部署时，除了性能外，能源使用是一个关键因素。尽管边缘设备被广泛用于AI推理部署，但目前缺乏对其性能和能耗的研究，以指导设备和模型选择，从而满足应用需求。本研究旨在填补这一空白。

**Method:** 本研究通过严格表征传统模型、神经网络和大型语言模型在Raspberry Pi (RPi), Intel Neural Compute Stick (INCS), NVIDIA Jetson nano (NJn), 和 Google Coral USB (GCU)等边缘设备上的性能。具体分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。

**Result:** 研究分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。结果表明，硬件和框架优化以及AI模型的外部参数调优可以在模型性能和资源使用之间取得平衡，从而实现实用的边缘AI部署。

**Conclusion:** 硬件和框架优化，以及AI模型的外部参数调优，可以在模型性能和资源使用之间取得平衡，以实现实用的边缘AI部署。

> **ai_Abstract:** 本研究旨在解决边缘AI推理中设备和模型选择缺乏性能和能耗研究的空白。通过在多种边缘设备（如Raspberry Pi, Intel Neural Compute Stick等）上严格评估传统模型、神经网络和大型语言模型的性能，论文分析了F1分数、推理时间、推理功耗和内存使用之间的权衡。研究结果强调，通过硬件和框架优化以及AI模型参数调优，可以有效平衡模型性能和资源消耗，从而实现可持续的边缘AI部署。

> **摘要翻译:** 物联网（IoT）及其尖端AI应用（例如，自动驾驶汽车和智能工业）的普及结合了两种范式：数据驱动系统及其在边缘的部署。通常，边缘设备执行推理以支持对延迟敏感的应用。除了这些资源受限边缘设备的性能外，它们的能源使用是采用和部署边缘应用的关键因素。此类设备的例子包括Raspberry Pi (RPi)、Intel Neural Compute Stick (INCS)、NVIDIA Jetson nano (NJn)和Google Coral USB (GCU)。尽管它们在边缘部署中用于AI推理，但目前尚无关于其性能和能源使用的研究，以指导设备和模型选择，从而满足应用需求。本研究通过严格表征传统模型、神经网络和大型语言模型在上述边缘设备上的性能来填补这一空白。具体来说，我们分析了模型F1分数、推理时间、推理功耗和内存使用之间的权衡。硬件和框架优化，以及AI模型的外部参数调优，可以在模型性能和资源使用之间取得平衡，以实现实用的边缘AI部署。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [687] [Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions](https://arxiv.org/abs/2507.23539)
> *稀疏性假设下核矩阵-向量乘法的改进算法*

*Piotr Indyk, Michael Kapralov, Kshiteej Sheth, Tal Wagner* | **Category: cs.LG, cs.DS** | **Updated: 2025-07-31**

**Keywords:** 核矩阵-向量乘法, 稀疏性假设, 高斯核, 注意力机制, 亚二次算法

**Comment:** Published in ICLR 2025

> **TL;DR:** 提出了一种在稀疏性假设下，用于高斯核矩阵-向量乘法的首个亚二次时间算法，解决了注意力矩阵的快速处理问题。

**AI_Comments:** 该论文的创新之处在于提出了一个关于高斯核矩阵稀疏性的新颖建模假设，并通过实验验证了其在实际应用（如LLMs）中的有效性。在此基础上，开发出首个亚二次时间算法，显著提升了核矩阵-向量乘法的效率，对需要快速处理注意力机制的AI模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是快速处理注意力矩阵的问题，特别是为非对称高斯核矩阵计算矩阵-向量积。目标是在n的亚二次时间复杂度、d的线性时间复杂度内，近似计算Kx。

**Method:** 该算法依赖于一个建模假设：矩阵K的条目总和与n呈线性关系（而非最坏情况下的二次增长）。作者通过实验验证了这一假设，特别是在大型语言模型（LLMs）中遇到的高斯核矩阵。在此假设下，提出了第一个针对无限制向量的亚二次时间算法。

**Result:** 获得了在特定稀疏性假设下，针对无限制向量的第一个亚二次时间算法，用于计算高斯核矩阵-向量乘积。

**Conclusion:** 该研究成功开发了在特定稀疏性假设（矩阵K的条目总和与n呈线性关系）下，高效计算高斯核矩阵-向量乘积的算法，实现了亚二次时间复杂度，并为大型语言模型中的快速注意力计算提供了理论和实验支持。

> **ai_Abstract:** 该论文提出并验证了一种新的稀疏性假设，即高斯核矩阵的条目总和与尺寸n呈线性关系，而非传统的二次增长。在此假设下，作者开发了首个用于非对称高斯核矩阵-向量乘法的亚二次时间算法，旨在解决大型语言模型中注意力矩阵的快速处理问题。该算法能够以亚二次时间（关于n）和线性时间（关于d）近似计算Kx。

> **摘要翻译:** 受快速处理注意力矩阵问题的启发，我们研究了用于计算非对称高斯核矩阵 $K\in \mathbb{R}^{n\times n}$ 的矩阵-向量积的快速算法。K 的列由一组 $n$ 个键 $k_1,k_2\ldots, k_n\in \mathbb{R}^d$ 索引，行由一组 $n$ 个查询 $q_1,q_2,\ldots,q_n\in \mathbb{R}^d$ 索引，其 $i,j$ 个条目为 $K_{ij} = e^{-\|q_i-k_j\|_2^2/2\sigma^2}$，其中 $\sigma>0$ 是某个带宽参数。给定向量 $x\in \mathbb{R}^n$ 和误差参数 $\epsilon>0$，我们的任务是输出一个 $y\in \mathbb{R}^n$ 使得 $\|Kx-y\|_2\leq \epsilon \|x\|_2$，且时间复杂度在 $n$ 上是亚二次的，在 $d$ 上是线性的。我们的算法依赖于关于矩阵 K 的以下建模假设：K 的条目总和与 $n$ 呈线性关系，而不是最坏情况下的二次增长。我们通过实验验证了这一假设，适用于在各种设置中遇到的高斯核矩阵，例如大型语言模型中的快速注意力计算。我们获得了第一个在此假设下适用于无限制向量的亚二次时间算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [691] [Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios](https://arxiv.org/abs/2407.03080)
> *数据稀缺场景下合成表格数据生成的人工归纳偏置*

*Patricia A. Apellániz, Ana Jiménez, Borja Arroyo Galende, Juan Parras, Santiago Zazo* | **Category: cs.LG, cs.AI, I.2.0** | **Updated: 2025-07-31**

**Keywords:** 合成表格数据, 深度生成模型, 归纳偏置, 迁移学习, 元学习

**Comment:** 19 pages, 6 Figures

> **TL;DR:** 该论文提出了一种在数据稀缺场景下，通过将人工归纳偏置集成到深度生成模型中来提高合成表格数据质量的新方法，实验表明该方法显著提高了性能。

**AI_Comments:** 该论文创新性地将人工归纳偏置引入到深度生成模型中，以解决数据稀缺场景下合成表格数据质量差的问题。其重要性在于提供了一种在实际应用中（如医疗和金融）更有效生成高质量合成数据的方法。该方法具有模型无关性，增强了其普适性。

<details>
  <summary>Details</summary>

**Motivation:** 深度生成模型在合成表格数据生成方面表现出色，但其有效性依赖于大量训练数据，这在现实世界中往往是缺乏的。为了克服这一限制，本文旨在提出一种在数据量低的情况下提高数据质量的方法。

**Method:** 本文提出了一种新颖的方法，通过将人工归纳偏置明确地集成到生成过程中。该框架利用迁移学习和元学习技术来构建并将信息归纳偏置注入到深度生成模型中。论文评估了四种方法：预训练、模型平均、模型无关元学习（MAML）和域随机化搜索（DRS）。

**Result:** 实验结果表明，引入归纳偏置显著提高了性能。其中，迁移学习方法优于元学习，在Jensen-Shannon散度方面实现了高达60%的增益。

**Conclusion:** 该方法是模型无关的，在医疗保健和金融等领域尤其重要，因为这些领域对高质量合成数据的需求很高，但数据可用性通常有限。通过在数据稀缺场景下引入人工归纳偏置，可以显著提高合成表格数据的质量。

> **ai_Abstract:** 本研究提出了一种在数据稀缺场景下生成高质量合成表格数据的新方法。针对深度生成模型在数据量不足时效果受限的问题，该方法通过将人工归纳偏置明确集成到生成过程中。它利用迁移学习和元学习技术构建并注入有益的归纳偏置。实验评估了预训练、模型平均、MAML和DRS四种方法，结果显示引入归纳偏置能显著提升性能，尤其迁移学习方法优于元学习，在Jensen-Shannon散度上实现了高达60%的改进。该方法具有模型无关性，特别适用于医疗、金融等数据稀缺但对数据质量要求高的领域。

> **摘要翻译:** 尽管使用深度生成模型（DGMs）生成合成表格数据为数据稀缺和隐私问题提供了一个引人注目的解决方案，但其有效性依赖于大量训练数据的可用性，这在现实世界中往往是缺乏的。为了克服这一限制，我们提出了一种新颖的方法，将人工归纳偏置明确地集成到生成过程中，以提高低数据量下的数据质量。我们的框架利用迁移学习和元学习技术来构建并将信息归纳偏置注入到DGMs中。我们评估了四种方法（预训练、模型平均、模型无关元学习（MAML）和域随机化搜索（DRS））并分析了它们对生成文本质量的影响。实验结果表明，引入归纳偏置显著提高了性能，其中迁移学习方法优于元学习，在Jensen-Shannon散度方面实现了高达60%的增益。该方法是模型无关的，在医疗保健和金融等领域尤其重要，因为这些领域对高质量合成数据的需求很高，但数据可用性通常有限。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [695] [EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution](https://arxiv.org/abs/2507.23600)
> *EB-gMCR：基于能量的生成模型用于信号解混和多变量曲线分辨*

*Yu-Tang Chang, Shih-Fang Chen* | **Category: cs.LG, cs.CE, G.1.6; G.3; G.4; I.6.5** | **Updated: 2025-07-31**

**Keywords:** 信号解混, 多变量曲线分辨, 生成模型, 深度学习, 能量模型

**Comment:** 

> **TL;DR:** EB-gMCR是一种基于能量的深度学习生成模型，用于信号解混和多变量曲线分辨。它能自动发现最少组件集，解决了传统方法在组件数量未知和数据量大时的挑战，并在合成数据集上表现出色。

**AI_Comments:** EB-gMCR的创新之处在于将MCR重新概念化为生成过程，并引入了基于能量的深度学习框架来自动确定最佳组件数量。这解决了传统MCR方法在处理复杂或大规模数据集时面临的关键挑战，即需要预先指定组件数量的问题。其通过可微分门控网络进行组件选择的机制，以及易于集成化学先验的能力，使其在实际应用中具有高度的适应性和实用性，特别是在化学和生物领域。该方法在性能上显著优于传统方法，为大规模信号解混分析开辟了新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 信号解混分析在化学和生物研究中广泛应用。多变量曲线分辨（MCR）是信号解混的一个分支，用于分离混合化学信号。然而，传统的基于矩阵分解（MF）的MCR方法需要用户指定组件数量，且在数据集规模或组件数量增加时面临可伸缩性和可靠性挑战。

**Method:** 本研究将MCR重新表述为生成过程（gMCR），并引入了一种基于能量的深度学习求解器EB-gMCR。EB-gMCR从一个大型候选池（例如1024个光谱）开始，并使用可微分的门控网络来仅保留活跃组件，同时估计它们的浓度，从而自动发现能够忠实重建数据的最小组件集。

**Result:** 在包含多达256个潜在源的噪声合成数据集上，EB-gMCR的R^2保持在0.98以上，并且恢复的组件数量与真实值相差在5%以内；在较低噪声下，R^2达到0.99以上，组件估计几乎精确。额外的化学先验（如非负性或非线性混合）可以作为简单的插件函数引入，无需改变核心学习过程即可适应其他仪器或领域。

**Conclusion:** 通过结合高容量生成建模和硬组件选择，EB-gMCR为大规模信号解混分析（包括化学文库驱动的场景）提供了一条实用的途径。

> **ai_Abstract:** 本研究提出了一种名为EB-gMCR的新型基于能量的深度学习生成模型，用于信号解混和多变量曲线分辨（MCR）。该方法将MCR重新定义为生成过程，解决了传统MCR在组件数量未知和大规模数据处理上的挑战。EB-gMCR通过从大型候选池中自动选择最少有效组件来重建数据，并在合成数据集上表现出高精度和组件数量估计的鲁棒性。它还允许轻松集成化学先验，为大规模信号解混提供了实用方案。

> **摘要翻译:** 信号解混分析将数据分解为基本模式，广泛应用于化学和生物研究。多变量曲线分辨（MCR）是信号解混的一个分支，它将混合化学信号分离为基本模式（组分）及其浓度，在理解组成方面发挥着关键作用。经典的MCR通常被构建为矩阵分解（MF），需要用户指定组分数量，这在真实数据中通常是未知的。随着数据集大小或组分数量的增加，基于MF的MCR的可伸缩性和可靠性面临重大挑战。本研究将MCR重新表述为生成过程（gMCR），并引入了一种基于能量的深度学习求解器EB-gMCR，该求解器能够自动发现能够忠实重建数据的最小组分集。EB-gMCR从一个大型候选池（例如1024个光谱）开始，并采用可微分的门控网络来仅保留活跃组分，同时估计它们的浓度。在包含多达256个潜在源的噪声合成数据集上，EB-gMCR的R^2保持在0.98以上，并且恢复的组分数量与真实值相差在5%以内；在较低噪声下，它实现了R^2 >= 0.99，组分估计几乎精确。额外的化学先验，例如非负性或非线性混合，可以作为简单的插件函数引入，从而无需改变核心学习过程即可适应其他仪器或领域。通过结合高容量生成建模和硬组分选择，EB-gMCR为大规模信号解混分析（包括化学文库驱动的场景）提供了一条实用的途径。源代码可在https://github.com/b05611038/ebgmcr_solver获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [726] [FLOSS: Federated Learning with Opt-Out and Straggler Support](https://arxiv.org/abs/2507.23115)
> *FLOSS：支持选择退出和掉队者的联邦学习*

*David J Goetze, Dahlia J Felten, Jeannie R Albrecht, Rohit Bhattacharya* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 联邦学习, 数据隐私, 选择退出, 掉队者, 缺失数据

**Comment:** 5 pages

> **TL;DR:** 现有联邦学习未考虑用户选择退出和掉队者导致的缺失数据，FLOSS系统旨在缓解这些缺失数据对模型性能的影响。

**AI_Comments:** 这项工作创新性地关注了联邦学习中用户选择退出和设备掉队导致的数据缺失问题，这是一个在实际部署中非常重要的挑战。通过提出FLOSS系统来缓解这些影响，该研究为提高联邦学习在复杂现实环境中的鲁棒性和性能提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的联邦学习隐私保护工作主要关注同意共享数据的用户。然而，现代数据隐私协议允许用户选择不共享数据，加上设备能力差异导致的掉队者，会产生各种来源的缺失数据，从而引入偏差并降低模型性能。

**Method:** 论文提出了FLOSS系统，该系统旨在缓解在掉队者和用户选择退出的情况下，缺失数据对联邦学习的影响。

**Result:** 论文通过模拟实验经验性地证明了FLOSS系统的性能。

**Conclusion:** FLOSS系统能够有效缓解用户选择退出和掉队者导致的缺失数据对联邦学习性能的影响。

> **ai_Abstract:** 本文提出了FLOSS系统，旨在解决联邦学习中由用户选择退出和设备掉队导致的缺失数据问题。这些缺失数据会导致模型偏差并降低性能。FLOSS系统通过模拟实验证明了其在缓解这些不利影响方面的有效性。

> **摘要翻译:** 联邦学习中数据隐私的先前工作侧重于针对同意共享数据以进行训练的用户的隐私保护操作。然而，现代数据隐私协议也赋予用户在需要时选择退出数据共享的权利。当这种情况与异构设备能力导致的掉队者结合时，结果是从各种来源丢失数据，这会引入偏差并降低模型性能。在本文中，我们提出了FLOSS，一个旨在缓解在掉队者和用户选择退出情况下此类缺失数据对联邦学习影响的系统，并通过模拟实验经验性地证明了其性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [737] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
> *评估COVID-19特征对比特币收益预测的贡献：基于LightGBM和遗传优化的方法*

*Imen Mahmoud, Andrei Velichko* | **Category: cs.LG, cs.AI, econ.GN, q-fin.EC** | **Updated: 2025-07-31**

**Keywords:** 比特币收益预测, COVID-19, LightGBM, 遗传算法, 特征贡献

**Comment:** 22 pages, 5 figures

> **TL;DR:** 本研究提出结合LightGBM和遗传算法的方法，评估COVID-19指标对比特币收益预测的贡献，发现COVID-19数据显著提高了预测准确性，特别是疫苗接种率。

**AI_Comments:** 该研究的创新之处在于将公共卫生数据（特别是COVID-19指标）纳入金融市场预测，为理解宏观事件对加密货币市场的影响提供了新视角。其方法论结合了强大的机器学习模型LightGBM和优化算法遗传算法，并通过严谨的统计评估验证了结果的稳健性。这对于在不确定时期进行投资决策和政策制定具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 确定纳入疫情相关的健康数据是否能显著提高比特币收益预测的准确性。

**Method:** 提出了一种结合LightGBM回归模型和遗传算法（GA）优化的方法。构建了包含每日比特币收益和COVID-19指标（疫苗接种率、住院率、检测统计数据）的综合数据集。使用GA对包含和不包含COVID-19特征的预测模型进行优化，并进行31次独立运行。通过分布重叠和Mann-Whitney U检验统计比较性能指标（R2、RMSE、MAE）。使用置换特征重要性（PFI）分析量化个体特征贡献。

**Result:** COVID-19指标显著提高了模型性能，尤其是在捕捉极端市场波动方面（R2增加了40%，RMSE降低了2%，两者均具有高度统计显著性）。在COVID-19特征中，疫苗接种指标，特别是完全接种个体的75百分位，是主要的预测因子。

**Conclusion:** 该方法通过整合公共卫生信号，扩展了现有的金融分析工具，为投资者和政策制定者提供了更精确的指标，以应对系统性危机期间的市场不确定性。

> **ai_Abstract:** 本研究提出一种结合LightGBM和遗传算法的新方法，旨在评估COVID-19相关指标对比特币收益预测的贡献。通过构建包含每日比特币收益和COVID-19数据的综合数据集，并优化模型，研究发现纳入COVID-19指标显著提高了预测准确性，尤其在极端市场波动中表现更佳（R2提升40%，RMSE降低2%），其中疫苗接种率是关键预测因子。该方法为金融分析提供了新的公共卫生信号视角，有助于投资者和政策制定者应对市场不确定性。

> **摘要翻译:** 本研究提出了一种新颖的方法框架，整合了LightGBM回归模型和遗传算法（GA）优化，以系统地评估COVID-19相关指标对比特币收益预测的贡献。主要目标不仅仅是预测比特币收益，而是确定纳入疫情相关的健康数据是否能显著提高预测准确性。构建了一个包含每日比特币收益和COVID-19指标（疫苗接种率、住院率、检测统计数据）的综合数据集。使用GA对包含和不包含COVID-19特征的预测模型进行优化，并进行31次独立运行，从而实现稳健的统计评估。通过分布重叠和Mann-Whitney U检验统计比较了性能指标（R2、RMSE、MAE）。置换特征重要性（PFI）分析量化了个体特征贡献。结果表明，COVID-19指标显著提高了模型性能，特别是在捕捉极端市场波动方面（R2增加了40%，RMSE降低了2%，两者均具有高度统计显著性）。在COVID-19特征中，疫苗接种指标，特别是完全接种个体的75百分位，是主要的预测因子。所提出的方法通过整合公共卫生信号，扩展了现有的金融分析工具，为投资者和政策制定者提供了更精确的指标，以应对系统性危机期间的市场不确定性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [761] [FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations](https://arxiv.org/abs/2507.23154)
> *FuseTen：一种基于时空卫星观测的每日10米地表温度估计生成模型*

*Sofiane Bouaziz, Adel Hafiane, Raphael Canals, Rachid Nedjai* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 地表温度, 生成模型, 卫星观测, 时空融合, 遥感

**Comment:** Accepted in the 2025 International Conference on Machine Intelligence
  for GeoAnalytics and Remote Sensing (MIGARS)

> **TL;DR:** FuseTen是一种新颖的生成模型，通过融合多源卫星数据，首次实现了每日10米高分辨率地表温度的估计，并在定量和视觉方面显著优于现有基线方法。

**AI_Comments:** FuseTen的创新之处在于其首次将生成模型应用于多源卫星数据的融合，以解决地表温度估计中空间和时间分辨率的固有矛盾。其引入注意力机制和PatchGAN判别器有助于提升生成结果的真实性和准确性。这项工作对于城市热岛效应、干旱监测和土地退化研究具有重要意义，提供了一种获取高分辨率每日LST数据的有效工具。

<details>
  <summary>Details</summary>

**Motivation:** 城市热浪、干旱和土地退化是气候变化背景下日益严峻的挑战。准确的地表温度（LST）时空信息对于研究这些现象至关重要。然而，卫星平台在空间和时间分辨率之间存在固有的权衡，这限制了获取高分辨率每日LST的能力。

**Method:** 本文提出了FuseTen，一种新颖的生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成每日10米空间分辨率的地表温度（LST）数据。FuseTen采用基于物理原理的平均监督策略训练生成架构，并在融合过程中整合了注意力模块和归一化模块，同时使用PatchGAN判别器来确保真实感。

**Result:** 实验结果显示，FuseTen在多个日期上均优于线性基线方法，在定量指标上平均提高了32.06%，在视觉保真度上平均提高了31.42%。

**Conclusion:** 据作者所知，FuseTen是第一个能够生成如此精细空间分辨率（10米）的每日地表温度估计的非线性方法，为地表温度观测提供了重要进展。

> **ai_Abstract:** FuseTen是一种新颖的生成模型，旨在解决卫星地表温度（LST）数据在空间和时间分辨率上的权衡问题。该模型通过融合Sentinel-2、Landsat 8和Terra MODIS的多源卫星观测数据，生成每日10米高分辨率的LST估计。FuseTen采用生成对抗网络（GAN）架构，结合了注意力机制、归一化模块和PatchGAN判别器，并以物理原理为基础进行监督训练。实验证明，FuseTen在定量和视觉效果上均显著优于传统线性方法，是首个实现如此高分辨率每日LST估计的非线性方法。

> **摘要翻译:** 城市热浪、干旱和土地退化是气候变化背景下日益紧迫和增长的挑战。研究它们的一种有价值的方法需要准确的地表条件时空信息。地表温度（LST）是评估和理解这些现象最重要的变量之一，它来源于卫星，提供了地球表面热状态的基本信息。然而，卫星平台在空间和时间分辨率之间存在固有的权衡。为了弥补这一差距，我们提出了FuseTen，一个新颖的生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成每日10米空间分辨率的地表温度观测。FuseTen采用基于物理原理的平均监督策略训练生成架构。它在融合过程中整合了注意力模块和归一化模块，并使用PatchGAN判别器来增强真实感。跨多个日期的实验表明，FuseTen优于线性基线方法，在定量指标上平均提高了32.06%，在视觉保真度上平均提高了31.42%。据我们所知，这是第一个生成如此精细空间分辨率的每日地表温度估计的非线性方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [772] [Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models](https://arxiv.org/abs/2507.22766)
> *传感分选系统工艺参数的贝叶斯优化，使用高斯过程作为代理模型*

*Felix Kronenwett, Georg Maier, Thomas Längle* | **Category: cs.LG, cs.AI, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 贝叶斯优化, 传感分选系统, 高斯过程, 工艺参数优化, 代理模型

**Comment:** Accepted at the 30th IEEE International Conference on Emerging
  Technologies and Factory Automation (ETFA)

> **TL;DR:** 本文提出了一种基于贝叶斯优化和高斯过程代理模型的方法，用于优化、监控和调整传感分选系统的工艺参数，以减少实验次数并考虑不确定性。

**AI_Comments:** 这篇论文的创新点在于将贝叶斯优化与高斯过程代理模型相结合，应用于传感分选系统的工艺参数优化，有效解决了传统方法中频繁验证和调整的效率问题。通过考虑不确定性和多目标优化，提高了优化的鲁棒性和实用性，对于工业自动化和过程控制领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传感分选系统需要根据材料特性、系统尺寸和所需分选精度持续调整工艺参数，但由于要求和物料流组成的变化，需要频繁验证和重新调整，这促使开发一种更高效、能考虑不确定性的优化方法。

**Method:** 该方法基于贝叶斯优化，使用高斯过程回归模型作为代理模型来优化、循环监控和调整传感分选系统的工艺参数。它旨在最小化所需实验次数，同时考虑两个可能的优化目标（基于两种物料输出流的要求），并考虑模型计算中分选精度的不确定性。

**Result:** 该方法已使用三个示例工艺参数进行了评估。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种针对传感分选系统工艺参数的优化、监控和调整方法。该方法利用贝叶斯优化，并以高斯过程回归模型作为代理模型，旨在根据系统行为的具体要求和不确定性进行优化。其主要优势在于能显著减少所需的实验次数，同时考虑两种物料输出流的优化目标，并纳入分选精度中的不确定性。该方法已通过三个示例工艺参数进行了评估。

> **摘要翻译:** 传感分选系统能够将物料流物理分离成两部分。分选决策基于所用传感器的图像数据评估，并使用执行器进行。根据物料流的特性、系统的尺寸和所需的分选精度，必须设置各种工艺参数。然而，由于要求和物料流组成的变化，需要持续的验证和重新调整。在本文中，我们介绍了一种优化、循环监控和调整传感分选系统工艺参数的方法。基于贝叶斯优化，高斯过程回归模型被用作代理模型，以实现系统行为的特定要求及其包含的不确定性。该方法最大限度地减少了必要的实验次数，同时根据对两种物料输出流的要求，同时考虑了两个可能的优化目标。此外，在模型计算中确定分选精度时考虑了不确定性。我们用三个示例工艺参数评估了该方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [779] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
> *应力感知弹性神经网络训练*

*Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicole, Stefano Ghidoni, Nassir Navab* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 应力感知学习, 弹性训练, 塑性变形优化器, 鲁棒性, 泛化能力

**Comment:** 16 pages, 11 figures

> **TL;DR:** 引入应力感知学习，通过注入自适应噪声帮助神经网络在训练停滞时逃离尖锐局部最优，提升鲁棒性和泛化能力。

**AI_Comments:** 这项工作通过引入“应力感知”的概念并将其与材料科学中的变形理论相结合，为神经网络训练提供了一种新颖的弹性优化方法。其创新点在于动态地在优化过程中注入噪声以应对训练停滞，从而有效避免尖锐局部最优并提升模型泛化能力。该方法在实际应用中具有重要意义，因为它能在不显著增加计算成本的情况下提高模型的稳健性。

<details>
  <summary>Details</summary>

**Motivation:** 解决深度神经网络在训练中遇到的优化困难，使其在稳定或不确定动态下能动态调整优化行为，从而提升训练的鲁棒性和泛化能力。

**Method:** 提出“应力感知学习”范式，灵感来源于材料科学中的临时（弹性）和永久（塑性）变形概念。具体实现是“塑性变形优化器”，当内部应力信号（训练损失和准确率停滞）表明优化困难时，该机制会向模型参数注入自适应噪声，使模型能够逃离尖锐的局部最优并收敛到更平坦、更具泛化性的损失景观区域。

**Result:** 在六种架构、四种优化器和七个视觉基准上的实验表明，该方法在计算开销极小的情况下，提高了模型的鲁棒性和泛化能力。

**Conclusion:** 通过引入应力感知学习和塑性变形优化器，模型能够在训练停滞时有效调整优化行为，逃离尖锐局部最优，从而在计算开销极小的情况下显著提升神经网络的鲁棒性和泛化能力。

> **ai_Abstract:** 本文提出了一种名为“应力感知学习”的弹性神经网络训练新范式，其核心是“塑性变形优化器”。该优化器受材料疲劳启发，在训练损失和准确率停滞时，通过注入自适应噪声来帮助深度神经网络动态调整优化过程，使其能够逃离尖锐的局部最优，并收敛到更平坦、泛化能力更强的损失景观区域。实验证明，该方法在多种架构和基准上显著提升了模型的鲁棒性和泛化能力，且计算开销极小。

> **摘要翻译:** 本文介绍了应力感知学习，这是一种弹性神经网络训练范式，其中深度神经网络根据材料科学中结构疲劳启发的临时（弹性）和永久（塑性）变形概念，动态调整其优化行为——无论是在稳定的训练机制下还是在不确定的动态设置中。为了实例化这一概念，我们提出了塑性变形优化器，这是一种应力感知机制，当内部应力信号（反映训练损失和准确率停滞）表明持续的优化困难时，它会向模型参数注入自适应噪声。这使得模型能够逃离尖锐的局部最优，并收敛到损失景观中更平坦、更具泛化性的区域。在六种架构、四种优化器和七个视觉基准上的实验表明，在计算开销极小的情况下，鲁棒性和泛化能力得到改善。代码和3D可视化将在GitHub上提供：https://github.com/Stress-Aware-Learning/SAL。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [782] [Optimal and Near-Optimal Adaptive Vector Quantization](https://arxiv.org/abs/2402.03158)
> *最佳和近乎最佳的自适应向量量化*

*Ran Ben-Basat, Yaniv Ben-Itzhak, Michael Mitzenmacher, Shay Vargaftik* | **Category: cs.LG, cs.DS, cs.IT, cs.NI, math.IT** | **Updated: 2025-07-31**

**Keywords:** 自适应向量量化, 量化, 机器学习, 优化, 算法

**Comment:** 

> **TL;DR:** 本文提出了新的算法，解决了自适应向量量化（AVQ）在运行时和内存上的不可行性问题，实现了更优的时间和空间复杂度，从而有望在机器学习中更广泛地应用AVQ。

**AI_Comments:** 这篇论文通过提出计算效率更高的算法，解决了自适应向量量化（AVQ）长期存在的实用性问题。其创新之处在于在保持最优解的同时，大幅降低了时间和空间复杂度，并提供了针对大规模数据的近最优解，这对于推动AVQ在实际机器学习场景中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 最佳自适应量化方法在运行时和内存需求方面被认为是不可行的，这限制了其在机器学习应用中的广泛使用，尽管它是最准确的量化形式。

**Method:** 重新审视自适应向量量化（AVQ）问题，并提出了能够找到最优解且具有渐近改进的时间和空间复杂度的算法。此外，还为大型输入提供了一种更快的近乎最优的算法。

**Result:** 实验表明，所提出的算法有望使自适应向量量化（AVQ）在各种机器学习应用中得到更广泛的使用。

**Conclusion:** 所提出的算法克服了传统最优自适应向量量化方法的计算障碍，使其在机器学习领域中成为一个更可行且有前景的优化工具。

> **ai_Abstract:** 本文针对机器学习中关键的自适应向量量化（AVQ）问题，解决了其因高运行时和内存需求而导致的不可行性。作者提出了新的算法，这些算法在时间复杂度和空间复杂度上都有渐近改进，并且还开发了一种针对大型输入的近乎最优的快速算法。实验结果表明，这些新算法有望显著扩展AVQ在多种机器学习应用中的实际应用范围。

> **摘要翻译:** 量化是许多机器学习用例中的一项基本优化，包括压缩梯度、模型权重和激活以及数据集。最准确的量化形式是自适应的，其中误差相对于给定输入最小化，而不是针对最坏情况进行优化。然而，最佳自适应量化方法在运行时和内存需求方面被认为是不可行的。
我们重新审视了自适应向量量化（AVQ）问题，并提出了能够找到最优解且具有渐近改进的时间和空间复杂度的算法。我们还为大型输入提供了一种更快的近乎最优的算法。我们的实验表明，我们的算法可能会为在各种机器学习应用中更广泛地使用AVQ打开大门。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [786] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
> *DiSC-Med：基于扩散的语义通信，用于鲁棒的医学图像传输*

*Fupei Guo, Hao Zheng, Xiang Zhang, Li Chen, Yue Wang, Songyang Zhang* | **Category: cs.LG, eess.IV** | **Updated: 2025-07-31**

**Keywords:** 语义通信, 医学图像传输, 扩散模型, 智能健康, 带宽效率

**Comment:** To appear in 2025 IEEE Global Communications Conference (Globecom)

> **TL;DR:** DiSC-Med是一种基于扩散的语义通信框架，专为在噪声信道中高效、鲁棒地传输医学图像而设计，通过语义信息捕获和增强的压缩去噪实现优异的性能。

**AI_Comments:** DiSC-Med的创新之处在于将扩散模型引入语义通信，并针对医学图像传输的特点进行了优化，特别是其能够捕获关键语义信息而非简单像素传输，显著提升了在恶劣信道下的传输效率和鲁棒性。这对于远程医疗领域具有重要意义，有望克服现有技术在带宽和噪声方面的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现远程医疗的及时有效响应，通过有限带宽的噪声信道高效传输医疗数据是一个关键挑战。

**Method:** 本文提出了一种名为DiSC-Med的新型基于扩散的语义通信框架，用于医学图像传输。该框架开发了医用增强型压缩块和去噪块，分别用于提高带宽效率和鲁棒性。与传统的像素级通信框架不同，DiSC-Med能够捕获关键语义信息。

**Result:** DiSC-Med在噪声信道下实现了卓越的重建性能和超高带宽效率。在真实世界医学数据集上的广泛实验验证了该框架的有效性。

**Conclusion:** DiSC-Med框架在鲁棒和高效的远程医疗应用中展现出巨大潜力。

> **ai_Abstract:** DiSC-Med是一种新颖的基于扩散的语义通信框架，旨在解决远程医疗中医学图像在噪声和带宽受限信道下高效鲁棒传输的挑战。该框架通过引入医用增强型压缩和去噪模块，能够捕获关键语义信息，从而在保持超高带宽效率的同时，实现优于传统像素级方法的图像重建性能。实验结果证明了其在实际医疗应用中的有效性和潜力。

> **摘要翻译:** 人工智能的快速发展推动了智能健康与下一代无线通信技术相结合，激发了远程诊断和干预等令人兴奋的应用。为了实现远程医疗的及时有效响应，通过有限带宽的噪声信道高效传输医疗数据成为一个关键挑战。在这项工作中，我们提出了一种新颖的基于扩散的语义通信框架，即DiSC-Med，用于医学图像传输，其中开发了医用增强型压缩和去噪模块，分别用于提高带宽效率和鲁棒性。与传统的像素级通信框架不同，我们提出的DiSC-Med能够捕获关键语义信息，并在噪声信道下以超高带宽效率实现卓越的重建性能。在真实世界医学数据集上的广泛实验验证了我们框架的有效性，展示了其在鲁棒和高效远程医疗应用中的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [791] [How Can I Publish My LLM Benchmark Without Giving the True Answers Away?](https://arxiv.org/abs/2505.18102)
> *如何在不泄露真实答案的情况下发布我的LLM基准测试？*

*Takashi Ishida, Thanawat Lodkaew, Ikko Yamane* | **Category: cs.LG, cs.AI, cs.CL, stat.ME** | **Updated: 2025-07-31**

**Keywords:** LLM基准测试, 数据污染, 贝叶斯准确率, 答案随机性, 模型评估

**Comment:** Extended version of the paper presented as an Oral at the ICML 2025
  Workshop on the Impact of Memorization on Trustworthy Foundation Models

> **TL;DR:** 本文提出了一种新的方法来发布大型语言模型（LLM）基准测试，通过注入答案随机性来防止数据泄露和检测数据污染，同时允许公开评估。

**AI_Comments:** 这项工作提出了一种新颖且实用的方法来解决LLM基准测试中的核心挑战——数据污染和真实答案泄露。其创新点在于通过注入答案随机性来构建一个“防污染”的基准测试，并利用贝叶斯准确率作为检测污染的阈值。这对于维护LLM评估的公平性和有效性至关重要，特别是随着LLM能力的增强和训练数据来源的复杂化，其重要性日益凸显。该方法为开放式但安全的基准测试发布提供了一条可行的路径。

<details>
  <summary>Details</summary>

**Motivation:** 发布大型语言模型（LLM）基准测试存在污染未来LLM的风险，即基准测试可能被无意或有意地用于训练或选择模型。现有的缓解策略（如保持基准测试私有并让参与者提交模型）需要对单一组织信任，并且仍然允许通过重复查询进行测试集过拟合。

**Method:** 我们提出了一种在不完全披露真实答案的情况下发布基准测试的方法，同时仍能公开评估LLM。主要思想是通过准备多个逻辑上正确的答案，并仅将其中一个作为解决方案包含在基准测试中来注入答案随机性。这降低了基准测试的最佳可能准确率（即贝叶斯准确率）。

**Result:** 该方法不仅有助于避免泄露真实答案，还能作为检测数据污染的测试。如果模型尽管有预期但仍超过了贝叶斯准确率，这是数据污染的强烈信号。实验证据表明，我们的方法可以在广泛的基准测试、模型和训练方法上准确检测数据污染。

**Conclusion:** 本文提出了一种通过在基准测试答案中注入随机性来有效防止大型语言模型基准测试数据泄露的方法，并且能够准确检测数据污染，即使是全能模型也不应超过贝叶斯准确率。

> **ai_Abstract:** 本文提出了一种创新的大型语言模型（LLM）基准测试发布方法，旨在解决数据污染和测试集过拟合问题。通过在基准测试答案中注入随机性（提供多个正确答案，只包含一个作为标准答案），该方法既能避免泄露真实答案，又能通过监测模型表现是否异常超过贝叶斯准确率来有效检测数据污染。实验证明了该方法在多种基准、模型和训练方法上的准确性。

> **摘要翻译:** 在互联网上发布大型语言模型（LLM）基准测试存在污染未来LLM的风险：基准测试可能被无意（或有意）地用于训练或选择模型。一种常见的缓解措施是保持基准测试私有，并让参与者向组织者提交他们的模型或预测。然而，这种策略需要信任单一组织，并且仍然允许通过重复查询进行测试集过拟合。为了克服这个问题，我们提出了一种在不完全披露问题真实答案的情况下发布基准测试的方法，同时仍能保持公开评估LLM的能力。我们的主要思想是通过准备几个逻辑上正确的答案，并仅将其中一个作为解决方案包含在基准测试中来注入答案随机性。这降低了基准测试的最佳可能准确率，即贝叶斯准确率。这不仅有助于我们不泄露真实答案，而且这种方法还提供了一种检测数据污染的测试。原则上，即使是完全有能力的模型也不应超过贝叶斯准确率。如果一个模型尽管有这种预期但仍超过了这个上限，这就是数据污染的强烈信号。我们提供了实验证据，表明我们的方法可以在广泛的基准测试、模型和训练方法上准确检测数据污染。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [792] [NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions](https://arxiv.org/abs/2507.23186)
> *NaN传播：一种用于黑盒计算函数中稀疏性检测的新方法*

*Peter Sharpe* | **Category: cs.LG, cs.PL** | **Updated: 2025-08-01**

**Keywords:** NaN传播, 稀疏性检测, 黑盒函数, 梯度计算, IEEE 754

**Comment:** 

> **TL;DR:** NaN传播是一种利用IEEE 754 NaN特性来检测黑盒函数稀疏性的新方法，它能有效避免现有方法的假阴性问题，并提升梯度计算速度。

**AI_Comments:** NaN传播方法的核心创新在于巧妙地利用了IEEE 754浮点标准中NaN值的“污染”特性来追踪数据依赖性，这提供了一种新颖且鲁棒的黑盒稀疏性检测途径。其重要性在于解决了传统有限差分方法在黑盒场景下易产生假阴性导致梯度计算错误的问题，显著提高了梯度计算的准确性和效率，这对于优化工作流中的瓶瓶颈问题具有重要实践价值。该方法无需修改现有代码的特点，极大地提升了其在实际工程应用中的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 在数值计算函数梯度时，稀疏性检测能通过雅可比着色和压缩显著加速计算。然而，黑盒函数的稀疏性检测技术有限，现有的基于有限差分的方法因巧合的零梯度而产生假阴性，这会导致梯度计算错误且难以诊断。

**Method:** NaN传播方法利用IEEE 754非数值（NaN）的普遍污染特性，通过浮点数值计算追踪输入-输出依赖关系。该方法通过系统地用NaN污染输入并观察哪些输出变为NaN来重建保守的稀疏模式，从而消除了假阴性的主要来源。此外，它还利用NaN负载编码等高级策略实现比线性时间复杂度更快的速度，并提出了缓解工程应用中常见分支代码执行挑战的算法。

**Result:** 该方法在一个航空航天机翼重量模型上实现了1.52倍的加速，并发现了数十个传统方法遗漏的依赖关系。这在优化工作流程中是显著的实际改进。

**Conclusion:** NaN传播是一种有效且实用的黑盒函数稀疏性检测方法，它通过利用IEEE 754标准特性，解决了传统方法中假阴性的问题，提高了梯度计算的准确性和效率，并且无需修改现有代码，具有跨语言和数学库的通用性。

> **ai_Abstract:** 本文提出了一种名为NaN传播的新型方法，用于在黑盒计算函数中进行稀疏性检测。针对现有基于有限差分的方法在梯度计算中容易产生假阴性并导致错误的问题，NaN传播利用IEEE 754 NaN值的普遍污染特性，通过系统地污染输入并观察输出的NaN状态来追踪输入-输出依赖关系，从而重建保守的稀疏模式。该方法有效消除了假阴性，并在航空航天模型上实现了1.52倍的加速，发现了传统方法遗漏的依赖项。该技术兼容IEEE 754标准，无需修改现有代码即可跨语言和库使用，并且通过高级策略可实现更快的检测速度。

> **摘要翻译:** 当数值评估函数的梯度时，稀疏性检测可以通过雅可比着色和压缩显著提高计算速度。然而，黑盒函数的稀疏性检测技术有限，并且现有的基于有限差分的方法由于偶然的零梯度而导致假阴性。这些假阴性会悄无声息地破坏梯度计算，导致难以诊断的错误。我们引入了NaN传播，它利用IEEE 754非数值的普遍污染特性，通过浮点数值计算追踪输入-输出依赖关系。通过系统地用NaN污染输入并观察哪些输出变为NaN，该方法重建了保守的稀疏模式，消除了假阴性的一大来源。我们在一个航空航天机翼重量模型上演示了这种方法，实现了1.52倍的加速，同时发现了传统方法遗漏的数十个依赖关系——这是一个显著的实际改进，因为梯度计算通常是优化工作流程中的瓶颈。该技术利用IEEE 754兼容性，无需修改现有黑盒代码即可跨编程语言和数学库工作。此外，通过直接位操作进行NaN负载编码等高级策略可以实现比线性时间复杂度更快的速度，从而在现有黑盒稀疏性检测方法上实现速度提升。还提出了实用的算法来缓解工程应用中常见的分支代码执行带来的挑战。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [819] [MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization](https://arxiv.org/abs/2412.12098)
> *MaxInfoRL：通过信息增益最大化提升强化学习中的探索能力*

*Bhavya Sukhija, Stelian Coros, Andreas Krause, Pieter Abbeel, Carmelo Sferrazza* | **Category: cs.LG, cs.AI, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 探索, 信息增益, 内在奖励, MaxInfoRL

**Comment:** 

> **TL;DR:** MaxInfoRL是一个强化学习框架，通过最大化信息增益来指导探索，有效平衡内在和外在探索，并在困难探索问题中表现出色。

**AI_Comments:** MaxInfoRL的创新之处在于其通过最大化信息增益来指导探索的策略，这提供了一种更原则性的方式来平衡强化学习中的内在和外在探索，解决了传统方法中平衡挑战和任务依赖性的问题。其在多臂老虎机和复杂RL任务中的表现证明了其有效性和通用性。

<details>
  <summary>Details</summary>

**Motivation:** 大多数强化学习算法使用无方向探索，或通过内在奖励进行有方向探索，但有效地平衡任务奖励和内在奖励具有挑战性且通常依赖于特定任务。

**Method:** 本文引入了一个名为MaxInfoRL的框架，用于平衡内在和外在探索。MaxInfoRL通过最大化关于潜在任务的信息增益等内在奖励，将探索引向信息丰富的转换。当与玻尔兹曼探索结合时，该方法自然地权衡了价值函数最大化与状态、奖励和动作熵的最大化。

**Result:** 该方法在多臂老虎机的简化设置中实现了次线性遗憾。将其应用于连续状态-动作空间的各种离策略无模型强化学习方法，产生了在困难探索问题和视觉控制等复杂场景中表现出卓越性能的新算法。

**Conclusion:** MaxInfoRL提供了一种通用的强化学习探索框架，通过信息增益最大化有效平衡内在和外在探索，在多臂老虎机和复杂RL任务中均展现出优越性能。

> **ai_Abstract:** MaxInfoRL是一个新的强化学习框架，旨在通过最大化关于潜在任务的信息增益来引导探索，从而更好地平衡内在和外在探索。该方法与玻尔兹曼探索结合，自然地权衡了价值函数最大化与状态、奖励和动作熵的平衡。实验表明，MaxInfoRL在多臂老虎机问题中实现了次线性遗憾，并应用于连续状态-动作空间的离策略无模型RL方法时，在困难探索问题和视觉控制等复杂场景中表现出优越性能。

> **摘要翻译:** 强化学习（RL）算法旨在平衡利用当前最佳策略与探索可能带来更高奖励的新选项。大多数常见的RL算法使用无方向探索，即选择随机动作序列。探索也可以通过内在奖励进行指导，例如好奇心或模型认知不确定性。然而，有效平衡任务和内在奖励具有挑战性，并且通常依赖于特定任务。在这项工作中，我们引入了一个框架MaxInfoRL，用于平衡内在和外在探索。MaxInfoRL通过最大化内在奖励（例如关于潜在任务的信息增益）来引导探索走向信息丰富的转换。当与玻尔兹曼探索结合时，这种方法自然地权衡了价值函数最大化与状态、奖励和动作熵的最大化。我们展示了我们的方法在多臂老虎机的简化设置中实现了次线性遗憾。然后，我们将这种通用公式应用于连续状态-动作空间的各种离策略无模型RL方法，产生了在困难探索问题和视觉控制等复杂场景中表现出卓越性能的新算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [821] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
> *StackLiverNet：一种用于准确和可解释的肝病检测的新型堆叠集成模型*

*Md. Ehsanul Haque, S. M. Jahidul Islam, Shakil Mia, Rumana Sharmin, Ashikuzzaman, Md Samir Morshed, Md. Tahmidul Huque* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 肝病检测, 堆叠集成, 可解释人工智能, 机器学习, 诊断

**Comment:** Accepted and presented paper of THE 16th INTERNATIONAL IEEE
  CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT)
  INDIA

> **TL;DR:** StackLiverNet是一个新的堆叠集成模型，用于准确、快速、可解释地检测肝病，解决了现有方法准确性差、可解释性低和计算成本高的问题，并在测试集上取得了99.89%的准确率。

**AI_Comments:** StackLiverNet的创新在于其堆叠集成架构结合了先进的预处理和多种可解释性方法，显著提高了肝病检测的准确性、速度和临床可用性。其高准确率和低计算成本是重要优势，而LIME、SHAP和Morris方法的应用则极大地增强了模型在医疗领域的透明度和信任度。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习和深度学习模型在肝病分类中存在误分类率高、可解释性差、计算开销大以及缺乏良好预处理策略等问题。

**Method:** 本研究引入了StackLiverNet，一个为肝病检测任务量身定制的可解释堆叠集成模型。该框架使用先进的数据预处理和特征选择技术，并通过随机欠采样处理类别不平衡。StackLiverNet是多个超参数优化的基础分类器的集成，其互补优势通过LightGBM元模型得以利用。此外，应用局部可解释模型无关解释（LIME）生成个体预测的透明解释，并使用SHAP通过其对预测的全局贡献来对特征进行排名，而Morris方法通过敏感性分析确认了最具影响力的特征。

**Result:** 所提供的模型表现出卓越的性能，测试准确率为99.89%，Cohen Kappa为0.9974，AUC为0.9993，仅有5次错误分类，并且训练和推理速度高效（训练时间4.2783秒，推理时间0.1106秒），适用于临床实践。LIME的应用揭示了高浓度的碱性磷酸酶和中等水平的SGOT是肝病的重要观察指标。SHAP和Morris方法也确认了最有影响力的特征。

**Conclusion:** StackLiverNet提供了一种高效、准确且可解释的肝病检测方案，能够克服现有方法的缺点，并适用于临床实践。

> **ai_Abstract:** 本文提出StackLiverNet，一个新型堆叠集成模型，旨在解决现有肝病检测方法在准确性、可解释性和计算效率上的不足。该模型整合了先进的数据预处理、特征选择和随机欠采样技术，并结合多个超参数优化的基础分类器与LightGBM元模型。实验结果显示，StackLiverNet在肝病检测中表现出卓越的性能，测试准确率达99.89%，且训练和推理速度快，适用于临床实践。此外，通过LIME、SHAP和Morris方法增强了模型的可解释性，识别出重要的生物标志物。

> **摘要翻译:** 肝脏疾病是世界上一个严重的健康问题，需要精确及时的诊断以提高患者的生存机会。目前的文献中实施了大量的机器学习和深度学习模型来对肝脏疾病进行分类，但其中大多数都存在一些问题，例如误分类错误率高、可解释性差、计算开销大以及缺乏良好的预处理策略。为了解决这些缺点，本研究引入了StackLiverNet；一个专为肝脏疾病检测任务定制的可解释堆叠集成模型。该框架使用先进的数据预处理和特征选择技术，以提高模型的鲁棒性和预测能力。执行随机欠采样以处理类别不平衡并使训练平衡。StackLiverNet是几个超参数优化的基础分类器的集成，其互补优势通过LightGBM元模型得以利用。所提供的模型表现出卓越的性能，测试准确率为99.89%，Cohen Kappa为0.9974，AUC为0.9993，仅有5次错误分类，并且训练和推理速度高效，适用于临床实践（训练时间4.2783秒，推理时间0.1106秒）。此外，应用局部可解释模型无关解释（LIME）来生成个体预测的透明解释，揭示高浓度的碱性磷酸酶和中等水平的SGOT是肝脏疾病的重要观察结果。此外，SHAP用于根据其对预测的全局贡献来对特征进行排名，而Morris方法通过敏感性分析确认了最具影响力的特征。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [856] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
> *稳定和可解释神经网络计算的结构化变换*

*Saleh Nikooroo, Thomas Engel* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** 结构化变换, 神经网络, 稳定性, 可解释性, 训练动态

**Comment:** 

> **TL;DR:** 引入结构化层变换以提高神经网络的稳定性、可解释性和训练动态。

**AI_Comments:** 这项工作通过引入结构化层级变换，为神经网络的稳定性、可解释性提供了一种新颖且有原则的方法。其创新之处在于将变换分解为结构化和残差部分，有助于更好地控制信号传播。该研究的重要性在于它为设计更可靠、更易于理解的神经网络模型奠定了基础，解决了当前深度学习模型中普遍存在的“黑箱”问题，同时保持了性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管当代神经网络表现出色，但它们通常缺乏促进稳定学习和可解释行为的结构化保障。

**Method:** 本文引入了一种层级变换的重新表述，它不同于标准的无约束仿射范式。每个变换都被分解为结构化线性算子和残差校正分量，以实现更规范的信号传播和改进的训练动态。该公式鼓励内部一致性，并支持跨深度的稳定信息流，同时与标准学习目标和反向传播完全兼容。

**Result:** 通过一系列合成和真实世界的实验，本文证明了使用这些结构化变换构建的模型表现出改进的梯度条件、降低的扰动敏感性和层级鲁棒性。这些益处在不同架构规模和训练方案中持续存在。

**Conclusion:** 这项研究为一类更具原则性的神经网络架构奠定了基础，这些架构优先考虑稳定性和透明度，同时不牺牲表达能力。

> **ai_Abstract:** 本文提出了一种新的神经网络层级变换方法，将传统无约束仿射变换分解为结构化线性算子和残差校正分量。这种方法旨在解决现有神经网络缺乏稳定性和可解释性的问题，通过促进更规范的信号传播和改进训练动态。实验结果表明，采用该变换的模型在梯度条件、抗扰动性和鲁棒性方面均有提升，为构建更稳定、透明且不失表达能力的神经网络架构提供了基础。

> **摘要翻译:** 尽管当代神经网络表现出色，但它们通常缺乏促进稳定学习和可解释行为的结构化保障。在这项工作中，我们引入了一种层级变换的重新表述，它不同于标准的无约束仿射范式。每个变换都被分解为结构化线性算子和残差校正分量，从而实现更规范的信号传播和改进的训练动态。我们的公式鼓励内部一致性，并支持跨深度的稳定信息流，同时与标准学习目标和反向传播完全兼容。通过一系列合成和真实世界的实验，我们证明了使用这些结构化变换构建的模型表现出改进的梯度条件、降低的扰动敏感性和层级鲁棒性。我们进一步表明，这些益处在不同架构规模和训练方案中持续存在。这项研究为一类更具原则性的神经网络架构奠定了基础，这些架构优先考虑稳定性和透明度——在不牺牲表达能力的情况下，为推理学习行为提供了新工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [867] [LLM-Assisted Cheating Detection in Korean Language via Keystrokes](https://arxiv.org/abs/2507.22956)
> *通过按键检测韩语中LLM辅助的作弊行为*

*Dong Hyun Roh, Rajesh Kumar, An Ngo* | **Category: cs.LG, cs.HC, K.3.1** | **Updated: 2025-07-29**

**Keywords:** 键盘敲击, LLM辅助作弊, 韩语, 认知过程, 作弊检测

**Comment:** This paper has 11 pages, 6 figures, 2 tables, and has been accepted
  for publication at IEEE-IJCB 2025

> **TL;DR:** 本文提出了一个基于键盘敲击的框架，用于检测韩语中LLM辅助的作弊行为，研究发现键盘敲击动态在不同认知需求和写作策略下均能有效识别LLM辅助的写作。

**AI_Comments:** 该研究创新性地将键盘敲击动态应用于LLM辅助作弊检测，特别是在韩语环境中，并考虑了不同的认知过程和写作策略，为教育和内容原创性评估提供了新的视角和有效工具。其超越人类评估者的表现尤为突出，凸显了该方法的实用价值和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在语言覆盖、认知背景和LLM参与粒度方面存在空白，本研究旨在通过基于键盘敲击的方法解决这些问题，以检测韩语中LLM辅助的作弊行为。

**Method:** 本研究构建了一个包含69名参与者的数据集，他们分别在真实写作、转述ChatGPT响应和转录ChatGPT响应三种条件下完成写作任务。每项任务都涵盖布鲁姆分类法定义的六种认知过程。研究提取了可解释的时间和节奏特征，并在认知感知和认知无关两种设置下评估了多种分类器。

**Result:** 时间特征在认知感知评估场景下表现良好，而节奏特征在跨认知场景下具有更好的泛化能力。对于所提出的模型和人类评估者而言，检测真实和转录响应比检测转述响应更容易，且模型表现显著优于人类评估者。

**Conclusion:** 研究结果证实，键盘敲击动态有助于可靠地检测不同认知需求和写作策略（包括转述和转录LLM生成响应）下的LLM辅助写作。

> **ai_Abstract:** 本文提出了一个创新的基于键盘敲击的框架，专门用于检测韩语环境中LLM辅助的作弊行为。该研究通过构建一个包含真实写作、转述和转录LLM响应的数据集，并考虑了布鲁姆分类法定义的六种认知过程，填补了现有研究的空白。通过分析时间与节奏特征，研究发现键盘敲击动态能够有效区分不同写作策略下的LLM辅助写作，尤其在模型表现上显著优于人类评估者，证实了其在作弊检测领域的可靠性和潜力。

> **摘要翻译:** 本文提出了一个基于键盘敲击的框架，用于检测韩语中LLM辅助的作弊行为，解决了先前研究在语言覆盖、认知背景和LLM参与粒度方面的关键空白。我们提出的数据集包括69名参与者，他们在三种条件下完成了写作任务：真实写作、转述ChatGPT响应和转录ChatGPT响应。每项任务都涵盖布鲁姆分类法定义的六种认知过程（记忆、理解、应用、分析、评估和创造）。我们提取了可解释的时间和节奏特征，并在认知感知和认知无关两种设置下评估了多种分类器。时间特征在认知感知评估场景下表现良好，而节奏特征在跨认知场景下具有更好的泛化能力。此外，对于所提出的模型和人类评估者而言，检测真实和转录响应比转述响应更容易，且模型表现显著优于人类。我们的发现证实，键盘敲击动态有助于可靠地检测不同认知需求和写作策略（包括转述和转录LLM生成响应）下的LLM辅助写作。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [887] [Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation](https://arxiv.org/abs/2507.23217)
> *基于伪目录引导的检索增强生成实现零样本文档理解*

*Hyeon Seong Jeong, Sangwoo Jo, Byeong Hyun Yoon, Yoonseok Heo, Haedong Jeong, Taehoon Kim* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 零样本文档理解, 检索增强生成, 多模态LLM, 伪目录, DocsRay

**Comment:** 

> **TL;DR:** DocsRay是一个无需训练的文档理解系统，它利用多模态大型语言模型和伪目录引导的检索增强生成，有效处理复杂文档，显著提高效率和准确性。

**AI_Comments:** DocsRay的创新点在于其无需训练的零样本方法，通过引入伪目录引导和分层RAG，有效地利用了多模态LLM处理复杂文档的能力。这种方法避免了对大量标注数据的依赖，同时解决了多模态信息的统一表示和高效检索问题。其性能提升和超越SOTA的结果表明了该系统在实际应用中的巨大潜力，尤其是在处理长文档和复杂结构文档方面。

<details>
  <summary>Details</summary>

**Motivation:** 理解复杂的多模态文档面临挑战，主要原因在于文档结构不一致和训练数据有限。

**Method:** 本文提出了DocsRay系统，一个无需训练的文档理解系统，它将伪目录（TOC）生成与分层检索增强生成（RAG）相结合。DocsRay利用多模态大型语言模型（LLMs）的原生能力处理包含文本、图像、图表和表格等多种元素的文档。其框架结合了三个关键技术：1) 一个语义结构化模块，使用基于提示的LLM交互生成分层伪TOC；2) 零样本多模态分析，利用多模态LLMs的固有能力将不同文档元素转换为统一的、以文本为中心的表示；3) 一个高效的两阶段分层检索系统，将检索复杂度从O(N)降低到O(S + k1 * Ns)。

**Result:** DocsRay在平均49.4页、20,971个文本标记的文档上，将查询延迟从3.89秒减少到2.12秒，效率提高了45%。在MMLongBench-Doc基准测试中，DocsRay-Pro取得了64.7%的准确率，大幅超越了之前最先进的结果。

**Conclusion:** DocsRay通过结合伪目录引导和分层检索增强生成，成功实现了复杂多模态文档的零样本理解，显著提升了处理效率和准确性，证明了其在无需额外训练的情况下处理多样化文档的强大能力。

> **ai_Abstract:** 本文提出DocsRay，一个无需训练的零样本文档理解系统，旨在解决复杂多模态文档结构不一致和数据稀缺的挑战。DocsRay通过整合伪目录生成和分层检索增强生成（RAG），利用多模态LLM的原生能力处理文本、图像、图表等多样化内容。其核心在于语义结构化模块生成伪TOC、零样本多模态分析将元素统一为文本表示，以及高效的两阶段分层检索系统。实验证明，DocsRay显著提升了查询效率（45%）并在MMLongBench-Doc基准测试中达到了超越SOTA的准确率（64.7%）。

> **摘要翻译:** 理解复杂的多模态文档仍然具有挑战性，原因在于其结构不一致和训练数据可用性有限。我们引入了 DocsRay，一个无需训练的文档理解系统，它将伪目录（TOC）生成与分层检索增强生成（RAG）相结合。我们的方法利用多模态大型语言模型（LLMs）的原生能力，无需专门模型或额外训练即可无缝处理包含文本、图像、图表和表格等多样化元素的文档。DocsRay 的框架协同结合了三项关键技术：(1) 一个语义结构化模块，使用基于提示的 LLM 交互生成分层伪 TOC；(2) 零样本多模态分析，利用多模态 LLMs 的固有能力将不同文档元素转换为统一的、以文本为中心的表示；(3) 一个高效的两阶段分层检索系统，将检索复杂度从 O(N) 降低到 O(S + k1 * Ns)。在平均 49.4 页和 20,971 个文本标记的文档上进行评估，DocsRay 将查询延迟从 3.89 秒减少到 2.12 秒，实现了 45% 的效率提升。在 MMLongBench-Doc 基准测试中，DocsRay-Pro 达到了 64.7% 的准确率，显著超越了之前最先进的结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [888] [Consensus-Driven Active Model Selection](https://arxiv.org/abs/2507.23771)
> *共识驱动的主动模型选择*

*Justin Kay, Grant Van Horn, Subhransu Maji, Daniel Sheldon, Sara Beery* | **Category: cs.LG, cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 主动模型选择, 共识驱动, 贝叶斯推理, 标注效率, 模型选择

**Comment:** ICCV 2025 Highlight. 16 pages, 8 figures

> **TL;DR:** CODA是一种新的主动模型选择方法，它利用模型共识和贝叶斯推理，显著减少了选择最佳模型所需的标注工作量，性能优于现有方法。

**AI_Comments:** 该论文在主动模型选择领域取得了显著进展，引入了一种创新性的、基于共识的概率框架。其核心创新在于利用模型间的共识和分歧来高效地指导数据标注，从而大幅减少了模型选择的成本。70%以上的标注工作量减少是一项重大的实际突破，使得模型选择在资源有限的场景下更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 现成的机器学习模型众多，但选择最适合特定数据分析任务的模型是一个挑战。传统模型选择依赖于耗时且昂贵的验证数据集标注。

**Method:** CODA（共识驱动的主动模型选择）方法利用候选模型的预测来优先标注测试数据点，以有效区分最佳候选模型。它在一个概率框架内建模分类器、类别和数据点之间的关系，并利用模型间的共识和分歧来指导标签获取过程，同时使用贝叶斯推理更新对最佳模型的信念。

**Result:** CODA在26个基准任务集合上进行了验证，其性能显著优于现有的主动模型选择方法，将发现最佳模型所需的标注工作量比现有最先进技术减少了70%以上。

**Conclusion:** 该论文提出了一种名为CODA的共识驱动主动模型选择方法，该方法通过高效利用模型间信息显著减少了模型选择所需的标注工作量，从而解决了传统方法昂贵耗时的问题。

> **ai_Abstract:** 该论文介绍了一种名为CODA的新型主动模型选择方法，旨在解决传统模型选择中验证数据集标注成本高昂的问题。CODA通过一个概率框架，建模分类器、类别和数据点之间的关系，并利用候选模型间的共识和分歧来指导数据点标签的优先级获取。这种方法能够高效地识别最佳模型，实验结果表明，与现有最先进技术相比，CODA将选择最佳模型所需的标注工作量减少了70%以上。

> **摘要翻译:** 现成的机器学习模型的广泛可用性带来了一个挑战：对于给定的数据分析任务，应该选择众多可用候选模型中的哪一个？模型选择的这个问题传统上通过收集和标注验证数据集来解决——这是一个成本高昂且耗时的过程。我们提出了一种主动模型选择方法，利用候选模型的预测来优先标注测试数据点，从而有效地区分最佳候选模型。我们的方法CODA通过在概率框架内建模分类器、类别和数据点之间的关系来执行共识驱动的主动模型选择。该框架利用候选池中模型之间的共识和分歧来指导标签获取过程，并使用贝叶斯推理来更新关于哪个模型是最佳的信念，随着更多信息的收集。我们通过整理26个基准任务集合来验证我们的方法，这些任务涵盖了一系列模型选择场景。CODA显著优于现有的主动模型选择方法，与之前的最先进技术相比，将发现最佳模型所需的标注工作量减少了70%以上。代码和数据可在https://github.com/justinkay/coda 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [892] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
> *利用自编码器进行心电图潜在特征提取以用于下游预测任务*

*Christopher Harvey, Sumaiya Shomaji, Zijun Yao, Amit Noheria* | **Category: cs.LG** | **Updated: 2025-07-31**

**Keywords:** ECG, 自编码器, 变分自编码器, 特征提取, 深度学习

**Comment:** arXiv admin note: substantial text overlap with arXiv:2410.02937

> **TL;DR:** 本研究通过探索主成分分析（PCA）和自编码器（尤其是新型VAE变体）对心电图（ECG）数据进行特征提取，有效降低了数据复杂性，并在小数据集下实现了与SOTA模型相媲美的预测性能，同时显著减少了计算资源。

**AI_Comments:** 该论文的创新点在于引入并比较了多种VAE变体用于ECG数据的潜在特征提取，并证明了这些方法在处理复杂医学信号和应对小数据集挑战方面的有效性。其重要性体现在提供了一种计算效率高且性能接近SOTA模型的解决方案，特别适用于资源受限或数据稀缺的临床场景。此外，其避免过拟合的能力也增加了模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管心电图（ECG）是一种廉价且广泛可用的心脏评估工具，但其高复杂性和个体间差异性（通常是60,000维的向量）使得它在深度学习模型中难以应用，特别是在只有小型训练数据集可用时。

**Method:** 本研究通过探索从代表性心跳ECG中生成特征的方法来解决挑战，重点关注主成分分析（PCA）和自编码器来降低数据复杂性。研究引入了三种新型变分自编码器（VAE）变体：随机自编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta VAE（C beta-VAE），并比较它们在保持信号保真度和使用Light Gradient Boost Machine（LGBM）增强下游预测任务方面的有效性。

**Result:** A beta-VAE实现了卓越的信号重建，将平均绝对误差（MAE）降低到15.7+/-3.2 μV，达到了信号噪声水平。此外，SAE编码与传统ECG总结特征结合，改善了左心室射血分数（LVEF）降低的预测，使用LGBM分类器在保留测试集上实现了0.901的受试者工作特征曲线下面积（AUROC）。这一性能几乎与最先进的CNN模型的0.909 AUROC相匹配，但所需的计算资源显著减少。此外，ECG特征提取-LGBM管道避免了过拟合，并在使用更少数据训练时保持了预测性能。

**Conclusion:** 本研究的结果表明，这些VAE编码不仅在简化ECG数据方面有效，而且为在有限规模标记训练数据环境下应用深度学习提供了一个实用的解决方案。

> **ai_Abstract:** 本研究旨在解决心电图（ECG）数据在深度学习中因其复杂性和小数据集限制而面临的挑战。通过探索主成分分析（PCA）和自编码器（特别是三种新型变分自编码器VAEs：SAE、A beta-VAE、C beta-VAE）进行特征提取，研究成功降低了数据复杂度。结果显示，A beta-VAE在信号重建方面表现出色，而SAE编码结合传统特征在预测左心室射血分数降低方面达到了0.901的AUROC，接近最先进的CNN模型性能（0.909），但显著降低了计算资源需求。该方法还展现了在数据量较少时避免过拟合并保持预测能力的优势，为在有限标记数据环境下应用深度学习提供了实用方案。

> **摘要翻译:** 心电图（ECG）是一种廉价且广泛可用的心脏评估工具。尽管其格式标准化且文件大小小，但ECG信号的高度复杂性和个体间差异性（通常是500 Hz下12导联的60,000大小向量）使其难以在深度学习模型中使用，尤其是在只有小型训练数据集可用时。本研究通过探索从代表性心跳ECG中生成特征的方法来解决这些挑战，重点关注主成分分析（PCA）和自编码器来降低数据复杂性。我们引入了三种新型变分自编码器（VAE）变体——随机自编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta VAE（C beta-VAE）——并比较它们在保持信号保真度和使用Light Gradient Boost Machine（LGBM）增强下游预测任务方面的有效性。A beta-VAE实现了卓越的信号重建，将平均绝对误差（MAE）降低到15.7+/-3.2 μV，这达到了信号噪声水平。此外，SAE编码与传统ECG总结特征结合，改善了左心室射血分数（LVEF）降低的预测，在保留测试集上使用LGBM分类器实现了0.901的受试者工作特征曲线下面积（AUROC）。这一性能几乎与最先进的CNN模型的0.909 AUROC相匹配，但所需的计算资源显著减少。此外，ECG特征提取-LGBM管道避免了过拟合，并在使用更少数据训练时保持了预测性能。我们的发现表明，这些VAE编码不仅在简化ECG数据方面有效，而且为在有限规模标记训练数据环境下应用深度学习提供了一个实用的解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [911] [Efficient Machine Unlearning via Influence Approximation](https://arxiv.org/abs/2507.23257)
> *影响力近似的机器学习遗忘算法*

*Jiawei Liu, Chenwang Wu, Defu Lian, Enhong Chen* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 机器学习遗忘, 影响力近似, 增量学习, 计算效率, 隐私保护

**Comment:** 12 pages, 4 figures

> **TL;DR:** 本文提出了一种基于增量学习视角的高效机器学习遗忘算法IAU，通过近似影响力来避免高昂的Hessian矩阵计算，并在效率、遗忘保证和模型效用之间取得平衡，优于现有方法。

**AI_Comments:** 本文的创新点在于将认知科学的“记忆比遗忘容易”这一理念引入机器学习遗忘领域，并巧妙地将遗忘问题转化为增量学习问题，从而避开了传统影响力方法中计算Hessian矩阵的高昂开销。这种方法不仅具有理论上的优雅性，也通过实证验证了其在效率和性能上的优越性，对大规模机器学习模型的隐私保护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于隐私问题，机器学习遗忘受到关注，但现有基于影响力的遗忘方法计算量大（需计算Hessian矩阵），不适用于大规模模型和频繁数据删除请求。

**Method:** 论文受认知科学启发，建立了记忆（增量学习）与遗忘（遗忘学习）之间的理论联系，将遗忘学习问题转化为增量学习问题。基于此，提出了影响力近似遗忘（IAU）算法，利用增量学习中更高效的梯度优化来避免耗时的Hessian计算。

**Result:** IAU算法在移除保证、遗忘效率和模型效用之间取得了卓越的平衡，并在各种数据集和模型架构上优于现有最先进的方法。

**Conclusion:** 本文通过建立增量学习和遗忘学习的联系，并提出高效的IAU算法，有效解决了大规模机器学习模型遗忘的计算效率问题，实现了高性能的遗忘能力。

> **ai_Abstract:** 针对现有机器学习遗忘方法计算开销大的问题，本文提出了一种名为影响力近似遗忘（IAU）的新算法。该算法受认知科学启发，将遗忘学习与增量学习建立理论联系，从而利用增量学习中高效的梯度优化来避免耗时的Hessian矩阵计算。实验证明，IAU在保证遗忘效果、提高效率和保持模型性能方面表现出色，并优于现有方法。

> **摘要翻译:** 由于日益增长的隐私问题，旨在使机器学习模型“遗忘”特定训练数据的机器学习遗忘受到了越来越多的关注。在现有方法中，基于影响力的遗忘方法因其无需重新训练即可估计单个训练样本对模型参数的影响而成为一种突出的方法。然而，这种方法存在计算开销过大的问题，因为它需要计算所有训练样本和参数的Hessian矩阵及其逆矩阵，这使得它对于大规模模型和涉及频繁数据删除请求的场景不切实际。这凸显了遗忘的困难。受认知科学的启发，即记忆比遗忘更容易，本文建立了记忆（增量学习）和遗忘（遗忘学习）之间的理论联系。这种联系使得机器学习遗忘可以从增量学习的角度来解决。与遗忘（遗忘）中耗时的Hessian计算不同，增量学习（记忆）通常依赖于更高效的梯度优化，这支持了前面提到的认知理论。基于这种联系，我们引入了影响力近似遗忘（IAU）算法，用于从增量角度实现高效的机器学习遗忘。广泛的实证评估表明，IAU在移除保证、遗忘效率和可比模型效用之间取得了卓越的平衡，同时在各种数据集和模型架构上优于现有最先进的方法。我们的代码可在https://github.com/Lolo1222/IAU 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [929] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
> *INSPIRE-GNN：通过强化学习增强图神经网络改进稀疏自行车网络预测的智能传感器布局*

*Mohit Gupta, Debjit Bhowmick, Rhys Newbury, Meead Saberi, Shirui Pan, Ben Beck* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 传感器布局, 强化学习, 图神经网络, 自行车流量估计, 数据稀疏性

**Comment:** 

> **TL;DR:** INSPIRE-GNN是一个结合强化学习和图神经网络的框架，用于优化稀疏自行车计数传感器的布局，显著提高了自行车流量估计的准确性。

**AI_Comments:** INSPIRE-GNN的创新之处在于其结合了强化学习（DQN）来智能地优化传感器布局，以提升图神经网络在数据稀疏环境下的预测能力。这种数据驱动的传感器放置策略是其关键亮点，解决了传统方法难以应对的高稀疏性挑战。该研究对于智慧城市交通规划，特别是自行车基础设施的优化具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 许多城市面临自行车计数传感器覆盖范围有限导致数据高度稀疏的问题，这影响了准确的链接级自行车流量估计，而这对于可持续城市交通规划至关重要。

**Method:** 本文提出了INSPIRE-GNN，一个新颖的强化学习（RL）增强型混合图神经网络（GNN）框架。它集成了图卷积网络（GCN）和图注意力网络（GAT）与基于深度Q网络（DQN）的RL代理。该框架通过数据驱动的方式战略性选择传感器位置，以最大化估计性能。

**Result:** 将INSPIRE-GNN应用于墨尔本自行车网络（15,933条路段中仅141条有传感器，99%稀疏），结果表明，通过在部署50、100、200和500个传感器时战略性选择额外传感器位置，该框架显著提高了流量估计。它在关键指标（MSE、RMSE、MAE）上优于传统的启发式传感器布局方法（如介数中心性、接近度中心性、观测自行车活动和随机布局），并且在自行车流量估计性能方面优于标准机器学习和深度学习模型。

**Conclusion:** INSPIRE-GNN框架为交通规划者提供了可操作的见解，以有效扩展传感器网络，优化传感器布局，并最大限度地提高自行车数据的流量估计准确性和可靠性，从而支持知情的交通规划决策。

> **ai_Abstract:** 本文提出了INSPIRE-GNN，一个结合强化学习（RL）和图神经网络（GNN）的混合框架，旨在解决城市自行车网络中传感器数据稀疏导致的流量估计不准确问题。该模型通过RL代理智能选择传感器位置，以优化GNN在数据稀疏环境下的预测性能。在墨尔本自行车网络的实验表明，INSPIRE-GNN在流量估计准确性上显著优于传统启发式方法和标准机器学习模型，为交通规划提供了有效的传感器网络扩展和优化策略。

> **摘要翻译:** 准确的链接级自行车流量估算对于可持续城市交通规划至关重要。然而，由于自行车计数传感器覆盖范围有限，许多城市面临数据高度稀疏的重大挑战。为了解决这个问题，我们提出了INSPIRE-GNN，一个新颖的强化学习（RL）增强型混合图神经网络（GNN）框架，旨在优化传感器布局并改善数据稀疏环境中的链接级自行车流量估算。INSPIRE-GNN将图卷积网络（GCN）和图注意力网络（GAT）与基于深度Q网络（DQN）的RL代理相结合，从而能够数据驱动地战略性选择传感器位置，以最大化估算性能。应用于墨尔本的自行车网络，该网络包含15,933个路段，其中只有141个路段（99%稀疏）有传感器覆盖——INSPIRE-GNN通过在部署50、100、200和500个传感器时战略性选择额外的传感器位置，在流量估算方面表现出显著改进。我们的框架在均方误差（MSE）、均方根误差（RMSE）和平均绝对误差（MAE）等关键指标上优于传统的传感器布局启发式方法，如介数中心性、接近度中心性、观测自行车活动和随机布局。此外，我们的实验将INSPIRE-GNN与标准的机器学习和深度学习模型在自行车流量估算性能方面进行了基准测试，强调了其有效性。我们提出的框架为交通规划者提供了可操作的见解，以有效扩展传感器网络，优化传感器布局，并最大限度地提高自行车数据的流量估算准确性和可靠性，从而支持知情的交通规划决策。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [935] [DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System](https://arxiv.org/abs/2507.23261)
> *DynaSwarm：面向基于LLM的多智能体系统的动态图结构选择*

*Hui Yi Leong, Yuqing Wu* | **Category: cs.LG, cs.AI, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 多智能体系统, LLM, 动态图结构, 强化学习, A2C

**Comment:** 

> **TL;DR:** DynaSwarm是一个动态框架，通过A2C强化学习和动态图选择器，优化LLM多智能体系统的协作图结构，实现样本自适应的性能提升。

**AI_Comments:** DynaSwarm的创新之处在于其动态图结构选择机制，通过结合强化学习和LLM微调，实现了多智能体系统在不同任务和样本上的自适应性。这解决了传统MAS框架中僵化结构带来的限制，为LLM驱动的MAS设计提供了新的思路，提升了其实用性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM多智能体系统（MAS）框架依赖于手动设计和静态的协作图结构，这限制了其适应性和性能。

**Method:** 本文提出了DynaSwarm，一个动态框架，通过两项关键创新增强了基于LLM的MAS：1) 采用Actor-Critic强化学习（A2C）机制优化图结构，相比以往的强化学习方法具有更高的稳定性；2) 引入动态图选择器，通过参数高效的LLM微调，为每个输入样本自适应地选择最优图结构。此外，还提出了微调演示检索器以充分利用上下文学习（ICL）的能力。

**Result:** 在问答、数学推理和编码任务上的大量实验表明，DynaSwarm在多个LLM骨干网络上始终优于最先进的单智能体和MAS基线。

**Conclusion:** 研究结果强调了在LLM MAS设计中样本感知结构灵活性的重要性。

> **ai_Abstract:** DynaSwarm是一个针对基于LLM的多智能体系统设计的动态框架，旨在克服现有系统静态图结构带来的适应性和性能限制。它引入了A2C强化学习机制来稳定优化图结构，并利用参数高效的LLM微调实现动态图选择，为每个输入样本自适应地选择最佳结构。通过消除对固定图架构的依赖，DynaSwarm能够根据样本特性动态路由查询。实验证明，DynaSwarm在多种任务和LLM骨干网络上均优于现有基线，突出了样本感知结构灵活性在LLM MAS设计中的重要性。

> **摘要翻译:** 当前的LLM多智能体系统（MAS）框架通常依赖于手动设计和静态的协作图结构，这限制了其适应性和性能。为了解决这些限制，我们提出了DynaSwarm，一个动态框架，通过两项关键创新增强了基于LLM的MAS：（1）一种Actor-Critic强化学习（A2C）机制，用于优化图结构，与之前的强化学习方法相比，具有更高的稳定性；（2）一个动态图选择器，通过参数高效的LLM微调，为每个输入样本自适应地选择最优图结构。DynaSwarm消除了对僵化、一刀切的图架构的需求，而是利用样本特异性来动态地通过专门的智能体网络路由查询。(c) 我们建议微调演示检索器，以充分利用上下文学习（ICL）的力量。在问答、数学推理和编码任务上的大量实验表明，DynaSwarm在多个LLM骨干网络上始终优于最先进的单智能体和MAS基线。我们的发现强调了在LLM MAS设计中样本感知结构灵活性的重要性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [937] [Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles](https://arxiv.org/abs/2501.15544)
> *推进生成式人工智能和大型语言模型在电动汽车物联网需求侧管理中的应用*

*Hanwen Zhang, Ruichen Zhang, Wei Zhang, Dusit Niyato, Yonggang Wen, Chunyan Miao* | **Category: cs.LG, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 生成式人工智能, 大型语言模型, 需求侧管理, 电动汽车物联网, 能源优化

**Comment:** 11 Pages

> **TL;DR:** 本文探讨了生成式人工智能和大型语言模型（LLM）在电动汽车物联网（IoEV）需求侧管理（DSM）中的应用，提出了一种结合检索增强生成（RAG）的LLM增强方案，通过案例研究证明了其在电动汽车充电调度和优化中提升能源效率和用户适应性的有效性。

**AI_Comments:** 本文的创新之处在于将大型语言模型与检索增强生成技术相结合，应用于电动汽车物联网中的需求侧管理，实现了能源优化策略的自动化生成和定制。这为传统能源管理带来了新的智能化范式，尤其是在处理复杂、动态的电动汽车充电调度问题上展现出显著潜力。

<details>
  <summary>Details</summary>

**Motivation:** 生成式人工智能，特别是大型语言模型（LLM），有望彻底改变微电网中的能源优化和需求侧管理（DSM）。本文旨在探索LLM在能源管理中的集成应用，特别是其在自动化优化电动汽车物联网（IoEV）中DSM策略方面的作用。

**Method:** 本文首先探讨了与需求侧管理（DSM）相关的挑战和解决方案，并利用大型语言模型（LLM）探索了新的机会。随后，提出了一种创新的解决方案，通过检索增强生成（retrieval-augmented generation）技术增强LLM，以实现自动问题表述、代码生成和定制优化。

**Result:** 通过一个案例研究，展示了所提出的解决方案在电动汽车充电调度和优化中的有效性，突出了该解决方案在能源效率和用户适应性方面的显著进步。

**Conclusion:** 这项工作强调了大型语言模型（LLM）在能源优化方面的巨大潜力，并预示着智能需求侧管理（DSM）解决方案新时代的到来。

> **ai_Abstract:** 该论文探讨了生成式人工智能和大型语言模型（LLM）在微电网需求侧管理（DSM）中的应用，特别是结合电动汽车物联网（IoEV）进行能源优化。研究分析了DSM的挑战与机遇，并提出了一种创新的LLM增强型解决方案，该方案利用检索增强生成技术实现自动问题表述、代码生成和优化定制。通过电动汽车充电调度的案例研究，验证了该方案在提高能源效率和用户适应性方面的有效性，彰显了LLM在智能DSM领域的巨大潜力。

> **摘要翻译:** 生成式人工智能，特别是通过大型语言模型（LLM），有望改变微电网中的能源优化和需求侧管理（DSM）。本文探讨了LLM在能源管理中的集成，强调其在电动汽车物联网（IoEV）中自动化优化DSM策略的作用。我们调查了与DSM相关的挑战和解决方案，并探索了利用LLM带来的新机遇。然后，我们提出了一种创新解决方案，该方案通过检索增强生成（retrieval-augmented generation）来增强LLM，以实现自动问题表述、代码生成和定制优化。我们提供了一个案例研究，以证明我们提出的解决方案在电动汽车充电调度和优化中的有效性，突出了我们的解决方案在能源效率和用户适应性方面的显著进步。这项工作强调了LLM在能源优化方面的潜力，并开创了智能DSM解决方案的新时代。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [947] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
> *噪声标签下的鲁棒分类：一种面向基础模型的几何感知可靠性框架*

*Ecem Bozkurt, Antonio Ortega* | **Category: cs.LG, cs.AI, eess.SP** | **Updated: 2025-07-31**

**Keywords:** 噪声标签, 鲁棒分类, 基础模型, 几何感知, 可靠性估计

**Comment:** 5 pages, 2 figures, under review at CAMSAP 2025

> **TL;DR:** 本文提出了一种两阶段几何感知可靠性框架，用于在噪声标签下对基础模型进行鲁棒分类，无需模型再训练，并通过引入几何信息和新的可靠性估计方法，在CIFAR-10和DermaMNIST数据集上优于现有基线。

**AI_Comments:** 本文的创新点在于将几何信息融入到基础模型在噪声标签下的鲁棒分类中，并提出了减少对距离和局部邻域依赖的可靠性估计方法。其无需模型再训练的特点对于实际应用具有重要价值，特别是在数据标注成本高昂的场景下。该框架的普适性以及在不同数据集上的优越表现，表明了其在处理噪声数据方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在大数据集上预训练的基础模型在许多下游机器学习任务中至关重要，尤其是在获取完美标注数据成本过高的情况下。现有研究表明，使用基础模型嵌入的kNN方法即使在严重标签噪声下也能表现良好，且这些方法利用了局部几何信息，这启发了本文的研究。

**Method:** 本文提出一个两阶段框架，包括可靠性估计和可靠性加权推理，以确保在存在标签噪声的情况下进行鲁棒分类，且无需模型再训练。该方法通过引入几何信息来提高性能，利用非负核（NNK）邻域构建方法为给定实例获取训练数据的局部邻域。文中还提出了几种可靠性估计方法，随着标签噪声的增加，这些方法对距离和局部邻域的依赖性更小。

**Result:** 在CIFAR-10和DermaMNIST数据集上的评估表明，本文提出的方法在各种噪声条件下提高了鲁棒性，超越了标准K-NN方法和最近的自适应邻域基线。

**Conclusion:** 通过引入几何信息和新的可靠性估计方法，本文提出的两阶段框架显著提高了基础模型在噪声标签下的分类鲁棒性，且无需模型再训练。

> **ai_Abstract:** 本文提出了一种针对基础模型在噪声标签下进行鲁棒分类的两阶段框架，该框架无需模型再训练。受局部几何信息对K-NN方法有效性的启发，作者引入了几何信息，并利用非负核（NNK）构建局部邻域进行可靠性加权推理。此外，论文还提出了多种对噪声不敏感的可靠性估计方法。在CIFAR-10和DermaMNIST数据集上的实验结果表明，该方法在不同噪声条件下均优于现有的K-NN和自适应邻域基线，显著提升了分类鲁棒性。

> **摘要翻译:** 在大型数据集上预训练的基础模型（FMs）已成为各种下游机器学习任务的基础，特别是在获取完美标注数据成本过高的情况下。本文假设基础模型必须使用噪声数据进行微调，并提出一个两阶段框架，以确保在存在标签噪声的情况下进行鲁棒分类，而无需模型再训练。最近的工作表明，使用基础模型嵌入的简单k最近邻（kNN）方法即使在严重标签噪声下也能取得良好性能。我们的工作受到这些方法利用局部几何事实的启发。在本文中，遵循类似的两阶段过程，即可靠性估计后进行可靠性加权推理，我们表明通过引入几何信息可以实现性能提升。对于给定实例，我们提出的推理方法使用训练数据的局部邻域，该邻域通过非负核（NNK）邻域构建获得。我们提出了几种可靠性估计方法，随着标签噪声的增加，这些方法可以减少对距离和局部邻域的依赖。我们在CIFAR-10和DermaMNIST上的评估表明，我们的方法在各种噪声条件下提高了鲁棒性，超越了标准K-NN方法和最近的自适应邻域基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [24] [Explanations for Unrealizability of Infinite-State Safety Shields](https://arxiv.org/abs/2507.23603)
> *无限状态安全防护罩不可实现性的解释*

*Andoni Rodriguez, Irfansha Shaik, Davide Corsi, Roy Fox, Cesar Sanchez* | **Category: cs.LO** | **Updated: 2025-07-31**

**Keywords:** 安全防护罩, 不可实现性, 无限状态, 时序公式展开, 安全强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种通过时序公式展开的方法，用于为无限状态安全防护罩的不可实现性提供简单、无条件和有条件的解释。

**AI_Comments:** 本文解决了安全强化学习中一个重要且实际的问题，即无限状态安全防护罩的不可实现性。通过提供解释其不可实现性的方法，该研究增强了对复杂系统行为的理解和调试能力，对于提高安全关键系统设计的可靠性具有重要意义。其创新点在于利用时序公式展开来生成可理解的解释。

<details>
  <summary>Details</summary>

**Motivation:** 安全强化学习中的防护罩合成，尤其是在无限状态领域，常因规范不一致而导致防护罩无法实现。为了解决这一问题，即理解和解释为何防护罩不可实现，本文提出了相应的方法。

**Method:** 该研究提出了一种通过时序公式展开（temporal formula unrolling）的方法，以获得证明防护罩不可实现性的简单无条件和有条件解释。

**Result:** 本文展示了所提出技术的不同变体及其在解释无限状态安全防护罩不可实现性方面的适用性。

**Conclusion:** 本文提供了一种有效的方法来解释无限状态安全防护罩的不可实现性，这有助于解决安全强化学习中合成规范不一致的挑战。

> **ai_Abstract:** 安全强化学习中，防护罩是一种确保安全的常用方法，但无限状态领域的防护罩常因规范不一致而无法实现。为解决这一问题，本文提出了一种基于时序公式展开的方法，旨在提供简单、无条件和有条件的解释，以揭示防护罩不可实现的原因。论文展示了该技术的多种变体及其在实际中的应用。

> **摘要翻译:** 安全强化学习致力于在确保安全的同时开发最优策略。解决此类任务的一种流行方法是防护罩（shielding），其中从逻辑规范中合成一个正确构建的安全组件。最近，防护罩合成已扩展到无限状态领域，例如连续环境。这使得防护罩更适用于现实场景。然而，防护罩通常可能由于规范不一致（例如，矛盾）而无法实现。为了解决这一空白，我们提出了一种通过时序公式展开来获得简单无条件和有条件解释的方法，这些解释可以证明不可实现性。在本文中，我们展示了该技术的不同变体及其适用性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [108] [Automated Strategy Invention for Confluence of Term Rewrite Systems](https://arxiv.org/abs/2411.06409)
> *项重写系统合流的自动化策略发明*

*Liao Zhang, Fabian Mitterwallner, Jan Jakubuv, Cezary Kaliszyk* | **Category: cs.LO, cs.AI, F.4.2; I.2.8** | **Updated: 2025-07-31**

**Keywords:** 项重写系统, 合流, 自动化策略发明, 机器学习, 自动证明器

**Comment:** 

> **TL;DR:** 本文通过应用机器学习开发了一种学习引导的自动合流证明器，以解决项重写系统中参数选择的复杂性，并显著提升了现有最佳证明器的性能。

**AI_Comments:** 本文的创新之处在于首次将机器学习应用于自动合流证明器，以解决传统人工设计策略在巨大参数空间中的局限性。其重要性在于，通过自动化策略发明，显著提升了项重写系统合流性证明的效率和能力，甚至解决了之前无法自动证明的问题，这对于软件验证和编译器优化领域具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动项重写工具的参数空间过于庞大，超出了人类选择参数的能力，这促使研究人员探索自动化策略发明。

**Method:** 本文聚焦于项重写系统的合流性质，并应用机器学习开发了第一个学习引导的自动合流证明器。此外，研究人员随机生成了大量数据集用于分析项重写系统的合流性。

**Result:** 研究结果表明，当配备本文发明的策略时，最先进的自动合流证明器CSI在增强数据集和原始人工创建的基准数据集Cops上都超越了其人工设计的策略，成功证明/反驳了之前无法自动证明的多个项重写系统的合流性。

**Conclusion:** 通过机器学习发明策略，可以显著提高自动合流证明器的性能，使其超越人工设计的策略，并能解决此前无法自动证明的合流问题。

> **ai_Abstract:** 本文针对项重写系统中的参数选择复杂性问题，提出了一种自动化策略发明方法。通过应用机器学习，研究人员开发了首个学习引导的自动合流证明器，并生成了大型数据集进行分析。实验结果显示，该方法显著提升了现有最佳自动合流证明器CSI的性能，使其在多个数据集上超越了人工设计的策略，并成功解决了此前无法自动证明的合流问题。

> **摘要翻译:** 项重写在软件验证和编译器优化中扮演着关键角色。随着数十种高度参数化技术的开发，用于证明各种系统属性的自动项重写工具在一个广阔的参数空间中工作。这种复杂性超出了人类选择参数的能力，从而促使人们对自动化策略发明进行研究。在本文中，我们专注于合流，这是项重写系统的一个重要属性，并应用机器学习开发了第一个学习引导的自动合流证明器。此外，我们随机生成了一个大型数据集来分析项重写系统的合流性。我们的结果侧重于改进最先进的自动合流证明器CSI：当配备我们发明的策略时，它在增强数据集和原始人工创建的基准数据集Cops上都超越了其人工设计的策略，成功证明/反驳了之前无法自动证明的多个项重写系统的合流性。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [150] [Who Wins the Multi-Structural Game?](https://arxiv.org/abs/2507.18718)
> *谁赢得多结构博弈？*

*Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta* | **Category: cs.LO, F.4.1** | **Updated: 2025-07-31**

**Keywords:** 组合博弈, 多结构博弈, PSPACE难, NEXPTIME, Ehrenfeucht-Fraïssé博弈

**Comment:** 27 pages, 7 figures

> **TL;DR:** 本论文分析了多结构 (MS) 博弈的复杂度，证明其是PSPACE难的且包含在NEXPTIME中，并解决了Ehrenfeucht-Fraïssé (EF) 博弈的一个未决问题。

**AI_Comments:** 本论文通过确定多结构博弈（一个近期备受关注的主题）的复杂度边界，并解决Ehrenfeucht-Fraïssé博弈背景下的一个长期未决问题，做出了重要贡献。将既有技术与优化理论和并行玩法的新见解相结合，展示了博弈论中复杂度分析的复杂方法。

<details>
  <summary>Details</summary>

**Motivation:** 组合博弈（如Ehrenfeucht-Fraïssé (EF) 博弈）常用于捕捉形式逻辑语言的句法特性。对于这类博弈，存在一个自然决策问题，即“给定一个博弈实例，扰乱者是否在该实例中获胜？”EF博弈的此问题已被证明是PSPACE完全的。本研究的动机在于分析最近备受关注的“多结构”(MS) 博弈的相同问题，并解决Pezzoli提出的关于EF博弈难度结果对模式元数依赖性的未决问题。

**Method:** 本研究结合了Pezzoli构造的改编、优化问题不可近似性理论的见解以及最近开发的多结构博弈并行玩法技术。

**Result:** 本研究表明，对于多结构 (MS) 博弈，“扰乱者是否在给定实例中获胜”的决策问题是PSPACE难的，但包含在NEXPTIME中。此外，还解决了Pezzoli提出的关于Ehrenfeucht-Fraïssé (EF) 博弈难度结果对所考虑模式元数依赖性的未决问题。

**Conclusion:** 本论文确定了多结构博弈决策问题的复杂度边界，并解决了Ehrenfeucht-Fraïssé博弈领域的一个长期存在的未决问题。

> **ai_Abstract:** 本论文探讨了多结构 (MS) 博弈中“扰乱者是否获胜”这一决策问题的计算复杂度，证明其为PSPACE难且包含在NEXPTIME中。研究基于Ehrenfeucht-Fraïssé (EF) 博弈的技术，并通过结合Pezzoli的改编构造、不可近似性理论的见解以及MS博弈的并行玩法技术，解决了关于EF博弈难度结果对模式元数依赖性的一个未决问题。

> **摘要翻译:** 组合博弈，由两名玩家（扰乱者和复制者）进行，经常被用来捕捉形式逻辑语言的句法特性。例如，广泛使用的Ehrenfeucht-Fraïssé (EF) 博弈捕捉一阶公式的量词秩的句法度量。对于每个此类博弈，都有一个相关的自然决策问题：“给定一个博弈实例，扰乱者是否在该实例中获胜？”对于EF博弈，Pezzoli在1998年证明了这个问题是PSPACE完全的。在本论文中，我们证明了对于最近备受关注的“多结构”(MS) 博弈，同样的问题是PSPACE难的，但包含在NEXPTIME中。在此过程中，我们还解决了Pezzoli提出的一个悬而未决的问题，即EF博弈的难度结果对所考虑模式的元数（arity）的依赖性。我们的技术结合了Pezzoli构造的改编，以及优化问题不可近似性理论的见解，以及最近开发的MS博弈并行玩法技术。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [444] [Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2](https://arxiv.org/abs/2508.00015)
> *扩展摘要：部分封装及其在ACL2中对浮点运算的支持*

*Matt Kaufmann, J Strother Moore* | **Category: cs.LO, cs.MS** | **Updated: 2025-07-25**

**Keywords:** Partial-encapsulate, ACL2, 浮点运算

**Comment:** In Proceedings ACL2 2025, arXiv:2507.18567

> **TL;DR:** 本文阐述了部分封装（partial-encapsulate）在ACL2中实现浮点运算的强大功能和应用。

**AI_Comments:** 鉴于摘要非常简短，这可能是一篇扩展摘要而非完整论文。其创新之处在于展示了ACL2中一个特定功能（partial-encapsulate）在实际应用（浮点运算）中的效用。这对于在形式化验证系统ACL2中简化或实现与浮点算术相关的复杂证明具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在阐明部分封装（partial-encapsulate）的强大功能，并展示其在ACL2中实现浮点运算方面的具体应用。

**Method:** 通过展示部分封装（partial-encapsulate）如何在ACL2中用于实现浮点运算来阐述其功能。

**Result:** 本文阐释了部分封装（partial-encapsulate）的强大功能。

**Conclusion:** 部分封装（partial-encapsulate）在ACL2中对实现浮点运算具有重要支持作用，并展现出其强大功能。

> **ai_Abstract:** 这篇扩展摘要阐述了部分封装（partial-encapsulate）的强大功能，具体展示了它在ACL2定理证明器中实现浮点运算的应用。

> **摘要翻译:** 我们阐述了部分封装（partial-encapsulate）的强大功能，展示了它如何在ACL2中用于实现浮点运算。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [617] [Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers](https://arxiv.org/abs/2508.00419)
> *循环不变量生成：推理优化LLMs和SMT求解器的混合框架*

*Varun Bharti, Shashwat Jha, Dhruv Kumar, Pankaj Jalote* | **Category: cs.LO, cs.LG, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 循环不变量, 大语言模型, SMT求解器, 程序验证, 混合框架

**Comment:** Under Review

> **TL;DR:** 该研究提出一个结合LLMs和SMT求解器的混合框架，用于自动生成循环不变量，并在Code2Inv基准测试中实现了100%的覆盖率，超越了现有最佳方法。

**AI_Comments:** 该论文的创新点在于将LLMs的生成能力与SMT求解器的形式化验证能力相结合，形成一个高效的反馈循环系统。其重要性在于显著提升了循环不变量合成的自动化水平和准确性，解决了程序验证中的一个关键难题。结果表明LLMs不仅能处理自然语言，也具备一定的逻辑推理潜力，这为未来的程序分析和验证工具开发开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 循环不变量对于证明带有循环的程序的正确性至关重要，但开发它们极具挑战性，且完全自动合成无法保证。现有方法（符号技术和神经方法）只能在标准基准测试的子集上正确合成循环不变量。

**Method:** 作者将OpenAI的O1、O1-mini和O3-mini等推理优化大型语言模型与Z3 SMT求解器集成到一个紧密耦合的生成-检查管道中，利用求解器反例迭代地指导不变量细化。他们使用Code2Inv基准测试（包含C程序及其前置条件和后置条件）进行评估。

**Result:** 在133个任务的Code2Inv基准测试中，该框架实现了100%的覆盖率（133/133），优于之前最佳的107/133。每个实例仅需1-2次模型提议，耗时14-55秒。

**Conclusion:** 这些结果表明LLMs具有潜在的逻辑推理能力，可以帮助自动化循环不变量的合成。尽管实验主要针对C语言程序，但该方法应可推广到其他命令式语言。

> **ai_Abstract:** 本文提出了一个混合框架，结合了推理优化的LLMs（如OpenAI的O1系列）和SMT求解器（Z3），以自动化循环不变量的合成。该框架采用生成-检查管道，利用求解器反例迭代细化不变量。在Code2Inv基准测试中，该方法在133个C程序任务上达到了100%的覆盖率，显著优于现有最佳方法，并证明了LLMs在逻辑推理方面的潜力，为程序正确性证明提供了新的自动化途径。

> **摘要翻译:** 循环不变量对于证明带有循环的程序的正确性至关重要。开发循环不变量具有挑战性，并且对于任意程序，无法保证完全自动合成。一些方法被提出来使用符号技术合成循环不变量，最近也出现了使用神经方法。这些方法只能在标准基准测试的子集上正确合成循环不变量。在这项工作中，我们研究了现代的、推理优化的大型语言模型是否能做得更好。我们将OpenAI的O1、O1-mini和O3-mini集成到一个与Z3 SMT求解器紧密耦合的生成-检查管道中，利用求解器反例迭代地指导不变量细化。我们使用Code2Inv基准测试，它提供了C程序及其形式化的前置条件和后置条件。在这个包含133个任务的基准测试上，我们的框架实现了100%的覆盖率（133个中的133个），超越了之前最佳的133个中的107个，同时每个实例仅需1-2次模型提议，墙钟时间为14-55秒。这些结果表明LLMs具有潜在的逻辑推理能力，可以帮助自动化循环不变量的合成。虽然我们的实验针对C语言特定程序，但这种方法应该可以推广到其他命令式语言。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [655] [On the Number of Quantifiers Needed to Define Boolean Functions](https://arxiv.org/abs/2407.00688)
> *定义布尔函数所需量词的数量*

*Marco Carmosino, Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta* | **Category: cs.LO, cs.CC** | **Updated: 2025-07-31**

**Keywords:** 量词数量, 布尔函数, 多结构博弈, 并行博弈, 一阶逻辑

**Comment:** Full version of version that is to appear in Proceedings of 49th
  International Symposium on Mathematical Foundations of Computer Science,
  2024. arXiv admin note: substantial text overlap with arXiv:2402.10293

> **TL;DR:** 本文通过分析多结构博弈在有序二元字符串上的应用，并引入“并行博弈”技术，为定义布尔函数所需的一阶量词数量提供了紧密的上界。

**AI_Comments:** 本文在解决量词数量这一经典难题上取得了重要进展，特别是在处理历来难以分析的有序结构方面。通过引入“并行博弈”这一新颖技术，成功地为定义布尔函数提供了一系列紧密的量词上界，其中对所有布尔函数的界限与Lupanov的电路规模上界具有类比性，显示了其理论重要性。

<details>
  <summary>Details</summary>

**Motivation:** 表达一阶性质所需量词的数量由多结构博弈决定，而有序结构（如字符串）在这些博弈中历来难以分析。本研究旨在克服这一困难并为布尔函数量词数量提供界限。

**Method:** 本文通过分析在带有序关系的二元字符串上的多结构博弈来研究量词数量，并引入了一种名为“并行博弈”的技术，该技术在许多情况下能显著减少所需量词的数量。

**Result:** 为表征不同大小的字符串子集所需的量词数量提供了本质上紧密（tight）的上界。这些结果立即给出了定义几种不同类别的布尔函数所需的量词数量的界限。证明了在$n$位输入上的每个布尔函数都可以由具有$(1 + \varepsilon)n\log(n) + O(1)$量词的一阶句子定义，并且这个界限本质上是紧密的。当布尔函数是稀疏时，将所需量词数量减少到$(1 + \varepsilon)\log(n) + O(1)$。

**Conclusion:** 本文成功地为定义布尔函数所需的一阶量词数量提供了本质上紧密的上界，包括普适情况和稀疏布尔函数的情况，解决了在有序结构上分析量词数量的难题。

> **ai_Abstract:** 本文研究了定义一阶（FO）性质所需量词的数量，特别是在有序二元字符串上的多结构博弈。针对传统上难以分析的有序结构，作者引入了“并行博弈”技术，从而显著减少了所需量词。研究提供了表征字符串子集所需量词的紧密上界，并进一步推导了定义不同类别布尔函数所需的量词界限。核心成果包括证明了所有$n$位布尔函数可用$(1 + \varepsilon)n\log(n) + O(1)$量词定义，且此界限紧密；对于稀疏布尔函数，量词数量可降至$(1 + \varepsilon)\log(n) + O(1)$。

> **摘要翻译:** 表达一阶（FO）性质所需量词的数量由双人组合博弈（称为多结构博弈）来衡量。我们使用一种称为并行博弈的技术，分析了这些博弈在带有序关系的二元字符串上的表现，该技术在许多情况下显著减少了所需量词的数量。像字符串这样的有序结构在这些和类似博弈的背景下，历来难以分析。尽管如此，本文为表征不同大小的字符串子集所需的量词数量提供了本质上紧密（tight）的上界。这些结果立即给出了定义几种不同类别的布尔函数所需的量词数量的界限。我们的一个结果类似于卢帕诺夫在命题逻辑中关于电路规模和公式规模的上界：我们证明了在$n$位输入上的每个布尔函数都可以由具有$(1 + \varepsilon)n\log(n) + O(1)$量词的一阶句子定义，并且这个界限本质上是紧密的。当布尔函数是稀疏时，我们将这个数量减少到$(1 + \varepsilon)\log(n) + O(1)$。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [764] [Cobblestone: Iterative Automation for Formal Verification](https://arxiv.org/abs/2410.19940)
> *Cobblestone：形式化验证的迭代自动化*

*Saketh Ram Kasibatla, Arpan Agarwal, Yuriy Brun, Sorin Lerner, Talia Ringer, Emily First* | **Category: cs.LO, cs.AI, cs.PL** | **Updated: 2025-07-31**

**Keywords:** 形式化验证, 证明合成, 大型语言模型, 自动化, Coq

**Comment:** 14 pages, 14 figures

> **TL;DR:** Cobblestone通过迭代的、分而治之的方法，利用大型语言模型自动生成形式化证明，显著提高了自动化验证的效率和能力。

**AI_Comments:** Cobblestone的创新之处在于其迭代的“分而治之”策略，以及在利用LLM的强大生成能力的同时，通过结构化迭代来克服LLM固有的不可靠性，从而保证证明的可靠性。这对于降低形式化验证的门槛，使其更广泛地应用于软件开发具有重要意义。其成本效益和与现有工具的兼容性也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 形式化验证虽然能有效提高软件质量，但需要大量的精力和专业知识。现有机器学习工具虽能自动合成证明，但成功率有限。本研究旨在通过结合大型语言模型（LLM）和迭代方法，克服这些挑战，提高形式化证明的自动化程度和成功率。

**Method:** Cobblestone采用分而治之的证明合成方法。它利用大型语言模型（LLM）生成潜在证明，然后将复杂问题分解为更简单的部分。系统会自动识别哪些部分已成功证明，并对剩余部分进行迭代处理，以构建一个可靠的、即使依赖于不可靠LLM也能保证正确性的证明。该方法还支持结合来自用户或其他工具的外部输入，例如证明结构或相关引理。

**Result:** 在四个开源Coq项目基准测试中，Cobblestone在全自动情况下表现优于最先进的非LLM工具，并能证明许多其他基于LLM的工具无法证明的定理，甚至在多个基准测试中超越它们。每次运行平均成本为1.25美元，耗时14.7分钟。当结合外部输入（如预言机）时，Cobblestone的定理证明成功率可达58%。

**Conclusion:** 本研究表明，工具可以通过利用部分进展和外部输入，更有效地实现形式化验证的自动化。

> **ai_Abstract:** Cobblestone是一种创新的分而治之方法，利用大型语言模型（LLM）实现形式化验证的自动化证明合成。它通过迭代生成、分解和完善证明，即使依赖于不完全可靠的LLM也能确保证明的可靠性。实验表明，Cobblestone在自动化性能上超越了现有工具，显著提高了形式化验证的效率和可及性，尤其是在结合外部输入时表现更佳。

> **摘要翻译:** 使用Coq等证明助手进行形式化验证是提高软件质量的有效方法，但需要大量的精力和专业知识。机器学习可以自动合成证明，但此类工具只能证明所需软件属性的一小部分。我们引入了Cobblestone，这是一种用于证明合成的分而治之的方法。Cobblestone使用大型语言模型（LLM）生成潜在证明，利用这些证明将问题分解为更简单的部分，自动识别其中哪些部分已成功证明，并对剩余部分进行迭代，以构建一个正确的证明，尽管依赖于不可靠的LLM，但仍能保证其可靠性。我们在四个开源Coq项目基准测试上评估了Cobblestone，并控制了训练数据泄露。在全自动情况下，Cobblestone的表现优于最先进的非LLM工具，并且能够证明许多其他基于LLM的工具无法证明的定理，在许多基准测试中表现更优。每次Cobblestone运行平均仅花费1.25美元，耗时14.7分钟。Cobblestone还可以与来自用户或另一个工具的外部输入一起使用，提供证明结构或相关引理。在有这种预言机的情况下进行评估，Cobblestone证明了高达58%的定理。总的来说，我们的研究表明，工具可以利用部分进展和外部输入，更有效地自动化形式化验证。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [831] [Prophecies all the Way: Game-based Model-Checking for HyperQPTL beyond $\forall^*\exists^*$](https://arxiv.org/abs/2504.08575)
> *一路预言：超越$orall^*	ext{E}^*$的HyperQPTL的基于博弈的模型检测*

*Sarah Winter, Martin Zimmermann* | **Category: cs.LO, cs.FL** | **Updated: 2025-07-31**

**Keywords:** HyperQPTL, 模型检测, 基于博弈, 不完全信息博弈, Skolem函数

**Comment:** 

> **TL;DR:** 本文通过不完全信息博弈，将基于博弈的模型检测方法扩展到完整的HyperQPTL，从而支持任意量词前缀并生成有限状态的Skolem函数。

**AI_Comments:** 这项工作通过将基于博弈的模型检测方法从受限片段扩展到更具表现力的时态逻辑（HyperQPTL），展现了创新性。在此背景下，不完全信息博弈的应用是一种新颖的技术。作为副产品获得的用于解释的有限状态Skolem函数对于实际应用特别有价值，因为它有助于理解复杂的性质行为。这可能为TOWER完备问题提供比经典自动机理论方法更直观且可能更高效的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** HyperLTL的模型检测问题虽然可判定但TOWER完备，且经典算法是基于自动机的。最近提出了针对$orall^*	ext{E}^*$片段的基于博弈的方法，本文旨在将这种基于博弈的方法扩展到具有任意量词前缀并能表达所有$	ext{w}$-正则超性质的完整HyperQPTL。

**Method:** 本文采用不完全信息博弈来扩展基于博弈的模型检测方法，使其适用于完整的HyperQPTL。

**Result:** 本文提出了一个针对完整HyperQPTL的基于博弈的算法。作为该算法的副产品，通过具有前瞻功能的传感器获得了Skolem函数的有限状态实现，这些实现能够解释HyperQPTL性质的满足或违反。

**Conclusion:** 本文成功地将基于博弈的模型检测方法扩展到了完整的HyperQPTL，为验证复杂的超性质提供了一种新方法，并产生了可解释的Skolem函数。

> **ai_Abstract:** 本文将先前仅限于HyperLTL的$orall^*	ext{E}^*$片段的基于博弈的模型检测方法，通过利用不完全信息博弈，扩展到了完整的HyperQPTL。这种新方法能够处理任意量词前缀和对命题的量化，涵盖了所有$	ext{w}$-正则超性质。一个重要的副产品是，通过传感器推导出了Skolem函数的有限状态实现，这些实现能够解释HyperQPTL性质的满足或违反。

> **摘要翻译:** HyperLTL是一种时态逻辑，用于表达轨迹集合的性质，并应用于基于信息流的安全和隐私。其模型检测问题是可判定的，但却是TOWER完备的。虽然针对完整HyperLTL的经典模型检测算法是基于自动机的，但最近已经提出了针对$orall^*	ext{E}^*$片段的基于博弈的替代方法。
本文采用不完全信息博弈，将基于博弈的方法扩展到完整的HyperQPTL。HyperQPTL具有任意量词前缀和对命题的量化，并且可以表达每个$	ext{w}$-正则超性质。作为我们基于博弈算法的副产品，我们通过具有前瞻的传感器获得了Skolem函数的有限状态实现，这些实现解释了HyperQPTL性质的满足或违反。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [157] [Causal-Inspired Multi-Agent Decision-Making via Graph Reinforcement Learning](https://arxiv.org/abs/2507.23080)
> *基于图强化学习的因果启发式多智能体决策*

*Jing Wang, Yan Jin, Fei Ding, Chongfeng Wei* | **Category: cs.MA** | **Updated: 2025-07-30**

**Keywords:** 因果学习, 多智能体决策, 图强化学习, 自动驾驶, 因果解耦

**Comment:** 

> **TL;DR:** 本研究通过结合因果解耦表示学习和图神经网络，提升了多智能体自动驾驶在复杂交通场景中的决策能力，尤其是在无信号交叉口。

**AI_Comments:** 该论文的创新之处在于将因果学习与图强化学习相结合，通过因果解耦表示学习来识别和利用影响决策的关键因果特征。这种方法有望提高多智能体自动驾驶系统在复杂交互环境中的安全性和效率，特别是在处理因果关系复杂的交通场景方面具有重要意义。其贡献在于提供了一种更鲁棒、更具解释性的决策框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动驾驶研究难以解决多车辆无缝交互环境中的挑战。

**Method:** 本研究将因果学习与强化学习方法相结合，利用因果解耦表示学习（CDRL）识别并提取影响自动驾驶车辆最佳决策的因果特征。这些特征被整合到基于图神经网络的强化学习算法中，以增强复杂交通场景中的决策能力。该方法将因果特征作为输入，优化了车辆在无信号交叉口的行驶行为。

**Result:** 实验结果表明，所提出的方法在训练期间获得了最高的平均奖励，并且在碰撞率和测试期间的平均累积奖励等多个关键指标上显著优于其他基于学习的方法。

**Conclusion:** 本研究为推进多智能体自动驾驶系统提供了一个有前景的方向，使自动驾驶车辆在复杂交通环境中导航更安全、更高效。

> **ai_Abstract:** 本研究提出了一种将因果学习与图强化学习相结合的新方法，旨在解决多智能体自动驾驶中的决策挑战。通过利用因果解耦表示学习提取关键因果特征，并将其输入到图神经网络中，该方法显著提升了车辆在复杂交通场景（特别是无信号交叉口）的决策性能，在碰撞率和累积奖励方面优于现有方法，为多智能体自动驾驶系统的发展提供了新思路。

> **摘要翻译:** 自自动驾驶技术问世以来，在过去十年中取得了显著进展。然而，大多数现有研究仍然难以解决多车辆必须无缝交互的环境所带来的挑战。本研究旨在通过利用因果解耦表示学习（CDRL）来识别和提取影响自动驾驶车辆最佳决策的因果特征，从而将因果学习与基于强化学习的方法相结合。然后，这些特征被整合到基于图神经网络的强化学习算法中，以增强复杂交通场景中的决策能力。通过使用因果特征作为输入，所提出的方法能够优化车辆在无信号交叉口的行驶行为。实验结果表明，我们提出的方法在训练期间实现了最高的平均奖励，并且在测试期间，我们的方法在碰撞率和平均累积奖励等几个关键指标上显著优于其他基于学习的方法。这项研究为推进多智能体自动驾驶系统提供了一个有前景的方向，并使自动驾驶车辆在复杂交通环境中导航更安全、更高效。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [200] [Barriers to Healthcare: Agent-Based Modeling to Mitigate Inequity](https://arxiv.org/abs/2507.23644)
> *医疗保健障碍：基于Agent的建模以减轻不平等*

*Alba Aguilera, Georgina Curto, Nardine Osman* | **Category: cs.MA** | **Updated: 2025-07-31**

**Keywords:** 基于Agent的建模, 能力方法, 强化学习, 健康不平等, 政策评估

**Comment:** 

> **TL;DR:** 本文通过将能力方法（CA）与强化学习环境相结合，提出了一个基于Agent的模拟模型，用于评估旨在减轻巴塞罗那无家可归人口健康不平等的政策。这是首个与CA对齐的模拟概念验证，用于评估人类发展政策的影响。

**AI_Comments:** 该论文的创新点在于将诺贝尔经济学奖得主阿马蒂亚·森提出的“能力方法”（Capability Approach）与基于Agent的建模和强化学习相结合，为社会政策评估提供了一个更具人文关怀和理论深度的框架。这种结合使得模型不仅关注结果，更关注个体实现其潜能的能力，从而对不平等的衡量和政策效果的评估提供了新的视角。其应用于健康不平等缓解的案例研究，特别是针对弱势群体（无家可归者），显示了该方法的实际应用价值和潜在社会影响力。未来研究可以进一步探索该模型在不同社会挑战和政策情境下的普适性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 基于Agent的模拟在非侵入性地评估社会政策方面具有巨大潜力，但在建模Agent行为和衡量不平等的标准方面存在挑战。本文旨在通过整合能力方法（CA）来解决这些挑战，以更好地指导模拟和评估政策，从而应对紧迫的人类发展挑战。

**Method:** 本文将能力方法（CA）的概念框架整合到模拟中，以指导模拟并评估政策有效性。研究定义了一个强化学习环境，其中Agent在特定政策的约束下恢复其能力。该模型与当地利益相关者、非营利组织和领域专家合作，应用于巴塞罗那无家可归人口的健康不平等缓解案例研究。

**Result:** 研究提出了首个与人类发展能力方法（CA）对齐的概念验证模拟，用于评估议会正在讨论的政策影响。该模型成功应用于巴塞罗那无家可归人口的健康不平等缓解案例研究。

**Conclusion:** 本文证明了将能力方法（CA）整合到基于Agent的模拟中，能够有效地评估旨在缓解人类发展挑战（如健康不平等）的政策，为政策制定者提供有价值的工具。

> **ai_Abstract:** 本文提出了一种新的基于Agent的模拟方法，该方法整合了能力方法（CA）和强化学习，以更有效地评估社会政策。针对现有Agent模拟在行为建模和不平等衡量方面的局限性，研究构建了一个Agent在政策约束下恢复能力的强化学习环境。该模型在一个案例研究中被应用，旨在减轻巴塞罗那无家可归人口的健康不平等，并成功展示了其作为首个与CA对齐的概念验证模拟，用于评估人类发展政策影响的潜力。

> **摘要翻译:** 基于Agent的模拟作为一种在政策实际实施到真实人群之前，以非侵入性方式评估社会政策的工具，具有巨大的潜力。然而，这些计算方法为解决紧迫的人类发展挑战可能提供的建议，会根据我们如何建模Agent（人）的行为以及我们用来衡量不平等的标准而发生显著变化。在本文中，我们整合了能力方法（CA）的概念框架，该框架明确旨在促进和评估人类福祉，以指导模拟并评估政策的有效性。我们定义了一个强化学习环境，其中Agent在特定政策的约束下行为以恢复其能力。通过与当地利益相关者、非营利组织和领域专家合作，我们将模型应用于一个案例研究，以减轻巴塞罗那无家可归人口（PEH）的健康不平等。通过这样做，我们提出了第一个与人类发展能力方法（CA）对齐的概念验证模拟，用于评估议会正在讨论的政策影响。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [720] [A survey of multi-agent geosimulation methodologies: from ABM to LLM](https://arxiv.org/abs/2507.23694)
> *多智能体地理模拟方法综述：从ABM到LLM*

*Virginia Padilla, Jacinto Dávila* | **Category: cs.MA, cs.AI, 68T42, I.2.11** | **Updated: 2025-07-31**

**Keywords:** 多智能体地理模拟, ABM, LLM, 智能体组件, 框架

**Comment:** 20 pages, 1 table

> **TL;DR:** 本文综述了多智能体地理模拟方法，并提出大型语言模型（LLM）可以作为智能体组件有效地融入地理模拟系统，为下一代系统提供坚实平台。

**AI_Comments:** 本文的创新之处在于提出了将大型语言模型（LLM）整合到多智能体地理模拟系统中的可能性，并强调了为此所需的结构化架构。这对于推动地理模拟领域的发展，特别是创建更智能、更具适应性的模拟系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在全面审视编码多智能体系统、模拟和信息系统底层原理和联系的基于智能体的方法，并确认一个用于地理模拟平台的正式规范框架。

**Method:** 本文基于二十年的研究，提供对基于智能体方法的全面考察，并确认了一个旨在作为地理模拟平台正式规范的框架。研究发现，大型语言模型（LLM）如果遵循特定于基本智能体活动（如感知、记忆、规划和行动）的结构化架构，则可以有效地作为智能体组件被整合。

**Result:** 研究结果表明，大型语言模型（LLM）如果遵循特定于基本智能体活动（如感知、记忆、规划和行动）的结构化架构，可以有效地作为智能体组件被整合。这种整合与本文形式化的架构精确一致。

**Conclusion:** 通过将大型语言模型（LLM）作为智能体组件融入，并遵循本文形式化的架构，为下一代地理模拟系统提供了一个坚实的平台。

> **ai_Abstract:** 本文对多智能体地理模拟方法进行了全面综述，并基于二十年的研究，确认了一个用于地理模拟平台的正式框架。研究发现，大型语言模型（LLM）可以遵循特定架构有效地整合为智能体组件，这种整合与本文形式化的架构一致，为构建下一代地理模拟系统奠定了基础。

> **摘要翻译:** 我们对编码多智能体系统、模拟和信息系统底层原理和联系的基于智能体的方法进行了全面审视。基于二十年的研究，本文确认了一个旨在作为地理模拟平台正式规范的框架。我们的研究结果表明，大型语言模型（LLM）如果遵循特定于基本智能体活动（如感知、记忆、规划和行动）的结构化架构，则可以有效地作为智能体组件被整合。这种整合与我们形式化的架构精确一致，为下一代地理模拟系统提供了一个坚实的平台。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [207] [HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction](https://arxiv.org/abs/2506.10006)
> *通过动态双向重建实现灵活多模态输入的HER2表达预测*

*Jie Qin, Wei Yang, Yan Su, Yiran Zhu, Weizhen Li, Yunyue Pan, Chengchang Pan, Honggang Qi* | **Category: cs.MM, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** HER2, 多模态, 乳腺癌, 图像分析, GAN

**Comment:** 8 pages,6 figures,3 tables,accepted by the 33rd ACM International
  Conference on Multimedia(ACM MM 2025)

> **TL;DR:** 提出一种灵活支持单模态或双模态输入的HER2预测框架，通过动态重建缺失模态，显著提高评估准确性和可及性。

**AI_Comments:** 该研究的创新之处在于其灵活的多模态输入处理能力，特别是在缺失模态时通过跨模态GAN进行特征空间重建，有效解决了临床实践中图像获取的限制和成本问题。其提出的“双模态优先，单模态兼容”架构，在不强制同步采集的情况下，显著提升了HER2评估的准确性和可及性，对资源受限地区尤其重要。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺癌HER2评估依赖H&E和IHC图像，但同时获取这两种模态常常受到临床限制和成本的阻碍。

**Method:** 提出一种自适应双模态预测框架，通过动态分支选择器（根据输入可用性激活模态补全或联合推理）和跨模态GAN（CM-GAN，用于缺失模态的特征空间重建）实现单模态或双模态输入。

**Result:** H&E单模态准确率从71.44%显著提升至94.25%，双模态输入达到95.09%，单模态条件下保持90.28%的可靠性。

**Conclusion:** 该“双模态优先，单模态兼容”架构在无需强制同步采集的情况下，实现了接近双模态的准确性，为资源受限地区提供了经济高效的解决方案，显著提高了HER2评估的可及性。

> **ai_Abstract:** 本文针对HER2评估中H&E和IHC图像获取的成本和限制问题，提出一种自适应双模态预测框架。该框架通过动态分支选择器和跨模态GAN，灵活支持单模态或双模态输入，显著将仅H&E图像的准确率从71.44%提升至94.25%，双模态输入下达到95.09%。该方案无需强制同步采集，提供了经济高效的解决方案，显著提高了HER2评估的可及性。

> **摘要翻译:** 在乳腺癌HER2评估中，临床评估依赖于H&E和IHC图像的结合，然而同时获取这两种模态常常受到临床限制和成本的阻碍。我们提出了一种自适应双模态预测框架，通过两项核心创新灵活支持单模态或双模态输入：一个动态分支选择器，根据输入可用性激活模态补全或联合推理；以及一个跨模态GAN（CM-GAN），能够实现缺失模态的特征空间重建。这种设计显著将仅H&E图像的准确率从71.44%提高到94.25%，在完整的双模态输入下达到95.09%，并在单模态条件下保持90.28%的可靠性。这种“双模态优先，单模态兼容”的架构在不强制同步采集的情况下，提供了接近双模态的准确性，为资源受限地区提供了经济高效的解决方案，并显著提高了HER2评估的可及性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [332] [MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for Document Question-Answering with Hierarchical Index and Multi-Granularity Retrieval](https://arxiv.org/abs/2508.00579)
> *MMRAG-DocQA：一种用于文档问答的多模态检索增强生成方法，结合分层索引和多粒度检索*

*Ziyu Gong, Yihua Huang, Chengcheng Mai* | **Category: cs.MM, cs.IR** | **Updated: 2025-08-01**

**Keywords:** 多模态RAG, 文档问答, 分层索引, 多粒度检索

**Comment:** 

> **TL;DR:** MMRAG-DocQA提出了一种结合分层索引和多粒度检索的多模态RAG方法，以解决长上下文多模态文档问答中现有方法的幻觉、模态间断裂和跨页碎片化问题，并在公共数据集上表现出优越性。

**AI_Comments:** 该论文提出了一种创新的多模态RAG框架，通过分层索引和多粒度检索有效地解决了长文档多模态问答中模态间断裂和跨页信息碎片化两大核心挑战。其将文本与视觉信息深度融合，并结合LLM进行语义重排序，提升了问答的准确性和鲁棒性，对于多模态信息检索和生成领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态长上下文文档问答方法存在问题：基于大型视觉语言模型（LVLM）的方法容易产生幻觉；基于检索增强生成（RAG）的方法难以处理模态间断裂和跨页碎片化问题。

**Method:** 提出了一种名为MMRAG-DocQA的新型多模态RAG模型。该模型利用文本和视觉信息进行长距离跨页问答。它设计了一种分层索引方法，整合了扁平化的页内块和拓扑的跨页块，以建立页内多模态关联和长距离跨页依赖。通过联合相似度评估和基于大型语言模型（LLM）的重排序，提出了一种多粒度语义检索方法，包括页级父页检索和文档级摘要检索，以促进多模态证据连接和长距离证据集成与推理。

**Result:** 在公共数据集MMLongBench-Doc和LongDocURL上的实验结果表明，MMRAG-DocQA方法在理解和回答富含模态和多页文档方面表现出优越性。

**Conclusion:** MMRAG-DocQA方法能够有效解决多模态长上下文文档问答中的挑战，并在处理复杂文档方面展现出卓越的性能。

> **ai_Abstract:** MMRAG-DocQA是一种针对多模态长上下文文档问答任务提出的新型检索增强生成（RAG）模型。它旨在解决现有LVLM方法易产生幻觉和RAG方法面临模态间断裂及跨页碎片化的问题。该模型引入了分层索引方法，结合页内和跨页信息，并采用多粒度语义检索策略，通过LLM重排序实现证据的有效连接与整合。实验证明，MMRAG-DocQA在处理复杂多模态文档问答方面表现出优越性能。

> **摘要翻译:** 多模态长上下文文档问答任务旨在定位和整合分布在多页上的多模态证据（如文本、表格、图表、图像和布局），以进行问题理解和答案生成。现有方法可分为基于大型视觉语言模型（LVLM）的方法和基于检索增强生成（RAG）的方法。然而，前者容易产生幻觉，而后者则面临模态间断裂和跨页碎片化的问题。为了应对这些挑战，本文提出了一种新颖的多模态RAG模型，名为MMRAG-DocQA，该模型利用长距离页面的文本和视觉信息来促进准确的问答。设计了一种分层索引方法，结合了扁平化的页内块和拓扑的跨页块，以共同建立页内多模态关联和长距离跨页依赖。通过联合相似度评估和基于大型语言模型（LLM）的重排序，提出了一种多粒度语义检索方法，包括页级父页检索和文档级摘要检索，以促进多模态证据连接和长距离证据集成与推理。在公共数据集MMLongBench-Doc和LongDocURL上进行的实验结果表明，我们的MMRAG-DocQA方法在理解和回答富含模态和多页文档方面表现出优越性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [553] [Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models for Wireless Networks](https://arxiv.org/abs/2502.05695)
> *使用潜在扩散模型实现无线网络中语义感知自适应视频流*

*Zijiang Yan, Jianhua Pei, Hongda Wu, Hina Tabassum, Ping Wang* | **Category: cs.MM, cs.AI, cs.CV, cs.LG, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 语义通信, 潜在扩散模型, 自适应视频流, 无线网络, 体验质量

**Comment:** Accepted in IEEE Wireless Communications

> **TL;DR:** 本文提出了一种结合潜在扩散模型（LDMs）和FFmpeg的语义通信（SemCom）框架，用于解决传统视频流中带宽、存储和QoE问题，实现高效高质量的自适应视频流，尤其适用于无线网络。

**AI_Comments:** 这项工作的创新点在于将潜在扩散模型引入视频流的语义通信框架中，特别是利用LDM对I帧进行高效压缩，并通过结合传统FFmpeg技术、去噪和VFI技术来优化整体性能。其重要性在于为无线网络中的实时自适应视频流提供了更高效、高质量的解决方案，有望显著降低带宽需求并提升用户体验，尤其是在5G及未来网络中具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 传统恒定比特率流（CBS）和自适应比特率流（ABS）存在高带宽使用、存储效率低下以及体验质量（QoE）下降的问题。

**Method:** 本文提出了一种新颖的语义通信（SemCom）框架，通过将潜在扩散模型（LDMs）与FFmpeg技术相结合，实现实时自适应比特率视频流。该方法利用LDMs将I帧压缩到潜在空间，同时保留B帧和P帧作为调整元数据，支持用户端高效的视频重建。此外，框架还结合了先进的去噪和视频帧插值（VFI）技术，以减轻语义模糊并在嘈杂的无线通信环境中恢复帧间时间一致性。

**Result:** 实验结果表明，所提出的方法实现了高质量的视频流，并优化了带宽使用，在QoE和资源效率方面优于现有最先进的解决方案。

**Conclusion:** 这项工作为5G和未来的后5G网络中的可扩展实时视频流开辟了新的可能性。

> **ai_Abstract:** 本文提出了一种基于潜在扩散模型（LDMs）和FFmpeg的语义通信（SemCom）框架，旨在解决传统视频流中高带宽消耗、存储低效和QoE差的问题。该框架通过LDM压缩I帧以节省资源，并利用B/P帧及去噪、VFI技术优化视频重建和时间一致性。实验证明，该方法在带宽优化和QoE方面优于现有技术，为5G及未来网络中的可扩展实时视频流提供了新途径。

> **摘要翻译:** 本文提出了一种新颖的语义通信（SemCom）框架，通过将潜在扩散模型（LDMs）与FFmpeg技术相结合，实现实时自适应比特率视频流。该解决方案解决了与传统恒定比特率流（CBS）和自适应比特率流（ABS）相关的高带宽使用、存储效率低下和体验质量（QoE）下降的挑战。所提出的方法利用LDMs将I帧压缩到潜在空间，在不牺牲高视觉质量的情况下显著节省了存储和语义传输。在保留B帧和P帧作为调整元数据以支持用户端高效视频重建的同时，所提出的框架进一步结合了最先进的去噪和视频帧插值（VFI）技术。这些技术即使在嘈杂的无线通信环境中也能减轻语义模糊并恢复帧间时间一致性。实验结果表明，所提出的方法实现了高质量的视频流，并优化了带宽使用，在QoE和资源效率方面优于现有最先进的解决方案。这项工作为5G和未来的后5G网络中的可扩展实时视频流开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [22] [From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems](https://arxiv.org/abs/2507.22916)
> *从传播器到振荡器：对称微分方程在神经系统中的双重作用*

*Kun Jiang* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-20**

**Keywords:** 对称微分方程, 神经元模型, 功能对偶性, 信号传播器, 振荡器

**Comment:** 20 pages, 7 figures

> **TL;DR:** 本文深入研究了一种基于对称微分方程的新型神经元模型，发现其具有信号传播器和信号发生器（振荡器）的双重功能，并通过参数调整或连接结构修改实现功能模式转换，为神经形态工程提供了理论基础和应用路线图。

**AI_Comments:** 本文在先前工作的基础上，创新性地揭示了新型神经元模型的功能对偶性，即既能作为信号传播器，又能作为信号发生器。通过引入“在途能量”这一中间状态度量，提高了系统状态的可监测性和可预测性。研究结果与生物神经元的双重作用建立了强有力的联系，为神经形态工程提供了新的理论视角和潜在的应用方向，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文在前人工作的基础上，深入探讨了一种基于对称微分方程的新型神经元模型的内在动力学和功能多样性，旨在揭示其核心功能对偶性，并为神经形态工程中的应用提供理论基础。

**Method:** 通过系统探索参数空间，运用多种数学分析工具，理论上揭示了系统的功能对偶性。引入了一种名为“在途能量”的新型中间状态度量来监测和预测系统状态。通过模拟实验验证了功能模式转换以及外部信号对振荡的抑制作用。

**Result:** 该模型展现出两种截然不同的轨迹行为：一种是渐近稳定，对应可靠的信号传播器；另一种是李雅普诺夫稳定，表现为持续的自激振荡，充当信号发生器。引入了“在途能量”作为中间状态度量。模拟结果证实，两种功能模式之间的转换可以通过参数调整或连接结构修改来诱导。此外，外部信号可以有效抑制振荡。

**Conclusion:** 这些发现与生物神经元在信息传输和节律生成中的双重作用形成了令人信服的类比，从而为该模型在神经形态工程中的广泛应用建立了坚实的理论基础和清晰的功能路线图。

> **ai_Abstract:** 本研究深入探讨了一种基于对称微分方程的新型神经元模型，揭示了其作为信号传播器和信号发生器的功能对偶性。通过参数空间探索和数学分析，发现模型具有渐近稳定（传播器）和李雅普诺夫稳定（振荡器）两种模式。引入了“在途能量”来监测系统状态，并通过模拟验证了模式转换和外部信号对振荡的抑制作用。研究结果为该模型在神经形态工程中的应用提供了理论基础，并与生物神经元的双重功能相呼应。

> **摘要翻译:** 在我们之前的工作中，我们提出了一种基于对称微分方程的新型神经元模型，并证明了其作为高效信号传播器的潜力。在此基础上，本研究更深入地探讨了该模型的内在动力学和功能多样性。通过系统地探索参数空间并采用一系列数学分析工具，我们理论上揭示了系统功能对偶性的核心特性。具体而言，该模型展现出两种截然不同的轨迹行为：一种是渐近稳定，对应可靠的信号传播器；另一种是李雅普诺夫稳定，其特征是持续的自激振荡，作为信号发生器发挥作用。为了在模拟过程中有效监测和预测系统状态，我们引入了一种名为“在途能量”的新型中间状态度量。模拟结果证实，两种功能模式之间的转换可以通过参数调整或连接结构修改来诱导。此外，我们表明通过引入外部信号可以有效抑制振荡。这些发现与生物神经元在信息传输和节律生成中的双重作用形成了令人信服的类比，从而为该模型在神经形态工程中的广泛应用建立了坚实的理论基础和清晰的功能路线图。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [46] [Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System](https://arxiv.org/abs/2504.10053)
> *合成生物学与神经拟态计算的结合：迈向生物启发式嗅觉感知系统*

*Kevin Max, Larissa Sames, Shimeng Ye, Jan Steinkühler, Federico Corradi* | **Category: cs.NE, cs.ET, q-bio.NC** | **Updated: 2025-08-01**

**Keywords:** 合成生物学, 神经拟态计算, 嗅觉感知, 生物启发, 混合系统

**Comment:** Updated after revision at Neuromorphic Computing and Engineering

> **TL;DR:** 本研究探索了结合合成生物学、神经科学建模和神经拟态电子系统来创建模拟自然嗅觉的人工系统，并提出一个具有受体门控离子通道、生物半导体接口和基于脉冲网络的事件编码与计算功能的混合系统，通过模拟验证，旨在开发超灵敏、特异性、节能的嗅觉检测平台。

**AI_Comments:** 这篇论文通过将合成生物学与神经拟态计算相结合，为人工嗅觉系统的开发提供了一个创新且跨学科的方法。其引入的混合系统概念，特别是生物与半导体接口的设计，具有重要的创新性。该研究的潜在应用领域广泛，显示出其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探索合成生物学、神经科学建模和神经拟态电子系统的结合，以创建一种模仿自然嗅觉的人工系统，并开发一个用于超灵敏、特异性和节能嗅觉检测的平台。

**Method:** 本研究提出了一种结合合成生物学、神经科学建模和神经拟态电子系统的协同设计方法。具体提出了一种具有以下三个关键特征的合成感觉神经元混合系统：(a) 受体门控离子通道，(b) 合成生物学与半导体之间的接口，以及 (c) 基于脉冲网络的事件编码和计算。该方法通过对完整的传感和处理管道进行基于模拟的建模进行验证。

**Result:** 该方法通过对完整的传感和处理管道进行基于模拟的建模得到了验证。本研究旨在开发一个用于超灵敏、特异性和节能嗅觉检测的平台。

**Conclusion:** 本研究通过结合合成生物学、神经科学建模和神经拟态计算，成功探索并验证了一种创建生物启发式嗅觉感知系统的新方法，有望开发出适用于环境监测、医疗诊断和安全领域的超灵敏、特异性、节能的嗅觉检测平台。

> **ai_Abstract:** 本研究探讨了结合合成生物学、神经科学建模和神经拟态电子系统来构建生物启发式人工嗅觉感知系统的新途径。文章提出了一种协同设计方法，并设计了一个包含受体门控离子通道、生物半导体接口以及基于脉冲网络的事件编码和计算功能的合成感觉神经元混合系统。该方法通过模拟验证了其传感和处理流程，旨在开发一个用于超灵敏、特异性和节能嗅觉检测的平台，具有广泛的应用前景。

> **摘要翻译:** 在这项研究中，我们探索了合成生物学、神经科学建模和神经拟态电子系统的结合如何为创建模拟自然嗅觉的人工系统提供一种新方法。我们认为，协同设计方法在复制嗅觉传感和处理的复杂动态方面具有显著优势。我们提出了一种合成感觉神经元的混合系统，该系统提供三个关键特征：(a) 受体门控离子通道，(b) 合成生物学与半导体之间的接口，以及 (c) 基于脉冲网络的事件编码和计算。我们的方法通过对完整的传感和处理管道进行基于模拟的建模得到了验证。这项研究旨在开发一个用于超灵敏、特异性和节能嗅觉检测的平台，对环境监测、医疗诊断和安全领域具有潜在影响。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [536] [Preprocessing Methods for Memristive Reservoir Computing for Image Recognition](https://arxiv.org/abs/2506.05588)
> *忆阻器储层计算用于图像识别的预处理方法*

*Rishona Daniels, Duna Wattad, Ronny Ronen, David Saad, Shahar Kvatinsky* | **Category: cs.NE, cs.AR, cs.ET** | **Updated: 2025-07-31**

**Keywords:** 忆阻器, 储层计算, 图像识别, 预处理, 准确性

**Comment:** 6 pages, 5 figures, Accepted for presentation in IEEE MetroXRAINE
  2025 conference

> **TL;DR:** 本文系统比较了忆阻器储层计算（RC）中不同的预处理方法，并提出了一种基于奇偶校验的预处理方法，该方法在图像识别中显著提高了准确性。

**AI_Comments:** 本文针对忆阻器储层计算（RC）的关键挑战——预处理方法的影响进行了系统性评估，并提出了一种创新的基于奇偶校验的预处理方法。其创新之处在于不仅进行了对比分析，还通过提出新方法有效提升了系统性能，对推动忆阻器RC在图像识别领域的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 忆阻器储层计算（RC）在实现高性能方面仍面临挑战，其性能关键取决于输入预处理方法和储层大小。目前缺乏对这些因素影响的全面评估。

**Method:** 本文系统比较了忆忆阻器储层计算系统中各种预处理方法，评估它们对准确性和能耗的影响。此外，还提出了一种基于奇偶校验的预处理方法。

**Result:** 研究发现，所提出的基于奇偶校验的预处理方法能够将准确性提高2-6%，且与其它方法相比，仅需适度增加器件数量。研究结果强调了明智的预处理策略对于提高忆阻器储层计算系统效率和可扩展性的重要性。

**Conclusion:** 明智的预处理策略对于提高忆阻器储层计算（RC）系统的效率和可扩展性至关重要，所提出的奇偶校验预处理方法能有效提升图像识别准确性。

> **ai_Abstract:** 本文针对忆阻器储层计算（RC）在图像识别中的性能挑战，系统比较了不同的输入预处理方法及其对准确性和能耗的影响。研究提出了一种新的基于奇偶校验的预处理方法，该方法在仅适度增加器件数量的情况下，将准确性提高了2-6%。研究强调了选择合适的预处理策略对于提升忆阻器RC系统效率和可扩展性的关键作用。

> **摘要翻译:** 储层计算（RC）作为一种高效的循环神经网络架构，因其训练简化，仅需训练最后一个感知器读出层而备受关注。当使用忆阻器实现时，RC系统受益于其动态特性，这使得它们非常适合储层构建。然而，在基于忆阻器的RC中实现高性能仍然具有挑战性，因为它关键取决于输入预处理方法和储层大小。尽管兴趣日益增长，但目前仍缺乏量化这些因素影响的全面评估。本文系统比较了忆阻器RC系统中各种预处理方法，评估它们对准确性和能耗的影响。我们还提出了一种基于奇偶校验的预处理方法，该方法可将准确性提高2-6%，同时与其它方法相比，仅需适度增加器件数量。我们的研究结果强调了明智的预处理策略对于提高忆阻器RC系统效率和可扩展性的重要性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [741] [Reinitializing weights vs units for maintaining plasticity in neural networks](https://arxiv.org/abs/2508.00212)
> *神经网络中为保持可塑性而进行的权重与单元重新初始化比较*

*J. Fernando Hernandez-Garcia, Shibhansh Dohare, Jun Luo, Rich S. Sutton* | **Category: cs.NE, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 可塑性丧失, 持续学习, 权重重新初始化, 单元重新初始化, 神经网络

**Comment:** 

> **TL;DR:** 本文比较了神经网络中重新初始化权重和单元对保持可塑性的影响。研究发现，在小单元网络和包含层归一化的网络中，重新初始化权重比重新初始化单元更有效。

**AI_Comments:** 本文创新性地比较了两种不同的神经网络重初始化策略（权重与单元），并提出了一种新的选择性权重重初始化算法。这项工作对于持续学习领域具有重要意义，因为它提供了一种有效对抗可塑性丧失的方法，并明确指出了在特定网络结构下，重新初始化权重是更优的选择，这为未来的模型设计提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络在非静态数据上长时间训练时会失去学习能力，即失去可塑性，这对于设计持续学习系统是一个关键问题。

**Method:** 本文比较了两种不同的重新初始化方案：重新初始化单元和重新初始化权重。提出了一种新的算法，名为“选择性权重重新初始化”，用于重新初始化网络中最不重要的权重。该算法与两种现有的重新初始化单元的算法（持续反向传播和ReDo）进行了比较。实验在持续监督学习问题中进行。

**Result:** 实验发现，在两种情况下重新初始化权重在保持可塑性方面比重新初始化单元更有效：1) 当网络单元数量较少时；2) 当网络包含层归一化时。当网络规模足够大且不包含层归一化时，重新初始化权重和单元在保持可塑性方面同样有效。总体而言，重新初始化权重在比重新初始化单元更广泛的设置中保持了可塑性。

**Conclusion:** 重新初始化权重比重新初始化单元在更广泛的网络设置中更有效地保持神经网络的可塑性，尤其是在网络单元数量较少或包含层归一化时。

> **ai_Abstract:** 本文研究了在神经网络中通过重新初始化来解决可塑性丧失问题，该问题影响网络在非静态数据上的持续学习能力。论文比较了重新初始化权重和重新初始化单元两种方案，并提出了一种名为“选择性权重重新初始化”的新算法。实验结果表明，在网络单元数量较少或包含层归一化时，重新初始化权重在保持可塑性方面优于重新初始化单元。在其他情况下，两者效果相当。总体而言，重新初始化权重在更广泛的设置中表现出更好的可塑性保持能力。

> **摘要翻译:** 可塑性丧失是指神经网络在非静态数据上长时间训练后失去学习能力的一种现象。在设计持续学习系统时，这是一个必须克服的关键问题。防止可塑性丧失的一种有效技术是重新初始化网络的一部分。在本文中，我们比较了两种不同的重新初始化方案：重新初始化单元与重新初始化权重。我们提出了一种新的算法，命名为“选择性权重重新初始化”，用于重新初始化网络中最无用的权重。我们将我们的算法与持续反向传播和ReDo（两种先前提出的重新初始化网络单元的算法）进行了比较。通过我们在持续监督学习问题中的实验，我们确定了两种情况下，重新初始化权重在保持可塑性方面比重新初始化单元更有效：(1) 当网络具有少量单元时，以及 (2) 当网络包含层归一化时。相反，当网络规模足够大且不包含层归一化时，重新初始化权重和单元在保持可塑性方面同样有效。我们发现，重新初始化权重在比重新初始化单元更广泛的设置中保持了可塑性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [777] [Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics](https://arxiv.org/abs/2508.00229)
> *顺序式、并行式和连续式混合进化-群优化元启发式算法*

*Piotr Urbańczyk, Aleksandra Urbańczyk, Magdalena Król, Leszek Rutkowski, Marek Kisiel-Dorohinicki* | **Category: cs.NE, math.OC, 90C59 (Primary), 90C27, 68T20, 68W10 (Secondary), I.2.8; I.2.6; G.1.6; F.2.1; I.6.6** | **Updated: 2025-08-01**

**Keywords:** 混合元启发式, 粒子群优化, 遗传算法, 高维优化, 收敛性

**Comment:** 16 pages, 2 figures, 5 tables, 5 algorithms, conference

> **TL;DR:** 本文探讨了结合粒子群优化（PSO）和遗传算法（GA）的混合元启发式算法，并在多种基准函数上进行测试。实验结果表明，混合方法在收敛性和一致性方面表现更优，尤其在高维搜索空间中。文章还引入了一种通过显式信息传递机制确保PSO和GA步骤连续性的新型混合PSO-GA进化算法。

**AI_Comments:** 本文的创新点在于系统地探索了多种混合粒子群优化（PSO）和遗传算法（GA）的方式（顺序、并行、连续），并提出了一种通过显式信息传递机制确保连续性的新型混合算法。这种方法有效地结合了两种经典优化算法的优势，特别是在解决高维优化问题时展现出卓越的收敛性和一致性，为复杂问题优化提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索结合粒子群优化（PSO）和遗传算法（GA）特征的混合进化-群元启发式算法，并引入一种新型的连续混合PSO-GA进化算法，以确保PSO和GA步骤之间的连续性。

**Method:** 本文首先探索了将粒子群优化（PSO）和遗传算法（GA）以顺序式、并行式和连续式相结合的混合进化-群元启发式算法，并与标准GA和PSO进行比较。这些算法在一组包括Ackley、Griewank、Levy、Michalewicz、Rastrigin、Schwefel和Shifted Rotated Weierstrass在内的基准函数上进行了多维度测试。其次，本文介绍了一种新颖的连续混合PSO-GA进化算法，该算法通过修改GA的变异算子来继承速度和个体最佳信息，从而实现PSO和GA步骤之间的显式信息传递和连续性。

**Result:** 实验结果表明，混合方法在收敛性和一致性方面表现出优越性，特别是在高维搜索空间中。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文研究了顺序式、并行式和连续式混合进化-群优化元启发式算法，这些算法结合了粒子群优化（PSO）和遗传算法（GA）的优点。通过在多种基准函数上进行多维度测试，结果显示这些混合方法在收敛性和一致性上优于标准算法，尤其在高维问题中表现突出。此外，论文还提出了一种新颖的连续混合PSO-GA算法，通过修改GA的变异算子以传递PSO的速度和个体最佳信息，从而确保了算法步骤间的连续性。

> **摘要翻译:** 本文的目标是双重的。首先，它探讨了结合粒子群优化（PSO）和遗传算法（GA）特征的混合进化-群元启发式算法，以顺序式、并行式和连续式的方式与它们的标准基本形式（遗传算法和粒子群优化）进行比较。这些算法在一组基准函数上进行了测试，包括Ackley、Griewank、Levy、Michalewicz、Rastrigin、Schwefel和Shifted Rotated Weierstrass，跨多个维度。实验结果表明，混合方法实现了卓越的收敛性和一致性，尤其是在高维搜索空间中。本文的第二个目标是引入一种新颖的连续混合PSO-GA进化算法，该算法通过显式信息传递机制确保PSO和GA步骤之间的连续性，具体通过修改GA的变异算子来继承速度和个体最佳信息。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [812] [Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning](https://arxiv.org/abs/2508.00380)
> *进化生成优化：迈向通过生成学习实现的完全数据驱动进化优化*

*Kebin Sun, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan* | **Category: cs.NE** | **Updated: 2025-08-01**

**Keywords:** 进化优化, 生成学习, 数据驱动, 深度学习, 自动化优化

**Comment:** 

> **TL;DR:** EvoGO是一种完全数据驱动的进化优化框架，通过生成模型将劣质解转化为优质解，并在各种任务上展现出卓越的收敛速度和性能。

**AI_Comments:** EvoGO的创新之处在于其完全数据驱动的范式，通过生成学习实现了进化优化的自动化。该方法克服了传统方法对人工启发式规则的依赖，并通过生成模型高效地探索解空间。其在多种任务上的快速收敛和卓越性能显示了其巨大的潜力，尤其是在复杂高维优化问题中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据驱动进化算法大多依赖于手工设计的启发式方法，这限制了它们的通用性和自动化程度。

**Method:** 本文提出了进化生成优化（EvoGO）框架，通过生成学习实现完全数据驱动。EvoGO包含三个阶段：数据准备阶段构建配对数据集以增加训练多样性；模型训练阶段训练一个生成模型将劣质解转化为优质解；种群生成阶段用可扩展且并行的生成机制取代传统繁殖算子。

**Result:** 在数值基准、经典控制问题和高维机器人任务上的广泛实验表明，EvoGO在仅10代内就实现了收敛，并且显著优于包括传统EA、贝叶斯优化和基于强化学习的方法在内的多种优化方法。

**Conclusion:** EvoGO是一个有效的完全数据驱动进化优化框架，能够快速收敛并超越现有多种优化方法。

> **ai_Abstract:** 本文提出了一种名为进化生成优化（EvoGO）的完全数据驱动框架，旨在解决现有数据驱动进化算法对人工启发式方法的依赖问题。EvoGO通过数据准备、模型训练和种群生成三个阶段，利用生成模型将劣质解转化为优质解，并以生成机制取代传统繁殖操作。实验结果表明，EvoGO在多种任务上表现出快速收敛能力和优越的性能，超越了多种现有优化方法。

> **摘要翻译:** 数据驱动进化算法（EAs）的最新进展已证明利用数据提高优化精度和适应性的潜力。然而，大多数现有方法仍然依赖于手工设计的启发式方法，这限制了它们的通用性和自动化程度。为了解决这一挑战，我们提出进化生成优化（EvoGO），一个由生成学习驱动的完全数据驱动框架。EvoGO将进化优化过程简化为三个阶段：数据准备、模型训练和种群生成。数据准备阶段构建配对数据集，以在不产生额外评估成本的情况下丰富训练多样性。在模型训练期间，量身定制的生成模型学习将劣质解转化为优质解。在种群生成阶段，EvoGO用可扩展且并行的生成机制取代了传统的繁殖算子。在数值基准、经典控制问题和高维机器人任务上的广泛实验表明，EvoGO在仅仅10代内就能稳定收敛，并且显著优于各种优化方法，包括传统EAs、贝叶斯优化和基于强化学习的方法。源代码将公开发布。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [847] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
> *STF: 浅层时间反馈以增强脉冲Transformer*

*Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin* | **Category: cs.NE, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 脉冲神经网络, Transformer, 时间反馈, 脉冲编码, 性能增强

**Comment:** 32 pages, 4 figures

> **TL;DR:** STF是一个轻量级即插即用模块，通过浅层时间反馈提高脉冲Transformer的性能，解决了深度反馈的高成本问题。

**AI_Comments:** STF的创新之处在于其“浅层”和“轻量级”设计，有效解决了现有深层反馈机制的成本问题，并通过增强脉冲模式多样性来提升性能，这对于SNNs的实际应用具有重要意义。其即插即用的特性也增加了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 基于Transformer的脉冲神经网络（SNNs）与浮点人工神经网络（ANNs）之间存在显著的性能差距，而现有的深层反馈循环设计通常跨越多个深层，导致昂贵的特征转换、更高的参数开销、增加的能耗和更长的推理延迟。

**Method:** 提出浅层时间反馈（STF）模块，这是一个轻量级即插即用模块，用于编码层，由时间-空间位置嵌入（TSPE）和时间反馈（TF）组成。

**Result:** STF在CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集上，在不同脉冲时间步长设置下，持续提升了各种基于Transformer的SNN骨干网络的性能。进一步分析表明，STF增强了脉冲模式的多样性。在对抗鲁棒性和时间敏感性评估中，STF优于直接编码及其变体。

**Conclusion:** STF作为一种新的脉冲编码方案，在静态场景下具有潜力，能够有效提升基于Transformer的脉冲神经网络的性能，并解决了现有深层反馈机制的缺陷。

> **ai_Abstract:** 本文提出了一种名为STF（浅层时间反馈）的轻量级即插即用模块，旨在弥补基于Transformer的脉冲神经网络（SNNs）与传统人工神经网络（ANNs）之间的性能鸿沟，同时解决现有深层反馈机制带来的高成本问题。STF包含时间-空间位置嵌入（TSPE）和时间反馈（TF），并集成到编码层。实验证明，STF在多个静态数据集（如CIFAR-10、CIFAR-100、ImageNet-1K）上显著提升了基于Transformer的SNNs的性能，并增强了脉冲模式的多样性。此外，STF在对抗鲁棒性和时间敏感性方面表现优异，有望成为静态场景下新的高效脉冲编码方案。

> **摘要翻译:** 基于Transformer的脉冲神经网络（SNNs）由于脉冲序列的二元性质，与浮点人工神经网络（ANNs）存在巨大的性能差距。最近的研究引入了深层反馈循环，以传输高级语义信息来缩小这一差距。然而，这些设计通常跨越多个深层，导致昂贵的特征转换、更高的参数开销、增加的能耗和更长的推理延迟。为了解决这个问题，我们提出了浅层时间反馈（STF），一个用于编码层的轻量级即插即用模块，它由时间-空间位置嵌入（TSPE）和时间反馈（TF）组成。大量实验表明，在不同的脉冲时间步长设置下，STF在CIFAR-10、CIFAR-100和ImageNet-1K等静态数据集上，持续提升了各种基于Transformer的SNN骨干网络的性能。进一步分析揭示，STF增强了脉冲模式的多样性，这是性能提升的关键。此外，对抗鲁棒性和时间敏感性的评估证实，STF优于直接编码及其变体，突显了其作为静态场景下新型脉冲编码方案的潜力。我们的代码将在论文被接受后发布。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [18] [Enabling Immersive XR Collaborations over FTTR Networks (Invited)](https://arxiv.org/abs/2508.00009)
> *沉浸式XR协作在FTTR网络上的实现 (受邀)*

*Sourav Mondal, Elaine Wong* | **Category: cs.NI, cs.AI** | **Updated: 2025-07-21**

**Keywords:** FTTR, XR协作, 沉浸式体验, 带宽分配, 无缝切换

**Comment:** This invited paper was presented in Optica Advanced Photonic Congress
  2025

> **TL;DR:** 本文探讨了在FTTR网络上通过预测带宽分配和无缝切换方案实现高质量沉浸式XR协作的可能性。

**AI_Comments:** 本文的创新点在于将FTTR技术应用于沉浸式XR协作，并提出了具体的网络优化方案（预测带宽分配和无缝切换）。这对于未来XR应用的网络基础设施建设具有重要意义。然而，抽象中未提及具体的实验数据或实现细节。

<details>
  <summary>Details</summary>

**Motivation:** 光纤到房间（FTTR）是实现室内扩展现实（XR）协作的潜在解决方案。

**Method:** 本文探讨了FTTR上的预测带宽分配和无缝切换方案。

**Result:** 结果表明，可以实现室内协作的高质量沉浸式体验。

**Conclusion:** 通过FTTR上的预测带宽分配和无缝切换方案，可以实现高质量的沉浸式室内XR协作。

> **ai_Abstract:** 本文研究了FTTR网络在实现室内沉浸式XR协作方面的潜力。通过探索预测带宽分配和无缝切换方案，研究表明FTTR网络能够支持高质量的室内XR体验。

> **摘要翻译:** 光纤到房间（FTTR）是实现室内扩展现实（XR）协作的潜在解决方案。本文探讨了FTTR上的预测带宽分配和无缝切换方案，表明可以实现室内协作的高质量沉浸式体验。© 2025 作者。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [53] [Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?](https://arxiv.org/abs/2508.00010)
> *非地面网络随机几何模型：平面还是球面？*

*Ruibo Wang, Baha Eddine Youcef Belmekki, Howard H. Yang, Mohamed Slim Alouini* | **Category: cs.NI** | **Updated: 2025-07-21**

**Keywords:** 非地面网络, 随机几何, 平面模型, 球面模型, 相对误差

**Comment:** 

> **TL;DR:** 本文通过引入相对误差和推导最优平面高度，解决了非地面网络（NTN）性能分析中选择平面或球面随机几何模型时的挑战，旨在确定何时可以使用更简单的平面模型。

**AI_Comments:** 该论文为非地面网络（NTN）的性能分析提供了一个实用的框架，通过提供一种有原则的方法来评估平面随机几何模型的适用性。相对误差的引入和最优平面高度的推导是创新的贡献，它们平衡了计算效率和建模准确性，这对于大规模NTN至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 随着非地面网络（NTN）的爆炸式部署，网络性能分析的计算复杂性迅速增加。随机几何（SG）是分析大规模网络拓扑的合适工具，但选择平面模型或球面模型仍然具有挑战性。平面模型忽略地球曲率，在高空NTN分析中可能导致偏差，但因其简单性仍常被使用。因此，需要量化平面模型和球面模型之间的差距，以确定何时平面建模足够。

**Method:** 本文引入了相对误差来量化平面模型和球面模型之间的差距。为计算相对误差，首先提出了一种点过程（PP）生成算法，该算法可同时生成一对同质且渐近相似的平面和球面PP。然后，引入了几种典型的相似性度量（包括拓扑相关和网络级度量），并在此基础上进一步开发了一种相对误差估计算法。此外，推导了最优平面高度的解析表达式。

**Result:** 研究量化了平面模型与球面模型之间的相对误差，并提供了确定平面建模何时足够的方法。所推导的最优平面高度解析表达式降低了计算复杂性，并为平面近似提供了理论支持。数值结果调查了部署高度和区域如何影响NTN建模，并提供了HAP和LEO卫星星座的案例研究。

**Conclusion:** 本文通过引入相对误差概念和推导最优平面高度的解析表达式，为非地面网络（NTN）的随机几何建模提供了选择平面或球面模型的指导，平衡了计算复杂性与模型精度，从而有助于在特定条件下采用更简化的平面模型进行分析。

> **ai_Abstract:** 本文旨在解决非地面网络（NTN）性能分析中选择平面或球面随机几何模型的挑战。它引入了相对误差来量化这两种模型之间的差异，并提出了一个点过程生成算法和基于相似性度量的误差估计算法来计算该误差。此外，论文推导了最优平面高度的解析表达式，以降低计算复杂性并支持平面近似。数值结果和案例研究（如HAP和LEO星座）进一步探讨了部署高度和区域对NTN建模的影响，从而帮助确定何时可以采用更简化的平面模型。

> **摘要翻译:** 随着非地面网络（NTN）的爆炸式部署，网络性能分析的计算复杂性正在迅速升级。作为分析大规模网络拓扑最合适的数学工具之一，随机几何（SG）能够将网络性能指标表示为网络参数的函数，从而提供低复杂度的性能分析解决方案。然而，在平面模型和球面模型之间进行选择仍然具有挑战性。平面模型忽略了地球曲率，导致高空NTN分析出现偏差，但为了简单起见仍常被使用。本文引入相对误差来量化平面模型和球面模型之间的差距，有助于确定何时平面建模足够。为了计算相对误差，我们首先提出了一种点过程（PP）生成算法，该算法可同时生成一对同质且渐近相似的平面和球面PP。然后，我们引入了几种典型的相似性度量，包括拓扑相关和网络级度量，并进一步开发了一种基于这些度量的相对误差估计算法。此外，我们推导了最优平面高度的解析表达式，这降低了计算复杂性，并为平面近似提供了理论支持。最后，数值结果研究了部署高度和区域如何影响NTN建模，并以HAP和LEO卫星星座为例进行了案例研究。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [81] [AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks](https://arxiv.org/abs/2508.00011)
> *基于深度强化学习的HAPS-V2X网络中AoI感知资源分配*

*Ahmet Melih Ince, Ayse Elif Canbilen, Halim Yanikomeroglu* | **Category: cs.NI, cs.AI, cs.LG, cs.MA, cs.SY, eess.SY** | **Updated: 2025-07-21**

**Keywords:** HAPS, V2X, AoI, 深度强化学习, DDPG

**Comment:** 6 pages, 3 figures, to appear in IEEE conference proceedings

> **TL;DR:** 本文提出了一种基于深度确定性策略梯度（DDPG）的深度强化学习方法，用于在HAPS增强的V2X网络中动态优化信息年龄（AoI），以提高信息新鲜度和网络可靠性。

**AI_Comments:** 本文的创新点在于将HAPS与深度强化学习（DDPG）相结合，以解决6G V2X网络中的AoI优化问题。其重要性体现在为未来自动驾驶等安全关键应用提供了潜在的通信解决方案，特别是在传统基础设施受限的区域。通过去中心化的学习方式，提高了系统的鲁棒性和可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 第六代（6G）网络旨在满足自动驾驶等安全关键应用的超高可靠和低延迟通信（HRLLC）需求。将非地面网络（NTN）集成到6G基础设施中可以为网络带来冗余，确保即使在极端条件下也能通信连续性。高空平台站（HAPS）因其覆盖范围广和低延迟的优势而脱颖而出，支持通信可靠性并提高信息新鲜度，尤其是在农村地区和基础设施受限的地区。

**Method:** 本文提出了一种基于深度强化学习的方法，具体使用深度确定性策略梯度（DDPG）来动态优化HAPS增强的V2X网络中的信息年龄（AoI）。该方法通过实现独立学习而无需集中协调，从而提高了信息新鲜度和整体网络可靠性。

**Result:** 研究结果揭示了HAPS支持的解决方案与基于DDPG的学习相结合的潜力，可以在基于车队的自动驾驶系统中实现高效的AoI感知资源分配。

**Conclusion:** HAPS支持的解决方案与基于DDPG的学习相结合，在HAPS-V2X网络中，对于提高信息新鲜度、网络可靠性以及实现高效的AoI感知资源分配具有巨大潜力，尤其适用于车队式自动驾驶系统。

> **ai_Abstract:** 本文提出了一种基于深度确定性策略梯度（DDPG）的深度强化学习方法，用于优化高空平台站（HAPS）增强型车联网（V2X）中的信息年龄（AoI）。该方法旨在通过实现无需集中协调的独立学习，提高信息新鲜度和网络可靠性，特别适用于需要超高可靠和低延迟通信的6G自动驾驶应用。研究结果表明，该结合方案在车队式自动驾驶系统中实现高效的AoI感知资源分配方面具有潜力。

> **摘要翻译:** 第六代（6G）网络旨在满足自动驾驶等安全关键应用的超高可靠和低延迟通信（HRLLC）要求。将非地面网络（NTN）集成到6G基础设施中，为网络带来了冗余，确保即使在极端条件下也能通信连续性。特别是，高空平台站（HAPS）因其广泛的覆盖范围和低延迟优势而脱颖而出，支持通信可靠性并增强信息新鲜度，尤其是在农村地区和基础设施受限的区域。在本文中，我们提出了基于深度强化学习的方法，使用深度确定性策略梯度（DDPG）来动态优化HAPS增强型车联网（V2X）中的信息年龄（AoI）。所提出的方法通过实现无需集中协调的独立学习，提高了信息新鲜度和整体网络可靠性。研究结果揭示了HAPS支持的解决方案与基于DDPG的学习相结合的潜力，可在基于车队的自动驾驶系统中实现高效的AoI感知资源分配。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [109] [Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach](https://arxiv.org/abs/2508.00020)
> *从转发视角对星空地一体化网络 (SAGIN) 的性能分析：一种球面随机几何方法*

*Ferdaous Tarhouni, Ruibo Wang, Mohamed-Slim Alouini* | **Category: cs.NI** | **Updated: 2025-07-27**

**Keywords:** 星空地一体化网络, 高空平台, 转发, 球面随机几何, 性能分析

**Comment:** 

> **TL;DR:** 本文从转发视角评估了星空地一体化网络 (SAGIN) 的性能，并利用球面随机几何推导了新的性能指标的解析表达式，特别关注高空平台 (HAP) 的作用以及卫星网络拓扑对性能的影响。

**AI_Comments:** 本文创新性地将球面随机几何应用于从转发视角分析星空地一体化网络 (SAGIN) 的性能，并提出了新的性能评估指标。其推导的解析表达式为 SAGIN 的低复杂度性能评估提供了有价值的工具，特别是在缺乏相关研究的 SSG 领域。

<details>
  <summary>Details</summary>

**Motivation:** 星空地一体化网络 (SAGIN) 对于满足日益增长的全球无线通信需求至关重要，其中高空平台 (HAP) 可以作为通信枢纽并充当转发器以提升通信性能。

**Method:** 本文从转发视角评估 SAGIN 性能，引入了平均接入数据速率、平均回传数据速率和回传速率超出概率 (BREP) 三个指标。选择球面随机几何 (SSG) 工具，推导出上述指标的解析表达式，以实现低复杂度的性能评估，并提供 BREP 的闭式表达式。

**Result:** 推导了平均接入数据速率、平均回传数据速率和回传速率超出概率 (BREP) 的解析表达式，并提供了 BREP 的闭式表达式。数值结果分析了卫星网络拓扑对性能的影响，并分析了维持短期和长期数据速率所需的最小 HAP 发射功率。

**Conclusion:** 本文从转发视角对 SAGIN 性能进行了评估，并利用球面随机几何成功推导了性能指标的解析表达式，尤其强调了 HAP 的作用和卫星网络拓扑的影响，为 SAGIN 的性能评估提供了低复杂度的分析工具。

> **ai_Abstract:** 本文从转发器角度对星空地一体化网络 (SAGIN) 的性能进行了评估，重点关注高空平台 (HAP) 的作用。研究引入了平均接入数据速率、平均回传数据速率和回传速率超出概率 (BREP) 三个性能指标，并首次利用球面随机几何 (SSG) 推导了这些指标的解析表达式，特别是 BREP 的闭式表达式。此外，研究还探讨了卫星网络拓扑对性能的影响以及维持所需数据速率的最小 HAP 发射功率。

> **摘要翻译:** 近年来，星空地一体化网络 (SAGIN) 已成为满足全球无线通信日益增长需求的关键。在 SAGIN 中，高空平台 (HAP) 可以作为通信枢纽并充当转发器，以增强通信性能。在本文中，我们从转发视角评估了 SAGIN 中的网络性能并分析了 HAP 的作用。基于这一独特的视角，我们引入了三个指标来评估性能，分别为平均接入数据速率、平均回传数据速率和回传速率超出概率 (BREP)。考虑到动态拓扑和干扰分析的需求，我们选择球面随机几何 (SSG) 作为工具，并推导了上述指标的解析表达式，以实现低复杂度的性能评估。具体而言，我们提供了端到端性能指标 BREP 的闭式表达式。鉴于现有 SSG 领域文献中没有从转发视角研究网络的，我们在数值结果中专门调查了卫星网络拓扑对性能的影响，以进一步突出 SSG 框架的优势。此外，我们还分析了维持短期和长期数据速率需求所需的最小 HAP 发射功率。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [137] [Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network](https://arxiv.org/abs/2508.00042)
> *面向6G可靠人工智能：无线网络中的概念漂移检测*

*Athanasios Tziouvaras, Carolina Fortuna, George Floros, Kostas Kolomvatsos, Panagiotis Sarigiannidis, Marko Grobelnik, Blaž Bertalanič* | **Category: cs.NI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 6G网络, 概念漂移, 无监督学习, 机器学习, 无线网络

**Comment:** 10 pages, 12 figures

> **TL;DR:** 本文提出了两种无监督、模型无关的批处理概念漂移检测器，用于6G无线网络，它们在真实场景中表现优于传统方法，能有效检测漂移并触发模型再训练，提高AI可靠性。

**AI_Comments:** 本文的创新之处在于提出了无监督且模型无关的批量概念漂移检测器，解决了传统方法在无线网络这种非平稳环境中遇到的局限性。其重要性在于，通过有效检测概念漂移并触发及时再训练，极大地提高了6G网络中AI模型的可靠性和适应性，这对于实现AI原生6G网络的自动化和高性能愿景至关重要。

<details>
  <summary>Details</summary>

**Motivation:** AI原生6G网络因无线环境的非平稳性（基础设施变化、用户移动、新兴流量模式）导致概念漂移，从而迅速降低机器学习模型的准确性。现有方法要么过于领域特定，要么难以处理某些类型的概念漂移。

**Method:** 提出了两种无监督、模型无关的批处理概念漂移检测器。这两种方法都通过计算预期效用分数来判断概念漂移何时发生以及是否需要模型再训练，且部署后无需真实标签。

**Result:** 在户外定位指纹识别和链路异常检测两个真实无线用例中进行了验证。结果显示，这两种方法比ADWIN、DDM、CUSUM等经典检测器性能提升20-40个百分点。此外，在正确触发再训练警报方面，F1分数分别达到0.94和1.00，与最佳经典检测器相比，误报率降低了高达20个百分点。

**Conclusion:** 本文提出的无监督、模型无关的概念漂移检测器能够有效识别无线网络中的概念漂移，显著提升AI模型的可靠性并减少再训练的误报率，从而为6G网络中的可靠AI奠定基础。

> **ai_Abstract:** 本文针对AI原生6G网络中因无线环境非平稳性导致的概念漂移问题，提出了两种无监督、模型无关的批处理概念漂移检测器。这些检测器通过计算预期效用分数来判断漂移并触发模型再训练，无需真实标签。在真实无线场景中的验证表明，它们在性能上显著优于传统方法，并能有效降低再训练的误报率，从而提升6G网络中AI的可靠性。

> **摘要翻译:** AI原生6G网络通过将机器学习模型嵌入到网络的无线接入和核心部分，有望实现前所未有的自动化和性能。然而，由于基础设施变化、用户移动和新兴流量模式等原因，无线环境的非平稳性会导致概念漂移，这会迅速降低这些模型的准确性。现有方法通常非常领域特定，或者难以处理某些类型的概念漂移。本文介绍了两种无监督、模型无关的批处理概念漂移检测器。这两种方法都计算一个预期效用分数来决定概念漂移何时发生以及是否需要模型再训练，而部署后无需真实标签。我们在户外定位指纹识别和链路异常检测两个真实世界的无线用例中验证了我们的框架，并证明这两种方法比ADWIN、DDM、CUSUM等经典检测器性能高出20-40个百分点。此外，它们在正确触发再训练警报方面分别达到了0.94和1.00的F1分数，因此与最佳经典检测器相比，误报率降低了高达20个百分点。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [165] [Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies](https://arxiv.org/abs/2508.00228)
> *在可变延迟的400Gbps链路上对XRootD-HTTPS进行基准测试*

*Aashay Arora, Diego Davila, Frank Würthwein, John Graham, Dima Mishin, Justas Balcas, Tom Lehman, Xi Yang, Chin Guok, Harvey Newman* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** XRootD-HTTPS, 400Gbps, 网络基准测试, LHC, 数据传输

**Comment:** Submitted to CHEP 24

> **TL;DR:** 为应对高亮度大型强子对撞机时代的数据需求，本文旨在测试XRootD-HTTPS在400Gbps链路和可变延迟下的性能。

**AI_Comments:** 该论文对于确保高能物理实验数据传输基础设施的稳健性和可扩展性至关重要。其在真实网络条件下（包括可变延迟和网络环路）进行的系统性基准测试方法是一个亮点，为未来的系统优化提供了宝贵见解。

<details>
  <summary>Details</summary>

**Motivation:** 为迎接高亮度大型强子对撞机（High Luminosity-LHC）时代，迫切需要监督软件准备情况，以应对生产和用户数据分析访问中即将到来的网络流量增长。本研究旨在探讨US-CMS Tier-2站点所需的软件和硬件改进，以期能够维持并满足预计的400 Gbps带宽需求，同时应对站点间可变延迟带来的挑战。

**Method:** 本研究专注于识别XRootD HTTP第三方副本在多个400 Gbps链路上的性能，并探索不同的主机和传输配置。研究方法涉及系统测试，通过改变每个集群的源数量和每个源的CPU分配来进行。通过复制真实网络条件并创建跨越广域网多个交换机的网络“环路”，能够重现真实的网络条件。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对高亮度大型强子对撞机时代US-CMS Tier-2站点面临的网络流量增长（高达400 Gbps）和可变延迟的挑战，强调了软件和硬件准备的紧迫性。研究重点是对XRootD HTTP第三方副本在400 Gbps链路上的性能进行基准测试，探索了不同的主机和传输配置，并通过系统测试不同源数量和CPU分配，在模拟真实网络条件下进行。

> **摘要翻译:** 为迎接高亮度大型强子对撞机（High Luminosity-LHC）时代，迫切需要监督软件准备情况，以应对生产和用户数据分析访问中即将到来的网络流量增长。本文探讨了US-CMS Tier-2站点所需的软件和硬件改进，以期能够维持并满足预计的400 Gbps带宽需求，同时应对站点间可变延迟带来的挑战。具体而言，我们的研究重点是识别XRootD HTTP第三方副本在多个400 Gbps链路上的性能，并探索不同的主机和传输配置。我们的方法涉及系统测试，通过改变每个集群的源数量和每个源的CPU分配来进行。通过复制真实网络条件并创建跨越广域网多个交换机的网络“环路”，我们能够重现真实的网络条件。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [192] [From Timestamps to Versions: Version AoI in Single- and Multi-Hop Networks](https://arxiv.org/abs/2507.23433)
> *从时间戳到版本：单跳和多跳网络中的版本信息年龄 (VAoI)*

*Erfan Delfani, Nikolaos Pappas* | **Category: cs.NI, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 版本信息年龄, 稳态分布, 调度策略, 单跳网络, 多跳网络

**Comment:** 

> **TL;DR:** 本文全面分析了单跳和多跳网络中版本信息年龄 (VAoI) 的稳态分布，并在各种调度策略下推导了其闭式表达式，还确定了基于阈值调度的最优阈值。

**AI_Comments:** 本文创新性地关注了信息内容本身的重要性，引入了版本信息年龄 (VAoI) 这一新颖的度量。通过在单跳和多跳网络中对 VAoI 稳态分布的深入分析，并推导出闭式表达式，为理解和优化数据新鲜度提供了坚实的理论基础。特别是对最优阈值的确定，具有重要的实践指导意义。研究填补了现有工作在完整分布分析上的空白，对未来高效通信网络的设计具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的信息年龄 (AoI) 度量未能考虑内容的内在信息量。尽管提出了结合及时性和信息量的基于内容的度量，但现有研究主要关注平均度量值，而对完整分布（尤其是在多跳网络中）的探索不足。

**Method:** 本文对版本信息年龄 (VAoI) 的稳态分布进行了全面分析，该分析在单跳和多跳网络中，考虑了随机平稳、均匀和基于阈值的调度策略以及传输约束。研究推导了稳态分布和平均 VAoI 的闭式表达式，并针对基于阈值的调度，解析确定了最小化 VAoI 的最优阈值及其对应的最优 VAoI 闭式解。数值评估验证了分析结果。

**Result:** 推导了在各种调度策略下（包括随机平稳、均匀和基于阈值）VAoI 的稳态分布和平均 VAoI 的闭式表达式。对于基于阈值的调度，解析确定了最小化 VAoI 的最优阈值，并推导了相应的最优 VAoI 闭式解。数值评估验证了分析结果。

**Conclusion:** 数值评估验证了本文的分析发现，为在高效通信网络设计中利用 VAoI 提供了宝贵的见解。

> **ai_Abstract:** 本文针对现有信息及时性度量未考虑内容信息量的问题，提出了对版本信息年龄 (VAoI) 的全面分析。研究在单跳和多跳网络中，考察了随机平稳、均匀和基于阈值等多种调度策略下的 VAoI 稳态分布。论文推导了稳态分布和平均 VAoI 的闭式表达式，并特别针对基于阈值的调度，解析确定了最优阈值。数值结果验证了理论分析，为通信网络设计中利用 VAoI 提供了指导。

> **摘要翻译:** 通信网络中及时且信息丰富的数据传播对于提高系统性能和能源效率至关重要，因为它减少了过时或冗余数据的传输。信息年龄 (AoI) 等及时性指标有效地量化了数据的新鲜度；然而，这些指标未能考虑内容本身的内在信息量。为了解决这一限制，已经提出了结合及时性和信息量的基于内容的指标。然而，现有研究主要集中于评估平均指标值，对完整分布（特别是在多跳网络场景中）的探索仍不足。在本文中，我们对版本信息年龄 (VAoI)（一种基于内容的指标）的稳态分布进行了全面分析，该分析在单跳和多跳网络中，考虑了随机平稳、均匀和基于阈值的各种调度策略以及传输约束。我们推导了在这些调度方法下稳态分布和平均 VAoI 的闭式表达式。此外，对于基于阈值的调度，我们解析确定了最小化 VAoI 的最优阈值，并推导了相应的最优 VAoI 闭式解。数值评估验证了我们的分析发现，为在高效通信网络设计中利用 VAoI 提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [193] [Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](https://arxiv.org/abs/2508.00234)
> *面向多专家的边缘计算中服务质量感知的LLM路由*

*Jin Yang, Qiong Wu, Zhiying Feng, Zhi Zhou, Deke Guo, Xu Chen* | **Category: cs.NI, cs.AI, cs.DC, cs.MA** | **Updated: 2025-08-01**

**Keywords:** 边缘计算, LLM路由, 服务质量（QoS）, 深度强化学习（DRL）, 异构图注意力网络（HAN）

**Comment:** Accepted by IEEE Transactions on Mobile Computing

> **TL;DR:** 本文提出了一种基于深度强化学习的QoS感知LLM路由框架，用于边缘计算，以解决现有路由算法无法同时处理LLM服务异构性、请求干扰和动态工作负载的问题，并在实验中显著提高了服务质量和计算资源效率。

**AI_Comments:** 本文创新性地将深度强化学习应用于边缘计算中的LLM服务路由，以解决QoS保障问题。其核心贡献在于提出了动态状态抽象技术和异构图注意力网络（HAN）来处理复杂的全局状态，以及设计了专门的奖励函数。这对于提升边缘LLM服务的用户体验和资源利用率具有重要意义。该方法有望为未来大规模边缘AI部署提供有效的路由策略。

<details>
  <summary>Details</summary>

**Motivation:** 云端LLM服务存在高延迟、响应不稳定和隐私问题。将LLM部署在边缘网络可以提高实时响应速度并保护数据隐私，但如何将用户请求路由到合适的边缘LLM专家以确保可接受的服务质量（QoS）是一个关键挑战。现有路由算法未能同时解决LLM服务的异构性、请求间的干扰以及动态工作负载对长期稳定QoS维护的需求。

**Method:** 本文提出了一种新颖的基于深度强化学习（DRL）的QoS感知LLM路由框架。该框架利用动态状态抽象技术，通过异构图注意力网络（HAN）紧凑地表示全局状态特征。此外，引入了动作影响估计器和定制的奖励函数，以指导DRL智能体最大化QoS并防止延迟违规。

**Result:** 在泊松和真实世界工作负载上的大量实验表明，与现有基线相比，我们提出的算法显著提高了平均服务质量（QoS）和计算资源效率。

**Conclusion:** 本文提出的基于深度强化学习的QoS感知LLM路由框架，通过有效应对LLM服务异构性、请求干扰和动态工作负载的挑战，显著提升了边缘计算环境中LLM服务的服务质量和资源利用效率。

> **ai_Abstract:** 本文针对边缘计算环境中LLM服务面临的高延迟、响应不稳定和隐私问题，以及现有路由算法在处理服务异构性、请求干扰和动态工作负载方面的不足，提出了一种新颖的基于深度强化学习（DRL）的QoS感知LLM路由框架。该框架通过动态状态抽象技术结合异构图注意力网络（HAN）来表示全局状态，并引入动作影响估计器和定制奖励函数以优化QoS。实验结果表明，该算法显著提升了平均服务质量和计算资源效率。

> **摘要翻译:** 大型语言模型（LLMs）展示了卓越的能力，导致用户对LLM服务的需求显著增加。然而，基于云的LLM服务通常面临高延迟、不稳定的响应和隐私问题。因此，通常在网络边缘部署多个LLM以提高实时响应能力并保护数据隐私，特别是对于许多新兴的智能移动和物联网应用。考虑到LLM服务响应质量和延迟的不同，一个关键问题是如何将来自移动和物联网设备的用户请求路由到适当的LLM服务（即边缘LLM专家），以确保可接受的服务质量（QoS）。现有路由算法未能同时解决LLM服务的异构性、请求间的干扰以及保持长期稳定QoS所需的动态工作负载。为了应对这些挑战，本文提出了一种新颖的基于深度强化学习（DRL）的QoS感知LLM路由框架，用于持续高质量的LLM服务。由于全局状态的动态性，我们提出了一种动态状态抽象技术，通过异构图注意力网络（HAN）紧凑地表示全局状态特征。此外，我们引入了动作影响估计器和定制的奖励函数，以指导DRL智能体最大化QoS并防止延迟违规。在泊松和真实世界工作负载上的大量实验表明，我们提出的算法与现有基线相比，显著提高了平均QoS和计算资源效率。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [228] [Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study](https://arxiv.org/abs/2508.00256)
> *大型人工智能模型赋能低空无线网络安全通信：概念、展望与案例研究*

*Chuang Zhang, Geng Sun, Jiacheng Wang, Yijing Lin, Weijie Yuan, Sinem Coleri, Dusit Niyato, Tony Q. S. Quek* | **Category: cs.NI, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 大型人工智能模型, 低空无线网络, 安全通信, 强化学习, 大型语言模型

**Comment:** This paper has been submitted to IEEE Communications Magazine for
  consideration

> **TL;DR:** 本文探讨了大型人工智能模型（LAMs）在低空无线网络（LAWNs）中实现安全通信的解决方案，并提出了一种基于LAMs的优化框架，通过利用大型语言模型（LLMs）增强特征和设计奖励，提升了安全通信任务的强化学习性能。

**AI_Comments:** 本文的创新点在于将大型人工智能模型（特别是大型语言模型）应用于低空无线网络的安全通信领域，通过生成增强的状态特征和设计内在奖励来优化强化学习性能，为解决LAWNs面临的独特安全挑战提供了一种新颖且有效的方法。

<details>
  <summary>Details</summary>

**Motivation:** 低空无线网络（LAWNs）具有巨大的通信潜力，但由于其低空运行、频繁移动和对非授权频谱的依赖，面临独特的安全挑战，使其易受恶意攻击。传统AI方法在LAWNs中存在安全风险和局限性。

**Method:** 本文研究了大型人工智能模型（LAM）赋能的低空无线网络安全通信解决方案。具体地，首先探讨了传统AI方法在LAWNs中的安全风险和局限性，然后介绍了LAMs的基本概念及其在解决这些挑战中的作用。为展示LAMs的实际效益，提出了一种新颖的基于LAM的优化框架，该框架利用大型语言模型（LLMs）在手工表示之上生成增强的状态特征，并相应地设计内在奖励，从而提高安全通信任务的强化学习性能。

**Result:** 通过一个典型的案例研究，仿真结果验证了所提出框架的有效性。

**Conclusion:** 本文探讨了大型人工智能模型在低空无线网络安全通信中的应用，并提出了一个有效的LAMs优化框架。未来方向包括将LAMs进一步整合到安全的低空无线网络应用中。

> **ai_Abstract:** 本文探讨了大型人工智能模型（LAMs）在应对低空无线网络（LAWNs）独特安全挑战方面的潜力。研究发现传统AI方法存在局限性，因此提出了一种新颖的基于LAMs的优化框架，该框架利用大型语言模型（LLMs）来增强状态特征和设计内在奖励，从而显著提升了安全通信任务的强化学习性能。仿真结果验证了该框架的有效性，并展望了LAMs在未来LAWN安全应用中的集成方向。

> **摘要翻译:** 低空无线网络（LAWNs）通过支持城市包裹递送、空中检查和空中出租车等一系列应用，有可能彻底改变通信。然而，与传统无线网络相比，LAWNs由于低空操作、频繁移动和对非授权频谱的依赖，面临独特的安全挑战，使其更容易受到一些恶意攻击。在本文中，我们研究了一些由大型人工智能模型（LAM）赋能的低空无线网络安全通信解决方案。具体来说，我们首先探讨了LAWNs中传统AI方法的放大安全风险和重要局限性。然后，我们介绍了LAMs的基本概念，并深入探讨了LAMs在解决这些挑战中的作用。为了展示LAMs在LAWN安全通信方面的实际益处，我们提出了一种新颖的基于LAM的优化框架，该框架利用大型语言模型（LLMs）在手工表示之上生成增强的状态特征，并相应地设计内在奖励，从而提高安全通信任务的强化学习性能。通过一个典型的案例研究，仿真结果验证了所提出框架的有效性。最后，我们概述了将LAMs集成到安全LAWN应用中的未来方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [235] [Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach](https://arxiv.org/abs/2508.00629)
> *O-RAN中节能的CPU编排：一种dApp驱动的轻量级方法*

*Francisco Crespo, Javier Villegas, Carlos Baena, Eduardo Baena, Sergio Fortes, Raquel Barco* | **Category: cs.NI, cs.OS, cs.PF** | **Updated: 2025-08-01**

**Keywords:** O-RAN, CPU编排, 节能, dApp, 资源管理

**Comment:** 

> **TL;DR:** 本文提出了一种轻量级的分布式应用（dApp），用于在O-RAN分布式单元（DU）层面动态编排CPU使用，以提高能效和CPU利用率，同时不影响实时性能。

**AI_Comments:** 该论文的创新点在于提出了一个无需修改底层RAN软件或内核的轻量级dApp，以解决O-RAN中CPU资源管理的能效问题。这种方法具有高度的兼容性和部署灵活性，降低了实施障碍。其重要性在于为未来RAN网络的精细化资源控制提供了一个高效且实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 向软件定义无线接入网络（RANs）的转变，特别是O-RAN范式，在CPU资源管理方面引入了新挑战，特别是在严格的实时约束下，延迟敏感的RAN工作负载与通用操作系统调度器之间的相互作用常导致次优性能和不必要的能耗。

**Method:** 本文提出了一种轻量级、可编程的分布式应用（dApp），部署在分布式单元（DU）层面，与操作系统闭环协作，利用线程级遥测数据（如上下文切换、每周期指令数IPC、缓存指标）实时调整CPU线程亲和性、核心隔离和频率缩放。该方案无需访问专有RAN软件、特定硬件功能或内核修改。

**Result:** 实验结果表明，使用商用级srsRAN部署，该方案在不损害实时处理性能的情况下，实现了持续的节电，并引入了可忽略的开销，同时提高了能效和CPU利用率。

**Conclusion:** 低延迟的dApp在下一代网络中进行细粒度资源控制具有巨大潜力，能够有效解决O-RAN中CPU资源管理的能效和性能挑战。

> **ai_Abstract:** 本研究提出了一种针对O-RAN环境的轻量级分布式应用（dApp），旨在解决软件化RAN中CPU资源管理效率低下的问题。该dApp部署在分布式单元（DU）层面，通过与操作系统闭环协作，利用线程级遥测数据动态调整CPU线程亲和性、核心隔离和频率缩放，以优化能效和CPU利用率。其创新之处在于无需访问专有RAN软件或进行内核修改，且与底层RAN堆栈无关。实验证明，该方案在实现显著节能的同时，不影响实时处理性能。

> **摘要翻译:** 向由开放无线接入网络（O-RAN）范式驱动的软件化无线接入网络（RANs）过渡，通过基站功能的解耦和虚拟化，实现了灵活、厂商中立的部署。然而，这种转变在严格的实时约束下引入了有效管理CPU资源的新挑战。特别是，延迟敏感的RAN工作负载与通用操作系统（OS）调度器之间的相互作用常常导致次优性能和不必要的能耗。这项工作提出了一种轻量级、可编程的分布式应用（dApp），部署在分布式单元（DU）层面，用于动态编排CPU使用。该dApp与操作系统闭环协作，利用线程级遥测数据（如上下文切换、每周期指令数IPC和缓存指标），实时调整CPU线程亲和性、核心隔离和频率缩放。与现有解决方案不同，它不需要访问专有RAN软件、特定硬件功能或内核修改。所提出的解决方案完全符合O-RAN架构，并且与底层RAN堆栈无关，引入了可忽略的开销，同时提高了能效和CPU利用率。使用商用级srsRAN部署的实验结果表明，在不损害实时处理性能的情况下，实现了持续的节电，突出了低延迟dApp在下一代网络中进行细粒度资源控制的潜力。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [259] [Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning](https://arxiv.org/abs/2508.00261)
> *基于深度强化学习的多无人机辅助MEC能效轨迹控制与资源分配*

*Saichao Liu, Geng Sun, Chuang Zhang, Xuejie Liu, Jiacheng Wang, Changyuan Zhao, Dusit Niyato* | **Category: cs.NI, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 移动边缘计算, 无人机, 深度强化学习, 轨迹控制, 资源分配

**Comment:** This paper has been accepted by IEEE GLOBECOM 2025

> **TL;DR:** 本文研究了多无人机辅助的移动边缘计算（MEC）系统，通过优化无人机飞行路径和计算资源分配，旨在最大化卸载数量、最小化延迟和能耗。为此，提出了一种名为DPPOIL的增强型深度强化学习算法，仿真结果证明其优于基线方法。

**AI_Comments:** 该论文通过引入多无人机辅助MEC系统，并结合深度强化学习（DRL）中的模仿学习技术，解决了传统MEC的局限性。其创新点在于将轨迹控制和资源分配建模为多目标优化问题，并提出了DPPOIL算法来应对动态环境下的连续决策。这种结合DDRL和模仿学习的方法有望为未来无线通信和边缘计算领域提供新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 移动边缘计算（MEC）在物联网中提升智能设备计算能力方面具有前景，但其固定位置和有限服务范围限制了性能。为了克服这些限制，本文研究了无人机辅助的MEC系统。

**Method:** 本文将无人机辅助MEC系统中的能效轨迹控制和资源分配问题建模为一个多目标优化问题（TCRAMOP），旨在同时最大化无人机卸载数量并最小化总卸载延迟和总能耗。考虑到TCRAMOP需要连续决策且系统是动态的，本文提出了一种增强型深度强化学习（DRL）算法，即分布式近端策略优化与模仿学习（DPPOIL），该算法结合了生成对抗模仿学习技术以提高策略性能。

**Result:** 仿真结果表明，本文提出的DPPOIL算法是有效的，并且其学习到的策略优于其他基线方法。

**Conclusion:** 本文成功地将无人机辅助MEC系统中的轨迹控制和资源分配问题建模为多目标优化问题，并提出了一种基于深度强化学习的DPPOIL算法来有效解决该问题，提高了系统性能。

> **ai_Abstract:** 本文研究多无人机辅助的移动边缘计算（MEC）系统，以克服传统MEC的局限性。为提升系统性能，作者构建了一个多目标优化问题（TCRAMOP），旨在优化无人机轨迹和资源分配，以同时最大化卸载数量并最小化延迟和能耗。针对该动态决策问题，本文提出了一种名为DPPOIL的增强型深度强化学习算法，该算法集成了生成对抗模仿学习。仿真结果验证了DPPOIL的有效性及其优于基线方法的性能。

> **摘要翻译:** 移动边缘计算（MEC）是一种很有前景的技术，可以提高物联网（IoT）中智能设备（SDs）的计算能力。然而，MEC的性能受到其固定位置和有限服务范围的限制。因此，我们研究了一种无人机（UAV）辅助的MEC系统，其中部署了多架无人机，每架无人机可以同时为多个智能设备提供计算服务。为了提高系统性能，我们构建了一个基于无人机的轨迹控制和资源分配多目标优化问题（TCRAMOP），通过优化无人机的飞行路径以及分配给所服务智能设备的计算资源，同时最大化无人机的卸载数量，并最小化总卸载延迟和无人机的总能耗。然后，考虑到TCRAMOP的解决方案需要连续决策且系统是动态的，我们提出了一种增强型深度强化学习（DRL）算法，即分布式近端策略优化与模仿学习（DPPOIL）。该算法结合了生成对抗模仿学习技术以提高策略性能。仿真结果证明了我们提出的DPPOIL的有效性，并证明了DPPOIL的学习策略优于其他基线方法。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [290] [Mamba for Wireless Communications and Networking: Principles and Opportunities](https://arxiv.org/abs/2508.00403)
> *Mamba在无线通信与网络中的应用：原理与机遇*

*Rongsheng Zhang, Ruichen Zhang, Yang Lu, Wei Chen, Bo Ai, Dusit Niyato* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** Mamba, 无线通信, 神经网络, 资源分配, 信号处理

**Comment:** 

> **TL;DR:** 本文全面概述了Mamba模型在无线通信和网络中的应用潜力，包括其原理、两种应用框架（替代传统算法、启用新型范式）以及在智能资源分配和联合信源信道解码中的案例研究，并指出了未来的挑战和研究方向。

**AI_Comments:** 本文系统性地探讨了Mamba模型在无线通信领域的应用潜力，其创新点在于提出了“替代传统算法”和“启用新型范式”的应用框架，并提供了具体案例验证其在特征增强和计算效率上的优势。这对于推动Mamba在实际无线系统中的部署具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于无线网络中日益增长的异构性和动态性，Mamba模型在处理时间与空间数据任务方面的强大能力，使其在计算效率和有效性之间取得平衡，从而有望彻底改变无线通信和网络设计。

**Method:** 本文首先从长距离依赖建模和空间特征提取的角度分析了Mamba在无线信号处理任务中的潜力。然后提出了Mamba在无线通信中的两种应用框架：替代传统算法和启用新型范式。通过这两个框架，文章对智能资源分配和联合信源信道解码进行了案例研究。

**Result:** 案例研究表明，Mamba在特征增强和计算效率方面均有所改进。

**Conclusion:** Mamba在无线通信和网络中具有巨大潜力，但仍面临关键挑战，需要进一步研究。

> **ai_Abstract:** 本文深入探讨了Mamba模型在无线通信与网络领域的应用。文章分析了Mamba在处理时间与空间数据方面的优势，并提出了两种应用框架：替代传统算法和启用新型范式。通过智能资源分配和联合信源信道解码的案例研究，论文展示了Mamba在提升特征和计算效率方面的潜力，并展望了未来的研究方向和挑战。

> **摘要翻译:** Mamba已成为一种强大的模型，可有效处理涉及时间和空间数据的任务。鉴于无线网络中日益增长的异构性和动态性，Mamba有望通过平衡计算效率和有效性之间的权衡，彻底改变无线通信和网络设计。本文全面概述了Mamba在无线系统中的应用。具体而言，我们首先从长距离依赖建模和空间特征提取的角度分析了Mamba在无线信号处理任务中的潜力。然后，我们提出了Mamba在无线通信中的两种应用框架，即替代传统算法和启用新型范式。在两个框架的指导下，我们对智能资源分配和联合信源信道解码进行了案例研究，以展示Mamba在特征增强和计算效率方面的改进。最后，我们强调了Mamba在无线通信和网络中面临的关键挑战，并概述了潜在的研究方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [326] [Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications](https://arxiv.org/abs/2508.00583)
> *使用大型视觉模型增强物联网无线网络：基础与应用*

*Yunting Xu, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Deepu Rajan, Liang Yu, Haibo Zhou, Abbas Jamalipour, Xianbin Wang* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 大型视觉模型, 物联网, 无线网络, 渐进式微调, 无人机互联网

**Comment:** 7 pages, 6 figures

> **TL;DR:** 本文探讨了大型视觉模型在物联网无线网络中的应用，并提出了一种渐进式微调框架以克服模型大小和再训练的挑战。

**AI_Comments:** 本文的创新点在于提出了将大型视觉模型（LVMs）应用于物联网无线网络，并针对LVMs模型大和再训练困难的挑战，设计了一种渐进式微调框架。这为视觉智能与无线通信的交叉融合提供了新的思路和解决方案，特别是在无人机互联网等新兴应用场景中展示了其潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉模型（LVMs）在视觉智能方面表现出色，其在物联网（IoT）场景中的集成可以为视觉辅助网络优化提供卓越的泛化和适应性。然而，LVMs的模型规模大且在无线领域进行模型再训练面临挑战，这促使研究如何有效地将其应用于无线网络。

**Method:** 本文首先调查了LVMs的功能和核心架构，然后探讨了LVMs在无线通信中跨物理层、网络层和应用层的多种应用。为了解决LVMs模型大和再训练困难的问题，作者提出了一种渐进式微调框架，用于逐步适应预训练的LVMs以联合优化多个物联网任务。

**Result:** 在低空经济网络（LAENets）的案例研究中，所提出的框架在无人机互联网的联合波束成形和定位任务中，表现出优于传统CNNs的有效性。

**Conclusion:** 整合大型视觉模型到智能无线系统中是一个有前景的方向，所提出的渐进式微调框架能够有效支持LVMs在无线网络中的应用，尤其是在解决模型大小和再训练挑战方面。

> **ai_Abstract:** 本文探讨了大型视觉模型（LVMs）在物联网无线网络中的应用潜力。文章首先分析了LVMs的功能和架构，并探索了它们在无线通信各层级的应用。针对LVMs模型规模大和再训练困难的问题，作者提出了一种渐进式微调框架，以实现多物联网任务的联合优化。通过在低空经济网络中无人机互联网的案例研究，验证了该框架在联合波束成形和定位任务上优于传统卷积神经网络的有效性，表明LVMs是构建智能无线系统的一个有前景的方向。

> **摘要翻译:** 大型视觉模型（LVMs）已成为视觉智能领域的基础范式，在各种视觉任务中取得了最先进的性能。LVMs的最新进展促进了它们与物联网（IoT）场景的集成，为视觉辅助网络优化提供了卓越的泛化和适应性。在本文中，我们首先调查了LVMs的功能和核心架构，强调了它们在分类、分割、生成和多模态视觉处理方面的能力。然后，我们探讨了LVMs在无线通信中的各种应用，涵盖了物理层、网络层和应用层的代表性任务。此外，考虑到LVMs庞大的模型规模以及在无线领域进行模型再训练的挑战，我们提出了一种渐进式微调框架，该框架逐步适应预训练的LVMs以联合优化多个物联网任务。低空经济网络（LAENets）中的案例研究表明，所提出的框架在无人机互联网的联合波束成形和定位任务中，相较于传统CNNs表现出更高的有效性，这为将LVMs集成到智能无线系统中指明了一个有前景的方向。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [354] [Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications](https://arxiv.org/abs/2508.00616)
> *无人机载堆叠智能超表面辅助通信的联合关联与相移设计*

*Mingzhe Fan, Geng Sun, Hongyang Pan, Jiacheng Wang, Jiancheng An, Hongyang Du, Chau Yuen* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 无人机通信, 堆叠智能超表面, 联合优化, 相移, 网络容量

**Comment:** This papar has been submitted to the IEEE Global Communications
  Conference. arXiv admin note: substantial text overlap with arXiv:2506.23488

> **TL;DR:** 本文提出了一种针对无人机载堆叠智能超表面（UAV-SIMs）辅助通信系统的联合优化策略，以最大化网络容量。

**AI_Comments:** 本文通过将堆叠智能超表面（SIMs）部署到无人机上，提出了一个新颖的移动SIMs概念，有效解决了固定SIMs在通信性能上的局限性。其创新点在于将关联、位置和相移进行联合优化，并采用分解和交替优化策略，为未来移动超表面通信系统提供了有价值的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 固定式堆叠智能超表面（SIMs）会限制系统通信性能，而移动式SIMs（如无人机载SIMs）可以灵活部署以增强通信性能。

**Method:** 提出一个无人机载SIMs联合优化问题（USBJOP），综合考虑UAV-SIMs与用户的关联、UAV-SIMs的位置以及UAV-SIMs的相移。将USBJOP分解为三个子问题：UAV-SIMs与用户关联优化问题（AUUOP）、无人机位置优化问题（ULOP）和UAV-SIM相移优化问题（USPSOP）。通过交替优化（AO）策略求解，其中AUUOP和ULOP转换为凸形式并使用CVX工具求解，USPSOP采用逐层迭代优化方法。

**Result:** 仿真结果验证了所提出策略在不同仿真设置下的有效性。

**Conclusion:** 本文提出的针对无人机载堆叠智能超表面辅助通信系统的联合优化策略能够有效提升网络容量。

> **ai_Abstract:** 本研究提出了一种无人机载堆叠智能超表面（UAV-SIMs）辅助通信系统，旨在克服固定SIMs的性能限制。通过将无人机作为移动基站和SIMs部署平台，研究者构建了一个联合优化问题，以最大化网络容量，该问题涉及UAV-SIMs与用户的关联、无人机位置和SIMs相移。为解决该非凸问题，研究者将其分解为三个子问题并采用交替优化策略求解。仿真结果证明了所提策略的有效性。

> **摘要翻译:** 堆叠智能超表面（SIMs）作为一种实现波域信号处理的有前景技术已经出现，然而与移动SIMs相比，固定SIMs会限制系统的通信性能。在这项工作中，我们考虑了一个无人机载SIMs（UAV-SIMs）辅助的通信系统，其中无人机作为基站（BSs）可以缓存SIMs处理的数据，并且作为移动载体灵活部署SIMs以增强通信性能。为此，我们提出了一个基于UAV-SIM的联合优化问题（USBJOP），综合考虑UAV-SIMs与用户之间的关联、UAV-SIMs的位置以及UAV-SIMs的相移，旨在最大化网络容量。由于USBJOP的非凸性和NP-难性，我们将其分解为三个子优化问题，分别是UAV-SIMs与用户关联优化问题（AUUOP）、无人机位置优化问题（ULOP）和UAV-SIM相移优化问题（USPSOP）。然后，这三个子优化问题通过交替优化（AO）策略求解。具体而言，AUUOP和ULOP被转换为凸形式，然后通过CVX工具求解，而USPSOP我们采用逐层迭代优化方法。仿真结果验证了所提出策略在不同仿真设置下的有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [382] [Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience](https://arxiv.org/abs/2508.00688)
> *基于关键性的动态拓扑优化以增强空海蜂群韧性*

*Ruiyang Huang, Haocheng Wang, Yixuan Shen, Ning Gao, Qiang Ni, Shi Jin, Yifan Wu* | **Category: cs.NI, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 蜂群网络韧性, 拓扑优化, 关键性评估, 图卷积网络, 多目标优化

**Comment:** Submit to INFOCOM 2026

> **TL;DR:** 提出一个两步框架，结合基于关键性的节点优先级和多目标拓扑优化，以增强空海蜂群网络的韧性。

**AI_Comments:** 这篇论文的创新点在于结合了基于关键性评估的节点优先级与多目标拓扑优化，并引入了基于图卷积网络的SurBi-Ranking方法来实时动态评估关键性，这对于动态和对抗性环境下的网络韧性提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 异构空海蜂群网络在对抗环境中面临目标通信中断和结构脆弱性带来的巨大困难。

**Method:** 首先，设计一个三层架构来表示蜂群网络的结构、通信和任务依赖性。然后，引入SurBi-Ranking方法（利用图卷积网络）动态评估并实时排序节点和边的关键性。最后，应用NSGA-III算法优化网络拓扑，旨在平衡通信效率、全局连通性和任务成功率。

**Result:** SurBi-Ranking方法比K-Shell等传统方法能更准确地识别关键节点和边，对这些组件的蓄意攻击导致更显著的连通性下降。优化方法在攻击下优先处理SurBi-Ranked关键组件时，将自然连通性下降减少约30%，实现更高的任务成功率，并产生更低的通信重构成本。

**Conclusion:** 该优化方法确保了多阶段操作中持续的连通性和任务有效性。

> **ai_Abstract:** 本文针对异构空海蜂群网络在对抗环境中的通信中断和结构脆弱性问题，提出了一个两步框架以增强网络韧性。该框架首先通过三层架构表示网络依赖性，然后利用基于图卷积网络的SurBi-Ranking方法实时评估节点和边的关键性，最后采用NSGA-III算法优化网络拓扑以平衡通信效率、连通性和任务成功率。实验证明，该方法能更准确地识别关键组件，并在攻击下显著提高网络连通性和任务成功率，同时降低重构成本。

> **摘要翻译:** 异构空海蜂群网络在对抗环境中由于有针对性的通信中断和结构弱点而面临巨大困难。本文提出了一个两步框架来增强网络的韧性。具体而言，我们的框架结合了基于关键性的节点优先级和多目标拓扑优化。首先，我们设计了一个三层架构来表示蜂群网络的结构、通信和任务依赖性。然后，我们引入了SurBi-Ranking方法，该方法利用图卷积网络，实时动态评估和排序节点和边的关键性。接下来，我们应用NSGA-III算法优化网络拓扑，旨在平衡通信效率、全局连通性和任务成功率。实验表明，与K-Shell等传统方法相比，我们的SurBi-Ranking方法能更准确地识别关键节点和边，因为对这些组件的蓄意攻击会导致更显著的连通性下降。此外，我们的优化方法在攻击下优先处理SurBi-Ranked关键组件时，将自然连通性下降减少了约30%，实现了更高的任务成功率，并产生了更低的通信重构成本，确保了多阶段操作中持续的连通性和任务有效性。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [403] [Deep Joint Source-Channel Coding for Small Satellite Applications](https://arxiv.org/abs/2508.00715)
> *用于小型卫星应用的深度联合信源信道编码*

*Olga Kondrateva, Grace Li Zhang, Julian Zobel, Björn Scheuermann, Stefan Dietzel* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 深度联合信源信道编码, 小型卫星, 卫星通信, 注意力机制, 信道适应性

**Comment:** 

> **TL;DR:** 该论文提出了一种适用于卫星通信的深度联合信源信道编码（DJSCC）框架，特别是ADJSCC-SAT，它利用注意力机制适应各种信道条件，显著减少模型存储需求并提高鲁棒性。

**AI_Comments:** 该论文的创新之处在于提出了ADJSCC-SAT架构，通过引入注意力模块使单个DJSCC网络能够适应多种信道条件，解决了为每种信道条件使用单独模型的实际应用难题。这不仅提高了系统的灵活性和实用性，还显著减少了模型存储需求并增强了对信道估计误差的鲁棒性，对于资源受限的卫星通信环境具有重要意义。该工作是DJSCC技术在实际卫星任务中应用的重要一步。

<details>
  <summary>Details</summary>

**Motivation:** 小型卫星在地球观测中产生大量高维数据，但其在低地球轨道的运行由于有限的接触时间和恶劣多变的信道条件，造成了显著的通信瓶颈。虽然深度联合信源信道编码（DJSCC）是一种有前景的技术，但其在复杂卫星环境中的实际应用仍是一个悬而未决的问题。

**Method:** 本文提出了一种为卫星通信量身定制的综合DJSCC框架。首先建立了一个基本系统DJSCC-SAT，并集成了一个现实的多状态统计信道模型来指导其训练和评估。为了克服为每种信道条件使用单独模型的不切实际性，引入了一种可适应的架构ADJSCC-SAT，它利用注意力模块使单个神经网络能够以最小的开销适应各种信道状态。

**Result:** 通过对Sentinel-2多光谱数据的广泛评估，结果表明，我们的可适应方法实现了与使用多个专用网络相当的性能，同时显著减少了模型存储需求。此外，可适应模型显示出对信道估计误差的增强鲁棒性，优于非可适应基线。

**Conclusion:** 所提出的框架是向为实际卫星任务部署鲁棒、自适应的DJSCC系统迈出的实用而高效的一步。

> **ai_Abstract:** 本论文提出了一种针对小型卫星通信的深度联合信源信道编码（DJSCC）框架。针对卫星通信中存在的通信瓶颈和复杂多变的信道条件，作者首先建立了DJSCC-SAT系统并引入了多状态统计信道模型。为解决多模型适应性差的问题，进一步提出了基于注意力机制的ADJSCC-SAT架构，使单个神经网络能适应多种信道状态。实验结果表明，ADJSCC-SAT在保持高性能的同时，显著减少了模型存储需求，并增强了对信道估计误差的鲁棒性，为实际卫星任务中部署自适应DJSCC系统提供了实用且高效的解决方案。

> **摘要翻译:** 用于地球观测的小型卫星产生大量高维数据，但其在低地球轨道的运行由于有限的接触时间和恶劣多变的信道条件，造成了显著的通信瓶颈。虽然深度联合信源信道编码（DJSCC）已成为一种有前景的技术，但其在复杂卫星环境中的实际应用仍是一个悬而未决的问题。本文提出了一种为卫星通信量身定制的综合DJSCC框架。我们首先建立了一个基本系统DJSCC-SAT，并集成了一个现实的、多状态的统计信道模型来指导其训练和评估。为了克服为每种信道条件使用单独模型的不切实际性，我们随后引入了一种可适应的架构ADJSCC-SAT，它利用注意力模块使单个神经网络能够以最小的开销适应各种信道状态。通过对Sentinel-2多光谱数据的广泛评估，我们证明了我们的可适应方法实现了与使用多个专用网络相当的性能，同时显著减少了模型存储需求。此外，可适应模型显示出对信道估计误差的增强鲁棒性，优于非可适应基线。所提出的框架是向为实际卫星任务部署鲁棒、自适应的DJSCC系统迈出的实用而高效的一步。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [421] [Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE](https://arxiv.org/abs/2508.00735)
> *重叠的IPv4、IPv6和TCP数据：使用PYROLYSE探索网络栈和NIDS中的错误、测试用例上下文和多重重叠*

*Lucas Aubard, Johan Mazel, Gilles Guette, Pierre Chifflier* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** IP重组, TCP分段, NIDS, PYROLYSE, 漏洞

**Comment:** 

> **TL;DR:** 本文介绍了PYROLYSE工具，用于测试IP和TCP重组策略，发现这些策略比预期更多样，并报告了导致安全问题的八个错误，包括一个已分配CVE的NIDS错误，并建议NIDS在处理多于两个重叠数据块时不要应用双对策略。

**AI_Comments:** 本文通过开发PYROLYSE工具，对IP和TCP重组策略进行了前所未有的详尽测试，揭示了其复杂性和多样性。其创新之处在于能够系统性地发现不同网络栈和NIDS在处理重叠数据时的差异和错误。发现的漏洞，包括CVE的分配，凸显了这项研究在网络安全领域的重要性。论文提出的NIDS应调整其处理多重重叠数据块的建议，对提升网络防御机制的准确性和鲁棒性具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** IP分片和TCP分段机制允许数据包重叠，但IPv4、IPv6和TCP的重组策略在不同协议实现中存在差异。这导致网络入侵检测系统（NIDS）与被监控的主机操作系统对数据包的解释不同，从而产生漏洞。

**Method:** 本文开发了一个名为PYROLYSE的审计工具，用于穷尽测试和描述各种IP和TCP实现的重组策略。该工具通过测试n <= 3个测试用例块的所有重叠可能性以及不同的测试场景来分析PYROLYSE生成的结果。

**Result:** 重组策略的多样性远超预期，23种实现中观察到14到20种不同的行为。发现了8个影响一个操作系统、两个NIDS和两个嵌入式堆栈的错误，这些错误可能导致NIDS模式匹配绕过或DoS攻击等安全问题，其中一个NIDS错误已被分配CVE。通过分块对测试获得的IP和TCP策略通常与观察到的三元组重组不一致。

**Conclusion:** NIDS或其他网络流量分析工具在重叠数据块数量超过两个时，不应再应用n=2的对策略，因为这与观察到的三元组重组不一致。

> **ai_Abstract:** 本文介绍了PYROLYSE，一个用于审计IP和TCP重组策略的工具。研究发现，这些策略比以往认为的更为多样，并在不同实现中检测到多达20种行为。通过PYROLYSE，研究人员发现了8个安全漏洞，包括一个导致CVE的NIDS错误。研究还指出，通过对测试获得的策略在处理多重重叠时可能不准确，建议网络分析工具在处理超过两个重叠数据块时，不应仅依赖双对策略。

> **摘要翻译:** IP分片和TCP分段允许将大型数据包分割成较小的数据包，例如为了在容量有限的网络链路上进行传输。这些机制允许在重叠部分与不同数据进行完全或部分重叠。IPv4、IPv6和TCP的重组策略，即取决于重叠类型的数据块偏好，在不同的协议实现中有所不同。这导致了漏洞，因为NIDS可能会与被监控的主机操作系统以不同的方式解释数据包。一些NIDS，如Suricata或Snort，可以配置使其策略与被监控的操作系统保持一致。本文的第一个贡献是PYROLYSE，一个审计工具，它穷尽地测试和描述了各种IP和TCP实现类型的重组策略。该工具确保了实现在重组重叠数据块序列时没有错误。第二个贡献是PYROLYSE工件的分析。我们首先表明，重组策略比以前认为的要多样得多。事实上，通过测试n <= 3个测试用例块的所有重叠可能性以及不同的测试场景，我们观察到23个被测试的实现中，根据协议的不同，有14到20种不同的行为。其次，我们报告了影响一个操作系统、两个NIDS和两个嵌入式堆栈的八个错误，这些错误可能导致NIDS模式匹配绕过或DoS攻击等安全问题。一个NIDS错误被分配了CVE。最后，我们表明通过数据块对测试获得的已实现的IP和TCP策略通常与观察到的三元组重组不一致。因此，与它们目前所做的相反，当重叠数据块的数量超过两个时，NIDS或其他网络流量分析工具不应再应用n=2的对策略。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [439] [Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype](https://arxiv.org/abs/2508.00792)
> *数据移动管理器（DMM）用于SENSE-Rucio互操作原型*

*Aashay Arora, Diego Davila, Jonathan Guiang, Frank Würthwein, Harvey Newman, Justas Balcas, Tom Lehman, Xi Yang* | **Category: cs.NI** | **Updated: 2025-08-01**

**Keywords:** 数据移动管理器, Rucio, SENSE, 软件定义网络, 高能物理数据流

**Comment:** Submitted to CHEP 24

> **TL;DR:** DMM是一个连接Rucio和SENSE的原型接口，用于优化高能物理数据流，实现基于优先级的带宽分配和精细监控。

**AI_Comments:** 这篇论文的创新点在于提出了一个连接传统数据管理系统Rucio与SDN服务SENSE的接口，从而将SDN的优势引入到高能物理数据传输领域。其重要性在于优化了大型科学实验数据传输的网络效率和管理能力，特别是在带宽分配和流监控方面。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在开发一个接口，使CERN的数据管理软件Rucio能够与ESNet的软件定义网络（SDN）服务SENSE互操作，从而在现有全球LHC计算网格基础设施上实现SDN驱动的高能物理数据流，并优化网络使用。

**Method:** DMM是一个原型接口，通过连接CERN的数据管理软件Rucio和ESNet的SDN服务SENSE来实现。它通过访问主机级（网络接口）吞吐量指标和传输工具（FTS）数据传输作业级指标，实现端到端数据流监控，并支持基于传输优先级的带宽分配。

**Result:** DMM的关键特性是基于传输优先级的带宽分配，优化了网络使用。此外，它通过利用端到端数据流监控，提供了对性能不佳流的精细监控。

**Conclusion:** 论文详细介绍了数据移动管理器（DMM）的设计和实现，该管理器成功地将CERN的Rucio数据管理系统与ESNet的SENSE SDN服务连接起来，以优化高能物理数据传输。

> **ai_Abstract:** 本文介绍了数据移动管理器（DMM），这是一个连接CERN的Rucio数据管理软件与ESNet的SENSE SDN服务的原型接口。DMM旨在支持SDN驱动的高能物理数据流，并通过基于传输优先级的带宽分配来优化网络使用。它还通过端到端监控和收集主机及FTS传输指标，提供对数据流的精细监控。

> **摘要翻译:** 数据移动管理器（DMM）是一个原型接口，它将欧洲核子研究中心（CERN）的数据管理软件Rucio与ESNet的软件定义网络（SDN）服务SENSE连接起来。它利用现有的全球LHC计算网格基础设施，实现了支持SDN的高能物理数据流。DMM的一个关键特性是基于传输优先级的带宽分配，优化了网络使用。此外，它通过利用端到端数据流监控，提供了对性能不佳流的精细监控。这通过访问主机级（网络接口）吞吐量指标和传输工具（FTS）数据传输作业级指标来实现。本文详细介绍了DMM的设计和实现。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [824] [FAST-LoRa: An Efficient Simulation Framework for Evaluating LoRaWAN Networks and Transmission Parameter Strategies](https://arxiv.org/abs/2507.23342)
> *FAST-LoRa：评估LoRaWAN网络和传输参数策略的高效仿真框架*

*Laura Acosta García, Juan Aznar Poveda, Fabian Margreiter, Antonio-Javier García Sánchez, Joan García Haro, Thomas Fahringer, José Lorente López, José-Víctor Rodríguez* | **Category: cs.NI, cs.ET** | **Updated: 2025-07-31**

**Keywords:** LoRaWAN, 仿真框架, 传输参数, 能效, 计算效率

**Comment:** 

> **TL;DR:** FAST-LoRa是一个高效的LoRaWAN仿真框架，通过分析模型和矩阵操作显著减少了仿真时间，同时保持了与现有模拟器相似的准确性。

**AI_Comments:** FAST-LoRa的创新之处在于其通过简化模型和高效算法，在保证近似准确性的前提下，大幅提升了LoRaWAN仿真的速度，这对于快速迭代和优化网络参数具有重要意义。它补充了现有复杂模拟器的不足，提供了一个轻量级的替代方案。

<details>
  <summary>Details</summary>

**Motivation:** 现有LoRaWAN仿真工具计算开销大、仿真时间长，阻碍了传输参数的优化和网络性能评估。

**Method:** FAST-LoRa通过依赖分析模型（而非复杂的包级仿真）和使用高效矩阵操作实现网关接收来简化计算，作为一个轻量级、准确的近似工具。

**Result:** FAST-LoRa在估计关键网络指标（如PDR和EE）方面与现有模拟器具有相似的准确性（PDR的MAE为0.940 $\times 10^{-2}$，EE的MAE为0.040 bits/mJ），同时将计算时间缩短了多达三个数量级。

**Conclusion:** FAST-LoRa提供了一种快速、准确的LoRaWAN网络评估和传输参数选择方法，尤其适用于稳定流量和上行链路通信场景。

> **ai_Abstract:** 本文提出了FAST-LoRa，一个用于LoRaWAN网络的高效仿真框架。它通过采用分析模型和矩阵操作而非复杂的包级仿真，显著降低了计算开销和仿真时间。评估结果显示，FAST-LoRa在保证与现有模拟器相似的准确性的同时，能将计算时间缩短高达三个数量级，特别适用于评估稳定流量和上行链路通信场景下的传输参数策略。

> **摘要翻译:** 物联网（IoT）已经改变了许多行业，而基于LoRa（远距离）技术构建的LoRaWAN（远距离广域网）已成为在广域网络中实现可扩展、低成本和高能效通信的关键解决方案。仿真工具对于优化传输参数以及提高LoRaWAN网络的能效和性能至关重要。虽然现有的仿真框架通过包含多层通信协议准确地复制了真实世界的场景，但它们通常意味着显著的计算开销和仿真时间。为了解决这个问题，本文引入了FAST-LoRa，一个新颖的仿真框架，旨在实现对LoRaWAN网络和传输参数选择的快速高效评估。FAST-LoRa通过依赖分析模型（而不是复杂的包级仿真）和使用高效的矩阵操作实现网关接收来简化计算。FAST-LoRa并非旨在取代离散事件模拟器，而是作为一个轻量级且准确的近似工具，用于在流量模式稳定和以上行链路为主的通信场景中评估传输参数策略。在我们的评估中，我们将FAST-LoRa与一个成熟的模拟器进行了比较，使用了不同数量的终端设备和网关的多种网络配置。结果表明，FAST-LoRa在估计关键网络指标方面实现了相似的准确性，即使在存在干扰和多网关接收的复杂场景中，其数据包传输率（PDR）的平均绝对误差（MAE）为0.940 $\times 10^{-2}$，能效（EE）的平均绝对误差为0.040 bits/mJ，同时将计算时间显著减少了多达三个数量级。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [875] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
> *基于马尔可夫链框架和ITU-R传播模型的可扩展频谱可用性预测*

*Abir Ray* | **Category: cs.NI, cs.AI, cs.CL, cs.NA, math.NA** | **Updated: 2025-07-30**

**Keywords:** 频谱可用性预测, 马尔可夫链, ITU-R传播模型, 动态频谱接入, 认知无线电

**Comment:** 12 pages

> **TL;DR:** 本文提出了一种结合马尔可夫链和ITU-R传播模型的可扩展框架，用于准确且低成本地预测频谱在时间和空间上的可用性，适用于动态频谱共享系统。

**AI_Comments:** 该论文的创新点在于将马尔可夫链模型（用于时间域预测）与ITU-R传播模型（用于空间域预测）相结合，提供了一个统一且可扩展的频谱可用性预测框架。其强调的低计算成本和实时管理能力，使其在动态频谱共享和认知无线电领域具有重要的实际应用价值。该框架的灵活性使其能够适应不同的频段和场景，进一步提升了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 频谱资源在时间和空间上经常未被充分利用，这促使了动态频谱接入策略的出现。关键挑战在于预测频谱何时何地可用，以实现主动且无干扰的接入。

**Method:** 本文提出了一种可扩展的频谱可用性预测框架，该框架结合了主用户活动的二态马尔可夫链模型与ITU-R（P.528和P.2108建议书）高精度传播模型。马尔可夫链捕捉时间占用模式，传播模型结合路径损耗和杂波效应来确定主信号是否超过干扰阈值。该方法能够更准确地预测时间和空间上的频谱机会。

**Result:** 结果和分析表明，所提出的方法能够以较低的计算成本有效识别可用频谱。

**Conclusion:** 所提出的框架是灵活的，可以适应各种频段和场景，并且能够以较低的计算成本有效识别可用频谱，使其适用于认知无线电网络和其他动态频谱共享系统中的实时频谱管理。

> **ai_Abstract:** 本文提出了一个可扩展的频谱可用性预测框架，旨在解决动态频谱接入中预测频谱可用性的挑战。该框架结合了描述主用户活动时间模式的二态马尔可夫链模型和考虑路径损耗与杂波效应的ITU-R高精度传播模型，从而能够准确预测频谱在时间和空间上的可用性。研究开发了相应的系统模型和算法，并分析了其可扩展性和计算效率。结果表明，该方法能有效识别可用频谱，且计算成本低，适用于认知无线电网络等实时频谱管理系统。

> **摘要翻译:** 频谱资源在时间和空间上经常未被充分利用，这促使了动态频谱接入策略的出现，使次级用户能够利用未使用的频率。一个关键挑战是预测频谱何时何地可用（即未被主要许可用户使用），以实现主动且无干扰的接入。本文提出了一种可扩展的频谱可用性预测框架，该框架结合了主用户活动的二态马尔可夫链模型与ITU-R（特别是建议书P.528和P.2108）的高精度传播模型。马尔可夫链捕捉时间占用模式，而传播模型则结合路径损耗和杂波效应来确定主信号是否超过次级用户位置的干扰阈值。通过整合这些组件，所提出的方法可以更准确地预测时间和空间上的频谱机会。我们开发了该方法的系统模型和算法，分析了其可扩展性和计算效率，并讨论了假设、局限性和潜在应用。该框架是灵活的，可以适应各种频段和场景。结果和分析表明，所提出的方法能够以较低的计算成本有效识别可用频谱，使其适用于认知无线电网络和其他动态频谱共享系统中的实时频谱管理。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [927] [Agent Network Protocol Technical White Paper](https://arxiv.org/abs/2508.00007)
> *代理网络协议技术白皮书*

*Gaowei Chang, Eidan Lin, Chengxuan Yuan, Rizhao Cai, Binbin Chen, Xuan Xie, Yin Zhang* | **Category: cs.NI, cs.AI** | **Updated: 2025-07-18**

**Keywords:** 代理网络协议, ANP, AI代理, 互联网基础设施, 互操作性

**Comment:** This white paper is a reformatted version of the open-source
  community edition previously released by the ANP Open Source Technology
  Community(https://github.com/agent-network-protocol)

> **TL;DR:** 代理网络协议 (ANP) 提出了一种新的通信协议，旨在解决现有互联网基础设施不适用于大规模代理互联和协作的问题，通过分层协议系统实现代理身份认证、动态协商和能力发现互操作。

**AI_Comments:** 该白皮书提出了一种具有前瞻性的协议设计，旨在解决AI代理在现有互联网架构下互联互通的痛点。其AI原生设计理念和分层协议体系结构具有创新性，为未来代理网络的构建奠定了基础。重要性在于其试图标准化代理间的通信，可能促进AI生态的互操作性和规模化发展。

<details>
  <summary>Details</summary>

**Motivation:** 随着大模型和自主决策AI的发展，代理正迅速成为互联网的新实体。然而，现有互联网基础设施主要为人类交互设计，导致数据孤岛、不友好的接口以及代理间高昂的协作成本，难以支持大规模代理互联和协作的需求。

**Method:** 代理网络协议 (ANP) 提出了一种面向代理网络的下一代通信协议。它遵循AI原生设计、兼容现有互联网协议、采用模块化可组合架构、遵循极简可扩展原则，并可基于现有基础设施快速部署。通过三层协议系统——身份与加密通信层、元协议协商层和应用协议层——系统性地解决问题。

**Result:** ANP 系统性地解决了代理身份认证、动态协商和能力发现互操作性等问题，使大规模代理互联和协作成为可能。

**Conclusion:** 代理网络协议 (ANP) 旨在通过其AI原生设计和分层协议系统，为代理网络提供下一代通信基础设施，以适应代理取代传统软件、普遍互联、原生协议连接以及自主组织协作的互联网发展趋势。

> **ai_Abstract:** 本白皮书介绍了代理网络协议 (ANP)，旨在解决当前互联网基础设施不适合大规模代理互联与协作的问题。ANP 提出了一种AI原生、模块化、可扩展的新一代通信协议，通过三层协议系统（身份与加密通信层、元协议协商层、应用协议层）解决代理身份认证、动态协商和能力发现互操作性，以适应代理取代传统软件、普遍互联等互联网发展趋势。

> **摘要翻译:** 随着大模型和自主决策AI的发展，代理正迅速成为继移动应用之后互联网的新实体。然而，现有互联网基础设施主要为人类交互设计，导致数据孤岛、不友好的接口以及代理间高昂的协作成本，难以支持大规模代理互联和协作的需求。互联网正在经历一场深刻的变革，呈现出四大核心趋势：代理取代传统软件、普遍的代理互联、基于原生协议的连接以及自主的代理组织和协作。为顺应这些趋势，代理网络协议 (ANP) 提出了一种面向代理网络的下一代通信协议。ANP 秉持AI原生设计，保持与现有互联网协议的兼容性，采用模块化可组合架构，遵循极简但可扩展的原则，并可基于现有基础设施快速部署。通过三层协议系统——身份与加密通信层、元协议协商层和应用协议层——ANP 系统性地解决了代理身份认证、动态协商和能力发现互操作性等问题。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csos'></a>
## cs.OS 

### [199] [Composable OS Kernel Architectures for Autonomous Intelligence](https://arxiv.org/abs/2508.00604)
> *用于自主智能的可组合操作系统内核架构*

*Rajpreet Singh, Vidhi Kothari* | **Category: cs.OS, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 操作系统内核, 人工智能, 可加载内核模块, 神经符号系统, 自主智能

**Comment:** 8 pages

> **TL;DR:** 本文提出一种新的操作系统内核架构，旨在将传统内核转变为适应性强、AI集成的平台，以支持智能系统在边缘设备、云和嵌入式实时环境中的应用。

**AI_Comments:** 本文提出了一种前瞻性的操作系统内核设计理念，旨在解决智能系统日益增长的计算需求。其创新之处在于将AI能力深度集成到内核层面，而非仅仅作为应用层支持，特别是将LKMs重新定义为AI计算单元和引入神经符号设计，这为未来操作系统发展提供了新的方向。该研究对于边缘AI和实时智能系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着智能系统渗透到边缘设备、云基础设施和嵌入式实时环境中，需要一种新的操作系统内核架构来将内核从静态资源管理器转变为适应性强、AI集成的平台。

**Method:** 1. 将可加载内核模块（LKMs）视为面向AI的计算单元，用于内核空间中的快速感知和认知处理。2. 将Linux内核扩展为AI原生环境，内置深度学习推理、浮点加速和实时自适应调度，以实现高效的机器学习工作负载。3. 引入神经符号内核设计，利用范畴论和同伦类型论来统一操作系统内部的符号推理和可微逻辑。

**Result:** 这些方法共同使操作系统能够主动预测并适应自主智能应用程序的认知需求。

**Conclusion:** 本文提出的方法使操作系统能够主动预测并适应自主智能应用程序的认知需求，将内核从静态资源管理器转变为适应性强、AI集成的平台。

> **ai_Abstract:** 本研究提出一种用于智能系统的新型可组合操作系统内核架构，旨在将传统内核从静态资源管理器转变为适应性强、AI集成的平台。其主要创新包括将可加载内核模块用作AI计算单元、扩展Linux内核以支持AI原生环境（如内置深度学习推理和实时调度），以及引入结合范畴论和同伦类型论的神经符号内核设计，以统一符号推理和可微逻辑。这些方法共同使操作系统能够主动适应自主智能应用的认知需求。

> **摘要翻译:** 随着智能系统渗透到边缘设备、云基础设施和嵌入式实时环境中，本研究提出了一种用于智能系统的新型操作系统内核架构，将内核从静态资源管理器转变为适应性强、AI集成的平台。主要贡献包括：(1) 将可加载内核模块（LKMs）视为面向AI的计算单元，用于内核空间中的快速感知和认知处理；(2) 将Linux内核扩展为AI原生环境，内置深度学习推理、浮点加速和实时自适应调度，以实现高效的机器学习工作负载；(3) 引入神经符号内核设计，利用范畴论和同伦类型论来统一操作系统内部的符号推理和可微逻辑。总而言之，这些方法使操作系统能够主动预测并适应自主智能应用程序的认知需求。

</details>

[⬆️ 返回分类顶部](#csos) | [⬆️ 返回总目录](#toc)

---

<a id='cspf'></a>
## cs.PF 

### [525] [DGEMM without FP64 Arithmetic -- using FP64 Emulation and FP8 Tensor Cores with Ozaki Scheme](https://arxiv.org/abs/2508.00441)
> *无需FP64算术的DGEMM——使用FP64仿真和FP8张量核心结合Ozaki方案*

*Daichi Mukunoki* | **Category: cs.PF, cs.AR, cs.MS** | **Updated: 2025-08-01**

**Keywords:** DGEMM, FP64仿真, FP8张量核心, Ozaki方案, 低精度算术

**Comment:** 

> **TL;DR:** 本研究探讨了如何在缺乏原生FP64支持或FP64性能较慢的现代AI硬件上，利用Ozaki方案、FP8张量核心和FP64仿真来实现FP64矩阵乘法（DGEMM）。

**AI_Comments:** 该论文解决了AI优化硬件与传统科学计算高精度需求之间的关键鸿沟。其创新之处在于将Ozaki方案适应于利用最新的FP8张量核心，并引入FP64仿真以支持无原生FP64的硬件，同时结合了新的分块策略。这对于扩展现代GPU在科学工作负载中的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** AI计算对低精度矩阵乘法的需求日益增长，导致处理器为此类操作的性能增强，但这些低精度操作难以直接用于需要FP64的科学计算。Ozaki方案虽能利用低精度运算实现FP64 DGEMM，但其早期基于整数算术的扩展在面对最新倾向于增强FP8而非INT8性能的AI硬件时，可能不再是最优解。此外，一些处理器对FP64操作支持缓慢甚至不提供支持，因此需要新的方法来在这些硬件上高效执行DGEMM。

**Method:** 本研究重新审视了Ozaki方案中低精度浮点运算的利用，特别关注FP6和FP8张量核心的应用。同时，针对FP64操作非常慢或不支持的处理器，研究了基于整数算术的FP64仿真。此外，还提出并检验了一种新的分块策略。通过在Blackwell架构GPU上评估使用FP8张量核心和FP64仿真进行DGEMM的性能，以证明这些方法的有效性。

**Result:** 通过在Blackwell架构GPU上评估使用FP8张量核心和FP64仿真进行DGEMM的性能，证明了所提出方法的有效性。

**Conclusion:** 本研究提出的结合FP8张量核心、FP64仿真和新分块策略的方法，能够有效实现在缺乏或FP64性能较差的现代AI硬件上进行高精度的DGEMM运算。

> **ai_Abstract:** 本论文探讨了如何在以低精度浮点运算（如FP8）为主的现代AI硬件上实现FP64矩阵乘法（DGEMM）。基于Ozaki方案，该研究利用FP6和FP8张量核心，并针对缺乏原生FP64支持的处理器引入了基于整数算术的FP64仿真。此外，论文还提出了一种新的分块策略。通过在Blackwell架构GPU上的性能评估，验证了这些方法在AI优化硬件上执行科学计算的有效性。

> **摘要翻译:** 由于AI计算需要低精度矩阵乘法，随着AI计算需求的增长，对这些操作性能增强的处理器也越来越多。然而，直接将这些操作用于科学计算是困难的。Ozaki等人于2012年提出的Ozaki方案，是一种精确的矩阵乘法方法，它能够使用FP16等低精度浮点运算实现FP64矩阵乘法（DGEMM）。该方法随后被扩展以利用整数算术。与基于浮点的方法相比，使用整数运算降低了计算成本。它还在AI工作负载中，在具有快速INT8张量核心的GPU上，表现出比硬件FP64操作更高的性能。然而，最新的硬件倾向于增强FP8等低精度浮点运算性能，而非INT8。本研究考虑最新的AI硬件，重新审视Ozaki方案中低精度浮点运算的利用。具体来说，我们考虑使用FP6和FP8张量核心。此外，对于支持非常慢的FP64操作或根本不支持的处理器，我们考虑使用基于整数算术的FP64仿真。我们还研究了一种新的分块策略。我们通过评估在Blackwell架构GPU上使用FP8张量核心和FP64仿真进行DGEMM的性能，证明了这些方法的有效性。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [67] [Abstractions of Sequences, Functions and Operators](https://arxiv.org/abs/2507.23151)
> *序列、函数和算子的抽象*

*Louis Rustenholz, Pedro Lopez-Garcia, Manuel V. Hermenegildo* | **Category: cs.PL, cs.LO** | **Updated: 2025-07-30**

**Keywords:** 高阶抽象解释, B-bound域, 伽罗瓦连接, 程序分析, 非线性不变量

**Comment:** Under consideration for publication in STTT

> **TL;DR:** 本文提出了新的约束型抽象域（B-bound域）和域抽象方法，用于推断递归函数的非线性界限，显著改进了高阶抽象解释在程序和混合系统分析中的能力。

**AI_Comments:** 本文的创新之处在于提出了B-bound域，它通过结合预选边界函数的界限来处理传统数值抽象域难以应对的高度非线性不变量。发现约束空间的凸性性质对转移函数设计的自动化具有重要意义，极大地提高了实用性。域抽象的概念也为处理不同类型函数（符号到数值）的抽象提供了通用框架，并有助于降维，这对于复杂系统分析至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决推断递归定义函数（即算子不动点或函数方程解）的闭合形式界限的挑战。这在程序分析（如成本分析、循环加速、声明式语言分析）和由微分方程控制的混合系统中有广泛应用。

**Method:** 1. 提出了一个新的基于约束的数值函数抽象域家族，即B-bound域，它通过预选边界函数集的界限合取来抽象函数，以推断高度非线性数值不变量。
2. 揭示了约束空间中的一个凸性性质，该性质简化了转移函数的设计，并在某些情况下实现了完全自动化。
3. 引入了域抽象，这是一个将值空间中的任意映射提升到函数空间中伽罗瓦连接的函子，支持从符号函数到数值函数的抽象（即大小抽象），并实现了方程的降维。
4. 转移函数的构造基于一种简单的算子语言，从序列开始，并扩展到包括多元、分段和非离散域在内的更通用函数。

**Result:** 1. B-bound域能够推断经典数值抽象域难以处理的高度非线性数值不变量。
2. 发现的凸性性质简化了转移函数的设计，并在某些情况下实现了完全自动化。
3. 域抽象支持从符号函数到数值函数的抽象，并实现了方程的降维。

**Conclusion:** 本文在高阶抽象解释领域提出了理论和实践成果，通过引入创新的抽象域和技术，解决了推断递归函数复杂界限的挑战，从而提升了程序和混合系统分析的能力。

> **ai_Abstract:** 本文在高阶抽象解释框架下，针对推断递归定义函数（如程序分析和混合系统中的不动点）的闭合形式界限问题，提出了一系列理论和实践成果。主要贡献包括引入了新的B-bound域，这是一种基于约束的抽象域，能够推断高度非线性的数值不变量，并利用约束空间中的凸性简化了转移函数设计。此外，还提出了域抽象方法，将值空间映射提升为函数空间的伽罗瓦连接，从而支持符号到数值函数的抽象和方程降维。这些方法基于一个扩展的算子语言，适用于多种函数类型。

> **摘要翻译:** 我们提出了关于函数格序理论的理论和实践成果，重点关注抽象（函数集）的伽罗瓦连接——一个被称为高阶抽象解释的主题。
我们的动机是推断递归定义函数（即算子不动点，或等价地，函数方程的解）的闭合形式界限的挑战。这在程序分析（例如成本分析、循环加速、声明式语言分析）和由微分方程控制的混合系统中具有多重应用。
我们的主要贡献是一种新的基于约束的数值函数抽象域家族，即B-bound域，它通过预选边界函数集的界限合取来抽象函数f。它们允许推断高度非线性的数值不变量，这是经典数值抽象域难以处理的。我们揭示了约束空间中的一个凸性性质，该性质简化了转移函数的设计，并在某些情况下实现了完全自动化。
我们还引入了域抽象，这是一个将值空间中的任意映射提升到函数空间中伽罗瓦连接的函子。这支持从符号函数到数值函数的抽象（即大小抽象），并实现了方程的降维。
我们的转移函数构造基于一种简单的算子语言，从序列开始，并扩展到包括多元、分段和非离散域在内的更通用函数。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [426] [A Compute-Matched Re-Evaluation of TroVE on MATH](https://arxiv.org/abs/2507.22069)
> *TroVE在MATH数据集上的计算匹配再评估*

*Tobias Sesterhenn, Ian Berlot-Attwell, Janis Zenkner, Christian Bartelt* | **Category: cs.PL, cs.AI** | **Updated: 2025-07-31**

**Keywords:** LLM, MATH, TroVE, 计算预算, 再评估

**Comment:** 

> **TL;DR:** 本研究重新评估了TroVE在MATH基准上的表现，发现其声称的优势并非来自其工具箱机制，而仅仅是由于使用了更高的计算预算。在计算预算匹配后，TroVE的优势显著降低，表明其工具箱方法并未带来显著提升。

**AI_Comments:** 这篇论文的重要性在于它挑战了先前关于大型语言模型在数学问题解决中利用工具箱的有效性的结论。它强调了在比较不同模型和方法时进行公平计算预算匹配的重要性，揭示了性能提升可能源于资源投入而非方法论创新。这对于未来的研究，特别是LLM的评估，提供了重要的警示和指导。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究TroVE声称通过引入和重用高级工具箱，可以使代码生成大型语言模型（LLMs）在MATH基准测试中获得类似益处。然而，最近的分析（Berlot-Attwell et al., 2024）对这些收益提出了质疑，指出所创建的工具通常是微不足道的或很少被重用，暗示改进可能源于自洽性或自校正。因此，本研究的动机是重新评估TroVE，分析其每个模式的影响，并确定其益处来源。

**Method:** 本研究重新评估了TroVE在MATH数据集上的表现，并分析了其各个模式的影响。作者还对TroVE选择机制的原始实现进行了小幅修正，将TroVE在MATH上的准确率提高了3%。最关键的是，研究在计算预算匹配的条件下比较了TroVE和PRIMITIVE基线模型的性能。

**Result:** 研究结果表明，TroVE的益处并非来自其工具箱机制，而仅仅是因为相比PRIMITIVE基线模型，TroVE花费了更高的计算预算。在对计算预算进行匹配后，TroVE的优势降低到微不足道的1%提升。此外，对原始实现的小幅修正使TroVE的性能提高了3%。

**Conclusion:** 本研究的结论是，TroVE的工具箱方法在MATH数据集上并未提供显著的益处。其声称的性能提升主要是由于更高的计算预算，而非其工具创建和重用机制。

> **ai_Abstract:** 本研究对先前的TroVE工作在MATH基准测试上进行了计算匹配的再评估。TroVE声称通过工具箱方法优于直接生成基线，但本研究发现其主要优势源于更高的计算预算而非工具机制本身。在修正了TroVE的实现并匹配计算预算后，TroVE的性能提升显著下降至仅1%，表明其工具箱方法在MATH数据集上并未带来显著的实际收益。

> **摘要翻译:** 重用已建立的定理和公式是数学问题解决的核心，它们是应对日益复杂挑战的重要基石。最近的工作TroVE认为，通过诱导和重用更高级的工具箱，代码生成大型语言模型（LLMs）在MATH基准测试中也能获得类似的益处。通过将计算预算分配给三种模式的集合——直接生成代码、创建工具和重用工具——TroVE声称其性能优于仅执行直接生成的PRIMITIVE基线。然而，最近的分析（Berlot-Attwell et al., 2024）对这些收益提出了质疑，指出所创建的工具通常是微不足道的或很少被重用，暗示改进可能源于自洽性或自校正。在这项工作中，我们重新评估了TroVE在MATH上的表现，分析了其每种模式的影响，并表明其益处并非来自这些机制，而仅仅是由于TroVE相比PRIMITIVE花费了更高的计算预算。为此，我们还对TroVE选择机制的原始实现进行了一个小幅修正，将TroVE在MATH上的准确率提高了3%。在匹配计算预算后，TroVE的益处降低到微不足道的1%的提升，这表明这种工具箱方法在MATH上并未提供显著的益处。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [445] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
> *使用约束建模程序合成中的程序空间*

*Tilman Hinnerichs, Bart Swinkels, Jaap de Jong, Reuben Gardos Reid, Tudor Magirescu, Neil Yorke-Smith, Sebastijan Dumancic* | **Category: cs.PL, cs.AI** | **Updated: 2025-07-10**

**Keywords:** 程序合成, 约束, 程序空间, 句法约束, BART

**Comment:** 

> **TL;DR:** 本文提出了一种利用句法约束来建模程序空间的方法，并通过BART求解器演示，有效地减少了程序空间并加快了枚举时间。

**AI_Comments:** 本文的创新之处在于将约束从单纯表达程序语义扩展到用于建模和限制程序语法，从而在程序执行前就能有效剪枝搜索空间。这种方法对于应对程序合成中的组合爆炸问题具有重要意义。BART求解器的引入也展示了该理论的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 程序合成的核心挑战是驯服庞大的可能程序空间。由于程序合成本质上是组合搜索，现有方法使用约束来表达程序语义，但未有效利用其作为去除不必要程序的工具。最近的归纳逻辑编程方法引入了程序语法的约束，但需要进一步利用。

**Method:** 本文利用句法约束来建模程序空间，不仅定义了可行的解决方案，还定义了可能有用（likely useful）的解决方案。为了验证这一思想，引入了一个名为BART的求解器，用于高效地传播和解决这些约束。

**Result:** BART在程序空间枚举任务上进行了评估，结果发现约束消除了高达99%的程序空间，并且对程序空间进行建模显著减少了枚举时间。

**Conclusion:** 通过利用句法约束建模程序空间，可以显著减少程序合成中的搜索空间，从而提高程序枚举的效率。

> **ai_Abstract:** 本文提出了一种在程序合成中利用句法约束来有效建模程序空间的新方法。与传统仅用于表达语义的约束不同，该方法通过在程序语法上施加约束，不仅识别可行的程序，还识别出可能更有用的程序。研究引入了BART求解器来高效处理这些约束。实验结果表明，该方法能够消除高达99%的程序空间，并显著缩短程序枚举时间，从而有效解决了程序合成中搜索空间过大的问题。

> **摘要翻译:** 程序合成的一个核心挑战是驯服庞大的可能程序空间。由于程序合成本质上是组合搜索，社区一直在寻求利用强大的组合约束求解器。在这里，约束被用来表达程序语义，但没有作为一种潜在的强大工具来去除不必要的程序。最近的归纳逻辑编程方法引入了对要合成的程序语法的约束。这些句法约束允许在不执行程序的情况下检查和传播约束，因此适用于任意操作符。在这项工作中，我们利用句法约束来建模程序空间，不仅定义了可行的解决方案，还定义了可能有用（likely useful）的解决方案。为了演示这一思想，我们引入了BART，一个能够高效传播和解决这些约束的求解器。我们对BART在程序空间枚举任务上进行了评估，发现这些约束消除了高达99%的程序空间，并且对程序空间进行建模显著减少了枚举时间。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [470] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
> *从可证明的正确性到概率生成：程序合成范式的比较综述*

*Zurabi Kobaladze, Anna Arnania, Tamar Sanikidze* | **Category: cs.PL, I.2.6; F.1.1** | **Updated: 2025-07-21**

**Keywords:** 程序合成, 比较综述, 神经网络模型, 神经符号, 形式逻辑

**Comment:** 78 pages. Undergraduate thesis project submitted in partial
  fulfillment of the requirements for the Bachelor's degree in Computer Science
  at Kutaisi International University

> **TL;DR:** 本论文综述了程序合成范式的演变，从形式逻辑方法到大规模神经网络模型，比较了五种关键方法及其权衡，并强调向神经符号方法的转变。

**AI_Comments:** 这篇论文为程序合成领域提供了一个宝贵且全面的概述，系统地比较了不同范式及其演变。其优势在于强调了从传统符号方法向现代数据驱动和混合神经符号方法的转变，这对于理解自动代码生成领域的当前格局和未来挑战至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 程序合成领域在过去五十年中取得了显著发展，本研究旨在对塑造该领域的主要范式进行比较性文献综述，追溯其演变，分析不同方法，并指出其权衡与未来方向。

**Method:** 本论文通过比较文献综述的方式，考察了程序合成领域的五种主要范式：基于逻辑（演绎）的合成、归纳（基于示例）的合成、基于草图/模式的合成、基于大型语言模型的合成以及神经符号混合方法。对于每种方法，论文分析了其基本原理、著名系统、实际应用，并强调了正确性保证、规范要求、搜索复杂性和表达能力之间的权衡。

**Result:** 该综述突出了程序合成领域从形式化验证工具（如KIDS和Coq）到数据驱动模型（如Codex）的演变，并强调了从符号方法到混合神经符号方法的转变。论文讨论了在正确性、规范要求、搜索复杂性和表达能力方面的权衡。

**Conclusion:** 本论文全面叙述了程序合成的进展和持续挑战，并概述了可靠和可扩展程序合成的未来方向，特别强调了神经符号混合方法。

> **ai_Abstract:** 本论文对程序合成领域进行了比较性文献综述，追溯了该领域从形式逻辑到大规模神经网络模型的演变。论文考察了五种主要范式——包括基于逻辑、归纳、基于草图/模式、基于大型语言模型和神经符号混合的方法——分析了它们的基本原理、系统、应用以及在正确性、规范、搜索复杂性和表达能力方面的权衡。该工作强调了从符号方法向神经符号混合方法的转变，并探讨了实现可靠和可扩展程序合成的未来方向。

> **摘要翻译:** 程序合成——从高级规范自动生成可执行代码——五十多年来一直是计算机科学的核心目标。本论文对塑造该领域的主要范式进行了比较文献综述，追溯了其从基于形式逻辑的方法到使用大规模神经模型的最新进展的演变。我们考察了五种关键方法：基于逻辑（演绎）的合成、归纳（基于示例）的合成、基于草图/模式的合成、基于大型语言模型的合成以及神经符号混合方法。对于每种方法，我们分析了其基本原理、著名系统和实际应用，强调了正确性保证、规范要求、搜索复杂性和表达能力之间的权衡。通过回顾从KIDS和Coq等形式化验证合成工具到Codex等从自然语言生成概率代码的数据驱动模型的发展，我们提供了一个关于进展和持续挑战的全面叙述。这项工作强调了从符号方法到混合神经符号方法的转变，并概述了可靠和可扩展程序合成的未来方向。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [498] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
> *扩展摘要：具有多种实现的易变对象*

*Matt Kaufmann, Yahya Sohail, Warren A. Hunt Jr* | **Category: cs.PL, cs.LO** | **Updated: 2025-07-25**

**Keywords:** ACL2, attach-stobj, stobj, 重新认证, 可变对象

**Comment:** In Proceedings ACL2 2025, arXiv:2507.18567

> **TL;DR:** ACL2 8.6引入了`attach-stobj`功能，允许抽象`stobj`有不同的可执行操作，无需重新认证。

**AI_Comments:** 这项功能通过允许在不重新认证的情况下更改`stobj`的实现，显著提升了ACL2在处理可变对象时的灵活性和开发效率。

<details>
  <summary>Details</summary>

**Motivation:** 允许给定的抽象`stobj`支持不同的可执行操作，同时无需对其引入书籍或相关定理进行重新认证。

**Method:** 论文概述了ACL2的`attach-stobj`功能，该功能通过提供背景、用户级概览和实现说明来支持对给定抽象`stobj`的不同可执行操作，且无需重新认证。

**Result:** `attach-stobj`功能使得一个给定的抽象`stobj`能够支持不同的可执行操作，并且无需对其引入书籍或相关定理进行重新认证。

**Conclusion:** `attach-stobj`功能通过消除不必要的重新认证需求，显著提高了ACL2中处理具有多种实现的可变对象的灵活性和效率。

> **ai_Abstract:** 这份扩展摘要介绍了ACL2 8.6版中新增的`attach-stobj`功能。该功能允许为抽象`stobj`定义多种可执行操作，且无需对引入该`stobj`的书籍或其定理进行重新认证。论文还提供了背景、用户指南和实现细节。

> **摘要翻译:** 这份扩展摘要概述了ACL2的一个特性，即`attach-stobj`，该特性首次出现在ACL2 8.6版本（2024年10月）。该特性支持给定抽象`stobj`的不同可执行操作，而无需对其引入书籍或相关定理进行重新认证。本文提供了背景信息、用户级概览以及一些实现说明。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [519] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
> *使用大型语言模型在 Python 中进行自动化类型标注*

*Varun Bharti, Shashwat Jha, Dhruv Kumar, Pankaj Jalote* | **Category: cs.PL, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 类型标注, 大型语言模型, Python, 自动化, 代码理解

**Comment:** Under Review

> **TL;DR:** 本文探索了使用大型语言模型（LLMs）在 Python 中进行类型标注，并开发了一个“生成-检查-修复”的流水线，结果显示LLMs在无需特定微调的情况下，能有效生成高质量的类型标注。

**AI_Comments:** 该论文的创新点在于将大型语言模型应用于自动类型标注这一特定编程任务，并设计了一个实用的“生成-检查-修复”流水线，有效结合了LLM的生成能力和静态分析工具的验证能力。其重要性在于证明了LLMs在无需大量领域特定微调的情况下，也能在代码理解和生成方面表现出色，为软件开发自动化提供了新的思路。此外，研究结果表明，LLMs在某些方面甚至可以与传统需要大量标记数据训练的深度学习方法竞争，这对于资源有限的场景具有重要意义。该流水线的设计也使其具有良好的可扩展性。

<details>
  <summary>Details</summary>

**Motivation:** Python 中的类型标注可以提高可维护性和错误检测能力，但手动生成容易出错且耗时。传统的自动化方法（如静态分析、机器学习、深度学习）存在类型词汇有限、行为过度近似以及依赖大量标记数据集等问题。

**Method:** 本文探索了使用大型语言模型（LLMs）生成 Python 类型标注。开发了一个“生成-检查-修复”的流水线：LLM 根据具体语法树（CST）表示提出标注，静态类型检查器 Mypy 进行验证，错误反馈用于迭代修复。在 ManyTypes4Py 基准测试的 6000 个代码片段上评估了四种 LLM 变体：GPT 4oMini、GPT 4.1mini（通用型）、O3Mini、O4Mini（推理优化型）。

**Result:** GPT 4oMini 在 65.9% 的情况下实现了 Mypy 报告无错误的一致性，而 GPT 4.1mini、O3Mini 和 O4Mini 各自达到了约 88.6% 的一致性。在标注质量方面，GPT 4.1mini 和 O3Mini 表现最佳，实现了高达 70.5% 的精确匹配和 79.1% 的基础类型准确率，平均只需不到一次修复迭代。结果表明，通用型和推理优化型 LLMs 在无需任务特定微调或额外训练的情况下，能有效生成一致的类型标注，并且与需要大量标记数据集进行训练的传统深度学习技术具有竞争力。

**Conclusion:** 通用型和推理优化型大型语言模型，在没有经过任何特定任务微调或额外训练的情况下，能够有效地生成一致的类型标注，并且与需要大量标记数据集进行训练的传统深度学习技术相比具有竞争力。该流水线可以扩展到其他可选类型命令式语言。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLMs）自动生成 Python 类型标注的方法。针对手动标注的困难和传统自动化方法的局限性，作者开发了一个“生成-检查-修复”的流水线，结合LLM的标注生成能力和静态类型检查器Mypy的验证反馈机制。通过在ManyTypes4Py基准测试上对多种LLM变体进行评估，研究发现通用型和推理优化型LLMs在无需特定微调的情况下，能够生成高一致性和准确性的类型标注，其性能可与依赖大量训练数据的传统深度学习技术相媲美。该方法为Python类型标注自动化提供了一种有效的新途径，并具有向其他语言扩展的潜力。

> **摘要翻译:** Python 中的类型标注增强了可维护性和错误检测。然而，手动生成这些标注容易出错且需要额外的精力。传统的自动化方法，如静态分析、机器学习和深度学习，在类型词汇有限、行为过度近似以及依赖大量标记数据集方面存在困难。在这项工作中，我们探索了使用大型语言模型（LLMs）在 Python 中生成类型标注。我们开发了一个生成-检查-修复的流水线：LLM 在具体语法树表示的指导下提出标注，静态类型检查器（Mypy）验证它们，任何错误都会反馈以进行迭代细化。我们评估了四种 LLM 变体：GPT 4oMini、GPT 4.1mini（通用型）和 O3Mini、O4Mini（推理优化型），在来自 ManyTypes4Py 基准测试的 6000 个代码片段上。我们首先测量了 LLM 标注的代码片段中 MyPy 报告无错误的比例（即一致性结果）：GPT 4oMini 在 65.9% 的情况下达到了一致性（34.1% 不一致），而 GPT 4.1mini、O3Mini 和 O4Mini 各自达到了约 88.6% 的一致性（约 11.4% 的失败）。为了测量标注质量，我们计算了所有 6000 个片段的精确匹配和基础类型匹配准确率：GPT 4.1mini 和 O3Mini 表现最佳，实现了高达 70.5% 的精确匹配和 79.1% 的基础类型准确率，平均只需要不到一次修复迭代。我们的结果表明，通用型和推理优化型 LLM，在没有任何任务特定微调或额外训练的情况下，可以有效地生成一致的类型标注。它们的表现与需要大量标记数据集进行训练的传统深度学习技术具有竞争力。虽然我们的工作专注于 Python，但该流水线可以扩展到其他可选类型命令式语言，如 Ruby。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [540] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
> *Erlang中映射的语义子类型*

*Erdem Yildirim, Albert Schimpf, Stefan Wehr, Annette Bieniusa* | **Category: cs.PL** | **Updated: 2025-08-01**

**Keywords:** 语义子类型, Erlang, 映射类型, 集合论模型, 类型系统

**Comment:** 

> **TL;DR:** 本文为Erlang中的映射类型构建了一个集合论类型模型，并定义了基于集合包含的语义子类型关系，其新颖之处在于参数化映射类型的子类型定义。

**AI_Comments:** 本文的创新点在于为Erlang中的参数化映射类型定义了语义子类型关系，这可能对Erlang语言的类型系统和静态分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在Erlang中为映射类型，特别是参数化映射类型，定义语义子类型关系。

**Method:** 构建了一个包含类型变量、基本类型、集合论类型和映射类型的集合论类型模型，并基于集合包含定义了语义子类型关系。

**Result:** 成功构建了Erlang中映射类型的集合论模型，并定义了适用于所有Erlang映射类型的语义子类型关系。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文构建了一个用于Erlang中映射类型的集合论类型模型，该模型涵盖了Erlang所有映射类型，并基于集合包含定义了语义子类型关系。其核心创新在于为参数化映射类型定义了子类型。

> **摘要翻译:** 在本文中，我们将构建一个包含类型变量、基本类型、集合论类型和映射类型的集合论模型。映射类型的语法涵盖了Erlang中所有可用的映射类型。该类型模型用于定义基于集合包含的语义子类型关系。这项工作的新颖之处在于参数化映射类型的子类型定义。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [561] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
> *迈向统一的编程范式框架：分类形式化和方法论基础的系统综述*

*Mikel Vandeloise* | **Category: cs.PL, cs.CL, D.3.2; F.3.2; D.3.1** | **Updated: 2025-08-01**

**Keywords:** 编程范式, 系统综述, 分类形式化, 组合重构, 类型论

**Comment:** Preprint submitted to the Journal of Object Technology on July 29,
  2025. Data available upon request until peer-review is completed

> **TL;DR:** 现有编程范式分类方法因多范式语言而面临挑战，本系统综述发现文献正转向基于类型论、范畴论和UTP的组合式重构范式，以实现更统一的框架。

**AI_Comments:** 这篇综述揭示了编程范式研究领域的一个重要范式转变，即从静态分类转向动态、组合式的重构方法。其创新之处在于提出并描绘了利用高级数学理论（如类型论和范畴论）来形式化统一编程范式的新路径。这对于解决多范式语言的互操作性问题和推动未来编程语言设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多范式语言的兴起挑战了传统分类方法，导致互操作性缺陷等软件工程问题。本研究旨在评估分类形式化的现状及其局限性，并识别概念原语和数学框架，以实现一种更强大、更具重构性的方法。

**Method:** 本研究采用系统文献综述（SLR）的方法，综合分析了74项主要研究。

**Result:** 研究发现现有编程范式分类法缺乏概念粒度、统一的形式基础，并且难以处理混合语言。分析揭示了学术界正强烈趋向于编程范式的组合式重构方法，该方法通过识别一组最小的正交原子原语，并利用类型论、范畴论和统一编程理论（UTP）等数学框架来形式化地保证其组合属性。

**Conclusion:** 文献反映了从传统分类方法转向有前途的形式化、重构框架的重大思想转变。本综述描绘了这一演变的路线图，并提出了其统一的研究议程。

> **ai_Abstract:** 这篇系统文献综述旨在解决多范式语言对传统编程范式分类带来的挑战及其导致的软件工程问题。通过对74项研究的综合分析，发现现有分类法存在粒度不足和统一形式基础缺失的问题。研究揭示了学术界正转向利用类型论、范畴论和统一编程理论等数学框架，通过识别原子原语来组合式地重构编程范式，以期建立一个统一的框架。

> **摘要翻译:** 多范式语言的兴起挑战了传统的分类方法，导致了互操作性缺陷等实际软件工程问题。本系统文献综述（SLR）描绘了编程范式形式化基础的图谱。我们的目标是双重的：（1）评估分类形式化的现状及其局限性，以及（2）识别概念原语和数学框架，以实现一种更强大、更具重构性的方法。
基于对74项主要研究的综合，我们发现现有分类法缺乏概念粒度、统一的形式基础，并且难以处理混合语言。作为回应，我们的分析揭示了向范式组合式重构的强烈趋同。这种方法识别了一组最小的正交原子原语，并利用数学框架，主要是类型论、范畴论和统一编程理论（UTP），来形式化地保证它们的组合属性。
我们得出结论，文献反映了从分类转向这些有前途的形式化、重构框架的重大思想转变。本综述提供了这一演变的路线图，并提出了其统一的研究议程。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [709] [Float Self-Tagging](https://arxiv.org/abs/2411.16544)
> *浮点数自标记*

*Olivier Melançon, Manuel Serrano, Marc Feeley* | **Category: cs.PL, D.3.4** | **Updated: 2025-08-01**

**Keywords:** 浮点数, 自标记, 类型标记, 动态语言, 性能优化

**Comment:** 

> **TL;DR:** 提出了一种名为“自标记”的新方法，通过可逆位转换将浮点数的值和类型信息叠加到一个机器字中，有效减少了动态语言中浮点数的堆分配，并提高了性能。

**AI_Comments:** 这篇论文的创新点在于提出了“自标记”这一独特的浮点数编码方式，通过巧妙的位转换将值和类型信息融合，有效规避了传统标记方法带来的堆分配和性能开销。其重要性在于为动态语言中浮点数的优化提供了一个高效且实用的新思路，尤其在对内存和速度要求较高的场景下具有显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 动态和多态语言在运行时需要为对象附加类型信息，但IEEE754浮点数格式难以有效存储此信息。现有方法如标记指针、NaN-boxing和NuN-boxing都存在效率问题（堆分配或额外的运行时开销）。

**Method:** 引入了“自标记”方法，通过可逆的位转换将浮点数映射到包含正确类型信息的标记值，从而将浮点数的值和类型信息叠加在一个机器字中。该方法利用浮点数在实践中非均匀分布的特点，以避免最常遇到的浮点数的堆分配。

**Result:** 在两个Scheme编译器中实现并在四种微架构上进行了评估。实验表明，该方法实际上消除了几乎所有浮点数的堆分配，并为Scheme中浮点密集型基准测试提供了良好的执行速度，同时对其他基准测试的性能影响可忽略不计。

**Conclusion:** 自标记是标记指针、NaN-boxing和NuN-boxing等现有浮点数编码的一种有吸引力的替代方案，因为它显著减少了堆分配并保持了良好的执行性能。

> **ai_Abstract:** 本文提出了一种名为“自标记”的新型浮点数编码方案，旨在解决动态和多态语言中IEEE754浮点数类型信息存储效率低下的问题。与现有方法（如标记指针和NaN/NuN-boxing）相比，自标记通过可逆位转换将浮点数的值和类型信息叠加在一个机器字中，从而显著减少了堆分配并提高了浮点密集型应用的执行速度，同时对其他操作影响甚微。该方法利用了浮点数使用频率的非均匀分布特性，有效避免了常用浮点数的堆分配。

> **摘要翻译:** 动态和多态语言将类型等信息附加到运行时对象上，因此它们会调整值的内存布局以包含这些信息的空间。这使得高效实现IEEE754浮点数变得困难，因为这种格式没有留下易于访问的空间来存储类型信息。目前使用的三种主要浮点数编码——标记指针、NaN-boxing和NuN-boxing——都存在缺点。标记指针需要对所有浮点对象进行堆分配，而NaN/NuN-boxing则给类型检查和其他对象的处理带来了额外的运行时成本。
本文引入了自标记，一种新的对象标记方法，它使用可逆的位转换将浮点数映射到标记值，这些标记值在其位模式的正确位置包含正确的类型信息，将其值和类型信息叠加在一个机器字中。这种转换只能将所有浮点数的一个子集映射到正确类型的标记值，因此自标记利用了实践中浮点数非均匀分布的特点，以避免最常遇到的浮点数的堆分配。
自标记的变体在两个不同的Scheme编译器中实现，并在四种微架构上进行了评估，以评估其性能并将其与标记指针、NaN-boxing和NuN-boxing进行比较。实验表明，在实践中，该方法消除了几乎所有浮点数的堆分配，并为Scheme中浮点密集型基准测试提供了良好的执行速度，同时对其他基准测试的性能影响可忽略不计，使其成为标记指针以及NaN-boxing和NuN-boxing的一种有吸引力的替代方案。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [736] [Place Capability Graphs: A General-Purpose Model of Rust's Ownership and Borrowing Guarantees](https://arxiv.org/abs/2503.21691)
> *位置能力图：Rust所有权和借用保证的通用模型*

*Zachary Grannan, Aurel Bílý, Jonáš Fiala, Jasper Geer, Markus de Medeiros, Peter Müller, Alexander J. Summers* | **Category: cs.PL** | **Updated: 2025-08-01**

**Keywords:** Rust, 所有权, 借用, 类型系统, 程序分析, 验证

**Comment:** 

> **TL;DR:** Rust的类型系统难以精确建模；本文提出了一种名为“位置能力图”的新模型，克服了现有局限性，适用于验证工具。

**AI_Comments:** 该论文的创新在于提出了一个更精确、更通用的Rust所有权和借用系统模型，并能直接与编译器内部表示集成。这对于推动Rust的静态分析和验证工具至关重要，从而有助于构建更可靠和安全的软件。

<details>
  <summary>Details</summary>

**Motivation:** Rust独特类型系统提供的别名和可变性控制保证虽然吸引人，但现有模型在精确建模Rust借用、复合类型、函数签名和循环方面存在严重局限性，使得充分理解、提取和利用这些保证变得微妙且具有挑战性。

**Method:** 本文提出了一种名为“位置能力图”（Place Capability Graphs）的Rust类型检查新模型，该模型可以直接从Rust编译器的程序化表示和分析中计算得出。

**Result:** 该模型支持最流行的公共crates中超过97%的Rust函数，并通过开发现有Flowistry和Prusti工具的有前景的新原型版本，展示了其作为验证和程序分析工具通用基础的适用性。

**Conclusion:** 位置能力图克服了现有Rust类型检查模型的局限性，并为验证和程序分析工具提供了一个通用基础。

> **ai_Abstract:** 本文介绍了“位置能力图”（Place Capability Graphs），这是一种新颖的Rust类型检查模型，旨在解决现有模型在精确处理Rust借用、复合类型、函数签名和循环方面的局限性。该模型可以直接从Rust编译器的内部表示中计算，并已证明支持流行公共crates中超过97%的Rust函数。通过开发Flowistry和Prusti工具的改进原型，作者展示了该模型作为验证和程序分析工具通用基础的潜力。

> **摘要翻译:** Rust新颖的类型系统因其在控制别名和可变性方面提供的丰富保证，已成为验证和程序分析工具的一个有吸引力的目标。然而，全面理解、提取和利用这些保证是微妙且具有挑战性的：现有的Rust类型检查模型要么支持与真实世界Rust代码脱节的较小理想化语言，要么在精确建模Rust借用、存储它们的复合类型、函数签名和循环方面存在严重局限性。
在本文中，我们提出了一种名为“位置能力图”的Rust类型检查新模型，该模型消除了这些局限性，并且可以直接从Rust编译器自身的程序化表示和分析中计算得出。我们证明了我们的模型支持最流行的公共crates中超过97%的Rust函数，并通过开发现有Flowistry和Prusti工具的有前景的新原型版本，展示了其作为验证和程序分析工具通用基础的适用性。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [5] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
> *OpenScout v1.1 移动机器人：一个开放硬件持续开发的案例研究*

*Bartosz Krawczyk, Ahmed Elbary, Robbie Cato, Jagdish Patil, Kaung Myat, Anyeh Ndi-Tah, Nivetha Sakthivel, Mark Crampton, Gautham Das, Charles Fox* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 开放硬件, 移动机器人, ROS2, Gazebo, 案例研究

**Comment:** 6 pages, 4 figures, a TAROS2025 short paper

> **TL;DR:** OpenScout移动机器人升级到v1.1，计算硬件更简单、便宜、强大，并增加了ROS2和Gazebo仿真接口，本研究报告了其作为开放硬件的案例研究。

**AI_Comments:** 这篇论文通过OpenScout v1.1的案例，展示了开放硬件项目在持续迭代和改进方面的实践。其创新点在于通过简化和优化硬件配置，降低了成本并提升了性能，同时引入了ROS2和Gazebo仿真支持，这对于研究和工业应用都非常重要。它提供了一个关于开放硬件项目如何演进和保持活力的实际范例。

<details>
  <summary>Details</summary>

**Motivation:** 为OpenScout移动机器人提供更简化、更便宜、更强大的车载计算硬件，并增加模拟的ROS2接口和Gazebo仿真，以促进其作为开源硬件在研究和工业领域的应用。

**Method:** 本研究报告了OpenScout从v1.0到v1.1的更改、其原理、项目方法和结果，作为一项开放源硬件 (OSH) 的案例研究。

**Result:** OpenScout v1.1包含了简化、更便宜、更强大的车载计算硬件；一个模拟的ROS2接口；以及一个Gazebo仿真。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** OpenScout是一款开源硬件移动机器人，其v1.1版本在车载计算硬件方面进行了升级，使其更简化、成本更低、性能更强，并新增了ROS2和Gazebo仿真接口。本研究以OpenScout v1.1为例，详细阐述了开放硬件持续开发的案例，报告了其改进、原理、方法和成果。

> **摘要翻译:** OpenScout是一款用于研究和工业领域的开源硬件 (OSH) 移动机器人。它已扩展到v1.1版本，该版本包括更简化、更便宜、更强大的车载计算硬件；一个模拟的ROS2接口；以及一个Gazebo仿真。本研究报告了这些更改、其原理、项目方法和结果，作为一项OSH案例研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [10] [Human-Exoskeleton Kinematic Calibration to Improve Hand Tracking for Dexterous Teleoperation](https://arxiv.org/abs/2507.23592)
> *人机骨骼运动学标定以改进灵巧遥操作中的手部跟踪*

*Haiyun Zhang, Stefano Dalla Gasperina, Saad N. Yousaf, Toshimitsu Tsuboi, Tetsuya Narita, Ashish D. Deshpande* | **Category: cs.RO, cs.HC, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 手部外骨骼, 运动学标定, 手部跟踪, 灵巧遥操作, 残差加权优化

**Comment:** 8 pages, 10 figures, submitted to RA-L

> **TL;DR:** 提出一种针对外骨骼手部跟踪的个体化运动学标定框架，通过冗余关节传感和残差加权优化显著提升了手部跟踪精度，为高保真遥操作奠定基础。

**AI_Comments:** 该论文提出了一种创新的个体化运动学标定框架，有效解决了手部外骨骼在实际应用中因用户差异和穿戴不一致导致的跟踪精度下降问题。其核心创新在于结合了冗余关节传感、残差加权优化以及数据驱动的权重调整，实现了对虚拟连杆参数的精确估计。这项工作对于提升人机交互的沉浸感和精度具有重要意义，尤其是在高精度遥操作和机器人学习领域，为未来的应用奠定了坚实基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的手部外骨骼在灵巧遥操作和沉浸式操作界面中，由于用户解剖学差异和穿戴不一致性，导致运动学错位，从而降低手部跟踪性能并限制其在精确任务中的应用。

**Method:** 提出一种针对外骨骼手部跟踪的个体化标定框架，该框架利用冗余关节传感和残差加权优化策略来估计虚拟连杆参数。该方法在Maestro外骨骼上实现，并通过数据驱动方法利用运动捕捉地面真值经验性地调整成本函数权重。

**Result:** 针对不同手部几何形状的用户，该方法改进了关节角度和指尖位置估计。七名受试者的定量结果显示，与未标定和均匀加权模型相比，关节和指尖跟踪误差显著降低。Unity虚拟手进行的定性可视化进一步证实了运动保真度的改进。

**Conclusion:** 所提出的框架适用于具有闭环运动学和最小传感的外骨骼设计，并为高保真遥操作和从示范学习应用奠定了基础。

> **ai_Abstract:** 本文提出一种新颖的个体化标定框架，旨在解决手部外骨骼在灵巧遥操作中因用户差异和穿戴不一致导致的手部跟踪精度问题。该框架利用冗余关节传感和残差加权优化来估计虚拟连杆参数，并通过数据驱动方法优化成本函数权重。实验证明，该方法显著降低了关节和指尖跟踪误差，提高了运动保真度，为高精度遥操作和示范学习应用提供了基础。

> **摘要翻译:** 手部外骨骼是灵巧遥操作和沉浸式操作界面的关键工具，但由于用户特定的解剖学变异性和穿戴不一致性，实现精确的手部跟踪仍然是一个挑战。这些问题导致运动学错位，从而降低跟踪性能并限制其在精确任务中的适用性。我们提出了一种针对基于外骨骼手部跟踪的个体化标定框架，该框架利用冗余关节传感和残差加权优化策略来估计虚拟连杆参数。我们的方法在Maestro外骨骼上实现，改进了不同手部几何形状用户的关节角度和指尖位置估计。我们引入了一种数据驱动方法，利用运动捕捉地面真值经验性地调整成本函数权重，从而在参与者之间实现更准确和一致的标定。七名受试者的定量结果显示，与未标定和均匀加权模型相比，关节和指尖跟踪误差显著降低。使用基于Unity的虚拟手进行的定性可视化进一步证实了运动保真度的改进。所提出的框架适用于具有闭环运动学和最小传感的外骨骼设计，并为高保真遥操作和从示范学习应用奠定了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [13] [A Segmented Robot Grasping Perception Neural Network for Edge AI](https://arxiv.org/abs/2507.13970)
> *边缘AI的分段机器人抓取感知神经网络*

*Casper Bröcheler, Thomas Vroom, Derrick Timmermans, Alan van den Akker, Guangzhi Tang, Charalampos S. Kouzinopoulos, Rico Möckel* | **Category: cs.RO, cs.AI, I.2; I.2.9; I.2.10** | **Updated: 2025-08-01**

**Keywords:** 机器人抓取, 边缘AI, 神经网络, 低功耗, 片上系统

**Comment:** Accepted by SMC 2025

> **TL;DR:** 该研究在低功耗边缘芯片上实现了优化的机器人抓取感知神经网络，实现了实时、自主操作的全片上推理。

**AI_Comments:** 该论文的创新点在于将先进的深度学习抓取检测模型（热图引导抓取检测）成功部署到资源受限的边缘AI芯片（GAP9 RISC-V SoC）上，并通过硬件感知优化技术实现了全片上推理。这对于推动实时、低功耗的机器人自主操作具有重要意义，尤其是在工业自动化和移动机器人等领域。其主要贡献在于证明了在边缘设备上运行复杂AI模型的实际可行性。

<details>
  <summary>Details</summary>

**Motivation:** 机器人抓取是一项复杂的任务，需要精确的感知和控制。在资源受限的边缘环境中部署深度学习模型，可以实现低延迟、低功耗的实时抓取。

**Method:** 该工作在GAP9 RISC-V片上系统上实现了热图引导抓取检测（Heatmap-Guided Grasp Detection），这是一个用于检测6自由度抓取姿态的端到端框架。模型通过输入维度缩减、模型分区和量化等硬件感知技术进行了优化。

**Result:** 在GraspNet-1Billion基准测试上的实验评估验证了全片上推理的可行性，突出了低功耗微控制器在实时、自主操作方面的潜力。

**Conclusion:** 低功耗微控制器在边缘AI中实现实时、自主的机器人抓取感知方面具有巨大潜力，通过硬件优化技术可以实现全片上推理。

> **ai_Abstract:** 本文在GAP9 RISC-V片上系统上部署并优化了一个用于6自由度抓取姿态检测的热图引导抓取感知神经网络，旨在实现边缘AI环境下的低延迟、低功耗实时机器人抓取。通过输入维度缩减、模型分区和量化等硬件感知优化技术，该研究在GraspNet-1Billion基准测试上验证了全片上推理的可行性，展示了低功耗微控制器在实时自主操作中的巨大潜力。

> **摘要翻译:** 机器人抓取，即机器人可靠地固定和操纵不同形状、大小和方向物体的能力，是一项复杂的任务，需要精确的感知和控制。深度神经网络通过学习丰富和抽象的物体表示，在抓取合成方面取得了显著成功。当这些模型部署在边缘时，可以实现低延迟、低功耗的推理，使得在资源受限环境中进行实时抓取成为可能。这项工作在GAP9 RISC-V片上系统上实现了热图引导抓取检测，这是一个用于检测6自由度抓取姿态的端到端框架。模型通过硬件感知技术进行了优化，包括输入维度缩减、模型分区和量化。在GraspNet-1Billion基准测试上的实验评估验证了全片上推理的可行性，突出了低功耗微控制器在实时、自主操作方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [40] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
> *面向数据驱动的中风后步态自适应外骨骼辅助*

*Fabian C. Weigend, Dabin K. Choe, Santiago Canete, Conor J. Walsh* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 数据驱动, 外骨骼, 中风康复, 步态辅助, 时间卷积网络

**Comment:** 8 pages, 6 figures, 2 tables

> **TL;DR:** 开发了一种数据驱动方法，通过TCN模型估计踝关节扭矩，以实现中风后步态的自适应外骨骼辅助，并在原型机上验证了实时可行性。

**AI_Comments:** 该研究的创新之处在于首次尝试将数据驱动的自适应外骨骼辅助应用于中风后步态康复，解决了数据缺乏和患者异质性高的挑战。通过结合健康人预训练和中风患者小样本训练的策略，有效利用了有限的中风数据。实时原型机的成功演示也验证了其潜在的临床应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据驱动外骨骼方法难以应用于中风后等神经运动步态缺陷人群，因为人口异质性高、步态变异性大且缺乏训练模型所需的数据集。

**Method:** 提出了一种数据驱动的踝关节跖屈和背屈扭矩估计方法。使用多任务时间卷积网络（TCN）模型，结合三个惯性测量单元（IMU）的数据，并在6名健康人步态数据上预训练，然后用4名中风参与者的数据进行训练。实现了一个可穿戴原型机，并验证了实时传感、估计和驱动的可行性。

**Result:** TCN模型在4名中风参与者的数据上训练，R²达到0.74 ± 0.13。在一名中风参与者身上成功演示了实时传感、估计和驱动的可行性。

**Conclusion:** 本研究向实现中风后步态的数据驱动自适应外骨骼辅助迈出了第一步，并验证了实时扭矩估计和驱动的可行性。

> **ai_Abstract:** 该论文旨在解决数据驱动外骨骼辅助在中风后步态康复中应用的挑战。研究人员开发了一种数据驱动的踝关节扭矩估计方法，利用预训练在健康人数据上的多任务时间卷积网络（TCN）模型，并通过中风患者的IMU数据进行训练。该模型在估计中风后步态的踝关节扭矩方面表现出良好性能（R²为0.74 ± 0.13）。研究还实现并验证了一个可穿戴原型机，证明了实时传感、估计和驱动在实际应用中的可行性，为中风后步态的自适应外骨骼辅助迈出了关键一步。

> **摘要翻译:** 最近的工作表明，通过数据驱动方法控制的外骨骼可以动态调整对健康年轻人各种任务的辅助。然而，将这些方法应用于神经运动步态缺陷人群，如中风后偏瘫，具有挑战性。这不仅是由于高人口异质性和步态变异性，还因为缺乏用于训练精确模型的中风后步态数据集。尽管存在这些挑战，数据驱动方法为控制提供了有前景的途径，可能使外骨骼在非结构化社区环境中安全有效地运行。这项工作提出了实现中风后行走期间数据驱动扭矩估计的自适应跖屈和背屈辅助的第一步。我们使用从四名中风参与者在跑步机上行走时收集的数据训练了一个多任务时间卷积网络（TCN）（R²为0.74 ± 0.13）。该模型使用来自三个惯性测量单元（IMU）的数据，并在6名健康参与者的行走数据上进行了预训练。我们为外骨骼控制的踝关节扭矩估计方法实现了一个可穿戴原型，并向一名中风参与者展示了实时传感、估计和驱动的可行性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [48] [Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments](https://arxiv.org/abs/2507.21553)
> *多机器人激光雷达SLAM：地下隧道环境中的实际案例研究*

*Federica Di Lauro, Domenico G. Sorrenti, Miguel Angel Sotelo* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多机器人SLAM, 激光雷达, 回环检测, 地下隧道, 去中心化

**Comment:** 14 pages, 14 figures

> **TL;DR:** 分析去中心化多机器人激光雷达SLAM的局限性，发现回环检测假阳性问题，并提出新的启发式方法解决。

**AI_Comments:** 该研究通过实际案例分析，识别出多机器人激光雷达SLAM中回环检测的假阳性问题是一个关键瓶颈，并提出了具体的解决方案，具有较强的实践意义。选择地下隧道这一高挑战性环境也增加了研究的价值。

<details>
  <summary>Details</summary>

**Motivation:** 分析现有去中心化激光雷达SLAM系统的局限性，并发现回环检测中假阳性过多是主要的失败来源。

**Method:** 分析去中心化激光雷达SLAM系统管道，并开发了一种新的启发式方法来克服回环检测中假阳性过多的问题。研究参考环境是地下隧道。

**Result:** 发现回环检测是多机器人激光雷达SLAM系统中假阳性过多的主要失败来源。

**Conclusion:** 成功开发了一种新的启发式方法来克服去中心化多机器人激光雷达SLAM中回环检测假阳性过多的局限性，并指出了潜在的未充分探索的研究领域。

> **ai_Abstract:** 本文分析了去中心化多机器人激光雷达SLAM系统在地下隧道环境中的实际应用，发现回环检测是导致系统失败的主要原因，因为它产生了过多的假阳性。为了解决这一问题，研究人员开发并提出了一种新的启发式方法，旨在克服这些局限性，并指出了未来研究的方向。

> **摘要翻译:** 多机器人SLAM旨在通过多个机器人相互作用进行定位和构建地图。在本文描述的工作中，我们分析了一个去中心化激光雷达SLAM系统的管道，以研究现有技术的局限性，我们发现了一个重要的失败来源，即回环检测是过多假阳性的来源。因此，我们开发并提出了一种新的启发式方法来克服这些局限性。这项工作所参考的环境是极具挑战性的地下隧道。我们还强调了仍未充分探索的潜在新研究领域。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [75] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
> *用于高效机器人操作的设备端扩散Transformer策略*

*Yiming Wu, Huan Wang, Zhenghao Chen, Jianxin Pang, Dong Xu* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 扩散策略, 机器人操作, 设备端部署, 模型压缩, 实时

**Comment:** ICCV 2025

> **TL;DR:** LightDP是一个新框架，通过网络压缩和减少采样步骤，加速了扩散策略在资源受限移动设备上的实时部署，并在多个数据集上实现了有竞争力的性能。

**AI_Comments:** LightDP的创新性在于它成功地将计算密集型扩散策略优化到可以在资源受限的移动设备上实时运行，这对于机器人操作的实际部署具有重要意义。其核心贡献是结合了网络压缩（剪枝和再训练）和采样步骤减少（一致性蒸馏），解决了现有扩散策略在移动端应用的主要障碍。这项工作为未来在边缘设备上部署复杂的AI模型提供了宝贵的经验。

<details>
  <summary>Details</summary>

**Motivation:** 扩散策略在机器人操作任务中取得了显著进展，但由于计算效率低下和内存占用大，在资源受限的移动平台上应用仍面临挑战。

**Method:** 本文提出了LightDP框架，通过两种核心策略解决计算瓶颈：对去噪模块进行网络压缩，并减少所需的采样步骤。具体而言，首先对现有扩散策略架构进行计算分析，确定去噪网络是延迟的主要原因。为了克服传统剪枝方法通常带来的性能下降，引入了统一的剪枝和再训练流程，明确优化模型剪枝后的恢复能力。此外，将剪枝技术与一致性蒸馏相结合，在保持动作预测准确性的同时有效减少采样步骤。

**Result:** LightDP在标准数据集（PushT、Robomimic、CALVIN和LIBERO）上的实验评估表明，它在移动设备上实现了实时动作预测，并具有有竞争力的性能。广泛的实际实验也表明，所提出的LightDP可以实现与最先进的扩散策略相当的性能。

**Conclusion:** LightDP在资源受限环境中实现了扩散策略的实际部署，是迈向该领域的重要一步，能够在移动设备上实现实时机器人操作。

> **ai_Abstract:** 本文提出了LightDP，一个新颖的框架，旨在加速扩散策略在资源受限移动设备上的实时部署。LightDP通过对去噪模块进行网络压缩和减少采样步骤来解决计算效率和内存占用的挑战。该框架引入了统一的剪枝和再训练流程以优化模型恢复能力，并结合剪枝与一致性蒸馏以减少采样步骤同时保持准确性。实验证明，LightDP在多个标准数据集上实现了实时动作预测和与现有先进扩散策略相当的性能，为扩散策略在实际资源受限环境中的应用铺平了道路。

> **摘要翻译:** 扩散策略通过模仿学习显著推动了机器人操作任务的进展，但由于计算效率低下和内存占用大，它们在资源受限的移动平台上的应用仍然充满挑战。在本文中，我们提出了LightDP，一个专门为加速扩散策略而设计的新颖框架，以实现其在移动设备上的实时部署。LightDP通过两个核心策略解决了计算瓶颈：去噪模块的网络压缩和所需采样步骤的减少。我们首先对现有扩散策略架构进行了广泛的计算分析，确定去噪网络是延迟的主要贡献者。为了克服传统剪枝方法通常伴随的性能下降，我们引入了一个统一的剪枝和再训练流程，明确优化了模型剪枝后的可恢复性。此外，我们将剪枝技术与一致性蒸馏相结合，在保持动作预测准确性的同时有效减少采样步骤。在标准数据集（即PushT、Robomimic、CALVIN和LIBERO）上的实验评估表明，LightDP在移动设备上实现了实时动作预测，并具有竞争性的性能，标志着在资源有限环境中实际部署基于扩散的策略迈出了重要一步。广泛的实际实验也表明，所提出的LightDP可以实现与最先进的扩散策略相当的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [83] [Benchmarking Massively Parallelized Multi-Task Reinforcement Learning for Robotics Tasks](https://arxiv.org/abs/2507.23172)
> *大规模并行化多任务强化学习在机器人任务中的基准测试*

*Viraj Joshi, Zifan Xu, Bo Liu, Peter Stone, Amy Zhang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多任务强化学习, 并行化, 机器人, 基准测试, IsaacGym

**Comment:** RLC 2025

> **TL;DR:** 引入MTBench，一个大规模并行化的多任务机器人强化学习基准，用于评估不同MTRL算法的性能并发现挑战。

**AI_Comments:** MTBench的创新之处在于其大规模并行化设计和广泛的任务覆盖，填补了在策略多任务强化学习基准测试领域的空白。它不仅提供了一个高效的评估工具，更重要的是，揭示了结合大规模并行化与MTRL时出现的新挑战，为未来研究指明了方向，具有重要的实践和理论意义。

<details>
  <summary>Details</summary>

**Motivation:** 多任务强化学习（MTRL）是应用于复杂现实世界机器人任务的关键训练范式，需要通用且鲁棒的策略。大规模并行化训练在加速数据收集和实现多样化数据收集方面越来越受欢迎。然而，现有的MTRL研究主要局限于低并行化下的离策略方法。本研究旨在弥补在策略算法利用大规模并行化优势的空白。

**Method:** 研究引入了一个大规模并行化的机器人多任务基准（MTBench），这是一个开源基准，包含50个操作任务和20个运动任务，使用GPU加速模拟器IsaacGym实现。MTBench还包括四种基础RL算法和七种最先进的MTRL算法和架构，提供了一个统一的性能评估框架。

**Result:** 实验突出了使用MTBench评估MTRL方法的卓越速度，同时也揭示了大规模并行化与MTRL结合时出现的独特挑战。

**Conclusion:** MTBench提供了一个用于评估大规模并行化MTRL方法的有效基准，并揭示了将大规模并行化与MTRL结合时出现的独特挑战，为未来的研究指明了方向。

> **ai_Abstract:** 本研究针对现有MTRL研究在利用大规模并行化方面存在的局限性，特别是对在策略算法的支持不足，引入了一个名为MTBench的开源基准。MTBench利用GPU加速模拟器IsaacGym，包含了50个操作任务和20个运动任务，并集成了多种RL和MTRL算法，旨在提供一个统一的框架来评估大规模并行化MTRL的性能。实验结果表明，MTBench能够显著加速MTRL方法的评估，并揭示了大规模并行化与MTRL结合时所面临的独特挑战。

> **摘要翻译:** 多任务强化学习（MTRL）已成为将强化学习（RL）应用于一系列复杂现实世界机器人任务的关键训练范式，这需要通用且鲁棒的策略。与此同时，大规模并行化训练越来越受欢迎，不仅通过GPU加速模拟显著加快了数据收集，而且通过并行模拟异构场景实现了跨多个任务的多样化数据收集。然而，现有的MTRL研究主要局限于低并行化下的离策略方法，例如SAC。MTRL可以利用在策略算法的更高渐进性能，因为其批次需要来自当前策略的数据，因此可以利用GPU加速模拟提供的大规模并行化。为了弥补这一差距，我们引入了一个大规模并行化的机器人多任务基准（MTBench），这是一个开源基准，具有50个操作任务和20个运动任务的广泛分布，使用GPU加速模拟器IsaacGym实现。MTBench还包括四种基础RL算法与七种最先进的MTRL算法和架构相结合，提供了一个统一的性能评估框架。我们的大量实验突出了使用MTBench评估MTRL方法的卓越速度，同时也揭示了将大规模并行化与MTRL结合时出现的独特挑战。代码可在https://github.com/Viraj-Joshi/MTBench获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [103] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
> *视频生成器即机器人策略*

*Junbang Liang, Pavel Tokmakov, Ruoshi Liu, Sruthi Sudhakar, Paarth Shah, Rares Ambrus, Carl Vondrick* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 视频生成, 机器人策略, 泛化, 样本效率, 视觉运动控制

**Comment:** 

> **TL;DR:** 通过将视频生成作为机器人策略学习的代理，该研究提出了一种名为Video Policy的模块化框架，显著提高了机器人策略在感知和行为分布变化下的泛化能力和样本效率，尤其在少量演示数据和未见任务中表现出色。

**AI_Comments:** 创新之处在于将机器人策略学习重新定义为视频生成问题，这是一种解决数据效率和泛化挑战的新颖方法。利用大规模视频生成模型是向前迈出的重要一步。模块化设计也增加了灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视觉运动策略在感知或行为分布变化下泛化能力不足，并且其性能受限于人类演示数据的规模。

**Method:** 提出“视频策略”（Video Policy），一个结合视频和动作生成的模块化框架，可以端到端训练。它使用视频生成作为机器人策略学习的代理。

**Result:** 只需少量演示数据即可提取策略；显著提高鲁棒性和样本效率；在模拟和真实世界中，对未见物体、背景和任务都显示出强大的泛化能力；任务成功与生成的视频密切相关，无动作的视频数据为泛化到新任务提供了关键益处；通过利用大规模视频生成模型，与传统行为克隆相比，取得了卓越的性能。

**Conclusion:** 利用大规模视频生成模型，并将视频生成作为机器人策略学习的代理，为更具可扩展性和数据效率的机器人策略学习铺平了道路，克服了当前视觉运动策略的局限性。

> **ai_Abstract:** 本文介绍了“视频策略”（Video Policy），这是一个利用视频生成作为机器人策略学习代理的模块化框架。它解决了当前视觉运动策略的局限性，例如在分布变化下泛化能力差以及依赖大量演示数据的问题。通过结合视频和动作生成，该框架能够从最少的演示数据中学习到鲁棒且样本高效的策略，在各种设置下显示出强大的泛化能力，并优于传统的行为克隆方法。

> **摘要翻译:** 尽管灵巧操作取得了巨大进展，但当前的视觉运动策略仍受到两个挑战的根本限制：它们难以在感知或行为分布变化下泛化，并且其性能受限于人类演示数据的规模。在本文中，我们使用视频生成作为机器人策略学习的代理，以同时解决这两个限制。我们提出了Video Policy，一个结合视频和动作生成的模块化框架，可以端到端训练。我们的结果表明，学习生成机器人行为视频可以仅用最少的演示数据提取策略，显著提高了鲁棒性和样本效率。我们的方法在模拟和真实世界中，对未见物体、背景和任务都显示出强大的泛化能力。我们进一步强调，任务成功与生成的视频密切相关，无动作的视频数据为泛化到新任务提供了关键益处。通过利用大规模视频生成模型，我们实现了优于传统行为克隆的性能，为更具可扩展性和数据效率的机器人策略学习铺平了道路。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [128] [Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications](https://arxiv.org/abs/2507.23350)
> *农业应用中非完整移动机器人的多路径点路径规划与运动控制*

*Mahmoud Ghorab, Matthias Lorenzen* | **Category: cs.RO, cs.AI, cs.SY, eess.SY** | **Updated: 2025-07-31**

**Keywords:** 农业机器人, 路径规划, Dubins旅行商问题, 模型预测控制, 非完整机器人

**Comment:** 6 pages

> **TL;DR:** 本文提出了一种结合Dubins旅行商问题（DTSP）全局路径规划和非线性模型预测控制（NMPC）局部路径规划与控制的集成导航框架，用于农业环境中非完整移动机器人的多路径点导航，并在模拟中验证了其在生成更平滑、更短路径方面的有效性。

**AI_Comments:** 该论文的创新点在于将全局路径规划（DTSP）与局部运动控制（NMPC）进行了紧密耦合，以解决农业非完整机器人在复杂环境中的多路径点导航问题。这种集成方法不仅优化了路径长度和平滑度，还确保了对曲率约束的遵守，这对于保护农作物和土壤至关重要。其重要性在于为农业自动化提供了一种高效且实用的导航解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 农业环境中对能够自主导航的移动机器人需求日益增长，尤其是在需要高效路径规划通过无序坐标集、同时最小化行驶距离并遵守曲率约束以防止土壤损坏和保护植被的任务（如草地除草）中。

**Method:** 本文提出了一个集成的导航框架，结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和用于局部路径规划与控制的非线性模型预测控制（NMPC）策略。DTSP负责生成最短、受曲率约束的路径以高效访问所有目标点，而NMPC则利用此路径计算控制信号，以精确到达每个路径点。

**Result:** 系统性能通过对真实世界野外数据集的比较模拟分析进行了验证。结果表明，与解耦方法相比，耦合的基于DTSP的规划器产生了更平滑、更短的路径，在所提供的场景中减少了约16%的距离。在此基础上，NMPC控制器有效地引导机器人到达期望的路径点，同时局部优化轨迹并确保遵守约束。

**Conclusion:** 研究结果表明，所提出的框架在农业环境中实现高效自主导航具有潜力。

> **ai_Abstract:** 本文提出了一种用于农业环境中非完整移动机器人自主导航的集成框架。该框架结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和非线性模型预测控制（NMPC）策略，旨在解决在非结构化环境中多路径点导航时，最小化行驶距离并遵守曲率约束的问题。通过模拟验证，该耦合系统相比传统解耦方法能生成更平滑、更短的路径（减少约16%），并能有效控制机器人精确到达目标点，展示了其在农业应用中的潜力。

> **摘要翻译:** 对于能够在非结构化农业环境中导航的自主移动机器人需求日益增长。在草地中进行除草等任务需要通过无序坐标集进行高效的路径规划，同时最大限度地减少行驶距离并遵守曲率约束，以防止土壤损坏和保护植被。本文提出了一种集成的导航框架，该框架结合了基于Dubins旅行商问题（DTSP）的全局路径规划器和用于局部路径规划与控制的非线性模型预测控制（NMPC）策略。DTSP生成最短的、受曲率约束的路径，以有效地访问所有目标点，而NMPC则利用此路径计算控制信号，以精确到达每个路径点。通过对真实世界野外数据集的比较模拟分析验证了该系统的性能，结果表明，与解耦方法相比，耦合的基于DTSP的规划器产生了更平滑、更短的路径，在所提供的场景中减少了约16%的距离。在此基础上，NMPC控制器有效地引导机器人到达期望的路径点，同时局部优化轨迹并确保遵守约束。这些发现证明了所提出的框架在农业环境中实现高效自主导航的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [277] [GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting](https://arxiv.org/abs/2507.23273)
> *GSFusion：面向高斯泼溅的全局优化激光雷达-惯性-视觉建图*

*Jaeseok Park, Chanoh Park, Minsu Kim, Soohwan Kim* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D高斯泼溅, 激光雷达, 惯性, 视觉, 建图

**Comment:** 

> **TL;DR:** GSFusion是一个融合激光雷达、惯性和视觉数据的在线建图系统，解决了传统3DGS和激光雷达集成3DGS的挑战，提高了渲染质量和建图效率。

**AI_Comments:** GSFusion的创新之处在于其多传感器融合（LiDAR-Inertial-Visual）策略，以及针对激光雷达稀疏数据和3DGS全局一致性问题提出的特定解决方案（surfel-to-surfel约束、像素感知初始化和有界S型约束）。这显著提升了3DGS在复杂环境下的鲁棒性和性能，是实时高保真三维重建领域的重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于相机或RGB-D的3DGS建图方法存在计算量大、在纹理或光照差的环境中失效以及操作范围短等局限性。而激光雷达与3DGS集成时，又面临实现真实感所需的卓越全局对齐以及稀疏数据导致的优化时间过长等新挑战。

**Method:** 本文提出了GSFusion系统，这是一个在线的激光雷达-惯性-视觉建图系统。它通过全局位姿图优化中的surfel-to-surfel约束来确保高精度地图一致性。为处理稀疏数据，系统采用像素感知的高斯初始化策略进行高效表示，并使用有界S型约束防止高斯不受控制地增长。

**Result:** 在公共数据集和自建数据集上的实验表明，GSFusion系统在渲染质量和建图效率方面优于现有的3DGS SLAM系统。

**Conclusion:** GSFusion成功地将激光雷达、惯性、视觉数据融合，解决了传统3DGS和激光雷达集成3DGS的挑战，显著提升了3DGS的地图构建和渲染性能。

> **ai_Abstract:** 本文提出了GSFusion，一个在线的激光雷达-惯性-视觉建图系统，旨在克服传统3D高斯泼溅(3DGS)方法在计算、环境适应性和操作范围上的局限性，以及激光雷达与3DGS集成时面临的全局对齐和稀疏数据优化挑战。GSFusion通过全局位姿图优化中的surfel-to-surfel约束确保地图一致性，并采用像素感知的高斯初始化和有界S型约束来高效处理稀疏数据。实验证明，该系统在渲染质量和建图效率上优于现有3DGS SLAM系统。

> **摘要翻译:** 尽管3D高斯泼溅（3DGS）彻底改变了照片级真实感建图，但传统的基于相机传感器，甚至是RGB-D的方法，存在根本性的局限性，例如计算负载高、在纹理或光照差的环境中失效以及操作范围短。激光雷达作为一种强大的替代方案出现，但其与3DGS的集成引入了新的挑战，例如为了照片级真实感质量需要卓越的全局对齐，以及稀疏数据导致优化时间延长。为了解决这些挑战，我们提出了GSFusion，一个在线的激光雷达-惯性-视觉建图系统，通过全局位姿图优化中的surfel-to-surfel约束确保高精度地图一致性。为了处理稀疏数据，我们的系统采用了像素感知的高斯初始化策略进行高效表示，并使用有界S型约束防止高斯不受控制地增长。在公共数据集和我们自己的数据集上的实验表明，我们的系统在渲染质量和建图效率方面优于现有的3DGS SLAM系统。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [282] [SDHN: Skewness-Driven Hypergraph Networks for Enhanced Localized Multi-Robot Coordination](https://arxiv.org/abs/2504.06684)
> *SDHN: 基于偏度驱动的超图网络，用于增强局部多机器人协作*

*Delin Zhao, Yanbo Shan, Chang Liu, Shenghang Lin, Yingxin Shou, Bin Xu* | **Category: cs.RO, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 多机器人协作, 超图网络, 偏度驱动, 高阶交互, 强化学习

**Comment:** 

> **TL;DR:** SDHN提出了一种基于偏度驱动的超图网络，通过随机伯努利超边和偏度损失来建模高阶多机器人交互，从而实现高效的局部同步，并在多机器人协作任务中表现出色。

**AI_Comments:** 该论文的创新点在于提出了偏度驱动的超图网络SDHN，通过引入随机伯努利超边和偏度损失，有效解决了多机器人协作中高阶交互的建模问题，并促进了高效的局部同步。这种方法模拟了人类协作中的局部优先机制，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 多智能体强化学习在多机器人协作中广泛应用，但传统的简单图模型无法捕捉高阶协作，限制了其在复杂任务中的有效性。现有超图方法常生成任意结构，且缺乏对环境不确定性的适应性。

**Method:** 我们提出了偏度驱动超图网络（SDHN），它采用随机伯努利超边来显式建模高阶多机器人交互。通过引入偏度损失，SDHN促进了小超边主导的超图高效结构，使机器人能够优先进行局部同步，同时仍遵循整体信息。

**Result:** 在编队移动智能体和机器人仓库任务上的大量实验验证了SDHN的有效性，证明其性能优于最先进的基线。

**Conclusion:** SDHN通过引入偏度驱动的超图网络，有效解决了多机器人协作中高阶交互建模的挑战，实现了高效的局部同步，并在复杂任务中展现出卓越的性能。

> **ai_Abstract:** 该论文提出了偏度驱动超图网络（SDHN），旨在解决多机器人协作中传统图模型无法捕捉高阶交互以及现有超图方法缺乏适应性的问题。SDHN通过使用随机伯努利超边建模高阶交互，并引入偏度损失来构建小超边主导的超图结构，从而促进机器人间的局部同步。实验结果表明，SDHN在编队移动智能体和机器人仓库任务上均优于现有基线。

> **摘要翻译:** 多智能体强化学习广泛应用于多机器人协作，其中简单的图通常建模成对交互。然而，这种表示未能捕捉更高阶的协作，限制了在复杂任务中的有效性。尽管基于超图的方法增强了协作，但现有方法通常生成任意超图结构，并且缺乏对环境不确定性的适应性。为了解决这些挑战，我们提出了偏度驱动超图网络（SDHN），它采用随机伯努利超边来显式建模更高阶的多机器人交互。通过引入偏度损失，SDHN促进了一种高效的结构，即小超边主导超图，允许机器人优先进行局部同步，同时仍然遵循整体信息，类似于人类协作。在编队移动智能体和机器人仓库任务上的大量实验验证了SDHN的有效性，证明其性能优于最先进的基线。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [327] [Scalable Outdoors Autonomous Drone Flight with Visual-Inertial SLAM and Dense Submaps Built without LiDAR](https://arxiv.org/abs/2403.09596)
> *不使用激光雷达，利用视觉惯性SLAM和密集子图实现可扩展的户外自主无人机飞行*

*Sebastián Barbas Laina, Simon Boche, Sotiris Papatheodorou, Dimos Tzoumanikas, Simon Schaefer, Hanzhi Chen, Stefan Leutenegger* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 自主导航, 视觉惯性SLAM, 无人机, 户外, 子图

**Comment:** 8 pages, 8 figures

> **TL;DR:** 本文提出了一种纯视觉惯性SLAM的无人机系统，在户外复杂环境中实现可扩展的自主导航，且性能良好。

**AI_Comments:** 该论文的关键创新在于，它在没有激光雷达的情况下，仅依靠低成本的视觉惯性传感器和板载计算，在复杂的户外环境中实现了可扩展且鲁棒的自主无人机飞行。这显著降低了成本和重量，使其具有高度的实用性。所提出的新颖轨迹锚定方案也为系统的安全性和鲁棒性做出了贡献。

<details>
  <summary>Details</summary>

**Motivation:** 机器人应用中需要自主导航。本文旨在开发一种纯粹依赖成本效益高、轻量级无源视觉和惯性传感器的自主微型飞行器（MAV）系统，以在户外、非结构化和杂乱环境中进行大规模自主导航。

**Method:** 该系统利用视觉惯性同步定位与建图（VI-SLAM）进行MAV精确状态估计，并将其与体积占用子图系统结合，构建可用于路径规划的可扩展建图框架。为确保导航安全，还提出了一种新的参考轨迹锚定方案，即使在闭环等大状态更新时，也能以一致的方式变形MAV跟踪的参考轨迹。系统完全依赖成本效益高、轻量级无源视觉和惯性传感器，并进行板载计算。

**Result:** 系统在真实和模拟森林环境中进行了彻底验证，在最高3米/秒的速度下，未发生一次碰撞或系统故障。据作者所知，这是首个在如此非结构化环境中使用低成本无源视觉传感器和完全板载计算（包括VI-SLAM）实现此等性能的系统。

**Conclusion:** 本文提出的自主微型飞行器（MAV）系统，纯粹依赖成本效益高、轻量级无源视觉和惯性传感器，实现了在户外、非结构化和杂乱环境中的大规模自主导航。该系统通过结合视觉惯性SLAM、体积占用子图和新颖的参考轨迹锚定方案，展现了卓越的性能、安全性和可扩展性，且无需激光雷达。

> **ai_Abstract:** 本文介绍了一种自主微型飞行器（MAV）系统，该系统纯粹依赖于成本效益高且轻量级的视觉和惯性传感器，以在户外、非结构化和杂乱环境中实现大规模自主导航。该系统利用视觉惯性SLAM（VI-SLAM）进行精确状态估计，并结合体积占用子图系统实现可扩展的建图，可直接用于路径规划。为确保安全，还提出了一种新颖的参考轨迹锚定方案，即使在大的状态更新（如闭环）时也能一致地变形参考轨迹。该系统已在真实和模拟森林环境中验证，在高达3米/秒的速度下未发生碰撞或系统故障，展示了其在无激光雷达和纯板载计算条件下的卓越性能。

> **摘要翻译:** 自主导航是多种机器人应用所必需的。本文提出了一种自主微型飞行器（MAV）系统，该系统纯粹依赖成本效益高、轻量级无源视觉和惯性传感器，以在户外、非结构化和杂乱环境中进行大规模自主导航。我们利用视觉惯性同步定位与建图（VI-SLAM）进行精确的MAV状态估计，并将其与体积占用子图系统结合，以实现一个可扩展的建图框架，该框架可以直接用于路径规划。为确保MAV在导航过程中的安全，我们还提出了一种新颖的参考轨迹锚定方案，该方案即使在由于闭环引起的大状态更新时，也能以一致的方式变形MAV跟踪的参考轨迹。我们在真实和模拟森林环境中彻底验证了我们的系统，在最高3米/秒的速度下，未发生一次碰撞或系统故障。据我们所知，这是首个在如此非结构化环境中使用低成本无源视觉传感器和完全板载计算（包括VI-SLAM）实现此等性能的系统。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [362] [Learning Goal-Directed Object Pushing in Cluttered Scenes With Location-Based Attention](https://arxiv.org/abs/2403.17667)
> *在杂乱场景中学习基于位置注意力的目标导向物体推动*

*Nils Dengler, Juan Del Aguila Ferrandis, João Moura, Sethu Vijayakumar, Maren Bennewitz* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 非抓取式操作, 强化学习, 杂乱场景, 物体推动, 位置注意力

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)2025

> **TL;DR:** 本文提出了一种基于位置注意力的方法，通过强化学习在杂乱场景中实现鲁棒的非抓取式物体推动，无需预设路径并考虑目标姿态。

**AI_Comments:** 该论文的创新点在于引入了基于位置的注意力机制来处理杂乱场景中的非抓取式物体推动，并且不需要预定义全局路径，同时考虑了目标物体的最终姿态，这在实际应用中具有重要意义。其方法克服了传统抓取放置技术的局限性，并增强了在复杂、动态环境下的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂场景中，传统的抓取放置技术不足以完成任务，而非抓取式操作因其欠驱动特性和混合动力学而具有挑战性，需要机器人推理物体的长期行为和接触切换，同时要对接触不确定性保持鲁棒。工作空间中杂乱的存在进一步增加了任务的复杂性，需要更先进的空间分析以避免不必要的碰撞。

**Method:** 本文在之前关于平面推动的多模态分类探索强化学习工作的基础上，引入了基于位置的注意力机制，以在杂乱场景中实现鲁棒操作。与之前解决避障推动任务的方法不同，该框架不需要预定义的全局路径，并考虑了被操作物体的期望目标方向。

**Result:** 在仿真和真实KUKA iiwa机器人手臂上的实验结果表明，所学习的策略能够成功地操作物体，同时通过复杂的障碍物配置（包括动态障碍物）避免碰撞，从而达到期望的目标姿态。

**Conclusion:** 本文提出的基于位置注意力的强化学习方法能够有效地在杂乱场景中实现目标导向的物体推动，并成功避开障碍物，达到期望的目标姿态。

> **ai_Abstract:** 本研究提出了一种基于位置注意力的强化学习方法，旨在解决杂乱场景中非抓取式物体推动的挑战。该方法无需预设全局路径，并能考虑被推动物体的目标姿态。通过在仿真和真实机器人上的实验，验证了该策略在复杂障碍物（包括动态障碍物）环境下成功推动物体并避免碰撞的能力。

> **摘要翻译:** 在复杂场景中，当典型的抓取放置技术不足时，非抓取式操作往往能确保机器人完成任务。然而，非抓取式操作由于其欠驱动性质和混合动力学而具有挑战性，机器人需要推理物体的长期行为和接触切换，同时要对接触不确定性保持鲁棒。工作空间中杂乱的存在进一步增加了这项任务的复杂性，引入了需要包含更高级空间分析以避免不必要碰撞的需求。在之前关于平面推动的多模态分类探索强化学习工作的基础上，我们提出结合基于位置的注意力机制，以在杂乱场景中实现鲁棒操作。与之前解决此避障推动任务的方法不同，我们的框架不需要预定义的全局路径，并考虑了被操作物体的期望目标方向。在仿真以及使用真实KUKA iiwa机器人手臂进行的实验结果表明，我们学习到的策略成功地操作了物体，同时通过复杂的障碍物配置（包括动态障碍物）避免了碰撞，以达到期望的目标姿态。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [375] [H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation](https://arxiv.org/abs/2507.23523)
> *H-RDT：人类操作增强的双臂机器人操作*

*Hongzhe Bi, Lingxuan Wu, Tianwei Lin, Hengkai Tan, Zhizhong Su, Hang Su, Jun Zhu* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 模仿学习, 机器人操作, 人类数据, 扩散模型, 双臂机器人

**Comment:** 

> **TL;DR:** H-RDT通过利用大规模人类操作数据进行预训练，显著提升了双臂机器人操作的模仿学习性能，解决了数据稀缺和跨形态泛化问题。

**AI_Comments:** H-RDT的创新之处在于其将人类操作视频数据作为机器人策略学习的强大基础，通过两阶段训练范式解决了机器人模仿学习中数据稀缺和跨形态泛化的问题。其利用扩散变换器和流匹配来建模复杂的动作分布，并在双臂机器人操作任务中取得了显著的性能提升，为未来的机器人通用策略学习提供了有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 机器人模仿学习面临高质量机器人演示数据稀缺的挑战；现有机器人基础模型在跨形态机器人数据集上预训练时，由于不同机器人形态和动作空间的多样性，统一训练具有挑战性。

**Method:** 提出H-RDT（Human to Robotics Diffusion Transformer），利用带有3D手姿态标注的大规模第一视角人类操作视频作为行为先验，增强机器人操作能力。采用两阶段训练范式：1) 在大规模第一视角人类操作数据上预训练；2) 使用模块化动作编码器和解码器，在机器人特定数据上进行跨形态微调。H-RDT基于20亿参数的扩散变换器架构，使用流匹配建模复杂动作分布。

**Result:** H-RDT在仿真和真实世界实验、单任务和多任务场景、以及少样本学习和鲁棒性评估中，均优于从头开始训练和现有最先进的方法（如Pi0和RDT）。在仿真和真实世界实验中，分别比从头开始训练的性能显著提高了13.9%和40.5%。

**Conclusion:** 结果验证了核心假设：人类操作数据可以作为学习双臂机器人操作策略的强大基础。

> **ai_Abstract:** 本文提出了H-RDT，一种利用大规模人类操作视频数据（含3D手姿态）预训练机器人策略的新方法，以解决机器人模仿学习中数据稀缺和跨形态训练的挑战。H-RDT采用两阶段训练范式，首先在人类数据上预训练扩散变换器模型，然后通过模块化编码器/解码器在机器人数据上进行微调。实验证明，H-RDT在仿真和真实世界中均显著优于现有方法，验证了人类操作数据作为机器人操作策略学习基础的有效性。

> **摘要翻译:** 机器人操作的模仿学习面临一个根本性挑战：大规模、高质量机器人演示数据的稀缺。最近的机器人基础模型通常在跨形态机器人数据集上进行预训练以增加数据规模，但它们面临显著的局限性，因为不同机器人形态和动作空间的多样性使得统一训练具有挑战性。在本文中，我们提出了H-RDT（Human to Robotics Diffusion Transformer），一种利用人类操作数据增强机器人操作能力的新方法。我们的关键见解是，带有配对3D手姿态标注的大规模第一视角人类操作视频提供了丰富的行为先验，这些先验捕捉了自然操作策略，并能有益于机器人策略学习。我们引入了一种两阶段训练范式：(1) 在大规模第一视角人类操作数据上进行预训练，以及 (2) 使用模块化动作编码器和解码器，在机器人特定数据上进行跨形态微调。H-RDT建立在具有20亿参数的扩散变换器架构之上，使用流匹配来建模复杂的动作分布。涵盖仿真和真实世界实验、单任务和多任务场景，以及少样本学习和鲁棒性评估的广泛评估表明，H-RDT优于从头开始训练和现有最先进的方法，包括Pi0和RDT，在仿真和真实世界实验中分别比从头开始训练的性能显著提高了13.9%和40.5%。结果验证了我们的核心假设，即人类操作数据可以作为学习双臂机器人操作策略的强大基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [397] [PC-SRIF: Preconditioned Cholesky-based Square Root Information Filter for Vision-aided Inertial Navigation](https://arxiv.org/abs/2409.11372)
> *PC-SRIF：基于预处理Cholesky分解的平方根信息滤波器用于视觉辅助惯性导航*

*Tong Ke, Parth Agrawal, Yun Zhang, Weikun Zhen, Chao X. Guo, Toby Sharp, Ryan C. Dutoit* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 视觉辅助惯性导航, 平方根信息滤波器, Cholesky分解, 预处理, 数值稳定性

**Comment:** This work has been accepted to the 2025 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS 2025)

> **TL;DR:** PC-SRIF是一种新型的视觉辅助惯性导航系统（VINS）估计器，通过预处理技术解决了Cholesky分解的数值稳定性问题，实现了更高的效率和稳定性。

**AI_Comments:** 这项研究通过识别VINS中信息矩阵病态性的真正原因（而非固有属性）并提出创新的预处理技术，有效地解决了Cholesky分解在单精度下数值不稳定的核心问题。其创新点在于将数值稳定性与计算效率相结合，使得Cholesky分解的优势得以在实际VINS系统中充分发挥。41%的运行时加速是一个显著的提升，预示着该方法在实时VINS应用中具有巨大的潜力，对未来VINS系统的设计和优化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉辅助惯性导航系统（VINS）在采用Cholesky分解时面临数值稳定性问题，尤其是在单精度计算平台上，导致许多系统转而使用效率较低的QR分解。论文分析认为，信息矩阵的病态性并非VINS的固有属性，而是特定参数化导致的，因此需要一种方法来解决这些条件问题，以充分利用Cholesky分解的效率优势。

**Method:** 本文提出了一种预处理技术来缓解信息矩阵的病态性，并在此基础上引入了PC-SRIF（Preconditioned Cholesky-based Square Root Information Filter）。PC-SRIF在VINS中解决线性系统时，能在单精度下稳定地执行Cholesky分解。

**Result:** PC-SRIF在执行Cholesky分解时展现出卓越的稳定性，在VINS中解决线性系统时能以单精度运行。与替代估计器相比，PC-SRIF在理论上实现了更高的效率。实验验证了PC-SRIF在效率和数值稳定性方面的优势，其运行时比基于QR的SRIF快41%。

**Conclusion:** PC-SRIF通过引入预处理技术解决了Cholesky分解在VINS中数值不稳定的问题，从而在单精度下实现了高效且稳定的视觉辅助惯性导航。这使得VINS系统能够利用Cholesky分解的效率优势，显著提升了运行时性能。

> **ai_Abstract:** 本文提出了一种名为PC-SRIF（基于预处理Cholesky分解的平方根信息滤波器）的新型视觉辅助惯性导航系统（VINS）估计器。针对现有VINS在使用Cholesky分解时面临的数值稳定性问题，论文分析指出信息矩阵的病态性并非VINS固有，而是由特定参数化引起。PC-SRIF通过引入预处理技术解决了这些条件问题，使得Cholesky分解在单精度下也能稳定高效地应用于VINS中的线性系统求解。实验结果表明，PC-SRIF在效率和数值稳定性上均优于现有方法，其运行时比基于QR的SRIF快41%。

> **摘要翻译:** 在本文中，我们介绍了一种用于视觉辅助惯性导航系统（VINS）的新型估计器——基于预处理Cholesky分解的平方根信息滤波器（PC-SRIF）。在求解线性系统时，采用Cholesky分解具有卓越的效率，但可能会损害数值稳定性。因此，现有利用（平方根）信息滤波器的VINS在首选单精度的平台上通常选择QR分解，以避免与Cholesky分解相关的数值挑战。尽管这些问题通常归因于VINS中信息矩阵的病态性，但我们的分析表明，这并非VINS的固有属性，而是特定参数化的结果。我们识别了导致信息矩阵病态的几个因素，并提出了一种预处理技术来缓解这些条件问题。在此分析的基础上，我们提出了PC-SRIF，它在VINS中求解线性系统时，在单精度下执行Cholesky分解时表现出卓越的稳定性。因此，与替代估计器相比，PC-SRIF实现了卓越的理论效率。为了验证PC-SRIF在VINS中的效率优势和数值稳定性，我们进行了良好控制的实验，提供了支持我们理论发现的经验证据。值得注意的是，在我们的VINS实现中，PC-SRIF的运行时比基于QR的SRIF快41%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [414] [Controlling diverse robots by inferring Jacobian fields with deep networks](https://arxiv.org/abs/2407.08722)
> *利用深度网络推断雅可比场来控制多样化机器人*

*Sizhe Lester Li, Annan Zhang, Boyuan Chen, Hanna Matusik, Chao Liu, Daniela Rus, Vincent Sitzmann* | **Category: cs.RO, cs.CV, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 深度网络, 雅可比场, 机器人控制, 视觉运动, 软体机器人

**Comment:** Project Page:
  https://sizhe-li.github.io/publication/neural_jacobian_field

> **TL;DR:** 本研究提出一种利用深度神经网络从视频流推断机器人视觉运动雅可比场的方法，从而仅通过单个摄像头实现对各种机器人的控制，无需预设机器人模型或专家干预。

**AI_Comments:** 该论文的创新点在于提出了一种通用的机器人控制方法，它摆脱了传统机器人控制对精确物理模型和复杂传感器的依赖。通过深度网络从视频中直接学习视觉运动雅可比场，该方法能够控制材料和驱动方式各异的机器人，包括难以建模的软体机器人。其重要性在于，仅使用通用摄像头作为传感器极大地降低了机器人自动化的门槛和成本，有望拓宽机器人系统的设计自由度，并推动仿生和多样化机器人的实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 在机器人领域，模仿自然生物体的复杂结构和多样功能是一个长期存在的挑战。现代制造技术极大地扩展了硬件的可能性，但控制这些系统需要将期望运动转化为执行器指令的软件。传统机器人易于建模为通过关节连接的刚性连杆，但对于通常柔软、由多种材料制成、缺乏传感能力且可能在使用中改变材料特性的仿生机器人，其建模和控制仍然是一个开放的挑战。

**Method:** 本研究引入了一种方法，该方法使用深度神经网络将机器人的视频流映射到其视觉运动雅可比场（即所有3D点对机器人执行器的敏感度）。该方法仅通过单个摄像头即可实现机器人控制，不对手臂的材料、驱动或传感做任何假设，并且通过观察随机指令的执行进行训练，无需专家干预。

**Result:** 研究人员在各种驱动方式、材料、制造工艺和成本各异的机器人机械手上验证了该方法。该方法实现了精确的闭环控制，并恢复了每个机器人的因果动态结构。

**Conclusion:** 由于该方法仅使用通用摄像头作为唯一传感器即可实现机器人控制，因此我们预计这项工作将拓宽机器人系统的设计空间，并为降低机器人自动化门槛提供一个起点。

> **ai_Abstract:** 本研究旨在解决控制复杂、多样化（尤其是软体或仿生）机器人的挑战，这些机器人难以通过传统方法建模。论文提出一种创新方法，利用深度神经网络从单个摄像头视频流中推断出机器人的视觉运动雅可比场。该方法无需预设机器人材料、驱动或传感的任何假设，并通过观察随机指令的执行进行无监督训练。实验证明，该方法能对多种不同类型的机器人实现精确的闭环控制，并能恢复其动态结构。这项工作有望通过简化传感需求来拓宽机器人设计空间并降低自动化门槛。

> **摘要翻译:** 模仿自然生物体的复杂结构和多样功能是机器人领域一个长期存在的挑战。现代制造技术极大地扩展了可行的硬件，但使用这些系统需要控制软件将期望的运动转化为执行器指令。传统机器人可以很容易地建模为通过关节连接的刚性连杆，但对于通常柔软或由多种材料制成、缺乏传感能力且可能在使用中改变其材料特性的仿生机器人，其建模和控制仍然是一个开放的挑战。在此，我们介绍了一种方法，该方法使用深度神经网络将机器人的视频流映射到其视觉运动雅可比场（所有3D点对机器人执行器的敏感度）。我们的方法仅通过单个摄像头即可实现机器人控制，不对手臂的材料、驱动或传感做任何假设，并且通过观察随机指令的执行进行训练，无需专家干预。我们在各种驱动方式、材料、制造工艺和成本各异的机器人机械手上展示了我们的方法。我们的方法实现了精确的闭环控制，并恢复了每个机器人的因果动态结构。因为它使得机器人控制仅使用通用摄像头作为唯一传感器，我们预计我们的工作将拓宽机器人系统的设计空间，并为降低机器人自动化门槛提供一个起点。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [428] [Cooperative and Asynchronous Transformer-based Mission Planning for Heterogeneous Teams of Mobile Robots](https://arxiv.org/abs/2410.06372)
> *异构移动机器人团队的协作与异步Transformer任务规划*

*Milad Farjadnasab, Shahin Sirouspour* | **Category: cs.RO, cs.AI, I.2.9; I.2.11** | **Updated: 2025-07-31**

**Keywords:** 任务规划, 异构机器人, 多智能体强化学习, Transformer, 异步决策

**Comment:** 

> **TL;DR:** 本文提出了CATMiP框架，利用多智能体强化学习和异步Transformer架构，解决了异构移动机器人团队在通信受限下的协作任务规划挑战，并在模拟中展现出卓越的效率、可伸缩性和鲁棒性。

**AI_Comments:** 本文的创新点在于提出了CATMiP框架，它结合了多智能体强化学习和专门设计的异步Transformer架构（AMAT），以解决异构机器人团队在通信受限环境下的任务规划挑战。其异步训练和分布式执行方案，以及对CMacDec-POMDP的建模，使其能够有效处理团队异构性和通信不稳定性。该研究的重要性在于为现实世界中复杂的分布式机器人系统提供了一个高效、可伸缩且鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 异构移动机器人团队的协作任务规划面临独特挑战，尤其是在通信受限和计算资源有限的情况下。

**Method:** 本文提出了协作与异步Transformer任务规划（CATMiP）框架。该框架利用多智能体强化学习（MARL）来协调具有不同感知、运动和执行能力的智能体之间的分布式决策。它还制定了一个基于类别的宏观动作去中心化部分可观测马尔可夫决策过程（CMacDec-POMDP），以有效建模异构智能体团队的异步决策。该框架采用异步集中式训练和分布式执行方案，并由异步多智能体Transformer（AMAT）架构支持。

**Result:** 在2D网格世界模拟环境中评估了CATMiP，并与基于规划的探索方法进行了比较。结果表明，CATMiP在效率、可伸缩性以及对通信中断和输入噪声的鲁棒性方面表现出卓越的性能。

**Conclusion:** CATMiP框架在处理异构移动机器人团队的协作任务规划方面表现出色，特别是在通信受限的环境下。其效率、可伸缩性和鲁棒性使其在现实世界的异构移动机器人系统中具有巨大潜力。

> **ai_Abstract:** 本文提出了CATMiP框架，旨在解决异构移动机器人团队在通信受限和计算资源有限条件下的协作任务规划问题。该框架结合了多智能体强化学习和新颖的异步多智能体Transformer（AMAT）架构，通过建模为CMacDec-POMDP，实现了异构智能体团队的分布式异步决策。实验结果表明，CATMiP在效率、可伸伸缩性和对通信干扰的鲁棒性方面优于现有方法，展现了其在实际应用中的巨大潜力。

> **摘要翻译:** 异构移动机器人团队的协作任务规划带来了一系列独特的挑战，尤其是在通信受限和计算资源有限的情况下。为了应对这些挑战，我们提出了协作与异步Transformer任务规划（CATMiP）框架，该框架利用多智能体强化学习（MARL）来协调在偶发性自组织通信下运行的、具有不同感知、运动和执行能力的智能体之间的分布式决策。本文还制定了一个基于类别的宏观动作去中心化部分可观测马尔可夫决策过程（CMacDec-POMDP），以有效建模异构智能体团队的异步决策。该框架利用所提出的异步多智能体Transformer（AMAT）架构，实现了异步集中式训练和分布式执行方案。这种设计允许单个训练模型泛化到更大的环境，并适应不同的团队规模和组成。我们在2D网格世界模拟环境中评估了CATMiP，并将其性能与基于规划的探索方法进行了比较。结果表明，CATMiP在效率、可伸缩性以及对通信中断和输入噪声的鲁棒性方面表现出卓越的性能，突出了其在现实世界异构移动机器人系统中的潜力。代码可在https://github.com/mylad13/CATMiP获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [429] [KineDepth: Utilizing Robot Kinematics for Online Metric Depth Estimation](https://arxiv.org/abs/2409.19490)
> *KineDepth：利用机器人运动学进行在线度量深度估计*

*Soofiyan Atar, Yuheng Zhi, Florian Richter, Michael Yip* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 机器人运动学, 度量深度估计, 单目深度, 在线学习, 深度感知

**Comment:** 8 pages, 5 figures

> **TL;DR:** KineDepth利用机器人运动学将单目相对深度实时转换为度量深度，显著提高精度和任务成功率。

**AI_Comments:** 这篇论文的创新点在于巧妙地利用了机器人自身的运动学特性，将其转化为一个“移动的测量尺”，从而解决了单目深度估计中长期存在的度量尺度缺失问题。这种方法避免了对昂贵硬件传感器的依赖，降低了系统复杂性和成本，同时提高了在复杂环境（如透明/反射物体）下的鲁棒性。其在线训练和实时转换的能力对于机器人实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统硬件深度传感器存在成本高、校准复杂、对透明/反射物体表现差等局限性。单目深度估计虽成本低，但输出的是相对深度，不适用于需要度量深度的机器人应用。

**Method:** 提出KineDepth方法，利用单个校准摄像头，使机器人充当“测量尺”将相对深度实时转换为度量深度。该方法采用基于LSTM的度量深度回归器，在线训练并通过概率滤波精炼，尤其在机器人运动附近区域准确恢复度量深度。

**Result:** 实验证明，该方法显著优于现有最先进的单目度量深度估计技术，深度误差降低22.1%，下游任务成功率提高52%。

**Conclusion:** KineDepth通过创新性地利用机器人运动学，有效解决了单目深度估计中缺乏度量深度的问题，显著提升了机器人深度感知的精度和任务执行能力。

> **ai_Abstract:** 本文提出了KineDepth，一种利用单个校准摄像头和机器人运动学在线估计度量深度的方法。针对传统深度传感器和现有单目深度估计的不足，KineDepth通过基于LSTM的回归器和概率滤波，将单目相对深度实时转换为机器人所需的度量深度。实验证明，该方法在深度误差和下游任务成功率方面均显著优于现有技术。

> **摘要翻译:** 深度感知对于机器人对其环境的空间和几何理解至关重要，许多任务传统上依赖于RGB-D或立体相机等基于硬件的深度传感器。然而，这些传感器面临实际限制，包括透明和反射物体的问题、高成本、校准复杂性、空间和能量限制以及复合系统中故障率增加。虽然单目深度估计方法提供了一种经济高效且更简单的替代方案，但由于其输出的是相对深度而非机器人应用至关重要的度量深度，因此在机器人领域的应用受到限制。在本文中，我们提出了一种利用单个校准摄像头的方法，使机器人能够在执行任务时充当“测量尺”，将相对深度实时转换为度量深度。我们的方法采用基于LSTM的度量深度回归器，在线训练并通过概率滤波精炼，以准确恢复单目深度图中的度量深度，特别是在机器人运动附近的区域。对真实机器人的实验表明，我们的方法显著优于当前最先进的单目度量深度估计技术，深度误差降低22.1%，下游任务成功率提高52%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [442] [A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving](https://arxiv.org/abs/2507.23540)
> *自适应自动驾驶的统一感知-语言-动作框架*

*Yi Zhang, Erik Leo Haß, Kuo-Yi Chao, Nenad Petrovic, Yinglei Song, Chengdong Wu, Alois Knoll* | **Category: cs.RO, cs.AI, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 自动驾驶, 感知-语言-动作, 大型语言模型, 多传感器融合, 适应性规划

**Comment:** 

> **TL;DR:** 本文提出了一个统一的感知-语言-动作（PLA）框架，结合多传感器融合和基于大型语言模型（LLM）的视觉-语言-动作（VLA）架构，以提高自动驾驶的适应性、鲁棒性和可解释性。

**AI_Comments:** 该论文创新性地将多传感器融合与大型语言模型（LLM）结合，构建了一个统一的感知-语言-动作框架，以解决自动驾驶中碎片化架构和语义理解不足的问题。通过引入LLM，系统能够进行更高级的上下文推理和自然语言理解，从而提升了系统的可解释性和对复杂场景的适应性。这种方法为未来自动驾驶系统的发展提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶系统在复杂、开放世界环境中实现类人适应性、鲁棒性和可解释性面临重大挑战。这些挑战源于碎片化的架构、对新场景泛化能力有限以及从感知中提取语义不足。

**Method:** 本文提出了一个统一的感知-语言-动作（PLA）框架，该框架将多传感器融合（摄像头、激光雷达、雷达）与一个增强型大型语言模型（LLM）的视觉-语言-动作（VLA）架构（特别是基于GPT-4.1的推理核心）相结合。该框架将低级传感处理与高级上下文推理统一起来，将感知与基于自然语言的语义理解和决策紧密耦合，以实现上下文感知、可解释和安全受限的自动驾驶。

**Result:** 在带有施工区的城市交叉路口场景中进行的评估表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现出卓越的性能。

**Conclusion:** 结果突出了语言增强认知框架在提高自动驾驶系统安全性、可解释性和可扩展性方面的潜力。

> **ai_Abstract:** 本文提出了一个统一的感知-语言-动作（PLA）框架，旨在解决自动驾驶系统在复杂环境中适应性、鲁棒性和可解释性不足的问题。该框架通过整合多传感器融合和基于GPT-4.1的大型语言模型增强的视觉-语言-动作（VLA）架构，实现了低级感知与高级语义理解和决策的紧密耦合。实验结果表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现优异，并有望提升自动驾驶系统的安全性、可解释性和可扩展性。

> **摘要翻译:** 自动驾驶系统在复杂、开放世界环境中实现类人适应性、鲁棒性和可解释性面临重大挑战。这些挑战源于碎片化的架构、对新场景泛化能力有限以及从感知中提取语义不足。为了解决这些限制，我们提出了一个统一的感知-语言-动作（PLA）框架，该框架将多传感器融合（摄像头、激光雷达、雷达）与一个增强型大型语言模型（LLM）的视觉-语言-动作（VLA）架构（特别是基于GPT-4.1的推理核心）相结合。该框架将低级传感处理与高级上下文推理统一起来，将感知与基于自然语言的语义理解和决策紧密耦合，以实现上下文感知、可解释和安全受限的自动驾驶。在带有施工区的城市交叉路口场景中进行的评估表明，该框架在轨迹跟踪、速度预测和自适应规划方面表现出卓越的性能。结果突出了语言增强认知框架在提高自动驾驶系统安全性、可解释性和可扩展性方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [454] [Generalizable Image Repair for Robust Visual Control](https://arxiv.org/abs/2503.05911)
> *鲁棒视觉控制的通用图像修复*

*Carson Sobolewski, Zhenjiang Mao, Kshitij Maruti Vejre, Ivan Ruchkin* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 图像修复, 视觉控制, 鲁棒性, 生成对抗网络, 分布偏移

**Comment:** 8 pages, 4 figures, 2 tables, 2025 IEEE/RSJ International Conference
  on Intelligent Robots and Systems (IROS 2025)

> **TL;DR:** 提出了一种基于GAN的实时图像修复模块，用于在视觉控制中恢复受损图像，从而提高在各种视觉损坏下的控制性能和可靠性。

**AI_Comments:** 该论文的创新点在于提出了一个通用的实时图像修复模块，该模块结合了CycleGAN的泛化能力和pix2pix在有配对数据时的质量优势，并引入了以控制性能为导向的损失函数，使得图像修复直接服务于下游的控制任务。这对于提升视觉控制系统在复杂和不可预测环境下的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 基于视觉的控制需要准确的感知以实现鲁棒性，但传感器噪声、恶劣天气和动态光照导致的图像分布变化会降低感知质量，导致次优的控制决策。现有方法（如域适应和对抗训练）虽能提高鲁棒性，但难以泛化到未见的损坏，并引入了计算开销。

**Method:** 提出了一种实时图像修复模块，在图像被控制器使用前对其进行修复。该方法利用生成对抗模型（CycleGAN和pix2pix）进行图像修复：CycleGAN实现非配对图像到图像的转换以适应新颖的损坏，而pix2pix在有配对数据时利用其提高质量。为确保与控制性能对齐，引入了一个以控制为中心的损失函数，优先考虑修复图像的感知一致性。

**Result:** 在模拟自动驾驶赛车环境中，通过各种视觉损坏对方法进行了评估。结果显示，与基线方法相比，该方法显著提高了性能，缓解了分布偏移并增强了控制器可靠性。

**Conclusion:** 本研究提出的实时图像修复模块，通过利用生成对抗模型和引入控制聚焦损失函数，有效提升了视觉控制系统在面对各种图像损坏时的鲁棒性和可靠性。

> **ai_Abstract:** 本论文提出了一种通用的实时图像修复模块，旨在提高基于视觉的控制系统在面对传感器噪声、恶劣天气和动态光照等图像损坏时的鲁棒性。该模块利用CycleGAN和pix2pix等生成对抗模型进行图像恢复，并通过引入以控制为中心的损失函数来确保修复图像的感知质量与控制性能保持一致。在模拟自动驾驶赛车环境中的评估表明，该方法显著优于现有基线，有效缓解了图像分布偏移并增强了控制器的可靠性。

> **摘要翻译:** 基于视觉的控制依赖于精确的感知来实现鲁棒性。然而，由传感器噪声、恶劣天气和动态光照引起的图像分布变化会降低感知质量，导致次优的控制决策。现有的方法，包括域适应和对抗训练，虽然提高了鲁棒性，但难以泛化到未见的损坏，同时引入了计算开销。为了解决这一挑战，我们提出了一种实时图像修复模块，在受损图像被控制器使用之前对其进行恢复。我们的方法利用生成对抗模型，特别是CycleGAN和pix2pix，进行图像修复。CycleGAN实现了非配对图像到图像的转换，以适应新颖的损坏，而pix2pix在有配对图像数据时利用其来提高质量。为了确保与控制性能对齐，我们引入了一个以控制为中心的损失函数，该函数优先考虑修复图像中的感知一致性。我们在一个模拟自动驾驶赛车环境中，对我们的方法在各种视觉损坏下进行了评估。结果表明，我们的方法与基线方法相比显著提高了性能，缓解了分布偏移并增强了控制器可靠性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [465] [AugInsert: Learning Robust Visual-Force Policies via Data Augmentation for Object Assembly Tasks](https://arxiv.org/abs/2410.14968)
> *AugInsert：通过数据增强学习用于物体组装任务的鲁棒视觉-力策略*

*Ryan Diaz, Adam Imdieke, Vivek Veeriah, Karthik Desingh* | **Category: cs.RO, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 机器人组装, 鲁棒性, 数据增强, 多感官策略, 力矩传感

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025

> **TL;DR:** 本文引入了一个新颖的评估框架和数据增强技术，以评估并提高多感官（视觉-力）机器人策略在物体组装任务中的鲁棒性，发现抓取姿态是主要挑战，且力矩传感是最具信息量的模态。

**AI_Comments:** 该研究创新性地关注了多感官策略（特别是视觉-力融合）的鲁棒性评估，并提出了一个实用的评估框架和数据增强方法。它揭示了在机器人组装任务中，抓取姿态对鲁棒性的关键影响，并强调了力矩传感在接触丰富场景中的独特价值，这对于开发更具泛化能力的机器人策略具有重要指导意义。其对不同感官模态信息量的分析也提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中操作需要机器人策略对分布外条件具有鲁棒性。尽管在评估视觉运动策略的鲁棒性方面已有很多工作，但包含力矩传感的多感官方法的鲁棒性评估仍未被充分探索。

**Method:** 本文引入了一种新颖的、基于因素的评估框架，旨在评估“孔中插销”组装任务中多感官策略的鲁棒性。为此，开发了一个利用Perceiver IO架构的多感官策略框架来学习该任务。研究还探索了一种简单的多感官数据增强技术来增强域外性能，并提供了一个模拟环境以实现对这些因素的受控评估。

**Result:** 研究结果表明，抓取姿态等多感官变异对鲁棒性构成了最显著的挑战。单独应用于每个感官模态的简单单感官数据增强不足以克服这些挑战。此外，在接触丰富的组装任务中，力矩传感被发现是最具信息量的模态，而视觉信息量最少。

**Conclusion:** 多感官变异，特别是抓取姿态，是物体组装任务中鲁棒性的主要挑战，简单的单感官数据增强不足以解决。力矩传感在接触丰富的任务中比视觉更具信息量。

> **ai_Abstract:** 本文提出了一个新颖的基于因素的评估框架，用于评估多感官（视觉-力）策略在物体组装任务中的鲁棒性。研究开发了一个利用Perceiver IO架构的多感官策略框架，并探索了一种简单的数据增强技术以提高域外性能。通过模拟环境的受控评估，结果显示多感官变异（尤其是抓取姿态）是鲁棒性的主要挑战，且简单的单感官数据增强不足以克服。此外，研究发现力矩传感在接触丰富的组装任务中是最具信息量的模态，而视觉信息量最少。

> **摘要翻译:** 在非结构化环境（如家庭）中操作需要机器人策略对分布外条件具有鲁棒性。尽管在评估视觉运动策略的鲁棒性方面已有很多工作，但对于包含力矩传感的多感官方法的鲁棒性评估仍未被充分探索。本文引入了一个新颖的、基于因素的评估框架，旨在评估“孔中插销”组装任务中多感官策略的鲁棒性。为此，我们开发了一个利用Perceiver IO架构的多感官策略框架来学习该任务。我们研究了哪些因素在物体组装中构成了最大的泛化挑战，并探索了一种简单的多感官数据增强技术以增强分布外性能。我们提供了一个模拟环境以实现对这些因素的受控评估。我们的结果表明，抓取姿态等多感官变异对鲁棒性构成了最显著的挑战，并且单独应用于每个感官模态的简单单感官数据增强不足以克服它们。此外，我们发现在接触丰富的组装任务中，力矩传感是最具信息量的模态，而视觉信息量最少。最后，我们简要讨论了支持真实世界实验结果。有关更多实验和定性结果，请参阅项目网页https://rpm-lab-umn.github.io/auginsert/。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [479] [Estimating Scene Flow in Robot Surroundings with Distributed Miniaturized Time-of-Flight Sensors](https://arxiv.org/abs/2504.02439)
> *机器人周围环境中的分布式小型飞行时间传感器场景流估计*

*Jack Sander, Giammarco Caroleo, Alessandro Albini, Perla Maiolino* | **Category: cs.RO, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 场景流估计, 飞行时间传感器, 点云, 机器人安全, 运动跟踪

**Comment:** 7 pages, 5 figures, 2 tables, 1 algorithm, IEEE RO-MAN 2025 accepted
  paper

> **TL;DR:** 该研究提出了一种使用分布式小型ToF传感器从低密度和噪声点云中估计场景流的方法，并通过实验验证了其在估计物体运动方向和幅度方面的有效性。

**AI_Comments:** 该论文提出了一种在机器人周围环境中利用低成本、分布式小型ToF传感器进行场景流估计的创新方法。其亮点在于针对低密度和噪声点云数据进行了专门处理，通过结合ICP、分类和内点移除策略有效提升了估计的鲁棒性。这对于在实际机器人应用中实现安全的人机交互和障碍物规避具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 跟踪机器人周围的人或物体运动对于提高机器人运动和反应的安全性至关重要。

**Method:** 该方法从分布式小型ToF传感器获取的低密度和噪声点云中估计场景流。它将连续帧中的点进行聚类，并应用迭代最近点（ICP）来估计密集的运动流。此外，还引入了额外的步骤来减轻传感器噪声和低密度数据点的影响，具体包括基于适应度的分类来区分静止点和移动点，以及内点移除策略来细化几何对应关系。

**Result:** 实验结果表明，该方法能够持续近似运动的方向和幅度，其误差与传感器噪声一致。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种利用分布式小型飞行时间（ToF）传感器从低密度、噪声点云中估计机器人周围环境场景流的方法。该方法通过聚类连续帧点并应用迭代最近点（ICP）算法来估计运动流，并引入了基于适应度的分类和内点移除策略以处理噪声和数据稀疏性问题。实验证明，该方法能有效估计物体运动的方向和幅度，误差与传感器噪声水平一致，对于提升机器人安全运动具有重要意义。

> **摘要翻译:** 跟踪机器人周围的人或物体的运动对于提高机器人运动和反应的安全性至关重要。在这项工作中，我们提出了一种从分布式在机器人主体上的小型飞行时间（ToF）传感器获取的低密度和噪声点云中估计场景流的方法。所提出的方法将连续帧中的点进行聚类，并应用迭代最近点（ICP）来估计密集的运动流，并引入了额外的步骤来减轻传感器噪声和低密度数据点的影响。具体来说，我们采用基于适应度的分类来区分静止点和移动点，并采用内点移除策略来细化几何对应关系。所提出的方法在一个实验设置中得到了验证，其中使用24个ToF传感器来估计以不同受控速度移动的物体的速度。实验结果表明，该方法能够持续近似运动的方向和幅度，其误差与传感器噪声一致。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [492] [Exploring the Adversarial Vulnerabilities of Vision-Language-Action Models in Robotics](https://arxiv.org/abs/2411.13587)
> *探索机器人中视觉-语言-动作模型的对抗性漏洞*

*Taowen Wang, Cheng Han, James Chenhao Liang, Wenhao Yang, Dongfang Liu, Luna Xinyu Zhang, Qifan Wang, Jiebo Luo, Ruixiang Tang* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 视觉-语言-动作模型, 对抗性攻击, 机器人, 漏洞, 安全

**Comment:** ICCV camera ready; Github:
  https://github.com/William-wAng618/roboticAttack Homepage:
  https://vlaattacker.github.io/

> **TL;DR:** 机器人中的视觉-语言-动作（VLA）模型容易受到对抗性攻击，模拟任务中成功率最高可下降100%，揭示了关键的安全漏洞。

**AI_Comments:** 该论文创新性地探索了针对机器人中VLA模型的对抗性攻击，并考虑了独特的空间和功能方面。其在模拟环境中展示的显著任务退化（高达100%的失败率）是一个关键发现，凸显了在实际机器人应用中部署VLA模型时一个关键且常被忽视的安全问题。所提出的可操作评估指标对于该领域的未来研究具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作（VLA）模型在机器人领域取得了变革性进展，但它们也引入了新的攻击面。本研究旨在系统地评估这些模型的鲁棒性。

**Method:** 本研究提出了两种利用空间基础破坏机器人动作的无目标攻击，以及一种操纵机器人轨迹的有目标攻击。此外，还设计了一种对抗性补丁生成方法，通过在相机视野中放置小型彩色补丁，在数字和物理环境中有效执行攻击。

**Result:** 评估结果显示任务成功率显著下降，在一系列模拟机器人任务中最高可达100%的降低，凸显了当前VLA架构中存在的严重安全漏洞。

**Conclusion:** 通过揭示这些漏洞并提出可操作的评估指标，本研究增进了对基于VLA的机器人系统安全的理解和提升，强调了在实际部署前持续开发稳健防御策略的必要性。

> **ai_Abstract:** 本论文探讨了机器人中视觉-语言-动作（VLA）模型的对抗性漏洞。研究引入了新的攻击目标，包括利用空间特性的无目标攻击和操纵轨迹的有目标攻击，并设计了一种可在数字和物理环境中生效的对抗性补丁生成方法。在模拟机器人任务中的评估显示，任务成功率显著下降，最高达到100%的降低，揭示了当前VLA架构中存在的严重安全缺陷，并强调了开发稳健防御机制的紧迫性。

> **摘要翻译:** 最近在机器人领域，视觉-语言-动作（VLA）模型作为一种变革性方法出现，通过在端到端学习框架中整合视觉和语言输入，使机器人能够执行复杂任务。尽管它们具有显著能力，但VLA模型引入了新的攻击面。本文系统地评估了它们的鲁棒性。认识到机器人执行的独特需求，我们的攻击目标针对机器人系统固有的空间和功能特性。特别是，我们引入了两种利用空间基础来破坏机器人动作的无目标攻击，以及一种操纵机器人轨迹的有目标攻击。此外，我们设计了一种对抗性补丁生成方法，在相机的视野中放置一个小的彩色补丁，从而在数字和物理环境中有效执行攻击。我们的评估揭示了任务成功率的显著下降，在一系列模拟机器人任务中最高可达100%的降低，凸显了当前VLA架构中的关键安全漏洞。通过揭示这些漏洞并提出可操作的评估指标，我们增进了对基于VLA的机器人系统安全的理解和增强，强调了在实际物理世界部署之前持续开发稳健防御策略的必要性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [496] [Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study](https://arxiv.org/abs/2507.23589)
> *LLM推理模型能否取代经典规划？一项基准研究*

*Kai Goebel, Patrik Zips* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 大型语言模型, 机器人规划, 经典规划, 基准测试, PDDL

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLM）在机器人任务规划中的表现，发现它们在简单任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束遵守的复杂场景中仍面临困难。研究强调了LLM在现实世界机器人规划中的基本挑战，并建议未来研究结合LLM与经典规划器。

**AI_Comments:** 这项研究通过对LLM在机器人规划中的表现进行严格的基准测试，为该领域提供了宝贵的见解。其创新之处在于直接使用PDDL提示LLM并评估其计划的可执行性。结果清晰地指出了LLM在复杂规划任务上的局限性，强调了当前LLM推理能力与经典规划器在精确性、一致性和约束处理方面的差距。这对于指导未来研究方向，特别是探索结合LLM的语义理解能力与经典规划器的形式化推理能力的混合方法，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在机器人任务规划中的潜力引起了广泛兴趣，但其生成结构化和可执行计划的有效性尚不确定，因此需要进行系统评估。

**Method:** 本文对一系列当前最先进的语言模型进行了系统评估，直接使用规划领域定义语言（PDDL）领域和问题文件进行提示，并将其规划性能与Fast Downward规划器在各种基准上进行比较。评估内容包括成功率以及生成计划转化为实际可执行动作序列的忠实度。

**Result:** 研究发现，LLM在较简单的规划任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束遵守的更复杂场景中仍面临困难。

**Conclusion:** 这些结果突显了将语言模型应用于现实世界机器人规划所面临的基本挑战。研究旨在指导未来的研究转向结合语言模型与经典规划器的方法，以提高自主机器人规划的可靠性和可扩展性。

> **ai_Abstract:** 本文系统评估了大型语言模型（LLM）在机器人任务规划中的能力。通过使用PDDL直接提示LLM并与经典规划器Fast Downward进行比较，研究发现LLM在简单任务上表现良好，但在复杂任务中难以处理资源管理、状态跟踪和约束。这表明LLM在实际机器人规划中存在局限性，并提出未来研究应探索LLM与经典规划器结合的混合方法，以提高可靠性和可扩展性。

> **摘要翻译:** 大型语言模型最近的进展引发了人们对其在机器人任务规划中潜力的兴趣。尽管这些模型展示出强大的生成能力，但其在生成结构化和可执行计划方面的有效性仍不确定。本文对当前一系列最先进的语言模型进行了系统评估，每个模型都直接使用规划领域定义语言（PDDL）领域和问题文件进行提示，并将其规划性能与Fast Downward规划器在各种基准上进行了比较。除了测量成功率，我们还评估了生成的计划如何忠实地转化为实际可执行的动作序列，从而识别了在此设置中使用这些模型的优点和局限性。我们的研究结果表明，尽管这些模型在较简单的规划任务上表现良好，但它们在需要精确资源管理、一致状态跟踪和严格约束遵守的更复杂场景中仍继续面临困难。这些结果强调了将语言模型应用于现实世界机器人规划所面临的基本挑战。通过概述执行过程中出现的差距，我们旨在指导未来的研究转向结合语言模型与经典规划器的方法，以提高自主机器人规划的可靠性和可扩展性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [534] [Cooperative Payload Estimation by a Team of Mocobots](https://arxiv.org/abs/2502.04600)
> *由移动协作机器人团队进行的协作负载估计*

*Haoxuan Zhang, C. Lin Liu, Matthew L. Elwin, Randy A. Freeman, Kevin M. Lynch* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 协作操纵, 负载估计, 移动机械手, 移动协作机器人, 自主发现

**Comment:** 8 pages, 6 figures. Submitted to IEEE Robotics and Automation Letters
  (RA-L)

> **TL;DR:** 机器人团队通过协作操纵负载并利用传感器数据，能够自主估计负载特性和机器人附着点。

**AI_Comments:** 本文解决了多机器人协作操纵中的一个关键问题，即实现负载特性和机器人附着点的自主发现，这对于稳健和高性能的任务至关重要。使用移动协作机器人进行的实验验证增加了其在实际应用中的相关性。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现移动机械手团队对负载的高性能自主操作，或与人类进行协作操作，机器人需要能够识别其他机器人附着在负载上的位置，以及负载的质量和惯性特性。

**Method:** 机器人协作操纵负载，并利用抓取框架处的扭曲、扭曲导数和力矩数据来估计抓取框架之间的变换矩阵、负载质心的位置以及负载的惯性矩阵。

**Result:** 该方法通过一个由三台移动协作机器人（mocobots）组成的团队进行了实验验证。

**Conclusion:** 该方法成功地使机器人能够自主发现负载信息，以进行协作操作。

> **ai_Abstract:** 本文提出了一种让移动协作机器人（mocobots）团队自主估计负载特性（包括质量、惯性属性）以及其他机器人附着点的方法。通过协作操纵负载并利用抓取框架处的扭曲、扭曲导数和力矩数据，机器人能够确定抓取框架之间的变换矩阵、负载质心和其惯性矩阵。该方法已通过三台移动协作机器人进行了实验验证。

> **摘要翻译:** 为了实现移动机械手团队对负载的高性能自主操作，或与人类进行协作操作，机器人应该能够识别其他机器人附着在负载上的位置，以及负载的质量和惯性特性。在本文中，我们描述了一种让机器人自主发现这些信息的方法。机器人协作操纵负载，并利用其抓取框架处的扭曲、扭曲导数和力矩数据来估计抓取框架之间的变换矩阵、负载质心的位置以及负载的惯性矩阵。该方法已通过一个由三台移动协作机器人组成的团队进行了实验验证。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [568] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
> *XRoboToolkit：一个用于机器人远程操作的跨平台框架*

*Zhigen Zhao, Liuchuan Yu, Ke Jing, Ning Yang* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 机器人远程操作, 扩展现实, 跨平台框架, 数据集, 视觉-语言-动作模型

**Comment:** 6 pages, 6 figures, project link: https://github.com/XR-Robotics

> **TL;DR:** XRoboToolkit是一个基于扩展现实的跨平台机器人远程操作框架，旨在解决高质量机器人示范数据集收集的挑战。

**AI_Comments:** XRoboToolkit的创新在于其跨平台、基于OpenXR的扩展现实远程操作框架，解决了当前数据收集方法的可扩展性和数据质量问题。其模块化设计和对多种追踪模式的支持，使其在机器人领域具有重要应用潜力，特别是在推动视觉-语言-动作模型发展方面。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作模型的快速发展对大规模、高质量的机器人示范数据集产生了迫切需求。尽管远程操作是主要的数据收集方法，但现有方法存在可扩展性有限、设置复杂和数据质量不佳的问题。

**Method:** 本文提出了XRoboToolkit，一个基于OpenXR标准的扩展现实机器人远程操作跨平台框架。该系统具有低延迟立体视觉反馈、基于优化的逆运动学，并支持多种跟踪模式，包括头部、控制器、手部和辅助运动追踪器。其模块化架构实现了跨机器人平台和仿真环境的无缝集成。

**Result:** 该框架通过精确操作任务展示了其有效性，并通过训练表现出强大自主性能的VLA模型来验证了数据质量。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** XRoboToolkit是一个创新的跨平台框架，专为解决当前机器人远程操作在收集高质量、大规模数据集方面的局限性而设计。它利用扩展现实技术和OpenXR标准，提供低延迟视觉反馈、优化的逆运动学及多样的追踪支持。该框架具有模块化架构，可无缝集成到各种机器人和仿真环境中。实验证明，XRoboToolkit能有效支持精确操作任务，并生成高质量数据以训练强大的VLA模型。

> **摘要翻译:** 视觉-语言-动作模型的快速发展，对大规模、高质量的机器人示范数据集产生了迫切需求。尽管远程操作是数据收集的主要方法，但当前的方法存在可扩展性有限、设置程序复杂和数据质量不佳的问题。本文提出了XRoboToolkit，一个基于OpenXR标准的扩展现实机器人远程操作跨平台框架。该系统具有低延迟立体视觉反馈、基于优化的逆运动学，并支持多种跟踪模式，包括头部、控制器、手部和辅助运动追踪器。XRoboToolkit的模块化架构实现了跨机器人平台和仿真环境的无缝集成，涵盖了精密机械手、移动机器人和灵巧手。我们通过精确操作任务展示了该框架的有效性，并通过训练表现出强大自主性能的VLA模型来验证了数据质量。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [576] [Learning to Push, Group, and Grasp: A Diffusion Policy Approach for Multi-Object Delivery](https://arxiv.org/abs/2502.08452)
> *学习推动、分组和抓取：一种用于多对象递送的扩散策略方法*

*Takahiro Yonemaru, Weiwei Wan, Tatsuki Nishimura, Kensuke Harada* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 扩散策略, 模仿学习, 多对象抓取, 机器人, 分组

**Comment:** 

> **TL;DR:** 本文提出一种基于模仿学习和扩散策略的方法，使机器人能够高效地推动、分组和抓取多个物体，以提高多对象递送的效率。

**AI_Comments:** 本文的创新点在于将扩散策略与模仿学习相结合，用于解决复杂的多对象操作任务（推动、分组、抓取），相比传统基于规则的方法具有更好的适应性。这对于提高机器人工作效率在物流和工业应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 同时抓取和递送多个物体可以显著提高机器人工作效率，但传统基于规则的方法难以灵活适应多样场景，主要挑战在于如何有效地推动、分组和同步抓取物体，同时考虑物体分布和机器人硬件约束。

**Method:** 本文提出一种基于模仿学习的方法，通过远程操作收集专家演示，并训练一个扩散策略网络，使机器人能够动态生成推动、分组和抓取动作序列。

**Result:** 实验结果表明，所提出的方法能够有效且自适应地生成多对象分组和抓取策略，并在不同训练数据集大小、不同物体数量和真实世界物体场景下得到验证。

**Conclusion:** 随着更多训练数据的支持，模仿学习有望成为解决多对象抓取问题的有效方法。

> **ai_Abstract:** 本文提出一种基于模仿学习的扩散策略方法，用于高效的多对象抓取和递送。通过收集远程操作的专家演示并训练扩散策略网络，机器人能够动态生成推动、分组和抓取动作序列。实验证明，该方法能有效且自适应地生成多对象分组和抓取策略，克服了传统基于规则方法的局限性。

> **摘要翻译:** 同时抓取和递送多个物体可以显著提高机器人工作效率，几十年来一直是研究的重点。主要挑战在于如何推动物体、将它们分组，并针对各自组执行同步抓取，同时考虑物体分布和机器人的硬件约束。传统的基于规则的方法难以灵活适应各种场景。为了解决这一挑战，本文提出一种基于模仿学习的方法。我们通过远程操作收集了一系列专家演示，并训练了一个扩散策略网络，使机器人能够动态生成推动、分组和抓取动作序列，从而促进高效的多对象抓取和递送。我们进行了实验，在不同训练数据集大小、不同物体数量和真实世界物体场景下评估了该方法。结果表明，所提出的方法能够有效且自适应地生成多对象分组和抓取策略。随着更多训练数据的支持，模仿学习有望成为解决多对象抓取问题的有效方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [595] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
> *CHILD（类人机器人模仿与实时演示控制器）：一种全身类人机器人远程操作系统*

*Noboru Myers, Obin Kwon, Sankalp Yamsani, Joohyung Kim* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 类人机器人, 远程操作, 全身控制, 关节级控制, 力反馈

**Comment:** 

> **TL;DR:** CHILD是一个紧凑可重构的类人机器人全身远程操作系统，支持关节级控制、直接关节映射和运动操作，并结合自适应力反馈，已在类人机器人和双臂系统上验证，并开源了硬件设计。

**AI_Comments:** CHILD系统通过提供全身关节级远程操作，填补了现有远程操作系统的空白，显著提升了类人机器人执行复杂任务的能力。其紧凑、可重构的设计以及自适应力反馈是创新点。开源硬件设计极大地促进了研究的可复现性和社区协作，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有远程操作系统很少支持类人机器人的全身关节级远程操作，这限制了可完成任务的多样性。

**Method:** 本文提出了CHILD系统，一个紧凑可重构的远程操作系统，能够对类人机器人进行关节级控制。它可放入标准婴儿背带中，允许操作员控制所有四个肢体，并支持全身控制的直接关节映射和运动操作。系统融入了自适应力反馈以提升操作员体验并防止不安全的关节运动。硬件设计已开源。

**Result:** 通过在类人机器人和多个双臂系统上进行运动操作和全身控制示例，验证了CHILD系统的能力。系统提升了操作员体验并防止不安全的关节运动。

**Conclusion:** CHILD系统成功实现了类人机器人的全身关节级远程操作，支持多样的任务，并通过开源硬件设计促进了可访问性和可复现性。

> **ai_Abstract:** 本文介绍了一种名为CHILD（类人机器人模仿与实时演示控制器）的全身类人机器人远程操作系统。该系统旨在解决现有技术在类人机器人全身关节级远程操作方面的不足，从而扩展机器人可执行任务的范围。CHILD是一个紧凑且可重构的系统，支持对类人机器人进行关节级控制，包括全身控制的直接关节映射和运动操作。系统集成了自适应力反馈以提高操作员体验和安全性。通过在类人机器人和双臂系统上的验证，证明了其能力。此外，该项目的硬件设计已开源，以促进可访问性和可复现性。

> **摘要翻译:** 近年来，远程操作的进步已经展示了机器人执行复杂操作任务的能力。然而，现有工作很少支持类人机器人的全身关节级远程操作，这限制了可完成任务的多样性。这项工作提出了类人机器人模仿与实时演示控制器（CHILD），一个紧凑可重构的远程操作系统，能够对类人机器人进行关节级控制。CHILD系统可放入标准婴儿背带中，允许操作员控制所有四个肢体，并支持全身控制的直接关节映射和运动操作。系统融入了自适应力反馈以提升操作员体验并防止不安全的关节运动。我们通过在类人机器人和多个双臂系统上进行运动操作和全身控制示例来验证该系统的能力。最后，我们开源了硬件设计，以提高可访问性和可复现性。更多详细信息和开源信息可在我们的项目网站获取：https://uiuckimlab.github.io/CHILD-pages。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [618] [FalconGym: A Photorealistic Simulation Framework for Zero-Shot Sim-to-Real Vision-Based Quadrotor Navigation](https://arxiv.org/abs/2503.02198)
> *FalconGym：一个用于零样本模拟到真实视觉四旋翼导航的光真实感仿真框架*

*Yan Miao, Will Shen, Sayan Mitra* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 四旋翼飞行器, 模拟到真实, 视觉导航, 光真实感仿真, 零样本迁移

**Comment:** Accepted in IROS 2025

> **TL;DR:** 该研究提出了FalconGym，一个光真实感仿真框架，用于实现四旋翼飞行器视觉控制策略的零样本模拟到真实迁移，并在实际飞行中取得了高成功率。

**AI_Comments:** 这项研究的创新之处在于构建了一个光真实感的仿真环境FalconGym，并利用NeRF技术解决了传统模拟器视觉保真度不足的问题。其提出的结合NPE和多模态控制器的流水线方法，实现了视觉控制策略的零样本模拟到真实迁移，避免了额外的微调，这对于实际应用具有重要意义。在真实硬件上的高成功率和低误差证明了其方法的有效性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 鲁棒的从模拟到真实飞行的迁移是一个重大挑战，因为标准模拟器通常缺乏足够的视觉保真度。

**Method:** 本研究提出了一个名为FalconGym的光真实感四旋翼竞速赛道模拟环境，提供无限的合成图像用于训练。在此环境中，开发了一种跨越门的流水线方法，结合了：(i) 一个神经姿态估计器（NPE）与卡尔曼滤波器，用于从单帧RGB图像和IMU数据可靠地推断四旋翼姿态；(ii) 一个基于自注意力机制的多模态控制器，自适应地整合视觉特征和姿态估计。该控制器纯粹在FalconGym中通过模仿学习进行训练。

**Result:** 在三种不同赛道（圆形、U形和8字形）上的模拟实验表明，该控制器在成功率和过门精度方面均优于仅视觉的最新基线。在涵盖三条赛道和120个门的30次真实硬件飞行中，该控制器取得了95.8%的成功率，并且在穿过38厘米半径的门时平均误差仅为10厘米。

**Conclusion:** 该研究成功展示了在神经辐射场（NeRF）环境中学习的视觉控制策略，通过FalconGym光真实感仿真框架，实现了四旋翼飞行器竞速过门的零样本模拟到真实迁移，并在真实硬件上表现出卓越的鲁棒性和准确性。

> **ai_Abstract:** 本研究提出了FalconGym，一个光真实感仿真框架，旨在解决四旋翼飞行器视觉控制策略从模拟到真实迁移时标准模拟器视觉保真度不足的问题。该框架利用神经辐射场环境生成无限合成图像，并开发了一个结合神经姿态估计器、卡尔曼滤波器和自注意力多模态控制器的流水线方法。该控制器纯粹在仿真中训练，实现了零样本迁移，并在模拟和真实飞行中均表现出优于现有方法的成功率和过门精度。

> **摘要翻译:** 我们提出了一个新颖的框架，展示了在神经辐射场（NeRF）环境中学习的用于四旋翼飞行器穿越竞速门的视觉控制策略的零样本模拟到真实迁移。从模拟到真实飞行的鲁棒迁移带来了重大挑战，因为标准模拟器通常缺乏足够的视觉保真度。为了解决这个问题，我们构建了一个名为FalconGym的四旋翼竞速赛道光真实感模拟环境，它为训练提供了实际上无限的合成图像。在FalconGym中，我们开发了一种穿越门的流水线方法，结合了（i）一个神经姿态估计器（NPE）与卡尔曼滤波器，用于从单帧RGB图像和IMU数据可靠地推断四旋翼姿态，以及（ii）一个基于自注意力机制的多模态控制器，自适应地整合视觉特征和姿态估计。这种多模态设计补偿了感知噪声和间歇性门的可见性。我们纯粹在FalconGym中通过模仿学习训练该控制器，并将所得策略部署到真实硬件上，无需额外微调。在三种不同赛道（圆形、U形和8字形）上的模拟实验表明，我们的控制器在成功率和过门精度方面均优于仅视觉的最新基线。在涵盖三条赛道和120个门的30次真实硬件飞行中，我们的控制器取得了95.8%的成功率，并且在穿过38厘米半径的门时平均误差仅为10厘米。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [624] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
> *拓扑启发式软连续体机器人形态描述符*

*Zhiwei Wu, Siyi Wei, Jiahao Luo, Jinhui Zhang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 软连续体机器人, 形态描述符, 拓扑学, 莫尔斯理论, 形态控制

**Comment:** 

> **TL;DR:** 本文提出了一种结合伪刚体模型和莫尔斯理论的拓扑启发式形态描述符，用于软连续体机器人的定量形态表征、分类和控制，有望提高其在医疗应用中的精度和适应性。

**AI_Comments:** 本文的创新之处在于将伪刚体模型与莫尔斯理论相结合，为软连续体机器人提供了一种新颖的、拓扑启发的形态描述方法。这种方法不仅实现了形态的定量表征和分类，还将其扩展到形态控制，通过优化问题计算驱动参数，这在机器人领域具有重要的实际意义。尤其是在医疗应用中，如微创手术，精确的形态描述和控制对于提高手术精度和适应性至关重要。该框架提供了一个统一的解决方案，具有很高的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现机器人形态的定量表征，并提高软连续体机器人在微创手术和血管内介入等医疗应用中的精度和适应性。

**Method:** 本文通过将伪刚体（PRB）模型与莫尔斯理论相结合，提出了一种拓扑启发式形态描述符。通过计算方向投影的临界点，实现多模态配置的离散表示和形态分类。此外，通过将目标配置表述为优化问题，计算生成具有所需拓扑特征的平衡形状的驱动参数，将描述符应用于形态控制。

**Result:** 所提出的描述符能够离散表示多模态配置并促进形态分类。它还能够通过优化问题计算驱动参数，生成具有所需拓扑特征的平衡形状，从而实现形态控制。

**Conclusion:** 所提出的框架为软连续体机器人的定量形态描述、分类和控制提供了一种统一的方法，有望提高其在微创手术和血管内介入等医疗应用中的精度和适应性。

> **ai_Abstract:** 本文提出了一种用于软连续体机器人的拓扑启发式形态描述符。该描述符结合了伪刚体模型和莫尔斯理论，通过计算方向投影的临界点，实现了机器人形态的定量表征、多模态配置的离散表示和形态分类。该方法还可应用于形态控制，通过优化计算驱动参数以获得所需拓扑特征的形状。该框架为软连续体机器人的形态描述、分类和控制提供了一种统一的方法，有望提升其在医疗领域的应用潜力。

> **摘要翻译:** 本文提出了一种拓扑启发式软连续体机器人形态描述符，通过结合伪刚体（PRB）模型与莫尔斯理论，实现机器人形态的定量表征。通过计算方向投影的临界点，所提出的描述符能够离散表示多模态配置并促进形态分类。此外，我们将描述符应用于形态控制，将目标配置表述为优化问题，以计算生成具有所需拓扑特征的平衡形状的驱动参数。所提出的框架为软连续体机器人的定量形态描述、分类和控制提供了一种统一的方法，有望提高其在微创手术和血管内介入等医疗应用中的精度和适应性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [652] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
> *UAV-ON：一个面向空中智能体的开放世界目标导航基准*

*Jianqiang Xiao, Yuexuan Sun, Yixin Shao, Boxi Gan, Rongqiang Liu, Yanjing Wu, Weili Gua, Xiang Deng* | **Category: cs.RO, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 空中导航, 目标导航, 无人机, 开放世界, 基准

**Comment:** Accepted to ACM MM Dataset Track 2025

> **TL;DR:** UAV-ON是一个新的基准，用于解决无人机在开放世界中基于语义目标进行导航的挑战。

**AI_Comments:** UAV-ON通过引入开放世界、语义目标驱动的空中导航范式，填补了具身智能领域的一个重要空白，这对于无人机在复杂真实环境中的实际应用至关重要。其创新点在于摆脱了对详细指令的依赖，转而使用更具挑战性和现实意义的语义目标。基准的复杂性和所揭示的基线方法的不足，表明了该领域未来研究的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉与语言导航（VLN）范式过于依赖序列语言指令，限制了可扩展性和自主性。空中导航作为具身智能中的基本能力，在大规模、非结构化环境中未被充分探索。为了弥补这一空白，本文引入了UAV-ON。

**Method:** 本文引入了UAV-ON，一个用于空中智能体在开放世界环境中进行大规模目标导航（ObjectNav）的基准。UAV-ON包含14个高保真虚幻引擎环境，具有多样化的语义区域和复杂的空间布局，涵盖城市、自然和混合使用场景。它定义了1270个带注释的目标对象，每个对象都通过实例级指令进行描述，编码了类别、物理足迹和视觉描述符。这些指令作为语义目标，引入了真实的模糊性和复杂的推理挑战。为评估基准，本文实现了几种基线方法，包括空中目标导航智能体（AOA），一个模块化策略，将指令语义与自我中心观察相结合，用于长程、目标导向的探索。

**Result:** 实证结果表明，所有基线方法在此设置下都表现不佳，突出了空中导航和语义目标接地的复合挑战。

**Conclusion:** UAV-ON旨在推动在复杂真实世界环境中由语义目标描述驱动的可扩展无人机自主性研究。

> **ai_Abstract:** 本文提出了UAV-ON，一个针对空中智能体在开放世界中进行大规模目标导航的新基准。该基准旨在解决现有视觉与语言导航范式对详细指令依赖的局限性，使智能体能基于高级语义目标进行操作。UAV-ON包含14个高保真虚幻引擎环境和1270个带注释的目标对象，每个对象都具有详细的实例级指令。通过实现基线方法（如AOA）进行评估，结果显示现有方法在空中导航和语义目标接地方面面临显著挑战。UAV-ON旨在促进可扩展无人机自主性的研究。

> **摘要翻译:** 空中导航是具身智能中一项基础但未被充分探索的能力，它使智能体能够在传统导航范式失效的大规模、非结构化环境中运行。然而，大多数现有研究遵循视觉与语言导航（VLN）范式，该范式严重依赖序列语言指令，限制了其可扩展性和自主性。为了解决这一差距，我们引入了UAV-ON，一个用于空中智能体在开放世界环境中进行大规模目标导航（ObjectNav）的基准，其中智能体根据高级语义目标运行，而不像VLN那样依赖详细的指令指导。UAV-ON包含14个高保真虚幻引擎环境，具有多样化的语义区域和复杂的空间布局，涵盖城市、自然和混合使用场景。它定义了1270个带注释的目标对象，每个对象都通过实例级指令进行描述，编码了类别、物理足迹和视觉描述符，从而实现接地推理。这些指令作为语义目标，为空中智能体引入了真实的模糊性和复杂的推理挑战。为了评估该基准，我们实现了几种基线方法，包括空中目标导航智能体（AOA），一个模块化策略，将指令语义与自我中心观察相结合，用于长程、目标导向的探索。实证结果表明，所有基线在此设置下都表现不佳，突出了空中导航和语义目标接地的复合挑战。UAV-ON旨在推动在复杂真实世界环境中由语义目标描述驱动的可扩展无人机自主性研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [656] [Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance](https://arxiv.org/abs/2507.23088)
> *超越僵硬AI：迈向术中辅助的自然人机共生*

*Lalithkumar Seenivasan, Jiru Xu, Roger D. Soberanis Mukul, Hao Ding, Grayson Byrd, Yu-Chun Ku, Jose L. Porras, Masaru Ishii, Mathias Unberath* | **Category: cs.RO, cs.AI, cs.HC** | **Updated: 2025-07-30**

**Keywords:** 手术辅助, 人机共生, 感知智能体, LLM, SAM

**Comment:** 

> **TL;DR:** 本文提出了一种名为Perception Agent的新型感知智能体，结合语音LLM、SAM和跟踪模型，实现更自然的人机交互，克服传统AI在动态手术环境中的僵硬性，并能识别和记忆新元素，从而促进术中辅助的人机共生。

**AI_Comments:** 本文的创新点在于提出了Perception Agent，通过融合LLMs、SAM和跟踪基础模型，并结合记忆库和新颖的未见元素分割机制，显著提升了AI在动态手术环境中的交互自然度和适应性。它克服了传统AI的僵硬性，实现了对未知元素的识别和记忆，这对于复杂且多变的手术场景至关重要。该工作的重要性在于其为未来更智能、更灵活的实时术中辅助系统奠定了基础，向真正的人机共生迈进了一步。

<details>
  <summary>Details</summary>

**Motivation:** 新兴的AI驱动手术辅助解决方案在动态手术环境中表现出固有的僵硬性，依赖于大量的任务特定预训练、固定的对象类别和显式手动提示，这限制了自然人机交互，未能充分发挥其潜力。

**Method:** 本文引入了一种新颖的Perception Agent，该智能体利用语音集成、提示工程化的大型语言模型（LLMs）、Segment Anything Model（SAM）以及任意点跟踪基础模型，以实现更自然的实时术中人机交互。该智能体还包含一个记忆库和两种用于分割未见元素的新颖机制，使其能够灵活地分割手术场景中的已知和未见元素，并能记忆新元素以供未来手术使用。

**Result:** 通过在公共数据集上的定量分析表明，该智能体的性能与劳动密集型的手动提示策略相当。定性分析在一个定制数据集中展示了该智能体在分割新颖元素（器械、体模移植物和纱布）方面的灵活性。

**Conclusion:** Perception Agent通过提供自然的人机交互并克服传统AI的僵硬性，有望使基于AI的动态手术环境中的实时辅助更接近现实，标志着在手术过程中迈向人机共生的一大步。

> **ai_Abstract:** 本文提出一种名为Perception Agent的新型感知智能体，旨在克服当前AI在动态手术辅助中僵硬且不自然的交互问题。该智能体结合了语音LLM、SAM和跟踪模型，并引入了记忆库及分割未见元素的新机制，实现了更自然的人机交互，能够识别并记忆已知及新颖的手术场景元素。实验结果表明，其性能与传统手动提示方法相当，并展现了在分割新颖元素方面的灵活性，标志着向手术中人机共生迈进的关键一步。

> **摘要翻译:** 新兴的手术数据科学和机器人解决方案，特别是那些旨在提供现场辅助的方案，需要自然的人机界面才能充分发挥其在提供自适应和直观帮助方面的潜力。当代的AI驱动解决方案仍然固有地僵硬，提供有限的灵活性，并限制了动态手术环境中的自然人机交互。这些解决方案严重依赖于广泛的任务特定预训练、固定的对象类别和显式的手动提示。本工作引入了一种新颖的感知智能体（Perception Agent），它利用语音集成、提示工程化的大型语言模型（LLMs）、Segment Anything Model（SAM）和任意点跟踪基础模型，以实现在实时术中辅助中更自然的人机交互。通过整合一个记忆库和两种分割未见元素的新颖机制，Perception Agent提供了灵活性，可以通过直观的交互分割手术场景中的已知和未见元素。通过整合记忆新元素以供未来手术使用的能力，这项工作在手术过程中向人机共生迈出了显著的一步。通过在公共数据集上的定量分析，我们表明我们智能体的性能与劳动强度更高的手动提示策略相当。定性上，我们展示了我们智能体在定制数据集中分割新颖元素（器械、体模移植物和纱布）的灵活性。通过提供自然的人机交互并克服僵硬性，我们的Perception Agent可能使基于AI的动态手术环境中的实时辅助更接近现实。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [667] [SCORE: Saturated Consensus Relocalization in Semantic Line Maps](https://arxiv.org/abs/2503.03254)
> *SCORE：语义线图中的饱和共识重定位*

*Haodong Jiang, Xiang Zheng, Yanglin Zhang, Qingcheng Zeng, Yiqian Li, Ziyang Hong, Junfeng Wu* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 视觉重定位, 语义线图, 饱和共识最大化, 地图紧凑性, 鲁棒估计

**Comment:** 12 pages, 13 figurs, arxiv version for paper published at IROS 2025

> **TL;DR:** SCORE是一个使用语义3D线图进行视觉重定位的系统，通过创新的饱和共识最大化机制，在保持精度和运行时间的同时，显著减少了地图存储需求，即使在极端异常值比例下也能准确估计。

**AI_Comments:** 该论文通过引入语义线图和创新的饱和共识最大化（Sat-CM）机制，在视觉重定位领域取得了显著进展。其创新点在于极大地压缩了地图存储空间，同时在极端异常值环境下保持了鲁棒性和准确性，这对于资源受限的平台和大规模部署具有重要意义。Sat-CM机制对经典共识最大化的泛化，并通过概率理由分配权重，是其理论上的亮点。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉重定位系统在地图存储方面效率低下（结构或学习方法），并且在语义匹配中存在一对多歧义导致的极端异常值比例下，传统的共识最大化机制会失效。

**Method:** 提出SCORE系统，采用语义标记的3D线图实现重定位。核心创新是Saturated Consensus Maximization (Sat-CM)，它通过根据最大似然以概率理由为内点关联分配递减权重，泛化了经典的共识最大化(CM)。为了计算效率，提出了一个用于全局求解Sat-CM公式的加速框架，并将其专门应用于SCORE核心的Perspective-n-Lines问题。

**Result:** SCORE所需的存储空间仅为基于结构或基于学习的基线的0.01%-0.1%，同时保持了实际精度和可比的运行时间。在极端异常值比例（高达99.5%）下，Sat-CM能够实现准确估计，而CM会失败。

**Conclusion:** SCORE通过使用语义线图和创新的饱和共识最大化机制，显著提高了视觉重定位系统的地图紧凑性，并在高异常值环境下保持了鲁棒性和准确性。

> **ai_Abstract:** SCORE是一种新型视觉重定位系统，利用语义3D线图显著降低了地图存储需求（仅为传统方法的0.01%-0.1%），同时保持了高精度和效率。其核心是创新的饱和共识最大化（Sat-CM）机制，该机制通过对内点关联赋予递减权重，有效处理了高达99.5%的极端异常值，解决了传统共识最大化在语义匹配歧义下的失效问题，并通过加速框架保证了计算效率。

> **摘要翻译:** 我们提出了SCORE，一个视觉重定位系统，通过采用语义标记的3D线图，实现了前所未有的地图紧凑性。SCORE所需的存储空间仅为基于结构或基于学习的基线的0.01%-0.1%，同时保持了实际精度和可比的运行时间。其关键创新是一种新颖的鲁棒估计机制——饱和共识最大化（Sat-CM），它通过根据最大似然以概率理由为内点关联分配递减权重，泛化了经典的共识最大化（CM）。在语义匹配中一对多歧义导致的极端异常值比例（高达99.5%）下，Sat-CM能够在CM失效时实现准确估计。为了确保计算效率，我们提出了一个用于全局求解Sat-CM公式的加速框架，并将其专门应用于SCORE核心的Perspective-n-Lines问题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [678] [villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models](https://arxiv.org/abs/2507.23682)
> *villa-X：增强视觉-语言-动作模型中的潜在动作建模*

*Xiaoyu Chen, Hangxing Wei, Pushi Zhang, Chuheng Zhang, Kaixin Wang, Yanjiang Guo, Rushuai Yang, Yucen Wang, Xinquan Xiao, Li Zhao, Jianyu Chen, Jiang Bian* | **Category: cs.RO, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 机器人操作, 潜在动作, 视觉-语言-动作模型, 泛化, villa-X

**Comment:** Project page: https://aka.ms/villa-x

> **TL;DR:** villa-X是一个新的ViLLA框架，通过改进潜在动作建模，显著提升了机器人操作策略的泛化能力。

**AI_Comments:** 本文的创新点在于提出了ViLLA框架，并改进了潜在动作的学习和整合方式，这对于提升机器人操作策略的泛化能力具有重要意义。在模拟和真实世界的验证表明了其有效性，为机器人学习领域提供了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型在学习机器人操作策略方面表现出色，但最近的工作开始探索将潜在动作（一种帧间视觉变化的抽象表示）整合到VLA预训练中，本研究旨在进一步提升潜在动作建模以学习更具泛化性的机器人操作策略。

**Method:** 本文提出了一个名为villa-X的视觉-语言-潜在动作（ViLLA）新框架。该方法改进了潜在动作的学习方式以及它们在VLA预训练中的整合方式。

**Result:** villa-X在包括SIMPLER和LIBERO在内的模拟环境中以及在包括夹持器和灵巧手操作在内的两个真实世界机器人设置中都取得了卓越的性能。

**Conclusion:** ViLLA范式具有重要的前景，并且villa-X为未来的研究提供了坚实的基础。

> **ai_Abstract:** 本文介绍了villa-X，一个创新的视觉-语言-潜在动作（ViLLA）框架，旨在提升机器人操作策略的泛化能力。该框架通过优化潜在动作的学习和其在视觉-语言-动作（VLA）模型预训练中的整合方式，显著提高了模型在模拟和真实机器人环境中的表现。研究结果表明，ViLLA范式具有广阔的应用前景，而villa-X为未来的相关研究奠定了坚实基础。

> **摘要翻译:** 视觉-语言-动作（VLA）模型已成为一种流行的范式，用于学习能够遵循语言指令并泛化到新场景的机器人操作策略。最近的工作已开始探索将潜在动作（帧间视觉变化的抽象表示）整合到VLA预训练中。在本文中，我们介绍了villa-X，一个新颖的视觉-语言-潜在动作（ViLLA）框架，它推进了潜在动作建模，以学习可泛化的机器人操作策略。我们的方法改进了潜在动作的学习方式以及它们如何被整合到VLA预训练中。这些贡献共同使villa-X在包括SIMPLER和LIBERO在内的模拟环境以及在包括夹持器和灵巧手操作在内的两个真实世界机器人设置中都取得了卓越的性能。我们相信ViLLA范式具有重要的前景，并且我们的villa-X为未来的研究提供了坚实的基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [680] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
> *TopoDiffuser：一种基于扩散的、结合拓扑度量地图的多模态轨迹预测模型*

*Zehui Xu, Junhui Wang, Yongliang Shi, Chao Gao, Guyue Zhou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 轨迹预测, 扩散模型, 拓扑度量地图, 多模态, 道路合规性

**Comment:** 

> **TL;DR:** TopoDiffuser是一种基于扩散的多模态轨迹预测框架，通过将拓扑度量地图的结构线索嵌入去噪过程，生成准确、多样且符合道路规则的未来运动预测。

**AI_Comments:** 该论文的创新点在于将拓扑度量地图的结构线索巧妙地嵌入到扩散模型的去噪过程中，实现了无需显式约束即可生成符合道路几何的轨迹。这为轨迹预测领域提供了一种新颖且有效的方法，能够更好地处理道路合规性问题。其多模态融合以及在SOTA上的性能提升，表明了该方法的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的轨迹预测方法可能难以自然地遵循道路几何形状并生成多模态预测。本文旨在开发一种新的模型，能够无需显式约束地生成符合道路几何形状的准确、多样且符合道路规则的未来运动预测。

**Method:** TopoDiffuser是一个基于扩散的框架，通过将拓扑度量地图的结构线索嵌入条件扩散模型的去噪过程来生成轨迹。它使用一个多模态条件编码器融合激光雷达观测、历史运动和路线信息到一个统一的鸟瞰图（BEV）表示中。

**Result:** 在KITTI基准测试中，TopoDiffuser优于最先进的方法，同时保持了强大的几何一致性。消融研究进一步验证了每种输入模态、去噪步骤和轨迹样本数量的贡献。

**Conclusion:** TopoDiffuser成功地将拓扑度量地图集成到扩散模型中，实现了无需显式约束即可生成符合道路几何形状的准确、多样且符合道路规则的轨迹预测，并在现有基准上表现出色。

> **ai_Abstract:** TopoDiffuser是一种新颖的基于扩散的多模态轨迹预测模型，它将拓扑度量地图的结构信息融入其去噪过程，从而在没有显式几何约束的情况下，生成准确、多样且符合道路几何的未来运动轨迹。该模型通过多模态编码器整合激光雷达、历史运动和路线数据。在KITTI基准上的实验证明，TopoDiffuser超越了现有SOTA方法，并展现出卓越的几何一致性。

> **摘要翻译:** 本文介绍了 TopoDiffuser，一个基于扩散的多模态轨迹预测框架，它结合了拓扑度量地图来生成准确、多样化且符合道路规则的未来运动预测。通过将拓扑度量地图的结构线索嵌入到条件扩散模型的去噪过程中，所提出的方法能够生成自然遵循道路几何形状的轨迹，而无需依赖显式约束。一个多模态条件编码器将激光雷达观测、历史运动和路线信息融合到一个统一的鸟瞰图（BEV）表示中。在 KITTI 基准测试上进行的大量实验表明，TopoDiffuser 优于最先进的方法，同时保持了强大的几何一致性。消融研究进一步验证了每种输入模态的贡献，以及去噪步骤和轨迹样本数量的影响。为了支持未来的研究，我们公开了我们的代码：https://github.com/EI-Nav/TopoDiffuser。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [715] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
> *Omni-Scan：使用双臂机器人通过交接和高斯溅射合并创建视觉精确的数字孪生对象模型*

*Tianshuang Qiu, Zehan Ma, Karim El-Refai, Hiya Shah, Chung Min Kim, Justin Kerr, Ken Goldberg* | **Category: cs.RO, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 3D高斯溅射, 数字孪生, 双臂机器人, 物体扫描, 缺陷检测

**Comment:** 

> **TL;DR:** Omni-Scan提出了一种使用双臂机器人和3D高斯溅射来创建360度视觉精确数字孪生模型的方法，并成功应用于零件缺陷检测。

**AI_Comments:** Omni-Scan的创新之处在于利用双臂机器人的协同操作（抓取、旋转和交接）来克服传统3D扫描中物体遮挡和工作空间受限的问题，实现了全方位的物体扫描。其重要性在于能够生成高视觉精度的3D数字孪生模型，这对于仿真、VR以及尤其是工业零件缺陷检测等应用具有显著价值。将深度学习模型（如DepthAnything、Segment Anything、RAFT）与3DGS相结合，并通过修改训练管道来处理遮挡，是其技术亮点。文章未提及具体局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D物体扫描方法（如多摄像头阵列、激光扫描仪或机器人腕部安装摄像头）工作空间受限。数字孪生模型在仿真、虚拟现实、营销、机器人策略微调和零件检测方面很有用，因此需要一种能生成高质量、全方位3D模型的方法。

**Method:** Omni-Scan是一种通过双臂机器人生成高质量3D高斯溅射模型的方法。机器人用一个夹持器抓取物体并相对于固定摄像头旋转，然后由第二个夹持器重新抓取以暴露被遮挡的表面。该管道使用DepthAnything、Segment Anything和RAFT光流模型来识别和隔离机器人夹持的物体，同时移除夹持器和背景。它还修改了3DGS训练管道，以支持带有夹持器遮挡的串联数据集，从而生成对象的全方位（360度视角）模型。

**Result:** Omni-Scan应用于零件缺陷检测，能够以83%的平均准确率识别12种不同工业和家用物体上的视觉或几何缺陷。

**Conclusion:** Omni-Scan管道能够使用双臂机器人创建高质量、全方位的3D高斯溅射模型，有效解决了传统扫描方法的局限性，并成功应用于零件缺陷检测，展现出良好的准确性。

> **ai_Abstract:** 本文提出了Omni-Scan，一种利用双臂机器人创建高精度、全方位3D高斯溅射（3DGS）数字孪生模型的新方法。针对传统扫描方法工作空间受限的问题，Omni-Scan通过机器人抓取、旋转和交接物体，结合图像分割和光流技术去除背景和夹持器，并修改3DGS训练流程以处理遮挡数据，从而生成360度无死角的物体模型。实验结果表明，该系统在12种工业和家用物体的缺陷检测中实现了83%的平均准确率，证明了其在生成高质量数字孪生和实际应用中的有效性。

> **摘要翻译:** 3D高斯溅射（3DGSs）是源自多视图图像的3D物体模型。这种“数字孪生”模型对于仿真、虚拟现实、营销、机器人策略微调和零件检测非常有用。3D物体扫描通常需要多摄像头阵列、精密激光扫描仪或机器人腕部安装摄像头，这些设备的工作空间都受到限制。我们提出了Omni-Scan，这是一个使用双臂机器人生成高质量3D高斯溅射模型的管道，机器人用一个夹持器抓取物体并相对于固定摄像头旋转。然后，物体由第二个夹持器重新抓取，以暴露被第一个夹持器遮挡的表面。我们展示了Omni-Scan机器人管道，该管道使用DepthAnything、Segment Anything以及RAFT光流模型来识别和隔离机器人夹持的物体，同时移除夹持器和背景。然后，我们修改了3DGS训练管道，以支持带有夹持器遮挡的串联数据集，从而生成对象的全方位（360度视角）模型。我们将Omni-Scan应用于零件缺陷检测，发现它能够以83%的平均准确率识别12种不同工业和家用物体上的视觉或几何缺陷。Omni-Scan 3DGS模型的交互式视频可在https://berkeleyautomation.github.io/omni-scan/找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [716] [PIPE Planner: Pathwise Information Gain with Map Predictions for Indoor Robot Exploration](https://arxiv.org/abs/2503.07504)
> *PIPE规划器：用于室内机器人探索的地图预测路径信息增益*

*Seungjae Baek, Brady Moon, Seungchan Kim, Muqing Cao, Cherie Ho, Sebastian Scherer, Jeong hwan Jeon* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 机器人探索, 信息增益, 地图预测, 路径规划, 室内导航

**Comment:** 8 pages, 8 figures, IROS 2025

> **TL;DR:** PIPE规划器提出了一种结合地图预测的路径信息增益方法，以实现高效且知情的室内机器人探索，解决了传统方法计算量大和过高估计的问题。

**AI_Comments:** 该论文的创新之处在于将地图预测引入到路径信息增益的计算中，有效解决了传统方法中过高估计的问题，并显著提高了计算效率。这对于室内机器人自主探索领域是一个重要的进展，有望提升机器人在复杂未知环境中的探索效率和智能性。

<details>
  <summary>Details</summary>

**Motivation:** 在未知环境中进行自主探索需要估计行动的信息增益来指导规划决策。现有的方法通常在离散路点计算信息增益，而路径积分能提供更全面的估计，但通常计算困难或不可行，并且容易导致过高估计。

**Method:** 本文提出了路径信息增益与地图预测相结合的探索（PIPE）规划器，该规划器沿规划轨迹整合累积传感器覆盖范围，并利用地图预测来减轻过高估计。为了实现高效的路径覆盖计算，引入了一种有效计算沿规划路径的预期观测掩码的方法，显著降低了计算开销。

**Result:** PIPE规划器在真实世界平面图数据集上进行了验证，结果表明其性能优于最先进的基线方法。

**Conclusion:** 结果强调了将预测性地图与路径信息增益相结合，对于高效和知情探索的益处。

> **ai_Abstract:** PIPE规划器提出了一种用于室内机器人探索的新方法，通过整合沿着规划轨迹的累积传感器覆盖并利用地图预测来解决传统路径信息增益计算中存在的过高估计和计算效率低下的问题。该方法引入了高效计算预期观测掩码的技术，并在真实世界数据集中验证了其优于现有先进方法的性能，证明了预测性地图与路径信息增益结合在高效探索中的优势。

> **摘要翻译:** 在未知环境中进行自主探索需要估计行动的信息增益来指导规划决策。虽然以前的方法通常在离散路点计算信息增益，但路径积分可以提供更全面的估计，但通常计算困难或不可行，并且容易导致过高估计。在这项工作中，我们提出了路径信息增益与地图预测相结合的探索（PIPE）规划器，该规划器沿规划轨迹整合累积传感器覆盖范围，同时利用地图预测来减轻过高估计。为了实现高效的路径覆盖计算，我们引入了一种有效计算沿规划路径的预期观测掩码的方法，显著降低了计算开销。我们在真实世界平面图数据集上验证了PIPE，展示了其优于最先进基线的卓越性能。我们的结果突出了将预测性地图与路径信息增益相结合，对于高效和知情探索的益处。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [743] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
> *TOP：人形机器人稳定精确站立操作的时间优化策略*

*Zhenghan Chen, Haocheng Xu, Haodong Zhang, Liang Zhang, He Li, Dongqi Wang, Jiyu Yu, Yifei Yang, Zhongxiang Zhou, Rong Xiong* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 人形机器人, 站立操作, 时间优化策略, 运动控制, 强化学习

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的时间优化策略（TOP），用于训练站立操作控制模型，通过调整上身运动时间轨迹，同时确保平衡、精度和时间效率，从而实现人形机器人稳定精确的站立操作。

**AI_Comments:** 本文的创新点在于提出了时间优化策略（TOP），通过调整上身运动的时间轨迹来主动管理平衡负担，而非仅仅依赖于增强下身的抗干扰能力。这种方法结合了运动先验、解耦控制和强化学习，为人形机器人的高精度、高鲁棒性操作提供了一个新颖且有效的解决方案。其在仿真和真实世界中的验证增加了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人形机器人站立操作控制方法在精确控制高维上身关节方面表现不佳，或者难以同时确保鲁棒性和准确性，尤其是在上身运动快速时。

**Method:** 本文提出了一种时间优化策略（TOP），该方法包含三个部分：1. 利用运动先验（通过VAE训练）表示上身运动，增强上下身协调能力。2. 将全身控制解耦为上身PD控制器（用于精度）和下身RL控制器（用于鲁棒稳定性）。3. 将TOP方法与解耦控制器和VAE结合训练，以减少快速上身运动导致的平衡负担。

**Result:** 通过仿真和真实世界实验评估了所提出方法的有效性，结果表明其在稳定和精确的站立操作任务上表现出优越性。

**Conclusion:** 本文提出的时间优化策略（TOP）能够有效解决人形机器人在快速上身运动时保持稳定性和精确性的挑战，实现了稳定、精确且高效的站立操作。

> **ai_Abstract:** 本文提出了一种名为时间优化策略（TOP）的新型方法，旨在解决人形机器人在执行快速上身操作时难以同时保持稳定性和精确性的问题。该方法通过调整上身运动的时间轨迹来平衡精度、稳定性和时间效率。其核心在于利用VAE学习上身运动先验以促进全身协调，并将全身控制解耦为上身PD控制器和下身RL控制器。最终，TOP与这些组件协同训练，以减轻快速上身运动对平衡的负面影响。仿真和真实世界实验均验证了该方法在稳定和精确站立操作任务上的优越性。

> **摘要翻译:** 人形机器人有潜力执行各种操作任务，但这依赖于一个鲁棒且精确的站立控制器。现有方法要么不适合精确控制高维上身关节，要么难以同时确保鲁棒性和准确性，尤其是在上身运动快速时。本文提出了一种新颖的时间优化策略（TOP），通过调整上身运动的时间轨迹，而不仅仅是增强下身的抗干扰能力，来训练一个同时确保平衡、精度和时间效率的站立操作控制模型。我们的方法包括三个部分。首先，我们利用运动先验来表示上身运动，通过训练变分自编码器（VAE）来增强上下身之间的协调能力。然后，我们将全身控制解耦为用于精确度的上身PD控制器和用于增强鲁棒稳定性的下身RL控制器。最后，我们将TOP方法与解耦控制器和VAE结合训练，以减少因快速上身运动导致的平衡负担，这些运动会使机器人不稳定并超出下身RL策略的能力。所提出方法的有效性通过仿真和真实世界实验进行评估，这证明了其在稳定和精确的站立操作任务上的优越性。项目页面可在https://anonymous.4open.science/w/top-258F/找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [762] [Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents](https://arxiv.org/abs/2507.23698)
> *可扩展多任务强化学习用于视动智能体中的泛化空间智能*

*Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang* | **Category: cs.RO, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 强化学习, 多任务学习, 泛化, 视动智能体, Minecraft, 空间推理, 零样本泛化

**Comment:** 

> **TL;DR:** 本文展示了在Minecraft中通过RL微调的视动智能体可以实现对未见世界的零样本泛化，并通过自动化任务合成和分布式RL框架显著提升了空间推理能力。

**AI_Comments:** 本文的创新点在于提出了在Minecraft中自动化任务合成的方法来解决手动任务设计的瓶颈，并结合分布式RL框架实现了大规模多任务训练。这对于提升视动智能体的泛化能力，特别是零样本泛化能力具有重要意义。在可定制的3D环境中进行大规模任务生成是推动RL在真实世界应用的关键一步。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习在语言建模中取得了显著成功，但在视动智能体中尚未完全实现。主要挑战是RL模型倾向于过拟合特定任务或环境，阻碍了在不同设置中获得可泛化行为。

**Method:** 1. 探索RL增强3D世界中可泛化空间推理和交互能力。2. 分析并建立跨视图目标规范作为视动策略的统一多任务目标空间。3. 提出在Minecraft环境中自动化任务合成进行大规模多任务RL训练。4. 构建高效分布式RL框架支持训练。

**Result:** RL显著提升了交互成功率4倍，并实现了空间推理在不同环境（包括真实世界设置）中的零样本泛化。

**Conclusion:** 在3D模拟环境（特别是那些适合大规模任务生成的环境）中进行RL训练，对于显著提升视动智能体的空间推理能力具有巨大潜力。

> **ai_Abstract:** 本文旨在解决强化学习在视动智能体中泛化能力不足的问题。作者提出在高度可定制的Minecraft环境中利用自动化任务合成进行大规模多任务RL训练，并构建了高效的分布式RL框架。通过建立跨视图目标规范作为统一的多任务目标空间，研究表明RL微调的视动智能体能实现对未见世界的零样本泛化，并将交互成功率提升4倍，证明了3D模拟环境在提升视动智能体空间推理能力方面的巨大潜力。

> **摘要翻译:** 尽管强化学习（RL）在语言建模中取得了显著成功，但其胜利尚未完全转化为视动智能体。RL模型面临的主要挑战是它们倾向于过拟合特定任务或环境，从而阻碍了在不同设置中获得可泛化行为。本文通过证明在Minecraft中经过RL微调的视动智能体可以实现对未见世界的零样本泛化，为这一挑战提供了一个初步答案。具体来说，我们探索了RL在3D世界中增强可泛化空间推理和交互能力的潜力。为了解决多任务RL表示中的挑战，我们分析并建立了跨视图目标规范作为视动策略的统一多任务目标空间。此外，为了克服手动任务设计的显著瓶颈，我们提出了在高度可定制的Minecraft环境中进行自动化任务合成以进行大规模多任务RL训练，并构建了一个高效的分布式RL框架来支持这一点。实验结果表明，RL显著提升了交互成功率4倍，并使空间推理能够在不同环境（包括真实世界设置）中实现零样本泛化。我们的研究结果强调了在3D模拟环境，特别是那些适合大规模任务生成的环境中进行RL训练，对于显著推进视动智能体的空间推理能力的巨大潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [765] [Safe Navigation in Uncertain Crowded Environments Using Risk Adaptive CVaR Barrier Functions](https://arxiv.org/abs/2504.06513)
> *在不确定拥挤环境中基于风险自适应CVaR障碍函数的安全导航*

*Xinyi Wang, Taekyung Kim, Bardh Hoxha, Georgios Fainekos, Dimitra Panagou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 机器人导航, 风险自适应, CVaR障碍函数, 动态区域, 不确定环境

**Comment:** 2025 IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS). Project page: {https://lawliet9666.github.io/cvarbf/}

> **TL;DR:** 提出一种风险自适应的条件风险价值障碍函数（CVaR-BF）方法，用于在不确定拥挤环境中实现机器人安全导航，通过动态调整风险水平和引入动态区域障碍函数，实现主动避障并优于现有方法。

**AI_Comments:** 本文的创新之处在于结合了风险自适应的CVaR障碍函数和动态区域障碍函数，实现了在不确定环境中机器人导航的风险控制和主动避障。这种方法在处理动态和不确定性方面表现出色，对于提高机器人自主性和安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器人R在动态、拥挤环境中导航面临巨大挑战，主要源于障碍物模型中固有的不确定性。

**Method:** 提出一种基于条件风险价值障碍函数（CVaR-BF）的风险自适应方法，该方法能自动调整风险水平以接受最低必要风险。此外，引入了一种动态区域障碍函数，通过评估机器人与障碍物之间的相对状态来表征碰撞可能性。将风险自适应与该新函数结合，以自适应地扩大安全裕度。

**Result:** 对比和消融研究表明，所提出的方法优于现有的社交导航方法，并验证了所提框架的有效性。

**Conclusion:** 该研究通过提出风险自适应的CVaR障碍函数和动态区域障碍函数，成功解决了不确定拥挤环境中的机器人安全导航问题，实现了安全性和优化可行性的良好平衡。

> **ai_Abstract:** 本文提出了一种在不确定拥挤环境中实现机器人安全导航的风险自适应方法。该方法基于条件风险价值障碍函数（CVaR-BF），能够自动调整风险水平以最小化必要风险，从而在安全性和优化可行性之间取得平衡。此外，引入了动态区域障碍函数来评估碰撞可能性并自适应扩大安全裕度，使机器人能够主动避障。实验结果表明，该方法优于现有社交导航方法，验证了其有效性。

> **摘要翻译:** 机器人在动态、拥挤环境中的导航由于障碍物模型固有的不确定性而带来了巨大的挑战。在这项工作中，我们提出了一种基于条件风险价值障碍函数（CVaR-BF）的风险自适应方法，其中风险水平自动调整以接受最低必要的风险，从而在不确定性下在安全性和优化可行性方面取得了良好的性能。此外，我们引入了一种动态区域障碍函数，通过评估机器人与障碍物之间的相对状态来表征碰撞可能性。通过将风险自适应与此新函数相结合，我们的方法自适应地扩大了安全裕度，使机器人能够在高度动态的环境中主动避开障碍物。比较和消融研究表明，我们的方法优于现有的社交导航方法，并验证了我们所提出的框架的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [771] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
> *一种基于人体数据的全尺寸人形机器人全身运动模仿框架*

*Zhenghan Chen, Haodong Zhang, Dongqi Wang, Jiyu Yu, Haocheng Xu, Yue Wang, Rong Xiong* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 全身运动模仿, 人形机器人, 运动重定向, 模型预测控制, 平衡控制

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的全尺寸人形机器人全身运动模仿框架，通过接触感知全身运动重定向和非线性质心模型预测控制器，使机器人能够准确模仿人类动作并保持平衡，已在仿真和真实机器人上验证其有效性。

**AI_Comments:** 该论文提出了一种结合运动重定向和模型预测控制的创新框架，有效解决了全尺寸人形机器人模仿人类动作时平衡和精度难以兼顾的问题。其亮点在于引入接触感知和非线性质心模型预测控制器，以实现实时的平衡维持和抗干扰能力，这对于复杂动态动作的实现至关重要。该方法在仿真和真实机器人上的验证增强了其可靠性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 人形机器人模仿人类运动以实现多样化、富有表现力的动作面临挑战，主要原因是机器人与人类在运动学和动力学上的显著差异，这使得在保持平衡的同时精确模仿运动变得困难。

**Method:** 本文提出了一种新颖的全尺寸人形机器人全身运动模仿框架。该方法采用接触感知全身运动重定向来模仿人类运动并提供参考轨迹的初始值，同时利用非线性质心模型预测控制器实时确保运动精度、保持平衡并克服外部干扰。全身控制器的辅助实现了更精确的扭矩控制。

**Result:** 通过在仿真和真实人形机器人上模仿多种人类动作的实验表明，该框架能够以高精度和适应性执行动作。

**Conclusion:** 实验结果验证了所提出框架的有效性，证明其能够使全尺寸人形机器人准确模仿人类动作并保持平衡。

> **ai_Abstract:** 本文提出了一种针对全尺寸人形机器人的新型全身运动模仿框架，旨在克服人类与机器人之间运动学和动力学差异带来的运动模仿挑战。该框架结合了接触感知全身运动重定向技术以生成初始轨迹，并利用非线性质心模型预测控制器实时确保运动精度、平衡性和抗干扰能力。全身控制器进一步提升了扭矩控制的精确性。仿真和真实机器人上的实验验证了该方法在模仿多样化人类动作方面的准确性和适应性。

> **摘要翻译:** 运动模仿是人形机器人实现更多样化、复杂和富有表现力动作的关键且有效方法，使其表现更像人类。然而，人形机器人与人类在运动学和动力学上的显著差异，在精确模仿运动同时保持平衡方面带来了重大挑战。在本文中，我们提出了一种针对全尺寸人形机器人的新型全身运动模仿框架。所提出的方法采用接触感知全身运动重定向来模仿人类运动并提供参考轨迹的初始值，并且非线性质心模型预测控制器确保运动精度，同时实时保持平衡并克服外部干扰。全身控制器的辅助允许更精确的扭矩控制。我们已经在仿真和真实世界的人形机器人中进行了实验，模仿了各种人类动作。这些实验证明了其高精度和适应性的执行能力，从而验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [799] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
> *关于学习闭环概率多智能体模拟器*

*Juanwu Lu, Rohit Gupta, Ahmadreza Moradipari, Kyungtae Han, Ruqi Zhang, Ziran Wang* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 多智能体模拟, 概率框架, 分层贝叶斯模型, 自动驾驶, 闭环模拟器

**Comment:** Accepted to IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS) 2025. Source Code: https://github.com/juanwulu/niva

> **TL;DR:** 本文介绍了NIVA，一个用于多智能体模拟的概率框架，该框架基于分层贝叶斯模型，通过Waymo数据集实验证明其性能具有竞争力，并能更好地控制智能体的意图和驾驶风格。

**AI_Comments:** NIVA的创新之处在于其提出的概率框架和分层贝叶斯模型，以及它能够从贝叶斯推理角度统一现有序列到序列轨迹预测模型和新兴闭环模拟模型的能力。这对于需要生成多样化和交互式场景的自动驾驶交通模拟器至关重要，并且NIVA在提供竞争性性能的同时，还能提供对智能体行为的精细控制，这对于模拟真实交通流和行为具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车（AV）的快速部署使得对构建真实且可扩展的多智能体交通模拟器以进行高效评估的需求日益增长。该领域的最新进展集中在能够生成多样化和交互式场景的闭环模拟器上。

**Method:** 本文引入了神经交互代理（NIVA），这是一个由分层贝叶斯模型驱动的概率多智能体模拟框架。它通过从潜在的有限高斯混合分布中自回归采样，实现闭环、观察条件下的模拟。NIVA从贝叶斯推理的角度统一了现有的序列到序列轨迹预测模型和新兴的基于下一令牌预测（NTP）训练的闭环模拟模型。

**Result:** 在Waymo开放运动数据集上的实验表明，与现有方法相比，NIVA取得了具有竞争力的性能。

**Conclusion:** NIVA在提供具有竞争力的性能的同时，还能对意图和驾驶风格提供更精细的控制。

> **ai_Abstract:** NIVA是一个新颖的、基于分层贝叶斯模型的概率框架，用于闭环多智能体模拟。它能够统一现有的轨迹预测和闭环模拟模型，并在Waymo开放运动数据集上展示了具有竞争力的性能，同时提供了对智能体意图和驾驶风格的精细控制。

> **摘要翻译:** 自动驾驶汽车（AV）部署的快速迭代导致对构建真实且可扩展的多智能体交通模拟器以进行高效评估的需求日益增长。该领域的最新进展集中在能够生成多样化和交互式场景的闭环模拟器上。本文介绍了神经交互代理（NIVA），这是一个由分层贝叶斯模型驱动的概率多智能体模拟框架，通过从潜在的有限高斯混合分布中自回归采样，实现闭环、观察条件下的模拟。我们展示了NIVA如何从贝叶斯推理的角度统一现有的序列到序列轨迹预测模型和新兴的基于下一令牌预测（NTP）训练的闭环模拟模型。在Waymo开放运动数据集上的实验表明，与现有方法相比，NIVA取得了具有竞争力的性能，同时能对意图和驾驶风格提供更精细的控制。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [807] [E2E Parking Dataset: An Open Benchmark for End-to-End Autonomous Parking](https://arxiv.org/abs/2504.10812)
> *E2E停车数据集：端到端自动泊车的开放基准*

*Kejia Gao, Liguo Zhou, Mingjun Liu, Alois Knoll* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 自动泊车, 端到端学习, 数据集, 开放基准, E2E停车数据集

**Comment:** 

> **TL;DR:** 本文发布了一个名为E2E停车数据集的高质量开放数据集，以解决端到端自动泊车领域缺乏公开数据集的问题，并使用现有模型验证了其有效性。

**AI_Comments:** 本文的创新点在于填补了端到端自动泊车领域缺乏公开高质量数据集的空白，这对于推动该领域的可复现性研究和性能基准测试至关重要。通过发布E2E停车数据集，研究者可以更方便地进行模型训练和评估，加速自动泊车技术的发展。其重要性在于提供了一个开放的、可验证的平台，有助于标准化研究方法并促进社区协作。

<details>
  <summary>Details</summary>

**Motivation:** 端到端学习在自动泊车方面展现出巨大潜力，但缺乏公开可用的数据集限制了研究的可复现性和基准测试。尽管之前的研究提出了基于视觉的泊车模型和数据生成、训练及闭环测试的流程，但其数据集并未发布。

**Method:** 我们创建并开源了一个用于端到端自动泊车的高质量数据集。

**Result:** 使用原始模型，我们取得了85.16%的总体成功率，平均位置误差为0.24米，平均方向误差为0.34度。

**Conclusion:** 本文成功创建并开源了一个高质量的端到端自动泊车数据集，有效弥补了该领域公开数据集的空白，并验证了其在现有模型上的有效性，有助于推动自动泊车研究的可复现性和基准测试。

> **ai_Abstract:** 本文针对端到端自动泊车领域缺乏公开数据集的问题，创建并开源了一个高质量的E2E停车数据集。作者利用现有模型对该数据集进行了验证，取得了85.16%的成功率，并显著降低了泊车的位置和方向误差，为该领域的研究提供了重要的开放基准。

> **摘要翻译:** 端到端学习在自动泊车方面展现出巨大潜力，然而公开可用数据集的缺乏限制了其可复现性和基准测试。虽然先前的工作引入了基于视觉的泊车模型以及数据生成、训练和闭环测试的流程，但数据集本身并未发布。为了弥补这一空白，我们创建并开源了一个高质量的端到端自动泊车数据集。使用原始模型，我们实现了85.16%的总体成功率，并获得了更低的平均位置误差（0.24米）和方向误差（0.34度）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [815] [Learning to Drift with Individual Wheel Drive: Maneuvering Autonomous Vehicle at the Handling Limits](https://arxiv.org/abs/2507.23339)
> *基于独立轮驱动的学习漂移：在操控极限下操纵自动驾驶汽车*

*Yihan Zhou, Yiwen Lu, Bo Yang, Jiayun Li, Yilin Mo* | **Category: cs.RO, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 强化学习, 漂移控制, 仿真到现实差距, 独立轮驱动, 域随机化

**Comment:** 

> **TL;DR:** 本文提出了一种基于强化学习的方法，结合GPU加速并行仿真和系统域随机化，以弥合漂移控制中仿真到现实的差距，并在仿真和1/10比例的独立轮驱动遥控车平台上验证了其有效性。

**AI_Comments:** 本文的创新点在于结合GPU加速并行仿真和系统域随机化来有效弥合强化学习在漂移控制中的仿真到现实差距。其在定制的独立轮驱动遥控车平台上的验证，增强了研究的实际应用价值。该工作对于提升自动驾驶车辆在紧急情况下的安全操控能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 漂移对于在摩擦极限下安全处理紧急情况至关重要。现有的强化学习方法在漂移控制中存在显著的仿真到现实差距，导致策略在物理系统上失效。

**Method:** 提出了一种强化学习框架，该框架结合了GPU加速并行仿真和系统域随机化。该方法在仿真和定制设计的1/10比例独立轮驱动（IWD）遥控车平台上进行了验证，该平台具有独立的轮速控制。

**Result:** 在从稳态圆形漂移到方向转换和可变曲率路径跟踪的各种场景中，所提出的方法在仿真和现实环境中都能实现精确的轨迹跟踪，同时在复杂机动中保持受控的侧滑角。

**Conclusion:** 所提出的强化学习框架通过GPU加速并行仿真和系统域随机化，有效弥合了漂移控制中的仿真到现实差距，并在物理平台上实现了精确的极限操控。

> **ai_Abstract:** 本文提出了一种用于自动驾驶车辆漂移控制的强化学习框架，旨在解决仿真到现实的差距问题。该框架利用GPU加速并行仿真和系统域随机化，并在仿真和1/10比例的独立轮驱动遥控车上进行了验证。实验结果表明，该方法在复杂机动中能够实现精确的轨迹跟踪和受控的侧滑角，有效提升了自动驾驶车辆在极限操控下的性能。

> **摘要翻译:** 漂移，以高侧滑角下的受控车辆运动为特征，对于在摩擦极限下安全处理紧急情况至关重要。尽管最近的强化学习方法在漂移控制方面显示出前景，但它们面临着显著的仿真到现实差距，因为在仿真中表现良好的策略在转移到物理系统时常常失败。在本文中，我们提出了一种结合GPU加速并行仿真和系统域随机化的强化学习框架，有效地弥合了这一差距。所提出的方法在仿真和定制设计并开源的1/10比例独立轮驱动（IWD）遥控车平台上进行了验证，该平台具有独立的轮速控制。从稳态圆形漂移到方向转换和可变曲率路径跟踪的各种场景的实验表明，我们的方法在仿真和现实环境中都能实现精确的轨迹跟踪，同时在复杂机动中保持受控的侧滑角。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [820] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
> *SubCDM：基于集群子集的集体决策*

*Samratul Fuady, Danesh Tarapore, Mohammad D. Soorati* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 集体决策, 机器人集群, 资源效率, 去中心化, 子集决策

**Comment:** 6 pages, 7 figures. This paper has been accepted for presentation at
  the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems
  (IROS 2025)

> **TL;DR:** SubCDM是一种新的集体决策方法，允许机器人集群仅使用部分机器人进行决策，从而节省资源并保持决策准确性。

**AI_Comments:** SubCDM的创新之处在于其通过动态和去中心化的方式，允许机器人集群仅使用部分成员进行集体决策，显著提高了资源效率。这对于需要同时执行多任务的机器人集群具有重要意义，克服了传统方法资源消耗大的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的集体决策策略需要所有机器人参与，这会消耗大量资源并限制机器人执行其他任务。

**Method:** 我们提出了基于子集的集体决策（SubCDM），它仅使用集群子集进行决策。子集的构建是动态和去中心化的，仅依赖局部信息。该方法允许集群根据达成共识的难度自适应地确定子集大小。

**Result:** 使用一百个机器人进行的仿真结果表明，我们的方法在减少执行集体决策所需的机器人数量的同时，实现了与使用整个集群相当的准确性。

**Conclusion:** SubCDM提供了一种资源高效的集群机器人集体决策解决方案，通过使用子集进行决策，实现了与全集群决策相当的准确性。

> **ai_Abstract:** 本文提出了一种名为SubCDM（基于子集的集体决策）的新型机器人集群集体决策策略。与传统方法需要所有机器人参与不同，SubCDM允许集群仅使用动态且去中心化构建的子集进行决策。该方法能够根据决策难度自适应调整子集大小，并通过仿真证明其在减少所需机器人数量的同时，能达到与全集群参与相当的决策准确性，从而实现资源高效的集体决策。

> **摘要翻译:** 集体决策是自主机器人集群的关键功能，使它们能够根据环境特征就行动达成共识。现有策略需要所有机器人参与决策过程，这会消耗大量资源并阻止集群将机器人分配给任何其他任务。我们提出了基于子集的集体决策（SubCDM），它仅使用集群子集进行决策。子集的构建是动态和去中心化的，仅依赖局部信息。我们的方法允许集群根据达成共识的难度自适应地确定子集大小以进行准确决策。使用一百个机器人进行的仿真结果表明，我们的方法在减少执行集体决策所需的机器人数量的同时，实现了与使用整个集群相当的准确性，使其成为集群机器人中集体决策的资源高效解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [846] [Distributed AI Agents for Cognitive Underwater Robot Autonomy](https://arxiv.org/abs/2507.23735)
> *分布式AI智能体用于水下机器人认知自主性*

*Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot* | **Category: cs.RO, cs.AI, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 水下机器人, 认知自主性, 分布式AI智能体, 大型语言模型, ROS 2

**Comment:** 

> **TL;DR:** UROSA是一个利用分布式LLM AI智能体在ROS 2框架下实现水下机器人认知自主性的新架构，通过动态适应、RAG、RL和运行时节点生成，在复杂水下任务中表现出优异的适应性和可靠性。

**AI_Comments:** 这项工作的创新之处在于将分布式大型语言模型AI智能体集成到ROS 2框架中，以实现水下机器人的高级认知自主性，特别是其去中心化认知、动态适应性、检索增强生成和运行时扩展能力。这对于处理复杂和不可预测的水下环境具有重要意义，并为通用认知机器人框架奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂、不可预测环境中导航的机器人实现鲁棒的认知自主性仍然是机器人学的一个根本性挑战。

**Method:** 本文提出了水下机器人自组织自主性（UROSA）架构，该架构利用集成在机器人操作系统2（ROS 2）框架中的分布式大型语言模型AI智能体，以实现自主水下飞行器的高级认知能力。UROSA将认知分散到专门的AI智能体中，这些智能体负责多模态感知、自适应推理、动态任务规划和实时决策。核心创新包括：灵活智能体动态适应其角色、利用向量数据库进行高效知识管理的检索增强生成、强化学习驱动的行为优化，以及用于运行时功能可扩展性的自主即时ROS 2节点生成。

**Result:** 广泛的实证验证表明，UROSA在模拟和实际部署的现实水下任务中具有良好的适应性和可靠性，在处理不可预见的场景、环境不确定性和新任务目标方面，显示出优于传统基于规则的架构的显著优势。

**Conclusion:** 这项工作不仅推动了水下自主性，还建立了一个可扩展、安全、通用的认知机器人框架，能够推广到各种实际应用。

> **ai_Abstract:** 本文提出UROSA架构，通过在ROS 2中集成分布式LLM AI智能体，赋予水下机器人高级认知自主能力。UROSA将认知任务分散给专业智能体，并引入动态角色适应、RAG、RL行为优化和运行时节点生成等创新。实验证明，UROSA在复杂水下任务中表现出优异的适应性和可靠性，超越传统方法，为认知机器人学提供了通用框架。

> **摘要翻译:** 在复杂、不可预测环境中导航的机器人实现鲁棒的认知自主性仍然是机器人学的一个根本性挑战。本文提出了水下机器人自组织自主性（UROSA），这是一个突破性的架构，利用集成在机器人操作系统2（ROS 2）框架中的分布式大型语言模型AI智能体，以实现自主水下飞行器的高级认知能力。UROSA将认知分散到专门的AI智能体中，这些智能体负责多模态感知、自适应推理、动态任务规划和实时决策。核心创新包括：灵活智能体动态适应其角色、利用向量数据库进行高效知识管理的检索增强生成、强化学习驱动的行为优化，以及用于运行时功能可扩展性的自主即时ROS 2节点生成。广泛的实证验证表明，UROSA在模拟和实际部署的现实水下任务中具有良好的适应性和可靠性，在处理不可预见的场景、环境不确定性和新任务目标方面，显示出优于传统基于规则的架构的显著优势。这项工作不仅推动了水下自主性，还建立了一个可扩展、安全、通用的认知机器人框架，能够推广到各种实际应用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [848] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
> *HannesImitation：通过模仿学习实现Hannes假肢的抓取*

*Carlo Alessi, Federico Vasile, Federico Ceola, Giulia Pasquale, Nicolò Boccardo, Lorenzo Natale* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 模仿学习, 假肢, 抓取, 扩散策略, 非结构化环境

**Comment:** Paper accepted at IEEE/RSJ International Conference on Intelligent
  Robots and Systems (IROS)

> **TL;DR:** 该研究通过模仿学习控制Hannes假肢进行抓取，在非结构化环境中表现出色，并优于传统方法。

**AI_Comments:** 该论文的创新之处在于将模仿学习这一在机器人领域前景广阔的技术首次应用于假肢控制，填补了该领域的一个重要空白。通过创建专属的HannesImitationDataset并训练扩散策略，该研究显著提升了假肢在复杂、非结构化环境中的抓取能力和自主性，有望减轻用户负担并拓宽假肢的应用场景。其超越传统方法的性能也证明了模仿学习在假肢领域的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前假肢控制系统致力于提高自主性以减轻用户认知负荷，而模仿学习在机器人抓取领域已显示出巨大潜力。然而，模仿学习在假肢控制中的应用尚未得到充分探索。弥合这一空白可以增强假肢的灵活性，并使其能够在更多非受限场景中运行，通过演示学习任务而非依赖手动标注序列。

**Method:** 本文提出了HannesImitationPolicy，一种基于模仿学习的方法来控制Hannes假肢，使其能够在非结构化环境中抓取物体。此外，论文还引入了HannesImitationDataset，包含桌面、货架和人手与假肢之间交接场景的抓取演示数据。研究利用这些数据训练了一个单一的扩散策略，并将其部署在假肢上以预测抓取时的腕部方向和手部闭合。

**Result:** 实验评估表明，该策略在不同物体和条件下都能成功抓取。此外，研究还展示了该策略在非结构化场景中优于基于分割的视觉伺服控制器。

**Conclusion:** 本文成功将模仿学习应用于Hannes假肢的控制，实现了在非结构化环境中的鲁棒抓取，并证明了其性能优于传统方法，从而提升了假肢的灵活性恢复能力。

> **ai_Abstract:** 本文提出了HannesImitationPolicy，一种基于模仿学习的方法，用于控制Hannes假肢在非结构化环境中进行物体抓取。研究构建了包含多种抓取场景的HannesImitationDataset，并利用该数据集训练了一个单一的扩散策略来预测抓取时的手部姿态。实验结果表明，该方法在多样化的物体和条件下均能成功实现抓取，并且在非结构化场景中优于传统的基于分割的视觉伺服控制器，显著提升了假肢的自主性和操作灵活性。

> **摘要翻译:** 假肢控制的最新进展集中于通过使用摄像头和其他感官输入来增加自主性。这些系统旨在通过自动控制某些自由度来减轻用户的认知负荷。在机器人技术中，模仿学习已成为一种有前途的方法，用于学习抓取和复杂的操纵任务，同时简化数据收集。然而，其在假肢控制中的应用在很大程度上仍未被探索。弥合这一空白可以增强灵巧性恢复，并使假肢设备能够在更不受限制的场景中运行，在这些场景中，任务是通过演示学习的，而不是依赖手动标注的序列。为此，我们提出了HannesImitationPolicy，一种基于模仿学习的方法来控制Hannes假肢，使其能够在非结构化环境中抓取物体。此外，我们引入了HannesImitationDataset，包含桌面、货架和人手与假肢之间交接场景的抓取演示。我们利用这些数据训练了一个单一的扩散策略，并将其部署在假肢上以预测抓取时的腕部方向和手部闭合。实验评估表明，在不同物体和条件下都能成功抓取。最后，我们展示了该策略在非结构化场景中优于基于分割的视觉伺服控制器。更多材料可在我们的项目页面获取：https://hsp-iit.github.io/HannesImitation

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [849] [Trends in Motion Prediction Toward Deployable and Generalizable Autonomy: A Revisit and Perspectives](https://arxiv.org/abs/2505.09074)
> *运动预测迈向可部署和可泛化自主性的趋势：回顾与展望*

*Letian Wang, Marc-Antoine Lavoie, Sandro Papais, Barza Nisar, Yuxiao Chen, Wenhao Ding, Boris Ivanovic, Hao Shao, Abulikemu Abuduweili, Evan Cook, Yang Zhou, Peter Karkus, Jiachen Li, Changliu Liu, Marco Pavone, Steven Waslander* | **Category: cs.RO** | **Updated: 2025-07-31**

**Keywords:** 运动预测, 泛化能力, 可部署性, 自动驾驶, 机器人

**Comment:** Updated draft. 163 pages, 40 figures, 13 tables

> **TL;DR:** 这篇综述文章探讨了运动预测模型在实际部署和泛化能力方面的挑战，指出了研究基准与现实复杂性之间的差距，并提出了解决这些问题的关键挑战和未来研究方向。

**AI_Comments:** 本文作为一篇综述，其价值在于清晰地识别了运动预测领域当前面临的核心挑战——即模型在真实世界部署中的泛化性和可靠性问题。通过提供全面的分类和深入探讨关键挑战，它为研究人员提供了一个宝贵的路线图，指明了未来努力的方向，有助于推动该领域从理论研究走向实际应用。

<details>
  <summary>Details</summary>

**Motivation:** 现有的运动预测模型在实验室基准测试中表现良好，但在实际部署到现实世界时，往往难以泛化到开放世界条件，并且不符合部署标准，这揭示了研究基准与现实复杂性之间的差距。本文旨在解决这一问题。

**Method:** 本综述文章重新审视了运动预测模型的泛化能力和可部署性，重点关注机器人、自动驾驶和人体运动等应用。文章首先提供了运动预测方法的全面分类，涵盖表示、建模策略、应用领域和评估协议。然后，研究了两个关键挑战：如何使运动预测模型达到实际部署标准，以及如何将模型从有限的已知场景/数据集泛化到开放世界设置。

**Result:** 本文提供了一个运动预测方法的全面分类，并深入研究了模型可部署性和泛化能力的两大关键挑战。通过分析，文章强调了指导未来工作的关键开放挑战，旨在重新校准社区的努力方向，促进不仅可衡量而且对实际应用有意义的进展。

**Conclusion:** 运动预测领域需要重新校准研究方向，以弥合研究基准与现实世界部署之间的差距。未来的工作应着重于提高模型的可部署性和泛化能力，使其在真实世界的闭环自主系统中有效运行。

> **ai_Abstract:** 这篇综述文章深入探讨了运动预测领域的最新趋势，旨在弥合研究基准与实际部署和泛化能力之间的差距。文章首先构建了一个全面的运动预测方法分类体系，随后重点分析了模型在真实世界中实现可部署性和从有限数据泛化到开放世界环境的两大核心挑战。最终，文章指出了该领域的关键开放问题，旨在引导未来研究更聚焦于实际应用价值。

> **摘要翻译:** 运动预测，即对未来智能体状态或场景演变的预测，植根于人类认知，连接着感知与决策。它使机器人和自动驾驶汽车等智能系统能够在动态、有人参与的环境中安全行动，并为更广泛的时间序列推理挑战提供信息。随着方法、表示和数据集的进步，该领域取得了快速发展，这反映在快速演变的基准测试结果中。然而，当最先进的方法在现实世界中部署时，它们往往难以泛化到开放世界条件，并且不符合部署标准。这揭示了通常理想化或不适定的研究基准与现实世界复杂性之间的差距。
为了弥合这一差距，本综述重新审视了运动预测模型的泛化能力和可部署性，重点关注机器人、自动驾驶和人体运动的应用。我们首先提供了运动预测方法的全面分类，涵盖表示、建模策略、应用领域和评估协议。然后，我们研究了两个关键挑战：（1）如何推动运动预测模型达到实际部署标准，即运动预测并非独立运作，而是作为闭环自主堆栈的一个模块发挥作用——它从定位和感知接收输入，并为下游规划和控制提供信息。（2）如何将运动预测模型从有限的已知场景/数据集泛化到开放世界设置。在整篇论文中，我们强调了关键的开放挑战，以指导未来的工作，旨在重新校准社区的努力，促进不仅可衡量而且对实际应用有意义的进展。本论文对应的项目网页可以在这里找到：https://trends-in-motion-prediction-2025.github.io/。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [876] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
> *OmniUnet：一种用于行星探测器非结构化地形分割的多模态网络，利用RGB、深度和热成像*

*Raul Castilla-Arquillo, Carlos Perez-del-Pulgar, Levin Gerdes, Alfonso Garcia-Cerezo, Miguel A. Olivares-Mendez* | **Category: cs.RO, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 多模态感知, 地形分割, 行星探测器, 语义分割, OmniUnet

**Comment:** 

> **TL;DR:** OmniUnet是一种基于Transformer的多模态网络，利用RGB、深度和热成像数据对行星探测器上的非结构化地形进行语义分割，并在资源受限的硬件上实现了高精度和快速推理，适用于机器人部署。

**AI_Comments:** 该论文的创新之处在于其专门为行星探测器导航设计的OmniUnet多模态网络，特别是整合了对火星地形评估有价值的热成像数据。其重要性体现在解决了非结构化地形分割的关键挑战，并通过在资源受限硬件上验证其性能，展示了实际部署的可能性。此外，公开数据集和代码的举动极大地促进了未来在该领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 在非结构化环境中进行机器人导航需要多模态感知系统来支持安全导航，因为多模态能够整合不同传感器收集到的互补信息。此外，必须识别哪种传感器模态对目标环境中的导航最具信息量。在火星探索中，热成像因不同土壤类型之间的热行为差异而被证明对评估地形安全有价值。

**Method:** 本研究提出了OmniUnet，一种基于Transformer的神经网络架构，用于使用RGB、深度和热（RGB-D-T）图像进行语义分割。开发了一种定制的多模态传感器外壳，并安装在火星探测器自主测试平台（MaRTA）上，在西班牙北部巴德纳斯半沙漠收集多模态数据集。该数据集的一个子集经过手动标注以支持网络的监督训练。

**Result:** 该模型在定量和定性评估中均表现出色，像素精度达到80.37%，并在分割复杂的非结构化地形方面表现出强大的性能。推理测试在资源受限的计算机（Jetson Orin Nano）上平均预测时间为673毫秒。

**Conclusion:** OmniUnet在非结构化地形分割方面表现出强大的性能，并且在资源受限的硬件上推理时间短，证实了其在机器人上部署的适用性。网络的软件实现和标注数据集已公开，以支持行星机器人多模态地形感知领域的未来研究。

> **ai_Abstract:** 本论文介绍了OmniUnet，一个基于Transformer的多模态神经网络，用于利用RGB、深度和热成像数据对行星探测器上的非结构化地形进行语义分割。为了训练和评估该网络，研究人员开发了一个定制的多模态传感器系统，并在模拟火星环境的地点收集了一个包含RGB-D-T图像的独特数据集。该模型在复杂地形分割中取得了80.37%的像素精度，并在资源受限设备上实现了快速推理，证明了其在实际机器人部署中的潜力。此外，该研究将网络代码和标注数据集公开，以促进未来研究。

> **摘要翻译:** 机器人在非结构化环境中导航需要多模态感知系统来支持安全导航。多模态能够整合不同传感器收集到的互补信息。然而，这些信息必须由专门设计用于利用异构数据的机器学习算法进行处理。此外，有必要识别哪些传感器模态对于目标环境中的导航最具信息量。在火星探索中，热成像因不同土壤类型之间的热行为差异而被证明对评估地形安全有价值。本工作提出了OmniUnet，一种基于Transformer的神经网络架构，用于使用RGB、深度和热（RGB-D-T）图像进行语义分割。使用3D打印开发了一种定制的多模态传感器外壳，并安装在火星探测器自主测试平台（MaRTA）上，用于在西班牙北部巴德纳斯半沙漠收集多模态数据集。该地点是火星表面的代表性环境，具有沙土、基岩和致密土壤等地形类型。该数据集的一个子集经过手动标注以支持网络的监督训练。该模型经过定量和定性评估，实现了80.37%的像素精度，并在分割复杂的非结构化地形方面表现出强大的性能。推理测试在资源受限的计算机（Jetson Orin Nano）上平均预测时间为673毫秒，证实了其在机器人上部署的适用性。网络的软件实现和标注数据集已公开，以支持行星机器人多模态地形感知领域的未来研究。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [884] [SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics](https://arxiv.org/abs/2505.11494)
> *SHIELD：基于学习动力学的期望控制障碍函数实现人形机器人安全*

*Lizhi Yang, Blake Werner, Ryan K. Cosner, David Fridovich-Keil, Preston Culbertson, Aaron D. Ames* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 人形机器人安全, 控制障碍函数, 学习动力学, 概率安全, 强化学习

**Comment:** Video at https://youtu.be/-Qv1wR4jfj4. To appear at IROS 2025

> **TL;DR:** SHIELD是一个分层安全框架，通过结合学习到的不确定性模型和随机CBF，为人形机器人提供概率安全保障，无需重新训练控制器。

**AI_Comments:** SHIELD的创新之处在于其分层方法，巧妙地将数据驱动的不确定性模型与形式化保证的CBF相结合，解决了学习型控制器在安全保障方面的核心挑战。其“微创”特性和无需重新训练底层控制器的能力是其主要优势，使得在实际机器人系统上部署和迭代安全策略变得更加可行。这种平衡性能和风险的概率安全保障对于复杂动态系统（如人形机器人）至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 机器人学习（RL）控制器在复杂任务中表现出色，但难以确保动态安全。RL通过奖励工程启发式嵌入约束，且修改约束需重新训练。模型基方法（如控制障碍函数CBF）提供形式化保证但需要精确动力学模型，这与RL的“黑箱”特性冲突。

**Method:** 本文提出了SHIELD，一个分层的安全框架：(1) 使用真实世界数据训练一个生成式、随机动力学残差模型，捕获系统行为和不确定性；(2) 在名义（学习到的运动）控制器之上添加一个安全层，该层通过随机离散时间CBF公式利用该模型，以概率方式强制执行安全约束。

**Result:** SHIELD是一个微创安全层，可添加到现有自主堆栈中，提供平衡风险和性能的概率安全保证。在Unitree G1人形机器人上的硬件实验中，SHIELD使用名义（未知）RL控制器和板载感知，使得机器人在各种室内外环境中能够安全导航（避障）。

**Conclusion:** SHIELD通过结合学习到的不确定性模型和随机CBF，为复杂的学习型机器人控制器提供了有效的概率安全保障，且无需修改或重新训练底层控制器，平衡了风险与性能。

> **ai_Abstract:** SHIELD是一个新颖的分层安全框架，旨在为人形机器人上基于学习的“黑箱”控制器提供概率安全保障。它通过训练一个捕捉系统不确定性的随机动力学残差模型，并将其与随机离散时间控制障碍函数（CBF）结合，在现有控制器之上添加一个非侵入式安全层。该方法无需重新训练底层控制器即可强制执行安全约束，并在Unitree G1人形机器人上成功实现了复杂环境中的安全导航和避障。

> **摘要翻译:** 机器人学习为人形机器人动态运动等复杂任务产生了非常有效的“黑箱”控制器。然而，对于此类策略，确保动态安全，即满足约束，仍然具有挑战性。强化学习（RL）通过奖励工程启发式地嵌入约束，并且添加或修改约束需要重新训练。基于模型的方法，如控制障碍函数（CBF），可以在运行时指定约束并提供形式化保证，但需要精确的动力学模型。本文提出了SHIELD，一个分层的安全框架，通过以下方式弥合了这一差距：(1) 使用来自名义控制器硬件运行的真实世界数据训练一个生成式、随机动力学残差模型，捕获系统行为和不确定性；(2) 在名义（学习到的运动）控制器之上添加一个安全层，该层通过随机离散时间CBF公式利用该模型，以概率方式强制执行安全约束。结果是一个微创的安全层，可以添加到现有的自主堆栈中，以提供平衡风险和性能的概率安全保证。在Unitree G1人形机器人上的硬件实验中，SHIELD使用名义（未知）RL控制器和板载感知，使得机器人在各种室内外环境中能够安全导航（避障）。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [912] [User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals](https://arxiv.org/abs/2507.23544)
> *人机交互中通过多实例学习多模态社交信号进行用户体验估计*

*Ryo Miyoshi, Yuki Okafuji, Takuya Iwamoto, Junya Nakanishi, Jun Baba* | **Category: cs.RO, cs.CV, cs.HC** | **Updated: 2025-07-31**

**Keywords:** 用户体验估计, 人机交互, 多模态社交信号, 多实例学习, Transformer

**Comment:** This paper has been accepted for presentation at IEEE/RSJ
  International Conference on Intelligent Robots and Systems 2025 (IROS 2025)

> **TL;DR:** 本文提出一种基于多模态社交信号的多实例学习方法，用于在人机交互中估计用户体验，并优于人类评估员。

**AI_Comments:** 本文的创新点在于结合多模态社交信号（面部表情和声音）与Transformer模型，并通过多实例学习框架有效捕捉用户体验的时间动态，而非仅仅依赖瞬时观察。其超越人类评估员的性能，表明了该方法在自动化用户体验评估方面的巨大潜力，对于提升社交机器人的自适应能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 社交机器人需要根据用户状态调整行为，而准确评估人机交互中的用户体验对实现这种适应性至关重要。现有方法常单独关注用户体验的某个方面。

**Method:** 提出一种利用多模态社交信号的用户体验估计方法。构建了一个用户体验数据集，开发了一个基于Transformer的模型，利用面部表情和声音进行估计。采用多实例学习框架，捕获短期和长期交互模式，从而捕捉用户体验的时间动态。

**Result:** 该方法在用户体验估计方面优于第三方人类评估员。

**Conclusion:** 该研究通过捕获用户体验的时间动态，提供了一种更全面的用户体验表示方法，并实现了超越人类评估员的性能。

> **ai_Abstract:** 本文针对人机交互中用户体验（UX）评估的挑战，提出一种基于多模态社交信号（面部表情和声音）的用户体验估计方法。该方法构建了专用的UX数据集，并开发了一个Transformer模型，结合多实例学习框架以捕捉UX的短期和长期时间动态，从而提供更全面的UX表示。实验证明，该方法在UX估计上表现优于人类评估员。

> **摘要翻译:** 近年来，社会机器人需求增长，要求它们根据用户状态调整行为。在人机交互（HRI）中准确评估用户体验（UX）对于实现这种适应性至关重要。用户体验是一个多方面衡量标准，涵盖情感和参与度等，但现有方法通常单独关注这些方面。本研究提出一种通过利用多模态社交信号来估计人机交互中用户体验的方法。我们构建了一个用户体验数据集，并开发了一个基于Transformer的模型，该模型利用面部表情和声音进行估计。与依赖瞬时观察的传统模型不同，我们的方法使用多实例学习框架捕获短期和长期交互模式。这使得模型能够捕捉用户体验的时间动态，提供更全面的表示。实验结果表明，我们的方法在用户体验估计方面优于第三方人类评估员。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [914] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
> *使用MIGHTY吸盘的人机协作物体运输控制方案*

*Konstantinos Plotas, Emmanouil Papadakis, Drosakis Drosakis, Panos Trahanias, Dimitrios Papageorgiou* | **Category: cs.RO** | **Updated: 2025-08-01**

**Keywords:** 人机协作, 四足机器人, 导纳控制, MIGHTY吸盘, 物体运输

**Comment:** Please find the citation info @ Zenodo, ArXiv or Zenodo, as the
  proceedings of ICRA are no longer sent to IEEE Xplore

> **TL;DR:** 提出了一种基于导纳控制的人机协作四足机器人物体运输方案，通过可变阻尼和势能函数确保控制性和物体不脱落，并实验验证了其被动性。

**AI_Comments:** 该研究提出了一种新颖的人机协作控制方案，结合了导纳控制、可变阻尼和势能函数，有效地解决了协作运输中的控制性和物体保持问题。MIGHTY吸盘的多功能性（抓取和传感）是其创新点之一。

<details>
  <summary>Details</summary>

**Motivation:** 解决人机协作物体运输中的控制问题，旨在提高人类的可控性并减少其努力，同时确保物体在协作过程中不脱落。

**Method:** 提出了一种基于导纳控制的控制方案，该方案包含一个可变阻尼项以提高人类的可控性并减少其努力。此外，为了防止物体从吸盘脱落，引入了一个基于障碍人工势的附加控制信号。该方案被证明是被动的。

**Result:** 通过使用配备MIGHTY吸盘的Unitree Go1机器人进行的实验评估，证明了所提出的控制方案的性能。

**Conclusion:** 所提出的控制方案在人机协作物体运输中表现良好，能够有效提高人类的可控性、减少其努力，并确保物体不脱落。

> **ai_Abstract:** 本文提出了一种用于人机协作物体运输的控制方案，该方案适用于配备MIGHTY吸盘的四足机器人。该方案基于导纳控制，并引入可变阻尼以增强人类控制并减轻其负担。同时，通过障碍人工势信号确保物体不脱落。实验验证了该方案的被动性和有效性。

> **摘要翻译:** 在这项工作中，提出了一种用于人机协作物体运输的控制方案，该方案考虑了一个配备MIGHTY吸盘的四足机器人，该吸盘既用作抓取物体的夹具，也用作力/扭矩传感器。所提出的控制方案基于导纳控制的概念，并结合了一个可变阻尼项，旨在提高人类的可控性，同时减少其努力。此外，为了确保物体在协作过程中不从吸盘脱落，提出了一种基于障碍人工势的附加控制信号。所提出的控制方案被证明是被动的，并通过使用配备MIGHTY吸盘的Unitree Go1机器人进行的实验评估证明了其性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [915] [TopoRec: Point Cloud Recognition Using Topological Data Analysis](https://arxiv.org/abs/2506.18725)
> *TopoRec：使用拓扑数据分析进行点云识别*

*Anirban Ghosh, Iliya Kulbaka, Ian Dahlin, Ayan Dutta* | **Category: cs.RO, cs.CG, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 点云识别, 拓扑数据分析, TopoRec, 局部描述符, 无训练

**Comment:** 

> **TL;DR:** TopoRec是一种利用拓扑数据分析（TDA）进行点云识别的新方法，无需大量训练，在多个数据集上表现优于现有方法。

**AI_Comments:** TopoRec的创新点在于将拓扑数据分析（TDA）引入点云识别领域，提供了一种无需大量机器学习训练的替代方案。这对于资源受限或需要快速适应新环境的应用场景具有重要意义。其优于现有SOTA方法的性能和强大的泛化能力也凸显了TDA在处理点云数据方面的潜力。该方法降低了部署门槛，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 点云识别在自动驾驶、场景重建和定位等应用中仍是一个重要问题。从查询点云中提取有意义的全局描述符并与数据库匹配具有挑战性，尤其是在点云噪声或经过变换（如旋转）时，复杂性会增加。

**Method:** 本文提出了一种名为TopoRec的新方法，利用拓扑数据分析（TDA）从点云中提取局部描述符，从而无需资源密集型基于GPU的机器学习训练。具体来说，使用了ATOL向量化方法为点云生成向量。

**Result:** TopoRec在多个真实世界（如Oxford RobotCar, NCLT）和模拟（如ShapeNet）点云数据集上进行了大规模地点和对象识别测试。与现有的基于学习的方法（如PointNetVLAD和PCAN）以及手工制作的基线（如M2DP, ScanContext）相比，TopoRec无需大量训练，但始终表现出更高的准确性和强大的泛化能力。

**Conclusion:** TopoRec是一种新颖、高效的点云识别方法，它利用拓扑数据分析提取局部描述符，避免了复杂的机器学习训练，并在多个基准数据集上展现出卓越的性能和泛化能力，优于现有最先进的方法。

> **ai_Abstract:** 本文提出了一种名为TopoRec的新型点云识别方法，该方法利用拓扑数据分析（TDA）提取局部描述符，旨在解决传统方法在噪声和变换点云下的挑战，并避免了资源密集型的机器学习训练。通过使用ATOL向量化，TopoRec在多个真实世界和模拟数据集上进行了大规模地点和对象识别测试，结果显示其性能优于现有的基于学习和手工制作的基线方法，展现了卓越的准确性和强大的泛化能力，且无需大量训练。

> **摘要翻译:** 基于点云的对象/地点识别在自动驾驶、场景重建和定位等应用中仍然是一个备受关注的问题。从查询点云中提取有意义的全局描述符，并将其与数据库点云的描述符进行匹配，是一个具有挑战性的问题。此外，当查询点云存在噪声或经过变换（例如旋转）时，会增加其复杂性。为此，我们提出了一种名为TopoRec的新颖方法，该方法利用拓扑数据分析（TDA）从点云中提取局部描述符，从而无需资源密集型的基于GPU的机器学习训练。更具体地说，我们使用ATOL向量化方法为点云生成向量。为了测试所提出的TopoRec技术的质量，我们将其应用于多个真实世界（例如Oxford RobotCar、NCLT）和逼真（例如ShapeNet）的点云数据集，分别用于大规模地点和对象识别。与现有基于学习的方法（如PointNetVLAD和PCAN）不同，我们的方法不需要大量的训练，使其易于适应新环境。尽管如此，它在标准基准数据集上始终优于最先进的基于学习和手工制作的基线（例如M2DP、ScanContext），展示了卓越的准确性和强大的泛化能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cssc'></a>
## cs.SC 

### [603] [A Variant of Non-uniform Cylindrical Algebraic Decomposition for Real Quantifier Elimination](https://arxiv.org/abs/2508.00505)
> *一种用于实数变量消除的非均匀柱形代数分解变体*

*Jasper Nalbach, Erika Ábrahám* | **Category: cs.SC** | **Updated: 2025-08-01**

**Keywords:** 柱形代数分解, 非均匀CAD, 变量消除, SMT求解, 复杂度

**Comment:** 

> **TL;DR:** 提出并实现了一种新的非均匀柱形代数分解（NuCAD）变体，用于实数变量消除和SMT求解，并与CAlC进行了实验比较。

**AI_Comments:** 这项工作通过提供NuCAD的完整实现及其在SMT求解中的应用，填补了现有研究的空白，并有望改善实代数问题的求解效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的柱形代数分解（CAD）方法复杂度高（双指数），而之前的非均匀CAD（NuCAD）设计仅用于变量消除且没有完整的实现。

**Method:** 本文提出了一种新的非均匀柱形代数分解（NuCAD）变体，用于实数变量消除和SMT求解，并提供了实现，通过实验与CAlC进行了比较评估。

**Result:** 论文提供了该方法的实现，并通过实验将其与CAlC进行了比较评估。具体实验结果未在摘要中提及。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文针对现有的柱形代数分解（CAD）方法双指数复杂性问题，提出了一种新型的非均匀柱形代数分解（NuCAD）变体。该变体不仅适用于实数变量消除，还可用于SMT求解，弥补了之前NuCAD缺乏完整实现的不足。研究者提供了该方法的实现，并通过实验将其与CAlC进行了对比评估。

> **摘要翻译:** 柱形代数分解（CAD）方法是目前实践中用于解决实代数问题的唯一完整算法。为了改善其双指数复杂性，不同的探索引导适应性方法试图避免一些计算。第一个此类适应性方法名为NLSAT，随后是非均匀CAD（NuCAD）和柱形代数覆盖（CAlC）。NLSAT和CAlC都已在SMT求解器中开发和实现，用于可满足性检查，并且CAlC最近也适用于变量消除。然而，NuCAD仅为变量消除而设计，在此工作之前没有完整的实现。在本文中，我们提出了一种新的NuCAD变体，用于实数变量消除和SMT求解，并提供了实现，通过实验将其与CAlC进行了比较评估。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

### [631] [Projective Delineability for Single Cell Construction](https://arxiv.org/abs/2508.00512)
> *投影可描绘性在单细胞构建中的应用*

*Jasper Nalbach, Lucas Michel, Erika Ábrahám, Christopher W. Brown, James H. Davenport, Matthew England, Pierre Mathonet, Naïm Zénaïdi* | **Category: cs.SC** | **Updated: 2025-08-01**

**Keywords:** 投影可描绘性, 单细胞构建, 柱形代数分解, 量词消除, 计算复杂度

**Comment:** 

> **TL;DR:** 本文介绍了如何修改单细胞构建方法以利用投影可描绘性，从而可能减少计算量，并报告了实验结果。

**AI_Comments:** 本文的创新点在于引入并应用了“投影可描绘性”这一新概念，以优化基于CAD的算法中的单细胞构建过程。这对于改进CAD这种高复杂度但关键的计算方法具有重要意义，可能为实代数问题的求解带来更高的效率。其重要性在于，即使是启发式的改进，也能显著影响实际应用的性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管柱形代数分解（CAD）具有双指数复杂性，但它是解决实代数相关问题（如量词消除或SMT求解）的唯一完整实践方法。最近的探索引导算法（如NLSAT、NuCAD和CAlC）依赖于CAD技术，但启发式地减少了计算量。单细胞构建是这些算法中使用的范式。本文的动机是利用一种较弱但可能计算量更少的“投影可描绘性”概念来改进单细胞构建，以期提高效率。

**Method:** 本文修改了单细胞构建方法，以利用新引入的“投影可描绘性”概念。

**Result:** 本文报告了利用投影可描绘性改进单细胞构建的实验结果。

**Conclusion:** 通过将单细胞构建适应于利用投影可描绘性，可以减少计算量，这通过实验结果得到了验证。

> **ai_Abstract:** 柱形代数分解（CAD）是解决实代数问题的核心方法，但计算成本高昂。尽管NlSAT等启发式算法试图降低其复杂度，但它们仍依赖于单细胞构建范式。本文引入了一种较弱的“投影可描绘性”概念，该概念可能减少计算需求。研究主要通过调整单细胞构建方法来利用这种投影可描绘性，并通过实验结果验证其效果。

> **摘要翻译:** 柱形代数分解（CAD）是实践中用于解决与实代数相关的量词消除或SMT求解等问题的唯一完整方法，尽管其复杂度是双指数级的。最近的探索引导算法，如NLSAT、NuCAD和CAlC，依赖于CAD技术，但启发式地减少了计算量。单细胞构建是这些算法中使用的范式。
CAD算法所基于的核心属性称为可描绘性。最近，我们引入了一个较弱的概念，称为投影可描绘性，它可能需要较少的计算量来保证，但需要谨慎应用。本文调整了单细胞构建以利用投影可描绘性，并报告了实验结果。

</details>

[⬆️ 返回分类顶部](#cssc) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [184] ["I made this (sort of)": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation](https://arxiv.org/abs/2507.23365)
> *“我制作了这个（某种程度上）”: 通过基于提示的AI音乐生成协商作者身份、对抗欺诈并探索新的音乐空间*

*Bob L. T. Sturm* | **Category: cs.SD, cs.AI, eess.AS, I.2; J.5** | **Updated: 2025-07-31**

**Keywords:** AI音乐生成, 作者身份, 大型语言模型, 音乐创作, 自我反思

**Comment:** 

> **TL;DR:** 作者通过基于提示的AI音乐平台创作了两张专辑，并反思了作者身份、AI能力以及新的音乐空间。

**AI_Comments:** 这篇论文通过作者的亲身实践，深入探讨了AI音乐生成领域中关于作者身份、创造力归属以及人机协作的哲学和实践问题。其创新之处在于将大型语言模型（LLM）不仅作为创作工具，更作为一种自我反思和探索深层问题的媒介，通过LLM介导的自我访谈来剖析作者在AI时代的角色和身份转变。这为理解人类在AI驱动的创意过程中的定位提供了独特的视角和思考。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是探索当作者的个人内容（如垃圾邮件）与先进的AI音乐生成平台结合时会发生什么，以及这些AI平台在生成非“专业化”音乐方面的局限性。同时，作者也旨在深入反思在AI参与创作的背景下，作者身份、个人音乐身份的变化以及AI所开启的新音乐空间等深层问题。

**Method:** 作者通过以下方法进行研究：1. 使用最先进的基于提示的AI音乐生成平台创作了两张音乐专辑，其中一张专辑探索将垃圾邮件与平台结合，另一张则回应了第一张，并尝试挑战AI生成“专业化”音乐的局限性。2. 将有关这些专辑的信息输入到一个大型语言模型（LLM）中，并让LLM对作者进行采访，以此来探索更深层次的问题。3. 论文最后反思了LLM介导的自我反思作为一种研究方法。

**Result:** 研究结果探讨了在AI辅助创作中作者的作者身份程度、作者在生成音乐中的位置、作者音乐身份在面对比自己更有才华的机器时的变化，以及工作为作者或其他人/事物开启的新音乐空间。

**Conclusion:** 论文通过反思作者的创作经历以及大型语言模型（LLM）介导的自我反思作为一种研究方法，得出了其结论。

> **ai_Abstract:** 本文作者通过亲身实践，使用基于提示的AI音乐生成平台创作了两张专辑，以探讨AI辅助创作中的作者身份、AI生成音乐的局限性以及个人音乐身份的转变。作者进一步利用大型语言模型对自身进行访谈，深入剖析了“我”在AI生成音乐中的角色、AI能力对人类创作者的影响，以及由此开辟的新音乐创作空间。文章最终反思了这种以LLM为媒介的自我反思方法。

> **摘要翻译:** 我反思了自己使用最先进的基于提示的AI音乐生成平台创作两张音乐专辑的经历。第一张专辑明确提出了一个问题：当我的垃圾邮件与这些平台碰撞时会发生什么？第二张专辑是对第一张的直接回应，并探讨了最先进的基于提示的AI音乐生成平台无法生成“经过练习”、“精雕细琢”和“制作精良”的音乐的能力。我将有关这些专辑的信息输入到一个大型语言模型（LLM）中，并让它采访我，这导致了对几个更深层次问题的探索：我在多大程度上是作者？我在由此产生的音乐中处于何种位置？当面对在某些方面比我更有才华的机器时，我的音乐身份如何变化？我的作品为我或任何其他人/事物开启了哪些新的音乐空间？最后，我反思了我的反思，以及LLM介导的自我反思作为一种方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [438] [AudioGen-Omni: A Unified Multimodal Diffusion Transformer for Video-Synchronized Audio, Speech, and Song Generation](https://arxiv.org/abs/2508.00733)
> *AudioGen-Omni：一种用于视频同步音频、语音和歌曲生成的统一多模态扩散Transformer*

*Le Wang, Jun Wang, Feng Deng, Chen Zhang, Kun Gai, Di Zhang* | **Category: cs.SD, cs.CV, cs.MM, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 多模态扩散Transformer, 视频同步音频, 语音生成, 歌曲生成, 联合训练

**Comment:** 12 pages, 2 figures

> **TL;DR:** AudioGen-Omni提出了一种基于多模态扩散Transformer的统一方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲，并在效率和通用性方面有显著提升。

**AI_Comments:** 该论文的创新之处在于提出了一个统一的多模态扩散Transformer框架，能够处理视频同步的音频、语音和歌曲生成，这在多模态生成领域是一个复杂且重要的任务。其独特的联合训练范式，整合了大规模多模态语料，并通过解冻所有模态和引入PAAPI等技术，有效解决了跨模态条件生成和对齐的挑战。实现SOTA性能和显著提高的推理效率，表明了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在开发一种统一的方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲，克服传统文本冻结范式的语义限制，并提高生成效率和通用性。

**Method:** AudioGen-Omni采用了一种基于多模态扩散Transformer（MMDit）的统一方法。它引入了一种新颖的联合训练范式，无缝整合大规模视频-文本-音频语料库。模型使用统一的歌词-转录编码器，将演唱和口语输入中的字素和音素编码为密集帧级表示。这些表示通过基于AdaLN的联合注意力机制融合，该机制通过相位对齐各向异性位置注入（PAAPI）增强，并选择性地将RoPE应用于时间结构模态以确保精确的跨模态对齐。通过解冻所有模态并掩盖缺失输入，模型有效实现了跨模态条件生成。

**Result:** AudioGen-Omni在视频同步音频、语音和歌曲生成方面实现了高保真度。该方法增强了音频质量、语义对齐和唇形同步准确性，并在文本到音频/语音/歌曲任务上取得了最先进（SOTA）的结果。对于8秒的音频，推理时间为1.91秒，显著提高了效率和通用性。

**Conclusion:** AudioGen-Omni作为一种统一的多模态扩散Transformer，通过其创新的联合训练范式和架构设计，成功实现了高保真、视频同步的音频、语音和歌曲生成，并在效率和性能上达到了领先水平。

> **ai_Abstract:** AudioGen-Omni是一种统一的多模态扩散Transformer，能够生成与输入视频同步的高保真音频、语音和歌曲。它引入了新颖的联合训练范式，整合大规模视频-文本-音频语料库，并采用统一的歌词-转录编码器和增强的基于AdaLN的联合注意力机制进行跨模态融合。通过解冻所有模态并掩盖缺失输入，该模型克服了传统限制，显著提升了音频质量、语义对齐和唇形同步准确性，在相关任务上取得了最先进的结果，并在效率和通用性方面表现出色。

> **摘要翻译:** 我们提出了 AudioGen-Omni——一种基于多模态扩散 Transformer (MMDit) 的统一方法，能够生成与输入视频连贯同步的高保真音频、语音和歌曲。AudioGen-Omni 引入了一种新颖的联合训练范式，无缝整合了大规模视频-文本-音频语料库，使模型能够生成语义丰富、声学多样化的音频，并以多模态输入为条件，适应广泛的音频生成任务。AudioGen-Omni 采用了一个统一的歌词-转录编码器，将来自演唱和口语输入的字素和音素编码为密集的帧级表示。这些密集的帧级表示通过基于 AdaLN 的联合注意力机制融合，该机制通过相位对齐各向异性位置注入 (PAAPI) 增强，其中 RoPE 被选择性地应用于时间结构模态，以确保精确和鲁棒的跨模态对齐。通过解冻所有模态并掩盖缺失输入，AudioGen-Omni 减轻了文本冻结范式的语义约束，实现了有效的跨模态条件生成。这种联合训练方法提高了音频质量、语义对齐和唇形同步准确性，同时在文本到音频/语音/歌曲任务上取得了最先进的结果。对于 8 秒的音频，其推理时间为 1.91 秒，在效率和通用性方面都提供了显著改进。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [690] [Advancing Speech Quality Assessment Through Scientific Challenges and Open-source Activities](https://arxiv.org/abs/2508.00317)
> *通过科学挑战和开源活动推进语音质量评估*

*Wen-Chin Huang* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 语音质量评估, 科学挑战, 开源活动, 生成式AI, 语音技术

**Comment:** APSIPA ASC 2025 perspective paper

> **TL;DR:** 随着生成式AI的兴起，准确的语音质量评估（SQA）变得日益重要。本文回顾了近期推动SQA发展的科学挑战和开源活动，并强调了维持这些活动对SQA和生成式AI发展的重要性。

**AI_Comments:** 这篇论文强调了科学挑战和开源活动在推动语音质量评估（SQA）领域发展中的关键作用，并将其与当前生成式AI的兴起紧密联系起来。其创新点在于将这些社区驱动的活动视为领域进步的催化剂，而不仅仅是技术本身的迭代。该研究的重要性在于呼吁持续投入资源和精力维护这些开放性生态，这对整个语音技术生态系统，尤其是生成式AI的发展具有长远意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI的蓬勃发展，开发能够准确反映人类感知的自动化语音质量评估（SQA）方法变得越来越重要。

**Method:** 本文回顾了近期在语音质量评估（SQA）领域的科学挑战、开源实现和工具包。

**Result:** Not mentioned in abstract

**Conclusion:** 科学挑战和开源活动对语音质量评估（SQA）领域的发展起到了刺激作用，并且维持这些活动对于SQA本身以及语音生成AI的发展至关重要。

> **ai_Abstract:** 本文探讨了在生成式AI时代，开发准确的语音质量评估（SQA）方法的重要性。作者认为，近期的科学挑战和开源活动显著推动了SQA领域的发展。文章回顾了这些挑战、开源实现和工具包，并强调了持续开展此类活动对于促进SQA和语音生成AI进步的关键作用。

> **摘要翻译:** 语音质量评估（SQA）是指对语音质量的评价，为了跟上生成式AI的蓬勃发展，开发一种准确反映人类感知的自动SQA方法变得越来越重要。近年来，SQA已取得进展，研究人员开始在研究论文中可靠地使用自动SQA作为语音生成系统优劣的严格衡量标准。我们相信，近期的科学挑战和开源活动刺激了该领域的发展。在本文中，我们回顾了SQA的近期挑战以及开源实现和工具包，并强调了保持此类活动的重要性，以促进SQA本身以及语音生成AI的发展。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [855] [SwitchCodec: A High-Fidelity Nerual Audio Codec With Sparse Quantization](https://arxiv.org/abs/2505.24437)
> *SwitchCodec: 一种具有稀疏量化的高保真神经音频编解码器*

*Jin Wang, Wenbin Jiang, Xiangbo Wang, Yubo You, Sheng Fang* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 神经音频压缩, 残差专家向量量化, 高保真, 低比特率, 稀疏量化

**Comment:** 12 pages,8 figures

> **TL;DR:** SwitchCodec提出了一种新的神经音频编解码器，通过残差专家向量量化和多层判别器来提高低比特率下的音频质量和效率，实现了高保真压缩并显著减少了训练时间。

**AI_Comments:** 该论文的创新点在于提出了残差专家向量量化（REVQ）来解决低比特率下嵌入空间受限的问题，并结合了负载均衡策略和多层判别器以优化频谱生成。其高效的训练后策略在保持性能的同时显著减少了训练时间，这一点具有重要的实际意义，提升了模型训练效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有神经音频压缩方法在有限比特率下性能显著下降，因为可用的嵌入空间受到严重限制。

**Method:** 提出了一种通用的高保真神经音频压缩算法，特点是残差专家向量量化（REVQ）以扩展嵌入空间；引入了温和的负载均衡策略以充分利用扩展空间；开发了一种新颖的多层判别器，周期性地分层STFT频谱，引导生成器关注关键频谱区域；采用高效的训练后策略以支持多比特率且不损失低端质量。

**Result:** 在2.67 kbps带宽下，PESQ和ViSQOL分数分别为2.87和4.27。有效减少了频谱模糊，使与原始mel-频谱图的距离减少了13%。训练后策略实现了与专用固定比特率模型相当的性能，同时将所需训练时间减少了一半。

**Conclusion:** SwitchCodec通过其创新的残差专家向量量化、负载均衡和多层判别器设计，显著提高了神经音频压缩在低比特率下的高保真度，并且其高效的训练后策略在保持性能的同时减少了训练时间。

> **ai_Abstract:** SwitchCodec提出了一种解决低比特率下神经音频压缩性能下降问题的高保真算法。该方法通过引入残差专家向量量化（REVQ）来扩展嵌入空间，并结合负载均衡策略确保空间利用率。此外，设计了一种多层判别器来引导频谱生成，并通过高效的训练后策略支持多比特率。实验结果表明，SwitchCodec在低比特率下实现了优异的音频质量，显著减少了频谱模糊，并且其训练后策略能将训练时间减半，同时保持与固定比特率模型相当的性能。

> **摘要翻译:** 神经音频压缩已成为一种有前途的技术，可有效表示语音、音乐和通用音频。然而，现有方法在有限比特率下表现出显著的性能下降，因为可用的嵌入空间受到严重限制。为了解决这个问题，我们提出了一种通用的高保真神经音频压缩算法，其特点是残差专家向量量化（REVQ），这大大扩展了嵌入空间，同时对带宽的影响最小。引入了一种温和的负载均衡策略，以确保充分利用这个扩展空间。此外，我们开发了一种新颖的多层判别器，周期性地分层STFT频谱，引导生成器关注关键频谱区域。为了在不降低低端质量的情况下支持多比特率，我们采用了一种高效的训练后策略。我们提出的模型取得了令人印象深刻的性能，在2.67 kbps带宽下，PESQ和ViSQOL分数分别为2.87和4.27。该方法有效减少了频谱模糊，使与原始mel-频谱图的距离减少了13%。值得注意的是，我们的训练后策略实现了与专用固定比特率模型相当的性能，同时将所需训练时间减少了一半。广泛的消融研究证实了我们方法优于基线。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [883] [Improving Code Switching with Supervised Fine Tuning and GELU Adapters](https://arxiv.org/abs/2506.00291)
> *改进代码转换：监督微调与GELU适配器*

*Linh Pham* | **Category: cs.SD, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 代码转换, ASR, Whisper, 切换分词器, GELU适配器

**Comment:** Incorrect results

> **TL;DR:** 本文通过监督微调和GELU适配器，利用Whisper模型和“切换分词器方法”改进了代码转换ASR，并在多个数据集上显著降低了混合错误率，超越了现有最先进方法。

**AI_Comments:** 该论文通过创造性地利用现有单语模型（Whisper）和数据，通过“切换分词器方法”和GELU适配器，为代码转换ASR引入了一种创新方法，这在代码转换数据集稀缺的情况下至关重要。其超越SoTA方法的表现突显了其实用重要性。

<details>
  <summary>Details</summary>

**Motivation:** 当前代码转换数据集稀少，ASR需要新的方法来有效利用大量现有的单语数据和模型。

**Method:** 本文使用OpenAI的开源ASR模型Whisper。方法分为两部分：第一部分提出“切换分词器方法”，利用Whisper的单语能力单独分词训练文本；第二部分将“切换分词器方法”与在编码器上训练的GELU适配器结合。

**Result:** 提出的两种方法将ASCEND数据集的总混合错误率（MER）降低到9.4%，SEAME devman为6%，SEAME devsge为9.7%，均优于当前最先进方法。

**Conclusion:** 结合“切换分词器方法”和GELU适配器能显著提高代码转换ASR的性能，超越了当前最先进的方法。

> **ai_Abstract:** 本文针对代码转换数据集稀缺的问题，提出了一种利用OpenAI Whisper模型的ASR新方法。该方法引入了“切换分词器方法”以利用Whisper的单语能力提高转录准确性，并进一步结合了基于GELU的适配器。这种组合策略显著降低了ASCEND（9.4%）、SEAME devman（6%）和SEAME devsge（9.7%）数据集上的总混合错误率（MER），超越了现有最先进的代码转换ASR方法。

> **摘要翻译:** 当前代码转换数据集（无论是带标签还是不带标签的）都非常稀少。因此，ASR需要新的方法来利用现有的大量单语数据和模型。本文使用OpenAI的开源ASR模型Whisper，该模型已在68万小时的音频上进行预训练以执行单语ASR任务。在第一部分中，本文研究了如何利用Whisper的单语能力对训练文本进行单独分词，这种方法称为“切换分词器方法”，从而提高转录准确性。在第二部分中，我们将第一部分的切换分词器方法与在编码器上训练的基于GELU的适配器相结合。这两种方法将ASCEND数据集的总混合错误率（MER）降低到9.4%，SEAME devman为6%，SEAME devsge为9.7%，超越了当前的最先进方法。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [934] [Next Tokens Denoising for Speech Synthesis](https://arxiv.org/abs/2507.22746)
> *用于语音合成的下一令牌去噪*

*Yanqing Liu, Ruiqing Xue, Chong Zhang, Yufei Liu, Gang Wang, Bohan Li, Yao Qian, Lei He, Shujie Liu, Sheng Zhao* | **Category: cs.SD, cs.CL, eess.AS** | **Updated: 2025-08-01**

**Keywords:** 语音合成, 自回归模型, 扩散模型, 流匹配, Dragon-FM

**Comment:** 

> **TL;DR:** Dragon-FM是一种结合了自回归和流匹配的新型文本到语音模型，通过分块处理和混合AR与流匹配，解决了传统AR模型速度慢和扩散模型缓存问题，能高效生成高质量长音频。

**AI_Comments:** 该论文提出了一种创新的方法Dragon-FM，通过结合自回归（AR）模型和流匹配（Flow-Matching）的优点，有效解决了现有生成模型在语音合成中的局限性。其核心创新在于分块处理、跨块AR建模与块内并行流匹配的结合，以及连接连续与离散特征建模的能力。这使得模型在保证全局连贯性的同时，实现了快速生成，并能高效处理长篇音频内容，尤其是在零样本播客生成方面展现出潜力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 自回归（AR）模型依赖因果注意力，无法利用未来上下文，且生成速度慢。扩散模型则在键值（KV）缓存方面存在困难。

**Method:** 本文提出了Dragon-FM，一种结合了自回归和流匹配的新型文本到语音（TTS）设计。该模型以每秒12.5个令牌的紧凑速率分块处理48 kHz音频编解码器令牌。这种设计使得跨块的AR建模能够确保全局一致性，而块内并行流匹配则促进了快速迭代去噪。模型利用跨块的KV缓存，并在每个块内利用双向上下文。此外，它还连接了连续和离散特征建模，证明连续AR流匹配可以预测具有有限标量量化器的离散令牌。

**Result:** 在播客数据集上的实验表明，Dragon-FM能够高效生成高质量的零样本播客。

**Conclusion:** Dragon-FM通过结合自回归和流匹配，并采用高效的编解码器和快速分块自回归架构，有效解决了现有模型的局限性，能够高效生成高质量的长篇内容。

> **ai_Abstract:** Dragon-FM是一种新型文本到语音模型，旨在克服传统自回归（AR）模型速度慢和扩散模型键值缓存困难的局限性。它通过结合AR和流匹配，以分块方式处理48 kHz音频编码器令牌，实现跨块的全局一致性AR建模和块内快速迭代去噪的并行流匹配。该模型利用跨块的KV缓存和块内的双向上下文，并能将连续AR流匹配应用于离散令牌预测。其高效的编解码器和快速分块自回归架构使其特别适用于生成高质量的长篇内容，如播客。

> **摘要翻译:** 虽然扩散模型和自回归（AR）模型在生成建模方面取得了显著进展，但它们各自存在明显的局限性。依赖因果注意力的AR模型无法利用未来上下文，并且生成速度慢。相反，扩散模型在键值（KV）缓存方面存在困难。为了克服这些挑战，我们引入了Dragon-FM，这是一种新颖的文本到语音（TTS）设计，它统一了AR和流匹配。该模型以每秒12.5个令牌的紧凑速率分块处理48 kHz音频编解码器令牌。这种设计使得跨块的AR建模能够确保全局一致性，而块内并行流匹配则促进了快速迭代去噪。因此，该模型利用跨块的KV缓存，并在每个块内利用双向上下文。此外，它还连接了连续和离散特征建模，证明连续AR流匹配可以预测具有有限标量量化器的离散令牌。这种高效的编解码器和快速分块自回归架构也使得该模型在生成播客等长篇内容方面非常有效。在播客数据集上的实验证明了其高效生成高质量零样本播客的能力。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [9] [XABPs: Towards eXplainable Autonomous Business Processes](https://arxiv.org/abs/2507.23269)
> *XABPs：迈向可解释的自主业务流程*

*Peter Fettke, Fabiana Fournier, Lior Limonad, Andreas Metzger, Stefanie Rinderle-Ma, Barbara Weber* | **Category: cs.SE, cs.AI, cs.MA** | **Updated: 2025-07-31**

**Keywords:** 自主业务流程, 可解释AI, 业务流程管理, 信任, 问责制

**Comment:** 

> **TL;DR:** 自主业务流程（ABPs）虽有益处，但引发了信任、调试等担忧。本文提出了可解释的自主业务流程（XABPs），通过阐明其原理来解决这些问题，并概述了系统方法和研究挑战。

**AI_Comments:** 该论文解决了AI/ML在业务流程中应用的一个关键新兴问题：自主系统对透明度和问责制的需求。其创新之处在于提出了“可解释的ABPs”（XABPs）框架，以减轻与黑盒AI相关的风险，从而促进信任并简化调试和合规性。这对于弥合AI效率提升与业务治理实际需求之间的差距至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 自主业务流程（ABPs）虽然能提高效率、降低成本，但可能导致利益相关者信任度下降、调试困难、问责受阻、偏见风险以及合规性问题。本文旨在通过提出可解释的ABPs（XABPs），使系统能够阐明其原理，从而解决这些担忧。

**Method:** 本文概述了XABPs的系统方法，包括刻画其形式、构建可解释性结构，并识别了实现XABPs的关键业务流程管理（BPM）研究挑战。

**Result:** Not mentioned in abstract

**Conclusion:** 本文提出可解释的自主业务流程（XABPs）以解决自主业务流程（ABPs）带来的担忧，通过使系统能够阐明其原理，并概述了实现XABPs的系统方法和关键研究挑战。

> **ai_Abstract:** 本文提出了可解释的自主业务流程（XABPs），旨在解决自主业务流程（ABPs）带来的信任、调试和合规性等问题。尽管ABPs能提升效率和降低成本，但XABPs通过使系统能够解释其决策原理来增强其透明度和可信度。文章概述了XABPs的系统方法，包括其形式、可解释性结构，并指出了业务流程管理（BPM）领域实现XABPs的关键研究挑战。

> **摘要翻译:** 自主业务流程（ABPs），即利用 AI/ML 的自执行工作流，有潜力提高运营效率、减少错误、降低成本、缩短响应时间，并使人类员工能够从事更具战略性和创造性的工作。然而，ABPs 可能会引发特定担忧，包括利益相关者信任度下降、调试困难、问责受阻、偏见风险以及合规性问题。我们主张采用可解释的 ABPs（XABPs）来解决这些担忧，通过使系统能够阐明其原理。本文概述了 XABPs 的系统方法，描述了其形式，构建了可解释性，并指明了实现 XABPs 的关键 BPM 研究挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [19] [How Quantization Impacts Privacy Risk on LLMs for Code?](https://arxiv.org/abs/2508.00128)
> *量化如何影响代码大语言模型的隐私风险？*

*Md Nazmul Haque, Hua Yang, Zhou Yang, Bowen Xu* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 量化, 隐私风险, 代码大语言模型, 成员推断, 模型压缩

**Comment:** 

> **TL;DR:** 本研究首次实证探究了量化对代码大语言模型（LLMs4Code）任务性能和隐私风险的影响，发现量化能显著降低隐私风险，且任务性能与隐私风险呈正相关，揭示了量化大型模型可能比使用全精度小型模型能更好地平衡性能和隐私。

**AI_Comments:** 这项工作是首次对量化在代码大语言模型中对隐私风险影响的实证研究，具有重要的创新性。它不仅揭示了量化可以作为降低隐私风险的有效手段，还发现了性能与隐私之间的权衡关系，并提出了量化大型模型可能提供更好平衡的见解。这些发现为实际部署中的隐私保护提供了宝贵的指导。

<details>
  <summary>Details</summary>

**Motivation:** 代码大语言模型（LLMs4Code）依赖大量包含敏感数据的训练数据，引发了严重的隐私担忧。成员推断（MI）是评估隐私风险的有效工具。同时，量化等模型压缩技术被用于降低计算成本。然而，量化模型是否影响其保留和暴露隐私信息的能力尚不清楚，回答这个问题对于理解实际部署中的隐私风险至关重要。

**Method:** 本研究对LLMs4Code中量化如何同时影响任务性能和隐私风险进行了首次实证研究。为此，作者对三种代表性模型家族（Pythia、CodeGen和GPTNeo）实施了广泛使用的量化技术（静态和动态）。

**Result:** 结果表明，量化对降低相对于原始模型的隐私风险有显著影响。研究还发现任务性能与隐私风险之间存在正相关关系，表明存在潜在的权衡。此外，研究揭示了量化更大的模型可能比使用全精度小型模型能更好地实现平衡的可能性。

**Conclusion:** 这些发现适用于不同的架构、模型大小和成员推断方法，为部署压缩的LLMs4Code时保护隐私提供了实用指导。

> **ai_Abstract:** 本研究首次实证探究了量化对代码大语言模型（LLMs4Code）任务性能和隐私风险的影响。研究发现，量化能显著降低模型的隐私风险，并且任务性能与隐私风险之间存在正相关关系，表明两者之间存在权衡。此外，研究指出量化大型模型可能比使用全精度小型模型更能有效地平衡性能与隐私。这些发现为在部署压缩的LLMs4Code时保护隐私提供了实用指导。

> **摘要翻译:** 代码大语言模型（LLMs4Code）严重依赖海量的训练数据，其中包括敏感数据，例如项目的云服务凭证和开发者的个人身份信息，这引发了严重的隐私担忧。成员推断（MI）最近已成为评估隐私风险的有效工具，通过识别特定数据是否属于模型的训练集。与此同时，模型压缩技术，尤其是量化，因降低计算成本和实现大型模型部署而受到关注。然而，尽管量化模型仍然保留了从原始训练数据中学到的知识，但量化是否会影响它们保留和暴露隐私信息的能力尚不清楚。回答这个问题对于理解实际部署中的隐私风险至关重要。在这项工作中，我们首次对量化如何同时影响LLMs4Code中的任务性能和隐私风险进行了实证研究。为此，我们对三个代表性模型家族，即Pythia、CodeGen和GPTNeo，实施了广泛使用的量化技术（静态和动态）。我们的结果表明，相对于原始模型，量化对降低隐私风险有显著影响。我们还发现任务性能与隐私风险之间存在正相关关系，表明存在潜在的权衡。此外，我们揭示了量化更大的模型可能比使用全精度小型模型能产生更好平衡的可能性。最后，我们证明这些发现适用于不同的架构、模型大小和MI方法，为部署压缩的LLMs4Code时保护隐私提供了实用指导。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [54] [Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems](https://arxiv.org/abs/2508.00198)
> *测试不可测试之物？一项关于LLM驱动软件系统测试过程的实证研究*

*Cleyton Magalhaes, Italo Santos, Brody Stuart-Verner, Ronnie de Souza Santos* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** LLM系统测试, 实证研究, 软件工程, 验证方法, 测试策略

**Comment:** 

> **TL;DR:** 本研究探讨了LLM驱动系统在实际应用开发中的测试方式，发现测试结合了手动和自动化方法，并面临集成失败、输出不可预测等挑战，需要对传统验证方法进行调整。

**AI_Comments:** 该论文解决了LLM驱动系统测试这一新兴且重要的问题，填补了该领域研究的空白。其采用的实证研究方法，通过分析真实的学生项目报告，提供了关于实际测试挑战和实践的宝贵见解。研究结果对于指导未来LLM系统测试工具和方法的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管许多研究关注LLM如何支持代码生成、调试和文档等任务，但很少有研究关注如何测试集成LLM的完整系统在开发过程中的测试方式。本研究旨在探索LLM驱动系统在实际应用开发中的测试方式。

**Method:** 本研究采用探索性案例研究，分析了99份由学生撰写的报告。这些学生作为大学课程的一部分，构建并部署了LLM驱动的应用程序。每份报告都通过专题分析独立进行分析，并辅以结构化编码过程。

**Result:** 测试策略结合了手动和自动化方法，以评估系统逻辑和模型行为。常见的实践包括探索性测试、单元测试和提示迭代。报告的挑战包括集成失败、不可预测的输出、提示敏感性、幻觉以及对正确性的不确定性。

**Conclusion:** 测试LLM驱动系统需要对传统的验证方法进行调整，将源级推理与行为感知评估相结合。这些发现为软件系统中生成组件的测试提供了实践背景的证据。

> **ai_Abstract:** 本研究通过对99份学生项目报告的案例分析，探讨了LLM驱动软件系统的测试过程。研究发现，测试策略结合了手动和自动化方法，涵盖系统逻辑和模型行为评估，并采用了探索性测试、单元测试和提示迭代等实践。同时，研究也揭示了集成失败、输出不可预测、提示敏感性、幻觉和正确性不确定性等挑战。结论强调，测试LLM驱动系统需要调整传统的验证方法，融合源级推理和行为感知评估。

> **摘要翻译:** 背景：大型语言模型驱动的软件系统正在成为日常技术的常规部分，支持广泛领域的应用。在软件工程中，许多研究都集中在LLM如何支持代码生成、调试和文档等任务。然而，关于如何测试集成LLM的完整系统在开发过程中的关注有限。目的：本研究探讨了LLM驱动系统在实际应用开发中的测试方式。方法：我们进行了一项探索性案例研究，使用了99份由学生撰写的独立报告，这些学生作为大学课程的一部分构建并部署了LLM驱动的应用程序。每份报告都通过专题分析独立进行分析，并辅以结构化编码过程。结果：测试策略结合了手动和自动化方法，以评估系统逻辑和模型行为。常见的实践包括探索性测试、单元测试和提示迭代。报告的挑战包括集成失败、不可预测的输出、提示敏感性、幻觉以及对正确性的不确定性。结论：测试LLM驱动系统需要对传统的验证方法进行调整，将源级推理与行为感知评估相结合。这些发现为软件系统中生成组件的测试提供了实践背景的证据。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [82] [Leveraging Large Language Model for Information Retrieval-based Bug Localization](https://arxiv.org/abs/2508.00253)
> *利用大型语言模型进行信息检索式缺陷定位*

*Moumita Asad, Rafed Muhammad Yasir, Armin Geramirad, Sam Malek* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 缺陷定位, 信息检索, 词汇不匹配, GenLoc

**Comment:** 

> **TL;DR:** 提出了一种名为GenLoc的基于大型语言模型的缺陷定位方法，通过克服词汇不匹配问题，显著提升了缺陷定位的准确性，超越了现有最先进技术。

**AI_Comments:** 该论文创新性地将大型语言模型应用于信息检索式缺陷定位，有效解决了现有方法中普遍存在的词汇不匹配问题。通过结合代码探索功能和可选的语义检索，GenLoc显著提升了缺陷定位的准确性，为软件维护和调试领域提供了新的高效工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有信息检索式缺陷定位方法（包括向量空间模型和深度学习模型）的有效性常受限于缺陷报告与源代码之间的词汇不匹配问题。

**Method:** 提出了一种名为GenLoc的基于大型语言模型（LLM）的缺陷定位方法。GenLoc利用配备代码探索功能的LLM迭代分析代码库以识别潜在的缺陷文件。为了获取更好的上下文，GenLoc还可以选择性地使用向量嵌入检索语义相关文件。

**Result:** GenLoc在来自六个大型Java项目的9000多个真实缺陷报告上进行了评估。实验结果表明，GenLoc在多项指标上优于五种最先进的缺陷定位技术，在Accuracy@1上平均提高了60%以上。

**Conclusion:** GenLoc通过利用大型语言模型有效解决了信息检索式缺陷定位中的词汇不匹配问题，并显著提升了缺陷定位的准确性。

> **ai_Abstract:** 该论文提出了一种名为GenLoc的新型信息检索式缺陷定位方法，旨在解决现有方法中缺陷报告与源代码之间的词汇不匹配问题。GenLoc利用大型语言模型（LLM）结合代码探索功能迭代分析代码库，并可选地使用向量嵌入进行语义相关文件检索。在对9000多个真实缺陷报告的评估中，GenLoc在Accuracy@1上实现了超过60%的平均提升，显著优于五种最先进的缺陷定位技术。

> **摘要翻译:** 信息检索式缺陷定位旨在为给定的缺陷报告识别有缺陷的源文件。尽管现有方法——从向量空间模型到深度学习模型——在该领域已显示出潜力，但它们的有效性常常受限于缺陷报告和源代码之间的词汇不匹配问题。为了解决这个问题，我们提出了一种新颖的基于大型语言模型（LLM）的缺陷定位方法，名为GenLoc。给定一个缺陷报告，GenLoc利用配备代码探索功能的LLM迭代分析代码库并识别潜在的缺陷文件。为了收集更好的上下文，GenLoc可以选择性地使用向量嵌入检索语义相关文件。GenLoc已在来自六个大型Java项目的9000多个真实缺陷报告上进行了评估。实验结果表明，GenLoc在多项指标上优于五种最先进的缺陷定位技术，在Accuracy@1上平均提高了60%以上。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [110] [Accurate and Consistent Graph Model Generation from Text with Large Language Models](https://arxiv.org/abs/2508.00255)
> *使用大型语言模型从文本中准确且一致地生成图模型*

*Boqi Chen, Ou Wei, Bingzhou Zheng, Gunter Mussbacher* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 图模型生成, 大型语言模型, 一致性, 准确性, 抽象-具体化

**Comment:** Accepted at ACM / IEEE 28th International Conference on Model Driven
  Engineering Languages and Systems (MODELS 2025)

> **TL;DR:** 大型语言模型在从文本生成图模型时存在语法、约束和准确性问题，本文提出了一种新颖的抽象-具体化框架，通过聚合多个LLM输出，显著提高了生成图模型的一致性和质量。

**AI_Comments:** 该论文的创新点在于提出了一个抽象-具体化框架，通过聚合LLM的多个输出来解决图模型生成中的一致性和准确性问题，这是一种新颖且有效的策略，超越了仅仅解决语法问题的现有方法。其重要性在于提升了LLM在软件工程等领域生成高质量图模型的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于大型语言模型（LLM）的图模型生成方法通常产生部分正确的模型，存在三个主要问题：语法违规、约束不一致和不准确性（幻觉元素）。虽然语法问题可以通过约束解码或过滤解决，但后两个问题（约束不一致和不准确性）仍未得到充分解决。

**Method:** 本文受LLM中自洽性方法的启发，提出了一种新颖的抽象-具体化框架。该方法通过考虑LLM的多个输出，增强生成图模型的一致性和质量。具体而言，它首先构建一个聚合所有候选输出的概率部分模型，然后将此部分模型细化为满足所有约束的最合适的具体模型。

**Result:** 该框架在多种流行的开源和闭源LLM上，使用不同的数据集进行模型生成任务的评估。结果表明，该方法显著提高了生成图模型的一致性和质量。

**Conclusion:** 本文提出的抽象-具体化框架能够有效解决大型语言模型在图模型生成中存在的约束不一致和不准确性问题，显著提升了生成图模型的一致性和质量。

> **ai_Abstract:** 本文提出了一种新颖的抽象-具体化框架，旨在解决大型语言模型在图模型生成中存在的约束不一致性和不准确性问题。该框架通过聚合LLM的多个候选输出，首先构建一个概率部分模型，然后将其细化为满足所有约束的具体模型。实验结果表明，该方法显著提升了生成图模型的一致性和质量。

> **摘要翻译:** 从自然语言描述生成图模型是一项重要的任务，在软件工程中有许多应用。随着大型语言模型（LLMs）的兴起，使用LLMs进行图模型生成的兴趣日益增长。然而，基于LLM的图模型生成通常会产生部分正确的模型，并存在三个主要问题：（1）语法违规：生成的模型可能不符合其元模型定义的语法；（2）约束不一致：模型的结构可能不符合某些领域特定的约束；（3）不准确性：由于LLMs固有的不确定性，模型可能包含不准确的、幻觉的元素。虽然第一个问题通常通过约束解码或过滤等技术来解决，但后两个问题在很大程度上仍未得到解决。受LLM中近期自洽性方法的启发，我们提出了一种新颖的抽象-具体化框架，通过考虑LLM的多个输出来增强生成图模型的一致性和质量。我们的方法首先构建一个聚合所有候选输出的概率部分模型，然后将此部分模型细化为满足所有约束的最合适的具体模型。我们使用多样化的数据集对多个流行的开源和闭源LLM上的框架进行了评估，以进行模型生成任务。结果表明，我们的方法显著提高了生成图模型的一致性和质量。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [131] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
> *对LLM生成真实世界函数单元测试的基准评估*

*Dong Huang, Jie M. Zhang, Mark Harman, Qianru Zhang, Mingzhe Du, See-Kiong Ng* | **Category: cs.SE, cs.CL** | **Updated: 2025-08-01**

**Keywords:** LLM, 单元测试生成, 基准评估, 数据污染, 真实世界函数

**Comment:** Under Review

> **TL;DR:** 现有LLM单元测试生成基准存在数据污染和代码结构简单的问题，导致评估结果不可靠。本文引入了一个新的、更具挑战性的基准ULT，用于评估LLM在真实世界函数单元测试生成方面的能力，并发现LLM在该基准上表现显著不佳。

**AI_Comments:** 本文的主要创新在于创建了一个更健壮、更真实的基准（ULT），解决了现有数据集中常见的“数据污染”和“简单性”陷阱。这对于准确评估LLM在单元测试生成方面的能力以及指导未来研究至关重要。LLM在ULT上性能的显著下降，凸显了当前LLM在处理真实世界复杂场景的单元测试生成任务时，仍未达到理想水平。

<details>
  <summary>Details</summary>

**Motivation:** 现有的LLM单元测试生成基准存在两个主要缺点：数据污染和结构简单的函数代码。这导致从这些受限基准中得出的科学结论可能不可靠，实证证据可能因污染而产生偏差，并且可能无法推广到玩具程序之外。

**Method:** 本文引入了ULT（UnLeakedTestbench），一个专门为真实世界Python函数的功能级单元测试生成设计的新基准。ULT通过多阶段筛选过程构建，确保高圈复杂度并缓解测试用例污染。此外，还提供了PLT（PreLeakedTestbench），作为ULT的配对基准，用于受控分析测试生成中的记忆与推理。

**Result:** ULT显著更具挑战性。LLM生成的测试用例在准确性、语句覆盖率、分支覆盖率和变异分数上平均仅达到41.32%、45.10%、30.22%和40.21%。这些结果远低于TestEval（91.79%、92.18%、82.04%和49.69%）和PLT（47.07%、55.13%、40.07%和50.80%）上对应的指标。

**Conclusion:** LLM在ULT基准上的低表现表明，当前的LLM在生成复杂、真实世界函数的高质量单元测试方面仍面临重大挑战，并且现有基准可能高估了它们的能力。

> **ai_Abstract:** 本文针对当前LLM单元测试生成基准存在的局限性（数据污染和代码过于简单）提出了解决方案。作者引入了ULT，一个包含3,909个真实世界Python函数的新基准，通过多阶段筛选确保了高圈复杂度和低污染，从而提供更真实、更具挑战性的评估。同时，还引入了PLT用于分析记忆与推理。评估结果显示，LLM在ULT上的表现远低于现有基准，突显了LLM在生成真实世界复杂函数单元测试方面的不足。

> **摘要翻译:** 最近，大型语言模型（LLM）在自动化单元测试生成方面展现出巨大的前景，显著减少了开发人员所需的手动工作。为了有效评估LLM在该领域的能力，拥有一个精心设计、能准确反映真实世界场景并缓解常见缺陷的基准至关重要。现有的LLM测试生成基准受限于两个关键缺点：数据污染和结构简单的函数代码。因此，我们通常无法相信使用这些有限基准进行的实证研究得出的科学结论的有效性。所呈现的实证证据可能因污染而存在偏差，并且由于结构简单而无法推广到玩具程序之外。
为了解决这些问题，我们引入了ULT（UnLeakedTestbench），一个专门为真实世界Python函数的功能级单元测试生成设计的新基准。ULT通过多阶段筛选过程构建，确保高圈复杂度并缓解测试用例污染。ULT包含3,909个精心挑选的功能级任务，为LLM的测试生成能力提供了更真实、更具挑战性的评估。我们还提供了PLT（PreLeakedTestbench），作为ULT的配对基准，包含泄露的测试，旨在实现对测试生成中记忆与推理的受控分析。我们的评估结果表明，ULT显著更具挑战性。例如，LLM生成的测试用例在所有LLM上，其准确性、语句覆盖率、分支覆盖率和变异分数平均仅达到41.32%、45.10%、30.22%和40.21%。这些结果远低于TestEval（91.79%、92.18%、82.04%和49.69%）和PLT（47.07%、55.13%、40.07%和50.80%）上对应的指标。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [143] [CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation](https://arxiv.org/abs/2503.22688)
> *CodeIF-Bench：评估大型语言模型在交互式代码生成中遵循指令的能力*

*Peiding Wang, Li Zhang, Fang Liu, Lin Shi, Minxiao Li, Bo Shen, An Fu* | **Category: cs.SE, cs.AI, cs.PL** | **Updated: 2025-07-31**

**Keywords:** 代码生成, 指令遵循, 大型语言模型, 基准测试, 多轮交互

**Comment:** 

> **TL;DR:** CodeIF-Bench 是一个新基准，用于评估大型语言模型在多轮交互式代码生成中遵循指令的能力。

**AI_Comments:** 该论文通过引入 CodeIF-Bench 基准，填补了现有代码生成评估在多轮交互和指令遵循能力方面的空白，具有重要的创新性。其关注实际开发需求和可验证的指令类型，为更全面地评估大型语言模型在复杂编程场景下的表现提供了新工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有代码生成基准主要评估大型语言模型在单轮交互中生成代码的功能正确性，但对模型在多轮交互场景中严格遵循用户指令的能力洞察有限。

**Method:** 引入了 CodeIF-Bench 基准，包含九种可验证的指令类型，与真实世界软件开发需求对齐，可通过指定测试用例独立客观验证。在“静态对话”和“动态对话”设置下，评估了7个最先进的大型语言模型。

**Result:** 评估了7个最先进的大型语言模型，并总结了影响大型语言模型在多轮交互中遵循指令能力的重要因素以及潜在的改进方向。

**Conclusion:** 本研究通过 CodeIF-Bench 揭示了大型语言模型在多轮交互中遵循指令的能力，并指出了未来改进的方向。

> **ai_Abstract:** 本文介绍了 CodeIF-Bench，一个专门用于评估大型语言模型在多轮交互式代码生成中遵循指令能力的基准。针对现有基准的局限性，CodeIF-Bench 包含了九种与真实开发场景相关的可验证指令类型，并支持独立客观的测试。研究在静态和动态对话设置下评估了七个主流大型语言模型，并分析了影响其指令遵循能力的关键因素及未来的改进方向。

> **摘要翻译:** 大型语言模型 (LLMs) 在代码生成任务中表现出色，并已成为开发人员不可或缺的编程助手。然而，现有代码生成基准主要评估 LLMs 在单轮交互中生成代码的功能正确性。它们对 LLMs 在多轮交互场景中严格遵循用户指令的能力提供了有限的洞察。在本文中，我们引入了 CodeIF-Bench，这是一个用于评估 LLMs 在交互式代码生成中遵循指令能力的基准。具体来说，CodeIF-Bench 包含了九种可验证的指令类型，这些指令与现实世界的软件开发需求对齐，可以通过指定的测试用例进行独立客观的验证，从而促进了多轮交互中指令遵循能力的评估。在“静态对话”和“动态对话”设置下，我们评估了7个最先进的 LLMs 的性能，并总结了影响 LLMs 在多轮交互中遵循指令能力的重要因素，以及潜在的改进方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [156] [Quality Evaluation of COBOL to Java Code Transformation](https://arxiv.org/abs/2507.23356)
> *COBOL到Java代码转换的质量评估*

*Shmulik Froimovich, Raviv Gal, Wesam Ibraheem, Avi Ziv* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-31**

**Keywords:** COBOL到Java转换, 代码质量评估, LLM-as-a-judge, 自动化系统, 代码现代化

**Comment:** Submitted to ASE 2025

> **TL;DR:** 提出一个自动化系统，结合分析检查器和LLM-as-a-judge技术，评估IBM WCA4Z中COBOL到Java的代码转换质量，解决LLM翻译器评估难题并支持大规模基准测试。

**AI_Comments:** 该论文提出了一种创新的评估方法，结合了传统分析工具和新兴的LLM-as-a-judge技术，有效解决了大型语言模型在代码翻译评估中的“黑箱”问题和复杂性。其自动化和可扩展性对于加速遗留代码现代化进程、提高代码转换质量具有重要意义，尤其是在企业级应用中价值显著。

<details>
  <summary>Details</summary>

**Motivation:** 评估基于LLM的翻译器面临模型不透明性和翻译质量评估复杂性等关键挑战，因此需要一个自动化系统来解决这些问题。

**Method:** 该方法结合了分析检查器和LLM-as-a-judge (LaaJ) 技术，以提供可扩展、多方面的评估。

**Result:** 该系统支持持续集成工作流，实现大规模基准测试，并减少对人工审查的依赖。它为开发人员和项目经理提供可操作的见解。

**Conclusion:** 该系统通过提供可操作的见解，促进高质量、现代化代码库的演进，解决了LLM翻译器评估的复杂性。

> **ai_Abstract:** 本文介绍了一个用于评估IBM watsonx Code Assistant for Z (WCA4Z) 中COBOL到Java代码转换的自动化系统。该系统旨在解决基于LLM的翻译器在评估方面的挑战，如模型不透明性和质量评估复杂性。它通过结合分析检查器和LLM-as-a-judge技术，实现了可扩展、多维度的评估，并支持持续集成和大规模基准测试，从而减少了人工审查的需要，并为代码现代化提供了有价值的洞察。

> **摘要翻译:** 我们提出了一个自动化评估系统，用于评估IBM watsonx Code Assistant for Z (WCA4Z) 中COBOL到Java的代码翻译。该系统解决了评估基于LLM的翻译器中的关键挑战，包括模型不透明性和翻译质量评估的复杂性。我们的方法结合了分析检查器和LLM-as-a-judge (LaaJ) 技术，以提供可扩展、多方面的评估。该系统支持持续集成工作流，实现大规模基准测试，并减少对人工审查的依赖。我们描述了系统架构、评估策略和报告机制，这些机制为开发人员和项目经理提供了可操作的见解，促进了高质量、现代化代码库的演进。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [159] [Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory](https://arxiv.org/abs/2508.00462)
> *将权力差距管理作为结对编程技能的一个主题：一项扎根理论研究*

*Linus Ververs, Lutz Prechelt* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 结对编程, 权力差距, 扎根理论, 软件开发, 技能

**Comment:** 

> **TL;DR:** 本研究通过扎根理论和问卷调查，提出了结对编程中“权力差距”现象，并指出避免等级行为和增加平等行为是提升结对编程效果的关键技能。

**AI_Comments:** 这项研究通过引入“权力差距”这一概念，为结对编程中的人际动态提供了一个新颖的视角。采用扎根理论结合大规模调查的方法，使其研究结果具有较强的理论基础和实践普适性。其创新之处在于将权力动态引入结对编程技能的讨论，并提供了具体的行为建议，对于提升软件开发团队协作效率具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解工业界结对编程中与权力相关的现象，并为实践者提供如何更好地进行结对编程的建议。

**Method:** 采用扎根理论方法分析了22个工业结对编程会话，形成了一个关于权力相关行为的扎根理论。随后对292名参与者进行了问卷调查，以证明这些现象的普遍性。

**Result:** 研究提出了“权力差距”现象，即感知到的参与机会差异。该理论揭示了导致权力差距或由其产生的行为。权力差距倾向于损害知识转移、代码质量和过程效率。调查结果显示，理论中的所有概念在实践中都很常见，并为间接可观察的概念提供了更多依据。

**Conclusion:** 避免权力差距是结对编程技能的重要组成部分。结对伙伴需要避免等级行为（倾向于产生或增加权力差距），并应进行足够的平等化行为（防止或减少权力差距）。

> **ai_Abstract:** 本研究旨在理解工业界结对编程中与权力相关的现象并提供实践建议。研究通过分析22个工业结对编程会话，运用扎根理论方法构建了“权力差距”理论，该理论描述了感知到的参与机会差异及其对知识转移、代码质量和过程效率的负面影响。随后，对292名参与者的调查验证了该理论的普遍性。研究得出结论，避免权力差距是结对编程的关键技能，实践者应避免等级行为并增加平等化行为。

> **摘要翻译:** 背景：结对编程作为一种工作模式在专业的软件开发中被（偶尔或频繁地）使用。目标：理解工业界结对编程中出现哪些与权力相关的现象；为实践者提供如何更好地进行结对编程的建议。方法：使用扎根理论方法分析了22个工业结对编程会话。形成了一个关于权力相关行为的扎根理论。对292名参与者进行了关于该理论的问卷调查。用它来证明这些现象是普遍存在的。结果：我们的理论描述了权力差距现象：一种感知到的参与机会差异。该理论展示了产生权力差距或由其产生的行为。权力差距倾向于损害知识转移、代码质量和过程效率。调查结果显示，我们理论中的所有概念在实践中都很常见。它们还为只能间接观察到的概念提供了更多依据。结论：能够避免权力差距是结对编程技能的一个有价值的组成部分。具体来说，结对伙伴需要避免等级行为（倾向于产生或增加权力差距），并且应该进行足够的平等化行为（防止或减少权力差距）。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [187] [SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval](https://arxiv.org/abs/2508.00546)
> *SPENCER：高效代码检索的自适应模型蒸馏*

*Wenchao Gu, Zongyi Lyu, Yanlin Wang, Hongyu Zhang, Cuiyun Gao, Michael R. Lyu* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 代码检索, 模型蒸馏, 双编码器, 交叉编码器, SPENCER

**Comment:** 

> **TL;DR:** SPENCER提出了一种结合双编码器和交叉编码器的框架，并通过自适应模型蒸馏技术显著提高了代码检索的效率和性能。

**AI_Comments:** SPENCER的创新之处在于其结合双编码器和交叉编码器的混合架构，旨在兼顾效率和准确性。更重要的是，其提出的自适应模型蒸馏技术，特别是教学助手选择策略，为模型压缩和加速提供了一种新颖且有效的方法，在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的代码检索方法多采用双编码器以提高检索效率，但其模型结构限制了性能，因为在训练过程中缺乏代码片段和描述之间的底层交互。本文旨在在保持效率的同时提高模型的效果。

**Method:** 本文提出了一个名为SPENCER的框架，它首先使用双编码器缩小搜索空间，然后使用交叉编码器提高准确性。为了提高SPENCER的效率，提出了一种新颖的模型蒸馏技术，可大幅减少双编码器的推理时间。此外，还提出了一种教学助手选择策略，用于在模型蒸馏过程中自适应地选择合适的教学助手模型，以确保模型性能。

**Result:** 实验表明，双编码器和交叉编码器的组合在代码检索方面比单独基于双编码器的模型提高了整体性能。此外，所提出的模型蒸馏技术在将双编码器的推理时间减少70%的同时，保留了超过98%的整体性能。

**Conclusion:** SPENCER通过结合双编码器和交叉编码器以及创新的自适应模型蒸馏技术，成功地在代码检索任务中实现了效率和性能的平衡与提升。

> **ai_Abstract:** 本文针对代码检索任务中双编码器性能受限但效率高的痛点，提出了SPENCER框架。SPENCER结合了双编码器和交叉编码器，先通过双编码器缩小搜索范围，再利用交叉编码器提升精度。为进一步提高效率，SPENCER引入了一种自适应模型蒸馏技术，并辅以教学助手选择策略，以在保持高性能的同时大幅削减双编码器的推理时间。实验证明，该方法显著提升了代码检索的整体性能和效率。

> **摘要翻译:** 代码检索旨在根据用户的自然语言查询提供所需的代码片段。随着深度学习技术的发展，采用预训练模型进行此任务已成为主流。考虑到检索效率，大多数以前的方法都为此任务采用了双编码器，它分别将描述和代码片段编码成表示向量。然而，双编码器的模型结构往往会限制模型的性能，因为它在训练过程中缺乏代码片段和描述在模型底层之间的交互。为了在保持效率的同时提高模型的效果，我们提出了一个名为SPENCER的框架，它采用了高效代码检索的自适应模型蒸馏（Self-AdaPtive Model Distillation for Efficient CodE Retrieval）。SPENCER首先采用双编码器缩小搜索空间，然后采用交叉编码器提高准确性。为了提高SPENCER的效率，我们提出了一种新颖的模型蒸馏技术，可以大大减少双编码器的推理时间，同时保持整体性能。我们还为我们的模型蒸馏提出了一种教学助手选择策略，该策略可以在模型蒸馏过程中自适应地选择适合不同预训练模型的教学助手模型，以确保模型性能。大量的实验表明，与单独基于双编码器的代码检索模型相比，双编码器和交叉编码器的组合提高了整体性能。此外，我们的模型蒸馏技术在将双编码器的推理时间减少70%的同时，保留了超过98%的整体性能。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [212] [Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling](https://arxiv.org/abs/2507.23370)
> *Trae Agent：一种用于软件工程的基于LLM的Agent，具有测试时扩展能力*

*Trae Research Team, Pengfei Gao, Zhao Tian, Xiangxin Meng, Xinchen Wang, Ruida Hu, Yuanan Xiao, Yizhou Liu, Zhao Zhang, Junjie Chen, Cuiyun Gao, Yun Lin, Yingfei Xiong, Chao Peng, Xia Liu* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-31**

**Keywords:** LLM, 软件工程, Agent, 问题解决, SWE-bench

**Comment:** Pengfei Gao and Zhao Tian contributed equally to this technical
  report

> **TL;DR:** Trae Agent是一种基于LLM的Agent，通过模块化Agent解决大型集成空间和仓库级理解问题，在SWE-bench基准测试上实现了软件问题解决的SOTA性能。

**AI_Comments:** Trae Agent的创新之处在于其将软件问题解决视为最优解搜索问题，并通过模块化Agent实现了对大型集成空间和仓库级理解的有效处理，克服了现有方法的局限性。其在SWE-bench上取得的SOTA性能，特别是高Pass@1分数，凸显了其在实际软件工程任务中的巨大潜力。开源发布将极大地促进该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 软件问题解决是软件工程中的一个关键挑战。尽管LLM在解决实际软件工程任务方面取得了进展，但现有的基于提示的方法在有效探索大型集成空间和缺乏仓库级理解方面仍面临局限性，从而限制了它们的整体有效性。

**Method:** 本文提出了Trae Agent，这是第一个用于仓库级问题解决的基于Agent的集成推理方法。Trae Agent将目标表述为最优解搜索问题，并通过生成、剪枝和选择的模块化Agent解决了大型集成空间和仓库级理解这两个关键挑战。

**Result:** Trae Agent在SWE-bench基准测试上，与四种最先进的集成推理技术相比，Pass@1平均提高了10.22%。Trae Agent在SWE-bench Verified排行榜上排名第一，Pass@1得分达到75.20%。

**Conclusion:** Trae Agent通过其创新的基于Agent的集成推理方法，显著提升了软件问题解决的能力，并在行业标准基准测试中展现出卓越的性能，证明了其在解决大型集成空间和仓库级理解挑战方面的有效性。

> **ai_Abstract:** 本文介绍了Trae Agent，这是一种创新的基于LLM的Agent，专为解决软件工程中的仓库级问题而设计。该方法通过将问题解决框架化为最优解搜索，并利用模块化Agent处理大型集成空间和实现仓库级理解，从而克服了现有LLM方法在这些方面的局限性。在SWE-bench基准测试上的广泛实验表明，Trae Agent在Pass@1指标上显著优于现有SOTA集成推理技术，平均提升10.22%，并取得了75.20%的Pass@1分数，位列排行榜首位。该项目已开源以促进研究。

> **摘要翻译:** 软件问题解决是软件工程中的一个关键挑战，近年来受到了越来越多的关注。随着大型语言模型（LLM）的快速发展，在解决实际软件工程任务方面取得了实质性进展。最近的研究引入了集成推理技术来提高基于LLM的问题解决性能。然而，现有的基于提示的方法在有效探索大型集成空间方面仍然面临局限性，并且缺乏仓库级理解能力，这两者都限制了它们的整体有效性。在本文中，我们提出了Trae Agent，这是第一个用于仓库级问题解决的基于Agent的集成推理方法。Trae Agent将我们的目标表述为最优解搜索问题，并通过生成、剪枝和选择的模块化Agent解决了两个关键挑战，即大型集成空间和仓库级理解。我们使用三种领先的LLM在广泛采用的SWE-bench基准测试上进行了广泛的实验，将Trae Agent与四种最先进的集成推理技术进行了比较。实验结果表明，Trae Agent始终表现出卓越的性能，在Pass@1方面比所有基线平均提高了10.22%。Trae Agent在SWE-bench Verified排行榜上取得了第一名，Pass@1得分高达75.20%。我们很高兴将Trae Agent作为一个开源项目发布，以支持研究社区，所有资源均可在https://github.com/bytedance/trae-agent获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [215] [Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System](https://arxiv.org/abs/2508.00593)
> *用户反馈能否帮助问题检测？一项针对十亿用户在线服务系统的实证研究*

*Shuyao Jiang, Jiazhen Gu, Wujie Zheng, Yangfan Zhou, Michael R. Lyu* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 用户反馈, 问题检测, 实证研究, 在线服务系统, 机器学习

**Comment:** Accepted by the 19th ACM/IEEE International Symposium on Empirical
  Software Engineering and Measurement (ESEM 2025)

> **TL;DR:** 本文对十亿用户在线服务系统中的用户反馈进行了实证研究，旨在理解其特性以帮助问题检测，发现大量无关信息，但也证实了机器学习方法的可行性。

**AI_Comments:** 这篇论文为在大规模系统中利用用户反馈进行问题检测的挑战和机遇提供了宝贵的实证见解。所分析的数据量巨大（超过5000万条反馈）以及十亿用户系统的真实世界背景，使得其发现具有高度的相关性和可信度。一项关键的创新是，尽管用户反馈存在噪音，但论文证实了机器学习的可行性，为未来的研究和开发提供了有希望的方向。论文强调需要过滤无关信息，这对系统开发者而言是一个实用的启示。

<details>
  <summary>Details</summary>

**Motivation:** 长期以来，用户反馈被认为有助于问题检测，但在大型在线服务系统中，从海量用户反馈中识别严重问题仍具挑战性。本研究的动机是，为了开发更好的基于反馈的问题检测方法，首先需要全面了解真实生产系统中用户反馈的特征。

**Method:** 作者对一个拥有十亿用户的在线服务系统中六个真实服务的50,378,766条用户反馈进行了实证研究。研究内容包括：用户反馈中提供了什么信息；反馈的某些特征是否能作为严重问题的良好指标；以及采用机器学习技术分析用户反馈是否合理。

**Result:** 结果显示，大部分用户反馈提供了与系统问题无关的信息，因此在处理用户反馈时过滤掉无关信息至关重要。此外，仅凭用户反馈特征难以轻易检测出严重问题。最后，不同时间段内反馈主题的分布相似，这证实了设计基于机器学习的方法是更好地分析用户反馈的可行方向。

**Conclusion:** 作者认为，研究结果可作为大规模服务系统中基于反馈的问题检测的实证基础，为实际问题检测方法的设计和实现提供了启示。

> **ai_Abstract:** 这项实证研究分析了十亿用户在线服务系统中超过5000万条用户反馈，旨在探究用户反馈特征对问题检测的帮助。研究发现，大量反馈与系统问题无关，强调了过滤无关信息的重要性。尽管仅凭反馈特征难以检测严重问题，但研究证实了由于反馈主题分布随时间保持一致，机器学习方法是有效分析用户反馈的可行方向。这些发现为设计实用的基于反馈的问题检测系统提供了实证基础。

> **摘要翻译:** 背景：长期以来，人们认为用户反馈（通常由终端用户以自然语言编写）有助于问题检测。然而，对于接收海量反馈的大规模在线服务系统而言，从用户反馈中识别严重问题仍然是一项具有挑战性的任务。目的：为了开发更好的基于反馈的问题检测方法，首先全面了解真实生产系统中用户反馈的特征至关重要。方法：在本文中，我们对一个拥有十亿用户的在线服务系统中六个真实服务的50,378,766条用户反馈进行了实证研究。我们首先研究了用户在反馈中提供了什么。然后，我们检查了反馈项的某些特征是否能成为严重问题的良好指标。最后，我们调查了采用机器学习技术分析用户反馈是否合理。结果：我们的结果表明，大部分用户反馈提供了与系统问题无关的信息。因此，在处理用户反馈时，过滤掉与问题无关的信息至关重要。此外，我们发现仅凭用户反馈特征难以轻易检测出严重问题。最后，我们发现不同时间段内反馈主题的分布是相似的。这证实了设计基于机器学习的方法是更好地分析用户反馈的可行方向。结论：我们认为我们的发现可以作为大规模服务系统中基于反馈的问题检测的实证基础，为实际问题检测方法的设计和实现提供了启示。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [243] [MCeT: Behavioral Model Correctness Evaluation using Large Language Models](https://arxiv.org/abs/2508.00630)
> *MCeT：使用大型语言模型评估行为模型的正确性*

*Khaled Ahmed, Jialing Song, Boqi Chen, Ou Wei, Bingzhou Zheng* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 行为模型, 正确性评估, 大型语言模型, 序列图, 自动化工具

**Comment:** MODELS 2025

> **TL;DR:** MCeT是一个自动化工具，利用LLM通过细粒度的多视角和自洽性检查来评估行为模型（特别是序列图）相对于需求文本的正确性，显著提高了问题发现率和准确性。

**AI_Comments:** MCeT的创新之处在于其结合LLM的强大自然语言理解能力与结构化、细粒度的多视角检查方法，有效克服了LLM直接应用于模型正确性评估时存在的局限性（如低问题发现率和幻觉）。该工具的重要性在于它不仅能提升手动和AI生成模型验证的效率和准确性，还能促进AI建模助手的自我优化，对软件工程中的自动化文档验证和AI辅助设计领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 行为模型图是重要的文档，通常由系统工程师从需求文档中设计。随着大型语言模型（LLM）作为AI建模助手的日益普及，图表的生成将涉及更多的自动化。这使得自动化模型正确性评估工具的进步变得必要，以评估手动和AI自动生成的模型，为系统工程师提供反馈，并使AI助手能够自我评估和自我增强其生成的模型。

**Method:** 本文提出了MCeT，第一个完全自动化的工具，用于评估行为模型（特别是序列图）相对于其相应需求文本的正确性。该工具利用LLM进行评估。为了解决直接使用LLM发现问题不到35%的问题，MCeT采用了一种细粒度的、多视角方法：将图表分解为原子、不可分割的交互，并将需求文本分解为原子、自包含的项。然后，将图表与原子需求进行比较，并将每个图表原子与需求进行比较。此外，还提出了一种结合不同视角的自洽性检查方法，以减轻LLM幻觉问题。

**Result:** 在真实需求数据集上，MCeT的组合方法将直接方法的精确度从0.58提高到0.81。该方法比直接方法多发现了90%的经验工程师发现的问题，并且每张图平均报告了6个新问题。

**Conclusion:** MCeT是首个利用LLM进行行为模型正确性评估的自动化工具，其提出的细粒度多视角和自洽性检查方法显著提高了评估的准确性和问题发现能力，为模型验证和AI辅助设计提供了有效手段。

> **ai_Abstract:** 本文提出了MCeT，一个利用大型语言模型（LLM）自动化评估行为模型（特别是序列图）与需求文本之间正确性的工具。鉴于LLM直接评估效果不佳，MCeT采用了一种创新的细粒度、多视角分析方法，将图表和需求分解为原子单元进行对比，并结合自洽性检查以提高准确性并减少幻觉。实验表明，MCeT显著提升了问题发现率和精确度，为模型验证和AI辅助设计提供了有效手段。

> **摘要翻译:** 行为模型图（例如序列图）是一种重要的文档形式，通常由系统工程师根据需求文档设计，可以是完全手动，也可以是在设计工具的辅助下完成。随着大型语言模型（LLM）作为人工智能建模助手的日益普及，图表的生成将涉及更多的自动化。这使得自动化模型正确性评估工具的进步变得必要。这样的工具可用于评估手动和AI自动生成的模型；为系统工程师提供反馈，并使AI助手能够自我评估和自我增强其生成的模型。
在本文中，我们提出了MCeT，这是第一个完全自动化的工具，用于评估行为模型（特别是序列图）相对于其相应需求文本的正确性，并生成模型存在的问题列表。我们利用LLM进行正确性评估任务，因为它们已显示出卓越的自然语言理解能力。然而，我们发现直接要求LLM比较图表与需求，发现的问题不到经验工程师能发现的35%。我们建议通过一种细粒度的、多视角的方法来补充直接检查；我们将图表分解为原子、不可分割的交互，并将需求文本分解为原子、自包含的项。我们将图表与原子需求进行比较，并将每个图表原子与需求进行比较。我们还提出了一种自洽性检查方法，该方法结合了不同视角以减轻LLM幻觉问题。在真实需求数据集上，我们的组合方法将直接方法的精确度从0.58提高到0.81。此外，该方法比直接方法多发现了90%的经验工程师发现的问题，并且每张图平均报告了6个新问题。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [271] [Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?](https://arxiv.org/abs/2508.00700)
> *LLM生成的代码比人类编写的代码更具可维护性和可靠性吗？*

*Alfred Santa Molison, Marcia Moraes, Glaucia Melo, Fabio Santos, Wesley K. G. Assuncao* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 大型语言模型, 代码生成, 软件质量, 可维护性, 可靠性

**Comment:** Accepted ESEM2025

> **TL;DR:** 研究发现LLM生成的代码通常bug更少且修复成本更低，但面对复杂问题时可能引入结构性缺陷，需要更系统化的评估。

**AI_Comments:** 该研究通过实证方法，首次系统地比较了LLM生成代码与人类代码的质量属性，特别是关注了可维护性和可靠性，具有重要的实践意义。其创新之处在于使用了多种LLM配置和不同难度级别的任务来评估代码质量。研究结果揭示了LLM在减少bug方面的潜力，但也指出了其在处理复杂问题时可能引入新的结构性缺陷的局限性，这对于指导LLM在软件开发中的应用和未来的研究方向具有指导意义。研究的局限性可能在于其评估工具（SonarQube）的局限性以及数据集的代表性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在软件开发中的代码生成方面应用广泛，但其生成的代码在软件质量方面的表现以及与人类编写代码的比较仍不明确。本研究旨在比较LLM生成代码和人类编写代码的内部质量属性。

**Method:** 本研究采用实证方法，整合了编程任务数据集、三种LLM配置（零样本、少样本和微调），并使用SonarQube评估软件质量。数据集包含针对入门级、面试级和竞赛级三种难度级别的Python代码解决方案。研究分析了关键的代码质量指标，包括可维护性和可靠性，以及解决代码问题所需的估计工作量。

**Result:** 分析显示，LLM生成的代码总体上bug更少，且修复它们所需的工作量更少。有趣的是，微调模型减少了高严重性问题（如阻塞和关键bug）的发生率，并将其转移到较低严重性类别，但这降低了模型的性能。在竞赛级别的问题中，LLM解决方案有时会引入人类编写代码中不存在的结构性问题。

**Conclusion:** 本研究结果为LLM生成代码的质量提供了有价值的见解；然而，在更复杂的场景中引入关键问题，凸显了对LLM解决方案进行系统评估和验证的必要性。我们的工作加深了对LLM在代码生成方面的优点和局限性的理解。

> **ai_Abstract:** 本研究对比了LLM生成代码与人类编写代码的内部质量，发现LLM代码通常bug更少且修复成本较低。尽管微调模型能降低高严重性bug，但会牺牲性能。在复杂问题上，LLM代码可能引入新的结构性问题。研究强调了在实际应用中对LLM生成代码进行系统评估和验证的重要性，并加深了对LLM在代码生成方面优缺点的理解。

> **摘要翻译:** 背景：大型语言模型（LLM）在软件开发中的兴起为代码生成开辟了新的可能性。尽管这项技术被广泛使用，但LLM在软件质量方面生成代码解决方案的效果以及它们与人类编写代码的比较仍不清楚。目的：本研究比较了LLM生成代码和人类编写代码的内部质量属性。方法：我们的实证研究整合了编程任务数据集、三种LLM配置（零样本、少样本和微调），并使用SonarQube来评估软件质量。数据集包括针对入门级、面试级和竞赛级三种难度级别的Python代码解决方案。我们分析了关键的代码质量指标，包括可维护性和可靠性，以及解决代码问题所需的估计工作量。结果：我们的分析表明，LLM生成的代码总体上bug更少，并且修复它们所需的工作量更少。有趣的是，微调模型减少了高严重性问题（如阻塞和关键bug）的发生率，并将其转移到较低严重性类别，但这降低了模型的性能。在竞赛级别的问题中，LLM解决方案有时会引入人类编写代码中不存在的结构性问题。结论：我们的发现为LLM生成代码的质量提供了有价值的见解；然而，在更复杂的场景中引入关键问题，凸显了对LLM解决方案进行系统评估和验证的必要性。我们的工作加深了对LLM在代码生成方面的优点和局限性的理解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [299] [Tool-Assisted Conformance Checking to Reference Process Models](https://arxiv.org/abs/2508.00738)
> *工具辅助的参考过程模型一致性检查*

*Bernhard Rumpe, Max Stachon, Sebastian Stüber, Valdes Voufo* | **Category: cs.SE, cs.FL, 68N30, D.2.4** | **Updated: 2025-08-01**

**Keywords:** 一致性检查, 参考过程模型, 因果依赖分析, 过程验证, 工具辅助

**Comment:** 

> **TL;DR:** 本文提出了一种工具辅助的解决方案，用于通过因果依赖分析对具体过程模型进行参考过程模型的一致性检查，以提高验证的准确性和灵活性。

**AI_Comments:** 本文的创新之处在于其将因果依赖分析引入到过程模型一致性检查中，并提供了一个工具辅助的解决方案，有效弥补了现有方法在语义模型比较方面的不足。其重要性体现在能够提高过程模型一致性验证的准确性和灵活性，对于确保过程质量和一致性具有实际意义。论文也提及了对其优势和局限性的讨论，表明了研究的全面性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的过程模型一致性检查方法主要关注验证过程执行轨迹，缺乏语义模型比较所需的表达能力和自动化，导致该问题仍未解决。参考框架需要一致性检查以确保遵循既定指南和原则，这对于维护各种过程的质量和一致性至关重要。

**Method:** 本文探索了使用任务和事件的因果依赖分析，对具体过程模型进行参考模型的一致性检查。该方法被整合到一个更广泛的语义框架中，用于定义参考模型一致性，并提出了一个用于参考过程模型一致性检查的算法。

**Result:** 研究提供了一个工具辅助的解决方案，提高了过程模型一致性验证的准确性和灵活性。该方法通过案例研究进行了评估。

**Conclusion:** 本文的工具辅助解决方案通过因果依赖分析，有效解决了现有过程模型一致性检查在语义模型比较方面的不足，显著提升了参考过程模型一致性验证的准确性和灵活性。

> **ai_Abstract:** 本文提出了一种工具辅助的方法，利用任务和事件的因果依赖分析，对具体过程模型进行参考过程模型的一致性检查。该方法旨在解决现有方法在语义模型比较方面的不足，并通过整合到一个更广泛的语义框架中来定义参考模型一致性。研究提供了一个算法，并通过案例研究评估了其有效性，最终提供了一个能提高过程模型一致性验证准确性和灵活性的解决方案。

> **摘要翻译:** 参考模型传达最佳实践和标准。参考框架需要一致性检查以确保遵循既定指南和原则，这对于维护各种过程的质量和一致性至关重要。本文探索了使用任务和事件的因果依赖分析，对具体过程模型进行参考模型的一致性检查。现有过程模型一致性检查的概念侧重于验证过程执行轨迹，缺乏语义模型比较所需的表达能力和自动化，导致该问题仍未解决。我们将我们的方法整合到一个更广泛的语义框架中，用于定义参考模型一致性。我们概述了一个参考过程模型一致性检查的算法，通过案例研究对其进行评估，并讨论了其优点和局限性。我们的研究提供了一个工具辅助的解决方案，提高了过程模型一致性验证的准确性和灵活性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [340] [Automated Code Review Using Large Language Models at Ericsson: An Experience Report](https://arxiv.org/abs/2507.19115)
> *爱立信使用大型语言模型进行自动化代码审查：一份经验报告*

*Shweta Ramesh, Joy Bose, Hamender Singh, A K Raghavan, Sujoy Roychowdhury, Giriprasad Sridhara, Nishrith Saini, Ricardo Britto* | **Category: cs.SE, cs.AI, D.2.7** | **Updated: 2025-07-31**

**Keywords:** 代码审查, 大型语言模型, 自动化, 静态分析, 爱立信

**Comment:** 6 pages, 4 figures, 1 table. Accepted in ICSME 2025 conference in
  Auckland

> **TL;DR:** 爱立信利用大型语言模型（LLMs）和静态程序分析开发了一个轻量级工具，旨在自动化代码审查过程，以减轻经验开发人员的负担，并取得了令人鼓舞的初步结果。

**AI_Comments:** 该论文展示了将大型语言模型应用于传统软件工程实践（如代码审查）的实际案例，具有重要的行业应用价值。其创新点在于结合LLMs的自然语言理解能力与静态程序分析的结构化代码分析能力，构建了一个实用的自动化工具。这项工作对于提高代码审查效率、减轻开发人员工作量具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 代码审查是确保软件质量的关键手段，但它需要经验丰富的开发人员，而他们可能没有足够的时间进行深入审查。因此，自动化代码审查可以减轻开发人员的认知负担，使他们能专注于开发新功能和修复错误。

**Method:** 论文描述了开发一个结合大型语言模型（LLMs）和静态程序分析的轻量级工具的经验。

**Result:** 初步实验结果令人鼓舞，得到了经验丰富的开发人员的积极评价。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本经验报告详细介绍了爱立信在利用大型语言模型（LLMs）自动化代码审查方面的实践。为了解决传统代码审查耗时且依赖资深开发人员的问题，研究团队开发了一个结合LLMs和静态程序分析的轻量级工具。初步实验表明，该工具在减轻开发人员负担方面取得了积极且令人鼓舞的效果。

> **摘要翻译:** 代码审查是与测试和静态分析一起确保发布软件质量的主要手段之一。然而，代码审查需要经验丰富的开发人员，他们可能并不总是有时间对代码进行深入审查。因此，自动化代码审查可以帮助减轻经验丰富的软件开发人员的认知负担，使他们能够专注于编写代码以添加新功能和修复错误的主要活动。在本文中，我们描述了在爱立信使用大型语言模型实现代码审查过程自动化的经验。我们描述了使用LLM和静态程序分析开发轻量级工具的过程。然后，我们描述了与经验丰富的开发人员进行的初步实验，评估我们的代码审查工具及其令人鼓舞的结果。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [461] [Exploring the Evidence-Based SE Beliefs of Generative AI Tools](https://arxiv.org/abs/2407.13900)
> *探索生成式AI工具的基于证据的软件工程信念*

*Chris Brown, Jason Cusati* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** 生成式AI, 软件工程, 基于证据的实践, 大型语言模型, 可信度

**Comment:** 

> **TL;DR:** 研究发现生成式AI工具对基于证据的软件工程主张的理解模糊且缺乏可信证据支持。

**AI_Comments:** 这项研究指出了生成式AI在软件工程领域的一个关键局限性，即其对“证据”和“可信度”的理解不足。这对于AI在专业领域（如软件开发）的实际应用具有重要意义，因为它直接影响AI辅助决策的可靠性。该研究强调了未来需要专注于提高AI工具的“证据意识”和“推理透明度”，以使其在软件工程实践中更加值得信赖。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成式AI工具在软件开发中日益普及，但目前尚不清楚这些AI工具如何看待经过研究验证的基于证据的信念和实践。

**Method:** 研究人员通过概念性复制先前的工作，对五种生成式AI工具进行了初步评估，调查了经验性软件工程研究提出的17项基于证据的主张。

**Result:** 研究结果表明，生成式AI工具对研究主张持有模糊的信念，并且缺乏可信的证据来支持其回应。

**Conclusion:** 基于研究结果，论文为将生成式AI系统集成到开发环境中的实践者提供了启示，并指明了未来研究方向，以提高生成式AI的可靠性和可信度，旨在提高实践中对基于证据的软件工程研究成果的认识和采用。

> **ai_Abstract:** 这项研究评估了五种生成式AI工具对17项基于证据的软件工程主张的理解。研究发现，这些AI工具对研究主张的信念模糊，并且缺乏可信的证据来支持其响应。论文提出了对实践者的启示，并指出了未来研究方向，以提高生成式AI在软件开发中的可靠性和可信度，从而促进基于证据的软件工程实践的采用。

> **摘要翻译:** 近期生成式人工智能（AI）的创新，主要由大型语言模型（LLMs）驱动，已经改变了程序员开发和维护软件的方式——开辟了软件工程（SE）的新领域。生成式AI工具支持软件开发任务的先进能力导致其在软件开发工作流程中的采用率上升。然而，关于AI工具如何看待经过研究发现验证的基于证据的信念和实践，人们知之甚少。为此，我们进行了一项初步评估，概念性地复制了先前的工作，以探索用于支持软件开发任务的生成式AI工具的“信念”。我们调查了经验性软件工程研究提出的17项基于证据的主张，涉及五种生成式AI工具。我们的发现表明，生成式AI工具对研究主张持有模糊的信念，并且缺乏可信的证据来支持回应。基于我们的结果，我们为将生成式AI系统集成到开发环境中的实践者提供了启示，并阐明了未来的研究方向，以增强生成式AI的可靠性和可信度——旨在提高实践中对基于证据的软件工程研究成果的认识和采用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [499] [Novice Developers' Perspectives on Adopting LLMs for Software Development: A Systematic Literature Review](https://arxiv.org/abs/2503.07556)
> *新手开发者采纳大型语言模型进行软件开发的视角：一项系统性文献综述*

*Samuel Ferino, Rashina Hoda, John Grundy, Christoph Treude* | **Category: cs.SE, cs.AI** | **Updated: 2025-08-01**

**Keywords:** 系统性文献综述, 大型语言模型, 软件开发, 新手开发者, 采纳视角

**Comment:** 

> **TL;DR:** 本系统性文献综述（SLR）总结了2022年4月至2025年6月间发表的80项研究，分析了新手开发者在软件开发中采用大型语言模型（LLMs）的视角，包括其动机、使用任务、优缺点及未来研究方向。

**AI_Comments:** 这项SLR研究对于理解LLMs在软件开发领域，尤其是对新手开发者群体的影响具有重要意义。其创新之处在于系统性地梳理了大量近期研究，提供了一个全面的视角。研究的重要性体现在为软件工程教育和工具设计提供了数据支持。然而，由于LLM技术发展迅速，综述的时效性可能面临挑战，且其结论基于现有文献，可能无法涵盖所有新兴的应用或挑战。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的兴起，许多研究开始关注新手开发者（计算机科学/软件工程学生和两年以下经验的早期职业开发者）采纳基于LLM的工具进行软件开发的情况。本研究的动机在于系统性地收集和总结这些研究，以理解新手开发者使用这些工具的视角，这对于LLMs在软件工程中的成功采纳至关重要。

**Method:** 本研究采用系统性文献综述（SLR）方法，遵循Kitchenham et al.的指导原则。研究共分析了2022年4月至2025年6月间发表的80项初级研究，旨在回答四个研究问题（RQs）。具体方法包括：回答RQ1时对研究动机和方法进行分类；回答RQ2时识别新手开发者使用LLMs的软件开发任务；回答RQ3时分类研究中讨论的优点、挑战和建议；最后，在回答RQ4时讨论初级研究中提出的局限性和未来研究需求。

**Result:** 研究结果包括：1. 对研究动机和方法进行了分类（RQ1）。2. 识别了新手开发者使用LLMs进行软件开发的具体任务（RQ2）。3. 归纳了使用LLMs的优点、挑战和建议（RQ3）。4. 讨论了现有研究的局限性并提出了未来研究需求（RQ4）。

**Conclusion:** 本系统性文献综述系统地总结了新手开发者采纳LLMs进行软件开发的现有研究，揭示了其动机、应用场景、面临的挑战、获得的优势以及未来的研究方向。研究结果为软件工程研究人员、教育工作者和开发者提供了重要的指导和启示。

> **ai_Abstract:** 本研究进行了一项系统性文献综述（SLR），旨在系统地总结和分析2022年4月至2025年6月间发表的80项关于新手开发者（学生和早期职业开发者）采纳大型语言模型（LLMs）进行软件开发的初级研究。该综述回答了四个研究问题：分类研究动机和方法、识别LLMs在软件开发中的应用任务、归纳使用LLMs的优点、挑战和建议，以及讨论研究局限性和未来研究需求。研究结果为软件工程领域的研究人员、教育者和开发者提供了关于LLMs采纳的重要见解和未来研究方向。

> **摘要翻译:** 随着大型语言模型（LLMs）的兴起，近年来出现了许多研究，重点探索新手开发者（计算机科学/软件工程学生和两年或以下专业经验的早期职业行业开发者）采纳基于LLM的软件开发工具的情况。这些研究旨在理解新手开发者使用这些工具的视角，这是LLMs在软件工程中成功采纳的关键方面。为了系统地收集和总结这些研究，我们根据Kitchenham等人提出的指南，对2022年4月至2025年6月期间发表的80项初级研究进行了一项系统性文献综述（SLR），以回答四个研究问题（RQs）。在回答RQ1时，我们对研究动机和方法进行了分类。在RQ2中，我们识别了新手开发者使用LLMs进行软件开发的任务。在RQ3中，我们对研究中讨论的优点、挑战和建议进行了分类。最后，在回答RQ4时，我们讨论了初级研究中提出的研究局限性和未来研究需求。在整篇论文中，我们还指出了未来工作的方向以及对软件工程研究人员、教育工作者和开发者的启示。我们的研究成果已公开发布在https://github.com/Samuellucas97/SupplementaryInfoPackage-SLR。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [503] [SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution](https://arxiv.org/abs/2507.23348)
> *SWE-Debate：用于软件问题解决的竞争性多智能体辩论框架*

*Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, Qianxiang Wang* | **Category: cs.SE, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 多智能体系统, 软件问题解决, 大型语言模型, 竞争性辩论, 代码依赖图

**Comment:** Our code and data are available at
  https://github.com/YerbaPage/SWE-Debate

> **TL;DR:** SWE-Debate是一个竞争性多智能体辩论框架，通过鼓励多样化的推理路径和整合问题定位，解决了现有基于LLM的软件问题解决框架容易陷入局部解的限制，并在SWE-bench基准测试中取得了SOTA结果。

**AI_Comments:** SWE-Debate的创新之处在于引入了“竞争性多智能体辩论”范式来解决软件问题，这与现有独立探索的智能体方法形成鲜明对比。通过鼓励多样化的推理路径和结构化辩论，它有效地克服了传统方法易陷入局部最优解的限制，实现了更鲁棒的问题定位和修复。其在SWE-bench基准测试上的SOTA表现证明了该方法的有效性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于智能体的软件问题解决方法主要依赖于智能体的独立探索，这导致它们经常陷入局部解决方案，并且未能识别跨代码库不同部分的复杂问题模式。

**Method:** SWE-Debate是一个竞争性多智能体辩论框架。它首先通过遍历代码依赖图创建多个故障传播轨迹作为定位建议。然后，它组织一场由专门智能体进行的三轮辩论，每个智能体代表故障传播轨迹中不同的推理视角。这种结构化竞争使智能体能够协作地收敛到一个整合的修复计划。最后，这个整合的修复计划被集成到一个基于MCTS的代码修改智能体中用于补丁生成。

**Result:** 在SWE-bench基准测试上的实验表明，SWE-Debate在开源智能体框架中取得了新的最先进（SOTA）结果，并以大幅优势超越了基线。

**Conclusion:** SWE-Debate通过引入竞争性多智能体辩论框架，有效解决了现有软件问题解决智能体在复杂问题上陷入局部解的局限性，实现了更准确的问题定位和更优越的修复方案，并在SWE-bench基准测试上达到了新的SOTA性能。

> **ai_Abstract:** 本文提出了SWE-Debate，一个针对软件问题解决的竞争性多智能体辩论框架。针对现有基于LLM的智能体在独立探索中易陷入局部解的局限性，SWE-Debate通过生成故障传播轨迹作为定位建议，并组织专门智能体进行三轮辩论来整合修复计划。该方法鼓励多样化推理路径，实现更精确的问题定位。最终，整合的修复计划被用于MCTS-based代码修改。实验结果表明，SWE-Debate在SWE-bench基准测试上取得了SOTA性能，并显著优于现有基线。

> **摘要翻译:** 问题解决由于大型语言模型（LLM）先进的推理能力取得了显著进展。最近，诸如SWE-agent等基于智能体的框架通过使自主的、使用工具的智能体能够处理复杂的软件工程任务，进一步推动了这一进展。然而，现有的基于智能体的问题解决方法主要基于智能体的独立探索，它们常常陷入局部解决方案，并且未能识别跨代码库不同部分的问题模式。为了解决这一限制，我们提出了SWE-Debate，一个竞争性多智能体辩论框架，它鼓励多样化的推理路径并实现更整合的问题定位。SWE-Debate首先通过遍历代码依赖图创建多个故障传播轨迹作为定位建议。然后，它组织一场由专门智能体进行的三轮辩论，每个智能体代表故障传播轨迹中不同的推理视角。这种结构化竞争使智能体能够协作地收敛到一个整合的修复计划。最后，这个整合的修复计划被集成到一个基于MCTS的代码修改智能体中用于补丁生成。在SWE-bench基准测试上的实验表明，SWE-Debate在开源智能体框架中取得了新的最先进（SOTA）结果，并以大幅优势超越了基线。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [538] [SWE-Exp: Experience-Driven Software Issue Resolution](https://arxiv.org/abs/2507.23361)
> *SWE-Exp：经验驱动的软件问题解决*

*Silin Chen, Shaoxin Lin, Xiaodong Gu, Yuling Shi, Heng Lian, Longfei Yun, Dong Chen, Weiguo Sun, Lin Cao, Qianxiang Wang* | **Category: cs.SE, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 软件问题解决, LLM代理, 经验学习, SWE-Exp, 持续学习

**Comment:** Our code and data are available at
  https://github.com/YerbaPage/SWE-Exp

> **TL;DR:** SWE-Exp引入了一个经验增强的方法，通过从先前的代理轨迹中提炼经验来解决软件问题，从而实现持续学习和更高的解决率。

**AI_Comments:** 这篇论文的创新点在于引入了“经验”这一概念来提升LLM代理在软件问题解决中的能力，解决了现有代理无记忆的痛点。通过构建一个全面的经验库并从中提取多层次的知识，SWE-Exp显著提高了问题解决的效率和成功率。它为自动化软件工程代理提供了一个系统积累和利用专业知识的新范式，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型语言模型（LLM）代理在软件问题解决中表现出色，但它们像无记忆的探索者，每次都独立处理问题，不保留或重用过去的修复经验。这导致重复探索失败的路径，并错失将成功方法应用于类似问题的机会。

**Method:** 我们引入了SWE-Exp，一个经验增强的方法，它从先前的代理轨迹中提炼出简洁可操作的经验，从而实现跨问题的持续学习。该方法引入了一个多方面的经验库，捕捉成功和失败的修复尝试，并提取不同层次（从高级问题理解到具体的代码更改）的可重用问题解决知识。

**Result:** 实验表明，SWE-Exp在开源代理框架下，在SWE-bench-Verified上取得了最先进的解决率（Pass@1为41.6%）。

**Conclusion:** SWE-Exp建立了一种新范式，使得自动化软件工程代理能够系统地积累和利用修复专业知识，从试错探索根本性地转向战略性的、经验驱动的问题解决。

> **ai_Abstract:** SWE-Exp是一种经验增强的软件问题解决方法，旨在克服现有LLM代理在处理软件问题时缺乏记忆和经验重用的缺点。它通过构建一个多方面的经验库，从成功的和失败的修复尝试中提炼可重用的知识，从而实现代理的持续学习。实验证明，SWE-Exp在SWE-bench-Verified基准测试上达到了41.6%的Pass@1解决率，显著优于现有方法，标志着软件工程代理从盲目探索向经验驱动解决的转变。

> **摘要翻译:** 大型语言模型（LLM）代理的最新进展在软件问题解决方面取得了显著进展，利用了多代理协作和蒙特卡洛树搜索（MCTS）等先进技术。然而，当前的代理就像没有记忆的探索者——它们独立处理每个问题，不保留或重用以前修复经验中的知识。这导致重复探索失败的轨迹，并错失将成功的解决问题方法应用于类似问题的机会。为了解决这个问题，我们引入了SWE-Exp，一种经验增强的方法，它从先前的代理轨迹中提炼出简洁可操作的经验，从而实现跨问题的持续学习。我们的方法引入了一个多方面的经验库，捕捉成功和失败的修复尝试。具体而言，它在不同层面（从高级问题理解到具体的代码更改）提取可重用的问题解决知识。实验表明，SWE-Exp在开源代理框架下，在SWE-bench-Verified上取得了最先进的解决率（Pass@1为41.6%）。我们的方法建立了一种新范式，使得自动化软件工程代理能够系统地积累和利用修复专业知识，从试错探索根本性地转向战略性的、经验驱动的问题解决。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [541] [Are Sparse Autoencoders Useful for Java Function Bug Detection?](https://arxiv.org/abs/2505.10375)
> *稀疏自编码器对Java函数错误检测有用吗？*

*Rui Melo, Claudia Mamede, Andre Catarino, Rui Abreu, Henrique Lopes Cardoso* | **Category: cs.SE, cs.AI, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 稀疏自编码器, 错误检测, Java函数, 大型语言模型, 软件漏洞

**Comment:** 10 pages, 10 figures

> **TL;DR:** 本研究探讨了稀疏自编码器（SAE）在Java函数错误检测中的应用，发现它们无需微调底层大型语言模型，即可从预训练LLM的内部表示中有效检测软件错误，性能优于微调的Transformer编码器基线。

**AI_Comments:** 该论文的创新点在于首次实证证明了稀疏自编码器（SAE）可以直接从预训练大型语言模型的内部表示中检测软件错误，而无需进行耗时的微调或任务特定的监督。这为解决LLM在可解释性和部署方面的挑战提供了一个有前景的轻量级替代方案，对于提升自动化漏洞检测的效率和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的漏洞检测方法存在高误报率、可扩展性差和依赖人工等问题。尽管大型语言模型（LLM）为分类任务提供了新途径，但其复杂性和不透明性带来了可解释性和部署挑战。稀疏自编码器（SAE）提供了一个有前景的解决方案。

**Method:** 研究探讨了SAE是否可以作为Java函数错误检测的轻量级、可解释的替代方案。作者评估了SAE应用于GPT-2 Small和Gemma 2B表示时的有效性，检验了它们在不微调底层LLM的情况下突出错误行为的能力。

**Result:** SAE派生的特征使错误检测的F1分数高达89%，始终优于微调的Transformer编码器基线。

**Conclusion:** 本研究首次提供了经验证据，表明SAE可以直接从预训练LLM的内部表示中检测软件错误，而无需任何微调或特定任务的监督。

> **ai_Abstract:** 本研究探讨了稀疏自编码器（SAE）在Java函数错误检测中的应用，旨在解决传统方法和大型语言模型（LLM）的局限性。通过将SAE应用于GPT-2 Small和Gemma 2B的LLM内部表示，研究发现SAE能够有效检测软件错误，F1分数高达89%，且性能优于微调的Transformer编码器基线。这项工作首次证明SAE无需微调或特定任务监督，即可直接利用预训练LLM的内部表示进行错误检测。

> **摘要翻译:** 软件漏洞，如缓冲区溢出和SQL注入，是安全漏洞的主要来源。传统的漏洞检测方法仍然至关重要，但受限于高误报率、可扩展性问题和对人工的依赖。这些限制推动了人们对基于人工智能的自动化漏洞检测和安全代码生成的兴趣。尽管大型语言模型（LLM）为分类任务开辟了新途径，但其复杂性和不透明性给可解释性和部署带来了挑战。稀疏自编码器（SAE）为这个问题提供了一个有前景的解决方案。我们探索SAE是否可以作为Java函数错误检测的轻量级、可解释的替代方案。我们评估了SAE应用于GPT-2 Small和Gemma 2B表示时的有效性，检查了它们在不微调底层LLM的情况下突出错误行为的能力。我们发现SAE派生的特征使错误检测的F1分数高达89%，始终优于微调的Transformer编码器基线。我们的工作首次提供了经验证据，表明SAE可以直接从预训练LLM的内部表示中检测软件错误，而无需任何微调或特定任务的监督。代码可在https://github.com/rufimelo99/SAE-Java-Bug-Detection获取。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [583] [Private GPTs for LLM-driven testing in software development and machine learning](https://arxiv.org/abs/2506.06509)
> *用于软件开发和机器学习中LLM驱动测试的私有GPTs*

*Jakub Jagielski, Consuelo Rojas, Markus Abel* | **Category: cs.SE, cs.AI, I.2.1** | **Updated: 2025-07-31**

**Keywords:** 私有GPT, LLM驱动测试, 自动化测试生成, Gherkin语法, 软件开发

**Comment:** 5 pages, 10 figures

> **TL;DR:** 该研究探讨了使用私有GPT根据需求自动生成可执行测试代码的能力，发现采用Gherkin语法作为中间步骤的两步生成过程能产生更高质量的测试。

**AI_Comments:** 这项研究创新性地将私有GPTs应用于自动化测试代码生成，特别强调了通过Gherkin语法作为中间步骤的重要性，这不仅提高了生成代码的质量，还提升了其可读性和符合最佳实践的程度。这对于产品所有者和业务智能人员直接参与测试标准制定具有重要意义。该方法在实际软件开发和机器学习模型测试中具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是探索私有GPTs自动生成可执行测试代码的能力，以帮助产品负责人或业务智能人员通过大型语言模型直接生成可测试的需求。

**Method:** 研究通过两种方式探索了所生成测试的质量：1) 直接让LLM根据需求生成代码；2) 通过使用Gherkin语法作为中间步骤。具体而言，在“Hello World”程序和数字分类模型两个场景中评估了提示的有效性。

**Result:** 结果表明，两步过程（通过Gherkin语法）产生了更好的测试结果，这体现在人类可读性、最佳编码实践（即代码行数和额外库的使用）方面。此外，结构化提示能带来更高质量的测试输出。

**Conclusion:** 通过使用私有GPTs，特别是采用结构化提示和中间步骤（如Gherkin语法），可以有效地自动生成高质量的可执行测试代码，从而使产品负责人能够直接创建可测试的需求。

> **ai_Abstract:** 本研究探讨了私有GPTs在软件开发和机器学习中自动生成可执行测试代码的能力。研究以验收标准为输入，评估了直接由LLM生成测试代码和通过Gherkin语法作为中间步骤生成代码两种方式的质量。结果显示，采用Gherkin语法的两步生成过程在人类可读性和编码实践方面表现更优，并且结构化提示能显著提高测试输出的质量。研究通过“Hello World”程序和数字分类模型验证了这一发现。

> **摘要翻译:** 在这项贡献中，我们研究了私有GPTs根据需求自动生成可执行测试代码的能力。更具体地说，我们使用验收标准作为输入，这些标准是史诗或故事的一部分，通常用于现代开发流程中。这使得产品负责人或业务智能人员能够通过使用大型语言模型直接生成可测试的标准。我们通过两种方式探索了所生成测试的质量：i) 直接让LLM根据需求生成代码，ii) 通过使用Gherkin语法作为中间步骤。结果表明，两步过程产生了更好的结果——我们将“更好”定义为人类可读性和最佳编码实践，即代码行数和测试中通常使用的额外库的使用。具体而言，我们在两种场景下评估了提示的有效性：一个简单的“Hello World”程序和一个数字分类模型，结果表明结构化提示能带来更高质量的测试输出。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [589] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
> *函数式 vs. 面向对象：比较编程范式如何影响系统架构特性*

*Briza Mel Dias de Sousa, Renato Cordeiro Ferreira, Alfredo Goldman* | **Category: cs.SE, cs.PL, D.3.2; D.2.11; D.2.13** | **Updated: 2025-08-01**

**Keywords:** 函数式编程, 面向对象编程, 编程范式, 软件架构, 系统特性

**Comment:** 11 pages, 16 figures (1 table, 3 diagrams, 5 graphics, 7 listings),
  submitted to CTICQS capstone project competition at SBQS 2025

> **TL;DR:** 本研究比较了面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响，通过开发一个数字钱包系统并对其进行定性和定量分析。

**AI_Comments:** 这项研究具有重要的实践意义，因为它直接比较了两种主流编程范式对软件系统架构的影响。通过结合定性和定量方法，从编码者和阅读者的双重视角进行分析，提供了更全面的洞察。这有助于软件开发团队在项目初期做出更合理的架构决策，从而可能提高代码质量和可维护性。

<details>
  <summary>Details</summary>

**Motivation:** 面向对象编程（OOP）主导多年后，函数式编程（FP）在软件行业受到越来越多的关注。本研究的动机是比较这两种编程范式对软件系统架构特性的影响，以帮助开发者和组织在选择编程范式时做出更明智的决策。

**Method:** 1. 系统开发: 开发了一个数字钱包系统，使用Kotlin（代表OOP）和Scala（代表FP）两种语言实现。
2. 定性分析: 采用自我民族志方法，对两种实现进行并排比较，揭示编写代码者的视角。
3. 定量分析: 基于调查问卷，收集不同背景开发人员的反馈，了解他们阅读代码的印象。

**Result:** 抽象中未提及具体的实验结果，仅描述了研究方法。

**Conclusion:** 期望研究结果能帮助开发者或组织在选择适用于其项目的编程范式时做出更明智的决策。

> **ai_Abstract:** 本研究旨在比较面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响。研究通过在Kotlin（OOP）和Scala（FP）中实现一个数字钱包系统，并结合自我民族志定性分析和基于调查的定量分析，从编写者和阅读者的角度探讨了两种范式对系统架构的影响。研究结果旨在为开发者和组织在选择编程范式时提供决策参考。

> **摘要翻译:** 在面向对象编程（OOP）主导数十年之后，函数式编程（FP）在软件行业中正获得越来越多的关注。本研究比较了OOP和FP对软件系统架构特性的影响。为此，它检查了使用Kotlin（代表OOP）和Scala（代表FP）开发的数字钱包系统的设计和实现。通过定性和定量分析进行比较，以探索每种范式如何影响系统的架构特性。自我民族志定性分析提供了两种实现的并排比较，揭示了编写此类代码者的视角。基于调查的定量分析收集了来自不同背景开发人员的反馈，展示了他们对阅读这些代码的印象。希望这些结果能对寻求为其下一个项目选择最适合范式并做出更明智决策的开发人员或组织有所帮助。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [607] [On LLM-Assisted Generation of Smart Contracts from Business Processes](https://arxiv.org/abs/2507.23087)
> *基于LLM辅助从业务流程生成智能合约*

*Fabian Stiehle, Hans Weytjens, Ingo Weber* | **Category: cs.SE, cs.AI** | **Updated: 2025-07-30**

**Keywords:** 大型语言模型, 智能合约, 代码生成, 业务流程, 自动化评估

**Comment:** Accepted at the Workshop on Distributed Ledger Technologies in
  Business Process Management, At the International Conference for Business
  Process Management (BPM), 2025

> **TL;DR:** 本文探讨了使用大型语言模型（LLMs）从业务流程描述中生成智能合约代码，并引入了一个自动化评估框架。研究发现LLMs的性能未能达到智能合约开发所需的可靠性，并建议未来工作探索负责任的LLM集成。

**AI_Comments:** 本文的创新之处在于提出了一个自动化评估框架，解决了现有LLM生成代码评估中样本小、依赖手动检查或仅验证编译而不考虑执行正确性的问题。这对于智能合约这种对可靠性要求极高的领域尤为重要。研究结果揭示了当前LLM在智能合约生成方面仍存在可靠性不足的局限性，为未来LLM在软件工程领域的应用提供了重要的实践指导和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）改变了软件生产方式，并且被探索用于代码生成。现有基于LLM的代码生成工作在评估时存在局限性（小样本、手动检查、忽略正确执行），因此需要一种更可靠的方法来从业务流程描述中生成智能合约代码，以克服传统基于规则方法的限制。

**Method:** 本研究进行了一项探索性研究，旨在调查使用LLMs从业务流程描述中生成智能合约代码。为此，我们引入了一个自动化评估框架，并提供了来自更大过程模型数据集的经验数据。我们测试了不同类型和大小的LLMs在实现过程执行重要属性（包括强制过程流、资源分配和基于数据的条件）方面的能力。

**Result:** 研究结果表明，LLM的性能未能达到智能合约开发所需的完美可靠性。

**Conclusion:** LLMs在从业务流程生成智能合约方面尚未达到所需的可靠性。未来的工作应探索将LLMs负责任地集成到现有代码生成工具中，以确保更可靠的输出。本文提出的基准测试框架可以作为开发和评估此类集成的基础。

> **ai_Abstract:** 本研究探讨了使用大型语言模型（LLMs）从业务流程描述中生成智能合约代码的潜力。针对现有LLM代码生成评估的局限性，本文引入了一个自动化评估框架，并利用更大的过程模型数据集对不同类型的LLMs进行了测试。结果表明，LLMs在智能合约开发所需的可靠性方面仍有不足。研究建议未来工作应专注于负责任的LLM集成，并指出所提出的基准测试框架可为后续开发和评估提供基础。

> **摘要翻译:** 大型语言模型（LLMs）改变了软件生产的现实。在更广泛的软件工程社区中，除了许多其他用途，它们正被探索用于从不同类型输入生成代码的用例。在这项工作中，我们提出了一项探索性研究，旨在调查使用LLMs从业务流程描述中生成智能合约代码，这一想法已在近期文献中出现，旨在克服传统基于规则的代码生成方法的局限性。然而，当前基于LLM的工作在小样本上评估生成的代码，依赖于手动检查，或者测试代码是否编译但忽略了正确的执行。通过这项工作，我们引入了一个自动化评估框架，并提供了来自更大过程模型数据集的经验数据。我们测试了不同类型和大小的LLMs在实现过程执行重要属性（包括强制过程流、资源分配和基于数据的条件）方面的能力。我们的结果表明，LLM的性能未能达到智能合约开发所需的完美可靠性。我们建议未来的工作探索将LLMs负责任地集成到现有代码生成工具中，以确保更可靠的输出。我们的基准测试框架可以作为开发和评估此类集成的基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [625] [How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?](https://arxiv.org/abs/2506.15884)
> *社区异味如何影响机器学习项目中的自承认技术债务？*

*Shamse Tasnim Cynthia, Nuri Almarimi, Banani Roy* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 社区异味, 自承认技术债务, 机器学习项目, 社会技术问题, 软件质量

**Comment:** 

> **TL;DR:** 本研究调查了开源机器学习项目中社区异味与自承认技术债务（SATD）的流行程度及其关系，发现社区异味普遍存在，某些特定异味（如“无线电静默”和“组织孤岛”）与更高的SATD发生率强相关，且异味和SATD的演变趋势与项目规模相关。研究强调了早期检测和缓解社会技术问题对于维护ML系统质量和可持续性的重要性。

**AI_Comments:** 这项研究通过将社区异味的概念扩展到机器学习项目，填补了现有研究的空白。其创新之处在于首次系统性地分析了ML项目中社区异味与自承认技术债务之间的具体关联，并揭示了特定异味对不同类型技术债务的影响以及它们随时间演变的趋势。这对于ML项目管理者和开发者理解和解决社会技术问题，从而提高项目质量和可持续性具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的研究已探讨了社区异味和自承认技术债务在通用软件系统中的问题，但它们在机器学习（ML）项目中的相互作用仍未得到充分研究。本研究旨在填补这一空白，调查开源ML项目中社区异味的流行程度及其与SATD的关系。

**Method:** 本研究在发布级别分析了155个开源ML项目的数据。首先，检查了十种社区异味类型的普遍性及其在不同规模项目中的分布。其次，检测了发布级别的SATD，并应用统计分析来探究其与社区异味的关联。第三，确定了六种SATD类型与哪些社区异味最相关。最后，分析了社区异味和SATD在发布过程中的演变趋势。

**Result:** 研究发现社区异味普遍存在，并在小型、中型和大型项目中呈现独特的分布模式。结果显示，某些异味，如“无线电静默”和“组织孤岛”，与更高的SATD发生率强相关。分析还揭示，与权限和沟通相关的异味经常与持久的代码和设计债务同时出现。此外，社区异味和SATD的演变趋势依赖于项目规模，并具有共享的轨迹。

**Conclusion:** 本研究的发现强调了早期检测和缓解社会技术问题对于维护基于ML的系统长期质量和可持续性的重要性。

> **ai_Abstract:** 本研究深入探讨了开源机器学习项目中社区异味与自承认技术债务（SATD）之间的关联。通过对155个ML项目发布数据的分析，研究发现社区异味普遍存在且分布多样，某些特定异味如“无线电静默”和“组织孤岛”与更高的SATD发生率紧密相关，尤其权限和沟通相关的异味常与代码及设计债务并存。研究还揭示了异味和SATD的演变趋势受项目规模影响。这些发现强调了在ML项目中早期识别并解决社会技术问题对于保障系统长期质量和可持续性的关键作用。

> **摘要翻译:** 社区异味反映了糟糕的组织实践，这些实践通常会导致社会技术问题和自承认技术债务（SATD）的累积。尽管先前的研究已经探讨了这些问题在通用软件系统中的表现，但它们在基于机器学习（ML）的项目中的相互作用仍未得到充分研究。在本研究中，我们调查了开源ML项目中社区异味的流行程度及其与SATD的关系，分析了发布级别的数据。首先，我们检查了155个基于ML的系统在发布过程中十种社区异味类型的流行程度，发现社区异味普遍存在，并在小型、中型和大型项目中呈现出独特的分布模式。其次，我们在发布级别检测了SATD，并应用统计分析来检查其与社区异味的关联。我们的结果表明，某些异味，如“无线电静默”和“组织孤岛”，与更高的SATD发生率密切相关。第三，我们考虑了六种已识别的SATD类型，以确定哪些社区异味与每种债务类别最相关。我们的分析显示，与权限和沟通相关的异味经常与持久的代码和设计债务同时出现。最后，我们分析了社区异味和SATD如何在发布过程中演变，揭示了依赖于项目规模的趋势和共享的轨迹。我们的发现强调了早期检测和缓解社会技术问题对于维护基于ML的系统长期质量和可持续性的重要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [645] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
> *Desyan：一个无缝实现值流和符号分析的平台*

*Panagiotis Diamantakis, Thanassis Avgerinos, Yannis Smaragdakis* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 值流分析, 符号分析, Datalog, SMT求解, 程序分析

**Comment:** 

> **TL;DR:** Desyan是一个结合了值流和符号分析的平台，通过扩展Datalog引擎和集成SMT求解器，实现高效的程序分析。

**AI_Comments:** Desyan的创新之处在于它首次提供了一个统一的平台，能够高效且灵活地集成值流分析和符号分析，这两种在程序分析中至关重要的技术。通过扩展现有的高性能Datalog引擎并巧妙地集成SMT求解器和Datalog原生符号推理，Desyan解决了长期存在的集成难题，并为不同的分析需求提供了性能优化的解决方案。其对Datalog的利用和对多种推理模式的支持，使其在静态分析领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的值流分析和符号分析作为主流静态分析范式，尽管各自成功，但缺乏一个广泛采用的统一平台，可以轻松高效地将符号技术与高性能数据流推理集成。

**Method:** Desyan通过扩展生产级的Datalog定点引擎（Soufflé），并集成业界领先的SMT求解器，同时支持Datalog原生的符号推理（通过自底向上的代数推理模块），来无缝整合值流和符号推理。它还提供了自动高效处理程序分析中常见模式的构造。

**Result:** Desyan引擎能够根据底层分析需求混合使用不同类型的推理。对于值流分析，该引擎作为Datalog评估器性能最佳（执行时间常快20倍以上）；对于需要完整SMT的应用，它利用领先的SMT求解器；对于轻量级符号评估，它使用Datalog原生符号推理，相比急于求助于SMT求解器，能实现大幅加速（常快2倍以上）。

**Conclusion:** Desyan提供了一个统一且高效的平台，能够无缝集成值流和符号分析，并能根据分析需求灵活选择推理方式，从而显著提升了静态程序分析的性能和能力。

> **ai_Abstract:** Desyan是一个创新的程序分析平台，旨在弥合传统值流分析和符号分析之间的集成鸿沟。它通过扩展Soufflé Datalog引擎并集成高级SMT求解器，实现了这两种分析范式的无缝结合。Desyan支持灵活的推理模式，包括高效的值流分析、全面的SMT求解以及快速的Datalog原生符号推理，从而显著提升了静态程序分析的效率和能力。

> **摘要翻译:** 在过去的二十年里，两种不同类型的静态分析在学术界和工业界都已成为主导范式：值流分析（例如，数据流分析或指向分析）和符号分析（例如，符号执行）。尽管这两种方法在众多应用领域取得了各自的成功，但它们在很大程度上仍然是相互独立的；这源于一个简单的现实，即缺乏一个广泛采用的统一平台，可以轻松高效地将符号技术与高性能数据流推理集成。
为了弥补这一差距，我们引入了Desyan：一个用于编写程序分析的平台，可无缝集成值流和符号推理。Desyan通过集成业界领先的SMT引擎，扩展了一个生产级的Datalog定点引擎（Soufflé），使其具备了功能齐全的SMT求解能力。Desyan提供了构造，可以自动（且高效地！）处理程序分析中出现的典型模式。同时，这种集成对于求解技术是不可知的，并通过一个自底向上的代数推理模块，支持Datalog原生的符号推理。
结果是一个引擎，它允许根据底层分析的需要混合不同类型的推理。对于值流分析，该引擎是同类最佳的Datalog评估器（执行时间通常快20倍以上）；对于需要完整SMT的应用（例如，需要解决任意复杂条件的协同执行引擎或其他符号评估器），该引擎利用领先的SMT求解器；对于轻量级符号评估（例如，在路径敏感分析的上下文中解决简单条件），该引擎可以使用Datalog原生的符号推理，与急于求助于SMT求解器相比，实现了大幅加速（通常快2倍以上）。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [672] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
> *从代码到职业：评估竞技程序员的行业就业能力*

*Md Imranur Rahman Akib, Fathima Binthe Muhammed, Umit Saha, Md Fazlul Karim Patwary, Mehrin Anannya, Md Alomgeer Hussein, Md Biplob Hosen* | **Category: cs.SE, cs.PL** | **Updated: 2025-08-01**

**Keywords:** 竞技编程, 职业评估, 机器学习, 就业准备, Codeforces

**Comment:** 

> **TL;DR:** 该研究利用Codeforces数据和随机森林分类器，预测竞技程序员的行业就业潜力，并能有效区分不同技能水平的程序员。

**AI_Comments:** 这项研究创新性地将机器学习应用于竞技编程数据，以评估程序员的行业就业潜力，为招聘和求职提供了一个新颖的视角。其价值在于提供了一个量化评估编程能力的工具，有助于弥合教育与行业需求之间的差距。该方法的局限性可能在于其对Codeforces平台数据的依赖性，可能无法完全涵盖现实世界中所需的全部职业技能。

<details>
  <summary>Details</summary>

**Motivation:** 当今快速发展的科技行业，需要工具来评估程序员基于其编码表现的就业准备情况。本研究旨在分析用户的竞技编程活动与其获得不同级别软件工程职位的可能性之间的关联。

**Method:** 研究通过Codeforces API收集用户数据，处理关键性能指标，并使用随机森林分类器构建预测模型。该模型将用户分为四个就业能力等级。系统使用Flask实现并部署在Render上以提供实时预测。

**Result:** 评估表明，该方法能够有效地根据编码熟练度和参与度区分不同技能水平的程序员。

**Conclusion:** 这项工作为机器学习在职业评估中的应用奠定了基础，并可扩展到更广泛技术领域的就业准备预测。

> **ai_Abstract:** 本研究旨在解决科技行业对评估程序员就业准备工具的需求。通过分析Codeforces用户的竞技编程活动，研究人员利用Codeforces API收集数据，处理关键指标，并使用随机森林分类器构建了一个预测模型。该模型能够将用户分为四个就业能力等级，并已通过Flask和Render实现实时预测。结果表明，该方法能有效区分不同技能水平的程序员，为利用机器学习进行职业评估奠定了基础，并有望扩展到其他技术领域。

> **摘要翻译:** 在当今快速发展的科技行业中，对能够根据程序员编码表现评估其就业准备情况的工具需求日益增长。本研究侧重于预测Codeforces用户获得不同级别软件工程职位的潜力。主要目标是分析用户的竞技编程活动如何与他们获得从入门级到大型科技公司职位的机会相关联。我们使用Codeforces API收集用户数据，处理关键性能指标，并使用随机森林分类器构建预测模型。该模型将用户分为四个就业能力等级，从需要进一步发展到适合顶级科技工作的用户。该系统使用Flask实现并部署在Render上以提供实时预测。我们的评估表明，该方法能够有效地根据编码熟练度和参与度区分不同技能水平。这项工作为机器学习在职业评估中的应用奠定了基础，并且可以扩展到更广泛技术领域的就业准备预测。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [674] [Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots](https://arxiv.org/abs/2507.17049)
> *评估视觉语言动作机器人中的不确定性和质量*

*Pablo Valle, Chengjie Lu, Shaukat Ali, Aitor Arrieta* | **Category: cs.SE, cs.RO** | **Updated: 2025-07-31**

**Keywords:** 视觉语言动作, 机器人, 不确定性, 质量评估, 多模态AI

**Comment:** 

> **TL;DR:** 本研究提出并评估了八个不确定性指标和五个质量指标，用于更全面地评估视觉语言动作（VLA）机器人的性能，超越了传统的任务成功率。

**AI_Comments:** 本文的创新之处在于提出了超越传统二元成功率的VLA机器人评估指标，填补了现有评估方法的空白。这些新指标能够更细致地捕捉任务执行的质量和模型的不确定性，对于VLA模型在实际应用中的可靠性和鲁棒性评估至关重要。研究的重要性在于为VLA系统的开发和部署提供了更全面的评估工具，有助于推动该领域向更高级别的自主性和可靠性发展。

<details>
  <summary>Details</summary>

**Motivation:** 目前的视觉语言动作（VLA）模型主要通过任务成功率进行评估，但这无法捕捉任务执行的质量和模型决策的置信度。因此，需要更全面的评估方法来解决这一局限性。

**Method:** 研究提出了八个不确定性指标和五个专门为VLA模型设计的质量指标，用于机器人操作任务。通过一项大规模实证研究，涉及来自三种最先进VLA模型的908次成功任务执行，在四种代表性机器人操作任务中评估了这些指标的有效性。人类领域专家手动标记了任务质量，以分析所提出指标与专家判断之间的相关性。

**Result:** 结果显示，所提出的几个指标与人类评估表现出中度至强相关性，突出了它们在评估任务质量和模型置信度方面的实用性。此外，研究发现某些指标可以区分未成功任务中的高、中、低质量执行。

**Conclusion:** 本研究的发现挑战了当前仅依赖二元成功率的评估实践的充分性，并为改进VLA机器人系统的实时监控和自适应增强铺平了道路。

> **ai_Abstract:** 本研究旨在解决当前视觉语言动作（VLA）机器人评估方法仅依赖任务成功率的局限性，提出了八个不确定性指标和五个质量指标。通过对908次VLA模型机器人操作任务执行的实证研究，并结合人类专家标注，验证了这些新指标与人类评估之间存在显著相关性，表明它们能有效衡量任务执行质量和模型置信度。研究结果挑战了现有评估范式，并为未来VLA系统更全面的性能监控和改进提供了基础。

> **摘要翻译:** 视觉语言动作（VLA）模型是一类多模态人工智能（AI）系统，它整合了视觉感知、自然语言理解和动作规划，使智能体能够解释其环境、理解指令并自主执行具身任务。最近，该领域取得了显著进展。这类模型通常通过任务成功率进行评估，但这未能捕捉任务执行的质量和模型对其决策的置信度。在本文中，我们提出了八个不确定性指标和五个专门为VLA模型设计的质量指标，用于机器人操作任务。我们通过一项大规模实证研究评估了它们的有效性，该研究涉及来自三种最先进VLA模型的908次成功任务执行，涵盖四种代表性机器人操作任务。人类领域专家手动标记了任务质量，使我们能够分析所提出指标与专家判断之间的相关性。结果显示，几个指标与人类评估表现出中度至强相关性，突出了它们在评估任务质量和模型置信度方面的实用性。此外，我们发现某些指标可以区分未成功任务中的高、中、低质量执行，这在测试预言机不可用时可能很有趣。我们的发现挑战了当前仅依赖二元成功率的评估实践的充分性，并为改进VLA机器人系统的实时监控和自适应增强铺平了道路。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [692] [Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures](https://arxiv.org/abs/2508.00749)
> *用于组件和连接器架构语义差异分析的动态符号执行*

*Johanna Grahl, Bernhard Rumpe, Max Stachon, Sebastian Stüber* | **Category: cs.SE, cs.FL, cs.SC, 68N30, D.2.4** | **Updated: 2025-08-01**

**Keywords:** 动态符号执行, 语义差异分析, 组件和连接器架构, MontiArc, 模型驱动开发

**Comment:** 

> **TL;DR:** 本文研究了动态符号执行（DSE）在组件和连接器架构语义差异分析中的应用，发现DSE有前景但扩展性受限。

**AI_Comments:** 该论文创新性地将动态符号执行应用于组件和连接器架构的语义差异分析，并通过增强现有工具来收集运行时数据。其重要性在于为模型驱动开发中的模型一致性提供了新的分析方法。然而，论文明确指出可扩展性是其主要限制，这表明在应用于大型复杂系统时可能面临挑战，需要未来的研究来克服。

<details>
  <summary>Details</summary>

**Motivation:** 在模型驱动开发中，确保演化模型的正确性和一致性至关重要。

**Method:** 本文将动态符号执行（DSE）应用于组件和连接器架构的语义差异分析，具体利用MontiArc模型。作者增强了现有的MontiArc-to-Java生成器，以在运行时收集符号和具体执行数据（包括转换条件、访问状态和自动机内部变量）。他们还评估了基于运行时效率、最小性和完整性标准的各种执行策略，建立了评估DSE在语义差异分析中适用性的框架。

**Result:** 研究结果表明，动态符号执行（DSE）在分析组件和连接器架构方面显示出前景，但可扩展性仍然是主要限制。

**Conclusion:** DSE在分析组件和连接器架构方面有前景，但需要进一步研究以提高其在大型系统中的实用性。

> **ai_Abstract:** 本文探讨了动态符号执行（DSE）在组件和连接器架构语义差异分析中的应用，特别是在MontiArc模型上。通过增强MontiArc-to-Java生成器以收集运行时数据，作者能够识别关键执行轨迹。研究评估了DSE的多种执行策略，发现其在分析此类架构方面具有潜力，但可扩展性是其主要局限性，需要进一步研究以提升其实用性。

> **摘要翻译:** 在模型驱动开发中，确保演化模型的正确性和一致性至关重要。本文研究了动态符号执行（DSE）在组件和连接器架构语义差异分析中的应用，具体利用MontiArc模型。我们增强了现有的MontiArc-to-Java生成器，以在运行时收集符号和具体执行数据，包括自动机的转换条件、访问状态和内部变量。这些数据有助于识别提供系统行为关键洞察的重要执行轨迹。我们基于运行时效率、最小性和完整性标准评估了各种执行策略，建立了一个评估DSE在语义差异分析中适用性的框架。我们的研究结果表明，虽然DSE在分析组件和连接器架构方面显示出前景，但可扩展性仍然是主要限制，这表明需要进一步研究以增强其在大型系统中的实际效用。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [723] [NoCode-bench: A Benchmark for Evaluating Natural Language-Driven Feature Addition](https://arxiv.org/abs/2507.18130)
> *NoCode-bench：一个用于评估自然语言驱动的特性添加的基准*

*Le Deng, Zhonghao Jiang, Jialun Cao, Michael Pradel, Zhongxin Liu* | **Category: cs.SE** | **Updated: 2025-08-01**

**Keywords:** NoCode-bench, 自然语言处理, 无代码开发, 大型语言模型, 特性添加

**Comment:** 

> **TL;DR:** 引入了一个名为NoCode-bench的基准，用于评估大型语言模型在自然语言驱动的无代码特性添加任务中的表现，结果显示LLM在此类任务中的成功率较低，尚不适合完全的无代码开发。

**AI_Comments:** NoCode-bench的创新之处在于它首次提供了一个大规模、真实世界且经过验证的基准，用于评估LLM在自然语言驱动的特性添加这一新兴领域的表现。其重要性在于揭示了当前LLM在此任务中的局限性，特别是在复杂场景下的代码理解和生成能力，为未来的研究指明了方向。通过量化LLM的成功率，该基准为研究人员提供了明确的改进目标。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言驱动的无代码开发有望提高生产力并普及开发，大型语言模型在此范式中展现潜力，因此需要一个基准来评估其在该领域的表现。

**Method:** 本研究引入了NoCode-bench，一个旨在评估LLM在真实世界自然语言驱动的特性添加任务中的基准。它包含来自10个项目的634项任务和11.4万次代码更改。每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。此外，还包含一个由114个高质量、人工验证的实例组成的子集，即NoCode-bench Verified，以确保评估的可靠性。

**Result:** 实验结果显示，尽管代币使用量高，但最好的大型语言模型在任务中的成功率仅为15.79%，这突显了跨文件编辑、代码库理解和工具调用方面的挑战。

**Conclusion:** 研究结果表明，大型语言模型尚未准备好进行完全由自然语言驱动的无代码开发。NoCode-bench为该领域的未来进展奠定了基础。

> **ai_Abstract:** 本研究引入了NoCode-bench，一个专门用于评估大型语言模型（LLMs）在自然语言驱动的特性添加任务中表现的基准。该基准包含634项真实世界的任务，涵盖10个项目和11.4万次代码更改，并通过开发者测试用例进行验证，同时包含一个高质量的人工验证子集。实验结果显示，即使是表现最佳的LLMs，其任务成功率也仅为15.79%，表明LLMs在跨文件编辑、代码库理解和工具调用方面仍面临显著挑战。研究结论指出，LLMs目前尚无法完全支持自然语言驱动的无代码开发，但NoCode-bench为该领域的未来研究奠定了基础。

> **摘要翻译:** 自然语言驱动的无代码开发允许用户使用自然语言（NL）而不是编辑源代码来指定软件功能，这有望提高生产力并实现开发的民主化。大型语言模型（LLMs）在此范式中显示出潜力。在这种背景下，软件文档充当功能的NL规范。这项工作引入了NoCode-bench，一个旨在评估LLMs在真实世界NL驱动的特性添加任务中的基准，它包含来自10个项目的634项任务和11.4万次代码更改。每个任务将文档更新与相应的代码实现配对，并通过开发者编写的测试用例进行验证。一个由114个高质量、人工验证的实例组成的子集，即NoCode-bench Verified，确保了评估的可靠性。我们的实验表明，尽管代币使用量高，但最好的LLMs在任务中的成功率仅为15.79%，这突显了跨文件编辑、代码库理解和工具调用方面的挑战。这些发现表明，LLMs尚未准备好进行完全由NL驱动的无代码开发。NoCode-bench为该领域的未来进展奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [834] [Git Context Controller: Manage the Context of LLM-based Agents like Git](https://arxiv.org/abs/2508.00031)
> *Git 上下文控制器：像 Git 一样管理基于 LLM 的代理的上下文*

*Junde Wu* | **Category: cs.SE** | **Updated: 2025-07-30**

**Keywords:** LLM代理, 上下文管理, 版本控制, Git, 内存层次结构

**Comment:** in updating

> **TL;DR:** LLM代理的上下文管理是瓶颈，Git上下文控制器（GCC）提出像Git一样的版本化内存管理，显著提高代理在长期任务中的性能。

**AI_Comments:** 本文提出的GCC框架，通过将软件版本控制系统的概念引入到LLM代理的上下文管理中，提供了一种新颖且强大的解决方案。其创新点在于将上下文视为可版本化的内存层次结构，有效解决了长期任务中的记忆管理和鲁棒性问题。这一方法对于提升LLM代理在复杂、持久性任务中的应用潜力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）驱动的代理在长期工作流（例如为大型长期项目编码）中部署时，上下文管理成为一个关键瓶颈。

**Method:** 引入Git-Context-Controller（GCC），这是一个受软件版本控制系统启发的结构化上下文管理框架。GCC将上下文提升为像Git一样的版本化内存层次结构，将代理内存结构化为具有显式操作（COMMIT、BRANCH、MERGE和CONTEXT）的持久文件系统，从而实现基于里程碑的检查点、探索替代计划和结构化反思。

**Result:** 配备GCC的代理在SWE-Bench-Lite基准测试中取得了最先进的性能，解决了48.00%的软件错误，超越了26个竞争系统。在一个自我复制案例研究中，一个GCC增强代理从零开始构建了一个新的CLI代理，实现了40.7%的任务解决率，而没有GCC的只有11.7%。

**Conclusion:** GCC通过提供类似于Git的版本化上下文管理，显著提升了LLM代理在长期、复杂任务中的性能和鲁棒性，有效解决了上下文管理瓶颈。

> **ai_Abstract:** 本文介绍了Git-Context-Controller（GCC），一个受Git启发的结构化上下文管理框架，旨在解决大型语言模型（LLM）代理在长期工作流中面临的上下文管理瓶颈。GCC将代理内存视为版本化的持久文件系统，支持COMMIT、BRANCH、MERGE等操作，从而实现检查点、计划探索和记忆恢复。实验证明，GCC显著提升了LLM代理在软件错误修复和新代理构建任务上的性能，超越了现有方法。

> **摘要翻译:** 大型语言模型（LLM）驱动的代理通过将内部推理与外部工具使用相结合，展示了令人印象深刻的能力。然而，随着这些代理被部署在长期工作流中，例如为大型长期项目编码，上下文管理成为一个关键瓶颈。我们引入了Git-Context-Controller（GCC），这是一个受软件版本控制系统启发的结构化上下文管理框架。GCC将上下文提升为像Git一样的版本化内存层次结构。它将代理内存结构化为具有显式操作：COMMIT、BRANCH、MERGE和CONTEXT的持久文件系统，从而实现基于里程碑的检查点、探索替代计划和结构化反思。我们的方法使代理能够管理长期目标、隔离架构实验，并在会话和代理之间恢复或移交内存。经验上，配备GCC的代理在SWE-Bench-Lite基准测试中取得了最先进的性能，解决了48.00%的软件错误，超越了26个竞争系统。在一个自我复制案例研究中，一个GCC增强代理从零开始构建了一个新的CLI代理，实现了40.7%的任务解决率，而没有GCC的只有11.7%。代码已发布在：https://github.com/theworldofagents/GCC

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [838] [AutoBridge: Automating Smart Device Integration with Centralized Platform](https://arxiv.org/abs/2507.23178)
> *AutoBridge：自动化智能设备与中心化平台集成*

*Siyuan Liu, Zhice Yang, Huangxun Chen* | **Category: cs.SE, cs.AI, I.2.5** | **Updated: 2025-07-31**

**Keywords:** 物联网集成, 代码生成, 自动化, 智能设备, 调试

**Comment:** 14 pages, 12 figures, under review

> **TL;DR:** AutoBridge 是一种自动化物联网设备集成代码生成的工具，采用分而治之策略并结合多阶段调试，在测试中表现出高成功率和功能覆盖率，且优于专家程序员。

**AI_Comments:** AutoBridge 的创新之处在于其自动化物联网设备集成代码生成的能力，显著降低了集成复杂性和对人工专业知识的依赖。其分而治之策略和多阶段调试管道（特别是仅需二元反馈的硬件在环调试器）是其成功的关键。该研究的重要性在于它为构建更高效、更易于扩展的多模态物联网系统提供了解决方案，并且其在准确性方面超越专家程序员的性能，即使面对LLM的竞争，也凸显了其方法的强大和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 多模态物联网系统需要将新的物联网设备整合到中心化平台中，但这需要大量人工专业知识和精力来编写复杂的集成代码，以使平台理解和控制设备功能。

**Method:** AutoBridge 采用分而治之策略：首先通过逐步检索设备特定知识生成设备控制逻辑，然后利用平台特定知识合成符合平台的集成代码。为确保正确性，AutoBridge 包含一个多阶段调试流程，包括用于虚拟物联网设备测试的自动化调试器，以及一个仅需二元用户反馈（是/否）即可进行真实设备验证的交互式硬件在环调试器。

**Result:** AutoBridge 在包含34个物联网设备和两个开源物联网平台的基准测试中，实现了平均93.87%的成功率和94.87%的平均功能覆盖率，无需任何人工干预。在用户提供最少的二元反馈后，代码可达到100%的功能覆盖率。一项包含15名参与者的用户研究表明，即使专家程序员使用商业代码LLM，AutoBridge 在代码准确性方面仍比他们高出50%至80%。

**Conclusion:** AutoBridge 能够有效自动化物联网设备集成代码生成，显著提高集成效率和准确性，并减少对人工专业知识的依赖。

> **ai_Abstract:** AutoBridge 是一种旨在自动化物联网设备集成代码生成的工具，以解决将新设备整合到中心化平台时所需的大量人工编程工作。它采用分而治之的策略，通过检索设备和平台特定知识来生成代码，并通过多阶段调试流程（包括自动化和交互式硬件在环调试器）确保代码正确性。实验结果显示，AutoBridge 在自动化集成方面表现出色，无需人工干预即可达到高成功率和功能覆盖率，且在用户少量反馈下能实现100%覆盖。此外，用户研究表明其在代码准确性上显著优于专家程序员，即使他们使用商业代码LLM。

> **摘要翻译:** 多模态物联网系统协调各种物联网设备以提供以人为本的服务。将新物联网设备整合到中心化平台管理下的能力是一项基本要求。然而，这需要大量的人工专业知识和精力来编写复杂的物联网集成代码，以使平台能够理解和控制设备功能。因此，我们提出了AutoBridge来自动化物联网集成代码的生成。具体而言，AutoBridge采用分而治之的策略：它首先通过逐步检索设备特定知识来生成设备控制逻辑，然后利用平台特定知识合成符合平台的集成代码。为确保正确性，AutoBridge具有多阶段调试管道，包括用于虚拟物联网设备测试的自动化调试器，以及一个仅需二元用户反馈（是和否）即可进行真实设备验证的交互式硬件在环调试器。我们在包含34个物联网设备和两个开源物联网平台的基准测试中评估了AutoBridge。结果表明，AutoBridge在没有任何人工参与的情况下，实现了平均93.87%的成功率和平均94.87%的功能覆盖率。在用户提供最少的二元“是”和“否”反馈后，代码可以修订到100%的功能覆盖率。一项包含15名参与者的用户研究进一步表明，即使程序员被允许使用商业代码LLM，AutoBridge在代码准确性方面仍比专家程序员高出50%到80%。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [854] [Insights into resource utilization of code small language models serving with runtime engines and execution providers](https://arxiv.org/abs/2412.15441)
> *代码小型语言模型与运行时引擎和执行提供程序服务时的资源利用率洞察*

*Francisco Durán, Matias Martinez, Patricia Lago, Silverio Martínez-Fernández* | **Category: cs.SE, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 小型语言模型, 资源利用率, 能耗, 运行时引擎, 执行提供程序

**Comment:** Accepted in Journal of Systems and Software (JSS). For its published
  version refer to the Journal of JSS

> **TL;DR:** 本文分析了不同运行时引擎和执行提供程序组合对代码小型语言模型（SLMs）资源利用率（能耗、执行时间、计算资源）的影响，发现CUDA提供程序优于CPU，其中TORCH+CUDA组合在能效和计算资源利用方面表现最佳。

**AI_Comments:** 该论文通过量化分析不同服务配置对代码SLM资源利用率的影响，为软件工程师在实际部署中选择优化方案提供了具体的指导和数据支持。其创新点在于系统性地比较了多种运行时引擎和执行提供程序，并量化了能耗和执行时间上的差异。研究结果对于降低AI推理的碳足迹和运营成本具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LMs）的快速增长，尤其是在代码生成领域，需要大量的计算资源，这引发了对能耗和环境影响的担忧。优化语言模型推理资源利用率至关重要，而小型语言模型（SLMs）为降低资源需求提供了有前景的解决方案。

**Method:** 研究人员采用了一种面向技术的多阶段实验流程，使用十二个代码生成SLMs，调查了不同配置（运行时引擎和执行提供程序组合）下的能耗、执行时间和计算资源利用率。

**Result:** 各配置之间存在显著差异。CUDA执行提供程序配置在能耗和执行时间方面均优于CPU执行提供程序配置。在所有配置中，TORCH与CUDA配对展示出最高的能效，相较于其他服务配置，实现了37.99%至89.16%的节能。同样，ONNX与CPU执行提供程序等优化的运行时引擎在基于CPU的配置中实现了8.98%至72.04%的节能。此外，TORCH与CUDA配对还表现出高效的计算资源利用率。

**Conclusion:** 服务配置的选择显著影响资源利用率。虽然需要进一步研究，但TORCH+CUDA和ONNX+CPU等配置最适合软件工程师提高服务资源利用效率的需求。

> **ai_Abstract:** 本研究分析了代码小型语言模型（SLMs）在不同深度学习服务配置（运行时引擎与执行提供程序的组合）下的资源利用率。通过对12个代码生成SLMs进行实验，发现CUDA执行提供程序在能耗和执行时间上优于CPU。具体而言，TORCH与CUDA的组合在能效上表现最佳，实现了显著的节能，并且计算资源利用率高。ONNX与CPU的组合也在CPU配置中实现了节能。研究强调服务配置对资源利用率有重要影响，并推荐了适合软件工程师提升效率的配置。

> **摘要翻译:** 语言模型的快速增长，尤其是在代码生成领域，需要大量的计算资源，这引发了对能耗和环境影响的担忧。优化语言模型推理资源利用率至关重要，而小型语言模型（SLMs）为降低资源需求提供了有前景的解决方案。我们的目标是从软件工程师进行代码生成SLMs推理的角度，分析深度学习服务配置（定义为运行时引擎和执行提供程序的组合）对资源利用率（包括能耗、执行时间和计算资源利用率）的影响。我们采用了一种面向技术的多阶段实验流程，使用十二个代码生成SLMs，调查了不同配置下的能耗、执行时间和计算资源利用率。各配置之间出现了显著差异。CUDA执行提供程序配置在能耗和执行时间方面均优于CPU执行提供程序配置。在所有配置中，TORCH与CUDA配对展示出最高的能效，相较于其他服务配置，实现了37.99%至89.16%的节能。同样，ONNX与CPU执行提供程序等优化的运行时引擎在基于CPU的配置中实现了8.98%至72.04%的节能。此外，TORCH与CUDA配对还表现出高效的计算资源利用率。服务配置的选择显著影响资源利用率。虽然需要进一步研究，但我们推荐上述配置最适合软件工程师提高服务资源利用效率的需求。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [862] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
> *GPT-4.1 使用新型Python库在自动化实验设计中树立标准*

*Nuno Fachada, Daniel Fernandes, Carlos M. Fernandes, Bruno D. Ferreira-Saraiva, João P. Matos-Carvalho* | **Category: cs.SE, cs.AI, cs.CL, 68T50, I.2.2; I.2.7; D.2.3** | **Updated: 2025-07-30**

**Keywords:** LLMs, 自动化实验设计, Python库, 代码生成, 基准测试, GPT-4.1

**Comment:** 

> **TL;DR:** 本研究系统地评估了大型语言模型（LLMs）在自动化科学实验代码生成方面的能力，特别是它们解释和使用不熟悉Python API的情况。结果显示GPT-4.1在所有测试任务中表现出色，但同时也揭示了LLMs在端到端科学自动化方面的局限性以及对精心设计的提示和完善的库文档的需求。

**AI_Comments:** 本文为LLMs在科学自动化中的实际应用提供了一个有价值的基准，特别是它们与新API的交互能力。识别出GPT-4.1作为顶尖表现者具有重要意义。该研究在基准测试LLMs的同时，也揭示了第三方库的不足，这种双重效益是其创新之处。它为LLM的未来发展和科学工具设计提供了关键见解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在科学研究中作为自动化代码生成的工具发展迅速，但它们解释和使用不熟悉的Python API进行复杂计算实验的能力仍未得到很好的表征。

**Method:** 本研究系统地基准测试了一系列最先进的LLMs，以生成功能性Python代码，用于两个日益具有挑战性的场景：使用ParShift库进行对话式数据分析，以及使用pyclugen和scikit-learn进行合成数据生成和聚类。两个实验都使用结构化的零样本提示，指定了详细要求但省略了上下文示例。模型输出通过多次运行的功能正确性和提示符合性进行定量评估，并通过分析代码执行失败时产生的错误进行定性评估。

**Result:** 结果表明，只有一小部分模型能持续生成正确、可执行的代码，其中GPT-4.1是唯一一个在两项任务中都能始终成功的模型。除了基准测试LLM性能外，这种方法还有助于识别第三方库的缺点，例如不清晰的文档或模糊的实现错误。

**Conclusion:** 总体而言，这些发现突出了LLMs在端到端科学自动化方面的当前局限性，并强调了精心设计提示、全面库文档以及语言模型能力持续进步的必要性。

> **ai_Abstract:** 本文对最先进的大型语言模型（LLMs）在利用不熟悉API（如ParShift、pyclugen和scikit-learn）生成复杂科学任务的Python代码方面的能力进行了基准测试。研究采用零样本提示，并量化评估了代码的正确性和符合性。结果显示GPT-4.1在所有任务中均表现出色，并揭示了部分第三方库文档的不足。论文强调了LLMs在端到端科学自动化方面的当前局限性，并指出了改进提示设计、库文档和LLM能力的必要性。

> **摘要翻译:** 大型语言模型（LLMs）作为科学研究中自动化代码生成的工具发展迅速，然而它们解释和使用不熟悉的Python API进行复杂计算实验的能力仍然表征不足。本研究系统地基准测试了一系列最先进的LLMs，以生成功能性Python代码，用于两个日益具有挑战性的场景：使用ParShift库进行对话式数据分析，以及使用pyclugen和scikit-learn进行合成数据生成和聚类。这两个实验都使用结构化的零样本提示，指定了详细要求但省略了上下文示例。模型输出通过多次运行的功能正确性和提示符合性进行定量评估，并通过分析代码执行失败时产生的错误进行定性评估。结果表明，只有一小部分模型能持续生成正确、可执行的代码，其中GPT-4.1是唯一一个在两项任务中都能始终成功的模型。除了基准测试LLM性能外，这种方法还有助于识别第三方库的缺点，例如不清晰的文档或模糊的实现错误。总体而言，这些发现突出了LLMs在端到端科学自动化方面的当前局限性，并强调了精心设计提示、全面库文档以及语言模型能力持续进步的必要性。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [890] [Machine Learning Pipeline for Software Engineering: A Systematic Literature Review](https://arxiv.org/abs/2508.00045)
> *软件工程中的机器学习流水线：一项系统性文献综述*

*Samah Kansab* | **Category: cs.SE** | **Updated: 2025-07-31**

**Keywords:** 机器学习流水线, 软件工程, 系统性文献综述, 缺陷预测, 质量

**Comment:** 

> **TL;DR:** 该系统性文献综述（SLR）考察了为软件工程（SE）设计的最新机器学习（ML）流水线，总结了最佳实践、挑战和空白，并强调了精心设计的ML流水线对于解决SE挑战的重要性。

**AI_Comments:** 该研究通过系统性文献综述，全面梳理了软件工程中机器学习流水线的现状、最佳实践、挑战和趋势。其价值在于为研究人员和实践者提供了关于ML在SE中应用的结构化知识和可操作的见解，有助于推动ML在复杂软件开发环境中的有效采纳和创新。其创新性在于对ML流水线各阶段的深入分析和总结，而不仅仅是单一的ML算法应用。

<details>
  <summary>Details</summary>

**Motivation:** 软件开发实践的快速进步给软件工程（SE）生命周期中的质量和效率带来了挑战。随着SE系统日益复杂，传统方法难以扩展，导致调试时间延长、缺陷检测效率低下以及开发周期资源密集。机器学习（ML）已成为一个关键解决方案，可实现缺陷预测、代码审查和发布质量评估等任务的自动化。然而，ML在SE中的有效性取决于其流水线的稳健性，包括数据收集、预处理、特征工程、算法选择、验证和评估。

**Method:** 本研究采用系统性文献综述（SLR）的方法，考察了为软件工程（SE）设计的最新机器学习（ML）流水线，并整合了最佳实践、挑战和空白。

**Result:** 研究发现，SMOTE等稳健的预处理方法用于数据平衡，以及基于SZZ的算法用于特征选择，可以提高模型可靠性。随机森林和梯度提升等集成方法在各项任务中表现最佳，而朴素贝斯等简单模型在效率和可解释性方面仍具价值。AUC、F1-score和精确率是最常见的评估指标，而像最佳算术平均（BAM）这样的新指标则出现在小众应用中。引导法等验证技术被广泛用于确保模型的稳定性和泛化能力。

**Conclusion:** 本系统性文献综述强调了精心设计的机器学习流水线对于解决软件工程挑战的重要性，并为寻求优化软件质量和效率的研究人员和实践者提供了可操作的见解。通过识别空白和趋势，本研究为在日益复杂的开发环境中推进机器学习应用和促进创新奠定了基础。

> **ai_Abstract:** 本系统性文献综述（SLR）探讨了软件工程（SE）中机器学习（ML）流水线的最新进展。面对SE日益增长的复杂性，传统方法难以应对，ML提供了自动化解决方案。研究强调了稳健的ML流水线的重要性，涵盖数据预处理、特征工程、算法选择、验证和评估。SLR的发现包括SMOTE和SZZ等预处理技术对模型可靠性的提升，随机森林和梯度提升等集成方法在性能上的主导地位，以及AUC、F1-score等常见评估指标。研究最终强调了精心设计的ML流水线在解决SE挑战中的关键作用，并为优化软件质量和效率提供了实用指导。

> **摘要翻译:** 软件开发实践的快速进步给软件工程（SE）生命周期中的质量和效率带来了挑战。随着SE系统日益复杂，传统方法往往难以扩展，导致调试时间延长、缺陷检测效率低下以及开发周期资源密集。机器学习（ML）已成为一个关键解决方案，可实现缺陷预测、代码审查和发布质量评估等任务的自动化。然而，ML在SE中的有效性取决于其流水线的稳健性，包括数据收集、预处理、特征工程、算法选择、验证和评估。
  本系统性文献综述（SLR）考察了为SE设计的最新ML流水线，整合了最佳实践、挑战和空白。我们的研究结果表明，稳健的预处理，如用于数据平衡的SMOTE和用于特征选择的基于SZZ的算法，可以提高模型可靠性。随机森林和梯度提升等集成方法在各项任务中表现最佳，而朴素贝斯等简单模型在效率和可解释性方面仍具价值。AUC、F1-score和精确率等评估指标最为常见，而像最佳算术平均（BAM）这样的新指标则出现在小众应用中。引导法等验证技术被广泛用于确保模型的稳定性和泛化能力。
  本SLR强调了精心设计的ML流水线对于解决SE挑战的重要性，并为寻求优化软件质量和效率的研究人员和实践者提供了可操作的见解。通过识别空白和趋势，本研究为在日益复杂的开发环境中推进ML应用和促进创新奠定了基础。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [928] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
> *基于LLM代理的代码生成综述*

*Yihong Dong, Xue Jiang, Jiaru Qian, Tian Wang, Kechi Zhang, Zhi Jin, Ge Li* | **Category: cs.SE, cs.AI, cs.CL, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 代码生成, LLM代理, 软件开发生命周期, 综述, 人工智能

**Comment:** Work in progress

> **TL;DR:** 本文综述了基于大型语言模型（LLM）的代码生成代理，涵盖其核心特征、技术、应用、评估基准和未来研究方向。

**AI_Comments:** 这篇综述论文的重要性在于它系统地整理了LLM驱动的代码生成代理这一快速发展的新兴领域。它不仅清晰地界定了此类代理的核心特征，还全面梳理了其技术发展、应用、评估方法和工具，并指明了未来的研究方向，为该领域的学者和实践者提供了宝贵的参考框架。

<details>
  <summary>Details</summary>

**Motivation:** 代码生成代理正在彻底改变软件开发范式，该领域发展迅速且研究爆炸式增长，具有巨大的应用潜力，因此有必要进行系统性综述。

**Method:** 本文对基于LLM的代码生成代理领域进行了系统性综述，追溯了技术发展轨迹，系统分类了核心技术（包括单代理和多代理架构），详细介绍了LLM代理在软件开发生命周期（SDLC）中的应用，总结了主流评估基准和指标，并收录了代表性工具。

**Result:** 本综述系统地梳理了基于LLM的代码生成代理领域，包括其发展历程、核心技术分类、在SDLC中的应用、评估基准与工具，并识别了主要挑战。

**Conclusion:** 通过分析主要挑战，本文识别并提出了该领域未来工作的几个基础性、长期研究方向。

> **ai_Abstract:** 本文对基于大型语言模型（LLM）的代码生成代理进行了系统性综述。该综述首先阐述了LLM代理在代码生成方面的三大核心特征：自主性、扩展的任务范围和增强的工程实用性。接着，文章追溯了该技术的发展历程，并对核心技术（包括单代理和多代理架构）进行了系统分类。此外，综述还详细探讨了LLM代理在整个软件开发生命周期（SDLC）中的应用，总结了主流评估基准和指标，并列举了代表性工具。最后，文章分析了当前面临的主要挑战，并为未来的研究工作提出了基础性、长期性的方向。

> **摘要翻译:** 大型语言模型（LLM）驱动的代码生成代理正在彻底改变软件开发范式。与之前的代码生成技术不同，代码生成代理具有三个核心特征：1）自主性：独立管理从任务分解到编码和调试的整个工作流程的能力。2）扩展的任务范围：能力超越生成代码片段，涵盖整个软件开发生命周期（SDLC）。3）工程实用性的增强：研究重点从算法创新转向实际工程挑战，如系统可靠性、过程管理和工具集成。该领域最近发展迅速，研究爆炸式增长，展现出巨大的应用潜力。本文对基于LLM的代码生成代理领域进行了系统性综述。我们追溯了该技术从诞生至今的发展轨迹，并系统地分类了其核心技术，包括单代理和多代理架构。此外，本综述详细介绍了基于LLM的代理在整个SDLC中的应用，总结了主流评估基准和指标，并收录了代表性工具。最后，通过分析主要挑战，我们识别并提出了该领域未来工作的几个基础性、长期研究方向。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [26] [A Novel Dynamic Epidemic Model for Successive Opinion Diffusion in Social Networks](https://arxiv.org/abs/2504.01718)
> *社交网络中连续意见扩散的新型动态流行病模型*

*Bin Han, Fabienne Renckens, C. Clark Cao, Hans D. Schotten* | **Category: cs.SI** | **Updated: 2025-07-31**

**Keywords:** 意见扩散, 动态流行病模型, 社交网络, SHIMR模型, 回音室效应

**Comment:** To appear in IEEE GLOBECOM 2025

> **TL;DR:** 本文提出了一个扩展SHIMR模型的新型动态流行病模型，用于模拟社交网络中受社会距离和相关谣言影响的连续意见扩散，并解释了回音室效应。

**AI_Comments:** 该论文通过扩展现有的流行病模型，引入社会距离和累积谣言扩散的概念，为社交网络中的意见扩散建模提供了一个新颖的视角。其创新点在于将动态决策和多重谣言影响纳入模型，有助于更真实地模拟复杂社会现象，如回音室效应和极化。这对于理解和预测社交媒体中的信息传播具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 理解社交网络中的意见扩散动力学，特别是连续意见扩散、社会距离影响下的动态决策以及相关谣言引起的累积效应，并解释如回音室效应等现象。

**Method:** 本文提出了一个动态流行病模型，扩展了SHIMR模型，并纳入了受社会距离影响的动态决策以及由相互关联谣言引起的累积意见扩散。该模型还反映了谣言传播对社交网络结构的影响。

**Result:** 模拟验证了该模型在解释回音室效应等现象方面的有效性，并提供了对意见扩散动力学的见解。

**Conclusion:** 该模型有助于理解社会极化和网络演化，对于解释社交网络中的意见扩散现象具有重要意义。

> **ai_Abstract:** 本文提出了一种新颖的动态流行病模型，用于模拟社交网络中连续意见扩散。该模型是SHIMR模型的扩展，整合了受社会距离影响的动态决策和由相关谣言导致的累积意见扩散，并考虑了谣言传播对网络结构的影响。模拟结果验证了模型在解释回音室效应等现象方面的有效性，并为理解意见扩散动力学、社会极化和网络演化提供了见解。

> **摘要翻译:** 本文提出了一种用于社交网络中连续意见扩散的动态流行病模型，扩展了SHIMR模型。它结合了受社会距离影响的动态决策，并捕捉了由相互关联谣言引起的累积意见扩散。该模型反映了谣言传播对社交网络结构的影响。模拟验证了其在解释回音室效应等现象方面的有效性，并提供了对意见扩散动力学的见解，对理解社会极化和网络演化具有启示。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [453] [Constructing and Sampling Directed Graphs with Linearly Rescaled Degree Matrices](https://arxiv.org/abs/2507.23025)
> *使用线性重标度度矩阵构建和采样有向图*

*Yunxiang Yan, Meng Jiang* | **Category: cs.SI, cs.DM** | **Updated: 2025-07-30**

**Keywords:** 有向图, 采样, 联合度矩阵, 度相关矩阵, 度分布

**Comment:** SIGKDD 2022

> **TL;DR:** 该论文提出了一种新的有向图采样算法，通过使用线性重标度联合度矩阵（JDM）和度相关矩阵（DCM）来构建样本图，该算法能够可证明地保留入度和出度分布，并有望在实际大型有向网络上表现出色。

**AI_Comments:** 这篇论文的创新点在于提出了一个基于线性重标度JDM和DCM的有向图采样框架，并设计了一种能够可证明地保留图基本属性（入度和出度分布）的采样算法。其重要性在于为大型有向网络的分析提供了一种潜在的、更高效的替代方案，特别是在处理社交网络等大规模数据集时。通过证明偏差与矩阵稀疏性负相关，该研究为算法在实际应用中的优异表现提供了理论支持，克服了传统图算法的计算瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 对大型有向网络的分析通常耗时且昂贵，因为许多图算法的复杂性与图的大小呈多项式关系。因此，能够生成保留原始图属性的采样算法至关重要，因为它们可以加速分析过程。

**Method:** 本文提出了一种有前景的有向图采样框架：使用线性重标度联合度矩阵（JDM）和度相关矩阵（DCM）构建样本图。在此框架下，提出了一种新颖的图采样算法，该算法可证明地保留入度和出度分布。同时，还证明了联合度分布和度相关分布偏差的上限，并证明了这些偏差与JDM和DCM的稀疏性呈负相关。

**Result:** 实验表明，与边和节点的数量相比，JDM和DCM中非零项的数量非常小。该算法可证明地保留了入度和出度分布。同时，证明了联合度分布和度相关分布偏差的上限，并且这些偏差与JDM和DCM的稀疏性呈负相关。

**Conclusion:** 考虑到联合度矩阵（JDM）和度相关矩阵（DCM）总是非常稀疏，本文提出的算法有望在实际大型有向网络上表现出优于理论的性能。

> **ai_Abstract:** 本研究提出了一种用于大型有向图采样的创新框架，旨在解决现有图分析方法计算成本高昂的问题。该框架通过构建具有线性重标度联合度矩阵（JDM）和度相关矩阵（DCM）的样本图，并提出了一种新颖的采样算法。该算法能够可证明地保留图的入度和出度分布，并提供了联合度分布和度相关分布偏差的上限证明。鉴于JDM和DCM在实际网络中表现出的稀疏性，该方法有望在实际大型有向网络中实现高效且高性能的采样。

> **摘要翻译:** 近年来，借助强大的数据工程和数据存储技术，收集了许多大型有向网络，例如在线社交网络。对此类网络的分析吸引了学术界和工业界的广泛关注。然而，大型有向网络的分析通常耗时且昂贵，因为许多图算法的复杂性通常与图的大小呈多项式关系。因此，能够生成保留原始图属性的采样算法至关重要，因为它们可以加速分析过程。我们提出了一种有前景的有向图采样框架：使用线性重标度联合度矩阵（JDM）和度相关矩阵（DCM）构建样本图。先前的研究表明，具有相同JDM和DCM的图将具有一系列非常相似的图属性。我们还在真实世界数据集上进行了实验，结果表明，与边和节点的数量相比，JDM和DCM中非零项的数量非常小。采用此框架，我们提出了一种新颖的图采样算法，该算法可证明地保留了入度和出度分布，这是图的两个最基本的属性。我们还证明了联合度分布和度相关分布（对应于JDM和DCM）偏差的上限。此外，我们证明了这些分布的偏差与JDM和DCM的稀疏性呈负相关。考虑到这两个矩阵总是非常稀疏，我们相信所提出的算法将在真实世界的大型有向网络上表现出优于理论的性能。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [897] [From Individuals to Crowds: Dual-Level Public Response Prediction in Social Media](https://arxiv.org/abs/2508.00497)
> *从个体到群体：社交媒体中双层公共响应预测*

*Jinghui Zhang, Kaiyang Wan, Longwei Xu, Ao Li, Zongfang Liu, Xiuying Chen* | **Category: cs.SI** | **Updated: 2025-08-01**

**Keywords:** 公共响应预测, 社交媒体, 双层预测, SocialAlign, 情感分析

**Comment:** ACM MM 2025

> **TL;DR:** 本文提出了SocialAlign框架，一个统一的双层模型，用于在社交媒体中预测个体层面的个性化公共响应和宏观层面的群体情感分布，并通过引入新数据集SentiWeibo验证了其优越性。

**AI_Comments:** 该论文的创新点在于提出了一个双层（个体和群体）的公共响应预测框架SocialAlign，解决了现有模型在个性化响应和宏观情感趋势分析方面的局限性。引入PAC-LoRA结构实现个性化生成，并结合大模型（SocialLLM）进行内容分析和响应生成是其技术亮点。此外，构建大规模真实世界数据集SentiWeibo也为该领域的研究提供了宝贵的资源。这项工作对危机管理、政策制定和社交媒体分析具有重要实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 公共响应预测对于危机管理、政策制定和社交媒体分析至关重要。然而，现有工作存在两个主要局限性：一是缺乏微观层面的个性化，导致生成的响应过于通用，忽视了用户偏好；二是忽视了宏观层面的情感分布，只处理个体层面的情感，从而限制了对更广泛社会趋势和群体情感动态的分析。

**Method:** 我们提出了SocialAlign，一个统一的框架，用于在社交情境中预测微观和宏观层面的真实世界响应。在微观层面，SocialAlign利用带有可表达的个性化分析-组合LoRA（PAC-LoRA）结构的SocialLLM，部署了专门的专家模块，用于跨不同主题和用户配置文件的内容分析和响应生成，从而能够生成带有相应情感的个性化评论。在宏观层面，它对群体情感分布进行建模，并将预测结果与来自社交媒体数据的真实情感趋势对齐。为了在真实世界场景中评估SocialAlign，我们引入了SentiWeibo，一个从微博平台真实社交互动中整理出的大规模数据集。

**Result:** 在我们的SentiWeibo和相关LaMP基准测试中，实验结果表明SocialAlign超越了强大的基线，在公共响应预测方面显示出更高的准确性、可解释性和泛化能力。

**Conclusion:** SocialAlign成功解决了现有公共响应预测方法在个性化和宏观趋势分析方面的局限性，通过其独特的双层预测机制，提供了更准确、可解释和泛化的结果。这项工作有望启发公共响应预测和计算社会科学的进一步研究。

> **ai_Abstract:** 本文提出了一种名为SocialAlign的统一框架，旨在解决现有公共响应预测模型在个性化和宏观趋势分析方面的不足。SocialAlign采用双层预测机制：在微观层面，利用SocialLLM和PAC-LoRA结构生成个性化评论和情感；在宏观层面，建模并对齐群体情感分布。为评估模型，作者构建了SentiWeibo大规模数据集。实验结果表明，SocialAlign在准确性、可解释性和泛化能力上均优于现有基线，为公共响应预测和计算社会科学提供了新的方向。

> **摘要翻译:** 公共响应预测对于理解个体或群体如何对特定事件、政策或社会现象做出反应至关重要，这使其在危机管理、政策制定和社交媒体分析中具有高度价值。然而，现有工作面临着显著的局限性。首先，它们缺乏微观层面的个性化，产生通用的响应，忽视了个体用户偏好。此外，它们忽视了宏观层面的情感分布，只处理个体层面的情感，限制了它们分析更广泛的社会趋势和群体情感动态的能力。为了解决这些挑战，我们提出了SocialAlign，一个统一的框架，用于在社交情境中预测微观和宏观层面的真实世界响应。在微观层面，SocialAlign利用带有可表达的个性化分析-组合LoRA（PAC-LoRA）结构的SocialLLM，部署了专门的专家模块，用于跨不同主题和用户配置文件的内容分析和响应生成，从而能够生成带有相应情感的个性化评论。在宏观层面，它对群体情感分布进行建模，并将预测结果与来自社交媒体数据的真实情感趋势对齐。为了在真实世界场景中评估SocialAlign，我们引入了SentiWeibo，一个从微博平台真实社交互动中整理出的大规模数据集。在我们的SentiWeibo和相关LaMP基准测试中，实验结果表明SocialAlign超越了强大的基线，在公共响应预测方面显示出更高的准确性、可解释性和泛化能力。我们希望我们的工作能启发公共响应预测和计算社会科学的进一步研究：https://github.com/Znull-1220/SocialAlign。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [923] [Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation](https://arxiv.org/abs/2507.21903)
> *谁是重要的？——SUnSET：利益相关者、事件和时间的协同理解，用于时间线生成*

*Tiviatis Sim, Kaiwen Yang, Shen Xin, Kenji Kawaguchi* | **Category: cs.SI, cs.CL, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 时间线摘要, 利益相关者, 大型语言模型, 新闻报道, 事件跟踪

**Comment:** 

> **TL;DR:** SUnSET是一个新的框架，通过协同理解利益相关者、事件和时间，利用大型语言模型和基于利益相关者的排名来构建时间线摘要，显著优于现有基线。

**AI_Comments:** 该论文的创新点在于提出了SUnSET框架，通过协同分析利益相关者、事件和时间来改进时间线摘要，尤其引入了基于利益相关者的排名来量化其重要性。这弥补了现有方法仅关注文本内容而忽略参与者分析的不足，对于理解复杂新闻事件的深层关联具有重要意义。其超越现有基线的实验结果证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有新闻摘要方法在处理多源事件跟踪时面临挑战，且通常只考虑文本内容，缺乏对参与方（利益相关者）的分析，导致无法有效理解事件要旨。

**Method:** 本文提出了SUnSET框架（Synergistic Understanding of Stakeholder, Events and Time），利用大型语言模型（LLMs）构建SET三元组，并引入基于利益相关者的排名来构建一个可扩展的“Relevancy”度量，用于时间线摘要（TLS）任务。

**Result:** 实验结果表明，SUnSET超越了所有先前的基线，成为新的最先进技术（State-of-the-Art），突出了新闻文章中利益相关者信息的重要性。

**Conclusion:** 通过SUnSET框架，本文证明了在新闻文章中整合利益相关者信息对于时间线摘要任务的有效性和重要性，并显著提升了性能。

> **ai_Abstract:** 本研究提出SUnSET框架，旨在解决现有新闻摘要方法在多源事件跟踪和利益相关者分析方面的不足。SUnSET利用大型语言模型构建利益相关者、事件和时间（SET）三元组，并通过引入基于利益相关者的排名来计算“Relevancy”度量，以生成更有效的时间线摘要。实验结果显示，SUnSET在时间线摘要任务上超越了所有现有基线，达到了最先进的性能，强调了新闻报道中利益相关者信息的关键作用。

> **摘要翻译:** 随着新闻报道在全球范围内的日益普及和在线去中心化，跨多个来源跟踪相关事件带来了重大挑战。现有新闻摘要方法通常在基于文章的摘要上利用大型语言模型和图形方法。然而，这种方法并不有效，因为它只考虑日期相似文章的文本内容来理解事件的要旨。为了弥补对所涉各方分析的不足，提出一种新颖的框架来衡量利益相关者的重要性以及通过相关实体连接相关事件至关重要。因此，我们提出了SUnSET：利益相关者、事件和时间的协同理解，用于时间线摘要（TLS）任务。我们利用强大的大型语言模型（LLMs）构建SET三元组，并引入了基于利益相关者的排名来构建一个“Relevancy”度量，该度量可以扩展到一般情况。我们的实验结果优于所有先前的基线，并成为新的最先进技术，突出了新闻文章中利益相关者信息的影响。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [12] [OpenACE: An Open Benchmark for Evaluating Audio Coding Performance](https://arxiv.org/abs/2409.08374)
> *OpenACE：一个用于评估音频编码性能的开放基准*

*Jozef Coldenhoff, Niclas Granqvist, Milos Cernak* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** 音频编码, 语音编码, 评估基准, 开源, OpenACE

**Comment:** ICASSP 2025

> **TL;DR:** OpenACE提出了一个开放且可复现的全频带音频和语音编码质量基准，以解决当前评估缺乏统一性和开放性的问题，并展示了其在多种编解码器上的应用。

**AI_Comments:** OpenACE的创新之处在于它提供了一个开放且可复现的基准，解决了当前音频和语音编码评估中数据私有、不可复现以及ML编解码器测试偏差的问题。这对于推动该领域的公平比较和进展非常重要。其开放性将有助于社区协作和标准化。

<details>
  <summary>Details</summary>

**Motivation:** 当前的音频和语音编码评估缺乏统一的评价标准和开源测试，许多系统在专有、不可复现或小规模数据上进行评估。基于机器学习的编解码器常在与其训练数据分布相似的数据集上测试，这与基于数字信号处理的编解码器（通常能很好地处理未见数据）相比是不公平的。

**Method:** 本文提出了一个全频带音频和语音编码质量基准，包含更多可变内容类型，包括传统的开放测试向量。它展示了一个音频编码质量评估的用例，使用了开源的Opus、3GPP的EVS以及最近ETSI的LC3和LC3+。此外，还展示了16 kbps情感语音编码的质量变化。

**Result:** 提出了一个名为OpenACE的开放源码基准，其可用于评估全频带音频和语音编码质量。该基准包含更多样化的内容类型和开放测试向量。通过使用Opus、EVS、LC3和LC3+等编解码器展示了其在音频编码质量评估中的应用，并展示了情感语音编码的质量变化。

**Conclusion:** 该开放源码基准有助于音频和语音编码的民主化，并解决了当前评估中缺乏统一性和开放性的问题。

> **ai_Abstract:** OpenACE是一个旨在解决当前音频和语音编码评估中缺乏统一性和开放性问题的开放基准。它提供了一个全频带音频和语音编码质量评估平台，包含多样化的内容和传统测试向量。论文通过评估Opus、EVS、LC3和LC3+等编解码器，并分析情感语音编码的质量变化，展示了其应用。该开源基准旨在促进音频和语音编码的民主化。

> **摘要翻译:** 音频和语音编码缺乏统一的评估和开源测试。许多候选系统在专有、不可复现或小数据上进行评估，而基于机器学习的编解码器通常在与其训练数据分布相似的数据集上进行测试，这与通常能很好地处理未见数据的基于数字信号处理的编解码器相比是不公平的。本文提出了一个全频带音频和语音编码质量基准，包含更多可变的内容类型，包括传统的开放测试向量。一个音频编码质量评估的示例用例展示了开源的Opus、3GPP的EVS以及最近ETSI的LC3和蓝牙LE音频配置文件中使用的LC3+。此外，还显示了16 kbps情感语音编码的质量变化。所提出的开源基准有助于音频和语音编码的民主化，并可在https://github.com/JozefColdenhoff/OpenACE 获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [313] [Melody-Lyrics Matching with Contrastive Alignment Loss](https://arxiv.org/abs/2508.00123)
> *旋律-歌词匹配与对比对齐损失*

*Changhong Wang, Michel Olvera, Gaël Richard* | **Category: eess.AS, cs.IR** | **Updated: 2025-07-31**

**Keywords:** 旋律-歌词匹配, 自监督学习, 对比学习, 音乐信息检索, 音节表示

**Comment:** 10 pages, 7 figures, 3 tables. This work has been submitted to the
  IEEE for possible publication

> **TL;DR:** 提出了一种新的旋律-歌词匹配任务（MLM），利用自监督表示学习框架和对比对齐损失，无需对齐标注即可为给定旋律检索潜在歌词，并引入了音节级歌词表示。

**AI_Comments:** 这项工作提出了一种新颖且有挑战性的任务——旋律-歌词匹配，超越了传统的歌词生成或音乐-文本检索。其创新点在于采用了自监督学习框架和对比对齐损失，显著降低了对昂贵对齐标注的需求，这对于利用大规模未标注数据至关重要。引入的“sylphone”音节级歌词表示也很有趣，它捕捉了歌词中与音乐节奏和重音相关的语言学特征。该方法为音乐信息检索领域开辟了新的研究方向，特别是在歌词与旋律的深层结构性关联方面。

<details>
  <summary>Details</summary>

**Motivation:** 音乐与歌词之间的联系超越了语义，在节奏、韵律、音符时长、音节重音和结构对应等方面存在概念配对，这是音乐信息检索领域一个引人注目但鲜有探索的方向。

**Method:** 提出了一种新的任务——旋律-歌词匹配（MLM），旨在为给定符号旋律从文本源中检索潜在歌词。采用了一个自监督表示学习框架，并结合了对比对齐损失，用于旋律和歌词的表示学习，无需对齐标注。此外，引入了一种名为“sylphone”的新型音节级歌词表示，该表示由音素身份和元音重音激活。

**Result:** 实验结果和直观示例表明，该方法能够将旋律与连贯且可唱的歌词进行匹配。

**Conclusion:** 该研究成功提出了旋律-歌词匹配任务及其对应的自监督学习框架和新型歌词表示，有效利用了旋律和歌词间的深层关系，实现了无需对齐标注的歌词检索。

> **ai_Abstract:** 本文介绍了一项名为旋律-歌词匹配（MLM）的新任务，旨在为给定旋律检索合适的歌词。研究提出了一种无需对齐标注的自监督表示学习框架，该框架利用对比对齐损失来学习旋律和歌词之间的关系。此外，论文还引入了一种基于音素身份和元音重音的音节级歌词表示“sylphone”。实验证明，该方法能有效匹配旋律与连贯且可唱的歌词。

> **摘要翻译:** 音乐与歌词之间的联系远不止语义上的关联。两种模态中诸如节奏与韵律、音符时长与音节重音以及结构对应等概念对，在音乐信息检索领域提出了一个引人注目但鲜有探索的方向。在本文中，我们提出了旋律-歌词匹配（MLM），这是一项新任务，旨在为给定的符号旋律从文本源中检索潜在歌词。MLM并非从零开始生成歌词，而是本质上利用了旋律和歌词之间的关系。我们提出了一个带有对比对齐损失的自监督表示学习框架，用于旋律和歌词。这有可能利用现有大量带有配对旋律和歌词的歌曲。不需要对齐标注。此外，我们引入了sylphone，这是一种由音素身份和元音重音激活的音节级歌词新型表示。我们通过实证结果和直观示例证明，我们的方法可以将旋律与连贯且可唱的歌词进行匹配。我们开源了代码并在配套网页上提供了匹配示例：https://github.com/changhongw/mlm。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [348] [Dynamic Real-Time Ambisonics Order Adaptation for Immersive Networked Music Performances](https://arxiv.org/abs/2508.00509)
> *沉浸式网络音乐表演中动态实时声场技术阶数自适应*

*Paolo Ostan, Carlo Centofanti, Mirco Pezzoli, Alberto Bernardini, Claudia Rinaldi, Fabio Antonacci* | **Category: eess.AS** | **Updated: 2025-08-01**

**Keywords:** 声场技术, 网络音乐表演, 实时自适应, 带宽管理, 沉浸式音频

**Comment:** to appear in EUSIPCO 2025

> **TL;DR:** 本文提出了一种动态实时自适应高阶声场技术策略，根据网络带宽变化调整声场阶数，以在网络音乐表演中平衡沉浸感和可靠性。

**AI_Comments:** 这项研究的创新之处在于提出了一种实用的动态自适应机制，解决了高阶声场技术在带宽受限的网络环境下应用时的关键挑战。它通过平衡沉浸感和网络可靠性，显著提升了远程音乐表演的用户体验。

<details>
  <summary>Details</summary>

**Motivation:** 网络音乐表演（NMP）等高级远程应用需要解决方案来保证用户之间身临其境的真实世界般互动。采用空间音频格式如声场技术是实现沉浸式声学场景体验的基础。然而，声场编码阶数越高，所需的音频通道越多，从而增加带宽需求并更容易受到网络问题（如延迟、抖动和丢包）的影响，这给需要高空间保真度和低端到端延迟的交互式音乐会话带来了挑战。

**Method:** 本文提出了一种实时自适应高阶声场技术策略，该策略持续监测网络吞吐量并动态调整声场阶数。当可用带宽低于预设阈值时，阶数会降低以防止音频中断；一旦网络条件恢复，阶数会恢复到更高，从而平衡沉浸感和可靠性。

**Result:** 基于MUSHRA的评估表明，这种自适应方法在带宽受限的网络音乐表演场景中，有望保证用户体验。

**Conclusion:** 通过动态调整声场阶数以适应网络带宽，本文提出的方法能够有效平衡沉浸感和可靠性，从而在带宽受限的网络音乐表演中提供良好的用户体验。

> **ai_Abstract:** 本文针对网络音乐表演（NMP）中沉浸式空间音频传输面临的带宽和网络稳定性挑战，提出了一种动态实时自适应高阶声场技术策略。该策略通过持续监测网络吞吐量，自动调整声场编码阶数，以在保证沉浸感的同时，有效避免音频中断。当带宽下降时，降低阶数；带宽恢复时，则提高阶数。MUSHRA评估结果表明，该自适应方法在带宽受限的NMP场景中能有效提升用户体验。

> **摘要翻译:** 高级远程应用，如网络音乐表演（NMP），需要解决方案来保证用户之间身临其境的真实世界般互动。因此，采用空间音频格式，如声场技术（Ambisonics），对于让用户体验沉浸式声学场景至关重要。声音场景再现的准确性随着声场编码阶数的增加而提高，从而改善了沉浸感，但代价是需要更多的音频通道，这反过来又增加了带宽需求和对网络障碍（例如延迟、抖动和丢包）的敏感性。这些因素对交互式音乐会话构成了重大挑战，因为它们要求高空间保真度和低端到端延迟。我们提出了一种实时自适应高阶声场技术策略，该策略持续监测网络吞吐量并动态调整声场阶数。当可用带宽低于预设阈值时，阶数会降低以防止音频中断；一旦条件恢复，它会恢复到更高阶数，从而平衡沉浸感和可靠性。基于MUSHRA的评估表明，这种自适应方法有望在带宽受限的NMP场景中保证用户体验。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [401] [MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks](https://arxiv.org/abs/2507.23511)
> *MECAT：一个用于细粒度音频理解任务的多专家构建基准*

*Yadong Niu, Tianzi Wang, Heinrich Dinkel, Xingwei Sun, Jiahao Zhou, Gang Li, Jizhong Liu, Xunying Liu, Junbo Zhang, Jian Luan* | **Category: eess.AS, cs.AI, cs.CL, cs.SD** | **Updated: 2025-07-31**

**Keywords:** 细粒度音频理解, 基准, 多专家, DATE指标, 音频-语言模型

**Comment:** 9 main pages, 5 figures, 3 tables, and 14 appendix pages

> **TL;DR:** 本文介绍了MECAT，一个多专家构建的细粒度音频理解基准，旨在解决现有大型音频-语言模型在细致理解方面的不足。MECAT通过结合专家模型分析和思维链语言模型推理生成，提供多视角字幕和开放式问答对，并引入了新颖的DATE指标以更准确地评估模型。

**AI_Comments:** 本文的创新之处在于提出了MECAT基准，它通过结合专业专家模型分析和思维链大型语言模型推理来生成高质量的细粒度数据。此外，引入的DATE评估指标具有创新性，能够更精确地区分模型输出的详细程度，解决了现有指标无法有效区分通用和详细描述的问题。这项工作对于推动细粒度音频理解领域的发展具有重要意义，有助于弥合模型与人类理解之间的差距。局限性方面，抽象中未提及。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型音频-语言模型在开放式音频理解方面表现不足，难以达到人类水平的细致理解。主要原因是当前基准受限于数据标注和评估指标，无法可靠地区分通用和高度详细的模型输出。

**Method:** 本文引入了MECAT，一个多专家构建的细粒度音频理解任务基准。该基准通过一个整合了专业专家模型分析与思维链大型语言模型推理的管道生成，提供多视角、细粒度的字幕和开放式问答对。此外，还引入了新颖的DATE（Discriminative-Enhanced Audio Text Evaluation）指标，该指标通过结合单样本语义相似性和跨样本可区分性，惩罚通用术语并奖励详细描述。

**Result:** 对最先进的音频模型进行了综合评估，提供了对其当前能力和局限性的新见解。

**Conclusion:** MECAT基准和DATE指标能够更有效地评估和区分细粒度音频理解模型的能力，揭示了现有模型的局限性，有助于推动该领域的发展。

> **ai_Abstract:** 针对大型音频-语言模型在细粒度音频理解方面与人类水平存在差距以及现有基准评估不足的问题，本文提出了MECAT基准。MECAT通过结合专业专家模型分析与思维链大型语言模型推理，生成多视角、细粒度的字幕和开放式问答对。为更准确评估模型，本文还引入了DATE评估指标，该指标通过结合单样本语义相似性和跨样本可区分性，惩罚通用描述并奖励详细信息。研究对最先进的音频模型进行了全面评估，提供了对其能力和局限性的新见解。

> **摘要翻译:** 尽管大型音频-语言模型在开放式音频理解方面取得了进展，但它们仍未能达到人类水平的细致理解。这种差距持续存在，很大程度上是因为当前的基准受限于数据标注和评估指标，无法可靠地区分通用和高度详细的模型输出。为此，本工作引入了MECAT，一个用于细粒度音频理解任务的多专家构建基准。MECAT通过一个整合了专业专家模型分析与思维链大型语言模型推理的管道生成，提供了多视角、细粒度的字幕和开放式问答对。该基准辅以一个新颖的指标：DATE（Discriminative-Enhanced Audio Text Evaluation）。该指标通过结合单样本语义相似性和跨样本可区分性，惩罚通用术语并奖励详细描述。本文还对最先进的音频模型进行了综合评估，提供了对其当前能力和局限性的新见解。数据和代码可在https://github.com/xiaomi-research/mecat获取。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [449] [Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR](https://arxiv.org/abs/2507.22964)
> *探索越南语性别独立ASR的动态参数*

*Sotheara Leang, Éric Castelli, Dominique Vaufreydaz, Sethserey Sam* | **Category: eess.AS, cs.CL, cs.SD, eess.SP** | **Updated: 2025-07-30**

**Keywords:** 动态参数, 越南语ASR, 性别独立, SSCFs, MFCCs

**Comment:** 

> **TL;DR:** 本文探索了新的动态参数（基于SSCFs的极坐标参数和SSCF0）来增强越南语自动语音识别（ASR），结果显示这些参数显著降低了词错误率并提高了性别独立性。

**AI_Comments:** Not mentioned in abstract

<details>
  <summary>Details</summary>

**Motivation:** 语音信号的动态特性提供了时间信息，对增强自动语音识别（ASR）至关重要。本文旨在捕获语音的动态特性并最小化频谱变化，以提升越南语ASR的性能和性别独立性。

**Method:** 研究人员使用极坐标参数在频谱子带质心频率（SSCFs）的比率平面上表征声学转换，以捕获语音的动态特性并最小化频谱变化。这些动态参数与梅尔频率倒谱系数（MFCCs）结合应用于越南语ASR。此外，SSCF0被用作基频（F0）的伪特征，以稳健地描述音调信息。

**Result:** 研究结果表明，所提出的参数显著降低了词错误率，并且比基线MFCCs表现出更大的性别独立性。

**Conclusion:** 本文提出的动态参数（基于SSCFs的极坐标参数和SSCF0）能有效提升越南语自动语音识别的性能，特别是在降低词错误率和实现性别独立性方面。

> **ai_Abstract:** 本文探讨了在越南语自动语音识别（ASR）中应用新型动态参数以提高性能和性别独立性。研究通过在频谱子带质心频率（SSCFs）的比率平面上使用极坐标参数来表征声学转换，并结合梅尔频率倒谱系数（MFCCs）捕获更详细的频谱信息。此外，SSCF0被用作基频的伪特征以增强音调描述的鲁棒性。实验结果表明，这些新参数能显著降低词错误率，并比传统的MFCCs表现出更高的性别独立性。

> **摘要翻译:** 语音信号的动态特性提供了时间信息，在增强自动语音识别（ASR）中发挥着重要作用。在这项工作中，我们利用极坐标参数在频谱子带质心频率（SSCFs）的比率平面上表征声学转换，以捕获语音的动态特性并最小化频谱变化。这些动态参数与梅尔频率倒谱系数（MFCCs）结合应用于越南语ASR，以捕获更详细的频谱信息。SSCF0被用作基频（F0）的伪特征，以稳健地描述音调信息。研究结果表明，所提出的参数显著降低了词错误率，并且比基线MFCCs表现出更大的性别独立性。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [750] [Ambisonics Super-Resolution Using A Waveform-Domain Neural Network](https://arxiv.org/abs/2508.00240)
> *基于波形域神经网络的Ambisonics超分辨率*

*Ismael Nawfal, Symeon Delikaris Manias, Mehrez Souden, Juha Merimaa, Joshua Atkins, Elisabeth McMullin, Shadi Pirhosseinloo, Daniel Phillips* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** Ambisonics, 超分辨率, 神经网络, 空间音频, Conv-TasNet

**Comment:** 

> **TL;DR:** 本文提出了一种利用波形域神经网络（Conv-TasNet）实现Ambisonics超分辨率的方法，将一阶Ambisonics（FOA）输入转换为更高阶Ambisonics（HOA）输出，以提高空间音频的空间精度，同时保持FOA的效率。

**AI_Comments:** 该论文的创新之处在于提出了一种数据驱动的Ambisonics超分辨率方法，区别于传统的基于物理和心理声学的渲染器。通过利用深度学习模型（Conv-TasNet），它有效地提升了一阶Ambisonics的空间精度，同时保持了其效率，为空间音频处理提供了一个高效且高质量的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 一阶Ambisonics（FOA）作为一种流行的空间音频格式，其有限的通道数是以牺牲空间精度为代价的。理想情况下，能够利用FOA的效率同时克服其局限性。

**Method:** 本研究提出了一种数据驱动的空间音频解决方案。利用一个全卷积时域音频神经网络（Conv-TasNet），该方案将FOA输入转换为更高阶Ambisonics（HOA）输出。

**Result:** 定量评估显示，预测的第三阶HOA与实际值之间的平均位置均方误差差异为0.6dB。定性评估中，感知的音质比传统渲染方法提高了80%。

**Conclusion:** 该数据驱动方法在保持FOA效率的同时，实现了超越传统渲染器的音质，显著提高了Ambisonics的空间精度和感知质量。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动方法，通过一个全卷积时域音频神经网络（Conv-TasNet）实现Ambisonics超分辨率。该方法将一阶Ambisonics（FOA）输入转换为更高阶Ambisonics（HOA）输出，旨在克服FOA在空间精度上的限制，同时保持其效率。实验结果表明，该方法在定量上将预测与实际第三阶HOA之间的位置均方误差降低了0.6dB，并在定性上将感知质量比传统渲染方法提高了80%，证明了其在空间音频渲染方面的优越性。

> **摘要翻译:** Ambisonics是一种描述声场的空间音频格式。一阶Ambisonics（FOA）是一种流行的格式，仅包含四个通道。这种有限的通道数是以牺牲空间精度为代价的。理想情况下，人们能够利用FOA格式的效率而没有其局限性。我们设计了一种数据驱动的空间音频解决方案，该方案保留了FOA格式的效率，但实现了超越传统渲染器的质量。利用一个全卷积时域音频神经网络（Conv-TasNet），我们创建了一个解决方案，它接受FOA输入并提供更高阶Ambisonics（HOA）输出。与典型的基于物理和心理声学的渲染器相比，这种数据驱动的方法是新颖的。定量评估显示，预测的第三阶HOA与实际值之间的平均位置均方误差差异为0.6dB。中位数定性评级显示，与传统渲染方法相比，感知质量提高了80%。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [778] [Beamformed 360° Sound Maps: U-Net-Driven Acoustic Source Segmentation and Localization](https://arxiv.org/abs/2508.00307)
> *波束形成360°声学地图：U-Net驱动的声源分割与定位*

*Belman Jahir Rodriguez, Sergio F. Chevtchenko, Marcelo Herrera Martinez, Yeshwant Bethy, Saeed Afshar* | **Category: eess.AS, cs.AI, cs.SD, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 声源定位, U-Net, 语义分割, 波束形成, 360度声学地图

**Comment:** 

> **TL;DR:** 本文提出一种基于U-Net模型的新方法，将360度声源定位问题转化为球面语义分割任务。该方法通过分割波束形成的声学地图来识别活跃声源区域，而非直接回归离散的到达方向角，实现了更高的角度精度和阵列独立性，为密集空间音频理解提供了新范式。

**AI_Comments:** 这篇论文的创新点在于将声源定位问题转化为语义分割任务，并利用U-Net处理波束形成的声学地图，这提供了一种更细粒度和空间连续的声源表示方式，超越了传统的离散DoA估计。其阵列独立性是重要的优势，意味着该方法具有更广泛的适用性。数据集的真实世界性质也增加了研究的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的声源定位方法通常回归离散的到达方向角（DoA），限制了对密集空间音频的理解。本文旨在提出一种新的范式，通过语义分割的方式，识别波束形成声学地图中的活跃声源区域，从而实现更密集和鲁棒的空间音频理解，超越传统的声源定位（SSL）。

**Method:** 本研究引入了一个U-Net模型，将360度声源定位表述为球面语义分割任务。模型通过分割波束形成的音频地图（方位角和仰角）来识别活跃声源区域。使用定制的24麦克风阵列进行延迟-求和（DAS）波束形成，生成与无人机GPS遥测数据对齐的信号以创建二值监督掩码。一个修改后的U-Net模型在这些地图的频域表示上进行训练，并使用Tversky损失解决类别不平衡问题。由于网络在波束形成能量地图上操作，该方法具有阵列独立性。分割输出通过计算激活区域的质心进行后处理，以实现鲁棒的DoA估计。数据集包含DJI Air 3无人机的真实世界开放场地录音。

**Result:** 实验结果表明，该U-Net模型在不同环境中具有良好的泛化能力，并提供了更高的角度精度。

**Conclusion:** 该方法为密集空间音频理解提供了一种新范式，超越了传统的声源定位（SSL）。

> **ai_Abstract:** 本文提出了一种基于U-Net模型的360度声源定位新方法，将其视为球面语义分割任务。该模型通过分割波束形成的声学地图来识别活跃声源区域，而非直接回归离散的到达方向。研究利用自定义的24麦克风阵列进行延迟-求和波束形成，并结合无人机GPS遥测数据生成监督掩码。训练后的U-Net模型能够识别空间分布的声源，并通过后处理计算质心获得鲁棒的DoA估计。该方法具有阵列独立性，能在不同麦克风配置下应用。实验结果表明，该模型在不同环境中具有良好的泛化能力和更高的角度精度，为空间音频理解开辟了新途径。

> **摘要翻译:** 我们引入了一个U-net模型，用于360度声源定位，并将其表述为球面语义分割任务。我们的模型不是回归离散的到达方向（DoA）角度，而是将波束形成的音频地图（方位角和仰角）分割成活跃声源存在的区域。通过在定制的24麦克风阵列上使用延迟-求和（DAS）波束形成，我们生成与无人机GPS遥测数据对齐的信号，以创建二值监督掩码。一个修改后的U-Net，在这些地图的频域表示上进行训练，学习识别空间分布的声源区域，并通过Tversky损失解决类别不平衡问题。由于网络在波束形成能量地图上操作，该方法本质上与阵列无关，并且无需从头开始重新训练即可适应不同的麦克风配置。分割输出通过计算激活区域的质心进行后处理，从而实现鲁棒的DoA估计。我们的数据集包括DJI Air 3无人机的真实世界开放场地录音，这些录音在多个日期和地点与360度视频和飞行日志同步。实验结果表明，U-net在不同环境中具有泛化能力，提供了更高的角度精度，为超越传统声源定位（SSL）的密集空间音频理解提供了一种新范式。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [806] [Wavelet-Based Time-Frequency Fingerprinting for Feature Extraction of Traditional Irish Music](https://arxiv.org/abs/2508.00479)
> *基于小波的时间-频率指纹识别技术在传统爱尔兰音乐特征提取中的应用*

*Noah Shore* | **Category: eess.AS, cs.SD, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 小波变换, 时间-频率指纹识别, 特征提取, 爱尔兰音乐, 音频识别

**Comment:** Master's thesis. The focus of the thesis is on the underlying
  techniques for signal fingerprinting

> **TL;DR:** 该研究提出了一种基于小波的时间-频率指纹识别方法，用于传统爱尔兰音乐的音频识别和特征提取，并展示了其在识别录制音乐方面的准确性和效率，同时讨论了其在其他领域的应用潜力。

**AI_Comments:** 该研究创新性地将小波变换和相干性分析应用于传统爱尔兰音乐的特征提取和音频识别，有效解决了现场录音的识别挑战。其小波相干性模型在性能上优于其他时频分解方法，且其应用潜力不仅限于音乐领域，还扩展到了EEG信号分析和金融时间序列预测，展现了该方法的普适性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 解决时间序列数据中特征识别的挑战，特别是从传统爱尔兰音乐的现场录音中进行音频识别和特征提取。

**Method:** 采用连续小波变换提取频谱特征，并利用小波相干性分析比较录制音频频谱图与来源于ABC记谱法的合成乐曲。

**Result:** 实验结果表明，该基于小波的方法能够准确高效地识别录制乐曲。小波相干性模型相对于其他时频分解方法表现出优势。

**Conclusion:** 基于小波的时间-频率指纹识别方法能准确高效地识别传统爱尔兰音乐，并且该模型在EEG信号分析和金融时间序列预测等音乐以外的领域也具有应用潜力。

> **ai_Abstract:** 本文提出了一种基于小波的时间-频率指纹识别方法，专注于从传统爱尔兰音乐的现场录音中提取时间序列特征并进行音频识别。该方法通过连续小波变换提取频谱特征，并利用小波相干性分析将录制音频与由ABC记谱法生成的合成乐曲进行比较。实验结果证明，该基于小波的方法能够准确高效地识别录制乐曲。研究还强调了小波相干性模型相对于其他时频分解方法的优势，并探讨了该模型在EEG信号分析和金融时间序列预测等非音乐领域的应用潜力。

> **摘要翻译:** 这项工作提出了一种基于小波的时间-频率指纹识别方法，用于时间序列特征提取，重点关注传统爱尔兰音乐现场录音的音频识别。通过采用连续小波变换提取频谱特征，并利用小波相干性分析比较录制音频频谱图与合成乐曲，解决了时间序列数据中特征识别的挑战。合成乐曲来源于ABC记谱法，这是一种爱尔兰音乐常用的符号表示形式。实验结果表明，该基于小波的方法能够准确高效地识别录制乐曲。这项研究还详细阐述了小波相干性模型的性能，强调了其相对于其他时频分解方法的优势。此外，我们讨论并将该模型应用于音乐以外的多个领域，包括脑电图（EEG）信号分析和金融时间序列预测。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [826] [Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion](https://arxiv.org/abs/2507.14534)
> *Conan: 一种用于零样本自适应语音转换的块状在线网络*

*Yu Zhang, Baotong Tian, Zhiyao Duan* | **Category: eess.AS, cs.CL, cs.SD** | **Updated: 2025-07-30**

**Keywords:** 零样本语音转换, 在线语音转换, 语音克隆, 块状网络, HiFiGAN

**Comment:** 

> **TL;DR:** Conan是一个新的零样本在线语音转换模型，解决了实时通信中语义保真度、自然度以及对未知说话人适应性的挑战。

**AI_Comments:** Conan通过其创新的三组件设计，特别是块状在线处理和因果混洗声码器，有效提升了零样本语音转换的实时性、语义保真度和风格适应性，对于实时通信和娱乐应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的语音转换模型在实时约束下难以保持语义保真度、提供自然的声音转换，并且难以有效适应未见的说话者特征。

**Method:** 本文引入了Conan，一个块状在线零样本语音转换模型，旨在保留源内容的同时匹配参考语音的音色和风格。Conan包含三个核心组件：1）流内容提取器（利用Emformer进行低延迟流内容编码）；2）自适应风格编码器（从参考语音中提取细粒度风格特征以增强风格适应）；3）因果混洗声码器（使用像素混洗机制实现完全因果的HiFiGAN）。

**Result:** 实验评估表明，Conan在主观和客观指标上均优于基线模型。

**Conclusion:** Conan有效解决了零样本在线语音转换中存在的语义保真度、自然度和适应性问题，并在性能上超越了现有模型。

> **ai_Abstract:** 本文提出了Conan，一个块状在线零样本语音转换模型，旨在解决现有模型在实时通信中面临的语义保真度、自然度和对未知说话人适应性问题。Conan由流内容提取器、自适应风格编码器和因果混洗声码器三个核心组件构成，实验证明其在主客观指标上均优于基线模型。

> **摘要翻译:** 零样本在线语音转换（VC）在实时通信和娱乐领域具有重要前景。然而，当前的VC模型在实时约束下难以保持语义保真度、提供自然的声音转换，并且难以有效适应未见的说话者特征。为了解决这些挑战，我们引入了Conan，一个块状在线零样本语音转换模型，它在匹配参考语音的音色和风格的同时，保留了源内容的语义。Conan包含三个核心组件：1）流内容提取器，利用Emformer进行低延迟流内容编码；2）自适应风格编码器，从参考语音中提取细粒度风格特征以增强风格适应；3）因果混洗声码器，使用像素混洗机制实现完全因果的HiFiGAN。实验评估表明，Conan在主观和客观指标上均优于基线模型。音频样本可在https://aaronz345.github.io/ConanDemo找到。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [827] [VR-PTOLEMAIC: A Virtual Environment for the Perceptual Testing of Spatial Audio Algorithms](https://arxiv.org/abs/2508.00501)
> *VR-PTOLEMAIC: 空间音频算法感知测试的虚拟环境*

*Paolo Ostan, Francesca Del Gaudio, Federico Miotello, Mirco Pezzoli, Fabio Antonacci* | **Category: eess.AS, cs.SD** | **Updated: 2025-08-01**

**Keywords:** 空间音频算法, 虚拟现实, 感知评估, MUSHRA, VR-PTOLEMAIC

**Comment:** to appear in EAA Forum Acusticum 2025

> **TL;DR:** VR-PTOLEMAIC是一个用于感知评估空间音频算法的虚拟现实系统，它将MUSHRA方法集成到虚拟环境中，并被证明有效且用户体验良好。

**AI_Comments:** 该论文提出了一种创新的方法，利用VR技术为空间音频算法的感知评估提供了一个沉浸式和交互式的平台。其将MUSHRA评估方法集成到虚拟环境中的做法，提高了评估的真实性和效率。该系统的成功应用表明VR在音频技术研发和质量控制方面具有巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 沉浸式音频应用开发中，空间音频算法的感知评估是重要步骤，以确保合成声场在听觉体验、空间感知和听觉真实感方面达到质量标准。虚拟现实可以提供强大的平台来支持这些评估。

**Method:** 本文提出了VR-PTOLEMAIC，一个专为评估空间音频算法而设计的虚拟现实评估系统。该系统在虚拟环境中实现了MUSHRA（MUlti-Stimulus test with Hidden Reference and Anchor）评估方法。用户可以在虚拟重现的研讨室的25个模拟听音位置评估模拟声学响应与实际记录的二次Ambisonic房间脉冲响应（与各种源信号卷积）的关系。

**Result:** 通过广泛的测试活动，评估人员比较了各种声场重建算法的重建能力。结果显示，VR平台有效支持空间音频算法的评估，并且用户体验和沉浸感普遍得到积极反馈。

**Conclusion:** VR平台能够有效支持空间音频算法的评估，并提供良好的用户体验和沉浸感。

> **ai_Abstract:** 本文介绍了VR-PTOLEMAIC，一个基于虚拟现实的系统，用于感知评估空间音频算法。该系统将MUSHRA评估方法整合到虚拟环境中，允许用户在模拟的研讨室中测试不同声场重建算法的性能。通过广泛的测试活动，结果表明VR-PTOLEMAIC能有效支持空间音频算法的评估，并获得了积极的用户体验和沉浸感反馈。

> **摘要翻译:** 空间音频算法的感知评估是沉浸式音频应用开发中的一个重要步骤，因为它确保了合成声场在听觉体验、空间感知和听觉真实感方面达到质量标准。为了支持这些评估，虚拟现实通过提供沉浸式和交互式测试环境，可以提供一个强大的平台。在本文中，我们提出了VR-PTOLEMAIC，一个专为评估空间音频算法而设计的虚拟现实评估系统。该系统在虚拟环境中实现了MUSHRA（多刺激隐藏参考和锚点）评估方法。特别是，用户可以在虚拟再现的研讨室的25个模拟听音位置中的每一个位置定位自己，并评估模拟声学响应与实际记录的二次Ambisonic房间脉冲响应（所有这些都与各种源信号卷积）的关系。我们通过广泛的测试活动评估了所提出框架的可用性，其中评估人员被要求比较各种声场重建算法的重建能力。结果表明，VR平台有效支持空间音频算法的评估，并且用户体验和沉浸感普遍得到积极反馈。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [62] [Navigating Distribution Shifts in Medical Image Analysis: A Survey](https://arxiv.org/abs/2411.05824)
> *应对医学图像分析中的分布偏移：一项综述*

*Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Frans Coenen, Kaizhu Huang* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 医学图像分析, 分布偏移, 深度学习, 域泛化, 联邦学习

**Comment:** 

> **TL;DR:** 本综述系统地回顾了深度学习技术在医学图像分析中应对分布偏移的方法，并根据医疗机构的实际操作限制进行了分类，以促进深度学习在医疗领域的鲁棒部署。

**AI_Comments:** 这篇综述的创新之处在于其独特的分类方法，它不局限于技术规范，而是基于医疗机构的实际操作限制（如数据可访问性、隐私和协作协议）来组织内容。这种以应用场景为中心的视角，使得综述更具实用价值，能够更好地指导研究人员和临床医生在现实世界中部署和应用深度学习模型，以应对医学图像分析中的分布偏移问题。它强调了实际部署中的挑战，并为未来的研究提供了清晰的方向。

<details>
  <summary>Details</summary>

**Motivation:** 尽管深度学习在医学图像分析中取得了显著进展，但由于分布偏移，模型在不同医院、区域或患者群体中的性能下降，阻碍了其实际部署。因此，需要开发策略来提高深度学习模型的适应性和鲁棒性。

**Method:** 本文系统地综述了将深度学习技术应用于受分布偏移影响的医学图像分析系统的方法。与传统基于技术规范的分类不同，本文基于医疗机构面临的实际操作限制进行分类，具体分为联合训练、联邦学习、微调和域泛化，每种方法都针对数据可访问性、隐私问题和协作协议引起的不同场景。

**Result:** 本综述为研究人员提供了对深度学习如何战略性部署以解决医学图像分析中分布偏移的细致理解，确保了多样化和鲁棒的医疗应用。

**Conclusion:** 本文通过深入探讨这些主题，强调了未来研究的潜在途径，这些途径不仅解决了现有局限性，而且推动了可部署医学图像分析技术的边界。

> **ai_Abstract:** 本综述探讨了深度学习在医学图像分析中应对分布偏移的挑战。文章系统地回顾了现有方法，并根据医疗机构面临的实际操作限制，将其分为联合训练、联邦学习、微调和域泛化。这种分类方法旨在为研究人员提供一个实用的视角，以理解和部署深度学习技术，从而确保在多样化和复杂的医疗环境中实现鲁棒的医学图像应用，并指明了未来的研究方向。

> **摘要翻译:** 医学图像分析（MedIA）在现代医疗保健中变得不可或缺，它增强了临床诊断和个性化治疗。尽管深度学习（DL）技术取得了显著进展，但由于分布偏移，其实际部署面临挑战，即在特定数据集上训练的模型在来自不同医院、区域或患者群体的其他数据集上表现不佳。为了解决这个问题，研究人员一直在积极开发策略，以提高深度学习模型的适应性和鲁棒性，使其能够在不熟悉和多样化的环境中有效使用。本文系统地综述了将深度学习技术应用于受分布偏移影响的医学图像分析系统的方法。与传统基于技术规范的分类不同，我们的方法基于医疗机构面临的实际操作限制。具体来说，我们将现有工作分为联合训练、联邦学习、微调和域泛化，每种方法都针对数据可访问性、隐私问题和协作协议引起的独特场景。这种视角使研究人员能够对深度学习如何战略性部署以解决医学图像分析中的分布偏移有细致的理解，从而确保多样化和鲁棒的医疗应用。通过深入探讨这些主题，我们强调了未来研究的潜在途径，这些途径不仅解决了现有局限性，而且推动了可部署医学图像分析技术的边界。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [97] [Generating Novel Brain Morphology by Deforming Learned Templates](https://arxiv.org/abs/2503.03778)
> *通过形变学习模板生成新颖的大脑形态*

*Alan Q. Wang, Fangrui Huang, Bailey Trang, Wei Peng, Mohammad Abbasi, Kilian Pohl, Mert Sabuncu, Ehsan Adeli* | **Category: eess.IV, q-bio.TO** | **Updated: 2025-07-31**

**Keywords:** 脑部MRI生成, 潜在扩散模型, 形变场, 模板学习, 图像合成

**Comment:** Provisional Acceptance at MICCAI 2025

> **TL;DR:** 提出MorphLDM，一个基于潜在扩散模型的新方法，通过对学习到的模板应用合成形变场来生成3D脑部MRI图像，优于现有方法。

**AI_Comments:** 这项工作通过引入“形变学习模板”的概念，为3D脑部MRI生成提供了一种新颖且有效的方法，避免了传统方法直接生成图像可能带来的形态细节损失。其结合潜在扩散模型和形变场的创新架构，有望在生成高质量、形态合理的医学图像方面发挥重要作用，对于神经科学研究和临床应用具有潜在价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有生成模型在合成形态合理且属性特定的3D脑部MRI图像时，直接生成图像的方式可能限制其捕获复杂形态细节的能力。

**Method:** 提出MorphLDM，一种基于潜在扩散模型（LDMs）的3D脑部MRI生成方法。它通过将合成的形变场应用于学习到的模板来生成新图像。与典型的LDM不同，其编码器输出一个结合图像和学习模板的潜在嵌入，该模板本身是模板解码器的输出；此潜在嵌入传递给形变场解码器，其输出应用于学习模板。通过最小化原始图像与形变模板之间的配准损失来训练模型。

**Result:** 经验证明，该方法在图像多样性、输入条件依从性以及基于体素的形态测量等指标上优于现有的生成基线模型。

**Conclusion:** 该研究成功开发了一种通过形变学习模板来生成新颖大脑形态的有效方法，并在多项指标上超越了现有基线模型，表明了其在生成高质量、形态合理且属性特定的3D脑部MRI图像方面的潜力。

> **ai_Abstract:** 本文提出了一种名为MorphLDM的新型3D脑部MRI生成模型，该模型基于潜在扩散模型，旨在克服现有方法在捕获复杂形态细节方面的局限性。MorphLDM通过学习一个模板并生成形变场应用于该模板来合成新颖的脑部图像，而非直接生成图像。其独特的编码器-解码器结构结合了图像和模板信息，并通过最小化配准损失进行训练。实验结果表明，MorphLDM在图像多样性、条件依从性和形态测量方面均优于现有基线模型。

> **摘要翻译:** 设计用于合成形态合理且属性特定（例如年龄、性别、疾病状态）样本的3D结构脑部MRI生成模型是一个活跃的研究领域。现有基于GAN或扩散模型等框架的方法直接合成图像，这可能限制它们捕获复杂形态细节的能力。在这项工作中，我们提出了一种基于最先进潜在扩散模型（LDMs）的3D脑部MRI生成方法，名为MorphLDM，它通过对学习到的模板应用合成形变场来生成新颖图像。与使用基于重建的自编码器（如典型LDM）不同，我们的编码器输出一个源自图像和学习模板（其本身是模板解码器的输出）的潜在嵌入；此潜在嵌入传递给形变场解码器，其输出应用于学习模板。在编码器和两个解码器方面，原始图像和形变模板之间的配准损失被最小化。经验证明，我们的方法在图像多样性、输入条件依从性以及基于体素的形态测量等指标上优于生成基线模型。我们的代码可在https://github.com/alanqrwang/morphldm获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [139] [Optimizing Federated Learning Configurations for MRI Prostate Segmentation and Cancer Detection: A Simulation Study](https://arxiv.org/abs/2507.22790)
> *优化联邦学习配置用于MRI前列腺分割和癌症检测：一项模拟研究*

*Ashkan Moradi, Fadila Zerka, Joeran S. Bosma, Mohammed R. S. Sunoqrot, Bendik S. Abrahamsen, Derya Yakar, Jeroen Geerdink, Henkjan Huisman, Tone Frost Bathen, Mattijs Elschot* | **Category: eess.IV** | **Updated: 2025-07-31**

**Keywords:** 联邦学习, 前列腺分割, 癌症检测, MRI, 优化

**Comment:** 25 pages, 6 figures, 4 tables. Accepted for publication in Radiology:
  Artificial Intelligence, \c{opyright} 2025 Radiological Society of North
  America (RSNA)

> **TL;DR:** 本研究开发并优化了一个联邦学习框架，用于MRI前列腺分割和临床显著性前列腺癌检测，通过优化联邦学习配置显著提高了性能和泛化能力。

**AI_Comments:** 该论文的创新点在于将联邦学习应用于MRI前列腺分割和癌症检测，并系统地优化了FL的关键配置参数（局部迭代次数、联邦轮次、聚合策略），从而在保护数据隐私的同时提高了模型性能和泛化能力。这项研究对于推动医疗领域AI应用，尤其是在多中心数据共享受限的情况下，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 开发和优化一个跨多个客户端的联邦学习（FL）框架，用于双参数MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。

**Method:** 本研究采用回顾性方法，使用Flower FL训练基于nnU-Net的架构。数据收集自2010年1月至2021年8月。模型开发包括训练和优化局部迭代次数、联邦轮次和聚合策略。针对T2加权MRI上的FL前列腺分割（四个客户端，1294名患者）和使用双参数MRI的csPCa检测（三个客户端，1440名患者）进行了优化。性能评估使用Dice分数（分割）和PI-CAI分数（csPCa检测），并使用置换检验计算性能差异的P值。

**Result:** FL配置针对两项任务独立优化：前列腺分割在1个局部迭代次数和300个联邦轮次下使用FedMedian表现最佳；csPCa检测在5个局部迭代次数和200个联邦轮次下使用FedAdagrad表现最佳。与客户端的平均性能相比，优化后的FL模型在独立测试集上的前列腺分割和csPCa检测性能显著提高。优化后的FL模型在病灶检测性能上优于FL基线模型，但在前列腺分割方面未观察到差异。

**Conclusion:** 与局部模型相比，联邦学习（FL）增强了MRI前列腺分割和临床显著性前列腺癌（csPCa）检测的性能和泛化能力，并且优化其配置进一步提高了病灶检测性能。

> **ai_Abstract:** 本研究旨在开发并优化一个联邦学习（FL）框架，用于MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。研究利用Flower FL和nnU-Net架构，在多个客户端的数据上进行训练和优化，包括局部迭代次数、联邦轮次和聚合策略。结果显示，优化后的FL配置在两项任务上均显著提升了性能和泛化能力，尤其是在病灶检测方面，这表明FL及其配置优化在医疗图像分析中的潜力。

> **摘要翻译:** 目的：开发和优化一个跨多个客户端的联邦学习（FL）框架，用于双参数MRI前列腺分割和临床显著性前列腺癌（csPCa）检测。材料和方法：使用Flower FL进行了一项回顾性研究，训练基于nnU-Net的架构进行MRI前列腺分割和csPCa检测，数据收集自2010年1月至2021年8月。模型开发包括训练和优化局部迭代次数、联邦轮次以及FL前列腺分割（基于T2加权MRI，四个客户端，1294名患者）和csPCa检测（使用双参数MRI，三个客户端，1440名患者）的聚合策略。性能在独立测试集上进行评估，分割使用Dice分数，csPCa检测使用前列腺成像：癌症人工智能（PI-CAI）分数（定义为受试者工作特征曲线下面积和平均精度的平均值）。性能差异的P值使用置换检验计算。结果：FL配置针对两项任务独立优化，结果显示：前列腺分割在1个局部迭代次数和300个联邦轮次下使用FedMedian表现出改进的性能；csPCa检测在5个局部迭代次数和200个联邦轮次下使用FedAdagrad表现出改进的性能。与客户端的平均性能相比，优化后的FL模型在独立测试集上的前列腺分割和csPCa检测性能显著提高。优化后的FL模型与FL基线模型相比，显示出更高的病灶检测性能，但前列腺分割未观察到差异。结论：与局部模型相比，FL增强了MRI前列腺分割和csPCa检测的性能和泛化能力，并且优化其配置进一步提高了病灶检测性能。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [151] [LesionGen: A Concept-Guided Diffusion Model for Dermatology Image Synthesis](https://arxiv.org/abs/2507.23001)
> *LesionGen：一种概念引导的皮肤病图像合成扩散模型*

*Jamil Fayyad, Nourhan Bayasi, Ziyang Yu, Homayoun Najjaran* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 皮肤病图像合成, 扩散模型, 文本到图像生成, 数据增强, 深度学习

**Comment:** Accepted at the MICCAI 2025 ISIC Workshop

> **TL;DR:** LesionGen是一个概念引导的T2I-DPM框架，用于合成高质量的皮肤病变图像，以解决皮肤病深度学习模型数据稀缺的问题，并能提高分类模型的性能，尤其是在最差子组性能上。

**AI_Comments:** LesionGen的创新之处在于其利用概念引导的结构化描述来训练T2I-DPM，解决了皮肤病学领域医学图像数据缺乏丰富文本描述的痛点。这种方法不仅生成了逼真的图像，更重要的是，它证明了合成数据能够有效提升深度学习模型在皮肤病分类任务上的性能，特别是对弱势或代表性不足的子组，这对于公平性和泛化性具有重要意义。该工作为医疗领域数据增强提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤病分类的深度学习模型需要大量、多样化且标注良好的数据集，但由于隐私问题、高昂的标注成本和人口统计学代表性不足，此类资源通常有限。尽管文本到图像扩散概率模型（T2I-DPMs）在医学数据合成方面有前景，但由于现有皮肤图像数据集中缺乏丰富的文本描述，其在皮肤病学中的应用仍未得到充分探索。

**Method:** 本研究引入了LesionGen，一个临床知情的T2I-DPM框架，用于皮肤病图像合成。与依赖简单疾病标签的现有方法不同，LesionGen通过专家标注和伪生成的概念引导报告，在结构化、概念丰富的皮肤病学描述上进行训练。通过在这些高质量图像-描述对上微调预训练的扩散模型，实现了基于有意义的皮肤病学描述生成逼真多样的皮肤病变图像。

**Result:** 实验结果表明，仅使用我们合成数据集训练的模型，其分类准确率与使用真实图像训练的模型相当，并且在最差子组性能方面有显著提升。

**Conclusion:** LesionGen成功地通过生成高质量、概念引导的合成皮肤病变图像，有效解决了皮肤病学深度学习模型的数据稀缺问题，并能提升模型的分类性能，尤其是在处理代表性不足的子组时。

> **ai_Abstract:** LesionGen是一种新颖的文本到图像扩散模型，专为皮肤病图像合成设计，旨在解决深度学习模型在皮肤病学中面临的数据稀缺和标注挑战。该模型利用专家标注和伪生成报告中提取的结构化、概念丰富的皮肤病学描述进行训练，而非简单的疾病标签。通过微调预训练的扩散模型，LesionGen能够生成逼真且多样化的皮肤病变图像。实验证明，使用LesionGen合成数据训练的分类模型，其性能可媲美使用真实数据训练的模型，尤其在处理表现不佳的子组时有显著改善。

> **摘要翻译:** 深度学习皮肤病分类模型需要大量、多样化且标注良好的数据集。然而，由于隐私问题、高昂的标注成本和人口统计学代表性不足，此类资源通常有限。尽管文本到图像扩散概率模型（T2I-DPMs）在医学数据合成方面前景广阔，但由于现有皮肤图像数据集中缺乏丰富的文本描述，其在皮肤病学中的应用仍未得到充分探索。在这项工作中，我们引入了LesionGen，一个临床知情的T2I-DPM框架，用于皮肤病图像合成。与依赖简单疾病标签的现有方法不同，LesionGen在结构化、概念丰富的皮肤病学描述上进行训练，这些描述来源于专家标注和伪生成的概念引导报告。通过在这些高质量的图像-描述对上微调预训练的扩散模型，我们能够生成基于有意义的皮肤病学描述的逼真多样的皮肤病变图像。我们的结果表明，仅使用我们合成数据集训练的模型，其分类准确率与使用真实图像训练的模型相当，并且在最差子组性能方面有显著提升。代码和数据可在此处获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [179] [MRpro - open PyTorch-based MR reconstruction and processing package](https://arxiv.org/abs/2507.23129)
> *MRpro - 基于PyTorch的开放式MR重建与处理软件包*

*Felix Frederik Zimmermann, Patrick Schuenke, Christoph S. Aigner, Bill A. Bernhardt, Mara Guastini, Johannes Hammacher, Noah Jaitner, Andreas Kofler, Leonid Lunin, Stefan Martin, Catarina Redshaw Kranich, Jakob Schattenfroh, David Schote, Yanglei Wu, Christoph Kolbitsch* | **Category: eess.IV, cs.CV, physics.med-ph** | **Updated: 2025-07-30**

**Keywords:** MR重建, PyTorch, 开源, 图像处理, 深度学习

**Comment:** Submitted to Magnetic Resonance in Medicine

> **TL;DR:** MRpro是一个基于PyTorch的开源MR图像重建和处理包，提供统一的数据结构、可组合的重建算法和深度学习模块，支持多种应用并注重可复现性和可维护性。

**AI_Comments:** MRpro的创新之处在于其将MR图像重建的各个方面（数据处理、传统算法和深度学习方法）集成到一个统一的、基于PyTorch的开源框架中。其强调可复现性、可维护性和协作开发，对于推动MR成像研究的标准化和效率至关重要。这为研究人员提供了一个灵活且强大的工具，可以加速新算法的开发和验证。

<details>
  <summary>Details</summary>

**Motivation:** 旨在提供一个开放、可复现、可维护的MR图像重建和处理框架，以促进协作开发和未来的MR成像研究。

**Method:** MRpro提供三个主要方面：1) 统一的数据结构，用于处理MR数据集和元数据；2) 可组合的运算符库、函数和优化算法，包括统一的傅里叶运算符和扩展的相位图模拟，用于实现关键重建算法；3) 用于深度学习的基本构建模块，如数据一致性层、可微分优化层和最先进的骨干网络，并集成公共数据集以促进可复现性。

**Result:** MRpro在多种应用中展示了其多功能性，包括笛卡尔、径向和螺旋采集；运动校正重建；心脏MR指纹识别；学习空间自适应正则化权重；基于模型的学习图像重建和定量参数估计。

**Conclusion:** MRpro提供了一个可扩展的MR图像重建框架，以可复现性和可维护性为核心，促进了协作开发，并为未来的MR成像研究奠定了基础。

> **ai_Abstract:** MRpro是一个基于PyTorch的开源磁共振图像重建与处理软件包。它提供统一的数据结构、丰富的重建算法组件（包括傅里叶运算符和优化算法），以及用于深度学习的模块（如数据一致性层和骨干网络）。该框架支持多种MR采集模式和高级重建任务，如运动校正和定量参数估计，旨在提高MR研究的可复现性、可维护性和协作性。

> **摘要翻译:** 我们引入了MRpro，一个基于PyTorch和开放数据格式构建的开源图像重建软件包。该框架包含三个主要领域。首先，它为MR数据集及其相关元数据（例如k空间轨迹）的一致性操作提供了统一的数据结构。其次，它提供了一个由可组合运算符、近似泛函和优化算法组成的库，包括适用于所有常见轨迹的统一傅里叶运算符和用于定量MR的扩展相位图模拟。这些组件用于创建关键重建算法的即用型实现。第三，对于深度学习，MRpro包括基本构建块，如数据一致性层、可微分优化层和最先进的骨干网络，并集成了公共数据集以促进可复现性。MRpro作为一个协作项目开发，并受到自动化质量控制的支持。我们展示了MRpro在多种应用中的多功能性，包括笛卡尔、径向和螺旋采集；运动校正重建；心脏MR指纹识别；学习空间自适应正则化权重；基于模型的学习图像重建和定量参数估计。MRpro为MR图像重建提供了一个可扩展的框架。以可复现性和可维护性为核心，它促进了协作开发，并为未来的MR成像研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [214] [Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction](https://arxiv.org/abs/2507.23219)
> *学习基于小波递归重建的任意尺度RAW图像降采样*

*Yang Ren, Hai Jiang, Wei Li, Menglong Yang, Heng Zhang, Zehua Sheng, Qingsheng Ye, Shuaicheng Liu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** RAW图像降采样, 小波变换, 递归重建, 任意尺度, 能量最大化损失

**Comment:** Accepted by ACM MM 2025

> **TL;DR:** 本文提出一个基于小波的递归重建框架，用于任意尺度RAW图像降采样，解决了现有方法在sRGB域的局限性，并引入了一个新的数据集，实现了优于现有技术的结果。

**AI_Comments:** 本文的创新点在于首次提出了专门针对RAW图像的任意尺度降采样框架，并巧妙地结合了小波变换的信息无损特性和递归重建机制，同时引入了能量最大化损失和针对RAW图像特性设计的模块。这解决了RAW图像降采样领域的一个空白，为RAW图像的存储、传输和后续处理提供了高质量的解决方案，具有重要的实际应用价值。抽象中未提及模型的计算复杂度或推理速度，这在实际应用中可能是需要考虑的因素。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率图像的有效存储和传输需要图像降采样；现有基于学习的方法主要在sRGB域进行，导致细节模糊和伪影；RAW图像提供了更大的灵活性，但缺乏专门的降采样框架。

**Method:** 提出一个基于小波的递归重建框架，利用小波变换的信息无损特性，以从粗到精的方式实现任意尺度的RAW图像降采样。框架包含低频任意尺度降采样模块（LASDM）和高频预测模块（HFPM），旨在保持重建低分辨率RAW图像的结构和纹理完整性。引入一个能量最大化损失，用于对齐高分辨率和低分辨率域之间的高频能量。此外，构建了Realistic Non-Integer RAW Downscaling (Real-NIRD) 数据集，包含非整数降采样因子1.3倍，并结合了公共数据集（2倍、3倍、4倍）进行综合基准测试。

**Result:** 该方法在定量和视觉上都优于现有的最先进竞争方法。

**Conclusion:** 本文提出的基于小波的递归重建框架能够有效地实现任意尺度的RAW图像降采样，并在性能上超越了现有技术，为RAW图像处理提供了新的解决方案。

> **ai_Abstract:** 本文针对高分辨率RAW图像的有效存储和传输问题，提出了一个创新的基于小波的递归重建框架，用于实现任意尺度的RAW图像降采样。该框架通过结合低频和高频模块以及能量最大化损失，旨在有效保留图像细节和纹理。为全面评估其性能，研究者构建了包含非整数降采样因子的Real-NIRD数据集，并结合现有数据集进行基准测试。实验结果表明，该方法在性能上超越了现有最先进技术，为RAW图像降采样提供了高效且高质量的解决方案。

> **摘要翻译:** 图像降采样对于高分辨率（HR）图像的有效存储和传输至关重要。现有基于学习的方法侧重于在sRGB域内执行降采样，这通常会导致细节模糊和意外伪影。RAW图像凭借其未处理的光子信息，提供了更大的灵活性，但缺乏专门的降采样框架。在本文中，我们提出了一个基于小波的递归重建框架，该框架利用小波变换的信息无损特性，以从粗到精的方式实现任意尺度的RAW图像降采样。其中，低频任意尺度降采样模块（LASDM）和高频预测模块（HFPM）被提出，以保持重建的低分辨率（LR）RAW图像的结构和纹理完整性，同时引入了一个能量最大化损失，用于对齐高分辨率和低分辨率域之间的高频能量。此外，我们引入了Realistic Non-Integer RAW Downscaling (Real-NIRD) 数据集，其特征是非整数降采样因子1.3倍，并将其与公共数据集（2倍、3倍、4倍）结合，用于综合基准测试任意尺度图像降采样目的。大量的实验表明，我们的方法在定量和视觉上都优于现有的最先进竞争方法。代码和数据集将在https://github.com/RenYangSCU/ASRD 发布。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [250] [EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision](https://arxiv.org/abs/2507.23256)
> *EMedNeXt：一种为撒哈拉以南非洲地区优化的基于MedNeXt V2深度监督的增强型脑肿瘤分割框架*

*Ahmed Jaheen, Abdelrahman Elsayed, Damir Kim, Daniil Tikhonov, Matheus Scatolin, Mohor Banerjee, Qiankun Ji, Mostafa Salem, Hu Wang, Sarim Hashmi, Mohammad Yaqub* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 脑肿瘤分割, MedNeXt V2, 深度监督, 撒哈拉以南非洲, MRI

**Comment:** Submitted to the BraTS-Lighthouse 2025 Challenge (MICCAI 2025)

> **TL;DR:** EMedNeXt是一个增强型脑肿瘤分割框架，基于MedNeXt V2和深度监督，并针对撒哈拉以南非洲地区的低资源和低质量MRI图像进行了优化，在BraTS-Lighthouse 2025挑战赛中表现出色。

**AI_Comments:** EMedNeXt的创新之处在于其专门针对撒哈拉以南非洲地区独特的挑战（如低质量MRI和资源限制）进行了优化，这使得其在实际应用中更具可行性。该框架结合了MedNeXt V2、深度监督和多项改进，形成了一个鲁棒的解决方案。其在BraTS-Lighthouse 2025挑战赛中的优异表现，特别是高DSC和NSD分数，突显了其在解决全球医疗公平性问题上的重要性。该研究为欠发达地区的医学图像分析提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 全球数百万人受脑癌影响，医生诊断和监测胶质瘤依赖MRI。然而，当前手动分割MRI图像以量化肿瘤的方法耗时，需要专家放射科医生，且在资源匮乏的医疗系统中难以实现。在低收入地区，MRI扫描仪质量较低，放射学专业知识稀缺，导致分割和量化不准确。此外，非洲获得的MRI扫描数量通常较少。为了解决这些挑战，BraTS-Lighthouse 2025挑战赛专注于在撒哈拉以南非洲（SSA）进行鲁棒的肿瘤分割，因为资源限制和图像质量下降带来了显著的偏差。

**Method:** 本研究提出了EMedNeXt——一个增强型脑肿瘤分割框架，其基于MedNeXt V2并结合深度监督和为撒哈拉以南非洲（SSA）量身定制的优化后处理流程。EMedNeXt引入了三个关键贡献：更大的感兴趣区域、改进的基于nnU-Net v2的架构骨架以及一个鲁棒的模型集成系统。

**Result:** 在隐藏验证集上进行评估，我们的解决方案平均病灶级DSC达到0.897，平均病灶级NSD在0.5毫米和1.0毫米容差下分别为0.541和0.84。

**Conclusion:** EMedNeXt框架在应对撒哈拉以南非洲地区脑肿瘤分割的挑战（如资源限制和图像质量下降）方面表现出卓越的性能，证明了其在低资源医疗环境中进行准确肿瘤量化的潜力。

> **ai_Abstract:** 本研究提出了EMedNeXt，一个针对撒哈拉以南非洲（SSA）地区脑肿瘤分割的增强型框架。鉴于SSA地区MRI图像质量低、专家稀缺以及扫描数量少等挑战，EMedNeXt基于MedNeXt V2并整合了深度监督和优化的后处理流程。该框架通过引入更大的感兴趣区域、改进的nnU-Net v2架构和鲁棒的模型集成系统来提高性能。在隐藏验证集上的评估结果显示，EMedNeXt在肿瘤分割方面取得了高水平的准确性，证明了其在资源受限环境下进行精确脑肿瘤量化的有效性。

> **摘要翻译:** 脑癌影响全球数百万人，在几乎所有临床环境中，医生都依赖磁共振成像（MRI）来诊断和监测胶质瘤。然而，目前通过多参数MRI手动分割肿瘤进行量化的标准方法耗时，需要专家放射科医生，并且在资源不足的医疗系统中往往不可行。这个问题在低收入地区尤为突出，这些地区MRI扫描仪质量较低，放射学专业知识稀缺，导致分割和量化不准确。此外，非洲获得的MRI扫描数量通常较少。为了应对这些挑战，BraTS-Lighthouse 2025挑战赛专注于在撒哈拉以南非洲（SSA）进行鲁棒的肿瘤分割，因为资源限制和图像质量下降带来了显著的偏差。在本研究中，我们提出了EMedNeXt——一个增强型脑肿瘤分割框架，其基于MedNeXt V2并结合深度监督和为撒哈拉以南非洲（SSA）量身定制的优化后处理流程。EMedNeXt引入了三个关键贡献：更大的感兴趣区域、改进的基于nnU-Net v2的架构骨架以及一个鲁棒的模型集成系统。在隐藏验证集上进行评估，我们的解决方案平均病灶级DSC达到0.897，平均病灶级NSD在0.5毫米和1.0毫米容差下分别为0.541和0.84。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [312] [Pixel Embedding Method for Tubular Neurite Segmentation](https://arxiv.org/abs/2507.23359)
> *用于管状神经突触分割的像素嵌入方法*

*Huayu Fu, Jiamin Li, Haozhi Qu, Xiaolin Hu, Zengcai Guo* | **Category: eess.IV, cs.CV, q-bio.NC** | **Updated: 2025-07-31**

**Keywords:** 神经元分割, 像素嵌入, 拓扑重建, 深度学习, SWC格式

**Comment:** 

> **TL;DR:** 本文提出了一种基于像素嵌入的深度学习框架，用于自动分割神经元拓扑结构，并开发了一个端到端管道直接生成SWC格式的神经元结构树，同时引入了一种新的拓扑评估指标，实验证明其显著降低了神经元拓扑重建的错误率。

**AI_Comments:** 该论文的创新点在于提出了像素级嵌入向量来解决神经元遮挡区域的区分问题，并开发了一个端到端直接生成SWC格式结构树的管道，简化了工作流程。此外，引入新的拓扑评估指标也体现了对现有评估局限性的深入思考。这些贡献对于大规模神经影像数据的自动分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 处理大规模神经影像数据时，神经元拓扑的自动分割至关重要，能极大加速神经元标注和分析。然而，神经元分支的复杂形态以及纤维间的遮挡对基于深度学习的分割方法构成了巨大挑战。

**Method:** 首先，引入一个深度网络，输出像素级嵌入向量并设计相应的损失函数，使学习到的特征能有效区分遮挡区域内不同的神经元连接。其次，在此模型基础上，开发了一个端到端管道，直接将原始神经元图像映射为SWC格式的神经元结构树。最后，提出了一种新颖的拓扑评估指标，以更准确地量化神经元分割和重建的质量。

**Result:** 在fMOST成像数据集上的实验表明，与几种经典方法相比，本文提出的方法显著降低了神经元拓扑重建的错误率。

**Conclusion:** 该方法能够有效解决神经元分割中复杂的形态和遮挡问题，并显著提高神经元拓扑重建的准确性。

> **ai_Abstract:** 本研究提出了一种用于管状神经突触分割的像素嵌入方法，旨在解决神经元分支复杂形态和纤维遮挡带来的分割挑战。该方法包括一个生成像素级嵌入向量的深度网络及其对应的损失函数，一个将原始图像直接转换为SWC格式神经元结构树的端到端管道，以及一个新颖的拓扑评估指标。实验证明，该方法能显著降低神经元拓扑重建的错误率。

> **摘要翻译:** 神经元拓扑的自动分割对于处理大规模神经影像数据至关重要，因为它可以大大加速神经元注释和分析。然而，神经元分支的复杂形态以及纤维间的遮挡对基于深度学习的分割提出了重大挑战。为了解决这些问题，我们提出了一个改进的框架：首先，我们引入了一个深度网络，输出像素级嵌入向量并设计了相应的损失函数，使学习到的特征能够有效区分遮挡区域内不同的神经元连接。其次，在此模型的基础上，我们开发了一个端到端管道，直接将原始神经元图像映射为SWC格式的神经元结构树。最后，认识到现有评估指标未能完全捕捉分割精度，我们提出了一种新颖的拓扑评估指标，以更恰当地量化神经元分割和重建的质量。我们在fMOST成像数据集上的实验表明，与几种经典方法相比，我们的方法显著降低了神经元拓扑重建的错误率。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [347] [JPEG Processing Neural Operator for Backward-Compatible Coding](https://arxiv.org/abs/2507.23521)
> *适用于向后兼容编码的JPEG处理神经算子*

*Woo Kyoung Han, Yongjun Lee, Byeonghun Lee, Sang Hyun Park, Sunghoon Im, Kyong Hwan Jin* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** JPEG压缩, 神经算子, 向后兼容, 图像处理, 有损压缩

**Comment:** 

> **TL;DR:** JPNeO是一种新的JPEG算法，利用神经算子实现高兼容性和性能提升。

**AI_Comments:** 这篇论文的创新点在于将神经算子引入到JPEG编码和解码流程中，同时保持了与现有JPEG标准的完全向后兼容性，这对于实际应用和推广至关重要。其重要性体现在它为下一代图像压缩提供了一条可行的路径，既能利用深度学习的优势，又能避免大规模基础设施改造的障碍。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于学习的有损压缩算法取得了显著进展，但编解码器的标准化仍然是一个关键挑战。

**Method:** 论文提出了JPEG处理神经算子（JPNeO），通过在编码和解码阶段引入神经算子，在保持与当前JPEG格式完全向后兼容的同时，改进了色度分量保留并增强了重建保真度。

**Result:** JPNeO在减少内存使用和参数数量方面取得了实际效益，并且通过经验证据验证了高互信息空间存在的假设。

**Conclusion:** JPNeO作为一种高性能、开箱即用的图像压缩管道，无需更改源代码的协议。

> **ai_Abstract:** 本文介绍了一种名为JPEG处理神经算子（JPNeO）的新型JPEG算法，旨在解决基于学习的压缩算法标准化难题。JPNeO通过在编码和解码阶段集成神经算子，实现了与现有JPEG格式的完全向后兼容性，并显著提升了色度分量保留和重建保真度。此外，JPNeO还展现出内存使用和参数数量减少的实际优势，并验证了高互信息空间存在的假设。该算法提供了一个高性能且易于使用的图像压缩解决方案，无需修改现有协议。

> **摘要翻译:** 尽管基于学习的有损压缩算法取得了显著进展，但编解码器的标准化仍然是一个关键挑战。在本文中，我们提出了JPEG处理神经算子（JPNeO），这是一种下一代JPEG算法，可与当前JPEG格式保持完全向后兼容。我们的JPNeO通过在编码和解码阶段引入神经算子，与现有伪影去除方法相比，改进了色度分量保留并增强了重建保真度。JPNeO在减少内存使用和参数数量方面取得了实际效益。我们通过经验证据进一步验证了关于高互信息空间存在的假设。总而言之，JPNeO无需更改源代码的协议，即可作为一种高性能的开箱即用图像压缩管道。我们的源代码可在https://github.com/WooKyoungHan/JPNeO获取。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [406] [Exploiting Scale-Variant Attention for Segmenting Small Medical Objects](https://arxiv.org/abs/2407.07720)
> *利用尺度变异注意力分割小型医学目标*

*Wei Dai, Rui Liu, Zixuan Wu, Tianyi Wu, Min Wang, Junxian Zhou, Yixuan Yuan, Jun Liu* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 尺度变异注意力, 小型医学对象, 分割, 深度学习, SvANet

**Comment:** 14 pages, 9 figures, under review

> **TL;DR:** 本文提出了一种名为SvANet的新型网络，通过结合尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器，有效解决了深度学习在医学图像中分割小型目标时面临的信息丢失和压缩缺陷问题，并在多项小型医学目标分割任务上取得了卓越性能。

**AI_Comments:** 本文提出了一种新颖的SvANet模型，其创新点在于结合了尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器，专门针对小型医学对象分割中的信息丢失和压缩缺陷问题。该方法的重要性在于其在多种小型医学目标（如肿瘤、病变、血管等）分割任务上取得了显著的性能提升，这对于疾病的早期诊断和治疗具有重要意义。该研究成功解决了深度学习在处理小尺寸目标时的固有挑战，为医学图像分析领域提供了新的思路和强大的工具。

<details>
  <summary>Details</summary>

**Motivation:** 早期发现和准确诊断小型病理区域对于疾病的早期诊断和有效治疗至关重要。然而，深度学习算法，特别是卷积神经网络（CNNs），在医学图像中分割小型区域时面临挑战，因为卷积和池化操作会导致信息丢失和压缩缺陷，这在网络加深时对小型医学对象尤为明显。

**Method:** 本文提出了一种新颖的基于尺度变异注意力的网络（SvANet），用于精确分割医学图像中的小型对象。SvANet由尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器组成，旨在融合跨尺度特征并减轻压缩伪影，以增强对小型医学对象的区分能力。

**Result:** SvANet在分割肾肿瘤、皮肤病变、肝肿瘤、息肉、手术切除细胞、视网膜血管和精子等多种小型医学对象（占图像区域不到1%）时，取得了卓越的性能，平均Dice系数分别达到96.12%（KiTS23）、96.11%（ISIC 2018）、89.79%（ATLAS）、84.15%（PolypGen）、80.25%（TissueNet）、73.05%（FIVES）和72.58%（SpermHealth）。

**Conclusion:** 本文提出的SvANet通过引入尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器，成功克服了深度学习在小型医学目标分割中的挑战，并在多个数据集上取得了显著优于现有方法的性能，证明了其在医学图像早期诊断中的巨大潜力。

> **ai_Abstract:** 本研究提出了一种名为SvANet的新型深度学习网络，旨在解决传统CNN在医学图像中分割小型目标时面临的信息丢失和压缩缺陷问题。SvANet结合了尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器，以增强对小型医学对象的区分能力并减轻伪影。实验结果表明，SvANet在七个不同的医学图像数据集上，对多种占据图像极小比例的小型目标分割任务均取得了目前最先进的性能，验证了其在早期疾病诊断中的应用潜力。

> **摘要翻译:** 早期检测和准确诊断可以预测恶性疾病转化的风险，从而增加有效治疗的可能性。识别具有小病理区域的轻微综合征是一个不祥的警告，并且是疾病早期诊断的基础。尽管深度学习算法，特别是卷积神经网络（CNNs），在分割医学对象方面显示出前景，但在医学图像中分析小区域仍然具有挑战性。这种困难源于CNN中卷积和池化操作导致的信息丢失和压缩缺陷，随着网络加深，这些缺陷变得更加明显，特别是对于小型医学对象。为了应对这些挑战，我们提出了一种新颖的基于尺度变异注意力的网络（SvANet），用于精确分割医学图像中的小型对象。SvANet由尺度变异注意力、跨尺度指导、蒙特卡洛注意力和视觉转换器组成，它融合了跨尺度特征并减轻了压缩伪影，以增强对小型医学对象的区分能力。定量实验结果表明，SvANet在分割肾肿瘤、皮肤病变、肝肿瘤、息肉、手术切除细胞、视网膜血管和精子方面表现出卓越的性能，其平均Dice系数分别为96.12%、96.11%、89.79%、84.15%、80.25%、73.05%和72.58%，这些对象在KiTS23、ISIC 2018、ATLAS、PolypGen、TissueNet、FIVES和SpermHealth数据集中分别占据不到1%的图像区域。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [410] [Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach](https://arxiv.org/abs/2507.23648)
> *迈向现场就绪的基于人工智能的疟疾诊断：一种持续学习方法*

*Louise Guillon, Soheib Biga, Yendoube E. Kantchire, Mouhamadou Lamine Sane, Grégoire Pasquier, Kossi Yakpa, Stéphane E. Sossou, Marc Thellier, Laurent Bonnardot, Laurence Lachaud, Renaud Piarroux, Ameyo M. Dorkenoo* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 疟疾诊断, 持续学习, 计算机辅助诊断, 域增量学习, YOLO

**Comment:** MICCAI 2025 AMAI Workshop, Accepted, Submitted Manuscript Version

> **TL;DR:** 本文探讨持续学习如何增强基于AI的疟疾诊断模型在不同地点部署时的泛化能力和鲁棒性，发现持续学习，特别是基于排练的方法，能显著提升性能。

**AI_Comments:** 本文的创新点在于将持续学习引入到AI辅助疟疾诊断领域，以解决模型在实际部署中面临的域泛化挑战。这对于推动AI医疗技术在资源受限环境下的应用具有重要意义。特别是强调了基于排练的持续学习方法的有效性，为未来现场就绪的医疗AI系统提供了有价值的实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 疟疾在全球范围内仍是重大健康挑战，尤其在资源匮乏地区，专家显微镜检查受限。尽管深度学习辅助诊断系统表现良好，但其在不同条件地点间的泛化能力有限，阻碍了临床部署。目前很少有实际解决方案来解决这一泛化问题。

**Method:** 本文将问题定义为域增量学习场景，使用基于YOLO的目标检测器，通过持续学习（CL）策略来适应新的采集站点，同时保持在先前领域上的性能。评估了四种CL策略（两种基于排练、两种基于正则化方法），并在一个多站点临床薄血涂片图像数据集上进行了实地条件评估。

**Result:** 结果表明，持续学习，特别是基于排练的方法，可以显著提高性能。

**Conclusion:** 这些发现强调了持续学习在开发可部署的、现场就绪的疟疾计算机辅助诊断工具方面的潜力。

> **ai_Abstract:** 本文针对AI辅助疟疾诊断系统在不同临床地点泛化能力差的问题，提出采用持续学习（CL）策略来增强模型对域偏移的鲁棒性。研究将此问题构建为域增量学习场景，并利用基于YOLO的目标检测器在多站点临床数据集上评估了四种CL方法。实验结果表明，持续学习，特别是基于排练的方法，能显著提升模型性能，这预示着CL在开发可部署的疟疾诊断工具方面具有巨大潜力。

> **摘要翻译:** 疟疾仍然是一个重大的全球健康挑战，特别是在专家显微镜检查可能受限的低资源环境中。基于深度学习的计算机辅助诊断（CAD）系统已经开发出来，并在薄血涂片图像上表现出有前景的性能。然而，它们的临床部署可能会因跨不同条件站点的泛化能力有限而受阻。但目前很少有实用的解决方案被提出。在这项工作中，我们研究了持续学习（CL）作为一种增强疟疾CAD模型对域偏移鲁棒性的策略。我们将问题框定为域增量学习场景，其中基于YOLO的目标检测器必须适应新的采集站点，同时保持在先前已见域上的性能。我们利用一个多站点临床薄血涂片图像数据集，在真实条件下评估了四种CL策略，其中两种是基于排练的，两种是基于正则化的方法。我们的结果表明，CL，特别是基于排练的方法，可以显著提高性能。这些发现突出了持续学习在支持开发可部署的、现场就绪的疟疾CAD工具方面的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [462] [Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic](https://arxiv.org/abs/2507.23763)
> *基于快速欧拉特征的医学图像分割拓扑优化*

*Liu Li, Qiang Ma, Cheng Ouyang, Johannes C. Paetzold, Daniel Rueckert, Bernhard Kainz* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 医学图像分割, 拓扑优化, 欧拉特征, 拓扑感知, 深度学习

**Comment:** 

> **TL;DR:** 该研究提出了一种基于欧拉特征（$\\chi$）的快速拓扑感知医学图像分割方法，通过计算拓扑违规图并使用拓扑感知校正网络来提高分割结果的拓扑正确性，同时保持像素级准确性，解决了现有方法在处理高维数据时计算复杂度高的问题。

**AI_Comments:** 该论文的创新点在于提出了基于欧拉特征（\\chi）的快速拓扑评估和校正机制，有效解决了传统拓扑感知方法（如持久同源性）在高维数据处理上的计算效率问题。通过引入拓扑违规图和拓扑感知校正网络，为医学图像分割中拓扑约束的满足提供了一种实用且高效的解决方案。其重要性在于提升了医学图像分割结果的临床可用性，尤其是在拓扑正确性至关重要的应用场景。

<details>
  <summary>Details</summary>

**Motivation:** 现有的深度学习医学图像分割方法虽然在传统指标上表现良好，但在需要拓扑约束（如连续边界或闭合曲面）时，往往无法达到临床可接受的准确性。像素级准确性有时不如拓扑属的正确性重要。现有的拓扑感知方法（如持久同源性）计算复杂度高，难以应用于高维数据。

**Method:** 我们提出了一种基于欧拉特征（$\\chi$）的新型快速拓扑感知分割方法。首先，我们提出了在2D和3D中计算\\chi的快速公式，并将预测与真实值之间的\\chi误差作为拓扑评估指标。然后，通过“拓扑违规图”（突出显示\\chi误差区域）来估计任何分割网络的空间拓扑正确性。最后，通过拓扑感知校正网络，根据拓扑违规图来细化任意网络的分割结果。

**Result:** 我们的方法在2D和3D数据集上的实验表明，它能显著提高拓扑正确性，同时保持像素级分割准确性。

**Conclusion:** 本研究提出了一种基于快速欧拉特征的医学图像分割拓扑优化方法，有效地解决了深度学习分割在医学图像中拓扑约束方面面临的挑战，并在保持像素级准确性的同时显著提高了拓扑正确性。

> **ai_Abstract:** 该论文提出了一种创新的、快速的医学图像拓扑感知分割方法，旨在解决现有深度学习方法在拓扑约束下准确性不足以及持久同源性方法计算复杂度高的问题。该方法核心是利用快速欧拉特征（\\chi）计算来量化拓扑误差，并通过生成拓扑违规图来识别错误区域。随后，一个专门的拓扑感知校正网络利用这些违规图对初始分割结果进行精修。实验证明，该方法在2D和3D数据集上均能显著提升分割的拓扑正确性，同时不损害像素级的准确性。

> **摘要翻译:** 基于深度学习的医学图像分割技术在基于Dice分数或IoU等传统指标评估时显示出有前景的结果。然而，这些全自动方法往往未能达到临床可接受的准确性，尤其是在需要遵守拓扑约束时，例如连续边界或闭合曲面。在医学图像分割中，分割结果在所需拓扑属方面的正确性有时甚至比像素级准确性更为重要。现有的拓扑感知方法通常通过持久同源性（PH）的概念来估计和约束拓扑结构。然而，由于其多项式计算复杂性，这些方法难以用于高维数据。为了克服这个问题，我们提出了一种基于欧拉特征（\\chi）的新型快速拓扑感知分割方法。首先，我们提出了在2D和3D中计算\\chi的快速公式。预测与真实值之间的标量\\chi误差用作拓扑评估指标。然后，我们通过所谓的拓扑违规图，即突出显示\\chi误差区域的详细图，来估计任何分割网络的空间拓扑正确性。最后，通过拓扑感知校正网络，根据拓扑违规图来细化任意网络的分割结果。我们的实验在2D和3D数据集上进行，结果表明我们的方法可以显著提高拓扑正确性，同时保持像素级分割准确性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [463] [ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology](https://arxiv.org/abs/2503.17564)
> *ModalTune：利用多模态信息微调幻灯片级基础模型以实现数字病理学中的多任务学习*

*Vishwesh Ramanathan, Tony Xu, Pushpak Pati, Faruk Ahmed, Maged Goubran, Anne L. Martel* | **Category: eess.IV, cs.CV, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 数字病理学, 微调, 多模态, 多任务学习, 基础模型

**Comment:** 

> **TL;DR:** ModalTune是一个新颖的微调框架，它通过引入Modal Adapter和使用LLM编码标签，在数字病理学中实现了多模态、多任务、泛癌建模的SOTA结果，并解决了WSI的挑战和训练信号弱的问题。

**AI_Comments:** ModalTune的创新之处在于其统一的微调框架，通过Modal Adapter有效整合多模态信息，并利用LLMs编码标签，这在数字病理学领域是一个重要的突破。它解决了传统方法对共享信息利用不足的问题，并在低数据量和泛癌设置下展现出强大的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 数字病理学中的预测任务面临巨大全玻片图像（WSI）尺寸和弱训练信号的挑战。当前方法未能充分利用任务和模态之间共享的信息。

**Method:** 提出ModalTune框架，引入Modal Adapter以在不修改SLFM权重的情况下集成新模态。使用大型语言模型（LLMs）将标签编码为文本，捕获多任务和癌症类型之间的语义关系。

**Result:** ModalTune在四种癌症类型上，针对单模态和多模态模型均取得了最先进（SOTA）的结果，共同改进了生存和癌症亚型预测，并在泛癌设置中保持竞争力。此外，ModalTune还可推广到两个分布外（OOD）数据集。

**Conclusion:** ModalTune是数字病理学中首个用于多模态、多任务和泛癌建模的统一微调框架。

> **ai_Abstract:** ModalTune是一个针对数字病理学中全玻片图像（WSIs）预测挑战而设计的微调框架。它通过引入Modal Adapter实现多模态信息集成而不修改基础模型权重，并利用大型语言模型（LLMs）编码标签以捕获多任务和癌症类型间的语义关系。该方法在多任务学习中取得了最先进的成果，并在多癌症类型上表现出色，同时具备良好的泛化能力，是数字病理学中首个统一的多模态、多任务、泛癌建模微调框架。

> **摘要翻译:** 数字病理学中的预测任务由于全玻片图像（WSIs）的巨大尺寸和训练信号的弱性质而具有挑战性。计算、数据可用性和自监督学习（SSL）的进展为幻灯片级基础模型（SLFMs）铺平了道路，这些模型可以在数据量不足的情况下改进预测任务。然而，当前方法未能充分利用任务和模态之间共享的信息。为了克服这一挑战，我们提出了ModalTune，一个新颖的微调框架，它引入了模态适配器（Modal Adapter）以在不修改SLFM权重的情况下集成新模态。此外，我们使用大型语言模型（LLMs）将标签编码为文本，在单一训练方案中捕获跨多个任务和癌症类型的语义关系。ModalTune在四种癌症类型上，针对单模态和多模态模型均取得了最先进（SOTA）的结果，共同改进了生存和癌症亚型预测，并在泛癌设置中保持竞争力。此外，我们还展示了ModalTune可推广到两个分布外（OOD）数据集。据我们所知，这是数字病理学中首个用于多模态、多任务和泛癌建模的统一微调框架。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [488] [Rethink Domain Generalization in Heterogeneous Sequence MRI Segmentation](https://arxiv.org/abs/2507.23110)
> *重新思考异构序列MRI分割中的域泛化*

*Zheyuan Zhang, Linkai Peng, Wanying Dou, Cuiling Sun, Halil Ertugrul Aktas, Andrea M. Bejar, Elif Keles, Gorkem Durak, Ulas Bagci* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 域泛化, MRI分割, 胰腺分割, 异构序列, 半监督学习

**Comment:** 

> **TL;DR:** 本文提出了PancreasDG数据集，用于研究异构MRI序列胰腺分割的域泛化问题，并提出了一种半监督方法，显著提升了跨序列分割性能，揭示了该领域的重要见解。

**AI_Comments:** 这篇论文的创新点在于首次关注异构MRI序列在域泛化中的重要性，并构建了一个大规模、高质量的PancreasDG数据集来填补现有基准的空白。其提出的半监督方法利用解剖不变性，为解决跨序列域泛化问题提供了有效途径，显著提升了胰腺分割的精度，对临床应用具有重要意义。该研究不仅提供了数据集，还揭示了域泛化中的关键见解，对未来研究具有指导作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有域泛化基准主要关注跨中心差异，忽略了T1和T2等异构MR序列带来的主要变异源。胰腺分割在腹部成像中仍是重大挑战，其器官小、不规则、对比度低且在公共跨域基准中代表性不足，尽管其在早期癌症检测、手术和糖尿病研究中具有重要的临床意义。

**Method:** 本文提出了PancreasDG，一个大规模多中心3D MRI胰腺分割数据集，包含来自六个机构的563个MRI扫描，涵盖静脉期和异相序列，并具有双盲、两遍协议创建的像素精确胰腺掩膜。基于此数据集，研究了跨中心和跨序列的变异。此外，提出了一种利用解剖不变性的半监督方法。

**Result:** 通过全面分析，研究揭示了三点见解：(i) 有限采样引入了可能被误认为是分布偏移的显著方差；(ii) 相同序列的跨中心性能与源域性能相关；(iii) 跨序列偏移需要专门的解决方案。提出的半监督方法在跨序列分割中显著优于现有最先进的域泛化技术，Dice分数提高了61.63%，在两个测试中心达到87.00%。

**Conclusion:** PancreasDG为医学图像域泛化设定了一个新的基准，并提出了有效的半监督方法来解决异构序列带来的挑战。

> **ai_Abstract:** 本文针对异构MRI序列中域泛化在胰腺分割领域的挑战，提出了PancreasDG数据集，这是一个大规模多中心3D MRI胰腺分割数据集，包含多序列和多中心数据。研究发现，有限采样、跨中心性能与源域性能的相关性以及跨序列偏移需要专门解决方案。为此，作者提出了一种利用解剖不变性的半监督方法，该方法在跨序列分割上显著优于现有技术，并为医学图像域泛化树立了新基准。

> **摘要翻译:** 临床磁共振（MR）协议生成许多T1和T2序列，其外观差异大于产生它们的采集站点。现有域泛化基准几乎只关注跨中心偏移，而忽略了这种主要的变异来源。胰腺分割仍然是腹部成像中的一个重大挑战：腺体小、不规则，被器官和脂肪包围，并且通常T1对比度低。最先进的深度网络在肝脏或肾脏上已经达到90%以上的Dice分数，但仍有20-30%的胰腺被遗漏。尽管该器官在早期癌症检测、手术和糖尿病研究中具有临床重要性，但在公共跨域基准中系统性地代表不足。为了弥补这一差距，我们提出了PancreasDG，一个大规模多中心3D MRI胰腺分割数据集，用于研究医学图像中的域泛化。该数据集包含来自六个机构的563个MRI扫描，涵盖静脉期和异相序列，通过双盲、两遍协议创建的像素精确胰腺掩膜，从而能够研究跨中心和跨序列的变异。通过全面分析，我们揭示了三个见解：（i）有限采样引入了可能被误认为是分布偏移的显著方差；（ii）相同序列的跨中心性能与源域性能相关；（iii）跨序列偏移需要专门的解决方案。我们还提出了一种利用解剖不变性的半监督方法，其性能显著优于最先进的域泛化技术，在两个测试中心的跨序列分割中，Dice分数提高了61.63%，达到87.00%。PancreasDG为医学图像中的域泛化设定了一个新的基准。数据集、代码和模型将在https://pancreasdg.netlify.app提供。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [494] [Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation](https://arxiv.org/abs/2507.23398)
> *智能视频胶囊内窥镜：基于原始图像的定位，用于增强胃肠道检查*

*Oliver Bause, Julia Werner, Paul Palomero Bernardo, Oliver Bringmann* | **Category: eess.IV, cs.AR, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 视频胶囊内窥镜, 原始图像处理, 边缘计算, 深度学习, 节能AI

**Comment:** Accepted at the 32nd International Conference on Neural Information
  Processing - ICONIP 2025

> **TL;DR:** 本文提出了一种针对低功耗边缘设备的节能AI方法，通过直接处理拜耳图像和定制硬件，在视频胶囊内窥镜中实现了高效的器官分类，显著延长了电池寿命。

**AI_Comments:** 本文的主要创新在于直接在原始拜耳图像上进行深度学习推理，并结合定制的超低功耗硬件加速器，极大地优化了边缘设备的能耗。这对于电池寿命是关键限制因素的医疗设备（如视频胶囊内窥镜）具有重要意义，提供了一种实用且高效的解决方案，有望推动智能医疗设备的发展。其将AI模型小型化与硬件协同设计的思路值得借鉴。

<details>
  <summary>Details</summary>

**Motivation:** 传统的深度神经网络由于模型庞大和操作复杂，不适用于低功耗边缘设备。此外，将相机传感器捕获的拜耳图像转换为RGB图像会消耗大量能量，这在资源受限设备上应尽可能避免。本研究旨在为传感器边缘设备（特别是受电池寿命严重限制的视频胶囊内窥镜）开发硬件适用的AI方案。

**Method:** 通过一个仅有63,000个参数的CNN和维特比解码的时间序列分析，直接在拜耳图像上执行器官分类。该过程在定制的PULPissimo片上系统（带有RISC-V核心和超低功耗硬件加速器）上实现，支持相机图像捕获和原始图像处理。

**Result:** 器官分类的最终准确率为93.06%。每张图像仅需5.31微焦耳的能量。与传统视频胶囊相比，在进入小肠前平均可节省89.9%的能量。

**Conclusion:** 本研究提出了一种高效的AI图像分类方法，通过直接处理原始拜耳图像和定制硬件加速器，显著降低了视频胶囊内窥镜的能耗，同时保持了高精度，解决了边缘设备上的能源限制问题。

> **ai_Abstract:** 本文针对低功耗传感器边缘设备（特别是视频胶囊内窥镜）的能源限制问题，提出了一种硬件友好的AI图像分类方法。该方法直接在原始拜耳图像上进行器官分类，利用一个轻量级CNN（63,000参数）和维特比解码，在定制的PULPissimo片上系统上实现。实验结果显示，器官分类准确率达93.06%，每张图像能耗仅为5.31微焦耳，相较于传统视频胶囊，可节省89.9%的能量，显著提升了设备的续航能力。

> **摘要翻译:** 对于许多涉及低功耗传感器边缘设备的实际应用，用于图像分类的深度神经网络可能不适用。这是因为它们通常模型尺寸较大，并且所需的操作往往超出此类资源受限设备的能力。此外，相机传感器通常捕获应用了拜耳滤色器的图像，这些图像随后被转换为常用于神经网络训练的RGB图像。然而，在资源受限的设备上，这种转换会消耗能量，如果可能的话，最好跳过。这项工作通过视频胶囊内窥镜（一种用于检查小肠的重要医疗程序，但其电池寿命受到严重限制）解决了对适用于传感器边缘设备的硬件友好型AI的需求。器官分类直接在拜耳图像上进行，最终准确率达到93.06%，涉及一个只有63,000个参数的CNN和维特比解码形式的时间序列分析。最后，利用定制的PULPissimo片上系统（带有RISC-V核心和超低功耗硬件加速器），展示了用相机捕获图像和原始图像处理的过程，提供了一种每张图像仅需5.31微焦耳的节能AI图像分类方法。结果，与传统视频胶囊相比，在进入小肠前平均可节省89.9%的能量。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [520] [GEPAR3D: Geometry Prior-Assisted Learning for 3D Tooth Segmentation](https://arxiv.org/abs/2508.00155)
> *GEPAR3D：几何先验辅助学习的3D牙齿分割*

*Tomasz Szczepański, Szymon Płotka, Michal K. Grzeszczyk, Arleta Adamowicz, Piotr Fudalej, Przemysław Korzeniowski, Tomasz Trzciński, Arkadiusz Sitek* | **Category: eess.IV, cs.AI, cs.CV, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 3D牙齿分割, 几何先验, 深度分水岭, 牙根尖, CBCT

**Comment:** Accepted for the 28th International Conference on Medical Image
  Computing and Computer Assisted Intervention (MICCAI) 2025

> **TL;DR:** GEPAR3D是一种新颖的3D牙齿分割方法，它将实例检测和多类别分割统一起来，并利用几何先验和深度分水岭方法，显著提高了CBCT图像中牙齿（尤其是牙根尖）的分割精度，对正畸临床决策具有重要意义。

**AI_Comments:** GEPAR3D的创新之处在于其将几何先验（统计形状模型）与深度分水岭方法相结合，并统一了实例检测和多类别分割，有效地解决了牙根尖等复杂结构的分割难题。其在外部数据集上的优异表现验证了方法的泛化能力和临床应用潜力，对于正畸领域的精确诊断具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 牙齿分割在锥形束CT（CBCT）中仍具挑战，特别是牙根尖等精细结构，而这对于正畸中评估牙根吸收至关重要。

**Method:** 本文引入了GEPAR3D，一种将实例检测和多类别分割统一到一步的新方法，旨在改善牙根分割。该方法整合了牙列的统计形状模型作为几何先验，捕获解剖背景和形态一致性，同时利用深度分水岭方法，将每个牙齿建模为连续的3D能量盆地，编码体素到边界的距离，以确保对狭窄、复杂的牙根尖进行精确分割。

**Result:** GEPAR3D在所有测试集上实现了最高的整体分割性能，平均Dice相似系数（DSC）达到95.0%（比次优方法高2.8%），召回率提高到95.2%（提高9.5%）。定性分析也显示牙根分割质量显著改善。

**Conclusion:** GEPAR3D在牙根分割质量上取得显著改进，表明其在更准确的牙根吸收评估和增强正畸临床决策方面具有巨大潜力。

> **ai_Abstract:** GEPAR3D是一种新颖的3D牙齿分割方法，旨在解决CBCT中牙根尖等精细结构分割的挑战。它通过整合牙列的统计形状模型作为几何先验，并利用深度分水岭方法统一实例检测和多类别分割。该方法在外部测试集上表现出卓越的性能，DSC达到95.0%，召回率达到95.2%，显著提高了牙根分割的准确性，对正畸中的牙根吸收评估和临床决策具有重要意义。

> **摘要翻译:** 锥形束CT（CBCT）中的牙齿分割仍然具有挑战性，特别是对于牙根尖等精细结构，这对于正畸中评估牙根吸收至关重要。我们引入了GEPAR3D，一种新颖的方法，它将实例检测和多类别分割统一到一个步骤中，旨在改善牙根分割。我们的方法整合了牙列的统计形状模型作为几何先验，捕获解剖背景和形态一致性，而无需强制执行限制性邻接约束。我们利用深度分水岭方法，将每个牙齿建模为连续的3D能量盆地，编码体素到边界的距离。这种实例感知的表示确保了对狭窄、复杂的牙根尖进行精确分割。我们的方法在来自单个中心的公开CBCT扫描上进行训练，并在来自两个内部和两个公共医疗中心的外部测试集上进行评估。GEPAR3D实现了最高的整体分割性能，在所有测试集上平均Dice相似系数（DSC）达到95.0%（比次优方法高2.8%），召回率提高到95.2%（提高9.5%）。定性分析表明牙根分割质量显著改善，表明在更准确的牙根吸收评估和增强正畸临床决策方面具有巨大潜力。我们提供了实现和数据集：https://github.com/tomek1911/GEPAR3D。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [562] [On the Utility of Virtual Staining for Downstream Applications as it relates to Task Network Capacity](https://arxiv.org/abs/2508.00164)
> *虚拟染色在下游应用中的效用及其与任务网络容量的关系*

*Sourya Sengupta, Jianquan Xu, Phuong Nguyen, Frank J. Brooks, Yang Liu, Mark A. Anastasio* | **Category: eess.IV, q-bio.QM** | **Updated: 2025-07-31**

**Keywords:** 虚拟染色, 下游任务, 深度学习, 网络容量, 图像分割

**Comment:** 

> **TL;DR:** 虚拟染色对下游任务的效用取决于任务网络的容量，当任务网络容量足够大时，虚拟染色可能无法提升甚至会降低性能。

**AI_Comments:** 这篇论文提出了一个重要的观点，即虚拟染色不仅仅是生成高质量图像，其真正的价值应体现在对下游任务的促进作用上。它挑战了传统上仅通过图像质量度量来评估虚拟染色的方法，并引入了“任务网络容量”这一关键概念，揭示了虚拟染色在某些情况下可能并不带来益处甚至有害，这对于指导虚拟染色技术的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的虚拟染色评估方法主要关注图像质量，但生物医学图像通常用于下游生物或临床任务。本研究旨在系统地探究虚拟染色在促进临床相关下游任务（如分割或分类）方面的效用，并考虑执行这些任务的深度神经网络的容量。

**Method:** 本研究使用生物学数据集进行了全面的实证评估，通过比较无标记图像、虚拟染色图像和真实荧光图像的任务性能来评估虚拟染色的效用。

**Result:** 结果表明，虚拟染色的效用在很大程度上取决于分割或分类任务网络提取有意义的任务相关信息的能力，这与网络容量的概念有关。当相关任务网络的容量足够大时，虚拟染色可能无法改善甚至会降低分割或分类性能。

**Conclusion:** 在决定是否进行虚拟染色时，应考虑任务网络的容量。

> **ai_Abstract:** 这项研究系统地探讨了虚拟染色在促进下游生物医学任务（如图像分割和分类）方面的实际效用，并特别关注了执行这些任务的深度神经网络的“任务网络容量”。研究发现，虚拟染色的效用并非总是积极的，它强烈依赖于任务网络从图像中提取相关信息的能力。当任务网络的容量足够大时，虚拟染色甚至可能导致任务性能下降。因此，在选择是否应用虚拟染色时，必须考虑下游任务网络的容量。

> **摘要翻译:** 虚拟染色，或称体外标记，已被提出用于通过深度学习的图像到图像转换网络从无标记图像计算生成合成荧光图像。在大多数已报道的研究中，虚拟染色图像仅使用传统的图像质量度量（如结构相似性或信噪比）进行评估。然而，在生物医学成像中，图像通常是为了促进基于图像的推断而获取的，我们将其称为下游生物或临床任务。本研究系统地调查了虚拟染色在促进临床相关下游任务（如分割或分类）方面的效用，并考虑了用于执行这些任务的深度神经网络的容量。使用生物学数据集进行了全面的实证评估，通过使用无标记、虚拟染色和真实荧光图像评估任务性能。结果表明，虚拟染色的效用在很大程度上取决于分割或分类任务网络提取有意义的任务相关信息的能力，这与网络容量的概念有关。提供了虚拟染色在相关任务网络容量足够大时未能改善甚至降低分割或分类性能的例子。结果表明，在决定是否执行虚拟染色时，应考虑任务网络的容量。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [604] [Weakly Supervised Intracranial Aneurysm Detection and Segmentation in MR angiography via Multi-task UNet with Vesselness Prior](https://arxiv.org/abs/2508.00235)
> *基于血管性先验的多任务UNet弱监督颅内动脉瘤检测与分割（MR血管造影）*

*Erin Rainville, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao* | **Category: eess.IV, cs.AI, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 颅内动脉瘤, 弱监督, UNet, 血管性先验, 检测, 分割

**Comment:** Accepted to ICCV 2025 Workshop CVAMD

> **TL;DR:** 本文提出了一种弱监督3D多任务UNet模型，结合血管性先验，用于MR血管造影图像中的颅内动脉瘤联合检测和分割，并在现有技术上取得了优越性能。

**AI_Comments:** 该论文的创新点在于提出了一个结合血管性先验的弱监督多任务UNet，解决了颅内动脉瘤检测和分割中数据标注稀缺的难题。通过联合训练检测和分割任务，并利用先验信息指导模型学习，有效提升了模型的性能和鲁棒性。其在真实数据集上的优越表现显示了该方法在临床应用中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 颅内动脉瘤（IAs）破裂可能导致危及生命的后果，但其在放射影像中尺寸小、对比度低，使得准确高效的检测和形态学分析变得困难。此外，缺乏大型体素级专家标注的公共数据集，对深度学习算法的开发构成了挑战。

**Method:** 提出了一种新颖的弱监督3D多任务UNet，集成了血管性先验，以联合执行TOF-MRA中的动脉瘤检测和分割。具体地，利用Frangi血管性滤波器为网络输入和注意力模块提供软脑血管先验，从解码器进行分割，从辅助分支进行检测。模型在Lausanne数据集上使用粗略的真值分割进行训练，并在同一数据库的精细标注测试集上进行评估。模型还在ADAM数据集上进行了外部验证以评估泛化能力。

**Result:** 所提出的技术在动脉瘤分割（Dice = 0.614，95%HD =1.38mm）和检测（假阳性率 = 1.47，敏感性 = 92.9%）方面表现出优于SOTA技术的性能。

**Conclusion:** 本研究提出的弱监督多任务UNet结合血管性先验的方法，能够有效且准确地在MR血管造影图像中进行颅内动脉瘤的检测和分割，并在多个数据集上验证了其优越性和泛化能力。

> **ai_Abstract:** 本文针对颅内动脉瘤（IAs）在MR血管造影图像中检测和分割的挑战，特别是缺乏大规模精确标注数据的困境，提出了一种新颖的弱监督3D多任务UNet模型。该模型巧妙地整合了Frangi血管性先验，以同时进行动脉瘤的检测和分割。通过将血管性先验作为网络输入和注意力模块的指导，模型能够从解码器执行分割，并从辅助分支执行检测。研究在Lausanne和ADAM数据集上进行了训练和验证，结果表明，该方法在动脉瘤分割和检测方面均优于现有最先进技术，展现了其在临床应用中的巨大潜力。

> **摘要翻译:** 颅内动脉瘤（IAs）是脑血管的异常扩张，如果破裂，可能导致危及生命的后果。然而，它们在放射学扫描中尺寸小且对比度柔和，这使得准确高效地进行检测和形态学分析变得困难，而这些在疾病的临床护理中至关重要。此外，缺乏带有体素级专家标注的大型公共数据集，对开发解决这些问题的深度学习算法构成了挑战。因此，我们提出了一种新颖的弱监督3D多任务UNet，该网络集成了血管性先验，以在飞行时间MR血管造影（TOF-MRA）中联合执行动脉瘤检测和分割。具体而言，为了稳健地引导IA检测和分割，我们采用流行的Frangi血管性滤波器来导出软脑血管先验，用于网络输入和注意力块，以从解码器进行分割，并从辅助分支进行检测。我们在Lausanne数据集上使用粗略的真值分割训练我们的模型，并在同一数据库中具有精细标注的测试集上进行评估。为了进一步评估我们模型的泛化能力，我们还在ADAM数据集上进行了外部验证。我们的结果表明，所提出的技术在动脉瘤分割（Dice = 0.614，95%HD =1.38mm）和检测（假阳性率 = 1.47，敏感性 = 92.9%）方面优于SOTA技术。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [628] [Towards High-Resolution Alignment and Super-Resolution of Multi-Sensor Satellite Imagery](https://arxiv.org/abs/2507.23150)
> *面向多传感器卫星图像的高分辨率对齐与超分辨率*

*Philip Wootaek Shin, Vishal Gaur, Rahul Ramachandran, Manil Maskey, Jack Sampson, Vijaykrishnan Narayanan, Sujit Roy* | **Category: eess.IV, cs.CV** | **Updated: 2025-07-30**

**Keywords:** 超分辨率, 多传感器, 卫星图像, 图像对齐, HLS

**Comment:** 

> **TL;DR:** 本研究开发了一个初步框架，利用HLS 10m数据作为参考，对HLS 30m卫星图像进行对齐和超分辨率处理，以弥合不同传感器之间的分辨率差距，并提高超分辨率图像的质量。

**AI_Comments:** 本研究的创新点在于其直接使用真实的多传感器卫星数据（HLS 10m和HLS 30m）进行对齐和超分辨率，而非依赖人工降采样数据，这使其更贴近实际应用需求。它解决了异构传感器数据融合中的一个关键问题，为高分辨率遥感数据应用提供了新途径。然而，作为一个“初步框架”，其方法的通用性和在更广泛异构传感器组合上的表现仍有待进一步验证和提升。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率卫星图像对于地理空间分析至关重要，但不同卫星传感器之间的空间分辨率差异给数据融合和下游应用带来了挑战。现有的超分辨率方法依赖于人工降采样图像而非真实传感器数据，并且不适用于具有不同光谱和时间特征的异构卫星传感器。

**Method:** 本研究开发了一个初步框架，使用协调陆地卫星哨兵10米（HLS10）图像作为参考，对协调陆地卫星哨兵30米（HLS 30）图像进行对齐和超分辨率处理。该方法旨在弥合传感器之间的分辨率差距并提高超分辨率陆地卫星图像的质量。

**Result:** 定量和定性评估均证明了该方法的有效性，显示了其在增强基于卫星的遥感应用方面的潜力。

**Conclusion:** 这项研究为异构卫星图像超分辨率的可行性提供了见解，并强调了该领域未来发展需要考虑的关键因素。

> **ai_Abstract:** 本研究针对多传感器卫星图像在分辨率差异方面的数据融合挑战，提出了一个初步的对齐和超分辨率框架。该框架以协调陆地卫星哨兵10米（HLS10）图像为参考，处理协调陆地卫星哨兵30米（HLS 30）图像，旨在弥合不同传感器之间的分辨率差距并提升超分辨率图像的质量。实验结果表明该方法有效，并为异构卫星图像超分辨率的未来发展提供了可行性见解。

> **摘要翻译:** 高分辨率卫星图像对于地理空间分析至关重要，然而卫星传感器之间空间分辨率的差异给数据融合和下游应用带来了挑战。超分辨率技术可以帮助弥合这一差距，但现有方法依赖于人工降采样图像而非真实传感器数据，并且不适用于具有不同光谱和时间特征的异构卫星传感器。在这项工作中，我们开发了一个初步框架，利用协调陆地卫星哨兵10米（HLS10）作为参考，对来自HLS数据集的协调陆地卫星哨兵30米（HLS 30）图像进行对齐和超分辨率处理。我们的方法旨在弥合这些传感器之间的分辨率差距，并提高超分辨率陆地卫星图像的质量。定量和定性评估均证明了我们方法的有效性，显示了其在增强基于卫星的遥感应用方面的潜力。这项研究为异构卫星图像超分辨率的可行性提供了见解，并强调了该领域未来发展中的关键考虑因素。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [646] [Diffusion-Based User-Guided Data Augmentation for Coronary Stenosis Detection](https://arxiv.org/abs/2508.00438)
> *基于扩散的用户引导数据增强用于冠状动脉狭窄检测*

*Sumin Seo, In Kyu Lee, Hyun-Woo Kim, Jaesik Min, Chung-Hwan Jung* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 冠状动脉狭窄, 数据增强, 扩散模型, 深度学习, 医学影像

**Comment:** Accepted at MICCAI 2025. Dataset available at
  https://github.com/medipixel/DiGDA

> **TL;DR:** 本研究提出一种基于扩散模型的用户引导数据增强方法，用于生成逼真的冠状动脉狭窄病变，以解决深度学习在冠状动脉狭窄检测中面临的数据受限和类别不平衡问题，并在有限数据下表现出卓越的检测和分类性能。

**AI_Comments:** 该论文的创新之处在于利用扩散模型进行用户引导的数据增强，以生成逼真的医疗图像病变，这直接解决了医学影像领域数据稀缺和类别不平衡的常见挑战。这种方法在临床应用中具有高度实用性，尤其是在难以获取大规模、多样化且标注良好数据集的情况下，能够有效提升诊断模型的性能和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 冠状动脉狭窄的自动定位和严重程度测量对于诊断和治疗至关重要，但当前的深度学习方法常受限于标注数据不足和类别不平衡等挑战。

**Method:** 提出了一种新颖的数据增强方法，该方法使用基于扩散模型的图像修复技术来生成逼真的病变，并允许用户引导控制病变严重程度。

**Result:** 在各种合成数据集大小下，对病变检测和严重程度分类的广泛评估表明，该方法在大型内部数据集和公共冠状动脉造影数据集上均表现出卓越的性能。此外，即使在有限数据训练下，该方法也能保持高检测和分类性能。

**Conclusion:** 本研究提出的方法显著提高了狭窄严重程度的评估，并优化了数据利用，对于改善可靠的决策支持具有重要的临床意义，尤其是在数据有限的场景下。

> **ai_Abstract:** 本文提出了一种新颖的基于扩散模型的用户引导数据增强方法，旨在解决冠状动脉狭窄自动检测中面临的标注数据稀缺和类别不平衡问题。该方法通过扩散模型生成逼真的冠状动脉病变，并允许用户控制病变严重程度，从而有效扩充训练数据。实验结果表明，该方法在病变检测和严重程度分类方面表现优异，尤其是在有限数据训练下仍能保持高性能，这对于提高冠状动脉狭窄评估的准确性和优化医疗数据利用具有重要的临床价值。

> **摘要翻译:** 冠状动脉狭窄是导致缺血性心脏事件并增加死亡率的主要风险因素，对该病症的医疗处理需要细致、劳动密集型的分析。冠状动脉造影提供了评估狭窄的关键视觉线索，支持临床医生做出明智的诊断和治疗决策。深度学习的最新进展在狭窄的自动化定位和严重程度测量方面显示出巨大潜力。然而，在现实场景中，这些有效方法的成功常常受到标注数据有限和类别不平衡等挑战的阻碍。在本研究中，我们提出了一种新颖的数据增强方法，该方法使用基于扩散模型的图像修复技术来生成逼真的病变，允许用户引导控制严重程度。在各种合成数据集大小下，对病变检测和严重程度分类的广泛评估表明，我们的方法在大型内部数据集和公共冠状动脉造影数据集上均表现出卓越的性能。此外，我们的方法即使在有限数据训练下也能保持高检测和分类性能，这突显了其在改善狭窄严重程度评估和优化数据利用以实现更可靠决策支持方面的临床重要性。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [694] [FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems](https://arxiv.org/abs/2508.00721)
> *FMPlug：用于逆问题的即插即用基础流匹配先验*

*Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun* | **Category: eess.IV, cs.CV, cs.LG, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 流匹配先验, 逆问题, 即插即用框架, 图像超分辨率, 高斯去模糊

**Comment:** 

> **TL;DR:** FMPlug是一个即插即用的框架，通过利用观测对象与期望对象的相似性以及生成流的高斯性，并引入时间自适应热身策略和尖锐高斯正则化，显著提升了基础流匹配先验在解决病态逆问题上的性能，在图像超分辨率和高斯去模糊方面超越了现有SOTA方法。

**AI_Comments:** FMPlug的创新之处在于其“即插即用”的特性，以及巧妙地结合了观测-期望相似性和生成流高斯性这两个洞察力。通过引入时间自适应热身和高斯正则化，它有效地将领域无关的基础模型应用于逆问题，并取得了超越SOTA的性能，这表明了其在处理各种逆问题方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的逆问题解决方法依赖于领域特定或未经训练的先验，而本文旨在通过提出FMPlug框架，利用基础流匹配（FM）先验来解决病态逆问题，克服现有方法的局限性，并释放领域无关基础模型的潜力。

**Method:** FMPlug通过利用观测对象与期望对象的相似性以及生成流的高斯性这两个简单但强大的洞察力来增强基础流匹配先验。它引入了一种时间自适应热身策略和尖锐高斯正则化来解锁领域无关基础模型的真正潜力。

**Result:** FMPlug在图像超分辨率和高斯去模糊方面，以显著优势击败了使用基础流匹配先验的现有最先进方法。

**Conclusion:** FMPlug是一种新颖的即插即用框架，它通过利用简单而强大的洞察力并引入新的策略，显著提升了基础流匹配先验在解决病态逆问题上的性能，并在多个任务上超越了现有SOTA方法。

> **ai_Abstract:** FMPlug是一个新颖的即插即用框架，旨在通过增强基础流匹配（FM）先验来解决病态逆问题。它利用观测与期望对象的相似性及生成流的高斯性，并结合时间自适应热身策略和尖锐高斯正则化，从而提升了领域无关基础模型的性能。该方法在图像超分辨率和高斯去模糊任务上显著优于现有使用基础FM先验的最先进方法。

> **摘要翻译:** 我们提出了FMPlug，一个新颖的即插即用框架，它增强了基础流匹配（FM）先验，用于解决病态逆问题。与依赖领域特定或未经训练先验的传统方法不同，FMPlug巧妙地利用了两个简单但强大的洞察力：观测对象与期望对象之间的相似性以及生成流的高斯性。通过引入时间自适应热身策略和尖锐高斯正则化，FMPlug释放了领域无关基础模型的真正潜力。我们的方法在图像超分辨率和高斯去模糊方面，以显著优势击败了使用基础FM先验的现有最先进方法。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [744] [AI-Driven Collaborative Satellite Object Detection for Space Sustainability](https://arxiv.org/abs/2508.00755)
> *AI驱动的协同卫星目标检测实现空间可持续性*

*Peng Hu, Wenxuan Zhang* | **Category: eess.IV, cs.CV** | **Updated: 2025-08-01**

**Keywords:** 卫星目标检测, 空间可持续性, 深度学习, 协同检测, 空间态势感知

**Comment:** Submitted to the 13th Annual IEEE International Conference on
  Wireless for Space and Extreme Environments (WiSEE 2025)

> **TL;DR:** 该研究提出了一种AI驱动的卫星集群框架，通过多卫星协作进行深度学习目标检测，以提高空间态势感知能力，应对低地球轨道卫星密度增加带来的碰撞风险，并实验证明其在保持低SWaP的同时，具有与现有方法相当的检测精度。

**AI_Comments:** 该论文的创新点在于提出了AI驱动的协同卫星集群框架，通过多卫星协作实现空间目标检测，有效解决了传统地基系统在延迟和覆盖范围上的局限性。其引入距离感知视点选择策略和构建高保真数据集也为该领域的后续研究提供了有益的参考。该方法在低SWaP下实现了高精度，对于未来在轨部署具有重要意义，有助于提升空间态势感知和空间可持续性。

<details>
  <summary>Details</summary>

**Motivation:** 低地球轨道（LEO）卫星密度的不断增长导致在轨碰撞风险增加，严重威胁空间可持续性。传统的地基跟踪系统受限于延迟和覆盖范围，因此迫切需要机载、基于视觉的空间目标检测（SOD）能力。

**Method:** 本文提出了一种新颖的卫星集群框架，支持多颗卫星协同执行基于深度学习（DL）的空间目标检测（SOD）任务。为支持此方法，构建了一个模拟集群卫星编队成像场景的高保真数据集。引入了一种距离感知视点选择策略以优化检测性能，并使用最新的深度学习模型进行评估。

**Result:** 实验结果表明，与单卫星和现有方法相比，基于集群的方法在保持低尺寸、重量和功耗（SWaP）占用空间的同时，实现了具有竞争力的检测精度。

**Conclusion:** 这些发现强调了分布式、AI赋能的在轨系统在增强空间态势感知和促进长期空间可持续性方面的潜力。

> **ai_Abstract:** 本论文提出了一种AI驱动的协同卫星集群框架，旨在通过多卫星协作执行深度学习空间目标检测，以应对低地球轨道卫星密度增加带来的碰撞风险。研究构建了高保真数据集并引入了距离感知视点选择策略以优化检测。实验证明，该集群方法在保持低SWaP的同时，能实现与现有方法相当的检测精度，显示了分布式AI系统在提升空间态势感知和可持续性方面的巨大潜力。

> **摘要翻译:** 低地球轨道（LEO）中卫星密度的不断增长对空间可持续性提出了严峻挑战，这主要是由于在轨碰撞风险的增加。传统的地基跟踪系统受到延迟和覆盖范围的限制，这突显了对机载、基于视觉的空间目标检测（SOD）能力的需求。在本文中，我们提出了一种新颖的卫星集群框架，该框架能够使多个卫星协作执行基于深度学习（DL）的空间目标检测任务。为了支持这种方法，我们构建了一个高保真数据集，模拟了集群卫星编队的成像场景。引入了一种距离感知视点选择策略以优化检测性能，并使用最新的DL模型进行评估。实验结果表明，与单卫星和现有方法相比，基于集群的方法在保持低尺寸、重量和功耗（SWaP）占用空间的同时，实现了具有竞争力的检测精度。这些发现强调了分布式、AI赋能的在轨系统在增强空间态势感知和促进长期空间可持续性方面的潜力。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [188] [DoF Analysis and Beamforming Design for Active IRS-aided Multi-user MIMO Wireless Communication in Rank-deficient Channels](https://arxiv.org/abs/2411.07001)
> *秩亏信道中主动式IRS辅助多用户MIMO无线通信的DoF分析与波束成形设计*

*Jinbing Jiang, Feng Shu, Xuehui Wang, Ke Yang, Chong Shen, Qi Zhang, Dongming Wang, Jiangzhou Wang* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** IRS, MIMO, 自由度, 波束成形, 秩亏信道

**Comment:** 12 pages, 9 figures

> **TL;DR:** 本文分析了IRS辅助多用户MIMO网络的自由度（DoF），并提出了实现最大DoF的波束成形方法。研究发现，在秩亏信道中，IRS能使网络DoF倍增，并显著提升速率。

**AI_Comments:** 本文深入分析了IRS在秩亏信道中对DoF的潜在提升，并提出了具体的波束成形方案来利用这一优势。其核心创新在于揭示了IRS在特定信道条件下能使网络DoF倍增，并通过仿真验证了显著的速率增益。这对于未来6G通信中利用IRS提升频谱效率具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能反射面（IRS）因其显著提高数据速率的能力，有望成为未来6G等无线网络中的关键技术。本文旨在分析IRS辅助多用户MIMO网络中的自由度（DoF）。

**Method:** 首先，推导了IRS辅助单用户MIMO网络的DoF上限，并通过矩阵秩不等式将其结果推广到IRS辅助多用户MIMO场景。其次，提出了三种闭式波束成形方法：零空间投影加最大发射功率和最大接收功率（NSP-MTP-MRP）、施密特正交化加最小均方误差（SO-MMSE）以及两层泄漏加MMSE（TLL-MMSE），以实现最大DoF。

**Result:** 仿真结果表明，IRS确实能显著提升速率。例如，在严重秩亏信道中，所提出的IRS辅助TLL-MMSE方法的总速率大约是无IRS情况下的两倍。

**Conclusion:** IRS可以在秩亏信道中实现显著的DoF改进和速率提升。

> **ai_Abstract:** 本文研究了IRS辅助多用户MIMO网络中的自由度（DoF）和波束成形设计。通过推导DoF上限，并提出NSP-MTP-MRP、SO-MMSE和TLL-MMSE三种闭式波束成形方法，以实现最大DoF。仿真结果表明，在秩亏信道中，IRS能够使网络DoF倍增，并显著提升系统速率，特别是TLL-MMSE方法能使总速率翻倍。

> **摘要翻译:** 由于其显著提高数据速率的能力，智能反射面（IRS）将成为未来6G等无线网络的潜在关键技术。本文将重点分析IRS辅助多用户MIMO网络中的自由度（DoF）。首先，推导了IRS辅助单用户MIMO网络的DoF上限，即此类系统可实现的最大DoF，并通过矩阵秩不等式将其结果推广到IRS辅助多用户MIMO的情况。特别是在严重的秩亏（也称为低秩）信道（如视距（LoS）信道）中，在IRS的帮助下，网络DoF可能会比无IRS情况翻倍。为了验证增强DoF带来的速率性能增益，提出了三种闭式波束成形方法：零空间投影加最大发射功率和最大接收功率（NSP-MTP-MRP）、施密特正交化加最小均方误差（SO-MMSE）以及两层泄漏加MMSE（TLL-MMSE），以实现最大DoF。仿真结果表明，IRS确实带来了显著的速率提升。例如，在严重的秩亏信道中，所提出的IRS辅助TLL-MMSE的总速率大约是无IRS情况下的两倍。这意味着IRS在这种信道中可以实现显著的DoF改进。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [230] [HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Recordings](https://arxiv.org/abs/2507.17224)
> *HuiduRep：一个用于从细胞外记录中学习神经表征的鲁棒自监督框架*

*Feng Cao, Zishuo Feng, Wei Shi, Jicong Zhang* | **Category: eess.SP, cs.AI, q-bio.NC** | **Updated: 2025-08-01**

**Keywords:** 自监督学习, 神经表征, 尖峰分选, 细胞外记录, 对比学习

**Comment:** 9 pages, 3 figures, 6 tables

> **TL;DR:** HuiduRep是一个鲁棒的自监督框架，通过结合对比学习和去噪自编码器，从细胞外记录中提取判别性和可泛化的特征，以改善低信噪比、电极漂移和跨会话变异性下的尖峰分选。

**AI_Comments:** HuiduRep的创新之处在于其结合了对比学习和去噪自编码器来增强自监督学习，从而提高了从细胞外记录中提取神经表征的鲁棒性。其重要性体现在它解决了尖峰分选这一神经科学基础任务中的关键挑战，即在复杂条件下（低信噪比、电极漂移、跨会话变异性）实现准确和泛化。通过提供无需真值标签的解决方案，它降低了实际应用的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 在神经科学中，细胞外记录是解码单神经元分辨率脑活动的基础方式，而尖峰分选是脑感知管线中的关键步骤。然而，在低信噪比、电极漂移和跨会话变异性条件下，尖峰分选仍然面临挑战。

**Method:** 本文提出了HuiduRep，一个鲁棒的自监督表征学习框架。它通过将对比学习与去噪自编码器相结合，学习对噪声和漂移具有鲁棒性的潜在表征。基于HuiduRep，开发了一个无需真值标签即可聚类尖峰表征的尖峰分选管线。

**Result:** 在混合和真实世界数据集上的实验表明，HuiduRep表现出强大的鲁棒性。此外，该管线在各种数据集上的准确性和精度方面显著优于KiloSort4和MountainSort5等最先进的工具。

**Conclusion:** 这些发现表明，自监督尖峰表征学习作为一种基础工具，在细胞外记录的鲁棒和可泛化处理方面具有潜力。

> **ai_Abstract:** HuiduRep是一种新颖的自监督表征学习框架，专为解决细胞外记录中尖峰分选的挑战而设计，例如低信噪比和电极漂移。该框架结合了对比学习和去噪自编码器，以学习鲁棒且可泛化的神经表征。通过将这些表征应用于尖峰分选管线，HuiduRep在没有真值标签的情况下实现了高精度和鲁棒性，并在实验中优于现有最先进的工具。

> **摘要翻译:** 细胞外记录是神经元附近瞬态电压波动，是神经科学中以单神经元分辨率解码大脑活动的基本方式。尖峰分选是将每个检测到的尖峰归因于其相应神经元的过程，是脑感知管线中的关键一步。然而，在低信噪比（SNR）、电极漂移和跨会话变异性下，这仍然具有挑战性。在本文中，我们提出了HuiduRep，一个鲁棒的自监督表征学习框架，可以从细胞外记录中提取判别性和可泛化的特征。通过将对比学习与去噪自编码器相结合，HuiduRep学习对噪声和漂移具有鲁棒性的潜在表征。利用HuiduRep，我们开发了一个尖峰分选管线，该管线在没有真值标签的情况下对尖峰表征进行聚类。在混合和真实世界数据集上的实验表明，HuiduRep实现了强大的鲁棒性。此外，该管线在各种数据集上的准确性和精度方面显著优于KiloSort4和MountainSort5等最先进的工具。这些发现证明了自监督尖峰表征学习作为一种基础工具，在细胞外记录的鲁棒和可泛化处理方面的潜力。代码可在https://github.com/IgarashiAkatuki/HuiduRep获取。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [234] [Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey](https://arxiv.org/abs/2507.23526)
> *6G近场无线通信信道估计：一项综合性调查*

*Wen-Xuan Long, Shengyu Ye, Marco Moretti, Michele Morelli, Luca Sanguinetti, Rui Chen, Cheng-Xiang Wang* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 6G, 近场通信, 信道估计, ELAA, 综述

**Comment:** 

> **TL;DR:** 该论文全面调查了6G近场无线通信中的信道估计技术，讨论了其与远场的区别、模型、主要估计方法以及未来的挑战和方向。

**AI_Comments:** 该调查对6G近场通信中的核心问题——信道估计进行了及时且全面的梳理。其重要性在于，随着6G技术向超高频和ELAAs发展，近场效应成为关键挑战，传统远场方法不再适用。该论文不仅系统地介绍了近场传播特性和模型，还分类讨论了多种估计技术及其权衡，为研究人员提供了宝贵的参考框架。同时，指明未来挑战和方向，对推动该领域发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 第六代（6G）无线系统预计将采用超大孔径阵列（ELAAs）和极高频段，导致通信从传统远场转向近场，其中球形波前占据主导，信道响应依赖于角度和距离，增加了信道维度。传统的远场信道估计方法在近场场景中因导频开销和计算复杂性增加而面临挑战，因此亟需对近场信道估计进行深入研究和综述。

**Method:** 本文对近场信道估计的最新进展进行了全面调查。首先，从电磁学角度定义了近场和远场边界，并讨论了关键的传播差异，同时简要回顾了ELAA的发展。然后，介绍了主流的近场信道模型，并与远场模型进行了比较。最后，在不同配置（单/多用户、单/多载波）下审查了主要的估计技术，包括直接估计和RIS辅助的级联估计。

**Result:** 调查揭示了各种信道估计算法在估计精度、复杂度和开销之间的权衡。该调查旨在为6G系统中高效可扩展的近场信道估计提供见解和基础。

**Conclusion:** 本文旨在为6G系统中高效可扩展的近场信道估计提供见解和基础，并确定了关键挑战和未来的研究方向。

> **ai_Abstract:** 本论文对6G近场无线通信中的信道估计进行了全面调查。文章首先阐明了近场与远场的电磁学边界和传播特性差异，并回顾了ELAA的发展。接着，详细介绍了主流的近场信道模型，并与远场模型进行了对比。论文还分类回顾了各种信道估计技术，包括直接估计和RIS辅助估计，并分析了它们在精度、复杂度和开销方面的权衡。最终，该调查旨在为6G系统的近场信道估计提供基础和见解，并指明未来的研究方向和挑战。

> **摘要翻译:** 第六代（6G）无线系统有望采用超大孔径阵列（ELAAs）、新型天线架构，并在极高频段运行，以满足日益增长的数据需求。ELAAs显著增加了天线数量，实现了更精细的空间分辨率和改进的波束赋形。在高频下，ELAAs将通信从传统的远场转向近场，其中球形波前占据主导地位，信道响应取决于角度和距离，从而增加了信道维度。传统的远场信道估计方法依赖于角度信息，在近场场景中因导频开销和计算复杂性增加而面临困难。本文对近场信道估计的最新进展进行了全面调查。它首先从电磁学角度定义了近场和远场边界，并讨论了关键的传播差异，同时简要回顾了ELAA的发展。然后，介绍了主流的近场信道模型，并与远场模型进行了比较。在不同配置（单/多用户、单/多载波）下审查了主要的估计技术，包括直接估计和RIS辅助的级联估计。这些技术揭示了估计精度、复杂性和开销之间的权衡。本调查旨在为6G系统中高效可扩展的近场信道估计提供见解和基础，同时识别关键挑战和未来的研究方向。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [266] [Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN](https://arxiv.org/abs/2507.21696)
> *边缘智能体AI框架用于O-RAN中的自主网络优化*

*Abdelaziz Salama, Zeinab Nezami, Mohammed M. H. Qazzaz, Maryam Hafeez, Syed Ali Raza Zaidi* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 边缘AI, 自主网络优化, O-RAN, AI代理, 网络安全

**Comment:** 

> **TL;DR:** 本文提出了一个边缘AI框架，用于O-RAN中的自主网络优化，通过多工具架构、主动异常检测和安全对齐奖励机制，显著降低了网络中断，提高了性能和稳定性。

**AI_Comments:** 这篇论文通过提出一个创新的边缘AI框架，在解决O-RAN中AI代理部署的安全性和可靠性挑战方面迈出了重要一步。其核心创新在于结合了多工具架构、主动异常检测和安全对齐的奖励机制，这对于在复杂和动态的网络环境中实现自主优化至关重要。特别是其在极端条件下实现零网络中断的成果，证明了该框架在实际应用中的巨大潜力。这为未来5G及6G网络的智能化、自动化运营提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在现有无线接入网络 (RAN) 基础设施中部署AI代理对未来的6G网络构成了重大的安全和可靠性挑战。

**Method:** 本文提出了一个新颖的边缘AI框架，用于O-RAN环境中的自主网络优化，包含三项核心创新：1) 基于角色的多工具架构，实现分布式、上下文感知的决策；2) 由流量预测工具驱动的主动异常检测代理；3) 平衡性能与操作稳定性的安全对齐奖励机制。该框架集成到RAN智能控制器 (RIC) 中，利用多模态数据融合来预测和响应动态网络条件。

**Result:** 在真实5G场景下，该边缘框架在高压条件下实现了零网络中断，而传统固定功率网络的中断率为8.4%，基于大型语言模型（LLM）代理的方法为3.3%，同时保持了接近实时的响应能力和一致的服务质量（QoS）。

**Conclusion:** 当配备正确的工具和上下文感知能力时，AI代理可以安全有效地部署在关键网络基础设施中，为智能和自主的5G及未来网络运营奠定基础。

> **ai_Abstract:** 本文提出了一种创新的边缘AI框架，旨在解决在Open RAN环境中部署AI代理所面临的安全和可靠性挑战，以实现自主网络优化。该框架引入了基于角色的多工具架构、主动异常检测代理和安全对齐奖励机制。通过集成到RIC并利用多模态数据融合，该框架在5G场景下表现出色，实现了零网络中断，显著优于传统方法和LLM代理方法，同时保持了高响应速度和QoS。研究结果证实了AI代理在关键网络基础设施中安全有效部署的可行性。

> **摘要翻译:** 在现有无线接入网络 (RAN) 基础设施中部署AI代理对未来的6G网络构成了重大的安全和可靠性挑战。本文提出了一个新颖的边缘AI框架，用于Open RAN环境中的自主网络优化，通过三项核心创新解决了这些挑战：(1) 一个基于角色的多工具架构，实现分布式、上下文感知的决策；(2) 一个由流量预测工具驱动的主动异常检测代理；(3) 一个平衡性能与操作稳定性的安全对齐奖励机制。我们的框架集成到RAN智能控制器 (RIC) 中，利用包括网络KPI、流量预测模型和外部信息源在内的多模态数据融合，以预测和响应动态网络条件。使用真实的5G场景进行的广泛评估表明，在高压条件下，该边缘框架实现了零网络中断，而传统固定功率网络的中断率为8.4%，基于大型语言模型（LLM）代理的方法为3.3%，同时保持了接近实时的响应能力和一致的服务质量（QoS）。这些结果表明，当配备正确的工具和上下文感知能力时，AI代理可以安全有效地部署在关键网络基础设施中，为智能和自主的5G及未来网络运营奠定基础。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [318] [Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks](https://arxiv.org/abs/2507.23707)
> *蜂窝、无蜂窝及介于两者之间：无线网络效用区域分析的统一框架*

*Renato Luis Garrido Cavalcante, Tomasz Piotrowski, Slawomir Stanczak* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 效用区域, 凸性, 无线网络, 和速率最大化, 大规模MIMO

**Comment:** 

> **TL;DR:** 本文提出了一个统一框架来分析无线网络效用区域的凸性条件，并证明其对和速率最大化问题和大规模MIMO概念的意义。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一框架并推导了效用区域凸性的充分条件，这对于无线网络中的资源分配和优化问题具有深远的影响。它不仅简化了某些优化问题的求解，还为理解网络性能提供了新的理论工具，并对大规模MIMO中的核心概念提出了改进。

<details>
  <summary>Details</summary>

**Motivation:** 现有分析可能无法全面理解现代网络架构（如无蜂窝和超大MIMO）的干扰模式，并且需要更深入地理解效用区域的性质，特别是凸性，以便开发高效的优化算法。

**Method:** 引入了一个统一框架，重点分析信干噪比（SINR）和可实现速率区域，并推导出保证效用区域凸性的充分条件。

**Result:** 1. 框架为现代网络架构的干扰模式提供了有价值的见解，并推广了现有弱帕累托边界的特征。2. 导出了保证效用区域凸性的充分条件。3. 识别了一类本质上是凸的（加权）和速率最大化问题，无需变量变换。4. 为直接基于可实现速率而非SINR水平来公式化和速率最大化问题提供了严格的依据。5. 启发了大规模MIMO文献中“有利传播”概念的替代方案，该方案明确考虑了自干扰和波束成形策略。

**Conclusion:** 该研究通过推导效用区域凸性的充分条件，为无线网络，特别是现代架构中的和速率最大化问题提供了重要的理论基础和实际指导，并提出了对现有概念的改进。

> **ai_Abstract:** 本文提出了一个统一框架，用于分析无线网络的信干噪比和可实现速率效用区域。核心贡献在于推导了保证效用区域凸性的充分条件，这对于理解时间共享的限制至关重要。这些条件揭示了一类固有的凸和速率最大化问题，并为直接基于可实现速率进行问题建模提供了理论依据。此外，研究还为大规模MIMO中的有利传播概念提供了一个考虑自干扰和波束成形的新视角。

> **摘要翻译:** 我们引入了一个统一框架，用于分析无线网络的效用区域，重点关注信干噪比（SINR）和可实现速率区域。该框架为现代网络架构（如无蜂窝和超大MIMO网络）的干扰模式提供了宝贵的见解，并推广了弱帕累托边界的现有特征。一个核心贡献是推导出了保证效用区域凸性的充分条件。凸性是一个重要的特性，因为它确保了当网络在弱帕累托边界上运行时，时间共享（或用户分组）不能同时增加所有用户的效用。这些充分条件还具有两个关键含义。首先，它们识别了一类本质上是凸的（加权）和速率最大化问题，无需任何变量变换，从而为开发针对此类问题的有效、可证明最优的求解器铺平了道路。其次，它们为直接根据可实现速率而非SINR水平来公式化和速率最大化问题提供了严格的依据。我们的理论洞察还激发了大规模MIMO文献中“有利传播”概念的一种替代方案——该方案明确考虑了自干扰和波束成形策略。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [440] [Subband Architecture Aided Selective Fixed-Filter Active Noise Control](https://arxiv.org/abs/2508.00603)
> *子带架构辅助选择性固定滤波器主动噪声控制*

*Hong-Cheng Liang, Man-Wai Mak, Kong Aik Lee* | **Category: eess.SP, cs.SY, eess.AS, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 主动噪声控制, 子带架构, 选择性固定滤波器, 噪声抑制, 快速收敛

**Comment:** 

> **TL;DR:** 本文提出了一种基于无延迟子带结构的新型选择性固定滤波器方案，通过将噪声分解到不同子带并匹配预训练的子带滤波器，有效解决了传统选择性固定滤波器方法在处理复杂噪声时的局限性，实现了快速收敛和有效降噪。

**AI_Comments:** 该论文创新性地将子带架构引入选择性固定滤波器主动噪声控制中，通过频率分解和子带匹配解决了传统方法处理复杂噪声能力不足的问题。其提出的离线训练和在线组合策略，有效提升了系统的适应性和鲁棒性，对于实际噪声控制应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的前馈选择性固定滤波器方法虽然能避免自适应算法收敛慢的问题，但只能处理有限类型的噪声，并且在输入噪声功率谱密度不均匀时性能会下降。

**Method:** 本文提出了一种基于无延迟子带结构的新型选择性固定滤波器方案。离线训练阶段，为不同频率范围预训练子带控制滤波器并存储。在线控制阶段，使用多相FFT滤波器组分解输入噪声，并通过频率带匹配机制为每个子带信号分配最合适的控制滤波器，最后采用权重堆叠技术将所有子带权重组合成一个全带滤波器以实现实时噪声抑制。

**Result:** 实验结果表明，所提出的方案在处理更复杂的噪声环境时，提供了快速收敛、有效的噪声抑制和强大的鲁棒性。

**Conclusion:** 本文提出的基于子带架构的选择性固定滤波器主动噪声控制方案，有效克服了传统方法的局限性，在复杂噪声环境下表现出优越的性能。

> **ai_Abstract:** 本文针对传统选择性固定滤波器主动噪声控制方法在处理复杂和非均匀功率谱密度噪声时的局限性，提出了一种基于无延迟子带结构的新型方案。该方案在离线阶段预训练子带滤波器，在线阶段通过多相FFT滤波器组分解噪声并匹配合适的子带滤波器，最终通过权重堆叠实现全带噪声抑制。实验证明，该方法具有快速收敛、有效降噪和鲁棒性强的优点。

> **摘要翻译:** 前馈选择性固定滤波器方法根据检测到的参考信号的频谱特征选择最合适的预训练控制滤波器，有效避免了传统自适应算法收敛慢的问题。然而，它只能处理有限类型的噪声类型，并且当输入噪声呈现不均匀的功率谱密度时，性能会下降。为了解决这些局限性，本文设计了一种基于无延迟子带结构的新型选择性固定滤波器方案。在离线训练阶段，为不同的频率范围预训练子带控制滤波器并存储在专用的子滤波器数据库中。在在线控制阶段，使用多相FFT滤波器组分解输入的噪声，并通过频率带匹配机制为每个子带信号分配最合适的控制滤波器。随后，采用权重堆叠技术将所有子带权重组合成一个全带滤波器，实现实时噪声抑制。实验结果表明，所提出的方案在处理更复杂的噪声环境时，提供了快速收敛、有效的噪声抑制和强大的鲁棒性。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [459] [Rydberg Atomic Receiver: Next Frontier of Wireless Communications](https://arxiv.org/abs/2412.12485)
> *芮德堡原子接收机：无线通信的下一个前沿*

*Mingyao Cui, Qunsong Zeng, Kaibin Huang* | **Category: eess.SP, cs.NI, physics.app-ph** | **Updated: 2025-08-01**

**Keywords:** 芮德堡原子接收机, 无线通信, 量子通信, 电磁波测量, 多频带传感

**Comment:** Accepted by IEEE Communications Magazine

> **TL;DR:** 芮德堡原子接收机（RARE）利用量子效应有望突破传统无线通信接收机性能极限。本文综述了RARE的原理、与传统接收机的比较、最新进展及应用。

**AI_Comments:** 这篇论文探讨了芮德堡原子接收机（RARE）这一新兴技术在无线通信领域的巨大潜力。其创新之处在于利用量子尺度的原子特性来突破传统接收机的性能瓶颈，特别是在灵敏度、带宽和多频带感知方面。这预示着物理层无线通信可能迎来一场革命，具有重要的理论和实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统接收机性能存在限制，而芮德堡原子接收机（RARE）利用芮德堡原子的电子跃迁现象，在量子尺度上运行，有望突破经典接收机的性能极限，引发物理层无线通信的革命。

**Method:** 本文首先全面介绍了RARE的基本原理。然后，从天线尺寸、灵敏度和带宽方面对RARE与经典接收机进行了彻底比较。随后，概述了RARE辅助无线通信的最新进展，包括频分复用、多输入多输出、无线传感和量子多体技术。此外，介绍了RARE在多频带传感和通信中的独特应用。最后，总结并提供了有前景的研究方向。

**Result:** 论文介绍了RARE的基本原理，比较了其与经典接收机在天线尺寸、灵敏度和带宽上的优势，概述了RARE在频分复用、MIMO、无线传感和量子多体技术等方面的最新进展，并强调了其在多频带传感和通信中的独特应用。

**Conclusion:** 芮德堡原子接收机为无线通信带来了新的可能性，论文最后指出了其未来有前景的研究方向。

> **ai_Abstract:** 本文综述了芮德堡原子接收机（RARE）在无线通信领域的潜力，该技术利用芮德堡原子的电子跃迁现象，有望突破传统接收机的性能极限。文章详细阐述了RARE的基本原理，并与经典接收机在关键性能指标上进行了比较。此外，论文还回顾了RARE在频分复用、MIMO、无线传感及量子多体技术等方面的最新进展，并探讨了其在多频带传感与通信中的独特应用，最后指出了未来的研究方向。

> **摘要翻译:** 芮德堡原子接收机（RARE）通过利用芮德堡原子的电子跃迁现象，正在推动电磁波测量领域的范式转变。这种在量子尺度上运行的接收机有潜力突破经典接收机的性能极限，引发物理层无线通信的一场革命。本文的目的是深入探讨RARE赋能的通信。我们首先全面介绍了RARE的基本原理。然后，从天线尺寸、灵敏度和带宽方面对RARE与经典接收机进行了彻底比较。随后，我们概述了RARE辅助无线通信的最新进展，涵盖了频分复用、多输入多输出、无线传感和量子多体技术。此外，还介绍了RARE在多频带传感和通信中的独特应用。最后，我们通过提供有前景的研究方向来结束本文。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [511] [Cross-layer Integrated Sensing and Communication: A Joint Industrial and Academic Perspective](https://arxiv.org/abs/2505.10933)
> *跨层集成感知与通信：产学研联合视角*

*Henk Wymeersch, Nuutti Tervo, Stefan Wänstedt, Sharief Saleh, Joerg Ahlendorf, Ozgur Akgul, Vasileios Tsekenis, Sokratis Barmpounakis, Liping Bai, Martin Beale, Rafael Berkvens, Nabeel Nisar Bhat, Hui Chen, Shrayan Das, Claude Desset, Antonio de la Oliva, Prajnamaya Dass, Jeroen Famaey, Hamed Farhadi, Gerhard P. Fettweis, Yu Ge, Hao Guo, Rreze Halili, Katsuyuki Haneda, Abdur Rahman Mohamed Ismail, Akshay Jain, Sylvaine Kerboeuf, Musa Furkan Keskin, Emad Ibrahim, Bilal Khan, Siddhartha Kumar, Stefan Köpsell, Apostolos Kousaridas, Pekka Kyösti, Simon Lindberg, Mohammad Hossein Moghaddam, Ahmad Nimr, Victor Pettersson, Aarno Pärssinen, Basuki Priyanto, Athanasios Stavridis, Tommy Svensson, Sonika Ujjwal* | **Category: eess.SP, cs.IT, math.IT** | **Updated: 2025-07-31**

**Keywords:** 集成感知与通信, 6G, 跨层, 工业与学术, 无线电系统

**Comment:** 

> **TL;DR:** 本文提出了一个针对6G网络中集成感知与通信（ISAC）的全面跨层愿景，整合了学术界和工业界的见解。

**AI_Comments:** 本文的创新之处在于其全面的跨层视角和产学研联合的分析方法，为6G网络中ISAC的实现提供了系统性的指导。它不仅探讨了技术细节，还考虑了实际实施中的硬件和系统评估，这对于推动ISAC在未来通信系统中的应用至关重要。其重要性在于为6G的关键技术发展提供了清晰的路线图。

<details>
  <summary>Details</summary>

**Motivation:** 集成感知与通信（ISAC）使无线电系统能够同时感知和与其环境通信。本文旨在为6G网络中的ISAC提供一个全面的跨层愿景，整合物理层设计、硬件架构、AI驱动智能和协议层创新的见解。

**Method:** 本文首先回顾了ISAC的基本原理，强调了感知和通信在不同集成级别上的协同作用和权衡。分析了包括多频带操作、大规模分布式MIMO、非地面网络、可重构智能表面和机器学习等使能技术，并结合了波形设计、同步和全双工操作等硬件考虑。为了弥合实现和系统级评估之间的差距，引入了一个将设计参数与关键性能和价值指标相关联的定量跨层框架。

**Result:** 本文概述了深度集成的ISAC如何将6G转变为一个可编程和上下文感知的平台，支持从可靠无线接入到自主移动和数字孪生等应用。

**Conclusion:** 深度集成的ISAC有望将6G网络转变为一个可编程和上下文感知的平台，支持广泛的应用，这需要融合学术界和工业界的视角进行全面的跨层设计。

> **ai_Abstract:** 本文在欧盟Hexa-X-II项目背景下，为6G网络中的集成感知与通信（ISAC）提出了一个全面的跨层愿景。文章回顾了ISAC原理，分析了多项使能技术和硬件考量，并引入了一个定量跨层框架，旨在将ISAC深度集成，从而将6G转变为一个可编程和上下文感知的平台，支持多样化应用。

> **摘要翻译:** 集成感知与通信（ISAC）使无线电系统能够同时感知和与其环境通信。本文在欧盟资助的Hexa-X-II项目内开发，提出了一个针对6G网络中ISAC的全面跨层愿景，整合了物理层设计、硬件架构、AI驱动智能和协议层创新的见解。我们首先回顾了ISAC的基本原理，强调了感知和通信在不同集成级别上的协同作用和权衡。使能技术（如多频带操作、大规模分布式MIMO、非地面网络、可重构智能表面和机器学习）与硬件考量（包括波形设计、同步和全双工操作）一起进行了分析。为了弥合实现和系统级评估之间的差距，我们引入了一个将设计参数与关键性能和价值指标相关联的定量跨层框架。通过综合学术界和工业界的视角，本文概述了深度集成的ISAC如何将6G转变为一个可编程和上下文感知的平台，支持从可靠无线接入到自主移动和数字孪生等应用。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [653] [Closed-form Expression for the Power Profile in Wideband Systems with Inter-channel Stimulated Raman Scattering](https://arxiv.org/abs/2508.00093)
> *宽带系统中信道间受激拉曼散射下功率分布的闭式表达式*

*Lucas Alves Zischler, Chiara Lasagni, Paolo Serena, Alberto Bononi, Giammarco Di Sciullo, Divya A. Shaji, Antonio Mecozzi, Cristian Antonelli* | **Category: eess.SP** | **Updated: 2025-07-31**

**Keywords:** 宽带系统, 受激拉曼散射, 功率分布, 闭式表达式, 光信噪比

**Comment:** Submitted for the Journal of Lightwave Technology

> **TL;DR:** 提出了一个用于宽带系统功率分布的近似闭式表达式，考虑了信道间受激拉曼散射和光纤损耗，并可用于预加重。

**AI_Comments:** 这项工作提供了一个有价值的解析工具，解决了宽带系统中ISRS和损耗建模的复杂性，传统上需要数值方法。闭式表达式的提出简化了系统设计和优化过程，特别是通过预加重实现目标OSNR分布的能力，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 宽带系统存在显著的信道间受激拉曼散射（ISRS）和信道相关损耗，导致非均匀衰减，这些效应的组合只能通过数值方法准确估计，缺乏解析表达式。

**Method:** 提出了一个近似的闭式表达式，用于描述考虑了ISRS和光纤损耗的信道功率分布。此外，还推导了一个逆表达式，可用于通过预加重输入信道功率来达到目标OSNR分布。

**Result:** 提出的表达式在CLU传输情况下与数值解相比具有高精度，适用于单跨和多跨光纤链路。逆表达式可用于预加重以实现期望的OSNR分布。

**Conclusion:** 论文成功推导并验证了一个高精度的闭式表达式，用于估计宽带系统中考虑ISRS和光纤损耗的功率分布，并提供了实现OSNR预加重的方法。

> **ai_Abstract:** 本文针对宽带系统中信道间受激拉曼散射（ISRS）和信道相关损耗的复杂影响，提出了一个近似的闭式表达式来描述信道功率分布。该表达式在单跨和多跨光纤链路中与数值解相比展现出高精度。研究还推导了一个逆表达式，可用于通过预加重技术实现目标光信噪比（OSNR）分布，为宽带系统设计提供了新的工具。

> **摘要翻译:** 宽带系统会经历显著的信道间受激拉曼散射（ISRS）和信道相关损耗。由于非均匀衰减分布，ISRS和光纤损耗的综合影响只能通过数值方法准确估计。在这项工作中，我们提出了一个近似的闭式表达式，用于描述考虑这些综合影响的信道功率分布。我们针对CLU传输情况，将所提出的表达式与数值解进行了验证，结果表明其在单跨和多跨光纤链路上均具有高精度。此外，我们还推导了一个逆表达式，其被表述为输出功率的函数，可用于通过预加重启动信道功率来达到期望的光信噪比（OSNR）分布。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [702] [RIS-MAE: A Self-Supervised Modulation Classification Method Based on Raw IQ Signals and Masked Autoencoder](https://arxiv.org/abs/2508.00274)
> *RIS-MAE：一种基于原始IQ信号和掩码自编码器的自监督调制分类方法*

*Yunfei Liu, Mingxuan Liu, Wupeng Xie, Xinzhu Liu, Wenxue Liu, Yangang Sun, Xin Qiu, Cui Yuan, Jinhai Li* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 自动调制分类, 自监督学习, 原始IQ信号, 掩码自编码器, 少样本学习

**Comment:** 

> **TL;DR:** 提出RIS-MAE，一种基于原始IQ信号和掩码自编码器的自监督调制分类方法，解决了传统AMC方法依赖时频图像和大量标注数据的问题，在少样本和跨域任务中表现优异。

**AI_Comments:** 该论文的创新点在于将掩码自编码器引入到基于原始IQ信号的自动调制分类中，通过自监督学习有效解决了传统方法对标注数据的依赖和时频转换带来的信息损失问题。这对于实际无线通信场景中数据获取困难的问题具有重要意义。其在少样本和跨域任务中的优异表现，也凸显了其方法的实用性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 自动调制分类（AMC）是智能无线通信系统的基础技术，但当前主流方法存在两个关键问题：1. 使用时频图像而非原始信号，导致关键调制特征丢失，降低对不同通信条件的适应性。2. 依赖监督学习，需要大量难以获取的标注数据。

**Method:** 提出RIS-MAE自监督学习框架。该框架使用掩码自编码器从无标注数据中学习信号特征，以原始IQ序列作为输入，通过随机掩码和重建捕获重要的时域特征（如幅度、相位等），从而学习有用且可迁移的表示。

**Result:** RIS-MAE在四个数据集上进行测试，结果表明其在少样本和跨域任务中优于现有方法。仅需少量微调样本即可在未见过的数据集上实现高分类精度，证实了其泛化能力和实际部署潜力。

**Conclusion:** RIS-MAE通过自监督学习和原始IQ信号处理，有效解决了传统AMC方法对标注数据的依赖和特征丢失问题，展现出优越的泛化能力和实际应用前景。

> **ai_Abstract:** 本文提出RIS-MAE，一种基于原始IQ信号和掩码自编码器的自监督调制分类方法，旨在解决传统深度学习AMC方法依赖时频图像导致特征丢失以及需要大量标注数据的问题。RIS-MAE通过对原始IQ序列进行随机掩码和重建，从无标注数据中学习可迁移的信号特征。实验结果表明，RIS-MAE在少样本和跨域任务中表现优异，并在少量微调样本下对新数据集展现出高分类精度和强大的泛化能力，证明了其在实际应用中的潜力。

> **摘要翻译:** 自动调制分类（AMC）是智能无线通信系统中的一项基础技术。它对于频谱监测、认知无线电和安全通信等任务至关重要。近年来，深度学习方法在AMC领域取得了巨大进展。然而，主流方法仍然面临两个关键问题。首先，它们通常使用时频图像而不是原始信号。这会导致关键调制特征的丢失，并降低对不同通信条件的适应性。其次，大多数方法依赖于监督学习。这需要大量的标记数据，而这些数据在现实环境中很难获取。为了解决这些问题，我们提出了一种名为RIS-MAE的自监督学习框架。RIS-MAE使用掩码自编码器从无标记数据中学习信号特征。它以原始IQ序列作为输入。通过应用随机掩码和重建，它捕获重要的时域特征，如幅度、相位等。这有助于模型学习有用和可迁移的表示。RIS-MAE在四个数据集上进行了测试。结果表明，它在少样本和跨域任务中优于现有方法。值得注意的是，它仅需少量微调样本即可在以前未见过的数据集上实现高分类精度，证实了其泛化能力和实际部署潜力。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [749] [Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs](https://arxiv.org/abs/2410.16593)
> *同质图上可扩展和富有表现力的图神经网络的图采样*

*Haolin Li, Haoyu Wang, Luana Ruiz* | **Category: eess.SP, cs.AI, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 图采样, 图神经网络, 同质图, 可扩展性, 特征同质性

**Comment:** 

> **TL;DR:** 提出一种基于特征同质性的新型图采样算法，以解决大型图上GNN的可扩展性和表达性问题，优于随机采样并降低了复杂度。

**AI_Comments:** 这项研究通过引入基于特征同质性的图采样方法，有效解决了大型图上GNN训练中存在的关键问题，即如何平衡可扩展性和模型表达能力。其创新点在于通过最小化数据相关矩阵的迹来间接优化图连通性，提供了一种比随机采样更优且比谱方法更高效的替代方案。这对于实际应用中处理大规模图数据具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图神经网络（GNN）在处理大型网络时面临可扩展性挑战。尽管GNN的可迁移性允许在较小图上训练模型并应用于较大图，但现有方法常依赖随机子采样，这会导致子图断开连接并降低模型表达能力。

**Method:** 提出了一种新颖的图采样算法，该算法利用特征同质性来保留图结构。通过最小化数据相关矩阵的迹，该方法比随机采样更好地保留了图拉普拉斯矩阵的迹（作为图连通性的代理），同时实现了比谱方法更低的计算复杂性。

**Result:** 在引文网络上的实验表明，与随机采样相比，该方法在保留拉普拉斯矩阵迹和GNN可迁移性方面表现出更高的性能。

**Conclusion:** 该论文提出了一种有效的图采样算法，通过利用特征同质性解决了大型图上GNN的可扩展性和表达性问题，并通过实验验证了其在保留图结构和GNN可迁移性方面的优越性。

> **ai_Abstract:** 该论文提出了一种新颖的图采样算法，旨在解决图神经网络（GNN）在大型图上的可扩展性和表达性问题。该算法利用特征同质性来更好地保留图结构，通过最小化数据相关矩阵的迹来维护图连通性（以拉普拉斯矩阵的迹为代理），并相比现有方法具有更低的复杂性。实验证明，该方法在保留图结构和提升GNN可迁移性方面优于随机采样。

> **摘要翻译:** 图神经网络（GNN）在许多图机器学习任务中表现出色，但在扩展到大型网络时面临挑战。GNN可迁移性允许在较小图上训练并在较大图上应用模型，但现有方法通常依赖随机子采样，导致子图断开连接并降低模型表达能力。我们提出了一种新颖的图采样算法，该算法利用特征同质性来保留图结构。通过最小化数据相关矩阵的迹，我们的方法比随机采样更好地保留了图拉普拉斯矩阵的迹——图连通性的代理——同时实现了比谱方法更低的复杂性。在引文网络上的实验表明，与随机采样相比，该方法在保留拉普拉斯矩阵迹和GNN可迁移性方面表现出更高的性能。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [751] [Model-Driven Deep Learning Enhanced Joint Beamforming and Mode Switching for RDARS-Aided MIMO Systems](https://arxiv.org/abs/2508.00326)
> *模型驱动深度学习增强的RDARS辅助MIMO系统联合波束成形与模式切换*

*Chengwang Ji, Kehui Li, Haiquan Lu, Qiaoyan Peng, Jintao Wang, Shaodan Ma* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** RDARS, MIMO, 波束成形, 模式切换, 模型驱动深度学习

**Comment:** 

> **TL;DR:** 本文提出一种模型驱动的深度学习方法（PWM-BFNet），用于优化RDARS辅助MIMO系统中的联合波束成形和模式切换，显著提升了系统性能并加速了收敛。

**AI_Comments:** 该论文的创新之处在于将传统的优化技术（MM、WMMSE）与模型驱动的深度学习相结合，以解决6G无线系统中复杂的非凸混合整数约束问题。这种混合方法有效利用了两个领域的优势，提高了收敛速度和系统性能。应用于RDARS这一关键的6G技术，突显了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 可重构分布式天线和反射面（RDARS）是未来6G无线网络的一种有前景的架构，能带来额外的选择增益。然而，在RDARS辅助的MIMO系统中，通过联合优化基站和RDARS的波束成形矩阵以及RDARS的模式切换矩阵来最大化加权和速率（WSR）是一个具有非凸目标函数和混合整数二元约束的难题。

**Method:** 本文提出了一种基于惩罚项的加权最小均方误差（PWM）算法，该算法集成了大化-最小化（MM）和加权最小均方误差（WMMSE）方法。为了进一步跳出PWM算法中的局部最优解，将模型驱动的深度学习（DL）方法集成到该算法中，通过训练与PWM算法收敛相关的关键变量，以加速收敛速度并提高系统性能。

**Result:** 仿真结果表明，基于PWM的波束成形网络（PWM-BFNet）可以将迭代次数减少一半。在高总发射功率场景下，性能提升26.53%；在大量RDARS发射单元（TEs）场景下，性能提升103.2%。

**Conclusion:** 本文提出的模型驱动深度学习增强的PWM-BFNet算法能有效优化RDARS辅助MIMO系统，显著提升系统性能并加速收敛。

> **ai_Abstract:** 本文针对RDARS辅助的下行链路MIMO系统中联合波束成形和模式切换以最大化加权和速率的挑战性问题，提出了一种模型驱动的深度学习增强型惩罚项加权最小均方误差（PWM）算法，命名为PWM-BFNet。该算法融合了大化-最小化（MM）和加权最小均方误差（WMMSE）方法，并通过深度学习训练关键变量来加速收敛并提升性能。仿真结果表明，PWM-BFNet显著减少了迭代次数，并在不同条件下实现了显著的性能增益。

> **摘要翻译:** 可重构分布式天线和反射面（RDARS）是未来第六代（6G）无线网络的一种有前景的架构。特别是，RDARS辅助系统的动态工作模式配置与现有可重构智能表面（RIS）辅助系统和分布式天线系统（DAS）相比，带来了额外的选择增益。在本文中，我们考虑RDARS辅助的下行链路多输入多输出（MIMO）系统，旨在通过联合优化基站（BS）和RDARS的波束成形矩阵以及RDARS的模式切换矩阵来最大化加权和速率（WSR）。由于非凸目标函数和混合整数二元约束，该优化问题难以解决。为此，本文提出了一种基于惩罚项的加权最小均方误差（PWM）算法，该算法集成了大化-最小化（MM）和加权最小均方误差（WMMSE）方法。为了进一步跳出PWM算法中的局部最优解，我们将一种模型驱动的深度学习（DL）方法集成到该算法中，通过训练与PWM算法收敛相关的关键变量，以加速收敛速度并提高系统性能。仿真结果表明，基于PWM的波束成形网络（PWM-BFNet）可以将迭代次数减少一半，并在高总发射功率和大量RDARS发射单元（TEs）的场景下，分别实现26.53%和103.2%的性能提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [793] [STAR-RIS-aided RSMA for the URLLC multi-user MIMO Downlink](https://arxiv.org/abs/2508.00409)
> *STAR-RIS辅助的URLLC多用户MIMO下行链路中的RSMA*

*Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Robert Schober, Lajos Hanzo* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** STAR-RIS, RSMA, URLLC, MIMO, 能量效率

**Comment:** Accepted at 28th International Workshop on Smart Antennas 2025

> **TL;DR:** 本文将速率分裂多址(RSMA)与同时传输和反射(STAR)可重构智能表面(RIS)结合，以提高有限块长(FBL)多输入多输出(MIMO)下行链路的能量效率(EE)。提出了一种基于交替优化的算法来联合优化传输波束成形矩阵、STAR-RIS配置和速率分裂参数。数值结果表明，RSMA和STAR-RIS之间存在强大的协同作用，与反射式RIS和空分多址(SDMA)相比，实现了显著的EE增益。

**AI_Comments:** 本文的创新点在于将STAR-RIS与RSMA相结合，并通过联合优化提升了URLLC多用户MIMO下行链路的能量效率。这种结合利用了STAR-RIS的全平面覆盖能力和RSMA的干扰管理优势，为未来无线通信系统的高效设计提供了新的思路和显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高有限块长(FBL)多输入多输出(MIMO)下行链路的能量效率(EE)。

**Method:** 提出了一种基于交替优化的算法，用于联合优化传输波束成形矩阵、STAR-RIS配置和速率分裂参数。

**Result:** STAR-RIS实现了360度全平面覆盖，而RSMA通过有效管理干扰提供了显著增益。数值结果表明RSMA和STAR-RIS之间存在强大的协同作用，与反射式RIS和空分多址(SDMA)相比，实现了显著的EE增益。

**Conclusion:** RSMA与STAR-RIS的结合能够显著提高URLLC多用户MIMO下行链路的能量效率，显示出强大的协同作用。

> **ai_Abstract:** 本文研究了将速率分裂多址(RSMA)与同时传输和反射(STAR)可重构智能表面(RIS)相结合，以提高有限块长(FBL)多输入多输出(MIMO)下行链路的能量效率。通过提出一种基于交替优化的算法来联合优化传输波束成形、STAR-RIS配置和速率分裂参数，实现了STAR-RIS的360度覆盖和RSMA的干扰管理优势。数值结果验证了RSMA和STAR-RIS之间的强大协同作用，并展示了相对于传统反射式RIS和空分多址的显著能量效率增益。

> **摘要翻译:** 速率分裂多址(RSMA)与同时传输和反射(STAR)可重构智能表面(RIS)本质上相结合，以提高有限块长(FBL)多输入多输出(MIMO)下行链路的能量效率(EE)。本文提出了一种基于交替优化的算法，用于联合优化传输波束成形矩阵、STAR-RIS配置和速率分裂参数。STAR-RIS实现了360度全平面覆盖，而RSMA通过有效管理干扰提供了显著增益。数值结果表明，RSMA和STAR-RIS之间存在强大的协同作用，与反射式RIS和空分多址(SDMA)相比，实现了显著的EE增益。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [835] [When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework](https://arxiv.org/abs/2508.00456)
> *当视觉-语言模型（VLM）遇见波束预测：一种多模态对比学习框架*

*Ji Wang, Bin Tang, Jian Xiao, Qimei Cui, Xingwang Li, Tony Q. S. Quek* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 波束预测, 视觉-语言模型, 多模态学习, 对比学习, 毫米波

**Comment:** 

> **TL;DR:** 本文提出了一种基于VLM驱动的对比学习多模态波束预测框架，通过整合多模态数据和跨模态一致性，显著提升了毫米波波束预测的准确性。

**AI_Comments:** 本文的创新点在于首次将视觉-语言模型（VLM）引入到毫米波波束预测领域，并提出了一个新颖的多模态对比学习框架。通过整合图像、LiDAR和文本（位置信息）等多种模态数据，并利用VLM强大的跨模态表示能力和对比学习进行特征对齐，有效解决了传统方法在复杂环境中精度不足的问题。该研究为未来无线通信中的波束管理提供了新的思路和技术支持，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 毫米波波束预测在复杂动态的真实传播环境中面临巨大挑战，传统依赖实时信道状态信息（CSI）的方法计算成本高昂且难以保持精度。视觉-语言模型（VLM）强大的跨模态表示能力为解决这一问题提供了有前景的途径。

**Method:** 本文提出了一种VLM驱动的、基于对比学习的多模态波束预测框架。该框架通过模态特定编码器整合多模态数据。为增强跨模态一致性，采用了对比预训练策略来对齐潜在空间中的图像和LiDAR特征。此外，利用位置信息作为文本提示并连接到文本编码器，引入语言模态以进一步提高跨模态一致性。

**Result:** 在DeepSense-6G数据集上的实验表明，VLM骨干网络提供了额外的语义基础。与现有方法相比，整体基于距离的准确性分数（DBA-Score）达到0.9016，平均提升了1.46%。

**Conclusion:** 本文提出的VLM驱动的多模态对比学习框架能够有效提升毫米波波束预测的准确性，通过整合多模态数据和利用VLM的跨模态表示能力，克服了传统方法的局限性。

> **ai_Abstract:** 本文针对毫米波波束预测在复杂环境中的挑战，提出了一种VLM驱动的多模态对比学习框架。该框架通过模态特定编码器整合图像、LiDAR和位置文本信息，并利用对比预训练策略实现跨模态特征对齐。实验结果显示，该方法在DeepSense-6G数据集上显著提升了波束预测的准确性，证明了VLM在结合多模态数据进行波束预测方面的潜力。

> **摘要翻译:** 随着真实传播环境日益复杂和动态，毫米波波束预测面临巨大挑战。然而，视觉-语言模型（VLM）强大的跨模态表示能力提供了一种有前景的方法。传统依赖实时信道状态信息（CSI）的方法计算成本高昂，并且在这种环境中往往难以保持准确性。在本文中，我们提出了一种VLM驱动的、基于对比学习的多模态波束预测框架，该框架通过模态特定编码器整合多模态数据。为了强制实现跨模态一致性，我们采用对比预训练策略来对齐潜在空间中的图像和LiDAR特征。我们使用位置信息作为文本提示，并将其连接到文本编码器以引入语言模态，这进一步改善了跨模态一致性。在DeepSense-6G数据集上的实验表明，我们的VLM骨干网络提供了额外的语义基础。与现有方法相比，整体基于距离的准确性分数（DBA-Score）达到0.9016，对应着平均1.46%的提升。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [870] [Feasibility of Extracting Skin Nerve Activity from Electrocardiogram Recorded at A Low Sampling Frequency](https://arxiv.org/abs/2508.00494)
> *从低采样频率心电图中提取皮肤神经活动的可行性*

*Youngsun Kong, Farnoush Baghestani, I-Ping Chen, Ki Chon* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 皮肤神经活动, 心电图, 低采样频率, 交感神经系统, 可穿戴设备

**Comment:** Accepted and presented at the 47th Annual International Conference of
  the IEEE Engineering in Medicine and Biology Society (EMBC 2025)

> **TL;DR:** 本研究表明，即使心电图采样频率较低（0.5-1 kHz），也可以可靠地提取皮肤神经活动（SKNA），这使得传统或可穿戴心电设备能够用于交感神经系统评估。

**AI_Comments:** 这项研究具有重要的实际意义，因为它挑战了SKNA提取对高采样频率的传统要求。通过证明在较低采样频率下SKNA提取的可行性，它为更广泛地使用现有低采样率ECG设备（包括可穿戴设备）进行交感神经系统评估打开了大门，降低了成本和技术门槛。其创新之处在于重新评估了SKNA提取的频率需求，并提供了实验证据支持其假设。

<details>
  <summary>Details</summary>

**Motivation:** 皮肤神经活动（SKNA）是评估交感神经系统（SNS）的有前景的非侵入性替代方法。然而，SKNA提取通常需要高于2 kHz的采样频率，而常见的心电图（ECG）记录系统（特别是可穿戴设备）的采样频率为1 kHz或更低。鉴于最近的研究表明在交感神经刺激期间150-500 Hz频段占主导地位，研究人员假设可以从低采样频率的心电图中提取SKNA。

**Method:** 研究人员在SNS刺激期间从16名参与者中收集了心电图信号，并将信号重新采样为0.5 kHz、1 kHz和4 kHz。对来自不同采样频率的心电图信号衍生的SKNA指标进行了显著性、分类性能和可靠性的统计分析。

**Result:** 统计分析表明，从0.5 kHz、1 kHz和4 kHz采样的心电图信号中提取的SKNA指标之间没有显著差异。

**Conclusion:** 研究结果表明，如果肌肉伪影污染最小，受资源限制或过时指南限制于低采样率的常规心电图设备可以可靠地用于收集SKNA。

> **ai_Abstract:** 本研究旨在探讨从低采样频率心电图（ECG）中提取皮肤神经活动（SKNA）的可行性，因为SKNA通常需要高采样频率而常规ECG设备采样率较低。通过对16名参与者在交感神经系统刺激期间的心电图数据进行0.5、1和4 kHz的重采样和统计分析，结果显示不同采样频率下提取的SKNA指标没有显著差异。这表明即使是低采样率的传统或可穿戴心电图设备，在肌肉伪影最小的情况下，也能可靠地用于SKNA的采集和交感神经系统评估。

> **摘要翻译:** 皮肤神经活动（SKNA）源自心电图（ECG）信号，已成为准确有效评估交感神经系统（SNS）的有前景的非侵入性替代方法。通常，SKNA提取需要比典型心电图记录要求更高的采样频率（> 2 kHz），因为分析工具从0.5-1 kHz频段提取SKNA。然而，心电图记录系统通常提供1 kHz或更低的采样频率，特别是对于可穿戴设备。我们最近的功率谱分析表明，在交感神经刺激期间150-500 Hz频段占主导地位。因此，我们假设可以从低采样频率采样的心电图中提取SKNA。我们收集了16名参与者在SNS刺激期间的心电图信号，并将信号重新采样为0.5、1和4 kHz。我们对显著性、分类性能和可靠性的统计分析表明，从0.5、1和4 kHz采样的心电图信号中提取的SKNA指标之间没有显著差异。我们的发现表明，由于资源限制或过时指南而限制于低采样率的常规心电图设备，如果肌肉伪影污染最小，可以可靠地用于收集SKNA。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [907] [Multibeam High Throughput Satellite: Hardware Foundation, Resource Allocation, and Precoding](https://arxiv.org/abs/2508.00800)
> *多波束高通量卫星：硬件基础、资源分配与预编码*

*Rui Chen, Wen-Xuan Long, Bing-Qian Wang, Yuan He, Rui-Jin Sun, Nan Cheng, Gan Zheng, Dusit Niyato* | **Category: eess.SP** | **Updated: 2025-08-01**

**Keywords:** 高通量卫星, 多波束, 资源分配, 预编码, 6G通信

**Comment:** 38 pages, 18 figures

> **TL;DR:** 这篇综述论文回顾了多波束高通量卫星（HTS）系统的现状，涵盖了硬件基础、资源分配方法和预编码技术，并讨论了相关挑战和未来研究方向，旨在提升HTS系统性能以服务地面网络未覆盖区域。

**AI_Comments:** 本文作为一篇综述，系统地梳理了多波束高通量卫星系统的关键技术和挑战。其价值在于为研究人员和工程师提供了一个全面的概览，特别是在硬件基础、资源分配和预编码这三个核心领域。通过识别当前挑战，如Q/V波段链路问题和载荷轻量化，论文为未来的研究指明了方向，对于推动HTS技术发展以满足6G通信需求具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着6G通信对高容量卫星通信的需求增长，高通量卫星（HTS）系统变得至关重要。因此，有必要回顾多波束HTS系统的最新进展，并识别其面临的挑战和前景。

**Method:** 本文通过以下方式进行综述：首先，总结多波束HTS的硬件基础，包括地面站系统、星载有效载荷和用户终端。其次，回顾HTS系统灵活的星载无线资源分配方法，包括带宽、功率、时隙和联合分配方案。此外，调查了多波束预编码方法，并根据部署方式进行分类。最后，讨论了相关挑战。

**Result:** 本文总结了多波束HTS的硬件基础，回顾了多种资源分配方法以优化资源利用和满足非均匀服务需求，并调查了实现全频率复用和干扰消除的多种预编码方法。同时，讨论了Q/V波段链路中断、网关时间频率同步、信道状态信息精度、载荷轻量化发展以及深度学习应用等挑战。

**Conclusion:** 对所讨论主题的研究将有助于提升高通量卫星系统的性能，最终为地面网络服务不足的区域提供高速数据。

> **ai_Abstract:** 这篇综述论文全面审视了多波束高通量卫星（HTS）系统，这是6G通信的关键组成部分。文章首先概述了HTS的硬件基础，包括地面站、星载载荷和用户终端。接着，详细探讨了各种星载无线资源分配策略，旨在优化资源利用并满足多样化的服务需求。此外，论文还分类并分析了多波束预编码技术，这些技术对于实现全频率复用和有效干扰消除至关重要。最后，文章指出了当前HTS系统面临的关键挑战，包括Q/V波段链路、同步、CSI精度、载荷轻量化和深度学习应用，并强调了这些研究方向对于提升HTS性能和扩展服务覆盖的重要性。

> **摘要翻译:** 凭借其广泛的覆盖范围和不间断的服务，卫星通信是下一代6G通信的关键技术。高通量卫星（HTS）系统利用多点波束和频率复用技术，可实现高达Tbps的卫星通信容量，以满足不断增长的流量需求。因此，有必要回顾多波束HTS系统的最新进展，并识别其面临的挑战和前景。首先，我们总结了多波束HTS的硬件基础，包括地面站系统、星载有效载荷和用户终端。随后，我们回顾了HTS系统灵活的星载无线资源分配方法，包括带宽、功率、时隙和联合分配方案，以优化资源利用并满足非均匀服务需求。此外，我们调查了用于HTS系统的多波束预编码方法，以实现全频率复用和干扰消除，这些方法根据不同的部署方式进行分类，例如单网关预编码、多网关预编码、星载预编码以及星载/地面混合预编码。最后，我们讨论了与Q/V波段链路中断、网关的时间和频率同步、信道状态信息（CSI）的准确性、载荷轻量化发展以及深度学习（DL）应用相关的挑战。对这些主题的研究将有助于提升HTS系统的性能，并最终为地面网络服务不足的区域提供高速数据。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [910] [DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver](https://arxiv.org/abs/2507.22906)
> *基于DNN的绿色大规模H2AD MIMO接收机联合感知目标数量和方向的方法*

*Bin Deng, Jiatong Bai, Feilong Zhao, Zuming Xie, Maolin Li, Yan Wang, Feng Shu* | **Category: eess.SP, cs.AI, cs.IT, cs.LG, math.IT** | **Updated: 2025-07-15**

**Keywords:** H2AD MIMO, 目标感知, DNN, DOA估计, 绿色通信

**Comment:** 

> **TL;DR:** 该论文提出了一种基于DNN的两阶段传感框架，用于在绿色大规模H2AD MIMO接收机中联合估计多目标的数量和方向，旨在解决传统MIMO的高能耗、高成本和高复杂性问题。

**AI_Comments:** 该论文的创新点在于提出了一个针对H2AD MIMO的两阶段联合感知框架，并结合了多种机器学习方法来解决目标数量和方向估计的难题。特别是在低信噪比条件下，改进的1D-CNN表现出优越性，这对于实际应用具有重要意义。同时，引入CRLB作为理论基准也增加了研究的严谨性。该研究对于推动绿色MIMO技术在未来无线网络中的应用具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 未来的无线网络中，大规模或超大规模全数字MIMO面临高能耗、高电路成本和高复杂性三大挑战。H2AD MIMO架构作为一种绿色MIMO结构，具有替代前者的巨大潜力。然而，如何通过H2AD结构智能感知多发射器的数量和方向仍然是一个开放的难题。

**Method:** 本文提出了一种两阶段传感框架，用于联合估计多目标数量和方向。具体而言，设计了三种目标数量感知方法：改进的特征域聚类(EDC)框架、基于五个关键统计特征的增强型深度神经网络(DNN)以及利用完整特征值的改进一维卷积神经网络(1D-CNN)。随后，通过引入在线微聚类(OMC-DOA)方法实现了低复杂度和高精度的DOA估计。此外，还推导了多源条件下H2AD的Cramér-Rao下界(CRLB)作为理论性能基准。

**Result:** 仿真结果表明，开发的三种方法在中高信噪比下实现了100%的目标数量感知，而改进的1D-CNN在极低信噪比条件下表现出卓越的性能。引入的OMC-DOA在多源环境中优于现有的聚类和基于融合的DOA方法。

**Conclusion:** 本文提出的基于DNN的两阶段传感框架，能够有效且准确地在绿色大规模H2AD MIMO接收机中联合感知目标的数量和方向，解决了现有技术的挑战，并在不同信噪比条件下表现出优越的性能。

> **ai_Abstract:** 该论文提出了一种基于深度神经网络（DNN）的两阶段传感框架，用于在绿色大规模异构混合模拟-数字（H2AD）MIMO接收机中联合估计多目标的数量和方向。针对H2AD MIMO在解决传统全数字MIMO高能耗、高成本和高复杂性问题的背景下，如何智能感知目标数量和方向的挑战，作者设计了三种目标数量感知方法（改进EDC、增强DNN和改进1D-CNN）以及一种低复杂度高精度的DOA估计方法（OMC-DOA）。仿真结果验证了所提方法在不同信噪比下均能高效准确地完成目标数量和方向的感知。

> **摘要翻译:** 作为一种绿色MIMO结构，异构混合模拟-数字H2AD MIMO架构已被证明在未来无线网络中具有巨大潜力，可以替代大规模或超大规模全数字MIMO，以解决后者面临的三个挑战性问题：高能耗、高电路成本和高复杂性。然而，如何通过这种结构智能感知多发射器的数量和方向仍然是一个开放的难题。为了解决这个问题，我们提出了一种两阶段传感框架，用于联合估计多个目标的数量和方向。具体而言，设计了三种目标数量感知方法：改进的特征域聚类（EDC）框架、基于五个关键统计特征的增强型深度神经网络（DNN）以及利用完整特征值的改进一维卷积神经网络（1D-CNN）。随后，通过引入在线微聚类（OMC-DOA）方法实现了低复杂度和高精度的DOA估计。此外，我们推导了多源条件下H2AD的Cramér-Rao下界（CRLB）作为理论性能基准。仿真结果表明，开发的三种方法在中高信噪比下实现了100%的目标数量感知，而改进的1D-CNN在极低信噪比条件下表现出卓越的性能。引入的OMC-DOA在多源环境中优于现有的聚类和基于融合的DOA方法。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [138] [Data-Driven Motion Planning for Uncertain Nonlinear Systems](https://arxiv.org/abs/2508.00154)
> *不确定非线性系统的数据驱动运动规划*

*Babak Esmaeili, Hamidreza Modares, Stefano Di Cairano* | **Category: eess.SY, cs.LG, cs.RO, cs.SY, math.OC** | **Updated: 2025-07-31**

**Keywords:** 数据驱动, 运动规划, 不变集, 非线性系统, 线性矩阵不等式

**Comment:** 

> **TL;DR:** 本文提出了一种数据驱动的运动规划框架，用于非线性系统，通过构建一系列重叠的不变多面体，并利用数据驱动的线性矩阵不等式问题来学习不变集和局部状态反馈增益，从而实现安全、动态可行的路径。

**AI_Comments:** 该论文的创新之处在于其完全数据驱动的运动规划方法，摆脱了对精确系统动力学模型的依赖，这对于难以建模的复杂非线性系统具有重要意义。通过结合不变集理论、数据驱动LMI和实时增益插值，该方法提供了一种鲁棒且安全的路径规划方案。其局限性可能在于数据质量和数量对性能的影响，以及在高度不确定环境中的实时计算效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统运动规划方法依赖于系统动力学模型，而本文提出的方法仅需要数据即可计算安全区域和设计状态反馈控制器，解决了传统方法的局限性。

**Method:** 该框架为非线性系统构建一系列重叠的不变多面体。在每个随机采样航路点周围，算法识别一个凸可容许区域，并解决数据驱动的线性矩阵不等式问题，以学习多个椭球不变集及其局部状态反馈增益。这些椭球体的凸包通过插值增益得到的逐段仿射控制器仍保持不变，然后通过多面体近似。通过验证连续凸包多面体的交集并引入中间节点以实现平滑过渡，确保节点间的安全过渡。控制增益通过基于单纯形的插值实时进行插值，使状态在整个运动过程中保持在不变多面体内部。

**Result:** 通过仿真验证了该方法，证明了所提出的方法在为复杂非线性系统实现安全、动态可行的路径方面的有效性。

**Conclusion:** 本文成功提出了一个数据驱动的运动规划框架，该框架无需系统动力学模型，仅通过数据即可为不确定非线性系统实现安全、动态可行的路径。

> **ai_Abstract:** 本文提出了一种新颖的数据驱动运动规划框架，专为不确定非线性系统设计。该框架通过构建重叠的不变多面体序列，并利用数据驱动的线性矩阵不等式（LMI）来学习局部椭球不变集和状态反馈增益。这些椭球的凸包被近似为多面体，并通过实时增益插值确保平滑和安全的路径过渡。与传统依赖系统模型的方案不同，此方法仅需数据，并在仿真中展示了其在复杂非线性系统中生成安全、动态可行路径的有效性。

> **摘要翻译:** 本文提出了一种用于非线性系统的数据驱动运动规划框架，该框架构建了一系列重叠的不变多面体。在每个随机采样的航路点周围，算法识别一个凸可容许区域，并解决数据驱动的线性矩阵不等式问题，以学习多个椭球不变集及其局部状态反馈增益。这些椭球体的凸包在通过插值增益获得的逐段仿射控制器下仍然保持不变，然后通过多面体进行近似。通过验证连续凸包多面体的交集并引入中间节点以实现平滑过渡，确保节点之间的安全过渡。控制增益通过基于单纯形的插值实时进行插值，使状态在整个运动过程中保持在不变多面体内部。与依赖系统动力学模型的传统方法不同，我们的方法仅需要数据即可计算安全区域并设计状态反馈控制器。该方法通过仿真得到验证，证明了所提出的方法在为复杂非线性系统实现安全、动态可行的路径方面的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [166] [Integrating Opinion Dynamics into Safety Control for Decentralized Airplane Encounter Resolution](https://arxiv.org/abs/2508.00156)
> *将意见动力学整合到分散式飞机遭遇解决的安全控制中*

*Shuhao Qi, Zhiqi Tang, Zhiyong Sun, Sofie Haesaert* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 意见动力学, 飞机安全控制, 分散式冲突解决, 阻塞现象, 自主控制器

**Comment:** 

> **TL;DR:** 本文提出将受生物启发的非线性意见动力学整合到分散式飞机安全控制中，以解决空中交通阻塞问题，确保安全且无阻塞的冲突解决，并提高飞行效率。

**AI_Comments:** 这项研究的创新之处在于将“意见动力学”这一生物启发概念引入到传统的飞机安全控制领域，以解决分散式冲突解决中的阻塞问题。其亮点在于实现了无需通信或预设规则的协作决策，这对于未来高度自主的空中交通管理系统具有重要意义。该方法通过仿真验证了其在效率和安全上的提升，为自主控制器设计提供了宝贵的实践见解。

<details>
  <summary>Details</summary>

**Motivation:** 随着空域日益拥堵，分散式飞机冲突解决方法至关重要。现有的分散式安全控制器虽然能防止碰撞，但不能总是确保及时解决冲突，导致飞机进度长时间受阻。为解决这种“阻塞现象”，本文提出了新方法。

**Method:** 本文提出将受生物启发的非线性意见动力学整合到飞机安全控制框架中。意见动力学使安全控制器能够实现协作决策，从而解决阻塞问题，并在不依赖通信或预设规则的情况下促进快速、安全的协调。

**Result:** 广泛的仿真结果验证了该方法提高了飞行效率并保证了安全性。

**Conclusion:** 本研究为飞机自主控制器的设计提供了实用见解，通过整合意见动力学，可以实现安全且无阻塞的冲突解决。

> **ai_Abstract:** 针对空域拥堵下分散式飞机遭遇解决中存在的“阻塞现象”，本文提出将受生物启发的非线性意见动力学整合到飞机安全控制框架中。该方法通过实现协作决策，在无需通信或预设规则的情况下，确保了安全且无阻塞的冲突解决，并促进了快速、安全的协调。仿真结果验证了其在提高飞行效率和保障安全方面的有效性，为自主飞机控制器设计提供了新思路。

> **摘要翻译:** 随着空域日益拥堵，分散式飞机冲突解决方法变得至关重要。虽然分散式安全控制器可以防止危险的空中碰撞，但它们并不总能确保及时解决冲突。因此，在某些情况下，飞机进度可能会长时间受阻。为解决这种阻塞现象，本文提出将受生物启发的非线性意见动力学整合到飞机安全控制框架中，从而同时保证安全性和无阻塞的解决方案。特别是，意见动力学使安全控制器能够实现阻塞解决的协作决策，并在不依赖通信或预设规则的情况下促进快速、安全的协调。广泛的仿真结果验证了改进的飞行效率和安全保证。这项研究为飞机自主控制器的设计提供了实用见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [194] [Adaptive Compensation of Nonlinear Friction in Mechanical Systems Without Velocity Measurement](https://arxiv.org/abs/2508.00175)
> *机械系统中无速度测量的非线性摩擦自适应补偿*

*Jose Guadalupe Romero, Romeo Ortega, Leyan Fang, Alexey Bobtsov* | **Category: eess.SY, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 摩擦补偿, 无速度测量, 自适应控制, 全局收敛, 速度观测器

**Comment:** 

> **TL;DR:** 本文提出了一种无需速度测量的全局收敛跟踪控制器，用于补偿机械系统中的非线性摩擦，并利用基于浸入和不变性的自适应速度观测器进行摩擦补偿，这是该问题的首个全局收敛解决方案。

**AI_Comments:** 该论文解决了机械系统摩擦补偿中的一个关键挑战：无需速度测量。其创新点在于采用了基于浸入和不变性的自适应速度观测器，并宣称实现了全局收敛，这对于实际应用具有重要意义。突破了传统方法对速度测量的依赖，使得摩擦补偿在更多场景下变得可行。如果实际性能和鲁棒性与理论分析一致，这将是一个非常重要的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 摩擦是机械系统中不可避免的现象，严重阻碍了精确伺服控制。现有的摩擦补偿方案大多依赖于难以获得的速度测量，并且依赖于包含非线性未知参数的复杂摩擦数学模型。

**Method:** 本文提出了一种针对受静摩擦和库仑摩擦扰动的机械系统的全局收敛跟踪控制器，该控制器不依赖于速度测量。关键组件是基于浸入和不变性的自适应速度观测器，用于摩擦补偿。

**Result:** 本文提出的解决方案是已知针对无需速度测量的摩擦补偿问题的首个全局收敛解决方案。文中还展示了将该观测器应用于受更高级LuGre模型描述的摩擦影响的系统的仿真结果。

**Conclusion:** 本文成功提出了一种无需速度测量的非线性摩擦自适应补偿方法，并实现了全局收敛跟踪控制，为解决这一挑战性问题提供了突破性的解决方案。

> **ai_Abstract:** 本研究提出了一种创新性的全局收敛跟踪控制器，用于在没有速度测量的情况下补偿机械系统中的非线性摩擦。该方法利用基于浸入和不变性的自适应速度观测器来估计速度并进行摩擦补偿。与现有依赖速度测量和复杂摩擦模型的方案不同，本方法解决了长期存在的挑战，并被认为是首个实现全局收敛的解决方案。仿真结果也证明了其在更复杂摩擦模型（如LuGre模型）下的有效性。

> **摘要翻译:** 摩擦是所有包含相对运动部件的机械系统中不可避免的现象。众所周知，摩擦是精确伺服控制的严重障碍，因此人们对设计一种补偿摩擦的程序很感兴趣——这是一个多年来许多研究人员研究的课题。文献中报道的绝大多数摩擦补偿方案都依赖于速度测量的可用性，而这种信息很难获得。现有程序的第二个限制是它们依赖于包含几个未知参数的摩擦数学模型，其中一些参数非线性地进入动力学方程。在本文中，我们提出了一种针对受静摩擦和库仑摩擦扰动的机械系统的全局收敛跟踪控制器，这是一种可靠的摩擦现象数学模型，它不依赖于速度测量。关键组件是基于浸入和不变性的自适应速度观测器，用于摩擦补偿。据我们所知，这是解决这一挑战性问题的第一个全局收敛解决方案。我们还展示了将我们的观测器应用于受更高级LuGre模型描述的摩擦影响的系统的仿真结果。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [222] [Optimal Messaging Strategy for Incentivizing Agents in Dynamic Systems](https://arxiv.org/abs/2508.00188)
> *动态系统中激励代理的最优消息策略*

*Renyan Sun, Ashutosh Nayyar* | **Category: eess.SY, cs.GT, cs.SY, math.OC** | **Updated: 2025-07-31**

**Keywords:** 动态系统, 激励, 信息披露, 逆向归纳算法, 线性规划

**Comment:** We submitted a full paper to IEEE TAC for review. A preliminary
  version of this paper is scheduled to be presented at IEEE CDC conference in
  December 2025

> **TL;DR:** 本文研究在动态系统中，设计者如何通过信息披露和行动来激励代理遵循特定策略，并提出一种基于线性规划的逆向归纳算法来计算最优设计者策略。

**AI_Comments:** 这篇论文的创新点在于提供了一种可计算的最优设计者策略方法，通过结合逆向归纳算法和线性规划，解决了在动态系统中激励代理的复杂问题。这对于需要通过信息控制来引导多方行为的应用场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设计者希望在动态系统中通过选择性信息披露和自身行动来影响代理的行动，以激励代理遵循特定策略，并最大化其总预期回报。

**Method:** 提出一种基于逆向归纳算法（backward inductive algorithm）的计算方法，该算法通过求解一系列线性规划（linear programs）来计算最优设计者策略。

**Result:** 在对问题信息结构进行特定假设下，可以利用求解一系列线性规划的逆向归纳算法来计算出最优的设计者策略。

**Conclusion:** 论文成功地提供了一种计算最优设计者策略的方法，该策略能在动态系统中通过信息披露和行动激励代理遵循特定策略，从而最大化设计者的预期回报。

> **ai_Abstract:** 本文研究在有限时域离散时间动态系统中，设计者如何通过选择性信息披露和自身行动来激励一个或多个代理遵循预设策略，并同时最大化设计者的总预期回报。文章定义了一种基于序贯理性的激励兼容性概念，并提出在特定信息结构假设下，可以通过求解一系列线性规划的逆向归纳算法来计算出最优的设计者消息和行动策略。

> **摘要翻译:** 我们考虑一个由设计者和一个或多个代理共同控制的有限时域离散时间动态系统，其中设计者可以通过选择性信息披露影响代理的行动。在每个时间步，设计者从预先指定的消息空间向代理发送消息。设计者还可以采取直接影响系统动态和奖励的行动。每个代理使用其接收到的消息（及其自身信息）来选择其行动。我们关注的是设计者希望激励每个代理执行特定策略的场景。我们考虑了一种激励兼容性概念，该概念基于设计者和代理之间共同信息的每个实现中的序贯理性。我们的目标是找到一种设计者的消息和行动策略，该策略能在激励每个代理遵循预先指定策略的同时，最大化其总预期回报。在对问题信息结构进行某些假设下，我们表明最优设计者策略可以通过求解一系列线性规划的逆向归纳算法来计算。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [249] [Neural Co-state Projection Regulator: A Model-free Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2508.00283)
> *神经协态投影调节器：一种用于实时最优控制和输入约束的无模型范式*

*Lihan Lian, Uduak Inyang-Udoh* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 神经协态投影调节器, 最优控制, 无模型, 输入约束, 庞特里亚金最小原理

**Comment:** 

> **TL;DR:** 本文提出了一种名为神经协态投影调节器（NCPR）的无模型学习型最优控制框架，它基于庞特里亚金最小原理，能够解决带输入约束的非线性控制仿射系统中的二次调节器问题，并通过自监督学习训练神经网络来预测协态轨迹，最终通过求解轻量级二次规划实现实时控制动作，实验证明其在泛化性和采样效率方面优于强化学习。

**AI_Comments:** 这项工作在无模型最优控制领域具有创新性，它将庞特里亚金最小原理与深度学习相结合，为处理带约束的实时控制问题提供了一个有前景的解决方案。其自监督训练范式和对QP的轻量级求解，有望提高实际应用的效率和鲁棒性。该方法在泛化性和采样效率上的提升是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于学习的方法，特别是强化学习，在解决最优控制任务时存在样本效率低下、对奖励设计和超参数敏感以及泛化能力差（尤其是在输入约束下）等问题。

**Method:** 本文引入了神经协态投影调节器（NCPR），这是一个无模型的学习型最优控制框架，它以庞特里亚金最小原理为基础，能够解决带输入约束的非线性控制仿射系统中的二次调节器问题。在该框架中，一个神经网络（NN）在自监督设置下进行训练，以系统当前状态作为输入，预测投影协态（即协态乘以系统输入增益）的有限时域轨迹。随后，仅提取神经网络预测的第一个元素来求解一个轻量级二次规划（QP）。该工作流程在反馈控制设置中执行，允许实时计算满足输入约束和一阶最优性条件的控制动作。

**Result:** 所提出的基于学习的无模型二次调节器在独轮车模型机器人参考跟踪问题和摆锤摆动任务上进行了测试。与强化学习进行比较，并在独轮车模型示例中使用了基于模型的控制器作为参考。结果表明，该方法在未见系统状态和不同输入约束方面表现出卓越的泛化能力，并且还显示出更高的采样效率。

**Conclusion:** 神经协态投影调节器（NCPR）有效克服了现有学习方法在带输入约束的实时最优控制中的局限性，特别是在泛化能力和采样效率方面表现出显著优势。

> **ai_Abstract:** 本文提出了一种新颖的无模型学习型最优控制框架——神经协态投影调节器（NCPR），旨在解决现有强化学习方法在带输入约束的实时最优控制中存在的样本效率低、泛化能力差等问题。NCPR将庞特里亚金最小原理与自监督训练的神经网络相结合，神经网络预测投影协态轨迹，并通过求解轻量级二次规划实时生成满足约束的最优控制动作。实验结果表明，NCPR在处理未见状态和不同输入约束方面具有卓越的泛化能力，并显著提高了采样效率。

> **摘要翻译:** 基于学习的方法，特别是强化学习（RL），在无需明确系统模型的情况下解决最优控制任务方面已展现出前景。然而，这些方法通常样本效率低下，对奖励设计和超参数敏感，并且容易出现泛化能力差的问题，尤其是在输入约束下。为了解决这些挑战，我们引入了神经协态投影调节器（NCPR），这是一种基于庞特里亚金最小原理的无模型学习型最优控制框架，能够解决带输入约束的非线性控制仿射系统中的二次调节器问题。在该框架中，一个神经网络（NN）在自监督设置下进行训练，以系统当前状态作为输入，预测投影协态（即协态乘以系统输入增益）的有限时域轨迹。随后，仅提取神经网络预测的第一个元素来求解一个轻量级二次规划（QP）。该工作流程在反馈控制设置中执行，允许实时计算满足输入约束和一阶最优性条件的控制动作。我们将所提出的基于学习的无模型二次调节器在（1）独轮车模型机器人参考跟踪问题和（2）摆锤摆动任务上进行了测试。为了进行比较，两种任务均使用了强化学习；并且为了提供背景，独轮车模型示例中还使用了基于模型的控制器。我们的方法在未见系统状态和不同输入约束方面都表现出卓越的泛化能力，并且还显示出更高的采样效率。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [262] [Petri Net Modeling and Deadlock-Free Scheduling of Attachable Heterogeneous AGV Systems](https://arxiv.org/abs/2508.00724)
> *Petri网建模与可连接异构AGV系统无死锁调度*

*Boyu Li, Zhengchen Li, Weimin Wu, Mengchu Zhou* | **Category: eess.SY, cs.RO, cs.SY** | **Updated: 2025-08-01**

**Keywords:** Petri网, 异构AGV, 死锁预防, 调度, 元启发式

**Comment:** This work has been submitted to the IEEE for possible publication

> **TL;DR:** 本文研究了可连接异构AGV（载具和穿梭车）的调度问题，提出了一种基于Petri网的建模方法、无死锁调度策略和元启发式算法，并通过实验验证了其有效性。

**AI_Comments:** 本文的创新点在于将Petri网引入到可连接异构AGV系统的调度问题中，有效地解决了连接带来的同步和死锁挑战。其提出的Petri网建模方法、死锁预防策略以及结合元启发式算法的求解框架，为复杂AGV系统的调度提供了新的思路和高效的解决方案。该研究对于提升自动化物流系统的效率和可靠性具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动化和灵活性需求的增加推动了异构AGV的广泛应用。然而，可连接异构AGV之间的协同操作虽然提高了效率，但其连接导致的同步和相互依赖使得调度问题复杂且容易产生死锁。

**Method:** 引入Petri网对AGV调度进行建模，描述并发和顺序任务执行以及载具-穿梭车同步。提出了一种基于Petri网理论的触发驱动解码方法，以及死锁检测和预防策略，以确保无死锁调度。此外，在自适应大邻域搜索框架中开发了一种基于Petri网的元启发式算法，并结合了有效的加速方法来提高计算效率。

**Result:** 使用真实工业数据进行的数值实验验证了所提出算法相对于工程实践中应用的调度策略、精确求解器和四种最先进的元启发式算法的有效性。还进行了敏感性分析以提供管理见解。

**Conclusion:** 该研究提出的基于Petri网的建模和调度方法，能够有效解决可连接异构AGV系统的死锁问题，并提高调度效率，在实际应用中具有优越性。

> **ai_Abstract:** 该论文研究了由可连接异构AGV（载具和穿梭车）组成的物料运输系统的调度问题。针对连接导致的同步和死锁风险，作者引入Petri网进行系统建模，并提出了一种基于Petri网理论的触发驱动解码方法以及死锁检测和预防策略，以确保无死锁调度。为提高计算效率，还在自适应大邻域搜索框架中开发了一种基于Petri网的元启发式算法。通过真实工业数据的实验验证了所提算法的有效性，并提供了管理见解。

> **摘要翻译:** 自动化和灵活性需求的增加推动了异构自动导引车（AGV）的广泛应用。这项工作旨在研究由可连接异构AGV（即载具和穿梭车）组成的物料运输系统中的一个新的调度问题。它们可以灵活地相互连接和分离，以协同执行复杂的运输任务。虽然这种协作提高了操作效率，但连接引起的同步和相互依赖使得调度变得耦合且容易产生死锁。为了解决这一挑战，引入Petri网来建模AGV调度，很好地描述了并发和顺序任务执行以及载具-穿梭车同步。基于Petri网理论，提出了一种触发驱动解码方法，以及死锁检测和预防策略，以确保无死锁调度。此外，在自适应大邻域搜索框架中开发了一种基于Petri网的元启发式算法，并结合了有效的加速方法来提高计算效率。最后，使用真实工业数据进行的数值实验验证了所提出算法相对于工程实践中应用的调度策略、精确求解器和四种最先进的元启发式算法的有效性。还进行了敏感性分析以提供管理见解。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [278] [Low-dimensional observer design for stable linear systems by model reduction](https://arxiv.org/abs/2508.00609)
> *基于模型降阶的稳定线性系统低维观测器设计*

*M. F. Shakib, M. Khalil, R. Postoyan* | **Category: eess.SY, cs.SY, math.OC** | **Updated: 2025-08-01**

**Keywords:** 低维观测器, 模型降阶, 矩匹配, 稳定线性系统, 状态估计

**Comment:** 

> **TL;DR:** 本文提出了一种通过矩匹配模型降阶技术为稳定LTI系统设计低维观测器的方法，该观测器能够对原始系统状态进行精确或有界误差的估计。

**AI_Comments:** 本文的创新之处在于将模型降阶（矩匹配）与低维观测器设计相结合，为稳定线性系统提供了一种计算效率高的状态估计方法。这对于处理大型系统尤其重要，因为全阶观测器可能不切实际。该方法在确保状态估计准确性和误差有界性方面表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 为稳定的单输入单输出连续时间线性时不变（LTI）系统设计一种低维观测器，以有效估计系统状态。

**Method:** 该方法利用矩匹配模型降阶技术将原始系统近似为一个降阶模型，然后基于此降阶模型设计一个低维观测器来估计原始系统的状态。

**Result:** 该观测器能够对特定类别的输入实现精确的渐近状态重构，并对通用输入建立指数输入到状态稳定性特性，从而确保有界的估计误差。数值模拟证实了该方法的有效性。

**Conclusion:** 本文提出的基于模型降阶的低维观测器设计方法对于稳定线性系统是有效的，能够提供准确且误差有界的状态估计。

> **ai_Abstract:** 本文针对稳定的单输入单输出连续时间线性时不变（LTI）系统，提出了一种基于矩匹配模型降阶技术的低维观测器设计方法。该观测器利用降阶模型估计原始系统状态，并被证明对特定输入实现精确渐近状态重构，对通用输入则具有指数输入到状态稳定性，确保估计误差有界。数值模拟验证了其有效性。

> **摘要翻译:** 本文提出了一种用于稳定、单输入单输出、连续时间线性时不变（LTI）系统的低维观测器设计。通过矩匹配模型降阶技术，我们将系统近似为一个降阶模型。基于这个降阶模型，我们设计了一个低维观测器来估计原始系统的状态。我们表明，对于与观测器维度相关联的给定输入类别，该观测器能够实现精确的渐近状态重构。此外，我们为通用输入建立了指数输入到状态稳定性特性，确保了有界的估计误差。数值模拟证实了该方法在基准模型降阶问题上的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [306] [Cyber-Physical Co-Simulation of Load Frequency Control under Load-Altering Attacks](https://arxiv.org/abs/2508.00637)
> *负载频率控制在负载改变攻击下的信息物理协同仿真*

*Michał Forystek, Andrew D. Syrmakesis, Alkistis Kontou, Panos Kotsampopoulos, Nikos D. Hatziargyriou, Charalambos Konstantinou* | **Category: eess.SY, cs.CR, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 信息物理协同仿真, 负载频率控制, 负载改变攻击, 电网安全, 通信网络

**Comment:** 2025 IEEE International Conference on Communications, Control, and
  Computing Technologies for Smart Grids (SmartGridComm)

> **TL;DR:** 本文提出了一个开源的信息物理协同仿真环境，用于分析负载改变攻击对电力系统稳定性的影响，特别是在负载频率控制和欠频减载场景下。

**AI_Comments:** 本文的创新之处在于提供了一个开源的信息物理协同仿真环境，专门用于分析负载改变攻击对电网，特别是对LFC和UFLS等关键保护机制的影响。这对于理解和缓解日益增长的网络威胁对电力基础设施的风险至关重要。其重要性在于为研究人员提供了一个实用的工具，以进行更深入、更真实的攻击分析。

<details>
  <summary>Details</summary>

**Motivation:** 信息通信技术（ICT）的集成给电网带来了好处，但也引入了新的网络威胁。负载改变攻击（LAAs），特别是动态形式的DLAAs，通过操纵高功率设备负载来响应电网频率测量，对电网稳定性构成重大威胁。由于通信网络在电力系统网络安全研究中的重要性，需要一个工具来全面分析此类攻击。

**Method:** 本文提出了一个开源的信息物理协同仿真环境。该环境对电力系统及其相应的通信网络进行建模，并实现了电网保护机制（如负载频率控制LFC和欠频减载UFLS）。

**Result:** 该设置允许在具体的LFC和UFLS场景下对负载改变攻击进行全面分析。

**Conclusion:** 该研究提供了一个协同仿真环境，能够深入分析负载改变攻击对电力系统稳定性的影响，特别是针对LFC和UFLS等关键保护机制。

> **ai_Abstract:** 本文针对信息通信技术集成到电网所带来的网络安全威胁，特别是负载改变攻击（LAAs）对电网稳定性的影响，提出了一个开源的信息物理协同仿真环境。该环境能够同时模拟电力系统和通信网络，并包含负载频率控制（LFC）和欠频减载（UFLS）等保护机制，从而实现对LAAs在具体场景下的全面分析。

> **摘要翻译:** 将信息和通信技术（ICT）设备集成到电网中带来了许多好处。然而，它也将电网暴露在新的潜在网络威胁之下。许多控制和保护机制，如负责在负荷波动期间保持标称频率的负载频率控制（LFC）和在紧急情况下断开部分负荷的欠频减载（UFLS），都依赖于通过通信网络进行的信息交换。最近出现的负载改变攻击（LAAs）利用高功率设备僵尸网络引入负载波动。在它们的动态形式（DLAAs）中，它们根据实时电网频率测量来操纵负载以提高效率，对电网稳定性构成显著威胁。认识到通信网络在电网网络安全研究中的重要性，本文提出了一个开源的协同仿真环境，该环境对电力系统和相应的通信网络进行建模，并实现了电网保护机制。这种设置允许在具体的LFC和UFLS场景中对攻击进行全面分析。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [341] [Learning to optimize with guarantees: a complete characterization of linearly convergent algorithms](https://arxiv.org/abs/2508.00775)
> *学习优化与保证：线性收敛算法的完整表征*

*Andrea Martin, Ian R. Manchester, Luca Furieri* | **Category: eess.SY, cs.LG, cs.SY, math.OC** | **Updated: 2025-08-01**

**Keywords:** 优化算法, 线性收敛, 最坏情况保证, 平均情况性能, 非光滑优化

**Comment:** 

> **TL;DR:** 该研究旨在改进给定线性收敛算法的平均情况性能，同时保留其最坏情况保证，通过表征并推导所有保持收敛性质的更新规则修改。

**AI_Comments:** 该论文通过完整表征线性收敛算法的修改，提供了重要的理论贡献。这使得实践者能够针对特定问题类型调整算法以提高平均情况性能，同时保留关键的最坏情况保证，这对于高风险应用至关重要。这项工作弥合了理论保证和实际效率之间的关键差距，为适应现有鲁棒求解器提供了一种有原则的方法。

<details>
  <summary>Details</summary>

**Motivation:** 在关键的工程应用中，优化算法需要提供可证明的最坏情况保证，但这通常会牺牲在实际常见问题实例上的性能。本研究旨在解决如何增强现有线性收敛算法，以提高其在特定问题集上的平均情况性能，同时保持其在整个问题类别上的最坏情况保证。

**Method:** 通过表征针对非光滑复合优化问题实现线性收敛的算法类别，并从基线线性收敛算法出发，推导出所有且仅有能够保持其收敛性质的更新规则修改。

**Result:** 研究结果适用于增强多种传统算法，如非凸、梯度主导函数的梯度下降法；强凸函数的Nesterov加速法；以及多面体可行集优化的投影法。该方法在解决具有紧密迭代预算的优化问题（如病态线性方程组和线性系统MPC）中展现出有效性。

**Conclusion:** 该论文对保持线性收敛算法最坏情况保证的同时改进其平均情况性能的修改进行了完整表征，适用于多种优化问题和传统算法。

> **ai_Abstract:** 本文旨在解决在不损害可证明最坏情况保证的前提下，提升线性收敛优化算法在特定问题实例上平均性能的挑战。作者通过完整表征在非光滑复合优化问题中保持算法线性收敛特性的更新规则修改，实现了这一目标。所提出的方法被证明适用于多种传统算法（如梯度下降、Nesterov方法、投影方法），并在解决病态线性系统和在紧密迭代预算下进行模型预测控制等实际应用中表现出有效性。

> **摘要翻译:** 在关键的工程应用中，优化算法必须对数学定义的各类问题提供可证明的最坏情况保证。然而，针对最坏情况进行设计不可避免地会牺牲在实践中经常出现的特定问题实例上的性能。我们旨在解决如何增强给定线性收敛算法的问题，以提高其在受限目标问题集上的平均情况性能——例如，为特定动力系统应用定制模型预测控制（MPC）的现成求解器——同时保留其在整个问题类别上的最坏情况保证。为此，我们表征了针对非光滑复合优化问题类别实现线性收敛的算法。特别是，从一个基线线性收敛算法出发，我们推导出了所有——且仅有——能够保持其收敛性质的更新规则修改。我们的结果适用于增强传统算法，例如用于非凸、梯度主导函数的梯度下降法；用于强凸函数的Nesterov加速法；以及用于多面体可行集优化的投影法。我们在应用于病态线性方程组和线性系统MPC的紧密迭代预算优化问题中展示了该方法的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [590] [Risk-Aware Autonomous Driving with Linear Temporal Logic Specifications](https://arxiv.org/abs/2409.09769)
> *基于线性时序逻辑规范的风险感知自动驾驶*

*Shuhao Qi, Zengjie Zhang, Zhiyong Sun, Sofie Haesaert* | **Category: eess.SY, cs.FL, cs.RO, cs.SY** | **Updated: 2025-07-31**

**Keywords:** 自动驾驶, 风险感知, 线性时序逻辑, 线性规划, 占用测度

**Comment:** 

> **TL;DR:** 本文将人类驾驶员的风险感知能力扩展到自动驾驶系统，通过线性时序逻辑（LTL）规范和线性规划（LP）解决不同类型驾驶风险的平衡问题。

**AI_Comments:** 本文的创新之处在于将线性时序逻辑（LTL）与风险度量相结合，以实现自动驾驶系统中的类人风险感知，特别是在平衡多种风险类型方面。通过将控制合成问题转化为线性规划问题，为风险感知策略的生成提供了一个可行的数学框架。该方法在处理交通规则和事件时序/严重性方面具有较强的表达能力。

<details>
  <summary>Details</summary>

**Motivation:** 人类驾驶员在驾驶时能自然地平衡交通规则违规、轻微事故和致命事故等不同风险，但自动驾驶系统尚未能实现这种行为。

**Method:** 本文将一个在类人驾驶研究中验证过的风险度量扩展到更复杂的、由线性时序逻辑（LTL）规范定义的驾驶场景，该扩展将事件的时间和严重性纳入LTL规范。通过采用由安全和协同安全公式组成的LTL规范，将控制合成问题重新表述为可达性问题。利用占用测度，进一步为基于LTL的风险度量制定线性规划（LP）问题。

**Result:** 合成的策略能够平衡不同类型的驾驶风险，包括碰撞风险和交通规则违规。该方法的有效性在Carla模拟器中的三个典型交通场景中得到了验证。

**Conclusion:** 本文提出的方法能够使自动驾驶系统实现类似人类的风险感知，有效平衡不同类型的驾驶风险，并在模拟器中验证了其有效性。

> **ai_Abstract:** 本文旨在解决自动驾驶系统中缺乏类人风险感知的问题。研究人员扩展了一个已验证的风险度量，通过线性时序逻辑（LTL）规范融入事件的时间和严重性，以处理碰撞风险和交通规则违规等复杂场景。通过将控制合成问题重构为可达性问题，并利用占用测度将其表述为线性规划（LP），该方法能够合成平衡多种驾驶风险的策略。在Carla模拟器中的实验验证了其有效性。

> **摘要翻译:** 人类驾驶员在驾驶时能自然地平衡交通规则违规、轻微事故和致命事故等不同风险。然而，在自动驾驶系统中实现相同的行为仍然是一个开放问题。本文将一个在类人驾驶研究中验证过的风险度量扩展到更复杂的、由线性时序逻辑（LTL）规范定义的驾驶场景，这些场景超越了单纯的碰撞风险。该扩展将事件的时间和严重性纳入LTL规范，从而反映出类似人类的风险意识。在不牺牲交通规则表达能力的前提下，我们采用由安全和协同安全公式组成的LTL规范，从而允许将控制合成问题重新表述为可达性问题。通过利用占用测度，我们进一步为这个基于LTL的风险度量制定了一个线性规划（LP）问题。因此，合成的策略能够平衡不同类型的驾驶风险，包括碰撞风险和交通规则违规。所提出方法的有效性在Carla模拟器中的三个典型交通场景中得到了验证。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [632] [Prescribed-Time Boresight Control of Spacecraft Under Pointing Constraints](https://arxiv.org/abs/2504.04312)
> *受指向约束的航天器预设时间视轴控制*

*Xiaodong Shao, Haoyang Yang, Haoran Li, Zongyu Zuo, Jose Guadalupe Romero, Qinglei Hu* | **Category: eess.SY, cs.SY** | **Updated: 2025-08-01**

**Keywords:** 预设时间控制, 视轴控制, 航天器, 指向约束, 制导与控制

**Comment:** 

> **TL;DR:** 本文提出了一种集成视轴制导与控制（IBGC）方案，用于在时间和指向约束下实现航天器视轴的预设时间重定向，并通过仿真和实验验证了其有效性。

**AI_Comments:** 该论文的创新点在于提出了集成的视轴制导与控制方案，结合了预设时间控制、扰动观测和避障策略。引入的PPTA函数和预设时间稳定性判据是其理论贡献。该方法能够确保航天器在严格的时间和指向约束下完成任务，具有重要的工程应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 解决航天器在时间和指向约束下视轴重定向的问题。

**Method:** 提出了一种集成视轴制导与控制（IBGC）方案。该方案包括：1) 提出了一个$C^1$连续、饱和的预设时间调整（PPTA）函数和一个实用的预设时间稳定性判据。2) 利用时间尺度变换技术和PPTA函数，设计了预设时间制导律，使视轴避开所有禁区并到达目标区域。3) 导出了预设时间扰动观测器（PTDO）以重建外部扰动。4) 利用障碍函数和PPTA函数，开发了基于PTDO的姿态跟踪控制器，确保视轴在“安全管”内进行预设时间跟踪。

**Result:** 通过合理设置制导和控制律的安全裕度、稳定时间和安全管，所提出的IBGC方案能够在所需的任务完成时间内实现受指向约束的视轴重定向。仿真和实验结果证明了所提出IBGC方案的有效性。

**Conclusion:** 所提出的集成视轴制导与控制（IBGC）方案能够有效解决航天器在时间和指向约束下的视轴重定向问题，并实现了预设时间内的准确跟踪和避障。

> **ai_Abstract:** 本文提出了一种集成视轴制导与控制（IBGC）方案，用于解决航天器在时间和指向约束下的视轴重定向问题。该方案引入了预设时间调整（PPTA）函数和相应的稳定性判据，并利用时间尺度变换技术设计了预设时间制导律以实现避障和目标区域引导。同时，通过预设时间扰动观测器（PTDO）重建外部扰动，并结合障碍函数和PPTA函数开发了基于PTDO的姿态跟踪控制器，确保视轴在“安全管”内进行预设时间跟踪。仿真和实验结果验证了该IBGC方案在预设时间内实现精确指向和避障的有效性。

> **摘要翻译:** 本文提出了一种集成视轴制导与控制（IBGC）方案，以解决航天器在时间和指向约束下的视轴重定向问题。文中提出了一种$C^1$连续、饱和的预设时间调整（PPTA）函数，并建立了实用的预设时间稳定性判据。利用时间尺度变换技术和PPTA函数，我们提出了一种预设时间制导律，该制导律可在预设时间内将视轴矢量从自由空间中几乎任何初始方向引导至目标方向的小邻域内，同时避开所有带有安全裕度的禁区。随后，推导了预设时间扰动观测器（PTDO）以重建外部扰动。通过利用障碍函数和PPTA函数，开发了一种基于PTDO的简化姿态跟踪控制器，该控制器确保在“安全管”内进行预设时间视轴跟踪。通过巧妙设置制导和控制律的安全裕度、稳定时间和安全管，所提出的IBGC方案在所需任务完成时间内实现了受指向约束的视轴重定向。仿真和实验结果证明了所提出IBGC方案的有效性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [39] [Matrix Decomposition and Applications](https://arxiv.org/abs/2201.00145)
> *矩阵分解及其应用*

*Jun Lu* | **Category: math.NA, cs.LG, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 矩阵分解, 数值线性代数, 机器学习, 综述, 反向传播

**Comment:** 

> **TL;DR:** 本综述旨在对矩阵分解技术及其在机器学习中的应用进行独立的介绍，涵盖数值线性代数和矩阵分析的基础概念。

**AI_Comments:** 这篇论文作为矩阵分解的入门综述，其价值在于为读者提供了一个自洽的介绍，尤其强调了其在机器学习（特别是反向传播算法）中的应用。论文清晰地指出了其覆盖范围的局限性，并引导读者进一步探索相关文献，这体现了其严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 本论文旨在对矩阵分解技术及其应用进行独立的介绍，鉴于其在机器学习中的核心地位，并追溯其在数值分析领域的历史渊源。

**Method:** 本论文采用综述的形式，通过介绍数值线性代数和矩阵分析中的基本概念和数学工具，从而引出矩阵分解技术及其应用。

**Result:** 本论文的成果是提供了一个关于矩阵分解概念、数学工具及其应用的独立介绍。

**Conclusion:** 本综述提供了矩阵分解的独立介绍，但受限于篇幅未能涵盖所有相关成果，并建议读者参考更详细的线性代数文献。

> **ai_Abstract:** 本综述论文提供了一个关于矩阵分解技术及其在机器学习中应用的独立介绍。它从数值线性代数和矩阵分析的基础概念开始，并提及了Householder的早期工作。论文旨在无缝引入矩阵分解技术，并承认其范围有限，建议读者查阅更专业的文献以深入了解特定领域。

> **摘要翻译:** 1954年，Alston S. Householder 出版了《数值分析原理》，这是最早的关于矩阵分解的现代论著之一，该书推崇（分块）LU分解——将矩阵分解为下三角矩阵和上三角矩阵的乘积。如今，矩阵分解已成为机器学习中的核心技术，这主要归功于拟合神经网络中反向传播算法的发展。本综述的唯一目的是对数值线性代数和矩阵分析中的概念和数学工具进行独立的介绍，以便在后续章节中无缝地引入矩阵分解技术及其应用。然而，我们清楚地意识到，鉴于讨论范围的限制，我们无法涵盖所有关于矩阵分解的有用和有趣的结果，例如欧几里得空间、厄米特空间、希尔伯特空间以及复数域中的分离分析。我们建议读者参考线性代数领域的文献以获取更详细的相关领域介绍。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [74] [Propagation of chaos in infinite horizon and numerical stability for stochastic McKean-Vlasov equations](https://arxiv.org/abs/2312.12699)
> *随机McKean-Vlasov方程的无限 horizon 混沌传播与数值稳定性*

*Zhuoqi Liu, Shuaibin Gao, Chenggui Yuan, Qian Guo* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 随机McKean-Vlasov方程, 数值稳定性, 混沌传播, Euler-Maruyama格式, 粒子方法

**Comment:** 

> **TL;DR:** 本文研究了随机McKean-Vlasov方程在无限时间范围内的混沌传播现象，并分析了其随机粒子方法的数值稳定性，包括欧拉-马利亚纳和后向欧拉-马利亚纳格式在不同条件下的均方和几乎必然指数稳定性。

**AI_Comments:** 本文在随机McKean-Vlasov方程的数值稳定性研究上取得了重要进展。其创新点在于证明了在超线性条件下后向Euler-Maruyama格式的均方指数稳定性无需粒子破坏，这是一个新颖且重要的结论。通过巧妙地操纵经验测度，为数值分析提供了严谨的理论支撑，并强调了理论分析在实际应用中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过随机粒子方法研究随机McKean-Vlasov方程（SMVEs）的数值稳定性，并确保数值解能够重现原始SMVEs的稳定性。

**Method:** 本文采用随机粒子方法，通过巧妙地操纵经验测度，研究了Euler-Maruyama (EM) 格式及其对应的相互作用粒子系统的均方和几乎必然指数稳定性。此外，还探讨了后向EM格式的均方和几乎必然稳定性。

**Result:** 1. 获得了均方意义下的长时间混沌传播，并证明了无限 horizon 下的几乎必然传播。2. 当系数满足线性增长条件时，证明了 Euler-Maruyama (EM) 格式及其对应相互作用粒子系统的均方和几乎必然指数稳定性。3. 在漂移和扩散中的状态变量均为超线性的情况下，实现了相互作用系统的后向EM格式的均方指数稳定性，且没有粒子破坏。4. 在扩散系数满足线性增长条件下，研究了后向EM格式的几乎必然稳定性。

**Conclusion:** 结合这些论断，数值解能够再现原始随机McKean-Vlasov方程的稳定性。通过反馈控制问题和随机意见动力学模型等示例，证明了数值稳定性理论分析的重要性。

> **ai_Abstract:** 本文深入探讨了随机McKean-Vlasov方程（SMVEs）的数值稳定性，主要通过随机粒子方法。研究首先确立了SMVEs的长时间和无限horizon下的混沌传播特性。随后，论文详细分析了在不同系数条件下，包括线性增长和超线性增长情况，Euler-Maruyama (EM) 格式和后向EM格式的均方及几乎必然指数稳定性。特别地，在超线性情况下，后向EM格式的均方稳定性被证明是无粒子破坏的，这是一项新颖的发现。研究结果表明，所提出的数值方法能够有效地再现原始SMVEs的稳定性，并通过具体示例验证了数值稳定性理论分析的重要性。

> **摘要翻译:** 本文主要研究随机McKean-Vlasov方程（SMVEs）通过随机粒子方法的数值稳定性。首先，获得了均方意义下的长时间混沌传播，并证明了无限 horizon 下的几乎必然传播。接下来，当系数满足线性增长条件时，通过巧妙地操纵经验测度，证明了与相应相互作用粒子系统相关的Euler-Maruyama (EM) 格式的均方和几乎必然指数稳定性。然后，对于漂移和扩散中的状态变量均为超线性的情况，在没有粒子破坏的情况下，实现了相互作用系统后向EM格式的均方指数稳定性，这是一个新颖的结论。此外，在扩散系数满足线性增长条件下，研究了后向EM格式的几乎必然稳定性。结合这些论断，数值解能够再现原始SMVEs的稳定性。通过反馈控制问题和随机意见动力学模型等示例，证明了数值稳定性理论分析的重要性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [102] [A fully segregated and unconditionally stable IMEX scheme for dispersed multiphase flows](https://arxiv.org/abs/2504.02629)
> *一种用于分散多相流的完全分离且无条件稳定的IMEX格式*

*Douglas Pacheco, Richard Schussnig* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 多相流, IMEX方案, 压力校正, 无条件稳定, 分离式求解器

**Comment:** 

> **TL;DR:** 本文提出了一种新的、完全分离的IMEX（隐式-显式）压力校正方法，用于分散多相流模拟，该方法具有无条件能量稳定性和无需定点迭代的特点，解决了传统单体求解器昂贵且耦合项显式处理导致时间步限制的问题。

**AI_Comments:** 该论文的创新点在于提出了一个完全分离且无条件稳定的IMEX方案，有效解决了多相流模拟中计算成本高和时间步限制的难题。其无需定点迭代的特性显著提高了计算效率和鲁棒性，对于工程和科学计算领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单体求解器在模拟多相流时成本高昂且难以实现。此外，将子问题分解时，显式处理耦合项（压力和阻力）可能会导致时间步长限制，影响计算效率和稳定性。因此，需要一种解耦且稳定的方法。

**Method:** 本文提出了一种基于平均速度场不可压缩性的一阶压力校正方法，并结合了阻力的显式处理。同时，对对流项和粘性项进行了半隐式处理。这形成了一种隐式-显式（IMEX）方法，该方法具有无条件能量稳定性，并且不需要任何类型的定点迭代。每个时间步仅包含线性标量输运方程和一个单独的压力泊松问题作为基本构建块。

**Result:** 所提出的IMEX方法不仅具有无条件能量稳定性，而且无需任何类型的定点迭代。每个时间步的计算仅涉及线性、标量输运方程和一个压力泊松问题。该方法在没有CFL类条件的情况下，在理论上被严格证明具有时间稳定性，并通过两相数值算例证实了理论的有效性。

**Conclusion:** 本文提出了一种新型的、无条件稳定的完全分离IMEX方案，有效解决了分散多相流模拟中计算成本高昂和时间步限制的问题，为多相流模拟提供了一种高效且鲁棒的数值方法。

> **ai_Abstract:** 本文提出了一种新的、完全分离的隐式-显式（IMEX）压力校正方案，用于模拟分散多相流。该方法基于平均速度场不可压缩性，并显式处理阻力，同时半隐式处理对流和粘性项。与传统的昂贵单体求解器和受时间步限制的解耦方法相比，该IMEX方案具有无条件能量稳定性和无需定点迭代的优点，每个时间步仅涉及简单的线性方程。理论上，该方案在无CFL条件下具有时间稳定性，并通过两相数值算例得到了验证。

> **摘要翻译:** 欧拉-欧拉或体积平均纳维-斯托克斯方程在各种应用中用于模拟具有两个或更多相互渗透相的系统。每种流体都遵循其自身的动量和质量方程，并且相通常通过阻力以及共享压力进行耦合。因此，整体求解器可能非常昂贵且难以实现，所以解耦方法具有很大的计算吸引力。然而，分解子问题需要显式处理耦合项（压力和阻力），这必须小心进行以避免时间步限制。在这种背景下，我们基于平均速度场的不可压缩性，结合阻力的显式处理，推导了一种新的一阶压力校正方法。此外，对流项和粘性项都采用半隐式处理。这为我们提供了一种隐式-显式（IMEX）方法，该方法不仅因其无条件能量稳定性而非常鲁棒，而且因为它不需要任何类型的定点迭代。每个时间步仅包含线性、标量输运方程和一个单独的压力泊松问题作为构建块。我们严格证明了在没有任何CFL类条件下的时间稳定性，并通过两相数值算例证实了该理论。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [121] [Rational complex Bezier curves](https://arxiv.org/abs/2507.23485)
> *有理复数贝塞尔曲线*

*A. Canton, L. Fernandez-Jambrina, M. J. Vazquez-Gallo* | **Category: math.NA, cs.GR, cs.NA, 65D17, 68U07** | **Updated: 2025-07-31**

**Keywords:** 有理复数贝塞尔曲线, 投影变换, 几何反演, 曲线度数, CAD

**Comment:** 9 pages, 6 figures

> **TL;DR:** 论文开发了有理复数贝塞尔曲线的形式，扩展了CAD范式，允许使用复数投影变换，并能在某些情况下降低曲线的度数。

**AI_Comments:** 这篇论文通过引入复数域的概念到贝塞尔曲线中，为CAD和几何建模领域带来了创新。其重要性在于，利用复数投影变换和可能降低曲线度数的特性，为曲线设计提供了更强大的工具和更灵活的表示方法。这可能简化复杂曲线的表示和操作，尤其是在需要应用高级几何变换时。

<details>
  <summary>Details</summary>

**Motivation:** 为了扩展CAD范式，利用复数投影变换的优势，并可能在某些情况下降低曲线的度数，从而为曲线设计提供更灵活的工具。

**Method:** 论文开发了有理复数贝塞尔曲线的形式化，这是CAD范式的一个简单扩展。该框架通过将控制多边形和权重扩展到复数值来描述曲线弧，并利用实平面和复数平面的两种投影变换群。

**Result:** 该形式允许应用如几何反演等有用的变换到设计曲线中。此外，复数公式的使用在某些情况下可以降低曲线的度数，并提供了一个简单的公式，通过多项式结果来判断有理三次曲线是否为圆锥曲线。论文中包含了该形式应用于经典曲线的例子。

**Conclusion:** 有理复数贝塞尔曲线的形式化为CAD和曲线设计提供了新的工具，通过引入复数域的特性，增强了曲线变换的灵活性并优化了曲线的表示。

> **ai_Abstract:** 本文提出并发展了有理复数贝塞尔曲线的形式化，将其作为CAD范式的一个扩展。通过将控制多边形和权重扩展到复数值，该框架能够利用实数和复数两种投影变换群，从而实现几何反演等有用变换。此外，这种复数公式在某些情况下可以降低曲线的度数，并提供了一种判断有理三次曲线是否为圆锥曲线的简便方法。论文还提供了该形式应用于经典曲线的示例。

> **摘要翻译:** 本文开发了有理复数贝塞尔曲线的形式化。
该框架是CAD范式的一个简单扩展，因为它通过控制多边形和权重来描述曲线弧，这些控制多边形和权重被扩展到复数值。这种扩展的主要优点之一是我们可以利用两组不同的投影变换。除了实平面的投影变换群之外，我们还有复数投影变换群。这使得我们能够将几何反演等有用的变换应用于设计中的曲线。除此之外，复数公式的使用在某些情况下可以降低曲线的度数。这可以通过两个多项式的结式来检查，并提供了一个简单的公式来确定有理三次曲线是否为圆锥曲线。论文中包含了该形式应用于经典曲线的例子。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [130] [Global Energy Minimization for Simplex Mesh Optimization: A Radius Ratio Approach to Sliver Elimination](https://arxiv.org/abs/2507.01762)
> *单纯形网格优化的全局能量最小化：一种基于半径比率的薄片消除方法*

*Dong Wang, Chunyu Chen, Huayi Wei* | **Category: math.NA, cs.NA, math.OC, 65N50, 65K10, 65F08** | **Updated: 2025-08-01**

**Keywords:** 单纯形网格, 网格优化, 薄片消除, 半径比率, 能量最小化

**Comment:** 

> **TL;DR:** 本文提出了一种基于半径比率能量函数的新方法，用于优化单纯形网格质量，有效消除薄片单元，提高数值模拟的稳定性和准确性。

**AI_Comments:** 这项研究的创新之处在于引入了基于半径比率的能量函数，并利用其梯度特性（可分解为对称正定矩阵作为预处理器）来加速网格优化过程。这对于提高有限元分析和计算几何中数值模拟的准确性和稳定性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，3D单纯形网格中薄片单元的存在会严重影响模拟结果。

**Method:** 本文提出了一种基于半径比率能量函数的新方法来优化单纯形网格单元的质量。该方法通过将能量函数的梯度分解为矩阵-向量积，并使矩阵成为对称正定矩阵，作为预处理器以显著加速优化过程。

**Result:** 实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

**Conclusion:** 该方法通过全局能量最小化和半径比率能量函数，能够有效消除单纯形网格中的薄片单元，显著提高网格质量，从而增强数值模拟的稳定性和准确性。

> **ai_Abstract:** 本文提出了一种新颖的单纯形网格优化方法，该方法基于半径比率能量函数，旨在消除3D网格中的薄片单元。通过将能量函数的梯度分解为对称正定矩阵，该方法能够显著加速优化过程。实验结果证明了其在提高网格质量和消除薄片单元方面的有效性。

> **摘要翻译:** 单纯形网格的质量对于有限元分析和计算几何中的数值模拟的稳定性和准确性至关重要。然而，3D单纯形网格中薄片单元的存在会严重影响结果。本文提出了一种基于半径比率能量函数的新方法来优化单纯形网格单元的质量。该方法可以有效消除薄片单元，从而提高网格质量。所提出的能量函数的梯度可以分解为矩阵-向量积。经过少量处理，该矩阵变为对称正定矩阵，并且这个对称正定矩阵可以作为预处理器，显著加速优化过程。实验结果表明，该方法在消除薄片单元和提高网格质量方面具有显著优势。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [158] [Dynamic analysis of free-free Timoshenko beams on elastic foundation under transverse transient ground deformation](https://arxiv.org/abs/2507.22850)
> *弹性地基上自由-自由Timoshenko梁在横向瞬态地面变形下的动力分析*

*Gersena Banushi* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** Timoshenko梁, 瞬态地面变形, 动力分析, 弹性地基, 土-结构相互作用

**Comment:** Key words: buried Timoshenko beam, semi-analytical model, dynamic
  amplification, transient ground deformation (TGD), modal analysis

> **TL;DR:** 本文提出了一个基于Timoshenko梁和Winkler地基理论的半解析模型，用于分析地下梁在瞬态地面变形下的动力响应，并通过有限元分析验证了其准确性。

**AI_Comments:** 这项研究通过引入一个考虑系统惯性和土-结构界面动力相互作用的半解析模型，弥补了现有简化模型在分析地下大直径管道和隧道动力响应方面的不足。其创新性在于提出了基于Timoshenko梁和Winkler地基理论的闭式解析解，并揭示了振动频谱的精细结构。通过与有限元分析的对比验证了模型的准确性，增强了其在实际工程应用中的可靠性。该方法对于理解和设计受地震波等地面振动影响的地下结构具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地下基础设施，如管道和隧道，易受地震和交通荷载引起的瞬态地面变形影响。现有设计方法基于简化模型，忽略系统惯性和土-结构界面相对位移，不适用于大直径管道和隧道，因此需要精确的动力分析。

**Method:** 本研究引入了一种基于Timoshenko梁和Winkler地基理论的新型半解析模型来分析埋地直梁在横向瞬态地面变形下的动力响应。该模型获得了闭式解析解。通过分析不同长度和运行条件的埋地钢水管道案例，并将解析解与有限元分析结果进行比较来验证模型。

**Result:** 闭式解析解表明，振动频谱分为四个部分，由三个过渡频率分隔；在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统动力响应。解析解与有限元分析结果显示出极好的一致性。频率响应分析揭示，在接近系统基频的强制频率下，土-结构相互作用存在动力放大效应。

**Conclusion:** 所提出的方法提供了一个鲁棒的分析框架，用于评估影响埋地梁动力行为的主要因素，从而更深入地理解系统在各种地面振动源下的响应。

> **ai_Abstract:** 本文针对地下基础设施在瞬态地面变形下的动力响应分析，提出了一种基于Timoshenko梁和Winkler地基理论的新型半解析模型。该模型通过闭式解析解揭示了振动频谱的四个分区及其在过渡频率处的特性变化。通过与有限元分析的对比，验证了模型的准确性，并发现系统基频附近的动力放大效应。该研究为评估埋地梁的动力行为提供了一个可靠的分析框架。

> **摘要翻译:** 地下基础设施，如管道和隧道，可能容易受到地震和交通荷载等不同振动源引起的瞬态地面变形（TGD）的影响。当前的设计方法基于简单的分析模型，将土体运动理想化为行进的正弦波，忽略了系统惯性和土-结构界面的相对位移。然而，对于需要精确动力分析的埋地大直径管道和隧道，这种假设可能不成立。为了分析埋地直梁在横向TGD作用下的动力响应，本研究引入了一种基于Timoshenko梁和Winkler地基理论的新型半解析模型。闭式解析解表明，振动频谱分为四个部分，由三个过渡频率分隔。在每个过渡频率处，振动模式的振荡特性发生变化，显著影响系统的动力响应。为了验证所提出模型的有效性，本研究分析了一个在横向TGD作用下，长度和运行条件不同的埋地钢水管道的案例。获得的解析解与有限元分析结果的比较显示，两种方法之间具有极好的一致性。频率响应分析揭示，在接近系统基频的强制频率下，土-结构相互作用存在动力放大。这些频率可能落在表征地震波的主导频率范围内，需要精确的动力分析。所提出的方法提供了一个鲁棒的分析框架，用于评估影响埋地梁动力行为的主要因素，从而更深入地理解系统在各种地面振动源下的响应。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [616] [Zeroing Diagonals, Conjugate Hollowization, and Characterizing Nondefinite Operators](https://arxiv.org/abs/2508.00096)
> *对角线清零、共轭空心化和非定常算子的表征*

*David R. Nicholus* | **Category: math.NA, cs.NA, math.RA, 65F25, 15A21, 15B10, 15A23, 15B99, 15A86** | **Updated: 2025-07-31**

**Keywords:** 对角线清零, 空心矩阵, 无迹矩阵, 正交相似, 非定常算子

**Comment:** 24 pages, 4 figures

> **TL;DR:** 本文证明了Damm和Fassbender的猜想，即对于任意一对实数无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV是空心矩阵，且VMV⁻¹几乎是空心矩阵。这一结论源于一个更普遍的定理，并揭示了在对角线上引入零的条件，还提供了实数无迹矩阵的新表征，并加强了Fillmore的定理。

**AI_Comments:** 本文在矩阵理论和线性代数领域具有重要意义。其创新之处在于证明了一个长期存在的猜想，并通过一个更普遍的定理为该猜想提供了坚实的基础。研究不仅解决了特定问题，还揭示了在矩阵对角线上引入零的普适条件和内在机制，这对于理解矩阵结构和性质至关重要。此外，对Fillmore定理的加强版本也进一步深化了我们对矩阵相似性的认识。通过对非定常矩阵的分类，本文为未来的研究提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在证明Damm和Fassbender的猜想，即对于任意一对实数无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV是空心矩阵，且VMV⁻¹几乎是空心矩阵。此外，研究还旨在揭示在对角线上引入零的条件，并表征非定常算子。

**Method:** 研究通过证明一个更普遍的定理来得出Damm和Fassbender猜想的推论。此外，通过设置L=M，深入探讨了在单个算子对角线上引入零的自由度和约束。在此基础上，证明了实数无迹矩阵的新表征，以及Fillmore定理的更强版本。研究将结果置于非定常矩阵的表征和分类背景中，通过大致量化和方式来衡量其对角线可以引入多少个零。

**Result:** 1. 证明了Damm和Fassbender的猜想：对于任意一对实数无迹矩阵L, M，存在一个正交矩阵V，使得V⁻¹LV是空心矩阵，且VMV⁻¹几乎是空心矩阵。2. 揭示了在L, M的特定条件下，V可以在V⁻¹LV的所有对角线元素（除了第一个或前两个）以及VMV⁻¹的所有对角线元素（除了最后两个）中引入0。3. 揭示了在单个算子对角线上引入0的自由度和约束。4. 证明了实数无迹矩阵的新颖表征。5. 证明了Fillmore开创性定理的更强版本，即每个实数矩阵都正交相似于一个主对角线为常数的矩阵。

**Conclusion:** 本文的结果通过对非定常矩阵的表征和分类进行了背景化，大致根据可以向其对角线引入多少个零以及以何种方式引入零来进行分类。研究提供了关于在矩阵对角线上引入零的深刻见解，并对现有理论进行了扩展和加强。

> **ai_Abstract:** 本文证明了Damm和Fassbender关于实数无迹矩阵对角线清零的猜想，即存在正交矩阵V使得V⁻¹LV为空心矩阵且VMV⁻¹几乎为空心矩阵。这一结论源于一个更普遍的定理，并揭示了在不同条件下向矩阵对角线引入零元素的可能性。研究通过设置L=M，深入探讨了单个算子对角线清零的自由度与约束，进而提出了实数无迹矩阵的新表征，并给出了Fillmore定理的加强版本。这些结果被置于非定常矩阵的表征和分类框架下，主要关注其对角线可引入零的数量和方式。

> **摘要翻译:** 我们证明了Damm和Fassbender的猜想，即对于任意一对实数无迹矩阵L,M，存在一个正交矩阵V，使得V⁻¹LV是空心矩阵，且VMV⁻¹几乎是空心矩阵，其中如果一个矩阵的主对角线仅由0组成，则该矩阵是空心矩阵；如果一个无迹矩阵除了最后两个元素外，其所有主对角线元素都是0，则该矩阵几乎是空心矩阵。这个断言是我们更普遍的定理的一个推论，也是另一个推论，揭示了在L,M的条件下，V可以在V⁻¹LV的所有对角线元素（除了第一个或前两个）以及VMV⁻¹的所有对角线元素（除了最后两个）中引入0。通过设置L=M，可以揭示许多关于在单个算子对角线上引入0所涉及的自由度和约束。由此，我们证明了实数无迹矩阵的新颖表征，以及Fillmore开创性定理的更强版本，即每个实数矩阵都正交相似于一个主对角线为常数的矩阵。我们的结果被置于非定常矩阵的表征和分类背景中，大致根据可以向其对角线引入多少个零以及以何种方式引入零来进行分类。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [627] [On the power of adaption and randomization](https://arxiv.org/abs/2406.07108)
> *关于适应性和随机化的能力*

*David Krieg, Erich Novak, Mario Ullrich* | **Category: math.NA, cs.CC, cs.NA, math.FA** | **Updated: 2025-07-31**

**Keywords:** 自适应算法, 随机算法, 线性算子, 凸集, n-宽度

**Comment:** 

> **TL;DR:** 本文研究了自适应和随机算法在凸集上逼近线性算子相对于非自适应、确定性算法的最大增益的界限，对对称集合给出了最优结果，并对非对称集合统一了n-宽度和s-数。

**AI_Comments:** 本文的创新之处在于量化了自适应和随机方法的能力界限，尤其是在对称集合上的最优性以及对n-宽度和s-数的统一。这有助于理解逼近理论中不同算法方法的理论极限和优势。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在量化和理解自适应和随机算法在逼近线性算子方面的能力，并将其与非自适应和确定性算法进行比较。

**Method:** 本文提出了最大增益的界限，证明了在对称集合上的结果是最优的，并统一了n-宽度和s-数的一些概念，展示了它们与最小误差的联系。此外，还讨论了向非线性宽度和基于函数值的逼近的扩展。

**Result:** 对于对称凸集，得到了最优界限。对于非对称集合，统一了n-宽度和s-数，并揭示了它们与最小误差的关联。论文还讨论了向非线性宽度和基于函数值的逼近的扩展。

**Conclusion:** 论文以一系列开放问题作为结束，表明该领域仍有待进一步研究。

> **ai_Abstract:** 本文探讨了自适应和随机算法在凸集上逼近线性算子时相对于非自适应、确定性算法的最大优势。研究为对称集合确立了最优界限，并针对非对称集合统一了n-宽度和s-数，揭示了它们与最小逼近误差的联系。作者还讨论了向非线性宽度和基于函数值的逼近的扩展，并以一系列开放研究问题作结。

> **摘要翻译:** 我们提出了自适应和随机算法相对于非自适应、确定性算法在凸集上逼近线性算子的最大增益的界限。如果集合是另外对称的，那么我们的结果是最佳的。对于非对称集合，我们统一了n-宽度和s-数的一些概念，并展示了它们与最小误差的联系。我们还讨论了向非线性宽度和基于函数值的逼近的扩展，并以一系列开放问题作为结束。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [651] [Leveraging Operator Learning to Accelerate Convergence of the Preconditioned Conjugate Gradient Method](https://arxiv.org/abs/2508.00101)
> *利用算子学习加速预处理共轭梯度法的收敛*

*Alena Kopaničáková, Youngkyu Lee, George Em Karniadakis* | **Category: math.NA, cs.LG, cs.NA, math.OC, 65M55, 68T05, 49K20** | **Updated: 2025-07-31**

**Keywords:** 算子学习, 预处理共轭梯度法, 紧缩策略, DeepONet, 大规模线性系统

**Comment:** 31 pages

> **TL;DR:** 该研究提出一种基于算子学习（DeepONet）的新型紧缩策略，以加速预处理共轭梯度法（PCG）在大规模线性系统中的收敛。

**AI_Comments:** 该论文的创新点在于将算子学习（DeepONet）引入到预处理共轭梯度法的紧缩策略中，这是一种新颖的方法来生成紧缩子空间，区别于传统的特征向量或Krylov子空间方法。这为加速数值线性代数算法提供了新的视角，并展示了机器学习在高性能计算中的潜力。其重要性在于能够有效加速大规模线性系统的求解，这在科学计算和工程应用中具有重要意义。局限性可能在于DeepONet的训练成本和泛化到更复杂非线性问题的能力。

<details>
  <summary>Details</summary>

**Motivation:** 加速预处理共轭梯度法（PCG）在大规模参数化线性方程组中的收敛。

**Method:** 提出一种新的紧缩策略，利用算子学习（特别是DeepONet）生成紧缩子空间。具体包括两种组装紧缩算子互补方法：一是使用DeepONet学习的基函数近似离散PDE算子的近零空间向量；二是直接利用DeepONet预测的解。此外，还提出了几种规定紧缩算子稀疏模式的策略。

**Result:** 通过对稳态、瞬态、标量和矢量值问题（在结构化和非结构化几何上）进行全面的数值实验，证明了所提出的基于DeepONet的紧缩PCG方法的有效性及其在各种模型参数和问题分辨率下的泛化能力。

**Conclusion:** 所提出的基于DeepONet的紧缩PCG方法能够有效加速大规模参数化线性方程组的收敛，并具有良好的泛化能力。

> **ai_Abstract:** 该论文提出一种利用深度算子网络（DeepONet）生成紧缩子空间的新型紧缩策略，以加速预处理共轭梯度（PCG）方法求解大规模参数化线性方程组的收敛。该方法包含两种组装紧缩算子的互补途径，并引入了稀疏模式规定策略。数值实验验证了其有效性和广泛的泛化能力。

> **摘要翻译:** 我们提出了一种新的紧缩策略，以加速求解参数化大规模线性方程组的预处理共轭梯度（PCG）方法的收敛。与依赖于特征向量近似或循环Krylov子空间的传统紧缩技术不同，我们使用算子学习，特别是深度算子网络（DeepONet）来生成紧缩子空间。为此，我们引入了两种互补的方法来组装紧缩算子。第一种方法使用DeepONet学习的基函数来近似离散PDE算子的近零空间向量。第二种方法直接利用DeepONet预测的解。为了进一步增强收敛性，我们还提出了几种规定紧缩算子稀疏模式的策略。本文展示了一系列全面的数值实验，包括在结构化和非结构化几何上提出的稳态、瞬态、标量和矢量值问题，并证明了所提出的基于DeepONet的紧缩PCG方法的有效性，以及它在各种模型参数和问题分辨率下的泛化能力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [679] [Partial Floquet Transformation and Model Order Reduction of Linear Time-Periodic Systems](https://arxiv.org/abs/2508.00221)
> *局部Floquet变换与线性时变周期系统的模型降阶*

*Sam Bender, Christopher Beattie* | **Category: math.NA, cs.NA, math.DS** | **Updated: 2025-07-31**

**Keywords:** 线性时变周期系统, 模型降阶, Floquet变换, 不变子空间, Dominant Pole算法

**Comment:** 21 pages

> **TL;DR:** 本文提出了一种局部Floquet变换方法，结合不变子空间和改进的Dominant Pole算法，用于大型线性时变周期系统的模型降阶，以克服传统Floquet变换的计算难题。

**AI_Comments:** 这项工作具有创新性，因为它通过引入“局部Floquet变换”的概念，有效地解决了传统Floquet变换在处理大型线性时变周期系统时计算量过大的问题。通过结合不变子空间和修改后的Dominant Pole算法，该方法提供了一种更实际可行的模型降阶策略，对于需要模拟复杂时变周期系统的工程领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 线性时变周期系统（LTP系统）普遍存在，其大规模系统的模拟需要有效的模型降阶策略。传统的Floquet变换方法对于大型系统来说计算上难以处理，因此需要一种新的方法来解决这一挑战。

**Method:** 本文提出了一种局部Floquet变换的概念，该变换与LTP系统相关联的时变微分算子的选定不变子空间相关联。作者修改并重新利用Rommes的Dominant Pole算法来识别用于模型降阶的有效不变子空间。文章还讨论了相关局部Floquet变换和时变降阶基的构建，以生成有效的降阶LTP模型。

**Result:** 论文在一个简单的时变周期系统上演示了所提出的过程。

**Conclusion:** 本文提出的局部Floquet变换方法为大型线性时变周期系统的模型降阶提供了一种可行且计算效率更高的方法，克服了传统Floquet变换的计算复杂性。

> **ai_Abstract:** 本文针对大规模线性时变周期（LTP）系统模型降阶中传统Floquet变换计算复杂的问题，提出了一种新的局部Floquet变换方法。该方法通过识别时变微分算子的选定不变子空间，并修改Dominant Pole算法来辅助这一过程，从而构建局部Floquet变换和时变降阶基，以实现LTP模型的有效降阶。文章在一个简单系统上验证了该方法。

> **摘要翻译:** 时变周期动力系统在自然界和工程系统中都普遍存在。例如，大规模线性时变周期动力系统可能通过对给定周期解（可能是基线周期强迫的结果）附近的非线性系统进行线性化，并随后进行空间离散化而产生。模拟对各种输入剖面（视为基线周期强迫的扰动）响应的潜在需求，为适用于线性时变周期（LTP）系统的有效模型降阶策略创造了强大的动力。考虑到潜在时变周期系统结构的经典方法通常利用Floquet变换；然而，对于大阶系统而言，Floquet变换的计算通常是难以处理的。在本文中，我们提出了局部Floquet变换的概念，该变换与LTP系统相关联的时变微分算子的选定不变子空间相关联。我们修改并重新利用Rommes的Dominant Pole算法来识别用于模型降阶的有效不变子空间。我们讨论了相关局部Floquet变换和时变降阶基的构建，以便生成有效的降阶LTP模型，并在一个简单的时变周期系统上演示了该过程。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [707] [A reduced-IRKA method for large-scale $\mathcal{H}_2$-optimal model order reduction](https://arxiv.org/abs/2508.00242)
> *大规模$\\mathcal{H}_2$最优模型降阶的降维IRKA方法*

*Yiding Lin, Valeria Simoncini* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** 模型降阶, IRKA, 大规模系统, $\\mathcal{H}_2$最优

**Comment:** 

> **TL;DR:** 提出了一种新的降维IRKA方法，有效解决了大规模系统下的$\\mathcal{H}_2$最优模型降阶问题。

**AI_Comments:** 这篇论文通过改进IRKA算法来解决其在大规模$\\mathcal{H}_2$最优模型降阶问题上的局限性，具有重要的实际意义。其创新之处在于引入了顺序生成投影子空间、在投影问题上应用IRKA以及结合偏移量注入和内存截断的策略，这使得该方法能够高效处理大规模系统。

<details>
  <summary>Details</summary>

**Motivation:** 现有的迭代有理Krylov算法（IRKA）在处理大规模线性动力系统时性能不佳，无法满足$\\mathcal{H}_2$最优模型降阶的需求。

**Method:** 论文引入了一种新的有理Krylov子空间投影方法，该方法通过选择合适的偏移量来处理大规模问题。投影子空间是顺序生成的，并在投影问题上应用IRKA程序以生成降维问题的新最优有理空间和相关偏移量。这些偏移量随后被注入以扩展投影空间，同时对生成空间中的旧信息进行截断以限制内存需求。

**Result:** 在基准问题上的数值实验表明，新方法是有效的。

**Conclusion:** 提出的降维IRKA方法能有效处理大规模系统的$\\mathcal{H}_2$最优模型降阶问题，并表现出良好的性能。

> **ai_Abstract:** 本文提出了一种针对大规模线性动力系统$\\mathcal{H}_2$最优模型降阶的改进方法，即降维IRKA方法。针对传统IRKA算法在大规模问题上性能不足的局限性，新方法通过顺序生成有理Krylov子空间，并在投影问题上应用IRKA，结合合适的偏移量注入和旧信息截断来有效管理内存，从而实现了对大规模问题的有效处理。数值实验验证了其有效性。

> **摘要翻译:** $\\mathcal{H}_2$最优模型降阶（MOR）是线性动力系统降阶方法中最重要的框架之一。在这种背景下，迭代有理Krylov算法（IRKA）是一种公认的方法，用于在系统维度较小或中等时计算固定维度$r$的最优投影空间。然而，对于大规模问题，IRKA的性能并不令人满意。在本文中，我们引入了一种新的有理Krylov子空间投影方法，该方法通过方便选择的偏移量，可以有效地处理大规模问题。投影子空间是顺序生成的，并在投影问题上应用IRKA程序，为降维问题生成一个新的维度为$r$的最优有理空间以及相关的偏移量。后者随后被注入以扩展投影空间。为了限制内存需求，对生成空间中的旧信息进行了截断。在基准问题上的数值实验证明了新方法的有效性。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [735] [A COGENT case study: Supporting Applications with Chombo](https://arxiv.org/abs/2508.00375)
> *COGENT案例研究：Chombo支持应用程序*

*Daniel F. Martin, Milo Dorr, Mikhail Dorf, Lee F. Ricketson* | **Category: math.NA, cs.NA, physics.plasm-ph** | **Updated: 2025-08-01**

**Keywords:** Chombo, COGENT, 科学应用, 软件框架, 案例研究

**Comment:** 

> **TL;DR:** Chombo框架通过开发新功能来支持COGENT科学应用，使其能够模拟托卡马克边缘层，并且这些功能也能支持其他类似应用。

**AI_Comments:** 这篇论文展示了一个成熟的软件框架如何通过灵活的扩展和定制化开发，来满足特定科学应用的复杂需求，并在此过程中提升了框架本身的通用性和复用性。其创新点在于通过实际案例验证了Chombo框架的适应性和扩展性，强调了软件框架在支持前沿科学研究中的重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 探讨Chombo软件框架如何通过定制化开发支持科学应用COGENT的特定需求。

**Method:** 通过与Edge Simulation Laboratory合作构建COGENT模型，并在Chombo框架中设计和实现了新的能力，例如高阶映射多块离散化和多维代码组织。

**Result:** Chombo框架中开发的新能力使COGENT能够开发出独特的模拟功能，用于模拟托卡马克中的边缘层。这些新开发的能力也能够支持其他有类似需求的应用程序。

**Conclusion:** Chombo框架通过定制化开发，不仅成功支持了COGENT的特定科学模拟需求，而且这些新开发的功能具有通用性，能够惠及其他类似应用。

> **ai_Abstract:** 本文通过COGENT案例研究，详细阐述了Chombo软件框架如何通过定制化开发，满足了COGENT科学应用在托卡马克边缘层模拟方面的特定需求。Chombo为此引入了高阶映射多块离散化和多维代码组织等新功能，成功赋能COGENT构建了独特的模拟能力，并指出这些新功能同样适用于其他具有相似需求的应用程序。

> **摘要翻译:** 我们展示了一个软件框架（Chombo）如何支持科学应用（COGENT）的特定需求的案例研究。自2000年成立以来，Chombo框架已支持各种应用程序。这种支持的一个例子是与边缘模拟实验室合作构建COGENT模型。COGENT工作的特定需求要求在Chombo框架中设计和实现一套新功能，例如高阶映射多块离散化和多维代码组织。这些功能使COGENT能够开发出独特的模拟能力，用于模拟托卡马克中的边缘层。一旦开发出来，这些功能就能够支持其他有类似需求的应用程序。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [770] [A new addition theorem for the 3-D Navier-Lamé system and its application to the method of fundamental solutions](https://arxiv.org/abs/2508.00515)
> *三维 Navier-Lamé 系统的新加法定理及其在基本解法中的应用*

*J. A. Barceló, C. Castro, A. Ruiz, M. C. Vilela* | **Category: math.NA, cs.NA** | **Updated: 2025-08-01**

**Keywords:** Navier-Lamé系统, 加法定理, 基本解法, 贝塞尔函数, 球谐函数

**Comment:** 

> **TL;DR:** 本文提出了一个针对三维Navier-Lamé系统基本解的新加法定理，该定理通过贝塞尔函数和标量球谐函数展开，并证明了其在外部域中逼近Navier-Lamé系统的效率。

**AI_Comments:** 这项研究的创新之处在于提出了一个针对三维Navier-Lamé系统基本解的新加法定理，该定理简化了基本解的计算，使其仅依赖于贝塞尔函数和标量球谐函数。这对于提高基于基本解的数值方法的计算效率和适用性具有重要意义，特别是在处理外部域问题时。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是为基于基本解的配置数值方法（如边界元法或基本解法）提供一个特别有用的工具，以提高其在逼近Navier-Lamé系统时的效率。

**Method:** 作者获得了一个针对满足Kupradze辐射条件的三维Navier-Lamé系统基本解的新加法定理，该定理提供了基本解的展开式，仅涉及贝塞尔函数和标量球谐函数的评估。

**Result:** 该加法定理提供了一个基本解的展开式，其计算仅涉及贝塞尔函数和标量球谐函数。此外，研究显示了该方法在逼近外部域中的Navier-Lamé系统时的效率。

**Conclusion:** 本文提出的新加法定理及其基于基本解法的应用，在逼近外部域中的Navier-Lamé系统时表现出高效性。

> **ai_Abstract:** 本文提出了一个针对三维Navier-Lamé系统基本解的新加法定理。该定理将基本解展开为仅涉及贝塞尔函数和标量球谐函数的表达式，这对于基于基本解的配置数值方法（如边界元法）具有重要意义。研究特别强调并证明了该方法在外部域中逼近Navier-Lamé系统时的效率。

> **摘要翻译:** 我们获得了满足Kupradze辐射条件的三维Navier-Lamé系统基本解的一个新加法定理。这提供了一个仅涉及贝塞尔函数和标量球谐函数评估的基本解展开式。这在基于基本解的配置数值方法（如边界元法或基本解法）中特别有用。对于后一种方法，我们展示了其在逼近外部域中的Navier-Lamé系统时的效率。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [805] [Solitary-wave solutions of the fractional nonlinear Schrödinger equation. II. A numerical study of the dynamics](https://arxiv.org/abs/2508.00559)
> *分数阶非线性薛定谔方程的孤立波解。II. 动力学数值研究*

*Angel Durán, Nuria Reguera* | **Category: math.NA, cs.NA, math.AP, 76B25, 35C07, 65H10** | **Updated: 2025-08-01**

**Keywords:** 分数阶非线性薛定谔方程, 孤立波, 数值研究, 动力学, 稳定性

**Comment:** 

> **TL;DR:** 本文对分数阶非线性薛定谔方程的孤立波解的动力学进行了数值研究，探讨了波的稳定性、扰动影响和波相互作用。

**AI_Comments:** 本文是作者前期关于分数阶非线性薛定谔方程孤立波存在性研究的延续，着重于其动力学的数值分析。采用傅里叶谱方法和高阶Runge-Kutta方法保证了数值模拟的精度。对波的稳定性、扰动和相互作用的探讨，为理解此类方程的复杂动力学提供了重要的数值证据。

<details>
  <summary>Details</summary>

**Motivation:** 作者在前一部分工作中分析了分数阶非线性薛定谔方程孤立波解的存在性，本文旨在对其动力学进行数值研究。

**Method:** 采用傅里叶谱方法进行空间离散，并使用四阶Runge-Kutta-Composition方法作为时间积分器，对周期性初值问题进行近似计算。

**Result:** 讨论了波的稳定性问题，包括小扰动和大扰动的影响、孤立波的相互作用以及初始数据解析成波列的情况。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文对分数阶非线性薛定谔方程的孤立波解的动力学进行了数值研究。该研究利用傅里叶谱方法进行空间离散，并结合四阶Runge-Kutta-Composition方法进行时间积分，以近似周期性初值问题。研究内容包括探讨波的稳定性，分析小扰动和大扰动的影响，孤立波之间的相互作用，以及初始数据如何分解为波列。

> **摘要翻译:** 本文对分数阶非线性薛定谔方程孤立波解的动力学进行了数值研究，其存在性已由作者在项目的第一部分中进行了分析。计算研究将通过周期性初值问题的近似来完成，该近似采用了一个完全离散方案，包括用于空间离散的傅里叶谱方法和作为时间积分器的四阶Runge-Kutta-Composition方法。讨论了有关波稳定性的一些问题，例如小扰动和大扰动的影响、孤立波的相互作用以及初始数据解析成波列的情况。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [840] [Towards a mixed-precision ADI method for Lyapunov equations](https://arxiv.org/abs/2508.00722)
> *面向Lyapunov方程的混合精度ADI方法*

*Jonas Schulze, Jens Saak* | **Category: math.NA, cs.NA, 15A24, 65F10, 65F45, 65F55** | **Updated: 2025-08-01**

**Keywords:** 混合精度, ADI方法, Lyapunov方程, 低秩, H2范数

**Comment:** 11 pages, 3 figures, 1 table; submitted to PAMM 2025

> **TL;DR:** 对Lyapunov方程的LR-ADI方法应用混合精度，在某些应用中表现出竞争力，特别是对于一阶系统，单精度累积可达到与双精度相当的残差。

**AI_Comments:** 本文的创新在于系统地将混合精度应用于Lyapunov方程的低秩ADI (LR-ADI) 方法，这对于大规模问题的计算效率至关重要。发现对于一阶系统，单精度累积可以产生可比的精度具有重要意义。其重要性在于潜在地降低计算成本和内存占用，使ADI在对性能要求苛刻的实际应用中更具可行性。

<details>
  <summary>Details</summary>

**Motivation:** 探索将混合精度应用于Lyapunov方程的低秩ADI (LR-ADI) 方法，以期提高计算效率和竞争力。

**Method:** 该研究将混合精度应用于低秩Lyapunov ADI (LR-ADI) 方法。具体而言，算法的某些部分在较低的工作精度下执行，包括累积总解、求解ADI迭代中的线性系统，以及以IEEE 754单精度和双精度的各种组合存储残差的内部低秩因子。

**Result:** 对于一阶示例，单精度累积的解产生的残差与双精度解的残差几乎一样小。对于某些应用，如计算描述符系统的H2范数，ADI的低精度或混合精度变体可能非常有竞争力。

**Conclusion:** 混合精度或低精度ADI方法在处理Lyapunov方程的某些特定应用（如计算描述符系统的H2范数）时具有良好的竞争力。

> **ai_Abstract:** 本文研究了将混合精度应用于低秩Lyapunov ADI (LR-ADI) 方法。作者在算法的某些部分，例如解的累积、线性系统的求解以及残差低秩因子的存储中，使用了单精度和双精度的组合。对来自描述符系统Lyapunov方程的实证测试表明，对于一阶情况，单精度累积的残差与双精度相当。研究得出结论，混合精度ADI变体对于计算H2范数等特定应用具有竞争力。

> **摘要翻译:** 我们将混合精度应用于低秩Lyapunov ADI (LR-ADI) 方法，通过在较低的工作精度下执行算法的某些方面。具体来说，我们以IEEE 754单精度和双精度的各种组合来累积总解、求解构成ADI迭代的线性系统，并存储残差的内部低秩因子。我们通过实验测试了我们在源自一阶和二阶描述符系统的Lyapunov方程上的实现。对于一阶示例，以单精度累积解产生的残差几乎与双精度解一样小。对于某些应用，例如计算描述符系统的H2范数，ADI的低精度或混合精度变体可能非常具有竞争力。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='statap'></a>
## stat.AP 

### [111] [Predicting Formula 1 Race Outcomes: Decomposing the Roles of Drivers and Constructors through Linear Modeling](https://arxiv.org/abs/2508.00200)
> *F1赛车结果预测：通过线性模型分解车手和制造商的角色*

*Saurabh Rane* | **Category: stat.AP** | **Updated: 2025-07-31**

**Keywords:** F1赛车, 车手, 制造商, 线性模型, RAPM

**Comment:** 26 pages, 12 figures, 9 tables

> **TL;DR:** 本文将篮球和冰球中常用的RAPM方法扩展到F1赛车，使用时间衰减岭回归和LOESS平滑来预测2014-2024年F1比赛结果，并量化了车手和制造商对比赛成绩的单独影响，发现制造商解释了64.0%的比赛结果方差。

**AI_Comments:** 这篇论文的创新点在于将体育分析中成熟的RAPM方法引入F1赛车领域，解决了传统积分系统难以分离车手和制造商独立贡献的难题。通过量化制造商和车手的具体影响，为F1车队管理、车手招募和战略规划提供了更精细的数据支持。其发现制造商在比赛结果中占据主导地位，提供了重要的洞察。

<details>
  <summary>Details</summary>

**Motivation:** F1赛车表现是赛车和车手能力的结合，但单独量化车手和制造商的影响仍然具有挑战性。

**Method:** 本文扩展了正则化调整加减（RAPM）方法，并采用了时间衰减岭回归（time-decayed ridge regression）和LOESS平滑来预测2014-2024年混合动力引擎时代的比赛结果。通过测量制造商和车手系数随时间的变化来量化其相对个体影响。

**Result:** 制造商解释了混合动力引擎时代64.0%的比赛结果方差。制造商在基准排名前10的得分者等排名无关的群体中重要性增加，而在排位赛中重要性降低。

**Conclusion:** 通过将表现分解为单独的车手和制造商指标，创建了一个强大的框架，用于F1积分系统模糊的制造商间车手比较。这项工作增强了对车手和制造商对比赛成功贡献的理解，为F1战略决策提供了有价值的见解。

> **ai_Abstract:** 本文将体育分析中常用的正则化调整加减（RAPM）方法应用于F1赛车，旨在量化车手和制造商对比赛结果的独立贡献。研究采用时间衰减岭回归和LOESS平滑，分析了2014-2024年混合动力引擎时代的比赛数据。结果表明，制造商在比赛结果方差中占据64.0%的解释力，并在某些情境下（如前10名得分手）重要性更高，而在排位赛中则较低。该研究提供了一个评估车手和制造商独立表现的框架，有助于F1的战略决策。

> **摘要翻译:** F1赛车表现是赛车能力和车手能力的结合。虽然一场比赛或一个赛季可以告诉你赛车和车手共同表现如何，但要分离出车手和制造商的个体影响仍然具有挑战性。本文扩展了一种在篮球和冰球中常用的正则化调整加减（RAPM）方法（Sill 2010），以解析出个体车手和制造商的影响。它采用时间衰减岭回归结合LOESS平滑（Jacoby 2000）来预测混合动力引擎时代（2014-2024年）的比赛结果。通过测量制造商和车手系数随时间的变化，我们测量了在此期间车手和制造商的相对个体影响。结果显示，制造商解释了混合动力引擎时代64.0%的比赛结果方差。此外，制造商在基准排名无关的群体（例如，前10名得分手）中重要性增加，而在排位赛中重要性降低。通过将表现分解为单独的车手和制造商指标，我们创建了一个强大的框架，用于F1积分系统模糊的制造商间车手比较。我们的工作增强了对车手和制造商对比赛成功贡献的理解，为F1战略决策提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [237] [A Multivariate Space-Time Dynamic Model for Characterizing the Atmospheric Impacts Following the Mt Pinatubo Eruptio](https://arxiv.org/abs/2408.13392)
> *表征皮纳图博火山喷发后大气影响的多变量时空动态模型*

*Robert Garrett, Lyndsay Shand, J. Gabriel Huerta* | **Category: stat.AP** | **Updated: 2025-08-01**

**Keywords:** 多变量时空动态模型, 皮纳图博火山, 大气影响, 气溶胶注入, 气候变化

**Comment:** 

> **TL;DR:** 本文开发了一个多变量时空动态线性模型，用于量化皮纳图博火山喷发后大气参数之间的关系，并证明了其相对于单变量模型的优势，为理解大规模火山喷发对气候的影响提供了工具。

**AI_Comments:** 该论文的创新之处在于提出了一个新颖的多变量时空动态线性模型，能够同时捕捉大气影响的空间和时间变异性。其重要性在于提供了一个更全面的框架来分析像火山喷发这样复杂的气候事件，并通过与单变量模型的比较突出了其优势，为未来的平流层气溶胶注入研究提供了方法学基础。

<details>
  <summary>Details</summary>

**Motivation:** 1991年皮纳图博火山喷发导致大气中硫酸盐气溶胶大量增加，吸收辐射并引起全球地表和平流层温度变化。这种规模的火山喷发可作为平流层气溶胶注入的自然类比，后者是一种拟议的太阳辐射修正方法，旨在应对气候变暖。研究的目标是表征皮纳图博火山喷发后大气影响的多变量和动态性质。

**Method:** 研究开发了一个多变量时空动态线性模型来理解空间和时间变化的全面影响。具体来说，空间变化通过一组灵活的基函数建模，其基系数通过向量自回归（VAR）结构随时间变化。这个新颖的模型采用动态线性模型（DLM）框架，并通过定制的MCMC方法进行估计。

**Result:** 模型展示了如何量化皮纳图博火山喷发前后关键大气参数之间的关系，并强调了该模型相对于单变量模型的优势。

**Conclusion:** 该研究开发的多变量时空动态模型能够有效地量化皮纳图博火山喷发后大气参数的动态和多变量影响，并证明了其在分析此类复杂大气事件方面的优越性。

> **ai_Abstract:** 本研究提出了一种新颖的多变量时空动态线性模型，旨在表征1991年皮纳图博火山喷发后大气影响的多变量和动态性质。该模型将空间变化通过基函数建模，并允许其系数通过向量自回归结构随时间变化，采用动态线性模型框架并通过MCMC方法估计。研究利用MERRA-2再分析数据，展示了该模型如何量化火山喷发前后关键大气参数间的关系，并强调了其相对于单变量模型的优势，为理解大规模火山事件对气候的影响提供了有效工具。

> **摘要翻译:** 1991年6月皮纳图博火山喷发导致大气中硫酸盐气溶胶大量增加，吸收辐射并导致全球地表和平流层温度变化。这种规模的火山喷发可作为平流层气溶胶注入的自然类比，后者是一种拟议的太阳辐射修正方法，旨在应对气候变暖。此类事件的影响是多方面的且具有区域特异性。我们的目标是表征皮纳图博火山喷发后大气影响的多变量和动态性质。我们开发了一个多变量时空动态线性模型，以理解空间和时间变化的全面影响。具体来说，空间变化通过一组灵活的基函数建模，其基系数通过向量自回归（VAR）结构随时间变化。这个新颖的模型采用动态线性模型（DLM）框架，并通过定制的MCMC方法进行估计。我们展示了该模型如何利用MERRA-2再分析数据量化皮纳图博火山喷发前后关键大气参数之间的关系，并强调了该模型相对于单变量模型的优势。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

### [263] [Assessing Racial Disparities in Healthcare Expenditures via Mediator Distribution Shifts](https://arxiv.org/abs/2504.21688)
> *通过中介变量分布变化评估医疗支出中的种族差异*

*Xiaxian Ou, Xinwei He, David Benkeser, Razieh Nabi* | **Category: stat.AP, stat.ME, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 种族差异, 医疗支出, 中介变量, 分解, 机器学习

**Comment:** 

> **TL;DR:** 该研究开发了一个框架，通过分解中介变量的分布变化来评估医疗支出中的种族差异，并利用机器学习方法进行分析，以深入理解其驱动因素。

**AI_Comments:** 这篇论文的创新之处在于它提出了一种新颖的框架，通过分解中介变量的分布变化来评估医疗支出中的种族差异，而不是简单地将种族本身视为可操纵的暴露。这种方法为理解差异的潜在驱动因素提供了一个更细致的视角。研究的重要性在于其有助于识别导致医疗支出差异的具体中介因素，从而为制定有针对性的政策和干预措施提供指导。尽管摘要中未明确提及，但潜在的局限性可能包括获取全面且高质量的中介变量数据的挑战，以及该框架的实际效果尚未在摘要中呈现具体结果。

<details>
  <summary>Details</summary>

**Motivation:** 医疗支出中的种族差异已被充分证实，但其根本驱动因素复杂且需要进一步研究。

**Method:** 本研究开发了一个框架，通过分解中介变量（如社会经济地位、保险可及性、健康行为或健康状况）的分布变化来分解医疗支出中的种族差异，而不是将种族本身视为可操纵的暴露。该框架将总差异分解为两部分：一部分归因于中介变量分布的差异，另一部分是即使中介变量分布均衡后仍将存在的残余部分。研究利用医疗支出调查数据，并采用基于影响函数技术和灵活机器学习工具（包括超级学习器和为零膨胀、右偏支出数据设计的两部分模型）的渐近线性估计器来确保有效推断。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该研究提出一个新颖的框架，用于分解医疗支出中的种族差异，通过分析中介变量（如社会经济地位、保险和健康行为）的分布变化，而非将种族作为直接原因。该框架将总差异分解为中介变量效应和残余效应，并利用医疗支出调查数据，结合影响函数技术和机器学习方法进行分析，旨在深入理解和量化这些差异的驱动因素。

> **摘要翻译:** 医疗支出中的种族差异已被充分证实，但其根本驱动因素仍然复杂，需要进一步研究。本研究开发了一个框架，通过中介变量分布的变化来分解此类差异，而不是将种族本身视为可操纵的暴露。我们将差异定义为不同种族群体间协变量调整后结果分布的差异，并将总差异分解为两个组成部分：一个归因于中介变量分布的差异，另一个是即使在这些分布均衡后仍将存在的残余部分。利用医疗支出调查（Medical Expenditures Panel Survey）的数据，我们研究了如果社会经济地位、保险可及性、健康行为或健康状况等中介变量在不同种族群体间得到均衡，支出差异将持续存在或减少的程度。为确保有效推断，我们基于影响函数技术和灵活的机器学习工具（包括超级学习器和为零膨胀、右偏支出数据设计的两部分模型）推导出渐近线性估计器。

</details>

[⬆️ 返回分类顶部](#statap) | [⬆️ 返回总目录](#toc)

---

<a id='q-finmf'></a>
## q-fin.MF 

### [300] [Volatility Modeling with Rough Paths: A Signature-Based Alternative to Classical Expansions](https://arxiv.org/abs/2507.23392)
> *粗糙路径下的波动率建模：经典展开的基于签名的替代方法*

*Elisa Alòs, Òscar Burés, Rafael de Santiago, Josep Vives* | **Category: q-fin.MF, math.PR, 60L70, 60H10, 91G20, 91G60, 60G22** | **Updated: 2025-08-01**

**Keywords:** 波动率建模, 粗糙路径, 路径签名, 隐含波动率, Malliavin微积分

**Comment:** 

> **TL;DR:** 本文比较了两种隐含波动率曲面校准方法：基于Malliavin微积分的渐近展开法和基于粗糙路径理论的路径签名法。研究表明，签名法在Heston模型中与渐近法精度相当，且在粗糙Bergomi模型中表现出更好的模型独立性和鲁棒性。

**AI_Comments:** 本文创新性地将粗糙路径理论中的路径签名应用于波动率建模，提供了一种比传统渐近展开法更具模型独立性和鲁棒性的校准方法。其重要性在于，该方法在处理具有粗糙或非马尔可夫特征的复杂波动率动态时表现出色，克服了传统方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为校准隐含波动率曲面，寻找一种比传统渐近展开法更灵活、更具模型独立性的替代方法，尤其是在波动率具有粗糙或非马尔可夫特征的情况下。

**Method:** 本文比较了两种校准隐含波动率曲面的方法：1. 基于Malliavin微积分的二阶渐近展开法，该方法在资产价格遵循Heston型随机波动率模型时有效。2. 基于粗糙路径理论的路径签名数据驱动方法，该方法将波动率建模为初级随机过程签名的线性泛函，无需特定的参数形式。

**Result:** 数值实验表明，当真实动态为Heston模型时，基于签名的方法达到了与渐近法相当的校准精度。在资产遵循粗糙Bergomi波动率过程（超出渐近展开范围）的更通用设置中，签名方法仍能提供准确结果。

**Conclusion:** 这些发现突出了基于签名的校准方法在波动率表现出粗糙或非马尔可夫特征的环境中，其模型独立性、鲁棒性和适应性。

> **ai_Abstract:** 本文比较了两种校准隐含波动率曲面的方法：基于Malliavin微积分的渐近展开法（适用于Heston模型）和基于粗糙路径理论的路径签名法。研究发现，签名法在Heston模型中与渐近法精度相当，但在波动率具有粗糙或非马尔可夫特征的更一般设置（如粗糙Bergomi模型）中，签名法表现出卓越的模型独立性、鲁棒性和适应性。

> **摘要翻译:** 我们比较了两种校准隐含波动率曲面的方法：一种是通过Malliavin微积分推导的二阶渐近展开法，另一种是基于粗糙路径理论的路径签名数据驱动方法。前者由Alos 等人（2015）开发，在资产价格遵循Heston型随机波动率模型的假设下，能提供高效准确的校准公式。后者将波动率建模为初级随机过程签名的线性泛函，从而在不需要特定参数形式的情况下实现灵活的近似。我们的数值实验表明，当真实动态为Heston模型时，基于签名的方法达到了与渐近法相当的校准精度。然后，我们在更一般的设置中测试了该模型，即资产遵循粗糙Bergomi波动率过程——这是一种超出渐近展开范围的机制——结果表明签名方法继续提供准确的结果。这些发现突出了基于签名的校准方法在波动率表现出粗糙或非马尔可夫特征的环境中的模型独立性、鲁棒性和适应性。

</details>

[⬆️ 返回分类顶部](#q-finmf) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [4] [Sinusoidal Approximation Theorem for Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.00247)
> *柯尔莫哥洛夫-阿诺德网络的正弦近似定理*

*Sergei Gleyzer, Hanh Nguyen, Dinesh P. Ramakrishnan, Eric A. F. Reinhardt* | **Category: stat.ML, cs.LG, cs.NA, math.NA** | **Updated: 2025-08-01**

**Keywords:** 柯尔莫哥洛夫-阿诺德网络, 正弦函数, 神经网络, 通用逼近, 机器学习

**Comment:** 15 pages, 3 figures

> **TL;DR:** 提出一种基于正弦函数的柯尔莫哥洛夫-阿诺德网络（KAN）变体，并证明其理论有效性，实验结果显示其性能优于固定频率傅里叶变换，与多层感知机（MLP）相当。

**AI_Comments:** 该论文的创新点在于将正弦函数引入到柯尔莫哥洛夫-阿诺德网络（KAN）中作为激活函数，并证明了其理论有效性，这为KANs的激活函数设计提供了新的方向。通过使用可学习频率的正弦函数，可能能够更好地捕捉周期性或振荡模式，从而在某些任务上表现出优势。其与MLPs相当的性能表明了该变体的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有柯尔莫哥洛夫-阿诺德网络（KANs）通常使用样条基函数作为激活函数，而后续工作探索了其他替代方案。本文旨在提出一种新的KAN变体，以替代传统的样条激活函数。

**Method:** 提出一种新的KAN变体，通过将柯尔莫哥洛夫-阿诺德表示中的内外函数替换为具有可学习频率的加权正弦函数。受Lorentz和Sprecher引入的简化启发，将正弦激活的相位固定为线性间隔的常数值，并提供了其理论有效性的证明。此外，还进行了数值实验，评估其在多变量函数上的性能，并将其与固定频率傅里叶变换方法和多层感知机（MLPs）进行比较。

**Result:** 数值实验表明，该方法优于固定频率傅里叶变换，并取得了与多层感知机（MLPs）相当的性能。

**Conclusion:** 提出的基于正弦函数的柯尔莫哥洛夫-阿诺德网络（KAN）变体具有理论有效性，并在实践中表现出与主流神经网络相当的性能，为KANs提供了一种新的有效激活函数选择。

> **ai_Abstract:** 本研究提出一种新颖的柯尔莫哥洛夫-阿诺德网络（KAN）变体，其核心在于用具有可学习频率的加权正弦函数替代传统的样条基函数作为内外激活。该变体固定了正弦激活的相位，并提供了严格的理论有效性证明。通过数值实验，该正弦KAN在多变量函数逼近任务中表现出优于固定频率傅里叶变换的性能，并能达到与多层感知机（MLP）相当的水平，为KAN的设计提供了新的思路。

> **摘要翻译:** 柯尔莫哥洛夫-阿诺德表示定理指出，任何连续多变量函数都可以精确地表示为连续单变量函数的有限叠加。这种表示的后续简化涉及将这些函数表达为少量独特单调函数的参数化和。这些发展导致了具有S型激活的多层感知机网络通用逼近能力的证明，形成了大多数现代神经网络的替代理论方向。柯尔莫哥洛夫-阿诺德网络（KANs）最近被提议作为多层感知机的替代品。KANs的特点是将可学习的非线性激活直接应用于输入值，并将其建模为基样条函数的加权和。这种方法取代了传统感知机中使用的线性变换和S型后激活。后续工作探索了样条激活的替代方案。在这项工作中，我们提出了一种新颖的KAN变体，通过将柯尔莫哥洛夫-阿诺德表示中的内外函数替换为具有可学习频率的加权正弦函数。受Lorentz和Sprecher引入的简化启发，我们将正弦激活的相位固定为线性间隔的常数值，并提供了其理论有效性的证明。我们还进行了数值实验，以评估其在一系列多变量函数上的性能，并将其与固定频率傅里叶变换方法和多层感知机（MLPs）进行比较。我们表明，它优于固定频率傅里叶变换，并取得了与MLPs相当的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [294] [Bagged Regularized $k$-Distances for Anomaly Detection](https://arxiv.org/abs/2312.01046)
> *用于异常检测的袋装正则化k距离*

*Yuchao Cai, Hanfang Yang, Yuheng Ma, Hanyuan Hang* | **Category: stat.ML, cs.LG, math.ST, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 异常检测, 距离基方法, 袋装, 正则化k距离, 凸优化

**Comment:** 

> **TL;DR:** 本文提出了一种名为BRDAD的新型距离基算法，通过将无监督异常检测问题转化为凸优化问题，解决了现有距离基方法对最近邻数量选择敏感的问题，并提升了在大规模数据集上的效率和性能。

**AI_Comments:** 该论文的创新点在于将无监督异常检测问题转化为凸优化，并通过最小化替代风险来优化权重，从而有效解决了距离基方法对超参数选择的敏感性问题。此外，引入袋装技术不仅提高了算法在处理大规模数据集时的效率，还在实践中展现了性能优势。这项工作在理论和实践上都为异常检测领域提供了重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于距离的方法在无监督异常检测中表现出色，但它们严重受限于对最近邻数量选择的敏感性。

**Method:** 本文提出了一种名为袋装正则化k距离异常检测（BRDAD）的新型距离基算法。该算法将无监督异常检测问题转化为一个凸优化问题，通过最小化替代风险（即袋装加权k距离密度估计（BWDDE）的经验风险的有限样本界）来选择权重。此外，BRDAD算法还结合了袋装技术来解决处理大规模数据集时的效率问题。

**Result:** 在理论方面，该算法的AUC遗憾率收敛速度快，并且袋装技术显著降低了计算复杂度。在实践方面，数值实验表明该算法的参数选择与现有最先进的距离基方法相比不敏感，并且在真实世界数据集上，引入袋装技术后，其性能优于其他方法。

**Conclusion:** BRDAD算法通过将无监督异常检测转化为凸优化问题并引入袋装技术，成功解决了距离基方法中超参数选择的敏感性问题和大规模数据集的效率问题，并在理论和实践中都展现出优越的性能。

> **ai_Abstract:** 本文针对无监督异常检测中距离基方法对最近邻数量选择敏感的问题，提出了一种名为袋装正则化k距离异常检测（BRDAD）的新算法。BRDAD将异常检测转化为凸优化问题，通过最小化替代风险来选择权重，有效解决了超参数敏感性。同时，引入袋装技术提升了处理大规模数据集的效率。理论分析表明其AUC遗憾率收敛快且计算复杂度低，实际实验也验证了其参数不敏感性和在真实数据集上的优越性能。

> **摘要翻译:** 我们考虑无监督异常检测的范式，它涉及在没有标记样本的情况下识别数据集中的异常。尽管基于距离的方法在无监督异常检测中表现出色，但它们严重受限于对最近邻数量选择的敏感性。在本文中，我们提出了一种名为袋装正则化k距离异常检测（BRDAD）的新型距离基算法，将无监督异常检测问题转化为一个凸优化问题。我们的BRDAD算法通过最小化替代风险（即袋装加权k距离密度估计（BWDDE）的经验风险的有限样本界）来选择权重。这种方法使我们能够成功解决基于距离算法中超参数选择的敏感性挑战。此外，在处理大规模数据集时，我们的BRDAD算法中整合的袋装技术可以解决效率问题。在理论方面，我们建立了算法的AUC遗憾率的快速收敛速度，并证明了袋装技术显著降低了计算复杂度。在实践方面，我们进行了数值实验，以说明我们的算法与现有最先进的基于距离的方法相比，其参数选择不敏感。此外，与其它方法相比，我们的方法在真实世界数据集上，通过引入的袋装技术取得了卓越的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [301] [Large Deviations of Gaussian Neural Networks with ReLU activation](https://arxiv.org/abs/2405.16958)
> *高斯神经网络与ReLU激活函数的大偏差*

*Quirin Vogel* | **Category: stat.ML, cs.LG, math.PR, 60F10, 68T07** | **Updated: 2025-08-01**

**Keywords:** 大偏差, 高斯神经网络, ReLU激活函数, 深度学习, 速率函数

**Comment:** 13 pages, 2 figures, proof simplified

> **TL;DR:** 本文为具有高斯权重和至多线性增长激活函数（如ReLU）的深度神经网络证明了一个大偏差原理，概括了之前的工作。

**AI_Comments:** 本文的创新之处在于将大偏差原理推广到更具实际应用价值的ReLU等线性增长激活函数，这弥补了以往研究的局限性。对速率函数的简化和幂级数展开的提供，对于高斯神经网络的理论分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究主要考虑有界且连续的激活函数，但在实践中，ReLU等线性增长的激活函数更为常用。因此，需要将大偏差原理推广到这些更实际的激活函数。

**Method:** 通过证明一个大偏差原理，并简化了速率函数的先前表达式，为ReLU情况提供了幂级数展开。

**Result:** 证明了具有高斯权重和至多线性增长激活函数（如ReLU）的深度神经网络的大偏差原理。简化了速率函数的先前表达式，并为ReLU情况提供了幂级数展开。

**Conclusion:** 该研究成功地将大偏差原理推广到了实际中常用的线性增长激活函数（如ReLU），并简化了相关表达式，提供了新的分析工具。

> **ai_Abstract:** 本文为采用高斯权重和线性增长激活函数（如ReLU）的深度神经网络建立了大偏差原理。这项工作是对先前研究的推广，因为之前的研究仅限于有界连续激活函数，而ReLU在实际应用中更为普遍。此外，研究还简化了速率函数的现有表达式，并为ReLU情况提供了幂级数展开。

> **摘要翻译:** 我们证明了具有高斯权重和至多线性增长激活函数（如ReLU）的深度神经网络的大偏差原理。这概括了早期考虑有界连续激活函数的工作。在实践中，ReLU等线性增长激活函数最常用。我们还简化了之前关于速率函数的表达式，并提供了ReLU情况的幂级数展开。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [308] [Pure interaction effects unseen by Random Forests](https://arxiv.org/abs/2406.15500)
> *随机森林未发现的纯交互效应*

*Ricardo Blum, Munir Hiabu, Enno Mammen, Joseph Theo Meyer* | **Category: stat.ML, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 随机森林, 交互效应, CART准则, 分区方案, 模型拟合

**Comment:** arXiv admin note: substantial text overlap with arXiv:2309.01460

> **TL;DR:** 随机森林在捕获某些纯交互效应方面表现不佳，本文提出并验证了替代的分裂方案可以改进这一点。

**AI_Comments:** 本文挑战了随机森林在处理所有交互效应方面的普遍认知，特别是指出了其在纯交互效应上的盲点。通过提出并验证替代的分区方案，为改进随机森林的性能提供了一个创新方向，对于理解和优化集成学习模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随机森林被广泛声称能很好地捕获交互作用，但有简单例子表明它在存在某些纯交互作用时表现不佳，传统CART准则难以捕捉。

**Method:** 提出并使用简单的替代分区方案进行树生长过程，并在模拟研究中将这些变体与传统随机森林和极端随机树进行比较，最后应用于真实数据集。

**Result:** 提出的修改方案在纯交互作用发挥关键作用的场景中，增强了模型的拟合能力。

**Conclusion:** 替代的分区方案可以有效改进随机森林在捕获纯交互效应方面的不足，提高模型拟合能力。

> **ai_Abstract:** 本文研究了随机森林在捕获特定纯交互效应方面的局限性，指出传统CART准则的不足。作者提出并评估了替代的树分裂方案，通过模拟研究和真实数据集的应用，证明这些改进能显著提升模型在存在纯交互效应时的拟合能力。

> **摘要翻译:** 随机森林被广泛声称能很好地捕获交互作用。然而，一些简单的例子表明，在存在传统CART准则在树构建过程中难以捕获的某些纯交互作用时，它们的表现不佳。受此启发，本文认为在树生长过程中使用的简单替代分区方案可以增强这些交互作用的识别。在一项模拟研究中，这些变体与传统的随机森林和极端随机树进行了比较。结果验证了所考虑的修改在纯交互作用发挥关键作用的场景中增强了模型的拟合能力。最后，这些方法被应用于真实数据集。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [385] [Batched Nonparametric Bandits via k-Nearest Neighbor UCB](https://arxiv.org/abs/2505.10498)
> *基于k-最近邻UCB的批处理非参数多臂赌博机*

*Sakshi Arya* | **Category: stat.ML, cs.LG, math.ST, stat.ME, stat.TH, 68T05, 62L05, 62G08, 68Q32, F.2.2; I.2.6** | **Updated: 2025-08-01**

**Keywords:** 批处理非参数多臂赌博机, k-最近邻, UCB, 遗憾界, 上下文多臂赌博机

**Comment:** 

> **TL;DR:** 该论文提出了一种名为BaNk-UCB的非参数算法，结合k-最近邻回归和上置信界原理，用于解决批处理非参数上下文多臂赌博机问题，并在理论和实践中均表现出接近最优的性能。

**AI_Comments:** 该论文的创新之处在于提出了一种完全非参数的算法 BaNk-UCB，它通过结合 k-NN 回归和 UCB 原理，并利用局部几何来估计奖励，这与之前依赖参数或分箱的方法不同。其方法的简单性、对上下文维度的适应性以及在理论上提供的接近最优遗憾界保证，使其在在线反馈受限的实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在医学和市场营销等在线反馈受限的领域中，面临着序贯决策的约束，因此需要一种新的非参数方法来解决批处理上下文多臂赌博机问题。

**Method:** 该论文提出了一种名为 BaNk-UCB 的非参数算法。该方法结合了自适应 k-最近邻 (k-NN) 回归和上置信界 (UCB) 原理。BaNk-UCB 是完全非参数的，能适应上下文维度，并且易于实现。它通过利用局部几何来估计奖励，并自适应地平衡探索与利用，这与以往依赖参数或基于分箱的估计器的方法不同。

**Result:** 在标准的 Lipschitz 平滑性和边际假设下，该方法提供了接近最优的遗憾界保证，并且采用了一种理论上合理的批处理调度，平衡了批次间的遗憾并达到了最小最大最优率。在合成和真实世界数据集上的实证评估表明，BaNk-UCB 始终优于基于分箱的基线方法。

**Conclusion:** 该论文成功提出了一种新颖的非参数算法 BaNk-UCB，用于解决批处理非参数上下文多臂赌博机问题，该算法具有强大的理论保证和优越的实证性能，尤其适用于在线反馈受限的领域。

> **ai_Abstract:** 该论文提出了一种新颖的非参数算法 BaNk-UCB，用于解决批处理非参数上下文多臂赌博机问题，特别针对在线反馈受限的领域。BaNk-UCB 将自适应 k-NN 回归与 UCB 原理相结合，利用局部几何进行奖励估计，并自适应地平衡探索与利用。该算法在理论上提供了接近最优的遗憾界保证，并在实验中表现出优于现有基于分箱的基线方法的性能。

> **摘要翻译:** 我们研究了批处理非参数上下文多臂赌博机中的序贯决策，其中行动在一个有限的时间范围内进行，并被划分为少量批次。受医学和市场营销等领域中在线反馈受限的约束所驱动，我们提出了一种非参数算法，该算法将自适应 k-最近邻 (k-NN) 回归与上置信界 (UCB) 原理相结合。我们的方法 BaNk-UCB 是完全非参数的，能适应上下文维度，并且易于实现。与以往依赖参数或基于分箱的估计器的工作不同，BaNk-UCB 利用局部几何来估计奖励，并自适应地平衡探索与利用。我们在标准的 Lipschitz 平滑性和边际假设下，提供了接近最优的遗憾界保证，并使用了一种理论上合理的批处理调度，该调度平衡了批次间的遗憾并达到了最小最大最优率。在合成和真实世界数据集上的实证评估表明，BaNk-UCB 始终优于基于分箱的基线方法。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [708] [funOCLUST: Clustering Functional Data with Outliers](https://arxiv.org/abs/2508.00110)
> *funOCLUST：带有离群点的函数数据聚类*

*Katharine M. Clark, Paul D. McNicholas* | **Category: stat.ML, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 函数数据聚类, 离群点检测, OCLUST, 稳健聚类, 曲线聚类

**Comment:** 

> **TL;DR:** funOCLUST是一种将OCLUST算法扩展到函数数据领域的方法，用于稳健地聚类曲线并识别离群点。

**AI_Comments:** 该论文的创新之处在于将OCLUST算法扩展到函数数据领域，提供了一种针对无限维函数数据中离群点问题的稳健聚类解决方案，这对于实际应用中处理复杂函数数据集具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 函数数据由于其无限维性质和对离群点的潜在敏感性，在聚类时面临独特的挑战。

**Method:** 提出了OCLUST算法在函数环境下的扩展，利用OCLUST框架创建了一种稳健的方法来聚类曲线并修剪离群点。

**Result:** 该方法在模拟和真实世界函数数据集上进行了评估，在聚类和离群点识别方面表现出强大的性能。

**Conclusion:** funOCLUST算法成功地为函数数据提供了稳健的聚类和离群点识别能力。

> **ai_Abstract:** 本文提出了一种名为funOCLUST的新方法，它是OCLUST算法在函数数据领域的扩展，旨在解决函数数据聚类中因无限维性和离群点敏感性带来的挑战。该方法能够稳健地聚类曲线并有效识别离群点，并在模拟和真实数据集上展示了良好的性能。

> **摘要翻译:** 函数数据由于其无限维性质和对离群点的潜在敏感性，在聚类时面临独特的挑战。本文提出了OCLUST算法在函数环境下的扩展，以解决这些问题。该方法利用OCLUST框架，创建了一种稳健的方法来聚类曲线并修剪离群点。该方法在模拟和真实世界函数数据集上进行了评估，在聚类和离群点识别方面表现出强大的性能。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='cond-matdis-nn'></a>
## cond-mat.dis-nn 

### [25] [Lattice Protein Folding with Variational Annealing](https://arxiv.org/abs/2502.20632)
> *格点蛋白质折叠与变分退火*

*Shoummo Ahsan Khandoker, Estelle M. Inack, Mohamed Hibat-Allah* | **Category: cond-mat.dis-nn, cs.AI, cs.LG, q-bio.BM** | **Updated: 2025-07-30**

**Keywords:** 蛋白质折叠, 格点蛋白质, 变分退火, 循环神经网络, 组合优化

**Comment:** 

> **TL;DR:** 本文提出了一种结合扩张循环神经网络和退火过程的新型上界训练方案，用于解决格点蛋白质折叠中的组合优化问题，并成功预测了二维HP格点蛋白质的最低能量折叠。

**AI_Comments:** 本文的创新之处在于将扩张循环神经网络与退火过程相结合，并引入了独特的上界训练和掩蔽方案来解决格点蛋白质折叠这一经典的组合优化难题。其重要性体现在为蛋白质折叠这一计算生物学核心问题提供了新的机器学习解决方案，并展现了其在处理其他受限组合优化问题上的通用潜力。该方法能够有效预测最优折叠并避免无效采样，为未来的药物设计和生物工程应用奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 蛋白质折叠原理的理解是计算生物学的基石，对药物设计、生物工程和基本生物学过程的理解具有重要意义。然而，寻找最佳折叠是一个计算上具有挑战性的组合优化问题。

**Method:** 本文引入了一种新颖的上界训练方案，该方案采用掩蔽技术来识别二维疏水-极性（HP）格点蛋白质折叠中的最低能量折叠。通过利用结合了由类温度波动驱动的退火过程的扩张循环神经网络（RNN），该方法能准确预测基准系统中多达60个珠子的最佳折叠。该方法还能有效地阻止无效折叠被采样，同时不损害RNN的自回归采样特性。

**Result:** 该方法能够准确预测多达60个珠子的基准系统的最佳折叠，并有效阻止无效折叠被采样，同时不损害RNN的自回归采样特性。

**Conclusion:** 该方案可推广到三维空间，并可扩展到具有更大字母表的格点蛋白质模型。研究结果强调了先进机器学习技术在解决复杂蛋白质折叠问题和更广泛的受限组合优化挑战中的潜力。

> **ai_Abstract:** 本研究提出了一种解决格点蛋白质折叠问题的创新方法，该问题是一个复杂的组合优化挑战。通过引入一种结合扩张循环神经网络（RNN）和类温度退火过程的新型上界训练方案，该方法能够有效地识别二维HP格点蛋白质的最低能量折叠。该方案利用掩蔽技术防止无效折叠采样，同时保持RNN的自回归特性，并已成功应用于多达60个珠子的基准系统。研究结果突出了先进机器学习技术在解决蛋白质折叠及其他受限组合优化问题上的巨大潜力，并且该方案具有向三维和更大字母表模型推广的能力。

> **摘要翻译:** 理解蛋白质折叠原理是计算生物学的基石，对药物设计、生物工程以及理解基本生物学过程具有重要意义。格点蛋白质折叠模型提供了一个简化而强大的框架，用于研究蛋白质折叠的复杂性，从而能够在受约束条件下探索能量最优的折叠。然而，找到这些最优折叠是一个计算上具有挑战性的组合优化问题。在这项工作中，我们引入了一种新颖的上界训练方案，该方案采用掩蔽技术来识别二维疏水-极性（HP）格点蛋白质折叠中的最低能量折叠。通过利用结合了由类温度波动驱动的退火过程的扩张循环神经网络（RNN），我们的方法能够准确预测多达60个珠子的基准系统的最佳折叠。我们的方法还能有效地阻止无效折叠被采样，同时不损害RNN的自回归采样特性。该方案可推广到三维空间，并可扩展到具有更大字母表的格点蛋白质模型。我们的研究结果强调了先进机器学习技术在解决复杂蛋白质折叠问题和更广泛的受限组合优化挑战中的潜力。

</details>

[⬆️ 返回分类顶部](#cond-matdis-nn) | [⬆️ 返回总目录](#toc)

---

<a id='q-bioqm'></a>
## q-bio.QM 

### [27] [Numerical Uncertainty in Linear Registration: An Experimental Study](https://arxiv.org/abs/2508.00781)
> *线性配准中的数值不确定性：一项实验研究*

*Niusha Mirhakimi, Yohan Chatelain, Jean-Baptiste Poline, Tristan Glatard* | **Category: q-bio.QM, eess.IV** | **Updated: 2025-08-01**

**Keywords:** 线性配准, 数值不确定性, 蒙特卡洛算术, MRI预处理, 稳定性

**Comment:** 

> **TL;DR:** 该研究使用蒙特卡洛算术评估了MRI预处理中常用线性配准工具的数值不确定性，发现SPM稳定性最高，FSL和ANTs变异性更大，且健康人群的结果可推广到临床人群，数值不确定性可用于自动化质量控制。

**AI_Comments:** 这项研究通过实验方法系统地评估了MRI线性配准中数值不确定性这一被忽视的问题，其创新点在于首次使用蒙特卡洛算术对主流配准工具进行全面比较，并探讨了工具、相似性度量以及不同人群对稳定性的影响。其重要性在于为临床和研究实践中选择更稳定的配准工具提供了实证依据，并提出了利用不确定性度量进行自动化质量控制的新思路，这对于提高MRI数据分析的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管线性配准是MRI预处理流程中的关键步骤，但其数值不确定性尚未得到充分研究。

**Method:** 本研究使用蒙特卡洛算术（MCA）模拟，评估了主要软件包（SPM、FSL和ANTs）中最常用的线性配准工具。评估涵盖了多种图像相似性度量、两种脑模板以及健康对照组（n=50）和帕金森病患者组（n=50）的数据。

**Result:** 研究发现线性配准工具和相似性度量会影响数值稳定性。在评估的工具中，SPM在默认相似性度量下表现出最高的稳定性。FSL和ANTs表现出更大且相似的变异范围，其中ANTs对数值扰动特别敏感，偶尔会导致配准失败。此外，健康组和帕金森病组之间没有观察到显著差异。

**Conclusion:** 健康受试者获得的数值稳定性分析结果可能推广到临床人群。数值不确定性度量可以支持线性配准结果的自动化质量控制。本研究的实验结果表征了线性配准的数值稳定性，可作为未来不确定性分析的基础。

> **ai_Abstract:** 本研究通过蒙特卡洛算术（MCA）模拟，系统评估了MRI预处理中常用线性配准工具（SPM、FSL、ANTs）的数值不确定性。结果显示，SPM在稳定性方面表现最佳，而FSL和ANTs变异性较大，其中ANTs对数值扰动尤为敏感，可能导致配准失败。研究还发现健康对照组与帕金森病患者组的数值稳定性无显著差异，表明健康人群的研究结果可推广至临床。此外，数值不确定性度量可用于线性配准结果的自动化质量控制。本研究为未来不确定性分析提供了实验基础。

> **摘要翻译:** 尽管线性配准是MRI预处理流程中的关键步骤，但其数值不确定性尚未得到充分研究。本研究使用蒙特卡洛算术（MCA）模拟，评估了主要软件包（SPM、FSL和ANTs）中最常用的线性配准工具，涵盖了多种图像相似性度量、两种脑模板以及健康对照组（n=50）和帕金森病患者组（n=50）的数据。我们的研究结果强调了线性配准工具和相似性度量对数值稳定性的影响。在评估的工具中，SPM在默认相似性度量下表现出最高的稳定性。FSL和ANTs表现出更大且相似的变异范围，其中ANTs对数值扰动特别敏感，偶尔会导致配准失败。此外，健康组和帕金森病患者组之间没有观察到显著差异，这表明健康受试者获得的数值稳定性分析结果可能推广到临床人群。最后，我们还展示了数值不确定性度量如何支持线性配准结果的自动化质量控制（QC）。总的来说，我们的实验结果通过实验表征了线性配准的数值稳定性，并可作为未来不确定性分析的基础。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

### [350] [A Large Sensor Foundation Model Pretrained on Continuous Glucose Monitor Data for Diabetes Management](https://arxiv.org/abs/2412.09727)
> *糖尿病管理中基于连续血糖监测数据预训练的大型传感器基础模型*

*Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao* | **Category: q-bio.QM, cs.AI, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 连续血糖监测, 糖尿病管理, 大型传感器模型, 血糖预测, Transformer

**Comment:** 

> **TL;DR:** 提出CGM-LSM，一个基于Transformer解码器的大型传感器模型，用160万条CGM数据预训练，显著提升了血糖预测的准确性和泛化性。

**AI_Comments:** 本文的创新点在于将大型语言模型的自回归范式引入到连续血糖监测数据分析中，构建了一个大规模预训练的传感器基础模型。其重要性体现在解决了现有模型泛化能力差的痛点，通过在海量数据上预训练，实现了跨患者群体的零样本预测，显著提升了血糖预测的准确性和鲁棒性，为个性化和主动式糖尿病管理提供了有力工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有大多数糖尿病管理模型是任务专用的，缺乏跨患者群体的泛化能力，限制了AI在实时血糖预测中的应用。

**Method:** 引入了CGM-LSM，一个基于Transformer解码器的大型传感器模型（LSM）。该模型在来自不同糖尿病类型、年龄和性别的患者的160万条连续血糖监测（CGM）记录上进行了预训练。通过将患者建模为血糖时间步序列，以学习CGM数据中嵌入的潜在知识，并将其应用于2小时血糖读数预测。

**Result:** CGM-LSM显著提高了预测准确性和鲁棒性：在1小时预测中，均方根误差降低了48.51%；在未见过的患者群体中，展现出一致的零样本预测性能。

**Conclusion:** CGM-LSM通过大规模预训练和强大的泛化能力，为主动式糖尿病管理中的实时血糖预测提供了新的机会，并揭示了CGM基础模型发展中的关键机遇和挑战。

> **ai_Abstract:** 本文提出了CGM-LSM，一个基于Transformer解码器的大型传感器模型，利用160万条连续血糖监测(CGM)数据进行预训练，旨在解决现有模型泛化能力不足的问题。CGM-LSM通过将患者血糖数据建模为时间序列，显著提升了2小时血糖预测的准确性和鲁棒性，尤其在1小时预测中均方根误差降低了48.51%，并在未见患者群体中展现出零样本预测能力，为糖尿病管理提供了更有效、更通用的实时血糖预测工具。

> **摘要翻译:** 连续血糖监测（CGM）与人工智能相结合，通过实时血糖预测为主动式糖尿病管理提供了新机遇。然而，现有的大多数模型都是任务专用的，缺乏跨患者群体的泛化能力。受大型语言模型自回归范式的启发，我们引入了CGM-LSM，一个基于Transformer解码器的大型传感器模型（LSM），该模型在来自不同糖尿病类型、年龄和性别的患者的160万条CGM记录上进行了预训练。我们将患者建模为血糖时间步序列，以学习CGM数据中嵌入的潜在知识，并将其应用于2小时血糖读数预测。与现有方法相比，CGM-LSM显著提高了预测准确性和鲁棒性：在1小时预测中，均方根误差降低了48.51%，并在未见的患者群体中展现出一致的零样本预测性能。我们分析了模型在不同患者亚组和预测场景下的性能变化，并概述了推进CGM基础模型的关键机遇和挑战。

</details>

[⬆️ 返回分类顶部](#q-bioqm) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [61] [Block-corrected Modularity for Community Detection](https://arxiv.org/abs/2502.20083)
> *社区检测的块校正模块度*

*Hasti Narimanzadeh, Takayuki Hiraoka, Mikko Kivelä* | **Category: physics.soc-ph, cond-mat.stat-mech, cs.SI** | **Updated: 2025-08-01**

**Keywords:** 社区检测, 块校正模块度, 复杂网络, 未知属性, Louvain算法

**Comment:** 22 pages, 11 figures

> **TL;DR:** 提出了一种块校正模块度，用于在复杂网络中发现被已知属性掩盖的社区结构，并在合成和真实网络上验证了其有效性。

**AI_Comments:** 这篇论文的创新点在于提出了“块校正模块度”的概念，解决了在已知结构存在的情况下识别深层社区结构的问题。它提供了一种新的视角来处理复杂网络中的社区检测，特别是在存在混淆变量（即已知属性）时。其分析证明和在合成及真实世界网络上的验证增强了其重要性。该方法在处理由未知属性驱动的社区发现方面具有潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在复杂网络中，区分由未知节点属性引起的社区结构与由已知属性引起的社区结构非常重要。现有方法可能无法揭示被已知块结构掩盖的社区。

**Method:** 提出了一种“块校正模块度”（block-corrected modularity），通过折扣网络中已知的块结构来揭示被其掩盖的社区。为了最大化该模块度，开发了一种高效的谱方法以及两种受Louvain启发的微调算法。

**Result:** 分析性地证明了所提出的模块度在简单网络模型中能找到由未知属性驱动的社区结构。在多个简单合成网络模型上，块校正模块度能够找到底层社区结构，而使用不同空模型的现有方法则失败。还在多个合成网络模型上展示了所开发算法的性能。最后，在通过OpenAlex数据构建的真实世界引文网络上，通过校正时间引文模式，评估了该方法。

**Conclusion:** 提出的块校正模块度及其优化算法能够有效地识别复杂网络中被已知结构掩盖的社区，并在合成和真实世界网络上表现出优越性。

> **ai_Abstract:** 本文提出了一种“块校正模块度”方法，旨在复杂网络中识别被已知块结构掩盖的社区。该方法通过折扣已知结构来揭示由未知属性驱动的社区。研究分析性地证明了其有效性，并在合成网络上显示出优于现有方法的性能。为最大化该模块度，开发了高效的谱方法和两种Louvain启发式算法。最后，该方法在真实世界引文网络上得到了验证。

> **摘要翻译:** 复杂网络中未知的节点属性可能引入重要的社区结构，需要与已知属性驱动的社区结构区分开来。我们提出了一种块校正模块度，该模块度通过折扣网络中存在的给定块结构来揭示被其掩盖的社区。我们分析性地展示了所提出的模块度如何在简单的网络模型中找到由未知属性驱动的社区结构。此外，我们观察到块校正模块度在许多简单的合成网络模型上找到了底层的社区结构，而使用不同空模型的现有方法则失败了。我们开发了一种高效的谱方法以及两种受Louvain启发的微调算法来最大化所提出的模块度，并展示了它们在多个合成网络模型上的性能。最后，我们通过校正时间引文模式，使用OpenAlex数据构建的各种真实世界引文网络评估了我们的方法。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [101] [Improved Simulation of Asynchronous Entanglement Distribution in Noisy Quantum Networks](https://arxiv.org/abs/2507.22992)
> *噪声量子网络中异步纠缠分发改进的模拟*

*Emma Hughes, William Munizzi, Prineha Narang* | **Category: quant-ph, cs.IT, math.IT, physics.optics** | **Updated: 2025-07-30**

**Keywords:** 量子网络, 纠缠分发, 模拟, 并行协议, 哈希率

**Comment:** 26 pages, 2 figures, 1 computational package

> **TL;DR:** 本文提出了一个轻量级模拟框架，用于评估噪声量子网络中异步纠缠分发协议的性能。研究发现，并行协议在哈希率方面优于顺序协议，且运行时间更短，是实现量子互联网的有力候选。

**AI_Comments:** 该论文的创新之处在于提出了一个轻量级、可访问且可扩展的模拟框架，能够将复杂的量子过程模拟简化为简单的内存时间计算。这对于评估和开发异步纠缠分发策略具有重要意义，并为实现量子互联网提供了有价值的见解。

<details>
  <summary>Details</summary>

**Motivation:** 为了在实际误差模型下评估异步纠缠分发协议的性能，并提供一个轻量级、可访问且可扩展的模拟工具。

**Method:** 引入了一个轻量级模拟框架，专注于顺序和并行两种纠缠分发协议。通过比较分布式纠缠态的保真度和哈希率（一种纠缠效率的度量）来评估协议性能。这些指标在不同网络规模和噪声参数下进行比较，并将复杂的量子过程模拟简化为简单的内存时间计算。

**Result:** 并行协议始终优于顺序协议，特别是在哈希率指标上，因为它减少了运行时间。

**Conclusion:** 并行协议是实现可实现量子互联网的有力候选。

> **ai_Abstract:** 本文提出了一个轻量级模拟框架，用于在实际误差模型下评估噪声量子网络中的异步纠缠分发协议。该框架比较了顺序和并行两种协议的性能，使用纠缠态保真度和哈希率作为关键指标。研究结果表明，并行协议在哈希率方面表现出显著优势，且运行时间更短，使其成为未来量子互联网的有力候选。该模拟框架通过简化复杂的量子过程，提供了一个易于使用且可扩展的工具。

> **摘要翻译:** 这项工作引入了一个轻量级的模拟框架，用于在现实误差模型下评估异步纠缠分发协议。我们关注两种当前协议：顺序协议（纠缠一次在一个节点上建立）和并行协议（所有节点同时尝试生成纠缠）。我们使用两个关键指标来评估每种协议的性能：分布式纠缠态的保真度，以及哈希率（纠缠效率的度量）。这些指标在不同网络规模和噪声参数下对两种协议进行了比较。我们证明了并行协议始终优于顺序协议，特别是在哈希率指标上，因为它减少了运行时间，这表明并行协议是可实现量子互联网的有力候选。我们的框架通过将复杂量子过程的模拟简化为简单的内存时间计算，为评估纠缠分发策略提供了一个可访问且可扩展的工具。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [287] [Quantum Generative Modeling using Parameterized Quantum Circuits](https://arxiv.org/abs/2303.16955)
> *量子生成模型与参数化量子电路*

*Soumyadip Sarkar* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量子生成模型, 参数化量子电路, Born机器, KL散度, 量子机器学习

**Comment:** 

> **TL;DR:** 本文展示了使用参数化量子电路实现的3量子比特Born机器，成功模拟了3比特高斯分布，KL散度接近于零。

**AI_Comments:** 这篇论文通过一个具体的小规模实现，展示了量子生成模型在学习复杂概率分布方面的潜力。其创新点在于结合了参数化量子电路、KL散度损失和参数位移梯度优化，为量子机器学习的实际应用奠定了基础。虽然目前仅限于小规模验证，但其对收敛行为和可扩展性的讨论为未来的研究指明了方向，是量子机器学习领域的重要初步探索。

<details>
  <summary>Details</summary>

**Motivation:** 量子生成模型利用量子力学固有的概率特性来学习和重现复杂的概率分布。

**Method:** 本文实现了一个3量子比特的量子电路Born机器，使用Kullback-Leibler (KL) 散度损失和参数位移梯度优化方法，训练其模拟一个3比特高斯分布。变分量子电路由参数化旋转门和纠缠门层组成，通过优化使其Born规则输出分布与目标分布紧密匹配。论文还详细阐述了模型分布的数学公式、KL散度成本函数以及用于梯度评估的参数位移规则。

**Result:** 在状态向量模拟器上的训练结果显示，KL散度被最小化到接近于零，最终生成的分布与目标概率在定量上一致。研究还分析了收敛行为，并讨论了可扩展性和量子优势的含义。

**Conclusion:** 结果证明了小规模量子生成学习的可行性，并为量子电路模型的训练动态提供了见解。

> **ai_Abstract:** 本文提出并实现了一个基于参数化量子电路的3量子比特Born机器，旨在学习和重现复杂的概率分布。该模型利用KL散度作为损失函数，通过参数位移梯度优化进行训练，成功模拟了一个3比特高斯分布，达到了近乎零的KL散度，验证了小规模量子生成学习的可行性，并深入探讨了其训练动态。

> **摘要翻译:** 量子生成模型利用量子力学固有的概率特性来学习和重现复杂的概率分布。在本文中，我们展示了一个3量子比特量子电路Born机器的实现，该机器通过使用Kullback-Leibler (KL) 散度损失和参数位移梯度优化进行训练，以模拟3比特高斯分布。变分量子电路由参数化旋转门和纠缠门层组成，并进行优化，使得Born规则的输出分布与目标分布紧密匹配。我们详细阐述了模型分布的数学公式、KL散度成本函数以及用于梯度评估的参数位移规则。在状态向量模拟器上的训练结果表明，KL散度被最小化到接近于零，并且最终生成的分布与目标概率在定量上对齐。我们分析了收敛行为，并讨论了可扩展性和量子优势的含义。我们的结果证明了小规模量子生成学习的可行性，并为量子电路模型的训练动态提供了见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [321] [Polynomial time constructive decision algorithm for multivariable quantum signal processing](https://arxiv.org/abs/2410.02332)
> *多变量量子信号处理的“多项式时间”构造性判定算法*

*Yuki Ito, Hitomi Mori, Kazuki Sakamoto, Keisuke Fujii* | **Category: quant-ph, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 多变量量子信号处理, M-QSP, 判定算法, 多项式时间, Laurent多项式

**Comment:** 20 pages, 2 figures

> **TL;DR:** 本文提出了一种经典算法，用于判定给定的多变量Laurent多项式对是否可以通过多变量量子信号处理（M-QSP）实现。该算法在多项式时间内运行，并提供了构造性的参数选择方法。

**AI_Comments:** 这项工作解决了M-QSP领域的一个关键开放问题，即确定其可实现多项式的充分必要条件。提出的多项式时间算法不仅提供了理论上的判定，还具有构造性，能够帮助实际应用中参数的选择，这对于M-QSP的进一步发展和实际部署具有重要意义。其创新性在于将理论判定与实际构造相结合。

<details>
  <summary>Details</summary>

**Motivation:** 多变量量子信号处理（M-QSP）是一种有效的多变量多项式变换手段，但目前尚不清楚M-QSP可以构造哪些类型多项式的充分必要条件。

**Method:** 本文提出了一种经典的算法，用于判定给定的多变量Laurent多项式对是否可以通过M-QSP实现。该算法返回True或False。

**Result:** 该算法返回True是充分必要条件，并且在变量数和信号算子数上以多项式时间运行。此外，该算法还提供了一种选择实现M-QSP所需参数的构造性方法。

**Conclusion:** 这些发现为识别M-QSP的实际应用提供了宝贵的见解。

> **ai_Abstract:** 本文针对多变量量子信号处理（M-QSP）中，其可构造多项式的充分必要条件未知的问题，提出了一种多项式时间的经典判定算法。该算法能够判断一对多变量Laurent多项式是否可由M-QSP实现，并提供构造性参数选择方法。其“返回True”即为充分必要条件，且运行效率高，对M-QSP的实际应用具有重要指导意义。

> **摘要翻译:** 量子信号处理（QSP）和量子奇异值变换（QSVT）为理解许多量子算法（包括因式分解、矩阵求逆和哈密顿量模拟）提供了一个统一的框架。作为QSP的多变量版本，多变量量子信号处理（M-QSP）被提出。M-QSP将对应每个变量的信号算子与信号处理算子交织在一起，这为执行多变量多项式变换提供了一种有效的方法。然而，M-QSP可以构造哪些类型多项式的充分必要条件是未知的。在本文中，我们提出了一种经典算法，用于确定给定的一对多变量Laurent多项式是否可以通过M-QSP实现，该算法返回True或False。作为该算法最重要的特性之一，它返回True是充分必要条件。所提出的经典算法在变量数和信号算子数上以多项式时间运行。我们的算法还提供了一种选择实现M-QSP所需参数的构造性方法。这些发现为识别M-QSP的实际应用提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [392] [Quantum-Informed Machine Learning for Chaotic Systems](https://arxiv.org/abs/2507.19861)
> *量子信息机器学习用于混沌系统*

*Maida Wang, Xiao Xue, Peter V. Coveney* | **Category: quant-ph, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 量子机器学习, 混沌系统, 玻恩机, Koopman算子, 混合AI

**Comment:** 33 pages, 4 figures

> **TL;DR:** 本文提出了一种量子信息机器学习框架，利用量子电路玻恩机高效学习混沌系统的不变特性，显著减少数据存储，并将其整合到基于Koopman的经典模型中，从而在多个混沌系统上超越传统方法，为使用近期量子硬件学习动力学系统提供了实用途径。

**AI_Comments:** 该论文的创新之处在于其混合量子-经典方法，有效解决了量子机器学习（硬件噪声、可扩展性）和经典方法（不稳定性、数据存储）在处理混沌系统时的局限性。利用量子玻恩机进行高效的先验学习是其关键贡献，使得量子机器学习在复杂系统中的应用更具实用性。

<details>
  <summary>Details</summary>

**Motivation:** 由于长期预测的不稳定性以及难以准确捕获不变统计特性，学习混沌系统的行为仍然具有挑战性。尽管量子机器学习在捕获高维数据中的物理特性方面前景广阔，但其在实际部署中受限于当前的硬件噪声和可扩展性问题。

**Method:** 本文引入了一个量子信息机器学习框架，用于学习偏微分方程并应用于混沌系统。该框架使用量子电路玻恩机来学习混沌动力学系统的不变特性，通过紧凑的参数表示实现了显著的内存效率。然后，将这种统计量子信息先验整合到基于Koopman的自回归模型中，以解决梯度消失或爆炸等问题。该框架在Kuramoto-Sivashinsky方程、二维Kolmogorov流和湍流通道流三个代表性系统上进行了评估。

**Result:** 该方法将数据存储需求减少了两个数量级以上。所产生的模型在保持长期统计保真度的同时，解决了梯度问题。在所有测试系统中，该量子信息模型与没有量子先验的经典对应模型相比，均取得了卓越的性能。

**Conclusion:** 这种混合架构为使用近期量子硬件学习动力学系统提供了一条实用的途径。

> **ai_Abstract:** 本文提出了一种用于混沌系统的量子信息机器学习框架。它利用量子电路玻恩机高效学习不变统计特性，显著减少了数据存储需求。这种量子先验知识随后被整合到基于Koopman的经典模型中，以提高长期统计保真度并解决梯度问题。该混合模型在多个混沌系统上表现出优于经典方法的性能，为利用近期量子硬件学习动力学系统提供了一种实用的方法。

> **摘要翻译:** 由于长期预测的不稳定性以及难以准确捕获不变统计特性，学习混沌系统的行为仍然具有挑战性。虽然量子机器学习为有效捕获高维数据中的物理特性提供了一条有前景的途径，但其在实际部署中受到当前硬件噪声和有限可扩展性的阻碍。本文引入了一种量子信息机器学习框架，用于学习偏微分方程，并专注于混沌系统应用。该框架采用量子电路玻恩机来学习混沌动力学系统的不变特性，通过用一组紧凑的可训练电路参数表示这些复杂的物理统计数据，实现了显著的内存效率。与原始仿真数据相比，这种方法将数据存储需求减少了两个数量级以上。然后，将由此产生的统计量子信息先验知识整合到基于Koopman的自回归模型中，以解决梯度消失或爆炸等问题，同时保持长期统计保真度。该框架在三个代表性系统上进行了评估：Kuramoto-Sivashinsky方程、二维Kolmogorov流和湍流通道流。在所有情况下，与没有量子先验的经典对应模型相比，量子信息模型都取得了卓越的性能。这种混合架构为使用近期量子硬件学习动力学系统提供了一条实用的途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [599] [Amplitude amplification and estimation require inverses](https://arxiv.org/abs/2507.23787)
> *振幅放大和估计需要逆操作*

*Ewin Tang, John Wright* | **Category: quant-ph, cs.CC, cs.DS** | **Updated: 2025-07-31**

**Keywords:** 量子加速, 振幅放大, 逆操作, Grover加速, 压缩预言机方法

**Comment:** 20 pages

> **TL;DR:** 本文证明了量子算法中的振幅放大和估计等通用加速效果，只有在能高效执行逆操作时才成立，否则量子加速难以实现。

**AI_Comments:** 这篇论文揭示了量子算法中一个重要的限制条件，即逆操作的可实现性。它对量子计算的实际应用，尤其是在需要模拟物理系统演化的领域，提供了深刻的见解。其创新之处在于通过严格证明解释了长期存在的现象，并提出了“二分法”的概念。

<details>
  <summary>Details</summary>

**Motivation:** 解释为什么在量子学习、计量和传感等领域难以获得二次“Grover”加速，因为这些场景下实现逆操作（U†）非常困难，甚至等同于系统内的时间逆转。

**Method:** 通过Zhandry引入的“压缩预言机方法”（compressed oracle method）进行证明，并给出了基于迹估计的问题实例。

**Result:** 证明了通用的蛮力搜索和计数量子加速仅在所应用的过程可高效逆转时才成立。在无法高效实现逆操作的情况下，仅使用U的算法无法超越朴素的、二次慢速的方法。

**Conclusion:** 结果表明量子加速存在一个二分法：没有逆操作访问，量子加速稀缺；有逆操作访问，量子加速丰富。

> **ai_Abstract:** 本文证明了量子振幅放大和估计算法的通用加速效果依赖于可逆操作。通过使用压缩预言机方法，作者展示了在无法高效实现逆操作的情况下，量子算法无法超越传统方法。这一发现解释了为何在量子学习、计量和传感等领域难以实现二次Grover加速，因为这些场景下逆操作等同于系统中的时间逆转，难以实现。

> **摘要翻译:** 我们证明，用于蛮力搜索和计数的通用量子加速仅在所应用的过程能够被高效逆转时才成立。加速这些问题的算法，即振幅放大和振幅估计，假设能够应用状态准备幺正算子 U 及其逆 U†；我们给出了基于迹估计的问题实例，其中仅使用 U 的算法无法击败朴素的、二次慢速的方法。我们的证明很简单，并通过 Zhandry 引入的压缩预言机方法实现。由于这两种子程序是量子算法中二次“Grover”加速普遍存在的原因，我们的结果解释了为什么在量子学习、计量和传感等设置中，这种加速要难得多。在这些设置中，U 模拟实验系统的演化，因此实现 U† 可能要困难得多——等同于在系统内逆转时间。我们的结果提出了一种二分法：没有逆操作访问，量子加速稀缺；有逆操作访问，量子加速丰富。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [675] [Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning](https://arxiv.org/abs/2508.00024)
> *嵌入式量子-经典支持向量机实现可扩展量子机器学习*

*Sebastián Andrés Cajas Ordóñez, Luis Fernando Torres Torres, Mario Bifulco, Carlos Andrés Durán, Cristian Bosch, Ricardo Simón Carbajo* | **Category: quant-ph, cs.AI, cs.LG** | **Updated: 2025-07-28**

**Keywords:** 量子机器学习, 支持向量机, Vision Transformer, 量子核, 嵌入学习

**Comment:** 

> **TL;DR:** 提出一种结合ViT嵌入的量子-经典SVM管道，解决量子SVM的可扩展性问题，并发现ViT嵌入能带来量子优势。

**AI_Comments:** 这篇论文的创新点在于将现代神经网络架构（特别是Vision Transformer）的嵌入与量子机器学习相结合，解决了量子SVM的可扩展性难题。它首次系统性地证明了嵌入选择对量子核优势的关键影响，为未来的量子机器学习算法设计提供了重要指导，尤其是在利用现有先进深度学习模型进行特征工程方面。

<details>
  <summary>Details</summary>

**Motivation:** 量子支持向量机由于高维量子态和硬件限制面临可扩展性挑战。

**Method:** 提出一个嵌入感知型量子-经典管道，结合类别平衡的k-means蒸馏和预训练的Vision Transformer (ViT) 嵌入。使用16-qubit张量网络模拟。

**Result:** ViT嵌入独特地实现了量子优势，在Fashion-MNIST上比经典SVMs提高了8.02%的准确性，在MNIST上提高了4.42%。CNN特征表现出性能下降。首次系统性证明量子核优势关键取决于嵌入选择。

**Conclusion:** 量子核优势关键取决于嵌入选择，揭示了Transformer注意力与量子特征空间之间的基本协同作用，为可扩展量子机器学习提供了一条利用现代神经网络架构的实用途径。

> **ai_Abstract:** 本文提出了一种嵌入感知的量子-经典支持向量机（SVM）管道，旨在解决量子SVM的可扩展性问题。该方法结合了类别平衡的k-means蒸馏和预训练的Vision Transformer (ViT) 嵌入。研究发现，ViT嵌入能够带来显著的量子优势，在图像分类任务上优于经典SVM，而CNN特征则表现不佳。这首次证明了量子核优势对嵌入选择的依赖性，并揭示了Transformer注意力与量子特征空间之间的协同作用，为可扩展量子机器学习提供了新思路。

> **摘要翻译:** 量子支持向量机由于高维量子态和硬件限制面临可扩展性挑战。我们提出了一种嵌入感知型量子-经典管道，该管道结合了类别平衡的k-means蒸馏和预训练的Vision Transformer嵌入。我们的关键发现：ViT嵌入独特地实现了量子优势，在Fashion-MNIST上比经典SVMs提高了高达8.02%的准确性，在MNIST上提高了4.42%，而CNN特征则表现出性能下降。通过cuTensorNet进行16比特张量网络模拟，我们首次提供了系统性证据，表明量子核优势关键取决于嵌入选择，揭示了Transformer注意力与量子特征空间之间的基本协同作用。这为利用现代神经网络架构实现可扩展量子机器学习提供了一条实用途径。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [676] [Entanglement-induced provable and robust quantum learning advantages](https://arxiv.org/abs/2410.03094)
> *纠缠诱导的可证明且鲁棒的量子学习优势*

*Haimeng Zhao, Dong-Ling Deng* | **Category: quant-ph, cs.CC, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量子学习优势, 纠缠, 机器学习, 信息论, 噪声鲁棒性

**Comment:** 7 pages, 2 figures + 13-page supplementary materials

> **TL;DR:** 该研究通过信息论证明并实验验证了量子学习在表达能力、推理速度和训练效率方面相对于经典模型的优势，其核心在于纠缠可减少非局部任务所需的通信。

**AI_Comments:** 该论文的创新之处在于首次从信息论角度严格证明了量子学习优势的存在，并指出了纠缠是其核心驱动力。它不仅提供了理论上的突破，还通过实际实验验证了其鲁棒性，为量子机器学习的实际应用奠定了基础，尤其是在NISQ设备上的应用潜力巨大。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算在机器学习方面具有巨大潜力，但迄今为止尚未实现量子学习优势的证明。本研究旨在严格建立并展示这种优势。

**Method:** 通过信息论证明，设计了一个利用纠缠以恒定参数解决特定任务的量子模型，而经典模型需要线性扩展才能达到较高精度。并通过数值模拟和IonQ Aria上的俘获离子实验验证了所提出的优势。

**Result:** 严格建立了在表达能力、推理速度和训练效率方面，相对于常用经典模型的噪声鲁棒、无条件量子学习优势。证明了这种优势来源于纠缠可以减少非局部任务所需的通信。量子模型可以用恒定资源进行训练，并且对恒定噪声具有鲁棒性。数值和实验结果均证明了期望的优势。

**Conclusion:** 本研究的结果为利用当前噪声中等规模量子设备展示量子学习优势提供了宝贵的指导。

> **ai_Abstract:** 本研究首次严格证明了量子学习在表达能力、推理速度和训练效率方面对经典模型的优势，并阐明其核心在于纠缠能减少非局部任务的通信需求。通过信息论分析、数值模拟和俘获离子实验，验证了量子模型在恒定资源下可训练且对噪声鲁棒，为在当前量子设备上实现量子学习优势提供了方向。

> **摘要翻译:** 量子计算在增强机器学习方面具有无与伦比的潜力。然而，迄今为止尚未实现量子学习优势的展示。我们通过严格建立在表达能力、推理速度和训练效率方面相对于常用经典模型的噪声鲁棒、无条件量子学习优势，向前迈进了一步。我们的证明是信息论的，并指出了这种优势的起源：纠缠可以用于减少非局部任务所需的通信。特别是，我们设计了一个任务，量子模型可以使用恒定数量的参数和纠缠确定性地解决该任务，而常用经典模型必须线性扩展才能达到大于指数级小的精度。我们表明，量子模型可以用恒定资源进行训练，并且对恒定噪声具有鲁棒性。通过IonQ Aria上的数值和俘获离子实验，我们展示了期望的优势。我们的结果为利用当前噪声中等规模设备展示量子学习优势提供了宝贵的指导。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [683] [Hybrid Quantum Classical Surrogate for Real Time Inverse Finite Element Modeling in Digital Twins](https://arxiv.org/abs/2508.00029)
> *数字孪生中实时逆有限元建模的混合量子经典代理*

*Azadeh Alavi, Sanduni Jayasinghe, Mojtaba Mahmoodian, Sam Mazaheri, John Thangarajah, Sujeeva Setunge* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 混合量子经典, 逆有限元, 数字孪生, 结构健康监测, 量子机器学习

**Comment:** Submitted to Scientific Report

> **TL;DR:** 本文提出了一种混合量子经典多层感知器（QMLP）框架，用于解决数字孪生中实时逆有限元分析的高计算成本和复杂性问题，并在桥梁实验中表现出卓越的性能，为更高效的结构健康监测奠定了基础。

**AI_Comments:** 该论文提出了一种创新的混合量子经典方法（QMLP），将量子计算的潜力与经典神经网络相结合，以解决实时逆有限元分析中的计算瓶颈。其在结构健康监测领域的应用，特别是对大型土木结构的数字孪生体的支持，具有重要意义。通过在桥梁上的实验验证，展示了其相对于经典方法的显著性能提升，这表明了量子增强技术在工程领域实际应用中的巨大前景。其创新点在于将传感器数据巧妙地转换为适合量子处理的格式，并利用PQC进行特征变换，这为未来的混合算法设计提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型土木结构（如桥梁、管道和海上平台）对现代基础设施至关重要，其意外故障可能导致严重的经济和安全后果。虽然有限元（FE）建模广泛用于实时结构健康监测（SHM），但其高计算成本以及逆有限元分析（其中低维传感器数据必须映射到高维位移或应力场）的复杂性带来了持续的挑战。

**Method:** 本文提出了一种混合量子经典多层感知器（QMLP）框架。该方法使用对称正定（SPD）矩阵和多项式特征嵌入传感器数据，生成适合量子处理的表示。参数化量子电路（PQC）转换这些特征，并将所得的量子输出馈送到经典神经网络进行最终推理。通过融合量子能力与经典建模，QMLP 在保持计算可行性的同时处理大规模逆有限元映射。

**Result:** 通过在桥梁上的广泛实验，QMLP 实现了 0.0000000000316 的均方误差（MSE），大大优于纯经典基线。

**Conclusion:** 这些发现证实了量子增强方法在实时结构健康监测方面的潜力，为建立更高效、可扩展的数字孪生体铺平了道路，这些数字孪生体能够近乎实时地稳健监测和诊断结构完整性。

> **ai_Abstract:** 本文提出了一种混合量子经典多层感知器（QMLP）框架，旨在解决数字孪生中实时逆有限元建模的高计算成本和复杂性问题。该方法通过将传感器数据嵌入为适合量子处理的表示，利用参数化量子电路进行特征转换，并将结果输入经典神经网络进行最终推断。实验结果表明，QMLP 在桥梁结构健康监测中表现出色，均方误差远低于纯经典方法，验证了量子增强方法在构建高效、可扩展的数字孪生体方面的巨大潜力。

> **摘要翻译:** 大型土木结构，例如桥梁、管道和海上平台，对现代基础设施至关重要，意外故障可能导致严重的经济和安全影响。尽管有限元（FE）建模广泛用于实时结构健康监测（SHM），但其高计算成本以及逆有限元分析（其中低维传感器数据必须映射到高维位移或应力场）的复杂性带来了持续的挑战。本文提出了一种混合量子经典多层感知器（QMLP）框架来解决这些问题，并促进数字孪生在各种结构应用中的快速更新。
我们的方法使用对称正定（SPD）矩阵和多项式特征嵌入传感器数据，产生适合量子处理的表示。参数化量子电路（PQC）转换这些特征，所得的量子输出馈送到经典神经网络进行最终推理。通过融合量子能力与经典建模，QMLP 在保持计算可行性的同时处理大规模逆有限元映射。
通过在桥梁上的广泛实验，我们证明 QMLP 实现了 0.0000000000316 的均方误差（MSE），大大优于纯经典基线。这些发现证实了量子增强方法在实时结构健康监测方面的潜力，为建立更高效、可扩展的数字孪生体铺平了道路，这些数字孪生体能够近乎实时地稳健监测和诊断结构完整性。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [693] [Quantum Semi-Random Forests for Qubit-Efficient Recommender Systems](https://arxiv.org/abs/2508.00027)
> *用于量子比特高效推荐系统的量子半随机森林*

*Azadeh Alavi, Fatemeh Kouchmeshki, Abdolrahman Alavi, Yongli Ren, Jiayang Niu* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-30**

**Keywords:** 量子推荐系统, 量子半随机森林, 量子比特效率, QAOA, 混合机器学习

**Comment:** Submitted to IEEE Quantum AI Conference (QAI 2025), awaiting peer
  review

> **TL;DR:** 该研究提出了一种三阶段混合机器学习算法，利用仅五个量子比特的量子半随机森林，实现了与现有最先进方法相似的推荐系统性能，解决了当前量子推荐系统对大量量子比特的需求问题。

**AI_Comments:** 该论文的创新之处在于提出了一种量子比特高效的混合机器学习算法，显著降低了量子推荐系统所需的量子比特数量，使其更适用于当前的NISQ设备。通过结合经典特征压缩、量子优化和量子机器学习，该方法为在有限量子资源下构建实用量子应用提供了重要思路。

<details>
  <summary>Details</summary>

**Motivation:** 现代推荐系统为每个项目描述了数百个稀疏语义标签，但大多数量子管道仍为每个标签映射一个量子比特，这需要远超一百个量子比特，远远超出当前噪声中等规模量子（NISQ）设备的范围，并且容易产生深度、误差放大的电路。本研究旨在解决这一问题。

**Method:** 本研究提出了一种三阶段混合机器学习算法。该算法首先通过SVD草图和k-means学习一个1000原子字典（>97%方差），然后通过深度为3的QAOA解决一个2020 QUBO问题以选择5个原子，最后利用仅五个量子比特构建量子半随机森林（QsRF）来对推荐进行评分。

**Result:** 该方法在仅使用五个量子比特的情况下，性能与最先进的方法相似。在一个由这些代码训练的100棵树的QsRF在ICM-150/500上与全特征基线相匹配。

**Conclusion:** 该研究成功开发了一种量子比特高效的推荐系统，通过创新的三阶段混合算法，在有限的量子硬件资源下实现了与现有高性能系统相当的推荐效果。

> **ai_Abstract:** 本研究提出了一种新颖的三阶段混合机器学习算法，旨在解决当前量子推荐系统对大量量子比特的需求。该方法首先通过SVD草图和k-means进行特征压缩，然后利用QAOA在有限的量子比特预算下进行特征选择，最后使用一个仅需五个量子比特的量子半随机森林（QsRF）进行推荐评分。实验结果表明，该量子比特高效的推荐系统在性能上与现有最先进的全特征基线方法相当。

> **摘要翻译:** 现代推荐系统使用数百个稀疏语义标签描述每个项目，然而大多数量子管道仍然为每个标签映射一个量子比特，这需要远超一百个量子比特，远远超出当前噪声中等规模量子（NISQ）设备的范围，并且容易产生深度、误差放大的电路。我们通过一个三阶段混合机器学习算法弥补了这一差距，该算法压缩标签配置文件，通过QAOA在固定量子比特预算下优化特征选择，并使用仅由五个量子比特构建的量子半随机森林（QsRF）对推荐进行评分，同时其性能与最先进的方法相似。利用SVD草图和k-means，我们学习了一个1000原子字典（>97%方差），然后通过深度为3的QAOA解决一个2020 QUBO问题以选择5个原子。一个由这些代码训练的100棵树的QsRF在ICM-150/500上与全特征基线相匹配。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [696] [Dimension reduction with structure-aware quantum circuits for hybrid machine learning](https://arxiv.org/abs/2508.00048)
> *混合机器学习中基于结构感知的量子电路降维*

*Ammar Daskin* | **Category: quant-ph, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 量子电路, 降维, 混合机器学习, 施密特分解, 数据压缩

**Comment:** Any comments are welcome! The simulation code is provided at
  https://github.com/adaskin/structure-aware-circuits

> **TL;DR:** 本文提出了一种利用基于结构感知的量子电路进行数据降维的方法，并将其与经典神经网络结合构建混合机器学习模型，实现了数据压缩和有效的低秩近似。

**AI_Comments:** 这篇论文的创新点在于将量子电路应用于数据降维，特别是利用了施密特分解和张量网络分解的思想来构建“结构感知”的量子电路。其重要性在于通过量子计算的指数级压缩能力，为处理大规模数据集和训练大型机器学习模型提供了潜在的解决方案，有望显著减少计算资源和参数数量。这种混合模型的方法也为量子机器学习的实际应用开辟了新的路径。

<details>
  <summary>Details</summary>

**Motivation:** 传统的数据降维方法在处理大规模数据时可能面临挑战，而量子计算有望提供指数级的压缩能力，从而减少大规模模型训练中的可学习参数。

**Method:** 本文利用施密特分解（Schmidt decomposition）和奇异值分解（SVD）的思想对向量进行低秩近似。研究人员设计了基于训练样本均值向量的张量网络分解所确定的值$k$的量子电路，该电路能够近似整个数据集的简化形式表示。随后，将此量子电路与经典神经网络头部结合，构建了一个混合机器学习模型。该量子电路能够将$2^n$维向量压缩为$n$维概率向量，实现指数级压缩。

**Result:** 实验结果证实，所设计的量子电路能够成功压缩数据，并为经典处理组件提供有效的$k$秩近似。

**Conclusion:** 基于结构感知的量子电路能够实现高效的数据降维和压缩，为构建混合机器学习模型提供了新的途径，并有望减少大规模模型的训练参数。

> **ai_Abstract:** 本文提出了一种新颖的混合机器学习方法，利用基于结构感知的量子电路进行数据降维。该方法通过将向量的施密特分解思想应用于量子电路设计，实现了对数据集的低秩近似和指数级压缩。研究人员将此量子电路与经典神经网络结合，构建了一个混合模型，并在scikit-learn数据集上进行了验证。实验结果表明，该量子电路能够有效地压缩数据，并为后续的经典处理提供高质量的$k$秩近似，有望在大规模机器学习中减少模型参数。

> **摘要翻译:** 向量的施密特分解可以理解为向量形式的奇异值分解（SVD）。通过对所有子系统递归地应用施密特分解和SVD，一个向量可以被写成二维向量张量积的线性组合。给定一个表示为张量积线性组合的向量，仅使用$k$个主项可以得到该向量的$k$秩近似。因此，以这种简化形式表示向量可以保留向量最重要的部分，同时去除其中的微小噪声，类似于基于SVD的去噪。
在本文中，我们展示了基于值$k$（由训练样本均值向量的张量网络分解确定）设计的量子电路能够近似整个数据集的简化形式表示。然后，我们将这种电路假设与经典神经网络头部结合，构建了一个混合机器学习模型。由于量子电路对于$2^n$维向量的输出是一个$n$维概率向量，这提供了输入数据的指数级压缩，并可能减少训练大规模模型的可学习参数数量。我们使用Python scikit-learn模块中提供的数据集进行实验。结果证实，量子电路能够成功压缩数据，为经典处理组件提供有效的$k$秩近似。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [144] [Cyclotomy, cyclotomic cosets and arithmetic properties of some families in $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$](https://arxiv.org/abs/2507.23179)
> *循环论、循环陪集和 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质*

*Juncheng Zhou, Hongfeng Wu* | **Category: math.NT, cs.IT, math.IT** | **Updated: 2025-08-01**

**Keywords:** 分圆论, 算术性质, 循环陪集, 本原幂等元, 有限域环

**Comment:** 

> **TL;DR:** 本文通过使用2阶分圆类，研究了特定环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质，并得到了本原幂等元的显式表达式。

**AI_Comments:** 这篇论文在代数编码理论和数论交叉领域做出了贡献，通过对分圆类的深入分析，不仅揭示了特定环结构的算术性质，还提供了本原幂等元的具体形式，这对于构造新的编码方案或理解现有方案的代数结构具有潜在的重要性。推广先前结果也显示了其方法的普适性。

<details>
  <summary>Details</summary>

**Motivation:** 获得环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质。

**Method:** 使用关于 $n=p^sq^t$ 的2阶分圆类，并在特定条件下（$p\equiv3 \mathrm{mod} 4$, $\gcd(\phi(p^s),\phi(q^t))=2$, $l$ 是 $q^t$ 的原根, $\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$）。

**Result:** 获得了环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质；推广了参考文献[ref1]中的结果；获得了环中最小理想的本原幂等元的显式表达式。

**Conclusion:** 本文成功获得了环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质，推广了现有结果，并给出了最小理想的本原幂等元的显式表达式。

> **ai_Abstract:** 本文研究了在特定条件下环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质。通过利用2阶分圆类，该研究不仅获得了这些族的算术特性，还成功推广了现有成果，并给出了环中最小理想的本原幂等元的显式表达式。

> **摘要翻译:** 借助于关于 $n=p^sq^t$ 的2阶分圆类，其中 $p\equiv3 \mathrm{mod} 4$，$\gcd(\phi(p^s),\phi(q^t))=2$， $l$ 是 $q^t$ 的原根且 $\mathrm{ord}_{p^s}(l)=\phi(p^s)/2$，获得了环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中某些族的算术性质。这些分圆类的形式使我们能够进一步推广参考文献[ref1]中获得的结果。此外，还获得了环 $\frac{\mathbb{F}_l[x]}{\langle x^{p^sq^t}-1\rangle}$ 中最小理想的本原幂等元的显式表达式。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [153] [New Pilot-Study Design in Functional Data Analysis](https://arxiv.org/abs/2508.00176)
> *函数型数据分析中的新预研究设计*

*Ping-Han Huang, Ming-Hung Kao* | **Category: stat.ME, stat.AP** | **Updated: 2025-07-31**

**Keywords:** 函数型数据分析, 预研究设计, 数据收集, 轨迹恢复, 搜索算法

**Comment:** 

> **TL;DR:** 本文提出了一种新的预研究设计框架和搜索算法，旨在解决函数型数据分析中数据收集成本高、观测点稀疏的问题，并提高轨迹恢复的准确性和未来设计的有效性。

**AI_Comments:** 该论文的创新点在于首次将注意力集中在函数型数据分析中预研究本身的设计上，填补了现有研究的空白。通过提出一套新的框架和搜索算法，它为在资源有限条件下进行高效、准确的数据收集提供了实用且优越的解决方案，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 在应用研究中，频繁测量通常成本高昂、耗时或繁重，尤其是在函数型数据分析中，每个受试者由于实际限制只能在少数时间点被观测。现有设计方法多集中于为个体受试者选择最佳时间点，并依赖于预研究估算的参数，但预研究本身的设计却很少受到关注。

**Method:** 本文提出了一种构建预研究设计的新框架，旨在支持准确的轨迹恢复和未来设计的有效规划。为此，开发了一种搜索算法来生成高质量的预研究设计。

**Result:** 通过仿真研究和真实数据应用，结果表明所提出的方法优于常用的替代方案。

**Conclusion:** 本文提出的新预研究设计框架在资源受限的环境中具有重要价值，能够提高函数型数据分析中轨迹恢复的准确性并有效规划未来的设计。

> **ai_Abstract:** 针对函数型数据分析中数据收集成本高、观测点稀疏的问题，本文提出了一种新颖的预研究设计框架。该框架旨在提高轨迹恢复的准确性并有效规划未来的研究设计。通过开发一种搜索算法来生成高质量的预研究，并经仿真和实际数据验证，该方法显著优于现有替代方案，尤其适用于资源受限的环境。

> **摘要翻译:** 高效的数据收集在应用研究中至关重要，因为频繁测量可能成本高昂、耗时或繁重。在函数型数据设置中，由于实际限制，每个受试者只能在少数时间点被观测，这一挑战尤为突出。大多数现有设计方法侧重于为个体受试者选择最佳时间点，通常依赖于从预研究中估计的模型参数。然而，预研究本身的设计受到的关注有限。我们提出了一个构建预研究设计的框架，该框架支持准确的轨迹恢复和未来设计的有效规划。开发了一种搜索算法来生成此类高质量的预研究设计。仿真研究和真实数据应用表明，我们的方法优于常用的替代方案，突显了其在资源有限环境中的价值。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

### [293] [Bayesian CART models for aggregate claim modeling](https://arxiv.org/abs/2409.01908)
> *聚合索赔建模的贝叶斯CART模型*

*Yaojun Zhang, Lanpeng Ji, Georgios Aivaliotis, Charles C. Taylor* | **Category: stat.ME, cs.LG, q-fin.ST, stat.AP, stat.ML** | **Updated: 2025-08-01**

**Keywords:** 贝叶斯CART, 聚合索赔建模, 频率-严重性, 序列模型, 联合模型

**Comment:** 

> **TL;DR:** 本文提出了三种贝叶斯CART模型用于聚合索赔金额建模，并发现威布尔分布以及考虑索赔频率和严重性之间依赖关系的模型表现更优。

**AI_Comments:** 该论文引入了专门为聚合索赔建模量身定制的新型贝叶斯CART模型，解决了重尾数据以及频率与严重性之间依赖关系等挑战。研究发现威布尔分布更优以及纳入依赖关系能提高模型性能，为精算科学和风险管理提供了宝贵的见解。所提出的通用框架也暗示了其更广泛的适用性。

<details>
  <summary>Details</summary>

**Motivation:** 为了改进聚合索赔建模，本文提出了新的贝叶斯CART模型，旨在处理索赔数据的各种特征，特别是右偏和重尾的严重性数据以及索赔频率与严重性之间的依赖关系。

**Method:** 本文提出了三种贝叶斯CART（BCART）模型：频率-严重性模型、序列模型和联合模型，用于聚合索赔金额建模。研究提出了一个适用于多变量响应数据的BCART通用框架，尤其适用于具有双变量响应（索赔数量和聚合索赔金额）的联合BCART模型。研究通过使用各种分布，调查了用于右偏和重尾索赔严重性数据的BCART模型。模型的有效性通过精心设计的模拟和真实的保险数据进行了验证。

**Result:** 研究发现，对于索赔严重性数据建模，威布尔分布由于其在树模型中捕获不同尾部特征的能力，优于伽马分布和对数正态分布。此外，发现纳入索赔数量和平均严重性之间依赖关系的序列BCART模型和联合BCART模型是有益的，因此优于假设独立性的频率-严重性BCART模型。

**Conclusion:** 对于聚合索赔建模，考虑索赔频率和严重性之间依赖关系的序列和联合贝叶斯CART模型比传统的频率-严重性模型更有效且更受青睐，并且威布尔分布是严重性建模的良好选择。

> **ai_Abstract:** 本文提出了三种贝叶斯CART（BCART）模型——频率-严重性、序列和联合模型——用于聚合索赔金额建模，并为多变量响应提出了一个通用框架。文章特别研究了针对右偏和重尾索赔严重性数据的BCART模型，结果表明威布尔分布在捕获尾部特征方面优于伽马和对数正态分布。研究得出结论，纳入索赔数量和严重性之间依赖关系的序列和联合BCART模型比假设独立性的频率-严重性模型更有效且更受青睐，并通过模拟和真实保险数据进行了验证。

> **摘要翻译:** 本文提出了三种贝叶斯CART（或BCART）模型用于聚合索赔金额建模，即频率-严重性模型、序列模型和联合模型。我们为适用于多变量响应数据的BCART模型提出了一个通用框架，这对于具有双变量响应（索赔数量和聚合索赔金额）的联合BCART模型特别有用。为了促进频率-严重性建模，我们通过使用各种分布，研究了针对右偏和重尾索赔严重性数据的BCART模型。我们发现威布尔分布优于伽马分布和对数正态分布，因为它能够在树模型中捕获不同的尾部特征。此外，我们发现纳入索赔数量和平均严重性之间依赖关系的序列BCART模型和联合BCART模型是有益的，因此优于假设独立性的频率-严重性BCART模型。这些模型性能的有效性通过精心设计的模拟和真实的保险数据进行了说明。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='mathfa'></a>
## math.FA 

### [186] [The algebraic structure of hyperinterpolation class on the sphere](https://arxiv.org/abs/2404.00523)
> *球面上超插值类的代数结构*

*Congpei An, Jiashu Ran* | **Category: math.FA, cs.NA, math.NA, 41A10, 41A36, 47L20, 47L80** | **Updated: 2025-08-01**

**Keywords:** 超插值, 代数结构, 球面, 超半群, 超自伴算子

**Comment:** 16 pages, 1 figure

> **TL;DR:** 本文研究了单位球面上超插值类的代数性质，引入了超自伴算子、超投影算子和超半群，并分析了特定超插值算子的代数特性。

**AI_Comments:** 该论文通过探索超插值的代数结构，为理解这些算子超越其近似性质的范畴提供了理论基础。引入超自伴算子、超投影算子和超半群等概念，并将其应用于特定类型的超插值，是球面数值分析领域的重要贡献。其创新之处在于将抽象代数概念应用于具体的数值方法，这可能为分析和设计近似方案开辟新的途径。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究单位球面 $ \mathbb{S}^d $ 上超插值类 $ \mathbf{HC}(\mathbb{S}^d) $ 的代数性质，特别是那些具有有界 $ L_2 $ 算子范数的算子，并在此基础上发展超自伴算子、超投影算子和超半群的理论。

**Method:** 本文利用离散（半）内积框架，发展了超自伴算子、超投影算子和超半群的理论。研究分析了四种特定算子：滤波、Lasso、硬阈值和广义超插值，并通过证明其代数性质（如自伴性、可交换性、形成半群等）来达成研究目的。

**Result:** 研究结果表明，广义超插值算子是超自伴的，并与超插值算子可交换。硬阈值和经典超插值算子形成一个超半群，其中硬阈值超插值构成最小素超理想。此外，超插值算子作为超同态作用于超半群。

**Conclusion:** 本文成功建立了单位球面上超插值类的代数性质和相互关系，揭示了各种超插值算子的具体特性，包括它们在形成超半群和充当超同态方面的作用。

> **ai_Abstract:** 本文探讨了单位球面上超插值类的代数性质，并利用离散（半）内积框架发展了超自伴算子、超投影算子和超半群的理论。文章分析了滤波、Lasso、硬阈值和广义超插值四种算子，证明了广义超插值算子的超自伴性与可交换性。研究还指出，硬阈值和经典超插值算子构成一个超半群，其中硬阈值超插值是最小素超理想，且超插值算子在此超半群上表现为超同态。

> **摘要翻译:** 本文研究了单位球面 $ \mathbb{S}^d $ 上超插值类 $ \mathbf{HC}(\mathbb{S}^d) $ 的代数性质。我们关注源自经典超插值且具有有界 $ L_2 $ 算子范数的算子。通过利用离散（半）内积框架，我们发展了超自伴算子、超投影算子和超半群的理论。我们分析了四种特定算子：滤波、Lasso、硬阈值和广义超插值。我们证明了广义超插值算子是超自伴的，并与超插值算子可交换。此外，我们证明了硬阈值和经典超插值算子形成一个超半群，其中硬阈值超插值构成最小素超理想。最后，我们确定超插值算子作为超同态作用于超半群。

</details>

[⬆️ 返回分类顶部](#mathfa) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [221] [A potential theory on weighted graphs](https://arxiv.org/abs/2405.07961)
> *加权图上的势理论*

*Trent DeGiovanni, Fernando Guevara Vasquez* | **Category: math.PR, cs.NA, math.NA, 31C20, 65M80, 31B10** | **Updated: 2025-08-01**

**Keywords:** 加权图, 势理论, 离散算子, Calderón微积分, 隐藏策略

**Comment:** 30 pages, 7 figures

> **TL;DR:** 该论文提出了在加权图上经典势理论的离散模拟，包括定义了各种算子并将其应用于隐藏异常的策略。

**AI_Comments:** 这篇论文的创新之处在于成功地将经典的连续势理论推广到了离散的加权图上，这对于理解和解决离散系统中的势问题具有重要意义。特别是引入离散的Calderón微积分和展示其在隐藏策略中的应用，显示了该理论的实用价值和广阔前景。

<details>
  <summary>Details</summary>

**Motivation:** 旨在将经典的连续势理论及其相关概念和结果推广并应用于离散的加权图领域，以建立其在离散设置中的对应物。

**Method:** 通过将节点划分为外部、边界和内部节点，并对拉普拉斯算子进行适当分解，定义了迹算子、单层和双层势算子以及边界层算子的离散模拟。论文还引入了一种离散的Calderón微积分。

**Result:** 这些离散算子能够表示具有不同边界条件的外部或内部调和函数。该形式化方法将势理论中的一些著名结果（例如关于Neumann-Poincaré算子谱的结果）引入到加权图中。论文还通过加权图上的隐藏策略（允许从远离异常的电测量角度隐藏异常）说明了该形式化方法。

**Conclusion:** 论文成功地为加权图建立了势理论的离散模拟，并展示了其在将连续势理论结果推广到离散域以及在实际应用（如隐藏策略）中的潜力，为离散系统中的势理论研究提供了新的框架。

> **ai_Abstract:** 这篇论文在加权图上建立了经典势理论的离散对应。通过对节点进行分区和拉普拉斯算子分解，文章定义了多种离散算子（如迹算子、单双层势算子），这些算子能够表示离散调和函数。该形式化方法引入了离散Calderón微积分，并将连续势理论的著名结果推广到加权图，并以一个在电测量中隐藏异常的策略为例进行了应用演示。

> **摘要翻译:** 我们提出了加权图上经典势理论的模拟。通过将节点划分为外部、边界和内部节点，并对拉普拉斯算子进行适当分解，我们定义了迹算子、单层和双层势算子以及边界层算子的离散模拟。与连续域中一样，这些算子可以表示具有不同边界条件的外部或内部调和函数。我们引入的形式主义包括离散的Calderón微积分，并将势理论中的一些著名结果带到加权图上，例如关于Neumann-Poincaré算子谱的结果。我们用加权图上的隐藏策略说明了这种形式主义，该策略允许从远离异常的电测量角度隐藏异常。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='physicsflu-dyn'></a>
## physics.flu-dyn 

### [261] [Adaptive Mesh Refinement for Two-Phase Viscoelastic Fluid Mixture Models](https://arxiv.org/abs/2409.19974)
> *两相粘弹性流体混合物模型的自适应网格细化*

*Bindi M. Nagda, Aaron Barrett, Boyce E. Griffith, Aaron L. Fogelson, Jian Du* | **Category: physics.flu-dyn, cs.NA, math.NA, 76-10, 76T06, G.1.8; G.4** | **Updated: 2025-08-01**

**Keywords:** 自适应网格细化, 两相流, 粘弹性流体, 多重网格, 计算流体力学

**Comment:** 

> **TL;DR:** 开发了一种用于模拟两相粘弹性流体混合物的自适应网格细化（AMR）方法，该方法准确、鲁棒、高效，并能显著降低计算成本。

**AI_Comments:** 该论文的创新点在于将自适应网格细化技术与多重网格预处理相结合，解决了两相粘弹性流体混合物模型数值模拟中的挑战，尤其是在捕捉尖锐梯度和提高计算效率方面取得了显著进展。其提出的方法对于需要高精度和低计算成本的多相流模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多相流在工业、自然和生物医学系统中应用广泛，但其模型（特别是包含非线性和共不可压缩性条件）在数值上具有挑战性。需要开发AMR技术来准确捕捉高应力区域和大材料梯度，同时保持低计算成本。

**Method:** 提出了一种在自适应网格上模拟多相混合物的计算方法，并利用多重网格求解器对鞍点系统进行预处理。

**Result:** AMR离散化在$L^1$, $L^2$和$L^\infty$范数下渐近达到二阶精度。求解器能准确解析尖锐梯度。多重网格预处理策略使线性求解器迭代次数与网格间距无关。数值实验显示，AMR求解器比均匀网格提速高达十倍，并可能实现更大的提速。

**Conclusion:** 所开发的AMR求解器为两相粘弹性流体混合物模型提供了一种准确、鲁棒、高效的模拟方法，显著降低了计算成本。

> **ai_Abstract:** 本文针对两相粘弹性流体混合物模型在数值模拟中面临的挑战，提出了一种基于自适应网格细化（AMR）的计算方法。该方法结合多重网格求解器对鞍点系统进行预处理，实现了对高应力区域和材料梯度的准确捕捉，同时显著降低了计算成本。实验结果表明，该AMR离散化具有二阶精度，能有效解析尖锐梯度，且线性求解器迭代次数与网格无关，相比均匀网格可实现高达十倍的加速。

> **摘要翻译:** 多相流是一类重要的流体流动，其研究促进了工业、自然和生物医学系统中各种应用的发展。我们考虑了一个模型，该模型使用两相的连续体描述，其中每相使用单独的动量方程，并伴随速度场的共不可压缩性条件。由此产生的方程系统由于存在多个非线性项和共不可压缩性条件而带来数值挑战，由此产生的流体动力学促使开发一种自适应网格细化（AMR）技术，以准确捕捉高应力区域和大的材料梯度，同时保持较低的计算成本。我们提出了一种在自适应网格上模拟多相混合物的准确、鲁棒和高效的计算方法，并利用多重网格求解器对鞍点系统进行预处理。我们证明了AMR离散化在$L^1$，$L^2$和$L^\infty$范数下渐近达到二阶精度。该求解器可以准确地解析解中的尖锐梯度，并且，通过本文介绍的多重网格预处理策略，线性求解器迭代次数与网格间距无关。我们的AMR求解器提供了主要的成本节约优势，在本文提出的数值实验中，与均匀网格相比，速度提高了十倍，根据问题设置，可能实现更大的速度提升。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

### [319] [Hybrid High-Order formulations with turbulence modelling capabilities for incompressible flow problems](https://arxiv.org/abs/2505.22480)
> *具有湍流建模能力的不可压缩流问题混合高阶公式*

*Lorenzo Botti, Daniele Antonio Di Pietro, Francesco Carlo Massa* | **Category: physics.flu-dyn, cs.NA, math.NA** | **Updated: 2025-07-31**

**Keywords:** 混合高阶公式, 湍流建模, 不可压缩流, Navier-Stokes方程, ESDIRK方法

**Comment:** 

> **TL;DR:** 本文提出了一种用于不可压缩Navier-Stokes方程的混合高阶（HHO）公式，该公式非常适合湍流模拟，并具有压力鲁棒性、质量守恒、无粘性极限鲁棒性、高阶时间步进、内存占用减少等优点，并通过2D/3D算例和Taylor-Green涡流模拟进行了验证。

**AI_Comments:** 该论文提出的混合高阶（HHO）公式在计算流体力学领域具有显著创新性，特别是在湍流模拟方面。其亮点在于结合了多种先进特性，如压力鲁棒性、精确的质量守恒、高阶时间步进和内存优化，这些都对高保真模拟至关重要。通过静态凝聚减少内存占用和利用p多层策略提高求解器性能的设想，显示了其在计算效率上的潜力。这项工作对于开发更高效、更精确的湍流模拟工具具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在提出一种适用于湍流模拟的不可压缩Navier-Stokes方程的混合高阶（HHO）公式，以满足高精度计算的需求。

**Method:** 本文提出了一种混合高阶（HHO）的不可压缩Navier-Stokes方程公式。空间离散采用混合速度和压力空间，时间离散基于显式单对角隐式龙格-库塔（ESDIRK）方法。该公式具有压力鲁棒性、单元格内质量守恒至机器精度、无粘性极限鲁棒性、具有局部时间步长自适应的隐式高阶精确时间步进、通过速度和压力的静态凝聚减少内存占用，以及利用继承的p多层解策略提高迭代求解器性能的潜力。

**Result:** 该方案在实践中展示了其相关特性，通过执行具有挑战性的2D和3D测试案例，并考虑了雷诺数为1600的Taylor-Green涡流问题的模拟。

**Conclusion:** 本文提出的混合高阶（HHO）公式在模拟湍流时表现出优异的性能和吸引人的特性，包括高精度、鲁棒性和计算效率。

> **ai_Abstract:** 本文提出了一种用于不可压缩Navier-Stokes方程的混合高阶（HHO）公式，特别适用于湍流模拟。该方法采用混合速度-压力空间进行空间离散，并结合ESDIRK方法进行时间离散。该公式具有多项优点，包括压力鲁棒性、质量守恒、无粘性极限鲁棒性、高阶时间精度、内存效率以及迭代求解器性能提升的潜力。通过2D和3D测试案例以及Taylor-Green涡流模拟，验证了该方案的有效性。

> **摘要翻译:** 我们提出了一种不可压缩Navier-Stokes方程的混合高阶（HHO）公式，该公式非常适合用于湍流模拟。空间离散依赖于混合速度和压力空间，时间离散基于显式单对角隐式龙格-库塔（ESDIRK）方法。该公式具有一些吸引人的特性，在需要高保真计算时可以有效地利用，即：压力鲁棒性、高达机器精度的逐单元质量守恒、无粘性极限鲁棒性、具有局部时间步长自适应的隐式高阶精确时间步进、由于速度和压力的静态凝聚而减少内存占用，以及利用继承的p多层解策略提高迭代求解器性能的可能性。在实际演示了该方案的相关特性，并执行了具有挑战性的2D和3D测试案例后，我们考虑了雷诺数为1600的Taylor-Green涡流问题的模拟。

</details>

[⬆️ 返回分类顶部](#physicsflu-dyn) | [⬆️ 返回总目录](#toc)

---

<a id='statth'></a>
## stat.TH 

### [276] [Information geometry of Lévy processes and financial models](https://arxiv.org/abs/2507.23646)
> *Lévy过程的信息几何与金融模型*

*Jaehyung Choi* | **Category: stat.TH, cs.IT, math.DG, math.IT, math.PR, q-fin.MF** | **Updated: 2025-07-31**

**Keywords:** Lévy过程, 信息几何, α散度, Fisher信息矩阵, 金融模型

**Comment:** 21 pages

> **TL;DR:** 本文探讨了Lévy过程的信息几何，推导了α散度、Fisher信息矩阵和α连接，并将其应用于金融模型中的Lévy过程。

**AI_Comments:** 本文创新性地将信息几何理论应用于Lévy过程，并进一步探讨了其在金融建模中的潜在应用，为理解金融市场中的复杂随机过程提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 探索Lévy过程的信息几何结构及其在金融模型中的应用。

**Method:** 首先推导了两个Lévy过程之间的α散度，然后利用α散度计算了Fisher信息矩阵和α连接。最后，通过具体的金融Lévy过程（如缓变稳定过程、CGMY模型和方差伽马过程）来阐述其微分几何结构。

**Result:** 推导出了Lévy过程之间的α散度、Fisher信息矩阵和α连接，并展示了这些信息几何工具在金融模型相关Lévy过程中的应用。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文深入研究了Lévy过程的信息几何，从推导Lévy过程间的α散度开始，进而计算出Fisher信息矩阵和α连接。研究还探讨了这些信息几何工具的统计应用，并通过金融建模中常见的Lévy过程（如缓变稳定过程、CGMY模型和方差伽马过程）的微分几何结构进行了具体阐释。

> **摘要翻译:** 我们探索了Lévy过程的信息几何。作为起点，我们推导了两个Lévy过程之间的α散度。随后，从α散度计算出与Lévy过程几何相关的Fisher信息矩阵和α连接。此外，我们讨论了这种信息几何的统计应用。作为说明性例子，我们研究了与金融建模相关的各种Lévy过程的微分几何结构，包括缓变稳定过程、CGMY模型和方差伽马过程。

</details>

[⬆️ 返回分类顶部](#statth) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [284] [Nyström Type Exponential Integrators for Strongly Magnetized Charged Particle Dynamics](https://arxiv.org/abs/2505.00288)
> *强磁化带电粒子动力学的Nyström型指数积分器*

*Tri P. Nguyen, Ilon Joseph, Mayya Tokman* | **Category: physics.comp-ph, cs.NA, math.NA, physics.plasm-ph, 65L04, 78A35** | **Updated: 2025-08-01**

**Keywords:** Nyström型积分器, 指数积分器, 强磁化等离子体, 粒子推进, 数值刚性

**Comment:** 

> **TL;DR:** 本文针对强磁化等离子体中带电粒子动力学模拟的计算刚性问题，提出并验证了Nyström型指数积分器，数值实验表明其在计算效率上比标准指数方法有显著改进。

**AI_Comments:** 这篇论文的创新点在于将指数积分器的概念扩展到Nyström型，以更有效地处理强磁化等离子体中带电粒子运动的二阶微分方程，从而解决了传统方法在数值刚性问题上的效率瓶颈。其重要性在于为PIC模拟提供了更高效、更精确的数值工具，对计算等离子体物理领域具有积极影响。

<details>
  <summary>Details</summary>

**Motivation:** 等离子体物理模拟中，在强磁化环境下计算带电粒子动力学（粒子推进问题）是计算密集型任务，且由于时间尺度范围广导致数值模型非常僵硬，现有时间积分器效率有限，因此需要更高效的方法。

**Method:** 本文扩展了标准指数算法框架，导出了Nyström型指数方法，将牛顿运动方程作为二阶微分方程进行积分。具体导出了二阶和三阶的Nyström型方案，并将其应用于强磁化粒子推进问题。

**Result:** 数值实验表明，Nyström型指数积分器比标准指数方法在计算效率上提供了显著的改进。

**Conclusion:** Nyström型指数积分器是解决强磁化带电粒子动力学计算中数值刚性问题的一种更高效、更具潜力的数值方法。

> **ai_Abstract:** 本文针对强磁化等离子体中带电粒子动力学模拟的计算刚性问题，提出并发展了Nyström型指数积分器。通过将牛顿方程作为二阶微分方程积分，并推导了二阶和三阶的具体方案，数值实验证明这些新方法在计算效率上显著优于现有标准指数方法，为解决粒子推进问题提供了更高效的工具。

> **摘要翻译:** 计算电磁场中带电粒子的动力学（即粒子推进问题）是等离子体物理模拟中粒子网格（PIC）方法计算最密集的部分之一。当等离子体被强磁化时，这项任务尤其具有挑战性，因为在这种情况下，粒子运动包含从高度振荡的快速回旋运动到缓慢宏观行为的广泛时间尺度，导致所得数值模型非常僵硬。当前用于模拟粒子运动的最先进时间积分器在面对问题严重的数值刚性时存在局限性，因此人们对更高效的方法感兴趣。最近，指数积分器被提出作为这些模拟的一种有前景的新方法，并显示出比常用方案具有计算优势。指数方法可以精确求解线性问题并且是A稳定的。在本文中，标准指数算法框架被扩展，以导出Nyström型指数方法，该方法将牛顿运动方程作为二阶微分方程进行积分。具体导出了二阶和三阶的Nyström型方案，并将其应用于强磁化粒子推进问题。数值实验表明，Nyström型指数积分器比标准指数方法在计算效率上提供了显著改进。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [286] [Constrained Stochastic Recursive Momentum Successive Convex Approximation](https://arxiv.org/abs/2404.11790)
> *受约束的随机递归动量逐次凸近似*

*Basil M. Idrees, Lavish Arora, Ketan Rajawat* | **Category: math.OC, eess.SP** | **Updated: 2025-08-01**

**Keywords:** 随机优化, 非凸约束, 逐次凸近似, 递归动量, 随机一阶复杂度

**Comment:** 32 pages, 4 figures, journal submission

> **TL;DR:** 提出了一种新的递归动量加速逐次凸近似算法，用于解决带非凸约束的随机优化问题，实现了近乎最优的随机一阶复杂度。

**AI_Comments:** 这项工作通过引入递归动量和新的约束条件参数化，为解决具有非凸约束的随机优化问题提供了一个重要且高效的框架。其创新点在于将SCA与动量机制结合，并对理论收敛性进行了严格的分析，达到了与无约束问题最先进算法相当的复杂度，这对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决带有非凸函数约束的随机优化问题，这些问题常见于轨迹生成、稀疏近似和鲁棒分类等领域。

**Method:** 提出了一种递归动量加速的逐次凸近似（SCA）算法。该算法在每次迭代中构建随机目标函数和约束函数的凸替代，并求解由此产生的凸优化问题。采用递归更新规则来跟踪随机目标函数的梯度，从而减少方差并加速算法收敛。证明的关键在于Mangasarian-Fromowitz约束条件的一种新的参数化版本。

**Result:** 所提出的算法实现了近乎最优的随机一阶（SFO）复杂度，其自适应步长与最先进的无约束随机优化算法所达到的复杂度相匹配。在障碍物规避轨迹优化问题中，其性能优于现有算法；在二元分类问题中，其性能与专门的稀疏分类算法相当。

**Conclusion:** 该算法为解决带非凸函数约束的随机优化问题提供了一个高效且性能优越的解决方案，特别是在复杂度和实际应用方面表现出色。

> **ai_Abstract:** 本文提出了一种名为“受约束随机递归动量逐次凸近似”的新型算法，旨在解决具有非凸函数约束的随机优化问题。该算法通过构建凸替代并结合递归动量梯度跟踪来加速收敛和减少方差。理论上，它实现了近乎最优的随机一阶复杂度，并能获得收敛速率的问题相关界限。实验证明，该算法在轨迹优化和稀疏分类等实际问题中表现出优于或与现有先进算法相当的性能。

> **摘要翻译:** 我们考虑带有非凸函数约束的随机优化问题，例如轨迹生成、稀疏近似和鲁棒分类中出现的问题。为此，我们提出了一种基于递归动量的加速逐次凸近似（SCA）算法。在每次迭代中，所提出的算法需要构建随机目标函数和约束函数的凸替代，并求解由此产生的凸优化问题。采用递归更新规则来跟踪随机目标函数的梯度，这有助于减少方差，从而加速算法收敛。证明的一个关键要素是标准Mangasarian-Fromowitz约束条件的一个新的参数化版本，这使我们能够限制对偶变量，从而获得迭代逼近$\epsilon$-稳定点的速率的问题相关界限。值得注意的是，所提出的算法实现了近乎最优的随机一阶（SFO）复杂度，其自适应步长与解决无约束问题的最先进随机优化算法所达到的复杂度非常匹配。作为一个例子，我们详细介绍了一个可以使用所提出算法解决的避障轨迹优化问题，并表明其性能优于现有轨迹优化算法。所提出算法的性能还显示出与应用于二元分类问题的专门稀疏分类算法相当。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [322] [Probabilistic Iterative Hard Thresholding for Sparse Learning](https://arxiv.org/abs/2409.01413)
> *概率迭代硬阈值稀疏学习*

*Matteo Bergamaschi, Andrea Cristofari, Vyacheslav Kungurtsev, Francesco Rinaldi* | **Category: math.OC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 稀疏学习, 概率迭代硬阈值, L0范数, 基数约束, 收敛性

**Comment:** 

> **TL;DR:** 本文提出了一种解决带基数约束的期望目标优化问题的方法，证明了其收敛性，并在两个机器学习问题上验证了性能，以应对大数据背景下稀疏学习中现有方法收敛性不足的问题。

**AI_Comments:** 这篇论文的创新点在于提出了“概率迭代硬阈值”方法来解决L0范数优化在大数据背景下收敛性不足的问题。其重要性在于，在处理高维稀疏数据时，提供了一种理论上可收敛且在实践中有效的优化手段，填补了现有文献中的空白。论文通过理论证明和实验验证相结合，增强了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 在数据维度相对于样本量不利的统计建模中，发现隐藏的稀疏性对于构建准确的统计模型至关重要。尽管L0范数是强制稀疏性的有效机制，但在大数据环境下，需要评估梯度噪声估计时，现有文献中可靠收敛的方法很少。

**Method:** 本文提出了一种解决带基数约束的期望目标优化问题的方法。该方法基于概率迭代硬阈值（Probabilistic Iterative Hard Thresholding）的思想，并证明了其底层随机过程的收敛性。

**Result:** 作者证明了所提出的底层随机过程的收敛性，并在两个机器学习问题上展示了该方法的性能。

**Conclusion:** 该研究成功提出了一种在大数据环境下解决带基数约束的期望目标优化问题的可靠方法，并通过理论证明和实际应用验证了其有效性和收敛性，弥补了现有稀疏学习方法在收敛性方面的不足。

> **ai_Abstract:** 本文针对大数据环境下稀疏学习中现有方法收敛性不足的问题，提出了一种解决带基数约束的期望目标优化问题的新方法，该方法基于概率迭代硬阈值。研究证明了该方法底层随机过程的收敛性，并通过在两个机器学习问题上的应用，验证了其有效性和性能。这为在维度高、样本量相对较少的数据集中进行稀疏建模提供了可靠的解决方案。

> **摘要翻译:** 对于统计建模而言，当数据维度相对于样本量不利时，在真实数据中发现隐藏的稀疏性对于构建准确的统计模型至关重要。所谓的“l0范数”用于计算向量中非零分量的数量，当将其纳入优化问题以最小化给定模型与一组观测值的拟合度时，它是一种强大可靠的强制稀疏性机制。然而，在计算上必须评估梯度噪声估计的大数据环境中，可靠收敛的方法在文献中很少。在本文中，我们提出了一种解决带基数约束的期望目标优化问题的方法。我们证明了底层随机过程的收敛性，并在两个机器学习问题上展示了其性能。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [333] [Efficient Solving of Large Single Input Superstate Decomposable Markovian Decision Process](https://arxiv.org/abs/2508.00816)
> *大型单输入超态可分解马尔可夫决策过程的有效求解*

*Youssef Ait El Mahjoub, Jean-Michel Fourneau, Salma Alouah* | **Category: math.OC, cs.LG, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 马尔可夫决策过程, 策略评估, 结构分解, 单输入超态可分解MDP, 可扩展性

**Comment:** Preprint article submitted to ValueTools2025

> **TL;DR:** 本文提出了一种新的马尔可夫决策过程（MDP）结构——单输入超态可分解马尔可夫决策过程（SISDMDP），并开发了一种基于该结构的高效且精确的策略评估方法，适用于平均奖励和折扣奖励MDP。

**AI_Comments:** 本文的创新之处在于引入了SISDMDP这一新的MDP结构，并结合了现有的分解和循环特性，从而能够有效地处理大型状态空间。通过开发基于该结构的精确策略评估方法，为MDPs的求解提供了一个实用的、可扩展的方案，对于需要高效处理大型MDP的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 求解马尔可夫决策过程（MDPs）在序列决策中仍然是一个核心挑战，尤其是在处理大型状态空间和长期优化标准时。贝尔曼动态规划算法中的策略评估在无限 horizon 设置（如平均奖励或折扣奖励）中计算量巨大。

**Method:** 本文将聚合和分解技术扩展到一类结构化的MDPs。定义了单输入超态可分解马尔可夫决策过程（SISDMDP），它结合了Chiu的单输入分解和Robertazzi的单循环递归特性。当一个策略诱导这种结构时，结果转换图可以分解为具有集中递归的交互组件。开发了一种基于这种结构的精确且高效的策略评估方法。

**Result:** 该方法提供了一个可扩展的解决方案，适用于平均奖励和折扣奖励MDPs。

**Conclusion:** 通过引入SISDMDP结构和相应的策略评估方法，可以有效地求解大型马尔可夫决策过程，适用于多种奖励设置。

> **ai_Abstract:** 本文针对大型马尔可夫决策过程（MDPs）的求解挑战，提出了一种新的结构化MDP类别：单输入超态可分解马尔可夫决策过程（SISDMDP）。该结构结合了现有分解和循环特性，允许将策略诱导的转换图分解为具有集中递归的交互组件。基于此结构，作者开发了一种精确且高效的策略评估方法，该方法具有良好的可扩展性，并且适用于平均奖励和折扣奖励MDPs。

> **摘要翻译:** 求解马尔可夫决策过程（MDPs）在序列决策中仍然是一个核心挑战，尤其是在处理大型状态空间和长期优化标准时。贝尔曼动态规划算法中的一个关键步骤是策略评估，这在无限 horizon 设置（如平均奖励或折扣奖励）中变得计算量巨大。在马尔可夫链的背景下，聚合和分解技术长期以来一直被用来通过利用结构分解来降低复杂性。在这项工作中，我们将这些原则扩展到一类结构化的MDPs。我们定义了单输入超态可分解马尔可夫决策过程（SISDMDP），它结合了Chiu的单输入分解和Robertazzi的单循环递归特性。当一个策略诱导这种结构时，结果转换图可以分解为具有集中递归的交互组件。我们开发了一种基于这种结构的精确且高效的策略评估方法。这产生了一个可扩展的解决方案，适用于平均奖励和折扣奖励MDPs。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [703] [Riemannian Optimization for Distance Geometry: A Study of Convergence, Robustness, and Incoherence](https://arxiv.org/abs/2508.00091)
> *黎曼优化在距离几何中的应用：收敛性、鲁棒性和不协调性研究*

*Chandler Smith, HanQin Cai, Abiy Tasissa* | **Category: math.OC, cs.CG, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 黎曼优化, 距离几何, 矩阵补全, 收敛性, 不协调性

**Comment:** 54 pages, 6 figures

> **TL;DR:** 本文提出了一种用于欧几里得距离几何（EDG）问题的黎曼优化框架，通过将其公式化为正半定格拉姆矩阵空间上的低秩矩阵补全任务。该方法在理论上证明了收敛性和鲁棒性，并在合成数据上表现出有竞争力的性能。

**AI_Comments:** 本文的创新之处在于将欧几里得距离几何（EDG）问题巧妙地重新表述为正半定格拉姆矩阵流形上的黎曼优化问题，并将其与低秩矩阵补全相结合。其重要的贡献在于提供了严格的理论收敛性证明和鲁棒性分析，特别是在采样概率条件下的局部线性收敛性，以及引入了针对EDG的矩阵不协调性新概念。此外，对对称线性算子的分析以及Hanson-Wright不等式的新颖应用也体现了其深厚的理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 欧几里得距离几何（EDG）问题，即从部分成对距离中恢复点配置的问题，在传感器网络定位、分子构象和流形学习等广泛应用中出现，解决该问题具有重要意义。

**Method:** 本文提出了一种黎曼优化框架来解决EDG问题，将其表述为正半定格拉姆矩阵空间上的低秩矩阵补全任务。可用的距离测量值被编码为非正交基中的展开系数，通过对格拉姆矩阵的优化隐式地通过三角不等式强制执行几何一致性。技术贡献包括对非正交基中双基展开产生的对称线性算子的分析，以及Hanson-Wright不等式的新颖应用以建立受限等距性质。

**Result:** 在伯努利采样模型下，证明了秩-r矩阵流形上的黎曼梯度下降在采样概率满足特定条件时，以高概率局部线性收敛。提供了一种使用一步硬阈值过程的初始化方法，在满足特定采样概率时可实现收敛。在合成数据上的实证评估表明，该算法相对于最先进的方法具有竞争性能。此外，提出了针对EDG设置的矩阵不协调性的新概念，并为该方法提供了鲁棒性保证。

**Conclusion:** 本文成功地提出并分析了一种用于欧几里得距离几何问题的黎曼优化框架，通过将其转化为低秩矩阵补全任务，在理论上证明了其收敛性和鲁棒性，并通过实证验证了其竞争性能，并引入了针对EDG的矩阵不协调性新概念。

> **ai_Abstract:** 本文介绍了一种解决欧几里得距离几何（EDG）问题的黎曼优化框架。该方法将EDG建模为正半定格拉姆矩阵空间上的低秩矩阵补全任务，利用非正交基编码距离测量并隐式强制几何一致性。研究提供了黎曼梯度下降的局部线性收敛性理论证明，并提出了一种有效的初始化策略。此外，文章还引入了针对EDG的矩阵不协调性新概念，并提供了方法的鲁棒性保证。在合成数据上的实验结果表明，该算法具有与现有先进方法相当的性能。

> **摘要翻译:** 从部分成对距离中恢复点配置的问题，即欧几里得距离几何（EDG）问题，在包括传感器网络定位、分子构象和流形学习在内的广泛应用中出现。在本文中，我们提出了一种黎曼优化框架来解决EDG问题，通过将其表述为正半定格拉姆矩阵空间上的低秩矩阵补全任务。可用的距离测量值被编码为非正交基中的展开系数，通过对格拉姆矩阵的优化隐式地通过三角不等式强制执行几何一致性，这是经典多维尺度分析继承的结构。在观察到的距离的伯努利采样模型下，我们证明了秩-r矩阵流形上的黎曼梯度下降在高概率下局部线性收敛，当采样概率满足 $p \geq \mathcal{O}(\nu^2 r^2 \log(n)/n)$ 时，其中 $\nu$ 是一个EDG特有的不协调参数。此外，我们提供了一个使用一步硬阈值过程的初始化候选方案，在采样概率满足 $p \geq \mathcal{O}(\nu r^{3/2} \log^{3/4}(n)/n^{1/4})$ 的情况下可实现收敛。这项工作的一个关键技术贡献是对非正交基中双基展开产生的对称线性算子的分析，这需要新颖地应用Hanson-Wright不等式来在存在耦合项的情况下建立最优受限等距性质。在合成数据上的实证评估表明，我们的算法相对于最先进的方法取得了竞争性能。此外，我们提出了一个针对EDG设置的矩阵不协调性的新概念，并为我们的方法提供了鲁棒性保证。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [730] [System Identification from Partial Observations under Adversarial Attacks](https://arxiv.org/abs/2504.00244)
> *对抗性攻击下部分观测的系统辨识*

*Jihun Kim, Javad Lavaei* | **Category: math.OC, cs.SY, eess.SY, 93B15, 93B30, 93C05** | **Updated: 2025-08-01**

**Keywords:** 系统辨识, 部分观测, 对抗性攻击, $\\ell_1$-范数估计, 平衡截断

**Comment:** 8 pages, 3 figures

> **TL;DR:** 本文研究了在对抗性攻击下从输出测量中识别部分观测线性系统的问题，并首次提供了在任意攻击下具有部分观测系统的输入-输出分析。

**AI_Comments:** 这项工作首次在对抗性攻击下对部分观测系统进行了输入-输出分析，具有重要的理论和实际意义。其证明的误差指数衰减特性，为在不确定和恶意环境下进行系统辨识提供了新的视角和工具。

<details>
  <summary>Details</summary>

**Motivation:** 在对抗性攻击下，从输出测量中准确估计真实系统的平衡截断模型是一个具有挑战性的问题。

**Method:** 本文首先证明了对于任意类型攻击下的幂零系统，$\\ell_1$-范数估计器能够精确识别真实的马尔可夫参数矩阵。然后，将此结果扩展到一般系统，并证明估计误差随$k$的增长呈指数衰减。

**Result:** 在任意攻击下，$\ell_1$-范数估计器能够精确识别幂零系统的真实马尔可夫参数矩阵。对于一般系统，估计误差随$k$的增长呈指数衰减。估计的平衡截断模型在识别真实系统时，其误差也呈指数衰减。

**Conclusion:** 本文首次提供了在任意攻击下具有部分观测系统的输入-输出分析，并证明了在对抗性攻击下进行系统辨识的可行性和有效性。

> **ai_Abstract:** 本文研究了在对抗性攻击下，从部分观测数据中进行线性系统辨识的问题。研究表明，在攻击概率为$\Theta(1/k)$且攻击值任意的情况下，$\ell_1$-范数估计器能精确识别幂零系统的马尔可夫参数矩阵，并将此结果推广到一般系统，证明估计误差随系统阶数$k$的增加呈指数衰减。这是首次对在任意攻击下具有部分观测的系统进行输入-输出分析。

> **摘要翻译:** 本文关注部分观测线性系统辨识，目标是从输出测量中获得真实系统至$k$阶的平衡截断的合理准确估计。我们考虑了对抗性攻击下系统辨识的挑战性情况，其中每个时间发生攻击的概率为$\Theta(1/k)$，而攻击的值是任意的。我们首先表明，在任何类型的攻击下，$\ell_1$-范数估计器能够精确识别幂零系统的真实马尔可夫参数矩阵。然后，我们在此结果的基础上将其扩展到一般系统，并表明估计误差随$k$的增长呈指数衰减。因此，估计的平衡截断模型在识别真实系统时，其误差在相似变换下呈指数衰减。这项工作首次提供了在任意攻击下具有部分观测系统的输入-输出分析。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [766] [Neighbor-Sampling Based Momentum Stochastic Methods for Training Graph Neural Networks](https://arxiv.org/abs/2508.00267)
> *基于邻居采样的动量随机方法用于图神经网络训练*

*Molly Noel, Gabriel Mancino-Ball, Yangyang Xu* | **Category: math.OC, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 图神经网络, 邻居采样, Adam, 随机优化, 控制变量

**Comment:** 32 pages

> **TL;DR:** GCNs训练方法缺乏理论保证或实用元素。本文提出基于邻居采样的Adam型随机方法，利用控制变量技术，实现最优收敛率，在大规模图数据集上表现优异。

**AI_Comments:** 本文的创新点在于将Adam型优化器与邻居采样及控制变量技术相结合，为GCN训练提供了具有理论保证且在实践中表现优秀的解决方案。它解决了现有GCN训练方法在效率、理论严谨性及实用性上的不足，特别是在处理大规模图数据方面具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 图卷积网络（GCN）的高效训练方法存在缺乏理论保证或缺少现代深度学习算法中重要实用元素（如自适应性和动量）的问题。

**Method:** 提出几种基于邻居采样（NS）的Adam型随机方法来解决非凸GCN训练问题。利用控制变量技术减少邻居采样引起的随机误差。

**Result:** 在Adam型方法的标准假设下，所提方法具有最优收敛率。在节点分类任务的基准数据集上进行了广泛的数值实验，结果表明所提方法优于同样使用控制变量技术的经典基于NS的SGD，特别是在大规模图数据集上。

**Conclusion:** 所提出的基于邻居采样的Adam型随机方法在训练GCN时表现出优越的性能和理论保证，尤其适用于大规模图数据。

> **ai_Abstract:** 本文针对图卷积网络（GCN）训练中现有高效方法缺乏理论保证和实用特性（如自适应性、动量）的问题，提出了一系列基于邻居采样的Adam型随机优化方法。这些方法利用控制变量技术来降低采样误差，并在理论上证明了其最优收敛率。通过在节点分类任务上的实验，验证了所提方法在性能上优于传统的基于邻居采样的SGD方法，尤其在大规模图数据集上表现突出。

> **摘要翻译:** 图卷积网络（GCN）是图表示学习的强大工具。由于GCN采用递归邻域聚合，高效的训练方法存在缺乏理论保证或缺少现代深度学习算法中重要实用元素（如自适应性和动量）的问题。在本文中，我们提出了几种基于邻居采样（NS）的Adam型随机方法，用于解决非凸GCN训练问题。我们利用[1]中提出的控制变量技术来减少邻居采样引起的随机误差。在Adam型方法的标准假设下，我们证明了我们的方法享有最优收敛率。此外，我们在几个基准数据集上对节点分类任务进行了广泛的数值实验。结果表明，我们的方法优于同样使用控制变量技术的经典基于NS的SGD，特别是在大规模图数据集上。我们的代码可在https://github.com/RPI-OPT/CV-ADAM-GNN 获取。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='q-finrm'></a>
## q-fin.RM 

### [335] [Singular Control in a Cash Management Model with Ambiguity](https://arxiv.org/abs/2309.12014)
> *具有模糊性的现金管理模型中的奇异控制*

*Arnon Archankul, Giorgio Ferrari, Tobias Hellmann, Jacco J. J. Thijssen* | **Category: q-fin.RM, math.OC, q-fin.MF** | **Updated: 2025-08-01**

**Keywords:** 奇异控制, 现金管理, 模糊性, 最大最小偏好, Dynkin博弈

**Comment:** 

> **TL;DR:** 本文研究了在模糊性下现金储备管理的奇异控制模型，发现模糊性增加会导致更高的预期成本和更窄的无行动区域，这可以解释观察到的现金管理行为。

**AI_Comments:** 这篇论文通过引入模糊性（$\kappa$-无知下的最大最小偏好）到奇异控制的现金管理模型中，为理解管理者在不确定性下的决策提供了新的视角。其创新点在于结合了鲁棒控制理论和奇异控制，并利用Dynkin博弈分析了模糊性对最优策略和成本的影响。结果表明模糊性会促使更频繁的调整，这与实际观察到的行为相符，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在模糊性下，研究具有最大最小偏好的管理者如何进行现金储备管理，并确定最优策略和成本函数。

**Method:** 采用奇异控制模型，结合扩散过程和具有$\kappa$-无知特征的先验集上的最大最小偏好。建立了验证定理来确定成本函数和最优现金策略（控制障碍策略）。在算术布朗运动驱动的模型中，使用Dynkin博弈来分析模糊性增加的影响。

**Result:** 1. 建立了确定公司成本函数和最优现金策略（控制障碍策略）的验证定理。2. 在算术布朗运动驱动的模型中，模糊性增加会导致最坏情况先验下的预期成本更高。3. 模糊性增加会导致无行动区域变窄。

**Conclusion:** 模糊性是解释观察到的现金管理行为的一个重要因素，增加模糊性会促使管理者更频繁地调整现金储备。该研究结果可应用于模糊性下库存管理的奇异控制。

> **ai_Abstract:** 本文研究了在模糊性下，具有最大最小偏好的管理者如何进行现金储备管理的奇异控制模型。研究建立了确定公司成本函数和最优控制障碍策略的验证定理。通过算术布朗运动驱动的模型和Dynkin博弈，发现模糊性的增加会导致更高的预期成本和更窄的无行动区域，这为观察到的现金管理行为提供了新的解释，并具有更广泛的应用潜力。

> **摘要翻译:** 我们考虑一个现金储备管理的奇异控制模型，该模型由模糊性下的扩散过程驱动。假设管理者对由$\kappa$-无知表征的一组先验具有最大最小偏好。建立了验证定理以确定公司的成本函数和最优现金策略；后者采取控制障碍策略的形式。在由算术布朗运动驱动的模型中，我们使用Dynkin博弈表明，模糊性的增加会导致最坏情况先验下的预期成本更高，以及更窄的无行动区域。后一种效应可用于为观察到的现金管理行为提供模糊性驱动的解释。我们的研究结果可应用于模糊性下库存管理中奇异控制的更广泛应用。

</details>

[⬆️ 返回分类顶部](#q-finrm) | [⬆️ 返回总目录](#toc)

---

<a id='mathst'></a>
## math.ST 

### [356] [Conformal changepoint localization](https://arxiv.org/abs/2505.00292)
> *一致性变点定位*

*Sanjit Dandapanthula, Aaditya Ramdas* | **Category: math.ST, eess.SP, stat.ME, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 变点定位, 一致性推断, 置信区间, CONCH, p值

**Comment:** 

> **TL;DR:** 本文提出了CONCH算法，利用一致性p值矩阵为数据序列中的单个变点提供置信区间，并在多种合成和真实世界数据集上进行了验证。

**AI_Comments:** CONCH算法的创新之处在于其利用一致性p值矩阵为变点提供置信区间，而非简单的点估计，这增加了结果的可靠性。其广泛适用性，尤其是在处理不同类型数据和与黑盒分类器结合的能力，使其在实际应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 变点定位是估计有序数据列表中数据生成分布发生变化的索引，或声明未发生变化的关键问题。

**Method:** 本文提出了CONCH（CONformal CHangepoint localization）算法，该算法使用一致性p值矩阵，在预变和后变分布均可交换的温和假设下，为单个变点生成置信区间。

**Result:** CONCH算法在多种合成和真实世界数据集上进行了验证，包括使用黑盒预训练分类器检测图像、文本和加速度计数据序列中的变化。

**Conclusion:** CONCH算法能够有效地为数据序列中的变点提供置信区间，并在各种数据集和应用场景中展现出广泛的适用性。

> **ai_Abstract:** 本文介绍了CONCH算法，旨在于有序数据序列中进行变点定位。该算法利用一致性p值矩阵，在预变和后变分布可交换的温和假设下，为单个变点提供置信区间。CONCH算法在合成数据和真实世界的图像、文本、加速度计数据等多种数据集上得到了验证，并展示了其与黑盒预训练分类器结合检测序列变化的潜力。

> **摘要翻译:** 变点定位问题是估计有序数据列表中数据生成分布发生变化的索引，或声明未发生变化。我们提出了广泛适用的CONCH（一致性变点定位）算法，该算法利用一致性p值矩阵，在预变和后变分布均可交换的温和假设下，为（单个）变点生成置信区间。我们在各种合成和真实世界数据集上验证了CONCH算法，包括使用黑盒预训练分类器检测图像、文本和加速度计数据序列中的变化。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

### [871] [Constructive Disintegration and Conditional Modes](https://arxiv.org/abs/2508.00617)
> *构造性分解和条件众数*

*Nathaël Da Costa, Marvin Pförtner, Jon Cockayne* | **Category: math.ST, cs.LG, math.PR, stat.ML, stat.TH** | **Updated: 2025-08-01**

**Keywords:** 测度分解, 条件众数, 贝叶斯统计, 限制密度, 可微流形

**Comment:** 

> **TL;DR:** 本文提供了构建测度分解的数学工具，并揭示了限制密度与分解密度之间的差异。同时，研究了“条件众数”与条件测度众数不一致的问题，并讨论了这两种方法在实践中的应用。

**AI_Comments:** 该论文在贝叶斯统计的基础理论方面做出了重要贡献，澄清了测度分解和限制密度之间的关键区别，这对于理解近似贝叶斯推断和贝叶斯逆问题中的潜在混淆至关重要。其创新之处在于提供了构建分解的数学工具，并通过具体例子揭示了理论与“普遍结果”之间的差异。论文对“条件众数”的分析也具有实践指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 贝叶斯统计中的条件化操作，即测度分解，由于其定义的隐式性，构建起来通常很困难。机器学习中的一种普遍观点将分解的构建与概率密度函数在与给定观测一致的事件子集上的限制混淆。此外，该研究还受到近似贝叶斯推断和贝叶斯逆问题应用的启发。

**Method:** 本文提供了一套全面的数学工具，用于构建测度分解，并将其应用于在可微流形上寻找分解的密度。通过这些结果，作者研究了分解的众数，并分析了“条件众数”与通过分解获得的条件测度众数之间的关系。

**Result:** 研究发现，限制密度和分解密度可能存在巨大差异，并通过一个简单例子进行了说明。此外，结果表明，最近引入的“条件众数”概念通常不与通过分解获得的条件测度的众数一致，而是与限制测度的众数一致。

**Conclusion:** 限制密度和分解密度之间存在差异，并且“条件众数”与条件测度的众数不一致。根据建模上下文，限制方法和分解方法都有其效用。

> **ai_Abstract:** 本文探讨了贝叶斯统计中测度分解的构建及其与限制密度的关系。作者提出了一套构建分解的数学工具，并揭示了限制密度与分解密度之间的显著差异。此外，研究深入分析了“条件众数”的概念，指出其通常与通过分解获得的条件测度众数不符，而是与限制测度的众数相符。文章强调了根据具体建模上下文，两种方法均具有实用价值。

> **摘要翻译:** 条件化是贝叶斯统计中的核心操作，通过测度分解的概念形式化。然而，由于其定义的隐式性，构建分解通常很困难。机器学习中的一个普遍结果将分解的构建与概率密度函数限制在与给定观测一致的事件子集上混淆。我们提供了一套全面的数学工具，可用于构建分解，并将其应用于在可微流形上寻找分解的密度。利用我们的结果，我们提供了一个令人不安的简单例子，其中限制密度和分解密度存在巨大差异。受近似贝叶斯推断和贝叶斯逆问题应用的启发，我们进一步研究了分解的众数。我们表明，最近引入的“条件众数”概念通常不与通过分解获得的条件测度的众数一致，而是与限制测度的众数一致。我们还讨论了两种测度之间差异在实践中的含义，主张根据建模上下文，两种方法都有其效用。

</details>

[⬆️ 返回分类顶部](#mathst) | [⬆️ 返回总目录](#toc)

---

<a id='physicsplasm-ph'></a>
## physics.plasm-ph 

### [361] [Fast solvers for Tokamak fluid models with PETSC](https://arxiv.org/abs/2506.16676)
> *基于PETSC的托卡马克流体模型快速求解器*

*Mark F. Adams, Jin Chen, Benjamin Sturdevant* | **Category: physics.plasm-ph, cs.PF** | **Updated: 2025-08-01**

**Keywords:** 托卡马克, 磁流体动力学, PETSC, 多重网格, 快速求解器

**Comment:** 

> **TL;DR:** 本文开发了基于PETSC和半粗化多重网格的托卡马克MHD模型快速求解器，并在M3D-C1代码中应用，成功解决了环向坐标问题，并在SPARC4模型上展示了竞争性性能。

**AI_Comments:** 本文的创新点在于将半粗化多重网格方法集成到M3D-C1的PETSC块雅可比求解器中，以有效处理托卡马克MHD模型中的环向坐标问题。这种方法在实现较少代码改动的同时，提升了求解器的性能，对于加速托卡马克模拟具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为托卡马克磁流体动力学（MHD）模型开发快速、可扩展的求解器，以解决这些模型在隐式时间积分器中求解代数系统时遇到的计算挑战。

**Method:** 通过在现有PETSC块雅可比求解器中添加半粗化多重网格方法，解决了M3D-C1速度求解中的环向坐标问题，且仅增加了少量新代码。

**Result:** 新的求解器配置在SPARC4破裂的自洽逃逸电子模型上展示了具有竞争力的性能。

**Conclusion:** 新的求解器配置在特定托卡马克模型上表现良好，并概述了该求解器开发的后续步骤。

> **ai_Abstract:** 本文旨在为托卡马克磁流体动力学（MHD）模型开发快速、可扩展的求解器。针对M3D-C1代码中环向坐标的处理，作者在现有PETSC块雅可比求解器中引入了半粗化多重网格方法。实验结果表明，该新求解器配置在SPARC4破裂的自洽逃逸电子模型上展现出与现有方法相当的性能。文章还展望了未来求解器开发的进一步工作。

> **摘要翻译:** 这项工作开始开发使用多重网格方法，用于科学和工程相关托卡马克磁流体动力学（MHD）模型的快速、可扩展求解器。这些模型的特点是沿着环面磁场方向存在一个显著方向，该方向主导等离子体动力学。所有托卡马克模型都利用了这种结构，例如，NIMROD在极向平面中使用二维、非结构化、高阶有限元，并在环向坐标中使用傅里叶模式；三维扩展MHD代码M3D-C1在极向平面中使用二维、非结构化C1单元，并在环向方向使用三次Hermite函数和部分与磁场对齐的规则网格。这种结构表明应首先处理环向坐标，NIMROD在公式层面就做到了这一点，但M3D-C1使用完整的三维离散化。由此产生的代数系统在隐式时间积分器的每个时间步中求解。这项工作通过在现有PETSC（可移植、可扩展科学计算工具包）块雅可比求解器中添加半粗化多重网格，解决了M3D-C1速度求解中的环向坐标问题，只增加了少量新代码。这种新求解器配置的竞争性性能在SPARC4破裂的自洽逃逸电子模型上得到了验证，并概述了该求解器开发的后续步骤。

</details>

[⬆️ 返回分类顶部](#physicsplasm-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [378] [Nonlinear Computation with Linear Optics via Source-Position Encoding](https://arxiv.org/abs/2504.20401)
> *通过光源位置编码实现线性光学中的非线性计算*

*N. Richardson, C. Bosch, R. P. Adams* | **Category: physics.optics, cs.AR, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 光学计算, 非线性计算, 光源位置编码, 神经网络, 拓扑优化

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的方法，通过光源位置编码在完全线性介质中实现非线性计算，从而解决了光学神经网络中能量高效非线性实现的挑战，并在机器学习分类任务中取得了与标准人工神经网络相当的性能。

**AI_Comments:** 这项工作的创新之处在于，它通过巧妙地利用光源位置编码，在本质上是线性光学系统中实现了非线性计算，从而克服了光学神经网络发展中的一个关键瓶颈。这种方法在低功耗下运行，并且结合了先进的拓扑优化和机器学习技术来自动化硬件设计，这对于未来光学计算硬件的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 光学计算系统有望成为神经网络工作负载的替代硬件模型，但实现能量高效的光学非线性（神经网络的关键要求）是一个显著的缺失环节。

**Method:** 本文引入了一种新颖的方法，通过数据相关的空间位置驱动光学系统，在完全线性介质中实现非线性计算。利用这种位置编码，作者构建了一个基于拓扑优化的全自动化硬件设计框架，用于高度专业化的光学神经网络。

**Result:** 作者评估了他们的光学设计在机器学习分类任务上的性能，结果表明比线性方法有显著改进，并且与标准人工神经网络相比具有竞争力。

**Conclusion:** 本文展示了一种通过光源位置编码在完全线性光学介质中实现非线性计算的新方法，有效地解决了光学神经网络中的关键挑战，并实现了与传统电子神经网络相当的性能。

> **ai_Abstract:** 本文提出了一种通过光源位置编码在完全线性光学介质中实现非线性计算的新方法。该方法能以低功耗运行，通过数据相关的空间位置驱动光学系统，并结合拓扑优化，设计出专门的光学神经网络。实验表明，该方法在机器学习分类任务上显著优于线性方法，并能与标准人工神经网络达到竞争性性能，解决了光学计算中非线性实现的挑战。

> **摘要翻译:** 光学计算系统提供了一种替代的硬件模型，似乎与神经网络工作负载的需求相符。然而，在光学中实现能量高效的非线性——实现神经网络的关键要求——是一个明显的缺失环节。在这项工作中，我们引入了一种在新颖的方法，在完全线性介质中实现非线性计算。我们的方法可以在低功耗下运行，并且只需要能够以数据相关的空间位置驱动光学系统。利用这种位置编码，我们借鉴优化和机器学习的现代进展，为高度专业化的光学神经网络制定了一个全自动、基于拓扑优化的硬件设计框架。我们在机器学习分类任务上评估了我们的光学设计：展示了比线性方法显著的改进，并且与标准人工神经网络相比具有竞争力。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

### [789] [Complexity-energy trade-off in programmable unitary interferometers](https://arxiv.org/abs/2507.22972)
> *可编程幺正干涉仪中的复杂性-能量权衡*

*Nikita A. Nemkov, Stanislav S. Straupe* | **Category: physics.optics, cs.ET** | **Updated: 2025-07-30**

**Keywords:** 可编程干涉仪, 矩阵乘法, 复杂性-能量权衡, 集成光子学, 编程复杂性

**Comment:** 6 pages

> **TL;DR:** 可编程光干涉仪在实现矩阵乘法时，编程复杂性是固有的，而能实现高效编程的器件通常能量输出较低，这限制了其精度和能效。

**AI_Comments:** 这篇论文揭示了可编程光干涉仪在实现矩阵乘法时的一个基本权衡，即编程复杂性与能量效率之间的矛盾。指出这种复杂性是“固有”而非“偶然”的洞察，对于该领域的设计和优化具有重要指导意义，促使研究人员在设计此类器件时必须权衡其编程效率和性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的相干多端口干涉仪在集成光子学中实现矩阵乘法时，存在将矩阵元素映射到相移的复杂编程问题。

**Method:** 论文指出并论证了高编程复杂性是固有的，并进一步论证了高效编程算法的干涉仪通常会导致较低的有用输出能量。

**Result:** 结果表明，可编程光干涉仪的高编程复杂性是固有的；同时，能够实现高效编程算法的干涉仪通常会产生低得多的有用输出能量。

**Conclusion:** 可编程光干涉仪在实现矩阵乘法时，存在固有的编程复杂性，并且在复杂性与能量输出（进而影响精度和能效）之间存在权衡。

> **ai_Abstract:** 本文探讨了可编程幺正干涉仪在集成光子学中实现矩阵乘法时面临的挑战。研究指出，将所需矩阵变换映射到器件相移的高编程复杂性是固有的。此外，文章论证了那些能够实现高效编程算法的干涉仪，其有用输出能量通常会显著降低，这最终会限制其精度和能量效率。因此，在可编程光干涉仪中，存在着复杂性与能量输出之间的权衡。

> **摘要翻译:** 相干多端口干涉仪是集成光子学中实现矩阵乘法的一种有前景的方法。然而，大多数已知架构——例如MZI和分束器网格，以及更通用的干涉仪——都存在将所需变换的矩阵元素映射到设备中特定相移的复杂过程。我们指出，高编程复杂性是固有的，而不是偶然的。同时，我们认为，通常允许高效编程算法的干涉仪会产生低得多的有用输出能量，这最终限制了它们的精度和能量效率。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [399] [A General Framework for Estimating Preferences Using Response Time Data](https://arxiv.org/abs/2507.20403)
> *使用反应时间数据估计偏好的一般框架*

*Federico Echenique, Alireza Fallah, Michael I. Jordan* | **Category: econ.TH, cs.LG** | **Updated: 2025-07-31**

**Keywords:** 偏好估计, 反应时间, 漂移扩散模型, 预测准确性, 跨期选择

**Comment:** 

> **TL;DR:** 提出了一种利用选择和反应时间数据估计偏好参数的通用方法，该方法在应用于漂移扩散模型（DDM）时具有快速收敛速度，并在实证应用中显示其能提高预测准确性并对经济相关参数的估计很重要。

**AI_Comments:** 这项研究提出了一种通用的框架，利用反应时间数据来提高偏好参数估计的准确性，其对DDM的快速收敛性以及对其他模型的普适性是其创新点，对于行为经济学和决策科学领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 从选择和反应时间数据中恢复偏好参数。

**Method:** 提出了一种通用方法，该方法在应用于漂移扩散模型（DDM）时具有快速收敛速度（1/n），且可广泛应用于DDM的推广形式以及其他使用反应时间数据的决策模型。

**Result:** 在跨期选择实验的实证应用中，结果表明使用反应时间可以提高预测准确性，并且对经济相关参数的估计很重要。

**Conclusion:** 反应时间数据对于估计偏好参数具有重要价值，能够提高预测准确性并影响经济相关参数的估计。

> **ai_Abstract:** 本文提出了一种通用的方法论，用于从选择和反应时间数据中估计偏好参数。该方法在应用于漂移扩散模型（DDM）时表现出快速的收敛速度，并对DDM的推广形式及其他利用反应时间数据的决策模型具有普适性。通过在跨期选择实验中的实证应用，研究表明利用反应时间数据能够显著提高预测准确性，并且对经济相关参数的估计具有重要影响。

> **摘要翻译:** 我们提出了一种从选择和反应时间数据中恢复偏好参数的通用方法。当专门应用于流行的漂移扩散模型（DDM）时，我们的方法能以快速（对于n个数据点为1/n）的收敛速度生成估计值，但它们也广泛适用于DDM的推广形式以及其他利用反应时间数据的决策模型。本文开发了一个针对跨期选择实验的实证应用，表明使用反应时间能够提高预测准确性，并且对经济相关参数的估计至关重要。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [441] [A Lightweight Optimization Framework for Estimating 3D Brain Tumor Infiltration](https://arxiv.org/abs/2412.13811)
> *一种用于估计3D脑肿瘤浸润的轻量级优化框架*

*Jonas Weidner, Michal Balcerak, Ivan Ezhov, André Datchev, Laurin Lux, Lucas Zimmer, Daniel Rueckert, Björn Menze, Benedikt Wiestler* | **Category: physics.med-ph, cs.CV** | **Updated: 2025-07-31**

**Keywords:** 3D脑肿瘤浸润, 胶质母细胞瘤, 优化框架, 肿瘤生长建模, 放疗计划

**Comment:** 

> **TL;DR:** 本文提出一种轻量级优化框架，通过拟合MRI分割和施加平滑约束来估计3D脑肿瘤浸润，显著提高了肿瘤复发预测的准确性并大幅缩短了运行时间，使其更适用于临床。

**AI_Comments:** 本文提出了一种创新的轻量级优化框架，有效解决了胶质母细胞瘤浸润估计中的临床痛点。其核心创新在于提供了一个计算效率高且准确的肿瘤浸润模型，克服了以往方法计算量大的局限性。运行时间从30分钟大幅缩短至不到1分钟，极大地提高了其临床实用性，对于个体化放疗计划具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 胶质母细胞瘤的弥漫性微观浸润在标准MRI上难以检测，导致当前放疗计划采用统一的15毫米边缘，未能捕获患者特异性肿瘤扩散。现有的基于偏微分方程或物理信息神经网络的肿瘤生长模型计算成本高昂或约束过多，限制了其临床适应性。

**Method:** 本文提出一个轻量级、快速且鲁健的优化框架，通过将3D肿瘤浓度拟合到MRI肿瘤分割，同时强制实现平滑的浓度分布，来估计肿瘤浸润。

**Result:** 该方法在192名脑肿瘤患者的两个公共数据集上实现了卓越的肿瘤复发预测，优于现有基线方法，并将运行时间从30分钟缩短到不到1分钟。此外，该框架还展示了其集成额外成像模式或物理约束的通用性和适应性。

**Conclusion:** 本文提出的轻量级优化框架能有效估计3D脑肿瘤浸润，显著提高肿瘤复发预测的准确性，并大幅缩短计算时间，使其具有良好的临床适应性和多功能性。

> **ai_Abstract:** 本文提出了一种轻量级、快速且鲁棒的优化框架，旨在解决胶质母细胞瘤弥漫性微观浸润在标准MRI上难以检测以及现有肿瘤生长模型计算量大或约束过多的问题。该框架通过将3D肿瘤浓度拟合到MRI肿瘤分割并施加平滑浓度约束来估计肿瘤浸润。实验结果显示，该方法在192名患者的肿瘤复发预测上优于现有技术，并将运行时间从30分钟缩短至不到1分钟，同时展现出良好的通用性和适应性。

> **摘要翻译:** 胶质母细胞瘤是最具侵袭性的原发性脑肿瘤，由于其弥漫性微观浸润在标准MRI上仍 largely 未被检测到，因此带来了严重的临床挑战。结果，当前的放疗计划采用切除腔周围统一的15毫米边缘，未能捕获患者特异性肿瘤扩散。肿瘤生长建模提供了一种有前景的方法来揭示这种隐藏的浸润。然而，基于偏微分方程或物理信息神经网络的方法往往计算量大或约束过多，限制了它们对个体患者的临床适应性。在这项工作中，我们提出了一种轻量级、快速且鲁棒的优化框架，通过将其拟合到MRI肿瘤分割同时强制实现平滑的浓度分布，来估计3D肿瘤浓度。这种方法在两个公共数据集的192名脑肿瘤患者中实现了卓越的肿瘤复发预测，优于现有最先进的基线方法，同时将运行时间从30分钟缩短到不到1分钟。此外，我们通过展示该框架无缝集成额外成像模式或物理约束的能力，证明了其通用性和适应性。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [471] [Organic Electrochemical Neurons: Nonlinear Tools for Complex Dynamics](https://arxiv.org/abs/2508.00663)
> *有机电化学神经元：复杂动力学的非线性工具*

*Gonzalo Rivera-Sierra, Roberto Fenollosa, Juan Bisquert* | **Category: physics.chem-ph, cs.SY, eess.SY** | **Updated: 2025-08-01**

**Keywords:** 有机电化学神经元, 非线性动力学, 混合振荡器, 神经形态计算, 负微分电阻

**Comment:** 

> **TL;DR:** 本文提出了一个利用非线性动力学系统理论对放大器辅助有机电化学神经元进行建模和分析的框架。

**AI_Comments:** 这项工作创新性地将非线性动力学系统理论应用于有机电化学神经元的建模和分析，提供了一个比传统电路理论更深入的视角来理解复杂混合电路的振荡行为。其通用性使其在神经形态计算之外的多个领域具有潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 混合振荡器架构在人工神经元设计中显示出前景，但需要一个建模和分析框架来理解其复杂动力学。

**Method:** 通过将系统表述为描述膜电压和内部状态变量的耦合微分方程，利用零等倾线、相空间分析和分岔行为来识别自持振荡条件并表征动力学。

**Result:** 该模型揭示了振荡产生的核心机制，证明了动力学系统理论在理解和设计复杂混合电路中的效用。

**Conclusion:** 所提出的框架为开发可调谐的、受生物启发的振荡系统提供了一个可推广的基础，可应用于传感、信号处理和自适应控制等领域。

> **ai_Abstract:** 本文提出了一个基于非线性动力学系统理论的建模和分析框架，用于研究放大器辅助的有机电化学神经元。通过耦合微分方程描述系统，并运用零等倾线、相空间和分岔分析，揭示了自持振荡的条件及核心机制。该简化模型有助于分析集成经典反馈组件和负微分电阻器件的混合电路，为神经形态、生物电子及其他领域（如传感、信号处理和自适应控制）的生物启发式振荡系统设计提供了通用基础。

> **摘要翻译:** 结合反馈振荡器和自持负电阻振荡器的混合振荡器架构已成为人工神经元设计的一个有前景的平台。在这项工作中，我们引入了一个利用非线性动力学系统理论对放大器辅助有机电化学神经元进行建模和分析的框架。通过将系统表述为描述膜电压和内部状态变量的耦合微分方程，我们识别出自持振荡的条件，并通过零等倾线、相空间分析和分岔行为来表征所得动力学，为振荡器操作的标准电路理论论证提供了补充见解。我们简化但严谨的模型能够对集成经典反馈组件（例如运算放大器）与表现出负微分电阻的新型器件（例如有机电化学晶体管（OECT））的电路进行易于处理的分析。这种方法揭示了振荡产生的核心机制，证明了动力学系统理论在理解和设计复杂混合电路中的效用。除了神经形态和生物电子应用之外，所提出的框架为在传感、信号处理和自适应控制中开发可调谐的、受生物启发的振荡系统提供了一个可推广的基础。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [483] [chipfiring: A Python Package for Efficient Mathematical Analysis of Chip-Firing Games on Multigraphs](https://arxiv.org/abs/2508.00269)
> *chipfiring：一个用于多重图上筹码博弈高效数学分析的Python包*

*Dhyey Dharmendrakumar Mavani, Tairan Ji, Nathan Pflueger* | **Category: math.CO, cs.CG, cs.MS, math.AG** | **Updated: 2025-08-01**

**Keywords:** 筹码博弈, Python包, 图论, 组合学, 代数几何

**Comment:** 

> **TL;DR:** `chipfiring`是一个Python包，用于高效分析图上的筹码博弈，提供图定义、操作和属性分析工具。

**AI_Comments:** 该论文介绍了一个专门用于筹码博弈分析的Python包，其创新之处在于提供了针对该特定数学领域的优化算法和数据结构，弥补了通用图库的不足。这对于图论、组合学和代数几何领域的研究人员来说，是一个非常有价值的工具，能够提高研究效率。

<details>
  <summary>Details</summary>

**Motivation:** 旨在为图论、组合学和代数几何领域的研究人员和学生提供一个全面的Python包，用于对有限图上的筹码博弈进行数学分析，并解决现有通用图库的不足。

**Method:** 开发了一个名为`chipfiring`的Python包，其核心组件包括面向对象的图和除数实现、集成的拉普拉斯矩阵计算，以及Dhar算法的高效实现，用于确定美元博弈的可解性。

**Result:** 该包提供了一个强大的工具包，用于定义图和筹码配置、执行筹码博弈操作，并分析诸如可赢性、线性等价和除数秩等基本属性。它为探索丰富的数学模型提供了必要的算法和数据结构。

**Conclusion:** `chipfiring`包是一个专门为图论、组合学和代数几何领域的研究人员和学生设计的工具，通过提供高效的算法和数据结构，极大地便利了对筹码博弈的数学分析。

> **ai_Abstract:** `chipfiring`是一个用Python编写的综合性软件包，专门用于对有限图上的筹码博弈进行数学分析。它提供了一套完整的工具，包括图和筹码配置的定义、筹码博弈操作的执行，以及可赢性、线性等价和除数秩等关键属性的分析。该包集成了面向对象的实现、拉普拉斯矩阵计算和高效的Dhar算法，旨在为图论、组合学和代数几何领域的研究人员和学生提供探索复杂数学模型所需的必要算法和数据结构。

> **摘要翻译:** 本文介绍了一个名为`chipfiring`的综合性Python包，用于对有限图上的筹码博弈进行数学分析。该包提供了一个强大的工具包，用于定义图和筹码配置（除数），执行筹码博弈操作，并分析基本属性，如可赢性、线性等价和除数秩。我们详细介绍了该库的核心组件，包括其面向对象的图和除数实现、集成的拉普拉斯矩阵计算，以及Dhar算法的高效实现，用于确定美元博弈的可解性。`chipfiring`包专为图论、组合学和代数几何领域的研究人员和学生设计，为探索这些丰富的数学模型提供了必要的算法和数据结构。我们描述了该库的架构，通过全面的示例说明了其用法，并强调了其与通用图库相比的特殊贡献。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

### [642] [A note on the structure of locally finite planar quasi-transitive graphs](https://arxiv.org/abs/2412.20300)
> *关于局部有限平面拟传递图结构的一个注记*

*Ugo Giocanti* | **Category: math.CO, cs.DM, 05C10 (Primary), 05C63 (Secondary), 05C75 (Secondary), 68R10
  (Secondary), G.2.2** | **Updated: 2025-07-30**

**Keywords:** 局部有限图, 平面图, 拟传递图, 树分解, 结构定理

**Comment:** 16 pages, 4 figures

> **TL;DR:** 本文基于Hamann的工作，为3连通局部有限平面拟传递图提出了一个通用的结构定理，即它们都存在一个规范的树分解，并以此提供了一个Hamann等人最近结果的替代证明。

**AI_Comments:** 这篇论文延续了对无限平面图结构研究的传统，特别是在拟传递图的背景下。其创新之处在于将Droms的结构定理扩展到更广泛的拟传递图类别，并利用规范树分解为近期成果提供了新的图论证明。这表明树分解是分析此类图的强大工具，对理解其拓扑结构具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机源于Maschke在1896年对有限平面凯莱图的完整列表的建立，这开启了对平面无限凯莱图特征化的长期研究。Droms和Hamann的工作进一步推动了这一领域，激励了对更广泛的平面拟传递图进行结构特征化的需求。

**Method:** 本文基于Hamann (2018) 的工作，证明了3连通局部有限平面拟传递图的一个通用结构定理。该方法表明，每个此类图都存在一个规范的树分解，其边分离对应于图中（唯一）嵌入的循环分离，并且每个部分都允许无顶点累积嵌入。

**Result:** 主要结果是为3连通局部有限平面拟传递图提供了一个通用结构定理，表明它们都承认一个规范的树分解。作为一个推论，本文为Hamann, Lehner, Miraftab和Rührmann (2022) 的一个结果提供了另一种证明，即每个局部有限拟传递平面图都承认一个规范的树分解，其部分要么是1-端点图，要么是有限平面图。

**Conclusion:** 本文通过引入规范的树分解，为3连通局部有限平面拟传递图建立了一个结构性理解，这可以看作是Droms结构定理的一个版本，并为该领域最近的发现提供了替代证明。

> **ai_Abstract:** 本文基于Hamann (2018) 的工作，提出了一个关于3连通局部有限平面拟传递图的通用结构定理。该定理指出，这类图都存在一个规范的树分解，其边分离对应于图嵌入中的循环分离，且每个部分都可无顶点累积嵌入。这一结果被视为Droms关于拟传递平面图结构定理的一个版本。此外，作为推论，本文为Hamann, Lehner, Miraftab和Rührmann (2022) 关于局部有限拟传递平面图规范树分解的结论提供了一个替代证明。

> **摘要翻译:** 在1896年的一项早期工作中，Maschke建立了所有有限平面凯莱图的完整列表。这一结果在接下来的一个世纪中开启了漫长的研究线索，旨在以类似的方式刻画所有平面无限凯莱图。Droms (2006) 证明了有限生成平面群的结构定理，即那些承认平面凯莱图的有限生成群，该定理以Bass-Serre分解的形式给出。作为其结构定理的副产品，Droms证明了这类群是有限表示的。最近，Hamann (2018) 提供了一个图论证明，表明每个平面拟传递图G都承认一个生成Aut(G)不变的闭合路径集，该路径集只有有限多个轨道，并表明其结果是Droms结果的另一种证明。基于Hamann的工作，我们在这篇注记中表明，我们也可以为3连通局部有限平面拟传递图获得一个通用结构定理，即每个此类图都承认一个规范的树分解，其边分离对应于G（唯一）嵌入中的循环分离，并且每个部分都允许无顶点累积嵌入。这个结果可以看作是Droms关于拟传递平面图结构定理的一个版本。作为一个推论，我们获得了Hamann, Lehner, Miraftab和Rühmann (2022) 的一个结果的替代证明，即每个局部有限拟传递平面图都承认一个规范的树分解，其部分要么是1-端点图，要么是有限平面图。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='hep-ph'></a>
## hep-ph 

### [759] [Jet Image Generation in High Energy Physics Using Diffusion Models](https://arxiv.org/abs/2508.00250)
> *高能物理中基于扩散模型的喷注图像生成*

*Victor D. Martinez, Vidya Manian, Sudhir Malik* | **Category: hep-ph, cs.AI, cs.CV, cs.LG** | **Updated: 2025-08-01**

**Keywords:** 扩散模型, 喷注图像生成, 高能物理, 一致性模型, LHC

**Comment:** The paper is under review at IEEE Transactions in Nuclear Science

> **TL;DR:** 本文首次将扩散模型应用于高能物理喷注图像生成，发现一致性模型在图像保真度和生成稳定性上优于基于分数的扩散模型。

**AI_Comments:** 本文首次将扩散模型引入高能物理喷注图像生成，是一项重要的创新。其直接在图像空间操作的方法避免了潜在分布的复杂性。通过比较不同扩散模型，明确指出了一致性模型在性能上的优势，为该领域提供了更高效、更准确的生成工具，对高能物理研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在首次将扩散模型应用于高能物理中质子-质子碰撞事件的喷注图像生成。

**Method:** 将JetNet模拟数据集中的夸克、胶子、W玻色子、Z玻色子和顶夸克喷注的运动学变量映射为二维图像表示。在此图像上训练扩散模型以学习喷注成分的空间分布。研究比较了基于分数的扩散模型和一致性模型在准确生成类别条件喷注图像方面的性能，并强调其方法直接在图像空间中操作。

**Result:** 一致性模型在图像保真度和生成稳定性方面表现优于基于分数的扩散模型。通过Fréchet Inception Distance (FID)等多种指标评估了生成图像的保真度。

**Conclusion:** 这些进展显著提高了计算效率和生成准确性，为高能物理研究提供了有价值的工具。

> **ai_Abstract:** 本文首次在高能物理领域应用扩散模型生成LHC质子-质子碰撞事件的喷注图像。研究将JetNet数据集的喷注运动学变量转换为二维图像，并在此基础上训练扩散模型。通过比较基于分数的扩散模型和一致性模型，发现一致性模型在直接图像空间操作下，其生成的图像在保真度和稳定性方面表现更优，并显著提升了计算效率和生成准确性，为高能物理研究提供了新工具。

> **摘要翻译:** 本文首次将扩散模型应用于大型强子对撞机（LHC）质子-质子碰撞事件对应的喷注图像生成。将JetNet模拟数据集中的夸克、胶子、W玻色子、Z玻色子和顶夸克喷注的运动学变量映射为二维图像表示。在这些图像上训练扩散模型，以学习喷注成分的空间分布。我们比较了基于分数的扩散模型和一致性模型在准确生成类别条件喷注图像方面的性能。与基于潜在分布的方法不同，我们的方法直接在图像空间中操作。使用包括Fréchet Inception Distance (FID)在内的多种指标评估了生成图像的保真度，结果表明一致性模型比基于分数的扩散模型实现了更高的保真度和生成稳定性。这些进展显著提高了计算效率和生成准确性，为高能物理（HEP）研究提供了有价值的工具。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

### [882] [Anomaly detection with spiking neural networks for LHC physics](https://arxiv.org/abs/2508.00063)
> *基于脉冲神经网络的LHC物理异常检测*

*Barry M. Dillon, Jim Harkin, Aqib Javed* | **Category: hep-ph, cs.NE, hep-ex** | **Updated: 2025-07-31**

**Keywords:** 异常检测, 脉冲神经网络, LHC, 自编码器, 粒子物理

**Comment:** 24 pages, 15 figures, 1 table

> **TL;DR:** 本文研究了使用脉冲神经网络（SNN）构建的自编码器在大型强子对撞机（LHC）物理中进行异常检测，结果显示其性能与传统自编码器相当，且适用于低延迟、低内存的实时推理场景。

**AI_Comments:** 这篇论文的创新点在于将脉冲神经网络应用于LHC的异常检测任务，这对于需要极低延迟和计算资源的场景（如触发系统）具有重要意义。SNN在专用硬件上的潜力预示着未来在高性能物理实验中的广泛应用。

<details>
  <summary>Details</summary>

**Motivation:** 在大型强子对撞机（LHC）中发现新物理需要异常检测，尤其是在触发级别，以捕获传统选择标准可能丢弃的信号。这些系统必须在严格的延迟和计算约束下运行。

**Method:** 本文研究了使用神经形态脉冲神经网络（SNNs）构建的自编码器用于异常检测。利用CMS ADC2021数据集，设计并评估了一个简单的SNN自编码器架构。

**Result:** 结果表明，在所有信号模型中，SNN自编码器在LHC异常检测方面与传统自编码器具有竞争力。

**Conclusion:** SNN自编码器是一种有前景的LHC异常检测工具，其性能与传统方法相当，并且在低延迟、低内存的实时推理方面具有固有优势，尤其适用于FPGA和专用神经形态硬件。

> **ai_Abstract:** 本文探讨了利用脉冲神经网络（SNN）构建的自编码器在大型强子对撞机（LHC）物理中进行异常检测的应用。研究指出，SNN因其低延迟、低内存和实时推理的特性，特别适用于LHC触发层面的严格计算限制，能有效捕获传统方法遗漏的新物理信号。通过在CMS ADC2021数据集上评估一个简单的SNN自编码器架构，实验结果显示其性能与传统自编码器相当。

> **摘要翻译:** 异常检测为在大型强子对撞机（LHC）发现新物理提供了一种有前景的策略。本文为此目的研究了使用神经形态脉冲神经网络（SNNs）构建的自编码器。一个关键应用是在触发级别，异常检测工具可以在此处捕获否则会被传统选择标准丢弃的信号。这些系统必须在严格的延迟和计算约束下运行。SNNs本质上非常适合低延迟、低内存、实时推理，尤其是在现场可编程门阵列（FPGAs）上。随着专用神经形态硬件的快速发展，预计将获得进一步的收益。我们使用CMS ADC2021数据集，设计并评估了一个简单的SNN自编码器架构。我们的结果表明，在所有信号模型中，SNN自编码器在LHC异常检测方面与传统自编码器具有竞争力。

</details>

[⬆️ 返回分类顶部](#hep-ph) | [⬆️ 返回总目录](#toc)

---

<a id='astro-phim'></a>
## astro-ph.IM 

### [889] [Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation](https://arxiv.org/abs/2501.09112)
> *螳螂虾：探索计算机视觉网络中光度波段利用以进行光度红移估计*

*Andrew Engel, Nell Byler, Adam Tsou, Gautham Narayan, Emmanuel Bonilla, Ian Smith* | **Category: astro-ph.IM, cs.AI** | **Updated: 2025-07-31**

**Keywords:** 光度红移估计, 深度学习, 多波段融合, 计算机视觉, Mantis Shrimp

**Comment:** Accepted at ApJ

> **TL;DR:** Mantis Shrimp是一个多巡天深度学习模型，通过融合不同波段图像来估计星系光度红移，并发现早期融合与晚期融合性能相似，且模型能有效利用多波段信息。

**AI_Comments:** 这篇论文的创新点在于提出了一个多巡天深度学习模型Mantis Shrimp，用于解决光度红移估计中多波段图像融合的挑战。它不仅展示了图像模型在红移估计中的优势，还深入探讨了不同融合策略的有效性，并验证了模型对多波段信息的有效利用。尽管存在数据下载速度的实际限制，但其在小规模研究中的应用潜力仍值得关注，尤其是在天文数据处理和机器学习交叉领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于图像的卷积神经网络在光度红移估计中表现优异，但如何融合来自不同仪器（具有不同分辨率或噪声特性）的输入仍然是一个未解决的设计复杂性问题。

**Method:** 提出了Mantis Shrimp，一个多巡天深度学习模型，用于光度红移估计。该模型融合了紫外（GALEX）、光学（PanSTARRS）和红外（UnWISE）图像，并使用剪切图像估计红移的条件密度。研究了早期融合（重采样和堆叠图像）和晚期融合（连接潜在空间表示）方法。

**Result:** Mantis Shrimp模型的密度估计校准良好，点估计表现优秀，在光谱确认星系分布中偏差为1e-2，散度（NMAD）为2.44e-2，灾难性异常率（$\eta$）为17.53%。早期融合方法与晚期融合方法性能匹配。模型成功整合了所有巡天信息。

**Conclusion:** Mantis Shrimp模型在光度红移估计中表现良好，并能有效利用多波段信息。尽管其在大规模星系分析中的应用受限于数据下载速度，但对小规模研究（如生成恒星族群合成的红移先验）仍有价值。

> **ai_Abstract:** 本文提出了Mantis Shrimp，一个多巡天深度学习模型，用于融合紫外、光学和红外图像进行光度红移估计。该模型解决了多仪器图像融合的复杂性问题，其红移估计表现出良好的校准和性能。研究发现早期和晚期融合策略在性能上相似，且模型能有效利用多波段信息。尽管模型在大规模应用上存在数据下载速度的限制，但对小规模研究仍具价值。

> **摘要翻译:** 我们提出了Mantis Shrimp，一个用于光度红移估计的多巡天深度学习模型，它融合了紫外（GALEX）、光学（PanSTARRS）和红外（UnWISE）图像。机器学习现在已成为光度红移估计的一种成熟方法，在光谱识别星系密度高的区域，其性能普遍优于基于模板的方法。多项工作表明，基于图像的卷积神经网络可以优于基于表格的颜色/星等模型。与表格模型相比，图像模型具有额外的设计复杂性：如何融合来自不同仪器（具有不同分辨率或噪声特性）的输入在很大程度上是未知的。Mantis Shrimp模型使用剪切图像估计红移的条件密度。密度估计校准良好，点估计在可用光谱确认星系分布中表现良好，偏差为1e-2，散度（NMAD）为2.44e-2，灾难性异常率（$\eta$）为17.53%。我们发现早期融合方法（例如，重采样和堆叠来自不同仪器的图像）与晚期融合方法（例如，连接潜在空间表示）的性能匹配，因此设计选择最终取决于用户。最后，我们研究了模型如何学习利用跨波段的信息，发现有证据表明我们的模型成功地整合了所有巡天信息。我们的模型在分析大量星系方面的适用性受限于从外部服务器下载剪切图的速度；然而，我们的模型在小规模研究中可能有用，例如为恒星族群合成生成红移先验。

</details>

[⬆️ 返回分类顶部](#astro-phim) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [942] [A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection](https://arxiv.org/abs/2507.22908)
> *一种用于金融欺诈检测的混合量子增强学习隐私保护联邦框架*

*Abhishek Sawaika, Swetang Krishna, Tushar Tomar, Durga Pritam Suggisetti, Aditi Lal, Tanmaya Shrivastav, Nouhaila Innan, Muhammad Shafique* | **Category: q-fin.CP, cs.AI, cs.LG, I.2** | **Updated: 2025-07-15**

**Keywords:** 金融欺诈检测, 联邦学习, 量子增强学习, 隐私保护, FedRansel

**Comment:** To be published in proceedings of IEEE International Conference on
  Quantum Computing and Engineering (QCE) 2025

> **TL;DR:** 本文提出一个名为FedRansel的隐私保护联邦学习框架，结合量子增强LSTM和先进隐私保护技术，用于提高金融欺诈检测的准确性和数据安全性。

**AI_Comments:** 本文的创新点在于将量子增强学习与联邦学习相结合，并引入了专门的防御机制FedRansel来应对联邦学习中的攻击，这在金融欺诈检测领域是一个新颖且重要的探索。该方法在提高检测准确性的同时，也关注了敏感金融数据的隐私保护，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 数字交易的快速增长导致欺诈活动激增，传统检测方法在金融领域面临挑战。

**Method:** 引入一个专门的联邦学习框架，该框架独特地结合了量子增强长短期记忆（LSTM）模型和先进的隐私保护技术。通过将量子层集成到LSTM架构中，并设计了“FedRansel”方法来防御中毒和推理攻击。

**Result:** 与传统模型相比，性能在关键评估指标上提升约5%。与标准差分隐私机制相比，模型退化和推理准确性降低4-8%。

**Conclusion:** 该伪中心化设置与量子LSTM模型增强了欺诈检测准确性，并加强了敏感金融数据的安全性和保密性。

> **ai_Abstract:** 本文提出了一个名为“FedRansel”的隐私保护联邦学习框架，用于金融欺诈检测。该框架独特地将量子增强的LSTM模型与先进的隐私保护技术相结合，以有效捕获复杂的跨交易模式。实验结果显示，与传统模型相比，该方法在性能上提升了约5%，并且在防御中毒和推理攻击方面，相比标准差分隐私机制，能将模型退化和推理准确性降低4-8%，从而显著提高了欺诈检测的准确性和金融数据的安全性。

> **摘要翻译:** 数字交易的快速增长导致欺诈活动激增，对金融领域的传统检测方法构成挑战。为了解决这个问题，我们引入了一个专门的联邦学习框架，该框架独特地结合了量子增强长短期记忆（LSTM）模型和先进的隐私保护技术。通过将量子层集成到LSTM架构中，我们的方法能够巧妙地捕获复杂的跨交易模式，与传统模型相比，在关键评估指标上实现了约5%的性能提升。我们框架的核心是“FedRansel”，这是一种旨在防御中毒和推理攻击的新颖方法，与标准差分隐私机制相比，它将模型退化和推理准确性降低了4-8%。这种带有量子LSTM模型的伪中心化设置，增强了欺诈检测的准确性，并加强了敏感金融数据的安全性和保密性。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

