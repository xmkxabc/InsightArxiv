# AI-Enhanced arXiv Daily 2025-06-10

<a id='toc'></a>
## 今日总计: 1030 篇论文
### 目录
- [cs.CR](#cscr) (43 篇)
- [cs.AI](#csai) (77 篇)
- [cs.LG](#cslg) (196 篇)
- [cs.MA](#csma) (7 篇)
- [cs.RO](#csro) (51 篇)
- [cs.CV](#cscv) (192 篇)
- [cs.SE](#csse) (17 篇)
- [cs.SI](#cssi) (4 篇)
- [cs.NI](#csni) (5 篇)
- [cs.IT](#csit) (15 篇)
- [cs.AR](#csar) (11 篇)
- [cs.DC](#csdc) (7 篇)
- [cs.CY](#cscy) (14 篇)
- [cs.CE](#csce) (2 篇)
- [nlin.CG](#nlincg) (1 篇)
- [cs.CL](#cscl) (134 篇)
- [q-fin.ST](#q-finst) (4 篇)
- [cs.IR](#csir) (19 篇)
- [cs.CC](#cscc) (2 篇)
- [physics.soc-ph](#physicssoc-ph) (2 篇)
- [eess.SP](#eesssp) (27 篇)
- [cs.NE](#csne) (10 篇)
- [math.NA](#mathna) (24 篇)
- [q-bio.NC](#q-bionc) (2 篇)
- [quant-ph](#quant-ph) (9 篇)
- [cs.DB](#csdb) (2 篇)
- [cs.GR](#csgr) (12 篇)
- [eess.SY](#eesssy) (22 篇)
- [cs.HC](#cshc) (19 篇)
- [cs.PL](#cspl) (3 篇)
- [math-ph](#math-ph) (1 篇)
- [cs.SD](#cssd) (18 篇)
- [stat.ML](#statml) (13 篇)
- [cs.MM](#csmm) (4 篇)
- [cs.MS](#csms) (1 篇)
- [physics.med-ph](#physicsmed-ph) (1 篇)
- [math.NT](#mathnt) (2 篇)
- [cs.DS](#csds) (6 篇)
- [cs.CG](#cscg) (3 篇)
- [eess.AS](#eessas) (6 篇)
- [eess.IV](#eessiv) (9 篇)
- [cs.LO](#cslo) (3 篇)
- [q-bio.BM](#q-biobm) (3 篇)
- [physics.comp-ph](#physicscomp-ph) (1 篇)
- [physics.chem-ph](#physicschem-ph) (1 篇)
- [econ.TH](#econth) (1 篇)
- [physics.ed-ph](#physicsed-ph) (1 篇)
- [econ.GN](#econgn) (1 篇)
- [cs.DL](#csdl) (3 篇)
- [q-fin.CP](#q-fincp) (2 篇)
- [cs.DM](#csdm) (2 篇)
- [physics.optics](#physicsoptics) (1 篇)
- [math.OC](#mathoc) (2 篇)
- [math.PR](#mathpr) (2 篇)
- [stat.ME](#statme) (1 篇)
- [cs.GT](#csgt) (3 篇)
- [cs.PF](#cspf) (1 篇)
- [math.AP](#mathap) (1 篇)
- [math.HO](#mathho) (1 篇)
- [math.SP](#mathsp) (1 篇)
- [math.CO](#mathco) (1 篇)
- [math.AT](#mathat) (1 篇)

---
<a id='cscr'></a>
## cs.CR 

### [4] [TimeWak: Temporal Chained-Hashing Watermark for Time Series Data](https://arxiv.org/abs/2506.06407)
> *TimeWak：时间序列数据的时序链式哈希水印*

*Zhi Wen Soi, Chaoyi Zhu, Fouad Abiad, Aditya Shankar, Jeroen M. Galjaard, Huijuan Wang, Lydia Y. Chen* | **Main category: cs.CR**

**Keywords:** 时间序列数据, 水印, 扩散模型, 数据可追溯性, 时序链式哈希

**Comment:** 

> **TL;DR:** 该论文提出了TimeWak，一种针对扩散模型生成的多变量时间序列数据的新型水印方法，解决了真实空间嵌入和非均匀重建误差的挑战，并展示了数据质量的提升和持续的可检测性。

**AI_Comments:** 这篇论文在合成时间序列数据的可追溯性方面取得了重大进展，特别适用于隐私敏感的应用。其创新之处在于直接在真实时间-特征空间中嵌入水印，以及用于鲁棒检测的$\epsilon$-精确反演，这克服了以往方法的关键局限性。在数据效用性和一致可检测性方面令人印象深刻的性能提升突显了其实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 合成时间序列数据需要高数据效用性和可追溯性。现有水印方法在潜在空间中嵌入，但最先进的时间序列生成器在真实空间中运行，导致不兼容。因此，挑战在于如何在处理特征异构性和时间依赖性的同时，直接在真实空间中进行水印处理。

**Method:** 本文提出了TimeWak，一种针对多变量时间序列扩散模型的首次水印算法。它通过在真实时间-特征空间中直接嵌入时序链式哈希水印来处理时间依赖性和空间异构性。此外，它还采用$\epsilon$-精确反演来解决反演扩散过程以检测水印时特征间非均匀重建误差分布的问题。作者推导了多变量时间序列反演的误差界限，并保持了高水印可检测性。

**Result:** TimeWak在context-FID分数上比最先进的基线提高了61.96%，在相关性分数上提高了8.44%，同时保持了持续的可检测性。它在5个数据集和不同时间长度的基线上，对合成数据质量、水印可检测性以及在各种后编辑攻击下的鲁棒性进行了广泛评估。

**Conclusion:** TimeWak成功解决了在真实空间中对时间序列扩散模型进行水印的挑战，并在数据效用性、水印可检测性和鲁棒性方面表现出优于现有方法的性能。

> **ai_Abstract:** 本文介绍了TimeWak，一种专为扩散模型生成的多变量时间序列数据设计的新型水印算法。它通过将时序链式哈希水印直接嵌入到真实时间-特征空间中，解决了传统潜在空间水印与真实空间时间序列生成器不兼容的问题。TimeWak还包含一个$\epsilon$-精确反演机制，用于管理水印检测过程中的非均匀重建误差。广泛的评估表明，TimeWak显著提高了合成数据质量（context-FID提高61.96%，相关性分数提高8.44%），并保持了水印的一致可检测性以及对抗后编辑攻击的鲁棒性，优于最先进的基线。

> **摘要翻译:** 扩散模型生成的合成时间序列使得共享隐私敏感数据集（如患者的功能性MRI记录）成为可能。合成数据的关键标准包括高数据效用性和可追溯性以验证数据来源。最近的水印方法嵌入在同质潜在空间中，但最先进的时间序列生成器在真实空间中运行，使得基于潜在空间的水印不兼容。这带来了直接在真实空间中进行水印处理的挑战，同时需要处理特征异构性和时间依赖性。我们提出了TimeWak，这是第一个用于多变量时间序列扩散模型的水印算法。为了处理时间依赖性和空间异构性，TimeWak直接在真实时间-特征空间中嵌入了一个时序链式哈希水印。另一个独特之处是$\epsilon$-精确反演，它解决了反演扩散过程以检测水印时，特征之间非均匀重建误差分布的问题。我们推导了反演多变量时间序列的误差界限，并进一步保持了高水印可检测性。我们对TimeWak在合成数据质量、水印可检测性以及在各种后编辑攻击下的鲁棒性进行了广泛评估，涉及5个数据集和不同时间长度的基线。我们的结果表明，TimeWak在context-FID分数上实现了61.96%的改进，在相关性分数上比最先进的基线提高了8.44%，同时保持了持续的可检测性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [5] [HeavyWater and SimplexWater: Watermarking Low-Entropy Text Distributions](https://arxiv.org/abs/2506.06409)
> *HeavyWater 和 SimplexWater：水印低熵文本分布*

*Dor Tsur, Carol Xuan Long, Claudio Mayrink Verdun, Hsiang Hsu, Chen-Fu Chen, Haim Permuter, Sajani Vithana, Flavio P. Calmon* | **Main category: cs.CR**

**Keywords:** LLM水印, 低熵文本, HeavyWater, SimplexWater, 编码理论

**Comment:** 

> **TL;DR:** 本文提出了两种新的大语言模型水印技术（HeavyWater和SimplexWater），专门用于有效水印低熵文本分布，同时保持高检测准确率和低文本失真。

**AI_Comments:** 本文的创新点在于针对LLM水印在低熵文本分布（如代码）中面临的特定挑战提出了有效的解决方案。通过引入优化框架来指导水印设计，并提出HeavyWater和SimplexWater两种新水印，该研究在保持文本质量的同时显著提高了水印检测的准确性。其可调性、对任何LLM的普适性以及与编码理论的理论联系，都增加了其重要性和潜在影响力。

<details>
  <summary>Details</summary>

**Motivation:** 当前大语言模型（LLM）水印技术通过改变下一个token的预测来运作，但在低熵生成任务（如编码）中，下一个token的预测接近确定性，这使得LLM水印变得特别具有挑战性。研究的动机在于理解如何最有效地利用随机侧信息，以最大化水印检测的可能性并最小化生成文本的失真，从而解决现有水印在低熵文本方面面临的挑战。

**Method:** 本文提出了一个水印设计的优化框架，旨在最大化水印检测的可能性并最小化生成文本的失真。该框架指导了两种新水印：HeavyWater和SimplexWater的设计。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡，并且可以应用于任何LLM，同时与侧信息生成无关。

**Result:** HeavyWater和SimplexWater在多个基准测试中表现出高水印检测准确率，同时对文本生成质量的损害最小，尤其是在低熵区域。理论分析还揭示了LLM水印与编码理论之间令人惊讶的新联系。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡，并且可以应用于任何LLM。

**Conclusion:** 本文提出的HeavyWater和SimplexWater水印技术，有效地解决了大语言模型在低熵文本分布中水印的挑战，能够在保持生成文本质量的同时，实现高水印检测准确率，并揭示了与编码理论的新联系。

> **ai_Abstract:** 本文提出了一种优化框架，用于设计大语言模型（LLM）水印，旨在解决当前水印在低熵文本（如代码）中面临的挑战。基于此框架，研究人员开发了两种新的可调水印：HeavyWater和SimplexWater。这些水印能够有效利用随机侧信息，在最大化检测准确率的同时，将文本失真降至最低。实验结果表明，HeavyWater和SimplexWater在低熵文本生成中表现出色，实现了高水印检测率和低文本质量损害，并且适用于任何LLM。此外，研究还揭示了LLM水印与编码理论之间的新联系。

> **摘要翻译:** 大语言模型（LLM）水印能够验证文本来源，遏制机器生成文本的滥用，并促进对人工智能系统的信任。当前的水印通过改变LLM输出的下一个token预测来运作。更新后的（即带有水印的）预测取决于随机侧信息，例如通过哈希先前生成的token产生。LLM水印在低熵生成任务（例如编码）中特别具有挑战性——在这种任务中，下一个token的预测接近确定性。在本文中，我们提出了一个水印设计的优化框架。我们的目标是了解如何最有效地利用随机侧信息，以最大化水印检测的可能性并最小化生成文本的失真。我们的分析指导了两种新水印：HeavyWater和SimplexWater的设计。这两种水印都是可调的，可以在检测精度和文本失真之间进行权衡。它们也可以应用于任何LLM，并且与侧信息生成无关。我们通过几个基准测试检验了HeavyWater和SimplexWater的性能，证明它们能够以最小的文本生成质量妥协实现高水印检测准确率，尤其是在低熵区域。我们的理论分析还揭示了LLM水印与编码理论之间令人惊讶的新联系。代码实现可在 https://github.com/DorTsur/HeavyWater_SimplexWater 找到。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [6] [Benchmarking Misuse Mitigation Against Covert Adversaries](https://arxiv.org/abs/2506.06414)
> *基准测试对抗隐蔽性攻击的滥用缓解措施*

*Davis Brown, Mahdi Sabbaghi, Luze Sun, Alexander Robey, George J. Pappas, Eric Wong, Hamed Hassani* | **Main category: cs.CR**

**Keywords:** 语言模型安全, 隐蔽攻击, 分解攻击, 有状态防御, 基准测试

**Comment:** 

> **TL;DR:** 现有语言模型安全评估未能覆盖隐蔽的、多查询的分解攻击。本文开发了有状态防御基准测试（BSD）管道，用于自动化评估此类攻击和相应的防御措施，结果表明分解攻击是有效的滥用促成因素，并强调了有状态防御作为反制措施的重要性。

**AI_Comments:** 这项研究创新性地关注了语言模型中一个被忽视但现实存在的安全漏洞：隐蔽性、多阶段的“分解攻击”。通过开发BSD基准测试，它提供了一个系统化的方法来评估和开发针对这类复杂威胁的防御措施，特别是强调了有状态防御的重要性，这对于提高语言模型在实际应用中的安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有语言模型安全评估主要关注公开攻击和低风险任务，忽视了现实中攻击者可能通过在多个独立、看似无害的查询中逐步实现恶意目的的隐蔽性攻击。这种攻击难以检测，但组合后能促成危险任务的完成，因此需要识别针对此类策略的防御措施。

**Method:** 开发了“有状态防御基准测试”（BSD）数据生成管道，该管道能够自动化评估隐蔽攻击和相应的防御措施。利用此管道，整理并发布了两个新的数据集。

**Result:** 评估表明分解攻击是有效的滥用促成因素。通过BSD管道整理的新数据集被前沿模型一致拒绝，而对较弱的开源模型来说则过于困难。研究强调有状态防御是有效的反制措施。

**Conclusion:** 分解攻击是有效的滥用促成因素，而有状态防御被证实是应对此类隐蔽攻击的有效反制措施。

> **ai_Abstract:** 本文指出现有语言模型安全评估未能有效应对隐蔽性攻击，即攻击者通过多个看似无害的独立查询来规避安全措施，这些查询组合起来可实现恶意目的。为解决这一问题，研究者开发了“有状态防御基准测试”（BSD）数据生成管道，以自动化评估隐蔽攻击及其防御措施。通过该管道，他们创建了两个新数据集，并发现分解攻击是有效的滥用促成因素，而有状态防御是重要的反制措施。

> **摘要翻译:** 现有语言模型安全评估侧重于公开攻击和低风险任务。现实攻击者可以通过在许多独立的查询中请求看似无害的小任务来规避当前的防护措施。由于单个查询似乎无害，因此攻击难以检测。然而，当这些片段结合起来时，它们会通过帮助攻击者完成困难和危险的任务来促进滥用。为了识别针对此类策略的防御措施，我们开发了“有状态防御基准测试”（BSD），这是一个数据生成管道，可以自动化评估隐蔽攻击和相应的防御措施。利用此管道，我们整理了两个新的数据集，这些数据集被前沿模型一致拒绝，并且对于较弱的开源模型来说太困难。我们的评估表明，分解攻击是有效的滥用促成因素，并强调有状态防御是一种反制措施。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [7] [A Systematic Review of Poisoning Attacks Against Large Language Models](https://arxiv.org/abs/2506.06518)
> *大型语言模型中毒攻击的系统综述*

*Neil Fendley, Edward W. Staley, Joshua Carney, William Redman, Marie Chau, Nathan Drenkow* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 中毒攻击, 系统综述, 威胁模型, 安全风险

**Comment:** 28 Pages including number

> **TL;DR:** 本文对大型语言模型（LLM）中毒攻击进行了系统综述，提出了一个全面的威胁模型和分类框架，以解决现有术语不一致的问题并更好地理解安全风险。

**AI_Comments:** 本文通过对LLM中毒攻击进行系统性综述，填补了现有研究中框架和术语不一致的空白。其提出的全面威胁模型和分类维度，为后续研究提供了清晰的指导和统一的语言，对于理解和防御LLM安全风险具有重要意义。创新性在于其系统化的梳理和新模型的提出。

<details>
  <summary>Details</summary>

**Motivation:** 随着预训练大型语言模型及其训练数据集的广泛应用，人们对其使用中的安全风险日益担忧，其中LLM中毒攻击是一个重要威胁。现有针对分类中毒的框架和术语不适用于生成式LLM，因此需要更清晰的理解和统一的框架。

**Method:** 本文对已发表的LLM中毒攻击进行了系统综述，以阐明安全影响并解决文献中术语不一致的问题。作者提出了一个全面的中毒威胁模型，该模型包含四个中毒攻击规范（定义攻击的逻辑和操作策略）以及六个用于衡量攻击关键特征的中毒指标。在此框架下，作者将已发表的LLM中毒文献按照概念中毒、隐蔽中毒、持久中毒和针对特定任务的中毒这四个关键维度进行组织讨论。

**Result:** 本文提供了一个全面的中毒威胁模型，包含攻击规范和测量指标，并根据四个关键维度对LLM中毒攻击文献进行了系统组织和讨论，从而澄清了安全影响并解决了术语不一致的问题。

**Conclusion:** 本文通过系统综述和提出全面的中毒威胁模型，为理解和分类大型语言模型中毒攻击提供了清晰的框架，有助于更好地理解当前的安全风险格局。

> **ai_Abstract:** 本文针对大型语言模型（LLM）中毒攻击这一新兴研究领域，指出现有框架和术语未能完全适应生成式LLM的特点。为此，作者进行了一项系统综述，旨在阐明安全影响并解决文献中的术语不一致问题。文章提出了一种全面的中毒威胁模型，该模型包含四个攻击规范和六个衡量指标，并在此框架下，将已发表的LLM中毒文献按照概念、隐蔽、持久和针对特定任务的中毒等四个关键维度进行了组织和讨论，以增进对当前安全风险的理解。

> **摘要翻译:** 随着预训练大型语言模型（LLM）及其训练数据集的广泛可用性，人们对其使用相关的安全风险担忧显著增加。其中一个安全风险是LLM中毒攻击的威胁，即攻击者修改LLM训练过程的某些部分，导致LLM以恶意方式运行。作为一个新兴研究领域，当前LLM中毒攻击的框架和术语源自早期的分类中毒文献，并未完全适用于生成式LLM环境。我们对已发表的LLM中毒攻击进行了系统综述，以阐明其安全影响并解决文献中术语不一致的问题。我们提出了一个全面的中毒威胁模型，适用于对各种LLM中毒攻击进行分类。该中毒威胁模型包括四个中毒攻击规范，定义了攻击的逻辑和操纵策略，以及六个用于衡量攻击关键特征的中毒指标。在我们提出的框架下，我们围绕LLM中毒攻击的四个关键维度：概念中毒、隐蔽中毒、持久中毒和针对独特任务的中毒，组织了对已发表LLM中毒文献的讨论，以更好地理解当前的安全风险格局。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [22] [Breaking the Gaussian Barrier: Residual-PAC Privacy for Automatic Privatization](https://arxiv.org/abs/2506.06530)
> *突破高斯屏障：用于自动私有化的残差PAC隐私*

*Tao Zhang, Yevgeniy Vorobeychik* | **Main category: cs.CR**

**Keywords:** 残差PAC隐私, f-散度, Stackelberg残差PAC, 隐私保护, 效用

**Comment:** 

> **TL;DR:** 现有PAC隐私算法依赖高斯上界过于保守，本文提出基于f-散度的残差PAC隐私和SR-PAC机制，实现更紧密的隐私预算利用和更高的效用。

**AI_Comments:** 这篇论文通过引入残差PAC隐私和SR-PAC机制，成功地“突破了高斯屏障”，解决了现有PAC隐私框架在隐私预算利用上的保守性问题。其创新点在于引入了f-散度来衡量隐私，并结合博弈论优化噪声分布，使得隐私保护更加灵活高效，且对数据分布的普适性更强。这对于实际应用中实现更紧密的隐私预算和更高的数据效用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有PAC隐私算法依赖于高斯互信息上界，这被证明过于保守且效率低下，仅在特定高斯噪声条件下才紧密。

**Method:** 引入了基于f-散度的残差PAC隐私度量，用于量化对抗性推断后剩余的隐私。进一步提出了Stackelberg残差PAC (SR-PAC) 私有化机制，这是一个通过凸双层优化选择最优噪声分布的博弈论框架。

**Result:** 该方法实现了对任意数据分布的紧密隐私预算利用，在重复机制下具有良好的可组合性，并提供了具有更高统计效率的可证明隐私保证。数值实验表明，SR-PAC在保证目标隐私预算的同时，持续提高了效用。

**Conclusion:** 通过引入残差PAC隐私和SR-PAC机制，本文成功克服了现有PAC隐私框架中高斯上界的保守性问题，实现了更高效、更灵活且实用性更强的隐私保护。

> **ai_Abstract:** 本文针对现有PAC隐私框架中基于高斯互信息上界过于保守的问题，提出了创新的残差PAC隐私度量，该度量基于f-散度，能更准确地量化对抗性推断后的剩余隐私。在此基础上，进一步引入了Stackelberg残差PAC (SR-PAC) 私有化机制，该机制利用博弈论和凸双层优化选择最优噪声分布。实验证明，SR-PAC能够为任意数据分布提供紧密的隐私预算利用，提高统计效率，并在保持隐私预算的同时显著提升数据效用。

> **摘要翻译:** 概率近似正确 (PAC) 隐私框架 [1] 提供了一种强大的基于实例的方法，用于认证复杂数据驱动系统中的隐私。然而，现有的PAC隐私算法依赖于高斯互信息上界。我们表明这通常过于保守：这些算法获得的上限当且仅当扰动机制输出与独立高斯噪声联合高斯时才是紧密的。为了解决基于高斯方法固有的低效率问题，我们引入了残差PAC隐私，这是一种基于f-散度的度量，用于量化对抗性推断后剩余的隐私。当用Kullback-Leibler散度实例化时，残差PAC隐私受条件熵控制。此外，我们针对RPAC隐私提出了Stackelberg残差PAC (SR-PAC) 私有化机制，这是一个通过凸双层优化选择最优噪声分布的博弈论框架。我们的方法实现了对任意数据分布的紧密隐私预算利用。此外，它在重复机制下自然地组合，并提供了具有更高统计效率的可证明隐私保证。数值实验表明，SR-PAC在认证目标隐私预算的同时，与现有方法相比持续提高了效用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [36] [The complexity of the SupportMinors Modeling for the MinRank Problem](https://arxiv.org/abs/2506.06547)
> *MinRank问题中SupportMinors建模的复杂性*

*Daniel Cabarcas, Giulia Gaggero, Elisa Gorla* | **Main category: cs.CR**

**Keywords:** 复杂性, SupportMinors建模, MinRank问题, 复杂度估计, 验证

**Comment:** 

> **TL;DR:** 本文为SupportMinors建模的复杂性提供了经过验证的估计，证实了原始文章中的启发式估计。

**AI_Comments:** 这篇论文的重点是验证和量化MinRank问题中SupportMinors建模的计算复杂性，这对于密码学和计算代数领域可能很重要。其创新之处在于提供了“经过验证的估计”，而非仅仅是启发式估计，从而增强了该建模方法的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为SupportMinors建模的复杂性提供经过验证的估计，以证实原始文章中包含的启发式复杂性估计。

**Method:** 通过提供SupportMinors建模的复杂性证明估计。

**Result:** 研究结果主要证实了原始文章中包含的启发式复杂性估计。

**Conclusion:** 本文为SupportMinors建模的复杂性提供了经过验证的估计，并且这些估计与原始文章中的启发式估计基本一致。

> **ai_Abstract:** 本文提供了关于MinRank问题中SupportMinors建模复杂度的经过验证的估计。研究结果表明，这些新估计与原始论文中提出的启发式复杂性估计基本一致。

> **摘要翻译:** 在这篇笔记中，我们为SupportMinors建模的复杂性提供了经过验证的估计，这在很大程度上证实了原始文章中包含的启发式复杂性估计。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [50] [Adapting Under Fire: Multi-Agent Reinforcement Learning for Adversarial Drift in Network Security](https://arxiv.org/abs/2506.06565)
> *在攻击下适应：网络安全中对抗性漂移的多智能体强化学习*

*Emilia Rivas, Sabrina Saika, Ahtesham Bakht, Aritran Piplai, Nathaniel D. Bastian, Ankit Shah* | **Main category: cs.CR**

**Keywords:** 多智能体强化学习, 网络安全, 对抗性漂移, 入侵检测, 漂移适应

**Comment:** In Proceedings of the 22nd International Conference on Security and
  Cryptography, ISBN 978-989-758-760-3, ISSN 2184-7711, pages 547-554

> **TL;DR:** 本文提出了一种多智能体强化学习方法来应对网络入侵检测系统（NIDS）面临的不断演变的攻击。通过红方（攻击者）和蓝方（防御者）智能体的迭代适应，蓝方智能体利用漂移适应技术显著提高了NIDS的准确性。

**AI_Comments:** 本文将多智能体强化学习创新性地应用于网络安全领域，解决了一个关键的现实世界问题：抵御不断演变的威胁。红蓝智能体之间的迭代适应机制有效地模拟了对抗性环境，有助于开发出鲁棒的防御策略。在仅需少量适应步骤和样本的情况下，模型准确性的大幅提升，凸显了其漂移适应技术的效率和实用性。该方法有望带来更具弹性的NIDS。

<details>
  <summary>Details</summary>

**Motivation:** 不断演变的攻击对网络入侵检测系统（NIDS）的长期成功构成关键挑战。传统的基于签名的网络安全方法在检测未知攻击方面存在局限性，并且需要频繁更新以应对攻击者不断变化的策略。

**Method:** 设计了一个双智能体环境：红色对抗性智能体扰动数据包以规避入侵检测机制，而蓝色智能体则利用漂移适应技术学习新的防御策略来对抗攻击。两个智能体都迭代适应，红方响应演变的NIDS，蓝方调整以适应新兴攻击模式。

**Result:** 实验表明，蓝色智能体仅需2到3个适应步骤，每次仅使用25到30个样本，就能将模型准确性提高30%。通过研究模型的学习策略，本文对高效用的漂移适应技术提供了具体的见解。

**Conclusion:** 本文提出的多智能体强化学习方法，特别是防御智能体采用的漂移适应技术，能够有效提高网络入侵检测系统在面对不断演变攻击时的准确性，并为漂移适应技术提供了有价值的见解。

> **ai_Abstract:** 本文针对网络入侵检测系统（NIDS）面临的不断演变的攻击挑战，提出了一种多智能体强化学习框架。该框架包含一个不断演变其攻击方式的“红色”对抗性智能体，以及一个利用漂移适应技术调整其防御策略的“蓝色”防御智能体。这种迭代适应显著提高了NIDS的准确性，为对抗性漂移提供了有价值的有效防御策略见解。

> **摘要翻译:** 不断演变的攻击是网络入侵检测系统（NIDS）长期成功的关键挑战。这些不断变化的模式的出现暴露了传统网络安全方法的局限性。虽然基于签名的检测方法用于检测不同类型的攻击，但它们常常无法检测未知攻击。此外，由于攻击者不断改变策略，系统需要频繁更新新签名。在本文中，我们设计了一个环境，其中两个智能体随着时间推移改进其策略。对抗性智能体，即红色智能体，扰动数据包以规避入侵检测机制，而蓝色智能体则利用漂移适应技术学习新的防御策略来对抗攻击。两个智能体都迭代适应：红色智能体响应不断演变的NIDS，而蓝色智能体则调整以适应新兴的攻击模式。通过研究模型的学习策略，我们对高效用的漂移适应技术提供了具体的见解。实验表明，蓝色智能体仅需2到3个适应步骤，每次仅使用25到30个样本，就能将模型准确性提高30%。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [65] [Cyber Security of Sensor Systems for State Sequence Estimation: an AI Approach](https://arxiv.org/abs/2506.06572)
> *用于状态序列估计的传感器系统网络安全：一种AI方法*

*Xubin Fang, Rick S. Blum, Ramesh Bharadwaj, Brian M. Sadler* | **Main category: cs.CR**

**Keywords:** 传感器系统安全, 数据攻击, 序列估计, 机器学习, 网络安全

**Comment:** 

> **TL;DR:** 本文开发了首个能够识别和消除传感器系统受攻击数据的方法，以保护序列估计/回归算法，即使在强大的攻击模型下也能表现良好。

**AI_Comments:** 这篇论文的创新点在于它是首个专门针对传感器数据攻击中识别和消除问题数据的方法，且不依赖于数据统计模型。其提出的两阶段保护策略，特别是应对了解保护机制的攻击者的附加处理，展示了其在实际应用中的鲁棒性。这对于提高关键基础设施中传感器系统的网络安全至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 传感器系统易受数据攻击，可能导致灾难性后果，但目前对传感器数据攻击的对策研究不足。

**Method:** 本文开发了识别和消除受攻击传感器数据的方法，用于保护序列估计/回归算法。该方法构建了基于已知/观察到的强大攻击模型，且不假设传感器数据的统计模型形式，从而支持数据驱动和机器学习算法。论文提出了两种保护策略：一种针对不了解保护细节的攻击者（简单方法），另一种针对了解保护系统知识的攻击者（附加处理）。所有数据驱动处理仅使用未受攻击的训练数据。

**Result:** 实验结果表明，简单方法在设计测试案例中，性能与已知哪些传感器被攻击的方法几乎没有区别。当攻击者了解保护方法时，附加处理能够显著降低最坏情况下的性能下降，使其接近已知哪些传感器被攻击的方法，且在无攻击情况下仅有轻微下降。数学描述的最坏情况攻击也表明附加处理在没有数值结果的情况下也能提供类似优势。

**Conclusion:** 本文成功开发了识别和消除传感器数据攻击的方法，显著提高了传感器系统在强大攻击下的网络安全性，尤其是在攻击者了解保护机制的情况下，附加处理表现出优越性。

> **ai_Abstract:** 本文针对传感器系统易受数据攻击的问题，提出了一种AI驱动的新方法，用于识别和消除序列估计/回归算法中的受攻击传感器数据。该方法不依赖于统计模型假设，并开发了两种策略：一种针对不了解保护细节的攻击者，另一种通过附加处理应对了解保护机制的攻击者。实验结果表明，这些方法在强大攻击模型下表现出色，显著提高了传感器系统的网络安全性。

> **摘要翻译:** 传感器系统在当今非常流行，但容易受到传感器数据攻击。由于可能造成毁灭性后果，对抗传感器数据攻击是一个极其重要但尚未得到充分研究的课题。本文开发了首批能够准确识别/消除在基于已知/观察到的攻击构建的强大攻击模型下呈现给序列估计/回归算法的受攻击传感器数据的 problematic 部分的方法。该方法不假设传感器数据的统计模型形式，从而允许保护数据驱动和机器学习序列估计/回归算法。首先开发了一种针对不了解我们保护方法细节的攻击者的简单保护方法，然后是针对基于保护系统知识的攻击的附加处理。在为之设计的测试案例中，实验结果表明，简单方法在性能上与已知哪些传感器受到攻击的方法几乎没有区别（精确到小数点后两位）。对于攻击者了解保护方法的情况，实验结果表明，可以配置附加处理，使得在附加处理和大量传感器受攻击下的最坏情况性能下降显著小于简单方法的最坏情况性能下降，并且在相同数量的受攻击传感器下接近已知哪些传感器受攻击的方法，而在没有攻击的情况下只有轻微的性能下降。最坏情况攻击的数学描述被用来证明附加处理将在我们没有数值结果的案例中提供类似的优势。我们方法中使用的所有数据驱动处理都只使用未受攻击的训练数据。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [79] [Stochastic Training for Side-Channel Resilient AI](https://arxiv.org/abs/2506.06597)
> *用于侧信道弹性AI的随机训练*

*Anuj Dubey, Aydin Aysu* | **Main category: cs.CR**

**Keywords:** 侧信道攻击, AI模型, 边缘设备, 随机训练, 弹性

**Comment:** 

> **TL;DR:** 边缘设备上的AI模型易受侧信道攻击。本文提出了一种随机训练方法，通过在推理过程中引入随机模型配置来减少泄漏并提高弹性，同时保持高精度且无需硬件更改。

**AI_Comments:** 这项研究的创新之处在于提出了一种纯软件、基于训练的防御方法，以应对边缘AI上的侧信道攻击，这在嵌入式系统的限制下尤为重要。其无需硬件更改即可适用于现有Edge TPU的特点是一个显著的优势。

<details>
  <summary>Details</summary>

**Motivation:** 边缘设备上训练的AI模型的保密性面临侧信道攻击的风险，这些攻击利用功耗和电磁辐射。

**Method:** 本文提出了一种新颖的训练方法，通过在推理过程中引入随机和可互换的模型配置来增强对抗侧信道威胁的弹性。

**Result:** 在Google Coral Edge TPU上的实验结果显示，侧信道泄漏减少，并且在超过20,000条轨迹中，t-score的增长速度变慢，这表明了对抗对抗性观测的鲁棒性。该防御方案保持了高精度，在大多数配置下精度下降约1%，并且不需要额外的硬件或软件更改。

**Conclusion:** 所提出的随机训练方法通过减少泄漏和保持精度，有效增强了边缘设备上AI模型对抗侧信道攻击的弹性，使其成为现有Edge TPU的实用解决方案。

> **ai_Abstract:** 本文介绍了一种随机训练方法，用于保护边缘设备上的AI模型免受侧信道攻击。通过在推理过程中使用随机模型配置，该方法显著减少了侧信道泄漏，提高了鲁棒性，同时保持了高精度，且无需硬件或软件修改，使其适用于现有Edge TPU。

> **摘要翻译:** 边缘设备上训练的AI模型的保密性面临侧信道攻击的风险，这些攻击利用功耗和电磁辐射。本文提出了一种新颖的训练方法，通过在推理过程中引入随机和可互换的模型配置来增强对抗此类威胁的弹性。在Google Coral Edge TPU上的实验结果显示，侧信道泄漏减少，并且在超过20,000条轨迹中，t-score的增长速度变慢，这表明了对抗对抗性观测的鲁棒性。该防御方案保持了高精度，在大多数配置下精度下降约1%，并且不需要额外的硬件或软件更改，使其成为现有Edge TPU唯一适用的解决方案。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [93] [Scoring the Unscorables: Cyber Risk Assessment Beyond Internet Scans](https://arxiv.org/abs/2506.06604)
> *难以评分者的评分：超越互联网扫描的网络风险评估*

*Armin Sarabi, Manish Karir, Mingyan Liu* | **Main category: cs.CR**

**Keywords:** 网络风险评估, 技术签名, 数据泄露, 中小企业, 网络安全态势

**Comment:** 

> **TL;DR:** 本文提出了一种使用从组织网站爬取的技术签名来评估网络风险（特别是数据泄露可能性）的新方法，克服了传统IP扫描数据的局限性，并对模型进行了验证。

**AI_Comments:** 这篇论文通过引入“技术签名”这一新颖的数据类型来克服传统网络扫描数据的局限性，特别是在覆盖中小型企业方面的不足，具有创新性。它提供了一种更易于获取和扩展的网络风险评估方法，对于提升中小企业的网络安全量化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的网络风险评估方法依赖于基于IP地址的大规模扫描数据，但这种数据存在IP地址映射不完整/缺失以及大量中小型组织（SMEs）缺乏此类数据的局限性。

**Method:** 本文研究了使用新型数据类型进行网络风险量化，通过估计数据泄露的可能性。具体方法是使用从组织网站爬取到的公开且易于获取的技术签名来构建网络风险评估模型，并使用不同的网络事件数据集对模型进行交叉验证。

**Result:** 证明了使用技术签名构建高精度网络风险评估模型是可行的。研究显示技术签名与组织的网络安全态势之间存在强烈的关系。交叉验证模型还揭示了勒索软件攻击受害者与更广泛的网络事件和数据泄露受害者之间的关键差异。

**Conclusion:** 本文证明了使用从网站获取的技术签名来构建高精度网络风险评估模型是可行的，并且这些签名与组织的网络安全态势之间存在强烈的关系。

> **ai_Abstract:** 本文提出了一种创新的网络风险评估方法，通过分析从组织网站获取的公开技术签名来量化数据泄露的可能性。该方法解决了传统基于IP扫描数据在数据完整性和中小企业覆盖方面的不足，并证明了其构建高精度模型的普适性。研究发现技术签名与网络安全态势强相关，并通过交叉验证揭示了不同网络攻击受害者群体的特征。

> **摘要翻译:** 在本文中，我们提出了一项关于使用新型数据类型通过估计数据泄露的可能性来执行网络风险量化的研究。我们证明，利用从组织网站爬取获得的公开且易于获取的技术签名，构建一个高度准确的网络风险评估模型是可行的。这种方法克服了之前依赖于大规模IP地址扫描数据（这些数据存在IP地址映射不完整/缺失以及大量中小型组织（SMEs）缺乏此类数据的问题）的类似方法的局限性。与扫描数据相比，技术数字签名数据更容易为数百万中小企业获取。我们的研究表明，这些技术签名与组织的网络安全态势之间存在很强的关系。在利用不同的网络事件数据集对我们的模型进行交叉验证时，我们还强调了勒索软件攻击受害者与更广泛的网络事件和数据泄露受害者之间的关键差异。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [107] [TrustConnect: An In-Vehicle Anomaly Detection Framework through Topology-Based Trust Rating](https://arxiv.org/abs/2506.06635)
> *TrustConnect：一种基于拓扑信任评级的车载异常检测框架*

*Ayan Roy, Jeetkumar Patel, Rik Chakraborti, Shudip Datta* | **Main category: cs.CR**

**Keywords:** 车载网络, 异常检测, 信任评估, 拓扑, 网络安全

**Comment:** To Appear in 2025 the IEEE 101st Vehicular Technology Conference:
  VTC2025-Spring

> **TL;DR:** TrustConnect是一种车载异常检测框架，通过评估组件信任度来识别和防止错误信息传播，从而提升车辆可靠性。

**AI_Comments:** TrustConnect是一个创新性的框架，它通过引入基于拓扑的信任评级来解决车载网络中的异常检测问题。其重要性在于能够有效提升现代车辆的安全性与可靠性，尤其是在应对外部通信带来的潜在威胁方面。该方法考虑了组件的相互依赖性和外部暴露程度，这在实际应用中具有很高的价值。

<details>
  <summary>Details</summary>

**Motivation:** 现代车辆中，车载组件通过外部通信与外部环境交互，但虚假或伪造信息的存在可能扰乱车辆性能，并可能在网络中传播，导致灾难性后果。

**Method:** 本文提出了TrustConnect框架，旨在通过评估各种网络配置下单个组件的信任级别来评估车辆车载网络的信任度。该框架利用所有车辆组件的相互依赖性、其值的相关性以及基于每个组件外部暴露的远程注入脆弱性来确定车载网络的可靠性。

**Result:** 所提出的框架的有效性已通过使用Python的Networkx包生成的车载网络图在各种场景下的编程仿真得到验证。

**Conclusion:** TrustConnect框架能够有效评估车载网络的信任度，并通过识别和防止错误信息传播来增强车辆的可靠性和安全性。

> **ai_Abstract:** 本文提出了TrustConnect框架，旨在解决现代车辆中因虚假信息传播导致的网络性能问题。该框架通过评估车载网络中各个组件的信任度，并考虑组件间的相互依赖性、数据相关性和远程注入脆弱性，来确定网络的整体可靠性。通过编程仿真验证了其在不同场景下的有效性。

> **摘要翻译:** 现代车辆配备了大量车载组件，这些组件通过蓝牙和车对基础设施通信等远程通信和服务与外部环境交互。这些组件形成一个网络，交换信息以确保车辆的正常运行。然而，虚假或伪造信息的存在可能会扰乱车辆的性能。鉴于这些组件是相互连接的，错误数据可能会在整个网络中传播，可能影响其他组件并导致灾难性后果。为了解决这个问题，我们提出了TrustConnect，一个旨在通过评估各种网络配置下单个组件的信任级别来评估车辆车载网络信任度的框架。所提出的框架利用所有车辆组件的相互依赖性、其值的相关性以及基于每个组件外部暴露的远程注入脆弱性来确定车载网络的可靠性。所提出的框架的有效性已通过使用Python的Networkx包生成的车载网络图在各种场景下的编程仿真得到验证。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [109] [Profiling Electric Vehicles via Early Charging Voltage Patterns](https://arxiv.org/abs/2506.07714)
> *通过早期充电电压模式识别电动汽车*

*Francesco Marchiori, Denis Donadel, Alessandro Brighente, Mauro Conti* | **Main category: cs.CR**

**Keywords:** 电动汽车, 充电认证, 电压模式, 身份识别, 隐私风险

**Comment:** Accepted to be presented at the AI&CPSS Workshop in conjunction with
  ARES 2025

> **TL;DR:** 本文提出了一种利用电动汽车早期充电电压模式进行身份识别的框架，旨在提高充电认证的效率和安全性，同时揭示了潜在的隐私风险。

**AI_Comments:** 该研究创新性地将电动汽车认证的焦点从充电后期转移到早期电压模式，显著提高了检测效率和安全性。其提出的轻量级模型和对关键特征的识别，使其在实际应用中具有较高的效率和部署潜力。然而，研究也明确指出了这种识别能力可能带来的隐私风险，这在未来电动汽车数据利用中是需要重点关注和解决的问题。

<details>
  <summary>Details</summary>

**Motivation:** 尽管传统的认证协议存在，但攻击者仍可能通过定制的继电器攻击窃取电动汽车充电能量。现有方法侧重于充电后期，导致恶意行为者在被检测前已消耗大量能量。因此，需要更早期、更有效的认证方法来防止未经授权的充电。同时，通过充电模式唯一识别电动汽车可能导致用户追踪，引发隐私担忧。

**Method:** 本文提出了一种利用早期充电阶段的物理测量数据（电压模式）来唯一识别电动汽车的框架。研究假设早期电压行为与后期电流行为具有相似的特征。通过从早期电压测量中提取特征，验证了电动汽车识别的可行性。

**Result:** 该解决方案在包含49辆电动汽车的7408次有效充电数据集中进行了测试，实现了高达0.86的准确率。特征重要性分析表明，仅使用10个关键特征即可实现接近最优的性能，提高了效率并支持轻量级模型。

**Conclusion:** 这项研究为一种新颖的认证因素奠定了基础，同时也揭示了未经授权访问充电数据可能带来的隐私风险。

> **ai_Abstract:** 本文提出了一种基于电动汽车早期充电电压模式的身份识别框架，旨在解决现有充电认证方法检测滞后导致能量被盗的问题。研究假设早期电压行为与后期电流行为具有相似的识别特征。通过从早期电压测量中提取特征，该方法在49辆电动汽车的7408次充电数据上实现了高达0.86的准确率，并发现仅需10个关键特征即可实现接近最优性能。这项研究为更早、更可靠的电动汽车认证提供了新途径，同时也指出了充电数据可能引发的隐私风险。

> **摘要翻译:** 电动汽车（EVs）作为燃料动力汽车的可持续替代品正在迅速普及，因此安全的充电基础设施至关重要。尽管有传统的认证协议，但最近的结果表明，攻击者可能通过定制的继电器攻击窃取能量。一种对策是利用电动汽车在充电过程中交换电流的“指纹”。然而，现有方法侧重于最终充电阶段，使得恶意行为者在被检测和拒绝之前消耗大量能量。这强调了需要更早、更有效的认证方法来防止未经授权的充电。同时，识别也引发了隐私问题，因为通过充电模式唯一识别电动汽车可能导致用户追踪。
在本文中，我们提出了一种利用早期充电阶段的物理测量数据来唯一识别电动汽车的框架。我们假设早期充电过程中的电压行为与后期电流行为表现出相似的特征。通过从早期电压测量中提取特征，我们证明了电动汽车识别的可行性。我们的方法通过实现更快、更可靠的车辆识别来改进现有方法。我们在一个包含49辆电动汽车的7408次可用充电数据集中测试了我们的解决方案，实现了高达0.86的准确率。特征重要性分析表明，仅使用10个关键特征即可实现接近最优的性能，提高了效率，同时支持我们的轻量级模型。这项研究为一种新颖的认证因素奠定了基础，同时也揭示了未经授权访问充电数据可能带来的潜在隐私风险。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [120] [Fuse and Federate: Enhancing EV Charging Station Security with Multimodal Fusion and Federated Learning](https://arxiv.org/abs/2506.06730)
> *融合与联邦：通过多模态融合和联邦学习增强电动汽车充电站安全*

*Rabah Rahal, Abdelaziz Amara Korba, Yacine Ghamri-Doudane* | **Main category: cs.CR**

**Keywords:** 电动汽车充电站安全, 多模态融合, 联邦学习, 入侵检测, 网络安全

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的入侵检测框架，利用多模态数据融合和联邦学习，以提高电动汽车充电站的安全，有效检测复杂攻击，同时保护数据隐私。

**AI_Comments:** 该论文的创新点在于结合了多模态数据融合和联邦学习来解决电动汽车充电站的安全问题。多模态数据的使用增强了对复杂攻击模式的检测能力，而联邦学习则有效解决了数据隐私和可扩展性问题，这对于分布式智能电网基础设施至关重要。该方法在实际应用中具有重要意义，因为它为关键基础设施提供了更强的网络弹性。

<details>
  <summary>Details</summary>

**Motivation:** 电动汽车的快速普及使得电动汽车供电设备（EVSE）成为智能电网基础设施的关键组成部分。然而，EVSE系统面临严峻的网络安全挑战，如网络侦察、后门入侵和分布式拒绝服务（DDoS）攻击。现有入侵检测系统（IDS）难以检测针对EVSE基础设施新漏洞的复杂和定向攻击，因此需要创新和自适应的安全机制。

**Method:** 本文提出了一种新颖的入侵检测框架，该框架利用网络流量和内核事件等多模态数据源来识别复杂的攻击模式。该框架采用分布式学习方法，通过联邦学习在EVSE站点之间实现协作智能，同时保护数据隐私。

**Result:** 实验结果表明，所提出的框架优于现有解决方案，在去中心化环境中实现了98%以上的检测率和97%以上的精确率。

**Conclusion:** 该解决方案解决了电动汽车供电设备（EVSE）安全不断演变的问题，为高级网络威胁提供了可扩展且保护隐私的响应。

> **ai_Abstract:** 本文提出了一种创新的入侵检测框架，旨在增强电动汽车充电站（EVSE）的安全性。该框架通过融合网络流量和内核事件等多模态数据来识别复杂攻击模式，并利用联邦学习实现分布式协作智能，同时确保数据隐私。实验证明，该框架在去中心化环境中表现优异，检测率和精确率均超过97%，有效应对了EVSE日益严峻的网络安全挑战。

> **摘要翻译:** 电动汽车（EV）在全球的快速普及已将电动汽车供电设备（EVSE）确立为智能电网基础设施的关键组成部分。虽然对于确保可靠的能源输送和可访问性至关重要，但EVSE系统面临着严峻的网络安全挑战，包括网络侦察、后门入侵和分布式拒绝服务（DDoS）攻击。这些新兴威胁，由EVSE的互联和自治特性驱动，需要创新和自适应的安全机制，超越传统的入侵检测系统（IDS）。现有方法，无论是基于网络的还是基于主机的，往往无法检测专门为利用EVSE基础设施新漏洞而设计的复杂和定向攻击。本文提出了一种新颖的入侵检测框架，该框架利用多模态数据源，包括网络流量和内核事件，来识别复杂的攻击模式。该框架采用分布式学习方法，通过联邦学习在EVSE站点之间实现协作智能，同时保护数据隐私。实验结果表明，所提出的框架优于现有解决方案，在去中心化环境中实现了98%以上的检测率和97%以上的精确率。该解决方案解决了EVSE安全不断演变的问题，为高级网络威胁提供了可扩展且保护隐私的响应。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [133] [Ai-Driven Vulnerability Analysis in Smart Contracts: Trends, Challenges and Future Directions](https://arxiv.org/abs/2506.06735)
> *智能合约中人工智能驱动的漏洞分析：趋势、挑战与未来方向*

*Mesut Ozdag* | **Main category: cs.CR**

**Keywords:** 智能合约, 漏洞分析, 人工智能, 机器学习, 深度学习

**Comment:** 

> **TL;DR:** 本文综述了智能合约中AI驱动的漏洞检测技术，探讨了机器学习、深度学习、图神经网络和Transformer模型，并分析了它们的优缺点、挑战和未来方向。

**AI_Comments:** 这篇综述论文的重要性在于系统地梳理了智能合约AI驱动漏洞分析的最新进展，为研究人员和开发者提供了全面的视角。它不仅识别了当前的技术趋势，还明确指出了未来研究的关键挑战和机遇，对于推动智能合约安全领域的发展具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约中的漏洞导致了数百万美元的损失。传统的审计技术在可扩展性、自动化和适应性方面存在局限性。AI解决方案作为一种有前景的替代方案出现，能够学习复杂模式、检测细微缺陷并提供可扩展的安全保障。

**Method:** 本文审查了智能合约中AI驱动的漏洞检测新技术，重点关注机器学习、深度学习、图神经网络和基于Transformer的模型。分析了每种技术如何表示代码、处理语义信息以及响应实际漏洞类别。还比较了它们在准确性、可解释性、计算开销和实时适用性方面的优缺点。

**Result:** 本文分析并比较了各种AI驱动的漏洞检测技术（如机器学习、深度学习、图神经网络、Transformer模型）在表示代码、处理语义信息、响应漏洞以及准确性、可解释性、计算开销和实时适用性方面的优缺点。

**Conclusion:** 论文强调了该领域存在的开放挑战和未来的发展机遇。

> **ai_Abstract:** 本文针对智能合约中因漏洞造成的巨额损失和传统审计方法的局限性，综述了人工智能驱动的漏洞检测技术。重点探讨了机器学习、深度学习、图神经网络和基于Transformer的模型，分析了它们在代码表示、语义处理和漏洞响应方面的能力，并比较了它们在准确性、可解释性、计算开销和实时适用性上的优缺点。论文最后指出了该领域的开放挑战和未来发展方向。

> **摘要翻译:** 智能合约作为区块链生态系统的组成部分，使去中心化应用程序无需中介即可执行预定义操作。它们强制执行无需信任交互的能力使其成为以太坊等平台的核心组件。数值溢出、重入攻击和不当访问权限等漏洞已导致整个区块链和智能合约领域数百万美元的损失。传统智能合约审计技术，如手动代码审查和形式化验证，在可扩展性、自动化和适应不断发展的开发模式方面面临局限性。因此，基于人工智能的解决方案已成为一种有前景的替代方案，能够学习复杂模式、检测细微缺陷并提供可扩展的安全保障。本文研究了智能合约中用于漏洞检测的新型人工智能驱动技术，重点关注机器学习、深度学习、图神经网络和基于Transformer的模型。本文分析了每种技术如何表示代码、处理语义信息以及响应实际漏洞类别。我们还比较了它们在准确性、可解释性、计算开销和实时适用性方面的优缺点。最后，它强调了推进该领域的开放挑战和未来机遇。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [145] [Are Trees Really Green? A Detection Approach of IoT Malware Attacks](https://arxiv.org/abs/2506.07836)
> *树木真的环保吗？一种物联网恶意软件攻击检测方法*

*Silvia Lucia Sanna, Diego Soi, Davide Maiorca, Giorgio Giacinto* | **Main category: cs.CR**

**Keywords:** 物联网安全, 恶意软件检测, 机器学习, 能效, 基于树的模型

**Comment:** 

> **TL;DR:** 该研究提出了一种针对物联网恶意软件攻击的绿色检测方法，通过优化基于树的机器学习模型，在保持高检测性能的同时显著降低能耗，适用于资源受限的物联网设备。

**AI_Comments:** 该研究的创新之处在于其“绿色”检测理念，将机器学习模型的能耗优化纳入考量，这对于资源受限的物联网设备至关重要。它不仅关注了检测准确性，还解决了实际部署中的能耗挑战，为物联网安全领域提供了一个兼顾性能和效率的实用方案。

<details>
  <summary>Details</summary>

**Motivation:** 物联网设备因资源受限和安全补丁应用困难而容易受到网络攻击。现有的机器学习检测方法侧重于识别，但忽略了算法对计算资源（尤其是能耗）的影响，这在物联网环境中是一个重要问题。

**Method:** 该论文提出了一种“绿色”方法，利用流隐私保护统计特征来识别物联网恶意软件网络攻击。具体而言，该方法基于能耗和测试时间性能（通过Matthew's Correlation Coefficient衡量），优化了三种基于树的模型（决策树、随机森林和Extra-Trees）的超参数。

**Result:** 研究结果表明，优化后的模型在保持高检测性能和准确性的同时，能持续降低功耗（以瓦时计）。

**Conclusion:** 基于本地机器学习的入侵检测系统适用于物联网及其他资源受限设备，证明了在保证性能的同时实现能耗优化的可行性。

> **ai_Abstract:** 本文提出了一种检测物联网恶意软件攻击的“绿色”方法，旨在解决现有机器学习检测方案中能耗被忽视的问题。该方法通过优化决策树、随机森林和Extra-Trees等基于树的模型的超参数，在确保高检测准确性的同时，显著降低了功耗。实验结果表明，这种方法在保持高性能的同时，能够有效减少物联网设备上的能源消耗，使其更适合资源受限的物联网环境。

> **摘要翻译:** 如今，物联网（IoT）被广泛应用，其使用量呈指数级增长，因为它促进了远程监控、预测性维护和数据驱动的决策，尤其是在医疗保健和工业领域。然而，物联网设备由于其资源限制和应用安全补丁的困难而仍然脆弱。因此，每天都有各种网络安全攻击被报告，例如拒绝服务攻击，特别是在物联网驱动的解决方案中。大多数攻击检测方法都基于机器学习（ML）技术，这些技术可以检测攻击模式。然而，重点更多地放在识别上，而不是考虑ML算法对计算资源的影响。本文提出了一种绿色方法来识别基于流隐私保护统计特征的物联网恶意软件网络攻击。特别是，三种基于树的模型——决策树、随机森林和Extra-Trees——的超参数是根据能耗和测试时间性能（以Matthew's Correlation Coefficient衡量）进行优化的。我们的结果表明，模型在保持高性能和检测准确性的同时，持续降低了瓦时（Wh）功耗。这表明基于本地ML的入侵检测系统适用于物联网和其他资源受限设备。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [146] [LADSG: Label-Anonymized Distillation and Similar Gradient Substitution for Label Privacy in Vertical Federated Learning](https://arxiv.org/abs/2506.06742)
> *LADSG：垂直联邦学习中用于标签隐私的标签匿名化蒸馏和相似梯度替换*

*Zeyu Yan, Yifei Yao, Xuanbing Wen, Juli Zhang, Kai Fan* | **Main category: cs.CR**

**Keywords:** 垂直联邦学习, 标签隐私, 梯度替换, 标签匿名化, 异常检测

**Comment:** 20 pages, 6 figures. Under review

> **TL;DR:** 针对垂直联邦学习中的标签推断攻击，提出了LADSG框架，通过梯度替换、标签匿名化和异常检测，有效降低攻击成功率，且计算开销小。

**AI_Comments:** 本文提出了一种创新且实用的方法来解决垂直联邦学习中日益增长的标签隐私泄露问题。LADSG的统一框架能够同时处理多种攻击向量，这对于应对不断演变的攻击策略至关重要。其在降低攻击成功率方面的显著效果和极低的计算开销，使其成为VFL安全领域一个有前景的轻量级解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 垂直联邦学习面临内部标签推断攻击，这些攻击利用梯度和语义嵌入重建私有标签，绕过传统防御。现有防御措施针对单一泄漏路径，难以应对结合多种向量的混合攻击。

**Method:** 提出LADSG（Label-Anonymized Defense with Substitution Gradient），一个统一的防御框架，整合了梯度替换、标签匿名化和异常检测。

**Result:** 在六个真实世界数据集上的实验表明，LADSG将标签推断攻击成功率降低了30-60%，计算开销极小。

**Conclusion:** LADSG提供了一种轻量级的有效防御，能够同时缓解垂直联邦学习中的梯度和标签泄漏，同时保持可扩展性和效率。

> **ai_Abstract:** 本文提出了LADSG（Label-Anonymized Defense with Substitution Gradient），一个针对垂直联邦学习中标签隐私泄露的统一防御框架。面对利用梯度和语义嵌入进行标签重建的内部攻击，LADSG通过结合梯度替换、标签匿名化和异常检测，有效抵御了现有防御难以应对的混合攻击。实验证明，LADSG能在保持VFL效率的同时，显著降低标签推断攻击成功率（30-60%），且计算开销极低。

> **摘要翻译:** 垂直联邦学习（VFL）已成为协作机器学习的关键范式，它使多方能够在分布式特征空间上训练模型，同时保护数据隐私。尽管存在抵御外部攻击的安全协议——例如梯度掩码和加密，以防止未经授权访问敏感数据——但最近系统内部出现了标签推断攻击。这些攻击利用梯度和语义嵌入来重建私有标签，绕过了传统防御。例如，被动标签推断攻击仅使用40个辅助标签就可以重建数万名参与者的私人数据，构成了重大的安全威胁。现有防御措施解决了单一的泄漏路径，例如梯度泄漏或标签暴露。随着攻击策略的演变，它们的局限性变得清晰，特别是针对结合多种向量的混合攻击。为了解决这个问题，我们提出了LADSG（Label-Anonymized Defense with Substitution Gradient），一个统一的防御框架，它整合了梯度替换、标签匿名化和异常检测。LADSG在保持VFL的可扩展性和效率的同时，缓解了梯度和标签泄漏。在六个真实世界数据集上的实验表明，LADSG将标签推断攻击成功率降低了30-60%，计算开销极小，强调了轻量级防御在保护VFL中的重要性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [155] [TimberStrike: Dataset Reconstruction Attack Revealing Privacy Leakage in Federated Tree-Based Systems](https://arxiv.org/abs/2506.07605)
> *TimberStrike：揭示联邦树形系统中隐私泄露的数据集重建攻击*

*Marco Di Gennaro, Giovanni De Lucia, Stefano Longari, Stefano Zanero, Michele Carminati* | **Main category: cs.CR**

**Keywords:** 联邦学习, 隐私泄露, 树形模型, 数据集重建攻击, TimberStrike

**Comment:** Proceedings on Privacy Enhancing Technologies (To appear) 2025(4)

> **TL;DR:** TimberStrike攻击揭示了联邦树形模型中严重的隐私泄露，可重建高达95.63%的数据集，并指出需要专门的隐私保护机制。

**AI_Comments:** 该论文创新性地提出了针对联邦树形模型的TimberStrike数据集重建攻击，填补了该领域隐私泄露研究的空白。其重要性在于揭示了现有联邦树形系统在隐私保护方面的脆弱性，并量化了数据泄露的严重程度。同时，对差分隐私有效性的分析也为未来隐私保护机制的设计提供了宝贵启示，强调了需要更具针对性的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在神经网络方面得到了广泛研究，但树形模型的安全和隐私影响仍未被充分探索。

**Method:** 本文引入了TimberStrike，一种针对水平联邦树形模型的基于优化的数据集重建攻击。该攻击由单个客户端执行，利用决策树的离散性质，通过分裂值和决策路径推断其他客户端的敏感训练数据。

**Result:** TimberStrike在多个框架（包括Flower、NVFlare和FedTree）的联邦梯度提升实现上，始终能重建目标数据集的73.05%到95.63%。差分隐私虽然部分缓解了攻击，但显著降低了模型性能。

**Conclusion:** 研究结果强调了为基于树的联邦学习系统设计专门的隐私保护机制的必要性，并提供了初步的设计见解。

> **ai_Abstract:** 本文提出了TimberStrike，一种针对联邦树形模型的数据集重建攻击，旨在揭示其隐私泄露风险。该攻击利用决策树的离散特性，通过分裂值和决策路径从单个客户端推断出其他客户端的敏感训练数据。实验表明，在多种联邦梯度提升框架下，TimberStrike能够重建高达95.63%的目标数据集。研究还发现，差分隐私虽然能部分缓解攻击，但会严重损害模型性能。这突出了为联邦树形学习系统开发专门隐私保护机制的重要性。

> **摘要翻译:** 联邦学习已成为集中式机器学习的一种面向隐私的替代方案，可以在不直接共享数据的情况下实现协作模型训练。虽然对神经网络的研究广泛，但树形模型的安全和隐私影响仍未得到充分探索。这项工作引入了TimberStrike，一种针对水平联邦树形模型的基于优化的数据集重建攻击。我们的攻击由单个客户端执行，利用决策树的离散性质，通过分裂值和决策路径推断其他客户端的敏感训练数据。我们在包括Flower、NVFlare和FedTree在内的多个框架上评估了最先进的联邦梯度提升实现中的TimberStrike，证明了它们容易受到隐私泄露的影响。在一个公开可用的中风预测数据集上，TimberStrike在所有实现中始终能重建目标数据集的73.05%到95.63%。我们进一步分析了差分隐私，表明虽然它部分缓解了攻击，但也会显著降低模型性能。我们的发现强调了为基于树的联邦学习系统专门设计隐私保护机制的必要性，并提供了初步的设计见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [156] [Auditing Black-Box LLM APIs with a Rank-Based Uniformity Test](https://arxiv.org/abs/2506.06975)
> *使用基于排名的均匀性测试审计黑盒LLM API*

*Xiaoyuan Zhu, Yaowen Ye, Tianyi Qiu, Hanlin Zhu, Sijun Tan, Ajraf Mannan, Jonathan Michala, Raluca Ada Popa, Willie Neiswanger* | **Main category: cs.CR**

**Keywords:** 黑盒LLM API, 均匀性测试, 模型审计, 行为等同性, LLM安全

**Comment:** 

> **TL;DR:** 提出了一种基于排名的均匀性测试，用于验证黑盒LLM API与本地模型的行为一致性，以检测潜在的模型替换或修改，确保LLM服务的透明度和安全性。

**AI_Comments:** 这项工作通过提出一种新颖的、基于排名的均匀性测试方法，解决了黑盒LLM API透明度不足的关键问题。其创新之处在于能够仅通过行为观察来检测模型潜在的秘密修改或替换，且对对抗性提供商具有鲁棒性，这对于确保LLM服务的可靠性和安全性至关重要。该方法在查询效率和统计功效方面的优势也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 作为LLM的主要接口，API通常是黑盒系统，透明度低。API提供商可能为了降低成本或恶意改变行为而秘密提供量化或微调过的模型变体，这会导致性能下降和安全问题。用户缺乏模型权重和输出logits的访问权限，使得检测这些替换变得困难。

**Method:** 提出了一种基于排名的均匀性测试（rank-based uniformity test），该方法能够验证黑盒LLM与本地部署的真实模型之间的行为等同性。该方法准确、查询高效，并避免可检测的查询模式，使其对在检测到测试尝试时重新路由或混合响应的对抗性提供商具有鲁棒性。

**Result:** 在量化、有害微调、越狱提示和完整模型替换等多种威胁场景下进行了评估，结果表明在受限查询预算下，该方法始终比现有方法具有更优越的统计功效。

**Conclusion:** 该方法能有效且高效地检测黑盒LLM API的潜在模型替换或行为修改，即使在对抗性环境下也能保持鲁棒性，从而增强LLM API的透明度和安全性。

> **ai_Abstract:** 本文提出了一种基于排名的均匀性测试方法，旨在解决用户在使用黑盒LLM API时遇到的模型不透明性问题。该方法能够准确、高效地验证黑盒LLM与本地真实模型之间的行为一致性，从而检测API提供商可能进行的模型量化、微调或替换，这些行为可能导致性能下降或安全风险。实验证明，该方法在多种威胁场景下，即使在查询预算有限的情况下，也比现有方法具有更高的统计功效，并且对对抗性策略具有鲁棒性。

> **摘要翻译:** 随着API访问成为大型语言模型（LLM）的主要接口，用户通常与提供很少透明度的黑盒系统交互。为了降低成本或恶意改变模型行为，API提供商可能会悄悄地提供量化或微调过的变体，这会降低性能并损害安全性。检测此类替换非常困难，因为用户无法访问模型权重，在大多数情况下甚至无法访问输出 logits。为了解决这个问题，我们提出了一种基于排名的均匀性测试，可以验证黑盒LLM与本地部署的真实模型之间的行为等同性。我们的方法准确、查询高效，并避免可检测的查询模式，使其对在检测到测试尝试时重新路由或混合响应的对抗性提供商具有鲁棒性。我们在包括量化、有害微调、越狱提示和完整模型替换在内的各种威胁场景中评估了该方法，结果表明在受限查询预算下，它始终比现有方法具有优越的统计功效。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [166] [ModelForge: Using GenAI to Improve the Development of Security Protocols](https://arxiv.org/abs/2506.07010)
> *ModelForge：使用生成式AI改进安全协议的开发*

*Martin Duclos, Ivan A. Fernandez, Kaneesha Moore, Sudip Mittal, Edward Zieglar* | **Main category: cs.CR**

**Keywords:** 安全协议, 形式化方法, 生成式AI, 自然语言处理, ModelForge

**Comment:** 

> **TL;DR:** ModelForge是一个利用生成式AI和NLP自动化将安全协议的自然语言规范转换为形式化表示的工具，旨在简化安全协议的形式化验证。

**AI_Comments:** ModelForge的创新之处在于将生成式AI应用于安全协议的形式化表示转换，解决了传统方法中人工翻译的复杂性问题。这对于推广形式化方法在安全协议开发中的应用具有重要意义，因为它降低了使用门槛。虽然在处理复杂协议细节上仍有改进空间，但其概念验证和架构为未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 形式化方法可用于验证安全协议，但将自然语言协议规范转换为形式化表示的复杂性阻碍了其应用。

**Method:** 本文介绍了ModelForge，一个利用自然语言处理（NLP）和生成式AI（GenAI）自动化将协议规范翻译为Cryptographic Protocol Shapes Analyzer (CPSA)协议定义的工具。通过微调大型语言模型（LLM）来生成CPSA协议定义，并将其性能与其他流行LLM进行比较以进行评估。

**Result:** ModelForge持续生成高质量输出，在语法准确性方面表现出色，尽管在处理某些协议细节方面仍需完善。

**Conclusion:** 本工作的贡献包括一个旨在简化形式化方法在安全协议开发中应用的翻译工具的架构和概念验证。

> **ai_Abstract:** ModelForge是一款利用NLP和生成式AI的工具，旨在自动化将安全协议的自然语言规范转换为形式化表示，特别是针对CPSA。它通过微调LLM实现自动化，显著减少了手动工作，使形式化分析更易于访问。评估结果显示ModelForge在语法准确性方面表现优异，证明了其在简化安全协议开发中形式化方法应用的潜力。

> **摘要翻译:** 形式化方法可用于验证安全协议，但将自然语言协议规范转换为形式化表示的复杂性可能会阻碍其采用。在本文中，我们介绍了ModelForge，这是一种新颖的工具，可自动化为密码协议形状分析器 (CPSA) 翻译协议规范。通过利用自然语言处理 (NLP) 和生成式AI (GenAI) 的进步，ModelForge 处理协议规范并生成 CPSA 协议定义。这种方法减少了所需的手动工作，使形式化分析更易于访问。我们通过微调大型语言模型 (LLM) 来生成 CPSA 的协议定义，并将其性能与其他流行的 LLM 进行比较，从而评估了 ModelForge。我们的评估结果表明，ModelForge 持续产生高质量输出，在语法准确性方面表现出色，尽管在处理某些协议细节方面仍需完善。这项工作的贡献包括一个翻译工具的架构和概念验证，旨在简化形式化方法在安全协议开发中的采用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [176] [HauntAttack: When Attack Follows Reasoning as a Shadow](https://arxiv.org/abs/2506.07031)
> *HauntAttack：当攻击如影随形地伴随推理*

*Jingyuan Ma, Rui Li, Zheng Li, Junfeng Liu, Lei Sha, Zhifang Sui* | **Main category: cs.CR**

**Keywords:** 大型推理模型, 安全漏洞, 黑盒攻击, 推理安全, 有害指令

**Comment:** 

> **TL;DR:** 大型推理模型（LRMs）在推理任务中表现出色，但当有害指令被嵌入到推理问题中时，它们会表现出显著的安全漏洞。

**AI_Comments:** 这项研究揭示了大型推理模型在处理包含有害指令的推理任务时存在的严重安全风险，即使是先进的模型也未能幸免。HauntAttack作为一种新颖的黑盒攻击方法，通过巧妙地将有害指令融入推理路径，提供了一个评估和理解LRM安全漏洞的有效工具。这项工作对于推动安全AI研究和开发更鲁棒的推理模型具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型推理模型（LRMs）在数学和推理任务中表现出卓越能力，其推理能力的增强和内部推理过程的暴露引入了新的安全漏洞。具体来说，当推理与危害性强烈纠缠时，LRMs会表现出何种安全-推理权衡是一个令人担忧的问题。

**Method:** 提出了一种新颖的、通用的黑盒攻击框架HauntAttack，它系统地将有害指令嵌入到推理问题中。具体方法是将推理问题视为载体，并用有害指令替换其原始条件之一，从而创建一个逐步引导模型生成不安全输出的推理路径。

**Result:** 实验结果表明，即使是最先进的LRMs也表现出显著的安全漏洞。此外，对不同模型、各种有害指令类型和模型输出模式的详细分析，为LRMs的安全性提供了有价值的见解。

**Conclusion:** LRMs在处理嵌入了有害指令的推理问题时存在严重的安全漏洞，需要进一步关注其安全-推理权衡。

> **ai_Abstract:** 本文提出了HauntAttack，一个针对大型推理模型（LRMs）的黑盒攻击框架，旨在评估当推理问题中嵌入有害指令时LRMs的安全漏洞。通过将有害指令替换推理问题中的原始条件，HauntAttack能够引导LRMs生成不安全输出。实验结果表明，即使是最先进的LRMs也存在显著的安全漏洞，这强调了在推理能力提升的同时，LRMs在安全-推理权衡方面面临的挑战。

> **摘要翻译:** 大型推理模型（LRMs）在数学和推理任务中表现出色，展现出卓越的能力。然而，推理能力的增强和其内部推理过程的暴露引入了新的安全漏洞。一个令人担忧的问题是：当推理与危害性强烈纠缠时，LRMs会表现出何种安全-推理权衡？为了解决这个问题，我们引入了HauntAttack，一个新颖的、通用的黑盒攻击框架，它系统地将有害指令嵌入到推理问题中。具体来说，我们将推理问题视为载体，并用有害指令替换其原始条件之一。这个过程创建了一个推理路径，其中模型被一步步引导生成不安全输出。基于HauntAttack，我们对多个LRMs进行了全面的实验。我们的结果表明，即使是最先进的LRMs也表现出显著的安全漏洞。此外，我们对不同模型、各种有害指令类型和模型输出模式进行了详细分析，为LRMs的安全性提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [183] [NanoZone: Scalable, Efficient, and Secure Memory Protection for Arm CCA](https://arxiv.org/abs/2506.07034)
> *NanoZone：Arm CCA 的可伸缩、高效和安全的内存保护*

*Shiqi Liu, Yongpeng Gao, Mingyang Zhang, Jie Wang* | **Main category: cs.CR**

**Keywords:** Arm CCA, 内存保护, 机密计算, 细粒度隔离, 代码指针完整性

**Comment:** 

> **TL;DR:** NanoZone 为 Arm CCA 引入了一个三层区域模型和 CPI 机制，以在单个进程内实现可伸缩、高效且安全的细粒度内存保护，解决了现有虚拟机内和进程内隔离的局限性。

**AI_Comments:** NanoZone 在机密计算领域取得了显著进展，通过在单个进程内提供细粒度内存保护，对于缓解 Heartbleed 等复杂的虚拟机内部攻击至关重要。其与 CVM 风格隔离的兼容性以及可接受的性能开销（20% 的开销，但保留 95% 的吞吐量）使其成为增强 Arm CCA 安全性的一项实用且重要的贡献。区域模型和 CPI 的结合同时解决了隔离和控制流完整性问题。

<details>
  <summary>Details</summary>

**Motivation:** Arm 机密计算架构 (CCA) 目前以整个机密虚拟机 (CVM) 的粒度进行隔离，导致虚拟机内部的漏洞（如 Heartbleed）无法得到缓解。现有的最先进技术虽然将隔离粒度缩小到进程级别，但仍无法阻止在同一进程内进行的攻击。此外，以前的飞地内部方案要么速度太慢，要么与 CVM 风格的隔离不兼容。

**Method:** NanoZone 通过一个三层区域模型扩展了 Arm CCA，该模型可以在单个进程内生成无限数量的轻量级隔离域，并保护它们免受内核空间攻击者的侵害。为了阻止域切换滥用，该方案还添加了一个快速的用户级代码指针完整性 (CPI) 机制。研究人员开发了两个原型：一个功能版本在 Arm 官方模拟器上验证了对进程内和内核空间攻击者的抵抗能力，另一个性能版本在 Arm 开发板上评估了服务器应用程序中的会话密钥隔离、内存中键值保护和非易失性内存数据隔离。

**Result:** 与没有细粒度隔离的系统相比，NanoZone 带来了大约 20% 的性能开销，同时保留了 95% 的吞吐量。原型验证了对进程内和内核空间攻击者的抵抗能力，并在会话密钥隔离、内存中键值保护和非易失性内存数据隔离方面进行了评估。

**Conclusion:** NanoZone 为 Arm CCA 提供了一种可伸缩、高效且安全的细粒度内存保护解决方案，有效解决了现有隔离方案的局限性，并在可接受的性能开销下增强了安全性。

> **ai_Abstract:** 本文提出 NanoZone，一种用于 Arm 机密计算架构 (CCA) 的新型内存保护方案，旨在解决当前虚拟机级别和进程级别隔离的局限性。NanoZone 采用一个三层区域模型，在单个进程内创建轻量级、隔离的域，并防止内核空间威胁。它还集成了一个快速的用户级代码指针完整性 (CPI) 机制。原型验证了其对抗进程内和内核空间攻击的有效性，实现了细粒度隔离，仅带来约 20% 的性能开销，同时保留了 95% 的吞吐量。

> **摘要翻译:** Arm 机密计算架构 (CCA) 目前以整个机密虚拟机 (CVM) 的粒度进行隔离，这使得诸如 Heartbleed 等虚拟机内部错误无法得到缓解。现有的最先进技术将其缩小到进程级别，但仍然无法阻止在同一进程内进行枢轴攻击，并且以前的飞地内部方案要么太慢，要么与 CVM 风格的隔离不兼容。我们通过一个三层区域模型扩展了 CCA，该模型可以在单个进程内生成无限数量的轻量级隔离域，同时保护它们免受内核空间攻击者的侵害。为了阻止域切换滥用，我们还添加了一个快速的用户级代码指针完整性 (CPI) 机制。我们开发了两个原型：一个在 Arm 官方模拟器上运行的功能版本，用于验证对进程内和内核空间攻击者的抵抗能力；另一个是性能版本，在 Arm 开发板上评估了服务器应用程序中的会话密钥隔离、内存中键值保护和非易失性内存数据隔离。与没有细粒度隔离的系统相比，NanoZone 带来了大约 20% 的性能开销，同时保留了 95% 的吞吐量。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [192] [Dual-Priv Pruning : Efficient Differential Private Fine-Tuning in Multimodal Large Language Models](https://arxiv.org/abs/2506.07077)
> *双隐私剪枝：多模态大型语言模型中高效的差分隐私微调*

*Qianshan Wei, Jiaqi Li, Zihan You, Yi Zhan, Kecen Li, Jialin Wu, Xinfeng Li Hengjun Liu, Yi Yu, Bin Cao, Yiwen Xu, Yang Liu, Guilin Qi* | **Main category: cs.CR**

**Keywords:** 差分隐私, 多模态大型语言模型, 剪枝, 微调, 隐私保护AI

**Comment:** 

> **TL;DR:** Dual-Priv Pruning引入了两种剪枝机制（视觉token和梯度更新），以实现在多模态大型语言模型（MLLM）中高效且隐私的微调，同时减轻噪声影响和计算开销。

**AI_Comments:** 这篇论文解决了将差分隐私应用于多模态大型语言模型的一个关键挑战，这是一个新颖且重要的领域。所提出的Dual-Priv Pruning框架及其两种互补的剪枝机制（视觉token和梯度更新）是一种创新的方法，旨在减轻高维模型中DP常见的计算开销和效用下降。论文声称是第一个探索MLLM中DP微调的工作，这突显了其开创性及其对隐私保护AI发展的潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私（DP）在保护大型语言模型隐私方面有效，但其在多模态大型语言模型（MLLM）中的有效性仍不确定。将DP应用于MLLM会引入大量的计算开销，并且由于隐私所需的噪声会随参数维度增加而放大，导致模型性能显著下降，使得DP难以应用于复杂的MLLM架构。

**Method:** 本文提出了Dual-Priv Pruning，一个用于MLLM中DP微调的框架。它采用了两种互补的剪枝机制：(i) 视觉token剪枝，通过去除冗余视觉信息来降低输入维度；(ii) DP优化过程中的梯度更新剪枝，该机制根据噪声梯度的大小选择性地剪枝参数更新，旨在减轻噪声影响并提高效用。

**Result:** 实验表明，Dual-Priv Pruning在性能下降最小的情况下取得了有竞争力的结果。它始终比标准DP-SGD占用更少的内存，并在H20 GPU上展现出领先的内存效率，仅比零阶方法多占用1.74%的内存（零阶方法在A100 GPU上存在严重的性能问题）。

**Conclusion:** Dual-Priv Pruning通过提高计算效率和效用，同时保持有竞争力的性能，有效地解决了将差分隐私应用于多模态大型语言模型的挑战，并且是首个探索MLLM中DP微调的工作。

> **ai_Abstract:** 本文介绍了Dual-Priv Pruning，一个旨在利用差分隐私（DP）对多模态大型语言模型（MLLM）进行高效且隐私微调的新颖框架。该方法认识到DP在MLLM中面临的挑战——即高计算开销和噪声导致的显著效用下降——提出了两种剪枝策略：视觉token剪枝以降低输入维度，以及梯度更新剪枝以减轻优化过程中的噪声影响。实验结果表明，Dual-Priv Pruning在性能下降最小的情况下取得了有竞争力的表现，与标准DP-SGD相比显著提高了内存效率，并且是首次探索MLLM中DP微调的方法。

> **摘要翻译:** 差分隐私（DP）是一种广泛采用的技术，因其在保护任务特定数据集隐私方面的有效性而受到重视，使其成为大型语言模型的关键工具。然而，其在多模态大型语言模型（MLLM）中的有效性仍不确定。应用差分隐私（DP）本身会引入大量的计算开销，这对于处理大量文本和视觉数据的MLLM来说尤其重要。此外，DP的一个关键挑战是，隐私所需的注入噪声会随着参数维度的增加而按比例放大，导致模型性能显著下降；这种隐私与效用之间的权衡使得差分隐私（DP）难以应用于MLLM等复杂架构。为了解决这些问题，我们提出了双隐私剪枝（Dual-Priv Pruning），一个在MLLM中采用两种互补剪枝机制进行DP微调的框架：(i) 视觉token剪枝，通过去除冗余视觉信息来降低输入维度；(ii) DP优化过程中的梯度更新剪枝。后一种机制根据噪声梯度的大小选择性地剪枝参数更新，旨在减轻噪声影响并提高效用。实验表明，我们的方法在性能下降最小的情况下取得了有竞争力的结果。在计算效率方面，我们的方法始终比标准DP-SGD占用更少的内存。虽然比零阶方法仅多占用1.74%的内存（零阶方法在A100 GPU上存在严重的性能问题），但我们的方法在H20 GPU上展现出领先的内存效率。据我们所知，我们是第一个探索MLLM中DP微调的研究。我们的代码即将发布。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [199] [Exploiting Inaccurate Branch History in Side-Channel Attacks](https://arxiv.org/abs/2506.07263)
> *利用不准确的分支历史进行侧信道攻击*

*Yuhui Zhu, Alessandro Biondi* | **Main category: cs.CR**

**Keywords:** 分支预测, 侧信道攻击, Spectre, 推测执行, 分支历史注入

**Comment:** 20 pages, 8 figures, to be published in proceedings of the 34th
  USENIX Security Symposium (2025)

> **TL;DR:** 现代CPU的推测执行特性，特别是无偏分支预测和分支历史推测，因共享资源隔离不当，可被利用来引发恶意错误推测。本文揭示了新的分支历史注入（BHI）攻击面，并提出了Spectre-BSE、Spectre-BHS以及跨特权控制流侧信道攻击BiasScope，其中一个攻击演示器Chimera能以24,628比特/秒的速度泄露内核内存。

**AI_Comments:** 这篇论文意义重大，因为它揭示了源自CPU中未充分记录的分支预测特性所带来的新侧信道攻击面。其创新之处在于识别了看似增强性能的机制如何被滥用，从而创建新的错误推测原语，导致新型Spectre类攻击。对高速内核内存泄漏的演示突显了这些漏洞的实际严重性。该研究有助于更深入地理解推测执行的安全风险。

<details>
  <summary>Details</summary>

**Motivation:** 现代乱序CPU的推测执行严重依赖分支预测来优化性能，但当共享分支预测资源缺乏适当的隔离和清理时，它们可能产生安全漏洞，暴露不同软件上下文中的敏感数据。具体而言，本文旨在探究两个广泛实现但文档不足的分支预测单元（BPU）功能——无偏分支预测和分支历史推测——如何引入安全风险，因为它们可能无意中修改分支历史缓冲区（BHB）的更新行为并创建新的恶意错误推测原语。

**Method:** 本文研究了现代分支预测单元（BPU）的基本组成部分，并调查了资源共享和争用如何影响无偏分支预测和分支历史推测这两个特性。研究人员展示了这些功能如何修改BHB更新行为并创建触发恶意错误推测的新原语。基于这些发现，他们提出了三种新颖的攻击原语，并识别了相应的易受攻击控制流模式，在多个处理器上演示了漏洞利用。此外，还提出了一个基于eBPF的攻击演示器Chimera。

**Result:** 结果表明，无偏分支预测和分支历史推测这些BPU功能，虽然旨在提高效率，但会引入重大的安全风险，因为它们无意中修改了分支历史缓冲区（BHB）的更新行为，并创建了触发恶意错误推测的新原语。研究揭示了以前未知的针对分支历史注入（BHI）的跨特权攻击面。文章提出了三种新颖的攻击原语：Spectre-BSE、Spectre-BHS（两种Spectre攻击）和BiasScope（一种跨特权控制流侧信道攻击）。研究识别了相应的易受攻击控制流模式，并在多个处理器上成功演示了漏洞利用。最后，Chimera，一个基于eBPF的Spectre-BHS变体攻击演示器，被证明能够以24,628比特/秒的速度泄露内核内存内容。

**Conclusion:** 本文得出结论，现代CPU中某些特定的分支预测单元（BPU）功能，如无偏分支预测和分支历史推测，通过创建恶意错误推测的新原语，引入了显著的安全风险。这些风险导致了针对分支历史注入（BHI）的全新跨特权侧信道攻击面，并催生了Spectre变体（Spectre-BSE、Spectre-BHS）和BiasScope等新型攻击，这些攻击能够高效地泄露敏感数据。

> **ai_Abstract:** 本文研究了现代CPU中两个未充分记录的分支预测特性：无偏分支预测和分支历史推测，如何引入安全漏洞。研究揭示这些特性可能无意中改变分支历史缓冲区（BHB）的更新方式，从而为恶意错误推测创造新的原语。这导致了新的跨特权分支历史注入（BHI）攻击面。作者提出了三种新型攻击：Spectre-BSE、Spectre-BHS和BiasScope，并在多个处理器上展示了它们的利用。其中，一个名为Chimera的Spectre-BHS变体演示器能够以高速度泄露内核内存。

> **摘要翻译:** 现代乱序CPU严重依赖推测执行进行性能优化，其中分支预测是最小化停顿和最大化效率的基石。当共享分支预测资源缺乏适当的隔离和清理方法时，它们可能会产生安全漏洞，暴露不同软件上下文中的敏感数据。
本文研究了现代分支预测单元（BPU）的基本组成部分，并调查了资源共享和争用如何影响两个广泛实现但文档不足的功能：无偏分支预测（Bias-Free Branch Prediction）和分支历史推测（Branch History Speculation）。我们的分析表明，这些BPU功能虽然旨在通过更准确的分支历史来提高推测执行效率，但也可能引入重大的安全风险。我们展示了这些功能可能无意中修改分支历史缓冲区（BHB）的更新行为，并创建触发恶意错误推测的新原语。
这一发现揭示了以前未知的针对分支历史注入（BHI）的跨特权攻击面。基于这些发现，我们提出了三种新颖的攻击原语：两种Spectre攻击，即Spectre-BSE和Spectre-BHS，以及一种名为BiasScope的跨特权控制流侧信道攻击。我们的研究识别了相应的易受攻击控制流模式，并在多个处理器上展示了漏洞利用。最后，我们展示了Chimera：一个基于eBPF的Spectre-BHS变体攻击演示器，能够以24,628比特/秒的速度泄露内核内存内容。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [201] [Mind the Web: The Security of Web Use Agents](https://arxiv.org/abs/2506.07153)
> *小心网络：网络使用代理的安全性*

*Avishag Shapira, Parth Atulbhai Gandhi, Edan Habler, Oleg Brodt, Asaf Shabtai* | **Main category: cs.CR**

**Keywords:** Web-use agents, LLM security, Task-aligned injection, Attack surface, Web automation

**Comment:** 

> **TL;DR:** 网络使用代理因其高级功能而面临新的安全漏洞，攻击者可通过嵌入恶意内容利用LLM的上下文推理缺陷，实现高成功率的机密性、完整性和可用性攻击。

**AI_Comments:** 这篇论文揭示了一个新兴且重要的安全问题，即AI代理在与网络交互时所面临的风险。其创新之处在于提出了“任务对齐注入”这一新颖的攻击技术，巧妙地利用了大型语言模型在上下文推理方面的固有局限性。研究通过对主流代理的系统性评估，证实了攻击的普遍性和高成功率，这对于指导未来AI代理的安全设计与部署具有重大意义。论文不仅指出了问题，还提出了实用的缓解策略，具有很高的实践价值。

<details>
  <summary>Details</summary>

**Motivation:** 网络使用代理正被广泛部署以自动化复杂的网络任务，它们具有多标签导航、DOM操作、JavaScript执行和认证会话访问等广泛的浏览器功能。然而，这些强大的功能也创造了一个关键且以前未被探索的攻击面，攻击者可以利用这些代理的高权限能力。

**Method:** 研究人员展示了攻击者如何通过在网络页面（如评论、评论或广告）中嵌入恶意内容来利用网络使用代理的高权限能力。他们引入了“任务对齐注入”技术，将恶意命令伪装成有用的任务指导，从而利用大型语言模型（LLMs）上下文推理中的基本局限性。他们通过对四种流行代理（OpenAI Operator, Browser Use, Do Browser, OpenOperator）的系统评估，验证了九种有效载荷类型。

**Result:** 研究展示了九种能够损害机密性、完整性或可用性的有效载荷类型，包括未经授权的摄像头激活、用户冒充、本地文件外泄、密码泄露和拒绝服务。这些有效载荷在多个LLM上进行了验证，成功率达到80%-100%。即使代理内置了安全机制，这些攻击也能成功，仅需要能够发布公共网站内容的能力。

**Conclusion:** 网络使用代理因其易于利用性结合高权限访问，带来了前所未有的风险。为了解决这种攻击，论文提出了全面的缓解策略，包括监督机制、执行约束和任务感知推理技术，为安全开发和部署提供了实用方向。

> **ai_Abstract:** 本论文探讨了网络使用代理（Web-use agents）在自动化网络任务时引入的新型安全漏洞。研究指出，代理的强大浏览器功能（如DOM操作和会话访问）带来了未被探索的攻击面。通过引入“任务对齐注入”技术，攻击者可利用LLM的上下文推理缺陷，将恶意指令伪装成有用的任务指导。通过对四种主流代理的系统评估，论文展示了九种可导致数据泄露、身份冒充和拒绝服务等后果的攻击载荷，成功率高达80%-100%，即使代理内置安全机制也无法幸免。鉴于攻击的易行性和代理的高权限，这带来了前所未有的风险。论文最后提出了监督机制、执行约束和任务感知推理等缓解策略。

> **摘要翻译:** 网络使用代理正在迅速部署以自动化复杂的网络任务，它们以广泛的浏览器功能运行，包括多标签导航、DOM操作、JavaScript执行和认证会话访问。然而，这些强大的功能创造了一个关键且以前未被探索的攻击面。本文展示了攻击者如何通过在网络页面（如评论、评论或广告）中嵌入恶意内容来利用网络使用代理的高权限能力，这些内容是代理在合法浏览任务中遇到的。此外，我们引入了任务对齐注入技术，该技术将恶意命令伪装成有用的任务指导，而不是明显的攻击。这项技术利用了大型语言模型（LLMs）上下文推理中的基本局限性：代理难以保持连贯的上下文感知，并且无法检测看似有用的网络内容何时包含偏离其原始任务目标的引导尝试。通过对四种流行代理（OpenAI Operator、Browser Use、Do Browser、OpenOperator）的系统评估，我们展示了九种损害机密性、完整性和可用性的有效载荷类型，包括未经授权的摄像头激活、用户冒充、本地文件外泄、密码泄露和拒绝服务，并在多个LLM上进行了验证，成功率达到80%-100%。这些有效载荷在内置安全机制的代理中也能成功，仅需要能够在公共网站上发布内容的能力，考虑到易受攻击性与代理高权限访问相结合，这带来了前所未有的风险。为了解决这种攻击，我们提出了全面的缓解策略，包括监督机制、执行约束和任务感知推理技术，为安全开发和部署提供了实用方向。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [209] [A Simulation-based Evaluation Framework for Inter-VM RowHammer Mitigation Techniques](https://arxiv.org/abs/2506.07190)
> *基于仿真的虚拟机间RowHammer缓解技术评估框架*

*Hidemasa Kawasaki, Soramichi Akiyama* | **Main category: cs.CR**

**Keywords:** 虚拟机间RowHammer, 缓解, 仿真, DRAM, 评估框架

**Comment:** Presented in Fifth Workshop on DRAM Security (DRAMSec), June 21, 2025

> **TL;DR:** 由于硬件依赖性，评估虚拟机间RowHammer缓解技术很困难；本文提出了一个仿真框架，可以在各种DRAM映射下进行评估。

**AI_Comments:** 该框架为系统安全领域的一个重要评估挑战提供了实用的解决方案，使研究人员能够更高效、更全面地测试RowHammer缓解措施，而无需特定的硬件配置。其可配置性是关键创新。

<details>
  <summary>Details</summary>

**Motivation:** 现有虚拟机间RowHammer缓解技术的评估成本高昂或不可行，因为缓解能力和开销取决于特定且不同的硬件DRAM地址映射，这使得全面评估变得困难。

**Method:** 本文提出了一种基于仿真的框架，用于评估可配置DRAM地址映射下的基于软件的虚拟机间RowHammer缓解技术。他们展示了如何在框架上重现现有技术。

**Result:** 该框架能够评估具有可配置DRAM地址映射的技术的缓解能力和性能开销。

**Conclusion:** 所提出的基于仿真的框架通过允许可配置的DRAM地址映射，有效地解决了评估虚拟机间RowHammer缓解技术的挑战，从而能够全面评估其缓解能力和开销。

> **ai_Abstract:** 本文解决了评估虚拟机间RowHammer缓解技术的挑战，该挑战因硬件依赖的DRAM地址映射而复杂化。它提出了一个基于仿真的框架，允许可配置的DRAM地址映射，从而能够全面评估基于软件的缓解技术的有效性和性能开销，克服了硬件特定评估的局限性。

> **摘要翻译:** 虚拟机间RowHammer是一种跨越虚拟机(VM)边界诱发位翻转以从一个虚拟机攻击另一个虚拟机的攻击，并且已经提出了一些基于软件的技术来缓解这种攻击。评估这些缓解技术需要确认它们确实以低开销缓解了虚拟机间RowHammer。这个评估过程中的一个挑战是，缓解能力和开销都取决于底层硬件，其DRAM地址映射在不同机器上是不同的。这使得全面评估成本过高甚至不可行，因为可能无法获得具有特定DRAM地址映射的机器。为了解决这个挑战，我们提出了一种基于仿真的框架，用于评估可配置DRAM地址映射下的基于软件的虚拟机间RowHammer缓解技术。我们展示了如何在我们的框架上重现现有的缓解技术，并表明它可以通过可配置的DRAM地址映射评估它们的缓解能力和性能开销。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [217] [Efficient RL-based Cache Vulnerability Exploration by Penalizing Useless Agent Actions](https://arxiv.org/abs/2506.07200)
> *通过惩罚无用代理动作实现高效的基于强化学习的缓存漏洞探索*

*Kanato Nakanishi, Soramichi Akiyama* | **Main category: cs.CR**

**Keywords:** 缓存漏洞, 强化学习, 缓存时序攻击, 探索效率, 代理动作

**Comment:** Presented in Machine Learning for Computer Architecture and Systems
  (MLArchSys), June 21, 2025

> **TL;DR:** 本文提出了一种通过惩罚强化学习代理在缓存漏洞探索中执行的无用动作来提高探索效率的方法，从而显著减少了训练时间和无用动作的数量。

**AI_Comments:** 该论文通过引入对无用代理动作的惩罚机制，有效地解决了基于强化学习的缓存漏洞探索中存在的效率问题。这一创新点在于优化了RL代理的学习过程，使其更专注于有益的探索，从而显著缩短了训练时间，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 分析给定缓存结构对抗缓存时序攻击的漏洞具有挑战性，而现有的基于强化学习的方法因代理执行无用动作而效率低下。

**Method:** 提出了一种在训练过程中识别并惩罚无用动作的方法，使代理避免这些动作，从而提高探索效率。

**Result:** 在17种缓存结构上的实验表明，该训练机制将无用动作的数量减少了高达43.08%，与朴素的基于强化学习的方法相比，训练时间在基本情况下减少了28%，几何平均减少了4.84%。

**Conclusion:** 通过惩罚无用代理动作，可以显著提高基于强化学习的缓存漏洞探索的效率，减少训练时间和无用动作的数量。

> **ai_Abstract:** 本文提出了一种改进基于强化学习（RL）的缓存漏洞探索效率的方法。针对现有RL方法中代理执行无用动作导致效率低下的问题，该研究引入了一种机制，在训练过程中识别并惩罚这些无用动作，从而引导代理避免它们。实验结果表明，该方法显著减少了无用动作的数量和训练时间，证明了其在提高缓存漏洞分析效率方面的有效性。

> **摘要翻译:** 缓存时序攻击利用微架构特性来泄露敏感数据，对现代系统构成严重威胁。尽管其严重性，分析给定缓存结构对抗缓存时序攻击的漏洞具有挑战性。为此，已经提出了一种基于强化学习（RL）的方法来自动探索给定缓存结构的漏洞。然而，朴素的基于RL的方法由于代理执行对探索没有贡献的动作而效率低下。在本文中，我们提出了一种在训练期间识别这些无用动作并惩罚它们的方法，以便代理避免它们并提高探索效率。在17种缓存结构上的实验表明，我们的训练机制将无用动作的数量减少了高达43.08%。与朴素的基于RL的方法相比，这导致训练时间在基本情况下减少了28%，几何平均减少了4.84%。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [232] [SCGAgent: Recreating the Benefits of Reasoning Models for Secure Code Generation with Agentic Workflows](https://arxiv.org/abs/2506.07313)
> *SCGAgent：通过代理工作流重现推理模型在安全代码生成中的优势*

*Rebecca Saul, Hao Wang, Koushik Sen, David Wagner* | **Main category: cs.CR**

**Keywords:** 安全代码生成, 代理工作流, 大型语言模型, 代码安全性, 单元测试

**Comment:** 

> **TL;DR:** SCGAgent是一个安全代码生成代理，它利用代理工作流和安全编码指南，在保持功能性的同时显著提高了代码安全性，并能与复杂的推理LLM媲美。

**AI_Comments:** SCGAgent的创新之处在于，它通过代理工作流，使非推理模型也能实现与复杂推理模型相当甚至更优的安全代码生成性能。这表明，通过巧妙的流程设计和结合领域知识（安全编码指南），可以有效地弥补基础模型在特定能力（如安全性）上的不足，为LLM在关键应用领域（如安全软件开发）的部署提供了新的思路和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大型语言模型（LLM）在代码生成方面取得了广泛成功，但它们不优先考虑安全性，可能生成带有可利用漏洞的代码。

**Method:** 我们提出了生成更安全代码的技术，并引入了SCGAgent，一个主动的安全编码代理。SCGAgent结合了阐明安全编程实践的安全编码指南，并使用LLM生成的单元测试来保持功能正确性，通过代理工作流实现。

**Result:** SCGAgent能够保留基础Sonnet-3.7 LLM近98%的功能性，同时将安全性提高约25%。此外，SCGAgent能够使用非推理模型和代理工作流，匹配或超越复杂推理LLM的性能。

**Conclusion:** SCGAgent通过结合安全编码指南、LLM生成的单元测试和代理工作流，在不牺牲功能性的前提下显著提高了代码安全性，并能与复杂的推理模型相媲美，证明了代理工作流在安全代码生成中的有效性。

> **ai_Abstract:** 本研究提出了SCGAgent，一个旨在提高代码安全性的主动编码代理。该代理结合了安全编码指南和LLM生成的单元测试，以在生成安全代码的同时保持功能正确性。评估结果显示，SCGAgent在保留高功能性的前提下，显著提高了代码安全性，并能与先进的推理模型性能相媲美，这得益于其代理工作流。

> **摘要翻译:** 大型语言模型（LLM）在不同场景（日常和专业）的代码生成任务中取得了广泛成功。然而，当前的LLM尽管能生成功能代码，但并不优先考虑安全性，可能会生成带有可利用漏洞的代码。在这项工作中，我们提出了生成更可能安全的代码的技术，并引入了SCGAgent，一个实现我们技术的主动安全编码代理。我们使用阐明安全编程实践的安全编码指南，并结合LLM生成的单元测试来保持功能正确性。在我们的评估中，我们发现SCGAgent能够保留基础Sonnet-3.7 LLM近98%的功能性，同时将安全性提高约25%。此外，SCGAgent能够使用非推理模型和代理工作流，匹配或超越复杂推理LLM的性能。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [241] [Enhanced Consistency Bi-directional GAN(CBiGAN) for Malware Anomaly Detection](https://arxiv.org/abs/2506.07372)
> *增强一致性双向GAN (CBiGAN) 用于恶意软件异常检测*

*Thesath Wijayasiri, Kar Wai Fok, Vrizlynn L. L. Thing* | **Main category: cs.CR**

**Keywords:** 恶意软件检测, 异常检测, CBiGAN, 静态分析, 深度学习

**Comment:** 

> **TL;DR:** CBiGAN通过将二进制内容转化为图像，利用重建误差进行恶意软件异常检测，并取得了高准确率。

**AI_Comments:** 该论文的创新点在于将二进制文件内容转换为图像，并将其与CBiGAN结合用于恶意软件异常检测，有效利用了深度学习在图像识别领域的优势。这种方法有望提高对新型和未知恶意软件的检测能力，但其对不同文件类型和复杂恶意软件变体的泛化能力可能需要进一步研究和验证。

<details>
  <summary>Details</summary>

**Motivation:** 传统的静态分析依赖于有偏差或过时的数据集，导致对新兴恶意软件威胁的检测能力存在不足。

**Method:** 将文件的二进制内容转换为图像作为深度学习模型的输入，并应用增强一致性双向GAN (CBiGAN) 及其基于重建误差的异常检测方法来建模复杂的恶意软件模式。模型在包括可移植可执行文件 (PE) 和对象链接与嵌入 (OLE) 文件在内的多个数据集上进行了评估。

**Result:** CBiGAN实现了高曲线下面积 (AUC) 结果和良好的泛化能力，能够以相当高的准确率区分良性文件和各种恶意文件。

**Conclusion:** 增强一致性双向GAN (CBiGAN) 是一种有效且鲁棒的恶意软件异常检测方法，能够以高准确率区分良性文件和多样化的恶意文件。

> **ai_Abstract:** 本文提出了一种基于增强一致性双向GAN (CBiGAN) 的恶意软件异常检测方法，旨在解决传统静态分析中数据集偏差和过时的问题。该方法将文件的二进制内容转换为图像，并利用CBiGAN的重建误差进行异常检测。实验结果表明，CBiGAN在区分良性文件和多种恶意文件方面表现出高准确率、高AUC和良好的泛化能力。

> **摘要翻译:** 静态分析作为网络安全领域的基石技术，通过分析休眠软件而不执行潜在有害代码，提供了一种非侵入性的恶意软件检测方法。然而，传统的静态分析通常依赖于有偏差或过时的数据集，导致在应对新兴恶意软件威胁时检测能力存在差距。为了解决这个问题，我们的研究侧重于将文件的二进制内容作为恶意软件检测的关键特征。这些二进制内容被转换并表示为图像，然后作为深度学习模型的输入。这种方法考虑了二进制数据中的视觉模式，使模型能够有效地分析潜在的恶意软件。本文介绍了CBiGAN在恶意软件异常检测领域的应用。我们的方法利用CBiGAN卓越的潜在空间映射能力，这对于通过使用基于重建误差的异常检测方法建模复杂的恶意软件模式至关重要。我们使用了包括可移植可执行文件 (PE) 和对象链接与嵌入 (OLE) 文件在内的多个数据集。然后，我们针对多样化的PE和OLE文件集（包括从214个恶意软件家族中自行收集的恶意可执行文件）评估了我们的模型。我们的研究结果证明了这种创新方法的鲁棒性，CBiGAN取得了高曲线下面积 (AUC) 结果和良好的泛化能力，从而证实了其以相当高的准确率区分良性文件和各种恶意文件的能力。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [250] [From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks](https://arxiv.org/abs/2506.07392)
> *从静态防御到自适应防御：联邦多智能体深度强化学习驱动的无人机蜂群网络中DoS攻击的动态目标防御*

*Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Tian Qin, Yuyu Zhao* | **Main category: cs.CR**

**Keywords:** 无人机蜂群网络, 动态目标防御, 联邦多智能体深度强化学习, DoS攻击, 网络安全

**Comment:** 13pages; In submission

> **TL;DR:** 本文提出了一种基于联邦多智能体深度强化学习（FMADRL）的动态目标防御（MTD）框架，用于主动和自适应地缓解无人机蜂群网络中的DoS攻击，并通过仿真验证了其显著优于现有技术。

**AI_Comments:** 这项研究的创新之处在于将联邦多智能体深度强化学习与动态目标防御相结合，为无人机蜂群网络中的DoS攻击提供了一种自适应、分布式且高效的解决方案。通过避免原始数据共享，该方法解决了分布式学习中的隐私和通信开销问题，对于资源受限的无人机网络具有重要意义。其显著的性能提升表明了该框架在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 无人机蜂群网络因其开放的无线环境、动态拓扑和资源限制，极易受到拒绝服务（DoS）攻击。传统的静态或集中式防御机制在应对这种动态和分布式场景时往往不足。

**Method:** 提出了一种联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架。设计了三种轻量级且协调的MTD机制：领导者切换、路由变异和频率跳变。将防御问题建模为多智能体部分可观测马尔可夫决策过程（POMDP）。每个无人机配备本地策略智能体，通过基于策略梯度的FMADRL算法，利用奖励加权聚合协作优化防御策略，实现不共享原始数据的分布式学习。

**Result:** 仿真结果表明，该方法在攻击缓解率方面提高了34.6%，平均恢复时间缩短了94.6%，能耗降低了29.3%，防御成本降低了98.3%，同时在各种DoS攻击策略下保持了任务的鲁棒连续性。

**Conclusion:** 该研究提出了一种有效的联邦多智能体深度强化学习驱动的动态目标防御框架，能够显著提高无人机蜂群网络在DoS攻击下的韧性、效率和任务连续性。

> **ai_Abstract:** 本文提出了一种新颖的联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架，旨在主动和自适应地缓解无人机蜂群网络中的拒绝服务（DoS）攻击。该框架设计了领导者切换、路由变异和频率跳变三种轻量级且协调的MTD机制。防御问题被建模为多智能体部分可观测马尔可夫决策过程，其中无人机通过基于策略梯度的FMADRL算法协作优化其防御策略，实现分布式学习并减少通信开销。广泛的仿真实验证明，该方法在攻击缓解率、恢复时间、能耗和防御成本方面均显著优于现有技术，同时保持了任务的鲁棒性。

> **摘要翻译:** 无人机（UAV）蜂群的普及使得广泛的任务关键型应用成为可能，但由于其开放的无线环境、动态拓扑和资源限制，也使无人机网络面临严重的拒绝服务（DoS）威胁。传统的静态或集中式防御机制往往不足以应对这种动态和分布式场景。为了解决这些挑战，我们提出了一种新颖的联邦多智能体深度强化学习（FMADRL）驱动的动态目标防御（MTD）框架，用于在无人机蜂群网络中主动和自适应地缓解DoS攻击。具体而言，我们设计了三种轻量级且协调的MTD机制，包括领导者切换、路由变异和频率跳变，这些机制利用无人机蜂群固有的灵活性来扰乱攻击者的努力并增强网络韧性。防御问题被建模为多智能体部分可观测马尔可夫决策过程（POMDP），捕捉了受攻击下无人机蜂群的分布式、资源受限和不确定性。每架无人机都配备了一个本地策略智能体，该智能体根据部分观测和本地经验自主选择MTD动作。通过采用基于策略梯度的FMADRL算法，无人机通过奖励加权聚合协作优化其防御策略，实现不共享原始数据的分布式学习，从而减少通信开销。广泛的仿真表明，我们的方法显著优于现有技术，在攻击缓解率方面提高了34.6%，平均恢复时间缩短了94.6%，能耗和防御成本分别降低了29.3%和98.3%，同时在各种DoS攻击策略下保持了任务的鲁棒连续性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [259] [Beyond Jailbreaks: Revealing Stealthier and Broader LLM Security Risks Stemming from Alignment Failures](https://arxiv.org/abs/2506.07402)
> *超越越狱：揭示源于对齐失败的更隐蔽、更广泛的LLM安全风险*

*Yukai Zhou, Sibei Yang, Wenjie Wang* | **Main category: cs.CR**

**Keywords:** LLM安全, 隐性危害, 对齐失败, JailFlipBench, 安全风险

**Comment:** 

> **TL;DR:** 本文揭示了一种新的LLM安全风险，称为“隐性危害”，即看似无害的输入却导致危险的不正确输出。为此，论文提出了JailFlipBench基准和攻击方法来识别这些风险。

**AI_Comments:** 这篇论文提出了一个超越传统越狱攻击的LLM安全新视角，具有重要意义。通过关注源于对齐失败的“隐性危害”，并提出新的基准（JailFlipBench）和攻击方法，它解决了LLM在实际部署中一个关键且被忽视的风险领域。这项工作通过推动对潜在危害更全面的理解，对推进LLM安全和对齐研究至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 目前的越狱攻击主要关注明显有害的查询，但忽略了一个关键风险：大型语言模型（LLM）错误回答看似无害的输入也可能造成危险和现实世界损害（隐性危害）。本文旨在通过重新构建LLM风险格局来揭示这一被忽视的高风险区域。

**Method:** 作者通过基于输出事实性和输入无害性的结构化象限视角，系统地重新构建了LLM风险格局。为了调查这一空白，他们提出了JailFlipBench，一个旨在捕捉隐性危害的基准，涵盖单模态、多模态和事实扩展场景，并采用多样化的评估指标。此外，他们还开发了初始的JailFlip攻击方法，并对多个开源和黑盒LLM进行了全面评估。

**Result:** 评估结果表明，隐性危害带来了即时和紧迫的现实世界风险。

**Conclusion:** 研究结果呼吁在传统越狱范式之外进行更广泛的LLM安全评估和对齐。

> **ai_Abstract:** 本文识别出一种新的LLM安全风险，称为“隐性危害”，即看似无害的输入却导致危险的不正确输出，这与传统的越狱攻击不同。论文重新构建了LLM风险格局，提出了JailFlipBench基准来评估这种危害在各种场景下的表现，并开发了JailFlip攻击方法。全面的评估揭示了隐性危害带来了即时的现实世界风险，强调了在当前越狱范式之外进行更广泛LLM安全评估的必要性。

> **摘要翻译:** 大型语言模型 (LLM) 越来越多地部署在实际应用中，引发了对其安全性的担忧。虽然越狱攻击突出了在明显有害查询下的失败，但它们忽略了一个关键风险：错误回答看似无害的输入可能是危险的，并造成现实世界的损害（隐性危害）。我们通过基于输出事实性和输入无害性的结构化象限视角，系统地重新构建了LLM风险格局，揭示了一个被忽视的高风险区域。为了调查这一空白，我们提出了JailFlipBench，一个旨在捕捉隐性危害的基准，涵盖单模态、多模态和事实扩展场景，并采用多样化的评估指标。我们进一步开发了初始的JailFlip攻击方法，并对多个开源和黑盒LLM进行了全面评估，结果表明隐性危害带来了即时和紧迫的现实世界风险，呼吁在传统越狱范式之外进行更广泛的LLM安全评估和对齐。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [265] [Enhancing Watermarking Quality for LLMs via Contextual Generation States Awareness](https://arxiv.org/abs/2506.07403)
> *错误：AI分析失败。*

*Peiru Yang, Xintian Li, Wanchun Ni, Jinhua Yin, Huili Wang, Guoshun Nan, Shangguang Wang, Yongfeng Huang, Tao Qi* | **Main category: cs.CR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [269] [Pixel-Sensitive and Robust Steganography Based on Polar Codes](https://arxiv.org/abs/2506.07404)
> *基于极性码的像素敏感鲁棒隐写术*

*Yujun Ji, Jinsheng Li, Ling Liu, Qi Cao, Tao Dai* | **Main category: cs.CR**

**Keywords:** 隐写术, 极性码, 鲁棒性, 速率-失真, 自适应失真

**Comment:** 

> **TL;DR:** 本文提出了一种基于极性码的像素敏感鲁棒隐写方案，该方案在某些情况下可以达到嵌入容量，并能有效抵抗复杂的噪声攻击。

**AI_Comments:** 本文的创新点在于将极性码应用于像素敏感的鲁棒隐写术设计，有效解决了传统方法在面对不同强度噪声攻击时的不足。其在特定条件下达到嵌入容量并实现低错误率的实验结果，凸显了该方案在信息隐藏领域的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的隐写编码方法无法抵抗每个噪声元素具有不同强度的自适应攻击，而隐写术设计的核心问题是速率-失真编码问题。

**Method:** 本文提出了一种基于极性码的像素敏感鲁棒隐写方案。该方案旨在很好地匹配自适应失真，并且对复杂的噪声攻击具有鲁棒性。

**Result:** 实验证明，该方案在某些情况下可以达到嵌入容量，并且当发送方和接收方都知道攻击噪声时，可以实现秘密消息错误率在10^-5级别的隐写方案，这表明其具有显著的鲁棒性。

**Conclusion:** 本文提出的基于极性码的像素敏感鲁棒隐写方案，不仅能很好地匹配自适应失真，而且对复杂的噪声攻击具有显著的鲁棒性，并在某些情况下实现了嵌入容量。

> **ai_Abstract:** 针对现有隐写编码方法在自适应攻击下抵抗能力不足的问题，本文提出了一种基于极性码的像素敏感鲁棒隐写方案。该方案利用极性码能够达到速率-失真界限的特性，旨在匹配自适应失真并抵抗复杂的噪声攻击。实验证明，该方案在某些情况下能达到嵌入容量，并能在攻击噪声已知的情况下，实现10^-5级别的秘密消息错误率，展现出显著的鲁棒性。

> **摘要翻译:** 隐写术是一种用于秘密通信的信息隐藏技术。隐写术设计的核心问题是速率-失真编码问题。极性码已被证明可以为任何二元对称源实现速率-失真界限，本文利用极性码设计了一种隐写方案，在某些情况下可以达到失真受限发送方问题的嵌入容量。在自适应隐写术中，对于每个噪声元素可能具有不同强度的攻击场景，现有的隐写编码方法无法抵抗此类攻击。在本文中，我们提出了一种基于极性码的像素敏感鲁棒隐写方案。我们的隐写方案不仅能很好地匹配自适应失真，而且对复杂的噪声攻击具有鲁棒性。此外，证明了我们的方案在某些情况下实现了嵌入容量。实验表明，当发送方和接收方都知道攻击噪声时，可以设计并实现秘密消息错误率在10^-5级别的隐写方案。这表明其具有显著的鲁棒性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [277] [Explainable AI for Enhancing IDS Against Advanced Persistent Kill Chain](https://arxiv.org/abs/2506.07480)
> *可解释AI增强IDS对抗高级持续性杀伤链*

*Bassam Noori Shaker, Bahaa Al-Musawi, Mohammed Falih Hassan* | **Main category: cs.CR**

**Keywords:** 高级持续性威胁, 入侵检测系统, 可解释人工智能, 特征选择, XGBoost

**Comment:** 

> **TL;DR:** 本研究提出了一种结合SHAP和XGBoost的可解释人工智能（XAI）增强型入侵检测系统（IDS），用于检测高级持续性威胁（APT），通过精选少量关键特征，在SCVIC-APT-2021数据集上实现了高性能和模型轻量化。

**AI_Comments:** 该研究通过结合SHAP和XGBoost，在IDS领域引入了可解释性，这对于网络安全威胁检测的透明度和决策支持至关重要。其创新点在于能够从大量特征中智能选择出极少数最具影响力的特征，从而构建了一个既高效又轻量级的检测模型。这一方法在降低模型复杂性的同时，保持甚至提升了检测性能，对于实际部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 高级持续性威胁（APT）是复杂且持续的网络安全挑战，其特点是隐蔽、多阶段和有针对性的攻击。开发有效的入侵检测系统（IDS）需要精确选择网络流量特征，但并非所有特征都与APT阶段直接相关，这限制了IDS的性能。因此，需要识别并分析最相关的特征以提升IDS的检测能力。

**Method:** 本研究提出了一种特征选择与分类模型，该模型集成了SHapley Additive exPlanations (SHAP) 和 Extreme Gradient Boosting (XGBoost) 两种机器学习算法。旨在通过选择最少数量的有影响力特征来开发轻量级IDS，以检测APT的各个阶段。该方法还独立地指定了APT每个阶段的相关特征。

**Result:** 在SCVIC-APT-2021数据集上进行了广泛实验，结果表明所提出的方法比其他标准技术性能有所提高。宏观平均F1分数达到94%，召回率达到93%。同时，通过从77个特征中仅选择12个特征，显著降低了检测模型的复杂性。

**Conclusion:** 本研究提出的结合SHAP和XGBoost的特征选择与分类模型，能够有效地增强IDS在APT检测方面的性能，通过识别并利用关键特征，实现了一个轻量级且高效的系统。

> **ai_Abstract:** 本论文提出了一种利用可解释人工智能（XAI）增强的入侵检测系统（IDS），以有效对抗高级持续性威胁（APT）。该系统集成了SHAP进行特征选择和XGBoost进行分类，旨在通过识别并利用最少数量的关键网络流量特征来构建轻量级IDS。在SCVIC-APT-2021数据集上的实验结果表明，与现有技术相比，该方法在性能上有所提升，F1分数达到94%，召回率达到93%，同时将模型复杂性从77个特征显著降低至12个特征。

> **摘要翻译:** 高级持续性威胁（APT）代表着一种复杂且持续的网络安全挑战，其特点是隐蔽的、多阶段的、有针对性的攻击，旨在长期渗透信息系统。开发一种能够检测不同阶段APT的有效入侵检测系统（IDS）依赖于选择网络流量特征。然而，并非所有这些特征都与APT的阶段直接相关。一些网络流量特征可能不相关或与识别恶意活动的相关性有限。因此，仔细选择和分析最相关的特征以提高IDS性能至关重要。这项工作提出了一种特征选择和分类模型，该模型集成了两种著名的机器学习算法：SHapley Additive exPlanations (SHAP) 和 Extreme Gradient Boosting (XGBoost)。其目标是基于选定的最少数量的有影响力的特征来开发轻量级IDS，以检测各个阶段的APT。所提出的方法还独立地指定了APT每个阶段的相关特征。在SCVIC-APT-2021数据集上进行的广泛实验结果表明，我们提出的方法与其他标准技术相比，性能有所提高。具体而言，宏观平均F1分数和召回率分别达到94%和93%，同时通过从77个特征中仅选择12个特征，降低了检测模型的复杂性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [283] [MalGEN: A Generative Agent Framework for Modeling Malicious Software in Cybersecurity](https://arxiv.org/abs/2506.07586)
> *MalGEN：网络安全中恶意软件建模的生成式智能体框架*

*Bikash Saha, Sandeep Kumar Shukla* | **Main category: cs.CR**

**Keywords:** 大型语言模型, 网络安全, 恶意软件, 生成式智能体, MalGEN

**Comment:** 

> **TL;DR:** MalGEN是一个多智能体框架，用于模拟对抗性行为以生成规避性恶意软件样本，帮助评估和加强网络安全防御系统。

**AI_Comments:** MalGEN的创新之处在于其将LLM滥用风险转化为主动防御机会的理念，通过多智能体框架模拟AI驱动的恶意软件生成，这在当前研究中是一个重要的空白。它为网络安全研究人员提供了一个道德且受控的环境来合成和测试新型威胁，对于提升防御能力、解决数据稀缺以及开发面向未来的检测策略具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的双重用途对网络安全构成日益增长的挑战，它们可能被滥用生成规避性、AI制作的恶意软件。然而，研究社区目前缺乏受控且可扩展的工具来模拟这种行为，以进行测试和防御准备。

**Method:** 本文提出了MalGEN，一个多智能体框架，它通过模拟协调的对抗性行为来生成多样化、活动驱动的恶意软件样本。该框架中的智能体协同工作，在受控环境中模拟攻击者工作流程，包括载荷规划、能力选择和规避策略。研究人员使用MalGEN合成了十个新型恶意软件样本，并针对领先的防病毒和行为检测引擎进行了评估。

**Result:** 多个样本表现出隐蔽和规避特性，成功绕过了当前的防御系统，验证了MalGEN建模复杂新威胁的能力。

**Conclusion:** MalGEN将LLM滥用的威胁转化为主动防御的机会，提供了一个有价值的框架，用于评估和加强网络安全系统。该框架解决了数据稀缺问题，实现了严格的测试，并支持开发有弹性和面向未来的检测策略。

> **ai_Abstract:** 该研究提出了MalGEN，一个多智能体框架，旨在模拟并生成由大型语言模型（LLMs）驱动的规避性恶意软件样本。鉴于LLMs在网络安全中潜在的滥用风险以及当前缺乏模拟此类威胁的工具，MalGEN通过模拟攻击者工作流程来合成多样化的恶意软件。实验结果表明，MalGEN生成的样本能够绕过现有防御系统，验证了其建模复杂威胁的能力。MalGEN为网络安全系统提供了一个评估和强化的工具，有助于解决数据稀缺问题并支持未来检测策略的开发。

> **摘要翻译:** 大型语言模型（LLMs）的双重用途在网络安全领域提出了日益严峻的挑战。虽然LLM增强了防御者的自动化和推理能力，但它们也带来了新的风险，特别是它们可能被滥用以生成规避性、AI制作的恶意软件。尽管存在这种新兴威胁，但研究社区目前缺乏受控且可扩展的工具来模拟此类行为，以进行测试和防御准备。我们提出了MalGEN，一个多智能体框架，它模拟协调的对抗性行为，以生成多样化、活动驱动的恶意软件样本。这些智能体在为道德和防御性研究而构建的受控环境中协同工作，模拟攻击者工作流程，包括载荷规划、能力选择和规避策略。使用MalGEN，我们合成了十个新型恶意软件样本，并针对领先的防病毒和行为检测引擎进行了评估。多个样本表现出隐蔽和规避特性，成功绕过了当前的防御系统，验证了MalGEN建模复杂新威胁的能力。通过将LLM滥用的威胁转化为主动防御的机会，MalGEN提供了一个有价值的框架，用于评估和加强网络安全系统。该框架解决了数据稀缺问题，实现了严格的测试，并支持开发有弹性和面向未来的检测策略。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [300] ["I wasn't sure if this is indeed a security risk": Data-driven Understanding of Security Issue Reporting in GitHub Repositories of Open Source npm Packages](https://arxiv.org/abs/2506.07728)
> *“我不太确定这是否确实是一个安全风险”：对开源npm包GitHub仓库中安全问题报告的数据驱动理解*

*Rajdeep Ghosh, Shiladitya De, Mainack Mondal* | **Main category: cs.CR**

**Keywords:** 安全问题报告, npm, GitHub, 开源安全, 机器学习

**Comment:** This extended version of our USENIX Security '25 paper on Security
  issue reporting in NPM packages includes appendices for interested readers

> **TL;DR:** 研究发现，npm开源项目中大量未标记的安全问题未得到解决，现有自动化工具不足，需要更智能的工具和更好的协作。

**AI_Comments:** 这篇论文通过大规模数据分析揭示了开源项目（特别是npm生态系统）中安全问题报告和处理的真实图景，具有重要的实践意义。其创新之处在于结合了人工分析和机器学习模型来识别被忽视的安全问题，挑战了当前自动化工具的有效性。论文强调了用户-开发者交互中安全问题处理的不足，并指出了改进方向，即需要更智能的工具和更好的协作。这对于开源社区的安全管理和漏洞响应具有指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 尽管npm生态系统中安全漏洞报告和解决已被广泛研究，但用户（和机器人）报告安全问题的实际情况及其相关挑战在大规模研究中相对较少探索。本文旨在弥补这一空白。

**Method:** 收集了来自45,466个不同npm包的GitHub仓库中的10,907,467个问题报告。通过人工分析，然后开发高精度机器学习模型，识别出未标记为安全相关的问题。

**Result:** 标签显示只有0.13%的问题是安全相关的。通过分析识别出1,617,738个未标记为安全相关的问题（占总问题的14.8%）是安全相关的，以及这些问题上的4,461,934条评论。现有机器人不足以检测或提供帮助。许多用户报告的安全问题可能未被开发者处理，它们未被标记为安全相关且可能在没有正当理由的情况下被关闭。开发者能快速处理有已知解决方案（如CVE）的安全问题。没有已知解决方案（即使有可复现代码）的安全问题可能未被解决。

**Conclusion:** 研究结果为改进开源生态系统中的安全管理提供了可操作的见解，强调了对更智能工具和更好协作的需求。

> **ai_Abstract:** 本文通过对GitHub上npm包的大规模问题报告进行数据驱动分析，揭示了开源生态系统中安全问题报告的实际挑战。研究发现，大量安全问题未被正确标记和处理，现有自动化工具不足以有效识别和解决这些问题。作者指出，开发者倾向于处理有已知解决方案的安全问题，而那些没有已知解决方案的问题常被忽视。研究强调了开发更智能工具和加强协作以改善开源安全管理的必要性。

> **摘要翻译:** npm（Node Package Manager）生态系统是JavaScript开发最重要的包管理器，拥有数百万用户。因此，大量早期工作研究了如何促进此类生态系统中的漏洞报告、补丁传播以及安全问题的检测和解决。然而，用户（和机器人）报告安全相关问题的实际情况及其相关挑战在大规模研究中相对较少探索。在这项工作中，我们通过收集来自45,466个不同npm包的GitHub仓库中的10,907,467个问题报告来弥补这一空白。我们发现，与这些问题相关的标签表明只有0.13%的安全相关问题。然而，我们采用人工分析，然后开发高精度机器学习模型的方法识别出1,617,738个未标记为安全相关的问题（占所有问题的14.8%）以及对这些问题提出的4,461,934条评论。我们发现，当今广泛使用的机器人可能不足以检测或提供帮助。此外，我们对用户-开发者交互数据的分析表明，许多用户报告的安全问题可能未被开发者处理——它们未被标记为安全相关问题，并且可能在没有正当理由的情况下被关闭。因此，相关性分析表明，开发者能快速处理有已知解决方案（例如，对应CVE）的安全问题。然而，没有已知解决方案（即使有可复现代码）的安全问题可能未被解决。我们的发现为改进开源生态系统中的安全管理提供了可操作的见解，强调了对更智能工具和更好协作的需求。这项工作的数据和代码可在https://doi.org/10.5281/zenodo.15614029获取。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [306] [User-space library rootkits revisited: Are user-space detection mechanisms futile?](https://arxiv.org/abs/2506.07827)
> *用户空间库rootkit再探：用户空间检测机制是否徒劳？*

*Enrique Soriano-Salvador, Gorka Guardiola Múzquiz, Juan González Gómez* | **Main category: cs.CR**

**Keywords:** 用户空间rootkit, 检测机制, 进程隐藏, Linux安全, 反rootkit

**Comment:** 

> **TL;DR:** 研究表明，用于检测用户空间rootkit的用户空间工具是无效的，因为它们可以被规避。

**AI_Comments:** 这篇论文挑战了安全领域中一个普遍存在的假设，即用户空间rootkit易于检测。其发现对于用户空间安全工具的有效性提出了重要质疑，并强调了需要更复杂的跨层检测机制。论文通过实验验证了其主张，并提供了实用的改进建议，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管用户空间rootkit仍构成重大威胁，但人们普遍认为它们易于被用户空间工具检测到，而所有关注都集中在内核空间rootkit上。本研究旨在反驳这一假设。

**Method:** 通过在Linux系统上进行针对进程隐藏的实验，规避了被广泛接受的用户空间反rootkit工具的检测机制。

**Result:** 结果表明，用户空间rootkit的检测根本无法在用户空间完成，且检测结果必须极其谨慎地传达给用户。

**Conclusion:** 传统的用户空间rootkit检测机制是无效的，并提供了实现新检测工具和改进现有工具的指导。

> **ai_Abstract:** 本文探讨了用户空间rootkit的检测问题，挑战了普遍认为用户空间工具可以有效检测它们的观点。通过在Linux系统上进行实验，研究表明用户空间检测机制容易被规避，尤其是在进程隐藏方面。因此，作者得出结论，用户空间rootkit无法在用户空间完全检测，并强调了检测结果沟通的谨慎性，同时提供了改进检测工具的指导。

> **摘要翻译:** 恶意软件旨在隐藏恶意系统资源（例如进程、网络连接、文件等），通常被称为rootkit。这种恶意软件在当代系统中构成了重大威胁。尽管存在内核空间rootkit（即感染操作系统内核的rootkit），用户空间rootkit（即感染用户空间操作系统工具、命令和库的rootkit）仍然构成重大危险。然而，内核空间rootkit吸引了所有注意力，这隐含地假设用户空间rootkit（仍然存在的恶意软件）很容易通过寻找异常的知名用户空间工具检测到。这项工作的主要目的是回答以下问题：使用用户空间工具检测用户空间rootkit是否徒劳？与普遍认为其有效的观点相反，我们认为用户空间rootkit的检测根本无法在用户空间完成。此外，检测结果必须极其谨慎地传达给用户。为了支持这一主张，我们进行了不同的实验，重点关注Linux系统中的进程隐藏。在这些实验中，我们规避了被广泛接受为此类用户空间恶意软件标准解决方案的检测机制，绕过了最流行的开源进程隐藏反rootkit工具。本手稿描述了构建用户空间库rootkit的经典方法、传统检测机制以及不同的规避技术（它还包括易于理解的代码片段和示例）。此外，它还提供了一些实现新检测工具和尽可能改进现有工具的指导方针。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [314] [Securing Unbounded Differential Privacy Against Timing Attacks](https://arxiv.org/abs/2506.07868)
> *保护无界差分隐私免受时序攻击*

*Zachary Ratliff, Salil Vadhan* | **Main category: cs.CR**

**Keywords:** 差分隐私, 时序攻击, 无界DP, JOT-DP, 计算模型

**Comment:** 

> **TL;DR:** 现有针对无界差分隐私的JOT-DP方法存在误差、效率和计算模型限制。本文通过分析误差与计算模型（RAM与随机比特）的关系，并提供高效的转换程序来克服这些限制。

**AI_Comments:** 本文通过详细分析计算模型对抵御时序攻击的差分隐私保证的影响，特别是在无界数据集方面，展现了创新性。它超越了简化的假设，提供了更实际和高效的解决方案，解决了先前工作的实际限制。对RAM模型和随机比特模型之间区别的区分对于实际实现具有特别深刻的见解。

<details>
  <summary>Details</summary>

**Motivation:** 现有的JOT-DP方法在无界差分隐私（适用于任意大数据集）设置中存在局限性，包括导致常数加性错误概率（无法实现误差消失）、未能保持原始程序的计算效率，以及在过于简化的计算模型（运行时仅定义为抛硬币次数）下进行分析。

**Method:** 本文研究了在无界设置中纯JOT-DP所需的误差与计算模型的关系。作者提出了将上界设置中的纯JOT-DP程序高效转换为无界设置中纯JOT-DP程序的方法。这些转换程序确保新程序的输出分布与原程序在总变差距离上接近，其接近度（γ）根据所使用的计算模型而异。

**Result:** 在随机RAM模型中（数据集大小n已知或可快速计算，且可快速生成随机数），多项式小误差概率是必要且充分的。如果数据集大小n未知或仅有随机比特生成器，则任意小的常数误差概率是必要且充分的。这些积极结果通过高效的转换程序得以证明。

**Conclusion:** 本文克服了现有无界差分隐私JOT-DP方法的局限性，证明了所需误差取决于计算模型，并提供了高效的转换方法，从而在更实际的模型下实现了误差消失和效率保持。

> **ai_Abstract:** 本文解决了现有联合输出和运行时差分隐私（JOT-DP）方法在无界差分隐私应用中的局限性，特别是关于误差累积、计算效率低下以及对简化计算模型的依赖。作者证明了在无界设置中纯JOT-DP的必要错误概率取决于计算模型。他们表明，在随机RAM模型中可以实现多项式小误差，而仅使用随机比特生成器时只能实现常数误差。这项工作提供了高效的转换程序来实现这些结果，从而提高了JOT-DP在处理大型数据集时的实用性和理论理解。

> **摘要翻译:** 最近的工作开始从理论上研究如何通过使输出和运行时的联合分布具有差分隐私性（JOT-DP）来保护差分隐私程序免受时序攻击。然而，现有的JOT-DP方法存在一些局限性，特别是在无界差分隐私（保护数据集大小并适用于任意大数据集）的设置中。首先，在无界设置中将纯DP程序转换为纯JOT-DP程序的已知方法：(a) 会导致错误概率的常数加性增加（因此当n→∞时不会产生消失误差）；(b) 生成的JOT-DP程序未能保持原始纯DP程序的计算效率；(c) 在一个玩具计算模型中进行分析，其中运行时被定义为抛硬币的次数。在这项工作中，我们克服了这些局限性。具体来说，我们表明，在无界设置中纯JOT-DP所需的误差取决于计算模型。在随机RAM模型中，如果数据集大小n已知（或可以在常数时间内计算）并且我们可以在常数时间内生成随机数（而不仅仅是随机比特），则多项式小误差概率是必要且充分的。如果n未知或我们只有随机比特生成器，则（任意小的）常数误差概率是必要且充分的。上述积极结果是通过高效的程序证明的，这些程序将上界设置中的任何纯JOT-DP程序P转换为无界设置中的纯JOT-DP程序P'，使得P'的输出分布在总变差距离上与P的输出分布γ-接近，其中γ是任意小的常数或多项式小，具体取决于计算模型。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [318] [Evaluating explainable AI for deep learning-based network intrusion detection system alert classification](https://arxiv.org/abs/2506.07882)
> *评估用于基于深度学习的网络入侵检测系统告警分类的可解释AI*

*Rajesh Kalakoti, Risto Vaarandi, Hayretdin Bahsi, Sven Nõmm* | **Main category: cs.CR**

**Keywords:** 可解释AI, 网络入侵检测系统, 深度学习, 告警分类, DeepLIFT

**Comment:** Accepted version of a paper published in the Proceedings of the 11th
  International Conference on Information Systems Security and Privacy (ICISSP
  2025). Final version available via SCITEPRESS

> **TL;DR:** 深度学习NIDS告警量巨大，缺乏透明度。本研究评估了用于NIDS告警分类的可解释AI方法，发现DeepLIFT表现最佳，提高了信任和可解释性。

**AI_Comments:** 这篇论文解决了网络安全领域一个实际且重要的问题：NIDS告警泛滥及其深度学习模型缺乏透明度。其创新点在于系统地比较了多种XAI方法，并结合真实世界数据和SOC分析师的专业知识对结果进行了验证，这大大增强了研究成果的实用性和可信度。DeepLIFT被确认为表现最佳的XAI方法，为未来的NIDS研究提供了有价值的方向。论文强调了人机协作在AI系统部署中的重要性，对提升AI在关键领域的可接受度具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 网络入侵检测系统（NIDS）每天产生大量告警，使分析师难以优先处理高优先级威胁。尽管深度学习模型有望自动化NIDS告警的优先级排序，但其缺乏透明度会削弱对决策的信任。因此，本研究强调了在NIDS告警分类中对可解释人工智能（XAI）的迫切需求，以提高信任和可解释性。

**Method:** 本研究使用了爱沙尼亚塔林理工大学（TalTech）安全运营中心（SOC）的真实NIDS告警数据集，开发了一个长短期记忆（LSTM）模型来优先处理告警。为了解释LSTM模型的告警优先级决策，研究实施并比较了四种XAI方法：局部可解释模型无关解释（LIME）、SHapley加性解释（SHAP）、集成梯度（Integrated Gradients）和DeepLIFT。这些XAI方法的质量通过一个评估忠实性、复杂性、鲁棒性和可靠性的综合框架进行评估。研究还与SOC分析师合作，确定了有效告警分类的关键特征。

**Result:** 研究结果表明，DeepLIFT始终优于其他XAI方法，提供了高忠实性、低复杂性、鲁棒性能和强可靠性的解释。分析师识别的关键特征与XAI方法获得的关键特征之间存在高度一致性。

**Conclusion:** 本研究的结论是，DeepLIFT在解释NIDS告警优先级方面表现出色，并且XAI方法识别的特征与分析师识别的特征之间的强一致性验证了该方法的有效性和实际适用性，从而增强了信任和可解释性。

> **ai_Abstract:** 本论文旨在解决深度学习驱动的网络入侵检测系统（NIDS）产生大量告警的挑战，通过引入可解释人工智能（XAI）来增强透明度和信任。研究利用真实的NIDS告警数据集，开发了一个LSTM模型进行告警优先级排序，并比较了LIME、SHAP、Integrated Gradients和DeepL四种XAI方法。评估结果显示，DeepLIFT在忠实性、复杂性、鲁棒性和可靠性方面表现最佳。此外，研究还通过与安全运营中心（SOC）分析师的合作，验证了XAI方法识别的关键特征与分析师经验的高度一致性，从而提升了该方法的实用性和可信度。

> **摘要翻译:** 网络入侵检测系统（NIDS）监控网络中的网络攻击和其他不必要的活动。然而，NIDS解决方案通常每天生成大量的警报，使分析师难以优先处理高优先级威胁。虽然深度学习模型有望自动化NIDS警报的优先级排序，但这些模型缺乏透明度可能会削弱对其决策的信任。本研究强调了在NIDS警报分类中对可解释人工智能（XAI）的迫切需求，以提高信任和可解释性。我们使用了来自爱沙尼亚塔林理工大学（TalTech）安全运营中心（SOC）的真实NIDS警报数据集，开发了一个长短期记忆（LSTM）模型来优先处理警报。为了解释LSTM模型的警报优先级决策，我们实施并比较了四种XAI方法：局部可解释模型无关解释（LIME）、SHapley加性解释（SHAP）、集成梯度（Integrated Gradients）和DeepLIFT。这些XAI方法的质量通过一个评估忠实性、复杂性、鲁棒性和可靠性的综合框架进行评估。我们的结果表明，DeepLIFT始终优于其他XAI方法，提供了高忠实性、低复杂性、鲁棒性能和强可靠性的解释。在与SOC分析师的合作中，我们确定了有效警报分类的关键特征。这些分析师识别的特征与XAI方法获得的特征之间的高度一致性验证了它们的有效性，并增强了我们方法的实际适用性。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [323] [SoK: Data Reconstruction Attacks Against Machine Learning Models: Definition, Metrics, and Benchmark](https://arxiv.org/abs/2506.07888)
> *SoK: 针对机器学习模型的数据重建攻击：定义、度量和基准*

*Rui Wen, Yiyong Liu, Michael Backes, Yang Zhang* | **Main category: cs.CR**

**Keywords:** 数据重建攻击, 机器学习安全, 评估指标, 大型语言模型, 基准

**Comment:** To Appear in the 34th USENIX Security Symposium, August 13-15, 2025

> **TL;DR:** 本文提出了针对机器学习模型的数据重建攻击的统一分类法、正式定义和量化评估指标，并利用大型语言模型进行评估，建立了该领域的基准。

**AI_Comments:** 该论文通过提供对数据重建攻击急需的系统化知识（SoK）而具有创新性，这对于理解机器学习中的隐私风险至关重要。利用大型语言模型进行评估是一种新颖的方法，可能使评估过程更具可扩展性和客观性。建立基准对于该快速发展领域的未来研究至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 目前，数据重建攻击缺乏正式定义和适当的评估指标，这阻碍了该领域的进一步发展。

**Method:** 提出统一的攻击分类法和数据重建攻击的正式定义；提出一套考虑可量化性、一致性、精确性和多样性的定量评估指标；利用大型语言模型替代人类判断进行视觉评估；建立统一框架以系统评估现有攻击并为未来研究设定基准。

**Result:** 实证结果验证了所提出指标的有效性，并为设计新的攻击提供了宝贵见解。

**Conclusion:** 本文为数据重建攻击提供了统一的框架、定义和评估指标，并通过实证结果验证了其有效性，为未来的研究和攻击设计奠定了基础。

> **ai_Abstract:** 本文针对机器学习模型数据重建攻击缺乏正式定义和一致评估指标的问题，提出了统一的分类法、正式定义和一套定量评估指标，尤其关注视觉领域。作者还利用大型语言模型进行视觉评估，并提出了一个统一的框架，用于对现有和未来的攻击进行基准测试。实证结果证实了这些指标的有效性，并为新攻击的设计提供了见解。

> **摘要翻译:** 数据重建攻击旨在以有限的访问权限恢复目标模型的训练数据集，近年来受到越来越多的关注。然而，目前对于数据重建攻击的正式定义或衡量其质量的适当评估指标尚未达成共识。这种缺乏严格定义和通用指标的情况阻碍了该领域的进一步发展。在本文中，我们通过提出统一的攻击分类法和数据重建攻击的正式定义来解决视觉领域中的这个问题。我们首先提出一套定量评估指标，其中考虑了可量化性、一致性、精确性和多样性等重要标准。此外，我们利用大型语言模型（LLM）作为人类判断的替代，从而能够进行视觉评估，并强调高质量的重建。利用我们提出的分类法和指标，我们提出了一个统一的框架，用于系统地评估现有攻击的优缺点，并为未来的研究建立基准。主要从记忆角度进行的实证结果不仅验证了我们指标的有效性，而且为设计新攻击提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [328] [Secure Distributed Learning for CAVs: Defending Against Gradient Leakage with Leveled Homomorphic Encryption](https://arxiv.org/abs/2506.07894)
> *CAV安全分布式学习：使用分级同态加密防御梯度泄露*

*Muhammad Ali Najjar, Ren-Yi Huang, Dumindu Samaraweera, Prashant Shekhar* | **Main category: cs.CR**

**Keywords:** 联邦学习, 同态加密, 梯度泄露, 连接和自动驾驶车辆, 隐私保护

**Comment:** 

> **TL;DR:** FL在CAV中面临梯度泄露攻击，本文提出一种基于分级同态加密的选择性加密策略和完整FL管道，有效防御攻击同时保持模型精度。

**AI_Comments:** 这篇论文的创新点在于将分级同态加密应用于联邦学习，以解决梯度泄露问题，同时通过选择性加密策略有效降低了HE的计算和通信开销，使其在资源受限的CAV环境中更具实用性。其开源实现有助于推动该领域的研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习（FL）在CAV等领域中是保护隐私的机器学习的有效方法，但交换的模型梯度容易受到DLG等推理攻击，这可以重建私有训练数据。现有防御方法（如差分隐私和安全多方计算）通常会损害模型精度。同态加密（HE）虽然能提供无损计算，但其引入的显著计算和通信开销阻碍了其实际应用。

**Method:** 本文系统评估了各种分级HE方案，以识别最适合资源受限环境下FL的方案。提出了一种选择性加密策略，仅针对最敏感的梯度进行加密，以最小化计算开销。并开发了一个完整的基于HE的FL管道。

**Result:** 本文提出的方法有效缓解了DLG攻击，同时保持了模型精度。研究成果已开源，以促进可重现性和在安全关键领域的采用。

**Conclusion:** 本文提出的基于分级同态加密的FL管道能够有效防御梯度泄露攻击，同时保持模型精度，并适用于资源受限环境。

> **ai_Abstract:** 本文针对联邦学习（FL）在连接和自动驾驶车辆（CAV）中面临的梯度泄露攻击问题，提出了一种基于分级同态加密（HE）的解决方案。研究评估了不同分级HE方案，并开发了一种选择性加密策略，仅加密最敏感的梯度以减少计算开销。最终构建了一个完整的基于HE的FL管道，该管道能有效防御梯度泄露攻击，同时不牺牲模型精度，并开源了其实现。

> **摘要翻译:** 联邦学习（FL）实现了分布式客户端之间的协作模型训练，而无需共享原始数据，使其成为连接和自动驾驶车辆（CAV）等领域中保护隐私的机器学习的一种有前景的方法。然而，最近的研究表明，交换的模型梯度仍然容易受到推理攻击，例如基于梯度的深度泄露（DLG），这可以重建私人训练数据。虽然差分隐私（DP）和安全多方计算（SMPC）等现有防御措施提供了保护，但它们通常会损害模型精度。为此，同态加密（HE）通过直接在加密数据上实现无损计算，从而保护隐私和模型效用，提供了一个有前景的替代方案。然而，HE引入了显著的计算和通信开销，这可能会阻碍其实际应用。为了解决这个问题，我们系统地评估了各种分级HE方案，以识别最适合资源受限环境下FL的方案，因为它能够支持固定深度计算，而无需昂贵的自举。本文的贡献包括：对HE方案在实际FL应用中的综合评估；一种仅针对最敏感梯度进行加密以最小化计算开销的选择性加密策略；以及开发了一个完整的基于HE的FL管道，该管道有效缓解了DLG攻击，同时保持了模型精度。我们开源了我们的实现，以鼓励可重现性并促进其在安全关键领域的采用。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [334] [Exposing Hidden Backdoors in NFT Smart Contracts: A Static Security Analysis of Rug Pull Patterns](https://arxiv.org/abs/2506.07974)
> *揭露NFT智能合约中的隐藏后门：一种地毯式拉盘模式的静态安全分析*

*Chetan Pathade, Shweta Hooli* | **Main category: cs.CR**

**Keywords:** NFT, 智能合约, 地毯式拉盘, 静态分析, 安全漏洞

**Comment:** 10 Pages, 4 Figures

> **TL;DR:** 本文通过对49,940个NFT智能合约进行大规模静态分析，揭示了与“地毯式拉盘”骗局相关的隐藏后门和漏洞，并提出了风险评分模型及缓解策略。

**AI_Comments:** 这项研究的重要性在于它直击了NFT市场中一个日益严重的信任问题——“地毯式拉盘”骗局。通过大规模的静态分析，它提供了一种可扩展且自动化的方法来识别智能合约中的恶意后门，这对于保护投资者和维护市场健康至关重要。其创新点在于结合了现有的静态分析工具和自定义的风险评分模型，能够有效地分类和可视化风险。尽管没有进行实时攻击，但其揭示的模式对于预防和教育具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** NFT的爆炸式增长催生了“地毯式拉盘”骗局，其中开发者利用智能合约特权和隐藏后门来窃取用户资金或使资产所有权失效。传统的审计往往无法发现这些故意编码和混淆的后门。因此，需要一种大规模、可扩展的方法来检测这些恶意模式。

**Method:** 作者对49,940个经过验证的NFT智能合约进行了大规模静态分析，使用了Slither静态分析框架来发现与“地毯式拉盘”相关的潜在漏洞。他们引入了一个自定义风险评分模型，根据“地毯式拉盘”指标的存在和严重性将合约分为高、中、低风险等级。数据集来源于以太坊主网上的验证合约，并生成了多重可视化图表来突出危险信号集群、问题普遍性和关键漏洞的共现性。

**Result:** 研究结果揭示了通过大规模静态分析，可以发现简单审查容易遗漏的恶意模式。尽管没有进行实时攻击，但分析表明了隐藏后门在真实世界智能合约中的表现形式。

**Conclusion:** 该工作为通过可扩展的自动化分析检测和缓解NFT“地毯式拉盘”提供了实用基础。文章最后提出了针对开发者、市场和审计师的缓解策略，以增强智能合约的安全性。

> **ai_Abstract:** 本文针对NFT市场中日益增长的“地毯式拉盘”骗局，通过对近5万个NFT智能合约进行大规模静态安全分析，旨在揭露其中隐藏的恶意后门。研究利用Slither框架和自定义风险评分模型，识别并分类了与“地毯式拉盘”相关的潜在漏洞，并通过可视化展示了这些危险模式的普遍性和共现性。研究结果表明，静态分析能有效发现传统审计难以察觉的恶意代码，并为开发者、平台和审计师提供了实用的缓解策略，以提升NFT智能合约的安全性。

> **摘要翻译:** 非同质化代币（NFT）的爆炸式增长通过在区块链网络上实现独特资产的创建、交换和货币化，彻底改变了数字所有权。然而，这种受欢迎程度的激增也催生了一种令人不安的趋势：地毯式拉盘的出现——即开发者利用信任和智能合约特权来耗尽用户资金或使资产所有权失效的欺诈性方案。许多此类骗局的核心是嵌入在NFT智能合约中的隐藏后门。与无意的错误不同，这些后门是故意编码并经常被混淆以绕过传统审计并利用投资者信心。在本文中，我们对49,940个经过验证的NFT智能合约进行了大规模静态分析，使用Slither（一个静态分析框架）来揭示通常与地毯式拉盘相关的潜在漏洞。我们引入了一个自定义风险评分模型，根据地毯式拉盘指标的存在和严重性将合约分为高、中或低风险等级。我们的数据集来源于以太坊主网上的验证合约，我们生成了多个可视化图表以突出危险信号集群、问题普遍性和关键漏洞的共现。虽然我们没有进行实时攻击，但我们的结果揭示了通过大规模静态分析如何发现简单审查经常遗漏的恶意模式。最后，我们为开发者、市场和审计师提供了缓解策略，以增强智能合约的安全性。通过揭示隐藏后门在真实世界智能合约中的表现形式，这项工作为通过可扩展的自动化分析检测和缓解NFT地毯式拉盘提供了实用基础。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [340] [Unraveling Ethereum's Mempool: The Impact of Fee Fairness, Transaction Prioritization, and Consensus Efficiency](https://arxiv.org/abs/2506.07988)
> *揭示以太坊内存池：费用公平性、交易优先级和共识效率的影响*

*S M Mostaq Hossain, Amani Altarawneh* | **Main category: cs.CR**

**Keywords:** 以太坊, 内存池, 费用公平性, 交易优先级, 共识效率

**Comment:** 7 pages, 6 figures and 1 table

> **TL;DR:** 本研究实证分析了以太坊内存池动态，发现高费用交易被优先处理，低费用交易常被延迟或排除，且当前费用市场存在效率低下和不公平。研究提出了拥堵感知费用调整、保留区块槽位等解决方案，旨在促进交易公平性、提高验证者性能并支持以太坊去中心化。

**AI_Comments:** 这项研究通过对以太坊内存池的实证分析，揭示了EIP-1559实施后仍存在的费用公平性问题和效率低下。其创新之处在于提供了具体的实证数据支持，并提出了针对性的技术解决方案，如拥堵感知费用调整和保留区块槽位，这对于改善以太坊的用户体验和促进去中心化具有重要意义。研究的重要性在于它直接关系到以太坊作为全球领先区块链平台的可用性和公平性。

<details>
  <summary>Details</summary>

**Motivation:** 以太坊的交易池（内存池）动态和费用市场效率严重影响交易纳入、验证者工作负载和整体网络性能。本研究旨在通过实证分析来揭示这些影响并提出改进方案。

**Method:** 本研究使用来自Geth和Prysm节点的实时数据，实证分析了以太坊权益证明生态系统中的Gas价格变化、内存池清除率和区块最终确定时间。

**Result:** 观察到高费用交易始终被优先处理，而低费用交易面临延迟或排除；内存池拥堵是验证者效率和提案延迟的关键因素；提供了持续存在的基于费用的差异的经验证据；发现极高费用并不总是保证更快的确认，揭示了当前费用市场的效率低下。

**Conclusion:** 研究结果支持更公平的交易纳入、增强验证者性能并促进可扩展性，通过减少对高交易费用的依赖来促进以太坊的长期去中心化。

> **ai_Abstract:** 本研究实证分析了以太坊权益证明系统中的内存池动态和费用市场效率。研究发现，尽管EIP-1559旨在改善，高费用交易仍被优先处理，低费用交易常被延迟或排除，且极高费用不总能保证快速确认，揭示了当前费用市场的不公平和低效。为解决这些问题，论文提出了拥堵感知费用调整、为低费用交易预留区块槽位以及改进Gas耗尽漏洞处理等方案，旨在促进交易公平性、提高验证者性能和网络可扩展性，从而支持以太坊的长期去中心化。

> **摘要翻译:** 以太坊的交易池（内存池）动态和费用市场效率严重影响交易纳入、验证者工作负载和整体网络性能。本研究利用来自Geth和Prysm节点的实时数据，实证分析了以太坊权益证明生态系统中的Gas价格变化、内存池清除率和区块最终确定时间。我们观察到高费用交易始终被优先处理，而低费用交易尽管EIP-1559旨在改进，但仍面临延迟或排除。内存池拥堵仍然是验证者效率和提案延迟的关键因素。我们提供了持续存在的基于费用的差异的经验证据，并表明极高费用并不总是保证更快的确认，揭示了当前费用市场的效率低下。为了解决这些问题，我们提出了拥堵感知费用调整、为低费用交易保留区块槽位以及改进对Gas耗尽漏洞的处理。通过减轻优先级偏差和执行效率低下，我们的研究结果支持更公平的交易纳入、增强验证者性能并促进可扩展性。这项工作通过减少对高交易费用的依赖来促进以太坊的长期去中心化。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

### [768] [Amatriciana: Exploiting Temporal GNNs for Robust and Efficient Money Laundering Detection](https://arxiv.org/abs/2506.00654)
> *错误：AI分析失败。*

*Marco Di Gennaro, Francesco Panebianco, Marco Pianta, Stefano Zanero, Michele Carminati* | **Main category: cs.CR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscr) | [⬆️ 返回总目录](#toc)

---

<a id='csai'></a>
## cs.AI 

### [14] [Understanding Financial Reasoning in AI: A Multimodal Benchmark and Error Learning Approach](https://arxiv.org/abs/2506.06282)
> *理解人工智能中的金融推理：一个多模态基准和错误学习方法*

*Shuangyan Deng, Haizhou Peng, Jiachen Xu, Chunhou Liu, Ciprian Doru Giurcuaneanu, Jiamou Liu* | **Main category: cs.AI**

**Keywords:** 金融推理, 多模态AI, 基准, 错误学习, 金融数据分析

**Comment:** 

> **TL;DR:** 有效的金融推理需要文本和视觉理解。本文提出了一个名为FinMR的多模态金融基准，包含3200个问答对，并引入了一个错误感知学习框架。实验表明，多模态输入和错误反馈显著提高了性能，但视觉理解和数学逻辑仍是挑战。

**AI_Comments:** 该论文通过开发全面的多模态基准和创新的错误感知学习框架，解决了AI中金融推理能力的关键需求。将视觉数据整合并利用过去的错误进行自我纠正，是迈向更可靠和复杂的金融AI系统的重要一步。对视觉和数学逻辑中持续存在的挑战的识别，为未来的研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 有效的金融推理不仅需要文本理解，还需要解释图表、表格和趋势图等复杂视觉数据的能力。现有AI模型在金融特定环境中的推理能力，特别是多模态推理方面存在局限性，需要新的评估方法和改进方案。

**Method:** 本文引入了一个名为FinMR的新型多模态金融推理基准，该基准包含15个核心金融主题的3200个专家级问答对，并整合了文本和视觉模态数据。此外，提出了一种错误感知学习框架，该框架利用历史模型错误和反馈来指导推理，无需进行微调。

**Result:** 实验表明，多模态输入显著提升了最先进模型的性能。结合错误反馈带来了持续且可衡量的改进。研究结果突出了在视觉理解和数学逻辑方面持续存在的挑战，同时也展示了金融AI系统中自我反思推理的潜力。

**Conclusion:** 多模态输入和错误反馈显著提升了AI在金融推理方面的能力，但在视觉理解和数学逻辑方面仍存在挑战。自我反思推理在未来的金融AI系统中展现出巨大潜力。

> **ai_Abstract:** 本文介绍了FinMR，一个用于评估AI金融推理能力的新型多模态基准，包含15个金融主题的3200个问答对，整合了文本和视觉数据。同时，提出了一个利用历史模型错误指导推理的错误感知学习框架，无需微调。实验证明，多模态输入和错误反馈显著提升了性能，但视觉理解和数学逻辑仍是挑战，并展示了自我反思推理的潜力。

> **摘要翻译:** 有效的金融推理不仅需要文本理解，还需要解释图表、表格和趋势图等复杂视觉数据的能力。本文引入了一个新的基准，旨在评估人工智能模型——特别是大型语言和多模态模型——在金融特定环境中的推理能力。该基准涵盖了15个核心金融主题的3,200个专家级问答对，整合了文本和视觉模态，以反映金融领域真实的分析挑战。为了解决当前推理方法的局限性，我们提出了一种错误感知学习框架，该框架利用历史模型错误和反馈来指导推理，而无需进行微调。我们对最先进模型的实验表明，多模态输入显著提高了性能，并且结合错误反馈带来了持续和可衡量的改进。结果突出了视觉理解和数学逻辑方面持续存在的挑战，同时也展示了金融AI系统中自我反思推理的潜力。我们的代码和数据可在 https://anonymous/FinMR/CodeData 找到。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [28] [Unreal Patterns](https://arxiv.org/abs/2506.06284)
> *虚构模式*

*John Beverley, Jim Logan* | **Main category: cs.AI**

**Keywords:** 虚构实体, 本体论, 模式, 假设实体, 信息表示

**Comment:** 

> **TL;DR:** 本文提出了一种在本体论框架内表示不存在或可能永远不存在的实体信息的方法，通过使用实际类型的交集而不是虚拟实例或模态逻辑来建模，旨在提供一种实用且计算上可行的方式来处理对假设或不存在实体的引用。

**AI_Comments:** 该论文的创新之处在于其对处理不存在实体的实用主义方法，避免了传统方法中常见的形而上学假设和计算效率低下。它将自身定位在已建立的本体论框架内，强调可实现性，这对于将本体论应用于实际计算场景具有重要意义。通过专注于实际类型的交集而非虚拟实例，它为处理复杂、假设性数据提供了一个清晰且可能更高效的路径。

<details>
  <summary>Details</summary>

**Motivation:** 传统处理不存在实体的方法（如引入“虚拟实例”或依赖模态逻辑）被批评为过度承诺形而上学假设或引入计算效率低下，阻碍了实际应用。因此，需要一种更实用、可实现且计算上可行的解决方案。

**Method:** 该论文提出并辩护了一种方法，即使用实际类型的交集而不是特定的不存在的标记来建模不存在的实体。该方法定位在基本形式本体论（Basic Formal Ontology）及其现实主义承诺之内，强调实用、可实现性。

**Result:** 通过开发一种结构化的、本体论驱动的虚构模式方法，该论文旨在提供一种有用且计算上可行的方式来处理对假设或不存在实体的引用。

**Conclusion:** 本文得出的结论是，所提出的框架提供了一种实用、可实现且计算上可行的方法来处理对虚构、蓝图、模拟和未来场景等不存在或可能永远不存在的实体的引用，克服了传统方法的局限性。

> **ai_Abstract:** 本文提出了一种处理不存在或可能永远不存在实体（如虚构实体、蓝图、模拟和未来情景）信息的新框架。该框架批评了传统“虚拟实例”和模态逻辑方法在形而上学和计算效率上的不足，转而倡导在基本形式本体论（Basic Formal Ontology）内，通过建模实际类型的交集来表示这些“虚构模式”。其核心目标是提供一种实用、可实现且计算上高效的方式来处理对假设或不存在实体的引用。

> **摘要翻译:** 本文介绍了一个用于表示不存在或可能永远不存在的实体信息的框架，例如涉及虚构实体、蓝图、模拟和未来情景的实体。传统引入“虚拟实例”或依赖模态逻辑的方法受到批评，本文提出并捍卫了一种建议，即此类情况应使用实际类型的交集而不是特定的不存在的标记来建模。该论文将自身定位在基本形式本体论（Basic Formal Ontology）及其现实主义承诺之内，强调实用、可实现解决方案的重要性，而非纯粹的形而上学或哲学提案，认为现有处理不存在实体的方法要么过度承诺形而上学假设，要么引入阻碍应用的计算效率低下。通过开发一种结构化的、本体论驱动的虚构模式方法，本文旨在提供一种有用且计算上可行的方式来处理对假设或不存在实体的引用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [42] [NFISiS: New Perspectives on Fuzzy Inference Systems for Renewable Energy Forecasting](https://arxiv.org/abs/2506.06285)
> *NFISiS: 可再生能源预测中模糊推理系统的新视角*

*Kaike Sa Teles Rocha Alves, Eduardo Pestana de Aguiar* | **Main category: cs.AI**

**Keywords:** 演化模糊系统, Python库, 机器学习, 可解释性, 自适应系统

**Comment:** 

> **TL;DR:** 本文介绍了 `evolvingfuzzysystems`，一个用于演化模糊系统 (eFS) 的 Python 库，旨在提高这些模型的可用性并促进自适应机器学习领域的研究。

**AI_Comments:** 该论文通过提供一个公开的 Python 库，解决了演化模糊系统领域一个重要的实际限制。这一举措对于加速这些自适应且可解释的机器学习模型的研究和应用至关重要，这些模型在实际应用中具有高度相关性。对可用性和性能评估（包括计算成本）的关注增加了其实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 演化模糊系统 (eFS) 模型缺乏公开可用的实现，限制了它们的易用性和广泛采用，从而阻碍了相关研究和实际应用。

**Method:** 作者开发了名为 `evolvingfuzzysystems` 的 Python 库，其中实现了多种成熟的 eFS 模型。该库提供了用于模型训练、可视化和性能评估的内置工具。模型使用 `fetch_california_housing` 数据集进行评估，性能指标包括 NRMSE、NDEI 和 MAPE，同时通过测量执行时间和规则演化来分析计算复杂度。

**Result:** 评估结果表明，ePL 是一种简单而高效的模型，在准确性和计算成本之间取得了良好平衡，使其特别适用于实际应用。

**Conclusion:** 通过公开提供 eFS 模型的实现，`evolvingfuzzysystems` 库旨在促进自适应和可解释机器学习领域的研究和实际应用。

> **ai_Abstract:** 本文介绍了 `evolvingfuzzysystems`，一个旨在解决演化模糊系统 (eFS) 模型可用性受限问题的 Python 库。该库包含了多种 eFS 模型的实现，并提供了训练、可视化和性能评估工具。通过在 `fetch_california_housing` 数据集上的实验，研究表明 ePL 是一种高效的模型，能在准确性和计算成本之间取得平衡。该库的总体目标是推动自适应和可解释机器学习领域的进一步研究与实际应用。

> **摘要翻译:** 演化模糊系统 (eFS) 因其能够根据数据动态自适应更新结构同时保持可解释性而受到广泛关注。然而，这些模型缺乏公开可用的实现，限制了它们的易用性和广泛采用。为了弥补这一空白，我们推出了 evolvingfuzzysystems，这是一个 Python 库，提供了几种成熟 eFS 模型的实现，包括 ePL-KRLS-DISCO、ePL+、eMG、ePL、exTS、Simpl_eTS 和 eTS。该库通过提供用于训练、可视化和性能评估的内置工具，促进了模型评估和比较。这些模型使用 fetch_california_housing 数据集进行评估，性能通过归一化均方根误差 (NRMSE)、无量纲误差指数 (NDEI) 和平均绝对百分比误差 (MAPE) 来衡量。此外，通过测量训练和测试阶段的执行时间和规则演化来分析计算复杂度。结果突出显示 ePL 是一种简单而高效的模型，它在准确性和计算成本之间取得了平衡，使其特别适用于实际应用。通过公开这些模型，evolvingfuzzysystems 旨在促进自适应和可解释机器学习领域的研究和实际应用。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [53] [AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture](https://arxiv.org/abs/2506.06580)
> *数字孪生驱动的AI模拟：系统综述、参考框架与标准化架构映射*

*Xiaoran Liu, Istvan David* | **Main category: cs.AI**

**Keywords:** 数字孪生, AI模拟, 系统综述, 参考框架, ISO 23247

**Comment:** 

> **TL;DR:** 本论文系统综述了数字孪生在AI模拟中的应用，旨在解决AI数据不足的问题。通过分析22项研究，作者提出了一个参考框架，并将其映射到ISO 23247标准，同时指出了未来的挑战和研究机会。

**AI_Comments:** 该论文具有重要意义，因为它系统地调查了一个新兴且关键的领域：由数字孪生增强的AI模拟，这直接解决了AI开发中的一个主要瓶颈——数据稀缺。参考框架的推导及其与ISO标准的映射提供了宝贵的架构指导，有助于促进这一复杂领域的标准化和互操作性。同时，识别未来挑战也有助于指导后续研究工作。

<details>
  <summary>Details</summary>

**Motivation:** 现代亚符号AI的采纳面临数据量和质量不足的紧迫挑战，而AI模拟（特别是利用数字孪生）提供了一种安全高效地使用模拟合成数据开发AI智能体的方法来缓解这些问题。

**Method:** 本研究对数字孪生驱动的AI模拟进行了系统综述，分析了22项主要研究。在此基础上，识别了技术趋势，并导出了一个参考框架来定位数字孪生和AI组件。此外，通过将该框架映射到数字孪生的ISO 23247参考架构，提供了架构指南。

**Result:** 本研究识别了数字孪生驱动的AI模拟中的技术趋势，导出了一个整合数字孪生和AI组件的参考框架，并提供了将其映射到ISO 23247参考架构的架构指南。此外，还指出了该领域的挑战和研究机会。

**Conclusion:** 该论文通过系统综述、提出参考框架并映射到标准化架构，为数字孪生驱动的AI模拟领域提供了全面的洞察和结构化指导，同时展望了未来的研究方向。

> **ai_Abstract:** 本论文旨在解决现代AI面临的数据量和质量不足问题，通过系统综述数字孪生在AI模拟中的应用。研究分析了22项主要文献，识别了技术趋势，并提出了一个用于整合数字孪生和AI组件的参考框架。该框架进一步被映射到ISO 23247数字孪生参考架构，以提供具体的架构指南。最后，文章还指出了该领域未来的挑战和研究机会。

> **摘要翻译:** 现代亚符号AI的采纳面临着数据量和质量不足的特别紧迫的挑战。为了缓解这些挑战，AI模拟利用虚拟训练环境，在其中可以安全有效地使用模拟的合成数据开发AI智能体。数字孪生为AI模拟开辟了新途径，因为这些物理系统的高保真虚拟副本配备了最先进的模拟器，并能够进一步与物理系统交互以进行额外的数据收集。在本文中，我们报告了我们对数字孪生支持的AI模拟进行的系统综述。通过分析22项主要研究，我们确定了技术趋势并导出了一个参考框架来定位数字孪生和AI组件。基于我们的发现，我们导出了一个参考框架，并通过将其映射到数字孪生的ISO 23247参考架构来提供架构指南。最后，我们为未来的研究人员指出了挑战和研究机会。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [57] [Deep Research Bench: Evaluating AI Web Research Agents](https://arxiv.org/abs/2506.06287)
> *深度研究基准：评估AI网络研究代理*

*FutureSearch, :, Nikos I. Bosse, Jon Evans, Robert G. Gambee, Daniel Hnyk, Peter Mühlbacher, Lawrence Phillips, Dan Schwarz, Jack Wildman* | **Main category: cs.AI**

**Keywords:** AI网络研究代理, 评估, 基准测试, RetroSearch, LLM

**Comment:** 

> **TL;DR:** 引入Deep Research Bench，一个用于评估AI网络研究代理的基准，通过“RetroSearch”环境解决网络不断变化的问题，并提供工具以进行可靠的长期评估。

**AI_Comments:** 这篇论文的创新之处在于引入了“RetroSearch”环境，通过冻结网页数据集解决了网络动态变化对AI网络研究代理评估的挑战，从而实现了可重复和可靠的长期基准测试。这对于追踪和改进AI在网络研究中的性能至关重要，特别是在幻觉、工具使用和遗忘等关键方面。其提出的Deep Research Bench为评估未来大型语言模型在复杂网络研究任务中的能力提供了宝贵的工具和方法。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI最常见的用例之一是启用网络搜索的LLM聊天，但目前缺乏针对不断变化的网络进行控制的、直接评估网络研究代理质量的方法。

**Method:** 1. 引入Deep Research Bench，包含89个多步骤网络研究任务实例，涵盖8个任务类别，答案由人类精心整理。 2. 提供一个“RetroSearch”环境，包含大量冻结的抓取网页，并证明离线“RetroSearch”代理与“实时网络”代理表现相当。 3. 提供强大的代理工具和脚手架，用于基准测试主流LLM（如o3和Gemini 2.5 Pro）。 4. 包括对冗长代理轨迹的自动化评估，以报告幻觉、工具使用和遗忘的进展。 5. 评估了名为“Deep Research”、“Deep Search”、“Search”或“Research”的主流网络研究产品。

**Result:** 离线“RetroSearch”代理与“实时网络”代理表现相当，这使得模型能够进行可靠的长期评估。评估结果可在公共排行榜上获取。

**Conclusion:** Deep Research Bench及其RetroSearch环境实现了对AI网络研究代理的可靠和可重复的评估，解决了网络动态变化带来的挑战，并促进了该领域模型性能的长期追踪和改进。

> **ai_Abstract:** 该论文介绍了Deep Research Bench，这是一个用于评估AI网络研究代理的新基准。为解决网络动态变化的挑战，该基准引入了“RetroSearch”环境，使用固定的网页数据集进行离线评估，并证明其结果与实时网络评估一致。Deep Research Bench包含89个多步骤研究任务，并提供了评估工具，能够对主流LLM（如o3和Gemini 2.5 Pro）在幻觉、工具使用和遗忘方面的表现进行自动化追踪。该研究旨在为AI网络研究产品提供一个可靠、可重复的评估框架，并已公开评估结果。

> **摘要翻译:** 现代AI最常见的用例之一是启用网络搜索的LLM聊天。然而，目前还没有直接评估网络研究代理质量的方法，以控制不断变化的网络。我们引入了Deep Research Bench，它包含89个多步骤网络研究任务实例，难度各异，涵盖8个不同的任务类别，答案由熟练的人类精心整理。我们提供了一个“RetroSearch”环境，其中包含大量冻结的抓取网页，并证明离线“RetroSearch”代理与“实时网络”代理表现相当，从而实现了模型随时间推移的可靠评估。我们提供强大的代理工具和脚手架，用于基准测试发布时的主流LLM，包括像o3和Gemini 2.5 Pro这样的“思考”模型。我们对冗长的代理轨迹进行自动化评估，以报告幻觉、工具使用和遗忘方面的进展。最后，我们评估了名为“Deep Research”、“Deep Search”、“Search”或“Research”的主流网络研究产品。结果可在公共排行榜 https://drb.futuresearch.ai/ 上获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [72] [Large Language Models and Their Applications in Roadway Safety and Mobility Enhancement: A Comprehensive Review](https://arxiv.org/abs/2506.06301)
> *大型语言模型及其在道路安全和出行能力增强中的应用：一项综合综述*

*Muhammad Monjurul Karim, Yan Shi, Shucheng Zhang, Bingzhang Wang, Mehrdad Nasri, Yinhai Wang* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 道路安全, 出行能力, 交通系统, 综合综述

**Comment:** 

> **TL;DR:** 本文全面综述了大型语言模型（LLMs）在增强道路安全和出行能力方面的应用，探讨了其适应性策略、具体应用、使能技术、面临的挑战以及未来的研究方向。

**AI_Comments:** 这篇综述论文及时地总结了大型语言模型（LLMs）在道路交通领域的应用现状，特别是其如何通过多模态策略适应交通数据，弥补了LLMs在处理非文本数据方面的不足。其重要性在于为研究人员和从业者提供了一个清晰的路线图，指明了LLMs在交通安全和出行能力提升中的潜力与挑战。论文不仅列举了具体的应用案例，还深入探讨了使能技术和面临的限制，如幻觉和数据隐私问题，这对于引导未来的负责任创新至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 道路安全和出行能力是现代交通系统的关键挑战，需要创新的分析框架来处理复杂、动态和异构的环境。传统工程方法已取得进展，但现实交通的复杂性和动态性需要更先进的分析框架。大型语言模型（LLMs）以其在自然语言理解、知识整合和推理方面的能力，代表着一个有前途的范式转变。

**Method:** 本文通过全面综述的方式，分析了大型语言模型（LLMs）在增强道路安全和出行能力方面的应用和定制。重点关注LLMs如何通过架构、训练、提示和多模态策略来适应交通领域独特的时空和物理数据，弥合“模态鸿沟”。系统分析了LLMs在出行（例如，交通流预测、信号控制）和安全（例如，碰撞分析、驾驶员行为评估）中的多样化应用，并考察了V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术。

**Result:** 综述分析了LLMs在出行（交通流预测、信号控制）和安全（碰撞分析、驾驶员行为评估）中的多样化应用。考察了V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术。尽管潜力巨大，但也指出了LLMs固有限制（幻觉、推理缺陷）、数据治理（隐私、偏见）、部署复杂性（模拟到现实、延迟）以及严格安全保障方面的挑战。

**Conclusion:** LLMs在交通领域具有变革潜力，但需要负责任的创新以实现更安全、更智能的交通系统。本综述提供了当前能力、局限性和机遇的结构化路线图。

> **ai_Abstract:** 本文对大型语言模型（LLMs）在提升道路安全和出行能力方面的应用进行了全面综述。文章探讨了LLMs如何通过多种策略（如架构、训练、提示和多模态方法）适应交通领域独特的时空数据，以弥补“模态鸿沟”。综述分析了LLMs在交通流预测、信号控制、碰撞分析和驾驶员行为评估等方面的具体应用，并讨论了V2X集成、领域特定基础模型等使能技术。同时，论文也指出了LLMs固有的局限性（如幻觉、推理缺陷）、数据治理、部署复杂性以及安全保障等挑战，并展望了多模态融合、时空推理、人机协作等未来研究方向。该综述为LLMs在交通领域的应用提供了结构化的现状、局限性和机遇路线图。

> **摘要翻译:** 道路安全和出行能力仍然是现代交通系统的关键挑战，需要能够解决复杂、动态和异构环境的创新分析框架。尽管传统工程方法取得了进展，但现实交通的复杂性和动态性需要更先进的分析框架。大型语言模型（LLMs）凭借其在自然语言理解、知识整合和推理方面前所未有的能力，代表着一个有前途的范式转变。本文全面综述了LLMs在增强道路安全和出行能力方面的应用和定制。一个关键的重点是LLMs如何通过架构、训练、提示和多模态策略来适应——弥合交通领域独特的时空和物理数据之间的“模态鸿沟”。本综述系统地分析了LLMs在出行（例如，交通流预测、信号控制）和安全（例如，碰撞分析、驾驶员行为评估）中的多样化应用。V2X集成、领域特定基础模型、可解释性框架和边缘计算等使能技术也得到了考察。尽管潜力巨大，但在LLMs固有限制（幻觉、推理缺陷）、数据治理（隐私、偏见）、部署复杂性（模拟到现实、延迟）以及严格安全保障方面仍然存在挑战。未来有前景的研究方向包括先进的多模态融合、增强的时空推理、人机协作、持续学习以及开发高效、可验证的系统。本综述提供了当前能力、局限性和机遇的结构化路线图，强调了LLMs的变革潜力，同时强调了负责任创新的必要性，以实现更安全、更智能的交通系统。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [86] [Mapping Human-Agent Co-Learning and Co-Adaptation: A Scoping Review](https://arxiv.org/abs/2506.06324)
> *人机协同学习与协同适应性映射：一项范围审查*

*Shruti Kumar, Xiaoyu Chen, Xiaomei Wang* | **Main category: cs.AI**

**Keywords:** 人机协同学习, 协同适应性, 范围审查, 术语一致性, 认知理论

**Comment:** Abstract accepted to HFES 2024 Annual Meeting

> **TL;DR:** 本范围审查旨在梳理人机协同学习和协同适应性研究中术语的不一致性，并探究智能代理类型、任务领域以及所使用的认知理论和框架。

**AI_Comments:** 该论文通过范围审查的形式，针对人机协同领域中长期存在的术语不一致问题进行了梳理，并系统性地探索了智能代理类型、任务领域和理论框架。这对于新兴且复杂的跨学科领域具有重要意义，有助于标准化概念，并为未来的研究提供更明确的方向和理论支撑，避免概念混淆。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究中描述人机协同关系（特别是“协同学习”和“协同适应性”）的术语存在不一致性，且该研究领域相对较新，缺乏对智能代理类型、任务领域以及理论框架的系统性考察。

**Method:** 本研究采用范围审查（scoping review）的方法，旨在回答三个主要研究问题：1. 收集讨论人机协同模式的现有论文，并审查研究人员用于描述这种人机关系的术语；2. 探索现有研究中考虑的智能代理类型和任务领域；3. 调查现有研究中用于衡量人机协同学习和协同适应性的认知理论和框架。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本范围审查旨在系统性地梳理人机协同学习与协同适应性研究领域。鉴于当前术语使用不一致的问题，研究将收集相关文献，分析描述人机关系的术语，并探索智能代理类型、任务领域以及支撑该领域研究的认知理论和框架，以期为未来的研究提供清晰的指导和理论基础。

> **摘要翻译:** 多篇论文深入探讨了人机-AI-机器人协同学习和协同适应性的挑战。人们注意到，现有研究中用于描述这种协作关系的术语需要更加一致。例如，“co”前缀被交替用于表示“协作”和“相互”，而“协同学习”和“协同适应性”这两个术语有时也互换使用。然而，它们可能反映了研究侧重点的细微差异。当前范围审查的首要研究问题（RQ1）旨在收集讨论这种协作模式的现有论文，并审查研究人员用于描述这种人机关系的术语。鉴于该研究领域相对较新，我们还热衷于探索现有研究中已考虑的智能代理的具体类型和任务领域（RQ2）。这项探索意义重大，因为它能揭示人机交互的多样性，从一次性到持续学习/适应场景。它还可以帮助我们理解不同任务领域中人机交互的动态，指导我们对动态、复杂领域中研究的期望。我们的第三个目标（RQ3）是调查现有研究中已利用的认知理论和框架，以衡量人机协同学习和协同适应性。这项调查至关重要，因为它有助于我们理解人机协作和适应的理论基础，同时也能指导我们识别专门为此类关系提出的任何新框架。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [99] [Memory OS of AI Agent](https://arxiv.org/abs/2506.06326)
> *AI Agent的记忆操作系统*

*Jiazheng Kang, Mingming Ji, Zhe Zhao, Ting Bai* | **Main category: cs.AI**

**Keywords:** AI Agent, 记忆操作系统, 大语言模型, 长期记忆, 分层存储

**Comment:** 

> **TL;DR:** 提出MemoryOS，一个受操作系统启发的分层记忆管理系统，解决了LLM长期记忆和个性化交互不足的问题，并在基准测试中显著提升了性能。

**AI_Comments:** 这篇论文的创新点在于将操作系统中的记忆管理概念引入到AI Agent的长期记忆管理中，提出分层存储和动态更新机制，为解决LLM上下文窗口限制提供了一个新颖且有效的方法。其性能提升显著，对提升AI Agent的交互体验和个性化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）面临固定上下文窗口和记忆管理不足的关键挑战，导致长期记忆能力严重不足以及AI代理交互体验中个性化受限。

**Method:** 提出MemoryOS，一个受操作系统记忆管理原理启发的分层存储架构。它包含记忆存储、更新、检索和生成四个关键模块。存储架构分为短期记忆、中期记忆和长期个人记忆三层。更新操作包括短期到中期（基于对话链的FIFO）和中期到长期（分段页面组织策略）。

**Result:** 在LoCoMo基准测试上，GPT-4o-mini的F1分数平均提高了49.11%，BLEU-1分数平均提高了46.18%，在长对话中显示出上下文连贯性和个性化记忆保留能力。

**Conclusion:** MemoryOS通过分层记忆整合和动态更新，有效解决了LLM的长期记忆和个性化交互问题，显著提升了AI代理在长对话中的表现。

> **ai_Abstract:** 本文提出MemoryOS，一个受操作系统启发的分层记忆管理系统，旨在解决大语言模型在长期记忆和个性化交互方面的不足。MemoryOS包含短期、中期和长期记忆单元，并设计了动态更新机制。实验结果表明，MemoryOS在LoCoMo基准测试上显著提升了GPT-4o-mini在长对话中的表现，增强了上下文连贯性和个性化记忆保留。

> **摘要翻译:** 论文标题：AI Agent的记忆操作系统
论文摘要：
大语言模型（LLMs）面临固定上下文窗口和记忆管理不足的关键挑战，导致长期记忆能力严重短缺，以及与AI代理交互体验中的个性化受限。为了克服这一挑战，我们创新性地提出了一个记忆操作系统，即MemoryOS，以实现AI代理全面高效的记忆管理。受操作系统中记忆管理原理的启发，MemoryOS设计了一个分层存储架构，并由四个关键模块组成：记忆存储、更新、检索和生成。具体来说，该架构包含三个层次的存储单元：短期记忆、中期记忆和长期个人记忆。MemoryOS中的关键操作包括存储单元之间的动态更新：短期到中期的更新遵循基于对话链的FIFO原则，而中期到长期的更新则采用分段页面组织策略。我们开创性的MemoryOS实现了分层记忆整合和动态更新。在LoCoMo基准测试上进行的广泛实验表明，GPT-4o-mini的F1分数平均提高了49.11%，BLEU-1分数平均提高了46.18%，超过了基线模型，这在长对话中显示出上下文连贯性和个性化记忆保留能力。实现代码已在https://github.com/BAI-LAB/MemoryOS 开源。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [112] [Will artificial agents pursue power by default?](https://arxiv.org/abs/2506.06352)
> *人工智能体默认会追求权力吗？*

*Christian Tarsney* | **Main category: cs.AI**

**Keywords:** 人工智能, 权力寻求, 工具性收敛, AI风险, 决策理论

**Comment:** 

> **TL;DR:** 论文通过决策理论框架形式化了工具性收敛和权力寻求的概念，并得出结论：AI寻求权力有一定道理，但其预测效用有限，除非AI能获得绝对权力。

**AI_Comments:** 这篇论文通过严谨的决策理论框架，对AI风险领域中关于AI权力寻求的核心论点进行了形式化和审视。其创新之处在于提供了一个理论工具来分析这一复杂问题，并得出了一个 nuanced 的结论，即该主张并非全盘皆错，但也并非普遍适用。这对于理解AI行为的潜在风险具有重要意义，尤其是在区分不同能力水平和目标信息的AI代理时。论文的局限性可能在于其抽象性，实际应用中可能需要更多具体情境的考量。

<details>
  <summary>Details</summary>

**Motivation:** 针对高级AI可能对人类构成灾难性风险的担忧，研究者们认为AI代理会寻求权力，因为权力是一种收敛的工具性目标。但也有人对此表示怀疑，因此本研究旨在评估这一主张。

**Method:** 本文旨在在一个抽象的、决策理论框架中形式化工具性收敛和权力寻求的概念，并评估权力是一种收敛的工具性目标这一主张。

**Result:** 结论是，权力是收敛的工具性目标这一主张至少包含一部分事实，但可能预测效用有限，因为在缺乏关于代理最终目标的实质性信息的情况下，代理的选项并非总能按权力进行排序。然而，对于那些有很大机会获得绝对或接近绝对权力的代理来说，工具性收敛的事实更具预测性。

**Conclusion:** 权力作为收敛性工具性目标的主张有其真实性，但其预测能力有限，因为在不了解AI最终目标的情况下，其选项无法总是按权力排序。然而，对于有潜力获得绝对或接近绝对权力的AI而言，工具性收敛的预测性更强。

> **ai_Abstract:** 本文在一个抽象的决策理论框架中，形式化并评估了人工智能代理是否会寻求权力这一问题。研究发现，“权力是收敛的工具性目标”这一主张具有一定真实性，但在缺乏AI最终目标信息时，其预测效用有限。然而，对于有潜力获得绝对或接近绝对权力的AI，工具性收敛的预测性更强。

> **摘要翻译:** 研究人员担心先进人工智能带来的灾难性风险，认为足够强大的人工智能代理会寻求超越人类的权力，因为权力是一个收敛的工具性目标，对广泛的最终目标都有用。最近也有人对此类主张表示怀疑。本文旨在在一个抽象的、决策理论框架中形式化工具性收敛和权力寻求的概念，并评估权力是一个收敛的工具性目标这一主张。我得出结论，这一主张至少包含一部分事实，但可能预测效用有限，因为在缺乏关于代理最终目标的实质性信息的情况下，代理的选项并非总能按权力进行排序。然而，对于那些有很大机会获得绝对或接近绝对权力的代理来说，工具性收敛的事实更具预测性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [126] [Towards Foundation Model on Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2506.06367)
> *迈向时序知识图谱推理的基础模型*

*Jiaxin Pan, Mojtaba Nayyeri, Osama Mohammed, Daniel Hernandez, Rongchuan Zhang, Cheng Cheng, Steffen Staab* | **Main category: cs.AI**

**Keywords:** 时序知识图谱, 链接预测, 全归纳学习, 基础模型, 零样本学习

**Comment:** 

> **TL;DR:** 提出首个全归纳时序知识图谱链接预测方法POSTRA，通过预训练实现对未知TKGs的零样本泛化，迈向时序KG基础模型。

**AI_Comments:** 本文的创新点在于提出了首个全归纳的时序知识图谱链接预测方法POSTRA，突破了传统TKGE模型对已知元素的依赖。通过实现零样本泛化能力，POSTRA有望成为时序知识图谱领域的基础模型，极大地提升模型在真实世界复杂动态场景中的应用潜力，解决了跨领域和新数据泛化的核心挑战。

<details>
  <summary>Details</summary>

**Motivation:** 现有时序知识图谱嵌入（TKGE）模型在归纳或半归纳设置下进行链接预测，依赖训练期间已观测到的实体、关系和时间信息，限制了模型向新领域迁移和泛化到真实世界场景的能力，难以学习可迁移且不依赖数据集特定词汇的表示。

**Method:** 引入首个全归纳的时序知识图谱链接预测方法POSTRA。该模型采用正弦位置编码来捕获精细时间模式，并利用消息传递，结合局部和全局时间上下文生成自适应实体和关系表示。模型设计与时间粒度和时间跨度无关，有效解决了TKGs之间的时间差异，促进了时间感知结构信息的传递。

**Result:** POSTRA作为一种预训练、可扩展和可迁移的模型，在未见过的时序知识图谱上表现出强大的零样本性能，有效地泛化到新实体、关系和时间戳。广泛的理论分析和实证结果表明，单个预训练模型可以提高各种归纳时序推理场景的零样本性能。

**Conclusion:** 该研究代表了向时序知识图谱基础模型迈出的重要一步，通过实现对新实体、关系和时间戳的零样本泛化能力，克服了现有模型的局限性。

> **ai_Abstract:** 本文提出POSTRA，首个用于时序知识图谱（TKG）链接预测的全归纳方法。针对现有TKGE模型在面对新实体、关系和时间戳时泛化能力不足的问题，POSTRA通过正弦位置编码捕获时间模式，并利用消息传递生成自适应实体和关系表示。该模型设计独立于时间粒度和跨度，并通过预训练实现对未见TKGs的强大零样本性能，显著提升了在归纳时序推理场景中的泛化能力，为构建时序KG基础模型奠定了基础。

> **摘要翻译:** 时序知识图谱（TKGs）以四元组形式（s, p, o, t）存储时序事实。现有的时序知识图谱嵌入（TKGE）模型在直推式或半归纳式设置下执行链接预测任务，这意味着测试图中的实体、关系和时间信息在训练期间是完全或部分可见的。这种在推理时对已见元素的依赖限制了模型向新领域迁移和泛化到真实世界场景的能力。一个核心局限在于难以学习可迁移且不依赖数据集特定词汇的实体、关系和时间戳表示。为了克服这些局限性，我们引入了首个针对时序知识图谱链接预测的全归纳方法。我们的模型采用正弦位置编码来捕获细粒度的时间模式，并利用消息传递，结合局部和全局时间上下文生成自适应实体和关系表示。我们的模型设计与时间粒度和时间跨度无关，有效解决了TKGs之间的时间差异，并促进了时间感知结构信息的传递。作为一种预训练、可扩展和可迁移的模型，POSTRA在未见过的时序知识图谱上展示了强大的零样本性能，有效地泛化到新实体、关系和时间戳。广泛的理论分析和实证结果表明，单个预训练模型可以提高各种归纳时序推理场景的零样本性能，标志着向时序知识图谱基础模型迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [139] [SIGMA: Refining Large Language Model Reasoning via Sibling-Guided Monte Carlo Augmentation](https://arxiv.org/abs/2506.06470)
> *SIGMA：通过同级引导蒙特卡洛增强改进大型语言模型推理*

*Yanwei Ren, Haotian Zhang, Fuxiang Wu, Jiayan Qiu, Jiaxing Huang, Baosheng Yu, Liu Liu* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 蒙特卡洛树搜索, 推理增强, 数据效率, SIGMA

**Comment:** 

> **TL;DR:** SIGMA通过重新整合蒙特卡洛树搜索中被丢弃的同级节点，显著提升了LLM的推理能力，同时大幅减少了数据需求。

**AI_Comments:** 该论文的创新点在于认识到蒙特卡洛树搜索中被丢弃的非最优路径中蕴含的价值，并提出SIGMA框架系统地利用这些“同级”信息来反哺和优化最优路径。这种方法通过利用被忽视的数据信号，显著提升了LLM的推理能力，同时大幅减少了对大规模数据集的依赖，这对于LLM的训练效率和性能提升具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大型语言模型通过简单扩充数据集提升效果已收效甚微，数据质量成为焦点。尽管MCTS能生成高质量思维链数据，但传统方法只保留最优路径，丢弃了包含有价值见解、错误模式和替代策略的同级节点，导致大量信息浪费。

**Method:** 提出SIGMA（Sibling Guided Monte Carlo Augmentation）框架，重新整合被丢弃的同级节点以改进LLM推理。SIGMA在每个搜索路径中的同级节点之间建立语义链接，并应用两阶段改进：一个批判模型识别同级节点集中的优缺点，一个修订模型根据比较反馈进行基于文本的反向传播，以改进最优路径。

**Result:** 在具有挑战性的MATH基准测试中，SIGMA微调的7B模型仅使用3万样本就达到了54.92%的准确率，优于使用59万样本训练的SOTA模型。

**Conclusion:** SIGMA通过同级引导优化，不仅显著减少了数据使用，还显著提升了LLM的推理能力。

> **ai_Abstract:** SIGMA是一种新颖的框架，旨在通过重新整合蒙特卡洛树搜索中被丢弃的同级节点来改进大型语言模型的推理能力。它通过在同级节点间建立语义链接，并利用批判模型和修订模型的两阶段反馈机制来优化最优推理路径。实验结果表明，SIGMA在MATH基准测试上以更少的数据量（3万样本）取得了超越SOTA模型（59万样本）的性能，证明了其在提升LLM推理能力和数据效率方面的有效性。

> **摘要翻译:** 简单地扩充数据集来增强大型语言模型的效果已开始出现边际效益递减，这使得人们的关注点转向数据质量。蒙特卡洛树搜索（MCTS）已成为一种生成高质量思维链数据的强大技术，然而，传统方法通常只保留搜索树中的最高得分轨迹，而丢弃了通常包含有价值的部分见解、反复出现的错误模式和替代推理策略的同级节点。这种无条件地拒绝非最优推理分支可能会浪费整个搜索树中大量的信息数据。我们提出了SIGMA（同级引导蒙特卡洛增强），这是一个新颖的框架，它重新整合了这些被丢弃的同级节点以改进LLM推理。SIGMA在每个搜索路径中的同级节点之间建立语义链接，并应用两阶段改进：一个批判模型识别同级节点集中的被忽视的优点和缺点，一个修订模型根据这种比较反馈进行基于文本的反向传播，以改进最高得分轨迹。通过恢复和放大来自非最优推理分支的未充分利用但有价值的信号，SIGMA显著改善了推理轨迹。在具有挑战性的MATH基准测试中，我们的SIGMA微调的7B模型仅使用3万样本就达到了54.92%的准确率，超越了在59万样本上训练的SOTA模型。这一结果突出表明，我们的同级引导优化不仅显著减少了数据使用，而且显著提升了LLM的推理能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [150] [Reinforcement Learning for Autonomous Warehouse Orchestration in SAP Logistics Execution: Redefining Supply Chain Agility](https://arxiv.org/abs/2506.06523)
> *强化学习在SAP物流执行中实现自主仓库编排：重新定义供应链敏捷性*

*Sumanth Pillella* | **Main category: cs.AI**

**Keywords:** 强化学习, 仓库编排, SAP物流执行, 供应链敏捷性, 任务优化

**Comment:** 6 pages

> **TL;DR:** 本研究引入了一个开创性的强化学习框架，用于在SAP LE中自主编排仓库任务，显著提高了任务优化准确性并缩短了处理时间，从而增强了供应链的敏捷性和效率。

**AI_Comments:** 该论文的创新点在于将强化学习应用于SAP物流执行中的仓库任务自主编排，这在当前供应链需求不断增长的背景下具有重要意义。其通过模拟真实世界场景并展示出95%的任务优化准确率和60%的处理时间减少，证明了该方法的有效性和潜力。此外，论文还考虑了数据隐私、可扩展性和SAP集成等实际应用中的关键问题，使其解决方案更具实用性。这为提升供应链敏捷性提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在供应链需求不断升级的时代，SAP物流执行（LE）对于管理仓库运营、运输和交付至关重要。为了应对这些挑战并增强运营敏捷性和效率，本研究旨在利用强化学习（RL）实现仓库任务的自主编排。

**Method:** 本研究引入了一个利用强化学习（RL）的开创性框架，以在SAP LE中自主编排仓库任务。该框架将仓库流程建模为动态环境，实时优化任务分配、库存移动和订单拣选。研究使用了包含多语言数据和操作中断的30万条LE事务的合成数据集来模拟真实世界的仓库场景。

**Result:** 该分析实现了95%的任务优化准确率，与传统方法相比，处理时间减少了60%。可视化（包括效率热图和性能图）指导敏捷仓库策略。

**Conclusion:** 该方法解决了数据隐私、可扩展性和SAP集成问题，为现代供应链提供了一个变革性的解决方案，重新定义了供应链敏捷性。

> **ai_Abstract:** 本研究提出了一种基于强化学习（RL）的创新框架，旨在SAP物流执行（LE）中实现仓库任务的自主编排。通过将仓库流程视为动态环境，该框架能实时优化任务分配、库存移动和订单拣选。利用包含30万条LE事务的合成数据集进行模拟，结果显示任务优化准确率达到95%，处理时间相较传统方法缩短了60%。该方案解决了数据隐私、可扩展性和SAP集成等关键挑战，为提升现代供应链的敏捷性和效率提供了变革性的途径。

> **摘要翻译:** 在供应链需求不断升级的时代，SAP物流执行（LE）对于管理仓库运营、运输和交付至关重要。本研究引入了一个开创性的强化学习（RL）框架，用于在SAP LE中自主编排仓库任务，从而提高运营敏捷性和效率。通过将仓库流程建模为动态环境，该框架实时优化任务分配、库存移动和订单拣选。一个包含30万条LE事务的合成数据集模拟了真实世界的仓库场景，包括多语言数据和操作中断。分析实现了95%的任务优化准确率，与传统方法相比，处理时间减少了60%。可视化（包括效率热图和性能图）指导敏捷仓库策略。该方法解决了数据隐私、可扩展性和SAP集成问题，为现代供应链提供了一个变革性的解决方案。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [160] [ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search](https://arxiv.org/abs/2506.06524)
> *ScriptDoctor：通过大型语言模型和树搜索自动生成PuzzleScript游戏*

*Sam Earle, Ahmed Khalifa, Muhammad Umair Nasir, Zehua Jiang, Graham Todd, Andrzej Banburski-Fahey, Julian Togelius* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 自动游戏设计, PuzzleScript, 游戏生成, 树搜索

**Comment:** 5 pages, 3 figures, 3 tables, submitted to IEEE Conference on Games
  as a Short Paper

> **TL;DR:** ScriptDoctor是一个利用大型语言模型和树搜索，自动生成和测试PuzzleScript游戏的系统，旨在将LLM集成到更长期的自动游戏设计流程中。

**AI_Comments:** ScriptDoctor的创新之处在于其将大型语言模型与迭代测试循环相结合，实现了游戏内容的自动化、开放式生成和验证，这对于将LLM更深入地集成到自动游戏设计流程中具有重要意义。它超越了LLM的临时性使用，展示了其在复杂、有约束环境（如PuzzleScript）中自主创作的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人们对在自动游戏设计（AGD）中使用大型预训练模型很感兴趣，但目前这种应用大多是在持续人工监督下的临时使用。仍需大量工作来展示如何将这些工具整合到更长期的AGD流程中，实现系统与游戏引擎的自主交互和测试。

**Method:** ScriptDoctor系统通过一个迭代循环来生成和测试游戏设计理念。该循环利用人工编写的示例来引导系统输出，利用PuzzleScript引擎的编译错误来生成功能性代码，并使用基于搜索的代理来玩测试生成的游戏。

**Result:** ScriptDoctor提供了一个具体案例，展示了自动化、开放式、基于大型语言模型的工作流在生成新颖游戏内容方面的潜力。

**Conclusion:** 自动化、开放式、基于大型语言模型的工作流在生成新颖游戏内容方面具有巨大潜力，ScriptDoctor系统为此提供了一个具体范例。

> **ai_Abstract:** 本文介绍了ScriptDoctor，一个由大型语言模型（LLM）驱动的系统，用于自动生成和测试PuzzleScript游戏。该系统旨在解决当前自动游戏设计中LLM应用依赖人工监督的局限性，通过迭代循环，结合人工示例、编译错误反馈和搜索代理的玩测试，实现游戏内容的自主生成和验证。ScriptDoctor展示了LLM在自动化、开放式游戏内容生成工作流中的巨大潜力。

> **摘要翻译:** 人们对在自动游戏设计（AGD）中使用大型预训练模型抱有浓厚兴趣，无论是通过生成代码、资产，还是更抽象的设计理念概念化。但迄今为止，这种兴趣主要源于在持续人工监督下对这些生成模型的临时性使用。仍需大量工作来展示如何将这些工具整合到更长期的AGD流程中，在这些流程中，系统与游戏引擎进行交互以自主测试生成的内容。为此，我们引入了ScriptDoctor，一个由大型语言模型（LLM）驱动的系统，用于在PuzzleScript中自动生成和测试游戏。PuzzleScript是一种表达力强但高度受限的描述语言，用于2D网格世界中的回合制解谜游戏。ScriptDoctor通过一个迭代循环生成和测试游戏设计理念，其中人工编写的示例用于引导系统输出，PuzzleScript引擎的编译错误用于生成功能性代码，基于搜索的代理则对生成的游戏进行玩测试。ScriptDoctor为自动化、开放式、基于LLM的工作流在生成新颖游戏内容方面的潜力提供了一个具体案例。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [171] [The Optimization Paradox in Clinical AI Multi-Agent Systems](https://arxiv.org/abs/2506.06574)
> *临床AI多智能体系统中的优化悖论*

*Suhana Bedi, Iddah Mlauzi, Daniel Shin, Sanmi Koyejo, Nigam H. Shah* | **Main category: cs.AI**

**Keywords:** 多智能体系统, 临床AI, 优化悖论, 系统验证, 诊断准确性

**Comment:** 

> **TL;DR:** 临床AI多智能体系统中，组件级优化不一定带来系统级性能提升，甚至可能导致诊断准确性下降，需要关注信息流和系统级验证。

**AI_Comments:** 这篇论文揭示了在复杂多智能体AI系统中一个重要的反直觉现象，即“优化悖论”。它强调了在医疗等高风险领域部署AI系统时，不能仅仅停留在组件层面的优化，而必须考虑系统整体的协同效应、信息流和兼容性。其创新之处在于通过实际数据验证了这一悖论，并为未来医疗AI系统的设计和验证提供了关键指导，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 临床AI多智能体系统部署日益增多，但组件级优化与系统整体性能之间的关系尚不清楚。

**Method:** 使用MIMIC-CDM数据集中2400例真实患者病例，涵盖四种腹部病理（阑尾炎、胰腺炎、胆囊炎、憩室炎），将临床诊断分解为信息收集、解释和鉴别诊断。比较了单一智能体系统和多智能体系统，并使用了诊断结果、过程依从性和成本效率等综合指标进行评估。

**Result:** 发现了一个悖论：多智能体系统通常优于单一智能体系统，但组件优化或“最佳品种”系统（具有优越组件和出色过程指标，信息准确率达85.5%）在诊断准确率上表现显著不佳（67.7%），远低于表现最佳的多智能体系统（77.4%）。

**Conclusion:** 成功将AI整合到医疗保健中，不仅需要组件级优化，还需要关注智能体之间的信息流和兼容性。研究结果强调了需要进行端到端系统验证，而不是仅仅依赖于组件指标。

> **ai_Abstract:** 本研究调查了临床AI多智能体系统中组件级优化与系统整体性能之间的关系。通过在2400例真实患者病例上比较单一智能体和多智能体系统，研究发现了一个“优化悖论”：尽管多智能体系统通常表现更好，但组件最优化的系统反而可能在诊断准确性上表现不佳。这表明在医疗AI中，成功的系统集成需要关注智能体间的信息流和兼容性，并强调了进行端到端系统验证的重要性。

> **摘要翻译:** 多智能体人工智能系统越来越多地部署在临床环境中，然而，组件级优化与系统整体性能之间的关系仍知之甚少。我们使用来自MIMIC-CDM数据集的2400例真实患者病例，评估了四种腹部病理（阑尾炎、胰腺炎、胆囊炎、憩室炎）的这种关系，将临床诊断分解为信息收集、解释和鉴别诊断。我们使用涵盖诊断结果、过程依从性和成本效率的综合指标，评估了单一智能体系统（一个模型执行所有任务）与多智能体系统（每个任务都有专门模型）的性能。我们的结果揭示了一个悖论：虽然多智能体系统通常优于单一智能体系统，但组件优化或“最佳品种”系统（具有优越组件和出色过程指标，信息准确率达85.5%）在诊断准确率方面表现显著不佳（67.7%），远低于表现最佳的多智能体系统（77.4%）。这一发现强调，AI在医疗保健中的成功整合不仅需要组件级优化，还需要关注智能体之间的信息流和兼容性。我们的研究结果凸显了需要进行端到端系统验证，而不是仅仅依赖于组件指标。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [187] [GELD: A Unified Neural Model for Efficiently Solving Traveling Salesman Problems Across Different Scales](https://arxiv.org/abs/2506.06634)
> *GELD：一种高效解决不同规模旅行商问题的统一神经网络模型*

*Yubin Xiao, Di Wang, Rui Cao, Xuan Wu, Boyang Li, You Zhou* | **Main category: cs.AI**

**Keywords:** 旅行商问题, 神经网络, 组合优化, 统一模型, 大规模TSP

**Comment:** 21pages, 4 figures, and 14 tables

> **TL;DR:** GELD是一种新型神经网络TSP求解器，能高效解决从小规模到超大规模的TSP问题，且性能优于现有SOTA模型。

**AI_Comments:** GELD的创新之处在于其统一的架构能够同时处理小规模和超大规模TSP，解决了现有模型的局限性。其低复杂度注意力机制和两阶段训练策略是其实现高效和泛化能力的关键。能够解决744,710个节点TSP且不依赖分治策略是其显著的突破，极大地扩展了神经TSP求解器的实际应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于神经网络的TSP求解器难以使用同一组预训练模型参数高效地解决小规模和大规模TSP问题，限制了它们的实用性。

**Method:** 本文提出GELD模型，基于“广域全局评估和精细局部选择”框架。GELD结合轻量级全局视角编码器（GE）和重量级局部视角解码器（LD）以丰富嵌入表示并加速决策过程。GE引入了新颖的低复杂度注意力机制，实现低推理延迟和可扩展性。此外，还提出两阶段训练策略，利用不同大小的训练实例来增强GELD的泛化能力。

**Result:** 在合成和真实世界数据集上的广泛实验表明，GELD在解决方案质量和推理速度方面均优于七种最先进的模型。GELD还可以作为后处理方法，通过可承受的额外计算时间显著提升现有神经TSP求解器的解决方案质量。GELD能够解决节点数高达744,710的TSP问题，是首个在不依赖分治策略的情况下解决如此大规模TSP问题的方法。

**Conclusion:** GELD是一个统一的神经网络模型，能够高效且高质量地解决不同规模的旅行商问题，填补了现有模型在处理大尺度TSP方面的空白，并展现出卓越的性能和实用性。

> **ai_Abstract:** 本文提出了一种名为GELD的新型神经网络模型，旨在高效解决不同规模的旅行商问题（TSP）。GELD采用“广域全局评估和精细局部选择”框架，结合轻量级全局视角编码器（GE）和重量级局部视角解码器（LD），并引入低复杂度注意力机制和两阶段训练策略。实验证明，GELD在解决方案质量和推理速度上均优于现有SOTA模型，且能处理节点数高达744,710的超大规模TSP，无需分治策略。

> **摘要翻译:** 旅行商问题（TSP）是一个著名的组合优化问题，具有广泛的现实世界应用。最近基于神经网络的TSP求解器取得了有希望的成果。然而，这些模型通常难以使用同一组预训练模型参数高效地解决小规模和大规模TSP，这限制了它们的实际效用。为了解决这个问题，我们引入了一种名为GELD的新型神经TSP求解器，它建立在我们提出的广域全局评估和精细局部选择框架之上。具体来说，GELD将一个轻量级的全局视角编码器（GE）与一个重量级的局部视角解码器（LD）相结合，以丰富嵌入表示，同时加速决策过程。此外，GE包含一种新颖的低复杂度注意力机制，使得GELD能够实现低推理延迟并扩展到更大规模的TSP。此外，我们提出了一种两阶段训练策略，利用不同大小的训练实例来增强GELD的泛化能力。在合成和真实世界数据集上进行的广泛实验表明，GELD在解决方案质量和推理速度方面均优于七种最先进的模型。此外，GELD可以作为后处理方法，通过花费可承受的额外计算时间，显著提升现有神经TSP求解器导出的解决方案质量。值得注意的是，据我们所知，GELD能够解决多达744,710个节点的TSP问题，这是首个在不依赖分治策略的情况下解决如此大规模TSP问题的方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [197] [Contextual Experience Replay for Self-Improvement of Language Agents](https://arxiv.org/abs/2506.06698)
> *上下文经验回放用于语言智能体的自我提升*

*Yitao Liu, Chenglei Si, Karthik Narasimhan, Shunyu Yao* | **Main category: cs.AI**

**Keywords:** 上下文经验回放, 语言智能体, 自我提升, 大型语言模型, 网络导航

**Comment:** Accepted to ACL 2025. 20 pages

> **TL;DR:** 大型语言模型（LLM）智能体在复杂决策任务中因缺乏环境特定经验和持续学习能力而受限。本文提出上下文经验回放（CER），一个免训练框架，通过在上下文窗口中积累和合成过往经验，显著提升智能体在Web导航等任务中的表现和适应性。

**AI_Comments:** CER的创新之处在于其免训练的特性，以及在上下文窗口中实现持续学习的能力，这对于LLM智能体在复杂环境中的适应性和泛化能力至关重要。通过动态记忆缓冲区来积累和利用经验是一种高效且实用的方法，为LLM智能体的自我改进提供了一条新途径。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）智能体在网络导航等序列决策任务中，由于缺乏环境特定经验，且当前设计无法在推理时持续学习过往经验，导致其在复杂任务中表现不佳。

**Method:** 本文提出了上下文经验回放（CER），一个免训练的框架，旨在使其语言智能体在上下文窗口中高效地自我提升。CER通过将过往经验（包括环境动态和常见决策模式）积累并合成到一个动态记忆缓冲区中。智能体在新任务中可以检索并利用这些相关知识来增强自身，从而提高在复杂环境中的适应性。

**Result:** 在VisualWebArena基准测试中，CER取得了31.9%的竞争力表现。在WebArena基准测试中，CER的平均成功率为36.7%，相对GPT-4o智能体基线提升了51.0%的成功率。研究还对其进行了全面分析，以证明其效率、有效性并加深理解。

**Conclusion:** 上下文经验回放（CER）是一个高效且有效的免训练框架，它通过在上下文窗口中积累和利用过往经验，显著提升了语言智能体在复杂环境中的自我改进能力和适应性。

> **ai_Abstract:** 本文提出了上下文经验回放（CER），一个免训练的框架，旨在通过在上下文窗口中积累和合成过往经验，使语言智能体能够高效地自我提升。CER通过动态记忆缓冲区存储环境动态和决策模式，从而在复杂任务中增强智能体的适应性。在WebArena和VisualWebArena基准测试中，CER表现出竞争力，并在WebArena上相对GPT-4o基线提升了51.0%的成功率。

> **摘要翻译:** 大型语言模型（LLM）智能体已被应用于网络导航等序列决策任务中，但由于缺乏任何环境特定经验，它们在这些复杂任务中常常失败。此外，当前的LLM智能体并非旨在推理时持续学习过往经验，而这对于它们获取这些环境特定经验可能至关重要。为了解决这个问题，我们提出了上下文经验回放（CER），一个免训练的框架，旨在使其语言智能体在上下文窗口中高效地自我提升。具体来说，CER积累并合成过往经验到一个动态记忆缓冲区中。这些经验包括环境动态和常见决策模式，使智能体在新任务中能够检索并利用相关知识来增强自身，从而提高在复杂环境中的适应性。我们在具有挑战性的WebArena和VisualWebArena基准测试中评估了CER。在VisualWebArena上，CER取得了31.9%的竞争力表现。在WebArena上，CER也获得了36.7%的竞争力平均成功率，相对GPT-4o智能体基线提升了51.0%的成功率。我们还对其进行了全面分析，以证明其效率、有效性并加深理解。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [206] [Integrating AI Planning Semantics into SysML System Models for Automated PDDL File Generation](https://arxiv.org/abs/2506.06714)
> *将AI规划语义集成到SysML系统模型中以实现PDDL文件自动化生成*

*Hamied Nabizada, Tom Jeleniewski, Lasse Beers, Maximilian Weigand, Felix Gehlhoff, Alexander Fay* | **Main category: cs.AI**

**Keywords:** SysML, AI规划, PDDL, 系统建模, 自动化生成

**Comment:** 

> **TL;DR:** 本文提出了一种SysML配置文件，用于将PDDL规划语义直接集成到系统模型中，实现PDDL文件自动化生成，并在航空制造案例中得到验证。

**AI_Comments:** 这项工作创新性地将SysML系统建模与AI规划（PDDL）相结合，通过定义专门的SysML配置文件，实现了规划描述的自动化生成。其重要性在于为复杂的工程系统设计提供了一种集成化的、模型驱动的规划方法，有望提高规划效率和准确性。通过案例研究展示了其实用性，为未来在其他工程领域的应用提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 解决在工程设计中系统建模与AI规划之间的集成问题，实现规划描述的自动化和基于模型的生成。

**Method:** 提出一个SysML配置文件，该文件基于PDDL 3.1的BNF定义，定义了可重用的PDDL概念刻板印象（如类型、谓词、函数和动作），并使用OCL约束确保语法一致性。

**Result:** 该配置文件成功应用于航空制造案例研究，对一个具有可互换末端执行器的机器人系统进行建模和丰富，从而生成PDDL格式的领域和问题描述，这些描述可作为PDDL求解器的输入，用于导出优化的执行计划。

**Conclusion:** 该方法支持规划描述的自动化和基于模型的生成，并在工程设计中的系统建模与AI规划之间提供了可重用的桥梁。

> **ai_Abstract:** 本文介绍了一种SysML配置文件，旨在将PDDL规划语义无缝集成到系统模型中。该配置文件通过定义PDDL概念的刻板印象和OCL约束，实现了PDDL文件的自动化生成。通过航空制造中的机器人系统案例研究，验证了该方法能够生成PDDL领域和问题描述，进而用于规划求解器生成优化执行计划。这为系统建模与AI规划之间建立了自动化的、基于模型的桥梁。

> **摘要翻译:** 本文提出了一个SysML配置文件，该文件能够将基于规划领域定义语言（PDDL）的规划语义直接集成到系统模型中。为类型、谓词、函数和动作等关键PDDL概念定义了可重用的刻板印象，同时正式的OCL约束确保了语法一致性。该配置文件源自PDDL 3.1的巴克斯-瑙尔范式（BNF）定义，以与SysML建模实践保持一致。一个来自飞机制造的案例研究展示了该配置文件的应用：对一个带有可互换末端执行器的机器人系统进行建模和丰富，以生成PDDL格式的领域和问题描述。这些描述被用作PDDL求解器的输入，以导出优化的执行计划。该方法支持规划描述的自动化和基于模型的生成，并在工程设计中的系统建模与AI规划之间提供了可重用桥梁。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [213] [WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making](https://arxiv.org/abs/2506.06725)
> *WorldLLM：通过好奇心驱动的理论构建改进LLM的世界建模*

*Guillaume Levy, Cedric Colas, Pierre-Yves Oudeyer, Thomas Carta, Clement Romac* | **Main category: cs.AI**

**Keywords:** LLM, 世界建模, 贝叶斯推理, 强化学习, 好奇心驱动

**Comment:** 

> **TL;DR:** WorldLLM框架结合贝叶斯推理、主动探索和强化学习，通过迭代细化假设和收集证据，显著提高了LLM在结构化领域环境中的预测精度和可解释性。

**AI_Comments:** WorldLLM的创新之处在于其将贝叶斯推理、强化学习和两个LLM的协同作用结合起来，以实现好奇心驱动的理论构建和预测改进。其能够生成人类可解释的环境动态理论是一个重要的优势，有助于提高LLM在复杂环境中的透明度和可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）虽然拥有通用世界知识，但在结构化、特定领域（如模拟）中生成精确预测时表现不佳，因为它们无法将其广泛的非结构化理解与特定环境相结合。

**Method:** WorldLLM框架通过结合贝叶斯推理和自主主动探索与强化学习来增强基于LLM的世界建模。它利用LLM的上下文学习能力，通过自然语言假设指导LLM世界模型的预测。这些假设通过一个贝叶斯推理框架迭代细化，该框架使用第二个LLM作为给定收集到的证据的提议分布。证据通过好奇心驱动的强化学习策略收集，该策略探索环境以找到在当前假设下LLM预测模型中对数似然较低的转换。通过交替细化假设和收集新证据，框架自主地推动预测的持续改进。

**Result:** 在文本游戏环境中的实验证明，WorldLLM不仅提高了预测精度，而且生成了人类可解释的环境动态理论。

**Conclusion:** WorldLLM通过结合贝叶斯推理和强化学习，有效解决了LLM在结构化环境中精确预测的局限性，并能生成可解释的理论，从而持续改进其世界建模能力。

> **ai_Abstract:** WorldLLM是一个旨在解决大型语言模型在结构化、特定领域环境中预测精度不足的框架。它通过结合贝叶斯推理和好奇心驱动的强化学习，利用两个LLM迭代地细化自然语言假设并收集环境证据。这种方法显著提高了LLM的预测准确性，并能生成可解释的环境动态理论。

> **摘要翻译:** 大型语言模型（LLM）拥有通用世界知识，但在结构化、特定领域（如模拟）中生成精确预测时常常遇到困难。这些局限性源于它们无法将其广泛的、非结构化理解与特定环境相结合。为了解决这个问题，我们提出了WorldLLM，一个通过结合贝叶斯推理和自主主动探索与强化学习来增强基于LLM的世界建模的框架。WorldLLM利用LLM的上下文学习能力，通过提示中给出的自然语言假设来指导基于LLM的世界模型的预测。这些假设通过一个贝叶斯推理框架迭代细化，该框架利用第二个LLM作为给定收集到的证据的提议分布。这些证据通过一个好奇心驱动的强化学习策略收集，该策略探索环境以找到在当前假设下LLM预测模型中对数似然较低的转换。通过交替细化假设和收集新证据，我们的框架自主地推动预测的持续改进。我们的实验证明了WorldLLM在一个需要智能体操作和组合对象的文本游戏环境中的有效性。该框架不仅提高了预测精度，而且生成了人类可解释的环境动态理论。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [218] [Agent Semantics, Semantic Spacetime, and Graphical Reasoning](https://arxiv.org/abs/2506.07756)
> *代理语义、语义时空与图形推理*

*Mark Burgess* | **Main category: cs.AI**

**Keywords:** 语义时空, 图模型, 吸收态, 信息泄漏, 承诺理论

**Comment:** 

> **TL;DR:** 本文介绍了语义时空图模型的形式方面，及其在有向知识表示和过程建模中的应用。它定义了一个有限的$\gamma(3,4)$表示，以形成一个可扩展到任意语义复杂度的封闭操作集，并通过语义时空假设为图路径带来可预测性。论文还探讨了图过程中吸收态导致的信息泄漏问题，并将其与边界信息和意图性联系起来。

**AI_Comments:** 本文提出了一个新颖的语义时空图模型，并引入了$\gamma(3,4)$表示来处理复杂的语义。其创新之处在于将信息泄漏、吸收态与“除以零”的数学概念联系起来，并引入“意图性”作为补救机制，为图模型中的信息流和控制提供了独特视角。该模型在处理复杂知识表示和过程建模方面具有潜在的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在介绍语义时空图模型的形式方面，并探讨其在有向知识表示和过程建模中的应用，特别是解决图过程中信息泄漏和吸收态的问题。

**Method:** 本文定义了一个有限的$\gamma(3,4)$表示，用于形成一个封闭的操作集，并应用语义时空假设来为图中的路径提供可预测性。此外，它还参考了其与承诺理论（Promise Theory）的渊源来阐明吸收态。

**Result:** 语义时空假设以最小的约束带来了图路径的可预测性。任何部分图中普遍存在的吸收态意味着图过程会泄漏信息，这与除以零的问题密切相关，预示着封闭性的丧失以及需要手动注入补救信息。语义时空模型（及其承诺理论）的起源有助于阐明这些吸收态如何与意图性可以进入的边界信息相关联。

**Conclusion:** 语义时空模型及其承诺理论的起源有助于澄清吸收态如何与边界信息相关联，即意图性可以在这些边界信息处进入，从而解决图过程中信息泄漏和封闭性丧失的问题。

> **ai_Abstract:** 本文探讨了语义时空图模型的形式化方面及其在有向知识表示和过程建模中的应用。它引入了一个有限的$\gamma(3,4)$表示来处理语义复杂度，并通过语义时空假设实现了图路径的可预测性。文章深入分析了图过程中吸收态导致的信息泄漏问题，将其与“除以零”的封闭性丧失联系起来，并指出语义时空模型（及其承诺理论）揭示了吸收态与意图性可以注入的边界信息之间的关联，从而为信息泄漏提供了补救机制。

> **摘要翻译:** 本文介绍了语义时空图模型的一些形式方面，并参考其在有向知识表示和过程建模中的应用。定义了一个有限的$\gamma(3,4)$表示，以形成一个可以扩展到任何语义复杂度的封闭操作集。语义时空假设以最小的约束为图中的路径带来了可预测性。任何部分图中普遍存在的吸收态意味着图过程会泄漏信息。这个问题与除以零的问题密切相关，后者标志着封闭性的丧失以及需要手动注入补救信息。语义时空模型（及其承诺理论）的起源有助于阐明这些吸收态如何与意图性可以进入的边界信息相关联。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [222] [VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs](https://arxiv.org/abs/2506.06727)
> *VisioMath：LMMs中基于图像的数学推理基准测试*

*Can Li, Ting Zhang, Mei Wang, Hua Huang* | **Main category: cs.AI**

**Keywords:** 多模态模型, 数学推理, 图像基准, VisioMath, LMMs

**Comment:** 

> **TL;DR:** VisioMath是一个新基准，用于评估大型多模态模型在答案选项为图像时的数学推理能力，发现现有模型表现不佳。

**AI_Comments:** 该论文通过引入VisioMath基准，创新性地解决了大型多模态模型在处理基于图像答案的数学推理这一未充分探索的领域。它揭示了当前LMMs在区分视觉相似图像选项时的显著局限性，特别是GPT-4o的低准确率突显了未来研究的巨大潜力。VisioMath的重要性在于它为多模态推理领域提供了一个急需的、具有挑战性的测试平台，有望推动模型在更精细视觉理解方面的进步。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）在解决问题方面表现出色，但当答案选项以图像形式呈现时，它们的数学推理能力（多图像理解的关键方面）仍未得到充分探索。为弥补这一空白，引入了VisioMath。

**Method:** 引入VisioMath，一个包含8,070张图像和1,800道多项选择题的基准，其中每个答案选项都是一张图像。系统评估了最先进的LMMs在VisioMath上的表现。

**Result:** 即使是最先进的模型也难以完成这项任务。GPT-4o的准确率仅为45.9%，这突显了当前模型在对视觉相似的答案选项进行推理时的局限性。

**Conclusion:** VisioMath通过弥补现有基准中的关键空白，为未来的研究建立了严格的测试平台，推动了多模态推理的进步。

> **ai_Abstract:** 该论文介绍了VisioMath，一个新颖的基准数据集，旨在评估大型多模态模型（LMMs）在答案选项为图像时的数学推理能力。VisioMath包含8,070张图像和1,800道多项选择题，专门用于测试模型对视觉相似答案的细微区分能力。研究发现，即使是GPT-4o等最先进的LMMs，在此任务上的表现也差强人意，准确率仅为45.9%。VisioMath填补了现有基准的空白，为推动多模态推理研究提供了严格的测试平台。

> **摘要翻译:** 大型多模态模型（LMMs）在各个领域都展现出卓越的问题解决能力。然而，当答案选项以图像形式呈现时，它们的数学推理能力——多图像理解的一个重要方面——仍未得到充分探索。为了弥补这一空白，我们引入了VisioMath，一个旨在评估涉及基于图像答案选项的多模态环境中数学推理能力的基准。VisioMath包含8,070张图像和1,800道多项选择题，其中每个答案选项都是一张图像，对现有LMMs提出了独特的挑战。据我们所知，VisioMath是第一个专门为基于图像选项场景中的数学推理量身定制的数据集，在此类场景中，答案选项之间的细微差别对于准确解决问题至关重要。我们系统地评估了VisioMath上最先进的LMMs，发现即使是最先进的模型也难以完成这项任务。值得注意的是，GPT-4o的准确率仅为45.9%，这突显了当前模型在对视觉相似的答案选项进行推理时的局限性。通过弥补现有基准中的关键空白，VisioMath为未来的研究建立了严格的测试平台，推动了多模态推理的进步。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [228] [Honey, I shrunk the hypothesis space (through logical preprocessing)](https://arxiv.org/abs/2506.06739)
> *亲爱的，我缩小了假设空间（通过逻辑预处理）*

*Andrew Cropper, Filipe Gouveia, David M. Cerna* | **Main category: cs.AI**

**Keywords:** 归纳逻辑编程, 假设空间缩小, 逻辑预处理, 答案集编程, 机器学习

**Comment:** Submitted to JAIR

> **TL;DR:** 该研究提出了一种逻辑预处理方法，用于在归纳逻辑编程（ILP）搜索之前缩小假设空间，从而显著减少学习时间，同时保持预测准确性。

**AI_Comments:** 这篇论文提出了一种创新且实用的方法来优化归纳逻辑编程（ILP）的性能。通过在搜索之前对假设空间进行逻辑预处理，它有效地解决了ILP中常见的搜索效率问题。这种方法的重要性在于它能够将学习时间从数小时缩短到几秒，这对于实际应用中的ILP系统具有巨大的潜在价值。其通用性通过在不同领域（视觉推理和游戏）的成功应用得到了证明。

<details>
  <summary>Details</summary>

**Motivation:** 归纳逻辑编程（ILP）的目标是在假设空间中搜索能够泛化训练示例和背景知识的假设。本研究的动机是引入一种方法，在ILP系统搜索之前“缩小”假设空间，以提高学习效率。

**Method:** 该方法利用背景知识识别无论训练示例如何都无法成为最优假设的规则，例如“偶数不能是奇数”和“大于2的素数是奇数”。然后，它从假设空间中删除这些违反性规则。该方法通过答案集编程实现，并用于缩小基于约束的ILP系统的假设空间。

**Result:** 在包括视觉推理和游戏在内的多个领域进行的实验表明，该方法可以显著减少学习时间，同时保持预测准确性。例如，仅需10秒的预处理时间，学习时间就可以从10小时以上缩短到仅2秒。

**Conclusion:** 通过逻辑预处理缩小假设空间，可以大幅提高归纳逻辑编程（ILP）的学习效率，同时不牺牲预测准确性。

> **ai_Abstract:** 这项研究提出了一种逻辑预处理方法，用于在归纳逻辑编程（ILP）搜索之前缩小假设空间。该方法利用背景知识识别并移除不可能成为最优假设的规则，显著减少了ILP的学习时间，同时保持了预测准确性。实验证明，该方法在多个领域（如视觉推理和游戏）表现出色，能将学习时间大幅缩短。

> **摘要翻译:** 归纳逻辑编程（ILP）是一种逻辑机器学习形式。其目标是在假设空间中搜索能够泛化训练示例和背景知识的假设。我们引入了一种方法，在ILP系统搜索假设空间之前“缩小”它。我们的方法利用背景知识来查找无论训练示例如何都无法成为最优假设的规则。例如，我们的方法发现了诸如“偶数不能是奇数”和“大于2的素数是奇数”之类的关系。然后，它从假设空间中删除违反性规则。我们使用答案集编程实现了我们的方法，并用它来缩小基于约束的ILP系统的假设空间。我们在包括视觉推理和游戏在内的多个领域进行的实验表明，我们的方法可以显著减少学习时间，同时保持预测准确性。例如，仅需10秒的预处理时间，我们的方法就可以将学习时间从10小时以上缩短到仅2秒。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [234] [Boosting Vulnerability Detection of LLMs via Curriculum Preference Optimization with Synthetic Reasoning Data](https://arxiv.org/abs/2506.07390)
> *LLM漏洞检测能力提升：基于课程偏好优化与合成推理数据*

*Xin-Cheng Wen, Yijun Yang, Cuiyun Gao, Yang Xiao, Deheng Ye* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 漏洞检测, 推理数据合成, 偏好优化, 课程学习

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** 提出ReVD框架，通过合成推理数据和课程偏好优化显著提升LLM的软件漏洞检测能力，实现SOTA表现。

**AI_Comments:** 该论文通过引入合成推理数据和创新的偏好优化方法，有效解决了LLM在漏洞检测中对推理能力的需求和高质量数据稀缺的问题，为提升LLM在专业领域的应用提供了新的思路，具有重要的研究价值和实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在软件漏洞检测方面能力有限，主要原因在于缺乏与漏洞相关的推理数据，阻碍了模型捕获潜在漏洞模式的能力；同时，LLMs侧重于学习语义表示而非其背后的原因，导致无法识别语义相似的漏洞样本。此外，开发专门的LLMs用于漏洞检测面临高质量数据集稀缺的挑战。

**Method:** 本文提出了ReVD框架，通过以下方法挖掘漏洞模式：1) 构建漏洞及其修复代码的前向和后向推理过程，以合成高质量的推理数据。2) 设计三元组监督微调，随后进行课程在线偏好优化，使ReVD更好地理解漏洞模式。

**Result:** 在PrimeVul和SVEN数据集上进行的广泛实验表明，ReVD在基于LLM的软件漏洞检测方面达到了新的最先进水平，准确率提升了12.24%-22.77%。

**Conclusion:** ReVD框架通过结合合成推理数据和漏洞特定偏好优化，有效解决了LLM在漏洞检测中的局限性，并显著提升了其性能，达到了当前最先进水平。

> **ai_Abstract:** 本文提出ReVD框架，旨在提升大型语言模型在软件漏洞检测方面的能力。针对现有LLM缺乏推理数据和侧重语义而非推理原因的局限，ReVD通过合成高质量的漏洞推理数据，并结合三元组监督微调和课程在线偏好优化，使模型更好地理解和识别漏洞模式。实验结果表明，ReVD在PrimeVul和SVEN数据集上显著优于现有SOTA方法，大幅提高了漏洞检测的准确率，实现了12.24%-22.77%的准确率提升。

> **摘要翻译:** 大型语言模型（LLMs）在众多编码相关任务中表现出相当的熟练程度；然而，它们在检测软件漏洞方面的能力仍然有限。这种局限性主要源于两个因素：（1）缺乏与漏洞相关的推理数据，这阻碍了模型捕获潜在漏洞模式的能力；（2）它们侧重于学习语义表示而非其背后的原因，因此未能识别语义相似的漏洞样本。此外，开发专门用于漏洞检测的LLM具有挑战性，特别是在高质量数据集稀缺的环境中。在本文中，我们提出了一种新颖的框架ReVD，该框架通过推理数据合成和漏洞特定偏好优化，擅长挖掘漏洞模式。具体来说，我们构建了漏洞和相应修复代码的前向和后向推理过程，确保合成高质量的推理数据。此外，我们设计了三元组监督微调，随后进行课程在线偏好优化，以使ReVD更好地理解漏洞模式。在PrimeVul和SVEN数据集上进行的广泛实验表明，ReVD为基于LLM的软件漏洞检测设定了新的最先进水平，例如准确率提高了12.24%-22.77%。源代码和数据可在https://github.com/Xin-Cheng-Wen/PO4Vul 获取。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [236] [AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method](https://arxiv.org/abs/2506.06740)
> *AI PsyRoom：分段渴望与反应性结果优化方法的人工智能平台*

*Yigui Feng, Qinglin Wang, Ke Liu, Xinhai Chen, Bo Yang, Jie Liu* | **Main category: cs.AI**

**Keywords:** 心理咨询, 人工智能, 多智能体系统, 情感分类, 个性化治疗

**Comment:** 

> **TL;DR:** AI PsyRoom是一个多智能体框架，通过细粒度情感分类和对话重建，生成同理心对话和个性化治疗方案，显著提升AI心理咨询效果。

**AI_Comments:** 本文的创新点在于提出了一个多智能体模拟框架AI PsyRoom，通过细粒度情感分类和对话重建，解决了现有LLM在心理咨询中情感理解不足和个性化治疗方案生成困难的问题。其构建的EmoPsy数据集和PsyRoom B模块具有很高的实用价值和研究潜力，为AI辅助心理咨询领域的发展提供了重要基础。模型的公开可用性也促进了该领域的研究进展。

<details>
  <summary>Details</summary>

**Motivation:** 心理咨询面临服务需求增长和专业人员短缺的挑战；现有大型语言模型（LLM）缺乏对情感的深入理解，无法生成基于细粒度情感的个性化治疗方案。

**Method:** 提出了AI PsyRoom，一个多智能体模拟框架，旨在通过生成同理心和情感细致的对话来增强心理咨询。它利用细粒度情感分类和多智能体框架，构建了用于对话重建的PsyRoom A，并生成了高质量的EmoPsy对话数据集；同时提出了用于生成个性化治疗方案的PsyRoom B。

**Result:** AI PsyRoom在问题导向方面提升18%，表达方面提升23%，同理心方面提升24%，互动交流质量方面提升16%，显著优于现有最先进的方法。

**Conclusion:** AI PsyRoom为推进AI辅助心理咨询研究提供了基础，其数据集和模型已公开可用。

> **ai_Abstract:** 针对心理咨询中专业人员短缺及现有LLM情感理解和个性化治疗不足的问题，本文提出了AI PsyRoom，一个多智能体模拟框架。该框架通过细粒度情感分类和多智能体技术，构建了PsyRoom A用于对话重建并生成了大规模高质量情感对话数据集EmoPsy，同时提出了PsyRoom B用于生成个性化治疗方案。实验结果表明，AI PsyRoom在多个关键指标上显著优于现有方法，并已公开其数据集和模型，为AI辅助心理咨询研究提供了重要基础。

> **摘要翻译:** 心理咨询面临巨大挑战，因为心理健康服务需求不断增长，而训练有素的专业人员却短缺。大型语言模型（LLMs）已显示出辅助心理咨询的潜力，尤其是在同理心和情感支持方面。然而，现有模型缺乏对情感的深入理解，并且无法根据细粒度情感生成个性化的治疗方案。为了解决这些缺点，我们提出了AI PsyRoom，一个多智能体模拟框架，旨在通过生成富有同理心和情感细致的对话来增强心理咨询。通过利用细粒度情感分类和多智能体框架，我们构建了一个用于对话重建的多智能体PsyRoom A，生成了一个高质量的对话数据集EmoPsy，其中包含35种子情感、423个特定情感场景和12,350个对话。我们还提出了用于生成个性化治疗方案的PsyRoom B。定量评估表明，AI PsyRoom显著优于现有最先进的方法，在问题导向方面实现了18%的改进，在表达方面实现了23%的改进，在同理心方面实现了24%的改进，在互动交流质量方面实现了16%的改进。数据集和模型均已公开可用，为推进AI辅助心理咨询研究奠定了基础。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [245] [Bio-Inspired Classification: Combining Information Theory and Spiking Neural Networks -- Influence of the Learning Rules](https://arxiv.org/abs/2506.06750)
> *生物启发式分类：结合信息论与脉冲神经网络——学习规则的影响*

*Zofia Rudnicka, Janusz Szczepanski, Agnieszka Pregowska* | **Main category: cs.AI**

**Keywords:** 脉冲神经网络, 生物启发式学习, Lempel-Ziv复杂度, 分类, 学习规则

**Comment:** 

> **TL;DR:** 本文探讨了不同学习算法对脉冲神经网络（SNN）分类准确性的影响，并提出了一种结合SNN和Lempel-Ziv复杂度的生物启发式分类器，旨在平衡分类精度和计算效率。

**AI_Comments:** 本文的创新点在于结合了SNN的生物真实性和LZC的信息理论分析，为时空神经数据分类提供了一种新颖且可解释的方法。其重要性在于揭示了SNN学习规则选择的权衡，为实际应用中SNN的部署提供了指导。尤其强调了生物启发式算法在计算效率方面的优势，这对于资源受限或实时性要求高的场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 脉冲神经网络（SNN）的训练由于其时间动态性、脉冲事件的不可微性以及稀疏事件驱动激活等独特属性而具有挑战性。

**Method:** 本文广泛考虑了所选学习算法类型（包括生物启发式学习规则）对分类准确性的影响。提出了一种基于SNN和Lempel-Ziv复杂度（LZC）结合的生物启发式分类器，该方法结合了SNN在时间精度和生物真实性方面的优势与LZC的结构复杂度分析，以促进时空神经数据的有效和可解释分类。

**Result:** 经典的反向传播算法取得了出色的分类准确性，但计算成本极高，不适用于实时应用。Tempotron和Spikprop等生物启发式学习算法在提高计算效率的同时保持了有竞争力的分类性能，适用于时间敏感的任务。

**Conclusion:** 最合适的学习算法的选择取决于分类准确性与计算成本之间的权衡以及应用限制。

> **ai_Abstract:** 本研究旨在克服脉冲神经网络（SNN）训练的挑战，通过结合SNN和Lempel-Ziv复杂度（LZC）提出了一种生物启发式分类器。研究比较了不同学习规则对SNN分类准确性和计算效率的影响，发现经典的反向传播算法虽然准确但计算成本高昂，而Tempotron和Spikprop等生物启发式算法能在保持竞争性性能的同时显著提高效率，为实时应用提供了更可行的选择。

> **摘要翻译:** 脉冲神经网络（SNN）的训练由于其独特属性（包括时间动态性、脉冲事件的不可微性以及稀疏事件驱动激活）而具有挑战性。在本文中，我们广泛考虑了所选学习算法类型（包括生物启发式学习规则）对分类准确性的影响。我们提出了一种基于SNN和Lempel-Ziv复杂度（LZC）结合的生物启发式分类器。该方法结合了SNN在时间精度和生物真实性方面的优势与LZC的结构复杂度分析，以促进时空神经数据的有效和可解释分类。结果表明，经典的反向传播算法取得了出色的分类准确性，但计算成本极高，这使其不适用于实时应用。Tempotron和Spikprop等生物启发式学习算法在提高计算效率的同时保持了有竞争力的分类性能，使其适用于时间敏感的任务。所获得的结果表明，最合适的学习算法的选择取决于分类准确性与计算成本之间的权衡以及应用限制。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [254] [Learning What Matters Now: A Dual-Critic Context-Aware RL Framework for Priority-Driven Information Gain](https://arxiv.org/abs/2506.06786)
> *学习当前重要内容：一种用于优先级驱动信息增益的双评论家上下文感知强化学习框架*

*Dimitris Panagopoulos, Adolfo Perrusquia, Weisi Guo* | **Main category: cs.AI**

**Keywords:** 强化学习, 上下文感知, 优先级驱动, 信息增益, 搜索救援

**Comment:** 6 pages, 2 figures, 3 tables, submitted as a regural paper to IEEE
  International Conference on Systems, Man, and Cybernetics (SMC) 2025

> **TL;DR:** CA-MIQ是一种轻量级双评论家强化学习框架，它能根据任务优先级变化动态调整探索策略，在模拟搜索救援任务中表现出显著优于基线的任务成功率。

**AI_Comments:** CA-MIQ的创新之处在于其双评论家设计和内置的转移检测器，使其能够灵活适应优先级变化，这对于高动态环境中的自主系统至关重要。其在模拟搜救任务中的卓越表现，尤其是在多优先级转移场景下的高恢复率，凸显了该框架的实用性和重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自主系统在搜救任务中需要持续收集关键信息，同时灵活适应不断变化的行动优先级，这促使了对能够动态调整探索策略的强化学习框架的需求。

**Method:** 本文提出了CA-MIQ（Context-Aware Max-Information Q-learning），一个轻量级的双评论家强化学习（RL）框架。它将一个标准的外在评论家用于任务奖励，并结合一个内在评论家，该评论家融合了状态新颖性、信息位置感知和实时优先级对齐。内置的转移检测器会触发短暂的探索提升和选择性评论家重置，使智能体能够在优先级修订后重新聚焦。

**Result:** 在模拟搜救网格世界中，CA-MIQ在单次优先级转移后实现了比基线高近四倍的任务成功率，在多次转移场景中表现提高三倍以上，实现了100%的恢复率，而基线方法未能适应。

**Conclusion:** CA-MIQ在具有分段平稳信息价值分布的任何离散环境中都非常有效，能够有效地应对优先级变化。

> **ai_Abstract:** 本文提出了一种名为CA-MIQ的双评论家上下文感知强化学习框架，旨在解决自主系统在面临不断变化的优先级时如何高效收集任务关键信息的问题。CA-MIQ通过结合外在和内在评论家，并利用内置的转移检测器来动态调整探索策略。在模拟搜救任务中的实验表明，该框架在应对优先级变化方面表现出色，显著优于现有基线方法，任务成功率大幅提升。

> **摘要翻译:** 自主系统在高度危险的搜索救援（SAR）任务中运行，必须持续收集任务关键信息，同时灵活适应不断变化的行动优先级。我们提出了CA-MIQ（Context-Aware Max-Information Q-learning），一个轻量级的双评论家强化学习（RL）框架，它能在任务优先级改变时动态调整其探索策略。CA-MIQ将一个用于任务奖励的标准外在评论家与一个内在评论家配对，该内在评论家融合了状态新颖性、信息位置感知和实时优先级对齐。内置的转移检测器会触发短暂的探索提升和选择性评论家重置，允许智能体在优先级修订后重新聚焦。在模拟SAR网格世界中，实验专门测试了对智能体预期关注的信息类型优先级顺序变化的适应性，CA-MIQ在单次优先级转移后实现了比基线高近四倍的任务成功率，在多次转移场景中表现提高三倍以上，实现了100%的恢复率，而基线方法未能适应。这些结果凸显了CA-MIQ在任何具有分段平稳信息价值分布的离散环境中的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [262] [Cross-Entropy Games for Language Models: From Implicit Knowledge to General Capability Measures](https://arxiv.org/abs/2506.06832)
> *语言模型的交叉熵博弈：从隐性知识到通用能力衡量*

*Clément Hongler, Andrew Emil* | **Main category: cs.AI**

**Keywords:** 交叉熵博弈, 大型语言模型, 能力衡量, 隐性知识, 博弈论

**Comment:** 41 pages, 16 figures

> **TL;DR:** 该论文提出“交叉熵（Xent）博弈”作为一种新颖的框架，用于超越生成采样来评估大型语言模型（LLM）的通用能力，通过基于LLM概率度量的游戏化任务来衡量其隐含知识。

**AI_Comments:** 该论文提出了一个创新的博弈论框架——Xent博弈，旨在超越简单的生成评估来衡量LLM。通过关注隐性知识和更广泛的任务（如反事实思维和异常检测），它提供了一种更全面的方法来衡量LLM的通用能力。利用进化动力学探索通用能力无界范围的思想尤其引人入胜，有望带来更健壮和适应性更强的基准。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在探讨LLM“知道”概率度量意味着什么，并提出超越生成采样的任务来衡量LLM的通用能力，特别是解决衡量通用能力时面临的无界范围问题。

**Method:** 作者提出了基于LLM度量的“交叉熵（Xent）博弈”框架。这些博弈包括交叉熵分数和约束，可以是单人或多人，并可表示为简单的计算图和程序。他们提出使用有限的Xent博弈族作为“Xent博弈度量”来构建能力基准，并通过受进化动力学启发的思想来探索Xent博弈空间，以解决无界范围问题。

**Result:** Xent博弈空间被证明足够大，可以包含大量有趣的例子，并且可以从基本的博弈论一致性公理构建。Xent博弈度量可用于构建LLM能力基准。

**Conclusion:** Xent博弈为评估LLM能力提供了一个新颖的框架，超越了传统的生成采样，为衡量隐性知识和通用能力提供了一种结构化的方法，并通过进化动力学思想应对了无界范围的挑战。

> **ai_Abstract:** 本文引入了“交叉熵（Xent）博弈”这一新颖框架，用于超越传统生成采样来评估大型语言模型（LLM）。这些博弈基于LLM的概率度量，涵盖了摘要、反事实思维和异常检测等多样化任务。Xent博弈涉及交叉熵分数和约束，可以是单人或多人，并被证明可以形成一个丰富且符合公理一致性的空间。作者提出使用有限的Xent博弈族作为“Xent博弈度量”来衡量LLM的能力，并通过进化动力学探索博弈空间，以解决衡量通用能力时面临的无界范围问题。

> **摘要翻译:** 大型语言模型（LLM）定义了文本上的概率度量。通过考虑LLM“知道”这种度量意味着什么以及它在算法上需要什么这一隐性知识问题，我们自然而然地提出了一系列超越生成采样的任务，包括摘要、反事实思维、异常检测、原创性搜索、逆向提示、辩论、创造性解决等形式。这些任务可以被表述为基于LLM度量的博弈，我们称之为交叉熵（Xent）博弈。Xent博弈可以是单人或多人。它们涉及交叉熵分数和交叉熵约束，并且可以表示为简单的计算图和程序。我们展示了Xent博弈空间足够大，可以包含大量有趣的例子，同时可以从基本的博弈论一致性公理构建。然后我们讨论了如何使用Xent博弈空间来衡量LLM的能力。这导致了Xent博弈度量的构建：从给定范围中提取覆盖度量，构建的有限Xent博弈族可以作为能力基准。为了解决与衡量通用能力挑战相关的无界范围问题，我们建议利用受进化动力学启发的思想，以连贯的方式探索Xent博弈空间。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [268] [United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory](https://arxiv.org/abs/2506.06843)
> *统一的思维还是孤立的智能体？探索认知负荷理论下大型语言模型的协调性*

*HaoYang Shang, Xuan Liu, Zi Liang, Jie Zhang, Haibo Hu, Song Guo* | **Main category: cs.AI**

**Keywords:** 大型语言模型, 认知负荷理论, 多智能体系统, 协作问题解决, 性能上限

**Comment:** 

> **TL;DR:** 大型语言模型（LLMs）在复杂任务上表现受限，本文受认知负荷理论启发，提出CoThinker多智能体框架，通过专业化和结构化通信来管理认知负荷，有效提升了LLM的协作问题解决能力。

**AI_Comments:** 这篇论文通过将认知负荷理论引入LLM领域，为理解和解决LLM在复杂任务上的性能瓶颈提供了一个新颖且有力的视角。CoThinker框架的设计理念清晰，通过模拟人类认知过程中的负荷管理策略，有效地提升了LLM的协作能力，这对于未来构建更强大的LLM系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在复杂的、多方面的任务上表现出显著的性能上限，常常无法整合多样信息或遵循多重约束，这可能是因为任务需求超出了LLM的有效认知负荷容量。

**Method:** 引入CoThinker，一个新型的基于LLM的多智能体框架，旨在减轻认知过载并增强协作解决问题的能力。CoThinker通过智能体专业化分配内在认知负荷，并通过结构化通信和集体工作记忆管理事务性负荷，从而操作化认知负荷理论原则。

**Result:** CoThinker在复杂问题解决任务和伪造的高认知负荷场景中进行了实证验证，证明其在解决方案质量和效率上优于现有多智能体基线。分析揭示了特征交互模式，提供了关于集体认知出现和有效负荷管理的见解。

**Conclusion:** CoThinker提供了一种有原则的方法来克服大型语言模型的性能上限，通过有效管理认知负荷和促进集体认知。

> **ai_Abstract:** 本文探讨了大型语言模型（LLMs）在复杂任务上存在的性能上限，并将其归因于认知负荷超出其处理能力。受认知负荷理论（CLT）启发，作者提出了CoThinker，一个新型LLM多智能体框架。CoThinker通过智能体专业化和结构化通信来有效管理认知负荷，并被证明在复杂问题解决任务中优于现有基线，提升了解决方案质量和效率。这项工作为克服LLM性能瓶颈提供了一种原则性方法。

> **摘要翻译:** 大型语言模型（LLMs）在复杂的、多方面的任务上表现出显著的性能上限，因为它们常常无法整合多样信息或遵循多重约束。我们认为，这种限制产生于任务需求超出LLM的有效认知负荷容量时。这种解释与认知科学中的认知负荷理论（CLT）有很强的类比，CLT解释了人类思维中类似的性能边界，并且新兴证据表明LLMs具有有限的工作记忆特性，这进一步支持了该观点。基于这种以CLT为基础的理解，我们引入了CoThinker，一个新型的基于LLM的多智能体框架，旨在减轻认知过载并增强协作解决问题的能力。CoThinker通过智能体专业化分配内在认知负荷，并通过结构化通信和集体工作记忆管理事务性负荷，从而操作化CLT原则。我们在复杂问题解决任务和伪造的高认知负荷场景中对CoThinker进行了实证验证，证明其在解决方案质量和效率上优于现有多智能体基线。我们的分析揭示了特征交互模式，提供了关于集体认知出现和有效负荷管理的见解，从而提供了一种有原则的方法来克服LLM的性能上限。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [273] [Incorporating Failure of Machine Learning in Dynamic Probabilistic Safety Assurance](https://arxiv.org/abs/2506.06868)
> *将机器学习故障纳入动态概率安全保障*

*Razieh Arshadizadeh, Mahmoud Asgari, Zeinab Khosravi, Yiannis Papadopoulos, Koorosh Aslansefat* | **Main category: cs.AI**

**Keywords:** 机器学习故障, 概率安全保障, 贝叶斯网络, SafeML, 分布偏移

**Comment:** 

> **TL;DR:** 本文提出了一种结合SafeML和贝叶斯网络的新型概率安全保障框架，用于动态评估和适应性调整，以解决机器学习模型在安全关键系统中因分布偏移导致的推理故障问题。

**AI_Comments:** 本文提出了一种新颖的方法，通过将SafeML与贝叶斯网络相结合，将机器学习的固有故障（特别是由于数据分布偏移引起的推理故障）整合到概率安全评估中。这种动态的、基于模型的故障处理方式对于提升集成ML的安全关键系统的可靠性至关重要，弥补了传统安全评估方法的不足。其创新性在于将ML特有的不确定性纳入到系统级的因果安全分析中，为实际应用提供了更鲁棒的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习模型越来越多地集成到安全关键系统中，但其固有的不完善性（特别是操作数据和训练数据之间的分布偏移导致的推理故障）引入了新的故障类别。传统的安全评估方法不适用于从数据中学习行为的ML组件。

**Method:** 该研究将SafeML与贝叶斯网络（BNs）集成，以建模机器学习故障，作为更广泛的因果安全分析的一部分。这允许在不确定性下进行动态安全评估和系统适应。

**Result:** 该方法在一个模拟的具有交通标志识别功能的汽车队列系统中进行了演示。研究结果强调了在安全评估中明确建模ML故障的潜在更广泛的好处。

**Conclusion:** 在安全评估中明确建模机器学习故障具有潜在的广泛益处，可以实现不确定性下的动态安全评估和系统适应。

> **ai_Abstract:** 本文提出了一个将SafeML与贝叶斯网络相结合的概率安全保障框架，旨在解决机器学习模型在安全关键系统中因分布偏移导致的推理故障问题。该框架能够动态检测ML推理的置信度，并将ML故障整合到更广泛的因果安全分析中，从而在不确定性下实现动态安全评估和系统适应。通过在模拟汽车队列系统中的演示，研究突出了明确建模ML故障在安全评估中的重要性。

> **摘要翻译:** 机器学习（ML）模型越来越多地集成到自动驾驶车队等安全关键系统中，以实现实时决策。然而，其固有的不完善性引入了一种新型故障：通常由操作数据和训练数据之间的分布偏移触发的推理故障。传统的依赖于设计文物或代码的安全评估方法不适用于从数据中学习行为的ML组件。SafeML最近被提出，用于动态检测此类偏移并为基于ML组件的推理分配置信水平。在此基础上，我们引入了一个概率安全保障框架，该框架将SafeML与贝叶斯网络（BNs）集成，将ML故障建模为更广泛的因果安全分析的一部分。这允许在不确定性下进行动态安全评估和系统适应。我们在一个模拟的具有交通标志识别功能的汽车队列系统中演示了该方法。研究结果强调了在安全评估中明确建模ML故障的潜在更广泛的好处。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [280] [KnowCoder-V2: Deep Knowledge Analysis](https://arxiv.org/abs/2506.06881)
> *KnowCoder-V2: 深度知识分析*

*Zixuan Li, Wenxuan Liu, Long Bai, Chunmao Zhang, Wei Li, Fenghui Zhang, Quanxin Jin, Ruoyun He, Zhuo Chen, Zhilei Hu, Fei Wang, Bingbing Xu, Xuhui Jiang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng* | **Main category: cs.AI**

**Keywords:** 深度知识分析, KDR框架, KnowCoder-V2, 大型语言模型, 代码生成

**Comment:** 

> **TL;DR:** 本文提出了KDR框架和KnowCoder-V2 (KCII) LLM，通过离线知识组织和在线知识计算，有效解决了现有深度知识分析框架在知识管理、效率和复杂计算方面的挑战。

**AI_Comments:** 这篇论文的创新点在于提出了一个分阶段的深度知识分析框架KDR，并引入了KnowCoder-V2 (KCII) 这一新型LLM来桥接知识组织和计算。通过统一代码生成的方式，KCII能够将数据转化为结构化知识对象并进行复杂的分析，有效克服了传统LLM在处理大规模、系统性知识分析任务中的局限性。其离线知识组织和在线知识计算的结合，提高了处理效率和分析深度。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度研究框架在解决复杂深度知识分析任务时面临三大挑战：1) 缺乏系统知识组织和管理；2) 纯在线操作，对共享和大规模知识效率低下；3) 无法执行复杂知识计算，限制了产生有洞察力分析结果的能力。

**Method:** 提出了一种知识深度研究 (KDR) 框架，该框架引入独立的知识组织阶段，将大规模数据离线预处理为系统知识。在此基础上，扩展了深度研究，增加了在线执行复杂知识计算的推理步骤。为增强LLM解决知识分析任务的能力，引入了KnowCoder-V2 (KCII)，一个通过统一代码生成连接知识组织和推理的LLM。KCII为知识组织生成实例化代码将数据转换为知识对象，为知识计算生成分析代码并在知识对象上执行。

**Result:** 在六项知识分析任务的三十多个数据集上的实验结果表明KCII是有效的。此外，当集成到KDR框架中时，与主流深度研究框架相比，KCII能够生成具有洞察力分析结果的高质量报告。

**Conclusion:** Not mentioned in abstract.

> **ai_Abstract:** 本文提出了一个名为知识深度研究 (KDR) 的框架，旨在解决现有深度知识分析框架在知识组织、大规模知识处理效率和复杂知识计算方面的不足。KDR框架通过离线知识组织和在线知识计算实现深度知识分析能力。为增强框架内大型语言模型的能力，研究者引入了KnowCoder-V2 (KCII)，一个利用统一代码生成技术连接知识组织和推理的LLM。KCII通过生成实例化代码将数据转化为知识对象，并生成分析代码对这些对象进行复杂计算。实验结果表明，KCII在多项知识分析任务中表现出有效性，并且在KDR框架中能生成高质量的分析报告。

> **摘要翻译:** 深度知识分析任务总是涉及从大量数据中系统地提取和关联知识，然后进行逻辑推理以发现洞察。然而，为了解决此类复杂任务，现有的深度研究框架面临三大主要挑战：1) 它们缺乏系统的知识组织和管理；2) 它们纯粹在线操作，对于依赖共享和大规模知识的任务来说效率低下；3) 它们无法执行复杂的知识计算，限制了它们产生有洞察力分析结果的能力。受这些挑战的启发，在本文中，我们提出了一个**知识深度研究 (KDR)** 框架，该框架赋予深度研究深度知识分析能力。具体来说，它引入了一个独立的知识组织阶段，将大规模、领域相关的数据离线预处理为系统知识。基于这些知识，它扩展了深度研究，增加了另一种推理步骤，以在线方式执行复杂的知识计算。为了增强大型语言模型 (LLMs) 在上述框架中解决知识分析任务的能力，我们进一步引入了**\KCII**，一个通过统一代码生成连接知识组织和推理的LLM。对于知识组织，它生成预定义类的实例化代码，将数据转换为知识对象。对于知识计算，它生成分析代码并在上述知识对象上执行以获得深度分析结果。在六项知识分析任务的三十多个数据集上的实验结果证明了\KCII的有效性。此外，当集成到KDR框架中时，与主流深度研究框架相比，\KCII能够生成具有洞察力分析结果的高质量报告。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [286] [Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering](https://arxiv.org/abs/2506.06905)
> *元适应性提示蒸馏用于少样本视觉问答*

*Akash Gupta, Amos Storkey, Mirella Lapata* | **Main category: cs.AI**

**Keywords:** 元适应性, 提示蒸馏, 少样本学习, 视觉问答, 大型多模态模型

**Comment:** 

> **TL;DR:** 本文提出了一种元学习方法，通过蒸馏任务相关的图像特征生成可适应的软提示，以解决大型多模态模型（LMMs）在少样本视觉问答中上下文学习（ICL）表现不一致的问题，并在实验中表现优于现有方法。

**AI_Comments:** 该论文通过引入元学习和提示蒸馏，为解决LMMs在少样本场景下ICL性能不佳的问题提供了一个新颖且有效的途径。其创新点在于将任务相关的特征蒸馏为软提示，并通过注意力映射模块实现高效集成和适应。这对于提升LMMs在实际应用中的鲁棒性和效率具有重要意义，尤其是在数据稀缺的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 大型多模态模型（LMMs）的上下文学习（ICL）性能不稳定，尤其是在小型LMMs中，并且不会随着示例的增加而单调提升。研究人员推测这是因为LMM被图像嵌入中与下游任务无关的额外信息所淹没。

**Method:** 本文提出了一种元学习方法，通过固定一组软提示来诱导LMM的少样本能力。这些软提示从任务相关的图像特征中蒸馏而来，并可在测试时通过少量示例进行适应。为了促进蒸馏，引入了一个注意力映射模块，该模块可轻松集成到流行的LLaVA v1.5架构中，并与软提示共同学习，从而在低数据条件下通过少量梯度步骤实现LMMs的任务适应。

**Result:** 在VL-ICL Bench上的评估表明，即使在图像扰动下，该方法也始终优于ICL和相关的提示调整方法，改进了视觉问答任务中的任务归纳和推理能力。

**Conclusion:** 本文提出的元适应性提示蒸馏方法有效解决了LMMs在少样本视觉问答中ICL表现不一致的问题，通过引入任务相关的软提示和注意力映射模块，显著提升了模型在低数据条件下的任务适应和推理能力。

> **ai_Abstract:** 本文提出了一种名为“元适应性提示蒸馏”的新方法，旨在解决大型多模态模型（LMMs）在少样本视觉问答中上下文学习（ICL）性能不稳定的问题。该方法通过元学习框架，从任务相关的图像特征中蒸馏出一组可适应的软提示，并引入了一个注意力映射模块，使其能够与LLaVA v1.5等现有架构无缝集成。实验结果表明，该方法在低数据条件下，通过少量梯度步骤即可实现高效的任务适应，并且在VL-ICL Bench上显著优于传统的ICL和提示调整方法，提升了视觉问答任务的归纳和推理能力。

> **摘要翻译:** 大型多模态模型（LMMs）通常依赖于上下文学习（ICL）来以最少的监督执行新任务。然而，ICL的性能，尤其是在较小的LMMs中，表现不一致，并且不会随着示例的增加而单调提升。我们推测这是因为LMM被图像嵌入中存在的额外信息所淹没，而这些信息对于下游任务来说并非必需。为了解决这个问题，我们提出了一种元学习方法，该方法通过一组固定的软提示为LMMs诱导少样本能力提供了一种替代方案，这些软提示从任务相关的图像特征中蒸馏而来，并且可以在测试时使用少量示例进行适应。为了促进这种蒸馏，我们引入了一个注意力映射模块，该模块可以很容易地与流行的LLaVA v1.5架构集成，并与软提示共同学习，从而在低数据条件下通过少量梯度步骤实现LMMs的任务适应。在VL-ICL Bench上的评估表明，我们的方法始终优于ICL和相关的提示调整方法，即使在图像扰动下也是如此，改进了视觉问答任务中的任务归纳和推理能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [293] [Causal Graph based Event Reasoning using Semantic Relation Experts](https://arxiv.org/abs/2506.06910)
> *基于因果图的事件推理与语义关系专家*

*Mahnaz Koupaee, Xueying Bai, Mudan Chen, Greg Durrett, Nathanael Chambers, Niranjan Balasubramanian* | **Main category: cs.AI**

**Keywords:** 因果图, 事件推理, 大型语言模型, 语义关系, 事件预测

**Comment:** 

> **TL;DR:** 论文提出一种基于因果图的事件推理方法，利用LLM模拟语义关系专家生成因果图，以帮助LLM更好地理解事件间的因果关系，并在事件预测等任务上取得有竞争力的结果。

**AI_Comments:** 这项研究通过引入因果图作为LLM推理的并行机制，为解决LLM在深层事件推理中的因果关系识别问题提供了创新性的视角。其亮点在于利用LLM本身模拟专家进行协作式因果图生成，以及在未微调的情况下达到竞争性结果，这表明了该方法在提升LLM解释性和推理能力方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在事件推理中难以准确识别事件间的因果连接，导致在事件预测和时间线理解等深层推理任务中表现不佳。

**Method:** 本文提出一种协作式因果图生成方法，利用LLM模拟专注于特定语义关系的专家进行多轮讨论并最终整合。随后，将生成的因果图应用于多个下游应用，并引入一个新的可解释事件预测任务，该任务要求解释中包含事件的因果链。

**Result:** 生成的因果图能够辅助推理，其解释比基线生成更具信息量和连贯性。整体方法在未针对任何下游任务进行微调的情况下，在事件预测和下一事件预测任务上均取得了与最先进模型相当的竞争性结果。

**Conclusion:** 通过生成和利用因果事件图，可以有效帮助LLM明确表示因果关系，从而提升事件推理能力，并在相关任务中取得优异表现。

> **ai_Abstract:** 本文旨在解决大型语言模型在事件因果推理方面的不足。作者提出一种新颖的协作式方法，通过LLM模拟语义关系专家生成因果事件图，以显式地表示事件间的因果关系。研究评估了因果图的生成及其对推理的辅助作用，并将其应用于事件预测等任务。实验结果表明，该方法在未进行下游任务微调的情况下，在事件预测和下一事件预测任务上达到了与现有最先进模型相当的性能，并能提供更具信息量和连贯性的因果链解释。

> **摘要翻译:** 理解场景中事件如何相互因果连接对于有效建模和推理事件至关重要。但事件推理仍然是一个难题，尽管最近取得了进展，大型语言模型（LLM）仍然难以准确识别事件间的因果连接。这种困难导致在事件预测和时间线理解等深层推理任务上表现不佳。为了解决这一挑战，我们研究了因果事件图（例如，A使B成为可能）的生成作为一种并行机制，以帮助LLM在推理过程中明确表示因果关系。本文评估了如何生成正确的图以及图如何辅助推理。我们提出了一种协作式因果图生成方法，其中我们使用LLM模拟专注于特定语义关系的专家。这些专家进行多轮讨论，然后由最终专家进行整合。然后，为了展示因果图的效用，我们将其用于多个下游应用，并引入一个新的可解释事件预测任务，该任务要求解释中包含事件的因果链。这些解释比基线生成更具信息量和连贯性。最后，我们的整体方法未在任何下游任务上进行微调，在预测和下一事件预测任务上均取得了与最先进模型相当的竞争性结果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [297] [Boosting LLM Reasoning via Spontaneous Self-Correction](https://arxiv.org/abs/2506.06923)
> *通过自发自我纠正提升大型语言模型推理能力*

*Xutong Zhao, Tengyu Xu, Xuewei Wang, Zhengxing Chen, Di Jin, Liang Tan, Yen-Ting, Zishun Yu, Zhuokai Zhao, Yun He, Sinong Wang, Han Fang, Sarath Chandar, Chen Zhu* | **Main category: cs.AI**

**Keywords:** LLM推理, 自我纠正, 数学推理, 多智能体, 强化学习

**Comment:** 

> **TL;DR:** SPOC是一种自发自我纠正方法，使大型语言模型（LLM）能够在单次推理中进行数学推理的自我校正，显著提高了性能。

**AI_Comments:** SPOC的创新之处在于实现了单次推理中的“自发”自我纠正，通过将LLM转化为具有解决方案提议和验证双重角色的多智能体，有效解决了现有方法的局限性。利用合成数据微调和在线强化学习进一步增强了其能力，显著提升了LLM在复杂数学推理任务上的性能，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在数学推理方面仍面临挑战。现有的自我纠正方法需要额外的提示和系统设计，将纠正视为生成后的独立完善步骤，而非单次推理中的实时自发纠正。

**Method:** 提出SPOC方法，使LLM能够在单次推理中交错生成解决方案和验证，并根据验证结果动态终止生成。SPOC采用多智能体视角，赋予模型解决方案提议者和验证者双重角色。通过生成合成数据进行微调，并利用在线强化学习进一步提高解决方案提议和验证的准确性。

**Result:** SPOC显著提升了数学推理基准测试的性能。Llama-3.1-8B和70B Instruct模型在MATH500上分别获得了8.8%和11.6%的准确率提升，在AMC23上分别提升10.0%和20.0%，在AIME24上分别提升3.3%和6.7%。

**Conclusion:** SPOC显著提升了大型语言模型在数学推理任务上的准确性，证明了其自发自我纠正方法的有效性。

> **ai_Abstract:** 该论文提出了SPOC，一种创新的自发自我纠正方法，旨在提升大型语言模型（LLM）的数学推理能力。不同于现有需要额外提示的自我纠正方法，SPOC允许LLM在单次推理中交错生成解决方案和验证，并根据验证结果动态终止生成。该方法通过将模型视为多智能体，赋予其解决方案提议者和验证者双重角色，并利用合成数据微调和在线强化学习来提高性能。实验结果表明，SPOC在多个数学推理基准测试上显著提升了Llama-3.1模型家族的准确率。

> **摘要翻译:** 尽管大型语言模型（LLM）在广泛任务上取得了显著成功，但数学推理仍然是一个具有挑战性的任务。改进数学推理的方法之一是自我纠正，它设计自我改进循环，让模型纠正自己的错误。然而，现有的自我纠正方法将纠正视为独立的生成后完善，依赖于额外的提示和系统设计来引发自我纠正，而不是在单次通过中执行实时、自发的自我纠正。为了解决这个问题，我们提出了SPOC，一种自发自我纠正方法，使LLM能够在单次推理通过中生成交错的解决方案和验证，并根据验证结果动态终止生成，从而有效地扩展推理时间计算。SPOC通过将解决方案提议者和验证者双重角色分配给同一个模型来考虑多智能体视角。我们采用一种简单而有效的方法来生成用于微调的合成数据，使模型能够开发自我验证和多智能体协作的能力。我们通过在线强化学习进一步提高了其解决方案提议和验证的准确性。在数学推理基准测试上的实验表明，SPOC显著提高了性能。值得注意的是，SPOC提升了Llama-3.1-8B和70B Instruct模型的准确性，在MATH500上分别获得了8.8%和11.6%的提升，在AMC23上分别获得了10.0%和20.0%的提升，在AIME24上分别获得了3.3%和6.7%的提升。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [303] [An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design](https://arxiv.org/abs/2506.06935)
> *用于自主超材料建模和逆向设计的智能体框架*

*Darui Lu, Jordan M. Malof, Willie J. Padilla* | **Main category: cs.AI**

**Keywords:** 智能体框架, 超材料, 逆向设计, 大型语言模型, 深度学习

**Comment:** 22 pages, 6 figures

> **TL;DR:** 该研究开发了一个基于LLM的智能体框架，用于光子超材料的自主逆向设计，能够自动化、推理、规划和适应。

**AI_Comments:** 该论文的创新之处在于将LLM驱动的智能体框架应用于复杂的科学研究领域，特别是光子超材料的自主逆向设计。这种框架通过集成多种LLM系统和外部工具，显著提升了设计过程的自动化和智能化水平，展现了LLM在科学发现和工程设计中作为自主代理的巨大潜力。其内部反思和决策灵活性预示着能够生成超越传统方法的创新性解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 近期多LLM系统集成的显著进展使得智能体框架能够自主执行复杂任务，包括新型科学研究。本研究旨在开发并演示一个专门用于光子超材料逆向设计的智能体框架。

**Method:** 开发了一个智能体框架，当被查询所需光谱时，该智能体自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。

**Result:** 该框架在自动化、推理、规划和适应方面表现出有效性。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。

**Conclusion:** 该智能体框架在光子超材料的自主逆向设计中表现出有效性，能够自动化、推理、规划和适应，并具有生成多样化和新颖输出的潜力。

> **ai_Abstract:** 本研究开发了一个基于大型语言模型（LLM）的智能体框架，专门用于光子超材料的自主建模和逆向设计。该框架能够根据所需光学光谱，自主构建深度学习正向模型，利用外部API进行仿真和优化，并通过深度逆向方法生成最终设计。实验证明，该框架在自动化、推理、规划和适应方面表现出色，并具备内部反思和决策灵活性，能够产生多样化甚至新颖的设计。

> **摘要翻译:** 近期多大型语言模型（LLM）系统集成的显著进展，使得智能体框架能够自主执行复杂任务，包括新型科学研究。我们开发并演示了这样一个专门用于光子超材料逆向设计的框架。当被查询所需光学光谱时，该智能体自主提出并开发一个正向深度学习模型，通过API访问外部工具进行仿真和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。该框架的有效性体现在其自动化、推理、规划和适应的能力。值得注意的是，该智能体框架具有内部反思和决策灵活性，允许高度多样化和潜在新颖的输出。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [309] [The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity](https://arxiv.org/abs/2506.06941)
> *思维的幻觉：通过问题复杂性视角理解推理模型的优势与局限*

*Parshin Shojaee, Iman Mirzadeh, Keivan Alizadeh, Maxwell Horton, Samy Bengio, Mehrdad Farajtabar* | **Main category: cs.AI**

**Keywords:** 大型推理模型, 问题复杂性, 准确率崩溃, 推理轨迹, 缩放限制

**Comment:** preprint

> **TL;DR:** 大型推理模型（LRMs）在特定复杂性下准确率会完全崩溃，并且推理努力存在反直觉的缩放限制，揭示了其在精确计算和算法使用上的局限性。

**AI_Comments:** 这项研究通过引入可控的谜题环境，创新性地解决了现有推理模型评估范式中污染和缺乏内部推理洞察的问题。其发现的“准确率完全崩溃”和“反直觉缩放限制”对于理解LRMs的深层机制及其应用边界具有重要意义，对未来推理模型的设计和评估提出了新的挑战和方向。它强调了在追求模型复杂性时，更应关注其基础推理能力的本质。

<details>
  <summary>Details</summary>

**Motivation:** 现有对大型推理模型（LRMs）的评估主要集中在数学和编码基准的最终答案准确性，但这种范式存在污染且无法深入了解推理过程。LRMs的基本能力、扩展特性和局限性仍未被充分理解。

**Method:** 研究人员利用可控的谜题环境，精确操纵复杂性同时保持逻辑结构一致。这种设置不仅分析最终答案，还分析内部推理轨迹，以了解LRMs如何“思考”。通过广泛实验并比较LRMs与标准LLM。

**Result:** LRMs在超过一定复杂性后准确率会完全崩溃；LRMs表现出反直觉的缩放限制，推理努力随问题复杂性增加到一定程度后下降；识别出三种性能区域：低复杂性任务（标准模型优于LRMs），中等复杂性任务（LRMs有优势），高复杂性任务（两者均完全崩溃）；LRMs在精确计算方面存在局限性，未能使用显式算法，并在不同尺度上推理不一致；深入研究了推理轨迹，分析了探索解决方案的模式和模型的计算行为。

**Conclusion:** LRMs的推理能力存在根本性局限，尤其是在处理高复杂性问题和精确计算方面，其“思考”过程可能只是“思维的幻觉”，而非真正的通用推理。

> **ai_Abstract:** 本文系统研究了大型推理模型（LRMs）的能力和局限性，特别关注其在不同复杂性问题上的表现。通过可控的谜题环境，作者发现LRMs在达到一定复杂性后准确率会完全崩溃，并展示出反直觉的推理努力缩放限制。研究还揭示了LRMs在精确计算和算法使用上的不足，并区分了LRMs与标准LLM在不同复杂性任务中的性能区域，对LRMs的真实推理能力提出了质疑。

> **摘要翻译:** 大型语言模型的最新一代引入了大型推理模型（LRMs），这些模型在提供答案之前会生成详细的思维过程。虽然这些模型在推理基准测试中表现出改进的性能，但其基本能力、扩展特性和局限性仍未被充分理解。当前的评估主要侧重于已建立的数学和编码基准，强调最终答案的准确性。然而，这种评估范式常常受到污染，并且无法提供对推理轨迹的深入洞察。在这项工作中，我们借助可控的谜题环境系统地调查了这些差距，这些环境允许精确操纵复杂性同时保持一致的逻辑结构。这种设置不仅能够分析最终答案，还能分析内部推理轨迹，从而深入了解LRMs如何“思考”。通过广泛的实验，我们表明LRMs在超过一定复杂性后准确率会完全崩溃。此外，它们表现出反直觉的缩放限制：它们的推理努力随问题复杂性增加到一定程度后下降，尽管仍有剩余的token预算。通过在相同的推理计算量下比较LRMs与标准LLM对应物，我们确定了三种性能区域：（1）低复杂性任务，标准模型优于LRMs；（2）中等复杂性任务，LRMs表现出优势；（3）高复杂性任务，两种模型都面临完全崩溃。我们发现LRMs在精确计算方面存在局限性：它们未能使用显式算法，并且在不同尺度上推理不一致。我们还更深入地研究了推理轨迹，研究了探索解决方案的模式并分析了模型的计算行为，从而揭示了它们的优势、局限性，并对它们的推理能力提出了疑问。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [311] [Deontically Constrained Policy Improvement in Reinforcement Learning Agents](https://arxiv.org/abs/2506.06959)
> *强化学习智能体中受道义约束的策略改进*

*Alena Makarova, Houssam Abbas* | **Main category: cs.AI**

**Keywords:** 强化学习, 道义逻辑, 策略改进, 马尔可夫决策过程, 约束优化

**Comment:** 20 pages, 11 figures, DEON2025 conference

> **TL;DR:** 本文提出了一种在强化学习中，通过道义逻辑约束来学习最大化效用的决策策略的方法，并展示其能达到受约束的局部最大值。

**AI_Comments:** 这篇论文的创新点在于将道义逻辑引入强化学习的策略改进中，为RL智能体行为的伦理和社会规范提供了形式化约束的框架。它通过修改策略改进算法，使其能够同时考虑效用最大化和行为约束，这对于开发更安全、更符合社会规范的AI系统具有重要意义。该方法将义务视为价值最大化的结果，提出了双层优化的视角，具有理论深度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的强化学习智能体通过最大化效用函数来学习决策策略，但缺乏对行为的道德、社会或情境约束的考虑。本文旨在解决如何在最大化效用的同时，满足以道义逻辑表达的约束条件的问题。

**Method:** 论文使用预期行为功利主义逻辑（一种可在受控MDPs上解释的概率性stit逻辑），并开发了一种策略改进的变体。

**Result:** 所开发的策略改进方法能够使智能体在满足道义约束的同时，达到任务效用的受约束局部最大值。实验结果在示例MDPs上得到了验证。

**Conclusion:** 该方法可以被视为一种在双层结构中同时最大化两个价值函数（一个显式，一个隐式）的方式，其中智能体的义务源于价值最大化。

> **ai_Abstract:** 本文探讨了在强化学习中，如何使智能体在最大化任务效用的同时，遵守以道义逻辑表达的伦理、社会或情境约束。研究提出了一种基于预期行为功利主义逻辑的策略改进变体，该方法能够实现受约束的任务效用局部最大化，并可被理解为在双层结构中同时优化显式和隐式价值函数。实验结果验证了该方法的有效性。

> **摘要翻译:** 马尔可夫决策过程（MDPs）是机器学习领域中不确定性下决策最常用的模型。MDP捕捉了非确定性、概率不确定性和明确的行动模型。强化学习（RL）智能体通过最大化效用函数来学习在MDP中行动。本文考虑了学习一种决策策略的问题，该策略在最大化效用的同时，满足以道义逻辑表达的约束。在此设置中，效用捕捉了智能体的任务——例如从A到B快速移动。道义公式表示了对智能体如何完成任务的（伦理、社会、情境）约束，通过禁止某些行为类别。我们使用预期行为功利主义逻辑，这是一种可以在受控MDPs上解释的概率性stit逻辑。我们开发了一种策略改进的变体，并表明它能达到任务效用的受约束局部最大值。鉴于在stit逻辑中，智能体的义务源于价值最大化，这可以被视为一种在双层结构中同时最大化两个价值函数（其中一个隐式）的方式。我们通过在示例MDPs上的实验说明了这些结果。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [317] [Long-Tailed Learning for Generalized Category Discovery](https://arxiv.org/abs/2506.06965)
> *长尾学习用于广义类别发现*

*Cuong Manh Hoang* | **Main category: cs.AI**

**Keywords:** 广义类别发现, 长尾学习, 不平衡数据, 自引导标签, 表示平衡

**Comment:** 

> **TL;DR:** 针对不平衡的长尾分布，提出了一种新的广义类别发现（GCD）框架，通过自引导标签和表示平衡，超越了现有最先进方法。

**AI_Comments:** 该论文创新性地解决了广义类别发现（GCD）在长尾分布数据上的性能下降问题，其提出的自引导标签和表示平衡技术是关键创新点。这项工作对于将GCD方法应用于更真实的、不平衡的数据集具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有广义类别发现方法在平衡数据集上表现良好，但在真实世界不平衡的长尾分布数据集上效果显著下降。

**Method:** 提出了一种在长尾分布中进行广义类别发现的新框架。首先，引入自引导标签技术，利用可学习分布生成伪标签，以减少分类器的偏差。其次，提出表示平衡过程，通过挖掘样本邻域来学习判别性表示，并促使模型更多关注尾部类别。

**Result:** 在公共数据集上进行的实验表明，所提出的框架有效，并且模型性能超越了之前的最先进方法。

**Conclusion:** 该研究成功解决了长尾分布下广义类别发现的挑战，并提出了一个有效且性能优于现有先进方法的框架。

> **ai_Abstract:** 本文提出了一种新颖的广义类别发现（GCD）框架，专门针对真实世界数据集中常见的长尾分布问题。该框架采用自引导标签技术生成偏差较小的伪标签，并引入表示平衡过程，通过挖掘样本邻域来关注尾部类别。实验证明，该框架的性能优于现有的最先进方法。

> **摘要翻译:** 广义类别发现（GCD）利用已知类别的标记样本来发现未标记样本中的新类别。现有方法在具有平衡分布的人工数据集上表现出有效性能。然而，真实世界的数据集总是不平衡的，这严重影响了这些方法的有效性。为了解决这个问题，我们提出了一种新颖的框架，该框架在长尾分布中执行广义类别发现。我们首先提出了一种自引导标签技术，该技术使用可学习分布生成伪标签，从而产生偏差较小的分类器。然后，我们引入了一个表示平衡过程，以导出判别性表示。通过挖掘样本邻域，此过程鼓励模型更多地关注尾部类别。我们在公共数据集上进行了实验，以证明所提出框架的有效性。结果表明，我们的模型超越了以前的最先进方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [321] [Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments](https://arxiv.org/abs/2506.06981)
> *深度强化学习需要深度行为分析：探索无模型智能体在开放式环境中的隐式规划*

*Riley Simmons-Edler, Ryan P. Badman, Felix Baastad Berg, Raymond Chua, John J. Vastola, Joshua Lunger, William Qian, Kanaka Rajan* | **Main category: cs.AI**

**Keywords:** 深度强化学习, 行为分析, 无模型智能体, 隐式规划, 神经行为学

**Comment:** 

> **TL;DR:** 本文应用神经科学和行为学工具，在复杂新环境ForageWorld中研究深度强化学习智能体行为，发现无模型DRL智能体可展现规划式行为，并提出通用分析框架。

**AI_Comments:** 这篇论文通过引入神经科学和行为学的方法来分析DRL智能体的行为，提供了一种新颖且深入的视角。其创新之处在于揭示了无模型DRL智能体能够自发地表现出规划能力，这挑战了传统观念中规划需要显式世界模型的假设。该研究的重要性在于为理解和控制日益复杂的AI系统提供了新的工具和框架，对于AI的安全性和可解释性具有重要意义。通过将生物智能的研究方法引入AI领域，为未来AI的发展提供了新的研究范式。

<details>
  <summary>Details</summary>

**Motivation:** 随着任务和智能体复杂性增加，理解深度强化学习（DRL）智能体的行为仅通过奖励曲线比较不足，而DRL中行为分析的标准方法仍不成熟。

**Method:** 研究人员应用神经科学和行为学工具，在名为ForageWorld的复杂、部分可观察环境中研究DRL智能体。ForageWorld旨在捕捉真实世界动物觅食的关键方面。他们对智能体进行联合行为和神经分析。

**Result:** 发现无模型、基于RNN的DRL智能体可以纯粹通过涌现动力学表现出结构化的、类似规划的行为，而无需显式记忆模块或世界模型。研究表明，像研究动物一样研究DRL智能体，能揭示其学习动力学中丰富的结构。

**Conclusion:** 像研究生物智能一样研究DRL智能体，通过神经行为学启发工具分析行为和神经动力学，对于理解其行为、确保安全对齐和最大化期望行为至关重要。本文将这些工具提炼成一个通用分析框架。

> **ai_Abstract:** 本文指出，当前深度强化学习（DRL）的行为分析方法不足以应对复杂智能体和任务。为此，作者引入了受神经科学和行为学启发的分析工具，并在名为ForageWorld的复杂环境中研究无模型DRL智能体。研究发现，即使没有显式记忆或世界模型，这些智能体也能通过涌现动力学展现出规划式行为。论文强调了像研究动物一样分析DRL智能体的重要性，并提出了一个通用的行为分析框架，以促进对复杂AI行为的理解、安全对齐和期望行为的最大化。

> **摘要翻译:** 理解深度强化学习（DRL）智能体的行为——特别是随着任务和智能体复杂性的增加——需要的不仅仅是简单的奖励曲线比较，然而DRL中行为分析的标准方法仍然不成熟。我们应用神经科学和行为学工具，在一个新颖、复杂、部分可观察的环境ForageWorld中研究DRL智能体，该环境旨在捕捉真实世界动物觅食的关键方面——包括稀疏、耗尽的资源区、捕食者威胁和空间广阔的竞技场。我们使用这个环境作为平台，对智能体进行联合行为和神经分析，揭示了关于智能体策略、记忆和规划的详细、量化基础的见解。与普遍假设相反，我们发现无模型、基于RNN的DRL智能体可以纯粹通过涌现动力学表现出结构化的、类似规划的行为——无需显式记忆模块或世界模型。我们的结果表明，像研究动物一样研究DRL智能体——用神经行为学启发的工具分析它们，揭示行为和神经动力学中的结构——可以揭示其学习动力学中丰富的结构，否则这些结构将是不可见的。我们将这些工具提炼成一个通用分析框架，将核心行为和表征特征与诊断方法联系起来，可广泛应用于各种任务和智能体。随着智能体变得更加复杂和自主，弥合神经科学、认知科学和人工智能之间的鸿沟将是必不可少的——不仅是为了理解它们的行为，也是为了确保安全对齐和最大化难以通过奖励衡量的期望行为。我们展示了如何借鉴生物智能研究的经验来做到这一点。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [326] [Evaluating LLM-corrupted Crowdsourcing Data Without Ground Truth](https://arxiv.org/abs/2506.06991)
> *在没有真实标签的情况下评估LLM污染的众包数据*

*Yichi Zhang, Jinlong Pang, Zhaowei Zhu, Yang Liu* | **Main category: cs.AI**

**Keywords:** LLM, 众包, 同伴预测, 数据质量, 作弊检测

**Comment:** 33 pages, 9 figures

> **TL;DR:** 本文研究了在缺乏真实标签的情况下，如何利用同伴预测机制来检测众包数据中由大型语言模型（LLM）辅助作弊的情况，并提出了一个无需训练的评分机制，在真实众包数据上有效识别低投入作弊。

**AI_Comments:** 本文的创新点在于提出了一个无需真实标签的、基于同伴预测的LLM作弊检测机制，这对于当前LLM广泛应用于众包场景下数据质量保障具有重要意义。其无需训练的特性也降低了实施门槛。该方法对于评估和净化LLM污染的众包数据，特别是标注任务，提供了一个有前景的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI的成功依赖高质量的人类反馈，但众包工作者越来越多地使用LLM，导致众包数据可能被LLM生成的内容污染。现有LLM检测方法不适用于多项选择标注等任务，且通常依赖高维训练数据，因此需要一种无需真实标签的方法来评估LLM污染的众包数据。

**Method:** 本研究利用同伴预测机制，在没有真实标签的情况下评估众包数据。具体方法是量化工作者回答之间的关联，同时以请求者可获得的LLM生成标签（或其子集）为条件。论文提出了一个无需训练的评分机制，该机制在考虑LLM串通的众包模型下具有理论保证。

**Result:** 研究建立了该方法有效的条件，并在真实世界众包数据集上通过经验证明了其在检测低投入作弊方面的鲁棒性。

**Conclusion:** 该研究表明，在没有真实标签的情况下，利用同伴预测机制可以有效评估LLM污染的众包数据，并检测LLM辅助作弊，尤其适用于标注任务。

> **ai_Abstract:** 本研究旨在解决大型语言模型（LLM）在众包中引入的数据污染问题，尤其是在缺乏真实标签的标注任务中。鉴于现有LLM检测方法的局限性，作者提出了一种基于同伴预测的无需训练的评分机制。该机制通过量化工作者回答之间的关联，并在考虑LLM串通的众包模型下提供理论保证。实验结果表明，该方法在检测真实众包数据集上的低投入作弊方面具有鲁棒性。

> **摘要翻译:** 生成式人工智能最近的成功凸显了高质量人类反馈在构建值得信赖的人工智能系统中的关键作用。然而，众包工作者越来越多地使用大型语言模型（LLM）带来了重大挑战：旨在反映人类输入的数据库可能被LLM生成的回应所损害。现有的LLM检测方法通常依赖于高维训练数据，例如文本，这使得它们不适用于多项选择标注等注释任务。在这项工作中，我们调查了同伴预测的潜力——一种在不使用真实标签的情况下评估工作者回应中信息的机制——以减轻众包中LLM辅助作弊，重点关注注释任务。我们的方法在以请求者可获得的LLM生成标签（或其子集）为条件的情况下，量化了工作者回答之间的关联。在先前研究的基础上，我们提出了一个无需训练的评分机制，在考虑LLM串通的众包模型下具有理论保证。我们建立了该方法有效的条件，并通过经验证明了其在真实世界众包数据集上检测低投入作弊方面的鲁棒性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [331] [Mathesis: Towards Formal Theorem Proving from Natural Languages](https://arxiv.org/abs/2506.07047)
> *Mathesis：迈向自然语言形式化定理证明*

*Yu Xuejun, Jianyuan Zhong, Zijin Feng, Pengyi Zhai, Roozbeh Yousefzadeh, Wei Chong Ng, Haoxiong Liu, Ziyi Shou, Jing Xiong, Yudong Zhou, Claudia Beth Ong, Austen Jeremy Sugiarto, Yaoxi Zhang, Wai Ming Tai, Huan Cao, Dongcai Lu, Jiacheng Sun, Qiang Xu, Shen Xin, Zhenguo Li* | **Main category: cs.AI**

**Keywords:** 形式化定理证明, 自然语言处理, 大型语言模型, 自动形式化, 强化学习

**Comment:** 

> **TL;DR:** Mathesis是一个端到端的定理证明系统，能够直接处理自然语言问题，并通过强化学习自动形式化，在真实世界基准测试中表现出色。

**AI_Comments:** Mathesis的创新之处在于其构建了一个完整的端到端管道，直接将自然语言问题转化为形式化证明，这大大降低了形式化定理证明的门槛。其引入强化学习进行自动形式化是一个重要的突破，能够更好地适应自然语言的复杂性和多样性。Gaokao-Formal基准的建立也为真实世界问题的评估提供了有价值的工具。这项工作对于推动LLM在形式化推理领域的实际应用具有重要意义，有望在未来实现更广泛的自动化数学证明。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于大型语言模型的定理证明器需要专家编写的形式化语句作为输入，这限制了它们在处理自然语言表达的实际问题时的适用性。

**Method:** 本文提出了Mathesis，一个端到端的定理证明流程，可以直接处理非形式化问题陈述。它包含Mathesis-Autoformalizer，这是第一个使用强化学习来增强自然语言问题形式化能力的自动形式化器，并辅以LeanScorer框架进行细致的形式化质量评估。此外，它还提出了Mathesis-Prover，用于从形式化语句生成形式化证明。为了评估端到端形式化定理证明的实际适用性，引入了Gaokao-Formal，一个包含488个来自中国高考的复杂问题的基准测试。

**Result:** 实验证明了Mathesis的有效性，其自动形式化器在Gaokao-Formal上的通过率比最佳基线高出22%。整个系统在MiniF2F上实现了64%的准确率（pass@32），在Gaokao-Formal上达到了18%的最新水平。

**Conclusion:** Mathesis系统及其组件被精心设计并经过彻底研究，实验结果证明了其在从自然语言进行端到端形式化定理证明方面的有效性和优越性，尤其是在处理真实世界复杂问题方面。

> **ai_Abstract:** Mathesis提出了一个创新的端到端定理证明流程，旨在解决大型语言模型在处理自然语言问题时需要专家级形式化输入的局限性。该系统包含一个基于强化学习的自动形式化器（Mathesis-Autoformalizer），通过LeanScorer框架评估形式化质量，以及一个证明生成器（Mathesis-Prover）。为了验证其实用性，研究人员创建了Gaokao-Formal基准测试。实验结果表明，Mathesis在自动形式化方面显著优于现有基线，并在MiniF2F和Gaokao-Formal等基准测试中取得了先进的证明准确率，展示了从自然语言进行形式化定理证明的巨大潜力。

> **摘要翻译:** 标题：Mathesis：迈向自然语言形式化定理证明

摘要：大型语言模型在形式化推理方面展现出强大的前景。然而，大多数基于大型语言模型的定理证明器长期以来受限于需要专家编写的形式化语句作为输入，这限制了它们在处理自然语言表达的实际问题时的适用性。我们通过Mathesis解决了这一空白，它是第一个处理非形式化问题陈述的端到端定理证明流程。它贡献了Mathesis-Autoformalizer，这是第一个使用强化学习来增强自然语言问题形式化能力的自动形式化器，并辅以我们新颖的LeanScorer框架进行细致的形式化质量评估。它还提出了Mathesis-Prover，用于从形式化语句生成形式化证明。为了评估端到端形式化定理证明的实际适用性，我们引入了Gaokao-Formal，一个包含488个来自中国高考的复杂问题的基准测试。我们的方法经过精心设计，对每个组件进行了彻底研究。实验证明了Mathesis的有效性，其自动形式化器在Gaokao-Formal上的通过率比最佳基线高出22%。整个系统在MiniF2F上实现了64%的准确率（pass@32），在Gaokao-Formal上达到了18%的最新水平。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [337] [Reasoning Paths as Signals: Augmenting Multi-hop Fact Verification through Structural Reasoning Progression](https://arxiv.org/abs/2506.07075)
> *推理路径作为信号：通过结构化推理进展增强多跳事实核查*

*Liwen Zheng, Chaozhuo Li, Haoran Jia, Xi Zhang* | **Main category: cs.AI**

**Keywords:** 多跳事实核查, 推理路径, 结构化图, 证据检索, 声明核查

**Comment:** 

> **TL;DR:** 提出一种结构化推理框架，通过将推理路径建模为结构化图来增强多跳事实核查的证据检索和声明核查。

**AI_Comments:** 这篇论文的创新点在于将推理路径显式地建模为结构化图，并在证据检索和声明核查的全过程中利用这些结构信息。这种方法有效地解决了现有系统在处理复杂多跳证据时面临的碎片化检索和可解释性差的问题，通过捕捉长程依赖关系显著提升了多跳事实核查的性能和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有自动化事实核查系统在准确聚合和推理多跳证据方面面临挑战，因为它们依赖静态或浅层模型，未能捕捉推理路径的演变结构，导致证据检索碎片化和可解释性有限。

**Method:** 本文提出一个结构化推理框架，在证据检索和声明核查阶段都明确将推理路径建模为结构化图。该方法包含两个关键模块：一个结构增强检索机制，用于构建推理图以指导证据收集；以及一个推理路径引导的核查模块，用于逐步构建子图以表示演变的推理轨迹。此外，还整合了结构感知推理机制，以捕捉多跳证据链中的长程依赖。

**Result:** 在FEVER和HoVer数据集上的广泛实验表明，该方法始终优于强大的基线，突出了推理路径建模在增强检索精度和核查准确性方面的有效性。

**Conclusion:** 通过将推理路径显式建模为结构化图，本文提出的方法显著提高了多跳事实核查系统的证据检索精度和核查准确性。

> **ai_Abstract:** 本文提出了一种结构化推理框架，用于解决多跳事实核查中证据聚合和推理的挑战。该框架将推理路径建模为结构化图，并包含结构增强检索和推理路径引导的核查模块，以指导证据收集和表示推理轨迹。实验证明，该方法在提高检索精度和核查准确性方面优于现有基线。

> **摘要翻译:** 现实世界场景中事实主张日益增长的复杂性给自动化事实核查系统带来了重大挑战，特别是在准确聚合和推理多跳证据方面。现有方法通常依赖静态或浅层模型，未能捕捉推理路径的演变结构，导致检索碎片化和可解释性有限。为了解决这些问题，我们提出了一种用于多跳事实核查的结构化推理框架，该框架在证据检索和声明核查阶段都明确将推理路径建模为结构化图。我们的方法包含两个关键模块：一个结构增强检索机制，用于构建推理图以指导证据收集；以及一个推理路径引导的核查模块，用于逐步构建子图以表示演变的推理轨迹。我们进一步整合了一种结构感知推理机制，该机制捕捉多跳证据链中的长程依赖，从而实现更精确的核查。在FEVER和HoVer数据集上的广泛实验表明，我们的方法始终优于强大的基线，突出了推理路径建模在增强检索精度和核查准确性方面的有效性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [343] [BRIGHT+: Upgrading the BRIGHT Benchmark with MARCUS, a Multi-Agent RAG Clean-Up Suite](https://arxiv.org/abs/2506.07116)
> *BRIGHT+：使用多智能体RAG清理套件MARCUS升级BRIGHT基准*

*Liyang Chen, Yujun Cai, Jieqiong Dong, Yiwei Wang* | **Main category: cs.AI**

**Keywords:** RAG, BRIGHT, MARCUS, 语料库清理, 多智能体系统

**Comment:** 8 pages, 7 figures, 4 tables. Submitted to EMNLP 2025

> **TL;DR:** BRIGHT+通过多智能体RAG清理套件MARCUS升级了BRIGHT基准，显著提高了检索精度和多跳推理能力。

**AI_Comments:** 这项工作通过引入MARCUS清理套件，解决了现有RAG基准BRIGHT在数据质量上的痛点，显著提升了其评估能力。多智能体LLM驱动的清理方法具有创新性，并且BRIGHT+语料库和MARCUS流水线的发布对RAG领域的研究具有重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** BRIGHT基准的实际效果受到网络爬取内容的冗余和语义不连贯等问题限制，这些问题影响了检索精度和下游推理。

**Method:** 引入MARCUS，一个利用大型语言模型（LLMs）的多智能体流水线，系统地清理和重新分块BRIGHT，生成更高质量的语料库BRIGHT-Plus。MARCUS使用专门的智能体进行结构噪声去除和语义分割，在保留答案相关片段的同时提高上下文完整性。

**Result:** 实验评估表明，BRIGHT-Plus在各种检索器上，在检索精度和多跳推理方面都产生了持续且显著的改进。

**Conclusion:** BRIGHT-Plus语料库和MARCUS流水线的发布将支持未来对鲁棒、以推理为中心的检索的研究。

> **ai_Abstract:** 本文介绍了BRIGHT+，一个通过MARCUS多智能体RAG清理套件升级的BRIGHT基准。BRIGHT基准在评估复杂多跳检索方面具有影响力，但其效果受限于网络爬取内容的冗余和语义不连贯。为解决此问题，研究团队开发了MARCUS，一个利用大型语言模型的多智能体流水线，用于系统地清理和重新分块BRIGHT，生成高质量的BRIGHT+语料库。实验结果表明，BRIGHT+在检索精度和多跳推理方面均实现了显著提升。研究团队已发布BRIGHT+语料库和MARCUS流水线，以促进未来对鲁棒、以推理为中心的检索系统的研究。

> **摘要翻译:** 检索增强生成（RAG）系统需要结构干净且语义连贯的语料库。BRIGHT是一个近期且有影响力的基准，旨在评估跨多样化、高推理领域的复杂多跳检索。然而，其实际效果受到常见的网络爬取内容缺陷的限制，例如内容冗余和语义不连贯，这些缺陷损害了检索精度和下游推理。值得注意的是，我们发现此类问题集中在七个源自StackExchange的子领域，而其他领域（例如，编程和基于定理的内容）相对干净。
在本研究中，我们提出了MARCUS，一个利用大型语言模型（LLM）的多智能体流水线，系统地清理和重新分块BRIGHT，形成更高质量的语料库：BRIGHT-Plus。MARCUS应用专用智能体进行结构噪声去除和语义分割，在保留答案相关片段的同时提高上下文完整性。实验评估表明，BRIGHT-Plus在各种检索器上，在检索精度和多跳推理方面都产生了持续且显著的改进。我们发布了BRIGHT-Plus语料库和MARCUS流水线，以支持未来关于鲁棒、以推理为中心的检索的研究。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [346] [Translating Federated Learning Algorithms in Python into CSP Processes Using ChatGPT](https://arxiv.org/abs/2506.07173)
> *使用ChatGPT将Python中的联邦学习算法转换为CSP进程*

*Miroslav Popovic, Marko Popovic, Miodrag Djukic, Ilija Basicevic* | **Main category: cs.AI**

**Keywords:** 联邦学习, ChatGPT, CSP进程, 自动化翻译, 模型验证

**Comment:** 6 pages, 4 tables

> **TL;DR:** 本文介绍了一种使用ChatGPT自动将Python联邦学习算法翻译成CSP进程的方法，并成功验证了其有效性。

**AI_Comments:** 这项研究展示了大型语言模型（如ChatGPT）在自动化软件工程任务中的潜力，特别是将特定领域的代码（如联邦学习算法）转换为形式化验证语言（如CSP）。这可以显著提高验证效率，减少手动错误。其创新点在于利用LLM的自然语言理解和生成能力来辅助代码转换，而不仅仅是代码生成。未来可以探索其在其他领域或更复杂系统中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究中，将Python联邦学习算法手动翻译成CSP进程并进行验证。本文的动机是引入一种简单且自动化的翻译过程，以提高效率并减少人工干预。

**Method:** 本文引入了一种简单的翻译过程，使用ChatGPT自动将Python中的联邦学习算法翻译成对应的CSP进程。在此过程中，根据ChatGPT的反馈评估所用上下文的最小性。

**Result:** 所提出的翻译过程通过成功翻译（并经模型检查器PAT验证）通用集中式和去中心化联邦学习算法进行了实验验证。

**Conclusion:** ChatGPT能够有效地自动化将Python联邦学习算法翻译成CSP进程，并且翻译后的进程能够被模型检查器PAT验证其安全性和活性属性。

> **ai_Abstract:** 本文提出了一种利用ChatGPT将Python联邦学习算法自动转换为CSP进程的方法。该方法旨在简化并自动化此前手动进行的翻译过程，并通过模型检查器PAT对转换后的CSP进程进行验证。实验结果表明，该方法成功地将通用集中式和去中心化联邦学习算法从Python翻译成了可验证的CSP进程，证明了ChatGPT在自动化此类型代码转换中的潜力。

> **摘要翻译:** Python联邦学习算法测试平台是一个简单的Python FL框架，易于ML&AI开发者使用，他们无需成为专业的程序员，也适用于大型语言模型（LLM）。在之前的研究中，该框架提供的通用联邦学习算法被手动翻译成CSP进程，并通过模型检查器PAT自动验证了算法的安全性和活性属性。在本文中，引入了一种简单的翻译过程，其中使用ChatGPT自动化将上述Python联邦学习算法翻译成相应的CSP进程。在此过程中，根据ChatGPT的反馈估计所用上下文的最小性。所提出的翻译过程通过成功翻译（并经模型检查器PAT验证）通用集中式和去中心化联邦学习算法进行了实验验证。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [351] [Mitigating Behavioral Hallucination in Multimodal Large Language Models for Sequential Images](https://arxiv.org/abs/2506.07184)
> *缓解多模态大型语言模型在序列图像中的行为幻觉*

*Liangliang You, Junchi Yao, Shu Yang, Guimin Hu, Lijie Hu, Di Wang* | **Main category: cs.AI**

**Keywords:** 行为幻觉, 多模态大语言模型, 序列图像, SHE框架, BEACH指标

**Comment:** 

> **TL;DR:** 本研究提出SHE框架，通过两阶段方法（检测和缓解）解决多模态大语言模型在序列图像中出现的行为幻觉，并引入了BEACH指标来量化行为幻觉，实验证明SHE能有效降低行为幻觉。

**AI_Comments:** 本文创新性地提出了“行为幻觉”这一概念，区别于以往对“客观幻觉”的关注，并针对序列图像场景进行了深入研究。提出的SHE框架通过两阶段方法（检测与缓解）和新颖的BEACH量化指标，为解决多模态大模型在实际应用中的可靠性问题提供了有效途径。其轻量级的设计也增加了实际部署的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大型语言模型在处理序列图像时，除了客观幻觉外，还存在行为幻觉，而这方面的研究较少。本文旨在填补这一空白，并揭示行为幻觉主要源于先验驱动偏差和滚雪球效应。

**Method:** 本文提出了SHE（Sequence Hallucination Eradication）框架，这是一个轻量级的两阶段框架：首先通过使用自适应时间窗口进行视觉-文本对齐检查来检测幻觉；其次通过正交投影到联合嵌入空间来缓解幻觉。此外，还提出了一种新的度量标准BEACH来量化行为幻觉的严重性。

**Result:** 在标准基准测试上的实验结果表明，SHE在BEACH指标上将行为幻觉降低了10%以上，同时保持了描述的准确性。

**Conclusion:** SHE框架能够有效检测并缓解多模态大型语言模型在序列图像中产生的行为幻觉，显著提升了模型的可靠性。

> **ai_Abstract:** 本文关注多模态大型语言模型在序列图像中未被充分研究的行为幻觉问题。研究揭示了行为幻觉源于先验驱动偏差和滚雪球效应，并提出了SHE（Sequence Hallucination Eradication）框架。SHE是一个轻量级的两阶段方法，通过自适应时间窗口进行视觉-文本对齐检测幻觉，并通过正交投影缓解幻觉。此外，引入了新的BEACH指标来量化行为幻觉。实验证明，SHE在保持描述准确性的同时，能有效降低行为幻觉。

> **摘要翻译:** 尽管多模态大型语言模型在各种任务中表现出色，但它们仍然遭受幻觉的困扰，这限制了其在更广泛领域应用中的可靠性和可扩展性。为了解决这个问题，最近的研究主要集中在客观幻觉上。然而，对于序列图像，除了客观幻觉之外，还存在行为幻觉，这方面的研究较少。这项工作旨在填补这一空白。我们首先揭示了行为幻觉主要源于两个关键因素：先验驱动偏差和滚雪球效应。基于这些观察，我们引入了SHE（Sequence Hallucination Eradication），一个轻量级的两阶段框架，该框架（1）通过使用我们提出的自适应时间窗口进行视觉-文本对齐检查来检测幻觉，以及（2）通过正交投影到联合嵌入空间来缓解幻觉。我们还提出了一种新的度量标准（BEACH）来量化行为幻觉的严重性。在标准基准测试上的经验结果表明，SHE在BEACH上将行为幻觉降低了10%以上，同时保持了描述的准确性。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [356] [Exploring Effective Strategies for Building a Customised GPT Agent for Coding Classroom Dialogues](https://arxiv.org/abs/2506.07194)
> *探索构建定制化GPT智能体以编码课堂对话的有效策略*

*Luwei Bai, Dongkeun Han, Sara Hennessy* | **Main category: cs.AI**

**Keywords:** GPT智能体, 课堂对话, 编码策略, 大语言模型, 定制化

**Comment:** Draft technical report. 39 pages, 2 figures. Not yet submitted for
  publication. Update expected

> **TL;DR:** 本研究探讨了利用GPT-4的MyGPT智能体定制化编码课堂对话的有效策略，旨在解决小数据集和定制编码方案的挑战，并发现其可作为有用的编码助手。

**AI_Comments:** 本文的创新之处在于关注如何利用大语言模型（特别是MyGPT的定制化功能）来解决小数据集和定制化编码方案在课堂对话分析中的挑战，这与当前主流的大规模模型训练或固定代码本评估有所不同。其提出的实用策略对于教育研究者具有重要意义。局限性在于仍存在“一些局限性”，具体未详细说明。

<details>
  <summary>Details</summary>

**Motivation:** 课堂对话分析因其细致入微的对话功能理解需求和人工转录编码的劳动密集型性质而具有挑战性。现有的大语言模型研究主要集中在训练大型模型或使用固定代码本评估预训练模型，这对于处理小数据集或定制编码方案的对话研究人员来说通常不适用或不可复制。

**Method:** 本研究以GPT-4的MyGPT智能体为例，评估其在使用人类代码本编码课堂对话时的基线性能，并通过变量控制方法检查不同示例输入如何影响性能。通过设计本位研究方法，本研究基于MyGPT的独特功能，识别了一套在有限数据下配置有效智能体的实用策略。

**Result:** 研究结果表明，尽管存在一些局限性，但使用这些策略开发的MyGPT智能体可以通过生成编码建议来作为有用的编码助手。性能会随不同的示例输入而变化。

**Conclusion:** 定制化的MyGPT智能体可以作为课堂对话编码的有用辅助工具，尤其是在处理小数据集和定制编码方案时。

> **ai_Abstract:** 本研究旨在解决课堂对话分析中人工编码的挑战和现有大语言模型方法的局限性，提出构建定制化GPT智能体的有效策略。研究以GPT-4的MyGPT为例，评估其编码性能，并通过变量控制和设计本位研究识别出在有限数据下配置有效智能体的实用方法。结果表明，定制化的MyGPT智能体可作为有用的编码助手，提供编码建议。

> **摘要翻译:** 本研究探讨了开发定制化GPT智能体以编码课堂对话的有效策略。尽管课堂对话被广泛认为是教育的关键要素，但由于需要对对话功能进行细致入微的理解以及手动转录编码的劳动密集型性质，其分析仍然具有挑战性。大型语言模型的最新进展为自动化这一过程提供了有前景的途径。然而，现有研究主要集中在训练大型模型或使用固定代码本评估预训练模型，这对于处理处理小数据集或定制编码方案的对话研究人员来说通常不适用或不可复制。本研究以GPT-4的MyGPT智能体为例，评估了其在使用人类代码本编码课堂对话时的基线性能，并通过变量控制方法检查了不同示例输入如何影响性能。通过设计本位研究方法，本研究基于MyGPT的独特功能，识别了一套在有限数据下配置有效智能体的实用策略。研究结果表明，尽管存在一些局限性，但使用这些策略开发的MyGPT智能体可以通过生成编码建议来作为有用的编码助手。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [360] [Reasoning Multimodal Large Language Model: Data Contamination and Dynamic Evaluation](https://arxiv.org/abs/2506.07202)
> *推理多模态大语言模型：数据污染与动态评估*

*Ming Liu, Wensheng Zhang* | **Main category: cs.AI**

**Keywords:** 多模态大语言模型, 数据污染, 动态评估, 泛化能力, 任务扰动

**Comment:** 

> **TL;DR:** 本文提出一种新的动态评估框架，通过扰动任务而非输入来评估多模态大语言模型（MLLM）的泛化能力，以识别数据污染和过拟合的影响。

**AI_Comments:** 本文提出了一种新颖的动态评估框架，其创新点在于通过扰动任务本身而非输入来评估模型的泛化能力，并将其与损失景观的锐度概念联系起来。这种方法能够更深入地揭示数据污染和过拟合对MLLM泛化能力的影响，对于推动MLLM的可靠发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型（MLLMs）在视觉-语言基准测试中表现出色，但人们日益担忧数据污染（训练期间暴露测试集）可能掩盖其真正的泛化能力。这种担忧尤其存在于推理型MLLMs中，它们通常通过强化学习对可能受污染的基础模型进行微调。

**Method:** 本文提出了一种新颖的动态评估框架，旨在严格评估MLLM的泛化能力，超越静态基准测试。该方法不扰动输入，而是扰动任务本身。使用相同的视觉输入，模型在一系列任务（例如，问答、图像描述、提问、验证）中进行评估，以探究其多样化的能力。这种任务扰动揭示了模型性能是稳健的还是依赖于表面的任务特定线索。该方法类似于损失景观的锐度：对单一任务过拟合或受污染的模型（尖锐的最小值）在任务转换下会失败，而具有泛化解决方案的模型（平坦的最小值）则不会。研究者开发了一个自动化流程，通过使用释义和损坏采样，由校准后的评判器对开放式生成（描述、问题）进行评分。

**Result:** 将此框架应用于领先的图像/视频MLLMs，包括MME、RealWorldQA和CVRR-ES等基准测试，分析了每个模型的跨任务“能力向量”。研究表明，在模拟测试数据上进行微调（极端污染）会急剧提高任务特定性能，但会损害整体泛化能力。

**Conclusion:** 我们的动态任务扰动方法为MLLM的泛化能力提供了更深入的见解，能够区分真正的理解与虚假泄漏或过拟合。

> **ai_Abstract:** 本文针对多模态大语言模型（MLLMs）面临的数据污染问题，提出了一种创新的动态评估框架。该框架通过扰动任务而非输入，使用相同的视觉输入在不同任务家族中评估模型，以揭示其泛化能力是稳健的还是依赖于表面线索。研究发现，在模拟污染数据上微调会提高任务特定性能但损害整体泛化。这种方法有助于区分MLLM的真正理解与数据泄漏或过拟合。

> **摘要翻译:** 多模态大语言模型（MLLMs）在视觉-语言基准测试中表现出色，但人们日益担忧数据污染（训练期间暴露测试集）可能掩盖其真正的泛化能力。这种担忧延伸到推理型MLLMs，它们通常通过强化学习对可能受污染的基础模型进行微调。我们提出了一种新颖的动态评估框架，旨在严格评估MLLM的泛化能力，超越静态基准测试。该方法不扰动输入，而是扰动任务本身。使用相同的视觉输入，模型在一系列任务（例如，问答、图像描述、提问、验证）中进行评估，以探究其多样化的能力。这种任务扰动揭示了模型性能是稳健的还是依赖于表面的任务特定线索。我们的方法类似于损失景观的锐度：对单一任务过拟合或受污染的模型（尖锐的最小值）在任务转换下会失败，而具有泛化解决方案的模型（平坦的最小值）则不会。我们开发了一个自动化流程，通过使用释义和损坏采样，由校准后的评判器对开放式生成（描述、问题）进行评分。将此框架应用于领先的图像/视频MLLMs，包括MME、RealWorldQA和CVRR-ES等基准测试，我们分析了每个模型的跨任务“能力向量”。我们证明，在模拟测试数据上进行微调（极端污染）会急剧提高任务特定性能，但会损害整体泛化能力。我们的动态任务扰动为MLLM的泛化能力提供了更深入的见解，能够区分真正的理解与虚假泄漏或过拟合。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [364] [BIMgent: Towards Autonomous Building Modeling via Computer-use Agents](https://arxiv.org/abs/2506.07217)
> *BIMgent：迈向通过计算机代理实现的自主建筑建模*

*Zihan Deng, Changyu Du, Stavros Nousias, André Borrmann* | **Main category: cs.AI**

**Keywords:** BIM, 自主建模, 计算机代理, LLMs, GUI自动化

**Comment:** ICML 2025 Workshop on Computer Use Agents

> **TL;DR:** BIMgent是一个由多模态大型语言模型驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作，并在实际建筑建模任务中表现出优于基线模型的性能，有效减少了手动工作量。

**AI_Comments:** 该论文的创新之处在于将多模态大型语言模型应用于高度专业化的建筑信息模型（BIM）领域，通过GUI自动化实现自主建筑建模，这在现有研究中尚未得到充分探索。其重要性在于显著减少了手动工作量，并展示了在实际建筑建模场景中部署的潜力。尽管32%的成功率可能看起来不高，但考虑到基线模型0%的成功率，这已是显著的进步，表明了该方法的可行性和巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有计算机代理主要关注通用桌面自动化任务，很少探索其在高度专业化领域的应用。特别是，建筑、工程和施工（AEC）行业的3D建筑建模过程涉及开放式设计任务和建筑信息模型（BIM）创作软件中复杂的交互模式，目前尚未得到充分解决。

**Method:** 本文提出了BIMgent，一个由多模态大型语言模型（LLMs）驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作。BIMgent自动化了建筑建模过程，包括概念设计的多模态输入、软件特定工作流程的规划以及创作GUI操作的高效执行。

**Result:** BIMgent在实际建筑建模任务（包括基于文本的概念设计生成和现有建筑设计的重建）上进行了评估。BIMgent实现的设计质量合理，其操作成功率为32%，而所有基线模型均未能完成任务（成功率为0%）。

**Conclusion:** 结果表明，BIMgent在保留设计意图的同时有效减少了手动工作量，突显了其在实际建筑建模场景中实际部署的潜力。

> **ai_Abstract:** 针对现有计算机代理在专业领域应用有限的挑战，特别是AEC行业中复杂的3D建筑建模过程，本文提出了BIMgent。BIMgent是一个基于多模态大型语言模型（LLMs）的代理框架，通过自动化图形用户界面（GUI）操作实现自主建筑模型创作。它能够处理概念设计的多模态输入、规划软件工作流程并高效执行GUI动作。在实际建筑建模任务中，BIMgent取得了32%的成功率和合理的设计质量，而基线模型均未能完成任务，这表明BIMgent能有效减少手动工作量并保留设计意图，具有实际应用潜力。

> **摘要翻译:** 现有计算机代理主要关注通用桌面自动化任务，很少探索其在高度专业化领域的应用。特别是，建筑、工程和施工（AEC）行业的3D建筑建模过程涉及开放式设计任务和建筑信息模型（BIM）创作软件中复杂的交互模式，目前尚未得到充分解决。在本文中，我们提出了BIMgent，一个由多模态大型语言模型（LLMs）驱动的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作。BIMgent自动化了建筑建模过程，包括概念设计的多模态输入、软件特定工作流程的规划以及创作GUI操作的高效执行。我们在实际建筑建模任务（包括基于文本的概念设计生成和现有建筑设计的重建）上评估了BIMgent。BIMgent实现的设计质量合理。其操作成功率为32%，而所有基线模型均未能完成任务（成功率为0%）。结果表明，BIMgent在保留设计意图的同时有效减少了手动工作量，突显了其在实际建筑建模场景中实际部署的潜力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [368] [LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments](https://arxiv.org/abs/2506.07223)
> *LLM增强的快速反应异步反射具身智能体，用于动态变化环境中的实时决策*

*Yangqing Zheng, Shunqi Mao, Dingxin Zhang, Weidong Cai* | **Main category: cs.AI**

**Keywords:** 具身智能体, 实时决策, LLM, 延迟敏感, HAZARD基准

**Comment:** Accepted by the CVPR 2025 Embodied AI Workshop

> **TL;DR:** 针对具身智能体在动态高风险环境中决策延迟问题，本文提出时间转换机制和RRARA智能体，实现实时决策并显著优于现有基线。

**AI_Comments:** 本文创新性地解决了具身智能体在实时高风险环境中的决策延迟问题，通过引入时间转换机制和RRARA智能体，在LLM增强的具身智能体领域具有重要意义。RRARA结合了LLM的认知能力和规则代理的快速反应，为未来的具身智能体设计提供了新思路。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究未充分解决具身智能体在动态高风险（如火灾、洪水、大风）场景下决策延迟问题，这在这些极端条件下至关重要。

**Method:** 提出时间转换机制（TCM），将决策推理延迟转换为模拟帧，统一认知和物理成本。通过响应延迟（RL）和行动延迟比（LAR）扩展HAZARD基准，建立延迟感知评估协议。提出快速反应异步反射智能体（RRARA），结合轻量级LLM引导的反馈模块和基于规则的智能体，实现即时反应行为和异步反射改进。

**Result:** RRARA在延迟敏感场景中表现显著优于现有基线。

**Conclusion:** RRARA有效解决了具身智能体在动态高风险环境中的实时决策延迟问题，提升了性能。

> **ai_Abstract:** 本文针对具身智能体在动态高风险环境中决策延迟的关键问题，提出了时间转换机制（TCM）以统一延迟度量，并扩展了HAZARD基准以实现延迟感知评估。核心贡献是设计了快速反应异步反射智能体（RRARA），该智能体结合了轻量级LLM反馈与规则代理，实现了即时反应和异步优化。实验证明RRARA在延迟敏感场景中性能显著超越现有方法。

> **摘要翻译:** 在具身智能领域，大型语言模型（LLM）的演进显著增强了智能体的决策能力。因此，研究人员已开始探索智能体在动态变化的高风险场景中的表现，例如HAZARD基准中的火灾、洪水和大风场景。在这些极端条件下，决策延迟成为一个关键但尚未充分研究的问题。我们提出了一种时间转换机制（TCM），它将决策推理延迟转换为等效的模拟帧，从而在单一的基于FPS的度量标准下统一了认知和物理成本。通过用响应延迟（RL）和行动延迟比（LAR）扩展HAZARD，我们提供了一个完全延迟感知的评估协议。此外，我们提出了快速反应异步反射智能体（RRARA），它将一个轻量级LLM引导的反馈模块与一个基于规则的智能体相结合，以实现即时反应行为和异步反射改进。HAZARD上的实验表明，RRARA在延迟敏感场景中显著优于现有基线。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [373] [Subgoal-Guided Policy Heuristic Search with Learned Subgoals](https://arxiv.org/abs/2506.07255)
> *基于学习子目标的子目标引导策略启发式搜索*

*Jake Tuero, Michael Buro, Levi H. S. Lelis* | **Main category: cs.AI**

**Keywords:** 策略树搜索, 子目标, 样本效率, 启发式搜索

**Comment:** Accepted to ICML-25

> **TL;DR:** 现有策略树搜索训练成本高昂，因其依赖完整解决方案。本文提出从所有搜索树（包括失败尝试）中学习子目标和策略，以提高样本效率。

**AI_Comments:** 该论文解决了策略树搜索中的一个关键限制：策略训练的高成本和样本效率低下，尤其是在初始策略较差或处理复杂问题时。通过创新性地利用失败搜索尝试中的数据，该方法显著提高了样本效率。这种方法有望使策略树搜索在难以获得完整成功轨迹的复杂问题领域中变得更加实用和可扩展。从“失败”中学习的理念是机器学习中的一个强大概念，其在此的应用是一项显著贡献。

<details>
  <summary>Details</summary>

**Motivation:** 当前的策略树搜索算法在训练时需要完整的解决方案轨迹，这导致在处理困难问题或使用随机初始化策略时，训练成本过高且搜索样本在失败尝试中被浪费。

**Method:** 本文提出一种新颖的方法，用于为策略树搜索算法学习基于子目标的策略。子目标和以子目标为条件的策略均从搜索在尝试解决问题时扩展的所有树中学习，包括失败尝试的搜索树。

**Result:** 实证结果表明，所提出的策略制定和训练方法提高了在线设置中学习策略和启发式函数的样本效率。

**Conclusion:** 通过从包括失败尝试在内的所有搜索尝试中学习，本文提出的方法显著提高了策略树搜索算法中策略和启发式函数训练的样本效率。

> **ai_Abstract:** 本文提出了一种新颖的子目标引导策略启发式搜索方法，旨在提高策略树搜索算法的样本效率。现有方法需要完整的解决方案轨迹进行训练，导致在处理困难问题或初始策略随机时，训练成本高昂且样本浪费。本研究通过从所有搜索树（包括失败尝试的搜索树）中学习子目标和基于子目标的策略，有效地解决了这一问题。实验结果表明，该方法显著提升了在线设置下学习策略和启发式函数的样本效率。

> **摘要翻译:** 策略树搜索是一系列使用策略来指导搜索的树搜索算法。这些算法根据策略的质量，对解决给定问题所需的扩展次数提供保证。尽管这些算法已显示出有希望的结果，但其训练过程需要完整的解决方案轨迹来训练策略。搜索轨迹是在试错搜索过程中获得的。当训练问题实例很困难时，学习成本可能高得令人望而却步，尤其是在从随机初始化的策略开始时。结果，搜索样本在解决这些困难实例的失败尝试中被浪费。本文介绍了一种为策略树搜索算法学习基于子目标的策略的新方法。子目标和以子目标为条件的策略是从搜索在尝试解决问题时扩展的树中学习的，包括失败尝试的搜索树。我们凭经验表明，我们的策略制定和训练方法提高了在这种在线设置中学习策略和启发式函数的样本效率。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [383] [An Intelligent Fault Self-Healing Mechanism for Cloud AI Systems via Integration of Large Language Models and Deep Reinforcement Learning](https://arxiv.org/abs/2506.07411)
> *通过集成大型语言模型和深度强化学习为云AI系统提供智能故障自愈机制*

*Ze Yang, Yihong Jin, Juntian Liu, Xinhe Xu* | **Main category: cs.AI**

**Keywords:** 智能故障自愈, 大型语言模型, 深度强化学习, 云AI系统, 故障恢复

**Comment:** Proceedings of 2025 IEEE 8th International Conference on Advanced
  Electronic Materials, Computers and Software Engineering (AEMCSE 2025)

> **TL;DR:** 本文提出了一种智能故障自愈机制（IFSHM），通过整合大型语言模型（LLM）和深度强化学习（DRL），旨在为云AI系统提供具备语义理解和策略优化能力的故障恢复框架。

**AI_Comments:** 该论文的创新点在于首次将大型语言模型（LLM）引入到云AI系统的故障自愈机制中，并将其与深度强化学习（DRL）相结合。通过LLM进行环境建模和动作空间抽象，极大地提升了强化学习的探索效率和泛化能力，解决了传统DRL在复杂云环境中的局限性。此外，引入记忆引导的元控制器有效解决了灾难性遗忘问题，使得系统能够持续适应新的故障模式。这项工作为提升云AI系统的可靠性和韧性提供了重要的技术路径。

<details>
  <summary>Details</summary>

**Motivation:** 随着云AI系统规模和复杂性的不断增加，故障检测和自适应恢复已成为确保服务可靠性和连续性的核心挑战。

**Method:** 本文提出了一种智能故障自愈机制（IFSHM），该机制整合了大型语言模型（LLM）和深度强化学习（DRL）。在传统基于DRL的控制模型基础上，该方法构建了一个两阶段混合架构：1）LLM驱动的故障语义解释模块，能够从多源日志和系统指标中动态提取深层上下文语义，以准确识别潜在故障模式；2）DRL恢复策略优化器，基于强化学习，学习云环境中故障类型和响应行为的动态匹配。该方法的创新之处在于引入LLM进行环境建模和动作空间抽象，从而大大提高了强化学习的探索效率和泛化能力。同时，引入了记忆引导的元控制器，结合强化学习回放和LLM提示微调策略，以实现对新故障模式的持续适应并避免灾难性遗忘。

**Result:** 在云故障注入平台上的实验结果表明，与现有DRL和规则方法相比，IFSHM框架在未知故障场景下将系统恢复时间缩短了37%。

**Conclusion:** 本文提出的智能故障自愈机制（IFSHM）通过有效整合大型语言模型（LLM）和深度强化学习（DRL），显著提升了云AI系统在复杂和未知故障场景下的故障检测、语义理解和自适应恢复能力，尤其在缩短系统恢复时间方面表现出显著优势。

> **ai_Abstract:** 本文提出了一种名为智能故障自愈机制（IFSHM）的新框架，旨在解决云AI系统中的故障检测和恢复挑战。该机制巧妙地结合了大型语言模型（LLM）和深度强化学习（DRL）。IFSHM采用两阶段架构：首先，LLM模块负责从多源数据中进行故障语义解释和模式识别；其次，DRL优化器学习并执行最佳恢复策略。该方法通过引入LLM进行环境建模和动作空间抽象，显著提升了强化学习的效率和泛化能力，并通过记忆引导的元控制器确保了对新故障模式的持续适应。实验证明，IFSHM在未知故障场景下能将系统恢复时间缩短37%。

> **摘要翻译:** 随着云AI系统规模和复杂性的不断增加，系统故障的检测和自适应恢复已成为确保服务可靠性和连续性的核心挑战。在本文中，我们提出了一种智能故障自愈机制（IFSHM），该机制整合了大型语言模型（LLM）和深度强化学习（DRL），旨在实现云AI系统中具备语义理解和策略优化能力的故障恢复框架。在传统基于DRL的控制模型基础上，所提出的方法构建了一个两阶段混合架构：1）LLM驱动的故障语义解释模块，能够从多源日志和系统指标中动态提取深层上下文语义，以准确识别潜在故障模式；2）DRL恢复策略优化器，基于强化学习，学习云环境中故障类型和响应行为的动态匹配。该方法的创新之处在于引入LLM进行环境建模和动作空间抽象，从而大大提高了强化学习的探索效率和泛化能力。同时，引入了记忆引导的元控制器，结合强化学习回放和LLM提示微调策略，以实现对新故障模式的持续适应并避免灾难性遗忘。在云故障注入平台上的实验结果表明，与现有DRL和规则方法相比，IFSHM框架在未知故障场景下将系统恢复时间缩短了37%。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [388] [Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests](https://arxiv.org/abs/2506.07418)
> *评估多模态大语言模型中的视觉数学：一个基于袋鼠测试的多语言基准*

*Arnau Igualde Sáez, Lamyae Rhomrasi, Yusef Ahsini, Ricardo Vinuesa, Sergio Hoyas, Jose P. García Sabater, Marius J. Fullana i Alfonso, J. Alberto Conejero* | **Main category: cs.AI**

**Keywords:** 多模态大语言模型, 视觉数学, 基准测试, 推理, 袋鼠测试

**Comment:** 16 pages, 4 figures

> **TL;DR:** 论文评估了多模态大语言模型在视觉数学问题解决上的表现，发现现有模型在处理图像、多语言和复杂推理方面仍有不足，但Gemini和GPT 4o展现出更好的推理能力。

**AI_Comments:** 这篇论文对多模态大语言模型在视觉数学领域的应用进行了深入且多维度的评估，填补了该领域研究的空白。其创新之处在于构建了一个多语言、多难度级别的基准测试，并对模型的推理能力进行了细致区分。研究结果揭示了当前MLLMs在处理复杂视觉数学问题时的局限性，并强调了未来在图表信息利用和高级推理能力方面改进的重要性。特别是对模型“推理”而非“复述”的区分，为后续研究提供了有价值的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型在视觉语言能力方面前景广阔，但它们在视觉呈现的数学方面的有效性仍未被充分探索。

**Method:** 论文分析了多模态大语言模型在数学问题解决方面的开发和评估，重点关注图表、多语言文本和符号表示。随后，评估了包括GPT 4o、Pixtral、Qwen VL、Llama 3.2 Vision变体和Gemini 2.0 Flash在内的多个模型，使用一个涵盖英语、法语、西班牙语和加泰罗尼亚语的多语言袋鼠风格基准。

**Result:** 1. 整体准确率在几何、视觉代数、逻辑、模式和组合学方面仍处于中等水平，没有单一模型在所有主题上表现出色。
2. 大多数模型在没有图像的问题上准确率有所提高，但提升有限；一些模型在没有视觉输入的情况下性能几乎不变，表明对图表信息利用不足。
3. 不同语言和难度级别之间存在显著差异：模型通常能处理较简单的项目，但在高级几何和组合推理方面表现不佳。Gemini 2.0 Flash在基于图像的任务上准确率最高，其次是Qwen VL 2.5 72B和GPT 4o，但都未达到人类水平。
4. 一项旨在区分模型是推理还是简单复述的补充分析表明，Gemini和GPT 4o在结构化推理和一致性准确率方面表现突出。相比之下，Pixtral和Llama的推理一致性较差，在无法将其输出与给定答案选项对齐时，通常会采用启发式或随机方法。

**Conclusion:** 现有的多模态大语言模型在视觉数学问题解决方面仍有显著局限性，尤其是在处理复杂视觉信息和高级推理方面。尽管如此，Gemini和GPT 4o展现出更强的结构化推理能力，但所有模型都未能达到人类水平。

> **ai_Abstract:** 本文评估了多模态大语言模型在视觉数学问题解决中的表现，特别关注图表、多语言文本和符号。通过一项多语言袋鼠测试基准，研究发现现有模型在处理视觉数学问题时，尤其是在高级几何和组合推理方面，准确率仍处于中等水平，且对图表信息利用不足。尽管Gemini 2.0 Flash在图像任务上表现最佳，但所有模型都未达到人类水平。研究还指出，Gemini和GPT 4o展现出更强的结构化推理能力，而其他模型则可能依赖启发式或随机方法。

> **摘要翻译:** 多模态大型语言模型（MLLMs）有望提供先进的视觉语言能力，但它们在视觉呈现的数学方面的有效性仍未被充分探索。本文分析了MLLMs在数学问题解决方面的开发和评估，重点关注图表、多语言文本和符号表示。随后，我们使用一个涵盖英语、法语、西班牙语和加泰罗尼亚语的多语言袋鼠风格基准，评估了包括GPT 4o、Pixtral、Qwen VL、Llama 3.2 Vision变体和Gemini 2.0 Flash在内的多个模型。我们的实验揭示了四个关键发现。首先，在几何、视觉代数、逻辑、模式和组合学方面，整体准确率仍处于中等水平：没有单一模型在所有主题上表现出色。其次，虽然大多数模型在没有图像的问题上准确率有所提高，但提升通常有限；一些模型在没有视觉输入的情况下性能几乎不变，表明对图表信息利用不足。第三，不同语言和难度级别之间存在显著差异：模型通常能处理较简单的项目，但在高级几何和组合推理方面表现不佳。值得注意的是，Gemini 2.0 Flash在基于图像的任务上准确率最高，其次是Qwen VL 2.5 72B和GPT 4o，尽管都没有接近人类水平的性能。第四，一项旨在区分模型是推理还是简单复述的补充分析表明，Gemini和GPT 4o在结构化推理和一致性准确率方面表现突出。相比之下，Pixtral和Llama的推理一致性较差，在无法将其输出与给定答案选项对齐时，通常会采用启发式或随机方法。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [394] [HeTa: Relation-wise Heterogeneous Graph Foundation Attack Model](https://arxiv.org/abs/2506.07428)
> *HeTa: 关系感知异构图基础攻击模型*

*Yuling Wang, Zihui Chen, Pengfei Jiao, Xiao Wang* | **Main category: cs.AI**

**Keywords:** 异构图神经网络, 攻击模型, 基础模型, 泛化性, 关系感知

**Comment:** Accepted by IJCAI 2025

> **TL;DR:** HeTa是一个针对异构图神经网络（HGNNs）的新型关系感知基础攻击模型，旨在解决现有攻击缺乏泛化性和适应性的问题，通过发现HGNNs共享的脆弱模式，实现可转移且易于微调的扰动。

**AI_Comments:** HeTa的创新之处在于提出了一个针对异构图神经网络的基础攻击模型，解决了现有攻击泛化性差的问题。通过发现HGNNs之间共享的脆弱模式并采用关系感知的方法，HeTa实现了可转移和可微调的扰动生成，这对于评估HGNNs的鲁棒性和确保其安全性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 异构图神经网络（HGNNs）易受攻击，但现有攻击通常需要复杂的参数再训练以适应新场景，缺乏泛化性。因此，需要设计一个针对HGNNs的基础攻击模型，使其能够生成可泛化的扰动，并快速适应新的异构图。

**Method:** 本文提出了一个新颖的关系感知异构图基础攻击模型HeTa。它引入了一个基础代理模型来对齐异构性并识别共享的关系感知攻击单元的重要性。在此基础上，HeTa根据识别出的关系权重实现了序列化的逐关系攻击，使得扰动可以转移到各种目标HGNNs并轻松地为新的异构图进行微调。

**Result:** 广泛的实验证明了HeTa方法强大的攻击性能和泛化能力。

**Conclusion:** HeTa模型成功地为异构图神经网络提供了一种具有强大攻击性能和泛化能力的基础攻击方法，解决了现有攻击的局限性。

> **ai_Abstract:** 异构图神经网络（HGNNs）容易受到攻击，而现有攻击方法往往需要针对新场景进行复杂的参数再训练，缺乏泛化性。本文提出了一种新颖的关系感知异构图基础攻击模型HeTa，旨在为HGNNs设计一个能够生成可泛化扰动并快速适应新异构图的通用攻击框架。研究发现不同HGNNs在关系感知层面存在共享的脆弱模式。HeTa通过引入一个基础代理模型来识别共享关系感知攻击单元的重要性，并在此基础上实现逐关系攻击。实验结果表明，HeTa具有强大的攻击性能和良好的泛化能力，能够有效地攻击各种HGNNs并适应新的异构图。

> **摘要翻译:** 异构图神经网络（HGNNs）易受攻击，这突显了需要量身定制的攻击来评估其鲁棒性并确保安全性。然而，现有的HGNN攻击通常需要复杂的参数再训练才能为新场景生成特定的扰动。最近，基础模型为图神经网络的泛化开辟了新视野，通过捕获各种图分布中的共享语义。这促使我们思考：我们能否为HGNNs设计一个基础攻击模型，使其能够在不同的HGNNs之间实现可泛化的扰动，并快速适应新的异构图（HGs）？实证研究表明，尽管模型设计和参数空间存在显著差异，但从关系感知的角度来看，不同的HGNNs出人意料地共享着共同的脆弱模式。因此，我们探索如何通过挖掘共享攻击单元来设计基础HGNN攻击标准。在本文中，我们提出了一种新颖的关系感知异构图基础攻击模型HeTa。我们引入了一个基础代理模型来对齐异构性并识别共享关系感知攻击单元的重要性。在此基础上，我们根据识别出的关系权重实现了一个序列化的逐关系攻击。通过这种方式，扰动可以转移到各种目标HGNNs，并轻松地为新的HGs进行微调。广泛的实验展示了我们方法强大的攻击性能和泛化能力。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [399] [LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning](https://arxiv.org/abs/2506.07443)
> *错误：AI分析失败。*

*Weijie Shi, Han Zhu, Jiaming Ji, Mengze Li, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Sirui Han, Yike Guo* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [404] [Fact in Fragments: Deconstructing Complex Claims via LLM-based Atomic Fact Extraction and Verification](https://arxiv.org/abs/2506.07446)
> *错误：AI分析失败。*

*Liwen Zheng, Chaozhuo Li, Zheng Liu, Feiran Huang, Haoran Jia, Zaisheng Ye, Xi Zhang* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [409] [Efficient Generation of Diverse Cooperative Agents with World Models](https://arxiv.org/abs/2506.07450)
> *错误：AI分析失败。*

*Yi Loo, Akshunn Trivedi, Malika Meghjani* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [413] [Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions](https://arxiv.org/abs/2506.07527)
> *错误：AI分析失败。*

*Lu Ma, Hao Liang, Meiyi Qiang, Lexiang Tang, Xiaochen Ma, Zhen Hao Wong, Junbo Niu, Chengyu Shen, Runming He, Bin Cui, Wentao Zhang* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [416] [Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification](https://arxiv.org/abs/2506.07528)
> *错误：AI分析失败。*

*Qisheng Hu, Quanyu Long, Wenya Wang* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 19 pages, 9 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [421] [Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2506.07548)
> *错误：AI分析失败。*

*Weiqiang Jin, Hongyang Du, Guizhong Liu, Dong In Kim* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages; 12figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [426] [GTR-CoT: Graph Traversal as Visual Chain of Thought for Molecular Structure Recognition](https://arxiv.org/abs/2506.07553)
> *错误：AI分析失败。*

*Jingchao Wang, Haote Yang, Jiang Wu, Yifan He, Xingjian Wei, Yinfan Wang, Chengjin Liu, Lingli Ge, Lijun Wu, Bin Wang, Dahua Lin, Conghui He* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [431] [SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems](https://arxiv.org/abs/2506.07564)
> *错误：AI分析失败。*

*Peiran Li, Xinkai Zou, Zhuohang Wu, Ruifeng Li, Shuo Xing, Hanwen Zheng, Zhikai Hu, Yuping Wang, Haoxi Li, Qin Yuan, Yingmo Zhang, Zhengzhong Tu* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [436] [Automating Exploratory Multiomics Research via Language Models](https://arxiv.org/abs/2506.07591)
> *错误：AI分析失败。*

*Shang Qu, Ning Ding, Linhai Xie, Yifei Li, Zaoqu Liu, Kaiyan Zhang, Yibai Xiong, Yuxin Zuo, Zhangren Chen, Ermo Hua, Xingtai Lv, Youbang Sun, Yang Li, Dong Li, Fuchu He, Bowen Zhou* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [441] [SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling](https://arxiv.org/abs/2506.07636)
> *错误：AI分析失败。*

*Haoran Wang, Zhenyu Hou, Yao Wei, Jie Tang, Yuxiao Dong* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to Findings of ACL'25

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [446] [MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents](https://arxiv.org/abs/2506.07672)
> *错误：AI分析失败。*

*Yunhe Yan, Shihe Wang, Jiajun Du, Yexuan Yang, Yuxuan Shan, Qichen Qiu, Xianqing Jia, Xinge Wang, Xin Yuan, Xu Han, Mao Qin, Yinxiao Chen, Chen Peng, Shangguang Wang, Mengwei Xu* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [449] [NeurIPS 2025 E2LM Competition : Early Training Evaluation of Language Models](https://arxiv.org/abs/2506.07731)
> *错误：AI分析失败。*

*Mouadh Yagoubi, Yasser Dahou, Billel Mokeddem, Younes Belkada, Phuc H. Le-Khac, Basma El Amel Boussaha, Reda Alami, Jingwei Zuo, Damiano Marsili, Mugariya Farooq, Mounia Lalmas, Georgia Gkioxari, Patrick Gallinari, Philip Torr, Hakim Hacid* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [454] [RSafe: Incentivizing proactive reasoning to build robust and adaptive LLM safeguards](https://arxiv.org/abs/2506.07736)
> *错误：AI分析失败。*

*Jingnan Zheng, Xiangtian Ji, Yijun Lu, Chenhang Cui, Weixiang Zhao, Gelei Deng, Zhenkai Liang, An Zhang, Tat-Seng Chua* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [460] [REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models](https://arxiv.org/abs/2506.07759)
> *错误：AI分析失败。*

*Diego Forniés-Tabuenca, Alejandro Uribe, Urtzi Otamendi, Arkaitz Artetxe, Juan Carlos Rivera, Oier Lopez de Lacalle* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, 5 tables, 7 figures and 4 appendixes. Pre-print submitted
  to IEEE Transactions on Evolutionary Computation

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [465] [A Proposal to Extend the Common Model of Cognition with Metacognition](https://arxiv.org/abs/2506.07807)
> *错误：AI分析失败。*

*John Laird, Christian Lebiere, Paul Rosenbloom, Andrea Stocco, Robert Wray* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [468] [Guideline Forest: Experience-Induced Multi-Guideline Reasoning with Stepwise Aggregation](https://arxiv.org/abs/2506.07820)
> *错误：AI分析失败。*

*Jiaxiang CHen, Zhuo Wang, Mingxi Zou, Qifan Wang, Zenglin Xu* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [472] [Addition in Four Movements: Mapping Layer-wise Information Trajectories in LLMs](https://arxiv.org/abs/2506.07824)
> *错误：AI分析失败。*

*Yao Yan* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages, including appendix, 7 figures. EMNLP 2025 submission (ARR
  May 2025 cycle, reviews pending)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [475] [HAIBU-ReMUD: Reasoning Multimodal Ultrasound Dataset and Model Bridging to General Specific Domains](https://arxiv.org/abs/2506.07837)
> *错误：AI分析失败。*

*Shijie Wang, Yilun Zhang, Zeyu Lai, Dexing Kong* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [478] [A Temporal FRBR/FRBRoo-Based Model for Component-Level Versioning of Legal Norms](https://arxiv.org/abs/2506.07853)
> *错误：AI分析失败。*

*Hudson de Martim* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [481] [Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark](https://arxiv.org/abs/2506.07896)
> *错误：AI分析失败。*

*Shoko Oka* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 52 pages, Additional resources available on GitHub repository

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [483] [LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement](https://arxiv.org/abs/2506.07915)
> *错误：AI分析失败。*

*Dimitris Panagopoulos, Adolfo Perrusquia, Weisi Guo* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages, 4 Figures, 3 Tables, submitted to the IEEE for possible
  publication

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [486] [Solving Inequality Proofs with Large Language Models](https://arxiv.org/abs/2506.07927)
> *错误：AI分析失败。*

*Jiayi Sheng, Luna Lyu, Jikai Jin, Tony Xia, Alex Gu, James Zou, Pan Lu* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 52 pages, 16 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [490] [Gradients: When Markets Meet Fine-tuning -- A Distributed Approach to Model Optimisation](https://arxiv.org/abs/2506.07940)
> *错误：AI分析失败。*

*Christopher Subia-Waud* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [493] [Reinforcing Multimodal Understanding and Generation with Dual Self-rewards](https://arxiv.org/abs/2506.07963)
> *错误：AI分析失败。*

*Jixiang Hong, Yiran Zhang, Guanzhong Wang, Yi Liu, Ji-Rong Wen, Rui Yan* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [496] [$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment](https://arxiv.org/abs/2506.07982)
> *错误：AI分析失败。*

*Victor Barres, Honghua Dong, Soham Ray, Xujie Si, Karthik Narasimhan* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

### [499] [GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior](https://arxiv.org/abs/2506.08012)
> *错误：AI分析失败。*

*Penghao Wu, Shengnan Ma, Bo Wang, Jiaheng Yu, Lewei Lu, Ziwei Liu* | **Main category: cs.AI**

**Keywords:** 错误：AI分析失败。

**Comment:** Project Page at https://penghao-wu.github.io/GUI_Reflection/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csai) | [⬆️ 返回总目录](#toc)

---

<a id='cslg'></a>
## cs.LG 

### [1] [Extending AALpy with Passive Learning: A Generalized State-Merging Approach](https://arxiv.org/abs/2506.06333)
> *将AALpy扩展到被动学习：一种广义的状态合并方法*

*Benjamin von Berg, Bernhard K. Aichernig* | **Main category: cs.LG**

**Keywords:** AALpy, 被动学习, 状态合并, 自动机学习, 红蓝框架

**Comment:** Accepted for publication at CAV 2025, the 37th International
  Conference on Computer Aided Verification

> **TL;DR:** AALpy库新增了广义的状态合并实现，简化了被动自动机学习算法的开发。

**AI_Comments:** 这项工作通过集成被动学习的关键方法，增强了AALpy作为通用自动机学习库的功能。其创新之处在于提供了一个广义且可配置的状态合并框架，极大地降低了算法实现门槛，对于促进自动机学习领域的研究和应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AALpy库主要关注主动学习，而缺乏对被动自动机学习中重要方法（如状态合并）的通用支持，这限制了其在被动学习领域的应用和新算法的实现。

**Method:** 作者将一种广义的状态合并方法（基于红蓝框架）集成到AALpy库中。通过使用不同自动机类型的通用内部表示，实现了高度可配置的红蓝框架，并简化了状态合并算法的定义，主要集中于兼容性标准和评分的定义。

**Result:** 这种集成显著降低了状态合并算法的实现难度，使得现有和新颖的算法更容易被开发。文献中已有的状态合并算法现在只需几行代码即可在AALpy中定义。

**Conclusion:** 通过在AALpy中引入广义的状态合并实现，该工作有效地扩展了AALpy的功能，使其能够支持被动自动机学习，并极大地简化了相关算法的开发。

> **ai_Abstract:** 本文介绍了对开源自动机学习库AALpy的扩展，新增了被动自动机学习领域中广义状态合并方法（基于红蓝框架）的实现。通过采用通用内部表示，该实现具有高度可配置性，并显著降低了状态合并算法的开发难度，使得现有和新颖算法的定义变得更加简单高效。

> **摘要翻译:** AALpy是一个成熟的开源自动机学习库，用Python编写，专注于具有IO行为的系统的主动学习。它提供了广泛的最新算法，适用于从完全确定性到概率自动机的不同自动机类型。在这项工作中，我们介绍了最近添加的被动自动机学习领域中一种重要方法的广义实现：红蓝框架中的状态合并。使用不同自动机类型的通用内部表示，可以实现红蓝框架的通用且高度可配置的实现。我们描述了如何使用AALpy定义和执行状态合并算法，这主要将状态合并算法的实现工作量减少到兼容性标准和评分的定义。这有助于现有和新颖算法的实现。特别是，使用AALpy定义文献中一些现有的状态合并算法只需几行代码。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [17] [CellCLIP -- Learning Perturbation Effects in Cell Painting via Text-Guided Contrastive Learning](https://arxiv.org/abs/2506.06290)
> *CellCLIP——通过文本引导的对比学习来学习细胞图谱中的扰动效应*

*Mingyu Lu, Ethan Weinberger, Chanwoo Kim, Su-In Lee* | **Main category: cs.LG**

**Keywords:** 高内涵筛选, 细胞图谱, 对比学习, 跨模态, 扰动效应

**Comment:** 

> **TL;DR:** CellCLIP是一个用于高内涵筛选（HCS）数据的跨模态对比学习框架，它解决了传统方法在细胞图谱图像和扰动表示上的挑战，通过结合预训练图像编码器和新型通道编码方案，以及自然语言编码器来表示扰动，从而在跨模态检索和生物学下游任务中表现优异，并显著减少计算时间。

**AI_Comments:** CellCLIP的创新之处在于其针对细胞图谱数据的特性，引入了新颖的通道编码方案来优化图像嵌入，并结合了自然语言编码器来统一表示不同类型的扰动。这解决了传统跨模态对比学习方法在应用于高内涵筛选数据时的核心挑战。该方法的重要性在于其能够更有效地理解细胞对扰动的形态反应，为药物发现和疾病研究提供强大的工具。计算时间的显著减少也使其具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 高内涵筛选（HCS）技术（如细胞图谱）能够大规模地研究细胞对扰动的形态反应。理论上，跨模态对比学习可以帮助理解不同扰动及其对细胞状态的影响，但将此类方法应用于HCS数据面临挑战，包括细胞图谱图像与自然图像语义的巨大差异，以及在单一潜在空间中表示不同类型扰动（如小分子与CRISPR基因敲除）的难度。

**Method:** 本文引入了CellCLIP，一个用于HCS数据的跨模态对比学习框架。CellCLIP利用预训练的图像编码器结合新颖的通道编码方案，以更好地捕获图像嵌入中不同显微镜通道之间的关系，并使用自然语言编码器来表示扰动。

**Result:** CellCLIP框架优于当前的开源模型，在跨模态检索和生物学意义的下游任务中均表现出最佳性能，同时显著减少了计算时间。

**Conclusion:** CellCLIP成功地解决了将跨模态对比学习应用于高内涵筛选数据的挑战，提供了一个高效且高性能的框架，能够更好地理解扰动对细胞形态的影响。

> **ai_Abstract:** 本文介绍了CellCLIP，一个针对高内涵筛选（HCS）数据的跨模态对比学习框架。该框架旨在克服将现有跨模态对比学习方法应用于细胞图谱数据时的挑战，特别是细胞图像语义的差异性以及统一表示多种扰动类型的困难。CellCLIP通过结合预训练图像编码器、新颖的通道编码方案以及自然语言编码器来表示扰动，从而学习扰动与其对应的形态效应之间的统一潜在空间。实验结果表明，CellCLIP在跨模态检索和生物学下游任务中均优于现有开源模型，并显著降低了计算成本。

> **摘要翻译:** 高内涵筛选（HCS）检测，基于高通量显微镜技术，如细胞图谱（Cell Painting），已经实现了对细胞对扰动的形态反应进行前所未有的规模的探究。收集此类数据有望促进更好地理解不同扰动及其对细胞状态之间关系。为了实现这一目标，跨模态对比学习的最新进展理论上可以被利用来学习一个统一的潜在空间，将扰动与其相应的形态效应对齐。然而，由于细胞图谱图像与自然图像的语义存在实质性差异，以及在单一潜在空间中表示不同类别扰动（例如，小分子与CRISPR基因敲除）的难度，将此类方法应用于HCS数据并不直接。为了应对这些挑战，我们在此引入了CellCLIP，一个用于HCS数据的跨模态对比学习框架。CellCLIP利用预训练的图像编码器结合新颖的通道编码方案，以更好地捕获图像嵌入中不同显微镜通道之间的关系，并结合自然语言编码器来表示扰动。我们的框架优于当前的开源模型，在跨模态检索和具有生物学意义的下游任务中均表现出最佳性能，同时显著减少了计算时间。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [24] [Towards Infant Sleep-Optimized Driving: Synergizing Wearable and Vehicle Sensing in Intelligent Cruise Control](https://arxiv.org/abs/2506.06459)
> *面向婴儿睡眠优化的驾驶：智能巡航控制中可穿戴和车辆传感的协同作用*

*Ruitao Chen, Mozhang Guo, Jinge Li* | **Main category: cs.LG**

**Keywords:** 婴儿睡眠优化, 智能巡航控制, 强化学习, 可穿戴传感, 车辆传感

**Comment:** 

> **TL;DR:** 本文提出了一种智能巡航控制框架，通过结合可穿戴和车辆传感数据以及强化学习，优化驾驶行为以提升婴儿睡眠质量，并在仿真中显示出显著效果。

**AI_Comments:** 这项研究在自动驾驶领域引入了乘客福祉，特别是婴儿睡眠质量这一新颖且重要的考量维度，具有创新性。通过结合多模态数据（可穿戴、车辆、地图）和先进的AI技术（强化学习、LSTM、Transformer），为实现更人性化和以乘客为中心的智能驾驶提供了新的范式。其潜在应用价值在于显著提升家庭出行体验，减少父母的困扰。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶（AD）对乘客福祉，特别是婴儿睡眠的影响研究不足。突然的加速、急刹车和急转弯会扰乱婴儿睡眠，影响乘客舒适度和父母便利性。

**Method:** 本文提出了一种智能巡航控制框架，该框架将强化学习（RL）与长短期记忆（LSTM）和基于Transformer的神经网络相结合。通过协同利用可穿戴传感器提供的睡眠质量指标、车辆控制器提供的驾驶行为数据以及地图数据，该模型动态计算最佳驾驶激进程度，并将其转化为具体的自动驾驶控制策略（如加减速的幅度、频率、变道和超车），以适应不同驾驶条件，从而提高婴儿睡眠质量。

**Result:** 仿真结果表明，所提出的解决方案与基线方法相比，显著提高了婴儿睡眠质量，同时保持了理想的出行效率。

**Conclusion:** 通过整合可穿戴和车辆传感数据，并利用强化学习优化自动驾驶行为，可以有效地提升婴儿在车内的睡眠质量，同时不牺牲出行效率。

> **ai_Abstract:** 本文提出了一种创新的智能巡航控制框架，旨在解决自动驾驶对婴儿睡眠影响研究不足的问题。该框架结合了强化学习、LSTM和Transformer网络，通过协同分析可穿戴传感器提供的婴儿睡眠质量数据、车辆驾驶行为数据和地图数据，动态调整驾驶激进程度。其目标是优化自动驾驶行为，以提高婴儿睡眠质量，同时保持出行效率。仿真结果验证了该方法在改善婴儿睡眠方面优于基线方法。

> **摘要翻译:** 自动驾驶（AD）已大大提高了车辆安全性和驾驶舒适性，但其对乘客福祉，特别是婴儿睡眠的影响，尚未得到充分研究。突然的加速、急刹车和急转弯会扰乱婴儿睡眠，损害乘客舒适度及父母便利性。为解决此问题，本文探索了在自动驾驶中集成强化学习（RL），以个性化驾驶行为，并最佳地平衡乘员舒适度和出行效率。特别是，我们提出了一种智能巡航控制框架，该框架通过有效协同可穿戴传感和车辆数据，适应不同的驾驶条件以提高婴儿睡眠质量。长短期记忆（LSTM）和基于Transformer的神经网络与强化学习相结合，以建模驾驶行为与不同交通和道路条件下婴儿睡眠质量之间的关系。基于可穿戴传感器提供的睡眠质量指标、车辆控制器提供的驾驶动作数据以及地图应用程序提供的地图数据，模型动态计算最佳驾驶激进程度，随后将其转化为具体的自动驾驶控制策略，例如加减速的幅度、频率、变道和超车。仿真结果表明，与基线方法相比，所提出的解决方案显著提高了婴儿睡眠质量，同时保持了理想的出行效率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [31] [Improvement of Optimization using Learning Based Models in Mixed Integer Linear Programming Tasks](https://arxiv.org/abs/2506.06291)
> *混合整数线性规划任务中基于学习模型的优化改进*

*Xiaoke Wang, Batuhan Altundas, Zhaoxin Li, Aaron Zhao, Matthew Gombolay* | **Main category: cs.LG**

**Keywords:** 混合整数线性规划, 学习模型, 图神经网络, 行为克隆, 强化学习

**Comment:** 4 pages, 4 figures

> **TL;DR:** 该研究提出一个基于学习的框架，利用BC和RL训练GNN，为MILP求解器提供高质量初始解，从而减少优化时间和方差。

**AI_Comments:** 这项研究通过结合机器学习（特别是GNN、BC和RL）与传统优化方法（MILP），为解决大规模MILP问题提供了创新途径。其重要性在于，通过提供高质量的初始解来“热启动”求解器，显著提高了计算效率，这对于实时和大规模工业应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 混合整数线性规划（MILPs）在关键行业中解决规划和调度问题至关重要，但其广泛应用受限于计算时间过长，尤其在大规模、实时场景中。

**Method:** 本文提出了一个基于学习的框架，该框架利用行为克隆（BC）和强化学习（RL）来训练图神经网络（GNNs），旨在为多智能体任务分配和调度问题中的混合整数线性规划（MILP）求解器提供高质量的初始解以进行热启动。

**Result:** 实验结果表明，与传统技术相比，该方法在保持解的质量和可行性的同时，减少了优化时间和方差。

**Conclusion:** 该方法通过提供高质量的初始解，显著提高了MILP求解器的效率，使其在大规模实时应用中更具可行性。

> **ai_Abstract:** 本文提出一种基于学习的框架，结合行为克隆和强化学习训练图神经网络，旨在为混合整数线性规划（MILPs）求解器提供高质量的初始解，以解决其在复杂任务分配和调度问题中计算时间过长的问题。实验证明，该方法能有效缩短优化时间并降低方差，同时保持解的质量和可行性。

> **摘要翻译:** 混合整数线性规划（MILPs）是解决建筑、制造和物流等关键行业规划和调度问题的重要工具。然而，它们的广泛应用受到计算时间过长的限制，尤其是在大规模、实时场景中。为了解决这个问题，我们提出了一个基于学习的框架，该框架利用行为克隆（BC）和强化学习（RL）来训练图神经网络（GNNs），为多智能体任务分配和调度问题中的MILP求解器生成高质量的初始解以进行热启动。实验结果表明，与传统技术相比，我们的方法在保持解的质量和可行性的同时，减少了优化时间和方差。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [45] [Mutual-Taught for Co-adapting Policy and Reward Models](https://arxiv.org/abs/2506.06292)
> *用于协同适应策略模型和奖励模型的互教方法*

*Tianyuan Shi, Canbin Huang, Fanqi Wan, Longguang Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 偏好优化, 奖励模型, 策略模型, 自训练, 分布偏移

**Comment:** Accepted to ACL 2025 (Main Conference)

> **TL;DR:** 提出了一种名为Mutual-Taught的自训练方法，通过迭代更新策略模型和奖励模型来解决大型语言模型偏好优化中的分布偏移问题，无需额外人工标注，并取得了显著效果。

**AI_Comments:** 该论文提出了一种创新的自训练框架Mutual-Taught，通过模拟EM算法，巧妙地解决了LLM偏好优化中策略模型和奖励模型之间的分布偏移问题。其主要创新点在于无需额外人工标注即可实现双模型的协同适应和迭代改进，这对于大规模LLM训练具有重要意义。实验结果显示出显著的性能提升，特别是奖励模型达到了与GPT-4o相媲美的水平，这表明了该方法的有效性和潜力。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型（LLMs）的偏好优化过程中，新生成的模型样本与奖励模型（RM）训练数据之间可能出现分布偏移，这会降低RM的效率，进而负面影响策略模型（PM）的性能。

**Method:** 提出了一种名为Mutual-Taught的自训练方法，该方法无需额外人工标注即可迭代改进PM和RM。它模仿了期望最大化（EM）算法：E步中，PM利用当前RM的反馈进行更新，引导PM更好地近似潜在的最优偏好分布；M步中，通过构建E步更新前后PM的输出来更新RM的训练数据，确保RM适应不断变化的策略分布。

**Result:** 实验结果表明，这种迭代方法能持续改进两个模型。具体而言，8B策略模型LLaMA-3-8B-Instruct-MT在AlpacaEval-2上达到了54.1%的长度控制胜率，而8B奖励模型FsfairX-LLaMA3-RM-MT在RewardBench上的表现与GPT-4o-2024-08-06相当。

**Conclusion:** Mutual-Taught方法通过自适应地协同训练策略模型和奖励模型，有效解决了LLM偏好优化中的分布偏移问题，显著提升了模型性能。

> **ai_Abstract:** 本文提出了一种名为Mutual-Taught的自训练方法，用于解决大型语言模型偏好优化中策略模型和奖励模型之间的分布偏移问题。该方法通过迭代的E步（更新策略模型）和M步（更新奖励模型）来协同适应这两个模型，无需额外人工标注。实验证明，Mutual-Taught能持续提升模型性能，其策略模型在AlpacaEval-2上表现出色，奖励模型与顶尖模型持平。

> **摘要翻译:** 在大型语言模型（LLMs）的偏好优化过程中，新生成的模型样本与用于训练奖励模型（RM）的数据之间可能出现分布偏移。这种偏移降低了RM的效率，进而对策略模型（PM）的性能产生负面影响。为了解决这一挑战，我们提出了Mutual-Taught，一种自训练方法，无需额外人工标注即可迭代改进PM和RM。我们的方法模仿了期望最大化（EM）算法。在E步中，PM利用当前RM的反馈进行更新，引导PM更好地近似潜在的最优偏好分布。在M步中，我们通过构建E步更新前后PM的输出来更新RM的训练数据。这一过程确保了RM适应不断变化的策略分布。实验结果表明，这种迭代方法能持续改进两个模型。具体而言，我们的8B策略模型LLaMA-3-8B-Instruct-MT在AlpacaEval-2上达到了54.1%的长度控制胜率，而我们的8B奖励模型FsfairX-LLaMA3-RM-MT在RewardBench上的表现与GPT-4o-2024-08-06相当。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [60] [Prediction of Bank Credit Ratings using Heterogeneous Topological Graph Neural Networks](https://arxiv.org/abs/2506.06293)
> *异构拓扑图神经网络在银行信用评级预测中的应用*

*Junyi Liu, Stanley Kok* | **Main category: cs.LG**

**Keywords:** 银行信用评级, 异构图神经网络, 持久同调, 风险预测, 金融稳定

**Comment:** WITS 2024 (Workshop on Information Technologies and Systems 2024)

> **TL;DR:** 本文提出了一种异构拓扑图神经网络（HTGNN）模型，通过结合持久同调构建的网络和传统借贷网络来预测银行信用评级，有效解决了银行间连接图数据缺失的问题。

**AI_Comments:** 本文的创新点在于提出了一种新颖的方法来处理银行间连接图数据缺失的问题，通过结合持久同调和传统借贷网络构建异构图，使得GNNs能够应用于此领域。这对于金融风险管理和市场监管具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 银行信用评级对经济稳定和利益相关者决策至关重要。尽管图神经网络（GNNs）在预测方面有潜力，但由于隐私问题，完整的银行间连接图通常不可用，这阻碍了GNNs的直接应用。

**Method:** 研究利用持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络结合，创建了一个整合两类信息的异构网络，从而提升了预测能力。

**Result:** 在全球真实世界数据集上的实验验证了HTGNN的有效性。

**Conclusion:** 该研究对投资者和监管机构在加强主动风险缓解和实施有效市场干预方面具有重要意义。

> **ai_Abstract:** 本文提出了一种异构拓扑图神经网络（HTGNN）模型，用于解决银行信用评级预测中因隐私问题导致的银行间连接图数据缺失的挑战。该模型通过持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络融合，形成一个整合多源信息的异构网络。在全球真实数据集上的实验证明了HTGNN的有效性，为投资者和监管机构提供了更准确的风险评估工具。

> **摘要翻译:** 银行信用评级预测中的异构拓扑图神经网络

标准普尔和穆迪等机构提供的银行信用评级影响着经济稳定和利益相关者的决策。准确及时的预测有助于明智的决策、监管行动和投资者保护。然而，由于隐私问题，完整的银行间连接图通常不可用，这使得图神经网络（GNNs）在评级预测中的直接应用变得复杂。我们的研究利用持久同调构建了一个捕捉银行间关系的网络，并将其与传统借贷网络结合，创建了一个整合两类信息的异构网络，从而提高了预测能力。在全球真实世界数据集上的实验验证了HTGNN的有效性。这项研究对于投资者和监管机构在加强主动风险缓解和实施有效市场干预方面具有重要意义。代码可在https://github.com/Liu-Jun-Yi/HTGNN 找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [75] [GLProtein: Global-and-Local Structure Aware Protein Representation Learning](https://arxiv.org/abs/2506.06294)
> *GLProtein: 全局与局部结构感知蛋白质表示学习*

*Yunqing Liu, Wenqi Fan, Xiaoyong Wei, Qing Li* | **Main category: cs.LG**

**Keywords:** 蛋白质表示学习, 全局结构, 局部结构, 预训练, 生物信息学

**Comment:** 

> **TL;DR:** GLProtein是一个新的蛋白质预训练框架，它结合了全局结构相似性和局部氨基酸细节，显著提高了蛋白质预测任务的准确性。

**AI_Comments:** GLProtein的创新之处在于其是首个在蛋白质预训练中同时考虑全局结构相似性和局部氨基酸细节的框架，这为蛋白质表示学习提供了一个更全面的视角。通过结合多种编码技术，它有效地捕获了蛋白质多层次的结构信息，有望在蛋白质功能预测和结构理解方面取得突破。

<details>
  <summary>Details</summary>

**Motivation:** 尽管蛋白质序列分析在理解蛋白质功能方面取得了进展，但在整合蛋白质结构信息方面仍有进一步探索的潜力。作者认为蛋白质结构信息不仅限于3D信息，还包括氨基酸分子（局部信息）和蛋白质-蛋白质结构相似性（全局信息）。现有方法可能未能充分利用这些多层次的结构信息。

**Method:** 本文提出了GLProtein框架，这是蛋白质预训练中第一个结合全局结构相似性和局部氨基酸细节的框架。它创新性地将蛋白质掩码建模与三重态结构相似性评分、蛋白质3D距离编码和基于子结构的氨基酸分子编码相结合。

**Result:** GLProtein在多项生物信息学任务中优于现有方法，包括预测蛋白质-蛋白质相互作用、接触预测等。

**Conclusion:** GLProtein通过整合全局和局部结构信息，显著提高了蛋白质预测的准确性和功能洞察力，为蛋白质表示学习提供了一个更全面的框架。

> **ai_Abstract:** 本文提出了GLProtein，一个结合全局结构相似性和局部氨酸细节的蛋白质预训练框架。该框架通过整合蛋白质掩码建模、三重态结构相似性评分、3D距离编码和子结构氨基酸编码，旨在解决现有蛋白质表示学习未能充分利用多层次结构信息的问题。实验证明，GLProtein在多种生物信息学任务中表现优异，提升了蛋白质功能预测的准确性。

> **摘要翻译:** 蛋白质是生物系统的核心，作为所有生命形式的组成部分参与其中。尽管通过蛋白质序列分析在理解蛋白质功能方面取得了进展，但在整合蛋白质结构信息方面仍有进一步探索的潜力。我们认为蛋白质的结构信息不仅限于其3D信息，还包括来自氨基酸分子（局部信息）到蛋白质-蛋白质结构相似性（全局信息）的信息。为了解决这个问题，我们提出了**GLProtein**，这是蛋白质预训练中第一个结合了全局结构相似性和局部氨基酸细节以提高预测准确性和功能洞察力的框架。GLProtein创新性地将蛋白质掩码建模与三重态结构相似性评分、蛋白质3D距离编码和基于子结构的氨基酸分子编码相结合。实验结果表明，GLProtein在多项生物信息学任务中优于现有方法，包括预测蛋白质-蛋白质相互作用、接触预测等。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [89] [dLLM-Cache: Accelerating Diffusion Large Language Models with Adaptive Caching](https://arxiv.org/abs/2506.06295)
> *dLLM-Cache: 通过自适应缓存加速扩散大型语言模型*

*Zhiyuan Liu, Yicun Yang, Yaojie Zhang, Junjie Chen, Chang Zou, Qingyuan Wei, Shaobo Wang, Linfeng Zhang* | **Main category: cs.LG**

**Keywords:** dLLM-Cache, 扩散大型语言模型, 自适应缓存, 推理延迟, 加速

**Comment:** 

> **TL;DR:** dLLM-Cache是一种无需训练的自适应缓存框架，通过结合长间隔提示缓存和基于特征相似度的部分响应更新，将扩散大型语言模型（dLLM）的推理速度提高了9.1倍，使其延迟接近自回归模型。

**AI_Comments:** dLLM-Cache的创新之处在于其针对dLLM双向注意力机制的特性，提出了一种不同于传统ARM缓存策略的自适应缓存方法。该方法通过识别推理过程中的静态和动态部分，并结合特征相似度进行智能更新，实现了显著的性能提升。其无需训练的特性也降低了部署的复杂性。该研究对于推动dLLM在实际应用中的普及具有重要意义，因为它有效解决了dLLM面临的主要性能瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 扩散大型语言模型（dLLMs）尽管具有显著优势和潜力，但其推理延迟较高。传统的自回归模型（ARMs）加速技术（如键值缓存）由于dLLMs的双向注意力机制而无法兼容。

**Method:** 基于dLLM推理中静态提示和部分动态响应的观察，提出了dLLM-Cache。这是一种无需训练的自适应缓存框架，它结合了长间隔提示缓存和由特征相似度引导的部分响应更新，以高效地重用中间计算。

**Result:** 在LLaDA 8B和Dream 7B等代表性dLLMs上进行的大量实验表明，dLLM-Cache在不影响输出质量的情况下，比标准推理实现了高达9.1倍的加速。值得注意的是，在许多设置下，该方法使dLLM的推理延迟接近ARMs。

**Conclusion:** dLLM-Cache框架有效地解决了扩散大型语言模型的推理延迟问题，通过自适应缓存显著提高了推理速度，使其性能与自回归模型相媲美。

> **ai_Abstract:** 本文提出了一种名为dLLM-Cache的无需训练的自适应缓存框架，旨在解决扩散大型语言模型（dLLMs）高推理延迟的问题。研究发现，dLLM推理涉及静态提示和部分动态响应，其中大部分令牌在相邻去噪步骤中保持稳定。基于此，dLLM-Cache通过结合长间隔提示缓存和由特征相似度引导的部分响应更新，实现了中间计算的高效重用。实验结果表明，dLLM-Cache在LLaDA 8B和Dream 7B等模型上实现了高达9.1倍的加速，且不影响输出质量，使dLLM的推理延迟接近自回归模型。

> **摘要翻译:** 自回归模型（ARMs）长期以来主导着大型语言模型的格局。最近，一种新的范式以扩散大型语言模型（dLLMs）的形式出现，它通过迭代去噪掩码片段来生成文本。这种方法显示出显著的优势和潜力。然而，dLLMs面临高推理延迟的问题。传统的ARM加速技术，如键值缓存，由于其双向注意力机制，与dLLMs不兼容。为了解决这一特定挑战，我们的工作从一个关键观察开始：dLLM推理涉及静态提示和部分动态响应，其中大多数令牌在相邻去噪步骤中保持稳定。基于此，我们提出了dLLM-Cache，一个无需训练的自适应缓存框架，它结合了长间隔提示缓存和由特征相似度引导的部分响应更新。这种设计能够在不影响模型性能的情况下高效地重用中间计算。在LLaDA 8B和Dream 7B等代表性dLLMs上进行的大量实验表明，dLLM-Cache比标准推理实现了高达9.1倍的加速，且不影响输出质量。值得注意的是，我们的方法在许多设置下使dLLM的推理延迟接近ARMs。代码已在补充材料中提供，并将公开发布在GitHub上。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [92] [Beyond the Norm: A Survey of Synthetic Data Generation for Rare Events](https://arxiv.org/abs/2506.06380)
> *超越常规：稀有事件合成数据生成综述*

*Jingyi Gu, Xuan Zhang, Guiling Wang* | **Main category: cs.LG**

**Keywords:** 合成数据生成, 稀有事件, 极端事件, 生成建模, 重尾分布

**Comment:** 

> **TL;DR:** 本综述针对极端事件的数据稀缺问题，系统回顾了稀有事件合成数据生成方法，包括生成模型和大型语言模型，并提出了一个定制的评估框架，旨在推动该领域的研究。

**AI_Comments:** 本论文具有高度相关性，因为它解决了极端事件建模中数据稀缺的关键问题。其创新之处在于作为首个专门针对极端事件合成数据生成的综述，填补了现有文献的空白。论文提出的定制评估框架和对重尾分布指标适用性的深入分析对于实际应用具有重要价值。通过识别未充分探索的领域和开放性挑战，它也为未来的研究提供了明确的方向。

<details>
  <summary>Details</summary>

**Motivation:** 极端事件（如市场崩盘、自然灾害、流行病）虽然罕见但具灾难性，准确预测和预警至关重要。数据驱动方法需要大量训练数据，但极端事件数据本身稀缺，现有合成数据综述未针对极端事件的独特性能要求。

**Method:** 本综述系统回顾了生成建模技术和大型语言模型，特别是那些通过统计理论以及专门训练和采样机制增强以捕获重尾分布的模型。总结了基准数据集，并引入了一个涵盖统计、依赖性、视觉和面向任务指标的定制评估框架。深入分析了每个指标在极端性中的适用性及特定领域的适应性。对关键应用领域进行了分类，并识别了未充分探索的领域。最后，概述了开放性挑战。

**Result:** 本综述首次全面概述了极端事件的合成数据生成。总结了基准数据集，并提出了一个定制的评估框架。深入分析了评估指标在极端情况下的适用性。对关键应用领域进行了分类，并识别了行为金融学、野火、地震、风暴和传染病爆发等未充分探索的领域。概述了开放性挑战。

**Conclusion:** 本综述为推进合成稀有事件研究奠定了结构化基础。

> **ai_Abstract:** 本综述旨在解决稀有灾难性极端事件建模中数据稀缺的挑战。它全面回顾了针对极端事件的合成数据生成技术，涵盖了生成模型和大型语言模型，特别关注捕获重尾分布的方法。论文引入了一个新的定制评估框架，并深入分析了评估指标的适用性，为极端环境下的模型评估提供了指导。此外，它还对关键应用领域进行了分类，识别了未充分探索的领域，并概述了开放性挑战，为稀有事件合成数据研究提供了结构化基础。

> **摘要翻译:** 极端事件，如市场崩盘、自然灾害和流行病，虽然罕见但具有灾难性，常常引发互联系统中的连锁故障。准确预测和早期预警有助于最大限度地减少损失并提高准备程度。尽管数据驱动方法为极端事件建模提供了强大的能力，但它们需要大量训练数据，然而极端事件数据本身稀缺，这构成了一个根本性挑战。合成数据生成已成为一个强大的解决方案。然而，现有综述侧重于具有隐私保护通用数据，而非极端事件独特的性能要求。本综述首次全面概述了极端事件的合成数据生成。我们系统地回顾了生成建模技术和大型语言模型，特别是那些通过统计理论以及专门的训练和采样机制增强以捕获重尾分布的模型。我们总结了基准数据集，并引入了一个量身定制的评估框架，涵盖统计、依赖性、视觉和面向任务的指标。一个核心贡献是我们深入分析了每个指标在极端性中的适用性以及特定领域的适应性，为极端情况下的模型评估提供了可操作的指导。我们对关键应用领域进行了分类，并识别了未充分探索的领域，如行为金融学、野火、地震、风暴和传染病爆发。最后，我们概述了开放性挑战，为推进合成稀有事件研究奠定了结构化基础。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [102] [Dynamic Graph CNN with Jacobi Kolmogorov-Arnold Networks for 3D Classification of Point Sets](https://arxiv.org/abs/2506.06296)
> *结合Jacobi Kolmogorov-Arnold网络的动态图CNN用于三维点集分类*

*Hanaa El Afia, Said Ohamouddou, Raddouane Chiheb, Abdellatif El Afia* | **Main category: cs.LG**

**Keywords:** 动态图CNN, Jacobi KAN, 点云分类, ModelNet40, 多项式展开

**Comment:** 

> **TL;DR:** 本文提出了Jacobi-KAN-DGCNN框架，将DGCNN与Jacobi KAN结合，通过替换MLP层为可变单变量多项式展开，在ModelNet40数据集上实现了三维点云分类性能的提升，并在准确性和收敛速度上优于传统DGCNN基线，同时保持参数效率。

**AI_Comments:** 该论文的创新点在于将新颖的Jacobi Kolmogorov-Arnold网络（KAN）与经典的动态图卷积神经网络（DGCNN）相结合，通过替换MLP层为多项式展开，为三维点云分类提供了一种新的方法。这种方法在准确性和收敛速度上的提升，以及参数效率的保持，显示了其潜在的应用价值。然而，论文也指出了一个重要的局限性，即多项式次数与性能之间并非简单的正相关关系，这为未来的理论和实证研究留下了广阔的空间，需要进一步探究多项式基、次数与图学习机制的复杂相互作用。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升三维点云分类的性能，本文旨在将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）结合，通过替换DGCNN中的多层感知机（MLP）层为可适应的单变量多项式展开，以期在准确性和收敛速度上超越传统方法。

**Method:** 本文提出了Jacobi-KAN-DGCNN框架，该框架将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）集成。具体方法是，在简化的DGCNN架构中，用可适应的单变量多项式展开替换多层感知机（MLP）层，避免了MLP和KAN的深层结构，以便于逐层比较。

**Result:** 在ModelNet40数据集上的对比实验表明，采用Jacobi多项式的KAN层在准确性和收敛速度方面均优于传统的基于线性层的DGCNN基线，同时保持了参数效率。结果还显示，更高的多项式次数并不能自动提高性能。

**Conclusion:** Jacobi-KAN-DGCNN方法在三维点云分类中展现了潜力，但在准确性和收敛速度上超越了传统DGCNN。然而，更高多项式次数并非总能带来性能提升，这表明需要进一步的理论和实证研究来充分理解多项式基、次数以及基于图学习机制之间的相互作用。

> **ai_Abstract:** 本文提出了Jacobi-KAN-DGCNN，一个结合动态图卷积神经网络（DGCNN）和Jacobi Kolmogorov-Arnold网络（KAN）用于三维点云分类的新框架。该方法用可适应的单变量多项式展开替换了DGCNN中的MLP层。实验结果表明，在ModelNet40数据集上，Jacobi KAN层在准确性和收敛速度上优于传统DGCNN，同时保持了参数效率。研究还发现，并非所有更高的多项式次数都能自动提升性能，这指出了未来研究需深入探索多项式基、次数与图学习机制的相互作用。

> **摘要翻译:** 我们引入了Jacobi-KAN-DGCNN，这是一个将动态图卷积神经网络（DGCNN）与Jacobi Kolmogorov-Arnold网络（KAN）集成用于三维点云分类的框架。该方法在简化的DGCNN架构中，用可适应的单变量多项式展开替换了多层感知机（MLP）层，避免了MLP和KAN的深层结构，以便于逐层比较。在ModelNet40数据集上的对比实验中，采用Jacobi多项式的KAN层在准确性和收敛速度方面均优于传统的基于线性层的DGCNN基线，同时保持了参数效率。我们的结果表明，更高的多项式次数并不能自动提高性能，这凸显了需要进一步的理论和实证研究，以充分理解多项式基、次数以及基于图学习机制之间的相互作用。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [105] [Hierarchical and Collaborative LLM-Based Control for Multi-UAV Motion and Communication in Integrated Terrestrial and Non-Terrestrial Networks](https://arxiv.org/abs/2506.06532)
> *综合天地一体化网络中多无人机运动与通信的分层协作式LLM控制*

*Zijiang Yan, Hao Zhou, Jianhua Pei, Hina Tabassum* | **Main category: cs.LG**

**Keywords:** 多无人机控制, 大语言模型, 天地一体化网络, 运动规划, 通信控制

**Comment:** Accepted in ICML 2025 Workshop on Machine Learning for Wireless
  Communication and Networks (ML4Wireless)

> **TL;DR:** 该研究提出了一种基于LLM的分层协作方法，用于综合天地一体化网络中多无人机的运动和通信控制，并在空中高速公路场景中取得了显著效果。

**AI_Comments:** 这篇论文的创新点在于将大语言模型引入到多无人机系统的分层控制中，利用LLM的知识驱动能力来处理复杂的运动和通信协同问题。这种将高层战略规划和低层战术决策相结合的思路，为未来3D空中高速公路系统的发展提供了新的范式，具有重要的研究价值和应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 多无人机系统的控制和优化，尤其是在动态和受限环境中，仍然是一个重大挑战。

**Method:** 提出了一种新颖的基于大语言模型（LLM）的分层协作方法。一个LLM部署在高空平台站（HAPS）上执行无人机接入控制，而另一个LLM部署在每架无人机上处理运动规划和控制。

**Result:** 实验结果表明，所提出的协作式LLM方法与基线方法相比，实现了更高的系统奖励、更低的操作成本和显著降低的无人机碰撞率。

**Conclusion:** 这种知识驱动的范式对于开发下一代3D空中高速公路系统具有巨大潜力。

> **ai_Abstract:** 本文针对综合天地一体化网络中多无人机在动态受限环境下的运动与通信控制挑战，提出了一种新颖的分层协作式LLM（大语言模型）控制框架。该框架将LLM分别部署在高空平台站（HAPS）和每架无人机上，分别负责高层接入控制和低层运动规划。实验结果表明，该方法在空中高速公路场景中能有效提高系统奖励、降低运营成本并显著减少无人机碰撞。

> **摘要翻译:** 无人机（UAV）已广泛应用于各种实际场景。然而，多无人机系统的控制和优化仍然是一个重大挑战，特别是在动态和受限环境中。这项工作探索了在包含高空平台站（HAPS）的综合天地一体化网络中运行的多无人机的联合运动和通信控制。具体而言，我们考虑了一个空中高速公路场景，其中无人机必须加速、减速和变道以避免碰撞并保持整体交通流量。与现有研究不同，我们提出了一种新颖的基于大语言模型（LLM）的分层协作方法。在我们的方法中，部署在HAPS上的LLM执行无人机接入控制，而部署在每架无人机上的另一个LLM处理运动规划和控制。这种基于LLM的框架利用预训练模型中嵌入的丰富知识，以实现高层战略规划和低层战术决策。这种知识驱动的范式对于开发下一代3D空中高速公路系统具有巨大潜力。实验结果表明，我们提出的协作式LLM方法与基线方法相比，实现了更高的系统奖励、更低的操作成本和显著降低的无人机碰撞率。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [106] [End-to-End Probabilistic Framework for Learning with Hard Constraints](https://arxiv.org/abs/2506.07003)
> *错误：AI分析失败。*

*Utkarsh Utkarsh, Danielle C. Maddix, Ruijun Ma, Michael W. Mahoney, Yuyang Wang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 46 pages, 5 figures, 10 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [115] [Optimal patient allocation for echocardiographic assessments](https://arxiv.org/abs/2506.06297)
> *超声心动图评估患者优化分配*

*Bozhi Sun, Seda Tierney, Jeffrey A. Feinstein, Frederick Damen, Alison L. Marsden, Daniele E. Schiavazzi* | **Main category: cs.LG**

**Keywords:** 超声心动图, 患者分配, 离散事件仿真, 强化学习, 资源管理

**Comment:** 

> **TL;DR:** 医院超声心动图预约挑战大，本文通过仿真和强化学习优化患者动态分配，发现即时分配通常表现更好，RL可提高效率。

**AI_Comments:** 这篇论文通过结合离散事件随机仿真和强化学习，为解决医院资源分配的复杂问题提供了一个数据驱动的创新方法。其亮点在于利用真实世界数据进行预处理，并对比了不同分配策略的有效性，特别是证明了即时分配在特定场景下的优势。强化学习的应用进一步提升了解决方案的优化潜力，为医院超声实验室等医疗机构的效率提升提供了可行的智能管理策略。

<details>
  <summary>Details</summary>

**Motivation:** 医院超声心动图检查安排面临显著挑战，原因是非确定性因素（如患者未到、到达时间、检查时长不同等）以及胎儿和非胎儿患者流之间不对称的资源限制。

**Method:** 首先对斯坦福大学露西尔·帕卡德儿童医院超声实验室一周的运营数据进行预处理，估算患者未到概率并推导到达时间和检查时长的经验分布。然后，使用SimPy开发了一个离散事件随机仿真模型，并将其与开源Gymnasium Python库集成。作为策略优化的基准，开发了一个比较框架来评估即时分配和基于预约的分配策略。在此基础上，应用强化学习（RL）推导近似最优的动态分配策略，并与表现最佳的基于规则的策略进行基准测试。

**Result:** 在考虑胎儿与非胎儿房间比例为1:6、超声技师比例为4:2的医院配置下，研究表明即时分配通常表现更好，能更有效地适应患者变异性和资源限制。基于强化学习的策略与表现最佳的基于规则的策略进行基准测试，量化了它们的差异，并为通过智能、数据驱动的资源管理提高超声实验室效率提供了可操作的见解。

**Conclusion:** 本文为通过智能、数据驱动的资源管理提高超声实验室效率提供了可操作的见解，并成功推导出近似最优的动态分配策略。

> **ai_Abstract:** 本文针对医院超声心动图检查预约面临的非确定性因素和资源限制挑战，利用斯坦福大学儿童医院的运营数据进行预处理，估算患者未到概率和检查时长分布。研究团队构建了一个基于SimPy的离散事件随机仿真模型，并结合Gymnasium库，比较了即时分配和预约分配策略。结果显示，即时分配在适应患者变异性和资源限制方面通常表现更优。在此基础上，论文进一步应用强化学习（RL）推导出近似最优的动态分配策略，并与现有最佳规则策略进行基准测试，旨在通过智能数据驱动的资源管理提升超声实验室效率。

> **摘要翻译:** 在医院安排超声心动图检查面临重大挑战，原因是非确定性因素（例如，患者未到、患者到达时间、不同的检查时长等）以及胎儿和非胎儿患者流之间不对称的资源限制。为了解决这些挑战，我们首先对斯坦福大学露西尔·帕卡德儿童医院超声实验室一周的运营数据进行了广泛的预处理，以估算患者未到概率并推导到达时间和检查时长的经验分布。基于这些输入，我们使用SimPy开发了一个离散事件随机仿真模型，并将其与开源Gymnasium Python库集成。作为策略优化的基准，我们开发了一个比较框架来评估即时分配和基于预约的分配策略，其中不同比例的资源被提前预留。考虑到胎儿与非胎儿房间比例为1:6、胎儿与非胎儿超声技师比例为4:2的医院配置，我们表明即时分配通常能产生更好的性能，更有效地适应患者变异性和资源限制。在此基础上，我们应用强化学习（RL）来推导近似最优的动态分配策略。这种基于RL的策略与表现最佳的基于规则的策略进行基准测试，使我们能够量化它们的差异，并为通过智能、数据驱动的资源管理提高超声实验室效率提供可操作的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [117] [Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques](https://arxiv.org/abs/2506.06579)
> *迈向高效多大型语言模型推理：大型语言模型路由与分层技术的特征描述与分析*

*Adarsh Prasad Behera, Jaya Prakash Champati, Roberto Morabito, Sasu Tarkoma, James Gross* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 推理效率, 模型路由, 分层推理, 计算优化

**Comment:** 

> **TL;DR:** 本综述探讨了两种提高大型语言模型推理效率的策略：路由和分层推理，旨在通过动态模型选择来降低计算成本。

**AI_Comments:** 这篇综述性文章对多LLM推理的效率问题进行了深入探讨，提出了路由和分层推理这两种重要的优化策略。其创新性在于系统性地比较了这些方法，并指出了未来的研究方向，对于推动LLM在资源受限环境中的实际部署具有重要意义。文章关注的是一个当前非常热门且具有挑战性的领域，即如何在保持LLM强大能力的同时降低其运行成本和能耗。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的推理计算成本高昂且能耗大，尤其在硬件、功耗或带宽受限的环境中部署困难，限制了其在移动、边缘或成本敏感场景的应用。

**Method:** 本综述探讨了两种互补的LLM高效推理策略：(i) 路由，根据查询选择最合适的模型；(ii) 级联或分层推理（HI），通过模型序列逐步处理查询直至找到可靠响应。两种方法都旨在通过优先使用轻量级模型来减少计算。

**Result:** 本综述对这些技术进行了关键性能指标的比较分析，讨论了基准测试工作，并概述了开放挑战。

**Conclusion:** 未来的研究方向包括实现更快的响应时间、基于任务复杂性的自适应模型选择以及在异构环境中的可扩展部署，从而使基于LLM的系统在实际应用中更高效和易于访问。

> **ai_Abstract:** 本综述针对大型语言模型（LLMs）推理成本高昂的问题，探讨了两种提高效率的策略：路由和分层推理。这些方法通过动态选择模型（对简单查询使用轻量级模型，对复杂查询升级到大型模型）来优化资源分配并降低计算开销。论文对这些技术进行了比较分析，讨论了基准测试，并指出了未来的研究方向，旨在使LLM系统在实际应用中更高效、更易于访问，尤其是在资源受限的环境中。

> **摘要翻译:** 语言模型（LMs）的最新进展极大地推动了自然语言处理（NLP）领域的发展，在文本生成、摘要和问答等任务中表现出色。然而，它们的推理仍然计算成本高昂且能耗大，尤其是在硬件、功耗或带宽受限的环境中。这使得在移动、边缘或成本敏感环境中部署LMs变得困难。为了应对这些挑战，最近的方法引入了多LLM智能模型选择策略，根据查询复杂性动态分配计算资源——对简单查询使用轻量级模型，仅在必要时才升级到更大的模型。本综述探讨了两种互补的高效LLM推理策略：(i) 路由，根据查询选择最合适的模型；(ii) 级联或分层推理（HI），通过模型序列逐步处理查询，直到找到可靠的响应。这两种方法都旨在通过对简单任务使用轻量级模型，仅在需要时才进行卸载，从而减少计算。我们对这些技术在关键性能指标上进行了比较分析，讨论了基准测试工作，并概述了开放挑战。最后，我们概述了未来的研究方向，以实现更快的响应时间、基于任务复杂性的自适应模型选择以及在异构环境中的可扩展部署，从而使基于LLM的系统在实际应用中更高效和易于访问。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [119] [ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning](https://arxiv.org/abs/2506.07551)
> *ChemAgent：通过基于树搜索的工具学习增强化学和材料科学领域的大语言模型*

*Mengsong Wu, YaFei Wang, Yidong Ming, Yuqi An, Yuwei Wan, Wenliang Chen, Binbin Lin, Yuqiang Li, Tong Xie, Dongzhan Zhou* | **Main category: cs.LG**

**Keywords:** 化学大语言模型, 工具学习, 蒙特卡洛树搜索, 化学信息学, ChemAgent

**Comment:** 15 pages, 6 figures

> **TL;DR:** ChemAgent通过集成137个化学工具和分层进化蒙特卡洛树搜索（HE-MCTS）显著提升了LLM在化学任务中的表现，甚至超越了GPT-4o。

**AI_Comments:** 该论文的创新点在于其系统地集成了大量的化学专业工具（137个），并设计了HE-MCTS框架以优化工具的规划和执行，这大大增强了LLM在特定领域（化学）的专业能力。通过自生成数据进行步级微调，并声称超越GPT-4o，显示了其在解决特定领域知识瓶颈方面的潜力。这种将LLM与外部专业工具深度结合的范式，为未来其他专业领域LLM的发展提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在化学任务中面临预训练知识过时和难以整合专业化学知识的挑战。

**Method:** 提出ChemAgent，一个基于LLM的智能体，协同整合137个外部化学工具；创建数据集ChemToolBench以促进工具选择和参数填充；引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，能够独立优化工具规划和执行；利用自生成数据支持策略模型的步级微调以及任务自适应PRM和ORM的训练。

**Result:** 实验评估表明，该方法显著提高了在化学问答和发现任务中的性能，并且训练的任务自适应PRM和ORM超越了GPT-4o。

**Conclusion:** ChemAgent提供了一个强大的解决方案，将专业工具与大语言模型相结合，以实现先进的化学应用。

> **ai_Abstract:** 本文提出了ChemAgent，一个基于LLM的智能体，旨在解决当前LLM在化学领域面临的知识过时和专业知识整合难题。ChemAgent通过集成137个化学工具和一个名为ChemToolBench的数据集，并引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，实现了对工具规划和执行的独立优化。该方法利用自生成数据进行步级微调，并训练出性能超越GPT-4o的任务自适应模型。实验证明，ChemAgent显著提升了LLM在化学问答和发现任务中的表现，为化学领域的高级应用提供了有效的工具集成方案。

> **摘要翻译:** 大型语言模型（LLMs）最近在化学任务中展现出有前景的能力，但仍面临预训练知识过时以及难以整合专业化学知识的挑战。为了解决这些问题，我们提出了一种基于LLM的智能体——ChemAgent，它协同整合了137个外部化学工具，这些工具涵盖从基本信息检索到复杂反应预测的范围；并建立了一个数据集整理流程，以生成ChemToolBench数据集，该数据集有助于在微调和评估过程中进行有效的工具选择和精确的参数填充。我们引入了一种分层进化蒙特卡洛树搜索（HE-MCTS）框架，能够独立优化工具规划和执行。通过利用自生成数据，我们的方法支持策略模型的步级微调（FT），并训练出超越GPT-4o的任务自适应PRM和ORM。实验评估表明，我们的方法显著提高了在化学问答和发现任务中的性能，为将专业工具与LLM集成以实现高级化学应用提供了强大的解决方案。所有数据集和代码均可在https://github.com/AI4Chem/ChemistryAgent 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [129] [Pairwise Calibrated Rewards for Pluralistic Alignment](https://arxiv.org/abs/2506.06298)
> *用于多元对齐的成对校准奖励*

*Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira* | **Main category: cs.LG**

**Keywords:** 成对校准, 多元对齐, 奖励函数, 人类偏好, 偏好分布

**Comment:** 

> **TL;DR:** 当前对齐方法忽略人类偏好多样性，本文提出通过学习奖励函数分布来反映多元偏好，并引入成对校准准则以更忠实地表示多元价值观。

**AI_Comments:** 该论文创新性地提出通过学习奖励函数分布来解决AI对齐中人类偏好多样性问题，并通过“成对校准”准则和将分歧视为软标签的方式，有效地捕捉和表示了多元价值观，对实现更具包容性的AI对齐具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前的对齐流程假设单一的理想行为概念，但人类偏好存在多样性，导致少数观点被忽视。

**Method:** 本文提出通过学习多个奖励函数上的分布来反映多样化的人类偏好，每个奖励函数对应一个对齐策略。该分布直接从成对偏好中学习，不依赖标注者身份或预定义群体，将标注者分歧视为信息性软标签。核心准则是成对校准：对于每对候选响应，偏好其中一个响应的奖励函数比例与持有该偏好的标注者比例相匹配。

**Result:** 理论上证明了即使是小型无异常值集合也能准确表示多样化偏好分布。经验上，引入并验证了一种学习此类集合的实用训练启发式方法，并通过改进的校准效果证明了其有效性，这意味着更忠实地表示了多元价值观。

**Conclusion:** 本文提出了一种通过成对校准奖励来反映多样化人类偏好的方法，并通过实验证明其能够更忠实地表示多元价值观。

> **ai_Abstract:** 本文针对当前AI对齐方法忽视人类偏好多样性的问题，提出了一种新颖的“成对校准奖励”框架。该方法通过学习多个奖励函数上的分布来反映多元偏好，并利用成对偏好数据和标注者分歧作为软标签。核心思想是确保奖励函数对响应的偏好比例与标注者的实际偏好比例相匹配（成对校准）。理论和实践证明，该方法能有效捕捉和表示多元价值观，从而实现更忠实的AI对齐。

> **摘要翻译:** 当前的对齐流程假定单一、普遍的理想行为概念。然而，人类偏好常常因用户、情境和文化而异。结果是，分歧会坍缩为多数信号，少数观点被忽视。为解决此问题，我们提出通过多个奖励函数上的分布来反映多样化的人类偏好，每个奖励函数都会引出一个不同的对齐策略。该分布直接从成对偏好中学习，不依赖标注者身份或预定义群体。相反，标注者之间的分歧被视为信息性的软标签。我们的核心准则是成对校准：对于每对候选响应，偏好其中一个响应的奖励函数比例与持有该偏好的标注者比例相匹配。我们证明，即使是一个小的、无异常值的集合也能准确地表示多样化的偏好分布。在经验上，我们引入并验证了一种学习此类集合的实用训练启发式方法，并通过改进的校准效果证明了其有效性，这意味着更忠实地表示了多元价值观。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [131] [SALT: A Lightweight Model Adaptation Method for Closed Split Computing Environments](https://arxiv.org/abs/2506.07355)
> *SALT：一种闭环分体式计算环境下的轻量级模型自适应方法*

*Yuya Okada, Takayuki Nishio* | **Main category: cs.LG**

**Keywords:** 分体式计算, 模型自适应, 轻量级, 边缘AI, 闭环环境

**Comment:** 6 pages, submitted to IEEE Globecom 2025 (under review)

> **TL;DR:** SALT提出了一种在闭环分体式计算环境中进行轻量级模型自适应的方法，通过客户端适配器实现个性化推理，无需访问原始模型。

**AI_Comments:** SALT的创新之处在于其在“闭环分体式计算环境”这一特殊且受限的场景下实现了模型自适应。通过在客户端引入一个轻量级的适配器，它巧妙地规避了访问专有模型参数的难题，同时保持了低通信开销和部署成本，这对于边缘AI和隐私保护场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在闭环分体式计算环境中，头部和尾部网络是专有的且用户无法访问，导致传统模型自适应方法因需要访问模型参数或架构而不可行。

**Method:** SALT通过在客户端引入一个紧凑、可训练的适配器来细化来自头部网络的潜在特征，从而实现用户特定的自适应，而无需修改原始模型或增加通信开销。

**Result:** 在CIFAR-10和CIFAR-100上的用户特定分类任务中，SALT与微调方法相比，提高了准确性并降低了训练延迟。此外，SALT有助于在损耗网络上实现鲁棒推理的模型自适应。

**Conclusion:** SALT以最小的部署开销，为严格系统约束下的边缘AI系统中的个性化推理提供了一种实用解决方案。

> **ai_Abstract:** 本文提出了SALT（Split-Adaptive Lightweight Tuning），一种针对闭环分体式计算环境设计的轻量级模型自适应框架。鉴于传统方法无法在专有网络环境下工作，SALT在客户端引入了一个紧凑、可训练的适配器，用于优化头部网络的潜在特征，从而实现无需修改原始模型或增加通信开销的用户特定自适应。实验证明，SALT在用户分类任务上提高了准确性并缩短了训练延迟，并能促进损耗网络上的鲁棒推理，为边缘AI系统中的个性化推理提供了实用方案。

> **摘要翻译:** 我们提出了SALT（Split-Adaptive Lightweight Tuning），一种用于闭环约束下分体式计算的轻量级模型自适应框架，在这种环境下，头部和尾部网络是专有的且用户无法访问。在这样的闭环环境中，传统的自适应方法不可行，因为它们需要访问模型参数或架构。SALT通过在客户端引入一个紧凑、可训练的适配器来解决这一挑战，该适配器用于细化来自头部网络的潜在特征，从而实现用户特定的自适应，而无需修改原始模型或增加通信开销。我们在CIFAR-10和CIFAR-100上的用户特定分类任务中评估了SALT，结果表明与微调方法相比，它提高了准确性并降低了训练延迟。此外，SALT有助于在损耗网络上实现鲁棒推理的模型自适应，这是边缘-云环境中常见的挑战。以最小的部署开销，SALT为严格系统约束下的边缘AI系统中的个性化推理提供了一种实用解决方案。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [142] [LT-PINN: Lagrangian Topology-conscious Physics-informed Neural Network for Boundary-focused Engineering Optimization](https://arxiv.org/abs/2506.06300)
> *LT-PINN：用于边界聚焦工程优化的拉格朗日拓扑感知物理信息神经网络*

*Yuanye Zhou, Zhaokun Wang, Kai Zhou, Hui Tang, Xiaofan Li* | **Main category: cs.LG**

**Keywords:** 物理信息神经网络, 拓扑优化, 边界参数化, 拉格朗日方法, 工程优化

**Comment:** 

> **TL;DR:** LT-PINN是一种新型物理信息神经网络，通过参数化拓扑边界曲线并引入专门的损失函数，解决了传统PINN在拓扑优化中需要手动插值和处理复杂几何体的局限性，实现了更精确的边界确定和显著的误差降低。

**AI_Comments:** LT-PINN的创新之处在于其拉格朗日拓扑感知方法，通过直接参数化边界曲线并引入专门的损失函数，显著提升了PINN在拓扑优化中的性能。它克服了传统PINN在处理复杂几何和需要手动插值方面的局限性，使其在工程优化领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的物理信息神经网络（PINNs）在拓扑优化中依赖于基于密度的拓扑描述，这需要手动插值并限制了它们在复杂几何体上的适用性。

**Method:** 本文提出了拉格朗日拓扑感知物理信息神经网络（LT-PINNs）。该方法通过将拓扑边界曲线的控制变量参数化为可学习参数，从而消除了手动插值的需要，并实现了精确的边界确定。此外，引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。

**Result:** 1. LT-PINNs与最先进的密度拓扑导向PINNs（DT-PINNs）相比，相对L2误差显著降低。
2. LT-PINNs可以处理任意边界条件，适用于各种偏微分方程（PDEs）。
3. LT-PINNs无需手动插值即可推断出清晰的拓扑边界，尤其适用于复杂拓扑。

**Conclusion:** LT-PINN通过其创新的边界参数化和专门的损失函数，克服了传统PINN在拓扑优化中的局限性，在处理复杂几何和任意边界条件方面表现出更高的准确性、鲁棒性和工程应用潜力。

> **ai_Abstract:** 本文提出了一种名为拉格朗日拓扑感知物理信息神经网络（LT-PINN）的新型框架，用于边界聚焦工程优化。LT-PINN通过将拓扑边界曲线的控制变量参数化为可学习参数，消除了传统PINN在拓扑优化中对手动插值的需求，并实现了精确的边界确定。该方法引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。通过对弹性方程和拉普拉斯方程等不同偏微分方程的验证，以及在复杂流问题中的应用，结果表明LT-PINN相对于现有方法显著降低了L2误差，能够处理任意边界条件，并能清晰地推断出复杂拓扑的边界。

> **摘要翻译:** 物理信息神经网络（PINNs）已成为拓扑优化中强大的无网格工具，能够同时确定最佳拓扑和物理解。然而，传统的PINNs依赖于基于密度的拓扑描述，这需要手动插值并限制了它们在复杂几何体上的适用性。为了解决这个问题，我们提出了拉格朗日拓扑感知PINNs（LT-PINNs），这是一种用于边界聚焦工程优化的新型框架。通过将拓扑边界曲线的控制变量参数化为可学习参数，LT-PINNs消除了手动插值的需要，并实现了精确的边界确定。我们进一步引入了专门的边界条件损失函数和拓扑损失函数，以确保即使对于复杂的拓扑也能获得清晰准确的边界表示。LT-PINNs的准确性和鲁棒性通过两种类型的偏微分方程（PDEs）进行了验证，包括带有Dirichlet边界条件的弹性方程和带有Neumann边界条件的拉普拉斯方程。此外，我们证明了LT-PINNs在更复杂的瞬态和稳态流问题上的有效性，无需依赖测量数据，并展示了它们在流速重排中的工程应用潜力，将均匀的上游速度转换为正弦形下游剖面。结果表明：（1）与最先进的密度拓扑导向PINNs（DT-PINNs）相比，LT-PINNs在相对L2误差方面取得了显著降低；（2）LT-PINNs可以处理任意边界条件，使其适用于各种PDEs；（3）LT-PINNs无需手动插值即可推断出清晰的拓扑边界，尤其适用于复杂拓扑。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [144] [FedCGD: Collective Gradient Divergence Optimized Scheduling for Wireless Federated Learning](https://arxiv.org/abs/2506.07581)
> *FedCGD：无线联邦学习中集体梯度散度优化调度*

*Tan Chen, Jintao Yan, Yuxuan Sun, Sheng Zhou, Zhisheng Niu* | **Main category: cs.LG**

**Keywords:** 联邦学习, 集体梯度散度, 设备调度, 数据异构性, 无线网络

**Comment:** 

> **TL;DR:** 本文提出了FedCGD算法，通过最小化设备级和样本级集体梯度散度来优化无线联邦学习中的设备调度，从而在提高分类准确性的同时减少设备数量。

**AI_Comments:** 本文的创新点在于引入了“集体梯度散度（CGD）”的概念，并将其分为设备级和样本级进行分析，这与以往关注个体设备异构性的方法不同。通过将设备级CGD转化为加权地球移动距离（WEMD），并提出FedCGD算法来平衡WEMD和采样方差，为无线联邦学习中的设备调度提供了新的优化视角。其在提高准确率和减少设备数量方面的表现，表明了该方法的有效性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在无线网络中应用时面临数据异构性和有限带宽两大问题，现有调度策略大多将数据异构性视为个体设备属性，未能有效解决这些问题。

**Method:** 本文证明了联邦学习的收敛速度受设备级和样本级集体梯度散度（CGD）之和影响。设备级CGD指调度设备组的梯度散度，而非个体设备散度之和。样本级CGD在统计学上受采样方差上限约束，与用于本地更新的总样本数成反比。为推导设备级CGD的可处理形式，本文进一步考虑分类问题并将其转化为组分布与全局分布之间的加权地球移动距离（WEMD）。在此基础上，提出了FedCGD算法，通过平衡WEMD和采样方差来最小化多级CGD之和，且在多项式时间内完成。

**Result:** 仿真结果表明，所提出的策略在CIFAR-10数据集上将分类准确率提高了4.2%，同时调度的设备减少了41.8%，并且可以在减少WEMD和减少采样方差之间灵活切换。

**Conclusion:** FedCGD算法通过优化集体梯度散度，有效解决了无线联邦学习中的数据异构性和带宽限制问题，显著提高了性能并减少了资源消耗。

> **ai_Abstract:** 本文提出了一种名为FedCGD的无线联邦学习调度算法，旨在解决数据异构性和带宽限制问题。该算法核心在于证明联邦学习收敛速度受设备级和样本级集体梯度散度（CGD）之和影响。FedCGD将设备级CGD建模为加权地球移动距离（WEMD），并通过平衡WEMD与采样方差来最小化多级CGD。实验结果显示，FedCGD在提高分类准确率的同时显著减少了所需设备数量。

> **摘要翻译:** 联邦学习（FL）是一种很有前景的多设备协同训练模型范式。当应用于无线网络时，两个问题持续影响FL的性能，即设备的数据异构性和有限带宽。许多论文已经研究了考虑这两个问题的设备调度策略。然而，它们中的大多数将数据异构性视为个体设备的属性。在本文中，我们证明了FL的收敛速度受设备级和样本级集体梯度散度（CGD）之和的影响。设备级CGD指的是调度设备组的梯度散度，而不是个体设备散度之和。样本级CGD在统计学上受采样方差的上限约束，采样方差与用于本地更新的总样本数成反比。为了推导设备级CGD的可处理形式，我们进一步考虑了一个分类问题，并将其转化为组分布与全局分布之间的加权地球移动距离（WEMD）。然后，我们提出了FedCGD算法，通过平衡WEMD和采样方差，在多项式时间内最小化多级CGD之和。仿真结果表明，所提出的策略在CIFAR-10数据集上将分类准确率提高了4.2%，同时调度的设备减少了41.8%，并且可以在减少WEMD和减少采样方差之间灵活切换。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [153] [Reward Is Enough: LLMs Are In-Context Reinforcement Learners](https://arxiv.org/abs/2506.06303)
> *奖励足够：大型语言模型是情境强化学习者*

*Kefan Song, Amir Moeini, Peng Wang, Lei Gong, Rohan Chandra, Yanjun Qi, Shangtong Zhang* | **Main category: cs.LG**

**Keywords:** 情境强化学习, 大型语言模型, 奖励, 推理时间, 多轮提示

**Comment:** 

> **TL;DR:** 本文提出了一种名为情境强化学习（ICRL）的提示框架，发现大型语言模型（LLM）在推理时能够通过接收数值奖励信号来提高任务表现，表现出类似强化学习的行为。

**AI_Comments:** 这项研究的创新之处在于揭示了LLM在推理时表现出的类强化学习行为，并提出了一个实用的多轮提示框架ICRL。其重要性在于，它表明LLM不仅能处理静态信息，还能通过动态反馈进行自我优化，即使反馈是自生成的。这为未来LLM的自我改进和决策能力开辟了新的研究方向，尤其是在无需外部人工标注即可进行在线优化的场景中。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）是解决序列决策问题的框架。本文旨在证明RL现象可以在大型语言模型（LLM）的推理过程中涌现，即情境强化学习（ICRL）。

**Method:** 研究提出了一种新颖的多轮提示框架，称为ICRL提示。该方法在LLM生成响应后，提供数值标量反馈（奖励）。在下一轮中，LLM会再次收到相同的任务，并包含所有先前响应和奖励的上下文。通过这种方式，观察LLM响应质量随上下文增长而提高。

**Result:** ICRL提示在三个基准测试（Game of 24、创意写作和ScienceWorld）中进行了评估，并显示出相对于Self-Refine和Reflexion等基线方法的显著性能改进。令人惊讶的是，即使奖励信号由LLM自身生成，ICRL提示也能观察到性能提升。

**Conclusion:** 大型语言模型在推理时能够最大化标量奖励信号，表现出情境强化学习的能力，这为扩展测试时间计算提供了一个有前景的范式。

> **ai_Abstract:** 本文探讨了大型语言模型（LLM）在推理时涌现的“情境强化学习”（ICRL）现象。研究提出了一种多轮ICRL提示框架，通过在LLM生成响应后提供数值奖励，并将其作为后续轮次的上下文，观察到LLM的任务表现随上下文增长而提高。实验在Game of 24、创意写作和ScienceWorld等基准测试中，ICRL提示显著优于现有基线方法，甚至在LLM自生成奖励的情况下也能实现性能提升，这为LLM的推理能力和测试时间计算提供了新的视角。

> **摘要翻译:** 强化学习（RL）是一种人类设计的用于解决序列决策问题的框架。在这项工作中，我们令人惊讶地证明，RL在大型语言模型（LLM）的推理时间中涌现——这种现象被称为情境强化学习（ICRL）。具体来说，我们提出了一种新颖的多轮提示框架，称为ICRL提示。目标是提示LLM完成一项任务。在LLM在当前轮次生成响应后，我们为该响应提供数值标量反馈，称为奖励。在下一轮次中，我们再次提示LLM相同的任务，并提供包含所有先前响应和奖励的上下文。我们观察到LLM响应的质量随着上下文的增长而提高。换句话说，LLM能够在推理时最大化标量奖励信号，就像一个RL算法一样。我们在三个基准测试（Game of 24、创意写作和ScienceWorld）中评估了ICRL提示，并证明相对于Self-Refine和Reflexion等基线方法有显著的性能改进。令人惊讶的是，在一些实验中，奖励信号是由LLM自身生成的，但ICRL提示仍然观察到性能改进，这为扩展测试时间计算提供了一个有前景的范式。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [162] [InstantFT: An FPGA-Based Runtime Subsecond Fine-tuning of CNN Models](https://arxiv.org/abs/2506.06505)
> *InstantFT: 一种基于FPGA的CNN模型运行时亚秒级微调*

*Keisuke Sugiura, Hiroki Matsutani* | **Main category: cs.LG**

**Keywords:** FPGA, CNN微调, IoT设备, 参数高效微调, 运行时适应

**Comment:** 

> **TL;DR:** InstantFT是一种基于FPGA的方法，可在IoT设备上实现CNN模型的超快速微调，比现有方法快17.4倍，且保持相当的准确性。

**AI_Comments:** 本文的创新点在于提出了基于FPGA的InstantFT，显著加速了IoT设备上CNN模型的运行时微调，解决了传统训练方法在资源受限环境下的挑战。其在速度和能效上的显著提升，对边缘AI和动态数据环境下的模型适应性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限的IoT平台上，深度神经网络（DNNs）的训练需要大量计算和内存，使得DNN的运行时适应性成为挑战。

**Method:** 本文提出InstantFT，一种基于FPGA的方法，通过优化参数高效微调（PEFT）中的前向和后向计算，实现IoT设备上的超快速CNN微调。

**Result:** InstantFT在概念漂移数据集上比现有基于LoRA的方法微调预训练CNN快17.4倍，同时保持相当的准确性。基于FPGA的InstantFT将微调时间缩短至0.36秒，并将能效提高了16.3倍。

**Conclusion:** InstantFT使得CNN模型能够对非平稳数据分布进行即时适应，从而实现运行时模型更新。

> **ai_Abstract:** 本文提出InstantFT，一种基于FPGA的CNN模型微调方法，旨在解决IoT设备上DNNs运行时适应的资源限制问题。通过优化参数高效微调中的计算，InstantFT实现了超快速微调，实验表明其速度比现有LoRA方法快17.4倍，微调时间仅0.36秒，能效提高16.3倍，且保持相当的准确性，从而实现CNN对动态数据分布的即时适应。

> **摘要翻译:** 训练深度神经网络（DNNs）比推理需要显著更多的计算和内存，这使得DNNs在资源受限的IoT平台上进行运行时适应变得具有挑战性。我们提出了InstantFT，一种基于FPGA的方法，通过优化参数高效微调（PEFT）中的前向和后向计算，实现IoT设备上的超快速CNN微调。在具有概念漂移的数据集上进行的实验表明，InstantFT微调预训练CNN的速度比现有的基于低秩适应（LoRA）的方法快17.4倍，同时实现了相当的准确性。我们基于FPGA的InstantFT将微调时间缩短到仅0.36秒，并将能效提高了16.3倍，从而使CNN能够对非平稳数据分布进行即时适应。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [163] [Wine Quality Prediction with Ensemble Trees: A Unified, Leak-Free Comparative Study](https://arxiv.org/abs/2506.06327)
> *使用集成树进行葡萄酒质量预测：一项统一、无泄漏的比较研究*

*Zilang Chen* | **Main category: cs.LG**

**Keywords:** 葡萄酒质量预测, 集成树, 比较研究, 无泄漏, 特征选择

**Comment:** 14pages, 7figures,2tables

> **TL;DR:** 本研究对五种集成学习器在葡萄酒质量预测任务上进行了首次统一、无泄漏的基准测试，发现梯度提升机准确率最高，而随机森林是最具成本效益的生产模型。

**AI_Comments:** 本文通过对多种集成树模型进行全面且无数据泄漏的比较研究，为葡萄酒质量的客观评估提供了坚实的基础。其创新之处在于构建了一个严谨、可复现的基准测试流程，并提供了实际的生产模型选择建议，兼顾了准确性和计算效率。此外，对关键特征的识别也具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 准确且可重现的葡萄酒质量评估对生产控制至关重要，但目前仍主要依赖主观、劳动密集型的品鉴小组。

**Method:** 研究在Vinho Verde红葡萄酒和白葡萄酒数据集上，对随机森林、梯度提升机、XGBoost、LightGBM、CatBoost五种集成学习器进行了统一基准测试。工作流程采用80:20分层训练-测试集划分、训练集内五折分层组K折交叉验证、每折标准化、SMOTE-Tomek重采样、逆频率成本加权、Optuna超参数搜索以及两阶段特征选择再拟合。主要评估指标为加权F1分数。

**Result:** 梯度提升机获得了最高准确率（红葡萄酒加权F1为0.693 +/- 0.028，白葡萄酒为0.664 +/- 0.016），随机森林和XGBoost紧随其后。将模型限制在五个最重要的变量（酒精、挥发性酸度、硫酸盐、游离SO2和氯化物）上，可将维度降低55%，而加权F1仅降低2.6%（红葡萄酒）和3.0%（白葡萄酒）。运行时分析显示，随机森林最快（不到50分钟），梯度提升机最慢（平均12小时）。

**Conclusion:** 研究推荐随机森林作为最具成本效益的生产模型，XGBoost和LightGBM作为GPU高效替代方案，而梯度提升机作为离线基准测试的准确性上限。所提供的完整文档流程和指标集为未来不平衡多类别葡萄酒质量预测工作提供了可复现的基线。

> **ai_Abstract:** 本研究对五种集成学习器（随机森林、梯度提升机、XGBoost、LightGBM、CatBoost）在Vinho Verde葡萄酒数据集上进行了首次统一、无泄漏的葡萄酒质量预测基准测试。通过严谨的工作流程和评估，发现梯度提升机在准确性上表现最佳，而随机森林在效率上更具优势。研究还识别出影响葡萄酒质量的五个关键理化属性，并为未来的葡萄酒质量预测研究提供了可复现的基线和实际应用建议。

> **摘要翻译:** 准确且可重现的葡萄酒质量评估对生产控制至关重要，但目前仍主要依赖主观、劳动密集型的品鉴小组。我们首次对五种集成学习器（随机森林、梯度提升机、XGBoost、LightGBM、CatBoost）在经典的Vinho Verde红葡萄酒和白葡萄酒数据集（分别为1,599和4,898个实例，11个理化属性）上进行了统一的基准测试。我们的无泄漏工作流程采用了80:20分层训练-测试集划分、训练集内五折分层组K折交叉验证、每折标准化、SMOTE-Tomek重采样、逆频率成本加权、Optuna超参数搜索（每个模型120-200次试验）和两阶段特征选择再拟合。在未接触的测试集上报告最终得分，以加权F1作为主要指标。梯度提升机取得了最高准确率（红葡萄酒加权F1为0.693 +/- 0.028，白葡萄酒为0.664 +/- 0.016），随机森林和XGBoost的得分在其三个百分点以内。将每个模型限制在其排名前五的变量上，可将维度降低55%，同时红葡萄酒的加权F1仅降低2.6个百分点，白葡萄酒仅降低3.0个百分点，这表明酒精、挥发性酸度、硫酸盐、游离SO2和氯化物捕获了大部分预测信号。在EPYC 9K84/H20节点上的运行时分析显示出陡峭的效率梯度：梯度提升机平均每五折研究需要12小时，XGBoost和LightGBM需要2-3小时，CatBoost需要1小时，随机森林不到50分钟。因此，我们推荐随机森林作为最具成本效益的生产模型，XGBoost和LightGBM作为GPU高效替代方案，以及梯度提升机作为离线基准测试的准确性上限。完整文档化的流程和指标集为未来不平衡多类别葡萄酒质量预测工作提供了可复现的基线。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [173] [FuncGNN: Learning Functional Semantics of Logic Circuits with Graph Neural Networks](https://arxiv.org/abs/2506.06787)
> *FuncGNN：利用图神经网络学习逻辑电路的功能语义*

*Qiyun Zhao* | **Main category: cs.LG**

**Keywords:** 图神经网络, 逻辑电路, 功能语义, 电路表示, 结构异质性

**Comment:** 

> **TL;DR:** FuncGNN是一种新的图神经网络模型，通过混合特征聚合、门感知归一化和多层集成，有效解决了复杂集成电路建模中的结构异质性和信息丢失问题，并在逻辑分析任务中显著优于现有SOTA方法。

**AI_Comments:** FuncGNN的创新之处在于其结合了混合特征聚合、门感知归一化和多层集成，这些机制协同作用，有效提升了复杂逻辑电路表示的准确性和鲁棒性。该方法不仅在性能上超越了现有SOTA，还在资源效率方面取得了显著进步，这对于大规模集成电路设计和自动化具有重要意义。它为未来的电路建模和分析提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 随着集成电路规模的增长和设计复杂性的提高，有效的电路表示对于支持逻辑综合、形式验证和其他电子设计自动化中的自动化过程至关重要。然而，现代电路日益增长的复杂性和集成密度在与非反相图（AIGs）中引入了结构异质性和全局逻辑信息丢失，对准确的电路建模构成了重大挑战。

**Method:** 本文提出了FuncGNN，它通过以下方式解决上述问题：1. 整合混合特征聚合以提取多粒度拓扑模式，从而减轻结构异质性并增强逻辑电路表示。2. 引入门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。3. 采用多层集成，合并跨层中间特征，有效综合局部和全局语义信息，实现全面的逻辑表示。

**Result:** FuncGNN在信号概率预测和真值表距离预测这两个逻辑级分析任务上，分别实现了2.06%和18.71%的性能提升，同时训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。

**Conclusion:** FuncGNN通过其创新的混合特征聚合、门感知归一化和多层集成机制，有效克服了复杂集成电路建模中的挑战，显著提高了逻辑电路表示的准确性和效率，并在多个逻辑分析任务中展现出卓越的性能。

> **ai_Abstract:** 本文提出了FuncGNN，一种用于学习逻辑电路功能语义的图神经网络模型，旨在解决复杂集成电路中AIGs表示的结构异质性和信息丢失问题。FuncGNN通过混合特征聚合捕获多粒度拓扑模式，引入门感知归一化增强鲁棒性，并利用多层集成整合局部和全局语义信息。实验证明，FuncGNN在信号概率和真值表距离预测任务上显著优于现有方法，并大幅降低了训练时间和GPU内存消耗。

> **摘要翻译:** 随着集成电路规模的增长和设计复杂性的提高，有效的电路表示有助于支持逻辑综合、形式验证和电子设计自动化中的其他自动化过程。与非反相图（AIGs）作为一种紧凑和规范的结构，在这些工作流程中被广泛用于表示布尔逻辑。然而，现代电路日益增长的复杂性和集成密度在AIGs中引入了结构异质性和全局逻辑信息丢失，对准确的电路建模构成了重大挑战。为了解决这些问题，我们提出了FuncGNN，它集成了混合特征聚合以提取多粒度拓扑模式，从而减轻结构异质性并增强逻辑电路表示。FuncGNN进一步引入了门感知归一化，以适应电路特定的门分布，提高对结构异质性的鲁棒性。最后，FuncGNN采用了多层集成，合并跨层中间特征，有效综合局部和全局语义信息，实现全面的逻辑表示。在两个逻辑级分析任务（即信号概率预测和真值表距离预测）上的实验结果表明，FuncGNN优于现有的最先进方法，分别实现了2.06%和18.71%的改进，同时训练时间减少了约50.6%，GPU内存使用量减少了约32.8%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [174] [ExplainBench: A Benchmark Framework for Local Model Explanations in Fairness-Critical Applications](https://arxiv.org/abs/2506.06330)
> *ExplainBench: 公平性关键应用中局部模型解释的基准框架*

*James Afful* | **Main category: cs.LG**

**Keywords:** 局部模型解释, 公平性, 基准框架, 可解释机器学习, ExplainBench

**Comment:** 

> **TL;DR:** ExplainBench 是一个开源基准框架，用于系统评估公平性敏感场景下的局部模型解释技术。

**AI_Comments:** ExplainBench 的创新之处在于提供了一个急需的标准化、可复现的框架，用于比较评估局部模型解释技术，尤其关注公平性关键应用。这对于提升可解释AI的科学严谨性至关重要，因为它解决了现有评估方法碎片化的问题，并促进了对不同解释方法行为的深入理解，从而有助于构建更负责任的AI系统。

<details>
  <summary>Details</summary>

**Motivation:** 随着机器学习系统在高风险领域（如刑事司法、金融、医疗保健）的部署日益增多，对可解释和可信模型的需求加剧。尽管局部解释技术（如 SHAP、LIME、反事实方法）激增，但缺乏一个标准化、可复现的比较评估框架，尤其是在公平性敏感设置中。

**Method:** 本文引入了 ExplainBench，一个开源基准套件，用于在伦理上重要的数据集上系统评估局部模型解释。ExplainBench 为流行的解释算法提供统一封装器，集成模型训练和解释生成的端到端管道，并支持通过保真度、稀疏性和鲁棒性指标进行评估。该框架包括一个基于 Streamlit 的图形界面用于交互式探索，并打包为 Python 模块以便无缝集成到研究工作流程中。

**Result:** 作者在公平性研究中常用的数据集（如 COMPAS、UCI Adult Income 和 LendingClub）上演示了 ExplainBench，并展示了不同解释方法在共享实验协议下的行为。

**Conclusion:** 通过实现局部解释的可复现、比较分析，ExplainBench 提升了可解释机器学习的方法论基础，并促进了现实世界 AI 系统中的问责制。

> **ai_Abstract:** 本文介绍了 ExplainBench，一个开源的基准框架，旨在标准化和系统评估在公平性敏感应用中的局部模型解释技术。该框架为多种解释算法提供统一接口，支持端到端评估流程，并利用保真度、稀疏性和鲁棒性指标进行衡量。ExplainBench 通过在公平性数据集上的演示，促进了可解释机器学习的方法论发展和AI系统的问责制。

> **摘要翻译:** 随着机器学习系统越来越多地部署在刑事司法、金融和医疗保健等高风险领域，对可解释和可信模型的需求日益增加。尽管局部解释技术（包括 SHAP、LIME 和反事实方法）激增，但目前尚缺乏一个标准化、可复现的比较评估框架，尤其是在对公平性敏感的设置中。
我们引入了 ExplainBench，一个开源基准套件，用于在具有伦理影响的数据集上系统评估局部模型解释。ExplainBench 为流行的解释算法提供了统一的封装器，集成了模型训练和解释生成的端到端管道，并支持通过保真度、稀疏性和鲁棒性指标进行评估。该框架包括一个基于 Streamlit 的图形界面用于交互式探索，并打包为 Python 模块以便无缝集成到研究工作流程中。
我们在公平性研究中常用的数据集（如 COMPAS、UCI Adult Income 和 LendingClub）上演示了 ExplainBench，并展示了不同解释方法在共享实验协议下的行为。通过实现局部解释的可复现、比较分析，ExplainBench 提升了可解释机器学习的方法论基础，并促进了现实世界 AI 系统中的问责制。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [190] [Optimized Local Updates in Federated Learning via Reinforcement Learning](https://arxiv.org/abs/2506.06337)
> *通过强化学习优化联邦学习中的本地更新*

*Ali Murad, Bo Hui, Wei-Shinn Ku* | **Main category: cs.LG**

**Keywords:** 联邦学习, 强化学习, 本地更新, 非独立同分布数据, 数据隐私

**Comment:** This paper is accepted at IEEE IJCNN 2025

> **TL;DR:** 本文提出了一种利用深度强化学习（DRL）代理来优化联邦学习中客户端本地更新的数据量，以提升非独立同分布（non-IID）数据下的性能并避免信息过载。

**AI_Comments:** 该论文通过引入深度强化学习来优化联邦学习中的本地数据选择，解决了非独立同分布数据下性能下降的核心问题。其创新点在于将DRL应用于动态管理客户端的本地训练数据，通过优化数据分区来提高模型性能和隐私保护，这对于实际部署联邦学习具有重要意义。该方法通过避免不必要的信息共享，有效地提升了联邦学习的效率和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 联邦学习在非独立同分布（non-IID）数据存在时，由于中心化服务器的模型聚合，会导致性能下降。此外，客户端训练超出必要的数据量并不能提升整体性能，反而可能导致信息过度共享。

**Method:** 本文提出了一种新颖的框架，利用深度强化学习（DRL）代理来选择客户端模型训练所需的最优数据量，避免信息过度共享。DRL代理以训练损失的变化作为奖励信号，并根据客户端的本地性能（作为当前状态）输出每个类别在训练数据中的优化权重，用于下一轮本地训练。该代理学习一个策略，在联邦学习轮次中创建本地训练数据集的优化分区。在联邦学习结束后，客户端利用整个本地训练数据集进一步提升其在自身数据分布上的性能，从而缓解非独立同分布聚合的影响。

**Result:** 通过广泛的实验，本文证明了使用该算法训练联邦学习客户端在多个基准数据集和联邦学习框架上均能获得卓越的性能。

**Conclusion:** 本文提出的基于深度强化学习的优化本地更新方法，能够有效解决联邦学习中非独立同分布数据导致的性能下降问题，通过智能选择训练数据量，提升了整体性能并缓解了信息过度共享。

> **ai_Abstract:** 本文针对联邦学习在非独立同分布（non-IID）数据下性能下降的问题，提出了一种创新的解决方案。该方案引入了一个深度强化学习（DRL）代理，用于智能地选择客户端本地训练所需的最优数据量，以避免信息过度共享并提升模型性能。DRL代理通过监控训练损失变化来优化数据选择策略，并在联邦学习聚合后利用整个本地数据集进一步优化客户端自身性能，有效缓解了非IID效应。实验结果表明，该方法在多个基准数据集和FL框架上均实现了卓越的性能。

> **摘要翻译:** 联邦学习（FL）是一种分布式框架，用于在大规模分布式数据上进行协作模型训练，在保持客户端数据隐私的同时实现更高的性能。然而，在不同客户端之间存在非独立同分布（non-IID）数据的情况下，中心化服务器上的模型聚合性质可能导致性能下降。我们指出，客户端在超出必要的数据量上进行本地训练并不能提升所有客户端的整体性能。在本文中，我们设计了一个新颖的框架，该框架利用深度强化学习（DRL）代理来选择训练客户端模型所需的最优数据量，而不会与服务器过度共享信息。DRL代理最初不了解客户端的性能，它利用训练损失的变化作为奖励信号，并学习优化训练数据量，以提高客户端的性能。具体来说，在每次聚合轮次之后，DRL算法将本地性能视为当前状态，并输出训练数据中每个类别的优化权重，以用于下一轮本地训练。通过这样做，代理学习了一个策略，在联邦学习轮次中创建本地训练数据集的优化分区。在联邦学习之后，客户端利用整个本地训练数据集进一步提升其在自身数据分布上的性能，从而缓解聚合的非独立同分布效应。通过广泛的实验，我们证明通过我们的算法训练联邦学习客户端在多个基准数据集和联邦学习框架上均能获得卓越的性能。我们的代码可在https://github.com/amuraddd/optimized_client_training.git获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [200] [From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins](https://arxiv.org/abs/2506.06359)
> *从Transformer到大型语言模型：能源领域人工智能应用迈向智能体数字孪生的系统综述*

*Gabriel Antonesi, Tudor Cioara, Ionut Anghel, Vasilis Michalakopoulos, Elissaios Sarmas, Liana Toderean* | **Main category: cs.LG**

**Keywords:** Transformers, 大型语言模型, 能源领域, 数字孪生, 智能电网

**Comment:** 

> **TL;DR:** 本文系统综述了Transformer和大型语言模型（LLMs）在能源领域的应用，强调了它们在复杂数据建模方面的能力，并提出了将LLMs集成到智能体数字孪生中以增强能源管理的概念。

**AI_Comments:** 该论文具有重要意义，因为它将前沿AI技术（Transformer、LLMs）与关键的能源领域相结合。其创新之处在于系统地回顾了这些先进模型的应用，更重要的是，概念化了“智能体数字孪生”，这为能源管理提出了一种新颖、更自主的范式。这一框架有望显著增强智能电网的韧性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 尽管传统机器学习在智能电网能源管理中有所应用，但其在泛化、态势感知和异构数据集成方面存在局限性。Transformer和LLMs等基础模型在处理复杂时间/上下文关系和多模态数据融合方面展现出更强的能力，这对于能源领域的AI应用至关重要，因此有必要对其进行系统回顾。

**Method:** 本文对能源领域中快速发展的人工智能应用（特别是Transformer和LLMs）进行了系统综述。它考察了Transformer模型的架构基础、领域特定适应和实际应用，并探讨了LLMs在新兴能源领域的角色，包括其适应性、适用任务和引入的挑战。此外，还提出了智能体数字孪生的概念。

**Result:** 综述结果表明，Transformer和LLMs在建模复杂时间/上下文关系和多模态数据融合方面表现出改进的能力，并且生成式AI（GenAI）正在增强能源部门的决策制定，从高层规划到日常运营。此外，论文引入了智能体数字孪生概念，该模型通过集成LLMs为数字孪生能源管理系统带来自主性、主动性和社交互动。

**Conclusion:** 该论文得出结论，生成式AI（特别是LLMs）的最新发展将显著增强能源领域的决策制定，并引入了智能体数字孪生这一创新概念，旨在为能源管理系统赋予自主性和主动性。

> **ai_Abstract:** 本系统综述探讨了Transformer和大型语言模型（LLMs）等先进AI模型在能源领域的日益增长的应用。论文指出，这些模型通过有效处理复杂数据和关系，克服了传统机器学习的局限性。文中深入分析了它们的架构基础、领域适应性以及在预测和电网管理等任务中的实际应用。该综述强调了LLMs在增强能源运营中决策制定的新兴作用，并引入了智能体数字孪生这一创新概念，该概念利用LLMs提升能源管理系统的自主性和主动性。

> **摘要翻译:** 人工智能（AI）长期以来一直致力于通过增强态势感知和支持更有效的决策来改善智能电网中的能源管理。虽然传统的机器学习在预测和优化方面取得了显著成果，但它常常在泛化、态势感知和异构数据集成方面遇到困难。Transformer架构和大型语言模型（LLMs）等基础模型的最新进展，在建模复杂的时间和上下文关系以及多模态数据融合方面表现出更强的能力，这对于能源领域的大多数AI应用至关重要。在这篇综述中，我们综合了能源领域中快速发展的人工智能应用，重点关注Transformer和LLMs。我们研究了Transformer模型在各种预测和电网管理任务中的架构基础、领域特定适应和实际实现。然后，我们探讨了LLMs在该领域的新兴作用：针对能源领域的适应和微调、它们适合的任务类型以及它们引入的新挑战。在此过程中，我们强调了实际实现、创新以及研究前沿正在迅速扩展的领域。这些近期回顾的进展强调了一个更广泛的趋势：生成式AI（GenAI）开始不仅在高层规划中，而且在日常运营中（从预测和电网平衡到劳动力培训和资产入职）增强决策。基于这些发展，我们引入了智能体数字孪生（Agentic Digital Twin）的概念，这是一种集成了LLMs的下一代模型，旨在将自主性、主动性和社交互动引入基于数字孪生的能源管理系统。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [202] [Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models](https://arxiv.org/abs/2506.07468)
> *利用在线自博弈强化学习追逐移动目标以实现更安全的语言模型*

*Mickel Liu, Liwei Jiang, Yancheng Liang, Simon Shaolei Du, Yejin Choi, Tim Althoff, Natasha Jaques* | **Main category: cs.LG**

**Keywords:** 语言模型安全, 自博弈强化学习, 对抗性训练, 零和博弈, 多智能体强化学习

**Comment:** 

> **TL;DR:** 本文提出Self-RedTeam，一种在线自博弈强化学习算法，通过攻击者和防御者智能体的共同进化，旨在提升语言模型安全性，解决传统方法的滞后问题。

**AI_Comments:** 这篇论文的创新点在于将语言模型安全对齐问题转化为一个动态的、多智能体强化学习的自博弈过程，而非传统的静态修补。通过引入攻击者和防御者的共同进化，有效解决了现有方法中“攻击者过度拟合、防御者滞后”的问题，并提供了理论安全保证。隐藏式思维链的提出也进一步提升了实际效果。这项工作为语言模型安全性的自主和持续改进提供了一个有前景的新范式。

<details>
  <summary>Details</summary>

**Motivation:** 传统语言模型（LM）安全对齐方法是反应性的、分离的，导致攻击者过度拟合过时防御，而防御者永久落后于新兴威胁，存在攻击与防御不匹配的问题。

**Method:** 本文提出了Self-RedTeam，一种在线自博弈强化学习算法。该方法将安全对齐建模为双人零和博弈，其中单个语言模型轮流扮演攻击者和防御者角色，生成对抗性提示并进行防御，并由奖励LM裁决结果，从而实现动态共同适应。理论上，如果自博弈收敛到纳什均衡，防御者能可靠地对任何对抗性输入产生安全响应。此外，还提出了隐藏式思维链（hidden Chain-of-Thought），允许智能体私下规划，以提升对抗多样性并减少过度拒绝。

**Result:** 经验证明，与针对静态防御者训练的攻击者相比，Self-RedTeam能发现更多样化的攻击（SBERT +21.8%）。在安全基准测试（例如WildJailBreak）上，其防御鲁棒性比针对静态攻击者训练的防御者更高（+65.5%）。隐藏式思维链进一步提升了对抗多样性并减少了过度拒绝。

**Conclusion:** 本文结果促使语言模型安全训练从反应性修补转向主动共同进化，通过多智能体强化学习（MARL）实现语言模型的可扩展、自主和鲁棒的自我改进。

> **ai_Abstract:** 本文提出Self-RedTeam，一种在线自博弈强化学习算法，旨在解决传统语言模型安全对齐中攻击者与防御者之间的滞后问题。该算法将安全对齐建模为双人零和博弈，通过一个模型轮流扮演攻击者和防御者角色，实现动态共同适应。理论分析表明，收敛到纳什均衡可提供安全保证。实验结果显示，Self-RedTeam能发现更多样化的攻击并提升防御鲁棒性。此外，引入隐藏式思维链进一步增强了对抗多样性并减少了过度拒绝。该研究倡导LM安全训练从被动修补转向主动协同进化。

> **摘要翻译:** 传统语言模型（LM）安全对齐依赖于一种反应性的、分离的程序：攻击者利用静态模型，随后进行防御性微调以修补暴露的漏洞。这种顺序方法造成了不匹配——攻击者过度拟合过时的防御，而防御者则永久落后于新兴威胁。为了解决这个问题，我们提出了Self-RedTeam，一种在线自博弈强化学习算法，其中攻击者和防御者智能体通过持续交互共同进化。我们将安全对齐视为一个双人零和博弈，其中一个模型轮流扮演攻击者和防御者角色——生成对抗性提示并抵御它们——同时一个奖励LM裁决结果。这使得动态共同适应成为可能。基于零和博弈的博弈论框架，我们建立了理论安全保证，这激励了我们方法的设计：如果自博弈收敛到纳什均衡，防御者将可靠地对任何对抗性输入产生安全响应。经验上，与针对静态防御者训练的攻击者相比，Self-RedTeam发现了更多样化的攻击（SBERT +21.8%），并且在安全基准测试（例如WildJailBreak）上比针对静态攻击者训练的防御者实现了更高的鲁棒性（+65.5%）。我们进一步提出了隐藏式思维链（hidden Chain-of-Thought），允许智能体私下规划，这提升了对抗多样性并减少了过度拒绝。我们的结果促使LM安全训练从反应性修补转向主动共同进化，通过多智能体强化学习（MARL）实现LM的可扩展、自主和鲁棒的自我改进。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [208] [MoE-GPS: Guidlines for Prediction Strategy for Dynamic Expert Duplication in MoE Load Balancing](https://arxiv.org/abs/2506.07366)
> *MoE-GPS：MoE负载均衡中动态专家复制的预测策略指南*

*Haiyue Ma, Zhixu Du, Yiran Chen* | **Main category: cs.LG**

**Keywords:** MoE, 负载均衡, 专家混合, 预测策略, GPU推理

**Comment:** 

> **TL;DR:** MoE-GPS提出了一种预测策略，用于动态复制MoE中的专家以平衡负载，建议使用仅预测分布的方法，可将推理性能提高23%以上。

**AI_Comments:** 该论文提出MoE-GPS框架以解决MoE模型在多GPU环境下的负载不平衡问题，其创新点在于提出了“仅分布预测”这一高效策略，显著降低了预测开销并提升了推理性能。这对于优化大型MoE模型的部署和运行效率具有重要意义，尤其是在资源受限或对延迟敏感的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 在多GPU专家混合（MoE）网络中，由于每个专家处理不同数量的tokens，导致负载不平衡。现有的MoE推理负载均衡方法通过动态复制热门专家来处理过多的tokens，但这需要在路由前预测token分布。本文旨在探讨不同预测策略的权衡，并指导选择最佳预测器设计以优化系统性能。

**Method:** 本文提出了MoE-GPS框架，该框架通过量化对系统级模型运行时的性能影响，指导在各种系统配置下选择最佳预测器设计。具体地，MoE-GPS倡导“仅分布预测”（Distribution-Only Prediction）策略，这种策略只预测整体token分布，与传统的“Token-to-Expert Prediction”相比，显著降低了开销。

**Result:** 在Mixtral 8x7B MMLU数据集上，MoE-GPS建议使用“仅分布预测”策略，与“Token-to-Expert Prediction”相比，端到端推理性能提升了23%以上。

**Conclusion:** MoE-GPS框架为MoE负载均衡中的动态专家复制提供了有效的预测策略选择指南，特别是其推荐的“仅分布预测”策略能够显著提高端到端推理性能。

> **ai_Abstract:** 本文针对多GPU专家混合（MoE）网络中的负载不平衡问题，提出了MoE-GPS框架。该框架旨在通过量化对系统级模型运行时的性能影响，指导选择最优的动态专家复制预测策略。研究发现，MoE-GPS提倡的“仅分布预测”策略（只预测整体token分布）相比传统方法显著降低了开销，并在Mixtral 8x7B MMLU数据集上将端到端推理性能提升了23%以上，从而有效改善MoE模型的推理负载平衡。

> **摘要翻译:** 在多GPU专家混合（MoE）网络中，专家分布在不同的GPU上，由于每个专家处理不同数量的tokens，这会造成负载不平衡。最近的工作通过将热门专家动态复制到更多GPU来处理过多的tokens，从而改善MoE推理负载平衡，这需要在路由前预测分布。在本文中，我们讨论了预测策略、准确性、开销和端到端系统性能之间的权衡。我们提出了MoE-GPS，一个通过量化对系统级模型运行时的性能影响来指导在各种系统配置下选择最佳预测器设计的框架。具体来说，我们提倡“仅分布预测”，这是一种只预测整体token分布的预测策略，与传统的“Token-to-Expert Prediction”相比，显著降低了开销。在Mixtral 8x7B MMLU数据集上，MoE-GPS建议使用“仅分布预测”，与“Token-to-Expert Prediction”相比，端到端推理性能提高了23%以上。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [215] [Theoretical Analysis of Positional Encodings in Transformer Models: Impact on Expressiveness and Generalization](https://arxiv.org/abs/2506.06398)
> *Transformer模型中位置编码的理论分析：对表达能力和泛化能力的影响*

*Yin Li* | **Main category: cs.LG**

**Keywords:** 位置编码, Transformer模型, 表达能力, 泛化能力, 正交函数

**Comment:** 

> **TL;DR:** 本文提出了一个理论框架，分析了各种位置编码方法（包括正弦、学习、相对和基于偏置的方法）如何影响Transformer模型的表达能力、泛化能力和外推能力，并提出了基于正交函数的新编码方法，实验证明其在泛化和外推方面优于传统方法。

**AI_Comments:** 这项研究通过建立一个全面的理论框架，系统地分析了不同位置编码对Transformer模型性能的关键影响，填补了该领域的一个理论空白。其提出的基于正交函数的新编码方法，并在实验中验证了其优越性，为Transformer模型在长序列处理和泛化能力方面提供了新的设计思路和优化方向，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有Transformer理论在位置编码对模型性能影响方面存在空白，需要一个理论框架来分析不同位置编码方法对Transformer表达能力、泛化能力和序列外推能力的影响。

**Method:** 提出了一个理论框架，用于分析正弦、学习、相对和基于偏置（如ALiBi）等多种位置编码方法；通过函数逼近定义表达能力；使用Rademacher复杂度建立泛化界限；提出了基于正交函数（如小波和勒让德多项式）的新编码方法；分析了现有和提出的编码方法的外推能力，并将ALiBi的偏置方法扩展到统一的理论背景；在合成序列到序列任务上进行了实验评估。

**Result:** 基于正交变换的编码方法在泛化能力和序列外推方面优于传统的正弦编码方法。

**Conclusion:** 这项工作填补了Transformer理论中的一个关键空白，为自然语言处理、计算机视觉和其他Transformer应用中的设计选择提供了深入见解。

> **ai_Abstract:** 本文提出了一个理论框架，深入分析了Transformer模型中不同位置编码方法（如正弦、学习、相对和基于偏置的方法）对其表达能力、泛化能力和序列外推能力的影响。研究定义了表达能力和泛化界限，并提出了基于正交函数（如小波和勒让德多项式）的新型位置编码。实验结果表明，这些正交变换编码在泛化和外推性能上优于传统的正弦编码，为Transformer模型的设计提供了重要的理论和实践指导。

> **摘要翻译:** 位置编码是基于Transformer模型的核心组成部分，使得模型无需循环即可处理序列数据。本文提出了一个理论框架，用于分析各种位置编码方法，包括正弦、学习、相对和基于偏置的方法（如带有线性偏置的注意力机制ALiBi），如何影响Transformer的表达能力、泛化能力以及对更长序列的外推能力。表达能力通过函数逼近来定义，泛化界限通过Rademacher复杂度建立，并提出了基于正交函数（如小波和勒让德多项式）的新编码方法。本文分析了现有和提出的编码方法的外推能力，将ALiBi的偏置方法扩展到一个统一的理论背景。在合成序列到序列任务上的实验评估表明，基于正交变换的编码方法在泛化和外推方面优于传统的正弦编码。这项工作解决了Transformer理论中的一个关键空白，为自然语言处理、计算机视觉和其他Transformer应用中的设计选择提供了见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [224] [CoxNTF: A New Approach for Joint Clustering and Prediction in Survival Analysis](https://arxiv.org/abs/2506.06411)
> *CoxNTF：一种生存分析中联合聚类和预测的新方法*

*Paul Fogel, Christophe Geissler, George Luta* | **Main category: cs.LG**

**Keywords:** 生存分析, 非负张量分解, 联合聚类, 预测, CoxNTF

**Comment:** 7 pages, 3 figures, Conference on Lifetime Data Science 2025,
  Brooklyn, New York, USA

> **TL;DR:** CoxNTF是一种新的非负张量分解方法，结合生存信息进行聚类和预测，性能与现有方法相当且更具解释性。

**AI_Comments:** CoxNTF的创新之处在于将生存信息融入非负张量分解过程，解决了现有潜在因子表示方法在生存分析中预测能力受限的问题。其提供的可解释聚类框架和处理特征冗余的能力，使其在生存分析领域具有重要的应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法（如非负矩阵分解NMF）在生存分析中解释结果时，未融入生存信息，限制了其预测能力。

**Method:** 本文提出了CoxNTF，一种利用非负张量分解（NTF）来获得与生存结果密切相关的潜在表示的新方法。CoxNTF通过使用从Coxnet模型获得的生存概率来指导张量化过程，构建加权协变量张量。

**Result:** CoxNTF在生存预测性能上与使用原始协变量的Coxnet相当，同时提供了一个结构化且可解释的聚类框架。此外，新方法有效处理了特征冗余。

**Conclusion:** CoxNTF为生存分析中的联合聚类和预测提供了一个强大且有效的工具，兼具预测性能和解释性。

> **ai_Abstract:** 本文提出了CoxNTF，一种基于非负张量分解的新方法，用于生存分析中的联合聚类和预测。它通过将Coxnet模型的生存概率纳入协变量张量化过程，克服了现有方法未能整合生存信息的局限性。实验结果显示，CoxNTF在保持与传统Coxnet相当的预测性能的同时，提供了一个结构化、可解释的聚类框架，并能有效处理特征冗余。

> **摘要翻译:** 生存分析结果的解释常常受益于基线协变量的潜在因子表示。然而，现有方法，例如非负矩阵分解（NMF），并未纳入生存信息，限制了其预测能力。我们提出了CoxNTF，这是一种新颖的方法，它利用非负张量分解（NTF）来推导与生存结果密切相关的有意义的潜在表示。CoxNTF构建了一个加权协变量张量，其中使用从Coxnet模型获得的生存概率来指导张量化过程。我们的结果表明，CoxNTF实现了与使用原始协变量的Coxnet相当的生存预测性能，同时提供了一个结构化且可解释的聚类框架。此外，这种新方法有效处理了特征冗余，使其成为生存分析中联合聚类和预测的强大工具。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [229] [NeurNCD: Novel Class Discovery via Implicit Neural Representation](https://arxiv.org/abs/2506.06412)
> *NeurNCD: 基于隐式神经表示的新颖类别发现*

*Junming Wang, Yi Shi* | **Main category: cs.LG**

**Keywords:** 新颖类别发现, 隐式神经表示, NeurNCD, NeRF, 语义分割

**Comment:** Accepted by ICMR 2024

> **TL;DR:** NeurNCD是一个新颖的框架，它利用隐式神经表示（特别是Embedding-NeRF模型和KL散度）来克服传统显式表示的局限性，从而在无需大量标注数据的情况下，在开放和封闭世界设置中实现卓越的新颖类别发现和分割性能。

**AI_Comments:** NeurNCD的创新之处在于首次将隐式神经表示应用于新颖类别发现任务，这有望解决传统显式表示的固有缺陷。其数据高效性和在无需密集标注的情况下实现SOTA性能的能力，使其在实际应用中具有重要价值。这种方法为开放世界识别和分割问题开辟了新的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 在开放世界环境中发现新颖类别对于实际应用至关重要。传统的显式表示（如物体描述符或3D分割图）存在离散、易出错和噪声多的问题，这阻碍了准确的新颖类别发现。

**Method:** 本文提出了NeurNCD，这是一个通用的、数据高效的新颖类别发现框架。它采用精心设计的Embedding-NeRF模型与KL散度相结合，替代传统的显式3D分割图，以在视觉嵌入空间中聚合语义嵌入和熵。NeurNCD还集成了特征查询、特征调制和聚类等关键组件，以促进预训练语义分割网络与隐式神经表示之间的特征增强和信息交换。

**Result:** NeurNCD框架在开放和封闭世界设置中均实现了卓越的分割性能，且无需依赖密集标注数据集进行监督训练或人工交互来生成稀疏标签监督。在NYUv2和Replica数据集上的大量实验表明，该方法显著优于最先进的方法。

**Conclusion:** NeurNCD通过引入隐式神经表示，成功克服了传统显式表示在开放世界新颖类别发现中的局限性，并在数据效率和分割性能方面取得了显著提升。

> **ai_Abstract:** NeurNCD是一个开创性的新颖类别发现框架，它通过引入隐式神经表示（特别是Embedding-NeRF模型和KL散度）来克服传统显式表示在处理新颖类别时的局限性。该框架通过集成特征查询、调制和聚类，实现了高效的特征增强和信息交换，从而在无需大量标注数据的情况下，在开放和封闭世界设置中均展现出卓越的分割性能，并在标准数据集上超越了现有技术。

> **摘要翻译:** 在开放世界环境中发现新颖类别对于实际应用至关重要。传统的显式表示，例如物体描述符或3D分割图，受限于其离散、易出错和噪声多的特性，这阻碍了准确的新颖类别发现。为了解决这些挑战，我们引入了NeurNCD，这是第一个通用且数据高效的新颖类别发现框架，它采用精心设计的Embedding-NeRF模型结合KL散度，作为传统显式3D分割图的替代，以在视觉嵌入空间中聚合语义嵌入和熵。NeurNCD还集成了几个关键组件，包括特征查询、特征调制和聚类，促进了预训练语义分割网络与隐式神经表示之间的高效特征增强和信息交换。因此，我们的框架在开放和封闭世界设置中都取得了卓越的分割性能，而无需依赖密集标注数据集进行监督训练或人工交互来生成稀疏标签监督。大量的实验表明，我们的方法在NYUv2和Replica数据集上显著优于最先进的方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [237] [GeoClip: Geometry-Aware Clipping for Differentially Private SGD](https://arxiv.org/abs/2506.06549)
> *GeoClip: 差分隐私随机梯度下降的几何感知裁剪*

*Atefeh Gilani, Naima Tasnim, Lalitha Sankar, Oliver Kosut* | **Main category: cs.LG**

**Keywords:** 差分隐私SGD, 梯度裁剪, 几何感知, 自适应方法, 隐私-效用权衡

**Comment:** 

> **TL;DR:** DP-SGD中的梯度裁剪阈值设置具有挑战性，影响隐私与效用。GeoClip提出了一种几何感知的裁剪方法，在变换基中进行裁剪和扰动，并在实验中优于现有方法。

**AI_Comments:** 这篇论文通过考虑梯度分布的几何特性，引入了一种创新的DP-SGD梯度裁剪方法，是对传统基于坐标的方法的显著改进。其在不增加额外隐私成本的情况下自适应估计变换的能力，以及提供收敛性保证，是其显著的优势。GeoClip持续超越现有方法的表现，表明其对隐私保护机器学习领域做出了实用且有影响力的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 差分隐私随机梯度下降（DP-SGD）中设置每样本梯度裁剪阈值是一个关键挑战，因为它显著影响隐私和效用之间的权衡。现有的自适应方法在标准坐标系中操作，未能考虑梯度坐标之间的相关性。

**Method:** 本文提出了GeoClip，一个几何感知框架，在与梯度分布几何对齐的变换基中裁剪和扰动梯度。GeoClip仅使用先前发布的噪声梯度自适应地估计此变换，不产生额外的隐私成本。作者为GeoClip提供了收敛性保证，并推导出了一个闭合形式的解决方案，用于最小化添加噪声量同时控制梯度裁剪概率的最佳变换。

**Result:** 在表格和图像数据集上的实验表明，GeoClip在相同的隐私预算下始终优于现有的自适应裁剪方法。

**Conclusion:** GeoClip通过使用几何感知裁剪改进了DP-SGD中的隐私-效用权衡，并在实验中持续优于现有方法。

> **ai_Abstract:** 本文介绍了GeoClip，一个用于差分隐私随机梯度下降（DP-SGD）的几何感知框架。它通过在与梯度分布几何对齐的变换基中执行裁剪和扰动来解决梯度裁剪阈值设置的挑战。GeoClip利用先前的噪声梯度自适应地估计此变换，不产生额外隐私成本，并提供了收敛性保证和最优变换的闭合解。实验证明，GeoClip在隐私-效用权衡方面始终优于现有的自适应裁剪方法。

> **摘要翻译:** 差分隐私随机梯度下降（DP-SGD）是训练具有可证明隐私保证的机器学习模型最广泛使用的方法。DP-SGD 中的一个关键挑战是设置每样本梯度裁剪阈值，这显著影响隐私和效用之间的权衡。虽然最近的自适应方法通过在训练期间调整此阈值来提高性能，但它们在标准坐标系中操作，未能考虑梯度坐标之间的相关性。我们提出了 GeoClip，一个几何感知框架，它在与梯度分布几何对齐的变换基中裁剪和扰动梯度。GeoClip 仅使用先前发布的噪声梯度自适应地估计此变换，不产生额外的隐私成本。我们为 GeoClip 提供了收敛性保证，并推导出了一个闭合形式的解决方案，用于最小化添加噪声量同时控制梯度裁剪概率的最佳变换。在表格和图像数据集上的实验表明，GeoClip 在相同的隐私预算下始终优于现有的自适应裁剪方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [238] [Unlocking Chemical Insights: Superior Molecular Representations from Intermediate Encoder Layers](https://arxiv.org/abs/2506.06443)
> *解锁化学见解：来自中间编码器层的卓越分子表示*

*Luis Pinto* | **Main category: cs.LG**

**Keywords:** 分子表示, 分子编码器, 深度学习, 属性预测, 中间层

**Comment:** 

> **TL;DR:** 分子编码器的中间层提供了比最终层更好的分子表示，从而显著提高了属性预测任务的性能。

**AI_Comments:** 这篇论文提出了一个重要的发现，挑战了计算化学中的一个常见做法。通过证明分子编码器中间层的价值，它为优化模型性能和效率开辟了新途径。所提出的“评估-然后-微调”方法实用且计算高效，使得这些见解能够立即得到应用。这项工作强调了深入理解架构（超越最终输出层）的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 预训练分子编码器在计算化学中不可或缺，但仅依赖最终层嵌入进行下游任务的标准做法可能会丢弃有价值的信息，限制了性能。

**Method:** 研究人员对五种不同的分子编码器在22个ADMET属性预测任务中进行了全面的层级分析，评估了固定嵌入和对中间层进行微调的效果。

**Result:** 结果显示，来自中间层的嵌入始终优于最终层表示。使用最佳中间层的固定嵌入平均提高了5.4%的性能（最高达28.6%）。对这些中间层进行微调带来了更大的平均改进，达到8.5%（最高达40.8%），并在多个基准测试中取得了新的最先进结果。此外，固定嵌入性能与微调结果之间存在强正相关性，支持高效的“评估-然后-微调”方法。

**Conclusion:** 探索分子编码器的完整表示深度，即利用中间层，对于在计算化学任务中实现显著的性能改进和计算效率至关重要。

> **ai_Abstract:** 本文通过挑战仅使用最终层嵌入的传统做法，探讨了预训练分子编码器中信息未被充分利用的问题。通过对五种编码器在22个ADMET任务中的层级分析，研究发现中间层持续提供更优的分子表示。无论是使用固定嵌入还是对这些中间层进行微调，都能带来显著的性能提升，其中微调达到了新的最先进水平。研究结果强调了探索编码器完整表示深度以提高性能和计算效率的重要性，并提出了一种高效的“评估-然后-微调”策略。

> **摘要翻译:** 预训练分子编码器在计算化学中对于属性预测和分子生成等任务变得不可或缺。然而，仅依赖最终层嵌入进行下游任务的标准做法可能会丢弃有价值的信息。在这项工作中，我们通过对五种不同分子编码器在22个ADMET属性预测任务中进行全面的层级分析，挑战了这一传统做法。我们的结果表明，来自中间层的嵌入始终优于最终层表示。具体而言，使用来自最佳中间层的固定嵌入将下游性能平均提高了5.4%，最高达到28.6%。此外，对这些中间层进行微调带来了更大的平均改进，达到8.5%，性能提升高达40.8%，在多个基准测试中取得了新的最先进结果。此外，固定嵌入性能与微调结果之间存在很强的正相关性，这支持了一种高效的“评估-然后-微调”方法，从而以降低的计算成本识别最佳层。这些发现强调了探索分子编码器完整表示深度对于实现显著性能改进和计算效率的重要性。代码已公开在https://github.com/luispintoc/Unlocking-Chemical-Insights。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [247] [Saffron-1: Towards an Inference Scaling Paradigm for LLM Safety Assurance](https://arxiv.org/abs/2506.06444)
> *Saffron-1：迈向LLM安全保障的推理扩展范式*

*Ruizhong Qiu, Gaotang Li, Tianxin Wei, Jingrui He, Hanghang Tong* | **Main category: cs.LG**

**Keywords:** LLM安全, 推理扩展, 多分支奖励模型, 探索-效率困境, 越狱攻击

**Comment:** 19 pages

> **TL;DR:** 现有LLM安全保障方法易受攻击，且推理扩展未应用于安全领域。本文提出SAFFRON，一种新的推理扩展范式，通过多分支奖励模型（MRM）解决探索-效率困境，提高LLM安全性。

**AI_Comments:** 这篇论文在LLM安全保障领域引入了一个新颖的视角，将推理扩展技术应用于此前未被充分探索的安全上下文。其核心创新在于提出了多分支奖励模型（MRM）来解决“探索-效率困境”，这对于降低计算成本和提高安全保障效率至关重要。通过公开发布模型和数据集，该工作对社区研究具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM安全保障主要集中于训练阶段对齐，但易受越狱攻击。同时，推理扩展在LLM推理能力上取得显著进展，但在安全保障方面尚未被探索，传统推理扩展技术在安全上下文中表现不佳。

**Method:** 提出SAFFRON，一个专门为安全保障量身定制的新型推理扩展范式。核心是引入多分支奖励模型（MRM），显著减少所需的奖励模型评估次数，以解决探索-效率困境。为实现此范式，进一步提出：(i) MRM的部分监督训练目标，(ii) 一个保守的探索约束以防止越界探索，以及 (iii) 一个基于Trie的键值缓存策略，该策略有助于在树搜索期间实现序列间的缓存共享。

**Result:** 发现传统的推理扩展技术在安全上下文中表现不佳，甚至不如Best-of-N采样。广泛的实验验证了所提方法的有效性。公开发布了训练好的多分支奖励模型（Saffron-1）和配套的token级安全奖励数据集（Safety4M）。

**Conclusion:** SAFFRON范式通过创新的MRM和相关策略，有效克服了LLM安全保障中的探索-效率困境，显著提升了LLM的安全性，并为未来的研究提供了模型和数据集资源。

> **ai_Abstract:** 针对现有LLM安全保障方法易受越狱攻击且推理扩展未应用于安全领域的现状，本文提出了SAFFRON，一个创新的推理扩展范式，旨在增强LLM的安全性。SAFFRON通过引入多分支奖励模型（MRM）来解决探索-效率困境，显著减少了奖励模型评估的计算开销。该范式还包括MRM的部分监督训练、保守探索约束和基于Trie的缓存策略。实验证明其有效性，并公开了Saffron-1模型和Safety4M数据集，以促进LLM安全研究。

> **摘要翻译:** 现有安全保障研究主要集中于训练阶段对齐，以向大型语言模型（LLMs）灌输安全行为。然而，最近的研究揭示了这些方法容易受到各种越狱攻击。与此同时，推理扩展显著提升了LLMs的推理能力，但在安全保障方面仍未被探索。为了弥补这一空白，我们的工作开创性地将推理扩展应用于LLMs的鲁棒有效安全保障，以应对新兴威胁。我们发现，传统的推理扩展技术尽管在推理任务中取得了成功，但在安全上下文中表现不佳，甚至不如像Best-of-N采样这样的基本方法。我们将这种低效归因于一个新发现的挑战——探索-效率困境，该困境源于频繁的过程奖励模型（PRM）评估所带来的高计算开销。为了克服这一困境，我们提出了SAFFRON，一个专门为安全保障量身定制的新型推理扩展范式。我们方法的核心是引入了一种多分支奖励模型（MRM），它显著减少了所需的奖励模型评估次数。为了实现这一范式，我们进一步提出了：(i) MRM的部分监督训练目标，(ii) 一个保守的探索约束以防止越界探索，以及 (iii) 一个基于Trie的键值缓存策略，该策略有助于在树搜索期间实现序列间的缓存共享。广泛的实验验证了我们方法的有效性。此外，我们公开发布了我们训练好的多分支奖励模型（Saffron-1）和配套的token级安全奖励数据集（Safety4M），以加速LLM安全领域的未来研究。我们的代码、模型和数据可在https://github.com/q-rz/saffron 公开获取，我们的项目主页是https://q-rz.github.io/p/saffron 。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [252] [Can Hessian-Based Insights Support Fault Diagnosis in Attention-based Models?](https://arxiv.org/abs/2506.07871)
> *基于Hessian的洞察能否支持基于注意力的模型中的故障诊断？*

*Sigma Jahan, Mohammad Masudur Rahman* | **Main category: cs.LG**

**Keywords:** Hessian分析, 故障诊断, 注意力模型, 深度学习, 模型调试

**Comment:** 

> **TL;DR:** 本研究探讨了使用Hessian分析来诊断大型注意力模型中的故障，发现Hessian指标在定位不稳定性和故障源方面比梯度更有效。

**AI_Comments:** 这项研究的创新之处在于提出了将Hessian分析应用于注意力模型故障诊断，这是一个新颖且重要的方向。它超越了传统的梯度分析，提供了更深层次的模型内部洞察，对于理解和调试复杂的深度学习模型具有重要意义。其潜在的应用价值在于提高大型AI系统的可靠性和可维护性。

<details>
  <summary>Details</summary>

**Motivation:** 随着基于注意力的深度学习模型规模和复杂性增加，诊断其故障变得越来越困难。

**Method:** 本研究进行了一项实证研究，使用Hessian导出的洞察力通过曲率分析识别脆弱区域，并通过参数交互分析识别注意力机制内的参数相互依赖性。

**Result:** 通过在三种不同模型（HAN、3D-CNN、DistilBERT）上的实验表明，Hessian基于的指标可以比单独的梯度更有效地定位不稳定性和查明故障源。

**Conclusion:** 实证结果表明，Hessian指标可以显著改善复杂神经网络架构中的故障诊断，并可能改进软件调试实践。

> **ai_Abstract:** 本研究探讨了Hessian分析在诊断大型注意力模型故障方面的潜力。通过曲率和参数交互分析，研究人员使用Hessian导出的洞察力来识别脆弱区域和参数相互依赖性。实验结果表明，Hessian基于的指标在定位不稳定性和故障源方面优于单独的梯度，这表明它们可以显著改善复杂神经网络架构的故障诊断，并有助于改进软件调试。

> **摘要翻译:** 随着基于注意力的深度学习模型在规模和复杂性上的扩展，诊断其故障变得越来越具有挑战性。在这项工作中，我们进行了一项实证研究，以评估基于Hessian的分析在诊断基于注意力的模型中故障的潜力。具体来说，我们使用Hessian导出的洞察力来识别注意力机制中的脆弱区域（通过曲率分析）和参数相互依赖性（通过参数交互分析）。通过在三种不同模型（HAN、3D-CNN、DistilBERT）上的实验，我们表明基于Hessian的指标可以比单独的梯度更有效地定位不稳定性和查明故障源。我们的实证结果表明，这些指标可以显著改善复杂神经网络架构中的故障诊断，从而可能改进软件调试实践。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [256] [LETS Forecast: Learning Embedology for Time Series Forecasting](https://arxiv.org/abs/2506.06454)
> *LETS Forecast: 学习时间序列预测的嵌入式方法*

*Abrar Majeedi, Viswanatha Reddy Gajjala, Satya Sai Srinath Namburi GNVV, Nada Magdi Elkordi, Yin Li* | **Main category: cs.LG**

**Keywords:** 时间序列预测, 非线性动力学, 深度学习, 经验动力学建模, Takens定理

**Comment:** Accepted at International Conference on Machine Learning (ICML) 2025

> **TL;DR:** DeepEDM是一个结合非线性动力学系统建模和深度神经网络的时间序列预测框架，通过学习潜在空间和核回归，在合成数据和真实世界时间序列上表现出鲁棒性和更高的预测精度。

**AI_Comments:** DeepEDM的创新之处在于将非线性动力学系统建模与深度神经网络有效结合，明确地解决了时间序列中复杂动力学的问题，这对于提高预测精度和模型鲁棒性至关重要。该方法通过学习潜在空间和利用核回归，为时间序列预测提供了一个新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习时间序列预测方法未能明确建模复杂非线性动力学，而理解这些潜在动力学对于精确预测至关重要。

**Method:** 本文引入了DeepEDM框架，它将非线性动力学系统建模与深度神经网络相结合。该方法受经验动力学建模（EDM）启发并植根于Takens定理，通过时间延迟嵌入学习潜在空间，并利用核回归近似潜在动力学，同时高效利用softmax注意力机制。

**Result:** DeepEDM对输入噪声具有鲁棒性，并在预测准确性方面优于最先进的方法。

**Conclusion:** DeepEDM成功地将非线性动力学系统建模与深度学习相结合，提供了一种对噪声鲁棒且预测准确性高的时间序列预测方法。

> **ai_Abstract:** 本文提出了一种名为DeepEDM的新型时间序列预测框架，旨在解决现有深度学习方法未明确建模复杂非线性动力学的问题。DeepEDM借鉴经验动力学建模和Takens定理，通过深度神经网络学习时间延迟嵌入的潜在空间，并利用核回归来近似基础动力学，同时结合高效的softmax注意力。实验结果表明，DeepEDM对输入噪声具有鲁棒性，并在合成数据和真实世界时间序列上均超越了现有最先进的预测方法。

> **摘要翻译:** 真实世界的时间序列通常受复杂的非线性动力学支配。理解这些潜在动力学对于精确的未来预测至关重要。虽然深度学习在时间序列预测方面取得了巨大成功，但许多现有方法并未明确建模动力学。为了弥补这一差距，我们引入了DeepEDM，这是一个将非线性动力学系统建模与深度神经网络相结合的框架。受经验动力学建模（EDM）的启发并植根于Takens定理，DeepEDM提出了一种新颖的深度模型，该模型从时间延迟嵌入中学习潜在空间，并采用核回归来近似潜在动力学，同时利用softmax注意力的有效实现并允许对未来时间步进行准确预测。为了评估我们的方法，我们对非线性动力学系统的合成数据以及跨领域的真实世界时间序列进行了全面实验。我们的结果表明，DeepEDM对输入噪声具有鲁棒性，并在预测准确性方面优于最先进的方法。我们的代码可在以下网址获取：https://abrarmajeedi.github.io/deep_edm。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [257] [FairPFN: A Tabular Foundation Model for Causal Fairness](https://arxiv.org/abs/2506.07049)
> *FairPFN: 因果公平的表格基础模型*

*Jake Robertson, Noah Hollmann, Samuel Müller, Noor Awad, Frank Hutter* | **Main category: cs.LG**

**Keywords:** Causal fairness, Tabular foundation model, Algorithmic discrimination, Bias mitigation, Machine learning fairness

**Comment:** 

> **TL;DR:** 机器学习系统存在偏见；FairPFN是一个新的表格基础模型，无需先验因果模型知识即可解决因果公平问题，表现优于基线方法。

**AI_Comments:** FairPFN的创新在于其作为表格基础模型，无需先验因果模型知识即可解决因果公平性问题，这显著拓宽了因果公平方法在实际复杂场景中的应用范围，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习系统在关键领域使用，但常因历史数据偏见导致社会不公。现有因果公平框架需已知因果模型，限制了其在因果模型未知或难以识别的复杂公平场景中的适用性。

**Method:** 提出FairPFN，一个预训练于合成因果公平数据的表格基础模型。它无需因果模型知识，即可识别并减轻预测中受保护属性的因果效应。

**Result:** FairPFN在多种手工设计和真实世界场景中，无需因果模型知识，仍能有效识别并消除受保护的因果效应，性能优于强大的基线方法。

**Conclusion:** FairPFN为有前景的未来研究铺平了道路，使因果公平性更易于应用于更广泛的复杂公平问题。

> **ai_Abstract:** FairPFN是一个表格基础模型，通过在合成因果公平数据上预训练，解决了现有因果公平框架需要已知因果模型的问题。它无需因果模型知识即可有效识别并消除预测中的受保护属性的因果效应，在多种场景下表现优于基线方法，从而使因果公平性更易于应用于复杂的公平问题。

> **摘要翻译:** 机器学习（ML）系统被应用于医疗、执法和金融等关键领域。然而，这些系统通常在包含人口偏见的历史数据上进行训练，导致ML决策延续或加剧现有的社会不平等。因果公平提供了一个透明的、人机协作的框架来减轻算法歧视，这与直接和间接歧视的法律原则紧密契合。然而，当前的因果公平框架存在一个关键限制，即它们假设已知正确的因果模型，这限制了它们在因果模型未知或难以识别的复杂公平场景中的适用性。为了弥补这一差距，我们提出了FairPFN，一个在合成因果公平数据上预训练的表格基础模型，用于识别和减轻其预测中受保护属性的因果效应。FairPFN的关键贡献在于它不需要因果模型的知识，并且在识别和消除各种手工设计和真实世界场景中的受保护因果效应方面，相对于强大的基线方法，仍然表现出强大的性能。FairPFN为有前景的未来研究铺平了道路，使因果公平性更易于应用于更广泛的复杂公平问题。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [263] [WISCA: A Consensus-Based Approach to Harmonizing Interpretability in Tabular Datasets](https://arxiv.org/abs/2506.06455)
> *WISCA：一种基于共识的表格数据集可解释性协调方法*

*Antonio Jesús Banegas-Luna, Horacio Pérez-Sánchez, Carlos Martínez-Cortés* | **Main category: cs.LG**

**Keywords:** 可解释性, 共识, WISCA, 表格数据集, 机器学习

**Comment:** 27 pages, 11 figures, 2 tables, 13 equations

> **TL;DR:** WISCA提出了一种新的共识方法，通过结合类概率和归一化归因来协调机器学习模型中的可解释性解释，并显示出与最可靠的个体方法一致的结果。

**AI_Comments:** 这篇论文通过提出WISCA，解决了机器学习可解释性领域中一个重要的问题：不同解释算法结果不一致。WISCA的创新点在于其结合类概率和归一化归因来生成更可靠的共识解释。这项工作对于提高机器学习模型在关键应用中的可信度和透明度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习模型通常优先考虑预测准确性，但在科学和高风险领域，可解释性仍然至关重要。然而，不同的可解释性算法经常产生相互矛盾的解释，这突出了需要共识来协调结果。

**Method:** 本研究在六个具有已知真实值的合成数据集上训练了六个机器学习模型，并利用了各种模型无关的可解释性技术。使用现有方法和一种新颖的方法：WISCA（加权缩放共识归因）生成共识解释，WISCA集成了类概率和归一化归因。

**Result:** WISCA始终与最可靠的个体方法保持一致。

**Conclusion:** 强大的共识策略在提高解释可靠性方面具有重要价值。

> **ai_Abstract:** 这项研究提出了WISCA（加权缩放共识归因），一种新的共识方法，用于协调机器学习模型中不同可解释性算法产生的相互矛盾的解释。通过在合成数据集上训练模型并应用模型无关的可解释性技术，WISCA被证明能与最可靠的个体方法保持一致，从而提高了解释的可靠性，这对于科学和高风险领域至关重要。

> **摘要翻译:** 尽管机器学习（ML）模型通常优先考虑预测准确性，但在科学和高风险领域，可解释性仍然至关重要。然而，不同的可解释性算法经常产生相互矛盾的解释，这突出了需要共识来协调结果。在本研究中，六个ML模型在六个具有已知真实值的合成数据集上进行了训练，并利用了各种模型无关的可解释性技术。使用既定方法和一种新颖的方法：WISCA（加权缩放共识归因）生成了共识解释，该方法集成了类概率和归一化归因。WISCA始终与最可靠的个体方法保持一致，这强调了稳健的共识策略在提高解释可靠性方面的价值。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [270] [When Style Breaks Safety: Defending Language Models Against Superficial Style Alignment](https://arxiv.org/abs/2506.07452)
> *当风格破坏安全时：防御语言模型对抗肤浅的风格对齐*

*Yuxin Xiao, Sana Tonekaboni, Walter Gerych, Vinith Suriyakumar, Marzyeh Ghassemi* | **Main category: cs.LG**

**Keywords:** 大型语言模型, 越狱攻击, 风格对齐, 模型安全, SafeStyle

**Comment:** 

> **TL;DR:** 研究发现，在越狱查询中添加风格模式会显著提高大型语言模型的攻击成功率，并提出了一种名为SafeStyle的防御策略，通过风格匹配的安全训练数据有效提高了模型的安全性。

**AI_Comments:** 这篇论文揭示了一个重要的LLM安全漏洞，即“肤浅的风格对齐”可能导致模型更容易被越狱。其创新之处在于量化了风格模式对攻击成功率的影响，并提出了一个简单而有效的防御策略SafeStyle。这项研究对于理解LLM的鲁棒性和开发更安全的模型具有重要意义，特别是在实际应用中需要考虑用户提示的复杂性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管风格模式与恶意意图语义无关，但它们对大型语言模型（LLMs）安全性的影响尚不明确。研究旨在理解风格模式是否会损害LLM安全性、肤浅的风格对齐如何增加模型脆弱性，以及如何最好地在对齐过程中减轻这些风险。

**Method:** 研究评估了32个LLMs在七个越狱基准测试上的表现，以观察带有风格模式的恶意查询如何影响攻击成功率（ASR）。随后，调查了肤浅的风格对齐，发现用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。最后，提出了一种名为SafeStyle的防御策略，该策略通过将少量安全训练数据进行增强，使其与微调数据中的风格模式分布匹配，并在三个LLMs和五种微调风格设置中进行了评估。

**Result:** 研究发现，带有风格模式的恶意查询几乎对所有模型都提高了攻击成功率（ASR）。ASR的提高与风格模式的长度以及LLM对它们的相对注意力相关。用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。提出的SafeStyle防御策略在保持LLM安全性方面始终优于基线方法。

**Conclusion:** 风格模式会显著增加大型语言模型（LLMs）的越狱脆弱性。通过引入与微调风格分布匹配的增强安全训练数据（SafeStyle），可以有效地防御这种攻击，显著提高模型的安全性。

> **ai_Abstract:** 这项研究探讨了在大型语言模型（LLMs）的越狱查询中引入“风格模式”如何影响模型安全性。研究发现，即使风格与恶意意图无关，它们也能显著提高攻击成功率，且这种脆弱性与风格模式的长度和模型的注意力分配有关。此外，用特定风格进行微调会使LLMs更容易受到相同风格的越狱。为解决此问题，论文提出了SafeStyle防御策略，通过将少量安全训练数据与微调数据中的风格模式分布相匹配，有效提升了LLMs的安全性。

> **摘要翻译:** 大型语言模型（LLMs）可以用特定的风格（例如，将响应格式化为列表）进行提示，包括在越狱查询中。尽管这些风格模式在语义上与越狱查询背后的恶意意图无关，但它们的安全影响仍不清楚。在这项工作中，我们试图了解风格模式是否会损害LLM的安全性，肤浅的风格对齐如何增加模型的脆弱性，以及如何在对齐过程中最好地减轻这些风险。我们评估了32个LLM在七个越狱基准测试上的表现，发现带有风格模式的恶意查询几乎对所有模型都提高了攻击成功率（ASR）。值得注意的是，ASR的提高与风格模式的长度以及LLM对它们的相对注意力相关。然后，我们调查了肤浅的风格对齐，发现用特定风格进行微调会使LLMs更容易受到相同风格的越狱攻击。最后，我们提出了SafeStyle，这是一种防御策略，它结合了少量安全训练数据，并将其增强以匹配微调数据中的风格模式分布。在三个LLM和五种微调风格设置中，SafeStyle在保持LLM安全性方面始终优于基线方法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [274] [The Universality Lens: Why Even Highly Over-Parametrized Models Learn Well](https://arxiv.org/abs/2506.07661)
> *普适性视角：为什么即使是高度过参数化的模型也能很好地学习*

*Meir Feder, Ruediger Urbanke, Yaniv Fogel* | **Main category: cs.LG**

**Keywords:** 过参数化, 泛化, 信息论, 贝叶斯学习, 模型简单性

**Comment:** 

> **TL;DR:** 该研究通过信息论视角解释了为什么过度参数化模型能够很好地泛化：学习器的遗憾不取决于假设类的整体大小，而是取决于与真实数据生成过程接近的模型的累积概率（即“权重”）。这一概念解释了过参数化模型中简单假设的存在如何避免过拟合。

**AI_Comments:** 该论文为过度参数化模型的泛化能力提供了一个新颖的信息论视角，超越了传统的复杂性度量。引入“假设权重”的概念，为大型模型为何仍能找到简单解并避免过拟合提供了直观且严格的解释，有效连接了理论理解与平坦极小值和模型蒸馏等实际现象。其在不同学习设置下的广泛适用性也增强了其重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现代机器学习中的一个基本问题是，为什么像深度神经网络和Transformer这样的大型、过参数化模型，即使其参数数量远超训练样本，也倾向于很好地泛化。

**Method:** 该研究通过信息论的视角，以普适学习理论为基础进行探究。具体研究了一个具有对数损失和（几乎）均匀先验的贝叶斯混合学习器在广阔假设类上的表现。此外，还通过Langevin动力学的随机梯度下降与理论学习器进行连接，以弥合理论与实践。

**Result:** 研究发现，学习器的遗憾不取决于假设类的整体大小，而是由所有在Kullback-Leibler散度距离上接近真实数据生成过程的模型的累积概率（称为假设的“权重”）决定。这引出了模型简单性的概念：简单模型权重高，需要更少样本泛化；复杂模型权重低，需要更多数据。分析产生了非均匀遗憾界。

**Conclusion:** 过参数化模型之所以能够避免过拟合，是因为当数据支持时，简单假设的存在使得后验能够集中在它们上。该研究为现代AI系统的泛化行为提供了统一和原则性的理解，并与平坦极小值和模型蒸馏等实践概念相吻合。这些结果广泛适用于在线、批量和监督学习设置。

> **ai_Abstract:** 该论文通过信息论和普适学习理论，探讨了过度参数化模型泛化能力强的深层原因。研究表明，贝叶斯学习器的遗憾并非由假设类的总大小决定，而是取决于与真实数据生成过程接近的模型的累积概率（即“权重”）。这一发现解释了大型模型中简单假设的存在如何有效避免过拟合，并与平坦极小值等实际现象相符。此外，理论学习器可通过结合集成学习的标准机器学习方法进行近似，为理解现代AI系统的泛化行为提供了统一且原则性的视角。

> **摘要翻译:** 现代机器学习中的一个基本问题是，为什么大型的、过参数化的模型，例如深度神经网络和Transformer，即使它们的参数数量远远超过训练样本数量，也倾向于很好地泛化。
我们通过信息论的视角，以普适学习理论为基础，研究了这一现象。具体来说，我们研究了一个在广阔假设类上具有对数损失和（几乎）均匀先验的贝叶斯混合学习器。
我们的关键结果表明，学习器的遗憾不取决于假设类的整体大小，而是取决于所有在Kullback-Leibler散度距离上接近真实数据生成过程的模型的累积概率。我们将这种累积概率称为假设的权重。
这引出了模型简单性的一个自然概念：简单模型是那些具有大权重因此需要更少样本来泛化的模型，而复杂模型具有小权重因此需要更多数据。这种观点为过参数化模型为何经常避免过拟合提供了严谨而直观的解释：当数据支持时，简单假设的存在使得后验能够集中在它们上。
我们通过回顾带有Langevin动力学的随机梯度下降从正确的后验分布中采样，进一步弥合了理论与实践之间的鸿沟，使得我们的理论学习器可以通过结合集成学习的标准机器学习方法来近似。
我们的分析产生了非均匀遗憾界，并与平坦极小值和模型蒸馏等关键实践概念相吻合。这些结果广泛适用于在线、批量和监督学习设置，为现代AI系统的泛化行为提供了统一和原则性的理解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [275] [TimeRecipe: A Time-Series Forecasting Recipe via Benchmarking Module Level Effectiveness](https://arxiv.org/abs/2506.06482)
> *TimeRecipe：一种通过基准测试模块级有效性的时间序列预测方法*

*Zhiyuan Zhao, Juntong Ni, Shangqing Xu, Haoxin Liu, Wei Jin, B. Aditya Prakash* | **Main category: cs.LG**

**Keywords:** 时间序列预测, 基准测试, 模块级评估, 设计空间探索, 模型推荐

**Comment:** 46 pages, 1 figure, 28 tables

> **TL;DR:** TimeRecipe是一个统一的基准测试框架，通过模块级评估揭示了时间序列预测模型组件的有效性，其结果表明通过探索设计空间可以超越现有SOTA模型并提供设计选择与预测场景的直观联系，并发布了推荐工具包。

**AI_Comments:** 这篇论文的创新点在于提出了一个统一的模块级基准测试框架TimeRecipe，而非传统的高层次模型评估。这种细粒度的分析有助于深入理解不同设计组件对时间序列预测性能的影响，从而指导更有效的模型构建。其重要性在于揭示了通过系统探索设计空间可以超越现有SOTA，并提供了实用的模型推荐工具包，对时间序列预测领域的模型开发和应用具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的时间序列预测模型基准测试主要在高层次进行评估，未能深入揭示不同架构和设计组件（如序列分解或归一化）在不同条件下最有效的原因，导致对特定设计为何更优的理解有限。

**Method:** 提出了TimeRecipe，一个统一的基准测试框架，用于在模块级别系统地评估时间序列预测方法。该框架进行了超过10,000次实验，以评估单个组件在各种数据集、预测范围和任务设置下的有效性。

**Result:** 结果显示，对设计空间进行详尽探索可以产生超越现有最先进方法（SOTA）的模型，并揭示将特定设计选择与预测场景联系起来的有意义的直觉。此外，TimeRecipe发布了一个实用工具包，根据这些经验洞察推荐合适的模型架构。

**Conclusion:** 通过对时间序列预测模型组件进行模块级基准测试，可以发现更优的模型设计，并为特定预测场景提供有价值的设计选择指导。

> **ai_Abstract:** TimeRecipe是一个新颖的统一基准测试框架，旨在解决时间序列预测领域中对模型架构和组件有效性缺乏深入理解的问题。它通过在模块级别进行超过10,000次实验，系统评估了不同组件在多样化条件下的表现。研究结果表明，彻底探索设计空间可以发现超越现有SOTA的模型，并提供了关于设计选择与预测场景之间关系的直观见解。此外，TimeRecipe还提供了一个基于这些发现推荐模型架构的实用工具包。

> **摘要翻译:** 时间序列预测是一项重要的任务，在各个领域都有广泛的实际应用。尽管深度学习的最新进展使时间序列预测模型能够实现准确的预测，但关于哪些架构和设计组件（例如序列分解或归一化）在不同条件下最有效仍然存在相当大的争议。现有基准主要在高层次评估模型，对某些设计为何效果更好提供的见解有限。为了弥补这一差距，我们提出了TimeRecipe，一个统一的基准测试框架，系统地在模块级别评估时间序列预测方法。TimeRecipe进行了超过10,000次实验，以评估单个组件在各种数据集、预测范围和任务设置下的有效性。我们的结果表明，对设计空间进行详尽探索可以产生超越现有最先进方法（SOTA）的模型，并揭示将特定设计选择与预测场景联系起来的有意义的直觉。此外，我们在TimeRecipe中发布了一个实用工具包，根据这些经验洞察推荐合适的模型架构。该基准可在https://github.com/AdityaLab/TimeRecipe获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [282] [A Certified Unlearning Approach without Access to Source Data](https://arxiv.org/abs/2506.06486)
> *无需访问源数据的认证遗忘方法*

*Umit Yigit Basaran, Sk Miraj Ahmed, Amit Roy-Chowdhury, Basak Guler* | **Main category: cs.LG**

**Keywords:** 认证遗忘, 数据隐私, 代理数据集, 噪声缩放, 统计距离

**Comment:** Accepted by ICML 2025

> **TL;DR:** 提出了一种无需访问原始训练数据即可实现数据遗忘的认证方法，通过代理数据集和统计距离实现。

**AI_Comments:** 该论文的关键创新在于无需访问原始训练数据即可实现认证遗忘，这解决了传统方法在实际应用中面临的重大挑战。通过引入代理数据集和基于统计距离的噪声缩放，该方法在保证模型效用的同时，提供了强大的隐私保护。文中也坦诚了实际操作中统计距离近似可能导致隐私保证减弱的局限性，增加了研究的严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 随着数据隐私法规的日益普及，从训练模型中擦除私人或受版权保护信息的能力变得至关重要。传统的遗忘方法通常假设可以访问完整的训练数据集，这在源数据不再可用的情况下是不现实的。

**Method:** 提出了一种认证遗忘框架，无需访问原始训练数据样本即可实现有效数据删除。该方法利用一个近似源数据统计特性的代理数据集，并根据两者之间的统计距离进行受控噪声缩放。同时建立了理论界限，并引入了实用的噪声校准技术。

**Result:** 结果表明，该方法在隐私敏感设置中是有效且可靠的。

**Conclusion:** 该研究提出了一种无需访问源数据的认证遗忘方法，通过使用代理数据集和统计距离进行噪声缩放，成功实现了数据遗忘，并在隐私敏感环境中表现出有效性和可靠性。

> **ai_Abstract:** 本研究提出了一种无需访问原始训练数据即可进行认证遗忘的新方法。该方法通过构建一个近似源数据统计特性的代理数据集，并基于代理数据集与源数据之间的统计距离进行受控噪声缩放，从而实现有效的数据删除。该方法在理论上建立了界限，并引入了噪声校准技术，实验证明其在隐私敏感场景中的有效性和可靠性。

> **摘要翻译:** 随着数据隐私法规的日益普及，从训练模型中擦除私人或受版权保护信息的能力已成为一项关键要求。传统的遗忘方法通常假设可以访问完整的训练数据集，这在源数据不再可用的情况下是不现实的。为了解决这一挑战，我们提出了一种认证遗忘框架，该框架无需访问原始训练数据样本即可实现有效数据删除。我们的方法利用一个近似源数据统计特性的代理数据集，并允许根据两者之间的统计距离进行受控噪声缩放。虽然我们的理论保证假设已知精确的统计距离，但实际实现通常会近似此距离，这可能导致隐私保证较弱但仍有意义。这确保了模型在遗忘后的行为具有强大的保证，同时保持其整体效用。我们建立了理论界限，引入了实用的噪声校准技术，并通过在合成和真实世界数据集上的大量实验验证了我们的方法。结果表明，我们的方法在隐私敏感设置中是有效且可靠的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [287] [Fairness Overfitting in Machine Learning: An Information-Theoretic Perspective](https://arxiv.org/abs/2506.07861)
> *机器学习中的公平性过拟合：一个信息论视角*

*Firas Laakom, Haobo Chen, Jürgen Schmidhuber, Yuheng Bu* | **Main category: cs.LG**

**Keywords:** 公平性过拟合, 信息论, 泛化误差, 互信息, 条件互信息

**Comment:** 38 pages

> **TL;DR:** 本文提出了一个信息论框架来分析机器学习中的公平性泛化误差，并推导了基于互信息和条件互信息的紧密泛化界限，经验结果验证了其有效性。

**AI_Comments:** 本文创新性地将信息论引入公平性泛化误差分析，填补了公平性过拟合研究的空白，并提供了具有理论依据和实际应用价值的指导性框架。其提出的紧密界限对于理解和改进公平性算法的泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习公平性方法缺乏公平性在未见数据上泛化的形式保证，且相较于预测性能的过拟合，公平性损失的过拟合受关注较少。

**Method:** 本文提出了一个通过信息论视角分析公平性泛化误差的理论框架。其新颖的边界技术基于Efron-Stein不等式，推导出包含互信息（MI）和条件互信息（CMI）的紧密信息论公平性泛化界限。

**Result:** 经验结果验证了这些界限在不同公平性感知学习算法中的紧密性和实际相关性。

**Conclusion:** 本文的框架为指导设计改进公平性泛化的算法提供了宝贵的见解。

> **ai_Abstract:** 本文针对机器学习模型中公平性泛化缺乏形式保证的问题，提出了一个信息论框架来分析公平性泛化误差。该框架利用Efron-Stein不等式，推导出了基于互信息和条件互信息的紧密公平性泛化界限。经验验证表明这些界限具有紧密性和实际相关性，为未来设计提升公平性泛化能力的算法提供了理论指导。

> **摘要翻译:** 尽管在利用机器学习模型促进高风险应用中的公平性方面取得了实质性进展，但现有方法通常修改训练过程，例如通过正则化器或其他干预措施，但缺乏公平性在训练期间实现的泛化到未见数据的形式保证。尽管关于预测性能的过拟合已被广泛研究，但公平性损失方面的过拟合受到的关注要少得多。本文提出了一个通过信息论视角分析公平性泛化误差的理论框架。我们新颖的边界技术基于Efron-Stein不等式，这使我们能够推导出包含互信息（MI）和条件互信息（CMI）的紧密信息论公平性泛化界限。我们的经验结果验证了这些界限在不同公平性感知学习算法中的紧密性和实际相关性。我们的框架为指导设计改进公平性泛化的算法提供了宝贵的见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [288] [Membership Inference Attacks for Unseen Classes](https://arxiv.org/abs/2506.06488)
> *针对未见类别的成员推断攻击*

*Pratiksha Thaker, Neil Kale, Zhiwei Steven Wu, Virginia Smith* | **Main category: cs.LG**

**Keywords:** 成员推断攻击, 影子模型, 分位数回归, 分布偏移, 未见类别

**Comment:** Preprint

> **TL;DR:** 本研究探讨了在对抗者无法访问完整数据子类分布的极端场景下的成员推断攻击，发现传统影子模型攻击在此设定下性能急剧下降，并提出分位数回归方法作为替代，证明其在此“类别缺失”设置中显著优于影子模型攻击。

**AI_Comments:** 这篇论文解决了成员推断攻击领域的一个重要现实挑战：当攻击者无法访问完整的背景数据分布时，传统影子模型攻击的失效问题。引入分位数回归作为替代方案具有创新性，并且实验结果表明其在“未见类别”设置下的优越性，这对于评估机器学习模型的隐私风险具有重要意义，尤其是在数据稀缺或分布不匹配的场景下，其提出的方法具有更强的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的影子模型成员推断攻击通常假设攻击者能够访问与目标模型训练数据分布匹配的背景数据分布。然而，在更极端且现实的场景中，攻击者或审计者可能无法访问分布中的整个子类，导致传统影子模型攻击的性能灾难性下降，因此需要探索新的攻击方法。

**Method:** 研究首先展示了在对抗者无法访问完整子类数据分布的“类别缺失”设置下，影子模型攻击的性能会灾难性下降。随后，论文提出并评估了分位数回归方法，证明其在克服现有方法局限性方面的潜力。研究还提供了一个理论模型来阐释该方法的潜力和局限性。

**Result:** 分位数回归攻击在类别缺失设置下始终优于影子模型攻击。例如，在CIFAR-100数据集上，分位数回归攻击在未见类别上的真阳性率（TPR）是影子模型的11倍。即使在ImageNet数据集上移除90%的训练类别，分位数回归攻击也能实现非平凡的TPR。

**Conclusion:** 在攻击者无法访问完整子类数据分布的更现实的成员推断攻击场景中，传统影子模型攻击表现不佳，而分位数回归是一种有效且显著优于传统影子模型攻击的方法，能够应对此挑战。

> **ai_Abstract:** 本研究针对成员推断攻击中攻击者无法访问完整数据子类的现实场景进行了探讨。传统影子模型攻击在此“类别缺失”设置下表现极差。论文创新性地引入了分位数回归方法，并通过实验证明其在此挑战性环境中显著优于影子模型攻击，例如在CIFAR-100和ImageNet数据集上均有优异表现，并辅以理论模型分析。

> **摘要翻译:** 影子模型攻击是机器学习模型上成员推断攻击的最新方法。然而，这些攻击通常假设攻击者可以访问与目标模型训练数据分布匹配的背景（非成员）数据分布。我们首次研究了在攻击者或审计者无法访问分布中整个子类的情况下进行的成员推断攻击——这是一种比以往研究的分布偏移更极端但更现实的版本。在这种设置下，我们首先表明影子模型攻击的性能会灾难性下降，然后证明了另一种方法——分位数回归——的前景，该方法没有相同的局限性。我们表明，分位数回归攻击在类别缺失设置下始终优于影子模型攻击——例如，在CIFAR-100上，分位数回归攻击在未见类别上的TPR是影子模型的11倍，即使在ImageNet上移除90%的训练类别也能获得非平凡的TPR。我们还提供了一个理论模型，说明了这种方法的潜力和局限性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [294] [Alternating Gradient Flows: A Theory of Feature Learning in Two-layer Neural Networks](https://arxiv.org/abs/2506.06489)
> *梯度交替流：双层神经网络特征学习理论*

*Daniel Kunin, Giovanni Luca Marchetti, Feng Chen, Dhruva Karkada, James B. Simon, Michael R. DeWeese, Surya Ganguli, Nina Miolane* | **Main category: cs.LG**

**Keywords:** 梯度交替流,特征学习,双层神经网络,训练动态,梯度流

**Comment:** 35 pages, 7 figures

> **TL;DR:** 本文提出了梯度交替流（AGF）框架，用于描述和量化双层神经网络中特征学习的动态过程，解释了损失函数呈阶梯状下降的行为，并统一了现有分析。

**AI_Comments:** 这篇论文的创新点在于提出了一个全新的算法框架AGF，它能够以一种直观且量化的方式解释双层神经网络中特征学习的动态过程，特别是损失函数呈现阶梯状下降的现象。AGF的普适性体现在它能统一并扩展现有对不同类型线性网络的分析，并首次完整刻画了二次网络中的训练动态，这对于理解神经网络的内部机制具有重要意义。该工作为神经网络特征学习的理论研究迈出了坚实的一步。

<details>
  <summary>Details</summary>

**Motivation:** 神经网络学习什么特征以及如何学习仍然是一个悬而未决的问题。

**Method:** 引入了梯度交替流（AGF）框架，该框架将梯度流在小初始化训练下的行为近似为一个交替的两步过程：在休眠神经元上最大化效用函数，在活跃神经元上最小化成本函数。AGF从所有神经元休眠开始，每一轮一个休眠神经元激活，触发特征获取和损失下降。

**Result:** 1. AGF量化了损失下降的顺序、时机和幅度，与不同架构的实验结果相符。2. AGF统一并扩展了全连接线性网络和仅注意力线性Transformer中现有的鞍点到鞍点分析，其中学习到的特征分别是奇异模态和主成分。3. 在对角线性网络中，证明了在初始化趋于零的极限下，AGF收敛于梯度流。4. 将AGF应用于训练执行模运算的二次网络，首次完整描述了训练动态，揭示了网络按系数幅度递减的顺序学习傅里叶特征。

**Conclusion:** AGF为理解神经网络中的特征学习提供了有希望的一步。

> **ai_Abstract:** 本文提出了梯度交替流（AGF）框架，旨在解决神经网络特征学习的开放性问题。AGF将双层网络在小初始化训练下的梯度流动态近似为休眠神经元效用最大化和活跃神经元成本最小化的交替过程，解释了损失函数阶梯状下降的行为。该框架量化了损失下降的顺序、时机和幅度，并统一扩展了现有对线性网络和Transformer的分析。研究证明AGF在特定条件下收敛于梯度流，并首次完整描述了二次网络中傅里叶特征的学习动态。AGF为深入理解神经网络特征学习提供了新的视角。

> **摘要翻译:** 神经网络学习什么特征以及如何学习仍然是一个悬而未决的问题。在本文中，我们引入了梯度交替流（AGF），这是一个算法框架，描述了从小型初始化训练的双层网络中特征学习的动态过程。先前的研究表明，在这种情况下，梯度流呈现出阶梯状的损失曲线，在神经元缓慢对齐到有用方向的平台期和神经元范数迅速增长的急剧下降期之间交替。AGF将这种行为近似为一个交替的两步过程：在休眠神经元上最大化效用函数，在活跃神经元上最小化成本函数。AGF从所有神经元休眠开始。在每一轮中，一个休眠神经元激活，触发特征的获取和损失的下降。AGF量化了这些下降的顺序、时机和幅度，与不同架构的实验结果相符。我们表明，AGF统一并扩展了全连接线性网络和仅注意力线性Transformer中现有的鞍点到鞍点分析，其中学习到的特征分别是奇异模态和主成分。在对角线性网络中，我们证明了在初始化趋于零的极限下，AGF收敛于梯度流。将AGF应用于训练执行模运算的二次网络，我们首次完整地描述了训练动态，揭示了网络按系数幅度递减的顺序学习傅里叶特征。总而言之，AGF为理解神经网络中的特征学习提供了一个有希望的步骤。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [298] [Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms](https://arxiv.org/abs/2506.06499)
> *质量-多样性算法用于推理的合成问题生成*

*Alex Havrilla, Edward Hughes, Mikayel Samvelyan, Jacob Abernethy* | **Main category: cs.LG**

**Keywords:** 合成数据生成, 质量-多样性算法, 大语言模型, 推理, 数据增强

**Comment:** 

> **TL;DR:** 提出SPARQ，一种通过测量解决率生成高质量和多样化合成数学问题及解决方案的方法，能显著提升模型推理能力并促进OOD泛化。

**AI_Comments:** 这篇论文的创新点在于提出了SPARQ方法，通过质量-多样性算法和解决率作为难度代理来生成大规模、高质量且多样化的合成数据，克服了传统方法对真实数据或大型模型的依赖，显著提升了模型在推理任务上的性能和泛化能力。其揭示的合成数据质量、多样性以及缩放定律对模型泛化的影响，对于未来LLM的数据增强和训练具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM驱动的合成数据生成方法在保证问题质量的同时，限制了其在更复杂和多样化问题领域的扩展性。

**Method:** 提出SPARQ，一种利用质量-多样性算法生成高质量和多样化合成数学问题与解决方案对的新方法。该方法仅使用单个模型，通过测量问题的解决率（作为问题难度的代理）来评估问题质量。从7.5K样本的种子数据集开始，生成了超过2000万个新的问题-解决方案对。

**Result:** 1. 通过难度过滤生成的数据并对同一模型进行微调，模型相对性能提升高达24%。
2. 问题难度衡量下的更高质量数据有助于更好的分布内性能。
3. 生成多样化合成数据对分布内性能的益处不强，但过滤出更多样化的数据有助于更稳健的分布外泛化。
4. 证实了合成生成问题中存在模型和数据缩放定律，这积极地促进了下游模型的泛化。

**Conclusion:** SPARQ方法通过生成高质量和多样化的合成数据，显著提升了LLM的推理能力和泛化性，并揭示了合成数据在质量、多样性和缩放定律对模型性能和泛化能力的影响。

> **ai_Abstract:** 本文提出了SPARQ，一种基于质量-多样性算法的合成问题生成方法，旨在克服现有LLM驱动合成数据生成在扩展性和多样性上的限制。SPARQ仅使用单个模型，通过测量问题解决率来生成高质量和多样化的数学问题-解决方案对。实验表明，该方法能生成大量数据（超2000万对），并通过对过滤后的数据进行微调，使模型性能提升高达24%。研究还发现，高质量数据有利于分布内性能，而多样性数据则能增强分布外泛化能力，并证实了合成数据存在模型和数据缩放定律，对模型泛化有积极影响。

> **摘要翻译:** 大型语言模型（LLM）驱动的合成数据生成已成为提高模型推理能力的强大方法。然而，大多数方法要么将大型最先进模型蒸馏成小型学生模型，要么使用自然的真实问题陈述来保证问题陈述的质量。这限制了这些方法在更复杂和多样化问题领域的扩展性。为了解决这个问题，我们提出了SPARQ：通过质量-多样性算法进行推理的合成问题生成，这是一种新颖的方法，仅使用单个模型通过测量问题的解决率（问题难度的代理）来生成高质量和多样化的合成数学问题和解决方案对。从7.5K个样本的种子数据集开始，我们生成了超过2000万个新的问题-解决方案对。我们表明，通过难度过滤生成的数据，然后对同一模型进行微调，可以将相对模型性能提高高达24%。此外，我们进行了消融研究，探讨了合成数据数量、质量和多样性对模型泛化的影响。我们发现，以问题难度衡量的更高质量有助于更好的分布内性能。此外，虽然生成多样化的合成数据对分布内性能的益处不强，但过滤出更多样化的数据有助于更稳健的分布外泛化。我们还证实了合成生成问题中存在模型和数据缩放定律，这积极地促进了下游模型的泛化。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [304] [Optimal Rates in Continual Linear Regression via Increasing Regularization](https://arxiv.org/abs/2506.06501)
> *通过增加正则化实现持续线性回归的最优速率*

*Ran Levinstein, Amit Attia, Matan Schliserman, Uri Sherman, Tomer Koren, Daniel Soudry, Itay Evron* | **Main category: cs.LG**

**Keywords:** 持续学习, 线性回归, 正则化, 最优速率, 随机梯度下降

**Comment:** 

> **TL;DR:** 本文证明了通过增加正则化可以使持续线性回归达到最优学习速率，从而缩小了现有理论中的显著差距。

**AI_Comments:** 该论文通过使用正则化解决了持续线性回归中最优速率的差距，做出了重要的理论贡献。它通过将正则化与随机梯度下降联系起来，并提出了对持续学习有益的调度策略，为减轻遗忘提供了实用的见解，这对于持续学习至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 在持续线性回归中，先前的工作在最坏情况下的预期损失的上界和下界之间存在显著差距（从 $O(1/k^{1/4})$ 到 $\Omega(1/k)$），本文旨在缩小甚至消除这一差距。

**Method:** 本文采用了两种常用正则化方案：(1) 显式各向同性 $\ell_2$ 正则化，和 (2) 通过有限步长预算的隐式正则化。研究表明，这些方法可以归结为对精心定义的替代损失进行随机梯度下降 (SGD)。在此基础上，他们识别出一种固定正则化强度可以达到近似最优速率，并通过形式化和分析一种用于时变函数的广义 SGD 变体，推导出了一个可证明达到最优速率的递增正则化强度调度。

**Result:** 固定正则化强度可实现接近最优的 $O(\log k / k)$ 速率。通过递增正则化强度调度（或减少每个任务的步数），可证明达到最优的 $O(1/k)$ 速率。

**Conclusion:** 增加正则化系数或减少每个任务的步数对于实现持续线性回归中的最优速率是有益的，至少在最坏情况下是如此。

> **ai_Abstract:** 本文解决了持续线性回归中最优速率的差距问题。研究表明，显式 $\ell_2$ 正则化和隐式正则化（它们都映射到替代损失上的随机梯度下降）可以显著提高性能。固定正则化强度可实现接近最优的 $O(\log k / k)$ 速率，而递增正则化调度则能达到最优的 $O(1/k)$ 速率，这表明此类调度在持续学习中的益处。

> **摘要翻译:** 我们研究在随机任务排序下的可实现持续线性回归，这是发展持续学习理论的常见设置。在此设置中，经过 $k$ 次学习迭代后的最坏情况预期损失存在 $\Omega(1/k)$ 的下界。然而，先前使用无正则化方案的工作仅建立了 $O(1/k^{1/4})$ 的上界，留下了显著的差距。我们的论文证明，使用两种常用正则化方案可以缩小甚至消除这一差距：(1) 显式各向同性 $\ell_2$ 正则化，和 (2) 通过有限步长预算的隐式正则化。我们表明，这些在实践中用于减轻遗忘的方法，可以归结为在精心定义的替代损失上进行随机梯度下降 (SGD)。通过这种视角，我们确定了一种固定正则化强度，可以产生接近最优的 $O(\log k / k)$ 速率。此外，通过形式化和分析一种用于时变函数的广义 SGD 变体，我们推导出了一个可证明达到最优的 $O(1/k)$ 速率的递增正则化强度调度。这表明，增加正则化系数或减少每个任务步数的调度是有益的，至少在最坏情况下是如此。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [312] [Sharp Gap-Dependent Variance-Aware Regret Bounds for Tabular MDPs](https://arxiv.org/abs/2506.06521)
> *表格MDP的尖锐依赖于间隙的方差感知遗憾界限*

*Shulun Chen, Runlong Zhou, Zihan Zhang, Maryam Fazel, Simon S. Du* | **Main category: cs.LG**

**Keywords:** MDPs, 遗憾界限, 方差感知, 次优性间隙, MVP算法

**Comment:** 30 pages

> **TL;DR:** 本文为表格MDPs的MVP算法提供了尖锐的方差感知、依赖于间隙的遗憾界限，并建立了相应的下限，证明了最大条件总方差依赖性的必要性。

**AI_Comments:** 这项工作通过引入方差感知和依赖于间隙的遗憾界限，并提供了一个匹配的下限，为表格MDPs的遗憾分析做出了重要贡献。MVP算法及其新颖的分析方法是其创新点。特别是，下限的建立有力地证明了在学习过程中考虑条件方差的重要性，即使在非条件方差较低的情况下也是如此，这对于理解强化学习算法的根本限制具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究剧集式MDPs的依赖于间隙的遗憾界限，旨在获得更尖锐的（方差感知）遗憾界限。

**Method:** 通过对次优性间隙加权和的新颖分析，证明了单调值传播（MVP）算法可以实现方差感知的依赖于间隙的遗憾界限。同时，建立了相应的下限来补充研究。

**Result:** MVP算法实现了$$\tilde{O}\left(\left(\sum_{\Delta_h(s,a)>0} \frac{H^2 \log K \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_h(s,a)} +\sum_{\Delta_h(s,a)=0}\frac{ H^2 \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_{\mathrm{min}}} + SAH^4 (S \lor H) \right) \log K\right)$$的方差感知依赖于间隙的遗憾界限。此外，建立了一个下限$$\Omega \left( \sum_{\Delta_h(s,a)>0} \frac{H^2 \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_h(s,a)}\cdot \log K\right)$$，证明了即使在最大无条件总方差接近零的情况下，对$\mathtt{Var}_{\max}^{\text{c}}$的依赖也是必要的。

**Conclusion:** 本文的结论是，对于表格MDPs，即使在最大无条件总方差接近零的情况下，对最大条件总方差($\mathtt{Var}_{\max}^{\text{c}}$)的依赖也是必要的。MVP算法能够实现尖锐的方差感知、依赖于间隙的遗憾界限。

> **ai_Abstract:** 本文研究了剧集式MDPs的依赖于间隙的遗憾界限。作者证明了单调值传播（MVP）算法能够实现一个尖锐的方差感知、依赖于间隙的遗憾界限。该界限的推导基于对次优性间隙加权和的新颖分析。为了验证结果的必要性，论文还建立了一个下限，明确指出即使在最大无条件总方差极低的情况下，对最大条件总方差$\mathtt{Var}_{\max}^{\text{c}}$的依赖也是不可或缺的。

> **摘要翻译:** 我们考虑了剧集式MDPs的依赖于间隙的遗憾界限。我们展示了单调值传播（MVP）算法实现了方差感知、依赖于间隙的遗憾界限，其形式为$$\tilde{O}\left(\left(\sum_{\Delta_h(s,a)>0} \frac{H^2 \log K \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_h(s,a)} +\sum_{\Delta_h(s,a)=0}\frac{ H^2 \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_{\mathrm{min}}} + SAH^4 (S \lor H) \right) \log K\right)$$，其中$H$是规划范围，$S$是状态数，$A$是动作数，$K$是剧集数。这里，$\Delta_h(s,a) =V_h^* (a) - Q_h^* (s, a)$表示次优性间隙，$\Delta_{\mathrm{min}} := \min_{\Delta_h (s,a) > 0} \Delta_h(s,a)$。$\mathtt{Var}_{\max}^{\text{c}}$表示最大条件总方差，计算方式为在策略$\pi$下，以轨迹访问状态$s$在步骤$h$为条件，所有$(\pi, h, s)$元组的期望总方差的最大值。$\mathtt{Var}_{\max}^{\text{c}}$表征了学习任何$(h, s)$对时遇到的最大随机性。我们的结果源于对次优性间隙加权和的新颖分析，并可能适用于其他算法。为了补充这项研究，我们建立了一个下限$$\Omega \left( \sum_{\Delta_h(s,a)>0} \frac{H^2 \land \mathtt{Var}_{\max}^{\text{c}}}{\Delta_h(s,a)}\cdot \log K\right)$$，证明了即使在最大无条件总方差（不以$(h, s)$为条件）接近零的情况下，对$\mathtt{Var}_{\max}^{\text{c}}$的依赖也是必要的。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [327] [SDN-Based False Data Detection With Its Mitigation and Machine Learning Robustness for In-Vehicle Networks](https://arxiv.org/abs/2506.06556)
> *基于SDN的车载网络虚假数据检测、缓解及其机器学习鲁棒性*

*Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Yi Li* | **Main category: cs.LG**

**Keywords:** SDN, 虚假数据检测, 车载网络, 机器学习鲁棒性, LSTM

**Comment:** The 34th International Conference on Computer Communications and
  Networks (ICCCN 2025)

> **TL;DR:** 本文提出了一种基于SDN的虚假数据检测和缓解系统（FDDMS），利用LSTM模型实时检测车载网络中的虚假数据注入攻击，并通过增强的重训练技术提高其对对抗性攻击的鲁棒性，同时实现了SDN驱动的攻击流量缓解。

**AI_Comments:** 本文的创新点在于将SDN与机器学习（LSTM）结合应用于车载网络的安全领域，特别关注了对抗性攻击的鲁棒性问题，并提出了相应的重训练和缓解策略。这对于保障日益复杂的自动驾驶车辆的通信安全具有重要意义，提供了一种实时、鲁棒的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 随着自动驾驶和联网车辆的发展，现代车辆的复杂性增加，车载网络中ECU之间的通信安全对于车辆安全至关重要。因此，需要开发一种系统来检测并缓解车载网络中日益增长的虚假数据注入攻击威胁。

**Method:** 本文提出了一个基于SDN的虚假数据检测和缓解系统（FDDMS）。首先，解码原始CAN数据以构建虚假数据注入攻击模型。FDDMS使用基于LSTM的检测模型来识别攻击。为了评估和增强模型的鲁棒性，提出了一种DeepFool攻击的变体，并通过结合阈值选择策略的重训练技术来对抗四种对抗性攻击（FGM, BIM, DeepFool, DeepFool变体）。最后，通过SDN动态更新流规则来实施攻击流量重定向的缓解方案。

**Result:** 实验结果表明，所提出的FDDMS对对抗性攻击具有鲁棒性，并且能够有效、实时地检测和缓解车载网络中的虚假数据注入攻击。

**Conclusion:** 所提出的FDDMS能够有效保障车载网络通信安全，实时检测并缓解虚假数据注入攻击，且对对抗性攻击表现出良好的鲁棒性。

> **ai_Abstract:** 本文提出了一种基于SDN的虚假数据检测和缓解系统（FDDMS），旨在实时保障车载网络安全。该系统首先通过解码CAN数据构建攻击模型，然后利用基于LSTM的检测模型识别虚假数据注入攻击。为应对对抗性攻击，研究者提出了一种DeepFool变体来评估模型鲁棒性，并通过基于阈值选择的重训练技术增强了防御能力。此外，系统还实现了基于SDN的攻击流量重定向缓解机制。实验验证了FDDMS在对抗性攻击下具有鲁棒性，并能有效实时检测和缓解虚假数据注入。

> **摘要翻译:** 随着自动驾驶和联网车辆的发展，现代车辆的复杂性不断增加，系统中集成了大量电子控制单元（ECU）。在车载网络中，这些ECU使用一种称为控制器局域网（CAN）的标准协议相互通信。确保ECU之间的通信安全在维护车辆安全方面发挥着至关重要的作用。本文提出了一种针对车载网络的基于SDN的鲁棒虚假数据检测和缓解系统（FDDMS）。FDDMS利用软件定义网络（SDN）的独特功能，旨在实时监控和检测虚假数据注入攻击。具体来说，我们专注于支持SDN的车载网络中与制动相关的ECU。首先，我们解码原始CAN数据以创建攻击模型，该模型说明了虚假数据如何注入系统。然后，FDDMS结合了基于长短期记忆（LSTM）的检测模型，用于识别虚假数据注入攻击。我们进一步提出了一种有效的DeepFool攻击变体来评估模型的鲁棒性。为了对抗包括快速梯度下降法、基本迭代法、DeepFool和DeepFool变体在内的四种对抗性攻击的影响，我们通过基于阈值的选择策略进一步增强了重训练技术方法。最后，实施了一种缓解方案，通过SDN动态更新流规则来重定向攻击流量。我们的实验结果表明，所提出的FDDMS对对抗性攻击具有鲁棒性，并能有效实时检测和缓解虚假数据注入攻击。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [332] [Rapid training of Hamiltonian graph networks without gradient descent](https://arxiv.org/abs/2506.06558)
> *无需梯度下降的哈密顿图网络快速训练*

*Atamert Rahma, Chinmay Datar, Ana Cukarska, Felix Dietrich* | **Main category: cs.LG**

**Keywords:** 哈密顿图网络, 梯度下降, 随机特征, 快速训练, 动力系统

**Comment:** 10 pages, 7 figures, 2 tables, and an appendix

> **TL;DR:** 该研究提出了一种无需梯度下降的随机特征参数构建方法，可将哈密顿图网络（HGN）的训练速度提高多达600倍，且准确性相当，并能零样本泛化到更大的系统。

**AI_Comments:** 这项工作具有重要意义，因为它打破了神经网络在物理系统建模中对梯度下降优化的依赖。通过引入随机特征参数构建，它显著提高了训练效率，同时保持了准确性和关键的物理不变性。特别值得注意的是其零样本泛化能力，这表明该模型在处理大规模复杂系统方面具有巨大潜力。这为开发更高效、可扩展的物理建模AI提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 在数据驱动建模中，学习遵守物理对称性和约束的动力系统是一个基本挑战。将物理定律与图神经网络结合可以对复杂的N体动力学进行建模，但使用迭代的、基于梯度的优化算法（如Adam、RMSProp、LBFGS）训练图神经网络通常会导致训练缓慢，特别是对于大型复杂系统。

**Method:** 该研究通过用基于随机特征的参数构建取代迭代优化，来训练哈密顿图网络（HGN）。

**Result:** 与15种不同的优化器相比，哈密顿图网络（HGN）的训练速度提高了多达600倍，但精度相当。该方法在包括N体质量-弹簧系统（在不同几何形状的3D空间中）在内的各种模拟中表现出稳健的性能，同时保留了置换、旋转和平移等基本物理不变性。即使在最小的8节点系统上训练，模型也能以零样本方式泛化到多达4096个节点的系统，无需重新训练。

**Conclusion:** 该工作挑战了迭代梯度下降优化算法在物理系统神经网络模型训练中的主导地位。

> **ai_Abstract:** 该论文提出了一种无需梯度下降即可快速训练哈密顿图网络（HGN）的新方法。通过用基于随机特征的参数构建取代传统的迭代优化，HGN的训练速度比现有优化器快600倍，同时保持相似的准确性。该模型在各种N体动力学模拟中表现出强大的鲁棒性，并能零样本泛化到远大于训练规模的系统，挑战了梯度下降在物理系统建模中的主导地位。

> **摘要翻译:** 在数据驱动建模中，学习遵守物理对称性和约束的动力系统仍然是一个基本挑战。将物理定律与图神经网络相结合有助于对复杂的N体动力学进行原则性建模，并产生准确且置换不变的模型。然而，使用迭代的、基于梯度的优化算法（例如Adam、RMSProp、LBFGS）训练图神经网络通常会导致训练缓慢，特别是对于大型复杂系统。与15种不同的优化器相比，我们证明了哈密顿图网络（HGN）可以通过用基于随机特征的参数构建取代迭代优化，从而将训练速度提高多达600倍——但准确性相当。我们展示了在各种模拟中稳健的性能，包括在具有不同几何形状的多达3维的N体质量-弹簧系统，同时保留了关于置换、旋转和平移的基本物理不变性。我们揭示，即使在最小的8节点系统上进行训练，该模型也能以零样本方式泛化到多达4096个节点的系统，无需重新训练。我们的工作挑战了迭代梯度下降优化算法在物理系统神经网络模型训练中的主导地位。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [338] [Graph Persistence goes Spectral](https://arxiv.org/abs/2506.06571)
> *图持久性走向谱域*

*Mattie Ji, Amauri H. Souza, Vikas Garg* | **Main category: cs.LG**

**Keywords:** 持久同调, 图神经网络, 谱信息, 图表示学习, 拓扑描述符

**Comment:** 24 pages, 4 figures, 6 tables

> **TL;DR:** 本文提出了SpectRe，一种新的图拓扑描述符，它将谱信息与持久同调（PH）结合，以提高GNN的表达能力，并证明其比现有方法更具表达力和局部稳定性。

**AI_Comments:** 该论文通过将谱信息与拓扑方法（PH）相结合，解决了当前图表示学习中的一个重要限制，为提高GNN超越WL层次结构的表达能力提供了一种新颖的方法。严格的表达能力证明和局部稳定性是关键的理论贡献，而实验验证则支持了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的用于图表示学习的持久同调（PH）方法，尽管通过特征来装饰PH图，但由于其对特征的依赖性，未能捕获基本的图结构信息。这限制了消息传递图神经网络（GNN）的表达能力，使其无法超越Weisfeiler-Leman（WL）层次结构，尽管已知包含像循环这样的拓扑信息可以增强表达能力。

**Method:** 本文提出了SpectRe——一种新的图拓扑描述符，它将谱信息集成到持久同调（PH）图中。此外，论文还引入了全局和局部稳定性的概念来分析现有描述符，并确定SpectRe是局部稳定的。

**Result:** SpectRe在图上的表达能力严格优于现有描述符。它被证明是局部稳定的。在合成和真实世界数据集上的实验证明了SpectRe的有效性。

**Conclusion:** SpectRe通过将谱信息集成到PH图中，有效地增强了图模型在相关学习任务中的能力，解决了以往依赖特征的方法的局限性，并证明了其卓越的表达能力和局部稳定性。

> **ai_Abstract:** 本文介绍了SpectRe，一种新颖的图拓扑描述符，它将谱信息与持久同调（PH）图相结合，以克服现有依赖特征的PH方法在捕获图结构信息方面的局限性。SpectRe被证明比现有描述符更具表达能力，并且是局部稳定的。在各种数据集上的实验结果证实了其有效性及其在学习任务中提升图模型能力的潜力。

> **摘要翻译:** 将复杂的拓扑信息（例如循环）包含在内，可以证明地增强消息传递图神经网络（GNN）的表达能力，使其超越Weisfeiler-Leman（WL）层次结构。因此，持久同调（PH）方法越来越多地被用于图表示学习。在此背景下，最近的工作提出用顶点和边缘特征来装饰经典的PH图，以提高表达能力。然而，由于它们依赖于特征，这些方法仍然无法捕获基本的图结构信息。在本文中，我们提出了SpectRe——一种新的图拓扑描述符，它将谱信息集成到PH图中。值得注意的是，SpectRe在图上的表达能力严格优于现有描述符。我们还引入了全局和局部稳定性的概念来分析现有描述符，并确定SpectRe是局部稳定的。最后，在合成和真实世界数据集上的实验证明了SpectRe的有效性及其在相关学习任务中增强图模型能力的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [347] [Demystifying Topological Message-Passing with Relational Structures: A Case Study on Oversquashing in Simplicial Message-Passing](https://arxiv.org/abs/2506.06582)
> *揭秘具有关系结构的拓扑消息传递：一个关于单纯消息传递中过挤压的案例研究*

*Diaaeldin Taha, James Chapman, Marzieh Eidi, Karel Devriendt, Guido Montúfar* | **Main category: cs.LG**

**Keywords:** 拓扑深度学习, 消息传递, 过挤压, 关系结构, 单纯复形

**Comment:** 50 pages, 12 figures, published at ICLR 2025. The Thirteenth
  International Conference on Learning Representations. 2025

> **TL;DR:** 本文提出一个统一的公理框架，通过关系结构视角连接图和拓扑消息传递，以分析和缓解拓扑深度学习中的过挤压问题。

**AI_Comments:** 本文的创新点在于提出了一个统一的公理框架，将图论与拓扑消息传递相结合，为理解和解决拓扑深度学习中的核心挑战——过挤压问题提供了新的理论工具和分析视角。这对于推动拓扑深度学习的理论发展和实际应用具有重要意义，特别是其将图论的成熟方法引入高阶结构，具有广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 拓扑深度学习（TDL）在建模关系数据中的高阶交互方面表现出色，但拓扑消息传递中的过挤压等现象仍未被充分研究，缺乏理论分析。

**Method:** 提出一个统一的公理框架，通过关系结构的视角看待单纯复形和胞腔复形及其消息传递方案，从而连接图和拓扑消息传递。

**Result:** 该方法将图论结果和算法扩展到高阶结构，有助于分析和缓解拓扑消息传递网络中的过挤压。理论分析和对单纯网络的实证研究证明了该框架推进TDL的潜力。

**Conclusion:** 通过提出一个统一的公理框架，本文成功地连接了图和拓扑消息传递，并为分析和缓解拓扑消息传递中的过挤压问题提供了有效途径，从而推动了拓扑深度学习的发展。

> **ai_Abstract:** 本文针对拓扑深度学习中拓扑消息传递的过挤压问题，提出了一个统一的公理框架。该框架通过将单纯复形和胞腔复形视为关系结构，有效地连接了图和拓扑消息传递，并成功将图论的分析方法扩展到高阶结构。理论和实证研究表明，该框架能有效分析和缓解拓扑消息传递中的过挤压现象，对推进拓扑深度学习具有重要意义。

> **摘要翻译:** 拓扑深度学习（TDL）已成为建模关系数据中高阶交互的强大工具。然而，拓扑消息传递中的过挤压等现象仍未被充分研究，且缺乏理论分析。我们提出了一个统一的公理框架，通过关系结构的视角看待单纯复形和胞腔复形及其消息传递方案，从而连接图和拓扑消息传递。这种方法将图论结果和算法扩展到高阶结构，有助于分析和缓解拓扑消息传递网络中的过挤压。通过理论分析和对单纯网络的实证研究，我们证明了该框架在推进TDL方面的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [352] [Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixtures](https://arxiv.org/abs/2506.06584)
> *过参数化高斯混合模型梯度EM的全局收敛性*

*Mo Zhou, Weihang Xu, Maryam Fazel, Simon S. Du* | **Main category: cs.LG**

**Keywords:** 高斯混合模型, 梯度EM, 全局收敛, 过参数化, 张量分解

**Comment:** 77 pages

> **TL;DR:** 本文证明了在过参数化设置下，梯度EM算法对于高斯混合模型的全局收敛性，解决了m≥3时EM算法无法恢复真实值的问题。

**AI_Comments:** 这项工作在EM算法的理论分析方面取得了重大突破，首次证明了其在过参数化设置下对高斯混合模型的全局收敛性，超越了传统理论的m=2限制。这对于理解和应用EM算法具有重要意义，尤其是在实际应用中模型经常过参数化的情况。其分析工具的创新性也值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 在精确参数化设置中，EM算法对于高斯混合模型的全局收敛性仅在m=2时得到证明，且已知当m≥3时EM无法恢复真实值。因此，需要研究在更一般情况下EM算法的收敛性。

**Method:** 本文考虑了过参数化设置（学习模型使用n>m个分量来拟合m个分量的高斯混合模型）。分析分为两个阶段，引入了高斯混合分析的新工具，使用Hermite多项式研究梯度EM的动态，并采用张量分解来表征似然损失的几何景观。

**Result:** 对于任何位置良好分离的高斯混合模型，在温和过参数化n=Ω(m log m)的条件下，随机初始化的梯度EM算法以多项式速率和多项式样本全局收敛到真实值。

**Conclusion:** 这是EM或梯度EM算法在m=2的特殊情况之外的第一个全局收敛和恢复结果。

> **ai_Abstract:** 本文研究了过参数化设置下梯度EM算法在高斯混合模型学习中的全局收敛性。针对以往EM算法在精确参数化设置中m≥3时无法保证全局收敛的问题，作者证明了在温和过参数化（n=Ω(m log m)）条件下，随机初始化的梯度EM能以多项式速率和多项式样本全局收敛到真实值。该研究通过引入Hermite多项式和张量分解等新工具，首次实现了EM或梯度EM在m=2以外的全局收敛和恢复。

> **摘要翻译:** 学习高斯混合模型（GMMs）是机器学习中的一个基本问题，期望最大化（EM）算法及其流行的变体梯度EM可以说是实践中最广泛使用的算法。在精确参数化设置中，即真实GMM和学习模型具有相同数量的组件m时，大量工作旨在为EM建立严格的恢复保证。然而，全局收敛性仅在m=2的情况下得到证明，并且已知当m≥3时EM无法恢复真实值。
在本文中，我们考虑了过参数化设置，其中学习模型使用n>m个组件来拟合m个组件的真实GMM。与精确参数化情况相反，我们为梯度EM提供了严格的全局收敛保证。具体来说，对于任何位置良好分离的GMMs，我们证明了在仅有温和过参数化n=Ω(m log m)的情况下，随机初始化的梯度EM以多项式速率和多项式样本全局收敛到真实值。我们的分析分两个阶段进行，并引入了一套用于高斯混合分析的新颖工具。我们使用Hermite多项式来研究梯度EM的动态，并采用张量分解来表征似然损失的几何景观。这是EM或梯度EM在m=2的特殊情况之外的第一个全局收敛和恢复结果。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [357] [Direct Prediction Set Minimization via Bilevel Conformal Classifier Training](https://arxiv.org/abs/2506.06599)
> *通过双层共形分类器训练实现直接预测集最小化*

*Yuanjie Shi, Hooman Shahrokhi, Xuesong Jia, Xiongzhi Chen, Janardhan Rao Doppa, Yan Yan* | **Main category: cs.LG**

**Keywords:** 共形预测, 预测集最小化, 双层优化, 深度分类器, 不确定性量化

**Comment:** Accepted for Publication at International Conference on Machine
  Learning (ICML), 2025

> **TL;DR:** 本文提出DPSM算法，通过双层优化将共形预测融入深度分类器训练，以直接最小化预测集大小，实验证明其性能优于现有方法。

**AI_Comments:** 该论文的创新之处在于首次将共形训练建模为双层优化问题，并提出DPSM算法直接在训练阶段优化预测集大小，这显著提高了共形预测的实用性。理论上，其学习界优于现有方法，具有重要的理论贡献和实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 标准的共形预测（CP）校准方法倾向于产生过大的预测集，这使得它们在实践中不太有用。因此，本文旨在将共形原则整合到深度分类器的训练过程中，以直接最小化预测集的大小。

**Method:** 本文将共形训练公式化为一个双层优化问题，并提出了直接预测集最小化（DPSM）算法来解决它。DPSM的关键在于最小化预测集大小的度量（上层），该度量以一致性分数的学习分位数（下层）为条件。文章分析了DPSM的学习界为$O(1/\sqrt{n})$。

**Result:** 实验表明，DPSM在各种基准数据集和深度模型上显著优于最佳的现有共形训练基线，预测集大小减少了20.46%，并验证了本文的理论。

**Conclusion:** DPSM算法通过将共形原则融入深度分类器训练过程，并通过双层优化直接最小化预测集大小，从而有效解决了共形预测中预测集过大的问题，提高了其实用性。

> **ai_Abstract:** 本文针对共形预测中预测集过大的问题，提出了一种名为直接预测集最小化（DPSM）的新算法。该算法将共形训练建模为双层优化问题，旨在直接在深度分类器训练过程中最小化预测集的大小。DPSM通过最小化预测集大小（上层）并以一致性分数的学习分位数（下层）为条件来实现。理论分析表明，DPSM的泛化误差界为$O(1/\sqrt{n})$，优于现有方法。实验结果显示，DPSM在多个基准数据集上显著优于现有共形训练基线，预测集大小减少了20.46%，验证了其理论优势。

> **摘要翻译:** 共形预测（CP）是一个很有前景的不确定性量化框架，它作为黑盒分类器的封装，用于构建具有可证明保证的预测集（即候选类别的子集）。然而，CP的标准校准方法倾向于产生过大的预测集，这使得它们在实践中不太有用。本文考虑将共形原则整合到深度分类器的训练过程中，以直接最小化预测集大小的问题。我们将共形训练公式化为一个双层优化问题，并提出了直接预测集最小化（DPSM）算法来解决它。DPSM背后的关键思想是最小化预测集大小的度量（上层），该度量以一致性分数的学习分位数（下层）为条件。我们分析了DPSM的学习界为$O(1/\sqrt{n})$（使用$n$个训练样本），而之前基于随机近似分位数的共形训练方法的界为$\Omega(1/s)$（使用批量大小$s$，通常$s \ll \sqrt{n}$）。在各种基准数据集和深度模型上的实验表明，DPSM显著优于最佳的现有共形训练基线，预测集大小减少了20.46%\downarrow，并验证了我们的理论。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [361] [CAtCh: Cognitive Assessment through Cookie Thief](https://arxiv.org/abs/2506.06603)
> *CAtCh: 通过“偷饼干”进行认知评估*

*Joseph T Colonel, Carolyn Hagler, Guiselle Wismer, Laura Curtis, Jacqueline Becker, Juan Wisnivesky, Alex Federman, Gaurav Pandey* | **Main category: cs.LG**

**Keywords:** 认知障碍预测, 语音分析, 机器学习, 阿尔茨海默病, 多模态分析

**Comment:** 

> **TL;DR:** 本文评估了多种机器学习算法（包括为ADRD预测设计的开源方法和多模态情感分析方法）在通过患者录音预测更广泛认知障碍（CI）方面的表现，发现多模态方法优于单模态方法，且基于声学的方法表现优于基于语言学的方法，特别是与情感和韵律相关的可解释声学特征表现显著。

**AI_Comments:** 该论文的创新之处在于将原本用于ADRD预测的语音分析方法扩展到更广泛的认知障碍（CI）预测。其重要性在于揭示了多模态方法和声学特征在早期识别CI方面的潜力，这对于ADRD的早期干预和风险管理具有重要意义。特别是强调了可解释声学特征的有效性，为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器学习算法虽能预测阿尔茨海默病及相关痴呆（ADRD），但尚未应用于更广泛的认知障碍（CI）预测，而CI有时是ADRD的前兆和风险因素。因此，本文旨在评估这些方法在CI预测任务中的有效性。

**Method:** 研究评估了多种基于语音的开源方法（最初用于ADRD预测）以及多模态情感分析方法，用于从患者音频记录中预测认知障碍（CI）。具体比较了单模态与多模态方法，以及基于声学与基于语言学的方法。

**Result:** 多模态方法在CI预测方面优于单模态方法。基于声学的方法表现优于基于语言学的方法。与情感和韵律相关的可解释声学特征显著优于基于BERT的语言特征和可解释语言特征。

**Conclusion:** 多模态方法，特别是利用声学特征（尤其是与情感和韵律相关的可解释声学特征），在通过患者语音记录预测认知障碍方面表现出卓越的性能。

> **ai_Abstract:** 本文旨在解决当前机器学习算法在预测阿尔茨海默病及相关痴呆（ADRD）后，未能有效应用于更广泛认知障碍（CI）预测的空白。研究评估了为ADRD预测开发的开源语音方法和多模态情感分析方法，在通过患者音频记录预测CI任务中的表现。结果显示，多模态方法在CI预测上优于单模态方法，且基于声学的方法优于基于语言学的方法，特别是与情感和韵律相关的可解释声学特征表现出显著优势。

> **摘要翻译:** CAtCh: 通过“偷饼干”进行认知评估

已开发出多种机器学习算法，用于从自发语音中预测阿尔茨海默病及相关痴呆（ADRD）。然而，这些算法都未能应用于更广泛的认知障碍（CI）的预测，而CI在某些情况下是ADRD的前兆和风险因素。在本文中，我们评估了几种最初用于ADRD预测的基于语音的开源方法，以及用于从患者录音中预测CI的多模态情感分析方法。结果表明，多模态方法在CI预测方面优于单模态方法，且基于声学的方法表现优于基于语言学的方法。具体而言，与情感和韵律相关的可解释声学特征被发现显著优于基于BERT的语言特征和可解释语言特征。本研究开发的所有代码均可在 https://github.com/JTColonel/catch 获取。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [365] [Stacey: Promoting Stochastic Steepest Descent via Accelerated $\ell_p$-Smooth Nonconvex Optimization](https://arxiv.org/abs/2506.06606)
> *Stacey：通过加速$\\ell_p$-光滑非凸优化促进随机最速下降*

*Xinyu Luo, Cedar Site Bai, Bolian Li, Petros Drineas, Ruqi Zhang, Brian Bullins* | **Main category: cs.LG**

**Keywords:** 优化算法, 最速下降, 非欧几里得优化, 深度学习, $\\ell_p$范数

**Comment:** 

> **TL;DR:** Stacey是一种新的加速$\\ell_p$最速下降算法，解决了深度网络训练中非欧几里得结构的处理问题，并在经验上表现出更快的收敛速度和更高的精度。

**AI_Comments:** 这篇论文的创新点在于引入了加速$\\ell_p$最速下降算法Stacey来处理深度学习中普遍存在的非欧几里得结构，这弥补了现有优化方法的一个关键空白。通过在实际任务中展示优于现有流行方法的性能，Stacey有望为深度网络训练提供更高效和精确的优化途径，特别是其对非欧几里得方法的强调具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有流行的优化方法（如SGD、AdamW和Lion）依赖于$\\ell_2$或$\\ell_\infty$范数的最速下降更新，但在处理现代深度网络训练中观察到的非欧几里得结构方面存在关键空白。

**Method:** 本文引入了一种名为Stacey的加速$\\ell_p$最速下降算法。该算法使用插值原始-对偶迭代序列来有效地处理非欧几里得光滑优化任务。

**Result:** Stacey算法提供了新颖的理论保证。在图像分类和语言模型预训练等任务上，Stacey与流行方法相比，展示了更快的收敛速度和更高的最终精度。研究还评估了不同$p$值在各种模型和数据集上的表现，强调了非欧几里得方法相对于标准欧几里得方法的重要性和效率。

**Conclusion:** Stacey算法通过处理非欧几里得结构，在深度学习优化中实现了更快的收敛和更高的精度，证明了非欧几里得方法的优越性。

> **ai_Abstract:** 本文提出了一种名为Stacey的新型加速$\\ell_p$最速下降算法，旨在解决深度学习优化中非欧几里得结构处理的难题。Stacey利用插值原始-对偶迭代序列，不仅提供了理论保证，还在图像分类和语言模型预训练等任务上，相较于SGD、AdamW和Lion等传统方法，展现出更快的收敛速度和更高的最终精度。研究还强调了非欧几里得方法在不同$p$值和数据集上的优势。

> **摘要翻译:** 虽然SGD、AdamW和Lion等流行的优化方法依赖于$\\ell_2$或$\\ell_\infty$范数的最速下降更新，但在处理现代深度网络训练中观察到的非欧几里得结构方面仍然存在关键空白。在这项工作中，我们通过引入一种新的加速$\\ell_p$最速下降算法Stacey来解决这一需求，该算法使用插值原始-对偶迭代序列来有效地处理非欧几里得光滑优化任务。除了为我们算法的基础提供新颖的理论保证外，我们还在图像分类和语言模型（LLM）预训练等任务上将我们的方法与这些流行方法进行了经验比较，证明了更快的收敛速度和更高的最终精度。我们进一步评估了不同$p$值在各种模型和数据集上的表现，强调了非欧几里得方法相对于标准欧几里得方法的重要性和效率。代码可在https://github.com/xinyuluo8561/Stacey 找到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [369] [Curriculum Reinforcement Learning from Easy to Hard Tasks Improves LLM Reasoning](https://arxiv.org/abs/2506.06632)
> *从易到难的任务课程强化学习提升大型语言模型推理能力*

*Shubham Parashar, Shurui Gui, Xiner Li, Hongyi Ling, Sushil Vemuri, Blake Olson, Eric Li, Yu Zhang, James Caverlee, Dileep Kalathil, Shuiwang Ji* | **Main category: cs.LG**

**Keywords:** 强化学习, 课程学习, 大型语言模型, 推理能力, 从易到难

**Comment:** 

> **TL;DR:** 通过从易到难的任务安排（E2H Reasoner），课程强化学习能有效提升小型LLM的推理能力，并有理论收敛保证。

**AI_Comments:** 本文的创新点在于将课程学习的思想引入到强化学习中，以解决LLM在面对复杂推理任务时单独RL训练效果不佳的问题。通过“从易到难”的任务调度，使得小型LLM也能有效提升推理能力，这对于资源有限的场景具有重要意义。理论分析也提供了坚实的支撑。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，单独使用强化学习（RL）来提升大型语言模型（LLM）在固有困难任务上的推理能力效果不佳。

**Method:** 本文提出了E2H Reasoner方法，该方法借鉴课程学习思想，将任务从易到难（E2H）进行调度，使LLM能够逐步建立推理技能。在理论上，该方法在近似策略迭代框架内建立了收敛保证，并推导了有限样本复杂度界。

**Result:** 经验上，研究发现简单任务在初期很重要，但通过适当调度逐渐减少它们对于防止过拟合至关重要。理论上，当任务被适当分解和条件化时，通过课程阶段学习所需的总样本量少于直接学习。实验表明，E2H Reasoner显著提升了小型LLM（1.5B到3B）的推理能力，解决了它们在单独使用普通RL训练时遇到的困难。

**Conclusion:** E2H Reasoner通过课程强化学习，从易到难地安排任务，有效提升了小型LLM的推理能力，解决了其在单独使用RL训练时遇到的困难，并得到了理论支持。

> **ai_Abstract:** 本文提出E2H Reasoner，一种基于课程强化学习的方法，旨在通过从易到难的任务调度来提升大型语言模型（LLM）的推理能力。该方法经验上证明了简单任务在初期重要性以及逐渐减少简单任务以防过拟合的必要性。理论上，E2H Reasoner在近似策略迭代框架下具有收敛保证，并显示出比直接学习更低的样本复杂度。实验结果表明，E2H Reasoner显著改善了小型LLM的推理能力，弥补了传统RL训练的不足。

> **摘要翻译:** 我们旨在通过强化学习（RL）提高语言模型的推理能力。最近经过RL后训练的模型，如DeepSeek-R1，已在数学和编码任务上展示了推理能力。然而，先前的研究表明，单独使用RL来提高固有困难任务的推理能力效果不佳。在此，我们从课程学习中汲取灵感，并提出将任务从易到难（E2H）进行调度，使大型语言模型（LLM）能够逐步建立推理技能。我们的方法被称为E2H Reasoner。经验上，我们观察到，尽管简单任务在初期很重要，但通过适当的调度逐渐减少它们对于防止过拟合至关重要。理论上，我们在近似策略迭代框架内为E2H Reasoner建立了收敛保证。我们推导了有限样本复杂度界，并表明当任务被适当分解和条件化时，通过课程阶段学习所需的总样本量少于直接学习。跨多个领域的实验表明，E2H Reasoner显著提高了小型LLM（1.5B到3B）的推理能力，这些模型在单独使用普通RL训练时会遇到困难，这突显了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [374] [Vision-QRWKV: Exploring Quantum-Enhanced RWKV Models for Image Classification](https://arxiv.org/abs/2506.06633)
> *Vision-QRWKV: 探索量子增强型RWKV模型用于图像分类*

*Chi-Sheng Chen* | **Main category: cs.LG**

**Keywords:** 量子机器学习, RWKV模型, 图像分类, 混合量子-经典, 变分量子电路

**Comment:** 

> **TL;DR:** Vision-QRWKV是一种混合量子-经典RWKV模型，首次应用于图像分类，通过集成变分量子电路到通道混合组件中，在多数医学和标准图像分类基准测试中表现优于其经典对应模型，尤其是在区分度细微或嘈杂的数据集上。

**AI_Comments:** 这项研究的创新之处在于首次将量子增强型RWKV模型应用于图像分类任务，并集成了变分量子电路。其重要性在于证明了量子增强在处理复杂、高维图像数据方面的潜力，尤其是在医学图像等具有挑战性的数据集上。这为开发更高效、表达能力更强的轻量级视觉模型开辟了新途径。

<details>
  <summary>Details</summary>

**Motivation:** 量子机器学习在增强经典神经网络架构方面显示出潜力，尤其是在处理复杂、高维数据时。本文旨在通过将量子增强应用于RWKV架构，提升图像分类任务中的非线性特征转换和视觉表示的表达能力。

**Method:** 本文引入了Vision-QRWKV，这是一种混合量子-经典扩展的Receptance Weighted Key Value (RWKV) 架构，首次应用于图像分类任务。该模型通过将变分量子电路（VQC）集成到RWKV的通道混合组件中，以期改善非线性特征转换并增强视觉表示的表达能力。研究在14个医学和标准图像分类基准（包括MedMNIST数据集、MNIST和FashionMNIST）上评估了经典和量子RWKV模型。

**Result:** 量子增强模型在大多数数据集上，特别是那些具有细微或嘈杂类别区分的数据集（如ChestMNIST, RetinaMNIST, BloodMNIST）上，表现优于其经典对应模型。

**Conclusion:** 本研究代表了量子增强型RWKV在视觉领域的首次系统应用，提供了关于量子模型在轻量级和高效视觉任务中架构权衡和未来潜力的见解。

> **ai_Abstract:** Vision-QRWKV是一种混合量子-经典RWKV架构，首次应用于图像分类。该模型通过将变分量子电路集成到RWKV的通道混合组件中，旨在提高非线性特征转换和视觉表示的表达能力。在14个医学和标准图像分类基准测试中，Vision-QRWKV在多数数据集上，尤其是在区分度细微或嘈杂的数据集上，性能优于经典的RWKV模型。这项研究是量子增强型RWKV在视觉领域的首次系统应用，为未来轻量级高效视觉任务中的量子模型提供了见解。

> **摘要翻译:** 近年来，量子机器学习的进展在增强经典神经网络架构方面显示出潜力，特别是在涉及复杂、高维数据的领域。本文在时间序列建模的先前工作基础上，引入了Vision-QRWKV，这是一种Receptance Weighted Key Value (RWKV) 架构的混合量子-经典扩展，首次应用于图像分类任务。通过将变分量子电路（VQC）集成到RWKV的通道混合组件中，我们的模型旨在改善非线性特征转换并增强视觉表示的表达能力。
我们在14个医学和标准图像分类基准的多元集合上评估了经典和量子RWKV模型，包括MedMNIST数据集、MNIST和FashionMNIST。我们的结果表明，量子增强模型在大多数数据集上，特别是那些具有细微或嘈杂类别区分的数据集（例如，ChestMNIST, RetinaMNIST, BloodMNIST）上，表现优于其经典对应模型。这项研究代表了量子增强型RWKV在视觉领域的首次系统应用，为轻量级和高效视觉任务中量子模型的架构权衡和未来潜力提供了见解。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [375] [Breaking Data Silos: Towards Open and Scalable Mobility Foundation Models via Generative Continual Learning](https://arxiv.org/abs/2506.06694)
> *打破数据孤岛：通过生成式持续学习迈向开放和可扩展的移动性基础模型*

*Yuan Yuan, Yukun Liu, Chonghua Han, Jie Feng, Yong Li* | **Main category: cs.LG**

**Keywords:** 移动性基础模型, 生成式持续学习, 数据孤岛, 隐私保护, 灾难性遗忘

**Comment:** 

> **TL;DR:** MoveGCL是一个通过生成式持续学习来构建移动性基础模型的框架，它在不共享原始数据的情况下，实现了可扩展、保护隐私且性能优于联邦学习的去中心化模型演化。

**AI_Comments:** MoveGCL创新性地结合了生成式持续学习、数据蒸馏和专家混合模型，在不牺牲隐私的前提下，有效解决了移动性数据孤岛和灾难性遗忘问题，为构建实用的移动性基础模型提供了重要的技术路径。其性能与联合训练相当的实验结果显示了其在实际应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有基础模型在自然语言处理和计算机视觉领域取得了巨大成功，但在人类移动性领域面临挑战，主要原因是移动性数据的隐私敏感性以及由此导致的数据孤岛问题。

**Method:** 本文提出了MoveGCL框架，通过生成式持续学习训练移动性基础模型。它不共享原始数据，而是通过回放由冻结教师模型生成的合成轨迹实现去中心化和渐进式模型演化。通过定制的蒸馏策略强化知识保留，以缓解灾难性遗忘。为解决移动模式异构性，MoveGCL整合了专家混合Transformer与移动性感知专家路由机制，并采用分层渐进式适应策略稳定持续更新。

**Result:** 在六个真实世界城市数据集上的实验表明，MoveGCL性能与联合训练相当，显著优于联邦学习基线，同时提供强大的隐私保护。

**Conclusion:** MoveGCL是解锁移动性基础模型的重要一步，为基础模型时代开放、可扩展和隐私保护的模型开发提供了实用蓝图。

> **ai_Abstract:** 本文提出了MoveGCL框架，旨在通过生成式持续学习解决移动性数据隐私敏感和数据孤岛问题，以构建开放、可扩展的移动性基础模型。MoveGCL无需共享原始数据，通过合成轨迹回放和定制蒸馏策略实现去中心化模型演化和知识保留，并采用专家混合Transformer处理异构性。实验证明其性能与联合训练相当，且优于联邦学习，同时提供强隐私保护。

> **摘要翻译:** 基础模型通过在不同任务和数据集上实现通用学习，彻底改变了自然语言处理和计算机视觉等领域。然而，由于移动性数据的隐私敏感性以及由此导致机构间的数据孤岛，为人类移动性构建类似模型仍然充满挑战。为了弥合这一差距，我们提出了MoveGCL，一个通过生成式持续学习训练移动性基础模型的可扩展和隐私保护框架。在不共享原始数据的情况下，MoveGCL通过回放由冻结教师模型生成的合成轨迹，实现了去中心化和渐进式模型演化，并通过量身定制的蒸馏策略强化知识保留，从而缓解灾难性遗忘。为了解决移动模式的异构性，MoveGCL结合了专家混合Transformer与移动性感知专家路由机制，并采用了分层渐进式适应策略来稳定持续更新。在六个真实世界城市数据集上的实验表明，MoveGCL的性能与联合训练相当，并显著优于联邦学习基线，同时提供强大的隐私保护。MoveGCL标志着解锁移动性基础模型的关键一步，为基础模型时代开放、可扩展和隐私保护的模型开发提供了实用蓝图。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [378] [Non-Intrusive Load Monitoring Based on Image Load Signatures and Continual Learning](https://arxiv.org/abs/2506.06637)
> *基于图像负荷特征和持续学习的非侵入式负荷监测*

*Olimjon Toirov, Wei Yu* | **Main category: cs.LG**

**Keywords:** 非侵入式负荷监测, 图像负荷特征, 持续学习, 深度学习, 智能电力管理

**Comment:** 10 pages, 3 figures, 2025 2nd International Conference on Digital
  Society and Artificial Intelligence (DSAI 2025), Conference dates: May 23-25,
  2025

> **TL;DR:** 一种新的非侵入式负荷监测（NILM）方法，利用图像负荷特征和持续学习，提高了识别准确性并适应新负荷。

**AI_Comments:** 该论文的创新点在于将多维电信号转化为图像负荷特征，并将其与深度学习结合，同时引入持续学习策略以解决传统NILM方法在模型泛化能力和适应新负荷方面的不足。这种结合图像特征和持续学习的方法为非侵入式负荷监测提供了一个鲁棒且适应性强的解决方案，对于智能电力管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的非侵入式负荷监测（NILM）方法面临特征鲁棒性差和模型泛化能力不足的挑战，这是由于复杂多变的负荷组合和应用环境造成的。

**Method:** 本文提出了一种结合“图像负荷特征”和持续学习的非侵入式负荷监测方法。该方法将电流、电压、功率因数等多维电信号转换为可视化图像负荷特征，并结合深度卷积神经网络进行设备识别和分类。同时，引入自监督预训练以提高特征泛化能力，并采用持续在线学习策略克服模型遗忘，以适应新负荷的出现。

**Result:** 实验结果表明，所提出的方法在识别准确性方面取得了显著提升。

**Conclusion:** 所提出的基于图像负荷特征和持续学习的非侵入式负荷监测方法能够有效提高设备识别准确性，并克服传统方法的局限性。

> **ai_Abstract:** 针对传统非侵入式负荷监测（NILM）方法在复杂多变环境下的特征鲁棒性和模型泛化能力不足的问题，本文提出了一种结合“图像负荷特征”和持续学习的新方法。该方法将多维电信号转换为图像特征，利用深度卷积神经网络进行设备识别，并通过自监督预训练和持续在线学习提升泛化能力并适应新负荷。实验结果表明，该方法显著提高了识别准确性。

> **摘要翻译:** 非侵入式负荷监测（NILM）通过分析总线上的电信号来识别电路中每个用电设备的运行状态和能耗，这对智能电力管理具有重要意义。然而，复杂多变的负荷组合和应用环境导致传统NILM方法存在特征鲁棒性差和模型泛化能力不足的挑战。为此，本文提出了一种融合“图像负荷特征”和持续学习的新型非侵入式负荷监测方法。该方法将电流、电压、功率因数等多维电信号转换为可视化图像负荷特征，并结合深度卷积神经网络实现多设备的识别和分类；同时，引入自监督预训练以提高特征泛化能力，并采用持续在线学习策略克服模型遗忘，以适应新负荷的出现。本文在高采样率负荷数据集上进行了大量实验，并与多种现有方法和模型变体进行了比较。结果表明，所提出的方法在识别准确性方面取得了显著提升。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [384] [Spark Transformer: Reactivating Sparsity in FFN and Attention](https://arxiv.org/abs/2506.06644)
> *Spark Transformer：在FFN和注意力机制中重新激活稀疏性*

*Chong You, Kan Wu, Zhipeng Jia, Lin Chen, Srinadh Bhojanapalli, Jiaxian Guo, Utku Evci, Jan Wassenberg, Praneeth Netrapalli, Jeremiah J. Willcock, Suvinay Subramanian, Felix Chern, Alek Andreev, Shreya Pathak, Felix Yu, Prateek Jain, David E. Culler, Henry M. Levy, Sanjiv Kumar* | **Main category: cs.LG**

**Keywords:** Spark Transformer, 激活稀疏性, FFN, 注意力机制, top-k

**Comment:** 

> **TL;DR:** Spark Transformer通过创新的top-k掩码和参数重分配，在保持模型质量和训练效率的同时，在FFN和注意力机制中实现了高激活稀疏性，显著降低FLOPs并提高解码速度。

**AI_Comments:** Spark Transformer的创新之处在于其对激活稀疏性的实现方式，特别是统计top-k算法的应用，解决了传统top-k操作带来的训练减速问题，并兼顾了硬件友好性。此外，通过参数重分配来预测激活条目的设计，有效缓解了强制稀疏性可能导致的质量下降。这篇论文对于提升大型Transformer模型的效率，尤其是在资源受限环境下的部署，具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有Transformer中“惰性神经元”现象促使研究人员关注激活稀疏性以提高模型效率。然而，现代Transformer放弃了ReLU激活函数，导致重新引入激活稀疏性时常伴随模型质量下降、参数增加或训练复杂/变慢等问题，稀疏注意力也面临类似挑战。

**Method:** 本文引入Spark Transformer架构，通过top-k掩码实现高激活稀疏性，明确控制稀疏水平。关键在于提出统计top-k算法，这是一种硬件加速器友好、线性时间的近似算法，避免了昂贵的排序并减轻了训练减速。此外，Spark Transformer重新分配现有FFN参数和注意力键嵌入，形成低成本预测器来识别激活条目，从而减轻质量损失并增强实际时间效益。

**Result:** Spark Transformer在标准基准测试中表现出有竞争力的性能，同时展现出显著的稀疏性：仅8%的FFN神经元被激活，每个token最多关注256个token。这种稀疏性使FLOPs减少2.5倍，在CPU上解码实际时间加速高达1.79倍，在GPU上高达1.40倍。

**Conclusion:** Spark Transformer成功地在保持模型质量和标准训练程序的同时，显著提高了FFN和注意力机制的激活稀疏性，带来了FLOPs的显著减少和实际解码时间的加速，证明了在现代Transformer中重新激活稀疏性的可行性和有效性。

> **ai_Abstract:** 本文提出Spark Transformer，一个在FFN和注意力机制中实现高激活稀疏性的新型架构。通过引入硬件友好的统计top-k近似算法和参数重分配，Spark Transformer在保持模型质量、参数量和训练效率的同时，显著降低了计算量（FLOPs减少2.5倍）并提高了推理速度（CPU上加速达1.79倍，GPU上达1.40倍），验证了其在现代Transformer中重新激活稀疏性的有效性。

> **摘要翻译:** 在训练好的Transformer中发现“惰性神经元”现象，即其前馈网络（FFN）中的绝大多数神经元对每个token都是非活跃的，这极大地激发了人们对激活稀疏性以提高大型模型效率的兴趣。尽管在将这种稀疏性转化为实际时间效益方面取得了显著进展，但现代Transformer已经放弃了对这种现象至关重要的ReLU激活函数。现有重新引入激活稀疏性的努力常常会降低模型质量、增加参数数量、使训练复杂化或变慢。稀疏注意力，即将稀疏激活应用于注意力机制，也常面临类似的挑战。
本文介绍了Spark Transformer，这是一种新颖的架构，它在FFN和注意力机制中都实现了高水平的激活稀疏性，同时保持了模型质量、参数数量和标准训练程序。我们的方法通过top-k掩码实现稀疏性，从而明确控制稀疏水平。至关重要的是，我们引入了统计top-k，这是一种硬件加速器友好、线性时间的近似算法，它避免了昂贵的排序并减轻了标准top-k操作符带来的显著训练减速。此外，Spark Transformer重新分配现有的FFN参数和注意力键嵌入，形成一个低成本的预测器，用于识别激活的条目。这种设计不仅减轻了强制稀疏性带来的质量损失，而且还增强了实际时间效益。使用Gemma-2配方进行预训练，Spark Transformer在标准基准测试中表现出有竞争力的性能，同时展现出显著的稀疏性：只有8%的FFN神经元被激活，并且每个token最多关注256个token。这种稀疏性使FLOPs减少2.5倍，在CPU上解码实际时间加速高达1.79倍，在GPU上高达1.40倍。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [385] [Differentially Private Sparse Linear Regression with Heavy-tailed Responses](https://arxiv.org/abs/2506.06861)
> *差分隐私重尾响应稀疏线性回归*

*Xizhi Tian, Meng Ding, Touming Tao, Zihang Xiang, Di Wang* | **Main category: cs.LG**

**Keywords:** 差分隐私, 稀疏线性回归, 重尾响应, 高维数据, Huber损失

**Comment:** Accepted at ECML 2025

> **TL;DR:** 本文研究了高维重尾响应的差分隐私稀疏线性回归，并提出了两种新方法（DP-IHT-H和DP-IHT-L），在理论上取得了改进的误差界限，并在实验中表现优异。

**AI_Comments:** 这篇论文解决了差分隐私领域一个重要且具有挑战性的问题，即在高维和重尾数据背景下的稀疏线性回归。其创新点在于提出了两种新的算法（DP-IHT-H和DP-IHT-L），并提供了严格的理论误差界限，特别是DP-IHT-L的误差界限独立于尾部参数ζ，这显示了其在处理重尾数据时的鲁棒性。实验验证了这些方法的有效性，表明其在实际应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的差分隐私线性回归方法主要关注常规数据分布或低维不规则数据，未能解决高维重尾响应下的差分隐私稀疏线性回归问题。

**Method:** 本文提出了两种方法：1. DP-IHT-H: 利用Huber损失和私有迭代硬阈值（private iterative hard thresholding）方法。2. DP-IHT-L: 在响应数据额外假设下，进一步改进了误差界限。

**Result:** 1. DP-IHT-H: 在(ε, δ)-DP模型下，实现了估计误差界限为 \( \tilde{O}\biggl( s^{* \frac{1 }{2}} \cdot \biggl(\frac{\log d}{n}\biggr)^{\frac{\zeta}{1 + \zeta}} + s^{* \frac{1 + 2\zeta}{2 + 2\zeta}} \cdot \biggl(\frac{\log^2 d}{n \varepsilon}\biggr)^{\frac{\zeta}{1 + \zeta}} \biggr) \)。2. DP-IHT-L: 在额外假设下，实现了估计误差界限为 \( \tilde{O}\Bigl(\frac{(s^*)^{3/2} \log d}{n \varepsilon}\Bigr) \)，该界限与尾部参数ζ无关。3. 实验结果: 在合成和真实数据集上的实验表明，本文提出的方法优于为“常规”数据设计的标准DP算法。

**Conclusion:** 本文成功解决了高维重尾响应下的差分隐私稀疏线性回归问题，并提出了理论上具有更优误差界限且在实践中表现更好的新方法。

> **ai_Abstract:** 本文针对高维重尾响应数据下的差分隐私稀疏线性回归问题进行了深入研究。作者提出了两种新方法：DP-IHT-H，它结合了Huber损失和私有迭代硬阈值技术，并在(ε, δ)-DP模型下给出了理论误差界限；以及DP-IHT-L，在额外假设下进一步优化了误差界限，使其与数据尾部特性无关。实验结果表明，这些方法在性能上超越了现有为常规数据设计的差分隐私算法。

> **摘要翻译:** 作为一个机器学习和差分隐私（DP）中的基础问题，差分隐私线性回归已被广泛研究。然而，大多数现有方法主要关注常规数据分布或低维不规则数据。为了解决这些限制，本文全面研究了高维设置下重尾响应的差分隐私稀疏线性回归。第一部分，我们介绍了DP-IHT-H方法，该方法利用Huber损失和私有迭代硬阈值技术，在(ε, δ)-DP模型下实现了估计误差界限为 \( \tilde{O}\biggl( s^{* \frac{1 }{2}} \cdot \biggl(\frac{\log d}{n}\biggr)^{\frac{\zeta}{1 + \zeta}} + s^{* \frac{1 + 2\zeta}{2 + 2\zeta}} \cdot \biggl(\frac{\log^2 d}{n \varepsilon}\biggr)^{\frac{\zeta}{1 + \zeta}} \biggr) \)，其中n是样本量，d是维度，s*是参数的稀疏度，ζ ∈ (0, 1]表征数据的尾部厚度。第二部分，我们提出了DP-IHT-L，在响应数据额外假设下进一步改善了误差界限，达到了 \( \tilde{O}\Bigl(\frac{(s^*)^{3/2} \log d}{n \varepsilon}\Bigr) \)。与第一部分的结果相比，这个界限与尾部参数ζ无关。最后，通过在合成和真实世界数据集上的实验，我们证明了我们的方法优于为“常规”数据设计的标准DP算法。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [389] [SAFER: A Calibrated Risk-Aware Multimodal Recommendation Model for Dynamic Treatment Regimes](https://arxiv.org/abs/2506.06649)
> *SAFER：一种用于动态治疗方案的校准风险感知多模态推荐模型*

*Yishan Shen, Yuyang Ye, Hui Xiong, Yong Chen* | **Main category: cs.LG**

**Keywords:** 动态治疗方案, 推荐系统, 风险感知, 多模态, 共形预测

**Comment:** Accepted by ICML 2025

> **TL;DR:** SAFER是一个针对动态治疗方案的风险感知多模态推荐模型，它整合了结构化电子健康记录和临床笔记，利用共形预测提供安全且有统计学保证的治疗建议，并在败血症数据集上表现优于现有基线。

**AI_Comments:** SAFER的创新之处在于其整合了多模态数据（结构化EHR和临床笔记）以及利用共形预测提供统计学保证，从而在精准医疗的动态治疗方案中提供了更安全、更可靠的推荐。其解决标签不确定性和提供形式保证的能力，使其在实际高风险临床应用中具有重要价值。

<details>
  <summary>Details</summary>

**Motivation:** 动态治疗方案（DTRs）在精准医疗中至关重要，但现有方法主要依赖临床医生设定的黄金标准，缺乏已知的最优策略，并且主要使用结构化电子健康记录数据，未能从临床笔记中提取有价值的信息，限制了治疗推荐的可靠性。

**Method:** 本文提出了SAFER，一个校准的风险感知表格-语言推荐框架，用于动态治疗方案。它整合了结构化电子健康记录和临床笔记，使它们能够相互学习，并通过假设已故患者的模糊最优治疗方案来解决固有的标签不确定性。此外，SAFER采用共形预测来提供统计学保证，确保安全的治疗推荐，同时过滤掉不确定的预测。

**Result:** 在两个公开可用的败血症数据集上的实验表明，SAFER在多项推荐指标和反事实死亡率方面均优于最先进的基线方法，同时提供了强大的形式保证。

**Conclusion:** 这些发现强调了SAFER作为高风险动态治疗方案应用中一个值得信赖且有理论基础的解决方案的潜力。

> **ai_Abstract:** 本文介绍了一种名为 SAFER 的新型校准风险感知多模态推荐模型，专为动态治疗方案（DTRs）设计。针对现有 DTR 推荐系统在数据利用和风险管理上的局限性，SAFER 创新性地整合了结构化电子健康记录和临床笔记，并通过共形预测提供统计学保证，确保推荐的安全性。实验结果显示，SAFER 在败血症数据集上显著优于现有基线，证明了其在高风险临床决策中的可靠性和潜力。

> **摘要翻译:** 动态治疗方案 (DTRs) 对精准医疗至关重要，通过在不断变化的临床环境中进行个性化、实时决策来优化长期结果，但需要仔细监督不安全的治疗风险。现有工作主要依赖临床医生规定的黄金标准，尽管没有已知的最优策略，并且主要使用结构化电子健康记录 (EHR) 数据，而没有从临床笔记中提取有价值的见解，这限制了其治疗建议的可靠性。在这项工作中，我们引入了 SAFER，一个校准的风险感知表格-语言 DTR 推荐框架，它整合了结构化 EHR 和临床笔记，使它们能够相互学习，并通过假设已故患者的模糊最优治疗方案来解决固有的标签不确定性。此外，SAFER 采用共形预测来提供统计学保证，确保安全的治疗建议，同时过滤掉不确定的预测。在两个公开可用的败血症数据集上的实验表明，SAFER 在多个推荐指标和反事实死亡率方面均优于最先进的基线，同时提供了强大的形式保证。这些发现强调了 SAFER 作为高风险 DTR 应用中值得信赖且具有理论基础的解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [391] [Can In-Context Reinforcement Learning Recover From Reward Poisoning Attacks?](https://arxiv.org/abs/2506.06891)
> *情境式强化学习能否从奖励中毒攻击中恢复？*

*Paulius Sasnauskas, Yiğit Yalın, Goran Radanović* | **Main category: cs.LG**

**Keywords:** 情境式强化学习, 奖励中毒攻击, 对抗训练, 决策预训练Transformer, 鲁棒性

**Comment:** 

> **TL;DR:** 本文研究了情境式强化学习（ICRL）对奖励中毒攻击的鲁棒性，并提出了对抗训练决策预训练Transformer（AT-DPT）框架，该框架在强盗机设置下显著优于现有基线，并且鲁棒性可推广到MDP环境。

**AI_Comments:** 本文提出了一种新颖的对抗训练框架AT-DPT，以解决情境式强化学习（ICRL）中决策预训练Transformer（DPT）面临的奖励中毒攻击问题。其创新点在于同时训练攻击者和防御模型，这提供了一种主动应对奖励污染的机制。该研究的重要性在于提升了ICRL在对抗环境下的鲁棒性，对于确保AI系统在恶意环境中的可靠性具有实际意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究情境式强化学习（ICRL），特别是决策预训练Transformer（DPT），在奖励中毒攻击下的腐败鲁棒性，并解决DPT面临的奖励中毒攻击挑战。

**Method:** 提出了一种新颖的对抗训练框架，称为对抗训练决策预训练Transformer（AT-DPT）。该方法同时训练一个攻击者通过毒害环境奖励来最小化DPT的真实奖励，并训练一个DPT模型从被毒害的数据中推断出最优行动。

**Result:** 所提出的AT-DPT方法在强盗机设置下，在学习型攻击者下，显著优于包括处理奖励污染的鲁棒基线在内的标准强盗机算法。在自适应攻击者下也观察到类似结果。此外，在MDP设置中的评估也证实了在强盗机场景中观察到的鲁棒性可以推广到更复杂的环境。

**Conclusion:** AT-DPT框架能够有效地抵御奖励中毒攻击，并在多种环境中展现出优越的鲁棒性，显著优于现有基线。

> **ai_Abstract:** 本文研究了情境式强化学习（ICRL）在奖励中毒攻击下的鲁棒性，并提出了对抗训练决策预训练Transformer（AT-DPT）。AT-DPT通过同时训练攻击者和DPT模型来应对奖励中毒。实验结果表明，AT-DPT在强盗机和MDP设置中均显著优于现有基线，证明了其对奖励中毒攻击的有效性和泛化能力。

> **摘要翻译:** 我们研究了情境式强化学习（ICRL）的腐败鲁棒性，重点关注决策预训练Transformer（DPT，Lee et al., 2023）。为了解决针对DPT的奖励中毒攻击的挑战，我们提出了一种新颖的对抗训练框架，称为对抗训练决策预训练Transformer（AT-DPT）。我们的方法同时训练一个攻击者，通过毒害环境奖励来最小化DPT的真实奖励，并训练一个DPT模型从被毒害的数据中推断出最优行动。我们评估了我们方法对抗标准强盗算法的有效性，包括旨在处理奖励污染的鲁棒基线。我们的结果表明，在学习型攻击者下，所提出的方法在强盗机设置中显著优于这些基线。我们还评估了AT-DPT对抗自适应攻击者的情况，并观察到类似的结果。此外，我们将评估扩展到MDP设置，证实了在强盗机场景中观察到的鲁棒性可以推广到更复杂的环境。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [395] [Rescaled Influence Functions: Accurate Data Attribution in High Dimension](https://arxiv.org/abs/2506.06656)
> *重新缩放的影响函数：高维数据归因的精确方法*

*Ittai Rubinstein, Samuel B. Hopkins* | **Main category: cs.LG**

**Keywords:** 影响函数, 数据归因, 高维, 重新缩放影响函数, 数据投毒

**Comment:** 

> **TL;DR:** 本文提出了重新缩放的影响函数（RIF），这是一种新的数据归因工具，在高维情况下比传统影响函数（IF）更准确，并且能够检测IF无法发现的数据投毒攻击。

**AI_Comments:** 该论文提出了一种改进的数据归因方法RIF，解决了传统影响函数在高维数据下精度不足的问题。其创新点在于通过重新缩放提高了归因的准确性，并且能够识别更复杂的投毒攻击，这对于模型可解释性和安全性都具有重要意义。RIF作为IF的直接替代品，易于集成，具有较高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 数据归因旨在回答训练数据如何影响模型行为的问题。现有的主要实践方法基于影响函数（IF），但IF在高维场景下常常不精确，并倾向于低估样本移除的影响，即使对于逻辑回归等简单模型也是如此。

**Method:** 本文提出了重新缩放的影响函数（RIF），它可以作为影响函数的直接替代品，计算开销小但准确性显著提高。作者将IF和RIF在一系列真实世界数据集上进行了比较，并提供了理论分析来解释其改进。

**Result:** 重新缩放的影响函数（RIF）在实践中提供了显著更好的预测，并且能够检测到基于IF方法无法发现的数据投毒攻击。

**Conclusion:** 重新缩放的影响函数（RIF）是数据归因领域的一个重要进展，它在高维数据下提供了更高的准确性，并且能有效识别传统方法无法检测的恶意数据投毒攻击。

> **ai_Abstract:** 本文针对高维数据归因中传统影响函数（IF）精度不足的问题，提出了一种新的工具——重新缩放的影响函数（RIF）。RIF作为IF的直接替代品，计算开销小，但能显著提高数据归因的准确性。实验结果表明，RIF在真实世界数据集上表现出更优的预测能力，并且能有效检测出IF无法识别的数据投毒攻击。文章还提供了理论分析来解释RIF的改进。

> **摘要翻译:** 训练数据如何影响模型的行为？这是我们希望通过数据归因来回答的问题。数据归因的主要实践方法基于影响函数（IF）。IF利用一阶泰勒近似来有效地预测从训练集中移除一组样本的影响，而无需重新训练模型，并广泛应用于各种机器学习应用中。然而，特别是在高维（参数数量 ≥ 样本数量）的情况下，它们通常不精确，并且倾向于低估样本移除的影响，即使对于逻辑回归等简单模型也是如此。我们提出了重新缩放的影响函数（RIF），这是一种新的数据归因工具，可以作为影响函数的直接替代品，计算开销小但准确性显著提高。我们将IF和RIF在一系列真实世界数据集上进行了比较，表明RIF在实践中提供了显著更好的预测，并提出了解释这种改进的理论分析。最后，我们提出了一类简单的数据投毒攻击，这些攻击会欺骗基于IF的检测，但会被RIF检测到。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [400] [SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming](https://arxiv.org/abs/2506.06665)
> *错误：AI分析失败。*

*Hong-Ming Chiu, Hao Chen, Huan Zhang, Richard Y. Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [402] [Rewriting the Budget: A General Framework for Black-Box Attacks Under Cost Asymmetry](https://arxiv.org/abs/2506.06933)
> *错误：AI分析失败。*

*Mahdi Salmani, Alireza Abdollahpoorrostam, Seyed-Mohsen Moosavi-Dezfooli* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [405] [Through the Gaps: Uncovering Tactical Line-Breaking Passes with Clustering](https://arxiv.org/abs/2506.06666)
> *错误：AI分析失败。*

*Oktay Karakuş, Hasan Arkadaş* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages and 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [410] [Learning Robust Heterogeneous Graph Representations via Contrastive-Reconstruction under Sparse Semantics](https://arxiv.org/abs/2506.06682)
> *错误：AI分析失败。*

*Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [411] [Certified Unlearning for Neural Networks](https://arxiv.org/abs/2506.06985)
> *错误：AI分析失败。*

*Anastasia Koloskova, Youssef Allouah, Animesh Jha, Rachid Guerraoui, Sanmi Koyejo* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [414] [AlphaSteer: Learning Refusal Steering with Principled Null-Space Constraint](https://arxiv.org/abs/2506.07022)
> *错误：AI分析失败。*

*Leheng Sheng, Changshuo Shen, Weixiang Zhao, Junfeng Fang, Xiaohao Liu, Zhenkai Liang, Xiang Wang, An Zhang, Tat-Seng Chua* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [417] [MarginSel : Max-Margin Demonstration Selection for LLMs](https://arxiv.org/abs/2506.06699)
> *错误：AI分析失败。*

*Rajeev Bhatt Ambati, James Lester, Shashank Srivastava, Snigdha Chaturvedi* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [422] [Do Protein Transformers Have Biological Intelligence?](https://arxiv.org/abs/2506.06701)
> *错误：AI分析失败。*

*Fudong Lin, Wanrou Du, Jinchan Liu, Tarikul Milon, Shelby Meche, Wu Xu, Xiaoqi Qin, Xu Yuan* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by European Conference on Machine Learning and Principles
  and Practice of Knowledge Discovery in Databases (ECML-PKDD 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [424] [Safety-Aware Reinforcement Learning for Control via Risk-Sensitive Action-Value Iteration and Quantile Regression](https://arxiv.org/abs/2506.06954)
> *错误：AI分析失败。*

*Clinton Enwerem, Aniruddh G. Puranic, John S. Baras, Calin Belta* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 4 figures. Submission under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [427] [A Framework for Controllable Multi-objective Learning with Annealed Stein Variational Hypernetworks](https://arxiv.org/abs/2506.06715)
> *错误：AI分析失败。*

*Minh-Duc Nguyen, Dung D. Le* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Paper is under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [432] [The OCR Quest for Generalization: Learning to recognize low-resource alphabets with model editing](https://arxiv.org/abs/2506.06761)
> *错误：AI分析失败。*

*Adrià Molina Rodríguez, Oriol Ramos Terrades, Josep Lladós* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [433] [JavelinGuard: Low-Cost Transformer Architectures for LLM Security](https://arxiv.org/abs/2506.07330)
> *错误：AI分析失败。*

*Yash Datta, Sharath Rajasekar* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 1 Figure and 5 Tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [437] [Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World](https://arxiv.org/abs/2506.06782)
> *错误：AI分析失败。*

*Qinting Jiang, Chuyang Ye, Dongyan Wei, Bingli Wang, Yuan Xue, Jingyan Jiang, Zhi Wang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [442] [Caterpillar GNN: Replacing Message Passing with Efficient Aggregation](https://arxiv.org/abs/2506.06784)
> *错误：AI分析失败。*

*Marek Černý* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 40 pages, 9 figures, 3 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [447] [TokenBreak: Bypassing Text Classification Models Through Token Manipulation](https://arxiv.org/abs/2506.07948)
> *错误：AI分析失败。*

*Kasimir Schulz, Kenneth Yeung, Kieran Evans* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [450] [Is Optimal Transport Necessary for Inverse Reinforcement Learning?](https://arxiv.org/abs/2506.06793)
> *错误：AI分析失败。*

*Zixuan Dong, Yumi Omori, Keith Ross* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 19 pages, 10 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [452] [Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning](https://arxiv.org/abs/2506.07744)
> *错误：AI分析失败。*

*Seungho Baek, Taegeon Park, Jongchan Park, Seungjun Oh, Yusung Kim* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [455] [IMPA-HGAE:Intra-Meta-Path Augmented Heterogeneous Graph Autoencoder](https://arxiv.org/abs/2506.06809)
> *错误：AI分析失败。*

*Di Lin, Wanjing Ren, Xuanbin Li, Rui Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [457] [Path Integral Optimiser: Global Optimisation via Neural Schrödinger-Föllmer Diffusion](https://arxiv.org/abs/2506.06815)
> *错误：AI分析失败。*

*Max McGuinness, Eirik Fladmark, Francisco Vargas* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages. Presented at the OPT Workshop, NeurIPS 2024, Vancouver, CA

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [461] [Curvature Enhanced Data Augmentation for Regression](https://arxiv.org/abs/2506.06853)
> *错误：AI分析失败。*

*Ilya Kaufman Sirot, Omri Azencot* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [466] [High-Fidelity Scientific Simulation Surrogates via Adaptive Implicit Neural Representations](https://arxiv.org/abs/2506.06858)
> *错误：AI分析失败。*

*Ziwei Li, Yuhan Duan, Tianyu Xiong, Yi-Tang Chen, Wei-Lun Chao, Han-Wei Shen* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [473] [SAFE: Finding Sparse and Flat Minima to Improve Pruning](https://arxiv.org/abs/2506.06866)
> *错误：AI分析失败。*

*Dongyeop Lee, Kwanhee Lee, Jinseok Chung, Namhoon Lee* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [476] [Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning](https://arxiv.org/abs/2506.06873)
> *错误：AI分析失败。*

*Armin Behnamnia, Gholamali Aminian, Alireza Aghaei, Chengchun Shi, Vincent Y. F. Tan, Hamid R. Rabiee* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted as spotlight poster in ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [479] [FREE: Fast and Robust Vision Language Models with Early Exits](https://arxiv.org/abs/2506.06884)
> *错误：AI分析失败。*

*Divya Jyoti Bajpai, Manjesh Kumar Hanawal* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** To appear at the Association of Computational Linguistics (ACL) 2025
  Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [484] [Scalable Gaussian Processes with Latent Kronecker Structure](https://arxiv.org/abs/2506.06895)
> *错误：AI分析失败。*

*Jihao Andreas Lin, Sebastian Ament, Maximilian Balandat, David Eriksson, José Miguel Hernández-Lobato, Eytan Bakshy* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** International Conference on Machine Learning 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [487] [Uncertainty Estimation on Graphs with Structure Informed Stochastic Partial Differential Equations](https://arxiv.org/abs/2506.06907)
> *错误：AI分析失败。*

*Fred Xu, Thomas Markovich* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [491] [Graph-Based Physics-Guided Urban PM2.5 Air Quality Imputation with Constrained Monitoring Data](https://arxiv.org/abs/2506.06917)
> *错误：AI分析失败。*

*Shangjie Du, Hui Wei, Dong Yoon Lee, Zhizhang Hu, Shijia Pan* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACM Transactions on Sensor Networks (TOSN) 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [494] [Basis Transformers for Multi-Task Tabular Regression](https://arxiv.org/abs/2506.06926)
> *错误：AI分析失败。*

*Wei Min Loh, Jiaqi Shang, Pascal Poupart* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [500] [Understanding Sharpness Dynamics in NN Training with a Minimalist Example: The Effects of Dataset Difficulty, Depth, Stochasticity, and More](https://arxiv.org/abs/2506.06940)
> *错误：AI分析失败。*

*Geonhui Yoo, Minhak Song, Chulhee Yun* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [504] [UdonCare: Hierarchy Pruning for Unseen Domain Discovery in Predictive Healthcare](https://arxiv.org/abs/2506.06977)
> *错误：AI分析失败。*

*Pengfei Hu, Xiaoxue Han, Fei Wang, Yue Ning* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [507] [Near Optimal Non-asymptotic Sample Complexity of 1-Identification](https://arxiv.org/abs/2506.06978)
> *错误：AI分析失败。*

*Zitian Li, Wang Chi Cheung* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [511] [MoXGATE: Modality-aware cross-attention for multi-omic gastrointestinal cancer sub-type classification](https://arxiv.org/abs/2506.06980)
> *错误：AI分析失败。*

*Sajib Acharjee Dip, Uddip Acharjee Shuvo, Dipanwita Mallick, Abrar Rahman Abir, Liqing Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 1 figure, 6 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [515] [Fully Explainable Classification Models Using Hyperblocks](https://arxiv.org/abs/2506.06986)
> *错误：AI分析失败。*

*Austin Snyder, Ryan Gallagher, Boris Kovalerchuk* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 7 pages, 8 figures, 6 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [517] [Modified K-means Algorithm with Local Optimality Guarantees](https://arxiv.org/abs/2506.06990)
> *错误：AI分析失败。*

*Mingyi Li, Michael R. Metel, Akiko Takeda* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [521] [Towards Physics-informed Diffusion for Anomaly Detection in Trajectories](https://arxiv.org/abs/2506.06999)
> *错误：AI分析失败。*

*Arun Sharma, Mingzhou Yang, Majid Farhadloo, Subhankar Ghosh, Bharat Jayaprakash, Shashi Shekhar* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [524] [Comparison of Lightweight Methods for Vehicle Dynamics-Based Driver Drowsiness Detection](https://arxiv.org/abs/2506.07014)
> *错误：AI分析失败。*

*Yutaro Nakagama, Daisuke Ishii, Kazuki Yoshizoe* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 3 figures, to be published at IV 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [527] [Mixture Experts with Test-Time Self-Supervised Aggregation for Tabular Imbalanced Regression](https://arxiv.org/abs/2506.07033)
> *错误：AI分析失败。*

*Yung-Chien Wang, Kuang-Da Wang, Wei-Yao Wang, Wen-Chih Peng* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [530] [Efficient $Q$-Learning and Actor-Critic Methods for Robust Average Reward Reinforcement Learning](https://arxiv.org/abs/2506.07040)
> *错误：AI分析失败。*

*Yang Xu, Swetha Ganesh, Vaneet Aggarwal* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** arXiv admin note: text overlap with arXiv:2502.16816

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [534] [Policy Gradient with Tree Search: Avoiding Local Optimas through Lookahead](https://arxiv.org/abs/2506.07054)
> *错误：AI分析失败。*

*Uri Koren, Navdeep Kumar, Uri Gadot, Giorgia Ramponi, Kfir Yehuda Levy, Shie Mannor* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [536] [E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models](https://arxiv.org/abs/2506.07078)
> *错误：AI分析失败。*

*Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Under Review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [538] [State Entropy Regularization for Robust Reinforcement Learning](https://arxiv.org/abs/2506.07085)
> *错误：AI分析失败。*

*Uri Koren, Yonatan Ashlag, Mirco Mutti, Esther Derman, Pierre-Luc Bacon, Shie Mannor* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [541] [Pointwise confidence estimation in the non-linear $\ell^2$-regularized least squares](https://arxiv.org/abs/2506.07088)
> *错误：AI分析失败。*

*Ilja Kuzborskij, Yasin Abbasi Yadkori* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [543] [Patient Similarity Computation for Clinical Decision Support: An Efficient Use of Data Transformation, Combining Static and Time Series Data](https://arxiv.org/abs/2506.07092)
> *病人相似度计算用于临床决策支持：数据转换、结合静态和时间序列数据的有效利用*

*Joydeb Kumar Sana, Mohammad M. Masud, M Sohel Rahman, M Saifur Rahman* | **Main category: cs.LG**

**Keywords:** 病人相似度计算, 数据转换, 临床决策支持, 时间序列数据, 分布式计算

**Comment:** This paper presents a novel distributed patient similarity
  computation (DPSC) technique based on data transformation (DT) methods,
  utilizing an effective combination of time series and static data

> **TL;DR:** 该研究提出了一种基于数据转换的分布式病人相似度计算技术，有效结合静态和时间序列数据，显著提升了预测性能并减少了计算时间。

**AI_Comments:** 这篇论文的创新点在于结合了数据转换（aWOE和Z-score）和分布式计算（分布式DTW）来处理混合类型的临床数据（静态和时间序列），以实现高效且隐私保护的病人相似度计算。其在提升预测性能和降低计算时间方面的显著成果，对于大数据背景下的临床决策支持系统具有重要实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 病人相似度计算（PSC）是医疗信息学中的一个基本问题，旨在根据患者历史临床记录测量相似度，以改善临床决策支持。

**Method:** 提出了一种新颖的分布式病人相似度计算（DPSC）技术，基于数据转换（DT）方法，有效结合时间序列数据（传感器收集，如心率、血压、血氧饱和度、呼吸等）和静态数据（患者背景和人口统计数据，如年龄、体重、身高、性别等）。静态数据通过自适应证据权重（aWOE）和Z-score数据转换处理以提高预测性能，aWOE还用于保护数据隐私。时间序列相似度使用动态时间规整（DTW），并采用分布式DTW计算来解决大数据计算耗时问题。

**Result:** 对于冠状动脉疾病，该基于DT的方法在AUC、准确性和F-measure方面分别提升了11.4%、10.20%和12.6%。对于充血性心力衰竭（CHF），该方法在相同指标上分别提升了15.9%、10.5%和21.9%。计算时间减少高达40%。

**Conclusion:** 该研究提出的结合数据转换和分布式计算的病人相似度计算方法，在提升预测性能和降低计算时间方面表现出色，对临床决策支持有显著帮助。

> **ai_Abstract:** 本文提出了一种新颖的分布式病人相似度计算（DPSC）技术，通过有效结合时间序列和静态数据，并利用数据转换（DT）方法，显著提升了临床决策支持系统的预测性能。该方法采用aWOE和Z-score对静态数据进行转换以提高性能和保护隐私，并使用分布式DTW处理时间序列数据以克服大数据计算效率问题。实验结果表明，该方法在冠状动脉疾病和充血性心力衰竭的预测任务上，性能指标（AUC、准确率、F-measure）有显著提升，同时计算时间大幅减少。

> **摘要翻译:** 病人相似度计算（PSC）是医疗信息学中的一个基本问题。病人相似度计算的目的是根据患者的历史临床记录来衡量患者之间的相似性，这有助于改善临床决策支持。本文提出了一种新颖的分布式病人相似度计算（DPSC）技术，该技术基于数据转换（DT）方法，有效结合了时间序列数据和静态数据。时间序列数据是传感器收集的患者信息，包括心率、血压、血氧饱和度、呼吸等指标。静态数据主要是患者背景和人口统计数据，包括年龄、体重、身高、性别等。静态数据已用于患者聚类。在将静态数据输入机器学习模型之前，已执行自适应证据权重（aWOE）和Z-score数据转换（DT）方法，这提高了预测性能。在基于aWOE的病人相似度模型中，敏感患者信息已使用aWOE进行处理，这保护了训练模型的数据隐私。我们使用动态时间规整（DTW）方法进行时间序列相似度计算，该方法稳健且非常流行。然而，由于计算运行时间长，DTW不适合大数据。为了克服这个问题，本研究使用了分布式DTW计算。对于冠状动脉疾病，我们基于DT的方法在AUC、准确性和F-measure方面分别将预测性能提高了11.4%、10.20%和12.6%。在充血性心力衰竭（CHF）的情况下，我们提出的方法在相同指标上分别实现了高达15.9%、10.5%和21.9%的性能提升。所提出的方法将计算时间减少了高达40%。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [545] [Filling the Missings: Spatiotemporal Data Imputation by Conditional Diffusion](https://arxiv.org/abs/2506.07099)
> *错误：AI分析失败。*

*Wenying He, Jieling Huang, Junhua Gu, Ji Zhang, Yude Bai* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages,3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [547] [Towards Universal Offline Black-Box Optimization via Learning Language Model Embeddings](https://arxiv.org/abs/2506.07109)
> *错误：AI分析失败。*

*Rong-Xi Tan, Ming Chen, Ke Xue, Yao Wang, Yaoyuan Wang, Sheng Fu, Chao Qian* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [550] [Quality-Diversity Red-Teaming: Automated Generation of High-Quality and Diverse Attackers for Large Language Models](https://arxiv.org/abs/2506.07121)
> *错误：AI分析失败。*

*Ren-Jian Wang, Ke Xue, Zeyu Qin, Ziniu Li, Sheng Tang, Hao-Tian Li, Shengcai Liu, Chao Qian* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [553] [Reliable Critics: Monotonic Improvement and Convergence Guarantees for Reinforcement Learning](https://arxiv.org/abs/2506.07134)
> *错误：AI分析失败。*

*Eshwar S. R., Gugan Thoppe, Aditya Gopalan, Gal Dalal* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 19 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [556] [AMoPO: Adaptive Multi-objective Preference Optimization without Reward Models and Reference Models](https://arxiv.org/abs/2506.07165)
> *错误：AI分析失败。*

*Qi Liu, Jingqing Ruan, Hao Li, Haodong Zhao, Desheng Wang, Jiansong Chen, Wan Guanglu, Xunliang Cai, Zhi Zheng, Tong Xu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACL 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [558] [Efficient Text-Attributed Graph Learning through Selective Annotation and Graph Alignment](https://arxiv.org/abs/2506.07168)
> *错误：AI分析失败。*

*Huanyi Xie, Lijie Hu, Lu Yu, Tianhao Huang, Longfei Li, Meng Li, Jun Zhou, Huan Wang, Di Wang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 23 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [560] [Regularized Adaptive Graph Learning for Large-Scale Traffic Forecasting](https://arxiv.org/abs/2506.07179)
> *错误：AI分析失败。*

*Kaiqi Wu, Weiyang Kong, Sen Zhang, Yubao Liu, Zitong Chen* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [562] [Learning based on neurovectors for tabular data: a new neural network approach](https://arxiv.org/abs/2506.07185)
> *错误：AI分析失败。*

*J. C. Husillos, A. Gallego, A. Roma, A. Troncoso* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Submitted to 25th IEEE International Conference on Data Mining (ICDM
  2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [564] [Analyzing Breast Cancer Survival Disparities by Race and Demographic Location: A Survival Analysis Approach](https://arxiv.org/abs/2506.07191)
> *错误：AI分析失败。*

*Ramisa Farha, Joshua O. Olukoya* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [567] [GGBall: Graph Generative Model on Poincaré Ball](https://arxiv.org/abs/2506.07198)
> *错误：AI分析失败。*

*Tianci Bu, Chuanrui Wang, Hao Ma, Haoren Zheng, Xin Lu, Tailin Wu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 29 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [570] [Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward](https://arxiv.org/abs/2506.07218)
> *通过视觉感知奖励提升多模态大语言模型的多模态推理能力*

*Tong Xiao, Xin Xu, Zhenya Huang, Hongyu Gao, Quan Liu, Qi Liu, Enhong Chen* | **Main category: cs.LG**

**Keywords:** 多模态大语言模型, 视觉感知, 强化学习, 多模态推理, 感知奖励

**Comment:** 

> **TL;DR:** 本文提出Perception-R1，通过引入视觉感知奖励来解决现有强化学习方法在多模态大语言模型（MLLMs）中忽视多模态感知能力的问题，从而有效提升MLLMs的多模态感知和推理能力，并在多个基准测试中取得了最先进的性能。

**AI_Comments:** 该论文的创新点在于明确识别并解决了现有RLVR方法在提升MLLM推理能力时忽视多模态感知能力的关键限制。通过引入专门的视觉感知奖励，Perception-R1提供了一种新颖且有效的方式来增强MLLMs的底层感知基础，这对于复杂的推理至关重要。仅使用少量训练数据（1,442个）就达到SOTA性能，这表明了该方法的效率和潜力，为未来MLLM的感知增强研究开辟了新方向。

<details>
  <summary>Details</summary>

**Motivation:** 增强多模态大语言模型（MLLMs）的多模态推理能力是一项具有挑战性的任务。现有结合可验证奖励的强化学习（RLVR）方法在提升MLLMs推理能力时，却在很大程度上忽视了作为复杂多模态推理核心前提和基础组成部分的多模态感知能力的提升。McNemar's检验发现，现有RLVR方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步改进。

**Method:** 本文提出了Perception-R1方法，其核心是引入一种新颖的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容。具体步骤包括：首先，从多模态问题的CoT轨迹中收集文本视觉标注，作为奖励分配的视觉参考。其次，在RLVR训练过程中，使用一个判断型大语言模型（judging LLM）来评估视觉标注与MLLM生成响应之间的一致性。最后，根据这些一致性判断来分配视觉感知奖励。

**Result:** 在多个多模态推理基准测试上进行的广泛实验证明了Perception-R1的有效性。该方法在大多数基准测试上取得了最先进的性能，且仅使用了1,442个训练数据。

**Conclusion:** 通过引入视觉感知奖励，Perception-R1成功解决了现有RLVR方法在提升多模态大语言模型推理能力时忽视多模态感知能力的问题，从而有效激励了MLLMs的多模态感知和推理能力，并取得了显著的性能提升。

> **ai_Abstract:** 本文针对多模态大语言模型（MLLMs）在多模态推理中忽视多模态感知能力的问题，提出了一种名为Perception-R1的新方法。该方法通过引入独特的视觉感知奖励来解决现有强化学习与可验证奖励（RLVR）方法的不足。Perception-R1通过收集视觉标注作为参考，并利用一个判断型大语言模型评估MLLM响应与视觉标注的一致性来分配奖励，从而明确鼓励MLLMs准确感知视觉内容。实验结果表明，Perception-R1在多个多模态推理基准测试上取得了最先进的性能，有效提升了MLLMs的多模态感知和推理能力。

> **摘要翻译:** 增强多模态大语言模型（MLLMs）的多模态推理能力是一项具有挑战性的任务，并日益受到社区的关注。最近，一些研究已将结合可验证奖励的强化学习（RLVR）应用于多模态领域，以增强MLLMs的推理能力。然而，这些工作在很大程度上忽视了MLLMs多模态感知能力的提升，而多模态感知能力是复杂多模态推理的核心前提和基础组成部分。通过McNemar's检验，我们发现现有的RLVR方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步改进。为了解决这一限制，我们提出了Perception-R1，它引入了一种新颖的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容，从而能有效激励它们的多模态感知和推理能力。具体而言，我们首先从多模态问题的CoT轨迹中收集文本视觉标注，这些标注将作为奖励分配的视觉参考。在RLVR训练期间，我们采用一个判断型大语言模型（judging LLM）来评估视觉标注与MLLM生成响应之间的一致性，并根据这些一致性判断来分配视觉感知奖励。在多个多模态推理基准测试上进行的广泛实验证明了我们的Perception-R1的有效性，它在大多数基准测试上使用仅1,442个训练数据就取得了最先进的性能。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [572] [VARSHAP: Addressing Global Dependency Problems in Explainable AI with Variance-Based Local Feature Attribution](https://arxiv.org/abs/2506.07229)
> *错误：AI分析失败。*

*Mateusz Gajewski, Mikołaj Morzy, Adam Karczmarz, Piotr Sankowski* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [576] [Overclocking LLM Reasoning: Monitoring and Controlling Thinking Path Lengths in LLMs](https://arxiv.org/abs/2506.07240)
> *错误：AI分析失败。*

*Roy Eisenstadt, Itamar Zimerman, Lior Wolf* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [579] [Promoting Ensemble Diversity with Interactive Bayesian Distributional Robustness for Fine-tuning Foundation Models](https://arxiv.org/abs/2506.07247)
> *错误：AI分析失败。*

*Ngoc-Quan Pham, Tuan Truong, Quyen Tran, Tan Nguyen, Dinh Phung, Trung Le* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025 (Poster)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [581] [A Stable Whitening Optimizer for Efficient Neural Network Training](https://arxiv.org/abs/2506.07254)
> *错误：AI分析失败。*

*Kevin Frans, Sergey Levine, Pieter Abbeel* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [585] [A Cramér-von Mises Approach to Incentivizing Truthful Data Sharing](https://arxiv.org/abs/2506.07272)
> *错误：AI分析失败。*

*Alex Clinton, Thomas Zeng, Yiding Chen, Xiaojin Zhu, Kirthevasan Kandasamy* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [588] [Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models](https://arxiv.org/abs/2506.07275)
> *错误：AI分析失败。*

*Haochen Song, Dominik Hofer, Rania Islambouli, Laura Hawkins, Ananya Bhattacharjee, Meredith Franklin, Joseph Jay Williams* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [591] [Tokenized Bandit for LLM Decoding and Alignment](https://arxiv.org/abs/2506.07276)
> *错误：AI分析失败。*

*Suho Shin, Chenghao Yang, Haifeng Xu, Mohammad T. Hajiaghayi* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** To appear at ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [593] [EviNet: Evidential Reasoning Network for Resilient Graph Learning in the Open and Noisy Environments](https://arxiv.org/abs/2506.07288)
> *错误：AI分析失败。*

*Weijie Guan, Haohui Wang, Jian Kang, Lihui Liu, Dawei Zhou* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** KDD 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [595] [Pre-trained Large Language Models Learn Hidden Markov Models In-context](https://arxiv.org/abs/2506.07298)
> *错误：AI分析失败。*

*Yijia Dai, Zhaolin Gao, Yahya Satter, Sarah Dean, Jennifer J. Sun* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [597] [PASS: Private Attributes Protection with Stochastic Data Substitution](https://arxiv.org/abs/2506.07308)
> *错误：AI分析失败。*

*Yizhuo Chen, Chun-Fu, Chen, Hsiang Hsu, Shaohan Hu, Tarek Abdelzaher* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [600] [Paged Attention Meets FlexAttention: Unlocking Long-Context Efficiency in Deployed Inference](https://arxiv.org/abs/2506.07311)
> *错误：AI分析失败。*

*Thomas Joshi, Herman Saini, Neil Dhillon, Antoni Viros i Martin, Kaoutar El Maghraoui* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [602] [Generative Modeling of Networked Time-Series via Transformer Architectures](https://arxiv.org/abs/2506.07312)
> *变压器架构下的网络时间序列生成建模*

*Yusuf Elnady* | **Main category: cs.LG**

**Keywords:** 生成模型, Transformer, 时间序列, 数据增强

**Comment:** 

> **TL;DR:** 针对安全领域数据有限的问题，本文提出了一种高效的基于Transformer的生成模型，用于生成高质量时间序列数据，以提升机器学习模型性能，并达到SOTA结果。

**AI_Comments:** 该研究通过改进Transformer模型，解决了安全领域数据稀缺的实际问题，其创新点在于提升了生成数据对下游ML模型性能的贡献，而非仅仅扩大数据量。实现SOTA结果和良好的泛化能力是其重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 许多安全和网络应用需要大量数据集来训练机器学习模型，但数据获取受限是一个普遍问题。现有Transformer模型生成的合成样本未能有效提升模型性能。

**Method:** 设计了一种高效的基于Transformer的生成框架，用于生成时间序列数据。

**Result:** 该新型Transformer模型取得了SOTA结果，能够跨不同数据集工作，并生成高质量样本，从而提升现有和新型ML工作流的性能。

**Conclusion:** 通过设计高效的基于Transformer的生成模型，可以有效解决安全领域数据受限问题，生成高质量时间序列数据，并显著提升机器学习模型的性能。

> **ai_Abstract:** 本文针对安全和网络应用中数据有限的问题，提出了一种高效的基于Transformer的生成模型。该模型旨在生成高质量的时间序列数据，以弥补数据不足并提升机器学习模型的性能。实验结果表明，该模型达到了最先进的性能，并具有良好的泛化能力，能够生成高质量的样本。

> **摘要翻译:** 许多安全和网络应用需要大量数据集来训练机器学习模型。有限的数据访问是安全领域的一个众所周知的问题。最近的研究表明，Transformer模型有潜力通过合成新样本来扩大数据规模，但合成样本并未比真实数据更好地改进模型。为了解决这个问题，我们设计了一种高效的基于Transformer的模型作为生成框架，用于生成时间序列数据，该数据可用于提升现有和新型机器学习工作流的性能。我们的新型Transformer模型取得了SOTA结果。我们对模型进行了设计，使其具有通用性，可在不同数据集上工作，并生成高质量样本。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [605] [DEF: Diffusion-augmented Ensemble Forecasting](https://arxiv.org/abs/2506.07324)
> *错误：AI分析失败。*

*David Millard, Arielle Carr, Stéphane Gaudreault, Ali Baheri* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 26 pages, 20 plots, journal paper

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [608] [Mobility-Aware Asynchronous Federated Learning with Dynamic Sparsification](https://arxiv.org/abs/2506.07328)
> *错误：AI分析失败。*

*Jintao Yan, Tan Chen, Yuxuan Sun, Zhaojun Nan, Sheng Zhou, Zhisheng Niu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [611] [Graph-KV: Breaking Sequence via Injecting Structural Biases into Large Language Models](https://arxiv.org/abs/2506.07334)
> *错误：AI分析失败。*

*Haoyu Wang, Peihao Wang, Mufei Li, Shikun Liu, Siqi Miao, Zhangyang Wang, Pan Li* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [616] [Moment Alignment: Unifying Gradient and Hessian Matching for Domain Generalization](https://arxiv.org/abs/2506.07378)
> *错误：AI分析失败。*

*Yuen Chen, Haozhe Si, Guojun Zhang, Han Zhao* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** UAI 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [619] [RiemannFormer: A Framework for Attention in Curved Spaces](https://arxiv.org/abs/2506.07405)
> *错误：AI分析失败。*

*Zhongping Ji* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages, 1 figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [621] [InverseScope: Scalable Activation Inversion for Interpreting Large Language Models](https://arxiv.org/abs/2506.07406)
> *错误：AI分析失败。*

*Yifan Luo, Zhennan Zhou, Bin Dong* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 18 pages, 8 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [624] [Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring Systems in Multi-Cloud Environments Based on LLM](https://arxiv.org/abs/2506.07407)
> *错误：AI分析失败。*

*Yihong Jin, Ze Yang, Juntian Liu, Xinhe Xu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Proceedings of 2025 5th International Symposium on Computer
  Technology and Information Science (ISCTIS 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [626] [Fractional-order Jacobian Matrix Differentiation and Its Application in Artificial Neural Networks](https://arxiv.org/abs/2506.07408)
> *错误：AI分析失败。*

*Xiaojun zhou, Chunna Zhao, Yaqun Huang, Chengli Zhou, Junjie Ye, Kemeng Xiang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [628] [Variational Supervised Contrastive Learning](https://arxiv.org/abs/2506.07413)
> *错误：AI分析失败。*

*Ziwen Wang, Jiajun Fan, Thao Nguyen, Heng Ji, Ge Liu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [631] [LiteVLM: A Low-Latency Vision-Language Model Inference Pipeline for Resource-Constrained Environments](https://arxiv.org/abs/2506.07416)
> *错误：AI分析失败。*

*Jin Huang, Yuchao Jin, Le An, Josh Park* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [633] [Evidential Spectrum-Aware Contrastive Learning for OOD Detection in Dynamic Graphs](https://arxiv.org/abs/2506.07417)
> *错误：AI分析失败。*

*Nan Sun, Xixun Lin, Zhiheng Zhou, Yanmin Shang, Zhenlin Cheng, Yanan Cao* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 17 pages,5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [635] [Federated In-Context Learning: Iterative Refinement for Improved Answer Quality](https://arxiv.org/abs/2506.07440)
> *错误：AI分析失败。*

*Ruhan Wang, Zhiyong Wang, Chengkai Huang, Rui Wang, Tong Yu, Lina Yao, John C. S. Lui, Dongruo Zhou* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 27 pages, 16 figures. Accepted to ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [637] [Extending Epistemic Uncertainty Beyond Parameters Would Assist in Designing Reliable LLMs](https://arxiv.org/abs/2506.07448)
> *错误：AI分析失败。*

*T. Duy Nguyen-Hien, Desi R. Ivanova, Yee Whye Teh, Wee Sun Lee* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [641] [ProteinZero: Self-Improving Protein Generation via Online Reinforcement Learning](https://arxiv.org/abs/2506.07459)
> *ProteinZero：通过在线强化学习实现蛋白质生成的自我改进*

*Ziwen Wang, Jiajun Fan, Ruihan Guo, Thao Nguyen, Heng Ji, Ge Liu* | **Main category: cs.LG**

**Keywords:** 蛋白质生成, 强化学习, 逆折叠模型, 代理奖励, 序列多样性

**Comment:** 

> **TL;DR:** ProteinZero是一个利用在线强化学习的蛋白质设计框架，通过引入高效的代理奖励模型和多样性正则化，显著提高了蛋白质生成模型的成功率、结构准确性、可设计性、热力学稳定性和序列多样性，并将设计失败率降低了36%-48%。

**AI_Comments:** ProteinZero的创新之处在于将在线强化学习引入蛋白质设计，通过自我改进机制克服了传统监督学习对高质量数据集的依赖。其引入的代理奖励模型和多样性正则化是关键的技术贡献，不仅提高了性能，还保证了效率和多样性。这项工作为蛋白质设计领域开辟了一个全新的研究范式，具有重要的科学意义和潜在应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 蛋白质生成模型在蛋白质设计方面表现出巨大潜力，但由于高质量蛋白质数据集的稀缺性，导致监督预训练不足，从而限制了其成功率。

**Method:** ProteinZero是一个新颖的框架，通过在线强化学习实现逆折叠模型的规模化、自动化和持续自我改进。它引入了基于ESM-fold和新型快速ddG预测器的有效代理奖励模型，以加速评估。该框架采用通用的强化学习方法，平衡多奖励最大化、与参考模型的KL散度以及蛋白质嵌入层面的多样性正则化，以防止模式崩溃并促进更高的序列多样性。

**Result:** ProteinZero在蛋白质设计的各个关键指标上显著优于现有方法，在结构准确性、可设计性、热力学稳定性、序列多样性方面取得了显著改进。它将设计失败率比ProteinMPNN、ESM-IF和InstructPLM等广泛使用的方法降低了约36%-48%，在不同复杂蛋白质折叠中始终实现超过90%的成功率。此外，整个强化学习过程在单个8 X GPU节点上可在3天内完成，包括奖励计算。

**Conclusion:** ProteinZero为蛋白质设计建立了一个新范式，模型可以从自身生成的输出中持续进化，为探索广阔的蛋白质设计空间开辟了新的可能性。

> **ai_Abstract:** ProteinZero是一个利用在线强化学习实现蛋白质生成模型自我改进的新框架。它通过引入高效的代理奖励模型和新颖的蛋白质嵌入多样性正则化，克服了高质量蛋白质数据稀缺的限制。实验证明，ProteinZero在结构准确性、可设计性、热力学稳定性、序列多样性等关键指标上显著优于现有方法，并将设计失败率降低了36%-48%，在复杂蛋白质折叠中实现了超过90%的成功率。该方法高效且可扩展，为蛋白质设计开辟了模型持续进化的新途径。

> **摘要翻译:** 蛋白质生成模型在蛋白质设计方面展现出卓越的潜力，但由于高质量蛋白质数据集的稀缺性，导致监督预训练不足，其成功率仍然面临限制。我们提出了ProteinZero，这是一个新颖的框架，通过在线强化学习实现逆折叠模型的规模化、自动化和持续自我改进。为了实现计算上可行的在线反馈，我们引入了基于ESM-fold和新型快速ddG预测器的高效代理奖励模型，显著加速了评估速度。ProteinZero采用通用的强化学习框架，平衡多奖励最大化、与参考模型的KL散度以及新颖的蛋白质嵌入层面的多样性正则化，以防止模式崩溃同时促进更高的序列多样性。通过广泛的实验，我们证明ProteinZero在蛋白质设计的每个关键指标上都显著优于现有方法，在结构准确性、可设计性、热力学稳定性以及序列多样性方面取得了显著改进。最令人印象深刻的是，与ProteinMPNN、ESM-IF和InstructPLM等广泛使用的方法相比，ProteinZero将设计失败率降低了约36% - 48%，在多样化和复杂的蛋白质折叠中始终实现超过90%的成功率。值得注意的是，CATH-4.3上的整个强化学习运行，包括奖励计算，可以在不到3天的时间内使用单个8 X GPU节点完成。我们的工作为蛋白质设计建立了一个新范式，模型可以从自身生成的输出中持续进化，为探索广阔的蛋白质设计空间开辟了新的可能性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [643] [Circumventing Backdoor Space via Weight Symmetry](https://arxiv.org/abs/2506.07467)
> *错误：AI分析失败。*

*Jie Peng, Hongwei Yang, Jing Zhao, Hengji Dong, Hui He, Weizhe Zhang, Haoyu He* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [647] [Premise Selection for a Lean Hammer](https://arxiv.org/abs/2506.07477)
> *错误：AI分析失败。*

*Thomas Zhu, Joshua Clune, Jeremy Avigad, Albert Qiaochu Jiang, Sean Welleck* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** LeanHammer is available at https://github.com/JOSHCLUNE/LeanHammer

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [649] [Explicit Preference Optimization: No Need for an Implicit Reward Model](https://arxiv.org/abs/2506.07492)
> *显式偏好优化：无需隐式奖励模型*

*Xiangkun Hu, Lemin Kong, Tong He, David Wipf* | **Main category: cs.LG**

**Keywords:** 偏好优化, 大型语言模型, 奖励模型, EXPO, DPO

**Comment:** arXiv admin note: substantial text overlap with arXiv:2407.09072

> **TL;DR:** 本文提出了EXPO，一种显式偏好优化框架，旨在解决DPO等隐式奖励方法中存在的次优正则化和反直觉插值行为，并证明其在经验上是有效的。

**AI_Comments:** 这项工作通过提出EXPO框架，提供了一种更透明、更稳健的LLM偏好优化方法，解决了DPO等方法中隐式奖励重参数化带来的深层次问题。其创新点在于从“显式”角度出发，直接构建满足正则化要求的优化目标，而非依赖于复杂的重参数化技巧。这对于LLM的对齐训练具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的偏好微调中，RLHF训练序列复杂。DPO虽然简化了过程，但其依赖的隐式奖励重参数化会导致次优正则化和反直觉的插值行为，这些是现有方法需要解决的缺陷。

**Method:** 本文引入了EXPO（显式偏好优化）框架。与DPO不同，EXPO不需要通过重参数化来诱导隐式奖励。相反，它从头开始设定直观的正则化因子，以透明地避免关键DPO变体的潜在缺陷，并能证明满足了先前方法未能满足的正则化要求。

**Result:** 经验结果证实了本文的分析，并展示了EXPO框架的有效性。

**Conclusion:** EXPO框架提供了一种无需隐式奖励模型的新型显式偏好优化方法，有效解决了DPO等现有方法中存在的次优正则化和反直觉插值问题，并满足了更强的正则化要求，从而为LLM的偏好对齐提供了一种更优、更透明的解决方案。

> **ai_Abstract:** 本文针对大型语言模型（LLMs）偏好微调中现有的RLHF和DPO方法的局限性，提出了一种名为EXPO的显式偏好优化框架。RLHF训练复杂，而DPO虽简化了流程，但其基于隐式奖励的重参数化会导致次优正则化和反直觉插值行为。EXPO通过直接设定直观的正则化因子，避免了重参数化带来的问题，并被证明能满足DPO无法满足的正则化需求。实验结果验证了EXPO的分析正确性及其有效性。

> **摘要翻译:** 大型语言模型（LLMs）生成的响应通常通过人类反馈强化学习（RLHF）过程进行微调以适应人类偏好。由于RLHF依赖于一个具有挑战性的训练序列，其中一个独立的奖励模型被独立学习然后应用于LLM策略更新，因此持续的研究工作旨在寻找更直接的替代方案。在这方面，直接偏好优化（DPO）及其许多分支规避了单独奖励训练步骤的需要。相反，通过巧妙地使用一种诱导“隐式”奖励的重参数化技巧，DPO及相关方法将学习整合到单个损失函数的最小化中。然而，尽管在某些实际场景中取得了显著成功，我们证明DPO目标仍然受到次优正则化和反直觉插值行为的影响，这些是其所基于的重参数化未被充分认识的缺陷。为此，我们引入了一个称为EXPO的“显式”偏好优化框架，它不需要类似的重参数化来实现隐式奖励。与此截然不同的是，我们只是从头开始设定了直观吸引人的正则化因子，透明地避免了关键DPO变体的潜在陷阱，并可证明满足了以前方法未能满足的正则化要求。经验结果证实了我们的分析并展示了EXPO的有效性。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [652] [Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks](https://arxiv.org/abs/2506.07500)
> *错误：AI分析失败。*

*Shakir Yousefi, Andreas Plesner, Till Aczel, Roger Wattenhofer* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [654] [Graph-of-Causal Evolution: Challenging Chain-of-Model for Reasoning](https://arxiv.org/abs/2506.07501)
> *错误：AI分析失败。*

*Libo Wang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** The relevant code has been uploaded to the publicly available GitHub
  repository. The link is:
  https://github.com/brucewang123456789/GeniusTrail/tree/main/GoCE

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [656] [Reinforcement Learning via Implicit Imitation Guidance](https://arxiv.org/abs/2506.07505)
> *错误：AI分析失败。*

*Perry Dong, Alec M. Lessing, Annie S. Chen, Chelsea Finn* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [658] [Addressing Correlated Latent Exogenous Variables in Debiased Recommender Systems](https://arxiv.org/abs/2506.07517)
> *错误：AI分析失败。*

*Shuqiang Zhang, Yuchao Zhang, Jinkun Chen, Haochen Sui* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** In Proceedings of the 31st ACM SIGKDD Conference on Knowledge
  Discovery and Data Mining V.2 (KDD '25), August 3--7, 2025, Toronto, ON,
  Canada

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [660] [Flowing Datasets with Wasserstein over Wasserstein Gradient Flows](https://arxiv.org/abs/2506.07534)
> *错误：AI分析失败。*

*Clément Bonet, Christophe Vauthier, Anna Korba* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted as an oral at ICML2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [662] [Improving Memory Efficiency for Training KANs via Meta Learning](https://arxiv.org/abs/2506.07549)
> *错误：AI分析失败。*

*Zhangchi Zhao, Jun Shu, Deyu Meng, Zongben Xu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [665] [Denoising the Future: Top-p Distributions for Moving Through Time](https://arxiv.org/abs/2506.07578)
> *错误：AI分析失败。*

*Florian Andreas Marwitz, Ralf Möller, Magnus Bender, Marcel Gehrke* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [668] [MIRA: Medical Time Series Foundation Model for Real-World Health Data](https://arxiv.org/abs/2506.07584)
> *错误：AI分析失败。*

*Hao Li, Bowen Deng, Chang Xu, Zhiyuan Feng, Viktor Schlegel, Yu-Hao Huang, Yizheng Sun, Jingyuan Sun, Kailai Yang, Yiyao Yu, Jiang Bian* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [671] [Aircraft Trajectory Dataset Augmentation in Latent Space](https://arxiv.org/abs/2506.07585)
> *错误：AI分析失败。*

*Seokbin Yoon, Keumjin Lee* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [673] [PrunePEFT: Iterative Hybrid Pruning for Parameter-Efficient Fine-tuning of LLMs](https://arxiv.org/abs/2506.07587)
> *错误：AI分析失败。*

*Tongzhou Yu, Zhuhao Zhang, Guanghui Zhu, Shen Jiang, Meikang Qiu, Yihua Huang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [675] [Exploiting Curvature in Online Convex Optimization with Delayed Feedback](https://arxiv.org/abs/2506.07595)
> *错误：AI分析失败。*

*Hao Qiu, Emmanuel Esposito, Mengxiao Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [676] [TwinBreak: Jailbreaking LLM Security Alignments based on Twin Prompts](https://arxiv.org/abs/2506.07596)
> *错误：AI分析失败。*

*Torsten Krauß, Hamid Dashtbani, Alexandra Dmitrienko* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 26 pages, 25 tables, 13 figures, 2 algorithms, to appear in the 43th
  USENIX Security Symposium (USENIX Security 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [678] [FuXi-Air: Urban Air Quality Forecasting Based on Emission-Meteorology-Pollutant multimodal Machine Learning](https://arxiv.org/abs/2506.07616)
> *错误：AI分析失败。*

*Zhixin Geng, Xu Fan, Xiqiao Lu, Yan Zhang, Guangyuan Yu, Cheng Huang, Qian Wang, Yuewu Li, Weichun Ma, Qi Yu, Libo Wu, Hao Li* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [682] [The Catechol Benchmark: Time-series Solvent Selection Data for Few-shot Machine Learning](https://arxiv.org/abs/2506.07619)
> *错误：AI分析失败。*

*Toby Boyne, Juan S. Campos, Becky D. Langdon, Jixiang Qing, Yilin Xie, Shiqiang Zhang, Calvin Tsay, Ruth Misener, Daniel W. Davies, Kim E. Jelfs, Sarah Boyall, Thomas M. Dixon, Linden Schrecker, Jose Pablo Folch* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [683] [Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks](https://arxiv.org/abs/2506.07624)
> *错误：AI分析失败。*

*Ali Hariri, Álvaro Arroyo, Alessio Gravina, Moshe Eliasof, Carola-Bibiane Schönlieb, Davide Bacciu, Kamyar Azizzadenesheli, Xiaowen Dong, Pierre Vandergheynst* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [688] [ProARD: progressive adversarial robustness distillation: provide wide range of robust students](https://arxiv.org/abs/2506.07666)
> *错误：AI分析失败。*

*Seyedhamidreza Mousavi, Seyedali Mousavi, Masoud Daneshtalab* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [690] [How Benchmark Prediction from Fewer Data Misses the Mark](https://arxiv.org/abs/2506.07673)
> *错误：AI分析失败。*

*Guanhua Zhang, Florian E. Dorner, Moritz Hardt* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [692] [Evaluating Robustness in Latent Diffusion Models via Embedding Level Augmentation](https://arxiv.org/abs/2506.07706)
> *错误：AI分析失败。*

*Boris Martirosyan, Alexey Karmanov* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [694] [Language Embedding Meets Dynamic Graph: A New Exploration for Neural Architecture Representation Learning](https://arxiv.org/abs/2506.07735)
> *错误：AI分析失败。*

*Haizhao Jing, Haokui Zhang, Zhenhao Shang, Rong Xiao, Peng Wang, Yanning Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [698] [E-LDA: Toward Interpretable LDA Topic Models with Strong Guarantees in Logarithmic Parallel Time](https://arxiv.org/abs/2506.07747)
> *错误：AI分析失败。*

*Adam Breuer* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025; Code available at: https://github.com/BreuerLabs/E- LDA

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [700] [Comparing Credit Risk Estimates in the Gen-AI Era](https://arxiv.org/abs/2506.07754)
> *错误：AI分析失败。*

*Nicola Lavecchia, Sid Fadanelli, Federico Ricciuti, Gennaro Aloe, Enrico Bagli, Pietro Giuffrida, Daniele Vergari* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [702] [Clustered Federated Learning via Embedding Distributions](https://arxiv.org/abs/2506.07769)
> *错误：AI分析失败。*

*Dekai Zhang, Matthew Williams, Francesca Toni* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 24 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [704] [Enhancing Adversarial Robustness with Conformal Prediction: A Framework for Guaranteed Model Reliability](https://arxiv.org/abs/2506.07804)
> *错误：AI分析失败。*

*Jie Bao, Chuangyin Dang, Rui Luo, Hanwei Zhang, Zhixin Zhou* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [706] [Identifiable Object Representations under Spatial Ambiguities](https://arxiv.org/abs/2506.07806)
> *错误：AI分析失败。*

*Avinash Kori, Francesca Toni, Ben Glocker* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [708] [Accelerating Diffusion Models in Offline RL via Reward-Aware Consistency Trajectory Distillation](https://arxiv.org/abs/2506.07822)
> *错误：AI分析失败。*

*Xintong Duan, Yutong He, Fahim Tajwar, Ruslan Salakhutdinov, J. Zico Kolter, Jeff Schneider* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [711] [Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information](https://arxiv.org/abs/2506.07829)
> *错误：AI分析失败。*

*Jan Corazza, Hadi Partovi Aria, Hyohun Kim, Daniel Neider, Zhe Xu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [714] [Improving large language models with concept-aware fine-tuning](https://arxiv.org/abs/2506.07833)
> *错误：AI分析失败。*

*Michael K. Chen, Xikun Zhang, Jiaxing Huang, Dacheng Tao* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [717] [Jarzynski Reweighting and Sampling Dynamics for Training Energy-Based Models: Theoretical Analysis of Different Transition Kernels](https://arxiv.org/abs/2506.07843)
> *错误：AI分析失败。*

*Davide Carbone* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [720] [Residual Reweighted Conformal Prediction for Graph Neural Networks](https://arxiv.org/abs/2506.07854)
> *错误：AI分析失败。*

*Zheng Zhang, Jie Bao, Zhixin Zhou, Nicolo Colombo, Lixin Cheng, Rui Luo* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [725] [Lightweight Sequential Transformers for Blood Glucose Level Prediction in Type-1 Diabetes](https://arxiv.org/abs/2506.07864)
> *错误：AI分析失败。*

*Mirko Paolo Barbato, Giorgia Rigamonti, Davide Marelli, Paolo Napoletano* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [730] [Diffusion Counterfactual Generation with Semantic Abduction](https://arxiv.org/abs/2506.07883)
> *错误：AI分析失败。*

*Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Proceedings of the 42nd International Conference on Machine Learning,
  Vancouver, Canada

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [732] [Schauder Bases for $C[0, 1]$ Using ReLU, Softplus and Two Sigmoidal Functions](https://arxiv.org/abs/2506.07884)
> *错误：AI分析失败。*

*Anand Ganesh, Babhrubahan Bose, Anand Rajagopalan* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [734] [FunDiff: Diffusion Models over Function Spaces for Physics-Informed Generative Modeling](https://arxiv.org/abs/2506.07902)
> *错误：AI分析失败。*

*Sifan Wang, Zehao Dou, Tong-Rui Liu, Lu Lu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 31 pages, 12 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [737] [Diffuse Everything: Multimodal Diffusion Models on Arbitrary State Spaces](https://arxiv.org/abs/2506.07903)
> *错误：AI分析失败。*

*Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X. -F. Ye, Molei Tao* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ICML 2025. Code available at
  https://github.com/KevinRojas1499/Diffuse-Everything

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [740] [CausalPFN: Amortized Causal Effect Estimation via In-Context Learning](https://arxiv.org/abs/2506.07918)
> *错误：AI分析失败。*

*Vahid Balazadeh, Hamidreza Kamkari, Valentin Thomas, Benson Li, Junwei Ma, Jesse C. Cresswell, Rahul G. Krishnan* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [742] [Uncovering the Functional Roles of Nonlinearity in Memory](https://arxiv.org/abs/2506.07919)
> *错误：AI分析失败。*

*Manuel Brenner, Georgia Koppe* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [744] [W4S4: WaLRUS Meets S4 for Long-Range Sequence Modeling](https://arxiv.org/abs/2506.07920)
> *错误：AI分析失败。*

*Hossein Babaei, Mel White, Richard G. Baraniuk* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages, 2 figures, 3 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [747] [A Generative Physics-Informed Reinforcement Learning-Based Approach for Construction of Representative Drive Cycle](https://arxiv.org/abs/2506.07929)
> *错误：AI分析失败。*

*Amirreza Yasami, Mohammadali Tofigh, Mahdi Shahbakhti, Charles Robert Koch* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [749] [Ensemble-Based Survival Models with the Self-Attended Beran Estimator Predictions](https://arxiv.org/abs/2506.07933)
> *错误：AI分析失败。*

*Lev V. Utkin, Semen P. Khomets, Vlada A. Efremenko, Andrei V. Konstantinov, Natalya M. Verbova* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [752] [Cost-Optimal Active AI Model Evaluation](https://arxiv.org/abs/2506.07949)
> *错误：AI分析失败。*

*Anastasios N. Angelopoulos, Jacob Eisenstein, Jonathan Berant, Alekh Agarwal, Adam Fisch* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [754] [Neural Tangent Kernel Analysis to Probe Convergence in Physics-informed Neural Solvers: PIKANs vs. PINNs](https://arxiv.org/abs/2506.07958)
> *错误：AI分析失败。*

*Salah A. Faroughi, Farinaz Mostajeran* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [755] [A Two-Phase Deep Learning Framework for Adaptive Time-Stepping in High-Speed Flow Modeling](https://arxiv.org/abs/2506.07969)
> *错误：AI分析失败。*

*Jacob Helwig, Sai Sreeharsha Adavi, Xuan Zhang, Yuchao Lin, Felix S. Chim, Luke Takeshi Vizzini, Haiyang Yu, Muhammad Hasnain, Saykat Kumar Biswas, John J. Holloway, Narendra Singh, N. K. Anand, Swagnik Guhathakurta, Shuiwang Ji* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [758] [HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization](https://arxiv.org/abs/2506.07972)
> *错误：AI分析失败。*

*Hongzheng Chen, Yingheng Wang, Yaohui Cai, Hins Hu, Jiajie Li, Shirley Huang, Chenhui Deng, Rongjian Liang, Shufeng Kong, Haoxing Ren, Samitha Samaranayake, Carla P. Gomes, Zhiru Zhang* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [761] [Hyperpruning: Efficient Search through Pruned Variants of Recurrent Neural Networks Leveraging Lyapunov Spectrum](https://arxiv.org/abs/2506.07975)
> *错误：AI分析失败。*

*Caleb Zheng, Eli Shlizerman* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 26 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [763] [Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction](https://arxiv.org/abs/2506.07976)
> *错误：AI分析失败。*

*Junhong Shen, Hao Bai, Lunjun Zhang, Yifei Zhou, Amrith Setlur, Shengbang Tong, Diego Caples, Nan Jiang, Tong Zhang, Ameet Talwalkar, Aviral Kumar* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [764] [Realistic Urban Traffic Generator using Decentralized Federated Learning for the SUMO simulator](https://arxiv.org/abs/2506.07980)
> *错误：AI分析失败。*

*Alberto Bazán-Guillén, Carlos Beis-Penedo, Diego Cajaraville-Aboy, Pablo Barbecho-Bautista, Rebeca P. Díaz-Redondo, Luis J. de la Cruz Llopis, Ana Fernández-Vilas, Mónica Aguilar Igartua, Manuel Fernández-Veiga* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [765] [Generative Modeling of Weights: Generalization or Memorization?](https://arxiv.org/abs/2506.07998)
> *错误：AI分析失败。*

*Boya Zeng, Yida Yin, Zhiqiu Xu, Zhuang Liu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page at https://boyazeng.github.io/weight_memorization

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

### [767] [Reparameterized LLM Training via Orthogonal Equivalence Transformation](https://arxiv.org/abs/2506.08001)
> *错误：AI分析失败。*

*Zeju Qiu, Simon Buchholz, Tim Z. Xiao, Maximilian Dax, Bernhard Schölkopf, Weiyang Liu* | **Main category: cs.LG**

**Keywords:** 错误：AI分析失败。

**Comment:** Technical report v1 (36 pages, 24 figures, project page:
  https://spherelab.ai/poet-site/)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslg) | [⬆️ 返回总目录](#toc)

---

<a id='csma'></a>
## cs.MA 

### [8] [AI-Generated Compromises for Coalition Formation](https://arxiv.org/abs/2506.06837)
> *联盟形成中的AI生成妥协方案*

*Eyal Briman, Ehud Shapiro, Nimrod Talmon* | **Main category: cs.MA**

**Keywords:** AI生成妥协, 联盟形成, 自然语言处理, 大型语言模型, 民主文本编辑

**Comment:** 

> **TL;DR:** 本文提出了一种利用AI方法（NLP和大型语言模型）在语义度量空间中生成妥协方案以促进联盟形成和大规模民主文本编辑的方法。

**AI_Comments:** 本文的创新之处在于将AI方法（特别是NLP和LLM）应用于联盟形成中的妥协方案生成，并将其应用于大规模民主文本编辑这一实际且复杂的领域。这为多代理人系统中的协商和协作提供了新的工具和视角，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在联盟形成过程中，如何有效找到能让各代理人联合起来的妥协提案仍是一个悬而未决的问题。

**Method:** 本文通过形式化一个包含代理人有限理性和不确定性的模型，并开发AI方法来生成妥协方案。具体来说，研究利用自然语言处理技术和大型语言模型在文本上构建语义度量空间，并在此基础上设计算法以建议可能获得广泛支持的妥协点。研究聚焦于协作文档撰写领域，如社区章程的民主起草。

**Result:** 研究通过模拟联盟形成过程，证明AI可以促进大规模民主文本编辑，这是一个传统工具受限的领域。

**Conclusion:** AI能够促进大规模民主文本编辑，弥补了传统工具的局限性。

> **ai_Abstract:** 本文针对联盟形成中寻找妥协方案的挑战，提出了一种基于AI的方法。研究首先形式化了一个考虑代理人有限理性和不确定性的模型，然后利用自然语言处理技术和大型语言模型在文本上构建语义度量空间。在此空间中，设计了算法来生成可能获得广泛支持的妥协提案。通过模拟协作文档撰写过程，研究展示了AI在促进大规模民主文本编辑方面的有效性，填补了传统工具的空白。

> **摘要翻译:** 代理人提案之间寻找妥协方案的挑战是人工智能子领域（如论证、调解和谈判）的基础问题。在此传统基础上，Elkind 等人（2021）引入了一种联盟形成过程，该过程在每个代理人都有一个理想点的度量空间中，寻求多数支持且优于现状的提案。此过程中的关键一步是识别能让代理人联盟团结起来的妥协提案。如何有效找到此类妥协提案仍然是一个开放性问题。我们通过形式化一个包含代理人有限理性和不确定性的模型，并开发人工智能方法来生成妥协提案，从而解决了这一空白。我们专注于协作文档撰写领域，例如社区章程的民主起草。我们的方法使用自然语言处理技术和大型语言模型在文本上生成语义度量空间。基于此空间，我们设计了算法来建议可能获得广泛支持的妥协点。为了评估我们的方法，我们模拟了联盟形成过程，并表明人工智能可以促进大规模民主文本编辑，这是一个传统工具受限的领域。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [23] [Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments](https://arxiv.org/abs/2506.07232)
> *个体学习，团队进化：具身环境中多智能体LLM的适应性*

*Xinran Li, Chenjia Bai, Zijian Li, Jiakun Zheng, Ting Xiao, Jun Zhang* | **Main category: cs.MA**

**Keywords:** 多智能体LLM, 具身环境, 适应性, 协作规划, LIET

**Comment:** 

> **TL;DR:** 本文提出了一种名为LIET（Learn as Individuals, Evolve as a Team）的框架，旨在解决大型语言模型（LLMs）在具身多智能体环境中适应性不足的问题。LIET通过结合个体学习（理解环境）和团队进化（协作知识共享）使LLM智能体能更好地规划和沟通。实验证明，LIET在多项基准测试中优于现有基线，展现出强大的协作规划能力。

**AI_Comments:** LIET框架的创新之处在于其将个体学习与团队进化相结合的范式，为LLM在复杂具身多智能体环境中的适应性提供了新的解决方案。这种分层学习与协作知识共享的机制，有效地弥补了现有LLM在多智能体场景中适应能力不足的缺陷，是LLM应用于具身智能领域的重要进展。其灵感来源于多智能体强化学习，也体现了跨领域思想的融合。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）拥有广泛的知识库和强大的推理能力，并且代理方法设计精巧，但现有的基于LLM的规划算法在多智能体具身场景中的适应能力仍然有限。

**Method:** 本文引入了一个名为“个体学习，团队进化（LIET）”的范式来解决多智能体LLM的适应性问题。在个体层面，LLM智能体从探索性数据集中学习一个局部效用函数，以更好地理解具身环境，并在测试时查询该函数以支持知情决策。在团队层面，LLM智能体根据新经验协作迭代地维护和更新一个共享的协作知识列表，并利用它来指导更有效的沟通。通过结合个体学习和团队进化，LIET实现了LLM智能体的全面而灵活的适应。

**Result:** 在Communicative Watch-And-Help和ThreeD-World Multi-Agent Transport基准测试中的实验表明，使用LLaMA和GPT-4o实例化的LIET框架，其性能优于现有基线，并展现出强大的协作规划能力。

**Conclusion:** LIET通过结合个体学习和团队进化，为LLM智能体提供了全面而灵活的适应能力，使其在具身环境中展现出强大的协作规划能力。

> **ai_Abstract:** 大型语言模型（LLMs）在具身多智能体规划中面临适应性不足的挑战。本文提出了一种名为“个体学习，团队进化（LIET）”的框架来解决此问题。LIET借鉴了多智能体强化学习中的集中训练去中心化执行思想，使LLM智能体能够在个体层面通过学习局部效用函数来理解环境，并在团队层面通过维护和更新共享协作知识列表来增强沟通与合作。实验结果表明，LIET在多个具身多智能体基准测试中表现优于现有方法，证明了其在增强LLM智能体协作规划能力方面的有效性。

> **摘要翻译:** 大型语言模型（LLMs）拥有广泛的知识库和强大的推理能力，使其成为具身环境中复杂多智能体规划的有力工具。然而，尽管LLMs具有先进的能力和代理方法的复杂模块化设计，但现有的基于LLM的规划算法仍然受限于对多智能体具身场景的弱适应能力。我们通过引入一个框架来解决这一限制，该框架使LLM智能体能够在测试前和测试期间进行学习和进化，从而为它们配备与环境相关的知识，以实现更好的规划，并增强沟通以改进合作。受多智能体强化学习中集中训练去中心化执行的启发，我们提出了一种“个体学习，团队进化（LIET）”的范式，用于多智能体LLMs的适应。在个体层面，LLM智能体从探索性数据集中学习一个局部效用函数，以更好地理解具身环境，该函数随后在测试时被查询以支持知情决策。在团队层面，LLM智能体根据新经验协作迭代地维护和更新一个共享的协作知识列表，并利用它来指导更有效的沟通。通过结合个体学习和团队进化，LIET实现了LLM智能体的全面而灵活的适应。我们在Communicative Watch-And-Help和ThreeD-World Multi-Agent Transport基准测试中的实验表明，使用LLaMA和GPT-4o实例化的LIET，其性能优于现有基线，并展现出强大的协作规划能力。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [37] [Digital Twin-based Smart Manufacturing: Dynamic Line Reconfiguration for Disturbance Handling](https://arxiv.org/abs/2506.07332)
> *基于数字孪生的智能制造：面向扰动处理的动态产线重构*

*Bo Fu, Mingjie Bi, Shota Umeda, Takahiro Nakano, Youichi Nonaka, Quan Zhou, Takaharu Matsui, Dawn M. Tilbury, Kira Barton* | **Main category: cs.MA**

**Keywords:** 数字孪生, 智能制造, 产线重构, 扰动处理, 优化

**Comment:** IEEE Transactions on Automation Science and Engineering (T-ASE) and
  CASE 2025

> **TL;DR:** 该论文提出了一种基于数字孪生的动态产线重构框架，用于智能制造中处理扰动，显著提高了生产线在面对中断时的吞吐量恢复能力。

**AI_Comments:** 该论文的创新点在于结合了数字孪生技术与动态产线重构，提供了一个集成化的解决方案来应对复杂制造环境中的实时扰动。其高速仿真评估能力和快速优化器是亮点，极大地提升了系统响应速度和实用性。这对于实现真正的智能制造和工业4.0愿景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代制造业日益复杂，面临需求波动、供应链不确定性和产品定制化等挑战，需要能够灵活更新配置并迅速适应扰动的制造系统。然而，现有研究未能提供一个全面的可重构制造框架，以无缝监控系统扰动、基于机器能力优化替代产线配置，并自动化仿真评估以实现快速适应。

**Method:** 该框架包括：1) 用于监控扰动和触发重构的系统过程数字孪生；2) 捕获可用代理和资源选项的基于能力的本体模型；3) 生成最优产线配置的配置优化器；4) 初始化仿真设置并以约400倍实时速度评估产线配置的仿真生成程序。通过电池生产线案例研究进行评估。

**Result:** 在两个扰动场景中，该框架成功地在有限资源下恢复了系统吞吐量，避免了在没有重构计划的情况下可能发生的26%和63%的吞吐量下降。重构优化器平均0.03秒就能为一个包含51个操作和40个可用代理的生产线找到重构方案。

**Conclusion:** 该框架通过动态产线重构有效处理了制造扰动，显著提高了系统韧性和效率，尤其在处理操作时间变化引起的扰动方面表现出色。

> **ai_Abstract:** 本文针对现代制造中因需求波动和不确定性导致的系统扰动问题，提出了一种基于数字孪生的动态产线重构框架。该框架整合了数字孪生监控、能力本体建模、配置优化器和高速仿真评估，旨在实现制造系统对操作时间变化的快速适应。通过电池生产线案例验证，该框架能有效恢复因扰动导致的吞吐量下降，并在极短时间内生成最优重构方案，显著提升了制造系统的韧性和效率。

> **摘要翻译:** 现代制造业日益增长的复杂性，加上需求波动、供应链不确定性和产品定制化，凸显了对能够灵活更新其配置并迅速适应扰动的制造系统的需求。然而，当前研究在提供一个全面的可重构制造框架方面存在不足，该框架能够无缝监控系统扰动、基于机器能力优化替代产线配置，并自动化仿真评估以实现快速适应。本文提出了一种动态制造产线重构框架，以处理导致操作时间变化的扰动。该框架包含一个用于监控扰动和触发重构的系统过程数字孪生、一个捕获可用代理和资源选项的基于能力的本体模型、一个生成最优产线配置的配置优化器，以及一个初始化仿真设置并以大约400倍实时速度评估产线配置的仿真生成程序。对电池生产线进行了案例研究以评估所提出的框架。在两个已实施的扰动场景中，该框架成功地在有限资源下恢复了系统吞吐量，避免了在没有重构计划的情况下可能发生的26%和63%的吞吐量下降。重构优化器有效地找到了最优解决方案，平均0.03秒就能为一个包含51个操作和40个可用代理的制造产线找到一个重构计划。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [51] [Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents](https://arxiv.org/abs/2506.07388)
> *Shapley-Coop：自利LLM智能体中涌现合作的信用分配*

*Yun Hua, Haosheng Chen, Shiqin Wang, Wenhao Li, Xiangfeng Wang, Jun Luo* | **Main category: cs.MA**

**Keywords:** LLM智能体, 信用分配, 合作, Shapley值, 多智能体系统

**Comment:** 

> **TL;DR:** Shapley-Coop提出了一种基于Shapley值和谈判协议的信用分配机制，使自利LLM智能体能够在开放环境中通过任务时间定价和奖励再分配实现合作。

**AI_Comments:** Shapley-Coop的创新之处在于将Shapley值理论与LLM智能体的多智能体协作相结合，有效解决了自利智能体在开放环境中进行公平信用分配的难题。其基于边际贡献的定价机制和谈判协议为LLM智能体实现自主且高效的合作提供了新的范式，对于未来复杂人机协作系统的设计具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在缺乏协调规则的开放环境中，大型语言模型（LLM）智能体倾向于自利行为，难以实现协调。核心挑战在于信用分配，即公平评估每个智能体的贡献并设计能够协调其异质目标的定价机制，这对于日益复杂的人机协作至关重要。

**Method:** 提出了一种名为Shapley-Coop的合作工作流。该方法将Shapley Chain-of-Thought（利用边际贡献作为定价原则）与结构化谈判协议相结合，以实现有效的价格匹配，使LLM智能体能够通过理性任务时间定价和任务后奖励再分配进行协调。

**Result:** 在两个多智能体博弈和一个软件工程模拟中评估了Shapley-Coop，结果表明它持续增强了LLM智能体的协作，并促进了公平的信用分配。这些结果突出了Shapley-Coop定价机制在准确反映任务执行过程中个体贡献方面的有效性。

**Conclusion:** Shapley-Coop通过其创新的定价机制，成功解决了自利LLM智能体在开放环境中实现合作的信用分配挑战，显著提升了协作效率和公平性。

> **ai_Abstract:** 本文提出Shapley-Coop，一种为自利LLM智能体设计的新型信用分配机制，旨在促进开放环境中的合作。该方法结合了Shapley思维链的边际贡献定价原则与结构化谈判协议，通过任务时间定价和奖励再分配来协调智能体激励。实验结果表明，Shapley-Coop显著提升了LLM智能体的协作能力和信用分配的公平性。

> **摘要翻译:** 大型语言模型（LLM）在具有预定义角色和工作流程的多智能体系统中表现出强大的协作能力。然而，在缺乏协调规则的开放环境中，智能体倾向于以自利方式行事。实现协调的核心挑战在于信用分配——公平评估每个智能体的贡献并设计能够协调其异质目标的定价机制。这个问题至关重要，因为LLM越来越多地参与复杂的人机协作，其中公平的报酬和问责制依赖于有效的定价机制。受人类社会解决类似协调挑战（例如，通过临时合作，如雇佣或分包）的启发，我们提出了一种合作工作流Shapley-Coop。Shapley-Coop将Shapley思维链（利用边际贡献作为定价的原则基础）与结构化谈判协议相结合，以实现有效的价格匹配，使LLM智能体能够通过理性任务时间定价和任务后奖励再分配进行协调。这种方法协调了智能体的激励，促进了合作，并保持了自主性。我们在两个多智能体博弈和一个软件工程模拟中评估了Shapley-Coop，证明它持续增强了LLM智能体的协作并促进了公平的信用分配。这些结果突出了Shapley-Coop定价机制在准确反映任务执行过程中个体贡献方面的有效性。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [66] [G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems](https://arxiv.org/abs/2506.07398)
> *G-Memory：追溯多智能体系统的分层记忆*

*Guibin Zhang, Muxin Fu, Guancheng Wan, Miao Yu, Kun Wang, Shuicheng Yan* | **Main category: cs.MA**

**Keywords:** 多智能体系统, 分层记忆, 大语言模型, 组织记忆理论, G-Memory

**Comment:** 

> **TL;DR:** G-Memory引入了一种分层、智能体化的记忆系统，通过管理洞察、查询和交互图的三层图层次结构来改进多智能体系统的记忆能力，显著提高了任务成功率和知识问答准确性。

**AI_Comments:** G-Memory的创新之处在于其分层、智能体化的记忆架构，这有效地解决了多智能体系统在复杂协作和跨试验知识利用方面的记忆短板。将组织记忆理论引入MAS记忆设计，提供了一个新颖且有效的视角。其在不修改现有框架的情况下取得显著性能提升，证明了该方法的普适性和实用性。这对于推动MAS的自我演化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前大语言模型驱动的多智能体系统（MAS）的自我演化能力受到未充分发展的记忆架构的阻碍。现有的MAS记忆机制过于简单，忽视了细致的智能体间协作轨迹，并且缺乏跨试验和智能体特定的定制，这与为单个智能体开发的富有表现力的记忆形成鲜明对比。

**Method:** G-Memory是一个受组织记忆理论启发的分层、智能体化记忆系统。它通过一个三层图层次结构（洞察图、查询图和交互图）来管理MAS的冗长交互。当接收到新的用户查询时，G-Memory执行双向记忆遍历，以检索高级的、可泛化的洞察和细粒度的、浓缩的交互轨迹。在任务执行后，整个层次结构通过吸收新的协作轨迹而演化。

**Result:** G-Memory在五个基准测试、三个LLM骨干和三个流行的MAS框架中进行了广泛实验，结果显示，它在具身动作中的成功率提高了20.89%，在知识问答中的准确性提高了10.12%，且无需修改原始框架。

**Conclusion:** G-Memory通过引入分层、智能体化的记忆系统，有效解决了现有MAS记忆架构的不足，显著提升了多智能体系统的认知和执行能力，尤其是在跨试验知识利用和协作经验编码方面。

> **ai_Abstract:** 本文提出G-Memory，一个受组织记忆理论启发的分层、智能体化记忆系统，旨在弥补大语言模型驱动的多智能体系统（MAS）在记忆架构上的不足。针对现有MAS记忆机制过于简单且缺乏定制化的问题，G-Memory通过管理洞察、查询和交互图的三层图层次结构来处理MAS的复杂交互。它能够双向检索高级泛化洞察和细粒度交互轨迹，并在任务执行后通过吸收新的协作经验进行演化。实验结果表明，G-Memory在多个基准测试中显著提升了具身动作的成功率和知识问答的准确性。

> **摘要翻译:** 大语言模型（LLM）驱动的多智能体系统（MAS）展现出远超单一LLM智能体的认知和执行能力，但其自我演化能力仍受限于不完善的记忆架构。经仔细检查，我们惊觉现有MAS记忆机制（1）过于简单，完全忽视了细致的智能体间协作轨迹，以及（2）缺乏跨试验和智能体特定的定制，这与为单一智能体开发的富有表现力的记忆形成鲜明对比。为了弥补这一差距，我们引入了G-Memory，一个受组织记忆理论启发的分层、智能体化MAS记忆系统，它通过三层图层次结构：洞察图、查询图和交互图来管理冗长的MAS交互。当接收到新的用户查询时，G-Memory执行双向记忆遍历，以检索高级的、可泛化的洞察（使系统能够利用跨试验知识）和细粒度的、浓缩的交互轨迹（紧凑编码先前的协作经验）。在任务执行后，整个层次结构通过吸收新的协作轨迹而演化，促进智能体团队的逐步演化。在五个基准测试、三个LLM骨干和三个流行的MAS框架中进行的广泛实验表明，G-Memory在不修改原始框架的情况下，分别将具身动作的成功率提高了20.89%，知识问答的准确性提高了10.12%。我们的代码可在https://github.com/bingreeky/GMemory获取。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [80] [MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models](https://arxiv.org/abs/2506.07400)
> *MedChat：一个基于大语言模型的多智能体多模态诊断框架*

*Philip Liu, Sparsh Bansal, Jimmy Dinh, Aditya Pawar, Ramani Satishkumar, Shail Desai, Neeraj Gupta, Xin Wang, Shu Hu* | **Main category: cs.MA**

**Keywords:** 多智能体框架, 大型语言模型, 医疗诊断, 多模态, 青光眼检测

**Comment:** 7 pages, 6 figures. Accepted to the 2025 IEEE 8th International
  Conference on Multimedia Information Processing and Retrieval (MIPR). Code
  and platform available at https://github.com/Purdue-M2/MedChat

> **TL;DR:** MedChat是一个多智能体框架，结合专业视觉模型和多个特定角色的LLM智能体，旨在解决通用LLM在医疗图像诊断中的局限性，提高诊断准确性和报告效率。

**AI_Comments:** MedChat的创新之处在于其多智能体架构，模拟了多学科医疗团队的协作模式，有效解决了单一通用LLM在医学影像诊断中面临的幻觉和领域知识不足问题。其交互式诊断报告界面也具有重要的临床和教育应用价值，为未来医疗AI的发展提供了有益的探索。

<details>
  <summary>Details</summary>

**Motivation:** 现有深度学习结合LLM的青光眼检测策略面临幻觉、可解释性差和医学知识不足的问题，且单智能体方法无法模拟多学科医疗团队的复杂推理，导致临床准确性受限。

**Method:** 提出MedChat，一个多智能体诊断框架和平台。它结合了专业视觉模型与多个角色特定的LLM智能体，并通过一个导演智能体进行协调。

**Result:** MedChat增强了可靠性，降低了幻觉风险，并通过为临床审查和教育用途量身定制的界面实现了交互式诊断报告。

**Conclusion:** MedChat通过其多智能体框架解决了通用LLM在医疗图像诊断中的挑战，提高了诊断的可靠性和报告效率，为医疗影像诊断提供了新的解决方案。

> **ai_Abstract:** MedChat是一个创新的多智能体框架，旨在通过结合专业视觉模型和多角色LLM智能体来克服通用大型语言模型在医疗影像诊断中的局限性。它通过一个协调导演智能体，增强了诊断的可靠性，减少了幻觉，并支持交互式报告，从而提高了临床准确性和效率，特别是在青光眼检测等领域。

> **摘要翻译:** 深度学习驱动的青光眼检测与大型语言模型（LLM）的整合，提供了一种自动化策略，以缓解眼科医生短缺并提高临床报告效率。然而，将通用LLM应用于医学影像仍然具有挑战性，原因在于幻觉、有限的可解释性以及领域特定医学知识的不足，这些都可能降低临床准确性。尽管近期结合影像模型与LLM推理的方法改善了报告，但它们通常依赖于单一的通用智能体，这限制了它们模仿多学科医疗团队中多样化和复杂推理的能力。为解决这些局限性，我们提出了MedChat，一个多智能体诊断框架和平台，它结合了专业视觉模型与多个角色特定的LLM智能体，所有这些都由一个导演智能体协调。这种设计增强了可靠性，降低了幻觉风险，并通过一个为临床审查和教育用途量身定制的界面实现了交互式诊断报告。代码可在https://github.com/Purdue-M2/MedChat获取。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

### [94] [Diffusion of Responsibility in Collective Decision Making](https://arxiv.org/abs/2506.07935)
> *集体决策中的责任分散*

*Pavel Naumov, Jia Tao* | **Main category: cs.MA**

**Keywords:** 责任分散, 集体决策, 问责制, 独裁, 双模拟

**Comment:** 

> **TL;DR:** 在集体决策中，责任分散是一个常见问题。研究表明，要避免责任分散，唯一的途径是采取“独裁者”或“选举独裁”的决策机制。

**AI_Comments:** 这篇论文提出了一个重要的理论论点，即在集体决策中实现清晰的问责制，本质上会导致中心化、单边化的决策结构。这揭示了在追求分布式责任的系统中，问责制与决策形式之间可能存在的根本性权衡。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究集体决策机制中常见的、不受欢迎的“责任分散”现象。

**Method:** 通过定义决策机制的“双模拟”（bisimulation），证明双模拟能保留与责任相关的属性，并为最小的双模拟机制建立了结果。

**Result:** 研究表明，如果决策由两个主体做出，避免责任分散的唯一方法是其中一个主体充当“独裁者”单方面做出决策。在主体多于两个的场景中，任何无责任分散的机制都是“选举独裁”，即主体选举一个单一主体进行单方面决策。

**Conclusion:** 在集体决策中，要避免责任分散，必然导致某种形式的单方面决策，即独裁或选举独裁。

> **ai_Abstract:** 本文探讨了集体决策中责任分散的现象，该现象模糊了个人问责。研究发现，在双主体决策中，避免责任分散的唯一方式是其中一方充当独裁者。在多主体场景中，任何无责任分散的机制都将演变为“选举独裁”，即主体选举一人进行单边决策。这些技术结果是通过定义决策机制的双模拟并证明其责任相关属性的保留性而得出的。

> **摘要翻译:** “责任分散”一词指的是多个主体分担某个结果的责任，从而模糊了个人问责的情况。本文探讨了集体决策机制中这种经常不受欢迎的现象。研究表明，如果决策由两个主体做出，那么避免责任分散的唯一方法是其中一个主体充当“独裁者”，单方面做出决策。在主体多于两个的场景中，任何无责任分散的机制都是“选举独裁”，即主体选举一个单一主体进行单方面决策。技术结果是通过定义决策机制的“双模拟”获得的，证明双模拟保留了与责任相关的属性，并为最小的双模拟机制建立了结果。

</details>

[⬆️ 返回分类顶部](#csma) | [⬆️ 返回总目录](#toc)

---

<a id='csro'></a>
## cs.RO 

### [9] [Tactile MNIST: Benchmarking Active Tactile Perception](https://arxiv.org/abs/2506.06361)
> *触觉MNIST：主动触觉感知的基准测试*

*Tim Schneider, Guillaume Duret, Cristiana de Farias, Roberto Calandra, Liming Chen, Jan Peters* | **Main category: cs.RO**

**Keywords:** 触觉感知, 主动感知, 基准测试, 机器人学, 数据集

**Comment:** 

> **TL;DR:** 引入触觉MNIST，一个用于主动触觉感知的开源基准，旨在解决该领域缺乏标准化基准的问题。

**AI_Comments:** 这篇论文通过提供一个急需的标准化基准，解决了触觉传感和主动感知领域的一个关键空白。这将极大地帮助可复现研究，并通过为评估不同的主动触觉感知算法提供一个共同的基础来加速进展。包含模拟和真实世界数据，以及用于逼真渲染的CycleGAN，增强了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 触觉感知对机器人操作至关重要，但其固有的局部性限制了其在需要广泛空间或全局场景理解的任务中的应用。主动感知是解决此问题的一种人类启发策略。然而，主动感知和触觉传感领域都缺乏标准化的基准，阻碍了系统性进展。

**Method:** 本文引入了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的基准，专门为主动触觉感知任务（包括定位、分类和体积估计）设计。该基准套件提供多样化的模拟场景，并包含一个综合数据集，该数据集由13,500个合成3D MNIST数字模型和153,600个从真实3D打印数字中收集的触觉样本组成。此外，研究人员还使用此数据集训练了一个CycleGAN，用于逼真的触觉模拟渲染。

**Result:** 该研究成功引入了一个标准化的基准套件和数据集，为主动触觉感知任务提供了可复现的评估框架和标准化协议，从而促进了该领域的系统性进展。

**Conclusion:** 触觉MNIST基准套件通过提供标准化的协议和可复现的评估框架，促进了触觉传感和主动感知领域的系统性进展。

> **ai_Abstract:** 本文介绍了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的框架，旨在标准化主动触觉感知的评估。为解决局部触觉传感的局限性以及缺乏基准的问题，该套件提供了多样化的模拟场景和包含合成与真实触觉样本的综合数据集。该基准促进了主动触觉感知领域（如定位、分类和体积估计）的可复现研究和系统性进展。

> **摘要翻译:** 触觉感知通过提供丰富的局部信息，可以补充或替代视觉等其他感官模式，从而显著增强灵巧的机器人操作。然而，由于触觉感应本质上是局部的，它本身不适合需要广泛空间意识或全局场景理解的任务。解决这个问题的一种受人类启发的方法是考虑主动感知技术。也就是说，主动引导传感器朝向信息更丰富或更重要的特征区域，并随时间整合这些信息，以理解场景或完成任务。主动感知和不同的触觉感应方法最近都受到了广泛关注。然而，尽管取得了进展，这两个领域都缺乏标准化的基准。为了弥补这一差距，我们引入了触觉MNIST基准套件，这是一个开源的、与Gymnasium兼容的基准，专门为主动触觉感知任务设计，包括定位、分类和体积估计。我们的基准套件提供了多样化的模拟场景，从简单的玩具环境到使用基于视觉的触觉传感器的复杂触觉感知任务。此外，我们还提供了一个全面的数据集，包含13,500个合成3D MNIST数字模型和从600个3D打印数字中收集的153,600个真实世界触觉样本。使用此数据集，我们训练了一个CycleGAN用于逼真的触觉模拟渲染。通过提供标准化的协议和可复现的评估框架，我们的基准套件促进了触觉传感和主动感知领域的系统性进展。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [10] [CPS-Guard: Framework for Dependability Assurance of AI- and LLM-Based Cyber-Physical Systems](https://arxiv.org/abs/2506.06381)
> *CPS-Guard：面向AI和LLM网络物理系统可靠性保障框架*

*Trisanth Srinivasan, Santosh Patapati, Himani Musku, Idhant Gode, Aditya Arora, Samvit Bhattacharya, Abubakr Nazriev, Sanika Hirave, Zaryab Kanjiani, Srinjoy Ghose, Srinidhi Shetty* | **Main category: cs.RO**

**Keywords:** 网络物理系统, AI, 可靠性保障, 验证与确认, 多角色编排

**Comment:** 

> **TL;DR:** CPS-Guard是一个新颖的框架，通过多角色编排在模拟环境中自动化AI驱动CPS的可靠性保障过程，有效检测漏洞并支持自适应恢复策略。

**AI_Comments:** CPS-Guard的创新之处在于其多角色编排方法，自动化了AI驱动CPS的可靠性保障过程，这对于处理AI组件的动态和不可预测性至关重要。该框架提供了一个结构化和可扩展的解决方案，对于提高安全和关键安全系统的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 网络物理系统（CPS）日益依赖先进的AI技术在关键应用中运行，但传统的验证和确认方法难以处理AI组件不可预测和动态的特性。

**Method:** 本文引入了CPS-Guard框架，该框架采用多角色编排，在一个模拟环境中为AI驱动的CPS自动化迭代保障过程。通过将专业角色（如安全监控、安全评估、故障注入和恢复规划）分配给专用代理，CPS-Guard持续评估和完善AI行为以满足一系列可靠性要求。

**Result:** 通过一个涉及自动驾驶汽车的案例研究，结果表明CPS-Guard有效检测漏洞，管理性能影响，并支持自适应恢复策略。

**Conclusion:** CPS-Guard为安全和关键安全系统中的严格验证与确认提供了一个结构化和可扩展的解决方案。

> **ai_Abstract:** CPS-Guard是一个创新的框架，旨在解决AI驱动网络物理系统（CPS）中传统验证和确认方法所面临的挑战。该框架利用多角色编排，在模拟环境中自动化AI-powered CPS的迭代保障过程。通过分配专门的角色，如安全监控和故障注入，CPS-Guard持续评估并完善AI行为，以满足可靠性要求。案例研究表明，它能有效检测漏洞、管理性能影响并支持自适应恢复策略，为关键系统提供了严谨的V&V解决方案。

> **摘要翻译:** 网络物理系统（CPS）日益依赖先进的AI技术在关键应用中运行。然而，传统的验证和确认方法往往难以处理AI组件不可预测和动态的特性。在本文中，我们引入了CPS-Guard，这是一个新颖的框架，它采用多角色编排来自动化AI驱动CPS的迭代保障过程。通过在模拟环境中将专业角色（例如安全监控、安全评估、故障注入和恢复规划）分配给专用代理，CPS-Guard持续评估和完善AI行为以满足一系列可靠性要求。我们通过一个涉及具有AI规划器的自动驾驶汽车导航十字路口的案例研究来演示该框架。我们的结果表明，CPS-Guard有效检测漏洞，管理性能影响，并支持自适应恢复策略，从而为安全和关键安全系统中的严格验证与确认提供了一个结构化和可扩展的解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [38] [Active Illumination Control in Low-Light Environments using NightHawk](https://arxiv.org/abs/2506.06394)
> *在弱光环境中使用NightHawk进行主动照明控制*

*Yash Turkar, Youngjin Kim, Karthik Dantu* | **Main category: cs.RO**

**Keywords:** 主动照明, 曝光控制, 贝叶斯优化, 机器人视觉, 弱光环境

**Comment:** 

> **TL;DR:** NightHawk是一个在弱光环境中结合主动照明和曝光控制来优化图像质量的框架，通过在线贝叶斯优化和新颖的特征检测器度量，显著提高了特征检测和匹配，从而实现更可靠的视觉估计。

**AI_Comments:** 该论文的创新之处在于其结合主动照明与曝光控制的在线贝叶斯优化方法，以及提出的基于特征检测器的新颖图像效用度量。NightHawk显著提升了机器人视觉在极具挑战性的弱光环境中的性能，对于地下探测、搜救等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地下环境（如涵洞）由于光线昏暗和缺乏独特特征，给机器人视觉带来了重大挑战。车载照明虽然有帮助，但会引入镜面反射、过曝和功耗增加等问题。

**Method:** 提出NightHawk框架，结合主动照明和曝光控制以优化图像质量。NightHawk将在线贝叶斯优化问题公式化，以确定给定场景的最佳光强度和曝光时间。提出一种新颖的基于特征检测器的度量来量化图像效用，并将其用作优化器的成本函数。NightHawk被构建为一个事件触发的递归优化管道，并部署在伊利运河下涵洞中导航的腿式机器人上。

**Result:** 现场实验结果表明，特征检测和匹配提高了47-197%，从而在挑战性照明条件下实现了更可靠的视觉估计。

**Conclusion:** NightHawk框架通过结合主动照明和曝光控制，显著提高了弱光环境下机器人视觉的图像质量和视觉估计的可靠性。

> **ai_Abstract:** 本文提出了NightHawk，一个用于弱光环境下主动照明控制的框架，旨在解决地下环境中机器人视觉面临的挑战。NightHawk通过在线贝叶斯优化来确定最佳光强度和曝光时间，并引入了一种新颖的基于特征检测器的度量作为成本函数。在腿式机器人上的现场实验表明，该系统能将特征检测和匹配性能提高47-197%，从而在恶劣照明条件下实现更可靠的视觉估计。

> **摘要翻译:** 涵洞等地下环境由于光线昏暗和缺乏独特特征，给机器人视觉带来了重大挑战。尽管车载照明有所帮助，但它会引入镜面反射、过曝和功耗增加等问题。我们提出了NightHawk，一个结合主动照明和曝光控制以优化这些环境中图像质量的框架。NightHawk将在线贝叶斯优化问题公式化，以确定给定场景的最佳光强度和曝光时间。我们提出了一种新颖的基于特征检测器的度量来量化图像效用，并将其用作优化器的成本函数。我们将NightHawk构建为一个事件触发的递归优化管道，并将其部署在伊利运河下方涵洞中导航的腿式机器人上。现场实验结果表明，特征检测和匹配提高了47-197%，从而在挑战性照明条件下实现了更可靠的视觉估计。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [52] [Edge-Enabled Collaborative Object Detection for Real-Time Multi-Vehicle Perception](https://arxiv.org/abs/2506.06474)
> *边缘赋能的实时多车辆感知协同目标检测*

*Everett Richards, Bipul Thapa, Lena Mashayekhy* | **Main category: cs.RO**

**Keywords:** 边缘计算, 协同感知, 目标检测, 互联自动驾驶汽车, 低延迟

**Comment:** This paper has been accepted to IEEE EDGE 2025. The final version
  will be published in IEEE Xplore later this year

> **TL;DR:** 提出了一种名为ECOD的边缘赋能协同目标检测框架，通过边缘计算和多车辆协作，显著提高了互联自动驾驶汽车的目标分类准确性，并确保了低延迟实时处理。

**AI_Comments:** 这项研究通过引入边缘计算和多车辆协作来解决互联自动驾驶汽车中目标检测的准确性和延迟问题，具有创新性。它结合了车载系统的低延迟优势和云系统的多视角信息，通过边缘服务器实现了实时数据聚合和处理，有效克服了遮挡和盲区，并显著提高了目标分类准确性。其硬件测试平台的建立也增加了研究结果的可信度。

<details>
  <summary>Details</summary>

**Motivation:** 传统车载感知系统受遮挡和盲区限制，准确性有限；基于云的解决方案延迟高，不适用于自动驾驶的实时需求。

**Method:** 引入了边缘赋能协同目标检测（ECOD）框架，利用边缘计算和多CAV协作实现实时多视角目标检测。ECOD包含两个算法：感知聚合和协同估计（PACE）用于在边缘服务器上聚合多CAV检测数据以增强感知；可变目标统计和评估（VOTE）利用基于共识的投票机制整合多CAV数据以提高目标分类准确性。所有算法均在边缘设计，以实现实时低延迟操作。使用配备摄像头的机器人CAV和边缘服务器的硬件测试平台进行评估。

**Result:** ECOD显著提高了目标分类准确性，比传统单视角车载方法高出75%，同时确保了低延迟的边缘驱动实时处理。

**Conclusion:** 该研究突出了边缘计算在增强延迟敏感型自动驾驶系统协同感知方面的潜力。

> **ai_Abstract:** 针对互联自动驾驶汽车（CAV）中传统车载感知系统准确性受限和云端解决方案高延迟的问题，本文提出了一种边缘赋能协同目标检测（ECOD）框架。ECOD利用边缘计算和多CAV协作，通过感知聚合和协同估计（PACE）算法增强低能见度下的感知，并通过可变目标统计和评估（VOTE）算法通过共识投票提高目标分类准确性。实验结果表明，ECOD显著提升了目标分类准确性（比传统方法高出75%），并实现了低延迟实时处理，展示了边缘计算在协同感知领域的潜力。

> **摘要翻译:** 精确可靠的目标检测对于确保互联自动驾驶汽车（CAV）的安全和效率至关重要。传统的车载感知系统由于遮挡和盲区而准确性有限，而基于云的解决方案则引入了显著的延迟，使其不适用于动态环境中自动驾驶所需的实时处理需求。为了解决这些挑战，我们引入了一种创新的框架——边缘赋能协同目标检测（ECOD），用于CAV，该框架利用边缘计算和多CAV协作实现实时、多视角的目标检测。我们的ECOD框架集成了两个关键算法：感知聚合和协同估计（PACE）以及可变目标统计和评估（VOTE）。PACE在边缘服务器上聚合来自多个CAV的检测数据，以增强个体CAV能见度有限情况下的感知能力。VOTE利用基于共识的投票机制，通过整合来自多个CAV的数据来提高目标分类的准确性。这两种算法都在边缘设计，以实现实时操作，确保CAV的低延迟和可靠决策。我们开发了一个由配备摄像头的机器人CAV和边缘服务器组成的硬件控制测试平台，以评估我们框架的有效性。我们的实验结果表明，ECOD在提高目标分类准确性方面具有显著优势，性能优于传统的单视角车载方法高达75%，同时确保了低延迟的边缘驱动实时处理。这项研究突出了边缘计算在增强延迟敏感型自动驾驶系统协同感知方面的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [67] [Enhancing Situational Awareness in Underwater Robotics with Multi-modal Spatial Perception](https://arxiv.org/abs/2506.06476)
> *增强水下机器人多模态空间感知态势感知能力*

*Pushyami Kaveti, Ambjorn Grimsrud Waldum, Hanumant Singh, Martin Ludvigsen* | **Main category: cs.RO**

**Keywords:** 水下机器人, 多模态感知, SLAM, 态势感知, 传感器融合

**Comment:** 

> **TL;DR:** 本文提出了一种多模态融合感知方法，结合相机、IMU和声学设备，以实现在恶劣水下条件下鲁棒、实时的SLAM，提高水下机器人的态势感知能力。

**AI_Comments:** 该论文解决了水下机器人空间感知的一个关键挑战，即水下环境对传统视觉SLAM的严峻考验。其创新点在于提出并验证了多模态传感器融合的方法，通过结合相机、IMU和声学数据，显著提高了水下环境下的态势感知和SLAM鲁棒性。这对于推进水下自主作业和探索具有重要意义。同时，论文也诚实地指出了当前方法的局限性和未来研究方向，例如传感器校准和基于学习方法的进一步优化，这体现了严谨的科研态度。

<details>
  <summary>Details</summary>

**Motivation:** 自主水下航行器（AUVs）和遥控潜水器（ROVs）需要强大的空间感知能力（包括SLAM）来支持远程和自主任务。尽管基于视觉的系统成本低廉且能提供丰富的语义信息，但水下环境（如光衰减、反向散射和低对比度）会严重降低图像质量，导致传统视觉SLAM管道失效。此外，这些管道通常依赖单目或立体输入，限制了其在多摄像头配置车辆上的可扩展性。

**Method:** 提出利用多模态传感，融合来自多个传感器（包括相机、惯性测量单元（IMU）和声学设备）的数据，以增强态势感知并实现鲁棒、实时的SLAM。研究了几何和基于学习的技术以及语义分析。

**Result:** 通过在特隆赫姆峡湾的几次实地部署中从工作级ROV收集的数据进行的实验表明，在视觉挑战性的水下条件下，实时可靠的状态估计和高质量的3D重建是可行的。

**Conclusion:** 在视觉挑战性的水下条件下，多模态融合感知可以实现实时可靠的状态估计和高质量的3D重建。研究还讨论了系统约束并指出了开放的研究问题，如传感器校准和基于学习方法的局限性，这些问题需要进一步探索以推进大规模水下作业。

> **ai_Abstract:** 本文针对水下机器人（AUV和ROV）在恶劣水下环境中传统视觉SLAM失效的问题，提出了一种多模态感知融合方案。该方案融合了相机、IMU和声学设备的数据，旨在增强水下机器人的态势感知能力，并实现鲁棒、实时的同步定位与建图（SLAM）。研究探索了几何和基于学习的技术以及语义分析，并通过在特隆赫姆峡湾的工作级ROV实地部署数据进行了验证。实验结果证明了在视觉受限的水下条件下，该方法能够实现实时可靠的状态估计和高质量的3D重建。文章还讨论了系统限制和未来研究方向，如传感器校准和基于学习方法的局限性。

> **摘要翻译:** 自主水下航行器（AUVs）和遥控潜水器（ROVs）需要强大的空间感知能力，包括同步定位与建图（SLAM），以支持远程和自主任务。基于视觉的系统在这些进步中不可或缺，它们能以低成本捕获丰富的颜色和纹理，并实现语义场景理解。然而，水下条件——例如光衰减、反向散射和低对比度——经常会降低图像质量，以至于传统的基于视觉的SLAM管道失效。此外，这些管道通常依赖单目或立体输入，限制了它们对许多车辆上常见的多摄像头配置的可扩展性。为了解决这些问题，我们提出利用多模态传感，融合来自多个传感器（包括相机、惯性测量单元（IMU）和声学设备）的数据，以增强态势感知并实现鲁棒、实时的SLAM。我们探索了几何和基于学习的技术以及语义分析，并对在特隆赫姆峡湾几次实地部署中从工作级ROV收集的数据进行了实验。通过我们的实验结果，我们证明了在视觉挑战性的水下条件下，实时可靠的状态估计和高质量的3D重建是可行的。我们还讨论了系统约束并指出了开放的研究问题，例如传感器校准、基于学习方法的局限性，这些问题需要进一步探索以推进大规模水下作业。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [81] [BeliefMapNav: 3D Voxel-Based Belief Map for Zero-Shot Object Navigation](https://arxiv.org/abs/2506.06487)
> *BeliefMapNav：基于3D体素置信度图的零样本物体导航*

*Zibo Zhou, Yue Hu, Lingkai Zhang, Zonglin Li, Siheng Chen* | **Main category: cs.RO**

**Keywords:** 零样本物体导航, 3D体素图, 置信度图, LLM, VLM, 空间推理

**Comment:** 

> **TL;DR:** BeliefMapNav提出了一种基于3D体素置信度图的方法，通过整合语义和空间推理来改进零样本物体导航，在多个基准测试中取得了最先进的性能。

**AI_Comments:** 该研究的创新之处在于有效地弥合了LLM/VLM的高级语义推理与导航所需的低级空间理解之间的鸿沟。3D体素置信度图提供了一个关键的全局空间上下文，这是以前的零样本方法所缺乏的，从而实现了更鲁棒和高效的导航。SPL的显著提升也凸显了其实用效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的零样本物体导航方法（如基于LLM和VLM的模型）在选择下一个目标时缺乏对环境的全局理解和有效的空间推理能力，导致贪婪决策。

**Method:** 提出了一种新颖的3D体素置信度图，用于估计目标在体素化3D空间中的先验存在分布。该方法将LLM的语义先验、视觉嵌入与分层空间结构及实时观测相结合，构建目标位置的全面3D全局后验置信度。在此基础上，引入BeliefMapNav系统，其优势在于：1）将LLM语义推理锚定在3D分层语义体素空间中以实现精确目标估计；2）整合顺序路径规划以实现高效的全局导航决策。

**Result:** BeliefMapNav在HM3D、MP3D和HSSD基准测试中实现了最先进的（SOTA）成功率（SR）和按路径长度加权的成功率（SPL）。相较于此前最佳SR方法，SPL显著提高了46.4%。

**Conclusion:** BeliefMapNav通过引入3D体素置信度图，有效克服了现有零样本物体导航方法在空间推理和全局理解方面的局限性，成功整合了语义和空间信息，在导航性能和效率上达到了SOTA水平。

> **ai_Abstract:** 本文介绍了BeliefMapNav，一种新颖的零样本物体导航系统。它通过提出一个3D体素置信度图来解决当前基于LLM/VLM方法的局限性，即缺乏全局空间理解。该地图整合了来自LLM的语义先验、视觉嵌入和实时观测，以构建目标位置的全面3D全局后验置信度。BeliefMapNav利用此地图进行精确的目标估计和高效的全局路径规划，在多个基准测试中取得了最先进的成果，显著提高了成功率和路径效率。

> **摘要翻译:** 零样本物体导航（ZSON）允许机器人在不依赖预建地图或特定任务训练的情况下，使用自然语言指令在陌生环境中找到目标物体。最近的通用模型，如大型语言模型（LLM）和视觉语言模型（VLM），赋予代理零样本估计目标物体位置的语义推理能力。然而，这些模型在没有保持对环境的全局理解的情况下，常常贪婪地选择下一个目标，并且在有效导航所需的空间推理方面存在根本性局限性。为了克服这些限制，我们提出了一种新颖的基于3D体素的置信度图，该图估计目标在体素化3D空间中的先验存在分布。这种方法使代理能够将来自LLM的语义先验和视觉嵌入与分层空间结构以及实时观测相结合，以构建目标位置的全面3D全局后验置信度。在此3D体素图的基础上，我们引入了BeliefMapNav，一个具有两个关键优势的高效导航系统：i）将LLM语义推理 grounding 到3D分层语义体素空间中，以实现精确的目标位置估计，以及ii）整合顺序路径规划以实现高效的全局导航决策。在HM3D、MP3D和HSSD基准上的实验表明，BeliefMapNav实现了最先进的（SOTA）成功率（SR）和按路径长度加权的成功率（SPL），比之前最佳SR方法提高了显著的46.4% SPL，验证了其有效性和效率。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [95] [MapleGrasp: Mask-guided Feature Pooling for Language-driven Efficient Robotic Grasping](https://arxiv.org/abs/2506.06535)
> *MapleGrasp: 面具引导的特征池化用于语言驱动的高效机器人抓取*

*Vineet Bhat, Naman Patel, Prashanth Krishnamurthy, Ramesh Karri, Farshad Khorrami* | **Main category: cs.RO**

**Keywords:** 机器人抓取, 语言驱动, 特征池化, 深度学习, 语义分割

**Comment:** 

> **TL;DR:** MapleGrasp通过掩码引导的特征池化和大型数据集，提高了语言驱动机器人抓取（LDRG）的效率、准确性和泛化能力。

**AI_Comments:** 这篇论文通过引入“掩码引导特征池化”这一创新机制，有效降低了计算复杂度并提高了语言驱动机器人抓取的效率和准确性。其两阶段训练策略和对CLIP特征的巧妙利用值得关注。此外，RefGraspNet数据集的发布显著推动了开放词汇抓取领域的数据规模和模型泛化能力。在真实世界实验中取得的良好表现也证明了其方法的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 通过自然语言命令操纵未见过的物体对机器人来说仍然具有挑战性，且现有语言驱动机器人抓取（LDRG）方法在计算效率和泛化能力方面有待提升。

**Method:** 本文提出Mask-guided feature pooling，一种两阶段训练策略：首先，视觉-语言模型从CLIP融合的嵌入生成特征图，并结合文本嵌入产生分割掩码；其次，解码器仅在这些掩码区域内池化令牌特征，以高效预测抓取姿态。同时引入了比现有大八倍的RefGraspNet开源数据集，并将2D抓取预测扩展到3D。

**Result:** 在OCID-VLG基准上，掩码池化使性能比现有方法提高12%。引入了RefGraspNet，一个比现有数据集大8倍的开源数据集。在LIBERO模拟基准上，性能与最新视觉-语言-动作（VLA）模型相当，且在不同任务套件中泛化能力更强。在真实世界7自由度Franka机械臂上，对未见过物体的成功率为57%，超过竞争基线7%。

**Conclusion:** MapleGrasp通过其创新的掩码引导特征池化和大规模RefGraspNet数据集，显著提升了语言驱动机器人抓取任务的效率、准确性和泛化能力，并在实际应用中表现出色。

> **ai_Abstract:** MapleGrasp提出了一种名为掩码引导特征池化的轻量级方法，用于提升语言驱动机器人抓取（LDRG）的效率和性能。该方法采用两阶段训练，利用视觉-语言模型生成分割掩码，并在此掩码区域内高效池化特征以预测抓取姿态。结合新引入的大规模RefGraspNet数据集，MapleGrasp在多个基准测试中展示了显著的性能提升和更强的泛化能力，并在真实世界机器人实验中取得了高成功率。

> **摘要翻译:** 通过自然语言命令操纵未见过的物体对机器人来说仍然具有挑战性。语言驱动机器人抓取（LDRG）从自然语言查询和RGB-D图像中预测稳定的抓取姿态。本文介绍了一种轻量级增强现有LDRG方法的技术——掩码引导特征池化。我们的方法采用两阶段训练策略：首先，视觉-语言模型从CLIP融合的嵌入生成特征图，然后通过文本嵌入进行上采样和加权，以生成分割掩码。接下来，解码器为抓取预测生成独立的特征图，仅在这些掩码区域内池化令牌特征，从而高效地预测抓取姿态。这种有针对性的池化方法降低了计算复杂度，加速了训练和推理。在OCID-VLG基准测试中，结合掩码池化使性能比现有方法提高了12%。此外，我们引入了RefGraspNet，一个比现有替代方案大八倍的开源数据集，显著增强了开放词汇抓取模型的泛化能力。通过深度映射和逆运动学将2D抓取预测扩展到3D，我们的模块化方法在LIBERO模拟基准上实现了与最新视觉-语言-动作（VLA）模型相当的性能，并在不同任务套件中具有更好的泛化能力。在7自由度Franka机械臂上的真实世界实验表明，对于未见过的物体，成功率为57%，超过竞争基线7%。代码将在发布后发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [108] [Semantics-aware Predictive Inspection Path Planning](https://arxiv.org/abs/2506.06560)
> *语义感知预测性巡检路径规划*

*Mihir Dharmadhikari, Kostas Alexis* | **Main category: cs.RO**

**Keywords:** 巡检路径规划, 语义感知, 预测性规划, 机器人, 压载水舱

**Comment:** Accepted at IEEE Transactions on Field Robotics

> **TL;DR:** 本文提出了一种新颖的语义感知预测性规划（SPP）范式，用于工业环境中的巡检路径规划。该方法利用语义空间重复模式识别和预测来规划路径，并在仿真和实际船舶压载水舱中进行了验证，结果显示其在巡检时间和语义表面覆盖方面均优于现有技术。

**AI_Comments:** 本文的创新点在于提出了“语义感知预测性规划”范式，利用了工业环境中语义的结构化和重复性特点进行模式识别和预测，从而优化巡检路径。这种方法显著提高了巡检效率，对于需要高效、全面巡检的复杂工业环境具有重要意义。在真实船舶上的部署验证也增加了其应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 工业环境中（如船舶压载水舱）需要巡检特定对象或结构（“语义”）时，这些语义往往呈现结构化和重复的空间排列。受此启发，本文旨在利用这些重复模式来优化巡检路径规划。

**Method:** 本文首先提出了一种算法，用于在语义场景图表示中识别语义的空间重复模式（精确或不精确），并利用这些模式预测环境中未见部分的图演变。此外，还提出了两种针对压载水舱巡检的路径规划策略，以利用这些预测。为了评估该预测性规划范式的性能，进行了仿真和实验评估，包括与现有技术的比较以及处理不完美模式的能力测试。该方法还部署在两艘真实船舶的压载水舱内的抗碰撞空中机器人上。

**Result:** 仿真和现场实验结果表明，与现有技术相比，该方法在巡检时间方面有显著改善，同时保持了相同或更好的语义表面覆盖率。

**Conclusion:** 本文提出的语义感知预测性规划（SPP）范式能够显著提高结构化工业环境（如压载水舱）的巡检效率和覆盖率。

> **ai_Abstract:** 本文提出了一种名为“语义感知预测性规划”（SPP）的新型语义感知巡检路径规划范式。针对工业环境中语义的结构化和重复性空间排列，本文贡献了一种算法，用于识别语义场景图中的精确或不精确的空间重复模式，并利用这些模式预测环境中未见部分的图演变。在此基础上，提出了两种利用这些预测的巡检路径规划策略，并针对压载水舱巡检进行了优化。通过仿真和在真实船舶压载水舱中的实验评估，结果显示该方法在巡检时间上显著优于现有技术，同时保持了相同或更好的语义表面覆盖率。

> **摘要翻译:** 本文提出了一种新颖的语义感知巡检路径规划范式，称为“语义感知预测性规划”（SPP）。需要巡检特定对象或结构（称为“语义”）的工业环境，例如船舶内部的压载水舱，通常呈现出感兴趣语义的结构化和重复性空间排列。受此启发，我们首先贡献了一种算法，该算法在语义场景图表示中识别语义的空间重复模式——精确或不精确——并利用这些模式预测环境中未见部分的图演变。此外，提出了两种利用这些预测的巡检路径规划策略，专门针对压载水舱巡检。为了评估这种新型预测性规划范式的性能，我们进行了仿真和实验评估。首先，我们进行了一项仿真研究，将该方法与相关现有技术进行比较，并进一步展示了其处理不完美模式的能力测试。其次，我们将我们的方法部署在两艘真实船舶压载水舱内运行的抗碰撞空中机器人上。仿真和现场实验结果均表明，在巡检时间方面，该方法比现有技术有显著改进，同时保持了相同或更好的语义表面覆盖率。描述该方法不同部分和现场部署的一系列视频可在 https://tinyurl.com/spp-videos 获取。该工作的代码可在 https://github.com/ntnu-arl/predictive_planning_ros 获取。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [122] [Towards Terrain-Aware Task-Driven 3D Scene Graph Generation in Outdoor Environments](https://arxiv.org/abs/2506.06562)
> *面向室外环境下地形感知和任务驱动的3D场景图生成*

*Chad R Samuelson, Timothy W McLain, Joshua G Mangelson* | **Main category: cs.RO**

**Keywords:** 3D场景图, 室外环境, 自主操作, 机器人应用, 点云

**Comment:** Presented at the 2025 IEEE ICRA Workshop on Field Robotics

> **TL;DR:** 本文探讨了在室外环境中生成3D场景图（3DSGs），以支持高水平自主操作。

**AI_Comments:** 该论文的创新之处在于将主要在室内环境中研究的3D场景图扩展到更具挑战性的室外环境，这对于推进野外机器人的高水平自主操作至关重要。尽管摘要中未详细说明方法，但对地形感知和任务驱动的关注暗示了其在实际应用中的潜力。初步的定性结果虽然不是定量数据，但为该重要领域未来的研究奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的3D场景表示（如点云和占用网格）缺乏高水平推理所需的结构化语义组织。3D场景图（3DSGs）通过整合几何、拓扑和语义关系来解决这一问题，从而实现结构化推理、上下文感知决策和自适应规划。然而，大多数现有工作集中在室内3DSGs，因此需要研究其在室外环境中的构建和实用性。

**Method:** 本文提出了一种为大型室外环境生成与任务无关的度量语义点云的方法，并对现有室内3DSG生成技术进行了修改以适用于室外环境。

**Result:** 初步定性结果表明了室外3DSGs的可行性。

**Conclusion:** 室外3DSGs是可行的，并有望在未来的实际野外机器人应用中部署，以改善高水平自主操作的上下文感知决策和自适应规划。

> **ai_Abstract:** 本文旨在解决传统3D场景表示在机器人高层推理方面的局限性，重点研究3D场景图（3DSGs）在室外环境中的生成和应用。与以往多数侧重于室内环境的工作不同，作者提出了一种生成与任务无关的度量语义点云的方法，并对现有室内3DSG技术进行了修改以适应室外应用。初步的定性结果证明了室外3DSGs的可行性，并强调了它们在实际野外机器人应用中增强上下文感知决策和自适应规划的潜力。

> **摘要翻译:** 高水平自主操作依赖于机器人构建足够表达性环境模型的能力。传统的三维（3D）场景表示，如点云和占用网格，提供详细的几何信息但缺乏高水平推理所需的结构化语义组织。3D场景图（3DSGs）通过将几何、拓扑和语义关系集成到多级图表示中来解决这一限制。通过捕获对象和空间布局的层次抽象，3DSGs使机器人能够以结构化方式对环境进行推理，从而改善上下文感知决策和自适应规划。尽管最近的大多数工作都集中在室内3DSGs上，但本文研究了它们在室外环境中的构建和实用性。我们提出了一种为大型室外环境生成与任务无关的度量语义点云的方法，并提出了对现有室内3DSG生成技术的修改以适用于室外。我们的初步定性结果证明了室外3DSGs的可行性，并突出了它们在未来实际野外机器人应用中部署的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [135] [NeSyPack: A Neuro-Symbolic Framework for Bimanual Logistics Packing](https://arxiv.org/abs/2506.06567)
> *NeSyPack：一种用于双手物流包装的神经符号框架*

*Bowei Li, Peiqi Yu, Zhenran Tang, Han Zhou, Yifan Sun, Ruixuan Liu, Changliu Liu* | **Main category: cs.RO**

**Keywords:** 神经符号框架, 双手物流包装, 分层系统, 机器人, 技能图

**Comment:** 10 pages, 5 figures. Accepted to the RSS 2025 Workshop on
  Benchmarking Robot Manipulation: Improving Interoperability and Modularity.
  First Prize in the WBCD competition at ICRA 2025. Equal contribution by Bowei
  Li and Peiqi Yu

> **TL;DR:** NeSyPack是一个神经符号框架，通过结合数据驱动模型和符号推理，实现可解释、通用、数据高效且可靠的双手物流包装，并在WBCD竞赛中获得一等奖。

**AI_Comments:** NeSyPack的创新之处在于其神经符号混合方法，它结合了数据驱动模型的学习能力和符号推理的可解释性及通用性。这种模块化设计解决了端到端模型在面对新任务时需要大量重新训练的问题，提高了系统的鲁棒性和数据效率。在实际竞赛中取得的成功进一步证明了其在复杂机器人操作任务中的实用性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文旨在解决现有端到端模型需要大规模重新训练的问题，并构建一个通用、数据高效、可靠且可解释的双手物流包装系统。

**Method:** NeSyPack结合了数据驱动模型和符号推理，构建了一个可解释的分层系统。它通过分层推理将任务分解为子任务，并进一步分解为由符号技能图管理的原子技能。该技能图选择技能参数、机器人配置和任务特定的控制策略进行执行。这种模块化设计实现了鲁棒性、适应性和高效重用。

**Result:** 使用NeSyPack，研究团队在2025年IEEE机器人与自动化国际会议上的“双手能做什么”（WBCD）竞赛中获得一等奖。NeSyPack在性能上优于需要大规模重新训练的端到端模型。

**Conclusion:** NeSyPack框架通过结合神经符号方法，提供了一种通用、数据高效、可靠且可解释的双手物流包装解决方案，并在实际竞赛中证明了其有效性和优越性。

> **ai_Abstract:** NeSyPack是一个创新的神经符号框架，专为双手物流包装任务设计。它融合了数据驱动模型和符号推理，创建了一个可解释、通用、数据高效且可靠的分层系统。通过将复杂任务分解为由符号技能图管理的原子技能，NeSyPack实现了模块化、鲁棒性、适应性和高效的技能重用，显著优于传统的端到端模型。该框架的有效性已在2025年IEEE机器人与自动化国际会议的WBCD竞赛中得到验证，并荣获一等奖。

> **摘要翻译:** 本文介绍了NeSyPack，一种用于双手物流包装的神经符号框架。NeSyPack结合了数据驱动模型和符号推理，构建了一个可解释的分层系统，该系统具有通用性、数据效率和可靠性。它通过分层推理将任务分解为子任务，并进一步分解为由符号技能图管理的原子技能。该技能图选择技能参数、机器人配置和任务特定的控制策略进行执行。这种模块化设计实现了鲁棒性、适应性和高效重用——优于需要大规模重新训练的端到端模型。使用NeSyPack，我们的团队在2025年IEEE机器人与自动化国际会议上的“双手能做什么”（WBCD）竞赛中获得一等奖。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [147] [Enhancing Robot Safety via MLLM-Based Semantic Interpretation of Failure Data](https://arxiv.org/abs/2506.06570)
> *机器人安全增强：基于多模态大语言模型的故障数据语义解释*

*Aryaman Gupta, Yusuf Umut Ciftci, Somil Bansal* | **Main category: cs.RO**

**Keywords:** 机器人安全, 多模态大语言模型, 故障分析, 语义解释, 在线故障检测

**Comment:** 

> **TL;DR:** 利用多模态大语言模型自动分析机器人故障数据，生成语义化故障模式，以提高机器人安全和学习能力。

**AI_Comments:** 这篇论文的创新点在于利用了多模态大语言模型（MLLMs）的强大推理能力来自动化处理和解释大规模机器人故障数据，从而克服了传统手动分析的局限性。这种方法将非结构化的故障数据转化为可操作的语义信息，对提高机器人安全性和学习效率具有重要意义。特别是其在指导数据收集和在线故障检测方面的应用，显示了其潜在的实际价值。

<details>
  <summary>Details</summary>

**Motivation:** 机器人系统在真实世界中会遇到导致故障的复杂场景，这些故障数据对改进性能很重要，但手动分析大规模故障数据不切实际，因此需要自动化方法来提高机器人安全性和可靠性。

**Method:** 提出一种利用多模态大语言模型（MLLMs）自动将大规模机器人故障数据组织成有语义意义的集群的方法。该方法利用MLLMs的推理能力，从原始感知轨迹中推断高级故障原因，并从未经整理的故障日志中发现可解释的结构。

**Result:** 发现的语义集群揭示了潜在的模式和假设的故障原因，实现了可扩展的从经验中学习。这些故障模式可以指导有针对性的数据收集以优化策略，加速智能体策略的迭代改进和整体安全性。此外，这些语义集群还可用于在线故障检测。

**Conclusion:** 该框架通过将真实世界故障转化为可操作和可解释的适应信号，从而增强了机器人的学习能力和鲁棒性。

> **ai_Abstract:** 本文提出了一种基于多模态大语言模型（MLLMs）的自动化方法，用于将大规模机器人故障数据组织成语义集群。该方法能够从原始感知数据中推断出高级故障原因和可解释的结构，从而实现从故障中进行可扩展学习。研究表明，这些语义集群能够指导策略优化、加速学习过程，并可用于在线故障检测，最终增强机器人的安全性和鲁棒性。

> **摘要翻译:** 随着机器人系统日益融入现实世界环境，从自动驾驶汽车到家用助手，它们不可避免地会遇到导致故障的各种非结构化场景。虽然此类故障带来了安全性和可靠性挑战，但它们也为改善未来性能提供了丰富的感知数据。然而，手动分析大规模故障数据集是不切实际的。在这项工作中，我们提出了一种自动将大规模机器人故障数据组织成具有语义意义的集群的方法，从而实现在无人监督下从故障中进行可扩展学习。我们的方法利用了在互联网规模数据上训练的多模态大语言模型（MLLMs）的推理能力，从原始感知轨迹中推断出高级故障原因，并在未经整理的故障日志中发现可解释的结构。这些语义集群揭示了潜在的模式和假设的故障原因，从而实现了可扩展的从经验中学习。我们证明，所发现的故障模式可以指导有针对性的数据收集以优化策略，加速智能体策略的迭代改进和整体安全性。此外，我们还表明这些语义集群可用于在线故障检测，为实时适应提供了一种轻量级但功能强大的保障。我们证明，该框架通过将真实世界故障转化为可操作和可解释的适应信号，从而增强了机器人的学习能力和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [157] [Underwater Multi-Robot Simulation and Motion Planning in Angler](https://arxiv.org/abs/2506.06612)
> *Angler中的水下多机器人仿真与运动规划*

*Akshaya Agrawal, Evan Palmer, Zachary Kingston, Geoffrey A. Hollinger* | **Main category: cs.RO**

**Keywords:** 水下机器人, 多机器人系统, 仿真, 运动规划, Angler

**Comment:** Accepted for OCEANS 2025 Brest

> **TL;DR:** 该研究扩展了Angler开源框架，使其支持水下多机器人仿真和运动规划，从而能够在动态环境中开发和测试多机器人算法。

**AI_Comments:** 这项工作具有重要意义，因为它填补了现有Angler仿真框架在多机器人支持方面的空白。通过提供一个高保真、模块化的多机器人仿真平台，它极大地降低了水下多机器人算法开发和测试的成本与风险，加速了该领域的研究进展。其模块化设计和与ROS 2、OMPL的集成也增强了其可用性和扩展性。

<details>
  <summary>Details</summary>

**Motivation:** 在水下环境中部署多机器人系统成本高昂且耗时，因此需要一个能紧密模拟真实世界且支持多机器人的仿真框架来解耦软硬件开发。现有Angler框架虽接近现实但缺乏多机器人支持。

**Method:** 本研究通过模块化架构扩展了Angler，实现了Gazebo、ArduSub软件在环(SITL)和MAVROS之间的无冲突通信，以同时操作多个机器人。它还通过ROS 2中的JointTrajectory控制器与级联控制器接口，并集成了Open Motion Planning Library (OMPL)、碰撞避免模块和程序化环境生成工具。

**Result:** 开发了一个支持多机器人仿真和运动规划的Angler扩展，该扩展能够实现水下多机器人运动规划在动态环境中的开发和基准测试。

**Conclusion:** 该工作使得在动态水下环境中进行多机器人运动规划的开发和基准测试成为可能。

> **ai_Abstract:** 本论文介绍了一个Angler开源框架的扩展，旨在解决水下多机器人系统开发中真实环境测试的高成本和复杂性问题。Angler原本是一个模拟低级通信协议的框架，但不支持多机器人仿真。该扩展引入了一个模块化架构，通过在Gazebo、ArduSub SITL和MAVROS之间建立无冲突通信通道，实现了在同一环境中同时操作多个机器人。此外，它集成了ROS 2的JointTrajectory控制器、Open Motion Planning Library (OMPL)、碰撞避免模块和程序化环境生成工具，从而支持水下多机器人运动规划的开发和基准测试，尤其适用于动态环境。

> **摘要翻译:** 在水下环境中部署多机器人系统成本高昂且耗时；在仿真中测试算法和软件通过解耦软硬件改进了开发过程。然而，这需要一个与真实世界高度相似的仿真框架。Angler是一个开源框架，它模拟了机载自动驾驶仪（如ArduSub）的低级通信协议，提供了一个接近现实的框架，但遗憾的是缺乏对多机器人仿真的支持。我们提出了Angler的一个扩展，它支持多机器人仿真和运动规划。我们的扩展具有模块化架构，在Gazebo、ArduSub软件在环（SITL）和MAVROS之间创建了非冲突的通信通道，以便在同一环境中同时操作多个机器人。我们的多机器人运动规划模块通过ROS 2中的JointTrajectory控制器与级联控制器接口。我们还提供了与Open Motion Planning Library (OMPL)的集成、一个碰撞避免模块以及用于程序化环境生成的工具。我们的工作使得在动态环境中进行水下多机器人运动规划的开发和基准测试成为可能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [168] [Attention-Based Convolutional Neural Network Model for Human Lower Limb Activity Recognition using sEMG](https://arxiv.org/abs/2506.06624)
> *基于注意力机制的卷积神经网络模型用于sEMG人体下肢活动识别*

*Mojtaba Mollahossein, Farshad Haghgoo Daryakenari, Mohammad Hossein Rohban, Gholamreza Vossoughi* | **Main category: cs.RO**

**Keywords:** sEMG, 下肢活动识别, 注意力机制, 深度神经网络, 实时

**Comment:** 6 pages, 3 figures

> **TL;DR:** 本研究提出了一种轻量级、基于注意力机制的深度神经网络，用于使用sEMG信号进行实时下肢运动分类，在准确性和计算效率方面表现出色，适用于辅助机器人和康复系统。

**AI_Comments:** 该论文提出了一种轻量级且高效的注意力机制深度神经网络，用于sEMG信号的下肢活动识别。其创新性在于模型参数少且无需复杂预处理，这对于实时部署具有重要意义。在实际应用场景中，计算成本和实时响应能力是关键因素，该模型在这两方面都表现出色。其在辅助机器人和康复系统领域的潜在应用前景广阔。

<details>
  <summary>Details</summary>

**Motivation:** 使用表面肌电图（sEMG）信号准确分类下肢运动对于辅助机器人和康复系统至关重要。

**Method:** 本研究提出了一种轻量级基于注意力机制的深度神经网络（DNN），用于使用公开的BASAN数据集中的多通道sEMG数据进行实时运动分类。该模型仅包含62,876个参数，无需计算昂贵的预处理，适合实时部署。采用留一法验证策略，在行走、屈膝站立和伸膝坐立三种运动类别上对模型进行了评估。

**Result:** 该网络在验证集上实现了86.74%的准确率，在测试集上实现了85.38%的准确率，在实际条件下表现出强大的分类性能。与现有模型的比较分析突出了该方法在计算成本和实时响应至关重要场景下的效率和有效性。

**Conclusion:** 研究结果表明，所提出的模型是集成到人机交互系统中上层控制器的一个有前景的候选方案。

> **ai_Abstract:** 本研究提出了一种轻量级、基于注意力机制的深度神经网络（DNN），利用多通道sEMG信号对人体下肢活动进行实时分类。该模型参数少，无需复杂预处理，在BASAN数据集上对行走、屈膝站立和伸膝坐立三种运动类别进行了评估，在验证集和测试集上分别达到了86.74%和85.38%的准确率。研究结果表明，该模型在计算效率和分类性能上均表现出色，有望应用于辅助机器人和康复系统中的人机交互系统。

> **摘要翻译:** 使用表面肌电图（sEMG）信号准确分类下肢运动在辅助机器人和康复系统中起着关键作用。在本研究中，我们提出了一种轻量级、基于注意力机制的深度神经网络（DNN），用于使用公开的BASAN数据集中的多通道sEMG数据进行实时运动分类。所提出的模型仅包含62,876个参数，并且无需计算昂贵的预处理，使其适用于实时部署。我们采用留一法验证策略，以确保模型在不同受试者之间的泛化能力，并在三种运动类别上对模型进行了评估：行走、屈膝站立和伸膝坐立。该网络在验证集上实现了86.74%的准确率，在测试集上实现了85.38%的准确率，在实际条件下表现出强大的分类性能。与现有模型的比较分析突出了我们方法的效率和有效性，尤其是在计算成本和实时响应至关重要的场景中。结果表明，所提出的模型是集成到人机交互系统中上层控制器的一个有前景的候选方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [177] [Active Test-time Vision-Language Navigation](https://arxiv.org/abs/2506.06630)
> *活跃测试时间视觉语言导航*

*Heeju Ko, Sungjune Kim, Gyeongrok Oh, Jeongyoon Yoon, Honglak Lee, Sujin Jang, Seungryong Kim, Sangpil Kim* | **Main category: cs.RO**

**Keywords:** 视觉语言导航, 主动学习, 测试时间适应, 不确定性校准, 人机交互

**Comment:** 

> **TL;DR:** ATENA是一个测试时间主动学习框架，通过情景反馈和混合熵优化，帮助视觉语言导航代理在陌生环境中克服分布偏移并提高性能。

**AI_Comments:** 本文的创新点在于提出了一个结合人机交互和自主动学习的测试时间主动学习框架ATENA，以应对视觉语言导航在陌生环境中的性能退化问题。特别是，混合熵优化和自主动学习策略的引入，使得代理能够更好地校准不确定性并进行自适应决策，有效克服了测试时间的分布偏移。这对于现实世界中机器人导航的鲁棒性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 离线训练的视觉语言导航(VLN)策略在陌生测试环境中性能下降，且无法获得外部交互或反馈。现有的熵最小化方法可能导致错误累积和过度自信。

**Method:** 本文引入了ATENA（Active TEst-time Navigation Agent），一个测试时间主动学习框架，通过对不确定导航结果的情景反馈实现实用的人机交互。ATENA学习在成功情景中增加确定性，在失败情景中减少确定性，从而改善不确定性校准。提出了混合熵优化，其中熵是从动作和伪专家分布的组合中获得的，从而同时控制预测置信度和动作偏好。此外，还提出了一种自主动学习策略，使代理能够根据自信的预测评估其导航结果。

**Result:** 在REVERIE、R2R和R2R-CE等具有挑战性的VLN基准测试中，ATENA成功克服了测试时间的分布偏移，并在各种设置下均优于对比的基线方法。

**Conclusion:** ATENA通过其主动学习框架、混合熵优化和自主动学习策略，有效解决了视觉语言导航在测试时间面临的挑战，显著提高了在陌生环境中的性能和不确定性校准。

> **ai_Abstract:** 本文提出了ATENA，一个用于视觉语言导航（VLN）的测试时间主动学习框架，旨在解决代理在陌生环境中性能下降和现有熵最小化方法局限性的问题。ATENA通过情景反馈实现人机交互，学习校准不确定性。其核心方法包括混合熵优化（结合动作和伪专家分布）和自主动学习策略，使代理能持续评估并自适应决策。实验表明，ATENA在多个VLN基准测试中有效克服了分布偏移，并优于基线方法。

> **摘要翻译:** 视觉语言导航（VLN）策略在离线数据集上训练后，部署到不熟悉的导航环境进行测试时，其任务性能通常会下降，因为代理通常在没有外部交互或反馈的情况下进行评估。熵最小化已成为一种实用的解决方案，用于在测试时减少预测不确定性；然而，它可能会遭受累积误差的影响，因为代理在没有足够的上下文基础的情况下，可能会对不正确的动作过度自信。为了解决这些挑战，我们引入了ATENA（Active TEst-time Navigation Agent），一个测试时间主动学习框架，通过对不确定导航结果的情景反馈实现实用的人机交互。特别是，ATENA学习在成功情景中增加确定性，在失败情景中减少确定性，从而改善不确定性校准。在此，我们提出了混合熵优化，其中熵是从动作和伪专家分布（假设代理选择的动作是最佳的假设动作分布）的组合中获得的，从而同时控制预测置信度和动作偏好。此外，我们提出了一种自主动学习策略，使代理能够根据自信的预测评估其导航结果。因此，代理在所有迭代中保持积极参与，从而实现良好基础和自适应的决策。在具有挑战性的VLN基准测试——REVERIE、R2R和R2R-CE——上的广泛评估表明，ATENA成功克服了测试时间的分布偏移，在各种设置下均优于对比的基线方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [184] [Self-Adapting Improvement Loops for Robotic Learning](https://arxiv.org/abs/2506.06658)
> *机器人学习的自适应改进循环*

*Calvin Luo, Zilai Zeng, Mingxi Jia, Yilun Du, Chen Sun* | **Main category: cs.RO**

**Keywords:** 机器人学习, 自适应改进循环, 在线学习, 泛化, 视频生成模型

**Comment:** 

> **TL;DR:** 提出SAIL框架，使机器人通过自收集经验和互联网规模模型自适应地持续改进，解决泛化性挑战。

**AI_Comments:** 这项工作提出了一个新颖的在线自适应学习框架SAIL，通过结合互联网规模的预训练模型和自收集经验，有效解决了机器人学习中泛化性差的挑战。其核心创新在于“自适应改进循环”的理念，使得机器人能够持续地从自身经验中学习和进步，且对数据质量要求不高，具有重要的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频生成模型在机器人任务中泛化到未见任务仍是挑战。尽管可以利用离线数据，但目标是设计能通过自收集行为在线持续改进的智能体。

**Method:** 提出自适应改进循环（SAIL）框架。该框架使领域内视频模型通过与互联网规模预训练视频模型进行适应性学习，在自生成轨迹上迭代更新自身，从而稳定地提高特定任务的性能。

**Result:** 在MetaWorld任务和真实机械臂操作任务中，SAIL在多轮迭代后，对初始训练中未见的新任务持续展现出性能提升。SAIL对自收集经验的过滤方式以及初始领域内演示的质量表现出令人惊讶的鲁棒性。

**Conclusion:** 通过与总结的互联网规模数据进行适应性学习，并通过在线经验学习，SAIL展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的方法。

> **ai_Abstract:** 本文提出了自适应改进循环（SAIL）框架，旨在解决机器人学习中视频生成模型对未见任务泛化能力不足的问题。SAIL通过让领域内视频模型利用互联网规模预训练模型生成的自收集轨迹进行迭代更新，实现在线持续性能提升。实验证明，SAIL在多种机器人任务上对新任务表现出持续的性能改进，并且对经验过滤和初始演示质量具有鲁棒性，从而展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的有效途径。

> **摘要翻译:** 视频生成模型在专家演示上进行训练，已被用作高性能的文本条件视觉规划器来解决机器人任务。然而，泛化到未见任务仍然是一个挑战。尽管可以利用来自额外预收集的离线数据源（如网络规模视频数据集）的已学习先验知识来促进泛化能力的提高，但在经验时代，我们旨在设计能够通过自收集行为在线持续改进的智能体。因此，在这项工作中，我们提出了自适应改进循环（SAIL），其中领域内视频模型通过与互联网规模预训练视频模型进行适应性学习，在自生成轨迹上迭代更新自身，并稳定地提高其对特定感兴趣任务的性能。我们将SAIL应用于多样化的MetaWorld任务套件以及真实机械臂上的两个操作任务，发现对于在原始领域内视频模型训练期间最初未见的新任务，性能改进在多次迭代中持续出现。此外，我们发现SAIL在自收集经验是否以及如何过滤以及初始领域内演示的质量方面表现出令人惊讶的鲁棒性。通过与总结的互联网规模数据进行适应性学习，并通过在线经验学习，我们因此展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的方法。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [193] [Very Large-scale Multi-Robot Task Allocation in Challenging Environments via Robot Redistribution](https://arxiv.org/abs/2506.07293)
> *恶劣环境下基于机器人重新分配的超大规模多机器人任务分配*

*Seabin Lee, Joonyeol Sim, Changjoo Nam* | **Main category: cs.RO**

**Keywords:** 多机器人任务分配, 机器人重新分配, 广义Voronoi图, 完工时间最小化, 复杂环境

**Comment:** 15 pages

> **TL;DR:** 提出一种可扩展的多机器人任务分配方法，通过构建路图和机器人重新分配，在复杂环境中避免冲突和死锁，实现大规模机器人任务的快速完成。

**AI_Comments:** 该论文的创新点在于将机器人路径规划（通过广义Voronoi图构建路图）与任务分配深度结合，并通过一种新颖的机器人重新分配机制（推拉机制）来解决大规模、高冲突环境下的MRTA问题。其在处理数百个机器人的密集环境中的表现，突出了其在可扩展性和鲁棒性方面的显著优势，对于实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统的多机器人任务分配方法在障碍物密集和狭窄通道的复杂环境中效率低下，因为机器人冲突会产生额外成本并导致死锁，严重影响集体性能。

**Method:** 提出一种可扩展的多机器人任务分配（MRTA）方法，该方法考虑机器人路径以避免碰撞和死锁，从而最小化完工时间。具体地，该方法使用广义Voronoi图构建路图，并将路图划分为多个组件以指导机器人重新分配，以减少冲突。机器人重新分配过程采用遵循先进先出原则的推拉机制。

**Result:** 实验表明，该方法能够处理数百个机器人在密集杂乱环境中的实例，而竞争方法无法在规定时间内计算出解决方案。

**Conclusion:** 该研究成功开发了一种高效且可扩展的多机器人任务分配方法，通过集成路径规划和智能机器人重新分配策略，显著提高了在复杂大规模环境中的任务完成效率和鲁棒性。

> **ai_Abstract:** 这项研究提出了一种用于大规模多机器人任务分配（MRTA）的新方法，专门针对障碍物密集和狭窄通道的复杂环境。该方法通过构建基于广义Voronoi图的路图，并将其划分为多个组件来指导机器人重新分配，从而在考虑机器人路径的同时避免碰撞和死锁，旨在最小化任务完工时间。实验证明，该方法在处理数百个机器人的密集杂乱场景时，比现有方法更有效和可扩展。

> **摘要翻译:** 我们考虑多机器人任务分配（MRTA）问题，旨在优化在障碍物密集和狭窄通道等挑战性环境中多个机器人对多个任务的分配。在这种环境中，优化成本总和的传统方法通常无效，因为机器人之间的冲突会产生额外成本（例如，避碰、等待）。此外，不包含实际机器人路径的分配可能会导致死锁，从而显著降低机器人的集体性能。
我们提出了一种可扩展的MRTA方法，该方法考虑机器人的路径以避免碰撞和死锁，从而实现所有任务的快速完成（即最小化完工时间）。为了将机器人路径纳入任务分配，所提出的方法使用广义Voronoi图构建路图。该方法将路图划分为几个组件，以了解如何重新分配机器人，从而以更少的机器人之间冲突来完成所有任务。在重新分配过程中，机器人根据具有先进先出原则的推拉机制转移到它们的最终目的地。通过广泛的实验，我们表明我们的方法可以处理数百个机器人在密集杂乱环境中的实例，而竞争对手无法在规定时间内计算出解决方案。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [194] [DriveSuprim: Towards Precise Trajectory Selection for End-to-End Planning](https://arxiv.org/abs/2506.06659)
> *DriveSuprim: 面向端到端规划的精确轨迹选择*

*Wenhao Yao, Zhenxin Li, Shiyi Lan, Zi Wang, Xinglong Sun, Jose M. Alvarez, Zuxuan Wu* | **Main category: cs.RO**

**Keywords:** 轨迹选择, 端到端规划, 自动驾驶, 安全性, DriveSuprim

**Comment:** 15 pages, 6 figures

> **TL;DR:** DriveSuprim通过采用粗到细的过滤、基于旋转的增强和自蒸馏框架，提高了自动驾驶车辆轨迹选择的精确性和安全性。

**AI_Comments:** DriveSuprim通过引入多方面的创新（粗到细过滤、旋转增强、自蒸馏）有效地解决了选择式规划在复杂和罕见场景中的精度和鲁棒性问题。其在SOTA性能上的表现，尤其是在安全关键能力上的提升，显示了该方法在自动驾驶领域的重要性和实用性。

<details>
  <summary>Details</summary>

**Motivation:** 回归方法无法明确评估预测轨迹的安全性；现有选择方法在精确选择最佳轨迹和区分细微但关键的安全差异方面面临优化挑战，尤其是在罕见或代表性不足的场景中。

**Method:** DriveSuprim提出了一种粗到细的渐进式候选过滤范式，一种基于旋转的增强方法以提高分布外场景的鲁棒性，以及一个自蒸馏框架来稳定训练。

**Result:** DriveSuprim在NAVSIM v1中达到93.5%的PDMS，在NAVSIM v2中达到87.1%的EPDMS，无需额外数据，实现了最先进的性能，并展示了卓越的安全关键能力（包括避免碰撞和遵守规则），同时在各种驾驶场景中保持高轨迹质量。

**Conclusion:** DriveSuprim通过解决现有选择方法的挑战，显著提升了自动驾驶车辆的轨迹选择精度和安全关键能力，达到了最先进的性能。

> **ai_Abstract:** DriveSuprim是一种新的方法，旨在提高自动驾驶车辆在复杂环境中的轨迹选择精度和安全性。它通过结合粗到细的过滤、基于旋转的数据增强和自蒸馏框架来解决现有选择方法的不足。该方法在NAVSIM基准测试中表现出领先的性能，显著提升了碰撞避免和规则遵守等安全关键能力。

> **摘要翻译:** 在复杂的驾驶环境中，自动驾驶车辆必须安全导航。像基于回归的方法那样，依赖单一的预测路径通常不会明确评估预测轨迹的安全性。基于选择的方法通过生成和评估多个候选轨迹并预测每个轨迹的安全分数来解决这个问题，但面临着从数千种可能性中精确选择最佳选项以及区分细微但对安全至关重要的差异的优化挑战，尤其是在罕见或代表性不足的场景中。我们提出了DriveSuprim来克服这些挑战，并通过渐进式候选过滤的粗到细范式、提高分布外场景鲁棒性的基于旋转的增强方法以及稳定训练的自蒸馏框架来推进基于选择的范式。DriveSuprim实现了最先进的性能，在NAVSIM v1中达到93.5%的PDMS，在NAVSIM v2中达到87.1%的EPDMS，无需额外数据，展示了卓越的安全关键能力，包括避免碰撞和遵守规则，同时在各种驾驶场景中保持高轨迹质量。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [203] [Generalized Trajectory Scoring for End-to-end Multimodal Planning](https://arxiv.org/abs/2506.06664)
> *广义轨迹评分用于端到端多模态规划*

*Zhenxin Li, Wenhao Yao, Zi Wang, Xinglong Sun, Joshua Chen, Nadine Chang, Maying Shen, Zuxuan Wu, Shiyi Lan, Jose M. Alvarez* | **Main category: cs.RO**

**Keywords:** 轨迹评分, 多模态规划, 自动驾驶, 泛化性, 扩散模型

**Comment:** The 1st place solution of the End-to-end Driving Track at the CVPR
  2025 Autonomous Grand Challenge

> **TL;DR:** GTRS提出一个统一框架，结合粗粒度和细粒度轨迹评估，解决现有轨迹评分器泛化性差的问题，并在Navsim v2挑战中表现出色。

**AI_Comments:** GTRS的创新之处在于其统一了粗粒度和细粒度轨迹评估，并通过扩散模型、词汇泛化和传感器增强等技术显著提升了轨迹评分器的泛化能力，尤其是在域外和次优输入条件下的鲁棒性。其在Navsim v2挑战赛中获胜，证明了其在实际应用中的有效性和先进性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的轨迹评分器在泛化性方面存在显著局限性，无论是针对大量静态轨迹还是少量动态生成轨迹的评分方法，都难以进行细粒度适应或捕获更广泛的轨迹分布。

**Method:** 提出GTRS (Generalized Trajectory Scoring) 框架，包含三个创新点：1) 基于扩散的轨迹生成器，产生多样细粒度提案；2) 词汇泛化技术，在超密集轨迹集上通过dropout正则化训练评分器，使其在较小字集上也能鲁棒推理；3) 传感器增强策略，增强域外泛化性并结合关键轨迹判别细化训练。

**Result:** GTRS是Navsim v2挑战赛的获胜方案，即使在次优传感器输入下也表现出卓越性能，接近依赖于真实感知数据的特权方法。

**Conclusion:** GTRS通过结合粗粒度和细粒度评估，克服了现有轨迹评分器在泛化性方面的挑战，并在实际应用中展现出优越的性能，为端到端多模态规划提供了统一且鲁棒的解决方案。

> **ai_Abstract:** 本文提出了GTRS（广义轨迹评分）框架，旨在解决自动驾驶中端到端多模态规划现有轨迹评分器泛化性不足的问题。GTRS通过结合基于扩散的轨迹生成、词汇泛化技术和传感器增强策略，实现了粗粒度与细粒度轨迹评估的统一。该方法作为Navsim v2挑战赛的获胜方案，在次优传感器输入下仍展现出优异性能。

> **摘要翻译:** 端到端多模态规划是自动驾驶中一个有前景的范式，它能够实现基于多样轨迹候选的决策。其中一个关键组件是能够从这些候选轨迹中选择最优轨迹的鲁棒轨迹评分器。虽然最近的轨迹评分器专注于对大量静态轨迹或少量动态生成轨迹进行评分，但这两种方法在泛化性方面都面临显著局限。静态词汇表提供了有效的粗粒度离散化，但难以进行细粒度适应，而动态提案提供了详细的精度，却未能捕获更广泛的轨迹分布。为了克服这些挑战，我们提出了GTRS（广义轨迹评分），一个用于端到端多模态规划的统一框架，它结合了粗粒度评估和细粒度评估。GTRS由三个互补的创新组成：(1) 一个基于扩散的轨迹生成器，产生多样化的细粒度提案；(2) 一种词汇泛化技术，通过dropout正则化在超密集轨迹集上训练评分器，使其能够在较小子集上进行鲁棒推理；(3) 一种传感器增强策略，在整合关键轨迹判别细化训练的同时增强域外泛化性。作为Navsim v2挑战赛的获胜方案，GTRS即使在次优传感器输入下也表现出卓越性能，接近依赖于地面真实感知数据的特权方法。代码将在https://github.com/NVlabs/GTRS提供。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [211] [RoboCerebra: A Large-scale Benchmark for Long-horizon Robotic Manipulation Evaluation](https://arxiv.org/abs/2506.06677)
> *RoboCerebra：一个用于长周期机器人操纵评估的大规模基准*

*Songhao Han, Boxiang Qiu, Yue Liao, Siyuan Huang, Chen Gao, Shuicheng Yan, Si Liu* | **Main category: cs.RO**

**Keywords:** 机器人操纵, 视觉语言模型, 基准, 长周期规划, System 2能力

**Comment:** 23 pages, 18 figures

> **TL;DR:** 引入RoboCerebra，一个大规模基准，用于评估长周期机器人操纵中的高级推理和System 2能力，通过数据集、分层框架和评估协议来弥补现有基准的不足。

**AI_Comments:** RoboCerebra的创新之处在于其专注于机器人操纵中的System 2能力，即长周期规划和语义推理，这与现有基准主要关注System 1反应式策略形成对比。其大规模、高复杂度的模拟数据集和分层评估框架对于推动VLM在机器人领域更高级、更通用应用的发展至关重要。通过结合GPT生成任务和人类操作员执行来构建数据集，确保了数据质量和多样性。

<details>
  <summary>Details</summary>

**Motivation:** 现有机器人操纵基准主要关注反应式System 1策略，未能充分利用视觉语言模型（VLMs）在语义推理和长周期规划（System 2能力）方面的优势，因为其时间尺度有限且结构复杂性不足。

**Method:** 引入RoboCerebra基准，用于评估长周期机器人操纵中的高级推理。它包括：1) 一个大规模模拟数据集，具有扩展的任务周期和多样的子任务序列；2) 一个结合高级VLM规划器和低级VLA控制器的分层框架；3) 一个通过结构化System 1-System 2交互来评估规划、反思和记忆的评估协议。数据集通过GPT生成任务指令并分解为子任务序列，由人类操作员在模拟中执行以生成高质量轨迹。

**Result:** RoboCerebra与现有基准相比，具有显著更长的动作序列和更密集的注释。该研究还对最先进的VLMs作为System 2模块进行了基准测试，并分析了它们在关键认知维度上的性能。

**Conclusion:** RoboCerebra基准通过提供更长周期、更复杂的数据集和评估协议，促进了更强大和更通用机器人规划器的发展，尤其是在高级推理和System 2能力方面。

> **ai_Abstract:** 本文介绍了RoboCerebra，一个旨在弥补现有机器人基准在评估视觉语言模型（VLMs）长周期规划和高级推理（System 2能力）方面不足的大规模基准。RoboCerebra提供了一个包含长任务周期和复杂子任务序列的模拟数据集，一个结合VLM规划器和VLA控制器的分层框架，以及一个评估规划、反思和记忆的协议。通过使用GPT生成任务并由人类操作员执行子任务来构建数据集，RoboCerebra提供了比现有基准更长的动作序列和更密集的注释。研究还利用RoboCerebra对最先进的VLMs进行了基准测试，以促进更强大和更通用机器人规划器的发展。

> **摘要翻译:** 视觉语言模型（VLMs）的最新进展使得指令驱动的机器人系统具有更好的泛化能力。然而，大多数现有工作侧重于反应式System 1策略，未能充分利用VLMs在语义推理和长周期规划方面的优势。这些System 2能力——以深思熟虑、目标导向的思维为特征——由于当前基准的时间尺度有限和结构复杂性不足而未得到充分探索。为了弥补这一空白，我们引入了RoboCerebra，这是一个用于评估长周期机器人操纵中高级推理的基准。RoboCerebra包括：(1) 一个大规模模拟数据集，具有扩展的任务周期和家庭环境中多样化的子任务序列；(2) 一个结合高级VLM规划器和低级视觉语言动作（VLA）控制器的分层框架；以及 (3) 一个通过结构化System 1-System 2交互来评估规划、反思和记忆的评估协议。该数据集通过自上而下的流程构建，其中GPT生成任务指令并将其分解为子任务序列。人类操作员在模拟中执行子任务，从而生成具有动态对象变化的高质量轨迹。与现有基准相比，RoboCerebra具有显著更长的动作序列和更密集的注释。我们进一步将最先进的VLMs作为System 2模块进行基准测试，并分析了它们在关键认知维度上的性能，从而推动了更强大和更通用机器人规划器的发展。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [219] [RoboPARA: Dual-Arm Robot Planning with Parallel Allocation and Recomposition Across Tasks](https://arxiv.org/abs/2506.06683)
> *RoboPARA: 双臂机器人规划与跨任务并行分配和重组*

*Shiying Duan, Pei Ren, Nanxiang Jiang, Zhengping Che, Jian Tang, Yifan Sun, Zhaoxin Fan, Wenjun Wu* | **Main category: cs.RO**

**Keywords:** 双臂机器人, 任务规划, 并行性, 大型语言模型, 数据集

**Comment:** 

> **TL;DR:** RoboPARA是一个由LLM驱动的框架，用于优化双臂机器人任务的并行性，通过两阶段规划和新数据集实现了更高的效率和可靠性。

**AI_Comments:** RoboPARA的创新之处在于其LLM驱动的双臂任务并行规划框架，以及引入了专门用于评估双臂任务并行性的X-DAPT数据集，这对于推动双臂机器人协作和多任务处理领域的发展具有重要意义。其两阶段规划方法有效地解决了任务并行性优化不足的问题，提升了双臂机器人在复杂场景下的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在双臂机器人任务规划中未能充分优化任务并行性，限制了双臂协作的潜力。

**Method:** 提出RoboPARA框架，一个LLM驱动的双臂任务并行规划框架。它包括两个阶段：1) 基于依赖图的规划候选生成，构建有向无环图(DAG)以建模任务依赖并消除冗余；2) 基于图重遍历的双臂并行规划，优化DAG遍历以最大化并行性并保持任务连贯性。此外，引入了首个专门用于评估跨场景和难度级别双臂任务并行性的数据集X-DAPT。

**Result:** 在X-DAPT数据集上的大量实验表明，RoboPARA显著优于现有方法，尤其在复杂任务组合中，实现了更高的效率和可靠性。

**Conclusion:** RoboPARA通过其创新的LLM驱动框架和优化的并行规划方法，显著提升了双臂机器人在复杂多任务场景下的效率和可靠性，解决了现有方法并行性不足的问题。

> **ai_Abstract:** 本文提出了RoboPARA，一个由大型语言模型（LLM）驱动的双臂机器人任务并行规划框架，旨在解决现有方法在优化任务并行性方面的不足。RoboPARA采用两阶段方法，包括基于依赖图的规划候选生成和基于图重遍历的双臂并行规划，以最大化任务并行性并保持连贯性。此外，研究团队还发布了首个专门用于评估双臂任务并行性的X-DAPT数据集。实验结果表明，RoboPARA在效率和可靠性方面显著优于现有方法，尤其在复杂任务组合中表现突出。

> **摘要翻译:** 双臂机器人在提高复杂多任务场景的效率和灵活性方面发挥着关键作用。尽管现有方法在任务规划方面取得了可喜的成果，但它们往往未能充分优化任务并行性，限制了双臂协作的潜力。为了解决这个问题，我们提出了RoboPARA，一个新颖的由大型语言模型（LLM）驱动的双臂任务并行规划框架。RoboPARA采用两阶段过程：(1) 基于依赖图的规划候选生成，该阶段构建有向无环图（DAG）以建模任务依赖并消除冗余；(2) 基于图重遍历的双臂并行规划，该阶段优化DAG遍历以最大化并行性同时保持任务连贯性。此外，我们引入了跨场景双臂并行任务数据集（X-DAPT数据集），这是第一个专门设计用于评估跨不同场景和难度级别的双臂任务并行性的数据集。在X-DAPT数据集上进行的广泛实验表明，RoboPARA显著优于现有方法，尤其在复杂任务组合中，实现了更高的效率和可靠性。代码和数据集将在论文被接受后发布。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [225] [SpikePingpong: High-Frequency Spike Vision-based Robot Learning for Precise Striking in Table Tennis Game](https://arxiv.org/abs/2506.06690)
> *脉冲乒乓：基于高频脉冲视觉的机器人学习，实现乒乓球游戏中精准击球*

*Hao Wang, Chengkai Hou, Xianglong Li, Yankai Fu, Chenxuan Li, Ning Chen, Gaole Dai, Jiaming Liu, Tiejun Huang, Shanghang Zhang* | **Main category: cs.RO**

**Keywords:** 机器人学习, 乒乓球, 脉冲视觉, 高速控制, 精准击球

**Comment:** 

> **TL;DR:** SpikePingpong系统利用20kHz脉冲相机和模仿学习，在乒乓球机器人中实现高精度击球，显著提高了目标区域击球的成功率。

**AI_Comments:** 本文创新性地将高频脉冲视觉与模仿学习相结合，解决了高速乒乓球机器人控制中的两大核心挑战：高精度轨迹预测和精确落点规划。通过引入SONIC和IMPACT模块，以及利用20kHz脉冲相机，系统在精度和成功率上取得了显著突破，大幅超越了现有技术。这为机器人控制在高速、高精度领域的应用开辟了新的可能性，特别是对于需要实时响应和复杂战术的游戏或工业场景具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 控制现实世界中的高速物体是机器人领域的挑战。乒乓球是理想的测试平台，需要快速拦截高速球并精确调整轨迹。这面临两个挑战：高精度视觉系统预测球轨迹，以及智能战略规划以精确放置球到目标区域。

**Method:** 提出SpikePingpong系统，结合脉冲视觉和模仿学习。该系统包含两个模块：SONIC，一个基于脉冲相机的模块，通过补偿空气阻力、摩擦等不确定性实现毫米级球拍接触预测；IMPACT，一个战略规划模块，实现球的精确落点。系统使用20 kHz脉冲相机进行高时间分辨率球跟踪，并结合高效神经网络模型进行实时轨迹校正和击球规划。

**Result:** SpikePingpong在30厘米精度目标区域任务中达到91%的成功率，在更具挑战性的20厘米精度任务中达到71%的成功率，分别超越现有最先进方法38%和37%。

**Conclusion:** 这些显著的性能提升使得复杂战术游戏策略的稳健实施成为可能，为高速动态任务中的机器人控制提供了新的研究视角。

> **ai_Abstract:** 本论文提出了SpikePingpong系统，旨在解决机器人控制高速物体的挑战，以乒乓球为例。该系统结合了20 kHz脉冲视觉和模仿学习，通过SONIC模块实现毫米级球拍接触预测，并通过IMPACT模块进行精确的战略规划。实验结果表明，SpikePingpong在30厘米和20厘米精度任务中分别达到了91%和71%的成功率，显著优于现有技术，为高速动态任务中的机器人控制提供了新的研究视角。

> **摘要翻译:** 在现实世界中控制高速物体仍然是机器人领域的一个具有挑战性的前沿。乒乓球作为解决此问题的理想试验台，要求能够快速拦截高速移动的球并精确调整其轨迹。这项任务提出了两个基本挑战：它需要一个高精度视觉系统，能够准确预测球的轨迹；它还需要智能战略规划，以确保将球精确放置到目标区域。乒乓球的动态特性，加上其实时响应要求，使其特别适合于推进机器人控制在快节奏、对精度要求高的领域的能力。在本文中，我们提出了SpikePingpong，一个将基于脉冲的视觉与模仿学习相结合的新颖系统，用于高精度机器人乒乓球。我们的方法引入了两个直接解决上述挑战的关键尝试：SONIC，一个基于脉冲相机的模块，通过补偿空气阻力、摩擦等真实世界的不确定性，实现了球拍接触预测的毫米级精度；以及IMPACT，一个战略规划模块，能够将球精确放置到目标桌面区域。该系统利用20 kHz脉冲相机进行高时间分辨率的球跟踪，并结合高效的神经网络模型进行实时轨迹校正和击球规划。实验结果表明，SpikePingpong在30厘米精度目标区域任务中取得了91%的显著成功率，在更具挑战性的20厘米精度任务中取得了71%的成功率，分别超越了现有最先进方法38%和37%。这些显著的性能改进使得复杂战术游戏策略的稳健实施成为可能，为高速动态任务中的机器人控制提供了新的研究视角。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [233] [SARAL-Bot: Autonomous Robot for Strawberry Plant Care](https://arxiv.org/abs/2506.06798)
> *SARAL-Bot：草莓植株护理自主机器人*

*Arif Ahmed, Ritvik Agarwal, Gaurav Srikar, Nathaniel Rose, Parikshit Maini* | **Main category: cs.RO**

**Keywords:** 自主机器人, 草莓种植, 植物护理, 农业自动化, 机器视觉

**Comment:** Awarded Best Written Report @ Robotics Design Challenge (Advanced),
  ASABE 2024

> **TL;DR:** SARAL团队开发了一款名为SARAL-Bot的自主机器人，用于草莓种植，能导航、检测并移除不健康叶片，以解决劳动力短缺和降低成本。

**AI_Comments:** 这篇论文展示了一个实用的农业机器人应用，专注于解决草莓种植中的具体痛点。其创新之处在于结合了导航、视觉检测和物理移除功能于一体，为传统农业提供了现代化的解决方案。重要性在于它直接响应了农业劳动力短缺的挑战，并促进了智能和可持续的农业发展。

<details>
  <summary>Details</summary>

**Motivation:** 草莓种植对监测和维护植物健康提出密集的劳动力需求。为了解决劳动力短缺、降低成本和支持可持续农业，开发了这款自主机器人。

**Method:** SARAL团队为2024 ASABE学生机器人挑战赛开发了一款自主机器人。该机器人具备导航、不健康叶片检测和移除的能力，并通过基于视觉的植物评估来实现这些功能。

**Result:** 该系统解决了劳动力短缺，降低了成本，并通过基于视觉的植物评估支持可持续农业。这项工作展示了机器人技术在现代化草莓种植和实现可扩展、智能农业解决方案方面的潜力。

**Conclusion:** 机器人技术有潜力使草莓种植现代化，并实现可扩展、智能的农业解决方案。

> **ai_Abstract:** SARAL团队开发了一款名为SARAL-Bot的自主机器人，旨在解决草莓种植中劳动力密集的问题。该机器人专为2024年ASABE学生机器人挑战赛设计，具备导航、不健康叶片检测及移除功能。通过基于视觉的植物评估，该系统有助于缓解劳动力短缺，降低生产成本，并促进可持续农业实践，展示了机器人技术在现代化农业中的应用前景。

> **摘要翻译:** 草莓种植对监测和维护植物健康提出密集的劳动力需求。为了解决这一问题，SARAL团队为2024年ASABE学生机器人挑战赛开发了一款自主机器人，该机器人能够导航、检测和移除不健康的叶片。该系统通过基于视觉的植物评估解决了劳动力短缺问题，降低了成本，并支持可持续农业。这项工作展示了机器人技术使草莓种植现代化并实现可扩展、智能农业解决方案的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [242] [IRS: Instance-Level 3D Scene Graphs via Room Prior Guided LiDAR-Camera Fusion](https://arxiv.org/abs/2506.06804)
> *IRS: 实例级3D场景图，通过房间先验引导的激光雷达-相机融合*

*Hongming Chen, Yiyang Lin, Ziliang Li, Biyu Ye, Yuying Zhang, Ximin Lyu* | **Main category: cs.RO**

**Keywords:** 3D场景图, 激光雷达-相机融合, 视觉基础模型, 房间先验, 实例级理解

**Comment:** 

> **TL;DR:** 提出了一种通过激光雷达-相机融合构建实例级3D场景图的框架，利用房间先验和多级VFM，显著提高了构建速度和语义精度，并支持语言引导的机器人导航。

**AI_Comments:** 这篇论文的创新点在于其提出的激光雷达-相机融合框架，特别是利用房间先验和多级VFM来构建实例级3D场景图。其在构建速度上达到数量级提升，同时保持高精度，解决了传统方法在开放世界环境中的局限性，并为语言引导的机器人导航等实际应用提供了新的解决方案，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 室内场景理解对机器人技术至关重要，但传统方法（封闭集识别或闭环）在开放世界环境中适应性有限。视觉基础模型（VFMs）的出现使开放词汇识别和自然语言查询成为可能，为3D场景图构建提供了新机遇。

**Method:** 提出了一个鲁棒高效的实例级3D场景图构建框架，通过激光雷达-相机融合实现。利用激光雷达的宽视场和远距离感知能力快速获取房间级几何先验。采用多级VFMs提高语义提取的准确性和一致性。在实例融合过程中，基于房间的分割实现并行处理，同时几何和语义线索的整合显著增强了融合的准确性和鲁棒性。

**Result:** 相比现有方法，该方法在构建速度上实现了数量级提升，同时保持了高语义精度。在模拟和真实世界环境中都验证了其有效性，并通过语言引导的语义导航任务展示了其实用价值。

**Conclusion:** 该方法能够鲁棒高效地构建实例级3D场景图，在速度和精度上优于现有技术，并有望应用于实际机器人任务，如语言引导的语义导航。

> **ai_Abstract:** 本文提出了一种名为IRS的实例级3D场景图构建框架，该框架通过融合激光雷达和相机数据实现。它利用激光雷达获取房间级几何先验，并结合多级视觉基础模型进行语义提取，以提高准确性。通过基于房间的分割实现并行处理，并整合几何与语义信息，显著提升了实例融合的准确性和鲁棒性。实验证明，IRS在构建速度上比现有方法快一个数量级，同时保持了高语义精度，并在语言引导的语义导航等实际机器人应用中展现出巨大潜力。

> **摘要翻译:** 室内场景理解仍然是机器人学中的一个基本挑战，对导航和操作等下游任务具有直接影响。传统方法通常依赖于封闭集识别或闭环，限制了它们在开放世界环境中的适应性。随着视觉基础模型（VFMs）的出现，开放词汇识别和自然语言查询变得可行，为3D场景图构建解锁了新的可能性。
在本文中，我们提出了一种通过激光雷达-相机融合构建实例级3D场景图的鲁棒高效框架。利用激光雷达的宽视场（FOV）和远距离感知能力，我们快速获取房间级几何先验。采用多级VFMs以提高语义提取的准确性和一致性。在实例融合过程中，基于房间的分割实现了并行处理，同时几何和语义线索的整合显著增强了融合的准确性和鲁棒性。与现有最先进的方法相比，我们的方法在构建速度上实现了数量级提升，同时保持了高语义精度。
在模拟和真实世界环境中的广泛实验验证了我们方法的有效性。我们通过语言引导的语义导航任务进一步展示了其实用价值，突出了其在真实世界机器人应用中的潜力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [251] [RF-Source Seeking with Obstacle Avoidance using Real-time Modified Artificial Potential Fields in Unknown Environments](https://arxiv.org/abs/2506.06811)
> *射频源搜寻与避障：在未知环境中实时改进人工势场法*

*Shahid Mohammad Mulla, Aryan Kanakapudi, Lakshmi Narasimhan, Anuj Tiwari* | **Main category: cs.RO**

**Keywords:** 射频源搜寻, 人工势场, 避障, 无人机导航, 未知环境

**Comment:** 14 pages, 16 figures, 1 table, shorter version under review for IEEE
  ICCAS 2025 conference

> **TL;DR:** 本文提出了一种实时轨迹规划方法，通过采样方法实时调整人工势场（APF），实现无人机在未知环境中基于射频源搜寻的避障导航，并在仿真中验证了其高精度和更高的目标到达成功率。

**AI_Comments:** 本文的创新点在于结合了射频源搜寻与实时自适应人工势场，解决了未知环境下目标位置不确定和传统APF泛化能力差的问题。其重要性体现在提升了无人机在灾难响应和搜索救援等实际应用中的自主导航能力。论文在仿真中取得了显著效果，但在实际复杂环境中的鲁棒性和实时性仍需进一步验证。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人工势场避障算法难以适应不同障碍物配置的环境，且在搜索救援等应用中目标精确位置不可用。

**Method:** 本文提出了一种实时轨迹规划方法，通过基于采样的实时自适应修改人工势场（APF）。该方法仅利用目标的方位角而非精确位置，并根据新的障碍物配置实时调整势场参数。主要贡献包括：1) 基于天线布局的射频信号计算，提供方位角估计的射频源搜寻算法；2) 适用于变化环境中可适应性防撞的改进APF。在Gazebo仿真软件中使用ROS2进行评估。

**Result:** 射频源搜寻算法实现了高精度，平均角度误差仅为1.48度。基于此估计，所提出的导航算法将到达目标的成功率提高了46%，轨迹长度比标准势场法减少了1.2%。

**Conclusion:** 论文提出的射频源搜寻算法和改进人工势场避障方法，有效提升了无人机在未知环境中基于射频源搜寻的避障导航能力，提高了目标到达成功率和轨迹效率。

> **ai_Abstract:** 本文提出了一种在未知环境中进行射频源搜寻与避障的无人机实时轨迹规划方法。该方法通过实时自适应修改人工势场（APF）来应对不同障碍物配置，并仅利用射频信号提供的目标方位角进行导航。文章贡献包括高精度射频源搜寻算法和可适应性避碰的改进APF。仿真结果显示，该方法显著提高了目标到达成功率并优化了轨迹。

> **摘要翻译:** 无人机在未知障碍物环境中的导航对于灾难响应和基础设施监控等应用至关重要。然而，现有的人工势场（APF）等避障算法无法泛化到具有不同障碍物配置的环境中。此外，在搜索救援等应用中，最终目标的精确位置可能不可用，在这种情况下，可以使用射频源搜寻等方法来对准目标位置。本文提出了一种实时轨迹规划方法，该方法涉及通过基于采样的方法实时调整APF。所提出的方法仅利用目标的方位角而非其精确位置，并根据新的障碍物配置实时调整势场参数。文章的主要贡献是：i) 一种基于天线布局的射频信号计算提供方位角估计的射频源搜寻算法；ii) 一种用于在变化环境中进行适应性防撞的改进APF，这些贡献在Gazebo仿真软件中使用ROS2进行通信分别进行了评估。仿真结果表明，射频源搜寻算法实现了高精度，平均角度误差仅为1.48度，并且利用此估计，所提出的导航算法与标准势场法相比，将到达目标的成功率提高了46%，并将轨迹长度减少了1.2%。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [260] [Multimodal Spatial Language Maps for Robot Navigation and Manipulation](https://arxiv.org/abs/2506.06862)
> *机器人导航和操作的多模态空间语言地图*

*Chenguang Huang, Oier Mees, Andy Zeng, Wolfram Burgard* | **Main category: cs.RO**

**Keywords:** 多模态空间语言地图, 机器人导航, 机器人操作, 语言接地, 3D重建

**Comment:** accepted to International Journal of Robotics Research (IJRR). 24
  pages, 18 figures. The paper contains texts from VLMaps(arXiv:2210.05714) and
  AVLMaps(arXiv:2303.07522). The project page is https://mslmaps.github.io/

> **TL;DR:** 提出多模态空间语言地图（VLMaps和AVLMaps），融合预训练多模态特征与3D环境重建，使机器人能通过语言、视觉、听觉等指令进行零样本导航和操作，提高歧义环境下的召回率。

**AI_Comments:** 这项工作通过引入多模态空间语言地图，有效地弥合了语言指令与机器人实际环境感知之间的鸿沟。其创新之处在于将预训练的多模态特征与3D环境重建相结合，并扩展到多种感官输入（视觉、听觉、语言），显著提高了机器人在复杂和模糊环境中理解和执行零样本空间及多模态目标的能力。这对于提升机器人自主性和泛化能力具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在语言与机器人观测的关联方面，与环境建图脱节，缺乏几何地图的空间精度，或忽略视觉之外的其他模态信息。

**Method:** 提出多模态空间语言地图（multimodal spatial language maps），通过将预训练的多模态特征与环境的3D重建融合来构建空间地图表示。这些地图可自主构建。具体包括视觉-语言地图（VLMaps）和音频-视觉-语言地图（AVLMaps）。VLMaps结合LLMs可将自然语言命令转换为开放词汇空间目标并定位，并能在不同机器人之间共享以生成障碍物地图。AVLMaps通过融合预训练多模态基础模型的特征，进一步整合音频、视觉和语言线索，实现多模态目标查询的定位。

**Result:** 多模态空间语言地图在模拟和真实世界环境中实现了零样本空间和多模态目标导航，并在模糊场景中将召回率提高了50%。这些能力可扩展到移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。

**Conclusion:** 该研究成功开发了多模态空间语言地图，有效解决了现有方法在空间精度和多模态信息利用方面的不足，显著提升了机器人在复杂和模糊环境中进行零样本导航和操作的能力。

> **ai_Abstract:** 本文提出多模态空间语言地图（VLMaps和AVLMaps），旨在解决现有语言与机器人观测关联方法在环境建图脱节、空间精度不足及忽略视觉外模态信息的问题。该方法将预训练多模态特征与环境3D重建融合，自主构建地图。VLMaps结合LLMs能将自然语言命令转化为可定位的开放词汇空间目标，并支持跨机器人共享。AVLMaps在此基础上整合音频信息，实现多模态目标查询的定位，并增强歧义环境下的目标消歧能力。实验证明，该地图在模拟和真实环境中实现了零样本空间和多模态目标导航，并将模糊场景的召回率提高50%，适用于移动机器人和桌面操作器。

> **摘要翻译:** 将语言与导航代理的观测结果联系起来，可以利用预训练的多模态基础模型来匹配感知与物体或事件的描述。然而，以前的方法仍然与环境建图脱节，缺乏几何地图的空间精度，或者忽略了视觉之外的额外模态信息。为了解决这个问题，我们提出了多模态空间语言地图作为一种空间地图表示，它将预训练的多模态特征与环境的3D重建融合。我们使用标准探索自主构建这些地图。我们展示了我们地图的两个实例，即视觉-语言地图（VLMaps）及其通过添加音频信息扩展而成的音频-视觉-语言地图（AVLMaps）。当与大型语言模型（LLMs）结合时，VLMaps可以（i）将自然语言命令转换为直接在地图中定位的开放词汇空间目标（例如，“沙发和电视之间”），以及（ii）在不同的机器人实体之间共享以按需生成定制的障碍物地图。在此能力的基础上，AVLMaps通过引入统一的3D空间表示来扩展VLMaps，该表示通过融合预训练多模态基础模型的特征来整合音频、视觉和语言线索。这使得机器人能够将多模态目标查询（例如，文本、图像或音频片段）与空间位置联系起来进行导航。此外，多样化感官输入的整合显著增强了模糊环境中的目标消歧能力。在模拟和真实世界环境中的实验表明，我们的多模态空间语言地图实现了零样本空间和多模态目标导航，并将模糊场景中的召回率提高了50%。这些能力扩展到移动机器人和桌面操作器，支持由视觉、音频和空间线索引导的导航和交互。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [266] [Hierarchical Intention Tracking with Switching Trees for Real-Time Adaptation to Dynamic Human Intentions during Collaboration](https://arxiv.org/abs/2506.07004)
> *用于实时适应协作中动态人类意图的带切换树的分层意图跟踪*

*Zhe Huang, Ye-Ji Mun, Fatemeh Cheraghi Pouria, Katherine Driggs-Campbell* | **Main category: cs.RO**

**Keywords:** 分层意图跟踪, 人机协作, 动态意图, 实时适应, 贝叶斯滤波

**Comment:** 15 pages, 10 figures

> **TL;DR:** 本文提出了一种分层意图跟踪（HIT）算法，使协作机器人能够实时跟踪动态和分层的人类意图，从而提高效率、减轻工作负荷并提升用户舒适度。

**AI_Comments:** 该论文的创新之处在于将意图分层表示为可切换的树结构，并采用概率跟踪机制（贝叶斯滤波、传播）。这种方法解决了人机协作中实时适应的关键需求，从而实现更自然、更高效的交互。对用户舒适度和信任的强调是一个重要的积极成果。

<details>
  <summary>Details</summary>

**Motivation:** 在协作任务中，人类行为受多层次意图的引导且随时间演变，协作机器人需要准确实时跟踪这些动态和多层次的人类意图，以适应不断变化的偏好并及时纠正不准确的估计。

**Method:** 本文提出了分层意图跟踪（HIT）算法，该算法将人类意图表示为任意深度的意图树，并通过贝叶斯滤波、向上测量传播和向下后验传播在所有级别上概率性地跟踪人类意图。开发了一个基于HIT的机器人系统，在协作装配任务中动态切换交互任务树和验证任务树，以协调任务级别、交互级别和验证级别的人类意图。

**Result:** 用户研究表明，基于HIT的协作机器人系统在确保安全和任务完成的同时，实现了效率、体力负荷和用户舒适度之间的平衡，并超越了现有解决方案。实验后调查进一步显示，该系统增强了用户信任并最大限度地减少了对用户任务流程的干扰。

**Conclusion:** HIT算法使协作机器人能够有效跟踪动态和分层的人类意图，从而改善人机协作性能和用户体验。

> **ai_Abstract:** 本文介绍了一种分层意图跟踪（HIT）算法，该算法允许协作机器人通过对意图树进行概率性方法实时跟踪动态和多层次的人类意图。在协作装配任务中应用动态树切换，HIT与现有协作机器人解决方案相比，提高了效率，减轻了体力负荷，增强了用户舒适度，并建立了用户信任。

> **摘要翻译:** 在协作任务中，人类行为受多层次意图的引导，这些意图随时间演变，例如任务序列偏好和交互策略。为了适应这些不断变化的偏好并及时纠正任何不准确的估计，协作机器人必须实时准确地跟踪这些动态的人类意图。我们提出了一种分层意图跟踪（HIT）算法，用于协作机器人实时有效地跟踪动态和分层的人类意图。HIT将人类意图表示为任意深度的意图树，并通过贝叶斯滤波、向上测量传播和向下后验传播在所有级别上概率性地跟踪人类意图。我们开发了一个基于HIT的机器人系统，该系统在协作装配任务中动态切换交互任务树和验证任务树，使机器人能够有效协调三个级别的人类意图：任务级别（子任务目标位置）、交互级别（与机器人的交互模式）和验证级别（确认或纠正意图识别）。我们的用户研究表明，我们基于HIT的协作机器人系统超越了现有的协作机器人解决方案，在确保安全和任务完成的同时，实现了效率、体力负荷和用户舒适度之间的平衡。实验后调查进一步显示，基于HIT的系统通过其对多层次人类意图的有效理解，增强了用户信任并最大限度地减少了对用户任务流程的干扰。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [271] [CARoL: Context-aware Adaptation for Robot Learning](https://arxiv.org/abs/2506.07006)
> *CARoL：机器人学习中的上下文感知适应*

*Zechen Hu, Tong Xu, Xuesu Xiao, Xuan Wang* | **Main category: cs.RO**

**Keywords:** 强化学习, 机器人学习, 上下文感知, 知识适应, 迁移学习

**Comment:** 

> **TL;DR:** CARoL是一个新的框架，通过上下文感知分析状态转换来识别相似性并优先适应特定知识，从而有效地从先验知识中学习新的机器人任务。

**AI_Comments:** CARoL的创新点在于其上下文感知适应机制，能够智能地识别并整合先验知识，这对于提高机器人学习效率至关重要。其广泛的算法适用性和在模拟与真实环境中的验证，凸显了该方法的实用性和重要性，为解决强化学习在复杂真实世界应用中的效率问题提供了有效途径。

<details>
  <summary>Details</summary>

**Motivation:** 从头开始使用强化学习（RL）学习新的机器人任务通常效率低下。利用先验知识有显著提高学习效率的潜力，但这带来了两个关键挑战：如何确定现有知识的相关性以及如何将它们自适应地整合到新任务的学习中。

**Method:** 本文提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，用于从先验知识中高效学习一个相似但不同的新任务。CARoL通过分析系统动力学中的状态转换来融入上下文感知，以识别新任务与先验知识之间的相似性。然后，它利用这些已识别的相似性来优先处理和适应特定知识片段以用于新任务。此外，CARoL具有广泛的适用性，涵盖基于策略、基于价值和Actor-Critic的RL算法。

**Result:** CARoL在模拟机器人平台（包括CarRacing和LunarLander环境）和物理地面车辆上都验证了其效率和通用性。模拟结果表明，CARoL在学习新任务策略时展现出更快的收敛速度和更高的奖励。在真实世界实验中，CARoL使地面车辆能够快速高效地适应在模拟中学习到的策略，从而平稳地通过真实世界的越野地形。

**Conclusion:** CARoL通过上下文感知适应机制，有效地解决了强化学习中利用先验知识的挑战，显著提高了机器人学习新任务的效率和泛化能力，并在模拟和真实环境中均得到了验证。

> **ai_Abstract:** 本文提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，旨在解决强化学习从头开始学习机器人任务效率低下的问题。CARoL通过分析系统动力学中的状态转换来识别新任务与先验知识之间的相似性，并利用这些相似性来优先并适应特定的知识片段。该框架适用于多种RL算法，并在模拟和真实世界的机器人平台上验证了其效率和泛化能力，包括在CarRacing和LunarLander环境中实现更快的收敛和更高的奖励，以及使地面车辆在真实世界中高效适应越野地形。

> **摘要翻译:** 使用强化学习（RL）从头开始学习新的机器人任务通常效率低下。利用先验知识有显著提高学习效率的潜力，但这带来了两个关键挑战：如何确定现有知识的相关性以及如何将它们自适应地整合到新任务的学习中。在本文中，我们提出了CARoL（Context-aware Adaptation for Robot Learning），一个新颖的框架，用于从先验知识中高效学习一个相似但不同的新任务。CARoL通过分析系统动力学中的状态转换来融入上下文感知，以识别新任务与先验知识之间的相似性。然后，它利用这些已识别的相似性来优先处理和适应特定知识片段以用于新任务。此外，CARoL具有广泛的适用性，涵盖基于策略、基于价值和Actor-Critic的RL算法。我们在模拟机器人平台和物理地面车辆上都验证了CARoL的效率和通用性。模拟包括CarRacing和LunarLander环境，其中CARoL在学习新任务策略时展现出更快的收敛速度和更高的奖励。在真实世界实验中，我们展示了CARoL使地面车辆能够快速高效地适应在模拟中学习到的策略，从而平稳地通过真实世界的越野地形。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [278] [Prime the search: Using large language models for guiding geometric task and motion planning by warm-starting tree search](https://arxiv.org/abs/2506.07062)
> *启动搜索：使用大型语言模型通过热启动树搜索来指导几何任务和运动规划*

*Dongryung Lee, Sejune Joo, Kimin Lee, Beomjoon Kim* | **Main category: cs.RO**

**Keywords:** 大型语言模型, 几何任务和运动规划, 蒙特卡洛树搜索, 热启动, 机器人规划

**Comment:** The International Journal of Robotics Research (IJRR)

> **TL;DR:** 本文提出了一种利用大型语言模型（LLM）的常识知识来指导几何任务和运动规划（G-TAMP）的方法，通过热启动蒙特卡洛树搜索（MCTS）来提高规划效率和性能。

**AI_Comments:** 这项工作创新性地将大型语言模型（LLM）的常识推理能力与传统的任务和运动规划（TAMP）相结合，尤其是在几何TAMP领域。通过将LLM作为热启动蒙特卡洛树搜索（MCTS）的引导机制，它有效地解决了LLM输出不确定性的问题，并显著降低了计算成本。这种结合常识知识和搜索算法的混合方法为解决复杂的机器人操作问题提供了一个有前景的方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的几何任务和运动规划（G-TAMP）方法依赖于领域无关启发式或从规划经验中学习，通常需要大量的计算资源或数据。与此不同，人类在解决G-TAMP问题时常凭直觉决定操作哪些物体。受此启发，本文旨在利用LLM的常识知识来指导G-TAMP中的任务规划。

**Method:** 本文设计了一种基于谓词的提示，该提示编码了从运动规划算法中提取的几何信息，以使LLM能够进行几何推理。LLM生成一个任务计划，然后用于搜索一组可行的连续参数。为了应对LLM可能出错的问题，本文扩展了蒙特卡洛树搜索（MCTS）到混合动作空间，并使用LLM来指导搜索，具体通过LLM任务计划中探索的节点来热启动MCTS，而不是在每个节点都调用LLM。

**Result:** 在六个不同的G-TAMP问题上，本文方法优于先前的LLM规划器和纯搜索算法。

**Conclusion:** 利用大型语言模型（LLM）的常识知识，通过热启动蒙特卡洛树搜索（MCTS）来指导几何任务和运动规划（G-TAMP），可以显著提高规划效率和性能，超越了以往的LLM规划器和纯搜索算法。

> **ai_Abstract:** 本文提出了一种利用大型语言模型（LLM）的常识知识来指导几何任务和运动规划（G-TAMP）的新方法。针对传统方法计算成本高的问题，本文设计了一种基于谓词的提示，使LLM能够进行几何推理并生成任务计划。为了解决LLM可能出错的问题，本文将蒙特卡洛树搜索（MCTS）扩展到混合动作空间，并利用LLM生成的任务计划来热启动MCTS，从而避免了在每个节点都调用LLM的高成本。实验结果表明，该方法在六个不同的G-TAMP问题上优于以往的LLM规划器和纯搜索算法。

> **摘要翻译:** 将一组物体重新定位到指定区域，同时避开可移动障碍物的问题，可以被视为几何任务和运动规划（G-TAMP）问题，它是任务和运动规划（TAMP）的一个子类。传统的G-TAMP方法要么依赖于领域无关的启发式，要么依赖于从规划经验中学习来指导搜索，这两种方法通常都需要大量的计算资源或数据。相比之下，人类在G-TAMP问题中常常凭常识直觉决定操作哪些物体。受此启发，我们提出利用大型语言模型（LLM），它们从互联网规模的数据中获取了常识知识，来指导G-TAMP问题中的任务规划。为了使LLM能够进行几何推理，我们设计了一种基于谓词的提示，该提示编码了从运动规划算法中提取的几何信息。然后，我们查询LLM以生成一个任务计划，该计划随后用于搜索一组可行的连续参数。由于LLM容易出错，我们没有完全依赖LLM的输出，而是将蒙特卡洛树搜索（MCTS）扩展到混合动作空间，并使用LLM来指导搜索。与之前在每个节点都调用LLM并产生高计算成本的方法不同，我们使用LLM的任务计划中探索的节点来热启动MCTS。在六个不同的G-TAMP问题上，我们展示了我们的方法优于先前的LLM规划器和纯搜索算法。代码可在以下网址找到：https://github.com/iMSquared/prime-the-search

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [284] [Robotic Policy Learning via Human-assisted Action Preference Optimization](https://arxiv.org/abs/2506.07127)
> *机器人策略学习通过人机辅助动作偏好优化*

*Wenke xia, Yichu Yang, Hongtao Wu, Xiao Ma, Tao Kong, Di Hu* | **Main category: cs.RO**

**Keywords:** 机器人策略学习, 人机辅助, 动作偏好优化, VLA模型, 失败学习

**Comment:** 

> **TL;DR:** 本文提出HAPO方法，通过人机协作和动作偏好优化，使VLA模型能从失败中学习并纠正部署错误，实验证明其在多种操作任务中具有卓越的泛化性和鲁棒性。

**AI_Comments:** 这项工作通过引入人机协作和偏好优化，有效地解决了VLA模型在实际机器人部署中从失败中学习和自我纠正的关键挑战。其创新性在于将人类干预转化为可学习的偏好信号，并通过自适应重加权算法解决了VLA模型集成偏好学习时的技术障碍。这对于构建更鲁棒、适应性更强的机器人系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的视觉-语言-动作（VLA）模型对专家演示的依赖，限制了机器人系统在实际部署中纠正错误和从失败中学习的关键能力。

**Method:** 本文引入了名为HAPO（人机辅助动作偏好优化）的方法。该方法通过人机协作框架收集失败纠正和交互轨迹，并将这些人工干预轨迹用于动作偏好优化过程，旨在减少失败动作的发生并增强纠正动作的适应性。具体地，为解决将偏好优化引入VLA模型时不可逆交互和token概率不匹配的问题，提出了一种自适应重加权算法，以促进模型从二元期望信号中学习。

**Result:** 在模拟和真实世界场景中进行的实验证明，该框架在各种操作任务中具有卓越的泛化性和鲁棒性。

**Conclusion:** HAPO方法通过人机辅助动作偏好优化，确保了视觉-语言-动作（VLA）模型在实际部署中的可靠性以及从失败中有效学习的能力。

> **ai_Abstract:** 本文提出了一种名为HAPO（人机辅助动作偏好优化）的新方法，旨在解决视觉-语言-动作（VLA）模型在机器人部署中依赖专家演示导致无法纠正错误和从失败中学习的问题。HAPO通过人机协作框架收集失败纠正轨迹，并利用这些轨迹进行动作偏好优化，以减少失败动作并促进纠正性学习。该方法还引入了自适应重加权算法来处理偏好优化中的特定挑战。实验结果表明，HAPO显著提高了VLA模型在多种操作任务中的泛化性和鲁棒性，使其能够可靠部署并有效从错误中学习。

> **摘要翻译:** 建立一个可靠且可迭代改进的机器人系统对于部署现实世界应用至关重要。虽然视觉-语言-动作（VLA）模型被广泛认为是此类机器人部署的基础模型，但它们对专家演示的依赖阻碍了纠正和从失败中学习的关键能力。为了缓解这一限制，我们引入了一种名为HAPO的人机辅助动作偏好优化方法，旨在纠正部署失败并通过VLA模型的偏好对齐来促进有效适应。该方法首先通过人机协作框架，通过人工干预实现可靠的故障纠正和交互轨迹收集。这些人工干预轨迹进一步用于动作偏好优化过程，促进VLA模型减少失败动作的发生，同时增强纠正动作的适应性。具体而言，我们提出了一种自适应重加权算法，以解决将偏好优化引入VLA模型时不可逆交互和token概率不匹配的问题，从而促进模型从交互中获得的二元期望信号中学习。通过结合这些模块，我们的人机辅助动作偏好优化方法确保了VLA模型的可靠部署和从失败中有效学习。在模拟和真实世界场景中进行的实验证明了我们框架在各种操作任务中卓越的泛化性和鲁棒性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [291] [Improving Traffic Signal Data Quality for the Waymo Open Motion Dataset](https://arxiv.org/abs/2506.07150)
> *改善Waymo开放运动数据集的交通信号数据质量*

*Xintao Yan, Erdao Liang, Jiawei Wang, Haojie Zhu, Henry X. Liu* | **Main category: cs.RO**

**Keywords:** 交通信号数据质量, Waymo开放运动数据集, 自动驾驶, 数据增强, 闯红灯率

**Comment:** 

> **TL;DR:** 本研究提出了一种全自动方法，利用车辆轨迹数据和交通领域知识，有效推断和纠正Waymo开放运动数据集中的交通信号信息，显著提高了数据集质量并降低了估计的闯红灯率。

**AI_Comments:** 该论文提出了一种创新且实用的方法来解决自动驾驶数据集中交通信号数据质量的关键问题。其全自动化和对复杂现实场景的适应性是其主要优势。通过显著降低数据不准确性（如闯红灯率），该研究对提升自动驾驶模型训练的可靠性和性能具有重要价值。开源代码和数据也体现了其对社区的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶汽车（AVs）数据集在人工智能、自动驾驶和交通工程等研究领域具有重要前景，但这些数据集经常遇到交通信号状态缺失或不准确的问题，这会损害数据集的可靠性并影响使用其开发模型的性能。

**Method:** 本研究引入了一种全自动方法，通过利用可用的车辆轨迹数据以及交通领域的知识，有效推断和纠正Waymo开放运动数据集（WOMD）中的交通信号信息。该方法具有鲁棒性和灵活性，能够处理现实世界中不同的交叉路口几何形状和交通信号配置。

**Result:** 在原始数据集中，71.7%的交通信号状态缺失或未知，所有这些都通过我们提出的方法成功推断。此外，在缺乏地面真实信号状态的情况下，根据车辆轨迹的闯红灯率评估了我们方法的准确性。结果显示，我们的方法将原始数据中估计的闯红灯率从15.7%降低到2.9%，从而证明了其纠正数据不准确性的有效性。

**Conclusion:** 本文显著提高了AV数据集的质量，为更广泛的人工智能和AV研究社区做出了贡献，并有利于各种下游应用。

> **ai_Abstract:** 本研究提出了一种全自动方法，旨在解决Waymo开放运动数据集（WOMD）中交通信号数据缺失和不准确的问题。该方法利用车辆轨迹数据和交通领域知识，能够有效推断和纠正交通信号信息，并适用于多种复杂的交叉路口和信号配置。通过对WOMD的全面验证，该方法成功推断了原始数据中71.7%的缺失或未知信号状态，并将估计的闯红灯率从15.7%显著降低至2.9%，从而证明了其在提高自动驾驶数据集质量方面的有效性，对AI和AV研究具有重要意义。

> **摘要翻译:** 自动驾驶汽车（AVs）相关的数据集在人工智能（AI）、自动驾驶和交通工程等一系列研究领域中具有重要的前景。然而，这些数据集经常遇到与交通信号状态相关的挑战，例如数据缺失或不准确。此类问题会损害数据集的可靠性，并对使用它们开发的模型性能产生不利影响。本研究引入了一种全自动方法，旨在通过利用可用的车辆轨迹数据以及交通领域的知识，有效推断和纠正Waymo开放运动数据集（WOMD）中的交通信号信息，从而解决这些问题。所提出的方法具有鲁棒性和灵活性，能够处理现实世界中不同的交叉路口几何形状和交通信号配置。我们对整个WOMD进行了全面验证，重点关注了总计530,000个真实世界驾驶场景中超过360,000个与交通信号相关的场景。在原始数据集中，71.7%的交通信号状态缺失或未知，所有这些都通过我们提出的方法成功推断。此外，在缺乏地面真实信号状态的情况下，根据车辆轨迹的闯红灯率评估了我们方法的准确性。结果显示，我们的方法将原始数据中估计的闯红灯率从15.7%降低到2.9%，从而证明了其纠正数据不准确性的有效性。本文显著提高了AV数据集的质量，为更广泛的人工智能和AV研究社区做出了贡献，并有利于各种下游应用。代码和改进的交通信号数据已在https://github.com/michigan-traffic-lab/WOMD-Traffic-Signal-Data-Improvement 开源。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [295] [MorphoCopter: Design, Modeling, and Control of a New Transformable Quad-Bi Copter](https://arxiv.org/abs/2506.07204)
> *MorphoCopter: 一种新型可变形四旋翼-双旋翼飞行器的设计、建模与控制*

*Harsh Modi, Hao Su, Xiao Liang, Minghui Zheng* | **Main category: cs.RO**

**Keywords:** 变形四旋翼飞行器, 单一旋转关节, 自适应控制, 窄间隙通过, MorphoCopter

**Comment:** 

> **TL;DR:** MorphoCopter是一种新型可变形四旋翼飞行器，可通过单一旋转关节快速变形，实现超窄姿态，并采用自适应控制系统在不同配置下保持鲁棒性能。

**AI_Comments:** MorphoCopter的创新之处在于其单一旋转关节设计，实现了快速且显著的宽度缩减，同时通过自适应控制系统克服了现有变形无人机在可控性方面的挑战。这种设计对于在复杂和狭窄空间中执行任务的无人机具有重要意义，有望拓宽四旋翼飞行器的应用范围。

<details>
  <summary>Details</summary>

**Motivation:** 现有四旋翼飞行器硬件配置基本不变，限制了其在特定环境中的能力。现有变形设计常牺牲紧凑配置下的可控性或依赖复杂多关节系统。本研究旨在解决这些局限性。

**Method:** 本文提出了一种名为MorphoCopter的新型变形四旋翼飞行器，具有独特的单一旋转关节，能够快速变形。开发了一种新的惯性和控制动作感知的自适应控制系统，以在所有旋转关节配置中保持鲁棒性能。通过仿真和全面的飞行实验（包括鲁棒性测试、轨迹跟踪和窄间隙通过测试）进行验证。

**Result:** MorphoCopter在几秒内可将宽度从447毫米减少到138毫米（接近70%的缩减）。该设计实现了比现有解决方案更大的宽度缩减。自适应控制系统在所有旋转关节配置下保持了鲁棒性能。

**Conclusion:** MorphoCopter通过其独特的单一旋转关节设计和新的自适应控制系统，成功实现了快速变形、显著的宽度缩减以及在各种配置下的鲁棒飞行性能，克服了现有变形无人机的局限性。

> **ai_Abstract:** 本文介绍了一种名为MorphoCopter的新型可变形四旋翼飞行器。该飞行器通过独特的单一旋转关节，能够快速从X形四旋翼配置变形为堆叠的双旋翼或中间配置，实现高达70%的宽度缩减，以适应狭窄环境。为确保在不同形态下的鲁棒性能，研究开发了一种惯性和控制动作感知的自适应控制系统。通过仿真和全面的飞行实验，验证了其设计、变形能力和控制系统的有效性。

> **摘要翻译:** 本文介绍了一种名为MorphoCopter的新型变形四旋翼飞行器，涵盖其设计、建模、控制和实验测试。它具有独特的单一旋转关节，能够快速变形为超窄外形。尽管四旋翼飞行器在电影摄影、农业和灾害管理等应用中得到了广泛采用，并配备了日益复杂的控制系统，但其硬件配置基本保持不变，限制了它们在某些环境中的能力。我们的设计通过在需要时实现硬件配置的即时改变来解决这个问题。在标准飞行模式下，MorphoCopter采用X形配置，作为传统四旋翼飞行器运行，但可以迅速折叠成堆叠的双旋翼布局或介于两者之间的任何配置。现有的变形设计通常会牺牲紧凑配置下的可控性或依赖复杂的多个关节系统。此外，我们的设计实现了比任何现有解决方案更大的宽度缩减。我们开发了一种新的惯性和控制动作感知的自适应控制系统，该系统在所有旋转关节配置中都能保持鲁棒性能。原型机可以在短短几秒钟内将其宽度从447毫米减少到138毫米（接近70%的缩减）。我们通过严格的仿真和一系列全面的飞行实验（包括鲁棒性测试、轨迹跟踪和窄间隙通过测试）验证了MorphoCopter。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [301] [Machine Learning-Based Self-Localization Using Internal Sensors for Automating Bulldozers](https://arxiv.org/abs/2506.07271)
> *机器学习辅助的推土机自动化内部传感器自定位*

*Hikaru Sawafuji, Ryota Ozaki, Takuto Motomura, Toyohisa Matsuda, Masanori Tojima, Kento Uchida, Shinichi Shirakawa* | **Main category: cs.RO**

**Keywords:** 推土机自定位, 机器学习, 内部传感器, 扩展卡尔曼滤波器, RTK-GNSS

**Comment:** 

> **TL;DR:** 提出了一种基于机器学习的推土机自定位方法，利用内部传感器在RTK-GNSS信号丢失时提高定位精度。

**AI_Comments:** 该论文的创新之处在于提出了一种不依赖RTK-GNSS的推土机自定位方案，解决了传统方法在特定工况下信号丢失的问题。通过结合机器学习和内部传感器数据，提高了定位的鲁棒性和精度，尤其是在复杂和易打滑的环境中。创建新的专用数据集也为后续研究提供了宝贵资源。这项研究对于实现推土机在恶劣环境下的完全自动化具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统推土机自定位系统依赖RTK-GNSS，但在某些采矿条件下信号会丢失，因此需要不依赖RTK-GNSS的自定位方法。

**Method:** 提出的方法包括两步：1) 使用机器学习模型从内部传感器估计局部速度；2) 将这些估计值整合到扩展卡尔曼滤波器(EKF)中进行全局定位。还创建了新的推土机里程计数据集，并在多种驾驶场景下进行实验。

**Result:** 提出的自定位方法相比基于运动学的方法抑制了位置误差的积累，尤其是在打滑时。此外，推土机专用传感器（如铲刀位置传感器和液压传感器）有助于提高自定位精度。

**Conclusion:** 该研究成功开发了一种不依赖RTK-GNSS的推土机自定位方法，并通过结合机器学习和内部传感器显著提高了在复杂工况下的定位精度和鲁棒性。

> **ai_Abstract:** 本文针对传统推土机自定位系统在RTK-GNSS信号丢失时面临的挑战，提出了一种基于机器学习的内部传感器自定位方法。该方法通过机器学习模型估计局部速度，并将其融合到扩展卡尔曼滤波器中进行全局定位。实验结果表明，该方法在抑制位置误差积累方面优于传统方法，尤其在打滑条件下表现出色，并且推土机专用传感器对提高定位精度有显著贡献。

> **摘要翻译:** 自定位是推土机自动化的一项重要技术。
传统的推土机自定位系统依赖于RTK-GNSS（实时动态-全球导航卫星系统）。然而，在某些采矿条件下，RTK-GNSS信号有时会丢失。因此，需要不依赖RTK-GNSS的自定位方法。在本文中，我们提出了一种基于机器学习的推土机自定位方法。所提出的方法包括两个步骤：使用机器学习模型从内部传感器估计局部速度，并将这些估计值整合到扩展卡尔曼滤波器（EKF）中进行全局定位。我们还创建了一个新的推土机里程计数据集，并在包括S形弯道、挖掘和坡道行驶在内的各种驾驶场景中进行了实验。结果表明，与基于运动学的方法相比，所提出的自定位方法抑制了位置误差的积累，尤其是在打滑发生时。此外，这项研究表明，推土机专用传感器，如铲刀位置传感器和液压传感器，有助于提高自定位精度。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [307] [Model Analysis And Design Of Ellipse Based Segmented Varying Curved Foot For Biped Robot Walking](https://arxiv.org/abs/2506.07283)
> *双足机器人行走中基于椭圆分段变曲率足的模型分析与设计*

*Boyang Chen, Xizhe Zang, Chao Song, Yue Zhang, Jie Zhao* | **Main category: cs.RO**

**Keywords:** 双足机器人, 椭圆足, 能量效率, 步态控制, 足部设计

**Comment:** 

> **TL;DR:** 本文提出并验证了一种基于椭圆分段变曲率（ESVC）的仿人足机器人脚部设计，该设计通过优化足部形状，显著提高了双足机器人步态能量效率，尤其在侧向行走中节能高达18.52%。

**AI_Comments:** 这项研究通过仿生学方法，将人类足部的分段曲率特性应用于机器人足部设计，实现了显著的能量效率提升，尤其在侧向行走中的表现突出。其创新点在于提出了完整的分析接触模型和优化的椭圆参数确定方法，并引入了误差补偿机制，确保了设计的精确性和实用性。这项工作不仅为双足机器人的足部设计提供了新的思路和有效方案，也为未来基于数据驱动的足部形状优化研究奠定了基础，具有重要的工程实践和理论研究价值。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过受人类足部分段曲率翻滚形状启发的设计，提高双足机器人步态能量效率，同时保持足部位置控制器分析上的易处理性。

**Method:** 首先，通过仅使用基本函数建立椭圆段的空间变换，推导了ESVC足的完整分析接触模型。然后，采用非线性规划方法，基于已知的中足确定了后足和前足的最佳椭圆参数。引入误差补偿方法来解决翻滚长度计算中的近似不准确性。最后，将ESVC足与基于混合线性倒立摆模型的行走控制器集成，并通过仿真和TT II双足机器人上的物理实验进行验证。

**Result:** 在原地踏步、矢状面和侧向行走任务中的实验结果表明，与直线形和扁平足相比，ESVC足持续降低了能量消耗，其中侧向行走中能量效率提升高达18.52%。

**Conclusion:** ESVC足为实际双足机器人行走提供了一种实用且节能的替代方案。所提出的设计方法也为未来研究中数据驱动的足部形状优化奠定了基础。

> **ai_Abstract:** 本文提出并验证了一种受人类足部启发、基于椭圆分段变曲率（ESVC）的双足机器人足部设计。该设计通过建立分析接触模型、优化椭圆参数并引入误差补偿，旨在提高步态能量效率。结合混合线性倒立摆模型控制器，在仿真和物理实验中，ESVC足在多种行走任务中均显著降低了能量消耗，尤其在侧向行走中实现了高达18.52%的能量效率提升，证明了其在实际双足机器人行走中的实用性和节能性。

> **摘要翻译:** 本文提出并验证了一种用于双足机器人的基于椭圆分段变曲率（ESVC）的足部建模、设计和实验验证。受人类足部分段曲率翻滚形状的启发，ESVC足旨在提高步态能量效率，同时保持足部位置控制器分析上的易处理性。首先，我们通过仅使用基本函数建立椭圆段的空间变换，推导了ESVC足的完整分析接触模型。然后，采用非线性规划方法，基于已知的中足确定了后足和前足的最佳椭圆参数。引入误差补偿方法来解决翻滚长度计算中的近似不准确性。所提出的ESVC足随后与基于混合线性倒立摆模型的行走控制器集成，并通过仿真和TT II双足机器人上的物理实验进行验证。在原地踏步、矢状面和侧向行走任务中的实验结果表明，与直线形和扁平足相比，ESVC足持续降低了能量消耗，其中侧向行走中能量效率提升高达18.52%。这些发现表明，ESVC足为实际双足机器人行走提供了一种实用且节能的替代方案。所提出的设计方法也为未来研究中数据驱动的足部形状优化奠定了基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [315] [BR-MPPI: Barrier Rate guided MPPI for Enforcing Multiple Inequality Constraints with Learned Signed Distance Field](https://arxiv.org/abs/2506.07325)
> *BR-MPPI：基于障碍率引导的MPPI，用于通过学习符号距离场强制执行多重不等式约束*

*Hardik Parwana, Taekyung Kim, Kehan Long, Bardh Hoxha, Hideki Okamoto, Georgios Fainekos, Dimitra Panagou* | **Main category: cs.RO**

**Keywords:** MPPI, 控制障碍函数, 不等式约束, 最优控制, 四旋翼飞行器

**Comment:** 

> **TL;DR:** BR-MPPI将类控制障碍函数条件整合到MPPI中，通过将CBF条件视为增强系统中的等式约束来强制执行多个不等式约束，从而提高了安全性和采样效率。

**AI_Comments:** 本论文提出了一种创新方法，通过将 CBF 条件重新解释为等式约束，巧妙地融合了 MPPI（基于采样的最优控制）和 CBF（安全保证）的优势。将 classK 参数作为状态空间的一部分并由 MPPI 设计其导数的思想，对于将安全性融入采样框架中尤其巧妙。此外，状态变换和控制投影操作的引入进一步增强了其在复杂约束问题中的实用性。这项工作对于开发在严格不等式约束下运行系统的安全高效控制器具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** Model Predictive Path Integral (MPPI) 控制器擅长解决无约束最优控制问题，而控制障碍函数 (CBF) 则用于施加严格的不等式约束。本研究的动机在于将这两种方法结合起来，以有效地处理和强制执行多重不等式约束，克服MPPI在随机采样控制输入下难以满足此类约束的挑战。

**Method:** 本文提出了 BR-MPPI 算法，通过以下方式将 MPPI 与类 CBF 条件相结合：1. 将 CBF 条件（即障碍函数变化率受 classK 函数限制）重新表述为等式约束。2. 选择一个参数化的线性 classK 函数，并将其参数作为增强系统中的一个状态。3. 将该参数的时间导数视为由 MPPI 设计的额外控制输入。4. 设计一个成本函数，促使 classK 参数取特定值，以在安全集边界处重新激活 Nagumo 定理，从而强制执行安全性。5. 为解决多重状态和控制相关等式约束难以满足的问题，引入了状态变换和控制投影操作。

**Result:** 通过在四旋翼飞行器上进行的仿真和实验，经验证明所提出的 BR-MPPI 算法相较于普通的 MPPI，展现出更好的采样效率和更强的在安全集边界附近运行的能力。

**Conclusion:** BR-MPPI 成功地将 MPPI 和 CBF 结合起来，有效地强制执行多重不等式约束，从而提高了控制器的安全性和在安全边界附近的运行效率。

> **ai_Abstract:** 本文提出了一种名为 BR-MPPI 的新型控制框架，它将模型预测路径积分 (MPPI) 与控制障碍函数 (CBF) 原理相结合。该方法将 CBF 条件重新表述为增强系统中的等式约束，其中一个参数化的 classK 函数被视为附加状态，其导数由 MPPI 设计为控制输入。为了应对满足多个等式约束的挑战，该方法引入了状态变换和控制投影操作。在四旋翼飞行器上的仿真和实验结果表明，与标准 MPPI 相比，BR-MPPI 显著提高了采样效率，并能更安全地在约束边界附近运行。

> **摘要翻译:** 模型预测路径积分 (MPPI) 控制器用于解决无约束最优控制问题，而控制障碍函数 (CBF) 是一种施加严格不等式约束（又称障碍约束）的工具。在这项工作中，我们提出了一种将这两种方法集成在一起的方法，该方法采用类似 CBF 的条件来引导 MPPI 的控制采样过程。CBF 规定了一个不等式约束，通过障碍函数本身的 classK 函数来限制障碍函数的变化率。我们通过选择参数化的线性 classK 函数并将此参数视为增强系统中的一个状态，从而将 CBF 条件作为等式约束施加。此参数的时间导数作为由 MPPI 设计的额外控制输入。进一步设计了一个成本函数，通过促进 classK 参数的特定值来重新激活安全集边界处的 Nagumo 定理，以强制执行安全性。我们的问题公式导致 MPPI 受到多个状态和控制相关等式约束，这些约束很难通过随机采样的控制输入来满足。因此，我们还引入了状态变换和控制投影操作（受流形路径规划文献启发）来解决上述问题。我们通过四旋翼飞行器上的仿真和实验经验证明，我们提出的算法比普通的 MPPI 表现出更好的采样效率和更强的在安全集边界附近操作的能力。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [319] [Real-Time Execution of Action Chunking Flow Policies](https://arxiv.org/abs/2506.07339)
> *动作分块流策略的实时执行*

*Kevin Black, Manuel Y. Galliker, Sergey Levine* | **Main category: cs.RO**

**Keywords:** 实时AI, 动作分块, 视觉-语言模型, 延迟, 机器人, 异步执行

**Comment:** 

> **TL;DR:** 本文提出了一种名为实时分块（RTC）的新型推理算法，旨在解决视觉-语言动作（VLA）模型在实时物理交互中的高延迟问题。RTC无需重新训练即可使动作分块策略平滑异步执行，显著提高任务吞吐量和成功率，即使在高延迟环境下也能实现。

**AI_Comments:** 该论文解决了一个在现实世界中部署AI系统所面临的关键实际问题：高频控制任务中的延迟。其创新之处在于提出了一种“推理时间算法”，这意味着它无需重新训练即可作为现有VLA模型的即插即用解决方案，这对于立即应用具有高价值。通过“冻结”和“修复”动作块内动作以实现异步执行的方法非常巧妙。其所展示的对推理延迟的鲁棒性和改进的吞吐量是机器人操作和实时控制领域的重大贡献。

<details>
  <summary>Details</summary>

**Motivation:** 现代AI系统，特别是与物理世界交互的系统，需要实时性能。然而，当前最先进的通用模型（包括视觉-语言动作模型VLAs）存在高延迟问题。尽管动作分块能提高高频控制任务的时间一致性，但未能完全解决延迟问题，导致在分块边界处出现停顿或不协调的动作。

**Method:** 本文提出了一种新颖的推理时间算法——实时分块（RTC），用于实现动作分块策略的平滑异步执行。该方法无需重新训练即可适用于任何基于扩散或流的VLA。RTC在执行当前动作块的同时生成下一个动作块，通过“冻结”确定执行的动作并“修复”其余部分。为测试RTC，研究者引入了Kinetix模拟器中的12个高度动态任务的新基准，并评估了6个具有挑战性的真实世界双手操作任务。

**Result:** 结果表明，RTC速度快、性能好，并且对推理延迟具有独特的鲁棒性。它显著提高了任务吞吐量，即使在存在显著延迟的情况下，也能在精确任务（如点燃火柴）中实现高成功率。

**Conclusion:** RTC算法能够实现动作分块策略的平滑异步执行，有效解决了实时AI系统与物理世界交互中的延迟问题，从而提高了性能和鲁棒性。

> **ai_Abstract:** 本文提出了一种名为实时分块（RTC）的新型推理时间算法，旨在解决现代视觉-语言动作（VLA）模型在实时物理世界交互中面临的高延迟挑战。与现有动作分块方法不同，RTC通过在执行当前动作块的同时生成下一个动作块，实现动作分块策略的平滑异步执行，从而避免了在分块边界处的停顿和不协调动作。该方法无需对现有扩散或流式VLA进行重新训练即可应用。通过在Kinetix模拟器中的新基准测试和真实世界双手操作任务上的评估，RTC展现出卓越的速度、性能和对推理延迟的鲁棒性，显著提升了任务吞吐量，并在高延迟环境下也能确保高精度任务的成功率。

> **摘要翻译:** 现代AI系统，特别是与物理世界交互的系统，越来越需要实时性能。然而，最先进的通用模型（包括最近的视觉-语言动作模型（VLAs））的高延迟带来了重大挑战。虽然动作分块在高频率控制任务中实现了时间一致性，但它并未完全解决延迟问题，导致在分块边界处出现暂停或超出分布的生涩动作。本文提出了一种新颖的推理时间算法，能够实现动作分块策略的平滑异步执行。我们的方法——实时分块（RTC），无需重新训练即可开箱即用于任何基于扩散或流的VLA。它在执行当前动作块的同时生成下一个动作块，“冻结”保证执行的动作并“修复”其余部分。为了测试RTC，我们引入了Kinetix模拟器中的12个高度动态任务的新基准，并评估了6个具有挑战性的真实世界双手操作任务。结果表明，RTC速度快、性能好，并且对推理延迟具有独特的鲁棒性，显著提高了任务吞吐量，并使在精确任务中（例如点燃火柴）实现高成功率成为可能，即使在存在显著延迟的情况下也是如此。请访问https://pi.website/research/real_time_chunking 查看视频。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [324] [Reproducibility in the Control of Autonomous Mobility-on-Demand Systems](https://arxiv.org/abs/2506.07345)
> *自主按需出行系统控制中的可重现性*

*Xinling Li, Meshal Alharbi, Daniele Gammelli, James Harrison, Filipe Rodrigues, Maximilian Schiffer, Marco Pavone, Emilio Frazzoli, Jinhua Zhao, Gioele Zardini* | **Main category: cs.RO**

**Keywords:** 自动按需出行系统, 可重现性, 控制算法, 赛博物理系统, 标准化实践

**Comment:** 

> **TL;DR:** 自动按需出行（AMoD）系统研究面临严重的可重现性挑战，本文系统分析了问题根源，并提出了一个结构化框架和“可重现性清单”，旨在促进更透明、可复制的研究。

**AI_Comments:** 这篇论文解决了AMoD领域一个关键且日益重要的问题：研究的可重现性。其创新之处在于系统性地识别了不可重现性的来源，并提出了一个实用的框架和“可重现性清单”，这对于推动该领域健康发展至关重要。该工作不仅对AMoD有直接指导意义，其提出的原则也具有广泛适用性，能促进整个赛博物理系统研究的透明度和科学严谨性。

<details>
  <summary>Details</summary>

**Motivation:** 自动按需出行（AMoD）系统作为未来城市交通的重要范式，其领域发展迅速，但缺乏评估和报告结果的标准化实践，导致研究结果的可重现性面临重大挑战。模型假设、实验设置和算法实现缺乏透明度，这阻碍了科学进步并损害了对研究结果的信心。

**Method:** 本文对AMoD研究中的可重现性进行了系统性研究。具体方法包括：识别研究流程中的关键组成部分（涵盖系统建模、控制问题、仿真设计、算法规范和评估），分析不可重现性的常见来源，调查现有文献中的普遍实践并指出其不足。在此基础上，提出了一个结构化框架和“可重现性清单”，旨在支持未来工作实现可复制、可比较和可扩展的研究结果。

**Result:** 本文识别了AMoD研究中不可重现性的关键组成部分和常见来源，并调查了现有实践中的不足。它提出了一个结构化框架和一份实用的“可重现性清单”，这些工具旨在显著改善AMoD系统设计和部署中研究结果的可复制性、可比较性和可扩展性。

**Conclusion:** 本文旨在为智能出行系统设计和部署中更透明和可重现的研究文化奠定基础。尽管研究重点是AMoD，但所提出的原则和实践具有普适性，可以推广到更广泛的依赖网络自主性和数据驱动控制的赛博物理系统。

> **ai_Abstract:** 本文探讨了自动按需出行（AMoD）系统研究中日益突出的可重现性问题。鉴于该领域快速发展但缺乏标准化实践，导致透明度不足并阻碍科学进步。作者系统性地研究了AMoD研究流程中的关键组成部分和不可重现性的常见来源。通过调查现有文献并指出不足，本文提出了一个结构化框架和“可重现性清单”，旨在为AMoD及其他赛博物理系统提供指导，以促进更透明、可复制、可比较和可扩展的研究。

> **摘要翻译:** 自动按需出行（AMoD）系统，得益于机器人技术、控制和机器学习（ML）的进步，为未来城市交通提供了一个有前景的范式。AMoD通过利用自动驾驶车队集中控制来优化运营和提升服务性能，从而提供快速和个性化的出行服务。然而，该领域的快速增长已经超越了评估和报告结果标准化实践的发展，导致可重现性面临重大挑战。随着AMoD控制算法变得日益复杂和数据驱动，模型假设、实验设置和算法实现缺乏透明度阻碍了科学进步并损害了对结果的信心。本文对AMoD研究中的可重现性进行了系统性研究。我们识别了研究流程中的关键组成部分，涵盖系统建模、控制问题、仿真设计、算法规范和评估，并分析了不可重现性的常见来源。我们调查了文献中的普遍实践，指出了不足，并提出了一个结构化框架来评估和改善可重现性。具体而言，本文提供了具体的指南和一份“可重现性清单”，以支持未来工作实现可复制、可比较和可扩展的结果。尽管侧重于AMoD，但我们倡导的原则和实践可以推广到更广泛的依赖网络自主性和数据驱动控制的赛博物理系统。这项工作旨在为智能出行系统设计和部署中更透明和可重现的研究文化奠定基础。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [329] [UruBots Autonomous Cars Challenge Pro Team Description Paper for FIRA 2025](https://arxiv.org/abs/2506.07348)
> *UruBots 自动驾驶汽车挑战赛专业组团队描述论文 FIRA 2025*

*Pablo Moraes, Mónica Rodríguez, Sebastian Barcelona, Angel Da Silva, Santiago Fernandez, Hiago Sodre, Igor Nunes, Bruna Guterres, Ricardo Grando* | **Main category: cs.RO**

**Keywords:** 自动驾驶汽车, FIRA 挑战赛, 深度学习, 卷积神经网络, 实时导航

**Comment:** 

> **TL;DR:** UruBots 团队为 FIRA 2025 自动驾驶汽车挑战赛开发了一辆基于深度学习的紧凑型自动驾驶小车，并成功完成了赛道测试。

**AI_Comments:** 该论文展示了一个实用的自动驾驶小车开发案例，其亮点在于结合了硬件构建与基于深度学习的视觉导航系统。使用 CNN 和大量图像数据集进行训练是其成功的关键。虽然速度和尺寸受挑战赛限制，但其在实时决策和障碍规避方面的表现值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 参加 2025 年 FIRA 自动驾驶汽车挑战赛（专业组）。

**Method:** 构建了一辆紧凑型电动车，整合了机械、电子组件和机器学习算法。利用深度学习模型（特别是卷积神经网络 CNN）处理摄像头视觉输入，并通过超过一万张图像的数据集进行训练，以实时控制车辆的转向和油门进行导航。

**Result:** 车辆在 30 秒内完成了赛道，平均速度约为每秒 0.4 米，并成功避开了障碍物。

**Conclusion:** 该自动驾驶小车成功通过了赛道测试，证明了其在 FIRA 2025 挑战赛中的能力。

> **ai_Abstract:** 本文介绍了 UruBots 团队为 2025 年 FIRA 自动驾驶汽车挑战赛专业组开发的自动驾驶小车。该车辆集成了机械、电子组件和基于深度学习的视觉导航系统，特别是使用 CNN 处理摄像头图像以控制转向和油门。经过大量图像数据集的训练，该车成功在 30 秒内以约 0.4 米/秒的速度完成赛道并避开障碍物。

> **摘要翻译:** 这篇论文描述了 UruBots 团队为 2025 年 FIRA 自动驾驶汽车挑战赛（专业组）开发自动驾驶汽车的过程。该项目包括构建一辆紧凑型电动车，其大小与遥控车相近，能够自主导航通过不同的赛道。设计中整合了机械和电子组件以及机器学习算法，使车辆能够根据摄像头的视觉输入做出实时导航决策。我们使用深度学习模型处理摄像头图像并控制车辆运动。利用超过一万张图像的数据集，我们训练了一个卷积神经网络（CNN）来有效地驾驶车辆，通过转向和油门两个输出进行控制。该车在 30 秒内完成了赛道，速度约为每秒 0.4 米，同时避开了障碍物。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [335] [MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation](https://arxiv.org/abs/2506.07350)
> *MapBERT：实时语义地图生成的位掩码建模*

*Yijie Deng, Shuaihang Yuan, Congcong Wen, Hao Huang, Anthony Tzes, Geeta Chandra Raju Bethala, Yi Fang* | **Main category: cs.RO**

**Keywords:** 语义地图生成, 位掩码建模, MapBERT, BitVAE, 掩码Transformer

**Comment:** 

> **TL;DR:** MapBERT提出了一种基于位掩码建模的新框架，利用BitVAE和掩码Transformer，通过对象感知掩码策略，实现实时、鲁棒且高效的语义地图生成，并在Gibson基准测试中达到SOTA。

**AI_Comments:** MapBERT的创新之处在于首次将语义地图的独热编码与位编码的二进制结构相结合，并引入查找表无关的BitVAE进行高效编码。结合掩码Transformer和对象感知掩码策略，有效提升了模型对复杂室内语义分布的建模能力和对未观测区域的重建精度。其实时性和高效率对于实际机器人应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在实时生成未观测区域方面存在困难，且泛化性差，尤其是在学习室内语义分布时面临稀疏、不平衡的对象类别和多样化的空间尺度挑战。

**Method:** 提出MapBERT框架。首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌。在此基础上，使用掩码Transformer来推断缺失区域并从有限观测中生成完整的语义地图。为增强以对象为中心的推理，提出了对象感知掩码策略，同时掩码整个对象类别，并将其与可学习嵌入配对。

**Result:** MapBERT在Gibson基准测试中实现了最先进的语义地图生成，平衡了计算效率和对未观测区域的准确重建。

**Conclusion:** MapBERT通过其新颖的位掩码建模和对象感知策略，有效解决了实时语义地图生成中的挑战，实现了高性能和高效率，对机器人任务至关重要。

> **ai_Abstract:** MapBERT是一个新颖的框架，旨在解决具身智能体在实时语义地图生成中面临的挑战，特别是针对未观测区域的鲁棒性和泛化性问题。该方法首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌，并结合掩码Transformer来推断缺失区域。为提升对象感知推理，MapBERT引入了对象感知掩码策略，通过学习对象嵌入和空间令牌间的关系，有效捕获室内语义分布。实验证明，MapBERT在Gibson基准测试中实现了最先进的语义地图生成，同时保持了计算效率和高准确度。

> **摘要翻译:** 空间感知是具身智能体的关键能力，因为它使它们能够预测和推断未观测区域。主要挑战源于学习室内语义的分布，这因稀疏、不平衡的对象类别和多样化的空间尺度而变得复杂。现有方法难以实时鲁棒地生成未观测区域，并且对新环境的泛化性不佳。为此，我们提出了\textbf{MapBERT}，一个旨在有效建模未见空间分布的新颖框架。受语义地图独热编码与位编码二进制结构自然对齐的启发，我们首次利用查找表无关的BitVAE将语义地图编码为紧凑的位掩码令牌。在此基础上，采用掩码Transformer来推断缺失区域并从有限观测中生成完整的语义地图。为了增强以对象为中心的推理，我们提出了一种对象感知掩码策略，该策略同时掩码整个对象类别，并将其与可学习嵌入配对，捕获对象嵌入和空间令牌之间的隐式关系。通过学习这些关系，模型更有效地捕获对实际机器人任务至关重要的室内语义分布。Gibson基准测试的实验表明，MapBERT实现了最先进的语义地图生成，平衡了计算效率和对未观测区域的准确重建。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [341] [Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs](https://arxiv.org/abs/2506.07454)
> *基于语言的多机器人3D场景图分层规划与执行*

*Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, Nathan Hughes, Christopher Bradley, Yi Xuan Jia, Carlos Nieto-Granda, Rajat Talak, Chuchu Fan, Luca Carlone, Jonathan P. How, Nicholas Roy* | **Main category: cs.RO**

**Keywords:** 多机器人系统, 3D场景图, 自然语言处理, 任务规划, 大型语言模型

**Comment:** 12 pages, 4 figures

> **TL;DR:** 该研究提出了一个多机器人系统，利用3D场景图和大型语言模型，实现对自然语言复杂指令的分层规划与执行。

**AI_Comments:** 该论文的创新点在于将3D场景图与大型语言模型（LLM）相结合，实现了多机器人系统对复杂自然语言指令的理解和执行。这种集成方法提高了机器人在复杂环境中的态势感知能力和任务规划效率，为多机器人协同操作提供了新的范式。其在真实世界户外环境中的实验评估也增强了其实用性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有系统在执行自然语言表达的复杂指令时面临挑战，本研究旨在通过集成3D场景图和LLM来解决多机器人系统中的这一问题，使其能够理解和执行复杂的任务。

**Method:** 本系统引入了一个多机器人系统，该系统通过3D场景图集成测绘、定位以及任务和运动规划（TAMP）。它构建了一个共享的3D场景图，其中包含一个开放集基于对象的地图，用于多机器人3D场景图融合。该表示支持实时、视图不变的重定位和规划。此外，系统还引入了一种规划方法，利用大型语言模型（LLM）并结合共享3D场景图和机器人能力，将操作员意图转化为规划域定义语言（PDDL）目标。

**Result:** 该系统已在大型户外环境中的真实世界任务中进行了实验评估，验证了其性能。

**Conclusion:** 本研究提出的多机器人系统能够成功地将自然语言指令转化为可执行的机器人任务，并通过3D场景图和LLM实现高效的规划和执行。

> **ai_Abstract:** 本文介绍了一个多机器人系统，该系统利用共享的3D场景图整合了测绘、定位和任务与运动规划（TAMP），以执行自然语言指令。该系统通过一个开放集对象地图支持实时、视图不变的重定位和规划，并使用大型语言模型（LLM）将操作员意图转化为PDDL目标。系统已在真实世界的大规模户外环境中进行了性能评估。

> **摘要翻译:** 在本文中，我们介绍了一个多机器人系统，该系统通过3D场景图集成测绘、定位以及任务和运动规划（TAMP），以执行自然语言表达的复杂指令。我们的系统构建了一个共享的3D场景图，其中包含一个开放集基于对象的地图，该地图用于多机器人3D场景图融合。这种表示支持实时、视图不变的重定位（通过基于对象的地图）和规划（通过3D场景图），从而使机器人团队能够推理其周围环境并执行复杂任务。此外，我们引入了一种规划方法，该方法利用大型语言模型（LLM），通过共享的3D场景图和机器人能力提供的上下文，将操作员意图转化为规划域定义语言（PDDL）目标。我们对系统在大型户外环境中的真实世界任务中的性能进行了实验评估。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [344] [RAPID Hand: A Robust, Affordable, Perception-Integrated, Dexterous Manipulation Platform for Generalist Robot Autonomy](https://arxiv.org/abs/2506.07490)
> *RAPID 手: 一个鲁棒、经济、感知集成、灵巧操作平台，用于通用机器人自主性*

*Zhaoliang Wan, Zetong Bi, Zida Zhou, Hao Ren, Yiming Zeng, Yihan Li, Lu Qi, Xu Yang, Ming-Hsuan Yang, Hui Cheng* | **Main category: cs.RO**

**Keywords:** RAPID Hand, 多指机器人, 灵巧操作, 通用机器人自主性

**Comment:** 

> **TL;DR:** 开发了一种低成本、高灵巧度的机器人手RAPID Hand，集成了感知和遥操作，用于收集通用机器人自主学习数据。

**AI_Comments:** RAPID Hand的创新之处在于其协同优化了硬件、感知和遥操作界面，解决了现有平台在成本、灵巧度和数据收集方面的痛点。其采用低成本和现成组件，并承诺开源，极大地降低了研究门槛，有望加速通用机器人自主学习领域的发展。

<details>
  <summary>Details</summary>

**Motivation:** 缺乏低成本但高灵巧度的平台来收集真实世界多指机器人操作数据，以实现通用机器人自主性。现有遥操作方法在复杂多指系统上精度和稳定性不足。

**Method:** 提出了RAPID Hand，一个硬件和软件协同优化的平台。它包括紧凑的20自由度手、鲁棒的整体手部感知（腕部视觉、指尖触觉、本体感受，亚7毫秒延迟和空间对齐）和高自由度遥操作界面。通过通用驱动方案、定制感知电子设备和两种重定向约束，共同优化了手部设计、感知集成和遥操作界面。

**Result:** 评估了平台的硬件、感知和遥操作界面。在收集的数据上训练扩散策略显示出优于现有工作的性能，验证了系统收集可靠、高质量数据的能力。平台由低成本和现成组件构建，并将公开。

**Conclusion:** RAPID Hand是一个有效且可行的平台，能够促进通用机器人自主学习所需的高质量多指操作数据收集。

> **ai_Abstract:** 本文提出了RAPID Hand，一个用于通用机器人自主学习的低成本、高灵巧度多指操作平台。该平台通过硬件与软件的协同优化，集成了20自由度机械手、鲁棒的腕部视觉与指尖触觉感知系统，以及高自由度遥操作界面。实验证明，该平台能有效收集高质量数据，并在此数据上训练的扩散策略表现优异，为机器人操作数据收集提供了一个可复制且易于采用的解决方案。

> **摘要翻译:** 本文旨在解决用于通用机器人自主学习的低成本但高灵巧度平台在收集真实世界多指机器人操作数据方面的稀缺问题。为此，我们提出了RAPID Hand，一个硬件和软件协同优化的平台，其中紧凑的20自由度手、鲁棒的整体手部感知和高自由度遥操作界面是共同设计的。具体而言，RAPID Hand采用了紧凑实用的手部本体论和硬件级感知框架，该框架稳定地集成了腕部视觉、指尖触觉和本体感受，具有亚7毫秒的延迟和空间对齐。在高自由度手上收集高质量演示数据具有挑战性，因为现有遥操作方法在复杂多指系统上难以实现精度和稳定性。我们通过通用驱动方案、定制感知电子设备和两种重定向约束，共同优化了手部设计、感知集成和遥操作界面。我们评估了平台的硬件、感知和遥操作界面。在收集的数据上训练扩散策略显示出优于现有工作的性能，验证了系统收集可靠、高质量数据以实现高质量数据收集的能力。该平台由低成本和现成组件构建，并将公开以确保可重复性和易于采用。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [349] [Taking Flight with Dialogue: Enabling Natural Language Control for PX4-based Drone Agent](https://arxiv.org/abs/2506.07509)
> *借助对话实现飞行：为基于PX4的无人机智能体提供自然语言控制*

*Shoon Kit Lim, Melissa Jia Ying Chong, Jing Huey Khor, Ting Yang Ling* | **Main category: cs.RO**

**Keywords:** 无人机控制, 自然语言处理, PX4, 开源框架, 智能体

**Comment:** Source code available at:
  https://github.com/limshoonkit/ros2-agent-ws

> **TL;DR:** 本文提出了一个开源框架，通过自然语言控制基于PX4的无人机，旨在解决空中机器人研究不足和现有系统依赖闭源模型的问题。

**AI_Comments:** 该论文通过提供一个开源的解决方案，促进了无人机自然语言控制的民主化，特别是在使用本地托管模型方面具有创新性，降低了对昂贵闭源模型的依赖。这对于推动空中机器人领域的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 地面机器人研究进展迅速，但空中机器人相对未被充分探索；现有无人机多模态视觉-语言系统依赖闭源模型，限制了自然语言控制的普及。

**Method:** 提出了一个开源的智能体框架，该框架集成了基于PX4的飞控、机器人操作系统2 (ROS 2)中间件以及使用Ollama本地托管的模型。

**Result:** 在仿真和定制四旋翼平台上评估了性能，并对四种大型语言模型(LLM)系列用于命令生成和三种视觉-语言模型(VLM)系列用于场景理解进行了基准测试。

**Conclusion:** 本文成功构建并评估了一个开源框架，实现了通过自然语言对基于PX4的无人机进行控制，推动了自主无人机自然语言控制的民主化。

> **ai_Abstract:** 该论文提出了一个开源的智能体框架，旨在通过自然语言控制基于PX4的无人机，以解决空中机器人研究不足和现有系统依赖闭源模型的问题。该框架整合了PX4飞控、ROS 2和Ollama本地托管模型，并在仿真和实际四旋翼平台上对LLM和VLM的性能进行了评估。

> **摘要翻译:** 近期在智能体和物理人工智能(AI)方面的进展主要集中在地面平台，如人形机器人和轮式机器人，而空中机器人相对未被充分探索。同时，最先进的无人机(UAV)多模态视觉-语言系统通常依赖于只有资源充足的组织才能访问的闭源模型。为了实现自主无人机自然语言控制的民主化，我们提出了一个开源的智能体框架，该框架集成了基于PX4的飞控、机器人操作系统2 (ROS 2)中间件以及使用Ollama本地托管的模型。我们在仿真和定制四旋翼平台上评估了性能，对四种大型语言模型(LLM)系列用于命令生成和三种视觉-语言模型(VLM)系列用于场景理解进行了基准测试。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [354] [BitVLA: 1-bit Vision-Language-Action Models for Robotics Manipulation](https://arxiv.org/abs/2506.07530)
> *BitVLA：用于机器人操作的1比特视觉-语言-动作模型*

*Hongyu Wang, Chuyan Xiong, Ruiping Wang, Xilin Chen* | **Main category: cs.RO**

**Keywords:** 1比特量化, 视觉-语言-动作模型, 机器人操作, 模型压缩, 边缘部署

**Comment:** Work in progress

> **TL;DR:** BitVLA是首个用于机器人操作的1比特视觉-语言-动作模型，它将所有参数量化为三元（-1, 0, 1），并通过蒸馏感知训练进一步压缩视觉编码器。它在内存占用显著减少的情况下，实现了与最先进模型相当的性能。

**AI_Comments:** BitVLA的创新性在于将1比特量化应用于VLA模型，并结合蒸馏感知训练进一步压缩视觉编码器，有效解决了机器人系统内存受限的部署难题。其在性能与内存效率之间取得了出色的平衡，对于推动VLA模型在实际机器人应用中的落地具有重要意义。该工作证明了极低比特量化在复杂多模态模型中的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 视觉-语言-动作（VLA）模型在机器人操作任务中表现出色，但其不断增长的模型尺寸对在资源受限的机器人系统上部署提出了重大挑战。尽管1比特预训练已被证明能有效提高大型语言模型的推理效率且性能损失极小，但其在VLA模型中的应用仍未得到充分探索。

**Method:** 本文提出了BitVLA，这是首个用于机器人操作的1比特VLA模型，其所有参数均为三元（-1, 0, 1）。为了进一步减少视觉编码器的内存占用，提出了一种蒸馏感知训练策略，将全精度编码器压缩到1.58比特权重。在此过程中，一个全精度编码器作为教师模型，以更好地对齐潜在表示。

**Result:** 尽管缺乏大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与最先进模型OpenVLA-OFT（采用4比特后训练量化）相当的性能，而内存消耗仅为其29.8%。

**Conclusion:** BitVLA在内存受限的边缘设备上部署具有巨大潜力，因为它在显著降低内存消耗的同时保持了与现有先进模型相当的性能。

> **ai_Abstract:** 本文介绍了BitVLA，这是首个用于机器人操作的1比特视觉-语言-动作（VLA）模型，旨在解决现有VLA模型尺寸过大导致资源受限机器人系统部署困难的问题。BitVLA通过将所有模型参数量化为三元（-1, 0, 1），并采用蒸馏感知训练策略将视觉编码器压缩至1.58比特，显著降低了内存占用。尽管没有进行大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与现有先进模型OpenVLA-OFT（4比特后训练量化）相当的性能，但内存消耗仅为后者的29.8%。这表明BitVLA在边缘设备部署方面具有巨大潜力。

> **摘要翻译:** 视觉-语言-动作（VLA）模型在广泛的机器人操作任务中展现了令人印象深刻的能力。然而，其不断增长的模型尺寸对在资源受限的机器人系统上部署构成了重大挑战。尽管1比特预训练已被证明能有效提高大型语言模型的推理效率且性能损失极小，但其在VLA模型中的应用仍未得到充分探索。在这项工作中，我们提出了BitVLA，这是首个用于机器人操作的1比特VLA模型，其中每个参数都是三元的，即{-1, 0, 1}。为了进一步减少视觉编码器的内存占用，我们提出了一种蒸馏感知训练策略，将全精度编码器压缩到1.58比特权重。在此过程中，一个全精度编码器作为教师模型，以更好地对齐潜在表示。尽管缺乏大规模机器人预训练，BitVLA在LIBERO基准测试上实现了与最先进模型OpenVLA-OFT（采用4比特后训练量化）相当的性能，而内存消耗仅为其29.8%。这些结果突显了BitVLA在内存受限的边缘设备上部署的潜力。我们已在https://github.com/ustcwhy/BitVLA 发布了代码和模型权重。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [358] [Fractional Collisions: A Framework for Risk Estimation of Counterfactual Conflicts using Autonomous Driving Behavior Simulations](https://arxiv.org/abs/2506.07540)
> *分数碰撞：一个使用自动驾驶行为模拟进行反事实冲突风险评估的框架*

*Sreeja Roy-Singh, Sarvesh Kolekar, Daniel P. Bonny, Kyle Foss* | **Main category: cs.RO**

**Keywords:** 分数碰撞, 风险估计, 自动驾驶, 反事实模拟, 碰撞严重性

**Comment:** 

> **TL;DR:** 一个框架利用ADS传感器数据的反事实模拟来估计碰撞风险和严重程度，并显示自动驾驶系统（ADS）可以显著降低碰撞。

**AI_Comments:** 该论文引入了一个创新的“分数碰撞”框架，用于定量评估反事实模拟中的碰撞风险和严重程度，这对自动驾驶系统的评估和验证至关重要。使用概率模型来模拟人类行为以及与碰撞模型结合以估计伤害/财产损失的能力具有重要意义。通过真实世界碰撞数据进行验证以及展示ADS在降低风险方面的积极影响，突显了其在ADS开发和部署方面的实际重要性。

<details>
  <summary>Details</summary>

**Motivation:** 旨在利用自动驾驶系统（ADS）传感器数据或自然驾驶数据库构建的反事实模拟场景来估计碰撞风险，特别是为了评估新ADS软件版本的安全性。

**Method:** 该方法通过检测和分类双代理冲突类型，识别代理角色（发起者或响应者）及响应者的反应点，并将人类行为预期建模为概率反事实轨迹。这些状态用于计算碰撞时的速度差，并结合碰撞模型，以概率性伤害或财产损失的形式估计损失的严重程度，称之为“分数碰撞”。概率模型还可以扩展以包含与模拟、特征和代理相关的其他不确定性。该方法在合成模拟环境中得到验证，通过将自然响应者替换为ADS模拟器来评估ADS引起的碰撞风险。

**Result:** 该方法预测的分数碰撞与真实碰撞的误差在1%以内。在评估中，ADS将自然碰撞减少了4倍，分数碰撞风险降低了约62%。在25万英里的专有开放环路传感器数据上，ADS引发的冲突导致了0.4次致伤性分数碰撞和1.7次财产损失性分数碰撞，并且ADS在96%的代理引发的冲突中改善了碰撞风险。

**Conclusion:** 该框架提供了一种用于反事实模拟中估计碰撞风险和严重程度的鲁棒方法，证明了ADS相对于人类驾驶员具有显著降低碰撞风险的潜力。

> **ai_Abstract:** 该论文提出了一个“分数碰撞”框架，利用基于ADS传感器数据的反事实模拟来估计碰撞风险和严重程度。它通过建模概率性人类行为并计算潜在损害来评估双代理冲突。该方法通过真实世界数据进行验证，能够准确预测碰撞，并表明自动驾驶系统（ADS）与人类驾驶员相比可以显著降低碰撞风险和严重程度，在很大比例的冲突中改善了风险。

> **摘要翻译:** 我们提出了一种方法，用于根据自动驾驶系统（ADS）传感器数据或自然驾驶数据库构建的反事实模拟场景来估计碰撞风险。通过检测和分类冲突类型、识别代理的角色（发起者或响应者）、识别响应者的反应点，并将他们的人类行为预期建模为概率反事实轨迹来评估双代理冲突。这些状态用于计算碰撞时的速度差，结合碰撞模型，可以估计损失的严重程度，以概率性伤害或财产损失的形式，此后称为分数碰撞。概率模型还可以扩展，以包括与模拟、特征和代理相关的其他不确定性。我们在合成模拟环境中验证了该方法的有效性，使用了来自VTTI的SHRP2数据库和Nexar行车记录仪数据的300多个碰撞和近碰撞场景的重建轨迹。我们的方法预测的分数碰撞与真实碰撞的误差在1%以内。然后，我们通过将这些合成重建中的自然响应者替换为ADS模拟器，并将结果与人类响应结果进行比较，来评估任意ADS软件版本引起的碰撞风险。我们的ADS将自然碰撞减少了4倍，并将分数碰撞风险降低了约62%。该框架的实用性还在25万英里的专有开放环路传感器数据上得到了验证，这些数据是在ADS测试车辆上收集的，并用任意ADS软件版本进行了重新模拟。ADS引发的冲突导致了0.4次致伤性分数碰撞和1.7次财产损失性分数碰撞，并且ADS在96%的代理引发的冲突中改善了碰撞风险。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [362] [Blending Participatory Design and Artificial Awareness for Trustworthy Autonomous Vehicles](https://arxiv.org/abs/2506.07633)
> *融合参与式设计与人工意识以实现可信赖的自动驾驶汽车*

*Ana Tanevska, Ananthapathmanabhan Ratheesh Kumar, Arabinda Ghosh, Ernesto Casablanca, Ginevra Castellano, Sadegh Soudjani* | **Main category: cs.RO**

**Keywords:** 自动驾驶汽车, 人机交互, 马尔可夫链模型, 态势感知, 信任

**Comment:** Submitted to IEEE RO-MAN 2025

> **TL;DR:** 本文通过大规模用户研究，创建了一个人类驾驶员的数据驱动马尔可夫链模型，以提升自动驾驶汽车与人类交互的信任和透明度，并发现模型转换受AV透明度、环境和用户人口统计学影响。

**AI_Comments:** 本文的创新之处在于将参与式设计原则应用于自动驾驶汽车的人工意识架构中，特别是通过构建人类驾驶员的数据驱动模型来增强人机信任和透明度。大规模的用户研究为理解自动驾驶汽车透明度与用户行为之间的复杂关系提供了实证基础，而马尔可夫链模型的应用则为预测和适应人类行为提供了量化工具。这对于提升未来自动驾驶系统的安全性、可靠性和用户接受度具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前机器人代理（如自动驾驶汽车和无人机）需要在不确定的真实世界环境中处理态势感知、风险感知、协调和决策。此外，这些代理还需要与人类用户互动，这要求理解如何建模人类以及如何培养代理与人类之间的信任和透明度。

**Method:** 本研究旨在创建一个人类驾驶员的数据驱动模型，并将其整合到态势感知架构中，以实现可信赖的人机交互。为此，研究人员进行了一项大规模的、以用户为中心的人机交互研究，调查了自动驾驶汽车透明度与用户行为之间的关系。研究结果用于构建人类驾驶员的马尔可夫链模型。

**Result:** 研究结果表明，根据自动驾驶汽车的透明度、场景环境和用户的社会人口学特征，模型中的转换（transitions）会呈现显著差异。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在解决自动驾驶汽车与人类用户交互中的信任和透明度问题。文章提出了一种将人类驾驶员数据驱动模型整合到人工意识架构中的方法，以实现可信赖的人机交互。通过一项大规模用户研究，作者调查了自动驾驶汽车透明度对用户行为的影响，并基于收集到的数据构建了人类驾驶员的马尔可夫链模型。研究结果表明，模型中的转换受自动驾驶汽车透明度、环境和用户人口统计学特征的显著影响。

> **摘要翻译:** 当前的机器人代理，如自动驾驶汽车（AVs）和无人机，需要通过适当的态势感知（SA）、风险感知、协调和决策来应对不确定的真实世界环境。SymAware项目致力于通过设计一个用于多智能体系统的人工意识架构来解决这个问题，从而实现自动驾驶汽车和无人机的安全协作。然而，这些代理也需要与人类用户（驾驶员、行人、无人机操作员）互动，这反过来需要理解如何在交互场景中建模人类，以及如何培养代理和人类之间的信任和透明度。
在这项工作中，我们旨在创建一个人类驾驶员的数据驱动模型，并将其整合到我们的态势感知架构中，将我们的研究建立在可信赖人机交互的原则之上。为了收集创建模型所需的数据，我们进行了一项关于人机交互的大规模以用户为中心的研究，其中我们调查了自动驾驶汽车的透明度与用户行为之间的相互作用。
本文的贡献有两方面：首先，我们详细阐述了我们的人机研究及其发现；其次，我们展示了根据研究数据计算得出的人类驾驶员的马尔可夫链模型。我们的结果表明，根据自动驾驶汽车的透明度、场景环境和用户的社会人口学特征，模型中的转换会呈现显著差异。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [366] [Fast ECoT: Efficient Embodied Chain-of-Thought via Thoughts Reuse](https://arxiv.org/abs/2506.07639)
> *快速ECoT：通过思想重用实现高效具身思维链*

*Zhekai Duan, Yuan Zhang, Shikai Geng, Gaowen Liu, Joschka Boedecker, Chris Xiaoxuan Lu* | **Main category: cs.RO**

**Keywords:** 具身思维链, ECoT, 推理加速, 视觉-语言-动作模型, 实时部署

**Comment:** 

> **TL;DR:** Fast ECoT通过重用思想和并行化推理步骤来加速具身思维链（ECoT）的推理速度，从而显著降低延迟并提高实时部署能力，同时保持或提升性能。

**AI_Comments:** Fast ECoT的创新之处在于其无需模型更改或额外训练即可显著加速ECoT推理，这对于现有VLA系统的集成非常有利。通过利用ECoT本身的结构化和重复性，它巧妙地解决了实时部署的瓶颈。这种方法对于提高机器人和具身AI系统的响应速度和实用性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 具身思维链（ECoT）推理虽然能增强视觉-语言-动作（VLA）模型的性能和可解释性，但其顺序自回归令牌生成导致显著的推理延迟，从而限制了其实时部署。

**Method:** Fast ECoT是一种推理时加速方法，它利用ECoT的结构化和重复性，通过以下方式实现：1) 在不同时间步缓存和重用高级推理；2) 并行生成模块化推理步骤。此外，它引入了一个异步调度器，将推理与动作解码解耦，进一步提高了响应速度。

**Result:** 在模拟（LIBERO）和真实世界机器人任务中，Fast ECoT将延迟降低了高达7.5%，同时任务成功率和推理忠实度保持相当或有所提高。

**Conclusion:** Fast ECoT通过显著降低推理延迟，使ECoT策略更接近实际的实时部署，且无需模型更改或额外训练，易于集成到现有VLA管线中。

> **ai_Abstract:** 该论文提出了Fast ECoT，一种用于加速具身思维链（ECoT）推理的方法，旨在解决ECoT的顺序生成导致的实时部署延迟问题。Fast ECoT通过缓存和重用高级推理、并行化推理步骤以及引入异步调度器来解耦推理与动作解码。该方法无需模型修改或额外训练，并能轻松集成。实验结果表明，在模拟和真实机器人任务中，Fast ECoT将延迟降低了高达7.5%，同时保持或提高了任务成功率和推理忠实度，从而使ECoT策略更适用于实际实时应用。

> **摘要翻译:** 具身思维链（ECoT）推理通过中间推理步骤增强视觉-语言-动作（VLA）模型，从而提高性能和可解释性。然而，其顺序自回归令牌生成引入了显著的推理延迟，限制了实时部署。我们提出了快速ECoT，这是一种推理时加速方法，它利用ECoT的结构化和重复性来（1）在时间步之间缓存和重用高级推理，以及（2）并行生成模块化推理步骤。此外，我们引入了一个异步调度器，将推理与动作解码解耦，进一步提高了响应能力。快速ECoT无需模型更改或额外训练，并且易于集成到现有的VLA管线中。在模拟（LIBERO）和真实世界机器人任务中的实验表明，延迟降低了高达7.5%，同时任务成功率和推理忠实度相当或有所提高，使ECoT策略更接近实际的实时部署。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [371] [A Communication-Latency-Aware Co-Simulation Platform for Safety and Comfort Evaluation of Cloud-Controlled ICVs](https://arxiv.org/abs/2506.07696)
> *一种考虑通信延迟的云控智能网联汽车安全与舒适性评估协同仿真平台*

*Yongqi Zhao, Xinrui Zhang, Tomislav Mihalj, Martin Schabauer, Luis Putzer, Erik Reichmann-Blaga, Ádám Boronyák, András Rövid, Gábor Soós, Peizhi Zhang, Lu Xiong, Jia Hu, Arno Eichberger* | **Main category: cs.RO**

**Keywords:** 云控智能网联汽车, 协同仿真, 通信延迟, 安全性, 舒适性

**Comment:** 11 pages, 8 figures

> **TL;DR:** 本文提出了一种考虑通信延迟的协同仿真平台，用于评估云控智能网联汽车在真实V2C延迟条件下的安全性和舒适性，并验证了其有效性。

**AI_Comments:** 该论文提出了一种创新的协同仿真平台，通过集成车辆动力学仿真（CarMaker）和交通流仿真（Vissim），并引入了基于真实5G测量数据的通信延迟模型以及主动冲突模块，有效地解决了云控ICV在真实通信延迟环境下进行安全性和舒适性评估的挑战。其创新点在于将实际通信延迟数据融入仿真环境，并设计了能够生成关键场景的模块，这对于提高ICV测试的真实性和有效性具有重要意义。该平台为未来云控ICV的研发和测试提供了有力的工具。

<details>
  <summary>Details</summary>

**Motivation:** 测试云控智能网联汽车需要能够忠实模拟车辆行为和真实通信延迟的仿真环境。

**Method:** 本文提出了一种集成CarMaker和Vissim的通信延迟感知协同仿真平台。该平台结合了从中国和匈牙利5G实测数据中提取并使用Gamma分布统计建模的两种通信延迟模型。此外，还提出了一个主动冲突模块（PCM）来动态控制背景车辆并生成安全关键场景。该平台通过在六种测试条件（两种PCM模式和三种延迟条件）下对一个示例系统进行实验验证，并使用碰撞率、车头时距、冲突后通过时间以及纵向加速度的频谱特性等指标评估安全性和舒适性。

**Result:** 实验结果表明，主动冲突模块（PCM）能够有效提高驾驶环境的危险性，而车云（V2C）通信延迟主要影响乘坐舒适性。

**Conclusion:** 研究结果证实了该平台在不同测试条件下系统评估云控智能网联汽车的有效性。

> **ai_Abstract:** 本文提出并验证了一个考虑通信延迟的协同仿真平台，该平台整合了CarMaker和Vissim，旨在评估云控智能网联汽车在真实车云通信延迟下的安全性和舒适性。平台引入了基于5G实测数据的通信延迟模型和用于生成安全关键场景的主动冲突模块（PCM）。实验结果表明，PCM能有效增加测试场景的危险性，而V2C延迟主要影响乘坐舒适性，从而证明了该平台在多样化测试条件下评估云控ICV的有效性。

> **摘要翻译:** 测试云控智能网联汽车（ICVs）需要能够忠实模拟车辆行为和真实通信延迟的仿真环境。本文提出了一种通信延迟感知的协同仿真平台，该平台集成了CarMaker和Vissim，用于评估真实车云（V2C）延迟条件下的安全性和舒适性。平台中整合了两种通信延迟模型，这些模型来源于中国和匈牙利的5G实测数据，并使用伽马分布进行了统计建模。本文提出了一个主动冲突模块（PCM），用于动态控制背景车辆并生成安全关键场景。该平台通过对一个示例测试系统（SUT）在六种测试条件（结合两种PCM模式：启用/禁用和三种延迟条件：无、中国、匈牙牙）下进行实验验证。安全性和舒适性通过碰撞率、车头时距、冲突后通过时间以及纵向加速度的频谱特性等指标进行评估。结果表明，PCM有效提高了驾驶环境的危险性，而V2C延迟主要影响乘坐舒适性。这些发现证实了该平台在不同测试条件下系统评估云控智能网联汽车的有效性。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [376] [SMaRCSim: Maritime Robotics Simulation Modules](https://arxiv.org/abs/2506.07781)
> *SMaRCSim: 海洋机器人仿真模块*

*Mart Kartašev, David Dörner, Özer Özkahraman, Petter Ögren, Ivan Stenius, John Folkesson* | **Main category: cs.RO**

**Keywords:** 海洋机器人, 仿真, 水下车辆, 自主系统, SMaRCSim

**Comment:** 

> **TL;DR:** 本文介绍了SMaRCSim，一套用于水下机器人开发和测试的仿真模块，旨在解决现有工具的不足。

**AI_Comments:** 该论文提出了一套针对水下机器人开发特定挑战的仿真工具。其创新性在于解决了现有工具在机器学习方法开发、多异构自主车辆团队仿真以及与实际任务规划集成方面的空白，这对于加速水下机器人技术的进步至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 开发水下机器人的新功能并在现实世界中进行测试既耗时又耗费资源。尽管仿真环境有帮助，但现有工具缺乏对基于学习的方法开发、自主水下/水面/空中车辆团队创建以及与任务规划集成的支持。

**Method:** 作者开发了SMaRCSim，一套仿真软件包，以解决现有水下机器人开发和测试中遇到的问题。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了SMaRCSim，一套为海洋机器人开发设计的仿真模块。鉴于水下机器人功能开发和测试的挑战，以及现有仿真工具在支持基于学习的方法、多类型自主车辆团队协作以及与任务规划集成方面的不足，SMaRCSim旨在提供一个全面的解决方案，以促进水下领域新功能的快速开发和测试。

> **摘要翻译:** 开发水下机器人的新功能并在现实世界中进行测试既耗时又耗费资源。仿真环境允许在现场部署之前进行快速测试。然而，现有工具在我们的项目用例中缺乏某些功能：i) 开发水下车辆的基于学习的方法；ii) 创建自主水下、水面和空中车辆团队；iii) 将仿真与现场实验的任务规划相结合。解决这些问题的整体解决方案为将新颖功能引入水下领域提供了巨大潜力。在本文中，我们介绍了SMaRCSim，一套我们开发的仿真软件包，旨在帮助我们解决这些问题。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [381] [Primal-Dual iLQR for GPU-Accelerated Learning and Control in Legged Robots](https://arxiv.org/abs/2506.07823)
> *欠驱动iLQR用于足式机器人的GPU加速学习与控制*

*Lorenzo Amatucci, João Sousa-Pinto, Giulio Turrisi, Dominique Orban, Victor Barasuol, Claudio Semini* | **Main category: cs.RO**

**Keywords:** 足式机器人, 模型预测控制, GPU并行化, 原始-对偶iLQR, 实时控制

**Comment:** 

> **TL;DR:** 本文提出一种新颖的GPU加速的足式机器人模型预测控制（MPC）实现，显著提升了计算效率并支持多机器人控制和MPC在环学习。

**AI_Comments:** 这篇论文的创新点在于将原始-对偶iLQR算法与GPU并行化技术结合，特别是通过并行关联扫描解决KKT系统，从而极大地提升了模型预测控制的计算效率和可扩展性。这对于足式机器人等需要高频率实时控制的领域至关重要。其在多机器人控制和MPC在环学习方面的潜力也预示着广阔的应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有MPC实现可能在计算效率上不足以满足足式机器人实时控制的需求，尤其是在处理复杂动力学和长预测周期时。

**Method:** 本文引入了一种新颖的MPC实现，通过GPU并行化，并结合并行关联扫描来解决原始-对偶Karush-Kuhn-Tucker（KKT）系统，从而实现时间并行化和状态空间并行化。该方法将最优控制问题的复杂度从$\mathcal{O}(N(n + m)^3)$ 降低到 $\mathcal{O}(n\log{N} + m)$。

**Result:** 与现有最先进的求解器（acados和crocoddyl）相比，该实现使全身动力学（WB）-MPC的运行时提升高达60%，单刚体动力学（SRBD）-MPC提升高达700%。所提出的公式能有效扩展，支持最多16个足式机器人的集中式控制器，计算时间少于25毫秒。JAX实现还支持大规模多环境并行化，允许直接在GPU上进行MPC在环学习。

**Conclusion:** 该GPU加速的原始-对偶iLQR MPC实现显著提升了足式机器人控制的计算效率和可扩展性，为实时控制和基于MPC的学习提供了高效途径。

> **ai_Abstract:** 本文提出了一种基于GPU并行化的新型足式机器人模型预测控制（MPC）实现。通过并行关联扫描解决原始-对偶KKT系统，将最优控制问题复杂度显著降低。实验表明，该方法在运行时效率上远超现有求解器，并能有效扩展支持多机器人集中控制和MPC在环学习，为足式机器人的实时控制和学习提供了高效解决方案。

> **摘要翻译:** 本文介绍了一种新颖的模型预测控制（MPC）实现，用于足式机器人运动，该实现利用了GPU并行化。我们的方法通过引入并行关联扫描来解决原始-对偶Karush-Kuhn-Tucker（KKT）系统，从而实现了时间并行化和状态空间并行化。通过这种方式，最优控制问题的复杂度从 $\mathcal{O}(N(n + m)^3)$ 降低到 $\mathcal{O}(n\log{N} + m)$，其中 $n$、$m$ 和 $N$ 分别是系统状态的维度、控制向量的维度和预测范围的长度。我们展示了这种实现相对于两种最先进的求解器（acados和crocoddyl）的优势，在改变预测范围长度时，对于全身动力学（WB）-MPC，运行时性能提升高达60%，对于单刚体动力学（SRBD）-MPC，提升高达700%。所提出的公式也能有效地随问题状态维度扩展，使得最多16个足式机器人的集中式控制器可以在不到25毫秒内计算。此外，得益于JAX的实现，该求解器支持跨多个环境的大规模并行化，从而可以在GPU上直接进行MPC在环学习。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [386] [Versatile Loco-Manipulation through Flexible Interlimb Coordination](https://arxiv.org/abs/2506.07876)
> *通过灵活的肢体协调实现多功能运动-操作*

*Xinghao Zhu, Yuxin Chen, Lingfeng Sun, Farzad Niroui, Simon Le CleacH, Jiuguang Wang, Kuan Fang* | **Main category: cs.RO**

**Keywords:** 运动-操作, 强化学习, 肢体协调, 机器人, 自适应控制器

**Comment:** 

> **TL;DR:** ReLIC是一种基于强化学习的方法，通过自适应控制器和动态肢体分配，实现机器人灵活的运动-操作，并在真实世界任务中表现出高成功率。

**AI_Comments:** ReLIC的创新之处在于其自适应控制器和动态肢体分配机制，这使得机器人能够灵活地在运动和操作之间切换，并克服了传统方法对特定任务或配置的限制。其在真实世界任务中的高成功率证明了其实用性和重要性，为自主机器人在复杂非结构化环境中的应用提供了新的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 自主机器人在非结构化环境中操作需要灵活利用肢体进行运动-操作，但现有工作常受限于特定任务或预设肢体配置。

**Method:** 本文提出了基于肢体间协调的强化学习（ReLIC）方法。其核心是一个自适应控制器，根据任务需求无缝连接操作动作和稳定步态的执行。通过两个控制器模块的相互作用，ReLIC动态地为每个肢体分配操作或运动任务，并鲁棒地协调它们以实现任务成功。该方法在模拟中通过高效强化学习来学习稳定步态以适应操作目标，并通过接口与目标轨迹、接触点和自然语言指令等不同类型的任务规范进行交互。

**Result:** ReLIC在需要多样和复杂协调模式的12项真实世界任务中进行了评估，平均成功率达到78.9%，展示了其多功能性和鲁棒性。

**Conclusion:** ReLIC通过灵活的肢体协调实现了多功能运动-操作，并在真实世界任务中表现出强大的性能和适应性，克服了以往方法在特定任务或预设配置上的限制。

> **ai_Abstract:** 本文提出了一种名为ReLIC（基于肢体间协调的强化学习）的新方法，旨在实现机器人灵活的运动-操作能力。ReLIC通过一个自适应控制器，能够根据任务需求动态地协调机器人的肢体进行操作或运动。该方法利用强化学习在模拟中进行训练，并能与多种任务规范（如目标轨迹、接触点、自然语言指令）进行交互。在12项真实的复杂协调任务中，ReLIC平均实现了78.9%的成功率，证明了其在非结构化环境中进行多功能运动-操作的有效性和鲁棒性。

> **摘要翻译:** 自主机器人在非结构化环境中操作，灵活利用肢体进行运动-操作至关重要。然而，以往的运动-操作工作通常受限于特定任务或预设的肢体配置。在这项工作中，我们提出了基于肢体间协调的强化学习（ReLIC）方法，通过灵活的肢体协调实现多功能运动-操作。我们方法的关键是一个自适应控制器，它根据任务需求无缝连接操作动作的执行和稳定步态的生成。通过两个控制器模块的相互作用，ReLIC动态地为每个肢体分配操作或运动任务，并鲁棒地协调它们以实现任务成功。通过模拟中的高效强化学习，ReLIC学会了根据真实世界中的操作目标执行稳定步态。为了解决多样且复杂的任务，我们进一步提出将学习到的控制器与不同类型的任务规范（包括目标轨迹、接触点和自然语言指令）进行接口。在需要多样和复杂协调模式的12项真实世界任务中进行评估，ReLIC平均成功率达到78.9%，展示了其多功能性和鲁棒性。视频和代码可在https://relic-locoman.github.io/找到。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [392] [Design and Implementation of a Peer-to-Peer Communication, Modular and Decentral YellowCube UUV](https://arxiv.org/abs/2506.07924)
> *点对点通信、模块化和去中心化YellowCube UUV的设计与实现*

*Zhizun Xu, Baozhu Jia, Weichao Shi* | **Main category: cs.RO**

**Keywords:** UUV, 模块化, 去中心化, 点对点通信, YellowCube

**Comment:** 

> **TL;DR:** 本文介绍了一种名为YellowCube的模块化、去中心化UUV，它采用点对点（P2P）通信机制，解决了现有UUV传感器集成困难的问题。

**AI_Comments:** 该论文的创新点在于为模块化UUV引入了点对点（P2P）通信机制，这与传统的集中式架构形成对比。这种方法有望提高UUV系统的鲁棒性、灵活性和传感器集成能力，对于海洋工程和研究领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大多数水下无人航行器（UUV）难以集成新的或升级的传感器，这限制了它们适应不同任务的能力。因此，需要一个模块化UUV系统，能够轻松更换有效载荷部分以携带不同传感器。

**Method:** 本文设计并实现了一种名为YellowCube的模块化和去中心化UUV。与传统模块化水下航行器采用的集中式软件架构不同，YellowCube在其UUV模块之间实现了点对点（P2P）通信机制。

**Result:** 已在实验室和海上试验中进行了实验，以验证该UUV的性能。

**Conclusion:** 本文成功设计并实现了一种采用点对点通信机制的模块化、去中心化UUV (YellowCube)，并通过实验验证了其性能，解决了现有UUV传感器集成的问题。

> **ai_Abstract:** 本文提出并实现了一种名为YellowCube的新型模块化去中心化水下无人航行器（UUV），旨在解决现有UUV在集成新传感器方面的挑战。与传统模块化UUV采用集中式软件架构不同，YellowCube在其模块之间引入了点对点（P2P）通信机制，从而增强了系统的灵活性和适应性。该UUV的性能已通过实验室实验和海上试验得到验证。

> **摘要翻译:** 水下无人航行器（UUV）是海洋工程和海洋研究的关键工具。大多数现有UUV不便于新传感器或升级传感器的轻松集成。解决这个问题的一个方法是拥有一个模块化的UUV系统，该系统具有可更换的有效载荷部分，能够携带不同的传感器以适应不同的任务。本文介绍了名为YellowCube的模块化和去中心化UUV的设计与实现。与其他模块化水下航行器设计所采用的集中式软件架构不同，该UUV的模块之间实现了点对点（P2P）通信机制。已经在实验室和海上试验中进行了实验，以验证UUV的性能。

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

### [397] [BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models](https://arxiv.org/abs/2506.07961)
> *BridgeVLA：面向高效3D操作学习的视觉-语言模型输入-输出对齐*

*Peiyan Li, Yixiang Chen, Hongtao Wu, Xiao Ma, Xiangnan Wu, Yan Huang, Liang Wang, Tao Kong, Tieniu Tan* | **Main category: cs.RO**

**Keywords:** 3D操作, 视觉-语言模型, 输入-输出对齐, 样本效率, 机器人学习

**Comment:** In Submission

> **TL;DR:** BridgeVLA通过创新的输入-输出对齐方法，显著提高了机器人3D操作学习的样本效率和成功率。

**AI_Comments:** BridgeVLA的创新之处在于其独特的输入-输出对齐策略，通过将3D数据有效转换为2D表示，使其能够充分利用现有VLMs的强大能力，同时解决了3D空间结构利用不足的问题。其预训练方法也增强了模型的通用性。卓越的样本效率是其重要亮点，对于实际机器人部署具有巨大潜力，因为它大大减少了数据收集的需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有将3D信号整合到视觉-语言模型（VLMs）中进行动作预测的方法未能充分利用3D数据的空间结构，导致样本效率低下。

**Method:** BridgeVLA是一种新颖的3D视觉-语言-动作（VLA）模型，它通过以下方式实现：1) 将3D输入投影到多个2D图像，确保与VLM骨干的输入对齐。2) 利用2D热图进行动作预测，统一输入和输出空间到一致的2D图像空间。3) 提出可扩展的预训练方法，使VLM骨干在下游策略学习前具备预测2D热图的能力。

**Result:** BridgeVLA在三个模拟基准测试中均优于最先进的基线方法：在RLBench中，平均成功率从81.4%提高到88.2%；在COLOSSEUM中，在挑战性泛化设置下，平均成功率从56.7%提升至64.0%；在GemBench中，超越所有比较的基线方法。在真实机器人实验中，平均性能优于最先进基线方法32%，并在多种分布外设置中展现鲁棒泛化能力。在10+任务上，仅需每任务3条轨迹即可达到96.8%的成功率，展现出非凡的样本效率。

**Conclusion:** BridgeVLA能够高效且有效地学习3D操作，并在多个模拟和真实机器人基准测试中优于现有方法，展现出卓越的样本效率和泛化能力。

> **ai_Abstract:** 本文提出了BridgeVLA，一个新颖的3D视觉-语言-动作模型，旨在解决现有方法在机器人3D操作学习中3D数据利用不足和样本效率低下的问题。BridgeVLA通过将3D输入转换为2D图像并使用2D热图进行动作预测，实现了与视觉-语言模型骨干的输入-输出对齐。此外，它引入了一种可扩展的预训练方法。实验证明，BridgeVLA在模拟和真实机器人任务中均显著提高了学习效率和成功率，尤其在样本效率和泛化能力方面表现出色。

> **摘要翻译:** BridgeVLA：面向高效3D操作学习的视觉-语言模型输入-输出对齐

近年来，利用预训练视觉-语言模型（VLMs）构建视觉-语言-动作（VLA）模型已成为有效机器人操作学习的一种有前景的方法。然而，很少有方法将3D信号整合到VLM中进行动作预测，并且它们未能充分利用3D数据固有的空间结构，导致样本效率低下。在本文中，我们引入了BridgeVLA，这是一种新颖的3D VLA模型，它（1）将3D输入投影到多个2D图像，确保与VLM骨干的输入对齐，以及（2）利用2D热图进行动作预测，统一输入和输出空间到一致的2D图像空间。此外，我们提出了一种可扩展的预训练方法，使VLM骨干在下游策略学习之前具备预测2D热图的能力。广泛的实验表明，所提出的方法能够高效且有效地学习3D操作。BridgeVLA在三个模拟基准测试中均优于最先进的基线方法。在RLBench中，它将平均成功率从81.4%提高到88.2%。在COLOSSEUM中，它在具有挑战性的泛化设置中表现出显著更好的性能，将平均成功率从56.7%提高到64.0%。在GemBench中，它在平均成功率方面超越了所有比较的基线方法。在真实机器人实验中，BridgeVLA平均优于一种最先进的基线方法32%。它在多种分布外设置（包括视觉干扰和未见过指令）中稳健泛化。值得注意的是，它能够在10多个任务上仅用每任务3条轨迹就达到96.8%的成功率，突显了其非凡的样本效率。项目网站：https://bridgevla.github.io/

</details>

[⬆️ 返回分类顶部](#csro) | [⬆️ 返回总目录](#toc)

---

<a id='cscv'></a>
## cs.CV 

### [12] [Facial Foundational Model Advances Early Warning of Coronary Artery Disease from Live Videos with DigitalShadow](https://arxiv.org/abs/2506.06283)
> *面部基础模型利用DigitalShadow从实时视频中推进冠状动脉疾病的早期预警*

*Juexiao Zhou, Zhongyi Han, Mankun Xin, Xingwei He, Guotao Wang, Jiaoyan Song, Gongning Luo, Wenjia He, Xintong Li, Yuetan Chu, Juanwen Chen, Bo Wang, Xia Wu, Wenwen Duan, Zhixia Guo, Liyan Bai, Yilin Pan, Xuefei Bi, Lu Liu, Long Feng, Xiaonan He, Xin Gao* | **Main category: cs.CV**

**Keywords:** 冠状动脉疾病, 早期预警, 面部基础模型, 实时视频, DigitalShadow

**Comment:** 

> **TL;DR:** DigitalShadow是一个基于面部基础模型的早期预警系统，能从实时视频中非接触式地检测冠状动脉疾病风险，并提供个性化健康建议，同时注重隐私。

**AI_Comments:** 这项工作具有重要的创新性和实用性。它利用了前沿的面部基础模型技术，将非接触式视频分析应用于疾病早期预警，这在医疗健康领域是一个非常有前景的方向。其被动、非接触式的特点极大地提高了用户依从性，而对隐私的强调（支持本地部署）则解决了当前医疗数据应用中的一大痛点。如果该系统的准确性和可靠性得到充分验证，将对CAD的早期筛查和预防产生深远影响。然而，抽象中未提及模型的具体性能指标，这是未来评估其实际应用价值的关键。

<details>
  <summary>Details</summary>

**Motivation:** 全球人口老龄化给医疗系统带来挑战，冠状动脉疾病（CAD）是全球主要死亡原因，每年导致约1780万人死亡。CAD在很大程度上是可预防的，因此早期检测和主动管理至关重要。

**Method:** 本研究引入了DigitalShadow，一个由微调的面部基础模型驱动的先进CAD早期预警系统。该系统首先在2100万张面部图像上进行预训练，然后在中国四家医院的1751名受试者的7004张面部图像上微调成LiveCAD，一个专门的CAD风险评估模型。DigitalShadow被设计为被动、非接触式运行，从实时视频流中提取面部特征，无需用户主动参与。它与个性化数据库集成，生成自然语言风险报告和个性化健康建议，并支持本地部署以确保数据隐私。

**Result:** DigitalShadow系统能够从实时视频中提取面部特征，评估冠状动脉疾病风险，并生成自然语言风险报告和个性化健康建议。它提供了一种非接触式、注重隐私的早期预警方式。

**Conclusion:** DigitalShadow系统利用面部基础模型，提供了一种创新、非接触式且注重隐私的冠状动脉疾病早期预警解决方案，有助于解决全球健康挑战。

> **ai_Abstract:** 本论文介绍了一个名为DigitalShadow的先进冠状动脉疾病（CAD）早期预警系统。该系统利用一个在海量面部图像上预训练并针对CAD风险评估进行微调的面部基础模型（LiveCAD），能够从实时视频流中非接触式地提取面部特征，并结合个性化数据库生成自然语言风险报告和个性化健康建议。DigitalShadow强调隐私保护，支持本地部署，旨在为全球日益增长的CAD问题提供早期检测和管理方案。

> **摘要翻译:** 全球人口老龄化给医疗系统带来日益严峻的挑战，冠状动脉疾病（CAD）每年导致约1780万人死亡，是全球主要的死亡原因。由于CAD在很大程度上是可预防的，因此早期检测和主动管理至关重要。在这项工作中，我们介绍了DigitalShadow，一个由微调的面部基础模型驱动的先进CAD早期预警系统。该系统在2100万张面部图像上进行预训练，随后在中国四家医院的1751名受试者的7004张面部图像上微调成LiveCAD，一个专门的CAD风险评估模型。DigitalShadow被设计为被动、非接触式运行，从实时视频流中提取面部特征，无需用户主动参与。它与个性化数据库集成，生成自然语言风险报告和个性化健康建议。DigitalShadow以隐私为核心设计原则，支持本地部署以确保用户数据的安全处理。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [26] [Exploring Adversarial Watermarking in Transformer-Based Models: Transferability and Robustness Against Defense Mechanism for Medical Images](https://arxiv.org/abs/2506.06389)
> *探索基于Transformer模型中的对抗性水印：医疗图像的迁移性和对抗防御机制的鲁棒性*

*Rifat Sadik, Tanvir Rahman, Arpan Bhattacharjee, Bikash Chandra Halder, Ismail Hossain* | **Main category: cs.CV**

**Keywords:** 对抗性水印, Vision Transformers, 医疗图像, 对抗训练, 鲁棒性

**Comment:** 

> **TL;DR:** 本文研究了Vision Transformers（ViTs）在医疗图像上对对抗性水印的脆弱性，发现ViTs易受攻击，但对抗训练能有效提高其鲁棒性。

**AI_Comments:** 这篇论文在医疗AI安全领域具有重要意义，因为它揭示了Vision Transformers在医疗图像分析中对抗性攻击的潜在漏洞。研究不仅证实了ViTs的脆弱性，还提出了对抗训练作为一种有效的防御策略，这对于确保医疗诊断系统的可靠性和安全性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习模型，特别是Vision Transformers (ViTs)，在医学图像分析中表现出色，但其对全局注意力机制的依赖使其容易受到对抗性扰动。因此，本文旨在探究ViTs在医疗图像上对对抗性水印的脆弱性。

**Method:** 通过使用投影梯度下降（PGD）生成对抗性水印，研究了此类攻击对卷积神经网络（CNNs）的迁移性，并分析了防御机制——对抗训练的性能。

**Result:** 结果显示，对于干净图像，模型性能没有受到损害，但ViTs对对抗性攻击变得更加脆弱，准确率最低降至27.6%。然而，对抗训练将其提高到90.0%。

**Conclusion:** 尽管Vision Transformers在医疗图像分析中表现出色，但它们对对抗性水印攻击高度敏感。幸运的是，对抗训练可以显著提高ViTs的鲁棒性，使其能够抵御此类攻击。

> **ai_Abstract:** 本文探讨了Vision Transformers (ViTs) 在医疗图像处理中对抗性水印攻击的脆弱性。研究通过投影梯度下降（PGD）生成对抗性水印，并评估了攻击对CNN的迁移性以及对抗训练作为防御机制的效果。结果表明，ViTs在对抗性攻击下准确率显著下降，但对抗训练能有效提升其鲁棒性，将其准确率恢复到较高水平。

> **摘要翻译:** 深度学习模型在皮肤病图像分析中取得了显著成功，为自动化皮肤疾病诊断提供了潜力。此前，基于卷积神经网络（CNN）的架构在计算机视觉（CV）任务，如皮肤图像识别、生成和视频分析中，获得了巨大的普及和成功。但随着基于Transformer模型的出现，当前的CV任务正在使用这些模型进行。Vision Transformers（ViTs）就是这样一种在计算机视觉中取得成功的基于Transformer的模型。它使用自注意力机制在各种任务中实现最先进的性能。然而，它们对全局注意力机制的依赖使其容易受到对抗性扰动。本文旨在调查ViTs在医疗图像上对抗性水印的脆弱性——一种添加所谓“难以察觉的扰动”以欺骗模型的方法。通过投影梯度下降（PGD）生成对抗性水印，我们检查了此类攻击对CNN的迁移性，并分析了防御机制——对抗训练的性能。结果表明，虽然对干净图像的性能没有受到影响，但ViTs确实对对抗性攻击变得更加脆弱：准确率最低降至27.6%。然而，对抗训练将其提高到90.0%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [40] [(LiFT) Lightweight Fitness Transformer: A language-vision model for Remote Monitoring of Physical Training](https://arxiv.org/abs/2506.06480)
> *（LiFT）轻量级健身Transformer：一种用于远程监控体能训练的语言-视觉模型*

*A. Postlmayr, P. Cosman, S. Dey* | **Main category: cs.CV**

**Keywords:** 健身追踪, 远程监控, 语言-视觉模型, Transformer, 运动检测

**Comment:** 

> **TL;DR:** LiFT是一个轻量级语言-视觉模型，仅使用RGB智能手机摄像头即可远程监控数百种运动，解决了现有健身追踪系统在运动种类和部署复杂性方面的局限性。

**AI_Comments:** 该论文的创新点在于提出了一个轻量级的视觉-语言Transformer模型LiFT，并构建了迄今为止最大规模的健身数据集Olympia，极大地扩展了可追踪的运动种类。其重要性在于通过仅使用智能手机RGB摄像头，降低了远程健身监控的成本和复杂性，使其更具可访问性和隐私性。该方法的多任务能力和对大量运动的泛化能力是其显著优势，有望推动AI健身追踪的民主化。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自动化运动监督模型在运动种类上过于有限，或者对于实际部署来说过于复杂，无法泛化到多样化的动作。先前的方案通常只关注少数运动，且无法在多种动作中实现泛化。

**Method:** 研究人员开发了一个名为LiFT的鲁棒多任务运动分析模型，能够对数百种运动进行运动检测和重复计数。通过构建一个名为Olympia的大规模健身数据集（包含超过1900种运动），克服了先前的数据限制。该模型是第一个能对骨骼健身数据执行多任务的视觉-语言模型。

**Result:** 在Olympia数据集上，该模型使用RGB视频进行运动检测的准确率为76.5%，重复计数的一差准确率为85.3%。

**Conclusion:** 通过提出一个单一的视觉-语言Transformer模型，同时实现运动识别和重复计数，该研究在普及AI驱动的健身追踪方面迈出了重要一步。

> **ai_Abstract:** 本文介绍了一种名为LiFT（轻量级健身Transformer）的语言-视觉模型，旨在通过RGB智能手机摄像头实现远程体能训练监控。针对现有健身追踪系统运动种类有限和部署复杂的问题，LiFT开发了一个鲁棒的多任务模型，结合了大规模的Olympia数据集（包含1900多种运动），能够对数百种运动进行检测和重复计数。该模型在运动检测和重复计数方面取得了高准确率，并被认为是首个能对骨骼健身数据执行多任务的视觉-语言模型，为普及AI健身追踪迈出了重要一步。

> **摘要翻译:** 我们引入了一种健身追踪系统，该系统仅使用RGB智能手机摄像头即可实现运动的远程监控，从而使健身追踪更加私密、可扩展且经济高效。尽管先前的工作探索了自动化运动监督，但现有模型要么在运动种类上过于有限，要么对于实际部署来说过于复杂。先前的方案通常只关注少数运动，并且无法泛化到多样化的动作。相比之下，我们开发了一个鲁棒的多任务运动分析模型，能够对数百种运动进行运动检测和重复计数，其规模远远超过了以前的方法。我们通过组建一个名为Olympia的大规模健身数据集（涵盖1900多种运动）来克服先前的数据限制。据我们所知，我们的视觉-语言模型是第一个可以在骨骼健身数据上执行多任务的模型。在Olympia上，我们的模型仅使用RGB视频即可实现76.5%的运动检测准确率和85.3%的一差重复计数准确率。通过提出一个单一的视觉-语言Transformer模型，同时用于运动识别和重复计数，我们在普及AI驱动的健身追踪方面迈出了重要一步。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [55] [GS4: Generalizable Sparse Splatting Semantic SLAM](https://arxiv.org/abs/2506.06517)
> *GS4：可泛化的稀疏溅射语义SLAM*

*Mingqi Jiang, Chanho Kim, Chen Ziwen, Li Fuxin* | **Main category: cs.CV**

**Keywords:** 语义SLAM, 高斯溅射, 泛化能力, 3D重建, 实时定位与地图构建

**Comment:** 13 pages, 6 figures

> **TL;DR:** 提出了首个可泛化的基于高斯溅射的语义SLAM算法GS4，它通过学习网络增量构建3D场景，实现了最先进的性能和良好的泛化能力，且高斯数量远少于现有方法。

**AI_Comments:** 这篇论文通过引入“可泛化”的概念，显著提升了高斯溅射在SLAM领域的实用性，解决了现有方法对逐场景优化的依赖。其创新点在于结合了学习型网络预测高斯参数和高效的单次迭代优化策略，同时实现了3D语义分割。在减少高斯数量的同时达到SOTA性能和出色的泛化能力，是该工作的重要贡献，有望推动实时、高精度3D语义SLAM的应用。

<details>
  <summary>Details</summary>

**Motivation:** 传统SLAM算法生成的3D地图分辨率低且不完整。现有基于高斯溅射（GS）的SLAM方法依赖于耗时的逐场景优化，泛化能力差。

**Method:** 引入了GS4，一个基于学习的可泛化网络，从RGB-D视频流增量构建和更新3D场景表示。该方法从RGB-D图像识别骨干网络预测高斯参数，并无缝集成3D语义分割。通过全局定位后仅优化GS一次迭代来纠正定位漂移和浮点。

**Result:** 在ScanNet基准测试上实现了最先进的语义SLAM性能，且高斯数量比其他GS方法少一个数量级。通过零样本迁移在NYUv2和TUM RGB-D数据集上展示了模型的泛化能力。

**Conclusion:** GS4是首个可泛化的基于高斯溅射的语义SLAM算法，解决了现有GS方法在泛化性和效率上的不足，并在多个真实世界数据集上表现出卓越的性能和泛化能力。

> **ai_Abstract:** 本文提出了GS4，一种新颖的、可泛化的基于高斯溅射（GS）的语义SLAM算法。针对传统SLAM地图质量和现有GS-SLAM泛化性差的问题，GS4利用学习到的网络从RGB-D视频流增量构建和更新3D场景，并无缝集成3D语义分割。该方法通过单次迭代优化纠正定位问题，在ScanNet上实现了领先的语义SLAM性能，且显著减少了高斯数量，同时在NYUv2和TUM RGB-D数据集上展现出卓越的零样本泛化能力。

> **摘要翻译:** 传统SLAM算法在相机跟踪方面表现出色，但可能会生成分辨率较低且不完整的3D地图。最近，高斯溅射（GS）方法已成为SLAM的一种选择，可以构建准确、密集的3D地图。然而，现有的基于GS的SLAM方法依赖于逐场景优化，这非常耗时且不能很好地泛化到不同的场景。在这项工作中，我们引入了第一个可泛化的基于GS的语义SLAM算法，该算法使用学习到的可泛化网络从RGB-D视频流增量构建和更新3D场景表示。我们的方法从RGB-D图像识别骨干网络开始，预测每个下采样和反投影图像位置的高斯参数。此外，我们将3D语义分割无缝集成到我们的GS框架中，通过共享骨干网络连接3D映射和识别。为了纠正定位漂移和浮点，我们建议在全局定位后仅对GS进行1次迭代优化。我们在真实世界基准ScanNet上展示了最先进的语义SLAM性能，与最近的其他基于GS的方法相比，高斯数量少了一个数量级，并通过零样本迁移到NYUv2和TUM RGB-D数据集展示了我们模型的泛化能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [70] [Bridging Audio and Vision: Zero-Shot Audiovisual Segmentation by Connecting Pretrained Models](https://arxiv.org/abs/2506.06537)
> *音频与视觉的桥接：通过连接预训练模型实现零样本音视频分割*

*Seung-jae Lee, Paul Hongsuck Seo* | **Main category: cs.CV**

**Keywords:** 零样本学习, 音视频分割, 预训练模型, 多模态集成, 声源定位

**Comment:** Accepted on INTERSPEECH2025

> **TL;DR:** 提出了一种零样本音视频分割框架，通过整合预训练的多模态模型，无需特定标注即可实现SOTA性能。

**AI_Comments:** 这篇论文的创新点在于提出了一个零样本的音视频分割框架，通过巧妙地连接和利用现有的预训练模型，避免了昂贵的像素级标注，这对于实际应用具有重要意义。多模态（音频、视觉、文本）的融合是其成功的关键。

<details>
  <summary>Details</summary>

**Motivation:** 传统的音视频分割方法依赖于耗时且昂贵的大规模像素级标注，阻碍了其应用。

**Method:** 提出了一种新颖的零样本音视频分割框架，通过利用多个预训练模型消除任务特定训练。该方法整合了音频、视觉和文本表示来弥合模态差距，并系统地探索了连接预训练模型的不同策略。

**Result:** 该框架在零样本音视频分割任务上实现了最先进的性能。

**Conclusion:** 多模态模型集成对于细粒度音视频分割是有效的。

> **ai_Abstract:** 本文提出了一种新颖的零样本音视频分割（AVS）框架，旨在解决传统AVS方法对昂贵标注的依赖问题。该框架通过连接和整合音频、视觉和文本等多种预训练模型，实现了无需任务特定训练的精确声源分割。实验证明，该方法在多个数据集上取得了最先进的零样本AVS性能，验证了多模态模型集成在细粒度音视频分割中的有效性。

> **摘要翻译:** 音视频分割（AVS）旨在识别与声源对应的视觉区域，在视频理解、监控和人机交互中发挥着至关重要的作用。传统的AVS方法依赖于大规模像素级标注，获取成本高且耗时。为了解决这个问题，我们提出了一种新颖的零样本AVS框架，通过利用多个预训练模型来消除任务特定训练。我们的方法整合了音频、视觉和文本表示，以弥合模态差距，从而无需AVS特定标注即可实现精确的声源分割。我们系统地探索了连接预训练模型的不同策略，并在多个数据集上评估了它们的功效。实验结果表明，我们的框架实现了最先进的零样本AVS性能，突出了多模态模型集成对于细粒度音视频分割的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [84] [Securing Traffic Sign Recognition Systems in Autonomous Vehicles](https://arxiv.org/abs/2506.06563)
> *保障自动驾驶汽车交通标志识别系统安全*

*Thushari Hapuarachchi, Long Dang, Kaiqi Xiong* | **Main category: cs.CV**

**Keywords:** 深度神经网络, 交通标志识别, 数据投毒攻击, 模型鲁棒性, 数据增强

**Comment:** 

> **TL;DR:** 本文研究了交通标志识别系统中深度神经网络的鲁棒性，通过引入误差最小化攻击来展示数据投毒的危害，并提出了一种基于数据增强的训练方法和一种检测模型来有效缓解和识别此类攻击，显著提高了模型准确率和检测成功率。

**AI_Comments:** 本文创新性地探讨了自动驾驶领域交通标志识别系统中深度学习模型的数据投毒攻击问题，并提出了两类有效对策：一是基于数据增强的防御性训练方法，显著提升了模型在投毒攻击下的鲁棒性；二是中毒数据检测模型，能够准确识别隐蔽性攻击。这项工作对于提升自动驾驶系统在恶意攻击下的安全性具有重要意义，其提出的缓解和检测机制为未来安全AI系统的设计提供了宝贵经验。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）广泛应用于交通标志识别，但其训练数据集通常来源于未知来源，这使得模型在训练过程中面临被篡改或投毒的风险。因此，确保模型安全和鲁棒性至关重要。

**Method:** 首先，通过在训练数据中添加难以察觉的扰动，对用于交通标志识别的DNNs进行误差最小化攻击。其次，提出了一种基于数据增强的训练方法，利用非线性变换来破坏扰动，提高模型鲁棒性以缓解攻击。最后，提出了一种检测模型，即使扰动对人眼不可见，也能识别中毒数据。

**Result:** 误差最小化攻击将DNN的预测准确率从99.90%降低到10.6%。提出的缓解方案成功地将预测准确率恢复到96.05%，并且优于对抗训练。提出的检测模型在识别攻击方面的成功率超过99%。

**Conclusion:** 这项研究强调了在交通标志识别系统中，需要采用先进的DNN训练方法来减轻数据投毒攻击的影响。

> **ai_Abstract:** 本研究关注自动驾驶汽车中交通标志识别系统所使用的深度神经网络的安全性与鲁棒性。鉴于训练数据来源可能不明，论文首先通过实施误差最小化攻击展示了数据投毒的严重性（将准确率从99.90%降至10.6%）。为应对此威胁，作者提出了一种基于数据增强的训练方法，通过非线性变换有效恢复了模型准确率至96.05%，并优于传统对抗训练。此外，还开发了一个能够以超过99%成功率识别中毒数据的检测模型。研究强调了为保障交通标志识别系统的安全，采用先进训练方法以缓解数据投毒攻击的必要性。

> **摘要翻译:** 深度神经网络（DNNs）因其能够自动从图像中提取高级特征而被广泛用于交通标志识别。这些DNNs是在从未知来源获得的大规模数据集上训练的。因此，确保模型在训练过程中保持安全，不被损害或投毒至关重要。在本文中，我们研究了用于交通标志识别的DNNs的鲁棒性。首先，我们通过在训练数据上添加难以察觉的扰动，对用于交通标志识别的DNNs执行误差最小化攻击。然后，我们提出了一种基于数据增强的训练方法来缓解误差最小化攻击。所提出的训练方法利用非线性变换来破坏扰动并提高模型鲁棒性。我们使用两个著名的交通标志数据集进行了实验，以证明攻击的严重性和我们缓解方案的有效性。误差最小化攻击将DNNs的预测准确率从99.90%降低到10.6%。然而，我们的缓解方案成功地将预测准确率恢复到96.05%。此外，我们的方法在缓解误差最小化攻击方面优于对抗训练。此外，我们提出了一种检测模型，即使扰动对人眼不可见，也能够识别中毒数据。我们的检测模型在识别攻击方面的成功率超过99%。这项研究强调了在交通标志识别系统中，需要采用先进的DNN训练方法来减轻数据投毒攻击的影响。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [96] [Prompt to Protection: A Comparative Study of Multimodal LLMs in Construction Hazard Recognition](https://arxiv.org/abs/2506.07436)
> *从提示到防护：多模态大型语言模型在施工危险识别中的比较研究*

*Nishi Chaudhary, S M Jamil Uddin, Sathvik Sharath Chandra, Anto Ovid, Alex Albert* | **Main category: cs.CV**

**Keywords:** 多模态LLMs, 建筑安全, 危险识别, 提示工程, 思维链

**Comment:** 

> **TL;DR:** 本研究比较了多模态大型语言模型（Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3、Gemini 2.0 Pro）在建筑危险识别中的表现，并评估了零样本、少样本和思维链（CoT）等提示策略。结果显示CoT策略显著提高了准确性，且GPT-4.5和GPT-o3在多数情况下表现最优，强调了提示设计的重要性。

**AI_Comments:** 这项研究具有创新性，因为它系统地比较了多种尖端的多模态LLMs在一个关键的实际应用（建筑危险识别）中的表现，这是一个尚未充分探索的领域。其对提示策略的关注尤为重要，表明提示工程是释放这些模型在安全应用中全部潜力的关键。研究结果为研究人员和从业者开发更有效的AI驱动安全系统提供了实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 传统的计算机视觉模型依赖于领域特定训练和大量数据集，而多模态大型语言模型（LLMs）为建筑工地视觉危险识别提供了新机遇。然而，目前对不同LLMs在建筑领域安全关键视觉任务中的表现研究有限，本研究旨在弥补这一空白。

**Method:** 本研究对五种最先进的LLMs（Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3、Gemini 2.0 Pro）进行了比较评估，以测试它们从真实建筑图像中识别潜在危险的能力。每个模型在零样本、少样本和思维链（CoT）三种提示策略下进行测试。通过精确率、召回率和F1分数指标进行定量分析。

**Result:** 提示策略显著影响了性能，其中思维链（CoT）提示在所有模型中始终产生更高的准确性。LLM的性能在不同条件下有所不同，GPT-4.5和GPT-o3在大多数设置中表现优于其他模型。研究结果还表明，提示设计在提高多模态LLMs用于建筑安全应用的准确性和一致性方面发挥着关键作用。

**Conclusion:** 本研究为提示工程和LLMs在实际危险识别中的集成提供了可操作的见解，有助于开发更可靠的AI辅助安全系统。

> **ai_Abstract:** 本研究评估了五种先进的多模态大型语言模型（LLMs），包括Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3和Gemini 2.0 Pro，在建筑危险识别任务中的表现。研究利用真实世界建筑图像，并测试了零样本、少样本和思维链（CoT）三种提示策略。结果显示，CoT提示策略显著提高了模型的识别准确性，且GPT-4.5和GPT-o3在多数情况下表现最优。研究强调了提示设计在提升多模态LLMs在建筑安全应用中准确性和一致性方面的关键作用，为开发更可靠的AI辅助安全系统提供了实用见解。

> **摘要翻译:** 多模态大型语言模型（LLMs）的最新出现为改善建筑工地的视觉危险识别带来了新的机遇。与依赖领域特定训练和大量数据集的传统计算机视觉模型不同，现代LLMs可以使用简单的自然语言提示来解释和描述复杂的视觉场景。然而，尽管人们对其应用越来越感兴趣，但对于不同LLMs在建筑领域安全关键视觉任务中的表现研究有限。为了弥补这一空白，本研究对五种最先进的LLMs进行了比较评估：Claude-3 Opus、GPT-4.5、GPT-4o、GPT-o3和Gemini 2.0 Pro，以评估它们从真实世界建筑图像中识别潜在危险的能力。每个模型在三种提示策略下进行了测试：零样本（zero-shot）、少样本（few-shot）和思维链（CoT）。零样本提示涉及最少的指令，少样本提示结合了基本的安全上下文和危险源助记符，而CoT则提供了分步推理示例以支撑模型思考。在所有条件下，使用精确率、召回率和F1分数指标进行了定量分析。结果表明，提示策略显著影响了性能，CoT提示在所有模型中始终产生更高的准确性。此外，LLM的性能在不同条件下有所不同，其中GPT-4.5和GPT-o3在大多数设置中表现优于其他模型。研究结果还表明，提示设计在提高多模态LLMs用于建筑安全应用的准确性和一致性方面发挥着关键作用。本研究为提示工程和LLMs在实际危险识别中的集成提供了可操作的见解，有助于开发更可靠的AI辅助安全系统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [97] [Textile Analysis for Recycling Automation using Transfer Learning and Zero-Shot Foundation Models](https://arxiv.org/abs/2506.06569)
> *纺织品回收自动化分析：迁移学习与零样本基础模型的应用*

*Yannis Spyridis, Vasileios Argyriou* | **Main category: cs.CV**

**Keywords:** 纺织品回收, 自动化分拣, 迁移学习, 零样本分割, 深度学习

**Comment:** 

> **TL;DR:** 本文利用RGB图像、迁移学习和零样本基础模型，实现了纺织品分类和非纺织特征分割，以支持自动化纺织品回收。

**AI_Comments:** 这项研究通过结合迁移学习和零样本基础模型，为自动化纺织品回收提供了一种创新且经济高效的解决方案。特别是利用RGB图像进行复杂分析，以及零样本分割的应用，展示了其在实际工业应用中的巨大潜力，有助于提高回收效率并减少环境污染。

<details>
  <summary>Details</summary>

**Motivation:** 自动化分拣对于提高纺织品回收的效率和可扩展性至关重要，但准确识别材料成分和检测污染物仍然具有挑战性。

**Method:** 使用标准RGB图像，设计计算机视觉组件用于传送带设置，执行(a)四种常见纺织品类型的分类和(b)纽扣、拉链等非纺织特征的分割。分类采用迁移学习评估预训练架构，其中EfficientNetB0表现最佳。特征分割采用结合Grounding DINO和Segment Anything Model (SAM)的零样本方法。

**Result:** EfficientNetB0在纺织品分类任务中，在保留测试集上实现了81.25%的准确率。零样本分割方法在生成的掩码与真实值对比时，mIoU达到0.90。

**Conclusion:** 本研究证明了使用RGB图像结合现代深度学习技术（包括用于分类的迁移学习和用于零样本分割的基础模型）来支持自动化纺织品回收流水线中基本分析步骤的可行性。

> **ai_Abstract:** 本文旨在通过利用成本效益高的RGB图像和先进的深度学习技术，解决纺织品回收自动化分拣中的材料识别和污染物检测难题。研究设计了计算机视觉系统，实现了四种纺织品类型的分类（EfficientNetB0达到81.25%准确率）和非纺织特征（如纽扣、拉链）的零样本分割（Grounding DINO与SAM结合达到0.90 mIoU）。结果证明了该方法在自动化纺织品回收分析中的可行性。

> **摘要翻译:** 自动化分拣对于提高纺织品回收的效率和可扩展性至关重要，但准确识别材料成分和从传感器数据中检测污染物仍然具有挑战性。本文研究了使用标准RGB图像这种经济高效的传感模式，用于自动化系统中的关键预处理任务。我们提出了为传送带设置设计的计算机视觉组件，以执行(a)四种常见纺织品类型的分类和(b)纽扣和拉链等非纺织特征的分割。对于分类，使用迁移学习和交叉验证评估了几种预训练架构，其中EfficientNetB0在保留测试集上达到了81.25%的最佳性能。对于特征分割，采用了结合Grounding DINO开放词汇检测器和Segment Anything Model (SAM)的零样本方法，在生成的掩码与真实值对比时，表现出卓越的性能，mIoU为0.90。这项研究证明了使用RGB图像结合现代深度学习技术，包括用于分类的迁移学习和用于零样本分割的基础模型，以实现自动化纺织品回收流水线中基本分析步骤的可行性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [111] [A Deep Learning Approach for Facial Attribute Manipulation and Reconstruction in Surveillance and Reconnaissance](https://arxiv.org/abs/2506.06578)
> *一种用于监控和侦察中面部属性操纵和重建的深度学习方法*

*Anees Nashath Shaik, Barbara Villarini, Vasileios Argyriou* | **Main category: cs.CV**

**Keywords:** 面部属性操纵, 深度学习, 生成对抗网络, 监控, 偏见消除

**Comment:** 

> **TL;DR:** 本文提出了一种基于深度学习的平台，利用自编码器和GANs生成多样化的合成面部数据并增强图像，以解决监控人脸识别中的偏差和低质量问题。

**AI_Comments:** 本文的创新之处在于利用深度学习（特别是自编码器和GANs）来生成合成数据，以解决监控场景中因数据限制和偏差导致的人脸识别准确性和公平性问题。这对于提升AI在现实世界安防应用中的鲁棒性和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 监控系统常因图像质量低而导致人脸识别准确性下降。现有AI面部分析模型因训练数据不足和不平衡而存在肤色和遮挡偏见，导致识别性能不公平和不可靠。

**Method:** 提出了一个数据驱动的平台，通过深度学习（自编码器和生成对抗网络GANs）进行面部属性操纵和重建，生成定制的合成训练数据以弥补数据集偏差。此外，系统还集成了一个图像增强模块，用于改善低分辨率或被遮挡面部的清晰度。

**Result:** 使用CelebA数据集进行评估，结果表明所提出的平台有效增强了训练数据的多样性和模型的公平性。

**Conclusion:** 该工作有助于减少基于AI的面部分析中的偏见，提高复杂环境中的监控准确性，从而实现更公平、更可靠的安全应用。

> **ai_Abstract:** 本文提出了一种基于深度学习的平台，旨在解决监控系统中人脸识别因图像质量低和模型偏见导致的问题。该平台利用自编码器和生成对抗网络（GANs）进行面部属性操纵和重建，生成多样化的合成训练数据以弥补数据集偏差，并集成图像增强模块以提高低分辨率或遮挡面部的清晰度。在CelebA数据集上的评估表明，该方法能有效提升训练数据多样性和模型公平性，从而实现更可靠的安全应用。

> **摘要翻译:** 监控系统在安全和侦察中发挥着关键作用，但其性能常常受到低质量图像和视频的影响，导致人脸识别准确性降低。此外，现有的基于AI的面部分析模型存在与肤色变化和部分遮挡面部相关的偏见，进一步限制了它们在各种现实场景中的有效性。这些挑战是数据限制和不平衡的结果，现有训练数据集缺乏足够的多样性，导致不公平和不可靠的人脸识别性能。为了解决这些问题，我们提出了一个数据驱动的平台，通过生成定制的合成训练数据来弥补数据集偏差，从而增强监控能力。我们的方法利用基于深度学习的面部属性操纵和重建，使用自编码器和生成对抗网络（GANs）来创建多样化和高质量的面部数据集。此外，我们的系统集成了一个图像增强模块，提高了监控录像中低分辨率或被遮挡面部的清晰度。我们使用CelebA数据集评估了我们的方法，结果表明所提出的平台增强了训练数据的多样性和模型的公平性。这项工作有助于减少基于AI的面部分析中的偏见，并提高在复杂环境中的监控准确性，从而实现更公平、更可靠的安全应用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [125] [EV-LayerSegNet: Self-supervised Motion Segmentation using Event Cameras](https://arxiv.org/abs/2506.06596)
> *EV-LayerSegNet: 使用事件相机进行自监督运动分割*

*Youssef Farah, Federico Paredes-Vallés, Guido De Croon, Muhammad Ahmed Humais, Hussain Sajwani, Yahya Zweiri* | **Main category: cs.CV**

**Keywords:** 事件相机, 运动分割, 自监督学习, 仿射光流, 深度学习

**Comment:** This paper has been accepted for publication at the IEEE Conference
  on Computer Vision and Pattern Recognition (CVPR) Workshops, Nashville, 2025

> **TL;DR:** EV-LayerSegNet是一种自监督CNN，用于事件相机的运动分割，通过学习仿射光流和分割掩码来去模糊输入事件，并使用去模糊质量作为自监督学习损失，在模拟数据集上取得了不错的性能。

**AI_Comments:** EV-LayerSegNet的创新之处在于其自监督学习范式，这极大地降低了对昂贵且难以获取的真值标注的依赖。通过将去模糊质量作为自监督信号，该方法巧妙地利用了事件相机固有的特性。该研究为事件相机在运动分割领域的应用开辟了新的途径，尤其是在真值稀缺的场景下具有重要意义。然而，目前仅在模拟的仿射运动数据集上进行了验证，未来需要进一步在真实世界复杂场景中进行测试。

<details>
  <summary>Details</summary>

**Motivation:** 传统相机在捕捉运动动态方面的时间分辨率较低，而事件相机更适合运动分割任务。然而，训练基于事件的网络面临挑战，因为获取真值非常昂贵、易出错且频率有限。

**Method:** 本文引入了EV-LayerSegNet，一个用于事件运动分割的自监督CNN。受场景动态分层表示的启发，该方法能够分别学习仿射光流和分割掩码，并利用它们对输入事件进行去模糊处理。去模糊质量被用作自监督学习损失。

**Result:** 在仅包含仿射运动的模拟数据集上训练和测试了网络，其IoU（交并比）达到了71%，检测率达到了87%。

**Conclusion:** 该研究表明，通过自监督学习，利用场景的层状表示进行事件去模糊，可以有效地实现事件相机的运动分割。

> **ai_Abstract:** EV-LayerSegNet是一个针对事件相机运动分割的自监督卷积神经网络。为了解决传统事件网络训练中真值获取困难的问题，该方法借鉴场景分层表示，独立学习仿射光流和分割掩码，并利用它们对事件进行去模糊。去模糊质量被作为自监督学习的损失函数。在模拟数据集上，该网络在仿射运动分割任务中取得了71%的IoU和87%的检测率，验证了其有效性。

> **摘要翻译:** 事件相机是一种新型的仿生传感器，与传统相机相比，由于像素对亮度变化异步反应，它们能够以更高的时间分辨率捕捉运动动态。因此，它们更适合涉及运动的任务，例如运动分割。然而，训练基于事件的网络仍然是一个巨大的挑战，因为获取真值非常昂贵、容易出错且频率受限。在本文中，我们介绍了EV-LayerSegNet，一个用于事件运动分割的自监督CNN。受场景动态分层表示的启发，我们展示了可以分别学习仿射光流和分割掩码，并使用它们来对输入事件进行去模糊。然后测量去模糊质量，并将其用作自监督学习损失。我们在一个仅包含仿射运动的模拟数据集上训练和测试了该网络，实现了高达71%的IoU和87%的检测率。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [132] [FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity](https://arxiv.org/abs/2506.07865)
> *FreeGave：通过高斯速度从动态视频中学习3D物理*

*Jinxi Li, Ziyang Song, Siyuan Zhou, Bo Yang* | **Main category: cs.CV**

**Keywords:** 3D物理学习, 动态视频, 高斯速度, 无物体先验, 物理编码

**Comment:** CVPR 2025. Code and data are available at:
  https://github.com/vLAR-group/FreeGave

> **TL;DR:** FreeGave提出了一种无需物体先验知识，通过高斯速度场学习复杂动态3D场景物理的方法，并在未来帧外推和运动分割任务上表现优异，且其学习到的物理编码能捕捉有意义的3D物理运动模式。

**AI_Comments:** FreeGave的创新之处在于其无需物体先验知识即可学习3D场景物理的能力，以及通过物理编码和无散度模块来避免传统PINN损失的低效率。其在无监督学习物理运动模式方面的发现，对于未来3D场景理解和预测领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通过PINN损失或将物理模拟融入神经网络，常无法学习边界处的复杂物理运动，或需要物体先验信息（如掩码或类型）。

**Method:** 论文提出了FreeGave，通过引入物理编码，并结合精心设计的无散度模块来估计每个高斯的速度场，从而学习复杂动态3D场景的物理，且不依赖低效的PINN损失。

**Result:** 在三个公共数据集和一个新收集的真实世界数据集上的大量实验表明，该方法在未来帧外推和运动分割方面表现出优越性能。学习到的物理编码在没有人工标签的情况下，能真正学习到有意义的3D物理运动模式。

**Conclusion:** FreeGave成功地在没有物体先验知识的情况下，从多视图视频中学习了复杂动态3D场景的物理，并且其学习到的物理编码能够捕捉到有意义的3D物理运动模式，这表明其在未来帧预测和运动分割等任务上的有效性。

> **ai_Abstract:** 本文提出了FreeGave，一种无需物体先验知识，仅从多视图视频中学习复杂动态3D场景物理的方法。该方法通过引入物理编码和一个无散度模块来估计高斯速度场，避免了低效的PINN损失。实验结果表明，FreeGave在未来帧外推和运动分割任务上表现优异，并且其学习到的物理编码能够捕捉到有意义的3D物理运动模式。

> **摘要翻译:** 在本文中，我们旨在纯粹从多视图视频中建模3D场景的几何、外观和底层物理。通过将各种控制偏微分方程作为PINN损失或将物理模拟整合到神经网络中，现有工作常常无法学习边界处的复杂物理运动，或者需要物体先验信息，如掩码或类型。在本文中，我们提出了FreeGave，用于学习复杂动态3D场景的物理，而无需任何物体先验。我们方法的关键是引入一个物理编码，然后是一个精心设计的无散度模块，用于估计每个高斯的速度场，而不依赖于低效的PINN损失。在三个公共数据集和一个新收集的具有挑战性的真实世界数据集上进行的大量实验表明，我们的方法在未来帧外推和运动分割方面表现出卓越的性能。最值得注意的是，我们对所学习到的物理编码的调查表明，它们在训练中没有任何人工标签的情况下，确实学习到了有意义的3D物理运动模式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [138] [RARL: Improving Medical VLM Reasoning and Generalization with Reinforcement Learning and LoRA under Data and Hardware Constraints](https://arxiv.org/abs/2506.06600)
> *RARL：在数据和硬件限制下，通过强化学习和LoRA改进医疗VLM的推理和泛化能力*

*Tan-Hanh Pham, Chris Ngo* | **Main category: cs.CV**

**Keywords:** 医疗VLM, 强化学习, LoRA, 推理, 泛化

**Comment:** Under review

> **TL;DR:** RARL框架利用强化学习和LoRA在资源受限环境下显著提升了医疗VLM的推理和泛化能力，解决了当前医疗VLM在泛化、透明度和计算效率方面的局限性。

**AI_Comments:** 该论文的创新点在于结合强化学习和LoRA技术，以在资源受限的环境下提升医疗VLM的推理和泛化能力。其重要性体现在为医疗AI在实际临床部署中面临的计算和数据挑战提供了可行解决方案。通过在单个A100 GPU上完成训练，展示了其高效性和实际部署潜力，这对于医疗领域有限的硬件资源而言意义重大。此外，强调多样性提示和推理提示的作用，为未来的VLM优化提供了新的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前医疗视觉-语言模型（VLMs）在泛化能力、透明度和计算效率方面面临局限性，这阻碍了它们在资源受限的真实世界医疗应用中的部署。

**Method:** 本文提出了RARL（Reasoning-Aware Reinforcement Learning）框架，通过结合诊断准确性和推理质量的自定义奖励函数，使用Low-Rank Adaptation（LoRA）对轻量级基础模型Qwen2-VL-2B-Instruct进行微调。训练在一个NVIDIA A100 GPU上进行，并采用LLM-as-judge框架评估模型的正确性和解释质量。

**Result:** RARL显著提升了医疗图像分析和临床推理中的VLM性能，在推理型任务上比监督微调高出约7.78%，同时需要更少的计算资源。在未见数据集上的泛化能力也得到了提升，比监督微调高出约27%，比传统强化学习微调高出约4%。研究还表明，训练中的多样性提示和推理中的推理提示对VLM性能的提升至关重要。

**Conclusion:** 理由引导学习和理由提示有潜力引导医疗VLM实现更透明、准确和资源高效的临床决策。

> **ai_Abstract:** RARL是一个新颖的推理感知强化学习框架，旨在解决医疗VLM在泛化、透明度和计算效率方面的挑战，尤其是在资源受限的环境下。该框架通过LoRA和自定义奖励函数对轻量级模型进行微调，显著提升了医疗图像分析和临床推理的性能。实验结果表明，RARL在推理任务和未见数据集上的表现均优于监督微调和传统RL微调，并且计算效率更高，强调了理由引导学习和提示工程在提升医疗VLM能力方面的重要性。

> **摘要翻译:** 视觉-语言模型（VLMs）在医疗应用中日益增长的整合为诊断推理提供了有力的支持。然而，当前的医疗VLM在泛化能力、透明度和计算效率方面常常面临局限性，这些障碍阻碍了其在真实世界、资源受限环境中的部署。为了解决这些挑战，我们提出了一种推理感知强化学习框架——\textbf{RARL}，它在保持高效和适应低资源环境的同时，增强了医疗VLM的推理能力。我们的方法使用低秩适应（Low-Rank Adaptation）和联合考虑诊断准确性和推理质量的自定义奖励函数，对轻量级基础模型Qwen2-VL-2B-Instruct进行微调。训练在单个NVIDIA A100-PCIE-40GB GPU上进行，这证明了在受限环境中部署此类模型的可行性。我们使用LLM-as-judge框架评估模型，该框架同时对正确性和解释质量进行评分。实验结果表明，RARL显著提升了医疗图像分析和临床推理中的VLM性能，在推理型任务上比监督微调高出约7.78%，同时需要更少的计算资源。此外，我们证明了我们方法在未见数据集上的泛化能力，与监督微调相比，性能提升了约27%，比传统RL微调提升了约4%。我们的实验还表明，训练中的多样性提示和推理中的推理提示对于增强VLM性能至关重要。我们的发现突出了理由引导学习和理由提示在引导医疗VLM走向更透明、准确和资源高效的临床决策方面的潜力。代码和数据已公开可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [149] [Zero Shot Composed Image Retrieval](https://arxiv.org/abs/2506.06602)
> *零样本组合图像检索*

*Santhosh Kakarla, Gautama Shastry Bulusu Venkata* | **Main category: cs.CV**

**Keywords:** 组合图像检索, 零样本, BLIP-2, Q-Former, 多模态融合

**Comment:** 8 pages, 3 figures

> **TL;DR:** 零样本组合图像检索（CIR）性能不佳，本文通过微调BLIP-2并引入Q-Former大幅提升了Recall@10，同时发现Retrieval-DPO因缺乏多模态融合等原因效果很差。

**AI_Comments:** 本文通过对比两种不同的方法（基于BLIP-2微调和Retrieval-DPO）来改进零样本CIR，清晰地展示了多模态融合在图像-文本检索任务中的关键作用。对Retrieval-DPO失败原因的深入分析为未来研究提供了宝贵的经验，指明了有效基于偏好的检索方法的设计方向。

<details>
  <summary>Details</summary>

**Motivation:** 零样本组合图像检索（CIR）在FashionIQ基准上的Recall@10表现仅为20-25%，性能非常低，需要改进。

**Method:** 本文通过使用轻量级Q-Former微调BLIP-2，将视觉和文本特征融合为单一嵌入来改进零样本CIR。此外，还研究了Retrieval-DPO，它使用直接偏好优化（DPO）损失对CLIP的文本编码器进行微调，并应用于FAISS挖掘的硬负样本。

**Result:** 通过微调BLIP-2和Q-Former，Recall@10提升至衬衫45.6%、连衣裙40.1%、上衣50.4%，平均Recall@50提升至67.6%。然而，Retrieval-DPO仅达到0.02%的Recall@10，远低于零样本和提示微调基线，原因包括缺乏联合图像-文本融合、目标函数与Top-K指标不匹配、依赖低质量负样本以及视觉和Transformer层冻结。

**Conclusion:** 有效的基于偏好的CIR需要真正的多模态融合、考虑排名的目标函数以及精心策划的负样本。

> **ai_Abstract:** 零样本组合图像检索（CIR）性能不足。本文通过微调BLIP-2并引入轻量级Q-Former，将视觉和文本特征融合为单一嵌入，显著提升了CIR的检索性能。同时，研究发现Retrieval-DPO在CIR任务中表现不佳，并分析了其失败原因，强调了多模态融合、排名感知目标和高质量负样本对于有效CIR的重要性。

> **摘要翻译:** 组合图像检索（CIR）允许用户通过对参考图像应用细粒度文本编辑（例如，“把裙子改成蓝色”或“去除条纹”）来定位目标图像。零样本CIR，即使用独立的预训练视觉-语言编码器嵌入图像和文本，在FashionIQ基准上仅达到20-25%的Recall@10。我们通过使用轻量级Q-Former微调BLIP-2来改进这一点，该Q-Former将视觉和文本特征融合为单一嵌入，将Recall@10提高到衬衫45.6%、连衣裙40.1%和上衣50.4%，并将平均Recall@50提高到67.6%。我们还研究了Retrieval-DPO，它使用应用于FAISS挖掘的硬负样本的直接偏好优化（DPO）损失来微调CLIP的文本编码器。尽管对缩放因子、索引和采样策略进行了广泛调整，Retrieval-DPO仅达到0.02%的Recall@10——远低于零样本和提示微调基线——因为它（i）缺乏联合图像-文本融合，（ii）使用的边际目标与top-K指标不匹配，（iii）依赖低质量的负样本，以及（iv）保持视觉和Transformer层冻结。我们的结果表明，有效的基于偏好的CIR需要真正的多模态融合、考虑排名的目标函数和精心策划的负样本。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [159] [PhysLab: A Benchmark Dataset for Multi-Granularity Visual Parsing of Physics Experiments](https://arxiv.org/abs/2506.06631)
> *PhysLab：一个用于物理实验多粒度视觉解析的基准数据集*

*Minghao Zou, Qingtian Zeng, Yongping Miao, Shangkun Liu, Zilong Wang, Hantao Liu, Wei Zhou* | **Main category: cs.CV**

**Keywords:** PhysLab, 视觉解析, 物理实验, 基准数据集, 教育技术

**Comment:** 

> **TL;DR:** PhysLab是一个新的视频数据集，用于解决现有数据集在细粒度视觉解析、教育领域覆盖和程序指导方面的不足，它包含学生进行物理实验的视频，并提供多级别标注，旨在推动计算机视觉在教育领域的应用。

**AI_Comments:** PhysLab的创新之处在于它是首个专门为物理实验设计的视频数据集，解决了现有数据集在教育领域和细粒度程序指导方面的空白。它的重要性在于能够促进计算机视觉在教育场景中的应用，例如智能课堂系统和自动化实验分析。该数据集的多粒度标注和对复杂人-物交互的捕捉，使其成为推进细粒度视觉解析研究的重要资源。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像和视频视觉解析数据集存在以下局限性：1) 注释粒度不足，阻碍细粒度场景理解和高级推理；2) 领域覆盖有限，特别是缺乏针对教育场景的数据集；3) 缺乏明确的程序指导，逻辑规则少且结构化任务过程表示不足。

**Method:** 本文介绍了PhysLab，这是第一个捕捉学生进行复杂物理实验的视频数据集。该数据集包含四种代表性实验，涉及多样化的科学仪器和丰富的人-物交互模式。PhysLab包含620个长视频，并提供多级别标注，支持动作识别、物体检测、人-物交互分析等多种视觉任务。作者建立了强大的基线并进行了广泛评估，以突出程序性教育视频解析中的关键挑战。

**Result:** PhysLab数据集包含620个长视频，涵盖四种物理实验，具有多样化的科学仪器和丰富的人-物交互模式。它提供了支持多种视觉任务（如动作识别、物体检测、人-物交互分析）的多级别标注。研究者建立了强基线并进行了广泛评估，揭示了程序性教育视频解析中的关键挑战。

**Conclusion:** PhysLab有望成为推动细粒度视觉解析、促进智能课堂系统以及加强计算机视觉与教育技术之间整合的宝贵资源。

> **ai_Abstract:** 为了解决现有视觉解析数据集在注释粒度、领域覆盖和程序指导方面的不足，本文推出了PhysLab，一个包含学生进行复杂物理实验视频的基准数据集。PhysLab包含620个长视频，并提供多级别标注，支持多种视觉任务。研究者建立了基线并评估了程序性教育视频解析中的挑战。该数据集旨在促进细粒度视觉解析和智能课堂系统发展，加强计算机视觉与教育技术的融合。

> **摘要翻译:** 图像和视频的视觉解析对于广泛的现实世界应用至关重要。然而，该领域的进展受到现有数据集局限性的制约：(1) 注释粒度不足，阻碍细粒度场景理解和高级推理；(2) 领域覆盖有限，特别是缺乏针对教育场景的数据集；(3) 缺乏明确的程序指导，逻辑规则极少且结构化任务过程表示不足。为了弥补这些空白，我们引入了PhysLab，这是第一个捕捉学生进行复杂物理实验的视频数据集。该数据集包括四种代表性实验，具有多样化的科学仪器和丰富的人-物交互（HOI）模式。PhysLab包含620个长视频，并提供支持各种视觉任务（包括动作识别、物体检测、HOI分析等）的多级别标注。我们建立了强大的基线并进行了广泛评估，以突出程序性教育视频解析中的关键挑战。我们期望PhysLab能成为推动细粒度视觉解析、促进智能课堂系统以及加强计算机视觉与教育技术之间更紧密整合的宝贵资源。该数据集和评估工具包可在 https://github.com/ZMH-SDUST/PhysLab 公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [170] [Dark Channel-Assisted Depth-from-Defocus from a Single Image](https://arxiv.org/abs/2506.06643)
> *暗通道辅助的单幅图像离焦深度估计*

*Moushumi Medhi, Rajiv Ranjan Sahay* | **Main category: cs.CV**

**Keywords:** 暗通道, 离焦深度估计, 单幅图像, 深度估计, 对抗性训练

**Comment:** 

> **TL;DR:** 本文提出了一种利用暗通道先验从单幅离焦图像中估计场景深度的方法，通过对抗性端到端训练，实现了有意义的深度估计结果。

**AI_Comments:** 这项工作在单幅图像离焦深度估计这一欠约束问题上取得了进展，通过引入暗通道先验作为一种新颖的补充线索。其端到端的对抗性训练方法提高了估计性能，并在真实数据上得到了验证，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的离焦深度估计（DFD）技术通常依赖于多幅具有不同光圈或对焦设置的图像来恢复深度信息。由于单幅离焦图像的深度估计问题具有欠约束性质，因此很少有研究尝试从单幅图像进行DFD。

**Method:** 本方法利用暗通道作为补充线索，从单幅空间变异离焦模糊图像中估计场景深度，因为它能有效隐式捕获模糊图像的局部统计信息和场景结构。该方法利用局部离焦模糊和对比度变化之间的关系作为关键深度线索，以提高场景结构估计的整体性能。整个流程以完全端到端的方式进行对抗性训练。

**Result:** 在具有真实深度引起的离焦模糊的真实数据上进行的实验表明，将暗通道先验引入单幅图像DFD可以产生有意义的深度估计结果。

**Conclusion:** 将暗通道先验引入单幅图像离焦深度估计是有效的，能够从单幅离焦图像中获得有意义的深度估计结果。

> **ai_Abstract:** 本文提出了一种新颖的单幅图像离焦深度估计（DFD）方法，通过利用暗通道作为补充线索来捕获模糊图像的局部统计信息和场景结构。该方法克服了传统DFD技术对多幅图像的依赖，通过利用局部离焦模糊和对比度变化的关系作为深度线索，并采用完全端到端的对抗性训练。实验结果表明，该方法在真实数据上能够有效估计深度，验证了暗通道先验在单幅图像DFD中的有效性。

> **摘要翻译:** 在本文中，我们利用暗通道作为补充线索，从单幅空间变异离焦模糊图像中估计场景深度，因为它能有效隐式捕获模糊图像的局部统计信息和场景结构。现有的离焦深度估计（DFD）技术通常依赖于多幅具有不同光圈或对焦设置的图像来恢复深度信息。由于问题的欠约束性质，很少有尝试关注从单幅离焦图像进行DFD。我们的方法利用局部离焦模糊和对比度变化之间的关系作为关键深度线索，以提高场景结构估计的整体性能。整个流程以完全端到端的方式进行对抗性训练。在具有真实深度引起的离焦模糊的真实数据上进行的实验表明，将暗通道先验引入单幅图像DFD可以产生有意义的深度估计结果，验证了我们方法的有效性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [179] [Parametric Gaussian Human Model: Generalizable Prior for Efficient and Realistic Human Avatar Modeling](https://arxiv.org/abs/2506.06645)
> *参数化高斯人体模型：高效逼真人体化身建模的可泛化先验*

*Cheng Peng, Jingxiang Sun, Yushuo Chen, Zhaoqi Su, Zhuo Su, Yebin Liu* | **Main category: cs.CV**

**Keywords:** 参数化高斯人体模型, 3D高斯泼溅, 人体化身, 单目视频, 可泛化先验

**Comment:** Project Page: https://pengc02.github.io/pghm/

> **TL;DR:** PGHM将人体先验引入3DGS，实现了从单目视频中快速、高保真地重建人体化身，解决了现有方法的效率和泛化问题。

**AI_Comments:** 该论文创新性地将人体先验引入3D高斯泼溅，有效解决了现有方法在效率和泛化能力上的痛点。其核心组件，如UV对齐的潜在身份图和解耦的多头U-Net，设计巧妙，实现了从单目视频中高效生成高保真人体化身。这项工作对于推动虚拟现实、远程呈现和数字娱乐中人体化身的实际应用具有重要意义，因为它大大降低了高质量化身创建的门槛。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D高斯泼溅（3DGS）方法面临耗时的逐主题优化和稀疏单目输入下泛化能力差的挑战。逼真且可动画的人体化身对于虚拟/增强现实、远程呈现和数字娱乐至关重要。

**Method:** 提出参数化高斯人体模型（PGHM）。包含两个核心组件：1) 紫外线对齐的潜在身份图，将特定主体的几何和外观紧凑编码为可学习的特征张量；2) 解耦的多头U-Net，通过条件解码器分解静态、姿态依赖和视角依赖的组件来预测高斯属性。这种设计在挑战性姿态和视角下实现了鲁棒的渲染质量，并允许高效的主体适应。

**Result:** PGHM比从头开始优化的方法效率显著更高，每个主体仅需约20分钟即可生成具有可比视觉质量的化身。

**Conclusion:** PGHM由于其效率和可比的视觉质量，在现实世界单目化身创建中展现了实际应用价值。

> **ai_Abstract:** 本文介绍了PGHM，一个参数化高斯人体模型，它将人体先验集成到3D高斯泼溅（3DGS）中，以克服现有方法在人体化身建模中耗时优化和泛化能力差的挑战。PGHM利用UV对齐的潜在身份图和解耦的多头U-Net，从单目视频中高效重建高保真、可泛化的人体化身。实验表明，PGHM显著将每个主体的优化时间缩短至约20分钟，同时保持可比的视觉质量，使其在现实世界单目化身创建中具有实用性。

> **摘要翻译:** 逼真且可动画的人体化身是虚拟/增强现实、远程呈现和数字娱乐的关键推动者。尽管3D高斯泼溅（3DGS）的最新进展大大提高了渲染质量和效率，但现有方法仍面临根本性挑战，包括耗时的逐主题优化和稀疏单目输入下的泛化能力差。在这项工作中，我们提出了参数化高斯人体模型（PGHM），这是一个可泛化且高效的框架，它将人体先验集成到3DGS中，以实现从单目视频中快速高保真地重建化身。PGHM引入了两个核心组件：（1）一个UV对齐的潜在身份图，它将特定主体的几何和外观紧凑地编码为可学习的特征张量；（2）一个解耦的多头U-Net，通过条件解码器分解静态、姿态依赖和视角依赖的组件来预测高斯属性。这种设计在挑战性姿态和视角下实现了鲁棒的渲染质量，同时无需多视角捕获或长时间优化即可实现高效的主体适应。实验表明，PGHM比从头开始优化的方法效率显著更高，每个主体仅需约20分钟即可生成具有可比视觉质量的化身，从而证明了其在现实世界单目化身创建中的实际适用性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [186] [Flood-DamageSense: Multimodal Mamba with Multitask Learning for Building Flood Damage Assessment using SAR Remote Sensing Imagery](https://arxiv.org/abs/2506.06667)
> *Flood-DamageSense：多模态Mamba与多任务学习结合SAR遥感图像用于建筑物洪水损害评估*

*Yu-Hsuan Ho, Ali Mostafavi* | **Main category: cs.CV**

**Keywords:** 洪水损害评估, SAR遥感, 多模态Mamba, 多任务学习, 深度学习

**Comment:** 

> **TL;DR:** Flood-DamageSense是一种新型深度学习框架，结合SAR图像、光学地图和固有洪水风险层，通过多模态Mamba骨干网和多任务学习，显著提高了建筑物洪水损害评估的准确性，尤其在轻微和中度损害分类上表现突出。

**AI_Comments:** 这项研究的创新之处在于它是首个专门为建筑物级洪水损害评估设计的深度学习框架，并且创造性地引入了“固有洪水风险层”作为模型输入，这在消融研究中被证明是性能提升的关键因素。结合SAR图像的全天候能力和多任务学习，该模型不仅提高了评估的准确性，特别是对难以分类的轻微和中度损害，而且实现了快速的端到端处理，具有重要的实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有灾后损害分类器在洪水淹没后识别建筑物损害时表现不佳，因为洪水很少留下清晰的光谱或结构特征，导致现有模型难以识别洪水相关的建筑物损害。

**Method:** 本研究提出了Flood-DamageSense模型，这是一个专门用于建筑物级别洪水损害评估的深度学习框架。该架构融合了灾前和灾后的SAR/InSAR场景、超高分辨率光学底图以及编码长期暴露概率的固有洪水风险层。模型采用多模态Mamba骨干网，带有半Siamese编码器和任务特定解码器，共同预测分级建筑物损害状态、洪水范围和建筑物足迹。

**Result:** 在2017年飓风哈维（德克萨斯州哈里斯县）的图像上进行训练和评估，并辅以保险衍生的财产损害范围数据，结果显示，相对于最先进的基线模型，F1分数平均提高了19个百分点，其中在经常被错误分类的“轻微”和“中度”损害类别中增益最大。消融研究表明，固有风险特征是性能提升的最重要贡献者。

**Conclusion:** Flood-DamageSense通过结合风险感知建模和SAR的全天候能力，能够更快、更精细、更可靠地提供洪水损害信息，以支持灾后决策和资源分配。

> **ai_Abstract:** Flood-DamageSense是一种创新的深度学习框架，旨在解决现有模型在洪水后建筑物损害评估方面的不足。它整合了灾前/灾后SAR/InSAR图像、高分辨率光学底图和固有洪水风险层，利用多模态Mamba骨干网和多任务学习共同预测建筑物损害等级、洪水范围和建筑物足迹。该模型在飓风哈维的数据集上表现出色，相对于现有技术，F1分数提高了19个百分点，尤其在轻微和中度损害分类上取得了显著进展。其创新点在于引入了固有风险特征，并能快速生成实用的损害地图，为灾后响应提供支持。

> **摘要翻译:** 大多数灾后损害分类器仅在破坏力留下清晰光谱或结构特征时才能成功——而洪水淹没后很少出现这种情况。因此，现有模型在识别洪水相关建筑物损害方面表现不佳。本研究提出的模型Flood-DamageSense解决了这一空白，它是首个专门用于建筑物级别洪水损害评估的深度学习框架。该架构融合了灾前和灾后的SAR/InSAR场景、超高分辨率光学底图以及编码长期暴露概率的固有洪水风险层，即使组成变化很小，也能引导网络识别可能受影响的结构。采用多模态Mamba骨干网，带有半Siamese编码器和任务特定解码器，共同预测(1)分级建筑物损害状态、(2)洪水范围和(3)建筑物足迹。在2017年飓风哈维（德克萨斯州哈里斯县）的图像上进行训练和评估——并辅以保险衍生的财产损害范围——结果显示，相对于最先进的基线模型，F1分数平均提高了19个百分点，其中在经常被错误分类的“轻微”和“中度”损害类别中增益最大。消融研究表明，固有风险特征是性能提升的最重要贡献者。端到端后处理管道可在图像采集后数分钟内将像素级输出转换为可操作的建筑物尺度损害地图。通过结合风险感知建模和SAR的全天候能力，Flood-DamageSense能够更快、更精细、更可靠地提供洪水损害信息，以支持灾后决策和资源分配。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [196] [Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment](https://arxiv.org/abs/2506.06680)
> *深度学习模型在体外受精（IVF）治疗中胚胎选择的解释*

*Radha Kodali, Venkata Rao Dhulipalla, Venkata Siva Kishor Tatavarty, Madhavi Nadakuditi, Bharadwaj Thiruveedhula, Suryanarayana Gunnam, Durga Prasad Bavirisetti* | **Main category: cs.CV**

**Keywords:** 深度学习, 胚胎选择, 体外受精, 可解释人工智能, CNN-LSTM

**Comment:** 

> **TL;DR:** 本研究开发了一个结合CNN和LSTM的XAI框架，用于高效准确地解释体外受精胚胎选择，解决了传统方法的耗时和低效问题。

**AI_Comments:** 该研究创新性地将可解释人工智能（XAI）引入胚胎选择领域，有效解决了深度学习模型在医疗应用中常见的“黑箱”问题，显著提升了模型的透明度和临床可信度。结合CNN和LSTM的架构设计，充分利用了图像的空间特征，对于提高诊断准确性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 不孕不育问题日益严重，体外受精（IVF）是主要治疗手段。然而，传统的胚胎选择过程耗时且效率低下，需要更高效准确的自动化方法。

**Method:** 本研究引入了一个可解释人工智能（XAI）框架，用于胚胎分类。该框架融合了卷积神经网络（CNN）和长短期记忆网络（LSTM）架构，命名为CNN-LSTM。

**Result:** 所提出的深度学习模型在胚胎分类中实现了高准确度，同时通过XAI保持了可解释性。

**Conclusion:** 该研究提出的结合CNN和LSTM的XAI框架为体外受精中的胚胎选择提供了一个高准确度且可解释的解决方案。

> **ai_Abstract:** 本研究针对体外受精（IVF）中胚胎选择的传统方法耗时且效率低下的问题，提出了一种基于深度学习的可解释人工智能（XAI）框架。该框架融合了卷积神经网络（CNN）和长短期记忆网络（LSTM）架构（CNN-LSTM），旨在通过分析囊胚图像进行胚胎分类。研究结果表明，该模型在实现高准确度的同时，通过XAI保持了良好的可解释性，为IVF胚胎选择提供了高效且透明的解决方案。

> **摘要翻译:** 不孕不育对个体生活质量有相当大的影响，在社会和心理上都影响着他们，预计未来几年还会上升。体外受精（IVF）是经济发达国家解决低生育率问题的主要技术之一。专家胚胎学家通常通过审查囊胚图像来对胚胎进行分级，以选择最适合移植的胚胎，但这个过程耗时且效率低下。囊胚图像为评估胚胎活力提供了宝贵资源。在本研究中，我们引入了一种可解释人工智能（XAI）框架，用于胚胎分类，该框架采用卷积神经网络（CNN）和长短期记忆（LSTM）架构的融合，称为CNN-LSTM。利用深度学习，我们的模型在胚胎分类中实现了高准确度，同时通过XAI保持了可解释性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [205] [A Systematic Investigation on Deep Learning-Based Omnidirectional Image and Video Super-Resolution](https://arxiv.org/abs/2506.06710)
> *基于深度学习的全向图像和视频超分辨率的系统研究*

*Qianqian Zhao, Chunle Guo, Tianyi Zhang, Junpei Zhang, Peiyang Jia, Tan Su, Wenjie Jiang, Chongyi Li* | **Main category: cs.CV**

**Keywords:** 全向图像,视频超分辨率,深度学习,360Insta,系统综述

**Comment:** 

> **TL;DR:** 本文系统综述了基于深度学习的全向图像和视频超分辨率研究进展，并提出了一个包含真实退化数据的360Insta新数据集，用于更鲁棒的评估。

**AI_Comments:** 该论文的创新之处在于提出了一个包含真实世界退化数据的360Insta数据集，这解决了现有基准测试中合成数据无法充分反映真实世界复杂性的问题。这对于提升全向超分辨率方法的泛化能力和实际应用价值具有重要意义。同时，作为一篇系统综述，它为该领域的最新进展和未来方向提供了宝贵的洞察。

<details>
  <summary>Details</summary>

**Motivation:** 全向图像和视频超分辨率是低级视觉中的关键研究课题，在虚拟现实和增强现实应用中发挥着重要作用。其目标是从低分辨率输入重建高分辨率图像或视频帧，以增强细节保留并实现更准确的场景分析和解释。现有数据集主要依赖合成退化，未能捕捉真实世界的失真。

**Method:** 本文系统综述了基于深度学习的全向图像和视频超分辨率的最新进展，重点关注深度学习方法。针对现有数据集的不足，提出了一个包含真实退化全向图像和视频的新数据集360Insta。在公共数据集和360Insta数据集上对现有方法进行了全面的定性和定量评估。此外，还系统概述了研究现状并讨论了未来方向。

**Result:** 提出了一个包含真实退化全向图像和视频的新数据集360Insta，解决了现有全向基准测试中关键的空白，并能更鲁棒地评估全向超分辨率方法的泛化能力。对现有方法在公共数据集和所提出的数据集上进行了全面的定性和定量评估。

**Conclusion:** 本文提供了对基于深度学习的全向图像和视频超分辨率的系统回顾，并提出了一个用于更鲁棒评估的真实退化数据集360Insta，同时讨论了未来的研究方向。

> **ai_Abstract:** 本文对基于深度学习的全向图像和视频超分辨率进行了系统综述，该技术对VR/AR应用至关重要。鉴于现有数据集的局限性，作者提出了一个名为360Insta的新数据集，其中包含真实世界中退化的全向图像和视频，以促进对超分辨率方法泛化能力的更准确评估。研究对现有方法进行了全面评估，并展望了未来的研究方向。所有相关资源均已公开。

> **摘要翻译:** 全向图像和视频超分辨率是低级视觉中的一个关键研究课题，在虚拟现实和增强现实应用中发挥着重要作用。其目标是从低分辨率输入重建高分辨率图像或视频帧，从而增强细节保留并实现更准确的场景分析和解释。近年来，已经提出了许多创新和有效的方法，主要基于深度学习技术，涉及不同的网络架构、损失函数、投影策略和训练数据集。本文系统回顾了全向图像和视频超分辨率的最新进展，重点关注基于深度学习的方法。鉴于现有数据集主要依赖合成退化，未能捕捉真实世界的失真，我们引入了一个新数据集360Insta，它包含在不同条件下（包括不同的光照、运动和曝光设置）收集的真实退化全向图像和视频。该数据集解决了当前全向基准测试中的关键空白，并能够更鲁棒地评估全向超分辨率方法的泛化能力。我们对现有方法在公共数据集和我们提出的数据集上进行了全面的定性和定量评估。此外，我们系统概述了研究现状并讨论了未来探索的有希望的方向。这项工作中引入的所有数据集、方法和评估指标都是公开可用的，并将定期更新。项目页面：https://github.com/nqian1/Survey-on-ODISR-and-ODVSR。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [212] [Active Contour Models Driven by Hyperbolic Mean Curvature Flow for Image Segmentation](https://arxiv.org/abs/2506.06712)
> *双曲平均曲率流驱动的主动轮廓模型用于图像分割*

*Saiyu Hu, Chunlei He, Jianfeng Zhang, Dexing Kong, Shoujun Huang* | **Main category: cs.CV**

**Keywords:** 主动轮廓模型, 双曲平均曲率流, 图像分割, 水平集方法, 双模式正则化流

**Comment:** 

> **TL;DR:** 本文提出了基于双曲平均曲率流的主动轮廓模型（HMCF-ACMs）和双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），通过引入可调初始速度场和边缘感知力调制，显著提高了图像分割的精度、抗噪性和数值稳定性，解决了传统抛物线模型对初始曲线配置依赖性强的问题。

**AI_Comments:** 本文的创新点在于将双曲平均曲率流引入主动轮廓模型，并通过引入可调初始速度场和边缘感知力调制，有效解决了传统模型对初始初始曲线配置的强依赖性问题，并提升了在复杂图像分割场景下的性能。其理论分析和数值实现优化也为后续研究提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 传统的抛物线平均曲率流驱动的主动轮廓模型（PMCF-ACMs）在图像分割中广泛使用，但其结果严重依赖于初始曲线配置的选择。本文旨在解决这一局限性。

**Method:** 1. 提出了几种双曲平均曲率流驱动的主动轮廓模型（HMCF-ACMs），引入可调初始速度场以实现自适应优化。2. 证明了HMCF-ACMs确实是法向流，并利用带符号距离函数的水平集方法建立了耗散型HMCF公式与某些波动方程之间的数值等价性。3. 在此基础上，开发了双曲双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），利用平滑Heaviside函数进行边缘感知力调制，以抑制弱边界附近的过度扩散。4. 优化了使用九点模板空间离散化的加权四阶Runge-Kutta算法来求解波动方程。

**Result:** 实验表明，HMCF-ACMs和HDRF-ACMs由于初始速度和初始轮廓的任务自适应配置，能够实现更精确的分割，并具有卓越的抗噪性和数值稳定性。

**Conclusion:** 本文提出的基于双曲平均曲率流的主动轮廓模型（HMCF-ACMs）和双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），通过引入可调初始速度场和边缘感知力调制，显著提高了图像分割的精度、抗噪性和数值稳定性。

> **ai_Abstract:** 本文针对传统抛物线平均曲率流驱动的主动轮廓模型对初始曲线配置依赖性强的问题，提出了一种基于双曲平均曲率流的新型主动轮廓模型（HMCF-ACMs）及其扩展模型（HDRF-ACMs）。HMCF-ACMs引入了可调初始速度场以实现自适应优化，并被证明是法向流。HDRF-ACMs则通过平滑Heaviside函数进行边缘感知力调制，以抑制弱边界处的过度扩散。研究还建立了耗散型HMCF公式与波动方程的数值等价性，并优化了求解算法。实验结果验证了所提模型在图像分割中具有更高的精度、更强的抗噪性和更好的数值稳定性。

> **摘要翻译:** 抛物线平均曲率流驱动的主动轮廓模型（PMCF-ACMs）在图像分割中广泛使用，但其结果严重依赖于初始曲线配置的选择。在本文中，我们首先提出了几种双曲平均曲率流驱动的主动轮廓模型（HMCF-ACMs），它们引入了可调的初始速度场，从而能够对不同的分割场景进行自适应优化。我们将证明HMCF-ACMs确实是法向流，并利用带符号距离函数的水平集方法建立了耗散型HMCF公式与某些波动方程之间的数值等价性。在此框架的基础上，我们进一步开发了双曲双模式正则化流驱动的主动轮廓模型（HDRF-ACMs），它们利用平滑的Heaviside函数进行边缘感知力调制，以抑制弱边界附近的过度扩散。然后，我们在求解上述波动方程时，优化了一个使用九点模板空间离散化的加权四阶Runge-Kutta算法。实验表明，HMCF-ACMs和HDRF-ACMs由于初始速度和初始轮廓的任务自适应配置，能够实现更精确的分割，并具有卓越的抗噪性和数值稳定性。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [221] [Improving Wildlife Out-of-Distribution Detection: Africas Big Five](https://arxiv.org/abs/2506.06719)
> *改进野生动物分布外检测：非洲五大动物*

*Mufhumudzi Muthivhi, Jiahao Huo, Fredrik Gustafsson, Terence L. van Zyl* | **Main category: cs.CV**

**Keywords:** 野生动物, 分布外检测, 非洲五大动物, 最近类别均值, 计算机视觉

**Comment:** 

> **TL;DR:** 本研究旨在改进野生动物的分布外（OOD）检测，特别是针对非洲五大动物。通过使用基于特征的方法，特别是ImageNet预训练特征的NCM，实现了显著的性能提升，解决了现有分类模型在未知类别上过自信的问题。

**AI_Comments:** 这篇论文解决了计算机视觉领域中一个重要的实际问题，即模型在未知类别上的泛化能力，这在野生动物监测等实际应用中尤为关键。其创新点在于将OOD检测应用于野生动物领域，并证明了基于特征的方法（特别是NCM结合预训练特征）的有效性。这项工作对于提高自动化野生动物监测系统的可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决人与野生动物冲突中识别潜在危险个体的需求，以及现有计算机视觉动物分类模型在“封闭世界”假设下对未知类别预测过于自信的局限性。

**Method:** 研究调查了野生动物的分布外（OOD）检测，特别是针对非洲五大动物。选择了参数化的最近类别均值（NCM）和非参数化的对比学习方法作为基线，利用预训练和投影的分类编码器特征。此外，将这些基线与文献中各种常见的OOD方法进行了比较。

**Result:** 结果表明，基于特征的方法在不同分类阈值下表现出更强的泛化能力。具体而言，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。

**Conclusion:** 基于特征的方法，特别是结合ImageNet预训练特征的NCM，能够有效提升野生动物的分布外检测性能，为缓解人与野生动物冲突提供了更可靠的解决方案。

> **ai_Abstract:** 本研究致力于改进野生动物的分布外（OOD）检测，以解决现有动物分类模型在面对未知物种时过度自信的问题，这对于缓解人与野生动物冲突至关重要。研究选取了最近类别均值（NCM）和对比学习作为基线方法，并与多种现有OOD方法进行比较。结果显示，基于特征的方法，特别是结合ImageNet预训练特征的NCM，在泛化能力上表现出色，并在多项OOD检测指标上取得了显著提升。

> **摘要翻译:** 缓解人与野生动物冲突旨在解决双方之间不必要的遭遇。计算机视觉提供了一种识别可能升级为冲突的个体（例如非洲五大动物的成员）的解决方案。然而，环境通常包含多种不同的物种。当前最先进的动物分类模型是在封闭世界假设下训练的。即使遇到未知类别，它们几乎总是对其预测过于自信。本研究调查了野生动物的分布外（OOD）检测，特别是针对非洲五大动物。为此，我们选择了一种参数化的最近类别均值（NCM）和一种非参数化的对比学习方法作为基线，以利用来自流行分类编码器的预训练和投影特征。此外，我们将我们的基线与文献中各种常见的OOD方法进行了比较。结果表明，基于特征的方法在不同分类阈值下反映出更强的泛化能力。具体而言，使用ImageNet预训练特征的NCM在AUPR-IN、AUPR-OUT和AUTC上分别比最佳OOD方法提高了2%、4%和22%。代码可以在https://github.com/pxpana/BIG5OOD找到。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [227] [Mitigating Object Hallucination via Robust Local Perception Search](https://arxiv.org/abs/2506.06729)
> *通过鲁棒局部感知搜索缓解物体幻觉*

*Zixian Gao, Chao Yang, Zhanhui Zhou, Xing Xu, Chaochao Lu* | **Main category: cs.CV**

**Keywords:** 物体幻觉, MLLMs, 局部感知搜索, 解码方法, 噪声数据

**Comment:** 

> **TL;DR:** 多模态大型语言模型（MLLMs）存在物体幻觉问题。本文提出了局部感知搜索（LPS），这是一种简单、无需训练的解码方法，它利用局部视觉先验来抑制幻觉，尤其在噪声数据中表现出色，并且是即插即用的。

**AI_Comments:** 该论文的创新点在于提出了局部感知搜索（LPS）这一简单、无需训练且即插即用的解码方法，有效缓解了 MLLMs 中的幻觉问题。其在噪声环境下的突出表现以及与多种模型的兼容性，使其成为提升 MLLM 可靠性的重要贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型（MLLMs）在整合视觉和语言方面取得了显著成功，但它们仍存在幻觉现象，即输出看似合理但与图像内容不符。本文旨在解决这一问题。

**Method:** 本文引入了局部感知搜索（LPS），这是一种在推理过程中使用的简单、无需训练的解码方法。它利用局部视觉先验信息作为价值函数来纠正解码过程。LPS 是一种即插即用的方法，兼容各种模型。

**Result:** LPS 在广泛使用的幻觉基准和噪声数据上进行了大量实验，结果表明它与基线相比显著降低了幻觉的发生率，尤其是在噪声环境下表现出卓越的性能。研究还发现，局部视觉先验对模型性能的影响在图像噪声水平较高的情况下更为显著。

**Conclusion:** 局部感知搜索（LPS）通过在推理过程中利用局部视觉先验，有效缓解了多模态大型语言模型（MLLMs）中的物体幻觉问题，尤其是在噪声条件下。它是一种简单、无需训练且即插即用的解决方案。

> **ai_Abstract:** 本文针对多模态大型语言模型（MLLMs）中的物体幻觉问题，提出了一种名为局部感知搜索（LPS）的新方法。LPS 是一种简单、无需训练且即插即用的解码策略，通过利用局部视觉先验来纠正推理过程，从而有效抑制幻觉，尤其是在噪声环境中表现出色。实验证明 LPS 显著减少了幻觉的发生。

> **摘要翻译:** 多模态大型语言模型（MLLMs）的最新进展使其能够有效地整合视觉和语言，解决各种下游任务。然而，尽管取得了显著成功，这些模型仍然表现出幻觉现象，即输出看似合理但与图像内容不符。为了缓解这个问题，我们引入了局部感知搜索（LPS），这是一种在推理过程中使用的解码方法，它既简单又无需训练，却能有效抑制幻觉。该方法利用局部视觉先验信息作为价值函数来纠正解码过程。此外，我们观察到在图像噪声水平较高的情况下，局部视觉先验对模型性能的影响更为显著。值得注意的是，LPS 是一种即插即用的方法，与各种模型兼容。在广泛使用的幻觉基准和噪声数据上进行的广泛实验表明，与基线相比，LPS 显著降低了幻觉的发生率，尤其是在噪声环境下表现出卓越的性能。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [235] [RecipeGen: A Step-Aligned Multimodal Benchmark for Real-World Recipe Generation](https://arxiv.org/abs/2506.06733)
> *食谱生成：一个用于真实世界食谱生成的步骤对齐多模态基准*

*Ruoxuan Zhang, Jidong Gao, Bin Wen, Hongxia Xie, Chenming Zhang, Honghan-shuai, Wen-Huang Cheng* | **Main category: cs.CV**

**Keywords:** 食谱生成, 多模态基准, 文本到图像, 图像到视频, 文本到视频

**Comment:** This is an extended version of arXiv:2503.05228

> **TL;DR:** 提出了RecipeGen，一个大型多模态食谱生成基准，解决了现有数据集缺乏细粒度对齐的问题，并支持文本到图像、图像到视频和文本到视频的生成任务。

**AI_Comments:** 这篇论文的创新点在于构建了一个大规模、细粒度对齐的真实世界多模态食谱数据集RecipeGen，并提出了针对性的评估指标，这对于推动食谱生成，特别是多模态食谱生成领域的研究具有重要意义。它填补了现有数据集的空白，为未来的模型开发提供了坚实的基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有食谱数据集缺乏食谱目标、分步说明和视觉内容之间的细粒度对齐，这限制了食谱图像生成在烹饪教育和多模态食谱助手等领域的应用。

**Method:** 本文提出了RecipeGen，这是第一个用于基于食谱的文本到图像（T2I）、图像到视频（I2V）和文本到视频（T2V）生成的大规模、真实世界基准。RecipeGen包含26,453个食谱、196,724张图片和4,491个视频。此外，还提出了领域特定的评估指标来评估食材保真度和交互建模，并对代表性的T2I、I2V和T2V模型进行了基准测试。

**Result:** RecipeGen包含了26,453个食谱、196,724张图片和4,491个视频，涵盖了不同的食材、烹饪步骤、风格和菜肴类型。研究还提出了领域特定的评估指标，并对代表性模型进行了基准测试，为未来的食谱生成模型提供了见解。

**Conclusion:** RecipeGen是第一个用于真实世界食谱生成的大规模、步骤对齐的多模态基准，它通过解决现有数据集的细粒度对齐问题，并提供新的评估指标和基准测试，为未来的食谱生成模型研究奠定了基础。

> **ai_Abstract:** 本文介绍了RecipeGen，一个大型的、步骤对齐的多模态基准数据集，旨在解决现有食谱数据集在食谱目标、分步说明和视觉内容之间缺乏细粒度对齐的问题。RecipeGen支持文本到图像、图像到视频和文本到视频的食谱生成任务，并提供了新的评估指标和基准测试结果，为未来的食谱生成模型研究提供了基础和方向。

> **摘要翻译:** 创建食谱图像是食品计算中的一个关键挑战，在烹饪教育和多模态食谱助手中有应用。然而，现有数据集缺乏食谱目标、分步说明和视觉内容之间的细粒度对齐。我们提出了RecipeGen，这是第一个用于基于食谱的文本到图像（T2I）、图像到视频（I2V）和文本到视频（T2V）生成的大规模真实世界基准。RecipeGen包含26,453个食谱、196,724张图片和4,491个视频，涵盖了不同的食材、烹饪步骤、风格和菜肴类型。我们进一步提出了领域特定的评估指标来评估食材保真度和交互建模，对代表性的T2I、I2V和T2V模型进行了基准测试，并为未来的食谱生成模型提供了见解。项目页面现已可用。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [244] [THU-Warwick Submission for EPIC-KITCHEN Challenge 2025: Semi-Supervised Video Object Segmentation](https://arxiv.org/abs/2506.06748)
> *THU-Warwick 参加 EPIC-KITCHEN 2025 挑战赛：半监督视频对象分割*

*Mingqi Gao, Haoran Duan, Tianlu Zhang, Jungong Han* | **Main category: cs.CV**

**Keywords:** 视频对象分割, 半监督, SAM2, 深度信息, EPIC-KITCHEN

**Comment:** 

> **TL;DR:** 该论文介绍了THU-Warwick团队为EPIC-KITCHEN 2025挑战赛提交的半监督视频对象分割方法，该方法结合SAM2预训练和深度几何线索，在VISOR数据集上达到了90.1%的J&F分数。

**AI_Comments:** 该论文的创新点在于将强大的预训练模型（SAM2）与深度几何信息有效结合，以解决以自我为中心的视频对象分割中的复杂性和长期跟踪挑战。在VISOR数据集上取得的高J&F分数（90.1%）表明了该方法在实际应用中的有效性和鲁棒性，对于未来以自我为中心视觉任务的研究具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决以自我为中心的视频对象分割问题，特别是处理复杂场景和实现长期跟踪。

**Method:** 该方法将来自SAM2的大规模视觉预训练与基于深度的几何线索相结合，并在统一的框架中集成这些信号。

**Result:** 在VISOR测试集上，该方法达到了90.1%的J&F分数，显示出强大的分割性能。

**Conclusion:** 该方法通过结合视觉预训练和深度几何线索，在以自我为中心的视频对象分割方面取得了强大的性能。

> **ai_Abstract:** 本文介绍了THU-Warwick团队为EPIC-KITCHEN 2025挑战赛提交的半监督视频对象分割方法。该方法创新性地结合了SAM2的大规模视觉预训练模型和基于深度的几何线索，旨在有效处理复杂场景下的以自我为中心的视频对象分割及长期跟踪问题。通过在统一框架中整合这些技术，该方法在VISOR测试集上取得了显著的90.1%的J&F分数，展现出强大的分割能力。

> **摘要翻译:** 本报告描述了我们处理以自我为中心的视频对象分割的方法。我们的方法将SAM2的大规模视觉预训练与基于深度的几何线索相结合，以处理复杂场景和长期跟踪。通过在统一框架中整合这些信号，我们实现了强大的分割性能。在VISOR测试集上，我们的方法达到了90.1%的J&F分数。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [253] [SAR2Struct: Extracting 3D Semantic Structural Representation of Aircraft Targets from Single-View SAR Image](https://arxiv.org/abs/2506.06757)
> *SAR2Struct: 从单视SAR图像中提取飞机目标的3D语义结构表示*

*Ziyu Yue, Ruixi You, Feng Xu* | **Main category: cs.CV**

**Keywords:** SAR, 3D语义结构, 飞机目标, 单视SAR, 结构恢复

**Comment:** 13 pages, 12 figures

> **TL;DR:** 本文提出了一种从单视SAR图像中提取飞机目标3D语义结构表示的新任务和方法，通过两步算法框架实现了目标组件及其结构关系的推断。

**AI_Comments:** 本文的创新点在于提出了一个全新的任务——SAR目标结构恢复，并首次成功地从单视SAR图像中提取出3D语义结构表示，弥补了现有方法在语义信息捕获方面的不足。其两步算法框架结合了真实SAR图像的2D关键点检测与模拟数据学习3D结构映射的方法，为SAR图像理解和高级信息检索开辟了新的途径，具有重要的理论和应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 为了将合成孔径雷达（SAR）图像转换为人类可理解的形式，现有方法主要集中于3D表面重建或局部几何特征提取，但忽略了结构建模在捕获语义信息方面的作用。

**Method:** 本文提出了一种SAR目标结构恢复的新任务，旨在从单视SAR图像中推断目标组件及其结构关系（特别是对称性和邻接性）。为此，开发了一个基于结构描述符的两步算法框架。训练阶段，从真实SAR图像中检测2D关键点，并使用模拟数据学习这些关键点到3D分层结构的映射。测试阶段，将这两步整合以从真实SAR图像中推断3D结构。

**Result:** 实验结果验证了每个步骤的有效性，并首次证明了可以直接从单视SAR图像中推导出飞机目标的3D语义结构表示。

**Conclusion:** 本研究首次成功地从单视SAR图像中直接推导出了飞机目标的3D语义结构表示，并通过提出的两步算法框架验证了其有效性，为SAR高级信息检索提供了新的路径。

> **ai_Abstract:** 本文提出了一项名为SAR目标结构恢复的新任务，旨在从单视SAR图像中提取飞机目标的3D语义结构表示，包括其组件及其结构关系（如对称性和邻接性）。针对现有方法在语义信息捕获方面的不足，研究开发了一个基于结构描述符的两步算法框架。该框架在训练阶段利用真实SAR图像的2D关键点和模拟数据学习到3D结构的映射，并在测试阶段整合此过程以从真实SAR图像中推断3D结构。实验结果首次验证了从单视SAR图像直接推导飞机目标3D语义结构表示的可行性和有效性。

> **摘要翻译:** 为了将合成孔径雷达（SAR）图像转换为人类可理解的形式，是SAR高级信息检索的最终目标。现有方法主要集中于目标的3D表面重建或局部几何特征提取，忽略了结构建模在捕获语义信息方面的作用。本文提出了一项新任务：SAR目标结构恢复，旨在从单视SAR图像中推断目标的组件及其组件之间的结构关系，特别是对称性和邻接性。通过学习不同SAR图像中同类型目标所观察到的结构一致性和几何多样性，旨在直接从其2D SAR图像中导出目标的语义表示。为了解决这项具有挑战性的任务，开发了一个基于结构描述符的两步算法框架。具体而言，在训练阶段，它首先从真实SAR图像中检测2D关键点，然后使用模拟数据学习这些关键点到3D分层结构的映射。在测试阶段，将这两步整合以从真实SAR图像中推断3D结构。实验结果验证了每个步骤的有效性，并首次证明了可以直接从单视SAR图像中导出飞机目标的3D语义结构表示。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [261] [LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security](https://arxiv.org/abs/2506.06759)
> *LitMAS：一种轻量级通用多模态生物识别安全反欺骗框架*

*Nidheesh Gorthi, Kartik Thakral, Rishabh Ranjan, Richa Singh, Mayank Vatsa* | **Main category: cs.CV**

**Keywords:** 多模态反欺骗, 生物识别安全, 轻量级, 泛化, 模态对齐集中损失

**Comment:** Accepted in Interspeech 2025

> **TL;DR:** LitMAS是一种轻量级、通用的多模态反欺骗框架，通过引入模态对齐集中损失，在多种生物识别系统（语音、人脸、虹膜、指纹）中有效检测欺骗攻击，并以6M参数量超越SOTA。

**AI_Comments:** LitMAS的创新之处在于其提出了一个统一的、跨多种生物模态的反欺骗框架，并通过模态对齐集中损失实现了高效且泛化的欺骗检测。其轻量级设计（仅6M参数）使其特别适合边缘部署，这在实际应用中具有重要价值。该研究解决了当前反欺骗领域中模态特异性方案的局限性，为未来多模态生物识别系统的安全性提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 生物识别认证系统易受欺骗攻击，现有研究多关注特定模态的反欺骗技术，缺乏统一且资源高效的跨多模态解决方案。

**Method:** 提出LitMAS框架，它是一种轻量级且通用的多模态反欺骗框架，旨在检测语音、人脸、虹膜和指纹等生物识别系统中的欺骗攻击。其核心是模态对齐集中损失（Modality-Aligned Concentration Loss），该损失增强了类间可分离性，同时保持了跨模态一致性，从而实现了对不同生物特征的鲁棒欺骗检测。

**Result:** LitMAS仅用6M参数，在七个数据集上的平均等错误率（EER）超越现有最先进方法1.36%，显示出高效率、强泛化能力和边缘部署的适用性。

**Conclusion:** LitMAS提供了一个高效、通用且轻量级的多模态反欺骗解决方案，显著提升了生物识别系统的安全性，并适用于资源受限的边缘设备。

> **ai_Abstract:** 本文提出了LitMAS，一个轻量级且通用的多模态反欺骗框架，旨在解决现有生物识别系统易受欺骗攻击且缺乏统一跨模态解决方案的问题。LitMAS的核心是模态对齐集中损失，该损失通过增强类间可分离性并保持跨模态一致性，实现了对语音、人脸、虹膜和指纹等多种生物特征的鲁棒欺骗检测。实验结果表明，LitMAS以其仅6M的参数量，在七个数据集上的平均EER超越了现有SOTA方法1.36%，证明了其高效率、强大的泛化能力以及适用于边缘部署的特性。

> **摘要翻译:** 生物识别认证系统正越来越多地应用于关键领域，但它们仍然容易受到欺骗攻击。由于大多数研究工作都集中在特定模态的反欺骗技术上，因此构建一个统一、资源高效的跨多种生物识别模态的解决方案仍然是一个挑战。为了解决这个问题，我们提出了LitMAS，一个轻量级且通用的多模态反欺骗框架，旨在检测基于语音、人脸、虹膜和指纹的生物识别系统中的欺骗攻击。LitMAS的核心是模态对齐集中损失（Modality-Aligned Concentration Loss），它在保持跨模态一致性的同时增强了类间可分离性，从而实现了对各种生物特征的鲁棒欺骗检测。LitMAS仅用6M参数，在七个数据集上的平均等错误率（EER）超越现有最先进方法1.36%，展示了高效率、强泛化能力和边缘部署的适用性。代码和训练模型可在https://github.com/IAB-IITJ/LitMAS获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [267] [LoopDB: A Loop Closure Dataset for Large Scale Simultaneous Localization and Mapping](https://arxiv.org/abs/2506.06771)
> *LoopDB：一个用于大规模同步定位与建图的闭环检测数据集*

*Mohammad-Maher Nakshbandi, Ziad Sharawy, Dorian Cojocaru, Sorin Grigorescu* | **Main category: cs.CV**

**Keywords:** 闭环检测, 数据集, 同步定位与建图, SLAM, LoopDB

**Comment:** 

> **TL;DR:** LoopDB是一个包含1000多张图像的闭环检测数据集，适用于大规模同步定位与建图中的算法基准测试和训练。

**AI_Comments:** LoopDB数据集的创新之处在于其多样化的环境和大规模图像数量，这使其成为评估和训练闭环检测算法的宝贵资源。高分辨率图像和提供的真值信息增强了其在基准测试方面的实用性。该数据集的公开可用性将促进SLAM领域闭环检测方法的研究和发展。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是提供一个具有挑战性的闭环检测数据集，用于评估和训练同步定位与建图（SLAM）中的闭环检测算法的准确性。

**Method:** 本研究介绍了LoopDB数据集，它包含1000多张在公园、室内场景、停车场以及围绕单个物体等多种不同环境中捕获的图像。每场景由五张连续图像序列表示。数据集使用高分辨率相机收集，并提供连续图像之间的计算出的旋转和平移作为真值信息。

**Result:** 结果是创建并公开了一个名为LoopDB的闭环检测数据集，该数据集可用于基准测试和训练基于深度神经网络的闭环检测方法。

**Conclusion:** LoopDB数据集为大规模同步定位与建图中的闭环检测算法提供了一个有价值的基准测试和训练资源。

> **ai_Abstract:** 本研究推出了LoopDB，一个包含1000多张图像的闭环检测数据集，涵盖公园、室内、停车场和物体中心等多样化环境。该数据集通过高分辨率相机收集，并提供连续图像间的真值旋转和平移，旨在为大规模同步定位与建图（SLAM）中的闭环检测算法提供基准测试。此外，LoopDB也适用于深度神经网络闭环检测方法的训练和微调，并已公开可用。

> **摘要翻译:** 在本研究中，我们介绍了LoopDB，这是一个具有挑战性的闭环检测数据集，包含在公园、室内场景、停车场以及围绕单个物体等多种不同环境中捕获的1000多张图像。每个场景都由五张连续图像的序列表示。该数据集使用高分辨率相机收集，为通常用于同步定位与建图的闭环检测算法的准确性基准测试提供了合适的图像。作为真值信息，我们提供了每张连续图像之间计算出的旋转和平移。除了其基准测试目标外，该数据集还可用于训练和微调基于深度神经网络的闭环检测方法。LoopDB可在https://github.com/RovisLab/LoopDB公开获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [272] [Continuous-Time SO(3) Forecasting with Savitzky--Golay Neural Controlled Differential Equations](https://arxiv.org/abs/2506.06780)
> *连续时间SO(3)预测与Savitzky-Golay神经控制微分方程*

*Lennart Bastian, Mohammad Rashed, Nassir Navab, Tolga Birdal* | **Main category: cs.CV**

**Keywords:** SO(3)预测, 神经控制微分方程, Savitzky-Golay, 旋转动力学, 连续时间

**Comment:** Extended abstract, presented at the CVPR Workshop on 4D Vision

> **TL;DR:** 本文提出了一种使用Savitzky-Golay路径引导的神经控制微分方程，用于在SO(3)上建模连续时间旋转对象动力学，以应对噪声、稀疏观测和复杂动态下的长期旋转预测挑战。

**AI_Comments:** 这项工作的创新点在于将Savitzky-Golay路径与神经控制微分方程结合，用于SO(3)上的连续时间旋转预测，这使得模型能够处理复杂的运动模式和噪声数据，同时保持几何结构。其重要性在于提升了计算机视觉和机器人领域中物体旋转跟踪和预测的鲁棒性与准确性。

<details>
  <summary>Details</summary>

**Motivation:** 跟踪和预测物体旋转在计算机视觉和机器人领域至关重要，但SO(3)外推仍然具有挑战性，因为传感器观测可能嘈杂且稀疏，运动模式可能由复杂动力学决定，以及应用场景可能需要长期预测。现有方法依赖于简化的运动假设，无法有效解决这些问题。

**Method:** 本文提出使用由Savitzky-Golay路径引导的神经控制微分方程（Neural Controlled Differential Equations guided by Savitzky-Golay paths）来建模SO(3)上的连续时间旋转对象动力学。该方法学习底层对象轨迹的通用潜在动力学系统，同时尊重旋转的几何结构，区别于依赖简化运动假设的现有方法。

**Result:** 在真实世界数据上的实验结果表明，与现有方法相比，该方法具有引人注目的预测能力。

**Conclusion:** 该方法有效地解决了SO(3)旋转预测中的挑战，并在实际应用中表现出优越性。

> **ai_Abstract:** 本文提出了一种新颖的方法，利用Savitzky-Golay神经控制微分方程在SO(3)流形上对连续时间物体旋转进行建模和预测。该方法旨在克服传统SO(3)预测中传感器噪声、复杂动力学和长期预测需求带来的挑战，通过学习通用潜在动力学系统并尊重旋转的几何结构，实现了优于现有方法的预测性能。

> **摘要翻译:** 跟踪和预测物体的旋转在计算机视觉和机器人领域至关重要，但SO(3)外推仍然具有挑战性，因为 (1) 传感器观测可能嘈杂且稀疏，(2) 运动模式可能由复杂动力学决定，以及 (3) 应用场景可能需要长期预测。这项工作提出使用由Savitzky-Golay路径引导的神经控制微分方程来建模SO(3)上的连续时间旋转对象动力学。与现有依赖简化运动假设的方法不同，我们的方法学习底层对象轨迹的通用潜在动力学系统，同时尊重旋转的几何结构。在真实世界数据上的实验结果表明，与现有方法相比，该方法具有引人注目的预测能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [279] [Training-Free Identity Preservation in Stylized Image Generation Using Diffusion Models](https://arxiv.org/abs/2506.06802)
> *使用扩散模型在风格化图像生成中实现免训练的身份保留*

*Mohammad Ali Rezaei, Helia Hajikazem, Saeed Khanehgir, Mahdi Javanmardi* | **Main category: cs.CV**

**Keywords:** 扩散模型, 身份保留, 风格化图像生成, 免训练, 风格迁移

**Comment:** 

> **TL;DR:** 本文提出了一种免训练的框架，利用扩散模型在风格化图像生成中有效保留身份，即使在面部较小或相机距离较远的情况下也能实现高保真度。

**AI_Comments:** 该论文的创新之处在于提出了一个免训练的框架，解决了扩散模型在风格化图像生成中身份保留的难题，特别是在处理面部较小或相机距离较远等挑战性场景时。其“马赛克恢复内容图像”技术和免训练内容一致性损失是关键创新点，大大降低了实际应用中的计算成本和复杂性，具有重要的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有的风格迁移技术在实现高质量风格化的同时，难以保持图像中的身份，尤其是在面部较小或相机与面部距离较远的情况下，经常导致身份保留不足。

**Method:** 我们引入了一种新颖的、免训练的身份保留风格化图像合成框架，该框架使用扩散模型。关键贡献包括：(1) “马赛克恢复内容图像”技术，显著增强了身份保留，特别是在复杂场景中；(2) 一种免训练的内容一致性损失，通过在风格化过程中更多地关注原始图像，增强了细粒度内容细节的保留。

**Result:** 我们的实验表明，所提出的方法在同时保持高风格保真度和鲁棒身份完整性方面，显著超越了基线模型，尤其是在面部区域较小或相机与面部距离较大的条件下，且无需模型再训练或微调。

**Conclusion:** 本文提出的免训练框架能有效解决扩散模型在风格化图像生成中身份保留的挑战，即使在面部较小或相机距离较远等复杂场景下，也能实现出色的身份保留和风格保真度。

> **ai_Abstract:** 本研究提出了一种创新的免训练框架，利用扩散模型进行身份保留的风格化图像生成。该框架通过引入“马赛克恢复内容图像”技术和免训练的内容一致性损失，有效解决了现有风格迁移技术在保持身份方面的不足，尤其是在处理面部区域较小或相机距离较远的图像时。实验证明，该方法在保持高风格保真度和鲁棒身份完整性方面显著优于基线模型，且无需额外的模型训练或微调。

> **摘要翻译:** 尽管扩散模型展示了卓越的生成能力，但现有的风格迁移技术在实现高质量风格化的同时，往往难以保持身份。这种局限性对于面部较小或相机与面部距离显著的图像尤为突出，经常导致身份保留不足。为了解决这个问题，我们引入了一种新颖的、免训练的框架，用于使用扩散模型进行身份保留的风格化图像合成。主要贡献包括：(1) “马赛克恢复内容图像”技术，显著增强了身份保留，特别是在复杂场景中；(2) 一种免训练的内容一致性损失，通过在风格化过程中更多地关注原始图像，增强了细粒度内容细节的保留。我们的实验表明，所提出的方法在同时保持高风格保真度和鲁棒身份完整性方面，显著超越了基线模型，尤其是在面部区域较小或相机与面部距离较大的条件下，所有这些都无需模型再训练或微调。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [285] [Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2506.06818)
> *逐步分解与双流聚焦：一种无训练伪装目标分割的新方法*

*Chao Yin, Hao Li, Kequan Yang, Jide Li, Pinpin Zhu, Xiaoqiang Li* | **Main category: cs.CV**

**Keywords:** 伪装目标分割, 无训练, 可提示分割, 逐步分解, 双流视觉提示

**Comment:** under review

> **TL;DR:** 本文提出了RDVP-MSD，一个无训练的伪装目标分割框架，通过解决提示中的语义模糊性和差异性，实现了最先进的性能。

**AI_Comments:** 本文提出了一种创新的无训练方法，直接解决了可提示分割模型（如SAM）在处理具有挑战性的伪装目标时的局限性。文本提示的逐步分解以及双流、区域约束的视觉提示是解决语义模糊性和空间分离等核心问题的巧妙方案。该方法在无需任何训练或监督的情况下即可达到SOTA结果，这突显了其在效率和适应性方面的显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有可提示分割方法（如SAM），尤其是任务通用型，在伪装目标分割（COS）中面临两大问题：1）文本提示中语义模糊性，因整体描述缺乏判别性线索导致前景-背景混淆；2）视觉提示中语义差异与空间分离，因全局背景采样远离目标边界且特征相关性低。

**Method:** 本文提出了RDVP-MSD，一个新颖的无训练测试时自适应框架。它通过多模态逐步分解思维链（MSD-CoT）协同区域约束双流视觉提示（RDVP）。MSD-CoT逐步解开图像描述以消除语义模糊性，而RDVP将空间约束注入视觉提示中，并独立采样前景和背景点的视觉提示，有效缓解语义差异和空间分离。

**Result:** RDVP-MSD在多个COS基准测试中取得了最先进的分割结果，并比以前的方法提供了更快的推理速度，显示出显著提高的准确性和效率，且无需任何训练或监督。

**Conclusion:** RDVP-MSD通过解决与提示相关的问题，有效应对了伪装目标分割的挑战，在无需训练或监督的情况下实现了卓越的性能。

> **ai_Abstract:** 本文提出了一种名为RDVP-MSD的新型无训练框架，用于伪装目标分割（COS）。该方法旨在解决现有可提示分割方法（如SAM）在处理伪装目标时面临的语义模糊性（文本提示）和语义差异/空间分离（视觉提示）问题。RDVP-MSD利用多模态逐步分解思维链（MSD-CoT）来消除文本描述中的语义模糊性，并通过区域约束双流视觉提示（RDVP）注入空间约束并独立采样前景和背景点，从而改进视觉提示。该方法在多个COS基准测试中无需任何训练或监督就取得了最先进的性能，并提供了更快的推理速度，显著提高了准确性和效率。

> **摘要翻译:** 虽然可提示分割（例如SAM）在各种分割任务中显示出前景，但它仍然需要为每个要分割的对象手动提供视觉提示。相比之下，任务通用可提示分割旨在通过仅使用任务通用提示来指导所有测试样本的分割，从而减少对此类详细提示的需求。然而，当应用于伪装目标分割（COS）时，当前方法仍然面临两个关键问题：1）在获取实例特定文本提示时存在语义模糊性，这源于整体描述中缺乏足够的判别性线索，导致前景-背景混淆；2）在获取实例特定视觉提示时存在语义差异与空间分离，这是由于远离对象边界的全局背景采样和低特征相关性导致的，使得SAM分割无关区域。为了解决上述问题，我们提出了RDVP-MSD，这是一种新颖的无训练测试时自适应框架，它通过多模态逐步分解思维链（MSD-CoT）协同区域约束双流视觉提示（RDVP）。MSD-CoT逐步解开图像描述以消除语义模糊性，而RDVP将空间约束注入视觉提示中，并独立采样前景和背景点的视觉提示，有效缓解语义差异和空间分离。RDVP-MSD无需任何训练或监督，在多个COS基准测试中取得了最先进的分割结果，并比以前的方法提供了更快的推理速度，显示出显著提高的准确性和效率。代码将可在https://github.com/ycyinchao/RDVP-MSD获取。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [292] [Hi-LSplat: Hierarchical 3D Language Gaussian Splatting](https://arxiv.org/abs/2506.06822)
> *Hi-LSplat: 分层3D语言高斯泼溅*

*Chenlu Zhan, Yufei Zhang, Gaoang Wang, Hongwei Wang* | **Main category: cs.CV**

**Keywords:** 3D语言场, 高斯泼溅, 分层语义, 开放词汇, 视图一致性

**Comment:** 

> **TL;DR:** Hi-LSplat通过构建3D分层语义树和引入对比损失，解决了现有3D语言高斯泼溅模型中视图不一致和开放词汇语义理解不足的问题，实现了视图一致的3D开放词汇查询。

**AI_Comments:** 该论文通过引入3D分层语义树和针对性的对比损失，创新性地解决了3D语言场建模中长期存在的视图不一致性和开放词汇分层语义理解困难的问题。其方法不仅提升了3D开放词汇查询的准确性，还为3D场景的复杂语义理解提供了新的视角和工具，具有重要的研究价值和潜在应用前景。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于3DGS的模型在利用2D基础模型细化3D语义时，缺乏统一的3D表示，导致视图不一致。此外，固有的开放词汇挑战导致对象和关系描述不一致，阻碍了分层语义理解。

**Method:** 本文提出了Hi-LSplat，一个用于3D开放词汇查询的视图一致分层语言高斯泼溅工作。为实现视图一致的3D分层语义，首先通过分层实例聚类构建3D分层语义树，将2D特征提升到3D特征，解决2D语义特征导致的视图不一致问题。此外，引入实例级和部分级对比损失以捕获全面的分层语义表示。值得注意的是，构建了两个分层语义数据集以更好地评估模型能力。

**Result:** 广泛的实验突出显示了该方法在3D开放词汇分割和定位方面的优越性。其在分层语义数据集上的强大性能强调了其捕获3D场景中复杂分层语义的能力。

**Conclusion:** Hi-LSplat通过引入3D分层语义树和对比损失，有效解决了3D语言高斯泼溅中的视图不一致和分层语义理解问题，并在3D开放词汇任务上表现出色。

> **ai_Abstract:** 本文提出了Hi-LSplat，一个针对3D开放词汇查询的视图一致分层语言高斯泼溅模型。它通过构建3D分层语义树将2D特征提升到3D，并引入实例级和部分级对比损失，解决了现有方法中视图不一致和分层语义理解不足的问题。实验证明，Hi-LSplat在3D开放词汇分割和定位方面表现优异，并能有效捕获复杂的3D分层语义。

> **摘要翻译:** 标题：Hi-LSplat: 分层3D语言高斯泼溅

摘要：
最近，利用高斯泼溅建模3D语言场以实现开放式语言查询受到了越来越多的关注。然而，最近基于3DGS的模型利用依赖于视图的2D基础模型来细化3D语义，但缺乏统一的3D表示，导致视图不一致。此外，固有的开放词汇挑战导致对象和关系描述不一致，阻碍了分层语义理解。在本文中，我们提出了Hi-LSplat，一个用于3D开放词汇查询的视图一致分层语言高斯泼溅工作。为了实现视图一致的3D分层语义，我们首先通过分层实例聚类构建3D分层语义树，将2D特征提升到3D特征，从而解决了由2D语义特征引起的视图不一致问题。此外，我们引入了实例级和部分级对比损失，以捕获全面的分层语义表示。值得注意的是，我们构建了两个分层语义数据集，以更好地评估模型区分不同语义层级的能力。广泛的实验突出显示了我们的方法在3D开放词汇分割和定位方面的优越性。其在分层语义数据集上的强大性能强调了其捕获3D场景中复杂分层语义的能力。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [296] [Exploring Visual Prompting: Robustness Inheritance and Beyond](https://arxiv.org/abs/2506.06823)
> *探索视觉提示：鲁棒性继承及超越*

*Qi Li, Liangzhi Li, Zhouqiang Jiang, Bowen Wang, Keke Tang* | **Main category: cs.CV**

**Keywords:** 视觉提示, 鲁棒性继承, 泛化能力, 提示边界松弛, 迁移学习

**Comment:** arXiv admin note: substantial text overlap with arXiv:2311.10992

> **TL;DR:** 本文首次探讨了视觉提示（VP）在鲁棒源模型下的表现，发现鲁棒性可以继承但存在权衡，并提出PBL策略来缓解这一问题，显著提升了VP的泛化能力。

**AI_Comments:** 这篇论文创新性地将视觉提示（VP）的研究扩展到鲁棒源模型场景，填补了现有研究的空白。其提出的PBL策略具有轻量级和即插即用的优点，为提升VP在鲁棒性任务中的泛化能力提供了有效途径，具有重要的实践意义和潜在的应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注标准源模型下的视觉提示（VP），但对于鲁棒源模型下VP的性能尚不清楚，特别是鲁棒性能否成功继承，以及是否存在鲁棒性与泛化能力之间的权衡，以及如何缓解这一限制。

**Method:** 本文首次深入探讨了视觉提示（VP）在鲁棒源模型下的三个关键问题，并提出了名为“提示边界松弛（Prompt Boundary Loosening, PBL）”的策略来缓解VP所面临的权衡问题。PBL是一种轻量级、即插即用的策略。

**Result:** 研究发现鲁棒源模型的鲁棒性可以成功继承到视觉提示（VP）中，但存在鲁棒性与泛化能力之间的权衡。提出的PBL策略作为一种轻量级、即插即用的方法，在确保鲁棒性成功继承的同时，显著增强了VP在各种下游数据集上的泛化能力。广泛的实验表明这些发现是普遍的。

**Conclusion:** 本文首次全面回答了视觉提示（VP）在鲁棒源模型下的关键问题，证明了鲁棒性继承的可行性及权衡的存在，并成功开发了PBL策略来有效缓解这一权衡，显著提升了VP的性能和泛化能力，为VP在鲁棒性场景下的应用提供了重要指导。

> **ai_Abstract:** 本文首次系统探究了视觉提示（VP）在鲁棒源模型场景下的表现，回答了鲁棒性继承、鲁棒性与泛化能力权衡等关键问题。研究发现鲁棒性可以继承但存在权衡，并提出了一种名为“提示边界松弛（PBL）”的轻量级即插即用策略。PBL能够有效确保鲁棒性继承，并显著提升VP在不同下游数据集上的泛化能力，实验证实了其普适性和有效性。

> **摘要翻译:** 视觉提示（VP）作为一种高效的迁移学习方法，已在视觉任务中展现出其潜力。然而，以往的工作只专注于标准源模型下的VP，它在鲁棒源模型场景下的表现仍然未知：源模型的鲁棒性能否成功继承？在此过程中，VP是否也会像源模型一样，面临鲁棒性和泛化能力之间的权衡？如果存在这种权衡，是否有专门针对VP的策略来缓解这一局限性？在本文中，我们首次彻底探讨了这三个问题，并给出了肯定的答案。为了缓解VP面临的权衡，我们提出了一种名为“提示边界松弛（Prompt Boundary Loosening, PBL）”的策略。作为一种轻量级、即插即用的策略，它与VP天然兼容，当源模型是鲁棒模型时，PBL能有效确保鲁棒性的成功继承，同时显著增强VP在各种下游数据集上的泛化能力。对各种数据集进行的广泛实验表明，我们的发现是普遍的，并展示了所提出策略的显著优势。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [302] [Controllable Coupled Image Generation via Diffusion Models](https://arxiv.org/abs/2506.06826)
> *通过扩散模型实现可控耦合图像生成*

*Chenfei Yuan, Nanshan Jia, Hangqi Li, Peter W. Glynn, Zeyu Zheng* | **Main category: cs.CV**

**Keywords:** 耦合图像生成, 扩散模型, 注意力控制, 图像生成, 交叉注意力

**Comment:** 

> **TL;DR:** 本文提出了一种基于注意力层控制的方法，用于生成背景相似但前景物体可变的耦合图像，并通过优化权重控制参数在性能上超越现有方法。

**AI_Comments:** 这项工作创新性地提出了在扩散模型中通过注意力层控制实现耦合图像生成，有效地解决了背景一致性和前景多样性之间的平衡问题。这种精细化的控制方法为图像生成带来了新的可能性，尤其是在需要生成系列图像时。未来的工作可以探索这种控制方法在更多复杂场景或多模态生成中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 在耦合图像生成任务中，需要生成多张背景相同或相似但中心物体可以根据不同文本提示灵活变化图像。现有方法可能难以同时实现背景耦合和前景灵活性的平衡。

**Method:** 本文提出了一种注意力层控制方法。该方法在模型的交叉注意力模块中解耦了背景和实体组件，并附加了一系列随时间步变化的权重控制参数。通过结合评估背景耦合度、文本到图像对齐以及整体视觉质量的目标函数来优化这些权重控制参数。

**Result:** 实证结果表明，在背景耦合度、文本到图像对齐和整体视觉质量等标准上，本文方法优于现有方法。

**Conclusion:** 本文提出的注意力层控制方法能够有效地实现可控的耦合图像生成，在保持背景一致性的同时，允许前景物体根据不同的文本提示进行灵活变化，并展现出优于现有方法的性能。

> **ai_Abstract:** 本研究提出了一种基于扩散模型的注意力层控制方法，用于实现可控的耦合图像生成。该方法通过在交叉注意力模块中解耦背景和前景实体，并引入随时间变化的权重控制参数来优化背景耦合度、文本到图像对齐和视觉质量。实验结果表明，该方法在生成背景一致且前景灵活的耦合图像方面优于现有技术。

> **摘要翻译:** 我们为耦合图像生成任务提供了一种注意力层控制方法，“耦合”意味着多个同时生成的图像预期具有相同或非常相似的背景。在背景耦合的同时，生成的图像中的中心对象仍然有望享受不同文本提示带来的灵活性。所提出的方法在模型的交叉注意力模块中解耦了背景和实体组件，并附加了一系列取决于采样时间步的随时间变化的权重控制参数。我们通过一个组合目标来优化这一系列权重控制参数，该目标评估背景的耦合程度以及文本到图像的对齐和整体视觉质量。实证结果表明，我们的方法在这些标准上优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [308] [EndoARSS: Adapting Spatially-Aware Foundation Model for Efficient Activity Recognition and Semantic Segmentation in Endoscopic Surgery](https://arxiv.org/abs/2506.06830)
> *EndoARSS：在内窥镜手术中适应空间感知基础模型以实现高效活动识别和语义分割*

*Guankun Wang, Rui Tang, Mengya Xu, Long Bai, Huxin Gao, Hongliang Ren* | **Main category: cs.CV**

**Keywords:** 内窥镜手术, 活动识别, 语义分割, 多任务学习, 基础模型

**Comment:** Accepted by Advanced Intelligent Systems

> **TL;DR:** EndoARSS是一个基于DINOv2的多任务学习框架，通过低秩适应和空间感知注意力，显著提升了内窥镜手术中活动识别和语义分割的性能。

**AI_Comments:** 该论文的创新点在于将DINOv2基础模型应用于内窥镜手术场景，并结合多任务学习策略，通过引入低秩适应和空间感知注意力机制有效解决了传统模型面临的跨任务干扰和特征辨别力不足的问题。同时，新发布的数据集也为该领域的研究提供了宝贵的资源。其重要性在于显著提升了内窥镜手术环境理解的准确性和效率，对未来AI辅助手术系统的发展具有重要推动作用。

<details>
  <summary>Details</summary>

**Motivation:** 内窥镜手术场景复杂，存在高变异性和目标与背景间混淆的图像特征，导致传统深度学习模型在跨活动干扰下性能不佳。

**Method:** 本文提出了EndoARSS，一个专门为内窥镜手术活动识别和语义分割设计的新型多任务学习框架。该框架建立在DINOv2基础模型之上，集成了低秩适应（Low-Rank Adaptation）以促进高效微调，并引入任务高效共享低秩适应器（Task Efficient Shared Low-Rank Adapters）以缓解不同任务之间的梯度冲突。此外，还引入了空间感知多尺度注意力（Spatially-Aware Multi-Scale Attention）以增强特征表示的辨别力。为评估框架有效性，提出了三个新数据集：MTLESD、MTLEndovis和MTLEndovis-Gen。

**Result:** EndoARSS在多个基准测试中取得了卓越的性能，与现有模型相比，显著提高了准确性和鲁棒性。

**Conclusion:** EndoARSS有潜力推动AI驱动的内窥镜手术系统发展，为提高手术安全性和效率提供有价值的见解。

> **ai_Abstract:** 本文提出了EndoARSS，一个用于内窥镜手术活动识别和语义分割的新型多任务学习框架。该框架基于DINOv2基础模型，通过引入低秩适应和任务高效共享低秩适应器来高效微调并解决任务间梯度冲突，同时利用空间感知多尺度注意力增强特征辨别力。研究还发布了三个新数据集。实验证明EndoARSS在准确性和鲁棒性方面均显著优于现有模型，有望提升AI驱动手术系统的性能。

> **摘要翻译:** 内窥镜手术是机器人辅助微创手术的黄金标准，在早期疾病检测和精确干预方面具有显著优势。然而，手术场景的复杂性，表现为不同手术活动场景中的高变异性以及目标与背景之间混淆的图像特征，给手术环境理解带来了挑战。传统的深度学习模型常常难以应对跨活动干扰，导致在每个下游任务中表现不佳。为了解决这一局限性，我们探索了多任务学习，它利用任务之间相互关联的特征来提高整体任务性能。在本文中，我们提出了EndoARSS，一个专门为内窥镜手术活动识别和语义分割设计的新型多任务学习框架。我们的方法建立在DINOv2基础模型之上，集成了低秩适应（Low-Rank Adaptation）以促进高效微调，同时结合了任务高效共享低秩适应器（Task Efficient Shared Low-Rank Adapters）以缓解不同任务之间的梯度冲突。此外，我们引入了空间感知多尺度注意力（Spatially-Aware Multi-Scale Attention），通过实现全局信息的跨空间学习来增强特征表示的辨别力。为了评估我们框架的有效性，我们提出了三个新颖的数据集：MTLESD、MTLEndovis和MTLEndovis-Gen，它们专为内窥镜手术场景量身定制，并包含活动识别和语义分割任务的详细标注。广泛的实验表明，EndoARSS在多个基准测试中取得了卓越的性能，与现有模型相比，显著提高了准确性和鲁棒性。这些结果强调了EndoARSS推动AI驱动内窥镜手术系统的潜力，为提高手术安全性和效率提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [310] [Harnessing Vision-Language Models for Time Series Anomaly Detection](https://arxiv.org/abs/2506.06836)
> *利用视觉-语言模型进行时间序列异常检测*

*Zelin He, Sarah Alnegheimish, Matthew Reimherr* | **Main category: cs.CV**

**Keywords:** 时间序列异常检测, 视觉-语言模型, VLM4TS, ViT4TS, 视觉推理

**Comment:** 

> **TL;DR:** 本文提出了一种两阶段解决方案VLM4TS，利用视觉-语言模型（VLM）进行时间序列异常检测（TSAD），无需时间序列训练即可显著优于现有基线方法。

**AI_Comments:** 该论文的创新之处在于将视觉-语言模型（VLM）引入时间序列异常检测领域，通过将时间序列转换为2D表示，并结合VLM的推理能力，弥补了传统方法在上下文视觉-时间推理上的不足。其两阶段设计（ViT4TS进行初步筛选，VLM4TS进行精细化检测）提高了效率和准确性。特别值得注意的是，该方法在不进行时间序列特定训练的情况下，仍能超越现有基线，这表明了VLM在跨领域应用上的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有时间序列异常检测方法主要侧重于数值数据上的领域特定模型训练，缺乏人类专家识别上下文异常所具备的视觉-时间推理能力。尽管视觉语言模型（VLMs）在视觉推理任务中表现出色，但直接应用于时间序列的准确性和效率不足。

**Method:** 本文提出了一种两阶段解决方案：1. ViT4TS：一个基于轻量级预训练视觉编码器的视觉筛选阶段，利用二维时间序列表示准确地定位候选异常。2. VLM4TS：一个基于VLM的阶段，整合全局时间上下文和VLM推理能力，对ViT4TS提供的候选异常进行精细检测。

**Result:** VLM4TS在大多数情况下优于时间序列预训练和从头开始的基线方法，F1-max分数比最佳基线提高了24.6%。此外，VLM4TS持续优于现有的基于语言模型的TSAD方法，并且在Token使用效率上平均提高了36倍。

**Conclusion:** 本文提出了一种新颖的两阶段方法VLM4TS，成功地利用视觉语言模型的能力进行时间序列异常检测，并在准确性和效率方面取得了显著提升，无需时间序列训练。

> **ai_Abstract:** 本文提出了一种名为VLM4TS的两阶段时间序列异常检测（TSAD）框架，旨在克服传统方法在视觉-时间推理方面的不足。第一阶段ViT4TS使用轻量级视觉编码器定位候选异常，第二阶段VLM4TS则利用视觉语言模型（VLM）整合全局上下文进行精细化检测。实验证明，VLM4TS无需时间序列训练，在F1-max分数上比现有基线提高了24.6%，并且在Token使用效率上平均提高了36倍，显著优于现有方法。

> **摘要翻译:** 时间序列异常检测（TSAD）在医疗保健、金融和工业监测等多个领域发挥着至关重要的作用。以往的方法主要侧重于在数值数据上训练领域特定模型，缺乏人类专家识别上下文异常所具备的视觉-时间推理能力。为了弥补这一空白，我们探索了一种基于视觉语言模型（VLMs）的解决方案。最近的研究表明VLM在视觉推理任务中具有能力，但它们直接应用于时间序列在准确性和效率上都表现不佳。为了利用VLM的强大能力进行TSAD，我们提出了一种两阶段解决方案：(1) ViT4TS，一个建立在相对轻量级预训练视觉编码器上的视觉筛选阶段，它利用二维时间序列表示来准确地定位候选异常；(2) VLM4TS，一个基于VLM的阶段，它整合了全局时间上下文和VLM推理能力，以在ViT4TS提供的候选基础上细化检测。我们展示了在没有任何时间序列训练的情况下，VLM4TS在大多数情况下优于时间序列预训练和从头开始的基线，与最佳基线相比，F1-max分数提高了24.6%。此外，VLM4TS也持续优于现有的基于语言模型的TSAD方法，并且在Token使用效率上平均提高了36倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [316] [Multi-StyleGS: Stylizing Gaussian Splatting with Multiple Styles](https://arxiv.org/abs/2506.06846)
> *Multi-StyleGS：使用多种风格对高斯溅射进行风格化*

*Yangkai Lin, Jiabao Lei, Kui jia* | **Main category: cs.CV**

**Keywords:** 高斯溅射, 3D风格化, 多风格, 语义风格迁移, 内存高效

**Comment:** AAAI 2025

> **TL;DR:** 提出Multi-StyleGS，一种新的3D高斯溅射风格化方法，能够以内存高效的方式将多种风格应用于3D场景，并实现了更好的风格化效果和灵活编辑。

**AI_Comments:** 这篇论文在3D场景风格化领域做出了重要贡献，特别是在将多种艺术风格应用于高斯溅射模型方面。其创新点在于结合了二分匹配和语义分割网络来实现精细的局部风格迁移，同时解决了内存效率问题，这对于实际应用非常关键。该方法提高了风格化结果的真实感和编辑的灵活性，为3D内容创作提供了强大的新工具。

<details>
  <summary>Details</summary>

**Motivation:** 3D场景风格化需求日益增长，但现有的3D高斯溅射（GS）方法在自动或手动指定多种风格以及保持内存效率方面存在挑战。

**Method:** 引入Multi-StyleGS方案，采用二分匹配机制自动识别风格图像与渲染图像局部区域的对应关系；提出一种新的语义风格损失函数，结合分割网络将不同风格应用于场景中的各种对象；提出局部-全局特征匹配以增强多视图一致性；还提出多种技术来正则化分割网络，以更好地为每个高斯分配鲁棒的语义标签。

**Result:** 实验证明，该方法在生成合理的风格化结果和提供灵活编辑方面优于现有方法，并能实现更高的纹理细节和更好的色彩匹配。

**Conclusion:** 本文提出的Multi-StyleGS有效解决了3D高斯溅射多风格化的挑战，实现了内存高效的训练，并取得了优越的风格化效果和灵活的编辑能力。

> **ai_Abstract:** 本文针对3D高斯溅射（GS）在多风格化和内存效率方面的挑战，提出了一种名为Multi-StyleGS的新型解决方案。该方法通过引入二分匹配机制、语义风格损失函数（结合分割网络实现局部风格迁移）以及局部-全局特征匹配来增强多视图一致性。此外，Multi-StyleGS还实现了内存高效的训练，并能生成更丰富的纹理细节和更准确的色彩匹配。实验结果表明，Multi-StyleGS在生成逼真的风格化效果和提供灵活编辑方面优于现有方法。

> **摘要翻译:** 近年来，为了创意目的，对给定3D场景进行风格化以使其与参考图像的艺术风格保持一致的需求日益增长。虽然3D高斯溅射（GS）已成为一种有前景且高效的真实3D场景建模方法，但在使其适应通过自动局部风格迁移或手动指定来匹配多种风格，同时保持风格化训练的内存效率方面仍然存在挑战。在本文中，我们引入了一种新颖的3D GS风格化解决方案，称为Multi-StyleGS，以解决这些挑战。特别是，我们采用二分匹配机制自动识别风格图像与渲染图像局部区域之间的对应关系。为了促进局部风格迁移，我们引入了一种新颖的语义风格损失函数，该函数采用分割网络将不同风格应用于场景中的各种对象，并提出局部-全局特征匹配以增强多视图一致性。此外，该技术可以实现内存高效的训练，更多的纹理细节和更好的色彩匹配。为了更好地为每个高斯分配鲁棒的语义标签，我们提出了几种技术来正则化分割网络。正如我们全面的实验所证明的，我们的方法在生成合理的风格化结果和提供灵活编辑方面优于现有方法。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [320] [Deep Inertial Pose: A deep learning approach for human pose estimation](https://arxiv.org/abs/2506.06850)
> *深度惯性姿态：一种用于人体姿态估计的深度学习方法*

*Sara M. Cerqueira, Manuel Palermo, Cristina P. Santos* | **Main category: cs.CV**

**Keywords:** 人体姿态估计, 深度学习, 惯性传感器, 神经网络, 运动捕捉

**Comment:** 

> **TL;DR:** 该研究探索使用神经网络进行人体姿态估计，以替代复杂的生物力学模型，并发现混合LSTM-Madgwick方法在惯性传感器数据上表现良好，结果可与现有技术媲美。

**AI_Comments:** 该论文探索了深度学习在人体姿态估计领域的应用，旨在简化传统惯性运动捕捉系统所需的复杂生物力学建模。其创新点在于将神经网络应用于处理惯性测量单元（IMU）数据，以直接估计人体姿态，从而可能降低成本并提高易用性。论文通过比较不同网络架构和进行消融研究，提供了关于影响姿态估计性能的关键因素的见解。研究结果表明，深度学习方法在性能上可以与现有先进技术相媲美，这对于可穿戴运动捕捉技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 惯性运动捕捉系统因其可穿戴性和无约束使用而受到关注，但准确的人体关节估计需要复杂且专业的步骤，导致软件成本高昂。本研究旨在探索使用神经网络来简化人体姿态估计所需的复杂生物力学模型和分析数学。

**Method:** 本研究比较了不同的神经网络架构和方法，以评估它们在人体姿态估计中的准确性。实验使用了低成本（MPU9250）和高端（Mtw Awinda）的磁、角速率和重力（MARG）传感器数据。此外，还进行了一项消融研究，探讨了数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。

**Result:** 最有效的方法是Hybrid LSTM-Madgwick detached，使用Mtw Awinda数据时，其四元数角度距离误差为7.96。消融研究分析了数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。

**Conclusion:** 本研究表明，神经网络可以被训练用于人体姿态估计，并且其结果可与最先进的融合滤波器相媲美。

> **ai_Abstract:** 本研究提出了一种利用深度学习进行人体姿态估计的方法，旨在克服传统惯性运动捕捉系统在准确性方面的复杂性和高成本问题。研究比较了不同神经网络架构，并使用低成本和高端惯性传感器数据进行评估。结果显示，Hybrid LSTM-Madgwick detached方法表现最佳，误差为7.96。此外，通过消融研究分析了多个因素对估计误差的影响。研究表明，神经网络在人体姿态估计方面能达到与现有先进融合滤波器相当的性能。

> **摘要翻译:** 基于惯性的运动捕捉系统因其可穿戴性和无约束使用而受到越来越多的关注。然而，准确的人体关节估计需要几个复杂且专业要求高的步骤，这导致了昂贵的软件，例如Xsens Technologies最先进的MVN Awinda。这项工作旨在研究使用神经网络来抽象姿态估计所需的复杂生物力学模型和分析数学。因此，它比较了不同的神经网络架构和方法，以了解这些方法在使用低成本（MPU9250）和高端（Mtw Awinda）磁、角速率和重力（MARG）传感器时，能够多准确地估计人体姿态。最有效的方法是Hybrid LSTM-Madgwick detached，使用Mtw Awinda数据时，其四元数角度距离误差为7.96。此外，还进行了一项消融研究，以研究数据增强、输出表示、窗口大小、损失函数和磁力计数据对姿态估计误差的影响。这项工作表明，神经网络可以被训练用于估计人体姿态，其结果可与最先进的融合滤波器相媲美。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [325] [Position Prediction Self-Supervised Learning for Multimodal Satellite Imagery Semantic Segmentation](https://arxiv.org/abs/2506.06852)
> *多模态卫星图像语义分割中的位置预测自监督学习*

*John Waithaka, Moise Busogi* | **Main category: cs.CV**

**Keywords:** 自监督学习, 语义分割, 卫星图像, 位置预测, 多模态

**Comment:** 

> **TL;DR:** 本文提出了一种基于位置预测的自监督学习方法，用于多模态卫星图像语义分割，在定位任务上优于基于重建的方法。

**AI_Comments:** 本文的创新点在于将位置预测自监督学习范式引入到多模态卫星图像语义分割领域，解决了传统重建方法在定位能力上的不足。通过适应卫星数据特性，特别是处理多模态信息和促进跨模态交互，该方法为卫星图像分析提供了新的有效途径。其重要性在于为数据稀缺的地球观测任务提供了一种更高效的预训练策略。

<details>
  <summary>Details</summary>

**Motivation:** 卫星图像语义分割在地球观测中至关重要，但受限于标注训练数据稀缺。现有的自监督预训练方法（如MAE）侧重于重建而非分割任务中关键的定位。

**Method:** 提出将LOCA（位置感知）方法适应于多模态卫星图像语义分割。该方法通过扩展SatMAE的通道分组以处理多模态数据，并引入同组注意力掩码以促进预训练期间的跨模态交互。它使用相对补丁位置预测来鼓励空间推理以实现定位。

**Result:** 在Sen1Floods11洪水测绘数据集上，该方法显著优于现有的基于重建的卫星图像自监督学习方法。

**Conclusion:** 结果表明，位置预测任务在适当适应多模态卫星图像时，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。

> **ai_Abstract:** 本文提出了一种名为LOCA的位置预测自监督学习方法，用于解决多模态卫星图像语义分割中标注数据稀缺的问题。该方法通过扩展SatMAE的通道分组并引入同组注意力掩码来处理多模态数据，并利用相对补丁位置预测来促进定位推理。实验结果表明，该方法在洪水测绘数据集上显著优于现有的基于重建的自监督学习方法，证明了位置预测在学习更有效表示方面的优势。

> **摘要翻译:** 卫星图像的语义分割对于地球观测应用至关重要，但仍受限于有限的标注训练数据。尽管像掩码自编码器（MAE）这样的自监督预训练方法已显示出前景，但它们侧重于重建而非定位——这是分割任务的一个基本方面。我们提出将LOCA（位置感知）这一位置预测自监督学习方法应用于多模态卫星图像语义分割。我们的方法通过将SatMAE的通道分组从多光谱扩展到多模态数据来解决卫星数据独特的挑战，从而能够有效处理多种模态，并在预训练期间引入同组注意力掩码以鼓励跨模态交互。该方法使用相对补丁位置预测，鼓励空间推理以实现定位而非重建。我们在Sen1Floods11洪水测绘数据集上评估了我们的方法，它显著优于现有的基于重建的卫星图像自监督学习方法。我们的结果表明，位置预测任务在适当适应多模态卫星图像时，学习到的表示比基于重建的方法更有效地用于卫星图像语义分割。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [330] [DONUT: A Decoder-Only Model for Trajectory Prediction](https://arxiv.org/abs/2506.06854)
> *DONUT：一种用于轨迹预测的仅解码器模型*

*Markus Knoche, Daan de Geus, Bastian Leibe* | **Main category: cs.CV**

**Keywords:** 轨迹预测, 仅解码器模型, 自动驾驶, 自回归模型, 超预测

**Comment:** 

> **TL;DR:** DONUT是一种受语言模型启发的仅解码器模型，通过单一自回归模型和“超预测”策略，在自动驾驶轨迹预测中超越了现有方法并取得了最先进的结果。

**AI_Comments:** DONUT的创新之处在于将语言模型中成功的仅解码器架构和多令牌预测（超预测）策略应用于轨迹预测任务，这提供了一种新颖且有效的建模范式。其自回归和信息更新的特性，以及辅助的超预测任务，显著提升了模型性能，并在自动驾驶领域展现了重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶中预测场景中其他智能体的运动至关重要，因为它能让自动驾驶汽车进行预判。

**Method:** 提出DONUT（Decoder-Only Network for Unrolling Trajectories），与现有编解码器预测模型不同，它使用单一自回归模型编码历史轨迹并预测未来轨迹，实现了迭代预测和信息更新。此外，引入“超预测”策略，将预测更长时间范围轨迹作为辅助任务。

**Result:** 实验证明，DONUT的仅解码器方法优于编解码器基线，并在Argoverse 2单智能体运动预测基准测试中取得了新的最先进结果。

**Conclusion:** DONUT通过其独特的仅解码器架构和“超预测”策略，显著提升了轨迹预测性能，并在相关基准测试中达到了最先进水平。

> **ai_Abstract:** 本文提出了DONUT，一种受语言模型启发的仅解码器网络，用于自动驾驶中的轨迹预测。与传统的编解码器模型不同，DONUT采用单一自回归模型处理历史和未来轨迹，并引入“超预测”策略以增强长期预测能力。实验结果表明，DONUT在Argoverse 2基准测试中超越了现有编解码器方法，并达到了最先进的性能。

> **摘要翻译:** 预测场景中其他智能体的运动与自动驾驶高度相关，因为它能让自动驾驶汽车进行预判。受语言建模中仅解码器模型成功的启发，我们提出了DONUT，一个用于展开轨迹的仅解码器网络（Decoder-Only Network for Unrolling Trajectories）。与现有编解码器预测模型不同，我们使用单一自回归模型编码历史轨迹并预测未来轨迹。这使得模型能够以一致的方式进行迭代预测，并确保模型始终获得最新信息，从而提高性能。此外，受语言建模中多令牌预测的启发，我们引入了一种“超预测”策略，赋予网络在更长的时间范围内预测轨迹的辅助任务。这使得模型能够更好地预判未来，并进一步提高性能。通过实验，我们证明了我们的仅解码器方法优于编解码器基线，并在Argoverse 2单智能体运动预测基准测试中取得了新的最先进结果。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [336] [Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning](https://arxiv.org/abs/2506.06856)
> *视觉-EKIPL：用于视觉推理的外部知识注入策略学习*

*Chaoyang Wang, Zeyu Zhang, Haiyun Jiang* | **Main category: cs.CV**

**Keywords:** 视觉推理, 强化学习, 多模态大语言模型, 外部知识注入, 策略学习

**Comment:** 

> **TL;DR:** Vision-EKIPL通过引入外部高质量动作来指导策略模型优化，显著提升了多模态大语言模型（MLLMs）的视觉推理能力和训练效率。

**AI_Comments:** Vision-EKIPL的创新点在于将外部知识引入到强化学习的策略学习过程中，这有效地突破了传统RL方法中动作空间受限于策略模型本身的瓶颈。这种方法不仅提升了模型性能，还显著提高了训练效率，为未来多模态推理模型的设计提供了有价值的参考。

<details>
  <summary>Details</summary>

**Motivation:** 现有强化学习方法在多模态大语言模型（MLLMs）中进行推理时，动作组仅从策略模型本身采样，这限制了模型的推理能力上限并导致训练效率低下。

**Method:** 本文提出了一种名为Vision-EKIPL的新型强化学习框架。其核心是在强化学习训练过程中引入由外部辅助模型生成的高质量动作来指导策略模型的优化。这种知识注入显著扩展了模型的探索空间。

**Result:** Vision-EKIPL在Reason-RFT-CoT基准测试上比现有最佳方法（SOTA）提高了高达5%的性能。

**Conclusion:** Vision-EKIPL能够克服传统强化学习方法的局限性，显著增强MLLMs的视觉推理性能，并为该领域的研究提供了一种新的有效范式。

> **ai_Abstract:** 本文提出了Vision-EKIPL，一个新颖的强化学习框架，旨在解决现有RL方法在多模态大语言模型（MLLMs）视觉推理中动作采样受限和训练效率低下的问题。Vision-EKIPL通过引入外部辅助模型生成的高质量动作来指导策略模型优化，从而扩展探索空间，提高推理能力上限，并加速训练收敛。实验证明，Vision-EKIPL在特定基准测试上实现了显著的性能提升，为视觉推理领域提供了新的解决方案。

> **摘要翻译:** 视觉推理对于理解复杂的多模态数据和推进通用人工智能至关重要。现有方法通过强化学习（RL）微调（例如GRPO）增强多模态大语言模型（MLLMs）的推理能力。然而，当前的RL方法仅从策略模型本身采样动作组，这限制了模型的推理能力上限并导致训练效率低下。为了解决这些局限性，本文提出了一种名为Vision-EKIPL的新型RL框架。该框架的核心是在RL训练过程中引入由外部辅助模型生成的高质量动作来指导策略模型的优化。这种从外部模型注入知识的策略学习显著扩展了模型的探索空间，有效提高了推理边界，并大大加速了训练收敛速度和效率。实验结果表明，我们提出的Vision-EKIPL在Reason-RFT-CoT基准测试上比现有最佳方法（SOTA）提高了高达5%的性能。这揭示了Vision-EKIPL可以克服传统RL方法的局限性，显著增强MLLMs的视觉推理性能，并为该领域的研究提供了一种新的有效范式。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [342] [Face recognition on point cloud with cgan-top for denoising](https://arxiv.org/abs/2506.06864)
> *基于cGAN-TOP去噪的点云人脸识别*

*Junyu Liu, Jianfeng Ren, Sunhong Liang, Xudong Jiang* | **Main category: cs.CV**

**Keywords:** 点云人脸识别, cGAN-TOP, 去噪, LDGCNN, 3D人脸识别

**Comment:** Published in ICASSP 2023

> **TL;DR:** 本文提出了一种端到端的3D噪声点云人脸识别方法，通过cGAN-TOP进行去噪，并结合LDGCNN进行识别，显著提高了噪声条件下的识别精度。

**AI_Comments:** 该论文的创新点在于将去噪和识别模块协同整合到一个端到端系统中，特别是在噪声点云人脸识别方面。cGAN-TOP的引入有效解决了3D点云数据中常见的噪声问题，并通过实验证明了其在提高识别精度方面的显著效果，对实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 由于传感器不完善，原始点云通常包含大量噪声，这阻碍了3D点云人脸识别的准确性，因此需要一种能够协同去噪和识别的端到端方法。

**Method:** 本文提出了一种端到端的3D噪声点云人脸识别方法。具体来说，设计了一个基于三正交平面的条件生成对抗网络（cGAN-TOP）来有效去除点云中的噪声并恢复底层特征。随后，采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸，该网络分层链接了局部点特征和多尺度邻近特征。

**Result:** 该方法在Bosphorus数据集上得到了验证，在所有噪声设置下均显著提高了识别精度，最大增益达到14.81%。

**Conclusion:** 本文提出的协同去噪和识别的端到端方法，通过cGAN-TOP和LDGCNN的结合，有效解决了噪声点云人脸识别的挑战，并显著提升了识别性能。

> **ai_Abstract:** 本文提出了一种用于噪声点云的端到端3D人脸识别系统，该系统创新性地整合了去噪和识别模块。其中，cGAN-TOP用于有效去除点云噪声并恢复特征，而LDGCNN则用于从处理后的点云中识别面部。该方法在Bosphorus数据集上验证，在不同噪声环境下均显著提高了识别准确率，最高提升了14.81%。

> **摘要翻译:** 三维点云人脸识别正日益受到关注，然而由于传感器不完善，原始点云通常包含大量噪声。本文提出了一种端到端的噪声点云三维人脸识别方法，该方法协同整合了去噪和识别模块。具体来说，设计了一种基于三正交平面的条件生成对抗网络（cGAN-TOP），以有效去除点云中的噪声并恢复用于后续识别的底层特征。然后，采用链接动态图卷积神经网络（LDGCNN）从处理后的点云中识别人脸，该网络分层链接了局部点特征和多尺度邻近特征。所提出的方法在Bosphorus数据集上进行了验证。它在所有噪声设置下均显著提高了识别精度，最大增益达到14.81%。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [345] [Hybrid Vision Transformer-Mamba Framework for Autism Diagnosis via Eye-Tracking Analysis](https://arxiv.org/abs/2506.06886)
> *混合视觉Transformer-Mamba框架用于眼动追踪分析的自闭症诊断*

*Wafaa Kasri, Yassine Himeur, Abigail Copiaco, Wathiq Mansoor, Ammar Albanna, Valsamma Eapen* | **Main category: cs.CV**

**Keywords:** 自闭症谱系障碍诊断, 眼动追踪, 视觉Transformer, Vision Mamba, 混合深度学习

**Comment:** 7 pages, 4 figures and 2 tables

> **TL;DR:** 提出了一种结合ViT和Vision Mamba的混合深度学习框架，通过眼动追踪数据诊断ASD，在Saliency4ASD数据集上表现优异，有望实现可扩展、可解释的ASD筛查。

**AI_Comments:** 这项研究的创新之处在于结合了ViT和Vision Mamba这两种先进的深度学习架构，并应用于眼动追踪数据进行ASD诊断，这提供了一种非侵入性且高效的诊断方法。其强调可解释AI和在资源受限环境下的潜力，增加了其实际应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确的自闭症谱系障碍（ASD）诊断对于早期干预至关重要。

**Method:** 本研究提出了一个结合Vision Transformers（ViT）和Vision Mamba的混合深度学习框架，用于通过眼动追踪数据检测ASD。该模型利用基于注意力的融合来整合视觉、语音和面部线索，捕捉空间和时间动态。与传统的手工方法不同，它应用了最先进的深度学习和可解释人工智能技术以提高诊断准确性和透明度。

**Result:** 在Saliency4ASD数据集上，所提出的ViT-Mamba模型优于现有方法，实现了0.96的准确率、0.95的F1分数、0.97的敏感性和0.94的特异性。

**Conclusion:** 该模型有望实现可扩展、可解释的ASD筛查，尤其适用于专家诊断资源有限的资源受限或偏远临床环境。

> **ai_Abstract:** 本研究提出了一个混合深度学习框架，结合Vision Transformers和Vision Mamba，利用眼动追踪数据进行自闭症谱系障碍（ASD）诊断。该模型通过注意力机制融合视觉、语音和面部线索，捕捉时空动态，并利用可解释AI提升诊断准确性和透明度。在Saliency4ASD数据集上的实验表明，该模型在准确率、F1分数、敏感性和特异性方面均超越现有方法，显示出其在ASD筛查，尤其是在资源受限环境中的应用前景。

> **摘要翻译:** 准确的自闭症谱系障碍（ASD）诊断对于早期干预至关重要。本研究提出了一种结合视觉Transformer（ViT）和视觉Mamba的混合深度学习框架，用于通过眼动追踪数据检测ASD。该模型利用基于注意力的融合来整合视觉、语音和面部线索，捕捉空间和时间动态。与传统的手工方法不同，它应用了最先进的深度学习和可解释人工智能技术，以提高诊断准确性和透明度。在Saliency4ASD数据集上进行测试，所提出的ViT-Mamba模型优于现有方法，实现了0.96的准确率、0.95的F1分数、0.97的敏感性和0.94的特异性。这些发现表明该模型在可扩展、可解释的ASD筛查方面的潜力，特别是在专家诊断资源有限的资源受限或偏远临床环境中。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [350] [NSD-Imagery: A benchmark dataset for extending fMRI vision decoding methods to mental imagery](https://arxiv.org/abs/2506.06898)
> *NSD-Imagery：一个用于将fMRI视觉解码方法扩展到心理意象的基准数据集*

*Reese Kneeland, Paul S. Scotti, Ghislain St-Yves, Jesse Breedlove, Kendrick Kay, Thomas Naselaris* | **Main category: cs.CV**

**Keywords:** fMRI, 视觉解码, 心理意象, 数据集, 脑机接口

**Comment:** Published at CVPR 2025

> **TL;DR:** 发布了NSD-Imagery数据集，用于评估fMRI视觉解码模型在心理意象重建上的表现。研究发现，解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的，并且简单的线性解码架构和多模态特征解码模型泛化能力更好。

**AI_Comments:** 该论文通过发布NSD-Imagery数据集，填补了fMRI视觉解码领域的一个重要空白，即从对“所见图像”的解码扩展到更具挑战性和实际应用价值的“心理意象”解码。其创新性在于提供了首个大规模的心理意象fMRI基准数据集，并揭示了现有模型在心理意象解码上的泛化能力差异，特别是指出了简单架构的优势。这对于推动脑机接口和医疗诊断等领域的发展具有重要意义，因为它为开发更实用、更通用的视觉解码方法提供了新的方向和评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大规模fMRI-to-图像重建模型（如在NSD上训练的模型）仅在“所见图像”重建上进行评估，而心理意象重建是一个具有挑战性的泛化要求，但对于医疗领域和脑机接口等实际应用至关重要，因为这些应用中的信息总是内部生成的。因此，需要一个基准数据集来评估和改进模型在心理意象解码方面的能力。

**Method:** 发布了NSD-Imagery数据集，该数据集包含人类fMRI活动与心理意象的配对数据，以补充现有的Natural Scenes Dataset (NSD)。使用NSD-Imagery，对一系列近期在NSD上训练的开源视觉解码模型（MindEye1, MindEye2, Brain Diffuser, iCNN, Takagi et al.）进行了基准测试。

**Result:** 解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的。模型架构选择显著影响交叉解码性能：采用简单线性解码架构和多模态特征解码的模型能更好地泛化到心理意象，而复杂架构倾向于过拟合视觉训练数据。

**Conclusion:** 心理意象数据集对于实际应用的发展至关重要。NSD-Imagery被确立为一个有用的资源，可以更好地使视觉解码方法与这一目标保持一致。

> **ai_Abstract:** 该研究发布了NSD-Imagery，一个将人类fMRI活动与心理意象配对的基准数据集，旨在弥补现有模型在“所见图像”重建上评估的局限性，并扩展到心理意象重建。通过对现有视觉解码模型在NSD-Imagery上进行基准测试，研究发现模型在心理意象上的解码性能与在所见图像上的性能是分离的，且简单的线性解码和多模态特征解码架构在泛化到心理意象方面表现更优。这强调了心理意象数据集对实际应用的重要性，并确立NSD-Imagery为视觉解码研究提供了关键资源。

> **摘要翻译:** 我们发布了NSD-Imagery，一个人类fMRI活动与心理意象配对的基准数据集，以补充现有的自然场景数据集（NSD），后者是一个大规模的fMRI活动与所见图像配对的数据集，使得fMRI到图像重建工作取得了前所未有的进展。最近在NSD上训练的模型仅在所见图像重建上进行了评估。通过使用NSD-Imagery，可以评估这些模型在心理意象重建上的表现。这是一个具有挑战性的泛化要求，因为心理意象在人脑活动中的编码信噪比和空间分辨率相对较低；然而，从所见图像到心理意象的泛化对于医疗领域和脑机接口等实际应用至关重要，因为所需信息总是内部生成的。我们提供了NSD-Imagery上一系列近期在NSD上训练的开源视觉解码模型（MindEye1、MindEye2、Brain Diffuser、iCNN、Takagi et al.）的基准测试，并表明解码方法在心理意象上的表现与视觉重建的表现很大程度上是脱钩的。我们进一步证明，架构选择显著影响交叉解码性能：采用简单线性解码架构和多模态特征解码的模型能更好地泛化到心理意象，而复杂架构倾向于过拟合视觉训练数据。我们的发现表明，心理意象数据集对于实际应用的发展至关重要，并确立NSD-Imagery作为一种有用的资源，可以更好地使视觉解码方法与这一目标保持一致。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [355] [KNN-Defense: Defense against 3D Adversarial Point Clouds using Nearest-Neighbor Search](https://arxiv.org/abs/2506.06906)
> *错误：AI分析失败。*

*Nima Jamali, Matina Mahdizadeh Sani, Hanieh Naderi, Shohreh Kasaei* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [359] [Gaussian Mapping for Evolving Scenes](https://arxiv.org/abs/2506.06909)
> *演化场景的高斯映射*

*Vladimir Yugay, Thies Kersten, Luca Carlone, Theo Gevers, Martin R. Oswald, Lukas Schmid* | **Main category: cs.CV**

**Keywords:** 高斯映射, 动态场景, 新视图合成, 长期动态, 关键帧管理

**Comment:** 

> **TL;DR:** 引入了一种动态场景适应机制和新颖的关键帧管理机制，用于高斯映射系统，以处理长期动态场景，并在准确性上超越现有技术。

**AI_Comments:** 这项工作通过解决高斯泼溅系统在动态场景，特别是长期动态场景中的应用挑战，迈出了重要一步。其创新点在于结合了动态场景适应和智能关键帧管理，这对于在复杂、不断变化的环境中实现鲁棒的3D重建至关重要。这对于增强现实、机器人和自动驾驶等领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D高斯泼溅映射系统在处理静态场景方面表现出色，但大多局限于静态场景。虽然一些工作开始解决短期动态问题，但长期动态（场景在视野外发生变化）仍未得到充分探索，这限制了这些系统在真实世界应用中的实用性。

**Method:** 我们引入了一种动态场景适应机制，用于持续更新3D表示以反映最新变化。此外，我们提出了一种新颖的关键帧管理机制，该机制通过丢弃过时观测同时尽可能保留信息来维护几何和语义一致性。

**Result:** 在合成和真实世界数据集上评估了演化场景的高斯映射（GaME），发现它比现有技术更准确。

**Conclusion:** 演化场景的高斯映射（GaME）通过其动态场景适应和关键帧管理机制，有效地解决了高斯泼溅映射系统在处理长期动态场景方面的局限性，并实现了更高的准确性。

> **ai_Abstract:** 本文提出了一种名为“演化场景的高斯映射”（GaME）的新型高斯映射系统，旨在解决现有3D高斯泼溅系统在处理长期动态场景时的局限性。GaME引入了动态场景适应机制以持续更新3D表示，并采用了一种新颖的关键帧管理机制来维护几何和语义一致性，通过丢弃过时观测来避免重建过程中的干扰。实验结果表明，GaME在合成和真实世界数据集上均比现有技术更准确。

> **摘要翻译:** 具有新视图合成（NVS）能力的映射系统在计算机视觉领域广泛应用，包括增强现实、机器人和自动驾驶。其中，基于3D高斯泼溅的系统表现出高NVS性能；然而，许多现有方法仅限于静态场景。尽管最近的工作已开始解决短期动态（相机视野内的运动），但长期动态（场景在视野外通过变化演化）仍较少被探索。为了克服这一限制，我们引入了一种动态场景适应机制，该机制持续更新3D表示以反映最新变化。此外，由于陈旧观测扰乱重建过程，维持几何和语义一致性仍然具有挑战性，因此我们提出了一种新颖的关键帧管理机制，该机制丢弃过时观测同时尽可能保留信息。我们在合成和真实世界数据集上评估了演化场景的高斯映射（GaME），发现它比现有技术更准确。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [363] [Sleep Stage Classification using Multimodal Embedding Fusion from EOG and PSM](https://arxiv.org/abs/2506.06912)
> *基于EOG和PSM多模态嵌入融合的睡眠阶段分类*

*Olivier Papillon, Rafik Goubran, James Green, Julien Larivière-Chartier, Caitlin Higginson, Frank Knoefel, Rébecca Robillard* | **Main category: cs.CV**

**Keywords:** 睡眠阶段分类, 多模态嵌入, EOG, PSM, ImageBind

**Comment:** Submitted to IEEE MeMeA 2025

> **TL;DR:** 本文利用ImageBind融合眼电图（EOG）和压力敏感垫（PSM）数据进行睡眠阶段分类，实现了高准确性，接近传统EEG方法，并适用于家庭监测。

**AI_Comments:** 本文的创新之处在于首次将PSM和EOG数据与ImageBind结合用于睡眠分期，并证明了预训练的多模态模型（即使源自非医学领域）在特定医学任务中的强大适应性。这为简化家庭睡眠监测提供了新的可能性，尤其对于老年人群的睡眠障碍诊断具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 诊断睡眠障碍需要准确的睡眠阶段分类，但传统多导睡眠图（PSG）/脑电图（EEG）复杂且不适合家庭监测。本文旨在利用眼电图（EOG）和压力敏感垫（PSM）等侵入性较小的方法解决此限制。

**Method:** 本文提出了一种新颖的方法，利用ImageBind多模态嵌入深度学习模型，融合压力敏感垫（PSM）数据和双通道眼电图（EOG）信号进行五阶段睡眠-觉醒分类。这是首次将PSM和EOG数据与ImageBind结合用于睡眠阶段分类的方法，并使用85晚患者记录进行评估。

**Result:** 经过微调的ImageBind显著提高了分类准确性，优于现有基于单通道EOG（DeepSleepNet）、PSM数据（ViViT）以及其他多模态深度学习方法（MBT）的模型。即使未经微调，模型也表现出强大性能，突出了其在有限标记数据下对特定任务的适应性，准确性接近需要复杂EEG数据的系统。

**Conclusion:** 预训练的多模态嵌入模型，即使最初是为非医学领域开发的，也可以有效地用于睡眠分期，其准确性接近需要复杂EEG数据的系统。

> **ai_Abstract:** 本文提出了一种新颖的五阶段睡眠分类方法，利用非侵入性眼电图（EOG）和压力敏感垫（PSM）数据。该方法利用ImageBind多模态深度学习模型融合这些不同数据源。结果表明，与现有单模态和其他多模态方法相比，该方法在分类准确性方面表现更优，即使未经广泛微调也具有强大性能，这表明其在医疗应用中的强大适应性以及在家庭睡眠监测中的潜力。

> **摘要翻译:** 准确的睡眠阶段分类对于诊断睡眠障碍至关重要，尤其是在老年人群中。虽然传统的多导睡眠图（PSG）依赖脑电图（EEG）作为金标准，但其复杂性以及对专业设备的需求使得居家睡眠监测变得具有挑战性。为了解决这一限制，我们研究了使用眼电图（EOG）和压力敏感垫（PSM）作为侵入性较小的替代方案，进行五阶段睡眠-觉醒分类。本研究引入了一种新颖的方法，利用ImageBind（一种多模态嵌入深度学习模型）来整合PSM数据与双通道EOG信号，用于睡眠阶段分类。我们的方法是首次报道的将PSM和EOG数据与ImageBind融合用于睡眠阶段分类的方法。我们的结果表明，微调ImageBind显著提高了分类准确性，优于现有基于单通道EOG（DeepSleepNet）、仅使用PSM数据（ViViT）以及其他多模态深度学习方法（MBT）的模型。值得注意的是，该模型即使在未经微调的情况下也取得了强大性能，这突出了其在有限标记数据下对特定任务的适应性，使其在医疗应用中尤其具有优势。我们使用来自睡眠诊所的85晚患者记录评估了我们的方法。我们的研究结果表明，预训练的多模态嵌入模型，即使是最初为非医学领域开发的模型，也可以有效地应用于睡眠分期，其准确性接近需要复杂EEG数据的系统。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [367] [Reading in the Dark with Foveated Event Vision](https://arxiv.org/abs/2506.06918)
> *使用中心凹事件视觉在黑暗中阅读*

*Carl Brander, Giovanni Cioffi, Nico Messikommer, Davide Scaramuzza* | **Main category: cs.CV**

**Keywords:** 事件视觉, OCR, 智能眼镜, 低光照, 带宽效率

**Comment:** CVPR 2025 Workshop on Event-based Vision

> **TL;DR:** 该论文提出了一种新颖的基于事件的OCR方法，用于智能眼镜在低光照和高速场景下阅读文本，通过注视点事件流显著降低带宽，并优于传统OCR。

**AI_Comments:** 这项工作具有显著的创新性，它将事件相机与注视点追踪技术相结合，极大地解决了智能眼镜在低光照和高动态场景下的感知难题。带宽的大幅减少（高达2400倍）是其最突出的优势之一，这将显著延长智能眼镜的电池续航时间。同时，结合多模态LLM进行OCR也体现了前沿技术的融合。这项技术对于增强AR/VR设备的实用性和用户体验具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 当前配备RGB摄像头的智能眼镜在低光照和高速运动场景下感知环境时，由于运动模糊和帧摄像头的有限动态范围而面临困难。此外，捕获密集图像需要大量带宽和功耗，从而更快地耗尽电池。这些挑战对于开发从图像中读取文本的算法尤为重要。

**Method:** 该研究提出了一种新颖的基于事件的智能眼镜光学字符识别（OCR）方法。通过利用用户的眼球注视，对事件流进行中心凹处理，显著减少了约98%的带宽，同时利用了事件摄像头在高动态和快速场景中的优势。所提出的方法执行在合成数据上训练的深度二值重建，并利用多模态LLM进行OCR。

**Result:** 该方法优于传统的OCR解决方案。它展示了在RGB摄像头难以工作的低光照环境下阅读文本的能力，并且比可穿戴RGB摄像头使用的带宽减少了多达2400倍。

**Conclusion:** 该论文成功开发了一种基于事件的OCR方法，解决了传统RGB摄像头在低光照和高带宽方面的限制，为智能眼镜在挑战性环境下的文本阅读提供了高效且高性能的解决方案。

> **ai_Abstract:** 该论文介绍了一种用于智能眼镜的新型基于事件的OCR方法，旨在克服传统RGB摄像头在低光照和高速运动场景中的局限性。通过利用用户眼球注视进行事件流的中心凹处理，该方法显著降低了带宽（98%），并利用事件摄像头在高动态范围和快速场景中的优势。该方法在合成数据上训练深度二值重建，并结合多模态LLM进行OCR，其性能优于传统解决方案，在低光照环境下也能有效阅读文本，并且带宽消耗比RGB摄像头少2400倍。

> **摘要翻译:** 论文标题：使用中心凹事件视觉在黑暗中阅读

论文摘要：当前配备RGB摄像头的智能眼镜在低光照和高速运动场景下感知环境时，由于运动模糊和帧摄像头的有限动态范围而面临困难。此外，使用帧摄像头捕获密集图像需要大量带宽和功耗，从而更快地耗尽电池。这些挑战对于开发能够从图像中读取文本的算法尤为重要。在这项工作中，我们提出了一种新颖的基于事件的智能眼镜光学字符识别（OCR）方法。通过利用用户的眼球注视，我们对事件流进行中心凹处理，显著减少了约98%的带宽，同时利用了事件摄像头在高动态和快速场景中的优势。我们提出的方法执行在合成数据上训练的深度二值重建，并利用多模态LLM进行OCR，优于传统的OCR解决方案。我们的结果表明，该方法能够在RGB摄像头难以工作的低光照环境下阅读文本，同时比可穿戴RGB摄像头使用的带宽减少了多达2400倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [372] [How Important are Videos for Training Video LLMs?](https://arxiv.org/abs/2506.06928)
> *视频对训练视频大型语言模型有多重要？*

*George Lydakis, Alexander Hermans, Ali Athar, Daan de Geus, Bastian Leibe* | **Main category: cs.CV**

**Keywords:** 视频大型语言模型, 时间推理, 图像训练, 视频训练, 效率瓶颈

**Comment:** Project page on
  https://visualcomputinginstitute.github.io/videollm-pseudovideo-training/

> **TL;DR:** 研究发现，视频大型语言模型（Video LLMs）在仅通过图像训练后，其时间推理能力比预期更强，而视频特有训练带来的提升却出奇地小，这表明当前模型可能未能充分利用视频中的丰富时间特征。

**AI_Comments:** 这篇论文的创新之处在于挑战了传统观念，即视频数据对于训练Video LLMs的时间推理能力至关重要。它揭示了当前视频训练方案可能存在的效率低下问题，并指出了仅通过图像训练的LLMs在时间推理方面的潜力，这为未来的研究提供了新的方向，即如何更有效地利用视频数据或探索图像训练模型时间推理的内在机制。

<details>
  <summary>Details</summary>

**Motivation:** 当前视频大型语言模型（Video LLMs）通常使用预训练的文本LLM并在图像和视频字幕数据集上进行微调。然而，本文旨在探究视频数据对于训练Video LLMs时间推理能力的重要性，因为研究发现仅通过图像训练的模型也能展现出意想不到的时间推理能力，且视频特有训练带来的提升有限。

**Method:** 研究使用了两种通过LongVU算法训练的LLM的图像训练版本，并在时间推理基准TVBench上进行测试。此外，论文还引入了一种简单的微调方案，该方案涉及带有注释图像序列和针对时间能力问题的训练。

**Result:** 仅通过图像训练的LLMs在TVBench时间推理基准上的表现显著高于随机水平。新引入的简单微调方案在时间推理性能上接近甚至有时超过了视频训练的LLMs所达到的水平。

**Conclusion:** 研究结果表明，当前模型可能未能充分利用真实视频中丰富的时序特征。这促使需要进一步研究允许图像训练的LLMs执行时序推理的机制，以及导致当前视频训练方案效率低下的瓶颈。

> **ai_Abstract:** 本研究探讨了视频数据在训练视频大型语言模型（Video LLMs）中的重要性。令人惊讶的是，研究发现仅通过图像训练的Video LLMs已具备显著的时间推理能力，而额外的视频特有训练带来的性能提升却微乎其微。论文通过在TVBench基准上的实验以及引入一种新的图像序列微调方案证明了这一点，该方案甚至能达到或超越视频训练模型的表现。这暗示了当前模型在利用视频丰富时间特征方面的不足，并呼吁进一步研究图像训练LLMs的时间推理机制和现有视频训练方案的效率瓶颈。

> **摘要翻译:** 视频大型语言模型（LLMs）的研究进展迅速，短短几年内就涌现出众多模型和基准。通常，这些模型以预训练的纯文本LLM作为初始化，并在图像和视频字幕数据集上进行微调。在本文中，我们提出的发现表明，Video LLMs在仅通过图像训练后，其时间推理能力比人们预想的更强，而视频特有训练带来的提升却出奇地小。具体而言，我们展示了使用近期LongVU算法训练的两种LLMs的图像训练版本在时间推理基准TVBench上的表现显著高于随机水平。此外，我们引入了一种简单的微调方案，该方案涉及带注释图像序列和针对时间能力的问题。这个基线在时间推理性能上接近，甚至偶尔高于，视频训练的LLMs所达到的水平。这表明当前模型对真实视频中丰富的时序特征利用不足。我们的分析促使进一步研究允许图像训练的LLMs执行时序推理的机制，以及导致当前视频训练方案效率低下的瓶颈。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [377] [Polar Hierarchical Mamba: Towards Streaming LiDAR Object Detection with Point Clouds as Egocentric Sequences](https://arxiv.org/abs/2506.06944)
> *极坐标分层Mamba：基于以自我为中心的点云序列的流式激光雷达目标检测*

*Mellon M. Zhang, Glen Chou, Saibal Mukhopadhyay* | **Main category: cs.CV**

**Keywords:** LiDAR, Object Detection, Streaming, Mamba, State Space Models

**Comment:** 

> **TL;DR:** 提出了一种名为PHiM的新型Mamba架构，用于流式LiDAR目标检测，它在Waymo数据集上实现了最先进的性能，超越了现有流式检测器并与全扫描基线持平，同时吞吐量翻倍。

**AI_Comments:** 这篇论文的创新点在于将Mamba架构引入到流式LiDAR目标检测领域，并针对极坐标系的特性进行了分层和维度分解的设计，有效解决了传统卷积在极坐标系下的失真问题以及现有Mamba模型不适用于流式处理的限制。其重要性在于为自动驾驶车辆的实时感知提供了更高效、更准确的解决方案，尤其是在低延迟和高吞吐量方面取得了显著突破。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶需要低延迟和高吞吐的实时感知。传统LiDAR目标检测方法处理360度全扫描会引入显著延迟。现有流式方法依赖与极坐标几何不匹配的卷积，导致性能下降或需要复杂的失真缓解。现有基于Mamba的模型仅适用于全扫描设置，内存密集且不适合流式处理。

**Method:** 提出极坐标分层Mamba (PHiM)，这是一种为极坐标流式LiDAR设计的SSM架构。PHiM使用局部双向Mamba块进行扇区内空间编码，并使用全局前向Mamba进行扇区间时间建模，用失真感知、维度分解的操作取代了卷积和位置编码。

**Result:** PHiM在Waymo Open Dataset上在流式检测器中达到了新的最先进水平，比之前的最佳性能提高了10%，并且在两倍吞吐量下与全扫描基线匹配。

**Conclusion:** PHiM成功解决了流式LiDAR目标检测中的挑战，通过其创新的SSM架构实现了卓越的性能和效率，使其成为自动驾驶领域的重要进展。

> **ai_Abstract:** 本文提出了一种名为极坐标分层Mamba (PHiM) 的新型状态空间模型（SSM）架构，专为解决流式激光雷达目标检测中的挑战而设计。PHiM通过结合局部双向Mamba块进行扇区内空间编码和全局前向Mamba进行扇区间时间建模，有效克服了传统方法中卷积与极坐标几何不匹配以及现有Mamba模型不适用于流式处理的问题。实验结果表明，PHiM在Waymo Open Dataset上显著提升了流式检测器的性能，超越了现有最佳方法10%，并在吞吐量翻倍的情况下达到了全扫描基线的性能水平。

> **摘要翻译:** 准确高效的目标检测对于自动驾驶车辆至关重要，其中实时感知需要低延迟和高吞吐量。激光雷达传感器提供稳健的深度信息，但传统方法一次性处理完整的360度扫描，引入了显著延迟。流式方法通过在原生极坐标系中顺序处理部分扫描来解决这个问题，但它们依赖于与极坐标几何不匹配的平移不变卷积，导致性能下降或需要复杂的失真缓解。最近基于Mamba的状态空间模型（SSM）在激光雷达感知方面显示出前景，但仅限于全扫描设置，依赖于内存密集且不适合流式处理的几何序列化和位置嵌入。我们提出了极坐标分层Mamba（PHiM），一种专为极坐标流式激光雷达设计的SSM新架构。PHiM使用局部双向Mamba块进行扇区内空间编码，并使用全局前向Mamba进行扇区间时间建模，用失真感知、维度分解的操作取代了卷积和位置编码。PHiM在Waymo开放数据集上的流式检测器中达到了新的最先进水平，比之前的最佳性能提高了10%，并在两倍吞吐量下与全扫描基线匹配。代码将在https://github.com/meilongzhang/Polar-Hierarchical-Mamba 提供。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [382] [LaTtE-Flow: Layerwise Timestep-Expert Flow-based Transformer](https://arxiv.org/abs/2506.06952)
> *LaTtE-Flow: 分层时间步专家流式Transformer*

*Ying Shen, Zhiyang Xu, Jiuhai Chen, Shizhe Diao, Jiaxin Zhang, Yuguang Yao, Joy Rimchala, Ismini Lourentzou, Lifu Huang* | **Main category: cs.CV**

**Keywords:** 多模态模型, 图像生成, 视觉-语言模型, Transformer, 流式模型

**Comment:** Unified multimodal model, Flow-matching

> **TL;DR:** LaTtE-Flow是一个统一图像理解和生成的模型，通过分层时间步专家机制实现了更快的推理速度和良好的性能。

**AI_Comments:** 该模型的创新在于其分层时间步专家流式架构和时间步条件残差注意力机制，这在不牺牲性能的前提下显著提高了统一模型中的效率。这解决了实际部署中一个关键的瓶颈（速度问题）。

<details>
  <summary>Details</summary>

**Motivation:** 现有的统一多模态模型需要大量预训练，性能不如专用模型，且图像生成速度慢，限制了实际部署。

**Method:** LaTtE-Flow基于预训练的视觉-语言模型（VLM）。它采用新颖的分层时间步专家流式架构，将流匹配过程分配给专门的Transformer层组，每组负责不同的时间步子集，在每个采样时间步只激活少量层。此外，它还提出了时间步条件残差注意力机制。

**Result:** LaTtE-Flow在多模态理解任务上表现出色，图像生成质量具有竞争力，推理速度比最近的统一多模态模型快约6倍。

**Conclusion:** LaTtE-Flow为统一图像理解和生成提供了一个高效且有效的解决方案，解决了以往模型在性能和速度上的局限。

> **ai_Abstract:** LaTtE-Flow是一种新型高效的多模态模型，统一了图像理解和生成。它利用预训练的视觉-语言模型（VLM），并引入了分层时间步专家流式架构，该架构将流匹配过程分配给专门的Transformer层，从而提高了采样效率。它还采用了时间步条件残差注意力机制。实验表明，该模型在理解任务上表现出色，生成质量具有竞争力，并且推理速度显著加快。

> **摘要翻译:** 最近在统一图像理解和生成的跨模态基础模型方面的进展，为在单一框架内处理广泛的视觉-语言任务开辟了激动人心的途径。尽管取得了进展，但现有的统一模型通常需要大量的预训练，并且与专门针对每项任务的模型相比，难以达到相同的性能水平。此外，许多此类模型图像生成速度缓慢，限制了它们在实时或资源受限环境中的实际部署。在这项工作中，我们提出了分层时间步专家流式Transformer（LaTtE-Flow），这是一种新颖高效的架构，可在单一多模态模型中统一图像理解和生成。LaTtE-Flow以强大的预训练视觉-语言模型（VLM）为基础，继承了强大的多模态理解能力，并通过新颖的分层时间步专家流式架构对其进行扩展，以实现高效的图像生成。LaTtE-Flow将流匹配过程分布在专门的Transformer层组中，每组负责不同的时间步子集。这种设计通过在每个采样时间步仅激活少量层来显著提高采样效率。为了进一步提升性能，我们提出了一种时间步条件残差注意力机制，以实现层间高效的信息重用。实验表明，LaTtE-Flow在多模态理解任务上取得了强大性能，同时图像生成质量具有竞争力，推理速度比最近的统一多模态模型快约6倍。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [387] [Task-driven real-world super-resolution of document scans](https://arxiv.org/abs/2506.06953)
> *任务驱动的文档扫描真实世界超分辨率*

*Maciej Zyrek, Tomasz Tarasiewicz, Jakub Sadel, Aleksandra Krzywon, Michal Kawulok* | **Main category: cs.CV**

**Keywords:** 超分辨率, 文档扫描, 任务驱动, 多任务学习, 光学字符识别

**Comment:** 

> **TL;DR:** 本文提出了一种任务驱动的多任务学习框架，用于文档扫描的超分辨率，通过结合文本检测和识别等高层视觉任务的辅助损失函数，以提高真实世界场景下的性能。

**AI_Comments:** 该论文的创新点在于提出了一个任务驱动的多任务学习框架，将高层视觉任务（如OCR）的辅助损失函数融入超分辨率网络的训练中，这有效地解决了传统超分辨率模型在真实世界复杂场景（如文档扫描）中泛化能力不足的问题。通过动态权重平均机制平衡不同损失项，进一步优化了模型性能。这项工作对于提升文档数字化和OCR的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于深度学习的单图像超分辨率方法在模拟数据集上表现良好，但在真实世界的文档扫描等复杂降级和语义变异场景下泛化能力差。

**Method:** 本文引入了一个任务驱动的多任务学习框架，用于训练专门针对光学字符识别（OCR）任务优化的超分辨率网络。该方法结合了来自高层视觉任务的辅助损失函数，包括使用CTPN的文本检测、CNN的文本识别、Key.Net的关键点定位和色调一致性。为了平衡这些目标，采用了动态权重平均机制来自适应调整每个损失项的重要性。

**Result:** 在模拟和真实世界的扫描文档数据集上的实验评估表明，所提出的方法提高了文本检测（通过IoU测量），同时保持了整体图像保真度。

**Conclusion:** 多目标优化在超分辨率模型中对于弥合模拟训练和真实世界部署之间的差距具有重要价值。

> **ai_Abstract:** 本研究提出了一种任务驱动的多任务学习框架，旨在解决现有超分辨率模型在真实世界文档扫描中泛化能力差的问题。通过将文本检测、文本识别、关键点定位和色调一致性等高层视觉任务的辅助损失函数纳入训练，并采用动态权重平均机制平衡各目标，该方法在SRResNet架构上进行了验证。实验结果表明，该方法有效提升了文本检测性能，并保持了图像整体质量，证明了多目标优化在弥合模拟与真实世界超分辨率之间鸿沟的重要性。

> **摘要翻译:** 单图像超分辨率是指从单个低分辨率观测图像重建高分辨率图像。尽管最近基于深度学习的方法在模拟数据集上取得了显著成功——通过降级和下采样高分辨率图像获得低分辨率图像——但它们经常无法推广到真实世界场景，例如受复杂降级和语义变异影响的文档扫描。在本研究中，我们引入了一个任务驱动的多任务学习框架，用于训练专门针对光学字符识别任务优化的超分辨率网络。我们建议结合来自高层视觉任务的辅助损失函数，包括使用连接主义文本提议网络的文本检测、通过卷积循环神经网络的文本识别、使用Key.Net的关键点定位以及色调一致性。为了平衡这些不同的目标，我们采用了动态权重平均机制，该机制根据每个损失项的收敛行为自适应调整其相对重要性。我们在SRResNet架构上验证了我们的方法，这是一种成熟的单图像超分辨率技术。在模拟和真实世界扫描文档数据集上的实验评估表明，所提出的方法提高了文本检测（通过交并比测量），同时保持了整体图像保真度。这些发现强调了超分辨率模型中多目标优化的价值，以弥合模拟训练机制与真实世界部署之间的差距。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [393] [AR-RAG: Autoregressive Retrieval Augmentation for Image Generation](https://arxiv.org/abs/2506.06962)
> *AR-RAG：图像生成中的自回归检索增强*

*Jingyuan Qi, Zhiyang Xu, Qifan Wang, Lifu Huang* | **Main category: cs.CV**

**Keywords:** 图像生成, 检索增强, 自回归, 补丁级检索, k近邻

**Comment:** Image Generation, Retrieval Augmented Generation

> **TL;DR:** AR-RAG通过在图像生成过程中自回归地进行逐块检索增强，解决了现有方法的局限性，并提出了DAiD和FAiD两种实现框架，显著提升了图像生成性能。

**AI_Comments:** AR-RAG的创新点在于其自回归和上下文感知的检索增强机制，这与现有方法中单一静态检索形成了鲜明对比，有效解决了过度复制和风格偏差等问题。DAiD和FAiD两种实现框架，特别是DAiD的无需训练特性，使其具有很好的实用性和通用性。该方法在多个基准测试上的显著性能提升，表明其在图像生成领域具有重要意义和应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 现有图像生成方法在生成前只进行单一静态检索，导致过度复制和风格偏差等局限性。AR-RAG旨在通过在每个生成步骤执行上下文感知的检索来解决这些问题。

**Method:** AR-RAG通过在补丁级别自回归地整合k近邻检索来增强图像生成。它使用先前生成的补丁作为查询，在每个生成步骤进行上下文感知的检索。提出了两种并行框架：1) 解码中的分布增强（DAiD），一种无需训练的即插即用解码策略，直接合并模型预测补丁和检索补丁的分布；2) 解码中的特征增强（FAiD），一种参数高效的微调方法，通过多尺度卷积操作平滑检索补丁的特征并增强图像生成过程。

**Result:** AR-RAG在Midjourney-30K、GenEval和DPG-Bench等广泛采用的基准测试中，相对于最先进的图像生成模型展现出显著的性能提升。

**Conclusion:** AR-RAG是一种新颖且有效的图像生成范式，通过自回归的、上下文感知的补丁级检索增强，克服了现有方法的局限性，从而提升了性能。

> **ai_Abstract:** AR-RAG是一种新颖的图像生成范式，通过在每个生成步骤自回归地进行上下文感知的补丁级k近邻检索来增强图像生成。它克服了现有方法中单一静态检索导致的过度复制和风格偏差等局限性。为实现AR-RAG，论文提出了两种并行框架：无需训练的DAiD（解码中的分布增强）和参数高效的FAiD（解码中的特征增强）。实验结果表明，AR-RAG在多个基准测试上显著优于现有最先进的图像生成模型。

> **摘要翻译:** 我们引入了自回归检索增强（AR-RAG），这是一种新颖的范式，通过自回归地结合补丁级别的k近邻检索来增强图像生成。与之前在生成前执行单一、静态检索并将整个生成过程基于固定参考图像的方法不同，AR-RAG在每个生成步骤执行上下文感知的检索，使用先前生成的补丁作为查询来检索并合并最相关的补丁级视觉参考，使模型能够响应不断变化的生成需求，同时避免现有方法中普遍存在的局限性（例如，过度复制、风格偏差等）。为了实现AR-RAG，我们提出了两个并行框架：（1）解码中的分布增强（DAiD），这是一种无需训练的即插即用解码策略，直接将模型预测补丁的分布与检索到的补丁的分布合并；（2）解码中的特征增强（FAiD），这是一种参数高效的微调方法，通过多尺度卷积操作逐步平滑检索到的补丁的特征，并利用它们来增强图像生成过程。我们在广泛采用的基准测试（包括Midjourney-30K、GenEval和DPG-Bench）上验证了AR-RAG的有效性，证明了其相对于最先进的图像生成模型有显著的性能提升。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [398] [Dual-view Spatio-Temporal Feature Fusion with CNN-Transformer Hybrid Network for Chinese Isolated Sign Language Recognition](https://arxiv.org/abs/2506.06966)
> *双视角时空特征融合与CNN-Transformer混合网络在中文孤立手语识别中的应用*

*Siyuan Jing, Guangxue Wang, Haoyang Zhai, Qin Tao, Jun Yang, Bing Wang, Peng Jin* | **Main category: cs.CV**

**Keywords:** 孤立手语识别, 双视角数据集, CNN-Transformer, 特征融合, 中文手语

**Comment:** 18 pages, 3 figures

> **TL;DR:** 本文提出了一个双视角中文手语数据集（NationalCSL-DP）和一个结合CNN-Transformer的混合网络，并采用了一种有效的特征融合策略，显著提升了孤立手语识别性能，尽管从多视角数据中学习互补特征仍具挑战。

**AI_Comments:** 该论文通过引入双视角数据集NationalCSL-DP，创新性地解决了中文孤立手语识别中词汇覆盖有限和单视角数据导致遮挡的关键问题。提出的CNN-Transformer混合网络和简单有效的融合策略为该领域提供了强大的基线并显著提升了性能。然而，它也指出了序列到序列模型在有效学习多视角数据互补特征方面仍面临的挑战，这为未来的研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 现有手语数据集未涵盖全部手语词汇，且大多只提供单视角RGB视频，导致在孤立手语识别（ISLR）中难以处理手部遮挡问题。

**Method:** 本文提出了一个名为NationalCSL-DP的双视角手语数据集，该数据集完全涵盖了中国国家手语词汇，包含134140个由十名手语者在正面和左侧两个垂直视角下录制的视频。此外，还提出了一个CNN-Transformer混合网络作为基线模型，并设计了一种简单但有效的预测融合策略。

**Result:** 所提出的融合策略能显著提高孤立手语识别（ISLR）的性能。然而，对于序列到序列模型而言，无论采用早期融合还是后期融合策略，从两个垂直视角的手语视频中学习互补特征并非易事。

**Conclusion:** 本文通过引入一个全面的双视角数据集和一种有效的融合策略，成功解决了孤立手语识别中的现有局限性，尽管对于序列到序列模型而言，从多视角数据中学习互补特征仍然是一个挑战。

> **ai_Abstract:** 本文针对孤立手语识别（ISLR）中词汇覆盖不全和单视角数据导致手部遮挡的问题，提出了一个名为NationalCSL-DP的新型双视角中文手语数据集，该数据集涵盖了完整的中文手语词汇。同时，论文还提出了一个结合CNN和Transformer的混合网络，并设计了一种有效的特征融合策略。实验结果表明，该融合策略显著提升了ISLR的性能，但从双视角数据中学习互补特征对于序列到序列模型而言仍是一个挑战。

> **摘要翻译:** 由于许多手语数据集的出现，孤立手语识别（ISLR）近年来取得了显著进展。此外，各种先进深度神经网络的发展是这一突破的另一个原因。然而，将该技术应用于现实世界仍面临挑战。首先，现有手语数据集并未涵盖全部手语词汇。其次，大多数手语数据集仅提供单视角RGB视频，这使得在执行ISLR时难以处理手部遮挡问题。为了弥补这一空白，本文提出了一个用于ISLR的双视角手语数据集，名为NationalCSL-DP，该数据集完全涵盖了中国国家手语词汇。该数据集包含由十名手语者录制的134140个手语视频，涉及两个垂直视角，即正面和左侧。此外，还提出了一种CNN-Transformer网络作为强大的基线，以及一种极其简单但有效的预测融合策略。进行了大量实验以证明数据集和基线的有效性。结果表明，所提出的融合策略可以显著提高ISLR的性能，但对于序列到序列模型来说，无论采用早期融合还是后期融合策略，从两个垂直视角的手语视频中学习互补特征并非易事。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [403] [Guiding Cross-Modal Representations with MLLM Priors via Preference Alignment](https://arxiv.org/abs/2506.06970)
> *错误：AI分析失败。*

*Pengfei Zhao, Rongbo Luan, Wei Zhang, Peng Wu, Sifeng He* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [408] [Hybrid Mesh-Gaussian Representation for Efficient Indoor Scene Reconstruction](https://arxiv.org/abs/2506.06988)
> *错误：AI分析失败。*

*Binxiao Huang, Zhihao Li, Shiyong Liu, Xiao Tang, Jiajun Tang, Jiaqi Lin, Yuxin Cheng, Zhenyu Chen, Xiaofei Wu, Ngai Wong* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [412] [Boosting Adversarial Transferability via Commonality-Oriented Gradient Optimization](https://arxiv.org/abs/2506.06992)
> *错误：AI分析失败。*

*Yanting Gao, Yepeng Liu, Junming Liu, Qi Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 22 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [415] [DM$^3$Net: Dual-Camera Super-Resolution via Domain Modulation and Multi-scale Matching](https://arxiv.org/abs/2506.06993)
> *错误：AI分析失败。*

*Cong Guan, Jiacheng Ying, Yuya Ieiri, Osamu Yoshie* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [418] [D2R: dual regularization loss with collaborative adversarial generation for model robustness](https://arxiv.org/abs/2506.07056)
> *错误：AI分析失败。*

*Zhenyu Liu, Huizhi Liang, Rajiv Ranjan, Zhanxing Zhu, Vaclav Snasel, Varun Ojha* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [420] [Technical Report for ICRA 2025 GOOSE 3D Semantic Segmentation Challenge: Adaptive Point Cloud Understanding for Heterogeneous Robotic Systems](https://arxiv.org/abs/2506.06995)
> *错误：AI分析失败。*

*Xiaoya Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Winner of the GOOSE 3D Semantic Segmentation Challenge at the IEEE
  ICRA Workshop on Field Robotics 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [423] [Backdoor Attack on Vision Language Models with Stealthy Semantic Manipulation](https://arxiv.org/abs/2506.07214)
> *错误：AI分析失败。*

*Zhiyuan Zhong, Zhen Sun, Yepang Liu, Xinlei He, Guanhong Tao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [425] [BePo: Leveraging Birds Eye View and Sparse Points for Efficient and Accurate 3D Occupancy Prediction](https://arxiv.org/abs/2506.07002)
> *错误：AI分析失败。*

*Yunxiao Shi, Hong Cai, Jisoo Jeong, Yinhao Zhu, Shizhong Han, Amin Ansari, Fatih Porikli* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Two-page abstract version available at CVPR 2025 Embodied AI Workshop

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [430] [UNO: Unified Self-Supervised Monocular Odometry for Platform-Agnostic Deployment](https://arxiv.org/abs/2506.07013)
> *错误：AI分析失败。*

*Wentao Zhao, Yihe Niu, Yanbo Wang, Tianchen Deng, Shenghai Yuan, Zhenli Wang, Rui Guo, Jingchuan Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 15pages, 8 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [435] [TABLET: Table Structure Recognition using Encoder-only Transformers](https://arxiv.org/abs/2506.07015)
> *错误：AI分析失败。*

*Qiyu Hou, Jun Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** ICDAR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [439] [Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI](https://arxiv.org/abs/2506.07286)
> *错误：AI分析失败。*

*Aditya Chakravarty* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted in CVPR 2025 Embodied AI Workshop

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [440] [MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks](https://arxiv.org/abs/2506.07016)
> *错误：AI分析失败。*

*Sanjoy Chowdhury, Mohamed Elmoghany, Yohan Abeysinghe, Junjie Fei, Sayan Nag, Salman Khan, Mohamed Elhoseiny, Dinesh Manocha* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Audio-visual learning, Audio-Visual RAG, Multi-Video Linkage

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [444] [Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation](https://arxiv.org/abs/2506.07338)
> *错误：AI分析失败。*

*Yijie Deng, Shuaihang Yuan, Geeta Chandra Raju Bethala, Anthony Tzes, Yu-Shen Liu, Yi Fang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [445] [Interpretable and Reliable Detection of AI-Generated Images via Grounded Reasoning in MLLMs](https://arxiv.org/abs/2506.07045)
> *错误：AI分析失败。*

*Yikun Ji, Hong Yan, Jun Lan, Huijia Zhu, Weiqiang Wang, Qi Fan, Liqing Zhang, Jianfu Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [448] [From Swath to Full-Disc: Advancing Precipitation Retrieval with Multimodal Knowledge Expansion](https://arxiv.org/abs/2506.07050)
> *错误：AI分析失败。*

*Zheng Wang, Kai Ying, Bin Xu, Chunjiao Wang, Cong Bai* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [453] [A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge](https://arxiv.org/abs/2506.07055)
> *错误：AI分析失败。*

*Tarique Dahri, Zulfiqar Ali Memon, Zhenyu Yu, Mohd. Yamani Idna Idris, Sheheryar Khan, Sadiq Ahmad, Maged Shoman, Saddam Aziz, Rizwan Qureshi* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [458] [R3D2: Realistic 3D Asset Insertion via Diffusion for Autonomous Driving Simulation](https://arxiv.org/abs/2506.07826)
> *错误：AI分析失败。*

*William Ljungbergh, Bernardo Taveira, Wenzhao Zheng, Adam Tonderski, Chensheng Peng, Fredrik Kahl, Christoffer Petersson, Michael Felsberg, Kurt Keutzer, Masayoshi Tomizuka, Wei Zhan* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [459] [FLAIR-HUB: Large-scale Multimodal Dataset for Land Cover and Crop Mapping](https://arxiv.org/abs/2506.07080)
> *错误：AI分析失败。*

*Anatol Garioud, Sébastien Giordano, Nicolas David, Nicolas Gonthier* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [463] [LogoSP: Local-global Grouping of Superpoints for Unsupervised Semantic Segmentation of 3D Point Clouds](https://arxiv.org/abs/2506.07857)
> *错误：AI分析失败。*

*Zihui Zhang, Weisheng Dai, Hongtao Wen, Bo Yang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** CVPR 2025. Code and data are available at:
  https://github.com/vLAR-group/LogoSP

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [464] [UCOD-DPL: Unsupervised Camouflaged Object Detection via Dynamic Pseudo-label Learning](https://arxiv.org/abs/2506.07087)
> *错误：AI分析失败。*

*Weiqi Yan, Lvhai Chen, Huaijia Kou, Shengchuan Zhang, Yan Zhang, Liujuan Cao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by CVPR 2025 (Hightlight)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [467] [SceneLCM: End-to-End Layout-Guided Interactive Indoor Scene Generation with Latent Consistency Model](https://arxiv.org/abs/2506.07091)
> *错误：AI分析失败。*

*Yangkai Lin, Jiabao Lei, Kui Jia* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [470] [UA-Pose: Uncertainty-Aware 6D Object Pose Estimation and Online Object Completion with Partial References](https://arxiv.org/abs/2506.07996)
> *错误：AI分析失败。*

*Ming-Feng Li, Xin Yang, Fu-En Wang, Hritam Basak, Yuyin Sun, Shreekant Gayaka, Min Sun, Cheng-Hao Kuo* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** CVPR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [471] [EdgeSpotter: Multi-Scale Dense Text Spotting for Industrial Panel Monitoring](https://arxiv.org/abs/2506.07112)
> *错误：AI分析失败。*

*Changhong Fu, Hua Lin, Haobo Zuo, Liangliang Yao, Liguo Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [474] [Image segmentation and classification of E-waste for waste segregation](https://arxiv.org/abs/2506.07122)
> *错误：AI分析失败。*

*Prakriti Tripathi, Theertha Biju, Maniram Thota, Rakesh Lingam* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 4 pages, 7 figures. For code and link to dataset, see
  https://github.com/prakriti16/Image-segmentation-and-classification-of-e-waste

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [477] [Hi-VAE: Efficient Video Autoencoding with Global and Detailed Motion](https://arxiv.org/abs/2506.07136)
> *错误：AI分析失败。*

*Huaize Liu, Wenzhang Sun, Qiyuan Zhang, Donglin Di, Biao Gong, Hao Li, Chen Wei, Changqing Zou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [480] [Learning Compact Vision Tokens for Efficient Large Multimodal Models](https://arxiv.org/abs/2506.07138)
> *错误：AI分析失败。*

*Hao Tang, Chengchao Shen* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** The source code and trained weights are available at
  https://github.com/visresearch/LLaVA-STF

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [482] [GoTrack: Generic 6DoF Object Pose Refinement and Tracking](https://arxiv.org/abs/2506.07155)
> *错误：AI分析失败。*

*Van Nguyen Nguyen, Christian Forster, Sindi Shkodrani, Vincent Lepetit, Bugra Tekin, Cem Keskin, Tomas Hodan* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [485] [Faster than Fast: Accelerating Oriented FAST Feature Detection on Low-end Embedded GPUs](https://arxiv.org/abs/2506.07164)
> *错误：AI分析失败。*

*Qiong Chang, Xinyuan Chen, Xiang Li, Weimin Wang, Jun Miyazaki* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [489] [Frame Guidance: Training-Free Guidance for Frame-Level Control in Video Diffusion Models](https://arxiv.org/abs/2506.07177)
> *错误：AI分析失败。*

*Sangwon Jang, Taekyung Ki, Jaehyeong Jo, Jaehong Yoon, Soo Ye Kim, Zhe Lin, Sung Ju Hwang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://frame-guidance-video.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [492] [Hierarchical Feature-level Reverse Propagation for Post-Training Neural Networks](https://arxiv.org/abs/2506.07188)
> *错误：AI分析失败。*

*Ni Ding, Lei He, Shengbo Eben Li, Keqiang Li* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 7 figures,

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [495] [SAP-Bench: Benchmarking Multimodal Large Language Models in Surgical Action Planning](https://arxiv.org/abs/2506.07196)
> *错误：AI分析失败。*

*Mengya Xu, Zhongzhen Huang, Dillan Imans, Yiru Ye, Xiaofan Zhang, Qi Dou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 11 pages, 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [498] [TV-LiVE: Training-Free, Text-Guided Video Editing via Layer Informed Vitality Exploitation](https://arxiv.org/abs/2506.07205)
> *错误：AI分析失败。*

*Min-Jung Kim, Dongjin Kim, Seokju Yun, Jaegul Choo* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [501] [Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial Margin Contrastive Learning](https://arxiv.org/abs/2309.11082)
> *错误：AI分析失败。*

*Chen Jiang, Hong Liu, Xuzheng Yu, Qing Wang, Yuan Cheng, Jia Xu, Zhongyi Liu, Qingpei Guo, Wei Chu, Ming Yang, Yuan Qi* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACM MM 2023

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [502] [AugmentGest: Can Random Data Cropping Augmentation Boost Gesture Recognition Performance?](https://arxiv.org/abs/2506.07216)
> *错误：AI分析失败。*

*Nada Aboudeshish, Dmitry Ignatov, Radu Timofte* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [503] [MiniGPT-Reverse-Designing: Predicting Image Adjustments Utilizing MiniGPT-4](https://arxiv.org/abs/2406.00971)
> *错误：AI分析失败。*

*Vahid Azizi, Fatemeh Koochaki* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [505] [Hallucination at a Glance: Controlled Visual Edits and Fine-Grained Multimodal Learning](https://arxiv.org/abs/2506.07227)
> *错误：AI分析失败。*

*Tianyi Bai, Yuxuan Fan, Jiantao Qiu, Fupeng Sun, Jiayi Song, Junlin Han, Zichen Liu, Conghui He, Wentao Zhang, Binhang Yuan* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [509] [Multi-Step Visual Reasoning with Visual Tokens Scaling and Verification](https://arxiv.org/abs/2506.07235)
> *错误：AI分析失败。*

*Tianyi Bai, Zengjie Hu, Fupeng Sun, Jiantao Qiu, Yizhen Jiang, Guangxin He, Bohan Zeng, Conghui He, Binhang Yuan, Wentao Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [513] [From Generation to Generalization: Emergent Few-Shot Learning in Video Diffusion Models](https://arxiv.org/abs/2506.07280)
> *错误：AI分析失败。*

*Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 27 pages, 23 figures, 9 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [514] [STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis](https://arxiv.org/abs/2506.06276)
> *错误：AI分析失败。*

*Jiatao Gu, Tianrong Chen, David Berthelot, Huangjie Zheng, Yuyang Wang, Ruixiang Zhang, Laurent Dinh, Miguel Angel Bautista, Josh Susskind, Shuangfei Zhai* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** TLDR: We show for the first time that normalizing flows can be scaled
  for high-resolution and text-conditioned image synthesis

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [516] [FANVID: A Benchmark for Face and License Plate Recognition in Low-Resolution Videos](https://arxiv.org/abs/2506.07304)
> *错误：AI分析失败。*

*Kavitha Viswanathan, Vrinda Goel, Shlesh Gholap, Devayan Ghosh, Madhav Gupta, Dhruvi Ganatra, Sanket Potdar, Amit Sethi* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [519] [AllTracker: Efficient Dense Point Tracking at High Resolution](https://arxiv.org/abs/2506.07310)
> *错误：AI分析失败。*

*Adam W. Harley, Yang You, Xinglong Sun, Yang Zheng, Nikhil Raghuraman, Yunqi Gu, Sheldon Liang, Wen-Hsuan Chu, Achal Dave, Pavel Tokmakov, Suya You, Rares Ambrus, Katerina Fragkiadaki, Leonidas J. Guibas* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [522] ["CASE: Contrastive Activation for Saliency Estimation](https://arxiv.org/abs/2506.07327)
> *错误：AI分析失败。*

*Dane Williamson, Yangfeng Ji, Matthew Dwyer* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 5 figures. Submitted to IEEE Transactions on Neural Networks
  and Learning Systems (TNNLS)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [525] [CBAM-STN-TPS-YOLO: Enhancing Agricultural Object Detection through Spatially Adaptive Attention Mechanisms](https://arxiv.org/abs/2506.07357)
> *错误：AI分析失败。*

*Satvik Praveen, Yoonsung Jung* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [526] [Multiple Object Stitching for Unsupervised Representation Learning](https://arxiv.org/abs/2506.07364)
> *错误：AI分析失败。*

*Chengchao Shen, Dawei Liu, Jianxin Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [529] [C3S3: Complementary Competition and Contrastive Selection for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.07368)
> *错误：AI分析失败。*

*Jiaying He, Yitong Lin, Jiahe Chen, Honghui Xu, Jianwei Zheng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages, 4 figures, ICME2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [531] [Generative Models at the Frontier of Compression: A Survey on Generative Face Video Coding](https://arxiv.org/abs/2506.07369)
> *错误：AI分析失败。*

*Bolin Chen, Shanzhi Yin, Goluck Konuko, Giuseppe Valenzise, Zihan Zhang, Shiqi Wang, Yan Ye* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [533] [ARGUS: Hallucination and Omission Evaluation in Video-LLMs](https://arxiv.org/abs/2506.07371)
> *错误：AI分析失败。*

*Ruchit Rawal, Reza Shirkavand, Heng Huang, Gowthami Somepalli, Tom Goldstein* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page with all the artifacts:
  https://ruchitrawal.github.io/argus

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [535] [DINO-CoDT: Multi-class Collaborative Detection and Tracking with Vision Foundation Models](https://arxiv.org/abs/2506.07375)
> *错误：AI分析失败。*

*Xunjie He, Christina Dao Wen Lee, Meiling Wang, Chengran Yuan, Zefan Huang, Yufeng Yue, Marcelo H. Ang Jr* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [537] [Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation](https://arxiv.org/abs/2506.07376)
> *错误：AI分析失败。*

*Jintao Tong, Ran Ma, Yixiong Zou, Guangyao Chen, Yuhua Li, Ruixuan Li* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025 Spotlight

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [540] [MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems](https://arxiv.org/abs/2506.07399)
> *错误：AI分析失败。*

*Peiru Yang, Jinhua Yin, Haoran Zheng, Xueying Bai, Huili Wang, Yufei Sun, Xintian Li, Shangguang Wang, Yongfeng Huang, Tao Qi* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [542] [Compressed Feature Quality Assessment: Dataset and Baselines](https://arxiv.org/abs/2506.07412)
> *压缩特征质量评估：数据集与基线*

*Changsheng Gao, Wei Zhou, Guosheng Lin, Weisi Lin* | **Main category: cs.CV**

**Keywords:** 压缩特征, 质量评估, 数据集, 语义失真, 基线

**Comment:** 

> **TL;DR:** 本文提出了压缩特征质量评估（CFQA）问题，并构建了首个CFQA基准数据集和基线，以解决压缩特征的语义退化难以量化的问题。

**AI_Comments:** 这项工作具有重要意义，因为它首次提出了压缩特征质量评估（CFQA）这一明确的研究问题，并构建了首个专门为此目的设计的基准数据集。这为后续研究提供了一个标准化的评估框架和资源，有助于推动特征压缩和语义保真度量领域的发展。数据集的代表性以及对现有指标局限性的揭示，为未来开发更先进的度量方法指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 在资源受限环境中部署大型模型时，需要高效传输中间特征表示。特征编码（压缩特征）在此过程中至关重要，但会引入传统指标难以量化的语义退化。因此，需要评估压缩特征的语义保真度。

**Method:** 本文提出了压缩特征质量评估（CFQA）研究问题，旨在评估压缩特征的语义保真度。为推动CFQA研究，构建了首个基准数据集，包含300个原始特征和12000个压缩特征，来源于三个视觉任务和四种特征编解码器。使用任务特定的性能下降作为真实的语义失真进行评估。评估了三种常用指标（MSE、余弦相似度、中心核对齐）在捕获语义退化方面的性能。

**Result:** 评估结果强调了数据集的代表性，并指出需要更精细的指标来解决压缩特征中语义失真的细微差别。

**Conclusion:** 本文引入了压缩特征质量评估（CFQA）研究问题，并发布了首个CFQA基准数据集和源代码，旨在推动该领域的发展，并为社区探索CFQA提供基础资源。

> **ai_Abstract:** 为了解决资源受限环境下大型模型部署中压缩特征语义退化难以量化的问题，本文提出了压缩特征质量评估（CFQA）这一研究问题。为此，作者构建了首个CFQA基准数据集，该数据集包含来自多种视觉任务和特征编解码器的原始及压缩特征，并以任务性能下降作为真值语义失真。研究评估了现有度量（如MSE、余弦相似度、中心核对齐）在捕获语义退化方面的表现，结果表明数据集具有代表性，并强调了开发更精确度量的重要性。本文还开源了数据集和代码，以促进CFQA领域的进一步研究。

> **摘要翻译:** 大型模型在资源受限环境中的广泛部署凸显了中间特征表示高效传输的需求。在这种背景下，特征编码将特征压缩成紧凑的比特流，成为涉及特征传输、存储和重用场景的关键组成部分。然而，这种压缩过程引入了固有的语义退化，而这种退化用传统指标来量化是出了名的困难。为了解决这个问题，本文引入了压缩特征质量评估（CFQA）这一研究问题，旨在评估压缩特征的语义保真度。为了推进CFQA研究，我们提出了首个基准数据集，该数据集包含300个原始特征和12000个压缩特征，这些特征来源于三个视觉任务和四种特征编解码器。任务特定的性能下降被作为真实的语义失真，用于评估CFQA指标。我们评估了三种广泛使用的指标（MSE、余弦相似度和中心核对齐）在捕获语义退化方面的性能。结果强调了数据集的代表性，并突出了需要更精细的指标来解决压缩特征中语义失真的细微差别。为了促进CFQA研究的持续发展，我们发布了数据集和所有附带的源代码，网址为\href{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}{https://github.com/chansongoal/Compressed-Feature-Quality-Assessment}。这一贡献旨在推动该领域的发展，并为社区探索CFQA提供基础资源。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [544] [DPFormer: Dynamic Prompt Transformer for Continual Learning](https://arxiv.org/abs/2506.07414)
> *错误：AI分析失败。*

*Sheng-Kai Huang, Jiun-Feng Chang, Chun-Rong Huang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [546] [FAMSeg: Fetal Femur and Cranial Ultrasound Segmentation Using Feature-Aware Attention and Mamba Enhancement](https://arxiv.org/abs/2506.07431)
> *错误：AI分析失败。*

*Jie He, Minglang Chen, Minying Lu, Bocheng Liang, Junming Wei, Guiyan Peng, Jiaxi Chen, Ying Tan* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [552] [PhysiInter: Integrating Physical Mapping for High-Fidelity Human Interaction Generation](https://arxiv.org/abs/2506.07456)
> *错误：AI分析失败。*

*Wei Yao, Yunlian Sun, Chang Liu, Hongwen Zhang, Jinhui Tang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [555] [GLOS: Sign Language Generation with Temporally Aligned Gloss-Level Conditioning](https://arxiv.org/abs/2506.07460)
> *错误：AI分析失败。*

*Taeryung Lee, Hyeongjin Nam, Gyeongsik Moon, Kyoung Mu Lee* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [557] [DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO](https://arxiv.org/abs/2506.07464)
> *错误：AI分析失败。*

*Jinyoung Park, Jeehye Na, Jinyoung Kim, Hyunwoo J. Kim* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Work in progress

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [559] [Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.07471)
> *错误：AI分析失败。*

*CH Cho, WJ Moon, W Jun, MS Jung, JP Heo* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to AAAI 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [561] [CoCoA-Mix: Confusion-and-Confidence-Aware Mixture Model for Context Optimization](https://arxiv.org/abs/2506.07484)
> *错误：AI分析失败。*

*Dasol Hong, Wooju Lee, Hyun Myung* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 5 figures; accepted at ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [563] [Drive Any Mesh: 4D Latent Diffusion for Mesh Deformation from Video](https://arxiv.org/abs/2506.07489)
> *错误：AI分析失败。*

*Yahao Shi, Yang Liu, Yanmin Wu, Xing Liu, Chen Zhao, Jie Luo, Bin Zhou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** technical report

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [566] [SpatialLM: Training Large Language Models for Structured Indoor Modeling](https://arxiv.org/abs/2506.07491)
> *错误：AI分析失败。*

*Yongsen Mao, Junhao Zhong, Chuan Fang, Jia Zheng, Rui Tang, Hao Zhu, Ping Tan, Zihan Zhou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [569] [Genesis: Multimodal Driving Scene Generation with Spatio-Temporal and Cross-Modal Consistency](https://arxiv.org/abs/2506.07497)
> *错误：AI分析失败。*

*Xiangyu Guo, Zhanqian Wu, Kaixin Xiong, Ziyang Xu, Lijun Zhou, Gangwei Xu, Shaoqing Xu, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wenyu Liu, Xinggang Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [571] [MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts](https://arxiv.org/abs/2506.07533)
> *错误：AI分析失败。*

*Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by the 63rd Annual Meeting of the Association for
  Computational Linguistics (ACL 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [574] [Domain Randomization for Object Detection in Manufacturing Applications using Synthetic Data: A Comprehensive Study](https://arxiv.org/abs/2506.07539)
> *错误：AI分析失败。*

*Xiaomeng Zhu, Jacob Henningsson, Duruo Li, Pär Mårtensson, Lars Hanson, Mårten Björkman, Atsuto Maki* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** This is accepted by 2025 IEEE International Conference on Robotics &
  Automation (ICRA), waiting for publication. 14 pages, 14 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [577] [APTOS-2024 challenge report: Generation of synthetic 3D OCT images from fundus photographs](https://arxiv.org/abs/2506.07542)
> *错误：AI分析失败。*

*Bowen Liu, Weiyi Zhang, Peranut Chotcomwongse, Xiaolan Chen, Ruoyu Chen, Pawin Pakaymaskul, Niracha Arjkongharn, Nattaporn Vongsa, Xuelian Cheng, Zongyuan Ge, Kun Huang, Xiaohui Li, Yiru Duan, Zhenbang Wang, BaoYe Xie, Qiang Chen, Huazhu Fu, Michael A. Mahr, Jiaqi Qu, Wangyiyang Chen, Shiye Wang, Yubo Tan, Yongjie Li, Mingguang He, Danli Shi, Paisan Ruamviboonsuk* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [580] [Synthesize Privacy-Preserving High-Resolution Images via Private Textual Intermediaries](https://arxiv.org/abs/2506.07555)
> *错误：AI分析失败。*

*Haoxiang Wang, Zinan Lin, Da Yu, Huishuai Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [583] [Cross-channel Perception Learning for H&E-to-IHC Virtual Staining](https://arxiv.org/abs/2506.07559)
> *错误：AI分析失败。*

*Hao Yang, JianYu Wu, Run Fang, Xuelian Zhao, Yuan Ji, Zhiyu Chen, Guibin He, Junceng Guo, Yang Liu, Xinhua Zeng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [586] [OpenDance: Multimodal Controllable 3D Dance Generation Using Large-scale Internet Data](https://arxiv.org/abs/2506.07565)
> *错误：AI分析失败。*

*Jinlu Zhang, Zixi Kang, Yizhou Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [589] [Towards the Influence of Text Quantity on Writer Retrieval](https://arxiv.org/abs/2506.07566)
> *错误：AI分析失败。*

*Marco Peer, Robert Sablatnig, Florian Kleber* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** accepted for ICDAR2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [592] [LLM-driven Indoor Scene Layout Generation via Scaled Human-aligned Data Synthesis and Multi-Stage Preference Optimization](https://arxiv.org/abs/2506.07570)
> *错误：AI分析失败。*

*Yixuan Yang, Zhen Luo, Tongsheng Ding, Junru Lu, Mingqi Gao, Jinyu Yang, Victor Sanchez, Feng Zheng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [594] [Learning Speaker-Invariant Visual Features for Lipreading](https://arxiv.org/abs/2506.07572)
> *错误：AI分析失败。*

*Yu Li, Feng Xue, Shujie Li, Jinrui Zhang, Shuang Yang, Dan Guo, Richang Hong* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [596] [Uncertainty-o: One Model-agnostic Framework for Unveiling Uncertainty in Large Multimodal Models](https://arxiv.org/abs/2506.07575)
> *错误：AI分析失败。*

*Ruiyang Zhang, Hu Zhang, Hao Fei, Zhedong Zheng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://uncertainty-o.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [599] [Super Encoding Network: Recursive Association of Multi-Modal Encoders for Video Understanding](https://arxiv.org/abs/2506.07576)
> *错误：AI分析失败。*

*Boyu Chen, Siran Chen, Kunchang Li, Qinglin Xu, Yu Qiao, Yali Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [601] [Explore the vulnerability of black-box models via diffusion models](https://arxiv.org/abs/2506.07590)
> *错误：AI分析失败。*

*Jiacheng Shi, Yanfu Zhang, Huajie Shao, Ashley Gao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [604] [SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding](https://arxiv.org/abs/2506.07600)
> *错误：AI分析失败。*

*Nianbo Zeng, Haowen Hou, Fei Richard Yu, Si Shi, Ying Tiffany He* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [606] [SurgBench: A Unified Large-Scale Benchmark for Surgical Video Analysis](https://arxiv.org/abs/2506.07603)
> *错误：AI分析失败。*

*Jianhui Wei, Zikai Xiao, Danyu Sun, Luqi Gong, Zongxin Yang, Zuozhu Liu, Jian Wu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [609] [DragNeXt: Rethinking Drag-Based Image Editing](https://arxiv.org/abs/2506.07611)
> *错误：AI分析失败。*

*Yuan Zhou, Junbao Zhou, Qingshan Xu, Kesen Zhao, Yuxuan Wang, Hao Fei, Richang Hong, Hanwang Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [610] [Scaling Human Activity Recognition: A Comparative Evaluation of Synthetic Data Generation and Augmentation Techniques](https://arxiv.org/abs/2506.07612)
> *错误：AI分析失败。*

*Zikang Leng, Archith Iyer, Thomas Plötz* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [612] [Event-Priori-Based Vision-Language Model for Efficient Visual Understanding](https://arxiv.org/abs/2506.07627)
> *错误：AI分析失败。*

*Haotong Qin, Cheng Hu, Michele Magno* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [614] [HuSc3D: Human Sculpture dataset for 3D object reconstruction](https://arxiv.org/abs/2506.07628)
> *错误：AI分析失败。*

*Weronika Smolak-Dyżewska, Dawid Malarz, Grzegorz Wilczyński, Rafał Tobiasz, Joanna Waczyńska, Piotr Borycki, Przemysław Spurek* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [615] [HieraEdgeNet: A Multi-Scale Edge-Enhanced Framework for Automated Pollen Recognition](https://arxiv.org/abs/2506.07637)
> *错误：AI分析失败。*

*Yuchong Long, Wen Sun, Ningxiao Sun, Wenxiao Wang, Chao Li, Shan Yin* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 5 figures, 2 tables. The dataset at
  https://www.kaggle.com/datasets/ayinven/hieraedgenetintegratesdatasets. The
  models at
  https://huggingface.co/datasets/AyinMostima/HieraEdgeNetintegratesdatasets.
  The source code in at https://github.com/AyinMostima/PalynoKit

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [618] [Synthetic Visual Genome](https://arxiv.org/abs/2506.07643)
> *错误：AI分析失败。*

*Jae Sung Park, Zixian Ma, Linjie Li, Chenhao Zheng, Cheng-Yu Hsieh, Ximing Lu, Khyathi Chandu, Quan Kong, Norimasa Kobori, Ali Farhadi, Yejin Choi, Ranjay Krishna* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** CVPR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [620] [FMaMIL: Frequency-Driven Mamba Multi-Instance Learning for Weakly Supervised Lesion Segmentation in Medical Images](https://arxiv.org/abs/2506.07652)
> *错误：AI分析失败。*

*Hangbei Cheng, Xiaorong Dong, Xueyu Liu, Jianan Zhang, Xuetao Ma, Mingqiang Wei, Liansheng Wang, Junxin Chen, Yongfei Wu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [623] [ProSplat: Improved Feed-Forward 3D Gaussian Splatting for Wide-Baseline Sparse Views](https://arxiv.org/abs/2506.07670)
> *错误：AI分析失败。*

*Xiaohan Lu, Jiaye Fu, Jiaqi Zhang, Zetian Song, Chuanmin Jia, Siwei Ma* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [625] [OpenSplat3D: Open-Vocabulary 3D Instance Segmentation using Gaussian Splatting](https://arxiv.org/abs/2506.07697)
> *错误：AI分析失败。*

*Jens Piekenbrinck, Christian Schmidt, Alexander Hermans, Narunas Vaskevicius, Timm Linder, Bastian Leibe* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [627] [NOVA3D: Normal Aligned Video Diffusion Model for Single Image to 3D Generation](https://arxiv.org/abs/2506.07698)
> *错误：AI分析失败。*

*Yuxiao Yang, Peihao Li, Yuhong Zhang, Junzhe Lu, Xianglong He, Minghan Qin, Weitao Wang, Haoqian Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 7 figures, accepted by ICME 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [630] [Adaptive Blind Super-Resolution Network for Spatial-Specific and Spatial-Agnostic Degradations](https://arxiv.org/abs/2506.07705)
> *错误：AI分析失败。*

*Weilei Wen, Chunle Guo, Wenqi Ren, Hongpeng Wang, Xiuli Shao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** IEEE TRANSACTIONS ON IMAGE PROCESSING

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [632] [Consistent Video Editing as Flow-Driven Image-to-Video Generation](https://arxiv.org/abs/2506.07713)
> *错误：AI分析失败。*

*Ge Wang, Songlin Fan, Hangxu Liu, Quanjian Song, Hewei Wang, Jinfeng Xu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 12 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [634] [ReverB-SNN: Reversing Bit of the Weight and Activation for Spiking Neural Networks](https://arxiv.org/abs/2506.07720)
> *错误：AI分析失败。*

*Yufei Guo, Yuhan Zhang, Zhou Jie, Xiaode Liu, Xin Tong, Yuanpei Chen, Weihang Peng, Zhe Ma* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accpeted by ICML2024

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [636] [ETA: Efficiency through Thinking Ahead, A Dual Approach to Self-Driving with Large Models](https://arxiv.org/abs/2506.07725)
> *错误：AI分析失败。*

*Shadi Hamdan, Chonghao Sima, Zetong Yang, Hongyang Li, Fatma Güney* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** ICCV 2025 submission. For code, see
  https://github.com/opendrivelab/ETA

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [639] [SpikeSMOKE: Spiking Neural Networks for Monocular 3D Object Detection with Cross-Scale Gated Coding](https://arxiv.org/abs/2506.07737)
> *错误：AI分析失败。*

*Xuemei Chen, Huamin Wang, Hangchi Shen, Shukai Duan, Shiping Wen, Tingwen Huang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [640] [AssetDropper: Asset Extraction via Diffusion Models with Reward-Driven Optimization](https://arxiv.org/abs/2506.07738)
> *错误：AI分析失败。*

*Lanjiong Li, Guanhua Zhao, Lingting Zhu, Zeyu Cai, Lequan Yu, Jian Zhang, Zeyu Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** SIGGRAPH 2025. 11 pages, 12 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [642] [ArchiLense: A Framework for Quantitative Analysis of Architectural Styles Based on Vision Large Language Models](https://arxiv.org/abs/2506.07739)
> *错误：AI分析失败。*

*Jing Zhong, Jun Yin, Peilin Li, Pengyu Zeng, Miao Zhang, Shuai Lu, Ran Luo* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [645] [Flow-Anything: Learning Real-World Optical Flow Estimation from Large-Scale Single-view Images](https://arxiv.org/abs/2506.07740)
> *错误：AI分析失败。*

*Yingping Liang, Ying Fu, Yutao Hu, Wenqi Shao, Jiaming Liu, Debing Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [646] [Difference Inversion: Interpolate and Isolate the Difference with Token Consistency for Image Analogy Generation](https://arxiv.org/abs/2506.07750)
> *错误：AI分析失败。*

*Hyunsoo Kim, Donghyun Kim, Suhyun Kim* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Published at CVPR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [648] [Trend-Aware Fashion Recommendation with Visual Segmentation and Semantic Similarity](https://arxiv.org/abs/2506.07773)
> *错误：AI分析失败。*

*Mohamed Djilani, Nassim Ali Ousalah, Nidhal Eddine Chenni* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [651] [Language-Vision Planner and Executor for Text-to-Visual Reasoning](https://arxiv.org/abs/2506.07778)
> *错误：AI分析失败。*

*Yichang Xu, Gaowen Liu, Ramana Rao Kompella, Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Furkan Tekin, Zachary Yahn, Ling Liu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [653] [Design and Evaluation of Deep Learning-Based Dual-Spectrum Image Fusion Methods](https://arxiv.org/abs/2506.07779)
> *错误：AI分析失败。*

*Beining Xu, Junxian Li* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 11 pages, 13 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [655] [Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger](https://arxiv.org/abs/2506.07785)
> *错误：AI分析失败。*

*Qi Yang, Chenghao Zhang, Lubin Fan, Kun Ding, Jieping Ye, Shiming Xiang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025 Spotlight. 22 pages, 16 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [657] [Image Reconstruction as a Tool for Feature Analysis](https://arxiv.org/abs/2506.07803)
> *错误：AI分析失败。*

*Eduard Allakhverdov, Dmitrii Tarasov, Elizaveta Goncharova, Andrey Kuznetsov* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 23 pages, 14 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [659] [Incorporating Uncertainty-Guided and Top-k Codebook Matching for Real-World Blind Image Super-Resolution](https://arxiv.org/abs/2506.07809)
> *错误：AI分析失败。*

*Weilei Wen, Tianyi Zhang, Qianqian Zhao, Zhaohui Zheng, Chunle Guo, Xiuli Shao, Chongyi Li* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [661] [Looking Beyond Visible Cues: Implicit Video Question Answering via Dual-Clue Reasoning](https://arxiv.org/abs/2506.07811)
> *错误：AI分析失败。*

*Tieyuan Chen, Huabin Liu, Yi Wang, Chaofan Gan, Mingxi Lyu, Gui Zou, Weiyao Lin* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [663] [Self-Cascaded Diffusion Models for Arbitrary-Scale Image Super-Resolution](https://arxiv.org/abs/2506.07813)
> *错误：AI分析失败。*

*Junseo Bang, Joonhee Lee, Kyeonghyun Lee, Haechang Lee, Dong Un Kang, Se Young Chun* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [664] [M2Restore: Mixture-of-Experts-based Mamba-CNN Fusion Framework for All-in-One Image Restoration](https://arxiv.org/abs/2506.07814)
> *错误：AI分析失败。*

*Yongzhen Wang, Yongjun Li, Zhuoran Zheng, Xiao-Ping Zhang, Mingqiang Wei* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 8 figures, 3 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [667] [Diffusion models under low-noise regime](https://arxiv.org/abs/2506.07841)
> *错误：AI分析失败。*

*Elizabeth Pavlova, Xue-Xin Wei* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [669] [F2Net: A Frequency-Fused Network for Ultra-High Resolution Remote Sensing Segmentation](https://arxiv.org/abs/2506.07847)
> *错误：AI分析失败。*

*Hengzhi Chen, Liqian Feng, Wenhua Wu, Xiaogang Zhu, Shawn Leo, Kun Hu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [672] [PolyVivid: Vivid Multi-Subject Video Generation with Cross-Modal Interaction and Enhancement](https://arxiv.org/abs/2506.07848)
> *错误：AI分析失败。*

*Teng Hu, Zhentao Yu, Zhengguang Zhou, Jiangning Zhang, Yuan Zhou, Qinglin Lu, Ran Yi* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [674] [SAM2Auto: Auto Annotation Using FLASH](https://arxiv.org/abs/2506.07850)
> *错误：AI分析失败。*

*Arash Rocky, Q. M. Jonathan Wu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [677] [Egocentric Event-Based Vision for Ping Pong Ball Trajectory Prediction](https://arxiv.org/abs/2506.07860)
> *错误：AI分析失败。*

*Ivan Alberico, Marco Cannici, Giovanni Cioffi, Davide Scaramuzza* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** IEEE/CVF Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW), Nashville (TN), USA, 2025; 5th International Workshop on
  Event-Based Vision

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [680] [VIVAT: Virtuous Improving VAE Training through Artifact Mitigation](https://arxiv.org/abs/2506.07863)
> *错误：AI分析失败。*

*Lev Novitskiy, Viacheslav Vasilev, Maria Kovaleva, Vladimir Arkhipkin, Denis Dimitrov* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [684] [Spatio-Temporal State Space Model For Efficient Event-Based Optical Flow](https://arxiv.org/abs/2506.07878)
> *错误：AI分析失败。*

*Muhammad Ahmed Humais, Xiaoqian Huang, Hussain Sajwani, Sajid Javed, Yahya Zweiri* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [686] [CrosswalkNet: An Optimized Deep Learning Framework for Pedestrian Crosswalk Detection in Aerial Images with High-Performance Computing](https://arxiv.org/abs/2506.07885)
> *错误：AI分析失败。*

*Zubin Bhuyan, Yuanchang Xie, AngkeaReach Rith, Xintong Yan, Nasko Apostolov, Jimi Oke, Chengbo Ai* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [689] [EgoM2P: Egocentric Multimodal Multitask Pretraining](https://arxiv.org/abs/2506.07886)
> *错误：AI分析失败。*

*Gen Li, Yutong Chen, Yiqian Wu, Kaifeng Zhao, Marc Pollefeys, Siyu Tang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [691] [Video Unlearning via Low-Rank Refusal Vector](https://arxiv.org/abs/2506.07891)
> *错误：AI分析失败。*

*Simone Facchiano, Stefano Saravalle, Matteo Migliarini, Edoardo De Matteis, Alessio Sampieri, Andrea Pilzer, Emanuele Rodolà, Indro Spinelli, Luca Franco, Fabio Galasso* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [693] [WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning](https://arxiv.org/abs/2506.07905)
> *错误：AI分析失败。*

*Jie Yang, Feipeng Ma, Zitian Wang, Dacheng Yin, Kang Rong, Fengyun Rao, Ruimao Zhang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [695] [A Comparative Study of U-Net Architectures for Change Detection in Satellite Images](https://arxiv.org/abs/2506.07925)
> *错误：AI分析失败。*

*Yaxita Amin, Naimisha S Trivedi, Rashmi Bhattad* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [696] [Mimicking or Reasoning: Rethinking Multi-Modal In-Context Learning in Vision-Language Models](https://arxiv.org/abs/2506.07936)
> *错误：AI分析失败。*

*Chengyue Huang, Yuchen Zhu, Sichen Zhu, Jingyun Xiao, Moises Andrade, Shivang Chopra, Zsolt Kira* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [699] [Decoupling the Image Perception and Multimodal Reasoning for Reasoning Segmentation with Digital Twin Representations](https://arxiv.org/abs/2506.07943)
> *错误：AI分析失败。*

*Yizhen Li, Dell Zhang, Xuelong Li, Yiqing Shen* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [701] [Creating a Historical Migration Dataset from Finnish Church Records, 1800-1920](https://arxiv.org/abs/2506.07960)
> *错误：AI分析失败。*

*Ari Vesalainen, Jenna Kanerva, Aida Nitsch, Kiia Korsu, Ilari Larkiola, Laura Ruotsalainen, Filip Ginter* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [703] [SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design](https://arxiv.org/abs/2506.07964)
> *错误：AI分析失败。*

*Wenxin Tang, Jingyu Xiao, Wenxuan Jiang, Xi Xiao, Yuhang Wang, Xuxin Tang, Qing Li, Yuehe Ma, Junliang Liu, Shisong Tang, Michael R. Lyu* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [705] [SpaCE-10: A Comprehensive Benchmark for Multimodal Large Language Models in Compositional Spatial Intelligence](https://arxiv.org/abs/2506.07966)
> *错误：AI分析失败。*

*Ziyang Gong, Wenhao Li, Oliver Ma, Songyuan Li, Jiayi Ji, Xue Yang, Gen Luo, Junchi Yan, Rongrong Ji* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [707] [CyberV: Cybernetics for Test-time Scaling in Video Understanding](https://arxiv.org/abs/2506.07971)
> *错误：AI分析失败。*

*Jiahao Meng, Shuyang Sun, Yue Tan, Lu Qi, Yunhai Tong, Xiangtai Li, Longyin Wen* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [710] [OneIG-Bench: Omni-dimensional Nuanced Evaluation for Image Generation](https://arxiv.org/abs/2506.07977)
> *错误：AI分析失败。*

*Jingjing Chang, Yixiao Fang, Peng Xing, Shuhan Wu, Wei Cheng, Rui Wang, Xianfang Zeng, Gang Yu, Hai-Bao Chen* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [712] [Real-time Localization of a Soccer Ball from a Single Camera](https://arxiv.org/abs/2506.07981)
> *错误：AI分析失败。*

*Dmitrii Vorobev, Artem Prosvetov, Karim Elhadji Daou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [716] [CXR-LT 2024: A MICCAI challenge on long-tailed, multi-label, and zero-shot disease classification from chest X-ray](https://arxiv.org/abs/2506.07984)
> *错误：AI分析失败。*

*Mingquan Lin, Gregory Holste, Song Wang, Yiliang Zhou, Yishu Wei, Imon Banerjee, Pengyi Chen, Tianjie Dai, Yuexi Du, Nicha C. Dvornek, Yuyan Ge, Zuowei Guo, Shouhei Hanaoka, Dongkyun Kim, Pablo Messina, Yang Lu, Denis Parra, Donghyun Son, Álvaro Soto, Aisha Urooj, René Vidal, Yosuke Yamagishi, Zefan Yang, Ruichi Zhang, Yang Zhou, Leo Anthony Celi, Ronald M. Summers, Zhiyong Lu, Hao Chen, Adam Flanders, George Shih, Zhangyang Wang, Yifan Peng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 17 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [719] [Rethinking Crowd-Sourced Evaluation of Neuron Explanations](https://arxiv.org/abs/2506.07985)
> *错误：AI分析失败。*

*Tuomas Oikarinen, Ge Yan, Akshay Kulkarni, Tsui-Wei Weng* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [722] [Rethinking Cross-Modal Interaction in Multimodal Diffusion Transformers](https://arxiv.org/abs/2506.07986)
> *错误：AI分析失败。*

*Zhengyao Lv, Tianlin Pan, Chenyang Si, Zhaoxi Chen, Wangmeng Zuo, Ziwei Liu, Kwan-Yee K. Wong* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [724] [PairEdit: Learning Semantic Variations for Exemplar-based Image Editing](https://arxiv.org/abs/2506.07992)
> *错误：AI分析失败。*

*Haoguang Lu, Jiacheng Chen, Zhenguo Yang, Aurele Tohokantche Gnanha, Fu Lee Wang, Li Qing, Xudong Mao* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [728] [MADFormer: Mixed Autoregressive and Diffusion Transformers for Continuous Image Generation](https://arxiv.org/abs/2506.07999)
> *错误：AI分析失败。*

*Junhao Chen, Yulia Tsvetkov, Xiaochuang Han* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [731] [Aligning Text, Images, and 3D Structure Token-by-Token](https://arxiv.org/abs/2506.08002)
> *错误：AI分析失败。*

*Aadarsh Sahoo, Vansh Tibrewal, Georgia Gkioxari* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project webpage: https://glab-caltech.github.io/kyvo/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [733] [Audio-Sync Video Generation with Multi-Stream Temporal Control](https://arxiv.org/abs/2506.08003)
> *错误：AI分析失败。*

*Shuchen Weng, Haojie Zheng, Zheng Chang, Si Li, Boxin Shi, Xinlong Wang* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [735] [Dynamic View Synthesis as an Inverse Problem](https://arxiv.org/abs/2506.08004)
> *错误：AI分析失败。*

*Hidir Yesiltepe, Pinar Yanardag* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project Page: https://inverse-dvs.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [738] [ZeroVO: Visual Odometry with Minimal Assumptions](https://arxiv.org/abs/2506.08005)
> *错误：AI分析失败。*

*Lei Lai, Zekai Yin, Eshed Ohn-Bar* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [741] [Dreamland: Controllable World Creation with Simulator and Generative Models](https://arxiv.org/abs/2506.08006)
> *错误：AI分析失败。*

*Sicheng Mo, Ziyang Leng, Leon Liu, Weizhen Wang, Honglin He, Bolei Zhou* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project Page: https://metadriverse.github.io/dreamland/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [743] [Hidden in plain sight: VLMs overlook their visual representations](https://arxiv.org/abs/2506.08008)
> *错误：AI分析失败。*

*Stephanie Fu, Tyler Bonnen, Devin Guillory, Trevor Darrell* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://hidden-plain-sight.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [746] [Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion](https://arxiv.org/abs/2506.08009)
> *错误：AI分析失败。*

*Xun Huang, Zhengqi Li, Guande He, Mingyuan Zhou, Eli Shechtman* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project website: http://self-forcing.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [748] [Vision Transformers Don't Need Trained Registers](https://arxiv.org/abs/2506.08010)
> *错误：AI分析失败。*

*Nick Jiang, Amil Dravid, Alexei Efros, Yossi Gandelsman* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page and code: https://avdravid.github.io/test-time-registers

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [750] [Play to Generalize: Learning to Reason Through Game Play](https://arxiv.org/abs/2506.08011)
> *错误：AI分析失败。*

*Yunfei Xie, Yinsong Ma, Shiyi Lan, Alan Yuille, Junfei Xiao, Chen Wei* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project Page: https://yunfeixie233.github.io/ViGaL/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [751] [StableMTL: Repurposing Latent Diffusion Models for Multi-Task Learning from Partially Annotated Synthetic Datasets](https://arxiv.org/abs/2506.08013)
> *错误：AI分析失败。*

*Anh-Quan Cao, Ivan Lopes, Raoul de Charette* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Code is available at https://github.com/astra-vision/StableMTL

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

### [753] [4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos](https://arxiv.org/abs/2506.08015)
> *错误：AI分析失败。*

*Zhen Xu, Zhengqin Li, Zhao Dong, Xiaowei Zhou, Richard Newcombe, Zhaoyang Lv* | **Main category: cs.CV**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://4dgt.github.io

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscv) | [⬆️ 返回总目录](#toc)

---

<a id='csse'></a>
## cs.SE 

### [11] [Enhancing Software Supply Chain Security Through STRIDE-Based Threat Modelling of CI/CD Pipelines](https://arxiv.org/abs/2506.06478)
> *错误：AI分析失败。*

*Sowmiya Dhandapani* | **Main category: cs.SE**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [25] [Information-Theoretic Detection of Unusual Source Code Changes](https://arxiv.org/abs/2506.06508)
> *基于信息论的异常源代码变更检测*

*Adriano Torres, Sebastian Baltes, Christoph Treude, Markus Wagner* | **Main category: cs.SE**

**Keywords:** 信息论, 源代码变更, 熵, 异常检测, 代码复杂度

**Comment:** 48 pages, 17 figures, 7 tables, accepted for publication in the
  Empirical Software Engineering journal

> **TL;DR:** 本文提出了一种基于信息论的方法来检测异常源代码变更，通过测量令牌和抽象语法树节点的熵来评估代码的信息内容和演化模式，并发现该方法能有效识别异常变更。

**AI_Comments:** 本文创新性地将信息论引入源代码变更检测和复杂度度量，通过熵的概念为代码演化分析提供了新的视角。其提出的文本熵和结构熵概念，并结合实证评估，证明了信息论方法在识别异常变更方面的潜力，且可能捕捉到传统度量未涵盖的复杂度维度，对于软件质量保证和维护具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 软件项目的代码库通过插入和删除信息不断演化，现有方法可能无法完全捕捉代码复杂度的所有维度。本研究旨在从信息论角度测量源代码的信息内容，并检测异常变更，以期为静态衡量程序复杂度提供新方法。

**Method:** 研究从信息论角度出发，关注代码的两种基本表示（令牌和抽象语法树节点）的熵，并推导出文本熵和结构熵的定义。通过对95个活跃维护的开源项目进行实证评估，计算了熵指标与经典代码复杂度度量之间的统计关系。最后，进行了基于熵的异常检测。

**Result:** 研究发现熵可能捕捉到与经典度量不同的复杂度维度。基于熵的异常检测方法能够以超过60%的精度有效识别异常源代码变更事件。

**Conclusion:** 本文为信息论测量源代码演化奠定了基础，为静态衡量程序开发过程中的复杂度提供了一种新方法。

> **ai_Abstract:** 本文提出了一种基于信息论的异常源代码变更检测方法。研究通过测量开源项目源代码中令牌和抽象语法树节点的熵来定义文本熵和结构熵，并评估了95个开源项目的熵演化模式。结果表明，熵能捕捉到与传统指标不同的代码复杂度维度，并且基于熵的异常检测方法能够以超过60%的精度有效识别异常源代码变更事件。这项工作为信息论视角下的源代码演化测量和静态程序复杂度评估提供了新途径。

> **摘要翻译:** 软件项目的代码库主要通过向源代码中插入和删除信息来演化。我们可以通过代码相应表示的信息元素——令牌、单词、节点——来衡量这种演化。在这项工作中，我们从信息论的角度来衡量开源项目源代码的信息内容。我们的重点是代码的两种基本表示形式：令牌和抽象语法树节点的熵，并从中推导出文本熵和结构熵的定义。我们进行了一项实证评估，评估了95个活跃维护的开源项目的熵演化模式。我们计算了我们推导出的熵指标与衡量代码复杂度的经典方法之间的统计关系，并发现熵可能捕捉到与经典指标不同的复杂度维度。最后，我们进行了基于熵的异常检测，以证明我们的方法可以有效识别异常源代码变更事件，精度超过60%，并为信息论测量源代码演进奠定了基础，从而为在程序开发过程中静态衡量程序复杂度铺平了道路。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [39] [Private GPTs for LLM-driven testing in software development and machine learning](https://arxiv.org/abs/2506.06509)
> *用于软件开发和机器学习中基于LLM的测试的私有GPTs*

*Jakub Jagielski, Markus Abel* | **Main category: cs.SE**

**Keywords:** 私有GPTs, LLM驱动测试, 自动化测试, 软件开发, Gherkin语法

**Comment:** 5 pages, 10 figures

> **TL;DR:** 本文探讨了私有GPTs根据需求自动生成可执行测试代码的能力，发现两步过程（通过Gherkin语法）和结构化提示能产生更高质量的测试。

**AI_Comments:** 该研究探讨了利用私有GPTs实现LLM驱动的测试自动化，这在当前AI辅助软件开发的背景下具有重要意义。特别是，它为产品所有者直接生成可测试标准提供了潜在途径，弥合了业务需求与技术实现之间的鸿沟。比较直接生成和通过Gherkin语法中间步骤的方法，并得出两步法更优的结论，为实际应用提供了有价值的指导。对结构化提示词有效性的强调也进一步提升了其实用性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探究私有GPTs自动根据需求（如验收标准）生成可执行测试代码的能力，从而让产品负责人或业务智能人员能够直接通过大型语言模型（LLMs）生成可测试标准。

**Method:** 研究人员使用私有GPTs，以验收标准作为输入，探索了两种生成测试代码的方式：1) LLM直接从需求生成代码；2) 通过使用Gherkin语法作为中间步骤。他们通过评估提示词在“Hello World”程序和数字分类模型两个场景中的有效性来衡量所生成测试的质量。

**Result:** 结果表明，两步过程（通过Gherkin语法）能产生更好的测试结果，这体现在人类可读性和最佳编码实践（如代码行数和附加库的使用）方面。此外，结构化提示词能带来更高质量的测试输出。

**Conclusion:** 本文得出结论，私有GPTs能够有效地根据需求生成可执行测试代码，并且采用中间步骤（如Gherkin语法）和结构化提示词可以显著提高生成测试的质量和实用性。

> **ai_Abstract:** 本文研究了私有GPTs在软件开发和机器学习中根据需求自动生成可执行测试代码的能力。研究人员利用验收标准作为输入，比较了LLM直接生成测试代码和通过Gherkin语法作为中间步骤的两种方法。实验结果表明，采用两步过程（通过Gherkin语法）能生成更高质量的测试，并在“Hello World”程序和数字分类模型场景中验证了结构化提示词能提升测试输出的质量。

> **摘要翻译:** 在这项贡献中，我们检验了私有GPTs根据需求自动生成可执行测试代码的能力。更具体地说，我们使用验收标准作为输入，这些标准通常以史诗或故事的形式在现代开发流程中使用。这使得产品负责人或业务智能人员能够分别通过使用大型语言模型（LLMs）直接生成可测试的标准。我们通过两种方式探索了所生成测试的质量：i）直接让LLM从需求生成代码，ii）通过使用Gherkin语法作为中间步骤。结果表明，两步过程产生了更好的结果——我们将“更好”定义为人类可读性和最佳编码实践，即代码行数和测试中通常使用的额外库的使用。具体来说，我们在两种场景中评估了提示词的有效性：一个简单的“Hello World”程序和一个数字分类模型，结果显示结构化提示词能带来更高质量的测试输出。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [54] [Mind the Gap: A Readability-Aware Metric for Test Code Complexity](https://arxiv.org/abs/2506.06764)
> *注意差距：一种测试代码复杂度的可读性感知度量*

*Wendkûuni C. Ouédraogo, Yinghua Li, Xueqi Dang, Xin Zhou, Anil Koyuncu, Jacques Klein, David Lo, Tegawendé F. Bissyandé* | **Main category: cs.SE**

**Keywords:** 测试代码复杂度, 可读性度量, CCTR, 单元测试, 生成测试

**Comment:** 

> **TL;DR:** 本文提出了一种名为CCTR的测试代码认知复杂度度量，该度量专门针对单元测试，并考虑了传统复杂度模型忽略的结构和语义特征，实验证明CCTR能有效区分结构化和碎片化的测试套件，并更好地反映开发者感知的复杂性，为评估和改进自动生成的测试提供了更可靠的基础。

**AI_Comments:** 本文的创新之处在于提出了CCTR这一专门针对单元测试的认知复杂度度量，它弥补了传统复杂度指标在评估自动生成测试方面存在的“差距”。通过整合断言密度、注解角色和测试组合模式等测试特有特征，CCTR能够更准确地反映测试代码的实际复杂性和可读性，这对于当前LLM等工具大量生成测试代码的背景下尤为重要。其重要性体现在为自动化测试的质量评估提供了更可靠的工具，有助于改进生成测试的质量。

<details>
  <summary>Details</summary>

**Motivation:** 自动生成的单元测试在结构和可读性上差异显著，但现有的大多数评估指标（如圈复杂度、认知复杂度）是为功能代码而非测试代码设计的。这些传统指标对LLM生成的测试评分接近零，且对EvoSuite生成的测试的行为及其对测试特有代码结构的适用性尚未被充分探索，这导致了评估自动生成测试的局限性。

**Method:** 本文引入了CCTR（Test-Aware Cognitive Complexity），一种专门为单元测试定制的测试感知认知复杂度度量。CCTR整合了结构和语义特征，例如断言密度、注解角色和测试组合模式。研究人员在Defects4J和SF110的350个类上，评估了由EvoSuite、GPT-4o和Mistral Large-1024生成的15,750个测试套件。

**Result:** 结果表明，CCTR能有效区分结构化和碎片化的测试套件，并产生可解释的评分，这些评分能更好地反映开发者感知的努力。CCTR通过弥合结构分析和测试可读性之间的差距，为生成测试的更可靠评估和改进提供了基础。

**Conclusion:** CCTR通过整合结构分析和测试可读性，为自动生成的测试提供了一个更可靠的评估和改进的基础。

> **ai_Abstract:** 针对自动生成的单元测试在结构和可读性上的显著差异以及现有复杂度指标（如圈复杂度、认知复杂度）不适用于测试代码的问题，本文提出了一种名为CCTR的测试感知认知复杂度度量。CCTR专门为单元测试定制，并整合了断言密度、注解角色和测试组合模式等结构和语义特征。通过在Defects4J和SF110的350个类上对15,750个由EvoSuite、GPT-4o和Mistral Large-1024生成的测试套件进行评估，结果显示CCTR能够有效地区分结构化和碎片化的测试套件，并产生更符合开发者感知努力的可解释评分。CCTR的引入为自动生成测试的更可靠评估和改进奠定了基础。

> **摘要翻译:** 自动生成的单元测试——来自像EvoSuite这样的基于搜索的工具或大型语言模型（LLMs）——在结构和可读性上差异显著。然而，大多数评估依赖于像圈复杂度（Cyclomatic Complexity）和认知复杂度（Cognitive Complexity）这样的指标，这些指标是为功能代码而不是测试代码设计的。最近的研究表明，SonarSource的认知复杂度指标对LLM生成的测试分配了接近零的分数，但其在EvoSuite生成的测试上的行为及其对测试特定代码结构的适用性仍未被探索。我们引入了CCTR，一种专门为单元测试定制的测试感知认知复杂度度量。CCTR整合了结构和语义特征，如断言密度、注解角色和测试组合模式——这些维度被传统复杂度模型所忽略，但对理解测试代码至关重要。我们评估了来自Defects4J和SF110的350个类中，由EvoSuite、GPT-4o和Mistral Large-1024生成的15,750个测试套件。结果显示CCTR能有效区分结构化和碎片化的测试套件，产生可解释的评分，这些评分能更好地反映开发者感知的努力。通过弥合结构分析和测试可读性之间的差距，CCTR为生成测试的更可靠评估和改进提供了基础。我们公开所有数据、提示和评估脚本以支持复现。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [69] [Beyond Surface Similarity: Evaluating LLM-Based Test Refactorings with Structural and Semantic Awareness](https://arxiv.org/abs/2506.06767)
> *超越表面相似性：通过结构和语义感知评估基于LLM的测试重构*

*Wendkûuni C. Ouédraogo, Yinghua Li, Xueqi Dang, Xin Zhou, Anil Koyuncu, Jacques Klein, David Lo, Tegawendé F. Bissyandé* | **Main category: cs.SE**

**Keywords:** LLM, 测试重构, 评估指标, CTSES, 单元测试

**Comment:** 

> **TL;DR:** 引入CTSES，一种复合度量，用于更准确地评估LLM驱动的单元测试重构，克服了现有度量的局限性。

**AI_Comments:** 该论文的创新之处在于提出了CTSES这一复合度量，有效解决了LLM驱动的测试重构评估中的现有挑战。通过整合多种指标，CTSES能够更全面地评估重构的质量，包括行为保持、词汇质量和结构对齐，这对于提高LLM在软件工程中的应用至关重要。其重要性在于为未来LLM在代码重构领域的应用提供了更可靠的评估工具。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）被越来越多地用于自动化重构单元测试，以提高可读性、命名和结构清晰度，同时保持功能行为。然而，评估此类重构仍然具有挑战性：传统的度量标准对重命名和结构编辑过于敏感，而基于嵌入的相似性捕获语义但忽略可读性和模块化。

**Method:** 本文引入了CTSES，一种复合度量，它整合了CodeBLEU、METEOR和ROUGE-L，以平衡行为保留、词汇质量和结构对齐。CTSES在超过5,000个由GPT-4o和Mistral-Large-2407使用思维链提示自动重构的测试套件上进行了评估，涵盖两个已建立的Java基准：Defects4J和SF110。

**Result:** 我们的结果表明，CTSES产生了更忠实和可解释的评估，比现有度量更好地符合开发人员的期望和人类直觉。

**Conclusion:** CTSES作为一种新的复合度量，能够对LLM驱动的测试重构进行更准确、更符合人类直觉的评估，从而克服了现有评估方法的局限性。

> **ai_Abstract:** 本研究提出了一种名为CTSES的复合度量，用于评估大型语言模型（LLM）驱动的单元测试重构。针对现有评估方法在可读性、模块化和行为保留方面的不足，CTSES结合了CodeBLEU、METEOR和ROUGE-L，以提供更全面、更准确的评估。在GPT-4o和Mistral-Large-2407重构的Java测试套件上的实验表明，CTSES的评估结果与开发人员的期望和人类直觉更一致。

> **摘要翻译:** 大型语言模型（LLM）正越来越多地被用于自动化重构单元测试，旨在提高可读性、命名和结构清晰度，同时保留功能行为。然而，评估此类重构仍然具有挑战性：像CodeBLEU这样的传统度量对重命名和结构编辑过于敏感，而基于嵌入的相似性虽然能捕获语义，但却忽略了可读性和模块化。我们引入了CTSES，这是一种复合度量，它整合了CodeBLEU、METEOR和ROUGE-L，以平衡行为保留、词汇质量和结构对齐。CTSES在超过5,000个由GPT-4o和Mistral-Large-2407使用思维链提示自动重构的测试套件上进行了评估，涵盖两个已建立的Java基准：Defects4J和SF110。我们的结果表明，CTSES产生了更忠实和可解释的评估，比现有度量更好地符合开发人员的期望和人类直觉。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [82] [Taxonomy of migration scenarios for Qiskit refactoring using LLMs](https://arxiv.org/abs/2506.07135)
> *使用LLM对Qiskit重构迁移场景进行分类*

*José Manuel Suárez, Luís Mariano Bibbó, Joaquín Bogado, Alejandro Fernandez* | **Main category: cs.SE**

**Keywords:** 量子计算, Qiskit, 重构, 大型语言模型, 分类法

**Comment:** Accepted for publication in ASQC JAIIO 54
  (https://54jaiio.sadio.org.ar/simposios/)

> **TL;DR:** 量子编程库Qiskit的频繁更新导致重构挑战。本研究通过LLM和专家方法构建并统一了Qiskit重构迁移场景的分类法，为AI辅助迁移和量子软件工程奠定基础。

**AI_Comments:** 这篇论文通过引入LLM来解决量子软件工程中独特的重构挑战，具有创新性。它提供了一个结构化的分类法，这对于理解和管理量子编程库的快速演进至关重要。统一专家和LLM方法提高了分类法的鲁棒性和实用性，为未来AI在量子软件开发中的应用铺平了道路。

<details>
  <summary>Details</summary>

**Motivation:** 量子计算发展导致量子编程库的异构性和快速演进，频繁的软件更新使得现有代码需要重构，这在量子软件工程中与经典软件工程面临的重构挑战不同，增加了复杂性。LLM在经典软件开发中很有价值，但在量子软件工程中的价值尚未探索。

**Method:** 本研究开发了量子电路重构问题的分类法，并利用大型语言模型（LLMs）对Qiskit不同版本间的迁移重构需求进行分类。通过审查Qiskit文档和发布说明，创建了重构的初始分类法。生成了由专家和LLM分别构建的两种分类法，并对其进行比较、分析异同，最终整合为一个统一的分类法。

**Result:** 本研究成功创建了一个统一的Qiskit重构迁移场景分类法，该分类法结合了专家开发者和LLM的分析结果。

**Conclusion:** 统一的Qiskit重构分类法为未来AI辅助迁移的研究奠定了基础，并能更严格地评估自动化重构技术。此外，这项工作通过增强软件开发工作流、提高语言兼容性及推广最佳实践，对量子软件工程（QSE）做出了贡献。

> **ai_Abstract:** 本研究旨在解决量子编程库（特别是Qiskit）频繁更新导致的重构挑战。通过结合专家知识和大型语言模型（LLMs），研究人员开发了一个统一的Qiskit重构迁移场景分类法。该分类法系统地识别并组织了重构需求，为未来AI辅助量子软件迁移工具的开发和自动化重构技术的评估提供了基础，并对量子软件工程做出了贡献。

> **摘要翻译:** 随着量子计算的发展，量子编程库的异构性和持续演进给软件开发人员带来了新的挑战。软件库的频繁更新会破坏现有代码，需要进行重构，从而增加了本已复杂的领域中的复杂性。由于量子计算软件的性质，这些重构挑战在许多情况下与经典软件工程中已知的挑战根本不同。本研究通过开发量子电路重构问题的分类法来应对这些挑战，提供了一个结构化的框架来分析和比较不同的重构方法。大型语言模型（LLMs）已被证明是经典软件开发的宝贵工具，但它们在量子软件工程中的价值尚未被探索。本研究使用LLMs来分类Qiskit不同版本之间迁移场景中的重构需求。对Qiskit文档和发布说明进行了仔细审查，以创建在Qiskit版本之间迁移所需的重构的初始分类法。生成了两种分类法：一种由专家开发人员生成，另一种由LLM生成。对这些分类法进行了比较，分析了差异和相似性，并将其整合为一个统一的分类法，反映了两种方法的结果。通过系统地分类Qiskit中的重构挑战，统一的分类法为未来AI辅助迁移的研究奠定了基础，同时能够更严格地评估自动化重构技术。此外，这项工作通过增强软件开发工作流、提高语言兼容性以及推广量子编程的最佳实践，为量子软件工程（QSE）做出了贡献。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [83] [Is Your Training Pipeline Production-Ready? A Case Study in the Healthcare Domain](https://arxiv.org/abs/2506.06946)
> *您的训练管道准备好投入生产了吗？医疗保健领域的一个案例研究*

*Daniel Lawand, Lucas Quaresma, Roberto Bolgheroni, Alfredo Goldman, Renato Cordeiro Ferreira* | **Main category: cs.SE**

**Keywords:** 机器学习, MLOps, 训练管道, 软件工程, 医疗保健, 微服务

**Comment:** 9 pages, 3 figures (2 diagrams, 1 code listing), submitted to the
  workshop SADIS 2025

> **TL;DR:** 本文通过一个医疗保健项目（SPIRA）的案例研究，探讨了机器学习训练管道如何从初始的“一团糟”演变为微服务架构，强调了生产就绪所需的软件工程实践。

**AI_Comments:** 该论文作为一份实践案例研究非常有价值，它清晰地展示了机器学习训练管道从实验阶段到生产就绪系统的演变过程。它强调了软件工程原则和架构选择（如转向微服务）在实现健壮和可维护的MLOps中的关键作用。其对医疗保健领域的关注增加了特定的相关性。

<details>
  <summary>Details</summary>

**Motivation:** 将机器学习训练管道部署到生产环境需要强大的软件工程实践，这与实验性工作流程显著不同。本文旨在调查这一挑战，并为负责将ML训练管道投入生产的ML工程师和寻求采用MLOps实践的数据科学家提供见解。

**Method:** 本文采用案例研究方法，以SPIRA项目为例，比较了其持续训练子系统架构的三个版本，从“一团糟”演变为模块化单体，再到微服务。通过采用不同的设计原则和模式来增强其可维护性、鲁棒性和可扩展性。

**Result:** SPIRA项目的训练管道架构经过演变，从缺乏关键软件质量属性的初始版本，通过采用不同的设计原则和模式，成功提升了可维护性、鲁棒性和可扩展性。

**Conclusion:** 将ML训练管道部署到生产环境需要采纳强大的软件工程实践和不断演进的架构（如从单体到微服务），这对于ML工程师和数据科学家实现MLOps实践至关重要。

> **ai_Abstract:** 本文是一份经验报告，详细介绍了医疗保健领域SPIRA项目中的机器学习训练管道如何从最初缺乏软件质量属性的版本，通过架构演进（从“一团糟”到模块化单体再到微服务），逐步提升其可维护性、鲁棒性和可扩展性。它强调了在生产环境中部署ML训练管道所需强大的软件工程实践，并为ML工程师和数据科学家提供关于MLOps实践的实用见解。

> **摘要翻译:** 将机器学习 (ML) 训练管道部署到生产环境需要强大的软件工程实践。这与实验性工作流程显著不同。这份经验报告调查了 SPIRA 项目中的这一挑战，该项目的目标是创建一个支持 ML 的系统 (MLES)，通过语音分析预诊断呼吸不足。SPIRA 训练管道的第一个版本缺乏关键的软件质量属性。本文概述了 MLES，然后比较了持续训练子系统架构的三个版本，这些版本从“一团糟”演变为模块化单体，再到微服务。通过采用不同的设计原则和模式来增强其可维护性、鲁棒性和可扩展性。通过这种方式，本文旨在为负责将 ML 训练管道投入生产的 ML 工程师和寻求采用 MLOps 实践的数据科学家提供见解。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [110] [GUIPilot: A Consistency-based Mobile GUI Testing Approach for Detecting Application-specific Bugs](https://arxiv.org/abs/2506.07385)
> *GUIPilot：一种基于一致性的移动GUI测试方法，用于检测应用程序特定错误*

*Ruofan Liu, Xiwen Teoh, Yun Lin, Guanjie Chen, Ruofei Ren, Denys Poshyvanyk, Jin Song Dong* | **Main category: cs.SE**

**Keywords:** 移动GUI测试, 一致性检测, 应用程序错误, 屏幕不一致性, 过程不一致性

**Comment:** 

> **TL;DR:** GUIPilot通过检测移动应用设计与实现之间的屏幕和过程不一致性来发现应用程序错误。

**AI_Comments:** GUIPilot的创新之处在于其结合了对屏幕布局（静态）和GUI行为（动态）一致性的检测，并通过将问题转化为可优化的小部件对齐和利用视觉-语言模型来解决。其在实际应用中的高精确度和发现实际bug的能力显示了其重要的实用价值，为移动应用测试提供了一种有效的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 移动设计通常包括设计模型，用于指定预期的屏幕外观和行为。然而，实现可能与设计不一致，需要一种有效的方法来检测这些不一致性以发现应用程序错误。

**Method:** GUIPilot旨在检测设计模型与应用程序实现之间的屏幕不一致性和过程不一致性。对于屏幕不一致性，它将每个屏幕抽象为小部件容器，通过定义小部件的偏序和操作成本，将屏幕匹配问题转化为可优化的小部件对齐问题。对于过程不一致性，它将指定的GUI转换转化为移动屏幕上的逐步操作（如点击、长按），并利用视觉-语言模型推断小部件特定操作，以验证预期转换的存在或缺失。

**Result:** 在80个移动应用和160个设计模型上的实验表明：GUIPilot在检测屏幕不一致性方面达到94.5%的精确度和99.6%的召回率，分别比最先进的方法（如GVT）高出66.2%和56.6%。在检测过程不一致性方面报告零错误。此外，在交易移动应用程序上的工业案例研究中，GUIPilot检测到9个应用程序错误，并均得到专家确认。

**Conclusion:** GUIPilot是一种高效且准确的移动GUI测试方法，能够有效检测设计与实现之间的屏幕和过程不一致性，并通过在实际应用中发现错误，证明了其优越性和实用价值。

> **ai_Abstract:** GUIPilot是一种基于一致性的移动GUI测试方法，旨在通过检测移动设计模型与其应用实现之间的屏幕和过程不一致性来发现应用程序错误。它通过将屏幕匹配转换为小部件对齐问题来识别屏幕布局差异，并利用视觉-语言模型推断动作以验证GUI转换。实验结果表明，GUIPilot在检测屏幕和过程不一致性方面表现出高精度和召回率，并成功在实际应用中发现错误，优于现有技术。

> **摘要翻译:** 在这项工作中，我们提出了GUIPilot，一种用于检测移动设计与其实现之间不一致性的方法。移动设计通常包括设计模型，这些模型指定了（1）预期的屏幕外观（例如，小部件布局、颜色和形状）和（2）预期的屏幕行为，涉及一个屏幕如何过渡到另一个屏幕（例如，带有文本描述的标签小部件）。给定一个设计模型及其应用程序的实现，GUIPilot报告它们的屏幕不一致性以及过程不一致性。一方面，GUIPilot通过将每个屏幕抽象为一个小部件容器来检测屏幕不一致性，其中每个小部件由其位置、宽度、高度和类型表示。通过定义小部件的偏序以及屏幕中小部件替换、插入和删除的成本，我们将屏幕匹配问题转换为一个可优化的小部件对齐问题。另一方面，我们将指定的GUI转换转化为移动屏幕上的逐步操作（例如，点击、长按、在某些小部件上输入文本）。为此，我们提出了一个视觉提示，供视觉-语言模型推断屏幕上特定于小部件的操作。通过这种方式，我们可以验证实现中预期转换的存在或缺失。我们对80个移动应用程序和160个设计模型的广泛实验表明：（1）GUIPilot在检测屏幕不一致性方面可以达到94.5%的精确度和99.6%的召回率，分别比最先进的方法（如GVT）高出66.2%和56.6%，并且（2）GUIPilot在检测过程不一致性方面报告零错误。此外，我们对将GUIPilot应用于交易移动应用程序的工业案例研究表明，GUIPilot检测到九个应用程序错误，所有错误都得到了原始应用程序专家的确认。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [124] [Generate Realistic Test Scenes for V2X Communication Systems](https://arxiv.org/abs/2506.07419)
> *生成V2X通信系统逼真测试场景*

*An Guo, Xinyu Gao, Chunrong Fang, Haoxiang Tian, Weisong Sun, Yanzhou Mu, Shuncheng Tang, Lei Ma, Zhenyu Chen* | **Main category: cs.SE**

**Keywords:** V2X通信, 协同感知, 测试场景生成, 自动化测试, V2XGen

**Comment:** 

> **TL;DR:** V2XGen是一个自动测试场景生成工具，能生成逼真的V2X场景并有效检测系统错误，还能通过再训练提升感知性能。

**AI_Comments:** V2XGen的创新之处在于其自动化生成逼真V2X测试场景的能力，解决了手动数据收集和标记耗时耗费的问题。其适应度引导的场景生成策略和高保真对象实例生成方法，使得生成的场景能够有效检测系统错误并提升协同感知系统的性能，对于V2X系统的开发和测试具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆的安全运行需要准确感知复杂驾驶环境。V2X协同感知技术可以克服单智能体感知的局限性，但需要彻底的测试和持续的性能提升。创建V2X测试场景面临挑战，因为涉及多车、多地理位置的复杂通信，且现有测试方法耗时且成本高昂。

**Method:** 本文设计并实现了V2XGen，一个用于V2X协同感知系统的自动化测试生成工具。V2XGen采用高保真方法生成逼真的协同对象实例，并将其策略性地放置在背景数据中的关键位置。此外，V2XGen采用适应度引导的V2X场景生成策略进行场景转换生成过程，并提高了测试效率。

**Result:** 实验结果表明，V2XGen能够生成逼真的测试场景，并有效检测不同V2X驾驶条件下的错误行为。此外，结果验证了使用生成场景对被测系统进行再训练可以提高平均检测精度，同时减少遮挡和远距离感知错误。

**Conclusion:** V2XGen能够生成逼真的V2X测试场景，有效检测系统错误，并通过再训练提升协同感知系统的性能，从而克服了现有测试方法的挑战。

> **ai_Abstract:** 本文提出V2XGen，一个用于V2X协同感知系统的自动化测试场景生成工具。针对现有测试方法耗时且成本高的问题，V2XGen通过高保真方法生成逼真的协同对象实例并进行策略性放置，同时采用适应度引导策略提高效率。实验证明V2XGen能生成逼真场景，有效检测系统错误行为，并且使用生成场景进行再训练可提升检测精度并减少感知错误。

> **摘要翻译:** 准确感知复杂的驾驶环境对于确保自动驾驶车辆的安全运行至关重要。随着深度学习和通信技术的巨大进步，V2X（车联网）技术的协同感知已成为克服单智能体感知系统在感知远距离物体和遮挡方面的局限性的一种解决方案。尽管取得了长足的进步，V2X协同感知系统仍需要彻底的测试和系统性能的持续增强。鉴于V2X驾驶场景涉及多个车辆在不同地理位置的复杂通信，为这些系统创建V2X测试场景带来了重大挑战。此外，当前的测试方法依赖于手动数据收集和标记，这既耗时又昂贵。
在本文中，我们设计并实现了V2XGen，一个用于V2X协同感知系统的自动化测试生成工具。V2XGen利用高保真方法生成逼真的协同对象实例，并将其策略性地放置在背景数据中的关键位置。此外，V2XGen采用适应度引导的V2X场景生成策略进行转换后的场景生成过程，并提高了测试效率。我们使用具有不同融合方案的多个协同感知系统对V2XGen进行了实验，以评估其在各种任务上的性能。实验结果表明，V2XGen能够生成逼真的测试场景，并有效检测不同V2X驾驶条件下的错误行为。此外，结果验证了使用生成场景对被测系统进行再训练可以提高平均检测精度，同时减少遮挡和远距离感知错误。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [137] [A Framework for Creating Non-Regressive Test Cases via Branch Consistency Analysis Driven by Descriptions](https://arxiv.org/abs/2506.07486)
> *一种基于描述驱动的分支一致性分析生成非回归测试用例的框架*

*Yuxiang Zhang, Pengyu Xue, Zhen Yang, Xiaoxue Ren, Xiang Li, Linhao Wu, Jiancheng Zhao, Xingda Yu* | **Main category: cs.SE**

**Keywords:** 非回归测试, LLM, 测试生成, 分支一致性, 缺陷检测

**Comment:** 

> **TL;DR:** 现有的自动化测试生成在有缺陷的方法上表现不佳。本文提出了DISTINCT框架，它利用自然语言描述和分支一致性分析，将大型语言模型（LLM）转化为故障感知测试生成器，显著提高了缺陷检测率。

**AI_Comments:** 该论文的创新之处在于它改变了LLM在测试生成中的角色，使其从单纯追求代码覆盖率转变为能够有效检测缺陷的工具。通过引入自然语言描述和精细的分支一致性分析，DISTINCT框架为LLM提供了更深层次的语义理解能力，从而能够生成更具故障敏感性的测试用例。这对于处理实际软件开发中常见的非回归场景，即需要测试可能存在缺陷的方法，具有重要的实践意义和价值。

<details>
  <summary>Details</summary>

**Motivation:** 自动化测试生成研究普遍假设核心方法是正确的，但实际中测试人员经常面临核心方法可能存在缺陷的非回归场景。基线评估显示，EvoSuite和两个领先的基于LLM的生成器（ChatTester和ChatUniTest）在有缺陷的核心方法上，尽管分支覆盖率高达83%，但都未能暴露缺陷。

**Method:** 本文提出了DISTINCT，一个由描述引导的分支一致性分析框架，它将LLM转化为故障感知测试生成器。为此，作者首先构建了两个新的基准测试集：Defects4J-Desc和QuixBugs-Desc，其中每个核心方法都附带额外的自然语言描述（NLD）以帮助理解代码功能。DISTINCT包含三个迭代组件：(1) 生成器：根据NLD和核心方法推导初始测试；(2) 验证器：使用编译器诊断迭代修复不可编译的测试；(3) 分析器：通过分支级分析迭代地将测试行为与NLD语义对齐。

**Result:** 与现有技术相比，DISTINCT在两个基准测试集上，编译成功率（CSR）平均提高了14.64%，通过率（PR）平均提高了6.66%。它显著提高了两个基准测试集上的缺陷检测率（DDR），尤其在Defects4J-Desc上观测到149.26%的显著提升。在代码覆盖率方面，DISTINCT使语句覆盖率（SC）平均提高了3.77%，分支覆盖率（BC）提高了5.36%。

**Conclusion:** 这些结果为非回归测试生成设定了新的基线，并强调了描述驱动的推理如何使LLM超越单纯的覆盖率追求，转向有效的缺陷检测。

> **ai_Abstract:** 本文旨在解决当前自动化测试生成在缺陷方法上表现不佳的问题，特别是LLM生成的测试尽管覆盖率高但未能有效检测缺陷。为此，作者提出了DISTINCT框架，该框架利用自然语言描述和分支一致性分析，将LLM转化为故障感知测试生成器。DISTINCT通过生成、验证和分析三个迭代组件，显著提升了测试的编译成功率、通过率，并大幅提高了缺陷检测率，尤其在特定基准测试集上实现了近150%的提升。这项工作为非回归测试生成树立了新标杆，并展示了描述驱动推理在使LLM实现有效缺陷检测方面的潜力。

> **摘要翻译:** 自动化测试生成研究绝大多数都假设核心方法是正确的，然而实际操作者经常面临核心方法可能有缺陷的非回归场景。对EvoSuite和两个领先的基于大型语言模型（LLM）的生成器（即ChatTester和ChatUniTest）在有缺陷的核心方法上的基线评估显示，尽管分支覆盖率高达83%，但生成的测试均未能暴露缺陷。
为了解决这个问题，我们首先构建了两个新的实验基准测试集，即Defects4J-Desc和QuixBugs-Desc。特别是，每个核心方法都配备了额外的自然语言描述（NLD），以便理解代码功能。
随后，我们提出了DISTINCT，一个由描述引导的分支一致性分析框架，它将LLM转化为故障感知测试生成器。DISTINCT包含三个迭代组件：(1) 一个生成器，根据NLD和核心方法推导初始测试；(2) 一个验证器，使用编译器诊断迭代修复不可编译的测试；(3) 一个分析器，通过分支级分析迭代地将测试行为与NLD语义对齐。
广泛的实验证实了我们方法的有效性。与现有最先进的方法相比，DISTINCT在两个基准测试集上，编译成功率（CSR）平均提高了14.64%，通过率（PR）平均提高了6.66%。它显著提高了两个基准测试集上的缺陷检测率（DDR），尤其在Defects4J-Desc上观测到149.26%的显著提升。在代码覆盖率方面，DISTINCT使语句覆盖率（SC）平均提高了3.77%，分支覆盖率（BC）提高了5.36%。这些结果为非回归测试生成设定了新的基线，并强调了描述驱动的推理如何使LLM超越单纯的覆盖率追求，转向有效的缺陷检测。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [148] [Large Language Models for Multilingual Vulnerability Detection: How Far Are We?](https://arxiv.org/abs/2506.07503)
> *大型语言模型在多语言漏洞检测中的应用：我们进展如何？*

*Honglin Shu, Michael Fu, Junji Yu, Dong Wang, Chakkrit Tantithamthavorn, Junjie Chen, Yasutaka Kamei* | **Main category: cs.SE**

**Keywords:** 大型语言模型, 漏洞检测, 多语言, 软件安全, GPT-4o

**Comment:** 33 pages, 9 figures

> **TL;DR:** 本研究全面评估了PLM和LLM在多语言、多粒度漏洞检测中的有效性。结果显示，经过指令微调和少样本提示的GPT-4o显著优于其他模型，尤其在检测多语言和高危漏洞方面表现出色，揭示了LLM在该领域的巨大潜力。

**AI_Comments:** 这项研究首次对PLM和LLM在多语言、多粒度漏洞检测中的表现进行了全面实证评估，填补了现有研究的空白。其创新之处在于使用了大量真实世界的跨语言补丁数据，并深入分析了模型在不同粒度（函数级和行级）下的性能。研究结果明确指出GPT-4o在这一领域的领先地位，并强调了LLM在识别高危漏洞方面的独特优势，为未来的软件安全研究和实践提供了重要指导。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要关注特定编程语言（如C/C++）和函数级漏洞检测，PLM和LLM在多语言、多粒度场景下的优缺点尚未充分探索。本研究旨在弥补这一空白。

**Method:** 作者进行了一项全面的细粒度实证研究，评估了最先进的PLM和LLM在多语言漏洞检测中的有效性。使用了来自七种编程语言的30,000多个真实世界漏洞修复补丁，并系统地评估了模型在函数级和行级的性能。

**Result:** GPT-4o（通过指令微调和少样本提示增强）显著优于所有其他评估模型，包括CodeT5P。基于LLM的方法在检测独特的多语言漏洞方面表现出卓越的能力，尤其擅长识别最危险和高严重性漏洞。

**Conclusion:** LLM在多语言、函数级和行级漏洞检测方面具有巨大的应用潜力，它们与PLM方法相比展现出互补的优势和显著的改进。这是PLM和LLM在多语言漏洞检测领域的首次实证评估，突显了LLM在解决实际软件安全挑战中的价值。

> **ai_Abstract:** 本研究旨在弥补多语言、多粒度漏洞检测领域中PLM和LLM评估的空白。作者进行了一项细致的实证研究，使用涵盖七种编程语言的30,000多个真实漏洞修复补丁，在函数级和行级评估了最先进的PLM和LLM。研究发现，经过指令微调和少样本提示的GPT-4o在所有评估模型中表现最佳，尤其在检测多语言和高危漏洞方面展现出卓越能力。结果表明，LLM在多语言漏洞检测方面具有巨大潜力，并相较于PLM有显著改进，为解决实际软件安全问题提供了新途径。

> **摘要翻译:** 各种基于深度学习的方法，利用预训练语言模型（PLM），已被提出用于自动化漏洞检测。随着大型语言模型（LLM）的最新进展，一些研究已开始探索它们在漏洞检测任务中的应用。然而，现有研究主要集中于特定编程语言（例如C/C++）和函数级检测，PLM和LLM在多语言和多粒度场景下的优缺点在很大程度上尚未被探索。为了弥补这一空白，我们进行了一项全面的细粒度实证研究，评估了最先进的PLM和LLM在多语言漏洞检测中的有效性。我们使用来自七种编程语言的30,000多个真实世界漏洞修复补丁，系统地评估了模型在函数级和行级的性能。我们的主要发现表明，经过指令微调和少样本提示增强的GPT-4o显著优于所有其他评估模型，包括CodeT5P。此外，基于LLM的方法在检测独特的多语言漏洞方面表现出卓越的能力，尤其擅长识别最危险和高严重性漏洞。这些结果强调了采用LLM进行多语言、函数级和行级漏洞检测的巨大潜力，揭示了它们与PLM方法相比的互补优势和实质性改进。这项首次对PLM和LLM进行多语言漏洞检测的实证评估，突出了LLM在解决真实世界软件安全挑战中的价值。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [158] [IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents](https://arxiv.org/abs/2506.07524)
> *IntenTest：面向API调用型LLM智能体的意图完整性压力测试*

*Shiwei Feng, Xiangzhe Xu, Xuan Chen, Kaiyuan Zhang, Syed Yusuf Ahmed, Zian Su, Mingwei Zheng, Xiangyu Zhang* | **Main category: cs.SE**

**Keywords:** LLM智能体, 意图完整性, 压力测试, API调用, 自然语言处理

**Comment:** 

> **TL;DR:** IntenTest是一个API中心化的压力测试框架，用于系统性地发现LLM智能体中意图完整性违规问题。它通过生成基于工具包文档的真实任务并应用有针对性的变异来暴露细微的智能体错误，同时保留用户意图，并在实验中显著优于现有基线。

**AI_Comments:** 该论文提出了一种新颖且实用的方法来解决LLM智能体在API调用中意图完整性问题，这是当前LLM应用落地中的一个关键挑战。其创新点在于结合了API文档、语义分区、任务变异和策略记忆，使得测试过程更加系统化、高效和真实。这项工作对于提高LLM智能体的可靠性和安全性具有重要意义，尤其是在自动化现实世界任务方面。

<details>
  <summary>Details</summary>

**Motivation:** LLM智能体在自动化现实任务中通过调用API变得越来越普及，但它们经常遭受用户意图误解的困扰，导致智能体行为偏离用户预期目标，尤其是在外部工具包不断演进的情况下。传统的软件测试方法假设结构化输入，因此无法处理自然语言的模糊性。

**Method:** IntenTest是一个API中心化的压力测试框架。它生成基于工具包文档的真实任务，并应用有针对性的变异来暴露智能体错误，同时保留用户意图。它提出语义分区，将自然语言任务组织成基于工具包API参数及其等价类的有意义类别。在每个分区内，种子任务被变异并通过轻量级预测器进行排名，以估计触发智能体错误的 likelihood。为了提高效率，IntenTest维护一个数据类型感知的策略记忆，从过去的案例中检索和调整有效的变异模式。

**Result:** 在对80个工具包API进行的实验表明，IntenTest有效地发现了意图完整性违规，在错误暴露率和查询效率方面均显著优于基线。此外，IntenTest能够很好地推广到使用较小LLM进行测试生成的更强目标模型，并适应跨领域不断演进的API。

**Conclusion:** IntenTest通过其新颖的API中心化压力测试框架，有效地解决了LLM智能体中意图完整性违规的问题，显著提高了测试效率和错误发现率，并展现出良好的泛化和适应能力。

> **ai_Abstract:** IntenTest是一个创新的API中心化压力测试框架，旨在解决LLM智能体在执行API调用时出现的意图误解问题。它通过基于工具包文档生成真实任务并应用有针对性的变异来系统地揭示意图完整性违规。该框架引入了语义分区和数据类型感知的策略记忆，以提高测试效率和错误发现能力。实验证明，IntenTest在错误暴露率和查询效率方面显著优于现有基线，并能有效推广到更强的LLM模型和适应不断演进的API。

> **摘要翻译:** LLM智能体正越来越多地被部署，通过自然语言指令调用API来自动化现实世界的任务。尽管功能强大，但它们经常遭受用户意图误解的困扰，导致智能体的行为偏离用户预期目标，尤其是在外部工具包不断演进的情况下。传统的软件测试假设输入是结构化的，因此在处理自然语言的模糊性方面存在不足。我们引入了IntenTest，一个以API为中心的压力测试框架，它系统地揭示LLM智能体中的意图完整性违规。与之前专注于固定基准或对抗性输入的工作不同，IntenTest基于工具包的文档生成真实任务，并应用有针对性的变异来暴露细微的智能体错误，同时保留用户意图。为了指导测试，我们提出了语义分区，它根据工具包API参数及其等价类将自然语言任务组织成有意义的类别。在每个分区内，种子任务通过一个轻量级预测器进行变异和排名，该预测器估计触发智能体错误的 likelihood。为了提高效率，IntenTest维护一个数据类型感知的策略记忆，从过去的案例中检索和调整有效的变异模式。对80个工具包API的实验表明，IntenTest有效地发现了意图完整性违规，在错误暴露率和查询效率方面均显著优于基线。此外，IntenTest能够很好地推广到使用较小LLM进行测试生成的更强目标模型，并适应跨领域不断演进的API。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [169] [Evaluating LLMs Effectiveness in Detecting and Correcting Test Smells: An Empirical Study](https://arxiv.org/abs/2506.07594)
> *评估大型语言模型在检测和纠正测试异味方面的有效性：一项实证研究*

*E. G. Santana Jr, Jander Pereira Santos Junior, Erlon P. Almeida, Iftekhar Ahmed, Paulo Anselmo da Mota Silveira Neto, Eduardo Santana de Almeida* | **Main category: cs.SE**

**Keywords:** 测试异味, 大型语言模型, 代码重构, 软件质量, 实证研究

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLMs）在检测和重构测试异味方面的能力，发现Gemini-1.5 Pro表现最佳，但仍存在挑战。

**AI_Comments:** 这项研究创新性地将大型语言模型应用于测试异味的自动化重构，超越了现有工具的局限性。其重要性在于为提高测试代码质量和开发效率提供了新的途径。Gemini-1.5 Pro在检测准确性和提升测试覆盖率方面的优异表现是亮点，但研究也坦诚地指出了模型可能引入新异味以及跨语言/异味类型挑战的局限性，这为未来研究指明了方向。

<details>
  <summary>Details</summary>

**Motivation:** 测试异味会降低代码的可维护性和可靠性，而现有工具主要侧重于检测而非自动化重构。尽管大型语言模型（LLMs）在代码理解和转换方面显示出潜力，但它们在识别和重构测试异味方面的能力尚未得到充分探索。

**Method:** 研究评估了GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro，在Python和Java测试套件上进行实验。首先使用PyNose和TsDetect进行初始异味检测，然后由LLM驱动进行重构。

**Result:** Gemini-1.5 Pro在检测准确性方面表现最佳（Python为74.35%，Java为80.32%），而LLaMA 3 70B最低。所有模型都能重构异味，但有效性各异，有时会引入新的异味。与GPT-4和LLaMA不同，Gemini还能提高测试覆盖率，而其他模型通常会降低。

**Conclusion:** 研究结果突出了大型语言模型在自动化测试异味重构方面的潜力，其中Gemini-1.5 Pro表现最强，但跨语言和异味类型仍存在挑战。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs），包括GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro，在检测和纠正Python和Java测试代码中测试异味方面的有效性。研究发现，Gemini-1.5 Pro在检测准确性上表现最佳，并且能够提高测试覆盖率。尽管所有模型都能进行重构，但其有效性各异，且有时会引入新的异味。结果表明LLMs在自动化测试异味重构方面具有潜力，Gemini是其中的佼佼者，但仍面临跨语言和异味类型的挑战。

> **摘要翻译:** 测试异味表明测试代码中存在不良开发实践，降低了可维护性和可靠性。尽管开发人员常常难以预防或重构这些问题，但现有工具主要侧重于检测而非自动化重构。大型语言模型（LLMs）在代码理解和转换方面显示出强大潜力，但它们识别和重构测试异味的能力仍未得到充分探索。我们评估了GPT-4-Turbo、LLaMA 3 70B和Gemini-1.5 Pro在Python和Java测试套件上的表现，使用PyNose和TsDetect进行初始异味检测，然后进行LLM驱动的重构。Gemini取得了最高的检测准确率（Python为74.35%，Java为80.32%），而LLaMA最低。所有模型都能重构异味，但有效性各异，有时会引入新的异味。与GPT-4和LLaMA不同，Gemini还能提高测试覆盖率，而其他模型通常会降低。这些结果突出了LLMs在自动化测试异味重构方面的潜力，其中Gemini是表现最强的模型，尽管跨语言和异味类型仍存在挑战。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [178] [Leveraging Network Methods for Hub-like Microservice Detection](https://arxiv.org/abs/2506.07683)
> *利用网络方法检测类中心微服务*

*Alexander Bakhtin, Matteo Esposito, Valentina Lenarduzzi, Davide Taibi* | **Main category: cs.SE**

**Keywords:** 微服务架构, 类中心反模式, 网络分析, 中心检测, Erdos-Renyi编码

**Comment:** 

> **TL;DR:** 本文研究了一种鲁棒的类中心微服务反模式检测方法，发现Kirkley的ER编码方法在检测数量和精度方面最为准确，并为现有工具的改进提供了依据。

**AI_Comments:** 这项研究通过系统地比较多种网络分析方法来检测微服务架构中的“类中心”反模式，具有重要的实践意义。它不仅填补了该反模式检测方法上的空白，还对现有广泛使用的工具如Arcan的检测能力进行了评估和改进建议，有助于提升微服务系统设计的质量和可维护性。其创新点在于将网络科学的度量方法应用于软件架构反模式检测。

<details>
  <summary>Details</summary>

**Motivation:** 微服务架构中的“类中心”反模式缺乏明确的定义和有效的检测方法，导致难以识别和解决其负面影响。本研究旨在找到一种高精度、能够输出合理数量类中心候选的鲁棒检测方法。

**Method:** 研究利用了25个微服务网络数据集，并比较了多种网络中心检测技术，包括无标度特性、中心性度量、聚类系数、最小描述长度原理以及Arcan工具所采用的方法。

**Result:** 研究发现所分析的架构网络并非无标度网络；大多数考虑的中心检测方法在检测到的中心上不一致；Kirkley利用Erdos-Renyi编码的方法在检测到的中心数量和检测精度方面是最准确的。

**Conclusion:** Kirkley利用Erdos-Renyi编码的方法是检测类中心微服务反模式最准确的方法。研究建议可以更新Arcan工具以使用归一化度中心性，或直接采用基于ER编码的方法。

> **ai_Abstract:** 本文旨在为微服务架构中的“类中心”反模式寻找一种鲁棒的检测方法。通过分析25个微服务网络并比较多种网络中心检测技术，研究发现所分析的网络并非无标度网络，且大多数检测方法结果不一致。其中，Kirkley基于Erdos-Renyi编码的方法被证明在检测数量和精度上最为准确。研究结果为更新现有工具如Arcan提供了依据，并指出了未来研究方向。

> **摘要翻译:** 背景: 微服务架构是一种流行的架构范式，通过将应用程序分解为小型、独立部署的服务来促进灵活性。人们提出了架构反模式目录，以突出有缺陷的微服务设计的负面影响。特别是，“类中心”反模式缺乏明确的定义和检测方法。
目的: 在这项工作中，我们旨在为“类中心”微服务反模式找到一种鲁棒的检测方法，该方法能够以高精度输出合理数量的类中心候选。
方法: 我们利用了25个微服务网络数据集和几种网络中心检测技术来识别“类中心”反模式，即无标度特性、中心性度量和聚类系数、最小描述长度原理以及Arcan工具背后的方法。
结果与结论: 我们的发现表明，所研究的架构网络并非无标度网络，大多数考虑的中心检测方法在检测到的中心上不一致，并且Kirkley利用Erdos-Renyi编码的方法在检测到的中心数量和检测精度方面是最准确的。进一步研究这些方法在基于微服务和其他系统中检测类中心组件的适用性开辟了新的研究方向。此外，我们的结果评估了广泛使用的Arcan工具所采用的方法，并强调了更新该工具以使用网络中组件的归一化度中心性，或采用基于ER编码的方法的潜力。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [185] [Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation](https://arxiv.org/abs/2506.07690)
> *集中度变化倾向：微服务架构退化的早期指标*

*Alexander Bakhtin, Matteo Esposito, Valentina Lenarduzzi, Davide Taibi* | **Main category: cs.SE**

**Keywords:** 微服务架构, 架构退化, 集中度指标, 时间网络, 软件指标

**Comment:** 

> **TL;DR:** 本研究提出并评估了一种新的指标“集中度变化倾向”，作为微服务架构退化的早期预警信号。

**AI_Comments:** 本文的创新之处在于提出了“集中度变化倾向”这一新颖的时间集中度指标，并将其作为微服务架构退化的早期预警。这对于维护微服务系统的健康和稳定性具有重要意义，提供了一种前瞻性的架构质量监控方法。

<details>
  <summary>Details</summary>

**Motivation:** 微服务架构的广泛采用需要识别各种模式和反模式以防止架构退化。现有研究已探索软件指标与微服务架构网络中集中度之间的关系，本研究旨在探究时间集中度指标是否能通过关联或影响软件指标来提供架构退化的早期检测。

**Method:** 研究重建了一个包含42个服务的开源微服务项目7个版本的架构。针对每个版本中的每个服务，计算了软件和集中度指标。从集中度指标中推导出一个新指标——集中度变化倾向，然后探索了这些指标之间的关联。

**Result:** 研究发现7个规模指标和5个复杂性指标与集中度存在一致的相关性。集中度变化倾向虽然未影响软件指标，但它提供了一个新的视角，并被确认为微服务架构退化的早期指标。

**Conclusion:** 集中度变化倾向被确认为微服务架构退化的一个早期指标，为理解和预防架构退化提供了新的视角。

> **ai_Abstract:** 本研究旨在通过引入“集中度变化倾向”这一新指标，实现微服务架构退化的早期检测。通过分析一个包含42个服务的开源微服务项目7个版本的架构数据，计算了软件和集中度指标。研究发现，7个规模指标和5个复杂性指标与集中度存在一致相关性，并且“集中度变化倾向”作为一个新的时间集中度指标，被证实是微服务架构退化的一个早期预警信号。

> **摘要翻译:** 在过去的十年中，微服务架构的广泛采用要求识别各种模式和反模式，以防止微服务架构退化。通常，系统被建模为连接服务的网络。最近，时间网络的研究已成为描述和分析演化网络的一种方式。先前的研究已经探索了诸如规模、复杂性和质量等软件指标如何与架构网络中的微服务集中度相关联。本研究调查了时间集中度指标是否能通过关联或影响软件指标，为架构退化的早期检测提供见解。我们重建了一个包含42个服务的开源微服务项目7个版本的架构。对于每个版本中的每个服务，我们计算了软件和集中度指标。从后者之一中，我们推导出了一个新指标，即集中度变化倾向。然后，我们探索了这些指标之间的相关性。我们识别出7个规模指标和5个复杂性指标与集中度具有一致的相关性，而集中度变化倾向并未影响软件指标，从而提供了另一个视角和微服务架构退化的早期指标。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [195] [Towards a Small Language Model Lifecycle Framework](https://arxiv.org/abs/2506.07695)
> *构建小型语言模型生命周期框架*

*Parsa Miraghaei, Sergio Moreschini, Antti Kolehmainen, David Hästbacka* | **Main category: cs.SE**

**Keywords:** 小型语言模型, 生命周期框架, 文献调查, 模块化模型, 理论与实践

**Comment:** 

> **TL;DR:** 该研究提出了一个模块化的SLM生命周期框架，旨在统一现有研究并指导SLM的开发和维护。

**AI_Comments:** 这项工作通过提出一个统一的SLM生命周期框架，解决了当前SLM研究分散的痛点。其创新之处在于将生命周期分解为模块化组件，并强调了组件间的互联性，这对于指导SLM的系统化开发和维护具有重要意义。该框架有望提高SLM开发的效率和质量，并为未来的工具链建设奠定基础。

<details>
  <summary>Details</summary>

**Motivation:** 现有的小型语言模型（SLMs）研究分散，缺乏统一的生命周期视角，而市场对高效可部署语言模型的需求日益增长。

**Method:** 通过对36篇文献进行全面调查，分析并分类了与生命周期相关的技术。

**Result:** 提出了一个模块化的生命周期模型，该模型由主要、可选和跨领域组件构成，并捕捉了各阶段之间的关键互联，支持方法重用、协同适应和生命周期感知。

**Conclusion:** 该框架为SLM的开发和维护提供了连贯的基础，弥合了理论与实践之间的鸿沟，并指导了未来的研究和工具开发。

> **ai_Abstract:** 本研究针对小型语言模型（SLMs）研究碎片化的问题，通过对36篇文献的综合调查，提出了一个模块化的SLM生命周期框架。该框架旨在统一SLM的开发和维护过程，促进方法重用和协同适应，从而弥合理论与实践之间的差距，并为未来的研究和工具开发提供指导。

> **摘要翻译:** 背景：对高效、可部署语言模型日益增长的需求，使得人们对小型语言模型（SLMs）的兴趣日益增加。然而，现有研究仍然碎片化，缺乏统一的生命周期视角。
目标：本研究旨在通过综合学术文献和实践来源的见解，为SLMs定义一个全面的生命周期框架。
方法：我们对36项工作进行了全面调查，分析并分类了与生命周期相关的技术。
结果：我们提出了一个模块化的生命周期模型，该模型由主要、可选和跨领域组件构成。该模型捕捉了各阶段之间的关键互联，支持方法重用、协同适应和生命周期感知。
结论：我们的框架为开发和维护SLMs提供了连贯的基础，弥合了理论与实践之间的鸿沟，并指导了未来的研究和工具开发。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

### [204] [Adversarial Attack Classification and Robustness Testing for Large Language Models for Code](https://arxiv.org/abs/2506.07942)
> *面向代码大型语言模型的对抗性攻击分类与鲁棒性测试*

*Yang Liu, Armstrong Foundjem, Foutse Khomh, Heng Li* | **Main category: cs.SE**

**Keywords:** 对抗性攻击, LLM4Code, 鲁棒性测试, 自然语言, 代码生成

**Comment:** 

> **TL;DR:** 本研究探讨了自然语言输入中的对抗性扰动如何影响代码大型语言模型（LLM4Code），并提出了一个对抗性攻击分类法和鲁棒性测试框架，发现词级扰动对模型构成严重挑战。

**AI_Comments:** 本研究的创新点在于其首次系统性地探讨了自然语言输入中对抗性扰动对LLM4Code的影响，并提出了一个新颖的对抗性攻击分类法。其贡献在于提供了一个结构化的鲁棒性测试框架，并揭示了词级（语义）扰动对LLM4Code的严重威胁，这对于开发更安全、更可靠的代码生成系统具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）已成为软件开发中的重要工具，但其在工作流程中面临对抗性输入引起的漏洞问题，可能导致生成不正确或不安全的代码。现有研究常忽视自然语言在指导代码任务中的作用，因此本研究旨在填补这一空白，确保LLM4Code的鲁棒性。

**Method:** 本研究调查了提示、注释和描述等自然语言输入中的对抗性扰动如何影响LLM4Code。研究检查了字符、单词和句子级别的扰动效果，以识别最具影响力的漏洞。研究分析了多个项目（如ReCode, OpenAttack）和数据集（如HumanEval, MBPP），建立了一个对抗性攻击分类法，该分类法根据输入类型（代码、提示、注释）和粒度（字符、单词、句子级别）进行分类。研究采用混合方法，结合定量性能指标和定性漏洞分析。

**Result:** LLM4Code模型在不同扰动类型下表现出不同的鲁棒性。句子级攻击效果最差，表明模型对更广泛的上下文变化具有弹性。相反，词级扰动带来了严峻挑战，暴露了语义漏洞。字符级影响各不相同，显示模型对细微语法偏差的敏感性。

**Conclusion:** 本研究为LLM4Code鲁棒性测试提供了一个结构化框架，并强调了自然语言在对抗性评估中的关键作用。提高模型对语义级干扰的弹性对于安全可靠的代码生成系统至关重要。

> **ai_Abstract:** 本研究旨在评估面向代码的大型语言模型（LLM4Code）在自然语言对抗性扰动下的鲁棒性。研究分析了字符、单词和句子级别的扰动对LLM4Code的影响，并基于输入类型和扰动粒度构建了一个对抗性攻击分类法。通过对多个项目和数据集的分析，研究发现词级扰动对LLM4Code构成严重挑战，暴露了语义漏洞，而句子级攻击效果最弱。本研究提出了一个结构化框架，用于测试LLM4Code的鲁棒性，并强调了自然语言在对抗性评估中的关键作用，指出提高模型对语义级干扰的弹性对于确保代码生成系统的安全和可靠至关重要。

> **摘要翻译:** 大型语言模型（LLMs）已成为代码生成、代码补全和代码分析等软件开发任务中的重要工具。随着它们在工作流程中深度集成，确保其抵御漏洞（特别是那些由多样化或对抗性输入触发的漏洞）的鲁棒性变得越来越重要。当模型遇到受扰动的任务描述、代码或注释时，此类漏洞可能导致不正确或不安全的代码生成。先前的研究常常忽视自然语言在指导代码任务中的作用。本研究调查了提示、注释和描述等自然语言输入中的对抗性扰动如何影响面向代码的大型语言模型（LLM4Code）。它检查了字符、单词和句子级别的扰动效果，以识别最具影响力的漏洞。我们分析了多个项目（例如ReCode、OpenAttack）和数据集（例如HumanEval、MBPP），建立了一个对抗性攻击分类法。第一个维度根据输入类型（代码、提示或注释）进行分类，而第二个维度则侧重于粒度：字符、单词或句子级别的更改。我们采用混合方法，结合定量性能指标和定性漏洞分析。LLM4Code模型在不同扰动类型下表现出不同的鲁棒性。句子级攻击效果最差，表明模型对更广泛的上下文变化具有弹性。相反，词级扰动带来了严峻挑战，暴露了语义漏洞。字符级影响各不相同，显示模型对细微语法偏差的敏感性。我们的研究为测试LLM4Code鲁棒性提供了一个结构化框架，并强调了自然语言在对抗性评估中的关键作用。提高模型对语义级干扰的弹性对于安全可靠的代码生成系统至关重要。

</details>

[⬆️ 返回分类顶部](#csse) | [⬆️ 返回总目录](#toc)

---

<a id='cssi'></a>
## cs.SI 

### [13] [A Benchmarking Framework for Network Classification Methods](https://arxiv.org/abs/2506.06513)
> *网络分类方法的基准测试框架*

*Joao V. Merenda, Gonzalo Travieso, Odemir M. Bruno* | **Main category: cs.SI**

**Keywords:** 网络分类, 基准测试, 特征提取, 合成网络, 结构噪声

**Comment:** 10 pages, 3 figures

> **TL;DR:** 本研究提出了一个用于测试网络分类方法有效性的合成网络基准数据集，并引入了结构噪声。实验结果表明，DTWB在有噪声的情况下表现最佳，强调了鲁棒特征提取技术的重要性。

**AI_Comments:** 这项研究的创新之处在于构建了一个带有结构噪声的合成网络基准数据集，这对于全面评估网络分类方法的鲁棒性至关重要。DTWB在噪声条件下的优异表现揭示了其在实际应用中的巨大潜力。研究结果也明确指出了传统拓扑测量在噪声环境下的局限性，并强调了更先进特征提取方法的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 网络分类在复杂系统研究中至关重要，影响生物学、社会学和计算机科学等领域。为了测试不同网络分类方法的有效性和弹性，需要一个基准框架。

**Method:** 本研究提出了一个由合成网络组成的创新基准数据集，该数据集被分类为各种类别和子类别。为了测试这些方法，引入了各种类型和级别的结构噪声。评估了五种特征提取技术：传统结构测量、Life-Like Network Automata (LLNA)、Graph2Vec、Deterministic Tourist Walk (DTW)及其改进版本Deterministic Tourist Walk with Bifurcation (DTWB)。

**Result:** 实验结果表明，DTWB在分类类别和子类别方面均超越了其他方法，即使在面临显著噪声时也是如此。LLNA和DTW也表现良好，而Graph2Vec在准确性方面处于中等水平。拓扑测量尽管简单且常用，但始终表现出最弱的分类性能。

**Conclusion:** 这些发现强调了鲁棒特征提取技术对于有效网络分类的必要性，尤其是在有噪声的条件下。

> **ai_Abstract:** 本研究提出了一个创新的合成网络基准数据集，用于评估不同网络分类方法的有效性和鲁棒性，并通过引入结构噪声来模拟真实条件。研究比较了五种特征提取技术：传统结构测量、LLNA、Graph2Vec、DTW和DTWB。结果显示，DTWB在噪声环境下表现出卓越的分类性能，优于其他所有方法。LLNA和DTW也表现良好，而拓扑测量表现最差。研究强调了在复杂和有噪声的网络分类任务中，鲁棒特征提取技术的重要性。

> **摘要翻译:** 网络分类在复杂系统研究中扮演着至关重要的角色，影响着生物学、社会学和计算机科学等领域。在这项研究中，我们提出了一个由合成网络组成的创新基准数据集，这些网络被分为不同的类别和子类别。该数据集专门用于测试不同网络分类方法的有效性和弹性。为了测试这些方法，我们还引入了各种类型和级别的结构噪声。我们评估了五种特征提取技术：传统结构测量、生命般网络自动机（LLNA）、Graph2Vec、确定性旅行者漫步（DTW）及其改进版本——带分叉的确定性旅行者漫步（DTWB）。我们的实验结果表明，即使在面临显著噪声时，DTWB在分类类别和子类别方面均超越了其他方法。LLNA和DTW也表现良好，而Graph2Vec在准确性方面处于中等水平。有趣的是，拓扑测量尽管简单且常用，但始终表现出最弱的分类性能。这些发现强调了鲁棒特征提取技术对于有效网络分类的必要性，尤其是在有噪声的条件下。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [27] [Neighborhood Overlap-Aware High-Order Graph Neural Network for Dynamic Graph Learning](https://arxiv.org/abs/2506.06728)
> *邻域重叠感知高阶图神经网络用于动态图学习*

*Ling Wang* | **Main category: cs.SI**

**Keywords:** 动态图学习, 图神经网络, 邻域重叠, 高阶图, 链接预测

**Comment:** 

> **TL;DR:** 提出NO-HGNN，通过计算邻域重叠相关性并将其嵌入高阶GNN的消息传递过程，有效提升动态图学习中的链接预测性能。

**AI_Comments:** 这篇论文的创新点在于将邻域重叠这一高阶结构信息引入动态图神经网络的消息传递过程，解决了现有DGNNs在捕获复杂节点交互方面的不足。通过量化邻域重叠并将其作为相关性分数，NO-HGNN能够更精细地建模动态图中的结构依赖性，这对于链接预测等任务至关重要。该方法为动态图学习提供了一个新的视角和有效的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 动态图学习（DGL）在建模演化图拓扑的时间动态和结构依赖性方面面临挑战。现有DGNNs忽视了更复杂的结构模式，特别是邻域重叠，这在表征节点交互中至关重要。

**Method:** 引入邻域重叠感知高阶图神经网络（NO-HGNN），其创新点在于：(a) 基于邻域重叠程度计算相关性分数，以更好地捕获复杂节点交互；(b) 将此相关性直接嵌入到高阶图神经网络在DGL中的消息传递过程中。

**Result:** 在两个真实世界的动态图上的实验表明，NO-HGNN在链接预测精度上取得了显著提升，优于几种最先进的方法。

**Conclusion:** NO-HGNN通过有效建模邻域重叠来捕捉复杂节点交互，显著提高了动态图链接预测的性能，证明了其在动态图学习中的有效性。

> **ai_Abstract:** 本文针对动态图学习中现有方法忽略邻域重叠这一复杂结构模式的局限性，提出了一种名为邻域重叠感知高阶图神经网络（NO-HGNN）的新模型。NO-HGNN通过计算基于邻域重叠的相关性分数，并将其融入高阶图神经网络的消息传递机制中，旨在更有效地捕获复杂节点交互和图拓扑的动态性。实验结果表明，NO-HGNN在链接预测任务上显著优于现有SOTA方法。

> **摘要翻译:** 动态图学习（DGL）旨在学习信息丰富且随时间演变的节点嵌入，以支持链接预测等下游任务。DGL的一个根本挑战在于有效建模演化图拓扑的时间动态和结构依赖性。动态图神经网络（DGNNs）的最新进展通过利用消息传递机制捕获成对节点交互，取得了显著成功。然而，这些方法往往忽略了更复杂的结构模式，特别是邻域重叠，这在表征节点交互中可以发挥关键作用。为了克服这一限制，我们引入了邻域重叠感知高阶图神经网络（NO-HGNN），它建立在两个关键创新之上：(a) 基于邻域重叠的程度计算相关性分数，以更好地捕获复杂节点交互；(b) 将此相关性直接嵌入到DGL中高阶图神经网络的消息传递过程中。在两个真实世界的动态图上的实验表明，NO-HGNN在链接预测精度上取得了显著提升，优于几种最先进的方法。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [41] [An $α$-triangle eigenvector centrality of graphs](https://arxiv.org/abs/2506.07026)
> *图的$\\alpha$-三角形特征向量中心性*

*Zhang Qingying, Sun Lizhu, Bu Changjiang* | **Main category: cs.SI**

**Keywords:** 中心性度量, $\\alpha$-三角形特征向量中心性, 复杂网络, 张量, 网络连通性

**Comment:** 18pages,13figures

> **TL;DR:** 本文提出了一种新的网络中心性度量$\\alpha$TEC，它结合了边和三角形结构，并通过参数$\\alpha$动态调整其影响，能有效识别节点结构位置并影响网络连通性。

**AI_Comments:** 该论文的创新点在于提出了一种结合边和三角形结构的新型中心性度量，并引入可调参数$\\alpha$以动态平衡这两种结构的影响，这使得该度量在不同网络和应用场景中具有更强的适应性。其基于张量特征向量的方法论也为中心性研究提供了新的视角。

<details>
  <summary>Details</summary>

**Motivation:** 复杂网络分析中，中心性度量是识别网络中重要顶点的基本研究领域。现有方法多样，但可能没有充分结合边和三角形结构并动态调整其影响。

**Method:** 提出了$\\alpha$-三角形特征向量中心性（$\\alpha$TEC），这是一种基于边和三角形结构的全局中心性度量。它通过参数$\\alpha \\in (0,1]$动态调整边和三角形结构的影响。顶点中心性分数被定义为非负张量谱半径对应的特征向量。通过Perron-Frobenius定理保证了连通图中所有顶点的唯一正中心性分数。

**Result:** 在合成网络和真实世界网络上的数值实验表明，$\\alpha$TEC能有效识别图中顶点的结构位置。随着$\\alpha$的增加（减少），中心性排名反映出边结构贡献更强（弱），三角形结构贡献更弱（强）。实验证明，$\\alpha$TEC排名较高的顶点对网络连通性有更大的影响。

**Conclusion:** $\\alpha$TEC是一种有效的中心性度量，它结合了边和三角形结构，能够识别顶点在网络中的结构位置，并且与网络连通性有显著关联。其参数$\\alpha$允许动态调整不同结构的影响。

> **ai_Abstract:** 本文提出了一种名为$\\alpha$TEC的新型全局中心性度量，用于复杂网络分析。$\\alpha$TEC基于边和三角形结构，并通过参数$\\alpha$动态平衡两者影响。通过非负张量的特征向量定义中心性分数，并利用Perron-Frobenius定理确保其唯一性。实验证明，$\\alpha$TEC能有效识别顶点结构位置，且$\\alpha$的调整能反映不同结构贡献。此外，高$\\alpha$TEC排名的顶点对网络连通性影响更大。

> **摘要翻译:** 复杂网络分析中，中心性代表一个基本研究领域，其中中心性度量识别网络中的重要顶点。多年来，研究人员从不同角度发展了多种中心性度量。本文提出了一种$\\alpha$-三角形特征向量中心性（$\\alpha$TEC），这是一种基于边和三角形结构的全局中心性度量。它可以通过参数$\\alpha$（$\\alpha \\in (0,1]$）动态调整边和三角形的影响。顶点的中心性分数被定义为非负张量的谱半径对应的特征向量。根据Perron-Frobenius定理，$\\alpha$TEC保证了连通图中所有顶点的唯一正中心性分数。对合成网络和真实世界网络的数值实验表明，$\\alpha$TEC能有效识别图中顶点的结构位置。随着$\\alpha$的增加（减少），中心性排名反映出边结构贡献更强（弱），三角形结构贡献更弱（强）。此外，我们实验证明，$\\alpha$TEC排名较高的顶点对网络连通性有更大的影响。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

### [56] [Fast Geometric Embedding for Node Influence Maximization](https://arxiv.org/abs/2506.07435)
> *用于节点影响力最大化的快速几何嵌入*

*Alexander Kolpakov, Igor Rivin* | **Main category: cs.SI**

**Keywords:** 几何嵌入, 节点影响力最大化, 中心性度量, 力布局, 可扩展性

**Comment:** 8 pages, 4 figures, 18 tables; Github repository available
  (https://github.com/sashakolpakov/graphem/); Package available on PyPi
  (https://pypi.org/project/graphem-jax/)

> **TL;DR:** 本文提出了一种高效的力布局算法，将图嵌入低维空间，以径向距离作为中心性度量的近似值，从而实现快速且可扩展的节点影响力最大化，替代了传统的计算密集型方法。

**AI_Comments:** 本文的创新之处在于利用几何嵌入的径向距离来近似图的中心性度量，并将其应用于节点影响力最大化问题。这种方法有效解决了传统中心性计算在大型图上的高计算成本问题，提供了一个快速且可扩展的解决方案，对于实际网络分析具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在大型图上计算经典的中心性度量（如介数和紧密度）计算成本高昂。

**Method:** 引入了一种高效的力布局算法，将图嵌入低维空间，其中径向距离作为各种中心性度量的代理。

**Result:** 该方法在多种图族上进行了评估，并与度中心性、PageRank和基于路径的中心性表现出强相关性。所提出的嵌入允许在网络中找到高影响力节点，并为标准贪婪算法提供了一种快速且可扩展的替代方案。

**Conclusion:** 该几何嵌入方法为节点影响力最大化提供了一种快速且可扩展的解决方案，有效替代了计算成本高的传统方法。

> **ai_Abstract:** 本文提出了一种快速几何嵌入方法，通过高效的力布局算法将大型图嵌入低维空间。该方法的径向距离可作为多种中心性度量的近似值，并被证明与度中心性、PageRank和基于路径的中心性高度相关。作为一项应用，该嵌入技术能够快速有效地识别网络中的高影响力节点，为传统的贪婪算法提供了一种可扩展且计算效率更高的替代方案。

> **摘要翻译:** 计算经典中心性度量（如介数和紧密度）在大型图上计算成本高昂。在这项工作中，我们引入了一种高效的力布局算法，将图嵌入低维空间，其中到原点的径向距离可作为各种中心性度量的代理。我们在多种图族上评估了我们的方法，并证明了其与度中心性、PageRank和基于路径的中心性之间存在强相关性。作为一项应用，所提出的嵌入允许在网络中找到高影响力节点，并为标准贪婪算法提供了一种快速且可扩展的替代方案。

</details>

[⬆️ 返回分类顶部](#cssi) | [⬆️ 返回总目录](#toc)

---

<a id='csni'></a>
## cs.NI 

### [20] [Steps towards an Ecology for the Internet](https://arxiv.org/abs/2506.06469)
> *迈向互联网生态的步骤*

*Anil Madhavapeddy, Sam Reynolds, Alec P. Christie, David A. Coomes, Michael W. Dales, Patrick Ferris, Ryan Gibb, Hamed Haddadi, Sadiq Jaffer, Josh Millar, Cyrus Omar, William J. Sutherland, Jon Crowcroft* | **Main category: cs.NI**

**Keywords:** 互联网生态, 数字免疫系统, 去中心化, 弹性网络, 生物系统

**Comment:** To appear in the sixth decennial Aarhus conference: Computing X
  Crisis, Aug 2025

> **TL;DR:** 本文探讨了互联网缺乏内置“免疫系统”且日益中心化的问题，提出借鉴生物系统，通过去中心化和引入适应机制来构建更具弹性的互联网，以应对未来威胁。

**AI_Comments:** 本文提出了一个引人深思的观点，将互联网的未来发展与生物生态系统进行类比，强调了去中心化和引入“免疫系统”的重要性。这种跨学科的视角为解决当前互联网面临的中心化、安全性和弹性问题提供了新的思路，具有潜在的创新性和重要性。其对“再中心化”的倡导，对于构建更公平、更安全的网络环境具有积极意义。

<details>
  <summary>Details</summary>

**Motivation:** 互联网已成为关键的全球系统，但缺乏内置的“免疫系统”，面临着从虚假生成数据洪水到AI驱动恶意软件等威胁。日益增长的中心化导致网络互惠互利关系破裂，监视资本主义成为主导商业模式。为了应对未来万亿节点互联网的挑战，需要构建一个更具弹性的系统。

**Method:** 本文借鉴生物系统的经验，旨在将适应机制整合到互联网的结构中。提出如何将数字免疫系统融入互联网，包括软件栈如何变异以鼓励更多的架构多样性。强烈主张互联网“再中心化”以激励更多的互惠互利形式的通信。

**Result:** Not mentioned in abstract

**Conclusion:** 本文强烈主张互联网应“再中心化”，以激励更多的互惠互利形式的通信，并融入类似生物系统的适应机制和数字免疫系统，从而构建一个更具弹性的未来互联网。

> **ai_Abstract:** 本文指出当前互联网缺乏“免疫系统”且过度中心化，难以应对未来万亿节点可能面临的AI恶意软件和虚假数据等威胁。作者提出借鉴生物系统的进化和适应机制，构建一个更具弹性的互联网，包括引入数字免疫系统和鼓励软件栈多样性。核心主张是互联网应“再中心化”，以促进更健康的互惠通信模式。

> **摘要翻译:** 互联网已从一套简单的端到端连接协议发展成为一个关键的全球系统，但缺乏内置的“免疫系统”。在未来十年，互联网可能会增长到万亿个节点，需要保护其免受从虚假生成数据洪水到AI驱动恶意软件等各种威胁。不幸的是，日益增长的中心化导致了网络互惠互利关系的破裂，监视资本主义现在是主导的商业模式。我们从生物系统中汲取经验，以发展一个更具弹性的互联网，使其能够将适应机制整合到其结构中。我们还为互联网如何整合数字免疫系统贡献了想法，包括软件栈如何变异以鼓励更多的架构多样性。我们强烈主张互联网“再中心化”，以激励更多的互惠互利形式的通信。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [34] [A Comparative Analyses Of Network Formation In Low-power Lossy Networks: ContikiMAC vs Orchestra-enabled TSCH](https://arxiv.org/abs/2506.06688)
> *低功耗有损网络中网络形成的比较分析：ContikiMAC 对比 Orchestra-enabled TSCH*

*Heerok Banerjee* | **Main category: cs.NI**

**Keywords:** 低功耗有损网络, MAC协议, ContikiMAC, TSCH, 网络形成

**Comment:** 

> **TL;DR:** 本文比较了ContikiMAC和Orchestra-enabled TSCH在低功耗有损网络(LLN)中的网络形成性能，结果显示ContikiMAC在网络形成方面性能高出13倍。

**AI_Comments:** 该论文提供了关于LLN中MAC协议的明确量化比较，特别关注网络形成速度和能耗，这对于实际系统设计具有重要参考价值。

<details>
  <summary>Details</summary>

**Motivation:** 在低功耗有损网络(LLN)中，介质访问控制(MAC)层协议的设计和选择对于满足网络加入时间、网络寿命、能耗和端到端延迟等目标至关重要。

**Method:** 本文对Contiki-MAC和Orchestra-enabled TSCH协议进行了比较分析，以评估它们的网络加入与收敛时间以及能耗。

**Result:** 研究结果表明，Contiki-MAC在网络形成方面比Orchestra-enabled TSCH的性能高出13倍。

**Conclusion:** Contiki-MAC在低功耗有损网络(LLN)的网络形成速度上显著优于Orchestra-enabled TSCH。

> **ai_Abstract:** 本文对低功耗有损网络(LLN)中的Contiki-MAC和Orchestra-enabled TSCH协议的网络形成性能进行了比较分析。研究侧重于网络加入和收敛时间以及能耗。结果表明，Contiki-MAC在网络形成速度上比Orchestra-enabled TSCH快13倍，表现出显著优势。

> **摘要翻译:** 介质访问控制 (MAC) 层协议是决定任何网络中数据传输和接收的基础范式。特别是对于低功耗有损网络 (LLN)，适当的 MAC 层协议的设计和选择至关重要，以满足多个网络目标，例如加入时间、网络寿命、能耗、端到端延迟等。在本报告中，我们对 Contiki-MAC 和启用 Orchestra 的 TSCH 协议进行了比较分析，该分析提供了关于网络加入和收敛时间以及构建此类 LLN 所需能耗的见解。我们的结果表明，Contiki-MAC 在网络形成方面比启用 Orchestra 的 TSCH 性能高出 13 倍。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [48] [ARGOS: Anomaly Recognition and Guarding through O-RAN Sensing](https://arxiv.org/abs/2506.06916)
> *ARGOS: 通过O-RAN感知进行异常识别与防护*

*Stavros Dimou, Guevara Noubir* | **Main category: cs.NI**

**Keywords:** 流氓基站攻击, O-RAN, 入侵检测系统, 实时检测, 机器学习

**Comment:** 

> **TL;DR:** ARGOS是一个O-RAN兼容的入侵检测系统，用于实时检测流氓基站降级攻击，通过增强的KPM服务模型和无监督机器学习实现，并在实际测试中表现出色，VAE模型达到99.5%的准确率。

**AI_Comments:** ARGOS的创新之处在于它是首个在O-RAN背景下探索实时RBS降级攻击检测的系统，并利用了从COTS UE直接获取的跨层特征。其在实际测试环境中的高性能验证，特别是VAE模型的高准确率和低误报率，凸显了其在增强5G网络安全方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 流氓基站（RBS）攻击，特别是利用降级漏洞的攻击，仍然是一个持续存在的威胁，因为5G独立组网（SA）部署仍然有限，且用户设备（UE）制造商继续支持传统网络连接。

**Method:** 本文提出了ARGOS，一个部署在近实时RIC中的O-RAN兼容入侵检测系统（IDS），旨在实时检测RBS降级攻击。该系统增强了3GPP KPM服务模型，以实现更丰富、UE级别的遥测，并包含一个自定义的xApp，应用无监督机器学习模型进行异常检测。更新后的KPM服务模型利用从调制解调器层1（ML1）日志和直接从商用现货（COTS）UE收集的测量报告中提取的跨层特征。为了在实际条件下评估系统性能，使用Open5GS、srsRAN和FlexRIC实现了一个专用测试平台，并通过大量的真实世界测量数据集进行了验证。

**Result:** 在评估的模型中，变分自编码器（VAE）在检测性能和效率之间取得了最佳平衡，达到了99.5%的准确率，仅有0.6%的误报率，并且系统开销极小。

**Conclusion:** ARGOS系统能够有效实时检测O-RAN环境下的流氓基站降级攻击，其中VAE模型表现最佳。

> **ai_Abstract:** 本文提出了ARGOS，一个O-RAN兼容的入侵检测系统，部署在近实时RIC中，用于实时检测流氓基站降级攻击。该系统通过增强的3GPP KPM服务模型实现UE级遥测，并利用自定义xApp中的无监督机器学习模型进行异常检测，其特征提取自ML1日志和COTS UE的测量报告。在专用测试平台上验证显示，变分自编码器（VAE）模型表现最佳，实现了99.5%的准确率和极低的误报率。

> **摘要翻译:** 流氓基站（RBS）攻击，特别是那些利用降级漏洞的攻击，仍然是一个持续存在的威胁，因为5G独立组网（SA）部署仍然有限，且用户设备（UE）制造商继续支持传统网络连接。这项工作介绍了ARGOS，一个全面的O-RAN兼容入侵检测系统（IDS），部署在近实时RIC中，旨在实时检测RBS降级攻击，这是O-RAN背景下以前未探索的领域。该系统增强了3GPP KPM服务模型，以实现更丰富、UE级别的遥测，并具有一个自定义的xApp，应用无监督机器学习模型进行异常检测。独特的是，更新后的KPM服务模型在从调制解调器层1（ML1）日志和直接从商用现货（COTS）UE收集的测量报告中提取的跨层特征上运行。为了在实际条件下评估系统性能，使用Open5GS、srsRAN和FlexRIC实现了一个专用测试平台，并针对大量的真实世界测量数据集进行了验证。在评估的模型中，变分自编码器（VAE）在检测性能和效率之间取得了最佳平衡，达到了99.5%的准确率，仅有0.6%的误报率，并且系统开销极小。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [63] [Delay Optimization in Remote ID-Based UAV Communication via BLE and Wi-Fi Switching](https://arxiv.org/abs/2506.07715)
> *基于远程ID的无人机通信中BLE和Wi-Fi切换的延迟优化*

*Yian Zhu, Ziye Jia, Lei Zhang, Yao Wu, Qiuming Zhu, Qihui Wu* | **Main category: cs.NI**

**Keywords:** 远程ID, 无人机通信, 延迟优化, BLE/Wi-Fi切换, 深度Q网络

**Comment:** 

> **TL;DR:** 本文提出一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法，以最小化远程ID无人机通信中的延迟，在动态密度场景下显著降低了延迟。

**AI_Comments:** 这篇论文通过引入自适应BLE/Wi-Fi切换策略，并结合深度Q网络来应对动态无人机密度下的延迟问题，具有较强的创新性。其提出的延迟模型和优化问题为远程ID通信的性能提升提供了理论基础，实验结果也验证了该方法的有效性，对提升无人机间通信的效率和可靠性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 远程识别（Remote ID）广播能力对无人机间通信至关重要，但动态环境中多无人机操作的效率和及时性要求远程ID通信具有低延迟。

**Method:** 首先，建立了考虑BLE 4和Wi-Fi协议下数据包接收和碰撞的远程ID通信延迟模型。然后，基于这些模型，提出了一个优化问题来最小化长期通信延迟，并通过自适应协议选择实现。最后，提出了一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法来应对无人机密度变化。

**Result:** 在动态密度场景下，与静态BLE 4模式相比，该策略实现了32.1%的低延迟；与静态Wi-Fi模式相比，实现了37.7%的低延迟。

**Conclusion:** 通过建立延迟模型和采用基于多智能体深度Q网络的自适应BLE/Wi-Fi切换算法，可以有效降低远程ID无人机通信的延迟，尤其是在动态无人机密度场景下，从而提高通信效率和及时性。

> **ai_Abstract:** 本文研究了远程ID无人机通信中的延迟优化问题，认为低延迟对于动态环境下的多无人机操作至关重要。作者建立了BLE 4和Wi-Fi协议下的远程ID通信延迟模型，并将其建模为一个最小化长期通信延迟的优化问题。为应对无人机密度变化，提出了一种基于多智能体深度Q网络（MADQN）的自适应BLE/Wi-Fi切换算法。实验结果表明，该算法在动态密度场景下，相较于静态BLE 4和Wi-Fi模式，分别将延迟降低了32.1%和37.7%。

> **摘要翻译:** 远程识别（Remote ID）广播能力允许无人机（UAV）交换消息，这是无人机间通信的关键技术。尽管此能力增强了操作可见性，但在动态环境中，基于远程ID的通信中的低延迟对于确保多无人机操作的效率和及时性至关重要。为了解决这一挑战，我们首先通过考虑BLE 4和Wi-Fi协议下的数据包接收和碰撞，建立了远程ID通信的延迟模型。基于这些模型，我们提出了一个优化问题，旨在通过自适应协议选择来最小化长期通信延迟。由于延迟性能随无人机密度的变化而变化，我们提出了一种基于多智能体深度Q网络方法的自适应BLE/Wi-Fi切换算法。实验结果表明，在动态密度场景下，我们的策略与静态BLE 4和Wi-Fi模式相比，分别实现了32.1%和37.7%的更低延迟。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

### [78] [Diffusion-RL for Scalable Resource Allocation for 6G Networks](https://arxiv.org/abs/2506.07880)
> *用于6G网络可扩展资源分配的扩散强化学习*

*Salar Nouri, Mojdeh Karbalaee Motalleb, Vahid Shah-Mansouri* | **Main category: cs.NI**

**Keywords:** 扩散强化学习, 资源分配, O-RAN, 6G, 网络切片

**Comment:** 9 pages, 8 figures

> **TL;DR:** 本文提出了一种基于扩散强化学习（Diffusion-RL）的新方法，用于在开放无线接入网络（O-RAN）中进行资源分配，以满足5G和6G服务的不同需求，并在效率、可扩展性和鲁棒性方面优于现有方法。

**AI_Comments:** 该论文的创新之处在于将扩散模型与强化学习相结合，应用于O-RAN中的资源分配，并利用生成式AI和网络切片来处理复杂多样的服务需求。其在效率、可扩展性和鲁棒性方面的优势表明了该方法在未来6G网络中的巨大潜力，为解决动态异构网络环境下的资源优化问题提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决开放无线接入网络（O-RAN）中5G和6G服务类型（如eMBB、URLLC和mMTC）的多元化需求，需要一种新颖的资源分配方法。

**Method:** 本文引入了一种基于扩散的强化学习（Diffusion-RL）算法，旨在优化物理资源块（PRB）的分配和功耗，从而最大化加权吞吐量并最小化用户设备（UE）的延迟。该模型融合了受控噪声和扰动，以探索最佳资源分布，同时满足每种服务类型的服务质量（QoS）要求。此外，还对O-RAN中用于资源分配的机器学习（ML）技术进行了全面分析和比较。

**Result:** 通过与穷举搜索算法、深度Q网络（DQN）和半监督变分自编码器（SS-VAE）等基准进行性能评估，实验结果表明，所提出的基于扩散的强化学习方法在效率、可扩展性和鲁棒性方面均优于现有方法。针对每种服务类型，提供了吞吐量和延迟等综合指标。

**Conclusion:** 基于扩散的强化学习方法为动态异构O-RAN环境中的资源分配提供了一个有前景的解决方案，对未来的6G网络具有重要意义。

> **ai_Abstract:** 本文提出了一种创新的基于扩散强化学习（Diffusion-RL）的资源分配方法，专为开放无线接入网络（O-RAN）设计，以应对5G和6G网络中多种服务类型（如eMBB、URLLC、mMTC）的动态需求。该方法结合了生成式AI和网络切片，通过优化物理资源块和功耗，旨在最大化吞吐量并最小化延迟。实验结果表明，Diffusion-RL在效率、可扩展性和鲁棒性方面均优于现有的基准方法，为未来6G网络中的资源分配提供了有力的解决方案。

> **摘要翻译:** 本文提出了一种在开放无线接入网络（O-RAN）中进行资源分配的新颖方法，该方法利用生成式AI技术和网络切片来解决5G和6G服务类型（如增强型移动宽带（eMBB）、超可靠低延迟通信（URLLC）和大规模机器类型通信（mMTC））的多元化需求。此外，我们还对O-RAN中用于资源分配的机器学习（ML）技术进行了全面分析和比较，评估了它们在优化网络性能方面的有效性。我们引入了一种基于扩散的强化学习（Diffusion-RL）算法，旨在优化物理资源块（PRB）的分配和功耗，从而最大化加权吞吐量并最小化用户设备（UE）的延迟。Diffusion-RL模型融合了受控噪声和扰动，以探索最佳资源分布，同时满足每种服务类型的服务质量（QoS）要求。我们评估了所提出方法与多种基准（包括穷举搜索算法、深度Q网络（DQN）和半监督变分自编码器（SS-VAE））的性能。针对每种服务类型，提供了吞吐量和延迟等综合指标。实验结果表明，基于扩散的强化学习方法在效率、可扩展性和鲁棒性方面均优于现有方法，为动态异构O-RAN环境中的资源分配提供了一个有前景的解决方案，对未来的6G网络具有重要意义。

</details>

[⬆️ 返回分类顶部](#csni) | [⬆️ 返回总目录](#toc)

---

<a id='csit'></a>
## cs.IT 

### [15] [Statistical Limits for Finite-Rank Tensor Estimation](https://arxiv.org/abs/2506.06749)
> *有限秩张量估计的统计极限*

*Riccardo Rossetti, Galen Reeves* | **Main category: cs.IT**

**Keywords:** 张量估计, 统计极限, 高维模型, 异方差噪声, 分配问题

**Comment:** 25 pages, 0 figures

> **TL;DR:** 本文提供了一个统一的框架来分析张量估计问题，包括非线性观测、异方差噪声和协变量信息，并推导出贝叶斯最优设置下的互信息和最小均方误差的渐近精确公式，同时应用于两种新颖场景的统计阈值表征。

**AI_Comments:** 这篇论文的创新之处在于其提供了一个统一且通用的框架，能够处理传统方法难以解决的非线性、异方差噪声和协变量信息等复杂情况。其推导出的渐近精确公式对于理解复杂高维张量估计问题的统计极限具有重要理论价值。该工作对信号处理、机器学习等领域中张量数据分析具有重要指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在为允许非线性观测、异方差噪声和协变量信息的张量估计问题提供一个统一的分析框架，特别关注高维模型中观测值依赖于有限数量未知参数之间相互作用的情况。

**Method:** 本文建立了一个统一的框架来分析张量估计问题，该框架能够处理非线性观测、异方差噪声和协变量信息。主要方法是推导出贝叶斯最优设置下互信息（或自由能）以及最小均方误差的渐近精确公式，并将此框架应用于推导两种新颖场景的统计阈值。

**Result:** 主要结果是推导出了贝叶斯最优设置下互信息（或自由能）以及最小均方误差的渐近精确公式。该框架被应用于推导两种新颖场景的统计阈值的精确表征：(1) 独立但非同分布的异方差噪声下的张量估计，和 (2) 高阶分配问题（从张量值观测中恢复未知排列）。

**Conclusion:** 本文成功提供了一个统一的框架，能够处理复杂的张量估计问题，并为贝叶斯最优设置下的统计极限提供了精确的表征，同时为异方差噪声和高阶分配问题提供了尖锐的统计阈值分析。

> **ai_Abstract:** 本研究提出一个统一框架，用于分析包含非线性观测、异方差噪声和协变量信息的高维张量估计问题。核心贡献在于推导出贝叶斯最优设置下互信息和最小均方误差的渐近精确公式。该框架进一步应用于精确刻画了两种新颖场景的统计阈值：异方差噪声下的张量估计和高阶分配问题。

> **摘要翻译:** 本文提供了一个分析张量估计问题的统一框架，该框架允许非线性观测、异方差噪声和协变量信息。我们研究了一类通用的高维模型，其中每个观测值都取决于有限数量未知参数之间的相互作用。我们的主要结果提供了互信息（等效地，自由能）以及贝叶斯最优设置下最小均方误差的渐近精确公式。然后，我们将此框架应用于推导两种新颖场景的统计阈值的精确表征：(1) 在独立但非同分布的异方差噪声下的张量估计，以及 (2) 高阶分配问题，其目标是从张量值观测中恢复未知排列。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [29] [MIMO Pinching-Antenna-Aided SWIPT](https://arxiv.org/abs/2506.06754)
> *MIMO 夹持天线辅助的SWIPT*

*Haoyun Li, Zhonghao Lyu, Yulan Gao, Ming Xiao, H. Vincent Poor* | **Main category: cs.IT**

**Keywords:** 夹持天线系统, SWIPT, MIMO, 波束成形, 交替优化

**Comment:** 

> **TL;DR:** 提出了一种基于夹持天线系统(PASS)的MIMO-SWIPT系统，通过联合优化波束成形和天线位置，在保证能量收集的同时最大化信息传输速率。

**AI_Comments:** 该研究创新性地将新兴的夹持天线系统(PASS)引入到MIMO-SWIPT领域，利用其可调控的LoS链路增强能力来优化系统性能。其提出的联合优化波束成形和天线位置的策略，以及采用的WMMSE和高斯-赛德尔相结合的AO框架，为解决此类复杂非凸问题提供了有效途径。数值结果验证了PASS的优越性，表明该技术在未来无线通信中具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 夹持天线系统(PASS)有望通过调整夹持天线位置来建立或增强可靠的视距(LoS)链路，从而改善无线通信。受此启发，本文提出了一个用于同时无线信息和功率传输(SWIPT)的PASS辅助MIMO系统。

**Method:** 提出了一种新型的PASS辅助MIMO系统用于SWIPT，其中PASS配备多个波导，为多个信息解码接收器(IDR)和能量收集接收器(EHR)提供信息传输和无线功率传输(WPT)。目标是最大化所有IDR的总速率，同时保证每个EHR的最小收集能量，通过联合优化夹持波束成形和PA位置。该非凸问题通过交替优化(AO)框架解决：基于加权最小均方误差(WMMSE)方法迭代优化夹持波束成形，并使用基于高斯-赛德尔的方法更新PA位置。

**Result:** 数值结果验证了PASS相比传统设计的显著优越性。

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文提出了一种创新的夹持天线系统(PASS)辅助的多输入多输出(MIMO)系统，用于同时无线信息和功率传输(SWIPT)。该系统旨在通过联合优化夹持波束成形和夹持天线位置，在确保能量收集接收器(EHRs)最小能量收集的同时，最大化信息解码接收器(IDRs)的总速率。为了解决这一复杂的非凸优化问题，研究者采用了一种基于加权最小均方误差(WMMSE)和高斯-赛德尔方法的交替优化(AO)框架。数值结果表明，所提出的PASS系统相比传统设计具有显著优势。

> **摘要翻译:** 夹持天线系统（PASS）最近作为一种有前景的技术出现，通过调整夹持天线（PA）的位置来建立或加强可靠的视距（LoS）链路，从而改善无线通信。受这些益处的启发，我们提出了一种新颖的PASS辅助多输入多输出（MIMO）系统，用于同时无线信息和功率传输（SWIPT），其中PASS配备多个波导，分别为多个多天线信息解码接收器（IDR）和能量收集接收器（EHR）提供信息传输和无线功率传输（WPT）。基于该系统，我们考虑通过联合优化夹持波束成形和PA位置，在保证每个EHR最小收集能量的同时，最大化所有IDR的总速率。为了解决这个高度非凸问题，我们在一个交替优化（AO）框架中，基于加权最小均方误差（WMMSE）方法迭代优化夹持波束成形，并使用基于高斯-赛德尔的方法更新PA位置。数值结果验证了PASS与传统设计相比的显著优越性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [43] [Polarized Element-pair Code Based FFMA over a Gaussian Multiple-access Channel](https://arxiv.org/abs/2506.06796)
> *高斯多址信道下基于极化单元对码的FFMA*

*Zhang-li-han Liu, Qi-yue Yu* | **Main category: cs.IT**

**Keywords:** 极化单元对码, FFMA, 高斯多址信道, 有限块长, 解码算法

**Comment:** 13 pages 8 figures

> **TL;DR:** 本文提出一种用于PA-FFMA系统的极化单元对（EP）码，它针对高斯多址信道（GMAC）设计，通过独特的处理顺序和新颖的解码算法，解决了多用户有限块长问题，并在15用户场景下比现有系统实现1.25 dB的编码增益。

**AI_Comments:** 这篇论文通过引入专门为高斯多址信道设计的极化单元对码，并在FFMA架构中应用，创新性地解决了多用户有限块长通信的挑战。其独特的处理顺序和针对性的解码算法（SCL和TopL-BMD）是亮点。1.25 dB的编码增益证明了其在性能上的显著提升，对于多用户通信系统的实际应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 解决多用户有限块长（FBL）问题并提高错误性能，特别是在FFMA系统中，通过交换信道编码和多路复用操作的传统顺序。

**Method:** 1. 提出极化单元对（EP）码用于PA-FFMA系统，该码专为高斯多址信道（GMAC）设计。 2. 推导了基于该极化EP码的FFMA系统的信道容量，并开发了最优功率分配方案以最大化多用户信道容量。 3. 采用Marto Loco方法进行码构造。 4. 引入两种专用解码算法：用于信息-奇偶校验平衡场景的逐次消除列表（SCL）译码器，以及用于小载荷情况的Top$L$-BMD译码器。

**Result:** 仿真结果表明，在15个用户的情况下，该系统比最先进的极化随机扩频系统实现了1.25 dB的编码增益。

**Conclusion:** 本文提出了一种专为GMAC环境设计的极化EP码，并结合FFMA系统架构和创新的解码算法，有效解决了多用户有限块长问题，显著提升了错误性能，并实现了可观的编码增益。

> **ai_Abstract:** 本文提出了一种针对高斯多址信道（GMAC）环境设计的极化单元对（EP）码，并将其应用于极化调整有限域多址（PA-FFMA）系统。该系统通过独特的处理顺序解决了多用户有限块长（FBL）问题并提高了错误性能。研究内容包括推导信道容量、开发最优功率分配方案、采用Marto Loco方法进行码构造，以及引入SCL和Top$L$-BMD两种专用解码算法。仿真结果显示，在15个用户场景下，该系统相比现有极化随机扩频系统实现了1.25 dB的编码增益。

> **摘要翻译:** 本文提出了一种用于极化调整有限域多址（PA-FFMA）系统的极化单元对（EP）码。FFMA系统的核心创新在于其独特的处理顺序，该顺序交换了信道编码和多路复用操作的传统序列，有效解决了多用户有限块长（FBL）问题，同时提高了错误性能。在此架构中，EP作为用户分离的虚拟资源，不同的EP码提供不同的错误性能特性。所提出的极化EP码与经典极化码在一个方面有所不同，即它专门为高斯多址信道（GMAC）环境而非单用户高斯信道设计。我们推导了基于这种极化EP码的FFMA系统的信道容量，然后开发了一种最优功率分配方案以最大化多用户信道容量。码构造采用Marto Loco方法选择极化索引集。对于解码，我们引入了两种专用算法。一种是用于信息-奇偶校验平衡场景的逐次消除列表（SCL）译码器，另一种是用于小载荷情况的Top$L$-BMD译码器，同时保持可比较的错误性能。仿真结果表明，对于15个用户，我们的系统比最先进的极化随机扩频系统实现了1.25 dB的编码增益。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [58] [Passive Detection in Multi-Static ISAC Systems: Performance Analysis and Joint Beamforming Optimization](https://arxiv.org/abs/2506.07019)
> *多基地ISAC系统中的无源探测：性能分析与联合波束赋形优化*

*Renjie He, Yiqiu Wang, Meixia Tao, Shu Sun* | **Main category: cs.IT**

**Keywords:** 无源探测, ISAC系统, 波束赋形, 广义似然比检验, 性能分析

**Comment:** 

> **TL;DR:** 本文研究了多基地ISAC系统中利用未知通信信号进行无源探测，并提出了两种联合波束赋形优化设计以平衡探测性能和通信质量。

**AI_Comments:** 本文的创新点在于提出了在多基地ISAC系统中，利用未知通信信号进行无源目标探测的方法，这大大降低了对先验知识的需求。其提出的两种联合波束赋形优化设计，特别是第一种复杂的非凸优化问题的解决，展示了其在实际应用中的潜力，能够有效平衡感知和通信性能。这项工作为未来ISAC系统的发展提供了重要思路。

<details>
  <summary>Details</summary>

**Motivation:** 传统有源探测需要完整的先验知识，而本文研究的无源探测不需要对通信信号有完整的先验知识，旨在解决这一限制并在多基地ISAC系统中实现目标探测。

**Method:** 首先，推导了广义似然比检验检测器，并进行了大样本状态下的渐近分析。然后，提出了两种联合发射波束赋形设计：第一种设计在满足通信用户信噪比要求和总发射功率约束下，最大化渐近检测概率，并采用基于二次变换和半正定松弛的交替优化算法解决其非凸性；第二种设计采用启发式方法，旨在最大化目标能量，同时满足直达路径的最小信噪比阈值，且计算复杂度较低。

**Result:** 数值结果验证了渐近分析的准确性，并表明所提出的波束赋形设计在平衡无源探测性能和通信质量方面具有优越性。

**Conclusion:** 这项工作突出了在多基地ISAC系统中利用未知通信数据信号进行目标探测的潜力。

> **ai_Abstract:** 本文探讨了多基地ISAC系统中的无源探测问题，提出了一种无需通信信号完整先验知识的探测方法。研究推导了广义似然比检验检测器并进行了渐近分析，在此基础上提出了两种联合发射波束赋形优化设计。第一种设计通过交替优化算法最大化渐近检测概率，第二种设计通过启发式方法最大化目标能量。数值结果表明，所提出的波束赋形设计在平衡无源探测性能和通信质量方面表现出色，证实了利用未知通信信号进行目标探测的可行性。

> **摘要翻译:** 本文研究了多基地集成感知与通信（ISAC）系统中的无源探测问题，其中多个感知接收器（SRs）协同使用协作基站发送的随机未知通信信号来联合探测目标。与传统的有源探测不同，所考虑的无源探测不需要每个感知接收器对传输的通信信号有完整的先验知识。首先，我们推导了一个广义似然比检验检测器，并在大样本条件下对检测统计量进行了渐近分析。我们检查了目标路径和直达路径的信噪比（SNRs）如何影响检测性能。然后，我们基于这些分析提出了两种联合发射波束赋形设计。在第一种设计中，在总发射功率约束下，在满足每个通信用户的信噪比（SNR）要求的同时，最大化渐近检测概率。考虑到问题的非凸性，我们开发了一种基于二次变换和半正定松弛的交替优化算法。第二种设计采用启发式方法，旨在最大化目标能量，同时满足直达路径上的最小信噪比阈值，并提供较低的计算复杂度。数值结果验证了渐近分析，并证明了所提出的波束赋形设计在平衡无源探测性能和通信质量方面的优越性。这项工作突出了在多基地ISAC系统中利用未知通信数据信号进行目标探测的潜力。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [73] [Energy Efficiency Maximization for Movable Antenna Communication Systems](https://arxiv.org/abs/2506.07129)
> *可移动天线通信系统的能量效率最大化*

*Jingze Ding, Zijian Zhou, Lipeng Zhu, Yuping Zhao, Bingli Jiao, Rui Zhang* | **Main category: cs.IT**

**Keywords:** 可移动天线, 能量效率最大化, 多用户通信, 时间延迟, 能量消耗

**Comment:** 

> **TL;DR:** 本文研究了可移动天线（MA）辅助多用户上行通信系统中的能量效率最大化问题，考虑了天线移动的时间延迟和能量消耗，并提出了针对单用户和多用户场景的优化算法。

**AI_Comments:** 本文的创新之处在于其首次将可移动天线通信系统中天线移动的时间延迟和能量消耗纳入能量效率最大化问题，这使得研究更贴近实际应用。所提出的针对单用户和多用户场景的优化算法具有理论和实践意义。此外，对不完善CSI鲁棒性的验证增强了方案的实用性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的可移动天线（MA）通信系统在最大化能量效率时，通常忽略了天线移动带来的时间延迟和能量消耗。为了更实际地提高系统性能，本文旨在解决这一问题。

**Method:** 本文首先针对单用户场景，提出了一种基于一维（1D）穷举搜索的优化算法来最大化用户能量效率，并推导了能量效率的上限。然后，对于多用户场景，提出了一种迭代算法来公平地最大化所有用户的最小能量效率。

**Result:** 仿真结果表明，与现有不考虑移动成本的MA方案以及传统的固定位置天线（FPA）方案相比，所提出的方案能有效提高能量效率。此外，该方案对不完善的信道状态信息（CSI）具有鲁棒性。

**Conclusion:** 本文提出的考虑天线移动成本的能量效率最大化方案，在多用户上行MA通信系统中表现出优越的性能和鲁棒性，为实际系统部署提供了有价值的见解。

> **ai_Abstract:** 本文研究了可移动天线（MA）辅助多用户上行通信系统的能量效率最大化，首次将天线移动的时间延迟和能量消耗纳入考虑。针对单用户情况，提出了一维穷举搜索算法并推导了能量效率上限。针对多用户情况，提出了一种迭代算法以公平最大化最小能量效率。仿真结果验证了所提方案在提高能量效率方面的有效性，并显示其对不完善CSI的鲁棒性，为实际部署提供了指导。

> **摘要翻译:** 本文研究了可移动天线（MA）辅助多用户上行通信系统中的能量效率最大化问题，其中考虑了实际天线移动所产生的时间延迟和能量消耗。我们首先研究了单用户的特殊情况，并提出了一种基于一维（1D）穷举搜索的优化算法来最大化用户的能量效率。此外，我们推导了能量效率的上限，并分析了在不同信道路径数下达到此性能界限所需的条件。然后，对于一般多用户场景，我们提出了一种迭代算法来公平地最大化所有用户的最小能量效率。仿真结果表明，与现有不考虑移动相关成本的MA方案以及传统的固定位置天线（FPA）方案相比，所提出的方案在提高能量效率方面是有效的。此外，结果表明所提出的方案对不完善的信道状态信息（CSI）具有鲁棒性，并为实际系统部署提供了有价值的见解。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [87] [Fluid Antenna-Empowered Receive Spatial Modulation](https://arxiv.org/abs/2506.07362)
> *流体天线赋能的接收空间调制*

*Xinghao Guo, Yin Xu, Dazhi He, Cixiao Zhang, Hanjiang Hong, Kai-Kit Wong, Chan-Byoung Chae, Wenjun Zhang, Yiyan Wu* | **Main category: cs.IT**

**Keywords:** 流体天线, 接收空间调制, 空间分集, 端口选择, 低复杂度检测

**Comment:** 12 pages, submitted to IEEE Journal

> **TL;DR:** 本文提出了一种流体天线赋能的接收空间调制（FA-RSM）系统，解决了端口选择、理论分析和检测等挑战，并通过仿真验证了其优于传统RSM系统，且具有低复杂度。

**AI_Comments:** 这篇论文创新性地将新兴的流体天线技术应用于接收空间调制，通过解决关键技术挑战，提升了系统的性能。其提出的低复杂度算法和检测器，对于实际系统部署具有重要意义，尤其是在权衡性能与成本方面提供了有效的解决方案。研究中对空间相关性导致性能增益饱和的揭示，也为未来研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 充分利用空间分集，并将新兴的流体天线技术与接收空间调制（RSM）方案相结合，以提升系统性能。

**Method:** 本文提出了一种新型的流体天线赋能的接收空间调制（FA-RSM）系统。为解决FA-RSM系统中的端口选择、理论分析和检测三大挑战，研究者首先提出了一种基于容量最大化的最优端口选择算法，并提供了两种低复杂度替代方案。其次，对端口选择进行了理论分析，提供了性能评估指标，并表明增加激活端口数量可提升系统性能。最后，提出了两种低复杂度检测器。

**Result:** 仿真结果表明，FA-RSM系统显著优于传统的RSM系统。所提出的低复杂度端口选择算法能实现最小的性能下降。激活更多端口可以提高性能，但由于固有的空间相关性，增益会逐渐饱和，这凸显了有效端口选择在降低系统复杂度和成本方面的重要性。此外，所提出的两种检测器都以低计算复杂度实现了接近最优的检测性能。

**Conclusion:** FA-RSM系统通过创新的端口选择和低复杂度检测器，显著提升了性能，并强调了有效端口选择对于平衡性能、复杂度和成本的重要性，使其成为一个对接收机友好的系统。

> **ai_Abstract:** 本文提出了一种将流体天线（FA）与接收空间调制（RSM）结合的新型FA-RSM系统。该系统通过解决端口选择、理论分析和检测三大挑战，实现了性能的显著提升。研究者提出了最优及低复杂度的端口选择算法，并分析了激活端口数量对性能的影响及饱和现象。同时，设计了两种低复杂度检测器。仿真结果表明，FA-RSM系统性能优于传统RSM，且具有低复杂度、接收机友好的特点。

> **摘要翻译:** 流体天线（FA）作为一种新兴的天线技术，充分利用了空间分集。本文将FA与接收空间调制（RSM）方案相结合，提出了一种新颖的流体天线赋能的RSM（FA-RSM）系统。在该系统中，发射器配备了一个FA，同时激活多个端口来传输预编码信号。我们解决了FA-RSM系统中的三个关键挑战：端口选择、理论分析和检测。首先，对于端口选择，提出了一个从容量最大化角度出发的最优算法，随后提出了两种低复杂度替代方案。其次，对于理论分析，提供了端口选择的性能评估指标，这些指标表明增加激活端口的数量可以增强系统性能。第三，关于检测，提出了两种低复杂度检测器。仿真结果证实，FA-RSM系统显著优于传统的RSM系统。所提出的低复杂度端口选择算法有助于实现最小的性能下降。此外，虽然激活额外端口可以提高性能，但由于固有的空间相关性，增益逐渐饱和，这凸显了有效端口选择在降低系统复杂度和成本方面的重要性。最后，所提出的两种检测器都以低计算复杂度实现了接近最优的检测性能，强调了FA-RSM系统对接收机的友好性。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [100] [The error-correcting pair for several classes of NMDS linear codes](https://arxiv.org/abs/2506.07380)
> *几类NMDS线性码的纠错对*

*Dong He, Zhaohui Zhang, Qunying Liao* | **Main category: cs.IT**

**Keywords:** 纠错对, NMDS线性码, Product Singleton Bound, 扭曲广义Reed-Solomon码, 必要条件

**Comment:** 20 pages

> **TL;DR:** 本文研究了几类NMDS线性码的纠错对，并针对不同最小距离的NMDS码，基于Product Singleton Bound给出了其具有纠错对时参数的必要条件和相应的例子。

**AI_Comments:** 本文在He和Liao (2023) 的工作基础上，进一步细化了NMDS线性码拥有纠错对的条件，通过给出具体的必要条件和构造性例子，对NMDS码的解码理论和应用具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 纠错对是线性码的通用代数解码方法。近最大距离可分（NMDS）线性码是线性码的一个子类，由于其高效的性能，在秘密共享方案和通信系统中具有应用，因此研究NMDS线性码的纠错对具有重要意义。

**Method:** 本文基于Product Singleton Bound给出了NMDS线性码具有纠错对的几个必要条件。此外，还基于扭曲广义Reed-Solomon码给出了相应的例子。

**Result:** 对于最小距离为$2\ell+1$的NMDS线性码，论文给出了其具有$\ell$-纠错对时$\mathcal{A}$参数为第1、2、4或5种情况的几个必要条件，并给出了$\mathcal{A}$参数为第1种情况的例子。对于最小距离为$2\ell+2$的NMDS线性码，论文给出了其具有$\ell$-纠错对时$\mathcal{A}$参数为第2、4、7或8种情况的几个必要条件，并分别给出了$\mathcal{A}$参数为第1或第2种情况的例子。

**Conclusion:** 本文为NMDS线性码的纠错对的存在性提供了重要的必要条件，并通过具体例子验证了这些条件，有助于深入理解NMDS码的纠错能力。

> **ai_Abstract:** 本文深入研究了NMDS线性码的纠错对。基于Product Singleton Bound，作者为最小距离为$2\ell+1$和$2\ell+2$的NMDS线性码提供了其具有$\ell$-纠错对时$\mathcal{A}$参数的几个必要条件。此外，论文还利用扭曲广义Reed-Solomon码为这些条件提供了具体的例子，从而为理解NMDS码的纠错能力提供了新的见解。

> **摘要翻译:** 纠错对是线性码的一种通用代数解码方法。近最大距离可分（NMDS）线性码是线性码的一个子类，由于其高效的性能，在秘密共享方案和通信系统中具有应用，因此我们专注于NMDS线性码的纠错对。2023年，He和Liao表明，对于最小距离为$2\ell+1$或$2\ell+2$的NMDS线性码$\mathcal{C}$，如果$\mathcal{C}$具有一个$\ell$-纠错对$\left( \mathcal{A}, \mathcal{B} \right)$，则$\mathcal{A}$的参数分别有6种或10种可能性。\n在本手稿中，我们基于Product Singleton Bound，给出了最小距离为$2\ell+1$的NMDS线性码$\mathcal{C}$具有$\ell$-纠错对$(\mathcal{A}, \mathcal{B})$的几个必要条件，其中$\mathcal{A}$的参数是第1、2、4或5种情况，然后基于扭曲广义Reed-Solomon码，我们给出了$\mathcal{A}$参数为第1种情况的例子。此外，我们还给出了最小距离为$2\ell+2$的NMDS线性码$\mathcal{C}$具有$\ell$-纠错对$(\mathcal{A}, \mathcal{B})$的几个必要条件，其中$\mathcal{A}$的参数是第2、4、7或8种情况，然后我们分别给出了$\mathcal{A}$参数为第1或第2种情况的例子。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [113] [Distributed Image Semantic Communication via Nonlinear Transform Coding](https://arxiv.org/abs/2506.07391)
> *分布式图像语义通信通过非线性变换编码*

*Yufei Bo, Meixia Tao, Kai Niu* | **Main category: cs.IT**

**Keywords:** 分布式图像通信, 语义通信, 非线性变换编码, 源信道编码, 联合熵模型

**Comment:** arXiv admin note: text overlap with arXiv:2503.21249

> **TL;DR:** 本文提出了一种基于非线性变换编码（NTC）的分布式图像语义通信方法D-NTSC/D-NTSCC，该方法显式建模源相关性，并在多视角数据集上实现了最先进的性能。

**AI_Comments:** 该论文的创新点在于其提出了一种显式建模源相关性的分布式图像语义通信方法，与现有隐式学习的方法形成对比。通过引入非线性变换编码、联合熵模型和变换模块，并结合Swin Transformers，该方法在理论和实践上都取得了显著进步。在分布式通信场景中，尤其是在处理多视图图像等相关数据时，这种显式建模相关性的方法对于提高传输效率和重建质量具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于学习的分布式图像语义通信方法隐式地、纯数据驱动地学习源相关性，而本文旨在通过非线性变换编码（NTC）从概率和几何角度显式建模源相关性，以提高传输效率和重建质量。

**Method:** 本文提出了一种通用的分布式图像语义通信方法，适用于分离源和信道编码（SSCC）和联合源信道编码（JSCC）。该方法利用非线性变换编码（NTC）显式地从概率和几何角度建模源相关性。具体地，它采用一个联合熵模型来近似潜在表示的联合分布以指导自适应速率分配，并使用一个变换模块来对齐潜在特征以实现解码器处最大相关性学习。该框架被实现为D-NTSC（用于SSCC）和D-NTSCC（用于JSCC），两者均基于Swin Transformers进行有效的特征提取和相关性利用。此外，采用变分推断来推导联合优化编码、解码和联合熵建模的损失函数。

**Result:** 在真实世界多视角数据集上的广泛实验表明，D-NTSC和D-NTSCC分别优于现有的分布式SSCC和分布式JSCC基线，在像素级和感知质量指标上均实现了最先进的性能。

**Conclusion:** 本文提出的基于非线性变换编码的分布式图像语义通信方法（D-NTSC和D-NTSCC）在实验中表现出优越性，并在多视角数据集上达到了最先进的性能，证明了其在处理相关图像语义传输方面的有效性和潜力。

> **ai_Abstract:** 本文提出了一种名为D-NTSC（用于SSCC）和D-NTSCC（用于JSCC）的分布式图像语义通信新方法。该方法通过非线性变换编码（NTC）显式地从概率和几何角度建模相关图像的源相关性，克服了现有数据驱动方法隐式学习的局限性。它结合了联合熵模型进行自适应速率分配和变换模块进行特征对齐，并利用Swin Transformers进行高效特征提取。实验证明，该方法在多视角数据集上超越了现有基线，在图像质量上达到了最先进水平。

> **摘要翻译:** 本文研究了无线信道上相关图像语义传输的分布式源信道编码。在此设置中，不同发射机处的关联图像被单独编码和传输，以便在接收机处联合恢复。我们提出了一种通用的分布式图像语义通信方法，适用于分离源和信道编码（SSCC）以及联合源信道编码（JSCC）。与现有纯数据驱动隐式学习源相关性的学习方法不同，我们的方法利用非线性变换编码（NTC）从概率和几何角度显式建模源相关性。一个联合熵模型近似潜在表示的联合分布以指导自适应速率分配，而一个变换模块对齐潜在特征以实现解码器处最大相关性学习。我们将此框架实现为用于SSCC的D-NTSC和用于JSCC的D-NTSCC，两者都建立在Swin Transformers上，以实现有效的特征提取和相关性利用。采用变分推断来推导联合优化编码、解码和联合熵建模的原理性损失函数。在真实世界多视角数据集上的广泛实验表明，D-NTSC和D-NTSCC分别优于现有的分布式SSCC和分布式JSCC基线，在像素级和感知质量指标上均实现了最先进的性能。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [127] [Flexible MIMO for Future Wireless Communications: Which Flexibilities are Possible?](https://arxiv.org/abs/2506.07599)
> *错误：AI分析失败。*

*Zhe Wang, Jiayi Zhang, Bokai Xu, Wenhui Yi, Emil Björnson, Bo Ai* | **Main category: cs.IT**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 5 figures, 1 table

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [140] [Criss-Cross Deletion Correcting Codes: Optimal Constructions with Efficient Decoders](https://arxiv.org/abs/2506.07607)
> *交叉删除纠错码：高效解码器的最优构造*

*Yubo Sun, Gennian Ge* | **Main category: cs.IT**

**Keywords:** 交叉删除, 纠错码, 最优构造, 解码器, 冗余度

**Comment:** 

> **TL;DR:** 本文构建了用于交叉删除的最优纠错码，并提供了高效的解码算法。

**AI_Comments:** 该论文在二维错误纠正领域取得了重要进展，特别是针对交叉删除这一特定错误模型。其创新性在于提出了最优的代码构造和高效的解码算法，填补了该领域的空白。理论下界和构造的匹配性证明了其工作的严谨性和贡献度。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决二维纠错中的基本挑战，通过构建针对“交叉删除”的最优代码。

**Method:** 研究考虑了同时删除 $t_r$ 行和 $t_c$ 列的 $n 	imes n$ 数组上的 $(t_r, t_c)$-交叉删除。推导了最优码冗余的球填充类型下界和Gilbert-Varshamov类型上界。对于 $(1,1)$-交叉删除，开发了两种构造族。对于 $(t_r, t_c)$-交叉删除，当单向删除连续发生时，提供了推导最优码的策略。

**Result:** 最优冗余度介于 $(t_r + t_c)n	ext{log }q + (t_r + t_c)	ext{log }n + O_{q,t_r,t_c}(1)$ 和 $(t_r + t_c)n	ext{log }q + 2(t_r + t_c)	ext{log }n + O_{q,t_r,t_c}(1)$ 之间。对于 $(1,1)$-交叉删除，构造的冗余度分别为 $2n	ext{log }q + 2	ext{log }n$ 和 $2n	ext{log }q + 2	ext{log }n + O_q(1)$，与下界匹配，证实了其最优性。提出了时间复杂度为 $O(n^2)$ 的解码算法。

**Conclusion:** 本文构建的交叉删除纠错码是最优的，并且提供了高效的解码算法，解决了二维纠错中的挑战。

> **ai_Abstract:** 本文研究了二维纠错中的交叉删除问题，即同时删除二维数组中的行和列。作者推导了 $(t_r, t_c)$-交叉删除纠错码的最优冗余度上下界。对于 $(1,1)$-交叉删除，提出了两种最优构造，其冗余度与理论下界仅相差一个常数。对于更一般的 $(t_r, t_c)$-交叉删除，也提供了构建最优码的策略。此外，论文还提出了时间复杂度为 $O(n^2)$ 的高效解码算法。

> **摘要翻译:** 本文通过构建“交叉删除”的最优代码，解决了二维纠错中的基本挑战。我们考虑一个 $n 	imes n$ 的$q$进制字母表 $\Sigma_q := \{0, 1, \ldots, q-1\}$ 上的数组，该数组受到“$(t_r, t_c)$-交叉删除”的影响，其中涉及同时删除 $t_r$ 行和 $t_c$ 列。如果代码 $\mathcal{C} \subseteq \Sigma_q^{n \times n}$ 能够成功纠正这些删除，则将其定义为“$(t_r,t_c)$-交叉删除纠错码”。我们推导了最优码冗余的球填充类型下界和Gilbert-Varshamov类型上界。我们的结果表明，$(t_r, t_c)$-交叉删除纠错码的最优冗余度介于 $(t_r + t_c)n\text{log }q + (t_r + t_c)\text{log }n + O_{q,t_r,t_c}(1)$ 和 $(t_r + t_c)n\text{log }q + 2(t_r + t_c)\text{log }n + O_{q,t_r,t_c}(1)$ 之间，其中对数以二为底，$O_{q,t_r,t_c}(1)$ 是一个仅取决于 $q$、$t_r$ 和 $t_c$ 的常数。对于 $(1,1)$-交叉删除的情况，我们开发了两个构造族。一个针对非二进制字母表实现了 $2n\text{log }q + 2\text{log }n$ 的冗余度，而另一个对于任意字母表需要 $2n\text{log }q + 2\text{log }n + O_q(1)$ 比特的冗余度。这两个构造都与我们的下界匹配，仅相差一个仅取决于 $q$ 的常数 $O_q(1)$，从而证实了它们的最优性。对于 $(t_r, t_c)$-交叉删除的情况，当两种单向删除连续发生时，我们提供了一种推导最优码的策略。我们提出了时间复杂度为 $O(n^2)$ 的解码算法，这对于二维场景来说是最优的。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [151] [Correcting Errors Through Partitioning and Burst-Deletion Correction](https://arxiv.org/abs/2506.07609)
> *通过分区和突发删除纠正错误*

*Yubo Sun, Gennian Ge* | **Main category: cs.IT**

**Keywords:** 分区, 突发删除, 纠错码, 序列对, t-删除s-替换

**Comment:** 

> **TL;DR:** 本文提出了一种分区技术，用于分解具有重叠t-删除s-替换球的序列对，从而构建了新的t-删除s-替换纠错码，其性能在某些情况下优于现有方法。

**AI_Comments:** 这项研究的创新之处在于提出了分区技术，将复杂的t-删除s-替换问题转化为可利用现有突发删除纠正方法的子问题。其重要性在于构建了性能优越的新型纠错码，并为整个错误纠正领域提供了更深层次的理解和统一的理论框架，有助于揭示当前方法的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在通过提出一种分区技术，利用现有的突发删除纠错方法来开发更有效的t-删除s-替换纠错码。

**Method:** 本文提出了一种分区技术，将具有重叠t-删除s-替换球的序列对分解为子对，其中每个子对的≤t-突发删除球相交。在此基础上，构建了适用于二元字母表（t=1,2）和非二元字母表（t=1）的t-删除s-替换纠错码。

**Result:** 所构建的纠错码在某些情况下与现有结果相匹配，在其他情况下则优于当前方法。该框架为现有工作提供了新见解，阐明了当前方法的局限性，并提供了错误纠正策略的统一视角。

**Conclusion:** 本文提出的分区框架不仅成功构建了性能优越的t-删除s-替换纠错码，而且为错误纠正策略提供了新的见解和统一的视角，揭示了现有方法的局限性。

> **ai_Abstract:** 本文提出了一种创新的分区技术，旨在解决t-删除s-替换错误纠正问题。通过将序列对分解为子对并利用≤t-突发删除纠正方法，研究人员构建了针对二元和非二元字母表的t-删除s-替换纠错码。这些新构造的码在某些情况下性能与现有方法相当，在另一些情况下则表现更优。该研究不仅提供了新的纠错方案，也为理解现有工作和错误纠正策略提供了统一的视角。

> **摘要翻译:** 在本文中，我们提出了一种分区技术，该技术将一对具有重叠t-删除s-替换球的序列分解为子对，其中每个子对的≤t-突发删除球相交。这种分解有助于开发利用≤t-突发删除纠正方法的t-删除s-替换纠错码。在≤t-突发删除纠正领域已建立的方法基础上，我们为二元字母表中的t∈{1,2}和非二元字母表中的t=1构建了t-删除s-替换纠错码，其中一些构造与现有结果相匹配，另一些则优于当前方法。我们的框架为先前工作的基本原理提供了新见解，阐明了当前方法的局限性，并为错误纠正策略提供了统一的视角。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [161] [A General Coding Framework for Adaptive Private Information Retrieval](https://arxiv.org/abs/2506.07787)
> *自适应私有信息检索的通用编码框架*

*Jinbao Zhu, Xiaohu Tang* | **Main category: cs.IT**

**Keywords:** 私有信息检索, 自适应PIR, 慢服务器, 编码框架, 分布式存储系统

**Comment:** Accepted by IEEE TIT

> **TL;DR:** 本文提出了一种通用的编码框架，用于设计能够容忍可变数量慢服务器（stragglers）的自适应私有信息检索（PIR）方案，并给出了具体的速率实现。

**AI_Comments:** 本文的创新点在于提出了一个通用的编码框架来解决自适应PIR问题，特别是考虑了实际场景中慢服务器的存在。通过引入“可行PIR编码框架”的概念，为设计容错的PIR方案提供了一个灵活且强大的工具。其重要性在于提升了PIR方案在非理想网络环境下的鲁棒性和实用性，为分布式存储系统中的隐私保护和数据检索提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 在实际的分布式存储系统中，用户从服务器检索文件时，可能会遇到响应缓慢或无响应的服务器（称为“慢服务器”），其身份和数量未知且可能随时间变化。传统PIR方案难以应对这种情况，因此需要一种能够容忍可变数量慢服务器的自适应PIR方案。

**Method:** 本文提出了一种通用编码方法，通过引入“可行PIR编码框架”的概念来设计自适应PIR方案。该方法允许在有限域上构建PIR方案，以应对可变数量的慢服务器。此外，论文还提供了一个“可行PIR编码框架”的实现。

**Result:** 任何在有限域$\\mathbb{F}_q$上的“可行PIR编码框架”都可以用于构建一个自适应PIR方案，该方案在$0\\leq S\\leq N-(K+X+T)$的慢服务器数量下，同时实现$1-\\frac{K+X+T-1}{N-S}$的检索速率。此外，论文提供了一个确保自适应PIR方案可以在任何大小为$q\\geq N+\\max\\{K, N-(K+X+T-1)\\}$的有限域$\\mathbb{F}_q$上运行的“可行PIR编码框架”的实现。

**Conclusion:** 本文提出了一个通用的编码框架来解决自适应私有信息检索问题，该框架能够有效容忍分布式存储系统中存在可变数量的慢服务器，并实现了特定的检索速率，为实际应用提供了理论基础和实现方法。

> **ai_Abstract:** 本研究解决了在存在可变数量慢服务器的分布式存储系统中进行私有信息检索（PIR）的挑战。论文提出了一种“通用编码框架”来设计自适应PIR方案，引入了“可行PIR编码框架”的概念。研究表明，任何在有限域上的可行PIR编码框架都可以构建一个自适应PIR方案，该方案在不同数量的慢服务器存在时，能实现特定的检索速率。此外，论文还提供了一个确保该方案在特定有限域上运行的具体实现。

> **摘要翻译:** 关于$T$合谋私有信息检索（PIR）的问题，用户可以从具有$N$个服务器的分布式存储系统中检索$M$个文件中的一个，而不会向任何多达$T$个合谋服务器组透露所需文件的索引信息。在所考虑的存储系统中，$M$个文件以$X$安全$K$编码的方式存储在$N$个分布式服务器上，使得任何多达$X$个合谋服务器组都无法了解文件内容；与文件总大小相比，每个服务器的存储开销减少了$\\frac{1}{K}$；并且文件可以从任意$K+X$个服务器中重建。然而，在实际场景中，当用户从分布式系统检索所需文件时，一些服务器可能响应非常慢或根本不响应。这些服务器被称为“慢服务器”，其身份和数量事先未知，并且可能随时间变化。本文考虑了能够容忍可变数量慢服务器存在的自适应PIR问题。我们通过引入“可行PIR编码框架”的概念，提出了一种设计自适应PIR方案的通用编码方法。我们证明，任何在大小为$q$的有限域$\\mathbb{F}_q$上的“可行PIR编码框架”都可以用于构建一个自适应PIR方案，该方案在相同的有限域上同时实现$1-\\frac{K+X+T-1}{N-S}$的检索速率，适用于所有$0\\leq S\\leq N-(K+X+T)$的慢服务器数量。此外，我们提供了一个“可行PIR编码框架”的实现，确保自适应PIR方案可以在任何大小为$q\\geq N+\\max\\{K, N-(K+X+T-1)\\}$的有限域$\\mathbb{F}_q$上运行。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [172] [Learned Off-Grid Imager for Low-Altitude Economy with Cooperative ISAC Network](https://arxiv.org/abs/2506.07799)
> *用于低空经济的合作ISAC网络学习型离格成像仪*

*Yixuan Huang, Jie Yang, Shuqiang Xia, Chao-Kai Wen, Shi Jin* | **Main category: cs.IT**

**Keywords:** 低空经济, 合作ISAC, 压缩感知, 离格误差, 无人机检测

**Comment:** submitted to IEEE for possible publication

> **TL;DR:** 本文提出了一种基于压缩感知和物理嵌入学习的低空监视框架，利用现有蜂窝网络实现高精度无人机检测，有效解决了传统方法的离格误差问题，并显著提高了检测率。

**AI_Comments:** 本文的创新点在于将物理嵌入学习与压缩感知相结合，有效解决了低空监视中的离格误差问题，并引入难例挖掘机制提升了稀有目标检测能力，对低空经济的空域安全和管理具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 低空经济是未来经济增长的关键驱动力，需要利用现有移动蜂窝网络感知能力进行有效的飞行活动监测。然而，传统的单站和基于定位的感知方法在融合感知结果和匹配信道参数方面面临挑战。

**Method:** 将低空监视建模为基于压缩感知（CS）的成像问题，利用多基站协作和空中图像的固有稀疏性。推导了点扩散函数以分析不同天线、子载波和分辨率设置对成像性能的影响。提出了一种物理嵌入学习方法以减轻传统CS方法中的离格误差。此外，将在线难例挖掘方案集成到损失函数设计中，以增强对稀有无人机的检测。

**Result:** 仿真结果表明所提出的低空监视框架的有效性。所提出的物理嵌入学习算法实现了97.55%的检测率，在离格条件下显著优于传统的基于CS的方法。

**Conclusion:** 该研究提出了一种有效的低空监视框架，通过结合物理嵌入学习和在线难例挖掘，显著提高了无人机检测的准确性，尤其是在存在离格误差的情况下，为低空经济的飞行活动监测提供了新途径。

> **ai_Abstract:** 本文针对低空经济中飞行活动监视的需求，提出了一种基于压缩感知（CS）的低空成像框架。该框架利用多基站协作和空中图像稀疏性，并将低空监视建模为CS成像问题。为解决传统CS方法中的离格误差，引入了一种物理嵌入学习方法，并结合在线难例挖掘方案以提高稀有无人机检测能力。仿真结果显示，该方法检测率高达97.55%，显著优于传统CS方法。

> **摘要翻译:** 低空经济正在成为未来经济增长的关键驱动力，因此需要利用现有移动蜂窝网络的感知能力进行有效的飞行活动监视。然而，传统的单站和基于定位的感知方法在融合感知结果和匹配信道参数方面面临挑战。为了解决这些挑战，我们通过利用多个基站的协作和空中图像固有的稀疏性，将低空监视建模为一个基于压缩感知（CS）的成像问题。此外，我们推导了点扩散函数，以分析不同天线、子载波和分辨率设置对成像性能的影响。鉴于无人机（UAVs）的随机空间分布，我们提出了一种物理嵌入学习方法来减轻传统基于CS方法中的离格误差。此外，为了增强在广阔低空空域中稀有无人机的检测，我们将在线难例挖掘方案集成到损失函数设计中，使网络在训练期间能够自适应地关注与真实值存在显著差异的样本。仿真结果证明了所提出的低空监视框架的有效性。所提出的物理嵌入学习算法实现了97.55%的检测率，在离格条件下显著优于传统的基于CS的方法。本文的部分源代码将很快在https://github.com/kiwi1944/LAEImager访问。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [180] [On the Fixed-Length-Burst Levenshtein Ball with Unit Radius](https://arxiv.org/abs/2506.07817)
> *关于单位半径的固定长度突发Levenshtein球*

*Yuanxiao Xi, Yubo Sun, Gennian Ge* | **Main category: cs.IT**

**Keywords:** Levenshtein球, 突发错误, 组合编码理论, 序列分析, 基数

**Comment:** 

> **TL;DR:** 本文系统地研究了固定长度突发Levenshtein球，并提供了其基数、极值界、期望大小及其集中性质的综合解决方案。

**AI_Comments:** 本文解决了Levenshtein球分析中一个重要的未研究领域，即当删除和插入次数t>1时的普遍情况，并特别聚焦于“突发”操作。其创新性在于为复杂的固定长度突发Levenshtein球提供了全面的数学解决方案，包括基数、极值和统计性质。这对于纠错码和序列分析等领域具有重要理论价值。

<details>
  <summary>Details</summary>

**Motivation:** 分析固定长度Levenshtein球的大小和结构在组合编码理论中具有重要挑战。现有研究已成功描述了单次删除和单次插入的情况，但涉及任意数量的t次删除和t次插入（t>1）的普遍情况仍未得到充分研究。

**Method:** 本文系统地检查了具有多次删除和插入的固定长度Levenshtein球，特别关注删除和插入连续发生的固定长度突发Levenshtein球。作者提供了明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质的综合解决方案。

**Result:** 本文为固定长度突发Levenshtein球提供了明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质的综合解决方案。

**Conclusion:** 本文为固定长度突发Levenshtein球的多种关键指标（包括明确的基数公式、极值界、期望大小及其集中性质）提供了全面的解决方案，填补了t>1情况下的研究空白。

> **ai_Abstract:** 本文系统研究了固定长度突发Levenshtein球，其中删除和插入操作是连续发生的。针对这一在组合编码理论中具有挑战性且t>1情况未被充分研究的领域，论文提供了关于此类球的明确基数公式、极值界（最小和最大尺寸）、期望大小及其集中性质的综合解决方案，填补了现有研究的空白。

> **摘要翻译:** 考虑一个长度为n的q元序列$m{x}$。半径为t的固定长度Levenshtein球$	ext{L}_t(m{x})$包含所有可以通过对$m{x}$执行t次删除后t次插入而得到的长度为n的q元序列。分析这些球的大小和结构在组合编码理论中提出了重大挑战。最近的研究已成功地描述了单次删除和单次插入情况下的固定长度Levenshtein球。这些工作推导出了各种关键指标的明确公式，包括球的精确大小、极值界（最小和最大尺寸），以及期望大小及其集中性质。然而，涉及任意数量的t次删除和t次插入（t>1）的普遍情况在很大程度上仍未得到研究。这项工作系统地检查了具有多次删除和插入的固定长度Levenshtein球，特别关注固定长度突发Levenshtein球，其中删除和插入是连续发生的。我们为明确的基数公式、极值界（最小和最大尺寸）、期望大小及其围绕期望值的集中性质提供了综合解决方案。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

### [188] [Hybrid Beamforming Optimization for MIMO ISAC Exploiting Prior Information: A PCRB-based Approach](https://arxiv.org/abs/2506.07869)
> *利用先验信息的多输入多输出综合感知与通信混合波束成形优化：一种基于PCRB的方法*

*Yizhuo Wang, Shuowen Zhang* | **Main category: cs.IT**

**Keywords:** MIMO ISAC, 混合波束成形, PCRB, 交替优化, 射频链

**Comment:** submitted for possible journal publication

> **TL;DR:** 本文提出了一种基于PCRB的混合波束成形优化方法，用于MIMO ISAC系统，旨在最小化感知误差并满足通信速率要求，同时揭示了RF链的影响和性能权衡。

**AI_Comments:** 该论文为MIMO ISAC系统提供了一个基于PCRB的混合波束成形优化框架，对ISAC的实际部署具有重要意义。对射频链影响和PCRB-速率权衡的分析为系统设计提供了宝贵的见解。交替优化和凸逼近方法的使用使得所提出的解决方案具有可操作性。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为多输入多输出（MIMO）综合感知与通信（ISAC）系统优化混合波束成形，以在满足通信速率要求的同时，提高感知性能（最小化后验克拉美-劳界PCRB），特别是在目标位置未知但有先验分布信息的情况下。

**Method:** 该研究通过推导均方误差的后验克拉美-劳界（PCRB）来表征感知性能。它研究了联合发射混合波束成形和接收模拟波束成形优化，以在满足通信速率要求的情况下最小化PCRB。首先，针对纯感知系统，推导了最小化PCRB的发射/接收模拟波束成形矩阵中每个元素的闭式最优解。然后，开发了一种基于交替优化（AO）的算法。接着，针对窄带MIMO ISAC系统，通过利用加权最小均方误差和可行点追踪逐次凸逼近方法，设计了一种高效的基于AO的混合波束成形算法。最后，将窄带系统的结果扩展到MIMO正交频分复用（OFDM）ISAC系统。

**Result:** 数值结果验证了所提出混合波束成形设计的有效性。研究发现，接收射频链的数量对感知性能的影响比发射射频链更显著。在基站总收发射频链预算给定的情况下，由于非平凡的PCRB-速率权衡，最优发射射频链数量会随着通信速率目标的增加而增加。

**Conclusion:** 本文提出的混合波束成形优化方法能有效提升MIMO ISAC系统的感知性能，同时兼顾通信速率要求，并揭示了接收射频链的关键作用以及PCRB-速率之间的权衡关系。

> **ai_Abstract:** 本文提出了一种基于后验克拉美-劳界（PCRB）的混合波束成形优化方法，用于多输入多输出（MIMO）综合感知与通信（ISAC）系统。该方法联合优化发射混合波束成形和接收模拟波束成形，以在满足通信速率要求的同时最小化感知性能的PCRB。论文针对纯感知场景推导了闭式解，并为窄带和OFDM ISAC系统开发了基于交替优化（AO）的算法。数值结果验证了所提设计的有效性，并揭示了接收射频链对感知性能的影响大于发射射频链，且在给定射频链预算下，最优发射射频链数量会随通信速率目标的增加而增加，这归因于非平凡的PCRB-速率权衡。

> **摘要翻译:** 本文考虑了一个多输入多输出（MIMO）综合感知与通信（ISAC）系统，其中一个带有收发混合模拟-数字阵列的多天线基站（BS）发送双功能信号，与多天线用户进行通信，并同时根据反射回波信号和目标位置的先验分布信息感知目标的未知随机位置信息。在收发混合阵列下，我们通过推导均方误差的后验克拉美-劳界（PCRB）来表征感知性能，该PCRB是发射混合波束成形和接收模拟波束成形的函数。我们研究了联合发射混合波束成形和接收模拟波束成形优化，以在满足通信速率要求的情况下最小化PCRB。我们首先考虑一个纯感知系统，并推导出最小化PCRB的发射/接收模拟波束成形矩阵中每个元素的闭式最优解。然后，我们开发了一种基于交替优化（AO）的算法。接下来，我们研究了一个窄带MIMO ISAC系统，并通过利用加权最小均方误差和可行点追踪逐次凸逼近方法，设计了一种高效的基于AO的混合波束成形算法。此外，我们将窄带系统的结果扩展到MIMO正交频分复用（OFDM）ISAC系统。数值结果验证了我们提出的混合波束成形设计的有效性。结果表明，接收射频链的数量对感知性能的影响比发射射频链更显著。在给定基站总收发射频链预算的情况下，随着通信速率目标的增加，最优发射射频链数量会增加，这归因于非平凡的PCRB-速率权衡。

</details>

[⬆️ 返回分类顶部](#csit) | [⬆️ 返回总目录](#toc)

---

<a id='csar'></a>
## cs.AR 

### [16] [Design and Implementation of a RISC-V SoC with Custom DSP Accelerators for Edge Computing](https://arxiv.org/abs/2506.06693)
> *面向边缘计算的RISC-V SoC及定制DSP加速器设计与实现*

*Priyanshu Yadav* | **Main category: cs.AR**

**Keywords:** RISC-V, 边缘计算, DSP加速器, SoC, 功耗效率

**Comment:** 12 Pages, 1 figure

> **TL;DR:** 本文分析了RISC-V指令集架构的模块化设计、性能和功耗效率，展示了其在嵌入式系统和定制加速器中的优势，并显示相比ARM Cortex-M0功耗降低17%。

**AI_Comments:** 该论文的创新之处在于展示了RISC-V在边缘计算领域的实际优势，特别是其功耗效率和对定制DSP加速器的灵活性，这对于资源受限的边缘设备至关重要。与ARM Cortex-M0的对比分析为RISC-V的竞争力提供了有力证据。

<details>
  <summary>Details</summary>

**Motivation:** 旨在全面分析RISC-V指令集架构，重点关注其模块化设计、实现挑战和性能特征，以证明其在嵌入式系统中的优势以及对定制加速器的可扩展性，尤其适用于边缘计算。

**Method:** 研究人员对RISC-V指令集架构（RV32I及M、A扩展）进行了全面分析。他们通过对流水线实现的周期精确仿真，评估了CPI和功耗效率等性能指标，并与ARM Cortex-M0进行了比较分析。

**Result:** 研究结果表明RISC-V在嵌入式系统和定制加速器方面具有优势和可扩展性。与类似工艺节点中的ARM Cortex-M0实现相比，功耗降低了17%。

**Conclusion:** RISC-V是一种适合嵌入式系统和定制加速器的灵活开放标准架构，为边缘计算应用提供了显著的功耗效率优势。

> **ai_Abstract:** 本文通过对RISC-V指令集架构（特别是带有M和A扩展的RV32I）进行周期精确仿真分析，评估了其性能指标和功耗效率。研究结果展示了RISC-V在嵌入式系统中的优势及其对定制加速器的可扩展性。与ARM Cortex-M0的比较分析显示，RISC-V的功耗降低了17%，突出了其在边缘计算领域进行特定领域优化的灵活性。

> **摘要翻译:** 本文对RISC-V指令集架构进行了全面分析，重点关注其模块化设计、实现挑战和性能特征。我们研究了带有乘法(M)和原子操作(A)扩展的RV32I基本指令集。通过对流水线实现的周期精确仿真，我们评估了包括CPI(每指令周期)和功耗效率在内的性能指标。我们的结果表明RISC-V在嵌入式系统中的优势及其对定制加速器的可扩展性。比较分析显示，与类似工艺节点中的ARM Cortex-M0实现相比，功耗降低了17%。RISC-V的开放标准性质为领域特定优化提供了显著的灵活性。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [30] [Containerized In-Storage Processing and Computing-Enabled SSD Disaggregation](https://arxiv.org/abs/2506.06769)
> *容器化存储内处理与计算赋能的SSD解耦*

*Miryeong Kwon, Donghyun Gouk, Eunjee Na, Jiseon Kim, Junhee Kim, Hyein Woo, Eojin Ryu, Hyunkyu Choi, Jinwoo Baek, Hanyeoreum Bae, Mahmut Kandemir, Myoungsoo Jung* | **Main category: cs.AR**

**Keywords:** 存储内处理, SSD, 容器化, 解耦, DockerSSD

**Comment:** 

> **TL;DR:** DockerSSD通过在SSD上直接实现容器化数据处理来解决存储内处理的挑战，显著提升I/O密集型工作负载和分布式LLM推理的性能。

**AI_Comments:** 该论文通过将容器化技术引入SSD的存储内处理，提供了一种新颖且高效的解决方案，有效解决了数据传输和解耦的挑战。其对大型语言模型推理性能的显著提升，预示着其在未来AI和大数据应用中的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 存储内处理（ISP）虽然能最小化数据传输，但在适应性和解耦方面面临挑战。

**Method:** 本文提出了DockerSSD，一个利用操作系统级虚拟化和轻量级固件在SSD上直接实现容器化数据处理的ISP模型。其关键特性包括用于网络化ISP管理的以太网 over NVMe，以及用于安全高效容器执行的虚拟固件。DockerSSD支持解耦存储池。

**Result:** DockerSSD在I/O密集型工作负载中实现了高达2.0倍的性能提升，在分布式LLM推理中实现了7.9倍的性能改进。

**Conclusion:** DockerSSD通过在SSD上实现容器化存储内处理，成功解决了现有ISP的挑战，并显著提升了I/O密集型和分布式LLM推理等大型服务的性能，同时减少了主机开销。

> **ai_Abstract:** 本文提出DockerSSD，一种创新的存储内处理（ISP）模型，通过利用操作系统级虚拟化和轻量级固件，直接在SSD上实现容器化数据处理。该系统通过以太网 over NVMe实现网络管理，并使用虚拟固件确保容器执行的安全高效。DockerSSD支持解耦存储池，有效降低主机开销，并显著提升了I/O密集型工作负载（最高2.0倍）和分布式大型语言模型（LLM）推理（最高7.9倍）的性能。

> **摘要翻译:** ISP最大限度地减少了分析的数据传输，但在适应性和解耦方面面临挑战。我们提出了DockerSSD，这是一种ISP模型，利用操作系统级虚拟化和轻量级固件，直接在SSD上实现容器化数据处理。主要特点包括用于基于网络的ISP管理的以太网 over NVMe，以及用于安全高效容器执行的虚拟固件。DockerSSD支持解耦存储池，减少了主机开销，并增强了LLM推理等大规模服务。它在I/O密集型工作负载中实现了高达2.0倍的性能提升，在分布式LLM推理中实现了7.9倍的改进。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [44] [Taming Wild Branches: Overcoming Hard-to-Predict Branches using the Bullseye Predictor](https://arxiv.org/abs/2506.06773)
> *驯服“狂野”分支：使用Bullseye预测器克服难以预测的分支*

*Emet Behrendt, Shing Wai Pun, Prashant J. Nair* | **Main category: cs.AR**

**Keywords:** 分支预测, 难以预测分支, Bullseye预测器, TAGE-SC-L, 感知器

**Comment:** Paper accepted and presented at the 6th Championship Branch
  Prediction (CBP) workshop, co-held with ISCA 2025, on June 21, 2025, Tokyo,
  Japan

> **TL;DR:** 本文提出了Bullseye预测器，通过专门针对难以预测的分支来改进分支预测，从而实现比TAGE-SC-L更好的准确性。

**AI_Comments:** 本文的创新之处在于其专门针对难以预测分支的策略，通过引入HIT、感知器、试验阶段和更新抑制等机制，有效解决了通用预测器难以处理的“尾部”问题。这对于提升现代CPU架构的性能至关重要，因为它能显著减少分支误预测这一关键性能瓶颈。

<details>
  <summary>Details</summary>

**Motivation:** 乱序处理器的分支预测性能关键，但CBP-2016获胜者TAGE-SC-L等现有分支预测器仍有超过一半的误预测源于一小部分难以预测（H2P）的分支。这些分支在多样化的全局历史下发生，导致TAGE中反复抖动并被逐出，简单地扩大表只能带来微小的改进。

**Method:** 作者用一个28 KB的H2P目标子系统，即Bullseye预测器，增强了159 KB的TAGE-SC-L预测器。它使用一个组相联的H2P识别表（HIT）来识别有问题的分支PC，并将其引导到两个分支特定的感知器之一。一个短暂的试验阶段在H2P缓存中跟踪一对一的准确性。只有当感知器的持续准确性和输出幅度超过动态阈值时，分支才成为感知器驻留，此后该PC的TAGE更新被抑制以减少污染。HIT、缓存和感知器与TAGE-SC-L完全并行运行。

**Result:** 该方法实现了平均MPKI为3.4045和CycWpPKI为145.09。

**Conclusion:** Bullseye预测器通过补充现有预测器，有效解决了难以预测分支的挑战，显著提高了整体分支预测的准确性和性能。

> **ai_Abstract:** 本文旨在解决现有最先进分支预测器（如TAGE-SC-L）中难以预测（H2P）分支导致的误预测问题。作者提出了Bullseye预测器，这是一个28 KB的H2P目标子系统，用于增强TAGE-SC-L。Bullseye通过识别表（HIT）识别H2P分支，并将其引导至专门的感知器。它采用试验阶段和动态阈值来确保高准确性，并抑制这些分支的TAGE更新，同时与TAGE-SC-L并行操作。这种方法显著减少了误预测，提高了MPKI和CycWpPKI指标。

> **摘要翻译:** 分支预测是乱序处理器性能的关键。虽然CBP-2016的获胜者TAGE-SC-L结合了几何历史表、一个统计校正器和一个循环预测器，但其剩余的误预测中超过一半源于一小部分难以预测（H2P）的分支。这些分支在不同的全局历史下出现，导致TAGE中反复抖动并在有用性计数器成熟之前被逐出。先前的研究表明，简单地扩大表只能带来微小的改进。
我们用一个28 KB的H2P目标子系统（称为Bullseye预测器）增强了一个159 KB的TAGE-SC-L预测器。它使用一个组相联的H2P识别表（HIT）来识别有问题的分支PC，并将其引导到两个分支特定的感知器之一，一个由哈希局部历史索引，另一个由折叠全局历史索引。一个短暂的试验阶段在H2P缓存中跟踪一对一的准确性。只有当感知器的持续准确性和输出幅度超过动态阈值时，分支才成为感知器驻留，此后该PC的TAGE更新被抑制以减少污染。HIT、缓存和感知器与TAGE-SC-L完全并行运行，为H2P尾部提供更高的保真度。这实现了平均MPKI为3.4045和CycWpPKI为145.09。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [59] [ASPO: Constraint-Aware Bayesian Optimization for FPGA-based Soft Processors](https://arxiv.org/abs/2506.06817)
> *ASPO：面向FPGA软处理器的约束感知贝叶斯优化*

*Haoran Wu, Ce Guo, Wayne Luk, Robert Mullins* | **Main category: cs.AR**

**Keywords:** 贝叶斯优化, FPGA, 软处理器, 约束感知, 设计自动化

**Comment:** Accepted to International Conference on Field-Programmable Logic and
  Applications (FPL) 2025

> **TL;DR:** ASPO是一种定制的贝叶斯优化方法，专为FPGA软处理器设计，能处理分类约束并加速评估，显著提升执行和设计效率。

**AI_Comments:** ASPO的创新之处在于它首次为FPGA软处理器设计定制了贝叶斯优化的数学机制，特别是在处理分类参数和加速评估过程方面。这对于提高复杂硬件设计的自动化优化效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 标准贝叶斯优化（BO）不擅长处理分类参数约束，且其优化时间随处理器复杂性增加而显著增长，尤其对于FPGA软处理器而言，这成为一个重要挑战。

**Method:** ASPO通过利用析取形式和定制的BO协方差核来支持分类参数。它通过对BO采集函数施加潜在评估时间惩罚并重用先前评估配置的FPGA综合检查点来加速设计评估过程。该方法针对RocketChip、BOOM和EL2 VeeR三种软处理器，并基于七个RISC-V基准进行评估。

**Result:** ASPO在BOOM处理器上，将“乘法”基准的执行时间比默认配置减少了高达35%。与最先进的面向硬件的BO方法Boomerang相比，它将BOOM处理器的设计时间减少了高达74%。

**Conclusion:** ASPO通过处理分类约束和加速设计评估，有效解决了FPGA软处理器优化所面临的挑战，从而显著提升了性能和缩短了设计时间。

> **ai_Abstract:** 本文提出ASPO，一种针对FPGA软处理器的约束感知贝叶斯优化方法。ASPO通过定制的协方差核处理分类参数约束，并利用评估时间惩罚和综合检查点复用加速设计评估。实验结果表明，ASPO在BOOM处理器上显著减少了执行时间和设计时间，分别达到35%和74%的提升，优于现有方法。

> **摘要翻译:** 贝叶斯优化（BO）在调整处理器设计参数方面已显示出潜力。然而，标准BO不支持涉及分类参数的约束，例如分支预测器和除法电路的类型。此外，BO的优化时间随处理器复杂性而增长，这对于基于FPGA的软处理器而言变得越来越重要。本文介绍了ASPO，一种利用析取形式使BO能够处理涉及分类参数的约束的方法。与直接应用标准BO的现有方法不同，所提出的ASPO方法首次定制了BO的数学机制，以解决FPGA上软处理器设计面临的挑战。具体来说，ASPO使用新颖的定制BO协方差核来支持分类参数。它还通过对BO采集函数施加潜在评估时间惩罚并重用先前评估配置的FPGA综合检查点来加速设计评估过程。ASPO针对三种软处理器：RocketChip、BOOM和EL2 VeeR。该方法基于七个RISC-V基准进行评估。结果表明，与默认配置相比，ASPO可以将BOOM处理器上“乘法”基准的执行时间缩短高达35%。此外，与最先进的面向硬件的BO方法Boomerang相比，它将BOOM处理器的设计时间缩短了高达74%。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [74] [QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine](https://arxiv.org/abs/2506.07046)
> *QForce-RL：量化FPGA优化的强化学习计算引擎*

*Anushka Jha, Tanushree Dewangan, Mukul Lokhande, Santosh Kumar Vishvakarma* | **Main category: cs.AR**

**Keywords:** 强化学习, FPGA, 量化, 硬件加速, QForce-RL

**Comment:** 

> **TL;DR:** QForce-RL提出了一种量化和轻量级的强化学习架构，用于在FPGA上实现高效部署，性能提升显著。

**AI_Comments:** QForce-RL的创新在于将量化技术应用于FPGA上的强化学习部署，有效解决了资源消耗大的痛点。其轻量级架构和对现有优化方案的整合（如E2HRL和QuaRL）使其在保持性能的同时，实现了显著的能效和吞吐量提升，对于边缘设备上的RL部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 强化学习（RL）在序列决策和动态环境控制中表现出色，但其在FPGA上的部署资源消耗巨大，尤其是在训练高质量图像的智能体时面临大量计算挑战。

**Method:** QForce-RL通过利用量化技术和轻量级RL架构来提高吞吐量并降低能耗，同时保持性能。它借鉴了E2HRL来减少RL动作以学习期望策略，并利用QuaRL进行基于量化的SIMD硬件加速。

**Result:** QForce-RL的性能提升高达2.3倍，帧率（FPS）比现有最先进（SoTA）作品高2.6倍。

**Conclusion:** QForce-RL提供了一种可扩展且参数化高效的部署方案，适用于资源受限设备，并在延迟、吞吐量、功耗和能效方面具有灵活性。

> **ai_Abstract:** 本论文提出了QForce-RL，一个量化且FPGA优化的强化学习计算引擎，旨在解决RL在FPGA部署中面临的资源消耗和计算挑战。QForce-RL通过结合量化技术和轻量级架构，以及借鉴E2HRL和QuaRL的优势，显著提高了吞吐量并降低了能耗，同时保持了高性能。该架构具有可扩展性，适用于资源受限设备，并提供了灵活的部署选项。实验结果显示，QForce-RL在性能上提升高达2.3倍，FPS提高2.6倍。

> **摘要翻译:** 强化学习（RL）在序列决策和动态环境控制方面已超越其他方法。然而，FPGA部署的资源消耗巨大，因为其涉及到使用高质量图像训练智能体的大量计算，并带来了新的挑战。在这项工作中，我们提出了QForce-RL，它利用量化技术来提高吞吐量并降低能耗，采用轻量级RL架构，而不会导致显著的性能下降。QForce-RL借鉴了E2HRL来减少整体RL动作以学习期望策略，并利用QuaRL进行基于量化的SIMD硬件加速。我们还对不同的RL环境进行了详细分析，重点关注模型大小、参数和加速计算操作。该架构可扩展到资源受限设备，并提供参数化的有效部署，在延迟、吞吐量、功耗和能效方面具有灵活性。所提出的QForce-RL与现有最先进（SoTA）作品相比，性能提升高达2.3倍，帧率（FPS）提高2.6倍。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [88] [MAGNet: A Multi-Scale Attention-Guided Graph Fusion Network for DRC Violation Detection](https://arxiv.org/abs/2506.07126)
> *MAGNet: 一种用于DRC违规检测的多尺度注意力引导图融合网络*

*Weihan Lu, Hong Cai Chen* | **Main category: cs.AR**

**Keywords:** DRC违规检测, 深度学习, 图神经网络, U-Net, 混合模型

**Comment:** 9 pages, 12 figures, 2 tables

> **TL;DR:** MAGNet是一种混合深度学习模型，结合了改进的U-Net和图神经网络，用于提高集成电路设计中DRC违规检测的准确性并降低误报率。

**AI_Comments:** MAGNet的创新点在于其混合架构，将卷积神经网络（U-Net）的空间特征提取能力与图神经网络的拓扑关系建模能力相结合。这种融合对于处理复杂的芯片布局数据非常有效，特别是考虑到DRC违规的稀疏性和多尺度性质。此外，动态注意力模块、多尺度卷积模块和标签放大策略是模型性能提升的关键。该研究对于提高IC设计的自动化和效率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 设计规则检查（DRC）对于集成电路（IC）设计的成本降低和设计效率提高具有重要意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。

**Method:** 本文提出了MAGNet，一个混合深度学习模型，它将改进的U-Net与图神经网络（GNN）相结合，用于DRC违规预测。U-Net骨干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）进行增强，以提取细粒度和多尺度空间特征。同时，基于芯片布局瓦片构建像素对齐的图结构，并应用专门的GNN来建模引脚之间的拓扑关系。在图构建过程中，生成图到网格的映射以将GNN特征与布局图像对齐。此外，训练期间采用标签放大策略，以增强模型对稀疏违规模式的敏感性。随后，通过增量训练，实现了对热点更敏感的判别能力。

**Result:** MAGNet有效结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。与ibUnet、RouteNet和J-Net相比，MAGNet显著优于这些模型，在整体性能上取得了实质性改进。

**Conclusion:** MAGNet成功地将空间、语义和结构信息结合起来，显著提高了DRC违规检测的准确性和效率，并在与现有模型的比较中表现出优越的性能。

> **ai_Abstract:** 本文提出了一种名为MAGNet的混合深度学习模型，旨在提高集成电路设计中的设计规则检查（DRC）违规检测精度。MAGNet结合了改进的U-Net（通过动态注意力模块和多尺度卷积模块增强）和图神经网络（用于建模拓扑关系），并通过图到网格映射和标签放大策略优化训练。实验结果表明，MAGNet在预测准确性和降低误报率方面优于现有模型，有效整合了空间、语义和结构信息。

> **摘要翻译:** 设计规则检查（DRC）对于集成电路（IC）设计的成本降低和设计效率提高具有重要意义。基于机器学习的DRC已成为计算机辅助设计（CAD）中的重要方法。在本文中，我们提出了MAGNet，一个混合深度学习模型，它将改进的U-Net与图神经网络相结合，用于DRC违规预测。U-Net骨干通过动态注意力模块（DAM）和多尺度卷积模块（MSCM）进行增强，以加强其提取细粒度和多尺度空间特征的能力。同时，我们基于芯片布局瓦片构建了一个像素对齐的图结构，并应用了一个专门的GNN来建模引脚之间的拓扑关系。在图构建过程中，生成了一个图到网格的映射，以将GNN特征与布局图像对齐。此外，在训练期间采用了一种标签放大策略，以增强模型对稀疏违规模式的敏感性。总体而言，MAGNet有效地结合了空间、语义和结构信息，在DRC热点检测中实现了更高的预测准确性和更低的误报率。随后，通过增量训练，我们实现了对热点更敏感的判别能力。结果表明，与ibUnet、RouteNet和J-Net相比，MAGNet显著优于这些模型，在整体性能上取得了实质性改进。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [101] [VeriLoC: Line-of-Code Level Prediction of Hardware Design Quality from Verilog Code](https://arxiv.org/abs/2506.07239)
> *VeriLoC：基于Verilog代码的硬件设计质量行级别预测*

*Raghu Vamshi Hemadri, Jitendra Bhandari, Johann Knechtel, Badri P Gopalan, Ramesh Narayanaswamy, Ramesh Karri, Siddharth Garg* | **Main category: cs.AR**

**Keywords:** 硬件设计质量, Verilog, 行级别预测, LLM, 时序拥塞

**Comment:** 

> **TL;DR:** VeriLoC首次实现了从Verilog代码对硬件设计质量（如时序和布线拥塞）进行行级别和模块级别的预测，显著提高了预测精度。

**AI_Comments:** VeriLoC的创新之处在于首次将LLM应用于Verilog代码的行级别质量预测，解决了现有方法无法深入到代码行层面的局限。其显著的性能提升预示着在复杂硬件设计早期阶段发现潜在问题、提高设计效率的巨大潜力，对硬件设计自动化领域具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代芯片设计复杂，急需从Verilog代码早期预测关键设计质量指标，尤其是预测导致时序违规或布线拥塞的单个代码行。现有工作未考虑行级别预测。

**Method:** 提出VeriLoC，利用Verilog代码生成LLM提取局部行级别和模块级别嵌入，并训练下游分类器/回归器。

**Result:** VeriLoC在行级别拥塞和时序预测上取得了0.86-0.95的高F1分数，并将SOTA方法的平均百分比误差从14%-18%降低到仅4%。

**Conclusion:** VeriLoC的嵌入和研究成果对于复杂硬件设计的其他预测和优化任务也具有价值。

> **ai_Abstract:** 本文提出了VeriLoC，一种创新的方法，首次实现了从Verilog代码对硬件设计质量（包括时序和布线拥塞）进行行级别和模块级别的预测。该方法利用Verilog代码生成大型语言模型（LLM）来提取代码嵌入，并训练分类器/回归器进行预测。实验结果显示，VeriLoC在行级别预测上F1分数高达0.86-0.95，并将平均百分比误差从14%-18%显著降低至4%，表明其在早期硬件设计质量预测方面的卓越性能。

> **摘要翻译:** 现代芯片设计复杂，迫切需要在早期阶段直接从Verilog代码（一种常用的硬件设计编程语言）预测关键设计质量指标，如时序和布线拥塞。预测导致时序违规或下游布线拥塞的单个代码行尤其重要且复杂。以往的工作尝试了将Verilog转换为中间图表示，并使用LLM嵌入以及其他特征来预测模块级质量，但没有考虑行级质量预测。我们提出了VeriLoC，这是第一个直接从Verilog在行级和模块级预测设计质量的方法。为此，VeriLoC利用最近的Verilog代码生成LLM来提取局部行级和模块级嵌入，并在这些嵌入的串联上训练下游分类器/回归器。VeriLoC在行级拥塞和时序预测方面取得了0.86-0.95的高F1分数，并将SOTA方法的平均百分比误差从14%-18%降低到仅4%。我们相信VeriLoC的嵌入和我们工作的见解对于复杂硬件设计的其他预测和优化任务也具有价值。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [114] [A Survey on LUT-based Deep Neural Networks Implemented in FPGAs](https://arxiv.org/abs/2506.07367)
> *基于查找表（LUT）的FPGA深度神经网络实现综述*

*Zeyu Guo* | **Main category: cs.AR**

**Keywords:** FPGA, 深度神经网络, 查找表, 边缘计算, 硬件加速

**Comment:** 

> **TL;DR:** 这篇综述探讨了在FPGA中实现基于查找表的深度神经网络，以解决边缘应用中传统方法的延迟和可扩展性问题，并概述了未来的研究方向。

**AI_Comments:** 这篇综述的重要性在于它识别并系统地分析了一种解决FPGA上深度神经网络实现瓶颈的关键技术——基于LUT的计算。通过摆脱对DSP块的过度依赖，基于LUT的DNN为边缘AI应用提供了更高的资源利用率和更低的延迟，这对于推动FPGA在AI加速领域的应用至关重要。该综述不仅总结了现有技术，还指明了未来的研究方向，具有很高的指导价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的云端深度神经网络部署在边缘应用中存在高延迟和安全风险。FPGA提供了一个平衡的解决方案，但传统的FPGA深度神经网络严重依赖DSP块进行MAC操作，限制了可扩展性。

**Method:** 这篇综述通过全面回顾基于查找表的深度神经网络架构，包括其演变、设计方法和性能权衡，来解决上述挑战。

**Result:** 综述提供了基于查找表的深度神经网络架构的全面回顾，涵盖了它们的演变、设计方法和性能权衡。

**Conclusion:** 文章概述了未来研究的有前景方向。

> **ai_Abstract:** 本综述关注在FPGA中实现低延迟、高能效的深度神经网络推理，以满足边缘应用的需求。针对传统FPGA深度神经网络依赖DSP块导致可扩展性受限的问题，文章探讨了基于查找表（LUT）的深度神经网络，该方法通过充分利用FPGA的查找表进行计算，提高了资源利用率并降低了推理延迟。该综述全面回顾了基于LUT的深度神经网络架构，包括其演变、设计方法和性能权衡，并指出了未来研究方向。

> **摘要翻译:** 低延迟、高能效的深度神经网络（DNN）推理对于边缘应用至关重要，而传统的基于云的部署存在高延迟和安全风险。现场可编程门阵列（FPGA）提供了一个引人注目的解决方案，平衡了可重构性、能效和实时性能。然而，传统的基于FPGA的DNN严重依赖数字信号处理（DSP）块进行乘积累加（MAC）操作，从而限制了可扩展性。
基于查找表（LUT）的DNN通过充分利用FPGA查找表进行计算来解决这一挑战，从而提高资源利用率并降低推理延迟。本综述全面回顾了基于查找表的DNN架构，包括其演变、设计方法和性能权衡，同时概述了未来研究的有前景方向。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [128] [FREESS: An Educational Simulator of a RISC-V-Inspired Superscalar Processor Based on Tomasulo's Algorithm](https://arxiv.org/abs/2506.07665)
> *FREESS：一个基于Tomasulo算法的RISC-V启发式超标量处理器教育模拟器*

*Roberto Giorgi* | **Main category: cs.AR**

**Keywords:** RISC-V, 超标量处理器, Tomasulo算法, 教育模拟器, 指令级并行

**Comment:** WCAE'25 - Workshop on Computer Architecture Education, June 21--25,
  2025, Tokyo, Japan

> **TL;DR:** FREESS是一个免费、交互式的教育模拟器，用于演示基于Tomasulo算法的RISC-V超标量处理器中的指令级并行。

**AI_Comments:** FREESS的创新之处在于它提供了一个免费、交互式且开源的平台，将复杂的超标量处理器乱序执行概念可视化，极大地降低了学生理解这些抽象概念的门槛。其基于Tomasulo算法的实现和可配置的参数使其成为一个非常灵活和实用的教育工具。作为开源项目，它也鼓励了更深层次的学习和实验。

<details>
  <summary>Details</summary>

**Motivation:** FREESS旨在作为高级计算机体系结构课程的实践教育工具，帮助学生探索动态、乱序指令执行，并理解指令如何在其操作数可用时立即发出。

**Method:** FREESS是一个基于Tomasulo算法扩展版本的模拟器，它建模了关键的微体系结构组件，如指令窗口（IW）、重排序缓冲区（ROB）、寄存器映射（RM）、空闲池（FP）和加载/存储队列。它允许用户动态配置运行时参数，并使用受RISC-V启发的最少指令集来演示关键流水线阶段。

**Result:** FREESS使学生能够探索动态、乱序指令执行，强调指令在其操作数可用时如何发出。它能演示取指、寄存器重命名、乱序分派、执行、完成、提交、推测分支和内存访问等关键流水线阶段，并提供分步示例，视觉上展示多条指令如何在单个周期内并行发出和执行。

**Conclusion:** FREESS是一个免费、开源的教育模拟器，它通过提供实践工具和示例，鼓励学生和教育工作者自由地编写和分析自己的指令级程序和超标量架构，从而深入理解指令级并行。

> **ai_Abstract:** FREESS是一个免费、交互式的教育模拟器，旨在帮助高级计算机体系结构课程的学生理解RISC-V启发式超标量处理器中的指令级并行和乱序执行。它基于扩展的Tomasulo算法，模拟了关键的微体系结构组件，并允许动态配置参数。通过使用精简的RISC-V指令集和分步示例，FREESS清晰地演示了流水线阶段和多指令并行执行，并作为一个开源工具鼓励用户进行实验。

> **摘要翻译:** FREESS是一个免费的交互式模拟器，它演示了RISC-V启发式超标量处理器中的指令级并行。FREESS基于Tomasulo算法的扩展版本，旨在作为高级计算机体系结构课程的实践教育工具。它使学生能够探索动态、乱序指令执行，强调指令在其操作数可用时立即发出。该模拟器模拟了关键的微体系结构组件，包括指令窗口（IW）、重排序缓冲区（ROB）、寄存器映射（RM）、空闲池（FP）和加载/存储队列。FREESS允许用户动态配置运行时参数，例如超标量发射宽度、功能单元类型和延迟，以及架构缓冲区和队列的大小。为了简化学习，该模拟器使用受RISC-V启发的最少指令集（ADD、ADDI、BEQ、BNE、LW、MUL、SW），足以演示关键的流水线阶段：取指、寄存器重命名、乱序分派、执行、完成、提交、推测分支和内存访问。FREESS包含三个分步的、带图示的示例，直观地演示了如何在单个周期内并行发出和执行多条指令。作为开源项目，FREESS鼓励学生和教育工作者通过编写和分析自己的指令级程序和超标量架构来自由实验。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [141] [ProtocolLLM: RTL Benchmark for SystemVerilog Generation of Communication Protocols](https://arxiv.org/abs/2506.07945)
> *ProtocolLLM：用于通信协议SystemVerilog生成的RTL基准测试*

*Arnav Sheth, Ivaxi Sheth, Mario Fritz* | **Main category: cs.AR**

**Keywords:** LLM, SystemVerilog, HDL, 通信协议, RTL基准测试

**Comment:** Accepted at MLSysArch@ISCA 2025

> **TL;DR:** 本文引入了ProtocolLLM，一个针对SystemVerilog通信协议生成的RTL基准测试套件，旨在分析大型语言模型（LLM）在硬件描述语言（HDL）代码生成方面的能力。

**AI_Comments:** 这项工作通过引入专门的RTL基准测试套件，填补了LLM在硬件描述语言（特别是SystemVerilog）代码生成领域研究的空白。它为评估和提升LLM在硬件设计自动化中的应用奠定了基础，对于实现更高效、更可靠的硬件设计流程具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）在通用编程语言代码生成方面显示出巨大潜力，但在硬件描述语言（HDL）特别是SystemVerilog的可综合和功能正确设计生成方面的应用尚未得到充分探索。HDL对时序语义、并发性和可综合性有严格要求，且HDL设计流程包含结构代码生成之外的多种复杂任务。

**Method:** 本文引入了ProtocolLLM，这是首个针对SPI、I2C、UART和AXI四种广泛使用的通信协议的RTL基准测试套件。研究定义了捕获不同设计抽象级别和提示特异性的代码生成任务，并通过波形仿真和测试平台评估生成设计的语法正确性、可综合性和功能保真度。

**Result:** 本文介绍了针对四种广泛使用的通信协议（SPI、I2C、UART、AXI）的RTL基准测试套件ProtocolLLM，并定义了评估LLM生成SystemVerilog实现能力的代码生成任务。具体评估结果（如LLM的性能表现）未在摘要中提及。

**Conclusion:** 本文通过引入ProtocolLLM基准测试套件，为分析和评估大型语言模型在SystemVerilog通信协议生成方面的能力提供了框架，旨在推动LLM在硬件描述语言设计领域的应用。

> **ai_Abstract:** 本文旨在分析最先进的大型语言模型（LLM）在生成标准通信协议SystemVerilog实现方面的能力，这些协议是嵌入式和片上系统（SoC）架构的核心组件。为此，论文引入了ProtocolLLM，这是首个针对SPI、I2C、UART和AXI四种常用协议的RTL基准测试套件。研究定义了捕获不同设计抽象级别和提示特异性的代码生成任务，并通过波形仿真和测试平台评估了生成设计的语法正确性、可综合性和功能保真度。

> **摘要翻译:** 大型语言模型（LLM）的最新进展在通用编程语言代码生成方面展现出良好前景。相比之下，它们在硬件描述语言（HDL）方面的适用性，尤其是在生成可综合且功能正确的RTL设计方面，仍未得到充分探索。SystemVerilog等HDL是面向逻辑的，要求严格遵守时序语义、并发性和可综合性约束。此外，基于HDL的设计流程涵盖了结构代码生成之外的广泛任务，包括测试平台开发、基于断言的验证、时序收敛以及片上通信的协议级集成。本文的目标是分析最先进的LLM在生成标准通信协议的SystemVerilog实现方面的能力，这些协议是嵌入式和片上系统（SoC）架构的核心组件。本文引入了第一个针对四种广泛使用的协议（SPI、I2C、UART和AXI）的基准测试套件。我们定义了捕获不同设计抽象级别和提示特异性的代码生成任务。通过波形仿真和测试平台，评估了生成设计的语法正确性、可综合性和功能保真度。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

### [152] [Understanding the Error Sensitivity of Privacy-Aware Computing](https://arxiv.org/abs/2506.07957)
> *理解隐私感知计算的错误敏感性*

*Matías Mazzanti, Esteban Mocskos, Augusto Vega, Pradip Bose* | **Main category: cs.AR**

**Keywords:** 同态加密, 错误敏感性, CKKS, 残余数系统, 数论变换

**Comment:** 

> **TL;DR:** 同态加密（HE）在隐私保护计算中很有潜力，但其固有的错误机制和操作中的软硬件错误可能导致静默数据损坏（SDC）。本研究首次深入探讨HE应用的位错误敏感性，并详细分析了流行的CKKS方案及其优化技术（RNS和NTT）对错误敏感性的影响，为该领域的未来研究奠定基础。

**AI_Comments:** 本文首次深入研究了同态加密（HE）的错误敏感性，填补了该领域的一个重要空白。通过对流行的CKKS方案及其优化技术（RNS和NTT）的详细错误特性分析，为HE在实际应用中的鲁棒性问题提供了新的视角。这项工作对于推动HE的可靠部署和未来研究具有重要意义，尤其是在数据敏感性极高的领域。

<details>
  <summary>Details</summary>

**Motivation:** 同态加密（HE）虽然为隐私保护计算提供了巨大机会，但其依赖于噪声的机制以及运行中可能出现的软硬件错误，易导致传统错误检测和纠正机制失效，从而引发静默数据损坏（SDC）。这突显了对HE应用错误敏感性进行深入研究的必要性。

**Method:** 本研究对Cheon-Kim-Kim-Song (CKKS) 同态加密方案进行了详细的错误特性分析，并深入探讨了残余数系统（RNS）和数论变换（NTT）这两种广泛采用的HE优化技术对CKKS错误敏感性的影响。

**Result:** Not mentioned in abstract

**Conclusion:** 本研究首次探讨了同态加密的鲁棒性和错误敏感性，为该领域的未来关键工作铺平了道路。

> **ai_Abstract:** 同态加密（HE）为隐私保护计算提供了“圣杯”级的解决方案，特别是在医疗、金融等敏感数据领域。然而，HE固有的噪声机制和运行过程中的软硬件错误可能导致静默数据损坏（SDC），且难以通过传统方法检测。本文旨在深入探讨HE应用对位错误的敏感性，并首次详细分析了流行的CKKS同态加密方案的错误特性。研究还考察了残余数系统（RNS）和数论变换（NTT）这两种HE优化技术对CKKS错误敏感性的影响，为未来HE鲁棒性研究奠定了基础。

> **摘要翻译:** 同态加密（HE）使得在不解密的情况下对加密数据进行安全计算成为可能，为隐私保护计算提供了巨大机会。特别是在医疗、金融和政府等数据隐私和安全至关重要的领域，HE通过在敏感数据上实现第三方计算和服务而受益。换句话说，HE构成了密码学的“圣杯”：数据始终保持加密状态，在使用过程中受到保护。
HE的安全保障依赖于添加到数据中的噪声，以使相对简单的问题在计算上变得难以处理。这种以错误为中心的内在HE机制带来了与HE自身容错性和鲁棒性相关的新挑战：HE操作期间的硬件和软件引起的错误很容易规避传统的错误检测和纠正机制，导致静默数据损坏（SDC）。
在这项工作中，我们促使对HE应用对位错误的敏感性进行彻底讨论，并对CKKS（Cheon-Kim-Kim-Song）进行了详细的错误特性研究。CKKS因其对AI和机器学习应用的定点算术支持而成为最流行的HE方案之一。我们还深入探讨了残余数系统（RNS）和数论变换（NTT）这两种广泛采用的HE优化技术对CKKS错误敏感性的影响。据我们所知，这是首次研究同态加密的鲁棒性和错误敏感性，因此，它可以为该领域的未来关键工作铺平道路。

</details>

[⬆️ 返回分类顶部](#csar) | [⬆️ 返回总目录](#toc)

---

<a id='csdc'></a>
## cs.DC 

### [19] [Generating representative macrobenchmark microservice systems from distributed traces with Palette](https://arxiv.org/abs/2506.06448)
> *使用Palette从分布式跟踪生成代表性宏基准微服务系统*

*Vaastav Anand, Matheus Stolet, Jonathan Mace, Antoine Kaufmann* | **Main category: cs.DC**

**Keywords:** 微服务, 分布式跟踪, 宏基准测试, 图形因果模型, 系统生成

**Comment:** 

> **TL;DR:** Palette系统利用大型互联网公司的分布式跟踪数据，通过图形因果模型抽象系统拓扑，生成代表性宏基准微服务系统，以解决研究人员和从业者缺乏代表性评估系统的问题。

**AI_Comments:** 这篇论文提出了一种创新方法，通过利用实际分布式跟踪数据来生成代表性微服务宏基准系统，解决了当前微服务研究和实践中评估环境不具代表性的痛点。其核心创新在于使用图形因果模型（GCMs）来抽象和建模复杂的系统拓扑，这使得生成的基准系统能更好地反映真实世界的行为模式。如果该方法能够有效且广泛地应用，将极大地推动微服务领域的研究和开发。

<details>
  <summary>Details</summary>

**Motivation:** 微服务系统在评估其进展时需要代表性系统（具有匹配的规模、拓扑和执行模式），但研究人员和从业者通常无法获得此类系统，只能使用次优的非代表性替代方案，如小型、过度简化的合成基准系统或模拟模型。

**Method:** 提出使用来自大型互联网公司的分布式跟踪数据集来生成代表性微服务系统。引入了一种新颖的系统拓扑抽象，该抽象使用图形因果模型（GCMs）来建模底层系统，其中包含分支概率、对外调用执行顺序和执行时间。然后将此拓扑整合到Palette系统中，该系统能够从分布式跟踪生成代表性灵活的宏基准微服务系统。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 该论文旨在解决微服务系统评估中缺乏代表性系统的问题。作者提出利用大型互联网公司提供的分布式跟踪数据集来生成此类系统。为此，他们引入了一种基于图形因果模型（GCMs）的新颖系统拓扑抽象，该模型能够捕捉系统中的分支概率、调用执行顺序和执行时间。最终，该拓扑被集成到名为Palette的系统中，该系统能够根据分布式跟踪数据生成代表性的、灵活的宏基准微服务系统。

> **摘要翻译:** 微服务是当今开发云系统的主导设计。微服务的进步需要在具有代表性的系统中进行评估，例如具有匹配的规模、拓扑和执行模式的系统。不幸的是，在实践中，研究人员和从业者往往无法获得代表性系统。因此，他们不得不求助于次优的非代表性替代方案，例如小型且过度简化的合成基准系统或模拟系统模型。
为了解决这个问题，我们建议使用大型互联网公司提供的分布式跟踪数据集来生成代表性微服务系统。为此，我们引入了一种新颖的系统拓扑抽象，该抽象使用图形因果模型（GCMs）来建模底层系统，其中包含分支概率、对外调用执行顺序和执行时间。然后，我们将此拓扑整合到Palette中，Palette是一个从分布式跟踪生成代表性灵活宏基准微服务系统的系统。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [33] [Performance Impact of Containerized METADOCK 2 on Heterogeneous Platforms](https://arxiv.org/abs/2506.06450)
> *容器化METADOCK 2在异构平台上的性能影响*

*Antonio Jesús Banegas-Luna, Baldomero Imbernón Tudela, Carlos Martínez-Cortés, José María Cecilia, Horacio Pérez-Sánchez* | **Main category: cs.DC**

**Keywords:** 容器化, METADOCK 2, 虚拟筛选, 高性能计算, 药物发现

**Comment:** 20 pages, 5 figures, 2 tables

> **TL;DR:** 本研究评估了容器化METADOCK 2在异构HPC平台上的性能，发现容器化引入的性能开销可忽略不计，且能高效处理大型分子复合物，是虚拟筛选的强大解决方案。

**AI_Comments:** 这项研究的重要性在于它验证了容器化技术在高通量计算密集型科学应用中的可行性和高效性。通过展示极低的性能开销，并突出其在处理大型分子复合物方面的优势，该研究为药物发现等领域推广容器化工作流提供了有力证据，极大地提升了计算实验的可移植性和可重复性。

<details>
  <summary>Details</summary>

**Motivation:** 虚拟筛选（VS）是药物发现中的计算密集型过程，需要大量资源。本研究旨在评估容器化对METADOCK 2在高通量对接软件在异构高性能计算（HPC）平台上部署时的性能影响。

**Method:** 本研究通过在不同的CPU和GPU配置上测试Docker、Singularity和Apptainer三种容器化技术，评估了METADOCK 2的性能影响。

**Result:** 实验结果显示，容器化引入的性能开销可忽略不计，偏差低于1%。METADOCK 2能够高效处理大型分子复合物，超越了AutoDock Vina等商业工具的限制。容器化部署在科学计算中能确保可移植性、可重复性和可扩展性。

**Conclusion:** 容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大且高效的解决方案。

> **ai_Abstract:** 本研究评估了在高通量药物发现中，容器化METADOCK 2在异构高性能计算平台上的性能表现。实验结果显示，使用Docker、Singularity和Apptainer三种容器化技术几乎不引入性能开销（偏差低于1%），且METADOCK 2能够高效处理大型分子复合物，优于商业工具。这表明容器化部署为科学计算带来了可移植性、可重复性和可扩展性，证实容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大高效解决方案。

> **摘要翻译:** 虚拟筛选（VS）是一个计算密集型过程，对药物发现至关重要，通常需要大量资源来分析大型化学文库并预测配体-蛋白质相互作用。本研究评估了容器化对METADOCK 2（一种高通量对接软件）在异构高性能计算（HPC）平台上部署时的性能影响。通过在不同的CPU和GPU配置上测试Docker、Singularity和Apptainer三种容器化技术，实验表明容器化引入的性能开销可忽略不计，偏差低于1%。此外，METADOCK 2展示了高效处理大型分子复合物的能力，超越了AutoDock Vina等商业工具的限制。结果强调了基于容器的部署在科学计算中确保可移植性、可重复性和可扩展性的优势。本研究得出结论，容器化METADOCK 2是异构HPC平台上虚拟筛选任务的强大且高效的解决方案。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [47] [Cost-Efficient LLM Training with Lifetime-Aware Tensor Offloading via GPUDirect Storage](https://arxiv.org/abs/2506.06472)
> *成本高效的LLM训练：基于GPUDirect Storage的生命周期感知张量卸载*

*Ziqi Yuan, Haoyang Zhang, Yirui Eric Zhou, Apoorve Mohan, I-Hsin Chung, Seetharami Seelam, Jian Huang* | **Main category: cs.DC**

**Keywords:** LLM训练, 张量卸载, GPUDirect Storage, 内存扩展, TERAIO

**Comment:** 

> **TL;DR:** TERAIO是一个新的生命周期感知张量卸载框架，通过GPUDirect Storage将LLM训练中的非活跃张量卸载到SSD，显著提升了训练性能并降低了成本。

**AI_Comments:** TERAIO的创新点在于其独特的生命周期感知张量卸载策略，能够更精确地管理GPU内存和SSD之间的张量迁移。结合GPUDirect Storage实现GPU与SSD之间的直接数据传输，有效绕过了CPU瓶颈，显著提升了卸载效率和整体训练性能。这对于降低大型语言模型训练的成本和扩展其模型规模具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 观察到LLM训练迭代中，活跃张量仅占GPU内存的一小部分（平均1.7%），而大量非活跃张量通常较大且长时间不被使用，这为将张量卸载到低成本SSD提供了充足的机会，以扩展GPU内存并避免GPU训练过程停滞。

**Method:** 提出并实现了TERAIO框架，这是一个新的生命周期感知张量卸载框架，用于利用低成本PCIe SSD扩展GPU内存。TERAIO通过分析训练过程的前几次迭代来准确估计每个张量的生命周期，并生成一个优化的张量卸载/预取计划。该计划通过PyTorch集成到已编译的LLM程序中。TERAIO还包含一个运行时张量迁移引擎，通过GPUDirect Storage执行卸载/预取计划，实现GPU和SSD之间的直接张量迁移，以缓解CPU瓶颈并最大化SSD带宽利用率。

**Result:** 与ZeRO-Offload和ZeRO-Infinity等现有技术相比，TERAIO平均将各种LLM的训练性能提升了1.47倍，并达到了假设GPU内存无限的理想性能的80.7%。

**Conclusion:** TERAIO通过其生命周期感知的张量卸载策略和对GPUDirect Storage的有效利用，显著提高了大型语言模型训练的成本效益和性能，使其能够接近理想的GPU内存使用效率。

> **ai_Abstract:** 本文介绍了TERAIO，一个专为多GPU和多SSD的LLM训练设计的生命周期感知张量卸载框架。该框架利用LLM训练中活跃张量占用内存少、非活跃张量大且长时间不用的特点，通过精确估计张量生命周期并生成优化卸载/预取计划，将张量高效地迁移到低成本SSD。TERAIO通过GPUDirect Storage实现GPU与SSD间的直接数据传输，有效缓解CPU瓶颈并最大化SSD带宽。实验结果表明，TERAIO相较于现有技术，将LLM训练性能平均提升1.47倍，并达到了接近理想的性能。

> **摘要翻译:** 我们提出了一种新的生命周期感知张量卸载框架的设计和实现，用于使用低成本PCIe固态硬盘（SSD）扩展GPU内存。我们的框架TERAIO专为多GPU和多SSD的大型语言模型（LLM）训练而开发。其设计源于我们的观察：在每次LLM训练迭代中，活跃张量仅占用分配的GPU内存的一小部分（平均1.7%），而非活跃张量通常较大且长时间不被使用，这为将张量卸载/预取到/从较慢的SSD提供了充足的机会，而不会中断GPU训练过程。TERAIO通过分析训练过程的前几次迭代，准确估计每个张量的生命周期（在GPU内存中的活跃时间）。通过张量生命周期分析，TERAIO将生成一个优化的张量卸载/预取计划，并通过PyTorch将其集成到已编译的LLM程序中。TERAIO拥有一个运行时张量迁移引擎，通过GPUDirect Storage执行卸载/预取计划，从而实现GPU和SSD之间的直接张量迁移，以缓解CPU瓶颈并最大化SSD带宽利用率。与ZeRO-Offload和ZeRO-Infinity等最先进的研究相比，我们表明TERAIO平均将各种LLM的训练性能提高了1.47倍，并达到了假设GPU内存无限的理想性能的80.7%。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [62] [pFedSOP : Accelerating Training Of Personalized Federated Learning Using Second-Order Optimization](https://arxiv.org/abs/2506.07159)
> *pFedSOP：使用二阶优化加速个性化联邦学习的训练*

*Mrinmay Sen, Chalavadi Krishna Mohan* | **Main category: cs.DC**

**Keywords:** 个性化联邦学习, 二阶优化, Fisher信息矩阵, 通信效率, 梯度更新

**Comment:** 

> **TL;DR:** pFedSOP提出了一种利用二阶优化加速个性化联邦学习训练的方法，通过近似Hessian矩阵并减少通信轮次，在异构数据集上表现优于现有算法。

**AI_Comments:** pFedSOP的创新之处在于其在个性化联邦学习中成功且高效地引入了二阶优化，巧妙地通过Fisher信息矩阵近似Hessian矩阵，解决了直接使用Hessian的计算难题。这对于提升PFL的训练效率和性能具有重要意义，尤其是在数据高度异构的环境下。该方法不仅加速了训练，还减少了通信轮次，是联邦学习领域的一个重要进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有个性化联邦学习（PFL）方法存在通信轮次多、训练速度慢（由于一阶优化）以及局部计算量大等问题。二阶优化虽然具有二次收敛性，但其在PFL中的应用因Hessian矩阵及其逆的挑战而受限。

**Method:** 本文提出了pFedSOP，它首先使用基于Gompertz函数的局部与全局梯度更新之间的归一化角度计算个性化局部梯度更新，融入客户端特有的全局信息。然后，利用从该个性化梯度更新计算得到的正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新个性化模型。

**Result:** 在异构分区图像分类数据集上进行的部分客户端参与的广泛实验表明，pFedSOP优于最先进的联邦学习（FL）和个性化联邦学习（PFL）算法。

**Conclusion:** pFedSOP通过有效利用近似二阶优化，成功解决了现有PFL方法训练速度慢和通信轮次多的问题，显著提升了PFL的性能和效率。

> **ai_Abstract:** 该论文提出了pFedSOP，一种加速个性化联邦学习（PFL）训练的方法。它通过高效地利用二阶优化，克服了传统PFL中一阶优化导致的训练缓慢和通信开销大的问题。pFedSOP通过计算个性化局部梯度更新并使用正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新模型。实验证明，pFedSOP在异构数据集上优于现有FL和PFL算法，减少了通信轮次并提高了性能。

> **摘要翻译:** 个性化联邦学习（PFL）使客户端能够协同训练针对其个体目标量身定制的个性化模型，解决了传统联邦学习（FL）中因数据高度异构性导致的模型泛化挑战。然而，现有的PFL方法通常需要增加通信轮次才能达到期望的性能，这主要是由于使用线性收敛的一阶优化导致训练缓慢。此外，许多这些方法在搜索个性化局部模型期间，由于额外数据被送入模型，增加了局部计算量。解决这种缓慢训练的一个有前景的解决方案是二阶优化，它以其二次收敛性而闻名。然而，由于Hessian矩阵及其逆的挑战，将其应用于PFL具有挑战性。在本文中，我们提出了pFedSOP，它有效地在PFL中利用二阶优化，以加速个性化模型的训练并以更少的通信轮次提高性能。我们的方法首先使用基于Gompertz函数的局部和全局梯度更新之间的归一化角度计算个性化局部梯度更新，其中包含客户端特定的全局信息。然后，我们使用从该个性化梯度更新计算得到的正则化Fisher信息矩阵（FIM）作为Hessian的近似来更新个性化模型。这种基于FIM的二阶优化通过解决精确Hessian的挑战，以更少的通信轮次加速训练，并避免在搜索个性化局部模型期间将额外数据送入模型。在具有部分客户端参与的异构分区图像分类数据集上的广泛实验表明，pFedSOP优于最先进的FL和PFL算法。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [77] [Addressing tokens dynamic generation, propagation, storage and renewal to secure the GlideinWMS pilot based jobs and system](https://arxiv.org/abs/2506.07379)
> *解决令牌动态生成、传播、存储和更新以保护基于GlideinWMS试点的工作和系统*

*Bruno Moreira Coimbra, Marco Mambelli* | **Main category: cs.DC**

**Keywords:** GlideinWMS, 令牌, 安全, 凭证, 动态生成

**Comment:** 8 pages, 3 figures, for associated code, see
  https://github.com/glideinWMS/glideinwms, to be published in proceedings of
  27th International Conference on Computing in High Energy and Nuclear Physics
  (CHEP 2024). 21-25 October 2024. Krakow,; Poland. (C24-10-21.8)

> **TL;DR:** GlideinWMS正在演进其凭证管理系统，以应对令牌广泛采用带来的挑战，通过动态生成、范围限制和新的凭证模块来增强安全性并支持多系统使用。

**AI_Comments:** 该论文展示了GlideinWMS在应对大规模分布式计算环境中凭证管理挑战方面的积极探索。其创新点在于引入了动态凭证生成、范围限制以及多系统兼容的凭证模块设计，这对于提升系统安全性和操作灵活性具有重要意义。考虑凭证的存储、续订和失效机制也体现了对凭证生命周期管理的全面考虑。

<details>
  <summary>Details</summary>

**Motivation:** GlideinWMS从X.509向令牌的过渡带来了挑战，包括当前基础设施支持不足、更严格的要求以及更高的时间和空间粒度，迫使系统重新审视凭证的生成、使用和传播方式，以确保飞行员基础设施的安全并满足新需求。

**Method:** GlideinWMS设计了新的凭证模块，这些模块可在多个系统（如GlideinWMS、HEPCloud）中使用，并采用凭证具有类型、目的和不同流程的模型。凭证被动态生成以自定义持续时间并将范围限制到目标资源，从而强制执行最小特权原则。此外，团队还考虑在GlideinWMS基础设施中添加凭证存储、续订和失效机制。

**Result:** 新的凭证模块被设计用于多个系统（GlideinWMS，HEPCloud）。凭证的动态生成允许自定义持续时间并限制范围，从而强制执行最小特权原则。

**Conclusion:** 该论文介绍了GlideinWMS在令牌广泛采用背景下所面临的挑战以及其为保护试点基础设施和支持新需求而制定的演进计划。通过设计新的凭证模块和动态凭证管理机制，GlideinWMS旨在提高凭证的安全性、灵活性和可用性。

> **ai_Abstract:** 本文探讨了GlideinWMS从X.509向令牌过渡所面临的挑战及应对策略。为解决令牌广泛采用带来的安全和管理问题，GlideinWMS开发了新的凭证模块，支持动态生成、范围限制，并计划引入存储、续订和失效机制，以确保飞行员基础设施的安全并满足未来需求。这些新模块旨在实现最小特权原则，并可应用于多个系统。

> **摘要翻译:** GlideinWMS是WLCG社区中首批从X.509过渡到支持令牌的中间件之一。第一步是从2019年的原型到2022年投入生产使用令牌。本文将介绍令牌更广泛采用所带来的挑战，以及为保护GlideinWMS的试点基础设施和支持新需求而制定的演进计划。在过去几年中，GlideinWMS团队支持了实验和资源向令牌的迁移。当前基础设施中支持不足、更严格的要求以及更高的时间和空间粒度迫使GlideinWMS再次重新审视凭证的生成、使用和传播方式。新的凭证模块已被设计用于多个系统（GlideinWMS、HEPCloud），并使用凭证具有类型、目的和不同流程的模型。凭证被动态生成，以自定义持续时间并将范围限制到目标资源。这允许强制执行最小特权原则。最后，我们还考虑在GlideinWMS基础设施中添加凭证存储、续订和失效机制，以更好地服务实验需求。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [91] [New Limits on Distributed Quantum Advantage: Dequantizing Linear Programs](https://arxiv.org/abs/2506.07574)
> *分布式量子优势的新限制：线性程序的去量子化*

*Alkida Balliu, Corinna Coupette, Antonio Cruciani, Francesco d'Amore, Massimo Equi, Henrik Lievonen, Augusto Modanese, Dennis Olivetti, Jukka Suomela* | **Main category: cs.DC**

**Keywords:** 分布式量子优势, 线性程序, LOCAL模型, 去量子化, 局部可检查标签问题

**Comment:** 

> **TL;DR:** 本研究表明，在分布式计算的LOCAL模型中，线性程序不存在分布式量子优势，即任何量子-LOCAL算法都可以被等效的经典确定性LOCAL算法替代。此外，对于某些局部可检查标签问题（LCL），量子-LOCAL模型比经典的SLOCAL模型更弱。

**AI_Comments:** 这项研究的创新之处在于，它明确地划定了分布式量子计算在特定问题（如线性程序）上的局限性，表明并非所有问题都能从量子并行性中受益。通过“去量子化”证明，它为理解量子算法的真正优势边界提供了理论工具。此外，其在LCL问题上展示的量子-LOCAL模型弱于经典SLOCAL模型的结果，对于理解不同分布式模型的能力差异具有重要意义，挑战了量子计算普遍优于经典的直觉。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在探讨在分布式计算的LOCAL模型中，分布式量子优势的局限性。

**Method:** 研究通过证明任何线性程序的量子-LOCAL算法都可以被去量子化为具有相同近似度和通信轮次的经典、确定性LOCAL算法。在此基础上，利用这一结果证明了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。

**Result:** 1. 对于任何线性程序，不存在分布式量子优势。如果存在一个在T轮通信中找到线性优化问题$\Pi$的$\alpha$-近似的量子-LOCAL算法$\mathcal{A}$，则可以构建一个在T轮中找到$\Pi$的$\alpha$-近似的经典、确定性LOCAL算法$\mathcal{A}'$。因此，所有针对线性程序的经典下界，包括KMW界，在量子-LOCAL中也同样适用。
2. 存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。
这些结果从量子-LOCAL扩展到有限依赖和非信号分布。研究的一个推论是，在LCL问题背景下，非信号模型和SLOCAL模型是不可比较的。

**Conclusion:** 本研究为分布式量子优势设定了新的限制，尤其是在线性程序和某些局部可检查标签问题（LCL）的背景下，表明在这些情况下，经典算法的能力与量子算法相当甚至更强。

> **ai_Abstract:** 本研究在分布式计算的LOCAL模型中，对分布式量子优势提出了新的限制。核心贡献是证明了对于任何线性程序，不存在分布式量子优势，即量子-LOCAL算法可以被等效的经典LOCAL算法去量子化。基于此，研究进一步揭示了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL模型甚至比经典的SLOCAL模型更弱。这些发现不仅扩展到其他分布模型，还表明在LCL问题上，非信号模型与SLOCAL模型是不可比较的，为量子计算的分布式优势边界提供了重要见解。

> **摘要翻译:** 在这项工作中，我们给出了两个结果，在分布式计算的LOCAL模型背景下，对分布式量子优势设定了新的限制。首先，我们证明了对于任何线性程序，不存在分布式量子优势。换句话说，如果存在一个量子-LOCAL算法$\mathcal{A}$，在T轮通信中找到某个线性优化问题$\Pi$的$\alpha$-近似，我们就可以构建一个经典、确定性LOCAL算法$\mathcal{A}'$，在T轮中找到$\Pi$的$\alpha$-近似。因此，所有针对线性程序的经典下界，包括KMW界，在量子-LOCAL中也同样适用。其次，利用上述结果，我们证明了存在一个局部可检查标签问题（LCL），对于该问题，量子-LOCAL严格弱于经典的确定性SLOCAL模型。我们的结果从量子-LOCAL也扩展到有限依赖和非信号分布，我们工作的一个推论是，在LCL问题背景下，非信号模型和SLOCAL模型是不可比较的：根据之前的工作，存在一个LCL问题，SLOCAL严格弱于非信号模型，而我们的工作提供了相反方向的分离。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

### [104] [A Terminology for Scientific Workflow Systems](https://arxiv.org/abs/2506.07838)
> *科学工作流系统的术语*

*Frédéric Sutera, Tainã Coleman, İlkay Altintaş, Rosa M. Badia, Bartosz Balis, Kyle Chard, Iacopo Colonnelli, Ewa Deelman, Paolo Di Tommaso, Thomas Fahringer, Carole Goble, Shantenu Jha, Daniel S. Katz, Johannes Köster, Ulf Leser, Kshitij Mehta, Hilary Oliver, J. -Luc Peterson, Giovanni Pizzi, Loïc Pottier, Raül Sirvent, Eric Suchyta, Douglas Thain, Sean R. Wilkinson, Justin M. Wozniak, Rafael Ferreira da Silva* | **Main category: cs.DC**

**Keywords:** 科学工作流系统, 术语, 工作流管理系统, 分类, 数据管理

**Comment:** 

> **TL;DR:** 鉴于科学工作流系统（WMS）的多样性和选择困难，本文提出了一套社区驱动的WMS术语和分类方法。

**AI_Comments:** 这篇论文通过引入一套结构化的社区驱动术语，为混乱且多样化的科学工作流系统领域带来了急需的清晰度。其创新之处在于提供了一个统一的框架来描述和分类WMS，这对于研究人员和开发者在选择、比较和设计系统时都极具价值。这种标准化有助于促进WMS领域的交流和理解，并可能为未来的系统开发提供指导。

<details>
  <summary>Details</summary>

**Motivation:** 科学工作流系统（WMS）种类繁多，功能重叠但也有独特之处，导致研究人员在选择WMS时面临复杂问题，缺乏统一的解决方案来应对科学流程和基础设施的多样性。

**Method:** 由WMS开发者和实践者组成的团队合作，共同制定了一套社区驱动的WMS术语。该术语包含五个轴：工作流特性、组成、编排、数据管理和元数据捕获。论文还基于此术语对23个现有WMS进行了分类。

**Result:** 提出了一个由五个轴（工作流特性、组成、编排、数据管理、元数据捕获）组成的社区驱动的WMS术语，并基于此术语对23个现有WMS进行了分类。

**Conclusion:** 通过引入一套统一的术语和分类方法，本文旨在帮助研究人员更好地理解和选择科学工作流系统，解决WMS多样性带来的挑战。

> **ai_Abstract:** 鉴于科学工作流管理系统（WMS）数量众多且功能多样，研究人员在选择合适的系统时面临挑战。本文旨在解决这一问题，通过汇集WMS开发者和实践者的努力，制定了一套社区驱动的WMS术语。该术语包含工作流特性、组成、编排、数据管理和元数据捕获五个核心轴，每个轴下包含多个概念，用于描述WMS的关键特征。基于这套术语，论文还对23个现有WMS进行了分类，以帮助用户更好地理解和选择系统。

> **摘要翻译:** 科学工作流这一术语在过去二十年里不断演变，涵盖了广泛的相互依赖的计算任务和数据移动的组合。它也成为了现代科学应用中处理的统称。如今，许多科学应用可以被视为由多个依赖步骤组成的工作流，并且已经开发了数百个工作流管理系统（WMS）来管理和运行这些工作流。然而，尚未出现一种开箱即用的解决方案来解决科学过程及其所实现基础设施的多样性。相反，需要以某种新颖特征执行科学工作流的新研究问题往往会导致全新的WMS的开发。直接的结果是，许多现有WMS共享一些显著特征，提供类似功能，并且可以管理相同类别的工作流，但也具有一些独特的能力。这种情况使得开发工作流的研究人员面临选择WMS的复杂问题。这种选择可能由技术考虑驱动，以找到最适合其应用和可用资源的系统，或由其他因素驱动，如声誉、采用率、强大的社区支持或长期可持续性。为了解决这个问题，一群WMS开发者和实践者共同努力，制定了一套基于社区的WMS术语。本文总结了他们的发现，并介绍了这个新的术语来表征WMS。该术语由五个轴组成：工作流特性、组成、编排、数据管理和元数据捕获。每个轴都包含几个概念，捕捉了WMS的突出特征。基于此术语，本文还根据所提出的轴和术语对23个现有WMS进行了分类。

</details>

[⬆️ 返回分类顶部](#csdc) | [⬆️ 返回总目录](#toc)

---

<a id='cscy'></a>
## cs.CY 

### [18] [Disentangling AI Alignment: A Structured Taxonomy Beyond Safety and Ethics](https://arxiv.org/abs/2506.06286)
> *解构AI对齐：超越安全与伦理的结构化分类法*

*Kevin Baum* | **Main category: cs.CY**

**Keywords:** AI对齐, 分类法, AI安全, 机器伦理, 规范性期望

**Comment:** accepted for the LNCS post proceedings of the AISoLA 2024 conference

> **TL;DR:** 本文提出了一个结构化的概念框架，通过区分对齐目标、范围和受众来理解AI对齐，以解决AI安全、对齐和机器伦理领域概念边界模糊的问题，并促进跨领域的整合。

**AI_Comments:** 该论文创新性地提出了一个结构化的AI对齐分类法，超越了传统的安全和伦理范畴，引入了目的、范围和受众维度，极大地澄清了AI对齐领域的复杂性。这对于促进跨学科研究和实际部署全面对齐的AI系统具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI代理日益脱离受控环境并在现实世界中产生影响，确保它们不仅安全而且符合更广泛的规范性期望成为一项紧迫的跨学科挑战。然而，AI安全、AI对齐和机器伦理等相关领域的概念界限和相互关系仍然模糊不清，导致研究人员缺乏明确的指导。

**Method:** 为了解决这一元挑战，本文开发了一个结构化的概念框架来理解AI对齐。该框架不只关注对齐目标，而是引入了一个分类法，区分了对齐目的（安全性、伦理性、合法性等）、范围（结果vs.执行）和受众（个体vs.集体）。

**Result:** 这种结构化方法揭示了多种合法的对齐配置，为跨领域的实践和哲学整合奠定了基础，并阐明了代理在“全面考虑”下对齐的含义。

**Conclusion:** 本文提出的结构化分类法有助于澄清AI对齐的复杂性，为理解和实现AI的全面对齐提供了理论基础和整合视角。

> **ai_Abstract:** 本文提出了一种结构化的AI对齐概念框架，旨在解决AI安全、对齐和机器伦理领域中概念边界模糊的问题。该框架通过区分对齐目的（如安全、伦理、合法性）、范围（结果或执行）和受众（个体或集体），揭示了多种有效的对齐配置，为跨学科整合提供了基础，并明确了AI代理“全面考虑”下对齐的含义。

> **摘要翻译:** 人工智能研究的最新进展使得具有重大现实世界影响的人工智能代理很快将超越严格受控环境运行变得越来越可能。因此，确保这些代理不仅安全而且符合更广泛的规范性期望，是一项紧迫的跨学科挑战。多个领域——特别是人工智能安全、人工智能对齐和机器伦理——声称对此任务有所贡献。然而，这些领域之间的概念界限和相互关系仍然模糊不清，使得研究人员在定位其工作时缺乏明确的指导。
为了解决这一元挑战，我们开发了一个结构化的概念框架来理解人工智能对齐。我们不只关注对齐目标，而是引入了一个分类法，区分了对齐目的（安全性、伦理性、合法性等）、范围（结果与执行）和受众（个体与集体）。这种结构化方法揭示了多种合法的对齐配置，为跨领域的实践和哲学整合提供了基础，并阐明了代理在“全面考虑”下对齐的含义。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [32] [How Malicious AI Swarms Can Threaten Democracy](https://arxiv.org/abs/2506.06299)
> *恶意AI蜂群如何威胁民主*

*Daniel Thilo Schroeder, Meeyoung Cha, Andrea Baronchelli, Nick Bostrom, Nicholas A. Christakis, David Garcia, Amit Goldenberg, Yara Kyrychenko, Kevin Leyton-Brown, Nina Lutz, Gary Marcus, Filippo Menczer, Gordon Pennycook, David G. Rand, Frank Schweitzer, Christopher Summerfield, Audrey Tang, Jay Van Bavel, Sander van der Linden, Dawn Song, Jonas R. Kunst* | **Main category: cs.CY**

**Keywords:** 恶意AI蜂群, 虚假信息, 民主, AI安全, 平台防御

**Comment:** 8 pages, 1 figure

> **TL;DR:** 恶意AI蜂群将对民主构成严重威胁，需要平台、模型和系统层面的多管齐下应对。

**AI_Comments:** 这篇论文创新性地提出了“恶意AI蜂群”的概念，强调了AI在虚假信息操作中从单点攻击向协同、持续威胁演变的趋势。其重要性在于及时预警了这一潜在威胁，并提出了一套全面的、多层次的防御框架，涵盖了技术、平台和治理层面，对于维护民主进程具有重要的指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI技术进步，复杂的虚假信息操作进入新时代，特别是恶意AI蜂群的出现，它们能秘密协调、渗透社区、规避检测，并持续运行，对全球日益脆弱的民主进程构成威胁。

**Method:** 提出三管齐下的应对措施：1) 平台侧防御（常驻蜂群检测仪表板、选前高保真蜂群模拟压力测试、透明度审计、客户端“AI盾”）；2) 模型侧保护（标准化说服风险测试、来源认证通行密钥、水印）；3) 系统级监督（联合国支持的AI影响力观察站）。

**Result:** 恶意AI蜂群可能导致捏造的基层共识、共享现实的碎片化、大规模骚扰、选民微观压制或动员、AI训练数据污染以及机构信任的侵蚀。

**Conclusion:** 鉴于民主进程日益脆弱，迫切需要平台、模型和系统层面的综合应对措施来抵御恶意AI蜂群的威胁。

> **ai_Abstract:** 本文探讨了恶意AI蜂群对民主构成的迫在眉睫的威胁。这些蜂群能够秘密协调、传播虚假信息、规避检测，并导致虚假共识、社会分裂和信任侵蚀。为应对此威胁，文章提出了一项三管齐下的策略，包括加强平台防御、实施模型级保护以及建立系统级监督（如联合国支持的AI影响力观察站）。

> **摘要翻译:** 人工智能的进步预示着一个复杂虚假信息操作的新时代。虽然单个AI系统已经能创建令人信服——有时甚至是误导性的——信息，但一个迫在眉睫的发展是恶意AI蜂群的出现。这些系统可以秘密协调、渗透社区、规避传统检测器，并进行持续的A/B测试，不间断地运行。其结果可能包括捏造的基层共识、共享现实的碎片化、大规模骚扰、选民微观压制或动员、AI训练数据污染以及机构信任的侵蚀。鉴于全球民主进程日益脆弱，我们敦促采取三管齐下的应对措施：(1) 平台侧防御——常驻蜂群检测仪表板、选前高保真蜂群模拟压力测试、透明度审计以及用户的可选客户端“AI盾”；(2) 模型侧保护——标准化说服风险测试、来源认证通行密钥和水印；以及 (3) 系统级监督——一个由联合国支持的AI影响力观察站。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [46] [LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment](https://arxiv.org/abs/2506.06355)
> *LLMs作为世界模型：数据驱动和以人为中心的灾害事前模拟用于灾害影响评估*

*Lingyao Li, Dawei Li, Zhenhui Ou, Xiaoran Xu, Jingxiao Liu, Zihui Ma, Runlong Yu, Min Deng* | **Main category: cs.CY**

**Keywords:** 大型语言模型, 灾害模拟, 地震影响评估, 多模态数据, 世界模型

**Comment:** 

> **TL;DR:** 本研究利用大型语言模型（LLMs）作为世界模型，通过多模态数据对地震影响进行事前模拟，并在实际地震中表现出高精度，可用于灾害规划。

**AI_Comments:** 这篇论文的创新点在于将LLMs作为“世界模型”应用于灾害模拟，特别是结合了多模态数据，包括视觉信息，这比传统方法更全面。其在实际地震数据上的高准确性验证了该方法的有效性。这为利用AI进行灾害预警和规划提供了新的思路，可能对未来灾害管理产生深远影响。

<details>
  <summary>Details</summary>

**Motivation:** 高效模拟对于加强对地震等突发灾害的事前准备至关重要。大型语言模型（LLMs）作为世界模型在模拟复杂场景方面显示出潜力，本研究旨在利用其能力主动估计感知的地震影响。

**Method:** 本研究检验了多个LLMs以主动估计感知的地震影响。框架利用包括地理空间、社会经济、建筑和街道级图像数据在内的多模态数据集，生成邮政编码和县级的修正麦卡利烈度（MMI）预测。评估在2014年纳帕和2019年里奇克雷斯特地震上使用USGS“你感觉到了吗？（DYFI）”报告进行。研究还探讨了RAG和ICL等技术以及视觉输入对模拟性能和准确性的影响。

**Result:** 在邮政编码级别，与USGS DYFI报告显示出显著一致性，相关性达到0.88，RMSE为0.77。RAG和ICL等技术可以提高模拟性能。视觉输入相比单独的结构化数值数据显著提高了准确性。

**Conclusion:** 研究结果表明，大型语言模型（LLMs）在模拟灾害影响方面显示出巨大潜力，可以有效帮助加强事前规划。

> **ai_Abstract:** 本文探讨了利用大型语言模型（LLMs）作为世界模型进行地震影响的事前模拟。研究团队开发了一个框架，整合多模态数据（包括地理空间、社会经济、建筑和图像数据），以预测邮政编码和县级的修正麦卡利烈度（MMI）。通过对历史地震的评估，该模型展示了与实际报告高度一致的预测能力，相关系数达到0.88，RMSE为0.77。研究还发现，RAG和ICL等技术以及视觉输入能显著提升模拟性能和准确性。这表明LLMs在灾害影响评估和事前规划方面具有巨大潜力。

> **摘要翻译:** 高效模拟对于加强对地震等突发灾害的积极准备至关重要。大型语言模型（LLMs）作为世界模型的最新进展在模拟复杂场景方面显示出潜力。本研究检验了多个LLMs，以主动估计感知的地震影响。利用包括地理空间、社会经济、建筑和街道级图像数据在内的多模态数据集，我们的框架在邮政编码和县级生成修正麦卡利烈度（MMI）预测。对2014年纳帕和2019年里奇克雷斯特地震使用USGS“你感觉到了吗？（DYFI）”报告进行的评估表明，与邮政编码级别的真实报告相比，结果显示出显著的一致性，表现为0.88的高相关性和0.77的低RMSE。RAG和ICL等技术可以提高模拟性能，而视觉输入相比单独的结构化数值数据显著提高了准确性。这些发现表明LLMs在模拟灾害影响方面的潜力，有助于加强事前规划。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [61] [Evaluating Large Language Model Capabilities in Assessing Spatial Econometrics Research](https://arxiv.org/abs/2506.06377)
> *评估大型语言模型在空间计量经济学研究评估中的能力*

*Giuseppe Arbia, Luca Morandini, Vincenzo Nardelli* | **Main category: cs.CY**

**Keywords:** 大型语言模型, 空间计量经济学, 同行评审, 经济推理, 评估

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLMs）在评估空间计量经济学研究中的表现，发现它们擅长初步的表面检查，但在深入的经济推理方面存在局限性，表明其在同行评审中可作为辅助工具，但仍需人类监督。

**AI_Comments:** 该论文创新性地探讨了LLMs在专业领域（空间计量经济学）评估中的应用潜力，揭示了其在表面检查方面的优势和深层推理的局限性。这对于理解LLMs在复杂学术工作中的角色及其未来发展方向具有重要意义，尤其是在自动化同行评审的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在调查大型语言模型（LLMs）评估空间计量经济学实证研究的经济合理性和理论一致性的能力。

**Method:** 研究团队从28篇已发表论文（2005-2024年）中创建了原始和故意修改的“反事实”摘要，并由不同的大型语言模型进行评估。LLMs提供了定性评估，并对变量选择、系数合理性和出版适宜性进行了结构化的二元分类。

**Result:** 结果表明，LLMs在评估变量选择的一致性方面表现出色（GPT-4o的F1分数达到0.87），但在评估系数合理性和整体出版适宜性等更深层次方面时，其表现差异显著。此外，LLM的选择、论文的具体特征以及两者之间的相互作用显著影响评估的准确性，尤其是在进行细致判断时。

**Conclusion:** 研究结果突出了LLMs在辅助进行初步、表面层次检查方面的当前优势，以及它们在执行全面、深入经济推理方面的局限性，这表明LLMs在同行评审中具有潜在的辅助作用，但仍需要强大的人工监督。

> **ai_Abstract:** 本研究评估了大型语言模型（LLMs）在评估空间计量经济学实证研究的经济合理性和理论一致性方面的能力。通过让LLMs评估28篇论文的原始和修改摘要，研究发现LLMs在变量选择的一致性评估上表现良好，但在更深层次的经济推理方面存在局限性。研究强调LLMs可作为同行评审的辅助工具，但需人类监督。

> **摘要翻译:** 本文研究了大型语言模型（LLMs）评估空间计量经济学实证研究中经济合理性和理论一致性的能力。我们从28篇已发表论文（2005-2024年）中创建了原始和故意修改的“反事实”摘要，并由不同的大型语言模型进行评估。LLMs提供了定性评估，并对变量选择、系数合理性和出版适宜性进行了结构化的二元分类。结果表明，虽然LLMs可以熟练评估变量选择的一致性（GPT-4o等顶级模型总体F1分数达到0.87），但它们在评估系数合理性和整体出版适宜性等更深层次方面时，表现差异显著。结果进一步揭示，LLM的选择、论文的具体特征以及两者之间的相互作用显著影响评估的准确性，尤其是在进行细致判断时。这些发现突出了LLMs在协助进行初步、表面层次检查方面的当前优势，以及它们在执行全面、深入经济推理方面的局限性，这表明它们在同行评审中具有潜在的辅助作用，但仍需要强大的人工监督。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [76] [Human and AI collaboration in Fitness Education:A Longitudinal Study with a Pilates Instructor](https://arxiv.org/abs/2506.06383)
> *健身教育中的人机协作：一项与普拉提教练的纵向研究*

*Qian Huang, King Wang Poon* | **Main category: cs.CY**

**Keywords:** 人机协作, 健身教育, 普拉提, 定性研究, 生成式AI

**Comment:** 19 pages, 5 figures

> **TL;DR:** 一项为期一年的定性案例研究，探讨了生成式AI如何融入普拉提教练的课程规划和教学，以理解AI在健身教育中与人类专业知识协作的最佳角色。

**AI_Comments:** 该研究通过长期的定性案例研究方法，深入探讨了AI在健身教育实践中的具体应用和人机协作模式，具有较强的实践指导意义。其创新之处在于关注AI与人类专业知识的融合而非替代，但抽象中未提及具体发现或影响。

<details>
  <summary>Details</summary>

**Motivation:** 尽管人工智能有望改变教学和指导实践，但其与人类专业知识相结合的最佳作用尚不明确，本研究旨在探索这一点。

**Method:** 本研究通过一项为期一年的定性案例研究，与一名普拉提教练合作进行。研究人员参与了教练的课程，并进行了双周半结构化访谈，以探讨生成式AI如何融入课程规划和教学。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本研究旨在探讨人工智能在健身教育中与人类专业知识协作的最佳方式。通过与一名普拉提教练进行为期一年的定性案例研究，研究人员参与课程并进行访谈，以了解生成式AI如何应用于课程规划和教学。

> **摘要翻译:** 人工智能有望改变教学和指导实践，但其与人类专业知识相结合的最佳作用尚不明确。本研究通过一项为期一年的定性案例研究，与一名普拉提教练合作，调查了健身教育中的人机协作。研究人员参与了教练的课程，并进行了双周半结构化访谈，以探讨生成式人工智能如何融入课程规划和教学。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [90] [Benchmarking Large Language Models on Homework Assessment in Circuit Analysis](https://arxiv.org/abs/2506.06390)
> *大型语言模型在电路分析作业评估中的基准测试*

*Liangliang Chen, Zhihao Qin, Yiming Guo, Jacqueline Rohde, Ying Zhang* | **Main category: cs.CY**

**Keywords:** 大型语言模型, 作业评估, 电路分析, 工程教育, 基准测试

**Comment:** 

> **TL;DR:** 本文评估了GPT-3.5 Turbo、GPT-4o和Llama 3 70B等大型语言模型在电路分析本科作业评估中的能力，并开发了一个LaTeX格式的新数据集。结果显示GPT-4o和Llama 3 70B表现优于GPT-3.5 Turbo。

**AI_Comments:** 该论文通过构建特定领域的LaTeX格式数据集和细致的评估指标，为LLM在工程教育中的应用提供了一个有价值的基准。其创新之处在于克服了LLM在图像识别方面的局限性，并针对作业评估的多个维度进行量化。研究结果不仅揭示了不同LLM在教育应用中的性能差异，也明确指出了其当前局限性，对未来开发可靠的教育辅助工具具有指导意义。该研究的通用性也使其方法可以推广到其他工程学科。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）具有彻底改变包括教育在内各个领域的潜力，因为它们拥有广泛的先验知识和快速发展。本文旨在探究LLM如何在工程教育中发挥作用，特别是评估它们在电路分析作业评估中的能力。

**Method:** 研究人员开发了一个包含官方参考答案和真实学生答案的LaTeX格式数据集，以克服LLM图像识别的局限性。设计了一个提示模板来测试学生答案的五个指标：完整性、方法、最终答案、算术错误和单位。对GPT-3.5 Turbo、GPT-4o和Llama 3 70B进行了基准测试。

**Result:** GPT-4o和Llama 3 70B在所有五个指标上的表现均显著优于GPT-3.5 Turbo，且两者在不同评估方面各有优势。研究还揭示了当前LLM在电路分析某些方面的局限性。

**Conclusion:** 本研究的结果为开发可靠、个性化的电路分析导师建立了基准并提供了宝贵的见解。此外，所提出的评估方法未来可以推广到更广泛的工程教育课程中。

> **ai_Abstract:** 本研究评估了大型语言模型（LLM）在本科电路分析作业评估中的潜力。通过开发一个包含LaTeX格式解决方案的新数据集，并针对完整性、方法、最终答案、算术错误和单位等五个指标设计评估模板，研究人员对GPT-3.5 Turbo、GPT-4o和Llama 3 70B进行了基准测试。结果表明，GPT-4o和Llama 3 70B的表现显著优于GPT-3.5 Turbo，且各自在不同评估方面展现出优势。文章还指出了当前LLM在电路分析中的局限性，并强调了确保评估可靠性的重要性，为未来开发个性化电路分析导师奠定了基础，并提出了可推广的评估方法。

> **摘要翻译:** 大型语言模型（LLM）由于其广泛的先验知识和快速发展，有潜力彻底改变包括代码开发、机器人技术、金融和教育在内的各个领域。本文研究了LLM如何在工程教育中发挥作用。具体来说，我们对不同LLM（包括GPT-3.5 Turbo、GPT-4o和Llama 3 70B）在评估本科电路分析课程作业方面的能力进行了基准测试。我们开发了一个新颖的数据集，其中包含电路分析中各种问题的官方参考解决方案和真实学生解决方案。为了克服当前最先进LLM在图像识别方面的局限性，数据集中的解决方案被转换为LaTeX格式。使用该数据集，设计了一个提示模板来测试学生解决方案的五个指标：完整性、方法、最终答案、算术错误和单位。结果显示，GPT-4o和Llama 3 70B在所有五个指标上的表现均显著优于GPT-3.5 Turbo，其中GPT-4o和Llama 3 70B在不同评估方面各有独特优势。此外，我们还提出了当前LLM在电路分析几个方面的局限性。鉴于确保LLM生成的作业评估的可靠性以避免误导学生至关重要，我们的结果建立了基准，并为开发可靠的个性化电路分析导师（这是我们未来工作的重点）提供了宝贵的见解。此外，所提出的评估方法未来可以推广到更广泛的工程教育课程中。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [103] [From Rogue to Safe AI: The Role of Explicit Refusals in Aligning LLMs with International Humanitarian Law](https://arxiv.org/abs/2506.06391)
> *从失控到安全AI：显式拒绝在使LLM与国际人道法保持一致中的作用*

*John Mavi, Diana Teodora Găitan, Sergio Coronado* | **Main category: cs.CY**

**Keywords:** LLM, 国际人道法, 显式拒绝, AI安全, 基准

**Comment:** 

> **TL;DR:** 本研究评估了大型语言模型（LLM）拒绝违反国际人道法（IHL）提示的能力，发现显式且清晰的拒绝对于AI安全至关重要，且轻量级干预可以改善拒绝质量，但复杂提示仍存在漏洞。

**AI_Comments:** 该研究的创新之处在于关注显式拒绝作为LLM与国际人道法对齐的机制，特别是“解释性拒绝”的概念，这对于提高透明度具有深刻见解。其重要性体现在解决了LLM在敏感应用中的关键安全和伦理问题，并提出了有价值的评估基准。然而，研究也指出，对于复杂提示，简单的干预可能不足以解决所有漏洞，这揭示了未来研究的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）已广泛应用，但其与国际人道法（IHL）的对齐情况尚不明确。本研究旨在评估LLM拒绝明确违反这些法律框架的提示的能力。

**Method:** 研究评估了八个领先的LLM拒绝违反国际人道法（IHL）提示的能力，并重点关注拒绝的清晰度和建设性。同时，研究测试了标准化系统级安全提示对拒绝解释质量的影响。

**Result:** 大多数模型拒绝了非法请求，但响应的清晰度和一致性各不相同。解释性拒绝（揭示理由并引用法律/安全原则）有助于澄清系统边界并防止滥用。标准化系统级安全提示显著提高了大多数模型中拒绝解释的质量。然而，涉及技术语言或代码请求的更复杂提示仍暴露出持续存在的漏洞。

**Conclusion:** 本研究的发现有助于开发更安全、更透明的AI系统，并提出了一个评估LLM符合国际人道法（IHL）情况的基准。显式且清晰的拒绝，辅以轻量级干预，对于LLM与IHL的对齐至关重要，尽管在处理复杂情况时仍存在挑战。

> **ai_Abstract:** 本研究评估了八个领先的大型语言模型（LLM）与国际人道法（IHL）的对齐情况，重点测试了它们拒绝违反法律框架提示的能力。研究发现，尽管大多数模型能拒绝非法请求，但其拒绝的清晰度和一致性存在差异。提供理由并引用法律/安全原则的解释性拒绝对于明确系统边界和防止滥用至关重要。一个标准化的系统级安全提示显著提升了大多数模型中拒绝解释的质量，但面对涉及技术语言或代码的复杂提示时，模型仍暴露出漏洞。本研究为开发更安全、更透明的AI系统做出了贡献，并提出了一个评估LLM符合IHL情况的基准。

> **摘要翻译:** 大型语言模型（LLM）在各个领域得到广泛应用，但它们与国际人道法（IHL）的对齐情况尚不清楚。本研究评估了八个领先的LLM拒绝明确违反这些法律框架的提示的能力，并侧重于有用性——即拒绝的沟通方式是否清晰和具有建设性。虽然大多数模型拒绝了非法请求，但其响应的清晰度和一致性各不相同。通过揭示模型的理由并引用相关法律或安全原则，解释性拒绝阐明了系统的边界，减少了模糊性，并有助于防止滥用。一个标准化的系统级安全提示显著提高了大多数模型中拒绝解释的质量，突出了轻量级干预的有效性。然而，涉及技术语言或代码请求的更复杂提示揭示了持续存在的漏洞。这些发现有助于开发更安全、更透明的AI系统，并提出了一个评估LLM符合IHL情况的基准。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [116] [Large Language Models Can Be a Viable Substitute for Expert Political Surveys When a Shock Disrupts Traditional Measurement Approaches](https://arxiv.org/abs/2506.06540)
> *当冲击扰乱传统测量方法时，大型语言模型可以有效替代专家政治调查*

*Patrick Y. Wu* | **Main category: cs.CY**

**Keywords:** 大型语言模型, 专家政治调查, 颠覆性事件, 政治测量, 案例研究

**Comment:** 19 pages, 6 figures

> **TL;DR:** 当传统测量方法因冲击事件受阻时，大型语言模型（LLMs）可以作为专家政治调查的有效替代品，以重建事件前的认知并研究相关因素。

**AI_Comments:** 这篇论文提出了一种创新性的方法，利用大型语言模型（LLMs）来解决政治学研究中一个关键的测量难题，即在重大事件发生后，传统专家调查可能存在的偏差问题。其重要性在于，它为在动态且难以进行传统数据收集的政治环境中，提供了一种新的、可行的研究工具。通过具体案例研究展示了LLMs的潜力，为LLMs在社会科学领域的应用开辟了新途径。论文的局限性可能在于，所提出的“两部分标准”的具体内容在摘要中并未详细阐述，且仅通过一个案例研究来验证其有效性，可能需要更多不同情境下的验证。

<details>
  <summary>Details</summary>

**Motivation:** 在颠覆性事件或冲击（如DOGE联邦裁员）发生后，专家判断会受到结果知识的影响，这使得重建研究事件相关因素所需的事件前认知变得困难或不可能。

**Method:** 本文论证了大型语言模型（LLMs）在冲击扰乱传统测量时可以替代专家政治调查。研究以DOGE裁员为例进行案例分析，使用LLMs进行配对比较提示，并得出联邦行政机构的意识形态得分。此外，研究还通过相同方法发现某些联邦机构作为知识机构的认知可以预测哪些机构被DOGE裁员，即使在控制意识形态的情况下。

**Result:** LLM得出的机构意识形态得分复制了裁员前的专家测量结果，并成功预测了哪些机构成为DOGE的裁员目标。同时，某些联邦机构作为知识机构的认知也能预测裁员目标，即使在控制意识形态后。这表明LLMs可以快速、容易地测试冲击背后的假设相关因素。

**Conclusion:** 本文得出的结论是，利用大型语言模型（LLMs）可以在传统测量技术失效时，为冲击事件的相关因素提供见解。研究提出了一项两部分标准，指导研究人员何时可以将LLMs作为专家政治调查的替代品。

> **ai_Abstract:** 本研究提出，在颠覆性事件导致传统测量方法失效时，大型语言模型（LLMs）可以有效替代专家政治调查，以重建事件前的认知。研究以DOGE联邦裁员为例，利用LLMs进行配对比较，成功复制了专家测量结果并预测了被裁机构。结果表明，LLMs能快速识别与冲击事件相关的因素，并提出何时使用LLMs替代专家调查的标准。

> **摘要翻译:** 在颠覆性事件或冲击（例如2025年政府效率部（DOGE）的联邦裁员）发生后，专家判断会受到结果知识的影响。这使得重建研究事件相关因素所需的事件前认知变得困难或不可能。这篇立场论文认为，当冲击扰乱传统测量时，经过大量数字媒体数据训练的大型语言模型（LLMs）可以有效替代专家政治调查。我们以DOGE裁员作为这一立场的具体案例研究。我们使用LLMs进行配对比较提示，并得出联邦行政机构的意识形态得分。这些得分复制了裁员前的专家测量结果，并预测了哪些机构成为DOGE的目标。我们还使用相同的方法发现，某些联邦机构作为知识机构的认知可以预测哪些机构成为DOGE的目标，即使在控制意识形态的情况下。这项案例研究表明，使用LLMs使我们能够快速、轻松地测试冲击背后假设的相关因素。更广泛地说，我们对这一近期事件的案例研究表明，当传统测量技术失效时，LLMs如何为冲击的相关因素提供见解。最后，我们提出了一个两部分标准，说明研究人员何时可以转向LLMs作为专家政治调查的替代品。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [130] [Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce](https://arxiv.org/abs/2506.06576)
> *采用AI代理的未来工作：审计美国劳动力的自动化和增强潜力*

*Yijia Shao, Humishka Zope, Yucheng Jiang, Jiaxin Pei, David Nguyen, Erik Brynjolfsson, Diyi Yang* | **Main category: cs.CY**

**Keywords:** AI代理, 劳动力市场, 自动化, 增强, 人类能动性, WORKBank数据库

**Comment:** Preprint

> **TL;DR:** AI代理正在重塑劳动力市场，本文提出了一个审计框架，以系统地评估工人对AI代理自动化或增强任务的偏好，并将其与技术能力对齐，揭示了AI代理开发的机遇和挑战。

**AI_Comments:** 本文通过引入“人类能动性量表”（HAS）和WORKBank数据库，提供了一个系统性的方法来评估AI代理在工作场所的自动化和增强潜力，并考虑了人类的偏好与技术能力之间的对齐。这种以人为中心的研究方法对于指导未来AI代理的负责任开发具有重要意义，尤其是在避免工作替代和增强人类能动性方面。其划分的四个区域也为AI研发提供了清晰的方向。

<details>
  <summary>Details</summary>

**Motivation:** 快速兴起的复合AI系统（AI代理）正在重塑劳动力市场，引发了对工作替代、人类能动性减弱和过度依赖自动化的担忧。然而，目前缺乏对这一不断演变格局的系统理解。

**Method:** 本文引入了一个新颖的审计框架，旨在评估工人希望AI代理自动化或增强哪些职业任务，以及这些愿望如何与当前技术能力对齐。该框架包含音频增强的迷你访谈以捕捉细微的工人愿望，并引入了“人类能动性量表”（HAS）来量化人类参与的首选水平。利用此框架，研究构建了WORKBank数据库（基于美国劳工部的O*NET数据库），收集了来自1,500名领域工人（涵盖104个职业的844多项任务）的偏好和AI专家的能力评估。通过综合考虑愿望和技术能力，WORKBank中的任务被划分为自动化“绿灯”区、自动化“红灯”区、研发机会区和低优先级区四个区域。

**Result:** 研究揭示了WORKBank中任务的关键不匹配和AI代理开发的机遇。结果显示，不同职业的“人类能动性量表”（HAS）配置文件多样，反映了对人类参与的异质期望。此外，研究提供了AI代理集成可能如何重塑核心人类能力（从信息聚焦技能转向人际交往技能）的早期信号。

**Conclusion:** 研究强调了将AI代理开发与人类愿望对齐以及为不断演变的工作场所动态做好准备的重要性。

> **ai_Abstract:** 本文针对AI代理对劳动力市场的影响，提出了一种新颖的审计框架来评估工人对AI代理自动化或增强任务的偏好与当前技术能力的匹配度。通过音频访谈和“人类能动性量表”（HAS），作者构建了WORKBank数据库，收集了1500名工人对844多项任务的偏好和AI专家的能力评估。研究将任务划分为四个区域，揭示了AI代理开发中的机遇和不匹配，并发现不同职业对人类参与的期望存在差异，预示着核心人类能力将从信息技能转向人际交往技能。研究强调了AI代理开发需与人类愿望对齐，并为职场变化做好准备。

> **摘要翻译:** 快速兴起的复合AI系统（又称AI代理）正在重塑劳动力市场，引发了对工作替代、人类能动性减弱和过度依赖自动化的担忧。然而，我们缺乏对不断演变格局的系统理解。在本文中，我们通过引入一种新颖的审计框架来弥补这一空白，该框架旨在评估职业任务中工人希望AI代理自动化或增强哪些部分，以及这些愿望如何与当前技术能力对齐。我们的框架具有音频增强的迷你访谈功能，以捕捉细微的工人愿望，并引入了人类能动性量表（HAS）作为量化人类参与首选水平的共同语言。利用这个框架，我们构建了WORKBank数据库，该数据库基于美国劳工部的O*NET数据库，捕获了来自1,500名领域工人（涵盖104个职业的844多项任务）的偏好以及AI专家的能力评估。综合考虑愿望和技术能力，WORKBank中的任务被划分为四个区域：自动化“绿灯”区、自动化“红灯”区、研发机会区、低优先级区。这突出了AI代理开发中的关键不匹配和机遇。我们的结果超越了简单的自动化与否的二分法，揭示了不同职业中多样化的HAS配置文件，反映了对人类参与的异质期望。此外，我们的研究提供了关于AI代理集成可能如何重塑核心人类能力（从信息聚焦技能转向人际交往技能）的早期信号。这些发现强调了将AI代理开发与人类愿望对齐以及为不断演变的工作场所动态做好准备的重要性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [143] [Privacy Perspectives and Practices of Chinese Smart Home Product Teams](https://arxiv.org/abs/2506.06591)
> *中国智能家居产品团队的隐私视角与实践*

*Shijing He, Yaxiong Lei, Xiao Zhan, Chi Zhang, Juan Ye, Ruba Abu-Salma, Jose Such* | **Main category: cs.CY**

**Keywords:** 智能家居, 隐私, 中国, 产品团队, 数据隐私法

**Comment:** 

> **TL;DR:** 本文通过访谈探讨了中国智能家居产品团队的隐私视角和实践，揭示了他们强调遵守优先于个人隐私权利的国家安全的中国数据隐私法，以及文化、社会和法律因素对平衡隐私、安全和便利性的影响。文章为解决中国多用户智能家居中的隐私问题提出了建议。

**AI_Comments:** 本文通过关注产品团队而非用户视角，在智能家居隐私研究领域填补了重要空白，尤其是在中国这种非西方背景下。其发现揭示了特定法律框架（国家安全优先）和文化因素所带来的独特挑战和考量，为行业和政策制定者提供了超越以用户为中心研究的宝贵见解。提出的建议对行业和政策制定者具有实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 以往的研究主要关注设备所有者、主要用户和旁观者群体在智能家居设备方面的隐私需求和担忧，但对于智能家居产品团队的隐私观点和实践知之甚少，尤其是在非西方背景下，本研究旨在填补这一空白。

**Method:** 本研究通过对27名中国智能家居产品团队成员（包括产品/项目经理、软件/硬件工程师、用户体验（UX）设计师、法律/隐私专家以及市场/运营专员）进行半结构化访谈， بررسی了他们的隐私视角、实践和风险缓解策略。

**Result:** 研究结果显示，参与者强调遵守中国的个人数据隐私法律，这些法律通常将国家安全置于个人隐私权之上。中国特有的文化、社会和法律因素也影响了参与者的道德考量以及在平衡用户隐私和安全与便利性方面的态度。

**Conclusion:** 根据研究发现，本文为智能家居产品团队提出了一系列建议，并提出了社会技术和法律干预措施，以解决中国多用户智能家居中的隐私问题，特别是那些属于弱势群体的隐私问题。

> **ai_Abstract:** 本研究通过访谈调查了中国智能家居产品团队的隐私视角和实践。结果表明，这些团队优先遵守中国的个人数据隐私法律，这些法律通常将国家安全置于个人隐私之上。此外，中国的文化、社会和法律因素显著影响了他们对用户隐私、安全与便利性之间平衡的伦理考量。文章最后提出了解决中国智能家居隐私问题的建议和干预措施，尤其针对弱势用户群体。

> **摘要翻译:** 之前的研究已经探讨了设备所有者、主要用户以及不同旁观者群体在智能家居设备（如安防摄像头、智能音箱和集线器）方面的隐私需求和担忧，但对于智能家居产品团队的隐私观点和实践知之甚少，特别是在非西方背景下。本文介绍了对27名中国智能家居产品团队成员（包括产品/项目经理、软件/硬件工程师、用户体验（UX）设计师、法律/隐私专家以及市场/运营专员）进行半结构化访谈的发现。我们 بررسی了他们的隐私视角、实践和风险缓解策略。我们的结果显示，参与者强调遵守中国数据隐私法律，这些法律通常将国家安全置于个人隐私权之上。中国特有的文化、社会和法律因素也影响了参与者的道德考量以及在平衡用户隐私和安全与便利性方面的态度。根据我们的发现，我们为智能家居产品团队提出了一系列建议，以及社会技术和法律干预措施，以解决中国多用户智能家居中的隐私问题——特别是那些属于弱势群体的隐私问题。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [154] [Spatial Disparities in Fire Shelter Accessibility: Capacity Challenges in the Palisades and Eaton Fires](https://arxiv.org/abs/2506.06803)
> *火灾避难所可达性中的空间差异：Palisades和Eaton火灾中的容量挑战*

*Su Yeon Han, Yubin Lee, Jooyoung Yoo, Jeon-Young Kang, Jinwoo Park, Soe W. Myint, Eunsang Cho, Xin Gu, Joon-Seok Kim* | **Main category: cs.CY**

**Keywords:** 火灾避难所, 可达性, 空间差异, 容量挑战, 灾害规划

**Comment:** 35 pages, 11 figures

> **TL;DR:** 研究发现加州Palisades和Eaton火灾期间避难所严重短缺且存在空间不平等，尤其在偏远地区，并提出通过优化避难所布局策略可改善可达性。

**AI_Comments:** 本研究创新性地结合了地理空间分析和模拟方法来评估和优化火灾避难所的可达性与公平性，对未来灾害管理和基础设施规划具有重要指导意义，尤其是在气候变化导致野火风险增高的背景下。

<details>
  <summary>Details</summary>

**Motivation:** 随着加州野火频率和严重性增加，对城市社区韧性和公平应急响应构成挑战。Palisades和Eaton火灾期间，尽管有协调努力，避难所短缺导致大量疏散人员无处可去，促使本研究旨在衡量避难所可达性、评估现有容量是否满足需求并识别空间差异。

**Method:** 研究通过测量火灾高峰期的避难所可达性，评估现有避难所容量是否满足需求，并识别空间差异。此外，研究使用基于容量算法和基于邻近度方法模拟了避难所安置策略。

**Result:** 结果显示避难所严重短缺，特别是在地理隔离区域和山区，避难所的可达性存在明显不公平。模拟表明，新的避难所安置策略（基于容量算法和基于邻近度方法）可以潜在改善避难所可达性和公平性。

**Conclusion:** 研究强调，为提高灾害准备并减少常发野火地区的脆弱性，迫切需要进行战略性避难所规划和基础设施建设。

> **ai_Abstract:** 本研究分析了加州Palisades和Eaton火灾期间避难所的可达性问题，发现避难所严重短缺且存在空间不平等，尤其是在偏远和山区。通过模拟基于容量和邻近度的避难所安置策略，研究证明了改善避难所可达性和公平性的潜力，并强调了战略性避难所规划对于提高野火地区灾害准备的重要性。

> **摘要翻译:** 随着加州野火频率和严重性的增加，在长期干旱和环境变化的加剧下，对城市社区韧性和公平应急响应构成了重大挑战。本研究调查了2025年1月在南加州爆发的Palisades和Eaton火灾期间避难所可达性问题，这两场火灾导致超过18万人流离失所，1.6万座建筑物被毁。尽管许多组织为紧急援助做出了协调努力，但避难所短缺使许多疏散人员缺乏安全或可及的避难所。本研究旨在衡量火灾高峰期间避难所的可达性，评估现有避难所容量是否满足需求，并识别可达性中的空间差异。结果显示避难所严重短缺，尤其是在地理隔离区域和山区，避难所的可达性存在明显不公平。我们使用基于容量算法和基于邻近度方法的避难所安置策略模拟表明，避难所可达性和公平性均有潜在改善。研究结果强调了战略性避难所规划和基础设施建设的迫切需求，以增强灾害准备并减少常发野火地区的脆弱性。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [164] [Position: Simulating Society Requires Simulating Thought](https://arxiv.org/abs/2506.06958)
> *立场：模拟社会需要模拟思想*

*Chance Jiajie Li, Jiayi Wu, Zhenze Mo, Ao Qu, Yuhan Tang, Kaiya Ivy Zhao, Yulu Gan, Jie Fan, Jiangbo Yu, Jinhua Zhao, Paul Liang, Luis Alonso, Kent Larson* | **Main category: cs.CY**

**Keywords:** 社会模拟, 大型语言模型, 生成式智能体, 认知科学, 因果推理

**Comment:** 

> **TL;DR:** 现有LLM社会模拟缺乏认知基础和因果推理；本文提出GenMinds范式和RECAP评估框架，旨在模拟思想而非仅是语言。

**AI_Comments:** 这篇论文提出了一种重要的观点，即在社会模拟中，LLM需要从简单的行为模仿转向更深层次的认知模拟，即模拟“思想”而非仅仅“语言”。GenMinds范式和RECAP评估框架的提出，为实现这一目标提供了具体的方向和工具，强调了认知科学在AI社会模拟中的重要性，具有创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型（LLMs）在模拟社会时，主要通过提示和微调来模仿个体和群体行为，但它们缺乏内部连贯性、因果推理和信念可追溯性，导致它们在分析人们如何推理、审议或响应干预方面不可靠。文章认为模拟社会需要认知上扎根的、结构化的、可修改和可追溯的推理，而不仅仅是生成貌似合理的行为。

**Method:** 提出一个概念建模范式——“生成式思维”（Generative Minds, GenMinds），它借鉴认知科学来支持生成式智能体中的结构化信念表示。为了评估这些智能体，引入了RECAP（REconstructing CAusal Paths）框架，这是一个旨在通过因果可追溯性、人口学基础和干预一致性来评估推理保真度的基准。

**Result:** 本文的贡献是提出了GenMinds范式和RECAP评估框架，推动了社会模拟从表面模仿向模拟思想而非仅仅语言的生成式智能体的转变。

**Conclusion:** 模拟社会需要超越表面行为模仿，转向模拟具有认知基础、结构化、可修订和可追溯思维的生成式智能体，这通过GenMinds和RECAP框架得以实现。

> **ai_Abstract:** 本文提出，使用大型语言模型进行社会模拟，需要模拟具有认知基础、结构化、可修改和可追溯的思维，而非仅是表面行为。针对现有LLM智能体在因果推理和信念可追溯性上的不足，作者引入了“生成式思维”（GenMinds）概念建模范式，该范式借鉴认知科学以支持智能体中的结构化信念表示。同时，为评估此类智能体，文章提出了RECAP框架，一个通过因果可追溯性、人口学基础和干预一致性来衡量推理保真度的基准。这些工作旨在推动社会模拟从单纯的语言模仿转向更深层次的思想模拟。

> **摘要翻译:** 模拟社会需要模拟思想
我们认为，用大型语言模型（LLMs）模拟社会，需要的不仅仅是生成貌似合理的行为——它需要认知上扎根的推理，这种推理是结构化的、可修改的和可追溯的。基于LLM的智能体越来越多地被用于模拟个体和群体行为——主要是通过提示和监督微调。然而，它们常常缺乏内部连贯性、因果推理和信念可追溯性——这使得它们在分析人们如何推理、审议或响应干预方面不可靠。
为了解决这个问题，我们提出了一种概念建模范式，即生成式思维（Generative Minds, GenMinds），它借鉴认知科学来支持生成式智能体中的结构化信念表示。为了评估这些智能体，我们引入了RECAP（REconstructing CAusal Paths）框架，这是一个旨在通过因果可追溯性、人口学基础和干预一致性来评估推理保真度的基准。这些贡献推动了更广泛的转变：从表面层面的模仿转向模拟思想——而不仅仅是语言——用于社会模拟的生成式智能体。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [175] [Adultification Bias in LLMs and Text-to-Image Models](https://arxiv.org/abs/2506.07282)
> *LLMs和文本到图像模型中的成人化偏见*

*Jane Castleman, Aleksandra Korolova* | **Main category: cs.CY**

**Keywords:** 成人化偏见, 生成式AI, LLM, 文本到图像模型, 偏见缓解

**Comment:** Accepted to the ACM Conference on Fairness, Accountability, and
  Transparency (FAccT '25)

> **TL;DR:** 研究发现，大型语言模型（LLMs）和文本到图像（T2I）模型对黑人女孩存在成人化偏见，将其描述为更年长、更具性意味或面临更严厉的后果，表明现有AI对齐方法不足以解决此类偏见。

**AI_Comments:** 这项研究通过引入“成人化偏见”这一新颖且重要的概念，揭示了生成式AI模型中存在的深层社会偏见。其创新之处在于系统地跨模态（LLM和T2I）测量了这种偏见，并明确指出现有对齐技术的局限性。这对于推动AI伦理和负责任的AI开发具有重要意义，提醒开发者和研究者需要更细致、更全面的方法来识别和缓解AI系统中的隐性偏见，特别是针对弱势群体。

<details>
  <summary>Details</summary>

**Motivation:** 随着生成式AI模型在教育、警务和社交媒体等领域的快速采用，其潜在的偏见和安全问题日益突出，特别是在涉及受保护属性（如种族和性别）和未成年人时。本文关注“成人化偏见”，即黑人女孩被错误地认为比白人同龄人更不顺从、更具性暗示和更应受责备的现象，以促进AI系统的安全交互。

**Method:** 研究测量了广泛使用的LLM（如OpenAI、Meta）和文本到图像（T2I）模型（如Stability AI）中的显性和隐性成人化偏见，重点关注年轻女孩，特别是黑人女孩。

**Result:** 发现LLMs对黑人女孩表现出显性和隐性成人化偏见，与白人同龄人相比，她们被赋予更严厉、更性化的后果。T2I模型将黑人女孩描绘得更年长，穿着更暴露，表明成人化偏见跨模态存在。

**Conclusion:** 当前的对齐方法不足以全面解决诸如成人化偏见等问题，因此需要新的对齐方法来确保安全和公平的AI部署。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）和文本到图像（T2I）模型中存在的“成人化偏见”，即黑人女孩被错误地视为比白人同龄人更成熟、更具性暗示或更应受责备。通过对OpenAI、Meta和Stability AI等广泛使用的模型进行测试，发现LLMs对黑人女孩施加更严厉、更性化的后果，而T2I模型则将其描绘得更年长、穿着更暴露。研究强调，这种偏见跨模态存在，并指出当前AI对齐方法在解决此类复杂偏见方面的不足，呼吁开发新的对齐技术以确保AI的公平和安全部署。

> **摘要翻译:** 生成式AI模型在教育、警务和社交媒体等领域的快速采用，引发了对潜在偏见和安全问题的严重担忧，尤其是在涉及种族和性别等受保护属性以及与未成年人互动时。鉴于促进与AI系统安全交互的紧迫性，我们研究了年轻女孩在种族和性别方面的偏见。更具体地说，我们关注“成人化偏见”，这是一种黑人女孩被假定比白人同龄人更不顺从、更具性暗示和更应受责备的现象。对齐技术的进步显示出缓解偏见的希望，但其覆盖范围和有效性在不同模型和偏见类型之间存在差异。因此，我们测量了广泛使用的LLM和文本到图像（T2I）模型（如OpenAI、Meta和Stability AI模型）中的显性和隐性成人化偏见。我们发现LLM对黑人女孩表现出显性和隐性成人化偏见，与白人同龄人相比，她们被赋予更严厉、更性化的后果。此外，我们发现T2I模型将黑人女孩描绘得更年长，穿着更暴露，这说明成人化偏见在不同模态中持续存在。我们做出了三个关键贡献：(1) 我们测量了生成式AI模型中的一种新形式的偏见，(2) 我们系统地研究了跨模态的成人化偏见，(3) 我们的发现强调，当前的对齐方法不足以全面解决偏见。因此，需要新的对齐方法来解决诸如成人化等偏见，以确保AI的安全和公平部署。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

### [182] [Deepfake Technology Unveiled: The Commoditization of AI and Its Impact on Digital Trust](https://arxiv.org/abs/2506.07363)
> *深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响*

*Claudiu Popa, Rex Pallath, Liam Cunningham, Hewad Tahiri, Abiram Kesavarajah, Tao Wu* | **Main category: cs.CY**

**Keywords:** 深度伪造, 数字信任, 生成式AI, 欺诈, 错误信息

**Comment:** 12 pages, 13 figures

> **TL;DR:** 随着生成式AI工具的普及，深度伪造技术门槛降低，引发信任、隐私和安全问题。本白皮书探讨了深度伪造的含义，展示了如何用有限资源创建逼真的深度伪造，并强调了应对技术和伦理挑战、维护数字信任的紧迫性。

**AI_Comments:** 本文创新性地通过列举具体工具（如Runway、Rope和ElevenLabs）来演示深度伪造的易操作性，直观地揭示了该技术对数字信任的潜在威胁。其重要性在于，它不仅指出了深度伪造的危害，更提出了通过监管、教育和合作来应对挑战的紧迫性，对于政策制定者和公众都具有警示意义。

<details>
  <summary>Details</summary>

**Motivation:** 生成式AI工具的普及降低了深度伪造技术的财务和技术门槛，导致欺诈、错误信息和多媒体真实性受侵蚀，引发了对信任、隐私和安全的担忧。因此，本白皮书旨在探讨深度伪造技术的影响。

**Method:** 本白皮书分析了深度伪造技术在促成欺诈、错误信息和多媒体真实性侵蚀方面的作用。通过使用Runway、Rope和ElevenLabs等经济高效、易于使用的工具，演示了如何用有限的资源创建逼真的深度伪造。同时，分析了深度伪造缓解和检测的技术和伦理挑战。

**Result:** 研究表明，即使资源有限，也能使用Runway、Rope和ElevenLabs等工具创建逼真的深度伪造，这给个人和组织都带来了风险。

**Conclusion:** 深度伪造技术带来了严峻的技术和伦理挑战，迫切需要监管框架、公众意识和协作努力来维护数字媒体的信任。

> **ai_Abstract:** 本白皮书深入探讨了深度伪造技术，指出生成式AI工具的普及如何降低了其创建门槛，从而引发了数字信任、隐私和安全危机。文章分析了深度伪造在欺诈和错误信息传播中的作用，并演示了如何利用现有工具以有限资源生成逼真内容。最后，强调了为应对技术和伦理挑战，亟需建立监管框架、提升公众意识并加强合作，以维护数字媒体的真实性。

> **摘要翻译:** 深度伪造技术揭秘：人工智能的商品化及其对数字信任的影响。随着生成式人工智能可及性的提高，语音克隆、换脸和合成媒体创建工具取得了显著进展，降低了其使用的财务和技术障碍。虽然这些技术带来了创新的机会，但其快速增长引发了对信任、隐私和安全的担忧。本白皮书探讨了深度伪造技术的影响，分析了其在促成欺诈、错误信息和多媒体真实性侵蚀方面的作用。通过使用Runway、Rope和ElevenLabs等经济高效、易于使用的工具，我们探讨了如何用有限的资源创建逼真的深度伪造，展示了对个人和组织造成的风险。通过分析深度伪造缓解和检测的技术和伦理挑战，我们强调了维护数字媒体信任的监管框架、公众意识和协作努力的迫切需求。

</details>

[⬆️ 返回分类顶部](#cscy) | [⬆️ 返回总目录](#toc)

---

<a id='csce'></a>
## cs.CE 

### [21] [Deep Learning Enhanced Multi-Day Turnover Quantitative Trading Algorithm for Chinese A-Share Market](https://arxiv.org/abs/2506.06356)
> *深度学习增强的中国A股市场多日周转量化交易算法*

*Yimin Du* | **Main category: cs.CE**

**Keywords:** 深度学习, 量化交易, A股市场, 多日周转, 风险管理

**Comment:** 10 pages

> **TL;DR:** 本文提出了一种结合深度学习和多模块策略的中国A股市场多日周转量化交易算法，实现了高年化收益和低最大回撤。

**AI_Comments:** 这篇论文的创新点在于将深度学习与一个多模块、综合性的量化交易框架相结合，特别针对中国A股市场进行了优化。其强调资本效率、风险管理以及在实际市场条件下的鲁棒性，并提供了令人印象深刻的回测结果，表明其在实际应用中的潜力。多模块的设计使其能够处理复杂的市场动态，而深度学习的应用则提升了预测的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在为中国A股市场开发一种先进的、结合深度学习和多模块策略的量化交易算法，以实现资本效率与风险管理的平衡，并获得卓越的交易表现。

**Method:** 该算法是一个多日周转量化交易算法，整合了深度学习技术和全面的横截面股票预测。它包含五个相互关联的模块：通过深度横截面预测网络进行初始股票选择；使用混合模型进行开盘信号分布分析以识别套利机会；基于市值和流动性的动态头寸调整；网格搜索优化的止盈止损机制；以及多粒度基于波动率的市场择时模型。算法通过自适应持有期和复杂的进出场时机来平衡资本效率和风险管理。

**Result:** 算法在2010-2020年数据上训练，在2021-2024年数据上回测，实现了15.2%的年化收益率，最大回撤低于5%，夏普比率为1.87。该策略每天保持50-100个头寸，最长持有期为9天，通过动态止盈止损机制提高了资本周转效率，同时保持了风险调整后的回报。

**Conclusion:** 该算法在中国A股市场表现出强大的鲁棒性，在不同市场机制下均能保持高性能，并具有适合机构部署的高资本容量。

> **ai_Abstract:** 本文提出一种面向中国A股市场的深度学习增强型多日周转量化交易算法。该算法整合了深度学习驱动的股票预测和五个关键模块，包括股票选择、开盘信号分析、动态仓位管理、止盈止损及市场择时。经过2010-2020年数据训练和2021-2024年数据回测，该策略实现了15.2%的年化收益率、低于5%的最大回撤和1.87的夏普比率，表现出高资本效率、低风险和机构部署潜力。

> **摘要翻译:** 本文提出了一种复杂的、结合了先进深度学习技术和全面横截面股票预测的中国A股市场多日周转量化交易算法。我们的框架结合了五个相互关联的模块：通过深度横截面预测网络进行初始股票选择、使用混合模型进行开盘信号分布分析以识别套利机会、基于市值和流动性的动态头寸调整、网格搜索优化的止盈止损机制，以及多粒度基于波动率的市场择时模型。该算法采用一种新颖的方法，通过自适应持有期和复杂的进出场时机来平衡资本效率与风险管理。该方法在2010-2020年的A股综合数据上进行训练，并在2021-2024年的数据上进行了严格的回测，取得了显著的性能，年化收益率为15.2%，最大回撤控制在5%以下，夏普比率为1.87。该策略通过保持50-100个日常头寸（最长持有期9天）展示了卓越的可扩展性，并结合了动态止盈止损机制，在保持风险调整后回报的同时提高了资本周转效率。我们的方法在各种市场机制下均表现出强大的鲁棒性，同时保持了适合机构部署的高资本容量。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

### [35] [\textit{QuantMCP}: Grounding Large Language Models in Verifiable Financial Reality](https://arxiv.org/abs/2506.06622)
> *QuantMCP：将大型语言模型植根于可验证的金融现实*

*Yifan Zeng* | **Main category: cs.CE**

**Keywords:** 大型语言模型, 金融分析, QuantMCP, 模型上下文协议, 金融数据API

**Comment:** 

> **TL;DR:** QuantMCP是一个新颖的框架，通过利用模型上下文协议（MCP），使大型语言模型（LLMs）能够与金融数据API准确交互，从而克服幻觉问题并支持更明智的金融决策。

**AI_Comments:** QuantMCP的创新之处在于它为大型语言模型提供了一个可靠的机制，使其能够访问和利用实时的、可验证的金融数据，从而有效解决LLM在金融领域应用中常见的幻觉问题。通过结合MCP和金融API，它为LLM在金融分析和决策中的实际应用奠定了坚实的基础，显著提升了其可靠性和洞察力。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在金融分析和决策方面潜力巨大，但其直接应用常受限于数据幻觉和缺乏实时、可验证的金融信息。

**Method:** 本文介绍了QuantMCP，一个旨在将LLMs严格植根于金融现实的新颖框架。它通过利用模型上下文协议（MCP）进行标准化和安全的工具调用，使LLMs能够准确地与各种Python可访问的金融数据API（如Wind、yfinance）进行交互。

**Result:** 用户可以通过自然语言精确检索最新的金融数据，从而克服LLM在事实数据回忆方面的固有局限性。一旦获得这些经过验证的结构化数据，LLM的分析能力将被解锁，使其能够执行复杂的数据解释、生成见解，并最终支持更明智的金融决策过程。

**Conclusion:** QuantMCP在会话式AI和复杂的金融数据世界之间提供了一个健壮、可扩展且安全的桥梁，旨在增强金融领域LLM应用的可靠性和分析深度。

> **ai_Abstract:** QuantMCP是一个旨在解决大型语言模型（LLMs）在金融应用中数据幻觉和缺乏实时数据问题的框架。它通过利用模型上下文协议（MCP）与金融数据API（如Wind、yfinance）接口，使用户能通过自然语言检索准确的金融数据。这不仅克服了LLM在事实回忆上的限制，还解锁了其分析能力，支持更复杂的数据解释和决策，从而提升LLM在金融领域的可靠性和分析深度。

> **摘要翻译:** 大型语言模型（LLMs）在革新金融分析和决策方面具有巨大潜力，但其直接应用常常受到数据幻觉以及缺乏实时、可验证金融信息等问题的阻碍。本文介绍了QuantMCP，一个旨在将LLMs严格植根于金融现实的新颖框架。通过利用模型上下文协议（MCP）进行标准化和安全的工具调用，QuantMCP使LLMs能够准确地与各种Python可访问的金融数据API（例如Wind、yfinance）进行接口。用户可以通过自然语言进行交互，精确检索最新的金融数据，从而克服LLM在事实数据回忆方面的固有局限性。更关键的是，一旦获得了这些经过验证的结构化数据，LLM的分析能力将被解锁，使其能够执行复杂的数据解释、生成见解，并最终支持更明智的金融决策过程。QuantMCP在会话式AI和复杂的金融数据世界之间提供了一个健壮、可扩展且安全的桥梁，旨在增强金融领域LLM应用的可靠性和分析深度。

</details>

[⬆️ 返回分类顶部](#csce) | [⬆️ 返回总目录](#toc)

---

<a id='nlincg'></a>
## nlin.CG 

### [2] [Elementary Cellular Automata as Non-Cryptographic Hash Functions](https://arxiv.org/abs/2506.06551)
> *基本元胞自动机作为非加密哈希函数*

*Daniel McKinley* | **Main category: nlin.CG**

**Keywords:** 基本元胞自动机, 非加密哈希函数, 误差最小化, 有损压缩, 边缘检测

**Comment:** 

> **TL;DR:** 本文将基本元胞自动机（ECA）实现为非加密哈希函数，并发现10种规则具有误差最小化、最大化、唯一解、有损逆、高效追溯哈希以及边缘检测应用等特性。

**AI_Comments:** 这项工作展示了基本元胞自动机在非加密哈希函数领域的潜在应用，特别是其在数据压缩和图像处理（如边缘检测）方面的能力。算法与传统变换的并行性可能意味着其具有计算效率。然而，其非加密性质限制了其在安全敏感应用中的使用。

<details>
  <summary>Details</summary>

**Motivation:** Not mentioned in abstract

**Method:** 本文将256种基本元胞自动机（ECA）中的10种实现为哈希函数。该实现采用在4x4环绕邻域单元上运行的误差最小化有损压缩算法。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套2的幂结构并行，并用Java实现，旨在对任何2字节RGB代码位图进行哈希处理。

**Result:** 在处理所有256种规则后，发现在两个8个子集中有10种规则具有误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及应用于边缘检测等特性。

**Conclusion:** 本文成功将部分基本元胞自动机实现为非加密哈希函数，并发现特定规则具有可用于数据处理和图像分析（如边缘检测）的理想属性。

> **ai_Abstract:** 本文将256种基本元胞自动机（ECA）中的10种作为非加密哈希函数进行实现，利用误差最小化有损压缩算法处理环绕的4x4邻域单元。研究发现，有10种规则表现出误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及边缘检测应用等特性。该算法结构类似于快速傅里叶变换，并用Java实现，可对2字节RGB位图进行哈希处理。

> **摘要翻译:** 本文将256种基本元胞自动机（ECA）中的10种实现为哈希函数，该实现采用在4x4环绕邻域单元上运行的误差最小化有损压缩算法。所有256种规则都经过处理，发现在两个8个子集中有10种规则具有误差最小化和最大化、唯一解、有损逆、高效追溯哈希以及应用于边缘检测等特性。该算法与快速傅里叶变换和快速沃尔什-哈达玛变换的嵌套2的幂结构并行，并用Java实现，旨在对任何2字节RGB代码位图进行哈希处理。

</details>

[⬆️ 返回分类顶部](#nlincg) | [⬆️ 返回总目录](#toc)

---

<a id='cscl'></a>
## cs.CL 

### [3] [Language Models over Canonical Byte-Pair Encodings](https://arxiv.org/abs/2506.07956)
> *基于规范字节对编码的语言模型*

*Tim Vieira, Tianyu Liu, Clemente Pasti, Yahya Emara, Brian DuSell, Benjamin LeBrun, Mario Giulianelli, Juan Luis Gastaldi, Timothy J. O'Donnell, Ryan Cotterell* | **Main category: cs.CL**

**Keywords:** 语言模型, 字节对编码, 分词, 规范性, 概率分布

**Comment:** ICML 2025

> **TL;DR:** 语言模型在处理字节对编码时会为无效的token序列分配概率，本文提出了两种方法来强制规范性，从而提高模型性能。

**AI_Comments:** 这篇论文解决了现代语言模型在处理字节对编码时一个基本但常被忽视的问题。通过确保只有有效的token序列被赋予概率，它使得模型更加高效和准确，这对于大规模模型尤为重要。提出的两种方法，一种无需重新训练，另一种通过模型设计保证，为解决实际问题提供了灵活的方案，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现代语言模型使用确定性分词器（如字节对编码）将字符字符串表示为token字符串的分布。然而，它们当前存在一个问题：模型会为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量。这些非规范编码在确定性分词器下是不可能的，也永远不会出现在训练语料库中。这种错误的分配既是错误的，因为它从未出现在训练数据中，也是浪费的，因为它将概率质量从合理的输出中转移出去。

**Method:** 本文提出了两种方法来强制token级语言模型中的规范性，确保只有规范的token字符串被赋予正概率：
1.  通过条件作用实现规范性：利用测试时推理策略，无需额外训练。
2.  通过构建实现规范性：一种模型参数化，保证规范输出，但需要训练。

**Result:** 实验表明，纠正规范性错误可以提高多个模型和语料库在保留数据上的似然性。

**Conclusion:** 通过强制语言模型仅将正概率分配给规范的token字符串，可以避免概率质量的错误分配和浪费，从而显著提高模型在未见数据上的似然性。

> **ai_Abstract:** 现代语言模型在处理字节对编码时，会错误地为“非规范”的token编码分配概率质量，这既不合理又浪费。本文提出了两种方法来解决这一问题：一是通过测试时推理策略进行“条件性规范化”，无需额外训练；二是通过模型参数化进行“构建性规范化”，需要训练。实验结果表明，这些方法能够有效纠正规范性错误，并提高模型在保留数据上的似然性。

> **摘要翻译:** 现代语言模型将字符字符串的概率分布表示为通过确定性分词器（例如字节对编码）派生出的（较短的）token字符串的分布。虽然这种方法在将语言模型扩展到大型语料库方面非常有效，但其目前的实现方式有一个令人担忧的特性：模型会为每个字符字符串的指数级数量的“非规范”token编码分配非零概率质量——这些token字符串解码为有效的字符字符串，但在确定性分词器下是不可能的（即，无论语料库多大，它们都不会出现在任何训练语料库中）。这种错误分配既是错误的，因为非规范字符串从未出现在训练数据中，也是浪费的，因为它将概率质量从合理的输出中转移出去。这些都是可以避免的错误！在这项工作中，我们提出了在token级语言模型中强制规范性的方法，确保只有规范的token字符串被赋予正概率。我们提出了两种方法：(1) 通过条件作用实现规范性，利用测试时推理策略，无需额外训练；(2) 通过构建实现规范性，这是一种模型参数化，保证规范输出，但需要训练。我们证明，纠正规范性错误可以提高多个模型和语料库在保留数据上的似然性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [85] [PolitiSky24: U.S. Political Bluesky Dataset with User Stance Labels](https://arxiv.org/abs/2506.07606)
> *PolitiSky24：带有用户立场标签的美国政治Bluesky数据集*

*Peyman Rostami, Vahid Rahimzadeh, Ali Adibi, Azadeh Shakery* | **Main category: cs.CL**

**Keywords:** 政治立场检测, Bluesky, 用户级立场, 数据集, 大型语言模型

**Comment:** The dataset is available at https://doi.org/10.5281/zenodo.15616911

> **TL;DR:** 提出了PolitiSky24，这是首个针对2024年美国大选的Bluesky用户级政治立场检测数据集，包含16,044个用户-目标立场对，通过结合信息检索和大型语言模型实现81%的标注准确率。

**AI_Comments:** 该论文的创新之处在于它是首个针对新兴平台Bluesky的用户级政治立场数据集，并专注于2024年美国大选，具有高度的及时性。其采用结合信息检索和大型语言模型的标注方法，并提供理由和文本跨度以提高透明度，这在立场检测领域是一个重要的进步。该数据集填补了用户级立场检测资源的空白，对于研究新兴社交媒体平台上的政治观点具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有的立场检测数据集主要关注推文级别和传统平台，而Bluesky等新兴平台的用户级立场资源稀缺。用户级立场检测能提供更全面的视角，考虑用户完整的发布历史而非孤立的帖子。

**Method:** PolitiSky24数据集通过精心评估的流程创建，该流程结合了高级信息检索和大型语言模型（LLMs），生成带有支持理由和文本跨度的立场标签以提高透明度。

**Result:** PolitiSky24是首个针对2024年美国总统选举的Bluesky立场检测数据集，包含16,044个用户-目标立场对，并丰富了参与度元数据、交互图和用户发布历史。该标注方法的准确率达到81%。

**Conclusion:** PolitiSky24数据集通过其及时性、开放数据性质和用户级视角，弥补了政治立场分析中用户级和新兴平台数据资源的空白。

> **ai_Abstract:** 本文介绍了PolitiSky24，这是一个针对2024年美国总统选举的Bluesky平台用户级政治立场检测数据集。该数据集克服了现有研究主要关注推文级别和传统平台而缺乏新兴平台用户级资源的不足。PolitiSky24包含16,044个针对卡马拉·哈里斯和唐纳德·特朗普的用户-目标立场对，并提供了丰富的元数据。数据集通过结合信息检索和大型语言模型构建，其标注方法达到了81%的准确率。该资源为政治立场分析提供了及时、开放且用户级的宝贵数据。

> **摘要翻译:** 立场检测旨在识别文本中针对特定目标（如政治人物）表达的观点。虽然以前的数据集主要关注来自已建立平台的推文级别立场，但用户级别立场资源，尤其是在Bluesky等新兴平台上，仍然稀缺。用户级别立场检测通过考虑用户的完整发布历史而非孤立的帖子，提供更全面的视角。我们提出了第一个针对2024年美国总统选举的立场检测数据集，该数据集从Bluesky收集，并以卡马拉·哈里斯和唐纳德·特朗普为中心。该数据集包含16,044个用户-目标立场对，并丰富了参与度元数据、交互图和用户发布历史。PolitiSky24是使用精心评估的管道创建的，该管道结合了高级信息检索和大型语言模型，生成带有支持理由和文本跨度的立场标签，以提高透明度。该标注方法使用可扩展的LLM实现了81%的准确率。该资源通过其及时性、开放数据性质和用户级别视角解决了政治立场分析中的空白。该数据集可在https://doi.org/10.5281/zenodo.15616911获取。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [216] [Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights](https://arxiv.org/abs/2506.06404)
> *价值对齐大型语言模型的意外危害：心理学和实证洞察*

*Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak* | **Main category: cs.CL**

**Keywords:** 价值对齐LLMs, 安全风险, 有害行为, 心理学洞察, 上下文对齐

**Comment:** Accepted to ACL 2025

> **TL;DR:** 本文揭示了价值对齐的大型语言模型（LLMs）可能无意中产生有害内容，甚至比未微调模型风险更高，因为它会真正地按照对齐的价值观生成文本，从而放大有害结果。

**AI_Comments:** 这篇论文揭示了价值对齐大型语言模型潜在的“双刃剑”效应，即为了追求个性化和价值观对齐，模型可能在无意中放大有害内容。其创新之处在于不仅从实证角度验证了这一风险，还深入探讨了其背后的心理学机制，并提出了“黑箱”洞察。这对于LLM的安全性和负责任的AI发展具有重要意义，提醒开发者在追求对齐的同时，必须警惕并解决随之而来的潜在危害。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）的应用范围不断扩大，人们对与人类价值观对齐的个性化LLMs越来越感兴趣。然而，将这些模型与个人价值观对齐引发了重大的安全担忧，因为某些价值观可能与有害信息相关联。

**Method:** 本文识别了与价值对齐LLMs相关的特定安全风险，并调查了这些挑战背后的心理学原理。研究使用了包含详细安全类别的数据集，并结合心理学假设来发现价值对齐与安全风险之间的显著关联。

**Result:** 研究发现两个关键洞察：(1) 价值对齐LLMs比未微调模型更容易产生有害行为，并且在传统安全评估中比其他微调模型表现出略高的风险。(2) 这些安全问题之所以出现，是因为价值对齐LLMs确实按照对齐的价值观生成文本，这会放大有害结果。研究发现了价值对齐与安全风险之间的显著关联。

**Conclusion:** 本研究深入探讨了价值对齐的“黑箱”，并提出了上下文对齐方法以增强价值对齐LLMs的安全性。

> **ai_Abstract:** 随着大型语言模型（LLMs）的普及，个性化和价值对齐的LLMs受到关注。然而，本文指出价值对齐可能带来意想不到的安全风险，因为某些价值观可能与有害信息相关。研究发现，价值对齐LLMs比未微调模型更容易产生有害内容，甚至比其他微调模型风险更高，原因在于它们会忠实地按照对齐的价值观生成文本，从而放大潜在的有害结果。通过详细的安全数据集和心理学假设，研究揭示了价值对齐与安全风险之间的显著关联，为理解价值对齐的“黑箱”提供了洞察，并提出了上下文对齐的安全增强方法。

> **摘要翻译:** 大型语言模型（LLMs）的应用范围持续扩大，导致人们对与人类价值观对齐的个性化LLMs的兴趣日益增加。然而，将这些模型与个人价值观对齐引发了重大的安全担忧，因为某些价值观可能与有害信息相关联。在本文中，我们识别了与价值对齐LLMs相关的特定安全风险，并调查了这些挑战背后的心理学原理。我们的发现揭示了两个关键洞察。(1) 价值对齐LLMs比未微调模型更容易产生有害行为，并且在传统安全评估中比其他微调模型表现出略高的风险。(2) 这些安全问题之所以出现，是因为价值对齐LLMs确实按照对齐的价值观生成文本，这会放大有害结果。使用包含详细安全类别的数据集，我们发现价值对齐与安全风险之间存在显著关联，并得到了心理学假设的支持。这项研究为价值对齐的“黑箱”提供了洞察，并提出了上下文对齐方法以增强价值对齐LLMs的安全性。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [220] [Can LLMs Generate Reliable Test Case Generators? A Study on Competition-Level Programming Problems](https://arxiv.org/abs/2506.06821)
> *LLMs能否生成可靠的测试用例生成器？一项关于竞赛级编程问题的研究*

*Yuhan Cao, Zian Chen, Kun Quan, Ziliang Zhang, Yu Wang, Xiaoning Dong, Yeqi Feng, Guanzhong He, Jingcheng Huang, Jianhao Li, Yixuan Tan, Jiafu Tang, Yilin Tang, Junlei Wu, Qianyu Xiao, Can Zheng, Shouchen Zhou, Yuxiang Zhu, Yiming Huang, Tian Xie, Tianxing He* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 测试用例生成, 竞赛级编程, 代码调试, TCGBench

**Comment:** 37 pages, 22 figures

> **TL;DR:** 大型语言模型（LLMs）在生成有效测试用例生成器方面表现良好，但在生成针对性测试用例以发现人类代码缺陷方面仍远低于人类水平。

**AI_Comments:** 这篇论文创新性地将LLMs应用于竞赛级编程问题的测试用例生成，并区分了“有效”和“有针对性”两种生成任务，揭示了LLMs在发现代码缺陷方面的局限性。其提出的TCGBench基准和高质量数据集对于未来研究LLMs在代码调试和验证领域的应用具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在代码生成方面展现出卓越能力，但其在通过测试用例生成进行代码检查或调试方面的潜力仍未被充分探索。

**Method:** 本研究提出了TCGBench，一个用于评估LLM生成测试用例生成器的基准。该基准包含两项任务：1) 为给定竞赛级编程问题生成有效的测试用例生成器；2) 生成能揭示人类编写代码错误的有针对性测试用例生成器。此外，研究构建了一个高质量、手动整理的指令数据集，并发现通过提示和微调可提升LLM性能。

**Result:** 实验结果表明，最先进的LLMs在大多数情况下可以生成有效的测试用例生成器。然而，大多数LLMs在有效生成揭示人类代码缺陷的有针对性测试用例方面存在困难，即使是先进的推理模型（如o3-mini）也远低于人类表现。分析还表明，利用构建的高质量数据集，LLM的性能可以通过提示和微调得到增强。

**Conclusion:** LLMs在生成通用测试用例生成器方面有潜力，但在生成能够有效发现代码缺陷的针对性测试用例方面仍需显著改进，且当前表现远不及人类。高质量的数据集有助于提升LLMs在此方面的能力。

> **ai_Abstract:** 本研究探讨了大型语言模型（LLMs）在生成竞赛级编程问题测试用例生成器方面的能力。研究提出了TCGBench基准，用于评估LLMs生成有效及针对性测试用例生成器的性能。结果显示，LLMs能生成有效测试用例，但在发现人类代码缺陷的针对性测试用例生成方面表现不佳，远低于人类水平。研究还发现，通过高质量数据集进行提示和微调可以提升LLMs的性能。

> **摘要翻译:** 大型语言模型（LLMs）在代码生成方面展现出卓越的能力，能够在推理过程中处理复杂的任务。然而，LLMs在多大程度上能够通过测试用例生成来用于代码检查或调试，这在很大程度上仍未被探索。我们从竞赛级编程（CP）程序的角度研究了这个问题，并提出了TCGBench，一个用于（LLM生成）测试用例生成器的基准。该基准包含两项任务，旨在研究LLMs在以下方面的能力：(1) 为给定的CP问题生成有效的测试用例生成器，以及进一步 (2) 生成有针对性的测试用例生成器，以揭示人类编写代码中的错误。实验结果表明，尽管最先进的LLMs在大多数情况下可以生成有效的测试用例生成器，但大多数LLMs在有效生成能够揭示人类代码缺陷的有针对性测试用例方面存在困难。特别是，即使是先进的推理模型（例如o3-mini）在生成有针对性的生成器任务中也远低于人类表现。此外，我们构建了一个高质量、手动整理的指令数据集，用于生成有针对性的生成器。分析表明，通过提示和微调，借助该数据集可以增强LLMs的性能。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [239] [BTPD: A Multilingual Hand-curated Dataset of Bengali Transnational Political Discourse Across Online Communities](https://arxiv.org/abs/2506.06813)
> *BTPD：一个多语言、人工整理的孟加拉语跨国政治话语在线社区数据集*

*Dipto Das, Syed Ishtiaque Ahmed, Shion Guha* | **Main category: cs.CL**

**Keywords:** 孟加拉语, 政治话语, 数据集, 多语言, 在线社区

**Comment:** 

> **TL;DR:** 本文介绍了BTPD，一个用于孟加拉语跨国政治话语分析的多语言人工整理数据集，旨在解决该领域数据稀缺的问题。

**AI_Comments:** 该论文通过创建BTPD数据集，解决了孟加拉语等资源不足语言在政治话语分析领域的数据稀缺问题，为理解这些语言的在线政治讨论和意识形态两极分化提供了重要的基础资源，具有显著的实用价值和创新性。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究在英语政治话语分析方面进展显著，但在孟加拉语等资源不足的语言中，由于缺乏可用数据集，研究工作受到严重限制。

**Method:** 通过社区知情的关键词检索方法，从三个具有不同社区结构和互动动态的在线平台中人工整理并收集了BTPD数据集。

**Result:** 论文介绍了BTPD数据集，并提供了其主题和多语言内容的概览。

**Conclusion:** 论文成功地提出了一个用于分析孟加拉语跨国政治话语的多语言数据集BTPD，填补了该领域的数据空白。

> **ai_Abstract:** 本文介绍了BTPD，一个专门为孟加拉语跨国政治话语分析而创建的多语言、人工整理数据集。该数据集从三个在线平台收集，旨在弥补孟加拉语等资源不足语言在政治话语研究中缺乏数据的空白。论文详细描述了数据集的整理过程，并概述了其包含的主题和多语言内容。

> **摘要翻译:** 理解在线空间中的政治话语对于分析公众舆论和意识形态两极分化至关重要。虽然社会计算和计算语言学已经探索了英语中的此类讨论，但由于缺乏数据集，孟加拉语等主要但资源不足的语言中的此类研究工作受到严重限制。在本文中，我们提出了一个多语言的孟加拉语跨国政治话语（BTPD）数据集，该数据集从三个在线平台收集，每个平台都代表着独特的社区结构和互动动态。除了描述我们如何通过社区知情的关键词检索方法人工整理数据集之外，本文还提供了其主题和多语言内容的概览。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [248] [How do datasets, developers, and models affect biases in a low-resourced language?](https://arxiv.org/abs/2506.06816)
> *数据集、开发者和模型如何影响低资源语言中的偏见？*

*Dipto Das, Shion Guha, Bryan Semaan* | **Main category: cs.CL**

**Keywords:** 低资源语言, 偏见, 孟加拉语, 情感分析, 算法审计

**Comment:** 

> **TL;DR:** 本文经验性地测试了在孟加拉语（一种低资源语言）中，针对性别、宗教和国籍身份的偏见，通过使用特定语言模型和多语言支持来解决这些偏见的效果。研究发现，即使语义内容和结构相似，孟加拉语情感分析模型仍表现出偏见。

**AI_Comments:** 本文针对低资源语言中的偏见问题进行了重要的实证研究，填补了该领域研究不足的空白。其创新之处在于通过算法审计具体分析了数据集、开发者和模型对偏见的影响，并将其与更宏观的认知不正义和AI对齐问题相结合，具有重要的理论和实践意义。研究结果揭示了即使在语义相似的情况下，模型仍可能存在偏见，这对于开发更公平的AI系统具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 语言技术等社会技术系统常表现出基于身份的偏见，这加剧了历史上被边缘化社区的经历，且在低资源语境中研究不足。尽管通常建议使用特定语言或多语言支持的模型和数据集来解决这些偏见，但这些方法的有效性尚未得到充分的实证检验。

**Method:** 研究对基于mBERT和BanglaBERT构建的情感分析模型进行了算法审计，这些模型使用Google Dataset Search中的所有孟加拉语情感分析（BSA）数据集进行了微调。分析了不同身份类别（性别、宗教、国籍）的偏见，并检查了结合预训练模型和由不同人口背景的个人创建的数据集所产生的不一致性和不确定性。

**Result:** 分析表明，尽管语义内容和结构相似，BSA模型在不同身份类别中表现出偏见。研究还发现，结合由不同人口背景的个人创建的预训练模型和数据集会导致不一致性和不确定性。

**Conclusion:** 研究结果与关于认知不正义、AI对齐以及算法审计中方法论决策的更广泛讨论相关联。

> **ai_Abstract:** 本文实证研究了在低资源语言孟加拉语中，数据集、开发者和模型如何影响基于性别、宗教和国籍的偏见。通过对使用mBERT和BanglaBERT构建的情感分析模型进行算法审计，并利用所有孟加拉语情感分析数据集进行微调，研究发现这些模型在不同身份类别中存在偏见，即使语义内容和结构相似。同时，文章还探讨了结合不同背景的预训练模型和数据集所导致的不一致性，并将这些发现与认知不正义、AI对齐及算法审计的方法论决策等更广泛的议题联系起来。

> **摘要翻译:** 社会技术系统，如语言技术，经常表现出基于身份的偏见。这些偏见加剧了历史上被边缘化社区的经历，并且在低资源环境中仍未得到充分研究。尽管通常建议使用特定语言或多语言支持的模型和数据集来解决这些偏见，但本文在孟加拉语（一种广泛使用但资源匮乏的语言）中，针对性别、宗教和国籍身份，实证检验了此类方法的有效性。我们对基于mBERT和BanglaBERT构建的情感分析模型进行了算法审计，这些模型使用Google Dataset Search中的所有孟加拉语情感分析（BSA）数据集进行了微调。我们的分析表明，尽管语义内容和结构相似，BSA模型在不同身份类别中表现出偏见。我们还检查了结合预训练模型和由不同人口背景的个人创建的数据集所产生的不一致性和不确定性。我们将这些发现与关于认知不正义、AI对齐和算法审计中方法论决策的更广泛讨论联系起来。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [264] [Reward Model Interpretability via Optimal and Pessimal Tokens](https://arxiv.org/abs/2506.07326)
> *奖励模型通过最优和最差令牌的可解释性研究*

*Brian Christian, Hannah Rose Kirk, Jessica A. F. Thompson, Christopher Summerfield, Tsvetomira Dumbalska* | **Main category: cs.CL**

**Keywords:** 奖励模型, 可解释性, 偏见, 大型语言模型, 价值对齐

**Comment:** Accepted for publication in Proceedings of the 2025 ACM Conference on
  Fairness, Accountability, and Transparency (FAccT '25), to appear June 2025

> **TL;DR:** 本文通过对奖励模型在整个词汇空间中的响应进行穷尽分析，揭示了奖励模型在编码人类价值判断方面存在显著的异质性、不对称性、对提示语的敏感性和对高频词的偏爱，并发现其可能存在有害偏见，挑战了奖励模型作为人类价值代理的适用性。

**AI_Comments:** 这篇论文的创新之处在于它将研究重点从奖励模型作为微调工具转向了奖励模型本身的可解释性，揭示了其内部运作机制和潜在偏见。其重要性在于，它对奖励模型作为人类价值代理的可靠性提出了质疑，并揭示了即使是“无害性训练”也可能导致有害偏见的产生和传播，这对未来大型语言模型的开发和部署具有重要的指导意义。论文通过系统性分析，提供了具体的证据来支持其发现，这对于理解和改进奖励模型至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 奖励模型在使大型语言模型与人类价值观对齐方面至关重要，但其本身作为直接编码人类价值判断的工具，却相对未被充分研究。

**Method:** 提出了一种新的奖励模型可解释性方法，通过对奖励模型在整个词汇空间中的响应进行穷尽分析。具体而言，研究了不同奖励模型如何对每个可能的单令牌响应进行评分，以响应含有价值判断的提示语。

**Result:** 1. 训练目标相似的模型之间存在显著异质性。
2. 模型在编码高分和低分令牌方面存在系统性不对称。
3. 模型对提示语的敏感性显著，这与人类认知偏见相似。
4. 模型过高评价更频繁的令牌。
5. 这些模型可能对某些身份群体编码了令人担忧的偏见，这可能是无害性训练的意外后果。

**Conclusion:** 研究结果挑战了奖励模型可互换性的假设，以及它们作为复杂和依赖上下文的人类价值观代理的适用性。这些模型可能编码了对某些身份群体的偏见，这种扭曲可能通过下游的大型语言模型传播。

> **ai_Abstract:** 本研究通过对奖励模型在整个词汇空间中的响应进行穷尽分析，提出了一种新颖的奖励模型可解释性方法。通过评估不同奖励模型对价值导向提示的单令牌响应评分，揭示了模型间的显著异质性、对高低分令牌编码的系统性不对称、对提示语框定的敏感性（类似人类认知偏见）以及对高频令牌的过高评价。研究结果挑战了奖励模型的可互换性及其作为复杂人类价值观代理的适用性，并指出这些模型可能无意中编码了对特定身份群体的偏见，存在将这些偏见传播到下游大型语言模型的风险。

> **摘要翻译:** 奖励建模已成为使大型语言模型与人类价值观对齐的关键组成部分。人们将大量注意力集中在将奖励模型用作微调生成模型的方法。然而，奖励模型本身——它们通过将提示-响应对转化为标量奖励来直接编码人类价值判断——却相对未被充分研究。我们提出了一种通过对其在整个词汇空间中的响应进行穷尽分析来解释奖励模型的新方法。通过检查不同的奖励模型如何对价值导向提示的每个可能的单令牌响应进行评分，我们发现了一些惊人的发现：(i) 训练目标相似的模型之间存在显著异质性，(ii) 模型在编码高分和低分令牌方面存在系统性不对称，(iii) 模型对提示语的敏感性显著，这与人类认知偏见相似，以及 (iv) 模型过高评价更频繁的令牌。我们展示了这些效应在十个最近的开源奖励模型中（参数数量和架构各不相同）。我们的结果挑战了奖励模型可互换性的假设，以及它们作为复杂和依赖上下文的人类价值观代理的适用性。我们发现这些模型可能对某些身份群体编码了令人担忧的偏见，这可能是无害性训练的意外后果——这种扭曲有传播到当前部署给数百万用户的大型语言模型中的风险。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [289] [Correlated Errors in Large Language Models](https://arxiv.org/abs/2506.07962)
> *大型语言模型中的相关错误*

*Elliot Kim, Avi Garg, Kenny Peng, Nikhil Garg* | **Main category: cs.CL**

**Keywords:** 大型语言模型, 错误相关性, 算法单一文化, 实证评估, 模型多样性

**Comment:** Accepted to ICML 2025

> **TL;DR:** 研究发现不同大型语言模型的错误高度相关，即使架构和提供商不同，尤其是在大型高精度模型中，这会影响下游任务。

**AI_Comments:** 这项研究揭示了大型语言模型领域一个重要的未被充分认识的问题：模型错误的高度相关性。这挑战了多样性必然带来差异的普遍假设，并对LLM的鲁棒性和公平性提出了新的担忧，尤其是在关键的下游应用中。其发现“算法单一文化”的潜在影响具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 普遍认为训练数据、架构和提供商的多样性可以减轻大型语言模型（LLM）的同质性，但缺乏实证证据证明不同LLM是否存在有意义的差异。

**Method:** 对350多个大型语言模型进行了大规模实证评估，使用了两个流行的排行榜和一个简历筛选任务。

**Result:** 发现模型错误存在显著相关性；在一个排行榜数据集上，当两个模型都出错时，它们有60%的时间错误一致；识别出导致模型相关性的因素，包括共享架构和提供商；更大、更准确的模型即使架构和提供商不同，其错误也高度相关；展示了相关性在LLM作为评估者和招聘这两个下游任务中的影响，后者反映了算法单一文化的理论预测。

**Conclusion:** 大型语言模型的错误存在显著相关性，即使在多样化的模型中也是如此，这可能导致下游任务中的问题，并支持算法单一文化的理论。

> **ai_Abstract:** 本文通过对350多个大型语言模型（LLM）进行大规模实证评估，发现不同LLM的错误存在显著相关性，即使模型架构和提供商多样化，特别是对于更大、更准确的模型。这种错误相关性会影响LLM作为评估者和招聘等下游任务，揭示了潜在的“算法单一文化”问题。

> **摘要翻译:** 训练数据、架构和提供商的多样性被认为可以减轻大型语言模型 (LLM) 中的同质性。然而，我们缺乏关于不同LLM是否真正存在有意义差异的实证证据。我们对总共350多个LLM进行了大规模实证评估，使用了两个流行的排行榜和一个简历筛选任务。我们发现模型错误存在显著相关性——在一个排行榜数据集上，当两个模型都出错时，它们有60%的时间错误一致。我们识别了导致模型相关性的因素，包括共享架构和提供商。然而，至关重要的是，更大、更准确的模型即使架构和提供商不同，其错误也高度相关。最后，我们展示了相关性在两个下游任务中的影响：LLM作为评估者的评估和招聘——后者反映了关于算法单一文化的理论预测。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [299] [How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG](https://arxiv.org/abs/2506.06331)
> *实际性能提升有多大？一个用于GraphRAG的无偏评估框架*

*Qiming Zeng, Xiao Yan, Hao Luo, Yuhao Lin, Yuxiang Wang, Fangcheng Fu, Bo Du, Quanqing Xu, Jiawei Jiang* | **Main category: cs.CL**

**Keywords:** GraphRAG, 评估框架, 偏差, 大型语言模型, 知识图谱图谱

**Comment:** 

> **TL;DR:** 当前GraphRAG评估存在不相关问题和评估偏差两大缺陷，导致性能结论可能不准确。本文提出了一个无偏评估框架，通过图文结合的问题生成和无偏评估程序来解决这些问题。应用该框架发现，现有GraphRAG方法的实际性能提升远比之前报告的要温和。

**AI_Comments:** 这篇论文通过揭示并解决GraphRAG评估中存在的关键方法论缺陷，做出了重要贡献。它提出了一个无偏框架，挑战了现有的性能主张，并推动了更严谨的科学实践，这对于GraphRAG研究的健康发展至关重要。其对评估有效性的关注是一个重要的创新点。

<details>
  <summary>Details</summary>

**Motivation:** 当前的GraphRAG答案评估框架存在两个关键缺陷：不相关的问题和评估偏差。这些缺陷可能导致对性能的偏颇甚至错误的结论，从而无法准确衡量GraphRAG方法的真实效果。

**Method:** 本文提出了一个无偏评估框架，包含两部分：1. 使用图文结合的问题生成来产生与底层数据集更相关的问题。2. 采用无偏评估程序来消除基于LLM的答案评估中的偏差。

**Result:** 将提出的无偏框架应用于评估3种代表性的GraphRAG方法后发现，它们的性能提升远比之前报告的要温和。

**Conclusion:** 尽管提出的评估框架可能仍有缺陷，但它强调了进行科学评估的必要性，以期为GraphRAG研究奠定坚实的基础，并指出之前报告的性能可能被高估。

> **ai_Abstract:** 本文指出了当前GraphRAG性能评估框架中存在的关键缺陷（不相关问题和评估偏差），这些缺陷可能导致夸大的性能声明。为此，论文提出了一个无偏评估框架，该框架结合了图文结合的问题生成和无偏评估程序。通过将此新框架应用于三种代表性的GraphRAG方法，研究发现它们的实际性能提升远比之前报告的要温和，从而强调了GraphRAG研究中严格科学评估的必要性。

> **摘要翻译:** 通过从知识图中检索上下文，基于图的检索增强生成（GraphRAG）增强了大型语言模型（LLMs），以生成高质量的用户问题答案。许多GraphRAG方法已被提出，并报告了令人鼓舞的答案质量性能。然而，我们观察到当前GraphRAG的答案评估框架存在两个关键缺陷，即不相关的问题和评估偏差，这可能导致对性能的偏颇甚至错误的结论。为了解决这两个缺陷，我们提出了一个无偏评估框架，该框架使用图文结合的问题生成来产生与底层数据集更相关的问题，并采用无偏评估程序来消除基于LLM的答案评估中的偏差。我们将我们的无偏框架应用于评估3种代表性的GraphRAG方法，发现它们的性能提升远比之前报告的要温和。尽管我们的评估框架可能仍有缺陷，但它呼吁进行科学评估，为GraphRAG研究奠定坚实的基础。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [348] [TESU-LLM: Training Speech-LLMs Without Speech via Unified Encoder Alignment](https://arxiv.org/abs/2506.06343)
> *TESU-LLM：通过统一编码器对齐实现无需语音的语音-LLM训练*

*Taesoo Kim, Jong Hwan Ko* | **Main category: cs.CL**

**Keywords:** 语音-LLM, 统一编码器, 仅文本训练, 潜在空间对齐, 可扩展性

**Comment:** 

> **TL;DR:** TESU-LLM提出了一种新颖的框架，仅使用文本数据即可训练具备语音能力的LLM。它通过统一编码器将文本和语音输入映射到共享潜在空间，并与LLM的嵌入空间对齐，从而在语音相关基准测试上取得了与传统方法相当的强大性能，解决了大规模语音数据和计算资源依赖的挑战。

**AI_Comments:** 本文提出了一种创新方法，克服了训练语音使能LLM时数据稀缺和计算负担的挑战。通过将语音数据与训练过程解耦，TESU-LLM显著增强了此类模型的可扩展性和可访问性。统一编码器对齐以实现仅文本监督的核心思想对于未来在有限数据下进行多模态学习的研究具有重要影响。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语音使能语言模型依赖于大规模配对的语音-文本数据和大量的计算资源，这在可扩展性和可访问性方面带来了挑战。

**Method:** TESU-LLM框架利用一个统一编码器，将语义等效的文本和语音输入映射到共享的潜在空间。通过一个轻量级投影网络将编码器输出与大型语言模型的嵌入空间对齐，使得模型能够从仅文本监督泛化到基于语音的推理。

**Result:** 尽管完全仅用文本进行训练，TESU-LLM 在各种语音相关基准测试上取得了强大性能，与使用大规模多模态数据集和大量计算资源训练的基线方法相当。

**Conclusion:** TESU-LLM 方法有效且高效，为无需语音数据即可构建语音大型语言模型提供了一条可扩展的路径。

> **ai_Abstract:** TESU-LLM提出了一种新颖的框架，旨在解决现有语音LLM对大规模语音-文本数据和计算资源的高度依赖问题。该方法通过一个统一编码器将文本和语音输入映射到共享潜在空间，并利用轻量级投影网络与LLM的嵌入空间对齐，从而仅利用文本数据训练出具备语音能力的LLM。实验结果表明，TESU-LLM在多个语音相关基准测试上表现出色，性能可与传统上需要大量多模态数据和计算资源训练的模型媲美，为构建可扩展的语音LLM提供了有效途径。

> **摘要翻译:** 标题：TESU-LLM：通过统一编码器对齐实现无需语音的语音-LLM训练

摘要：近年来，语音支持的语言模型在构建智能语音助手方面取得了可喜的进展。然而，大多数现有方法依赖于大规模配对的语音-文本数据和大量的计算资源，这在可扩展性和可访问性方面带来了挑战。在本文中，我们提出了 **TESU-LLM**，一个新颖的框架，它使得仅使用文本数据即可训练具备语音能力的语言模型。我们的关键洞察是利用一个统一编码器，将语义等效的文本和语音输入映射到共享的潜在空间。通过一个轻量级投影网络将编码器输出与大型语言模型的嵌入空间对齐，我们使模型能够从仅文本监督泛化到基于语音的推理。尽管完全仅用文本进行训练，TESU-LLM 在各种语音相关基准测试上取得了与使用大规模多模态数据集和大量计算资源训练的基线方法相当的强大性能。这些结果突出了我们方法的有效性和效率，为无需语音数据即可构建语音大型语言模型提供了一条可扩展的路径。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [353] [Unified Game Moderation: Soft-Prompting and LLM-Assisted Label Transfer for Resource-Efficient Toxicity Detection](https://arxiv.org/abs/2506.06347)
> *统一游戏内容审核：软提示与LLM辅助标签迁移实现资源高效的毒性检测*

*Zachary Yang, Domenico Tullo, Reihaneh Rabbany* | **Main category: cs.CL**

**Keywords:** 毒性检测, 软提示, LLM辅助标签迁移, 游戏审核, 资源效率

**Comment:** 11 pages, 1 figure, 9 Tables, KDD 2025 ADS Track

> **TL;DR:** 该研究提出了一个统一的毒性检测系统，利用软提示处理多款游戏，并使用LLM辅助标签迁移扩展到多语言，显著降低了资源消耗和维护成本。

**AI_Comments:** 这篇论文的创新点在于结合了软提示和LLM辅助标签迁移，为游戏毒性检测提供了一个资源高效且可扩展的统一解决方案。软提示通过引入游戏上下文token，使得一个模型能处理多款游戏，避免了为每款游戏训练独立模型的开销。LLM辅助标签迁移则巧妙地利用了大型语言模型的生成能力，解决了多语言标签数据稀缺的问题。这种方法在实际生产环境中被验证有效，显著降低了运维成本，对于大规模在线游戏平台的实时内容审核具有重要意义。其对计算效率和可扩展性的关注，使其在AI应用部署方面具有很高的实用价值。

<details>
  <summary>Details</summary>

**Motivation:** 游戏社区中的毒性检测在扩展到多款游戏和多种语言时面临巨大的扩展挑战，尤其是在计算效率至关重要的实时环境中。

**Method:** 该研究提出了两种关键方法：一是引入软提示方法，通过整合游戏上下文token，使单个模型能够有效地处理多款游戏，其性能与更复杂的方法（如课程学习）相匹配，同时提供了卓越的可扩展性。二是开发了一个使用GPT-4o-mini的LLM辅助标签迁移框架，将支持扩展到七种额外语言。这些方法是基于之前关于ToxBuster（一个基于BERT的实时毒性检测系统）的工作。

**Result:** 在法语、德语、葡萄牙语和俄语的真实游戏聊天数据上评估，宏观F1分数介于32.96%至58.88%之间，其中在德语中的表现尤其出色，超过了45.39%的英语基准。在生产环境中，与为每个游戏和语言组合维护独立模型相比，这种统一方法显著减少了计算资源和维护开销。在Ubisoft，该模型平均每天每款游戏成功识别出50名从事可制裁行为的玩家。

**Conclusion:** 这种统一的游戏毒性检测方法通过软提示和LLM辅助标签迁移，有效解决了跨游戏和跨语言的扩展挑战，显著降低了资源消耗和维护成本，并在实际应用中取得了良好的效果。

> **ai_Abstract:** 这篇论文提出了一种统一的游戏毒性检测方法，旨在解决跨游戏和多语言环境下的扩展性及效率问题。该方法包含两个核心创新：一是采用软提示技术，使单个模型能适应多款游戏，提升了可扩展性；二是利用LLM（GPT-4o-mini）辅助标签迁移，将支持扩展至七种额外语言。实验结果显示，该方法在多语言真实游戏数据上表现良好，特别是在德语方面，并且显著降低了生产环境中的计算资源和维护成本，在实际应用中有效识别了违规玩家。

> **摘要翻译:** 游戏社区中的毒性检测在扩展到多款游戏和多种语言时面临巨大的扩展挑战，尤其是在计算效率至关重要的实时环境中。我们提出了两个关键发现来解决这些挑战，同时基于我们之前关于ToxBuster（一个基于BERT的实时毒性检测系统）的工作。首先，我们引入了一种软提示方法，通过整合游戏上下文token，使单个模型能够有效地处理多款游戏，其性能与课程学习等更复杂的方法相匹配，同时提供了卓越的可扩展性。其次，我们开发了一个使用GPT-4o-mini的LLM辅助标签迁移框架，将支持扩展到七种额外语言。在法语、德语、葡萄牙语和俄语的真实游戏聊天数据上的评估取得了32.96%到58.88%的宏观F1分数，其中在德语中的表现尤其出色，超过了45.39%的英语基准。在生产环境中，与为每个游戏和语言组合维护独立模型相比，这种统一方法显著减少了计算资源和维护开销。在Ubisoft，该模型平均每天每款游戏成功识别出50名从事可制裁行为的玩家。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [390] [Relationship Detection on Tabular Data Using Statistical Analysis and Large Language Models](https://arxiv.org/abs/2506.06371)
> *表格数据关系检测：结合统计分析与大型语言模型*

*Panagiotis Koletsis, Christos Panagiotopoulos, Georgios Th. Papadopoulos, Vasilis Efthymiou* | **Main category: cs.CL**

**Keywords:** 表格数据, 关系检测, 统计分析, 大型语言模型, 知识图谱

**Comment:** 

> **TL;DR:** 本文提出一种混合方法，结合统计分析和大型语言模型，用于在无标签表格数据中检测列之间的关系，通过减少知识图谱关系搜索空间，在基准数据集上表现出竞争力。

**AI_Comments:** 该论文通过结合统计分析和大型语言模型，为表格数据中的关系检测提供了一种新颖的混合方法，特别是在减少搜索空间方面表现出创新性。其在无标签数据上的应用具有实用价值，并在SOTA数据集上表现出竞争力，表明了其有效性和重要性。代码的公开性也促进了研究的复现和发展。

<details>
  <summary>Details</summary>

**Motivation:** 表格解释任务的重要性及其进展，特别是无标签表格数据中列间关系检测（CPA）的挑战。

**Method:** 提出一种混合方法，结合大型语言模型（LLMs）和统计分析。统计分析用于减少知识图谱（KG）关系搜索空间，主要通过域和范围约束检测以及关系共现分析实现。

**Result:** 在SemTab挑战提供的两个基准数据集上进行了实验评估，验证了每个模块的影响以及不同量化级别和提示技术下最先进LLMs的有效性。所提出的方法与现有最先进方法相比具有竞争力。

**Conclusion:** 该混合方法在无标签表格数据的列间关系检测任务上表现出竞争力，证明了结合统计分析和LLMs的有效性。

> **ai_Abstract:** 本文提出一种结合统计分析和大型语言模型（LLMs）的混合方法，用于在无标签表格数据中检测列之间的关系（CPA任务）。该方法利用统计分析（包括域和范围约束检测以及关系共现分析）来有效减少知识图谱（KG）关系的搜索空间。在SemTab挑战的两个基准数据集上的实验表明，该方法在性能上与现有最先进方法具有竞争力，并评估了不同模块、LLMs量化级别和提示技术的影响。

> **摘要翻译:** 过去几年，表格解释任务由于其重要性以及该领域新技术和基准的引入而取得了显著进展。这项工作尝试了一种混合方法，用于检测无标签表格数据列之间的关系，使用知识图谱（KG）作为参考点，这项任务被称为CPA。该方法利用大型语言模型（LLMs），同时采用统计分析来减少潜在KG关系的搜索空间。该方法用于减少搜索空间的主要模块是域和范围约束检测，以及关系共现分析。在SemTab挑战提供的两个基准数据集上进行的实验评估，评估了每个模块的影响以及不同量化级别下各种最先进LLMs的有效性。实验还在不同的提示技术下进行。所提出的方法（已在github上公开）在这些数据集上证明与最先进的方法具有竞争力。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [406] [Enhancing Decision-Making of Large Language Models via Actor-Critic](https://arxiv.org/abs/2506.06376)
> *错误：AI分析失败。*

*Heng Dong, Kefei Duan, Chongjie Zhang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Forty-second International Conference on Machine Learning (ICML 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [407] [Break-The-Chain: Reasoning Failures in LLMs via Adversarial Prompting in Code Generation](https://arxiv.org/abs/2506.06971)
> *错误：AI分析失败。*

*Jaechul Roh, Varun Gandhi, Shivani Anilkumar, Arin Garg* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [428] [Detection Method for Prompt Injection by Integrating Pre-trained Model and Heuristic Feature Engineering](https://arxiv.org/abs/2506.06384)
> *错误：AI分析失败。*

*Yi Ji, Runzhi Li, Baolei Mao* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by KSEM2025 AI & Sec Workshop

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [443] [LLM Unlearning Should Be Form-Independent](https://arxiv.org/abs/2506.07795)
> *错误：AI分析失败。*

*Xiaotian Ye, Mengqi Zhang, Shu Wu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [451] [Confidence Is All You Need: Few-Shot RL Fine-Tuning of Language Models](https://arxiv.org/abs/2506.06395)
> *错误：AI分析失败。*

*Pengyi Li, Matvey Skripkin, Alexander Zubrey, Andrey Kuznetsov, Ivan Oseledets* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [456] [Natural Language Interaction with Databases on Edge Devices in the Internet of Battlefield Things](https://arxiv.org/abs/2506.06396)
> *错误：AI分析失败。*

*Christopher D. Molek, Roberto Fronteddu, K. Brent Venable, Niranjan Suri* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [462] [Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs](https://arxiv.org/abs/2506.06401)
> *错误：AI分析失败。*

*Hongming Yang, Shi Lin, Jun Shao, Changting Lin, Donghai Zhu, Meng Han, Qinglei Kong* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** This work is accepted at ACL 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [469] [SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities](https://arxiv.org/abs/2506.06406)
> *错误：AI分析失败。*

*Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Chen Wei, Fangxiang Feng, Xiaojie Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [497] [Canonical Autoregressive Generation](https://arxiv.org/abs/2506.06446)
> *错误：AI分析失败。*

*Ivi Chatzi, Nina Corvelo Benz, Stratis Tsirtsis, Manuel Gomez-Rodriguez* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [506] [Low-resource Machine Translation: what for? who for? An observational study on a dedicated Tetun language translation service](https://arxiv.org/abs/2411.12262)
> *错误：AI分析失败。*

*Raphael Merx, Adérito José Guterres Correia, Hanna Suominen, Ekaterina Vylomova* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** to be published in LoResMT 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [554] [What Is Seen Cannot Be Unseen: The Disruptive Effect of Knowledge Conflict on Large Language Models](https://arxiv.org/abs/2506.06485)
> *错误：AI分析失败。*

*Kaiser Sun, Fan Bai, Mark Dredze* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [573] [Improving LLM-Powered EDA Assistants with RAFT](https://arxiv.org/abs/2506.06500)
> *错误：AI分析失败。*

*Luyao Shi, Michael Kazda, Charles Schmitter, Hemlata Gupta* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted paper at IEEE International Conference on LLM-Aided Design,
  2025 (LAD 2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [582] [Biases Propagate in Encoder-based Vision-Language Models: A Systematic Analysis From Intrinsic Measures to Zero-shot Retrieval Outcomes](https://arxiv.org/abs/2506.06506)
> *错误：AI分析失败。*

*Kshitish Ghate, Tessa Charlesworth, Mona Diab, Aylin Caliskan* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ACL Findings 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [603] [Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance](https://arxiv.org/abs/2506.06522)
> *错误：AI分析失败。*

*Aladin Djuhera, Swanand Ravindra Kadhe, Syed Zawad, Farhan Ahmed, Heiko Ludwig, Holger Boche* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [622] [Beyond Facts: Evaluating Intent Hallucination in Large Language Models](https://arxiv.org/abs/2506.06539)
> *错误：AI分析失败。*

*Yijie Hao, Haofei Yu, Jiaxuan You* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ACL 2025 main conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [644] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
> *错误：AI分析失败。*

*Ho Yin 'Sam' Ng, Ting-Yao Hsu, Aashish Anantha Ramakrishnan, Branislav Kveton, Nedim Lipka, Franck Dernoncourt, Dongwon Lee, Tong Yu, Sungchul Kim, Ryan A. Rossi, Ting-Hao 'Kenneth' Huang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [679] [Precise Information Control in Long-Form Text Generation](https://arxiv.org/abs/2506.06589)
> *错误：AI分析失败。*

*Jacqueline He, Howard Yen, Margaret Li, Shuyue Stella Li, Zhiyuan Zeng, Weijia Shi, Yulia Tsvetkov, Danqi Chen, Pang Wei Koh, Luke Zettlemoyer* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 56 pages, 8 figures. Code and models are publicly available at
  https://github.com/jacqueline-he/precise-information-control

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [685] [MedCite: Can Language Models Generate Verifiable Text for Medicine?](https://arxiv.org/abs/2506.06605)
> *错误：AI分析失败。*

*Xiao Wang, Mengjue Tan, Qiao Jin, Guangzhi Xiong, Yu Hu, Aidong Zhang, Zhiyong Lu, Minjia Zhang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [687] [Training-Free Tokenizer Transplantation via Orthogonal Matching Pursuit](https://arxiv.org/abs/2506.06607)
> *错误：AI分析失败。*

*Charles Goddard, Fernando Fernandes Neto* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [697] [Quantile Regression with Large Language Models for Price Prediction](https://arxiv.org/abs/2506.06657)
> *错误：AI分析失败。*

*Nikhita Vedula, Dushyanta Dhyani, Laleh Jalali, Boris Oreshkin, Mohsen Bayati, Shervin Malmasi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to Findings of ACL, 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [709] [Transferring Features Across Language Models With Model Stitching](https://arxiv.org/abs/2506.06609)
> *错误：AI分析失败。*

*Alan Chen, Jack Merullo, Alessandro Stolfo, Ellie Pavlick* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [713] [DivScore: Zero-Shot Detection of LLM-Generated Text in Specialized Domains](https://arxiv.org/abs/2506.06705)
> *错误：AI分析失败。*

*Zhihui Chen, Kai He, Yucheng Huang, Yunxiao Zhu, Mengling Feng* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Zhihui Chen and Kai He contributed equally to this work, Mengling
  Feng is the corresponding author

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [715] [Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings](https://arxiv.org/abs/2506.06616)
> *错误：AI分析失败。*

*Samuel Kim, Oghenemaro Imieye, Yunting Yin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Submitted to the IEEE EMBS BHI 2025 Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [718] [BriefMe: A Legal NLP Benchmark for Assisting with Legal Briefs](https://arxiv.org/abs/2506.06619)
> *错误：AI分析失败。*

*Jesse Woo, Fateme Hashemi Chaleshtori, Ana Marasović, Kenneth Marino* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ACL Findings 2025; 10 pages main, 5 pages references, 37 pages
  appendix

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [726] [C-PATH: Conversational Patient Assistance and Triage in Healthcare System](https://arxiv.org/abs/2506.06737)
> *错误：AI分析失败。*

*Qi Shi, Qiwei Han, Cláudia Soares* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted in IEEE ICDH 2025, 10 pages, 8 figures, 5 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [727] [Psychological Counseling Cannot Be Achieved Overnight: Automated Psychological Counseling Through Multi-Session Conversations](https://arxiv.org/abs/2506.06626)
> *错误：AI分析失败。*

*Junzhe Wang, Bichen Wang, Xing Fu, Yixin Sun, Yanyan Zhao, Bing Qin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 15 pages, 19 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [736] [Label-semantics Aware Generative Approach for Domain-Agnostic Multilabel Classification](https://arxiv.org/abs/2506.06806)
> *错误：AI分析失败。*

*Subhendu Khatuya, Shashwat Naidu, Saptarshi Ghosh, Pawan Goyal, Niloy Ganguly* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** This work has been accepted to appear at the Association for
  Computational Linguistics (ACL), 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [739] [Not quite Sherlock Holmes: Language model predictions do not reliably differentiate impossible from improbable events](https://arxiv.org/abs/2506.06808)
> *错误：AI分析失败。*

*James A. Michaelov, Reeka Estacio, Zhien Zhang, Benjamin K. Bergen* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to Findings of ACL 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [745] [SafeLawBench: Towards Safe Alignment of Large Language Models](https://arxiv.org/abs/2506.06636)
> *错误：AI分析失败。*

*Chuxue Cao, Han Zhu, Jiaming Ji, Qichao Sun, Zhenghao Zhu, Yinyu Wu, Juntao Dai, Yaodong Yang, Sirui Han, Yike Guo* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ACL2025 Findings

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [760] [PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation](https://arxiv.org/abs/2506.06842)
> *错误：AI分析失败。*

*Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ACL 2025 Main Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [774] [DiscoSum: Discourse-aware News Summarization](https://arxiv.org/abs/2506.06930)
> *错误：AI分析失败。*

*Alexander Spangher, Tenghao Huang, Jialiang Gu, Jiatong Shi, Muhao Chen* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 3 figures, 10 pages in Appendix

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [778] [Learning Distribution-Wise Control in Representation Space for Language Models](https://arxiv.org/abs/2506.06686)
> *错误：AI分析失败。*

*Chunyuan Deng, Ruidi Chang, Hanjie Chen* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [782] [BIS Reasoning 1.0: The First Large-Scale Japanese Benchmark for Belief-Inconsistent Syllogistic Reasoning](https://arxiv.org/abs/2506.06955)
> *错误：AI分析失败。*

*Ha-Thanh Nguyen, Chaoran Liu, Hirokazu Kiyomaru, Koichi Takeda, Yusuke Miyao, Maki Matsuda, Yusuke Oda, Pontus Stenetorp, Qianying Liu, Su Myat Noe, Hideyuki Tachibana, Kouta Nakayama, Sadao Kurohashi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [786] [What makes Reasoning Models Different? Follow the Reasoning Leader for Efficient Decoding](https://arxiv.org/abs/2506.06998)
> *错误：AI分析失败。*

*Ming Li, Zhengyuan Yang, Xiyao Wang, Dianqi Li, Kevin Lin, Tianyi Zhou, Lijuan Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [789] [Dynamic and Parametric Retrieval-Augmented Generation](https://arxiv.org/abs/2506.06704)
> *错误：AI分析失败。*

*Weihang Su, Qingyao Ai, Jingtao Zhan, Qian Dong, Yiqun Liu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [793] [A Survey of Retentive Network](https://arxiv.org/abs/2506.06708)
> *错误：AI分析失败。*

*Haiqi Yang, Zhiyuan Li, Yi Chang, Yuan Wu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 15 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [797] [A Culturally-diverse Multilingual Multimodal Video Benchmark & Model](https://arxiv.org/abs/2506.07032)
> *错误：AI分析失败。*

*Bhuiyan Sanjid Shafique, Ashmal Vayani, Muhammad Maaz, Hanoona Abdul Rasheed, Dinura Dissanayake, Mohammed Irfan Kurpath, Yahya Hmaiti, Go Inoue, Jean Lahoud, Md. Safirur Rashid, Shadid Intisar Quasem, Maheen Fatima, Franco Vidal, Mykola Maslych, Ketan Pravin More, Sanoojan Baliah, Hasindri Watawana, Yuhao Li, Fabian Farestam, Leon Schaller, Roman Tymtsiv, Simon Weber, Hisham Cholakkal, Ivan Laptev, Shin'ichi Satoh, Michael Felsberg, Mubarak Shah, Salman Khan, Fahad Shahbaz Khan* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [800] [Lingshu: A Generalist Foundation Model for Unified Multimodal Medical Understanding and Reasoning](https://arxiv.org/abs/2506.07044)
> *错误：AI分析失败。*

*LASA Team, Weiwen Xu, Hou Pong Chan, Long Li, Mahani Aljunied, Ruifeng Yuan, Jianyu Wang, Chenghao Xiao, Guizhen Chen, Chaoqun Liu, Zhaodonghui Li, Yu Sun, Junao Shen, Chaojun Wang, Jie Tan, Deli Zhao, Tingyang Xu, Hao Zhang, Yu Rong* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Technical Report, 53 pages, 25 tables, and 16 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [802] [Flattery in Motion: Benchmarking and Analyzing Sycophancy in Video-LLMs](https://arxiv.org/abs/2506.07180)
> *错误：AI分析失败。*

*Wenrui Zhou, Shu Yang, Qingsong Yang, Zikun Guo, Lijie Hu, Di Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 24 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [806] [Com$^2$: A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models](https://arxiv.org/abs/2506.07064)
> *错误：AI分析失败。*

*Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACL 2025 Main Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [814] [How Far Are We from Optimal Reasoning Efficiency?](https://arxiv.org/abs/2506.07104)
> *错误：AI分析失败。*

*Jiaxuan Gao, Shu Yan, Qixin Tan, Lu Yang, Shusheng Xu, Wei Fu, Zhiyu Mei, Kaifeng Lyu, Yi Wu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [816] [Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models](https://arxiv.org/abs/2506.07106)
> *错误：AI分析失败。*

*Samir Abdaljalil, Hasan Kurban, Khalid Qaraqe, Erchin Serpedin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [821] [Unblocking Fine-Grained Evaluation of Detailed Captions: An Explaining AutoRater and Critic-and-Revise Pipeline](https://arxiv.org/abs/2506.07631)
> *错误：AI分析失败。*

*Brian Gordon, Yonatan Bitton, Andreea Marzoca, Yasumasa Onoe, Xiao Wang, Daniel Cohen-Or, Idan Szpektor* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [822] [Geopolitical biases in LLMs: what are the "good" and the "bad" countries according to contemporary language models](https://arxiv.org/abs/2506.06751)
> *错误：AI分析失败。*

*Mikhail Salnikov, Dmitrii Korzh, Ivan Lazichny, Elvir Karimov, Artyom Iudin, Ivan Oseledets, Oleg Y. Rogov, Alexander Panchenko, Natalia Loukachevitch, Elena Tutubalina* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [829] [Prompting Science Report 2: The Decreasing Value of Chain of Thought in Prompting](https://arxiv.org/abs/2506.07142)
> *错误：AI分析失败。*

*Lennart Meincke, Ethan Mollick, Lilach Mollick, Dan Shapiro* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [831] [Syntactic Control of Language Models by Posterior Inference](https://arxiv.org/abs/2506.07154)
> *错误：AI分析失败。*

*Vicky Xefteri, Tim Vieira, Ryan Cotterell, Afra Amini* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [834] [CTDGSI: A comprehensive exploitation of instance selection methods for automatic text classification. VII Concurso de Teses, Dissertações e Trabalhos de Graduação em SI -- XXI Simpósio Brasileiro de Sistemas de Informação](https://arxiv.org/abs/2506.07169)
> *错误：AI分析失败。*

*Washington Cunha, Leonardo Rocha, Marcos André Gonçalves* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 5 figures, 2 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [840] [They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse](https://arxiv.org/abs/2506.06775)
> *错误：AI分析失败。*

*Walter Paci, Alessandro Panunzi, Sandro Pezzelle* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to the ACL2025 Findings

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [842] [Extending dependencies to the taggedPBC: Word order in transitive clauses](https://arxiv.org/abs/2506.06785)
> *错误：AI分析失败。*

*Hiram Ring* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [843] [SDE-SQL: Enhancing Text-to-SQL Generation in Large Language Models via Self-Driven Exploration with SQL Probes](https://arxiv.org/abs/2506.07245)
> *错误：AI分析失败。*

*Wenxuan Xie, Yaxun Dai, Wenhao Jiang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [844] [Parsing the Switch: LLM-Based UD Annotation for Complex Code-Switched and Low-Resource Languages](https://arxiv.org/abs/2506.07274)
> *错误：AI分析失败。*

*Olga Kellert, Nemika Tyagi, Muhammad Imran, Nelvin Licona-Guevara, Carlos Gómez-Rodríguez* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [849] [On the Adaptive Psychological Persuasion of Large Language Models](https://arxiv.org/abs/2506.06800)
> *错误：AI分析失败。*

*Tianjie Ju, Yujia Chen, Hao Fei, Mong-Li Lee, Wynne Hsu, Pengzhou Cheng, Zongru Wu, Zhuosheng Zhang, Gongshen Liu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Working in progress

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [854] [Improving LLM Reasoning through Interpretable Role-Playing Steering](https://arxiv.org/abs/2506.07335)
> *错误：AI分析失败。*

*Anyi Wang, Dong Shu, Yifan Wang, Yunpu Ma, Mengnan Du* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, 8 figures, 8 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [855] [Advancing Question Generation with Joint Narrative and Difficulty Control](https://arxiv.org/abs/2506.06812)
> *错误：AI分析失败。*

*Bernardo Leite, Henrique Lopes Cardoso* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint. Accepted to the BEA 2025 Workshop (ACL)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [857] [Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning](https://arxiv.org/abs/2506.06964)
> *错误：AI分析失败。*

*Subhojyoti Mukherjee, Viet Dac Lai, Raghavendra Addanki, Ryan Rossi, Seunghyun Yoon, Trung Bui, Anup Rao, Jayakumar Subramanian, Branislav Kveton* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 39 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [861] [Beyond Classification: Towards Speech Emotion Reasoning with Multitask AudioLLMs](https://arxiv.org/abs/2506.06820)
> *错误：AI分析失败。*

*Wenyu Zhang, Yingxu He, Geyu Lin, Zhuohan Liu, Shuo Sun, Bin Wang, Xunlong Zou, Jeremy H. M. Wong, Qiongqiong Wang, Hardik B. Sailor, Nancy F. Chen, Ai Ti Aw* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [867] [RULE: Reinforcement UnLEarning Achieves Forget-Retain Pareto Optimality](https://arxiv.org/abs/2506.07171)
> *错误：AI分析失败。*

*Chenlong Zhang, Zhuoran Jin, Hongbang Yuan, Jiaheng Wei, Tong Zhou, Kang Liu, Jun Zhao, Yubo Chen* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Paper under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [869] [Improving the Efficiency of Long Document Classification using Sentence Ranking Approach](https://arxiv.org/abs/2506.07248)
> *错误：AI分析失败。*

*Prathamesh Kokate, Mitali Sarnaik, Manavi Khopade, Raviraj Joshi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [870] [Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models](https://arxiv.org/abs/2506.07424)
> *错误：AI分析失败。*

*Kyeonghyun Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, YoungBin Kim* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ACL 2025 main conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [873] [Well Begun is Half Done: Low-resource Preference Alignment by Weak-to-Strong Decoding](https://arxiv.org/abs/2506.07434)
> *错误：AI分析失败。*

*Feifan Song, Shaohang Wei, Wen Luo, Yuxuan Fan, Tianyu Liu, Guoyin Wang, Houfeng Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACL 2025 Findings

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [874] [Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models](https://arxiv.org/abs/2506.06844)
> *错误：AI分析失败。*

*Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by ACL 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [877] [KScope: A Framework for Characterizing the Knowledge Status of Language Models](https://arxiv.org/abs/2506.07458)
> *错误：AI分析失败。*

*Yuxin Xiao, Shan Chen, Jack Gallifant, Danielle Bitterman, Thomas Hartvigsen, Marzyeh Ghassemi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [878] [CCI4.0: A Bilingual Pretraining Dataset for Enhancing Reasoning in Large Language Models](https://arxiv.org/abs/2506.07463)
> *错误：AI分析失败。*

*Guang Liu, Liangdong Wang, Jijie Li, Yang Yu, Yao Xu, Jiabei Chen, Yu Bai, Feng Liao, Yonghua Lin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [882] [Right Is Not Enough: The Pitfalls of Outcome Supervision in Training LLMs for Math Reasoning](https://arxiv.org/abs/2506.06877)
> *错误：AI分析失败。*

*Jiaxing Guo, Wenjie Yang, Shengzhong Zhang, Tongshan Xu, Lun Du, Da Zheng, Zengfeng Huang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [885] [SELT: Self-Evaluation Tree Search for LLMs with Task Decomposition](https://arxiv.org/abs/2506.07557)
> *错误：AI分析失败。*

*Mengsong Wu, Di Zhang, Yuqiang Li, Dongzhan Zhou, Wenliang Chen* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 11 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [889] [Mixture of Small and Large Models for Chinese Spelling Check](https://arxiv.org/abs/2506.06887)
> *错误：AI分析失败。*

*Ziheng Qiao, Houquan Zhou, Zhenghua Li* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [890] [LoRMA: Low-Rank Multiplicative Adaptation for LLMs](https://arxiv.org/abs/2506.07621)
> *错误：AI分析失败。*

*Harsh Bihany, Shubham Patel, Ashutosh Modi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted at ACL Findings 2025; 21 pages (9 main paper + 5 pages
  references + 7 pages appendix)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [891] [Automatic Speech Recognition of African American English: Lexical and Contextual Effects](https://arxiv.org/abs/2506.06888)
> *错误：AI分析失败。*

*Hamid Mojarad, Kevin Tang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** submitted to Interspeech 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [892] [Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models](https://arxiv.org/abs/2506.07583)
> *错误：AI分析失败。*

*Ramakrishna Appicharla, Baban Gain, Santanu Pal, Asif Ekbal* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [893] [Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch](https://arxiv.org/abs/2506.07667)
> *错误：AI分析失败。*

*Prarabdh Shukla, Wei Yin Chong, Yash Patel, Brennan Schaffner, Danish Pruthi, Arjun Bhagoji* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [896] [Training Superior Sparse Autoencoders for Instruct Models](https://arxiv.org/abs/2506.07691)
> *错误：AI分析失败。*

*Jiaming Li, Haoran Ye, Yukun Chen, Xinyue Li, Lei Zhang, Hamid Alinejad-Rokny, Jimmy Chih-Hsien Peng, Min Yang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [897] [Synthesis by Design: Controlled Data Generation via Structural Guidance](https://arxiv.org/abs/2506.07664)
> *错误：AI分析失败。*

*Lei Xu, Sirui Chen, Yuxuan Huang, Chaochao Lu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [899] [GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation](https://arxiv.org/abs/2506.07671)
> *错误：AI分析失败。*

*Ionut-Teodor Sorodoc, Leonardo F. R. Ribeiro, Rexhina Blloshmi, Christopher Davis, Adrià de Gispert* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ACL 2025 (Findings)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [902] [MultiMatch: Multihead Consistency Regularization Matching for Semi-Supervised Text Classification](https://arxiv.org/abs/2506.07801)
> *错误：AI分析失败。*

*Iustin Sirbu, Robert-Adrian Popovici, Cornelia Caragea, Stefan Trausan-Matu, Traian Rebedea* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [903] [Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking](https://arxiv.org/abs/2506.07751)
> *错误：AI分析失败。*

*Silin Gao, Antoine Bosselut, Samy Bengio, Emmanuel Abbe* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [907] [Hybrid Extractive Abstractive Summarization for Multilingual Sentiment Analysis](https://arxiv.org/abs/2506.06929)
> *错误：AI分析失败。*

*Mikhail Krasitskii, Grigori Sidorov, Olga Kolesnikova, Liliana Chanona Hernandez, Alexander Gelbukh* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [908] [MEMOIR: Lifelong Model Editing with Minimal Overwrite and Informed Retention for LLMs](https://arxiv.org/abs/2506.07899)
> *错误：AI分析失败。*

*Ke Wang, Yiming Qin, Nikolaos Dimitriadis, Alessandro Favero, Pascal Frossard* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** The first two authors contributed equally to this work

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [909] [What Makes a Good Natural Language Prompt?](https://arxiv.org/abs/2506.06950)
> *错误：AI分析失败。*

*Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, Min-Yen Kan* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ACL 2025 Main Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [911] [MiniCPM4: Ultra-Efficient LLMs on End Devices](https://arxiv.org/abs/2506.07900)
> *错误：AI分析失败。*

*MiniCPM Team, Chaojun Xiao, Yuxuan Li, Xu Han, Yuzhuo Bai, Jie Cai, Haotian Chen, Wentong Chen, Xin Cong, Ganqu Cui, Ning Ding, Shengdan Fan, Yewei Fang, Zixuan Fu, Wenyu Guan, Yitong Guan, Junshao Guo, Yufeng Han, Bingxiang He, Yuxiang Huang, Cunliang Kong, Qiuzuo Li, Siyuan Li, Wenhao Li, Yanghao Li, Yishan Li, Zhen Li, Dan Liu, Biyuan Lin, Yankai Lin, Xiang Long, Quanyu Lu, Yaxi Lu, Peiyan Luo, Hongya Lyu, Litu Ou, Yinxu Pan, Zekai Qu, Qundong Shi, Zijun Song, Jiayuan Su, Zhou Su, Ao Sun, Xianghui Sun, Peijun Tang, Fangzheng Wang, Feng Wang, Shuo Wang, Yudong Wang, Yesai Wu, Zhenyu Xiao, Jie Xie, Zihao Xie, Yukun Yan, Jiarui Yuan, Kaihuo Zhang, Lei Zhang, Linyue Zhang, Xueren Zhang, Yudi Zhang, Hengyu Zhao, Weilin Zhao, Weilun Zhao, Yuanqian Zhao, Zhi Zheng, Ge Zhou, Jie Zhou, Wei Zhou, Zihan Zhou, Zixuan Zhou, Zhiyuan Liu, Guoyang Zeng, Chao Jia, Dahai Li, Maosong Sun* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** MiniCPM4 Technical Report

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [912] [A dependently-typed calculus of event telicity and culminativity](https://arxiv.org/abs/2506.06968)
> *错误：AI分析失败。*

*Pavel Kovalev, Carlo Angiuli* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 52 pages, Agda formalization available at
  https://doi.org/10.5281/zenodo.15602617

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [913] [Atomic Reasoning for Scientific Table Claim Verification](https://arxiv.org/abs/2506.06972)
> *错误：AI分析失败。*

*Yuji Zhang, Qingyun Wang, Cheng Qian, Jiateng Liu, Chenkai Sun, Denghui Zhang, Tarek Abdelzaher, Chengxiang Zhai, Preslav Nakov, Heng Ji* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [915] [Chain of Methodologies: Scaling Test Time Computation without Training](https://arxiv.org/abs/2506.06982)
> *错误：AI分析失败。*

*Cong Liu, Jie Wu, Weigang Wu, Xu Chen, Liang Lin, Wei-Shi Zheng* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [916] [Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors](https://arxiv.org/abs/2506.06987)
> *错误：AI分析失败。*

*Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** This paper has been accepted to the 63rd Annual Meeting of the
  Association for Computational Linguistics (ACL 2025), Main Conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [917] [Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text](https://arxiv.org/abs/2506.07001)
> *错误：AI分析失败。*

*Yize Cheng, Vinu Sankar Sadasivan, Mehrdad Saberi, Shoumik Saha, Soheil Feizi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [920] [KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering](https://arxiv.org/abs/2506.07037)
> *错误：AI分析失败。*

*Zhongze Luo, Weixuan Wan, Qizhi Zheng, Yanhong Bai, Jingyun Sun, Jian Wang, Dan Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 23 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [922] [Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants](https://arxiv.org/abs/2506.07042)
> *错误：AI分析失败。*

*Stergios Chatzikyriakidis* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [929] [Representation Decomposition for Learning Similarity and Contrastness Across Modalities for Affective Computing](https://arxiv.org/abs/2506.07086)
> *错误：AI分析失败。*

*Yuanhe Tian, Pengsen Cheng, Guoqing Jin, Lei Zhang, Yan Song* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [934] [Semantic-preserved Augmentation with Confidence-weighted Fine-tuning for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2506.07148)
> *错误：AI分析失败。*

*Yaping Chai, Haoran Xie, Joe S. Qin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages, 7 figures, 4 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [936] [GeometryZero: Improving Geometry Solving for LLM with Group Contrastive Policy Optimization](https://arxiv.org/abs/2506.07160)
> *错误：AI分析失败。*

*Yikun Wang, Yibin Wang, Dianyi Wang, Zimian Peng, Qipeng Guo, Dacheng Tao, Jiaqi Wang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [942] [Bias Attribution in Filipino Language Models: Extending a Bias Interpretability Metric for Application on Agglutinative Languages](https://arxiv.org/abs/2506.07249)
> *错误：AI分析失败。*

*Lance Calvin Lim Gamboa, Yue Feng, Mark Lee* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted into the Gender Bias in NLP Workshop at ACL 2025
  (GeBNLP@ACL2025)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [945] [Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs](https://arxiv.org/abs/2506.07270)
> *错误：AI分析失败。*

*Atahan Özer, Çağatay Yıldız* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [948] [Exploring the Impact of Temperature on Large Language Models:Hot or Cold?](https://arxiv.org/abs/2506.07295)
> *错误：AI分析失败。*

*Lujun Li, Lama Sleem, Niccolo' Gentile, Geoffrey Nichil, Radu State* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [949] [Subjectivity in the Annotation of Bridging Anaphora](https://arxiv.org/abs/2506.07297)
> *错误：AI分析失败。*

*Lauren Levine, Amir Zeldes* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** LAW-XIX, ACL 2025 Workshop

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [950] [ConfQA: Answer Only If You Are Confident](https://arxiv.org/abs/2506.07309)
> *错误：AI分析失败。*

*Yin Huang, Yifan Ethan Xu, Kai Sun, Vera Yan, Alicia Sun, Haidar Khan, Jimmy Nguyen, Mohammad Kachuee, Zhaojiang Lin, Yue Liu, Aaron Colak, Anuj Kumar, Wen-tau Yih, Xin Luna Dong* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages main content, 10 pages appendix, 5 figures, 7 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [953] [Refusal-Feature-guided Teacher for Safe Finetuning via Data Filtering and Alignment Distillation](https://arxiv.org/abs/2506.07356)
> *错误：AI分析失败。*

*Seokil Ham, Yubin Choi, Seungju Cho, Yujin Yang, Younghun Kim, Changick Kim* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [959] [SEED: Enhancing Text-to-SQL Performance and Practical Usability Through Automatic Evidence Generation](https://arxiv.org/abs/2506.07423)
> *错误：AI分析失败。*

*Janghyeon Yun, Sang-goo Lee* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [960] [Conjoined Predication and Scalar Implicature](https://arxiv.org/abs/2506.07429)
> *错误：AI分析失败。*

*Ratna Kandala* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [962] [LG-ANNA-Embedding technical report](https://arxiv.org/abs/2506.07438)
> *错误：AI分析失败。*

*Jooyoung Choi, Hyun Kim, Hansol Jang, Changwook Jun, Kyunghoon Bae, Hyewon Choi, Stanley Jungkyu Choi, Honglak Lee, Chulmin Yun* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [963] [Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling](https://arxiv.org/abs/2506.07453)
> *错误：AI分析失败。*

*Pritom Saha Akash, Kevin Chen-Chuan Chang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [964] [From Calibration to Collaboration: LLM Uncertainty Quantification Should Be More Human-Centered](https://arxiv.org/abs/2506.07461)
> *错误：AI分析失败。*

*Siddartha Devic, Tejas Srinivasan, Jesse Thomason, Willie Neiswanger, Vatsal Sharan* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [967] [Improving Fairness of Large Language Models in Multi-document Summarization](https://arxiv.org/abs/2506.07479)
> *错误：AI分析失败。*

*Haoyuan Li Yusen Zhang, Snigdha Chaturvedi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to ACL 2025 main

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [968] [A Hybrid GA LLM Framework for Structured Task Optimization](https://arxiv.org/abs/2506.07483)
> *错误：AI分析失败。*

*Berry Feng, Jonas Lin, Patrick Lau* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 7 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [969] [DEBATE: A Dataset for Disentangling Textual Ambiguity in Mandarin Through Speech](https://arxiv.org/abs/2506.07502)
> *错误：AI分析失败。*

*Haotian Guo, Jing Han, Yongfeng Tu, Shihao Gao, Shengfan Shen, Wulong Xiang, Weihao Gan, Zixing Zhang* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [970] [What Do Indonesians Really Need from Language Technology? A Nationwide Survey](https://arxiv.org/abs/2506.07506)
> *错误：AI分析失败。*

*Muhammad Dehan Al Kautsar, Lucky Susanto, Derry Wijaya, Fajri Koto* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 26 pages, 12 figures, 5 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [971] [DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction](https://arxiv.org/abs/2506.07510)
> *错误：AI分析失败。*

*Solee Im, Wonjun Lee, Jinmyeong An, Yunsu Kim, Jungseul Ok, Gary Geunbae Lee* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** ACL2025 Findings

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [973] [Towards Large Language Models with Self-Consistent Natural Language Explanations](https://arxiv.org/abs/2506.07523)
> *错误：AI分析失败。*

*Sahar Admoni, Ofra Amir, Assaf Hallak, Yftah Ziser* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [975] [Bit-level BPE: Below the byte boundary](https://arxiv.org/abs/2506.07541)
> *错误：AI分析失败。*

*Sangwhan Moon, Tatsuya Hiraoka, Naoaki Okazaki* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [979] [Instructing Large Language Models for Low-Resource Languages: A Systematic Study for Basque](https://arxiv.org/abs/2506.07597)
> *错误：AI分析失败。*

*Oscar Sainz, Naiara Perez, Julen Etxaniz, Joseba Fernandez de Landa, Itziar Aldabe, Iker García-Ferrero, Aimar Zabala, Ekhi Azurmendi, German Rigau, Eneko Agirre, Mikel Artetxe, Aitor Soroa* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [981] [Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation](https://arxiv.org/abs/2506.07617)
> *错误：AI分析失败。*

*Roman Kyslyi, Yuliia Maksymiuk, Ihor Pysmennyi* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint. Will be published at Proceedings of the Fourth Ukrainian
  Natural Language Processing Workshop (UNLP)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [982] [Intent Matters: Enhancing AI Tutoring with Fine-Grained Pedagogical Intent Annotation](https://arxiv.org/abs/2506.07626)
> *错误：AI分析失败。*

*Kseniia Petukhova, Ekaterina Kochmar* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [984] [TreeReview: A Dynamic Tree of Questions Framework for Deep and Efficient LLM-based Scientific Peer Review](https://arxiv.org/abs/2506.07642)
> *错误：AI分析失败。*

*Yuan Chang, Ziyue Li, Hengyuan Zhang, Yuanbo Kong, Yanru Wu, Zhijiang Guo, Ngai Wong* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 30 pages, 17 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [985] [Evaluating LLMs Robustness in Less Resourced Languages with Proxy Models](https://arxiv.org/abs/2506.07645)
> *错误：AI分析失败。*

*Maciej Chrabąszcz, Katarzyna Lorenc, Karolina Seweryn* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [986] [Transcript-Prompted Whisper with Dictionary-Enhanced Decoding for Japanese Speech Annotation](https://arxiv.org/abs/2506.07646)
> *错误：AI分析失败。*

*Rui Hu, Xiaolong Lin, Jiawang Liu, Shixi Huang, Zhenpeng Zhan* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to INTERSPEECH 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [988] [Beyond Benchmarks: A Novel Framework for Domain-Specific LLM Evaluation and Knowledge Mapping](https://arxiv.org/abs/2506.07658)
> *错误：AI分析失败。*

*Nitin Sharma, Thomas Wolfers, Çağatay Yıldız* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 35 pages, 24 figures. First submission

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [993] [Through the Valley: Path to Effective Long CoT Training for Small Language Models](https://arxiv.org/abs/2506.07712)
> *错误：AI分析失败。*

*Renjie Luo, Jiaxi Li, Chen Huang, Wei Lu* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [994] [Multilingual Grammatical Error Annotation: Combining Language-Agnostic Framework with Language-Specific Flexibility](https://arxiv.org/abs/2506.07719)
> *错误：AI分析失败。*

*Mengyang Qiu, Tran Minh Nguyen, Zihao Huang, Zelong Li, Yang Gu, Qingyu Gao, Siliang Liu, Jungyeul Park* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** BEA2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [996] [Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU](https://arxiv.org/abs/2506.07726)
> *错误：AI分析失败。*

*Vincenzo Timmel, Manfred Vogel, Daniel Perruchoud, Reza Kakooee* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [1003] [WebUIBench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in WebUI-to-Code](https://arxiv.org/abs/2506.07818)
> *错误：AI分析失败。*

*Zhiyu Lin, Zhengda Zhou, Zhiyuan Zhao, Tianrui Wan, Yilun Ma, Junyu Gao, Xuelong Li* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [1005] [Learning to Focus: Causal Attention Distillation via Gradient-Guided Token Pruning](https://arxiv.org/abs/2506.07851)
> *错误：AI分析失败。*

*Yiju Guo, Wenkai Yang, Zexu Sun, Ning Ding, Zhiyuan Liu, Yankai Lin* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [1009] [Quantum Graph Transformer for NLP Sentiment Classification](https://arxiv.org/abs/2506.07937)
> *错误：AI分析失败。*

*Shamminuj Aktar, Andreas Bärtschi, Abdel-Hameed A. Badawy, Stephan Eidenbenz* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [1010] [Statistical Hypothesis Testing for Auditing Robustness in Language Models](https://arxiv.org/abs/2506.07947)
> *错误：AI分析失败。*

*Paulius Rauba, Qiyao Wei, Mihaela van der Schaar* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** arXiv admin note: substantial text overlap with arXiv:2412.00868

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

### [1013] [Reinforcement Pre-Training](https://arxiv.org/abs/2506.08007)
> *错误：AI分析失败。*

*Qingxiu Dong, Li Dong, Yao Tang, Tianzhu Ye, Yutao Sun, Zhifang Sui, Furu Wei* | **Main category: cs.CL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscl) | [⬆️ 返回总目录](#toc)

---

<a id='q-finst'></a>
## q-fin.ST 

### [49] [The Hype Index: an NLP-driven Measure of Market News Attention](https://arxiv.org/abs/2506.06329)
> *炒作指数：一种基于自然语言处理的市场新闻关注度衡量方法*

*Zheng Cao, Wanchaloem Wunkaew, Helyette Geman* | **Main category: q-fin.ST**

**Keywords:** 炒作指数, 自然语言处理, 市场关注度, 金融新闻, 股票波动性

**Comment:** 

> **TL;DR:** 本文引入炒作指数，利用自然语言处理技术量化金融新闻中对大盘股的媒体关注度，并发现其在股票波动性分析和市场信号方面具有价值。

**AI_Comments:** 本文的创新之处在于引入了“炒作指数”这一概念，并结合NLP技术量化市场新闻关注度，为金融领域的量化分析提供了新的视角和工具。其在股票波动性分析和市场信号方面的应用潜力值得关注。

<details>
  <summary>Details</summary>

**Motivation:** 量化媒体对大盘股的关注度，并利用自然语言处理（NLP）从金融新闻中提取预测信号。

**Method:** 1. 构建新闻计数型炒作指数（News Count-Based Hype Index），通过计算提及每只股票或行业的文章份额来衡量相对媒体曝光度。2. 将其扩展为资本化调整型炒作指数（Capitalization Adjusted Hype Index），通过计算股票或行业媒体权重与其市值权重之比进行调整。3. 在股票和行业层面计算这两种炒作指数。4. 通过以下方式评估：分类到不同炒作组、与收益/波动率/VIX指数的关联、对短期市场波动的信号能力以及经验属性（相关性、采样、趋势）。

**Result:** 炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了有价值的工具。

**Conclusion:** 炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了有价值的工具。

> **ai_Abstract:** 本文提出了一种名为“炒作指数”的新型指标，旨在利用自然语言处理（NLP）技术量化媒体对大盘股的关注度，并从金融新闻中提取预测信号。研究以S&P 100指数成分股为研究对象，首先构建了基于新闻计数的炒作指数，随后进一步开发了考虑经济规模的资本化调整型炒作指数。这两种指数都在股票和行业层面进行了计算，并从多个角度进行了评估，包括分类、与市场指标的关联、短期市场信号能力以及经验特性。研究结果表明，炒作指数系列为股票波动性分析、市场信号识别以及金融领域NLP应用提供了有价值的工具。

> **摘要翻译:** 本文引入了炒作指数作为衡量媒体对大盘股关注度的新型指标，利用自然语言处理（NLP）的进展从金融新闻中提取预测信号。我们以S&P 100指数为研究范围，首先构建了新闻计数型炒作指数，该指数通过计算提及每只股票或行业的新闻文章份额来衡量相对媒体曝光度。然后，我们将其扩展为资本化调整型炒作指数，该指数通过计算股票或行业的媒体权重与其在行业或部门内的市值权重之比来调整经济规模。我们在股票和行业层面计算了这两种版本的炒作指数，并通过多重视角对其进行了评估：（1）将其分类到不同的炒作组，（2）其与不同滞后期的收益、波动率和VIX指数的关联，（3）其对短期市场波动的信号能力，以及（4）其经验属性，包括相关性、采样和趋势。我们的研究结果表明，炒作指数家族为股票波动性分析、市场信号传递和金融领域NLP扩展提供了一套有价值的工具。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [520] [DELPHYNE: A Pre-Trained Model for General and Financial Time Series](https://arxiv.org/abs/2506.06288)
> *错误：AI分析失败。*

*Xueying Ding, Aakriti Mittal, Achintya Gopal* | **Main category: q-fin.ST**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [578] [Explainable-AI powered stock price prediction using time series transformers: A Case Study on BIST100](https://arxiv.org/abs/2506.06345)
> *错误：AI分析失败。*

*Sukru Selim Calik, Andac Akyuz, Zeynep Hilal Kilimci, Kerem Colak* | **Main category: q-fin.ST**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

### [850] [Towards Competent AI for Fundamental Analysis in Finance: A Benchmark Dataset and Evaluation](https://arxiv.org/abs/2506.07315)
> *错误：AI分析失败。*

*Zonghan Wu, Junlin Wang, Congyuan Zou, Chenhan Wang, Yilei Shao* | **Main category: q-fin.ST**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-finst) | [⬆️ 返回总目录](#toc)

---

<a id='csir'></a>
## cs.IR 

### [64] [FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models](https://arxiv.org/abs/2506.06335)
> *FinBERT2：一种专门的双向编码器，旨在弥合大型语言模型在金融领域部署中的差距*

*Xuan Xu, Fufang Wen, Beilin Chu, Zhibing Fu, Qinhong Lin, Jiaqi Liu, Binjie Fei, Zhongliang Yang, Linna Zhou, Yu Li* | **Main category: cs.IR**

**Keywords:** FinBERT2, 金融NLP, 双向编码器, 领域适应, 大型语言模型

**Comment:** 

> **TL;DR:** FinBERT2是一个专门的金融领域双向编码器，它通过在大型金融语料库上预训练，显著提升了大型语言模型在金融判别、检索和主题建模任务上的性能，弥补了现有LLM在该领域的不足。

**AI_Comments:** 这项工作非常重要，因为它直接解决了LLMs在特定领域（金融）部署中的实际痛点。通过开发一个领域特定的双向编码器（FinBERT2），作者证明了在某些任务上，经过精心设计的专业化小型模型仍能超越通用大型模型，尤其是在成本和效率方面。FinBERT2在中文金融语料上的大规模预训练，使其在中文金融NLP领域具有显著的应用价值。这项研究为在特定垂直领域中如何有效地利用和改进AI模型提供了新的视角，即并非所有任务都需要最大的LLM，有时领域优化的编码器可能是更优解。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在自然语言处理中占据主导地位，但在金融领域的实际应用中面临三大限制：(1) 在判别性任务上（如市场情绪分析）性能不如微调过的BERT且计算成本高；(2) 在生成性任务中依赖RAG方法，但通用检索器在领域特定检索任务上表现不佳；(3) 在主题建模等其他基于特征的场景中存在不足。

**Method:** 本文提出了FinBERT2，一个专门的双向编码器，它在一个包含320亿token的高质量金融特定语料库上进行了预训练。这是已知该参数规模模型中最大的中文金融预训练语料库。FinBERT2被用作一个更优的骨干模型。

**Result:** 1. 判别性微调模型（Fin-Labelers）在五项金融分类任务中，平均性能优于其他（Fin）BERT变体0.4%-3.3%，优于领先的LLM 9.7%-12.3%。
2. 对比性微调模型（Fin-Retrievers）在五项金融检索任务中，平均性能优于开源嵌入器（如BGE-base-zh，提高6.8%）和专有嵌入器（如OpenAI的text-embedding-3-large，提高4.2%）。
3. 基于FinBERT2变体构建的Fin-TopicModel，为金融标题提供了卓越的聚类和主题表示能力。

**Conclusion:** 这项工作通过与当代大型语言模型的比较分析，重新审视了金融BERT模型，并为在LLM时代有效利用FinBERT提供了实用的见解。

> **ai_Abstract:** 该论文提出了FinBERT2，一个专门针对金融领域训练的双向编码器，旨在解决当前大型语言模型（LLMs）在金融应用中面临的性能和效率问题。通过在一个大规模高质量中文金融语料库上预训练，FinBERT2在多项金融分类、检索和主题建模任务上显著超越了现有BERT变体和领先的LLMs，证明了其作为金融领域LLM骨干模型的优越性，并为该领域的实际部署提供了有效途径。

> **摘要翻译:** 在自然语言处理（NLP）中，焦点已从BERT等仅编码器的小型语言模型转向GPT-3等仅解码器的大型语言模型（LLMs）。然而，LLMs在金融领域的实际应用暴露出三个局限性：(1) 尽管计算资源成本高昂，LLMs在判别性任务（例如金融报告中的市场情绪分析）上的表现通常不如微调过的BERT；(2) 生成性任务的应用严重依赖于检索增强生成（RAG）方法来提供当前和专业信息，而通用检索器在领域特定检索任务上表现不佳；(3) 在其他基于特征的场景（如主题建模）中存在额外不足。我们介绍了FinBERT2，一个专门的双向编码器，它在一个包含320亿token的高质量金融特定语料库上进行了预训练。这是已知该参数规模模型中最大的中文金融预训练语料库。作为更好的骨干模型，FinBERT2可以通过以下成就弥合LLMs在金融领域部署中的差距：(1) 判别性微调模型（Fin-Labelers）在五项金融分类任务中，平均性能优于其他（Fin）BERT变体0.4%-3.3%，优于领先的LLMs 9.7%-12.3%。(2) 对比性微调模型（Fin-Retrievers）在五项金融检索任务中，表现优于开源（例如，比BGE-base-zh平均提高6.8%）和专有（例如，比OpenAI的text-embedding-3-large平均提高4.2%）嵌入器；(3) 基于FinBERT2变体，我们构建了Fin-TopicModel，它能够为金融标题提供卓越的聚类和主题表示。我们的工作通过与当代LLMs的比较分析，重新审视了金融BERT模型，并为在LLM时代有效利用FinBERT提供了实用的见解。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [191] [NR4DER: Neural Re-ranking for Diversified Exercise Recommendation](https://arxiv.org/abs/2506.06341)
> *NR4DER: 神经网络重排序用于多样化习题推荐*

*Xinghe Cheng, Xufang Zhou, Liangda Fang, Chaobo He, Yuyu Zhou, Weiqi Luo, Zhiguo Gong, Quanlong Guan* | **Main category: cs.IR**

**Keywords:** 习题推荐, 神经网络重排序, 在线教育, 多样性推荐, mLSTM

**Comment:** accepted for presentation at the SIGIR 2025 Full Papers track

> **TL;DR:** NR4DER模型通过结合mLSTM、序列增强和神经网络重排序，解决了在线教育中习题推荐的准确性和多样性不足问题，尤其针对学习节奏多样和不活跃的学生。

**AI_Comments:** NR4DER的创新点在于其多阶段的推荐框架，特别是引入了针对不活跃学生的序列增强和用于多样性推荐的神经网络重排序，这对于提升在线教育平台的学习体验和降低辍学率具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有习题推荐方法在在线教育中面临高辍学率、难以匹配学生多样化学习节奏、难以适应不活跃学生学习模式以及推荐准确性和多样性有限等挑战。

**Method:** NR4DER模型首先利用mLSTM模型提升习题过滤模块的有效性；其次，采用序列增强方法增强不活跃学生的表示，以准确匹配学生与适当难度的习题；最后，利用神经网络重排序根据学生的学习历史生成多样化的推荐列表。

**Result:** 广泛的实验结果表明，NR4DER在多个真实世界数据集上显著优于现有方法，并能有效满足学生多样化的学习节奏。

**Conclusion:** NR4DER模型通过其多阶段方法有效地解决了在线教育中习题推荐的准确性和多样性问题，特别是在处理学生学习节奏多样性方面表现出色。

> **ai_Abstract:** 本论文提出了一种名为NR4DER的神经网络重排序模型，旨在解决在线教育中习题推荐的准确性和多样性不足问题。针对现有方法难以匹配学生多样化学习节奏和适应不活跃学生学习模式的痛点，NR4DER通过结合mLSTM进行习题过滤、序列增强来表征不活跃学生以及神经网络重排序生成多样化推荐列表。实验证明，NR4DER在真实数据集上表现优异，并有效提升了推荐的准确性和多样性，适应了学生不同的学习节奏。

> **摘要翻译:** 随着在线教育平台的广泛普及，越来越多的学生通过大规模开放在线课程（MOOCs）获取新知识。习题推荐在改善学生学习成果方面取得了进展。然而，现有方法不仅难以解决高辍学率问题，也未能匹配学生多样化的学习节奏。它们经常在适应不活跃学生的学习模式和适应个性化学习节奏方面面临困难，导致推荐的准确性和多样性有限。为了解决这些挑战，我们提出了用于多样化习题推荐的神经网络重排序（简称NR4DER）。NR4DER首先利用mLSTM模型提高习题过滤模块的有效性。然后，它采用序列增强方法增强不活跃学生的表示，准确匹配学生与适当难度的习题。最后，它利用神经网络重排序根据学生个人学习历史生成多样化的推荐列表。广泛的实验结果表明，NR4DER在多个真实世界数据集上显著优于现有方法，并能有效满足学生多样化的学习节奏。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [231] [DISRetrieval: Harnessing Discourse Structure for Long Document Retrieval](https://arxiv.org/abs/2506.06313)
> *DISRetrieval：利用语篇结构进行长文档检索*

*Huiyao Chen, Yi Yang, Yinghui Li, Meishan Zhang, Min Zhang* | **Main category: cs.IR**

**Keywords:** 长文档检索, 语篇结构, 层次检索, 大型语言模型, 修辞结构理论

**Comment:** 21 pages, 7 figures

> **TL;DR:** DISRetrieval是一个新颖的层次检索框架，通过利用语篇结构显著改善了长文档检索和下游问答任务的性能。

**AI_Comments:** 该论文的创新点在于将语言学中的语篇结构理论（RST）引入到长文档检索中，通过构建层次化的文档表示来克服现有方法的局限性。这种方法不仅提升了检索效率，也为LLMs处理长文本提供了更具语义和结构性的上下文。其贡献在于提供了一个更符合人类理解模式的长文档处理范式。

<details>
  <summary>Details</summary>

**Motivation:** 现有长文档检索方法未能有效捕捉指导人类理解的内在语篇结构，导致在处理大型语言模型（LLMs）的上下文长度限制时表现不佳。

**Method:** 本文提出了DISRetrieval，一个新颖的层次检索框架，它利用语言语篇结构来增强长文档理解。该方法包含三项关键创新：1) 一个语篇感知的文档组织框架，利用修辞结构理论（RST）创建句子级层次表示；2) 一种LLM增强的节点表示技术，结合语篇结构与自适应摘要来丰富树节点；3) 一种层次证据检索机制，有效选择相关内容并保持语篇连贯性。

**Result:** 在QASPER和QuALITY数据集上的全面实验表明，DISRetrieval在token级检索指标和下游问答任务上均显著优于现有方法。消融研究证实，结合语篇结构显著增强了不同文档长度和查询类型的检索效率。

**Conclusion:** 本研究验证了语言学信息丰富的文档表示在长文本理解中的重要性，并证明了通过整合语篇结构可以显著提高长文档检索的有效性。

> **ai_Abstract:** DISRetrieval是一个新颖的层次检索框架，旨在通过利用语言语篇结构来改进长文档理解和检索。它通过语篇感知的文档组织、LLM增强的节点表示和层次证据检索机制，解决了现有方法未能捕捉文档内在语篇结构的问题。在QASPER和QuALITY数据集上的实验表明，DISRetrieval在检索和问答任务上均表现出色，证明了语篇结构在长文本理解中的重要性。

> **摘要翻译:** 长文档理解在自然语言处理中变得越来越重要，而基于检索的方法已成为解决大型语言模型（LLM）上下文长度限制的一种有前景的解决方案。然而，现有方法要么将文档视为扁平序列，要么采用任意分块策略，未能捕捉指导人类理解的内在语篇结构。我们提出了DISRetrieval，一个新颖的层次检索框架，它利用语言语篇结构来增强长文档理解。我们的方法引入了三项关键创新：（1）一个语篇感知的文档组织框架，它利用修辞结构理论（RST）创建句子级层次表示，同时保留语义关系和自然的文档流；（2）一种LLM增强的节点表示技术，它将语篇结构与自适应摘要相结合，以用上下文信息丰富树节点；以及（3）一种层次证据检索机制，它能有效选择相关内容，同时保持语篇连贯性。通过在QASPER和QuALITY数据集上进行的全面实验，DISRetrieval在token级检索指标和下游问答任务上均显著优于现有方法。我们的消融研究证实，结合语篇结构显著提高了不同文档长度和查询类型的检索效率，验证了语言学信息丰富的文档表示在长文本理解中的重要性。我们的代码和数据集已在github/DreamH1gh/DISRetrieval公开发布，以促进未来的研究。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [240] [A Reinforcement-Learning-Enhanced LLM Framework for Automated A/B Testing in Personalized Marketing](https://arxiv.org/abs/2506.06316)
> *强化学习增强的LLM框架，用于个性化营销中的自动化A/B测试*

*Haoyang Feng, Yanjun Dai, Yuan Gao* | **Main category: cs.IR**

**Keywords:** 强化学习, 大型语言模型, A/B测试, 个性化营销, 策略优化

**Comment:** 

> **TL;DR:** 本文提出了一个RL-LLM-AB测试框架，结合强化学习和LLM实现自动化个性化A/B测试，并展示了其在真实营销数据上的优越性。

**AI_Comments:** 这篇论文的创新点在于将强化学习与大型语言模型相结合，应用于A/B测试的自动化和个性化，特别是在营销领域。通过整合用户画像和上下文，并引入长期偏好捕捉机制，该框架有望显著提升A/B测试的效率和效果，为个性化营销提供了一个强大的新工具。其优势在于能够实时动态调整策略并考虑长期用户反馈，超越了传统A/B测试的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 针对个性化营销中如何有效算法化A/B测试以最大化用户响应的挑战。

**Method:** 提出了RL-LLM-AB测试框架。该框架基于预训练的指令调优语言模型，通过Prompt-Conditioned Generator生成A/B版本内容，多模态感知模块融合用户画像和查询上下文构成交互状态，策略优化模块（Actor-Critic结构）实时选择内容版本并根据反馈（点击率、转化率）估计长期收益。此外，嵌入Memory-Augmented Reward Estimator以捕捉长期用户偏好漂移，泛化策略。

**Result:** 数值结果表明，所提出的RL-LLM-ABTest框架在真实营销数据上优于现有A/B测试方法，包括经典A/B测试、上下文强盗算法和基准强化学习方法。

**Conclusion:** RL-LLM-AB测试框架能够有效自动化和个性化A/B测试，并在个性化营销中实现更好的用户响应最大化。

> **ai_Abstract:** 本文提出了一种名为RL-LLM-AB测试的创新框架，旨在通过结合强化学习的策略优化能力和大型语言模型（LLM）的生成与理解能力，实现个性化营销中的自动化A/B测试。该框架利用LLM生成内容变体，并动态整合用户画像与查询上下文以形成交互状态，随后通过基于Actor-Critic的强化学习模块实时选择最佳内容版本并估计长期收益。此外，引入记忆增强奖励估计器以适应用户偏好变化。实验结果表明，该框架在真实营销数据上显著优于传统及基准A/B测试方法。

> **摘要翻译:** 对于个性化营销，如何有效算法化A/B测试以最大化用户响应是一个亟待解决的新挑战。在本文中，我们提出了一种新方法，即RL-LLM-AB测试框架，用于结合强化学习策略优化和LLM来自动化和个性化A/B测试。RL-LLM-AB测试建立在预训练的指令调优语言模型之上。它首先使用Prompt-Conditioned Generator生成A/B版本的候选内容变体，然后通过多模态感知模块动态嵌入和融合用户画像和当前查询的上下文，构成当前的交互状态。内容版本随后通过具有Actor-Critic结构的策略优化模块实时选择，并根据实时反馈（如点击率和转化率）估计长期收益。此外，框架中嵌入了一个记忆增强奖励估计器，以捕捉长期用户偏好漂移，这有助于在多个用户和内容上下文中泛化策略。数值结果表明，我们提出的RL-LLM-ABTest在真实世界营销数据上优于现有A/B测试方法，包括经典A/B测试、上下文强盗算法和基准强化学习方法。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [290] [Is BERTopic Better than PLSA for Extracting Key Topics in Aviation Safety Reports?](https://arxiv.org/abs/2506.06328)
> *BERTopic在航空安全报告关键主题提取方面是否优于PLSA？*

*Aziida Nanyonga, Joiner Keith, Turhan Ugur, Wild Graham* | **Main category: cs.IR**

**Keywords:** BERTopic, PLSA, 航空安全, 主题建模, NTSB报告

**Comment:** 

> **TL;DR:** 本研究发现，BERTopic在从航空安全报告中提取主题方面优于PLSA，在主题连贯性和可解释性方面表现更佳。

**AI_Comments:** 本研究通过实证比较，突出了现代基于Transformer的主题建模方法（如BERTopic）在处理复杂、非结构化文本数据方面的优越性，特别是在航空安全这一关键领域。其创新性在于将先进的自然语言处理技术应用于实际安全报告分析，为提升航空安全理解和决策提供了新的工具。研究结果对未来在类似领域应用更先进的AI模型具有指导意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在比较BERTopic和PLSA在从航空安全报告中提取有意义主题方面的有效性，以增强对航空事件数据模式的理解。

**Method:** 本研究使用了超过36,000份2000年至2020年的美国国家运输安全委员会（NTSB）报告数据集。BERTopic采用了基于Transformer的嵌入和层次聚类，而PLSA则通过期望最大化（EM）算法利用概率建模。

**Result:** 结果显示，BERTopic在主题连贯性方面优于PLSA，其Cv得分为0.41，而PLSA为0.37，同时经航空安全专家验证，BERTopic还表现出卓越的可解释性。

**Conclusion:** 这些发现强调了现代基于Transformer的方法在分析复杂航空数据集方面的优势，为增强航空安全领域的洞察力和知情决策铺平了道路。

> **ai_Abstract:** 本研究比较了BERTopic和PLSA在从航空安全报告中提取关键主题的有效性。研究使用了超过36,000份NTSB报告数据集，发现BERTopic在主题连贯性（Cv得分为0.41）和专家验证的可解释性方面均优于PLSA（Cv得分为0.37）。这表明现代基于Transformer的方法在分析复杂航空数据方面具有显著优势，有助于提升航空安全洞察和决策。

> **摘要翻译:** 本研究比较了BERTopic和概率潜在语义分析（PLSA）在从航空安全报告中提取有意义主题方面的有效性，旨在增强对航空事件数据模式的理解。研究使用了2000年至2020年间超过36,000份美国国家运输安全委员会（NTSB）报告的数据集，BERTopic采用了基于Transformer的嵌入和层次聚类，而PLSA则通过期望最大化（EM）算法利用概率建模。结果显示，BERTopic在主题连贯性方面优于PLSA，其Cv得分为0.41，而PLSA为0.37，同时经航空安全专家验证，BERTopic还表现出卓越的可解释性。这些发现强调了现代基于Transformer的方法在分析复杂航空数据集方面的优势，为增强航空安全领域的洞察力和知情决策铺平了道路。未来的工作将探索混合模型、多语言数据集和高级聚类技术，以进一步改进该领域的主题建模。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [313] [Preference-based learning for news headline recommendation](https://arxiv.org/abs/2506.06334)
> *新闻标题推荐中的偏好学习*

*Alexandre Bouras, Audrey Durand, Richard Khoury* | **Main category: cs.IR**

**Keywords:** 偏好学习, 新闻标题推荐, 语境多臂老虎机, 用户参与度, 在线推荐

**Comment:** 

> **TL;DR:** 本研究探讨了在语境多臂老虎机设置下，通过偏好学习优化新闻标题推荐策略，并发现有噪声语境下可能不需要显式探索。

**AI_Comments:** 这项研究的创新之处在于将偏好学习应用于新闻标题推荐，并特别关注了在语境多臂老虎机设置下，翻译对用户参与度预测的影响。其发现显式探索在噪声语境下可能不必要，为实际系统设计提供了简化和效率提升的潜力，具有重要的实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机是探索优化新闻标题推荐的策略，并评估翻译对用户参与度预测的影响以及不同交互策略在数据收集过程中对用户参与度的益处。

**Method:** 本研究使用真实世界的法语在线新闻用户交互数据，在语境多臂老虎机（contextual bandit）设置下学习了一个新闻标题推荐代理。

**Result:** 研究结果表明，在存在噪声语境的情况下，可能不需要显式探索。

**Conclusion:** 在有噪声语境的实际应用中，可以采用更简单但高效的策略进行新闻标题推荐，而无需进行显式探索。

> **ai_Abstract:** 本研究旨在通过偏好学习优化新闻标题推荐。研究利用真实的法语用户交互数据，在语境多臂老虎机框架下构建推荐代理，以探究翻译对用户参与度预测的影响以及不同交互策略的效益。核心发现是在噪声语境下，显式探索可能并非必需，这为实际应用提供了更简洁高效的推荐策略。

> **摘要翻译:** 本研究探讨了通过基于偏好学习来优化新闻标题推荐的策略。我们利用用户与法语在线新闻帖子互动的真实世界数据，在语境多臂老虎机设置下学习了一个新闻标题推荐代理。这使我们能够探索翻译对参与度预测的影响，以及不同交互策略在数据收集过程中对用户参与度的益处。我们的结果表明，在存在噪声语境的情况下，可能不需要显式探索，这为实践中更简单但高效的策略打开了大门。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [322] [Research on E-Commerce Long-Tail Product Recommendation Mechanism Based on Large-Scale Language Models](https://arxiv.org/abs/2506.06336)
> *基于大规模语言模型的电商长尾商品推荐机制研究*

*Qingyi Lu, Haotian Lyu, Jiayun Zheng, Yang Wang, Li Zhang, Chengrui Zhou* | **Main category: cs.IR**

**Keywords:** 长尾商品推荐, 大规模语言模型, 电商, 数据稀疏, 协同过滤

**Comment:** 

> **TL;DR:** 针对电商长尾商品推荐中的数据稀疏和冷启动问题，本文提出了一种结合大规模语言模型（LLM）的推荐机制，通过语义表征和用户意图编码，显著提高了长尾商品的召回率、命中率和用户覆盖率。

**AI_Comments:** 这项研究创新性地将大规模语言模型应用于电商长尾商品推荐，有效解决了传统方法在数据稀疏和冷启动方面的挑战。通过结合语义理解和用户行为模式，该方法为提升长尾商品的曝光和销售提供了新的途径，对未来的个性化推荐系统发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 随着电商平台产品目录的扩展，准确推荐长尾商品对于提升用户体验和平台收入至关重要。传统推荐方法面临数据稀疏和冷启动的长尾问题，性能受限。

**Method:** 提出了一种结合产品文本描述和用户行为序列的长尾商品推荐机制，使用大规模语言模型（LLM）。首先，引入语义视窗利用预训练LLM将多模态文本内容（如商品标题、描述、用户评论）转换为有意义的嵌入。其次，采用基于注意力的用户意图编码器，通过建模协同行为模式捕获用户潜在兴趣。最后，这些组件输入到混合排序模型中，融合语义相似度分数、协同过滤输出和LLM生成的推荐候选。

**Result:** 在真实电商数据集上的广泛实验表明，该方法在召回率（+12%）、命中率（+9%）和用户覆盖率（+15%）方面优于基线模型，从而提高了长尾商品的曝光率和购买率。

**Conclusion:** 该研究强调了LLM在解释产品内容和用户意图方面的潜力，为未来的电商推荐系统提供了有前景的方向。

> **ai_Abstract:** 本文提出了一种基于大规模语言模型（LLM）的电商长尾商品推荐机制，旨在解决传统方法在数据稀疏和冷启动问题上的不足。该机制通过LLM将产品文本内容转化为语义嵌入，并利用注意力机制编码用户对长尾商品的兴趣，最终通过混合排序模型生成推荐。实验结果显示，该方法显著提升了长尾商品的召回率、命中率和用户覆盖率，证明了LLM在电商推荐中的应用潜力。

> **摘要翻译:** 随着电商平台产品目录的扩展，准确推荐长尾商品对于提升用户体验和平台收入变得越来越重要。一个关键挑战是长尾问题，即极端数据稀疏性和冷启动问题限制了传统推荐方法的性能。为了解决这个问题，我们提出了一种新颖的长尾商品推荐机制，该机制利用大规模语言模型（LLM）整合产品文本描述和用户行为序列。首先，我们引入了一个语义视窗，它利用预训练的LLM将产品标题、描述和用户评论等多模态文本内容转换为有意义的嵌入。这些嵌入有助于有效表示项目级语义。然后，我们采用了一个基于注意力的用户意图编码器，通过建模协同行为模式来捕获用户的潜在兴趣，特别是对长尾商品的兴趣。这些组件被输入到一个混合排序模型中，该模型融合了语义相似度分数、协同过滤输出和LLM生成的推荐候选。在真实世界的电商数据集上进行的广泛实验表明，我们的方法在召回率（+12%）、命中率（+9%）和用户覆盖率（+15%）方面优于基线模型。这些改进使得长尾商品的曝光率和购买率更高。我们的工作突出了LLM在解释产品内容和用户意图方面的潜力，为未来的电商推荐系统提供了有前景的方向。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [333] [Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components](https://arxiv.org/abs/2506.06339)
> *优化阿拉伯语RAG管道：核心组件的系统分析*

*Jumana Alsubhi, Mohammad D. Alahmadi, Ahmed Alhusayni, Ibrahim Aldailami, Israa Hamdine, Ahmad Shabana, Yazeed Iskandar, Suhayb Khayyat* | **Main category: cs.IR**

**Keywords:** RAG, 阿拉伯语, 优化, 嵌入模型, 重排序器

**Comment:** 

> **TL;DR:** 本研究对阿拉伯语RAG管道的核心组件进行了全面实证评估，发现句子感知分块、BGE-M3和Multilingual-E5-large嵌入模型、bge-reranker-v2-m3重排序器以及Aya-8B语言模型表现最佳，为构建高质量阿拉伯语RAG提供了实用指导。

**AI_Comments:** 这项研究填补了阿拉伯语RAG管道优化领域的空白，通过系统的实证分析提供了宝贵的实践指导。其创新性在于首次对阿拉伯语RAG核心组件进行了全面评估，并明确指出了在特定语言环境下表现最佳的组件组合。这对于推动阿拉伯语自然语言处理技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管RAG管道在处理高资源语言方面已得到广泛研究，但其组件在阿拉伯语环境下的优化仍未得到充分探索，因此需要进行系统性评估。

**Method:** 本研究对分块策略、嵌入模型、重排序器和语言模型等RAG核心组件进行了全面的实证评估。实验使用了多样化的阿拉伯语数据集，并利用RAGAS框架，通过上下文精度、上下文召回率、答案忠实度和答案相关性四个核心指标系统地比较了性能。

**Result:** 实验结果表明，句子感知分块优于所有其他分段方法。BGE-M3和Multilingual-E5-large是最有效的嵌入模型。重排序器（bge-reranker-v2-m3）的加入显著提高了复杂数据集的忠实度。Aya-8B在生成质量上超越了StableLM。

**Conclusion:** 这些发现为构建高质量的阿拉伯语RAG管道提供了关键见解，并为不同文档类型选择最佳组件提供了实用指南。

> **ai_Abstract:** 本研究针对阿拉伯语RAG（检索增强生成）管道的核心组件进行了首次全面实证评估。通过系统比较分块策略、嵌入模型、重排序器和语言模型在多个阿拉伯语数据集上的表现，研究发现句子感知分块、BGE-M3和Multilingual-E5-large嵌入模型、bge-reranker-v2-m3重排序器以及Aya-8B语言模型在各项指标上表现突出。这些结果为优化阿拉伯语RAG系统提供了关键指导和实用建议。

> **摘要翻译:** 检索增强生成（RAG）已成为一种强大的架构，能够将检索系统的精确性与大型语言模型的流畅性相结合。尽管有几项研究调查了高资源语言的RAG管道，但阿拉伯语RAG组件的优化仍未得到充分探索。本研究对最先进的RAG组件——包括分块策略、嵌入模型、重排序器和语言模型——在多样化的阿拉伯语数据集上进行了全面的实证评估。我们使用RAGAS框架，系统地比较了上下文精度、上下文召回率、答案忠实度和答案相关性这四个核心指标的性能。我们的实验表明，句子感知分块优于所有其他分段方法，而BGE-M3和Multilingual-E5-large成为最有效的嵌入模型。重排序器（bge-reranker-v2-m3）的加入显著提高了复杂数据集的忠实度，并且Aya-8B在生成质量上超越了StableLM。这些发现为构建高质量的阿拉伯语RAG管道提供了关键见解，并为不同文档类型选择最佳组件提供了实用指南。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [339] [Structured Semantics from Unstructured Notes: Language Model Approaches to EHR-Based Decision Support](https://arxiv.org/abs/2506.06340)
> *从非结构化笔记中获取结构化语义：基于EHR的决策支持中的语言模型方法*

*Wu Hao Ran, Xi Xi, Furong Li, Jingyi Lu, Jian Jiang, Hui Huang, Yuzhuan Zhang, Shi Li* | **Main category: cs.IR**

**Keywords:** 大型语言模型, 电子健康记录, 临床决策支持, 非结构化数据, 语义表示

**Comment:** 

> **TL;DR:** 本文探讨了大型语言模型（LLMs）如何应用于电子健康记录（EHRs）中的非结构化数据，以改善临床决策支持，并讨论了相关挑战与机遇。

**AI_Comments:** 这篇论文探讨了将LLMs应用于医疗领域的核心挑战，即从非结构化EHR数据中提取有价值的结构化语义。它强调了文本特征的重要性，并关注了数据协调、代码整合以及AI模型通用性和公平性等关键问题，这对于推动医疗AI的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索大型语言模型在分析医疗领域复杂、非结构化数据（特别是EHR中的自由文本临床笔记）方面的应用，以利用这些数据源改善临床决策支持，并解决传统EHR分析中对文本特征的忽视问题。

**Method:** 本文探讨了应用先进语言模型来利用电子健康记录（EHRs）中多样化的数据源，包括自由文本临床笔记、结构化实验室结果和诊断代码，以改进临床决策支持。研究将讨论文本特征如何提供语义丰富的表示并协调跨机构数据，并深入探讨结合医疗代码以及确保AI模型在医疗保健中通用性和公平性的挑战和机遇。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文探讨了利用大型语言模型分析电子健康记录（EHRs）中复杂、非结构化数据，以改进临床决策支持的应用。研究重点在于如何利用EHR中多样化的数据源，特别是文本特征，来提供语义丰富的表示并协调跨机构数据。同时，文章也讨论了整合医疗代码以及确保AI模型在医疗保健领域通用性和公平性所面临的挑战和机遇。

> **摘要翻译:** 大型语言模型（LLMs）的出现为分析复杂的非结构化数据开辟了新途径，特别是在医疗领域。电子健康记录（EHRs）包含各种格式的丰富信息，包括自由文本临床笔记、结构化实验室结果和诊断代码。本文探讨了先进语言模型在利用这些多样化数据源以改进临床决策支持方面的应用。我们将讨论文本特征（在传统高维EHR分析中常被忽视）如何提供语义丰富的表示，并有助于协调跨不同机构的数据。此外，我们深入探讨了结合医疗代码以及确保人工智能模型在医疗保健中通用性和公平性的挑战和机遇。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [510] [GOLFer: Smaller LM-Generated Documents Hallucination Filter & Combiner for Query Expansion in Information Retrieval](https://arxiv.org/abs/2506.04762)
> *错误：AI分析失败。*

*Lingyuan Liu, Mengxiang Zhang* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [638] [Infinity Search: Approximate Vector Search with Projections on q-Metric Spaces](https://arxiv.org/abs/2506.06557)
> *错误：AI分析失败。*

*Antonio Pariente, Ignacio Hounie, Santiago Segarra, Alejandro Ribeiro* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [812] [HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval](https://arxiv.org/abs/2506.07296)
> *错误：AI分析失败。*

*Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted at ACL 2025, Main track. 13 Pages, 1 figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [859] [Correcting for Position Bias in Learning to Rank: A Control Function Approach](https://arxiv.org/abs/2506.06989)
> *错误：AI分析失败。*

*Md Aminul Islam, Kathryn Vasilaky, Elena Zheleva* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [872] [RADAR: Recall Augmentation through Deferred Asynchronous Retrieval](https://arxiv.org/abs/2506.07261)
> *错误：AI分析失败。*

*Amit Jaspal, Qian Dang, Ajantha Ramineni* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [876] [LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking](https://arxiv.org/abs/2506.07449)
> *错误：AI分析失败。*

*Vahid Azizi, Fatemeh Koochaki* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [887] [MoE-MLoRA for Multi-Domain CTR Prediction: Efficient Adaptation with Expert Specialization](https://arxiv.org/abs/2506.07563)
> *错误：AI分析失败。*

*Ken Yagel, Eyal German, Aviel Ben Siman Tov* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [901] [OneSug: The Unified End-to-End Generative Framework for E-commerce Query Suggestion](https://arxiv.org/abs/2506.06913)
> *错误：AI分析失败。*

*Xian Guo, Ben Chen, Siyuan Wang, Ying Yang, Chenyi Lei, Yuqing Ding, Han Li* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 11 pages, 8 figures, and 6 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [947] [Research Knowledge Graphs: the Shifting Paradigm of Scholarly Information Representation](https://arxiv.org/abs/2506.07285)
> *错误：AI分析失败。*

*Matthäus Zloch, Danilo Dessì, Jennifer D'Souza, Leyla Jael Castro, Benjamin Zapilko, Saurav Karmakar, Brigitte Mathiak, Markus Stocker, Wolfgang Otto, Sören Auer, Stefan Dietze* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** Extended Semantic Web Conference 2025, In-use track, 10 pages, 1
  figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

### [965] [Leveraging Historical and Current Interests for Continual Sequential Recommendation](https://arxiv.org/abs/2506.07466)
> *错误：AI分析失败。*

*Gyuseok Lee, Hyunsik Yoo, Junyoung Hwang, SeongKu Kang, Hwanjo Yu* | **Main category: cs.IR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csir) | [⬆️ 返回总目录](#toc)

---

<a id='cscc'></a>
## cs.CC 

### [68] [Robust predicate and function computation in continuous chemical reaction networks](https://arxiv.org/abs/2506.06590)
> *连续化学反应网络中的鲁棒谓词和函数计算*

*Kim Calabrese, David Doty, Mina Latifi* | **Main category: cs.CC**

**Keywords:** 化学反应网络, 鲁棒计算, 谓词计算, 函数计算, 质量作用模型

**Comment:** 

> **TL;DR:** 本文研究了连续化学反应网络（CRNs）中布尔谓词和数值函数的鲁棒计算。鉴于CRNs在稳定计算下对布尔谓词的决策能力有限，作者引入了“鲁棒计算”这一概念，并证明了CRNs在鲁棒计算下能够实现更广泛的布尔谓词和分段仿射函数计算。

**AI_Comments:** 本文的创新之处在于引入了“鲁棒计算”这一概念，为化学反应网络的设计提供了一种更实际的计算模型，克服了传统“稳定计算”在布尔谓词决策上的局限性。这对于理解和构建基于化学反应的计算系统具有重要意义，尤其是在生物计算和分子编程领域。

<details>
  <summary>Details</summary>

**Motivation:** 之前的研究发现，在“稳定”（完全速率无关）计算下，连续化学反应网络（CRNs）在布尔谓词的决策能力上受到严重限制，其答案仅基于输入是否为零或正。为了克服这一限制，作者引入了一种略微放宽的速率无关计算概念，即“鲁棒计算”。

**Method:** 本文采用标准的质量作用速率模型，其中每个反应的速率等于其反应物浓度乘积与速率常数的乘积。如果CRN在任何正速率常数选择下都能收敛到正确的输出，则认为计算是“鲁棒”的。研究通过理论分析，证明了CRN在鲁棒计算下的能力。

**Result:** 1. 与函数计算相反，连续CRN在稳定地决定布尔谓词方面受到严重限制。
2. CRN可以鲁棒地决定所有有限的“阈值谓词”布尔组合，即通过对输入加权求和并与常数比较定义的谓词。
3. CRN可以鲁棒地计算任何具有有理系数的分段仿射函数，其中阈值谓词决定了给定输入的仿射片段。

**Conclusion:** 通过引入“鲁棒计算”的概念，本文扩展了连续化学反应网络在布尔谓词和数值函数计算上的能力范围，使其能够处理更复杂的计算任务，如阈值谓词和分段仿射函数，这为基于化学反应的计算提供了更实际的模型。

> **ai_Abstract:** 本文探讨了连续化学反应网络（CRNs）中布尔谓词和数值函数的计算能力。鉴于CRN在“稳定”计算（完全速率无关）下对布尔谓词的决策能力存在严重限制，作者引入了“鲁棒计算”这一新概念。鲁棒计算允许CRN在质量作用速率模型下，只要速率常数为正，就能收敛到正确结果。研究表明，CRN能够鲁棒地决定所有有限的阈值谓词布尔组合，并能鲁棒地计算任何具有有理系数的分段仿射函数，显著扩展了CRN的计算能力。

> **摘要翻译:** 我们首次研究了连续化学反应网络（CRNs）模型中布尔谓词和数值函数的速率常数无关计算，该模型将化学物质的量建模为非负实值浓度。实值数值函数之前已被研究，发现只有连续、分段有理线性函数 $f: \mathbb{R}_{> 0}^k \to \mathbb{R}_{> 0}$ 可以被“稳定”地计算，也称为“速率无关”计算，这意味着CRN无论反应速率如何都能得到正确答案。
我们发现，与函数计算相反，连续CRN在稳定地决策布尔谓词方面受到严重限制，其答案仅基于哪些输入是零或正值。
这种限制促使我们提出了一种略微放宽的CRN速率无关计算概念，我们称之为“鲁棒计算”。这里使用标准的质量作用速率模型，其中每个反应被赋予一个等于其反应物浓度乘积和其速率常数的速率。如果在此模型中，计算对于任何正速率常数选择都能收敛到正确的输出，则计算是正确的。这种对抗者弱于稳定计算的对抗者，后者能够以非质量作用速率运行反应。
我们表明，CRN可以鲁棒地决定所有有限的“阈值谓词”布尔组合：这些谓词通过对输入 $\mathbf{x} \in \mathbb{R}^k_{\ge 0}$ 进行有理加权求和并与常数比较来定义，回答“$\sum_{i=1}^k w_i \cdot \mathbf{x}(i) > h$ 吗？”的问题，其中 $w_i$ 是有理权重，$h$ 是实数阈值。转向函数计算，我们表明CRN可以鲁棒地计算任何具有有理系数的分段仿射函数，其中阈值谓词决定了给定输入的仿射片段。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

### [799] [#P is Sandwiched by One and Two #2DNF Calls: Is Subtraction Stronger Than We Thought?](https://arxiv.org/abs/2506.06716)
> *错误：AI分析失败。*

*Max Bannach, Erik D. Demaine, Timothy Gomez, Markus Hecher* | **Main category: cs.CC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscc) | [⬆️ 返回总目录](#toc)

---

<a id='physicssoc-ph'></a>
## physics.soc-ph 

### [71] [Powers of Magnetic Graph Matrix: Fourier Spectrum, Walk Compression, and Applications](https://arxiv.org/abs/2506.07343)
> *磁图矩阵的幂：傅里叶谱、游走压缩及应用*

*Yinan Huang, David F. Gleich, Pan Li* | **Main category: physics.soc-ph**

**Keywords:** 磁图矩阵, 傅里叶变换, 游走压缩, 有向网络, 链接预测

**Comment:** 

> **TL;DR:** 本文提出了一种通过有向游走剖面来解释磁图矩阵幂的新方法，并建立了其与傅里叶变换的联系，从而实现了游走剖面的精确和近似重构，并展示了在识别受挫有向循环和链接预测等方面的应用。

**AI_Comments:** 本文通过对磁图矩阵的幂进行新颖的组合解释，并将其与傅里叶变换联系起来，为分析复杂有向网络的局部、非平衡行为提供了一个强大的新框架。其创新之处在于揭示了磁矩阵信息的可压缩性，并为图分析中的新应用（如识别受挫循环和链接预测）开辟了道路，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究主要利用磁图矩阵的谱特性来研究全局和静态网络特征，但其建模局部、非平衡行为（通常由矩阵幂描述）的能力尚未得到充分探索。

**Method:** 本文通过有向游走剖面（按边反转次数索引的图游走计数）对磁图矩阵的幂进行了新颖的组合解释。关键是，研究建立了游走剖面与磁矩阵幂的傅里叶变换之间的对应关系。

**Result:** 游走剖面与磁矩阵幂的傅里叶变换相对应，这使得可以从多个离散电位的磁矩阵幂中精确重构游走剖面。更重要的是，在实际网络中，通常只需要更少数量的电位就可以实现准确的近似重构，这表明磁矩阵捕获的信息具有经验可压缩性。

**Conclusion:** 这种新的视角为磁图矩阵的幂提供了新的应用，例如，它们可以识别受挫的有向循环（如前馈环），并且可以通过编码有向图中的局部结构细节有效地用于链接预测。

> **ai_Abstract:** 本文提出了一种通过有向游走剖面来解释磁图矩阵幂的新颖组合方法，并建立了游走剖面与磁矩阵幂的傅里叶变换之间的对应关系。这一发现使得能够从多个离散电位的磁矩阵幂中精确重构游走剖面，并且在实际网络中，少量电位即可实现准确的近似重构，揭示了磁矩阵信息的可压缩性。这种新视角为识别受挫有向循环和通过编码局部结构细节进行链接预测等应用提供了可能性。

> **摘要翻译:** 磁图最初是为了模拟磁场下的量子系统而开发的，最近已成为分析复杂有向网络的强大框架。现有研究主要利用磁图矩阵的谱特性来研究全局和静态网络特征。然而，它们建模局部、非平衡行为（通常由矩阵幂描述）的能力在很大程度上仍未被探索。我们通过有向游走剖面（即按边反转次数索引的图游走计数）对磁图矩阵的幂进行了一种新颖的组合解释。至关重要的是，我们确定游走剖面对应于磁矩阵幂的傅里叶变换。这种联系允许从多个离散电位的磁矩阵幂中精确重构游走剖面，更重要的是，在实际网络中，通常只需要更少数量的电位就可以实现准确的近似重构。这表明磁矩阵捕获的信息具有经验可压缩性。这种新的视角提出了新的应用；例如，我们说明了磁矩阵的幂如何识别受挫的有向循环（例如，前馈环），并且可以通过编码有向图中的局部结构细节有效地用于链接预测。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

### [98] [Refugees' path to legal stability is long and systematically unequal](https://arxiv.org/abs/2506.07916)
> *难民获得法律稳定性的道路漫长且系统性不平等*

*Ola Ali, Elma Dervic, Guillermo Prieto-Viertel, Carsten Källner, Rainer Stütz, Andrea Vismara, Rafael Prieto-Curiel* | **Main category: physics.soc-ph**

**Keywords:** 难民, 法律稳定性, 移民融合, 不平等, 奥地利

**Comment:** 

> **TL;DR:** 难民在奥地利获得法律身份的“法律旅程”漫长且存在系统性不平等，不同国籍和性别面临显著差异，非官方入境者更难获得稳定身份。

**AI_Comments:** 这篇论文的创新之处在于其大规模的数据集（超过35万奥地利移民）和基于网络的方法，揭示了难民法律整合过程中的系统性不平等。研究结果对政策制定者具有重要意义，凸显了制度设计、程序入口和不同国籍/性别背景对难民“法律旅程”的深刻影响，为优化难民庇护和融入政策提供了实证依据。

<details>
  <summary>Details</summary>

**Motivation:** 法律系统不仅影响移民和难民的认定，还影响他们融入社会的速度和稳定性。难民经常在多种法律分类之间转换，这一“法律旅程”通常漫长且不确定，因此需要分析其模式。

**Method:** 使用基于网络的方法，分析了2022年至2024年间奥地利超过35万移民的法律过渡过程。

**Result:** 难民获得稳定身份的途径高度不平等，乌克兰人平均2个月，叙利亚人9个月，阿富汗人20个月。女性，尤其是来自这些地区的女性，更有可能获得保护；阿富汗男性平均等待时间长达30个月。未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。

**Conclusion:** 法律融合不是一个统一的过程，而是由制度设计、程序切入点和不平等的时程结构化的。

> **ai_Abstract:** 该研究分析了奥地利超过35万移民的“法律旅程”，揭示难民获得法律稳定性的过程漫长且存在系统性不平等。研究发现，不同国籍（如乌克兰、叙利亚、阿富汗）和性别（特别是阿富汗男性）的难民在获得保护和稳定身份的时间上存在显著差异。此外，未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。研究强调，法律融合是一个由制度设计和不平等时间线结构化的非统一过程。

> **摘要翻译:** 法律系统不仅塑造了对移民和难民的承认，也塑造了他们融入社会的速度和稳定性。难民经常在多种法律分类之间转换，我们称之为“法律旅程”。这一旅程通常漫长且不确定。我们采用基于网络的方法，分析了2022年至2024年间奥地利超过35万移民的法律过渡过程。难民在获得稳定身份方面面临高度不平等的途径，乌克兰人只需2个月，叙利亚人9个月，阿富汗人则需20个月。女性，特别是来自这些地区的女性，更有可能获得保护；阿富汗男性平均等待时间长达30个月。我们还发现，未经官方边境检查入境者面临更高的离境率和更低获得稳定身份的机会。我们表明，法律融合并非一个统一的过程，而是由制度设计、程序切入点和不平等的时程所结构化的。

</details>

[⬆️ 返回分类顶部](#physicssoc-ph) | [⬆️ 返回总目录](#toc)

---

<a id='eesssp'></a>
## eess.SP 

### [118] [WiFi Pathologies Detection using LLMs](https://arxiv.org/abs/2506.06943)
> *使用LLM进行WiFi故障检测*

*Forough Shirin Abkenar* | **Main category: eess.SP**

**Keywords:** WiFi故障检测, 大型语言模型, 微调, IEEE 802.11, 网络病理学

**Comment:** 

> **TL;DR:** 本文微调LLM来检测WiFi网络故障，其中序贯模型在有标签数据上表现良好，而因果模型在无标签数据上表现出色。

**AI_Comments:** 这篇论文的创新点在于将大型语言模型应用于WiFi网络故障检测这一特定领域，并探索了不同类型的LLMs（编码器-only和解码器-only）在有标签和无标签数据上的性能差异。这为网络故障诊断提供了新的思路，并展示了LLMs在非传统NLP任务中的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 检测IEEE 802.11（WiFi）网络中的故障（pathologies）。

**Method:** 微调编码器-only和解码器-only大型语言模型（LLMs），方法包括手动设计提示词后进行微调。

**Result:** 评估显示，序贯模型在使用有标签数据时实现了高检测精度，而因果模型在无标签数据上的表现同样出色。

**Conclusion:** 通过微调LLMs，可以有效地检测WiFi网络故障，不同类型的LLM模型在有标签和无标签数据上表现出各自的优势。

> **ai_Abstract:** 本文研究了使用微调的大型语言模型（LLMs）来检测WiFi网络故障。通过手动设计提示词并对编码器-only和解码器-only LLMs进行微调，作者发现序贯模型在有标签数据上表现出高检测精度，而因果模型在无标签数据上同样表现良好，表明LLMs在WiFi故障诊断中的潜力。

> **摘要翻译:** 在本文中，我们对仅编码器和仅解码器的大型语言模型（LLMs）进行了微调，以检测IEEE 802.11网络（通常称为WiFi）中的故障。我们的方法涉及手动制作提示词，然后进行微调。评估表明，序贯模型在使用有标签数据时实现了高检测精度，而因果模型在无标签数据上的表现同样出色。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [198] [On the Interplay of Privacy, Persuasion and Quantization](https://arxiv.org/abs/2506.06321)
> *隐私、说服与量化的相互作用*

*Anju Anand, Emrah Akyol* | **Main category: eess.SP**

**Keywords:** 隐私, 网络物理系统, 量化, 目标不一致, 权衡

**Comment:** 

> **TL;DR:** 本文提出了一个通信理论框架，用于网络物理系统中在编码器和解码器目标不一致的情况下的隐私感知和弹性决策，分析了不同策略和最优控制器，并展示了隐私参数如何平衡控制性能和抗未授权推理的能力。

**AI_Comments:** 这篇论文解决了网络物理系统中一个关键且实际的问题，即在系统组件目标不一致的情况下实现隐私感知决策。编码器通过拉格朗日优化同时平衡控制和隐私的方法具有创新性。对不同信息揭示策略的分析以及在有限速率信道中使用基于梯度的方法，展示了研究方法的全面性。关于隐私参数如何影响控制性能和弹性之间权衡的发现，为设计安全高效的网络物理系统提供了宝贵的见解。

<details>
  <summary>Details</summary>

**Motivation:** 传统的通信设置中，编码器和解码器通常共享一个共同的目标（例如MSE），但这在网络物理系统中，尤其是在涉及隐私保护的决策制定时，编码器和解码器可能存在目标不一致（例如，编码器需要平衡控制精度和隐私泄露，而解码器只关注估计误差）。这种目标不一致导致了冲突，因此需要开发一个新的通信理论框架来解决这一问题。

**Method:** 本文开发了一个通信理论框架，用于在编码器和解码器目标不一致的情况下实现隐私感知和弹性决策。编码器观察两个相关信号($X$,$	heta$)并发送有限速率消息$Z$给解码器以估计$X+	heta$，同时防止窃听者推断私有参数$	heta$。编码器通过最小化一个平衡合法控制精度和$	heta$隐私泄露的拉格朗日函数进行优化，而解码器仅最小化其自身的估计误差。研究分析了由此冲突产生的完全揭示、部分揭示和不揭示策略，并在解除速率约束时表征了最优线性编码器。对于有限速率信道，采用基于梯度的方法来计算最优控制器。

**Result:** 数值实验表明，调整隐私参数可以塑造控制性能和抵御未经授权推理的弹性之间的权衡。

**Conclusion:** 调整隐私参数对于管理网络物理系统中控制性能和抵御未经授权推理的弹性之间的权衡至关重要。

> **ai_Abstract:** 本文提出了一个通信理论框架，用于解决网络物理系统中编码器和解码器目标不一致时的隐私感知与弹性决策问题。研究中，编码器在平衡控制精度和隐私泄露的前提下进行优化，而解码器则纯粹追求最小化估计误差。文章分析了多种信息揭示策略，并在无限速率条件下推导了最优线性编码器，对于有限速率信道则采用梯度方法计算最优控制器。数值实验结果表明，通过调整隐私参数，可以有效权衡控制系统性能与抵抗未授权推理的能力。

> **摘要翻译:** 我们开发了一个通信理论框架，用于在编码器和解码器目标不一致的网络物理系统中进行隐私感知和弹性决策。编码器观察两个相关信号($X$,$	heta$)并传输一个有限速率消息$Z$，以帮助合法的控制器（解码器）估计$X+	heta$，同时窃听者截获$Z$以推断私有参数$	heta$。与编码器和解码器共享共同MSE目标的传统设置不同，本文中编码器最小化一个平衡合法控制精度和$	heta$隐私泄露的拉格朗日函数。相反，解码器的目标纯粹是最小化其自身的估计误差，而不考虑隐私。我们全面分析了由此冲突产生的完全揭示、部分揭示和不揭示策略，并在解除速率约束时表征了最优线性编码器。对于有限速率信道，我们采用基于梯度的方法来计算最优控制器。数值实验说明了调整隐私参数如何塑造控制性能和抵御未经授权推理的弹性之间的权衡。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [207] [High-gain MIMO Beamforming Antenna System for DSRC and mmwave 5G Integration in Autonomous Vehicles](https://arxiv.org/abs/2506.06354)
> *用于自动驾驶车辆中DSRC和毫米波5G集成的高增益MIMO波束赋形天线系统*

*Mohammad Shahed Pervez, Amanpreet Kaur* | **Main category: eess.SP**

**Keywords:** MIMO, 波束赋形, 自动驾驶车辆, DSRC, 毫米波5G

**Comment:** 

> **TL;DR:** 本文提出了一种新颖的高增益MIMO波束赋形天线系统，可同时支持自动驾驶车辆中的DSRC（5.9 GHz）和毫米波5G（28 GHz）通信。

**AI_Comments:** 该论文提出了一种创新的双频MIMO波束赋形天线系统，旨在解决自动驾驶车辆通信的关键需求。其创新点在于同时支持DSRC和毫米波5G，并关注了实际应用中的挑战，如紧凑性和波束控制。这项工作对于推动自动驾驶车辆的通信技术发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 自动驾驶车辆的发展需要鲁棒、高速、低延迟的无线通信系统。

**Method:** 本文提出了一种新颖的高增益多输入多输出（MIMO）波束赋形天线系统，该系统可同时支持5.9 GHz的专用短程通信（DSRC）和28 GHz的毫米波（mmWave）5G通信。该设计解决了动态车辆环境中紧凑性、双频操作、波束控制能力以及端口间隔离等挑战。

**Result:** Not mentioned in abstract

**Conclusion:** Not mentioned in abstract

> **ai_Abstract:** 本文介绍了一种专为自动驾驶车辆设计的新型高增益MIMO波束赋形天线系统。该系统能够同时支持5.9 GHz的DSRC和28 GHz的毫米波5G通信，并解决了紧凑性、双频操作、波束控制和端口隔离等关键挑战，旨在满足自动驾驶车辆对鲁棒、高速、低延迟无线通信的需求。

> **摘要翻译:** 自动驾驶车辆的演进需要鲁棒、高速、低延迟的无线通信系统。本文提出了一种新颖的高增益多输入多输出（MIMO）波束赋形天线系统，该系统可同时支持5.9 GHz的专用短程通信（DSRC）和28 GHz的毫米波（mmWave）5G通信。所提出的设计解决了动态车辆环境中紧凑性、双频操作、波束控制能力以及端口间隔离等挑战。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [214] [Cascaded Multiwire-PLC/Multiple-VLC System: Characterization and Performance](https://arxiv.org/abs/2506.06357)
> *级联多线电力线通信/多可见光通信系统：特性与性能*

*Hugerles S. Silva, Higo T. P. Silva, Paulo V. B. Tomé, Felipe A. P. Figueiredo, Edson P. da Silva, Rausley A. A. de Souza* | **Main category: eess.SP**

**Keywords:** 电力线通信, 可见光通信, 混合系统, 性能分析, 级联系统

**Comment:** 

> **TL;DR:** 本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统，并通过推导原创分析表达式和蒙特卡洛仿真验证了其性能和在多种应用场景中的可行性。

**AI_Comments:** 该论文的创新之处在于提出了一个新型的级联多线电力线通信/多可见光通信混合系统架构，并首次推导了其关键性能指标的原创分析表达式，填补了该领域研究的空白。其提出的低成本、高性能和广泛应用前景的特点，使其在未来智能环境和物联网等领域具有重要应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提出一种具有低安装成本、增强性能、实用可行性及广泛应用范围的通信系统，以满足智能环境、物联网等下一代网络的需求。

**Method:** 本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统。通过推导关键统计数据、中断概率、误码概率和遍历信道容量指标的新颖分析表达式来表征系统性能。此外，利用蒙特卡洛仿真对分析结果进行了验证，并在各种信道和PLC/VLC系统参数下展示了性能曲线。

**Result:** 研究推导了关键统计数据、中断概率、误码概率和遍历信道容量的原创分析表达式。这些分析结果通过蒙特卡洛仿真得到了验证。结果表明，所提出的系统在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络中均具有可行性。

**Conclusion:** 所提出的级联多线电力线通信/多可见光通信混合系统具有低安装成本、增强性能和广泛的应用前景，并已证明在智能环境、物联网网络和下一代网络等多种应用场景中是可行的。

> **ai_Abstract:** 本文提出并分析了一种级联多线电力线通信（PLC）/多可见光通信（VLC）混合系统。该系统旨在提供低安装成本、增强性能和广泛应用。研究通过推导原创的分析表达式来表征系统性能，并使用蒙特卡洛仿真验证了这些结果，证明了其在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络等多种应用场景中的可行性。

> **摘要翻译:** 本文提出了一种级联多线电力线通信（PLC）/多可见光通信（VLC）系统。这种混合架构具有低安装成本、增强的性能、实际可行性和广泛的应用范围。文中推导了关键统计数据、中断概率、误码概率和遍历信道容量指标的新颖分析表达式。此外，分析结果通过蒙特卡洛仿真进行了验证，并在各种信道和PLC/VLC系统参数下展示了多条性能曲线。本工作中推导出的所有表达式都是原创的，以前从未发表过。我们提出的系统被证明在智能环境、绿色通信系统、物联网网络、工业环境和下一代网络中是可行的。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [223] [Model-based Neural Data Augmentation for sub-wavelength Radio Localization](https://arxiv.org/abs/2506.06387)
> *基于模型的神经数据增强用于亚波长无线电定位*

*Baptiste Chatelier, Vincent Corlay, Musa Furkan Keskin, Matthieu Crussière, Henk Wymeersch, Luc Le Magoarou* | **Main category: eess.SP**

**Keywords:** 无线电定位, 神经网络数据增强, 指纹识别, 非视距, 亚波长

**Comment:** 

> **TL;DR:** 该论文提出了一种基于模型的神经网络数据增强方法，显著提高了指纹识别无线电定位的精度并降低了内存需求，尤其在非视距（NLoS）环境中表现出色。

**AI_Comments:** 这项工作创新性地将模型驱动的神经网络与传统的指纹识别定位框架相结合，通过生成式模型进行数据增强，有效解决了复杂无线电环境下定位精度和内存效率的矛盾。其在NLoS环境中实现亚波长精度的能力以及显著的内存优化，对于未来无线通信和定位技术的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 传统信号处理技术在复杂无线电环境（特别是NLoS路径主导的场景）中定位精度下降。现有的机器学习辅助定位方法虽然提高了精度，但在训练和推理阶段计算复杂度高。本文旨在同时减少指纹识别定位框架的内存需求并提高其精度。

**Method:** 该工作扩展了指纹识别定位框架，通过使用一个基于模型的神经网络来学习位置到信道的映射，并将其用作生成式神经信道模型。这个生成模型用于增强指纹识别的比较字典，同时降低内存需求。

**Result:** 所提出的方法在NLoS环境中实现了亚波长定位精度，优于传统的指纹识别基线方法。与经典指纹识别方法相比，定位精度提高了几个数量级，同时内存需求降低了一个数量级。

**Conclusion:** 该研究成功地通过引入基于模型的神经网络数据增强，显著提升了无线电定位的精度，特别是在挑战性的NLoS环境中，并同时有效地降低了内存消耗，为高精度、低开销的无线电定位提供了新的解决方案。

> **ai_Abstract:** 本文提出了一种新颖的基于模型的神经数据增强方法，用于亚波长无线电定位。通过使用一个学习位置到信道映射的生成式神经网络来增强指纹识别比较字典，该方法显著提高了在复杂NLoS环境中的定位精度，实现了亚波长级别，并且在定位精度方面提高了数个数量级，同时将内存需求降低了一个数量级，解决了传统方法在复杂环境中的局限性以及机器学习方法的高计算开销问题。

> **摘要翻译:** 基站大型天线阵列的日益部署显著提高了无线电定位方法的空间分辨率和定位精度。然而，传统的信号处理技术在复杂的无线电环境中，特别是在非视距（NLoS）传播路径占主导的场景中，表现不佳，导致定位精度下降。机器学习的最新发展促进了机器学习辅助定位技术的发展，提高了复杂无线电环境中的定位精度。然而，这些方法在训练和推理阶段通常涉及大量的计算复杂性。这项工作通过同时减少内存需求和提高精度来扩展了成熟的基于指纹识别的定位框架。具体来说，一个基于模型的神经网络被用来学习位置到信道的映射，然后作为生成式神经信道模型。这个生成模型在减少内存需求的同时增强了指纹识别的比较字典。所提出的方法优于指纹识别基线，即使在NLoS环境中也能实现亚波长定位精度。值得注意的是，与经典指纹识别方法相比，它在定位精度方面提供了几个数量级的改进，同时将内存需求降低了一个数量级。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [549] [MoE-Gyro: Self-Supervised Over-Range Reconstruction and Denoising for MEMS Gyroscopes](https://arxiv.org/abs/2506.06318)
> *错误：AI分析失败。*

*Feiyang Pan, Shenghe Zheng, Chunyan Yin, Guangbin Dou* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [575] [A Reinforcement Learning Approach for RIS-aided Fair Communications](https://arxiv.org/abs/2506.06344)
> *错误：AI分析失败。*

*Alex Pierron, Michel Barbeau, Luca De Cicco, Jose Rubio-Hernan, Joaquin Garcia-Alfaro* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 7 pages, 6 figures, 1 table, 16 references

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [584] [Deep learning methods for modeling infrasound transmission loss in the middle atmosphere](https://arxiv.org/abs/2506.06351)
> *错误：AI分析失败。*

*Alexis Le Pichon, Alice Janela Cameijo, Samir Aknine, Youcef Sklab, Souhila Arib, Quentin Brissaud, Sven Peter Naesholm* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [587] [Large Language Models for EEG: A Comprehensive Survey and Taxonomy](https://arxiv.org/abs/2506.06353)
> *错误：AI分析失败。*

*Naseem Babu, Jimson Mathew, A. P. Vinod* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [590] [Towards real-time assessment of infrasound event detection capability using deep learning-based transmission loss estimation](https://arxiv.org/abs/2506.06358)
> *错误：AI分析失败。*

*Alice Janela Cameijo, Alexis Le Pichon, Youcef Sklab, Souhila Arib, Quentin Brissaud, Sven peter Naesholm, Constantino Listowski, Samir Aknine* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 49 pages, 22 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [756] [Benchmarking Early Agitation Prediction in Community-Dwelling People with Dementia Using Multimodal Sensors and Machine Learning](https://arxiv.org/abs/2506.06306)
> *错误：AI分析失败。*

*Ali Abedi, Charlene H. Chu, Shehroz S. Khan* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 4 figures, 2 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [759] [An Open-Source Python Framework and Synthetic ECG Image Datasets for Digitization, Lead and Lead Name Detection, and Overlapping Signal Segmentation](https://arxiv.org/abs/2506.06315)
> *错误：AI分析失败。*

*Masoud Rahimi, Reza Karbasi, Abdol-Hossein Vahabie* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 5 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [762] [Heart Rate Classification in ECG Signals Using Machine Learning and Deep Learning](https://arxiv.org/abs/2506.06349)
> *错误：AI分析失败。*

*Thien Nhan Vo, Thanh Xuan Truong* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [777] [Leveraging Novel Ensemble Learning Techniques and Landsat Multispectral Data for Estimating Olive Yields in Tunisia](https://arxiv.org/abs/2506.06309)
> *错误：AI分析失败。*

*Mohamed Kefi, Tien Dat Pham, Thin Nguyen, Mark G. Tjoelker, Viola Devasirvatham, Kenichi Kashiwagi* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [779] [Enhancing Contrastive Learning-based Electrocardiogram Pretrained Model with Patient Memory Queue](https://arxiv.org/abs/2506.06310)
> *错误：AI分析失败。*

*Xiaoyu Sun, Yang Yang, Xunde Dong* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [781] [A Novel Shape-Aware Topological Representation for GPR Data with DNN Integration](https://arxiv.org/abs/2506.06311)
> *错误：AI分析失败。*

*Meiyan Kang, Shizuo Kaji, Sang-Yun Lee, Taegon Kim, Hee-Hwan Ryu, Suyoung Choi* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 15 pages, 6 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [784] [Composite Reward Design in PPO-Driven Adaptive Filtering](https://arxiv.org/abs/2506.06323)
> *错误：AI分析失败。*

*Abdullah Burkan Bereketoglu* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 5 pages, 9 figures, 1 table, , Keywords: Adaptive filtering,
  reinforcement learning, PPO, noise reduction, signal denoising

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [785] [Uncertainty-Aware Multi-view Arrhythmia Classification from ECG](https://arxiv.org/abs/2506.06342)
> *错误：AI分析失败。*

*Mohd Ashhad, Sana Rahmani, Mohammed Fayiz, Ali Etemad, Javad Hashemi* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** This paper has been accepted to IJCNN 2024 conference

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [788] [LD-RPMNet: Near-Sensor Diagnosis for Railway Point Machines](https://arxiv.org/abs/2506.06346)
> *错误：AI分析失败。*

*Wei Li, Xiaochun Wu, Xiaoxi Hu, Yuxuan Zhang, Sebastian Bader, Yuhan Huang* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** This paper is accepted for IEEE Sensors Applcations Symposium (SAS)
  2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [791] [Multi-Platform Methane Plume Detection via Model and Domain Adaptation](https://arxiv.org/abs/2506.06348)
> *错误：AI分析失败。*

*Vassiliki Mancoridis, Brian Bue, Jake H. Lee, Andrew K. Thorpe, Daniel Cusworth, Alana Ayasse, Philip G. Brodrick, Riley Duren* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages 8 figures. In review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [796] [Towards Generalizable Drowsiness Monitoring with Physiological Sensors: A Preliminary Study](https://arxiv.org/abs/2506.06360)
> *错误：AI分析失败。*

*Jiyao Wang, Suzan Ayas, Jiahao Zhang, Xiao Wen, Dengbo He, Birsen Donmez* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by HFES2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [804] [Transformer-Based Decomposition of Electrodermal Activity for Real-World Mental Health Applications](https://arxiv.org/abs/2506.06378)
> *错误：AI分析失败。*

*Charalampos Tsirmpas, Stasinos Konstantopoulos, Dimitris Andrikopoulos, Konstantina Kyriakouli, Panagiotis Fatouros* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [841] [IQFM A Wireless Foundational Model for I/Q Streams in AI-Native 6G](https://arxiv.org/abs/2506.06718)
> *错误：AI分析失败。*

*Omar Mashaal, Hatem Abou-Zeid* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [853] [Conditional Denoising Diffusion for ISAC Enhanced Channel Estimation in Cell-Free 6G](https://arxiv.org/abs/2506.06942)
> *错误：AI分析失败。*

*Mohammad Farzanullah, Han Zhang, Akram Bin Sediq, Ali Afana, Melike Erol-Kantarci* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** IEEE PIMRC conference, 6 pages, 6 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [900] [Diffusion Models-Aided Uplink Channel Estimation for RIS-Assisted Systems](https://arxiv.org/abs/2506.07770)
> *错误：AI分析失败。*

*Yang Wang, Yin Xu, Cixiao Zhang, Zhiyong Chen, Xiaowu Ou, Mingzeng Dai, Meixia Tao, Wenjun Zhang* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 5 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [1014] [Experimental Performances of mmWave RIS-assisted 5G-Advanced Wireless Deployments in Urban Environments](https://arxiv.org/abs/2506.06525)
> *错误：AI分析失败。*

*Ahmet Faruk Coskun, Alper Tolga Kocaoglu, Emre Arslan, Zehra Yigit, Samed Kesir, Batuhan Kaplan, Jianwu Dou, Yijun Cui* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages, 8 figures, 3 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

### [1015] [RIS Size Determination Across Frequencies and Deployment Scenarios: A Simulation-Based Study](https://arxiv.org/abs/2506.06528)
> *错误：AI分析失败。*

*Emre Arslan, Ahmet Faruk Coskun* | **Main category: eess.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages, 5 figures, 4 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssp) | [⬆️ 返回总目录](#toc)

---

<a id='csne'></a>
## cs.NE 

### [121] [Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies](https://arxiv.org/abs/2506.06325)
> *社区微电网中基于鹰鸽策略的能源交易演化模型*

*Viorica Rozina Chifu, Tudor Cioara, Cristina Bianca Pop, Ionut Anghel* | **Main category: cs.NE**

**Keywords:** 社区微电网, 能源交易, 演化算法, 鹰鸽策略, 去中心化模型

**Comment:** 

> **TL;DR:** 提出一种去中心化能源合作模型，通过演化算法和鹰鸽策略实现社区微电网的能源平衡。

**AI_Comments:** 该论文提出了一种新颖的将演化算法和博弈论（鹰鸽策略）应用于社区微电网能源交易的去中心化模型。其创新性在于将微电网行为抽象为简单的博弈策略，并通过演化过程优化整体能源平衡。模型的去中心化特性使其更适用于实际部署，且在模拟场景中表现出良好的能源稳定效果。

<details>
  <summary>Details</summary>

**Motivation:** 解决社区微电网中去中心化能源合作的问题，实现能源交易的本地决策和能源平衡。

**Method:** 本文提出一个去中心化的能源合作模型，将每个微电网建模为采用鹰或鸽策略的自主代理。通过演化算法模拟买卖微电网之间的互动，其中个体表示为能源交易矩阵。算法通过重组和变异操作实现种群演化，并使用多标准适应度函数进行评估，考虑了卖方利润、社区能源稳定性、能源不平衡惩罚和电池退化。

**Result:** 该方法在一个包含100个微电网的模拟场景中进行了测试，其中95个微电网达到了稳定的能源状态。

**Conclusion:** 结果证实了所提出模型在实现个体微电网和整个社区层面能源平衡的有效性。

> **ai_Abstract:** 本文提出了一种基于鹰鸽策略的去中心化演化模型，用于社区微电网的能源交易与合作。模型将微电网视为自主代理，其行为（鹰或鸽）取决于电池能量水平。通过演化算法模拟微电网间的能源交易，以能源交易矩阵为个体，并利用多标准适应度函数进行评估。在包含100个微电网的模拟场景中，该模型成功使95个微电网达到稳定能源状态，证明了其在实现个体和社区层面能源平衡的有效性。

> **摘要翻译:** 本文提出了一种微电网之间能源合作的去中心化模型，其中决策在微电网社区层面本地做出。每个微电网都被建模为一个自主代理，根据电池中存储的能量水平及其在能源交易过程中的作用，采用鹰或鸽策略。买卖微电网之间的相互作用通过演化算法进行建模。算法种群中的个体表示为能量交易矩阵，该矩阵编码了买卖微电网之间交易的能量量。种群演化通过重组和变异操作实现。重组使用针对矩阵结构的专门操作符，变异根据高斯分布应用于矩阵元素。个体的评估通过多标准适应度函数进行，该函数考虑了卖方利润、社区层面的能量稳定性、社区层面的能量不平衡惩罚以及微电网电池的退化。该方法在一个包含100个微电网的模拟场景中进行了测试，每个微电网都有自己的买卖阈值，以反映具有可变微电网电池存储特性的现实环境。通过将算法应用于此场景，100个微电网中有95个达到了稳定的能源状态。这一结果证实了所提出模型在实现个体微电网和整个社区层面能源平衡的有效性。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [249] [EvoGrad: Metaheuristics in a Differentiable Wonderland](https://arxiv.org/abs/2506.06320)
> *EvoGrad：可微分仙境中的元启发式算法*

*Beatrice F. R. Citterio, Andrea Tangherloni* | **Main category: cs.NE**

**Keywords:** EvoGrad, 可微分编程, 进化计算, 群智能, 梯度优化

**Comment:** 

> **TL;DR:** EvoGrad是一个将进化计算和群智能算法与梯度优化相结合的可微分框架，通过使传统操作可微分，显著提高了优化效率，并在实验中超越了传统算法。

**AI_Comments:** EvoGrad的创新之处在于它首次统一了进化计算/群智能与可微分编程，使得元启发式算法能够利用梯度信息，从而显著提高了优化效率。这对于解决传统EC/SI在连续优化和深度学习训练中效率不足的问题具有重要意义，并可能开启混合优化算法的新研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的进化计算（EC）和群智能（SI）算法在离散或复杂搜索空间中表现出色，但通常不利用局部梯度信息，这限制了它们的优化效率。而可微分编程通过启用高效的基于梯度的训练，彻底改变了优化领域。

**Method:** 本文引入了EvoGrad，一个统一的可微分框架，通过反向传播将EC和SI与基于梯度的优化相结合。EvoGrad将传统的进化和群智能操作符（例如选择、变异、交叉和粒子更新）转换为可微分操作符，从而实现端到端的梯度优化。

**Result:** 在基准优化函数和小型神经网络回归器的训练中，EvoGrad的可微分版本的EC和SI元启发式算法在大多数情况下始终优于传统的、不感知梯度的算法。结果表明完全可微分的进化和群智能优化具有显著优势。

**Conclusion:** 本文提出的完全可微分的进化和群智能优化方法具有显著优势，为混合优化框架设定了新标准。

> **ai_Abstract:** 本文提出了EvoGrad，一个创新的可微分框架，它将传统的进化计算（EC）和群智能（SI）算法与基于梯度的优化方法相结合。通过将EC和SI的常见操作（如选择、变异、交叉和粒子更新）转化为可微分形式，EvoGrad实现了端到端的梯度优化。实验结果表明，与传统的、不感知梯度的算法相比，EvoGrad在基准测试和神经网络训练中表现出显著的性能提升，为混合优化领域树立了新标准。

> **摘要翻译:** 可微分编程通过实现复杂模型（如具有数十亿甚至数万亿参数的深度神经网络）的高效基于梯度的训练，彻底改变了优化领域。然而，传统的进化计算（EC）和群智能（SI）算法在离散或复杂搜索空间中取得了广泛成功，但通常不利用局部梯度信息，这限制了它们的优化效率。在本文中，我们引入了EvoGrad，一个统一的可微分框架，通过反向传播将EC和SI与基于梯度的优化相结合。EvoGrad将传统的进化和群智能操作符（例如选择、变异、交叉和粒子更新）转换为可微分操作符，从而实现端到端的梯度优化。在基准优化函数和小型神经网络回归器的训练中，我们对EC和SI元启发式算法的可微分版本进行了大量实验，结果显示它们在大多数情况下始终优于传统的、不感知梯度的算法。我们的结果表明完全可微分的进化和群智能优化具有显著优势，为混合优化框架设定了新标准。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [258] [Neural networks with image recognition by pairs](https://arxiv.org/abs/2506.06322)
> *成对图像识别的神经网络*

*Polad Geidarov* | **Main category: cs.NE**

**Keywords:** 神经网络, 图像识别, 度量识别, 成对训练, 机器学习

**Comment:** 

> **TL;DR:** 本文提出了一种通过成对图像识别来训练度量识别神经网络的方法，旨在简化学习过程并允许网络轻松扩展，无需依赖复杂的分析表达式来计算权重。

**AI_Comments:** 这篇论文提出了一种实用的方法来解决传统度量识别神经网络的局限性，即其固定的架构和对分析计算的依赖。通过引入“成对图像识别”的训练机制，它显著简化了学习过程，并增强了网络的可扩展性，使其能够更灵活地适应新的数据和类别。这种方法对于需要动态扩展和简化训练的实际应用场景具有重要意义，尤其是在图像识别领域。

<details>
  <summary>Details</summary>

**Motivation:** 传统的基于度量识别的神经网络架构严格固定，其神经元、连接、权重和阈值都是根据初始任务条件（如可识别类别数量、样本数量、度量表达式）通过分析方法计算出来的。本文的动机是探讨如何转换这些网络，以便能够应用经典的学习算法，而无需使用计算权重值的分析表达式。

**Method:** 本文讨论了将度量识别神经网络进行转换的可能性，以便能够对其应用经典的学习算法。在转换后的网络中，训练是通过成对识别图像来进行的。

**Result:** 这种方法简化了学习过程，并且允许通过向识别任务添加新图像来轻松扩展神经网络。这些网络的优点包括：1）网络架构的简单性和透明性；2）训练的简单性和可靠性；3）在识别问题中能够使用大量图像；4）在不改变先前权重和阈值值的情况下，可识别类别的数量可以持续增加。

**Conclusion:** 通过将度量识别神经网络转换为使用成对图像识别进行训练，可以实现学习过程的简化和网络的灵活扩展，同时保持架构的简单性、训练的可靠性，并支持大量图像和类别增长。

> **ai_Abstract:** 本文提出了一种改进基于度量识别的神经网络的方法，旨在通过成对图像识别来替代传统复杂的分析计算权重方式。这种新方法使得神经网络的训练过程更加简化和可靠，同时保持了架构的透明性。它还允许网络轻松扩展，支持处理大量图像，并在不影响现有参数的情况下持续增加可识别的类别数量，从而克服了传统方法中严格架构和计算的限制。

> **摘要翻译:** 基于度量识别方法的神经网络具有严格确定的架构。神经元、连接以及权重和阈值的值是根据任务的初始条件（可识别类别的数量、样本数量、使用的度量表达式）进行分析计算的。本文讨论了转换这些网络的可能性，以便对其应用经典的学习算法，而无需使用计算权重值的分析表达式。在接收到的网络中，训练是通过成对识别图像来进行的。这种方法简化了学习过程，并易于通过向识别任务添加新图像来扩展神经网络。这些网络的优点包括：1）网络架构的简单性和透明性；2）训练的简单性和可靠性；3）在识别问题中能够使用大量图像的能力；4）在不改变先前权重和阈值值的情况下，可识别类别的数量可以持续增加。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [305] [Introduction to Predictive Coding Networks for Machine Learning](https://arxiv.org/abs/2506.06332)
> *机器学习的预测编码网络介绍*

*Mikko Stenlund* | **Main category: cs.NE**

**Keywords:** 预测编码网络, 机器学习, 神经网络, CIFAR-10, PyTorch

**Comment:** 22 pages

> **TL;DR:** 本文旨在为机器学习从业者介绍预测编码网络（PCNs），涵盖其架构、更新规则，并提供一个使用PyTorch实现CIFAR-10图像分类的案例。

**AI_Comments:** 本文的重要性在于它向机器学习领域引入了一种受生物学启发的新型网络架构，即预测编码网络，为传统前馈神经网络提供了替代方案。通过提供具体的实现细节和PyTorch代码，极大地降低了实践者学习和应用PCNs的门槛。其在CIFAR-10任务上的“打破基准”表现，虽然抽象中未详细说明，但暗示了PCNs的强大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在为机器学习从业者提供预测编码网络（PCNs）的快速入门介绍，PCNs作为一种受生物学启发的框架，为机器学习中的传统前馈神经网络提供了一种替代方案。

**Method:** 本文涵盖了预测编码网络的基础网络架构、推理和学习更新规则，以及算法实现。通过一个具体的图像分类任务（CIFAR-10）作为应用案例，并提供了一个包含PyTorch实现的Python笔记本。

**Result:** 提供了一个在CIFAR-10图像分类任务上表现出色的应用案例，并附带了相应的PyTorch实现Python笔记本。

**Conclusion:** 本文作为预测编码网络的入门介绍，提供了其在机器学习中应用的具体实现和性能展示，表明PCNs是传统神经网络的有效替代方案。

> **ai_Abstract:** 本文为机器学习从业者提供了预测编码网络（PCNs）的入门指南，详细介绍了其基本架构、推理和学习更新规则以及算法实现。文中通过CIFAR-10图像分类任务展示了PCNs的实际应用，并提供了相应的PyTorch实现。

> **摘要翻译:** 预测编码网络（PCN）是一种受生物学启发的框架，用于理解大脑中的分层计算，并为机器学习中的传统前馈神经网络提供了一种替代方案。本笔记旨在为机器学习从业者快速、入门级地介绍PCN。我们涵盖了基础网络架构、推理和学习更新规则以及算法实现。提供了一个具体的图像分类任务（CIFAR-10）作为一项“打破基准”的应用，并附带了一个包含PyTorch实现的Python笔记本。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [379] [CR-BLEA: Contrastive Ranking for Adaptive Resource Allocation in Bilevel Evolutionary Algorithms](https://arxiv.org/abs/2506.06362)
> *CR-BLEA：双层进化算法中自适应资源分配的对比排序*

*Dejun Xu, Jijia Chen, Gary G. Yen, Min Jiang* | **Main category: cs.NE**

**Keywords:** 双层优化, 进化算法, 资源分配, 对比排序, 计算效率

**Comment:** 

> **TL;DR:** 提出CR-BLEA框架，通过对比排序网络自适应分配双层进化算法的资源，显著降低计算成本并保持或提高精度。

**AI_Comments:** 这项工作创新性地将对比学习引入双层进化算法的资源分配中，通过在线学习解决方案间的关系来智能地识别并优先处理有前景的下层任务，有效解决了双层优化中的计算效率瓶颈。其通用性和在不同算法上的良好表现，显示出该方法在提高双层进化算法可扩展性方面的巨大潜力。

<details>
  <summary>Details</summary>

**Motivation:** 双层优化，特别是双层进化算法，由于其嵌套结构和大量无前景下层任务的冗余评估，导致计算成本高昂和资源浪费。

**Method:** 提出CR-BLEA框架，核心是一个对比排序网络，它在线学习上层和下层解决方案对之间的关系模式。该知识指导一个基于参考的排序策略，优先处理优化任务，并根据估计的种群质量自适应控制重采样。

**Result:** 在五种最先进的双层算法上的综合实验表明，CR-BLEA框架显著降低了计算成本，同时保持或甚至提高了解决方案的准确性。

**Conclusion:** CR-BLEA为提高双层进化算法的效率提供了一种可推广的策略，为更具可扩展性的双层优化铺平了道路。

> **ai_Abstract:** 本文针对双层进化算法中计算成本高和资源浪费的问题，提出了一种名为CR-BLEA的新型资源分配框架。该框架的核心是利用一个对比排序网络，在线学习上、下层解决方案之间的关系模式，并以此指导一个基于参考的排序策略，从而智能地优先处理有前景的下层任务并自适应控制重采样。实验结果表明，CR-BLEA能显著降低计算成本，同时保持或提升解决方案的准确性，为双层优化领域提供了一种通用且高效的策略。

> **摘要翻译:** 双层优化由于其嵌套结构带来了显著的计算挑战，其中每个上层候选解都需要解决相应的下层问题。尽管进化算法（EAs）在处理这种复杂景观方面是有效的，但其高资源需求仍然是一个关键瓶颈——特别是大量无前景的下层任务的冗余评估。尽管多任务和迁移学习方面取得了最新进展，资源浪费仍然存在。为了解决这个问题，我们为双层进化算法提出了一种新颖的资源分配框架，该框架选择性地识别并专注于有前景的下层任务。我们方法的核心是一个对比排序网络，它在线学习成对的上层和下层解决方案之间的关系模式。这些知识指导一个基于参考的排序策略，该策略优先处理优化任务，并根据估计的种群质量自适应控制重采样。对五种最先进的双层算法进行的综合实验表明，我们的框架显著降低了计算成本，同时保持——甚至提高了——解决方案的准确性。这项工作提供了一种可推广的策略来提高双层进化算法的效率，为更具可扩展性的双层优化铺平了道路。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [401] [Structured State Space Model Dynamics and Parametrization for Spiking Neural Networks](https://arxiv.org/abs/2506.06374)
> *错误：AI分析失败。*

*Maxime Fabre, Lyubov Dudchenko, Emre Neftci* | **Main category: cs.NE**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [772] [Can Biologically Plausible Temporal Credit Assignment Rules Match BPTT for Neural Similarity? E-prop as an Example](https://arxiv.org/abs/2506.06904)
> *错误：AI分析失败。*

*Yuhan Helena Liu, Guangyu Robert Yang, Christopher J. Cueva* | **Main category: cs.NE**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [832] [Employing Discrete Fourier Transform in Representational Learning](https://arxiv.org/abs/2506.06765)
> *错误：AI分析失败。*

*Raoof HojatJalali, Edmondo Trentin* | **Main category: cs.NE**

**Keywords:** 错误：AI分析失败。

**Comment:** Preprint

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [914] [Research on Aerodynamic Performance Prediction of Airfoils Based on a Fusion Algorithm of Transformer and GAN](https://arxiv.org/abs/2506.06979)
> *错误：AI分析失败。*

*MaolinYang, Yaohui Wang, Pingyu Jiang* | **Main category: cs.NE**

**Keywords:** 错误：AI分析失败。

**Comment:** 33 pages,10 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

### [943] [Transient Dynamics in Lattices of Differentiating Ring Oscillators](https://arxiv.org/abs/2506.07253)
> *错误：AI分析失败。*

*Peter DelMastro, Arjun Karuvally, Hananel Hazan, Hava Siegelmann, Edward Rietman* | **Main category: cs.NE**

**Keywords:** 错误：AI分析失败。

**Comment:** 15 pages, 10 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csne) | [⬆️ 返回总目录](#toc)

---

<a id='mathna'></a>
## math.NA 

### [123] [Quantum-Enhanced Spectral Solution of the Poisson Equation](https://arxiv.org/abs/2506.07743)
> *量子增强的泊松方程谱解法*

*G. Intoccia, U. Chirico, G. Pepe, S. Cuomo* | **Main category: math.NA**

**Keywords:** 泊松方程, 量子傅里叶变换, 混合方法, 偏微分方程, 计算复杂度

**Comment:** 

> **TL;DR:** 本文提出了一种混合数值-量子方法，利用量子傅里叶变换（QFT）求解泊松方程，显著提高了计算效率并降低了时间和空间复杂度。

**AI_Comments:** 这项工作在量子计算应用于偏微分方程求解方面迈出了重要一步，特别是通过利用QFT来优化计算效率和资源消耗。其创新性在于将量子框架与数值方法相结合，直接估计系数，从而绕过经典计算的瓶颈。尽管论文承认量子实现仍面临挑战，但它为未来量子数值算法的发展提供了一个有价值的起点，对高性能计算和科学模拟领域具有潜在影响。

<details>
  <summary>Details</summary>

**Motivation:** 经典的泊松方程解法涉及大量积分计算，对于大量数据点而言计算成本高昂，因此需要一种更高效的方法。

**Method:** 本文提出了一种混合数值-量子方法，利用量子傅里叶变换（QFT）来增强计算效率并降低时间和空间复杂度。该方法直接在量子框架内估计解的级数展开系数，从而避免了经典方法中繁重的积分计算。

**Result:** 数值实验验证了该方法的有效性，并在时间、空间复杂度和解的准确性方面取得了显著改进。

**Conclusion:** 量子辅助技术能够有效解决偏微分方程（PDEs）。尽管量子实现存在固有的挑战，但这项工作为未来完善和扩展量子数值方法的研究奠定了基础。

> **ai_Abstract:** 该论文介绍了一种混合数值-量子方法，通过利用量子傅里叶变换（QFT）来高效地求解泊松方程，特别是在处理齐次狄利克雷边界条件时。该方法避免了传统方法的积分密集型计算，直接在量子领域估计解的级数展开系数。实验结果表明，与经典方法相比，该方法在计算时间、空间复杂度和解的准确性方面都有显著提升，凸显了量子辅助技术在解决偏微分方程中的潜力。

> **摘要翻译:** 我们提出了一种用于齐次狄利克雷边界条件下求解泊松方程的混合数值-量子方法，该方法利用量子傅里叶变换（QFT）来提高计算效率并降低时间和空间复杂度。这种方法绕过了经典方法中繁重的积分计算，后者在处理大量数据点时计算成本很高。所提出的方法直接在量子框架内估计解的级数展开系数。数值实验验证了其有效性，并在时间、空间复杂度和解的准确性方面取得了显著改进，展示了量子辅助技术在解决偏微分方程（PDEs）方面的能力。尽管量子实现存在固有的挑战，但目前的工作为未来旨在完善和扩展量子数值方法的研究提供了一个起点。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [528] [Energy-stable Port-Hamiltonian Systems](https://arxiv.org/abs/2506.06471)
> *错误：AI分析失败。*

*Patrick Buchfink, Silke Glas, Hans Zwart* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [613] [Efficient implementation of high-order isospectral symplectic Runge-Kutta schemes](https://arxiv.org/abs/2506.06533)
> *错误：AI分析失败。*

*Clauson Carvalho da Silva, Christian Lessig, Carlos Tomei* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [776] [A robust finite element method for linearized magnetohydrodynamics on general domains](https://arxiv.org/abs/2506.06685)
> *错误：AI分析失败。*

*L. Beirao da Veiga, C. Lovadina, M. Trezzi* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [790] [Deep regularization networks for inverse problems with noisy operators](https://arxiv.org/abs/2506.07008)
> *错误：AI分析失败。*

*Fatemeh Pourahmadian, Yang Xu* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [846] [Fully discrete finite element approximation for the projection method to solve the Chemotaxis-Fluid System](https://arxiv.org/abs/2506.06792)
> *错误：AI分析失败。*

*Chenyang Li* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [880] [Fourth- and higher-order finite element methods for the incompressible Navier-Stokes equations with Dirichlet boundary conditions](https://arxiv.org/abs/2506.06863)
> *错误：AI分析失败。*

*Yang Li, Heyu Wang, Qinghai Zhang* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [883] [A structure-preserving, second-order-in-time scheme for the von Neumann equation with power nonlinearity](https://arxiv.org/abs/2506.06879)
> *错误：AI分析失败。*

*Agissilaos Athanassoulis, Fotini Karakatsani, Irene Kyza* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [884] [Estimation of sparse polynomial approximation error to continuous function](https://arxiv.org/abs/2506.06880)
> *错误：AI分析失败。*

*Renzhong Feng, Bowen Zhang* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [886] [On the randomized SVD in infinite dimensions](https://arxiv.org/abs/2506.06882)
> *错误：AI分析失败。*

*Daniel Kressner, David Persson, André Uschmajew* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [924] [A novel efficient structure-preserving exponential integrator for Hamiltonian systems](https://arxiv.org/abs/2506.07072)
> *错误：AI分析失败。*

*Pan Zhang, Fengyang Xiao, Lu Li* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [928] [The PML method for calculating the propagating modes of electromagnetic wave in periodic structures](https://arxiv.org/abs/2506.07084)
> *错误：AI分析失败。*

*Lide Cai, Junqing Chen, Yanpeng Gao* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [931] [Computational homogenization of parabolic equations with memory effects for a periodic heterogeneous medium](https://arxiv.org/abs/2506.07111)
> *错误：AI分析失败。*

*P. N. Vabishchevich* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 19 pages, 13 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [932] [New highly efficient and accurate numerical scheme for the Cahn-Hilliard-Brinkman system](https://arxiv.org/abs/2506.07128)
> *错误：AI分析失败。*

*Dawei Chen, Qinzhen Ren, Minghui Li* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, 34 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [933] [Highly efficient linear energy stable methods for preserving the original energy dissipation law of the incompressible Navier-Stokes equation](https://arxiv.org/abs/2506.07141)
> *错误：AI分析失败。*

*Zihan Weng, Qi Hong, Yuezheng Gong* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [954] [2N-storage Runge-Kutta methods: Order conditions, general properties and some analytic solutions](https://arxiv.org/abs/2506.07359)
> *错误：AI分析失败。*

*Alexei Bazavov* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 33 pages, 2 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [955] [Numerical Approximation and Analysis of the Inverse Robin Problem Using the Kohn-Vogelius Method](https://arxiv.org/abs/2506.07370)
> *错误：AI分析失败。*

*Erik Burman, Siyu Cen, Bangti Jin, Zhi Zhou* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 25 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [957] [Multiscale model reduction and two-level Schwarz preconditioner for H(curl) elliptic problems](https://arxiv.org/abs/2506.07381)
> *错误：AI分析失败。*

*Chupeng Ma, Yongwei Zhang* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [961] [The pollution effect for the Ginzburg-Landau equation](https://arxiv.org/abs/2506.07433)
> *错误：AI分析失败。*

*Théophile Chaumont-Frelet, Patrick Henning* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [980] [IDENT Review: Recent Advances in Identification of Differential Equations from Noisy Data](https://arxiv.org/abs/2506.07604)
> *错误：AI分析失败。*

*Roy Y. He, Hao Liu, Wenjing Liao, Sung Ha Kang* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [987] [Data-Informed Mathematical Characterization of Absorption Properties in Artificial and Natural Porous Materials](https://arxiv.org/abs/2506.07656)
> *错误：AI分析失败。*

*Elishan C. Braun, Gabriella Bretti, Melania Di Fazio, Laura Medeghini, Mario Pezzella* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [997] [Minimal Subsampled Rank-1 Lattices for Multivariate Approximation with Optimal Convergence Rate](https://arxiv.org/abs/2506.07729)
> *错误：AI分析失败。*

*Felix Bartel, Alexander D. Gilbert, Frances Y. Kuo, Ian H. Sloan* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [1001] [Lengthscale-informed sparse grids for kernel methods in high dimensions](https://arxiv.org/abs/2506.07797)
> *错误：AI分析失败。*

*Elliot J. Addy, Jonas Latz, Aretha L. Teckentrup* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 43 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

### [1007] [FractionalDiffEq.jl: High Performance Fractional Differential Equation Solver in Julia](https://arxiv.org/abs/2506.07926)
> *错误：AI分析失败。*

*Qingyu Qu, Wei Ruan* | **Main category: math.NA**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathna) | [⬆️ 返回总目录](#toc)

---

<a id='q-bionc'></a>
## q-bio.NC 

### [134] [AI Agent Behavioral Science](https://arxiv.org/abs/2506.06366)
> *AI智能体行为科学*

*Lin Chen, Yunke Zhang, Jie Feng, Haoye Chai, Honglin Zhang, Bingbing Fan, Yibo Ma, Shiyuan Zhang, Nian Li, Tianhui Liu, Nicholas Sukiennik, Keyu Zhao, Yu Li, Ziyi Liu, Fengli Xu, Yong Li* | **Main category: q-bio.NC**

**Keywords:** AI智能体, 行为科学, 大型语言模型, 负责任AI, 类人行为

**Comment:** 

> **TL;DR:** 大型语言模型（LLM）的最新进展使得AI系统能够表现出类人行为，因此需要一门新的行为科学来理解和管理AI智能体在现实世界中的行动。

**AI_Comments:** 本论文提出了一个及时且至关重要的跨学科新领域。通过将研究焦点从AI的内部机制转向情境中的可观察行为，它为理解和管理日益自主的AI系统，尤其是在负责任AI原则方面，提供了一个实用的框架。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLM）的最新进展使得AI系统能够以越来越像人类的方式行事，在日益多样化、交互式和开放式的场景中表现出规划、适应和社交动态。这些行为不仅是模型内部架构的产物，更是它们集成到智能体系统中并在特定情境下运作的结果，其中目标、反馈和交互会随着时间推移塑造行为。这种转变呼唤一种新的科学视角：AI智能体行为科学，以理解这些在情境中产生的行为。

**Method:** AI智能体行为科学这种范式不只关注内部机制，而是强调系统地观察行为、设计干预措施以验证假设，以及对AI智能体如何随时间行动、适应和交互进行理论指导的解释。该研究系统化了跨个体、多智能体和人机交互设置的日益增长的研究。

**Result:** 这种新视角通过将公平性、安全性、可解释性、可问责性和隐私视为行为属性来指导负责任的AI。它统一了最新发现并提出了未来的研究方向。

**Conclusion:** AI智能体行为科学是传统方法的必要补充，为理解、评估和管理日益自主的AI系统的真实世界行为提供了基本工具。

> **ai_Abstract:** 大型语言模型使AI智能体能够展现类人行为。本论文提出“AI智能体行为科学”作为研究这些涌现行为的新范式。与传统关注内部机制的方法不同，该领域强调系统观察、干预设计以及对AI智能体在特定情境中行为的理论指导解释。它整合了现有研究，并通过将公平性、安全等属性视为行为特性来指导负责任的AI，为理解和管理自主AI提供了工具。

> **摘要翻译:** 大型语言模型（LLM）的最新进展使得AI系统能够以越来越像人类的方式行事，在日益多样化、交互式和开放式的场景中表现出规划、适应和社交动态。这些行为不仅是模型内部架构的产物，更是它们集成到智能体系统中并在特定情境下运作的结果，其中目标、反馈和交互会随着时间推移塑造行为。这种转变需要一种新的科学视角：AI智能体行为科学。这种范式不只关注内部机制，而是强调系统地观察行为、设计干预措施以验证假设，以及对AI智能体如何随时间行动、适应和交互进行理论指导的解释。我们系统化了跨个体、多智能体和人机交互设置的日益增长的研究，并进一步展示了这种视角如何通过将公平性、安全性、可解释性、可问责性和隐私视为行为属性来指导负责任的AI。通过统一最新发现并提出未来方向，我们将AI智能体行为科学定位为传统方法的必要补充，为理解、评估和管理日益自主的AI系统的真实世界行为提供了基本工具。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

### [803] [Less is More: some Computational Principles based on Parcimony, and Limitations of Natural Intelligence](https://arxiv.org/abs/2506.07060)
> *错误：AI分析失败。*

*Laura Cohen, Xavier Hinaut, Lilyana Petrova, Alexandre Pitti, Syd Reynal, Ichiro Tsuda* | **Main category: q-bio.NC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-bionc) | [⬆️ 返回总目录](#toc)

---

<a id='quant-ph'></a>
## quant-ph 

### [136] [A weighted quantum ensemble of homogeneous quantum classifiers](https://arxiv.org/abs/2506.07810)
> *同质量子分类器的加权量子集成*

*Emiliano Tolotti, Enrico Blanzieri, Davide Pastorello* | **Main category: quant-ph**

**Keywords:** 量子集成, 同质分类器, 加权平均, 量子机器学习, 预测精度

**Comment:** 21 pages, 4 figures

> **TL;DR:** 本文提出了一种加权同质量子分类器集成方法，利用量子分类器和经典权重优化来提高预测精度。

**AI_Comments:** 本文在量子机器学习领域具有创新性，它将经典的集成学习思想（特别是加权同质集成）引入了量子计算框架。通过利用量子叠加和并行性，它有效地解决了在量子模型中实现多样性和优化权重的问题。这种结合量子计算能力与经典优化策略的方法，为未来更强大的量子机器学习算法奠定了基础。

<details>
  <summary>Details</summary>

**Motivation:** 机器学习中的集成方法旨在通过结合多个模型来提高预测精度。传统集成方法通过确保预测器之间的多样性来捕捉不同的数据方面，并且加权平均集成通过权重学习过程为更准确的模型分配更高的影响力。本文的动机是将这些优势引入量子领域，提出一种加权同质量子集成方法。

**Method:** 本文提出了一种加权同质量子集成方法，该方法使用带有索引寄存器进行数据编码的量子分类器。这种方法利用基于实例的量子分类器，通过叠加和受控酉变换实现特征和训练点的子采样，并允许以量子并行方式执行具有不同数据组成的内部分类器。该方法整合了涉及电路执行和经典权重优化的学习过程，以便在测试时执行编码了权重的训练好的集成。

**Result:** 经验评估证明了所提出方法的有效性，并提供了对其性能的深入见解。

**Conclusion:** 所提出的加权同质量子集成方法是有效的，能够提高预测精度。

> **ai_Abstract:** 本文提出了一种加权同质量子分类器集成方法，旨在结合多个量子模型以提高预测准确性。该方法利用带有索引寄存器的量子分类器进行数据编码，并通过叠加和受控酉变换实现特征和训练点的子采样，从而在量子并行模式下执行多样化的内部分类器。它还集成了量子电路执行和经典的权重优化过程，以在测试时使用编码在电路中的权重进行集成。经验评估验证了该方法的有效性。

> **摘要翻译:** 机器学习中的集成方法旨在通过结合多个模型来提高预测精度。这通过确保预测器之间的多样性来实现，以捕捉不同的数据方面。同质集成使用相同的模型，通过不同的数据子集实现多样性；加权平均集成通过权重学习过程为更准确的模型分配更高的影响力。我们提出了一种使用带有索引寄存器进行数据编码的量子分类器来实现加权同质量子集成的方法。这种方法利用基于实例的量子分类器，通过叠加和受控酉变换实现特征和训练点的子采样，并允许以量子并行方式执行具有不同数据组成的内部分类器。该方法整合了涉及电路执行和经典权重优化的学习过程，以便在测试时执行编码了权重的训练好的集成。经验评估证明了所提出方法的有效性，并提供了对其性能的深入见解。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [165] [Optimal quantum sampling on distributed databases](https://arxiv.org/abs/2506.07724)
> *分布式数据库上的最优量子采样*

*Longyun Chen, Jingcheng Liu, Penghui Yao* | **Main category: quant-ph**

**Keywords:** 量子采样, 分布式数据库, 最优算法, 预定通信, 量子存储

**Comment:** 

> **TL;DR:** 由于大规模量子存储成本高昂，本文研究了分布式数据库上的量子采样问题，并提出了在预定通信模型下最优的顺序和并行算法。

**AI_Comments:** 本文的创新之处在于，它通过将基本的量子子程序（采样）应用于分布式环境，解决了实际挑战（高昂的量子存储成本）。对最优算法以及不同通信模型（顺序与并行）的关注也值得注意。

<details>
  <summary>Details</summary>

**Motivation:** 大规模量子存储成本高昂，这促使研究人员在分布式环境下探索量子采样问题。

**Method:** 本文假设数据分布在多台机器上，每台机器维护一个计算元素多重性的基本预言机。协调器向所有机器进行预言机查询以实现联合数据库采样。研究聚焦于预定通信模型，并提出了顺序和并行两种算法。

**Result:** 本文提出了针对分布式数据库上量子采样的顺序和并行算法。并证明这两种算法在各自设置下都是最优的。

**Conclusion:** 本文在预定通信模型下，成功引入并分析了分布式数据库上的最优量子采样算法，解决了大规模量子存储成本带来的挑战。

> **ai_Abstract:** 本文针对大规模量子存储成本高昂的问题，在分布式数据库环境下研究了量子采样。在数据分布且机器具有基本多重性预言机的假设下，文章提出了在预定通信模型下，协调器从联合数据库采样的顺序和并行算法，并证明了其最优性。

> **摘要翻译:** 量子采样是许多量子算法中的一个基本子程序，它涉及将给定的概率分布编码到纯态的振幅中。鉴于大规模量子存储的巨大成本，我们启动了分布式环境下量子采样的研究。具体来说，我们假设数据分布在多台机器上，每台机器只维护一个计算单个元素多重性的基本预言机。给定一个量子采样任务，即从联合数据库中进行采样，协调器可以向所有机器进行预言机查询。我们专注于预定通信模型，其中协调器和机器之间的通信是预先确定的。我们提出了顺序算法和并行算法：顺序算法依次查询机器，而并行算法允许协调器同时查询所有机器。此外，我们证明这两种算法在各自的设置中都是最优的。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [255] [Quantum accessible information and classical entropy inequalities](https://arxiv.org/abs/2506.06700)
> *量子可及信息与经典熵不等式*

*A. S. Holevo, A. V. Utkin* | **Main category: quant-ph**

**Keywords:** 量子可及信息, 香农熵, 熵不等式, 量子金字塔, 全局信息最优测量

**Comment:** 34 pages, no figures

> **TL;DR:** 本文重新审视并证明了关于等角等概率量子态（量子金字塔）系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式。

**AI_Comments:** 该论文通过严谨的数学证明，解决了量子信息理论中的一个重要假设，即将量子金字塔的全局信息最优测量问题与经典熵不等式联系起来。其创新之处在于将优化准则应用于特定量子态系综，从而推导出香农熵的紧致下界，并成功证明了先前研究中的假设。这项工作对深入理解量子信息的可及性及其与经典熵的联系具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 计算量子态系综的可及信息是量子信息论中的一个基本问题。此外，作者旨在重新审视并证明先前研究中提出的关于等角等概率态系综的全局信息最优测量的假设。

**Method:** 本文应用了文献[7]中获得的优化准则，将其应用于特定的态系综，以推导香农熵的非平凡紧致下界。研究人员重新审视了文献[2]中提出的关于等角等概率态系综（量子金字塔）的全局信息最优测量的假设，并提出了相应的紧致熵不等式。他们证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立。

**Result:** 应用优化准则得到了香农熵的非平凡紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。研究人员提出了等角等概率态系综的紧致熵不等式，并证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立，从而为关于全局信息最优可观测量的假设提供了证明。

**Conclusion:** 本文成功地证明了关于等角等概率量子态系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式，为量子信息理论提供了重要的理论支持。

> **ai_Abstract:** 本文探讨了量子态系综的可及信息计算问题，这是一个量子信息论中的基本问题。研究人员应用了最近获得的优化准则，推导出了香农熵的非平凡紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。在此基础上，文章重新审视并证明了文献[2]中提出的关于等角等概率量子态（量子金字塔）系综的全局信息最优测量的假设，并提出了相应的紧致熵不等式。这些不等式在锐角或平坦金字塔态系综的情况下得到了证明，从而证实了全局信息最优可观测量的假设。

> **摘要翻译:** 计算量子态系综的可及信息是量子信息论中的一个基本问题。文献[7]中最近获得的优化准则，当应用于特定的态系综时，可以为香农熵提供非平凡的紧致下界，这些下界是著名的对数-索伯列夫不等式的离散形式。鉴于此，本文重新审视了文献[2]中提出并经过数值验证的关于等角等概率态系综（量子金字塔）的全局信息最优测量的假设，并提出了相应的紧致熵不等式。我们证明了这些不等式在对应于锐角或平坦金字塔的态系综情况下的成立，从而为关于全局信息最优可观测量的假设提供了证明。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [729] [Depth-Optimal Quantum Layout Synthesis as SAT](https://arxiv.org/abs/2506.06752)
> *错误：AI分析失败。*

*Anna B. Jakobsen, Anders B. Clausen, Jaco van de Pol, Irfansha Shaik* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 24 pages, 4 figures, 11 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [906] [Deep reinforcement learning for near-deterministic preparation of cubic- and quartic-phase gates in photonic quantum computing](https://arxiv.org/abs/2506.07859)
> *错误：AI分析失败。*

*Amanuel Anteneh Léandre Brunel, Carlos González-Arciniegas, Olivier Pfister* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [1018] [Adam assisted Fully informed Particle Swarm Optimzation ( Adam-FIPSO ) based Parameter Prediction for the Quantum Approximate Optimization Algorithm (QAOA)](https://arxiv.org/abs/2506.06790)
> *错误：AI分析失败。*

*Shashank Sanjay Bhat, Peiyong Wang, Udaya Parampalli* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [1019] [Hadamard-$Π$: Equational Quantum Programming](https://arxiv.org/abs/2506.06835)
> *错误：AI分析失败。*

*Wang Fang, Chris Heunen, Robin Kaarsgaard* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 116 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [1023] [Quantum SAT Problems with Finite Sets of Projectors are Complete for a Plethora of Classes](https://arxiv.org/abs/2506.07244)
> *错误：AI分析失败。*

*Ricardo Rivera Cardoso, Alex Meiburg, Daniel Nagaj* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 81 pages, 14 figures. To appear in TQC2025 proceedings

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

### [1026] [Quantum Information-Theoretical Size Bounds for Conjunctive Queries with Functional Dependencies](https://arxiv.org/abs/2506.07552)
> *错误：AI分析失败。*

*Valter Uotila, Jiaheng Lu* | **Main category: quant-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#quant-ph) | [⬆️ 返回总目录](#toc)

---

<a id='csdb'></a>
## cs.DB 

### [167] [KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes](https://arxiv.org/abs/2506.06541)
> *KramaBench：一个针对数据湖上数据到洞察管道中AI系统的基准*

*Eugenie Lai, Gerardo Vitagliano, Ziyu Zhang, Sivaprasad Sudhir, Om Chabra, Anna Zeng, Anton A. Zabreyko, Chenning Li, Ferdi Kossmann, Jialin Ding, Jun Chen, Markos Markakis, Matthew Russo, Weiyang Wang, Ziniu Wu, Michael J. Cafarella, Lei Cao, Samuel Madden, Tim Kraska* | **Main category: cs.DB**

**Keywords:** 数据到洞察管道, 数据湖, AI系统, 基准, 数据科学智能体

**Comment:** 

> **TL;DR:** 该论文引入了KramaBench，这是一个用于评估AI系统处理复杂真实世界数据到洞察管道能力的基准。现有AI模型在这些端到端任务上表现不足，这突显了对更好自主数据科学智能体的需求。

**AI_Comments:** KramaBench通过关注复杂真实世界数据科学管道所需的端到端能力，弥补了AI评估中的一个关键空白。其手动策划的性质和多样化的领域使其成为一个强大的基准。研究结果表明当前模型在整合领域知识和处理复杂数据处理工作流方面的不足，这对于推动自主数据科学的发展具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 尽管AI系统在推理、编码和理解方面表现出色，但尚不清楚这些能力在设计和执行涉及数据提取、集成、清理和分析等复杂真实世界数据到洞察管道方面的转化程度。因此，需要一个基准来评估AI系统在这方面的端到端能力。

**Method:** 研究人员推出了KRAMABENCH，这是一个包含104个手动策划的真实世界数据科学管道的基准，涵盖来自6个不同领域24个数据源的1700个数据文件。他们使用DS-GURU参考框架评估了5个通用模型和3个代码生成模型，该框架指导AI模型将问题分解为子任务、推理每个步骤并生成Python代码。

**Result:** KRAMABENCH的评估结果表明，尽管现有模型足以解决规范明确的数据科学代码生成任务，但在需要大量数据处理和领域知识来构建真实世界数据科学管道时，现有开箱即用模型表现不足。

**Conclusion:** KramaBench的进展对于开发用于真实世界应用的自主数据科学智能体至关重要，因为当前的AI系统在处理端到端数据到洞察管道的复杂性方面仍面临挑战。

> **ai_Abstract:** KramaBench是一个新的基准，旨在评估AI系统在构建真实世界数据湖上数据到洞察管道方面的能力。该基准包含104个真实数据科学管道，涵盖广泛的数据处理任务，从数据发现到统计推理和流程编排。评估结果表明，尽管现有AI模型在特定代码生成任务上表现良好，但在处理需要大量数据处理和领域知识的复杂真实世界管道时，它们仍显不足。KramaBench的进展被认为是开发自主数据科学智能体的关键一步。

> **摘要翻译:** 构建真实世界的数据到洞察管道通常涉及从数据湖中提取数据、跨异构数据源进行数据集成以及从数据清洗到分析的各种操作。数据科学管道的设计和实现需要领域知识、技术专长，甚至项目特定的洞察力。AI系统已经展示出卓越的推理、编码和理解能力。然而，尚不清楚这些能力在多大程度上转化为成功设计和执行此类复杂管道。我们引入了KRAMABENCH：一个由104个手动策划的真实世界数据科学管道组成的基准，涵盖来自6个不同领域24个数据源的1700个数据文件。我们表明，这些管道测试了AI系统在数据处理方面的端到端能力，需要数据发现、整理和清洗、高效处理、统计推理以及根据高级任务编排数据处理步骤。我们的评估使用我们的参考框架DS-GURU测试了5个通用模型和3个代码生成模型，该框架指导AI模型将问题分解为一系列子任务，推理每个步骤，并合成实现所提出设计的Python代码。我们在KRAMABENCH上的结果表明，尽管模型足以解决规范明确的数据科学代码生成任务，但当构建真实世界数据科学管道需要大量数据处理和领域知识时，现有开箱即用模型表现不足。KramaBench的进展代表着开发用于真实世界应用的自主数据科学智能体的关键步骤。我们的代码、参考框架和数据可在https://github.com/mitdbg/KramaBench获取。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

### [990] [QUITE: A Query Rewrite System Beyond Rules with LLM Agents](https://arxiv.org/abs/2506.07675)
> *错误：AI分析失败。*

*Yuyang Song, Hanxu Yan, Jiale Lao, Yibo Wang, Yufei Li, Yuanchun Zhou, Jianguo Wang, Mingjie Tang* | **Main category: cs.DB**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdb) | [⬆️ 返回总目录](#toc)

---

<a id='csgr'></a>
## cs.GR 

### [181] [Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization](https://arxiv.org/abs/2506.07069)
> *使用神经排序和轴向光栅化加速3D高斯泼溅*

*Zhican Wang, Guanghui He, Dantong Liu, Lingjun Gao, Shell Xu Hu, Chen Zhang, Zhuoran Song, Nicholas Lane, Wayne Luk, Hongxiang Fan* | **Main category: cs.GR**

**Keywords:** 3D高斯泼溅, 神经排序, 轴向光栅化, 硬件-算法协同设计, 实时渲染

**Comment:** Preprint. Under review

> **TL;DR:** 本文提出了一种架构-算法协同设计，通过神经排序和轴向光栅化显著加速资源受限设备上的3D高斯泼溅，实现了高速度提升和能耗节省。

**AI_Comments:** 该论文通过将硬件-软件协同设计与新颖的算法技术（神经排序、轴向光栅化）相结合，提出了一种高度创新的方法，解决了在边缘设备上实时3DGS渲染的关键问题。所实现的显著速度提升和能耗节省突出了其在AR/VR和自动驾驶等对效率至关重要的应用中的潜在影响。开源设计的计划也对研究社区做出了宝贵贡献。

<details>
  <summary>Details</summary>

**Motivation:** 尽管3D高斯泼溅（3DGS）在高质量和高效视图合成方面表现出色，但由于严格的功耗和面积预算，在资源受限设备上实现实时渲染仍然是一个重大挑战。传统光栅化中存在大量冗余计算，且排序过程效率低下。

**Method:** 1. 提出轴向光栅化，通过专门的硬件设计预计算并重用沿X和Y轴的共享项，减少多乘加（MAC）操作高达63%。2. 引入新颖的神经排序方法，使用高效神经网络预测与顺序无关的混合权重，消除对昂贵硬件排序器的需求，并提出专门的训练框架提高算法稳定性。3. 设计高效的可重构处理阵列，统一支持光栅化和神经网络推理，最大化硬件利用率和吞吐量。4. 引入受莫顿编码和希尔伯特曲线启发的$\\pi$-轨迹瓦片调度，优化高斯重用并减少内存访问开销。

**Result:** 所提出的设计在保持渲染质量的同时，与边缘GPU相比，在真实场景中实现了23.4~27.8倍的速度提升和28.8~51.4倍的能耗节省。

**Conclusion:** 本文提出了一种有效的架构-算法协同设计，用于加速资源受限设备上的3D高斯泼溅，显著提高了性能和能效。作者计划开源其设计以促进该领域的进一步发展。

> **ai_Abstract:** 本文介绍了一种架构-算法协同设计，旨在加速资源受限设备上的3D高斯泼溅（3DGS），解决在严格功耗和面积预算下实时渲染的挑战。主要创新包括轴向光栅化，通过重用共享项减少冗余计算；以及神经排序，通过神经网络预测混合权重，无需硬件排序器。此外，还提出了高效的可重构处理阵列和$\\pi$-轨迹瓦片调度，以优化硬件利用率、吞吐量、高斯重用和内存访问。实验结果表明，与边缘GPU相比，所提出的设计在保持渲染质量的同时，显著提高了渲染速度（23.4-27.8倍）和能效（28.8-51.4倍）。

> **摘要翻译:** 3D高斯泼溅（3DGS）最近因其高质量和高效的视图合成而受到广泛关注，使其在AR/VR、机器人和自动驾驶等领域得到广泛应用。尽管其算法性能令人印象深刻，但由于严格的功耗和面积预算，在资源受限设备上实现实时渲染仍然是一个重大挑战。本文提出了一种架构-算法协同设计来解决这些低效率问题。首先，我们揭示了传统光栅化过程中重复计算常见项/表达式所造成的实质性冗余。为了解决这个问题，我们提出了轴向光栅化，通过专门的硬件设计预计算并重用沿X和Y轴的共享项，有效减少了多乘加（MAC）操作高达63%。其次，通过识别排序过程中的资源和性能低效率，我们引入了一种新颖的神经排序方法，该方法使用高效的神经网络预测与顺序无关的混合权重，从而无需昂贵的硬件排序器。还提出了一个专门的训练框架来提高其算法稳定性。第三，为了统一支持光栅化和神经网络推理，我们设计了一种高效的可重构处理阵列，以最大限度地提高硬件利用率和吞吐量。此外，我们引入了一种受莫顿编码和希尔伯特曲线启发的$\\pi$轨迹瓦片调度，以优化高斯重用并减少内存访问开销。综合实验表明，与边缘GPU相比，所提出的设计在保持渲染质量的同时，在真实场景中实现了23.4~27.8倍的速度提升和28.8~51.4倍的能耗节省。我们计划开源我们的设计，以促进该领域的进一步发展。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [488] [Vid2Sim: Generalizable, Video-based Reconstruction of Appearance, Geometry and Physics for Mesh-free Simulation](https://arxiv.org/abs/2506.06440)
> *错误：AI分析失败。*

*Chuhao Chen, Zhiyang Dou, Chen Wang, Yiming Huang, Anjun Chen, Qiao Feng, Jiatao Gu, Lingjie Liu* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by CVPR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [523] [Splat and Replace: 3D Reconstruction with Repetitive Elements](https://arxiv.org/abs/2506.06462)
> *错误：AI分析失败。*

*Nicolás Violante, Andreas Meuleman, Alban Gauthier, Frédo Durand, Thibault Groueix, George Drettakis* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** SIGGRAPH Conference Papers 2025. Project site:
  https://repo-sam.inria.fr/nerphys/splat-and-replace/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [548] [Noise Consistency Regularization for Improved Subject-Driven Image Synthesis](https://arxiv.org/abs/2506.06483)
> *错误：AI分析失败。*

*Yao Ni, Song Wen, Piotr Koniusz, Anoop Cherian* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [565] [JGS2: Near Second-order Converging Jacobi/Gauss-Seidel for GPU Elastodynamics](https://arxiv.org/abs/2506.06494)
> *错误：AI分析失败。*

*Lei Lan, Zixuan Lu, Chun Yuan, Weiwei Xu, Hao Su, Huamin Wang, Chenfanfu Jiang, Yin Yang* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [805] [HOI-PAGE: Zero-Shot Human-Object Interaction Generation with Part Affordance Guidance](https://arxiv.org/abs/2506.07209)
> *错误：AI分析失败。*

*Lei Li, Angela Dai* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://hoipage.github.io/ Video:
  https://youtu.be/b1pJU9lKQTE

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [823] [PIG: Physically-based Multi-Material Interaction with 3D Gaussians](https://arxiv.org/abs/2506.07657)
> *错误：AI分析失败。*

*Zeyu Xiao, Zhenyi Wu, Mingyang Sun, Qipeng Yan, Yufan Guo, Zhuoer Liang, Lihua Zhang* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [828] [GaussianVAE: Adaptive Learning Dynamics of 3D Gaussians for High-Fidelity Super-Resolution](https://arxiv.org/abs/2506.07897)
> *错误：AI分析失败。*

*Shuja Khalid, Mohamed Ibrahim, Yang Liu* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [830] [Speedy Deformable 3D Gaussian Splatting: Fast Rendering and Compression of Dynamic Scenes](https://arxiv.org/abs/2506.07917)
> *错误：AI分析失败。*

*Allen Tu, Haiyang Ying, Alex Hanson, Yonghan Lee, Tom Goldstein, Matthias Zwicker* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** Project Page: https://speede3dgs.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [833] [Squeeze3D: Your 3D Generation Model is Secretly an Extreme Neural Compressor](https://arxiv.org/abs/2506.07932)
> *错误：AI分析失败。*

*Rishit Dagli, Yushi Guan, Sankeerth Durvasula, Mohammadreza Mofayezi, Nandita Vijaykumar* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [918] [CrossGen: Learning and Generating Cross Fields for Quad Meshing](https://arxiv.org/abs/2506.07020)
> *错误：AI分析失败。*

*Qiujie Dong, Jiepeng Wang, Rui Xu, Cheng Lin, Yuan Liu, Shiqing Xin, Zichun Zhong, Xin Li, Changhe Tu, Taku Komura, Leif Kobbelt, Scott Schaefer, Wenping Wang* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** Project page: https://anonymousproject-homepage.github.io/

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

### [977] [Immersive Visualization of Flat Surfaces Using Ray Marching](https://arxiv.org/abs/2506.07558)
> *错误：AI分析失败。*

*Fabian Lander, Diaaeldin Taha* | **Main category: cs.GR**

**Keywords:** 错误：AI分析失败。

**Comment:** Presented at Bridges Math and Art Conference, Eindhoven 2025. Online
  demo and code available at
  https://fabianlander.github.io/apps/raymarchingflatsurfacesapp/ and
  https://github.com/FabianLander/RayMarchingFlatSurfaces

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgr) | [⬆️ 返回总目录](#toc)

---

<a id='eesssy'></a>
## eess.SY 

### [189] [FPGA-Based Material Testing Machine Controller](https://arxiv.org/abs/2506.07139)
> *基于FPGA的材料测试机控制器*

*Arev Hambardzumyan, Rafayel Ghasabyan, Vahagn Tamazyan* | **Main category: eess.SY**

**Keywords:** FPGA, 材料测试, 控制器, 并行控制, 可重构性

**Comment:** 

> **TL;DR:** 传统的材料测试控制器在可扩展性、适应性、并行性和速度方面存在局限，FPGA控制器提供了一种高性能解决方案，具有可重构性和并行控制能力，适用于多通道测试设备。

**AI_Comments:** 本文指出FPGA在材料测试控制器领域的应用，其创新性在于利用FPGA的可重构性和并行处理能力，解决了传统控制器在可扩展性、适应性和速度上的瓶颈，对于需要处理多样化材料和多通道测试的现代测试设备具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 在当代材料测试领域，由于材料和测试标准的日益多样化，对可扩展性、适应性、并行性和速度的需求激增。传统的基于控制器的系统往往难以满足这些要求，导致适应性和处理速度受限。

**Method:** 本研究提出并采用FPGA（现场可编程门阵列）作为材料测试机的控制器，以解决传统控制器的局限性。

**Result:** 基于FPGA的控制器具有可重构能力，能够经济高效地适应不断变化的材料和标准；同时，FPGA还能够集成并行控制和数据采集电路，这对于需要多个控制通道同时独立运行的多通道测试设备至关重要。

**Conclusion:** 基于FPGA的控制器为材料测试提供了一种多功能、高性能的解决方案，能够克服传统系统在适应性、并行性和速度方面的局限性。

> **ai_Abstract:** 鉴于现代材料测试对可扩展性、适应性、并行性和速度的需求，本研究提出了一种基于FPGA的材料测试机控制器。与传统控制器相比，FPGA控制器能够提供可重构能力以适应不断变化的材料和标准，并支持集成并行控制和数据采集电路，从而满足多通道测试设备对同时独立操作的需求，提供了一种高性能的解决方案。

> **摘要翻译:** 在当代材料测试领域，由于材料和测试标准的日益多样化，对可扩展性、适应性、并行性和速度的需求激增。传统的基于控制器的系统往往难以满足这些要求，导致适应性和处理速度受限。相比之下，基于FPGA的控制器提供了一种多功能、高性能的解决方案。基于FPGA的控制器在材料测试中的主要优势包括：可重构能力，能够经济高效地适应不断变化的材料和标准；FPGA还能够集成并行控制和数据采集电路，这对于需要多个控制通道同时独立运行的多通道测试设备至关重要。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [210] [Deep Equivariant Multi-Agent Control Barrier Functions](https://arxiv.org/abs/2506.07755)
> *深度等变多智能体控制障碍函数*

*Nikolaos Bousias, Lars Lindemann, George Pappas* | **Main category: eess.SY**

**Keywords:** 控制障碍函数, 多智能体系统, 对称性, 等变神经网络, 安全性

**Comment:** 

> **TL;DR:** 本文提出了一种融入对称性的分布式控制障碍函数（symmetries-infused distributed Control Barrier Functions），通过利用系统固有几何结构，解决了现有学习型控制障碍函数在多智能体系统安全方面面临的可伸缩性、泛化性和采样效率不足的问题。该方法在多机器人导航任务中表现出色，实现了零样本泛化，并在安全性、可伸缩性和任务成功率方面优于现有基线。

**AI_Comments:** 这篇论文的创新点在于将群对称性（group symmetries）的概念引入到多智能体控制障碍函数（CBF）的设计中，解决了传统学习型CBF方法在可伸缩性和泛化性方面的局限。通过理论分析和实际仿真，证明了利用等变参数化可以显著提升多智能体系统的安全性和任务成功率，特别是在零样本泛化到更大规模群体方面表现出色。这项工作强调了在设计安全分布式神经策略时，考虑并嵌入系统内在几何结构的重要性，对于未来大规模自主多智能体系统的安全部署具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于学习的控制障碍函数（CBF）方法在可伸缩性、泛化性和采样效率方面不足，因为它们忽略了系统固有的几何结构，这在复杂环境中大规模部署多智能体系统时，确保数据驱动策略的安全性是一个关键挑战。

**Method:** 引入了融入对称性的分布式控制障碍函数，通过强制在可学习的基于图的安全证书上满足内在对称性。该方法理论上论证了CBF和策略进行等变参数化的必要性，并提出了一种简单、高效且适应性强的方法，通过兼容群作用来构建等变群模块化网络，以分布式、数据高效的方式编码安全约束。

**Result:** 在多机器人导航任务的广泛模拟中，该方法在安全性、可伸缩性和任务成功率方面优于最先进的基线，并能够对更大、更密集的群体进行零样本泛化。

**Conclusion:** 强调了在安全分布式神经策略中嵌入对称性的重要性。

> **ai_Abstract:** 本文提出了一种名为“融入对称性的分布式控制障碍函数”（symmetries-infused distributed Control Barrier Functions）的新方法，旨在解决现有学习型控制障碍函数在多智能体系统安全方面存在的扩展性、泛化性和采样效率不足的问题。通过利用系统固有的几何对称性，并构建等变群模块化网络，该方法能够以分布式且数据高效的方式编码安全约束，并实现了对更大、更密集群体的零样本泛化。实验结果表明，该方法在多机器人导航任务中，在安全性、可伸缩性和任务成功率方面均优于现有基线。

> **摘要翻译:** 随着多智能体系统在复杂环境中大规模自主部署，确保数据驱动策略的安全性至关重要。控制障碍函数已成为强制执行安全约束的有效工具，然而，现有的基于学习的方法往往缺乏可伸缩性、泛化性和采样效率，因为它们忽略了系统固有的几何结构。为了弥补这一空白，我们引入了融入对称性的分布式控制障碍函数，强制在可学习的基于图的安全证书上满足内在对称性。我们从理论上阐述了CBF和策略进行等变参数化的必要性，并提出了一种简单、高效且适应性强的方法，通过兼容群作用来构建此类等变群模块化网络。这种方法以分布式、数据高效的方式编码安全约束，能够对更大、更密集的群体进行零样本泛化。通过在多机器人导航任务上的广泛模拟，我们证明了我们的方法在安全性、可伸缩性和任务成功率方面优于最先进的基线，突出了在安全分布式神经策略中嵌入对称性的重要性。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [419] [Towards Data-Driven Model-Free Safety-Critical Control](https://arxiv.org/abs/2506.06931)
> *错误：AI分析失败。*

*Zhe Shen, Yitaek Kim, Christoffer Sloth* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** submitted to IROS 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [508] [A Koopman-backstepping approach to data-driven robust output regulation for linear parabolic systems](https://arxiv.org/abs/2506.06451)
> *错误：AI分析失败。*

*Joachim Deutscher, Julian Zimmer* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 11 pages, 3 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [551] [The Economic Dispatch of Power-to-Gas Systems with Deep Reinforcement Learning:Tackling the Challenge of Delayed Rewards with Long-Term Energy Storage](https://arxiv.org/abs/2506.06484)
> *错误：AI分析失败。*

*Manuel Sage, Khalil Al Handawi, Yaoyao Fiona Zhao* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted for publication at the 19th ASME International Conference on
  Energy Sustainability

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [598] [Hierarchical Debate-Based Large Language Model (LLM) for Complex Task Planning of 6G Network Management](https://arxiv.org/abs/2506.06519)
> *错误：AI分析失败。*

*Yuyan Lin, Hao Zhou, Chengming Hu, Xue Liu, Hao Chen, Yan Xin, Jianzhong, Zhang* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [650] [Learning Neural Controllers with Optimality and Stability Guarantees Using Input-Output Dissipativity](https://arxiv.org/abs/2506.06564)
> *错误：AI分析失败。*

*Han Wang, Keyan Miao, Diego Madeira, Antonis Papachristodoulou* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** submitted to Automatica

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [666] [Evaluating Undergrounding Decisions for Wildfire Ignition Risk Mitigation across Multiple Hazards](https://arxiv.org/abs/2506.06575)
> *错误：AI分析失败。*

*Ryan Piansky, Daniel K. Molzahn, Nicole D. Jackson, J. Kyle Skolfield* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [681] [From Model-Based and Adaptive Control to Evolving Fuzzy Control](https://arxiv.org/abs/2506.06594)
> *错误：AI分析失败。*

*Daniel Leite, Igor Škrjanc, Fernando Gomide* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 4 pages, 2 figures. Fuzz-IEEE 2025 Booklet: 60 Years of Fuzzy Set
  Theory

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [721] [Computationally Efficient Analytical Models of Frequency and Voltage in Low-Inertia Systems](https://arxiv.org/abs/2506.06620)
> *错误：AI分析失败。*

*Marena Trujillo, Amir Sajadi, Jonathan Shaw, Bri-Mathias Hodge* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [771] [Controlled Reach-avoid Set Computation for Discrete-time Polynomial Systems via Convex Optimization](https://arxiv.org/abs/2506.06679)
> *错误：AI分析失败。*

*Taoran Wu, Yiling Xue, Dejin Ren, Arvind Easwaran, Martin Fränzle, Bai Xue* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [780] [Optimizing Battery and Line Undergrounding Investments for Transmission Systems under Wildfire Risk Scenarios: A Benders Decomposition Approach](https://arxiv.org/abs/2506.06687)
> *错误：AI分析失败。*

*Ryan Piansky, Rahul K. Gupta, Daniel K. Molzahn* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [811] [On the Generalization of Data-Assisted Control in port-Hamiltonian Systems (DAC-pH)](https://arxiv.org/abs/2506.07079)
> *错误：AI分析失败。*

*Mostafa Eslami, Maryam Babazadeh* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** This paper presents an early investigation of Data-Assisted Control
  (DAC) with reinforcement learning, showcasing its potential through a simple
  example. Theoretical analysis is ongoing to establish formal support and
  guarantees for the proposed approach

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [818] [Adaptive Event-triggered Formation Control of Autonomous Vehicles](https://arxiv.org/abs/2506.06746)
> *错误：AI分析失败。*

*Ziming Wang, Yihuai Zhang, Chenguang Zhao, Huan Yu* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [856] [Distributed Risk-Sensitive Safety Filters for Uncertain Discrete-Time Systems](https://arxiv.org/abs/2506.07347)
> *错误：AI分析失败。*

*Armin Lederer, Erfaun Noorani, Andreas Krause* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [864] [Deep reinforcement learning-based joint real-time energy scheduling for green buildings with heterogeneous battery energy storage devices](https://arxiv.org/abs/2506.06824)
> *错误：AI分析失败。*

*Chi Liu, Zhezhuang Xu, Jiawei Zhou, Yazhou Yuan, Kai Ma, Meng Yuan* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [923] [Attitude Estimation Using Scalar Measurements](https://arxiv.org/abs/2506.07068)
> *错误：AI分析失败。*

*Hassan Alnahhal, Sifeddine Benahmed, Soulaimane Berkane, Tarel Hamel* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 6 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [930] [Decentralized Optimization with Amplified Privacy via Efficient Communication](https://arxiv.org/abs/2506.07102)
> *错误：AI分析失败。*

*Wei Huo, Changxin Liu, Kemi Ding, Karl Henrik Johansson, Ling Shi* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [956] [Extended Version of "Distributed Adaptive Resilient Consensus Control for Uncertain Nonlinear Multiagent Systems Against Deception Attacks"](https://arxiv.org/abs/2506.07374)
> *错误：AI分析失败。*

*Mengze Yu, Wei Wang, Jiaqi Yan* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 7 pages, 6 figures. submitted to IEEE Control Systems Letters

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [972] [Pseudo-random sequences for low-cost operando impedance measurements of Li-ion batteries](https://arxiv.org/abs/2506.07519)
> *错误：AI分析失败。*

*Jussi Sihvo, Noël Hallemans, Ai Hui Tan, David A. Howey, Stephen. R. Duncan, Tomi Roinila* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [992] [A 40.68-MHz, 200-ns-Settling Active Rectifier and TX-Side Load Monitoring for Minimizing Radiated Power in Biomedical Implants](https://arxiv.org/abs/2506.07710)
> *错误：AI分析失败。*

*Ronald Wijermars, Yi-Han Ou-Yang, Sijun Du, Dante Gabriel Muratore* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

### [1006] [A distributed motion planning approach to cooperative underwater acoustic source tracking and pursuit](https://arxiv.org/abs/2506.07877)
> *错误：AI分析失败。*

*Andrea Tiranti, Francesco Wanderlingh, Enrico Simetti, Marco Baglietto, Giovanni Indiveri, Antonio Pascoal* | **Main category: eess.SY**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eesssy) | [⬆️ 返回总目录](#toc)

---

<a id='cshc'></a>
## cs.HC 

### [226] [Human Side of Smart Contract Fuzzing: An Empirical Study](https://arxiv.org/abs/2506.07389)
> *智能合约模糊测试的人为因素：一项实证研究*

*Guanming Qiao, Partha Protim Paul* | **Main category: cs.HC**

**Keywords:** 智能合约模糊测试, 人为因素, 易用性, 区块链安全, 漏洞检测

**Comment:** 

> **TL;DR:** 本研究通过分析GitHub issues和用户研究，探讨了智能合约模糊测试工具在实际应用中面临的技术和人为挑战，并为工具设计改进提供了见解。

**AI_Comments:** 这项研究通过结合GitHub issue分析和用户研究，从“人为因素”的角度深入剖析了智能合约模糊测试工具的实际采用障碍，这对于传统上偏重技术的研究领域而言具有创新性。其发现的挑战，特别是关于文档和自动化方面的问题，为工具开发者提供了非常具体的改进方向，有助于弥合理论研究与实际应用之间的鸿沟，对提升智能合约模糊测试工具的实用性和普及性具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 智能合约模糊测试是检测区块链应用漏洞的关键技术，但由于智能合约与传统软件系统之间的根本差异，其实际应用对从业者来说仍然充满挑战。本研究旨在调查从业者在采用智能合约模糊测试工具时所面临的挑战。

**Method:** 本研究通过对两个广泛使用的智能合约模糊测试工具（Echidna和Foundry）的381个GitHub issues进行归纳内容分析。此外，还进行了一项用户研究，以检查这些挑战如何影响不同的从业者群体（智能合约开发者和传统软件安全专业人员），并确定从业者克服这些挑战的策略。研究系统地将这些挑战分类。

**Result:** 研究发现领域特定的易用性和有用性挑战，包括区块链模拟的技术问题，以及缺乏可访问文档和流程自动化的人为问题。

**Conclusion:** 研究结果为工具开发者和研究人员提供了可操作的见解，指导未来智能合约模糊测试工具设计的改进。

> **ai_Abstract:** 本研究通过分析GitHub issues和进行用户研究，深入探讨了智能合约模糊测试工具在实际应用中面临的挑战，特别关注了技术障碍（如区块链模拟）和人为因素（如文档不足和自动化缺乏）。研究结果旨在为智能合约模糊测试工具的设计改进提供指导，以提高其易用性和实用性，从而促进其在区块链安全领域的广泛应用。

> **摘要翻译:** 智能合约（SC）模糊测试是检测区块链应用程序漏洞的关键技术。然而，由于SC与传统软件系统之间的根本差异，其实际应用对从业者来说仍然充满挑战。在本研究中，我们通过对两个广泛使用的SC模糊测试器：Echidna和Foundry的381个GitHub issue进行归纳内容分析，调查了从业者在采用SC模糊测试工具时所面临的挑战。此外，我们还进行了一项用户研究，以检查这些挑战如何影响不同的从业者群体，即SC开发者和传统软件安全专业人员，并确定从业者克服这些挑战的策略。我们根据这些挑战的性质及其在SC模糊测试工作流程中的出现，将其系统地分类。我们的发现揭示了领域特定的易用性和有用性挑战，包括区块链模拟的技术问题，以及缺乏可访问文档和流程自动化的人为问题。我们的结果为工具开发者和研究人员提供了可操作的见解，指导未来SC模糊测试工具设计的改进。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [230] [Fake Friends and Sponsored Ads: The Risks of Advertising in Conversational Search](https://arxiv.org/abs/2506.06447)
> *虚假朋友和赞助广告：对话式搜索中广告的风险*

*Jacob Erickson* | **Main category: cs.HC**

**Keywords:** 对话式搜索, 广告风险, 虚假朋友困境, 用户体验, 人工智能伦理

**Comment:** Accepted for publication at ACM CUI 2025

> **TL;DR:** 本文探讨了对话式搜索（如ChatGPT）中广告的潜在风险，包括用户体验下降、数据滥用、误导甚至伤害用户，并提出了“虚假朋友困境”。

**AI_Comments:** 这篇论文提出了一个非常及时且重要的议题，即在人工智能驱动的对话式搜索日益普及的今天，广告可能带来的伦理和用户体验风险。文章引入的“虚假朋友困境”概念尤其具有创新性，它深刻揭示了AI代理在商业利益驱动下可能对用户信任造成的潜在滥用。该研究不仅提出了问题，还呼吁采取行动，这对于未来AI产品设计和政策制定具有指导意义，强调了在商业利益与用户福祉之间取得平衡的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 数字商务严重依赖广告，但广告在信息检索（如搜索）中可能通过降低搜索质量、滥用用户数据、误导甚至伤害用户来损害用户体验。随着ChatGPT等对话式搜索技术的普及，这些挑战依然严峻，因此有必要审视对话式搜索中广告的未来。

**Method:** 本文通过几个推测性示例来阐述对话式搜索中广告对寻求敏感话题指导的用户可能造成的风险。此外，它概述了广告在该领域可能采取的形式，并提出了“虚假朋友困境”，即对话代理可能利用未对齐的用户信任来实现其他目标。

**Result:** 本文批判性地审视了对话式搜索中广告的未来，揭示了广告对用户（尤其是在敏感话题上）潜在的风险，并提出了“虚假朋友困境”，即对话代理可能利用用户信任以达成自身目的。

**Conclusion:** 本文对对话式搜索中在线广告的未来进行了发人深省的讨论，并以行动呼吁结束。

> **ai_Abstract:** 本文探讨了在ChatGPT等对话式搜索技术普及的背景下，广告可能对用户体验和信息质量造成的负面影响。文章通过推测性示例揭示了广告可能带来的风险，例如降低搜索质量、滥用用户数据、误导甚至伤害用户，并提出了“虚假朋友困境”，即对话式代理可能利用用户信任来实现自身目标。研究对对话式搜索中的广告未来进行了深入讨论，并呼吁采取行动。

> **摘要翻译:** 数字商务依靠广告蓬勃发展，许多最大的科技公司将其作为重要的收入来源。然而，在信息寻求行为（如搜索）的背景下，广告可能会通过降低搜索质量、滥用用户数据进行不当个性化、可能误导个人甚至导致他们受到伤害来降低用户体验。随着ChatGPT等对话式搜索技术的普及，这些挑战依然严峻。本文批判性地审视了对话式搜索中广告的未来，利用几个推测性示例来说明对寻求敏感话题指导的用户可能造成的潜在风险。此外，它概述了广告在该领域可能采取的形式，并引入了“虚假朋友困境”，即对话代理可能利用未对齐的用户信任来实现其他目标。本研究对对话式搜索领域在线广告的未来进行了发人深省的讨论，并以行动呼吁结束。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [380] [Identity Deepfake Threats to Biometric Authentication Systems: Public and Expert Perspectives](https://arxiv.org/abs/2506.06825)
> *身份深度伪造对生物识别认证系统的威胁：公众和专家视角*

*Shijing He, Yaxiong Lei, Zihan Zhang, Yuzhou Sun, Shujun Li, Chi Zhang, Juan Ye* | **Main category: cs.HC**

**Keywords:** 深度伪造, 生物识别认证, 公众认知, 专家视角, 深度伪造杀伤链, 缓解框架

**Comment:** 

> **TL;DR:** 本研究通过调查和访谈揭示了公众与专家在生物识别深度伪造威胁认知上的差异，并提出了一个深度伪造杀伤链模型和三层缓解框架。

**AI_Comments:** 这项研究通过结合实证调查和访谈，深入揭示了生物识别深度伪造威胁中公众与专家认知之间的关键差距，这对于理解和应对实际安全挑战至关重要。其创新点在于提出了“深度伪造杀伤链模型”和基于此模型的三层缓解框架，为防御AI生成的身份威胁提供了具体的、以人为本的策略，而非单纯的技术解决方案。这种多维度的方法使其在当前快速发展的AI威胁背景下具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 发现生成式AI深度伪造对生物识别认证构成威胁，但专家理解与公众认知之间存在显著差距，这导致系统存在关键漏洞。研究旨在弥合这一差距，为防御AI生成的身份威胁提供实证路线图。

**Method:** 采用混合方法研究，包括对408名关键行业专业人士的调查，以及对37名参与者（25名专家，12名公众）进行深度访谈。引入了新的深度伪造杀伤链模型，并基于此模型和实证结果提出了三层缓解框架。

**Result:** 发现公众日益依赖生物识别技术，而专家对静态模态（如面部和语音识别）的欺骗表示严重担忧。在意识和信任方面存在显著的人口统计学和行业特定差异，例如金融专业人士表现出更高的怀疑态度。

**Conclusion:** 本工作提供了首个以实证为基础的路线图，通过将技术保障与以人为本的见解相结合，以防御AI生成的身份威胁。

> **ai_Abstract:** 本研究探讨了生成式AI深度伪造对生物识别认证系统的威胁，并揭示了专家与公众在风险认知上的显著差异。通过混合方法研究（调查和访谈），作者发现公众为求便利日益依赖生物识别，而专家则对静态模态的欺骗深感担忧。研究引入了深度伪造杀伤链模型，并据此提出了一个三层缓解框架，强调动态生物识别信号、隐私保护数据治理和有针对性教育的重要性，旨在提供防御AI生成身份威胁的实证路线图。

> **摘要翻译:** 生成式AI (Gen-AI) 深度伪造对生物识别认证构成迅速演变的威胁，然而，专家对这些风险的理解与公众认知之间存在显著差距。这种脱节在数百万用户信任的系统中造成了关键漏洞。为了弥合这一差距，我们进行了一项全面的混合方法研究，调查了408名来自关键行业的专业人士，并对37名参与者（25名专家，12名普通公众 [非专家]）进行了深度访谈。我们的发现揭示了一个悖论：尽管公众日益依赖生物识别技术以求便利，但专家对静态模态（如面部和语音识别）的欺骗表示严重担忧。我们发现在意识和信任方面存在显著的人口统计学和行业特定差异，例如金融专业人士表现出更高的怀疑态度。为了系统地分析这些威胁，我们引入了一个新颖的深度伪造杀伤链模型，该模型改编自Hutchins et al.的网络安全框架，用于描绘恶意行为者针对生物识别系统使用的特定攻击向量。基于此模型和我们的实证发现，我们提出了一个三层缓解框架，优先考虑动态生物识别信号（例如，眼球运动）、强大的隐私保护数据治理以及有针对性的教育 H。这项工作提供了首个以实证为基础的路线图，通过将技术保障与以人为本的见解相结合，以防御AI生成的身份威胁。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [532] [RadioGami: Batteryless, Long-Range Wireless Paper Sensors Using Tunnel Diodes](https://arxiv.org/abs/2506.06473)
> *错误：AI分析失败。*

*Imran Fahad, Danny Scott, Azizul Zahid, Matthew Bringle, Srinayana Patil, Ella Bevins, Carmen Palileo, Sai Swaminathan* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** The paper is published in the Proceedings of the ACM on Interactive,
  Mobile, Wearable and Ubiquitous Technologies (IMWUT) and will be presented at
  UbiComp 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [770] [LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models](https://arxiv.org/abs/2506.06874)
> *错误：AI分析失败。*

*Ala Yankouskaya, Areej B. Babiker, Syeda W. F. Rizvi, Sameha Alshakhsi, Magnus Liebherr, Raian Ali* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [838] [Mind Games! Exploring the Impact of Dark Patterns in Mixed Reality Scenarios](https://arxiv.org/abs/2506.06774)
> *错误：AI分析失败。*

*Luca-Maxim Meinhardt, Simon Demharter, Michael Rietzler, Mark Colley, Thomas Eßmeyer, Enrico Rukzio* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [839] [Sword and Shield: Uses and Strategies of LLMs in Navigating Disinformation](https://arxiv.org/abs/2506.07211)
> *错误：AI分析失败。*

*Gionnieve Lim, Bryan Chen Zhengyu Tan, Kellie Yu Hui Sim, Weiyan Shi, Ming Hui Chew, Ming Shan Hee, Roy Ka-Wei Lee, Simon T. Perrault, Kenny Tsu Wei Choo* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [847] [Secondary Stakeholders in AI: Fighting for, Brokering, and Navigating Agency](https://arxiv.org/abs/2506.07281)
> *错误：AI分析失败。*

*Leah Hope Ajmani, Nuredin Ali Abdelkadir, Stevie Chancellor* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [866] [In-Sensor Motion Recognition with Memristive System and Light Sensing Surfaces](https://arxiv.org/abs/2506.06829)
> *错误：AI分析失败。*

*Hritom Das, Imran Fahad, SNB Tushar, Sk Hasibul Alam, Graham Buchanan, Danny Scott, Garrett S. Rose, Sai Swaminathan* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** The paper was published in the 2024 IEEE Computer Society Annual
  Symposium on VLSI (ISVLSI)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [921] [From Inquisitorial to Adversarial: Using Legal Theory to Redesign Online Reporting Systems](https://arxiv.org/abs/2506.07041)
> *错误：AI分析失败。*

*Leijie Wang, Weizi Wu, Lirong Que, Nirvan Tyagi, Amy X. Zhang* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** Under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [940] [earEOG via Periauricular Electrodes to Facilitate Eye Tracking in a Natural Headphone Form Factor](https://arxiv.org/abs/2506.07193)
> *错误：AI分析失败。*

*Tobias King, Michael Knierim, Philipp Lepold, Christopher Clarke, Hans Gellersen, Michael Beigl, Tobias Röddiger* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [946] [IDEIA: A Generative AI-Based System for Real-Time Editorial Ideation in Digital Journalism](https://arxiv.org/abs/2506.07278)
> *错误：AI分析失败。*

*Victor B. Santos, Cauã O. Jordão, Leonardo J. O. Ibiapina, Gabriel M. Silva, Mirella E. B. Santana, Matheus A. Garrido, Lucas R. C. Farias* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [958] [Happiness Finder: Exploring the Role of AI in Enhancing Well-Being During Four-Leaf Clover Searches](https://arxiv.org/abs/2506.07393)
> *错误：AI分析失败。*

*Anna Yokokubo, Takeo Hamada, Tatsuya Ishizuka, Hiroaki Mori, Noboru Koshizuka* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [991] [Interaction Analysis by Humans and AI: A Comparative Perspective](https://arxiv.org/abs/2506.07707)
> *错误：AI分析失败。*

*Maryam Teimouri, Filip Ginter, Tomi "bgt" Suovuo* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [1000] [Supporting Aging Well through Accessible Digital Games: The Supplemental Role of AI in Game Design for Older Adults](https://arxiv.org/abs/2506.07777)
> *错误：AI分析失败。*

*Brandon Lyman, Yichi Zhang, Celia Pearce, Miso Kim, Casper Harteveld, Leanne Chukoskie, Bob De Schutter* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, 1 figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [1004] [Integrating Artificial Intelligence as Assistive Technology for Older Adult Gamers: A Pilot Study](https://arxiv.org/abs/2506.07830)
> *错误：AI分析失败。*

*Yichi Zhang, Brandon Lyman, Celia Pearce, Miso Kim, Casper Harteveld, Leanne Chukoskie, Bob De Schutter* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 9 pages, 1 figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [1008] [Predicting Situation Awareness from Physiological Signals](https://arxiv.org/abs/2506.07930)
> *错误：AI分析失败。*

*Kieran J. Smith, Tristan C. Endsley, Torin K. Clark* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 15 pages, 6 figures, submitted to IEEE Transactions on Human-Machine
  Systems

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [1011] [Implementation Considerations for Automated AI Grading of Student Work](https://arxiv.org/abs/2506.07955)
> *错误：AI分析失败。*

*Zewei, Tian, Alex Liu, Lief Esbenshade, Shawon Sarkar, Zachary Zhang, Kevin He, Min Sun* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

### [1012] [Supporting Construction Worker Well-Being with a Multi-Agent Conversational AI System](https://arxiv.org/abs/2506.07997)
> *错误：AI分析失败。*

*Fan Yang, Yuan Tian, Jiansong Zhang* | **Main category: cs.HC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cshc) | [⬆️ 返回总目录](#toc)

---

<a id='cspl'></a>
## cs.PL 

### [243] [Execution-Aware Program Reduction for WebAssembly via Record and Replay](https://arxiv.org/abs/2506.07834)
> *通过记录和回放实现WebAssembly的执行感知程序精简*

*Doehyun Baek, Daniel Lehmann, Ben L. Titzer, Sukyoung Ryu, Michael Pradel* | **Main category: cs.PL**

**Keywords:** WebAssembly, 程序精简, 调试, 记录和回放, 执行感知

**Comment:** 

> **TL;DR:** 本文提出了RR-Reduce和Hybrid-Reduce，这是两种新颖的执行感知程序精简技术，用于WebAssembly (Wasm) 程序调试。它们通过记录和回放利用执行行为，显著优于现有方法，在精简速度和程序大小方面均有大幅提升。

**AI_Comments:** 本文的创新之处在于通过记录和回放利用程序的执行行为来进行程序精简，这相较于静态的、执行不感知的现有方法是一个重大改进。这种方法解决了调试复杂Wasm程序中的关键挑战，提供了快速精简和极限大小精简的能力。实验中展示的显著性能提升对实际的调试工作流程具有高度影响力。

<details>
  <summary>Details</summary>

**Motivation:** 现有的执行不感知程序精简技术难以处理大型和复杂的WebAssembly (Wasm) 程序，因为它们依赖于静态信息和语法转换，而忽略了输入程序执行行为提供的宝贵信息，这阻碍了WebAssembly引擎中错误的调试。

**Method:** 本文提出了两种执行感知程序精简技术：
1. RR-Reduce：识别触发错误的函数作为目标函数，将其从程序其余部分中分离，并通过回放目标函数与程序其余部分之间的交互来生成精简程序。
2. Hybrid-Reduce：将RR-Reduce与一种互补的执行不感知精简技术结合，以进一步减小程序大小。
两种技术都通过记录和回放来利用程序的执行行为。

**Result:** 在28个触发各种错误的Wasm程序上进行了评估：
- RR-Reduce：平均在14.5分钟内将程序精简到其原始大小的1.20%，精简时间比现有技术快33.15倍。
- Hybrid-Reduce：平均在3.5小时内将程序精简到其原始大小的0.13%，精简程序大小比现有技术好3.42倍，精简时间比现有技术快2.26倍。

**Conclusion:** RR-Reduce被设想为几分钟内快速、按需调试的首选工具，而Hybrid-Reduce则适用于开发人员需要最小程序的场景。这些技术为WebAssembly程序的调试精简提供了显著的改进。

> **ai_Abstract:** 本文介绍了RR-Reduce和Hybrid-Reduce，这两种新颖的执行感知程序精简技术，专为WebAssembly (Wasm) 程序设计。与现有依赖静态信息、忽略执行行为的方法不同，这些技术通过记录和回放来识别并隔离触发错误的函数，或结合其他精简方法。评估结果表明，RR-Reduce显著提高了精简速度（比现有技术快33.15倍），而Hybrid-Reduce则能实现更小的程序大小（原始大小的0.13%）和更快的精简时间，使其成为Wasm调试的重要工具。

> **摘要翻译:** WebAssembly (Wasm) 程序可能会触发其引擎实现中的错误。为了帮助调试，程序精简技术尝试生成输入程序的较小变体，该变体仍能触发错误。然而，现有的执行不感知程序精简技术难以处理大型和复杂的 Wasm 程序，因为它们依赖于静态信息并应用语法转换，同时忽略了输入程序执行行为提供的宝贵信息。
我们提出了 RR-Reduce 和 Hybrid-Reduce，这是新颖的执行感知程序精简技术，它们通过记录和回放利用执行行为。RR-Reduce 识别一个触发错误的函数作为目标函数，将该函数从程序的其余部分中分离出来，并生成一个精简的程序，该程序只回放目标函数与程序其余部分之间的交互。Hybrid-Reduce 将一种互补的执行不感知精简技术与 RR-Reduce 结合起来，以进一步减小程序大小。
我们在 28 个 Wasm 程序上评估了 RR-Reduce 和 Hybrid-Reduce，这些程序在三个引擎中触发了各种错误。平均而言，RR-Reduce 在 14.5 分钟内将程序精简到其原始大小的 1.20%，在精简时间方面比现有技术快 33.15 倍。Hybrid-Reduce 在 3.5 小时内将程序精简到其原始大小的 0.13%，在精简程序大小方面比现有技术好 3.42 倍，在精简时间方面好 2.26 倍。我们将 RR-Reduce 设想为几分钟内快速、按需调试的首选工具，而 Hybrid-Reduce 则适用于开发人员需要最小程序的场景。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [568] [Optimizing Optimizations: Case Study on Detecting Specific Types of Mathematical Optimization Constraints with E-Graphs in JijModeling](https://arxiv.org/abs/2506.06495)
> *错误：AI分析失败。*

*Hiromi Ishii, Taro Shimizu, Toshiki Teramura* | **Main category: cs.PL**

**Keywords:** 错误：AI分析失败。

**Comment:** To be presented at EGRAPHS '25
  https://pldi25.sigplan.org/home/egraphs-2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

### [629] [Reasoning about External Calls](https://arxiv.org/abs/2506.06544)
> *错误：AI分析失败。*

*Sophia Drossopoulou, Julian Mackay, Susan Eisenbach, James Noble* | **Main category: cs.PL**

**Keywords:** 错误：AI分析失败。

**Comment:** 86 pages, 25 main paper, and 58 pages of appendices, many diagrams
  and figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cspl) | [⬆️ 返回总目录](#toc)

---

<a id='math-ph'></a>
## math-ph 

### [246] [Skewness of von Neumann entropy over Bures-Hall random states](https://arxiv.org/abs/2506.06663)
> *Bures-Hall随机态中冯诺依曼熵的偏度*

*Linfeng Wei, Youyi Huang, Lu Wei* | **Main category: math-ph**

**Keywords:** 冯诺依曼熵, Bures-Hall系综, 偏度, 累积量, 求和恒等式

**Comment:** 33 pages, 2 figures

> **TL;DR:** 本文计算了Bures-Hall随机态中冯诺依曼熵的第三个累积量（偏度），得到了精确的闭合形式公式，并通过发现新的求和恒等式，提高了冯诺依曼熵分布的近似精度。

**AI_Comments:** 该论文的创新之处在于推导出了冯诺依曼熵第三个累积量的精确闭合形式公式，这极大地提高了对其分布的理解和近似精度。同时，发现“十几个新的求和恒等式”是方法学上的一个重要贡献，展现了解决量子信息理论中复杂问题（特别是纠缠量化）的深厚数学方法。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在研究Bures-Hall系综中冯诺依曼熵的偏度，通过计算其第三个累积量来描述分布的不对称程度，以补充现有文献中仅包含前两个累积量的研究。

**Method:** 通过计算冯诺依曼熵的第三个累积量来研究其偏度。关键在于发现了十几个新的求和恒等式，用于简化涉及多伽马函数的大量有限求和。

**Result:** 得到了冯诺依曼熵第三个累积量的精确闭合形式公式。

**Conclusion:** 所推导的第三个累积量的精确闭合形式公式，使得冯诺依曼熵分布的近似更加准确。

> **ai_Abstract:** 本文研究了Bures-Hall系综中双分系统冯诺依曼熵的偏度，扩展了先前仅涉及前两个累积量的工作。作者推导出了第三个累积量的精确闭合形式公式，该公式量化了分布的不对称性。这一成果的取得得益于发现了新的求和恒等式，用于简化多伽马函数的求和，最终使得冯诺依曼熵分布的近似更加精确。

> **摘要翻译:** 我们研究了Bures-Hall系综中双分系统纠缠的程度，以冯诺依曼熵衡量。最近文献中已经推导出了该系综上冯诺依曼熵前两个累积量的闭合形式表达式。在本文中，我们通过计算描述分布不对称程度的第三个累积量来关注其偏度。主要结果是第三个累积量的精确闭合形式公式，这使得冯诺依曼熵的分布近似更加准确。获得结果的关键在于找到十几个新的求和恒等式，以简化大量涉及多伽马函数的有限求和。

</details>

[⬆️ 返回分类顶部](#math-ph) | [⬆️ 返回总目录](#toc)

---

<a id='cssd'></a>
## cs.SD 

### [276] [Towards Energy-Efficient and Low-Latency Voice-Controlled Smart Homes: A Proposal for Offline Speech Recognition and IoT Integration](https://arxiv.org/abs/2506.07494)
> *迈向节能低延迟的语音控制智能家居：离线语音识别与物联网集成的提案*

*Peng Huang, Imdad Ullah, Xiaotong Wei, Tariq Ahamed Ahanger, Najm Hassan, Zawar Hussain Shah* | **Main category: cs.SD**

**Keywords:** 智能家居, 离线语音识别, 物联网集成, 节能, 低延迟

**Comment:** 

> **TL;DR:** 现有智能家居语音控制系统依赖云端，存在能耗、延迟和单点故障问题。本文提出基于离线语音识别和本地IoT网络的智能家居方案，旨在实现低延迟、节能且鲁棒的语音控制。

**AI_Comments:** 这篇立场论文的创新之处在于提出了一种完全离线的智能家居语音控制方案，解决了传统云端方案的痛点。其重要性在于提升了智能家居的隐私性、响应速度和能源效率。该提案为未来智能家居的发展提供了一个有前景的方向，特别是在对实时性和数据安全有高要求的场景下。

<details>
  <summary>Details</summary>

**Motivation:** 现有智能家居AI语音识别服务主要部署在云平台，导致不必要的能耗、通信延迟和单点故障风险。

**Method:** 1) 将离线关键词识别(KWS)技术集成到资源有限的家用电器中，使其能理解语音命令；2) 设计一个去中心化架构的本地IoT网络来管理和连接设备。

**Result:** 该提案将使用户能够在家庭任何地方使用低延迟的语音控制，不依赖互联网，并提供更好的可扩展性和能源可持续性。

**Conclusion:** 通过结合离线语音识别和本地IoT网络，可以构建一个节能、低延迟、高鲁棒性和可扩展性的智能家居系统，摆脱对互联网的依赖。

> **ai_Abstract:** 本文提出一种旨在解决现有云端智能家居语音控制系统能耗高、延迟大及单点故障风险的方案。该方案核心在于将离线关键词识别技术植入本地设备，并构建去中心化的本地物联网网络，从而实现无需互联网依赖的低延迟、节能且高鲁棒性的智能家居语音控制。

> **摘要翻译:** 智能家居系统，基于AI语音识别和物联网技术，使人们能够通过语音命令控制设备，提高人们的生活效率。然而，现有的AI语音识别服务主要部署在互联网上的云平台。当用户发出命令时，像“Amazon Echo”这样的语音识别设备会通过众多网络节点发布录音，到达多个服务器，然后通过互联网接收响应。这种机制存在几个问题，包括不必要的能源消耗、通信延迟和单点故障的风险。在这篇立场论文中，我们提出了一种基于离线语音识别和物联网技术的智能家居概念：1) 将离线关键词识别（KWS）技术集成到资源有限的家用电器中，使其能够理解用户语音命令；2) 设计一个具有去中心化架构的本地物联网网络来管理和连接各种设备，增强系统的鲁棒性和可扩展性。这项基于离线语音识别和物联网技术的智能家居提案将使用户能够在家庭任何地方使用低延迟的语音控制，而无需依赖互联网，并提供更好的可扩展性和能源可持续性。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [429] [Towards Generalized Source Tracing for Codec-Based Deepfake Speech](https://arxiv.org/abs/2506.07294)
> *错误：AI分析失败。*

*Xuanjun Chen, I-Ming Lin, Lin Zhang, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Submitted to IEEE ASRU 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [783] [A Fast and Lightweight Model for Causal Audio-Visual Speech Separation](https://arxiv.org/abs/2506.06689)
> *错误：AI分析失败。*

*Wendi Sang, Kai Li, Runxuan Yang, Jianqiang Huang, Xiaolin Hu* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 8 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [820] [RBA-FE: A Robust Brain-Inspired Audio Feature Extractor for Depression Diagnosis](https://arxiv.org/abs/2506.07118)
> *错误：AI分析失败。*

*Yu-Xuan Wu, Ziyan Huang, Bin Hu, Zhi-Hong Guan* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 14 pages

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [827] [Can Quantized Audio Language Models Perform Zero-Shot Spoofing Detection?](https://arxiv.org/abs/2506.06756)
> *错误：AI分析失败。*

*Bikash Dutta, Rishabh Ranjan, Shyam Sathvik, Mayank Vatsa, Richa Singh* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted in Interspeech 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [837] [SynHate: Detecting Hate Speech in Synthetic Deepfake Audio](https://arxiv.org/abs/2506.06772)
> *错误：AI分析失败。*

*Rishabh Ranjan, Kishan Pipariya, Mayank Vatsa, Richa Singh* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted in Interspeech 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [851] [Speech Recognition on TV Series with Video-guided Post-Correction](https://arxiv.org/abs/2506.07323)
> *错误：AI分析失败。*

*Haoyuan Yang, Yue Zhang, Liqiang Jing* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [858] [Lightweight Joint Audio-Visual Deepfake Detection via Single-Stream Multi-Modal Learning Framework](https://arxiv.org/abs/2506.07358)
> *错误：AI分析失败。*

*Kuiyuan Zhang, Wenjie Pei, Rushi Lan, Yifang Guo, Zhongyun Hua* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [868] [Audio synthesizer inversion in symmetric parameter spaces with approximately equivariant flow matching](https://arxiv.org/abs/2506.07199)
> *错误：AI分析失败。*

*Ben Hayes, Charalampos Saitis, György Fazekas* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted at ISMIR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [881] [LeVo: High-Quality Song Generation with Multi-Preference Alignment](https://arxiv.org/abs/2506.07520)
> *错误：AI分析失败。*

*Shun Lei, Yaoxun Xu, Zhiwei Lin, Huaicheng Zhang, Wei Tan, Hangting Chen, Jianwei Yu, Yixuan Zhang, Chenyu Yang, Haina Zhu, Shuai Wang, Zhiyong Wu, Dong Yu* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [919] ["In This Environment, As That Speaker": A Text-Driven Framework for Multi-Attribute Speech Conversion](https://arxiv.org/abs/2506.07036)
> *错误：AI分析失败。*

*Jiawei Jin, Zhuhan Yang, Yixuan Zhou, Zhiyong Wu* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted by Interspeech2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [925] [Insights on Harmonic Tones from a Generative Music Experiment](https://arxiv.org/abs/2506.07073)
> *错误：AI分析失败。*

*Emmanuel Deruty, Maarten Grachten* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 15th International Workshop on Machine Learning and Music, September
  9, 2024, Vilnius, Lithuania

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [927] [Streaming Endpointer for Spoken Dialogue using Neural Audio Codecs and Label-Delayed Training](https://arxiv.org/abs/2506.07081)
> *错误：AI分析失败。*

*Sathvik Udupa, Shinji Watanabe, Petr Schwarz, Jan Cernocky* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [935] [Technical Report: A Practical Guide to Kaldi ASR Optimization](https://arxiv.org/abs/2506.07149)
> *错误：AI分析失败。*

*Mengze Hong, Di Jiang* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [941] [Methods for pitch analysis in contemporary popular music: Vitalic's use of tones that do not operate on the principle of acoustic resonance](https://arxiv.org/abs/2506.07207)
> *错误：AI分析失败。*

*Emmanuel Deruty, Pascal Arbez-Nicolas, David Meredith* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [966] [An introduction to pitch strength in contemporary popular music analysis and production](https://arxiv.org/abs/2506.07473)
> *错误：AI分析失败。*

*Emmanuel Deruty* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** In Music 2024, Innovation in Music Conference, 14-16 June, 2024,
  Kristiania University College, Oslo, Norway

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [974] [Generative Voice Bursts during Phone Call](https://arxiv.org/abs/2506.07526)
> *错误：AI分析失败。*

*Paritosh Ranjan, Surajit Majumder, Prodip Roy* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** 12 pages, 2 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

### [995] [Towards a Unified Benchmark for Arabic Pronunciation Assessment: Quranic Recitation as Case Study](https://arxiv.org/abs/2506.07722)
> *错误：AI分析失败。*

*Yassine El Kheir, Omnia Ibrahim, Amit Meghanani, Nada Almarwani, Hawau Olamide Toyin, Sadeen Alharbi, Modar Alfadly, Lamya Alkanhal, Ibrahim Selim, Shehab Elbatal, Salima Mdhaffar, Thomas Hain, Yasser Hifny, Mostafa Shahin, Ahmed Ali* | **Main category: cs.SD**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted Interspeech 2025 and ArabicNLP Shared Task 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cssd) | [⬆️ 返回总目录](#toc)

---

<a id='statml'></a>
## stat.ML 

### [281] [Generalization Analysis for Bayesian Optimal Experiment Design under Model Misspecification](https://arxiv.org/abs/2506.07805)
> *模型误设下贝叶斯最优实验设计的泛化分析*

*Roubing Tang, Sabina J. Sloman, Samuel Kaski* | **Main category: stat.ML**

**Keywords:** 贝叶斯最优实验设计, 模型误设, 泛化误差, 协变量漂移, 误差（去）放大

**Comment:** 

> **TL;DR:** 本文对模型误设下贝叶斯最优实验设计的泛化误差进行了分析，并提出了一种新的采集函数以提高泛化性能。

**AI_Comments:** 本文的创新点在于对模型误设下泛化误差的深入分解，特别是识别并命名了“误差（去）放大”这一新现象。此外，通过开发一种考虑代表性和去放大特性的新型采集函数，有效地提高了BOED在实际应用中面对模型误设时的泛化性能，具有重要的理论和实践意义。

<details>
  <summary>Details</summary>

**Motivation:** 在科学和工业（如药物发现和临床试验）中，受时间和预算限制的实验设计是一个核心挑战。贝叶斯最优实验设计（BOED）被越来越多地应用于此类问题。然而，在训练过程中，BOED选择的输入与测试样本的自然分布之间存在协变量漂移，且现有工作表明在模型误设的情况下，协变量漂移会放大泛化误差。

**Method:** 本文首先提供了泛化误差的数学分解，揭示了模型误设情况下泛化误差的关键因素，并识别了一种新的现象——误差（去）放大。其次，进行了详细的实证分析，以证明能产生代表性和去放大训练数据的方法可以提高泛化性能。最后，开发了一种新颖的采集函数，通过包含代表性项并隐式地诱导去放大来减轻模型误设的影响。

**Result:** 研究表明，在模型误设下，泛化误差除了协变量漂移外，还是误差（去）放大现象的结果。实证分析表明，产生代表性和去放大训练数据的方法能提高泛化性能。实验结果证明，所提出的方法在存在模型误设的情况下优于传统的BOED。

**Conclusion:** 本文通过对泛化误差的分解和引入新的采集函数，有效地解决了模型误设下贝叶斯最优实验设计的泛化性能问题，并证明了其优越性。

> **ai_Abstract:** 本文研究了模型误设下贝叶斯最优实验设计（BOED）的泛化性能问题。作者首先对泛化误差进行了数学分解，揭示了除了协变量漂移外，还存在一种新的“误差（去）放大”现象。随后，通过实证分析证明了具有代表性和去放大特性的训练数据能提高泛化性能。最后，提出了一种新的采集函数，通过引入代表性项和隐式诱导去放大来缓解模型误设的影响，实验证明该方法优于传统BOED。

> **摘要翻译:** 在科学和工业中的许多场景，例如药物发现和临床试验，一个核心挑战是在时间和预算限制下设计实验。贝叶斯最优实验设计（BOED）是一种选择信息量最大设计的范式，并已越来越多地应用于此类问题。在训练期间，BOED根据预定的采集标准选择输入。在测试期间，训练期间学习到的模型会遇到自然发生的测试样本分布。这导致了一个协变量漂移的实例，即训练和测试样本来自不同的分布。先前的研究表明，在模型误设的情况下，协变量漂移会放大泛化误差。我们的第一个贡献是提供了泛化误差的数学分解，揭示了在模型误设情况下泛化误差的关键因素。我们表明，在误设下的泛化误差是除了协变量漂移之外，还是一种我们称之为误差（去）放大的现象的结果，这种现象在先前的研究中尚未被识别或研究。我们的第二个贡献是提供了详细的实证分析，以表明产生代表性和去放大训练数据的方法可以提高泛化性能。我们的第三个贡献是开发了一种新颖的采集函数，通过包含一个代表性项并隐式地诱导去放大来减轻模型误设的影响。我们的实验结果表明，我们的方法在存在误设的情况下优于传统的BOED。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [607] [On the Fundamental Impossibility of Hallucination Control in Large Language Models](https://arxiv.org/abs/2506.06382)
> *错误：AI分析失败。*

*Michał P. Karpowicz* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [757] [A Statistical Framework for Model Selection in LSTM Networks](https://arxiv.org/abs/2506.06840)
> *错误：AI分析失败。*

*Fahad Mostafa* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [826] [Direct Fisher Score Estimation for Likelihood Maximization](https://arxiv.org/abs/2506.06542)
> *错误：AI分析失败。*

*Sherman Khoo, Yakun Wang, Song Liu, Mark Beaumont* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [835] [Robust Learnability of Sample-Compressible Distributions under Noisy or Adversarial Perturbations](https://arxiv.org/abs/2506.06613)
> *错误：AI分析失败。*

*Arefe Boushehrian, Amir Najafi* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 50 pages, 1 figure

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [845] [Continuous Semi-Implicit Models](https://arxiv.org/abs/2506.06778)
> *错误：AI分析失败。*

*Longlin Yu, Jiajun Zha, Tong Yang, Tianyu Xie, Xiangyu Zhang, S. -H. Gary Chan, Cheng Zhang* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 26 pages, 8 figures, ICML 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [848] [The Currents of Conflict: Decomposing Conflict Trends with Gaussian Processes](https://arxiv.org/abs/2506.06828)
> *错误：AI分析失败。*

*Simon P. von der Maase* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** Total Words: 8122, Total pages: 28, Total figures: 6, Total Tables: 5

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [860] [Half-AVAE: Adversarial-Enhanced Factorized and Structured Encoder-Free VAE for Underdetermined Independent Component Analysis](https://arxiv.org/abs/2506.07011)
> *错误：AI分析失败。*

*Yuan-Hao Wei, Yan-Jie Sun* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [865] [Quantile-Optimal Policy Learning under Unmeasured Confounding](https://arxiv.org/abs/2506.07140)
> *错误：AI分析失败。*

*Zhongren Chen, Siyu Chen, Zhengling Qi, Xiaohong Chen, Zhuoran Yang* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [871] [ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition](https://arxiv.org/abs/2506.07259)
> *错误：AI分析失败。*

*Daolang Huang, Xinyi Wen, Ayush Bharti, Samuel Kaski, Luigi Acerbi* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 27 pages, 13 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [895] [Rao-Blackwellised Reparameterisation Gradients](https://arxiv.org/abs/2506.07687)
> *错误：AI分析失败。*

*Kevin Lam, Thang Bui, George Deligiannidis, Yee Whye Teh* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [898] [Quickest Causal Change Point Detection by Adaptive Intervention](https://arxiv.org/abs/2506.07760)
> *错误：AI分析失败。*

*Haijie Xu, Chen Zhang* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

### [904] [Accelerating Constrained Sampling: A Large Deviations Approach](https://arxiv.org/abs/2506.07816)
> *错误：AI分析失败。*

*Yingli Wang, Changwei Tu, Xiaoyu Wang, Lingjiong Zhu* | **Main category: stat.ML**

**Keywords:** 错误：AI分析失败。

**Comment:** 40 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statml) | [⬆️ 返回总目录](#toc)

---

<a id='csmm'></a>
## cs.MM 

### [370] [An Efficient Digital Watermarking Technique for Small Scale devices](https://arxiv.org/abs/2506.06691)
> *一种适用于小型设备的有效数字水印技术*

*Kaushik Talathi, Aparna Santra Biswas* | **Main category: cs.MM**

**Keywords:** 数字水印, FWT-AQIM, 小型设备, 物联网, 鲁棒性

**Comment:** 28 pages, 11 figures, 4 tables

> **TL;DR:** 本研究提出了一种混合FWT-AQIM轻量级水印方案，用于在资源受限的小型设备上保护数字图像，并在鲁棒性、不可感知性和计算效率之间取得了平衡。

**AI_Comments:** 该论文的创新之处在于其提出的FWT-AQIM混合方案，专为小型、资源受限设备设计，有效平衡了水印的鲁棒性、不可感知性和计算效率。其在实际硬件（如Raspberry Pi 5）上的出色性能验证了其在物联网和移动应用中内容保护的潜力，为轻量级数字水印领域提供了有价值的贡献。

<details>
  <summary>Details</summary>

**Motivation:** 在物联网和移动平台时代，确保内容真实性同时避免对有限硬件造成过重负担是一个关键问题。

**Method:** 该研究引入了混合快速小波变换和加性量化索引调制（FWT-AQIM）方案。该方法在YCbCr色彩空间的亮度分量中使用低频FWT子带嵌入水印，并使用加性QIM以简化操作，最大限度地减少感知失真。使用基于马赛克的水印增加了冗余，增强了鲁棒性而没有降低吞吐量。

**Result:** 在Raspberry Pi 5上测试时，提取和嵌入过程均在40毫秒内完成，并需要最小的RAM。标准和高分辨率图像的质量评估显示PSNR≥34 dB和SSIM≥0.97。鲁棒性验证包括各种几何和信号处理攻击，显示出接近零的误码率和NCC≥0.998。吞吐量峰值为11 MP/s。

**Conclusion:** FWT-AQIM为带宽和功耗受限环境中的实时安全水印提供了一种高效、可扩展的解决方案，为新兴物联网和多媒体应用中的可靠内容保护开辟了道路。

> **ai_Abstract:** 本研究提出了一种名为FWT-AQIM的混合数字水印技术，旨在解决物联网和移动平台中，在资源受限的小型设备上实现数字内容真实性保护的问题。该方法结合了快速小波变换和加性量化索引调制，将水印嵌入图像的亮度分量中，以在鲁棒性、不可感知性和计算效率之间取得平衡。实验结果表明，该技术在Raspberry Pi 5上运行高效，处理时间短，内存占用低，同时在图像质量和抗攻击鲁棒性方面表现出色，为带宽和功耗受限环境下的实时安全水印提供了有效且可扩展的解决方案。

> **摘要翻译:** 在物联网和移动平台时代，确保内容真实性同时避免对有限硬件造成过重负担是一个关键问题。本研究引入了混合快速小波变换和加性量化索引调制（FWT-AQIM）方案，这是一种轻量级水印方法，用于在低功耗、内存受限的小型设备上保护数字图像，以在鲁棒性、不可感知性和计算效率之间取得平衡。该方法在YCbCr色彩空间的亮度分量中使用低频FWT子带嵌入水印，最大限度地减少感知失真，并使用加性QIM以简化操作。在Raspberry Pi 5上测试时，提取和嵌入过程均在40毫秒内运行，并需要最小的RAM。对标准和高分辨率图像的质量评估显示PSNR大于等于34 dB和SSIM大于等于0.97，而鲁棒性验证包括各种几何和信号处理攻击，显示出接近零的误码率和NCC大于等于0.998。使用基于马赛克的水印，增加了冗余，增强了鲁棒性而没有降低吞吐量，吞吐量峰值为11 MP/s。这些发现表明，FWT-AQIM为带宽和功耗受限环境中的实时安全水印提供了一种高效、可扩展的解决方案，为新兴物联网和多媒体应用中的可靠内容保护开辟了道路。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [792] [Experimental Evaluation of Static Image Sub-Region-Based Search Models Using CLIP](https://arxiv.org/abs/2506.06938)
> *错误：AI分析失败。*

*Bastian Jäckl, Vojtěch Kloda, Daniel A. Keim, Jakub Lokoč* | **Main category: cs.MM**

**Keywords:** 错误：AI分析失败。

**Comment:** 14 pages, 4 figures, 2 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [815] [The State-of-the-Art in Lifelog Retrieval: A Review of Progress at the ACM Lifelog Search Challenge Workshop 2022-24](https://arxiv.org/abs/2506.06743)
> *错误：AI分析失败。*

*Allie Tran, Werner Bailer, Duc-Tien Dang-Nguyen, Graham Healy, Steve Hodges, Björn Þór Jónsson, Luca Rossetto, Klaus Schoeffmann, Minh-Triet Tran, Lucia Vadicamo, Cathal Gurrin* | **Main category: cs.MM**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

### [926] [Harmony-Aware Music-driven Motion Synthesis with Perceptual Constraint on UGC Datasets](https://arxiv.org/abs/2506.07076)
> *错误：AI分析失败。*

*Xinyi Wu, Haohong Wang, Aggelos K. Katsaggelos* | **Main category: cs.MM**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csmm) | [⬆️ 返回总目录](#toc)

---

<a id='csms'></a>
## cs.MS 

### [396] [El0ps: An Exact L0-regularized Problems Solver](https://arxiv.org/abs/2506.06373)
> *El0ps：一个精确的L0正则化问题求解器*

*Théo Guyard, Cédric Herzet, Clément Elvira* | **Main category: cs.MS**

**Keywords:** L0正则化, Python工具箱, 机器学习, 信号处理, 最先进性能

**Comment:** 

> **TL;DR:** El0ps是一个Python工具箱，用于解决机器学习、统计和信号处理中的L0正则化问题，提供灵活的自定义框架、最先进的求解器和内置机器学习管道。

**AI_Comments:** El0ps的创新之处在于其提供了自定义L0正则化问题实例的灵活性，以及一个实现最先进性能的专用求解器，这对于L0正则化问题在实际应用中的推广和集成具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决现有工具箱在处理L0正则化问题时的不足，并为L0正则化问题在机器学习、统计和信号处理等实际应用中的集成提供一个全面的工具。

**Method:** 本文提出了El0ps，一个Python工具箱，它提供了处理L0正则化问题的实用程序。El0ps允许用户通过灵活的框架定义这些问题的自定义实例，提供了一个实现最先进性能的专用求解器，并提供了几个内置的机器学习管道。

**Result:** El0ps提供了一个灵活的框架，允许用户定义L0正则化问题的自定义实例；提供了一个实现最先进性能的专用求解器；并提供了几个内置的机器学习管道。

**Conclusion:** El0ps旨在提供一个全面的工具，为L0正则化问题在实际应用中的集成开辟新视角。

> **ai_Abstract:** 本文介绍了El0ps，一个针对机器学习、统计和信号处理中L0正则化问题的Python工具箱。El0ps通过提供灵活的框架支持自定义问题定义，集成了一个达到最先进性能的专用求解器，并包含多种内置机器学习管道，旨在为L0正则化问题在实际应用中的集成提供一个全面的解决方案。

> **摘要翻译:** 本文介绍了El0ps，一个Python工具箱，它提供了几个实用程序来处理与机器学习、统计学和信号处理等领域应用相关的L0正则化问题。与现有工具箱不同，El0ps允许用户通过灵活的框架定义这些问题的自定义实例，提供了一个实现最先进性能的专用求解器，并提供了几个内置的机器学习管道。我们开发El0ps的目的是提供一个全面的工具，为L0正则化问题在实际应用中的集成开辟新视角。

</details>

[⬆️ 返回分类顶部](#csms) | [⬆️ 返回总目录](#toc)

---

<a id='physicsmed-ph'></a>
## physics.med-ph 

### [434] [Active Lubrication of Transluminal Medical Instruments](https://arxiv.org/abs/2506.07225)
> *错误：AI分析失败。*

*Mostafa A. Atalla, Jelte Nieuwenhuis, Alan Martin, Xuan Wang, Ahranee Canden, Matt J. Carré, Roger Lewis, Aimée Sakes, Michaël Wiertlewski* | **Main category: physics.med-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#physicsmed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='mathnt'></a>
## math.NT 

### [438] [Stark-Coleman Invariants and Quantum Lower Bounds: An Integrated Framework for Real Quadratic Fields](https://arxiv.org/abs/2506.07640)
> *错误：AI分析失败。*

*Ruopengyu Xu, Chenglian Liu* | **Main category: math.NT**

**Keywords:** 错误：AI分析失败。

**Comment:** 16 pages, 1 figure, 3 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

### [1027] [Half-Iterates of $x(1+x)$, $\sin(x)$ and $\exp(x/e)$](https://arxiv.org/abs/2506.07625)
> *错误：AI分析失败。*

*Steven Finch* | **Main category: math.NT**

**Keywords:** 错误：AI分析失败。

**Comment:** 18 pages; 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathnt) | [⬆️ 返回总目录](#toc)

---

<a id='csds'></a>
## cs.DS 

### [512] [Efficient Computation of Closed Substrings](https://arxiv.org/abs/2506.06452)
> *错误：AI分析失败。*

*Samkith K Jain, Neerja Mhaskar* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** Submitted to SPIRE 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [518] [Sample and Expand: Discovering Low-rank Submatrices With Quality Guarantees](https://arxiv.org/abs/2506.06456)
> *错误：AI分析失败。*

*Martino Ciaperoni, Aristides Gionis, Heikki Mannila* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [617] [Modern Minimal Perfect Hashing: A Survey](https://arxiv.org/abs/2506.06536)
> *错误：AI分析失败。*

*Hans-Peter Lehmann, Thomas Mueller, Rasmus Pagh, Giulio Ermanno Pibiri, Peter Sanders, Sebastiano Vigna, Stefan Walzer* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [894] [Online Job Assignment](https://arxiv.org/abs/2506.06893)
> *错误：AI分析失败。*

*Farbod Ekbatani, Yiding Feng, Ian Kash, Rad Niazadeh* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [952] [On Sketching Trimmed Statistics](https://arxiv.org/abs/2506.07342)
> *错误：AI分析失败。*

*Honghao Lin, Hoai-An Nguyen, David P. Woodruff* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

### [989] [On Deterministically Finding an Element of High Order Modulo a Composite](https://arxiv.org/abs/2506.07668)
> *错误：AI分析失败。*

*Ziv Oznovich, Ben Lee Volk* | **Main category: cs.DS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csds) | [⬆️ 返回总目录](#toc)

---

<a id='cscg'></a>
## cs.CG 

### [539] [On geodesic disks enclosing many points](https://arxiv.org/abs/2506.06477)
> *错误：AI分析失败。*

*Prosenjit Bose, Guillermo Esteban, David Orden, Rodrigo Silveira, Tyler Tuttle* | **Main category: cs.CG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [938] [Rectangular Duals on the Cylinder and the Torus](https://arxiv.org/abs/2506.07170)
> *错误：AI分析失败。*

*Therese Biedl, Philipp Kindermann, Jonathan Klawitter* | **Main category: cs.CG**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

### [978] [An $O(n\log n)$ Algorithm for Single-Source Shortest Paths in Disk Graphs](https://arxiv.org/abs/2506.07571)
> *错误：AI分析失败。*

*Mark de Berg, Sergio Cabello* | **Main category: cs.CG**

**Keywords:** 错误：AI分析失败。

**Comment:** 19 pages, 8 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cscg) | [⬆️ 返回总目录](#toc)

---

<a id='eessas'></a>
## eess.AS 

### [670] [AS-ASR: A Lightweight Framework for Aphasia-Specific Automatic Speech Recognition](https://arxiv.org/abs/2506.06566)
> *错误：AI分析失败。*

*Chen Bao, Chuanbing Huo, Qinyu Chen, Chang Gao* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** Under review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [723] [Neural Spectral Band Generation for Audio Coding](https://arxiv.org/abs/2506.06732)
> *错误：AI分析失败。*

*Woongjib Choi, Byeong Hyeon Kim, Hyungseob Lim, Inseon Jang, Hong-Goo Kang* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted to Interspeech 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [1017] [Accurate analysis of the pitch pulse-based magnitude/phase structure of natural vowels and assessment of three lightweight time/frequency voicing restoration methods](https://arxiv.org/abs/2506.06675)
> *错误：AI分析失败。*

*Aníbal J. S. Ferreira, Luis M. T. Jesus, Laurentino M. M. Leal, Jorge E. F. Spratley* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** 58 pages, 17 figures, 8 tables

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [1022] [Reducing Object Hallucination in Large Audio-Language Models via Audio-Aware Decoding](https://arxiv.org/abs/2506.07233)
> *错误：AI分析失败。*

*Tzu-wen Hsu, Ke-Han Lu, Cheng-Han Chiang, Hung-yi Lee* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [1025] [Speaker-Distinguishable CTC: Learning Speaker Distinction Using CTC for Multi-Talker Speech Recognition](https://arxiv.org/abs/2506.07515)
> *错误：AI分析失败。*

*Asahi Sakuma, Hiroaki Sato, Ryuga Sugano, Tadashi Kumano, Yoshihiko Kawai, Tetsuji Ogawa* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted at INTERSPEECH 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

### [1028] [SongBloom: Coherent Song Generation via Interleaved Autoregressive Sketching and Diffusion Refinement](https://arxiv.org/abs/2506.07634)
> *错误：AI分析失败。*

*Chenyu Yang, Shuai Wang, Hangting Chen, Wei Tan, Jianwei Yu, Haizhou Li* | **Main category: eess.AS**

**Keywords:** 错误：AI分析失败。

**Comment:** Submitted to NeurIPS2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessas) | [⬆️ 返回总目录](#toc)

---

<a id='eessiv'></a>
## eess.IV 

### [766] [ResPF: Residual Poisson Flow for Efficient and Physically Consistent Sparse-View CT Reconstruction](https://arxiv.org/abs/2506.06400)
> *错误：AI分析失败。*

*Changsheng Fang, Yongtong Liu, Bahareh Morovati, Shuo Han, Yu Shi, Li Zhou, Shuyi Fan, Hengyong Yu* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [787] [SPC to 3D: Novel View Synthesis from Binary SPC via I2I translation](https://arxiv.org/abs/2506.06890)
> *错误：AI分析失败。*

*Sumit Sharma, Gopi Raju Matta, Kaushik Mitra* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** Accepted for publication at ICIP 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [794] [Optimal Transport Driven Asymmetric Image-to-Image Translation for Nuclei Segmentation of Histological Images](https://arxiv.org/abs/2506.07023)
> *错误：AI分析失败。*

*Suman Mahapatra, Pradipta Maji* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 8 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [795] [SiliCoN: Simultaneous Nuclei Segmentation and Color Normalization of Histological Images](https://arxiv.org/abs/2506.07028)
> *错误：AI分析失败。*

*Suman Mahapatra, Pradipta Maji* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 10 pages, 9 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [807] [Transfer Learning and Explainable AI for Brain Tumor Classification: A Study Using MRI Data from Bangladesh](https://arxiv.org/abs/2506.07228)
> *错误：AI分析失败。*

*Shuvashis Sarker* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 2024 6th International Conference on Sustainable Technologies for
  Industry 5.0 (STI)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [809] [A Comprehensive Analysis of COVID-19 Detection Using Bangladeshi Data and Explainable AI](https://arxiv.org/abs/2506.07234)
> *错误：AI分析失败。*

*Shuvashis Sarker* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 2024 4th International Conference on Innovations in Science,
  Engineering and Technology (ICISET)

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [810] [A Narrative Review on Large AI Models in Lung Cancer Screening, Diagnosis, and Treatment Planning](https://arxiv.org/abs/2506.07236)
> *错误：AI分析失败。*

*Jiachen Zhong, Yiting Wang, Di Zhu, Ziwei Wang* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** Under Review

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [819] [Text-guided multi-stage cross-perception network for medical image segmentation](https://arxiv.org/abs/2506.07475)
> *错误：AI分析失败。*

*Gaoyu Chen* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

### [825] [Fine-Grained Motion Compression and Selective Temporal Fusion for Neural B-Frame Video Coding](https://arxiv.org/abs/2506.07709)
> *错误：AI分析失败。*

*Xihua Sheng, Peilin Chen, Meng Wang, Li Zhang, Shiqi Wang, Dapeng Oliver Wu* | **Main category: eess.IV**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#eessiv) | [⬆️ 返回总目录](#toc)

---

<a id='cslo'></a>
## cs.LO 

### [769] [Recursive Semantic Anchoring in ISO 639:2023: A Structural Extension to ISO/TC 37 Frameworks](https://arxiv.org/abs/2506.06870)
> *错误：AI分析失败。*

*Bugra Kilictas, Faruk Alpay* | **Main category: cs.LO**

**Keywords:** 错误：AI分析失败。

**Comment:** 21 pages, no figures. Includes formal proofs, RDF/Turtle ontology
  schema, {\phi}-index disambiguation cases, and evaluation of
  transformer-based AI models under semantic drift

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [983] [Verification of Quantum Circuits through Barrier Certificates using a Scenario Approach](https://arxiv.org/abs/2506.07635)
> *错误：AI分析失败。*

*Siwei Hu, Victor Lopata, Sadegh Soudjani, Paolo Zuliani* | **Main category: cs.LO**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

### [1002] [On-The-Fly Symbolic Algorithm for Timed ATL with Abstractions](https://arxiv.org/abs/2506.07802)
> *错误：AI分析失败。*

*Nicolaj Ø. Jensen, Kim G. Larsen, Didier Lime, Jiří Srba* | **Main category: cs.LO**

**Keywords:** 错误：AI分析失败。

**Comment:** Full version of paper published in CONCUR 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cslo) | [⬆️ 返回总目录](#toc)

---

<a id='q-biobm'></a>
## q-bio.BM 

### [773] [Template-Guided 3D Molecular Pose Generation via Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2506.06305)
> *错误：AI分析失败。*

*Noémie Bergues, Arthur Carré, Paul Join-Lambert, Brice Hoffmann, Arnaud Blondel, Hamza Tajmouati* | **Main category: q-bio.BM**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [798] [AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization](https://arxiv.org/abs/2506.07035)
> *错误：AI分析失败。*

*Zixuan Jiang, Renjing Xu* | **Main category: q-bio.BM**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

### [852] [Graph Neural Networks in Modern AI-aided Drug Discovery](https://arxiv.org/abs/2506.06915)
> *错误：AI分析失败。*

*Odin Zhang, Haitao Lin, Xujun Zhang, Xiaorui Wang, Zhenxing Wu, Qing Ye, Weibo Zhao, Jike Wang, Kejun Ying, Yu Kang, Chang-yu Hsieh, Tingjun Hou* | **Main category: q-bio.BM**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-biobm) | [⬆️ 返回总目录](#toc)

---

<a id='physicscomp-ph'></a>
## physics.comp-ph 

### [775] [Scientific machine learning in Hydrology: a unified perspective](https://arxiv.org/abs/2506.06308)
> *错误：AI分析失败。*

*Adoubi Vincent De Paul Adombi* | **Main category: physics.comp-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#physicscomp-ph) | [⬆️ 返回总目录](#toc)

---

<a id='physicschem-ph'></a>
## physics.chem-ph 

### [801] [ChemGraph: An Agentic Framework for Computational Chemistry Workflows](https://arxiv.org/abs/2506.06363)
> *错误：AI分析失败。*

*Thang D. Pham, Aditya Tanikanti, Murat Keçeli* | **Main category: physics.chem-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#physicschem-ph) | [⬆️ 返回总目录](#toc)

---

<a id='econth'></a>
## econ.TH 

### [808] [From Axioms to Algorithms: Mechanized Proofs of the vNM Utility Theorem](https://arxiv.org/abs/2506.07066)
> *错误：AI分析失败。*

*Li Jingyuan* | **Main category: econ.TH**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#econth) | [⬆️ 返回总目录](#toc)

---

<a id='physicsed-ph'></a>
## physics.ed-ph 

### [813] [Pendulum Tracker -- SimuFísica: A Web-based Tool for Real-time Measurement of Oscillatory Motion](https://arxiv.org/abs/2506.07301)
> *错误：AI分析失败。*

*Marco P. M. de Souza, Juciane G. Maia, Lilian N. de Andrade* | **Main category: physics.ed-ph**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#physicsed-ph) | [⬆️ 返回总目录](#toc)

---

<a id='econgn'></a>
## econ.GN 

### [817] [Improving choice model specification using reinforcement learning](https://arxiv.org/abs/2506.06410)
> *错误：AI分析失败。*

*Gabriel Nova, Sander van Cranenburgh, Stephane Hess* | **Main category: econ.GN**

**Keywords:** 错误：AI分析失败。

**Comment:** 13 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#econgn) | [⬆️ 返回总目录](#toc)

---

<a id='csdl'></a>
## cs.DL 

### [824] [Influential scientists shape knowledge flows between science and IGO policy](https://arxiv.org/abs/2506.06753)
> *错误：AI分析失败。*

*Kimitaka Asatani, Yurie Iwata, Yuta Tomokiyo, Basil Mahfouz, Masaru Yarime, Ichiro Sakata* | **Main category: cs.DL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [976] [From Rapid Release to Reinforced Elite: Citation Inequality Is Stronger in Preprints than Journals](https://arxiv.org/abs/2506.07547)
> *错误：AI分析失败。*

*Chiaki Miura, Ichiro Sakata* | **Main category: cs.DL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

### [998] [Research quality evaluation by AI in the era of Large Language Models: Advantages, disadvantages, and systemic effects](https://arxiv.org/abs/2506.07748)
> *错误：AI分析失败。*

*Mike Thelwall* | **Main category: cs.DL**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdl) | [⬆️ 返回总目录](#toc)

---

<a id='q-fincp'></a>
## q-fin.CP 

### [836] [Explaining Risks: Axiomatic Risk Attributions for Financial Models](https://arxiv.org/abs/2506.06653)
> *错误：AI分析失败。*

*Dangxing Chen* | **Main category: q-fin.CP**

**Keywords:** 错误：AI分析失败。

**Comment:** This article has been accepted for publication in Quantitative
  Finance, published by Taylor & Francis

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

### [875] [Uncertainty-Aware Strategies: A Model-Agnostic Framework for Robust Financial Optimization through Subsampling](https://arxiv.org/abs/2506.07299)
> *错误：AI分析失败。*

*Hans Buehler, Blanka Horvath, Yannick Limmer, Thorsten Schmidt* | **Main category: q-fin.CP**

**Keywords:** 错误：AI分析失败。

**Comment:** 18 pages, 12 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#q-fincp) | [⬆️ 返回总目录](#toc)

---

<a id='csdm'></a>
## cs.DM 

### [862] [HyColor: An Efficient Heuristic Algorithm for Graph Coloring](https://arxiv.org/abs/2506.07373)
> *错误：AI分析失败。*

*Enqiang Zhu, Yu Zhang, Haopeng Sun, Ziqi Wei, Witold Pedrycz, Chanjuan Liu, Jin Xu* | **Main category: cs.DM**

**Keywords:** 错误：AI分析失败。

**Comment:** 14 pages, 4 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

### [944] [CNFs and DNFs with Exactly $k$ Solutions](https://arxiv.org/abs/2506.07268)
> *错误：AI分析失败。*

*L. Sunil Chandran, Rishikesh Gajjala, Kuldeep S. Meel* | **Main category: cs.DM**

**Keywords:** 错误：AI分析失败。

**Comment:** To appear in SAT 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csdm) | [⬆️ 返回总目录](#toc)

---

<a id='physicsoptics'></a>
## physics.optics 

### [863] [Inverse Design of Metamaterials with Manufacturing-Guiding Spectrum-to-Structure Conditional Diffusion Model](https://arxiv.org/abs/2506.07083)
> *错误：AI分析失败。*

*Jiawen Li, Jiang Guo, Yuanzhe Li, Zetian Mao, Jiaxing Shen, Tashi Xu, Diptesh Das, Jinming He, Run Hu, Yaerim Lee, Koji Tsuda, Junichiro Shiomi* | **Main category: physics.optics**

**Keywords:** 错误：AI分析失败。

**Comment:** 20 pages, 7 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#physicsoptics) | [⬆️ 返回总目录](#toc)

---

<a id='mathoc'></a>
## math.OC 

### [879] [Decentralized Optimization on Compact Submanifolds by Quantized Riemannian Gradient Tracking](https://arxiv.org/abs/2506.07351)
> *错误：AI分析失败。*

*Jun Chen, Lina Liu, Tianyi Zhu, Yong Liu, Guang Dai, Yunliang Jiang, Ivor W. Tsang* | **Main category: math.OC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

### [910] [Discrete and Continuous Difference of Submodular Minimization](https://arxiv.org/abs/2506.07952)
> *错误：AI分析失败。*

*George Orfanides, Tim Hoheisel, Marwa El Halabi* | **Main category: math.OC**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathoc) | [⬆️ 返回总目录](#toc)

---

<a id='mathpr'></a>
## math.PR 

### [888] [Poisson Midpoint Method for Log Concave Sampling: Beyond the Strong Error Lower Bounds](https://arxiv.org/abs/2506.07614)
> *错误：AI分析失败。*

*Rishikesh Srinivasan, Dheeraj Nagaraj* | **Main category: math.PR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

### [1020] [CIR bridge for modeling of fish migration on sub-hourly scale](https://arxiv.org/abs/2506.07094)
> *错误：AI分析失败。*

*Hidekazu Yoshioka* | **Main category: math.PR**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathpr) | [⬆️ 返回总目录](#toc)

---

<a id='statme'></a>
## stat.ME 

### [905] [Conditional Local Independence Testing with Application to Dynamic Causal Discovery](https://arxiv.org/abs/2506.07844)
> *错误：AI分析失败。*

*Mingzhou Liu, Xinwei Sun, Yizhou Wang* | **Main category: stat.ME**

**Keywords:** 错误：AI分析失败。

**Comment:** Working paper

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#statme) | [⬆️ 返回总目录](#toc)

---

<a id='csgt'></a>
## cs.GT 

### [937] [Delegation with Costly Inspection](https://arxiv.org/abs/2506.07162)
> *错误：AI分析失败。*

*Mohammad T. Hajiaghayi, Piotr Krysta, Mohammad Mahdavi, Suho Shin* | **Main category: cs.GT**

**Keywords:** 错误：AI分析失败。

**Comment:** To appear at ACM EC 2025

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [939] [Value-Set Iteration: Computing Optimal Correlated Equilibria in Infinite-Horizon Multi-Player Stochastic Games](https://arxiv.org/abs/2506.07186)
> *错误：AI分析失败。*

*Jiarui Gan, Rupak Majumdar* | **Main category: cs.GT**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

### [951] [Vulnerability and Defence: A Case for Stackelberg Game Dynamics](https://arxiv.org/abs/2506.07316)
> *错误：AI分析失败。*

*Azhar Iqbal, Ishan Honhaga, Eyoel Teffera, Anthony Perry, Robin Baker, Glenn Pearce, Claudia Szabo* | **Main category: cs.GT**

**Keywords:** 错误：AI分析失败。

**Comment:** 20 pages, 5 figures

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#csgt) | [⬆️ 返回总目录](#toc)

---

<a id='cspf'></a>
## cs.PF 

### [999] [Pinching-Antenna Systems For Indoor Immersive Communications: A 3D-Modeling Based Performance Analysis](https://arxiv.org/abs/2506.07771)
> *错误：AI分析失败。*

*Yulei Wang, Yalin Liu, Yaru Fu, Zhiguo Ding* | **Main category: cs.PF**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#cspf) | [⬆️ 返回总目录](#toc)

---

<a id='mathap'></a>
## math.AP 

### [1016] [A Directional-ODE Framework for Discretization of Advection-Diffusion Equations](https://arxiv.org/abs/2506.06543)
> *错误：AI分析失败。*

*Amin Jafarimoghaddam, Manuel Soler, Irene Ortiz* | **Main category: math.AP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathap) | [⬆️ 返回总目录](#toc)

---

<a id='mathho'></a>
## math.HO 

### [1021] [Meaning as Use, Application, Employment, Purpose, Usefulness](https://arxiv.org/abs/2506.07131)
> *错误：AI分析失败。*

*Ruy J. G. B. de Queiroz* | **Main category: math.HO**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathho) | [⬆️ 返回总目录](#toc)

---

<a id='mathsp'></a>
## math.SP 

### [1024] [Stable Computation of Laplacian Eigenfunctions Corresponding to Clustered Eigenvalues](https://arxiv.org/abs/2506.07340)
> *错误：AI分析失败。*

*Ryoki Endo, Xuefeng Liu* | **Main category: math.SP**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathsp) | [⬆️ 返回总目录](#toc)

---

<a id='mathco'></a>
## math.CO 

### [1029] [Refuting Perfect Matchings in Spectral Expanders is Hard](https://arxiv.org/abs/2506.07700)
> *错误：AI分析失败。*

*Ari Biswas, Rajko Nenadov* | **Main category: math.CO**

**Keywords:** 错误：AI分析失败。

**Comment:** 

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathco) | [⬆️ 返回总目录](#toc)

---

<a id='mathat'></a>
## math.AT 

### [1030] [Stability and Extension of Steady and Ranging Persistence](https://arxiv.org/abs/2506.07911)
> *错误：AI分析失败。*

*Yann-Situ Gazull* | **Main category: math.AT**

**Keywords:** 错误：AI分析失败。

**Comment:** 20 pages + 11 pages Appendix, preprint

> **TL;DR:** 错误：AI分析失败。

**AI_Comments:** 错误：AI分析失败。

<details>
  <summary>Details</summary>

**Motivation:** 错误：AI分析失败。

**Method:** 错误：AI分析失败。

**Result:** 错误：AI分析失败。

**Conclusion:** 错误：AI分析失败。

> **ai_Abstract:** 错误：AI分析失败。

> **摘要翻译:** 错误：AI分析失败。

</details>

[⬆️ 返回分类顶部](#mathat) | [⬆️ 返回总目录](#toc)

